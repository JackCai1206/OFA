2023-01-09 03:37:30 - utils.py[line:255] - INFO: distributed init (rank 0): env://
2023-01-09 03:37:30 - utils.py[line:261] - INFO: Start init
2023-01-09 03:37:30 - distributed_c10d.py[line:228] - INFO: Added key: store_based_barrier_key:1 to store for rank: 0
2023-01-09 03:37:30 - distributed_c10d.py[line:262] - INFO: Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 1 nodes.
2023-01-09 03:37:30 - utils.py[line:271] - INFO: initialized host Alienware008AMD8647567023 as rank 0
single-machine distributed training is initialized.
2023-01-09 03:37:30 - train.py[line:77] - INFO: {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 10, 'log_format': 'simple', 'log_file': None, 'tensorboard_logdir': None, 'wandb_project': None, 'azureml_logging': False, 'seed': 1, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': 512, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': '../../ofa_module', 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 2, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': 'env://', 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': True, 'ddp_backend': 'pytorch_ddp', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': True, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_algorithm': 'LocalSGD', 'localsgd_frequency': 3, 'nprocs_per_node': 2, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False}, 'dataset': {'_name': None, 'num_workers': 0, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': None, 'batch_size': 4, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 500, 'validate_after_updates': 0, 'fixed_validation_seed': 7, 'disable_validation': False, 'max_tokens_valid': None, 'batch_size_valid': 4, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0}, 'optimization': {'_name': None, 'max_epoch': 10, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 1.0, 'sentence_avg': False, 'update_freq': [8], 'lr': [5e-05], 'stop_min_lr': -1.0, 'use_bmuf': False}, 'checkpoint': {'_name': None, 'save_dir': '../../checkpoints/OFA/detection_checkpoints/10_5e-5_512', 'restore_file': '../../checkpoints/ofa_base.pt', 'finetune_from_model': None, 'reset_dataloader': True, 'reset_lr_scheduler': False, 'reset_meters': True, 'reset_optimizer': True, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 500, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': 1, 'no_save': False, 'no_epoch_checkpoints': True, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'AP', 'maximize_best_checkpoint_metric': True, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1, 'use_ema_weights_to_init_param': False, 'use_latest_weights_to_init_ema': False}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 2}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': Namespace(_name='ofa_base', activation_fn='gelu', adam_betas='(0.9,0.999)', adam_eps=1e-08, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, add_type_embedding=True, all_gather_list_size=16384, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, arch='ofa_base', attention_dropout=0.0, attn_scale_factor=2, azureml_logging=False, batch_size=4, batch_size_valid=4, best_checkpoint_metric='AP', bf16=False, bitfit=False, bpe=None, bpe_dir='../../utils/BPE', broadcast_buffers=False, bucket_cap_mb=25, checkpoint_shard_count=1, checkpoint_suffix='', clip_norm=1.0, code_dict_size=8192, code_image_size=128, code_layernorm_embedding=True, combine_valid_subsets=None, constraint_range=None, cpu=False, cpu_offload=False, criterion='adjust_label_smoothed_cross_entropy', cross_self_attention=False, curriculum=0, data='../../dataset/OFA_data/train.tsv,../../dataset/OFA_data/val.tsv', data_buffer_size=10, dataset_impl=None, ddp_backend='pytorch_ddp', ddp_comm_hook='none', decoder_attention_heads=12, decoder_drop_path_rate=0.1, decoder_embed_dim=768, decoder_embed_path=None, decoder_ffn_embed_dim=3072, decoder_input_dim=768, decoder_layerdrop=0, decoder_layers=6, decoder_layers_to_keep=None, decoder_learned_pos=True, decoder_normalize_before=True, decoder_output_dim=768, device_id=0, disable_entangle=True, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_num_procs=2, distributed_port=-1, distributed_rank=0, distributed_world_size=2, drop_worst_after=0, drop_worst_ratio=0.0, dropout=0.1, ema_decay=0.9999, ema_fp32=False, ema_seed_model=None, ema_start_update=0, ema_update_freq=1, empty_cache_freq=0, encoder_attention_heads=12, encoder_drop_path_rate=0.1, encoder_embed_dim=768, encoder_embed_path=None, encoder_ffn_embed_dim=3072, encoder_layerdrop=0, encoder_layers=6, encoder_layers_to_keep=None, encoder_learned_pos=True, encoder_normalize_before=True, end_learning_rate=0.0, entangle_position_embedding=False, eos=2, eval_acc=True, eval_args='{"beam":5,"max_len_a":0,"max_len_b":200}', eval_print_samples=False, fast_stat_sync=False, find_unused_parameters=True, finetune_from_model=None, fix_batches_to_gpus=False, fixed_validation_seed=7, force_anneal=None, fp16=True, fp16_adam_stats=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=512, fp32_reduce_scatter=False, freeze_decoder_embedding=False, freeze_encoder_embedding=False, gen_subset='test', gradient_as_bucket_view=False, heartbeat_timeout=-1, ignore_eos=False, ignore_prefix_size=0, ignore_unused_valid_subsets=False, image_bucket_size=42, imagenet_default_mean_and_std=False, keep_best_checkpoints=1, keep_interval_updates=-1, keep_interval_updates_pattern=-1, keep_last_epochs=-1, label_smoothing=0.1, layernorm_embedding=True, load_checkpoint_on_all_dp_ranks=False, localsgd_frequency=3, log_file=None, log_format='simple', log_interval=10, lr=[5e-05], lr_scheduler='polynomial_decay', max_epoch=10, max_image_size=512, max_source_positions=1024, max_src_length=80, max_target_positions=1024, max_tgt_length=20, max_tokens=None, max_tokens_valid=None, max_update=0, max_valid_steps=None, maximize_best_checkpoint_metric=True, memory_efficient_bf16=False, memory_efficient_fp16=False, min_loss_scale=0.0001, min_params_to_wrap=100000000, model_parallel_size=1, no_cross_attention=False, no_epoch_checkpoints=True, no_last_checkpoints=False, no_progress_bar=False, no_reshard_after_forward=False, no_save=False, no_save_optimizer_state=False, no_scale_embedding=True, no_seed_provided=False, no_token_positional_embeddings=False, nprocs_per_node=2, num_bins=1000, num_shards=1, num_workers=0, on_cpu_convert_precision=False, optimizer='adam', optimizer_overrides='{}', orig_patch_image_size=256, pad=1, patch_image_size=512, patch_layernorm_embedding=True, patience=-1, pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, plasma_path='/tmp/plasma', pooler_activation_fn='tanh', pooler_classifier='mlp', pooler_dropout=0.0, power=1.0, profile=False, quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, quantization_config_path=None, reg_alpha=1.0, relu_dropout=0.0, report_accuracy=False, required_batch_size_multiple=8, required_seq_len_multiple=1, reset_dataloader=True, reset_logging=False, reset_lr_scheduler=False, reset_meters=True, reset_optimizer=True, resnet_drop_path_rate=0.0, resnet_type='resnet101', restore_file='../../checkpoints/ofa_base.pt', sample_patch_num=196, save_dir='../../checkpoints/OFA/detection_checkpoints/10_5e-5_512', save_interval=1, save_interval_updates=500, scale_attn=True, scale_fc=True, scale_heads=True, scale_resids=False, scoring='bleu', scst=False, scst_args='{}', seed=1, selected_cols='0,1,2', sentence_avg=False, shard_id=0, share_all_embeddings=True, share_decoder_input_output_embed=True, simul_type=None, skip_invalid_size_inputs_valid_test=False, slowmo_algorithm='LocalSGD', slowmo_momentum=None, stop_min_lr=-1.0, stop_time_hours=0, store_ema=False, suppress_crashes=False, sync_bn=False, task='detection', tensorboard_logdir=None, threshold_loss_scale=None, token_bucket_size=256, tokenizer=None, total_num_update=1000000, tpu=False, train_subset='train', unk=3, update_freq=[8], use_bmuf=False, use_ema_weights_to_init_param=False, use_latest_weights_to_init_ema=False, use_old_adam=False, use_plasma_view=False, use_rdrop=False, use_sharded_state=False, user_dir='../../ofa_module', valid_subset='valid', validate_after_updates=0, validate_interval=1, validate_interval_updates=500, wandb_project=None, warmup_ratio=0.06, warmup_updates=0, weight_decay=0.01, write_checkpoints_asynchronously=False, zero_sharding='none'), 'task': {'_name': 'detection', 'data': '../../dataset/OFA_data/train.tsv,../../dataset/OFA_data/val.tsv', 'selected_cols': '0,1,2', 'bpe': None, 'bpe_dir': '../../utils/BPE', 'max_source_positions': 1024, 'max_target_positions': 1024, 'max_src_length': 80, 'max_tgt_length': 20, 'code_dict_size': 8192, 'patch_image_size': 512, 'orig_patch_image_size': 256, 'num_bins': 1000, 'imagenet_default_mean_and_std': False, 'constraint_range': None, 'eval_acc': True, 'eval_args': '{"beam":5,"max_len_a":0,"max_len_b":200}', 'eval_print_samples': False, 'max_image_size': 512, 'scst': False, 'scst_args': '{}'}, 'criterion': {'_name': 'adjust_label_smoothed_cross_entropy', 'label_smoothing': 0.1, 'report_accuracy': False, 'ignore_prefix_size': 0, 'ignore_eos': False, 'sentence_avg': False, 'drop_worst_ratio': 0.0, 'drop_worst_after': 0, 'use_rdrop': False, 'reg_alpha': 1.0, 'sample_patch_num': 196, 'constraint_range': None}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9,0.999)', 'adam_eps': 1e-08, 'weight_decay': 0.01, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': False, 'lr': [5e-05]}, 'lr_scheduler': {'_name': 'polynomial_decay', 'warmup_updates': 0, 'warmup_ratio': 0.06, 'force_anneal': None, 'end_learning_rate': 0.0, 'power': 1.0, 'total_num_update': 1000000.0, 'lr': [5e-05]}, 'scoring': {'_name': 'bleu', 'pad': 1, 'eos': 2, 'unk': 3}, 'bpe': None, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}, 'simul_type': None}
2023-01-09 03:37:30 - ofa_task.py[line:109] - INFO: source dictionary: 59457 types
2023-01-09 03:37:30 - ofa_task.py[line:110] - INFO: target dictionary: 59457 types
/data/hulab/zcai75/anaconda3/envs/vilt/lib/python3.8/site-packages/torch/functional.py:478: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at  ../aten/src/ATen/native/TensorShape.cpp:2894.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
2023-01-09 03:37:33 - train.py[line:110] - INFO: OFAModel(
  (encoder): TransformerEncoder(
    (encoder_dropout): Dropout(p=0.2, inplace=False)
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(59457, 768, padding_idx=1)
    (layernorm_embedding): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (type_embedding): Embedding(2, 768)
    (embed_images): ResNet(
      (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)
      (layer1): Sequential(
        (0): Bottleneck(
          (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (downsample): Sequential(
            (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (drop_path): Identity()
        )
        (1): Bottleneck(
          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (2): Bottleneck(
          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
      )
      (layer2): Sequential(
        (0): Bottleneck(
          (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (downsample): Sequential(
            (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
            (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (drop_path): Identity()
        )
        (1): Bottleneck(
          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (2): Bottleneck(
          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (3): Bottleneck(
          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
      )
      (layer3): Sequential(
        (0): Bottleneck(
          (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (downsample): Sequential(
            (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)
            (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (drop_path): Identity()
        )
        (1): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (2): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (3): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (4): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (5): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (6): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (7): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (8): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (9): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (10): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (11): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (12): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (13): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (14): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (15): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (16): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (17): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (18): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (19): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (20): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (21): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (22): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
      )
    )
    (image_proj): Linear(in_features=1024, out_features=768, bias=True)
    (patch_layernorm_embedding): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (embed_positions): Embedding(1026, 768)
    (embed_image_positions): Embedding(1765, 768)
    (pos_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (image_pos_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (pos_q_linear): Linear(in_features=768, out_features=768, bias=True)
    (pos_k_linear): Linear(in_features=768, out_features=768, bias=True)
    (layers): ModuleList(
      (0): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): Identity()
      )
      (1): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(p=0.019999999552965164)
      )
      (2): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(p=0.03999999910593033)
      )
      (3): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(p=0.06000000238418579)
      )
      (4): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(p=0.07999999821186066)
      )
      (5): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(p=0.10000000149011612)
      )
    )
    (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (token_rel_pos_table_list): ModuleList(
      (0): Embedding(511, 12)
      (1): Embedding(511, 12)
      (2): Embedding(511, 12)
      (3): Embedding(511, 12)
      (4): Embedding(511, 12)
      (5): Embedding(511, 12)
    )
    (image_rel_pos_table_list): ModuleList(
      (0): Embedding(6892, 12)
      (1): Embedding(6892, 12)
      (2): Embedding(6892, 12)
      (3): Embedding(6892, 12)
      (4): Embedding(6892, 12)
      (5): Embedding(6892, 12)
    )
  )
  (decoder): TransformerDecoder(
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(59457, 768, padding_idx=1)
    (layernorm_embedding): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (embed_positions): Embedding(1026, 768)
    (embed_image_positions): Embedding(1765, 768)
    (pos_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (image_pos_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (self_pos_q_linear): Linear(in_features=768, out_features=768, bias=True)
    (self_pos_k_linear): Linear(in_features=768, out_features=768, bias=True)
    (cross_pos_q_linear): Linear(in_features=768, out_features=768, bias=True)
    (cross_pos_k_linear): Linear(in_features=768, out_features=768, bias=True)
    (code_layernorm_embedding): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (layers): ModuleList(
      (0): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (cross_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): Identity()
      )
      (1): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (cross_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(p=0.019999999552965164)
      )
      (2): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (cross_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(p=0.03999999910593033)
      )
      (3): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (cross_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(p=0.06000000238418579)
      )
      (4): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (cross_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(p=0.07999999821186066)
      )
      (5): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (cross_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(p=0.10000000149011612)
      )
    )
    (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (output_projection): Linear(in_features=768, out_features=59457, bias=False)
    (token_rel_pos_table_list): ModuleList(
      (0): Embedding(511, 12)
      (1): Embedding(511, 12)
      (2): Embedding(511, 12)
      (3): Embedding(511, 12)
      (4): Embedding(511, 12)
      (5): Embedding(511, 12)
    )
    (image_rel_pos_table_list): ModuleList(
      (0): Embedding(6892, 12)
      (1): Embedding(6892, 12)
      (2): Embedding(6892, 12)
      (3): Embedding(6892, 12)
      (4): Embedding(6892, 12)
      (5): Embedding(6892, 12)
    )
  )
  (classification_heads): ModuleDict()
)
2023-01-09 03:37:33 - train.py[line:111] - INFO: task: DetectionTask
2023-01-09 03:37:33 - train.py[line:112] - INFO: model: OFAModel
2023-01-09 03:37:33 - train.py[line:113] - INFO: criterion: AdjustLabelSmoothedCrossEntropyCriterion
2023-01-09 03:37:33 - train.py[line:114] - INFO: num. shared model params: 182,238,536 (num. trained: 182,238,536)
2023-01-09 03:37:33 - train.py[line:121] - INFO: num. expert model params: 0 (num. trained: 0)
local datafile ../../dataset/OFA_data/val.tsv slice_id 0 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../dataset/OFA_data/val.tsv slice_id 0 finished initializing row_count and line_idx-to-offset mapping
file ../../dataset/OFA_data/val.tsv slice_id 0 row count 4952 total row count 4952
2023-01-09 03:37:34 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_tokens.weight <- decoder.embed_tokens.weight
2023-01-09 03:37:34 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_tokens.weight <- decoder.output_projection.weight
2023-01-09 03:37:34 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer1.0.conv1.bias
2023-01-09 03:37:34 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer1.0.conv2.bias
2023-01-09 03:37:34 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer1.0.conv3.bias
2023-01-09 03:37:34 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer1.0.downsample.0.bias
2023-01-09 03:37:34 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer1.1.conv1.bias
2023-01-09 03:37:34 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer1.1.conv2.bias
2023-01-09 03:37:34 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer1.1.conv3.bias
2023-01-09 03:37:34 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer1.2.conv1.bias
2023-01-09 03:37:34 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer1.2.conv2.bias
2023-01-09 03:37:34 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer1.2.conv3.bias
2023-01-09 03:37:34 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.0.conv1.bias
2023-01-09 03:37:34 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.0.conv2.bias
2023-01-09 03:37:34 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.0.conv3.bias
2023-01-09 03:37:34 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.0.downsample.0.bias
2023-01-09 03:37:34 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.1.conv1.bias
2023-01-09 03:37:34 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.1.conv2.bias
2023-01-09 03:37:34 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.1.conv3.bias
2023-01-09 03:37:34 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.2.conv1.bias
2023-01-09 03:37:34 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.2.conv2.bias
2023-01-09 03:37:34 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.2.conv3.bias
2023-01-09 03:37:34 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.3.conv1.bias
2023-01-09 03:37:34 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.3.conv2.bias
2023-01-09 03:37:34 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.3.conv3.bias
2023-01-09 03:37:34 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.0.conv1.bias
2023-01-09 03:37:34 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.0.conv2.bias
2023-01-09 03:37:34 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.0.conv3.bias
2023-01-09 03:37:34 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.0.downsample.0.bias
2023-01-09 03:37:34 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.1.conv1.bias
2023-01-09 03:37:34 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.1.conv2.bias
2023-01-09 03:37:34 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.1.conv3.bias
2023-01-09 03:37:34 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.2.conv1.bias
2023-01-09 03:37:34 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.2.conv2.bias
2023-01-09 03:37:34 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.2.conv3.bias
2023-01-09 03:37:34 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.3.conv1.bias
2023-01-09 03:37:34 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.3.conv2.bias
2023-01-09 03:37:34 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.3.conv3.bias
2023-01-09 03:37:34 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.4.conv1.bias
2023-01-09 03:37:34 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.4.conv2.bias
2023-01-09 03:37:34 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.4.conv3.bias
2023-01-09 03:37:34 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.5.conv1.bias
2023-01-09 03:37:34 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.5.conv2.bias
2023-01-09 03:37:34 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.5.conv3.bias
2023-01-09 03:37:34 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.6.conv1.bias
2023-01-09 03:37:34 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.6.conv2.bias
2023-01-09 03:37:34 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.6.conv3.bias
2023-01-09 03:37:34 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.7.conv1.bias
2023-01-09 03:37:34 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.7.conv2.bias
2023-01-09 03:37:34 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.7.conv3.bias
2023-01-09 03:37:34 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.8.conv1.bias
2023-01-09 03:37:34 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.8.conv2.bias
2023-01-09 03:37:34 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.8.conv3.bias
2023-01-09 03:37:34 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.9.conv1.bias
2023-01-09 03:37:34 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.9.conv2.bias
2023-01-09 03:37:34 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.9.conv3.bias
2023-01-09 03:37:34 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.10.conv1.bias
2023-01-09 03:37:34 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.10.conv2.bias
2023-01-09 03:37:34 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.10.conv3.bias
2023-01-09 03:37:34 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.11.conv1.bias
2023-01-09 03:37:34 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.11.conv2.bias
2023-01-09 03:37:34 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.11.conv3.bias
2023-01-09 03:37:34 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.12.conv1.bias
2023-01-09 03:37:34 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.12.conv2.bias
2023-01-09 03:37:34 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.12.conv3.bias
2023-01-09 03:37:34 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.13.conv1.bias
2023-01-09 03:37:34 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.13.conv2.bias
2023-01-09 03:37:34 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.13.conv3.bias
2023-01-09 03:37:34 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.14.conv1.bias
2023-01-09 03:37:34 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.14.conv2.bias
2023-01-09 03:37:34 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.14.conv3.bias
2023-01-09 03:37:34 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.15.conv1.bias
2023-01-09 03:37:34 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.15.conv2.bias
2023-01-09 03:37:34 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.15.conv3.bias
2023-01-09 03:37:34 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.16.conv1.bias
2023-01-09 03:37:34 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.16.conv2.bias
2023-01-09 03:37:34 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.16.conv3.bias
2023-01-09 03:37:34 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.17.conv1.bias
2023-01-09 03:37:34 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.17.conv2.bias
2023-01-09 03:37:34 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.17.conv3.bias
2023-01-09 03:37:34 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.18.conv1.bias
2023-01-09 03:37:34 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.18.conv2.bias
2023-01-09 03:37:34 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.18.conv3.bias
2023-01-09 03:37:34 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.19.conv1.bias
2023-01-09 03:37:34 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.19.conv2.bias
2023-01-09 03:37:34 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.19.conv3.bias
2023-01-09 03:37:34 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.20.conv1.bias
2023-01-09 03:37:34 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.20.conv2.bias
2023-01-09 03:37:34 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.20.conv3.bias
2023-01-09 03:37:34 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.21.conv1.bias
2023-01-09 03:37:34 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.21.conv2.bias
2023-01-09 03:37:34 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.21.conv3.bias
2023-01-09 03:37:34 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.22.conv1.bias
2023-01-09 03:37:34 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.22.conv2.bias
2023-01-09 03:37:34 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.22.conv3.bias
2023-01-09 03:37:34 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- decoder.output_projection.bias
2023-01-09 03:37:34 - utils.py[line:759] - INFO: ***********************CUDA enviroments for all 1 workers***********************
2023-01-09 03:37:34 - utils.py[line:761] - INFO: rank   0: capabilities =  8.6  ; total memory = 23.691 GB ; name = NVIDIA GeForce RTX 3090                 
2023-01-09 03:37:34 - utils.py[line:767] - INFO: ***********************CUDA enviroments for all 1 workers***********************
2023-01-09 03:37:34 - train.py[line:152] - INFO: training on 1 devices (GPUs/TPUs)
2023-01-09 03:37:34 - train.py[line:157] - INFO: max tokens per device = None and max sentences per device = 4
2023-01-09 03:37:34 - trainer.py[line:458] - INFO: Preparing to load checkpoint ../../checkpoints/ofa_base.pt
2023-01-09 03:37:34 - trainer.py[line:624] - INFO: No existing checkpoint found ../../checkpoints/ofa_base.pt
2023-01-09 03:37:34 - trainer.py[line:639] - INFO: loading train data for epoch 1
local datafile ../../dataset/OFA_data/train.tsv slice_id 0 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../dataset/OFA_data/train.tsv slice_id 0 finished initializing row_count and line_idx-to-offset mapping
file ../../dataset/OFA_data/train.tsv slice_id 0 row count 117266 total row count 117266
/data/hulab/zcai75/anaconda3/envs/vilt/lib/python3.8/site-packages/torchvision/transforms/functional.py:417: UserWarning: Argument 'interpolation' of type int is deprecated since 0.13 and will be removed in 0.15. Please use InterpolationMode enum.
  warnings.warn(
slice_id 0 seek offset 0
Total steps 36650, warmup steps 2199, warmup_factor 0.00045475216007276033
2023-01-09 03:37:56 - trainer.py[line:703] - INFO: begin training epoch 1
2023-01-09 03:37:56 - train.py[line:305] - INFO: Start iterating over samples
2023-01-09 03:38:01 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2023-01-09 03:38:21 - progress_bar.py[line:272] - INFO: epoch 001:     11 / 3665 loss=11.154, loss_v1=0, loss_v2=0, nll_loss=11.155, ntokens=823.1, nsentences=32, sample_size=823.1, sample_size_v1=0, sample_size_v2=0, ppl=2280.42, wps=427.3, ups=0.51, wpb=823.1, bsz=32, num_updates=10, lr=2.27376e-07, gnorm=10.942, clip=100, loss_scale=64, train_wall=24, gb_free=15.4, wall=47
2023-01-09 03:38:40 - progress_bar.py[line:272] - INFO: epoch 001:     21 / 3665 loss=11.146, loss_v1=0, loss_v2=0, nll_loss=11.146, ntokens=854.1, nsentences=32, sample_size=854.1, sample_size_v1=0, sample_size_v2=0, ppl=2266.84, wps=438.7, ups=0.51, wpb=854.1, bsz=32, num_updates=20, lr=4.54752e-07, gnorm=12.127, clip=100, loss_scale=64, train_wall=19, gb_free=15.6, wall=66
2023-01-09 03:39:00 - progress_bar.py[line:272] - INFO: epoch 001:     31 / 3665 loss=11.05, loss_v1=0, loss_v2=0, nll_loss=11.04, ntokens=999.4, nsentences=32, sample_size=999.4, sample_size_v1=0, sample_size_v2=0, ppl=2104.98, wps=507.8, ups=0.51, wpb=999.4, bsz=32, num_updates=30, lr=6.82128e-07, gnorm=10.691, clip=100, loss_scale=64, train_wall=20, gb_free=15.3, wall=86
2023-01-09 03:39:19 - progress_bar.py[line:272] - INFO: epoch 001:     41 / 3665 loss=10.817, loss_v1=0, loss_v2=0, nll_loss=10.781, ntokens=773.5, nsentences=32, sample_size=773.5, sample_size_v1=0, sample_size_v2=0, ppl=1758.97, wps=395.9, ups=0.51, wpb=773.5, bsz=32, num_updates=40, lr=9.09504e-07, gnorm=11.138, clip=100, loss_scale=64, train_wall=20, gb_free=15.3, wall=106
2023-01-09 03:39:39 - progress_bar.py[line:272] - INFO: epoch 001:     51 / 3665 loss=10.633, loss_v1=0, loss_v2=0, nll_loss=10.576, ntokens=959.3, nsentences=32, sample_size=959.3, sample_size_v1=0, sample_size_v2=0, ppl=1526.45, wps=490.2, ups=0.51, wpb=959.3, bsz=32, num_updates=50, lr=1.13688e-06, gnorm=9.214, clip=100, loss_scale=64, train_wall=20, gb_free=15.6, wall=125
2023-01-09 03:39:59 - progress_bar.py[line:272] - INFO: epoch 001:     61 / 3665 loss=10.542, loss_v1=0, loss_v2=0, nll_loss=10.475, ntokens=989.3, nsentences=32, sample_size=989.3, sample_size_v1=0, sample_size_v2=0, ppl=1422.92, wps=502.9, ups=0.51, wpb=989.3, bsz=32, num_updates=60, lr=1.36426e-06, gnorm=7.93, clip=100, loss_scale=64, train_wall=20, gb_free=14.7, wall=145
2023-01-09 03:40:18 - progress_bar.py[line:272] - INFO: epoch 001:     71 / 3665 loss=10.235, loss_v1=0, loss_v2=0, nll_loss=10.133, ntokens=767, nsentences=32, sample_size=767, sample_size_v1=0, sample_size_v2=0, ppl=1123.1, wps=392.2, ups=0.51, wpb=767, bsz=32, num_updates=70, lr=1.59163e-06, gnorm=8.283, clip=100, loss_scale=64, train_wall=20, gb_free=15.7, wall=164
2023-01-09 03:40:38 - progress_bar.py[line:272] - INFO: epoch 001:     81 / 3665 loss=10.137, loss_v1=0, loss_v2=0, nll_loss=10.024, ntokens=1045, nsentences=32, sample_size=1045, sample_size_v1=0, sample_size_v2=0, ppl=1040.98, wps=530.4, ups=0.51, wpb=1045, bsz=32, num_updates=80, lr=1.81901e-06, gnorm=6.785, clip=100, loss_scale=64, train_wall=20, gb_free=15, wall=184
2023-01-09 03:40:57 - progress_bar.py[line:272] - INFO: epoch 001:     91 / 3665 loss=10.065, loss_v1=0, loss_v2=0, nll_loss=9.944, ntokens=806.8, nsentences=32, sample_size=806.8, sample_size_v1=0, sample_size_v2=0, ppl=984.76, wps=410.9, ups=0.51, wpb=806.8, bsz=32, num_updates=90, lr=2.04638e-06, gnorm=6.981, clip=100, loss_scale=64, train_wall=20, gb_free=15.4, wall=204
2023-01-09 03:41:17 - progress_bar.py[line:272] - INFO: epoch 001:    101 / 3665 loss=9.949, loss_v1=0, loss_v2=0, nll_loss=9.813, ntokens=952.7, nsentences=32, sample_size=952.7, sample_size_v1=0, sample_size_v2=0, ppl=899.73, wps=483.5, ups=0.51, wpb=952.7, bsz=32, num_updates=100, lr=2.27376e-06, gnorm=5.836, clip=100, loss_scale=64, train_wall=20, gb_free=15.6, wall=223
2023-01-09 03:41:37 - progress_bar.py[line:272] - INFO: epoch 001:    111 / 3665 loss=9.776, loss_v1=0, loss_v2=0, nll_loss=9.621, ntokens=1101, nsentences=32, sample_size=1101, sample_size_v1=0, sample_size_v2=0, ppl=787.42, wps=553.3, ups=0.5, wpb=1101, bsz=32, num_updates=110, lr=2.50114e-06, gnorm=5.457, clip=100, loss_scale=64, train_wall=20, gb_free=15.4, wall=243
2023-01-09 03:41:57 - progress_bar.py[line:272] - INFO: epoch 001:    121 / 3665 loss=9.763, loss_v1=0, loss_v2=0, nll_loss=9.605, ntokens=822, nsentences=32, sample_size=822, sample_size_v1=0, sample_size_v2=0, ppl=778.6, wps=412.8, ups=0.5, wpb=822, bsz=32, num_updates=120, lr=2.72851e-06, gnorm=5.255, clip=100, loss_scale=64, train_wall=20, gb_free=15.3, wall=263
2023-01-09 03:42:17 - progress_bar.py[line:272] - INFO: epoch 001:    131 / 3665 loss=9.555, loss_v1=0, loss_v2=0, nll_loss=9.374, ntokens=932.2, nsentences=32, sample_size=932.2, sample_size_v1=0, sample_size_v2=0, ppl=663.4, wps=467.5, ups=0.5, wpb=932.2, bsz=32, num_updates=130, lr=2.95589e-06, gnorm=5.11, clip=100, loss_scale=64, train_wall=20, gb_free=15.3, wall=283
2023-01-09 03:42:37 - progress_bar.py[line:272] - INFO: epoch 001:    141 / 3665 loss=9.61, loss_v1=0, loss_v2=0, nll_loss=9.433, ntokens=1073.4, nsentences=32, sample_size=1073.4, sample_size_v1=0, sample_size_v2=0, ppl=691.17, wps=536.9, ups=0.5, wpb=1073.4, bsz=32, num_updates=140, lr=3.18327e-06, gnorm=4.461, clip=100, loss_scale=64, train_wall=20, gb_free=15.2, wall=303
2023-01-09 03:42:57 - progress_bar.py[line:272] - INFO: epoch 001:    151 / 3665 loss=9.443, loss_v1=0, loss_v2=0, nll_loss=9.247, ntokens=826.8, nsentences=32, sample_size=826.8, sample_size_v1=0, sample_size_v2=0, ppl=607.75, wps=415.6, ups=0.5, wpb=826.8, bsz=32, num_updates=150, lr=3.41064e-06, gnorm=4.415, clip=100, loss_scale=64, train_wall=20, gb_free=15.2, wall=323
2023-01-09 03:43:17 - progress_bar.py[line:272] - INFO: epoch 001:    161 / 3665 loss=9.334, loss_v1=0, loss_v2=0, nll_loss=9.125, ntokens=888.2, nsentences=32, sample_size=888.2, sample_size_v1=0, sample_size_v2=0, ppl=558.42, wps=446.5, ups=0.5, wpb=888.2, bsz=32, num_updates=160, lr=3.63802e-06, gnorm=4.19, clip=100, loss_scale=64, train_wall=20, gb_free=15.5, wall=343
2023-01-09 03:43:37 - progress_bar.py[line:272] - INFO: epoch 001:    171 / 3665 loss=9.414, loss_v1=0, loss_v2=0, nll_loss=9.214, ntokens=1081.2, nsentences=32, sample_size=1081.2, sample_size_v1=0, sample_size_v2=0, ppl=593.82, wps=541.6, ups=0.5, wpb=1081.2, bsz=32, num_updates=170, lr=3.86539e-06, gnorm=3.456, clip=100, loss_scale=64, train_wall=20, gb_free=15.3, wall=363
2023-01-09 03:43:56 - progress_bar.py[line:272] - INFO: epoch 001:    181 / 3665 loss=9.281, loss_v1=0, loss_v2=0, nll_loss=9.065, ntokens=750.3, nsentences=32, sample_size=750.3, sample_size_v1=0, sample_size_v2=0, ppl=535.58, wps=379, ups=0.51, wpb=750.3, bsz=32, num_updates=180, lr=4.09277e-06, gnorm=4.024, clip=100, loss_scale=64, train_wall=20, gb_free=15.3, wall=383
2023-01-09 03:44:16 - progress_bar.py[line:272] - INFO: epoch 001:    191 / 3665 loss=9.356, loss_v1=0, loss_v2=0, nll_loss=9.15, ntokens=1013.7, nsentences=32, sample_size=1013.7, sample_size_v1=0, sample_size_v2=0, ppl=568.04, wps=514.6, ups=0.51, wpb=1013.7, bsz=32, num_updates=190, lr=4.32015e-06, gnorm=3.591, clip=100, loss_scale=64, train_wall=20, gb_free=15.3, wall=402
2023-01-09 03:44:36 - progress_bar.py[line:272] - INFO: epoch 001:    201 / 3665 loss=9.229, loss_v1=0, loss_v2=0, nll_loss=9.007, ntokens=935.7, nsentences=32, sample_size=935.7, sample_size_v1=0, sample_size_v2=0, ppl=514.44, wps=477.3, ups=0.51, wpb=935.7, bsz=32, num_updates=200, lr=4.54752e-06, gnorm=3.336, clip=100, loss_scale=64, train_wall=20, gb_free=15.4, wall=422
2023-01-09 03:44:55 - progress_bar.py[line:272] - INFO: epoch 001:    211 / 3665 loss=9.15, loss_v1=0, loss_v2=0, nll_loss=8.919, ntokens=773.3, nsentences=32, sample_size=773.3, sample_size_v1=0, sample_size_v2=0, ppl=483.88, wps=394.8, ups=0.51, wpb=773.3, bsz=32, num_updates=210, lr=4.7749e-06, gnorm=3.584, clip=100, loss_scale=64, train_wall=20, gb_free=14.9, wall=442
2023-01-09 03:45:15 - progress_bar.py[line:272] - INFO: epoch 001:    221 / 3665 loss=9.003, loss_v1=0, loss_v2=0, nll_loss=8.754, ntokens=996.7, nsentences=32, sample_size=996.7, sample_size_v1=0, sample_size_v2=0, ppl=431.82, wps=507.3, ups=0.51, wpb=996.7, bsz=32, num_updates=220, lr=5.00227e-06, gnorm=3.163, clip=100, loss_scale=64, train_wall=20, gb_free=15.3, wall=461
2023-01-09 03:45:35 - progress_bar.py[line:272] - INFO: epoch 001:    231 / 3665 loss=9.225, loss_v1=0, loss_v2=0, nll_loss=9, ntokens=980.7, nsentences=32, sample_size=980.7, sample_size_v1=0, sample_size_v2=0, ppl=512, wps=498, ups=0.51, wpb=980.7, bsz=32, num_updates=230, lr=5.22965e-06, gnorm=2.903, clip=100, loss_scale=64, train_wall=20, gb_free=15.6, wall=481
2023-01-09 03:45:54 - progress_bar.py[line:272] - INFO: epoch 001:    241 / 3665 loss=8.843, loss_v1=0, loss_v2=0, nll_loss=8.576, ntokens=811.6, nsentences=32, sample_size=811.6, sample_size_v1=0, sample_size_v2=0, ppl=381.73, wps=414.7, ups=0.51, wpb=811.6, bsz=32, num_updates=240, lr=5.45703e-06, gnorm=3.238, clip=100, loss_scale=64, train_wall=20, gb_free=15.7, wall=501
2023-01-09 03:46:14 - progress_bar.py[line:272] - INFO: epoch 001:    251 / 3665 loss=8.937, loss_v1=0, loss_v2=0, nll_loss=8.679, ntokens=1063.1, nsentences=32, sample_size=1063.1, sample_size_v1=0, sample_size_v2=0, ppl=409.95, wps=537.3, ups=0.51, wpb=1063.1, bsz=32, num_updates=250, lr=5.6844e-06, gnorm=2.693, clip=100, loss_scale=64, train_wall=20, gb_free=15.4, wall=520
2023-01-09 03:46:34 - progress_bar.py[line:272] - INFO: epoch 001:    261 / 3665 loss=8.876, loss_v1=0, loss_v2=0, nll_loss=8.61, ntokens=761.5, nsentences=32, sample_size=761.5, sample_size_v1=0, sample_size_v2=0, ppl=390.72, wps=387.6, ups=0.51, wpb=761.5, bsz=32, num_updates=260, lr=5.91178e-06, gnorm=2.981, clip=100, loss_scale=64, train_wall=20, gb_free=15.5, wall=540
2023-01-09 03:46:53 - progress_bar.py[line:272] - INFO: epoch 001:    271 / 3665 loss=8.776, loss_v1=0, loss_v2=0, nll_loss=8.499, ntokens=965.6, nsentences=32, sample_size=965.6, sample_size_v1=0, sample_size_v2=0, ppl=361.91, wps=490.6, ups=0.51, wpb=965.6, bsz=32, num_updates=270, lr=6.13915e-06, gnorm=2.769, clip=100, loss_scale=64, train_wall=20, gb_free=15.4, wall=560
2023-01-09 03:47:13 - progress_bar.py[line:272] - INFO: epoch 001:    281 / 3665 loss=8.721, loss_v1=0, loss_v2=0, nll_loss=8.435, ntokens=918.4, nsentences=32, sample_size=918.4, sample_size_v1=0, sample_size_v2=0, ppl=346.21, wps=466.8, ups=0.51, wpb=918.4, bsz=32, num_updates=280, lr=6.36653e-06, gnorm=2.42, clip=100, loss_scale=64, train_wall=20, gb_free=15.5, wall=579
2023-01-09 03:47:33 - progress_bar.py[line:272] - INFO: epoch 001:    291 / 3665 loss=8.652, loss_v1=0, loss_v2=0, nll_loss=8.359, ntokens=826.3, nsentences=32, sample_size=826.3, sample_size_v1=0, sample_size_v2=0, ppl=328.37, wps=418.8, ups=0.51, wpb=826.3, bsz=32, num_updates=290, lr=6.59391e-06, gnorm=2.716, clip=100, loss_scale=64, train_wall=20, gb_free=15, wall=599
2023-01-09 03:47:53 - progress_bar.py[line:272] - INFO: epoch 001:    301 / 3665 loss=8.603, loss_v1=0, loss_v2=0, nll_loss=8.303, ntokens=977.2, nsentences=32, sample_size=977.2, sample_size_v1=0, sample_size_v2=0, ppl=315.93, wps=485.8, ups=0.5, wpb=977.2, bsz=32, num_updates=300, lr=6.82128e-06, gnorm=2.497, clip=100, loss_scale=64, train_wall=20, gb_free=15.3, wall=619
2023-01-09 03:48:13 - progress_bar.py[line:272] - INFO: epoch 001:    311 / 3665 loss=8.433, loss_v1=0, loss_v2=0, nll_loss=8.112, ntokens=1020, nsentences=32, sample_size=1020, sample_size_v1=0, sample_size_v2=0, ppl=276.63, wps=506.8, ups=0.5, wpb=1020, bsz=32, num_updates=310, lr=7.04866e-06, gnorm=2.152, clip=100, loss_scale=64, train_wall=20, gb_free=15.5, wall=639
2023-01-09 03:48:33 - progress_bar.py[line:272] - INFO: epoch 001:    321 / 3665 loss=8.326, loss_v1=0, loss_v2=0, nll_loss=7.993, ntokens=759.3, nsentences=32, sample_size=759.3, sample_size_v1=0, sample_size_v2=0, ppl=254.72, wps=379.4, ups=0.5, wpb=759.3, bsz=32, num_updates=320, lr=7.27603e-06, gnorm=2.548, clip=100, loss_scale=64, train_wall=20, gb_free=15.7, wall=659
2023-01-09 03:48:53 - progress_bar.py[line:272] - INFO: epoch 001:    331 / 3665 loss=8.224, loss_v1=0, loss_v2=0, nll_loss=7.877, ntokens=1046.5, nsentences=32, sample_size=1046.5, sample_size_v1=0, sample_size_v2=0, ppl=235.14, wps=520.9, ups=0.5, wpb=1046.5, bsz=32, num_updates=330, lr=7.50341e-06, gnorm=2.276, clip=100, loss_scale=64, train_wall=20, gb_free=15.3, wall=679
2023-01-09 03:49:13 - progress_bar.py[line:272] - INFO: epoch 001:    341 / 3665 loss=8.24, loss_v1=0, loss_v2=0, nll_loss=7.891, ntokens=862.7, nsentences=32, sample_size=862.7, sample_size_v1=0, sample_size_v2=0, ppl=237.32, wps=432.8, ups=0.5, wpb=862.7, bsz=32, num_updates=340, lr=7.73079e-06, gnorm=2.293, clip=100, loss_scale=64, train_wall=20, gb_free=15.6, wall=699
2023-01-09 03:49:33 - progress_bar.py[line:272] - INFO: epoch 001:    351 / 3665 loss=8.018, loss_v1=0, loss_v2=0, nll_loss=7.645, ntokens=784.8, nsentences=32, sample_size=784.8, sample_size_v1=0, sample_size_v2=0, ppl=200.19, wps=401.6, ups=0.51, wpb=784.8, bsz=32, num_updates=350, lr=7.95816e-06, gnorm=2.624, clip=100, loss_scale=64, train_wall=20, gb_free=15.3, wall=719
2023-01-09 03:49:52 - progress_bar.py[line:272] - INFO: epoch 001:    361 / 3665 loss=8.093, loss_v1=0, loss_v2=0, nll_loss=7.725, ntokens=1000.8, nsentences=32, sample_size=1000.8, sample_size_v1=0, sample_size_v2=0, ppl=211.57, wps=511.3, ups=0.51, wpb=1000.8, bsz=32, num_updates=360, lr=8.18554e-06, gnorm=2.188, clip=100, loss_scale=64, train_wall=20, gb_free=15.2, wall=738
2023-01-09 03:50:12 - progress_bar.py[line:272] - INFO: epoch 001:    371 / 3665 loss=7.99, loss_v1=0, loss_v2=0, nll_loss=7.61, ntokens=805.8, nsentences=32, sample_size=805.8, sample_size_v1=0, sample_size_v2=0, ppl=195.33, wps=411.8, ups=0.51, wpb=805.8, bsz=32, num_updates=370, lr=8.41291e-06, gnorm=2.241, clip=100, loss_scale=64, train_wall=20, gb_free=15.4, wall=758
2023-01-09 03:50:31 - progress_bar.py[line:272] - INFO: epoch 001:    381 / 3665 loss=7.846, loss_v1=0, loss_v2=0, nll_loss=7.447, ntokens=931.3, nsentences=32, sample_size=931.3, sample_size_v1=0, sample_size_v2=0, ppl=174.53, wps=475.8, ups=0.51, wpb=931.3, bsz=32, num_updates=380, lr=8.64029e-06, gnorm=2.257, clip=100, loss_scale=64, train_wall=20, gb_free=15.4, wall=778
2023-01-09 03:50:51 - progress_bar.py[line:272] - INFO: epoch 001:    391 / 3665 loss=7.73, loss_v1=0, loss_v2=0, nll_loss=7.311, ntokens=948.5, nsentences=32, sample_size=948.5, sample_size_v1=0, sample_size_v2=0, ppl=158.79, wps=483.2, ups=0.51, wpb=948.5, bsz=32, num_updates=390, lr=8.86767e-06, gnorm=2.034, clip=100, loss_scale=64, train_wall=20, gb_free=15.6, wall=797
2023-01-09 03:51:11 - progress_bar.py[line:272] - INFO: epoch 001:    401 / 3665 loss=7.678, loss_v1=0, loss_v2=0, nll_loss=7.255, ntokens=711.3, nsentences=32, sample_size=711.3, sample_size_v1=0, sample_size_v2=0, ppl=152.71, wps=363, ups=0.51, wpb=711.3, bsz=32, num_updates=400, lr=9.09504e-06, gnorm=2.333, clip=100, loss_scale=64, train_wall=20, gb_free=15.1, wall=817
2023-01-09 03:51:30 - progress_bar.py[line:272] - INFO: epoch 001:    411 / 3665 loss=7.576, loss_v1=0, loss_v2=0, nll_loss=7.137, ntokens=966.2, nsentences=32, sample_size=966.2, sample_size_v1=0, sample_size_v2=0, ppl=140.76, wps=491.2, ups=0.51, wpb=966.2, bsz=32, num_updates=410, lr=9.32242e-06, gnorm=2.095, clip=100, loss_scale=64, train_wall=20, gb_free=15.2, wall=837
2023-01-09 03:51:50 - progress_bar.py[line:272] - INFO: epoch 001:    421 / 3665 loss=7.579, loss_v1=0, loss_v2=0, nll_loss=7.135, ntokens=972.9, nsentences=32, sample_size=972.9, sample_size_v1=0, sample_size_v2=0, ppl=140.52, wps=493.7, ups=0.51, wpb=972.9, bsz=32, num_updates=420, lr=9.5498e-06, gnorm=1.823, clip=100, loss_scale=64, train_wall=20, gb_free=15.4, wall=856
2023-01-09 03:52:10 - progress_bar.py[line:272] - INFO: epoch 001:    431 / 3665 loss=7.552, loss_v1=0, loss_v2=0, nll_loss=7.107, ntokens=873.1, nsentences=32, sample_size=873.1, sample_size_v1=0, sample_size_v2=0, ppl=137.85, wps=428.7, ups=0.49, wpb=873.1, bsz=32, num_updates=430, lr=9.77717e-06, gnorm=2.116, clip=100, loss_scale=64, train_wall=20, gb_free=15.3, wall=877
2023-01-09 03:52:31 - progress_bar.py[line:272] - INFO: epoch 001:    441 / 3665 loss=7.518, loss_v1=0, loss_v2=0, nll_loss=7.062, ntokens=1014.9, nsentences=32, sample_size=1014.9, sample_size_v1=0, sample_size_v2=0, ppl=133.66, wps=489.8, ups=0.48, wpb=1014.9, bsz=32, num_updates=440, lr=1.00045e-05, gnorm=1.936, clip=100, loss_scale=64, train_wall=21, gb_free=15.1, wall=897
2023-01-09 03:52:51 - progress_bar.py[line:272] - INFO: epoch 001:    451 / 3665 loss=7.447, loss_v1=0, loss_v2=0, nll_loss=6.978, ntokens=909.1, nsentences=32, sample_size=909.1, sample_size_v1=0, sample_size_v2=0, ppl=126.08, wps=452.8, ups=0.5, wpb=909.1, bsz=32, num_updates=450, lr=1.02319e-05, gnorm=1.968, clip=100, loss_scale=64, train_wall=20, gb_free=15.6, wall=917
2023-01-09 03:53:11 - progress_bar.py[line:272] - INFO: epoch 001:    461 / 3665 loss=7.301, loss_v1=0, loss_v2=0, nll_loss=6.815, ntokens=941, nsentences=32, sample_size=941, sample_size_v1=0, sample_size_v2=0, ppl=112.56, wps=480.7, ups=0.51, wpb=941, bsz=32, num_updates=460, lr=1.04593e-05, gnorm=2.002, clip=100, loss_scale=64, train_wall=20, gb_free=15.6, wall=937
2023-01-09 03:53:30 - progress_bar.py[line:272] - INFO: epoch 001:    471 / 3665 loss=7.198, loss_v1=0, loss_v2=0, nll_loss=6.691, ntokens=1148.3, nsentences=32, sample_size=1148.3, sample_size_v1=0, sample_size_v2=0, ppl=103.35, wps=583.9, ups=0.51, wpb=1148.3, bsz=32, num_updates=470, lr=1.06867e-05, gnorm=1.885, clip=100, loss_scale=64, train_wall=20, gb_free=15.4, wall=957
2023-01-09 03:53:50 - progress_bar.py[line:272] - INFO: epoch 001:    481 / 3665 loss=7.366, loss_v1=0, loss_v2=0, nll_loss=6.878, ntokens=945.3, nsentences=32, sample_size=945.3, sample_size_v1=0, sample_size_v2=0, ppl=117.58, wps=482.4, ups=0.51, wpb=945.3, bsz=32, num_updates=480, lr=1.09141e-05, gnorm=2.066, clip=100, loss_scale=64, train_wall=20, gb_free=15.7, wall=976
2023-01-09 03:54:10 - progress_bar.py[line:272] - INFO: epoch 001:    491 / 3665 loss=7.194, loss_v1=0, loss_v2=0, nll_loss=6.681, ntokens=918.9, nsentences=32, sample_size=918.9, sample_size_v1=0, sample_size_v2=0, ppl=102.63, wps=468.2, ups=0.51, wpb=918.9, bsz=32, num_updates=490, lr=1.11414e-05, gnorm=1.982, clip=100, loss_scale=64, train_wall=20, gb_free=15.2, wall=996
2023-01-09 03:54:29 - progress_bar.py[line:272] - INFO: epoch 001:    501 / 3665 loss=6.998, loss_v1=0, loss_v2=0, nll_loss=6.454, ntokens=983.4, nsentences=32, sample_size=983.4, sample_size_v1=0, sample_size_v2=0, ppl=87.69, wps=501.4, ups=0.51, wpb=983.4, bsz=32, num_updates=500, lr=1.13688e-05, gnorm=1.894, clip=100, loss_scale=64, train_wall=20, gb_free=15.3, wall=1015
2023-01-09 03:54:29 - train.py[line:445] - INFO: begin validation on "valid" subset
slice_id 0 seek offset 0
slice_id 0 seek offset 0
/home/zcai75/Github/OFA/fairseq/fairseq/search.py:140: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  beams_buf = indices_buf // vocab_size
/home/zcai75/Github/OFA/models/sequence_generator.py:705: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  unfin_idx = bbsz_idx // beam_size
2023-01-09 03:59:11 - progress_bar.py[line:282] - INFO: epoch 001 | valid on 'valid' subset | loss 7.073 | loss_v1 0 | loss_v2 0 | nll_loss 6.529 | ntokens 117.187 | nsentences 4 | sample_size 117.187 | sample_size_v1 0 | sample_size_v2 0 | AP 0 | total positives 21.7391 | TP 0 | FP 8 | ppl 92.34 | wps 522.5 | wpb 117.2 | bsz 4 | num_updates 500
2023-01-09 03:59:11 - checkpoint_utils.py[line:64] - INFO: Preparing to save checkpoint for epoch 1 @ 500 updates
2023-01-09 03:59:11 - trainer.py[line:431] - INFO: Saving checkpoint to ../../checkpoints/OFA/detection_checkpoints/10_5e-5_512/checkpoint_1_500.pt
2023-01-09 03:59:26 - trainer.py[line:441] - INFO: Finished saving checkpoint to ../../checkpoints/OFA/detection_checkpoints/10_5e-5_512/checkpoint_1_500.pt
2023-01-09 04:00:04 - checkpoint_utils.py[line:133] - INFO: Saved checkpoint ../../checkpoints/OFA/detection_checkpoints/10_5e-5_512/checkpoint_1_500.pt (epoch 1 @ 500 updates, score 0.0) (writing took 53.43062990391627 seconds)
2023-01-09 04:00:23 - progress_bar.py[line:272] - INFO: epoch 001:    511 / 3665 loss=7.085, loss_v1=0, loss_v2=0, nll_loss=6.55, ntokens=905.6, nsentences=32, sample_size=905.6, sample_size_v1=0, sample_size_v2=0, ppl=93.71, wps=25.6, ups=0.03, wpb=905.6, bsz=32, num_updates=510, lr=1.15962e-05, gnorm=1.905, clip=100, loss_scale=64, train_wall=19, gb_free=15.5, wall=1370
2023-01-09 04:00:43 - progress_bar.py[line:272] - INFO: epoch 001:    521 / 3665 loss=6.997, loss_v1=0, loss_v2=0, nll_loss=6.446, ntokens=985.2, nsentences=32, sample_size=985.2, sample_size_v1=0, sample_size_v2=0, ppl=87.17, wps=505.6, ups=0.51, wpb=985.2, bsz=32, num_updates=520, lr=1.18236e-05, gnorm=1.728, clip=100, loss_scale=128, train_wall=19, gb_free=15.4, wall=1389
2023-01-09 04:01:03 - progress_bar.py[line:272] - INFO: epoch 001:    531 / 3665 loss=6.958, loss_v1=0, loss_v2=0, nll_loss=6.396, ntokens=964.8, nsentences=32, sample_size=964.8, sample_size_v1=0, sample_size_v2=0, ppl=84.21, wps=492.9, ups=0.51, wpb=964.8, bsz=32, num_updates=530, lr=1.20509e-05, gnorm=1.701, clip=100, loss_scale=128, train_wall=20, gb_free=15.2, wall=1409
2023-01-09 04:01:22 - progress_bar.py[line:272] - INFO: epoch 001:    541 / 3665 loss=6.926, loss_v1=0, loss_v2=0, nll_loss=6.362, ntokens=722.3, nsentences=32, sample_size=722.3, sample_size_v1=0, sample_size_v2=0, ppl=82.28, wps=370, ups=0.51, wpb=722.3, bsz=32, num_updates=540, lr=1.22783e-05, gnorm=2.244, clip=100, loss_scale=128, train_wall=19, gb_free=15.5, wall=1428
2023-01-09 04:01:42 - progress_bar.py[line:272] - INFO: epoch 001:    551 / 3665 loss=6.927, loss_v1=0, loss_v2=0, nll_loss=6.356, ntokens=978.1, nsentences=32, sample_size=978.1, sample_size_v1=0, sample_size_v2=0, ppl=81.93, wps=497.5, ups=0.51, wpb=978.1, bsz=32, num_updates=550, lr=1.25057e-05, gnorm=1.886, clip=100, loss_scale=128, train_wall=20, gb_free=15.3, wall=1448
2023-01-09 04:02:01 - progress_bar.py[line:272] - INFO: epoch 001:    561 / 3665 loss=6.971, loss_v1=0, loss_v2=0, nll_loss=6.402, ntokens=994.8, nsentences=32, sample_size=994.8, sample_size_v1=0, sample_size_v2=0, ppl=84.57, wps=505.5, ups=0.51, wpb=994.8, bsz=32, num_updates=560, lr=1.27331e-05, gnorm=1.922, clip=100, loss_scale=128, train_wall=20, gb_free=15.3, wall=1468
2023-01-09 04:02:21 - progress_bar.py[line:272] - INFO: epoch 001:    571 / 3665 loss=6.685, loss_v1=0, loss_v2=0, nll_loss=6.082, ntokens=763, nsentences=32, sample_size=763, sample_size_v1=0, sample_size_v2=0, ppl=67.76, wps=389.7, ups=0.51, wpb=763, bsz=32, num_updates=570, lr=1.29604e-05, gnorm=2.298, clip=100, loss_scale=128, train_wall=20, gb_free=15.5, wall=1487
2023-01-09 04:02:41 - progress_bar.py[line:272] - INFO: epoch 001:    581 / 3665 loss=6.786, loss_v1=0, loss_v2=0, nll_loss=6.184, ntokens=995.7, nsentences=32, sample_size=995.7, sample_size_v1=0, sample_size_v2=0, ppl=72.72, wps=505.8, ups=0.51, wpb=995.7, bsz=32, num_updates=580, lr=1.31878e-05, gnorm=1.913, clip=100, loss_scale=128, train_wall=20, gb_free=15.1, wall=1507
2023-01-09 04:03:00 - progress_bar.py[line:272] - INFO: epoch 001:    591 / 3665 loss=6.877, loss_v1=0, loss_v2=0, nll_loss=6.288, ntokens=918.9, nsentences=32, sample_size=918.9, sample_size_v1=0, sample_size_v2=0, ppl=78.17, wps=467.4, ups=0.51, wpb=918.9, bsz=32, num_updates=590, lr=1.34152e-05, gnorm=1.944, clip=100, loss_scale=128, train_wall=20, gb_free=15.2, wall=1527
2023-01-09 04:03:20 - progress_bar.py[line:272] - INFO: epoch 001:    601 / 3665 loss=6.706, loss_v1=0, loss_v2=0, nll_loss=6.093, ntokens=863.2, nsentences=32, sample_size=863.2, sample_size_v1=0, sample_size_v2=0, ppl=68.26, wps=440.2, ups=0.51, wpb=863.2, bsz=32, num_updates=600, lr=1.36426e-05, gnorm=2.163, clip=100, loss_scale=128, train_wall=20, gb_free=15.4, wall=1546
2023-01-09 04:03:40 - progress_bar.py[line:272] - INFO: epoch 001:    611 / 3665 loss=6.689, loss_v1=0, loss_v2=0, nll_loss=6.066, ntokens=994.8, nsentences=32, sample_size=994.8, sample_size_v1=0, sample_size_v2=0, ppl=67, wps=505.3, ups=0.51, wpb=994.8, bsz=32, num_updates=610, lr=1.38699e-05, gnorm=1.784, clip=100, loss_scale=128, train_wall=20, gb_free=15.5, wall=1566
2023-01-09 04:04:00 - progress_bar.py[line:272] - INFO: epoch 001:    621 / 3665 loss=6.797, loss_v1=0, loss_v2=0, nll_loss=6.191, ntokens=907.6, nsentences=32, sample_size=907.6, sample_size_v1=0, sample_size_v2=0, ppl=73.06, wps=455.6, ups=0.5, wpb=907.6, bsz=32, num_updates=620, lr=1.40973e-05, gnorm=1.892, clip=100, loss_scale=128, train_wall=20, gb_free=15.5, wall=1586
2023-01-09 04:04:20 - progress_bar.py[line:272] - INFO: epoch 001:    631 / 3665 loss=6.692, loss_v1=0, loss_v2=0, nll_loss=6.066, ntokens=953.6, nsentences=32, sample_size=953.6, sample_size_v1=0, sample_size_v2=0, ppl=67, wps=476.4, ups=0.5, wpb=953.6, bsz=32, num_updates=630, lr=1.43247e-05, gnorm=1.976, clip=100, loss_scale=128, train_wall=20, gb_free=15.5, wall=1606
2023-01-09 04:04:40 - progress_bar.py[line:272] - INFO: epoch 001:    641 / 3665 loss=6.798, loss_v1=0, loss_v2=0, nll_loss=6.182, ntokens=1118.4, nsentences=32, sample_size=1118.4, sample_size_v1=0, sample_size_v2=0, ppl=72.6, wps=556.9, ups=0.5, wpb=1118.4, bsz=32, num_updates=640, lr=1.45521e-05, gnorm=1.907, clip=100, loss_scale=128, train_wall=20, gb_free=15.3, wall=1626
2023-01-09 04:05:00 - progress_bar.py[line:272] - INFO: epoch 001:    651 / 3665 loss=6.669, loss_v1=0, loss_v2=0, nll_loss=6.04, ntokens=787, nsentences=32, sample_size=787, sample_size_v1=0, sample_size_v2=0, ppl=65.79, wps=395.5, ups=0.5, wpb=787, bsz=32, num_updates=650, lr=1.47794e-05, gnorm=2.136, clip=100, loss_scale=128, train_wall=20, gb_free=15.4, wall=1646
2023-01-09 04:05:19 - progress_bar.py[line:272] - INFO: epoch 001:    661 / 3665 loss=6.582, loss_v1=0, loss_v2=0, nll_loss=5.933, ntokens=889.6, nsentences=32, sample_size=889.6, sample_size_v1=0, sample_size_v2=0, ppl=61.1, wps=446.1, ups=0.5, wpb=889.6, bsz=32, num_updates=660, lr=1.50068e-05, gnorm=2.08, clip=100, loss_scale=128, train_wall=20, gb_free=15, wall=1666
2023-01-09 04:05:39 - progress_bar.py[line:272] - INFO: epoch 001:    671 / 3665 loss=6.716, loss_v1=0, loss_v2=0, nll_loss=6.081, ntokens=988.7, nsentences=32, sample_size=988.7, sample_size_v1=0, sample_size_v2=0, ppl=67.67, wps=493.9, ups=0.5, wpb=988.7, bsz=32, num_updates=670, lr=1.52342e-05, gnorm=1.901, clip=100, loss_scale=128, train_wall=20, gb_free=15.4, wall=1686
2023-01-09 04:05:59 - progress_bar.py[line:272] - INFO: epoch 001:    681 / 3665 loss=6.598, loss_v1=0, loss_v2=0, nll_loss=5.954, ntokens=839.3, nsentences=32, sample_size=839.3, sample_size_v1=0, sample_size_v2=0, ppl=61.98, wps=421.7, ups=0.5, wpb=839.3, bsz=32, num_updates=680, lr=1.54616e-05, gnorm=2.267, clip=100, loss_scale=128, train_wall=20, gb_free=15.3, wall=1706
2023-01-09 04:06:19 - progress_bar.py[line:272] - INFO: epoch 001:    691 / 3665 loss=6.484, loss_v1=0, loss_v2=0, nll_loss=5.817, ntokens=890, nsentences=32, sample_size=890, sample_size_v1=0, sample_size_v2=0, ppl=56.36, wps=450.5, ups=0.51, wpb=890, bsz=32, num_updates=690, lr=1.56889e-05, gnorm=2.231, clip=100, loss_scale=128, train_wall=20, gb_free=15.3, wall=1725
2023-01-09 04:06:39 - progress_bar.py[line:272] - INFO: epoch 001:    701 / 3665 loss=6.635, loss_v1=0, loss_v2=0, nll_loss=5.986, ntokens=979.6, nsentences=32, sample_size=979.6, sample_size_v1=0, sample_size_v2=0, ppl=63.38, wps=494.1, ups=0.5, wpb=979.6, bsz=32, num_updates=700, lr=1.59163e-05, gnorm=1.905, clip=100, loss_scale=128, train_wall=20, gb_free=15.2, wall=1745
2023-01-09 04:06:59 - progress_bar.py[line:272] - INFO: epoch 001:    711 / 3665 loss=6.528, loss_v1=0, loss_v2=0, nll_loss=5.862, ntokens=788.9, nsentences=32, sample_size=788.9, sample_size_v1=0, sample_size_v2=0, ppl=58.16, wps=400.9, ups=0.51, wpb=788.9, bsz=32, num_updates=710, lr=1.61437e-05, gnorm=2.153, clip=100, loss_scale=128, train_wall=20, gb_free=15.2, wall=1765
2023-01-09 04:07:18 - progress_bar.py[line:272] - INFO: epoch 001:    721 / 3665 loss=6.557, loss_v1=0, loss_v2=0, nll_loss=5.893, ntokens=1024.7, nsentences=32, sample_size=1024.7, sample_size_v1=0, sample_size_v2=0, ppl=59.42, wps=516.7, ups=0.5, wpb=1024.7, bsz=32, num_updates=720, lr=1.63711e-05, gnorm=1.843, clip=100, loss_scale=128, train_wall=20, gb_free=15.3, wall=1785
2023-01-09 04:07:38 - progress_bar.py[line:272] - INFO: epoch 001:    731 / 3665 loss=6.573, loss_v1=0, loss_v2=0, nll_loss=5.908, ntokens=867.8, nsentences=32, sample_size=867.8, sample_size_v1=0, sample_size_v2=0, ppl=60.04, wps=439.1, ups=0.51, wpb=867.8, bsz=32, num_updates=730, lr=1.65985e-05, gnorm=2.047, clip=100, loss_scale=128, train_wall=20, gb_free=15.4, wall=1805
2023-01-09 04:07:58 - progress_bar.py[line:272] - INFO: epoch 001:    741 / 3665 loss=6.498, loss_v1=0, loss_v2=0, nll_loss=5.819, ntokens=906.8, nsentences=32, sample_size=906.8, sample_size_v1=0, sample_size_v2=0, ppl=56.46, wps=458.1, ups=0.51, wpb=906.8, bsz=32, num_updates=740, lr=1.68258e-05, gnorm=2.052, clip=100, loss_scale=128, train_wall=20, gb_free=15.6, wall=1824
2023-01-09 04:08:18 - progress_bar.py[line:272] - INFO: epoch 001:    751 / 3665 loss=6.443, loss_v1=0, loss_v2=0, nll_loss=5.758, ntokens=1021.6, nsentences=32, sample_size=1021.6, sample_size_v1=0, sample_size_v2=0, ppl=54.13, wps=514.9, ups=0.5, wpb=1021.6, bsz=32, num_updates=750, lr=1.70532e-05, gnorm=1.831, clip=100, loss_scale=128, train_wall=20, gb_free=15.4, wall=1844
2023-01-09 04:08:38 - progress_bar.py[line:272] - INFO: epoch 001:    761 / 3665 loss=6.485, loss_v1=0, loss_v2=0, nll_loss=5.807, ntokens=843.9, nsentences=32, sample_size=843.9, sample_size_v1=0, sample_size_v2=0, ppl=55.97, wps=427.6, ups=0.51, wpb=843.9, bsz=32, num_updates=760, lr=1.72806e-05, gnorm=1.897, clip=100, loss_scale=128, train_wall=20, gb_free=15.3, wall=1864
2023-01-09 04:08:57 - progress_bar.py[line:272] - INFO: epoch 001:    771 / 3665 loss=6.445, loss_v1=0, loss_v2=0, nll_loss=5.753, ntokens=977.4, nsentences=32, sample_size=977.4, sample_size_v1=0, sample_size_v2=0, ppl=53.93, wps=493.6, ups=0.5, wpb=977.4, bsz=32, num_updates=770, lr=1.7508e-05, gnorm=2.005, clip=100, loss_scale=128, train_wall=20, gb_free=15.3, wall=1884
2023-01-09 04:09:17 - progress_bar.py[line:272] - INFO: epoch 001:    781 / 3665 loss=6.423, loss_v1=0, loss_v2=0, nll_loss=5.73, ntokens=985.3, nsentences=32, sample_size=985.3, sample_size_v1=0, sample_size_v2=0, ppl=53.07, wps=496.5, ups=0.5, wpb=985.3, bsz=32, num_updates=780, lr=1.77353e-05, gnorm=1.931, clip=100, loss_scale=128, train_wall=20, gb_free=15.4, wall=1904
2023-01-09 04:09:37 - progress_bar.py[line:272] - INFO: epoch 001:    791 / 3665 loss=6.316, loss_v1=0, loss_v2=0, nll_loss=5.607, ntokens=773.6, nsentences=32, sample_size=773.6, sample_size_v1=0, sample_size_v2=0, ppl=48.75, wps=391.8, ups=0.51, wpb=773.6, bsz=32, num_updates=790, lr=1.79627e-05, gnorm=1.992, clip=100, loss_scale=128, train_wall=20, gb_free=15.6, wall=1923
2023-01-09 04:09:57 - progress_bar.py[line:272] - INFO: epoch 001:    801 / 3665 loss=6.436, loss_v1=0, loss_v2=0, nll_loss=5.736, ntokens=1064.9, nsentences=32, sample_size=1064.9, sample_size_v1=0, sample_size_v2=0, ppl=53.29, wps=537.2, ups=0.5, wpb=1064.9, bsz=32, num_updates=800, lr=1.81901e-05, gnorm=1.878, clip=100, loss_scale=128, train_wall=20, gb_free=15.1, wall=1943
2023-01-09 04:10:17 - progress_bar.py[line:272] - INFO: epoch 001:    811 / 3665 loss=6.296, loss_v1=0, loss_v2=0, nll_loss=5.579, ntokens=885.1, nsentences=32, sample_size=885.1, sample_size_v1=0, sample_size_v2=0, ppl=47.8, wps=447.7, ups=0.51, wpb=885.1, bsz=32, num_updates=810, lr=1.84175e-05, gnorm=1.813, clip=100, loss_scale=128, train_wall=20, gb_free=15.6, wall=1963
2023-01-09 04:10:36 - progress_bar.py[line:272] - INFO: epoch 001:    821 / 3665 loss=6.34, loss_v1=0, loss_v2=0, nll_loss=5.629, ntokens=789, nsentences=32, sample_size=789, sample_size_v1=0, sample_size_v2=0, ppl=49.47, wps=399.7, ups=0.51, wpb=789, bsz=32, num_updates=820, lr=1.86448e-05, gnorm=1.921, clip=100, loss_scale=128, train_wall=20, gb_free=15.1, wall=1983
2023-01-09 04:10:56 - progress_bar.py[line:272] - INFO: epoch 001:    831 / 3665 loss=6.387, loss_v1=0, loss_v2=0, nll_loss=5.679, ntokens=1041.5, nsentences=32, sample_size=1041.5, sample_size_v1=0, sample_size_v2=0, ppl=51.23, wps=524.3, ups=0.5, wpb=1041.5, bsz=32, num_updates=830, lr=1.88722e-05, gnorm=1.771, clip=100, loss_scale=128, train_wall=20, gb_free=15.2, wall=2002
2023-01-09 04:11:16 - progress_bar.py[line:272] - INFO: epoch 001:    841 / 3665 loss=6.349, loss_v1=0, loss_v2=0, nll_loss=5.633, ntokens=774.2, nsentences=32, sample_size=774.2, sample_size_v1=0, sample_size_v2=0, ppl=49.64, wps=393, ups=0.51, wpb=774.2, bsz=32, num_updates=840, lr=1.90996e-05, gnorm=1.844, clip=100, loss_scale=128, train_wall=20, gb_free=15.6, wall=2022
2023-01-09 04:11:36 - progress_bar.py[line:272] - INFO: epoch 001:    851 / 3665 loss=6.254, loss_v1=0, loss_v2=0, nll_loss=5.528, ntokens=837.6, nsentences=32, sample_size=837.6, sample_size_v1=0, sample_size_v2=0, ppl=46.14, wps=424.8, ups=0.51, wpb=837.6, bsz=32, num_updates=850, lr=1.9327e-05, gnorm=2.165, clip=100, loss_scale=128, train_wall=20, gb_free=15.3, wall=2042
2023-01-09 04:11:55 - progress_bar.py[line:272] - INFO: epoch 001:    861 / 3665 loss=6.261, loss_v1=0, loss_v2=0, nll_loss=5.532, ntokens=1070.2, nsentences=32, sample_size=1070.2, sample_size_v1=0, sample_size_v2=0, ppl=46.28, wps=538.7, ups=0.5, wpb=1070.2, bsz=32, num_updates=860, lr=1.95543e-05, gnorm=1.816, clip=100, loss_scale=128, train_wall=20, gb_free=15.1, wall=2062
2023-01-09 04:12:15 - progress_bar.py[line:272] - INFO: epoch 001:    871 / 3665 loss=6.377, loss_v1=0, loss_v2=0, nll_loss=5.66, ntokens=980.8, nsentences=32, sample_size=980.8, sample_size_v1=0, sample_size_v2=0, ppl=50.58, wps=494.6, ups=0.5, wpb=980.8, bsz=32, num_updates=870, lr=1.97817e-05, gnorm=1.596, clip=100, loss_scale=128, train_wall=20, gb_free=15.5, wall=2082
2023-01-09 04:12:35 - progress_bar.py[line:272] - INFO: epoch 001:    881 / 3665 loss=6.214, loss_v1=0, loss_v2=0, nll_loss=5.48, ntokens=905.6, nsentences=32, sample_size=905.6, sample_size_v1=0, sample_size_v2=0, ppl=44.65, wps=457.9, ups=0.51, wpb=905.6, bsz=32, num_updates=880, lr=2.00091e-05, gnorm=1.881, clip=100, loss_scale=128, train_wall=20, gb_free=15.5, wall=2101
2023-01-09 04:12:55 - progress_bar.py[line:272] - INFO: epoch 001:    891 / 3665 loss=6.185, loss_v1=0, loss_v2=0, nll_loss=5.441, ntokens=997.4, nsentences=32, sample_size=997.4, sample_size_v1=0, sample_size_v2=0, ppl=43.44, wps=502.6, ups=0.5, wpb=997.4, bsz=32, num_updates=890, lr=2.02365e-05, gnorm=1.689, clip=100, loss_scale=128, train_wall=20, gb_free=15.2, wall=2121
2023-01-09 04:13:15 - progress_bar.py[line:272] - INFO: epoch 001:    901 / 3665 loss=6.417, loss_v1=0, loss_v2=0, nll_loss=5.706, ntokens=965.1, nsentences=32, sample_size=965.1, sample_size_v1=0, sample_size_v2=0, ppl=52.18, wps=486.5, ups=0.5, wpb=965.1, bsz=32, num_updates=900, lr=2.04638e-05, gnorm=1.669, clip=100, loss_scale=128, train_wall=20, gb_free=15.4, wall=2141
2023-01-09 04:13:35 - progress_bar.py[line:272] - INFO: epoch 001:    911 / 3665 loss=6.132, loss_v1=0, loss_v2=0, nll_loss=5.379, ntokens=991, nsentences=32, sample_size=991, sample_size_v1=0, sample_size_v2=0, ppl=41.61, wps=500.2, ups=0.5, wpb=991, bsz=32, num_updates=910, lr=2.06912e-05, gnorm=1.886, clip=100, loss_scale=128, train_wall=20, gb_free=15.5, wall=2161
2023-01-09 04:13:54 - progress_bar.py[line:272] - INFO: epoch 001:    921 / 3665 loss=6.272, loss_v1=0, loss_v2=0, nll_loss=5.54, ntokens=1045.7, nsentences=32, sample_size=1045.7, sample_size_v1=0, sample_size_v2=0, ppl=46.52, wps=527.3, ups=0.5, wpb=1045.7, bsz=32, num_updates=920, lr=2.09186e-05, gnorm=1.691, clip=100, loss_scale=128, train_wall=20, gb_free=15.2, wall=2181
2023-01-09 04:14:14 - progress_bar.py[line:272] - INFO: epoch 001:    931 / 3665 loss=6.24, loss_v1=0, loss_v2=0, nll_loss=5.502, ntokens=834.7, nsentences=32, sample_size=834.7, sample_size_v1=0, sample_size_v2=0, ppl=45.32, wps=421.9, ups=0.51, wpb=834.7, bsz=32, num_updates=930, lr=2.1146e-05, gnorm=1.728, clip=100, loss_scale=128, train_wall=20, gb_free=15.5, wall=2200
2023-01-09 04:14:34 - progress_bar.py[line:272] - INFO: epoch 001:    941 / 3665 loss=6.162, loss_v1=0, loss_v2=0, nll_loss=5.412, ntokens=967.7, nsentences=32, sample_size=967.7, sample_size_v1=0, sample_size_v2=0, ppl=42.58, wps=483.3, ups=0.5, wpb=967.7, bsz=32, num_updates=940, lr=2.13734e-05, gnorm=1.619, clip=100, loss_scale=128, train_wall=20, gb_free=15.6, wall=2220
2023-01-09 04:14:54 - progress_bar.py[line:272] - INFO: epoch 001:    951 / 3665 loss=6.114, loss_v1=0, loss_v2=0, nll_loss=5.357, ntokens=878.7, nsentences=32, sample_size=878.7, sample_size_v1=0, sample_size_v2=0, ppl=40.97, wps=445, ups=0.51, wpb=878.7, bsz=32, num_updates=950, lr=2.16007e-05, gnorm=1.71, clip=100, loss_scale=128, train_wall=20, gb_free=15.6, wall=2240
2023-01-09 04:15:14 - progress_bar.py[line:272] - INFO: epoch 001:    961 / 3665 loss=6.09, loss_v1=0, loss_v2=0, nll_loss=5.336, ntokens=829.5, nsentences=32, sample_size=829.5, sample_size_v1=0, sample_size_v2=0, ppl=40.38, wps=421.6, ups=0.51, wpb=829.5, bsz=32, num_updates=960, lr=2.18281e-05, gnorm=1.9, clip=100, loss_scale=128, train_wall=20, gb_free=15.1, wall=2260
2023-01-09 04:15:33 - progress_bar.py[line:272] - INFO: epoch 001:    971 / 3665 loss=6.08, loss_v1=0, loss_v2=0, nll_loss=5.317, ntokens=946.4, nsentences=32, sample_size=946.4, sample_size_v1=0, sample_size_v2=0, ppl=39.85, wps=479.4, ups=0.51, wpb=946.4, bsz=32, num_updates=970, lr=2.20555e-05, gnorm=1.552, clip=100, loss_scale=128, train_wall=20, gb_free=15.5, wall=2280
2023-01-09 04:15:53 - progress_bar.py[line:272] - INFO: epoch 001:    981 / 3665 loss=6.267, loss_v1=0, loss_v2=0, nll_loss=5.527, ntokens=911.1, nsentences=32, sample_size=911.1, sample_size_v1=0, sample_size_v2=0, ppl=46.11, wps=460.3, ups=0.51, wpb=911.1, bsz=32, num_updates=980, lr=2.22829e-05, gnorm=1.621, clip=100, loss_scale=128, train_wall=20, gb_free=15.3, wall=2299
2023-01-09 04:16:13 - progress_bar.py[line:272] - INFO: epoch 001:    991 / 3665 loss=6.072, loss_v1=0, loss_v2=0, nll_loss=5.311, ntokens=838.2, nsentences=32, sample_size=838.2, sample_size_v1=0, sample_size_v2=0, ppl=39.71, wps=424.6, ups=0.51, wpb=838.2, bsz=32, num_updates=990, lr=2.25102e-05, gnorm=1.89, clip=100, loss_scale=128, train_wall=20, gb_free=15.4, wall=2319
2023-01-09 04:16:33 - progress_bar.py[line:272] - INFO: epoch 001:   1001 / 3665 loss=6.131, loss_v1=0, loss_v2=0, nll_loss=5.373, ntokens=1060, nsentences=32, sample_size=1060, sample_size_v1=0, sample_size_v2=0, ppl=41.43, wps=534.6, ups=0.5, wpb=1060, bsz=32, num_updates=1000, lr=2.27376e-05, gnorm=1.6, clip=100, loss_scale=128, train_wall=20, gb_free=14.6, wall=2339
2023-01-09 04:16:33 - train.py[line:445] - INFO: begin validation on "valid" subset
slice_id 0 seek offset 0
slice_id 0 seek offset 0
2023-01-09 04:21:24 - progress_bar.py[line:282] - INFO: epoch 001 | valid on 'valid' subset | loss 6.117 | loss_v1 0 | loss_v2 0 | nll_loss 5.342 | ntokens 117.1 | nsentences 4 | sample_size 117.1 | sample_size_v1 0 | sample_size_v2 0 | AP 0 | total positives 21.727 | TP 0 | FP 8 | ppl 40.57 | wps 504.4 | wpb 117.1 | bsz 4 | num_updates 1000 | best_AP 0
2023-01-09 04:21:24 - checkpoint_utils.py[line:64] - INFO: Preparing to save checkpoint for epoch 1 @ 1000 updates
2023-01-09 04:21:24 - trainer.py[line:431] - INFO: Saving checkpoint to ../../checkpoints/OFA/detection_checkpoints/10_5e-5_512/checkpoint_1_1000.pt
2023-01-09 04:21:27 - trainer.py[line:441] - INFO: Finished saving checkpoint to ../../checkpoints/OFA/detection_checkpoints/10_5e-5_512/checkpoint_1_1000.pt
2023-01-09 04:22:19 - checkpoint_utils.py[line:133] - INFO: Saved checkpoint ../../checkpoints/OFA/detection_checkpoints/10_5e-5_512/checkpoint_1_1000.pt (epoch 1 @ 1000 updates, score 0.0) (writing took 55.51414623018354 seconds)
2023-01-09 04:22:39 - progress_bar.py[line:272] - INFO: epoch 001:   1011 / 3665 loss=6.201, loss_v1=0, loss_v2=0, nll_loss=5.453, ntokens=800, nsentences=32, sample_size=800, sample_size_v1=0, sample_size_v2=0, ppl=43.79, wps=21.9, ups=0.03, wpb=800, bsz=32, num_updates=1010, lr=2.2965e-05, gnorm=1.697, clip=100, loss_scale=128, train_wall=19, gb_free=15.3, wall=2705
2023-01-09 04:22:58 - progress_bar.py[line:272] - INFO: epoch 001:   1021 / 3665 loss=6.056, loss_v1=0, loss_v2=0, nll_loss=5.294, ntokens=896.1, nsentences=32, sample_size=896.1, sample_size_v1=0, sample_size_v2=0, ppl=39.22, wps=460.1, ups=0.51, wpb=896.1, bsz=32, num_updates=1020, lr=2.31924e-05, gnorm=1.713, clip=100, loss_scale=128, train_wall=19, gb_free=15.1, wall=2725
2023-01-09 04:23:18 - progress_bar.py[line:272] - INFO: epoch 001:   1031 / 3665 loss=6.238, loss_v1=0, loss_v2=0, nll_loss=5.494, ntokens=1072.5, nsentences=32, sample_size=1072.5, sample_size_v1=0, sample_size_v2=0, ppl=45.06, wps=546.1, ups=0.51, wpb=1072.5, bsz=32, num_updates=1030, lr=2.34197e-05, gnorm=1.61, clip=100, loss_scale=256, train_wall=20, gb_free=15.1, wall=2744
2023-01-09 04:23:37 - progress_bar.py[line:272] - INFO: epoch 001:   1041 / 3665 loss=6.008, loss_v1=0, loss_v2=0, nll_loss=5.226, ntokens=577.3, nsentences=32, sample_size=577.3, sample_size_v1=0, sample_size_v2=0, ppl=37.43, wps=296.8, ups=0.51, wpb=577.3, bsz=32, num_updates=1040, lr=2.36471e-05, gnorm=2.128, clip=100, loss_scale=256, train_wall=19, gb_free=15.3, wall=2764
2023-01-09 04:23:57 - progress_bar.py[line:272] - INFO: epoch 001:   1051 / 3665 loss=6.037, loss_v1=0, loss_v2=0, nll_loss=5.274, ntokens=892, nsentences=32, sample_size=892, sample_size_v1=0, sample_size_v2=0, ppl=38.69, wps=455.8, ups=0.51, wpb=892, bsz=32, num_updates=1050, lr=2.38745e-05, gnorm=1.87, clip=100, loss_scale=256, train_wall=20, gb_free=15.4, wall=2783
2023-01-09 04:24:17 - progress_bar.py[line:272] - INFO: epoch 001:   1061 / 3665 loss=6.219, loss_v1=0, loss_v2=0, nll_loss=5.472, ntokens=1044.6, nsentences=32, sample_size=1044.6, sample_size_v1=0, sample_size_v2=0, ppl=44.38, wps=531.1, ups=0.51, wpb=1044.6, bsz=32, num_updates=1060, lr=2.41019e-05, gnorm=1.657, clip=100, loss_scale=256, train_wall=20, gb_free=15.4, wall=2803
2023-01-09 04:24:36 - progress_bar.py[line:272] - INFO: epoch 001:   1071 / 3665 loss=6.015, loss_v1=0, loss_v2=0, nll_loss=5.238, ntokens=751.5, nsentences=32, sample_size=751.5, sample_size_v1=0, sample_size_v2=0, ppl=37.75, wps=384.4, ups=0.51, wpb=751.5, bsz=32, num_updates=1070, lr=2.43292e-05, gnorm=1.849, clip=100, loss_scale=256, train_wall=20, gb_free=15.7, wall=2822
2023-01-09 04:24:56 - progress_bar.py[line:272] - INFO: epoch 001:   1081 / 3665 loss=6.043, loss_v1=0, loss_v2=0, nll_loss=5.276, ntokens=990.6, nsentences=32, sample_size=990.6, sample_size_v1=0, sample_size_v2=0, ppl=38.76, wps=507, ups=0.51, wpb=990.6, bsz=32, num_updates=1080, lr=2.45566e-05, gnorm=1.674, clip=100, loss_scale=256, train_wall=20, gb_free=15.4, wall=2842
2023-01-09 04:25:15 - progress_bar.py[line:272] - INFO: epoch 001:   1091 / 3665 loss=6.061, loss_v1=0, loss_v2=0, nll_loss=5.293, ntokens=841.1, nsentences=32, sample_size=841.1, sample_size_v1=0, sample_size_v2=0, ppl=39.22, wps=429.7, ups=0.51, wpb=841.1, bsz=32, num_updates=1090, lr=2.4784e-05, gnorm=1.678, clip=100, loss_scale=256, train_wall=20, gb_free=15.5, wall=2862
2023-01-09 04:25:35 - progress_bar.py[line:272] - INFO: epoch 001:   1101 / 3665 loss=6.023, loss_v1=0, loss_v2=0, nll_loss=5.243, ntokens=966.2, nsentences=32, sample_size=966.2, sample_size_v1=0, sample_size_v2=0, ppl=37.87, wps=492.7, ups=0.51, wpb=966.2, bsz=32, num_updates=1100, lr=2.50114e-05, gnorm=1.648, clip=100, loss_scale=256, train_wall=20, gb_free=15.4, wall=2881
2023-01-09 04:25:54 - progress_bar.py[line:272] - INFO: epoch 001:   1111 / 3665 loss=6.053, loss_v1=0, loss_v2=0, nll_loss=5.289, ntokens=764.6, nsentences=32, sample_size=764.6, sample_size_v1=0, sample_size_v2=0, ppl=39.09, wps=391, ups=0.51, wpb=764.6, bsz=32, num_updates=1110, lr=2.52387e-05, gnorm=1.657, clip=100, loss_scale=256, train_wall=20, gb_free=15.2, wall=2901
2023-01-09 04:26:14 - progress_bar.py[line:272] - INFO: epoch 001:   1121 / 3665 loss=6.041, loss_v1=0, loss_v2=0, nll_loss=5.263, ntokens=1132, nsentences=32, sample_size=1132, sample_size_v1=0, sample_size_v2=0, ppl=38.4, wps=574.9, ups=0.51, wpb=1132, bsz=32, num_updates=1120, lr=2.54661e-05, gnorm=1.458, clip=100, loss_scale=256, train_wall=20, gb_free=15.4, wall=2920
2023-01-09 04:26:34 - progress_bar.py[line:272] - INFO: epoch 001:   1131 / 3665 loss=5.946, loss_v1=0, loss_v2=0, nll_loss=5.157, ntokens=1048.3, nsentences=32, sample_size=1048.3, sample_size_v1=0, sample_size_v2=0, ppl=35.68, wps=533, ups=0.51, wpb=1048.3, bsz=32, num_updates=1130, lr=2.56935e-05, gnorm=1.572, clip=100, loss_scale=256, train_wall=20, gb_free=14.8, wall=2940
2023-01-09 04:26:53 - progress_bar.py[line:272] - INFO: epoch 001:   1141 / 3665 loss=6.094, loss_v1=0, loss_v2=0, nll_loss=5.329, ntokens=812.3, nsentences=32, sample_size=812.3, sample_size_v1=0, sample_size_v2=0, ppl=40.21, wps=413.6, ups=0.51, wpb=812.3, bsz=32, num_updates=1140, lr=2.59209e-05, gnorm=1.605, clip=100, loss_scale=256, train_wall=20, gb_free=15.4, wall=2960
2023-01-09 04:27:13 - progress_bar.py[line:272] - INFO: epoch 001:   1151 / 3665 loss=5.966, loss_v1=0, loss_v2=0, nll_loss=5.185, ntokens=835.2, nsentences=32, sample_size=835.2, sample_size_v1=0, sample_size_v2=0, ppl=36.37, wps=420.2, ups=0.5, wpb=835.2, bsz=32, num_updates=1150, lr=2.61482e-05, gnorm=1.64, clip=100, loss_scale=256, train_wall=20, gb_free=15.5, wall=2980
2023-01-09 04:27:33 - progress_bar.py[line:272] - INFO: epoch 001:   1161 / 3665 loss=5.917, loss_v1=0, loss_v2=0, nll_loss=5.126, ntokens=950.7, nsentences=32, sample_size=950.7, sample_size_v1=0, sample_size_v2=0, ppl=34.92, wps=478, ups=0.5, wpb=950.7, bsz=32, num_updates=1160, lr=2.63756e-05, gnorm=1.466, clip=100, loss_scale=256, train_wall=20, gb_free=15.3, wall=2999
2023-01-09 04:27:53 - progress_bar.py[line:272] - INFO: epoch 001:   1171 / 3665 loss=6.046, loss_v1=0, loss_v2=0, nll_loss=5.274, ntokens=912.9, nsentences=32, sample_size=912.9, sample_size_v1=0, sample_size_v2=0, ppl=38.71, wps=458.9, ups=0.5, wpb=912.9, bsz=32, num_updates=1170, lr=2.6603e-05, gnorm=1.595, clip=100, loss_scale=256, train_wall=20, gb_free=15.4, wall=3019
2023-01-09 04:28:13 - progress_bar.py[line:272] - INFO: epoch 001:   1181 / 3665 loss=5.951, loss_v1=0, loss_v2=0, nll_loss=5.165, ntokens=785.1, nsentences=32, sample_size=785.1, sample_size_v1=0, sample_size_v2=0, ppl=35.87, wps=395.9, ups=0.5, wpb=785.1, bsz=32, num_updates=1180, lr=2.68304e-05, gnorm=1.929, clip=100, loss_scale=256, train_wall=20, gb_free=15.5, wall=3039
2023-01-09 04:28:33 - progress_bar.py[line:272] - INFO: epoch 001:   1191 / 3665 loss=6.066, loss_v1=0, loss_v2=0, nll_loss=5.292, ntokens=1109.3, nsentences=32, sample_size=1109.3, sample_size_v1=0, sample_size_v2=0, ppl=39.18, wps=554.8, ups=0.5, wpb=1109.3, bsz=32, num_updates=1190, lr=2.70578e-05, gnorm=1.557, clip=100, loss_scale=256, train_wall=20, gb_free=15.3, wall=3059
2023-01-09 04:28:53 - progress_bar.py[line:272] - INFO: epoch 001:   1201 / 3665 loss=6.131, loss_v1=0, loss_v2=0, nll_loss=5.367, ntokens=1070.2, nsentences=32, sample_size=1070.2, sample_size_v1=0, sample_size_v2=0, ppl=41.27, wps=536.3, ups=0.5, wpb=1070.2, bsz=32, num_updates=1200, lr=2.72851e-05, gnorm=1.537, clip=100, loss_scale=256, train_wall=20, gb_free=15.1, wall=3079
2023-01-09 04:29:13 - progress_bar.py[line:272] - INFO: epoch 001:   1211 / 3665 loss=6.123, loss_v1=0, loss_v2=0, nll_loss=5.352, ntokens=815.5, nsentences=32, sample_size=815.5, sample_size_v1=0, sample_size_v2=0, ppl=40.84, wps=411.8, ups=0.5, wpb=815.5, bsz=32, num_updates=1210, lr=2.75125e-05, gnorm=1.642, clip=100, loss_scale=256, train_wall=20, gb_free=15.1, wall=3099
2023-01-09 04:29:33 - progress_bar.py[line:272] - INFO: epoch 001:   1221 / 3665 loss=5.974, loss_v1=0, loss_v2=0, nll_loss=5.191, ntokens=1013.8, nsentences=32, sample_size=1013.8, sample_size_v1=0, sample_size_v2=0, ppl=36.53, wps=510.1, ups=0.5, wpb=1013.8, bsz=32, num_updates=1220, lr=2.77399e-05, gnorm=1.694, clip=100, loss_scale=256, train_wall=20, gb_free=14.9, wall=3119
2023-01-09 04:29:52 - progress_bar.py[line:272] - INFO: epoch 001:   1231 / 3665 loss=6.126, loss_v1=0, loss_v2=0, nll_loss=5.356, ntokens=1098.3, nsentences=32, sample_size=1098.3, sample_size_v1=0, sample_size_v2=0, ppl=40.97, wps=551.2, ups=0.5, wpb=1098.3, bsz=32, num_updates=1230, lr=2.79673e-05, gnorm=1.433, clip=100, loss_scale=256, train_wall=20, gb_free=15.4, wall=3139
2023-01-09 04:30:12 - progress_bar.py[line:272] - INFO: epoch 001:   1241 / 3665 loss=6.142, loss_v1=0, loss_v2=0, nll_loss=5.371, ntokens=956.4, nsentences=32, sample_size=956.4, sample_size_v1=0, sample_size_v2=0, ppl=41.39, wps=482.9, ups=0.5, wpb=956.4, bsz=32, num_updates=1240, lr=2.81946e-05, gnorm=1.333, clip=100, loss_scale=256, train_wall=20, gb_free=15.3, wall=3159
2023-01-09 04:30:32 - progress_bar.py[line:272] - INFO: epoch 001:   1251 / 3665 loss=5.979, loss_v1=0, loss_v2=0, nll_loss=5.19, ntokens=1007.8, nsentences=32, sample_size=1007.8, sample_size_v1=0, sample_size_v2=0, ppl=36.51, wps=510, ups=0.51, wpb=1007.8, bsz=32, num_updates=1250, lr=2.8422e-05, gnorm=1.468, clip=100, loss_scale=256, train_wall=20, gb_free=15.5, wall=3178
2023-01-09 04:30:52 - progress_bar.py[line:272] - INFO: epoch 001:   1261 / 3665 loss=6.018, loss_v1=0, loss_v2=0, nll_loss=5.231, ntokens=1026.4, nsentences=32, sample_size=1026.4, sample_size_v1=0, sample_size_v2=0, ppl=37.56, wps=518.6, ups=0.51, wpb=1026.4, bsz=32, num_updates=1260, lr=2.86494e-05, gnorm=1.618, clip=100, loss_scale=256, train_wall=20, gb_free=15.6, wall=3198
2023-01-09 04:31:12 - progress_bar.py[line:272] - INFO: epoch 001:   1271 / 3665 loss=5.952, loss_v1=0, loss_v2=0, nll_loss=5.168, ntokens=676.2, nsentences=32, sample_size=676.2, sample_size_v1=0, sample_size_v2=0, ppl=35.95, wps=340.6, ups=0.5, wpb=676.2, bsz=32, num_updates=1270, lr=2.88768e-05, gnorm=1.609, clip=100, loss_scale=256, train_wall=20, gb_free=15.7, wall=3218
2023-01-09 04:31:31 - progress_bar.py[line:272] - INFO: epoch 001:   1281 / 3665 loss=5.941, loss_v1=0, loss_v2=0, nll_loss=5.141, ntokens=860.8, nsentences=32, sample_size=860.8, sample_size_v1=0, sample_size_v2=0, ppl=35.29, wps=438.8, ups=0.51, wpb=860.8, bsz=32, num_updates=1280, lr=2.91041e-05, gnorm=1.572, clip=100, loss_scale=256, train_wall=20, gb_free=15.5, wall=3238
2023-01-09 04:31:51 - progress_bar.py[line:272] - INFO: epoch 001:   1291 / 3665 loss=5.964, loss_v1=0, loss_v2=0, nll_loss=5.178, ntokens=1054.3, nsentences=32, sample_size=1054.3, sample_size_v1=0, sample_size_v2=0, ppl=36.19, wps=535.4, ups=0.51, wpb=1054.3, bsz=32, num_updates=1290, lr=2.93315e-05, gnorm=1.539, clip=100, loss_scale=256, train_wall=20, gb_free=14.6, wall=3257
2023-01-09 04:32:11 - progress_bar.py[line:272] - INFO: epoch 001:   1301 / 3665 loss=6.005, loss_v1=0, loss_v2=0, nll_loss=5.215, ntokens=792.6, nsentences=32, sample_size=792.6, sample_size_v1=0, sample_size_v2=0, ppl=37.14, wps=403.5, ups=0.51, wpb=792.6, bsz=32, num_updates=1300, lr=2.95589e-05, gnorm=1.614, clip=100, loss_scale=256, train_wall=20, gb_free=15.6, wall=3277
2023-01-09 04:32:30 - progress_bar.py[line:272] - INFO: epoch 001:   1311 / 3665 loss=5.925, loss_v1=0, loss_v2=0, nll_loss=5.126, ntokens=914, nsentences=32, sample_size=914, sample_size_v1=0, sample_size_v2=0, ppl=34.93, wps=464.6, ups=0.51, wpb=914, bsz=32, num_updates=1310, lr=2.97863e-05, gnorm=1.586, clip=100, loss_scale=256, train_wall=20, gb_free=15.4, wall=3297
2023-01-09 04:32:50 - progress_bar.py[line:272] - INFO: epoch 001:   1321 / 3665 loss=5.905, loss_v1=0, loss_v2=0, nll_loss=5.105, ntokens=981.5, nsentences=32, sample_size=981.5, sample_size_v1=0, sample_size_v2=0, ppl=34.41, wps=499, ups=0.51, wpb=981.5, bsz=32, num_updates=1320, lr=3.00136e-05, gnorm=1.447, clip=100, loss_scale=256, train_wall=20, gb_free=15.4, wall=3316
2023-01-09 04:33:10 - progress_bar.py[line:272] - INFO: epoch 001:   1331 / 3665 loss=6.038, loss_v1=0, loss_v2=0, nll_loss=5.257, ntokens=866.1, nsentences=32, sample_size=866.1, sample_size_v1=0, sample_size_v2=0, ppl=38.24, wps=441, ups=0.51, wpb=866.1, bsz=32, num_updates=1330, lr=3.0241e-05, gnorm=1.541, clip=100, loss_scale=256, train_wall=20, gb_free=15.4, wall=3336
2023-01-09 04:33:29 - progress_bar.py[line:272] - INFO: epoch 001:   1341 / 3665 loss=5.9, loss_v1=0, loss_v2=0, nll_loss=5.102, ntokens=884.3, nsentences=32, sample_size=884.3, sample_size_v1=0, sample_size_v2=0, ppl=34.34, wps=449.4, ups=0.51, wpb=884.3, bsz=32, num_updates=1340, lr=3.04684e-05, gnorm=1.617, clip=100, loss_scale=256, train_wall=20, gb_free=15.1, wall=3356
2023-01-09 04:33:49 - progress_bar.py[line:272] - INFO: epoch 001:   1351 / 3665 loss=5.89, loss_v1=0, loss_v2=0, nll_loss=5.09, ntokens=1015.3, nsentences=32, sample_size=1015.3, sample_size_v1=0, sample_size_v2=0, ppl=34.05, wps=516, ups=0.51, wpb=1015.3, bsz=32, num_updates=1350, lr=3.06958e-05, gnorm=1.37, clip=100, loss_scale=256, train_wall=20, gb_free=15.2, wall=3375
2023-01-09 04:34:09 - progress_bar.py[line:272] - INFO: epoch 001:   1361 / 3665 loss=5.977, loss_v1=0, loss_v2=0, nll_loss=5.182, ntokens=983.4, nsentences=32, sample_size=983.4, sample_size_v1=0, sample_size_v2=0, ppl=36.31, wps=498.8, ups=0.51, wpb=983.4, bsz=32, num_updates=1360, lr=3.09231e-05, gnorm=1.514, clip=100, loss_scale=256, train_wall=20, gb_free=15.4, wall=3395
2023-01-09 04:34:28 - progress_bar.py[line:272] - INFO: epoch 001:   1371 / 3665 loss=5.909, loss_v1=0, loss_v2=0, nll_loss=5.109, ntokens=855.1, nsentences=32, sample_size=855.1, sample_size_v1=0, sample_size_v2=0, ppl=34.52, wps=435.4, ups=0.51, wpb=855.1, bsz=32, num_updates=1370, lr=3.11505e-05, gnorm=1.411, clip=100, loss_scale=256, train_wall=20, gb_free=15.4, wall=3415
2023-01-09 04:34:48 - progress_bar.py[line:272] - INFO: epoch 001:   1381 / 3665 loss=5.86, loss_v1=0, loss_v2=0, nll_loss=5.048, ntokens=976.2, nsentences=32, sample_size=976.2, sample_size_v1=0, sample_size_v2=0, ppl=33.09, wps=495.9, ups=0.51, wpb=976.2, bsz=32, num_updates=1380, lr=3.13779e-05, gnorm=1.437, clip=100, loss_scale=256, train_wall=20, gb_free=15.4, wall=3434
2023-01-09 04:35:08 - progress_bar.py[line:272] - INFO: epoch 001:   1391 / 3665 loss=5.878, loss_v1=0, loss_v2=0, nll_loss=5.079, ntokens=750.8, nsentences=32, sample_size=750.8, sample_size_v1=0, sample_size_v2=0, ppl=33.8, wps=382.7, ups=0.51, wpb=750.8, bsz=32, num_updates=1390, lr=3.16053e-05, gnorm=1.555, clip=90, loss_scale=256, train_wall=20, gb_free=15.7, wall=3454
2023-01-09 04:35:27 - progress_bar.py[line:272] - INFO: epoch 001:   1401 / 3665 loss=5.889, loss_v1=0, loss_v2=0, nll_loss=5.088, ntokens=765.4, nsentences=32, sample_size=765.4, sample_size_v1=0, sample_size_v2=0, ppl=34, wps=390.7, ups=0.51, wpb=765.4, bsz=32, num_updates=1400, lr=3.18327e-05, gnorm=1.531, clip=100, loss_scale=256, train_wall=20, gb_free=15.4, wall=3474
2023-01-09 04:35:47 - progress_bar.py[line:272] - INFO: epoch 001:   1411 / 3665 loss=5.77, loss_v1=0, loss_v2=0, nll_loss=4.953, ntokens=799.6, nsentences=32, sample_size=799.6, sample_size_v1=0, sample_size_v2=0, ppl=30.97, wps=408.1, ups=0.51, wpb=799.6, bsz=32, num_updates=1410, lr=3.206e-05, gnorm=1.646, clip=100, loss_scale=256, train_wall=20, gb_free=15.2, wall=3493
2023-01-09 04:36:07 - progress_bar.py[line:272] - INFO: epoch 001:   1421 / 3665 loss=5.915, loss_v1=0, loss_v2=0, nll_loss=5.115, ntokens=988.5, nsentences=32, sample_size=988.5, sample_size_v1=0, sample_size_v2=0, ppl=34.66, wps=501, ups=0.51, wpb=988.5, bsz=32, num_updates=1420, lr=3.22874e-05, gnorm=1.489, clip=100, loss_scale=256, train_wall=20, gb_free=15.4, wall=3513
2023-01-09 04:36:26 - progress_bar.py[line:272] - INFO: epoch 001:   1431 / 3665 loss=5.84, loss_v1=0, loss_v2=0, nll_loss=5.032, ntokens=719.2, nsentences=32, sample_size=719.2, sample_size_v1=0, sample_size_v2=0, ppl=32.71, wps=366.4, ups=0.51, wpb=719.2, bsz=32, num_updates=1430, lr=3.25148e-05, gnorm=1.538, clip=100, loss_scale=256, train_wall=20, gb_free=15.4, wall=3532
2023-01-09 04:36:46 - progress_bar.py[line:272] - INFO: epoch 001:   1441 / 3665 loss=5.924, loss_v1=0, loss_v2=0, nll_loss=5.121, ntokens=978.9, nsentences=32, sample_size=978.9, sample_size_v1=0, sample_size_v2=0, ppl=34.81, wps=498, ups=0.51, wpb=978.9, bsz=32, num_updates=1440, lr=3.27422e-05, gnorm=1.464, clip=100, loss_scale=256, train_wall=20, gb_free=15, wall=3552
2023-01-09 04:37:06 - progress_bar.py[line:272] - INFO: epoch 001:   1451 / 3665 loss=5.971, loss_v1=0, loss_v2=0, nll_loss=5.17, ntokens=978.3, nsentences=32, sample_size=978.3, sample_size_v1=0, sample_size_v2=0, ppl=36, wps=496.5, ups=0.51, wpb=978.3, bsz=32, num_updates=1450, lr=3.29695e-05, gnorm=1.553, clip=100, loss_scale=256, train_wall=20, gb_free=15.7, wall=3572
2023-01-09 04:37:25 - progress_bar.py[line:272] - INFO: epoch 001:   1461 / 3665 loss=5.872, loss_v1=0, loss_v2=0, nll_loss=5.069, ntokens=746.8, nsentences=32, sample_size=746.8, sample_size_v1=0, sample_size_v2=0, ppl=33.56, wps=380.4, ups=0.51, wpb=746.8, bsz=32, num_updates=1460, lr=3.31969e-05, gnorm=1.543, clip=100, loss_scale=256, train_wall=20, gb_free=15.3, wall=3591
2023-01-09 04:37:45 - progress_bar.py[line:272] - INFO: epoch 001:   1471 / 3665 loss=5.807, loss_v1=0, loss_v2=0, nll_loss=4.991, ntokens=843.4, nsentences=32, sample_size=843.4, sample_size_v1=0, sample_size_v2=0, ppl=31.8, wps=430.2, ups=0.51, wpb=843.4, bsz=32, num_updates=1470, lr=3.34243e-05, gnorm=1.576, clip=100, loss_scale=256, train_wall=20, gb_free=15.3, wall=3611
2023-01-09 04:38:04 - progress_bar.py[line:272] - INFO: epoch 001:   1481 / 3665 loss=5.942, loss_v1=0, loss_v2=0, nll_loss=5.142, ntokens=1044.4, nsentences=32, sample_size=1044.4, sample_size_v1=0, sample_size_v2=0, ppl=35.3, wps=530.1, ups=0.51, wpb=1044.4, bsz=32, num_updates=1480, lr=3.36517e-05, gnorm=1.54, clip=100, loss_scale=256, train_wall=20, gb_free=15.3, wall=3631
2023-01-09 04:38:24 - progress_bar.py[line:272] - INFO: epoch 001:   1491 / 3665 loss=6.052, loss_v1=0, loss_v2=0, nll_loss=5.263, ntokens=742.1, nsentences=32, sample_size=742.1, sample_size_v1=0, sample_size_v2=0, ppl=38.4, wps=378.6, ups=0.51, wpb=742.1, bsz=32, num_updates=1490, lr=3.3879e-05, gnorm=1.646, clip=100, loss_scale=256, train_wall=20, gb_free=15.1, wall=3650
2023-01-09 04:38:44 - progress_bar.py[line:272] - INFO: epoch 001:   1501 / 3665 loss=5.949, loss_v1=0, loss_v2=0, nll_loss=5.151, ntokens=890.9, nsentences=32, sample_size=890.9, sample_size_v1=0, sample_size_v2=0, ppl=35.54, wps=452.8, ups=0.51, wpb=890.9, bsz=32, num_updates=1500, lr=3.41064e-05, gnorm=1.537, clip=100, loss_scale=256, train_wall=20, gb_free=15.5, wall=3670
2023-01-09 04:38:44 - train.py[line:445] - INFO: begin validation on "valid" subset
slice_id 0 seek offset 0
slice_id 0 seek offset 0
2023-01-09 04:43:31 - progress_bar.py[line:282] - INFO: epoch 001 | valid on 'valid' subset | loss 5.909 | loss_v1 0 | loss_v2 0 | nll_loss 5.089 | ntokens 116.839 | nsentences 4 | sample_size 116.839 | sample_size_v1 0 | sample_size_v2 0 | AP 0 | total positives 21.6729 | TP 0 | FP 7.3441 | ppl 34.04 | wps 509.9 | wpb 116.8 | bsz 4 | num_updates 1500 | best_AP 0
2023-01-09 04:43:31 - checkpoint_utils.py[line:64] - INFO: Preparing to save checkpoint for epoch 1 @ 1500 updates
2023-01-09 04:43:31 - trainer.py[line:431] - INFO: Saving checkpoint to ../../checkpoints/OFA/detection_checkpoints/10_5e-5_512/checkpoint_1_1500.pt
2023-01-09 04:43:34 - trainer.py[line:441] - INFO: Finished saving checkpoint to ../../checkpoints/OFA/detection_checkpoints/10_5e-5_512/checkpoint_1_1500.pt
2023-01-09 04:44:27 - checkpoint_utils.py[line:133] - INFO: Saved checkpoint ../../checkpoints/OFA/detection_checkpoints/10_5e-5_512/checkpoint_1_1500.pt (epoch 1 @ 1500 updates, score 0.0) (writing took 55.98700888408348 seconds)
2023-01-09 04:44:46 - progress_bar.py[line:272] - INFO: epoch 001:   1511 / 3665 loss=5.88, loss_v1=0, loss_v2=0, nll_loss=5.07, ntokens=955.7, nsentences=32, sample_size=955.7, sample_size_v1=0, sample_size_v2=0, ppl=33.59, wps=26.4, ups=0.03, wpb=955.7, bsz=32, num_updates=1510, lr=3.43338e-05, gnorm=1.429, clip=100, loss_scale=256, train_wall=19, gb_free=15.7, wall=4033
2023-01-09 04:45:06 - progress_bar.py[line:272] - INFO: epoch 001:   1521 / 3665 loss=6.064, loss_v1=0, loss_v2=0, nll_loss=5.272, ntokens=982.7, nsentences=32, sample_size=982.7, sample_size_v1=0, sample_size_v2=0, ppl=38.64, wps=504.3, ups=0.51, wpb=982.7, bsz=32, num_updates=1520, lr=3.45612e-05, gnorm=1.389, clip=100, loss_scale=256, train_wall=19, gb_free=15.5, wall=4052
2023-01-09 04:45:25 - progress_bar.py[line:272] - INFO: epoch 001:   1531 / 3665 loss=5.934, loss_v1=0, loss_v2=0, nll_loss=5.139, ntokens=813.1, nsentences=32, sample_size=813.1, sample_size_v1=0, sample_size_v2=0, ppl=35.23, wps=416.5, ups=0.51, wpb=813.1, bsz=32, num_updates=1530, lr=3.47885e-05, gnorm=1.634, clip=100, loss_scale=256, train_wall=19, gb_free=15.3, wall=4072
2023-01-09 04:45:45 - progress_bar.py[line:272] - INFO: epoch 001:   1541 / 3665 loss=5.866, loss_v1=0, loss_v2=0, nll_loss=5.054, ntokens=991.4, nsentences=32, sample_size=991.4, sample_size_v1=0, sample_size_v2=0, ppl=33.21, wps=504.5, ups=0.51, wpb=991.4, bsz=32, num_updates=1540, lr=3.50159e-05, gnorm=1.398, clip=100, loss_scale=512, train_wall=20, gb_free=15.3, wall=4091
2023-01-09 04:46:05 - progress_bar.py[line:272] - INFO: epoch 001:   1551 / 3665 loss=6.04, loss_v1=0, loss_v2=0, nll_loss=5.249, ntokens=912.5, nsentences=32, sample_size=912.5, sample_size_v1=0, sample_size_v2=0, ppl=38.02, wps=465.2, ups=0.51, wpb=912.5, bsz=32, num_updates=1550, lr=3.52433e-05, gnorm=1.497, clip=100, loss_scale=512, train_wall=20, gb_free=15.4, wall=4111
2023-01-09 04:46:24 - progress_bar.py[line:272] - INFO: epoch 001:   1561 / 3665 loss=5.972, loss_v1=0, loss_v2=0, nll_loss=5.176, ntokens=831.8, nsentences=32, sample_size=831.8, sample_size_v1=0, sample_size_v2=0, ppl=36.14, wps=424.7, ups=0.51, wpb=831.8, bsz=32, num_updates=1560, lr=3.54707e-05, gnorm=1.455, clip=100, loss_scale=512, train_wall=20, gb_free=15.5, wall=4130
2023-01-09 04:46:44 - progress_bar.py[line:272] - INFO: epoch 001:   1571 / 3665 loss=5.876, loss_v1=0, loss_v2=0, nll_loss=5.069, ntokens=991.5, nsentences=32, sample_size=991.5, sample_size_v1=0, sample_size_v2=0, ppl=33.57, wps=505.5, ups=0.51, wpb=991.5, bsz=32, num_updates=1570, lr=3.5698e-05, gnorm=1.351, clip=100, loss_scale=512, train_wall=20, gb_free=15.5, wall=4150
2023-01-09 04:47:03 - progress_bar.py[line:272] - INFO: epoch 001:   1581 / 3665 loss=5.92, loss_v1=0, loss_v2=0, nll_loss=5.113, ntokens=974, nsentences=32, sample_size=974, sample_size_v1=0, sample_size_v2=0, ppl=34.61, wps=495.1, ups=0.51, wpb=974, bsz=32, num_updates=1580, lr=3.59254e-05, gnorm=1.339, clip=100, loss_scale=512, train_wall=20, gb_free=15.3, wall=4170
2023-01-09 04:47:23 - progress_bar.py[line:272] - INFO: epoch 001:   1591 / 3665 loss=5.938, loss_v1=0, loss_v2=0, nll_loss=5.139, ntokens=823.8, nsentences=32, sample_size=823.8, sample_size_v1=0, sample_size_v2=0, ppl=35.23, wps=420.2, ups=0.51, wpb=823.8, bsz=32, num_updates=1590, lr=3.61528e-05, gnorm=1.538, clip=100, loss_scale=512, train_wall=20, gb_free=15.1, wall=4189
2023-01-09 04:47:43 - progress_bar.py[line:272] - INFO: epoch 001:   1601 / 3665 loss=5.83, loss_v1=0, loss_v2=0, nll_loss=5.014, ntokens=897.9, nsentences=32, sample_size=897.9, sample_size_v1=0, sample_size_v2=0, ppl=32.32, wps=460.6, ups=0.51, wpb=897.9, bsz=32, num_updates=1600, lr=3.63802e-05, gnorm=1.5, clip=100, loss_scale=512, train_wall=19, gb_free=15.6, wall=4209
2023-01-09 04:48:02 - progress_bar.py[line:272] - INFO: epoch 001:   1611 / 3665 loss=5.955, loss_v1=0, loss_v2=0, nll_loss=5.152, ntokens=1024.8, nsentences=32, sample_size=1024.8, sample_size_v1=0, sample_size_v2=0, ppl=35.56, wps=520.6, ups=0.51, wpb=1024.8, bsz=32, num_updates=1610, lr=3.66075e-05, gnorm=1.526, clip=100, loss_scale=512, train_wall=20, gb_free=15.7, wall=4228
2023-01-09 04:48:22 - progress_bar.py[line:272] - INFO: epoch 001:   1621 / 3665 loss=5.963, loss_v1=0, loss_v2=0, nll_loss=5.163, ntokens=808.3, nsentences=32, sample_size=808.3, sample_size_v1=0, sample_size_v2=0, ppl=35.84, wps=412.6, ups=0.51, wpb=808.3, bsz=32, num_updates=1620, lr=3.68349e-05, gnorm=1.508, clip=100, loss_scale=512, train_wall=20, gb_free=15.5, wall=4248
2023-01-09 04:48:42 - progress_bar.py[line:272] - INFO: epoch 001:   1631 / 3665 loss=5.901, loss_v1=0, loss_v2=0, nll_loss=5.095, ntokens=970.1, nsentences=32, sample_size=970.1, sample_size_v1=0, sample_size_v2=0, ppl=34.18, wps=486.7, ups=0.5, wpb=970.1, bsz=32, num_updates=1630, lr=3.70623e-05, gnorm=1.437, clip=100, loss_scale=512, train_wall=20, gb_free=15.5, wall=4268
2023-01-09 04:49:02 - progress_bar.py[line:272] - INFO: epoch 001:   1641 / 3665 loss=5.927, loss_v1=0, loss_v2=0, nll_loss=5.124, ntokens=1233, nsentences=31.8, sample_size=1233, sample_size_v1=0, sample_size_v2=0, ppl=34.88, wps=607.7, ups=0.49, wpb=1233, bsz=31.8, num_updates=1640, lr=3.72897e-05, gnorm=1.342, clip=100, loss_scale=512, train_wall=20, gb_free=15.5, wall=4288
2023-01-09 04:49:22 - progress_bar.py[line:272] - INFO: epoch 001:   1651 / 3665 loss=5.972, loss_v1=0, loss_v2=0, nll_loss=5.172, ntokens=965, nsentences=32, sample_size=965, sample_size_v1=0, sample_size_v2=0, ppl=36.05, wps=487.1, ups=0.5, wpb=965, bsz=32, num_updates=1650, lr=3.75171e-05, gnorm=1.406, clip=100, loss_scale=512, train_wall=20, gb_free=15.7, wall=4308
2023-01-09 04:49:42 - progress_bar.py[line:272] - INFO: epoch 001:   1661 / 3665 loss=5.843, loss_v1=0, loss_v2=0, nll_loss=5.029, ntokens=838.2, nsentences=32, sample_size=838.2, sample_size_v1=0, sample_size_v2=0, ppl=32.64, wps=424.2, ups=0.51, wpb=838.2, bsz=32, num_updates=1660, lr=3.77444e-05, gnorm=1.617, clip=100, loss_scale=512, train_wall=20, gb_free=15.5, wall=4328
2023-01-09 04:50:01 - progress_bar.py[line:272] - INFO: epoch 001:   1671 / 3665 loss=5.858, loss_v1=0, loss_v2=0, nll_loss=5.045, ntokens=1002.9, nsentences=32, sample_size=1002.9, sample_size_v1=0, sample_size_v2=0, ppl=33.02, wps=505, ups=0.5, wpb=1002.9, bsz=32, num_updates=1670, lr=3.79718e-05, gnorm=1.5, clip=100, loss_scale=512, train_wall=20, gb_free=14.6, wall=4348
2023-01-09 04:50:21 - progress_bar.py[line:272] - INFO: epoch 001:   1681 / 3665 loss=5.965, loss_v1=0, loss_v2=0, nll_loss=5.161, ntokens=801.8, nsentences=32, sample_size=801.8, sample_size_v1=0, sample_size_v2=0, ppl=35.79, wps=405.9, ups=0.51, wpb=801.8, bsz=32, num_updates=1680, lr=3.81992e-05, gnorm=1.58, clip=100, loss_scale=512, train_wall=20, gb_free=15.6, wall=4367
2023-01-09 04:50:41 - progress_bar.py[line:272] - INFO: epoch 001:   1691 / 3665 loss=5.891, loss_v1=0, loss_v2=0, nll_loss=5.082, ntokens=1020.7, nsentences=32, sample_size=1020.7, sample_size_v1=0, sample_size_v2=0, ppl=33.86, wps=515.4, ups=0.5, wpb=1020.7, bsz=32, num_updates=1690, lr=3.84266e-05, gnorm=1.409, clip=100, loss_scale=512, train_wall=20, gb_free=15.3, wall=4387
2023-01-09 04:50:57 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 256.0
2023-01-09 04:51:03 - progress_bar.py[line:272] - INFO: epoch 001:   1702 / 3665 loss=5.721, loss_v1=0, loss_v2=0, nll_loss=4.893, ntokens=904.3, nsentences=32, sample_size=904.3, sample_size_v1=0, sample_size_v2=0, ppl=29.7, wps=416, ups=0.46, wpb=904.3, bsz=32, num_updates=1700, lr=3.86539e-05, gnorm=1.479, clip=100, loss_scale=256, train_wall=22, gb_free=15.5, wall=4409
2023-01-09 04:51:23 - progress_bar.py[line:272] - INFO: epoch 001:   1712 / 3665 loss=5.91, loss_v1=0, loss_v2=0, nll_loss=5.104, ntokens=821.1, nsentences=32, sample_size=821.1, sample_size_v1=0, sample_size_v2=0, ppl=34.38, wps=415.4, ups=0.51, wpb=821.1, bsz=32, num_updates=1710, lr=3.88813e-05, gnorm=1.585, clip=100, loss_scale=256, train_wall=20, gb_free=15.6, wall=4429
2023-01-09 04:51:42 - progress_bar.py[line:272] - INFO: epoch 001:   1722 / 3665 loss=5.803, loss_v1=0, loss_v2=0, nll_loss=4.984, ntokens=827.3, nsentences=32, sample_size=827.3, sample_size_v1=0, sample_size_v2=0, ppl=31.65, wps=420.1, ups=0.51, wpb=827.3, bsz=32, num_updates=1720, lr=3.91087e-05, gnorm=1.463, clip=100, loss_scale=256, train_wall=20, gb_free=15.4, wall=4448
2023-01-09 04:52:02 - progress_bar.py[line:272] - INFO: epoch 001:   1732 / 3665 loss=5.761, loss_v1=0, loss_v2=0, nll_loss=4.936, ntokens=999.5, nsentences=32, sample_size=999.5, sample_size_v1=0, sample_size_v2=0, ppl=30.62, wps=504.7, ups=0.5, wpb=999.5, bsz=32, num_updates=1730, lr=3.93361e-05, gnorm=1.379, clip=100, loss_scale=256, train_wall=20, gb_free=15.2, wall=4468
2023-01-09 04:52:22 - progress_bar.py[line:272] - INFO: epoch 001:   1742 / 3665 loss=5.928, loss_v1=0, loss_v2=0, nll_loss=5.124, ntokens=935.5, nsentences=32, sample_size=935.5, sample_size_v1=0, sample_size_v2=0, ppl=34.87, wps=472.9, ups=0.51, wpb=935.5, bsz=32, num_updates=1740, lr=3.95634e-05, gnorm=1.435, clip=100, loss_scale=256, train_wall=20, gb_free=15.5, wall=4488
2023-01-09 04:52:42 - progress_bar.py[line:272] - INFO: epoch 001:   1752 / 3665 loss=5.933, loss_v1=0, loss_v2=0, nll_loss=5.131, ntokens=874.3, nsentences=32, sample_size=874.3, sample_size_v1=0, sample_size_v2=0, ppl=35.04, wps=442, ups=0.51, wpb=874.3, bsz=32, num_updates=1750, lr=3.97908e-05, gnorm=1.469, clip=100, loss_scale=256, train_wall=20, gb_free=15.3, wall=4508
2023-01-09 04:53:01 - progress_bar.py[line:272] - INFO: epoch 001:   1762 / 3665 loss=5.738, loss_v1=0, loss_v2=0, nll_loss=4.91, ntokens=1009.1, nsentences=32, sample_size=1009.1, sample_size_v1=0, sample_size_v2=0, ppl=30.06, wps=510.4, ups=0.51, wpb=1009.1, bsz=32, num_updates=1760, lr=4.00182e-05, gnorm=1.465, clip=100, loss_scale=256, train_wall=20, gb_free=15.3, wall=4528
2023-01-09 04:53:21 - progress_bar.py[line:272] - INFO: epoch 001:   1772 / 3665 loss=5.952, loss_v1=0, loss_v2=0, nll_loss=5.148, ntokens=1025.5, nsentences=32, sample_size=1025.5, sample_size_v1=0, sample_size_v2=0, ppl=35.46, wps=515.4, ups=0.5, wpb=1025.5, bsz=32, num_updates=1770, lr=4.02456e-05, gnorm=1.349, clip=100, loss_scale=256, train_wall=20, gb_free=15.3, wall=4548
2023-01-09 04:53:41 - progress_bar.py[line:272] - INFO: epoch 001:   1782 / 3665 loss=5.871, loss_v1=0, loss_v2=0, nll_loss=5.061, ntokens=841.7, nsentences=32, sample_size=841.7, sample_size_v1=0, sample_size_v2=0, ppl=33.39, wps=426.2, ups=0.51, wpb=841.7, bsz=32, num_updates=1780, lr=4.04729e-05, gnorm=1.385, clip=100, loss_scale=256, train_wall=20, gb_free=15.3, wall=4567
2023-01-09 04:54:01 - progress_bar.py[line:272] - INFO: epoch 001:   1792 / 3665 loss=5.698, loss_v1=0, loss_v2=0, nll_loss=4.868, ntokens=955.7, nsentences=32, sample_size=955.7, sample_size_v1=0, sample_size_v2=0, ppl=29.21, wps=482.8, ups=0.51, wpb=955.7, bsz=32, num_updates=1790, lr=4.07003e-05, gnorm=1.346, clip=100, loss_scale=256, train_wall=20, gb_free=15.4, wall=4587
2023-01-09 04:54:21 - progress_bar.py[line:272] - INFO: epoch 001:   1802 / 3665 loss=5.82, loss_v1=0, loss_v2=0, nll_loss=4.997, ntokens=931.6, nsentences=32, sample_size=931.6, sample_size_v1=0, sample_size_v2=0, ppl=31.93, wps=471.1, ups=0.51, wpb=931.6, bsz=32, num_updates=1800, lr=4.09277e-05, gnorm=1.472, clip=100, loss_scale=256, train_wall=20, gb_free=15.5, wall=4607
2023-01-09 04:54:40 - progress_bar.py[line:272] - INFO: epoch 001:   1812 / 3665 loss=5.837, loss_v1=0, loss_v2=0, nll_loss=5.025, ntokens=792.7, nsentences=32, sample_size=792.7, sample_size_v1=0, sample_size_v2=0, ppl=32.56, wps=400.7, ups=0.51, wpb=792.7, bsz=32, num_updates=1810, lr=4.11551e-05, gnorm=1.725, clip=100, loss_scale=256, train_wall=20, gb_free=15.4, wall=4627
2023-01-09 04:55:00 - progress_bar.py[line:272] - INFO: epoch 001:   1822 / 3665 loss=5.648, loss_v1=0, loss_v2=0, nll_loss=4.808, ntokens=959.5, nsentences=32, sample_size=959.5, sample_size_v1=0, sample_size_v2=0, ppl=28, wps=485.1, ups=0.51, wpb=959.5, bsz=32, num_updates=1820, lr=4.13824e-05, gnorm=1.389, clip=100, loss_scale=256, train_wall=20, gb_free=15.3, wall=4646
2023-01-09 04:55:20 - progress_bar.py[line:272] - INFO: epoch 001:   1832 / 3665 loss=5.879, loss_v1=0, loss_v2=0, nll_loss=5.07, ntokens=1056, nsentences=32, sample_size=1056, sample_size_v1=0, sample_size_v2=0, ppl=33.58, wps=531.6, ups=0.5, wpb=1056, bsz=32, num_updates=1830, lr=4.16098e-05, gnorm=1.502, clip=100, loss_scale=256, train_wall=20, gb_free=15.5, wall=4666
2023-01-09 04:55:40 - progress_bar.py[line:272] - INFO: epoch 001:   1842 / 3665 loss=5.822, loss_v1=0, loss_v2=0, nll_loss=5.006, ntokens=772.9, nsentences=32, sample_size=772.9, sample_size_v1=0, sample_size_v2=0, ppl=32.14, wps=392.2, ups=0.51, wpb=772.9, bsz=32, num_updates=1840, lr=4.18372e-05, gnorm=1.754, clip=100, loss_scale=256, train_wall=20, gb_free=15.5, wall=4686
2023-01-09 04:55:59 - progress_bar.py[line:272] - INFO: epoch 001:   1852 / 3665 loss=5.801, loss_v1=0, loss_v2=0, nll_loss=4.98, ntokens=874.7, nsentences=32, sample_size=874.7, sample_size_v1=0, sample_size_v2=0, ppl=31.56, wps=443.1, ups=0.51, wpb=874.7, bsz=32, num_updates=1850, lr=4.20646e-05, gnorm=1.531, clip=100, loss_scale=256, train_wall=20, gb_free=15.4, wall=4706
2023-01-09 04:56:19 - progress_bar.py[line:272] - INFO: epoch 001:   1862 / 3665 loss=5.744, loss_v1=0, loss_v2=0, nll_loss=4.918, ntokens=1025.6, nsentences=32, sample_size=1025.6, sample_size_v1=0, sample_size_v2=0, ppl=30.23, wps=518.8, ups=0.51, wpb=1025.6, bsz=32, num_updates=1860, lr=4.2292e-05, gnorm=1.526, clip=100, loss_scale=256, train_wall=20, gb_free=15.3, wall=4725
2023-01-09 04:56:39 - progress_bar.py[line:272] - INFO: epoch 001:   1872 / 3665 loss=5.852, loss_v1=0, loss_v2=0, nll_loss=5.041, ntokens=846.8, nsentences=32, sample_size=846.8, sample_size_v1=0, sample_size_v2=0, ppl=32.92, wps=428.6, ups=0.51, wpb=846.8, bsz=32, num_updates=1870, lr=4.25193e-05, gnorm=1.481, clip=100, loss_scale=256, train_wall=20, gb_free=15.5, wall=4745
2023-01-09 04:56:59 - progress_bar.py[line:272] - INFO: epoch 001:   1882 / 3665 loss=5.821, loss_v1=0, loss_v2=0, nll_loss=4.997, ntokens=1056.1, nsentences=32, sample_size=1056.1, sample_size_v1=0, sample_size_v2=0, ppl=31.94, wps=532.1, ups=0.5, wpb=1056.1, bsz=32, num_updates=1880, lr=4.27467e-05, gnorm=1.494, clip=100, loss_scale=256, train_wall=20, gb_free=15.5, wall=4765
2023-01-09 04:57:19 - progress_bar.py[line:272] - INFO: epoch 001:   1892 / 3665 loss=5.779, loss_v1=0, loss_v2=0, nll_loss=4.955, ntokens=1101.4, nsentences=32, sample_size=1101.4, sample_size_v1=0, sample_size_v2=0, ppl=31.02, wps=554.2, ups=0.5, wpb=1101.4, bsz=32, num_updates=1890, lr=4.29741e-05, gnorm=1.351, clip=100, loss_scale=256, train_wall=20, gb_free=15, wall=4785
2023-01-09 04:57:38 - progress_bar.py[line:272] - INFO: epoch 001:   1902 / 3665 loss=5.859, loss_v1=0, loss_v2=0, nll_loss=5.051, ntokens=837.1, nsentences=32, sample_size=837.1, sample_size_v1=0, sample_size_v2=0, ppl=33.15, wps=424.2, ups=0.51, wpb=837.1, bsz=32, num_updates=1900, lr=4.32015e-05, gnorm=1.533, clip=100, loss_scale=256, train_wall=20, gb_free=15.6, wall=4805
2023-01-09 04:57:58 - progress_bar.py[line:272] - INFO: epoch 001:   1912 / 3665 loss=5.829, loss_v1=0, loss_v2=0, nll_loss=5.013, ntokens=876.3, nsentences=32, sample_size=876.3, sample_size_v1=0, sample_size_v2=0, ppl=32.29, wps=443.4, ups=0.51, wpb=876.3, bsz=32, num_updates=1910, lr=4.34288e-05, gnorm=1.61, clip=100, loss_scale=256, train_wall=20, gb_free=15.6, wall=4824
2023-01-09 04:58:18 - progress_bar.py[line:272] - INFO: epoch 001:   1922 / 3665 loss=5.716, loss_v1=0, loss_v2=0, nll_loss=4.882, ntokens=873.5, nsentences=32, sample_size=873.5, sample_size_v1=0, sample_size_v2=0, ppl=29.48, wps=442.9, ups=0.51, wpb=873.5, bsz=32, num_updates=1920, lr=4.36562e-05, gnorm=1.877, clip=100, loss_scale=256, train_wall=20, gb_free=15.3, wall=4844
2023-01-09 04:58:38 - progress_bar.py[line:272] - INFO: epoch 001:   1932 / 3665 loss=5.935, loss_v1=0, loss_v2=0, nll_loss=5.129, ntokens=992.7, nsentences=32, sample_size=992.7, sample_size_v1=0, sample_size_v2=0, ppl=34.99, wps=500, ups=0.5, wpb=992.7, bsz=32, num_updates=1930, lr=4.38836e-05, gnorm=1.621, clip=100, loss_scale=256, train_wall=20, gb_free=15.4, wall=4864
2023-01-09 04:58:57 - progress_bar.py[line:272] - INFO: epoch 001:   1942 / 3665 loss=5.769, loss_v1=0, loss_v2=0, nll_loss=4.942, ntokens=747.4, nsentences=32, sample_size=747.4, sample_size_v1=0, sample_size_v2=0, ppl=30.75, wps=379.3, ups=0.51, wpb=747.4, bsz=32, num_updates=1940, lr=4.4111e-05, gnorm=1.831, clip=100, loss_scale=256, train_wall=20, gb_free=15.4, wall=4884
2023-01-09 04:59:17 - progress_bar.py[line:272] - INFO: epoch 001:   1952 / 3665 loss=5.745, loss_v1=0, loss_v2=0, nll_loss=4.917, ntokens=902.1, nsentences=32, sample_size=902.1, sample_size_v1=0, sample_size_v2=0, ppl=30.2, wps=456.2, ups=0.51, wpb=902.1, bsz=32, num_updates=1950, lr=4.43383e-05, gnorm=1.911, clip=100, loss_scale=256, train_wall=20, gb_free=15.4, wall=4904
2023-01-09 04:59:37 - progress_bar.py[line:272] - INFO: epoch 001:   1962 / 3665 loss=5.843, loss_v1=0, loss_v2=0, nll_loss=5.02, ntokens=1112.1, nsentences=32, sample_size=1112.1, sample_size_v1=0, sample_size_v2=0, ppl=32.46, wps=559.7, ups=0.5, wpb=1112.1, bsz=32, num_updates=1960, lr=4.45657e-05, gnorm=1.387, clip=100, loss_scale=256, train_wall=20, gb_free=15.6, wall=4923
2023-01-09 04:59:57 - progress_bar.py[line:272] - INFO: epoch 001:   1972 / 3665 loss=5.833, loss_v1=0, loss_v2=0, nll_loss=5.02, ntokens=921, nsentences=32, sample_size=921, sample_size_v1=0, sample_size_v2=0, ppl=32.44, wps=465.8, ups=0.51, wpb=921, bsz=32, num_updates=1970, lr=4.47931e-05, gnorm=1.513, clip=100, loss_scale=256, train_wall=20, gb_free=15.5, wall=4943
2023-01-09 05:00:17 - progress_bar.py[line:272] - INFO: epoch 001:   1982 / 3665 loss=5.717, loss_v1=0, loss_v2=0, nll_loss=4.883, ntokens=957.8, nsentences=32, sample_size=957.8, sample_size_v1=0, sample_size_v2=0, ppl=29.5, wps=484.9, ups=0.51, wpb=957.8, bsz=32, num_updates=1980, lr=4.50205e-05, gnorm=1.596, clip=100, loss_scale=256, train_wall=20, gb_free=15.6, wall=4963
2023-01-09 05:00:37 - progress_bar.py[line:272] - INFO: epoch 001:   1992 / 3665 loss=5.836, loss_v1=0, loss_v2=0, nll_loss=5.017, ntokens=1146.6, nsentences=32, sample_size=1146.6, sample_size_v1=0, sample_size_v2=0, ppl=32.39, wps=575.9, ups=0.5, wpb=1146.6, bsz=32, num_updates=1990, lr=4.52478e-05, gnorm=1.581, clip=100, loss_scale=256, train_wall=20, gb_free=15.2, wall=4983
2023-01-09 05:00:56 - progress_bar.py[line:272] - INFO: epoch 001:   2002 / 3665 loss=5.794, loss_v1=0, loss_v2=0, nll_loss=4.975, ntokens=788.2, nsentences=32, sample_size=788.2, sample_size_v1=0, sample_size_v2=0, ppl=31.45, wps=398.5, ups=0.51, wpb=788.2, bsz=32, num_updates=2000, lr=4.54752e-05, gnorm=1.73, clip=100, loss_scale=256, train_wall=20, gb_free=15, wall=5003
2023-01-09 05:00:56 - train.py[line:445] - INFO: begin validation on "valid" subset
slice_id 0 seek offset 0
slice_id 0 seek offset 0
2023-01-09 05:05:18 - progress_bar.py[line:282] - INFO: epoch 001 | valid on 'valid' subset | loss 5.753 | loss_v1 0 | loss_v2 0 | nll_loss 4.913 | ntokens 117.418 | nsentences 4 | sample_size 117.418 | sample_size_v1 0 | sample_size_v2 0 | AP 0 | total positives 21.7827 | TP 0 | FP 4.47496 | ppl 30.12 | wps 559.1 | wpb 117.4 | bsz 4 | num_updates 2000 | best_AP 0
2023-01-09 05:05:18 - checkpoint_utils.py[line:64] - INFO: Preparing to save checkpoint for epoch 1 @ 2000 updates
2023-01-09 05:05:18 - trainer.py[line:431] - INFO: Saving checkpoint to ../../checkpoints/OFA/detection_checkpoints/10_5e-5_512/checkpoint_1_2000.pt
2023-01-09 05:05:22 - trainer.py[line:441] - INFO: Finished saving checkpoint to ../../checkpoints/OFA/detection_checkpoints/10_5e-5_512/checkpoint_1_2000.pt
2023-01-09 05:06:08 - checkpoint_utils.py[line:133] - INFO: Saved checkpoint ../../checkpoints/OFA/detection_checkpoints/10_5e-5_512/checkpoint_1_2000.pt (epoch 1 @ 2000 updates, score 0.0) (writing took 49.530594874639064 seconds)
2023-01-09 05:06:27 - progress_bar.py[line:272] - INFO: epoch 001:   2012 / 3665 loss=5.716, loss_v1=0, loss_v2=0, nll_loss=4.882, ntokens=949.8, nsentences=32, sample_size=949.8, sample_size_v1=0, sample_size_v2=0, ppl=29.48, wps=28.7, ups=0.03, wpb=949.8, bsz=32, num_updates=2010, lr=4.57026e-05, gnorm=1.565, clip=100, loss_scale=256, train_wall=19, gb_free=15.4, wall=5334
2023-01-09 05:06:47 - progress_bar.py[line:272] - INFO: epoch 001:   2022 / 3665 loss=5.871, loss_v1=0, loss_v2=0, nll_loss=5.056, ntokens=1106, nsentences=32, sample_size=1106, sample_size_v1=0, sample_size_v2=0, ppl=33.26, wps=566.1, ups=0.51, wpb=1106, bsz=32, num_updates=2020, lr=4.593e-05, gnorm=1.48, clip=100, loss_scale=256, train_wall=20, gb_free=15.5, wall=5353
2023-01-09 05:07:06 - progress_bar.py[line:272] - INFO: epoch 001:   2032 / 3665 loss=5.849, loss_v1=0, loss_v2=0, nll_loss=5.037, ntokens=755.5, nsentences=32, sample_size=755.5, sample_size_v1=0, sample_size_v2=0, ppl=32.82, wps=387.4, ups=0.51, wpb=755.5, bsz=32, num_updates=2030, lr=4.61573e-05, gnorm=1.885, clip=100, loss_scale=256, train_wall=19, gb_free=15.7, wall=5373
2023-01-09 05:07:26 - progress_bar.py[line:272] - INFO: epoch 001:   2042 / 3665 loss=5.681, loss_v1=0, loss_v2=0, nll_loss=4.843, ntokens=809.4, nsentences=32, sample_size=809.4, sample_size_v1=0, sample_size_v2=0, ppl=28.7, wps=414.2, ups=0.51, wpb=809.4, bsz=32, num_updates=2040, lr=4.63847e-05, gnorm=1.888, clip=100, loss_scale=256, train_wall=20, gb_free=15.2, wall=5392
2023-01-09 05:07:46 - progress_bar.py[line:272] - INFO: epoch 001:   2052 / 3665 loss=5.645, loss_v1=0, loss_v2=0, nll_loss=4.804, ntokens=946.7, nsentences=32, sample_size=946.7, sample_size_v1=0, sample_size_v2=0, ppl=27.93, wps=483.9, ups=0.51, wpb=946.7, bsz=32, num_updates=2050, lr=4.66121e-05, gnorm=1.692, clip=100, loss_scale=256, train_wall=20, gb_free=15.5, wall=5412
2023-01-09 05:08:05 - progress_bar.py[line:272] - INFO: epoch 001:   2062 / 3665 loss=5.832, loss_v1=0, loss_v2=0, nll_loss=5.011, ntokens=834.8, nsentences=32, sample_size=834.8, sample_size_v1=0, sample_size_v2=0, ppl=32.24, wps=425.6, ups=0.51, wpb=834.8, bsz=32, num_updates=2060, lr=4.68395e-05, gnorm=1.924, clip=100, loss_scale=256, train_wall=20, gb_free=15.5, wall=5431
2023-01-09 05:08:25 - progress_bar.py[line:272] - INFO: epoch 001:   2072 / 3665 loss=5.746, loss_v1=0, loss_v2=0, nll_loss=4.926, ntokens=952.5, nsentences=32, sample_size=952.5, sample_size_v1=0, sample_size_v2=0, ppl=30.4, wps=486.1, ups=0.51, wpb=952.5, bsz=32, num_updates=2070, lr=4.70668e-05, gnorm=1.691, clip=100, loss_scale=256, train_wall=20, gb_free=15.3, wall=5451
2023-01-09 05:08:44 - progress_bar.py[line:272] - INFO: epoch 001:   2082 / 3665 loss=5.7, loss_v1=0, loss_v2=0, nll_loss=4.861, ntokens=954.6, nsentences=32, sample_size=954.6, sample_size_v1=0, sample_size_v2=0, ppl=29.07, wps=486.6, ups=0.51, wpb=954.6, bsz=32, num_updates=2080, lr=4.72942e-05, gnorm=1.749, clip=100, loss_scale=256, train_wall=20, gb_free=15.6, wall=5471
2023-01-09 05:09:04 - progress_bar.py[line:272] - INFO: epoch 001:   2092 / 3665 loss=5.963, loss_v1=0, loss_v2=0, nll_loss=5.157, ntokens=963, nsentences=32, sample_size=963, sample_size_v1=0, sample_size_v2=0, ppl=35.67, wps=488.7, ups=0.51, wpb=963, bsz=32, num_updates=2090, lr=4.75216e-05, gnorm=1.752, clip=100, loss_scale=256, train_wall=20, gb_free=15.3, wall=5490
2023-01-09 05:09:24 - progress_bar.py[line:272] - INFO: epoch 001:   2102 / 3665 loss=5.714, loss_v1=0, loss_v2=0, nll_loss=4.888, ntokens=943.8, nsentences=32, sample_size=943.8, sample_size_v1=0, sample_size_v2=0, ppl=29.62, wps=480, ups=0.51, wpb=943.8, bsz=32, num_updates=2100, lr=4.7749e-05, gnorm=1.66, clip=100, loss_scale=256, train_wall=20, gb_free=15.3, wall=5510
2023-01-09 05:09:43 - progress_bar.py[line:272] - INFO: epoch 001:   2112 / 3665 loss=5.662, loss_v1=0, loss_v2=0, nll_loss=4.821, ntokens=985.6, nsentences=32, sample_size=985.6, sample_size_v1=0, sample_size_v2=0, ppl=28.27, wps=501.6, ups=0.51, wpb=985.6, bsz=32, num_updates=2110, lr=4.79764e-05, gnorm=1.579, clip=100, loss_scale=256, train_wall=20, gb_free=15.5, wall=5530
2023-01-09 05:10:03 - progress_bar.py[line:272] - INFO: epoch 001:   2122 / 3665 loss=5.806, loss_v1=0, loss_v2=0, nll_loss=4.98, ntokens=1042.1, nsentences=32, sample_size=1042.1, sample_size_v1=0, sample_size_v2=0, ppl=31.55, wps=528.7, ups=0.51, wpb=1042.1, bsz=32, num_updates=2120, lr=4.82037e-05, gnorm=1.711, clip=100, loss_scale=256, train_wall=20, gb_free=15.5, wall=5549
2023-01-09 05:10:23 - progress_bar.py[line:272] - INFO: epoch 001:   2132 / 3665 loss=5.721, loss_v1=0, loss_v2=0, nll_loss=4.893, ntokens=833.3, nsentences=32, sample_size=833.3, sample_size_v1=0, sample_size_v2=0, ppl=29.71, wps=424.5, ups=0.51, wpb=833.3, bsz=32, num_updates=2130, lr=4.84311e-05, gnorm=1.732, clip=100, loss_scale=256, train_wall=20, gb_free=15.4, wall=5569
2023-01-09 05:10:42 - progress_bar.py[line:272] - INFO: epoch 001:   2142 / 3665 loss=5.571, loss_v1=0, loss_v2=0, nll_loss=4.723, ntokens=903.3, nsentences=32, sample_size=903.3, sample_size_v1=0, sample_size_v2=0, ppl=26.41, wps=460.5, ups=0.51, wpb=903.3, bsz=32, num_updates=2140, lr=4.86585e-05, gnorm=1.658, clip=100, loss_scale=256, train_wall=20, gb_free=15.5, wall=5589
2023-01-09 05:11:02 - progress_bar.py[line:272] - INFO: epoch 001:   2152 / 3665 loss=5.745, loss_v1=0, loss_v2=0, nll_loss=4.912, ntokens=1029.6, nsentences=32, sample_size=1029.6, sample_size_v1=0, sample_size_v2=0, ppl=30.1, wps=521.9, ups=0.51, wpb=1029.6, bsz=32, num_updates=2150, lr=4.88859e-05, gnorm=1.664, clip=100, loss_scale=256, train_wall=20, gb_free=15.1, wall=5608
2023-01-09 05:11:22 - progress_bar.py[line:272] - INFO: epoch 001:   2162 / 3665 loss=5.722, loss_v1=0, loss_v2=0, nll_loss=4.891, ntokens=858.4, nsentences=32, sample_size=858.4, sample_size_v1=0, sample_size_v2=0, ppl=29.68, wps=437.6, ups=0.51, wpb=858.4, bsz=32, num_updates=2160, lr=4.91132e-05, gnorm=1.867, clip=100, loss_scale=256, train_wall=20, gb_free=15.2, wall=5628
2023-01-09 05:11:41 - progress_bar.py[line:272] - INFO: epoch 001:   2172 / 3665 loss=5.613, loss_v1=0, loss_v2=0, nll_loss=4.774, ntokens=841.9, nsentences=32, sample_size=841.9, sample_size_v1=0, sample_size_v2=0, ppl=27.37, wps=430.3, ups=0.51, wpb=841.9, bsz=32, num_updates=2170, lr=4.93406e-05, gnorm=1.847, clip=100, loss_scale=256, train_wall=20, gb_free=15.4, wall=5648
2023-01-09 05:12:01 - progress_bar.py[line:272] - INFO: epoch 001:   2182 / 3665 loss=5.789, loss_v1=0, loss_v2=0, nll_loss=4.963, ntokens=1049.1, nsentences=32, sample_size=1049.1, sample_size_v1=0, sample_size_v2=0, ppl=31.2, wps=532.6, ups=0.51, wpb=1049.1, bsz=32, num_updates=2180, lr=4.9568e-05, gnorm=1.697, clip=100, loss_scale=256, train_wall=20, gb_free=15.3, wall=5667
2023-01-09 05:12:21 - progress_bar.py[line:272] - INFO: epoch 001:   2192 / 3665 loss=5.765, loss_v1=0, loss_v2=0, nll_loss=4.933, ntokens=869.5, nsentences=32, sample_size=869.5, sample_size_v1=0, sample_size_v2=0, ppl=30.56, wps=442.3, ups=0.51, wpb=869.5, bsz=32, num_updates=2190, lr=4.97954e-05, gnorm=1.787, clip=100, loss_scale=256, train_wall=20, gb_free=14.8, wall=5687
2023-01-09 05:12:41 - progress_bar.py[line:272] - INFO: epoch 001:   2202 / 3665 loss=5.708, loss_v1=0, loss_v2=0, nll_loss=4.88, ntokens=970.9, nsentences=32, sample_size=970.9, sample_size_v1=0, sample_size_v2=0, ppl=29.44, wps=479.4, ups=0.49, wpb=970.9, bsz=32, num_updates=2200, lr=4.99985e-05, gnorm=1.698, clip=100, loss_scale=256, train_wall=20, gb_free=15.5, wall=5707
2023-01-09 05:13:01 - progress_bar.py[line:272] - INFO: epoch 001:   2212 / 3665 loss=5.812, loss_v1=0, loss_v2=0, nll_loss=4.986, ntokens=1049.5, nsentences=32, sample_size=1049.5, sample_size_v1=0, sample_size_v2=0, ppl=31.69, wps=513, ups=0.49, wpb=1049.5, bsz=32, num_updates=2210, lr=4.9984e-05, gnorm=1.751, clip=100, loss_scale=512, train_wall=20, gb_free=15.5, wall=5728
2023-01-09 05:13:21 - progress_bar.py[line:272] - INFO: epoch 001:   2222 / 3665 loss=5.663, loss_v1=0, loss_v2=0, nll_loss=4.825, ntokens=779, nsentences=32, sample_size=779, sample_size_v1=0, sample_size_v2=0, ppl=28.34, wps=388.9, ups=0.5, wpb=779, bsz=32, num_updates=2220, lr=4.99695e-05, gnorm=1.766, clip=100, loss_scale=512, train_wall=20, gb_free=15.4, wall=5748
2023-01-09 05:13:41 - progress_bar.py[line:272] - INFO: epoch 001:   2232 / 3665 loss=5.708, loss_v1=0, loss_v2=0, nll_loss=4.877, ntokens=997, nsentences=32, sample_size=997, sample_size_v1=0, sample_size_v2=0, ppl=29.38, wps=504.6, ups=0.51, wpb=997, bsz=32, num_updates=2230, lr=4.9955e-05, gnorm=1.687, clip=100, loss_scale=512, train_wall=20, gb_free=15.2, wall=5767
2023-01-09 05:14:01 - progress_bar.py[line:272] - INFO: epoch 001:   2242 / 3665 loss=5.638, loss_v1=0, loss_v2=0, nll_loss=4.799, ntokens=879.9, nsentences=32, sample_size=879.9, sample_size_v1=0, sample_size_v2=0, ppl=27.83, wps=449.6, ups=0.51, wpb=879.9, bsz=32, num_updates=2240, lr=4.99405e-05, gnorm=1.678, clip=100, loss_scale=512, train_wall=20, gb_free=15.4, wall=5787
2023-01-09 05:14:20 - progress_bar.py[line:272] - INFO: epoch 001:   2252 / 3665 loss=5.735, loss_v1=0, loss_v2=0, nll_loss=4.909, ntokens=859.3, nsentences=32, sample_size=859.3, sample_size_v1=0, sample_size_v2=0, ppl=30.03, wps=438.4, ups=0.51, wpb=859.3, bsz=32, num_updates=2250, lr=4.9926e-05, gnorm=1.631, clip=100, loss_scale=512, train_wall=20, gb_free=15.2, wall=5807
2023-01-09 05:14:40 - progress_bar.py[line:272] - INFO: epoch 001:   2262 / 3665 loss=5.714, loss_v1=0, loss_v2=0, nll_loss=4.877, ntokens=981.7, nsentences=32, sample_size=981.7, sample_size_v1=0, sample_size_v2=0, ppl=29.39, wps=499.5, ups=0.51, wpb=981.7, bsz=32, num_updates=2260, lr=4.99115e-05, gnorm=1.767, clip=100, loss_scale=512, train_wall=20, gb_free=15.4, wall=5826
2023-01-09 05:15:00 - progress_bar.py[line:272] - INFO: epoch 001:   2272 / 3665 loss=5.583, loss_v1=0, loss_v2=0, nll_loss=4.737, ntokens=945.8, nsentences=32, sample_size=945.8, sample_size_v1=0, sample_size_v2=0, ppl=26.67, wps=481.3, ups=0.51, wpb=945.8, bsz=32, num_updates=2270, lr=4.9897e-05, gnorm=1.735, clip=100, loss_scale=512, train_wall=20, gb_free=15.5, wall=5846
2023-01-09 05:15:19 - progress_bar.py[line:272] - INFO: epoch 001:   2282 / 3665 loss=5.823, loss_v1=0, loss_v2=0, nll_loss=4.999, ntokens=962.6, nsentences=32, sample_size=962.6, sample_size_v1=0, sample_size_v2=0, ppl=31.98, wps=488.4, ups=0.51, wpb=962.6, bsz=32, num_updates=2280, lr=4.98824e-05, gnorm=1.768, clip=100, loss_scale=512, train_wall=20, gb_free=15.1, wall=5866
2023-01-09 05:15:39 - progress_bar.py[line:272] - INFO: epoch 001:   2292 / 3665 loss=5.749, loss_v1=0, loss_v2=0, nll_loss=4.921, ntokens=987.8, nsentences=32, sample_size=987.8, sample_size_v1=0, sample_size_v2=0, ppl=30.3, wps=501.1, ups=0.51, wpb=987.8, bsz=32, num_updates=2290, lr=4.98679e-05, gnorm=1.774, clip=100, loss_scale=512, train_wall=20, gb_free=15.4, wall=5885
2023-01-09 05:15:59 - progress_bar.py[line:272] - INFO: epoch 001:   2302 / 3665 loss=5.587, loss_v1=0, loss_v2=0, nll_loss=4.735, ntokens=916.6, nsentences=32, sample_size=916.6, sample_size_v1=0, sample_size_v2=0, ppl=26.63, wps=466.6, ups=0.51, wpb=916.6, bsz=32, num_updates=2300, lr=4.98534e-05, gnorm=1.669, clip=100, loss_scale=512, train_wall=20, gb_free=15.7, wall=5905
2023-01-09 05:16:18 - progress_bar.py[line:272] - INFO: epoch 001:   2312 / 3665 loss=5.675, loss_v1=0, loss_v2=0, nll_loss=4.838, ntokens=889.1, nsentences=32, sample_size=889.1, sample_size_v1=0, sample_size_v2=0, ppl=28.6, wps=452.4, ups=0.51, wpb=889.1, bsz=32, num_updates=2310, lr=4.98389e-05, gnorm=1.805, clip=100, loss_scale=512, train_wall=20, gb_free=15.2, wall=5925
2023-01-09 05:16:38 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 256.0
2023-01-09 05:16:40 - progress_bar.py[line:272] - INFO: epoch 001:   2323 / 3665 loss=5.689, loss_v1=0, loss_v2=0, nll_loss=4.858, ntokens=821, nsentences=32, sample_size=821, sample_size_v1=0, sample_size_v2=0, ppl=28.99, wps=380.6, ups=0.46, wpb=821, bsz=32, num_updates=2320, lr=4.98244e-05, gnorm=1.76, clip=100, loss_scale=256, train_wall=22, gb_free=15.2, wall=5946
2023-01-09 05:17:00 - progress_bar.py[line:272] - INFO: epoch 001:   2333 / 3665 loss=5.662, loss_v1=0, loss_v2=0, nll_loss=4.822, ntokens=1075.4, nsentences=32, sample_size=1075.4, sample_size_v1=0, sample_size_v2=0, ppl=28.28, wps=545.5, ups=0.51, wpb=1075.4, bsz=32, num_updates=2330, lr=4.98099e-05, gnorm=1.596, clip=100, loss_scale=256, train_wall=20, gb_free=15.1, wall=5966
2023-01-09 05:17:19 - progress_bar.py[line:272] - INFO: epoch 001:   2343 / 3665 loss=5.758, loss_v1=0, loss_v2=0, nll_loss=4.927, ntokens=1099.4, nsentences=32, sample_size=1099.4, sample_size_v1=0, sample_size_v2=0, ppl=30.43, wps=555.1, ups=0.5, wpb=1099.4, bsz=32, num_updates=2340, lr=4.97954e-05, gnorm=1.496, clip=100, loss_scale=256, train_wall=20, gb_free=15.4, wall=5986
2023-01-09 05:17:39 - progress_bar.py[line:272] - INFO: epoch 001:   2353 / 3665 loss=5.73, loss_v1=0, loss_v2=0, nll_loss=4.903, ntokens=1006.9, nsentences=32, sample_size=1006.9, sample_size_v1=0, sample_size_v2=0, ppl=29.91, wps=511.4, ups=0.51, wpb=1006.9, bsz=32, num_updates=2350, lr=4.97808e-05, gnorm=1.494, clip=100, loss_scale=256, train_wall=20, gb_free=15.1, wall=6005
2023-01-09 05:17:59 - progress_bar.py[line:272] - INFO: epoch 001:   2363 / 3665 loss=5.565, loss_v1=0, loss_v2=0, nll_loss=4.712, ntokens=958.5, nsentences=32, sample_size=958.5, sample_size_v1=0, sample_size_v2=0, ppl=26.2, wps=487.8, ups=0.51, wpb=958.5, bsz=32, num_updates=2360, lr=4.97663e-05, gnorm=1.629, clip=100, loss_scale=256, train_wall=20, gb_free=15.2, wall=6025
2023-01-09 05:18:18 - progress_bar.py[line:272] - INFO: epoch 001:   2373 / 3665 loss=5.688, loss_v1=0, loss_v2=0, nll_loss=4.851, ntokens=964.5, nsentences=32, sample_size=964.5, sample_size_v1=0, sample_size_v2=0, ppl=28.85, wps=489.8, ups=0.51, wpb=964.5, bsz=32, num_updates=2370, lr=4.97518e-05, gnorm=1.905, clip=100, loss_scale=256, train_wall=20, gb_free=15.5, wall=6045
2023-01-09 05:18:38 - progress_bar.py[line:272] - INFO: epoch 001:   2383 / 3665 loss=5.734, loss_v1=0, loss_v2=0, nll_loss=4.904, ntokens=773.7, nsentences=32, sample_size=773.7, sample_size_v1=0, sample_size_v2=0, ppl=29.94, wps=394.6, ups=0.51, wpb=773.7, bsz=32, num_updates=2380, lr=4.97373e-05, gnorm=2.092, clip=100, loss_scale=256, train_wall=20, gb_free=15.3, wall=6064
2023-01-09 05:18:58 - progress_bar.py[line:272] - INFO: epoch 001:   2393 / 3665 loss=5.588, loss_v1=0, loss_v2=0, nll_loss=4.736, ntokens=953.3, nsentences=32, sample_size=953.3, sample_size_v1=0, sample_size_v2=0, ppl=26.65, wps=485.3, ups=0.51, wpb=953.3, bsz=32, num_updates=2390, lr=4.97228e-05, gnorm=1.64, clip=100, loss_scale=256, train_wall=20, gb_free=15.4, wall=6084
2023-01-09 05:19:17 - progress_bar.py[line:272] - INFO: epoch 001:   2403 / 3665 loss=5.634, loss_v1=0, loss_v2=0, nll_loss=4.793, ntokens=1029.2, nsentences=32, sample_size=1029.2, sample_size_v1=0, sample_size_v2=0, ppl=27.72, wps=521.1, ups=0.51, wpb=1029.2, bsz=32, num_updates=2400, lr=4.97083e-05, gnorm=1.558, clip=100, loss_scale=256, train_wall=20, gb_free=15.5, wall=6104
2023-01-09 05:19:37 - progress_bar.py[line:272] - INFO: epoch 001:   2413 / 3665 loss=5.697, loss_v1=0, loss_v2=0, nll_loss=4.864, ntokens=706.2, nsentences=32, sample_size=706.2, sample_size_v1=0, sample_size_v2=0, ppl=29.11, wps=359.7, ups=0.51, wpb=706.2, bsz=32, num_updates=2410, lr=4.96938e-05, gnorm=2.396, clip=100, loss_scale=256, train_wall=20, gb_free=15.3, wall=6123
2023-01-09 05:19:57 - progress_bar.py[line:272] - INFO: epoch 001:   2423 / 3665 loss=5.547, loss_v1=0, loss_v2=0, nll_loss=4.696, ntokens=819.3, nsentences=32, sample_size=819.3, sample_size_v1=0, sample_size_v2=0, ppl=25.92, wps=416, ups=0.51, wpb=819.3, bsz=32, num_updates=2420, lr=4.96793e-05, gnorm=1.858, clip=100, loss_scale=256, train_wall=20, gb_free=15.7, wall=6143
2023-01-09 05:20:17 - progress_bar.py[line:272] - INFO: epoch 001:   2433 / 3665 loss=5.441, loss_v1=0, loss_v2=0, nll_loss=4.578, ntokens=947.9, nsentences=32, sample_size=947.9, sample_size_v1=0, sample_size_v2=0, ppl=23.88, wps=480.1, ups=0.51, wpb=947.9, bsz=32, num_updates=2430, lr=4.96647e-05, gnorm=1.689, clip=100, loss_scale=256, train_wall=20, gb_free=15.2, wall=6163
2023-01-09 05:20:36 - progress_bar.py[line:272] - INFO: epoch 001:   2443 / 3665 loss=5.627, loss_v1=0, loss_v2=0, nll_loss=4.783, ntokens=693.9, nsentences=32, sample_size=693.9, sample_size_v1=0, sample_size_v2=0, ppl=27.53, wps=352.5, ups=0.51, wpb=693.9, bsz=32, num_updates=2440, lr=4.96502e-05, gnorm=1.99, clip=100, loss_scale=256, train_wall=20, gb_free=15.5, wall=6182
2023-01-09 05:20:56 - progress_bar.py[line:272] - INFO: epoch 001:   2453 / 3665 loss=5.647, loss_v1=0, loss_v2=0, nll_loss=4.807, ntokens=948.1, nsentences=32, sample_size=948.1, sample_size_v1=0, sample_size_v2=0, ppl=27.99, wps=479.8, ups=0.51, wpb=948.1, bsz=32, num_updates=2450, lr=4.96357e-05, gnorm=1.66, clip=100, loss_scale=256, train_wall=20, gb_free=15.5, wall=6202
2023-01-09 05:21:16 - progress_bar.py[line:272] - INFO: epoch 001:   2463 / 3665 loss=5.594, loss_v1=0, loss_v2=0, nll_loss=4.746, ntokens=936.1, nsentences=32, sample_size=936.1, sample_size_v1=0, sample_size_v2=0, ppl=26.83, wps=474.1, ups=0.51, wpb=936.1, bsz=32, num_updates=2460, lr=4.96212e-05, gnorm=1.545, clip=100, loss_scale=256, train_wall=20, gb_free=15.5, wall=6222
2023-01-09 05:21:35 - progress_bar.py[line:272] - INFO: epoch 001:   2473 / 3665 loss=5.744, loss_v1=0, loss_v2=0, nll_loss=4.91, ntokens=922.8, nsentences=32, sample_size=922.8, sample_size_v1=0, sample_size_v2=0, ppl=30.06, wps=467.5, ups=0.51, wpb=922.8, bsz=32, num_updates=2470, lr=4.96067e-05, gnorm=1.666, clip=100, loss_scale=256, train_wall=20, gb_free=15.2, wall=6242
2023-01-09 05:21:55 - progress_bar.py[line:272] - INFO: epoch 001:   2483 / 3665 loss=5.664, loss_v1=0, loss_v2=0, nll_loss=4.826, ntokens=792.5, nsentences=32, sample_size=792.5, sample_size_v1=0, sample_size_v2=0, ppl=28.37, wps=403.2, ups=0.51, wpb=792.5, bsz=32, num_updates=2480, lr=4.95922e-05, gnorm=2.44, clip=100, loss_scale=256, train_wall=20, gb_free=15.3, wall=6261
2023-01-09 05:22:15 - progress_bar.py[line:272] - INFO: epoch 001:   2493 / 3665 loss=5.652, loss_v1=0, loss_v2=0, nll_loss=4.812, ntokens=981, nsentences=32, sample_size=981, sample_size_v1=0, sample_size_v2=0, ppl=28.09, wps=496.9, ups=0.51, wpb=981, bsz=32, num_updates=2490, lr=4.95777e-05, gnorm=1.602, clip=100, loss_scale=256, train_wall=20, gb_free=15.1, wall=6281
2023-01-09 05:22:35 - progress_bar.py[line:272] - INFO: epoch 001:   2503 / 3665 loss=5.724, loss_v1=0, loss_v2=0, nll_loss=4.894, ntokens=1062.8, nsentences=32, sample_size=1062.8, sample_size_v1=0, sample_size_v2=0, ppl=29.74, wps=535.2, ups=0.5, wpb=1062.8, bsz=32, num_updates=2500, lr=4.95631e-05, gnorm=1.562, clip=100, loss_scale=256, train_wall=20, gb_free=14.8, wall=6301
2023-01-09 05:22:35 - train.py[line:445] - INFO: begin validation on "valid" subset
slice_id 0 seek offset 0
slice_id 0 seek offset 0
2023-01-09 05:27:24 - progress_bar.py[line:282] - INFO: epoch 001 | valid on 'valid' subset | loss 5.641 | loss_v1 0 | loss_v2 0 | nll_loss 4.784 | ntokens 116.837 | nsentences 4 | sample_size 116.837 | sample_size_v1 0 | sample_size_v2 0 | AP 0 | total positives 21.6737 | TP 0 | FP 7.24394 | ppl 27.55 | wps 506.3 | wpb 116.8 | bsz 4 | num_updates 2500 | best_AP 0
2023-01-09 05:27:24 - checkpoint_utils.py[line:64] - INFO: Preparing to save checkpoint for epoch 1 @ 2500 updates
2023-01-09 05:27:24 - trainer.py[line:431] - INFO: Saving checkpoint to ../../checkpoints/OFA/detection_checkpoints/10_5e-5_512/checkpoint_1_2500.pt
2023-01-09 05:27:28 - trainer.py[line:441] - INFO: Finished saving checkpoint to ../../checkpoints/OFA/detection_checkpoints/10_5e-5_512/checkpoint_1_2500.pt
2023-01-09 05:28:20 - checkpoint_utils.py[line:133] - INFO: Saved checkpoint ../../checkpoints/OFA/detection_checkpoints/10_5e-5_512/checkpoint_1_2500.pt (epoch 1 @ 2500 updates, score 0.0) (writing took 55.89446717966348 seconds)
2023-01-09 05:28:39 - progress_bar.py[line:272] - INFO: epoch 001:   2513 / 3665 loss=5.631, loss_v1=0, loss_v2=0, nll_loss=4.785, ntokens=719.2, nsentences=32, sample_size=719.2, sample_size_v1=0, sample_size_v2=0, ppl=27.57, wps=19.7, ups=0.03, wpb=719.2, bsz=32, num_updates=2510, lr=4.95486e-05, gnorm=1.867, clip=100, loss_scale=256, train_wall=19, gb_free=15.7, wall=6665
2023-01-09 05:28:58 - progress_bar.py[line:272] - INFO: epoch 001:   2523 / 3665 loss=5.584, loss_v1=0, loss_v2=0, nll_loss=4.735, ntokens=1000.4, nsentences=32, sample_size=1000.4, sample_size_v1=0, sample_size_v2=0, ppl=26.63, wps=512.8, ups=0.51, wpb=1000.4, bsz=32, num_updates=2520, lr=4.95341e-05, gnorm=1.53, clip=100, loss_scale=256, train_wall=19, gb_free=15.5, wall=6685
2023-01-09 05:29:18 - progress_bar.py[line:272] - INFO: epoch 001:   2533 / 3665 loss=5.825, loss_v1=0, loss_v2=0, nll_loss=5.003, ntokens=1013.7, nsentences=32, sample_size=1013.7, sample_size_v1=0, sample_size_v2=0, ppl=32.07, wps=516.2, ups=0.51, wpb=1013.7, bsz=32, num_updates=2530, lr=4.95196e-05, gnorm=1.647, clip=100, loss_scale=256, train_wall=20, gb_free=15.3, wall=6704
2023-01-09 05:29:38 - progress_bar.py[line:272] - INFO: epoch 001:   2543 / 3665 loss=5.608, loss_v1=0, loss_v2=0, nll_loss=4.766, ntokens=849.8, nsentences=32, sample_size=849.8, sample_size_v1=0, sample_size_v2=0, ppl=27.21, wps=434.4, ups=0.51, wpb=849.8, bsz=32, num_updates=2540, lr=4.95051e-05, gnorm=1.816, clip=100, loss_scale=256, train_wall=20, gb_free=15.6, wall=6724
2023-01-09 05:29:57 - progress_bar.py[line:272] - INFO: epoch 001:   2553 / 3665 loss=5.572, loss_v1=0, loss_v2=0, nll_loss=4.719, ntokens=1038.9, nsentences=32, sample_size=1038.9, sample_size_v1=0, sample_size_v2=0, ppl=26.34, wps=529.2, ups=0.51, wpb=1038.9, bsz=32, num_updates=2550, lr=4.94906e-05, gnorm=1.88, clip=100, loss_scale=256, train_wall=20, gb_free=15.1, wall=6744
2023-01-09 05:30:17 - progress_bar.py[line:272] - INFO: epoch 001:   2563 / 3665 loss=5.716, loss_v1=0, loss_v2=0, nll_loss=4.881, ntokens=1071.9, nsentences=32, sample_size=1071.9, sample_size_v1=0, sample_size_v2=0, ppl=29.47, wps=545.4, ups=0.51, wpb=1071.9, bsz=32, num_updates=2560, lr=4.94761e-05, gnorm=1.562, clip=100, loss_scale=256, train_wall=20, gb_free=15.5, wall=6763
2023-01-09 05:30:36 - progress_bar.py[line:272] - INFO: epoch 001:   2573 / 3665 loss=5.622, loss_v1=0, loss_v2=0, nll_loss=4.783, ntokens=723.1, nsentences=32, sample_size=723.1, sample_size_v1=0, sample_size_v2=0, ppl=27.53, wps=369.8, ups=0.51, wpb=723.1, bsz=32, num_updates=2570, lr=4.94616e-05, gnorm=2.071, clip=100, loss_scale=256, train_wall=20, gb_free=14.9, wall=6783
2023-01-09 05:30:42 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 128.0
2023-01-09 05:30:58 - progress_bar.py[line:272] - INFO: epoch 001:   2584 / 3665 loss=5.58, loss_v1=0, loss_v2=0, nll_loss=4.728, ntokens=888.7, nsentences=32, sample_size=888.7, sample_size_v1=0, sample_size_v2=0, ppl=26.5, wps=409, ups=0.46, wpb=888.7, bsz=32, num_updates=2580, lr=4.9447e-05, gnorm=1.748, clip=100, loss_scale=128, train_wall=22, gb_free=14.8, wall=6804
2023-01-09 05:31:18 - progress_bar.py[line:272] - INFO: epoch 001:   2594 / 3665 loss=5.629, loss_v1=0, loss_v2=0, nll_loss=4.783, ntokens=929.7, nsentences=32, sample_size=929.7, sample_size_v1=0, sample_size_v2=0, ppl=27.53, wps=473.5, ups=0.51, wpb=929.7, bsz=32, num_updates=2590, lr=4.94325e-05, gnorm=1.604, clip=100, loss_scale=128, train_wall=20, gb_free=15.4, wall=6824
2023-01-09 05:31:37 - progress_bar.py[line:272] - INFO: epoch 001:   2604 / 3665 loss=5.663, loss_v1=0, loss_v2=0, nll_loss=4.826, ntokens=793.4, nsentences=32, sample_size=793.4, sample_size_v1=0, sample_size_v2=0, ppl=28.37, wps=404.8, ups=0.51, wpb=793.4, bsz=32, num_updates=2600, lr=4.9418e-05, gnorm=1.84, clip=100, loss_scale=128, train_wall=20, gb_free=15.2, wall=6844
2023-01-09 05:31:57 - progress_bar.py[line:272] - INFO: epoch 001:   2614 / 3665 loss=5.601, loss_v1=0, loss_v2=0, nll_loss=4.752, ntokens=1003.1, nsentences=32, sample_size=1003.1, sample_size_v1=0, sample_size_v2=0, ppl=26.94, wps=511.3, ups=0.51, wpb=1003.1, bsz=32, num_updates=2610, lr=4.94035e-05, gnorm=1.609, clip=100, loss_scale=128, train_wall=20, gb_free=15.4, wall=6863
2023-01-09 05:32:17 - progress_bar.py[line:272] - INFO: epoch 001:   2624 / 3665 loss=5.673, loss_v1=0, loss_v2=0, nll_loss=4.835, ntokens=1151.3, nsentences=32, sample_size=1151.3, sample_size_v1=0, sample_size_v2=0, ppl=28.54, wps=584.2, ups=0.51, wpb=1151.3, bsz=32, num_updates=2620, lr=4.9389e-05, gnorm=1.416, clip=100, loss_scale=128, train_wall=20, gb_free=15.1, wall=6883
2023-01-09 05:32:36 - progress_bar.py[line:272] - INFO: epoch 001:   2634 / 3665 loss=5.659, loss_v1=0, loss_v2=0, nll_loss=4.823, ntokens=825.7, nsentences=32, sample_size=825.7, sample_size_v1=0, sample_size_v2=0, ppl=28.3, wps=421.6, ups=0.51, wpb=825.7, bsz=32, num_updates=2630, lr=4.93745e-05, gnorm=1.819, clip=100, loss_scale=128, train_wall=20, gb_free=15.1, wall=6903
2023-01-09 05:32:56 - progress_bar.py[line:272] - INFO: epoch 001:   2644 / 3665 loss=5.605, loss_v1=0, loss_v2=0, nll_loss=4.756, ntokens=946.2, nsentences=32, sample_size=946.2, sample_size_v1=0, sample_size_v2=0, ppl=27.01, wps=482, ups=0.51, wpb=946.2, bsz=32, num_updates=2640, lr=4.936e-05, gnorm=1.802, clip=100, loss_scale=128, train_wall=20, gb_free=15.4, wall=6922
2023-01-09 05:33:16 - progress_bar.py[line:272] - INFO: epoch 001:   2654 / 3665 loss=5.623, loss_v1=0, loss_v2=0, nll_loss=4.773, ntokens=1127.8, nsentences=32, sample_size=1127.8, sample_size_v1=0, sample_size_v2=0, ppl=27.35, wps=571.3, ups=0.51, wpb=1127.8, bsz=32, num_updates=2650, lr=4.93454e-05, gnorm=1.558, clip=100, loss_scale=128, train_wall=20, gb_free=14.6, wall=6942
2023-01-09 05:33:35 - progress_bar.py[line:272] - INFO: epoch 001:   2664 / 3665 loss=5.753, loss_v1=0, loss_v2=0, nll_loss=4.927, ntokens=888.7, nsentences=32, sample_size=888.7, sample_size_v1=0, sample_size_v2=0, ppl=30.42, wps=452.1, ups=0.51, wpb=888.7, bsz=32, num_updates=2660, lr=4.93309e-05, gnorm=1.793, clip=100, loss_scale=128, train_wall=20, gb_free=15.4, wall=6962
2023-01-09 05:33:55 - progress_bar.py[line:272] - INFO: epoch 001:   2674 / 3665 loss=5.648, loss_v1=0, loss_v2=0, nll_loss=4.811, ntokens=828.3, nsentences=32, sample_size=828.3, sample_size_v1=0, sample_size_v2=0, ppl=28.06, wps=421.9, ups=0.51, wpb=828.3, bsz=32, num_updates=2670, lr=4.93164e-05, gnorm=2.059, clip=100, loss_scale=128, train_wall=20, gb_free=15.2, wall=6981
2023-01-09 05:34:15 - progress_bar.py[line:272] - INFO: epoch 001:   2684 / 3665 loss=5.565, loss_v1=0, loss_v2=0, nll_loss=4.708, ntokens=964.8, nsentences=32, sample_size=964.8, sample_size_v1=0, sample_size_v2=0, ppl=26.14, wps=490.1, ups=0.51, wpb=964.8, bsz=32, num_updates=2680, lr=4.93019e-05, gnorm=1.53, clip=100, loss_scale=128, train_wall=20, gb_free=15.5, wall=7001
2023-01-09 05:34:35 - progress_bar.py[line:272] - INFO: epoch 001:   2694 / 3665 loss=5.62, loss_v1=0, loss_v2=0, nll_loss=4.776, ntokens=962, nsentences=32, sample_size=962, sample_size_v1=0, sample_size_v2=0, ppl=27.39, wps=480.1, ups=0.5, wpb=962, bsz=32, num_updates=2690, lr=4.92874e-05, gnorm=1.78, clip=100, loss_scale=128, train_wall=20, gb_free=15.3, wall=7021
2023-01-09 05:34:55 - progress_bar.py[line:272] - INFO: epoch 001:   2704 / 3665 loss=5.574, loss_v1=0, loss_v2=0, nll_loss=4.733, ntokens=765.8, nsentences=32, sample_size=765.8, sample_size_v1=0, sample_size_v2=0, ppl=26.6, wps=382, ups=0.5, wpb=765.8, bsz=32, num_updates=2700, lr=4.92729e-05, gnorm=2.129, clip=100, loss_scale=128, train_wall=20, gb_free=15.5, wall=7041
2023-01-09 05:35:15 - progress_bar.py[line:272] - INFO: epoch 001:   2714 / 3665 loss=5.546, loss_v1=0, loss_v2=0, nll_loss=4.681, ntokens=1095.2, nsentences=32, sample_size=1095.2, sample_size_v1=0, sample_size_v2=0, ppl=25.66, wps=543.4, ups=0.5, wpb=1095.2, bsz=32, num_updates=2710, lr=4.92584e-05, gnorm=1.568, clip=100, loss_scale=128, train_wall=20, gb_free=15.5, wall=7061
2023-01-09 05:35:35 - progress_bar.py[line:272] - INFO: epoch 001:   2724 / 3665 loss=5.742, loss_v1=0, loss_v2=0, nll_loss=4.909, ntokens=1012.9, nsentences=32, sample_size=1012.9, sample_size_v1=0, sample_size_v2=0, ppl=30.04, wps=503.2, ups=0.5, wpb=1012.9, bsz=32, num_updates=2720, lr=4.92439e-05, gnorm=1.67, clip=100, loss_scale=128, train_wall=20, gb_free=15.4, wall=7081
2023-01-09 05:35:55 - progress_bar.py[line:272] - INFO: epoch 001:   2734 / 3665 loss=5.653, loss_v1=0, loss_v2=0, nll_loss=4.822, ntokens=830.2, nsentences=32, sample_size=830.2, sample_size_v1=0, sample_size_v2=0, ppl=28.29, wps=417.5, ups=0.5, wpb=830.2, bsz=32, num_updates=2730, lr=4.92293e-05, gnorm=1.897, clip=100, loss_scale=128, train_wall=20, gb_free=15.6, wall=7101
2023-01-09 05:36:14 - progress_bar.py[line:272] - INFO: epoch 001:   2744 / 3665 loss=5.586, loss_v1=0, loss_v2=0, nll_loss=4.734, ntokens=932.3, nsentences=32, sample_size=932.3, sample_size_v1=0, sample_size_v2=0, ppl=26.61, wps=476.6, ups=0.51, wpb=932.3, bsz=32, num_updates=2740, lr=4.92148e-05, gnorm=1.871, clip=100, loss_scale=128, train_wall=20, gb_free=15.3, wall=7121
2023-01-09 05:36:34 - progress_bar.py[line:272] - INFO: epoch 001:   2754 / 3665 loss=5.686, loss_v1=0, loss_v2=0, nll_loss=4.843, ntokens=944, nsentences=32, sample_size=944, sample_size_v1=0, sample_size_v2=0, ppl=28.69, wps=480.6, ups=0.51, wpb=944, bsz=32, num_updates=2750, lr=4.92003e-05, gnorm=1.796, clip=100, loss_scale=128, train_wall=20, gb_free=15.4, wall=7140
2023-01-09 05:36:54 - progress_bar.py[line:272] - INFO: epoch 001:   2764 / 3665 loss=5.665, loss_v1=0, loss_v2=0, nll_loss=4.832, ntokens=824.8, nsentences=32, sample_size=824.8, sample_size_v1=0, sample_size_v2=0, ppl=28.48, wps=420.7, ups=0.51, wpb=824.8, bsz=32, num_updates=2760, lr=4.91858e-05, gnorm=1.934, clip=100, loss_scale=128, train_wall=20, gb_free=15.1, wall=7160
2023-01-09 05:37:13 - progress_bar.py[line:272] - INFO: epoch 001:   2774 / 3665 loss=5.546, loss_v1=0, loss_v2=0, nll_loss=4.695, ntokens=967.9, nsentences=32, sample_size=967.9, sample_size_v1=0, sample_size_v2=0, ppl=25.9, wps=491.7, ups=0.51, wpb=967.9, bsz=32, num_updates=2770, lr=4.91713e-05, gnorm=1.778, clip=100, loss_scale=128, train_wall=20, gb_free=15.4, wall=7180
2023-01-09 05:37:33 - progress_bar.py[line:272] - INFO: epoch 001:   2784 / 3665 loss=5.674, loss_v1=0, loss_v2=0, nll_loss=4.827, ntokens=1044.3, nsentences=32, sample_size=1044.3, sample_size_v1=0, sample_size_v2=0, ppl=28.39, wps=531.3, ups=0.51, wpb=1044.3, bsz=32, num_updates=2780, lr=4.91568e-05, gnorm=1.565, clip=100, loss_scale=128, train_wall=20, gb_free=15.3, wall=7199
2023-01-09 05:37:53 - progress_bar.py[line:272] - INFO: epoch 001:   2794 / 3665 loss=5.587, loss_v1=0, loss_v2=0, nll_loss=4.741, ntokens=789.9, nsentences=32, sample_size=789.9, sample_size_v1=0, sample_size_v2=0, ppl=26.75, wps=403.1, ups=0.51, wpb=789.9, bsz=32, num_updates=2790, lr=4.91423e-05, gnorm=1.844, clip=100, loss_scale=128, train_wall=20, gb_free=15.6, wall=7219
2023-01-09 05:38:12 - progress_bar.py[line:272] - INFO: epoch 001:   2804 / 3665 loss=5.586, loss_v1=0, loss_v2=0, nll_loss=4.743, ntokens=986.7, nsentences=32, sample_size=986.7, sample_size_v1=0, sample_size_v2=0, ppl=26.78, wps=500.4, ups=0.51, wpb=986.7, bsz=32, num_updates=2800, lr=4.91277e-05, gnorm=1.757, clip=100, loss_scale=128, train_wall=20, gb_free=15.4, wall=7239
2023-01-09 05:38:32 - progress_bar.py[line:272] - INFO: epoch 001:   2814 / 3665 loss=5.618, loss_v1=0, loss_v2=0, nll_loss=4.762, ntokens=1120.9, nsentences=32, sample_size=1120.9, sample_size_v1=0, sample_size_v2=0, ppl=27.13, wps=567.5, ups=0.51, wpb=1120.9, bsz=32, num_updates=2810, lr=4.91132e-05, gnorm=1.511, clip=100, loss_scale=128, train_wall=20, gb_free=15.4, wall=7258
2023-01-09 05:38:52 - progress_bar.py[line:272] - INFO: epoch 001:   2824 / 3665 loss=5.61, loss_v1=0, loss_v2=0, nll_loss=4.768, ntokens=748.3, nsentences=32, sample_size=748.3, sample_size_v1=0, sample_size_v2=0, ppl=27.24, wps=382.6, ups=0.51, wpb=748.3, bsz=32, num_updates=2820, lr=4.90987e-05, gnorm=1.839, clip=100, loss_scale=128, train_wall=20, gb_free=15.6, wall=7278
2023-01-09 05:39:11 - progress_bar.py[line:272] - INFO: epoch 001:   2834 / 3665 loss=5.648, loss_v1=0, loss_v2=0, nll_loss=4.811, ntokens=983.5, nsentences=32, sample_size=983.5, sample_size_v1=0, sample_size_v2=0, ppl=28.07, wps=499.4, ups=0.51, wpb=983.5, bsz=32, num_updates=2830, lr=4.90842e-05, gnorm=1.623, clip=100, loss_scale=128, train_wall=20, gb_free=15.5, wall=7298
2023-01-09 05:39:31 - progress_bar.py[line:272] - INFO: epoch 001:   2844 / 3665 loss=5.574, loss_v1=0, loss_v2=0, nll_loss=4.718, ntokens=1015.7, nsentences=32, sample_size=1015.7, sample_size_v1=0, sample_size_v2=0, ppl=26.33, wps=514.1, ups=0.51, wpb=1015.7, bsz=32, num_updates=2840, lr=4.90697e-05, gnorm=1.8, clip=100, loss_scale=128, train_wall=20, gb_free=15.7, wall=7317
2023-01-09 05:39:51 - progress_bar.py[line:272] - INFO: epoch 001:   2854 / 3665 loss=5.723, loss_v1=0, loss_v2=0, nll_loss=4.887, ntokens=843.1, nsentences=32, sample_size=843.1, sample_size_v1=0, sample_size_v2=0, ppl=29.58, wps=425, ups=0.5, wpb=843.1, bsz=32, num_updates=2850, lr=4.90552e-05, gnorm=1.678, clip=100, loss_scale=128, train_wall=20, gb_free=15.3, wall=7337
2023-01-09 05:40:11 - progress_bar.py[line:272] - INFO: epoch 001:   2864 / 3665 loss=5.542, loss_v1=0, loss_v2=0, nll_loss=4.696, ntokens=739.3, nsentences=32, sample_size=739.3, sample_size_v1=0, sample_size_v2=0, ppl=25.92, wps=373.9, ups=0.51, wpb=739.3, bsz=32, num_updates=2860, lr=4.90407e-05, gnorm=1.824, clip=100, loss_scale=128, train_wall=20, gb_free=15.3, wall=7357
2023-01-09 05:40:31 - progress_bar.py[line:272] - INFO: epoch 001:   2874 / 3665 loss=5.536, loss_v1=0, loss_v2=0, nll_loss=4.683, ntokens=959.8, nsentences=32, sample_size=959.8, sample_size_v1=0, sample_size_v2=0, ppl=25.68, wps=483.7, ups=0.5, wpb=959.8, bsz=32, num_updates=2870, lr=4.90262e-05, gnorm=1.767, clip=100, loss_scale=128, train_wall=20, gb_free=15.7, wall=7377
2023-01-09 05:40:50 - progress_bar.py[line:272] - INFO: epoch 001:   2884 / 3665 loss=5.653, loss_v1=0, loss_v2=0, nll_loss=4.8, ntokens=903.1, nsentences=32, sample_size=903.1, sample_size_v1=0, sample_size_v2=0, ppl=27.86, wps=454.5, ups=0.5, wpb=903.1, bsz=32, num_updates=2880, lr=4.90116e-05, gnorm=1.955, clip=100, loss_scale=128, train_wall=20, gb_free=15.3, wall=7397
2023-01-09 05:41:10 - progress_bar.py[line:272] - INFO: epoch 001:   2894 / 3665 loss=5.558, loss_v1=0, loss_v2=0, nll_loss=4.712, ntokens=763.9, nsentences=32, sample_size=763.9, sample_size_v1=0, sample_size_v2=0, ppl=26.21, wps=385.5, ups=0.5, wpb=763.9, bsz=32, num_updates=2890, lr=4.89971e-05, gnorm=1.958, clip=100, loss_scale=128, train_wall=20, gb_free=15.5, wall=7417
2023-01-09 05:41:30 - progress_bar.py[line:272] - INFO: epoch 001:   2904 / 3665 loss=5.612, loss_v1=0, loss_v2=0, nll_loss=4.769, ntokens=1031.5, nsentences=32, sample_size=1031.5, sample_size_v1=0, sample_size_v2=0, ppl=27.27, wps=519.5, ups=0.5, wpb=1031.5, bsz=32, num_updates=2900, lr=4.89826e-05, gnorm=1.565, clip=100, loss_scale=128, train_wall=20, gb_free=15.2, wall=7436
2023-01-09 05:41:50 - progress_bar.py[line:272] - INFO: epoch 001:   2914 / 3665 loss=5.637, loss_v1=0, loss_v2=0, nll_loss=4.782, ntokens=1020.1, nsentences=32, sample_size=1020.1, sample_size_v1=0, sample_size_v2=0, ppl=27.51, wps=512.4, ups=0.5, wpb=1020.1, bsz=32, num_updates=2910, lr=4.89681e-05, gnorm=1.613, clip=100, loss_scale=128, train_wall=20, gb_free=15.4, wall=7456
2023-01-09 05:42:10 - progress_bar.py[line:272] - INFO: epoch 001:   2924 / 3665 loss=5.692, loss_v1=0, loss_v2=0, nll_loss=4.856, ntokens=843.8, nsentences=32, sample_size=843.8, sample_size_v1=0, sample_size_v2=0, ppl=28.95, wps=425.2, ups=0.5, wpb=843.8, bsz=32, num_updates=2920, lr=4.89536e-05, gnorm=1.679, clip=100, loss_scale=128, train_wall=20, gb_free=15.2, wall=7476
2023-01-09 05:42:30 - progress_bar.py[line:272] - INFO: epoch 001:   2934 / 3665 loss=5.442, loss_v1=0, loss_v2=0, nll_loss=4.583, ntokens=865.2, nsentences=32, sample_size=865.2, sample_size_v1=0, sample_size_v2=0, ppl=23.97, wps=437.2, ups=0.51, wpb=865.2, bsz=32, num_updates=2930, lr=4.89391e-05, gnorm=1.989, clip=100, loss_scale=128, train_wall=20, gb_free=15.7, wall=7496
2023-01-09 05:42:50 - progress_bar.py[line:272] - INFO: epoch 001:   2944 / 3665 loss=5.725, loss_v1=0, loss_v2=0, nll_loss=4.883, ntokens=1238.4, nsentences=32, sample_size=1238.4, sample_size_v1=0, sample_size_v2=0, ppl=29.51, wps=618.2, ups=0.5, wpb=1238.4, bsz=32, num_updates=2940, lr=4.89246e-05, gnorm=1.47, clip=100, loss_scale=128, train_wall=20, gb_free=15.2, wall=7516
2023-01-09 05:43:10 - progress_bar.py[line:272] - INFO: epoch 001:   2954 / 3665 loss=5.623, loss_v1=0, loss_v2=0, nll_loss=4.784, ntokens=861.4, nsentences=32, sample_size=861.4, sample_size_v1=0, sample_size_v2=0, ppl=27.55, wps=433.9, ups=0.5, wpb=861.4, bsz=32, num_updates=2950, lr=4.891e-05, gnorm=1.847, clip=100, loss_scale=128, train_wall=20, gb_free=15.3, wall=7536
2023-01-09 05:43:29 - progress_bar.py[line:272] - INFO: epoch 001:   2964 / 3665 loss=5.572, loss_v1=0, loss_v2=0, nll_loss=4.722, ntokens=989.7, nsentences=32, sample_size=989.7, sample_size_v1=0, sample_size_v2=0, ppl=26.4, wps=498.5, ups=0.5, wpb=989.7, bsz=32, num_updates=2960, lr=4.88955e-05, gnorm=1.544, clip=100, loss_scale=128, train_wall=20, gb_free=15.6, wall=7556
2023-01-09 05:43:49 - progress_bar.py[line:272] - INFO: epoch 001:   2974 / 3665 loss=5.642, loss_v1=0, loss_v2=0, nll_loss=4.795, ntokens=1027.4, nsentences=32, sample_size=1027.4, sample_size_v1=0, sample_size_v2=0, ppl=27.75, wps=519.4, ups=0.51, wpb=1027.4, bsz=32, num_updates=2970, lr=4.8881e-05, gnorm=1.494, clip=100, loss_scale=128, train_wall=20, gb_free=15.4, wall=7576
2023-01-09 05:44:09 - progress_bar.py[line:272] - INFO: epoch 001:   2984 / 3665 loss=5.556, loss_v1=0, loss_v2=0, nll_loss=4.707, ntokens=878.1, nsentences=32, sample_size=878.1, sample_size_v1=0, sample_size_v2=0, ppl=26.12, wps=445.2, ups=0.51, wpb=878.1, bsz=32, num_updates=2980, lr=4.88665e-05, gnorm=1.771, clip=100, loss_scale=128, train_wall=20, gb_free=15.6, wall=7595
2023-01-09 05:44:29 - progress_bar.py[line:272] - INFO: epoch 001:   2994 / 3665 loss=5.582, loss_v1=0, loss_v2=0, nll_loss=4.733, ntokens=998.9, nsentences=32, sample_size=998.9, sample_size_v1=0, sample_size_v2=0, ppl=26.59, wps=504.6, ups=0.51, wpb=998.9, bsz=32, num_updates=2990, lr=4.8852e-05, gnorm=2.072, clip=100, loss_scale=128, train_wall=20, gb_free=15.3, wall=7615
2023-01-09 05:44:49 - progress_bar.py[line:272] - INFO: epoch 001:   3004 / 3665 loss=5.48, loss_v1=0, loss_v2=0, nll_loss=4.613, ntokens=1009.9, nsentences=32, sample_size=1009.9, sample_size_v1=0, sample_size_v2=0, ppl=24.47, wps=510.5, ups=0.51, wpb=1009.9, bsz=32, num_updates=3000, lr=4.88375e-05, gnorm=1.648, clip=100, loss_scale=128, train_wall=20, gb_free=14.9, wall=7635
2023-01-09 05:44:49 - train.py[line:445] - INFO: begin validation on "valid" subset
slice_id 0 seek offset 0
slice_id 0 seek offset 0
2023-01-09 05:49:37 - progress_bar.py[line:282] - INFO: epoch 001 | valid on 'valid' subset | loss 5.572 | loss_v1 0 | loss_v2 0 | nll_loss 4.699 | ntokens 117.16 | nsentences 4 | sample_size 117.16 | sample_size_v1 0 | sample_size_v2 0 | AP 0 | total positives 21.7367 | TP 0 | FP 7.70194 | ppl 25.98 | wps 508.5 | wpb 117.2 | bsz 4 | num_updates 3000 | best_AP 0
2023-01-09 05:49:37 - checkpoint_utils.py[line:64] - INFO: Preparing to save checkpoint for epoch 1 @ 3000 updates
2023-01-09 05:49:37 - trainer.py[line:431] - INFO: Saving checkpoint to ../../checkpoints/OFA/detection_checkpoints/10_5e-5_512/checkpoint_1_3000.pt
2023-01-09 05:49:41 - trainer.py[line:441] - INFO: Finished saving checkpoint to ../../checkpoints/OFA/detection_checkpoints/10_5e-5_512/checkpoint_1_3000.pt
2023-01-09 05:50:27 - checkpoint_utils.py[line:133] - INFO: Saved checkpoint ../../checkpoints/OFA/detection_checkpoints/10_5e-5_512/checkpoint_1_3000.pt (epoch 1 @ 3000 updates, score 0.0) (writing took 49.9539893520996 seconds)
2023-01-09 05:50:47 - progress_bar.py[line:272] - INFO: epoch 001:   3014 / 3665 loss=5.519, loss_v1=0, loss_v2=0, nll_loss=4.663, ntokens=713.2, nsentences=32, sample_size=713.2, sample_size_v1=0, sample_size_v2=0, ppl=25.33, wps=19.9, ups=0.03, wpb=713.2, bsz=32, num_updates=3010, lr=4.8823e-05, gnorm=1.996, clip=100, loss_scale=128, train_wall=19, gb_free=15.3, wall=7993
2023-01-09 05:51:06 - progress_bar.py[line:272] - INFO: epoch 001:   3024 / 3665 loss=5.595, loss_v1=0, loss_v2=0, nll_loss=4.75, ntokens=958.9, nsentences=32, sample_size=958.9, sample_size_v1=0, sample_size_v2=0, ppl=26.91, wps=492.5, ups=0.51, wpb=958.9, bsz=32, num_updates=3020, lr=4.88085e-05, gnorm=1.877, clip=100, loss_scale=128, train_wall=19, gb_free=15.5, wall=8013
2023-01-09 05:51:26 - progress_bar.py[line:272] - INFO: epoch 001:   3034 / 3665 loss=5.479, loss_v1=0, loss_v2=0, nll_loss=4.613, ntokens=1023.3, nsentences=32, sample_size=1023.3, sample_size_v1=0, sample_size_v2=0, ppl=24.47, wps=522.2, ups=0.51, wpb=1023.3, bsz=32, num_updates=3030, lr=4.87939e-05, gnorm=1.498, clip=100, loss_scale=128, train_wall=20, gb_free=15.5, wall=8032
2023-01-09 05:51:45 - progress_bar.py[line:272] - INFO: epoch 001:   3044 / 3665 loss=5.695, loss_v1=0, loss_v2=0, nll_loss=4.859, ntokens=929.6, nsentences=32, sample_size=929.6, sample_size_v1=0, sample_size_v2=0, ppl=29.02, wps=473.8, ups=0.51, wpb=929.6, bsz=32, num_updates=3040, lr=4.87794e-05, gnorm=1.674, clip=100, loss_scale=128, train_wall=20, gb_free=15.3, wall=8052
2023-01-09 05:52:05 - progress_bar.py[line:272] - INFO: epoch 001:   3054 / 3665 loss=5.505, loss_v1=0, loss_v2=0, nll_loss=4.647, ntokens=861.9, nsentences=32, sample_size=861.9, sample_size_v1=0, sample_size_v2=0, ppl=25.05, wps=440.6, ups=0.51, wpb=861.9, bsz=32, num_updates=3050, lr=4.87649e-05, gnorm=1.7, clip=100, loss_scale=128, train_wall=20, gb_free=15.5, wall=8071
2023-01-09 05:52:25 - progress_bar.py[line:272] - INFO: epoch 001:   3064 / 3665 loss=5.489, loss_v1=0, loss_v2=0, nll_loss=4.627, ntokens=1005.9, nsentences=32, sample_size=1005.9, sample_size_v1=0, sample_size_v2=0, ppl=24.71, wps=513.6, ups=0.51, wpb=1005.9, bsz=32, num_updates=3060, lr=4.87504e-05, gnorm=1.711, clip=100, loss_scale=128, train_wall=20, gb_free=15.2, wall=8091
2023-01-09 05:52:44 - progress_bar.py[line:272] - INFO: epoch 001:   3074 / 3665 loss=5.656, loss_v1=0, loss_v2=0, nll_loss=4.812, ntokens=1014.8, nsentences=32, sample_size=1014.8, sample_size_v1=0, sample_size_v2=0, ppl=28.09, wps=516.6, ups=0.51, wpb=1014.8, bsz=32, num_updates=3070, lr=4.87359e-05, gnorm=1.693, clip=100, loss_scale=128, train_wall=20, gb_free=15.4, wall=8111
2023-01-09 05:53:04 - progress_bar.py[line:272] - INFO: epoch 001:   3084 / 3665 loss=5.578, loss_v1=0, loss_v2=0, nll_loss=4.73, ntokens=889.9, nsentences=32, sample_size=889.9, sample_size_v1=0, sample_size_v2=0, ppl=26.54, wps=453.7, ups=0.51, wpb=889.9, bsz=32, num_updates=3080, lr=4.87214e-05, gnorm=1.817, clip=100, loss_scale=128, train_wall=20, gb_free=15.5, wall=8130
2023-01-09 05:53:24 - progress_bar.py[line:272] - INFO: epoch 001:   3094 / 3665 loss=5.543, loss_v1=0, loss_v2=0, nll_loss=4.69, ntokens=970.8, nsentences=32, sample_size=970.8, sample_size_v1=0, sample_size_v2=0, ppl=25.81, wps=493.7, ups=0.51, wpb=970.8, bsz=32, num_updates=3090, lr=4.87069e-05, gnorm=1.601, clip=100, loss_scale=256, train_wall=20, gb_free=15.2, wall=8150
2023-01-09 05:53:43 - progress_bar.py[line:272] - INFO: epoch 001:   3104 / 3665 loss=5.689, loss_v1=0, loss_v2=0, nll_loss=4.846, ntokens=1087, nsentences=32, sample_size=1087, sample_size_v1=0, sample_size_v2=0, ppl=28.76, wps=549.7, ups=0.51, wpb=1087, bsz=32, num_updates=3100, lr=4.86923e-05, gnorm=1.367, clip=100, loss_scale=256, train_wall=20, gb_free=15.1, wall=8170
2023-01-09 05:54:03 - progress_bar.py[line:272] - INFO: epoch 001:   3114 / 3665 loss=5.648, loss_v1=0, loss_v2=0, nll_loss=4.812, ntokens=812.2, nsentences=32, sample_size=812.2, sample_size_v1=0, sample_size_v2=0, ppl=28.09, wps=414.5, ups=0.51, wpb=812.2, bsz=32, num_updates=3110, lr=4.86778e-05, gnorm=1.852, clip=100, loss_scale=256, train_wall=20, gb_free=15.5, wall=8189
2023-01-09 05:54:23 - progress_bar.py[line:272] - INFO: epoch 001:   3124 / 3665 loss=5.642, loss_v1=0, loss_v2=0, nll_loss=4.799, ntokens=1040.3, nsentences=32, sample_size=1040.3, sample_size_v1=0, sample_size_v2=0, ppl=27.83, wps=527.4, ups=0.51, wpb=1040.3, bsz=32, num_updates=3120, lr=4.86633e-05, gnorm=1.627, clip=100, loss_scale=256, train_wall=20, gb_free=15.1, wall=8209
2023-01-09 05:54:42 - progress_bar.py[line:272] - INFO: epoch 001:   3134 / 3665 loss=5.617, loss_v1=0, loss_v2=0, nll_loss=4.766, ntokens=1036, nsentences=32, sample_size=1036, sample_size_v1=0, sample_size_v2=0, ppl=27.21, wps=525.4, ups=0.51, wpb=1036, bsz=32, num_updates=3130, lr=4.86488e-05, gnorm=1.475, clip=100, loss_scale=256, train_wall=20, gb_free=15.5, wall=8229
2023-01-09 05:55:02 - progress_bar.py[line:272] - INFO: epoch 001:   3144 / 3665 loss=5.607, loss_v1=0, loss_v2=0, nll_loss=4.766, ntokens=794.2, nsentences=32, sample_size=794.2, sample_size_v1=0, sample_size_v2=0, ppl=27.22, wps=404.4, ups=0.51, wpb=794.2, bsz=32, num_updates=3140, lr=4.86343e-05, gnorm=1.986, clip=100, loss_scale=256, train_wall=20, gb_free=15.1, wall=8248
2023-01-09 05:55:22 - progress_bar.py[line:272] - INFO: epoch 001:   3154 / 3665 loss=5.553, loss_v1=0, loss_v2=0, nll_loss=4.702, ntokens=927, nsentences=32, sample_size=927, sample_size_v1=0, sample_size_v2=0, ppl=26.02, wps=471.6, ups=0.51, wpb=927, bsz=32, num_updates=3150, lr=4.86198e-05, gnorm=1.932, clip=100, loss_scale=256, train_wall=20, gb_free=15.6, wall=8268
2023-01-09 05:55:41 - progress_bar.py[line:272] - INFO: epoch 001:   3164 / 3665 loss=5.611, loss_v1=0, loss_v2=0, nll_loss=4.759, ntokens=1024.1, nsentences=32, sample_size=1024.1, sample_size_v1=0, sample_size_v2=0, ppl=27.08, wps=519.6, ups=0.51, wpb=1024.1, bsz=32, num_updates=3160, lr=4.86053e-05, gnorm=1.781, clip=100, loss_scale=256, train_wall=20, gb_free=15, wall=8288
2023-01-09 05:56:01 - progress_bar.py[line:272] - INFO: epoch 001:   3174 / 3665 loss=5.557, loss_v1=0, loss_v2=0, nll_loss=4.702, ntokens=762.5, nsentences=32, sample_size=762.5, sample_size_v1=0, sample_size_v2=0, ppl=26.03, wps=388.6, ups=0.51, wpb=762.5, bsz=32, num_updates=3170, lr=4.85908e-05, gnorm=1.838, clip=100, loss_scale=256, train_wall=20, gb_free=15.6, wall=8307
2023-01-09 05:56:22 - progress_bar.py[line:272] - INFO: epoch 001:   3184 / 3665 loss=5.522, loss_v1=0, loss_v2=0, nll_loss=4.673, ntokens=870.1, nsentences=32, sample_size=870.1, sample_size_v1=0, sample_size_v2=0, ppl=25.52, wps=419.3, ups=0.48, wpb=870.1, bsz=32, num_updates=3180, lr=4.85762e-05, gnorm=1.955, clip=100, loss_scale=256, train_wall=21, gb_free=15.4, wall=8328
2023-01-09 05:56:43 - progress_bar.py[line:272] - INFO: epoch 001:   3194 / 3665 loss=5.497, loss_v1=0, loss_v2=0, nll_loss=4.635, ntokens=1024.3, nsentences=32, sample_size=1024.3, sample_size_v1=0, sample_size_v2=0, ppl=24.84, wps=491.2, ups=0.48, wpb=1024.3, bsz=32, num_updates=3190, lr=4.85617e-05, gnorm=1.681, clip=100, loss_scale=256, train_wall=21, gb_free=14.9, wall=8349
2023-01-09 05:57:02 - progress_bar.py[line:272] - INFO: epoch 001:   3204 / 3665 loss=5.628, loss_v1=0, loss_v2=0, nll_loss=4.777, ntokens=777.1, nsentences=32, sample_size=777.1, sample_size_v1=0, sample_size_v2=0, ppl=27.42, wps=396.3, ups=0.51, wpb=777.1, bsz=32, num_updates=3200, lr=4.85472e-05, gnorm=1.749, clip=100, loss_scale=256, train_wall=20, gb_free=15.5, wall=8368
2023-01-09 05:57:22 - progress_bar.py[line:272] - INFO: epoch 001:   3214 / 3665 loss=5.526, loss_v1=0, loss_v2=0, nll_loss=4.676, ntokens=962.4, nsentences=32, sample_size=962.4, sample_size_v1=0, sample_size_v2=0, ppl=25.57, wps=492, ups=0.51, wpb=962.4, bsz=32, num_updates=3210, lr=4.85327e-05, gnorm=1.628, clip=100, loss_scale=256, train_wall=20, gb_free=15.2, wall=8388
2023-01-09 05:57:41 - progress_bar.py[line:272] - INFO: epoch 001:   3224 / 3665 loss=5.586, loss_v1=0, loss_v2=0, nll_loss=4.731, ntokens=1290, nsentences=32, sample_size=1290, sample_size_v1=0, sample_size_v2=0, ppl=26.56, wps=654.9, ups=0.51, wpb=1290, bsz=32, num_updates=3220, lr=4.85182e-05, gnorm=1.355, clip=100, loss_scale=256, train_wall=20, gb_free=15.4, wall=8408
2023-01-09 05:58:01 - progress_bar.py[line:272] - INFO: epoch 001:   3234 / 3665 loss=5.618, loss_v1=0, loss_v2=0, nll_loss=4.766, ntokens=842.1, nsentences=32, sample_size=842.1, sample_size_v1=0, sample_size_v2=0, ppl=27.21, wps=430, ups=0.51, wpb=842.1, bsz=32, num_updates=3230, lr=4.85037e-05, gnorm=1.786, clip=100, loss_scale=256, train_wall=20, gb_free=15.7, wall=8427
2023-01-09 05:58:21 - progress_bar.py[line:272] - INFO: epoch 001:   3244 / 3665 loss=5.491, loss_v1=0, loss_v2=0, nll_loss=4.637, ntokens=812.7, nsentences=32, sample_size=812.7, sample_size_v1=0, sample_size_v2=0, ppl=24.89, wps=414.7, ups=0.51, wpb=812.7, bsz=32, num_updates=3240, lr=4.84892e-05, gnorm=1.97, clip=100, loss_scale=256, train_wall=20, gb_free=15.2, wall=8447
2023-01-09 05:58:40 - progress_bar.py[line:272] - INFO: epoch 001:   3254 / 3665 loss=5.538, loss_v1=0, loss_v2=0, nll_loss=4.678, ntokens=1044.9, nsentences=32, sample_size=1044.9, sample_size_v1=0, sample_size_v2=0, ppl=25.59, wps=531, ups=0.51, wpb=1044.9, bsz=32, num_updates=3250, lr=4.84746e-05, gnorm=1.63, clip=100, loss_scale=256, train_wall=20, gb_free=15.6, wall=8467
2023-01-09 05:59:00 - progress_bar.py[line:272] - INFO: epoch 001:   3264 / 3665 loss=5.629, loss_v1=0, loss_v2=0, nll_loss=4.781, ntokens=1000.9, nsentences=32, sample_size=1000.9, sample_size_v1=0, sample_size_v2=0, ppl=27.5, wps=507.6, ups=0.51, wpb=1000.9, bsz=32, num_updates=3260, lr=4.84601e-05, gnorm=1.58, clip=100, loss_scale=256, train_wall=20, gb_free=15.2, wall=8486
2023-01-09 05:59:20 - progress_bar.py[line:272] - INFO: epoch 001:   3274 / 3665 loss=5.613, loss_v1=0, loss_v2=0, nll_loss=4.773, ntokens=810.1, nsentences=32, sample_size=810.1, sample_size_v1=0, sample_size_v2=0, ppl=27.33, wps=411.2, ups=0.51, wpb=810.1, bsz=32, num_updates=3270, lr=4.84456e-05, gnorm=1.768, clip=100, loss_scale=256, train_wall=20, gb_free=15.6, wall=8506
2023-01-09 05:59:39 - progress_bar.py[line:272] - INFO: epoch 001:   3284 / 3665 loss=5.542, loss_v1=0, loss_v2=0, nll_loss=4.689, ntokens=965.5, nsentences=32, sample_size=965.5, sample_size_v1=0, sample_size_v2=0, ppl=25.79, wps=492.3, ups=0.51, wpb=965.5, bsz=32, num_updates=3280, lr=4.84311e-05, gnorm=1.681, clip=100, loss_scale=256, train_wall=20, gb_free=15.6, wall=8526
2023-01-09 05:59:59 - progress_bar.py[line:272] - INFO: epoch 001:   3294 / 3665 loss=5.583, loss_v1=0, loss_v2=0, nll_loss=4.722, ntokens=969, nsentences=32, sample_size=969, sample_size_v1=0, sample_size_v2=0, ppl=26.4, wps=491.9, ups=0.51, wpb=969, bsz=32, num_updates=3290, lr=4.84166e-05, gnorm=1.62, clip=100, loss_scale=256, train_wall=20, gb_free=15.2, wall=8545
2023-01-09 06:00:19 - progress_bar.py[line:272] - INFO: epoch 001:   3304 / 3665 loss=5.564, loss_v1=0, loss_v2=0, nll_loss=4.719, ntokens=808.2, nsentences=32, sample_size=808.2, sample_size_v1=0, sample_size_v2=0, ppl=26.34, wps=408.5, ups=0.51, wpb=808.2, bsz=32, num_updates=3300, lr=4.84021e-05, gnorm=1.716, clip=100, loss_scale=256, train_wall=20, gb_free=15.4, wall=8565
2023-01-09 06:00:39 - progress_bar.py[line:272] - INFO: epoch 001:   3314 / 3665 loss=5.539, loss_v1=0, loss_v2=0, nll_loss=4.684, ntokens=979.9, nsentences=32, sample_size=979.9, sample_size_v1=0, sample_size_v2=0, ppl=25.7, wps=487.4, ups=0.5, wpb=979.9, bsz=32, num_updates=3310, lr=4.83876e-05, gnorm=1.69, clip=100, loss_scale=256, train_wall=20, gb_free=15.3, wall=8585
2023-01-09 06:00:59 - progress_bar.py[line:272] - INFO: epoch 001:   3324 / 3665 loss=5.647, loss_v1=0, loss_v2=0, nll_loss=4.797, ntokens=970.8, nsentences=32, sample_size=970.8, sample_size_v1=0, sample_size_v2=0, ppl=27.8, wps=482.4, ups=0.5, wpb=970.8, bsz=32, num_updates=3320, lr=4.83731e-05, gnorm=1.724, clip=100, loss_scale=256, train_wall=20, gb_free=15.2, wall=8605
2023-01-09 06:01:19 - progress_bar.py[line:272] - INFO: epoch 001:   3334 / 3665 loss=5.628, loss_v1=0, loss_v2=0, nll_loss=4.781, ntokens=845.6, nsentences=32, sample_size=845.6, sample_size_v1=0, sample_size_v2=0, ppl=27.48, wps=421.6, ups=0.5, wpb=845.6, bsz=32, num_updates=3330, lr=4.83585e-05, gnorm=2.099, clip=100, loss_scale=256, train_wall=20, gb_free=15.5, wall=8625
2023-01-09 06:01:39 - progress_bar.py[line:272] - INFO: epoch 001:   3344 / 3665 loss=5.624, loss_v1=0, loss_v2=0, nll_loss=4.786, ntokens=1053.4, nsentences=32, sample_size=1053.4, sample_size_v1=0, sample_size_v2=0, ppl=27.59, wps=531.4, ups=0.5, wpb=1053.4, bsz=32, num_updates=3340, lr=4.8344e-05, gnorm=1.674, clip=100, loss_scale=256, train_wall=20, gb_free=15.4, wall=8645
2023-01-09 06:01:59 - progress_bar.py[line:272] - INFO: epoch 001:   3354 / 3665 loss=5.605, loss_v1=0, loss_v2=0, nll_loss=4.75, ntokens=1062.9, nsentences=32, sample_size=1062.9, sample_size_v1=0, sample_size_v2=0, ppl=26.92, wps=539.7, ups=0.51, wpb=1062.9, bsz=32, num_updates=3350, lr=4.83295e-05, gnorm=1.518, clip=100, loss_scale=256, train_wall=20, gb_free=15.2, wall=8665
2023-01-09 06:02:18 - progress_bar.py[line:272] - INFO: epoch 001:   3364 / 3665 loss=5.571, loss_v1=0, loss_v2=0, nll_loss=4.716, ntokens=787.2, nsentences=32, sample_size=787.2, sample_size_v1=0, sample_size_v2=0, ppl=26.29, wps=400.4, ups=0.51, wpb=787.2, bsz=32, num_updates=3360, lr=4.8315e-05, gnorm=1.801, clip=100, loss_scale=256, train_wall=20, gb_free=15.3, wall=8685
2023-01-09 06:02:38 - progress_bar.py[line:272] - INFO: epoch 001:   3374 / 3665 loss=5.537, loss_v1=0, loss_v2=0, nll_loss=4.689, ntokens=935.2, nsentences=32, sample_size=935.2, sample_size_v1=0, sample_size_v2=0, ppl=25.79, wps=475.7, ups=0.51, wpb=935.2, bsz=32, num_updates=3370, lr=4.83005e-05, gnorm=2.018, clip=100, loss_scale=256, train_wall=20, gb_free=15.3, wall=8704
2023-01-09 06:02:58 - progress_bar.py[line:272] - INFO: epoch 001:   3384 / 3665 loss=5.503, loss_v1=0, loss_v2=0, nll_loss=4.643, ntokens=1010.5, nsentences=32, sample_size=1010.5, sample_size_v1=0, sample_size_v2=0, ppl=24.98, wps=514, ups=0.51, wpb=1010.5, bsz=32, num_updates=3380, lr=4.8286e-05, gnorm=1.662, clip=100, loss_scale=256, train_wall=20, gb_free=14.5, wall=8724
2023-01-09 06:03:17 - progress_bar.py[line:272] - INFO: epoch 001:   3394 / 3665 loss=5.574, loss_v1=0, loss_v2=0, nll_loss=4.72, ntokens=788.5, nsentences=32, sample_size=788.5, sample_size_v1=0, sample_size_v2=0, ppl=26.36, wps=402.5, ups=0.51, wpb=788.5, bsz=32, num_updates=3390, lr=4.82715e-05, gnorm=1.895, clip=100, loss_scale=256, train_wall=20, gb_free=15.5, wall=8743
2023-01-09 06:03:37 - progress_bar.py[line:272] - INFO: epoch 001:   3404 / 3665 loss=5.565, loss_v1=0, loss_v2=0, nll_loss=4.713, ntokens=904.8, nsentences=32, sample_size=904.8, sample_size_v1=0, sample_size_v2=0, ppl=26.22, wps=461.1, ups=0.51, wpb=904.8, bsz=32, num_updates=3400, lr=4.82569e-05, gnorm=1.731, clip=100, loss_scale=256, train_wall=20, gb_free=15.6, wall=8763
2023-01-09 06:03:56 - progress_bar.py[line:272] - INFO: epoch 001:   3414 / 3665 loss=5.525, loss_v1=0, loss_v2=0, nll_loss=4.674, ntokens=990.3, nsentences=32, sample_size=990.3, sample_size_v1=0, sample_size_v2=0, ppl=25.52, wps=503.8, ups=0.51, wpb=990.3, bsz=32, num_updates=3410, lr=4.82424e-05, gnorm=1.752, clip=100, loss_scale=256, train_wall=20, gb_free=15.5, wall=8783
2023-01-09 06:04:16 - progress_bar.py[line:272] - INFO: epoch 001:   3424 / 3665 loss=5.611, loss_v1=0, loss_v2=0, nll_loss=4.758, ntokens=871.5, nsentences=32, sample_size=871.5, sample_size_v1=0, sample_size_v2=0, ppl=27.05, wps=443.7, ups=0.51, wpb=871.5, bsz=32, num_updates=3420, lr=4.82279e-05, gnorm=1.863, clip=100, loss_scale=256, train_wall=20, gb_free=15.6, wall=8802
2023-01-09 06:04:36 - progress_bar.py[line:272] - INFO: epoch 001:   3434 / 3665 loss=5.573, loss_v1=0, loss_v2=0, nll_loss=4.727, ntokens=932.4, nsentences=32, sample_size=932.4, sample_size_v1=0, sample_size_v2=0, ppl=26.48, wps=474.2, ups=0.51, wpb=932.4, bsz=32, num_updates=3430, lr=4.82134e-05, gnorm=1.88, clip=100, loss_scale=256, train_wall=20, gb_free=15.5, wall=8822
2023-01-09 06:04:55 - progress_bar.py[line:272] - INFO: epoch 001:   3444 / 3665 loss=5.482, loss_v1=0, loss_v2=0, nll_loss=4.617, ntokens=955.4, nsentences=32, sample_size=955.4, sample_size_v1=0, sample_size_v2=0, ppl=24.54, wps=485.5, ups=0.51, wpb=955.4, bsz=32, num_updates=3440, lr=4.81989e-05, gnorm=1.726, clip=100, loss_scale=256, train_wall=20, gb_free=15.3, wall=8842
2023-01-09 06:05:15 - progress_bar.py[line:272] - INFO: epoch 001:   3454 / 3665 loss=5.548, loss_v1=0, loss_v2=0, nll_loss=4.691, ntokens=887.8, nsentences=32, sample_size=887.8, sample_size_v1=0, sample_size_v2=0, ppl=25.83, wps=451.9, ups=0.51, wpb=887.8, bsz=32, num_updates=3450, lr=4.81844e-05, gnorm=1.668, clip=100, loss_scale=256, train_wall=20, gb_free=14.8, wall=8861
2023-01-09 06:05:35 - progress_bar.py[line:272] - INFO: epoch 001:   3464 / 3665 loss=5.464, loss_v1=0, loss_v2=0, nll_loss=4.602, ntokens=676.3, nsentences=32, sample_size=676.3, sample_size_v1=0, sample_size_v2=0, ppl=24.29, wps=345.1, ups=0.51, wpb=676.3, bsz=32, num_updates=3460, lr=4.81699e-05, gnorm=2.064, clip=100, loss_scale=256, train_wall=20, gb_free=15.5, wall=8881
2023-01-09 06:05:54 - progress_bar.py[line:272] - INFO: epoch 001:   3474 / 3665 loss=5.48, loss_v1=0, loss_v2=0, nll_loss=4.619, ntokens=889.6, nsentences=32, sample_size=889.6, sample_size_v1=0, sample_size_v2=0, ppl=24.58, wps=454.1, ups=0.51, wpb=889.6, bsz=32, num_updates=3470, lr=4.81554e-05, gnorm=1.945, clip=100, loss_scale=256, train_wall=20, gb_free=15.3, wall=8901
2023-01-09 06:06:14 - progress_bar.py[line:272] - INFO: epoch 001:   3484 / 3665 loss=5.611, loss_v1=0, loss_v2=0, nll_loss=4.76, ntokens=981.1, nsentences=32, sample_size=981.1, sample_size_v1=0, sample_size_v2=0, ppl=27.09, wps=497.8, ups=0.51, wpb=981.1, bsz=32, num_updates=3480, lr=4.81408e-05, gnorm=1.721, clip=100, loss_scale=256, train_wall=20, gb_free=15.6, wall=8920
2023-01-09 06:06:34 - progress_bar.py[line:272] - INFO: epoch 001:   3494 / 3665 loss=5.518, loss_v1=0, loss_v2=0, nll_loss=4.659, ntokens=685.9, nsentences=32, sample_size=685.9, sample_size_v1=0, sample_size_v2=0, ppl=25.27, wps=350.7, ups=0.51, wpb=685.9, bsz=32, num_updates=3490, lr=4.81263e-05, gnorm=1.899, clip=100, loss_scale=256, train_wall=20, gb_free=15.2, wall=8940
2023-01-09 06:06:53 - progress_bar.py[line:272] - INFO: epoch 001:   3504 / 3665 loss=5.518, loss_v1=0, loss_v2=0, nll_loss=4.665, ntokens=918.5, nsentences=32, sample_size=918.5, sample_size_v1=0, sample_size_v2=0, ppl=25.37, wps=466.9, ups=0.51, wpb=918.5, bsz=32, num_updates=3500, lr=4.81118e-05, gnorm=1.763, clip=100, loss_scale=256, train_wall=20, gb_free=15.6, wall=8960
2023-01-09 06:06:53 - train.py[line:445] - INFO: begin validation on "valid" subset
slice_id 0 seek offset 0
slice_id 0 seek offset 0
2023-01-09 06:11:43 - progress_bar.py[line:282] - INFO: epoch 001 | valid on 'valid' subset | loss 5.522 | loss_v1 0 | loss_v2 0 | nll_loss 4.654 | ntokens 117.13 | nsentences 4 | sample_size 117.13 | sample_size_v1 0 | sample_size_v2 0 | AP 0 | total positives 21.7318 | TP 0 | FP 7.1664 | ppl 25.18 | wps 505.9 | wpb 117.1 | bsz 4 | num_updates 3500 | best_AP 0
2023-01-09 06:11:43 - checkpoint_utils.py[line:64] - INFO: Preparing to save checkpoint for epoch 1 @ 3500 updates
2023-01-09 06:11:43 - trainer.py[line:431] - INFO: Saving checkpoint to ../../checkpoints/OFA/detection_checkpoints/10_5e-5_512/checkpoint_1_3500.pt
2023-01-09 06:11:46 - trainer.py[line:441] - INFO: Finished saving checkpoint to ../../checkpoints/OFA/detection_checkpoints/10_5e-5_512/checkpoint_1_3500.pt
2023-01-09 06:12:33 - checkpoint_utils.py[line:133] - INFO: Saved checkpoint ../../checkpoints/OFA/detection_checkpoints/10_5e-5_512/checkpoint_1_3500.pt (epoch 1 @ 3500 updates, score 0.0) (writing took 49.865629331208766 seconds)
2023-01-09 06:12:53 - progress_bar.py[line:272] - INFO: epoch 001:   3514 / 3665 loss=5.614, loss_v1=0, loss_v2=0, nll_loss=4.764, ntokens=1044.7, nsentences=32, sample_size=1044.7, sample_size_v1=0, sample_size_v2=0, ppl=27.17, wps=29.1, ups=0.03, wpb=1044.7, bsz=32, num_updates=3510, lr=4.80973e-05, gnorm=1.642, clip=100, loss_scale=256, train_wall=19, gb_free=15.5, wall=9319
2023-01-09 06:13:12 - progress_bar.py[line:272] - INFO: epoch 001:   3524 / 3665 loss=5.552, loss_v1=0, loss_v2=0, nll_loss=4.696, ntokens=835.3, nsentences=32, sample_size=835.3, sample_size_v1=0, sample_size_v2=0, ppl=25.92, wps=430.2, ups=0.52, wpb=835.3, bsz=32, num_updates=3520, lr=4.80828e-05, gnorm=1.803, clip=100, loss_scale=256, train_wall=19, gb_free=15.6, wall=9338
2023-01-09 06:13:32 - progress_bar.py[line:272] - INFO: epoch 001:   3534 / 3665 loss=5.499, loss_v1=0, loss_v2=0, nll_loss=4.641, ntokens=975, nsentences=32, sample_size=975, sample_size_v1=0, sample_size_v2=0, ppl=24.96, wps=497.5, ups=0.51, wpb=975, bsz=32, num_updates=3530, lr=4.80683e-05, gnorm=1.844, clip=100, loss_scale=256, train_wall=20, gb_free=15.3, wall=9358
2023-01-09 06:13:51 - progress_bar.py[line:272] - INFO: epoch 001:   3544 / 3665 loss=5.583, loss_v1=0, loss_v2=0, nll_loss=4.73, ntokens=1120.6, nsentences=32, sample_size=1120.6, sample_size_v1=0, sample_size_v2=0, ppl=26.54, wps=569.1, ups=0.51, wpb=1120.6, bsz=32, num_updates=3540, lr=4.80538e-05, gnorm=1.732, clip=100, loss_scale=256, train_wall=20, gb_free=14.8, wall=9378
2023-01-09 06:14:11 - progress_bar.py[line:272] - INFO: epoch 001:   3554 / 3665 loss=5.501, loss_v1=0, loss_v2=0, nll_loss=4.636, ntokens=908.1, nsentences=32, sample_size=908.1, sample_size_v1=0, sample_size_v2=0, ppl=24.86, wps=464.2, ups=0.51, wpb=908.1, bsz=32, num_updates=3550, lr=4.80392e-05, gnorm=1.598, clip=100, loss_scale=256, train_wall=20, gb_free=15.6, wall=9397
2023-01-09 06:14:30 - progress_bar.py[line:272] - INFO: epoch 001:   3564 / 3665 loss=5.538, loss_v1=0, loss_v2=0, nll_loss=4.69, ntokens=913, nsentences=32, sample_size=913, sample_size_v1=0, sample_size_v2=0, ppl=25.82, wps=465.6, ups=0.51, wpb=913, bsz=32, num_updates=3560, lr=4.80247e-05, gnorm=1.801, clip=100, loss_scale=256, train_wall=20, gb_free=15.3, wall=9417
2023-01-09 06:14:50 - progress_bar.py[line:272] - INFO: epoch 001:   3574 / 3665 loss=5.485, loss_v1=0, loss_v2=0, nll_loss=4.622, ntokens=1003.8, nsentences=32, sample_size=1003.8, sample_size_v1=0, sample_size_v2=0, ppl=24.62, wps=511.8, ups=0.51, wpb=1003.8, bsz=32, num_updates=3570, lr=4.80102e-05, gnorm=1.626, clip=100, loss_scale=256, train_wall=20, gb_free=15.5, wall=9436
2023-01-09 06:15:10 - progress_bar.py[line:272] - INFO: epoch 001:   3584 / 3665 loss=5.604, loss_v1=0, loss_v2=0, nll_loss=4.749, ntokens=901.6, nsentences=32, sample_size=901.6, sample_size_v1=0, sample_size_v2=0, ppl=26.89, wps=459.5, ups=0.51, wpb=901.6, bsz=32, num_updates=3580, lr=4.79957e-05, gnorm=1.633, clip=100, loss_scale=256, train_wall=20, gb_free=15.3, wall=9456
2023-01-09 06:15:29 - progress_bar.py[line:272] - INFO: epoch 001:   3594 / 3665 loss=5.533, loss_v1=0, loss_v2=0, nll_loss=4.684, ntokens=856.1, nsentences=32, sample_size=856.1, sample_size_v1=0, sample_size_v2=0, ppl=25.71, wps=437, ups=0.51, wpb=856.1, bsz=32, num_updates=3590, lr=4.79812e-05, gnorm=1.902, clip=100, loss_scale=256, train_wall=20, gb_free=15.3, wall=9476
2023-01-09 06:15:49 - progress_bar.py[line:272] - INFO: epoch 001:   3604 / 3665 loss=5.534, loss_v1=0, loss_v2=0, nll_loss=4.676, ntokens=1022.9, nsentences=32, sample_size=1022.9, sample_size_v1=0, sample_size_v2=0, ppl=25.56, wps=519.8, ups=0.51, wpb=1022.9, bsz=32, num_updates=3600, lr=4.79667e-05, gnorm=1.704, clip=100, loss_scale=512, train_wall=20, gb_free=15.3, wall=9495
2023-01-09 06:16:09 - progress_bar.py[line:272] - INFO: epoch 001:   3614 / 3665 loss=5.531, loss_v1=0, loss_v2=0, nll_loss=4.67, ntokens=855.8, nsentences=32, sample_size=855.8, sample_size_v1=0, sample_size_v2=0, ppl=25.45, wps=436.6, ups=0.51, wpb=855.8, bsz=32, num_updates=3610, lr=4.79522e-05, gnorm=1.704, clip=100, loss_scale=512, train_wall=20, gb_free=15.5, wall=9515
2023-01-09 06:16:28 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 256.0
2023-01-09 06:16:30 - progress_bar.py[line:272] - INFO: epoch 001:   3625 / 3665 loss=5.478, loss_v1=0, loss_v2=0, nll_loss=4.62, ntokens=853.6, nsentences=32, sample_size=853.6, sample_size_v1=0, sample_size_v2=0, ppl=24.59, wps=396.2, ups=0.46, wpb=853.6, bsz=32, num_updates=3620, lr=4.79377e-05, gnorm=1.877, clip=100, loss_scale=256, train_wall=22, gb_free=14.5, wall=9536
2023-01-09 06:16:50 - progress_bar.py[line:272] - INFO: epoch 001:   3635 / 3665 loss=5.459, loss_v1=0, loss_v2=0, nll_loss=4.598, ntokens=1154.8, nsentences=32, sample_size=1154.8, sample_size_v1=0, sample_size_v2=0, ppl=24.22, wps=586.3, ups=0.51, wpb=1154.8, bsz=32, num_updates=3630, lr=4.79231e-05, gnorm=1.491, clip=100, loss_scale=256, train_wall=20, gb_free=15.3, wall=9556
2023-01-09 06:17:09 - progress_bar.py[line:272] - INFO: epoch 001:   3645 / 3665 loss=5.576, loss_v1=0, loss_v2=0, nll_loss=4.722, ntokens=868.5, nsentences=32, sample_size=868.5, sample_size_v1=0, sample_size_v2=0, ppl=26.4, wps=443.8, ups=0.51, wpb=868.5, bsz=32, num_updates=3640, lr=4.79086e-05, gnorm=1.963, clip=100, loss_scale=256, train_wall=20, gb_free=15.4, wall=9576
2023-01-09 06:17:29 - progress_bar.py[line:272] - INFO: epoch 001:   3655 / 3665 loss=5.522, loss_v1=0, loss_v2=0, nll_loss=4.664, ntokens=843.4, nsentences=32, sample_size=843.4, sample_size_v1=0, sample_size_v2=0, ppl=25.35, wps=429.6, ups=0.51, wpb=843.4, bsz=32, num_updates=3650, lr=4.78941e-05, gnorm=1.965, clip=100, loss_scale=256, train_wall=20, gb_free=15.2, wall=9595
2023-01-09 06:17:48 - progress_bar.py[line:272] - INFO: epoch 001:   3665 / 3665 loss=5.495, loss_v1=0, loss_v2=0, nll_loss=4.638, ntokens=1008.6, nsentences=30.8, sample_size=1008.6, sample_size_v1=0, sample_size_v2=0, ppl=24.89, wps=531.5, ups=0.53, wpb=1008.6, bsz=30.8, num_updates=3660, lr=4.78796e-05, gnorm=1.822, clip=100, loss_scale=256, train_wall=19, gb_free=14.6, wall=9614
2023-01-09 06:17:48 - train.py[line:445] - INFO: begin validation on "valid" subset
slice_id 0 seek offset 0
slice_id 0 seek offset 0
2023-01-09 06:22:49 - progress_bar.py[line:282] - INFO: epoch 001 | valid on 'valid' subset | loss 5.514 | loss_v1 0 | loss_v2 0 | nll_loss 4.636 | ntokens 117.12 | nsentences 4 | sample_size 117.12 | sample_size_v1 0 | sample_size_v2 0 | AP 0 | total positives 21.7278 | TP 0 | FP 7.1042 | ppl 24.86 | wps 487.1 | wpb 117.1 | bsz 4 | num_updates 3660 | best_AP 0
2023-01-09 06:22:49 - checkpoint_utils.py[line:64] - INFO: Preparing to save checkpoint for epoch 1 @ 3660 updates
2023-01-09 06:22:49 - trainer.py[line:431] - INFO: Saving checkpoint to ../../checkpoints/OFA/detection_checkpoints/10_5e-5_512/checkpoint_best.pt
2023-01-09 06:23:09 - trainer.py[line:441] - INFO: Finished saving checkpoint to ../../checkpoints/OFA/detection_checkpoints/10_5e-5_512/checkpoint_best.pt
2023-01-09 06:23:42 - checkpoint_utils.py[line:133] - INFO: Saved checkpoint ../../checkpoints/OFA/detection_checkpoints/10_5e-5_512/checkpoint_best.pt (epoch 1 @ 3660 updates, score 0.0) (writing took 52.64436386199668 seconds)
2023-01-09 06:23:42 - train.py[line:332] - INFO: end of epoch 1 (average epoch stats below)
2023-01-09 06:23:42 - progress_bar.py[line:282] - INFO: epoch 001 | loss 6.263 | loss_v1 0 | loss_v2 0 | nll_loss 5.531 | ntokens 925.048 | nsentences 31.996 | sample_size 925.048 | sample_size_v1 0 | sample_size_v2 0 | AP 0 | ppl 46.24 | wps 340.6 | ups 0.37 | wpb 925 | bsz 32 | num_updates 3660 | lr 4.78796e-05 | gnorm 2.036 | clip 100 | loss_scale 256 | train_wall 7222 | gb_free 14.6 | wall 9968
2023-01-09 06:23:42 - trainer.py[line:639] - INFO: loading train data for epoch 2
local datafile ../../dataset/OFA_data/train.tsv slice_id 0 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../dataset/OFA_data/train.tsv slice_id 0 finished initializing row_count and line_idx-to-offset mapping
file ../../dataset/OFA_data/train.tsv slice_id 0 row count 117266 total row count 117266
slice_id 0 seek offset 0
2023-01-09 06:24:13 - trainer.py[line:703] - INFO: begin training epoch 2
2023-01-09 06:24:13 - train.py[line:305] - INFO: Start iterating over samples
2023-01-09 06:24:32 - progress_bar.py[line:272] - INFO: epoch 002:     10 / 3665 loss=5.528, loss_v1=0, loss_v2=0, nll_loss=4.666, ntokens=823.4, nsentences=32, sample_size=823.4, sample_size_v1=0, sample_size_v2=0, ppl=25.39, wps=20.4, ups=0.02, wpb=823.4, bsz=32, num_updates=3670, lr=4.78651e-05, gnorm=1.888, clip=100, loss_scale=256, train_wall=19, gb_free=15.1, wall=10019
2023-01-09 06:24:52 - progress_bar.py[line:272] - INFO: epoch 002:     20 / 3665 loss=5.5, loss_v1=0, loss_v2=0, nll_loss=4.642, ntokens=905.5, nsentences=32, sample_size=905.5, sample_size_v1=0, sample_size_v2=0, ppl=24.97, wps=466.9, ups=0.52, wpb=905.5, bsz=32, num_updates=3680, lr=4.78506e-05, gnorm=1.881, clip=100, loss_scale=256, train_wall=19, gb_free=15.6, wall=10038
2023-01-09 06:25:11 - progress_bar.py[line:272] - INFO: epoch 002:     30 / 3665 loss=5.57, loss_v1=0, loss_v2=0, nll_loss=4.723, ntokens=1045.7, nsentences=32, sample_size=1045.7, sample_size_v1=0, sample_size_v2=0, ppl=26.4, wps=534.7, ups=0.51, wpb=1045.7, bsz=32, num_updates=3690, lr=4.78361e-05, gnorm=1.768, clip=100, loss_scale=256, train_wall=20, gb_free=15.3, wall=10058
2023-01-09 06:25:31 - progress_bar.py[line:272] - INFO: epoch 002:     40 / 3665 loss=5.491, loss_v1=0, loss_v2=0, nll_loss=4.625, ntokens=761.4, nsentences=32, sample_size=761.4, sample_size_v1=0, sample_size_v2=0, ppl=24.68, wps=386.5, ups=0.51, wpb=761.4, bsz=32, num_updates=3700, lr=4.78215e-05, gnorm=2.07, clip=100, loss_scale=256, train_wall=20, gb_free=15.5, wall=10077
2023-01-09 06:25:51 - progress_bar.py[line:272] - INFO: epoch 002:     50 / 3665 loss=5.452, loss_v1=0, loss_v2=0, nll_loss=4.588, ntokens=928.8, nsentences=32, sample_size=928.8, sample_size_v1=0, sample_size_v2=0, ppl=24.04, wps=474.9, ups=0.51, wpb=928.8, bsz=32, num_updates=3710, lr=4.7807e-05, gnorm=1.844, clip=100, loss_scale=256, train_wall=20, gb_free=15.4, wall=10097
2023-01-09 06:26:10 - progress_bar.py[line:272] - INFO: epoch 002:     60 / 3665 loss=5.532, loss_v1=0, loss_v2=0, nll_loss=4.678, ntokens=950, nsentences=32, sample_size=950, sample_size_v1=0, sample_size_v2=0, ppl=25.6, wps=485.4, ups=0.51, wpb=950, bsz=32, num_updates=3720, lr=4.77925e-05, gnorm=1.717, clip=100, loss_scale=256, train_wall=20, gb_free=15.3, wall=10116
2023-01-09 06:26:30 - progress_bar.py[line:272] - INFO: epoch 002:     70 / 3665 loss=5.471, loss_v1=0, loss_v2=0, nll_loss=4.606, ntokens=782.3, nsentences=32, sample_size=782.3, sample_size_v1=0, sample_size_v2=0, ppl=24.36, wps=401, ups=0.51, wpb=782.3, bsz=32, num_updates=3730, lr=4.7778e-05, gnorm=1.834, clip=100, loss_scale=256, train_wall=19, gb_free=15.4, wall=10136
2023-01-09 06:26:49 - progress_bar.py[line:272] - INFO: epoch 002:     80 / 3665 loss=5.476, loss_v1=0, loss_v2=0, nll_loss=4.616, ntokens=1033, nsentences=32, sample_size=1033, sample_size_v1=0, sample_size_v2=0, ppl=24.53, wps=526.4, ups=0.51, wpb=1033, bsz=32, num_updates=3740, lr=4.77635e-05, gnorm=1.655, clip=100, loss_scale=256, train_wall=20, gb_free=15.1, wall=10155
2023-01-09 06:27:09 - progress_bar.py[line:272] - INFO: epoch 002:     90 / 3665 loss=5.571, loss_v1=0, loss_v2=0, nll_loss=4.717, ntokens=833.1, nsentences=32, sample_size=833.1, sample_size_v1=0, sample_size_v2=0, ppl=26.31, wps=426.2, ups=0.51, wpb=833.1, bsz=32, num_updates=3750, lr=4.7749e-05, gnorm=1.92, clip=100, loss_scale=256, train_wall=20, gb_free=15.1, wall=10175
2023-01-09 06:27:28 - progress_bar.py[line:272] - INFO: epoch 002:    100 / 3665 loss=5.559, loss_v1=0, loss_v2=0, nll_loss=4.702, ntokens=958.3, nsentences=32, sample_size=958.3, sample_size_v1=0, sample_size_v2=0, ppl=26.03, wps=487.9, ups=0.51, wpb=958.3, bsz=32, num_updates=3760, lr=4.77345e-05, gnorm=1.785, clip=100, loss_scale=256, train_wall=20, gb_free=15, wall=10195
2023-01-09 06:27:48 - progress_bar.py[line:272] - INFO: epoch 002:    110 / 3665 loss=5.483, loss_v1=0, loss_v2=0, nll_loss=4.623, ntokens=1097.8, nsentences=32, sample_size=1097.8, sample_size_v1=0, sample_size_v2=0, ppl=24.64, wps=557.9, ups=0.51, wpb=1097.8, bsz=32, num_updates=3770, lr=4.772e-05, gnorm=1.606, clip=100, loss_scale=256, train_wall=20, gb_free=15.2, wall=10214
2023-01-09 06:28:08 - progress_bar.py[line:272] - INFO: epoch 002:    120 / 3665 loss=5.526, loss_v1=0, loss_v2=0, nll_loss=4.669, ntokens=878.2, nsentences=32, sample_size=878.2, sample_size_v1=0, sample_size_v2=0, ppl=25.43, wps=448.1, ups=0.51, wpb=878.2, bsz=32, num_updates=3780, lr=4.77054e-05, gnorm=1.797, clip=100, loss_scale=256, train_wall=20, gb_free=15.7, wall=10234
2023-01-09 06:28:27 - progress_bar.py[line:272] - INFO: epoch 002:    130 / 3665 loss=5.49, loss_v1=0, loss_v2=0, nll_loss=4.628, ntokens=936.2, nsentences=32, sample_size=936.2, sample_size_v1=0, sample_size_v2=0, ppl=24.73, wps=477, ups=0.51, wpb=936.2, bsz=32, num_updates=3790, lr=4.76909e-05, gnorm=1.743, clip=100, loss_scale=256, train_wall=20, gb_free=15.3, wall=10254
2023-01-09 06:28:47 - progress_bar.py[line:272] - INFO: epoch 002:    140 / 3665 loss=5.486, loss_v1=0, loss_v2=0, nll_loss=4.625, ntokens=1060, nsentences=32, sample_size=1060, sample_size_v1=0, sample_size_v2=0, ppl=24.67, wps=538.7, ups=0.51, wpb=1060, bsz=32, num_updates=3800, lr=4.76764e-05, gnorm=1.817, clip=100, loss_scale=256, train_wall=20, gb_free=15.2, wall=10273
2023-01-09 06:29:07 - progress_bar.py[line:272] - INFO: epoch 002:    150 / 3665 loss=5.549, loss_v1=0, loss_v2=0, nll_loss=4.692, ntokens=777, nsentences=32, sample_size=777, sample_size_v1=0, sample_size_v2=0, ppl=25.85, wps=397.4, ups=0.51, wpb=777, bsz=32, num_updates=3810, lr=4.76619e-05, gnorm=1.92, clip=100, loss_scale=256, train_wall=20, gb_free=15.5, wall=10293
2023-01-09 06:29:26 - progress_bar.py[line:272] - INFO: epoch 002:    160 / 3665 loss=5.481, loss_v1=0, loss_v2=0, nll_loss=4.62, ntokens=964.5, nsentences=32, sample_size=964.5, sample_size_v1=0, sample_size_v2=0, ppl=24.59, wps=490.8, ups=0.51, wpb=964.5, bsz=32, num_updates=3820, lr=4.76474e-05, gnorm=1.755, clip=100, loss_scale=256, train_wall=20, gb_free=15.4, wall=10312
2023-01-09 06:29:46 - progress_bar.py[line:272] - INFO: epoch 002:    170 / 3665 loss=5.532, loss_v1=0, loss_v2=0, nll_loss=4.673, ntokens=1038.2, nsentences=32, sample_size=1038.2, sample_size_v1=0, sample_size_v2=0, ppl=25.5, wps=528.2, ups=0.51, wpb=1038.2, bsz=32, num_updates=3830, lr=4.76329e-05, gnorm=1.686, clip=100, loss_scale=256, train_wall=20, gb_free=15.5, wall=10332
2023-01-09 06:30:06 - progress_bar.py[line:272] - INFO: epoch 002:    180 / 3665 loss=5.503, loss_v1=0, loss_v2=0, nll_loss=4.642, ntokens=772.3, nsentences=32, sample_size=772.3, sample_size_v1=0, sample_size_v2=0, ppl=24.97, wps=392.2, ups=0.51, wpb=772.3, bsz=32, num_updates=3840, lr=4.76184e-05, gnorm=1.784, clip=100, loss_scale=256, train_wall=20, gb_free=15.2, wall=10352
2023-01-09 06:30:25 - progress_bar.py[line:272] - INFO: epoch 002:    190 / 3665 loss=5.496, loss_v1=0, loss_v2=0, nll_loss=4.639, ntokens=1014.3, nsentences=32, sample_size=1014.3, sample_size_v1=0, sample_size_v2=0, ppl=24.92, wps=512.2, ups=0.5, wpb=1014.3, bsz=32, num_updates=3850, lr=4.76038e-05, gnorm=1.586, clip=100, loss_scale=256, train_wall=20, gb_free=15, wall=10372
2023-01-09 06:30:45 - progress_bar.py[line:272] - INFO: epoch 002:    200 / 3665 loss=5.575, loss_v1=0, loss_v2=0, nll_loss=4.721, ntokens=997.2, nsentences=32, sample_size=997.2, sample_size_v1=0, sample_size_v2=0, ppl=26.37, wps=504.6, ups=0.51, wpb=997.2, bsz=32, num_updates=3860, lr=4.75893e-05, gnorm=1.833, clip=100, loss_scale=256, train_wall=20, gb_free=15.5, wall=10391
2023-01-09 06:31:05 - progress_bar.py[line:272] - INFO: epoch 002:    210 / 3665 loss=5.511, loss_v1=0, loss_v2=0, nll_loss=4.649, ntokens=753, nsentences=32, sample_size=753, sample_size_v1=0, sample_size_v2=0, ppl=25.09, wps=382.5, ups=0.51, wpb=753, bsz=32, num_updates=3870, lr=4.75748e-05, gnorm=1.957, clip=100, loss_scale=256, train_wall=20, gb_free=15.6, wall=10411
2023-01-09 06:31:25 - progress_bar.py[line:272] - INFO: epoch 002:    220 / 3665 loss=5.44, loss_v1=0, loss_v2=0, nll_loss=4.579, ntokens=951.6, nsentences=32, sample_size=951.6, sample_size_v1=0, sample_size_v2=0, ppl=23.91, wps=481.5, ups=0.51, wpb=951.6, bsz=32, num_updates=3880, lr=4.75603e-05, gnorm=1.721, clip=100, loss_scale=256, train_wall=20, gb_free=15.3, wall=10431
2023-01-09 06:31:44 - progress_bar.py[line:272] - INFO: epoch 002:    230 / 3665 loss=5.576, loss_v1=0, loss_v2=0, nll_loss=4.722, ntokens=1054, nsentences=32, sample_size=1054, sample_size_v1=0, sample_size_v2=0, ppl=26.4, wps=532.5, ups=0.51, wpb=1054, bsz=32, num_updates=3890, lr=4.75458e-05, gnorm=1.824, clip=100, loss_scale=256, train_wall=20, gb_free=15.7, wall=10451
2023-01-09 06:32:04 - progress_bar.py[line:272] - INFO: epoch 002:    240 / 3665 loss=5.503, loss_v1=0, loss_v2=0, nll_loss=4.642, ntokens=822, nsentences=32, sample_size=822, sample_size_v1=0, sample_size_v2=0, ppl=24.97, wps=417.9, ups=0.51, wpb=822, bsz=32, num_updates=3900, lr=4.75313e-05, gnorm=1.97, clip=100, loss_scale=256, train_wall=20, gb_free=15.2, wall=10470
2023-01-09 06:32:24 - progress_bar.py[line:272] - INFO: epoch 002:    250 / 3665 loss=5.461, loss_v1=0, loss_v2=0, nll_loss=4.597, ntokens=996.9, nsentences=32, sample_size=996.9, sample_size_v1=0, sample_size_v2=0, ppl=24.19, wps=503.7, ups=0.51, wpb=996.9, bsz=32, num_updates=3910, lr=4.75168e-05, gnorm=1.852, clip=100, loss_scale=256, train_wall=20, gb_free=14.5, wall=10490
2023-01-09 06:32:44 - progress_bar.py[line:272] - INFO: epoch 002:    260 / 3665 loss=5.515, loss_v1=0, loss_v2=0, nll_loss=4.655, ntokens=796.1, nsentences=32, sample_size=796.1, sample_size_v1=0, sample_size_v2=0, ppl=25.19, wps=403.3, ups=0.51, wpb=796.1, bsz=32, num_updates=3920, lr=4.75022e-05, gnorm=2.05, clip=100, loss_scale=256, train_wall=20, gb_free=15.7, wall=10510
2023-01-09 06:33:03 - progress_bar.py[line:272] - INFO: epoch 002:    270 / 3665 loss=5.562, loss_v1=0, loss_v2=0, nll_loss=4.71, ntokens=884.3, nsentences=32, sample_size=884.3, sample_size_v1=0, sample_size_v2=0, ppl=26.18, wps=448.5, ups=0.51, wpb=884.3, bsz=32, num_updates=3930, lr=4.74877e-05, gnorm=1.804, clip=100, loss_scale=256, train_wall=20, gb_free=15.7, wall=10530
2023-01-09 06:33:23 - progress_bar.py[line:272] - INFO: epoch 002:    280 / 3665 loss=5.469, loss_v1=0, loss_v2=0, nll_loss=4.606, ntokens=953, nsentences=32, sample_size=953, sample_size_v1=0, sample_size_v2=0, ppl=24.35, wps=482.7, ups=0.51, wpb=953, bsz=32, num_updates=3940, lr=4.74732e-05, gnorm=1.774, clip=100, loss_scale=256, train_wall=20, gb_free=15.4, wall=10549
2023-01-09 06:33:43 - progress_bar.py[line:272] - INFO: epoch 002:    290 / 3665 loss=5.438, loss_v1=0, loss_v2=0, nll_loss=4.573, ntokens=743.9, nsentences=32, sample_size=743.9, sample_size_v1=0, sample_size_v2=0, ppl=23.81, wps=377.5, ups=0.51, wpb=743.9, bsz=32, num_updates=3950, lr=4.74587e-05, gnorm=2.035, clip=100, loss_scale=256, train_wall=20, gb_free=15.1, wall=10569
2023-01-09 06:34:03 - progress_bar.py[line:272] - INFO: epoch 002:    300 / 3665 loss=5.494, loss_v1=0, loss_v2=0, nll_loss=4.631, ntokens=1005.6, nsentences=32, sample_size=1005.6, sample_size_v1=0, sample_size_v2=0, ppl=24.78, wps=508.1, ups=0.51, wpb=1005.6, bsz=32, num_updates=3960, lr=4.74442e-05, gnorm=1.62, clip=100, loss_scale=256, train_wall=20, gb_free=15.5, wall=10589
2023-01-09 06:34:22 - progress_bar.py[line:272] - INFO: epoch 002:    310 / 3665 loss=5.513, loss_v1=0, loss_v2=0, nll_loss=4.653, ntokens=1028.4, nsentences=32, sample_size=1028.4, sample_size_v1=0, sample_size_v2=0, ppl=25.15, wps=519.3, ups=0.5, wpb=1028.4, bsz=32, num_updates=3970, lr=4.74297e-05, gnorm=1.489, clip=100, loss_scale=256, train_wall=20, gb_free=15.2, wall=10609
2023-01-09 06:34:42 - progress_bar.py[line:272] - INFO: epoch 002:    320 / 3665 loss=5.519, loss_v1=0, loss_v2=0, nll_loss=4.664, ntokens=802.3, nsentences=32, sample_size=802.3, sample_size_v1=0, sample_size_v2=0, ppl=25.36, wps=407.6, ups=0.51, wpb=802.3, bsz=32, num_updates=3980, lr=4.74152e-05, gnorm=1.812, clip=100, loss_scale=256, train_wall=20, gb_free=15.4, wall=10628
2023-01-09 06:35:02 - progress_bar.py[line:272] - INFO: epoch 002:    330 / 3665 loss=5.433, loss_v1=0, loss_v2=0, nll_loss=4.565, ntokens=992.1, nsentences=32, sample_size=992.1, sample_size_v1=0, sample_size_v2=0, ppl=23.67, wps=503, ups=0.51, wpb=992.1, bsz=32, num_updates=3990, lr=4.74007e-05, gnorm=1.677, clip=100, loss_scale=256, train_wall=20, gb_free=15.2, wall=10648
2023-01-09 06:35:21 - progress_bar.py[line:272] - INFO: epoch 002:    340 / 3665 loss=5.489, loss_v1=0, loss_v2=0, nll_loss=4.627, ntokens=895.4, nsentences=32, sample_size=895.4, sample_size_v1=0, sample_size_v2=0, ppl=24.71, wps=453.6, ups=0.51, wpb=895.4, bsz=32, num_updates=4000, lr=4.73861e-05, gnorm=1.688, clip=100, loss_scale=256, train_wall=20, gb_free=15.4, wall=10668
2023-01-09 06:35:21 - train.py[line:445] - INFO: begin validation on "valid" subset
slice_id 0 seek offset 0
slice_id 0 seek offset 0
2023-01-09 06:40:09 - progress_bar.py[line:282] - INFO: epoch 002 | valid on 'valid' subset | loss 5.489 | loss_v1 0 | loss_v2 0 | nll_loss 4.615 | ntokens 117.221 | nsentences 4 | sample_size 117.221 | sample_size_v1 0 | sample_size_v2 0 | AP 0 | total positives 21.752 | TP 0 | FP 7.08966 | ppl 24.51 | wps 512.2 | wpb 117.2 | bsz 4 | num_updates 4000 | best_AP 0
2023-01-09 06:40:09 - checkpoint_utils.py[line:64] - INFO: Preparing to save checkpoint for epoch 2 @ 4000 updates
2023-01-09 06:40:09 - trainer.py[line:431] - INFO: Saving checkpoint to ../../checkpoints/OFA/detection_checkpoints/10_5e-5_512/checkpoint_2_4000.pt
2023-01-09 06:40:12 - trainer.py[line:441] - INFO: Finished saving checkpoint to ../../checkpoints/OFA/detection_checkpoints/10_5e-5_512/checkpoint_2_4000.pt
2023-01-09 06:41:26 - checkpoint_utils.py[line:133] - INFO: Saved checkpoint ../../checkpoints/OFA/detection_checkpoints/10_5e-5_512/checkpoint_2_4000.pt (epoch 2 @ 4000 updates, score 0.0) (writing took 77.92114583589137 seconds)
2023-01-09 06:41:46 - progress_bar.py[line:272] - INFO: epoch 002:    350 / 3665 loss=5.47, loss_v1=0, loss_v2=0, nll_loss=4.608, ntokens=716.2, nsentences=32, sample_size=716.2, sample_size_v1=0, sample_size_v2=0, ppl=24.39, wps=18.6, ups=0.03, wpb=716.2, bsz=32, num_updates=4010, lr=4.73716e-05, gnorm=2.044, clip=100, loss_scale=256, train_wall=19, gb_free=15.4, wall=11052
2023-01-09 06:42:05 - progress_bar.py[line:272] - INFO: epoch 002:    360 / 3665 loss=5.494, loss_v1=0, loss_v2=0, nll_loss=4.632, ntokens=1034.4, nsentences=32, sample_size=1034.4, sample_size_v1=0, sample_size_v2=0, ppl=24.8, wps=529, ups=0.51, wpb=1034.4, bsz=32, num_updates=4020, lr=4.73571e-05, gnorm=1.722, clip=100, loss_scale=256, train_wall=20, gb_free=15.4, wall=11072
2023-01-09 06:42:25 - progress_bar.py[line:272] - INFO: epoch 002:    370 / 3665 loss=5.553, loss_v1=0, loss_v2=0, nll_loss=4.699, ntokens=828.4, nsentences=32, sample_size=828.4, sample_size_v1=0, sample_size_v2=0, ppl=25.97, wps=424.9, ups=0.51, wpb=828.4, bsz=32, num_updates=4030, lr=4.73426e-05, gnorm=1.822, clip=100, loss_scale=256, train_wall=19, gb_free=15.6, wall=11091
2023-01-09 06:42:45 - progress_bar.py[line:272] - INFO: epoch 002:    380 / 3665 loss=5.497, loss_v1=0, loss_v2=0, nll_loss=4.636, ntokens=895.1, nsentences=32, sample_size=895.1, sample_size_v1=0, sample_size_v2=0, ppl=24.87, wps=456.2, ups=0.51, wpb=895.1, bsz=32, num_updates=4040, lr=4.73281e-05, gnorm=1.813, clip=100, loss_scale=256, train_wall=20, gb_free=15.7, wall=11111
2023-01-09 06:43:04 - progress_bar.py[line:272] - INFO: epoch 002:    390 / 3665 loss=5.434, loss_v1=0, loss_v2=0, nll_loss=4.564, ntokens=1030.5, nsentences=32, sample_size=1030.5, sample_size_v1=0, sample_size_v2=0, ppl=23.66, wps=525.2, ups=0.51, wpb=1030.5, bsz=32, num_updates=4050, lr=4.73136e-05, gnorm=1.545, clip=100, loss_scale=256, train_wall=20, gb_free=15.2, wall=11131
2023-01-09 06:43:24 - progress_bar.py[line:272] - INFO: epoch 002:    400 / 3665 loss=5.431, loss_v1=0, loss_v2=0, nll_loss=4.563, ntokens=655.8, nsentences=32, sample_size=655.8, sample_size_v1=0, sample_size_v2=0, ppl=23.64, wps=335.5, ups=0.51, wpb=655.8, bsz=32, num_updates=4060, lr=4.72991e-05, gnorm=2.132, clip=100, loss_scale=256, train_wall=20, gb_free=15.5, wall=11150
2023-01-09 06:43:44 - progress_bar.py[line:272] - INFO: epoch 002:    410 / 3665 loss=5.445, loss_v1=0, loss_v2=0, nll_loss=4.581, ntokens=950.8, nsentences=32, sample_size=950.8, sample_size_v1=0, sample_size_v2=0, ppl=23.93, wps=479.5, ups=0.5, wpb=950.8, bsz=32, num_updates=4070, lr=4.72845e-05, gnorm=1.824, clip=100, loss_scale=256, train_wall=20, gb_free=15.5, wall=11170
2023-01-09 06:44:03 - progress_bar.py[line:272] - INFO: epoch 002:    420 / 3665 loss=5.489, loss_v1=0, loss_v2=0, nll_loss=4.624, ntokens=980.2, nsentences=32, sample_size=980.2, sample_size_v1=0, sample_size_v2=0, ppl=24.65, wps=499.4, ups=0.51, wpb=980.2, bsz=32, num_updates=4080, lr=4.727e-05, gnorm=1.538, clip=100, loss_scale=256, train_wall=20, gb_free=15.4, wall=11190
2023-01-09 06:44:23 - progress_bar.py[line:272] - INFO: epoch 002:    430 / 3665 loss=5.566, loss_v1=0, loss_v2=0, nll_loss=4.713, ntokens=924.4, nsentences=32, sample_size=924.4, sample_size_v1=0, sample_size_v2=0, ppl=26.22, wps=468.1, ups=0.51, wpb=924.4, bsz=32, num_updates=4090, lr=4.72555e-05, gnorm=1.743, clip=100, loss_scale=256, train_wall=20, gb_free=14.9, wall=11209
2023-01-09 06:44:43 - progress_bar.py[line:272] - INFO: epoch 002:    440 / 3665 loss=5.504, loss_v1=0, loss_v2=0, nll_loss=4.646, ntokens=933.8, nsentences=32, sample_size=933.8, sample_size_v1=0, sample_size_v2=0, ppl=25.04, wps=476.7, ups=0.51, wpb=933.8, bsz=32, num_updates=4100, lr=4.7241e-05, gnorm=1.87, clip=100, loss_scale=256, train_wall=20, gb_free=15.5, wall=11229
2023-01-09 06:45:02 - progress_bar.py[line:272] - INFO: epoch 002:    450 / 3665 loss=5.496, loss_v1=0, loss_v2=0, nll_loss=4.633, ntokens=989.4, nsentences=32, sample_size=989.4, sample_size_v1=0, sample_size_v2=0, ppl=24.81, wps=501.4, ups=0.51, wpb=989.4, bsz=32, num_updates=4110, lr=4.72265e-05, gnorm=1.699, clip=100, loss_scale=256, train_wall=20, gb_free=15.3, wall=11249
2023-01-09 06:45:22 - progress_bar.py[line:272] - INFO: epoch 002:    460 / 3665 loss=5.499, loss_v1=0, loss_v2=0, nll_loss=4.639, ntokens=902.6, nsentences=32, sample_size=902.6, sample_size_v1=0, sample_size_v2=0, ppl=24.92, wps=460.3, ups=0.51, wpb=902.6, bsz=32, num_updates=4120, lr=4.7212e-05, gnorm=1.877, clip=100, loss_scale=256, train_wall=20, gb_free=15.5, wall=11268
2023-01-09 06:45:42 - progress_bar.py[line:272] - INFO: epoch 002:    470 / 3665 loss=5.42, loss_v1=0, loss_v2=0, nll_loss=4.55, ntokens=1135.4, nsentences=32, sample_size=1135.4, sample_size_v1=0, sample_size_v2=0, ppl=23.42, wps=574.1, ups=0.51, wpb=1135.4, bsz=32, num_updates=4130, lr=4.71975e-05, gnorm=1.429, clip=100, loss_scale=256, train_wall=20, gb_free=15.1, wall=11288
2023-01-09 06:46:01 - progress_bar.py[line:272] - INFO: epoch 002:    480 / 3665 loss=5.623, loss_v1=0, loss_v2=0, nll_loss=4.781, ntokens=951.3, nsentences=32, sample_size=951.3, sample_size_v1=0, sample_size_v2=0, ppl=27.5, wps=481.4, ups=0.51, wpb=951.3, bsz=32, num_updates=4140, lr=4.7183e-05, gnorm=1.709, clip=100, loss_scale=512, train_wall=20, gb_free=15.5, wall=11308
2023-01-09 06:46:21 - progress_bar.py[line:272] - INFO: epoch 002:    490 / 3665 loss=5.469, loss_v1=0, loss_v2=0, nll_loss=4.6, ntokens=819.1, nsentences=32, sample_size=819.1, sample_size_v1=0, sample_size_v2=0, ppl=24.25, wps=417, ups=0.51, wpb=819.1, bsz=32, num_updates=4150, lr=4.71684e-05, gnorm=1.945, clip=100, loss_scale=512, train_wall=20, gb_free=15.4, wall=11327
2023-01-09 06:46:41 - progress_bar.py[line:272] - INFO: epoch 002:    500 / 3665 loss=5.36, loss_v1=0, loss_v2=0, nll_loss=4.486, ntokens=921.7, nsentences=32, sample_size=921.7, sample_size_v1=0, sample_size_v2=0, ppl=22.41, wps=468.6, ups=0.51, wpb=921.7, bsz=32, num_updates=4160, lr=4.71539e-05, gnorm=1.856, clip=100, loss_scale=512, train_wall=20, gb_free=15.4, wall=11347
2023-01-09 06:47:00 - progress_bar.py[line:272] - INFO: epoch 002:    510 / 3665 loss=5.607, loss_v1=0, loss_v2=0, nll_loss=4.756, ntokens=959.9, nsentences=32, sample_size=959.9, sample_size_v1=0, sample_size_v2=0, ppl=27.02, wps=487.4, ups=0.51, wpb=959.9, bsz=32, num_updates=4170, lr=4.71394e-05, gnorm=1.668, clip=100, loss_scale=512, train_wall=20, gb_free=15.2, wall=11367
2023-01-09 06:47:20 - progress_bar.py[line:272] - INFO: epoch 002:    520 / 3665 loss=5.505, loss_v1=0, loss_v2=0, nll_loss=4.65, ntokens=985.6, nsentences=32, sample_size=985.6, sample_size_v1=0, sample_size_v2=0, ppl=25.1, wps=500.2, ups=0.51, wpb=985.6, bsz=32, num_updates=4180, lr=4.71249e-05, gnorm=1.58, clip=100, loss_scale=512, train_wall=20, gb_free=15.6, wall=11386
2023-01-09 06:47:40 - progress_bar.py[line:272] - INFO: epoch 002:    530 / 3665 loss=5.417, loss_v1=0, loss_v2=0, nll_loss=4.546, ntokens=937.1, nsentences=32, sample_size=937.1, sample_size_v1=0, sample_size_v2=0, ppl=23.36, wps=474.2, ups=0.51, wpb=937.1, bsz=32, num_updates=4190, lr=4.71104e-05, gnorm=1.633, clip=100, loss_scale=512, train_wall=20, gb_free=15.3, wall=11406
2023-01-09 06:48:00 - progress_bar.py[line:272] - INFO: epoch 002:    540 / 3665 loss=5.449, loss_v1=0, loss_v2=0, nll_loss=4.581, ntokens=743.4, nsentences=32, sample_size=743.4, sample_size_v1=0, sample_size_v2=0, ppl=23.94, wps=373.1, ups=0.5, wpb=743.4, bsz=32, num_updates=4200, lr=4.70959e-05, gnorm=1.913, clip=100, loss_scale=512, train_wall=20, gb_free=15.6, wall=11426
2023-01-09 06:48:20 - progress_bar.py[line:272] - INFO: epoch 002:    550 / 3665 loss=5.47, loss_v1=0, loss_v2=0, nll_loss=4.606, ntokens=937.4, nsentences=32, sample_size=937.4, sample_size_v1=0, sample_size_v2=0, ppl=24.35, wps=467.7, ups=0.5, wpb=937.4, bsz=32, num_updates=4210, lr=4.70814e-05, gnorm=1.671, clip=100, loss_scale=512, train_wall=20, gb_free=15.4, wall=11446
2023-01-09 06:48:40 - progress_bar.py[line:272] - INFO: epoch 002:    560 / 3665 loss=5.519, loss_v1=0, loss_v2=0, nll_loss=4.665, ntokens=1028, nsentences=32, sample_size=1028, sample_size_v1=0, sample_size_v2=0, ppl=25.36, wps=510.7, ups=0.5, wpb=1028, bsz=32, num_updates=4220, lr=4.70668e-05, gnorm=1.806, clip=100, loss_scale=512, train_wall=20, gb_free=15.4, wall=11466
2023-01-09 06:49:00 - progress_bar.py[line:272] - INFO: epoch 002:    570 / 3665 loss=5.332, loss_v1=0, loss_v2=0, nll_loss=4.449, ntokens=657.9, nsentences=32, sample_size=657.9, sample_size_v1=0, sample_size_v2=0, ppl=21.84, wps=331.6, ups=0.5, wpb=657.9, bsz=32, num_updates=4230, lr=4.70523e-05, gnorm=2.207, clip=100, loss_scale=512, train_wall=20, gb_free=15.5, wall=11486
2023-01-09 06:49:02 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 256.0
2023-01-09 06:49:22 - progress_bar.py[line:272] - INFO: epoch 002:    581 / 3665 loss=5.452, loss_v1=0, loss_v2=0, nll_loss=4.586, ntokens=1038, nsentences=32, sample_size=1038, sample_size_v1=0, sample_size_v2=0, ppl=24.01, wps=472.4, ups=0.46, wpb=1038, bsz=32, num_updates=4240, lr=4.70378e-05, gnorm=1.739, clip=100, loss_scale=256, train_wall=22, gb_free=15.4, wall=11508
2023-01-09 06:49:42 - progress_bar.py[line:272] - INFO: epoch 002:    591 / 3665 loss=5.56, loss_v1=0, loss_v2=0, nll_loss=4.706, ntokens=959.6, nsentences=32, sample_size=959.6, sample_size_v1=0, sample_size_v2=0, ppl=26.1, wps=485.3, ups=0.51, wpb=959.6, bsz=32, num_updates=4250, lr=4.70233e-05, gnorm=1.633, clip=100, loss_scale=256, train_wall=20, gb_free=15.3, wall=11528
2023-01-09 06:50:01 - progress_bar.py[line:272] - INFO: epoch 002:    601 / 3665 loss=5.446, loss_v1=0, loss_v2=0, nll_loss=4.58, ntokens=842.4, nsentences=32, sample_size=842.4, sample_size_v1=0, sample_size_v2=0, ppl=23.91, wps=426.4, ups=0.51, wpb=842.4, bsz=32, num_updates=4260, lr=4.70088e-05, gnorm=1.899, clip=100, loss_scale=256, train_wall=20, gb_free=15.4, wall=11548
2023-01-09 06:50:21 - progress_bar.py[line:272] - INFO: epoch 002:    611 / 3665 loss=5.404, loss_v1=0, loss_v2=0, nll_loss=4.53, ntokens=980.1, nsentences=32, sample_size=980.1, sample_size_v1=0, sample_size_v2=0, ppl=23.1, wps=494.9, ups=0.5, wpb=980.1, bsz=32, num_updates=4270, lr=4.69943e-05, gnorm=1.692, clip=100, loss_scale=256, train_wall=20, gb_free=15.5, wall=11567
2023-01-09 06:50:41 - progress_bar.py[line:272] - INFO: epoch 002:    621 / 3665 loss=5.532, loss_v1=0, loss_v2=0, nll_loss=4.674, ntokens=885.5, nsentences=32, sample_size=885.5, sample_size_v1=0, sample_size_v2=0, ppl=25.52, wps=448.3, ups=0.51, wpb=885.5, bsz=32, num_updates=4280, lr=4.69798e-05, gnorm=1.728, clip=100, loss_scale=256, train_wall=20, gb_free=15.7, wall=11587
2023-01-09 06:51:01 - progress_bar.py[line:272] - INFO: epoch 002:    631 / 3665 loss=5.454, loss_v1=0, loss_v2=0, nll_loss=4.592, ntokens=939.3, nsentences=32, sample_size=939.3, sample_size_v1=0, sample_size_v2=0, ppl=24.12, wps=474, ups=0.5, wpb=939.3, bsz=32, num_updates=4290, lr=4.69653e-05, gnorm=1.761, clip=100, loss_scale=256, train_wall=20, gb_free=15.5, wall=11607
2023-01-09 06:51:21 - progress_bar.py[line:272] - INFO: epoch 002:    641 / 3665 loss=5.524, loss_v1=0, loss_v2=0, nll_loss=4.66, ntokens=1069.3, nsentences=32, sample_size=1069.3, sample_size_v1=0, sample_size_v2=0, ppl=25.29, wps=539.2, ups=0.5, wpb=1069.3, bsz=32, num_updates=4300, lr=4.69507e-05, gnorm=1.637, clip=100, loss_scale=256, train_wall=20, gb_free=15.5, wall=11627
2023-01-09 06:51:40 - progress_bar.py[line:272] - INFO: epoch 002:    651 / 3665 loss=5.52, loss_v1=0, loss_v2=0, nll_loss=4.665, ntokens=759.1, nsentences=32, sample_size=759.1, sample_size_v1=0, sample_size_v2=0, ppl=25.38, wps=384, ups=0.51, wpb=759.1, bsz=32, num_updates=4310, lr=4.69362e-05, gnorm=1.882, clip=100, loss_scale=256, train_wall=20, gb_free=15.4, wall=11647
2023-01-09 06:52:00 - progress_bar.py[line:272] - INFO: epoch 002:    661 / 3665 loss=5.412, loss_v1=0, loss_v2=0, nll_loss=4.545, ntokens=870.5, nsentences=32, sample_size=870.5, sample_size_v1=0, sample_size_v2=0, ppl=23.34, wps=439.8, ups=0.51, wpb=870.5, bsz=32, num_updates=4320, lr=4.69217e-05, gnorm=1.79, clip=100, loss_scale=256, train_wall=20, gb_free=15.1, wall=11666
2023-01-09 06:52:20 - progress_bar.py[line:272] - INFO: epoch 002:    671 / 3665 loss=5.546, loss_v1=0, loss_v2=0, nll_loss=4.689, ntokens=979.5, nsentences=32, sample_size=979.5, sample_size_v1=0, sample_size_v2=0, ppl=25.79, wps=495.5, ups=0.51, wpb=979.5, bsz=32, num_updates=4330, lr=4.69072e-05, gnorm=1.665, clip=100, loss_scale=256, train_wall=20, gb_free=15.4, wall=11686
2023-01-09 06:52:40 - progress_bar.py[line:272] - INFO: epoch 002:    681 / 3665 loss=5.497, loss_v1=0, loss_v2=0, nll_loss=4.636, ntokens=855.4, nsentences=32, sample_size=855.4, sample_size_v1=0, sample_size_v2=0, ppl=24.87, wps=431.3, ups=0.5, wpb=855.4, bsz=32, num_updates=4340, lr=4.68927e-05, gnorm=1.708, clip=100, loss_scale=256, train_wall=20, gb_free=15.3, wall=11706
2023-01-09 06:52:59 - progress_bar.py[line:272] - INFO: epoch 002:    691 / 3665 loss=5.364, loss_v1=0, loss_v2=0, nll_loss=4.488, ntokens=879.9, nsentences=32, sample_size=879.9, sample_size_v1=0, sample_size_v2=0, ppl=22.43, wps=445.8, ups=0.51, wpb=879.9, bsz=32, num_updates=4350, lr=4.68782e-05, gnorm=1.787, clip=100, loss_scale=256, train_wall=20, gb_free=15.2, wall=11726
2023-01-09 06:53:19 - progress_bar.py[line:272] - INFO: epoch 002:    701 / 3665 loss=5.562, loss_v1=0, loss_v2=0, nll_loss=4.708, ntokens=983, nsentences=32, sample_size=983, sample_size_v1=0, sample_size_v2=0, ppl=26.13, wps=493.8, ups=0.5, wpb=983, bsz=32, num_updates=4360, lr=4.68637e-05, gnorm=1.581, clip=100, loss_scale=256, train_wall=20, gb_free=15.4, wall=11746
2023-01-09 06:53:39 - progress_bar.py[line:272] - INFO: epoch 002:    711 / 3665 loss=5.467, loss_v1=0, loss_v2=0, nll_loss=4.607, ntokens=779.5, nsentences=32, sample_size=779.5, sample_size_v1=0, sample_size_v2=0, ppl=24.37, wps=394.7, ups=0.51, wpb=779.5, bsz=32, num_updates=4370, lr=4.68491e-05, gnorm=1.756, clip=100, loss_scale=256, train_wall=20, gb_free=15.6, wall=11765
2023-01-09 06:53:59 - progress_bar.py[line:272] - INFO: epoch 002:    721 / 3665 loss=5.5, loss_v1=0, loss_v2=0, nll_loss=4.64, ntokens=1037.4, nsentences=32, sample_size=1037.4, sample_size_v1=0, sample_size_v2=0, ppl=24.93, wps=523.9, ups=0.51, wpb=1037.4, bsz=32, num_updates=4380, lr=4.68346e-05, gnorm=1.702, clip=100, loss_scale=256, train_wall=20, gb_free=15.3, wall=11785
2023-01-09 06:54:19 - progress_bar.py[line:272] - INFO: epoch 002:    731 / 3665 loss=5.598, loss_v1=0, loss_v2=0, nll_loss=4.741, ntokens=870.5, nsentences=32, sample_size=870.5, sample_size_v1=0, sample_size_v2=0, ppl=26.74, wps=439.6, ups=0.5, wpb=870.5, bsz=32, num_updates=4390, lr=4.68201e-05, gnorm=1.767, clip=100, loss_scale=256, train_wall=20, gb_free=15.5, wall=11805
2023-01-09 06:54:38 - progress_bar.py[line:272] - INFO: epoch 002:    741 / 3665 loss=5.462, loss_v1=0, loss_v2=0, nll_loss=4.598, ntokens=857, nsentences=32, sample_size=857, sample_size_v1=0, sample_size_v2=0, ppl=24.22, wps=433.8, ups=0.51, wpb=857, bsz=32, num_updates=4400, lr=4.68056e-05, gnorm=1.818, clip=100, loss_scale=256, train_wall=20, gb_free=15.5, wall=11825
2023-01-09 06:54:58 - progress_bar.py[line:272] - INFO: epoch 002:    751 / 3665 loss=5.412, loss_v1=0, loss_v2=0, nll_loss=4.546, ntokens=965.6, nsentences=32, sample_size=965.6, sample_size_v1=0, sample_size_v2=0, ppl=23.37, wps=486.4, ups=0.5, wpb=965.6, bsz=32, num_updates=4410, lr=4.67911e-05, gnorm=1.693, clip=100, loss_scale=256, train_wall=20, gb_free=15.5, wall=11845
2023-01-09 06:55:18 - progress_bar.py[line:272] - INFO: epoch 002:    761 / 3665 loss=5.532, loss_v1=0, loss_v2=0, nll_loss=4.67, ntokens=842.6, nsentences=32, sample_size=842.6, sample_size_v1=0, sample_size_v2=0, ppl=25.46, wps=426.2, ups=0.51, wpb=842.6, bsz=32, num_updates=4420, lr=4.67766e-05, gnorm=1.758, clip=100, loss_scale=256, train_wall=20, gb_free=14.9, wall=11864
2023-01-09 06:55:38 - progress_bar.py[line:272] - INFO: epoch 002:    771 / 3665 loss=5.463, loss_v1=0, loss_v2=0, nll_loss=4.599, ntokens=959.4, nsentences=32, sample_size=959.4, sample_size_v1=0, sample_size_v2=0, ppl=24.24, wps=484.8, ups=0.51, wpb=959.4, bsz=32, num_updates=4430, lr=4.67621e-05, gnorm=1.637, clip=100, loss_scale=256, train_wall=20, gb_free=15.5, wall=11884
2023-01-09 06:55:58 - progress_bar.py[line:272] - INFO: epoch 002:    781 / 3665 loss=5.457, loss_v1=0, loss_v2=0, nll_loss=4.591, ntokens=973.1, nsentences=32, sample_size=973.1, sample_size_v1=0, sample_size_v2=0, ppl=24.1, wps=489.4, ups=0.5, wpb=973.1, bsz=32, num_updates=4440, lr=4.67476e-05, gnorm=1.638, clip=100, loss_scale=256, train_wall=20, gb_free=15.3, wall=11904
2023-01-09 06:56:18 - progress_bar.py[line:272] - INFO: epoch 002:    791 / 3665 loss=5.422, loss_v1=0, loss_v2=0, nll_loss=4.553, ntokens=755.4, nsentences=32, sample_size=755.4, sample_size_v1=0, sample_size_v2=0, ppl=23.47, wps=381.4, ups=0.5, wpb=755.4, bsz=32, num_updates=4450, lr=4.6733e-05, gnorm=1.749, clip=100, loss_scale=256, train_wall=20, gb_free=15.6, wall=11924
2023-01-09 06:56:37 - progress_bar.py[line:272] - INFO: epoch 002:    801 / 3665 loss=5.486, loss_v1=0, loss_v2=0, nll_loss=4.624, ntokens=1076.7, nsentences=32, sample_size=1076.7, sample_size_v1=0, sample_size_v2=0, ppl=24.66, wps=542.4, ups=0.5, wpb=1076.7, bsz=32, num_updates=4460, lr=4.67185e-05, gnorm=1.58, clip=100, loss_scale=256, train_wall=20, gb_free=15.2, wall=11944
2023-01-09 06:56:57 - progress_bar.py[line:272] - INFO: epoch 002:    811 / 3665 loss=5.453, loss_v1=0, loss_v2=0, nll_loss=4.587, ntokens=880.6, nsentences=32, sample_size=880.6, sample_size_v1=0, sample_size_v2=0, ppl=24.04, wps=445, ups=0.51, wpb=880.6, bsz=32, num_updates=4470, lr=4.6704e-05, gnorm=1.614, clip=100, loss_scale=256, train_wall=20, gb_free=15.5, wall=11964
2023-01-09 06:57:17 - progress_bar.py[line:272] - INFO: epoch 002:    821 / 3665 loss=5.489, loss_v1=0, loss_v2=0, nll_loss=4.628, ntokens=804.3, nsentences=32, sample_size=804.3, sample_size_v1=0, sample_size_v2=0, ppl=24.73, wps=407.9, ups=0.51, wpb=804.3, bsz=32, num_updates=4480, lr=4.66895e-05, gnorm=1.852, clip=100, loss_scale=256, train_wall=20, gb_free=15.4, wall=11983
2023-01-09 06:57:37 - progress_bar.py[line:272] - INFO: epoch 002:    831 / 3665 loss=5.452, loss_v1=0, loss_v2=0, nll_loss=4.586, ntokens=1016.9, nsentences=32, sample_size=1016.9, sample_size_v1=0, sample_size_v2=0, ppl=24.01, wps=511.7, ups=0.5, wpb=1016.9, bsz=32, num_updates=4490, lr=4.6675e-05, gnorm=1.525, clip=100, loss_scale=256, train_wall=20, gb_free=15.2, wall=12003
2023-01-09 06:57:57 - progress_bar.py[line:272] - INFO: epoch 002:    841 / 3665 loss=5.485, loss_v1=0, loss_v2=0, nll_loss=4.623, ntokens=776.2, nsentences=32, sample_size=776.2, sample_size_v1=0, sample_size_v2=0, ppl=24.65, wps=392.8, ups=0.51, wpb=776.2, bsz=32, num_updates=4500, lr=4.66605e-05, gnorm=1.815, clip=100, loss_scale=256, train_wall=20, gb_free=15.6, wall=12023
2023-01-09 06:57:57 - train.py[line:445] - INFO: begin validation on "valid" subset
slice_id 0 seek offset 0
slice_id 0 seek offset 0
2023-01-09 07:02:42 - progress_bar.py[line:282] - INFO: epoch 002 | valid on 'valid' subset | loss 5.465 | loss_v1 0 | loss_v2 0 | nll_loss 4.582 | ntokens 117.365 | nsentences 4 | sample_size 117.365 | sample_size_v1 0 | sample_size_v2 0 | AP 0 | total positives 21.7843 | TP 0 | FP 7.39257 | ppl 23.95 | wps 516.3 | wpb 117.4 | bsz 4 | num_updates 4500 | best_AP 0
2023-01-09 07:02:42 - checkpoint_utils.py[line:64] - INFO: Preparing to save checkpoint for epoch 2 @ 4500 updates
2023-01-09 07:02:42 - trainer.py[line:431] - INFO: Saving checkpoint to ../../checkpoints/OFA/detection_checkpoints/10_5e-5_512/checkpoint_2_4500.pt
2023-01-09 07:02:45 - trainer.py[line:441] - INFO: Finished saving checkpoint to ../../checkpoints/OFA/detection_checkpoints/10_5e-5_512/checkpoint_2_4500.pt
2023-01-09 07:03:56 - checkpoint_utils.py[line:133] - INFO: Saved checkpoint ../../checkpoints/OFA/detection_checkpoints/10_5e-5_512/checkpoint_2_4500.pt (epoch 2 @ 4500 updates, score 0.0) (writing took 74.18194720102474 seconds)
2023-01-09 07:04:15 - progress_bar.py[line:272] - INFO: epoch 002:    851 / 3665 loss=5.448, loss_v1=0, loss_v2=0, nll_loss=4.579, ntokens=844.9, nsentences=32, sample_size=844.9, sample_size_v1=0, sample_size_v2=0, ppl=23.9, wps=22.3, ups=0.03, wpb=844.9, bsz=32, num_updates=4510, lr=4.6646e-05, gnorm=1.944, clip=100, loss_scale=256, train_wall=19, gb_free=15.3, wall=12402
2023-01-09 07:04:35 - progress_bar.py[line:272] - INFO: epoch 002:    861 / 3665 loss=5.413, loss_v1=0, loss_v2=0, nll_loss=4.543, ntokens=1037, nsentences=32, sample_size=1037, sample_size_v1=0, sample_size_v2=0, ppl=23.32, wps=531.7, ups=0.51, wpb=1037, bsz=32, num_updates=4520, lr=4.66314e-05, gnorm=1.767, clip=100, loss_scale=256, train_wall=19, gb_free=15.4, wall=12421
2023-01-09 07:04:54 - progress_bar.py[line:272] - INFO: epoch 002:    871 / 3665 loss=5.566, loss_v1=0, loss_v2=0, nll_loss=4.713, ntokens=960.5, nsentences=32, sample_size=960.5, sample_size_v1=0, sample_size_v2=0, ppl=26.23, wps=491.1, ups=0.51, wpb=960.5, bsz=32, num_updates=4530, lr=4.66169e-05, gnorm=1.53, clip=100, loss_scale=256, train_wall=20, gb_free=15.4, wall=12441
2023-01-09 07:05:14 - progress_bar.py[line:272] - INFO: epoch 002:    881 / 3665 loss=5.342, loss_v1=0, loss_v2=0, nll_loss=4.463, ntokens=893.1, nsentences=32, sample_size=893.1, sample_size_v1=0, sample_size_v2=0, ppl=22.05, wps=455.2, ups=0.51, wpb=893.1, bsz=32, num_updates=4540, lr=4.66024e-05, gnorm=1.638, clip=100, loss_scale=256, train_wall=20, gb_free=15.4, wall=12460
2023-01-09 07:05:34 - progress_bar.py[line:272] - INFO: epoch 002:    891 / 3665 loss=5.429, loss_v1=0, loss_v2=0, nll_loss=4.559, ntokens=1017, nsentences=32, sample_size=1017, sample_size_v1=0, sample_size_v2=0, ppl=23.57, wps=515.8, ups=0.51, wpb=1017, bsz=32, num_updates=4550, lr=4.65879e-05, gnorm=1.659, clip=100, loss_scale=256, train_wall=20, gb_free=15.2, wall=12480
2023-01-09 07:05:53 - progress_bar.py[line:272] - INFO: epoch 002:    901 / 3665 loss=5.571, loss_v1=0, loss_v2=0, nll_loss=4.719, ntokens=1021.8, nsentences=32, sample_size=1021.8, sample_size_v1=0, sample_size_v2=0, ppl=26.33, wps=520.4, ups=0.51, wpb=1021.8, bsz=32, num_updates=4560, lr=4.65734e-05, gnorm=1.561, clip=100, loss_scale=256, train_wall=20, gb_free=15.4, wall=12500
2023-01-09 07:06:13 - progress_bar.py[line:272] - INFO: epoch 002:    911 / 3665 loss=5.401, loss_v1=0, loss_v2=0, nll_loss=4.533, ntokens=954.6, nsentences=32, sample_size=954.6, sample_size_v1=0, sample_size_v2=0, ppl=23.15, wps=487.2, ups=0.51, wpb=954.6, bsz=32, num_updates=4570, lr=4.65589e-05, gnorm=1.671, clip=100, loss_scale=256, train_wall=20, gb_free=15.5, wall=12519
2023-01-09 07:06:33 - progress_bar.py[line:272] - INFO: epoch 002:    921 / 3665 loss=5.511, loss_v1=0, loss_v2=0, nll_loss=4.647, ntokens=992.5, nsentences=32, sample_size=992.5, sample_size_v1=0, sample_size_v2=0, ppl=25.05, wps=505.2, ups=0.51, wpb=992.5, bsz=32, num_updates=4580, lr=4.65444e-05, gnorm=1.539, clip=100, loss_scale=256, train_wall=20, gb_free=15.1, wall=12539
2023-01-09 07:06:52 - progress_bar.py[line:272] - INFO: epoch 002:    931 / 3665 loss=5.5, loss_v1=0, loss_v2=0, nll_loss=4.64, ntokens=829.1, nsentences=32, sample_size=829.1, sample_size_v1=0, sample_size_v2=0, ppl=24.93, wps=423.4, ups=0.51, wpb=829.1, bsz=32, num_updates=4590, lr=4.65299e-05, gnorm=1.709, clip=100, loss_scale=256, train_wall=20, gb_free=15.5, wall=12558
2023-01-09 07:07:12 - progress_bar.py[line:272] - INFO: epoch 002:    941 / 3665 loss=5.431, loss_v1=0, loss_v2=0, nll_loss=4.565, ntokens=953.2, nsentences=32, sample_size=953.2, sample_size_v1=0, sample_size_v2=0, ppl=23.67, wps=485.3, ups=0.51, wpb=953.2, bsz=32, num_updates=4600, lr=4.65153e-05, gnorm=1.569, clip=100, loss_scale=256, train_wall=20, gb_free=15.5, wall=12578
2023-01-09 07:07:31 - progress_bar.py[line:272] - INFO: epoch 002:    951 / 3665 loss=5.372, loss_v1=0, loss_v2=0, nll_loss=4.495, ntokens=853.2, nsentences=32, sample_size=853.2, sample_size_v1=0, sample_size_v2=0, ppl=22.54, wps=435.6, ups=0.51, wpb=853.2, bsz=32, num_updates=4610, lr=4.65008e-05, gnorm=1.727, clip=100, loss_scale=256, train_wall=20, gb_free=15.7, wall=12598
2023-01-09 07:07:51 - progress_bar.py[line:272] - INFO: epoch 002:    961 / 3665 loss=5.433, loss_v1=0, loss_v2=0, nll_loss=4.568, ntokens=832.7, nsentences=32, sample_size=832.7, sample_size_v1=0, sample_size_v2=0, ppl=23.72, wps=425.7, ups=0.51, wpb=832.7, bsz=32, num_updates=4620, lr=4.64863e-05, gnorm=2.115, clip=100, loss_scale=256, train_wall=20, gb_free=15.3, wall=12617
2023-01-09 07:08:11 - progress_bar.py[line:272] - INFO: epoch 002:    971 / 3665 loss=5.364, loss_v1=0, loss_v2=0, nll_loss=4.486, ntokens=935.5, nsentences=32, sample_size=935.5, sample_size_v1=0, sample_size_v2=0, ppl=22.4, wps=477.2, ups=0.51, wpb=935.5, bsz=32, num_updates=4630, lr=4.64718e-05, gnorm=1.546, clip=100, loss_scale=256, train_wall=20, gb_free=15.7, wall=12637
2023-01-09 07:08:30 - progress_bar.py[line:272] - INFO: epoch 002:    981 / 3665 loss=5.549, loss_v1=0, loss_v2=0, nll_loss=4.697, ntokens=919.6, nsentences=32, sample_size=919.6, sample_size_v1=0, sample_size_v2=0, ppl=25.94, wps=466.4, ups=0.51, wpb=919.6, bsz=32, num_updates=4640, lr=4.64573e-05, gnorm=1.671, clip=100, loss_scale=256, train_wall=20, gb_free=15.3, wall=12657
2023-01-09 07:08:50 - progress_bar.py[line:272] - INFO: epoch 002:    991 / 3665 loss=5.423, loss_v1=0, loss_v2=0, nll_loss=4.552, ntokens=832.3, nsentences=32, sample_size=832.3, sample_size_v1=0, sample_size_v2=0, ppl=23.46, wps=424.4, ups=0.51, wpb=832.3, bsz=32, num_updates=4650, lr=4.64428e-05, gnorm=1.961, clip=100, loss_scale=256, train_wall=20, gb_free=15.5, wall=12676
2023-01-09 07:09:10 - progress_bar.py[line:272] - INFO: epoch 002:   1001 / 3665 loss=5.482, loss_v1=0, loss_v2=0, nll_loss=4.616, ntokens=1080, nsentences=32, sample_size=1080, sample_size_v1=0, sample_size_v2=0, ppl=24.53, wps=546.5, ups=0.51, wpb=1080, bsz=32, num_updates=4660, lr=4.64283e-05, gnorm=1.476, clip=100, loss_scale=256, train_wall=20, gb_free=14.7, wall=12696
2023-01-09 07:09:29 - progress_bar.py[line:272] - INFO: epoch 002:   1011 / 3665 loss=5.504, loss_v1=0, loss_v2=0, nll_loss=4.647, ntokens=812.9, nsentences=32, sample_size=812.9, sample_size_v1=0, sample_size_v2=0, ppl=25.05, wps=412.1, ups=0.51, wpb=812.9, bsz=32, num_updates=4670, lr=4.64137e-05, gnorm=1.802, clip=100, loss_scale=256, train_wall=20, gb_free=15.3, wall=12716
2023-01-09 07:09:50 - progress_bar.py[line:272] - INFO: epoch 002:   1021 / 3665 loss=5.402, loss_v1=0, loss_v2=0, nll_loss=4.531, ntokens=887.5, nsentences=32, sample_size=887.5, sample_size_v1=0, sample_size_v2=0, ppl=23.12, wps=440.4, ups=0.5, wpb=887.5, bsz=32, num_updates=4680, lr=4.63992e-05, gnorm=1.709, clip=100, loss_scale=256, train_wall=20, gb_free=15.1, wall=12736
2023-01-09 07:10:10 - progress_bar.py[line:272] - INFO: epoch 002:   1031 / 3665 loss=5.505, loss_v1=0, loss_v2=0, nll_loss=4.642, ntokens=1054.4, nsentences=32, sample_size=1054.4, sample_size_v1=0, sample_size_v2=0, ppl=24.97, wps=521.9, ups=0.5, wpb=1054.4, bsz=32, num_updates=4690, lr=4.63847e-05, gnorm=1.697, clip=100, loss_scale=256, train_wall=20, gb_free=15, wall=12756
2023-01-09 07:10:30 - progress_bar.py[line:272] - INFO: epoch 002:   1041 / 3665 loss=5.329, loss_v1=0, loss_v2=0, nll_loss=4.449, ntokens=583.8, nsentences=32, sample_size=583.8, sample_size_v1=0, sample_size_v2=0, ppl=21.85, wps=293.1, ups=0.5, wpb=583.8, bsz=32, num_updates=4700, lr=4.63702e-05, gnorm=2.393, clip=100, loss_scale=256, train_wall=20, gb_free=15.5, wall=12776
2023-01-09 07:10:49 - progress_bar.py[line:272] - INFO: epoch 002:   1051 / 3665 loss=5.399, loss_v1=0, loss_v2=0, nll_loss=4.526, ntokens=888.8, nsentences=32, sample_size=888.8, sample_size_v1=0, sample_size_v2=0, ppl=23.04, wps=448.6, ups=0.5, wpb=888.8, bsz=32, num_updates=4710, lr=4.63557e-05, gnorm=1.907, clip=100, loss_scale=256, train_wall=20, gb_free=15.3, wall=12796
2023-01-09 07:11:09 - progress_bar.py[line:272] - INFO: epoch 002:   1061 / 3665 loss=5.534, loss_v1=0, loss_v2=0, nll_loss=4.677, ntokens=1031.9, nsentences=32, sample_size=1031.9, sample_size_v1=0, sample_size_v2=0, ppl=25.58, wps=521.7, ups=0.51, wpb=1031.9, bsz=32, num_updates=4720, lr=4.63412e-05, gnorm=1.521, clip=100, loss_scale=256, train_wall=20, gb_free=15.4, wall=12816
2023-01-09 07:11:29 - progress_bar.py[line:272] - INFO: epoch 002:   1071 / 3665 loss=5.38, loss_v1=0, loss_v2=0, nll_loss=4.505, ntokens=739, nsentences=32, sample_size=739, sample_size_v1=0, sample_size_v2=0, ppl=22.71, wps=376.6, ups=0.51, wpb=739, bsz=32, num_updates=4730, lr=4.63267e-05, gnorm=1.929, clip=100, loss_scale=256, train_wall=20, gb_free=15.7, wall=12835
2023-01-09 07:11:49 - progress_bar.py[line:272] - INFO: epoch 002:   1081 / 3665 loss=5.438, loss_v1=0, loss_v2=0, nll_loss=4.572, ntokens=1054.2, nsentences=32, sample_size=1054.2, sample_size_v1=0, sample_size_v2=0, ppl=23.78, wps=534.9, ups=0.51, wpb=1054.2, bsz=32, num_updates=4740, lr=4.63122e-05, gnorm=1.627, clip=100, loss_scale=256, train_wall=20, gb_free=15.5, wall=12855
2023-01-09 07:12:08 - progress_bar.py[line:272] - INFO: epoch 002:   1091 / 3665 loss=5.436, loss_v1=0, loss_v2=0, nll_loss=4.57, ntokens=835.8, nsentences=32, sample_size=835.8, sample_size_v1=0, sample_size_v2=0, ppl=23.75, wps=425.2, ups=0.51, wpb=835.8, bsz=32, num_updates=4750, lr=4.62976e-05, gnorm=1.789, clip=100, loss_scale=512, train_wall=20, gb_free=15.5, wall=12875
2023-01-09 07:12:28 - progress_bar.py[line:272] - INFO: epoch 002:   1101 / 3665 loss=5.408, loss_v1=0, loss_v2=0, nll_loss=4.536, ntokens=975.9, nsentences=32, sample_size=975.9, sample_size_v1=0, sample_size_v2=0, ppl=23.19, wps=495.4, ups=0.51, wpb=975.9, bsz=32, num_updates=4760, lr=4.62831e-05, gnorm=1.704, clip=100, loss_scale=512, train_wall=20, gb_free=15.4, wall=12894
2023-01-09 07:12:48 - progress_bar.py[line:272] - INFO: epoch 002:   1111 / 3665 loss=5.459, loss_v1=0, loss_v2=0, nll_loss=4.592, ntokens=769.2, nsentences=32, sample_size=769.2, sample_size_v1=0, sample_size_v2=0, ppl=24.12, wps=390.6, ups=0.51, wpb=769.2, bsz=32, num_updates=4770, lr=4.62686e-05, gnorm=1.798, clip=100, loss_scale=512, train_wall=20, gb_free=15.3, wall=12914
2023-01-09 07:13:07 - progress_bar.py[line:272] - INFO: epoch 002:   1121 / 3665 loss=5.418, loss_v1=0, loss_v2=0, nll_loss=4.546, ntokens=1127.6, nsentences=32, sample_size=1127.6, sample_size_v1=0, sample_size_v2=0, ppl=23.36, wps=570.6, ups=0.51, wpb=1127.6, bsz=32, num_updates=4780, lr=4.62541e-05, gnorm=1.559, clip=100, loss_scale=512, train_wall=20, gb_free=15.5, wall=12934
2023-01-09 07:13:27 - progress_bar.py[line:272] - INFO: epoch 002:   1131 / 3665 loss=5.393, loss_v1=0, loss_v2=0, nll_loss=4.521, ntokens=1061.7, nsentences=32, sample_size=1061.7, sample_size_v1=0, sample_size_v2=0, ppl=22.96, wps=538.2, ups=0.51, wpb=1061.7, bsz=32, num_updates=4790, lr=4.62396e-05, gnorm=1.613, clip=100, loss_scale=512, train_wall=20, gb_free=14.9, wall=12953
2023-01-09 07:13:47 - progress_bar.py[line:272] - INFO: epoch 002:   1141 / 3665 loss=5.487, loss_v1=0, loss_v2=0, nll_loss=4.626, ntokens=797.9, nsentences=32, sample_size=797.9, sample_size_v1=0, sample_size_v2=0, ppl=24.7, wps=405.9, ups=0.51, wpb=797.9, bsz=32, num_updates=4800, lr=4.62251e-05, gnorm=1.853, clip=100, loss_scale=512, train_wall=20, gb_free=15.5, wall=12973
2023-01-09 07:14:06 - progress_bar.py[line:272] - INFO: epoch 002:   1151 / 3665 loss=5.433, loss_v1=0, loss_v2=0, nll_loss=4.565, ntokens=847.4, nsentences=32, sample_size=847.4, sample_size_v1=0, sample_size_v2=0, ppl=23.67, wps=430.3, ups=0.51, wpb=847.4, bsz=32, num_updates=4810, lr=4.62106e-05, gnorm=1.8, clip=100, loss_scale=512, train_wall=20, gb_free=15.5, wall=12993
2023-01-09 07:14:14 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 256.0
2023-01-09 07:14:28 - progress_bar.py[line:272] - INFO: epoch 002:   1162 / 3665 loss=5.35, loss_v1=0, loss_v2=0, nll_loss=4.474, ntokens=972, nsentences=32, sample_size=972, sample_size_v1=0, sample_size_v2=0, ppl=22.22, wps=448.7, ups=0.46, wpb=972, bsz=32, num_updates=4820, lr=4.6196e-05, gnorm=1.799, clip=100, loss_scale=256, train_wall=22, gb_free=15.2, wall=13014
2023-01-09 07:14:48 - progress_bar.py[line:272] - INFO: epoch 002:   1172 / 3665 loss=5.471, loss_v1=0, loss_v2=0, nll_loss=4.607, ntokens=893, nsentences=32, sample_size=893, sample_size_v1=0, sample_size_v2=0, ppl=24.38, wps=453.2, ups=0.51, wpb=893, bsz=32, num_updates=4830, lr=4.61815e-05, gnorm=1.914, clip=100, loss_scale=256, train_wall=20, gb_free=15.6, wall=13034
2023-01-09 07:15:08 - progress_bar.py[line:272] - INFO: epoch 002:   1182 / 3665 loss=5.426, loss_v1=0, loss_v2=0, nll_loss=4.554, ntokens=844.1, nsentences=32, sample_size=844.1, sample_size_v1=0, sample_size_v2=0, ppl=23.49, wps=428.5, ups=0.51, wpb=844.1, bsz=32, num_updates=4840, lr=4.6167e-05, gnorm=2.332, clip=100, loss_scale=256, train_wall=20, gb_free=15.3, wall=13054
2023-01-09 07:15:27 - progress_bar.py[line:272] - INFO: epoch 002:   1192 / 3665 loss=5.457, loss_v1=0, loss_v2=0, nll_loss=4.59, ntokens=1105.4, nsentences=32, sample_size=1105.4, sample_size_v1=0, sample_size_v2=0, ppl=24.08, wps=559, ups=0.51, wpb=1105.4, bsz=32, num_updates=4850, lr=4.61525e-05, gnorm=1.559, clip=100, loss_scale=256, train_wall=20, gb_free=15.3, wall=13074
2023-01-09 07:15:47 - progress_bar.py[line:272] - INFO: epoch 002:   1202 / 3665 loss=5.514, loss_v1=0, loss_v2=0, nll_loss=4.658, ntokens=1042.9, nsentences=32, sample_size=1042.9, sample_size_v1=0, sample_size_v2=0, ppl=25.25, wps=527, ups=0.51, wpb=1042.9, bsz=32, num_updates=4860, lr=4.6138e-05, gnorm=1.612, clip=100, loss_scale=256, train_wall=20, gb_free=15.1, wall=13093
2023-01-09 07:16:07 - progress_bar.py[line:272] - INFO: epoch 002:   1212 / 3665 loss=5.424, loss_v1=0, loss_v2=0, nll_loss=4.551, ntokens=775.7, nsentences=32, sample_size=775.7, sample_size_v1=0, sample_size_v2=0, ppl=23.44, wps=395.7, ups=0.51, wpb=775.7, bsz=32, num_updates=4870, lr=4.61235e-05, gnorm=2.058, clip=100, loss_scale=256, train_wall=20, gb_free=15.4, wall=13113
2023-01-09 07:16:26 - progress_bar.py[line:272] - INFO: epoch 002:   1222 / 3665 loss=5.476, loss_v1=0, loss_v2=0, nll_loss=4.614, ntokens=1075.3, nsentences=32, sample_size=1075.3, sample_size_v1=0, sample_size_v2=0, ppl=24.49, wps=544.1, ups=0.51, wpb=1075.3, bsz=32, num_updates=4880, lr=4.6109e-05, gnorm=1.571, clip=100, loss_scale=256, train_wall=20, gb_free=15.2, wall=13133
2023-01-09 07:16:46 - progress_bar.py[line:272] - INFO: epoch 002:   1232 / 3665 loss=5.531, loss_v1=0, loss_v2=0, nll_loss=4.672, ntokens=1056.8, nsentences=32, sample_size=1056.8, sample_size_v1=0, sample_size_v2=0, ppl=25.5, wps=533.4, ups=0.5, wpb=1056.8, bsz=32, num_updates=4890, lr=4.60945e-05, gnorm=1.444, clip=100, loss_scale=256, train_wall=20, gb_free=15.3, wall=13153
2023-01-09 07:17:06 - progress_bar.py[line:272] - INFO: epoch 002:   1242 / 3665 loss=5.526, loss_v1=0, loss_v2=0, nll_loss=4.669, ntokens=943.1, nsentences=32, sample_size=943.1, sample_size_v1=0, sample_size_v2=0, ppl=25.45, wps=477.9, ups=0.51, wpb=943.1, bsz=32, num_updates=4900, lr=4.60799e-05, gnorm=1.619, clip=100, loss_scale=256, train_wall=20, gb_free=15.2, wall=13172
2023-01-09 07:17:26 - progress_bar.py[line:272] - INFO: epoch 002:   1252 / 3665 loss=5.405, loss_v1=0, loss_v2=0, nll_loss=4.531, ntokens=977.1, nsentences=32, sample_size=977.1, sample_size_v1=0, sample_size_v2=0, ppl=23.12, wps=496, ups=0.51, wpb=977.1, bsz=32, num_updates=4910, lr=4.60654e-05, gnorm=1.645, clip=100, loss_scale=256, train_wall=20, gb_free=15.6, wall=13192
2023-01-09 07:17:46 - progress_bar.py[line:272] - INFO: epoch 002:   1262 / 3665 loss=5.49, loss_v1=0, loss_v2=0, nll_loss=4.626, ntokens=1090.4, nsentences=32, sample_size=1090.4, sample_size_v1=0, sample_size_v2=0, ppl=24.7, wps=550.6, ups=0.5, wpb=1090.4, bsz=32, num_updates=4920, lr=4.60509e-05, gnorm=1.625, clip=100, loss_scale=256, train_wall=20, gb_free=15.1, wall=13212
2023-01-09 07:18:05 - progress_bar.py[line:272] - INFO: epoch 002:   1272 / 3665 loss=5.401, loss_v1=0, loss_v2=0, nll_loss=4.534, ntokens=674.7, nsentences=32, sample_size=674.7, sample_size_v1=0, sample_size_v2=0, ppl=23.17, wps=344.3, ups=0.51, wpb=674.7, bsz=32, num_updates=4930, lr=4.60364e-05, gnorm=2.29, clip=100, loss_scale=256, train_wall=20, gb_free=15.4, wall=13231
2023-01-09 07:18:25 - progress_bar.py[line:272] - INFO: epoch 002:   1282 / 3665 loss=5.379, loss_v1=0, loss_v2=0, nll_loss=4.502, ntokens=821.9, nsentences=32, sample_size=821.9, sample_size_v1=0, sample_size_v2=0, ppl=22.65, wps=418.5, ups=0.51, wpb=821.9, bsz=32, num_updates=4940, lr=4.60219e-05, gnorm=1.79, clip=100, loss_scale=256, train_wall=20, gb_free=15.7, wall=13251
2023-01-09 07:18:45 - progress_bar.py[line:272] - INFO: epoch 002:   1292 / 3665 loss=5.447, loss_v1=0, loss_v2=0, nll_loss=4.58, ntokens=1081.7, nsentences=32, sample_size=1081.7, sample_size_v1=0, sample_size_v2=0, ppl=23.93, wps=546.5, ups=0.51, wpb=1081.7, bsz=32, num_updates=4950, lr=4.60074e-05, gnorm=1.466, clip=100, loss_scale=256, train_wall=20, gb_free=15.4, wall=13271
2023-01-09 07:19:04 - progress_bar.py[line:272] - INFO: epoch 002:   1302 / 3665 loss=5.417, loss_v1=0, loss_v2=0, nll_loss=4.551, ntokens=813.6, nsentences=32, sample_size=813.6, sample_size_v1=0, sample_size_v2=0, ppl=23.44, wps=413.1, ups=0.51, wpb=813.6, bsz=32, num_updates=4960, lr=4.59929e-05, gnorm=1.766, clip=100, loss_scale=256, train_wall=20, gb_free=15.6, wall=13291
2023-01-09 07:19:24 - progress_bar.py[line:272] - INFO: epoch 002:   1312 / 3665 loss=5.412, loss_v1=0, loss_v2=0, nll_loss=4.54, ntokens=979.3, nsentences=32, sample_size=979.3, sample_size_v1=0, sample_size_v2=0, ppl=23.26, wps=496.4, ups=0.51, wpb=979.3, bsz=32, num_updates=4970, lr=4.59783e-05, gnorm=1.801, clip=100, loss_scale=256, train_wall=20, gb_free=15.2, wall=13310
2023-01-09 07:19:44 - progress_bar.py[line:272] - INFO: epoch 002:   1322 / 3665 loss=5.38, loss_v1=0, loss_v2=0, nll_loss=4.505, ntokens=1013.7, nsentences=32, sample_size=1013.7, sample_size_v1=0, sample_size_v2=0, ppl=22.71, wps=514.1, ups=0.51, wpb=1013.7, bsz=32, num_updates=4980, lr=4.59638e-05, gnorm=1.481, clip=100, loss_scale=256, train_wall=20, gb_free=15.3, wall=13330
2023-01-09 07:20:03 - progress_bar.py[line:272] - INFO: epoch 002:   1332 / 3665 loss=5.571, loss_v1=0, loss_v2=0, nll_loss=4.719, ntokens=825.4, nsentences=32, sample_size=825.4, sample_size_v1=0, sample_size_v2=0, ppl=26.34, wps=420.1, ups=0.51, wpb=825.4, bsz=32, num_updates=4990, lr=4.59493e-05, gnorm=1.744, clip=100, loss_scale=256, train_wall=20, gb_free=15.7, wall=13350
2023-01-09 07:20:23 - progress_bar.py[line:272] - INFO: epoch 002:   1342 / 3665 loss=5.402, loss_v1=0, loss_v2=0, nll_loss=4.528, ntokens=934, nsentences=32, sample_size=934, sample_size_v1=0, sample_size_v2=0, ppl=23.07, wps=473.9, ups=0.51, wpb=934, bsz=32, num_updates=5000, lr=4.59348e-05, gnorm=1.71, clip=100, loss_scale=256, train_wall=20, gb_free=15.5, wall=13369
2023-01-09 07:20:23 - train.py[line:445] - INFO: begin validation on "valid" subset
slice_id 0 seek offset 0
slice_id 0 seek offset 0
2023-01-09 07:25:14 - progress_bar.py[line:282] - INFO: epoch 002 | valid on 'valid' subset | loss 5.435 | loss_v1 0 | loss_v2 0 | nll_loss 4.55 | ntokens 117.515 | nsentences 4 | sample_size 117.515 | sample_size_v1 0 | sample_size_v2 0 | AP 0 | total positives 21.8037 | TP 0 | FP 6.91842 | ppl 23.42 | wps 506 | wpb 117.5 | bsz 4 | num_updates 5000 | best_AP 0
2023-01-09 07:25:14 - checkpoint_utils.py[line:64] - INFO: Preparing to save checkpoint for epoch 2 @ 5000 updates
2023-01-09 07:25:14 - trainer.py[line:431] - INFO: Saving checkpoint to ../../checkpoints/OFA/detection_checkpoints/10_5e-5_512/checkpoint_2_5000.pt
2023-01-09 07:25:17 - trainer.py[line:441] - INFO: Finished saving checkpoint to ../../checkpoints/OFA/detection_checkpoints/10_5e-5_512/checkpoint_2_5000.pt
2023-01-09 07:26:29 - checkpoint_utils.py[line:133] - INFO: Saved checkpoint ../../checkpoints/OFA/detection_checkpoints/10_5e-5_512/checkpoint_2_5000.pt (epoch 2 @ 5000 updates, score 0.0) (writing took 75.19090613210574 seconds)
2023-01-09 07:26:49 - progress_bar.py[line:272] - INFO: epoch 002:   1352 / 3665 loss=5.346, loss_v1=0, loss_v2=0, nll_loss=4.466, ntokens=984.5, nsentences=32, sample_size=984.5, sample_size_v1=0, sample_size_v2=0, ppl=22.09, wps=25.5, ups=0.03, wpb=984.5, bsz=32, num_updates=5010, lr=4.59203e-05, gnorm=1.497, clip=100, loss_scale=256, train_wall=20, gb_free=15, wall=13755
2023-01-09 07:27:08 - progress_bar.py[line:272] - INFO: epoch 002:   1362 / 3665 loss=5.477, loss_v1=0, loss_v2=0, nll_loss=4.616, ntokens=932.6, nsentences=32, sample_size=932.6, sample_size_v1=0, sample_size_v2=0, ppl=24.52, wps=479.5, ups=0.51, wpb=932.6, bsz=32, num_updates=5020, lr=4.59058e-05, gnorm=1.737, clip=100, loss_scale=256, train_wall=19, gb_free=15.5, wall=13774
2023-01-09 07:27:28 - progress_bar.py[line:272] - INFO: epoch 002:   1372 / 3665 loss=5.432, loss_v1=0, loss_v2=0, nll_loss=4.564, ntokens=890.6, nsentences=32, sample_size=890.6, sample_size_v1=0, sample_size_v2=0, ppl=23.65, wps=456.3, ups=0.51, wpb=890.6, bsz=32, num_updates=5030, lr=4.58913e-05, gnorm=1.794, clip=100, loss_scale=256, train_wall=19, gb_free=15.5, wall=13794
2023-01-09 07:27:47 - progress_bar.py[line:272] - INFO: epoch 002:   1382 / 3665 loss=5.353, loss_v1=0, loss_v2=0, nll_loss=4.474, ntokens=963.7, nsentences=32, sample_size=963.7, sample_size_v1=0, sample_size_v2=0, ppl=22.22, wps=491.5, ups=0.51, wpb=963.7, bsz=32, num_updates=5040, lr=4.58768e-05, gnorm=1.643, clip=100, loss_scale=256, train_wall=20, gb_free=15.4, wall=13813
2023-01-09 07:28:07 - progress_bar.py[line:272] - INFO: epoch 002:   1392 / 3665 loss=5.399, loss_v1=0, loss_v2=0, nll_loss=4.527, ntokens=760, nsentences=32, sample_size=760, sample_size_v1=0, sample_size_v2=0, ppl=23.06, wps=390, ups=0.51, wpb=760, bsz=32, num_updates=5050, lr=4.58622e-05, gnorm=1.832, clip=100, loss_scale=256, train_wall=19, gb_free=15.6, wall=13833
2023-01-09 07:28:26 - progress_bar.py[line:272] - INFO: epoch 002:   1402 / 3665 loss=5.366, loss_v1=0, loss_v2=0, nll_loss=4.49, ntokens=762.9, nsentences=32, sample_size=762.9, sample_size_v1=0, sample_size_v2=0, ppl=22.47, wps=391, ups=0.51, wpb=762.9, bsz=32, num_updates=5060, lr=4.58477e-05, gnorm=2.024, clip=100, loss_scale=256, train_wall=19, gb_free=15.5, wall=13852
2023-01-09 07:28:46 - progress_bar.py[line:272] - INFO: epoch 002:   1412 / 3665 loss=5.354, loss_v1=0, loss_v2=0, nll_loss=4.476, ntokens=880.9, nsentences=32, sample_size=880.9, sample_size_v1=0, sample_size_v2=0, ppl=22.25, wps=450.7, ups=0.51, wpb=880.9, bsz=32, num_updates=5070, lr=4.58332e-05, gnorm=1.819, clip=100, loss_scale=256, train_wall=20, gb_free=15.3, wall=13872
2023-01-09 07:29:05 - progress_bar.py[line:272] - INFO: epoch 002:   1422 / 3665 loss=5.439, loss_v1=0, loss_v2=0, nll_loss=4.572, ntokens=968.9, nsentences=32, sample_size=968.9, sample_size_v1=0, sample_size_v2=0, ppl=23.78, wps=493.4, ups=0.51, wpb=968.9, bsz=32, num_updates=5080, lr=4.58187e-05, gnorm=1.581, clip=100, loss_scale=256, train_wall=20, gb_free=15.5, wall=13892
2023-01-09 07:29:25 - progress_bar.py[line:272] - INFO: epoch 002:   1432 / 3665 loss=5.391, loss_v1=0, loss_v2=0, nll_loss=4.52, ntokens=740.6, nsentences=32, sample_size=740.6, sample_size_v1=0, sample_size_v2=0, ppl=22.94, wps=379.4, ups=0.51, wpb=740.6, bsz=32, num_updates=5090, lr=4.58042e-05, gnorm=2.164, clip=100, loss_scale=256, train_wall=19, gb_free=15.5, wall=13911
2023-01-09 07:29:44 - progress_bar.py[line:272] - INFO: epoch 002:   1442 / 3665 loss=5.45, loss_v1=0, loss_v2=0, nll_loss=4.583, ntokens=946.4, nsentences=32, sample_size=946.4, sample_size_v1=0, sample_size_v2=0, ppl=23.97, wps=483.6, ups=0.51, wpb=946.4, bsz=32, num_updates=5100, lr=4.57897e-05, gnorm=1.881, clip=100, loss_scale=256, train_wall=20, gb_free=15.5, wall=13931
2023-01-09 07:30:04 - progress_bar.py[line:272] - INFO: epoch 002:   1452 / 3665 loss=5.511, loss_v1=0, loss_v2=0, nll_loss=4.646, ntokens=1012.4, nsentences=32, sample_size=1012.4, sample_size_v1=0, sample_size_v2=0, ppl=25.03, wps=515.9, ups=0.51, wpb=1012.4, bsz=32, num_updates=5110, lr=4.57752e-05, gnorm=1.571, clip=100, loss_scale=256, train_wall=20, gb_free=15.4, wall=13950
2023-01-09 07:30:24 - progress_bar.py[line:272] - INFO: epoch 002:   1462 / 3665 loss=5.38, loss_v1=0, loss_v2=0, nll_loss=4.509, ntokens=704, nsentences=32, sample_size=704, sample_size_v1=0, sample_size_v2=0, ppl=22.77, wps=360.4, ups=0.51, wpb=704, bsz=32, num_updates=5120, lr=4.57606e-05, gnorm=1.951, clip=100, loss_scale=256, train_wall=20, gb_free=15.1, wall=13970
2023-01-09 07:30:43 - progress_bar.py[line:272] - INFO: epoch 002:   1472 / 3665 loss=5.348, loss_v1=0, loss_v2=0, nll_loss=4.474, ntokens=856.9, nsentences=32, sample_size=856.9, sample_size_v1=0, sample_size_v2=0, ppl=22.22, wps=438, ups=0.51, wpb=856.9, bsz=32, num_updates=5130, lr=4.57461e-05, gnorm=1.805, clip=100, loss_scale=256, train_wall=20, gb_free=15.6, wall=13989
2023-01-09 07:31:03 - progress_bar.py[line:272] - INFO: epoch 002:   1482 / 3665 loss=5.475, loss_v1=0, loss_v2=0, nll_loss=4.606, ntokens=1010.8, nsentences=32, sample_size=1010.8, sample_size_v1=0, sample_size_v2=0, ppl=24.36, wps=514.8, ups=0.51, wpb=1010.8, bsz=32, num_updates=5140, lr=4.57316e-05, gnorm=1.617, clip=100, loss_scale=256, train_wall=20, gb_free=15.5, wall=14009
2023-01-09 07:31:22 - progress_bar.py[line:272] - INFO: epoch 002:   1492 / 3665 loss=5.463, loss_v1=0, loss_v2=0, nll_loss=4.601, ntokens=705.6, nsentences=32, sample_size=705.6, sample_size_v1=0, sample_size_v2=0, ppl=24.27, wps=360.7, ups=0.51, wpb=705.6, bsz=32, num_updates=5150, lr=4.57171e-05, gnorm=1.943, clip=100, loss_scale=256, train_wall=20, gb_free=15.7, wall=14029
2023-01-09 07:31:42 - progress_bar.py[line:272] - INFO: epoch 002:   1502 / 3665 loss=5.429, loss_v1=0, loss_v2=0, nll_loss=4.561, ntokens=890.3, nsentences=32, sample_size=890.3, sample_size_v1=0, sample_size_v2=0, ppl=23.6, wps=453.1, ups=0.51, wpb=890.3, bsz=32, num_updates=5160, lr=4.57026e-05, gnorm=1.755, clip=100, loss_scale=256, train_wall=20, gb_free=15.5, wall=14048
2023-01-09 07:32:02 - progress_bar.py[line:272] - INFO: epoch 002:   1512 / 3665 loss=5.341, loss_v1=0, loss_v2=0, nll_loss=4.463, ntokens=985.6, nsentences=32, sample_size=985.6, sample_size_v1=0, sample_size_v2=0, ppl=22.06, wps=493.3, ups=0.5, wpb=985.6, bsz=32, num_updates=5170, lr=4.56881e-05, gnorm=1.605, clip=100, loss_scale=256, train_wall=20, gb_free=15.3, wall=14068
2023-01-09 07:32:22 - progress_bar.py[line:272] - INFO: epoch 002:   1522 / 3665 loss=5.577, loss_v1=0, loss_v2=0, nll_loss=4.723, ntokens=982.7, nsentences=32, sample_size=982.7, sample_size_v1=0, sample_size_v2=0, ppl=26.41, wps=491, ups=0.5, wpb=982.7, bsz=32, num_updates=5180, lr=4.56736e-05, gnorm=1.678, clip=100, loss_scale=256, train_wall=20, gb_free=15.3, wall=14088
2023-01-09 07:32:42 - progress_bar.py[line:272] - INFO: epoch 002:   1532 / 3665 loss=5.445, loss_v1=0, loss_v2=0, nll_loss=4.581, ntokens=831.4, nsentences=32, sample_size=831.4, sample_size_v1=0, sample_size_v2=0, ppl=23.94, wps=417.5, ups=0.5, wpb=831.4, bsz=32, num_updates=5190, lr=4.56591e-05, gnorm=1.918, clip=100, loss_scale=256, train_wall=20, gb_free=15.4, wall=14108
2023-01-09 07:33:02 - progress_bar.py[line:272] - INFO: epoch 002:   1542 / 3665 loss=5.406, loss_v1=0, loss_v2=0, nll_loss=4.532, ntokens=1013.2, nsentences=32, sample_size=1013.2, sample_size_v1=0, sample_size_v2=0, ppl=23.14, wps=507.4, ups=0.5, wpb=1013.2, bsz=32, num_updates=5200, lr=4.56445e-05, gnorm=1.658, clip=100, loss_scale=256, train_wall=20, gb_free=15.2, wall=14128
2023-01-09 07:33:22 - progress_bar.py[line:272] - INFO: epoch 002:   1552 / 3665 loss=5.575, loss_v1=0, loss_v2=0, nll_loss=4.719, ntokens=933.8, nsentences=32, sample_size=933.8, sample_size_v1=0, sample_size_v2=0, ppl=26.34, wps=468, ups=0.5, wpb=933.8, bsz=32, num_updates=5210, lr=4.563e-05, gnorm=1.711, clip=100, loss_scale=256, train_wall=20, gb_free=15.3, wall=14148
2023-01-09 07:33:42 - progress_bar.py[line:272] - INFO: epoch 002:   1562 / 3665 loss=5.471, loss_v1=0, loss_v2=0, nll_loss=4.61, ntokens=813.2, nsentences=32, sample_size=813.2, sample_size_v1=0, sample_size_v2=0, ppl=24.41, wps=410.5, ups=0.5, wpb=813.2, bsz=32, num_updates=5220, lr=4.56155e-05, gnorm=1.954, clip=100, loss_scale=256, train_wall=20, gb_free=15.5, wall=14168
2023-01-09 07:34:02 - progress_bar.py[line:272] - INFO: epoch 002:   1572 / 3665 loss=5.469, loss_v1=0, loss_v2=0, nll_loss=4.607, ntokens=1099.9, nsentences=32, sample_size=1099.9, sample_size_v1=0, sample_size_v2=0, ppl=24.37, wps=553.6, ups=0.5, wpb=1099.9, bsz=32, num_updates=5230, lr=4.5601e-05, gnorm=1.715, clip=100, loss_scale=256, train_wall=20, gb_free=15.2, wall=14188
2023-01-09 07:34:21 - progress_bar.py[line:272] - INFO: epoch 002:   1582 / 3665 loss=5.468, loss_v1=0, loss_v2=0, nll_loss=4.6, ntokens=928.3, nsentences=32, sample_size=928.3, sample_size_v1=0, sample_size_v2=0, ppl=24.25, wps=468.1, ups=0.5, wpb=928.3, bsz=32, num_updates=5240, lr=4.55865e-05, gnorm=1.648, clip=100, loss_scale=256, train_wall=20, gb_free=15, wall=14208
2023-01-09 07:34:41 - progress_bar.py[line:272] - INFO: epoch 002:   1592 / 3665 loss=5.467, loss_v1=0, loss_v2=0, nll_loss=4.605, ntokens=850.7, nsentences=32, sample_size=850.7, sample_size_v1=0, sample_size_v2=0, ppl=24.34, wps=433, ups=0.51, wpb=850.7, bsz=32, num_updates=5250, lr=4.5572e-05, gnorm=1.921, clip=100, loss_scale=256, train_wall=20, gb_free=15.5, wall=14227
2023-01-09 07:35:01 - progress_bar.py[line:272] - INFO: epoch 002:   1602 / 3665 loss=5.396, loss_v1=0, loss_v2=0, nll_loss=4.522, ntokens=951.1, nsentences=32, sample_size=951.1, sample_size_v1=0, sample_size_v2=0, ppl=22.98, wps=485.1, ups=0.51, wpb=951.1, bsz=32, num_updates=5260, lr=4.55575e-05, gnorm=1.853, clip=100, loss_scale=256, train_wall=20, gb_free=15.2, wall=14247
2023-01-09 07:35:20 - progress_bar.py[line:272] - INFO: epoch 002:   1612 / 3665 loss=5.474, loss_v1=0, loss_v2=0, nll_loss=4.608, ntokens=940.6, nsentences=32, sample_size=940.6, sample_size_v1=0, sample_size_v2=0, ppl=24.38, wps=477.8, ups=0.51, wpb=940.6, bsz=32, num_updates=5270, lr=4.55429e-05, gnorm=1.783, clip=100, loss_scale=256, train_wall=20, gb_free=15.1, wall=14267
2023-01-09 07:35:40 - progress_bar.py[line:272] - INFO: epoch 002:   1622 / 3665 loss=5.444, loss_v1=0, loss_v2=0, nll_loss=4.577, ntokens=802, nsentences=32, sample_size=802, sample_size_v1=0, sample_size_v2=0, ppl=23.87, wps=407.9, ups=0.51, wpb=802, bsz=32, num_updates=5280, lr=4.55284e-05, gnorm=1.846, clip=100, loss_scale=256, train_wall=20, gb_free=15.2, wall=14286
2023-01-09 07:36:00 - progress_bar.py[line:272] - INFO: epoch 002:   1632 / 3665 loss=5.428, loss_v1=0, loss_v2=0, nll_loss=4.561, ntokens=986.4, nsentences=32, sample_size=986.4, sample_size_v1=0, sample_size_v2=0, ppl=23.6, wps=501.2, ups=0.51, wpb=986.4, bsz=32, num_updates=5290, lr=4.55139e-05, gnorm=1.715, clip=100, loss_scale=256, train_wall=20, gb_free=15, wall=14306
2023-01-09 07:36:19 - progress_bar.py[line:272] - INFO: epoch 002:   1642 / 3665 loss=5.436, loss_v1=0, loss_v2=0, nll_loss=4.564, ntokens=1162.9, nsentences=32, sample_size=1162.9, sample_size_v1=0, sample_size_v2=0, ppl=23.65, wps=588, ups=0.51, wpb=1162.9, bsz=32, num_updates=5300, lr=4.54994e-05, gnorm=1.508, clip=100, loss_scale=256, train_wall=20, gb_free=15.5, wall=14326
2023-01-09 07:36:39 - progress_bar.py[line:272] - INFO: epoch 002:   1652 / 3665 loss=5.415, loss_v1=0, loss_v2=0, nll_loss=4.55, ntokens=986.5, nsentences=32, sample_size=986.5, sample_size_v1=0, sample_size_v2=0, ppl=23.42, wps=499.8, ups=0.51, wpb=986.5, bsz=32, num_updates=5310, lr=4.54849e-05, gnorm=1.732, clip=100, loss_scale=256, train_wall=20, gb_free=15.3, wall=14345
2023-01-09 07:36:59 - progress_bar.py[line:272] - INFO: epoch 002:   1662 / 3665 loss=5.417, loss_v1=0, loss_v2=0, nll_loss=4.545, ntokens=844.1, nsentences=32, sample_size=844.1, sample_size_v1=0, sample_size_v2=0, ppl=23.34, wps=430.2, ups=0.51, wpb=844.1, bsz=32, num_updates=5320, lr=4.54704e-05, gnorm=2.02, clip=100, loss_scale=256, train_wall=20, gb_free=15.4, wall=14365
2023-01-09 07:37:18 - progress_bar.py[line:272] - INFO: epoch 002:   1672 / 3665 loss=5.458, loss_v1=0, loss_v2=0, nll_loss=4.593, ntokens=1001.5, nsentences=32, sample_size=1001.5, sample_size_v1=0, sample_size_v2=0, ppl=24.13, wps=507.8, ups=0.51, wpb=1001.5, bsz=32, num_updates=5330, lr=4.54559e-05, gnorm=1.565, clip=100, loss_scale=512, train_wall=20, gb_free=15.6, wall=14385
2023-01-09 07:37:38 - progress_bar.py[line:272] - INFO: epoch 002:   1682 / 3665 loss=5.46, loss_v1=0, loss_v2=0, nll_loss=4.59, ntokens=801, nsentences=32, sample_size=801, sample_size_v1=0, sample_size_v2=0, ppl=24.09, wps=407.4, ups=0.51, wpb=801, bsz=32, num_updates=5340, lr=4.54414e-05, gnorm=1.68, clip=100, loss_scale=512, train_wall=20, gb_free=15.4, wall=14404
2023-01-09 07:37:58 - progress_bar.py[line:272] - INFO: epoch 002:   1692 / 3665 loss=5.441, loss_v1=0, loss_v2=0, nll_loss=4.576, ntokens=1054.7, nsentences=32, sample_size=1054.7, sample_size_v1=0, sample_size_v2=0, ppl=23.86, wps=534, ups=0.51, wpb=1054.7, bsz=32, num_updates=5350, lr=4.54268e-05, gnorm=1.579, clip=100, loss_scale=512, train_wall=20, gb_free=14.9, wall=14424
2023-01-09 07:38:18 - progress_bar.py[line:272] - INFO: epoch 002:   1702 / 3665 loss=5.322, loss_v1=0, loss_v2=0, nll_loss=4.44, ntokens=944.7, nsentences=32, sample_size=944.7, sample_size_v1=0, sample_size_v2=0, ppl=21.71, wps=478.4, ups=0.51, wpb=944.7, bsz=32, num_updates=5360, lr=4.54123e-05, gnorm=1.859, clip=100, loss_scale=512, train_wall=20, gb_free=15.4, wall=14444
2023-01-09 07:38:37 - progress_bar.py[line:272] - INFO: epoch 002:   1712 / 3665 loss=5.465, loss_v1=0, loss_v2=0, nll_loss=4.598, ntokens=802, nsentences=32, sample_size=802, sample_size_v1=0, sample_size_v2=0, ppl=24.22, wps=407.7, ups=0.51, wpb=802, bsz=32, num_updates=5370, lr=4.53978e-05, gnorm=1.907, clip=100, loss_scale=512, train_wall=20, gb_free=15.6, wall=14464
2023-01-09 07:38:57 - progress_bar.py[line:272] - INFO: epoch 002:   1722 / 3665 loss=5.421, loss_v1=0, loss_v2=0, nll_loss=4.554, ntokens=804.5, nsentences=32, sample_size=804.5, sample_size_v1=0, sample_size_v2=0, ppl=23.49, wps=409, ups=0.51, wpb=804.5, bsz=32, num_updates=5380, lr=4.53833e-05, gnorm=1.884, clip=100, loss_scale=512, train_wall=20, gb_free=15.3, wall=14483
2023-01-09 07:39:17 - progress_bar.py[line:272] - INFO: epoch 002:   1732 / 3665 loss=5.368, loss_v1=0, loss_v2=0, nll_loss=4.491, ntokens=977, nsentences=32, sample_size=977, sample_size_v1=0, sample_size_v2=0, ppl=22.48, wps=495.2, ups=0.51, wpb=977, bsz=32, num_updates=5390, lr=4.53688e-05, gnorm=1.555, clip=100, loss_scale=512, train_wall=20, gb_free=15.2, wall=14503
2023-01-09 07:39:19 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 256.0
2023-01-09 07:39:38 - progress_bar.py[line:272] - INFO: epoch 002:   1743 / 3665 loss=5.514, loss_v1=0, loss_v2=0, nll_loss=4.656, ntokens=950.6, nsentences=32, sample_size=950.6, sample_size_v1=0, sample_size_v2=0, ppl=25.2, wps=438.9, ups=0.46, wpb=950.6, bsz=32, num_updates=5400, lr=4.53543e-05, gnorm=1.751, clip=100, loss_scale=256, train_wall=22, gb_free=14.7, wall=14525
2023-01-09 07:39:58 - progress_bar.py[line:272] - INFO: epoch 002:   1753 / 3665 loss=5.423, loss_v1=0, loss_v2=0, nll_loss=4.555, ntokens=860.8, nsentences=32, sample_size=860.8, sample_size_v1=0, sample_size_v2=0, ppl=23.51, wps=436.9, ups=0.51, wpb=860.8, bsz=32, num_updates=5410, lr=4.53398e-05, gnorm=1.836, clip=100, loss_scale=256, train_wall=20, gb_free=15.5, wall=14544
2023-01-09 07:40:18 - progress_bar.py[line:272] - INFO: epoch 002:   1763 / 3665 loss=5.346, loss_v1=0, loss_v2=0, nll_loss=4.47, ntokens=1072.1, nsentences=32, sample_size=1072.1, sample_size_v1=0, sample_size_v2=0, ppl=22.17, wps=543.5, ups=0.51, wpb=1072.1, bsz=32, num_updates=5420, lr=4.53252e-05, gnorm=1.675, clip=100, loss_scale=256, train_wall=20, gb_free=15.5, wall=14564
2023-01-09 07:40:38 - progress_bar.py[line:272] - INFO: epoch 002:   1773 / 3665 loss=5.557, loss_v1=0, loss_v2=0, nll_loss=4.695, ntokens=992.9, nsentences=32, sample_size=992.9, sample_size_v1=0, sample_size_v2=0, ppl=25.9, wps=502.5, ups=0.51, wpb=992.9, bsz=32, num_updates=5430, lr=4.53107e-05, gnorm=1.65, clip=100, loss_scale=256, train_wall=20, gb_free=15.4, wall=14584
2023-01-09 07:40:57 - progress_bar.py[line:272] - INFO: epoch 002:   1783 / 3665 loss=5.416, loss_v1=0, loss_v2=0, nll_loss=4.55, ntokens=842.7, nsentences=32, sample_size=842.7, sample_size_v1=0, sample_size_v2=0, ppl=23.42, wps=427.8, ups=0.51, wpb=842.7, bsz=32, num_updates=5440, lr=4.52962e-05, gnorm=1.657, clip=100, loss_scale=256, train_wall=20, gb_free=15.5, wall=14604
2023-01-09 07:41:17 - progress_bar.py[line:272] - INFO: epoch 002:   1793 / 3665 loss=5.38, loss_v1=0, loss_v2=0, nll_loss=4.507, ntokens=971.3, nsentences=32, sample_size=971.3, sample_size_v1=0, sample_size_v2=0, ppl=22.73, wps=493.9, ups=0.51, wpb=971.3, bsz=32, num_updates=5450, lr=4.52817e-05, gnorm=1.686, clip=100, loss_scale=256, train_wall=20, gb_free=15.4, wall=14623
2023-01-09 07:41:37 - progress_bar.py[line:272] - INFO: epoch 002:   1803 / 3665 loss=5.451, loss_v1=0, loss_v2=0, nll_loss=4.581, ntokens=895.5, nsentences=32, sample_size=895.5, sample_size_v1=0, sample_size_v2=0, ppl=23.94, wps=454.9, ups=0.51, wpb=895.5, bsz=32, num_updates=5460, lr=4.52672e-05, gnorm=1.698, clip=100, loss_scale=256, train_wall=20, gb_free=15.4, wall=14643
2023-01-09 07:41:56 - progress_bar.py[line:272] - INFO: epoch 002:   1813 / 3665 loss=5.412, loss_v1=0, loss_v2=0, nll_loss=4.541, ntokens=780.3, nsentences=32, sample_size=780.3, sample_size_v1=0, sample_size_v2=0, ppl=23.28, wps=397, ups=0.51, wpb=780.3, bsz=32, num_updates=5470, lr=4.52527e-05, gnorm=1.723, clip=100, loss_scale=256, train_wall=20, gb_free=15.7, wall=14663
2023-01-09 07:42:16 - progress_bar.py[line:272] - INFO: epoch 002:   1823 / 3665 loss=5.344, loss_v1=0, loss_v2=0, nll_loss=4.467, ntokens=976.2, nsentences=32, sample_size=976.2, sample_size_v1=0, sample_size_v2=0, ppl=22.12, wps=495, ups=0.51, wpb=976.2, bsz=32, num_updates=5480, lr=4.52382e-05, gnorm=1.661, clip=100, loss_scale=256, train_wall=20, gb_free=15.2, wall=14682
2023-01-09 07:42:36 - progress_bar.py[line:272] - INFO: epoch 002:   1833 / 3665 loss=5.501, loss_v1=0, loss_v2=0, nll_loss=4.637, ntokens=1078.3, nsentences=32, sample_size=1078.3, sample_size_v1=0, sample_size_v2=0, ppl=24.88, wps=545.5, ups=0.51, wpb=1078.3, bsz=32, num_updates=5490, lr=4.52237e-05, gnorm=1.533, clip=100, loss_scale=256, train_wall=20, gb_free=15.5, wall=14702
2023-01-09 07:42:55 - progress_bar.py[line:272] - INFO: epoch 002:   1843 / 3665 loss=5.416, loss_v1=0, loss_v2=0, nll_loss=4.548, ntokens=745, nsentences=32, sample_size=745, sample_size_v1=0, sample_size_v2=0, ppl=23.39, wps=379.7, ups=0.51, wpb=745, bsz=32, num_updates=5500, lr=4.52091e-05, gnorm=1.836, clip=100, loss_scale=256, train_wall=20, gb_free=15.6, wall=14722
2023-01-09 07:42:55 - train.py[line:445] - INFO: begin validation on "valid" subset
slice_id 0 seek offset 0
slice_id 0 seek offset 0
2023-01-09 07:47:42 - progress_bar.py[line:282] - INFO: epoch 002 | valid on 'valid' subset | loss 5.409 | loss_v1 0 | loss_v2 0 | nll_loss 4.528 | ntokens 116.796 | nsentences 4 | sample_size 116.796 | sample_size_v1 0 | sample_size_v2 0 | AP 0 | total positives 21.6624 | TP 0 | FP 6.68417 | ppl 23.06 | wps 510.5 | wpb 116.8 | bsz 4 | num_updates 5500 | best_AP 0
2023-01-09 07:47:42 - checkpoint_utils.py[line:64] - INFO: Preparing to save checkpoint for epoch 2 @ 5500 updates
2023-01-09 07:47:42 - trainer.py[line:431] - INFO: Saving checkpoint to ../../checkpoints/OFA/detection_checkpoints/10_5e-5_512/checkpoint_2_5500.pt
2023-01-09 07:47:45 - trainer.py[line:441] - INFO: Finished saving checkpoint to ../../checkpoints/OFA/detection_checkpoints/10_5e-5_512/checkpoint_2_5500.pt
2023-01-09 07:48:58 - checkpoint_utils.py[line:133] - INFO: Saved checkpoint ../../checkpoints/OFA/detection_checkpoints/10_5e-5_512/checkpoint_2_5500.pt (epoch 2 @ 5500 updates, score 0.0) (writing took 75.65835849381983 seconds)
2023-01-09 07:49:17 - progress_bar.py[line:272] - INFO: epoch 002:   1853 / 3665 loss=5.433, loss_v1=0, loss_v2=0, nll_loss=4.565, ntokens=937, nsentences=32, sample_size=937, sample_size_v1=0, sample_size_v2=0, ppl=23.67, wps=24.6, ups=0.03, wpb=937, bsz=32, num_updates=5510, lr=4.51946e-05, gnorm=1.589, clip=100, loss_scale=256, train_wall=19, gb_free=15.3, wall=15103
2023-01-09 07:49:36 - progress_bar.py[line:272] - INFO: epoch 002:   1863 / 3665 loss=5.398, loss_v1=0, loss_v2=0, nll_loss=4.524, ntokens=971.2, nsentences=32, sample_size=971.2, sample_size_v1=0, sample_size_v2=0, ppl=23.01, wps=500.3, ups=0.52, wpb=971.2, bsz=32, num_updates=5520, lr=4.51801e-05, gnorm=1.649, clip=100, loss_scale=256, train_wall=19, gb_free=15.5, wall=15123
2023-01-09 07:49:56 - progress_bar.py[line:272] - INFO: epoch 002:   1873 / 3665 loss=5.483, loss_v1=0, loss_v2=0, nll_loss=4.62, ntokens=871.3, nsentences=32, sample_size=871.3, sample_size_v1=0, sample_size_v2=0, ppl=24.58, wps=447.6, ups=0.51, wpb=871.3, bsz=32, num_updates=5530, lr=4.51656e-05, gnorm=1.77, clip=100, loss_scale=256, train_wall=19, gb_free=15.5, wall=15142
2023-01-09 07:50:16 - progress_bar.py[line:272] - INFO: epoch 002:   1883 / 3665 loss=5.429, loss_v1=0, loss_v2=0, nll_loss=4.561, ntokens=1024.1, nsentences=32, sample_size=1024.1, sample_size_v1=0, sample_size_v2=0, ppl=23.61, wps=521.2, ups=0.51, wpb=1024.1, bsz=32, num_updates=5540, lr=4.51511e-05, gnorm=1.626, clip=100, loss_scale=256, train_wall=20, gb_free=15.4, wall=15162
2023-01-09 07:50:35 - progress_bar.py[line:272] - INFO: epoch 002:   1893 / 3665 loss=5.376, loss_v1=0, loss_v2=0, nll_loss=4.498, ntokens=1079.7, nsentences=32, sample_size=1079.7, sample_size_v1=0, sample_size_v2=0, ppl=22.6, wps=547.9, ups=0.51, wpb=1079.7, bsz=32, num_updates=5550, lr=4.51366e-05, gnorm=1.601, clip=100, loss_scale=256, train_wall=20, gb_free=15.6, wall=15182
2023-01-09 07:50:55 - progress_bar.py[line:272] - INFO: epoch 002:   1903 / 3665 loss=5.53, loss_v1=0, loss_v2=0, nll_loss=4.674, ntokens=792.2, nsentences=32, sample_size=792.2, sample_size_v1=0, sample_size_v2=0, ppl=25.53, wps=405.5, ups=0.51, wpb=792.2, bsz=32, num_updates=5560, lr=4.51221e-05, gnorm=1.812, clip=100, loss_scale=256, train_wall=20, gb_free=15.5, wall=15201
2023-01-09 07:51:14 - progress_bar.py[line:272] - INFO: epoch 002:   1913 / 3665 loss=5.443, loss_v1=0, loss_v2=0, nll_loss=4.578, ntokens=854.3, nsentences=32, sample_size=854.3, sample_size_v1=0, sample_size_v2=0, ppl=23.88, wps=437.8, ups=0.51, wpb=854.3, bsz=32, num_updates=5570, lr=4.51075e-05, gnorm=1.72, clip=100, loss_scale=256, train_wall=19, gb_free=15.4, wall=15221
2023-01-09 07:51:34 - progress_bar.py[line:272] - INFO: epoch 002:   1923 / 3665 loss=5.378, loss_v1=0, loss_v2=0, nll_loss=4.504, ntokens=893.1, nsentences=32, sample_size=893.1, sample_size_v1=0, sample_size_v2=0, ppl=22.68, wps=456.8, ups=0.51, wpb=893.1, bsz=32, num_updates=5580, lr=4.5093e-05, gnorm=2.012, clip=100, loss_scale=256, train_wall=20, gb_free=15.5, wall=15240
2023-01-09 07:51:54 - progress_bar.py[line:272] - INFO: epoch 002:   1933 / 3665 loss=5.534, loss_v1=0, loss_v2=0, nll_loss=4.672, ntokens=961.6, nsentences=32, sample_size=961.6, sample_size_v1=0, sample_size_v2=0, ppl=25.49, wps=489.8, ups=0.51, wpb=961.6, bsz=32, num_updates=5590, lr=4.50785e-05, gnorm=1.774, clip=100, loss_scale=256, train_wall=20, gb_free=15.5, wall=15260
2023-01-09 07:52:13 - progress_bar.py[line:272] - INFO: epoch 002:   1943 / 3665 loss=5.423, loss_v1=0, loss_v2=0, nll_loss=4.554, ntokens=769.9, nsentences=32, sample_size=769.9, sample_size_v1=0, sample_size_v2=0, ppl=23.49, wps=393, ups=0.51, wpb=769.9, bsz=32, num_updates=5600, lr=4.5064e-05, gnorm=1.828, clip=100, loss_scale=256, train_wall=20, gb_free=15.5, wall=15279
2023-01-09 07:52:33 - progress_bar.py[line:272] - INFO: epoch 002:   1953 / 3665 loss=5.373, loss_v1=0, loss_v2=0, nll_loss=4.5, ntokens=972.9, nsentences=32, sample_size=972.9, sample_size_v1=0, sample_size_v2=0, ppl=22.63, wps=495.8, ups=0.51, wpb=972.9, bsz=32, num_updates=5610, lr=4.50495e-05, gnorm=1.683, clip=100, loss_scale=256, train_wall=20, gb_free=15.4, wall=15299
2023-01-09 07:52:52 - progress_bar.py[line:272] - INFO: epoch 002:   1963 / 3665 loss=5.489, loss_v1=0, loss_v2=0, nll_loss=4.619, ntokens=1083.7, nsentences=32, sample_size=1083.7, sample_size_v1=0, sample_size_v2=0, ppl=24.57, wps=550.3, ups=0.51, wpb=1083.7, bsz=32, num_updates=5620, lr=4.5035e-05, gnorm=1.54, clip=100, loss_scale=256, train_wall=20, gb_free=15, wall=15319
2023-01-09 07:53:12 - progress_bar.py[line:272] - INFO: epoch 002:   1973 / 3665 loss=5.464, loss_v1=0, loss_v2=0, nll_loss=4.602, ntokens=903.7, nsentences=32, sample_size=903.7, sample_size_v1=0, sample_size_v2=0, ppl=24.28, wps=461.4, ups=0.51, wpb=903.7, bsz=32, num_updates=5630, lr=4.50205e-05, gnorm=1.67, clip=100, loss_scale=256, train_wall=20, gb_free=14.9, wall=15338
2023-01-09 07:53:32 - progress_bar.py[line:272] - INFO: epoch 002:   1983 / 3665 loss=5.378, loss_v1=0, loss_v2=0, nll_loss=4.505, ntokens=968.4, nsentences=32, sample_size=968.4, sample_size_v1=0, sample_size_v2=0, ppl=22.71, wps=493.4, ups=0.51, wpb=968.4, bsz=32, num_updates=5640, lr=4.5006e-05, gnorm=1.802, clip=100, loss_scale=256, train_wall=20, gb_free=14.8, wall=15358
2023-01-09 07:53:52 - progress_bar.py[line:272] - INFO: epoch 002:   1993 / 3665 loss=5.436, loss_v1=0, loss_v2=0, nll_loss=4.564, ntokens=1019.4, nsentences=32, sample_size=1019.4, sample_size_v1=0, sample_size_v2=0, ppl=23.66, wps=505, ups=0.5, wpb=1019.4, bsz=32, num_updates=5650, lr=4.49914e-05, gnorm=1.536, clip=100, loss_scale=256, train_wall=20, gb_free=15.5, wall=15378
2023-01-09 07:54:13 - progress_bar.py[line:272] - INFO: epoch 002:   2003 / 3665 loss=5.449, loss_v1=0, loss_v2=0, nll_loss=4.584, ntokens=835.6, nsentences=32, sample_size=835.6, sample_size_v1=0, sample_size_v2=0, ppl=23.99, wps=403.7, ups=0.48, wpb=835.6, bsz=32, num_updates=5660, lr=4.49769e-05, gnorm=1.886, clip=100, loss_scale=256, train_wall=21, gb_free=15.4, wall=15399
2023-01-09 07:54:33 - progress_bar.py[line:272] - INFO: epoch 002:   2013 / 3665 loss=5.375, loss_v1=0, loss_v2=0, nll_loss=4.501, ntokens=933.1, nsentences=32, sample_size=933.1, sample_size_v1=0, sample_size_v2=0, ppl=22.65, wps=459.2, ups=0.49, wpb=933.1, bsz=32, num_updates=5670, lr=4.49624e-05, gnorm=1.629, clip=100, loss_scale=256, train_wall=20, gb_free=15.6, wall=15419
2023-01-09 07:54:52 - progress_bar.py[line:272] - INFO: epoch 002:   2023 / 3665 loss=5.548, loss_v1=0, loss_v2=0, nll_loss=4.695, ntokens=1103.1, nsentences=32, sample_size=1103.1, sample_size_v1=0, sample_size_v2=0, ppl=25.91, wps=563, ups=0.51, wpb=1103.1, bsz=32, num_updates=5680, lr=4.49479e-05, gnorm=1.564, clip=100, loss_scale=256, train_wall=20, gb_free=15.7, wall=15439
2023-01-09 07:55:12 - progress_bar.py[line:272] - INFO: epoch 002:   2033 / 3665 loss=5.415, loss_v1=0, loss_v2=0, nll_loss=4.542, ntokens=774, nsentences=32, sample_size=774, sample_size_v1=0, sample_size_v2=0, ppl=23.29, wps=398.2, ups=0.51, wpb=774, bsz=32, num_updates=5690, lr=4.49334e-05, gnorm=1.889, clip=100, loss_scale=256, train_wall=19, gb_free=15.5, wall=15458
2023-01-09 07:55:31 - progress_bar.py[line:272] - INFO: epoch 002:   2043 / 3665 loss=5.353, loss_v1=0, loss_v2=0, nll_loss=4.476, ntokens=845.1, nsentences=32, sample_size=845.1, sample_size_v1=0, sample_size_v2=0, ppl=22.25, wps=433.5, ups=0.51, wpb=845.1, bsz=32, num_updates=5700, lr=4.49189e-05, gnorm=1.898, clip=100, loss_scale=256, train_wall=19, gb_free=15.5, wall=15478
2023-01-09 07:55:51 - progress_bar.py[line:272] - INFO: epoch 002:   2053 / 3665 loss=5.395, loss_v1=0, loss_v2=0, nll_loss=4.521, ntokens=989.9, nsentences=32, sample_size=989.9, sample_size_v1=0, sample_size_v2=0, ppl=22.96, wps=504.1, ups=0.51, wpb=989.9, bsz=32, num_updates=5710, lr=4.49044e-05, gnorm=1.667, clip=100, loss_scale=256, train_wall=20, gb_free=15, wall=15497
2023-01-09 07:56:11 - progress_bar.py[line:272] - INFO: epoch 002:   2063 / 3665 loss=5.419, loss_v1=0, loss_v2=0, nll_loss=4.545, ntokens=768.5, nsentences=32, sample_size=768.5, sample_size_v1=0, sample_size_v2=0, ppl=23.35, wps=392.1, ups=0.51, wpb=768.5, bsz=32, num_updates=5720, lr=4.48898e-05, gnorm=1.823, clip=100, loss_scale=256, train_wall=20, gb_free=15.5, wall=15517
2023-01-09 07:56:30 - progress_bar.py[line:272] - INFO: epoch 002:   2073 / 3665 loss=5.393, loss_v1=0, loss_v2=0, nll_loss=4.522, ntokens=962.2, nsentences=32, sample_size=962.2, sample_size_v1=0, sample_size_v2=0, ppl=22.97, wps=490.1, ups=0.51, wpb=962.2, bsz=32, num_updates=5730, lr=4.48753e-05, gnorm=1.597, clip=100, loss_scale=256, train_wall=20, gb_free=15.4, wall=15537
2023-01-09 07:56:50 - progress_bar.py[line:272] - INFO: epoch 002:   2083 / 3665 loss=5.479, loss_v1=0, loss_v2=0, nll_loss=4.617, ntokens=1099.3, nsentences=32, sample_size=1099.3, sample_size_v1=0, sample_size_v2=0, ppl=24.55, wps=556.7, ups=0.51, wpb=1099.3, bsz=32, num_updates=5740, lr=4.48608e-05, gnorm=1.631, clip=100, loss_scale=256, train_wall=20, gb_free=13.5, wall=15556
2023-01-09 07:57:10 - progress_bar.py[line:272] - INFO: epoch 002:   2093 / 3665 loss=5.537, loss_v1=0, loss_v2=0, nll_loss=4.677, ntokens=837.9, nsentences=32, sample_size=837.9, sample_size_v1=0, sample_size_v2=0, ppl=25.58, wps=426.6, ups=0.51, wpb=837.9, bsz=32, num_updates=5750, lr=4.48463e-05, gnorm=1.754, clip=100, loss_scale=256, train_wall=20, gb_free=15.1, wall=15576
2023-01-09 07:57:29 - progress_bar.py[line:272] - INFO: epoch 002:   2103 / 3665 loss=5.357, loss_v1=0, loss_v2=0, nll_loss=4.483, ntokens=924.8, nsentences=32, sample_size=924.8, sample_size_v1=0, sample_size_v2=0, ppl=22.37, wps=470.1, ups=0.51, wpb=924.8, bsz=32, num_updates=5760, lr=4.48318e-05, gnorm=1.742, clip=100, loss_scale=256, train_wall=20, gb_free=15.5, wall=15596
2023-01-09 07:57:49 - progress_bar.py[line:272] - INFO: epoch 002:   2113 / 3665 loss=5.351, loss_v1=0, loss_v2=0, nll_loss=4.473, ntokens=967.6, nsentences=32, sample_size=967.6, sample_size_v1=0, sample_size_v2=0, ppl=22.21, wps=480.6, ups=0.5, wpb=967.6, bsz=32, num_updates=5770, lr=4.48173e-05, gnorm=1.833, clip=100, loss_scale=256, train_wall=20, gb_free=15.2, wall=15616
2023-01-09 07:58:10 - progress_bar.py[line:272] - INFO: epoch 002:   2123 / 3665 loss=5.462, loss_v1=0, loss_v2=0, nll_loss=4.591, ntokens=983.3, nsentences=32, sample_size=983.3, sample_size_v1=0, sample_size_v2=0, ppl=24.09, wps=487.4, ups=0.5, wpb=983.3, bsz=32, num_updates=5780, lr=4.48028e-05, gnorm=1.704, clip=90, loss_scale=256, train_wall=20, gb_free=15.6, wall=15636
2023-01-09 07:58:30 - progress_bar.py[line:272] - INFO: epoch 002:   2133 / 3665 loss=5.417, loss_v1=0, loss_v2=0, nll_loss=4.548, ntokens=892.6, nsentences=32, sample_size=892.6, sample_size_v1=0, sample_size_v2=0, ppl=23.39, wps=443.9, ups=0.5, wpb=892.6, bsz=32, num_updates=5790, lr=4.47882e-05, gnorm=1.737, clip=100, loss_scale=256, train_wall=20, gb_free=15.4, wall=15656
2023-01-09 07:58:50 - progress_bar.py[line:272] - INFO: epoch 002:   2143 / 3665 loss=5.323, loss_v1=0, loss_v2=0, nll_loss=4.443, ntokens=996.1, nsentences=32, sample_size=996.1, sample_size_v1=0, sample_size_v2=0, ppl=21.75, wps=497, ups=0.5, wpb=996.1, bsz=32, num_updates=5800, lr=4.47737e-05, gnorm=1.658, clip=100, loss_scale=256, train_wall=20, gb_free=14.8, wall=15676
2023-01-09 07:59:10 - progress_bar.py[line:272] - INFO: epoch 002:   2153 / 3665 loss=5.455, loss_v1=0, loss_v2=0, nll_loss=4.588, ntokens=948.2, nsentences=32, sample_size=948.2, sample_size_v1=0, sample_size_v2=0, ppl=24.04, wps=480.2, ups=0.51, wpb=948.2, bsz=32, num_updates=5810, lr=4.47592e-05, gnorm=1.659, clip=100, loss_scale=256, train_wall=20, gb_free=15.6, wall=15696
2023-01-09 07:59:29 - progress_bar.py[line:272] - INFO: epoch 002:   2163 / 3665 loss=5.45, loss_v1=0, loss_v2=0, nll_loss=4.583, ntokens=919.2, nsentences=32, sample_size=919.2, sample_size_v1=0, sample_size_v2=0, ppl=23.97, wps=467.2, ups=0.51, wpb=919.2, bsz=32, num_updates=5820, lr=4.47447e-05, gnorm=1.827, clip=100, loss_scale=256, train_wall=20, gb_free=15.4, wall=15715
2023-01-09 07:59:49 - progress_bar.py[line:272] - INFO: epoch 002:   2173 / 3665 loss=5.345, loss_v1=0, loss_v2=0, nll_loss=4.469, ntokens=859.4, nsentences=32, sample_size=859.4, sample_size_v1=0, sample_size_v2=0, ppl=22.15, wps=438.8, ups=0.51, wpb=859.4, bsz=32, num_updates=5830, lr=4.47302e-05, gnorm=1.912, clip=100, loss_scale=256, train_wall=20, gb_free=15.3, wall=15735
2023-01-09 08:00:08 - progress_bar.py[line:272] - INFO: epoch 002:   2183 / 3665 loss=5.465, loss_v1=0, loss_v2=0, nll_loss=4.601, ntokens=1008.4, nsentences=32, sample_size=1008.4, sample_size_v1=0, sample_size_v2=0, ppl=24.27, wps=512.1, ups=0.51, wpb=1008.4, bsz=32, num_updates=5840, lr=4.47157e-05, gnorm=1.681, clip=100, loss_scale=256, train_wall=20, gb_free=15.4, wall=15755
2023-01-09 08:00:28 - progress_bar.py[line:272] - INFO: epoch 002:   2193 / 3665 loss=5.471, loss_v1=0, loss_v2=0, nll_loss=4.605, ntokens=940.7, nsentences=32, sample_size=940.7, sample_size_v1=0, sample_size_v2=0, ppl=24.34, wps=477.2, ups=0.51, wpb=940.7, bsz=32, num_updates=5850, lr=4.47012e-05, gnorm=1.78, clip=100, loss_scale=256, train_wall=20, gb_free=15.2, wall=15774
2023-01-09 08:00:48 - progress_bar.py[line:272] - INFO: epoch 002:   2203 / 3665 loss=5.385, loss_v1=0, loss_v2=0, nll_loss=4.512, ntokens=919, nsentences=32, sample_size=919, sample_size_v1=0, sample_size_v2=0, ppl=22.82, wps=468.5, ups=0.51, wpb=919, bsz=32, num_updates=5860, lr=4.46867e-05, gnorm=1.698, clip=100, loss_scale=256, train_wall=20, gb_free=15.3, wall=15794
2023-01-09 08:01:08 - progress_bar.py[line:272] - INFO: epoch 002:   2213 / 3665 loss=5.499, loss_v1=0, loss_v2=0, nll_loss=4.638, ntokens=1040.9, nsentences=32, sample_size=1040.9, sample_size_v1=0, sample_size_v2=0, ppl=24.89, wps=527.3, ups=0.51, wpb=1040.9, bsz=32, num_updates=5870, lr=4.46721e-05, gnorm=1.601, clip=100, loss_scale=256, train_wall=20, gb_free=15.4, wall=15814
2023-01-09 08:01:27 - progress_bar.py[line:272] - INFO: epoch 002:   2223 / 3665 loss=5.353, loss_v1=0, loss_v2=0, nll_loss=4.478, ntokens=758.7, nsentences=32, sample_size=758.7, sample_size_v1=0, sample_size_v2=0, ppl=22.29, wps=387.3, ups=0.51, wpb=758.7, bsz=32, num_updates=5880, lr=4.46576e-05, gnorm=1.766, clip=100, loss_scale=256, train_wall=20, gb_free=15.5, wall=15833
2023-01-09 08:01:47 - progress_bar.py[line:272] - INFO: epoch 002:   2233 / 3665 loss=5.365, loss_v1=0, loss_v2=0, nll_loss=4.486, ntokens=1000.7, nsentences=32, sample_size=1000.7, sample_size_v1=0, sample_size_v2=0, ppl=22.4, wps=506.7, ups=0.51, wpb=1000.7, bsz=32, num_updates=5890, lr=4.46431e-05, gnorm=1.653, clip=100, loss_scale=256, train_wall=20, gb_free=15.5, wall=15853
2023-01-09 08:02:06 - progress_bar.py[line:272] - INFO: epoch 002:   2243 / 3665 loss=5.394, loss_v1=0, loss_v2=0, nll_loss=4.524, ntokens=895.5, nsentences=32, sample_size=895.5, sample_size_v1=0, sample_size_v2=0, ppl=23.01, wps=456.8, ups=0.51, wpb=895.5, bsz=32, num_updates=5900, lr=4.46286e-05, gnorm=1.798, clip=100, loss_scale=256, train_wall=20, gb_free=15.7, wall=15873
2023-01-09 08:02:26 - progress_bar.py[line:272] - INFO: epoch 002:   2253 / 3665 loss=5.474, loss_v1=0, loss_v2=0, nll_loss=4.609, ntokens=944, nsentences=32, sample_size=944, sample_size_v1=0, sample_size_v2=0, ppl=24.4, wps=478.6, ups=0.51, wpb=944, bsz=32, num_updates=5910, lr=4.46141e-05, gnorm=1.663, clip=100, loss_scale=512, train_wall=20, gb_free=15.3, wall=15892
2023-01-09 08:02:46 - progress_bar.py[line:272] - INFO: epoch 002:   2263 / 3665 loss=5.404, loss_v1=0, loss_v2=0, nll_loss=4.533, ntokens=931.5, nsentences=32, sample_size=931.5, sample_size_v1=0, sample_size_v2=0, ppl=23.15, wps=473.5, ups=0.51, wpb=931.5, bsz=32, num_updates=5920, lr=4.45996e-05, gnorm=1.814, clip=100, loss_scale=512, train_wall=20, gb_free=15.4, wall=15912
2023-01-09 08:03:06 - progress_bar.py[line:272] - INFO: epoch 002:   2273 / 3665 loss=5.299, loss_v1=0, loss_v2=0, nll_loss=4.419, ntokens=964.7, nsentences=32, sample_size=964.7, sample_size_v1=0, sample_size_v2=0, ppl=21.39, wps=490.1, ups=0.51, wpb=964.7, bsz=32, num_updates=5930, lr=4.45851e-05, gnorm=1.797, clip=100, loss_scale=512, train_wall=20, gb_free=15.5, wall=15932
2023-01-09 08:03:25 - progress_bar.py[line:272] - INFO: epoch 002:   2283 / 3665 loss=5.515, loss_v1=0, loss_v2=0, nll_loss=4.652, ntokens=948.7, nsentences=32, sample_size=948.7, sample_size_v1=0, sample_size_v2=0, ppl=25.14, wps=480.7, ups=0.51, wpb=948.7, bsz=32, num_updates=5940, lr=4.45705e-05, gnorm=1.713, clip=100, loss_scale=512, train_wall=20, gb_free=15.1, wall=15952
2023-01-09 08:03:45 - progress_bar.py[line:272] - INFO: epoch 002:   2293 / 3665 loss=5.476, loss_v1=0, loss_v2=0, nll_loss=4.612, ntokens=957, nsentences=32, sample_size=957, sample_size_v1=0, sample_size_v2=0, ppl=24.46, wps=486.2, ups=0.51, wpb=957, bsz=32, num_updates=5950, lr=4.4556e-05, gnorm=1.666, clip=100, loss_scale=512, train_wall=20, gb_free=15.4, wall=15971
2023-01-09 08:04:05 - progress_bar.py[line:272] - INFO: epoch 002:   2303 / 3665 loss=5.308, loss_v1=0, loss_v2=0, nll_loss=4.424, ntokens=903.7, nsentences=32, sample_size=903.7, sample_size_v1=0, sample_size_v2=0, ppl=21.46, wps=460.3, ups=0.51, wpb=903.7, bsz=32, num_updates=5960, lr=4.45415e-05, gnorm=1.672, clip=100, loss_scale=512, train_wall=20, gb_free=15.6, wall=15991
2023-01-09 08:04:24 - progress_bar.py[line:272] - INFO: epoch 002:   2313 / 3665 loss=5.48, loss_v1=0, loss_v2=0, nll_loss=4.617, ntokens=894.6, nsentences=32, sample_size=894.6, sample_size_v1=0, sample_size_v2=0, ppl=24.53, wps=455.1, ups=0.51, wpb=894.6, bsz=32, num_updates=5970, lr=4.4527e-05, gnorm=1.705, clip=100, loss_scale=512, train_wall=20, gb_free=15.4, wall=16011
2023-01-09 08:04:44 - progress_bar.py[line:272] - INFO: epoch 002:   2323 / 3665 loss=5.381, loss_v1=0, loss_v2=0, nll_loss=4.504, ntokens=810, nsentences=32, sample_size=810, sample_size_v1=0, sample_size_v2=0, ppl=22.69, wps=408.7, ups=0.5, wpb=810, bsz=32, num_updates=5980, lr=4.45125e-05, gnorm=1.845, clip=100, loss_scale=512, train_wall=20, gb_free=15.5, wall=16030
2023-01-09 08:05:04 - progress_bar.py[line:272] - INFO: epoch 002:   2333 / 3665 loss=5.363, loss_v1=0, loss_v2=0, nll_loss=4.488, ntokens=1086.2, nsentences=32, sample_size=1086.2, sample_size_v1=0, sample_size_v2=0, ppl=22.45, wps=542.2, ups=0.5, wpb=1086.2, bsz=32, num_updates=5990, lr=4.4498e-05, gnorm=1.591, clip=100, loss_scale=512, train_wall=20, gb_free=15.3, wall=16050
2023-01-09 08:05:24 - progress_bar.py[line:272] - INFO: epoch 002:   2343 / 3665 loss=5.478, loss_v1=0, loss_v2=0, nll_loss=4.615, ntokens=1093.5, nsentences=32, sample_size=1093.5, sample_size_v1=0, sample_size_v2=0, ppl=24.5, wps=543.5, ups=0.5, wpb=1093.5, bsz=32, num_updates=6000, lr=4.44835e-05, gnorm=1.578, clip=100, loss_scale=512, train_wall=20, gb_free=15.4, wall=16071
2023-01-09 08:05:24 - train.py[line:445] - INFO: begin validation on "valid" subset
slice_id 0 seek offset 0
slice_id 0 seek offset 0
2023-01-09 08:10:18 - progress_bar.py[line:282] - INFO: epoch 002 | valid on 'valid' subset | loss 5.396 | loss_v1 0 | loss_v2 0 | nll_loss 4.508 | ntokens 117.298 | nsentences 4 | sample_size 117.298 | sample_size_v1 0 | sample_size_v2 0 | AP 0 | total positives 21.7658 | TP 0 | FP 6.29321 | ppl 22.75 | wps 500.3 | wpb 117.3 | bsz 4 | num_updates 6000 | best_AP 0
2023-01-09 08:10:18 - checkpoint_utils.py[line:64] - INFO: Preparing to save checkpoint for epoch 2 @ 6000 updates
2023-01-09 08:10:18 - trainer.py[line:431] - INFO: Saving checkpoint to ../../checkpoints/OFA/detection_checkpoints/10_5e-5_512/checkpoint_2_6000.pt
2023-01-09 08:10:21 - trainer.py[line:441] - INFO: Finished saving checkpoint to ../../checkpoints/OFA/detection_checkpoints/10_5e-5_512/checkpoint_2_6000.pt
2023-01-09 08:11:34 - checkpoint_utils.py[line:133] - INFO: Saved checkpoint ../../checkpoints/OFA/detection_checkpoints/10_5e-5_512/checkpoint_2_6000.pt (epoch 2 @ 6000 updates, score 0.0) (writing took 76.5392587389797 seconds)
2023-01-09 08:11:54 - progress_bar.py[line:272] - INFO: epoch 002:   2353 / 3665 loss=5.466, loss_v1=0, loss_v2=0, nll_loss=4.6, ntokens=996.3, nsentences=32, sample_size=996.3, sample_size_v1=0, sample_size_v2=0, ppl=24.26, wps=25.6, ups=0.03, wpb=996.3, bsz=32, num_updates=6010, lr=4.4469e-05, gnorm=1.81, clip=100, loss_scale=512, train_wall=19, gb_free=15.3, wall=16460
2023-01-09 08:12:13 - progress_bar.py[line:272] - INFO: epoch 002:   2363 / 3665 loss=5.277, loss_v1=0, loss_v2=0, nll_loss=4.389, ntokens=948.7, nsentences=32, sample_size=948.7, sample_size_v1=0, sample_size_v2=0, ppl=20.96, wps=488.4, ups=0.51, wpb=948.7, bsz=32, num_updates=6020, lr=4.44544e-05, gnorm=1.857, clip=100, loss_scale=512, train_wall=19, gb_free=15.1, wall=16479
2023-01-09 08:12:32 - progress_bar.py[line:272] - INFO: epoch 002:   2373 / 3665 loss=5.426, loss_v1=0, loss_v2=0, nll_loss=4.554, ntokens=993.4, nsentences=32, sample_size=993.4, sample_size_v1=0, sample_size_v2=0, ppl=23.48, wps=508.5, ups=0.51, wpb=993.4, bsz=32, num_updates=6030, lr=4.44399e-05, gnorm=2.019, clip=100, loss_scale=512, train_wall=20, gb_free=15.5, wall=16499
2023-01-09 08:12:52 - progress_bar.py[line:272] - INFO: epoch 002:   2383 / 3665 loss=5.421, loss_v1=0, loss_v2=0, nll_loss=4.553, ntokens=745.2, nsentences=32, sample_size=745.2, sample_size_v1=0, sample_size_v2=0, ppl=23.47, wps=381.3, ups=0.51, wpb=745.2, bsz=32, num_updates=6040, lr=4.44254e-05, gnorm=2.283, clip=100, loss_scale=512, train_wall=20, gb_free=15.3, wall=16518
2023-01-09 08:13:12 - progress_bar.py[line:272] - INFO: epoch 002:   2393 / 3665 loss=5.375, loss_v1=0, loss_v2=0, nll_loss=4.5, ntokens=993.8, nsentences=32, sample_size=993.8, sample_size_v1=0, sample_size_v2=0, ppl=22.63, wps=505.6, ups=0.51, wpb=993.8, bsz=32, num_updates=6050, lr=4.44109e-05, gnorm=1.831, clip=100, loss_scale=512, train_wall=20, gb_free=15.2, wall=16538
2023-01-09 08:13:31 - progress_bar.py[line:272] - INFO: epoch 002:   2403 / 3665 loss=5.386, loss_v1=0, loss_v2=0, nll_loss=4.513, ntokens=1002.8, nsentences=32, sample_size=1002.8, sample_size_v1=0, sample_size_v2=0, ppl=22.84, wps=510.8, ups=0.51, wpb=1002.8, bsz=32, num_updates=6060, lr=4.43964e-05, gnorm=1.745, clip=100, loss_scale=512, train_wall=20, gb_free=15.5, wall=16558
2023-01-09 08:13:51 - progress_bar.py[line:272] - INFO: epoch 002:   2413 / 3665 loss=5.36, loss_v1=0, loss_v2=0, nll_loss=4.481, ntokens=678.6, nsentences=32, sample_size=678.6, sample_size_v1=0, sample_size_v2=0, ppl=22.34, wps=348.1, ups=0.51, wpb=678.6, bsz=32, num_updates=6070, lr=4.43819e-05, gnorm=2.107, clip=100, loss_scale=512, train_wall=19, gb_free=15.2, wall=16577
2023-01-09 08:14:10 - progress_bar.py[line:272] - INFO: epoch 002:   2423 / 3665 loss=5.324, loss_v1=0, loss_v2=0, nll_loss=4.44, ntokens=818.3, nsentences=32, sample_size=818.3, sample_size_v1=0, sample_size_v2=0, ppl=21.71, wps=418.5, ups=0.51, wpb=818.3, bsz=32, num_updates=6080, lr=4.43674e-05, gnorm=1.749, clip=100, loss_scale=512, train_wall=20, gb_free=15.6, wall=16597
2023-01-09 08:14:30 - progress_bar.py[line:272] - INFO: epoch 002:   2433 / 3665 loss=5.276, loss_v1=0, loss_v2=0, nll_loss=4.394, ntokens=1001.5, nsentences=32, sample_size=1001.5, sample_size_v1=0, sample_size_v2=0, ppl=21.02, wps=510.7, ups=0.51, wpb=1001.5, bsz=32, num_updates=6090, lr=4.43528e-05, gnorm=1.722, clip=100, loss_scale=512, train_wall=20, gb_free=15, wall=16616
2023-01-09 08:14:49 - progress_bar.py[line:272] - INFO: epoch 002:   2443 / 3665 loss=5.365, loss_v1=0, loss_v2=0, nll_loss=4.488, ntokens=691.8, nsentences=32, sample_size=691.8, sample_size_v1=0, sample_size_v2=0, ppl=22.44, wps=354.9, ups=0.51, wpb=691.8, bsz=32, num_updates=6100, lr=4.43383e-05, gnorm=2.045, clip=100, loss_scale=512, train_wall=19, gb_free=15.5, wall=16636
2023-01-09 08:15:09 - progress_bar.py[line:272] - INFO: epoch 002:   2453 / 3665 loss=5.427, loss_v1=0, loss_v2=0, nll_loss=4.558, ntokens=958, nsentences=32, sample_size=958, sample_size_v1=0, sample_size_v2=0, ppl=23.55, wps=487.7, ups=0.51, wpb=958, bsz=32, num_updates=6110, lr=4.43238e-05, gnorm=1.598, clip=100, loss_scale=512, train_wall=20, gb_free=15.5, wall=16655
2023-01-09 08:15:29 - progress_bar.py[line:272] - INFO: epoch 002:   2463 / 3665 loss=5.367, loss_v1=0, loss_v2=0, nll_loss=4.49, ntokens=918.7, nsentences=32, sample_size=918.7, sample_size_v1=0, sample_size_v2=0, ppl=22.47, wps=467.6, ups=0.51, wpb=918.7, bsz=32, num_updates=6120, lr=4.43093e-05, gnorm=1.729, clip=100, loss_scale=512, train_wall=20, gb_free=15.5, wall=16675
2023-01-09 08:15:48 - progress_bar.py[line:272] - INFO: epoch 002:   2473 / 3665 loss=5.443, loss_v1=0, loss_v2=0, nll_loss=4.574, ntokens=928.6, nsentences=32, sample_size=928.6, sample_size_v1=0, sample_size_v2=0, ppl=23.82, wps=472, ups=0.51, wpb=928.6, bsz=32, num_updates=6130, lr=4.42948e-05, gnorm=1.737, clip=100, loss_scale=512, train_wall=20, gb_free=15.1, wall=16695
2023-01-09 08:16:08 - progress_bar.py[line:272] - INFO: epoch 002:   2483 / 3665 loss=5.387, loss_v1=0, loss_v2=0, nll_loss=4.513, ntokens=799.1, nsentences=32, sample_size=799.1, sample_size_v1=0, sample_size_v2=0, ppl=22.83, wps=407.9, ups=0.51, wpb=799.1, bsz=32, num_updates=6140, lr=4.42803e-05, gnorm=1.925, clip=100, loss_scale=512, train_wall=20, gb_free=15.5, wall=16714
2023-01-09 08:16:28 - progress_bar.py[line:272] - INFO: epoch 002:   2493 / 3665 loss=5.38, loss_v1=0, loss_v2=0, nll_loss=4.508, ntokens=1005.6, nsentences=32, sample_size=1005.6, sample_size_v1=0, sample_size_v2=0, ppl=22.76, wps=503.8, ups=0.5, wpb=1005.6, bsz=32, num_updates=6150, lr=4.42658e-05, gnorm=1.662, clip=100, loss_scale=512, train_wall=20, gb_free=15.3, wall=16734
2023-01-09 08:16:48 - progress_bar.py[line:272] - INFO: epoch 002:   2503 / 3665 loss=5.486, loss_v1=0, loss_v2=0, nll_loss=4.621, ntokens=1007.3, nsentences=32, sample_size=1007.3, sample_size_v1=0, sample_size_v2=0, ppl=24.6, wps=503.4, ups=0.5, wpb=1007.3, bsz=32, num_updates=6160, lr=4.42513e-05, gnorm=1.723, clip=100, loss_scale=512, train_wall=20, gb_free=14.9, wall=16754
2023-01-09 08:17:08 - progress_bar.py[line:272] - INFO: epoch 002:   2513 / 3665 loss=5.409, loss_v1=0, loss_v2=0, nll_loss=4.536, ntokens=734.7, nsentences=32, sample_size=734.7, sample_size_v1=0, sample_size_v2=0, ppl=23.2, wps=370.1, ups=0.5, wpb=734.7, bsz=32, num_updates=6170, lr=4.42367e-05, gnorm=2.003, clip=100, loss_scale=512, train_wall=20, gb_free=15.7, wall=16774
2023-01-09 08:17:28 - progress_bar.py[line:272] - INFO: epoch 002:   2523 / 3665 loss=5.361, loss_v1=0, loss_v2=0, nll_loss=4.483, ntokens=1020.1, nsentences=32, sample_size=1020.1, sample_size_v1=0, sample_size_v2=0, ppl=22.36, wps=510, ups=0.5, wpb=1020.1, bsz=32, num_updates=6180, lr=4.42222e-05, gnorm=1.589, clip=100, loss_scale=512, train_wall=20, gb_free=15.5, wall=16794
2023-01-09 08:17:48 - progress_bar.py[line:272] - INFO: epoch 002:   2533 / 3665 loss=5.546, loss_v1=0, loss_v2=0, nll_loss=4.69, ntokens=975.3, nsentences=32, sample_size=975.3, sample_size_v1=0, sample_size_v2=0, ppl=25.81, wps=488.8, ups=0.5, wpb=975.3, bsz=32, num_updates=6190, lr=4.42077e-05, gnorm=1.713, clip=100, loss_scale=512, train_wall=20, gb_free=15.3, wall=16814
2023-01-09 08:18:08 - progress_bar.py[line:272] - INFO: epoch 002:   2543 / 3665 loss=5.358, loss_v1=0, loss_v2=0, nll_loss=4.483, ntokens=855.9, nsentences=32, sample_size=855.9, sample_size_v1=0, sample_size_v2=0, ppl=22.36, wps=431.8, ups=0.5, wpb=855.9, bsz=32, num_updates=6200, lr=4.41932e-05, gnorm=1.699, clip=100, loss_scale=512, train_wall=20, gb_free=15.7, wall=16834
2023-01-09 08:18:27 - progress_bar.py[line:272] - INFO: epoch 002:   2553 / 3665 loss=5.348, loss_v1=0, loss_v2=0, nll_loss=4.469, ntokens=1039.1, nsentences=32, sample_size=1039.1, sample_size_v1=0, sample_size_v2=0, ppl=22.15, wps=523.1, ups=0.5, wpb=1039.1, bsz=32, num_updates=6210, lr=4.41787e-05, gnorm=1.641, clip=100, loss_scale=512, train_wall=20, gb_free=15.2, wall=16854
2023-01-09 08:18:47 - progress_bar.py[line:272] - INFO: epoch 002:   2563 / 3665 loss=5.45, loss_v1=0, loss_v2=0, nll_loss=4.582, ntokens=1017.9, nsentences=32, sample_size=1017.9, sample_size_v1=0, sample_size_v2=0, ppl=23.96, wps=512.7, ups=0.5, wpb=1017.9, bsz=32, num_updates=6220, lr=4.41642e-05, gnorm=1.597, clip=100, loss_scale=512, train_wall=20, gb_free=15.1, wall=16874
2023-01-09 08:19:07 - progress_bar.py[line:272] - INFO: epoch 002:   2573 / 3665 loss=5.337, loss_v1=0, loss_v2=0, nll_loss=4.46, ntokens=701.5, nsentences=32, sample_size=701.5, sample_size_v1=0, sample_size_v2=0, ppl=22.01, wps=356.8, ups=0.51, wpb=701.5, bsz=32, num_updates=6230, lr=4.41497e-05, gnorm=2.229, clip=100, loss_scale=512, train_wall=20, gb_free=14.9, wall=16893
2023-01-09 08:19:27 - progress_bar.py[line:272] - INFO: epoch 002:   2583 / 3665 loss=5.308, loss_v1=0, loss_v2=0, nll_loss=4.425, ntokens=826.2, nsentences=32, sample_size=826.2, sample_size_v1=0, sample_size_v2=0, ppl=21.48, wps=419.9, ups=0.51, wpb=826.2, bsz=32, num_updates=6240, lr=4.41351e-05, gnorm=1.765, clip=100, loss_scale=512, train_wall=20, gb_free=15.2, wall=16913
2023-01-09 08:19:46 - progress_bar.py[line:272] - INFO: epoch 002:   2593 / 3665 loss=5.387, loss_v1=0, loss_v2=0, nll_loss=4.512, ntokens=966, nsentences=32, sample_size=966, sample_size_v1=0, sample_size_v2=0, ppl=22.81, wps=489.6, ups=0.51, wpb=966, bsz=32, num_updates=6250, lr=4.41206e-05, gnorm=1.776, clip=100, loss_scale=512, train_wall=20, gb_free=15.2, wall=16933
2023-01-09 08:20:06 - progress_bar.py[line:272] - INFO: epoch 002:   2603 / 3665 loss=5.407, loss_v1=0, loss_v2=0, nll_loss=4.532, ntokens=774, nsentences=32, sample_size=774, sample_size_v1=0, sample_size_v2=0, ppl=23.14, wps=394.1, ups=0.51, wpb=774, bsz=32, num_updates=6260, lr=4.41061e-05, gnorm=1.846, clip=100, loss_scale=512, train_wall=20, gb_free=15.4, wall=16952
2023-01-09 08:20:26 - progress_bar.py[line:272] - INFO: epoch 002:   2613 / 3665 loss=5.408, loss_v1=0, loss_v2=0, nll_loss=4.538, ntokens=1033.2, nsentences=32, sample_size=1033.2, sample_size_v1=0, sample_size_v2=0, ppl=23.24, wps=524, ups=0.51, wpb=1033.2, bsz=32, num_updates=6270, lr=4.40916e-05, gnorm=1.538, clip=100, loss_scale=512, train_wall=20, gb_free=15.6, wall=16972
2023-01-09 08:20:46 - progress_bar.py[line:272] - INFO: epoch 002:   2623 / 3665 loss=5.398, loss_v1=0, loss_v2=0, nll_loss=4.526, ntokens=1133, nsentences=32, sample_size=1133, sample_size_v1=0, sample_size_v2=0, ppl=23.04, wps=571.6, ups=0.5, wpb=1133, bsz=32, num_updates=6280, lr=4.40771e-05, gnorm=1.529, clip=100, loss_scale=512, train_wall=20, gb_free=15.2, wall=16992
2023-01-09 08:21:05 - progress_bar.py[line:272] - INFO: epoch 002:   2633 / 3665 loss=5.508, loss_v1=0, loss_v2=0, nll_loss=4.646, ntokens=875.3, nsentences=32, sample_size=875.3, sample_size_v1=0, sample_size_v2=0, ppl=25.04, wps=444.3, ups=0.51, wpb=875.3, bsz=32, num_updates=6290, lr=4.40626e-05, gnorm=2.196, clip=100, loss_scale=512, train_wall=20, gb_free=15.6, wall=17012
2023-01-09 08:21:25 - progress_bar.py[line:272] - INFO: epoch 002:   2643 / 3665 loss=5.382, loss_v1=0, loss_v2=0, nll_loss=4.507, ntokens=969, nsentences=32, sample_size=969, sample_size_v1=0, sample_size_v2=0, ppl=22.74, wps=490.8, ups=0.51, wpb=969, bsz=32, num_updates=6300, lr=4.40481e-05, gnorm=1.68, clip=100, loss_scale=512, train_wall=20, gb_free=15.3, wall=17031
2023-01-09 08:21:45 - progress_bar.py[line:272] - INFO: epoch 002:   2653 / 3665 loss=5.356, loss_v1=0, loss_v2=0, nll_loss=4.481, ntokens=1033.8, nsentences=32, sample_size=1033.8, sample_size_v1=0, sample_size_v2=0, ppl=22.32, wps=522.6, ups=0.51, wpb=1033.8, bsz=32, num_updates=6310, lr=4.40336e-05, gnorm=1.635, clip=100, loss_scale=512, train_wall=20, gb_free=15.1, wall=17051
2023-01-09 08:22:05 - progress_bar.py[line:272] - INFO: epoch 002:   2663 / 3665 loss=5.502, loss_v1=0, loss_v2=0, nll_loss=4.64, ntokens=938.9, nsentences=32, sample_size=938.9, sample_size_v1=0, sample_size_v2=0, ppl=24.94, wps=475.7, ups=0.51, wpb=938.9, bsz=32, num_updates=6320, lr=4.4019e-05, gnorm=1.811, clip=100, loss_scale=512, train_wall=20, gb_free=15.5, wall=17071
2023-01-09 08:22:24 - progress_bar.py[line:272] - INFO: epoch 002:   2673 / 3665 loss=5.358, loss_v1=0, loss_v2=0, nll_loss=4.481, ntokens=777.3, nsentences=32, sample_size=777.3, sample_size_v1=0, sample_size_v2=0, ppl=22.33, wps=395.1, ups=0.51, wpb=777.3, bsz=32, num_updates=6330, lr=4.40045e-05, gnorm=1.988, clip=100, loss_scale=512, train_wall=20, gb_free=15.5, wall=17091
2023-01-09 08:22:44 - progress_bar.py[line:272] - INFO: epoch 002:   2683 / 3665 loss=5.377, loss_v1=0, loss_v2=0, nll_loss=4.503, ntokens=978.3, nsentences=32, sample_size=978.3, sample_size_v1=0, sample_size_v2=0, ppl=22.67, wps=496.2, ups=0.51, wpb=978.3, bsz=32, num_updates=6340, lr=4.399e-05, gnorm=1.53, clip=100, loss_scale=512, train_wall=20, gb_free=15.4, wall=17110
2023-01-09 08:23:04 - progress_bar.py[line:272] - INFO: epoch 002:   2693 / 3665 loss=5.37, loss_v1=0, loss_v2=0, nll_loss=4.496, ntokens=950.7, nsentences=32, sample_size=950.7, sample_size_v1=0, sample_size_v2=0, ppl=22.56, wps=481.9, ups=0.51, wpb=950.7, bsz=32, num_updates=6350, lr=4.39755e-05, gnorm=1.601, clip=100, loss_scale=512, train_wall=20, gb_free=15.7, wall=17130
2023-01-09 08:23:23 - progress_bar.py[line:272] - INFO: epoch 002:   2703 / 3665 loss=5.34, loss_v1=0, loss_v2=0, nll_loss=4.458, ntokens=723.4, nsentences=32, sample_size=723.4, sample_size_v1=0, sample_size_v2=0, ppl=21.98, wps=368.1, ups=0.51, wpb=723.4, bsz=32, num_updates=6360, lr=4.3961e-05, gnorm=2.213, clip=100, loss_scale=512, train_wall=20, gb_free=15.5, wall=17150
2023-01-09 08:23:43 - progress_bar.py[line:272] - INFO: epoch 002:   2713 / 3665 loss=5.326, loss_v1=0, loss_v2=0, nll_loss=4.443, ntokens=1068.4, nsentences=32, sample_size=1068.4, sample_size_v1=0, sample_size_v2=0, ppl=21.75, wps=540.4, ups=0.51, wpb=1068.4, bsz=32, num_updates=6370, lr=4.39465e-05, gnorm=1.498, clip=100, loss_scale=512, train_wall=20, gb_free=15.1, wall=17169
2023-01-09 08:24:03 - progress_bar.py[line:272] - INFO: epoch 002:   2723 / 3665 loss=5.488, loss_v1=0, loss_v2=0, nll_loss=4.63, ntokens=1010.3, nsentences=32, sample_size=1010.3, sample_size_v1=0, sample_size_v2=0, ppl=24.76, wps=510.6, ups=0.51, wpb=1010.3, bsz=32, num_updates=6380, lr=4.3932e-05, gnorm=1.749, clip=100, loss_scale=512, train_wall=20, gb_free=15.6, wall=17189
2023-01-09 08:24:23 - progress_bar.py[line:272] - INFO: epoch 002:   2733 / 3665 loss=5.446, loss_v1=0, loss_v2=0, nll_loss=4.578, ntokens=868.9, nsentences=32, sample_size=868.9, sample_size_v1=0, sample_size_v2=0, ppl=23.89, wps=440.2, ups=0.51, wpb=868.9, bsz=32, num_updates=6390, lr=4.39174e-05, gnorm=1.861, clip=100, loss_scale=512, train_wall=20, gb_free=15.3, wall=17209
2023-01-09 08:24:42 - progress_bar.py[line:272] - INFO: epoch 002:   2743 / 3665 loss=5.333, loss_v1=0, loss_v2=0, nll_loss=4.45, ntokens=865.6, nsentences=32, sample_size=865.6, sample_size_v1=0, sample_size_v2=0, ppl=21.86, wps=440.1, ups=0.51, wpb=865.6, bsz=32, num_updates=6400, lr=4.39029e-05, gnorm=1.805, clip=100, loss_scale=512, train_wall=20, gb_free=15.2, wall=17229
2023-01-09 08:25:02 - progress_bar.py[line:272] - INFO: epoch 002:   2753 / 3665 loss=5.43, loss_v1=0, loss_v2=0, nll_loss=4.562, ntokens=985.4, nsentences=32, sample_size=985.4, sample_size_v1=0, sample_size_v2=0, ppl=23.62, wps=498.5, ups=0.51, wpb=985.4, bsz=32, num_updates=6410, lr=4.38884e-05, gnorm=1.662, clip=100, loss_scale=512, train_wall=20, gb_free=15.6, wall=17248
2023-01-09 08:25:12 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 512.0
2023-01-09 08:25:24 - progress_bar.py[line:272] - INFO: epoch 002:   2764 / 3665 loss=5.413, loss_v1=0, loss_v2=0, nll_loss=4.544, ntokens=793.7, nsentences=32, sample_size=793.7, sample_size_v1=0, sample_size_v2=0, ppl=23.33, wps=366.3, ups=0.46, wpb=793.7, bsz=32, num_updates=6420, lr=4.38739e-05, gnorm=2.016, clip=100, loss_scale=512, train_wall=22, gb_free=15.1, wall=17270
2023-01-09 08:25:43 - progress_bar.py[line:272] - INFO: epoch 002:   2774 / 3665 loss=5.355, loss_v1=0, loss_v2=0, nll_loss=4.474, ntokens=977.5, nsentences=32, sample_size=977.5, sample_size_v1=0, sample_size_v2=0, ppl=22.22, wps=495.3, ups=0.51, wpb=977.5, bsz=32, num_updates=6430, lr=4.38594e-05, gnorm=1.65, clip=100, loss_scale=512, train_wall=20, gb_free=15.4, wall=17290
2023-01-09 08:26:03 - progress_bar.py[line:272] - INFO: epoch 002:   2784 / 3665 loss=5.467, loss_v1=0, loss_v2=0, nll_loss=4.602, ntokens=1098.5, nsentences=32, sample_size=1098.5, sample_size_v1=0, sample_size_v2=0, ppl=24.28, wps=553.5, ups=0.5, wpb=1098.5, bsz=32, num_updates=6440, lr=4.38449e-05, gnorm=1.465, clip=100, loss_scale=512, train_wall=20, gb_free=15.1, wall=17310
2023-01-09 08:26:23 - progress_bar.py[line:272] - INFO: epoch 002:   2794 / 3665 loss=5.348, loss_v1=0, loss_v2=0, nll_loss=4.472, ntokens=773.8, nsentences=32, sample_size=773.8, sample_size_v1=0, sample_size_v2=0, ppl=22.2, wps=394.1, ups=0.51, wpb=773.8, bsz=32, num_updates=6450, lr=4.38304e-05, gnorm=1.925, clip=100, loss_scale=512, train_wall=20, gb_free=15.6, wall=17329
2023-01-09 08:26:43 - progress_bar.py[line:272] - INFO: epoch 002:   2804 / 3665 loss=5.359, loss_v1=0, loss_v2=0, nll_loss=4.481, ntokens=994.8, nsentences=32, sample_size=994.8, sample_size_v1=0, sample_size_v2=0, ppl=22.33, wps=504.1, ups=0.51, wpb=994.8, bsz=32, num_updates=6460, lr=4.38159e-05, gnorm=1.744, clip=100, loss_scale=512, train_wall=20, gb_free=15.5, wall=17349
2023-01-09 08:27:02 - progress_bar.py[line:272] - INFO: epoch 002:   2814 / 3665 loss=5.417, loss_v1=0, loss_v2=0, nll_loss=4.546, ntokens=1089.1, nsentences=32, sample_size=1089.1, sample_size_v1=0, sample_size_v2=0, ppl=23.36, wps=550.9, ups=0.51, wpb=1089.1, bsz=32, num_updates=6470, lr=4.38013e-05, gnorm=1.489, clip=100, loss_scale=512, train_wall=20, gb_free=15.2, wall=17369
2023-01-09 08:27:22 - progress_bar.py[line:272] - INFO: epoch 002:   2824 / 3665 loss=5.379, loss_v1=0, loss_v2=0, nll_loss=4.505, ntokens=738.1, nsentences=32, sample_size=738.1, sample_size_v1=0, sample_size_v2=0, ppl=22.71, wps=376, ups=0.51, wpb=738.1, bsz=32, num_updates=6480, lr=4.37868e-05, gnorm=1.994, clip=100, loss_scale=512, train_wall=20, gb_free=15.5, wall=17388
2023-01-09 08:27:42 - progress_bar.py[line:272] - INFO: epoch 002:   2834 / 3665 loss=5.393, loss_v1=0, loss_v2=0, nll_loss=4.521, ntokens=957.3, nsentences=32, sample_size=957.3, sample_size_v1=0, sample_size_v2=0, ppl=22.95, wps=484.6, ups=0.51, wpb=957.3, bsz=32, num_updates=6490, lr=4.37723e-05, gnorm=1.839, clip=100, loss_scale=512, train_wall=20, gb_free=15.6, wall=17408
2023-01-09 08:28:02 - progress_bar.py[line:272] - INFO: epoch 002:   2844 / 3665 loss=5.358, loss_v1=0, loss_v2=0, nll_loss=4.48, ntokens=1013.2, nsentences=32, sample_size=1013.2, sample_size_v1=0, sample_size_v2=0, ppl=22.32, wps=513.2, ups=0.51, wpb=1013.2, bsz=32, num_updates=6500, lr=4.37578e-05, gnorm=1.774, clip=100, loss_scale=512, train_wall=20, gb_free=15.7, wall=17428
2023-01-09 08:28:02 - train.py[line:445] - INFO: begin validation on "valid" subset
slice_id 0 seek offset 0
slice_id 0 seek offset 0
2023-01-09 08:32:49 - progress_bar.py[line:282] - INFO: epoch 002 | valid on 'valid' subset | loss 5.38 | loss_v1 0 | loss_v2 0 | nll_loss 4.488 | ntokens 117.271 | nsentences 4 | sample_size 117.271 | sample_size_v1 0 | sample_size_v2 0 | AP 0 | total positives 21.7553 | TP 0 | FP 6.39015 | ppl 22.44 | wps 510.6 | wpb 117.3 | bsz 4 | num_updates 6500 | best_AP 0
2023-01-09 08:32:49 - checkpoint_utils.py[line:64] - INFO: Preparing to save checkpoint for epoch 2 @ 6500 updates
2023-01-09 08:32:49 - trainer.py[line:431] - INFO: Saving checkpoint to ../../checkpoints/OFA/detection_checkpoints/10_5e-5_512/checkpoint_2_6500.pt
2023-01-09 08:32:52 - trainer.py[line:441] - INFO: Finished saving checkpoint to ../../checkpoints/OFA/detection_checkpoints/10_5e-5_512/checkpoint_2_6500.pt
2023-01-09 08:34:04 - checkpoint_utils.py[line:133] - INFO: Saved checkpoint ../../checkpoints/OFA/detection_checkpoints/10_5e-5_512/checkpoint_2_6500.pt (epoch 2 @ 6500 updates, score 0.0) (writing took 74.91758675780147 seconds)
2023-01-09 08:34:23 - progress_bar.py[line:272] - INFO: epoch 002:   2854 / 3665 loss=5.445, loss_v1=0, loss_v2=0, nll_loss=4.574, ntokens=813.9, nsentences=32, sample_size=813.9, sample_size_v1=0, sample_size_v2=0, ppl=23.82, wps=21.3, ups=0.03, wpb=813.9, bsz=32, num_updates=6510, lr=4.37433e-05, gnorm=1.817, clip=100, loss_scale=512, train_wall=19, gb_free=15.7, wall=17809
2023-01-09 08:34:42 - progress_bar.py[line:272] - INFO: epoch 002:   2864 / 3665 loss=5.326, loss_v1=0, loss_v2=0, nll_loss=4.447, ntokens=742.6, nsentences=32, sample_size=742.6, sample_size_v1=0, sample_size_v2=0, ppl=21.81, wps=383.2, ups=0.52, wpb=742.6, bsz=32, num_updates=6520, lr=4.37288e-05, gnorm=1.848, clip=100, loss_scale=512, train_wall=19, gb_free=15.6, wall=17829
2023-01-09 08:34:56 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 256.0
2023-01-09 08:35:04 - progress_bar.py[line:272] - INFO: epoch 002:   2875 / 3665 loss=5.316, loss_v1=0, loss_v2=0, nll_loss=4.434, ntokens=913, nsentences=32, sample_size=913, sample_size_v1=0, sample_size_v2=0, ppl=21.62, wps=424.6, ups=0.47, wpb=913, bsz=32, num_updates=6530, lr=4.37143e-05, gnorm=1.748, clip=100, loss_scale=256, train_wall=21, gb_free=15.3, wall=17850
2023-01-09 08:35:24 - progress_bar.py[line:272] - INFO: epoch 002:   2885 / 3665 loss=5.435, loss_v1=0, loss_v2=0, nll_loss=4.564, ntokens=901.6, nsentences=32, sample_size=901.6, sample_size_v1=0, sample_size_v2=0, ppl=23.66, wps=459.8, ups=0.51, wpb=901.6, bsz=32, num_updates=6540, lr=4.36997e-05, gnorm=1.877, clip=100, loss_scale=256, train_wall=20, gb_free=15.4, wall=17870
2023-01-09 08:35:43 - progress_bar.py[line:272] - INFO: epoch 002:   2895 / 3665 loss=5.345, loss_v1=0, loss_v2=0, nll_loss=4.467, ntokens=789.2, nsentences=32, sample_size=789.2, sample_size_v1=0, sample_size_v2=0, ppl=22.12, wps=403.3, ups=0.51, wpb=789.2, bsz=32, num_updates=6550, lr=4.36852e-05, gnorm=1.895, clip=100, loss_scale=256, train_wall=20, gb_free=15.6, wall=17889
2023-01-09 08:36:03 - progress_bar.py[line:272] - INFO: epoch 002:   2905 / 3665 loss=5.384, loss_v1=0, loss_v2=0, nll_loss=4.51, ntokens=1053.9, nsentences=32, sample_size=1053.9, sample_size_v1=0, sample_size_v2=0, ppl=22.79, wps=536.1, ups=0.51, wpb=1053.9, bsz=32, num_updates=6560, lr=4.36707e-05, gnorm=1.56, clip=100, loss_scale=256, train_wall=20, gb_free=15.4, wall=17909
2023-01-09 08:36:22 - progress_bar.py[line:272] - INFO: epoch 002:   2915 / 3665 loss=5.456, loss_v1=0, loss_v2=0, nll_loss=4.59, ntokens=1074.1, nsentences=32, sample_size=1074.1, sample_size_v1=0, sample_size_v2=0, ppl=24.09, wps=546.6, ups=0.51, wpb=1074.1, bsz=32, num_updates=6570, lr=4.36562e-05, gnorm=1.602, clip=100, loss_scale=256, train_wall=20, gb_free=15, wall=17929
2023-01-09 08:36:42 - progress_bar.py[line:272] - INFO: epoch 002:   2925 / 3665 loss=5.407, loss_v1=0, loss_v2=0, nll_loss=4.537, ntokens=794.1, nsentences=32, sample_size=794.1, sample_size_v1=0, sample_size_v2=0, ppl=23.21, wps=406.2, ups=0.51, wpb=794.1, bsz=32, num_updates=6580, lr=4.36417e-05, gnorm=1.873, clip=100, loss_scale=256, train_wall=20, gb_free=15.7, wall=17948
2023-01-09 08:37:02 - progress_bar.py[line:272] - INFO: epoch 002:   2935 / 3665 loss=5.287, loss_v1=0, loss_v2=0, nll_loss=4.403, ntokens=947, nsentences=32, sample_size=947, sample_size_v1=0, sample_size_v2=0, ppl=21.15, wps=483, ups=0.51, wpb=947, bsz=32, num_updates=6590, lr=4.36272e-05, gnorm=1.729, clip=100, loss_scale=256, train_wall=20, gb_free=15.4, wall=17968
2023-01-09 08:37:21 - progress_bar.py[line:272] - INFO: epoch 002:   2945 / 3665 loss=5.496, loss_v1=0, loss_v2=0, nll_loss=4.634, ntokens=1241.7, nsentences=32, sample_size=1241.7, sample_size_v1=0, sample_size_v2=0, ppl=24.83, wps=627.8, ups=0.51, wpb=1241.7, bsz=32, num_updates=6600, lr=4.36127e-05, gnorm=1.477, clip=90, loss_scale=256, train_wall=20, gb_free=15, wall=17988
2023-01-09 08:37:41 - progress_bar.py[line:272] - INFO: epoch 002:   2955 / 3665 loss=5.352, loss_v1=0, loss_v2=0, nll_loss=4.474, ntokens=826.3, nsentences=32, sample_size=826.3, sample_size_v1=0, sample_size_v2=0, ppl=22.22, wps=421.7, ups=0.51, wpb=826.3, bsz=32, num_updates=6610, lr=4.35982e-05, gnorm=1.9, clip=100, loss_scale=256, train_wall=20, gb_free=15.6, wall=18007
2023-01-09 08:38:01 - progress_bar.py[line:272] - INFO: epoch 002:   2965 / 3665 loss=5.371, loss_v1=0, loss_v2=0, nll_loss=4.495, ntokens=1004, nsentences=32, sample_size=1004, sample_size_v1=0, sample_size_v2=0, ppl=22.55, wps=511.2, ups=0.51, wpb=1004, bsz=32, num_updates=6620, lr=4.35836e-05, gnorm=1.607, clip=100, loss_scale=256, train_wall=20, gb_free=15.5, wall=18027
2023-01-09 08:38:21 - progress_bar.py[line:272] - INFO: epoch 002:   2975 / 3665 loss=5.428, loss_v1=0, loss_v2=0, nll_loss=4.559, ntokens=1049.2, nsentences=32, sample_size=1049.2, sample_size_v1=0, sample_size_v2=0, ppl=23.57, wps=527.3, ups=0.5, wpb=1049.2, bsz=32, num_updates=6630, lr=4.35691e-05, gnorm=1.638, clip=100, loss_scale=256, train_wall=20, gb_free=15.1, wall=18047
2023-01-09 08:38:41 - progress_bar.py[line:272] - INFO: epoch 002:   2985 / 3665 loss=5.347, loss_v1=0, loss_v2=0, nll_loss=4.468, ntokens=903.4, nsentences=32, sample_size=903.4, sample_size_v1=0, sample_size_v2=0, ppl=22.14, wps=449.9, ups=0.5, wpb=903.4, bsz=32, num_updates=6640, lr=4.35546e-05, gnorm=1.792, clip=100, loss_scale=256, train_wall=20, gb_free=15.4, wall=18067
2023-01-09 08:39:01 - progress_bar.py[line:272] - INFO: epoch 002:   2995 / 3665 loss=5.368, loss_v1=0, loss_v2=0, nll_loss=4.491, ntokens=972.2, nsentences=32, sample_size=972.2, sample_size_v1=0, sample_size_v2=0, ppl=22.49, wps=484.6, ups=0.5, wpb=972.2, bsz=32, num_updates=6650, lr=4.35401e-05, gnorm=1.738, clip=100, loss_scale=256, train_wall=20, gb_free=15.6, wall=18087
2023-01-09 08:39:21 - progress_bar.py[line:272] - INFO: epoch 002:   3005 / 3665 loss=5.31, loss_v1=0, loss_v2=0, nll_loss=4.428, ntokens=1016.8, nsentences=32, sample_size=1016.8, sample_size_v1=0, sample_size_v2=0, ppl=21.52, wps=506.8, ups=0.5, wpb=1016.8, bsz=32, num_updates=6660, lr=4.35256e-05, gnorm=1.638, clip=100, loss_scale=256, train_wall=20, gb_free=15.3, wall=18107
2023-01-09 08:39:41 - progress_bar.py[line:272] - INFO: epoch 002:   3015 / 3665 loss=5.311, loss_v1=0, loss_v2=0, nll_loss=4.426, ntokens=702.2, nsentences=32, sample_size=702.2, sample_size_v1=0, sample_size_v2=0, ppl=21.5, wps=355.3, ups=0.51, wpb=702.2, bsz=32, num_updates=6670, lr=4.35111e-05, gnorm=1.941, clip=100, loss_scale=256, train_wall=20, gb_free=15.6, wall=18127
2023-01-09 08:40:00 - progress_bar.py[line:272] - INFO: epoch 002:   3025 / 3665 loss=5.349, loss_v1=0, loss_v2=0, nll_loss=4.473, ntokens=1010.5, nsentences=32, sample_size=1010.5, sample_size_v1=0, sample_size_v2=0, ppl=22.21, wps=513.6, ups=0.51, wpb=1010.5, bsz=32, num_updates=6680, lr=4.34966e-05, gnorm=1.593, clip=100, loss_scale=256, train_wall=20, gb_free=15.2, wall=18146
2023-01-09 08:40:20 - progress_bar.py[line:272] - INFO: epoch 002:   3035 / 3665 loss=5.263, loss_v1=0, loss_v2=0, nll_loss=4.371, ntokens=966.3, nsentences=32, sample_size=966.3, sample_size_v1=0, sample_size_v2=0, ppl=20.7, wps=491, ups=0.51, wpb=966.3, bsz=32, num_updates=6690, lr=4.3482e-05, gnorm=1.668, clip=100, loss_scale=256, train_wall=20, gb_free=15.1, wall=18166
2023-01-09 08:40:40 - progress_bar.py[line:272] - INFO: epoch 002:   3045 / 3665 loss=5.508, loss_v1=0, loss_v2=0, nll_loss=4.65, ntokens=884.1, nsentences=32, sample_size=884.1, sample_size_v1=0, sample_size_v2=0, ppl=25.11, wps=449.7, ups=0.51, wpb=884.1, bsz=32, num_updates=6700, lr=4.34675e-05, gnorm=1.87, clip=100, loss_scale=256, train_wall=20, gb_free=15.5, wall=18186
2023-01-09 08:40:59 - progress_bar.py[line:272] - INFO: epoch 002:   3055 / 3665 loss=5.325, loss_v1=0, loss_v2=0, nll_loss=4.443, ntokens=893.7, nsentences=32, sample_size=893.7, sample_size_v1=0, sample_size_v2=0, ppl=21.75, wps=455, ups=0.51, wpb=893.7, bsz=32, num_updates=6710, lr=4.3453e-05, gnorm=1.831, clip=100, loss_scale=256, train_wall=20, gb_free=15.6, wall=18205
2023-01-09 08:41:19 - progress_bar.py[line:272] - INFO: epoch 002:   3065 / 3665 loss=5.285, loss_v1=0, loss_v2=0, nll_loss=4.397, ntokens=1007, nsentences=32, sample_size=1007, sample_size_v1=0, sample_size_v2=0, ppl=21.07, wps=511.2, ups=0.51, wpb=1007, bsz=32, num_updates=6720, lr=4.34385e-05, gnorm=1.612, clip=100, loss_scale=256, train_wall=20, gb_free=15.3, wall=18225
2023-01-09 08:41:39 - progress_bar.py[line:272] - INFO: epoch 002:   3075 / 3665 loss=5.45, loss_v1=0, loss_v2=0, nll_loss=4.582, ntokens=1022, nsentences=32, sample_size=1022, sample_size_v1=0, sample_size_v2=0, ppl=23.95, wps=517.2, ups=0.51, wpb=1022, bsz=32, num_updates=6730, lr=4.3424e-05, gnorm=1.625, clip=100, loss_scale=256, train_wall=20, gb_free=15.4, wall=18245
2023-01-09 08:41:58 - progress_bar.py[line:272] - INFO: epoch 002:   3085 / 3665 loss=5.381, loss_v1=0, loss_v2=0, nll_loss=4.507, ntokens=865.8, nsentences=32, sample_size=865.8, sample_size_v1=0, sample_size_v2=0, ppl=22.74, wps=440.2, ups=0.51, wpb=865.8, bsz=32, num_updates=6740, lr=4.34095e-05, gnorm=1.852, clip=100, loss_scale=256, train_wall=20, gb_free=15.6, wall=18265
2023-01-09 08:42:18 - progress_bar.py[line:272] - INFO: epoch 002:   3095 / 3665 loss=5.386, loss_v1=0, loss_v2=0, nll_loss=4.51, ntokens=1005.2, nsentences=32, sample_size=1005.2, sample_size_v1=0, sample_size_v2=0, ppl=22.79, wps=510.3, ups=0.51, wpb=1005.2, bsz=32, num_updates=6750, lr=4.3395e-05, gnorm=1.663, clip=100, loss_scale=256, train_wall=20, gb_free=15, wall=18284
2023-01-09 08:42:38 - progress_bar.py[line:272] - INFO: epoch 002:   3105 / 3665 loss=5.497, loss_v1=0, loss_v2=0, nll_loss=4.637, ntokens=1017.9, nsentences=32, sample_size=1017.9, sample_size_v1=0, sample_size_v2=0, ppl=24.89, wps=515.4, ups=0.51, wpb=1017.9, bsz=32, num_updates=6760, lr=4.33805e-05, gnorm=1.68, clip=100, loss_scale=256, train_wall=20, gb_free=15.5, wall=18304
2023-01-09 08:42:57 - progress_bar.py[line:272] - INFO: epoch 002:   3115 / 3665 loss=5.445, loss_v1=0, loss_v2=0, nll_loss=4.579, ntokens=839.9, nsentences=32, sample_size=839.9, sample_size_v1=0, sample_size_v2=0, ppl=23.89, wps=427.3, ups=0.51, wpb=839.9, bsz=32, num_updates=6770, lr=4.33659e-05, gnorm=1.832, clip=100, loss_scale=256, train_wall=20, gb_free=15.3, wall=18324
2023-01-09 08:43:17 - progress_bar.py[line:272] - INFO: epoch 002:   3125 / 3665 loss=5.384, loss_v1=0, loss_v2=0, nll_loss=4.508, ntokens=996.5, nsentences=32, sample_size=996.5, sample_size_v1=0, sample_size_v2=0, ppl=22.75, wps=505, ups=0.51, wpb=996.5, bsz=32, num_updates=6780, lr=4.33514e-05, gnorm=1.639, clip=100, loss_scale=256, train_wall=20, gb_free=15.3, wall=18343
2023-01-09 08:43:37 - progress_bar.py[line:272] - INFO: epoch 002:   3135 / 3665 loss=5.431, loss_v1=0, loss_v2=0, nll_loss=4.562, ntokens=1042.3, nsentences=32, sample_size=1042.3, sample_size_v1=0, sample_size_v2=0, ppl=23.62, wps=526.6, ups=0.51, wpb=1042.3, bsz=32, num_updates=6790, lr=4.33369e-05, gnorm=1.443, clip=100, loss_scale=256, train_wall=20, gb_free=15.4, wall=18363
2023-01-09 08:43:57 - progress_bar.py[line:272] - INFO: epoch 002:   3145 / 3665 loss=5.363, loss_v1=0, loss_v2=0, nll_loss=4.488, ntokens=809.9, nsentences=32, sample_size=809.9, sample_size_v1=0, sample_size_v2=0, ppl=22.43, wps=412.6, ups=0.51, wpb=809.9, bsz=32, num_updates=6800, lr=4.33224e-05, gnorm=2, clip=100, loss_scale=256, train_wall=20, gb_free=15.3, wall=18383
2023-01-09 08:44:16 - progress_bar.py[line:272] - INFO: epoch 002:   3155 / 3665 loss=5.334, loss_v1=0, loss_v2=0, nll_loss=4.455, ntokens=884.5, nsentences=32, sample_size=884.5, sample_size_v1=0, sample_size_v2=0, ppl=21.93, wps=450.5, ups=0.51, wpb=884.5, bsz=32, num_updates=6810, lr=4.33079e-05, gnorm=1.817, clip=100, loss_scale=256, train_wall=20, gb_free=15, wall=18402
2023-01-09 08:44:36 - progress_bar.py[line:272] - INFO: epoch 002:   3165 / 3665 loss=5.424, loss_v1=0, loss_v2=0, nll_loss=4.551, ntokens=982.2, nsentences=32, sample_size=982.2, sample_size_v1=0, sample_size_v2=0, ppl=23.44, wps=498.2, ups=0.51, wpb=982.2, bsz=32, num_updates=6820, lr=4.32934e-05, gnorm=1.604, clip=100, loss_scale=256, train_wall=20, gb_free=15.6, wall=18422
2023-01-09 08:44:56 - progress_bar.py[line:272] - INFO: epoch 002:   3175 / 3665 loss=5.337, loss_v1=0, loss_v2=0, nll_loss=4.458, ntokens=737.5, nsentences=32, sample_size=737.5, sample_size_v1=0, sample_size_v2=0, ppl=21.98, wps=375.8, ups=0.51, wpb=737.5, bsz=32, num_updates=6830, lr=4.32789e-05, gnorm=1.962, clip=100, loss_scale=256, train_wall=20, gb_free=15.6, wall=18442
2023-01-09 08:45:15 - progress_bar.py[line:272] - INFO: epoch 002:   3185 / 3665 loss=5.313, loss_v1=0, loss_v2=0, nll_loss=4.435, ntokens=884, nsentences=32, sample_size=884, sample_size_v1=0, sample_size_v2=0, ppl=21.63, wps=449, ups=0.51, wpb=884, bsz=32, num_updates=6840, lr=4.32643e-05, gnorm=1.811, clip=100, loss_scale=256, train_wall=20, gb_free=15.5, wall=18462
2023-01-09 08:45:35 - progress_bar.py[line:272] - INFO: epoch 002:   3195 / 3665 loss=5.405, loss_v1=0, loss_v2=0, nll_loss=4.532, ntokens=1070.9, nsentences=32, sample_size=1070.9, sample_size_v1=0, sample_size_v2=0, ppl=23.14, wps=543.4, ups=0.51, wpb=1070.9, bsz=32, num_updates=6850, lr=4.32498e-05, gnorm=1.625, clip=100, loss_scale=256, train_wall=20, gb_free=15.5, wall=18481
2023-01-09 08:45:55 - progress_bar.py[line:272] - INFO: epoch 002:   3205 / 3665 loss=5.352, loss_v1=0, loss_v2=0, nll_loss=4.47, ntokens=768.9, nsentences=32, sample_size=768.9, sample_size_v1=0, sample_size_v2=0, ppl=22.16, wps=391.2, ups=0.51, wpb=768.9, bsz=32, num_updates=6860, lr=4.32353e-05, gnorm=1.866, clip=100, loss_scale=256, train_wall=20, gb_free=15.2, wall=18501
2023-01-09 08:46:14 - progress_bar.py[line:272] - INFO: epoch 002:   3215 / 3665 loss=5.329, loss_v1=0, loss_v2=0, nll_loss=4.452, ntokens=1013.8, nsentences=32, sample_size=1013.8, sample_size_v1=0, sample_size_v2=0, ppl=21.89, wps=513.6, ups=0.51, wpb=1013.8, bsz=32, num_updates=6870, lr=4.32208e-05, gnorm=1.59, clip=100, loss_scale=256, train_wall=20, gb_free=15.2, wall=18521
2023-01-09 08:46:34 - progress_bar.py[line:272] - INFO: epoch 002:   3225 / 3665 loss=5.358, loss_v1=0, loss_v2=0, nll_loss=4.479, ntokens=1194, nsentences=32, sample_size=1194, sample_size_v1=0, sample_size_v2=0, ppl=22.3, wps=603.5, ups=0.51, wpb=1194, bsz=32, num_updates=6880, lr=4.32063e-05, gnorm=1.411, clip=100, loss_scale=256, train_wall=20, gb_free=15, wall=18540
2023-01-09 08:46:54 - progress_bar.py[line:272] - INFO: epoch 002:   3235 / 3665 loss=5.456, loss_v1=0, loss_v2=0, nll_loss=4.591, ntokens=851.7, nsentences=32, sample_size=851.7, sample_size_v1=0, sample_size_v2=0, ppl=24.1, wps=432.2, ups=0.51, wpb=851.7, bsz=32, num_updates=6890, lr=4.31918e-05, gnorm=1.893, clip=100, loss_scale=256, train_wall=20, gb_free=15.6, wall=18560
2023-01-09 08:47:14 - progress_bar.py[line:272] - INFO: epoch 002:   3245 / 3665 loss=5.299, loss_v1=0, loss_v2=0, nll_loss=4.414, ntokens=867.1, nsentences=32, sample_size=867.1, sample_size_v1=0, sample_size_v2=0, ppl=21.31, wps=440.2, ups=0.51, wpb=867.1, bsz=32, num_updates=6900, lr=4.31773e-05, gnorm=1.929, clip=100, loss_scale=256, train_wall=20, gb_free=15.3, wall=18580
2023-01-09 08:47:33 - progress_bar.py[line:272] - INFO: epoch 002:   3255 / 3665 loss=5.33, loss_v1=0, loss_v2=0, nll_loss=4.449, ntokens=1025.6, nsentences=32, sample_size=1025.6, sample_size_v1=0, sample_size_v2=0, ppl=21.84, wps=520.5, ups=0.51, wpb=1025.6, bsz=32, num_updates=6910, lr=4.31628e-05, gnorm=1.583, clip=100, loss_scale=256, train_wall=20, gb_free=15.4, wall=18600
2023-01-09 08:47:53 - progress_bar.py[line:272] - INFO: epoch 002:   3265 / 3665 loss=5.445, loss_v1=0, loss_v2=0, nll_loss=4.577, ntokens=1003.2, nsentences=32, sample_size=1003.2, sample_size_v1=0, sample_size_v2=0, ppl=23.86, wps=501.7, ups=0.5, wpb=1003.2, bsz=32, num_updates=6920, lr=4.31482e-05, gnorm=1.576, clip=100, loss_scale=256, train_wall=20, gb_free=15.3, wall=18620
2023-01-09 08:48:13 - progress_bar.py[line:272] - INFO: epoch 002:   3275 / 3665 loss=5.419, loss_v1=0, loss_v2=0, nll_loss=4.551, ntokens=812.9, nsentences=32, sample_size=812.9, sample_size_v1=0, sample_size_v2=0, ppl=23.44, wps=407.2, ups=0.5, wpb=812.9, bsz=32, num_updates=6930, lr=4.31337e-05, gnorm=1.881, clip=100, loss_scale=256, train_wall=20, gb_free=14.9, wall=18639
2023-01-09 08:48:33 - progress_bar.py[line:272] - INFO: epoch 002:   3285 / 3665 loss=5.337, loss_v1=0, loss_v2=0, nll_loss=4.461, ntokens=978.1, nsentences=32, sample_size=978.1, sample_size_v1=0, sample_size_v2=0, ppl=22.03, wps=491.2, ups=0.5, wpb=978.1, bsz=32, num_updates=6940, lr=4.31192e-05, gnorm=1.602, clip=100, loss_scale=256, train_wall=20, gb_free=15.4, wall=18659
2023-01-09 08:48:53 - progress_bar.py[line:272] - INFO: epoch 002:   3295 / 3665 loss=5.421, loss_v1=0, loss_v2=0, nll_loss=4.547, ntokens=962.9, nsentences=32, sample_size=962.9, sample_size_v1=0, sample_size_v2=0, ppl=23.37, wps=481.3, ups=0.5, wpb=962.9, bsz=32, num_updates=6950, lr=4.31047e-05, gnorm=1.671, clip=100, loss_scale=256, train_wall=20, gb_free=15.5, wall=18679
2023-01-09 08:49:13 - progress_bar.py[line:272] - INFO: epoch 002:   3305 / 3665 loss=5.315, loss_v1=0, loss_v2=0, nll_loss=4.434, ntokens=782.9, nsentences=32, sample_size=782.9, sample_size_v1=0, sample_size_v2=0, ppl=21.61, wps=394.6, ups=0.5, wpb=782.9, bsz=32, num_updates=6960, lr=4.30902e-05, gnorm=1.861, clip=100, loss_scale=256, train_wall=20, gb_free=15.7, wall=18699
2023-01-09 08:49:33 - progress_bar.py[line:272] - INFO: epoch 002:   3315 / 3665 loss=5.374, loss_v1=0, loss_v2=0, nll_loss=4.499, ntokens=1016.5, nsentences=32, sample_size=1016.5, sample_size_v1=0, sample_size_v2=0, ppl=22.62, wps=513.9, ups=0.51, wpb=1016.5, bsz=32, num_updates=6970, lr=4.30757e-05, gnorm=1.753, clip=100, loss_scale=256, train_wall=20, gb_free=15.4, wall=18719
2023-01-09 08:49:53 - progress_bar.py[line:272] - INFO: epoch 002:   3325 / 3665 loss=5.431, loss_v1=0, loss_v2=0, nll_loss=4.561, ntokens=983.3, nsentences=32, sample_size=983.3, sample_size_v1=0, sample_size_v2=0, ppl=23.6, wps=496.7, ups=0.51, wpb=983.3, bsz=32, num_updates=6980, lr=4.30612e-05, gnorm=1.732, clip=100, loss_scale=256, train_wall=20, gb_free=14.9, wall=18739
2023-01-09 08:50:12 - progress_bar.py[line:272] - INFO: epoch 002:   3335 / 3665 loss=5.435, loss_v1=0, loss_v2=0, nll_loss=4.567, ntokens=899.5, nsentences=32, sample_size=899.5, sample_size_v1=0, sample_size_v2=0, ppl=23.71, wps=456.2, ups=0.51, wpb=899.5, bsz=32, num_updates=6990, lr=4.30466e-05, gnorm=1.787, clip=100, loss_scale=256, train_wall=20, gb_free=15.2, wall=18759
2023-01-09 08:50:32 - progress_bar.py[line:272] - INFO: epoch 002:   3345 / 3665 loss=5.35, loss_v1=0, loss_v2=0, nll_loss=4.472, ntokens=939, nsentences=32, sample_size=939, sample_size_v1=0, sample_size_v2=0, ppl=22.2, wps=476.7, ups=0.51, wpb=939, bsz=32, num_updates=7000, lr=4.30321e-05, gnorm=1.689, clip=100, loss_scale=256, train_wall=20, gb_free=15.5, wall=18778
2023-01-09 08:50:32 - train.py[line:445] - INFO: begin validation on "valid" subset
slice_id 0 seek offset 0
slice_id 0 seek offset 0
2023-01-09 08:55:09 - progress_bar.py[line:282] - INFO: epoch 002 | valid on 'valid' subset | loss 5.358 | loss_v1 0 | loss_v2 0 | nll_loss 4.467 | ntokens 117.125 | nsentences 4 | sample_size 117.125 | sample_size_v1 0 | sample_size_v2 0 | AP 0 | total positives 21.7351 | TP 0 | FP 5.37237 | ppl 22.11 | wps 528.2 | wpb 117.1 | bsz 4 | num_updates 7000 | best_AP 0
2023-01-09 08:55:09 - checkpoint_utils.py[line:64] - INFO: Preparing to save checkpoint for epoch 2 @ 7000 updates
2023-01-09 08:55:09 - trainer.py[line:431] - INFO: Saving checkpoint to ../../checkpoints/OFA/detection_checkpoints/10_5e-5_512/checkpoint_2_7000.pt
2023-01-09 08:55:12 - trainer.py[line:441] - INFO: Finished saving checkpoint to ../../checkpoints/OFA/detection_checkpoints/10_5e-5_512/checkpoint_2_7000.pt
2023-01-09 08:56:24 - checkpoint_utils.py[line:133] - INFO: Saved checkpoint ../../checkpoints/OFA/detection_checkpoints/10_5e-5_512/checkpoint_2_7000.pt (epoch 2 @ 7000 updates, score 0.0) (writing took 74.78094239393249 seconds)
2023-01-09 08:56:43 - progress_bar.py[line:272] - INFO: epoch 002:   3355 / 3665 loss=5.457, loss_v1=0, loss_v2=0, nll_loss=4.592, ntokens=1088.4, nsentences=32, sample_size=1088.4, sample_size_v1=0, sample_size_v2=0, ppl=24.12, wps=29.3, ups=0.03, wpb=1088.4, bsz=32, num_updates=7010, lr=4.30176e-05, gnorm=1.637, clip=100, loss_scale=256, train_wall=19, gb_free=15.4, wall=19149
2023-01-09 08:57:03 - progress_bar.py[line:272] - INFO: epoch 002:   3365 / 3665 loss=5.364, loss_v1=0, loss_v2=0, nll_loss=4.485, ntokens=810.3, nsentences=32, sample_size=810.3, sample_size_v1=0, sample_size_v2=0, ppl=22.39, wps=416.6, ups=0.51, wpb=810.3, bsz=32, num_updates=7020, lr=4.30031e-05, gnorm=1.978, clip=100, loss_scale=256, train_wall=19, gb_free=15.5, wall=19169
2023-01-09 08:57:22 - progress_bar.py[line:272] - INFO: epoch 002:   3375 / 3665 loss=5.36, loss_v1=0, loss_v2=0, nll_loss=4.482, ntokens=953.8, nsentences=32, sample_size=953.8, sample_size_v1=0, sample_size_v2=0, ppl=22.34, wps=488.8, ups=0.51, wpb=953.8, bsz=32, num_updates=7030, lr=4.29886e-05, gnorm=1.703, clip=100, loss_scale=256, train_wall=19, gb_free=15.6, wall=19188
2023-01-09 08:57:42 - progress_bar.py[line:272] - INFO: epoch 002:   3385 / 3665 loss=5.382, loss_v1=0, loss_v2=0, nll_loss=4.509, ntokens=1070.4, nsentences=32, sample_size=1070.4, sample_size_v1=0, sample_size_v2=0, ppl=22.77, wps=545, ups=0.51, wpb=1070.4, bsz=32, num_updates=7040, lr=4.29741e-05, gnorm=1.636, clip=100, loss_scale=512, train_wall=20, gb_free=15.3, wall=19208
2023-01-09 08:58:01 - progress_bar.py[line:272] - INFO: epoch 002:   3395 / 3665 loss=5.384, loss_v1=0, loss_v2=0, nll_loss=4.506, ntokens=775.5, nsentences=31.8, sample_size=775.5, sample_size_v1=0, sample_size_v2=0, ppl=22.72, wps=398.1, ups=0.51, wpb=775.5, bsz=31.8, num_updates=7050, lr=4.29596e-05, gnorm=1.899, clip=100, loss_scale=512, train_wall=19, gb_free=15.5, wall=19228
2023-01-09 08:58:21 - progress_bar.py[line:272] - INFO: epoch 002:   3405 / 3665 loss=5.394, loss_v1=0, loss_v2=0, nll_loss=4.521, ntokens=934, nsentences=32, sample_size=934, sample_size_v1=0, sample_size_v2=0, ppl=22.96, wps=477.7, ups=0.51, wpb=934, bsz=32, num_updates=7060, lr=4.29451e-05, gnorm=1.559, clip=100, loss_scale=512, train_wall=20, gb_free=15.3, wall=19247
2023-01-09 08:58:40 - progress_bar.py[line:272] - INFO: epoch 002:   3415 / 3665 loss=5.283, loss_v1=0, loss_v2=0, nll_loss=4.4, ntokens=950.5, nsentences=32, sample_size=950.5, sample_size_v1=0, sample_size_v2=0, ppl=21.12, wps=485.9, ups=0.51, wpb=950.5, bsz=32, num_updates=7070, lr=4.29305e-05, gnorm=1.747, clip=100, loss_scale=512, train_wall=20, gb_free=15.4, wall=19267
2023-01-09 08:59:00 - progress_bar.py[line:272] - INFO: epoch 002:   3425 / 3665 loss=5.449, loss_v1=0, loss_v2=0, nll_loss=4.581, ntokens=822.8, nsentences=32, sample_size=822.8, sample_size_v1=0, sample_size_v2=0, ppl=23.93, wps=420.7, ups=0.51, wpb=822.8, bsz=32, num_updates=7080, lr=4.2916e-05, gnorm=2.199, clip=100, loss_scale=512, train_wall=20, gb_free=15.6, wall=19286
2023-01-09 08:59:20 - progress_bar.py[line:272] - INFO: epoch 002:   3435 / 3665 loss=5.413, loss_v1=0, loss_v2=0, nll_loss=4.541, ntokens=975, nsentences=32, sample_size=975, sample_size_v1=0, sample_size_v2=0, ppl=23.28, wps=496.3, ups=0.51, wpb=975, bsz=32, num_updates=7090, lr=4.29015e-05, gnorm=1.729, clip=100, loss_scale=512, train_wall=20, gb_free=15.3, wall=19306
2023-01-09 08:59:39 - progress_bar.py[line:272] - INFO: epoch 002:   3445 / 3665 loss=5.339, loss_v1=0, loss_v2=0, nll_loss=4.461, ntokens=977.2, nsentences=32, sample_size=977.2, sample_size_v1=0, sample_size_v2=0, ppl=22.02, wps=496.9, ups=0.51, wpb=977.2, bsz=32, num_updates=7100, lr=4.2887e-05, gnorm=1.667, clip=100, loss_scale=512, train_wall=20, gb_free=15.4, wall=19326
2023-01-09 08:59:59 - progress_bar.py[line:272] - INFO: epoch 002:   3455 / 3665 loss=5.404, loss_v1=0, loss_v2=0, nll_loss=4.533, ntokens=857.7, nsentences=32, sample_size=857.7, sample_size_v1=0, sample_size_v2=0, ppl=23.15, wps=437.5, ups=0.51, wpb=857.7, bsz=32, num_updates=7110, lr=4.28725e-05, gnorm=1.866, clip=100, loss_scale=512, train_wall=20, gb_free=15.5, wall=19345
2023-01-09 09:00:18 - progress_bar.py[line:272] - INFO: epoch 002:   3465 / 3665 loss=5.266, loss_v1=0, loss_v2=0, nll_loss=4.378, ntokens=676.4, nsentences=32, sample_size=676.4, sample_size_v1=0, sample_size_v2=0, ppl=20.8, wps=347, ups=0.51, wpb=676.4, bsz=32, num_updates=7120, lr=4.2858e-05, gnorm=2.134, clip=100, loss_scale=512, train_wall=19, gb_free=15.4, wall=19365
2023-01-09 09:00:38 - progress_bar.py[line:272] - INFO: epoch 002:   3475 / 3665 loss=5.323, loss_v1=0, loss_v2=0, nll_loss=4.442, ntokens=1045.6, nsentences=32, sample_size=1045.6, sample_size_v1=0, sample_size_v2=0, ppl=21.74, wps=532.6, ups=0.51, wpb=1045.6, bsz=32, num_updates=7130, lr=4.28435e-05, gnorm=1.691, clip=100, loss_scale=512, train_wall=20, gb_free=15.2, wall=19384
2023-01-09 09:00:58 - progress_bar.py[line:272] - INFO: epoch 002:   3485 / 3665 loss=5.453, loss_v1=0, loss_v2=0, nll_loss=4.583, ntokens=895.3, nsentences=32, sample_size=895.3, sample_size_v1=0, sample_size_v2=0, ppl=23.97, wps=455.4, ups=0.51, wpb=895.3, bsz=32, num_updates=7140, lr=4.28289e-05, gnorm=1.923, clip=100, loss_scale=512, train_wall=20, gb_free=15.3, wall=19404
2023-01-09 09:01:17 - progress_bar.py[line:272] - INFO: epoch 002:   3495 / 3665 loss=5.349, loss_v1=0, loss_v2=0, nll_loss=4.471, ntokens=703.4, nsentences=32, sample_size=703.4, sample_size_v1=0, sample_size_v2=0, ppl=22.18, wps=359.5, ups=0.51, wpb=703.4, bsz=32, num_updates=7150, lr=4.28144e-05, gnorm=2.197, clip=100, loss_scale=512, train_wall=20, gb_free=15.1, wall=19424
2023-01-09 09:01:37 - progress_bar.py[line:272] - INFO: epoch 002:   3505 / 3665 loss=5.297, loss_v1=0, loss_v2=0, nll_loss=4.414, ntokens=910.8, nsentences=32, sample_size=910.8, sample_size_v1=0, sample_size_v2=0, ppl=21.32, wps=462.9, ups=0.51, wpb=910.8, bsz=32, num_updates=7160, lr=4.27999e-05, gnorm=1.767, clip=100, loss_scale=512, train_wall=20, gb_free=15.3, wall=19443
2023-01-09 09:01:57 - progress_bar.py[line:272] - INFO: epoch 002:   3515 / 3665 loss=5.397, loss_v1=0, loss_v2=0, nll_loss=4.524, ntokens=1060.2, nsentences=32, sample_size=1060.2, sample_size_v1=0, sample_size_v2=0, ppl=23.01, wps=525.1, ups=0.5, wpb=1060.2, bsz=32, num_updates=7170, lr=4.27854e-05, gnorm=1.624, clip=100, loss_scale=512, train_wall=20, gb_free=15.4, wall=19463
2023-01-09 09:02:17 - progress_bar.py[line:272] - INFO: epoch 002:   3525 / 3665 loss=5.339, loss_v1=0, loss_v2=0, nll_loss=4.458, ntokens=821.7, nsentences=32, sample_size=821.7, sample_size_v1=0, sample_size_v2=0, ppl=21.98, wps=410, ups=0.5, wpb=821.7, bsz=32, num_updates=7180, lr=4.27709e-05, gnorm=2.016, clip=100, loss_scale=512, train_wall=20, gb_free=15.4, wall=19483
2023-01-09 09:02:37 - progress_bar.py[line:272] - INFO: epoch 002:   3535 / 3665 loss=5.338, loss_v1=0, loss_v2=0, nll_loss=4.46, ntokens=991.6, nsentences=32, sample_size=991.6, sample_size_v1=0, sample_size_v2=0, ppl=22.01, wps=491.6, ups=0.5, wpb=991.6, bsz=32, num_updates=7190, lr=4.27564e-05, gnorm=1.837, clip=100, loss_scale=512, train_wall=20, gb_free=15.2, wall=19504
2023-01-09 09:02:57 - progress_bar.py[line:272] - INFO: epoch 002:   3545 / 3665 loss=5.444, loss_v1=0, loss_v2=0, nll_loss=4.578, ntokens=1076.1, nsentences=32, sample_size=1076.1, sample_size_v1=0, sample_size_v2=0, ppl=23.88, wps=536.3, ups=0.5, wpb=1076.1, bsz=32, num_updates=7200, lr=4.27419e-05, gnorm=1.744, clip=100, loss_scale=512, train_wall=20, gb_free=15.2, wall=19524
2023-01-09 09:03:17 - progress_bar.py[line:272] - INFO: epoch 002:   3555 / 3665 loss=5.327, loss_v1=0, loss_v2=0, nll_loss=4.444, ntokens=890.2, nsentences=32, sample_size=890.2, sample_size_v1=0, sample_size_v2=0, ppl=21.77, wps=455.5, ups=0.51, wpb=890.2, bsz=32, num_updates=7210, lr=4.27274e-05, gnorm=1.765, clip=100, loss_scale=512, train_wall=20, gb_free=15.6, wall=19543
2023-01-09 09:03:36 - progress_bar.py[line:272] - INFO: epoch 002:   3565 / 3665 loss=5.314, loss_v1=0, loss_v2=0, nll_loss=4.432, ntokens=922.3, nsentences=32, sample_size=922.3, sample_size_v1=0, sample_size_v2=0, ppl=21.59, wps=471.3, ups=0.51, wpb=922.3, bsz=32, num_updates=7220, lr=4.27128e-05, gnorm=1.89, clip=100, loss_scale=512, train_wall=20, gb_free=15.4, wall=19563
2023-01-09 09:03:56 - progress_bar.py[line:272] - INFO: epoch 002:   3575 / 3665 loss=5.302, loss_v1=0, loss_v2=0, nll_loss=4.419, ntokens=1082.6, nsentences=32, sample_size=1082.6, sample_size_v1=0, sample_size_v2=0, ppl=21.39, wps=550.4, ups=0.51, wpb=1082.6, bsz=32, num_updates=7230, lr=4.26983e-05, gnorm=1.552, clip=100, loss_scale=512, train_wall=20, gb_free=15, wall=19582
2023-01-09 09:04:16 - progress_bar.py[line:272] - INFO: epoch 002:   3585 / 3665 loss=5.372, loss_v1=0, loss_v2=0, nll_loss=4.497, ntokens=815.2, nsentences=32, sample_size=815.2, sample_size_v1=0, sample_size_v2=0, ppl=22.59, wps=415.8, ups=0.51, wpb=815.2, bsz=32, num_updates=7240, lr=4.26838e-05, gnorm=1.933, clip=100, loss_scale=512, train_wall=20, gb_free=15.5, wall=19602
2023-01-09 09:04:35 - progress_bar.py[line:272] - INFO: epoch 002:   3595 / 3665 loss=5.394, loss_v1=0, loss_v2=0, nll_loss=4.518, ntokens=901.9, nsentences=32, sample_size=901.9, sample_size_v1=0, sample_size_v2=0, ppl=22.91, wps=459.6, ups=0.51, wpb=901.9, bsz=32, num_updates=7250, lr=4.26693e-05, gnorm=1.807, clip=100, loss_scale=512, train_wall=20, gb_free=15.4, wall=19622
2023-01-09 09:04:55 - progress_bar.py[line:272] - INFO: epoch 002:   3605 / 3665 loss=5.354, loss_v1=0, loss_v2=0, nll_loss=4.478, ntokens=968.8, nsentences=32, sample_size=968.8, sample_size_v1=0, sample_size_v2=0, ppl=22.28, wps=492.8, ups=0.51, wpb=968.8, bsz=32, num_updates=7260, lr=4.26548e-05, gnorm=1.835, clip=100, loss_scale=512, train_wall=20, gb_free=15.6, wall=19641
2023-01-09 09:05:15 - progress_bar.py[line:272] - INFO: epoch 002:   3615 / 3665 loss=5.361, loss_v1=0, loss_v2=0, nll_loss=4.485, ntokens=827.2, nsentences=32, sample_size=827.2, sample_size_v1=0, sample_size_v2=0, ppl=22.39, wps=421.7, ups=0.51, wpb=827.2, bsz=32, num_updates=7270, lr=4.26403e-05, gnorm=1.978, clip=100, loss_scale=512, train_wall=20, gb_free=15.6, wall=19661
2023-01-09 09:05:34 - progress_bar.py[line:272] - INFO: epoch 002:   3625 / 3665 loss=5.367, loss_v1=0, loss_v2=0, nll_loss=4.488, ntokens=917.2, nsentences=32, sample_size=917.2, sample_size_v1=0, sample_size_v2=0, ppl=22.45, wps=466.8, ups=0.51, wpb=917.2, bsz=32, num_updates=7280, lr=4.26258e-05, gnorm=1.866, clip=100, loss_scale=512, train_wall=20, gb_free=14.6, wall=19681
2023-01-09 09:05:54 - progress_bar.py[line:272] - INFO: epoch 002:   3635 / 3665 loss=5.297, loss_v1=0, loss_v2=0, nll_loss=4.413, ntokens=1081.8, nsentences=32, sample_size=1081.8, sample_size_v1=0, sample_size_v2=0, ppl=21.3, wps=548.1, ups=0.51, wpb=1081.8, bsz=32, num_updates=7290, lr=4.26112e-05, gnorm=1.552, clip=100, loss_scale=512, train_wall=20, gb_free=15.3, wall=19700
2023-01-09 09:06:14 - progress_bar.py[line:272] - INFO: epoch 002:   3645 / 3665 loss=5.382, loss_v1=0, loss_v2=0, nll_loss=4.51, ntokens=846.4, nsentences=32, sample_size=846.4, sample_size_v1=0, sample_size_v2=0, ppl=22.78, wps=431.8, ups=0.51, wpb=846.4, bsz=32, num_updates=7300, lr=4.25967e-05, gnorm=1.866, clip=100, loss_scale=512, train_wall=20, gb_free=15.3, wall=19720
2023-01-09 09:06:33 - progress_bar.py[line:272] - INFO: epoch 002:   3655 / 3665 loss=5.34, loss_v1=0, loss_v2=0, nll_loss=4.461, ntokens=817.8, nsentences=32, sample_size=817.8, sample_size_v1=0, sample_size_v2=0, ppl=22.03, wps=414.8, ups=0.51, wpb=817.8, bsz=32, num_updates=7310, lr=4.25822e-05, gnorm=1.952, clip=100, loss_scale=512, train_wall=20, gb_free=15.5, wall=19740
2023-01-09 09:06:52 - progress_bar.py[line:272] - INFO: epoch 002:   3665 / 3665 loss=5.356, loss_v1=0, loss_v2=0, nll_loss=4.478, ntokens=1022.6, nsentences=30.8, sample_size=1022.6, sample_size_v1=0, sample_size_v2=0, ppl=22.28, wps=536, ups=0.52, wpb=1022.6, bsz=30.8, num_updates=7320, lr=4.25677e-05, gnorm=1.711, clip=100, loss_scale=512, train_wall=19, gb_free=14.5, wall=19759
2023-01-09 09:06:52 - train.py[line:445] - INFO: begin validation on "valid" subset
slice_id 0 seek offset 0
slice_id 0 seek offset 0
2023-01-09 09:11:43 - progress_bar.py[line:282] - INFO: epoch 002 | valid on 'valid' subset | loss 5.355 | loss_v1 0 | loss_v2 0 | nll_loss 4.459 | ntokens 116.71 | nsentences 4 | sample_size 116.71 | sample_size_v1 0 | sample_size_v2 0 | AP 0 | total positives 21.6519 | TP 0 | FP 6.58239 | ppl 21.99 | wps 502.3 | wpb 116.7 | bsz 4 | num_updates 7320 | best_AP 0
2023-01-09 09:11:43 - checkpoint_utils.py[line:64] - INFO: Preparing to save checkpoint for epoch 2 @ 7320 updates
2023-01-09 09:11:44 - trainer.py[line:431] - INFO: Saving checkpoint to ../../checkpoints/OFA/detection_checkpoints/10_5e-5_512/checkpoint_best.pt
2023-01-09 09:12:03 - trainer.py[line:441] - INFO: Finished saving checkpoint to ../../checkpoints/OFA/detection_checkpoints/10_5e-5_512/checkpoint_best.pt
2023-01-09 09:12:39 - checkpoint_utils.py[line:133] - INFO: Saved checkpoint ../../checkpoints/OFA/detection_checkpoints/10_5e-5_512/checkpoint_best.pt (epoch 2 @ 7320 updates, score 0.0) (writing took 55.275780968833715 seconds)
2023-01-09 09:12:39 - train.py[line:332] - INFO: end of epoch 2 (average epoch stats below)
2023-01-09 09:12:39 - progress_bar.py[line:282] - INFO: epoch 002 | loss 5.428 | loss_v1 0 | loss_v2 0 | nll_loss 4.559 | ntokens 923.367 | nsentences 31.996 | sample_size 923.367 | sample_size_v1 0 | sample_size_v2 0 | AP 0 | ppl 23.57 | wps 333.4 | ups 0.36 | wpb 923.4 | bsz 32 | num_updates 7320 | lr 4.25677e-05 | gnorm 1.759 | clip 99.9 | loss_scale 512 | train_wall 7214 | gb_free 14.5 | wall 20105
2023-01-09 09:12:39 - trainer.py[line:639] - INFO: loading train data for epoch 3
local datafile ../../dataset/OFA_data/train.tsv slice_id 0 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../dataset/OFA_data/train.tsv slice_id 0 finished initializing row_count and line_idx-to-offset mapping
file ../../dataset/OFA_data/train.tsv slice_id 0 row count 117266 total row count 117266
slice_id 0 seek offset 0
2023-01-09 09:13:27 - trainer.py[line:703] - INFO: begin training epoch 3
2023-01-09 09:13:27 - train.py[line:305] - INFO: Start iterating over samples
2023-01-09 09:13:47 - progress_bar.py[line:272] - INFO: epoch 003:     10 / 3665 loss=5.405, loss_v1=0, loss_v2=0, nll_loss=4.533, ntokens=843.7, nsentences=32, sample_size=843.7, sample_size_v1=0, sample_size_v2=0, ppl=23.16, wps=20.4, ups=0.02, wpb=843.7, bsz=32, num_updates=7330, lr=4.25532e-05, gnorm=1.884, clip=100, loss_scale=512, train_wall=19, gb_free=15, wall=20173
2023-01-09 09:14:06 - progress_bar.py[line:272] - INFO: epoch 003:     20 / 3665 loss=5.323, loss_v1=0, loss_v2=0, nll_loss=4.443, ntokens=885.1, nsentences=32, sample_size=885.1, sample_size_v1=0, sample_size_v2=0, ppl=21.75, wps=456.1, ups=0.52, wpb=885.1, bsz=32, num_updates=7340, lr=4.25387e-05, gnorm=1.808, clip=100, loss_scale=512, train_wall=19, gb_free=15.6, wall=20192
2023-01-09 09:14:26 - progress_bar.py[line:272] - INFO: epoch 003:     30 / 3665 loss=5.382, loss_v1=0, loss_v2=0, nll_loss=4.506, ntokens=990.7, nsentences=32, sample_size=990.7, sample_size_v1=0, sample_size_v2=0, ppl=22.72, wps=507.8, ups=0.51, wpb=990.7, bsz=32, num_updates=7350, lr=4.25242e-05, gnorm=1.624, clip=100, loss_scale=512, train_wall=19, gb_free=15.5, wall=20212
2023-01-09 09:14:45 - progress_bar.py[line:272] - INFO: epoch 003:     40 / 3665 loss=5.349, loss_v1=0, loss_v2=0, nll_loss=4.472, ntokens=778.1, nsentences=32, sample_size=778.1, sample_size_v1=0, sample_size_v2=0, ppl=22.2, wps=397.9, ups=0.51, wpb=778.1, bsz=32, num_updates=7360, lr=4.25097e-05, gnorm=2.033, clip=100, loss_scale=512, train_wall=20, gb_free=15.3, wall=20231
2023-01-09 09:15:05 - progress_bar.py[line:272] - INFO: epoch 003:     50 / 3665 loss=5.345, loss_v1=0, loss_v2=0, nll_loss=4.465, ntokens=964.1, nsentences=32, sample_size=964.1, sample_size_v1=0, sample_size_v2=0, ppl=22.08, wps=491.3, ups=0.51, wpb=964.1, bsz=32, num_updates=7370, lr=4.24951e-05, gnorm=1.617, clip=100, loss_scale=512, train_wall=20, gb_free=15.3, wall=20251
2023-01-09 09:15:24 - progress_bar.py[line:272] - INFO: epoch 003:     60 / 3665 loss=5.408, loss_v1=0, loss_v2=0, nll_loss=4.536, ntokens=952.3, nsentences=32, sample_size=952.3, sample_size_v1=0, sample_size_v2=0, ppl=23.2, wps=485.5, ups=0.51, wpb=952.3, bsz=32, num_updates=7380, lr=4.24806e-05, gnorm=1.843, clip=100, loss_scale=512, train_wall=20, gb_free=15.4, wall=20271
2023-01-09 09:15:44 - progress_bar.py[line:272] - INFO: epoch 003:     70 / 3665 loss=5.311, loss_v1=0, loss_v2=0, nll_loss=4.429, ntokens=749.4, nsentences=32, sample_size=749.4, sample_size_v1=0, sample_size_v2=0, ppl=21.55, wps=383.6, ups=0.51, wpb=749.4, bsz=32, num_updates=7390, lr=4.24661e-05, gnorm=2.015, clip=100, loss_scale=512, train_wall=20, gb_free=15.5, wall=20290
2023-01-09 09:16:04 - progress_bar.py[line:272] - INFO: epoch 003:     80 / 3665 loss=5.306, loss_v1=0, loss_v2=0, nll_loss=4.422, ntokens=1032.8, nsentences=32, sample_size=1032.8, sample_size_v1=0, sample_size_v2=0, ppl=21.44, wps=513, ups=0.5, wpb=1032.8, bsz=32, num_updates=7400, lr=4.24516e-05, gnorm=1.724, clip=100, loss_scale=512, train_wall=20, gb_free=15.2, wall=20310
2023-01-09 09:16:24 - progress_bar.py[line:272] - INFO: epoch 003:     90 / 3665 loss=5.395, loss_v1=0, loss_v2=0, nll_loss=4.52, ntokens=816.9, nsentences=32, sample_size=816.9, sample_size_v1=0, sample_size_v2=0, ppl=22.95, wps=417, ups=0.51, wpb=816.9, bsz=32, num_updates=7410, lr=4.24371e-05, gnorm=2.078, clip=100, loss_scale=512, train_wall=20, gb_free=15.1, wall=20330
2023-01-09 09:16:37 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 256.0
2023-01-09 09:16:45 - progress_bar.py[line:272] - INFO: epoch 003:    101 / 3665 loss=5.424, loss_v1=0, loss_v2=0, nll_loss=4.553, ntokens=906.3, nsentences=32, sample_size=906.3, sample_size_v1=0, sample_size_v2=0, ppl=23.48, wps=419.6, ups=0.46, wpb=906.3, bsz=32, num_updates=7420, lr=4.24226e-05, gnorm=1.838, clip=100, loss_scale=256, train_wall=22, gb_free=15.6, wall=20352
2023-01-09 09:17:05 - progress_bar.py[line:272] - INFO: epoch 003:    111 / 3665 loss=5.306, loss_v1=0, loss_v2=0, nll_loss=4.422, ntokens=1098.2, nsentences=32, sample_size=1098.2, sample_size_v1=0, sample_size_v2=0, ppl=21.44, wps=557.9, ups=0.51, wpb=1098.2, bsz=32, num_updates=7430, lr=4.24081e-05, gnorm=1.631, clip=100, loss_scale=256, train_wall=20, gb_free=15.5, wall=20371
2023-01-09 09:17:25 - progress_bar.py[line:272] - INFO: epoch 003:    121 / 3665 loss=5.354, loss_v1=0, loss_v2=0, nll_loss=4.478, ntokens=852.9, nsentences=32, sample_size=852.9, sample_size_v1=0, sample_size_v2=0, ppl=22.28, wps=434.5, ups=0.51, wpb=852.9, bsz=32, num_updates=7440, lr=4.23935e-05, gnorm=1.914, clip=100, loss_scale=256, train_wall=20, gb_free=15.1, wall=20391
2023-01-09 09:17:44 - progress_bar.py[line:272] - INFO: epoch 003:    131 / 3665 loss=5.332, loss_v1=0, loss_v2=0, nll_loss=4.451, ntokens=943.2, nsentences=32, sample_size=943.2, sample_size_v1=0, sample_size_v2=0, ppl=21.86, wps=480.6, ups=0.51, wpb=943.2, bsz=32, num_updates=7450, lr=4.2379e-05, gnorm=1.871, clip=100, loss_scale=256, train_wall=20, gb_free=15.2, wall=20410
2023-01-09 09:18:04 - progress_bar.py[line:272] - INFO: epoch 003:    141 / 3665 loss=5.368, loss_v1=0, loss_v2=0, nll_loss=4.494, ntokens=1091.1, nsentences=32, sample_size=1091.1, sample_size_v1=0, sample_size_v2=0, ppl=22.54, wps=553.8, ups=0.51, wpb=1091.1, bsz=32, num_updates=7460, lr=4.23645e-05, gnorm=1.747, clip=100, loss_scale=256, train_wall=20, gb_free=15.3, wall=20430
2023-01-09 09:18:23 - progress_bar.py[line:272] - INFO: epoch 003:    151 / 3665 loss=5.358, loss_v1=0, loss_v2=0, nll_loss=4.479, ntokens=825.6, nsentences=32, sample_size=825.6, sample_size_v1=0, sample_size_v2=0, ppl=22.3, wps=421.4, ups=0.51, wpb=825.6, bsz=32, num_updates=7470, lr=4.235e-05, gnorm=2.066, clip=100, loss_scale=256, train_wall=20, gb_free=15.2, wall=20450
2023-01-09 09:18:43 - progress_bar.py[line:272] - INFO: epoch 003:    161 / 3665 loss=5.292, loss_v1=0, loss_v2=0, nll_loss=4.403, ntokens=914.2, nsentences=32, sample_size=914.2, sample_size_v1=0, sample_size_v2=0, ppl=21.16, wps=466.4, ups=0.51, wpb=914.2, bsz=32, num_updates=7480, lr=4.23355e-05, gnorm=1.719, clip=100, loss_scale=256, train_wall=20, gb_free=15.5, wall=20469
2023-01-09 09:19:03 - progress_bar.py[line:272] - INFO: epoch 003:    171 / 3665 loss=5.414, loss_v1=0, loss_v2=0, nll_loss=4.545, ntokens=1085.3, nsentences=32, sample_size=1085.3, sample_size_v1=0, sample_size_v2=0, ppl=23.34, wps=551.6, ups=0.51, wpb=1085.3, bsz=32, num_updates=7490, lr=4.2321e-05, gnorm=1.624, clip=100, loss_scale=256, train_wall=20, gb_free=15.1, wall=20489
2023-01-09 09:19:23 - progress_bar.py[line:272] - INFO: epoch 003:    181 / 3665 loss=5.28, loss_v1=0, loss_v2=0, nll_loss=4.396, ntokens=759.7, nsentences=32, sample_size=759.7, sample_size_v1=0, sample_size_v2=0, ppl=21.05, wps=381.6, ups=0.5, wpb=759.7, bsz=32, num_updates=7500, lr=4.23065e-05, gnorm=1.93, clip=100, loss_scale=256, train_wall=20, gb_free=15.3, wall=20509
2023-01-09 09:19:23 - train.py[line:445] - INFO: begin validation on "valid" subset
slice_id 0 seek offset 0
slice_id 0 seek offset 0
2023-01-09 09:24:02 - progress_bar.py[line:282] - INFO: epoch 003 | valid on 'valid' subset | loss 5.345 | loss_v1 0 | loss_v2 0 | nll_loss 4.448 | ntokens 117.017 | nsentences 4 | sample_size 117.017 | sample_size_v1 0 | sample_size_v2 0 | AP 0 | total positives 21.7116 | TP 0 | FP 5.52504 | ppl 21.82 | wps 523.1 | wpb 117 | bsz 4 | num_updates 7500 | best_AP 0
2023-01-09 09:24:02 - checkpoint_utils.py[line:64] - INFO: Preparing to save checkpoint for epoch 3 @ 7500 updates
2023-01-09 09:24:02 - trainer.py[line:431] - INFO: Saving checkpoint to ../../checkpoints/OFA/detection_checkpoints/10_5e-5_512/checkpoint_3_7500.pt
2023-01-09 09:24:05 - trainer.py[line:441] - INFO: Finished saving checkpoint to ../../checkpoints/OFA/detection_checkpoints/10_5e-5_512/checkpoint_3_7500.pt
2023-01-09 09:25:18 - checkpoint_utils.py[line:133] - INFO: Saved checkpoint ../../checkpoints/OFA/detection_checkpoints/10_5e-5_512/checkpoint_3_7500.pt (epoch 3 @ 7500 updates, score 0.0) (writing took 75.72000183537602 seconds)
2023-01-09 09:25:37 - progress_bar.py[line:272] - INFO: epoch 003:    191 / 3665 loss=5.329, loss_v1=0, loss_v2=0, nll_loss=4.447, ntokens=1001.4, nsentences=32, sample_size=1001.4, sample_size_v1=0, sample_size_v2=0, ppl=21.82, wps=26.7, ups=0.03, wpb=1001.4, bsz=32, num_updates=7510, lr=4.2292e-05, gnorm=1.632, clip=100, loss_scale=256, train_wall=19, gb_free=15.3, wall=20884
2023-01-09 09:25:57 - progress_bar.py[line:272] - INFO: epoch 003:    201 / 3665 loss=5.396, loss_v1=0, loss_v2=0, nll_loss=4.523, ntokens=883.9, nsentences=32, sample_size=883.9, sample_size_v1=0, sample_size_v2=0, ppl=23, wps=455.7, ups=0.52, wpb=883.9, bsz=32, num_updates=7520, lr=4.22774e-05, gnorm=2.017, clip=100, loss_scale=256, train_wall=19, gb_free=15.3, wall=20903
2023-01-09 09:26:16 - progress_bar.py[line:272] - INFO: epoch 003:    211 / 3665 loss=5.365, loss_v1=0, loss_v2=0, nll_loss=4.488, ntokens=781.4, nsentences=32, sample_size=781.4, sample_size_v1=0, sample_size_v2=0, ppl=22.44, wps=401.5, ups=0.51, wpb=781.4, bsz=32, num_updates=7530, lr=4.22629e-05, gnorm=1.988, clip=100, loss_scale=256, train_wall=19, gb_free=15.2, wall=20923
2023-01-09 09:26:36 - progress_bar.py[line:272] - INFO: epoch 003:    221 / 3665 loss=5.269, loss_v1=0, loss_v2=0, nll_loss=4.383, ntokens=1012, nsentences=32, sample_size=1012, sample_size_v1=0, sample_size_v2=0, ppl=20.87, wps=515.3, ups=0.51, wpb=1012, bsz=32, num_updates=7540, lr=4.22484e-05, gnorm=1.551, clip=100, loss_scale=256, train_wall=20, gb_free=15.2, wall=20942
2023-01-09 09:26:56 - progress_bar.py[line:272] - INFO: epoch 003:    231 / 3665 loss=5.444, loss_v1=0, loss_v2=0, nll_loss=4.574, ntokens=995, nsentences=32, sample_size=995, sample_size_v1=0, sample_size_v2=0, ppl=23.82, wps=506.8, ups=0.51, wpb=995, bsz=32, num_updates=7550, lr=4.22339e-05, gnorm=1.713, clip=100, loss_scale=256, train_wall=20, gb_free=15.5, wall=20962
2023-01-09 09:27:15 - progress_bar.py[line:272] - INFO: epoch 003:    241 / 3665 loss=5.339, loss_v1=0, loss_v2=0, nll_loss=4.46, ntokens=803.1, nsentences=32, sample_size=803.1, sample_size_v1=0, sample_size_v2=0, ppl=22.02, wps=411.8, ups=0.51, wpb=803.1, bsz=32, num_updates=7560, lr=4.22194e-05, gnorm=1.963, clip=100, loss_scale=256, train_wall=19, gb_free=15.6, wall=20981
2023-01-09 09:27:35 - progress_bar.py[line:272] - INFO: epoch 003:    251 / 3665 loss=5.32, loss_v1=0, loss_v2=0, nll_loss=4.438, ntokens=1046.1, nsentences=32, sample_size=1046.1, sample_size_v1=0, sample_size_v2=0, ppl=21.67, wps=533.1, ups=0.51, wpb=1046.1, bsz=32, num_updates=7570, lr=4.22049e-05, gnorm=1.555, clip=100, loss_scale=256, train_wall=20, gb_free=15.4, wall=21001
2023-01-09 09:27:54 - progress_bar.py[line:272] - INFO: epoch 003:    261 / 3665 loss=5.313, loss_v1=0, loss_v2=0, nll_loss=4.432, ntokens=750.1, nsentences=32, sample_size=750.1, sample_size_v1=0, sample_size_v2=0, ppl=21.58, wps=383.4, ups=0.51, wpb=750.1, bsz=32, num_updates=7580, lr=4.21904e-05, gnorm=2.138, clip=100, loss_scale=256, train_wall=20, gb_free=15.6, wall=21021
2023-01-09 09:28:14 - progress_bar.py[line:272] - INFO: epoch 003:    271 / 3665 loss=5.378, loss_v1=0, loss_v2=0, nll_loss=4.502, ntokens=955, nsentences=32, sample_size=955, sample_size_v1=0, sample_size_v2=0, ppl=22.65, wps=487.4, ups=0.51, wpb=955, bsz=32, num_updates=7590, lr=4.21758e-05, gnorm=1.797, clip=100, loss_scale=256, train_wall=20, gb_free=15.4, wall=21040
2023-01-09 09:28:33 - progress_bar.py[line:272] - INFO: epoch 003:    281 / 3665 loss=5.339, loss_v1=0, loss_v2=0, nll_loss=4.459, ntokens=911.5, nsentences=32, sample_size=911.5, sample_size_v1=0, sample_size_v2=0, ppl=21.99, wps=464.7, ups=0.51, wpb=911.5, bsz=32, num_updates=7600, lr=4.21613e-05, gnorm=1.71, clip=100, loss_scale=256, train_wall=20, gb_free=15.3, wall=21060
2023-01-09 09:28:53 - progress_bar.py[line:272] - INFO: epoch 003:    291 / 3665 loss=5.321, loss_v1=0, loss_v2=0, nll_loss=4.442, ntokens=773.1, nsentences=32, sample_size=773.1, sample_size_v1=0, sample_size_v2=0, ppl=21.74, wps=394.8, ups=0.51, wpb=773.1, bsz=32, num_updates=7610, lr=4.21468e-05, gnorm=1.942, clip=100, loss_scale=256, train_wall=20, gb_free=14.7, wall=21079
2023-01-09 09:29:13 - progress_bar.py[line:272] - INFO: epoch 003:    301 / 3665 loss=5.28, loss_v1=0, loss_v2=0, nll_loss=4.395, ntokens=946.5, nsentences=32, sample_size=946.5, sample_size_v1=0, sample_size_v2=0, ppl=21.04, wps=482.9, ups=0.51, wpb=946.5, bsz=32, num_updates=7620, lr=4.21323e-05, gnorm=1.749, clip=100, loss_scale=256, train_wall=20, gb_free=15.4, wall=21099
2023-01-09 09:29:32 - progress_bar.py[line:272] - INFO: epoch 003:    311 / 3665 loss=5.391, loss_v1=0, loss_v2=0, nll_loss=4.511, ntokens=1048.5, nsentences=32, sample_size=1048.5, sample_size_v1=0, sample_size_v2=0, ppl=22.81, wps=532.5, ups=0.51, wpb=1048.5, bsz=32, num_updates=7630, lr=4.21178e-05, gnorm=1.539, clip=100, loss_scale=256, train_wall=20, gb_free=15.6, wall=21119
2023-01-09 09:29:52 - progress_bar.py[line:272] - INFO: epoch 003:    321 / 3665 loss=5.347, loss_v1=0, loss_v2=0, nll_loss=4.471, ntokens=746.6, nsentences=32, sample_size=746.6, sample_size_v1=0, sample_size_v2=0, ppl=22.18, wps=381.4, ups=0.51, wpb=746.6, bsz=32, num_updates=7640, lr=4.21033e-05, gnorm=1.878, clip=100, loss_scale=256, train_wall=20, gb_free=15.7, wall=21138
2023-01-09 09:30:12 - progress_bar.py[line:272] - INFO: epoch 003:    331 / 3665 loss=5.292, loss_v1=0, loss_v2=0, nll_loss=4.41, ntokens=1042.6, nsentences=32, sample_size=1042.6, sample_size_v1=0, sample_size_v2=0, ppl=21.26, wps=524.3, ups=0.5, wpb=1042.6, bsz=32, num_updates=7650, lr=4.20888e-05, gnorm=1.638, clip=100, loss_scale=256, train_wall=20, gb_free=15.3, wall=21158
2023-01-09 09:30:31 - progress_bar.py[line:272] - INFO: epoch 003:    341 / 3665 loss=5.288, loss_v1=0, loss_v2=0, nll_loss=4.402, ntokens=843.5, nsentences=32, sample_size=843.5, sample_size_v1=0, sample_size_v2=0, ppl=21.14, wps=430.2, ups=0.51, wpb=843.5, bsz=32, num_updates=7660, lr=4.20743e-05, gnorm=1.79, clip=100, loss_scale=256, train_wall=20, gb_free=15.6, wall=21178
2023-01-09 09:30:51 - progress_bar.py[line:272] - INFO: epoch 003:    351 / 3665 loss=5.308, loss_v1=0, loss_v2=0, nll_loss=4.422, ntokens=783.7, nsentences=32, sample_size=783.7, sample_size_v1=0, sample_size_v2=0, ppl=21.44, wps=400.2, ups=0.51, wpb=783.7, bsz=32, num_updates=7670, lr=4.20597e-05, gnorm=1.841, clip=100, loss_scale=256, train_wall=20, gb_free=15.3, wall=21197
2023-01-09 09:31:11 - progress_bar.py[line:272] - INFO: epoch 003:    361 / 3665 loss=5.321, loss_v1=0, loss_v2=0, nll_loss=4.443, ntokens=1008.8, nsentences=32, sample_size=1008.8, sample_size_v1=0, sample_size_v2=0, ppl=21.75, wps=511.7, ups=0.51, wpb=1008.8, bsz=32, num_updates=7680, lr=4.20452e-05, gnorm=1.668, clip=100, loss_scale=256, train_wall=20, gb_free=15.3, wall=21217
2023-01-09 09:31:30 - progress_bar.py[line:272] - INFO: epoch 003:    371 / 3665 loss=5.369, loss_v1=0, loss_v2=0, nll_loss=4.492, ntokens=788.6, nsentences=32, sample_size=788.6, sample_size_v1=0, sample_size_v2=0, ppl=22.5, wps=402.9, ups=0.51, wpb=788.6, bsz=32, num_updates=7690, lr=4.20307e-05, gnorm=1.907, clip=100, loss_scale=256, train_wall=20, gb_free=15.5, wall=21237
2023-01-09 09:31:50 - progress_bar.py[line:272] - INFO: epoch 003:    381 / 3665 loss=5.303, loss_v1=0, loss_v2=0, nll_loss=4.42, ntokens=924.2, nsentences=32, sample_size=924.2, sample_size_v1=0, sample_size_v2=0, ppl=21.41, wps=466.9, ups=0.51, wpb=924.2, bsz=32, num_updates=7700, lr=4.20162e-05, gnorm=1.786, clip=100, loss_scale=256, train_wall=20, gb_free=15.2, wall=21256
2023-01-09 09:32:10 - progress_bar.py[line:272] - INFO: epoch 003:    391 / 3665 loss=5.297, loss_v1=0, loss_v2=0, nll_loss=4.413, ntokens=943.5, nsentences=32, sample_size=943.5, sample_size_v1=0, sample_size_v2=0, ppl=21.3, wps=476.5, ups=0.5, wpb=943.5, bsz=32, num_updates=7710, lr=4.20017e-05, gnorm=1.712, clip=100, loss_scale=256, train_wall=20, gb_free=15.6, wall=21276
2023-01-09 09:32:30 - progress_bar.py[line:272] - INFO: epoch 003:    401 / 3665 loss=5.31, loss_v1=0, loss_v2=0, nll_loss=4.428, ntokens=721.2, nsentences=32, sample_size=721.2, sample_size_v1=0, sample_size_v2=0, ppl=21.52, wps=365.4, ups=0.51, wpb=721.2, bsz=32, num_updates=7720, lr=4.19872e-05, gnorm=2.161, clip=100, loss_scale=256, train_wall=20, gb_free=15.2, wall=21296
2023-01-09 09:32:49 - progress_bar.py[line:272] - INFO: epoch 003:    411 / 3665 loss=5.299, loss_v1=0, loss_v2=0, nll_loss=4.415, ntokens=970.8, nsentences=32, sample_size=970.8, sample_size_v1=0, sample_size_v2=0, ppl=21.33, wps=489.6, ups=0.5, wpb=970.8, bsz=32, num_updates=7730, lr=4.19727e-05, gnorm=1.764, clip=100, loss_scale=256, train_wall=20, gb_free=15.1, wall=21316
2023-01-09 09:33:09 - progress_bar.py[line:272] - INFO: epoch 003:    421 / 3665 loss=5.365, loss_v1=0, loss_v2=0, nll_loss=4.487, ntokens=987.1, nsentences=32, sample_size=987.1, sample_size_v1=0, sample_size_v2=0, ppl=22.43, wps=497.6, ups=0.5, wpb=987.1, bsz=32, num_updates=7740, lr=4.19581e-05, gnorm=1.592, clip=100, loss_scale=256, train_wall=20, gb_free=15.5, wall=21336
2023-01-09 09:33:29 - progress_bar.py[line:272] - INFO: epoch 003:    431 / 3665 loss=5.409, loss_v1=0, loss_v2=0, nll_loss=4.538, ntokens=907.9, nsentences=32, sample_size=907.9, sample_size_v1=0, sample_size_v2=0, ppl=23.24, wps=457.1, ups=0.5, wpb=907.9, bsz=32, num_updates=7750, lr=4.19436e-05, gnorm=1.756, clip=100, loss_scale=256, train_wall=20, gb_free=15.1, wall=21355
2023-01-09 09:33:49 - progress_bar.py[line:272] - INFO: epoch 003:    441 / 3665 loss=5.364, loss_v1=0, loss_v2=0, nll_loss=4.487, ntokens=1007.8, nsentences=32, sample_size=1007.8, sample_size_v1=0, sample_size_v2=0, ppl=22.43, wps=508.9, ups=0.5, wpb=1007.8, bsz=32, num_updates=7760, lr=4.19291e-05, gnorm=1.776, clip=100, loss_scale=256, train_wall=20, gb_free=15.2, wall=21375
2023-01-09 09:34:09 - progress_bar.py[line:272] - INFO: epoch 003:    451 / 3665 loss=5.329, loss_v1=0, loss_v2=0, nll_loss=4.447, ntokens=895.6, nsentences=32, sample_size=895.6, sample_size_v1=0, sample_size_v2=0, ppl=21.81, wps=452.5, ups=0.51, wpb=895.6, bsz=32, num_updates=7770, lr=4.19146e-05, gnorm=2.048, clip=100, loss_scale=256, train_wall=20, gb_free=15.7, wall=21395
2023-01-09 09:34:29 - progress_bar.py[line:272] - INFO: epoch 003:    461 / 3665 loss=5.359, loss_v1=0, loss_v2=0, nll_loss=4.48, ntokens=942.2, nsentences=32, sample_size=942.2, sample_size_v1=0, sample_size_v2=0, ppl=22.32, wps=475.6, ups=0.5, wpb=942.2, bsz=32, num_updates=7780, lr=4.19001e-05, gnorm=1.738, clip=100, loss_scale=256, train_wall=20, gb_free=15.6, wall=21415
2023-01-09 09:34:48 - progress_bar.py[line:272] - INFO: epoch 003:    471 / 3665 loss=5.291, loss_v1=0, loss_v2=0, nll_loss=4.407, ntokens=1105.7, nsentences=32, sample_size=1105.7, sample_size_v1=0, sample_size_v2=0, ppl=21.21, wps=557.3, ups=0.5, wpb=1105.7, bsz=32, num_updates=7790, lr=4.18856e-05, gnorm=1.605, clip=100, loss_scale=256, train_wall=20, gb_free=15.4, wall=21435
2023-01-09 09:35:08 - progress_bar.py[line:272] - INFO: epoch 003:    481 / 3665 loss=5.421, loss_v1=0, loss_v2=0, nll_loss=4.552, ntokens=940.9, nsentences=32, sample_size=940.9, sample_size_v1=0, sample_size_v2=0, ppl=23.46, wps=474.6, ups=0.5, wpb=940.9, bsz=32, num_updates=7800, lr=4.18711e-05, gnorm=1.856, clip=90, loss_scale=256, train_wall=20, gb_free=15.5, wall=21454
2023-01-09 09:35:28 - progress_bar.py[line:272] - INFO: epoch 003:    491 / 3665 loss=5.329, loss_v1=0, loss_v2=0, nll_loss=4.448, ntokens=893.1, nsentences=32, sample_size=893.1, sample_size_v1=0, sample_size_v2=0, ppl=21.83, wps=451, ups=0.51, wpb=893.1, bsz=32, num_updates=7810, lr=4.18565e-05, gnorm=1.767, clip=100, loss_scale=256, train_wall=20, gb_free=15.2, wall=21474
2023-01-09 09:35:48 - progress_bar.py[line:272] - INFO: epoch 003:    501 / 3665 loss=5.288, loss_v1=0, loss_v2=0, nll_loss=4.404, ntokens=973.2, nsentences=32, sample_size=973.2, sample_size_v1=0, sample_size_v2=0, ppl=21.17, wps=491.3, ups=0.5, wpb=973.2, bsz=32, num_updates=7820, lr=4.1842e-05, gnorm=1.774, clip=100, loss_scale=256, train_wall=20, gb_free=15.1, wall=21494
2023-01-09 09:36:08 - progress_bar.py[line:272] - INFO: epoch 003:    511 / 3665 loss=5.417, loss_v1=0, loss_v2=0, nll_loss=4.547, ntokens=921.4, nsentences=32, sample_size=921.4, sample_size_v1=0, sample_size_v2=0, ppl=23.38, wps=460.3, ups=0.5, wpb=921.4, bsz=32, num_updates=7830, lr=4.18275e-05, gnorm=1.681, clip=100, loss_scale=256, train_wall=20, gb_free=15.3, wall=21514
2023-01-09 09:36:28 - progress_bar.py[line:272] - INFO: epoch 003:    521 / 3665 loss=5.365, loss_v1=0, loss_v2=0, nll_loss=4.487, ntokens=977.7, nsentences=32, sample_size=977.7, sample_size_v1=0, sample_size_v2=0, ppl=22.42, wps=494.3, ups=0.51, wpb=977.7, bsz=32, num_updates=7840, lr=4.1813e-05, gnorm=1.609, clip=100, loss_scale=256, train_wall=20, gb_free=15.4, wall=21534
2023-01-09 09:36:47 - progress_bar.py[line:272] - INFO: epoch 003:    531 / 3665 loss=5.337, loss_v1=0, loss_v2=0, nll_loss=4.457, ntokens=966.5, nsentences=32, sample_size=966.5, sample_size_v1=0, sample_size_v2=0, ppl=21.97, wps=488.5, ups=0.51, wpb=966.5, bsz=32, num_updates=7850, lr=4.17985e-05, gnorm=1.668, clip=100, loss_scale=256, train_wall=20, gb_free=15.3, wall=21554
2023-01-09 09:37:07 - progress_bar.py[line:272] - INFO: epoch 003:    541 / 3665 loss=5.311, loss_v1=0, loss_v2=0, nll_loss=4.431, ntokens=730.4, nsentences=32, sample_size=730.4, sample_size_v1=0, sample_size_v2=0, ppl=21.57, wps=370.5, ups=0.51, wpb=730.4, bsz=32, num_updates=7860, lr=4.1784e-05, gnorm=2.085, clip=100, loss_scale=256, train_wall=20, gb_free=15.5, wall=21573
2023-01-09 09:37:27 - progress_bar.py[line:272] - INFO: epoch 003:    551 / 3665 loss=5.32, loss_v1=0, loss_v2=0, nll_loss=4.436, ntokens=995.7, nsentences=32, sample_size=995.7, sample_size_v1=0, sample_size_v2=0, ppl=21.65, wps=502.7, ups=0.5, wpb=995.7, bsz=32, num_updates=7870, lr=4.17695e-05, gnorm=1.73, clip=100, loss_scale=256, train_wall=20, gb_free=15.2, wall=21593
2023-01-09 09:37:47 - progress_bar.py[line:272] - INFO: epoch 003:    561 / 3665 loss=5.354, loss_v1=0, loss_v2=0, nll_loss=4.476, ntokens=1009.3, nsentences=32, sample_size=1009.3, sample_size_v1=0, sample_size_v2=0, ppl=22.26, wps=509, ups=0.5, wpb=1009.3, bsz=32, num_updates=7880, lr=4.1755e-05, gnorm=1.643, clip=100, loss_scale=256, train_wall=20, gb_free=15.4, wall=21613
2023-01-09 09:38:06 - progress_bar.py[line:272] - INFO: epoch 003:    571 / 3665 loss=5.202, loss_v1=0, loss_v2=0, nll_loss=4.309, ntokens=738.9, nsentences=32, sample_size=738.9, sample_size_v1=0, sample_size_v2=0, ppl=19.82, wps=375.3, ups=0.51, wpb=738.9, bsz=32, num_updates=7890, lr=4.17404e-05, gnorm=2.21, clip=100, loss_scale=256, train_wall=20, gb_free=15.4, wall=21633
2023-01-09 09:38:26 - progress_bar.py[line:272] - INFO: epoch 003:    581 / 3665 loss=5.297, loss_v1=0, loss_v2=0, nll_loss=4.414, ntokens=1057.6, nsentences=32, sample_size=1057.6, sample_size_v1=0, sample_size_v2=0, ppl=21.31, wps=533, ups=0.5, wpb=1057.6, bsz=32, num_updates=7900, lr=4.17259e-05, gnorm=1.668, clip=100, loss_scale=256, train_wall=20, gb_free=15.1, wall=21653
2023-01-09 09:38:46 - progress_bar.py[line:272] - INFO: epoch 003:    591 / 3665 loss=5.416, loss_v1=0, loss_v2=0, nll_loss=4.542, ntokens=950.5, nsentences=32, sample_size=950.5, sample_size_v1=0, sample_size_v2=0, ppl=23.3, wps=479.2, ups=0.5, wpb=950.5, bsz=32, num_updates=7910, lr=4.17114e-05, gnorm=1.805, clip=100, loss_scale=256, train_wall=20, gb_free=15.2, wall=21672
2023-01-09 09:39:06 - progress_bar.py[line:272] - INFO: epoch 003:    601 / 3665 loss=5.357, loss_v1=0, loss_v2=0, nll_loss=4.481, ntokens=852.4, nsentences=32, sample_size=852.4, sample_size_v1=0, sample_size_v2=0, ppl=22.33, wps=431.9, ups=0.51, wpb=852.4, bsz=32, num_updates=7920, lr=4.16969e-05, gnorm=1.974, clip=100, loss_scale=256, train_wall=20, gb_free=15.5, wall=21692
2023-01-09 09:39:26 - progress_bar.py[line:272] - INFO: epoch 003:    611 / 3665 loss=5.255, loss_v1=0, loss_v2=0, nll_loss=4.367, ntokens=959.2, nsentences=32, sample_size=959.2, sample_size_v1=0, sample_size_v2=0, ppl=20.63, wps=485.9, ups=0.51, wpb=959.2, bsz=32, num_updates=7930, lr=4.16824e-05, gnorm=1.82, clip=100, loss_scale=512, train_wall=20, gb_free=15.5, wall=21712
2023-01-09 09:39:45 - progress_bar.py[line:272] - INFO: epoch 003:    621 / 3665 loss=5.397, loss_v1=0, loss_v2=0, nll_loss=4.525, ntokens=902, nsentences=32, sample_size=902, sample_size_v1=0, sample_size_v2=0, ppl=23.02, wps=455.1, ups=0.5, wpb=902, bsz=32, num_updates=7940, lr=4.16679e-05, gnorm=1.733, clip=100, loss_scale=512, train_wall=20, gb_free=15.5, wall=21732
2023-01-09 09:40:05 - progress_bar.py[line:272] - INFO: epoch 003:    631 / 3665 loss=5.3, loss_v1=0, loss_v2=0, nll_loss=4.414, ntokens=938.5, nsentences=32, sample_size=938.5, sample_size_v1=0, sample_size_v2=0, ppl=21.32, wps=475, ups=0.51, wpb=938.5, bsz=32, num_updates=7950, lr=4.16534e-05, gnorm=1.711, clip=100, loss_scale=512, train_wall=20, gb_free=15.5, wall=21751
2023-01-09 09:40:25 - progress_bar.py[line:272] - INFO: epoch 003:    641 / 3665 loss=5.389, loss_v1=0, loss_v2=0, nll_loss=4.515, ntokens=1087.2, nsentences=32, sample_size=1087.2, sample_size_v1=0, sample_size_v2=0, ppl=22.86, wps=547.3, ups=0.5, wpb=1087.2, bsz=32, num_updates=7960, lr=4.16388e-05, gnorm=1.6, clip=90, loss_scale=512, train_wall=20, gb_free=15.4, wall=21771
2023-01-09 09:40:45 - progress_bar.py[line:272] - INFO: epoch 003:    651 / 3665 loss=5.358, loss_v1=0, loss_v2=0, nll_loss=4.48, ntokens=759.8, nsentences=32, sample_size=759.8, sample_size_v1=0, sample_size_v2=0, ppl=22.32, wps=385.2, ups=0.51, wpb=759.8, bsz=32, num_updates=7970, lr=4.16243e-05, gnorm=2.008, clip=100, loss_scale=512, train_wall=20, gb_free=15.4, wall=21791
2023-01-09 09:41:05 - progress_bar.py[line:272] - INFO: epoch 003:    661 / 3665 loss=5.3, loss_v1=0, loss_v2=0, nll_loss=4.418, ntokens=851.4, nsentences=32, sample_size=851.4, sample_size_v1=0, sample_size_v2=0, ppl=21.38, wps=431.3, ups=0.51, wpb=851.4, bsz=32, num_updates=7980, lr=4.16098e-05, gnorm=1.971, clip=100, loss_scale=512, train_wall=20, gb_free=15.2, wall=21811
2023-01-09 09:41:24 - progress_bar.py[line:272] - INFO: epoch 003:    671 / 3665 loss=5.445, loss_v1=0, loss_v2=0, nll_loss=4.577, ntokens=1019.8, nsentences=32, sample_size=1019.8, sample_size_v1=0, sample_size_v2=0, ppl=23.87, wps=513.8, ups=0.5, wpb=1019.8, bsz=32, num_updates=7990, lr=4.15953e-05, gnorm=1.798, clip=100, loss_scale=512, train_wall=20, gb_free=15.4, wall=21831
2023-01-09 09:41:44 - progress_bar.py[line:272] - INFO: epoch 003:    681 / 3665 loss=5.323, loss_v1=0, loss_v2=0, nll_loss=4.439, ntokens=850.4, nsentences=32, sample_size=850.4, sample_size_v1=0, sample_size_v2=0, ppl=21.69, wps=430.3, ups=0.51, wpb=850.4, bsz=32, num_updates=8000, lr=4.15808e-05, gnorm=1.935, clip=100, loss_scale=512, train_wall=20, gb_free=15.4, wall=21850
2023-01-09 09:41:44 - train.py[line:445] - INFO: begin validation on "valid" subset
slice_id 0 seek offset 0
slice_id 0 seek offset 0
2023-01-09 09:46:29 - progress_bar.py[line:282] - INFO: epoch 003 | valid on 'valid' subset | loss 5.32 | loss_v1 0 | loss_v2 0 | nll_loss 4.423 | ntokens 117.498 | nsentences 4 | sample_size 117.498 | sample_size_v1 0 | sample_size_v2 0 | AP 0 | total positives 21.8061 | TP 0 | FP 5.93538 | ppl 21.45 | wps 516 | wpb 117.5 | bsz 4 | num_updates 8000 | best_AP 0
2023-01-09 09:46:29 - checkpoint_utils.py[line:64] - INFO: Preparing to save checkpoint for epoch 3 @ 8000 updates
2023-01-09 09:46:29 - trainer.py[line:431] - INFO: Saving checkpoint to ../../checkpoints/OFA/detection_checkpoints/10_5e-5_512/checkpoint_3_8000.pt
2023-01-09 09:46:32 - trainer.py[line:441] - INFO: Finished saving checkpoint to ../../checkpoints/OFA/detection_checkpoints/10_5e-5_512/checkpoint_3_8000.pt
2023-01-09 09:47:46 - checkpoint_utils.py[line:133] - INFO: Saved checkpoint ../../checkpoints/OFA/detection_checkpoints/10_5e-5_512/checkpoint_3_8000.pt (epoch 3 @ 8000 updates, score 0.0) (writing took 76.61128494888544 seconds)
2023-01-09 09:48:05 - progress_bar.py[line:272] - INFO: epoch 003:    691 / 3665 loss=5.195, loss_v1=0, loss_v2=0, nll_loss=4.299, ntokens=873.3, nsentences=32, sample_size=873.3, sample_size_v1=0, sample_size_v2=0, ppl=19.69, wps=22.9, ups=0.03, wpb=873.3, bsz=32, num_updates=8010, lr=4.15663e-05, gnorm=1.797, clip=100, loss_scale=512, train_wall=19, gb_free=15.5, wall=22231
2023-01-09 09:48:24 - progress_bar.py[line:272] - INFO: epoch 003:    701 / 3665 loss=5.41, loss_v1=0, loss_v2=0, nll_loss=4.54, ntokens=1022.5, nsentences=32, sample_size=1022.5, sample_size_v1=0, sample_size_v2=0, ppl=23.26, wps=523.3, ups=0.51, wpb=1022.5, bsz=32, num_updates=8020, lr=4.15518e-05, gnorm=1.778, clip=100, loss_scale=512, train_wall=20, gb_free=15.4, wall=22251
2023-01-09 09:48:44 - progress_bar.py[line:272] - INFO: epoch 003:    711 / 3665 loss=5.331, loss_v1=0, loss_v2=0, nll_loss=4.45, ntokens=809.6, nsentences=32, sample_size=809.6, sample_size_v1=0, sample_size_v2=0, ppl=21.86, wps=416.1, ups=0.51, wpb=809.6, bsz=32, num_updates=8030, lr=4.15373e-05, gnorm=1.85, clip=100, loss_scale=512, train_wall=19, gb_free=15.2, wall=22270
2023-01-09 09:49:04 - progress_bar.py[line:272] - INFO: epoch 003:    721 / 3665 loss=5.336, loss_v1=0, loss_v2=0, nll_loss=4.457, ntokens=1040.1, nsentences=32, sample_size=1040.1, sample_size_v1=0, sample_size_v2=0, ppl=21.97, wps=528.1, ups=0.51, wpb=1040.1, bsz=32, num_updates=8040, lr=4.15227e-05, gnorm=1.663, clip=100, loss_scale=512, train_wall=20, gb_free=15.3, wall=22290
2023-01-09 09:49:23 - progress_bar.py[line:272] - INFO: epoch 003:    731 / 3665 loss=5.401, loss_v1=0, loss_v2=0, nll_loss=4.53, ntokens=849.1, nsentences=32, sample_size=849.1, sample_size_v1=0, sample_size_v2=0, ppl=23.1, wps=433.3, ups=0.51, wpb=849.1, bsz=32, num_updates=8050, lr=4.15082e-05, gnorm=1.938, clip=100, loss_scale=512, train_wall=20, gb_free=15.4, wall=22309
2023-01-09 09:49:43 - progress_bar.py[line:272] - INFO: epoch 003:    741 / 3665 loss=5.33, loss_v1=0, loss_v2=0, nll_loss=4.447, ntokens=873.6, nsentences=32, sample_size=873.6, sample_size_v1=0, sample_size_v2=0, ppl=21.8, wps=447.1, ups=0.51, wpb=873.6, bsz=32, num_updates=8060, lr=4.14937e-05, gnorm=1.764, clip=100, loss_scale=512, train_wall=20, gb_free=15.6, wall=22329
2023-01-09 09:50:02 - progress_bar.py[line:272] - INFO: epoch 003:    751 / 3665 loss=5.285, loss_v1=0, loss_v2=0, nll_loss=4.397, ntokens=1006.7, nsentences=32, sample_size=1006.7, sample_size_v1=0, sample_size_v2=0, ppl=21.07, wps=513, ups=0.51, wpb=1006.7, bsz=32, num_updates=8070, lr=4.14792e-05, gnorm=1.645, clip=100, loss_scale=512, train_wall=20, gb_free=15.4, wall=22349
2023-01-09 09:50:22 - progress_bar.py[line:272] - INFO: epoch 003:    761 / 3665 loss=5.381, loss_v1=0, loss_v2=0, nll_loss=4.508, ntokens=824, nsentences=32, sample_size=824, sample_size_v1=0, sample_size_v2=0, ppl=22.75, wps=421.9, ups=0.51, wpb=824, bsz=32, num_updates=8080, lr=4.14647e-05, gnorm=1.859, clip=100, loss_scale=512, train_wall=20, gb_free=15.2, wall=22368
2023-01-09 09:50:41 - progress_bar.py[line:272] - INFO: epoch 003:    771 / 3665 loss=5.316, loss_v1=0, loss_v2=0, nll_loss=4.435, ntokens=950.2, nsentences=32, sample_size=950.2, sample_size_v1=0, sample_size_v2=0, ppl=21.64, wps=484, ups=0.51, wpb=950.2, bsz=32, num_updates=8090, lr=4.14502e-05, gnorm=1.605, clip=100, loss_scale=512, train_wall=20, gb_free=15.5, wall=22388
2023-01-09 09:51:01 - progress_bar.py[line:272] - INFO: epoch 003:    781 / 3665 loss=5.336, loss_v1=0, loss_v2=0, nll_loss=4.456, ntokens=1011.1, nsentences=32, sample_size=1011.1, sample_size_v1=0, sample_size_v2=0, ppl=21.95, wps=513.9, ups=0.51, wpb=1011.1, bsz=32, num_updates=8100, lr=4.14357e-05, gnorm=1.76, clip=100, loss_scale=512, train_wall=20, gb_free=15.5, wall=22407
2023-01-09 09:51:21 - progress_bar.py[line:272] - INFO: epoch 003:    791 / 3665 loss=5.298, loss_v1=0, loss_v2=0, nll_loss=4.412, ntokens=794, nsentences=32, sample_size=794, sample_size_v1=0, sample_size_v2=0, ppl=21.29, wps=405.5, ups=0.51, wpb=794, bsz=32, num_updates=8110, lr=4.14211e-05, gnorm=1.774, clip=100, loss_scale=512, train_wall=20, gb_free=15.6, wall=22427
2023-01-09 09:51:40 - progress_bar.py[line:272] - INFO: epoch 003:    801 / 3665 loss=5.34, loss_v1=0, loss_v2=0, nll_loss=4.46, ntokens=1043.4, nsentences=32, sample_size=1043.4, sample_size_v1=0, sample_size_v2=0, ppl=22, wps=529.8, ups=0.51, wpb=1043.4, bsz=32, num_updates=8120, lr=4.14066e-05, gnorm=1.559, clip=100, loss_scale=512, train_wall=20, gb_free=15.1, wall=22447
2023-01-09 09:52:00 - progress_bar.py[line:272] - INFO: epoch 003:    811 / 3665 loss=5.321, loss_v1=0, loss_v2=0, nll_loss=4.438, ntokens=849.2, nsentences=32, sample_size=849.2, sample_size_v1=0, sample_size_v2=0, ppl=21.68, wps=433.3, ups=0.51, wpb=849.2, bsz=32, num_updates=8130, lr=4.13921e-05, gnorm=1.773, clip=100, loss_scale=512, train_wall=20, gb_free=15.6, wall=22466
2023-01-09 09:52:20 - progress_bar.py[line:272] - INFO: epoch 003:    821 / 3665 loss=5.311, loss_v1=0, loss_v2=0, nll_loss=4.432, ntokens=801.4, nsentences=32, sample_size=801.4, sample_size_v1=0, sample_size_v2=0, ppl=21.58, wps=408.1, ups=0.51, wpb=801.4, bsz=32, num_updates=8140, lr=4.13776e-05, gnorm=1.964, clip=100, loss_scale=512, train_wall=20, gb_free=15.3, wall=22486
2023-01-09 09:52:39 - progress_bar.py[line:272] - INFO: epoch 003:    831 / 3665 loss=5.31, loss_v1=0, loss_v2=0, nll_loss=4.427, ntokens=1025.8, nsentences=32, sample_size=1025.8, sample_size_v1=0, sample_size_v2=0, ppl=21.51, wps=520.2, ups=0.51, wpb=1025.8, bsz=32, num_updates=8150, lr=4.13631e-05, gnorm=1.581, clip=100, loss_scale=512, train_wall=20, gb_free=15.2, wall=22506
2023-01-09 09:52:59 - progress_bar.py[line:272] - INFO: epoch 003:    841 / 3665 loss=5.353, loss_v1=0, loss_v2=0, nll_loss=4.476, ntokens=788.8, nsentences=32, sample_size=788.8, sample_size_v1=0, sample_size_v2=0, ppl=22.26, wps=402.8, ups=0.51, wpb=788.8, bsz=32, num_updates=8160, lr=4.13486e-05, gnorm=1.87, clip=100, loss_scale=512, train_wall=20, gb_free=15.6, wall=22525
2023-01-09 09:53:19 - progress_bar.py[line:272] - INFO: epoch 003:    851 / 3665 loss=5.275, loss_v1=0, loss_v2=0, nll_loss=4.386, ntokens=826.1, nsentences=32, sample_size=826.1, sample_size_v1=0, sample_size_v2=0, ppl=20.91, wps=421.8, ups=0.51, wpb=826.1, bsz=32, num_updates=8170, lr=4.13341e-05, gnorm=1.91, clip=100, loss_scale=512, train_wall=20, gb_free=15.3, wall=22545
2023-01-09 09:53:38 - progress_bar.py[line:272] - INFO: epoch 003:    861 / 3665 loss=5.294, loss_v1=0, loss_v2=0, nll_loss=4.411, ntokens=1047.2, nsentences=32, sample_size=1047.2, sample_size_v1=0, sample_size_v2=0, ppl=21.27, wps=531.8, ups=0.51, wpb=1047.2, bsz=32, num_updates=8180, lr=4.13196e-05, gnorm=1.624, clip=100, loss_scale=512, train_wall=20, gb_free=15.1, wall=22564
2023-01-09 09:53:58 - progress_bar.py[line:272] - INFO: epoch 003:    871 / 3665 loss=5.427, loss_v1=0, loss_v2=0, nll_loss=4.557, ntokens=986.4, nsentences=32, sample_size=986.4, sample_size_v1=0, sample_size_v2=0, ppl=23.54, wps=490.9, ups=0.5, wpb=986.4, bsz=32, num_updates=8190, lr=4.1305e-05, gnorm=1.685, clip=100, loss_scale=512, train_wall=20, gb_free=15.5, wall=22585
2023-01-09 09:54:18 - progress_bar.py[line:272] - INFO: epoch 003:    881 / 3665 loss=5.268, loss_v1=0, loss_v2=0, nll_loss=4.382, ntokens=918.5, nsentences=32, sample_size=918.5, sample_size_v1=0, sample_size_v2=0, ppl=20.86, wps=458.1, ups=0.5, wpb=918.5, bsz=32, num_updates=8200, lr=4.12905e-05, gnorm=1.682, clip=100, loss_scale=512, train_wall=20, gb_free=15.4, wall=22605
2023-01-09 09:54:38 - progress_bar.py[line:272] - INFO: epoch 003:    891 / 3665 loss=5.303, loss_v1=0, loss_v2=0, nll_loss=4.42, ntokens=1023.8, nsentences=32, sample_size=1023.8, sample_size_v1=0, sample_size_v2=0, ppl=21.4, wps=508.4, ups=0.5, wpb=1023.8, bsz=32, num_updates=8210, lr=4.1276e-05, gnorm=1.621, clip=100, loss_scale=512, train_wall=20, gb_free=15.3, wall=22625
2023-01-09 09:54:59 - progress_bar.py[line:272] - INFO: epoch 003:    901 / 3665 loss=5.391, loss_v1=0, loss_v2=0, nll_loss=4.516, ntokens=967.3, nsentences=32, sample_size=967.3, sample_size_v1=0, sample_size_v2=0, ppl=22.87, wps=482.4, ups=0.5, wpb=967.3, bsz=32, num_updates=8220, lr=4.12615e-05, gnorm=1.78, clip=100, loss_scale=512, train_wall=20, gb_free=15.4, wall=22645
2023-01-09 09:55:18 - progress_bar.py[line:272] - INFO: epoch 003:    911 / 3665 loss=5.251, loss_v1=0, loss_v2=0, nll_loss=4.364, ntokens=977.9, nsentences=32, sample_size=977.9, sample_size_v1=0, sample_size_v2=0, ppl=20.59, wps=493.6, ups=0.5, wpb=977.9, bsz=32, num_updates=8230, lr=4.1247e-05, gnorm=1.794, clip=100, loss_scale=512, train_wall=20, gb_free=15.5, wall=22665
2023-01-09 09:55:38 - progress_bar.py[line:272] - INFO: epoch 003:    921 / 3665 loss=5.403, loss_v1=0, loss_v2=0, nll_loss=4.529, ntokens=1043.5, nsentences=32, sample_size=1043.5, sample_size_v1=0, sample_size_v2=0, ppl=23.09, wps=527.8, ups=0.51, wpb=1043.5, bsz=32, num_updates=8240, lr=4.12325e-05, gnorm=1.602, clip=100, loss_scale=512, train_wall=20, gb_free=15.1, wall=22684
2023-01-09 09:55:58 - progress_bar.py[line:272] - INFO: epoch 003:    931 / 3665 loss=5.375, loss_v1=0, loss_v2=0, nll_loss=4.5, ntokens=852.2, nsentences=32, sample_size=852.2, sample_size_v1=0, sample_size_v2=0, ppl=22.62, wps=432.5, ups=0.51, wpb=852.2, bsz=32, num_updates=8250, lr=4.1218e-05, gnorm=1.778, clip=100, loss_scale=512, train_wall=20, gb_free=15.5, wall=22704
2023-01-09 09:56:18 - progress_bar.py[line:272] - INFO: epoch 003:    941 / 3665 loss=5.289, loss_v1=0, loss_v2=0, nll_loss=4.405, ntokens=941.9, nsentences=32, sample_size=941.9, sample_size_v1=0, sample_size_v2=0, ppl=21.19, wps=478.1, ups=0.51, wpb=941.9, bsz=32, num_updates=8260, lr=4.12034e-05, gnorm=1.561, clip=100, loss_scale=512, train_wall=20, gb_free=15.5, wall=22724
2023-01-09 09:56:37 - progress_bar.py[line:272] - INFO: epoch 003:    951 / 3665 loss=5.304, loss_v1=0, loss_v2=0, nll_loss=4.419, ntokens=877.2, nsentences=32, sample_size=877.2, sample_size_v1=0, sample_size_v2=0, ppl=21.39, wps=445.2, ups=0.51, wpb=877.2, bsz=32, num_updates=8270, lr=4.11889e-05, gnorm=1.856, clip=100, loss_scale=512, train_wall=20, gb_free=15.7, wall=22744
2023-01-09 09:56:57 - progress_bar.py[line:272] - INFO: epoch 003:    961 / 3665 loss=5.297, loss_v1=0, loss_v2=0, nll_loss=4.414, ntokens=793.8, nsentences=32, sample_size=793.8, sample_size_v1=0, sample_size_v2=0, ppl=21.32, wps=404.8, ups=0.51, wpb=793.8, bsz=32, num_updates=8280, lr=4.11744e-05, gnorm=1.966, clip=100, loss_scale=512, train_wall=20, gb_free=15.4, wall=22763
2023-01-09 09:57:17 - progress_bar.py[line:272] - INFO: epoch 003:    971 / 3665 loss=5.234, loss_v1=0, loss_v2=0, nll_loss=4.341, ntokens=971.3, nsentences=32, sample_size=971.3, sample_size_v1=0, sample_size_v2=0, ppl=20.26, wps=493.5, ups=0.51, wpb=971.3, bsz=32, num_updates=8290, lr=4.11599e-05, gnorm=1.551, clip=100, loss_scale=512, train_wall=20, gb_free=15.7, wall=22783
2023-01-09 09:57:36 - progress_bar.py[line:272] - INFO: epoch 003:    981 / 3665 loss=5.42, loss_v1=0, loss_v2=0, nll_loss=4.554, ntokens=904.5, nsentences=32, sample_size=904.5, sample_size_v1=0, sample_size_v2=0, ppl=23.49, wps=456.5, ups=0.5, wpb=904.5, bsz=32, num_updates=8300, lr=4.11454e-05, gnorm=1.88, clip=100, loss_scale=512, train_wall=20, gb_free=15.3, wall=22803
2023-01-09 09:57:56 - progress_bar.py[line:272] - INFO: epoch 003:    991 / 3665 loss=5.281, loss_v1=0, loss_v2=0, nll_loss=4.391, ntokens=835.7, nsentences=32, sample_size=835.7, sample_size_v1=0, sample_size_v2=0, ppl=20.99, wps=426.4, ups=0.51, wpb=835.7, bsz=32, num_updates=8310, lr=4.11309e-05, gnorm=1.868, clip=100, loss_scale=512, train_wall=20, gb_free=15.5, wall=22822
2023-01-09 09:58:16 - progress_bar.py[line:272] - INFO: epoch 003:   1001 / 3665 loss=5.318, loss_v1=0, loss_v2=0, nll_loss=4.437, ntokens=1059.1, nsentences=32, sample_size=1059.1, sample_size_v1=0, sample_size_v2=0, ppl=21.66, wps=536.1, ups=0.51, wpb=1059.1, bsz=32, num_updates=8320, lr=4.11164e-05, gnorm=1.524, clip=100, loss_scale=512, train_wall=20, gb_free=14.3, wall=22842
2023-01-09 09:58:35 - progress_bar.py[line:272] - INFO: epoch 003:   1011 / 3665 loss=5.327, loss_v1=0, loss_v2=0, nll_loss=4.447, ntokens=814.1, nsentences=32, sample_size=814.1, sample_size_v1=0, sample_size_v2=0, ppl=21.81, wps=415.4, ups=0.51, wpb=814.1, bsz=32, num_updates=8330, lr=4.11019e-05, gnorm=1.877, clip=100, loss_scale=512, train_wall=20, gb_free=15.3, wall=22862
2023-01-09 09:58:55 - progress_bar.py[line:272] - INFO: epoch 003:   1021 / 3665 loss=5.261, loss_v1=0, loss_v2=0, nll_loss=4.372, ntokens=910, nsentences=32, sample_size=910, sample_size_v1=0, sample_size_v2=0, ppl=20.71, wps=462.9, ups=0.51, wpb=910, bsz=32, num_updates=8340, lr=4.10873e-05, gnorm=1.672, clip=100, loss_scale=512, train_wall=20, gb_free=15.2, wall=22881
2023-01-09 09:59:15 - progress_bar.py[line:272] - INFO: epoch 003:   1031 / 3665 loss=5.397, loss_v1=0, loss_v2=0, nll_loss=4.524, ntokens=1038.7, nsentences=32, sample_size=1038.7, sample_size_v1=0, sample_size_v2=0, ppl=23.01, wps=525.8, ups=0.51, wpb=1038.7, bsz=32, num_updates=8350, lr=4.10728e-05, gnorm=1.621, clip=100, loss_scale=512, train_wall=20, gb_free=15, wall=22901
2023-01-09 09:59:35 - progress_bar.py[line:272] - INFO: epoch 003:   1041 / 3665 loss=5.199, loss_v1=0, loss_v2=0, nll_loss=4.302, ntokens=571.5, nsentences=32, sample_size=571.5, sample_size_v1=0, sample_size_v2=0, ppl=19.72, wps=287.9, ups=0.5, wpb=571.5, bsz=32, num_updates=8360, lr=4.10583e-05, gnorm=2.587, clip=100, loss_scale=512, train_wall=20, gb_free=15.3, wall=22921
2023-01-09 09:59:55 - progress_bar.py[line:272] - INFO: epoch 003:   1051 / 3665 loss=5.296, loss_v1=0, loss_v2=0, nll_loss=4.412, ntokens=887.5, nsentences=32, sample_size=887.5, sample_size_v1=0, sample_size_v2=0, ppl=21.3, wps=444.6, ups=0.5, wpb=887.5, bsz=32, num_updates=8370, lr=4.10438e-05, gnorm=1.87, clip=100, loss_scale=512, train_wall=20, gb_free=15.4, wall=22941
2023-01-09 10:00:15 - progress_bar.py[line:272] - INFO: epoch 003:   1061 / 3665 loss=5.42, loss_v1=0, loss_v2=0, nll_loss=4.549, ntokens=1028.9, nsentences=32, sample_size=1028.9, sample_size_v1=0, sample_size_v2=0, ppl=23.42, wps=513.5, ups=0.5, wpb=1028.9, bsz=32, num_updates=8380, lr=4.10293e-05, gnorm=1.684, clip=100, loss_scale=512, train_wall=20, gb_free=15.5, wall=22961
2023-01-09 10:00:34 - progress_bar.py[line:272] - INFO: epoch 003:   1071 / 3665 loss=5.327, loss_v1=0, loss_v2=0, nll_loss=4.445, ntokens=762.2, nsentences=32, sample_size=762.2, sample_size_v1=0, sample_size_v2=0, ppl=21.78, wps=383.4, ups=0.5, wpb=762.2, bsz=32, num_updates=8390, lr=4.10148e-05, gnorm=2.16, clip=100, loss_scale=512, train_wall=20, gb_free=15.6, wall=22981
2023-01-09 10:00:54 - progress_bar.py[line:272] - INFO: epoch 003:   1081 / 3665 loss=5.263, loss_v1=0, loss_v2=0, nll_loss=4.375, ntokens=1034.2, nsentences=32, sample_size=1034.2, sample_size_v1=0, sample_size_v2=0, ppl=20.76, wps=518.3, ups=0.5, wpb=1034.2, bsz=32, num_updates=8400, lr=4.10003e-05, gnorm=1.648, clip=100, loss_scale=512, train_wall=20, gb_free=15.3, wall=23001
2023-01-09 10:01:14 - progress_bar.py[line:272] - INFO: epoch 003:   1091 / 3665 loss=5.326, loss_v1=0, loss_v2=0, nll_loss=4.447, ntokens=859.7, nsentences=32, sample_size=859.7, sample_size_v1=0, sample_size_v2=0, ppl=21.81, wps=431.6, ups=0.5, wpb=859.7, bsz=32, num_updates=8410, lr=4.09857e-05, gnorm=1.957, clip=100, loss_scale=512, train_wall=20, gb_free=15.5, wall=23021
2023-01-09 10:01:34 - progress_bar.py[line:272] - INFO: epoch 003:   1101 / 3665 loss=5.3, loss_v1=0, loss_v2=0, nll_loss=4.414, ntokens=958, nsentences=32, sample_size=958, sample_size_v1=0, sample_size_v2=0, ppl=21.31, wps=484.1, ups=0.51, wpb=958, bsz=32, num_updates=8420, lr=4.09712e-05, gnorm=1.663, clip=100, loss_scale=512, train_wall=20, gb_free=15.4, wall=23040
2023-01-09 10:01:54 - progress_bar.py[line:272] - INFO: epoch 003:   1111 / 3665 loss=5.292, loss_v1=0, loss_v2=0, nll_loss=4.409, ntokens=755.7, nsentences=32, sample_size=755.7, sample_size_v1=0, sample_size_v2=0, ppl=21.24, wps=383.1, ups=0.51, wpb=755.7, bsz=32, num_updates=8430, lr=4.09567e-05, gnorm=2.054, clip=100, loss_scale=512, train_wall=20, gb_free=15.3, wall=23060
2023-01-09 10:02:14 - progress_bar.py[line:272] - INFO: epoch 003:   1121 / 3665 loss=5.287, loss_v1=0, loss_v2=0, nll_loss=4.402, ntokens=1125.8, nsentences=32, sample_size=1125.8, sample_size_v1=0, sample_size_v2=0, ppl=21.14, wps=568.3, ups=0.5, wpb=1125.8, bsz=32, num_updates=8440, lr=4.09422e-05, gnorm=1.536, clip=100, loss_scale=1024, train_wall=20, gb_free=15.5, wall=23080
2023-01-09 10:02:18 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 512.0
2023-01-09 10:02:35 - progress_bar.py[line:272] - INFO: epoch 003:   1132 / 3665 loss=5.304, loss_v1=0, loss_v2=0, nll_loss=4.42, ntokens=1103.7, nsentences=32, sample_size=1103.7, sample_size_v1=0, sample_size_v2=0, ppl=21.41, wps=507.5, ups=0.46, wpb=1103.7, bsz=32, num_updates=8450, lr=4.09277e-05, gnorm=1.61, clip=100, loss_scale=512, train_wall=22, gb_free=15.3, wall=23102
2023-01-09 10:02:55 - progress_bar.py[line:272] - INFO: epoch 003:   1142 / 3665 loss=5.359, loss_v1=0, loss_v2=0, nll_loss=4.481, ntokens=743.4, nsentences=32, sample_size=743.4, sample_size_v1=0, sample_size_v2=0, ppl=22.33, wps=378.6, ups=0.51, wpb=743.4, bsz=32, num_updates=8460, lr=4.09132e-05, gnorm=2.082, clip=100, loss_scale=512, train_wall=20, gb_free=15.7, wall=23121
2023-01-09 10:03:15 - progress_bar.py[line:272] - INFO: epoch 003:   1152 / 3665 loss=5.296, loss_v1=0, loss_v2=0, nll_loss=4.413, ntokens=884.7, nsentences=32, sample_size=884.7, sample_size_v1=0, sample_size_v2=0, ppl=21.3, wps=448.4, ups=0.51, wpb=884.7, bsz=32, num_updates=8470, lr=4.08987e-05, gnorm=1.859, clip=100, loss_scale=512, train_wall=20, gb_free=15.5, wall=23141
2023-01-09 10:03:34 - progress_bar.py[line:272] - INFO: epoch 003:   1162 / 3665 loss=5.238, loss_v1=0, loss_v2=0, nll_loss=4.349, ntokens=919.4, nsentences=32, sample_size=919.4, sample_size_v1=0, sample_size_v2=0, ppl=20.38, wps=466.2, ups=0.51, wpb=919.4, bsz=32, num_updates=8480, lr=4.08842e-05, gnorm=1.707, clip=100, loss_scale=512, train_wall=20, gb_free=15.5, wall=23161
2023-01-09 10:03:54 - progress_bar.py[line:272] - INFO: epoch 003:   1172 / 3665 loss=5.319, loss_v1=0, loss_v2=0, nll_loss=4.434, ntokens=888.6, nsentences=32, sample_size=888.6, sample_size_v1=0, sample_size_v2=0, ppl=21.62, wps=449.7, ups=0.51, wpb=888.6, bsz=32, num_updates=8490, lr=4.08696e-05, gnorm=1.876, clip=100, loss_scale=512, train_wall=20, gb_free=15.6, wall=23181
2023-01-09 10:04:14 - progress_bar.py[line:272] - INFO: epoch 003:   1182 / 3665 loss=5.292, loss_v1=0, loss_v2=0, nll_loss=4.406, ntokens=849.5, nsentences=32, sample_size=849.5, sample_size_v1=0, sample_size_v2=0, ppl=21.2, wps=430.4, ups=0.51, wpb=849.5, bsz=32, num_updates=8500, lr=4.08551e-05, gnorm=2.125, clip=100, loss_scale=512, train_wall=20, gb_free=15.4, wall=23200
2023-01-09 10:04:14 - train.py[line:445] - INFO: begin validation on "valid" subset
slice_id 0 seek offset 0
slice_id 0 seek offset 0
2023-01-09 10:09:02 - progress_bar.py[line:282] - INFO: epoch 003 | valid on 'valid' subset | loss 5.318 | loss_v1 0 | loss_v2 0 | nll_loss 4.419 | ntokens 116.685 | nsentences 4 | sample_size 116.685 | sample_size_v1 0 | sample_size_v2 0 | AP 0 | total positives 21.6462 | TP 0 | FP 5.31987 | ppl 21.4 | wps 506.3 | wpb 116.7 | bsz 4 | num_updates 8500 | best_AP 0
2023-01-09 10:09:02 - checkpoint_utils.py[line:64] - INFO: Preparing to save checkpoint for epoch 3 @ 8500 updates
2023-01-09 10:09:02 - trainer.py[line:431] - INFO: Saving checkpoint to ../../checkpoints/OFA/detection_checkpoints/10_5e-5_512/checkpoint_3_8500.pt
2023-01-09 10:09:05 - trainer.py[line:441] - INFO: Finished saving checkpoint to ../../checkpoints/OFA/detection_checkpoints/10_5e-5_512/checkpoint_3_8500.pt
2023-01-09 10:10:19 - checkpoint_utils.py[line:133] - INFO: Saved checkpoint ../../checkpoints/OFA/detection_checkpoints/10_5e-5_512/checkpoint_3_8500.pt (epoch 3 @ 8500 updates, score 0.0) (writing took 77.2164936340414 seconds)
2023-01-09 10:10:38 - progress_bar.py[line:272] - INFO: epoch 003:   1192 / 3665 loss=5.324, loss_v1=0, loss_v2=0, nll_loss=4.445, ntokens=1095.9, nsentences=32, sample_size=1095.9, sample_size_v1=0, sample_size_v2=0, ppl=21.78, wps=28.5, ups=0.03, wpb=1095.9, bsz=32, num_updates=8510, lr=4.08406e-05, gnorm=1.629, clip=100, loss_scale=512, train_wall=19, gb_free=15.3, wall=23585
2023-01-09 10:10:58 - progress_bar.py[line:272] - INFO: epoch 003:   1202 / 3665 loss=5.399, loss_v1=0, loss_v2=0, nll_loss=4.527, ntokens=1048.4, nsentences=32, sample_size=1048.4, sample_size_v1=0, sample_size_v2=0, ppl=23.05, wps=537.6, ups=0.51, wpb=1048.4, bsz=32, num_updates=8520, lr=4.08261e-05, gnorm=1.709, clip=100, loss_scale=512, train_wall=19, gb_free=15.3, wall=23604
2023-01-09 10:11:17 - progress_bar.py[line:272] - INFO: epoch 003:   1212 / 3665 loss=5.278, loss_v1=0, loss_v2=0, nll_loss=4.389, ntokens=759.9, nsentences=32, sample_size=759.9, sample_size_v1=0, sample_size_v2=0, ppl=20.95, wps=391.5, ups=0.52, wpb=759.9, bsz=32, num_updates=8530, lr=4.08116e-05, gnorm=2.077, clip=100, loss_scale=512, train_wall=19, gb_free=15.5, wall=23624
2023-01-09 10:11:37 - progress_bar.py[line:272] - INFO: epoch 003:   1222 / 3665 loss=5.332, loss_v1=0, loss_v2=0, nll_loss=4.451, ntokens=1075.7, nsentences=32, sample_size=1075.7, sample_size_v1=0, sample_size_v2=0, ppl=21.88, wps=547, ups=0.51, wpb=1075.7, bsz=32, num_updates=8540, lr=4.07971e-05, gnorm=1.602, clip=100, loss_scale=512, train_wall=20, gb_free=15.3, wall=23643
2023-01-09 10:11:57 - progress_bar.py[line:272] - INFO: epoch 003:   1232 / 3665 loss=5.427, loss_v1=0, loss_v2=0, nll_loss=4.558, ntokens=1100.7, nsentences=32, sample_size=1100.7, sample_size_v1=0, sample_size_v2=0, ppl=23.55, wps=558.8, ups=0.51, wpb=1100.7, bsz=32, num_updates=8550, lr=4.07826e-05, gnorm=1.488, clip=100, loss_scale=512, train_wall=20, gb_free=15.4, wall=23663
2023-01-09 10:12:16 - progress_bar.py[line:272] - INFO: epoch 003:   1242 / 3665 loss=5.424, loss_v1=0, loss_v2=0, nll_loss=4.554, ntokens=938.9, nsentences=32, sample_size=938.9, sample_size_v1=0, sample_size_v2=0, ppl=23.49, wps=477.9, ups=0.51, wpb=938.9, bsz=32, num_updates=8560, lr=4.0768e-05, gnorm=1.658, clip=100, loss_scale=512, train_wall=20, gb_free=15.3, wall=23683
2023-01-09 10:12:36 - progress_bar.py[line:272] - INFO: epoch 003:   1252 / 3665 loss=5.275, loss_v1=0, loss_v2=0, nll_loss=4.39, ntokens=987.3, nsentences=32, sample_size=987.3, sample_size_v1=0, sample_size_v2=0, ppl=20.96, wps=503.4, ups=0.51, wpb=987.3, bsz=32, num_updates=8570, lr=4.07535e-05, gnorm=1.584, clip=100, loss_scale=512, train_wall=20, gb_free=15.6, wall=23702
2023-01-09 10:12:50 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 256.0
2023-01-09 10:12:58 - progress_bar.py[line:272] - INFO: epoch 003:   1263 / 3665 loss=5.298, loss_v1=0, loss_v2=0, nll_loss=4.415, ntokens=920.8, nsentences=32, sample_size=920.8, sample_size_v1=0, sample_size_v2=0, ppl=21.34, wps=426, ups=0.46, wpb=920.8, bsz=32, num_updates=8580, lr=4.0739e-05, gnorm=1.82, clip=100, loss_scale=256, train_wall=22, gb_free=15.7, wall=23724
2023-01-09 10:13:17 - progress_bar.py[line:272] - INFO: epoch 003:   1273 / 3665 loss=5.296, loss_v1=0, loss_v2=0, nll_loss=4.409, ntokens=693.6, nsentences=32, sample_size=693.6, sample_size_v1=0, sample_size_v2=0, ppl=21.25, wps=355.3, ups=0.51, wpb=693.6, bsz=32, num_updates=8590, lr=4.07245e-05, gnorm=2.223, clip=100, loss_scale=256, train_wall=19, gb_free=15.2, wall=23743
2023-01-09 10:13:37 - progress_bar.py[line:272] - INFO: epoch 003:   1283 / 3665 loss=5.283, loss_v1=0, loss_v2=0, nll_loss=4.396, ntokens=814.6, nsentences=32, sample_size=814.6, sample_size_v1=0, sample_size_v2=0, ppl=21.06, wps=417, ups=0.51, wpb=814.6, bsz=32, num_updates=8600, lr=4.071e-05, gnorm=2.024, clip=100, loss_scale=256, train_wall=20, gb_free=15.5, wall=23763
2023-01-09 10:13:56 - progress_bar.py[line:272] - INFO: epoch 003:   1293 / 3665 loss=5.337, loss_v1=0, loss_v2=0, nll_loss=4.459, ntokens=1046.6, nsentences=32, sample_size=1046.6, sample_size_v1=0, sample_size_v2=0, ppl=21.99, wps=532.3, ups=0.51, wpb=1046.6, bsz=32, num_updates=8610, lr=4.06955e-05, gnorm=1.661, clip=100, loss_scale=256, train_wall=20, gb_free=15.4, wall=23783
2023-01-09 10:14:16 - progress_bar.py[line:272] - INFO: epoch 003:   1303 / 3665 loss=5.301, loss_v1=0, loss_v2=0, nll_loss=4.418, ntokens=809.3, nsentences=32, sample_size=809.3, sample_size_v1=0, sample_size_v2=0, ppl=21.38, wps=412.7, ups=0.51, wpb=809.3, bsz=32, num_updates=8620, lr=4.0681e-05, gnorm=2.036, clip=100, loss_scale=256, train_wall=20, gb_free=15.4, wall=23802
2023-01-09 10:14:36 - progress_bar.py[line:272] - INFO: epoch 003:   1313 / 3665 loss=5.258, loss_v1=0, loss_v2=0, nll_loss=4.367, ntokens=974, nsentences=32, sample_size=974, sample_size_v1=0, sample_size_v2=0, ppl=20.63, wps=495, ups=0.51, wpb=974, bsz=32, num_updates=8630, lr=4.06665e-05, gnorm=1.75, clip=100, loss_scale=256, train_wall=20, gb_free=15, wall=23822
2023-01-09 10:14:55 - progress_bar.py[line:272] - INFO: epoch 003:   1323 / 3665 loss=5.309, loss_v1=0, loss_v2=0, nll_loss=4.429, ntokens=1016.9, nsentences=32, sample_size=1016.9, sample_size_v1=0, sample_size_v2=0, ppl=21.54, wps=511.6, ups=0.5, wpb=1016.9, bsz=32, num_updates=8640, lr=4.06519e-05, gnorm=1.702, clip=100, loss_scale=256, train_wall=20, gb_free=15.3, wall=23842
2023-01-09 10:15:15 - progress_bar.py[line:272] - INFO: epoch 003:   1333 / 3665 loss=5.377, loss_v1=0, loss_v2=0, nll_loss=4.505, ntokens=705.5, nsentences=32, sample_size=705.5, sample_size_v1=0, sample_size_v2=0, ppl=22.7, wps=355.7, ups=0.5, wpb=705.5, bsz=32, num_updates=8650, lr=4.06374e-05, gnorm=2.116, clip=100, loss_scale=256, train_wall=20, gb_free=15.5, wall=23862
2023-01-09 10:15:35 - progress_bar.py[line:272] - INFO: epoch 003:   1343 / 3665 loss=5.281, loss_v1=0, loss_v2=0, nll_loss=4.394, ntokens=966.2, nsentences=32, sample_size=966.2, sample_size_v1=0, sample_size_v2=0, ppl=21.02, wps=485, ups=0.5, wpb=966.2, bsz=32, num_updates=8660, lr=4.06229e-05, gnorm=1.705, clip=100, loss_scale=256, train_wall=20, gb_free=15.6, wall=23881
2023-01-09 10:15:55 - progress_bar.py[line:272] - INFO: epoch 003:   1353 / 3665 loss=5.212, loss_v1=0, loss_v2=0, nll_loss=4.317, ntokens=1065.6, nsentences=32, sample_size=1065.6, sample_size_v1=0, sample_size_v2=0, ppl=19.93, wps=533.6, ups=0.5, wpb=1065.6, bsz=32, num_updates=8670, lr=4.06084e-05, gnorm=1.548, clip=100, loss_scale=256, train_wall=20, gb_free=15.3, wall=23901
2023-01-09 10:16:15 - progress_bar.py[line:272] - INFO: epoch 003:   1363 / 3665 loss=5.386, loss_v1=0, loss_v2=0, nll_loss=4.513, ntokens=928.7, nsentences=32, sample_size=928.7, sample_size_v1=0, sample_size_v2=0, ppl=22.84, wps=465.6, ups=0.5, wpb=928.7, bsz=32, num_updates=8680, lr=4.05939e-05, gnorm=1.833, clip=100, loss_scale=256, train_wall=20, gb_free=15.5, wall=23921
2023-01-09 10:16:35 - progress_bar.py[line:272] - INFO: epoch 003:   1373 / 3665 loss=5.33, loss_v1=0, loss_v2=0, nll_loss=4.45, ntokens=909.3, nsentences=32, sample_size=909.3, sample_size_v1=0, sample_size_v2=0, ppl=21.86, wps=457.6, ups=0.5, wpb=909.3, bsz=32, num_updates=8690, lr=4.05794e-05, gnorm=1.869, clip=100, loss_scale=256, train_wall=20, gb_free=15.6, wall=23941
2023-01-09 10:16:55 - progress_bar.py[line:272] - INFO: epoch 003:   1383 / 3665 loss=5.232, loss_v1=0, loss_v2=0, nll_loss=4.34, ntokens=993, nsentences=32, sample_size=993, sample_size_v1=0, sample_size_v2=0, ppl=20.25, wps=502.2, ups=0.51, wpb=993, bsz=32, num_updates=8700, lr=4.05649e-05, gnorm=1.669, clip=100, loss_scale=256, train_wall=20, gb_free=15.4, wall=23961
2023-01-09 10:17:14 - progress_bar.py[line:272] - INFO: epoch 003:   1393 / 3665 loss=5.31, loss_v1=0, loss_v2=0, nll_loss=4.427, ntokens=738.3, nsentences=32, sample_size=738.3, sample_size_v1=0, sample_size_v2=0, ppl=21.51, wps=377, ups=0.51, wpb=738.3, bsz=32, num_updates=8710, lr=4.05503e-05, gnorm=1.945, clip=100, loss_scale=256, train_wall=20, gb_free=15.6, wall=23981
2023-01-09 10:17:34 - progress_bar.py[line:272] - INFO: epoch 003:   1403 / 3665 loss=5.266, loss_v1=0, loss_v2=0, nll_loss=4.378, ntokens=791.9, nsentences=32, sample_size=791.9, sample_size_v1=0, sample_size_v2=0, ppl=20.8, wps=404.2, ups=0.51, wpb=791.9, bsz=32, num_updates=8720, lr=4.05358e-05, gnorm=2.008, clip=100, loss_scale=256, train_wall=20, gb_free=15.5, wall=24000
2023-01-09 10:17:54 - progress_bar.py[line:272] - INFO: epoch 003:   1413 / 3665 loss=5.239, loss_v1=0, loss_v2=0, nll_loss=4.35, ntokens=876.4, nsentences=32, sample_size=876.4, sample_size_v1=0, sample_size_v2=0, ppl=20.39, wps=445.5, ups=0.51, wpb=876.4, bsz=32, num_updates=8730, lr=4.05213e-05, gnorm=1.869, clip=100, loss_scale=256, train_wall=20, gb_free=15.2, wall=24020
2023-01-09 10:18:13 - progress_bar.py[line:272] - INFO: epoch 003:   1423 / 3665 loss=5.268, loss_v1=0, loss_v2=0, nll_loss=4.379, ntokens=892.3, nsentences=32, sample_size=892.3, sample_size_v1=0, sample_size_v2=0, ppl=20.81, wps=453.9, ups=0.51, wpb=892.3, bsz=32, num_updates=8740, lr=4.05068e-05, gnorm=2.02, clip=100, loss_scale=256, train_wall=20, gb_free=15.7, wall=24040
2023-01-09 10:18:33 - progress_bar.py[line:272] - INFO: epoch 003:   1433 / 3665 loss=5.297, loss_v1=0, loss_v2=0, nll_loss=4.413, ntokens=754.8, nsentences=32, sample_size=754.8, sample_size_v1=0, sample_size_v2=0, ppl=21.3, wps=381, ups=0.5, wpb=754.8, bsz=32, num_updates=8750, lr=4.04923e-05, gnorm=2.193, clip=100, loss_scale=256, train_wall=20, gb_free=15.3, wall=24059
2023-01-09 10:18:53 - progress_bar.py[line:272] - INFO: epoch 003:   1443 / 3665 loss=5.307, loss_v1=0, loss_v2=0, nll_loss=4.424, ntokens=1003.5, nsentences=32, sample_size=1003.5, sample_size_v1=0, sample_size_v2=0, ppl=21.47, wps=511, ups=0.51, wpb=1003.5, bsz=32, num_updates=8760, lr=4.04778e-05, gnorm=1.7, clip=100, loss_scale=256, train_wall=20, gb_free=15.4, wall=24079
2023-01-09 10:19:12 - progress_bar.py[line:272] - INFO: epoch 003:   1453 / 3665 loss=5.356, loss_v1=0, loss_v2=0, nll_loss=4.48, ntokens=990.4, nsentences=32, sample_size=990.4, sample_size_v1=0, sample_size_v2=0, ppl=22.31, wps=503, ups=0.51, wpb=990.4, bsz=32, num_updates=8770, lr=4.04633e-05, gnorm=1.752, clip=100, loss_scale=256, train_wall=20, gb_free=15.3, wall=24099
2023-01-09 10:19:32 - progress_bar.py[line:272] - INFO: epoch 003:   1463 / 3665 loss=5.192, loss_v1=0, loss_v2=0, nll_loss=4.295, ntokens=694.8, nsentences=31.8, sample_size=694.8, sample_size_v1=0, sample_size_v2=0, ppl=19.63, wps=357.3, ups=0.51, wpb=694.8, bsz=31.8, num_updates=8780, lr=4.04488e-05, gnorm=2.233, clip=100, loss_scale=256, train_wall=19, gb_free=15.4, wall=24118
2023-01-09 10:19:51 - progress_bar.py[line:272] - INFO: epoch 003:   1473 / 3665 loss=5.208, loss_v1=0, loss_v2=0, nll_loss=4.312, ntokens=835.8, nsentences=32, sample_size=835.8, sample_size_v1=0, sample_size_v2=0, ppl=19.87, wps=426.9, ups=0.51, wpb=835.8, bsz=32, num_updates=8790, lr=4.04342e-05, gnorm=2.023, clip=100, loss_scale=256, train_wall=20, gb_free=15.7, wall=24138
2023-01-09 10:20:11 - progress_bar.py[line:272] - INFO: epoch 003:   1483 / 3665 loss=5.419, loss_v1=0, loss_v2=0, nll_loss=4.548, ntokens=1067.4, nsentences=32, sample_size=1067.4, sample_size_v1=0, sample_size_v2=0, ppl=23.4, wps=541.8, ups=0.51, wpb=1067.4, bsz=32, num_updates=8800, lr=4.04197e-05, gnorm=1.702, clip=100, loss_scale=256, train_wall=20, gb_free=15.5, wall=24157
2023-01-09 10:20:31 - progress_bar.py[line:272] - INFO: epoch 003:   1493 / 3665 loss=5.345, loss_v1=0, loss_v2=0, nll_loss=4.47, ntokens=759, nsentences=32, sample_size=759, sample_size_v1=0, sample_size_v2=0, ppl=22.15, wps=386.4, ups=0.51, wpb=759, bsz=32, num_updates=8810, lr=4.04052e-05, gnorm=2.046, clip=100, loss_scale=256, train_wall=20, gb_free=15.5, wall=24177
2023-01-09 10:20:50 - progress_bar.py[line:272] - INFO: epoch 003:   1503 / 3665 loss=5.325, loss_v1=0, loss_v2=0, nll_loss=4.443, ntokens=937.4, nsentences=32, sample_size=937.4, sample_size_v1=0, sample_size_v2=0, ppl=21.75, wps=476.6, ups=0.51, wpb=937.4, bsz=32, num_updates=8820, lr=4.03907e-05, gnorm=1.859, clip=100, loss_scale=256, train_wall=20, gb_free=15.3, wall=24197
2023-01-09 10:21:10 - progress_bar.py[line:272] - INFO: epoch 003:   1513 / 3665 loss=5.28, loss_v1=0, loss_v2=0, nll_loss=4.393, ntokens=1007.2, nsentences=32, sample_size=1007.2, sample_size_v1=0, sample_size_v2=0, ppl=21.01, wps=510.7, ups=0.51, wpb=1007.2, bsz=32, num_updates=8830, lr=4.03762e-05, gnorm=1.574, clip=100, loss_scale=256, train_wall=20, gb_free=15.4, wall=24216
2023-01-09 10:21:30 - progress_bar.py[line:272] - INFO: epoch 003:   1523 / 3665 loss=5.391, loss_v1=0, loss_v2=0, nll_loss=4.516, ntokens=898.8, nsentences=32, sample_size=898.8, sample_size_v1=0, sample_size_v2=0, ppl=22.88, wps=457.2, ups=0.51, wpb=898.8, bsz=32, num_updates=8840, lr=4.03617e-05, gnorm=1.854, clip=100, loss_scale=256, train_wall=20, gb_free=15.6, wall=24236
2023-01-09 10:21:50 - progress_bar.py[line:272] - INFO: epoch 003:   1533 / 3665 loss=5.312, loss_v1=0, loss_v2=0, nll_loss=4.432, ntokens=861, nsentences=32, sample_size=861, sample_size_v1=0, sample_size_v2=0, ppl=21.59, wps=437.6, ups=0.51, wpb=861, bsz=32, num_updates=8850, lr=4.03472e-05, gnorm=1.952, clip=100, loss_scale=256, train_wall=20, gb_free=15.3, wall=24256
2023-01-09 10:22:09 - progress_bar.py[line:272] - INFO: epoch 003:   1543 / 3665 loss=5.26, loss_v1=0, loss_v2=0, nll_loss=4.373, ntokens=983.9, nsentences=32, sample_size=983.9, sample_size_v1=0, sample_size_v2=0, ppl=20.71, wps=499.1, ups=0.51, wpb=983.9, bsz=32, num_updates=8860, lr=4.03326e-05, gnorm=1.69, clip=100, loss_scale=256, train_wall=20, gb_free=15.6, wall=24275
2023-01-09 10:22:29 - progress_bar.py[line:272] - INFO: epoch 003:   1553 / 3665 loss=5.42, loss_v1=0, loss_v2=0, nll_loss=4.547, ntokens=956.3, nsentences=32, sample_size=956.3, sample_size_v1=0, sample_size_v2=0, ppl=23.38, wps=485.6, ups=0.51, wpb=956.3, bsz=32, num_updates=8870, lr=4.03181e-05, gnorm=1.861, clip=100, loss_scale=256, train_wall=20, gb_free=15, wall=24295
2023-01-09 10:22:49 - progress_bar.py[line:272] - INFO: epoch 003:   1563 / 3665 loss=5.365, loss_v1=0, loss_v2=0, nll_loss=4.489, ntokens=829.6, nsentences=32, sample_size=829.6, sample_size_v1=0, sample_size_v2=0, ppl=22.46, wps=420.9, ups=0.51, wpb=829.6, bsz=32, num_updates=8880, lr=4.03036e-05, gnorm=1.973, clip=100, loss_scale=256, train_wall=20, gb_free=15.4, wall=24315
2023-01-09 10:23:08 - progress_bar.py[line:272] - INFO: epoch 003:   1573 / 3665 loss=5.31, loss_v1=0, loss_v2=0, nll_loss=4.428, ntokens=1083, nsentences=32, sample_size=1083, sample_size_v1=0, sample_size_v2=0, ppl=21.52, wps=548.2, ups=0.51, wpb=1083, bsz=32, num_updates=8890, lr=4.02891e-05, gnorm=1.647, clip=100, loss_scale=256, train_wall=20, gb_free=15.4, wall=24335
2023-01-09 10:23:28 - progress_bar.py[line:272] - INFO: epoch 003:   1583 / 3665 loss=5.344, loss_v1=0, loss_v2=0, nll_loss=4.464, ntokens=902.1, nsentences=32, sample_size=902.1, sample_size_v1=0, sample_size_v2=0, ppl=22.06, wps=457.6, ups=0.51, wpb=902.1, bsz=32, num_updates=8900, lr=4.02746e-05, gnorm=1.855, clip=100, loss_scale=256, train_wall=20, gb_free=15.1, wall=24354
2023-01-09 10:23:48 - progress_bar.py[line:272] - INFO: epoch 003:   1593 / 3665 loss=5.322, loss_v1=0, loss_v2=0, nll_loss=4.442, ntokens=861.9, nsentences=32, sample_size=861.9, sample_size_v1=0, sample_size_v2=0, ppl=21.73, wps=437.8, ups=0.51, wpb=861.9, bsz=32, num_updates=8910, lr=4.02601e-05, gnorm=2.054, clip=100, loss_scale=256, train_wall=20, gb_free=15.5, wall=24374
2023-01-09 10:24:07 - progress_bar.py[line:272] - INFO: epoch 003:   1603 / 3665 loss=5.249, loss_v1=0, loss_v2=0, nll_loss=4.358, ntokens=977.4, nsentences=32, sample_size=977.4, sample_size_v1=0, sample_size_v2=0, ppl=20.51, wps=497, ups=0.51, wpb=977.4, bsz=32, num_updates=8920, lr=4.02456e-05, gnorm=1.85, clip=100, loss_scale=256, train_wall=20, gb_free=15.5, wall=24394
2023-01-09 10:24:27 - progress_bar.py[line:272] - INFO: epoch 003:   1613 / 3665 loss=5.338, loss_v1=0, loss_v2=0, nll_loss=4.455, ntokens=888.6, nsentences=32, sample_size=888.6, sample_size_v1=0, sample_size_v2=0, ppl=21.94, wps=450.2, ups=0.51, wpb=888.6, bsz=32, num_updates=8930, lr=4.02311e-05, gnorm=1.916, clip=90, loss_scale=256, train_wall=20, gb_free=15.4, wall=24413
2023-01-09 10:24:47 - progress_bar.py[line:272] - INFO: epoch 003:   1623 / 3665 loss=5.365, loss_v1=0, loss_v2=0, nll_loss=4.494, ntokens=900.8, nsentences=32, sample_size=900.8, sample_size_v1=0, sample_size_v2=0, ppl=22.53, wps=456.7, ups=0.51, wpb=900.8, bsz=32, num_updates=8940, lr=4.02165e-05, gnorm=1.986, clip=100, loss_scale=256, train_wall=20, gb_free=14.7, wall=24433
2023-01-09 10:25:07 - progress_bar.py[line:272] - INFO: epoch 003:   1633 / 3665 loss=5.245, loss_v1=0, loss_v2=0, nll_loss=4.355, ntokens=935.6, nsentences=32, sample_size=935.6, sample_size_v1=0, sample_size_v2=0, ppl=20.47, wps=474.8, ups=0.51, wpb=935.6, bsz=32, num_updates=8950, lr=4.0202e-05, gnorm=1.706, clip=100, loss_scale=256, train_wall=20, gb_free=15.2, wall=24453
2023-01-09 10:25:27 - progress_bar.py[line:272] - INFO: epoch 003:   1643 / 3665 loss=5.333, loss_v1=0, loss_v2=0, nll_loss=4.449, ntokens=1284.9, nsentences=32, sample_size=1284.9, sample_size_v1=0, sample_size_v2=0, ppl=21.85, wps=645.7, ups=0.5, wpb=1284.9, bsz=32, num_updates=8960, lr=4.01875e-05, gnorm=1.401, clip=100, loss_scale=256, train_wall=20, gb_free=15.3, wall=24473
2023-01-09 10:25:46 - progress_bar.py[line:272] - INFO: epoch 003:   1653 / 3665 loss=5.292, loss_v1=0, loss_v2=0, nll_loss=4.41, ntokens=908.4, nsentences=32, sample_size=908.4, sample_size_v1=0, sample_size_v2=0, ppl=21.26, wps=460.8, ups=0.51, wpb=908.4, bsz=32, num_updates=8970, lr=4.0173e-05, gnorm=1.92, clip=100, loss_scale=256, train_wall=20, gb_free=15.5, wall=24493
2023-01-09 10:26:06 - progress_bar.py[line:272] - INFO: epoch 003:   1663 / 3665 loss=5.275, loss_v1=0, loss_v2=0, nll_loss=4.388, ntokens=837.5, nsentences=32, sample_size=837.5, sample_size_v1=0, sample_size_v2=0, ppl=20.94, wps=427.6, ups=0.51, wpb=837.5, bsz=32, num_updates=8980, lr=4.01585e-05, gnorm=2.344, clip=100, loss_scale=256, train_wall=20, gb_free=15.5, wall=24512
2023-01-09 10:26:26 - progress_bar.py[line:272] - INFO: epoch 003:   1673 / 3665 loss=5.31, loss_v1=0, loss_v2=0, nll_loss=4.426, ntokens=952.9, nsentences=32, sample_size=952.9, sample_size_v1=0, sample_size_v2=0, ppl=21.5, wps=483.7, ups=0.51, wpb=952.9, bsz=32, num_updates=8990, lr=4.0144e-05, gnorm=1.764, clip=100, loss_scale=256, train_wall=20, gb_free=15.4, wall=24532
2023-01-09 10:26:45 - progress_bar.py[line:272] - INFO: epoch 003:   1683 / 3665 loss=5.347, loss_v1=0, loss_v2=0, nll_loss=4.465, ntokens=807, nsentences=32, sample_size=807, sample_size_v1=0, sample_size_v2=0, ppl=22.08, wps=410.2, ups=0.51, wpb=807, bsz=32, num_updates=9000, lr=4.01295e-05, gnorm=2.1, clip=100, loss_scale=256, train_wall=20, gb_free=15.1, wall=24551
2023-01-09 10:26:45 - train.py[line:445] - INFO: begin validation on "valid" subset
slice_id 0 seek offset 0
slice_id 0 seek offset 0
2023-01-09 10:31:22 - progress_bar.py[line:282] - INFO: epoch 003 | valid on 'valid' subset | loss 5.29 | loss_v1 0 | loss_v2 0 | nll_loss 4.388 | ntokens 117.113 | nsentences 4 | sample_size 117.113 | sample_size_v1 0 | sample_size_v2 0 | AP 0 | total positives 21.731 | TP 0 | FP 5.19952 | ppl 20.94 | wps 528.2 | wpb 117.1 | bsz 4 | num_updates 9000 | best_AP 0
2023-01-09 10:31:22 - checkpoint_utils.py[line:64] - INFO: Preparing to save checkpoint for epoch 3 @ 9000 updates
2023-01-09 10:31:22 - trainer.py[line:431] - INFO: Saving checkpoint to ../../checkpoints/OFA/detection_checkpoints/10_5e-5_512/checkpoint_3_9000.pt
2023-01-09 10:31:25 - trainer.py[line:441] - INFO: Finished saving checkpoint to ../../checkpoints/OFA/detection_checkpoints/10_5e-5_512/checkpoint_3_9000.pt
2023-01-09 10:32:17 - checkpoint_utils.py[line:133] - INFO: Saved checkpoint ../../checkpoints/OFA/detection_checkpoints/10_5e-5_512/checkpoint_3_9000.pt (epoch 3 @ 9000 updates, score 0.0) (writing took 55.30557708488777 seconds)
2023-01-09 10:32:37 - progress_bar.py[line:272] - INFO: epoch 003:   1693 / 3665 loss=5.334, loss_v1=0, loss_v2=0, nll_loss=4.454, ntokens=1054.5, nsentences=32, sample_size=1054.5, sample_size_v1=0, sample_size_v2=0, ppl=21.92, wps=30, ups=0.03, wpb=1054.5, bsz=32, num_updates=9010, lr=4.01149e-05, gnorm=1.669, clip=100, loss_scale=256, train_wall=19, gb_free=15.4, wall=24903
2023-01-09 10:32:56 - progress_bar.py[line:272] - INFO: epoch 003:   1703 / 3665 loss=5.26, loss_v1=0, loss_v2=0, nll_loss=4.372, ntokens=995.9, nsentences=32, sample_size=995.9, sample_size_v1=0, sample_size_v2=0, ppl=20.71, wps=511.5, ups=0.51, wpb=995.9, bsz=32, num_updates=9020, lr=4.01004e-05, gnorm=1.876, clip=100, loss_scale=256, train_wall=19, gb_free=14.5, wall=24923
2023-01-09 10:33:16 - progress_bar.py[line:272] - INFO: epoch 003:   1713 / 3665 loss=5.336, loss_v1=0, loss_v2=0, nll_loss=4.456, ntokens=727.5, nsentences=32, sample_size=727.5, sample_size_v1=0, sample_size_v2=0, ppl=21.94, wps=374, ups=0.51, wpb=727.5, bsz=32, num_updates=9030, lr=4.00859e-05, gnorm=2.112, clip=100, loss_scale=256, train_wall=19, gb_free=15.3, wall=24942
2023-01-09 10:33:35 - progress_bar.py[line:272] - INFO: epoch 003:   1723 / 3665 loss=5.282, loss_v1=0, loss_v2=0, nll_loss=4.399, ntokens=833.9, nsentences=32, sample_size=833.9, sample_size_v1=0, sample_size_v2=0, ppl=21.09, wps=427.6, ups=0.51, wpb=833.9, bsz=32, num_updates=9040, lr=4.00714e-05, gnorm=1.956, clip=100, loss_scale=256, train_wall=19, gb_free=15.4, wall=24962
2023-01-09 10:33:55 - progress_bar.py[line:272] - INFO: epoch 003:   1733 / 3665 loss=5.243, loss_v1=0, loss_v2=0, nll_loss=4.351, ntokens=988.2, nsentences=32, sample_size=988.2, sample_size_v1=0, sample_size_v2=0, ppl=20.41, wps=503.5, ups=0.51, wpb=988.2, bsz=32, num_updates=9050, lr=4.00569e-05, gnorm=1.795, clip=100, loss_scale=256, train_wall=20, gb_free=15.3, wall=24981
2023-01-09 10:34:14 - progress_bar.py[line:272] - INFO: epoch 003:   1743 / 3665 loss=5.351, loss_v1=0, loss_v2=0, nll_loss=4.472, ntokens=890.9, nsentences=32, sample_size=890.9, sample_size_v1=0, sample_size_v2=0, ppl=22.19, wps=455.8, ups=0.51, wpb=890.9, bsz=32, num_updates=9060, lr=4.00424e-05, gnorm=1.885, clip=100, loss_scale=256, train_wall=20, gb_free=15.6, wall=25001
2023-01-09 10:34:34 - progress_bar.py[line:272] - INFO: epoch 003:   1753 / 3665 loss=5.326, loss_v1=0, loss_v2=0, nll_loss=4.448, ntokens=866, nsentences=32, sample_size=866, sample_size_v1=0, sample_size_v2=0, ppl=21.83, wps=441.6, ups=0.51, wpb=866, bsz=32, num_updates=9070, lr=4.00279e-05, gnorm=1.975, clip=100, loss_scale=256, train_wall=20, gb_free=15.5, wall=25020
2023-01-09 10:34:54 - progress_bar.py[line:272] - INFO: epoch 003:   1763 / 3665 loss=5.241, loss_v1=0, loss_v2=0, nll_loss=4.351, ntokens=1057.3, nsentences=32, sample_size=1057.3, sample_size_v1=0, sample_size_v2=0, ppl=20.41, wps=537.4, ups=0.51, wpb=1057.3, bsz=32, num_updates=9080, lr=4.00134e-05, gnorm=1.754, clip=100, loss_scale=256, train_wall=20, gb_free=15.4, wall=25040
2023-01-09 10:35:13 - progress_bar.py[line:272] - INFO: epoch 003:   1773 / 3665 loss=5.439, loss_v1=0, loss_v2=0, nll_loss=4.568, ntokens=973.9, nsentences=32, sample_size=973.9, sample_size_v1=0, sample_size_v2=0, ppl=23.71, wps=494.7, ups=0.51, wpb=973.9, bsz=32, num_updates=9090, lr=3.99988e-05, gnorm=1.832, clip=100, loss_scale=512, train_wall=20, gb_free=15.5, wall=25060
2023-01-09 10:35:33 - progress_bar.py[line:272] - INFO: epoch 003:   1783 / 3665 loss=5.291, loss_v1=0, loss_v2=0, nll_loss=4.404, ntokens=818.2, nsentences=32, sample_size=818.2, sample_size_v1=0, sample_size_v2=0, ppl=21.18, wps=417.4, ups=0.51, wpb=818.2, bsz=32, num_updates=9100, lr=3.99843e-05, gnorm=1.886, clip=100, loss_scale=512, train_wall=20, gb_free=15.5, wall=25079
2023-01-09 10:35:53 - progress_bar.py[line:272] - INFO: epoch 003:   1793 / 3665 loss=5.234, loss_v1=0, loss_v2=0, nll_loss=4.345, ntokens=979.8, nsentences=32, sample_size=979.8, sample_size_v1=0, sample_size_v2=0, ppl=20.32, wps=498.4, ups=0.51, wpb=979.8, bsz=32, num_updates=9110, lr=3.99698e-05, gnorm=1.77, clip=100, loss_scale=512, train_wall=20, gb_free=15.4, wall=25099
2023-01-09 10:36:13 - progress_bar.py[line:272] - INFO: epoch 003:   1803 / 3665 loss=5.323, loss_v1=0, loss_v2=0, nll_loss=4.442, ntokens=879.9, nsentences=32, sample_size=879.9, sample_size_v1=0, sample_size_v2=0, ppl=21.74, wps=440.3, ups=0.5, wpb=879.9, bsz=32, num_updates=9120, lr=3.99553e-05, gnorm=1.83, clip=100, loss_scale=512, train_wall=20, gb_free=15.5, wall=25119
2023-01-09 10:36:33 - progress_bar.py[line:272] - INFO: epoch 003:   1813 / 3665 loss=5.278, loss_v1=0, loss_v2=0, nll_loss=4.389, ntokens=789.9, nsentences=32, sample_size=789.9, sample_size_v1=0, sample_size_v2=0, ppl=20.96, wps=384.6, ups=0.49, wpb=789.9, bsz=32, num_updates=9130, lr=3.99408e-05, gnorm=2.308, clip=100, loss_scale=512, train_wall=21, gb_free=15.6, wall=25139
2023-01-09 10:36:54 - progress_bar.py[line:272] - INFO: epoch 003:   1823 / 3665 loss=5.203, loss_v1=0, loss_v2=0, nll_loss=4.307, ntokens=986.6, nsentences=32, sample_size=986.6, sample_size_v1=0, sample_size_v2=0, ppl=19.79, wps=482.8, ups=0.49, wpb=986.6, bsz=32, num_updates=9140, lr=3.99263e-05, gnorm=1.678, clip=100, loss_scale=512, train_wall=20, gb_free=15.2, wall=25160
2023-01-09 10:37:13 - progress_bar.py[line:272] - INFO: epoch 003:   1833 / 3665 loss=5.381, loss_v1=0, loss_v2=0, nll_loss=4.508, ntokens=1045.7, nsentences=32, sample_size=1045.7, sample_size_v1=0, sample_size_v2=0, ppl=22.76, wps=531.1, ups=0.51, wpb=1045.7, bsz=32, num_updates=9150, lr=3.99118e-05, gnorm=1.747, clip=100, loss_scale=512, train_wall=20, gb_free=15.5, wall=25180
2023-01-09 10:37:33 - progress_bar.py[line:272] - INFO: epoch 003:   1843 / 3665 loss=5.3, loss_v1=0, loss_v2=0, nll_loss=4.418, ntokens=713, nsentences=32, sample_size=713, sample_size_v1=0, sample_size_v2=0, ppl=21.38, wps=368, ups=0.52, wpb=713, bsz=32, num_updates=9160, lr=3.98972e-05, gnorm=2.239, clip=100, loss_scale=512, train_wall=19, gb_free=15.7, wall=25199
2023-01-09 10:37:52 - progress_bar.py[line:272] - INFO: epoch 003:   1853 / 3665 loss=5.277, loss_v1=0, loss_v2=0, nll_loss=4.39, ntokens=909.2, nsentences=32, sample_size=909.2, sample_size_v1=0, sample_size_v2=0, ppl=20.97, wps=466.1, ups=0.51, wpb=909.2, bsz=32, num_updates=9170, lr=3.98827e-05, gnorm=1.759, clip=100, loss_scale=512, train_wall=19, gb_free=15.1, wall=25218
2023-01-09 10:38:12 - progress_bar.py[line:272] - INFO: epoch 003:   1863 / 3665 loss=5.25, loss_v1=0, loss_v2=0, nll_loss=4.36, ntokens=966.8, nsentences=32, sample_size=966.8, sample_size_v1=0, sample_size_v2=0, ppl=20.54, wps=494.7, ups=0.51, wpb=966.8, bsz=32, num_updates=9180, lr=3.98682e-05, gnorm=1.783, clip=100, loss_scale=512, train_wall=20, gb_free=15.5, wall=25238
2023-01-09 10:38:31 - progress_bar.py[line:272] - INFO: epoch 003:   1873 / 3665 loss=5.346, loss_v1=0, loss_v2=0, nll_loss=4.466, ntokens=858.1, nsentences=32, sample_size=858.1, sample_size_v1=0, sample_size_v2=0, ppl=22.1, wps=437.7, ups=0.51, wpb=858.1, bsz=32, num_updates=9190, lr=3.98537e-05, gnorm=1.881, clip=100, loss_scale=512, train_wall=20, gb_free=15.3, wall=25258
2023-01-09 10:38:51 - progress_bar.py[line:272] - INFO: epoch 003:   1883 / 3665 loss=5.315, loss_v1=0, loss_v2=0, nll_loss=4.434, ntokens=1011.3, nsentences=32, sample_size=1011.3, sample_size_v1=0, sample_size_v2=0, ppl=21.62, wps=514, ups=0.51, wpb=1011.3, bsz=32, num_updates=9200, lr=3.98392e-05, gnorm=1.682, clip=100, loss_scale=512, train_wall=20, gb_free=15.5, wall=25277
2023-01-09 10:39:11 - progress_bar.py[line:272] - INFO: epoch 003:   1893 / 3665 loss=5.278, loss_v1=0, loss_v2=0, nll_loss=4.391, ntokens=1102.6, nsentences=32, sample_size=1102.6, sample_size_v1=0, sample_size_v2=0, ppl=20.97, wps=556.3, ups=0.5, wpb=1102.6, bsz=32, num_updates=9210, lr=3.98247e-05, gnorm=1.64, clip=100, loss_scale=512, train_wall=20, gb_free=15.6, wall=25297
2023-01-09 10:39:31 - progress_bar.py[line:272] - INFO: epoch 003:   1903 / 3665 loss=5.391, loss_v1=0, loss_v2=0, nll_loss=4.519, ntokens=797, nsentences=32, sample_size=797, sample_size_v1=0, sample_size_v2=0, ppl=22.93, wps=404.7, ups=0.51, wpb=797, bsz=32, num_updates=9220, lr=3.98102e-05, gnorm=2.038, clip=100, loss_scale=512, train_wall=20, gb_free=15.6, wall=25317
2023-01-09 10:39:50 - progress_bar.py[line:272] - INFO: epoch 003:   1913 / 3665 loss=5.3, loss_v1=0, loss_v2=0, nll_loss=4.416, ntokens=840, nsentences=32, sample_size=840, sample_size_v1=0, sample_size_v2=0, ppl=21.34, wps=422.5, ups=0.5, wpb=840, bsz=32, num_updates=9230, lr=3.97957e-05, gnorm=1.899, clip=100, loss_scale=512, train_wall=20, gb_free=15.5, wall=25337
2023-01-09 10:40:10 - progress_bar.py[line:272] - INFO: epoch 003:   1923 / 3665 loss=5.252, loss_v1=0, loss_v2=0, nll_loss=4.364, ntokens=898.2, nsentences=32, sample_size=898.2, sample_size_v1=0, sample_size_v2=0, ppl=20.59, wps=456.5, ups=0.51, wpb=898.2, bsz=32, num_updates=9240, lr=3.97811e-05, gnorm=1.896, clip=100, loss_scale=512, train_wall=20, gb_free=15.3, wall=25356
2023-01-09 10:40:30 - progress_bar.py[line:272] - INFO: epoch 003:   1933 / 3665 loss=5.402, loss_v1=0, loss_v2=0, nll_loss=4.529, ntokens=972, nsentences=32, sample_size=972, sample_size_v1=0, sample_size_v2=0, ppl=23.09, wps=491.8, ups=0.51, wpb=972, bsz=32, num_updates=9250, lr=3.97666e-05, gnorm=1.905, clip=100, loss_scale=512, train_wall=20, gb_free=15.5, wall=25376
2023-01-09 10:40:50 - progress_bar.py[line:272] - INFO: epoch 003:   1943 / 3665 loss=5.288, loss_v1=0, loss_v2=0, nll_loss=4.401, ntokens=728.2, nsentences=32, sample_size=728.2, sample_size_v1=0, sample_size_v2=0, ppl=21.12, wps=370.2, ups=0.51, wpb=728.2, bsz=32, num_updates=9260, lr=3.97521e-05, gnorm=2.276, clip=100, loss_scale=512, train_wall=20, gb_free=15.5, wall=25396
2023-01-09 10:41:09 - progress_bar.py[line:272] - INFO: epoch 003:   1953 / 3665 loss=5.231, loss_v1=0, loss_v2=0, nll_loss=4.342, ntokens=973.6, nsentences=32, sample_size=973.6, sample_size_v1=0, sample_size_v2=0, ppl=20.28, wps=493, ups=0.51, wpb=973.6, bsz=32, num_updates=9270, lr=3.97376e-05, gnorm=1.79, clip=100, loss_scale=512, train_wall=20, gb_free=15.2, wall=25416
2023-01-09 10:41:29 - progress_bar.py[line:272] - INFO: epoch 003:   1963 / 3665 loss=5.394, loss_v1=0, loss_v2=0, nll_loss=4.518, ntokens=1073.4, nsentences=32, sample_size=1073.4, sample_size_v1=0, sample_size_v2=0, ppl=22.91, wps=541.6, ups=0.5, wpb=1073.4, bsz=32, num_updates=9280, lr=3.97231e-05, gnorm=1.722, clip=100, loss_scale=512, train_wall=20, gb_free=15.4, wall=25435
2023-01-09 10:41:49 - progress_bar.py[line:272] - INFO: epoch 003:   1973 / 3665 loss=5.362, loss_v1=0, loss_v2=0, nll_loss=4.488, ntokens=934.9, nsentences=32, sample_size=934.9, sample_size_v1=0, sample_size_v2=0, ppl=22.44, wps=473.2, ups=0.51, wpb=934.9, bsz=32, num_updates=9290, lr=3.97086e-05, gnorm=1.811, clip=100, loss_scale=512, train_wall=20, gb_free=15.1, wall=25455
2023-01-09 10:42:09 - progress_bar.py[line:272] - INFO: epoch 003:   1983 / 3665 loss=5.226, loss_v1=0, loss_v2=0, nll_loss=4.333, ntokens=966.2, nsentences=32, sample_size=966.2, sample_size_v1=0, sample_size_v2=0, ppl=20.15, wps=490, ups=0.51, wpb=966.2, bsz=32, num_updates=9300, lr=3.96941e-05, gnorm=1.798, clip=100, loss_scale=512, train_wall=20, gb_free=15, wall=25475
2023-01-09 10:42:28 - progress_bar.py[line:272] - INFO: epoch 003:   1993 / 3665 loss=5.361, loss_v1=0, loss_v2=0, nll_loss=4.483, ntokens=1030.9, nsentences=32, sample_size=1030.9, sample_size_v1=0, sample_size_v2=0, ppl=22.36, wps=521.9, ups=0.51, wpb=1030.9, bsz=32, num_updates=9310, lr=3.96795e-05, gnorm=1.823, clip=100, loss_scale=512, train_wall=20, gb_free=15.4, wall=25495
2023-01-09 10:42:48 - progress_bar.py[line:272] - INFO: epoch 003:   2003 / 3665 loss=5.312, loss_v1=0, loss_v2=0, nll_loss=4.43, ntokens=792, nsentences=32, sample_size=792, sample_size_v1=0, sample_size_v2=0, ppl=21.56, wps=401.8, ups=0.51, wpb=792, bsz=32, num_updates=9320, lr=3.9665e-05, gnorm=2.153, clip=100, loss_scale=512, train_wall=20, gb_free=15.5, wall=25514
2023-01-09 10:43:08 - progress_bar.py[line:272] - INFO: epoch 003:   2013 / 3665 loss=5.253, loss_v1=0, loss_v2=0, nll_loss=4.366, ntokens=940.1, nsentences=32, sample_size=940.1, sample_size_v1=0, sample_size_v2=0, ppl=20.62, wps=477, ups=0.51, wpb=940.1, bsz=32, num_updates=9330, lr=3.96505e-05, gnorm=1.667, clip=100, loss_scale=512, train_wall=20, gb_free=15.4, wall=25534
2023-01-09 10:43:28 - progress_bar.py[line:272] - INFO: epoch 003:   2023 / 3665 loss=5.421, loss_v1=0, loss_v2=0, nll_loss=4.552, ntokens=1077.6, nsentences=32, sample_size=1077.6, sample_size_v1=0, sample_size_v2=0, ppl=23.45, wps=544.1, ups=0.5, wpb=1077.6, bsz=32, num_updates=9340, lr=3.9636e-05, gnorm=1.635, clip=100, loss_scale=512, train_wall=20, gb_free=15.5, wall=25554
2023-01-09 10:43:47 - progress_bar.py[line:272] - INFO: epoch 003:   2033 / 3665 loss=5.3, loss_v1=0, loss_v2=0, nll_loss=4.414, ntokens=787.1, nsentences=32, sample_size=787.1, sample_size_v1=0, sample_size_v2=0, ppl=21.32, wps=400.3, ups=0.51, wpb=787.1, bsz=32, num_updates=9350, lr=3.96215e-05, gnorm=2.016, clip=100, loss_scale=512, train_wall=20, gb_free=15.5, wall=25574
2023-01-09 10:44:07 - progress_bar.py[line:272] - INFO: epoch 003:   2043 / 3665 loss=5.231, loss_v1=0, loss_v2=0, nll_loss=4.34, ntokens=847.4, nsentences=32, sample_size=847.4, sample_size_v1=0, sample_size_v2=0, ppl=20.26, wps=430.3, ups=0.51, wpb=847.4, bsz=32, num_updates=9360, lr=3.9607e-05, gnorm=1.864, clip=100, loss_scale=512, train_wall=20, gb_free=15.4, wall=25593
2023-01-09 10:44:27 - progress_bar.py[line:272] - INFO: epoch 003:   2053 / 3665 loss=5.297, loss_v1=0, loss_v2=0, nll_loss=4.414, ntokens=1005.4, nsentences=32, sample_size=1005.4, sample_size_v1=0, sample_size_v2=0, ppl=21.32, wps=509, ups=0.51, wpb=1005.4, bsz=32, num_updates=9370, lr=3.95925e-05, gnorm=1.678, clip=100, loss_scale=512, train_wall=20, gb_free=15, wall=25613
2023-01-09 10:44:46 - progress_bar.py[line:272] - INFO: epoch 003:   2063 / 3665 loss=5.288, loss_v1=0, loss_v2=0, nll_loss=4.402, ntokens=772.4, nsentences=32, sample_size=772.4, sample_size_v1=0, sample_size_v2=0, ppl=21.13, wps=392.4, ups=0.51, wpb=772.4, bsz=32, num_updates=9380, lr=3.9578e-05, gnorm=2.125, clip=100, loss_scale=512, train_wall=20, gb_free=15.3, wall=25633
2023-01-09 10:45:02 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 256.0
2023-01-09 10:45:08 - progress_bar.py[line:272] - INFO: epoch 003:   2074 / 3665 loss=5.21, loss_v1=0, loss_v2=0, nll_loss=4.314, ntokens=879.8, nsentences=32, sample_size=879.8, sample_size_v1=0, sample_size_v2=0, ppl=19.89, wps=405.8, ups=0.46, wpb=879.8, bsz=32, num_updates=9390, lr=3.95634e-05, gnorm=1.785, clip=100, loss_scale=256, train_wall=22, gb_free=15.6, wall=25654
2023-01-09 10:45:28 - progress_bar.py[line:272] - INFO: epoch 003:   2084 / 3665 loss=5.389, loss_v1=0, loss_v2=0, nll_loss=4.516, ntokens=1141.9, nsentences=32, sample_size=1141.9, sample_size_v1=0, sample_size_v2=0, ppl=22.87, wps=574.8, ups=0.5, wpb=1141.9, bsz=32, num_updates=9400, lr=3.95489e-05, gnorm=1.643, clip=100, loss_scale=256, train_wall=20, gb_free=15.2, wall=25674
2023-01-09 10:45:48 - progress_bar.py[line:272] - INFO: epoch 003:   2094 / 3665 loss=5.348, loss_v1=0, loss_v2=0, nll_loss=4.469, ntokens=756.4, nsentences=32, sample_size=756.4, sample_size_v1=0, sample_size_v2=0, ppl=22.14, wps=383.8, ups=0.51, wpb=756.4, bsz=32, num_updates=9410, lr=3.95344e-05, gnorm=2.161, clip=100, loss_scale=256, train_wall=20, gb_free=15.1, wall=25694
2023-01-09 10:46:07 - progress_bar.py[line:272] - INFO: epoch 003:   2104 / 3665 loss=5.237, loss_v1=0, loss_v2=0, nll_loss=4.345, ntokens=1006.8, nsentences=32, sample_size=1006.8, sample_size_v1=0, sample_size_v2=0, ppl=20.33, wps=510, ups=0.51, wpb=1006.8, bsz=32, num_updates=9420, lr=3.95199e-05, gnorm=1.711, clip=100, loss_scale=256, train_wall=20, gb_free=15.4, wall=25714
2023-01-09 10:46:27 - progress_bar.py[line:272] - INFO: epoch 003:   2114 / 3665 loss=5.216, loss_v1=0, loss_v2=0, nll_loss=4.323, ntokens=929, nsentences=32, sample_size=929, sample_size_v1=0, sample_size_v2=0, ppl=20.02, wps=471.3, ups=0.51, wpb=929, bsz=32, num_updates=9430, lr=3.95054e-05, gnorm=1.74, clip=100, loss_scale=256, train_wall=20, gb_free=15.5, wall=25733
2023-01-09 10:46:47 - progress_bar.py[line:272] - INFO: epoch 003:   2124 / 3665 loss=5.362, loss_v1=0, loss_v2=0, nll_loss=4.483, ntokens=964.9, nsentences=32, sample_size=964.9, sample_size_v1=0, sample_size_v2=0, ppl=22.37, wps=487.1, ups=0.5, wpb=964.9, bsz=32, num_updates=9440, lr=3.94909e-05, gnorm=1.868, clip=100, loss_scale=256, train_wall=20, gb_free=15.4, wall=25753
2023-01-09 10:47:07 - progress_bar.py[line:272] - INFO: epoch 003:   2134 / 3665 loss=5.252, loss_v1=0, loss_v2=0, nll_loss=4.361, ntokens=879, nsentences=32, sample_size=879, sample_size_v1=0, sample_size_v2=0, ppl=20.55, wps=445.5, ups=0.51, wpb=879, bsz=32, num_updates=9450, lr=3.94764e-05, gnorm=1.847, clip=100, loss_scale=256, train_wall=20, gb_free=15.4, wall=25773
2023-01-09 10:47:26 - progress_bar.py[line:272] - INFO: epoch 003:   2144 / 3665 loss=5.193, loss_v1=0, loss_v2=0, nll_loss=4.299, ntokens=1001.6, nsentences=32, sample_size=1001.6, sample_size_v1=0, sample_size_v2=0, ppl=19.68, wps=507.1, ups=0.51, wpb=1001.6, bsz=32, num_updates=9460, lr=3.94618e-05, gnorm=1.614, clip=100, loss_scale=256, train_wall=20, gb_free=15.5, wall=25793
2023-01-09 10:47:46 - progress_bar.py[line:272] - INFO: epoch 003:   2154 / 3665 loss=5.342, loss_v1=0, loss_v2=0, nll_loss=4.461, ntokens=945.6, nsentences=32, sample_size=945.6, sample_size_v1=0, sample_size_v2=0, ppl=22.03, wps=478.3, ups=0.51, wpb=945.6, bsz=32, num_updates=9470, lr=3.94473e-05, gnorm=1.776, clip=100, loss_scale=256, train_wall=20, gb_free=15.3, wall=25812
2023-01-09 10:48:06 - progress_bar.py[line:272] - INFO: epoch 003:   2164 / 3665 loss=5.319, loss_v1=0, loss_v2=0, nll_loss=4.439, ntokens=901.1, nsentences=32, sample_size=901.1, sample_size_v1=0, sample_size_v2=0, ppl=21.69, wps=456.1, ups=0.51, wpb=901.1, bsz=32, num_updates=9480, lr=3.94328e-05, gnorm=1.978, clip=100, loss_scale=256, train_wall=20, gb_free=15.5, wall=25832
2023-01-09 10:48:26 - progress_bar.py[line:272] - INFO: epoch 003:   2174 / 3665 loss=5.244, loss_v1=0, loss_v2=0, nll_loss=4.354, ntokens=892, nsentences=32, sample_size=892, sample_size_v1=0, sample_size_v2=0, ppl=20.45, wps=453.8, ups=0.51, wpb=892, bsz=32, num_updates=9490, lr=3.94183e-05, gnorm=1.813, clip=100, loss_scale=256, train_wall=20, gb_free=15.3, wall=25852
2023-01-09 10:48:45 - progress_bar.py[line:272] - INFO: epoch 003:   2184 / 3665 loss=5.3, loss_v1=0, loss_v2=0, nll_loss=4.415, ntokens=948.3, nsentences=32, sample_size=948.3, sample_size_v1=0, sample_size_v2=0, ppl=21.34, wps=479.8, ups=0.51, wpb=948.3, bsz=32, num_updates=9500, lr=3.94038e-05, gnorm=1.762, clip=100, loss_scale=256, train_wall=20, gb_free=15.4, wall=25872
2023-01-09 10:48:45 - train.py[line:445] - INFO: begin validation on "valid" subset
slice_id 0 seek offset 0
slice_id 0 seek offset 0
2023-01-09 10:53:30 - progress_bar.py[line:282] - INFO: epoch 003 | valid on 'valid' subset | loss 5.283 | loss_v1 0 | loss_v2 0 | nll_loss 4.381 | ntokens 117.282 | nsentences 4 | sample_size 117.282 | sample_size_v1 0 | sample_size_v2 0 | AP 0 | total positives 21.769 | TP 0 | FP 5.94588 | ppl 20.83 | wps 514.6 | wpb 117.3 | bsz 4 | num_updates 9500 | best_AP 0
2023-01-09 10:53:30 - checkpoint_utils.py[line:64] - INFO: Preparing to save checkpoint for epoch 3 @ 9500 updates
2023-01-09 10:53:30 - trainer.py[line:431] - INFO: Saving checkpoint to ../../checkpoints/OFA/detection_checkpoints/10_5e-5_512/checkpoint_3_9500.pt
2023-01-09 10:53:33 - trainer.py[line:441] - INFO: Finished saving checkpoint to ../../checkpoints/OFA/detection_checkpoints/10_5e-5_512/checkpoint_3_9500.pt
2023-01-09 10:54:17 - checkpoint_utils.py[line:133] - INFO: Saved checkpoint ../../checkpoints/OFA/detection_checkpoints/10_5e-5_512/checkpoint_3_9500.pt (epoch 3 @ 9500 updates, score 0.0) (writing took 46.86874318681657 seconds)
2023-01-09 10:54:37 - progress_bar.py[line:272] - INFO: epoch 003:   2194 / 3665 loss=5.367, loss_v1=0, loss_v2=0, nll_loss=4.493, ntokens=945.4, nsentences=32, sample_size=945.4, sample_size_v1=0, sample_size_v2=0, ppl=22.52, wps=26.9, ups=0.03, wpb=945.4, bsz=32, num_updates=9510, lr=3.93893e-05, gnorm=1.923, clip=100, loss_scale=256, train_wall=19, gb_free=15.5, wall=26223
2023-01-09 10:54:56 - progress_bar.py[line:272] - INFO: epoch 003:   2204 / 3665 loss=5.272, loss_v1=0, loss_v2=0, nll_loss=4.385, ntokens=985.6, nsentences=32, sample_size=985.6, sample_size_v1=0, sample_size_v2=0, ppl=20.89, wps=505.5, ups=0.51, wpb=985.6, bsz=32, num_updates=9520, lr=3.93748e-05, gnorm=1.678, clip=100, loss_scale=256, train_wall=19, gb_free=15.4, wall=26242
2023-01-09 10:55:16 - progress_bar.py[line:272] - INFO: epoch 003:   2214 / 3665 loss=5.425, loss_v1=0, loss_v2=0, nll_loss=4.554, ntokens=1051.3, nsentences=32, sample_size=1051.3, sample_size_v1=0, sample_size_v2=0, ppl=23.48, wps=534.9, ups=0.51, wpb=1051.3, bsz=32, num_updates=9530, lr=3.93603e-05, gnorm=1.674, clip=100, loss_scale=256, train_wall=20, gb_free=15.4, wall=26262
2023-01-09 10:55:35 - progress_bar.py[line:272] - INFO: epoch 003:   2224 / 3665 loss=5.254, loss_v1=0, loss_v2=0, nll_loss=4.366, ntokens=837.5, nsentences=32, sample_size=837.5, sample_size_v1=0, sample_size_v2=0, ppl=20.63, wps=426.9, ups=0.51, wpb=837.5, bsz=32, num_updates=9540, lr=3.93457e-05, gnorm=1.826, clip=100, loss_scale=256, train_wall=20, gb_free=14.7, wall=26282
2023-01-09 10:55:55 - progress_bar.py[line:272] - INFO: epoch 003:   2234 / 3665 loss=5.197, loss_v1=0, loss_v2=0, nll_loss=4.301, ntokens=903.5, nsentences=32, sample_size=903.5, sample_size_v1=0, sample_size_v2=0, ppl=19.72, wps=462, ups=0.51, wpb=903.5, bsz=32, num_updates=9550, lr=3.93312e-05, gnorm=1.881, clip=100, loss_scale=256, train_wall=20, gb_free=15.6, wall=26301
2023-01-09 10:56:14 - progress_bar.py[line:272] - INFO: epoch 003:   2244 / 3665 loss=5.29, loss_v1=0, loss_v2=0, nll_loss=4.406, ntokens=859.2, nsentences=32, sample_size=859.2, sample_size_v1=0, sample_size_v2=0, ppl=21.2, wps=439.5, ups=0.51, wpb=859.2, bsz=32, num_updates=9560, lr=3.93167e-05, gnorm=1.907, clip=100, loss_scale=256, train_wall=20, gb_free=15.4, wall=26321
2023-01-09 10:56:34 - progress_bar.py[line:272] - INFO: epoch 003:   2254 / 3665 loss=5.328, loss_v1=0, loss_v2=0, nll_loss=4.447, ntokens=877.2, nsentences=32, sample_size=877.2, sample_size_v1=0, sample_size_v2=0, ppl=21.81, wps=447.1, ups=0.51, wpb=877.2, bsz=32, num_updates=9570, lr=3.93022e-05, gnorm=1.923, clip=100, loss_scale=256, train_wall=20, gb_free=15.6, wall=26340
2023-01-09 10:56:54 - progress_bar.py[line:272] - INFO: epoch 003:   2264 / 3665 loss=5.264, loss_v1=0, loss_v2=0, nll_loss=4.375, ntokens=955.7, nsentences=32, sample_size=955.7, sample_size_v1=0, sample_size_v2=0, ppl=20.75, wps=486.2, ups=0.51, wpb=955.7, bsz=32, num_updates=9580, lr=3.92877e-05, gnorm=1.856, clip=100, loss_scale=256, train_wall=20, gb_free=15.5, wall=26360
2023-01-09 10:57:14 - progress_bar.py[line:272] - INFO: epoch 003:   2274 / 3665 loss=5.252, loss_v1=0, loss_v2=0, nll_loss=4.364, ntokens=1095.1, nsentences=32, sample_size=1095.1, sample_size_v1=0, sample_size_v2=0, ppl=20.6, wps=554.4, ups=0.51, wpb=1095.1, bsz=32, num_updates=9590, lr=3.92732e-05, gnorm=1.58, clip=100, loss_scale=256, train_wall=20, gb_free=14.3, wall=26380
2023-01-09 10:57:33 - progress_bar.py[line:272] - INFO: epoch 003:   2284 / 3665 loss=5.304, loss_v1=0, loss_v2=0, nll_loss=4.418, ntokens=790.4, nsentences=32, sample_size=790.4, sample_size_v1=0, sample_size_v2=0, ppl=21.38, wps=403, ups=0.51, wpb=790.4, bsz=32, num_updates=9600, lr=3.92587e-05, gnorm=1.991, clip=100, loss_scale=256, train_wall=20, gb_free=15.4, wall=26399
2023-01-09 10:57:53 - progress_bar.py[line:272] - INFO: epoch 003:   2294 / 3665 loss=5.325, loss_v1=0, loss_v2=0, nll_loss=4.443, ntokens=1013.2, nsentences=32, sample_size=1013.2, sample_size_v1=0, sample_size_v2=0, ppl=21.75, wps=513.3, ups=0.51, wpb=1013.2, bsz=32, num_updates=9610, lr=3.92441e-05, gnorm=1.65, clip=100, loss_scale=256, train_wall=20, gb_free=15.3, wall=26419
2023-01-09 10:58:13 - progress_bar.py[line:272] - INFO: epoch 003:   2304 / 3665 loss=5.204, loss_v1=0, loss_v2=0, nll_loss=4.31, ntokens=881.1, nsentences=32, sample_size=881.1, sample_size_v1=0, sample_size_v2=0, ppl=19.84, wps=438.7, ups=0.5, wpb=881.1, bsz=32, num_updates=9620, lr=3.92296e-05, gnorm=1.867, clip=100, loss_scale=256, train_wall=20, gb_free=15.5, wall=26439
2023-01-09 10:58:33 - progress_bar.py[line:272] - INFO: epoch 003:   2314 / 3665 loss=5.334, loss_v1=0, loss_v2=0, nll_loss=4.454, ntokens=904.2, nsentences=32, sample_size=904.2, sample_size_v1=0, sample_size_v2=0, ppl=21.91, wps=446.6, ups=0.49, wpb=904.2, bsz=32, num_updates=9630, lr=3.92151e-05, gnorm=1.832, clip=100, loss_scale=256, train_wall=20, gb_free=15.5, wall=26459
2023-01-09 10:58:53 - progress_bar.py[line:272] - INFO: epoch 003:   2324 / 3665 loss=5.255, loss_v1=0, loss_v2=0, nll_loss=4.365, ntokens=830.1, nsentences=32, sample_size=830.1, sample_size_v1=0, sample_size_v2=0, ppl=20.61, wps=412.2, ups=0.5, wpb=830.1, bsz=32, num_updates=9640, lr=3.92006e-05, gnorm=2.133, clip=100, loss_scale=256, train_wall=20, gb_free=15.5, wall=26480
2023-01-09 10:59:13 - progress_bar.py[line:272] - INFO: epoch 003:   2334 / 3665 loss=5.311, loss_v1=0, loss_v2=0, nll_loss=4.429, ntokens=1091, nsentences=32, sample_size=1091, sample_size_v1=0, sample_size_v2=0, ppl=21.54, wps=546.4, ups=0.5, wpb=1091, bsz=32, num_updates=9650, lr=3.91861e-05, gnorm=1.561, clip=100, loss_scale=256, train_wall=20, gb_free=15.4, wall=26500
2023-01-09 10:59:33 - progress_bar.py[line:272] - INFO: epoch 003:   2344 / 3665 loss=5.358, loss_v1=0, loss_v2=0, nll_loss=4.481, ntokens=1087.3, nsentences=32, sample_size=1087.3, sample_size_v1=0, sample_size_v2=0, ppl=22.33, wps=547.6, ups=0.5, wpb=1087.3, bsz=32, num_updates=9660, lr=3.91716e-05, gnorm=1.606, clip=100, loss_scale=256, train_wall=20, gb_free=15.4, wall=26519
2023-01-09 10:59:53 - progress_bar.py[line:272] - INFO: epoch 003:   2354 / 3665 loss=5.37, loss_v1=0, loss_v2=0, nll_loss=4.495, ntokens=1057.1, nsentences=32, sample_size=1057.1, sample_size_v1=0, sample_size_v2=0, ppl=22.55, wps=534, ups=0.51, wpb=1057.1, bsz=32, num_updates=9670, lr=3.91571e-05, gnorm=1.792, clip=100, loss_scale=256, train_wall=20, gb_free=15.2, wall=26539
2023-01-09 11:00:13 - progress_bar.py[line:272] - INFO: epoch 003:   2364 / 3665 loss=5.13, loss_v1=0, loss_v2=0, nll_loss=4.223, ntokens=903.9, nsentences=32, sample_size=903.9, sample_size_v1=0, sample_size_v2=0, ppl=18.68, wps=454.5, ups=0.5, wpb=903.9, bsz=32, num_updates=9680, lr=3.91426e-05, gnorm=1.843, clip=100, loss_scale=256, train_wall=20, gb_free=15.4, wall=26559
2023-01-09 11:00:33 - progress_bar.py[line:272] - INFO: epoch 003:   2374 / 3665 loss=5.312, loss_v1=0, loss_v2=0, nll_loss=4.428, ntokens=947, nsentences=32, sample_size=947, sample_size_v1=0, sample_size_v2=0, ppl=21.53, wps=479.6, ups=0.51, wpb=947, bsz=32, num_updates=9690, lr=3.9128e-05, gnorm=1.951, clip=100, loss_scale=256, train_wall=20, gb_free=15.4, wall=26579
2023-01-09 11:00:52 - progress_bar.py[line:272] - INFO: epoch 003:   2384 / 3665 loss=5.302, loss_v1=0, loss_v2=0, nll_loss=4.419, ntokens=747.9, nsentences=32, sample_size=747.9, sample_size_v1=0, sample_size_v2=0, ppl=21.39, wps=380.8, ups=0.51, wpb=747.9, bsz=32, num_updates=9700, lr=3.91135e-05, gnorm=2.33, clip=100, loss_scale=256, train_wall=20, gb_free=15.6, wall=26599
2023-01-09 11:01:12 - progress_bar.py[line:272] - INFO: epoch 003:   2394 / 3665 loss=5.276, loss_v1=0, loss_v2=0, nll_loss=4.389, ntokens=984.2, nsentences=32, sample_size=984.2, sample_size_v1=0, sample_size_v2=0, ppl=20.95, wps=499.9, ups=0.51, wpb=984.2, bsz=32, num_updates=9710, lr=3.9099e-05, gnorm=1.666, clip=100, loss_scale=256, train_wall=20, gb_free=15.5, wall=26618
2023-01-09 11:01:32 - progress_bar.py[line:272] - INFO: epoch 003:   2404 / 3665 loss=5.27, loss_v1=0, loss_v2=0, nll_loss=4.385, ntokens=979.6, nsentences=32, sample_size=979.6, sample_size_v1=0, sample_size_v2=0, ppl=20.89, wps=496.8, ups=0.51, wpb=979.6, bsz=32, num_updates=9720, lr=3.90845e-05, gnorm=1.673, clip=100, loss_scale=256, train_wall=20, gb_free=15.5, wall=26638
2023-01-09 11:01:51 - progress_bar.py[line:272] - INFO: epoch 003:   2414 / 3665 loss=5.265, loss_v1=0, loss_v2=0, nll_loss=4.377, ntokens=721.8, nsentences=32, sample_size=721.8, sample_size_v1=0, sample_size_v2=0, ppl=20.78, wps=368.1, ups=0.51, wpb=721.8, bsz=32, num_updates=9730, lr=3.907e-05, gnorm=2.278, clip=100, loss_scale=256, train_wall=20, gb_free=15.5, wall=26658
2023-01-09 11:02:11 - progress_bar.py[line:272] - INFO: epoch 003:   2424 / 3665 loss=5.158, loss_v1=0, loss_v2=0, nll_loss=4.257, ntokens=792.6, nsentences=32, sample_size=792.6, sample_size_v1=0, sample_size_v2=0, ppl=19.12, wps=403.7, ups=0.51, wpb=792.6, bsz=32, num_updates=9740, lr=3.90555e-05, gnorm=2.004, clip=100, loss_scale=256, train_wall=20, gb_free=15.7, wall=26677
2023-01-09 11:02:31 - progress_bar.py[line:272] - INFO: epoch 003:   2434 / 3665 loss=5.186, loss_v1=0, loss_v2=0, nll_loss=4.291, ntokens=993, nsentences=32, sample_size=993, sample_size_v1=0, sample_size_v2=0, ppl=19.57, wps=504.4, ups=0.51, wpb=993, bsz=32, num_updates=9750, lr=3.9041e-05, gnorm=1.747, clip=100, loss_scale=256, train_wall=20, gb_free=15.4, wall=26697
2023-01-09 11:02:50 - progress_bar.py[line:272] - INFO: epoch 003:   2444 / 3665 loss=5.187, loss_v1=0, loss_v2=0, nll_loss=4.289, ntokens=665.5, nsentences=32, sample_size=665.5, sample_size_v1=0, sample_size_v2=0, ppl=19.54, wps=339.1, ups=0.51, wpb=665.5, bsz=32, num_updates=9760, lr=3.90264e-05, gnorm=2.303, clip=100, loss_scale=256, train_wall=20, gb_free=15.3, wall=26716
2023-01-09 11:03:10 - progress_bar.py[line:272] - INFO: epoch 003:   2454 / 3665 loss=5.283, loss_v1=0, loss_v2=0, nll_loss=4.399, ntokens=984.3, nsentences=32, sample_size=984.3, sample_size_v1=0, sample_size_v2=0, ppl=21.09, wps=499.5, ups=0.51, wpb=984.3, bsz=32, num_updates=9770, lr=3.90119e-05, gnorm=1.756, clip=100, loss_scale=256, train_wall=20, gb_free=15.4, wall=26736
2023-01-09 11:03:30 - progress_bar.py[line:272] - INFO: epoch 003:   2464 / 3665 loss=5.269, loss_v1=0, loss_v2=0, nll_loss=4.382, ntokens=973.3, nsentences=32, sample_size=973.3, sample_size_v1=0, sample_size_v2=0, ppl=20.85, wps=493.9, ups=0.51, wpb=973.3, bsz=32, num_updates=9780, lr=3.89974e-05, gnorm=1.7, clip=100, loss_scale=256, train_wall=20, gb_free=14.9, wall=26756
2023-01-09 11:03:49 - progress_bar.py[line:272] - INFO: epoch 003:   2474 / 3665 loss=5.346, loss_v1=0, loss_v2=0, nll_loss=4.465, ntokens=880.9, nsentences=32, sample_size=880.9, sample_size_v1=0, sample_size_v2=0, ppl=22.09, wps=447.5, ups=0.51, wpb=880.9, bsz=32, num_updates=9790, lr=3.89829e-05, gnorm=1.803, clip=100, loss_scale=256, train_wall=20, gb_free=15.4, wall=26776
2023-01-09 11:04:09 - progress_bar.py[line:272] - INFO: epoch 003:   2484 / 3665 loss=5.281, loss_v1=0, loss_v2=0, nll_loss=4.395, ntokens=831.7, nsentences=32, sample_size=831.7, sample_size_v1=0, sample_size_v2=0, ppl=21.04, wps=423.1, ups=0.51, wpb=831.7, bsz=32, num_updates=9800, lr=3.89684e-05, gnorm=1.918, clip=100, loss_scale=256, train_wall=20, gb_free=15.5, wall=26795
2023-01-09 11:04:29 - progress_bar.py[line:272] - INFO: epoch 003:   2494 / 3665 loss=5.25, loss_v1=0, loss_v2=0, nll_loss=4.363, ntokens=994.5, nsentences=32, sample_size=994.5, sample_size_v1=0, sample_size_v2=0, ppl=20.58, wps=504.3, ups=0.51, wpb=994.5, bsz=32, num_updates=9810, lr=3.89539e-05, gnorm=1.645, clip=100, loss_scale=256, train_wall=20, gb_free=15.4, wall=26815
2023-01-09 11:04:48 - progress_bar.py[line:272] - INFO: epoch 003:   2504 / 3665 loss=5.377, loss_v1=0, loss_v2=0, nll_loss=4.501, ntokens=1007.7, nsentences=32, sample_size=1007.7, sample_size_v1=0, sample_size_v2=0, ppl=22.64, wps=509.9, ups=0.51, wpb=1007.7, bsz=32, num_updates=9820, lr=3.89394e-05, gnorm=1.852, clip=100, loss_scale=256, train_wall=20, gb_free=15.5, wall=26835
2023-01-09 11:05:08 - progress_bar.py[line:272] - INFO: epoch 003:   2514 / 3665 loss=5.285, loss_v1=0, loss_v2=0, nll_loss=4.398, ntokens=800, nsentences=32, sample_size=800, sample_size_v1=0, sample_size_v2=0, ppl=21.09, wps=407.8, ups=0.51, wpb=800, bsz=32, num_updates=9830, lr=3.89248e-05, gnorm=2.198, clip=100, loss_scale=256, train_wall=20, gb_free=15.4, wall=26854
2023-01-09 11:05:28 - progress_bar.py[line:272] - INFO: epoch 003:   2524 / 3665 loss=5.241, loss_v1=0, loss_v2=0, nll_loss=4.348, ntokens=949.4, nsentences=32, sample_size=949.4, sample_size_v1=0, sample_size_v2=0, ppl=20.37, wps=481.6, ups=0.51, wpb=949.4, bsz=32, num_updates=9840, lr=3.89103e-05, gnorm=1.642, clip=100, loss_scale=256, train_wall=20, gb_free=15.3, wall=26874
2023-01-09 11:05:48 - progress_bar.py[line:272] - INFO: epoch 003:   2534 / 3665 loss=5.394, loss_v1=0, loss_v2=0, nll_loss=4.522, ntokens=961.2, nsentences=32, sample_size=961.2, sample_size_v1=0, sample_size_v2=0, ppl=22.98, wps=477.3, ups=0.5, wpb=961.2, bsz=32, num_updates=9850, lr=3.88958e-05, gnorm=1.702, clip=100, loss_scale=256, train_wall=20, gb_free=15.4, wall=26894
2023-01-09 11:06:08 - progress_bar.py[line:272] - INFO: epoch 003:   2544 / 3665 loss=5.24, loss_v1=0, loss_v2=0, nll_loss=4.352, ntokens=877.1, nsentences=32, sample_size=877.1, sample_size_v1=0, sample_size_v2=0, ppl=20.43, wps=435.3, ups=0.5, wpb=877.1, bsz=32, num_updates=9860, lr=3.88813e-05, gnorm=1.87, clip=100, loss_scale=256, train_wall=20, gb_free=15.1, wall=26914
2023-01-09 11:06:28 - progress_bar.py[line:272] - INFO: epoch 003:   2554 / 3665 loss=5.213, loss_v1=0, loss_v2=0, nll_loss=4.319, ntokens=1036.1, nsentences=32, sample_size=1036.1, sample_size_v1=0, sample_size_v2=0, ppl=19.96, wps=513.2, ups=0.5, wpb=1036.1, bsz=32, num_updates=9870, lr=3.88668e-05, gnorm=1.57, clip=100, loss_scale=256, train_wall=20, gb_free=15.2, wall=26935
2023-01-09 11:06:48 - progress_bar.py[line:272] - INFO: epoch 003:   2564 / 3665 loss=5.346, loss_v1=0, loss_v2=0, nll_loss=4.465, ntokens=973.7, nsentences=32, sample_size=973.7, sample_size_v1=0, sample_size_v2=0, ppl=22.09, wps=483.4, ups=0.5, wpb=973.7, bsz=32, num_updates=9880, lr=3.88523e-05, gnorm=1.684, clip=100, loss_scale=256, train_wall=20, gb_free=15.1, wall=26955
2023-01-09 11:07:08 - progress_bar.py[line:272] - INFO: epoch 003:   2574 / 3665 loss=5.225, loss_v1=0, loss_v2=0, nll_loss=4.332, ntokens=713.9, nsentences=32, sample_size=713.9, sample_size_v1=0, sample_size_v2=0, ppl=20.15, wps=364.7, ups=0.51, wpb=713.9, bsz=32, num_updates=9890, lr=3.88378e-05, gnorm=2.329, clip=100, loss_scale=256, train_wall=20, gb_free=15.5, wall=26974
2023-01-09 11:07:28 - progress_bar.py[line:272] - INFO: epoch 003:   2584 / 3665 loss=5.186, loss_v1=0, loss_v2=0, nll_loss=4.29, ntokens=878.3, nsentences=32, sample_size=878.3, sample_size_v1=0, sample_size_v2=0, ppl=19.56, wps=444, ups=0.51, wpb=878.3, bsz=32, num_updates=9900, lr=3.88233e-05, gnorm=1.966, clip=100, loss_scale=512, train_wall=20, gb_free=14.9, wall=26994
2023-01-09 11:07:47 - progress_bar.py[line:272] - INFO: epoch 003:   2594 / 3665 loss=5.279, loss_v1=0, loss_v2=0, nll_loss=4.394, ntokens=915.9, nsentences=32, sample_size=915.9, sample_size_v1=0, sample_size_v2=0, ppl=21.02, wps=467.1, ups=0.51, wpb=915.9, bsz=32, num_updates=9910, lr=3.88087e-05, gnorm=1.757, clip=100, loss_scale=512, train_wall=20, gb_free=15.6, wall=27014
2023-01-09 11:08:07 - progress_bar.py[line:272] - INFO: epoch 003:   2604 / 3665 loss=5.274, loss_v1=0, loss_v2=0, nll_loss=4.387, ntokens=804.7, nsentences=32, sample_size=804.7, sample_size_v1=0, sample_size_v2=0, ppl=20.92, wps=411.3, ups=0.51, wpb=804.7, bsz=32, num_updates=9920, lr=3.87942e-05, gnorm=1.999, clip=100, loss_scale=512, train_wall=20, gb_free=14.9, wall=27033
2023-01-09 11:08:27 - progress_bar.py[line:272] - INFO: epoch 003:   2614 / 3665 loss=5.303, loss_v1=0, loss_v2=0, nll_loss=4.42, ntokens=1012.3, nsentences=32, sample_size=1012.3, sample_size_v1=0, sample_size_v2=0, ppl=21.41, wps=514.3, ups=0.51, wpb=1012.3, bsz=32, num_updates=9930, lr=3.87797e-05, gnorm=1.72, clip=100, loss_scale=512, train_wall=20, gb_free=15.4, wall=27053
2023-01-09 11:08:46 - progress_bar.py[line:272] - INFO: epoch 003:   2624 / 3665 loss=5.348, loss_v1=0, loss_v2=0, nll_loss=4.469, ntokens=1175.8, nsentences=32, sample_size=1175.8, sample_size_v1=0, sample_size_v2=0, ppl=22.15, wps=595.6, ups=0.51, wpb=1175.8, bsz=32, num_updates=9940, lr=3.87652e-05, gnorm=1.529, clip=100, loss_scale=512, train_wall=20, gb_free=15.4, wall=27073
2023-01-09 11:09:06 - progress_bar.py[line:272] - INFO: epoch 003:   2634 / 3665 loss=5.313, loss_v1=0, loss_v2=0, nll_loss=4.43, ntokens=810.5, nsentences=32, sample_size=810.5, sample_size_v1=0, sample_size_v2=0, ppl=21.56, wps=407.5, ups=0.5, wpb=810.5, bsz=32, num_updates=9950, lr=3.87507e-05, gnorm=1.976, clip=100, loss_scale=512, train_wall=20, gb_free=15.3, wall=27092
2023-01-09 11:09:26 - progress_bar.py[line:272] - INFO: epoch 003:   2644 / 3665 loss=5.298, loss_v1=0, loss_v2=0, nll_loss=4.417, ntokens=987, nsentences=32, sample_size=987, sample_size_v1=0, sample_size_v2=0, ppl=21.36, wps=493.2, ups=0.5, wpb=987, bsz=32, num_updates=9960, lr=3.87362e-05, gnorm=1.91, clip=100, loss_scale=512, train_wall=20, gb_free=15.4, wall=27113
2023-01-09 11:09:46 - progress_bar.py[line:272] - INFO: epoch 003:   2654 / 3665 loss=5.296, loss_v1=0, loss_v2=0, nll_loss=4.412, ntokens=1105, nsentences=32, sample_size=1105, sample_size_v1=0, sample_size_v2=0, ppl=21.28, wps=550.7, ups=0.5, wpb=1105, bsz=32, num_updates=9970, lr=3.87217e-05, gnorm=1.586, clip=100, loss_scale=512, train_wall=20, gb_free=14.5, wall=27133
2023-01-09 11:10:06 - progress_bar.py[line:272] - INFO: epoch 003:   2664 / 3665 loss=5.369, loss_v1=0, loss_v2=0, nll_loss=4.489, ntokens=891, nsentences=32, sample_size=891, sample_size_v1=0, sample_size_v2=0, ppl=22.46, wps=445.2, ups=0.5, wpb=891, bsz=32, num_updates=9980, lr=3.87071e-05, gnorm=1.97, clip=100, loss_scale=512, train_wall=20, gb_free=15.4, wall=27153
2023-01-09 11:10:26 - progress_bar.py[line:272] - INFO: epoch 003:   2674 / 3665 loss=5.262, loss_v1=0, loss_v2=0, nll_loss=4.375, ntokens=796.9, nsentences=32, sample_size=796.9, sample_size_v1=0, sample_size_v2=0, ppl=20.75, wps=399.8, ups=0.5, wpb=796.9, bsz=32, num_updates=9990, lr=3.86926e-05, gnorm=2.066, clip=100, loss_scale=512, train_wall=20, gb_free=15.4, wall=27173
2023-01-09 11:10:46 - progress_bar.py[line:272] - INFO: epoch 003:   2684 / 3665 loss=5.217, loss_v1=0, loss_v2=0, nll_loss=4.325, ntokens=943.1, nsentences=32, sample_size=943.1, sample_size_v1=0, sample_size_v2=0, ppl=20.04, wps=472.4, ups=0.5, wpb=943.1, bsz=32, num_updates=10000, lr=3.86781e-05, gnorm=1.828, clip=100, loss_scale=512, train_wall=20, gb_free=15.5, wall=27192
2023-01-09 11:10:46 - train.py[line:445] - INFO: begin validation on "valid" subset
slice_id 0 seek offset 0
slice_id 0 seek offset 0
2023-01-09 11:15:33 - progress_bar.py[line:282] - INFO: epoch 003 | valid on 'valid' subset | loss 5.265 | loss_v1 0 | loss_v2 0 | nll_loss 4.361 | ntokens 117.278 | nsentences 4 | sample_size 117.278 | sample_size_v1 0 | sample_size_v2 0 | AP 0 | total positives 21.7577 | TP 0 | FP 5.71082 | ppl 20.55 | wps 512.1 | wpb 117.3 | bsz 4 | num_updates 10000 | best_AP 0
2023-01-09 11:15:33 - checkpoint_utils.py[line:64] - INFO: Preparing to save checkpoint for epoch 3 @ 10000 updates
2023-01-09 11:15:33 - trainer.py[line:431] - INFO: Saving checkpoint to ../../checkpoints/OFA/detection_checkpoints/10_5e-5_512/checkpoint_3_10000.pt
2023-01-09 11:15:36 - trainer.py[line:441] - INFO: Finished saving checkpoint to ../../checkpoints/OFA/detection_checkpoints/10_5e-5_512/checkpoint_3_10000.pt
2023-01-09 11:16:19 - checkpoint_utils.py[line:133] - INFO: Saved checkpoint ../../checkpoints/OFA/detection_checkpoints/10_5e-5_512/checkpoint_3_10000.pt (epoch 3 @ 10000 updates, score 0.0) (writing took 46.8590668970719 seconds)
2023-01-09 11:16:39 - progress_bar.py[line:272] - INFO: epoch 003:   2694 / 3665 loss=5.27, loss_v1=0, loss_v2=0, nll_loss=4.383, ntokens=964.3, nsentences=32, sample_size=964.3, sample_size_v1=0, sample_size_v2=0, ppl=20.87, wps=27.3, ups=0.03, wpb=964.3, bsz=32, num_updates=10010, lr=3.86636e-05, gnorm=1.868, clip=100, loss_scale=512, train_wall=19, gb_free=15.3, wall=27545
2023-01-09 11:16:58 - progress_bar.py[line:272] - INFO: epoch 003:   2704 / 3665 loss=5.225, loss_v1=0, loss_v2=0, nll_loss=4.329, ntokens=771.5, nsentences=32, sample_size=771.5, sample_size_v1=0, sample_size_v2=0, ppl=20.1, wps=397, ups=0.51, wpb=771.5, bsz=32, num_updates=10020, lr=3.86491e-05, gnorm=2.271, clip=100, loss_scale=512, train_wall=19, gb_free=15.5, wall=27565
2023-01-09 11:17:18 - progress_bar.py[line:272] - INFO: epoch 003:   2714 / 3665 loss=5.218, loss_v1=0, loss_v2=0, nll_loss=4.325, ntokens=1114.7, nsentences=32, sample_size=1114.7, sample_size_v1=0, sample_size_v2=0, ppl=20.04, wps=567.1, ups=0.51, wpb=1114.7, bsz=32, num_updates=10030, lr=3.86346e-05, gnorm=1.626, clip=100, loss_scale=512, train_wall=20, gb_free=15.4, wall=27584
2023-01-09 11:17:38 - progress_bar.py[line:272] - INFO: epoch 003:   2724 / 3665 loss=5.373, loss_v1=0, loss_v2=0, nll_loss=4.499, ntokens=1014.4, nsentences=32, sample_size=1014.4, sample_size_v1=0, sample_size_v2=0, ppl=22.62, wps=514.8, ups=0.51, wpb=1014.4, bsz=32, num_updates=10040, lr=3.86201e-05, gnorm=1.828, clip=100, loss_scale=512, train_wall=20, gb_free=15.3, wall=27604
2023-01-09 11:17:57 - progress_bar.py[line:272] - INFO: epoch 003:   2734 / 3665 loss=5.274, loss_v1=0, loss_v2=0, nll_loss=4.388, ntokens=837.1, nsentences=32, sample_size=837.1, sample_size_v1=0, sample_size_v2=0, ppl=20.94, wps=427.2, ups=0.51, wpb=837.1, bsz=32, num_updates=10050, lr=3.86056e-05, gnorm=2.125, clip=100, loss_scale=512, train_wall=20, gb_free=15.6, wall=27623
2023-01-09 11:18:17 - progress_bar.py[line:272] - INFO: epoch 003:   2744 / 3665 loss=5.259, loss_v1=0, loss_v2=0, nll_loss=4.367, ntokens=933.2, nsentences=32, sample_size=933.2, sample_size_v1=0, sample_size_v2=0, ppl=20.63, wps=475.9, ups=0.51, wpb=933.2, bsz=32, num_updates=10060, lr=3.8591e-05, gnorm=1.876, clip=100, loss_scale=512, train_wall=20, gb_free=15.3, wall=27643
2023-01-09 11:18:36 - progress_bar.py[line:272] - INFO: epoch 003:   2754 / 3665 loss=5.295, loss_v1=0, loss_v2=0, nll_loss=4.41, ntokens=950.7, nsentences=32, sample_size=950.7, sample_size_v1=0, sample_size_v2=0, ppl=21.25, wps=483.2, ups=0.51, wpb=950.7, bsz=32, num_updates=10070, lr=3.85765e-05, gnorm=1.899, clip=100, loss_scale=512, train_wall=20, gb_free=15.3, wall=27663
2023-01-09 11:18:56 - progress_bar.py[line:272] - INFO: epoch 003:   2764 / 3665 loss=5.29, loss_v1=0, loss_v2=0, nll_loss=4.406, ntokens=841.2, nsentences=32, sample_size=841.2, sample_size_v1=0, sample_size_v2=0, ppl=21.2, wps=428.5, ups=0.51, wpb=841.2, bsz=32, num_updates=10080, lr=3.8562e-05, gnorm=1.982, clip=100, loss_scale=512, train_wall=20, gb_free=15.1, wall=27682
2023-01-09 11:19:16 - progress_bar.py[line:272] - INFO: epoch 003:   2774 / 3665 loss=5.23, loss_v1=0, loss_v2=0, nll_loss=4.338, ntokens=957.7, nsentences=32, sample_size=957.7, sample_size_v1=0, sample_size_v2=0, ppl=20.22, wps=487.2, ups=0.51, wpb=957.7, bsz=32, num_updates=10090, lr=3.85475e-05, gnorm=1.844, clip=100, loss_scale=512, train_wall=20, gb_free=15.3, wall=27702
2023-01-09 11:19:35 - progress_bar.py[line:272] - INFO: epoch 003:   2784 / 3665 loss=5.35, loss_v1=0, loss_v2=0, nll_loss=4.472, ntokens=1056.1, nsentences=32, sample_size=1056.1, sample_size_v1=0, sample_size_v2=0, ppl=22.19, wps=536, ups=0.51, wpb=1056.1, bsz=32, num_updates=10100, lr=3.8533e-05, gnorm=1.713, clip=100, loss_scale=512, train_wall=20, gb_free=15.2, wall=27722
2023-01-09 11:19:55 - progress_bar.py[line:272] - INFO: epoch 003:   2794 / 3665 loss=5.203, loss_v1=0, loss_v2=0, nll_loss=4.309, ntokens=789.1, nsentences=32, sample_size=789.1, sample_size_v1=0, sample_size_v2=0, ppl=19.82, wps=398.8, ups=0.51, wpb=789.1, bsz=32, num_updates=10110, lr=3.85185e-05, gnorm=1.999, clip=100, loss_scale=512, train_wall=20, gb_free=15.5, wall=27742
2023-01-09 11:20:15 - progress_bar.py[line:272] - INFO: epoch 003:   2804 / 3665 loss=5.279, loss_v1=0, loss_v2=0, nll_loss=4.393, ntokens=972.1, nsentences=32, sample_size=972.1, sample_size_v1=0, sample_size_v2=0, ppl=21.01, wps=481.7, ups=0.5, wpb=972.1, bsz=32, num_updates=10120, lr=3.8504e-05, gnorm=1.824, clip=100, loss_scale=512, train_wall=20, gb_free=15.5, wall=27762
2023-01-09 11:20:35 - progress_bar.py[line:272] - INFO: epoch 003:   2814 / 3665 loss=5.297, loss_v1=0, loss_v2=0, nll_loss=4.412, ntokens=1139.4, nsentences=32, sample_size=1139.4, sample_size_v1=0, sample_size_v2=0, ppl=21.29, wps=568.9, ups=0.5, wpb=1139.4, bsz=32, num_updates=10130, lr=3.84894e-05, gnorm=1.517, clip=100, loss_scale=512, train_wall=20, gb_free=15.2, wall=27782
2023-01-09 11:20:55 - progress_bar.py[line:272] - INFO: epoch 003:   2824 / 3665 loss=5.272, loss_v1=0, loss_v2=0, nll_loss=4.382, ntokens=742, nsentences=32, sample_size=742, sample_size_v1=0, sample_size_v2=0, ppl=20.86, wps=373.6, ups=0.5, wpb=742, bsz=32, num_updates=10140, lr=3.84749e-05, gnorm=2.148, clip=100, loss_scale=512, train_wall=20, gb_free=15.5, wall=27802
2023-01-09 11:21:15 - progress_bar.py[line:272] - INFO: epoch 003:   2834 / 3665 loss=5.338, loss_v1=0, loss_v2=0, nll_loss=4.461, ntokens=967.6, nsentences=32, sample_size=967.6, sample_size_v1=0, sample_size_v2=0, ppl=22.02, wps=485, ups=0.5, wpb=967.6, bsz=32, num_updates=10150, lr=3.84604e-05, gnorm=1.834, clip=100, loss_scale=512, train_wall=20, gb_free=15.5, wall=27822
2023-01-09 11:21:35 - progress_bar.py[line:272] - INFO: epoch 003:   2844 / 3665 loss=5.246, loss_v1=0, loss_v2=0, nll_loss=4.357, ntokens=1036.2, nsentences=32, sample_size=1036.2, sample_size_v1=0, sample_size_v2=0, ppl=20.49, wps=519.3, ups=0.5, wpb=1036.2, bsz=32, num_updates=10160, lr=3.84459e-05, gnorm=1.839, clip=100, loss_scale=512, train_wall=20, gb_free=15.7, wall=27842
2023-01-09 11:21:55 - progress_bar.py[line:272] - INFO: epoch 003:   2854 / 3665 loss=5.358, loss_v1=0, loss_v2=0, nll_loss=4.477, ntokens=850, nsentences=32, sample_size=850, sample_size_v1=0, sample_size_v2=0, ppl=22.26, wps=427.5, ups=0.5, wpb=850, bsz=32, num_updates=10170, lr=3.84314e-05, gnorm=1.954, clip=100, loss_scale=512, train_wall=20, gb_free=15.4, wall=27861
2023-01-09 11:22:15 - progress_bar.py[line:272] - INFO: epoch 003:   2864 / 3665 loss=5.249, loss_v1=0, loss_v2=0, nll_loss=4.36, ntokens=744.9, nsentences=32, sample_size=744.9, sample_size_v1=0, sample_size_v2=0, ppl=20.54, wps=374.9, ups=0.5, wpb=744.9, bsz=32, num_updates=10180, lr=3.84169e-05, gnorm=2.057, clip=100, loss_scale=512, train_wall=20, gb_free=15.4, wall=27881
2023-01-09 11:22:35 - progress_bar.py[line:272] - INFO: epoch 003:   2874 / 3665 loss=5.184, loss_v1=0, loss_v2=0, nll_loss=4.286, ntokens=947.8, nsentences=32, sample_size=947.8, sample_size_v1=0, sample_size_v2=0, ppl=19.51, wps=476.2, ups=0.5, wpb=947.8, bsz=32, num_updates=10190, lr=3.84024e-05, gnorm=1.85, clip=100, loss_scale=512, train_wall=20, gb_free=15.6, wall=27901
2023-01-09 11:22:55 - progress_bar.py[line:272] - INFO: epoch 003:   2884 / 3665 loss=5.336, loss_v1=0, loss_v2=0, nll_loss=4.456, ntokens=907.8, nsentences=32, sample_size=907.8, sample_size_v1=0, sample_size_v2=0, ppl=21.95, wps=458.9, ups=0.51, wpb=907.8, bsz=32, num_updates=10200, lr=3.83879e-05, gnorm=1.922, clip=100, loss_scale=512, train_wall=20, gb_free=15.4, wall=27921
2023-01-09 11:23:14 - progress_bar.py[line:272] - INFO: epoch 003:   2894 / 3665 loss=5.242, loss_v1=0, loss_v2=0, nll_loss=4.353, ntokens=762.5, nsentences=32, sample_size=762.5, sample_size_v1=0, sample_size_v2=0, ppl=20.44, wps=386.9, ups=0.51, wpb=762.5, bsz=32, num_updates=10210, lr=3.83733e-05, gnorm=2.17, clip=100, loss_scale=512, train_wall=20, gb_free=15.6, wall=27941
2023-01-09 11:23:34 - progress_bar.py[line:272] - INFO: epoch 003:   2904 / 3665 loss=5.276, loss_v1=0, loss_v2=0, nll_loss=4.39, ntokens=1060.7, nsentences=32, sample_size=1060.7, sample_size_v1=0, sample_size_v2=0, ppl=20.96, wps=535.9, ups=0.51, wpb=1060.7, bsz=32, num_updates=10220, lr=3.83588e-05, gnorm=1.665, clip=100, loss_scale=512, train_wall=20, gb_free=15.2, wall=27960
2023-01-09 11:23:54 - progress_bar.py[line:272] - INFO: epoch 003:   2914 / 3665 loss=5.343, loss_v1=0, loss_v2=0, nll_loss=4.463, ntokens=1037.8, nsentences=32, sample_size=1037.8, sample_size_v1=0, sample_size_v2=0, ppl=22.05, wps=522.8, ups=0.5, wpb=1037.8, bsz=32, num_updates=10230, lr=3.83443e-05, gnorm=1.664, clip=100, loss_scale=512, train_wall=20, gb_free=15.3, wall=27980
2023-01-09 11:24:14 - progress_bar.py[line:272] - INFO: epoch 003:   2924 / 3665 loss=5.275, loss_v1=0, loss_v2=0, nll_loss=4.389, ntokens=837.6, nsentences=32, sample_size=837.6, sample_size_v1=0, sample_size_v2=0, ppl=20.95, wps=423.7, ups=0.51, wpb=837.6, bsz=32, num_updates=10240, lr=3.83298e-05, gnorm=1.956, clip=100, loss_scale=512, train_wall=20, gb_free=15.4, wall=28000
2023-01-09 11:24:33 - progress_bar.py[line:272] - INFO: epoch 003:   2934 / 3665 loss=5.14, loss_v1=0, loss_v2=0, nll_loss=4.236, ntokens=879.1, nsentences=32, sample_size=879.1, sample_size_v1=0, sample_size_v2=0, ppl=18.84, wps=446.4, ups=0.51, wpb=879.1, bsz=32, num_updates=10250, lr=3.83153e-05, gnorm=2.013, clip=100, loss_scale=512, train_wall=20, gb_free=15.7, wall=28020
2023-01-09 11:24:53 - progress_bar.py[line:272] - INFO: epoch 003:   2944 / 3665 loss=5.415, loss_v1=0, loss_v2=0, nll_loss=4.547, ntokens=1218.4, nsentences=32, sample_size=1218.4, sample_size_v1=0, sample_size_v2=0, ppl=23.37, wps=611.3, ups=0.5, wpb=1218.4, bsz=32, num_updates=10260, lr=3.83008e-05, gnorm=1.5, clip=90, loss_scale=512, train_wall=20, gb_free=15.3, wall=28040
2023-01-09 11:25:13 - progress_bar.py[line:272] - INFO: epoch 003:   2954 / 3665 loss=5.271, loss_v1=0, loss_v2=0, nll_loss=4.383, ntokens=859.4, nsentences=32, sample_size=859.4, sample_size_v1=0, sample_size_v2=0, ppl=20.87, wps=434.6, ups=0.51, wpb=859.4, bsz=32, num_updates=10270, lr=3.82863e-05, gnorm=1.941, clip=100, loss_scale=512, train_wall=20, gb_free=15.4, wall=28059
2023-01-09 11:25:33 - progress_bar.py[line:272] - INFO: epoch 003:   2964 / 3665 loss=5.278, loss_v1=0, loss_v2=0, nll_loss=4.392, ntokens=1022.4, nsentences=32, sample_size=1022.4, sample_size_v1=0, sample_size_v2=0, ppl=20.99, wps=516.3, ups=0.51, wpb=1022.4, bsz=32, num_updates=10280, lr=3.82717e-05, gnorm=1.657, clip=100, loss_scale=512, train_wall=20, gb_free=15.6, wall=28079
2023-01-09 11:25:53 - progress_bar.py[line:272] - INFO: epoch 003:   2974 / 3665 loss=5.324, loss_v1=0, loss_v2=0, nll_loss=4.443, ntokens=1033.4, nsentences=32, sample_size=1033.4, sample_size_v1=0, sample_size_v2=0, ppl=21.75, wps=522.6, ups=0.51, wpb=1033.4, bsz=32, num_updates=10290, lr=3.82572e-05, gnorm=1.677, clip=100, loss_scale=512, train_wall=20, gb_free=15.6, wall=28099
2023-01-09 11:26:13 - progress_bar.py[line:272] - INFO: epoch 003:   2984 / 3665 loss=5.226, loss_v1=0, loss_v2=0, nll_loss=4.332, ntokens=859, nsentences=32, sample_size=859, sample_size_v1=0, sample_size_v2=0, ppl=20.15, wps=434.8, ups=0.51, wpb=859, bsz=32, num_updates=10300, lr=3.82427e-05, gnorm=1.919, clip=100, loss_scale=512, train_wall=20, gb_free=15.6, wall=28119
2023-01-09 11:26:28 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 256.0
2023-01-09 11:26:34 - progress_bar.py[line:272] - INFO: epoch 003:   2995 / 3665 loss=5.265, loss_v1=0, loss_v2=0, nll_loss=4.379, ntokens=973, nsentences=32, sample_size=973, sample_size_v1=0, sample_size_v2=0, ppl=20.8, wps=446.6, ups=0.46, wpb=973, bsz=32, num_updates=10310, lr=3.82282e-05, gnorm=1.78, clip=100, loss_scale=256, train_wall=22, gb_free=15.6, wall=28141
2023-01-09 11:26:54 - progress_bar.py[line:272] - INFO: epoch 003:   3005 / 3665 loss=5.24, loss_v1=0, loss_v2=0, nll_loss=4.347, ntokens=1047.2, nsentences=32, sample_size=1047.2, sample_size_v1=0, sample_size_v2=0, ppl=20.36, wps=528.5, ups=0.5, wpb=1047.2, bsz=32, num_updates=10320, lr=3.82137e-05, gnorm=1.609, clip=100, loss_scale=256, train_wall=20, gb_free=15.3, wall=28160
2023-01-09 11:27:14 - progress_bar.py[line:272] - INFO: epoch 003:   3015 / 3665 loss=5.175, loss_v1=0, loss_v2=0, nll_loss=4.276, ntokens=689.7, nsentences=32, sample_size=689.7, sample_size_v1=0, sample_size_v2=0, ppl=19.37, wps=350.8, ups=0.51, wpb=689.7, bsz=32, num_updates=10330, lr=3.81992e-05, gnorm=2.111, clip=100, loss_scale=256, train_wall=20, gb_free=15.6, wall=28180
2023-01-09 11:27:34 - progress_bar.py[line:272] - INFO: epoch 003:   3025 / 3665 loss=5.277, loss_v1=0, loss_v2=0, nll_loss=4.395, ntokens=1029.5, nsentences=32, sample_size=1029.5, sample_size_v1=0, sample_size_v2=0, ppl=21.04, wps=519, ups=0.5, wpb=1029.5, bsz=32, num_updates=10340, lr=3.81847e-05, gnorm=1.732, clip=100, loss_scale=256, train_wall=20, gb_free=15.2, wall=28200
2023-01-09 11:27:53 - progress_bar.py[line:272] - INFO: epoch 003:   3035 / 3665 loss=5.165, loss_v1=0, loss_v2=0, nll_loss=4.264, ntokens=956.9, nsentences=32, sample_size=956.9, sample_size_v1=0, sample_size_v2=0, ppl=19.22, wps=484.6, ups=0.51, wpb=956.9, bsz=32, num_updates=10350, lr=3.81702e-05, gnorm=1.866, clip=100, loss_scale=256, train_wall=20, gb_free=15.2, wall=28220
2023-01-09 11:28:13 - progress_bar.py[line:272] - INFO: epoch 003:   3045 / 3665 loss=5.39, loss_v1=0, loss_v2=0, nll_loss=4.512, ntokens=906.4, nsentences=32, sample_size=906.4, sample_size_v1=0, sample_size_v2=0, ppl=22.82, wps=458.8, ups=0.51, wpb=906.4, bsz=32, num_updates=10360, lr=3.81556e-05, gnorm=1.958, clip=100, loss_scale=256, train_wall=20, gb_free=15.7, wall=28239
2023-01-09 11:28:33 - progress_bar.py[line:272] - INFO: epoch 003:   3055 / 3665 loss=5.218, loss_v1=0, loss_v2=0, nll_loss=4.327, ntokens=867.3, nsentences=32, sample_size=867.3, sample_size_v1=0, sample_size_v2=0, ppl=20.07, wps=438.8, ups=0.51, wpb=867.3, bsz=32, num_updates=10370, lr=3.81411e-05, gnorm=1.867, clip=100, loss_scale=256, train_wall=20, gb_free=15.5, wall=28259
2023-01-09 11:28:53 - progress_bar.py[line:272] - INFO: epoch 003:   3065 / 3665 loss=5.22, loss_v1=0, loss_v2=0, nll_loss=4.329, ntokens=1015.5, nsentences=32, sample_size=1015.5, sample_size_v1=0, sample_size_v2=0, ppl=20.1, wps=513.2, ups=0.51, wpb=1015.5, bsz=32, num_updates=10380, lr=3.81266e-05, gnorm=1.664, clip=100, loss_scale=256, train_wall=20, gb_free=15.3, wall=28279
2023-01-09 11:29:13 - progress_bar.py[line:272] - INFO: epoch 003:   3075 / 3665 loss=5.362, loss_v1=0, loss_v2=0, nll_loss=4.482, ntokens=1053.7, nsentences=32, sample_size=1053.7, sample_size_v1=0, sample_size_v2=0, ppl=22.35, wps=530.1, ups=0.5, wpb=1053.7, bsz=32, num_updates=10390, lr=3.81121e-05, gnorm=1.747, clip=100, loss_scale=256, train_wall=20, gb_free=15.4, wall=28299
2023-01-09 11:29:32 - progress_bar.py[line:272] - INFO: epoch 003:   3085 / 3665 loss=5.265, loss_v1=0, loss_v2=0, nll_loss=4.376, ntokens=883, nsentences=32, sample_size=883, sample_size_v1=0, sample_size_v2=0, ppl=20.77, wps=447, ups=0.51, wpb=883, bsz=32, num_updates=10400, lr=3.80976e-05, gnorm=2.082, clip=100, loss_scale=256, train_wall=20, gb_free=15.3, wall=28319
2023-01-09 11:29:52 - progress_bar.py[line:272] - INFO: epoch 003:   3095 / 3665 loss=5.257, loss_v1=0, loss_v2=0, nll_loss=4.369, ntokens=1013.5, nsentences=32, sample_size=1013.5, sample_size_v1=0, sample_size_v2=0, ppl=20.67, wps=512.4, ups=0.51, wpb=1013.5, bsz=32, num_updates=10410, lr=3.80831e-05, gnorm=1.742, clip=100, loss_scale=256, train_wall=20, gb_free=15, wall=28338
2023-01-09 11:30:12 - progress_bar.py[line:272] - INFO: epoch 003:   3105 / 3665 loss=5.397, loss_v1=0, loss_v2=0, nll_loss=4.527, ntokens=1023.1, nsentences=32, sample_size=1023.1, sample_size_v1=0, sample_size_v2=0, ppl=23.06, wps=516.7, ups=0.51, wpb=1023.1, bsz=32, num_updates=10420, lr=3.80686e-05, gnorm=1.661, clip=100, loss_scale=256, train_wall=20, gb_free=15.3, wall=28358
2023-01-09 11:30:32 - progress_bar.py[line:272] - INFO: epoch 003:   3115 / 3665 loss=5.351, loss_v1=0, loss_v2=0, nll_loss=4.469, ntokens=828.1, nsentences=32, sample_size=828.1, sample_size_v1=0, sample_size_v2=0, ppl=22.15, wps=419.7, ups=0.51, wpb=828.1, bsz=32, num_updates=10430, lr=3.8054e-05, gnorm=2.027, clip=100, loss_scale=256, train_wall=20, gb_free=15.3, wall=28378
2023-01-09 11:30:51 - progress_bar.py[line:272] - INFO: epoch 003:   3125 / 3665 loss=5.282, loss_v1=0, loss_v2=0, nll_loss=4.395, ntokens=1028.5, nsentences=32, sample_size=1028.5, sample_size_v1=0, sample_size_v2=0, ppl=21.03, wps=518.6, ups=0.5, wpb=1028.5, bsz=32, num_updates=10440, lr=3.80395e-05, gnorm=1.742, clip=100, loss_scale=256, train_wall=20, gb_free=15.4, wall=28398
2023-01-09 11:31:11 - progress_bar.py[line:272] - INFO: epoch 003:   3135 / 3665 loss=5.326, loss_v1=0, loss_v2=0, nll_loss=4.447, ntokens=1043.6, nsentences=32, sample_size=1043.6, sample_size_v1=0, sample_size_v2=0, ppl=21.8, wps=526.3, ups=0.5, wpb=1043.6, bsz=32, num_updates=10450, lr=3.8025e-05, gnorm=1.601, clip=100, loss_scale=256, train_wall=20, gb_free=15.4, wall=28418
2023-01-09 11:31:31 - progress_bar.py[line:272] - INFO: epoch 003:   3145 / 3665 loss=5.254, loss_v1=0, loss_v2=0, nll_loss=4.366, ntokens=832.3, nsentences=32, sample_size=832.3, sample_size_v1=0, sample_size_v2=0, ppl=20.62, wps=421.8, ups=0.51, wpb=832.3, bsz=32, num_updates=10460, lr=3.80105e-05, gnorm=2.197, clip=100, loss_scale=256, train_wall=20, gb_free=15.2, wall=28437
2023-01-09 11:31:51 - progress_bar.py[line:272] - INFO: epoch 003:   3155 / 3665 loss=5.25, loss_v1=0, loss_v2=0, nll_loss=4.36, ntokens=910.4, nsentences=32, sample_size=910.4, sample_size_v1=0, sample_size_v2=0, ppl=20.53, wps=461.6, ups=0.51, wpb=910.4, bsz=32, num_updates=10470, lr=3.7996e-05, gnorm=1.962, clip=100, loss_scale=256, train_wall=20, gb_free=15.1, wall=28457
2023-01-09 11:32:11 - progress_bar.py[line:272] - INFO: epoch 003:   3165 / 3665 loss=5.294, loss_v1=0, loss_v2=0, nll_loss=4.409, ntokens=983.6, nsentences=32, sample_size=983.6, sample_size_v1=0, sample_size_v2=0, ppl=21.24, wps=496.6, ups=0.5, wpb=983.6, bsz=32, num_updates=10480, lr=3.79815e-05, gnorm=1.752, clip=100, loss_scale=256, train_wall=20, gb_free=15.4, wall=28477
2023-01-09 11:32:30 - progress_bar.py[line:272] - INFO: epoch 003:   3175 / 3665 loss=5.222, loss_v1=0, loss_v2=0, nll_loss=4.332, ntokens=783, nsentences=32, sample_size=783, sample_size_v1=0, sample_size_v2=0, ppl=20.14, wps=396.9, ups=0.51, wpb=783, bsz=32, num_updates=10490, lr=3.7967e-05, gnorm=2.211, clip=100, loss_scale=256, train_wall=20, gb_free=15.7, wall=28497
2023-01-09 11:32:50 - progress_bar.py[line:272] - INFO: epoch 003:   3185 / 3665 loss=5.234, loss_v1=0, loss_v2=0, nll_loss=4.343, ntokens=888.1, nsentences=32, sample_size=888.1, sample_size_v1=0, sample_size_v2=0, ppl=20.29, wps=450.2, ups=0.51, wpb=888.1, bsz=32, num_updates=10500, lr=3.79525e-05, gnorm=2.072, clip=100, loss_scale=256, train_wall=20, gb_free=15.5, wall=28516
2023-01-09 11:32:50 - train.py[line:445] - INFO: begin validation on "valid" subset
slice_id 0 seek offset 0
slice_id 0 seek offset 0
2023-01-09 11:37:32 - progress_bar.py[line:282] - INFO: epoch 003 | valid on 'valid' subset | loss 5.257 | loss_v1 0 | loss_v2 0 | nll_loss 4.35 | ntokens 116.837 | nsentences 4 | sample_size 116.837 | sample_size_v1 0 | sample_size_v2 0 | AP 0 | total positives 21.6785 | TP 0 | FP 5.89338 | ppl 20.39 | wps 518 | wpb 116.8 | bsz 4 | num_updates 10500 | best_AP 0
2023-01-09 11:37:32 - checkpoint_utils.py[line:64] - INFO: Preparing to save checkpoint for epoch 3 @ 10500 updates
2023-01-09 11:37:32 - trainer.py[line:431] - INFO: Saving checkpoint to ../../checkpoints/OFA/detection_checkpoints/10_5e-5_512/checkpoint_3_10500.pt
2023-01-09 11:37:35 - trainer.py[line:441] - INFO: Finished saving checkpoint to ../../checkpoints/OFA/detection_checkpoints/10_5e-5_512/checkpoint_3_10500.pt
2023-01-09 11:38:56 - checkpoint_utils.py[line:133] - INFO: Saved checkpoint ../../checkpoints/OFA/detection_checkpoints/10_5e-5_512/checkpoint_3_10500.pt (epoch 3 @ 10500 updates, score 0.0) (writing took 83.80292198900133 seconds)
2023-01-09 11:39:15 - progress_bar.py[line:272] - INFO: epoch 003:   3195 / 3665 loss=5.301, loss_v1=0, loss_v2=0, nll_loss=4.417, ntokens=1076.6, nsentences=32, sample_size=1076.6, sample_size_v1=0, sample_size_v2=0, ppl=21.37, wps=27.9, ups=0.03, wpb=1076.6, bsz=32, num_updates=10510, lr=3.79379e-05, gnorm=1.617, clip=100, loss_scale=256, train_wall=19, gb_free=15.6, wall=28902
2023-01-09 11:39:35 - progress_bar.py[line:272] - INFO: epoch 003:   3205 / 3665 loss=5.275, loss_v1=0, loss_v2=0, nll_loss=4.387, ntokens=800.7, nsentences=32, sample_size=800.7, sample_size_v1=0, sample_size_v2=0, ppl=20.93, wps=412.6, ups=0.52, wpb=800.7, bsz=32, num_updates=10520, lr=3.79234e-05, gnorm=2.038, clip=100, loss_scale=256, train_wall=19, gb_free=15.2, wall=28921
2023-01-09 11:39:54 - progress_bar.py[line:272] - INFO: epoch 003:   3215 / 3665 loss=5.238, loss_v1=0, loss_v2=0, nll_loss=4.347, ntokens=991.5, nsentences=32, sample_size=991.5, sample_size_v1=0, sample_size_v2=0, ppl=20.35, wps=507.3, ups=0.51, wpb=991.5, bsz=32, num_updates=10530, lr=3.79089e-05, gnorm=1.787, clip=100, loss_scale=256, train_wall=20, gb_free=15.1, wall=28941
2023-01-09 11:40:14 - progress_bar.py[line:272] - INFO: epoch 003:   3225 / 3665 loss=5.254, loss_v1=0, loss_v2=0, nll_loss=4.366, ntokens=1208.8, nsentences=32, sample_size=1208.8, sample_size_v1=0, sample_size_v2=0, ppl=20.62, wps=612.8, ups=0.51, wpb=1208.8, bsz=32, num_updates=10540, lr=3.78944e-05, gnorm=1.468, clip=100, loss_scale=256, train_wall=20, gb_free=15.2, wall=28960
2023-01-09 11:40:34 - progress_bar.py[line:272] - INFO: epoch 003:   3235 / 3665 loss=5.268, loss_v1=0, loss_v2=0, nll_loss=4.381, ntokens=852.8, nsentences=32, sample_size=852.8, sample_size_v1=0, sample_size_v2=0, ppl=20.84, wps=435.2, ups=0.51, wpb=852.8, bsz=32, num_updates=10550, lr=3.78799e-05, gnorm=1.971, clip=100, loss_scale=256, train_wall=20, gb_free=15.4, wall=28980
2023-01-09 11:40:53 - progress_bar.py[line:272] - INFO: epoch 003:   3245 / 3665 loss=5.186, loss_v1=0, loss_v2=0, nll_loss=4.289, ntokens=814.7, nsentences=32, sample_size=814.7, sample_size_v1=0, sample_size_v2=0, ppl=19.55, wps=415.9, ups=0.51, wpb=814.7, bsz=32, num_updates=10560, lr=3.78654e-05, gnorm=2.06, clip=100, loss_scale=256, train_wall=20, gb_free=15.3, wall=28999
2023-01-09 11:41:13 - progress_bar.py[line:272] - INFO: epoch 003:   3255 / 3665 loss=5.229, loss_v1=0, loss_v2=0, nll_loss=4.335, ntokens=1017.8, nsentences=32, sample_size=1017.8, sample_size_v1=0, sample_size_v2=0, ppl=20.18, wps=519.7, ups=0.51, wpb=1017.8, bsz=32, num_updates=10570, lr=3.78509e-05, gnorm=1.798, clip=100, loss_scale=256, train_wall=20, gb_free=15.3, wall=29019
2023-01-09 11:41:32 - progress_bar.py[line:272] - INFO: epoch 003:   3265 / 3665 loss=5.318, loss_v1=0, loss_v2=0, nll_loss=4.436, ntokens=963.9, nsentences=32, sample_size=963.9, sample_size_v1=0, sample_size_v2=0, ppl=21.65, wps=491.7, ups=0.51, wpb=963.9, bsz=32, num_updates=10580, lr=3.78363e-05, gnorm=1.712, clip=100, loss_scale=256, train_wall=20, gb_free=15.2, wall=29039
2023-01-09 11:41:52 - progress_bar.py[line:272] - INFO: epoch 003:   3275 / 3665 loss=5.283, loss_v1=0, loss_v2=0, nll_loss=4.397, ntokens=773.3, nsentences=32, sample_size=773.3, sample_size_v1=0, sample_size_v2=0, ppl=21.07, wps=394.9, ups=0.51, wpb=773.3, bsz=32, num_updates=10590, lr=3.78218e-05, gnorm=2.178, clip=100, loss_scale=256, train_wall=20, gb_free=15.5, wall=29058
2023-01-09 11:42:12 - progress_bar.py[line:272] - INFO: epoch 003:   3285 / 3665 loss=5.248, loss_v1=0, loss_v2=0, nll_loss=4.36, ntokens=968, nsentences=32, sample_size=968, sample_size_v1=0, sample_size_v2=0, ppl=20.54, wps=489.5, ups=0.51, wpb=968, bsz=32, num_updates=10600, lr=3.78073e-05, gnorm=1.81, clip=100, loss_scale=256, train_wall=20, gb_free=15.5, wall=29078
2023-01-09 11:42:31 - progress_bar.py[line:272] - INFO: epoch 003:   3295 / 3665 loss=5.272, loss_v1=0, loss_v2=0, nll_loss=4.383, ntokens=955, nsentences=32, sample_size=955, sample_size_v1=0, sample_size_v2=0, ppl=20.87, wps=485.8, ups=0.51, wpb=955, bsz=32, num_updates=10610, lr=3.77928e-05, gnorm=1.812, clip=100, loss_scale=256, train_wall=20, gb_free=15, wall=29098
2023-01-09 11:42:51 - progress_bar.py[line:272] - INFO: epoch 003:   3305 / 3665 loss=5.215, loss_v1=0, loss_v2=0, nll_loss=4.322, ntokens=785.7, nsentences=32, sample_size=785.7, sample_size_v1=0, sample_size_v2=0, ppl=19.99, wps=401.6, ups=0.51, wpb=785.7, bsz=32, num_updates=10620, lr=3.77783e-05, gnorm=1.907, clip=100, loss_scale=256, train_wall=20, gb_free=15.7, wall=29117
2023-01-09 11:43:11 - progress_bar.py[line:272] - INFO: epoch 003:   3315 / 3665 loss=5.257, loss_v1=0, loss_v2=0, nll_loss=4.37, ntokens=972.2, nsentences=32, sample_size=972.2, sample_size_v1=0, sample_size_v2=0, ppl=20.68, wps=494.8, ups=0.51, wpb=972.2, bsz=32, num_updates=10630, lr=3.77638e-05, gnorm=1.724, clip=100, loss_scale=256, train_wall=20, gb_free=15.5, wall=29137
2023-01-09 11:43:30 - progress_bar.py[line:272] - INFO: epoch 003:   3325 / 3665 loss=5.341, loss_v1=0, loss_v2=0, nll_loss=4.461, ntokens=975.4, nsentences=32, sample_size=975.4, sample_size_v1=0, sample_size_v2=0, ppl=22.02, wps=494.2, ups=0.51, wpb=975.4, bsz=32, num_updates=10640, lr=3.77493e-05, gnorm=1.782, clip=100, loss_scale=256, train_wall=20, gb_free=14.5, wall=29157
2023-01-09 11:43:50 - progress_bar.py[line:272] - INFO: epoch 003:   3335 / 3665 loss=5.37, loss_v1=0, loss_v2=0, nll_loss=4.493, ntokens=909, nsentences=32, sample_size=909, sample_size_v1=0, sample_size_v2=0, ppl=22.51, wps=458, ups=0.5, wpb=909, bsz=32, num_updates=10650, lr=3.77348e-05, gnorm=1.956, clip=100, loss_scale=256, train_wall=20, gb_free=15.2, wall=29176
2023-01-09 11:44:10 - progress_bar.py[line:272] - INFO: epoch 003:   3345 / 3665 loss=5.282, loss_v1=0, loss_v2=0, nll_loss=4.397, ntokens=927.6, nsentences=32, sample_size=927.6, sample_size_v1=0, sample_size_v2=0, ppl=21.08, wps=467, ups=0.5, wpb=927.6, bsz=32, num_updates=10660, lr=3.77202e-05, gnorm=1.854, clip=100, loss_scale=256, train_wall=20, gb_free=15.5, wall=29196
2023-01-09 11:44:30 - progress_bar.py[line:272] - INFO: epoch 003:   3355 / 3665 loss=5.342, loss_v1=0, loss_v2=0, nll_loss=4.463, ntokens=1047.2, nsentences=32, sample_size=1047.2, sample_size_v1=0, sample_size_v2=0, ppl=22.05, wps=525.6, ups=0.5, wpb=1047.2, bsz=32, num_updates=10670, lr=3.77057e-05, gnorm=1.687, clip=100, loss_scale=256, train_wall=20, gb_free=15.5, wall=29216
2023-01-09 11:44:50 - progress_bar.py[line:272] - INFO: epoch 003:   3365 / 3665 loss=5.246, loss_v1=0, loss_v2=0, nll_loss=4.355, ntokens=798, nsentences=32, sample_size=798, sample_size_v1=0, sample_size_v2=0, ppl=20.47, wps=401.4, ups=0.5, wpb=798, bsz=32, num_updates=10680, lr=3.76912e-05, gnorm=2.115, clip=100, loss_scale=256, train_wall=20, gb_free=15.6, wall=29236
2023-01-09 11:45:10 - progress_bar.py[line:272] - INFO: epoch 003:   3375 / 3665 loss=5.282, loss_v1=0, loss_v2=0, nll_loss=4.397, ntokens=948.1, nsentences=32, sample_size=948.1, sample_size_v1=0, sample_size_v2=0, ppl=21.07, wps=477.9, ups=0.5, wpb=948.1, bsz=32, num_updates=10690, lr=3.76767e-05, gnorm=1.917, clip=100, loss_scale=256, train_wall=20, gb_free=15.6, wall=29256
2023-01-09 11:45:30 - progress_bar.py[line:272] - INFO: epoch 003:   3385 / 3665 loss=5.251, loss_v1=0, loss_v2=0, nll_loss=4.362, ntokens=1056.5, nsentences=32, sample_size=1056.5, sample_size_v1=0, sample_size_v2=0, ppl=20.56, wps=530.4, ups=0.5, wpb=1056.5, bsz=32, num_updates=10700, lr=3.76622e-05, gnorm=1.664, clip=100, loss_scale=256, train_wall=20, gb_free=15.1, wall=29276
2023-01-09 11:45:49 - progress_bar.py[line:272] - INFO: epoch 003:   3395 / 3665 loss=5.285, loss_v1=0, loss_v2=0, nll_loss=4.399, ntokens=821.2, nsentences=32, sample_size=821.2, sample_size_v1=0, sample_size_v2=0, ppl=21.09, wps=414.1, ups=0.5, wpb=821.2, bsz=32, num_updates=10710, lr=3.76477e-05, gnorm=1.927, clip=100, loss_scale=256, train_wall=20, gb_free=15.5, wall=29296
2023-01-09 11:46:09 - progress_bar.py[line:272] - INFO: epoch 003:   3405 / 3665 loss=5.265, loss_v1=0, loss_v2=0, nll_loss=4.378, ntokens=889.3, nsentences=32, sample_size=889.3, sample_size_v1=0, sample_size_v2=0, ppl=20.79, wps=449.4, ups=0.51, wpb=889.3, bsz=32, num_updates=10720, lr=3.76332e-05, gnorm=1.853, clip=100, loss_scale=256, train_wall=20, gb_free=15.4, wall=29316
2023-01-09 11:46:29 - progress_bar.py[line:272] - INFO: epoch 003:   3415 / 3665 loss=5.188, loss_v1=0, loss_v2=0, nll_loss=4.294, ntokens=949.2, nsentences=32, sample_size=949.2, sample_size_v1=0, sample_size_v2=0, ppl=19.61, wps=478.1, ups=0.5, wpb=949.2, bsz=32, num_updates=10730, lr=3.76186e-05, gnorm=1.844, clip=100, loss_scale=256, train_wall=20, gb_free=15.4, wall=29335
2023-01-09 11:46:49 - progress_bar.py[line:272] - INFO: epoch 003:   3425 / 3665 loss=5.361, loss_v1=0, loss_v2=0, nll_loss=4.483, ntokens=836, nsentences=32, sample_size=836, sample_size_v1=0, sample_size_v2=0, ppl=22.37, wps=422.2, ups=0.51, wpb=836, bsz=32, num_updates=10740, lr=3.76041e-05, gnorm=2.094, clip=100, loss_scale=256, train_wall=20, gb_free=15.4, wall=29355
2023-01-09 11:47:09 - progress_bar.py[line:272] - INFO: epoch 003:   3435 / 3665 loss=5.3, loss_v1=0, loss_v2=0, nll_loss=4.414, ntokens=965, nsentences=32, sample_size=965, sample_size_v1=0, sample_size_v2=0, ppl=21.32, wps=485.3, ups=0.5, wpb=965, bsz=32, num_updates=10750, lr=3.75896e-05, gnorm=1.82, clip=100, loss_scale=256, train_wall=20, gb_free=15.3, wall=29375
2023-01-09 11:47:29 - progress_bar.py[line:272] - INFO: epoch 003:   3445 / 3665 loss=5.207, loss_v1=0, loss_v2=0, nll_loss=4.311, ntokens=963, nsentences=32, sample_size=963, sample_size_v1=0, sample_size_v2=0, ppl=19.85, wps=484.4, ups=0.5, wpb=963, bsz=32, num_updates=10760, lr=3.75751e-05, gnorm=1.881, clip=100, loss_scale=256, train_wall=20, gb_free=15.3, wall=29395
2023-01-09 11:47:49 - progress_bar.py[line:272] - INFO: epoch 003:   3455 / 3665 loss=5.287, loss_v1=0, loss_v2=0, nll_loss=4.402, ntokens=872.1, nsentences=32, sample_size=872.1, sample_size_v1=0, sample_size_v2=0, ppl=21.14, wps=439.8, ups=0.5, wpb=872.1, bsz=32, num_updates=10770, lr=3.75606e-05, gnorm=2.041, clip=100, loss_scale=256, train_wall=20, gb_free=15.3, wall=29415
2023-01-09 11:48:08 - progress_bar.py[line:272] - INFO: epoch 003:   3465 / 3665 loss=5.137, loss_v1=0, loss_v2=0, nll_loss=4.235, ntokens=636.6, nsentences=32, sample_size=636.6, sample_size_v1=0, sample_size_v2=0, ppl=18.83, wps=323.8, ups=0.51, wpb=636.6, bsz=32, num_updates=10780, lr=3.75461e-05, gnorm=2.374, clip=100, loss_scale=256, train_wall=20, gb_free=15.6, wall=29434
2023-01-09 11:48:28 - progress_bar.py[line:272] - INFO: epoch 003:   3475 / 3665 loss=5.239, loss_v1=0, loss_v2=0, nll_loss=4.35, ntokens=1035.7, nsentences=32, sample_size=1035.7, sample_size_v1=0, sample_size_v2=0, ppl=20.39, wps=522.1, ups=0.5, wpb=1035.7, bsz=32, num_updates=10790, lr=3.75316e-05, gnorm=1.702, clip=100, loss_scale=256, train_wall=20, gb_free=15.2, wall=29454
2023-01-09 11:48:48 - progress_bar.py[line:272] - INFO: epoch 003:   3485 / 3665 loss=5.312, loss_v1=0, loss_v2=0, nll_loss=4.428, ntokens=850.7, nsentences=32, sample_size=850.7, sample_size_v1=0, sample_size_v2=0, ppl=21.53, wps=428.9, ups=0.5, wpb=850.7, bsz=32, num_updates=10800, lr=3.75171e-05, gnorm=1.966, clip=100, loss_scale=256, train_wall=20, gb_free=15.4, wall=29474
2023-01-09 11:49:08 - progress_bar.py[line:272] - INFO: epoch 003:   3495 / 3665 loss=5.229, loss_v1=0, loss_v2=0, nll_loss=4.337, ntokens=696.4, nsentences=32, sample_size=696.4, sample_size_v1=0, sample_size_v2=0, ppl=20.2, wps=353.6, ups=0.51, wpb=696.4, bsz=32, num_updates=10810, lr=3.75025e-05, gnorm=2.45, clip=100, loss_scale=256, train_wall=20, gb_free=15.2, wall=29494
2023-01-09 11:49:27 - progress_bar.py[line:272] - INFO: epoch 003:   3505 / 3665 loss=5.216, loss_v1=0, loss_v2=0, nll_loss=4.323, ntokens=921.7, nsentences=32, sample_size=921.7, sample_size_v1=0, sample_size_v2=0, ppl=20.02, wps=464.9, ups=0.5, wpb=921.7, bsz=32, num_updates=10820, lr=3.7488e-05, gnorm=1.946, clip=100, loss_scale=512, train_wall=20, gb_free=15.3, wall=29514
2023-01-09 11:49:47 - progress_bar.py[line:272] - INFO: epoch 003:   3515 / 3665 loss=5.328, loss_v1=0, loss_v2=0, nll_loss=4.448, ntokens=1065.2, nsentences=32, sample_size=1065.2, sample_size_v1=0, sample_size_v2=0, ppl=21.83, wps=534.8, ups=0.5, wpb=1065.2, bsz=32, num_updates=10830, lr=3.74735e-05, gnorm=1.654, clip=100, loss_scale=512, train_wall=20, gb_free=15.3, wall=29534
2023-01-09 11:50:07 - progress_bar.py[line:272] - INFO: epoch 003:   3525 / 3665 loss=5.225, loss_v1=0, loss_v2=0, nll_loss=4.333, ntokens=809.2, nsentences=32, sample_size=809.2, sample_size_v1=0, sample_size_v2=0, ppl=20.15, wps=408.9, ups=0.51, wpb=809.2, bsz=32, num_updates=10840, lr=3.7459e-05, gnorm=2.031, clip=100, loss_scale=512, train_wall=20, gb_free=15.4, wall=29553
2023-01-09 11:50:27 - progress_bar.py[line:272] - INFO: epoch 003:   3535 / 3665 loss=5.211, loss_v1=0, loss_v2=0, nll_loss=4.313, ntokens=969.8, nsentences=32, sample_size=969.8, sample_size_v1=0, sample_size_v2=0, ppl=19.88, wps=487.3, ups=0.5, wpb=969.8, bsz=32, num_updates=10850, lr=3.74445e-05, gnorm=1.906, clip=100, loss_scale=512, train_wall=20, gb_free=15.2, wall=29573
2023-01-09 11:50:47 - progress_bar.py[line:272] - INFO: epoch 003:   3545 / 3665 loss=5.347, loss_v1=0, loss_v2=0, nll_loss=4.469, ntokens=1110.7, nsentences=32, sample_size=1110.7, sample_size_v1=0, sample_size_v2=0, ppl=22.15, wps=557, ups=0.5, wpb=1110.7, bsz=32, num_updates=10860, lr=3.743e-05, gnorm=1.684, clip=100, loss_scale=512, train_wall=20, gb_free=15.1, wall=29593
2023-01-09 11:51:07 - progress_bar.py[line:272] - INFO: epoch 003:   3555 / 3665 loss=5.192, loss_v1=0, loss_v2=0, nll_loss=4.297, ntokens=865.3, nsentences=32, sample_size=865.3, sample_size_v1=0, sample_size_v2=0, ppl=19.66, wps=436.8, ups=0.5, wpb=865.3, bsz=32, num_updates=10870, lr=3.74155e-05, gnorm=1.918, clip=100, loss_scale=512, train_wall=20, gb_free=15.6, wall=29613
2023-01-09 11:51:27 - progress_bar.py[line:272] - INFO: epoch 003:   3565 / 3665 loss=5.243, loss_v1=0, loss_v2=0, nll_loss=4.353, ntokens=981.8, nsentences=32, sample_size=981.8, sample_size_v1=0, sample_size_v2=0, ppl=20.43, wps=493.7, ups=0.5, wpb=981.8, bsz=32, num_updates=10880, lr=3.74009e-05, gnorm=1.899, clip=100, loss_scale=512, train_wall=20, gb_free=15.4, wall=29633
2023-01-09 11:51:47 - progress_bar.py[line:272] - INFO: epoch 003:   3575 / 3665 loss=5.201, loss_v1=0, loss_v2=0, nll_loss=4.306, ntokens=1069.7, nsentences=32, sample_size=1069.7, sample_size_v1=0, sample_size_v2=0, ppl=19.78, wps=536.8, ups=0.5, wpb=1069.7, bsz=32, num_updates=10890, lr=3.73864e-05, gnorm=1.539, clip=100, loss_scale=512, train_wall=20, gb_free=15, wall=29653
2023-01-09 11:52:06 - progress_bar.py[line:272] - INFO: epoch 003:   3585 / 3665 loss=5.285, loss_v1=0, loss_v2=0, nll_loss=4.399, ntokens=818.2, nsentences=32, sample_size=818.2, sample_size_v1=0, sample_size_v2=0, ppl=21.1, wps=413.2, ups=0.5, wpb=818.2, bsz=32, num_updates=10900, lr=3.73719e-05, gnorm=2.01, clip=100, loss_scale=512, train_wall=20, gb_free=15.4, wall=29673
2023-01-09 11:52:26 - progress_bar.py[line:272] - INFO: epoch 003:   3595 / 3665 loss=5.251, loss_v1=0, loss_v2=0, nll_loss=4.362, ntokens=875.9, nsentences=32, sample_size=875.9, sample_size_v1=0, sample_size_v2=0, ppl=20.56, wps=442.2, ups=0.5, wpb=875.9, bsz=32, num_updates=10910, lr=3.73574e-05, gnorm=2.076, clip=100, loss_scale=512, train_wall=20, gb_free=15.2, wall=29692
2023-01-09 11:52:46 - progress_bar.py[line:272] - INFO: epoch 003:   3605 / 3665 loss=5.253, loss_v1=0, loss_v2=0, nll_loss=4.366, ntokens=985.8, nsentences=32, sample_size=985.8, sample_size_v1=0, sample_size_v2=0, ppl=20.62, wps=496.7, ups=0.5, wpb=985.8, bsz=32, num_updates=10920, lr=3.73429e-05, gnorm=1.812, clip=100, loss_scale=512, train_wall=20, gb_free=15.3, wall=29712
2023-01-09 11:53:06 - progress_bar.py[line:272] - INFO: epoch 003:   3615 / 3665 loss=5.304, loss_v1=0, loss_v2=0, nll_loss=4.42, ntokens=879.3, nsentences=32, sample_size=879.3, sample_size_v1=0, sample_size_v2=0, ppl=21.4, wps=443.6, ups=0.5, wpb=879.3, bsz=32, num_updates=10930, lr=3.73284e-05, gnorm=1.924, clip=100, loss_scale=512, train_wall=20, gb_free=15.4, wall=29732
2023-01-09 11:53:26 - progress_bar.py[line:272] - INFO: epoch 003:   3625 / 3665 loss=5.23, loss_v1=0, loss_v2=0, nll_loss=4.338, ntokens=873.4, nsentences=32, sample_size=873.4, sample_size_v1=0, sample_size_v2=0, ppl=20.22, wps=441, ups=0.5, wpb=873.4, bsz=32, num_updates=10940, lr=3.73139e-05, gnorm=2.047, clip=100, loss_scale=512, train_wall=20, gb_free=14.5, wall=29752
2023-01-09 11:53:46 - progress_bar.py[line:272] - INFO: epoch 003:   3635 / 3665 loss=5.219, loss_v1=0, loss_v2=0, nll_loss=4.326, ntokens=1151.3, nsentences=32, sample_size=1151.3, sample_size_v1=0, sample_size_v2=0, ppl=20.06, wps=577.5, ups=0.5, wpb=1151.3, bsz=32, num_updates=10950, lr=3.72994e-05, gnorm=1.563, clip=100, loss_scale=512, train_wall=20, gb_free=15.3, wall=29772
2023-01-09 11:54:05 - progress_bar.py[line:272] - INFO: epoch 003:   3645 / 3665 loss=5.302, loss_v1=0, loss_v2=0, nll_loss=4.42, ntokens=885.3, nsentences=32, sample_size=885.3, sample_size_v1=0, sample_size_v2=0, ppl=21.4, wps=446.4, ups=0.5, wpb=885.3, bsz=32, num_updates=10960, lr=3.72848e-05, gnorm=2.049, clip=100, loss_scale=512, train_wall=20, gb_free=15.5, wall=29792
2023-01-09 11:54:25 - progress_bar.py[line:272] - INFO: epoch 003:   3655 / 3665 loss=5.217, loss_v1=0, loss_v2=0, nll_loss=4.323, ntokens=852.2, nsentences=32, sample_size=852.2, sample_size_v1=0, sample_size_v2=0, ppl=20.01, wps=430, ups=0.5, wpb=852.2, bsz=32, num_updates=10970, lr=3.72703e-05, gnorm=2.044, clip=100, loss_scale=512, train_wall=20, gb_free=15.5, wall=29811
2023-01-09 11:54:44 - progress_bar.py[line:272] - INFO: epoch 003:   3665 / 3665 loss=5.261, loss_v1=0, loss_v2=0, nll_loss=4.372, ntokens=1014.2, nsentences=30.8, sample_size=1014.2, sample_size_v1=0, sample_size_v2=0, ppl=20.71, wps=528.8, ups=0.52, wpb=1014.2, bsz=30.8, num_updates=10980, lr=3.72558e-05, gnorm=1.71, clip=100, loss_scale=512, train_wall=19, gb_free=14.7, wall=29831
2023-01-09 11:54:44 - train.py[line:445] - INFO: begin validation on "valid" subset
slice_id 0 seek offset 0
slice_id 0 seek offset 0
2023-01-09 11:59:36 - progress_bar.py[line:282] - INFO: epoch 003 | valid on 'valid' subset | loss 5.251 | loss_v1 0 | loss_v2 0 | nll_loss 4.345 | ntokens 117.543 | nsentences 4 | sample_size 117.543 | sample_size_v1 0 | sample_size_v2 0 | AP 0 | total positives 21.8126 | TP 0 | FP 6.14216 | ppl 20.32 | wps 505 | wpb 117.5 | bsz 4 | num_updates 10980 | best_AP 0
2023-01-09 11:59:36 - checkpoint_utils.py[line:64] - INFO: Preparing to save checkpoint for epoch 3 @ 10980 updates
2023-01-09 11:59:36 - trainer.py[line:431] - INFO: Saving checkpoint to ../../checkpoints/OFA/detection_checkpoints/10_5e-5_512/checkpoint_best.pt
2023-01-09 11:59:56 - trainer.py[line:441] - INFO: Finished saving checkpoint to ../../checkpoints/OFA/detection_checkpoints/10_5e-5_512/checkpoint_best.pt
2023-01-09 12:00:29 - checkpoint_utils.py[line:133] - INFO: Saved checkpoint ../../checkpoints/OFA/detection_checkpoints/10_5e-5_512/checkpoint_best.pt (epoch 3 @ 10980 updates, score 0.0) (writing took 53.64436869928613 seconds)
2023-01-09 12:00:29 - train.py[line:332] - INFO: end of epoch 3 (average epoch stats below)
2023-01-09 12:00:29 - progress_bar.py[line:282] - INFO: epoch 003 | loss 5.303 | loss_v1 0 | loss_v2 0 | nll_loss 4.419 | ntokens 923.158 | nsentences 31.996 | sample_size 923.158 | sample_size_v1 0 | sample_size_v2 0 | AP 0 | ppl 21.39 | wps 335.5 | ups 0.36 | wpb 923.2 | bsz 32 | num_updates 10980 | lr 3.72558e-05 | gnorm 1.843 | clip 99.9 | loss_scale 512 | train_wall 7223 | gb_free 14.7 | wall 30176
2023-01-09 12:00:29 - trainer.py[line:639] - INFO: loading train data for epoch 4
local datafile ../../dataset/OFA_data/train.tsv slice_id 0 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../dataset/OFA_data/train.tsv slice_id 0 finished initializing row_count and line_idx-to-offset mapping
file ../../dataset/OFA_data/train.tsv slice_id 0 row count 117266 total row count 117266
slice_id 0 seek offset 0
2023-01-09 12:01:31 - trainer.py[line:703] - INFO: begin training epoch 4
2023-01-09 12:01:31 - train.py[line:305] - INFO: Start iterating over samples
2023-01-09 12:01:51 - progress_bar.py[line:272] - INFO: epoch 004:     10 / 3665 loss=5.341, loss_v1=0, loss_v2=0, nll_loss=4.463, ntokens=870.4, nsentences=32, sample_size=870.4, sample_size_v1=0, sample_size_v2=0, ppl=22.06, wps=20.4, ups=0.02, wpb=870.4, bsz=32, num_updates=10990, lr=3.72413e-05, gnorm=2.118, clip=100, loss_scale=512, train_wall=19, gb_free=15.4, wall=30258
2023-01-09 12:02:11 - progress_bar.py[line:272] - INFO: epoch 004:     20 / 3665 loss=5.208, loss_v1=0, loss_v2=0, nll_loss=4.314, ntokens=883.2, nsentences=32, sample_size=883.2, sample_size_v1=0, sample_size_v2=0, ppl=19.89, wps=454.7, ups=0.51, wpb=883.2, bsz=32, num_updates=11000, lr=3.72268e-05, gnorm=2.067, clip=100, loss_scale=512, train_wall=19, gb_free=15.6, wall=30277
2023-01-09 12:02:11 - train.py[line:445] - INFO: begin validation on "valid" subset
slice_id 0 seek offset 0
slice_id 0 seek offset 0
2023-01-09 12:06:52 - progress_bar.py[line:282] - INFO: epoch 004 | valid on 'valid' subset | loss 5.24 | loss_v1 0 | loss_v2 0 | nll_loss 4.332 | ntokens 116.569 | nsentences 4 | sample_size 116.569 | sample_size_v1 0 | sample_size_v2 0 | AP 0 | total positives 21.6252 | TP 0 | FP 5.26333 | ppl 20.14 | wps 518.5 | wpb 116.6 | bsz 4 | num_updates 11000 | best_AP 0
2023-01-09 12:06:52 - checkpoint_utils.py[line:64] - INFO: Preparing to save checkpoint for epoch 4 @ 11000 updates
2023-01-09 12:06:52 - trainer.py[line:431] - INFO: Saving checkpoint to ../../checkpoints/OFA/detection_checkpoints/10_5e-5_512/checkpoint_4_11000.pt
2023-01-09 12:06:55 - trainer.py[line:441] - INFO: Finished saving checkpoint to ../../checkpoints/OFA/detection_checkpoints/10_5e-5_512/checkpoint_4_11000.pt
2023-01-09 12:08:11 - checkpoint_utils.py[line:133] - INFO: Saved checkpoint ../../checkpoints/OFA/detection_checkpoints/10_5e-5_512/checkpoint_4_11000.pt (epoch 4 @ 11000 updates, score 0.0) (writing took 79.650645586662 seconds)
2023-01-09 12:08:31 - progress_bar.py[line:272] - INFO: epoch 004:     30 / 3665 loss=5.262, loss_v1=0, loss_v2=0, nll_loss=4.374, ntokens=993.3, nsentences=32, sample_size=993.3, sample_size_v1=0, sample_size_v2=0, ppl=20.74, wps=26.1, ups=0.03, wpb=993.3, bsz=32, num_updates=11010, lr=3.72123e-05, gnorm=1.763, clip=100, loss_scale=512, train_wall=19, gb_free=15.5, wall=30657
2023-01-09 12:08:50 - progress_bar.py[line:272] - INFO: epoch 004:     40 / 3665 loss=5.22, loss_v1=0, loss_v2=0, nll_loss=4.327, ntokens=783.1, nsentences=32, sample_size=783.1, sample_size_v1=0, sample_size_v2=0, ppl=20.07, wps=404.2, ups=0.52, wpb=783.1, bsz=32, num_updates=11020, lr=3.71978e-05, gnorm=2.235, clip=100, loss_scale=512, train_wall=19, gb_free=15.3, wall=30676
2023-01-09 12:09:09 - progress_bar.py[line:272] - INFO: epoch 004:     50 / 3665 loss=5.228, loss_v1=0, loss_v2=0, nll_loss=4.338, ntokens=944.9, nsentences=32, sample_size=944.9, sample_size_v1=0, sample_size_v2=0, ppl=20.22, wps=484.1, ups=0.51, wpb=944.9, bsz=32, num_updates=11030, lr=3.71832e-05, gnorm=1.904, clip=100, loss_scale=512, train_wall=19, gb_free=15.5, wall=30696
2023-01-09 12:09:29 - progress_bar.py[line:272] - INFO: epoch 004:     60 / 3665 loss=5.259, loss_v1=0, loss_v2=0, nll_loss=4.369, ntokens=945.2, nsentences=32, sample_size=945.2, sample_size_v1=0, sample_size_v2=0, ppl=20.67, wps=481.9, ups=0.51, wpb=945.2, bsz=32, num_updates=11040, lr=3.71687e-05, gnorm=2.038, clip=100, loss_scale=512, train_wall=20, gb_free=15.3, wall=30715
2023-01-09 12:09:49 - progress_bar.py[line:272] - INFO: epoch 004:     70 / 3665 loss=5.233, loss_v1=0, loss_v2=0, nll_loss=4.339, ntokens=767.7, nsentences=32, sample_size=767.7, sample_size_v1=0, sample_size_v2=0, ppl=20.24, wps=392.3, ups=0.51, wpb=767.7, bsz=32, num_updates=11050, lr=3.71542e-05, gnorm=2.227, clip=100, loss_scale=512, train_wall=20, gb_free=15.4, wall=30735
2023-01-09 12:10:08 - progress_bar.py[line:272] - INFO: epoch 004:     80 / 3665 loss=5.24, loss_v1=0, loss_v2=0, nll_loss=4.348, ntokens=1023.8, nsentences=32, sample_size=1023.8, sample_size_v1=0, sample_size_v2=0, ppl=20.37, wps=522.4, ups=0.51, wpb=1023.8, bsz=32, num_updates=11060, lr=3.71397e-05, gnorm=1.675, clip=100, loss_scale=512, train_wall=20, gb_free=15.2, wall=30755
2023-01-09 12:10:28 - progress_bar.py[line:272] - INFO: epoch 004:     90 / 3665 loss=5.284, loss_v1=0, loss_v2=0, nll_loss=4.4, ntokens=835.8, nsentences=32, sample_size=835.8, sample_size_v1=0, sample_size_v2=0, ppl=21.11, wps=427.8, ups=0.51, wpb=835.8, bsz=32, num_updates=11070, lr=3.71252e-05, gnorm=2.234, clip=100, loss_scale=512, train_wall=20, gb_free=15.1, wall=30774
2023-01-09 12:10:47 - progress_bar.py[line:272] - INFO: epoch 004:    100 / 3665 loss=5.318, loss_v1=0, loss_v2=0, nll_loss=4.436, ntokens=968.8, nsentences=32, sample_size=968.8, sample_size_v1=0, sample_size_v2=0, ppl=21.64, wps=494, ups=0.51, wpb=968.8, bsz=32, num_updates=11080, lr=3.71107e-05, gnorm=1.774, clip=100, loss_scale=512, train_wall=20, gb_free=15, wall=30794
2023-01-09 12:11:07 - progress_bar.py[line:272] - INFO: epoch 004:    110 / 3665 loss=5.236, loss_v1=0, loss_v2=0, nll_loss=4.345, ntokens=1109.7, nsentences=32, sample_size=1109.7, sample_size_v1=0, sample_size_v2=0, ppl=20.33, wps=563.5, ups=0.51, wpb=1109.7, bsz=32, num_updates=11090, lr=3.70962e-05, gnorm=1.603, clip=100, loss_scale=512, train_wall=20, gb_free=15.4, wall=30813
2023-01-09 12:11:27 - progress_bar.py[line:272] - INFO: epoch 004:    120 / 3665 loss=5.238, loss_v1=0, loss_v2=0, nll_loss=4.346, ntokens=868.7, nsentences=32, sample_size=868.7, sample_size_v1=0, sample_size_v2=0, ppl=20.34, wps=443.6, ups=0.51, wpb=868.7, bsz=32, num_updates=11100, lr=3.70817e-05, gnorm=1.91, clip=100, loss_scale=512, train_wall=20, gb_free=15.6, wall=30833
2023-01-09 12:11:46 - progress_bar.py[line:272] - INFO: epoch 004:    130 / 3665 loss=5.23, loss_v1=0, loss_v2=0, nll_loss=4.337, ntokens=925.3, nsentences=32, sample_size=925.3, sample_size_v1=0, sample_size_v2=0, ppl=20.2, wps=471.8, ups=0.51, wpb=925.3, bsz=32, num_updates=11110, lr=3.70671e-05, gnorm=1.966, clip=100, loss_scale=512, train_wall=20, gb_free=15.3, wall=30853
2023-01-09 12:12:06 - progress_bar.py[line:272] - INFO: epoch 004:    140 / 3665 loss=5.208, loss_v1=0, loss_v2=0, nll_loss=4.316, ntokens=1068.5, nsentences=32, sample_size=1068.5, sample_size_v1=0, sample_size_v2=0, ppl=19.92, wps=542.6, ups=0.51, wpb=1068.5, bsz=32, num_updates=11120, lr=3.70526e-05, gnorm=1.622, clip=100, loss_scale=512, train_wall=20, gb_free=14.9, wall=30872
2023-01-09 12:12:26 - progress_bar.py[line:272] - INFO: epoch 004:    150 / 3665 loss=5.275, loss_v1=0, loss_v2=0, nll_loss=4.389, ntokens=781.7, nsentences=32, sample_size=781.7, sample_size_v1=0, sample_size_v2=0, ppl=20.96, wps=400, ups=0.51, wpb=781.7, bsz=32, num_updates=11130, lr=3.70381e-05, gnorm=2.096, clip=100, loss_scale=512, train_wall=20, gb_free=15.5, wall=30892
2023-01-09 12:12:29 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 256.0
2023-01-09 12:12:47 - progress_bar.py[line:272] - INFO: epoch 004:    161 / 3665 loss=5.191, loss_v1=0, loss_v2=0, nll_loss=4.292, ntokens=931.1, nsentences=32, sample_size=931.1, sample_size_v1=0, sample_size_v2=0, ppl=19.59, wps=427.9, ups=0.46, wpb=931.1, bsz=32, num_updates=11140, lr=3.70236e-05, gnorm=1.827, clip=100, loss_scale=256, train_wall=22, gb_free=15.6, wall=30914
2023-01-09 12:13:07 - progress_bar.py[line:272] - INFO: epoch 004:    171 / 3665 loss=5.316, loss_v1=0, loss_v2=0, nll_loss=4.435, ntokens=1077, nsentences=32, sample_size=1077, sample_size_v1=0, sample_size_v2=0, ppl=21.63, wps=540.1, ups=0.5, wpb=1077, bsz=32, num_updates=11150, lr=3.70091e-05, gnorm=1.671, clip=100, loss_scale=256, train_wall=20, gb_free=15.1, wall=30934
2023-01-09 12:13:27 - progress_bar.py[line:272] - INFO: epoch 004:    181 / 3665 loss=5.185, loss_v1=0, loss_v2=0, nll_loss=4.286, ntokens=764.3, nsentences=32, sample_size=764.3, sample_size_v1=0, sample_size_v2=0, ppl=19.51, wps=385.6, ups=0.5, wpb=764.3, bsz=32, num_updates=11160, lr=3.69946e-05, gnorm=2.22, clip=100, loss_scale=256, train_wall=20, gb_free=15.4, wall=30953
2023-01-09 12:13:47 - progress_bar.py[line:272] - INFO: epoch 004:    191 / 3665 loss=5.211, loss_v1=0, loss_v2=0, nll_loss=4.32, ntokens=985.5, nsentences=32, sample_size=985.5, sample_size_v1=0, sample_size_v2=0, ppl=19.98, wps=495.4, ups=0.5, wpb=985.5, bsz=32, num_updates=11170, lr=3.69801e-05, gnorm=1.799, clip=100, loss_scale=256, train_wall=20, gb_free=15.5, wall=30973
2023-01-09 12:14:07 - progress_bar.py[line:272] - INFO: epoch 004:    201 / 3665 loss=5.253, loss_v1=0, loss_v2=0, nll_loss=4.365, ntokens=912.7, nsentences=32, sample_size=912.7, sample_size_v1=0, sample_size_v2=0, ppl=20.6, wps=459.7, ups=0.5, wpb=912.7, bsz=32, num_updates=11180, lr=3.69655e-05, gnorm=1.877, clip=100, loss_scale=256, train_wall=20, gb_free=15.3, wall=30993
2023-01-09 12:14:27 - progress_bar.py[line:272] - INFO: epoch 004:    211 / 3665 loss=5.254, loss_v1=0, loss_v2=0, nll_loss=4.364, ntokens=759.4, nsentences=32, sample_size=759.4, sample_size_v1=0, sample_size_v2=0, ppl=20.6, wps=384.1, ups=0.51, wpb=759.4, bsz=32, num_updates=11190, lr=3.6951e-05, gnorm=2.179, clip=100, loss_scale=256, train_wall=20, gb_free=15.5, wall=31013
2023-01-09 12:14:46 - progress_bar.py[line:272] - INFO: epoch 004:    221 / 3665 loss=5.184, loss_v1=0, loss_v2=0, nll_loss=4.289, ntokens=1018.6, nsentences=32, sample_size=1018.6, sample_size_v1=0, sample_size_v2=0, ppl=19.55, wps=512, ups=0.5, wpb=1018.6, bsz=32, num_updates=11200, lr=3.69365e-05, gnorm=1.676, clip=100, loss_scale=256, train_wall=20, gb_free=15, wall=31033
2023-01-09 12:15:06 - progress_bar.py[line:272] - INFO: epoch 004:    231 / 3665 loss=5.297, loss_v1=0, loss_v2=0, nll_loss=4.411, ntokens=963, nsentences=32, sample_size=963, sample_size_v1=0, sample_size_v2=0, ppl=21.28, wps=485.2, ups=0.5, wpb=963, bsz=32, num_updates=11210, lr=3.6922e-05, gnorm=1.921, clip=100, loss_scale=256, train_wall=20, gb_free=15.5, wall=31053
2023-01-09 12:15:26 - progress_bar.py[line:272] - INFO: epoch 004:    241 / 3665 loss=5.198, loss_v1=0, loss_v2=0, nll_loss=4.304, ntokens=800.6, nsentences=32, sample_size=800.6, sample_size_v1=0, sample_size_v2=0, ppl=19.75, wps=403.9, ups=0.5, wpb=800.6, bsz=32, num_updates=11220, lr=3.69075e-05, gnorm=2.215, clip=100, loss_scale=256, train_wall=20, gb_free=15.4, wall=31072
2023-01-09 12:15:46 - progress_bar.py[line:272] - INFO: epoch 004:    251 / 3665 loss=5.233, loss_v1=0, loss_v2=0, nll_loss=4.34, ntokens=1051.2, nsentences=32, sample_size=1051.2, sample_size_v1=0, sample_size_v2=0, ppl=20.26, wps=528, ups=0.5, wpb=1051.2, bsz=32, num_updates=11230, lr=3.6893e-05, gnorm=1.688, clip=100, loss_scale=256, train_wall=20, gb_free=15.5, wall=31092
2023-01-09 12:16:06 - progress_bar.py[line:272] - INFO: epoch 004:    261 / 3665 loss=5.225, loss_v1=0, loss_v2=0, nll_loss=4.332, ntokens=740.6, nsentences=32, sample_size=740.6, sample_size_v1=0, sample_size_v2=0, ppl=20.14, wps=375, ups=0.51, wpb=740.6, bsz=32, num_updates=11240, lr=3.68785e-05, gnorm=2.239, clip=100, loss_scale=256, train_wall=20, gb_free=15.5, wall=31112
2023-01-09 12:16:26 - progress_bar.py[line:272] - INFO: epoch 004:    271 / 3665 loss=5.268, loss_v1=0, loss_v2=0, nll_loss=4.382, ntokens=947.2, nsentences=32, sample_size=947.2, sample_size_v1=0, sample_size_v2=0, ppl=20.84, wps=478, ups=0.5, wpb=947.2, bsz=32, num_updates=11250, lr=3.6864e-05, gnorm=1.949, clip=100, loss_scale=256, train_wall=20, gb_free=15.4, wall=31132
2023-01-09 12:16:45 - progress_bar.py[line:272] - INFO: epoch 004:    281 / 3665 loss=5.259, loss_v1=0, loss_v2=0, nll_loss=4.369, ntokens=891.9, nsentences=32, sample_size=891.9, sample_size_v1=0, sample_size_v2=0, ppl=20.66, wps=450.8, ups=0.51, wpb=891.9, bsz=32, num_updates=11260, lr=3.68494e-05, gnorm=1.951, clip=100, loss_scale=256, train_wall=20, gb_free=15.5, wall=31152
2023-01-09 12:17:05 - progress_bar.py[line:272] - INFO: epoch 004:    291 / 3665 loss=5.227, loss_v1=0, loss_v2=0, nll_loss=4.336, ntokens=804.9, nsentences=32, sample_size=804.9, sample_size_v1=0, sample_size_v2=0, ppl=20.19, wps=407, ups=0.51, wpb=804.9, bsz=32, num_updates=11270, lr=3.68349e-05, gnorm=2.184, clip=100, loss_scale=256, train_wall=20, gb_free=14.9, wall=31171
2023-01-09 12:17:25 - progress_bar.py[line:272] - INFO: epoch 004:    301 / 3665 loss=5.206, loss_v1=0, loss_v2=0, nll_loss=4.313, ntokens=990.9, nsentences=32, sample_size=990.9, sample_size_v1=0, sample_size_v2=0, ppl=19.88, wps=499.9, ups=0.5, wpb=990.9, bsz=32, num_updates=11280, lr=3.68204e-05, gnorm=1.867, clip=100, loss_scale=256, train_wall=20, gb_free=15.3, wall=31191
2023-01-09 12:17:45 - progress_bar.py[line:272] - INFO: epoch 004:    311 / 3665 loss=5.235, loss_v1=0, loss_v2=0, nll_loss=4.341, ntokens=1003.4, nsentences=32, sample_size=1003.4, sample_size_v1=0, sample_size_v2=0, ppl=20.27, wps=505.7, ups=0.5, wpb=1003.4, bsz=32, num_updates=11290, lr=3.68059e-05, gnorm=1.594, clip=100, loss_scale=256, train_wall=20, gb_free=15.5, wall=31211
2023-01-09 12:18:05 - progress_bar.py[line:272] - INFO: epoch 004:    321 / 3665 loss=5.235, loss_v1=0, loss_v2=0, nll_loss=4.345, ntokens=744, nsentences=32, sample_size=744, sample_size_v1=0, sample_size_v2=0, ppl=20.33, wps=378.3, ups=0.51, wpb=744, bsz=32, num_updates=11300, lr=3.67914e-05, gnorm=2.202, clip=100, loss_scale=256, train_wall=20, gb_free=15.7, wall=31231
2023-01-09 12:18:24 - progress_bar.py[line:272] - INFO: epoch 004:    331 / 3665 loss=5.169, loss_v1=0, loss_v2=0, nll_loss=4.272, ntokens=1017.8, nsentences=32, sample_size=1017.8, sample_size_v1=0, sample_size_v2=0, ppl=19.32, wps=514.7, ups=0.51, wpb=1017.8, bsz=32, num_updates=11310, lr=3.67769e-05, gnorm=1.73, clip=100, loss_scale=256, train_wall=20, gb_free=15.3, wall=31251
2023-01-09 12:18:44 - progress_bar.py[line:272] - INFO: epoch 004:    341 / 3665 loss=5.194, loss_v1=0, loss_v2=0, nll_loss=4.297, ntokens=822.6, nsentences=32, sample_size=822.6, sample_size_v1=0, sample_size_v2=0, ppl=19.65, wps=416.6, ups=0.51, wpb=822.6, bsz=32, num_updates=11320, lr=3.67624e-05, gnorm=1.986, clip=100, loss_scale=256, train_wall=20, gb_free=15.6, wall=31270
2023-01-09 12:19:04 - progress_bar.py[line:272] - INFO: epoch 004:    351 / 3665 loss=5.233, loss_v1=0, loss_v2=0, nll_loss=4.343, ntokens=799, nsentences=32, sample_size=799, sample_size_v1=0, sample_size_v2=0, ppl=20.29, wps=405.4, ups=0.51, wpb=799, bsz=32, num_updates=11330, lr=3.67478e-05, gnorm=2.025, clip=100, loss_scale=256, train_wall=20, gb_free=15.3, wall=31290
2023-01-09 12:19:24 - progress_bar.py[line:272] - INFO: epoch 004:    361 / 3665 loss=5.193, loss_v1=0, loss_v2=0, nll_loss=4.3, ntokens=998, nsentences=32, sample_size=998, sample_size_v1=0, sample_size_v2=0, ppl=19.7, wps=504.2, ups=0.51, wpb=998, bsz=32, num_updates=11340, lr=3.67333e-05, gnorm=1.708, clip=100, loss_scale=256, train_wall=20, gb_free=15.4, wall=31310
2023-01-09 12:19:43 - progress_bar.py[line:272] - INFO: epoch 004:    371 / 3665 loss=5.277, loss_v1=0, loss_v2=0, nll_loss=4.39, ntokens=791.8, nsentences=32, sample_size=791.8, sample_size_v1=0, sample_size_v2=0, ppl=20.96, wps=401.3, ups=0.51, wpb=791.8, bsz=32, num_updates=11350, lr=3.67188e-05, gnorm=2.176, clip=100, loss_scale=256, train_wall=20, gb_free=15.4, wall=31330
2023-01-09 12:20:03 - progress_bar.py[line:272] - INFO: epoch 004:    381 / 3665 loss=5.219, loss_v1=0, loss_v2=0, nll_loss=4.324, ntokens=925.8, nsentences=32, sample_size=925.8, sample_size_v1=0, sample_size_v2=0, ppl=20.03, wps=465.1, ups=0.5, wpb=925.8, bsz=32, num_updates=11360, lr=3.67043e-05, gnorm=1.986, clip=100, loss_scale=256, train_wall=20, gb_free=15.4, wall=31349
2023-01-09 12:20:23 - progress_bar.py[line:272] - INFO: epoch 004:    391 / 3665 loss=5.217, loss_v1=0, loss_v2=0, nll_loss=4.324, ntokens=988.2, nsentences=32, sample_size=988.2, sample_size_v1=0, sample_size_v2=0, ppl=20.03, wps=501, ups=0.51, wpb=988.2, bsz=32, num_updates=11370, lr=3.66898e-05, gnorm=1.773, clip=100, loss_scale=256, train_wall=20, gb_free=15.7, wall=31369
2023-01-09 12:20:43 - progress_bar.py[line:272] - INFO: epoch 004:    401 / 3665 loss=5.192, loss_v1=0, loss_v2=0, nll_loss=4.296, ntokens=709.9, nsentences=32, sample_size=709.9, sample_size_v1=0, sample_size_v2=0, ppl=19.64, wps=360.7, ups=0.51, wpb=709.9, bsz=32, num_updates=11380, lr=3.66753e-05, gnorm=2.239, clip=100, loss_scale=256, train_wall=20, gb_free=15.2, wall=31389
2023-01-09 12:21:02 - progress_bar.py[line:272] - INFO: epoch 004:    411 / 3665 loss=5.19, loss_v1=0, loss_v2=0, nll_loss=4.294, ntokens=955.8, nsentences=32, sample_size=955.8, sample_size_v1=0, sample_size_v2=0, ppl=19.62, wps=482.8, ups=0.51, wpb=955.8, bsz=32, num_updates=11390, lr=3.66608e-05, gnorm=1.982, clip=100, loss_scale=256, train_wall=20, gb_free=15.1, wall=31409
2023-01-09 12:21:22 - progress_bar.py[line:272] - INFO: epoch 004:    421 / 3665 loss=5.267, loss_v1=0, loss_v2=0, nll_loss=4.378, ntokens=950.6, nsentences=32, sample_size=950.6, sample_size_v1=0, sample_size_v2=0, ppl=20.8, wps=482, ups=0.51, wpb=950.6, bsz=32, num_updates=11400, lr=3.66463e-05, gnorm=1.911, clip=100, loss_scale=256, train_wall=20, gb_free=15.5, wall=31428
2023-01-09 12:21:42 - progress_bar.py[line:272] - INFO: epoch 004:    431 / 3665 loss=5.263, loss_v1=0, loss_v2=0, nll_loss=4.372, ntokens=906.9, nsentences=32, sample_size=906.9, sample_size_v1=0, sample_size_v2=0, ppl=20.71, wps=458.4, ups=0.51, wpb=906.9, bsz=32, num_updates=11410, lr=3.66317e-05, gnorm=2.013, clip=100, loss_scale=256, train_wall=20, gb_free=15.1, wall=31448
2023-01-09 12:22:02 - progress_bar.py[line:272] - INFO: epoch 004:    441 / 3665 loss=5.245, loss_v1=0, loss_v2=0, nll_loss=4.357, ntokens=1018.9, nsentences=32, sample_size=1018.9, sample_size_v1=0, sample_size_v2=0, ppl=20.49, wps=516.4, ups=0.51, wpb=1018.9, bsz=32, num_updates=11420, lr=3.66172e-05, gnorm=1.868, clip=100, loss_scale=256, train_wall=20, gb_free=15.1, wall=31468
2023-01-09 12:22:21 - progress_bar.py[line:272] - INFO: epoch 004:    451 / 3665 loss=5.216, loss_v1=0, loss_v2=0, nll_loss=4.322, ntokens=890.7, nsentences=32, sample_size=890.7, sample_size_v1=0, sample_size_v2=0, ppl=20, wps=450.9, ups=0.51, wpb=890.7, bsz=32, num_updates=11430, lr=3.66027e-05, gnorm=1.947, clip=100, loss_scale=256, train_wall=20, gb_free=15.6, wall=31488
2023-01-09 12:22:41 - progress_bar.py[line:272] - INFO: epoch 004:    461 / 3665 loss=5.245, loss_v1=0, loss_v2=0, nll_loss=4.353, ntokens=917.6, nsentences=32, sample_size=917.6, sample_size_v1=0, sample_size_v2=0, ppl=20.44, wps=464.8, ups=0.51, wpb=917.6, bsz=32, num_updates=11440, lr=3.65882e-05, gnorm=1.948, clip=100, loss_scale=256, train_wall=20, gb_free=15.6, wall=31507
2023-01-09 12:23:01 - progress_bar.py[line:272] - INFO: epoch 004:    471 / 3665 loss=5.201, loss_v1=0, loss_v2=0, nll_loss=4.307, ntokens=1109, nsentences=32, sample_size=1109, sample_size_v1=0, sample_size_v2=0, ppl=19.8, wps=559.7, ups=0.5, wpb=1109, bsz=32, num_updates=11450, lr=3.65737e-05, gnorm=1.609, clip=100, loss_scale=256, train_wall=20, gb_free=15.4, wall=31527
2023-01-09 12:23:21 - progress_bar.py[line:272] - INFO: epoch 004:    481 / 3665 loss=5.329, loss_v1=0, loss_v2=0, nll_loss=4.449, ntokens=931.1, nsentences=32, sample_size=931.1, sample_size_v1=0, sample_size_v2=0, ppl=21.85, wps=472.6, ups=0.51, wpb=931.1, bsz=32, num_updates=11460, lr=3.65592e-05, gnorm=1.948, clip=100, loss_scale=256, train_wall=20, gb_free=15.7, wall=31547
2023-01-09 12:23:40 - progress_bar.py[line:272] - INFO: epoch 004:    491 / 3665 loss=5.205, loss_v1=0, loss_v2=0, nll_loss=4.31, ntokens=869.3, nsentences=32, sample_size=869.3, sample_size_v1=0, sample_size_v2=0, ppl=19.83, wps=441.4, ups=0.51, wpb=869.3, bsz=32, num_updates=11470, lr=3.65447e-05, gnorm=1.976, clip=100, loss_scale=256, train_wall=20, gb_free=15.6, wall=31567
2023-01-09 12:24:00 - progress_bar.py[line:272] - INFO: epoch 004:    501 / 3665 loss=5.202, loss_v1=0, loss_v2=0, nll_loss=4.309, ntokens=996.8, nsentences=32, sample_size=996.8, sample_size_v1=0, sample_size_v2=0, ppl=19.82, wps=504.5, ups=0.51, wpb=996.8, bsz=32, num_updates=11480, lr=3.65301e-05, gnorm=1.806, clip=100, loss_scale=256, train_wall=20, gb_free=15.1, wall=31586
2023-01-09 12:24:20 - progress_bar.py[line:272] - INFO: epoch 004:    511 / 3665 loss=5.317, loss_v1=0, loss_v2=0, nll_loss=4.437, ntokens=885.5, nsentences=32, sample_size=885.5, sample_size_v1=0, sample_size_v2=0, ppl=21.66, wps=449.4, ups=0.51, wpb=885.5, bsz=32, num_updates=11490, lr=3.65156e-05, gnorm=1.949, clip=100, loss_scale=256, train_wall=20, gb_free=15.3, wall=31606
2023-01-09 12:24:39 - progress_bar.py[line:272] - INFO: epoch 004:    521 / 3665 loss=5.278, loss_v1=0, loss_v2=0, nll_loss=4.39, ntokens=953.5, nsentences=32, sample_size=953.5, sample_size_v1=0, sample_size_v2=0, ppl=20.96, wps=483.7, ups=0.51, wpb=953.5, bsz=32, num_updates=11500, lr=3.65011e-05, gnorm=1.852, clip=100, loss_scale=256, train_wall=20, gb_free=15.5, wall=31626
2023-01-09 12:24:39 - train.py[line:445] - INFO: begin validation on "valid" subset
slice_id 0 seek offset 0
slice_id 0 seek offset 0
2023-01-09 12:29:19 - progress_bar.py[line:282] - INFO: epoch 004 | valid on 'valid' subset | loss 5.228 | loss_v1 0 | loss_v2 0 | nll_loss 4.319 | ntokens 116.958 | nsentences 4 | sample_size 116.958 | sample_size_v1 0 | sample_size_v2 0 | AP 0 | total positives 21.7052 | TP 0 | FP 5.26575 | ppl 19.95 | wps 523.4 | wpb 117 | bsz 4 | num_updates 11500 | best_AP 0
2023-01-09 12:29:19 - checkpoint_utils.py[line:64] - INFO: Preparing to save checkpoint for epoch 4 @ 11500 updates
2023-01-09 12:29:19 - trainer.py[line:431] - INFO: Saving checkpoint to ../../checkpoints/OFA/detection_checkpoints/10_5e-5_512/checkpoint_4_11500.pt
2023-01-09 12:29:22 - trainer.py[line:441] - INFO: Finished saving checkpoint to ../../checkpoints/OFA/detection_checkpoints/10_5e-5_512/checkpoint_4_11500.pt
2023-01-09 12:30:35 - checkpoint_utils.py[line:133] - INFO: Saved checkpoint ../../checkpoints/OFA/detection_checkpoints/10_5e-5_512/checkpoint_4_11500.pt (epoch 4 @ 11500 updates, score 0.0) (writing took 76.08514588838443 seconds)
2023-01-09 12:30:54 - progress_bar.py[line:272] - INFO: epoch 004:    531 / 3665 loss=5.236, loss_v1=0, loss_v2=0, nll_loss=4.346, ntokens=985.9, nsentences=32, sample_size=985.9, sample_size_v1=0, sample_size_v2=0, ppl=20.33, wps=26.3, ups=0.03, wpb=985.9, bsz=32, num_updates=11510, lr=3.64866e-05, gnorm=1.789, clip=100, loss_scale=256, train_wall=19, gb_free=15.2, wall=32000
2023-01-09 12:31:14 - progress_bar.py[line:272] - INFO: epoch 004:    541 / 3665 loss=5.214, loss_v1=0, loss_v2=0, nll_loss=4.318, ntokens=767.7, nsentences=32, sample_size=767.7, sample_size_v1=0, sample_size_v2=0, ppl=19.95, wps=396.6, ups=0.52, wpb=767.7, bsz=32, num_updates=11520, lr=3.64721e-05, gnorm=2.23, clip=100, loss_scale=256, train_wall=19, gb_free=15.3, wall=32020
2023-01-09 12:31:33 - progress_bar.py[line:272] - INFO: epoch 004:    551 / 3665 loss=5.229, loss_v1=0, loss_v2=0, nll_loss=4.336, ntokens=981.2, nsentences=32, sample_size=981.2, sample_size_v1=0, sample_size_v2=0, ppl=20.2, wps=501.5, ups=0.51, wpb=981.2, bsz=32, num_updates=11530, lr=3.64576e-05, gnorm=1.824, clip=100, loss_scale=256, train_wall=20, gb_free=15.1, wall=32039
2023-01-09 12:31:53 - progress_bar.py[line:272] - INFO: epoch 004:    561 / 3665 loss=5.268, loss_v1=0, loss_v2=0, nll_loss=4.381, ntokens=995.7, nsentences=32, sample_size=995.7, sample_size_v1=0, sample_size_v2=0, ppl=20.83, wps=505.7, ups=0.51, wpb=995.7, bsz=32, num_updates=11540, lr=3.64431e-05, gnorm=1.906, clip=100, loss_scale=256, train_wall=20, gb_free=15.4, wall=32059
2023-01-09 12:32:12 - progress_bar.py[line:272] - INFO: epoch 004:    571 / 3665 loss=5.082, loss_v1=0, loss_v2=0, nll_loss=4.174, ntokens=722.3, nsentences=32, sample_size=722.3, sample_size_v1=0, sample_size_v2=0, ppl=18.05, wps=370.3, ups=0.51, wpb=722.3, bsz=32, num_updates=11550, lr=3.64286e-05, gnorm=2.24, clip=100, loss_scale=256, train_wall=19, gb_free=15.5, wall=32079
2023-01-09 12:32:32 - progress_bar.py[line:272] - INFO: epoch 004:    581 / 3665 loss=5.16, loss_v1=0, loss_v2=0, nll_loss=4.261, ntokens=1005.5, nsentences=32, sample_size=1005.5, sample_size_v1=0, sample_size_v2=0, ppl=19.17, wps=513.6, ups=0.51, wpb=1005.5, bsz=32, num_updates=11560, lr=3.6414e-05, gnorm=1.7, clip=100, loss_scale=256, train_wall=20, gb_free=15.4, wall=32098
2023-01-09 12:32:51 - progress_bar.py[line:272] - INFO: epoch 004:    591 / 3665 loss=5.299, loss_v1=0, loss_v2=0, nll_loss=4.415, ntokens=930.1, nsentences=32, sample_size=930.1, sample_size_v1=0, sample_size_v2=0, ppl=21.33, wps=475.4, ups=0.51, wpb=930.1, bsz=32, num_updates=11570, lr=3.63995e-05, gnorm=1.884, clip=100, loss_scale=256, train_wall=20, gb_free=15.3, wall=32118
2023-01-09 12:33:11 - progress_bar.py[line:272] - INFO: epoch 004:    601 / 3665 loss=5.263, loss_v1=0, loss_v2=0, nll_loss=4.373, ntokens=869.5, nsentences=32, sample_size=869.5, sample_size_v1=0, sample_size_v2=0, ppl=20.72, wps=444.4, ups=0.51, wpb=869.5, bsz=32, num_updates=11580, lr=3.6385e-05, gnorm=2.189, clip=100, loss_scale=256, train_wall=20, gb_free=15.4, wall=32137
2023-01-09 12:33:31 - progress_bar.py[line:272] - INFO: epoch 004:    611 / 3665 loss=5.161, loss_v1=0, loss_v2=0, nll_loss=4.264, ntokens=967.3, nsentences=32, sample_size=967.3, sample_size_v1=0, sample_size_v2=0, ppl=19.21, wps=494.4, ups=0.51, wpb=967.3, bsz=32, num_updates=11590, lr=3.63705e-05, gnorm=1.821, clip=100, loss_scale=256, train_wall=20, gb_free=15.5, wall=32157
2023-01-09 12:33:50 - progress_bar.py[line:272] - INFO: epoch 004:    621 / 3665 loss=5.3, loss_v1=0, loss_v2=0, nll_loss=4.418, ntokens=920.9, nsentences=32, sample_size=920.9, sample_size_v1=0, sample_size_v2=0, ppl=21.37, wps=468.8, ups=0.51, wpb=920.9, bsz=32, num_updates=11600, lr=3.6356e-05, gnorm=1.928, clip=100, loss_scale=256, train_wall=20, gb_free=15.5, wall=32176
2023-01-09 12:34:10 - progress_bar.py[line:272] - INFO: epoch 004:    631 / 3665 loss=5.184, loss_v1=0, loss_v2=0, nll_loss=4.286, ntokens=939.7, nsentences=32, sample_size=939.7, sample_size_v1=0, sample_size_v2=0, ppl=19.51, wps=479.6, ups=0.51, wpb=939.7, bsz=32, num_updates=11610, lr=3.63415e-05, gnorm=1.943, clip=100, loss_scale=256, train_wall=20, gb_free=15.5, wall=32196
2023-01-09 12:34:29 - progress_bar.py[line:272] - INFO: epoch 004:    641 / 3665 loss=5.306, loss_v1=0, loss_v2=0, nll_loss=4.42, ntokens=1140.1, nsentences=32, sample_size=1140.1, sample_size_v1=0, sample_size_v2=0, ppl=21.41, wps=579.1, ups=0.51, wpb=1140.1, bsz=32, num_updates=11620, lr=3.6327e-05, gnorm=1.716, clip=90, loss_scale=256, train_wall=20, gb_free=15.4, wall=32216
2023-01-09 12:34:49 - progress_bar.py[line:272] - INFO: epoch 004:    651 / 3665 loss=5.24, loss_v1=0, loss_v2=0, nll_loss=4.351, ntokens=785.8, nsentences=32, sample_size=785.8, sample_size_v1=0, sample_size_v2=0, ppl=20.4, wps=401.8, ups=0.51, wpb=785.8, bsz=32, num_updates=11630, lr=3.63124e-05, gnorm=2.212, clip=100, loss_scale=256, train_wall=20, gb_free=15.2, wall=32235
2023-01-09 12:35:09 - progress_bar.py[line:272] - INFO: epoch 004:    661 / 3665 loss=5.158, loss_v1=0, loss_v2=0, nll_loss=4.256, ntokens=853.7, nsentences=32, sample_size=853.7, sample_size_v1=0, sample_size_v2=0, ppl=19.11, wps=435.1, ups=0.51, wpb=853.7, bsz=32, num_updates=11640, lr=3.62979e-05, gnorm=2.147, clip=100, loss_scale=256, train_wall=20, gb_free=15.2, wall=32255
2023-01-09 12:35:29 - progress_bar.py[line:272] - INFO: epoch 004:    671 / 3665 loss=5.322, loss_v1=0, loss_v2=0, nll_loss=4.443, ntokens=976.4, nsentences=32, sample_size=976.4, sample_size_v1=0, sample_size_v2=0, ppl=21.74, wps=491.1, ups=0.5, wpb=976.4, bsz=32, num_updates=11650, lr=3.62834e-05, gnorm=1.865, clip=100, loss_scale=512, train_wall=20, gb_free=15.5, wall=32275
2023-01-09 12:35:49 - progress_bar.py[line:272] - INFO: epoch 004:    681 / 3665 loss=5.226, loss_v1=0, loss_v2=0, nll_loss=4.335, ntokens=850.9, nsentences=32, sample_size=850.9, sample_size_v1=0, sample_size_v2=0, ppl=20.18, wps=424, ups=0.5, wpb=850.9, bsz=32, num_updates=11660, lr=3.62689e-05, gnorm=2.008, clip=100, loss_scale=512, train_wall=20, gb_free=15.3, wall=32295
2023-01-09 12:36:09 - progress_bar.py[line:272] - INFO: epoch 004:    691 / 3665 loss=5.124, loss_v1=0, loss_v2=0, nll_loss=4.221, ntokens=882.1, nsentences=32, sample_size=882.1, sample_size_v1=0, sample_size_v2=0, ppl=18.65, wps=441.6, ups=0.5, wpb=882.1, bsz=32, num_updates=11670, lr=3.62544e-05, gnorm=1.857, clip=100, loss_scale=512, train_wall=20, gb_free=15.1, wall=32315
2023-01-09 12:36:29 - progress_bar.py[line:272] - INFO: epoch 004:    701 / 3665 loss=5.316, loss_v1=0, loss_v2=0, nll_loss=4.432, ntokens=992.6, nsentences=32, sample_size=992.6, sample_size_v1=0, sample_size_v2=0, ppl=21.58, wps=493.8, ups=0.5, wpb=992.6, bsz=32, num_updates=11680, lr=3.62399e-05, gnorm=1.825, clip=100, loss_scale=512, train_wall=20, gb_free=15.3, wall=32335
2023-01-09 12:36:49 - progress_bar.py[line:272] - INFO: epoch 004:    711 / 3665 loss=5.266, loss_v1=0, loss_v2=0, nll_loss=4.378, ntokens=832.5, nsentences=32, sample_size=832.5, sample_size_v1=0, sample_size_v2=0, ppl=20.79, wps=416.9, ups=0.5, wpb=832.5, bsz=32, num_updates=11690, lr=3.62254e-05, gnorm=1.94, clip=100, loss_scale=512, train_wall=20, gb_free=15.2, wall=32355
2023-01-09 12:37:08 - progress_bar.py[line:272] - INFO: epoch 004:    721 / 3665 loss=5.238, loss_v1=0, loss_v2=0, nll_loss=4.349, ntokens=1027.4, nsentences=32, sample_size=1027.4, sample_size_v1=0, sample_size_v2=0, ppl=20.37, wps=518.6, ups=0.5, wpb=1027.4, bsz=32, num_updates=11700, lr=3.62109e-05, gnorm=1.868, clip=100, loss_scale=512, train_wall=20, gb_free=15.4, wall=32375
2023-01-09 12:37:28 - progress_bar.py[line:272] - INFO: epoch 004:    731 / 3665 loss=5.348, loss_v1=0, loss_v2=0, nll_loss=4.468, ntokens=864.6, nsentences=32, sample_size=864.6, sample_size_v1=0, sample_size_v2=0, ppl=22.13, wps=442, ups=0.51, wpb=864.6, bsz=32, num_updates=11710, lr=3.61963e-05, gnorm=2.121, clip=100, loss_scale=512, train_wall=20, gb_free=15.5, wall=32394
2023-01-09 12:37:48 - progress_bar.py[line:272] - INFO: epoch 004:    741 / 3665 loss=5.219, loss_v1=0, loss_v2=0, nll_loss=4.325, ntokens=865.1, nsentences=32, sample_size=865.1, sample_size_v1=0, sample_size_v2=0, ppl=20.04, wps=443, ups=0.51, wpb=865.1, bsz=32, num_updates=11720, lr=3.61818e-05, gnorm=2.065, clip=100, loss_scale=512, train_wall=20, gb_free=15.6, wall=32414
2023-01-09 12:38:07 - progress_bar.py[line:272] - INFO: epoch 004:    751 / 3665 loss=5.207, loss_v1=0, loss_v2=0, nll_loss=4.314, ntokens=1038.6, nsentences=32, sample_size=1038.6, sample_size_v1=0, sample_size_v2=0, ppl=19.89, wps=528.8, ups=0.51, wpb=1038.6, bsz=32, num_updates=11730, lr=3.61673e-05, gnorm=1.731, clip=100, loss_scale=512, train_wall=20, gb_free=15.4, wall=32433
2023-01-09 12:38:27 - progress_bar.py[line:272] - INFO: epoch 004:    761 / 3665 loss=5.267, loss_v1=0, loss_v2=0, nll_loss=4.379, ntokens=816.6, nsentences=32, sample_size=816.6, sample_size_v1=0, sample_size_v2=0, ppl=20.81, wps=417.3, ups=0.51, wpb=816.6, bsz=32, num_updates=11740, lr=3.61528e-05, gnorm=2.037, clip=100, loss_scale=512, train_wall=20, gb_free=15.1, wall=32453
2023-01-09 12:38:46 - progress_bar.py[line:272] - INFO: epoch 004:    771 / 3665 loss=5.216, loss_v1=0, loss_v2=0, nll_loss=4.323, ntokens=964.4, nsentences=32, sample_size=964.4, sample_size_v1=0, sample_size_v2=0, ppl=20.02, wps=491.1, ups=0.51, wpb=964.4, bsz=32, num_updates=11750, lr=3.61383e-05, gnorm=1.819, clip=100, loss_scale=512, train_wall=20, gb_free=15.5, wall=32473
2023-01-09 12:39:06 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 256.0
2023-01-09 12:39:08 - progress_bar.py[line:272] - INFO: epoch 004:    782 / 3665 loss=5.247, loss_v1=0, loss_v2=0, nll_loss=4.358, ntokens=972.5, nsentences=32, sample_size=972.5, sample_size_v1=0, sample_size_v2=0, ppl=20.51, wps=448.6, ups=0.46, wpb=972.5, bsz=32, num_updates=11760, lr=3.61238e-05, gnorm=1.89, clip=100, loss_scale=256, train_wall=22, gb_free=15.3, wall=32494
2023-01-09 12:39:28 - progress_bar.py[line:272] - INFO: epoch 004:    792 / 3665 loss=5.137, loss_v1=0, loss_v2=0, nll_loss=4.234, ntokens=775.6, nsentences=32, sample_size=775.6, sample_size_v1=0, sample_size_v2=0, ppl=18.82, wps=391.4, ups=0.5, wpb=775.6, bsz=32, num_updates=11770, lr=3.61093e-05, gnorm=2.169, clip=100, loss_scale=256, train_wall=20, gb_free=15.6, wall=32514
2023-01-09 12:39:48 - progress_bar.py[line:272] - INFO: epoch 004:    802 / 3665 loss=5.268, loss_v1=0, loss_v2=0, nll_loss=4.38, ntokens=1105.7, nsentences=32, sample_size=1105.7, sample_size_v1=0, sample_size_v2=0, ppl=20.81, wps=556.4, ups=0.5, wpb=1105.7, bsz=32, num_updates=11780, lr=3.60947e-05, gnorm=1.654, clip=100, loss_scale=256, train_wall=20, gb_free=15.2, wall=32534
2023-01-09 12:40:08 - progress_bar.py[line:272] - INFO: epoch 004:    812 / 3665 loss=5.238, loss_v1=0, loss_v2=0, nll_loss=4.351, ntokens=857.1, nsentences=32, sample_size=857.1, sample_size_v1=0, sample_size_v2=0, ppl=20.41, wps=432.8, ups=0.5, wpb=857.1, bsz=32, num_updates=11790, lr=3.60802e-05, gnorm=1.924, clip=100, loss_scale=256, train_wall=20, gb_free=15.4, wall=32554
2023-01-09 12:40:27 - progress_bar.py[line:272] - INFO: epoch 004:    822 / 3665 loss=5.211, loss_v1=0, loss_v2=0, nll_loss=4.314, ntokens=812.2, nsentences=32, sample_size=812.2, sample_size_v1=0, sample_size_v2=0, ppl=19.89, wps=409.6, ups=0.5, wpb=812.2, bsz=32, num_updates=11800, lr=3.60657e-05, gnorm=2.015, clip=100, loss_scale=256, train_wall=20, gb_free=15.4, wall=32574
2023-01-09 12:40:47 - progress_bar.py[line:272] - INFO: epoch 004:    832 / 3665 loss=5.189, loss_v1=0, loss_v2=0, nll_loss=4.293, ntokens=978.1, nsentences=32, sample_size=978.1, sample_size_v1=0, sample_size_v2=0, ppl=19.6, wps=492.9, ups=0.5, wpb=978.1, bsz=32, num_updates=11810, lr=3.60512e-05, gnorm=1.729, clip=100, loss_scale=256, train_wall=20, gb_free=15.4, wall=32594
2023-01-09 12:41:07 - progress_bar.py[line:272] - INFO: epoch 004:    842 / 3665 loss=5.257, loss_v1=0, loss_v2=0, nll_loss=4.371, ntokens=748.5, nsentences=32, sample_size=748.5, sample_size_v1=0, sample_size_v2=0, ppl=20.69, wps=378.1, ups=0.51, wpb=748.5, bsz=32, num_updates=11820, lr=3.60367e-05, gnorm=2.14, clip=100, loss_scale=256, train_wall=20, gb_free=15.7, wall=32613
2023-01-09 12:41:27 - progress_bar.py[line:272] - INFO: epoch 004:    852 / 3665 loss=5.177, loss_v1=0, loss_v2=0, nll_loss=4.278, ntokens=852.9, nsentences=32, sample_size=852.9, sample_size_v1=0, sample_size_v2=0, ppl=19.41, wps=431.1, ups=0.51, wpb=852.9, bsz=32, num_updates=11830, lr=3.60222e-05, gnorm=2.021, clip=100, loss_scale=256, train_wall=20, gb_free=15.3, wall=32633
2023-01-09 12:41:47 - progress_bar.py[line:272] - INFO: epoch 004:    862 / 3665 loss=5.24, loss_v1=0, loss_v2=0, nll_loss=4.35, ntokens=1135.1, nsentences=32, sample_size=1135.1, sample_size_v1=0, sample_size_v2=0, ppl=20.39, wps=568.6, ups=0.5, wpb=1135.1, bsz=32, num_updates=11840, lr=3.60077e-05, gnorm=1.744, clip=100, loss_scale=256, train_wall=20, gb_free=14.9, wall=32653
2023-01-09 12:42:07 - progress_bar.py[line:272] - INFO: epoch 004:    872 / 3665 loss=5.31, loss_v1=0, loss_v2=0, nll_loss=4.427, ntokens=862.4, nsentences=32, sample_size=862.4, sample_size_v1=0, sample_size_v2=0, ppl=21.51, wps=435.6, ups=0.51, wpb=862.4, bsz=32, num_updates=11850, lr=3.59931e-05, gnorm=1.895, clip=100, loss_scale=256, train_wall=20, gb_free=15.5, wall=32673
2023-01-09 12:42:26 - progress_bar.py[line:272] - INFO: epoch 004:    882 / 3665 loss=5.162, loss_v1=0, loss_v2=0, nll_loss=4.263, ntokens=906.2, nsentences=32, sample_size=906.2, sample_size_v1=0, sample_size_v2=0, ppl=19.2, wps=457.2, ups=0.5, wpb=906.2, bsz=32, num_updates=11860, lr=3.59786e-05, gnorm=1.908, clip=100, loss_scale=256, train_wall=20, gb_free=15.4, wall=32693
2023-01-09 12:42:46 - progress_bar.py[line:272] - INFO: epoch 004:    892 / 3665 loss=5.258, loss_v1=0, loss_v2=0, nll_loss=4.37, ntokens=1058.2, nsentences=32, sample_size=1058.2, sample_size_v1=0, sample_size_v2=0, ppl=20.68, wps=530.7, ups=0.5, wpb=1058.2, bsz=32, num_updates=11870, lr=3.59641e-05, gnorm=1.69, clip=100, loss_scale=256, train_wall=20, gb_free=15.1, wall=32713
2023-01-09 12:43:06 - progress_bar.py[line:272] - INFO: epoch 004:    902 / 3665 loss=5.262, loss_v1=0, loss_v2=0, nll_loss=4.374, ntokens=982, nsentences=32, sample_size=982, sample_size_v1=0, sample_size_v2=0, ppl=20.73, wps=493.9, ups=0.5, wpb=982, bsz=32, num_updates=11880, lr=3.59496e-05, gnorm=1.843, clip=100, loss_scale=256, train_wall=20, gb_free=15.2, wall=32733
2023-01-09 12:43:26 - progress_bar.py[line:272] - INFO: epoch 004:    912 / 3665 loss=5.159, loss_v1=0, loss_v2=0, nll_loss=4.262, ntokens=984.3, nsentences=32, sample_size=984.3, sample_size_v1=0, sample_size_v2=0, ppl=19.19, wps=495, ups=0.5, wpb=984.3, bsz=32, num_updates=11890, lr=3.59351e-05, gnorm=1.813, clip=100, loss_scale=256, train_wall=20, gb_free=15.3, wall=32752
2023-01-09 12:43:46 - progress_bar.py[line:272] - INFO: epoch 004:    922 / 3665 loss=5.287, loss_v1=0, loss_v2=0, nll_loss=4.4, ntokens=1024.7, nsentences=32, sample_size=1024.7, sample_size_v1=0, sample_size_v2=0, ppl=21.12, wps=514.4, ups=0.5, wpb=1024.7, bsz=32, num_updates=11900, lr=3.59206e-05, gnorm=1.73, clip=100, loss_scale=256, train_wall=20, gb_free=15.4, wall=32772
2023-01-09 12:44:06 - progress_bar.py[line:272] - INFO: epoch 004:    932 / 3665 loss=5.235, loss_v1=0, loss_v2=0, nll_loss=4.343, ntokens=876.7, nsentences=32, sample_size=876.7, sample_size_v1=0, sample_size_v2=0, ppl=20.3, wps=442.2, ups=0.5, wpb=876.7, bsz=32, num_updates=11910, lr=3.59061e-05, gnorm=1.995, clip=100, loss_scale=256, train_wall=20, gb_free=15.6, wall=32792
2023-01-09 12:44:26 - progress_bar.py[line:272] - INFO: epoch 004:    942 / 3665 loss=5.166, loss_v1=0, loss_v2=0, nll_loss=4.267, ntokens=943.8, nsentences=32, sample_size=943.8, sample_size_v1=0, sample_size_v2=0, ppl=19.25, wps=472.3, ups=0.5, wpb=943.8, bsz=32, num_updates=11920, lr=3.58916e-05, gnorm=1.816, clip=100, loss_scale=256, train_wall=20, gb_free=15.4, wall=32812
2023-01-09 12:44:46 - progress_bar.py[line:272] - INFO: epoch 004:    952 / 3665 loss=5.171, loss_v1=0, loss_v2=0, nll_loss=4.273, ntokens=874.9, nsentences=32, sample_size=874.9, sample_size_v1=0, sample_size_v2=0, ppl=19.33, wps=443.9, ups=0.51, wpb=874.9, bsz=32, num_updates=11930, lr=3.5877e-05, gnorm=1.978, clip=100, loss_scale=256, train_wall=20, gb_free=15.5, wall=32832
2023-01-09 12:45:05 - progress_bar.py[line:272] - INFO: epoch 004:    962 / 3665 loss=5.2, loss_v1=0, loss_v2=0, nll_loss=4.305, ntokens=877.2, nsentences=32, sample_size=877.2, sample_size_v1=0, sample_size_v2=0, ppl=19.77, wps=445.6, ups=0.51, wpb=877.2, bsz=32, num_updates=11940, lr=3.58625e-05, gnorm=2.108, clip=100, loss_scale=256, train_wall=20, gb_free=15.5, wall=32852
2023-01-09 12:45:25 - progress_bar.py[line:272] - INFO: epoch 004:    972 / 3665 loss=5.121, loss_v1=0, loss_v2=0, nll_loss=4.214, ntokens=858.8, nsentences=32, sample_size=858.8, sample_size_v1=0, sample_size_v2=0, ppl=18.56, wps=437.2, ups=0.51, wpb=858.8, bsz=32, num_updates=11950, lr=3.5848e-05, gnorm=1.888, clip=100, loss_scale=256, train_wall=20, gb_free=15.6, wall=32871
2023-01-09 12:45:45 - progress_bar.py[line:272] - INFO: epoch 004:    982 / 3665 loss=5.291, loss_v1=0, loss_v2=0, nll_loss=4.409, ntokens=907.6, nsentences=32, sample_size=907.6, sample_size_v1=0, sample_size_v2=0, ppl=21.25, wps=459.4, ups=0.51, wpb=907.6, bsz=32, num_updates=11960, lr=3.58335e-05, gnorm=2.022, clip=100, loss_scale=256, train_wall=20, gb_free=15.5, wall=32891
2023-01-09 12:46:04 - progress_bar.py[line:272] - INFO: epoch 004:    992 / 3665 loss=5.207, loss_v1=0, loss_v2=0, nll_loss=4.313, ntokens=868.2, nsentences=32, sample_size=868.2, sample_size_v1=0, sample_size_v2=0, ppl=19.87, wps=440.5, ups=0.51, wpb=868.2, bsz=32, num_updates=11970, lr=3.5819e-05, gnorm=2.057, clip=100, loss_scale=256, train_wall=20, gb_free=15.4, wall=32911
2023-01-09 12:46:24 - progress_bar.py[line:272] - INFO: epoch 004:   1002 / 3665 loss=5.294, loss_v1=0, loss_v2=0, nll_loss=4.408, ntokens=1116.7, nsentences=32, sample_size=1116.7, sample_size_v1=0, sample_size_v2=0, ppl=21.23, wps=562.4, ups=0.5, wpb=1116.7, bsz=32, num_updates=11980, lr=3.58045e-05, gnorm=1.562, clip=100, loss_scale=256, train_wall=20, gb_free=15.4, wall=32930
2023-01-09 12:46:44 - progress_bar.py[line:272] - INFO: epoch 004:   1012 / 3665 loss=5.206, loss_v1=0, loss_v2=0, nll_loss=4.311, ntokens=790.7, nsentences=32, sample_size=790.7, sample_size_v1=0, sample_size_v2=0, ppl=19.85, wps=401.9, ups=0.51, wpb=790.7, bsz=32, num_updates=11990, lr=3.579e-05, gnorm=2.048, clip=100, loss_scale=256, train_wall=20, gb_free=15.1, wall=32950
2023-01-09 12:47:04 - progress_bar.py[line:272] - INFO: epoch 004:   1022 / 3665 loss=5.166, loss_v1=0, loss_v2=0, nll_loss=4.269, ntokens=894.8, nsentences=32, sample_size=894.8, sample_size_v1=0, sample_size_v2=0, ppl=19.28, wps=454.6, ups=0.51, wpb=894.8, bsz=32, num_updates=12000, lr=3.57754e-05, gnorm=1.979, clip=100, loss_scale=256, train_wall=20, gb_free=15.3, wall=32970
2023-01-09 12:47:04 - train.py[line:445] - INFO: begin validation on "valid" subset
slice_id 0 seek offset 0
slice_id 0 seek offset 0
2023-01-09 12:51:36 - progress_bar.py[line:282] - INFO: epoch 004 | valid on 'valid' subset | loss 5.233 | loss_v1 0 | loss_v2 0 | nll_loss 4.327 | ntokens 117.681 | nsentences 4 | sample_size 117.681 | sample_size_v1 0 | sample_size_v2 0 | AP 0 | total positives 21.8336 | TP 0 | FP 5.09208 | ppl 20.08 | wps 539.7 | wpb 117.7 | bsz 4 | num_updates 12000 | best_AP 0
2023-01-09 12:51:36 - checkpoint_utils.py[line:64] - INFO: Preparing to save checkpoint for epoch 4 @ 12000 updates
2023-01-09 12:51:36 - trainer.py[line:431] - INFO: Saving checkpoint to ../../checkpoints/OFA/detection_checkpoints/10_5e-5_512/checkpoint_4_12000.pt
2023-01-09 12:51:39 - trainer.py[line:441] - INFO: Finished saving checkpoint to ../../checkpoints/OFA/detection_checkpoints/10_5e-5_512/checkpoint_4_12000.pt
2023-01-09 12:52:51 - checkpoint_utils.py[line:133] - INFO: Saved checkpoint ../../checkpoints/OFA/detection_checkpoints/10_5e-5_512/checkpoint_4_12000.pt (epoch 4 @ 12000 updates, score 0.0) (writing took 75.48876390233636 seconds)
2023-01-09 12:53:11 - progress_bar.py[line:272] - INFO: epoch 004:   1032 / 3665 loss=5.317, loss_v1=0, loss_v2=0, nll_loss=4.435, ntokens=1017.9, nsentences=32, sample_size=1017.9, sample_size_v1=0, sample_size_v2=0, ppl=21.63, wps=27.7, ups=0.03, wpb=1017.9, bsz=32, num_updates=12010, lr=3.57609e-05, gnorm=1.838, clip=100, loss_scale=256, train_wall=19, gb_free=15.5, wall=33337
2023-01-09 12:53:30 - progress_bar.py[line:272] - INFO: epoch 004:   1042 / 3665 loss=5.1, loss_v1=0, loss_v2=0, nll_loss=4.191, ntokens=590, nsentences=32, sample_size=590, sample_size_v1=0, sample_size_v2=0, ppl=18.27, wps=305.6, ups=0.52, wpb=590, bsz=32, num_updates=12020, lr=3.57464e-05, gnorm=2.618, clip=100, loss_scale=256, train_wall=19, gb_free=15.6, wall=33356
2023-01-09 12:53:50 - progress_bar.py[line:272] - INFO: epoch 004:   1052 / 3665 loss=5.164, loss_v1=0, loss_v2=0, nll_loss=4.265, ntokens=905.4, nsentences=32, sample_size=905.4, sample_size_v1=0, sample_size_v2=0, ppl=19.23, wps=463.5, ups=0.51, wpb=905.4, bsz=32, num_updates=12030, lr=3.57319e-05, gnorm=1.953, clip=100, loss_scale=256, train_wall=20, gb_free=15.3, wall=33376
2023-01-09 12:54:09 - progress_bar.py[line:272] - INFO: epoch 004:   1062 / 3665 loss=5.33, loss_v1=0, loss_v2=0, nll_loss=4.45, ntokens=1008.3, nsentences=32, sample_size=1008.3, sample_size_v1=0, sample_size_v2=0, ppl=21.86, wps=513.5, ups=0.51, wpb=1008.3, bsz=32, num_updates=12040, lr=3.57174e-05, gnorm=1.819, clip=100, loss_scale=256, train_wall=20, gb_free=15.5, wall=33396
2023-01-09 12:54:29 - progress_bar.py[line:272] - INFO: epoch 004:   1072 / 3665 loss=5.109, loss_v1=0, loss_v2=0, nll_loss=4.205, ntokens=711.2, nsentences=32, sample_size=711.2, sample_size_v1=0, sample_size_v2=0, ppl=18.44, wps=365, ups=0.51, wpb=711.2, bsz=32, num_updates=12050, lr=3.57029e-05, gnorm=2.154, clip=100, loss_scale=256, train_wall=19, gb_free=15.7, wall=33415
2023-01-09 12:54:48 - progress_bar.py[line:272] - INFO: epoch 004:   1082 / 3665 loss=5.214, loss_v1=0, loss_v2=0, nll_loss=4.319, ntokens=1084, nsentences=32, sample_size=1084, sample_size_v1=0, sample_size_v2=0, ppl=19.96, wps=552.1, ups=0.51, wpb=1084, bsz=32, num_updates=12060, lr=3.56884e-05, gnorm=1.576, clip=100, loss_scale=256, train_wall=20, gb_free=15.1, wall=33435
2023-01-09 12:55:08 - progress_bar.py[line:272] - INFO: epoch 004:   1092 / 3665 loss=5.175, loss_v1=0, loss_v2=0, nll_loss=4.278, ntokens=814.6, nsentences=32, sample_size=814.6, sample_size_v1=0, sample_size_v2=0, ppl=19.4, wps=416.3, ups=0.51, wpb=814.6, bsz=32, num_updates=12070, lr=3.56739e-05, gnorm=2.115, clip=100, loss_scale=256, train_wall=20, gb_free=15.7, wall=33454
2023-01-09 12:55:28 - progress_bar.py[line:272] - INFO: epoch 004:   1102 / 3665 loss=5.267, loss_v1=0, loss_v2=0, nll_loss=4.379, ntokens=1011.4, nsentences=32, sample_size=1011.4, sample_size_v1=0, sample_size_v2=0, ppl=20.8, wps=515, ups=0.51, wpb=1011.4, bsz=32, num_updates=12080, lr=3.56593e-05, gnorm=1.723, clip=100, loss_scale=256, train_wall=20, gb_free=15.1, wall=33474
2023-01-09 12:55:47 - progress_bar.py[line:272] - INFO: epoch 004:   1112 / 3665 loss=5.217, loss_v1=0, loss_v2=0, nll_loss=4.323, ntokens=862, nsentences=32, sample_size=862, sample_size_v1=0, sample_size_v2=0, ppl=20.02, wps=440.1, ups=0.51, wpb=862, bsz=32, num_updates=12090, lr=3.56448e-05, gnorm=2.125, clip=100, loss_scale=256, train_wall=20, gb_free=15.1, wall=33493
2023-01-09 12:56:07 - progress_bar.py[line:272] - INFO: epoch 004:   1122 / 3665 loss=5.171, loss_v1=0, loss_v2=0, nll_loss=4.272, ntokens=1077.5, nsentences=32, sample_size=1077.5, sample_size_v1=0, sample_size_v2=0, ppl=19.32, wps=548.3, ups=0.51, wpb=1077.5, bsz=32, num_updates=12100, lr=3.56303e-05, gnorm=1.791, clip=100, loss_scale=256, train_wall=20, gb_free=15.4, wall=33513
2023-01-09 12:56:26 - progress_bar.py[line:272] - INFO: epoch 004:   1132 / 3665 loss=5.161, loss_v1=0, loss_v2=0, nll_loss=4.261, ntokens=1062.5, nsentences=32, sample_size=1062.5, sample_size_v1=0, sample_size_v2=0, ppl=19.18, wps=540.3, ups=0.51, wpb=1062.5, bsz=32, num_updates=12110, lr=3.56158e-05, gnorm=1.691, clip=100, loss_scale=256, train_wall=20, gb_free=15.4, wall=33533
2023-01-09 12:56:46 - progress_bar.py[line:272] - INFO: epoch 004:   1142 / 3665 loss=5.245, loss_v1=0, loss_v2=0, nll_loss=4.355, ntokens=762.9, nsentences=32, sample_size=762.9, sample_size_v1=0, sample_size_v2=0, ppl=20.47, wps=390.3, ups=0.51, wpb=762.9, bsz=32, num_updates=12120, lr=3.56013e-05, gnorm=2.259, clip=100, loss_scale=256, train_wall=20, gb_free=15.5, wall=33552
2023-01-09 12:57:06 - progress_bar.py[line:272] - INFO: epoch 004:   1152 / 3665 loss=5.245, loss_v1=0, loss_v2=0, nll_loss=4.355, ntokens=916.5, nsentences=32, sample_size=916.5, sample_size_v1=0, sample_size_v2=0, ppl=20.47, wps=467, ups=0.51, wpb=916.5, bsz=32, num_updates=12130, lr=3.55868e-05, gnorm=2.085, clip=100, loss_scale=256, train_wall=20, gb_free=15.4, wall=33572
2023-01-09 12:57:25 - progress_bar.py[line:272] - INFO: epoch 004:   1162 / 3665 loss=5.133, loss_v1=0, loss_v2=0, nll_loss=4.229, ntokens=917.5, nsentences=32, sample_size=917.5, sample_size_v1=0, sample_size_v2=0, ppl=18.76, wps=467.6, ups=0.51, wpb=917.5, bsz=32, num_updates=12140, lr=3.55723e-05, gnorm=1.951, clip=100, loss_scale=256, train_wall=20, gb_free=15.2, wall=33592
2023-01-09 12:57:45 - progress_bar.py[line:272] - INFO: epoch 004:   1172 / 3665 loss=5.237, loss_v1=0, loss_v2=0, nll_loss=4.347, ntokens=889.5, nsentences=32, sample_size=889.5, sample_size_v1=0, sample_size_v2=0, ppl=20.35, wps=452.5, ups=0.51, wpb=889.5, bsz=32, num_updates=12150, lr=3.55577e-05, gnorm=2.247, clip=100, loss_scale=256, train_wall=20, gb_free=15.3, wall=33611
2023-01-09 12:58:05 - progress_bar.py[line:272] - INFO: epoch 004:   1182 / 3665 loss=5.199, loss_v1=0, loss_v2=0, nll_loss=4.301, ntokens=850.6, nsentences=32, sample_size=850.6, sample_size_v1=0, sample_size_v2=0, ppl=19.72, wps=433.2, ups=0.51, wpb=850.6, bsz=32, num_updates=12160, lr=3.55432e-05, gnorm=2.314, clip=100, loss_scale=256, train_wall=20, gb_free=15.3, wall=33631
2023-01-09 12:58:24 - progress_bar.py[line:272] - INFO: epoch 004:   1192 / 3665 loss=5.226, loss_v1=0, loss_v2=0, nll_loss=4.335, ntokens=1119.5, nsentences=32, sample_size=1119.5, sample_size_v1=0, sample_size_v2=0, ppl=20.18, wps=567.7, ups=0.51, wpb=1119.5, bsz=32, num_updates=12170, lr=3.55287e-05, gnorm=1.842, clip=100, loss_scale=256, train_wall=20, gb_free=15.4, wall=33651
2023-01-09 12:58:44 - progress_bar.py[line:272] - INFO: epoch 004:   1202 / 3665 loss=5.307, loss_v1=0, loss_v2=0, nll_loss=4.425, ntokens=1070.3, nsentences=32, sample_size=1070.3, sample_size_v1=0, sample_size_v2=0, ppl=21.48, wps=530.4, ups=0.5, wpb=1070.3, bsz=32, num_updates=12180, lr=3.55142e-05, gnorm=1.796, clip=100, loss_scale=256, train_wall=20, gb_free=15.3, wall=33671
2023-01-09 12:59:05 - progress_bar.py[line:272] - INFO: epoch 004:   1212 / 3665 loss=5.217, loss_v1=0, loss_v2=0, nll_loss=4.32, ntokens=788.8, nsentences=32, sample_size=788.8, sample_size_v1=0, sample_size_v2=0, ppl=19.97, wps=393, ups=0.5, wpb=788.8, bsz=32, num_updates=12190, lr=3.54997e-05, gnorm=2.182, clip=100, loss_scale=256, train_wall=20, gb_free=15.5, wall=33691
2023-01-09 12:59:25 - progress_bar.py[line:272] - INFO: epoch 004:   1222 / 3665 loss=5.206, loss_v1=0, loss_v2=0, nll_loss=4.312, ntokens=1073.6, nsentences=32, sample_size=1073.6, sample_size_v1=0, sample_size_v2=0, ppl=19.86, wps=532, ups=0.5, wpb=1073.6, bsz=32, num_updates=12200, lr=3.54852e-05, gnorm=1.845, clip=100, loss_scale=256, train_wall=20, gb_free=15.4, wall=33711
2023-01-09 12:59:45 - progress_bar.py[line:272] - INFO: epoch 004:   1232 / 3665 loss=5.337, loss_v1=0, loss_v2=0, nll_loss=4.46, ntokens=1096.5, nsentences=32, sample_size=1096.5, sample_size_v1=0, sample_size_v2=0, ppl=22.01, wps=545.5, ups=0.5, wpb=1096.5, bsz=32, num_updates=12210, lr=3.54707e-05, gnorm=1.65, clip=100, loss_scale=256, train_wall=20, gb_free=15.3, wall=33731
2023-01-09 13:00:04 - progress_bar.py[line:272] - INFO: epoch 004:   1242 / 3665 loss=5.284, loss_v1=0, loss_v2=0, nll_loss=4.399, ntokens=917.6, nsentences=32, sample_size=917.6, sample_size_v1=0, sample_size_v2=0, ppl=21.09, wps=468.3, ups=0.51, wpb=917.6, bsz=32, num_updates=12220, lr=3.54562e-05, gnorm=2.005, clip=100, loss_scale=256, train_wall=20, gb_free=15.4, wall=33751
2023-01-09 13:00:24 - progress_bar.py[line:272] - INFO: epoch 004:   1252 / 3665 loss=5.161, loss_v1=0, loss_v2=0, nll_loss=4.26, ntokens=1009.2, nsentences=32, sample_size=1009.2, sample_size_v1=0, sample_size_v2=0, ppl=19.16, wps=514.9, ups=0.51, wpb=1009.2, bsz=32, num_updates=12230, lr=3.54416e-05, gnorm=1.804, clip=100, loss_scale=256, train_wall=20, gb_free=15.6, wall=33770
2023-01-09 13:00:44 - progress_bar.py[line:272] - INFO: epoch 004:   1262 / 3665 loss=5.275, loss_v1=0, loss_v2=0, nll_loss=4.389, ntokens=1039.6, nsentences=32, sample_size=1039.6, sample_size_v1=0, sample_size_v2=0, ppl=20.95, wps=528.5, ups=0.51, wpb=1039.6, bsz=32, num_updates=12240, lr=3.54271e-05, gnorm=1.866, clip=100, loss_scale=256, train_wall=20, gb_free=15.2, wall=33790
2023-01-09 13:01:03 - progress_bar.py[line:272] - INFO: epoch 004:   1272 / 3665 loss=5.173, loss_v1=0, loss_v2=0, nll_loss=4.274, ntokens=676.9, nsentences=32, sample_size=676.9, sample_size_v1=0, sample_size_v2=0, ppl=19.35, wps=347.6, ups=0.51, wpb=676.9, bsz=32, num_updates=12250, lr=3.54126e-05, gnorm=2.532, clip=100, loss_scale=256, train_wall=19, gb_free=15.4, wall=33809
2023-01-09 13:01:23 - progress_bar.py[line:272] - INFO: epoch 004:   1282 / 3665 loss=5.124, loss_v1=0, loss_v2=0, nll_loss=4.219, ntokens=822.6, nsentences=32, sample_size=822.6, sample_size_v1=0, sample_size_v2=0, ppl=18.63, wps=421.1, ups=0.51, wpb=822.6, bsz=32, num_updates=12260, lr=3.53981e-05, gnorm=2.118, clip=100, loss_scale=256, train_wall=20, gb_free=15.7, wall=33829
2023-01-09 13:01:42 - progress_bar.py[line:272] - INFO: epoch 004:   1292 / 3665 loss=5.211, loss_v1=0, loss_v2=0, nll_loss=4.317, ntokens=1045.4, nsentences=32, sample_size=1045.4, sample_size_v1=0, sample_size_v2=0, ppl=19.94, wps=531.1, ups=0.51, wpb=1045.4, bsz=32, num_updates=12270, lr=3.53836e-05, gnorm=1.75, clip=100, loss_scale=256, train_wall=20, gb_free=15.3, wall=33849
2023-01-09 13:02:02 - progress_bar.py[line:272] - INFO: epoch 004:   1302 / 3665 loss=5.205, loss_v1=0, loss_v2=0, nll_loss=4.311, ntokens=809.9, nsentences=32, sample_size=809.9, sample_size_v1=0, sample_size_v2=0, ppl=19.85, wps=413.1, ups=0.51, wpb=809.9, bsz=32, num_updates=12280, lr=3.53691e-05, gnorm=2.126, clip=100, loss_scale=512, train_wall=20, gb_free=15.6, wall=33868
2023-01-09 13:02:22 - progress_bar.py[line:272] - INFO: epoch 004:   1312 / 3665 loss=5.204, loss_v1=0, loss_v2=0, nll_loss=4.308, ntokens=980.6, nsentences=32, sample_size=980.6, sample_size_v1=0, sample_size_v2=0, ppl=19.81, wps=498.2, ups=0.51, wpb=980.6, bsz=32, num_updates=12290, lr=3.53546e-05, gnorm=1.917, clip=100, loss_scale=512, train_wall=20, gb_free=15.2, wall=33888
2023-01-09 13:02:41 - progress_bar.py[line:272] - INFO: epoch 004:   1322 / 3665 loss=5.173, loss_v1=0, loss_v2=0, nll_loss=4.278, ntokens=980.4, nsentences=32, sample_size=980.4, sample_size_v1=0, sample_size_v2=0, ppl=19.4, wps=499.5, ups=0.51, wpb=980.4, bsz=32, num_updates=12300, lr=3.534e-05, gnorm=1.785, clip=100, loss_scale=512, train_wall=20, gb_free=15.3, wall=33908
2023-01-09 13:03:01 - progress_bar.py[line:272] - INFO: epoch 004:   1332 / 3665 loss=5.304, loss_v1=0, loss_v2=0, nll_loss=4.418, ntokens=792.7, nsentences=32, sample_size=792.7, sample_size_v1=0, sample_size_v2=0, ppl=21.38, wps=398.8, ups=0.5, wpb=792.7, bsz=32, num_updates=12310, lr=3.53255e-05, gnorm=2.361, clip=100, loss_scale=512, train_wall=20, gb_free=15.6, wall=33927
2023-01-09 13:03:21 - progress_bar.py[line:272] - INFO: epoch 004:   1342 / 3665 loss=5.144, loss_v1=0, loss_v2=0, nll_loss=4.241, ntokens=965.7, nsentences=32, sample_size=965.7, sample_size_v1=0, sample_size_v2=0, ppl=18.91, wps=477, ups=0.49, wpb=965.7, bsz=32, num_updates=12320, lr=3.5311e-05, gnorm=1.879, clip=100, loss_scale=512, train_wall=20, gb_free=15.5, wall=33948
2023-01-09 13:03:42 - progress_bar.py[line:272] - INFO: epoch 004:   1352 / 3665 loss=5.14, loss_v1=0, loss_v2=0, nll_loss=4.239, ntokens=1050.5, nsentences=32, sample_size=1050.5, sample_size_v1=0, sample_size_v2=0, ppl=18.88, wps=519.2, ups=0.49, wpb=1050.5, bsz=32, num_updates=12330, lr=3.52965e-05, gnorm=1.769, clip=100, loss_scale=512, train_wall=20, gb_free=15.2, wall=33968
2023-01-09 13:04:02 - progress_bar.py[line:272] - INFO: epoch 004:   1362 / 3665 loss=5.252, loss_v1=0, loss_v2=0, nll_loss=4.363, ntokens=942.8, nsentences=32, sample_size=942.8, sample_size_v1=0, sample_size_v2=0, ppl=20.58, wps=467.9, ups=0.5, wpb=942.8, bsz=32, num_updates=12340, lr=3.5282e-05, gnorm=2.062, clip=100, loss_scale=512, train_wall=20, gb_free=15.3, wall=33988
2023-01-09 13:04:21 - progress_bar.py[line:272] - INFO: epoch 004:   1372 / 3665 loss=5.198, loss_v1=0, loss_v2=0, nll_loss=4.302, ntokens=876.1, nsentences=32, sample_size=876.1, sample_size_v1=0, sample_size_v2=0, ppl=19.72, wps=446.1, ups=0.51, wpb=876.1, bsz=32, num_updates=12350, lr=3.52675e-05, gnorm=2.017, clip=100, loss_scale=512, train_wall=20, gb_free=15.5, wall=34008
2023-01-09 13:04:41 - progress_bar.py[line:272] - INFO: epoch 004:   1382 / 3665 loss=5.142, loss_v1=0, loss_v2=0, nll_loss=4.243, ntokens=975.8, nsentences=32, sample_size=975.8, sample_size_v1=0, sample_size_v2=0, ppl=18.93, wps=495.8, ups=0.51, wpb=975.8, bsz=32, num_updates=12360, lr=3.5253e-05, gnorm=1.837, clip=100, loss_scale=512, train_wall=20, gb_free=15.4, wall=34027
2023-01-09 13:05:01 - progress_bar.py[line:272] - INFO: epoch 004:   1392 / 3665 loss=5.19, loss_v1=0, loss_v2=0, nll_loss=4.293, ntokens=748, nsentences=32, sample_size=748, sample_size_v1=0, sample_size_v2=0, ppl=19.61, wps=379, ups=0.51, wpb=748, bsz=32, num_updates=12370, lr=3.52385e-05, gnorm=2.135, clip=100, loss_scale=512, train_wall=20, gb_free=15.5, wall=34047
2023-01-09 13:05:21 - progress_bar.py[line:272] - INFO: epoch 004:   1402 / 3665 loss=5.157, loss_v1=0, loss_v2=0, nll_loss=4.256, ntokens=769.9, nsentences=32, sample_size=769.9, sample_size_v1=0, sample_size_v2=0, ppl=19.11, wps=389.2, ups=0.51, wpb=769.9, bsz=32, num_updates=12380, lr=3.52239e-05, gnorm=2.25, clip=100, loss_scale=512, train_wall=20, gb_free=15.4, wall=34067
2023-01-09 13:05:40 - progress_bar.py[line:272] - INFO: epoch 004:   1412 / 3665 loss=5.12, loss_v1=0, loss_v2=0, nll_loss=4.216, ntokens=862.7, nsentences=32, sample_size=862.7, sample_size_v1=0, sample_size_v2=0, ppl=18.59, wps=439.4, ups=0.51, wpb=862.7, bsz=32, num_updates=12390, lr=3.52094e-05, gnorm=1.945, clip=100, loss_scale=512, train_wall=20, gb_free=15.3, wall=34087
2023-01-09 13:06:00 - progress_bar.py[line:272] - INFO: epoch 004:   1422 / 3665 loss=5.21, loss_v1=0, loss_v2=0, nll_loss=4.316, ntokens=972.6, nsentences=32, sample_size=972.6, sample_size_v1=0, sample_size_v2=0, ppl=19.92, wps=490.4, ups=0.5, wpb=972.6, bsz=32, num_updates=12400, lr=3.51949e-05, gnorm=1.893, clip=100, loss_scale=512, train_wall=20, gb_free=15.6, wall=34106
2023-01-09 13:06:20 - progress_bar.py[line:272] - INFO: epoch 004:   1432 / 3665 loss=5.147, loss_v1=0, loss_v2=0, nll_loss=4.245, ntokens=728.7, nsentences=32, sample_size=728.7, sample_size_v1=0, sample_size_v2=0, ppl=18.96, wps=370.9, ups=0.51, wpb=728.7, bsz=32, num_updates=12410, lr=3.51804e-05, gnorm=2.24, clip=100, loss_scale=512, train_wall=20, gb_free=15.6, wall=34126
2023-01-09 13:06:39 - progress_bar.py[line:272] - INFO: epoch 004:   1442 / 3665 loss=5.193, loss_v1=0, loss_v2=0, nll_loss=4.299, ntokens=955.3, nsentences=32, sample_size=955.3, sample_size_v1=0, sample_size_v2=0, ppl=19.68, wps=486.1, ups=0.51, wpb=955.3, bsz=32, num_updates=12420, lr=3.51659e-05, gnorm=1.919, clip=100, loss_scale=512, train_wall=20, gb_free=15.4, wall=34146
2023-01-09 13:06:59 - progress_bar.py[line:272] - INFO: epoch 004:   1452 / 3665 loss=5.272, loss_v1=0, loss_v2=0, nll_loss=4.386, ntokens=1001.9, nsentences=32, sample_size=1001.9, sample_size_v1=0, sample_size_v2=0, ppl=20.91, wps=506.7, ups=0.51, wpb=1001.9, bsz=32, num_updates=12430, lr=3.51514e-05, gnorm=1.808, clip=100, loss_scale=512, train_wall=20, gb_free=15.3, wall=34165
2023-01-09 13:07:19 - progress_bar.py[line:272] - INFO: epoch 004:   1462 / 3665 loss=5.134, loss_v1=0, loss_v2=0, nll_loss=4.231, ntokens=725.8, nsentences=32, sample_size=725.8, sample_size_v1=0, sample_size_v2=0, ppl=18.78, wps=368.5, ups=0.51, wpb=725.8, bsz=32, num_updates=12440, lr=3.51369e-05, gnorm=2.323, clip=100, loss_scale=512, train_wall=20, gb_free=14.9, wall=34185
2023-01-09 13:07:39 - progress_bar.py[line:272] - INFO: epoch 004:   1472 / 3665 loss=5.115, loss_v1=0, loss_v2=0, nll_loss=4.208, ntokens=844.6, nsentences=32, sample_size=844.6, sample_size_v1=0, sample_size_v2=0, ppl=18.48, wps=430.4, ups=0.51, wpb=844.6, bsz=32, num_updates=12450, lr=3.51223e-05, gnorm=2.105, clip=100, loss_scale=512, train_wall=20, gb_free=15.5, wall=34205
2023-01-09 13:07:58 - progress_bar.py[line:272] - INFO: epoch 004:   1482 / 3665 loss=5.275, loss_v1=0, loss_v2=0, nll_loss=4.39, ntokens=1038.8, nsentences=32, sample_size=1038.8, sample_size_v1=0, sample_size_v2=0, ppl=20.96, wps=525.1, ups=0.51, wpb=1038.8, bsz=32, num_updates=12460, lr=3.51078e-05, gnorm=1.757, clip=100, loss_scale=512, train_wall=20, gb_free=15.5, wall=34225
2023-01-09 13:08:18 - progress_bar.py[line:272] - INFO: epoch 004:   1492 / 3665 loss=5.219, loss_v1=0, loss_v2=0, nll_loss=4.328, ntokens=703.2, nsentences=32, sample_size=703.2, sample_size_v1=0, sample_size_v2=0, ppl=20.09, wps=354.5, ups=0.5, wpb=703.2, bsz=32, num_updates=12470, lr=3.50933e-05, gnorm=2.345, clip=100, loss_scale=512, train_wall=20, gb_free=15.7, wall=34244
2023-01-09 13:08:38 - progress_bar.py[line:272] - INFO: epoch 004:   1502 / 3665 loss=5.207, loss_v1=0, loss_v2=0, nll_loss=4.313, ntokens=894.9, nsentences=32, sample_size=894.9, sample_size_v1=0, sample_size_v2=0, ppl=19.88, wps=453.9, ups=0.51, wpb=894.9, bsz=32, num_updates=12480, lr=3.50788e-05, gnorm=2.059, clip=100, loss_scale=512, train_wall=20, gb_free=15.5, wall=34264
2023-01-09 13:08:58 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 256.0
2023-01-09 13:09:00 - progress_bar.py[line:272] - INFO: epoch 004:   1513 / 3665 loss=5.208, loss_v1=0, loss_v2=0, nll_loss=4.314, ntokens=993.9, nsentences=32, sample_size=993.9, sample_size_v1=0, sample_size_v2=0, ppl=19.89, wps=458.2, ups=0.46, wpb=993.9, bsz=32, num_updates=12490, lr=3.50643e-05, gnorm=1.773, clip=100, loss_scale=256, train_wall=22, gb_free=15.3, wall=34286
2023-01-09 13:09:19 - progress_bar.py[line:272] - INFO: epoch 004:   1523 / 3665 loss=5.288, loss_v1=0, loss_v2=0, nll_loss=4.402, ntokens=866.5, nsentences=32, sample_size=866.5, sample_size_v1=0, sample_size_v2=0, ppl=21.14, wps=438.6, ups=0.51, wpb=866.5, bsz=32, num_updates=12500, lr=3.50498e-05, gnorm=2.012, clip=100, loss_scale=256, train_wall=20, gb_free=15.6, wall=34306
2023-01-09 13:09:19 - train.py[line:445] - INFO: begin validation on "valid" subset
slice_id 0 seek offset 0
slice_id 0 seek offset 0
2023-01-09 13:13:58 - progress_bar.py[line:282] - INFO: epoch 004 | valid on 'valid' subset | loss 5.211 | loss_v1 0 | loss_v2 0 | nll_loss 4.299 | ntokens 117.431 | nsentences 4 | sample_size 117.431 | sample_size_v1 0 | sample_size_v2 0 | AP 0 | total positives 21.7884 | TP 0 | FP 4.99596 | ppl 19.68 | wps 526.7 | wpb 117.4 | bsz 4 | num_updates 12500 | best_AP 0
2023-01-09 13:13:58 - checkpoint_utils.py[line:64] - INFO: Preparing to save checkpoint for epoch 4 @ 12500 updates
2023-01-09 13:13:58 - trainer.py[line:431] - INFO: Saving checkpoint to ../../checkpoints/OFA/detection_checkpoints/10_5e-5_512/checkpoint_4_12500.pt
2023-01-09 13:14:01 - trainer.py[line:441] - INFO: Finished saving checkpoint to ../../checkpoints/OFA/detection_checkpoints/10_5e-5_512/checkpoint_4_12500.pt
2023-01-09 13:15:14 - checkpoint_utils.py[line:133] - INFO: Saved checkpoint ../../checkpoints/OFA/detection_checkpoints/10_5e-5_512/checkpoint_4_12500.pt (epoch 4 @ 12500 updates, score 0.0) (writing took 75.91821954818442 seconds)
2023-01-09 13:15:33 - progress_bar.py[line:272] - INFO: epoch 004:   1533 / 3665 loss=5.241, loss_v1=0, loss_v2=0, nll_loss=4.351, ntokens=847.1, nsentences=32, sample_size=847.1, sample_size_v1=0, sample_size_v2=0, ppl=20.41, wps=22.7, ups=0.03, wpb=847.1, bsz=32, num_updates=12510, lr=3.50353e-05, gnorm=2.128, clip=100, loss_scale=256, train_wall=19, gb_free=15.4, wall=34679
2023-01-09 13:15:53 - progress_bar.py[line:272] - INFO: epoch 004:   1543 / 3665 loss=5.217, loss_v1=0, loss_v2=0, nll_loss=4.323, ntokens=952, nsentences=32, sample_size=952, sample_size_v1=0, sample_size_v2=0, ppl=20.02, wps=489.6, ups=0.51, wpb=952, bsz=32, num_updates=12520, lr=3.50208e-05, gnorm=1.821, clip=100, loss_scale=256, train_wall=19, gb_free=15.6, wall=34699
2023-01-09 13:16:12 - progress_bar.py[line:272] - INFO: epoch 004:   1553 / 3665 loss=5.321, loss_v1=0, loss_v2=0, nll_loss=4.439, ntokens=948.5, nsentences=32, sample_size=948.5, sample_size_v1=0, sample_size_v2=0, ppl=21.69, wps=484.1, ups=0.51, wpb=948.5, bsz=32, num_updates=12530, lr=3.50062e-05, gnorm=1.986, clip=100, loss_scale=256, train_wall=20, gb_free=15, wall=34718
2023-01-09 13:16:32 - progress_bar.py[line:272] - INFO: epoch 004:   1563 / 3665 loss=5.217, loss_v1=0, loss_v2=0, nll_loss=4.323, ntokens=811.5, nsentences=32, sample_size=811.5, sample_size_v1=0, sample_size_v2=0, ppl=20.01, wps=413.5, ups=0.51, wpb=811.5, bsz=32, num_updates=12540, lr=3.49917e-05, gnorm=2.162, clip=100, loss_scale=256, train_wall=20, gb_free=15.5, wall=34738
2023-01-09 13:16:51 - progress_bar.py[line:272] - INFO: epoch 004:   1573 / 3665 loss=5.233, loss_v1=0, loss_v2=0, nll_loss=4.343, ntokens=1055.7, nsentences=32, sample_size=1055.7, sample_size_v1=0, sample_size_v2=0, ppl=20.3, wps=538.8, ups=0.51, wpb=1055.7, bsz=32, num_updates=12550, lr=3.49772e-05, gnorm=1.821, clip=100, loss_scale=256, train_wall=20, gb_free=15.5, wall=34758
2023-01-09 13:17:11 - progress_bar.py[line:272] - INFO: epoch 004:   1583 / 3665 loss=5.272, loss_v1=0, loss_v2=0, nll_loss=4.384, ntokens=897.3, nsentences=32, sample_size=897.3, sample_size_v1=0, sample_size_v2=0, ppl=20.88, wps=456.2, ups=0.51, wpb=897.3, bsz=32, num_updates=12560, lr=3.49627e-05, gnorm=1.957, clip=100, loss_scale=256, train_wall=20, gb_free=15.2, wall=34777
2023-01-09 13:17:31 - progress_bar.py[line:272] - INFO: epoch 004:   1593 / 3665 loss=5.233, loss_v1=0, loss_v2=0, nll_loss=4.342, ntokens=867.6, nsentences=32, sample_size=867.6, sample_size_v1=0, sample_size_v2=0, ppl=20.27, wps=442.8, ups=0.51, wpb=867.6, bsz=32, num_updates=12570, lr=3.49482e-05, gnorm=2.106, clip=100, loss_scale=256, train_wall=20, gb_free=15.4, wall=34797
2023-01-09 13:17:50 - progress_bar.py[line:272] - INFO: epoch 004:   1603 / 3665 loss=5.158, loss_v1=0, loss_v2=0, nll_loss=4.258, ntokens=1001.6, nsentences=32, sample_size=1001.6, sample_size_v1=0, sample_size_v2=0, ppl=19.13, wps=510.9, ups=0.51, wpb=1001.6, bsz=32, num_updates=12580, lr=3.49337e-05, gnorm=2, clip=100, loss_scale=256, train_wall=20, gb_free=15.5, wall=34816
2023-01-09 13:18:10 - progress_bar.py[line:272] - INFO: epoch 004:   1613 / 3665 loss=5.256, loss_v1=0, loss_v2=0, nll_loss=4.366, ntokens=889.2, nsentences=32, sample_size=889.2, sample_size_v1=0, sample_size_v2=0, ppl=20.63, wps=450.7, ups=0.51, wpb=889.2, bsz=32, num_updates=12590, lr=3.49192e-05, gnorm=2.109, clip=100, loss_scale=256, train_wall=20, gb_free=15.3, wall=34836
2023-01-09 13:18:30 - progress_bar.py[line:272] - INFO: epoch 004:   1623 / 3665 loss=5.294, loss_v1=0, loss_v2=0, nll_loss=4.411, ntokens=938.7, nsentences=32, sample_size=938.7, sample_size_v1=0, sample_size_v2=0, ppl=21.28, wps=477.4, ups=0.51, wpb=938.7, bsz=32, num_updates=12600, lr=3.49046e-05, gnorm=2.179, clip=100, loss_scale=256, train_wall=20, gb_free=14.7, wall=34856
2023-01-09 13:18:49 - progress_bar.py[line:272] - INFO: epoch 004:   1633 / 3665 loss=5.137, loss_v1=0, loss_v2=0, nll_loss=4.235, ntokens=927.1, nsentences=32, sample_size=927.1, sample_size_v1=0, sample_size_v2=0, ppl=18.83, wps=470.6, ups=0.51, wpb=927.1, bsz=32, num_updates=12610, lr=3.48901e-05, gnorm=1.969, clip=100, loss_scale=256, train_wall=20, gb_free=14.9, wall=34876
2023-01-09 13:19:09 - progress_bar.py[line:272] - INFO: epoch 004:   1643 / 3665 loss=5.237, loss_v1=0, loss_v2=0, nll_loss=4.345, ntokens=1238.4, nsentences=32, sample_size=1238.4, sample_size_v1=0, sample_size_v2=0, ppl=20.33, wps=624.8, ups=0.5, wpb=1238.4, bsz=32, num_updates=12620, lr=3.48756e-05, gnorm=1.647, clip=100, loss_scale=256, train_wall=20, gb_free=15.3, wall=34895
2023-01-09 13:19:29 - progress_bar.py[line:272] - INFO: epoch 004:   1653 / 3665 loss=5.213, loss_v1=0, loss_v2=0, nll_loss=4.32, ntokens=913.8, nsentences=32, sample_size=913.8, sample_size_v1=0, sample_size_v2=0, ppl=19.98, wps=464.4, ups=0.51, wpb=913.8, bsz=32, num_updates=12630, lr=3.48611e-05, gnorm=1.966, clip=100, loss_scale=256, train_wall=20, gb_free=15.5, wall=34915
2023-01-09 13:19:49 - progress_bar.py[line:272] - INFO: epoch 004:   1663 / 3665 loss=5.197, loss_v1=0, loss_v2=0, nll_loss=4.3, ntokens=865.5, nsentences=32, sample_size=865.5, sample_size_v1=0, sample_size_v2=0, ppl=19.7, wps=439.3, ups=0.51, wpb=865.5, bsz=32, num_updates=12640, lr=3.48466e-05, gnorm=2.225, clip=100, loss_scale=256, train_wall=20, gb_free=15.5, wall=34935
2023-01-09 13:20:08 - progress_bar.py[line:272] - INFO: epoch 004:   1673 / 3665 loss=5.222, loss_v1=0, loss_v2=0, nll_loss=4.329, ntokens=987.5, nsentences=32, sample_size=987.5, sample_size_v1=0, sample_size_v2=0, ppl=20.1, wps=498.7, ups=0.5, wpb=987.5, bsz=32, num_updates=12650, lr=3.48321e-05, gnorm=1.951, clip=100, loss_scale=256, train_wall=20, gb_free=15.5, wall=34955
2023-01-09 13:20:29 - progress_bar.py[line:272] - INFO: epoch 004:   1683 / 3665 loss=5.251, loss_v1=0, loss_v2=0, nll_loss=4.36, ntokens=821.9, nsentences=32, sample_size=821.9, sample_size_v1=0, sample_size_v2=0, ppl=20.53, wps=402.7, ups=0.49, wpb=821.9, bsz=32, num_updates=12660, lr=3.48176e-05, gnorm=2.06, clip=100, loss_scale=256, train_wall=20, gb_free=15.3, wall=34975
2023-01-09 13:20:49 - progress_bar.py[line:272] - INFO: epoch 004:   1693 / 3665 loss=5.24, loss_v1=0, loss_v2=0, nll_loss=4.347, ntokens=1077.5, nsentences=32, sample_size=1077.5, sample_size_v1=0, sample_size_v2=0, ppl=20.36, wps=527.6, ups=0.49, wpb=1077.5, bsz=32, num_updates=12670, lr=3.48031e-05, gnorm=1.699, clip=100, loss_scale=256, train_wall=20, gb_free=15.3, wall=34995
2023-01-09 13:21:09 - progress_bar.py[line:272] - INFO: epoch 004:   1703 / 3665 loss=5.166, loss_v1=0, loss_v2=0, nll_loss=4.268, ntokens=997.3, nsentences=32, sample_size=997.3, sample_size_v1=0, sample_size_v2=0, ppl=19.27, wps=499.6, ups=0.5, wpb=997.3, bsz=32, num_updates=12680, lr=3.47885e-05, gnorm=2.022, clip=100, loss_scale=256, train_wall=20, gb_free=14.2, wall=35015
2023-01-09 13:21:29 - progress_bar.py[line:272] - INFO: epoch 004:   1713 / 3665 loss=5.218, loss_v1=0, loss_v2=0, nll_loss=4.326, ntokens=726.1, nsentences=32, sample_size=726.1, sample_size_v1=0, sample_size_v2=0, ppl=20.05, wps=371.8, ups=0.51, wpb=726.1, bsz=32, num_updates=12690, lr=3.4774e-05, gnorm=2.367, clip=100, loss_scale=256, train_wall=20, gb_free=15.3, wall=35035
2023-01-09 13:21:48 - progress_bar.py[line:272] - INFO: epoch 004:   1723 / 3665 loss=5.168, loss_v1=0, loss_v2=0, nll_loss=4.271, ntokens=833.3, nsentences=32, sample_size=833.3, sample_size_v1=0, sample_size_v2=0, ppl=19.31, wps=427.5, ups=0.51, wpb=833.3, bsz=32, num_updates=12700, lr=3.47595e-05, gnorm=2.155, clip=100, loss_scale=256, train_wall=19, gb_free=15.4, wall=35054
2023-01-09 13:22:08 - progress_bar.py[line:272] - INFO: epoch 004:   1733 / 3665 loss=5.144, loss_v1=0, loss_v2=0, nll_loss=4.243, ntokens=1013, nsentences=32, sample_size=1013, sample_size_v1=0, sample_size_v2=0, ppl=18.93, wps=514.1, ups=0.51, wpb=1013, bsz=32, num_updates=12710, lr=3.4745e-05, gnorm=1.97, clip=100, loss_scale=256, train_wall=20, gb_free=15.3, wall=35074
2023-01-09 13:22:27 - progress_bar.py[line:272] - INFO: epoch 004:   1743 / 3665 loss=5.249, loss_v1=0, loss_v2=0, nll_loss=4.359, ntokens=917.8, nsentences=32, sample_size=917.8, sample_size_v1=0, sample_size_v2=0, ppl=20.52, wps=466.7, ups=0.51, wpb=917.8, bsz=32, num_updates=12720, lr=3.47305e-05, gnorm=1.882, clip=100, loss_scale=256, train_wall=20, gb_free=15.5, wall=35094
2023-01-09 13:22:47 - progress_bar.py[line:272] - INFO: epoch 004:   1753 / 3665 loss=5.215, loss_v1=0, loss_v2=0, nll_loss=4.322, ntokens=858, nsentences=32, sample_size=858, sample_size_v1=0, sample_size_v2=0, ppl=20, wps=435.5, ups=0.51, wpb=858, bsz=32, num_updates=12730, lr=3.4716e-05, gnorm=2.121, clip=100, loss_scale=256, train_wall=20, gb_free=15.3, wall=35113
2023-01-09 13:23:07 - progress_bar.py[line:272] - INFO: epoch 004:   1763 / 3665 loss=5.158, loss_v1=0, loss_v2=0, nll_loss=4.26, ntokens=1078.3, nsentences=32, sample_size=1078.3, sample_size_v1=0, sample_size_v2=0, ppl=19.16, wps=544.9, ups=0.51, wpb=1078.3, bsz=32, num_updates=12740, lr=3.47015e-05, gnorm=1.778, clip=100, loss_scale=256, train_wall=20, gb_free=15.4, wall=35133
2023-01-09 13:23:27 - progress_bar.py[line:272] - INFO: epoch 004:   1773 / 3665 loss=5.344, loss_v1=0, loss_v2=0, nll_loss=4.464, ntokens=953.3, nsentences=32, sample_size=953.3, sample_size_v1=0, sample_size_v2=0, ppl=22.07, wps=484.1, ups=0.51, wpb=953.3, bsz=32, num_updates=12750, lr=3.46869e-05, gnorm=1.977, clip=100, loss_scale=256, train_wall=20, gb_free=15.5, wall=35153
2023-01-09 13:23:46 - progress_bar.py[line:272] - INFO: epoch 004:   1783 / 3665 loss=5.178, loss_v1=0, loss_v2=0, nll_loss=4.278, ntokens=810.4, nsentences=32, sample_size=810.4, sample_size_v1=0, sample_size_v2=0, ppl=19.4, wps=411.9, ups=0.51, wpb=810.4, bsz=32, num_updates=12760, lr=3.46724e-05, gnorm=2.174, clip=100, loss_scale=256, train_wall=20, gb_free=15.4, wall=35173
2023-01-09 13:24:07 - progress_bar.py[line:272] - INFO: epoch 004:   1793 / 3665 loss=5.154, loss_v1=0, loss_v2=0, nll_loss=4.253, ntokens=964.6, nsentences=32, sample_size=964.6, sample_size_v1=0, sample_size_v2=0, ppl=19.06, wps=477.3, ups=0.49, wpb=964.6, bsz=32, num_updates=12770, lr=3.46579e-05, gnorm=1.85, clip=100, loss_scale=256, train_wall=20, gb_free=15.4, wall=35193
2023-01-09 13:24:27 - progress_bar.py[line:272] - INFO: epoch 004:   1803 / 3665 loss=5.231, loss_v1=0, loss_v2=0, nll_loss=4.34, ntokens=871.6, nsentences=32, sample_size=871.6, sample_size_v1=0, sample_size_v2=0, ppl=20.26, wps=421.1, ups=0.48, wpb=871.6, bsz=32, num_updates=12780, lr=3.46434e-05, gnorm=2.022, clip=100, loss_scale=256, train_wall=21, gb_free=15.4, wall=35214
2023-01-09 13:24:48 - progress_bar.py[line:272] - INFO: epoch 004:   1813 / 3665 loss=5.165, loss_v1=0, loss_v2=0, nll_loss=4.267, ntokens=807.7, nsentences=32, sample_size=807.7, sample_size_v1=0, sample_size_v2=0, ppl=19.25, wps=395.1, ups=0.49, wpb=807.7, bsz=32, num_updates=12790, lr=3.46289e-05, gnorm=2.311, clip=100, loss_scale=256, train_wall=20, gb_free=15.6, wall=35234
2023-01-09 13:25:07 - progress_bar.py[line:272] - INFO: epoch 004:   1823 / 3665 loss=5.112, loss_v1=0, loss_v2=0, nll_loss=4.206, ntokens=976.2, nsentences=32, sample_size=976.2, sample_size_v1=0, sample_size_v2=0, ppl=18.46, wps=498, ups=0.51, wpb=976.2, bsz=32, num_updates=12800, lr=3.46144e-05, gnorm=1.877, clip=100, loss_scale=256, train_wall=20, gb_free=15.2, wall=35254
2023-01-09 13:25:27 - progress_bar.py[line:272] - INFO: epoch 004:   1833 / 3665 loss=5.301, loss_v1=0, loss_v2=0, nll_loss=4.418, ntokens=1066.6, nsentences=32, sample_size=1066.6, sample_size_v1=0, sample_size_v2=0, ppl=21.37, wps=541.1, ups=0.51, wpb=1066.6, bsz=32, num_updates=12810, lr=3.45999e-05, gnorm=1.903, clip=100, loss_scale=256, train_wall=20, gb_free=15.5, wall=35273
2023-01-09 13:25:47 - progress_bar.py[line:272] - INFO: epoch 004:   1843 / 3665 loss=5.183, loss_v1=0, loss_v2=0, nll_loss=4.285, ntokens=748.7, nsentences=32, sample_size=748.7, sample_size_v1=0, sample_size_v2=0, ppl=19.49, wps=382.3, ups=0.51, wpb=748.7, bsz=32, num_updates=12820, lr=3.45854e-05, gnorm=2.181, clip=100, loss_scale=256, train_wall=20, gb_free=15.7, wall=35293
2023-01-09 13:26:06 - progress_bar.py[line:272] - INFO: epoch 004:   1853 / 3665 loss=5.206, loss_v1=0, loss_v2=0, nll_loss=4.313, ntokens=906.3, nsentences=32, sample_size=906.3, sample_size_v1=0, sample_size_v2=0, ppl=19.88, wps=460.8, ups=0.51, wpb=906.3, bsz=32, num_updates=12830, lr=3.45708e-05, gnorm=1.963, clip=100, loss_scale=256, train_wall=20, gb_free=15.3, wall=35313
2023-01-09 13:26:26 - progress_bar.py[line:272] - INFO: epoch 004:   1863 / 3665 loss=5.202, loss_v1=0, loss_v2=0, nll_loss=4.307, ntokens=975.6, nsentences=32, sample_size=975.6, sample_size_v1=0, sample_size_v2=0, ppl=19.79, wps=494.8, ups=0.51, wpb=975.6, bsz=32, num_updates=12840, lr=3.45563e-05, gnorm=2.021, clip=100, loss_scale=256, train_wall=20, gb_free=15.4, wall=35332
2023-01-09 13:26:46 - progress_bar.py[line:272] - INFO: epoch 004:   1873 / 3665 loss=5.205, loss_v1=0, loss_v2=0, nll_loss=4.31, ntokens=837.8, nsentences=32, sample_size=837.8, sample_size_v1=0, sample_size_v2=0, ppl=19.84, wps=425.9, ups=0.51, wpb=837.8, bsz=32, num_updates=12850, lr=3.45418e-05, gnorm=2.203, clip=100, loss_scale=256, train_wall=20, gb_free=15.5, wall=35352
2023-01-09 13:27:05 - progress_bar.py[line:272] - INFO: epoch 004:   1883 / 3665 loss=5.233, loss_v1=0, loss_v2=0, nll_loss=4.341, ntokens=1044.3, nsentences=32, sample_size=1044.3, sample_size_v1=0, sample_size_v2=0, ppl=20.27, wps=528.9, ups=0.51, wpb=1044.3, bsz=32, num_updates=12860, lr=3.45273e-05, gnorm=1.831, clip=100, loss_scale=256, train_wall=20, gb_free=15.5, wall=35372
2023-01-09 13:27:25 - progress_bar.py[line:272] - INFO: epoch 004:   1893 / 3665 loss=5.227, loss_v1=0, loss_v2=0, nll_loss=4.334, ntokens=1111.8, nsentences=32, sample_size=1111.8, sample_size_v1=0, sample_size_v2=0, ppl=20.17, wps=561.3, ups=0.5, wpb=1111.8, bsz=32, num_updates=12870, lr=3.45128e-05, gnorm=1.721, clip=100, loss_scale=256, train_wall=20, gb_free=15.5, wall=35391
2023-01-09 13:27:45 - progress_bar.py[line:272] - INFO: epoch 004:   1903 / 3665 loss=5.302, loss_v1=0, loss_v2=0, nll_loss=4.42, ntokens=797.9, nsentences=32, sample_size=797.9, sample_size_v1=0, sample_size_v2=0, ppl=21.4, wps=401.8, ups=0.5, wpb=797.9, bsz=32, num_updates=12880, lr=3.44983e-05, gnorm=2.116, clip=100, loss_scale=256, train_wall=20, gb_free=15.2, wall=35411
2023-01-09 13:28:05 - progress_bar.py[line:272] - INFO: epoch 004:   1913 / 3665 loss=5.228, loss_v1=0, loss_v2=0, nll_loss=4.336, ntokens=863.7, nsentences=32, sample_size=863.7, sample_size_v1=0, sample_size_v2=0, ppl=20.19, wps=431.8, ups=0.5, wpb=863.7, bsz=32, num_updates=12890, lr=3.44838e-05, gnorm=1.982, clip=100, loss_scale=256, train_wall=20, gb_free=15.5, wall=35431
2023-01-09 13:28:25 - progress_bar.py[line:272] - INFO: epoch 004:   1923 / 3665 loss=5.16, loss_v1=0, loss_v2=0, nll_loss=4.261, ntokens=928.3, nsentences=32, sample_size=928.3, sample_size_v1=0, sample_size_v2=0, ppl=19.18, wps=464.3, ups=0.5, wpb=928.3, bsz=32, num_updates=12900, lr=3.44692e-05, gnorm=2.123, clip=100, loss_scale=256, train_wall=20, gb_free=15.4, wall=35451
2023-01-09 13:28:45 - progress_bar.py[line:272] - INFO: epoch 004:   1933 / 3665 loss=5.302, loss_v1=0, loss_v2=0, nll_loss=4.416, ntokens=954.1, nsentences=32, sample_size=954.1, sample_size_v1=0, sample_size_v2=0, ppl=21.35, wps=474.2, ups=0.5, wpb=954.1, bsz=32, num_updates=12910, lr=3.44547e-05, gnorm=2.071, clip=100, loss_scale=256, train_wall=20, gb_free=15.6, wall=35471
2023-01-09 13:29:05 - progress_bar.py[line:272] - INFO: epoch 004:   1943 / 3665 loss=5.182, loss_v1=0, loss_v2=0, nll_loss=4.284, ntokens=761.9, nsentences=32, sample_size=761.9, sample_size_v1=0, sample_size_v2=0, ppl=19.48, wps=381.7, ups=0.5, wpb=761.9, bsz=32, num_updates=12920, lr=3.44402e-05, gnorm=2.493, clip=100, loss_scale=256, train_wall=20, gb_free=15.4, wall=35491
2023-01-09 13:29:25 - progress_bar.py[line:272] - INFO: epoch 004:   1953 / 3665 loss=5.156, loss_v1=0, loss_v2=0, nll_loss=4.258, ntokens=925.4, nsentences=32, sample_size=925.4, sample_size_v1=0, sample_size_v2=0, ppl=19.13, wps=464.7, ups=0.5, wpb=925.4, bsz=32, num_updates=12930, lr=3.44257e-05, gnorm=1.974, clip=100, loss_scale=256, train_wall=20, gb_free=15.4, wall=35511
2023-01-09 13:29:45 - progress_bar.py[line:272] - INFO: epoch 004:   1963 / 3665 loss=5.234, loss_v1=0, loss_v2=0, nll_loss=4.342, ntokens=1065.4, nsentences=32, sample_size=1065.4, sample_size_v1=0, sample_size_v2=0, ppl=20.28, wps=533.5, ups=0.5, wpb=1065.4, bsz=32, num_updates=12940, lr=3.44112e-05, gnorm=1.821, clip=100, loss_scale=256, train_wall=20, gb_free=15.4, wall=35531
2023-01-09 13:30:05 - progress_bar.py[line:272] - INFO: epoch 004:   1973 / 3665 loss=5.248, loss_v1=0, loss_v2=0, nll_loss=4.359, ntokens=918.4, nsentences=32, sample_size=918.4, sample_size_v1=0, sample_size_v2=0, ppl=20.52, wps=465.7, ups=0.51, wpb=918.4, bsz=32, num_updates=12950, lr=3.43967e-05, gnorm=2.003, clip=100, loss_scale=256, train_wall=20, gb_free=14.5, wall=35551
2023-01-09 13:30:24 - progress_bar.py[line:272] - INFO: epoch 004:   1983 / 3665 loss=5.169, loss_v1=0, loss_v2=0, nll_loss=4.269, ntokens=1007, nsentences=32, sample_size=1007, sample_size_v1=0, sample_size_v2=0, ppl=19.28, wps=510.8, ups=0.51, wpb=1007, bsz=32, num_updates=12960, lr=3.43822e-05, gnorm=1.981, clip=100, loss_scale=256, train_wall=20, gb_free=14.9, wall=35571
2023-01-09 13:30:44 - progress_bar.py[line:272] - INFO: epoch 004:   1993 / 3665 loss=5.274, loss_v1=0, loss_v2=0, nll_loss=4.388, ntokens=1037.8, nsentences=32, sample_size=1037.8, sample_size_v1=0, sample_size_v2=0, ppl=20.94, wps=525, ups=0.51, wpb=1037.8, bsz=32, num_updates=12970, lr=3.43677e-05, gnorm=1.841, clip=100, loss_scale=256, train_wall=20, gb_free=15.4, wall=35591
2023-01-09 13:31:04 - progress_bar.py[line:272] - INFO: epoch 004:   2003 / 3665 loss=5.201, loss_v1=0, loss_v2=0, nll_loss=4.307, ntokens=816.6, nsentences=32, sample_size=816.6, sample_size_v1=0, sample_size_v2=0, ppl=19.8, wps=414.4, ups=0.51, wpb=816.6, bsz=32, num_updates=12980, lr=3.43531e-05, gnorm=2.193, clip=100, loss_scale=256, train_wall=20, gb_free=15.4, wall=35610
2023-01-09 13:31:24 - progress_bar.py[line:272] - INFO: epoch 004:   2013 / 3665 loss=5.184, loss_v1=0, loss_v2=0, nll_loss=4.287, ntokens=925.5, nsentences=32, sample_size=925.5, sample_size_v1=0, sample_size_v2=0, ppl=19.52, wps=469.7, ups=0.51, wpb=925.5, bsz=32, num_updates=12990, lr=3.43386e-05, gnorm=1.782, clip=100, loss_scale=256, train_wall=20, gb_free=15.5, wall=35630
2023-01-09 13:31:44 - progress_bar.py[line:272] - INFO: epoch 004:   2023 / 3665 loss=5.322, loss_v1=0, loss_v2=0, nll_loss=4.441, ntokens=1094.4, nsentences=32, sample_size=1094.4, sample_size_v1=0, sample_size_v2=0, ppl=21.73, wps=548.8, ups=0.5, wpb=1094.4, bsz=32, num_updates=13000, lr=3.43241e-05, gnorm=1.794, clip=100, loss_scale=256, train_wall=20, gb_free=15.7, wall=35650
2023-01-09 13:31:44 - train.py[line:445] - INFO: begin validation on "valid" subset
slice_id 0 seek offset 0
slice_id 0 seek offset 0
2023-01-09 13:36:44 - progress_bar.py[line:282] - INFO: epoch 004 | valid on 'valid' subset | loss 5.19 | loss_v1 0 | loss_v2 0 | nll_loss 4.278 | ntokens 117.448 | nsentences 4 | sample_size 117.448 | sample_size_v1 0 | sample_size_v2 0 | AP 0 | total positives 21.7932 | TP 0 | FP 6.07431 | ppl 19.39 | wps 489 | wpb 117.4 | bsz 4 | num_updates 13000 | best_AP 0
2023-01-09 13:36:44 - checkpoint_utils.py[line:64] - INFO: Preparing to save checkpoint for epoch 4 @ 13000 updates
2023-01-09 13:36:44 - trainer.py[line:431] - INFO: Saving checkpoint to ../../checkpoints/OFA/detection_checkpoints/10_5e-5_512/checkpoint_4_13000.pt
2023-01-09 13:36:47 - trainer.py[line:441] - INFO: Finished saving checkpoint to ../../checkpoints/OFA/detection_checkpoints/10_5e-5_512/checkpoint_4_13000.pt
2023-01-09 13:38:01 - checkpoint_utils.py[line:133] - INFO: Saved checkpoint ../../checkpoints/OFA/detection_checkpoints/10_5e-5_512/checkpoint_4_13000.pt (epoch 4 @ 13000 updates, score 0.0) (writing took 77.09617990395054 seconds)
2023-01-09 13:38:16 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 256.0
2023-01-09 13:38:22 - progress_bar.py[line:272] - INFO: epoch 004:   2034 / 3665 loss=5.21, loss_v1=0, loss_v2=0, nll_loss=4.317, ntokens=771.4, nsentences=32, sample_size=771.4, sample_size_v1=0, sample_size_v2=0, ppl=19.93, wps=19.4, ups=0.03, wpb=771.4, bsz=32, num_updates=13010, lr=3.43096e-05, gnorm=2.308, clip=100, loss_scale=256, train_wall=21, gb_free=15.6, wall=36048
2023-01-09 13:38:42 - progress_bar.py[line:272] - INFO: epoch 004:   2044 / 3665 loss=5.116, loss_v1=0, loss_v2=0, nll_loss=4.211, ntokens=852.4, nsentences=32, sample_size=852.4, sample_size_v1=0, sample_size_v2=0, ppl=18.52, wps=438.2, ups=0.51, wpb=852.4, bsz=32, num_updates=13020, lr=3.42951e-05, gnorm=2.13, clip=100, loss_scale=256, train_wall=19, gb_free=15.3, wall=36068
2023-01-09 13:39:01 - progress_bar.py[line:272] - INFO: epoch 004:   2054 / 3665 loss=5.222, loss_v1=0, loss_v2=0, nll_loss=4.33, ntokens=979.6, nsentences=32, sample_size=979.6, sample_size_v1=0, sample_size_v2=0, ppl=20.11, wps=501.2, ups=0.51, wpb=979.6, bsz=32, num_updates=13030, lr=3.42806e-05, gnorm=1.844, clip=100, loss_scale=256, train_wall=20, gb_free=15.5, wall=36087
2023-01-09 13:39:21 - progress_bar.py[line:272] - INFO: epoch 004:   2064 / 3665 loss=5.194, loss_v1=0, loss_v2=0, nll_loss=4.299, ntokens=788, nsentences=32, sample_size=788, sample_size_v1=0, sample_size_v2=0, ppl=19.68, wps=399.3, ups=0.51, wpb=788, bsz=32, num_updates=13040, lr=3.42661e-05, gnorm=2.334, clip=100, loss_scale=256, train_wall=20, gb_free=15.2, wall=36107
2023-01-09 13:39:41 - progress_bar.py[line:272] - INFO: epoch 004:   2074 / 3665 loss=5.138, loss_v1=0, loss_v2=0, nll_loss=4.234, ntokens=931.9, nsentences=32, sample_size=931.9, sample_size_v1=0, sample_size_v2=0, ppl=18.82, wps=474.3, ups=0.51, wpb=931.9, bsz=32, num_updates=13050, lr=3.42515e-05, gnorm=1.97, clip=100, loss_scale=256, train_wall=20, gb_free=15.5, wall=36127
2023-01-09 13:40:00 - progress_bar.py[line:272] - INFO: epoch 004:   2084 / 3665 loss=5.306, loss_v1=0, loss_v2=0, nll_loss=4.424, ntokens=1122.1, nsentences=32, sample_size=1122.1, sample_size_v1=0, sample_size_v2=0, ppl=21.47, wps=564.1, ups=0.5, wpb=1122.1, bsz=32, num_updates=13060, lr=3.4237e-05, gnorm=1.814, clip=100, loss_scale=256, train_wall=20, gb_free=15.4, wall=36147
2023-01-09 13:40:20 - progress_bar.py[line:272] - INFO: epoch 004:   2094 / 3665 loss=5.26, loss_v1=0, loss_v2=0, nll_loss=4.371, ntokens=746.9, nsentences=32, sample_size=746.9, sample_size_v1=0, sample_size_v2=0, ppl=20.69, wps=381.1, ups=0.51, wpb=746.9, bsz=32, num_updates=13070, lr=3.42225e-05, gnorm=2.404, clip=100, loss_scale=256, train_wall=20, gb_free=15.7, wall=36166
2023-01-09 13:40:40 - progress_bar.py[line:272] - INFO: epoch 004:   2104 / 3665 loss=5.156, loss_v1=0, loss_v2=0, nll_loss=4.255, ntokens=975.5, nsentences=32, sample_size=975.5, sample_size_v1=0, sample_size_v2=0, ppl=19.1, wps=495.1, ups=0.51, wpb=975.5, bsz=32, num_updates=13080, lr=3.4208e-05, gnorm=1.807, clip=100, loss_scale=256, train_wall=20, gb_free=15.4, wall=36186
2023-01-09 13:40:59 - progress_bar.py[line:272] - INFO: epoch 004:   2114 / 3665 loss=5.116, loss_v1=0, loss_v2=0, nll_loss=4.211, ntokens=927.8, nsentences=32, sample_size=927.8, sample_size_v1=0, sample_size_v2=0, ppl=18.51, wps=472.9, ups=0.51, wpb=927.8, bsz=32, num_updates=13090, lr=3.41935e-05, gnorm=1.91, clip=100, loss_scale=256, train_wall=20, gb_free=15.5, wall=36206
2023-01-09 13:41:19 - progress_bar.py[line:272] - INFO: epoch 004:   2124 / 3665 loss=5.295, loss_v1=0, loss_v2=0, nll_loss=4.412, ntokens=980, nsentences=32, sample_size=980, sample_size_v1=0, sample_size_v2=0, ppl=21.28, wps=496.2, ups=0.51, wpb=980, bsz=32, num_updates=13100, lr=3.4179e-05, gnorm=1.937, clip=90, loss_scale=256, train_wall=20, gb_free=15.5, wall=36225
2023-01-09 13:41:39 - progress_bar.py[line:272] - INFO: epoch 004:   2134 / 3665 loss=5.194, loss_v1=0, loss_v2=0, nll_loss=4.298, ntokens=890.4, nsentences=32, sample_size=890.4, sample_size_v1=0, sample_size_v2=0, ppl=19.66, wps=453.5, ups=0.51, wpb=890.4, bsz=32, num_updates=13110, lr=3.41645e-05, gnorm=1.986, clip=100, loss_scale=256, train_wall=20, gb_free=15.5, wall=36245
2023-01-09 13:41:58 - progress_bar.py[line:272] - INFO: epoch 004:   2144 / 3665 loss=5.105, loss_v1=0, loss_v2=0, nll_loss=4.2, ntokens=1019.6, nsentences=32, sample_size=1019.6, sample_size_v1=0, sample_size_v2=0, ppl=18.38, wps=515.8, ups=0.51, wpb=1019.6, bsz=32, num_updates=13120, lr=3.415e-05, gnorm=1.97, clip=100, loss_scale=256, train_wall=20, gb_free=15.5, wall=36265
2023-01-09 13:42:18 - progress_bar.py[line:272] - INFO: epoch 004:   2154 / 3665 loss=5.262, loss_v1=0, loss_v2=0, nll_loss=4.373, ntokens=933.4, nsentences=32, sample_size=933.4, sample_size_v1=0, sample_size_v2=0, ppl=20.73, wps=472.4, ups=0.51, wpb=933.4, bsz=32, num_updates=13130, lr=3.41354e-05, gnorm=2.058, clip=100, loss_scale=256, train_wall=20, gb_free=15.4, wall=36285
2023-01-09 13:42:38 - progress_bar.py[line:272] - INFO: epoch 004:   2164 / 3665 loss=5.257, loss_v1=0, loss_v2=0, nll_loss=4.37, ntokens=949.4, nsentences=32, sample_size=949.4, sample_size_v1=0, sample_size_v2=0, ppl=20.67, wps=482.7, ups=0.51, wpb=949.4, bsz=32, num_updates=13140, lr=3.41209e-05, gnorm=2.067, clip=100, loss_scale=256, train_wall=20, gb_free=15.5, wall=36304
2023-01-09 13:42:58 - progress_bar.py[line:272] - INFO: epoch 004:   2174 / 3665 loss=5.129, loss_v1=0, loss_v2=0, nll_loss=4.228, ntokens=894, nsentences=32, sample_size=894, sample_size_v1=0, sample_size_v2=0, ppl=18.75, wps=453.4, ups=0.51, wpb=894, bsz=32, num_updates=13150, lr=3.41064e-05, gnorm=1.968, clip=100, loss_scale=256, train_wall=20, gb_free=15.2, wall=36324
2023-01-09 13:43:18 - progress_bar.py[line:272] - INFO: epoch 004:   2184 / 3665 loss=5.226, loss_v1=0, loss_v2=0, nll_loss=4.334, ntokens=984.8, nsentences=32, sample_size=984.8, sample_size_v1=0, sample_size_v2=0, ppl=20.16, wps=485.8, ups=0.49, wpb=984.8, bsz=32, num_updates=13160, lr=3.40919e-05, gnorm=1.958, clip=100, loss_scale=256, train_wall=20, gb_free=15.4, wall=36344
2023-01-09 13:43:38 - progress_bar.py[line:272] - INFO: epoch 004:   2194 / 3665 loss=5.269, loss_v1=0, loss_v2=0, nll_loss=4.378, ntokens=939.8, nsentences=32, sample_size=939.8, sample_size_v1=0, sample_size_v2=0, ppl=20.8, wps=464.9, ups=0.49, wpb=939.8, bsz=32, num_updates=13170, lr=3.40774e-05, gnorm=2.126, clip=100, loss_scale=256, train_wall=20, gb_free=15.5, wall=36364
2023-01-09 13:43:58 - progress_bar.py[line:272] - INFO: epoch 004:   2204 / 3665 loss=5.214, loss_v1=0, loss_v2=0, nll_loss=4.322, ntokens=975.1, nsentences=32, sample_size=975.1, sample_size_v1=0, sample_size_v2=0, ppl=20, wps=482.4, ups=0.49, wpb=975.1, bsz=32, num_updates=13180, lr=3.40629e-05, gnorm=1.855, clip=100, loss_scale=256, train_wall=20, gb_free=15.5, wall=36385
2023-01-09 13:44:18 - progress_bar.py[line:272] - INFO: epoch 004:   2214 / 3665 loss=5.352, loss_v1=0, loss_v2=0, nll_loss=4.475, ntokens=1035.3, nsentences=32, sample_size=1035.3, sample_size_v1=0, sample_size_v2=0, ppl=22.24, wps=518.4, ups=0.5, wpb=1035.3, bsz=32, num_updates=13190, lr=3.40484e-05, gnorm=1.821, clip=100, loss_scale=256, train_wall=20, gb_free=15.4, wall=36405
2023-01-09 13:44:38 - progress_bar.py[line:272] - INFO: epoch 004:   2224 / 3665 loss=5.156, loss_v1=0, loss_v2=0, nll_loss=4.254, ntokens=851.5, nsentences=32, sample_size=851.5, sample_size_v1=0, sample_size_v2=0, ppl=19.09, wps=431.3, ups=0.51, wpb=851.5, bsz=32, num_updates=13200, lr=3.40338e-05, gnorm=2.018, clip=100, loss_scale=256, train_wall=20, gb_free=14.6, wall=36424
2023-01-09 13:44:58 - progress_bar.py[line:272] - INFO: epoch 004:   2234 / 3665 loss=5.115, loss_v1=0, loss_v2=0, nll_loss=4.209, ntokens=932.3, nsentences=32, sample_size=932.3, sample_size_v1=0, sample_size_v2=0, ppl=18.5, wps=475.4, ups=0.51, wpb=932.3, bsz=32, num_updates=13210, lr=3.40193e-05, gnorm=1.87, clip=100, loss_scale=256, train_wall=20, gb_free=15.6, wall=36444
2023-01-09 13:45:18 - progress_bar.py[line:272] - INFO: epoch 004:   2244 / 3665 loss=5.232, loss_v1=0, loss_v2=0, nll_loss=4.341, ntokens=950.6, nsentences=32, sample_size=950.6, sample_size_v1=0, sample_size_v2=0, ppl=20.27, wps=478.9, ups=0.5, wpb=950.6, bsz=32, num_updates=13220, lr=3.40048e-05, gnorm=1.871, clip=100, loss_scale=256, train_wall=20, gb_free=15.4, wall=36464
2023-01-09 13:45:37 - progress_bar.py[line:272] - INFO: epoch 004:   2254 / 3665 loss=5.249, loss_v1=0, loss_v2=0, nll_loss=4.36, ntokens=910.3, nsentences=32, sample_size=910.3, sample_size_v1=0, sample_size_v2=0, ppl=20.54, wps=460.6, ups=0.51, wpb=910.3, bsz=32, num_updates=13230, lr=3.39903e-05, gnorm=2.044, clip=100, loss_scale=256, train_wall=20, gb_free=15.3, wall=36484
2023-01-09 13:45:57 - progress_bar.py[line:272] - INFO: epoch 004:   2264 / 3665 loss=5.186, loss_v1=0, loss_v2=0, nll_loss=4.289, ntokens=934, nsentences=32, sample_size=934, sample_size_v1=0, sample_size_v2=0, ppl=19.55, wps=475.1, ups=0.51, wpb=934, bsz=32, num_updates=13240, lr=3.39758e-05, gnorm=2.017, clip=100, loss_scale=256, train_wall=20, gb_free=15.5, wall=36503
2023-01-09 13:46:17 - progress_bar.py[line:272] - INFO: epoch 004:   2274 / 3665 loss=5.214, loss_v1=0, loss_v2=0, nll_loss=4.32, ntokens=1117.6, nsentences=32, sample_size=1117.6, sample_size_v1=0, sample_size_v2=0, ppl=19.98, wps=560.4, ups=0.5, wpb=1117.6, bsz=32, num_updates=13250, lr=3.39613e-05, gnorm=1.813, clip=100, loss_scale=256, train_wall=20, gb_free=14.2, wall=36523
2023-01-09 13:46:36 - progress_bar.py[line:272] - INFO: epoch 004:   2284 / 3665 loss=5.217, loss_v1=0, loss_v2=0, nll_loss=4.322, ntokens=783.4, nsentences=32, sample_size=783.4, sample_size_v1=0, sample_size_v2=0, ppl=20.01, wps=399.4, ups=0.51, wpb=783.4, bsz=32, num_updates=13260, lr=3.39468e-05, gnorm=2.145, clip=100, loss_scale=256, train_wall=20, gb_free=15.5, wall=36543
2023-01-09 13:46:56 - progress_bar.py[line:272] - INFO: epoch 004:   2294 / 3665 loss=5.228, loss_v1=0, loss_v2=0, nll_loss=4.337, ntokens=1011, nsentences=32, sample_size=1011, sample_size_v1=0, sample_size_v2=0, ppl=20.21, wps=513, ups=0.51, wpb=1011, bsz=32, num_updates=13270, lr=3.39323e-05, gnorm=1.86, clip=100, loss_scale=256, train_wall=20, gb_free=15.3, wall=36562
2023-01-09 13:47:16 - progress_bar.py[line:272] - INFO: epoch 004:   2304 / 3665 loss=5.112, loss_v1=0, loss_v2=0, nll_loss=4.207, ntokens=871.6, nsentences=32, sample_size=871.6, sample_size_v1=0, sample_size_v2=0, ppl=18.47, wps=444.2, ups=0.51, wpb=871.6, bsz=32, num_updates=13280, lr=3.39177e-05, gnorm=2.014, clip=100, loss_scale=256, train_wall=20, gb_free=15.5, wall=36582
2023-01-09 13:47:36 - progress_bar.py[line:272] - INFO: epoch 004:   2314 / 3665 loss=5.244, loss_v1=0, loss_v2=0, nll_loss=4.353, ntokens=902.7, nsentences=32, sample_size=902.7, sample_size_v1=0, sample_size_v2=0, ppl=20.43, wps=458.5, ups=0.51, wpb=902.7, bsz=32, num_updates=13290, lr=3.39032e-05, gnorm=2.004, clip=100, loss_scale=256, train_wall=20, gb_free=15.5, wall=36602
2023-01-09 13:47:55 - progress_bar.py[line:272] - INFO: epoch 004:   2324 / 3665 loss=5.149, loss_v1=0, loss_v2=0, nll_loss=4.25, ntokens=823.7, nsentences=32, sample_size=823.7, sample_size_v1=0, sample_size_v2=0, ppl=19.02, wps=419.1, ups=0.51, wpb=823.7, bsz=32, num_updates=13300, lr=3.38887e-05, gnorm=2.295, clip=100, loss_scale=256, train_wall=20, gb_free=15.5, wall=36621
2023-01-09 13:48:15 - progress_bar.py[line:272] - INFO: epoch 004:   2334 / 3665 loss=5.176, loss_v1=0, loss_v2=0, nll_loss=4.278, ntokens=1090.8, nsentences=32, sample_size=1090.8, sample_size_v1=0, sample_size_v2=0, ppl=19.39, wps=546.7, ups=0.5, wpb=1090.8, bsz=32, num_updates=13310, lr=3.38742e-05, gnorm=1.689, clip=100, loss_scale=256, train_wall=20, gb_free=15.5, wall=36641
2023-01-09 13:48:35 - progress_bar.py[line:272] - INFO: epoch 004:   2344 / 3665 loss=5.277, loss_v1=0, loss_v2=0, nll_loss=4.39, ntokens=1067.2, nsentences=32, sample_size=1067.2, sample_size_v1=0, sample_size_v2=0, ppl=20.96, wps=531, ups=0.5, wpb=1067.2, bsz=32, num_updates=13320, lr=3.38597e-05, gnorm=1.732, clip=100, loss_scale=256, train_wall=20, gb_free=15.5, wall=36661
2023-01-09 13:48:55 - progress_bar.py[line:272] - INFO: epoch 004:   2354 / 3665 loss=5.256, loss_v1=0, loss_v2=0, nll_loss=4.369, ntokens=1047.8, nsentences=32, sample_size=1047.8, sample_size_v1=0, sample_size_v2=0, ppl=20.67, wps=523.2, ups=0.5, wpb=1047.8, bsz=32, num_updates=13330, lr=3.38452e-05, gnorm=2.164, clip=100, loss_scale=256, train_wall=20, gb_free=15.2, wall=36682
2023-01-09 13:49:15 - progress_bar.py[line:272] - INFO: epoch 004:   2364 / 3665 loss=5.036, loss_v1=0, loss_v2=0, nll_loss=4.121, ntokens=905.9, nsentences=32, sample_size=905.9, sample_size_v1=0, sample_size_v2=0, ppl=17.4, wps=453.9, ups=0.5, wpb=905.9, bsz=32, num_updates=13340, lr=3.38307e-05, gnorm=1.889, clip=100, loss_scale=256, train_wall=20, gb_free=15.4, wall=36701
2023-01-09 13:49:35 - progress_bar.py[line:272] - INFO: epoch 004:   2374 / 3665 loss=5.228, loss_v1=0, loss_v2=0, nll_loss=4.335, ntokens=954.4, nsentences=32, sample_size=954.4, sample_size_v1=0, sample_size_v2=0, ppl=20.19, wps=476.9, ups=0.5, wpb=954.4, bsz=32, num_updates=13350, lr=3.38161e-05, gnorm=2.076, clip=100, loss_scale=256, train_wall=20, gb_free=15.2, wall=36721
2023-01-09 13:49:55 - progress_bar.py[line:272] - INFO: epoch 004:   2384 / 3665 loss=5.198, loss_v1=0, loss_v2=0, nll_loss=4.302, ntokens=751.4, nsentences=32, sample_size=751.4, sample_size_v1=0, sample_size_v2=0, ppl=19.72, wps=376, ups=0.5, wpb=751.4, bsz=32, num_updates=13360, lr=3.38016e-05, gnorm=2.453, clip=100, loss_scale=256, train_wall=20, gb_free=15.6, wall=36741
2023-01-09 13:50:15 - progress_bar.py[line:272] - INFO: epoch 004:   2394 / 3665 loss=5.131, loss_v1=0, loss_v2=0, nll_loss=4.227, ntokens=970.9, nsentences=32, sample_size=970.9, sample_size_v1=0, sample_size_v2=0, ppl=18.72, wps=492.3, ups=0.51, wpb=970.9, bsz=32, num_updates=13370, lr=3.37871e-05, gnorm=1.845, clip=100, loss_scale=256, train_wall=20, gb_free=15.5, wall=36761
2023-01-09 13:50:35 - progress_bar.py[line:272] - INFO: epoch 004:   2404 / 3665 loss=5.181, loss_v1=0, loss_v2=0, nll_loss=4.287, ntokens=980.8, nsentences=32, sample_size=980.8, sample_size_v1=0, sample_size_v2=0, ppl=19.52, wps=497.6, ups=0.51, wpb=980.8, bsz=32, num_updates=13380, lr=3.37726e-05, gnorm=1.961, clip=100, loss_scale=256, train_wall=20, gb_free=15.5, wall=36781
2023-01-09 13:50:54 - progress_bar.py[line:272] - INFO: epoch 004:   2414 / 3665 loss=5.22, loss_v1=0, loss_v2=0, nll_loss=4.329, ntokens=759.9, nsentences=32, sample_size=759.9, sample_size_v1=0, sample_size_v2=0, ppl=20.1, wps=386.9, ups=0.51, wpb=759.9, bsz=32, num_updates=13390, lr=3.37581e-05, gnorm=2.609, clip=100, loss_scale=256, train_wall=20, gb_free=15.3, wall=36801
2023-01-09 13:51:14 - progress_bar.py[line:272] - INFO: epoch 004:   2424 / 3665 loss=5.035, loss_v1=0, loss_v2=0, nll_loss=4.12, ntokens=767.6, nsentences=32, sample_size=767.6, sample_size_v1=0, sample_size_v2=0, ppl=17.38, wps=392.6, ups=0.51, wpb=767.6, bsz=32, num_updates=13400, lr=3.37436e-05, gnorm=2.326, clip=100, loss_scale=256, train_wall=20, gb_free=15.6, wall=36820
2023-01-09 13:51:34 - progress_bar.py[line:272] - INFO: epoch 004:   2434 / 3665 loss=5.143, loss_v1=0, loss_v2=0, nll_loss=4.242, ntokens=992.7, nsentences=32, sample_size=992.7, sample_size_v1=0, sample_size_v2=0, ppl=18.92, wps=498.9, ups=0.5, wpb=992.7, bsz=32, num_updates=13410, lr=3.37291e-05, gnorm=1.887, clip=100, loss_scale=256, train_wall=20, gb_free=15.3, wall=36840
2023-01-09 13:51:53 - progress_bar.py[line:272] - INFO: epoch 004:   2444 / 3665 loss=5.099, loss_v1=0, loss_v2=0, nll_loss=4.192, ntokens=682, nsentences=32, sample_size=682, sample_size_v1=0, sample_size_v2=0, ppl=18.28, wps=349.2, ups=0.51, wpb=682, bsz=32, num_updates=13420, lr=3.37146e-05, gnorm=2.366, clip=100, loss_scale=256, train_wall=20, gb_free=15.5, wall=36860
2023-01-09 13:52:13 - progress_bar.py[line:272] - INFO: epoch 004:   2454 / 3665 loss=5.217, loss_v1=0, loss_v2=0, nll_loss=4.325, ntokens=985.2, nsentences=32, sample_size=985.2, sample_size_v1=0, sample_size_v2=0, ppl=20.04, wps=501, ups=0.51, wpb=985.2, bsz=32, num_updates=13430, lr=3.37e-05, gnorm=1.994, clip=100, loss_scale=256, train_wall=20, gb_free=15.3, wall=36879
2023-01-09 13:52:33 - progress_bar.py[line:272] - INFO: epoch 004:   2464 / 3665 loss=5.157, loss_v1=0, loss_v2=0, nll_loss=4.256, ntokens=973.9, nsentences=32, sample_size=973.9, sample_size_v1=0, sample_size_v2=0, ppl=19.11, wps=495.3, ups=0.51, wpb=973.9, bsz=32, num_updates=13440, lr=3.36855e-05, gnorm=1.977, clip=100, loss_scale=256, train_wall=20, gb_free=15.1, wall=36899
2023-01-09 13:52:52 - progress_bar.py[line:272] - INFO: epoch 004:   2474 / 3665 loss=5.216, loss_v1=0, loss_v2=0, nll_loss=4.323, ntokens=897.8, nsentences=32, sample_size=897.8, sample_size_v1=0, sample_size_v2=0, ppl=20.01, wps=456.9, ups=0.51, wpb=897.8, bsz=32, num_updates=13450, lr=3.3671e-05, gnorm=2.139, clip=100, loss_scale=256, train_wall=20, gb_free=15.3, wall=36919
2023-01-09 13:53:12 - progress_bar.py[line:272] - INFO: epoch 004:   2484 / 3665 loss=5.184, loss_v1=0, loss_v2=0, nll_loss=4.287, ntokens=829.4, nsentences=32, sample_size=829.4, sample_size_v1=0, sample_size_v2=0, ppl=19.53, wps=423.3, ups=0.51, wpb=829.4, bsz=32, num_updates=13460, lr=3.36565e-05, gnorm=2.29, clip=100, loss_scale=256, train_wall=20, gb_free=15.4, wall=36938
2023-01-09 13:53:31 - progress_bar.py[line:272] - INFO: epoch 004:   2494 / 3665 loss=5.195, loss_v1=0, loss_v2=0, nll_loss=4.3, ntokens=1002.9, nsentences=32, sample_size=1002.9, sample_size_v1=0, sample_size_v2=0, ppl=19.7, wps=510.5, ups=0.51, wpb=1002.9, bsz=32, num_updates=13470, lr=3.3642e-05, gnorm=2.004, clip=100, loss_scale=256, train_wall=20, gb_free=15.5, wall=36958
2023-01-09 13:53:51 - progress_bar.py[line:272] - INFO: epoch 004:   2504 / 3665 loss=5.294, loss_v1=0, loss_v2=0, nll_loss=4.411, ntokens=995.7, nsentences=32, sample_size=995.7, sample_size_v1=0, sample_size_v2=0, ppl=21.27, wps=499.8, ups=0.5, wpb=995.7, bsz=32, num_updates=13480, lr=3.36275e-05, gnorm=2.094, clip=100, loss_scale=256, train_wall=20, gb_free=15.6, wall=36978
2023-01-09 13:54:11 - progress_bar.py[line:272] - INFO: epoch 004:   2514 / 3665 loss=5.224, loss_v1=0, loss_v2=0, nll_loss=4.33, ntokens=822, nsentences=32, sample_size=822, sample_size_v1=0, sample_size_v2=0, ppl=20.11, wps=412, ups=0.5, wpb=822, bsz=32, num_updates=13490, lr=3.3613e-05, gnorm=2.488, clip=100, loss_scale=256, train_wall=20, gb_free=15.2, wall=36998
2023-01-09 13:54:31 - progress_bar.py[line:272] - INFO: epoch 004:   2524 / 3665 loss=5.129, loss_v1=0, loss_v2=0, nll_loss=4.225, ntokens=970.6, nsentences=32, sample_size=970.6, sample_size_v1=0, sample_size_v2=0, ppl=18.7, wps=484.3, ups=0.5, wpb=970.6, bsz=32, num_updates=13500, lr=3.35984e-05, gnorm=1.843, clip=100, loss_scale=256, train_wall=20, gb_free=15.5, wall=37018
2023-01-09 13:54:31 - train.py[line:445] - INFO: begin validation on "valid" subset
slice_id 0 seek offset 0
slice_id 0 seek offset 0
2023-01-09 13:59:11 - progress_bar.py[line:282] - INFO: epoch 004 | valid on 'valid' subset | loss 5.187 | loss_v1 0 | loss_v2 0 | nll_loss 4.275 | ntokens 116.888 | nsentences 4 | sample_size 116.888 | sample_size_v1 0 | sample_size_v2 0 | AP 0 | total positives 21.6842 | TP 0 | FP 4.6567 | ppl 19.36 | wps 521.6 | wpb 116.9 | bsz 4 | num_updates 13500 | best_AP 0
2023-01-09 13:59:11 - checkpoint_utils.py[line:64] - INFO: Preparing to save checkpoint for epoch 4 @ 13500 updates
2023-01-09 13:59:11 - trainer.py[line:431] - INFO: Saving checkpoint to ../../checkpoints/OFA/detection_checkpoints/10_5e-5_512/checkpoint_4_13500.pt
2023-01-09 13:59:15 - trainer.py[line:441] - INFO: Finished saving checkpoint to ../../checkpoints/OFA/detection_checkpoints/10_5e-5_512/checkpoint_4_13500.pt
2023-01-09 14:00:30 - checkpoint_utils.py[line:133] - INFO: Saved checkpoint ../../checkpoints/OFA/detection_checkpoints/10_5e-5_512/checkpoint_4_13500.pt (epoch 4 @ 13500 updates, score 0.0) (writing took 78.60083098290488 seconds)
2023-01-09 14:00:49 - progress_bar.py[line:272] - INFO: epoch 004:   2534 / 3665 loss=5.326, loss_v1=0, loss_v2=0, nll_loss=4.446, ntokens=984.9, nsentences=32, sample_size=984.9, sample_size_v1=0, sample_size_v2=0, ppl=21.8, wps=26.1, ups=0.03, wpb=984.9, bsz=32, num_updates=13510, lr=3.35839e-05, gnorm=1.959, clip=100, loss_scale=256, train_wall=19, gb_free=15.4, wall=37396
2023-01-09 14:01:09 - progress_bar.py[line:272] - INFO: epoch 004:   2544 / 3665 loss=5.14, loss_v1=0, loss_v2=0, nll_loss=4.238, ntokens=841.1, nsentences=32, sample_size=841.1, sample_size_v1=0, sample_size_v2=0, ppl=18.87, wps=427.1, ups=0.51, wpb=841.1, bsz=32, num_updates=13520, lr=3.35694e-05, gnorm=2.187, clip=100, loss_scale=512, train_wall=20, gb_free=15.3, wall=37415
2023-01-09 14:01:29 - progress_bar.py[line:272] - INFO: epoch 004:   2554 / 3665 loss=5.164, loss_v1=0, loss_v2=0, nll_loss=4.266, ntokens=1042.9, nsentences=32, sample_size=1042.9, sample_size_v1=0, sample_size_v2=0, ppl=19.24, wps=524, ups=0.5, wpb=1042.9, bsz=32, num_updates=13530, lr=3.35549e-05, gnorm=1.813, clip=100, loss_scale=512, train_wall=20, gb_free=15.2, wall=37435
2023-01-09 14:01:49 - progress_bar.py[line:272] - INFO: epoch 004:   2564 / 3665 loss=5.229, loss_v1=0, loss_v2=0, nll_loss=4.336, ntokens=1000.7, nsentences=32, sample_size=1000.7, sample_size_v1=0, sample_size_v2=0, ppl=20.19, wps=501.9, ups=0.5, wpb=1000.7, bsz=32, num_updates=13540, lr=3.35404e-05, gnorm=1.902, clip=100, loss_scale=512, train_wall=20, gb_free=15.1, wall=37455
2023-01-09 14:02:09 - progress_bar.py[line:272] - INFO: epoch 004:   2574 / 3665 loss=5.072, loss_v1=0, loss_v2=0, nll_loss=4.164, ntokens=676.4, nsentences=32, sample_size=676.4, sample_size_v1=0, sample_size_v2=0, ppl=17.93, wps=342.7, ups=0.51, wpb=676.4, bsz=32, num_updates=13550, lr=3.35259e-05, gnorm=2.816, clip=100, loss_scale=512, train_wall=20, gb_free=15.5, wall=37475
2023-01-09 14:02:28 - progress_bar.py[line:272] - INFO: epoch 004:   2584 / 3665 loss=5.124, loss_v1=0, loss_v2=0, nll_loss=4.221, ntokens=883.9, nsentences=32, sample_size=883.9, sample_size_v1=0, sample_size_v2=0, ppl=18.65, wps=445.3, ups=0.5, wpb=883.9, bsz=32, num_updates=13560, lr=3.35114e-05, gnorm=2.142, clip=100, loss_scale=512, train_wall=20, gb_free=14.8, wall=37495
2023-01-09 14:02:49 - progress_bar.py[line:272] - INFO: epoch 004:   2594 / 3665 loss=5.193, loss_v1=0, loss_v2=0, nll_loss=4.297, ntokens=933.5, nsentences=32, sample_size=933.5, sample_size_v1=0, sample_size_v2=0, ppl=19.65, wps=449.1, ups=0.48, wpb=933.5, bsz=32, num_updates=13570, lr=3.34969e-05, gnorm=1.988, clip=100, loss_scale=512, train_wall=21, gb_free=15.4, wall=37516
2023-01-09 14:03:10 - progress_bar.py[line:272] - INFO: epoch 004:   2604 / 3665 loss=5.154, loss_v1=0, loss_v2=0, nll_loss=4.254, ntokens=795.4, nsentences=32, sample_size=795.4, sample_size_v1=0, sample_size_v2=0, ppl=19.09, wps=382.9, ups=0.48, wpb=795.4, bsz=32, num_updates=13580, lr=3.34823e-05, gnorm=2.403, clip=100, loss_scale=512, train_wall=21, gb_free=15.1, wall=37536
2023-01-09 14:03:31 - progress_bar.py[line:272] - INFO: epoch 004:   2614 / 3665 loss=5.177, loss_v1=0, loss_v2=0, nll_loss=4.279, ntokens=1011.4, nsentences=32, sample_size=1011.4, sample_size_v1=0, sample_size_v2=0, ppl=19.41, wps=490.5, ups=0.48, wpb=1011.4, bsz=32, num_updates=13590, lr=3.34678e-05, gnorm=2.01, clip=100, loss_scale=512, train_wall=21, gb_free=15.3, wall=37557
2023-01-09 14:03:51 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 256.0
2023-01-09 14:03:53 - progress_bar.py[line:272] - INFO: epoch 004:   2625 / 3665 loss=5.289, loss_v1=0, loss_v2=0, nll_loss=4.403, ntokens=1181.4, nsentences=32, sample_size=1181.4, sample_size_v1=0, sample_size_v2=0, ppl=21.16, wps=534.7, ups=0.45, wpb=1181.4, bsz=32, num_updates=13600, lr=3.34533e-05, gnorm=1.706, clip=100, loss_scale=256, train_wall=22, gb_free=15, wall=37579
2023-01-09 14:04:12 - progress_bar.py[line:272] - INFO: epoch 004:   2635 / 3665 loss=5.182, loss_v1=0, loss_v2=0, nll_loss=4.284, ntokens=790.6, nsentences=31.8, sample_size=790.6, sample_size_v1=0, sample_size_v2=0, ppl=19.49, wps=402.9, ups=0.51, wpb=790.6, bsz=31.8, num_updates=13610, lr=3.34388e-05, gnorm=2.304, clip=100, loss_scale=256, train_wall=20, gb_free=15.4, wall=37599
2023-01-09 14:04:32 - progress_bar.py[line:272] - INFO: epoch 004:   2645 / 3665 loss=5.19, loss_v1=0, loss_v2=0, nll_loss=4.295, ntokens=964.8, nsentences=32, sample_size=964.8, sample_size_v1=0, sample_size_v2=0, ppl=19.62, wps=487, ups=0.5, wpb=964.8, bsz=32, num_updates=13620, lr=3.34243e-05, gnorm=2.12, clip=100, loss_scale=256, train_wall=20, gb_free=15.5, wall=37618
2023-01-09 14:04:52 - progress_bar.py[line:272] - INFO: epoch 004:   2655 / 3665 loss=5.214, loss_v1=0, loss_v2=0, nll_loss=4.321, ntokens=1107.6, nsentences=32, sample_size=1107.6, sample_size_v1=0, sample_size_v2=0, ppl=19.99, wps=556.6, ups=0.5, wpb=1107.6, bsz=32, num_updates=13630, lr=3.34098e-05, gnorm=1.705, clip=100, loss_scale=256, train_wall=20, gb_free=15.4, wall=37638
2023-01-09 14:05:12 - progress_bar.py[line:272] - INFO: epoch 004:   2665 / 3665 loss=5.246, loss_v1=0, loss_v2=0, nll_loss=4.354, ntokens=829.3, nsentences=32, sample_size=829.3, sample_size_v1=0, sample_size_v2=0, ppl=20.45, wps=419, ups=0.51, wpb=829.3, bsz=32, num_updates=13640, lr=3.33953e-05, gnorm=2.182, clip=100, loss_scale=256, train_wall=20, gb_free=15.4, wall=37658
2023-01-09 14:05:32 - progress_bar.py[line:272] - INFO: epoch 004:   2675 / 3665 loss=5.159, loss_v1=0, loss_v2=0, nll_loss=4.259, ntokens=847.1, nsentences=32, sample_size=847.1, sample_size_v1=0, sample_size_v2=0, ppl=19.15, wps=427.1, ups=0.5, wpb=847.1, bsz=32, num_updates=13650, lr=3.33807e-05, gnorm=2.32, clip=100, loss_scale=256, train_wall=20, gb_free=15.5, wall=37678
2023-01-09 14:05:52 - progress_bar.py[line:272] - INFO: epoch 004:   2685 / 3665 loss=5.139, loss_v1=0, loss_v2=0, nll_loss=4.238, ntokens=991.2, nsentences=32, sample_size=991.2, sample_size_v1=0, sample_size_v2=0, ppl=18.87, wps=499.5, ups=0.5, wpb=991.2, bsz=32, num_updates=13660, lr=3.33662e-05, gnorm=1.935, clip=100, loss_scale=256, train_wall=20, gb_free=14.7, wall=37698
2023-01-09 14:06:11 - progress_bar.py[line:272] - INFO: epoch 004:   2695 / 3665 loss=5.223, loss_v1=0, loss_v2=0, nll_loss=4.333, ntokens=933.9, nsentences=32, sample_size=933.9, sample_size_v1=0, sample_size_v2=0, ppl=20.15, wps=469, ups=0.5, wpb=933.9, bsz=32, num_updates=13670, lr=3.33517e-05, gnorm=2.071, clip=100, loss_scale=256, train_wall=20, gb_free=15.5, wall=37718
2023-01-09 14:06:31 - progress_bar.py[line:272] - INFO: epoch 004:   2705 / 3665 loss=5.163, loss_v1=0, loss_v2=0, nll_loss=4.263, ntokens=770.5, nsentences=32, sample_size=770.5, sample_size_v1=0, sample_size_v2=0, ppl=19.2, wps=389.6, ups=0.51, wpb=770.5, bsz=32, num_updates=13680, lr=3.33372e-05, gnorm=2.515, clip=100, loss_scale=256, train_wall=20, gb_free=15.3, wall=37737
2023-01-09 14:06:51 - progress_bar.py[line:272] - INFO: epoch 004:   2715 / 3665 loss=5.156, loss_v1=0, loss_v2=0, nll_loss=4.255, ntokens=1127, nsentences=32, sample_size=1127, sample_size_v1=0, sample_size_v2=0, ppl=19.1, wps=564.8, ups=0.5, wpb=1127, bsz=32, num_updates=13690, lr=3.33227e-05, gnorm=1.73, clip=100, loss_scale=256, train_wall=20, gb_free=14.1, wall=37757
2023-01-09 14:07:11 - progress_bar.py[line:272] - INFO: epoch 004:   2725 / 3665 loss=5.226, loss_v1=0, loss_v2=0, nll_loss=4.334, ntokens=978.2, nsentences=32, sample_size=978.2, sample_size_v1=0, sample_size_v2=0, ppl=20.17, wps=490.7, ups=0.5, wpb=978.2, bsz=32, num_updates=13700, lr=3.33082e-05, gnorm=2.095, clip=100, loss_scale=256, train_wall=20, gb_free=15.3, wall=37777
2023-01-09 14:07:31 - progress_bar.py[line:272] - INFO: epoch 004:   2735 / 3665 loss=5.197, loss_v1=0, loss_v2=0, nll_loss=4.3, ntokens=824, nsentences=32, sample_size=824, sample_size_v1=0, sample_size_v2=0, ppl=19.69, wps=414.7, ups=0.5, wpb=824, bsz=32, num_updates=13710, lr=3.32937e-05, gnorm=2.115, clip=100, loss_scale=256, train_wall=20, gb_free=15.6, wall=37797
2023-01-09 14:07:51 - progress_bar.py[line:272] - INFO: epoch 004:   2745 / 3665 loss=5.173, loss_v1=0, loss_v2=0, nll_loss=4.275, ntokens=961.5, nsentences=32, sample_size=961.5, sample_size_v1=0, sample_size_v2=0, ppl=19.37, wps=479.8, ups=0.5, wpb=961.5, bsz=32, num_updates=13720, lr=3.32792e-05, gnorm=1.975, clip=100, loss_scale=256, train_wall=20, gb_free=15.4, wall=37817
2023-01-09 14:08:11 - progress_bar.py[line:272] - INFO: epoch 004:   2755 / 3665 loss=5.232, loss_v1=0, loss_v2=0, nll_loss=4.342, ntokens=907.2, nsentences=32, sample_size=907.2, sample_size_v1=0, sample_size_v2=0, ppl=20.27, wps=452.3, ups=0.5, wpb=907.2, bsz=32, num_updates=13730, lr=3.32646e-05, gnorm=2.151, clip=100, loss_scale=256, train_wall=20, gb_free=15.4, wall=37837
2023-01-09 14:08:31 - progress_bar.py[line:272] - INFO: epoch 004:   2765 / 3665 loss=5.182, loss_v1=0, loss_v2=0, nll_loss=4.283, ntokens=785.4, nsentences=32, sample_size=785.4, sample_size_v1=0, sample_size_v2=0, ppl=19.47, wps=391.8, ups=0.5, wpb=785.4, bsz=32, num_updates=13740, lr=3.32501e-05, gnorm=2.312, clip=100, loss_scale=256, train_wall=20, gb_free=15.6, wall=37857
2023-01-09 14:08:52 - progress_bar.py[line:272] - INFO: epoch 004:   2775 / 3665 loss=5.136, loss_v1=0, loss_v2=0, nll_loss=4.233, ntokens=957, nsentences=32, sample_size=957, sample_size_v1=0, sample_size_v2=0, ppl=18.81, wps=456.6, ups=0.48, wpb=957, bsz=32, num_updates=13750, lr=3.32356e-05, gnorm=1.905, clip=100, loss_scale=256, train_wall=21, gb_free=15.6, wall=37878
2023-01-09 14:09:17 - progress_bar.py[line:272] - INFO: epoch 004:   2785 / 3665 loss=5.259, loss_v1=0, loss_v2=0, nll_loss=4.373, ntokens=1131.3, nsentences=32, sample_size=1131.3, sample_size_v1=0, sample_size_v2=0, ppl=20.72, wps=453.7, ups=0.4, wpb=1131.3, bsz=32, num_updates=13760, lr=3.32211e-05, gnorm=1.867, clip=100, loss_scale=256, train_wall=25, gb_free=15, wall=37903
2023-01-09 14:09:39 - progress_bar.py[line:272] - INFO: epoch 004:   2795 / 3665 loss=5.133, loss_v1=0, loss_v2=0, nll_loss=4.23, ntokens=796.6, nsentences=32, sample_size=796.6, sample_size_v1=0, sample_size_v2=0, ppl=18.76, wps=354.9, ups=0.45, wpb=796.6, bsz=32, num_updates=13770, lr=3.32066e-05, gnorm=2.181, clip=100, loss_scale=256, train_wall=22, gb_free=15.3, wall=37926
2023-01-09 14:10:00 - progress_bar.py[line:272] - INFO: epoch 004:   2805 / 3665 loss=5.164, loss_v1=0, loss_v2=0, nll_loss=4.265, ntokens=1009.1, nsentences=32, sample_size=1009.1, sample_size_v1=0, sample_size_v2=0, ppl=19.22, wps=492.8, ups=0.49, wpb=1009.1, bsz=32, num_updates=13780, lr=3.31921e-05, gnorm=2.018, clip=100, loss_scale=256, train_wall=20, gb_free=15.2, wall=37946
2023-01-09 14:10:20 - progress_bar.py[line:272] - INFO: epoch 004:   2815 / 3665 loss=5.205, loss_v1=0, loss_v2=0, nll_loss=4.31, ntokens=1047.4, nsentences=32, sample_size=1047.4, sample_size_v1=0, sample_size_v2=0, ppl=19.84, wps=522, ups=0.5, wpb=1047.4, bsz=32, num_updates=13790, lr=3.31776e-05, gnorm=1.825, clip=100, loss_scale=256, train_wall=20, gb_free=15.5, wall=37966
2023-01-09 14:10:40 - progress_bar.py[line:272] - INFO: epoch 004:   2825 / 3665 loss=5.159, loss_v1=0, loss_v2=0, nll_loss=4.26, ntokens=819.1, nsentences=32, sample_size=819.1, sample_size_v1=0, sample_size_v2=0, ppl=19.15, wps=409.2, ups=0.5, wpb=819.1, bsz=32, num_updates=13800, lr=3.3163e-05, gnorm=2.21, clip=100, loss_scale=256, train_wall=20, gb_free=14.8, wall=37986
2023-01-09 14:11:00 - progress_bar.py[line:272] - INFO: epoch 004:   2835 / 3665 loss=5.213, loss_v1=0, loss_v2=0, nll_loss=4.32, ntokens=949.4, nsentences=32, sample_size=949.4, sample_size_v1=0, sample_size_v2=0, ppl=19.97, wps=468.9, ups=0.49, wpb=949.4, bsz=32, num_updates=13810, lr=3.31485e-05, gnorm=2.017, clip=100, loss_scale=256, train_wall=20, gb_free=15.5, wall=38007
2023-01-09 14:11:23 - progress_bar.py[line:272] - INFO: epoch 004:   2845 / 3665 loss=5.182, loss_v1=0, loss_v2=0, nll_loss=4.284, ntokens=1020.4, nsentences=32, sample_size=1020.4, sample_size_v1=0, sample_size_v2=0, ppl=19.49, wps=455.7, ups=0.45, wpb=1020.4, bsz=32, num_updates=13820, lr=3.3134e-05, gnorm=1.916, clip=100, loss_scale=256, train_wall=22, gb_free=15.2, wall=38029
2023-01-09 14:11:45 - progress_bar.py[line:272] - INFO: epoch 004:   2855 / 3665 loss=5.245, loss_v1=0, loss_v2=0, nll_loss=4.353, ntokens=791.1, nsentences=32, sample_size=791.1, sample_size_v1=0, sample_size_v2=0, ppl=20.44, wps=347.9, ups=0.44, wpb=791.1, bsz=32, num_updates=13830, lr=3.31195e-05, gnorm=2.193, clip=100, loss_scale=256, train_wall=23, gb_free=15.4, wall=38052
2023-01-09 14:12:08 - progress_bar.py[line:272] - INFO: epoch 004:   2865 / 3665 loss=5.144, loss_v1=0, loss_v2=0, nll_loss=4.245, ntokens=749.2, nsentences=32, sample_size=749.2, sample_size_v1=0, sample_size_v2=0, ppl=18.96, wps=333.1, ups=0.44, wpb=749.2, bsz=32, num_updates=13840, lr=3.3105e-05, gnorm=2.269, clip=100, loss_scale=256, train_wall=22, gb_free=15.4, wall=38074
2023-01-09 14:12:30 - progress_bar.py[line:272] - INFO: epoch 004:   2875 / 3665 loss=5.155, loss_v1=0, loss_v2=0, nll_loss=4.255, ntokens=981.3, nsentences=32, sample_size=981.3, sample_size_v1=0, sample_size_v2=0, ppl=19.09, wps=444.8, ups=0.45, wpb=981.3, bsz=32, num_updates=13850, lr=3.30905e-05, gnorm=2.034, clip=100, loss_scale=256, train_wall=22, gb_free=15.5, wall=38096
2023-01-09 14:12:50 - progress_bar.py[line:272] - INFO: epoch 004:   2885 / 3665 loss=5.233, loss_v1=0, loss_v2=0, nll_loss=4.341, ntokens=898.7, nsentences=32, sample_size=898.7, sample_size_v1=0, sample_size_v2=0, ppl=20.27, wps=441.4, ups=0.49, wpb=898.7, bsz=32, num_updates=13860, lr=3.3076e-05, gnorm=2.143, clip=100, loss_scale=256, train_wall=20, gb_free=15.4, wall=38117
2023-01-09 14:13:10 - progress_bar.py[line:272] - INFO: epoch 004:   2895 / 3665 loss=5.137, loss_v1=0, loss_v2=0, nll_loss=4.235, ntokens=779, nsentences=32, sample_size=779, sample_size_v1=0, sample_size_v2=0, ppl=18.83, wps=395.8, ups=0.51, wpb=779, bsz=32, num_updates=13870, lr=3.30614e-05, gnorm=2.357, clip=100, loss_scale=256, train_wall=20, gb_free=15.5, wall=38136
2023-01-09 14:13:30 - progress_bar.py[line:272] - INFO: epoch 004:   2905 / 3665 loss=5.18, loss_v1=0, loss_v2=0, nll_loss=4.283, ntokens=1061.2, nsentences=32, sample_size=1061.2, sample_size_v1=0, sample_size_v2=0, ppl=19.46, wps=533.9, ups=0.5, wpb=1061.2, bsz=32, num_updates=13880, lr=3.30469e-05, gnorm=1.914, clip=100, loss_scale=256, train_wall=20, gb_free=15.5, wall=38156
2023-01-09 14:13:50 - progress_bar.py[line:272] - INFO: epoch 004:   2915 / 3665 loss=5.216, loss_v1=0, loss_v2=0, nll_loss=4.322, ntokens=1028.3, nsentences=32, sample_size=1028.3, sample_size_v1=0, sample_size_v2=0, ppl=20, wps=515, ups=0.5, wpb=1028.3, bsz=32, num_updates=13890, lr=3.30324e-05, gnorm=1.804, clip=100, loss_scale=256, train_wall=20, gb_free=14.9, wall=38176
2023-01-09 14:14:10 - progress_bar.py[line:272] - INFO: epoch 004:   2925 / 3665 loss=5.153, loss_v1=0, loss_v2=0, nll_loss=4.253, ntokens=769.1, nsentences=32, sample_size=769.1, sample_size_v1=0, sample_size_v2=0, ppl=19.06, wps=387.4, ups=0.5, wpb=769.1, bsz=32, num_updates=13900, lr=3.30179e-05, gnorm=2.475, clip=100, loss_scale=256, train_wall=20, gb_free=15.6, wall=38196
2023-01-09 14:14:30 - progress_bar.py[line:272] - INFO: epoch 004:   2935 / 3665 loss=5.064, loss_v1=0, loss_v2=0, nll_loss=4.154, ntokens=894.1, nsentences=32, sample_size=894.1, sample_size_v1=0, sample_size_v2=0, ppl=17.81, wps=444, ups=0.5, wpb=894.1, bsz=32, num_updates=13910, lr=3.30034e-05, gnorm=2.181, clip=100, loss_scale=256, train_wall=20, gb_free=15.4, wall=38216
2023-01-09 14:14:50 - progress_bar.py[line:272] - INFO: epoch 004:   2945 / 3665 loss=5.315, loss_v1=0, loss_v2=0, nll_loss=4.432, ntokens=1225.3, nsentences=32, sample_size=1225.3, sample_size_v1=0, sample_size_v2=0, ppl=21.58, wps=604.3, ups=0.49, wpb=1225.3, bsz=32, num_updates=13920, lr=3.29889e-05, gnorm=1.703, clip=100, loss_scale=256, train_wall=20, gb_free=15, wall=38236
2023-01-09 14:15:10 - progress_bar.py[line:272] - INFO: epoch 004:   2955 / 3665 loss=5.145, loss_v1=0, loss_v2=0, nll_loss=4.245, ntokens=814.5, nsentences=32, sample_size=814.5, sample_size_v1=0, sample_size_v2=0, ppl=18.96, wps=401.9, ups=0.49, wpb=814.5, bsz=32, num_updates=13930, lr=3.29744e-05, gnorm=2.379, clip=100, loss_scale=256, train_wall=20, gb_free=15.7, wall=38257
2023-01-09 14:15:31 - progress_bar.py[line:272] - INFO: epoch 004:   2965 / 3665 loss=5.196, loss_v1=0, loss_v2=0, nll_loss=4.3, ntokens=1026.3, nsentences=32, sample_size=1026.3, sample_size_v1=0, sample_size_v2=0, ppl=19.69, wps=502.6, ups=0.49, wpb=1026.3, bsz=32, num_updates=13940, lr=3.29599e-05, gnorm=1.791, clip=100, loss_scale=256, train_wall=20, gb_free=15.5, wall=38277
2023-01-09 14:15:51 - progress_bar.py[line:272] - INFO: epoch 004:   2975 / 3665 loss=5.22, loss_v1=0, loss_v2=0, nll_loss=4.328, ntokens=1003.8, nsentences=32, sample_size=1003.8, sample_size_v1=0, sample_size_v2=0, ppl=20.09, wps=496.7, ups=0.49, wpb=1003.8, bsz=32, num_updates=13950, lr=3.29453e-05, gnorm=1.89, clip=100, loss_scale=256, train_wall=20, gb_free=15.1, wall=38297
2023-01-09 14:16:11 - progress_bar.py[line:272] - INFO: epoch 004:   2985 / 3665 loss=5.111, loss_v1=0, loss_v2=0, nll_loss=4.205, ntokens=881.4, nsentences=32, sample_size=881.4, sample_size_v1=0, sample_size_v2=0, ppl=18.45, wps=436.2, ups=0.49, wpb=881.4, bsz=32, num_updates=13960, lr=3.29308e-05, gnorm=2.214, clip=100, loss_scale=256, train_wall=20, gb_free=15.3, wall=38317
2023-01-09 14:16:35 - progress_bar.py[line:272] - INFO: epoch 004:   2995 / 3665 loss=5.197, loss_v1=0, loss_v2=0, nll_loss=4.302, ntokens=1001.7, nsentences=32, sample_size=1001.7, sample_size_v1=0, sample_size_v2=0, ppl=19.72, wps=429.6, ups=0.43, wpb=1001.7, bsz=32, num_updates=13970, lr=3.29163e-05, gnorm=2.046, clip=100, loss_scale=256, train_wall=23, gb_free=15.6, wall=38341
2023-01-09 14:16:59 - progress_bar.py[line:272] - INFO: epoch 004:   3005 / 3665 loss=5.18, loss_v1=0, loss_v2=0, nll_loss=4.282, ntokens=1046, nsentences=32, sample_size=1046, sample_size_v1=0, sample_size_v2=0, ppl=19.45, wps=429, ups=0.41, wpb=1046, bsz=32, num_updates=13980, lr=3.29018e-05, gnorm=1.797, clip=100, loss_scale=256, train_wall=24, gb_free=15.5, wall=38365
2023-01-09 14:17:20 - progress_bar.py[line:272] - INFO: epoch 004:   3015 / 3665 loss=5.064, loss_v1=0, loss_v2=0, nll_loss=4.152, ntokens=645.5, nsentences=32, sample_size=645.5, sample_size_v1=0, sample_size_v2=0, ppl=17.77, wps=303.1, ups=0.47, wpb=645.5, bsz=32, num_updates=13990, lr=3.28873e-05, gnorm=2.478, clip=100, loss_scale=256, train_wall=21, gb_free=15.6, wall=38386
2023-01-09 14:17:40 - progress_bar.py[line:272] - INFO: epoch 004:   3025 / 3665 loss=5.181, loss_v1=0, loss_v2=0, nll_loss=4.286, ntokens=1037.7, nsentences=32, sample_size=1037.7, sample_size_v1=0, sample_size_v2=0, ppl=19.5, wps=513.2, ups=0.49, wpb=1037.7, bsz=32, num_updates=14000, lr=3.28728e-05, gnorm=1.924, clip=100, loss_scale=256, train_wall=20, gb_free=15.2, wall=38407
2023-01-09 14:17:40 - train.py[line:445] - INFO: begin validation on "valid" subset
slice_id 0 seek offset 0
slice_id 0 seek offset 0
2023-01-09 14:22:25 - progress_bar.py[line:282] - INFO: epoch 004 | valid on 'valid' subset | loss 5.179 | loss_v1 0 | loss_v2 0 | nll_loss 4.266 | ntokens 116.55 | nsentences 4 | sample_size 116.55 | sample_size_v1 0 | sample_size_v2 0 | AP 0 | total positives 21.6204 | TP 0 | FP 4.37641 | ppl 19.24 | wps 510.8 | wpb 116.6 | bsz 4 | num_updates 14000 | best_AP 0
2023-01-09 14:22:25 - checkpoint_utils.py[line:64] - INFO: Preparing to save checkpoint for epoch 4 @ 14000 updates
2023-01-09 14:22:25 - trainer.py[line:431] - INFO: Saving checkpoint to ../../checkpoints/OFA/detection_checkpoints/10_5e-5_512/checkpoint_4_14000.pt
2023-01-09 14:22:28 - trainer.py[line:441] - INFO: Finished saving checkpoint to ../../checkpoints/OFA/detection_checkpoints/10_5e-5_512/checkpoint_4_14000.pt
2023-01-09 14:23:30 - checkpoint_utils.py[line:133] - INFO: Saved checkpoint ../../checkpoints/OFA/detection_checkpoints/10_5e-5_512/checkpoint_4_14000.pt (epoch 4 @ 14000 updates, score 0.0) (writing took 64.86854351405054 seconds)
2023-01-09 14:23:50 - progress_bar.py[line:272] - INFO: epoch 004:   3035 / 3665 loss=5.071, loss_v1=0, loss_v2=0, nll_loss=4.163, ntokens=951.3, nsentences=32, sample_size=951.3, sample_size_v1=0, sample_size_v2=0, ppl=17.91, wps=25.8, ups=0.03, wpb=951.3, bsz=32, num_updates=14010, lr=3.28583e-05, gnorm=2.091, clip=100, loss_scale=256, train_wall=20, gb_free=15.3, wall=38776
2023-01-09 14:24:10 - progress_bar.py[line:272] - INFO: epoch 004:   3045 / 3665 loss=5.272, loss_v1=0, loss_v2=0, nll_loss=4.386, ntokens=878.3, nsentences=32, sample_size=878.3, sample_size_v1=0, sample_size_v2=0, ppl=20.9, wps=437.2, ups=0.5, wpb=878.3, bsz=32, num_updates=14020, lr=3.28437e-05, gnorm=2.377, clip=100, loss_scale=256, train_wall=20, gb_free=15.6, wall=38796
2023-01-09 14:24:30 - progress_bar.py[line:272] - INFO: epoch 004:   3055 / 3665 loss=5.148, loss_v1=0, loss_v2=0, nll_loss=4.244, ntokens=881.9, nsentences=32, sample_size=881.9, sample_size_v1=0, sample_size_v2=0, ppl=18.95, wps=437.2, ups=0.5, wpb=881.9, bsz=32, num_updates=14030, lr=3.28292e-05, gnorm=2.104, clip=100, loss_scale=256, train_wall=20, gb_free=15.5, wall=38816
2023-01-09 14:24:52 - progress_bar.py[line:272] - INFO: epoch 004:   3065 / 3665 loss=5.106, loss_v1=0, loss_v2=0, nll_loss=4.201, ntokens=1019.9, nsentences=32, sample_size=1019.9, sample_size_v1=0, sample_size_v2=0, ppl=18.39, wps=466.1, ups=0.46, wpb=1019.9, bsz=32, num_updates=14040, lr=3.28147e-05, gnorm=1.815, clip=100, loss_scale=256, train_wall=22, gb_free=15.3, wall=38838
2023-01-09 14:25:19 - progress_bar.py[line:272] - INFO: epoch 004:   3075 / 3665 loss=5.27, loss_v1=0, loss_v2=0, nll_loss=4.384, ntokens=1014.7, nsentences=32, sample_size=1014.7, sample_size_v1=0, sample_size_v2=0, ppl=20.87, wps=375.3, ups=0.37, wpb=1014.7, bsz=32, num_updates=14050, lr=3.28002e-05, gnorm=1.929, clip=100, loss_scale=256, train_wall=27, gb_free=15.4, wall=38865
2023-01-09 14:25:42 - progress_bar.py[line:272] - INFO: epoch 004:   3085 / 3665 loss=5.154, loss_v1=0, loss_v2=0, nll_loss=4.255, ntokens=917.5, nsentences=32, sample_size=917.5, sample_size_v1=0, sample_size_v2=0, ppl=19.1, wps=390.5, ups=0.43, wpb=917.5, bsz=32, num_updates=14060, lr=3.27857e-05, gnorm=2.143, clip=100, loss_scale=256, train_wall=23, gb_free=15.3, wall=38889
2023-01-09 14:26:04 - progress_bar.py[line:272] - INFO: epoch 004:   3095 / 3665 loss=5.174, loss_v1=0, loss_v2=0, nll_loss=4.275, ntokens=985, nsentences=32, sample_size=985, sample_size_v1=0, sample_size_v2=0, ppl=19.36, wps=463.2, ups=0.47, wpb=985, bsz=32, num_updates=14070, lr=3.27712e-05, gnorm=2.015, clip=100, loss_scale=256, train_wall=21, gb_free=14.9, wall=38910
2023-01-09 14:26:24 - progress_bar.py[line:272] - INFO: epoch 004:   3105 / 3665 loss=5.306, loss_v1=0, loss_v2=0, nll_loss=4.424, ntokens=1010, nsentences=32, sample_size=1010, sample_size_v1=0, sample_size_v2=0, ppl=21.46, wps=496.2, ups=0.49, wpb=1010, bsz=32, num_updates=14080, lr=3.27567e-05, gnorm=1.834, clip=100, loss_scale=256, train_wall=20, gb_free=15.2, wall=38930
2023-01-09 14:26:44 - progress_bar.py[line:272] - INFO: epoch 004:   3115 / 3665 loss=5.259, loss_v1=0, loss_v2=0, nll_loss=4.371, ntokens=866.7, nsentences=32, sample_size=866.7, sample_size_v1=0, sample_size_v2=0, ppl=20.69, wps=425.2, ups=0.49, wpb=866.7, bsz=32, num_updates=14090, lr=3.27422e-05, gnorm=2.108, clip=100, loss_scale=256, train_wall=20, gb_free=15.3, wall=38951
2023-01-09 14:27:05 - progress_bar.py[line:272] - INFO: epoch 004:   3125 / 3665 loss=5.181, loss_v1=0, loss_v2=0, nll_loss=4.283, ntokens=999.5, nsentences=32, sample_size=999.5, sample_size_v1=0, sample_size_v2=0, ppl=19.47, wps=490.7, ups=0.49, wpb=999.5, bsz=32, num_updates=14100, lr=3.27276e-05, gnorm=1.948, clip=100, loss_scale=256, train_wall=20, gb_free=15.5, wall=38971
2023-01-09 14:27:25 - progress_bar.py[line:272] - INFO: epoch 004:   3135 / 3665 loss=5.232, loss_v1=0, loss_v2=0, nll_loss=4.339, ntokens=1015.4, nsentences=32, sample_size=1015.4, sample_size_v1=0, sample_size_v2=0, ppl=20.23, wps=496.4, ups=0.49, wpb=1015.4, bsz=32, num_updates=14110, lr=3.27131e-05, gnorm=1.939, clip=100, loss_scale=256, train_wall=20, gb_free=15.5, wall=38991
2023-01-09 14:27:46 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 256.0
2023-01-09 14:27:48 - progress_bar.py[line:272] - INFO: epoch 004:   3146 / 3665 loss=5.185, loss_v1=0, loss_v2=0, nll_loss=4.289, ntokens=792.6, nsentences=32, sample_size=792.6, sample_size_v1=0, sample_size_v2=0, ppl=19.55, wps=351.2, ups=0.44, wpb=792.6, bsz=32, num_updates=14120, lr=3.26986e-05, gnorm=2.388, clip=100, loss_scale=256, train_wall=23, gb_free=15.3, wall=39014
2023-01-09 14:28:12 - progress_bar.py[line:272] - INFO: epoch 004:   3156 / 3665 loss=5.129, loss_v1=0, loss_v2=0, nll_loss=4.227, ntokens=943.8, nsentences=32, sample_size=943.8, sample_size_v1=0, sample_size_v2=0, ppl=18.73, wps=389, ups=0.41, wpb=943.8, bsz=32, num_updates=14130, lr=3.26841e-05, gnorm=2.099, clip=100, loss_scale=256, train_wall=24, gb_free=14.9, wall=39038
2023-01-09 14:28:37 - progress_bar.py[line:272] - INFO: epoch 004:   3166 / 3665 loss=5.263, loss_v1=0, loss_v2=0, nll_loss=4.373, ntokens=950, nsentences=32, sample_size=950, sample_size_v1=0, sample_size_v2=0, ppl=20.72, wps=377.7, ups=0.4, wpb=950, bsz=32, num_updates=14140, lr=3.26696e-05, gnorm=1.892, clip=100, loss_scale=256, train_wall=25, gb_free=15.3, wall=39063
2023-01-09 14:29:02 - progress_bar.py[line:272] - INFO: epoch 004:   3176 / 3665 loss=5.14, loss_v1=0, loss_v2=0, nll_loss=4.239, ntokens=797.9, nsentences=32, sample_size=797.9, sample_size_v1=0, sample_size_v2=0, ppl=18.88, wps=319.6, ups=0.4, wpb=797.9, bsz=32, num_updates=14150, lr=3.26551e-05, gnorm=2.421, clip=100, loss_scale=256, train_wall=25, gb_free=15.5, wall=39088
2023-01-09 14:29:27 - progress_bar.py[line:272] - INFO: epoch 004:   3186 / 3665 loss=5.119, loss_v1=0, loss_v2=0, nll_loss=4.216, ntokens=914.6, nsentences=32, sample_size=914.6, sample_size_v1=0, sample_size_v2=0, ppl=18.58, wps=365.7, ups=0.4, wpb=914.6, bsz=32, num_updates=14160, lr=3.26406e-05, gnorm=2.05, clip=100, loss_scale=256, train_wall=25, gb_free=15.4, wall=39113
2023-01-09 14:29:52 - progress_bar.py[line:272] - INFO: epoch 004:   3196 / 3665 loss=5.22, loss_v1=0, loss_v2=0, nll_loss=4.328, ntokens=1022.4, nsentences=32, sample_size=1022.4, sample_size_v1=0, sample_size_v2=0, ppl=20.08, wps=406.2, ups=0.4, wpb=1022.4, bsz=32, num_updates=14170, lr=3.2626e-05, gnorm=1.966, clip=100, loss_scale=256, train_wall=25, gb_free=15.4, wall=39139
2023-01-09 14:30:17 - progress_bar.py[line:272] - INFO: epoch 004:   3206 / 3665 loss=5.127, loss_v1=0, loss_v2=0, nll_loss=4.222, ntokens=816.1, nsentences=32, sample_size=816.1, sample_size_v1=0, sample_size_v2=0, ppl=18.66, wps=326.4, ups=0.4, wpb=816.1, bsz=32, num_updates=14180, lr=3.26115e-05, gnorm=2.184, clip=100, loss_scale=256, train_wall=25, gb_free=15.1, wall=39164
2023-01-09 14:30:43 - progress_bar.py[line:272] - INFO: epoch 004:   3216 / 3665 loss=5.175, loss_v1=0, loss_v2=0, nll_loss=4.278, ntokens=999.1, nsentences=32, sample_size=999.1, sample_size_v1=0, sample_size_v2=0, ppl=19.4, wps=396.7, ups=0.4, wpb=999.1, bsz=32, num_updates=14190, lr=3.2597e-05, gnorm=1.946, clip=100, loss_scale=256, train_wall=25, gb_free=15.2, wall=39189
2023-01-09 14:31:08 - progress_bar.py[line:272] - INFO: epoch 004:   3226 / 3665 loss=5.193, loss_v1=0, loss_v2=0, nll_loss=4.297, ntokens=1200.7, nsentences=32, sample_size=1200.7, sample_size_v1=0, sample_size_v2=0, ppl=19.66, wps=474.3, ups=0.39, wpb=1200.7, bsz=32, num_updates=14200, lr=3.25825e-05, gnorm=1.666, clip=100, loss_scale=256, train_wall=25, gb_free=14.9, wall=39214
2023-01-09 14:31:33 - progress_bar.py[line:272] - INFO: epoch 004:   3236 / 3665 loss=5.182, loss_v1=0, loss_v2=0, nll_loss=4.286, ntokens=775.3, nsentences=32, sample_size=775.3, sample_size_v1=0, sample_size_v2=0, ppl=19.5, wps=308.6, ups=0.4, wpb=775.3, bsz=32, num_updates=14210, lr=3.2568e-05, gnorm=2.214, clip=100, loss_scale=256, train_wall=25, gb_free=15.3, wall=39239
2023-01-09 14:31:58 - progress_bar.py[line:272] - INFO: epoch 004:   3246 / 3665 loss=5.068, loss_v1=0, loss_v2=0, nll_loss=4.158, ntokens=891.6, nsentences=32, sample_size=891.6, sample_size_v1=0, sample_size_v2=0, ppl=17.86, wps=353.5, ups=0.4, wpb=891.6, bsz=32, num_updates=14220, lr=3.25535e-05, gnorm=2.07, clip=100, loss_scale=256, train_wall=25, gb_free=15.1, wall=39264
2023-01-09 14:32:23 - progress_bar.py[line:272] - INFO: epoch 004:   3256 / 3665 loss=5.164, loss_v1=0, loss_v2=0, nll_loss=4.266, ntokens=996.7, nsentences=32, sample_size=996.7, sample_size_v1=0, sample_size_v2=0, ppl=19.24, wps=396.2, ups=0.4, wpb=996.7, bsz=32, num_updates=14230, lr=3.2539e-05, gnorm=1.92, clip=100, loss_scale=256, train_wall=25, gb_free=15, wall=39290
2023-01-09 14:32:49 - progress_bar.py[line:272] - INFO: epoch 004:   3266 / 3665 loss=5.269, loss_v1=0, loss_v2=0, nll_loss=4.381, ntokens=972.7, nsentences=32, sample_size=972.7, sample_size_v1=0, sample_size_v2=0, ppl=20.84, wps=385.2, ups=0.4, wpb=972.7, bsz=32, num_updates=14240, lr=3.25245e-05, gnorm=2.003, clip=100, loss_scale=256, train_wall=25, gb_free=15.4, wall=39315
2023-01-09 14:33:14 - progress_bar.py[line:272] - INFO: epoch 004:   3276 / 3665 loss=5.209, loss_v1=0, loss_v2=0, nll_loss=4.314, ntokens=825, nsentences=32, sample_size=825, sample_size_v1=0, sample_size_v2=0, ppl=19.89, wps=327.4, ups=0.4, wpb=825, bsz=32, num_updates=14250, lr=3.25099e-05, gnorm=2.379, clip=100, loss_scale=256, train_wall=25, gb_free=15.3, wall=39340
2023-01-09 14:33:39 - progress_bar.py[line:272] - INFO: epoch 004:   3286 / 3665 loss=5.106, loss_v1=0, loss_v2=0, nll_loss=4.201, ntokens=937.3, nsentences=32, sample_size=937.3, sample_size_v1=0, sample_size_v2=0, ppl=18.39, wps=372.6, ups=0.4, wpb=937.3, bsz=32, num_updates=14260, lr=3.24954e-05, gnorm=1.968, clip=100, loss_scale=256, train_wall=25, gb_free=15.6, wall=39365
2023-01-09 14:34:04 - progress_bar.py[line:272] - INFO: epoch 004:   3296 / 3665 loss=5.214, loss_v1=0, loss_v2=0, nll_loss=4.32, ntokens=956.3, nsentences=32, sample_size=956.3, sample_size_v1=0, sample_size_v2=0, ppl=19.98, wps=378.5, ups=0.4, wpb=956.3, bsz=32, num_updates=14270, lr=3.24809e-05, gnorm=2.05, clip=100, loss_scale=256, train_wall=25, gb_free=15.5, wall=39391
2023-01-09 14:34:29 - progress_bar.py[line:272] - INFO: epoch 004:   3306 / 3665 loss=5.101, loss_v1=0, loss_v2=0, nll_loss=4.194, ntokens=775, nsentences=32, sample_size=775, sample_size_v1=0, sample_size_v2=0, ppl=18.31, wps=309.8, ups=0.4, wpb=775, bsz=32, num_updates=14280, lr=3.24664e-05, gnorm=2.348, clip=100, loss_scale=256, train_wall=25, gb_free=15.6, wall=39416
2023-01-09 14:34:55 - progress_bar.py[line:272] - INFO: epoch 004:   3316 / 3665 loss=5.222, loss_v1=0, loss_v2=0, nll_loss=4.331, ntokens=1055.7, nsentences=32, sample_size=1055.7, sample_size_v1=0, sample_size_v2=0, ppl=20.12, wps=416, ups=0.39, wpb=1055.7, bsz=32, num_updates=14290, lr=3.24519e-05, gnorm=1.985, clip=100, loss_scale=256, train_wall=25, gb_free=15.4, wall=39441
2023-01-09 14:35:20 - progress_bar.py[line:272] - INFO: epoch 004:   3326 / 3665 loss=5.279, loss_v1=0, loss_v2=0, nll_loss=4.391, ntokens=969.4, nsentences=32, sample_size=969.4, sample_size_v1=0, sample_size_v2=0, ppl=20.99, wps=382.7, ups=0.39, wpb=969.4, bsz=32, num_updates=14300, lr=3.24374e-05, gnorm=2.088, clip=100, loss_scale=256, train_wall=25, gb_free=15.1, wall=39466
2023-01-09 14:35:45 - progress_bar.py[line:272] - INFO: epoch 004:   3336 / 3665 loss=5.221, loss_v1=0, loss_v2=0, nll_loss=4.329, ntokens=911.4, nsentences=32, sample_size=911.4, sample_size_v1=0, sample_size_v2=0, ppl=20.1, wps=360.9, ups=0.4, wpb=911.4, bsz=32, num_updates=14310, lr=3.24229e-05, gnorm=2.105, clip=100, loss_scale=256, train_wall=25, gb_free=15.3, wall=39491
2023-01-09 14:36:10 - progress_bar.py[line:272] - INFO: epoch 004:   3346 / 3665 loss=5.158, loss_v1=0, loss_v2=0, nll_loss=4.258, ntokens=913.2, nsentences=32, sample_size=913.2, sample_size_v1=0, sample_size_v2=0, ppl=19.14, wps=363.6, ups=0.4, wpb=913.2, bsz=32, num_updates=14320, lr=3.24083e-05, gnorm=2.051, clip=100, loss_scale=256, train_wall=25, gb_free=15.5, wall=39517
2023-01-09 14:36:36 - progress_bar.py[line:272] - INFO: epoch 004:   3356 / 3665 loss=5.238, loss_v1=0, loss_v2=0, nll_loss=4.347, ntokens=1034.1, nsentences=32, sample_size=1034.1, sample_size_v1=0, sample_size_v2=0, ppl=20.35, wps=409, ups=0.4, wpb=1034.1, bsz=32, num_updates=14330, lr=3.23938e-05, gnorm=1.9, clip=100, loss_scale=256, train_wall=25, gb_free=15.3, wall=39542
2023-01-09 14:37:01 - progress_bar.py[line:272] - INFO: epoch 004:   3366 / 3665 loss=5.182, loss_v1=0, loss_v2=0, nll_loss=4.284, ntokens=816.5, nsentences=32, sample_size=816.5, sample_size_v1=0, sample_size_v2=0, ppl=19.49, wps=326.6, ups=0.4, wpb=816.5, bsz=32, num_updates=14340, lr=3.23793e-05, gnorm=2.234, clip=100, loss_scale=256, train_wall=25, gb_free=15.5, wall=39567
2023-01-09 14:37:26 - progress_bar.py[line:272] - INFO: epoch 004:   3376 / 3665 loss=5.144, loss_v1=0, loss_v2=0, nll_loss=4.242, ntokens=955.5, nsentences=32, sample_size=955.5, sample_size_v1=0, sample_size_v2=0, ppl=18.92, wps=378.3, ups=0.4, wpb=955.5, bsz=32, num_updates=14350, lr=3.23648e-05, gnorm=2.035, clip=100, loss_scale=256, train_wall=25, gb_free=15.5, wall=39592
2023-01-09 14:37:51 - progress_bar.py[line:272] - INFO: epoch 004:   3386 / 3665 loss=5.231, loss_v1=0, loss_v2=0, nll_loss=4.34, ntokens=1046.8, nsentences=32, sample_size=1046.8, sample_size_v1=0, sample_size_v2=0, ppl=20.25, wps=409.2, ups=0.39, wpb=1046.8, bsz=32, num_updates=14360, lr=3.23503e-05, gnorm=1.821, clip=100, loss_scale=256, train_wall=26, gb_free=15.4, wall=39618
2023-01-09 14:38:17 - progress_bar.py[line:272] - INFO: epoch 004:   3396 / 3665 loss=5.166, loss_v1=0, loss_v2=0, nll_loss=4.268, ntokens=744.9, nsentences=32, sample_size=744.9, sample_size_v1=0, sample_size_v2=0, ppl=19.26, wps=295.1, ups=0.4, wpb=744.9, bsz=32, num_updates=14370, lr=3.23358e-05, gnorm=2.371, clip=100, loss_scale=256, train_wall=25, gb_free=15.2, wall=39643
2023-01-09 14:38:42 - progress_bar.py[line:272] - INFO: epoch 004:   3406 / 3665 loss=5.163, loss_v1=0, loss_v2=0, nll_loss=4.263, ntokens=937.7, nsentences=32, sample_size=937.7, sample_size_v1=0, sample_size_v2=0, ppl=19.2, wps=371, ups=0.4, wpb=937.7, bsz=32, num_updates=14380, lr=3.23213e-05, gnorm=2.091, clip=100, loss_scale=256, train_wall=25, gb_free=15.5, wall=39668
2023-01-09 14:39:07 - progress_bar.py[line:272] - INFO: epoch 004:   3416 / 3665 loss=5.163, loss_v1=0, loss_v2=0, nll_loss=4.264, ntokens=1073.7, nsentences=32, sample_size=1073.7, sample_size_v1=0, sample_size_v2=0, ppl=19.22, wps=423.3, ups=0.39, wpb=1073.7, bsz=32, num_updates=14390, lr=3.23068e-05, gnorm=1.991, clip=100, loss_scale=256, train_wall=25, gb_free=15, wall=39694
2023-01-09 14:39:32 - progress_bar.py[line:272] - INFO: epoch 004:   3426 / 3665 loss=5.199, loss_v1=0, loss_v2=0, nll_loss=4.305, ntokens=722.8, nsentences=32, sample_size=722.8, sample_size_v1=0, sample_size_v2=0, ppl=19.76, wps=289, ups=0.4, wpb=722.8, bsz=32, num_updates=14400, lr=3.22922e-05, gnorm=2.764, clip=100, loss_scale=256, train_wall=25, gb_free=15.3, wall=39719
2023-01-09 14:39:57 - progress_bar.py[line:272] - INFO: epoch 004:   3436 / 3665 loss=5.199, loss_v1=0, loss_v2=0, nll_loss=4.303, ntokens=967.9, nsentences=32, sample_size=967.9, sample_size_v1=0, sample_size_v2=0, ppl=19.74, wps=385.2, ups=0.4, wpb=967.9, bsz=32, num_updates=14410, lr=3.22777e-05, gnorm=1.973, clip=100, loss_scale=256, train_wall=25, gb_free=15.5, wall=39744
2023-01-09 14:40:22 - progress_bar.py[line:272] - INFO: epoch 004:   3446 / 3665 loss=5.12, loss_v1=0, loss_v2=0, nll_loss=4.214, ntokens=960.5, nsentences=32, sample_size=960.5, sample_size_v1=0, sample_size_v2=0, ppl=18.56, wps=386.3, ups=0.4, wpb=960.5, bsz=32, num_updates=14420, lr=3.22632e-05, gnorm=2.004, clip=100, loss_scale=256, train_wall=25, gb_free=15.4, wall=39769
2023-01-09 14:40:46 - progress_bar.py[line:272] - INFO: epoch 004:   3456 / 3665 loss=5.206, loss_v1=0, loss_v2=0, nll_loss=4.312, ntokens=839.6, nsentences=32, sample_size=839.6, sample_size_v1=0, sample_size_v2=0, ppl=19.86, wps=361.1, ups=0.43, wpb=839.6, bsz=32, num_updates=14430, lr=3.22487e-05, gnorm=2.269, clip=100, loss_scale=256, train_wall=23, gb_free=15.6, wall=39792
2023-01-09 14:41:07 - progress_bar.py[line:272] - INFO: epoch 004:   3466 / 3665 loss=5.068, loss_v1=0, loss_v2=0, nll_loss=4.158, ntokens=694, nsentences=32, sample_size=694, sample_size_v1=0, sample_size_v2=0, ppl=17.85, wps=322.3, ups=0.46, wpb=694, bsz=32, num_updates=14440, lr=3.22342e-05, gnorm=2.627, clip=100, loss_scale=256, train_wall=21, gb_free=15.5, wall=39813
2023-01-09 14:41:29 - progress_bar.py[line:272] - INFO: epoch 004:   3476 / 3665 loss=5.161, loss_v1=0, loss_v2=0, nll_loss=4.263, ntokens=1027.9, nsentences=32, sample_size=1027.9, sample_size_v1=0, sample_size_v2=0, ppl=19.2, wps=472.4, ups=0.46, wpb=1027.9, bsz=32, num_updates=14450, lr=3.22197e-05, gnorm=2.205, clip=100, loss_scale=256, train_wall=22, gb_free=15.3, wall=39835
2023-01-09 14:41:51 - progress_bar.py[line:272] - INFO: epoch 004:   3486 / 3665 loss=5.25, loss_v1=0, loss_v2=0, nll_loss=4.359, ntokens=851.5, nsentences=32, sample_size=851.5, sample_size_v1=0, sample_size_v2=0, ppl=20.52, wps=391.5, ups=0.46, wpb=851.5, bsz=32, num_updates=14460, lr=3.22052e-05, gnorm=2.331, clip=100, loss_scale=256, train_wall=22, gb_free=15.7, wall=39857
2023-01-09 14:42:14 - progress_bar.py[line:272] - INFO: epoch 004:   3496 / 3665 loss=5.074, loss_v1=0, loss_v2=0, nll_loss=4.164, ntokens=686.1, nsentences=32, sample_size=686.1, sample_size_v1=0, sample_size_v2=0, ppl=17.92, wps=295.4, ups=0.43, wpb=686.1, bsz=32, num_updates=14470, lr=3.21906e-05, gnorm=2.516, clip=100, loss_scale=256, train_wall=23, gb_free=15.6, wall=39880
2023-01-09 14:42:42 - progress_bar.py[line:272] - INFO: epoch 004:   3506 / 3665 loss=5.137, loss_v1=0, loss_v2=0, nll_loss=4.235, ntokens=927, nsentences=32, sample_size=927, sample_size_v1=0, sample_size_v2=0, ppl=18.83, wps=326.2, ups=0.35, wpb=927, bsz=32, num_updates=14480, lr=3.21761e-05, gnorm=2.159, clip=100, loss_scale=256, train_wall=28, gb_free=15.5, wall=39909
2023-01-09 14:43:10 - progress_bar.py[line:272] - INFO: epoch 004:   3516 / 3665 loss=5.267, loss_v1=0, loss_v2=0, nll_loss=4.38, ntokens=1081.6, nsentences=32, sample_size=1081.6, sample_size_v1=0, sample_size_v2=0, ppl=20.82, wps=386.6, ups=0.36, wpb=1081.6, bsz=32, num_updates=14490, lr=3.21616e-05, gnorm=1.85, clip=100, loss_scale=256, train_wall=28, gb_free=15.5, wall=39937
2023-01-09 14:43:34 - progress_bar.py[line:272] - INFO: epoch 004:   3526 / 3665 loss=5.193, loss_v1=0, loss_v2=0, nll_loss=4.298, ntokens=856.5, nsentences=32, sample_size=856.5, sample_size_v1=0, sample_size_v2=0, ppl=19.67, wps=354.5, ups=0.41, wpb=856.5, bsz=32, num_updates=14500, lr=3.21471e-05, gnorm=2.441, clip=100, loss_scale=256, train_wall=24, gb_free=14.7, wall=39961
2023-01-09 14:43:34 - train.py[line:445] - INFO: begin validation on "valid" subset
slice_id 0 seek offset 0
slice_id 0 seek offset 0
2023-01-09 14:48:50 - progress_bar.py[line:282] - INFO: epoch 004 | valid on 'valid' subset | loss 5.153 | loss_v1 0 | loss_v2 0 | nll_loss 4.235 | ntokens 117.151 | nsentences 4 | sample_size 117.151 | sample_size_v1 0 | sample_size_v2 0 | AP 0 | total positives 21.731 | TP 0 | FP 5.15994 | ppl 18.83 | wps 463 | wpb 117.2 | bsz 4 | num_updates 14500 | best_AP 0
2023-01-09 14:48:50 - checkpoint_utils.py[line:64] - INFO: Preparing to save checkpoint for epoch 4 @ 14500 updates
2023-01-09 14:48:50 - trainer.py[line:431] - INFO: Saving checkpoint to ../../checkpoints/OFA/detection_checkpoints/10_5e-5_512/checkpoint_4_14500.pt
2023-01-09 14:48:54 - trainer.py[line:441] - INFO: Finished saving checkpoint to ../../checkpoints/OFA/detection_checkpoints/10_5e-5_512/checkpoint_4_14500.pt
2023-01-09 14:50:59 - checkpoint_utils.py[line:133] - INFO: Saved checkpoint ../../checkpoints/OFA/detection_checkpoints/10_5e-5_512/checkpoint_4_14500.pt (epoch 4 @ 14500 updates, score 0.0) (writing took 128.40125009510666 seconds)
2023-01-09 14:51:18 - progress_bar.py[line:272] - INFO: epoch 004:   3536 / 3665 loss=5.101, loss_v1=0, loss_v2=0, nll_loss=4.194, ntokens=967.6, nsentences=32, sample_size=967.6, sample_size_v1=0, sample_size_v2=0, ppl=18.3, wps=20.9, ups=0.02, wpb=967.6, bsz=32, num_updates=14510, lr=3.21326e-05, gnorm=2.103, clip=100, loss_scale=256, train_wall=20, gb_free=15.4, wall=40425
2023-01-09 14:51:38 - progress_bar.py[line:272] - INFO: epoch 004:   3546 / 3665 loss=5.231, loss_v1=0, loss_v2=0, nll_loss=4.34, ntokens=1094.6, nsentences=32, sample_size=1094.6, sample_size_v1=0, sample_size_v2=0, ppl=20.25, wps=543.1, ups=0.5, wpb=1094.6, bsz=32, num_updates=14520, lr=3.21181e-05, gnorm=1.863, clip=100, loss_scale=256, train_wall=20, gb_free=15, wall=40445
2023-01-09 14:51:59 - progress_bar.py[line:272] - INFO: epoch 004:   3556 / 3665 loss=5.169, loss_v1=0, loss_v2=0, nll_loss=4.269, ntokens=903.1, nsentences=32, sample_size=903.1, sample_size_v1=0, sample_size_v2=0, ppl=19.29, wps=444.7, ups=0.49, wpb=903.1, bsz=32, num_updates=14530, lr=3.21036e-05, gnorm=2.072, clip=100, loss_scale=256, train_wall=20, gb_free=15.3, wall=40465
2023-01-09 14:52:19 - progress_bar.py[line:272] - INFO: epoch 004:   3566 / 3665 loss=5.176, loss_v1=0, loss_v2=0, nll_loss=4.278, ntokens=960.1, nsentences=32, sample_size=960.1, sample_size_v1=0, sample_size_v2=0, ppl=19.41, wps=467.8, ups=0.49, wpb=960.1, bsz=32, num_updates=14540, lr=3.20891e-05, gnorm=2.064, clip=100, loss_scale=256, train_wall=20, gb_free=15.5, wall=40486
2023-01-09 14:52:44 - progress_bar.py[line:272] - INFO: epoch 004:   3576 / 3665 loss=5.19, loss_v1=0, loss_v2=0, nll_loss=4.295, ntokens=1116.8, nsentences=32, sample_size=1116.8, sample_size_v1=0, sample_size_v2=0, ppl=19.62, wps=455.4, ups=0.41, wpb=1116.8, bsz=32, num_updates=14550, lr=3.20745e-05, gnorm=1.781, clip=100, loss_scale=256, train_wall=24, gb_free=15.4, wall=40510
2023-01-09 14:53:11 - progress_bar.py[line:272] - INFO: epoch 004:   3586 / 3665 loss=5.153, loss_v1=0, loss_v2=0, nll_loss=4.254, ntokens=749.1, nsentences=32, sample_size=749.1, sample_size_v1=0, sample_size_v2=0, ppl=19.08, wps=277.3, ups=0.37, wpb=749.1, bsz=32, num_updates=14560, lr=3.206e-05, gnorm=2.466, clip=100, loss_scale=256, train_wall=27, gb_free=15.5, wall=40537
2023-01-09 14:53:35 - progress_bar.py[line:272] - INFO: epoch 004:   3596 / 3665 loss=5.19, loss_v1=0, loss_v2=0, nll_loss=4.295, ntokens=876.6, nsentences=32, sample_size=876.6, sample_size_v1=0, sample_size_v2=0, ppl=19.63, wps=365.7, ups=0.42, wpb=876.6, bsz=32, num_updates=14570, lr=3.20455e-05, gnorm=2.307, clip=100, loss_scale=256, train_wall=24, gb_free=15.7, wall=40561
2023-01-09 14:53:58 - progress_bar.py[line:272] - INFO: epoch 004:   3606 / 3665 loss=5.116, loss_v1=0, loss_v2=0, nll_loss=4.21, ntokens=1011.7, nsentences=32, sample_size=1011.7, sample_size_v1=0, sample_size_v2=0, ppl=18.51, wps=444, ups=0.44, wpb=1011.7, bsz=32, num_updates=14580, lr=3.2031e-05, gnorm=1.914, clip=100, loss_scale=256, train_wall=23, gb_free=15.4, wall=40584
2023-01-09 14:54:20 - progress_bar.py[line:272] - INFO: epoch 004:   3616 / 3665 loss=5.195, loss_v1=0, loss_v2=0, nll_loss=4.299, ntokens=862.7, nsentences=32, sample_size=862.7, sample_size_v1=0, sample_size_v2=0, ppl=19.68, wps=378.2, ups=0.44, wpb=862.7, bsz=32, num_updates=14590, lr=3.20165e-05, gnorm=2.27, clip=100, loss_scale=256, train_wall=23, gb_free=15.7, wall=40607
2023-01-09 14:54:43 - progress_bar.py[line:272] - INFO: epoch 004:   3626 / 3665 loss=5.12, loss_v1=0, loss_v2=0, nll_loss=4.216, ntokens=900.6, nsentences=32, sample_size=900.6, sample_size_v1=0, sample_size_v2=0, ppl=18.59, wps=392.9, ups=0.44, wpb=900.6, bsz=32, num_updates=14600, lr=3.2002e-05, gnorm=2.206, clip=100, loss_scale=256, train_wall=23, gb_free=15.4, wall=40630
2023-01-09 14:55:06 - progress_bar.py[line:272] - INFO: epoch 004:   3636 / 3665 loss=5.113, loss_v1=0, loss_v2=0, nll_loss=4.208, ntokens=1085.6, nsentences=32, sample_size=1085.6, sample_size_v1=0, sample_size_v2=0, ppl=18.48, wps=469.7, ups=0.43, wpb=1085.6, bsz=32, num_updates=14610, lr=3.19875e-05, gnorm=1.871, clip=100, loss_scale=256, train_wall=23, gb_free=15.7, wall=40653
2023-01-09 14:55:30 - progress_bar.py[line:272] - INFO: epoch 004:   3646 / 3665 loss=5.215, loss_v1=0, loss_v2=0, nll_loss=4.32, ntokens=880.1, nsentences=32, sample_size=880.1, sample_size_v1=0, sample_size_v2=0, ppl=19.98, wps=380.8, ups=0.43, wpb=880.1, bsz=32, num_updates=14620, lr=3.19729e-05, gnorm=2.062, clip=100, loss_scale=256, train_wall=23, gb_free=15.1, wall=40676
2023-01-09 14:55:52 - progress_bar.py[line:272] - INFO: epoch 004:   3656 / 3665 loss=5.138, loss_v1=0, loss_v2=0, nll_loss=4.238, ntokens=862.8, nsentences=32, sample_size=862.8, sample_size_v1=0, sample_size_v2=0, ppl=18.86, wps=376.7, ups=0.44, wpb=862.8, bsz=32, num_updates=14630, lr=3.19584e-05, gnorm=2.168, clip=100, loss_scale=256, train_wall=23, gb_free=15.4, wall=40699
2023-01-09 14:56:12 - train.py[line:445] - INFO: begin validation on "valid" subset
slice_id 0 seek offset 0
slice_id 0 seek offset 0
2023-01-09 15:01:31 - progress_bar.py[line:282] - INFO: epoch 004 | valid on 'valid' subset | loss 5.163 | loss_v1 0 | loss_v2 0 | nll_loss 4.246 | ntokens 117.388 | nsentences 4 | sample_size 117.388 | sample_size_v1 0 | sample_size_v2 0 | AP 0 | total positives 21.7859 | TP 0 | FP 5.4483 | ppl 18.97 | wps 459.6 | wpb 117.4 | bsz 4 | num_updates 14639 | best_AP 0
2023-01-09 15:01:31 - checkpoint_utils.py[line:64] - INFO: Preparing to save checkpoint for epoch 4 @ 14639 updates
2023-01-09 15:01:31 - trainer.py[line:431] - INFO: Saving checkpoint to ../../checkpoints/OFA/detection_checkpoints/10_5e-5_512/checkpoint_best.pt
2023-01-09 15:01:48 - trainer.py[line:441] - INFO: Finished saving checkpoint to ../../checkpoints/OFA/detection_checkpoints/10_5e-5_512/checkpoint_best.pt
2023-01-09 15:02:13 - checkpoint_utils.py[line:133] - INFO: Saved checkpoint ../../checkpoints/OFA/detection_checkpoints/10_5e-5_512/checkpoint_best.pt (epoch 4 @ 14639 updates, score 0.0) (writing took 42.171346246730536 seconds)
2023-01-09 15:02:13 - train.py[line:332] - INFO: end of epoch 4 (average epoch stats below)
2023-01-09 15:02:13 - progress_bar.py[line:282] - INFO: epoch 004 | loss 5.207 | loss_v1 0 | loss_v2 0 | nll_loss 4.313 | ntokens 923.901 | nsentences 31.996 | sample_size 923.901 | sample_size_v1 0 | sample_size_v2 0 | AP 0 | ppl 19.88 | wps 310 | ups 0.34 | wpb 923.9 | bsz 32 | num_updates 14639 | lr 3.19454e-05 | gnorm 2.017 | clip 99.9 | loss_scale 512 | train_wall 7523 | gb_free 14.8 | wall 41080
2023-01-09 15:02:13 - trainer.py[line:639] - INFO: loading train data for epoch 5
local datafile ../../dataset/OFA_data/train.tsv slice_id 0 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../dataset/OFA_data/train.tsv slice_id 0 finished initializing row_count and line_idx-to-offset mapping
file ../../dataset/OFA_data/train.tsv slice_id 0 row count 117266 total row count 117266
slice_id 0 seek offset 0
2023-01-09 15:04:33 - trainer.py[line:703] - INFO: begin training epoch 5
2023-01-09 15:04:33 - train.py[line:305] - INFO: Start iterating over samples
2023-01-09 15:04:35 - progress_bar.py[line:272] - INFO: epoch 005:      1 / 3665 loss=5.18, loss_v1=0, loss_v2=0, nll_loss=4.282, ntokens=1066.1, nsentences=30.8, sample_size=1066.1, sample_size_v1=0, sample_size_v2=0, ppl=19.46, wps=20.4, ups=0.02, wpb=1066.1, bsz=30.8, num_updates=14640, lr=3.19439e-05, gnorm=1.954, clip=100, loss_scale=512, train_wall=22, gb_free=15.4, wall=41221
2023-01-09 15:04:55 - progress_bar.py[line:272] - INFO: epoch 005:     11 / 3665 loss=5.179, loss_v1=0, loss_v2=0, nll_loss=4.28, ntokens=819.3, nsentences=32, sample_size=819.3, sample_size_v1=0, sample_size_v2=0, ppl=19.43, wps=418.2, ups=0.51, wpb=819.3, bsz=32, num_updates=14650, lr=3.19294e-05, gnorm=2.214, clip=100, loss_scale=512, train_wall=20, gb_free=15.5, wall=41241
2023-01-09 15:05:15 - progress_bar.py[line:272] - INFO: epoch 005:     21 / 3665 loss=5.094, loss_v1=0, loss_v2=0, nll_loss=4.188, ntokens=849.9, nsentences=32, sample_size=849.9, sample_size_v1=0, sample_size_v2=0, ppl=18.22, wps=427.1, ups=0.5, wpb=849.9, bsz=32, num_updates=14660, lr=3.19149e-05, gnorm=2.182, clip=100, loss_scale=512, train_wall=20, gb_free=15.6, wall=41261
2023-01-09 15:05:35 - progress_bar.py[line:272] - INFO: epoch 005:     31 / 3665 loss=5.209, loss_v1=0, loss_v2=0, nll_loss=4.314, ntokens=1051.9, nsentences=32, sample_size=1051.9, sample_size_v1=0, sample_size_v2=0, ppl=19.9, wps=518.4, ups=0.49, wpb=1051.9, bsz=32, num_updates=14670, lr=3.19004e-05, gnorm=1.958, clip=100, loss_scale=512, train_wall=20, gb_free=15.1, wall=41281
2023-01-09 15:05:55 - progress_bar.py[line:272] - INFO: epoch 005:     41 / 3665 loss=5.079, loss_v1=0, loss_v2=0, nll_loss=4.169, ntokens=756.7, nsentences=32, sample_size=756.7, sample_size_v1=0, sample_size_v2=0, ppl=17.99, wps=370.9, ups=0.49, wpb=756.7, bsz=32, num_updates=14680, lr=3.18859e-05, gnorm=2.584, clip=100, loss_scale=512, train_wall=20, gb_free=15.3, wall=41302
2023-01-09 15:06:23 - progress_bar.py[line:272] - INFO: epoch 005:     51 / 3665 loss=5.116, loss_v1=0, loss_v2=0, nll_loss=4.212, ntokens=954.1, nsentences=32, sample_size=954.1, sample_size_v1=0, sample_size_v2=0, ppl=18.53, wps=339.5, ups=0.36, wpb=954.1, bsz=32, num_updates=14690, lr=3.18714e-05, gnorm=2.005, clip=100, loss_scale=512, train_wall=28, gb_free=15.3, wall=41330
2023-01-09 15:06:36 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 256.0
2023-01-09 15:06:49 - progress_bar.py[line:272] - INFO: epoch 005:     62 / 3665 loss=5.178, loss_v1=0, loss_v2=0, nll_loss=4.281, ntokens=890.8, nsentences=32, sample_size=890.8, sample_size_v1=0, sample_size_v2=0, ppl=19.45, wps=353, ups=0.4, wpb=890.8, bsz=32, num_updates=14700, lr=3.18568e-05, gnorm=2.265, clip=100, loss_scale=256, train_wall=23, gb_free=15.6, wall=41355
2023-01-09 15:07:11 - progress_bar.py[line:272] - INFO: epoch 005:     72 / 3665 loss=5.152, loss_v1=0, loss_v2=0, nll_loss=4.251, ntokens=849.1, nsentences=32, sample_size=849.1, sample_size_v1=0, sample_size_v2=0, ppl=19.05, wps=386.8, ups=0.46, wpb=849.1, bsz=32, num_updates=14710, lr=3.18423e-05, gnorm=2.451, clip=100, loss_scale=256, train_wall=22, gb_free=15.3, wall=41377
2023-01-09 15:07:33 - progress_bar.py[line:272] - INFO: epoch 005:     82 / 3665 loss=5.132, loss_v1=0, loss_v2=0, nll_loss=4.228, ntokens=1003.4, nsentences=32, sample_size=1003.4, sample_size_v1=0, sample_size_v2=0, ppl=18.74, wps=456.3, ups=0.45, wpb=1003.4, bsz=32, num_updates=14720, lr=3.18278e-05, gnorm=1.802, clip=100, loss_scale=256, train_wall=22, gb_free=15.5, wall=41399
2023-01-09 15:07:54 - progress_bar.py[line:272] - INFO: epoch 005:     92 / 3665 loss=5.191, loss_v1=0, loss_v2=0, nll_loss=4.295, ntokens=800.3, nsentences=32, sample_size=800.3, sample_size_v1=0, sample_size_v2=0, ppl=19.63, wps=368.4, ups=0.46, wpb=800.3, bsz=32, num_updates=14730, lr=3.18133e-05, gnorm=2.55, clip=100, loss_scale=256, train_wall=22, gb_free=14.8, wall=41421
2023-01-09 15:08:15 - progress_bar.py[line:272] - INFO: epoch 005:    102 / 3665 loss=5.223, loss_v1=0, loss_v2=0, nll_loss=4.331, ntokens=971.7, nsentences=32, sample_size=971.7, sample_size_v1=0, sample_size_v2=0, ppl=20.12, wps=462.7, ups=0.48, wpb=971.7, bsz=32, num_updates=14740, lr=3.17988e-05, gnorm=2.113, clip=100, loss_scale=256, train_wall=21, gb_free=15.2, wall=41442
2023-01-09 15:08:36 - progress_bar.py[line:272] - INFO: epoch 005:    112 / 3665 loss=5.117, loss_v1=0, loss_v2=0, nll_loss=4.213, ntokens=1086.4, nsentences=32, sample_size=1086.4, sample_size_v1=0, sample_size_v2=0, ppl=18.55, wps=539.1, ups=0.5, wpb=1086.4, bsz=32, num_updates=14750, lr=3.17843e-05, gnorm=2.022, clip=100, loss_scale=256, train_wall=20, gb_free=15.5, wall=41462
2023-01-09 15:08:56 - progress_bar.py[line:272] - INFO: epoch 005:    122 / 3665 loss=5.206, loss_v1=0, loss_v2=0, nll_loss=4.31, ntokens=942.1, nsentences=32, sample_size=942.1, sample_size_v1=0, sample_size_v2=0, ppl=19.84, wps=471.2, ups=0.5, wpb=942.1, bsz=32, num_updates=14760, lr=3.17698e-05, gnorm=2.086, clip=100, loss_scale=256, train_wall=20, gb_free=15.3, wall=41482
2023-01-09 15:09:15 - progress_bar.py[line:272] - INFO: epoch 005:    132 / 3665 loss=5.099, loss_v1=0, loss_v2=0, nll_loss=4.191, ntokens=854.5, nsentences=32, sample_size=854.5, sample_size_v1=0, sample_size_v2=0, ppl=18.27, wps=428.7, ups=0.5, wpb=854.5, bsz=32, num_updates=14770, lr=3.17552e-05, gnorm=2.243, clip=100, loss_scale=256, train_wall=20, gb_free=15.5, wall=41502
2023-01-09 15:09:36 - progress_bar.py[line:272] - INFO: epoch 005:    142 / 3665 loss=5.174, loss_v1=0, loss_v2=0, nll_loss=4.279, ntokens=1065.1, nsentences=32, sample_size=1065.1, sample_size_v1=0, sample_size_v2=0, ppl=19.41, wps=531, ups=0.5, wpb=1065.1, bsz=32, num_updates=14780, lr=3.17407e-05, gnorm=1.978, clip=100, loss_scale=256, train_wall=20, gb_free=15.4, wall=41522
2023-01-09 15:09:55 - progress_bar.py[line:272] - INFO: epoch 005:    152 / 3665 loss=5.191, loss_v1=0, loss_v2=0, nll_loss=4.294, ntokens=856.1, nsentences=32, sample_size=856.1, sample_size_v1=0, sample_size_v2=0, ppl=19.61, wps=429.3, ups=0.5, wpb=856.1, bsz=32, num_updates=14790, lr=3.17262e-05, gnorm=2.314, clip=100, loss_scale=256, train_wall=20, gb_free=15.1, wall=41542
2023-01-09 15:10:15 - progress_bar.py[line:272] - INFO: epoch 005:    162 / 3665 loss=5.089, loss_v1=0, loss_v2=0, nll_loss=4.18, ntokens=929.6, nsentences=32, sample_size=929.6, sample_size_v1=0, sample_size_v2=0, ppl=18.12, wps=465.6, ups=0.5, wpb=929.6, bsz=32, num_updates=14800, lr=3.17117e-05, gnorm=2.08, clip=100, loss_scale=256, train_wall=20, gb_free=15.4, wall=41562
2023-01-09 15:10:35 - progress_bar.py[line:272] - INFO: epoch 005:    172 / 3665 loss=5.238, loss_v1=0, loss_v2=0, nll_loss=4.349, ntokens=992.8, nsentences=32, sample_size=992.8, sample_size_v1=0, sample_size_v2=0, ppl=20.37, wps=497, ups=0.5, wpb=992.8, bsz=32, num_updates=14810, lr=3.16972e-05, gnorm=2.155, clip=100, loss_scale=256, train_wall=20, gb_free=15.6, wall=41582
2023-01-09 15:10:55 - progress_bar.py[line:272] - INFO: epoch 005:    182 / 3665 loss=5.085, loss_v1=0, loss_v2=0, nll_loss=4.176, ntokens=788.5, nsentences=32, sample_size=788.5, sample_size_v1=0, sample_size_v2=0, ppl=18.08, wps=395.8, ups=0.5, wpb=788.5, bsz=32, num_updates=14820, lr=3.16827e-05, gnorm=2.426, clip=100, loss_scale=256, train_wall=20, gb_free=15.6, wall=41602
2023-01-09 15:11:15 - progress_bar.py[line:272] - INFO: epoch 005:    192 / 3665 loss=5.157, loss_v1=0, loss_v2=0, nll_loss=4.258, ntokens=1080.1, nsentences=32, sample_size=1080.1, sample_size_v1=0, sample_size_v2=0, ppl=19.13, wps=538.6, ups=0.5, wpb=1080.1, bsz=32, num_updates=14830, lr=3.16682e-05, gnorm=1.876, clip=100, loss_scale=256, train_wall=20, gb_free=15.2, wall=41622
2023-01-09 15:11:35 - progress_bar.py[line:272] - INFO: epoch 005:    202 / 3665 loss=5.205, loss_v1=0, loss_v2=0, nll_loss=4.311, ntokens=836.7, nsentences=32, sample_size=836.7, sample_size_v1=0, sample_size_v2=0, ppl=19.85, wps=419.9, ups=0.5, wpb=836.7, bsz=32, num_updates=14840, lr=3.16537e-05, gnorm=2.318, clip=100, loss_scale=256, train_wall=20, gb_free=15.5, wall=41642
2023-01-09 15:11:55 - progress_bar.py[line:272] - INFO: epoch 005:    212 / 3665 loss=5.136, loss_v1=0, loss_v2=0, nll_loss=4.231, ntokens=792.5, nsentences=32, sample_size=792.5, sample_size_v1=0, sample_size_v2=0, ppl=18.78, wps=398.4, ups=0.5, wpb=792.5, bsz=32, num_updates=14850, lr=3.16391e-05, gnorm=2.353, clip=100, loss_scale=256, train_wall=20, gb_free=15.6, wall=41661
2023-01-09 15:12:15 - progress_bar.py[line:272] - INFO: epoch 005:    222 / 3665 loss=5.073, loss_v1=0, loss_v2=0, nll_loss=4.165, ntokens=959.5, nsentences=32, sample_size=959.5, sample_size_v1=0, sample_size_v2=0, ppl=17.94, wps=480.2, ups=0.5, wpb=959.5, bsz=32, num_updates=14860, lr=3.16246e-05, gnorm=1.999, clip=100, loss_scale=256, train_wall=20, gb_free=15.6, wall=41681
2023-01-09 15:12:35 - progress_bar.py[line:272] - INFO: epoch 005:    232 / 3665 loss=5.256, loss_v1=0, loss_v2=0, nll_loss=4.368, ntokens=992.2, nsentences=32, sample_size=992.2, sample_size_v1=0, sample_size_v2=0, ppl=20.64, wps=495.5, ups=0.5, wpb=992.2, bsz=32, num_updates=14870, lr=3.16101e-05, gnorm=2.061, clip=100, loss_scale=256, train_wall=20, gb_free=15.5, wall=41701
2023-01-09 15:12:55 - progress_bar.py[line:272] - INFO: epoch 005:    242 / 3665 loss=5.073, loss_v1=0, loss_v2=0, nll_loss=4.163, ntokens=867.6, nsentences=32, sample_size=867.6, sample_size_v1=0, sample_size_v2=0, ppl=17.92, wps=435, ups=0.5, wpb=867.6, bsz=32, num_updates=14880, lr=3.15956e-05, gnorm=2.313, clip=100, loss_scale=256, train_wall=20, gb_free=15.4, wall=41721
2023-01-09 15:13:15 - progress_bar.py[line:272] - INFO: epoch 005:    252 / 3665 loss=5.196, loss_v1=0, loss_v2=0, nll_loss=4.301, ntokens=1024.3, nsentences=32, sample_size=1024.3, sample_size_v1=0, sample_size_v2=0, ppl=19.71, wps=511, ups=0.5, wpb=1024.3, bsz=32, num_updates=14890, lr=3.15811e-05, gnorm=1.916, clip=100, loss_scale=256, train_wall=20, gb_free=15.3, wall=41741
2023-01-09 15:13:35 - progress_bar.py[line:272] - INFO: epoch 005:    262 / 3665 loss=5.065, loss_v1=0, loss_v2=0, nll_loss=4.155, ntokens=744, nsentences=32, sample_size=744, sample_size_v1=0, sample_size_v2=0, ppl=17.81, wps=372.8, ups=0.5, wpb=744, bsz=32, num_updates=14900, lr=3.15666e-05, gnorm=2.629, clip=100, loss_scale=256, train_wall=20, gb_free=15.4, wall=41761
2023-01-09 15:13:55 - progress_bar.py[line:272] - INFO: epoch 005:    272 / 3665 loss=5.204, loss_v1=0, loss_v2=0, nll_loss=4.308, ntokens=942.7, nsentences=32, sample_size=942.7, sample_size_v1=0, sample_size_v2=0, ppl=19.81, wps=473, ups=0.5, wpb=942.7, bsz=32, num_updates=14910, lr=3.15521e-05, gnorm=2.149, clip=100, loss_scale=256, train_wall=20, gb_free=15.5, wall=41781
2023-01-09 15:14:15 - progress_bar.py[line:272] - INFO: epoch 005:    282 / 3665 loss=5.183, loss_v1=0, loss_v2=0, nll_loss=4.285, ntokens=908.9, nsentences=32, sample_size=908.9, sample_size_v1=0, sample_size_v2=0, ppl=19.5, wps=459, ups=0.51, wpb=908.9, bsz=32, num_updates=14920, lr=3.15375e-05, gnorm=2.106, clip=100, loss_scale=256, train_wall=20, gb_free=15.2, wall=41801
2023-01-09 15:14:35 - progress_bar.py[line:272] - INFO: epoch 005:    292 / 3665 loss=5.135, loss_v1=0, loss_v2=0, nll_loss=4.234, ntokens=825.1, nsentences=32, sample_size=825.1, sample_size_v1=0, sample_size_v2=0, ppl=18.82, wps=417.6, ups=0.51, wpb=825.1, bsz=32, num_updates=14930, lr=3.1523e-05, gnorm=2.446, clip=100, loss_scale=256, train_wall=20, gb_free=15.7, wall=41821
2023-01-09 15:14:54 - progress_bar.py[line:272] - INFO: epoch 005:    302 / 3665 loss=5.141, loss_v1=0, loss_v2=0, nll_loss=4.241, ntokens=1034.9, nsentences=32, sample_size=1034.9, sample_size_v1=0, sample_size_v2=0, ppl=18.9, wps=523.3, ups=0.51, wpb=1034.9, bsz=32, num_updates=14940, lr=3.15085e-05, gnorm=2.095, clip=100, loss_scale=256, train_wall=20, gb_free=15.4, wall=41841
2023-01-09 15:15:14 - progress_bar.py[line:272] - INFO: epoch 005:    312 / 3665 loss=5.2, loss_v1=0, loss_v2=0, nll_loss=4.301, ntokens=1058, nsentences=32, sample_size=1058, sample_size_v1=0, sample_size_v2=0, ppl=19.71, wps=532.6, ups=0.5, wpb=1058, bsz=32, num_updates=14950, lr=3.1494e-05, gnorm=1.85, clip=100, loss_scale=256, train_wall=20, gb_free=15.2, wall=41861
2023-01-09 15:15:34 - progress_bar.py[line:272] - INFO: epoch 005:    322 / 3665 loss=5.148, loss_v1=0, loss_v2=0, nll_loss=4.249, ntokens=796.1, nsentences=32, sample_size=796.1, sample_size_v1=0, sample_size_v2=0, ppl=19.02, wps=404.2, ups=0.51, wpb=796.1, bsz=32, num_updates=14960, lr=3.14795e-05, gnorm=2.334, clip=100, loss_scale=256, train_wall=20, gb_free=15.2, wall=41880
2023-01-09 15:15:54 - progress_bar.py[line:272] - INFO: epoch 005:    332 / 3665 loss=5.097, loss_v1=0, loss_v2=0, nll_loss=4.192, ntokens=985.1, nsentences=32, sample_size=985.1, sample_size_v1=0, sample_size_v2=0, ppl=18.27, wps=498.5, ups=0.51, wpb=985.1, bsz=32, num_updates=14970, lr=3.1465e-05, gnorm=2.054, clip=100, loss_scale=256, train_wall=20, gb_free=15.2, wall=41900
2023-01-09 15:16:13 - progress_bar.py[line:272] - INFO: epoch 005:    342 / 3665 loss=5.152, loss_v1=0, loss_v2=0, nll_loss=4.251, ntokens=808, nsentences=32, sample_size=808, sample_size_v1=0, sample_size_v2=0, ppl=19.04, wps=409.3, ups=0.51, wpb=808, bsz=32, num_updates=14980, lr=3.14505e-05, gnorm=2.33, clip=100, loss_scale=256, train_wall=20, gb_free=15.7, wall=41920
2023-01-09 15:16:33 - progress_bar.py[line:272] - INFO: epoch 005:    352 / 3665 loss=5.104, loss_v1=0, loss_v2=0, nll_loss=4.197, ntokens=813.7, nsentences=32, sample_size=813.7, sample_size_v1=0, sample_size_v2=0, ppl=18.35, wps=412.9, ups=0.51, wpb=813.7, bsz=32, num_updates=14990, lr=3.1436e-05, gnorm=2.283, clip=100, loss_scale=256, train_wall=20, gb_free=15.5, wall=41939
2023-01-09 15:16:53 - progress_bar.py[line:272] - INFO: epoch 005:    362 / 3665 loss=5.123, loss_v1=0, loss_v2=0, nll_loss=4.22, ntokens=1044.2, nsentences=32, sample_size=1044.2, sample_size_v1=0, sample_size_v2=0, ppl=18.63, wps=525.7, ups=0.5, wpb=1044.2, bsz=32, num_updates=15000, lr=3.14214e-05, gnorm=1.893, clip=100, loss_scale=256, train_wall=20, gb_free=14.6, wall=41959
2023-01-09 15:16:53 - train.py[line:445] - INFO: begin validation on "valid" subset
slice_id 0 seek offset 0
slice_id 0 seek offset 0
2023-01-09 15:21:42 - progress_bar.py[line:282] - INFO: epoch 005 | valid on 'valid' subset | loss 5.147 | loss_v1 0 | loss_v2 0 | nll_loss 4.231 | ntokens 116.88 | nsentences 4 | sample_size 116.88 | sample_size_v1 0 | sample_size_v2 0 | AP 0 | total positives 21.6874 | TP 0 | FP 5.16882 | ppl 18.78 | wps 505.5 | wpb 116.9 | bsz 4 | num_updates 15000 | best_AP 0
2023-01-09 15:21:42 - checkpoint_utils.py[line:64] - INFO: Preparing to save checkpoint for epoch 5 @ 15000 updates
2023-01-09 15:21:42 - trainer.py[line:431] - INFO: Saving checkpoint to ../../checkpoints/OFA/detection_checkpoints/10_5e-5_512/checkpoint_5_15000.pt
2023-01-09 15:21:45 - trainer.py[line:441] - INFO: Finished saving checkpoint to ../../checkpoints/OFA/detection_checkpoints/10_5e-5_512/checkpoint_5_15000.pt
2023-01-09 15:22:55 - checkpoint_utils.py[line:133] - INFO: Saved checkpoint ../../checkpoints/OFA/detection_checkpoints/10_5e-5_512/checkpoint_5_15000.pt (epoch 5 @ 15000 updates, score 0.0) (writing took 72.80102843791246 seconds)
2023-01-09 15:23:14 - progress_bar.py[line:272] - INFO: epoch 005:    372 / 3665 loss=5.173, loss_v1=0, loss_v2=0, nll_loss=4.274, ntokens=798.4, nsentences=32, sample_size=798.4, sample_size_v1=0, sample_size_v2=0, ppl=19.35, wps=21, ups=0.03, wpb=798.4, bsz=32, num_updates=15010, lr=3.14069e-05, gnorm=2.372, clip=100, loss_scale=256, train_wall=19, gb_free=15.2, wall=42340
2023-01-09 15:23:33 - progress_bar.py[line:272] - INFO: epoch 005:    382 / 3665 loss=5.082, loss_v1=0, loss_v2=0, nll_loss=4.173, ntokens=919.3, nsentences=32, sample_size=919.3, sample_size_v1=0, sample_size_v2=0, ppl=18.04, wps=473, ups=0.51, wpb=919.3, bsz=32, num_updates=15020, lr=3.13924e-05, gnorm=2.15, clip=100, loss_scale=256, train_wall=19, gb_free=15.5, wall=42360
2023-01-09 15:23:53 - progress_bar.py[line:272] - INFO: epoch 005:    392 / 3665 loss=5.127, loss_v1=0, loss_v2=0, nll_loss=4.225, ntokens=956.2, nsentences=32, sample_size=956.2, sample_size_v1=0, sample_size_v2=0, ppl=18.7, wps=488.5, ups=0.51, wpb=956.2, bsz=32, num_updates=15030, lr=3.13779e-05, gnorm=1.943, clip=100, loss_scale=256, train_wall=20, gb_free=15.4, wall=42379
2023-01-09 15:24:13 - progress_bar.py[line:272] - INFO: epoch 005:    402 / 3665 loss=5.051, loss_v1=0, loss_v2=0, nll_loss=4.14, ntokens=735.7, nsentences=32, sample_size=735.7, sample_size_v1=0, sample_size_v2=0, ppl=17.63, wps=375.8, ups=0.51, wpb=735.7, bsz=32, num_updates=15040, lr=3.13634e-05, gnorm=2.557, clip=100, loss_scale=256, train_wall=20, gb_free=15.6, wall=42399
2023-01-09 15:24:32 - progress_bar.py[line:272] - INFO: epoch 005:    412 / 3665 loss=5.12, loss_v1=0, loss_v2=0, nll_loss=4.215, ntokens=1021.4, nsentences=32, sample_size=1021.4, sample_size_v1=0, sample_size_v2=0, ppl=18.57, wps=519.2, ups=0.51, wpb=1021.4, bsz=32, num_updates=15050, lr=3.13489e-05, gnorm=1.918, clip=100, loss_scale=256, train_wall=20, gb_free=15.5, wall=42418
2023-01-09 15:24:52 - progress_bar.py[line:272] - INFO: epoch 005:    422 / 3665 loss=5.152, loss_v1=0, loss_v2=0, nll_loss=4.252, ntokens=896.8, nsentences=32, sample_size=896.8, sample_size_v1=0, sample_size_v2=0, ppl=19.06, wps=457.9, ups=0.51, wpb=896.8, bsz=32, num_updates=15060, lr=3.13344e-05, gnorm=2.04, clip=100, loss_scale=256, train_wall=20, gb_free=15.7, wall=42438
2023-01-09 15:25:11 - progress_bar.py[line:272] - INFO: epoch 005:    432 / 3665 loss=5.136, loss_v1=0, loss_v2=0, nll_loss=4.234, ntokens=888.4, nsentences=32, sample_size=888.4, sample_size_v1=0, sample_size_v2=0, ppl=18.82, wps=453.1, ups=0.51, wpb=888.4, bsz=32, num_updates=15070, lr=3.13198e-05, gnorm=2.08, clip=100, loss_scale=256, train_wall=20, gb_free=15.6, wall=42458
2023-01-09 15:25:31 - progress_bar.py[line:272] - INFO: epoch 005:    442 / 3665 loss=5.161, loss_v1=0, loss_v2=0, nll_loss=4.262, ntokens=1043.7, nsentences=32, sample_size=1043.7, sample_size_v1=0, sample_size_v2=0, ppl=19.19, wps=530.6, ups=0.51, wpb=1043.7, bsz=32, num_updates=15080, lr=3.13053e-05, gnorm=2.093, clip=100, loss_scale=256, train_wall=20, gb_free=15.5, wall=42477
2023-01-09 15:25:51 - progress_bar.py[line:272] - INFO: epoch 005:    452 / 3665 loss=5.153, loss_v1=0, loss_v2=0, nll_loss=4.25, ntokens=910.7, nsentences=32, sample_size=910.7, sample_size_v1=0, sample_size_v2=0, ppl=19.02, wps=463.9, ups=0.51, wpb=910.7, bsz=32, num_updates=15090, lr=3.12908e-05, gnorm=2.128, clip=100, loss_scale=256, train_wall=20, gb_free=15.5, wall=42497
2023-01-09 15:26:10 - progress_bar.py[line:272] - INFO: epoch 005:    462 / 3665 loss=5.161, loss_v1=0, loss_v2=0, nll_loss=4.261, ntokens=948.9, nsentences=32, sample_size=948.9, sample_size_v1=0, sample_size_v2=0, ppl=19.18, wps=483.1, ups=0.51, wpb=948.9, bsz=32, num_updates=15100, lr=3.12763e-05, gnorm=2.115, clip=100, loss_scale=256, train_wall=20, gb_free=15.4, wall=42517
2023-01-09 15:26:30 - progress_bar.py[line:272] - INFO: epoch 005:    472 / 3665 loss=5.109, loss_v1=0, loss_v2=0, nll_loss=4.205, ntokens=1096.3, nsentences=32, sample_size=1096.3, sample_size_v1=0, sample_size_v2=0, ppl=18.44, wps=556.1, ups=0.51, wpb=1096.3, bsz=32, num_updates=15110, lr=3.12618e-05, gnorm=1.877, clip=100, loss_scale=256, train_wall=20, gb_free=15.5, wall=42536
2023-01-09 15:26:50 - progress_bar.py[line:272] - INFO: epoch 005:    482 / 3665 loss=5.266, loss_v1=0, loss_v2=0, nll_loss=4.379, ntokens=931.6, nsentences=32, sample_size=931.6, sample_size_v1=0, sample_size_v2=0, ppl=20.81, wps=474.5, ups=0.51, wpb=931.6, bsz=32, num_updates=15120, lr=3.12473e-05, gnorm=2.351, clip=100, loss_scale=256, train_wall=20, gb_free=15.2, wall=42556
2023-01-09 15:27:09 - progress_bar.py[line:272] - INFO: epoch 005:    492 / 3665 loss=5.149, loss_v1=0, loss_v2=0, nll_loss=4.249, ntokens=916, nsentences=32, sample_size=916, sample_size_v1=0, sample_size_v2=0, ppl=19.01, wps=464.9, ups=0.51, wpb=916, bsz=32, num_updates=15130, lr=3.12328e-05, gnorm=2.207, clip=100, loss_scale=256, train_wall=20, gb_free=15.5, wall=42576
2023-01-09 15:27:29 - progress_bar.py[line:272] - INFO: epoch 005:    502 / 3665 loss=5.158, loss_v1=0, loss_v2=0, nll_loss=4.258, ntokens=1010.4, nsentences=32, sample_size=1010.4, sample_size_v1=0, sample_size_v2=0, ppl=19.14, wps=505.3, ups=0.5, wpb=1010.4, bsz=32, num_updates=15140, lr=3.12183e-05, gnorm=1.983, clip=100, loss_scale=256, train_wall=20, gb_free=15.3, wall=42596
2023-01-09 15:27:49 - progress_bar.py[line:272] - INFO: epoch 005:    512 / 3665 loss=5.169, loss_v1=0, loss_v2=0, nll_loss=4.271, ntokens=847.5, nsentences=32, sample_size=847.5, sample_size_v1=0, sample_size_v2=0, ppl=19.3, wps=426.1, ups=0.5, wpb=847.5, bsz=32, num_updates=15150, lr=3.12037e-05, gnorm=2.156, clip=100, loss_scale=256, train_wall=20, gb_free=15.5, wall=42616
2023-01-09 15:28:09 - progress_bar.py[line:272] - INFO: epoch 005:    522 / 3665 loss=5.178, loss_v1=0, loss_v2=0, nll_loss=4.282, ntokens=960.3, nsentences=32, sample_size=960.3, sample_size_v1=0, sample_size_v2=0, ppl=19.45, wps=481.2, ups=0.5, wpb=960.3, bsz=32, num_updates=15160, lr=3.11892e-05, gnorm=2.055, clip=100, loss_scale=256, train_wall=20, gb_free=15.6, wall=42636
2023-01-09 15:28:29 - progress_bar.py[line:272] - INFO: epoch 005:    532 / 3665 loss=5.169, loss_v1=0, loss_v2=0, nll_loss=4.27, ntokens=1005.3, nsentences=32, sample_size=1005.3, sample_size_v1=0, sample_size_v2=0, ppl=19.29, wps=503, ups=0.5, wpb=1005.3, bsz=32, num_updates=15170, lr=3.11747e-05, gnorm=2.07, clip=100, loss_scale=256, train_wall=20, gb_free=14.9, wall=42656
2023-01-09 15:28:49 - progress_bar.py[line:272] - INFO: epoch 005:    542 / 3665 loss=5.17, loss_v1=0, loss_v2=0, nll_loss=4.267, ntokens=781.5, nsentences=32, sample_size=781.5, sample_size_v1=0, sample_size_v2=0, ppl=19.26, wps=393.5, ups=0.5, wpb=781.5, bsz=32, num_updates=15180, lr=3.11602e-05, gnorm=2.295, clip=100, loss_scale=256, train_wall=20, gb_free=14.9, wall=42675
2023-01-09 15:29:09 - progress_bar.py[line:272] - INFO: epoch 005:    552 / 3665 loss=5.127, loss_v1=0, loss_v2=0, nll_loss=4.224, ntokens=963.6, nsentences=32, sample_size=963.6, sample_size_v1=0, sample_size_v2=0, ppl=18.69, wps=483.9, ups=0.5, wpb=963.6, bsz=32, num_updates=15190, lr=3.11457e-05, gnorm=2.025, clip=100, loss_scale=256, train_wall=20, gb_free=15.4, wall=42695
2023-01-09 15:29:29 - progress_bar.py[line:272] - INFO: epoch 005:    562 / 3665 loss=5.195, loss_v1=0, loss_v2=0, nll_loss=4.303, ntokens=1009.3, nsentences=32, sample_size=1009.3, sample_size_v1=0, sample_size_v2=0, ppl=19.74, wps=507.4, ups=0.5, wpb=1009.3, bsz=32, num_updates=15200, lr=3.11312e-05, gnorm=1.944, clip=100, loss_scale=256, train_wall=20, gb_free=15.3, wall=42715
2023-01-09 15:29:49 - progress_bar.py[line:272] - INFO: epoch 005:    572 / 3665 loss=5.064, loss_v1=0, loss_v2=0, nll_loss=4.152, ntokens=774.9, nsentences=32, sample_size=774.9, sample_size_v1=0, sample_size_v2=0, ppl=17.78, wps=390.4, ups=0.5, wpb=774.9, bsz=32, num_updates=15210, lr=3.11167e-05, gnorm=2.464, clip=100, loss_scale=512, train_wall=20, gb_free=15.1, wall=42735
2023-01-09 15:30:09 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 256.0
2023-01-09 15:30:11 - progress_bar.py[line:272] - INFO: epoch 005:    583 / 3665 loss=5.064, loss_v1=0, loss_v2=0, nll_loss=4.152, ntokens=956.4, nsentences=32, sample_size=956.4, sample_size_v1=0, sample_size_v2=0, ppl=17.78, wps=438.4, ups=0.46, wpb=956.4, bsz=32, num_updates=15220, lr=3.11021e-05, gnorm=1.894, clip=100, loss_scale=256, train_wall=22, gb_free=15.2, wall=42757
2023-01-09 15:30:30 - progress_bar.py[line:272] - INFO: epoch 005:    593 / 3665 loss=5.222, loss_v1=0, loss_v2=0, nll_loss=4.329, ntokens=854.9, nsentences=32, sample_size=854.9, sample_size_v1=0, sample_size_v2=0, ppl=20.11, wps=430.3, ups=0.5, wpb=854.9, bsz=32, num_updates=15230, lr=3.10876e-05, gnorm=2.391, clip=100, loss_scale=256, train_wall=20, gb_free=15.7, wall=42777
2023-01-09 15:30:50 - progress_bar.py[line:272] - INFO: epoch 005:    603 / 3665 loss=5.156, loss_v1=0, loss_v2=0, nll_loss=4.256, ntokens=968.2, nsentences=32, sample_size=968.2, sample_size_v1=0, sample_size_v2=0, ppl=19.11, wps=487.8, ups=0.5, wpb=968.2, bsz=32, num_updates=15240, lr=3.10731e-05, gnorm=2.13, clip=100, loss_scale=256, train_wall=20, gb_free=15.6, wall=42797
2023-01-09 15:31:10 - progress_bar.py[line:272] - INFO: epoch 005:    613 / 3665 loss=5.206, loss_v1=0, loss_v2=0, nll_loss=4.311, ntokens=1065.7, nsentences=32, sample_size=1065.7, sample_size_v1=0, sample_size_v2=0, ppl=19.85, wps=539.3, ups=0.51, wpb=1065.7, bsz=32, num_updates=15250, lr=3.10586e-05, gnorm=1.972, clip=100, loss_scale=256, train_wall=20, gb_free=15.4, wall=42816
2023-01-09 15:31:30 - progress_bar.py[line:272] - INFO: epoch 005:    623 / 3665 loss=5.153, loss_v1=0, loss_v2=0, nll_loss=4.253, ntokens=805.9, nsentences=32, sample_size=805.9, sample_size_v1=0, sample_size_v2=0, ppl=19.07, wps=407.4, ups=0.51, wpb=805.9, bsz=32, num_updates=15260, lr=3.10441e-05, gnorm=2.269, clip=100, loss_scale=256, train_wall=20, gb_free=15.4, wall=42836
2023-01-09 15:31:50 - progress_bar.py[line:272] - INFO: epoch 005:    633 / 3665 loss=5.114, loss_v1=0, loss_v2=0, nll_loss=4.209, ntokens=956.3, nsentences=32, sample_size=956.3, sample_size_v1=0, sample_size_v2=0, ppl=18.49, wps=484, ups=0.51, wpb=956.3, bsz=32, num_updates=15270, lr=3.10296e-05, gnorm=2.126, clip=100, loss_scale=256, train_wall=20, gb_free=15.4, wall=42856
2023-01-09 15:32:09 - progress_bar.py[line:272] - INFO: epoch 005:    643 / 3665 loss=5.269, loss_v1=0, loss_v2=0, nll_loss=4.381, ntokens=1088.1, nsentences=32, sample_size=1088.1, sample_size_v1=0, sample_size_v2=0, ppl=20.84, wps=547.3, ups=0.5, wpb=1088.1, bsz=32, num_updates=15280, lr=3.10151e-05, gnorm=1.982, clip=100, loss_scale=256, train_wall=20, gb_free=15.5, wall=42876
2023-01-09 15:32:29 - progress_bar.py[line:272] - INFO: epoch 005:    653 / 3665 loss=5.12, loss_v1=0, loss_v2=0, nll_loss=4.217, ntokens=761.8, nsentences=32, sample_size=761.8, sample_size_v1=0, sample_size_v2=0, ppl=18.6, wps=385.2, ups=0.51, wpb=761.8, bsz=32, num_updates=15290, lr=3.10006e-05, gnorm=2.506, clip=100, loss_scale=256, train_wall=20, gb_free=15.4, wall=42896
2023-01-09 15:32:49 - progress_bar.py[line:272] - INFO: epoch 005:    663 / 3665 loss=5.124, loss_v1=0, loss_v2=0, nll_loss=4.222, ntokens=999.6, nsentences=32, sample_size=999.6, sample_size_v1=0, sample_size_v2=0, ppl=18.66, wps=505.3, ups=0.51, wpb=999.6, bsz=32, num_updates=15300, lr=3.0986e-05, gnorm=2.068, clip=100, loss_scale=256, train_wall=20, gb_free=15.4, wall=42915
2023-01-09 15:33:09 - progress_bar.py[line:272] - INFO: epoch 005:    673 / 3665 loss=5.26, loss_v1=0, loss_v2=0, nll_loss=4.37, ntokens=936.1, nsentences=32, sample_size=936.1, sample_size_v1=0, sample_size_v2=0, ppl=20.67, wps=472.4, ups=0.5, wpb=936.1, bsz=32, num_updates=15310, lr=3.09715e-05, gnorm=2.057, clip=100, loss_scale=256, train_wall=20, gb_free=15.4, wall=42935
2023-01-09 15:33:29 - progress_bar.py[line:272] - INFO: epoch 005:    683 / 3665 loss=5.098, loss_v1=0, loss_v2=0, nll_loss=4.193, ntokens=855, nsentences=32, sample_size=855, sample_size_v1=0, sample_size_v2=0, ppl=18.29, wps=433.6, ups=0.51, wpb=855, bsz=32, num_updates=15320, lr=3.0957e-05, gnorm=2.366, clip=100, loss_scale=256, train_wall=20, gb_free=15.4, wall=42955
2023-01-09 15:33:48 - progress_bar.py[line:272] - INFO: epoch 005:    693 / 3665 loss=5.032, loss_v1=0, loss_v2=0, nll_loss=4.118, ntokens=878.5, nsentences=32, sample_size=878.5, sample_size_v1=0, sample_size_v2=0, ppl=17.36, wps=443.8, ups=0.51, wpb=878.5, bsz=32, num_updates=15330, lr=3.09425e-05, gnorm=2.123, clip=100, loss_scale=256, train_wall=20, gb_free=15.6, wall=42975
2023-01-09 15:34:08 - progress_bar.py[line:272] - INFO: epoch 005:    703 / 3665 loss=5.249, loss_v1=0, loss_v2=0, nll_loss=4.36, ntokens=1020.8, nsentences=32, sample_size=1020.8, sample_size_v1=0, sample_size_v2=0, ppl=20.53, wps=513.6, ups=0.5, wpb=1020.8, bsz=32, num_updates=15340, lr=3.0928e-05, gnorm=2.085, clip=100, loss_scale=256, train_wall=20, gb_free=15.3, wall=42995
2023-01-09 15:34:28 - progress_bar.py[line:272] - INFO: epoch 005:    713 / 3665 loss=5.191, loss_v1=0, loss_v2=0, nll_loss=4.296, ntokens=886.7, nsentences=32, sample_size=886.7, sample_size_v1=0, sample_size_v2=0, ppl=19.64, wps=449.6, ups=0.51, wpb=886.7, bsz=32, num_updates=15350, lr=3.09135e-05, gnorm=2.224, clip=100, loss_scale=256, train_wall=20, gb_free=15.3, wall=43014
2023-01-09 15:34:48 - progress_bar.py[line:272] - INFO: epoch 005:    723 / 3665 loss=5.194, loss_v1=0, loss_v2=0, nll_loss=4.296, ntokens=1171.6, nsentences=32, sample_size=1171.6, sample_size_v1=0, sample_size_v2=0, ppl=19.65, wps=585.1, ups=0.5, wpb=1171.6, bsz=32, num_updates=15360, lr=3.0899e-05, gnorm=1.944, clip=100, loss_scale=256, train_wall=20, gb_free=14.9, wall=43034
2023-01-09 15:35:08 - progress_bar.py[line:272] - INFO: epoch 005:    733 / 3665 loss=5.182, loss_v1=0, loss_v2=0, nll_loss=4.285, ntokens=715, nsentences=32, sample_size=715, sample_size_v1=0, sample_size_v2=0, ppl=19.49, wps=363.6, ups=0.51, wpb=715, bsz=32, num_updates=15370, lr=3.08844e-05, gnorm=2.51, clip=100, loss_scale=256, train_wall=20, gb_free=15, wall=43054
2023-01-09 15:35:27 - progress_bar.py[line:272] - INFO: epoch 005:    743 / 3665 loss=5.086, loss_v1=0, loss_v2=0, nll_loss=4.18, ntokens=877.2, nsentences=32, sample_size=877.2, sample_size_v1=0, sample_size_v2=0, ppl=18.12, wps=442.2, ups=0.5, wpb=877.2, bsz=32, num_updates=15380, lr=3.08699e-05, gnorm=2.203, clip=100, loss_scale=256, train_wall=20, gb_free=15.3, wall=43074
2023-01-09 15:35:47 - progress_bar.py[line:272] - INFO: epoch 005:    753 / 3665 loss=5.234, loss_v1=0, loss_v2=0, nll_loss=4.344, ntokens=1037.2, nsentences=32, sample_size=1037.2, sample_size_v1=0, sample_size_v2=0, ppl=20.3, wps=522.6, ups=0.5, wpb=1037.2, bsz=32, num_updates=15390, lr=3.08554e-05, gnorm=2.027, clip=100, loss_scale=256, train_wall=20, gb_free=15.4, wall=43094
2023-01-09 15:36:07 - progress_bar.py[line:272] - INFO: epoch 005:    763 / 3665 loss=5.147, loss_v1=0, loss_v2=0, nll_loss=4.245, ntokens=847.7, nsentences=32, sample_size=847.7, sample_size_v1=0, sample_size_v2=0, ppl=18.96, wps=430, ups=0.51, wpb=847.7, bsz=32, num_updates=15400, lr=3.08409e-05, gnorm=2.21, clip=100, loss_scale=256, train_wall=20, gb_free=15.1, wall=43113
2023-01-09 15:36:27 - progress_bar.py[line:272] - INFO: epoch 005:    773 / 3665 loss=5.093, loss_v1=0, loss_v2=0, nll_loss=4.186, ntokens=941.9, nsentences=32, sample_size=941.9, sample_size_v1=0, sample_size_v2=0, ppl=18.2, wps=475.1, ups=0.5, wpb=941.9, bsz=32, num_updates=15410, lr=3.08264e-05, gnorm=2.297, clip=100, loss_scale=256, train_wall=20, gb_free=15.3, wall=43133
2023-01-09 15:36:47 - progress_bar.py[line:272] - INFO: epoch 005:    783 / 3665 loss=5.207, loss_v1=0, loss_v2=0, nll_loss=4.313, ntokens=957.3, nsentences=32, sample_size=957.3, sample_size_v1=0, sample_size_v2=0, ppl=19.88, wps=481.2, ups=0.5, wpb=957.3, bsz=32, num_updates=15420, lr=3.08119e-05, gnorm=2.072, clip=100, loss_scale=256, train_wall=20, gb_free=15.3, wall=43153
2023-01-09 15:37:06 - progress_bar.py[line:272] - INFO: epoch 005:    793 / 3665 loss=5.083, loss_v1=0, loss_v2=0, nll_loss=4.174, ntokens=843.2, nsentences=32, sample_size=843.2, sample_size_v1=0, sample_size_v2=0, ppl=18.05, wps=428, ups=0.51, wpb=843.2, bsz=32, num_updates=15430, lr=3.07974e-05, gnorm=2.312, clip=100, loss_scale=256, train_wall=20, gb_free=14.9, wall=43173
2023-01-09 15:37:26 - progress_bar.py[line:272] - INFO: epoch 005:    803 / 3665 loss=5.171, loss_v1=0, loss_v2=0, nll_loss=4.272, ntokens=1081.8, nsentences=32, sample_size=1081.8, sample_size_v1=0, sample_size_v2=0, ppl=19.32, wps=543.2, ups=0.5, wpb=1081.8, bsz=32, num_updates=15440, lr=3.07829e-05, gnorm=1.951, clip=100, loss_scale=256, train_wall=20, gb_free=15.4, wall=43193
2023-01-09 15:37:46 - progress_bar.py[line:272] - INFO: epoch 005:    813 / 3665 loss=5.134, loss_v1=0, loss_v2=0, nll_loss=4.231, ntokens=836.2, nsentences=32, sample_size=836.2, sample_size_v1=0, sample_size_v2=0, ppl=18.78, wps=424.7, ups=0.51, wpb=836.2, bsz=32, num_updates=15450, lr=3.07683e-05, gnorm=2.277, clip=100, loss_scale=256, train_wall=20, gb_free=15.5, wall=43212
2023-01-09 15:38:06 - progress_bar.py[line:272] - INFO: epoch 005:    823 / 3665 loss=5.1, loss_v1=0, loss_v2=0, nll_loss=4.193, ntokens=831.9, nsentences=32, sample_size=831.9, sample_size_v1=0, sample_size_v2=0, ppl=18.3, wps=422.3, ups=0.51, wpb=831.9, bsz=32, num_updates=15460, lr=3.07538e-05, gnorm=2.34, clip=100, loss_scale=256, train_wall=20, gb_free=15.4, wall=43232
2023-01-09 15:38:26 - progress_bar.py[line:272] - INFO: epoch 005:    833 / 3665 loss=5.083, loss_v1=0, loss_v2=0, nll_loss=4.175, ntokens=967.8, nsentences=32, sample_size=967.8, sample_size_v1=0, sample_size_v2=0, ppl=18.06, wps=489.1, ups=0.51, wpb=967.8, bsz=32, num_updates=15470, lr=3.07393e-05, gnorm=2.078, clip=100, loss_scale=256, train_wall=20, gb_free=15.3, wall=43252
2023-01-09 15:38:45 - progress_bar.py[line:272] - INFO: epoch 005:    843 / 3665 loss=5.188, loss_v1=0, loss_v2=0, nll_loss=4.293, ntokens=754.4, nsentences=32, sample_size=754.4, sample_size_v1=0, sample_size_v2=0, ppl=19.6, wps=382.5, ups=0.51, wpb=754.4, bsz=32, num_updates=15480, lr=3.07248e-05, gnorm=2.41, clip=100, loss_scale=256, train_wall=20, gb_free=15.6, wall=43272
2023-01-09 15:39:05 - progress_bar.py[line:272] - INFO: epoch 005:    853 / 3665 loss=5.048, loss_v1=0, loss_v2=0, nll_loss=4.135, ntokens=853.3, nsentences=32, sample_size=853.3, sample_size_v1=0, sample_size_v2=0, ppl=17.57, wps=429.4, ups=0.5, wpb=853.3, bsz=32, num_updates=15490, lr=3.07103e-05, gnorm=2.324, clip=100, loss_scale=256, train_wall=20, gb_free=15.5, wall=43291
2023-01-09 15:39:25 - progress_bar.py[line:272] - INFO: epoch 005:    863 / 3665 loss=5.193, loss_v1=0, loss_v2=0, nll_loss=4.296, ntokens=1183.8, nsentences=32, sample_size=1183.8, sample_size_v1=0, sample_size_v2=0, ppl=19.64, wps=591.3, ups=0.5, wpb=1183.8, bsz=32, num_updates=15500, lr=3.06958e-05, gnorm=1.847, clip=100, loss_scale=256, train_wall=20, gb_free=15.2, wall=43311
2023-01-09 15:39:25 - train.py[line:445] - INFO: begin validation on "valid" subset
slice_id 0 seek offset 0
slice_id 0 seek offset 0
2023-01-09 15:44:30 - progress_bar.py[line:282] - INFO: epoch 005 | valid on 'valid' subset | loss 5.136 | loss_v1 0 | loss_v2 0 | nll_loss 4.217 | ntokens 116.604 | nsentences 4 | sample_size 116.604 | sample_size_v1 0 | sample_size_v2 0 | AP 0 | total positives 21.6357 | TP 0 | FP 5.29241 | ppl 18.6 | wps 477.1 | wpb 116.6 | bsz 4 | num_updates 15500 | best_AP 0
2023-01-09 15:44:30 - checkpoint_utils.py[line:64] - INFO: Preparing to save checkpoint for epoch 5 @ 15500 updates
2023-01-09 15:44:30 - trainer.py[line:431] - INFO: Saving checkpoint to ../../checkpoints/OFA/detection_checkpoints/10_5e-5_512/checkpoint_5_15500.pt
2023-01-09 15:44:34 - trainer.py[line:441] - INFO: Finished saving checkpoint to ../../checkpoints/OFA/detection_checkpoints/10_5e-5_512/checkpoint_5_15500.pt
2023-01-09 15:45:49 - checkpoint_utils.py[line:133] - INFO: Saved checkpoint ../../checkpoints/OFA/detection_checkpoints/10_5e-5_512/checkpoint_5_15500.pt (epoch 5 @ 15500 updates, score 0.0) (writing took 78.66433993307874 seconds)
2023-01-09 15:46:09 - progress_bar.py[line:272] - INFO: epoch 005:    873 / 3665 loss=5.16, loss_v1=0, loss_v2=0, nll_loss=4.261, ntokens=829.7, nsentences=32, sample_size=829.7, sample_size_v1=0, sample_size_v2=0, ppl=19.18, wps=20.6, ups=0.02, wpb=829.7, bsz=32, num_updates=15510, lr=3.06813e-05, gnorm=2.175, clip=100, loss_scale=256, train_wall=20, gb_free=15.5, wall=43715
2023-01-09 15:46:29 - progress_bar.py[line:272] - INFO: epoch 005:    883 / 3665 loss=5.03, loss_v1=0, loss_v2=0, nll_loss=4.116, ntokens=883.3, nsentences=32, sample_size=883.3, sample_size_v1=0, sample_size_v2=0, ppl=17.33, wps=440.1, ups=0.5, wpb=883.3, bsz=32, num_updates=15520, lr=3.06667e-05, gnorm=2.286, clip=100, loss_scale=256, train_wall=20, gb_free=14.9, wall=43735
2023-01-09 15:46:49 - progress_bar.py[line:272] - INFO: epoch 005:    893 / 3665 loss=5.194, loss_v1=0, loss_v2=0, nll_loss=4.298, ntokens=1081.1, nsentences=32, sample_size=1081.1, sample_size_v1=0, sample_size_v2=0, ppl=19.67, wps=531.3, ups=0.49, wpb=1081.1, bsz=32, num_updates=15530, lr=3.06522e-05, gnorm=1.901, clip=100, loss_scale=256, train_wall=20, gb_free=15.2, wall=43755
2023-01-09 15:47:14 - progress_bar.py[line:272] - INFO: epoch 005:    903 / 3665 loss=5.164, loss_v1=0, loss_v2=0, nll_loss=4.265, ntokens=933.2, nsentences=32, sample_size=933.2, sample_size_v1=0, sample_size_v2=0, ppl=19.22, wps=370.2, ups=0.4, wpb=933.2, bsz=32, num_updates=15540, lr=3.06377e-05, gnorm=2.021, clip=100, loss_scale=256, train_wall=25, gb_free=15.6, wall=43780
2023-01-09 15:47:43 - progress_bar.py[line:272] - INFO: epoch 005:    913 / 3665 loss=5.098, loss_v1=0, loss_v2=0, nll_loss=4.192, ntokens=1015.8, nsentences=32, sample_size=1015.8, sample_size_v1=0, sample_size_v2=0, ppl=18.27, wps=353.1, ups=0.35, wpb=1015.8, bsz=32, num_updates=15550, lr=3.06232e-05, gnorm=1.927, clip=100, loss_scale=256, train_wall=29, gb_free=15.3, wall=43809
2023-01-09 15:48:11 - progress_bar.py[line:272] - INFO: epoch 005:    923 / 3665 loss=5.205, loss_v1=0, loss_v2=0, nll_loss=4.31, ntokens=967.1, nsentences=32, sample_size=967.1, sample_size_v1=0, sample_size_v2=0, ppl=19.83, wps=341.6, ups=0.35, wpb=967.1, bsz=32, num_updates=15560, lr=3.06087e-05, gnorm=2.071, clip=100, loss_scale=256, train_wall=28, gb_free=15.3, wall=43838
2023-01-09 15:48:37 - progress_bar.py[line:272] - INFO: epoch 005:    933 / 3665 loss=5.159, loss_v1=0, loss_v2=0, nll_loss=4.26, ntokens=856.1, nsentences=32, sample_size=856.1, sample_size_v1=0, sample_size_v2=0, ppl=19.16, wps=331, ups=0.39, wpb=856.1, bsz=32, num_updates=15570, lr=3.05942e-05, gnorm=2.173, clip=100, loss_scale=256, train_wall=26, gb_free=15.4, wall=43863
2023-01-09 15:49:01 - progress_bar.py[line:272] - INFO: epoch 005:    943 / 3665 loss=5.106, loss_v1=0, loss_v2=0, nll_loss=4.201, ntokens=968.2, nsentences=32, sample_size=968.2, sample_size_v1=0, sample_size_v2=0, ppl=18.39, wps=403.4, ups=0.42, wpb=968.2, bsz=32, num_updates=15580, lr=3.05797e-05, gnorm=2.061, clip=100, loss_scale=256, train_wall=24, gb_free=15.4, wall=43887
2023-01-09 15:49:25 - progress_bar.py[line:272] - INFO: epoch 005:    953 / 3665 loss=5.124, loss_v1=0, loss_v2=0, nll_loss=4.22, ntokens=835.2, nsentences=32, sample_size=835.2, sample_size_v1=0, sample_size_v2=0, ppl=18.64, wps=353.6, ups=0.42, wpb=835.2, bsz=32, num_updates=15590, lr=3.05652e-05, gnorm=2.329, clip=100, loss_scale=256, train_wall=24, gb_free=15.6, wall=43911
2023-01-09 15:49:47 - progress_bar.py[line:272] - INFO: epoch 005:    963 / 3665 loss=5.097, loss_v1=0, loss_v2=0, nll_loss=4.187, ntokens=899.1, nsentences=32, sample_size=899.1, sample_size_v1=0, sample_size_v2=0, ppl=18.21, wps=400.2, ups=0.45, wpb=899.1, bsz=32, num_updates=15600, lr=3.05506e-05, gnorm=2.238, clip=100, loss_scale=256, train_wall=22, gb_free=15.6, wall=43933
2023-01-09 15:50:10 - progress_bar.py[line:272] - INFO: epoch 005:    973 / 3665 loss=5.132, loss_v1=0, loss_v2=0, nll_loss=4.23, ntokens=932.9, nsentences=32, sample_size=932.9, sample_size_v1=0, sample_size_v2=0, ppl=18.77, wps=416.9, ups=0.45, wpb=932.9, bsz=32, num_updates=15610, lr=3.05361e-05, gnorm=2.092, clip=100, loss_scale=256, train_wall=22, gb_free=14.9, wall=43956
2023-01-09 15:50:32 - progress_bar.py[line:272] - INFO: epoch 005:    983 / 3665 loss=5.168, loss_v1=0, loss_v2=0, nll_loss=4.27, ntokens=809.7, nsentences=32, sample_size=809.7, sample_size_v1=0, sample_size_v2=0, ppl=19.29, wps=359.3, ups=0.44, wpb=809.7, bsz=32, num_updates=15620, lr=3.05216e-05, gnorm=2.227, clip=100, loss_scale=256, train_wall=23, gb_free=15.7, wall=43978
2023-01-09 15:50:55 - progress_bar.py[line:272] - INFO: epoch 005:    993 / 3665 loss=5.134, loss_v1=0, loss_v2=0, nll_loss=4.232, ntokens=929.8, nsentences=32, sample_size=929.8, sample_size_v1=0, sample_size_v2=0, ppl=18.79, wps=411.1, ups=0.44, wpb=929.8, bsz=32, num_updates=15630, lr=3.05071e-05, gnorm=2.104, clip=100, loss_scale=256, train_wall=23, gb_free=15.3, wall=44001
2023-01-09 15:51:17 - progress_bar.py[line:272] - INFO: epoch 005:   1003 / 3665 loss=5.211, loss_v1=0, loss_v2=0, nll_loss=4.316, ntokens=1071.9, nsentences=32, sample_size=1071.9, sample_size_v1=0, sample_size_v2=0, ppl=19.92, wps=471.5, ups=0.44, wpb=1071.9, bsz=32, num_updates=15640, lr=3.04926e-05, gnorm=1.791, clip=100, loss_scale=256, train_wall=23, gb_free=15.6, wall=44024
2023-01-09 15:51:40 - progress_bar.py[line:272] - INFO: epoch 005:   1013 / 3665 loss=5.111, loss_v1=0, loss_v2=0, nll_loss=4.207, ntokens=802.4, nsentences=32, sample_size=802.4, sample_size_v1=0, sample_size_v2=0, ppl=18.46, wps=358.2, ups=0.45, wpb=802.4, bsz=32, num_updates=15650, lr=3.04781e-05, gnorm=2.358, clip=100, loss_scale=256, train_wall=22, gb_free=15.4, wall=44046
2023-01-09 15:52:04 - progress_bar.py[line:272] - INFO: epoch 005:   1023 / 3665 loss=5.079, loss_v1=0, loss_v2=0, nll_loss=4.17, ntokens=949.7, nsentences=32, sample_size=949.7, sample_size_v1=0, sample_size_v2=0, ppl=18, wps=391.7, ups=0.41, wpb=949.7, bsz=32, num_updates=15660, lr=3.04636e-05, gnorm=1.997, clip=100, loss_scale=256, train_wall=24, gb_free=15.1, wall=44070
2023-01-09 15:52:28 - progress_bar.py[line:272] - INFO: epoch 005:   1033 / 3665 loss=5.232, loss_v1=0, loss_v2=0, nll_loss=4.342, ntokens=980.7, nsentences=32, sample_size=980.7, sample_size_v1=0, sample_size_v2=0, ppl=20.28, wps=408.7, ups=0.42, wpb=980.7, bsz=32, num_updates=15670, lr=3.0449e-05, gnorm=2.073, clip=100, loss_scale=256, train_wall=24, gb_free=15.6, wall=44094
2023-01-09 15:52:51 - progress_bar.py[line:272] - INFO: epoch 005:   1043 / 3665 loss=4.963, loss_v1=0, loss_v2=0, nll_loss=4.038, ntokens=586.9, nsentences=32, sample_size=586.9, sample_size_v1=0, sample_size_v2=0, ppl=16.42, wps=256.1, ups=0.44, wpb=586.9, bsz=32, num_updates=15680, lr=3.04345e-05, gnorm=2.826, clip=100, loss_scale=256, train_wall=23, gb_free=15.4, wall=44117
2023-01-09 15:53:12 - progress_bar.py[line:272] - INFO: epoch 005:   1053 / 3665 loss=5.116, loss_v1=0, loss_v2=0, nll_loss=4.212, ntokens=932.9, nsentences=32, sample_size=932.9, sample_size_v1=0, sample_size_v2=0, ppl=18.53, wps=450.7, ups=0.48, wpb=932.9, bsz=32, num_updates=15690, lr=3.042e-05, gnorm=2.054, clip=100, loss_scale=256, train_wall=21, gb_free=15.3, wall=44138
2023-01-09 15:53:32 - progress_bar.py[line:272] - INFO: epoch 005:   1063 / 3665 loss=5.22, loss_v1=0, loss_v2=0, nll_loss=4.328, ntokens=980.9, nsentences=32, sample_size=980.9, sample_size_v1=0, sample_size_v2=0, ppl=20.09, wps=483.5, ups=0.49, wpb=980.9, bsz=32, num_updates=15700, lr=3.04055e-05, gnorm=1.986, clip=100, loss_scale=256, train_wall=20, gb_free=15.3, wall=44158
2023-01-09 15:53:52 - progress_bar.py[line:272] - INFO: epoch 005:   1073 / 3665 loss=5.035, loss_v1=0, loss_v2=0, nll_loss=4.121, ntokens=721.9, nsentences=32, sample_size=721.9, sample_size_v1=0, sample_size_v2=0, ppl=17.4, wps=356, ups=0.49, wpb=721.9, bsz=32, num_updates=15710, lr=3.0391e-05, gnorm=2.589, clip=100, loss_scale=256, train_wall=20, gb_free=15.5, wall=44179
2023-01-09 15:54:13 - progress_bar.py[line:272] - INFO: epoch 005:   1083 / 3665 loss=5.155, loss_v1=0, loss_v2=0, nll_loss=4.256, ntokens=1078.7, nsentences=32, sample_size=1078.7, sample_size_v1=0, sample_size_v2=0, ppl=19.1, wps=527.9, ups=0.49, wpb=1078.7, bsz=32, num_updates=15720, lr=3.03765e-05, gnorm=1.922, clip=100, loss_scale=256, train_wall=20, gb_free=15.5, wall=44199
2023-01-09 15:54:33 - progress_bar.py[line:272] - INFO: epoch 005:   1093 / 3665 loss=5.099, loss_v1=0, loss_v2=0, nll_loss=4.195, ntokens=820.7, nsentences=32, sample_size=820.7, sample_size_v1=0, sample_size_v2=0, ppl=18.31, wps=404.6, ups=0.49, wpb=820.7, bsz=32, num_updates=15730, lr=3.0362e-05, gnorm=2.384, clip=100, loss_scale=256, train_wall=20, gb_free=15.7, wall=44219
2023-01-09 15:54:57 - progress_bar.py[line:272] - INFO: epoch 005:   1103 / 3665 loss=5.231, loss_v1=0, loss_v2=0, nll_loss=4.337, ntokens=989.9, nsentences=32, sample_size=989.9, sample_size_v1=0, sample_size_v2=0, ppl=20.2, wps=416.9, ups=0.42, wpb=989.9, bsz=32, num_updates=15740, lr=3.03475e-05, gnorm=2.101, clip=100, loss_scale=512, train_wall=24, gb_free=15.7, wall=44243
2023-01-09 15:55:00 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 256.0
2023-01-09 15:55:26 - progress_bar.py[line:272] - INFO: epoch 005:   1114 / 3665 loss=5.095, loss_v1=0, loss_v2=0, nll_loss=4.187, ntokens=857.6, nsentences=32, sample_size=857.6, sample_size_v1=0, sample_size_v2=0, ppl=18.21, wps=290.4, ups=0.34, wpb=857.6, bsz=32, num_updates=15750, lr=3.03329e-05, gnorm=2.246, clip=100, loss_scale=256, train_wall=30, gb_free=15.4, wall=44273
2023-01-09 15:55:48 - progress_bar.py[line:272] - INFO: epoch 005:   1124 / 3665 loss=5.094, loss_v1=0, loss_v2=0, nll_loss=4.189, ntokens=1136.6, nsentences=32, sample_size=1136.6, sample_size_v1=0, sample_size_v2=0, ppl=18.24, wps=512.9, ups=0.45, wpb=1136.6, bsz=32, num_updates=15760, lr=3.03184e-05, gnorm=1.764, clip=100, loss_scale=256, train_wall=22, gb_free=15.4, wall=44295
2023-01-09 15:56:09 - progress_bar.py[line:272] - INFO: epoch 005:   1134 / 3665 loss=5.185, loss_v1=0, loss_v2=0, nll_loss=4.29, ntokens=1050.3, nsentences=32, sample_size=1050.3, sample_size_v1=0, sample_size_v2=0, ppl=19.56, wps=502.9, ups=0.48, wpb=1050.3, bsz=32, num_updates=15770, lr=3.03039e-05, gnorm=2.041, clip=100, loss_scale=256, train_wall=21, gb_free=15.3, wall=44316
2023-01-09 15:56:29 - progress_bar.py[line:272] - INFO: epoch 005:   1144 / 3665 loss=5.043, loss_v1=0, loss_v2=0, nll_loss=4.128, ntokens=671.5, nsentences=32, sample_size=671.5, sample_size_v1=0, sample_size_v2=0, ppl=17.48, wps=333.1, ups=0.5, wpb=671.5, bsz=32, num_updates=15780, lr=3.02894e-05, gnorm=2.397, clip=100, loss_scale=256, train_wall=20, gb_free=15.6, wall=44336
2023-01-09 15:56:50 - progress_bar.py[line:272] - INFO: epoch 005:   1154 / 3665 loss=5.089, loss_v1=0, loss_v2=0, nll_loss=4.18, ntokens=889.3, nsentences=32, sample_size=889.3, sample_size_v1=0, sample_size_v2=0, ppl=18.13, wps=435.5, ups=0.49, wpb=889.3, bsz=32, num_updates=15790, lr=3.02749e-05, gnorm=2.188, clip=100, loss_scale=256, train_wall=20, gb_free=15.7, wall=44356
2023-01-09 15:57:15 - progress_bar.py[line:272] - INFO: epoch 005:   1164 / 3665 loss=5.125, loss_v1=0, loss_v2=0, nll_loss=4.222, ntokens=1067, nsentences=32, sample_size=1067, sample_size_v1=0, sample_size_v2=0, ppl=18.66, wps=428.1, ups=0.4, wpb=1067, bsz=32, num_updates=15800, lr=3.02604e-05, gnorm=1.821, clip=100, loss_scale=256, train_wall=25, gb_free=15.2, wall=44381
2023-01-09 15:57:41 - progress_bar.py[line:272] - INFO: epoch 005:   1174 / 3665 loss=5.07, loss_v1=0, loss_v2=0, nll_loss=4.16, ntokens=676.3, nsentences=32, sample_size=676.3, sample_size_v1=0, sample_size_v2=0, ppl=17.87, wps=255.8, ups=0.38, wpb=676.3, bsz=32, num_updates=15810, lr=3.02459e-05, gnorm=2.83, clip=100, loss_scale=256, train_wall=26, gb_free=15.7, wall=44408
2023-01-09 15:58:04 - progress_bar.py[line:272] - INFO: epoch 005:   1184 / 3665 loss=5.14, loss_v1=0, loss_v2=0, nll_loss=4.238, ntokens=1008.9, nsentences=32, sample_size=1008.9, sample_size_v1=0, sample_size_v2=0, ppl=18.86, wps=444.3, ups=0.44, wpb=1008.9, bsz=32, num_updates=15820, lr=3.02313e-05, gnorm=2.083, clip=100, loss_scale=256, train_wall=23, gb_free=14.6, wall=44430
2023-01-09 15:58:25 - progress_bar.py[line:272] - INFO: epoch 005:   1194 / 3665 loss=5.133, loss_v1=0, loss_v2=0, nll_loss=4.232, ntokens=1109.6, nsentences=32, sample_size=1109.6, sample_size_v1=0, sample_size_v2=0, ppl=18.79, wps=520.9, ups=0.47, wpb=1109.6, bsz=32, num_updates=15830, lr=3.02168e-05, gnorm=1.871, clip=100, loss_scale=256, train_wall=21, gb_free=15.5, wall=44452
2023-01-09 15:58:46 - progress_bar.py[line:272] - INFO: epoch 005:   1204 / 3665 loss=5.211, loss_v1=0, loss_v2=0, nll_loss=4.317, ntokens=966.5, nsentences=32, sample_size=966.5, sample_size_v1=0, sample_size_v2=0, ppl=19.94, wps=476.8, ups=0.49, wpb=966.5, bsz=32, num_updates=15840, lr=3.02023e-05, gnorm=2.191, clip=100, loss_scale=256, train_wall=20, gb_free=15.6, wall=44472
2023-01-09 15:59:06 - progress_bar.py[line:272] - INFO: epoch 005:   1214 / 3665 loss=5.142, loss_v1=0, loss_v2=0, nll_loss=4.238, ntokens=806.2, nsentences=32, sample_size=806.2, sample_size_v1=0, sample_size_v2=0, ppl=18.87, wps=400.2, ups=0.5, wpb=806.2, bsz=32, num_updates=15850, lr=3.01878e-05, gnorm=2.41, clip=100, loss_scale=256, train_wall=20, gb_free=15.4, wall=44492
2023-01-09 15:59:26 - progress_bar.py[line:272] - INFO: epoch 005:   1224 / 3665 loss=5.12, loss_v1=0, loss_v2=0, nll_loss=4.215, ntokens=1091.9, nsentences=32, sample_size=1091.9, sample_size_v1=0, sample_size_v2=0, ppl=18.57, wps=537.5, ups=0.49, wpb=1091.9, bsz=32, num_updates=15860, lr=3.01733e-05, gnorm=1.925, clip=100, loss_scale=256, train_wall=20, gb_free=15.1, wall=44512
2023-01-09 15:59:46 - progress_bar.py[line:272] - INFO: epoch 005:   1234 / 3665 loss=5.266, loss_v1=0, loss_v2=0, nll_loss=4.379, ntokens=1053.7, nsentences=32, sample_size=1053.7, sample_size_v1=0, sample_size_v2=0, ppl=20.81, wps=519.6, ups=0.49, wpb=1053.7, bsz=32, num_updates=15870, lr=3.01588e-05, gnorm=1.895, clip=100, loss_scale=256, train_wall=20, gb_free=15.4, wall=44533
2023-01-09 16:00:07 - progress_bar.py[line:272] - INFO: epoch 005:   1244 / 3665 loss=5.176, loss_v1=0, loss_v2=0, nll_loss=4.279, ntokens=936.2, nsentences=32, sample_size=936.2, sample_size_v1=0, sample_size_v2=0, ppl=19.41, wps=463, ups=0.49, wpb=936.2, bsz=32, num_updates=15880, lr=3.01443e-05, gnorm=2.062, clip=100, loss_scale=256, train_wall=20, gb_free=15.3, wall=44553
2023-01-09 16:00:27 - progress_bar.py[line:272] - INFO: epoch 005:   1254 / 3665 loss=5.096, loss_v1=0, loss_v2=0, nll_loss=4.188, ntokens=1045, nsentences=32, sample_size=1045, sample_size_v1=0, sample_size_v2=0, ppl=18.22, wps=519.5, ups=0.5, wpb=1045, bsz=32, num_updates=15890, lr=3.01297e-05, gnorm=1.924, clip=100, loss_scale=256, train_wall=20, gb_free=15.3, wall=44573
2023-01-09 16:00:47 - progress_bar.py[line:272] - INFO: epoch 005:   1264 / 3665 loss=5.166, loss_v1=0, loss_v2=0, nll_loss=4.267, ntokens=919, nsentences=32, sample_size=919, sample_size_v1=0, sample_size_v2=0, ppl=19.26, wps=459.3, ups=0.5, wpb=919, bsz=32, num_updates=15900, lr=3.01152e-05, gnorm=2.156, clip=100, loss_scale=256, train_wall=20, gb_free=15.5, wall=44593
2023-01-09 16:01:06 - progress_bar.py[line:272] - INFO: epoch 005:   1274 / 3665 loss=5.049, loss_v1=0, loss_v2=0, nll_loss=4.137, ntokens=657.7, nsentences=32, sample_size=657.7, sample_size_v1=0, sample_size_v2=0, ppl=17.6, wps=331.6, ups=0.5, wpb=657.7, bsz=32, num_updates=15910, lr=3.01007e-05, gnorm=2.719, clip=100, loss_scale=256, train_wall=20, gb_free=15.6, wall=44613
2023-01-09 16:01:26 - progress_bar.py[line:272] - INFO: epoch 005:   1284 / 3665 loss=5.113, loss_v1=0, loss_v2=0, nll_loss=4.211, ntokens=911.4, nsentences=32, sample_size=911.4, sample_size_v1=0, sample_size_v2=0, ppl=18.52, wps=457.3, ups=0.5, wpb=911.4, bsz=32, num_updates=15920, lr=3.00862e-05, gnorm=2.125, clip=100, loss_scale=256, train_wall=20, gb_free=15.4, wall=44633
2023-01-09 16:01:47 - progress_bar.py[line:272] - INFO: epoch 005:   1294 / 3665 loss=5.189, loss_v1=0, loss_v2=0, nll_loss=4.293, ntokens=1052.4, nsentences=32, sample_size=1052.4, sample_size_v1=0, sample_size_v2=0, ppl=19.61, wps=519.6, ups=0.49, wpb=1052.4, bsz=32, num_updates=15930, lr=3.00717e-05, gnorm=1.904, clip=100, loss_scale=256, train_wall=20, gb_free=15.4, wall=44653
2023-01-09 16:02:07 - progress_bar.py[line:272] - INFO: epoch 005:   1304 / 3665 loss=5.119, loss_v1=0, loss_v2=0, nll_loss=4.214, ntokens=845, nsentences=32, sample_size=845, sample_size_v1=0, sample_size_v2=0, ppl=18.55, wps=422.1, ups=0.5, wpb=845, bsz=32, num_updates=15940, lr=3.00572e-05, gnorm=2.385, clip=100, loss_scale=256, train_wall=20, gb_free=15.1, wall=44673
2023-01-09 16:02:27 - progress_bar.py[line:272] - INFO: epoch 005:   1314 / 3665 loss=5.052, loss_v1=0, loss_v2=0, nll_loss=4.139, ntokens=910.4, nsentences=32, sample_size=910.4, sample_size_v1=0, sample_size_v2=0, ppl=17.62, wps=456.6, ups=0.5, wpb=910.4, bsz=32, num_updates=15950, lr=3.00427e-05, gnorm=2.117, clip=100, loss_scale=256, train_wall=20, gb_free=15.3, wall=44693
2023-01-09 16:02:47 - progress_bar.py[line:272] - INFO: epoch 005:   1324 / 3665 loss=5.165, loss_v1=0, loss_v2=0, nll_loss=4.267, ntokens=1076.1, nsentences=32, sample_size=1076.1, sample_size_v1=0, sample_size_v2=0, ppl=19.25, wps=533.1, ups=0.5, wpb=1076.1, bsz=32, num_updates=15960, lr=3.00282e-05, gnorm=1.933, clip=100, loss_scale=256, train_wall=20, gb_free=15.3, wall=44713
2023-01-09 16:03:08 - progress_bar.py[line:272] - INFO: epoch 005:   1334 / 3665 loss=5.117, loss_v1=0, loss_v2=0, nll_loss=4.213, ntokens=718.2, nsentences=32, sample_size=718.2, sample_size_v1=0, sample_size_v2=0, ppl=18.55, wps=338, ups=0.47, wpb=718.2, bsz=32, num_updates=15970, lr=3.00136e-05, gnorm=2.622, clip=100, loss_scale=256, train_wall=21, gb_free=15.3, wall=44734
2023-01-09 16:03:31 - progress_bar.py[line:272] - INFO: epoch 005:   1344 / 3665 loss=5.06, loss_v1=0, loss_v2=0, nll_loss=4.148, ntokens=939.7, nsentences=32, sample_size=939.7, sample_size_v1=0, sample_size_v2=0, ppl=17.73, wps=415.8, ups=0.44, wpb=939.7, bsz=32, num_updates=15980, lr=2.99991e-05, gnorm=2.068, clip=100, loss_scale=256, train_wall=23, gb_free=15.5, wall=44757
2023-01-09 16:03:54 - progress_bar.py[line:272] - INFO: epoch 005:   1354 / 3665 loss=5.085, loss_v1=0, loss_v2=0, nll_loss=4.178, ntokens=1150.2, nsentences=32, sample_size=1150.2, sample_size_v1=0, sample_size_v2=0, ppl=18.1, wps=500.3, ups=0.43, wpb=1150.2, bsz=32, num_updates=15990, lr=2.99846e-05, gnorm=1.834, clip=100, loss_scale=256, train_wall=23, gb_free=15.3, wall=44780
2023-01-09 16:04:17 - progress_bar.py[line:272] - INFO: epoch 005:   1364 / 3665 loss=5.195, loss_v1=0, loss_v2=0, nll_loss=4.299, ntokens=870, nsentences=32, sample_size=870, sample_size_v1=0, sample_size_v2=0, ppl=19.68, wps=380.7, ups=0.44, wpb=870, bsz=32, num_updates=16000, lr=2.99701e-05, gnorm=2.28, clip=100, loss_scale=256, train_wall=23, gb_free=15.2, wall=44803
2023-01-09 16:04:17 - train.py[line:445] - INFO: begin validation on "valid" subset
slice_id 0 seek offset 0
slice_id 0 seek offset 0
2023-01-09 16:09:29 - progress_bar.py[line:282] - INFO: epoch 005 | valid on 'valid' subset | loss 5.133 | loss_v1 0 | loss_v2 0 | nll_loss 4.213 | ntokens 116.778 | nsentences 4 | sample_size 116.778 | sample_size_v1 0 | sample_size_v2 0 | AP 0 | total positives 21.6696 | TP 0 | FP 4.74313 | ppl 18.54 | wps 466.6 | wpb 116.8 | bsz 4 | num_updates 16000 | best_AP 0
2023-01-09 16:09:29 - checkpoint_utils.py[line:64] - INFO: Preparing to save checkpoint for epoch 5 @ 16000 updates
2023-01-09 16:09:29 - trainer.py[line:431] - INFO: Saving checkpoint to ../../checkpoints/OFA/detection_checkpoints/10_5e-5_512/checkpoint_5_16000.pt
2023-01-09 16:09:32 - trainer.py[line:441] - INFO: Finished saving checkpoint to ../../checkpoints/OFA/detection_checkpoints/10_5e-5_512/checkpoint_5_16000.pt
2023-01-09 16:10:46 - checkpoint_utils.py[line:133] - INFO: Saved checkpoint ../../checkpoints/OFA/detection_checkpoints/10_5e-5_512/checkpoint_5_16000.pt (epoch 5 @ 16000 updates, score 0.0) (writing took 77.89734930824488 seconds)
2023-01-09 16:11:06 - progress_bar.py[line:272] - INFO: epoch 005:   1374 / 3665 loss=5.081, loss_v1=0, loss_v2=0, nll_loss=4.173, ntokens=866.4, nsentences=32, sample_size=866.4, sample_size_v1=0, sample_size_v2=0, ppl=18.04, wps=21.2, ups=0.02, wpb=866.4, bsz=32, num_updates=16010, lr=2.99556e-05, gnorm=2.427, clip=100, loss_scale=256, train_wall=20, gb_free=15.3, wall=45212
2023-01-09 16:11:26 - progress_bar.py[line:272] - INFO: epoch 005:   1384 / 3665 loss=5.045, loss_v1=0, loss_v2=0, nll_loss=4.133, ntokens=883.5, nsentences=32, sample_size=883.5, sample_size_v1=0, sample_size_v2=0, ppl=17.55, wps=436.1, ups=0.49, wpb=883.5, bsz=32, num_updates=16020, lr=2.99411e-05, gnorm=2.1, clip=100, loss_scale=256, train_wall=20, gb_free=15.5, wall=45233
2023-01-09 16:11:47 - progress_bar.py[line:272] - INFO: epoch 005:   1394 / 3665 loss=5.115, loss_v1=0, loss_v2=0, nll_loss=4.21, ntokens=737.9, nsentences=32, sample_size=737.9, sample_size_v1=0, sample_size_v2=0, ppl=18.51, wps=366.6, ups=0.5, wpb=737.9, bsz=32, num_updates=16030, lr=2.99266e-05, gnorm=2.453, clip=100, loss_scale=256, train_wall=20, gb_free=15.6, wall=45253
2023-01-09 16:12:09 - progress_bar.py[line:272] - INFO: epoch 005:   1404 / 3665 loss=5.07, loss_v1=0, loss_v2=0, nll_loss=4.16, ntokens=828.1, nsentences=32, sample_size=828.1, sample_size_v1=0, sample_size_v2=0, ppl=17.87, wps=371.5, ups=0.45, wpb=828.1, bsz=32, num_updates=16040, lr=2.9912e-05, gnorm=2.55, clip=100, loss_scale=256, train_wall=22, gb_free=15.6, wall=45275
2023-01-09 16:12:32 - progress_bar.py[line:272] - INFO: epoch 005:   1414 / 3665 loss=5.048, loss_v1=0, loss_v2=0, nll_loss=4.137, ntokens=945.7, nsentences=32, sample_size=945.7, sample_size_v1=0, sample_size_v2=0, ppl=17.59, wps=402.6, ups=0.43, wpb=945.7, bsz=32, num_updates=16050, lr=2.98975e-05, gnorm=2.247, clip=100, loss_scale=256, train_wall=21, gb_free=15.1, wall=45299
2023-01-09 16:12:53 - progress_bar.py[line:272] - INFO: epoch 005:   1424 / 3665 loss=5.094, loss_v1=0, loss_v2=0, nll_loss=4.186, ntokens=856.7, nsentences=32, sample_size=856.7, sample_size_v1=0, sample_size_v2=0, ppl=18.21, wps=405.9, ups=0.47, wpb=856.7, bsz=32, num_updates=16060, lr=2.9883e-05, gnorm=2.299, clip=100, loss_scale=256, train_wall=21, gb_free=15.4, wall=45320
2023-01-09 16:13:16 - progress_bar.py[line:272] - INFO: epoch 005:   1434 / 3665 loss=5.121, loss_v1=0, loss_v2=0, nll_loss=4.217, ntokens=796.6, nsentences=32, sample_size=796.6, sample_size_v1=0, sample_size_v2=0, ppl=18.59, wps=358, ups=0.45, wpb=796.6, bsz=32, num_updates=16070, lr=2.98685e-05, gnorm=2.607, clip=100, loss_scale=256, train_wall=22, gb_free=15.3, wall=45342
2023-01-09 16:13:38 - progress_bar.py[line:272] - INFO: epoch 005:   1444 / 3665 loss=5.162, loss_v1=0, loss_v2=0, nll_loss=4.265, ntokens=1051, nsentences=32, sample_size=1051, sample_size_v1=0, sample_size_v2=0, ppl=19.23, wps=469.7, ups=0.45, wpb=1051, bsz=32, num_updates=16080, lr=2.9854e-05, gnorm=2.106, clip=100, loss_scale=256, train_wall=22, gb_free=15.3, wall=45364
2023-01-09 16:14:03 - progress_bar.py[line:272] - INFO: epoch 005:   1454 / 3665 loss=5.129, loss_v1=0, loss_v2=0, nll_loss=4.226, ntokens=936, nsentences=32, sample_size=936, sample_size_v1=0, sample_size_v2=0, ppl=18.72, wps=379.6, ups=0.41, wpb=936, bsz=32, num_updates=16090, lr=2.98395e-05, gnorm=2.131, clip=100, loss_scale=256, train_wall=25, gb_free=15.4, wall=45389
2023-01-09 16:14:28 - progress_bar.py[line:272] - INFO: epoch 005:   1464 / 3665 loss=5.033, loss_v1=0, loss_v2=0, nll_loss=4.12, ntokens=697.6, nsentences=32, sample_size=697.6, sample_size_v1=0, sample_size_v2=0, ppl=17.39, wps=277.1, ups=0.4, wpb=697.6, bsz=32, num_updates=16100, lr=2.9825e-05, gnorm=2.624, clip=100, loss_scale=256, train_wall=25, gb_free=15.7, wall=45414
2023-01-09 16:14:53 - progress_bar.py[line:272] - INFO: epoch 005:   1474 / 3665 loss=5.021, loss_v1=0, loss_v2=0, nll_loss=4.103, ntokens=822.4, nsentences=32, sample_size=822.4, sample_size_v1=0, sample_size_v2=0, ppl=17.19, wps=326.9, ups=0.4, wpb=822.4, bsz=32, num_updates=16110, lr=2.98105e-05, gnorm=2.323, clip=100, loss_scale=256, train_wall=25, gb_free=15.5, wall=45439
2023-01-09 16:15:19 - progress_bar.py[line:272] - INFO: epoch 005:   1484 / 3665 loss=5.231, loss_v1=0, loss_v2=0, nll_loss=4.339, ntokens=1120, nsentences=32, sample_size=1120, sample_size_v1=0, sample_size_v2=0, ppl=20.24, wps=437.7, ups=0.39, wpb=1120, bsz=32, num_updates=16120, lr=2.97959e-05, gnorm=1.923, clip=100, loss_scale=256, train_wall=26, gb_free=15.3, wall=45465
2023-01-09 16:15:44 - progress_bar.py[line:272] - INFO: epoch 005:   1494 / 3665 loss=5.085, loss_v1=0, loss_v2=0, nll_loss=4.177, ntokens=712.1, nsentences=32, sample_size=712.1, sample_size_v1=0, sample_size_v2=0, ppl=18.09, wps=285.6, ups=0.4, wpb=712.1, bsz=32, num_updates=16130, lr=2.97814e-05, gnorm=2.751, clip=100, loss_scale=256, train_wall=25, gb_free=14.6, wall=45490
2023-01-09 16:16:07 - progress_bar.py[line:272] - INFO: epoch 005:   1504 / 3665 loss=5.07, loss_v1=0, loss_v2=0, nll_loss=4.161, ntokens=904.4, nsentences=32, sample_size=904.4, sample_size_v1=0, sample_size_v2=0, ppl=17.89, wps=381.5, ups=0.42, wpb=904.4, bsz=32, num_updates=16140, lr=2.97669e-05, gnorm=1.994, clip=100, loss_scale=256, train_wall=20, gb_free=15.4, wall=45514
2023-01-09 16:16:28 - progress_bar.py[line:272] - INFO: epoch 005:   1514 / 3665 loss=5.128, loss_v1=0, loss_v2=0, nll_loss=4.225, ntokens=983.3, nsentences=32, sample_size=983.3, sample_size_v1=0, sample_size_v2=0, ppl=18.7, wps=482.1, ups=0.49, wpb=983.3, bsz=32, num_updates=16150, lr=2.97524e-05, gnorm=2.023, clip=100, loss_scale=256, train_wall=20, gb_free=15.7, wall=45534
2023-01-09 16:16:53 - progress_bar.py[line:272] - INFO: epoch 005:   1524 / 3665 loss=5.144, loss_v1=0, loss_v2=0, nll_loss=4.241, ntokens=844, nsentences=32, sample_size=844, sample_size_v1=0, sample_size_v2=0, ppl=18.91, wps=326.9, ups=0.39, wpb=844, bsz=32, num_updates=16160, lr=2.97379e-05, gnorm=2.292, clip=100, loss_scale=256, train_wall=26, gb_free=15.3, wall=45560
2023-01-09 16:17:19 - progress_bar.py[line:272] - INFO: epoch 005:   1534 / 3665 loss=5.112, loss_v1=0, loss_v2=0, nll_loss=4.205, ntokens=861, nsentences=32, sample_size=861, sample_size_v1=0, sample_size_v2=0, ppl=18.45, wps=343.6, ups=0.4, wpb=861, bsz=32, num_updates=16170, lr=2.97234e-05, gnorm=2.471, clip=100, loss_scale=256, train_wall=25, gb_free=15.5, wall=45585
2023-01-09 16:17:43 - progress_bar.py[line:272] - INFO: epoch 005:   1544 / 3665 loss=5.161, loss_v1=0, loss_v2=0, nll_loss=4.261, ntokens=1030.1, nsentences=32, sample_size=1030.1, sample_size_v1=0, sample_size_v2=0, ppl=19.17, wps=425.2, ups=0.41, wpb=1030.1, bsz=32, num_updates=16180, lr=2.97089e-05, gnorm=1.839, clip=100, loss_scale=256, train_wall=24, gb_free=15.3, wall=45609
2023-01-09 16:18:06 - progress_bar.py[line:272] - INFO: epoch 005:   1554 / 3665 loss=5.233, loss_v1=0, loss_v2=0, nll_loss=4.343, ntokens=881.7, nsentences=32, sample_size=881.7, sample_size_v1=0, sample_size_v2=0, ppl=20.29, wps=387, ups=0.44, wpb=881.7, bsz=32, num_updates=16190, lr=2.96943e-05, gnorm=2.281, clip=100, loss_scale=256, train_wall=23, gb_free=15.5, wall=45632
2023-01-09 16:18:28 - progress_bar.py[line:272] - INFO: epoch 005:   1564 / 3665 loss=5.14, loss_v1=0, loss_v2=0, nll_loss=4.237, ntokens=842.6, nsentences=32, sample_size=842.6, sample_size_v1=0, sample_size_v2=0, ppl=18.86, wps=382.5, ups=0.45, wpb=842.6, bsz=32, num_updates=16200, lr=2.96798e-05, gnorm=2.502, clip=100, loss_scale=256, train_wall=22, gb_free=15.3, wall=45654
2023-01-09 16:18:50 - progress_bar.py[line:272] - INFO: epoch 005:   1574 / 3665 loss=5.128, loss_v1=0, loss_v2=0, nll_loss=4.224, ntokens=1048.8, nsentences=32, sample_size=1048.8, sample_size_v1=0, sample_size_v2=0, ppl=18.69, wps=477.3, ups=0.46, wpb=1048.8, bsz=32, num_updates=16210, lr=2.96653e-05, gnorm=1.968, clip=100, loss_scale=256, train_wall=22, gb_free=15.6, wall=45676
2023-01-09 16:19:12 - progress_bar.py[line:272] - INFO: epoch 005:   1584 / 3665 loss=5.178, loss_v1=0, loss_v2=0, nll_loss=4.281, ntokens=897, nsentences=32, sample_size=897, sample_size_v1=0, sample_size_v2=0, ppl=19.44, wps=407.7, ups=0.45, wpb=897, bsz=32, num_updates=16220, lr=2.96508e-05, gnorm=2.154, clip=100, loss_scale=256, train_wall=22, gb_free=15.5, wall=45698
2023-01-09 16:19:39 - progress_bar.py[line:272] - INFO: epoch 005:   1594 / 3665 loss=5.156, loss_v1=0, loss_v2=0, nll_loss=4.257, ntokens=880.1, nsentences=32, sample_size=880.1, sample_size_v1=0, sample_size_v2=0, ppl=19.12, wps=323.5, ups=0.37, wpb=880.1, bsz=32, num_updates=16230, lr=2.96363e-05, gnorm=2.423, clip=100, loss_scale=256, train_wall=27, gb_free=15.4, wall=45725
2023-01-09 16:20:06 - progress_bar.py[line:272] - INFO: epoch 005:   1604 / 3665 loss=5.095, loss_v1=0, loss_v2=0, nll_loss=4.187, ntokens=974.2, nsentences=32, sample_size=974.2, sample_size_v1=0, sample_size_v2=0, ppl=18.21, wps=362.4, ups=0.37, wpb=974.2, bsz=32, num_updates=16240, lr=2.96218e-05, gnorm=2.342, clip=100, loss_scale=256, train_wall=27, gb_free=15.1, wall=45752
2023-01-09 16:20:32 - progress_bar.py[line:272] - INFO: epoch 005:   1614 / 3665 loss=5.155, loss_v1=0, loss_v2=0, nll_loss=4.254, ntokens=877.1, nsentences=32, sample_size=877.1, sample_size_v1=0, sample_size_v2=0, ppl=19.08, wps=334.2, ups=0.38, wpb=877.1, bsz=32, num_updates=16250, lr=2.96073e-05, gnorm=2.4, clip=100, loss_scale=256, train_wall=26, gb_free=15.7, wall=45778
2023-01-09 16:20:58 - progress_bar.py[line:272] - INFO: epoch 005:   1624 / 3665 loss=5.177, loss_v1=0, loss_v2=0, nll_loss=4.282, ntokens=902.2, nsentences=32, sample_size=902.2, sample_size_v1=0, sample_size_v2=0, ppl=19.45, wps=342.6, ups=0.38, wpb=902.2, bsz=32, num_updates=16260, lr=2.95928e-05, gnorm=2.349, clip=100, loss_scale=512, train_wall=26, gb_free=15.5, wall=45805
2023-01-09 16:21:23 - progress_bar.py[line:272] - INFO: epoch 005:   1634 / 3665 loss=5.074, loss_v1=0, loss_v2=0, nll_loss=4.164, ntokens=921.2, nsentences=32, sample_size=921.2, sample_size_v1=0, sample_size_v2=0, ppl=17.92, wps=364.6, ups=0.4, wpb=921.2, bsz=32, num_updates=16270, lr=2.95782e-05, gnorm=2.163, clip=100, loss_scale=512, train_wall=25, gb_free=15.5, wall=45830
2023-01-09 16:21:48 - progress_bar.py[line:272] - INFO: epoch 005:   1644 / 3665 loss=5.167, loss_v1=0, loss_v2=0, nll_loss=4.267, ntokens=1296.7, nsentences=32, sample_size=1296.7, sample_size_v1=0, sample_size_v2=0, ppl=19.26, wps=519.8, ups=0.4, wpb=1296.7, bsz=32, num_updates=16280, lr=2.95637e-05, gnorm=1.658, clip=100, loss_scale=512, train_wall=25, gb_free=15, wall=45855
2023-01-09 16:22:13 - progress_bar.py[line:272] - INFO: epoch 005:   1654 / 3665 loss=5.088, loss_v1=0, loss_v2=0, nll_loss=4.183, ntokens=814.9, nsentences=32, sample_size=814.9, sample_size_v1=0, sample_size_v2=0, ppl=18.17, wps=330.9, ups=0.41, wpb=814.9, bsz=32, num_updates=16290, lr=2.95492e-05, gnorm=2.34, clip=100, loss_scale=512, train_wall=25, gb_free=15.5, wall=45879
2023-01-09 16:22:38 - progress_bar.py[line:272] - INFO: epoch 005:   1664 / 3665 loss=5.064, loss_v1=0, loss_v2=0, nll_loss=4.153, ntokens=825.4, nsentences=32, sample_size=825.4, sample_size_v1=0, sample_size_v2=0, ppl=17.78, wps=333.8, ups=0.4, wpb=825.4, bsz=32, num_updates=16300, lr=2.95347e-05, gnorm=2.547, clip=100, loss_scale=512, train_wall=25, gb_free=15.6, wall=45904
2023-01-09 16:22:43 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 256.0
2023-01-09 16:23:05 - progress_bar.py[line:272] - INFO: epoch 005:   1675 / 3665 loss=5.195, loss_v1=0, loss_v2=0, nll_loss=4.299, ntokens=931.5, nsentences=32, sample_size=931.5, sample_size_v1=0, sample_size_v2=0, ppl=19.68, wps=340.7, ups=0.37, wpb=931.5, bsz=32, num_updates=16310, lr=2.95202e-05, gnorm=2.258, clip=100, loss_scale=256, train_wall=27, gb_free=15.3, wall=45931
2023-01-09 16:23:30 - progress_bar.py[line:272] - INFO: epoch 005:   1685 / 3665 loss=5.171, loss_v1=0, loss_v2=0, nll_loss=4.272, ntokens=892.4, nsentences=32, sample_size=892.4, sample_size_v1=0, sample_size_v2=0, ppl=19.31, wps=360.3, ups=0.4, wpb=892.4, bsz=32, num_updates=16320, lr=2.95057e-05, gnorm=2.3, clip=100, loss_scale=256, train_wall=25, gb_free=15.2, wall=45956
2023-01-09 16:23:55 - progress_bar.py[line:272] - INFO: epoch 005:   1695 / 3665 loss=5.095, loss_v1=0, loss_v2=0, nll_loss=4.189, ntokens=955, nsentences=32, sample_size=955, sample_size_v1=0, sample_size_v2=0, ppl=18.24, wps=386.9, ups=0.41, wpb=955, bsz=32, num_updates=16330, lr=2.94912e-05, gnorm=2.137, clip=100, loss_scale=256, train_wall=25, gb_free=15.6, wall=45981
2023-01-09 16:24:19 - progress_bar.py[line:272] - INFO: epoch 005:   1705 / 3665 loss=5.129, loss_v1=0, loss_v2=0, nll_loss=4.227, ntokens=1031.3, nsentences=32, sample_size=1031.3, sample_size_v1=0, sample_size_v2=0, ppl=18.73, wps=414.8, ups=0.4, wpb=1031.3, bsz=32, num_updates=16340, lr=2.94766e-05, gnorm=2.122, clip=100, loss_scale=256, train_wall=25, gb_free=15.5, wall=46006
2023-01-09 16:24:44 - progress_bar.py[line:272] - INFO: epoch 005:   1715 / 3665 loss=5.057, loss_v1=0, loss_v2=0, nll_loss=4.146, ntokens=718.1, nsentences=32, sample_size=718.1, sample_size_v1=0, sample_size_v2=0, ppl=17.71, wps=292, ups=0.41, wpb=718.1, bsz=32, num_updates=16350, lr=2.94621e-05, gnorm=2.712, clip=100, loss_scale=256, train_wall=25, gb_free=15.5, wall=46030
2023-01-09 16:25:09 - progress_bar.py[line:272] - INFO: epoch 005:   1725 / 3665 loss=5.084, loss_v1=0, loss_v2=0, nll_loss=4.178, ntokens=899.1, nsentences=32, sample_size=899.1, sample_size_v1=0, sample_size_v2=0, ppl=18.1, wps=363, ups=0.4, wpb=899.1, bsz=32, num_updates=16360, lr=2.94476e-05, gnorm=2.187, clip=100, loss_scale=256, train_wall=25, gb_free=15.5, wall=46055
2023-01-09 16:25:34 - progress_bar.py[line:272] - INFO: epoch 005:   1735 / 3665 loss=5.087, loss_v1=0, loss_v2=0, nll_loss=4.178, ntokens=1025.4, nsentences=32, sample_size=1025.4, sample_size_v1=0, sample_size_v2=0, ppl=18.1, wps=411.4, ups=0.4, wpb=1025.4, bsz=32, num_updates=16370, lr=2.94331e-05, gnorm=2.042, clip=100, loss_scale=256, train_wall=25, gb_free=15.4, wall=46080
2023-01-09 16:25:58 - progress_bar.py[line:272] - INFO: epoch 005:   1745 / 3665 loss=5.162, loss_v1=0, loss_v2=0, nll_loss=4.261, ntokens=814.9, nsentences=32, sample_size=814.9, sample_size_v1=0, sample_size_v2=0, ppl=19.18, wps=330.7, ups=0.41, wpb=814.9, bsz=32, num_updates=16380, lr=2.94186e-05, gnorm=2.283, clip=100, loss_scale=256, train_wall=25, gb_free=15.3, wall=46105
2023-01-09 16:26:23 - progress_bar.py[line:272] - INFO: epoch 005:   1755 / 3665 loss=5.079, loss_v1=0, loss_v2=0, nll_loss=4.172, ntokens=857.4, nsentences=32, sample_size=857.4, sample_size_v1=0, sample_size_v2=0, ppl=18.02, wps=347.5, ups=0.41, wpb=857.4, bsz=32, num_updates=16390, lr=2.94041e-05, gnorm=2.42, clip=100, loss_scale=256, train_wall=25, gb_free=15.4, wall=46129
2023-01-09 16:26:48 - progress_bar.py[line:272] - INFO: epoch 005:   1765 / 3665 loss=5.073, loss_v1=0, loss_v2=0, nll_loss=4.164, ntokens=1041.5, nsentences=32, sample_size=1041.5, sample_size_v1=0, sample_size_v2=0, ppl=17.93, wps=419, ups=0.4, wpb=1041.5, bsz=32, num_updates=16400, lr=2.93896e-05, gnorm=1.995, clip=100, loss_scale=256, train_wall=25, gb_free=15.3, wall=46154
2023-01-09 16:27:13 - progress_bar.py[line:272] - INFO: epoch 005:   1775 / 3665 loss=5.263, loss_v1=0, loss_v2=0, nll_loss=4.373, ntokens=1006.4, nsentences=32, sample_size=1006.4, sample_size_v1=0, sample_size_v2=0, ppl=20.73, wps=404.4, ups=0.4, wpb=1006.4, bsz=32, num_updates=16410, lr=2.93751e-05, gnorm=2.156, clip=100, loss_scale=256, train_wall=25, gb_free=15.1, wall=46179
2023-01-09 16:27:38 - progress_bar.py[line:272] - INFO: epoch 005:   1785 / 3665 loss=5.11, loss_v1=0, loss_v2=0, nll_loss=4.205, ntokens=831, nsentences=32, sample_size=831, sample_size_v1=0, sample_size_v2=0, ppl=18.44, wps=336.1, ups=0.4, wpb=831, bsz=32, num_updates=16420, lr=2.93605e-05, gnorm=2.257, clip=100, loss_scale=256, train_wall=25, gb_free=15.4, wall=46204
2023-01-09 16:28:02 - progress_bar.py[line:272] - INFO: epoch 005:   1795 / 3665 loss=5.084, loss_v1=0, loss_v2=0, nll_loss=4.175, ntokens=945, nsentences=32, sample_size=945, sample_size_v1=0, sample_size_v2=0, ppl=18.06, wps=383.7, ups=0.41, wpb=945, bsz=32, num_updates=16430, lr=2.9346e-05, gnorm=2.076, clip=100, loss_scale=256, train_wall=25, gb_free=15.5, wall=46228
2023-01-09 16:28:27 - progress_bar.py[line:272] - INFO: epoch 005:   1805 / 3665 loss=5.138, loss_v1=0, loss_v2=0, nll_loss=4.237, ntokens=875.3, nsentences=32, sample_size=875.3, sample_size_v1=0, sample_size_v2=0, ppl=18.85, wps=355.7, ups=0.41, wpb=875.3, bsz=32, num_updates=16440, lr=2.93315e-05, gnorm=2.172, clip=100, loss_scale=256, train_wall=25, gb_free=15.6, wall=46253
2023-01-09 16:28:51 - progress_bar.py[line:272] - INFO: epoch 005:   1815 / 3665 loss=5.123, loss_v1=0, loss_v2=0, nll_loss=4.219, ntokens=834.8, nsentences=32, sample_size=834.8, sample_size_v1=0, sample_size_v2=0, ppl=18.63, wps=338.9, ups=0.41, wpb=834.8, bsz=32, num_updates=16450, lr=2.9317e-05, gnorm=2.359, clip=100, loss_scale=256, train_wall=25, gb_free=15.4, wall=46278
2023-01-09 16:29:16 - progress_bar.py[line:272] - INFO: epoch 005:   1825 / 3665 loss=5.05, loss_v1=0, loss_v2=0, nll_loss=4.14, ntokens=1020.3, nsentences=32, sample_size=1020.3, sample_size_v1=0, sample_size_v2=0, ppl=17.63, wps=410.1, ups=0.4, wpb=1020.3, bsz=32, num_updates=16460, lr=2.93025e-05, gnorm=2.083, clip=100, loss_scale=256, train_wall=25, gb_free=15.3, wall=46303
2023-01-09 16:29:41 - progress_bar.py[line:272] - INFO: epoch 005:   1835 / 3665 loss=5.216, loss_v1=0, loss_v2=0, nll_loss=4.324, ntokens=970.1, nsentences=32, sample_size=970.1, sample_size_v1=0, sample_size_v2=0, ppl=20.02, wps=391.2, ups=0.4, wpb=970.1, bsz=32, num_updates=16470, lr=2.9288e-05, gnorm=2.154, clip=100, loss_scale=256, train_wall=25, gb_free=15.6, wall=46327
2023-01-09 16:30:06 - progress_bar.py[line:272] - INFO: epoch 005:   1845 / 3665 loss=5.126, loss_v1=0, loss_v2=0, nll_loss=4.221, ntokens=751, nsentences=32, sample_size=751, sample_size_v1=0, sample_size_v2=0, ppl=18.65, wps=305.6, ups=0.41, wpb=751, bsz=32, num_updates=16480, lr=2.92735e-05, gnorm=2.563, clip=100, loss_scale=256, train_wall=25, gb_free=15.3, wall=46352
2023-01-09 16:30:30 - progress_bar.py[line:272] - INFO: epoch 005:   1855 / 3665 loss=5.043, loss_v1=0, loss_v2=0, nll_loss=4.132, ntokens=897.7, nsentences=32, sample_size=897.7, sample_size_v1=0, sample_size_v2=0, ppl=17.53, wps=363.7, ups=0.41, wpb=897.7, bsz=32, num_updates=16490, lr=2.92589e-05, gnorm=2.226, clip=100, loss_scale=256, train_wall=25, gb_free=15.6, wall=46377
2023-01-09 16:30:55 - progress_bar.py[line:272] - INFO: epoch 005:   1865 / 3665 loss=5.168, loss_v1=0, loss_v2=0, nll_loss=4.269, ntokens=991.6, nsentences=32, sample_size=991.6, sample_size_v1=0, sample_size_v2=0, ppl=19.28, wps=401.8, ups=0.41, wpb=991.6, bsz=32, num_updates=16500, lr=2.92444e-05, gnorm=2.132, clip=100, loss_scale=256, train_wall=25, gb_free=15.4, wall=46401
2023-01-09 16:30:55 - train.py[line:445] - INFO: begin validation on "valid" subset
slice_id 0 seek offset 0
slice_id 0 seek offset 0
2023-01-09 16:36:19 - progress_bar.py[line:282] - INFO: epoch 005 | valid on 'valid' subset | loss 5.115 | loss_v1 0 | loss_v2 0 | nll_loss 4.192 | ntokens 117.388 | nsentences 4 | sample_size 117.388 | sample_size_v1 0 | sample_size_v2 0 | AP 0 | total positives 21.7876 | TP 0 | FP 5.15913 | ppl 18.28 | wps 451.6 | wpb 117.4 | bsz 4 | num_updates 16500 | best_AP 0
2023-01-09 16:36:19 - checkpoint_utils.py[line:64] - INFO: Preparing to save checkpoint for epoch 5 @ 16500 updates
2023-01-09 16:36:19 - trainer.py[line:431] - INFO: Saving checkpoint to ../../checkpoints/OFA/detection_checkpoints/10_5e-5_512/checkpoint_5_16500.pt
2023-01-09 16:36:23 - trainer.py[line:441] - INFO: Finished saving checkpoint to ../../checkpoints/OFA/detection_checkpoints/10_5e-5_512/checkpoint_5_16500.pt
2023-01-09 16:37:55 - checkpoint_utils.py[line:133] - INFO: Saved checkpoint ../../checkpoints/OFA/detection_checkpoints/10_5e-5_512/checkpoint_5_16500.pt (epoch 5 @ 16500 updates, score 0.0) (writing took 95.75115067185834 seconds)
2023-01-09 16:38:17 - progress_bar.py[line:272] - INFO: epoch 005:   1875 / 3665 loss=5.15, loss_v1=0, loss_v2=0, nll_loss=4.249, ntokens=873.2, nsentences=32, sample_size=873.2, sample_size_v1=0, sample_size_v2=0, ppl=19.01, wps=19.8, ups=0.02, wpb=873.2, bsz=32, num_updates=16510, lr=2.92299e-05, gnorm=2.369, clip=100, loss_scale=256, train_wall=20, gb_free=15.5, wall=46843
2023-01-09 16:38:37 - progress_bar.py[line:272] - INFO: epoch 005:   1885 / 3665 loss=5.113, loss_v1=0, loss_v2=0, nll_loss=4.207, ntokens=1016.3, nsentences=31.8, sample_size=1016.3, sample_size_v1=0, sample_size_v2=0, ppl=18.47, wps=507.4, ups=0.5, wpb=1016.3, bsz=31.8, num_updates=16520, lr=2.92154e-05, gnorm=2.151, clip=100, loss_scale=256, train_wall=20, gb_free=14.7, wall=46863
2023-01-09 16:38:57 - progress_bar.py[line:272] - INFO: epoch 005:   1895 / 3665 loss=5.171, loss_v1=0, loss_v2=0, nll_loss=4.273, ntokens=1074.8, nsentences=32, sample_size=1074.8, sample_size_v1=0, sample_size_v2=0, ppl=19.33, wps=528.3, ups=0.49, wpb=1074.8, bsz=32, num_updates=16530, lr=2.92009e-05, gnorm=1.819, clip=100, loss_scale=256, train_wall=20, gb_free=15.6, wall=46883
2023-01-09 16:39:17 - progress_bar.py[line:272] - INFO: epoch 005:   1905 / 3665 loss=5.12, loss_v1=0, loss_v2=0, nll_loss=4.216, ntokens=721, nsentences=32, sample_size=721, sample_size_v1=0, sample_size_v2=0, ppl=18.58, wps=357.1, ups=0.5, wpb=721, bsz=32, num_updates=16540, lr=2.91864e-05, gnorm=2.681, clip=100, loss_scale=256, train_wall=20, gb_free=15.6, wall=46903
2023-01-09 16:39:41 - progress_bar.py[line:272] - INFO: epoch 005:   1915 / 3665 loss=5.097, loss_v1=0, loss_v2=0, nll_loss=4.188, ntokens=917, nsentences=32, sample_size=917, sample_size_v1=0, sample_size_v2=0, ppl=18.23, wps=381.4, ups=0.42, wpb=917, bsz=32, num_updates=16550, lr=2.91719e-05, gnorm=2.121, clip=100, loss_scale=256, train_wall=24, gb_free=15.5, wall=46927
2023-01-09 16:40:08 - progress_bar.py[line:272] - INFO: epoch 005:   1925 / 3665 loss=5.165, loss_v1=0, loss_v2=0, nll_loss=4.267, ntokens=1001, nsentences=32, sample_size=1001, sample_size_v1=0, sample_size_v2=0, ppl=19.25, wps=374.3, ups=0.37, wpb=1001, bsz=32, num_updates=16560, lr=2.91574e-05, gnorm=2.203, clip=100, loss_scale=256, train_wall=27, gb_free=14.4, wall=46954
2023-01-09 16:40:36 - progress_bar.py[line:272] - INFO: epoch 005:   1935 / 3665 loss=5.165, loss_v1=0, loss_v2=0, nll_loss=4.265, ntokens=800.6, nsentences=32, sample_size=800.6, sample_size_v1=0, sample_size_v2=0, ppl=19.22, wps=283.7, ups=0.35, wpb=800.6, bsz=32, num_updates=16570, lr=2.91428e-05, gnorm=2.44, clip=100, loss_scale=256, train_wall=28, gb_free=15.6, wall=46982
2023-01-09 16:41:02 - progress_bar.py[line:272] - INFO: epoch 005:   1945 / 3665 loss=5.065, loss_v1=0, loss_v2=0, nll_loss=4.153, ntokens=824.7, nsentences=32, sample_size=824.7, sample_size_v1=0, sample_size_v2=0, ppl=17.79, wps=324, ups=0.39, wpb=824.7, bsz=32, num_updates=16580, lr=2.91283e-05, gnorm=2.434, clip=100, loss_scale=256, train_wall=25, gb_free=15.5, wall=47008
2023-01-09 16:41:27 - progress_bar.py[line:272] - INFO: epoch 005:   1955 / 3665 loss=5.014, loss_v1=0, loss_v2=0, nll_loss=4.1, ntokens=984.1, nsentences=32, sample_size=984.1, sample_size_v1=0, sample_size_v2=0, ppl=17.15, wps=388.4, ups=0.39, wpb=984.1, bsz=32, num_updates=16590, lr=2.91138e-05, gnorm=2.105, clip=100, loss_scale=256, train_wall=25, gb_free=15.3, wall=47033
2023-01-09 16:41:51 - progress_bar.py[line:272] - INFO: epoch 005:   1965 / 3665 loss=5.228, loss_v1=0, loss_v2=0, nll_loss=4.335, ntokens=1015, nsentences=32, sample_size=1015, sample_size_v1=0, sample_size_v2=0, ppl=20.18, wps=430.2, ups=0.42, wpb=1015, bsz=32, num_updates=16600, lr=2.90993e-05, gnorm=2.024, clip=100, loss_scale=256, train_wall=24, gb_free=15.4, wall=47057
2023-01-09 16:42:12 - progress_bar.py[line:272] - INFO: epoch 005:   1975 / 3665 loss=5.158, loss_v1=0, loss_v2=0, nll_loss=4.258, ntokens=916.1, nsentences=32, sample_size=916.1, sample_size_v1=0, sample_size_v2=0, ppl=19.13, wps=417.3, ups=0.46, wpb=916.1, bsz=32, num_updates=16610, lr=2.90848e-05, gnorm=2.187, clip=100, loss_scale=256, train_wall=22, gb_free=15.4, wall=47079
2023-01-09 16:42:34 - progress_bar.py[line:272] - INFO: epoch 005:   1985 / 3665 loss=5.058, loss_v1=0, loss_v2=0, nll_loss=4.148, ntokens=972, nsentences=32, sample_size=972, sample_size_v1=0, sample_size_v2=0, ppl=17.72, wps=455.2, ups=0.47, wpb=972, bsz=32, num_updates=16620, lr=2.90703e-05, gnorm=2.137, clip=100, loss_scale=256, train_wall=21, gb_free=15.5, wall=47100
2023-01-09 16:42:55 - progress_bar.py[line:272] - INFO: epoch 005:   1995 / 3665 loss=5.216, loss_v1=0, loss_v2=0, nll_loss=4.323, ntokens=1016, nsentences=32, sample_size=1016, sample_size_v1=0, sample_size_v2=0, ppl=20.02, wps=473.9, ups=0.47, wpb=1016, bsz=32, num_updates=16630, lr=2.90558e-05, gnorm=2.248, clip=100, loss_scale=256, train_wall=21, gb_free=15.4, wall=47122
2023-01-09 16:43:17 - progress_bar.py[line:272] - INFO: epoch 005:   2005 / 3665 loss=5.12, loss_v1=0, loss_v2=0, nll_loss=4.214, ntokens=833, nsentences=32, sample_size=833, sample_size_v1=0, sample_size_v2=0, ppl=18.56, wps=389.4, ups=0.47, wpb=833, bsz=32, num_updates=16640, lr=2.90412e-05, gnorm=2.486, clip=100, loss_scale=256, train_wall=21, gb_free=15.5, wall=47143
2023-01-09 16:43:40 - progress_bar.py[line:272] - INFO: epoch 005:   2015 / 3665 loss=5.132, loss_v1=0, loss_v2=0, nll_loss=4.228, ntokens=933.8, nsentences=32, sample_size=933.8, sample_size_v1=0, sample_size_v2=0, ppl=18.74, wps=408.7, ups=0.44, wpb=933.8, bsz=32, num_updates=16650, lr=2.90267e-05, gnorm=2.037, clip=100, loss_scale=256, train_wall=23, gb_free=15.5, wall=47166
2023-01-09 16:44:08 - progress_bar.py[line:272] - INFO: epoch 005:   2025 / 3665 loss=5.202, loss_v1=0, loss_v2=0, nll_loss=4.309, ntokens=1051.3, nsentences=32, sample_size=1051.3, sample_size_v1=0, sample_size_v2=0, ppl=19.81, wps=364.4, ups=0.35, wpb=1051.3, bsz=32, num_updates=16660, lr=2.90122e-05, gnorm=1.902, clip=100, loss_scale=256, train_wall=28, gb_free=15.1, wall=47195
2023-01-09 16:44:31 - progress_bar.py[line:272] - INFO: epoch 005:   2035 / 3665 loss=5.082, loss_v1=0, loss_v2=0, nll_loss=4.175, ntokens=735.6, nsentences=32, sample_size=735.6, sample_size_v1=0, sample_size_v2=0, ppl=18.06, wps=318.7, ups=0.43, wpb=735.6, bsz=32, num_updates=16670, lr=2.89977e-05, gnorm=2.775, clip=100, loss_scale=256, train_wall=23, gb_free=15.4, wall=47218
2023-01-09 16:44:55 - progress_bar.py[line:272] - INFO: epoch 005:   2045 / 3665 loss=5.052, loss_v1=0, loss_v2=0, nll_loss=4.141, ntokens=859.6, nsentences=32, sample_size=859.6, sample_size_v1=0, sample_size_v2=0, ppl=17.64, wps=370.1, ups=0.43, wpb=859.6, bsz=32, num_updates=16680, lr=2.89832e-05, gnorm=2.347, clip=100, loss_scale=256, train_wall=23, gb_free=15.4, wall=47241
2023-01-09 16:45:18 - progress_bar.py[line:272] - INFO: epoch 005:   2055 / 3665 loss=5.116, loss_v1=0, loss_v2=0, nll_loss=4.211, ntokens=971, nsentences=32, sample_size=971, sample_size_v1=0, sample_size_v2=0, ppl=18.52, wps=421.3, ups=0.43, wpb=971, bsz=32, num_updates=16690, lr=2.89687e-05, gnorm=2.062, clip=100, loss_scale=256, train_wall=23, gb_free=15.4, wall=47264
2023-01-09 16:45:40 - progress_bar.py[line:272] - INFO: epoch 005:   2065 / 3665 loss=5.141, loss_v1=0, loss_v2=0, nll_loss=4.238, ntokens=804.8, nsentences=32, sample_size=804.8, sample_size_v1=0, sample_size_v2=0, ppl=18.86, wps=357, ups=0.44, wpb=804.8, bsz=32, num_updates=16700, lr=2.89542e-05, gnorm=2.419, clip=100, loss_scale=256, train_wall=23, gb_free=15.3, wall=47287
2023-01-09 16:46:02 - progress_bar.py[line:272] - INFO: epoch 005:   2075 / 3665 loss=5.055, loss_v1=0, loss_v2=0, nll_loss=4.144, ntokens=922.4, nsentences=32, sample_size=922.4, sample_size_v1=0, sample_size_v2=0, ppl=17.68, wps=418, ups=0.45, wpb=922.4, bsz=32, num_updates=16710, lr=2.89397e-05, gnorm=2.195, clip=100, loss_scale=256, train_wall=22, gb_free=15.3, wall=47309
2023-01-09 16:46:25 - progress_bar.py[line:272] - INFO: epoch 005:   2085 / 3665 loss=5.265, loss_v1=0, loss_v2=0, nll_loss=4.377, ntokens=1141.8, nsentences=32, sample_size=1141.8, sample_size_v1=0, sample_size_v2=0, ppl=20.78, wps=509.7, ups=0.45, wpb=1141.8, bsz=32, num_updates=16720, lr=2.89251e-05, gnorm=1.893, clip=100, loss_scale=256, train_wall=22, gb_free=15.4, wall=47331
2023-01-09 16:46:47 - progress_bar.py[line:272] - INFO: epoch 005:   2095 / 3665 loss=5.13, loss_v1=0, loss_v2=0, nll_loss=4.227, ntokens=740.1, nsentences=32, sample_size=740.1, sample_size_v1=0, sample_size_v2=0, ppl=18.72, wps=333.6, ups=0.45, wpb=740.1, bsz=32, num_updates=16730, lr=2.89106e-05, gnorm=2.522, clip=100, loss_scale=256, train_wall=22, gb_free=15.5, wall=47353
2023-01-09 16:47:11 - progress_bar.py[line:272] - INFO: epoch 005:   2105 / 3665 loss=5.046, loss_v1=0, loss_v2=0, nll_loss=4.134, ntokens=1033.7, nsentences=32, sample_size=1033.7, sample_size_v1=0, sample_size_v2=0, ppl=17.56, wps=435.1, ups=0.42, wpb=1033.7, bsz=32, num_updates=16740, lr=2.88961e-05, gnorm=1.969, clip=100, loss_scale=256, train_wall=24, gb_free=15.4, wall=47377
2023-01-09 16:47:35 - progress_bar.py[line:272] - INFO: epoch 005:   2115 / 3665 loss=5.114, loss_v1=0, loss_v2=0, nll_loss=4.209, ntokens=1072.4, nsentences=32, sample_size=1072.4, sample_size_v1=0, sample_size_v2=0, ppl=18.5, wps=436.4, ups=0.41, wpb=1072.4, bsz=32, num_updates=16750, lr=2.88816e-05, gnorm=1.955, clip=100, loss_scale=256, train_wall=25, gb_free=14.5, wall=47402
2023-01-09 16:47:59 - progress_bar.py[line:272] - INFO: epoch 005:   2125 / 3665 loss=5.184, loss_v1=0, loss_v2=0, nll_loss=4.288, ntokens=830.1, nsentences=32, sample_size=830.1, sample_size_v1=0, sample_size_v2=0, ppl=19.54, wps=344.9, ups=0.42, wpb=830.1, bsz=32, num_updates=16760, lr=2.88671e-05, gnorm=2.359, clip=100, loss_scale=256, train_wall=24, gb_free=15.4, wall=47426
2023-01-09 16:48:23 - progress_bar.py[line:272] - INFO: epoch 005:   2135 / 3665 loss=5.082, loss_v1=0, loss_v2=0, nll_loss=4.171, ntokens=890.9, nsentences=32, sample_size=890.9, sample_size_v1=0, sample_size_v2=0, ppl=18.01, wps=378.5, ups=0.42, wpb=890.9, bsz=32, num_updates=16770, lr=2.88526e-05, gnorm=2.176, clip=100, loss_scale=256, train_wall=24, gb_free=15.5, wall=47449
2023-01-09 16:48:45 - progress_bar.py[line:272] - INFO: epoch 005:   2145 / 3665 loss=5.048, loss_v1=0, loss_v2=0, nll_loss=4.137, ntokens=1001.6, nsentences=32, sample_size=1001.6, sample_size_v1=0, sample_size_v2=0, ppl=17.59, wps=459.5, ups=0.46, wpb=1001.6, bsz=32, num_updates=16780, lr=2.88381e-05, gnorm=2.115, clip=100, loss_scale=256, train_wall=22, gb_free=15.5, wall=47471
2023-01-09 16:49:07 - progress_bar.py[line:272] - INFO: epoch 005:   2155 / 3665 loss=5.191, loss_v1=0, loss_v2=0, nll_loss=4.295, ntokens=964.6, nsentences=32, sample_size=964.6, sample_size_v1=0, sample_size_v2=0, ppl=19.63, wps=440.3, ups=0.46, wpb=964.6, bsz=32, num_updates=16790, lr=2.88235e-05, gnorm=2.238, clip=100, loss_scale=256, train_wall=22, gb_free=15.3, wall=47493
2023-01-09 16:49:29 - progress_bar.py[line:272] - INFO: epoch 005:   2165 / 3665 loss=5.174, loss_v1=0, loss_v2=0, nll_loss=4.276, ntokens=950.8, nsentences=32, sample_size=950.8, sample_size_v1=0, sample_size_v2=0, ppl=19.37, wps=433.2, ups=0.46, wpb=950.8, bsz=32, num_updates=16800, lr=2.8809e-05, gnorm=2.102, clip=100, loss_scale=256, train_wall=22, gb_free=15.6, wall=47515
2023-01-09 16:49:51 - progress_bar.py[line:272] - INFO: epoch 005:   2175 / 3665 loss=5.048, loss_v1=0, loss_v2=0, nll_loss=4.138, ntokens=917.6, nsentences=32, sample_size=917.6, sample_size_v1=0, sample_size_v2=0, ppl=17.61, wps=402.4, ups=0.44, wpb=917.6, bsz=32, num_updates=16810, lr=2.87945e-05, gnorm=2.189, clip=100, loss_scale=256, train_wall=23, gb_free=15.2, wall=47538
2023-01-09 16:50:16 - progress_bar.py[line:272] - INFO: epoch 005:   2185 / 3665 loss=5.12, loss_v1=0, loss_v2=0, nll_loss=4.216, ntokens=882, nsentences=32, sample_size=882, sample_size_v1=0, sample_size_v2=0, ppl=18.58, wps=355.1, ups=0.4, wpb=882, bsz=32, num_updates=16820, lr=2.878e-05, gnorm=2.253, clip=100, loss_scale=512, train_wall=25, gb_free=15.4, wall=47562
2023-01-09 16:50:41 - progress_bar.py[line:272] - INFO: epoch 005:   2195 / 3665 loss=5.215, loss_v1=0, loss_v2=0, nll_loss=4.318, ntokens=958.7, nsentences=32, sample_size=958.7, sample_size_v1=0, sample_size_v2=0, ppl=19.94, wps=388.4, ups=0.41, wpb=958.7, bsz=32, num_updates=16830, lr=2.87655e-05, gnorm=2.378, clip=100, loss_scale=512, train_wall=25, gb_free=15.1, wall=47587
2023-01-09 16:51:05 - progress_bar.py[line:272] - INFO: epoch 005:   2205 / 3665 loss=5.09, loss_v1=0, loss_v2=0, nll_loss=4.183, ntokens=989.2, nsentences=32, sample_size=989.2, sample_size_v1=0, sample_size_v2=0, ppl=18.17, wps=407.1, ups=0.41, wpb=989.2, bsz=32, num_updates=16840, lr=2.8751e-05, gnorm=2.143, clip=100, loss_scale=512, train_wall=24, gb_free=15, wall=47611
2023-01-09 16:51:29 - progress_bar.py[line:272] - INFO: epoch 005:   2215 / 3665 loss=5.281, loss_v1=0, loss_v2=0, nll_loss=4.396, ntokens=975.4, nsentences=32, sample_size=975.4, sample_size_v1=0, sample_size_v2=0, ppl=21.05, wps=415.2, ups=0.43, wpb=975.4, bsz=32, num_updates=16850, lr=2.87365e-05, gnorm=2.178, clip=100, loss_scale=512, train_wall=23, gb_free=15.3, wall=47635
2023-01-09 16:51:51 - progress_bar.py[line:272] - INFO: epoch 005:   2225 / 3665 loss=5.069, loss_v1=0, loss_v2=0, nll_loss=4.159, ntokens=848.2, nsentences=32, sample_size=848.2, sample_size_v1=0, sample_size_v2=0, ppl=17.86, wps=386.7, ups=0.46, wpb=848.2, bsz=32, num_updates=16860, lr=2.8722e-05, gnorm=2.477, clip=100, loss_scale=512, train_wall=22, gb_free=15.3, wall=47657
2023-01-09 16:52:12 - progress_bar.py[line:272] - INFO: epoch 005:   2235 / 3665 loss=4.999, loss_v1=0, loss_v2=0, nll_loss=4.082, ntokens=914.6, nsentences=32, sample_size=914.6, sample_size_v1=0, sample_size_v2=0, ppl=16.93, wps=418.6, ups=0.46, wpb=914.6, bsz=32, num_updates=16870, lr=2.87074e-05, gnorm=2.101, clip=100, loss_scale=512, train_wall=22, gb_free=15.5, wall=47679
2023-01-09 16:52:34 - progress_bar.py[line:272] - INFO: epoch 005:   2245 / 3665 loss=5.132, loss_v1=0, loss_v2=0, nll_loss=4.229, ntokens=893, nsentences=32, sample_size=893, sample_size_v1=0, sample_size_v2=0, ppl=18.76, wps=406.7, ups=0.46, wpb=893, bsz=32, num_updates=16880, lr=2.86929e-05, gnorm=2.341, clip=100, loss_scale=512, train_wall=22, gb_free=15.4, wall=47701
2023-01-09 16:52:52 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 256.0
2023-01-09 16:52:59 - progress_bar.py[line:272] - INFO: epoch 005:   2256 / 3665 loss=5.118, loss_v1=0, loss_v2=0, nll_loss=4.214, ntokens=840.2, nsentences=32, sample_size=840.2, sample_size_v1=0, sample_size_v2=0, ppl=18.55, wps=346.7, ups=0.41, wpb=840.2, bsz=32, num_updates=16890, lr=2.86784e-05, gnorm=2.431, clip=100, loss_scale=256, train_wall=24, gb_free=15.2, wall=47725
2023-01-09 16:53:23 - progress_bar.py[line:272] - INFO: epoch 005:   2266 / 3665 loss=5.047, loss_v1=0, loss_v2=0, nll_loss=4.134, ntokens=959.5, nsentences=32, sample_size=959.5, sample_size_v1=0, sample_size_v2=0, ppl=17.56, wps=386.6, ups=0.4, wpb=959.5, bsz=32, num_updates=16900, lr=2.86639e-05, gnorm=2.147, clip=100, loss_scale=256, train_wall=25, gb_free=15.2, wall=47750
2023-01-09 16:53:49 - progress_bar.py[line:272] - INFO: epoch 005:   2276 / 3665 loss=5.173, loss_v1=0, loss_v2=0, nll_loss=4.276, ntokens=1084.6, nsentences=32, sample_size=1084.6, sample_size_v1=0, sample_size_v2=0, ppl=19.38, wps=429.4, ups=0.4, wpb=1084.6, bsz=32, num_updates=16910, lr=2.86494e-05, gnorm=2.02, clip=100, loss_scale=256, train_wall=25, gb_free=15.4, wall=47775
2023-01-09 16:54:12 - progress_bar.py[line:272] - INFO: epoch 005:   2286 / 3665 loss=5.087, loss_v1=0, loss_v2=0, nll_loss=4.178, ntokens=812.5, nsentences=32, sample_size=812.5, sample_size_v1=0, sample_size_v2=0, ppl=18.1, wps=346.6, ups=0.43, wpb=812.5, bsz=32, num_updates=16920, lr=2.86349e-05, gnorm=2.321, clip=100, loss_scale=256, train_wall=23, gb_free=15, wall=47798
2023-01-09 16:54:35 - progress_bar.py[line:272] - INFO: epoch 005:   2296 / 3665 loss=5.131, loss_v1=0, loss_v2=0, nll_loss=4.228, ntokens=952.8, nsentences=32, sample_size=952.8, sample_size_v1=0, sample_size_v2=0, ppl=18.74, wps=411.7, ups=0.43, wpb=952.8, bsz=32, num_updates=16930, lr=2.86204e-05, gnorm=2.156, clip=100, loss_scale=256, train_wall=23, gb_free=15.4, wall=47822
2023-01-09 16:54:57 - progress_bar.py[line:272] - INFO: epoch 005:   2306 / 3665 loss=5.009, loss_v1=0, loss_v2=0, nll_loss=4.093, ntokens=866.9, nsentences=32, sample_size=866.9, sample_size_v1=0, sample_size_v2=0, ppl=17.06, wps=396, ups=0.46, wpb=866.9, bsz=32, num_updates=16940, lr=2.86058e-05, gnorm=2.229, clip=100, loss_scale=256, train_wall=22, gb_free=15.4, wall=47843
2023-01-09 16:55:19 - progress_bar.py[line:272] - INFO: epoch 005:   2316 / 3665 loss=5.089, loss_v1=0, loss_v2=0, nll_loss=4.18, ntokens=754.7, nsentences=32, sample_size=754.7, sample_size_v1=0, sample_size_v2=0, ppl=18.12, wps=346.9, ups=0.46, wpb=754.7, bsz=32, num_updates=16950, lr=2.85913e-05, gnorm=2.664, clip=100, loss_scale=256, train_wall=22, gb_free=15.7, wall=47865
2023-01-09 16:55:40 - progress_bar.py[line:272] - INFO: epoch 005:   2326 / 3665 loss=5.108, loss_v1=0, loss_v2=0, nll_loss=4.203, ntokens=903.3, nsentences=32, sample_size=903.3, sample_size_v1=0, sample_size_v2=0, ppl=18.41, wps=418.9, ups=0.46, wpb=903.3, bsz=32, num_updates=16960, lr=2.85768e-05, gnorm=2.264, clip=100, loss_scale=256, train_wall=22, gb_free=15.4, wall=47887
2023-01-09 16:56:02 - progress_bar.py[line:272] - INFO: epoch 005:   2336 / 3665 loss=5.132, loss_v1=0, loss_v2=0, nll_loss=4.228, ntokens=1078.3, nsentences=32, sample_size=1078.3, sample_size_v1=0, sample_size_v2=0, ppl=18.74, wps=498.2, ups=0.46, wpb=1078.3, bsz=32, num_updates=16970, lr=2.85623e-05, gnorm=1.995, clip=100, loss_scale=256, train_wall=22, gb_free=14.5, wall=47908
2023-01-09 16:56:24 - progress_bar.py[line:272] - INFO: epoch 005:   2346 / 3665 loss=5.194, loss_v1=0, loss_v2=0, nll_loss=4.301, ntokens=1061.4, nsentences=32, sample_size=1061.4, sample_size_v1=0, sample_size_v2=0, ppl=19.71, wps=490.3, ups=0.46, wpb=1061.4, bsz=32, num_updates=16980, lr=2.85478e-05, gnorm=1.982, clip=100, loss_scale=256, train_wall=22, gb_free=15.7, wall=47930
2023-01-09 16:56:45 - progress_bar.py[line:272] - INFO: epoch 005:   2356 / 3665 loss=5.202, loss_v1=0, loss_v2=0, nll_loss=4.308, ntokens=1144.4, nsentences=32, sample_size=1144.4, sample_size_v1=0, sample_size_v2=0, ppl=19.8, wps=530.3, ups=0.46, wpb=1144.4, bsz=32, num_updates=16990, lr=2.85333e-05, gnorm=2.037, clip=100, loss_scale=256, train_wall=22, gb_free=15.3, wall=47952
2023-01-09 16:57:06 - progress_bar.py[line:272] - INFO: epoch 005:   2366 / 3665 loss=4.967, loss_v1=0, loss_v2=0, nll_loss=4.043, ntokens=914.3, nsentences=32, sample_size=914.3, sample_size_v1=0, sample_size_v2=0, ppl=16.49, wps=432.5, ups=0.47, wpb=914.3, bsz=32, num_updates=17000, lr=2.85188e-05, gnorm=2.152, clip=100, loss_scale=256, train_wall=21, gb_free=15.2, wall=47973
2023-01-09 16:57:06 - train.py[line:445] - INFO: begin validation on "valid" subset
slice_id 0 seek offset 0
slice_id 0 seek offset 0
2023-01-09 17:01:56 - progress_bar.py[line:282] - INFO: epoch 005 | valid on 'valid' subset | loss 5.11 | loss_v1 0 | loss_v2 0 | nll_loss 4.188 | ntokens 116.918 | nsentences 4 | sample_size 116.918 | sample_size_v1 0 | sample_size_v2 0 | AP 0 | total positives 21.6963 | TP 0 | FP 5.18174 | ppl 18.22 | wps 503.7 | wpb 116.9 | bsz 4 | num_updates 17000 | best_AP 0
2023-01-09 17:01:56 - checkpoint_utils.py[line:64] - INFO: Preparing to save checkpoint for epoch 5 @ 17000 updates
2023-01-09 17:01:56 - trainer.py[line:431] - INFO: Saving checkpoint to ../../checkpoints/OFA/detection_checkpoints/10_5e-5_512/checkpoint_5_17000.pt
2023-01-09 17:01:59 - trainer.py[line:441] - INFO: Finished saving checkpoint to ../../checkpoints/OFA/detection_checkpoints/10_5e-5_512/checkpoint_5_17000.pt
2023-01-09 17:03:08 - checkpoint_utils.py[line:133] - INFO: Saved checkpoint ../../checkpoints/OFA/detection_checkpoints/10_5e-5_512/checkpoint_5_17000.pt (epoch 5 @ 17000 updates, score 0.0) (writing took 71.8024141388014 seconds)
2023-01-09 17:03:28 - progress_bar.py[line:272] - INFO: epoch 005:   2376 / 3665 loss=5.154, loss_v1=0, loss_v2=0, nll_loss=4.254, ntokens=893, nsentences=32, sample_size=893, sample_size_v1=0, sample_size_v2=0, ppl=19.08, wps=23.4, ups=0.03, wpb=893, bsz=32, num_updates=17010, lr=2.85043e-05, gnorm=2.583, clip=100, loss_scale=256, train_wall=19, gb_free=15.5, wall=48354
2023-01-09 17:03:47 - progress_bar.py[line:272] - INFO: epoch 005:   2386 / 3665 loss=5.132, loss_v1=0, loss_v2=0, nll_loss=4.229, ntokens=762.1, nsentences=32, sample_size=762.1, sample_size_v1=0, sample_size_v2=0, ppl=18.75, wps=391.4, ups=0.51, wpb=762.1, bsz=32, num_updates=17020, lr=2.84897e-05, gnorm=2.518, clip=100, loss_scale=256, train_wall=19, gb_free=15.3, wall=48373
2023-01-09 17:04:07 - progress_bar.py[line:272] - INFO: epoch 005:   2396 / 3665 loss=5.057, loss_v1=0, loss_v2=0, nll_loss=4.146, ntokens=1089.7, nsentences=32, sample_size=1089.7, sample_size_v1=0, sample_size_v2=0, ppl=17.71, wps=555.5, ups=0.51, wpb=1089.7, bsz=32, num_updates=17030, lr=2.84752e-05, gnorm=1.897, clip=100, loss_scale=256, train_wall=20, gb_free=15.1, wall=48393
2023-01-09 17:04:26 - progress_bar.py[line:272] - INFO: epoch 005:   2406 / 3665 loss=5.143, loss_v1=0, loss_v2=0, nll_loss=4.242, ntokens=889.9, nsentences=32, sample_size=889.9, sample_size_v1=0, sample_size_v2=0, ppl=18.92, wps=454, ups=0.51, wpb=889.9, bsz=32, num_updates=17040, lr=2.84607e-05, gnorm=2.333, clip=100, loss_scale=256, train_wall=20, gb_free=15.2, wall=48413
2023-01-09 17:04:46 - progress_bar.py[line:272] - INFO: epoch 005:   2416 / 3665 loss=5.092, loss_v1=0, loss_v2=0, nll_loss=4.185, ntokens=726.4, nsentences=32, sample_size=726.4, sample_size_v1=0, sample_size_v2=0, ppl=18.19, wps=372, ups=0.51, wpb=726.4, bsz=32, num_updates=17050, lr=2.84462e-05, gnorm=2.722, clip=100, loss_scale=256, train_wall=20, gb_free=15.5, wall=48432
2023-01-09 17:05:05 - progress_bar.py[line:272] - INFO: epoch 005:   2426 / 3665 loss=4.993, loss_v1=0, loss_v2=0, nll_loss=4.075, ntokens=828.2, nsentences=32, sample_size=828.2, sample_size_v1=0, sample_size_v2=0, ppl=16.85, wps=424.7, ups=0.51, wpb=828.2, bsz=32, num_updates=17060, lr=2.84317e-05, gnorm=2.348, clip=100, loss_scale=256, train_wall=19, gb_free=15.4, wall=48452
2023-01-09 17:05:25 - progress_bar.py[line:272] - INFO: epoch 005:   2436 / 3665 loss=5.038, loss_v1=0, loss_v2=0, nll_loss=4.127, ntokens=966.1, nsentences=32, sample_size=966.1, sample_size_v1=0, sample_size_v2=0, ppl=17.47, wps=492.2, ups=0.51, wpb=966.1, bsz=32, num_updates=17070, lr=2.84172e-05, gnorm=2.127, clip=100, loss_scale=256, train_wall=20, gb_free=15.3, wall=48471
2023-01-09 17:05:45 - progress_bar.py[line:272] - INFO: epoch 005:   2446 / 3665 loss=5.015, loss_v1=0, loss_v2=0, nll_loss=4.097, ntokens=730, nsentences=32, sample_size=730, sample_size_v1=0, sample_size_v2=0, ppl=17.12, wps=372.4, ups=0.51, wpb=730, bsz=32, num_updates=17080, lr=2.84027e-05, gnorm=2.604, clip=100, loss_scale=256, train_wall=20, gb_free=15.3, wall=48491
2023-01-09 17:06:04 - progress_bar.py[line:272] - INFO: epoch 005:   2456 / 3665 loss=5.103, loss_v1=0, loss_v2=0, nll_loss=4.196, ntokens=958.6, nsentences=32, sample_size=958.6, sample_size_v1=0, sample_size_v2=0, ppl=18.33, wps=488.4, ups=0.51, wpb=958.6, bsz=32, num_updates=17090, lr=2.83881e-05, gnorm=2.04, clip=100, loss_scale=256, train_wall=20, gb_free=15.5, wall=48511
2023-01-09 17:06:24 - progress_bar.py[line:272] - INFO: epoch 005:   2466 / 3665 loss=5.144, loss_v1=0, loss_v2=0, nll_loss=4.241, ntokens=996.9, nsentences=32, sample_size=996.9, sample_size_v1=0, sample_size_v2=0, ppl=18.91, wps=506.7, ups=0.51, wpb=996.9, bsz=32, num_updates=17100, lr=2.83736e-05, gnorm=2.14, clip=100, loss_scale=256, train_wall=20, gb_free=15, wall=48530
2023-01-09 17:06:44 - progress_bar.py[line:272] - INFO: epoch 005:   2476 / 3665 loss=5.123, loss_v1=0, loss_v2=0, nll_loss=4.22, ntokens=839, nsentences=32, sample_size=839, sample_size_v1=0, sample_size_v2=0, ppl=18.63, wps=428, ups=0.51, wpb=839, bsz=32, num_updates=17110, lr=2.83591e-05, gnorm=2.327, clip=100, loss_scale=256, train_wall=20, gb_free=15.6, wall=48550
2023-01-09 17:07:03 - progress_bar.py[line:272] - INFO: epoch 005:   2486 / 3665 loss=5.076, loss_v1=0, loss_v2=0, nll_loss=4.168, ntokens=858.7, nsentences=32, sample_size=858.7, sample_size_v1=0, sample_size_v2=0, ppl=17.97, wps=438.1, ups=0.51, wpb=858.7, bsz=32, num_updates=17120, lr=2.83446e-05, gnorm=2.32, clip=100, loss_scale=256, train_wall=20, gb_free=15.4, wall=48569
2023-01-09 17:07:24 - progress_bar.py[line:272] - INFO: epoch 005:   2496 / 3665 loss=5.155, loss_v1=0, loss_v2=0, nll_loss=4.255, ntokens=1142.7, nsentences=32, sample_size=1142.7, sample_size_v1=0, sample_size_v2=0, ppl=19.09, wps=542.4, ups=0.47, wpb=1142.7, bsz=32, num_updates=17130, lr=2.83301e-05, gnorm=2.033, clip=100, loss_scale=256, train_wall=21, gb_free=14.3, wall=48591
2023-01-09 17:07:45 - progress_bar.py[line:272] - INFO: epoch 005:   2506 / 3665 loss=5.121, loss_v1=0, loss_v2=0, nll_loss=4.216, ntokens=835.2, nsentences=32, sample_size=835.2, sample_size_v1=0, sample_size_v2=0, ppl=18.59, wps=401.6, ups=0.48, wpb=835.2, bsz=32, num_updates=17140, lr=2.83156e-05, gnorm=2.463, clip=100, loss_scale=256, train_wall=21, gb_free=15.3, wall=48611
2023-01-09 17:08:05 - progress_bar.py[line:272] - INFO: epoch 005:   2516 / 3665 loss=5.123, loss_v1=0, loss_v2=0, nll_loss=4.22, ntokens=857.8, nsentences=32, sample_size=857.8, sample_size_v1=0, sample_size_v2=0, ppl=18.63, wps=437.4, ups=0.51, wpb=857.8, bsz=32, num_updates=17150, lr=2.83011e-05, gnorm=2.56, clip=100, loss_scale=256, train_wall=20, gb_free=15.4, wall=48631
2023-01-09 17:08:24 - progress_bar.py[line:272] - INFO: epoch 005:   2526 / 3665 loss=5.082, loss_v1=0, loss_v2=0, nll_loss=4.173, ntokens=982, nsentences=32, sample_size=982, sample_size_v1=0, sample_size_v2=0, ppl=18.04, wps=501.2, ups=0.51, wpb=982, bsz=32, num_updates=17160, lr=2.82866e-05, gnorm=2.025, clip=100, loss_scale=256, train_wall=20, gb_free=15.5, wall=48651
2023-01-09 17:08:44 - progress_bar.py[line:272] - INFO: epoch 005:   2536 / 3665 loss=5.247, loss_v1=0, loss_v2=0, nll_loss=4.356, ntokens=988.1, nsentences=32, sample_size=988.1, sample_size_v1=0, sample_size_v2=0, ppl=20.47, wps=501.3, ups=0.51, wpb=988.1, bsz=32, num_updates=17170, lr=2.8272e-05, gnorm=1.999, clip=100, loss_scale=256, train_wall=20, gb_free=15.4, wall=48670
2023-01-09 17:09:04 - progress_bar.py[line:272] - INFO: epoch 005:   2546 / 3665 loss=5.086, loss_v1=0, loss_v2=0, nll_loss=4.179, ntokens=890.5, nsentences=32, sample_size=890.5, sample_size_v1=0, sample_size_v2=0, ppl=18.12, wps=446.5, ups=0.5, wpb=890.5, bsz=32, num_updates=17180, lr=2.82575e-05, gnorm=2.339, clip=100, loss_scale=256, train_wall=20, gb_free=15.1, wall=48690
2023-01-09 17:09:24 - progress_bar.py[line:272] - INFO: epoch 005:   2556 / 3665 loss=5.075, loss_v1=0, loss_v2=0, nll_loss=4.168, ntokens=1098.5, nsentences=32, sample_size=1098.5, sample_size_v1=0, sample_size_v2=0, ppl=17.98, wps=551.4, ups=0.5, wpb=1098.5, bsz=32, num_updates=17190, lr=2.8243e-05, gnorm=1.871, clip=100, loss_scale=256, train_wall=20, gb_free=14.8, wall=48710
2023-01-09 17:09:44 - progress_bar.py[line:272] - INFO: epoch 005:   2566 / 3665 loss=5.139, loss_v1=0, loss_v2=0, nll_loss=4.237, ntokens=921.6, nsentences=32, sample_size=921.6, sample_size_v1=0, sample_size_v2=0, ppl=18.86, wps=459.8, ups=0.5, wpb=921.6, bsz=32, num_updates=17200, lr=2.82285e-05, gnorm=2.389, clip=100, loss_scale=256, train_wall=20, gb_free=15.6, wall=48730
2023-01-09 17:10:04 - progress_bar.py[line:272] - INFO: epoch 005:   2576 / 3665 loss=5.001, loss_v1=0, loss_v2=0, nll_loss=4.082, ntokens=689.5, nsentences=32, sample_size=689.5, sample_size_v1=0, sample_size_v2=0, ppl=16.94, wps=335.3, ups=0.49, wpb=689.5, bsz=32, num_updates=17210, lr=2.8214e-05, gnorm=2.923, clip=100, loss_scale=256, train_wall=21, gb_free=15.5, wall=48751
2023-01-09 17:10:26 - progress_bar.py[line:272] - INFO: epoch 005:   2586 / 3665 loss=5.049, loss_v1=0, loss_v2=0, nll_loss=4.137, ntokens=945.6, nsentences=32, sample_size=945.6, sample_size_v1=0, sample_size_v2=0, ppl=17.59, wps=446.7, ups=0.47, wpb=945.6, bsz=32, num_updates=17220, lr=2.81995e-05, gnorm=2.153, clip=100, loss_scale=256, train_wall=21, gb_free=15.4, wall=48772
2023-01-09 17:10:47 - progress_bar.py[line:272] - INFO: epoch 005:   2596 / 3665 loss=5.129, loss_v1=0, loss_v2=0, nll_loss=4.227, ntokens=923.6, nsentences=32, sample_size=923.6, sample_size_v1=0, sample_size_v2=0, ppl=18.72, wps=436.4, ups=0.47, wpb=923.6, bsz=32, num_updates=17230, lr=2.8185e-05, gnorm=2.148, clip=100, loss_scale=256, train_wall=21, gb_free=15.2, wall=48793
2023-01-09 17:11:08 - progress_bar.py[line:272] - INFO: epoch 005:   2606 / 3665 loss=5.049, loss_v1=0, loss_v2=0, nll_loss=4.137, ntokens=818.5, nsentences=32, sample_size=818.5, sample_size_v1=0, sample_size_v2=0, ppl=17.59, wps=380.5, ups=0.46, wpb=818.5, bsz=32, num_updates=17240, lr=2.81704e-05, gnorm=2.589, clip=100, loss_scale=256, train_wall=21, gb_free=15.4, wall=48815
2023-01-09 17:11:30 - progress_bar.py[line:272] - INFO: epoch 005:   2616 / 3665 loss=5.169, loss_v1=0, loss_v2=0, nll_loss=4.27, ntokens=1152.9, nsentences=32, sample_size=1152.9, sample_size_v1=0, sample_size_v2=0, ppl=19.29, wps=530.7, ups=0.46, wpb=1152.9, bsz=32, num_updates=17250, lr=2.81559e-05, gnorm=1.984, clip=100, loss_scale=256, train_wall=22, gb_free=15, wall=48836
2023-01-09 17:11:52 - progress_bar.py[line:272] - INFO: epoch 005:   2626 / 3665 loss=5.236, loss_v1=0, loss_v2=0, nll_loss=4.345, ntokens=1117.8, nsentences=32, sample_size=1117.8, sample_size_v1=0, sample_size_v2=0, ppl=20.32, wps=515.5, ups=0.46, wpb=1117.8, bsz=32, num_updates=17260, lr=2.81414e-05, gnorm=1.891, clip=100, loss_scale=256, train_wall=22, gb_free=15.1, wall=48858
2023-01-09 17:12:13 - progress_bar.py[line:272] - INFO: epoch 005:   2636 / 3665 loss=5.173, loss_v1=0, loss_v2=0, nll_loss=4.275, ntokens=846.6, nsentences=32, sample_size=846.6, sample_size_v1=0, sample_size_v2=0, ppl=19.36, wps=395.9, ups=0.47, wpb=846.6, bsz=32, num_updates=17270, lr=2.81269e-05, gnorm=2.511, clip=100, loss_scale=256, train_wall=21, gb_free=15.1, wall=48879
2023-01-09 17:12:33 - progress_bar.py[line:272] - INFO: epoch 005:   2646 / 3665 loss=5.096, loss_v1=0, loss_v2=0, nll_loss=4.191, ntokens=1002.1, nsentences=32, sample_size=1002.1, sample_size_v1=0, sample_size_v2=0, ppl=18.27, wps=491.2, ups=0.49, wpb=1002.1, bsz=32, num_updates=17280, lr=2.81124e-05, gnorm=2.287, clip=100, loss_scale=256, train_wall=20, gb_free=15.4, wall=48900
2023-01-09 17:12:53 - progress_bar.py[line:272] - INFO: epoch 005:   2656 / 3665 loss=5.153, loss_v1=0, loss_v2=0, nll_loss=4.254, ntokens=1072.7, nsentences=32, sample_size=1072.7, sample_size_v1=0, sample_size_v2=0, ppl=19.08, wps=537.1, ups=0.5, wpb=1072.7, bsz=32, num_updates=17290, lr=2.80979e-05, gnorm=2.015, clip=100, loss_scale=256, train_wall=20, gb_free=15.6, wall=48920
2023-01-09 17:13:13 - progress_bar.py[line:272] - INFO: epoch 005:   2666 / 3665 loss=5.092, loss_v1=0, loss_v2=0, nll_loss=4.181, ntokens=786.6, nsentences=32, sample_size=786.6, sample_size_v1=0, sample_size_v2=0, ppl=18.13, wps=398, ups=0.51, wpb=786.6, bsz=32, num_updates=17300, lr=2.80834e-05, gnorm=2.564, clip=100, loss_scale=256, train_wall=20, gb_free=15.7, wall=48939
2023-01-09 17:13:33 - progress_bar.py[line:272] - INFO: epoch 005:   2676 / 3665 loss=5.095, loss_v1=0, loss_v2=0, nll_loss=4.186, ntokens=833.5, nsentences=32, sample_size=833.5, sample_size_v1=0, sample_size_v2=0, ppl=18.21, wps=419.9, ups=0.5, wpb=833.5, bsz=32, num_updates=17310, lr=2.80689e-05, gnorm=2.776, clip=100, loss_scale=256, train_wall=20, gb_free=15.5, wall=48959
2023-01-09 17:13:53 - progress_bar.py[line:272] - INFO: epoch 005:   2686 / 3665 loss=5.119, loss_v1=0, loss_v2=0, nll_loss=4.215, ntokens=1093.4, nsentences=32, sample_size=1093.4, sample_size_v1=0, sample_size_v2=0, ppl=18.57, wps=549, ups=0.5, wpb=1093.4, bsz=32, num_updates=17320, lr=2.80543e-05, gnorm=1.949, clip=100, loss_scale=256, train_wall=20, gb_free=14.8, wall=48979
2023-01-09 17:14:13 - progress_bar.py[line:272] - INFO: epoch 005:   2696 / 3665 loss=5.067, loss_v1=0, loss_v2=0, nll_loss=4.159, ntokens=801.2, nsentences=32, sample_size=801.2, sample_size_v1=0, sample_size_v2=0, ppl=17.87, wps=403.3, ups=0.5, wpb=801.2, bsz=32, num_updates=17330, lr=2.80398e-05, gnorm=2.451, clip=100, loss_scale=256, train_wall=20, gb_free=15.4, wall=48999
2023-01-09 17:14:33 - progress_bar.py[line:272] - INFO: epoch 005:   2706 / 3665 loss=5.077, loss_v1=0, loss_v2=0, nll_loss=4.167, ntokens=847.2, nsentences=32, sample_size=847.2, sample_size_v1=0, sample_size_v2=0, ppl=17.96, wps=426.3, ups=0.5, wpb=847.2, bsz=32, num_updates=17340, lr=2.80253e-05, gnorm=2.64, clip=100, loss_scale=256, train_wall=20, gb_free=15.4, wall=49019
2023-01-09 17:14:53 - progress_bar.py[line:272] - INFO: epoch 005:   2716 / 3665 loss=5.019, loss_v1=0, loss_v2=0, nll_loss=4.103, ntokens=1026.4, nsentences=32, sample_size=1026.4, sample_size_v1=0, sample_size_v2=0, ppl=17.18, wps=514.1, ups=0.5, wpb=1026.4, bsz=32, num_updates=17350, lr=2.80108e-05, gnorm=2.054, clip=100, loss_scale=256, train_wall=20, gb_free=15.4, wall=49039
2023-01-09 17:15:13 - progress_bar.py[line:272] - INFO: epoch 005:   2726 / 3665 loss=5.203, loss_v1=0, loss_v2=0, nll_loss=4.309, ntokens=972.8, nsentences=32, sample_size=972.8, sample_size_v1=0, sample_size_v2=0, ppl=19.82, wps=489.1, ups=0.5, wpb=972.8, bsz=32, num_updates=17360, lr=2.79963e-05, gnorm=2.312, clip=100, loss_scale=256, train_wall=20, gb_free=15.4, wall=49059
2023-01-09 17:15:32 - progress_bar.py[line:272] - INFO: epoch 005:   2736 / 3665 loss=5.118, loss_v1=0, loss_v2=0, nll_loss=4.214, ntokens=849.7, nsentences=32, sample_size=849.7, sample_size_v1=0, sample_size_v2=0, ppl=18.56, wps=428.6, ups=0.5, wpb=849.7, bsz=32, num_updates=17370, lr=2.79818e-05, gnorm=2.445, clip=100, loss_scale=256, train_wall=20, gb_free=15.1, wall=49079
2023-01-09 17:15:52 - progress_bar.py[line:272] - INFO: epoch 005:   2746 / 3665 loss=5.066, loss_v1=0, loss_v2=0, nll_loss=4.155, ntokens=913.2, nsentences=32, sample_size=913.2, sample_size_v1=0, sample_size_v2=0, ppl=17.81, wps=460.6, ups=0.5, wpb=913.2, bsz=32, num_updates=17380, lr=2.79673e-05, gnorm=2.179, clip=100, loss_scale=256, train_wall=20, gb_free=15.2, wall=49098
2023-01-09 17:16:12 - progress_bar.py[line:272] - INFO: epoch 005:   2756 / 3665 loss=5.144, loss_v1=0, loss_v2=0, nll_loss=4.243, ntokens=936.3, nsentences=32, sample_size=936.3, sample_size_v1=0, sample_size_v2=0, ppl=18.93, wps=470.9, ups=0.5, wpb=936.3, bsz=32, num_updates=17390, lr=2.79527e-05, gnorm=2.23, clip=100, loss_scale=256, train_wall=20, gb_free=15.3, wall=49118
2023-01-09 17:16:32 - progress_bar.py[line:272] - INFO: epoch 005:   2766 / 3665 loss=5.05, loss_v1=0, loss_v2=0, nll_loss=4.139, ntokens=748.9, nsentences=32, sample_size=748.9, sample_size_v1=0, sample_size_v2=0, ppl=17.62, wps=379.1, ups=0.51, wpb=748.9, bsz=32, num_updates=17400, lr=2.79382e-05, gnorm=2.614, clip=100, loss_scale=512, train_wall=20, gb_free=15.6, wall=49138
2023-01-09 17:16:52 - progress_bar.py[line:272] - INFO: epoch 005:   2776 / 3665 loss=5.108, loss_v1=0, loss_v2=0, nll_loss=4.203, ntokens=1028.4, nsentences=32, sample_size=1028.4, sample_size_v1=0, sample_size_v2=0, ppl=18.42, wps=518, ups=0.5, wpb=1028.4, bsz=32, num_updates=17410, lr=2.79237e-05, gnorm=2.073, clip=100, loss_scale=512, train_wall=20, gb_free=15.3, wall=49158
2023-01-09 17:17:12 - progress_bar.py[line:272] - INFO: epoch 005:   2786 / 3665 loss=5.195, loss_v1=0, loss_v2=0, nll_loss=4.3, ntokens=1073.5, nsentences=32, sample_size=1073.5, sample_size_v1=0, sample_size_v2=0, ppl=19.69, wps=539.1, ups=0.5, wpb=1073.5, bsz=32, num_updates=17420, lr=2.79092e-05, gnorm=2.003, clip=100, loss_scale=512, train_wall=20, gb_free=15.4, wall=49178
2023-01-09 17:17:31 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 256.0
2023-01-09 17:17:33 - progress_bar.py[line:272] - INFO: epoch 005:   2797 / 3665 loss=5.013, loss_v1=0, loss_v2=0, nll_loss=4.096, ntokens=774.4, nsentences=32, sample_size=774.4, sample_size_v1=0, sample_size_v2=0, ppl=17.1, wps=356, ups=0.46, wpb=774.4, bsz=32, num_updates=17430, lr=2.78947e-05, gnorm=2.344, clip=100, loss_scale=256, train_wall=22, gb_free=15.1, wall=49200
2023-01-09 17:17:53 - progress_bar.py[line:272] - INFO: epoch 005:   2807 / 3665 loss=5.131, loss_v1=0, loss_v2=0, nll_loss=4.23, ntokens=1024.8, nsentences=32, sample_size=1024.8, sample_size_v1=0, sample_size_v2=0, ppl=18.76, wps=515.8, ups=0.5, wpb=1024.8, bsz=32, num_updates=17440, lr=2.78802e-05, gnorm=2.189, clip=100, loss_scale=256, train_wall=20, gb_free=15.3, wall=49219
2023-01-09 17:18:13 - progress_bar.py[line:272] - INFO: epoch 005:   2817 / 3665 loss=5.09, loss_v1=0, loss_v2=0, nll_loss=4.181, ntokens=992.4, nsentences=32, sample_size=992.4, sample_size_v1=0, sample_size_v2=0, ppl=18.14, wps=499.8, ups=0.5, wpb=992.4, bsz=32, num_updates=17450, lr=2.78657e-05, gnorm=2.016, clip=100, loss_scale=256, train_wall=20, gb_free=15.4, wall=49239
2023-01-09 17:18:33 - progress_bar.py[line:272] - INFO: epoch 005:   2827 / 3665 loss=5.133, loss_v1=0, loss_v2=0, nll_loss=4.231, ntokens=842.8, nsentences=32, sample_size=842.8, sample_size_v1=0, sample_size_v2=0, ppl=18.77, wps=426.1, ups=0.51, wpb=842.8, bsz=32, num_updates=17460, lr=2.78512e-05, gnorm=2.499, clip=100, loss_scale=256, train_wall=20, gb_free=15.4, wall=49259
2023-01-09 17:18:53 - progress_bar.py[line:272] - INFO: epoch 005:   2837 / 3665 loss=5.117, loss_v1=0, loss_v2=0, nll_loss=4.215, ntokens=995, nsentences=32, sample_size=995, sample_size_v1=0, sample_size_v2=0, ppl=18.57, wps=501.4, ups=0.5, wpb=995, bsz=32, num_updates=17470, lr=2.78366e-05, gnorm=2.093, clip=100, loss_scale=256, train_wall=20, gb_free=15.5, wall=49279
2023-01-09 17:19:13 - progress_bar.py[line:272] - INFO: epoch 005:   2847 / 3665 loss=5.154, loss_v1=0, loss_v2=0, nll_loss=4.252, ntokens=1030.9, nsentences=32, sample_size=1030.9, sample_size_v1=0, sample_size_v2=0, ppl=19.05, wps=519, ups=0.5, wpb=1030.9, bsz=32, num_updates=17480, lr=2.78221e-05, gnorm=2.155, clip=100, loss_scale=256, train_wall=20, gb_free=15.3, wall=49299
2023-01-09 17:19:32 - progress_bar.py[line:272] - INFO: epoch 005:   2857 / 3665 loss=5.073, loss_v1=0, loss_v2=0, nll_loss=4.161, ntokens=774.5, nsentences=32, sample_size=774.5, sample_size_v1=0, sample_size_v2=0, ppl=17.89, wps=392.2, ups=0.51, wpb=774.5, bsz=32, num_updates=17490, lr=2.78076e-05, gnorm=2.525, clip=100, loss_scale=256, train_wall=20, gb_free=15.2, wall=49319
2023-01-09 17:19:52 - progress_bar.py[line:272] - INFO: epoch 005:   2867 / 3665 loss=5.011, loss_v1=0, loss_v2=0, nll_loss=4.095, ntokens=789.3, nsentences=32, sample_size=789.3, sample_size_v1=0, sample_size_v2=0, ppl=17.09, wps=397, ups=0.5, wpb=789.3, bsz=32, num_updates=17500, lr=2.77931e-05, gnorm=2.372, clip=100, loss_scale=256, train_wall=20, gb_free=15.6, wall=49338
2023-01-09 17:19:52 - train.py[line:445] - INFO: begin validation on "valid" subset
slice_id 0 seek offset 0
slice_id 0 seek offset 0
2023-01-09 17:24:34 - progress_bar.py[line:282] - INFO: epoch 005 | valid on 'valid' subset | loss 5.095 | loss_v1 0 | loss_v2 0 | nll_loss 4.174 | ntokens 116.649 | nsentences 4 | sample_size 116.649 | sample_size_v1 0 | sample_size_v2 0 | AP 0 | total positives 21.6446 | TP 0 | FP 4.81099 | ppl 18.05 | wps 517.4 | wpb 116.6 | bsz 4 | num_updates 17500 | best_AP 0
2023-01-09 17:24:34 - checkpoint_utils.py[line:64] - INFO: Preparing to save checkpoint for epoch 5 @ 17500 updates
2023-01-09 17:24:34 - trainer.py[line:431] - INFO: Saving checkpoint to ../../checkpoints/OFA/detection_checkpoints/10_5e-5_512/checkpoint_5_17500.pt
2023-01-09 17:24:37 - trainer.py[line:441] - INFO: Finished saving checkpoint to ../../checkpoints/OFA/detection_checkpoints/10_5e-5_512/checkpoint_5_17500.pt
2023-01-09 17:25:46 - checkpoint_utils.py[line:133] - INFO: Saved checkpoint ../../checkpoints/OFA/detection_checkpoints/10_5e-5_512/checkpoint_5_17500.pt (epoch 5 @ 17500 updates, score 0.0) (writing took 71.96269916417077 seconds)
2023-01-09 17:26:05 - progress_bar.py[line:272] - INFO: epoch 005:   2877 / 3665 loss=5.143, loss_v1=0, loss_v2=0, nll_loss=4.244, ntokens=1061.2, nsentences=32, sample_size=1061.2, sample_size_v1=0, sample_size_v2=0, ppl=18.95, wps=28.5, ups=0.03, wpb=1061.2, bsz=32, num_updates=17510, lr=2.77786e-05, gnorm=2.041, clip=100, loss_scale=256, train_wall=19, gb_free=15.1, wall=49711
2023-01-09 17:26:25 - progress_bar.py[line:272] - INFO: epoch 005:   2887 / 3665 loss=5.149, loss_v1=0, loss_v2=0, nll_loss=4.245, ntokens=783.2, nsentences=32, sample_size=783.2, sample_size_v1=0, sample_size_v2=0, ppl=18.96, wps=403, ups=0.51, wpb=783.2, bsz=32, num_updates=17520, lr=2.77641e-05, gnorm=2.518, clip=100, loss_scale=256, train_wall=19, gb_free=15.5, wall=49731
2023-01-09 17:26:44 - progress_bar.py[line:272] - INFO: epoch 005:   2897 / 3665 loss=5.016, loss_v1=0, loss_v2=0, nll_loss=4.099, ntokens=783.1, nsentences=32, sample_size=783.1, sample_size_v1=0, sample_size_v2=0, ppl=17.13, wps=401.9, ups=0.51, wpb=783.1, bsz=32, num_updates=17530, lr=2.77496e-05, gnorm=2.727, clip=100, loss_scale=256, train_wall=19, gb_free=15.4, wall=49750
2023-01-09 17:27:04 - progress_bar.py[line:272] - INFO: epoch 005:   2907 / 3665 loss=5.098, loss_v1=0, loss_v2=0, nll_loss=4.193, ntokens=1025.9, nsentences=32, sample_size=1025.9, sample_size_v1=0, sample_size_v2=0, ppl=18.29, wps=521.3, ups=0.51, wpb=1025.9, bsz=32, num_updates=17540, lr=2.7735e-05, gnorm=2.118, clip=100, loss_scale=256, train_wall=20, gb_free=15.1, wall=49770
2023-01-09 17:27:23 - progress_bar.py[line:272] - INFO: epoch 005:   2917 / 3665 loss=5.177, loss_v1=0, loss_v2=0, nll_loss=4.282, ntokens=1045.4, nsentences=32, sample_size=1045.4, sample_size_v1=0, sample_size_v2=0, ppl=19.45, wps=531.7, ups=0.51, wpb=1045.4, bsz=32, num_updates=17550, lr=2.77205e-05, gnorm=2.113, clip=100, loss_scale=256, train_wall=20, gb_free=15.2, wall=49790
2023-01-09 17:27:43 - progress_bar.py[line:272] - INFO: epoch 005:   2927 / 3665 loss=5.071, loss_v1=0, loss_v2=0, nll_loss=4.16, ntokens=770.7, nsentences=32, sample_size=770.7, sample_size_v1=0, sample_size_v2=0, ppl=17.87, wps=394.4, ups=0.51, wpb=770.7, bsz=32, num_updates=17560, lr=2.7706e-05, gnorm=2.671, clip=100, loss_scale=256, train_wall=20, gb_free=15.4, wall=49809
2023-01-09 17:28:03 - progress_bar.py[line:272] - INFO: epoch 005:   2937 / 3665 loss=5.048, loss_v1=0, loss_v2=0, nll_loss=4.135, ntokens=1032, nsentences=32, sample_size=1032, sample_size_v1=0, sample_size_v2=0, ppl=17.57, wps=525.4, ups=0.51, wpb=1032, bsz=32, num_updates=17570, lr=2.76915e-05, gnorm=1.943, clip=100, loss_scale=256, train_wall=20, gb_free=15.5, wall=49829
2023-01-09 17:28:22 - progress_bar.py[line:272] - INFO: epoch 005:   2947 / 3665 loss=5.207, loss_v1=0, loss_v2=0, nll_loss=4.312, ntokens=1155.9, nsentences=32, sample_size=1155.9, sample_size_v1=0, sample_size_v2=0, ppl=19.87, wps=585.6, ups=0.51, wpb=1155.9, bsz=32, num_updates=17580, lr=2.7677e-05, gnorm=1.912, clip=100, loss_scale=256, train_wall=20, gb_free=15.3, wall=49849
2023-01-09 17:28:42 - progress_bar.py[line:272] - INFO: epoch 005:   2957 / 3665 loss=5.101, loss_v1=0, loss_v2=0, nll_loss=4.197, ntokens=854.9, nsentences=32, sample_size=854.9, sample_size_v1=0, sample_size_v2=0, ppl=18.34, wps=436.1, ups=0.51, wpb=854.9, bsz=32, num_updates=17590, lr=2.76625e-05, gnorm=2.393, clip=100, loss_scale=256, train_wall=20, gb_free=15.5, wall=49868
2023-01-09 17:29:02 - progress_bar.py[line:272] - INFO: epoch 005:   2967 / 3665 loss=5.124, loss_v1=0, loss_v2=0, nll_loss=4.219, ntokens=1035, nsentences=32, sample_size=1035, sample_size_v1=0, sample_size_v2=0, ppl=18.63, wps=527.1, ups=0.51, wpb=1035, bsz=32, num_updates=17600, lr=2.7648e-05, gnorm=1.923, clip=100, loss_scale=256, train_wall=20, gb_free=15.5, wall=49888
2023-01-09 17:29:21 - progress_bar.py[line:272] - INFO: epoch 005:   2977 / 3665 loss=5.19, loss_v1=0, loss_v2=0, nll_loss=4.293, ntokens=1056, nsentences=32, sample_size=1056, sample_size_v1=0, sample_size_v2=0, ppl=19.6, wps=536.1, ups=0.51, wpb=1056, bsz=32, num_updates=17610, lr=2.76335e-05, gnorm=2.167, clip=100, loss_scale=256, train_wall=20, gb_free=15.4, wall=49907
2023-01-09 17:29:41 - progress_bar.py[line:272] - INFO: epoch 005:   2987 / 3665 loss=5.067, loss_v1=0, loss_v2=0, nll_loss=4.158, ntokens=862.3, nsentences=32, sample_size=862.3, sample_size_v1=0, sample_size_v2=0, ppl=17.85, wps=434.4, ups=0.5, wpb=862.3, bsz=32, num_updates=17620, lr=2.76189e-05, gnorm=2.48, clip=100, loss_scale=256, train_wall=20, gb_free=15.5, wall=49927
2023-01-09 17:30:01 - progress_bar.py[line:272] - INFO: epoch 005:   2997 / 3665 loss=5.071, loss_v1=0, loss_v2=0, nll_loss=4.161, ntokens=960.5, nsentences=32, sample_size=960.5, sample_size_v1=0, sample_size_v2=0, ppl=17.89, wps=487.3, ups=0.51, wpb=960.5, bsz=32, num_updates=17630, lr=2.76044e-05, gnorm=2.063, clip=100, loss_scale=256, train_wall=20, gb_free=15.6, wall=49947
2023-01-09 17:30:21 - progress_bar.py[line:272] - INFO: epoch 005:   3007 / 3665 loss=5.063, loss_v1=0, loss_v2=0, nll_loss=4.152, ntokens=1024.5, nsentences=32, sample_size=1024.5, sample_size_v1=0, sample_size_v2=0, ppl=17.78, wps=514.8, ups=0.5, wpb=1024.5, bsz=32, num_updates=17640, lr=2.75899e-05, gnorm=2.115, clip=100, loss_scale=256, train_wall=20, gb_free=15.5, wall=49967
2023-01-09 17:30:41 - progress_bar.py[line:272] - INFO: epoch 005:   3017 / 3665 loss=4.971, loss_v1=0, loss_v2=0, nll_loss=4.049, ntokens=681.4, nsentences=32, sample_size=681.4, sample_size_v1=0, sample_size_v2=0, ppl=16.56, wps=338, ups=0.5, wpb=681.4, bsz=32, num_updates=17650, lr=2.75754e-05, gnorm=2.717, clip=100, loss_scale=256, train_wall=20, gb_free=15.4, wall=49987
2023-01-09 17:31:01 - progress_bar.py[line:272] - INFO: epoch 005:   3027 / 3665 loss=5.051, loss_v1=0, loss_v2=0, nll_loss=4.139, ntokens=1006.8, nsentences=32, sample_size=1006.8, sample_size_v1=0, sample_size_v2=0, ppl=17.62, wps=496.8, ups=0.49, wpb=1006.8, bsz=32, num_updates=17660, lr=2.75609e-05, gnorm=2.186, clip=100, loss_scale=256, train_wall=20, gb_free=15.5, wall=50007
2023-01-09 17:31:21 - progress_bar.py[line:272] - INFO: epoch 005:   3037 / 3665 loss=5.094, loss_v1=0, loss_v2=0, nll_loss=4.186, ntokens=1077.7, nsentences=32, sample_size=1077.7, sample_size_v1=0, sample_size_v2=0, ppl=18.21, wps=535.1, ups=0.5, wpb=1077.7, bsz=32, num_updates=17670, lr=2.75464e-05, gnorm=2.137, clip=100, loss_scale=256, train_wall=20, gb_free=15.6, wall=50028
2023-01-09 17:31:41 - progress_bar.py[line:272] - INFO: epoch 005:   3047 / 3665 loss=5.133, loss_v1=0, loss_v2=0, nll_loss=4.231, ntokens=796.8, nsentences=32, sample_size=796.8, sample_size_v1=0, sample_size_v2=0, ppl=18.77, wps=405.3, ups=0.51, wpb=796.8, bsz=32, num_updates=17680, lr=2.75319e-05, gnorm=2.356, clip=100, loss_scale=256, train_wall=20, gb_free=15, wall=50047
2023-01-09 17:32:00 - progress_bar.py[line:272] - INFO: epoch 005:   3057 / 3665 loss=4.984, loss_v1=0, loss_v2=0, nll_loss=4.063, ntokens=874.8, nsentences=32, sample_size=874.8, sample_size_v1=0, sample_size_v2=0, ppl=16.72, wps=447.2, ups=0.51, wpb=874.8, bsz=32, num_updates=17690, lr=2.75173e-05, gnorm=2.291, clip=100, loss_scale=256, train_wall=20, gb_free=15.4, wall=50067
2023-01-09 17:32:20 - progress_bar.py[line:272] - INFO: epoch 005:   3067 / 3665 loss=5.092, loss_v1=0, loss_v2=0, nll_loss=4.186, ntokens=1068.2, nsentences=32, sample_size=1068.2, sample_size_v1=0, sample_size_v2=0, ppl=18.2, wps=542.1, ups=0.51, wpb=1068.2, bsz=32, num_updates=17700, lr=2.75028e-05, gnorm=1.868, clip=100, loss_scale=256, train_wall=20, gb_free=14.7, wall=50086
2023-01-09 17:32:40 - progress_bar.py[line:272] - INFO: epoch 005:   3077 / 3665 loss=5.181, loss_v1=0, loss_v2=0, nll_loss=4.285, ntokens=887.8, nsentences=32, sample_size=887.8, sample_size_v1=0, sample_size_v2=0, ppl=19.49, wps=452.4, ups=0.51, wpb=887.8, bsz=32, num_updates=17710, lr=2.74883e-05, gnorm=2.426, clip=100, loss_scale=256, train_wall=20, gb_free=15.6, wall=50106
2023-01-09 17:32:59 - progress_bar.py[line:272] - INFO: epoch 005:   3087 / 3665 loss=5.072, loss_v1=0, loss_v2=0, nll_loss=4.163, ntokens=922.7, nsentences=32, sample_size=922.7, sample_size_v1=0, sample_size_v2=0, ppl=17.92, wps=468.8, ups=0.51, wpb=922.7, bsz=32, num_updates=17720, lr=2.74738e-05, gnorm=2.444, clip=100, loss_scale=256, train_wall=20, gb_free=15.3, wall=50126
2023-01-09 17:33:19 - progress_bar.py[line:272] - INFO: epoch 005:   3097 / 3665 loss=5.1, loss_v1=0, loss_v2=0, nll_loss=4.194, ntokens=975.1, nsentences=32, sample_size=975.1, sample_size_v1=0, sample_size_v2=0, ppl=18.3, wps=495.5, ups=0.51, wpb=975.1, bsz=32, num_updates=17730, lr=2.74593e-05, gnorm=2.178, clip=100, loss_scale=256, train_wall=20, gb_free=15.6, wall=50145
2023-01-09 17:33:39 - progress_bar.py[line:272] - INFO: epoch 005:   3107 / 3665 loss=5.217, loss_v1=0, loss_v2=0, nll_loss=4.323, ntokens=1001.4, nsentences=32, sample_size=1001.4, sample_size_v1=0, sample_size_v2=0, ppl=20.02, wps=507.9, ups=0.51, wpb=1001.4, bsz=32, num_updates=17740, lr=2.74448e-05, gnorm=2.067, clip=100, loss_scale=256, train_wall=20, gb_free=15.5, wall=50165
2023-01-09 17:33:59 - progress_bar.py[line:272] - INFO: epoch 005:   3117 / 3665 loss=5.113, loss_v1=0, loss_v2=0, nll_loss=4.208, ntokens=824.5, nsentences=32, sample_size=824.5, sample_size_v1=0, sample_size_v2=0, ppl=18.48, wps=419.7, ups=0.51, wpb=824.5, bsz=32, num_updates=17750, lr=2.74303e-05, gnorm=2.418, clip=100, loss_scale=256, train_wall=20, gb_free=15.7, wall=50185
2023-01-09 17:34:18 - progress_bar.py[line:272] - INFO: epoch 005:   3127 / 3665 loss=5.125, loss_v1=0, loss_v2=0, nll_loss=4.222, ntokens=1024.3, nsentences=32, sample_size=1024.3, sample_size_v1=0, sample_size_v2=0, ppl=18.66, wps=519.4, ups=0.51, wpb=1024.3, bsz=32, num_updates=17760, lr=2.74157e-05, gnorm=2.1, clip=100, loss_scale=256, train_wall=20, gb_free=15.4, wall=50205
2023-01-09 17:34:38 - progress_bar.py[line:272] - INFO: epoch 005:   3137 / 3665 loss=5.175, loss_v1=0, loss_v2=0, nll_loss=4.277, ntokens=1018.4, nsentences=32, sample_size=1018.4, sample_size_v1=0, sample_size_v2=0, ppl=19.39, wps=514.1, ups=0.5, wpb=1018.4, bsz=32, num_updates=17770, lr=2.74012e-05, gnorm=2.118, clip=100, loss_scale=256, train_wall=20, gb_free=15, wall=50224
2023-01-09 17:34:58 - progress_bar.py[line:272] - INFO: epoch 005:   3147 / 3665 loss=5.14, loss_v1=0, loss_v2=0, nll_loss=4.24, ntokens=818.5, nsentences=32, sample_size=818.5, sample_size_v1=0, sample_size_v2=0, ppl=18.89, wps=411.4, ups=0.5, wpb=818.5, bsz=32, num_updates=17780, lr=2.73867e-05, gnorm=2.555, clip=100, loss_scale=256, train_wall=20, gb_free=15.5, wall=50244
2023-01-09 17:35:18 - progress_bar.py[line:272] - INFO: epoch 005:   3157 / 3665 loss=5.049, loss_v1=0, loss_v2=0, nll_loss=4.138, ntokens=941.1, nsentences=32, sample_size=941.1, sample_size_v1=0, sample_size_v2=0, ppl=17.6, wps=471.2, ups=0.5, wpb=941.1, bsz=32, num_updates=17790, lr=2.73722e-05, gnorm=2.459, clip=100, loss_scale=256, train_wall=20, gb_free=15.7, wall=50264
2023-01-09 17:35:38 - progress_bar.py[line:272] - INFO: epoch 005:   3167 / 3665 loss=5.206, loss_v1=0, loss_v2=0, nll_loss=4.309, ntokens=987.2, nsentences=32, sample_size=987.2, sample_size_v1=0, sample_size_v2=0, ppl=19.83, wps=492, ups=0.5, wpb=987.2, bsz=32, num_updates=17800, lr=2.73577e-05, gnorm=2.075, clip=100, loss_scale=256, train_wall=20, gb_free=15.1, wall=50284
2023-01-09 17:35:58 - progress_bar.py[line:272] - INFO: epoch 005:   3177 / 3665 loss=5.121, loss_v1=0, loss_v2=0, nll_loss=4.219, ntokens=816.9, nsentences=32, sample_size=816.9, sample_size_v1=0, sample_size_v2=0, ppl=18.62, wps=409, ups=0.5, wpb=816.9, bsz=32, num_updates=17810, lr=2.73432e-05, gnorm=2.694, clip=100, loss_scale=256, train_wall=20, gb_free=15.3, wall=50304
2023-01-09 17:36:18 - progress_bar.py[line:272] - INFO: epoch 005:   3187 / 3665 loss=5.023, loss_v1=0, loss_v2=0, nll_loss=4.107, ntokens=878.1, nsentences=32, sample_size=878.1, sample_size_v1=0, sample_size_v2=0, ppl=17.23, wps=439.3, ups=0.5, wpb=878.1, bsz=32, num_updates=17820, lr=2.73287e-05, gnorm=2.471, clip=100, loss_scale=256, train_wall=20, gb_free=15.3, wall=50324
2023-01-09 17:36:38 - progress_bar.py[line:272] - INFO: epoch 005:   3197 / 3665 loss=5.131, loss_v1=0, loss_v2=0, nll_loss=4.228, ntokens=1021.8, nsentences=32, sample_size=1021.8, sample_size_v1=0, sample_size_v2=0, ppl=18.73, wps=513.9, ups=0.5, wpb=1021.8, bsz=32, num_updates=17830, lr=2.73142e-05, gnorm=2.152, clip=100, loss_scale=256, train_wall=20, gb_free=15.6, wall=50344
2023-01-09 17:36:58 - progress_bar.py[line:272] - INFO: epoch 005:   3207 / 3665 loss=5.03, loss_v1=0, loss_v2=0, nll_loss=4.115, ntokens=810.4, nsentences=32, sample_size=810.4, sample_size_v1=0, sample_size_v2=0, ppl=17.33, wps=411.1, ups=0.51, wpb=810.4, bsz=32, num_updates=17840, lr=2.72996e-05, gnorm=2.36, clip=100, loss_scale=256, train_wall=20, gb_free=15.6, wall=50364
2023-01-09 17:37:17 - progress_bar.py[line:272] - INFO: epoch 005:   3217 / 3665 loss=5.131, loss_v1=0, loss_v2=0, nll_loss=4.228, ntokens=1083.9, nsentences=32, sample_size=1083.9, sample_size_v1=0, sample_size_v2=0, ppl=18.74, wps=548.2, ups=0.51, wpb=1083.9, bsz=32, num_updates=17850, lr=2.72851e-05, gnorm=2.131, clip=100, loss_scale=256, train_wall=20, gb_free=15.1, wall=50384
2023-01-09 17:37:37 - progress_bar.py[line:272] - INFO: epoch 005:   3227 / 3665 loss=5.085, loss_v1=0, loss_v2=0, nll_loss=4.177, ntokens=1142.2, nsentences=32, sample_size=1142.2, sample_size_v1=0, sample_size_v2=0, ppl=18.09, wps=578.1, ups=0.51, wpb=1142.2, bsz=32, num_updates=17860, lr=2.72706e-05, gnorm=1.907, clip=100, loss_scale=256, train_wall=20, gb_free=15.4, wall=50403
2023-01-09 17:37:57 - progress_bar.py[line:272] - INFO: epoch 005:   3237 / 3665 loss=5.09, loss_v1=0, loss_v2=0, nll_loss=4.182, ntokens=773.1, nsentences=32, sample_size=773.1, sample_size_v1=0, sample_size_v2=0, ppl=18.16, wps=392.2, ups=0.51, wpb=773.1, bsz=32, num_updates=17870, lr=2.72561e-05, gnorm=2.734, clip=100, loss_scale=256, train_wall=20, gb_free=15.2, wall=50423
2023-01-09 17:38:16 - progress_bar.py[line:272] - INFO: epoch 005:   3247 / 3665 loss=4.978, loss_v1=0, loss_v2=0, nll_loss=4.058, ntokens=898.8, nsentences=32, sample_size=898.8, sample_size_v1=0, sample_size_v2=0, ppl=16.65, wps=456.2, ups=0.51, wpb=898.8, bsz=32, num_updates=17880, lr=2.72416e-05, gnorm=2.34, clip=100, loss_scale=256, train_wall=20, gb_free=15.3, wall=50443
2023-01-09 17:38:36 - progress_bar.py[line:272] - INFO: epoch 005:   3257 / 3665 loss=5.062, loss_v1=0, loss_v2=0, nll_loss=4.151, ntokens=1010.1, nsentences=32, sample_size=1010.1, sample_size_v1=0, sample_size_v2=0, ppl=17.76, wps=512.8, ups=0.51, wpb=1010.1, bsz=32, num_updates=17890, lr=2.72271e-05, gnorm=2.049, clip=100, loss_scale=256, train_wall=20, gb_free=14.4, wall=50462
2023-01-09 17:38:56 - progress_bar.py[line:272] - INFO: epoch 005:   3267 / 3665 loss=5.155, loss_v1=0, loss_v2=0, nll_loss=4.254, ntokens=924.1, nsentences=32, sample_size=924.1, sample_size_v1=0, sample_size_v2=0, ppl=19.08, wps=468, ups=0.51, wpb=924.1, bsz=32, num_updates=17900, lr=2.72126e-05, gnorm=2.218, clip=100, loss_scale=256, train_wall=20, gb_free=15.5, wall=50482
2023-01-09 17:39:16 - progress_bar.py[line:272] - INFO: epoch 005:   3277 / 3665 loss=5.161, loss_v1=0, loss_v2=0, nll_loss=4.262, ntokens=871.1, nsentences=32, sample_size=871.1, sample_size_v1=0, sample_size_v2=0, ppl=19.18, wps=441.7, ups=0.51, wpb=871.1, bsz=32, num_updates=17910, lr=2.7198e-05, gnorm=2.478, clip=100, loss_scale=256, train_wall=20, gb_free=15.4, wall=50502
2023-01-09 17:39:35 - progress_bar.py[line:272] - INFO: epoch 005:   3287 / 3665 loss=5.004, loss_v1=0, loss_v2=0, nll_loss=4.087, ntokens=920.3, nsentences=32, sample_size=920.3, sample_size_v1=0, sample_size_v2=0, ppl=17, wps=467.2, ups=0.51, wpb=920.3, bsz=32, num_updates=17920, lr=2.71835e-05, gnorm=2.055, clip=100, loss_scale=256, train_wall=20, gb_free=14.7, wall=50522
2023-01-09 17:39:55 - progress_bar.py[line:272] - INFO: epoch 005:   3297 / 3665 loss=5.109, loss_v1=0, loss_v2=0, nll_loss=4.203, ntokens=907.8, nsentences=32, sample_size=907.8, sample_size_v1=0, sample_size_v2=0, ppl=18.42, wps=460.8, ups=0.51, wpb=907.8, bsz=32, num_updates=17930, lr=2.7169e-05, gnorm=2.378, clip=100, loss_scale=256, train_wall=20, gb_free=15.6, wall=50541
2023-01-09 17:40:15 - progress_bar.py[line:272] - INFO: epoch 005:   3307 / 3665 loss=5.023, loss_v1=0, loss_v2=0, nll_loss=4.108, ntokens=797.3, nsentences=32, sample_size=797.3, sample_size_v1=0, sample_size_v2=0, ppl=17.24, wps=405.7, ups=0.51, wpb=797.3, bsz=32, num_updates=17940, lr=2.71545e-05, gnorm=2.595, clip=100, loss_scale=256, train_wall=20, gb_free=15.4, wall=50561
2023-01-09 17:40:21 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 256.0
2023-01-09 17:40:36 - progress_bar.py[line:272] - INFO: epoch 005:   3318 / 3665 loss=5.1, loss_v1=0, loss_v2=0, nll_loss=4.194, ntokens=1036.2, nsentences=32, sample_size=1036.2, sample_size_v1=0, sample_size_v2=0, ppl=18.3, wps=477.2, ups=0.46, wpb=1036.2, bsz=32, num_updates=17950, lr=2.714e-05, gnorm=2.185, clip=100, loss_scale=256, train_wall=22, gb_free=15.4, wall=50583
2023-01-09 17:40:56 - progress_bar.py[line:272] - INFO: epoch 005:   3328 / 3665 loss=5.256, loss_v1=0, loss_v2=0, nll_loss=4.368, ntokens=961.3, nsentences=32, sample_size=961.3, sample_size_v1=0, sample_size_v2=0, ppl=20.65, wps=485.8, ups=0.51, wpb=961.3, bsz=32, num_updates=17960, lr=2.71255e-05, gnorm=2.241, clip=100, loss_scale=256, train_wall=20, gb_free=15.4, wall=50602
2023-01-09 17:41:16 - progress_bar.py[line:272] - INFO: epoch 005:   3338 / 3665 loss=5.126, loss_v1=0, loss_v2=0, nll_loss=4.222, ntokens=883, nsentences=32, sample_size=883, sample_size_v1=0, sample_size_v2=0, ppl=18.66, wps=448.7, ups=0.51, wpb=883, bsz=32, num_updates=17970, lr=2.7111e-05, gnorm=2.43, clip=100, loss_scale=256, train_wall=20, gb_free=15.5, wall=50622
2023-01-09 17:41:36 - progress_bar.py[line:272] - INFO: epoch 005:   3348 / 3665 loss=5.094, loss_v1=0, loss_v2=0, nll_loss=4.188, ntokens=1036.9, nsentences=32, sample_size=1036.9, sample_size_v1=0, sample_size_v2=0, ppl=18.23, wps=519.8, ups=0.5, wpb=1036.9, bsz=32, num_updates=17980, lr=2.70965e-05, gnorm=2.193, clip=100, loss_scale=256, train_wall=20, gb_free=15.2, wall=50642
2023-01-09 17:41:56 - progress_bar.py[line:272] - INFO: epoch 005:   3358 / 3665 loss=5.205, loss_v1=0, loss_v2=0, nll_loss=4.31, ntokens=978.4, nsentences=32, sample_size=978.4, sample_size_v1=0, sample_size_v2=0, ppl=19.84, wps=488.9, ups=0.5, wpb=978.4, bsz=32, num_updates=17990, lr=2.70819e-05, gnorm=2.312, clip=100, loss_scale=256, train_wall=20, gb_free=15.3, wall=50662
2023-01-09 17:42:16 - progress_bar.py[line:272] - INFO: epoch 005:   3368 / 3665 loss=5.103, loss_v1=0, loss_v2=0, nll_loss=4.197, ntokens=831.3, nsentences=32, sample_size=831.3, sample_size_v1=0, sample_size_v2=0, ppl=18.34, wps=416.4, ups=0.5, wpb=831.3, bsz=32, num_updates=18000, lr=2.70674e-05, gnorm=2.496, clip=100, loss_scale=256, train_wall=20, gb_free=15.3, wall=50682
2023-01-09 17:42:16 - train.py[line:445] - INFO: begin validation on "valid" subset
slice_id 0 seek offset 0
slice_id 0 seek offset 0
2023-01-09 17:46:55 - progress_bar.py[line:282] - INFO: epoch 005 | valid on 'valid' subset | loss 5.09 | loss_v1 0 | loss_v2 0 | nll_loss 4.164 | ntokens 116.825 | nsentences 4 | sample_size 116.825 | sample_size_v1 0 | sample_size_v2 0 | AP 0 | total positives 21.6769 | TP 0 | FP 4.91195 | ppl 17.92 | wps 522.6 | wpb 116.8 | bsz 4 | num_updates 18000 | best_AP 0
2023-01-09 17:46:55 - checkpoint_utils.py[line:64] - INFO: Preparing to save checkpoint for epoch 5 @ 18000 updates
2023-01-09 17:46:55 - trainer.py[line:431] - INFO: Saving checkpoint to ../../checkpoints/OFA/detection_checkpoints/10_5e-5_512/checkpoint_5_18000.pt
2023-01-09 17:46:58 - trainer.py[line:441] - INFO: Finished saving checkpoint to ../../checkpoints/OFA/detection_checkpoints/10_5e-5_512/checkpoint_5_18000.pt
2023-01-09 17:48:09 - checkpoint_utils.py[line:133] - INFO: Saved checkpoint ../../checkpoints/OFA/detection_checkpoints/10_5e-5_512/checkpoint_5_18000.pt (epoch 5 @ 18000 updates, score 0.0) (writing took 74.1012337161228 seconds)
2023-01-09 17:48:28 - progress_bar.py[line:272] - INFO: epoch 005:   3378 / 3665 loss=5.084, loss_v1=0, loss_v2=0, nll_loss=4.173, ntokens=979.2, nsentences=32, sample_size=979.2, sample_size_v1=0, sample_size_v2=0, ppl=18.04, wps=26.3, ups=0.03, wpb=979.2, bsz=32, num_updates=18010, lr=2.70529e-05, gnorm=2.128, clip=100, loss_scale=256, train_wall=19, gb_free=15.3, wall=51055
2023-01-09 17:48:48 - progress_bar.py[line:272] - INFO: epoch 005:   3388 / 3665 loss=5.108, loss_v1=0, loss_v2=0, nll_loss=4.202, ntokens=962.7, nsentences=32, sample_size=962.7, sample_size_v1=0, sample_size_v2=0, ppl=18.41, wps=493.2, ups=0.51, wpb=962.7, bsz=32, num_updates=18020, lr=2.70384e-05, gnorm=2.205, clip=100, loss_scale=256, train_wall=19, gb_free=15.6, wall=51074
2023-01-09 17:49:08 - progress_bar.py[line:272] - INFO: epoch 005:   3398 / 3665 loss=5.029, loss_v1=0, loss_v2=0, nll_loss=4.115, ntokens=778.3, nsentences=32, sample_size=778.3, sample_size_v1=0, sample_size_v2=0, ppl=17.33, wps=399.2, ups=0.51, wpb=778.3, bsz=32, num_updates=18030, lr=2.70239e-05, gnorm=2.674, clip=100, loss_scale=256, train_wall=19, gb_free=15.3, wall=51094
2023-01-09 17:49:27 - progress_bar.py[line:272] - INFO: epoch 005:   3408 / 3665 loss=5.075, loss_v1=0, loss_v2=0, nll_loss=4.167, ntokens=980.8, nsentences=32, sample_size=980.8, sample_size_v1=0, sample_size_v2=0, ppl=17.96, wps=498.3, ups=0.51, wpb=980.8, bsz=32, num_updates=18040, lr=2.70094e-05, gnorm=2.276, clip=100, loss_scale=256, train_wall=20, gb_free=15.5, wall=51113
2023-01-09 17:49:47 - progress_bar.py[line:272] - INFO: epoch 005:   3418 / 3665 loss=5.117, loss_v1=0, loss_v2=0, nll_loss=4.213, ntokens=993, nsentences=32, sample_size=993, sample_size_v1=0, sample_size_v2=0, ppl=18.55, wps=505.9, ups=0.51, wpb=993, bsz=32, num_updates=18050, lr=2.69949e-05, gnorm=2.401, clip=100, loss_scale=256, train_wall=20, gb_free=15.5, wall=51133
2023-01-09 17:50:06 - progress_bar.py[line:272] - INFO: epoch 005:   3428 / 3665 loss=5.093, loss_v1=0, loss_v2=0, nll_loss=4.184, ntokens=779.7, nsentences=32, sample_size=779.7, sample_size_v1=0, sample_size_v2=0, ppl=18.17, wps=397.7, ups=0.51, wpb=779.7, bsz=32, num_updates=18060, lr=2.69803e-05, gnorm=2.831, clip=100, loss_scale=256, train_wall=20, gb_free=15.4, wall=51153
2023-01-09 17:50:26 - progress_bar.py[line:272] - INFO: epoch 005:   3438 / 3665 loss=5.09, loss_v1=0, loss_v2=0, nll_loss=4.182, ntokens=934.6, nsentences=32, sample_size=934.6, sample_size_v1=0, sample_size_v2=0, ppl=18.15, wps=476.7, ups=0.51, wpb=934.6, bsz=32, num_updates=18070, lr=2.69658e-05, gnorm=2.242, clip=100, loss_scale=256, train_wall=20, gb_free=15.4, wall=51172
2023-01-09 17:50:46 - progress_bar.py[line:272] - INFO: epoch 005:   3448 / 3665 loss=5.079, loss_v1=0, loss_v2=0, nll_loss=4.17, ntokens=1021.9, nsentences=32, sample_size=1021.9, sample_size_v1=0, sample_size_v2=0, ppl=18, wps=518.9, ups=0.51, wpb=1021.9, bsz=32, num_updates=18080, lr=2.69513e-05, gnorm=2.159, clip=100, loss_scale=256, train_wall=20, gb_free=15, wall=51192
2023-01-09 17:51:06 - progress_bar.py[line:272] - INFO: epoch 005:   3458 / 3665 loss=5.11, loss_v1=0, loss_v2=0, nll_loss=4.204, ntokens=724.2, nsentences=32, sample_size=724.2, sample_size_v1=0, sample_size_v2=0, ppl=18.42, wps=365.7, ups=0.5, wpb=724.2, bsz=32, num_updates=18090, lr=2.69368e-05, gnorm=2.751, clip=100, loss_scale=256, train_wall=20, gb_free=15.6, wall=51212
2023-01-09 17:51:25 - progress_bar.py[line:272] - INFO: epoch 005:   3468 / 3665 loss=4.942, loss_v1=0, loss_v2=0, nll_loss=4.02, ntokens=775.4, nsentences=32, sample_size=775.4, sample_size_v1=0, sample_size_v2=0, ppl=16.23, wps=396.2, ups=0.51, wpb=775.4, bsz=32, num_updates=18100, lr=2.69223e-05, gnorm=2.775, clip=100, loss_scale=256, train_wall=20, gb_free=15.4, wall=51231
2023-01-09 17:51:45 - progress_bar.py[line:272] - INFO: epoch 005:   3478 / 3665 loss=5.105, loss_v1=0, loss_v2=0, nll_loss=4.199, ntokens=1062.7, nsentences=32, sample_size=1062.7, sample_size_v1=0, sample_size_v2=0, ppl=18.37, wps=539.1, ups=0.51, wpb=1062.7, bsz=32, num_updates=18110, lr=2.69078e-05, gnorm=2.225, clip=100, loss_scale=256, train_wall=20, gb_free=15.6, wall=51251
2023-01-09 17:52:04 - progress_bar.py[line:272] - INFO: epoch 005:   3488 / 3665 loss=5.12, loss_v1=0, loss_v2=0, nll_loss=4.215, ntokens=846.2, nsentences=32, sample_size=846.2, sample_size_v1=0, sample_size_v2=0, ppl=18.57, wps=430.4, ups=0.51, wpb=846.2, bsz=32, num_updates=18120, lr=2.68933e-05, gnorm=2.512, clip=100, loss_scale=256, train_wall=20, gb_free=15.5, wall=51271
2023-01-09 17:52:24 - progress_bar.py[line:272] - INFO: epoch 005:   3498 / 3665 loss=4.974, loss_v1=0, loss_v2=0, nll_loss=4.053, ntokens=695.2, nsentences=32, sample_size=695.2, sample_size_v1=0, sample_size_v2=0, ppl=16.6, wps=355, ups=0.51, wpb=695.2, bsz=32, num_updates=18130, lr=2.68788e-05, gnorm=2.902, clip=100, loss_scale=256, train_wall=20, gb_free=15.5, wall=51290
2023-01-09 17:52:44 - progress_bar.py[line:272] - INFO: epoch 005:   3508 / 3665 loss=5.06, loss_v1=0, loss_v2=0, nll_loss=4.149, ntokens=1013.4, nsentences=32, sample_size=1013.4, sample_size_v1=0, sample_size_v2=0, ppl=17.74, wps=496.3, ups=0.49, wpb=1013.4, bsz=32, num_updates=18140, lr=2.68642e-05, gnorm=2.174, clip=100, loss_scale=256, train_wall=20, gb_free=15.5, wall=51311
2023-01-09 17:53:05 - progress_bar.py[line:272] - INFO: epoch 005:   3518 / 3665 loss=5.165, loss_v1=0, loss_v2=0, nll_loss=4.266, ntokens=984.4, nsentences=32, sample_size=984.4, sample_size_v1=0, sample_size_v2=0, ppl=19.24, wps=470.6, ups=0.48, wpb=984.4, bsz=32, num_updates=18150, lr=2.68497e-05, gnorm=2.195, clip=100, loss_scale=256, train_wall=21, gb_free=15.6, wall=51332
2023-01-09 17:53:25 - progress_bar.py[line:272] - INFO: epoch 005:   3528 / 3665 loss=5.065, loss_v1=0, loss_v2=0, nll_loss=4.155, ntokens=833, nsentences=32, sample_size=833, sample_size_v1=0, sample_size_v2=0, ppl=17.81, wps=416.4, ups=0.5, wpb=833, bsz=32, num_updates=18160, lr=2.68352e-05, gnorm=2.626, clip=100, loss_scale=256, train_wall=20, gb_free=15.7, wall=51352
2023-01-09 17:53:45 - progress_bar.py[line:272] - INFO: epoch 005:   3538 / 3665 loss=5.102, loss_v1=0, loss_v2=0, nll_loss=4.195, ntokens=1066.3, nsentences=32, sample_size=1066.3, sample_size_v1=0, sample_size_v2=0, ppl=18.32, wps=543.8, ups=0.51, wpb=1066.3, bsz=32, num_updates=18170, lr=2.68207e-05, gnorm=2.041, clip=100, loss_scale=256, train_wall=20, gb_free=15.1, wall=51371
2023-01-09 17:54:05 - progress_bar.py[line:272] - INFO: epoch 005:   3548 / 3665 loss=5.187, loss_v1=0, loss_v2=0, nll_loss=4.29, ntokens=1115.9, nsentences=32, sample_size=1115.9, sample_size_v1=0, sample_size_v2=0, ppl=19.56, wps=566.9, ups=0.51, wpb=1115.9, bsz=32, num_updates=18180, lr=2.68062e-05, gnorm=1.943, clip=100, loss_scale=256, train_wall=20, gb_free=15.2, wall=51391
2023-01-09 17:54:24 - progress_bar.py[line:272] - INFO: epoch 005:   3558 / 3665 loss=5.048, loss_v1=0, loss_v2=0, nll_loss=4.136, ntokens=843.6, nsentences=32, sample_size=843.6, sample_size_v1=0, sample_size_v2=0, ppl=17.58, wps=431, ups=0.51, wpb=843.6, bsz=32, num_updates=18190, lr=2.67917e-05, gnorm=2.353, clip=100, loss_scale=256, train_wall=20, gb_free=15.4, wall=51411
2023-01-09 17:54:44 - progress_bar.py[line:272] - INFO: epoch 005:   3568 / 3665 loss=5.046, loss_v1=0, loss_v2=0, nll_loss=4.135, ntokens=1002.5, nsentences=32, sample_size=1002.5, sample_size_v1=0, sample_size_v2=0, ppl=17.56, wps=509.2, ups=0.51, wpb=1002.5, bsz=32, num_updates=18200, lr=2.67772e-05, gnorm=2.175, clip=100, loss_scale=256, train_wall=20, gb_free=15.1, wall=51430
2023-01-09 17:55:04 - progress_bar.py[line:272] - INFO: epoch 005:   3578 / 3665 loss=5.125, loss_v1=0, loss_v2=0, nll_loss=4.222, ntokens=1053.4, nsentences=32, sample_size=1053.4, sample_size_v1=0, sample_size_v2=0, ppl=18.66, wps=533.7, ups=0.51, wpb=1053.4, bsz=32, num_updates=18210, lr=2.67626e-05, gnorm=2.025, clip=100, loss_scale=256, train_wall=20, gb_free=15.5, wall=51450
2023-01-09 17:55:23 - progress_bar.py[line:272] - INFO: epoch 005:   3588 / 3665 loss=5.053, loss_v1=0, loss_v2=0, nll_loss=4.142, ntokens=776.2, nsentences=32, sample_size=776.2, sample_size_v1=0, sample_size_v2=0, ppl=17.66, wps=395.3, ups=0.51, wpb=776.2, bsz=32, num_updates=18220, lr=2.67481e-05, gnorm=2.511, clip=100, loss_scale=256, train_wall=20, gb_free=15.4, wall=51470
2023-01-09 17:55:43 - progress_bar.py[line:272] - INFO: epoch 005:   3598 / 3665 loss=5.042, loss_v1=0, loss_v2=0, nll_loss=4.129, ntokens=882.3, nsentences=32, sample_size=882.3, sample_size_v1=0, sample_size_v2=0, ppl=17.5, wps=449.3, ups=0.51, wpb=882.3, bsz=32, num_updates=18230, lr=2.67336e-05, gnorm=2.436, clip=100, loss_scale=256, train_wall=20, gb_free=15.1, wall=51489
2023-01-09 17:56:03 - progress_bar.py[line:272] - INFO: epoch 005:   3608 / 3665 loss=5.16, loss_v1=0, loss_v2=0, nll_loss=4.259, ntokens=1039.2, nsentences=32, sample_size=1039.2, sample_size_v1=0, sample_size_v2=0, ppl=19.15, wps=522.1, ups=0.5, wpb=1039.2, bsz=32, num_updates=18240, lr=2.67191e-05, gnorm=2.16, clip=100, loss_scale=256, train_wall=20, gb_free=15.3, wall=51509
2023-01-09 17:56:23 - progress_bar.py[line:272] - INFO: epoch 005:   3618 / 3665 loss=5.051, loss_v1=0, loss_v2=0, nll_loss=4.138, ntokens=814, nsentences=32, sample_size=814, sample_size_v1=0, sample_size_v2=0, ppl=17.61, wps=408.3, ups=0.5, wpb=814, bsz=32, num_updates=18250, lr=2.67046e-05, gnorm=2.325, clip=100, loss_scale=256, train_wall=20, gb_free=15, wall=51529
2023-01-09 17:56:43 - progress_bar.py[line:272] - INFO: epoch 005:   3628 / 3665 loss=5.037, loss_v1=0, loss_v2=0, nll_loss=4.124, ntokens=922.7, nsentences=32, sample_size=922.7, sample_size_v1=0, sample_size_v2=0, ppl=17.44, wps=462.4, ups=0.5, wpb=922.7, bsz=32, num_updates=18260, lr=2.66901e-05, gnorm=2.359, clip=100, loss_scale=256, train_wall=20, gb_free=15.2, wall=51549
2023-01-09 17:57:03 - progress_bar.py[line:272] - INFO: epoch 005:   3638 / 3665 loss=5.066, loss_v1=0, loss_v2=0, nll_loss=4.156, ntokens=1127.4, nsentences=32, sample_size=1127.4, sample_size_v1=0, sample_size_v2=0, ppl=17.83, wps=562.1, ups=0.5, wpb=1127.4, bsz=32, num_updates=18270, lr=2.66756e-05, gnorm=2.048, clip=100, loss_scale=256, train_wall=20, gb_free=15.1, wall=51569
2023-01-09 17:57:23 - progress_bar.py[line:272] - INFO: epoch 005:   3648 / 3665 loss=5.07, loss_v1=0, loss_v2=0, nll_loss=4.159, ntokens=877.4, nsentences=32, sample_size=877.4, sample_size_v1=0, sample_size_v2=0, ppl=17.86, wps=439.6, ups=0.5, wpb=877.4, bsz=32, num_updates=18280, lr=2.66611e-05, gnorm=2.365, clip=100, loss_scale=256, train_wall=20, gb_free=15.4, wall=51589
2023-01-09 17:57:43 - progress_bar.py[line:272] - INFO: epoch 005:   3658 / 3665 loss=5.046, loss_v1=0, loss_v2=0, nll_loss=4.134, ntokens=861.7, nsentences=32, sample_size=861.7, sample_size_v1=0, sample_size_v2=0, ppl=17.56, wps=431.3, ups=0.5, wpb=861.7, bsz=32, num_updates=18290, lr=2.66465e-05, gnorm=2.462, clip=100, loss_scale=256, train_wall=20, gb_free=15.4, wall=51609
2023-01-09 17:57:56 - train.py[line:445] - INFO: begin validation on "valid" subset
slice_id 0 seek offset 0
slice_id 0 seek offset 0
2023-01-09 18:02:47 - progress_bar.py[line:282] - INFO: epoch 005 | valid on 'valid' subset | loss 5.079 | loss_v1 0 | loss_v2 0 | nll_loss 4.154 | ntokens 116.599 | nsentences 4 | sample_size 116.599 | sample_size_v1 0 | sample_size_v2 0 | AP 0 | total positives 21.6276 | TP 0 | FP 5.68821 | ppl 17.8 | wps 500.9 | wpb 116.6 | bsz 4 | num_updates 18297 | best_AP 0
2023-01-09 18:02:47 - checkpoint_utils.py[line:64] - INFO: Preparing to save checkpoint for epoch 5 @ 18297 updates
2023-01-09 18:02:47 - trainer.py[line:431] - INFO: Saving checkpoint to ../../checkpoints/OFA/detection_checkpoints/10_5e-5_512/checkpoint_best.pt
2023-01-09 18:03:08 - trainer.py[line:441] - INFO: Finished saving checkpoint to ../../checkpoints/OFA/detection_checkpoints/10_5e-5_512/checkpoint_best.pt
2023-01-09 18:03:44 - checkpoint_utils.py[line:133] - INFO: Saved checkpoint ../../checkpoints/OFA/detection_checkpoints/10_5e-5_512/checkpoint_best.pt (epoch 5 @ 18297 updates, score 0.0) (writing took 56.85299780871719 seconds)
2023-01-09 18:03:44 - train.py[line:332] - INFO: end of epoch 5 (average epoch stats below)
2023-01-09 18:03:44 - progress_bar.py[line:282] - INFO: epoch 005 | loss 5.124 | loss_v1 0 | loss_v2 0 | nll_loss 4.22 | ntokens 924.206 | nsentences 31.996 | sample_size 924.206 | sample_size_v1 0 | sample_size_v2 0 | AP 0 | ppl 18.64 | wps 310.4 | ups 0.34 | wpb 924.2 | bsz 32 | num_updates 18297 | lr 2.66364e-05 | gnorm 2.231 | clip 100 | loss_scale 256 | train_wall 7758 | gb_free 14.7 | wall 51970
2023-01-09 18:03:44 - trainer.py[line:639] - INFO: loading train data for epoch 6
local datafile ../../dataset/OFA_data/train.tsv slice_id 0 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../dataset/OFA_data/train.tsv slice_id 0 finished initializing row_count and line_idx-to-offset mapping
file ../../dataset/OFA_data/train.tsv slice_id 0 row count 117266 total row count 117266
slice_id 0 seek offset 0
2023-01-09 18:05:02 - trainer.py[line:703] - INFO: begin training epoch 6
2023-01-09 18:05:02 - train.py[line:305] - INFO: Start iterating over samples
2023-01-09 18:05:09 - progress_bar.py[line:272] - INFO: epoch 006:      3 / 3665 loss=5.129, loss_v1=0, loss_v2=0, nll_loss=4.228, ntokens=994.8, nsentences=30.8, sample_size=994.8, sample_size_v1=0, sample_size_v2=0, ppl=18.74, wps=22.3, ups=0.02, wpb=994.8, bsz=30.8, num_updates=18300, lr=2.6632e-05, gnorm=2.206, clip=100, loss_scale=256, train_wall=19, gb_free=15.6, wall=52055
2023-01-09 18:05:28 - progress_bar.py[line:272] - INFO: epoch 006:     13 / 3665 loss=5.113, loss_v1=0, loss_v2=0, nll_loss=4.207, ntokens=834.3, nsentences=32, sample_size=834.3, sample_size_v1=0, sample_size_v2=0, ppl=18.46, wps=430.4, ups=0.52, wpb=834.3, bsz=32, num_updates=18310, lr=2.66175e-05, gnorm=2.652, clip=100, loss_scale=256, train_wall=19, gb_free=15.4, wall=52074
2023-01-09 18:05:47 - progress_bar.py[line:272] - INFO: epoch 006:     23 / 3665 loss=5.034, loss_v1=0, loss_v2=0, nll_loss=4.12, ntokens=909.4, nsentences=32, sample_size=909.4, sample_size_v1=0, sample_size_v2=0, ppl=17.38, wps=467.5, ups=0.51, wpb=909.4, bsz=32, num_updates=18320, lr=2.6603e-05, gnorm=2.256, clip=100, loss_scale=256, train_wall=19, gb_free=15.3, wall=52094
2023-01-09 18:06:07 - progress_bar.py[line:272] - INFO: epoch 006:     33 / 3665 loss=5.151, loss_v1=0, loss_v2=0, nll_loss=4.252, ntokens=950.8, nsentences=32, sample_size=950.8, sample_size_v1=0, sample_size_v2=0, ppl=19.06, wps=486.9, ups=0.51, wpb=950.8, bsz=32, num_updates=18330, lr=2.65885e-05, gnorm=2.369, clip=100, loss_scale=256, train_wall=20, gb_free=15.6, wall=52113
2023-01-09 18:06:27 - progress_bar.py[line:272] - INFO: epoch 006:     43 / 3665 loss=5.035, loss_v1=0, loss_v2=0, nll_loss=4.119, ntokens=820.8, nsentences=32, sample_size=820.8, sample_size_v1=0, sample_size_v2=0, ppl=17.37, wps=419.6, ups=0.51, wpb=820.8, bsz=32, num_updates=18340, lr=2.6574e-05, gnorm=2.695, clip=100, loss_scale=256, train_wall=20, gb_free=15.5, wall=52133
2023-01-09 18:06:46 - progress_bar.py[line:272] - INFO: epoch 006:     53 / 3665 loss=5.091, loss_v1=0, loss_v2=0, nll_loss=4.183, ntokens=1013.6, nsentences=32, sample_size=1013.6, sample_size_v1=0, sample_size_v2=0, ppl=18.17, wps=516.2, ups=0.51, wpb=1013.6, bsz=32, num_updates=18350, lr=2.65595e-05, gnorm=2.142, clip=100, loss_scale=256, train_wall=20, gb_free=15.2, wall=52152
2023-01-09 18:07:06 - progress_bar.py[line:272] - INFO: epoch 006:     63 / 3665 loss=5.106, loss_v1=0, loss_v2=0, nll_loss=4.204, ntokens=881.1, nsentences=32, sample_size=881.1, sample_size_v1=0, sample_size_v2=0, ppl=18.43, wps=449.5, ups=0.51, wpb=881.1, bsz=32, num_updates=18360, lr=2.65449e-05, gnorm=2.467, clip=100, loss_scale=256, train_wall=20, gb_free=15.3, wall=52172
2023-01-09 18:07:25 - progress_bar.py[line:272] - INFO: epoch 006:     73 / 3665 loss=5.053, loss_v1=0, loss_v2=0, nll_loss=4.14, ntokens=860.9, nsentences=32, sample_size=860.9, sample_size_v1=0, sample_size_v2=0, ppl=17.63, wps=438.9, ups=0.51, wpb=860.9, bsz=32, num_updates=18370, lr=2.65304e-05, gnorm=2.333, clip=100, loss_scale=256, train_wall=20, gb_free=15.1, wall=52192
2023-01-09 18:07:45 - progress_bar.py[line:272] - INFO: epoch 006:     83 / 3665 loss=5.041, loss_v1=0, loss_v2=0, nll_loss=4.128, ntokens=964.5, nsentences=32, sample_size=964.5, sample_size_v1=0, sample_size_v2=0, ppl=17.49, wps=492, ups=0.51, wpb=964.5, bsz=32, num_updates=18380, lr=2.65159e-05, gnorm=2.253, clip=100, loss_scale=256, train_wall=20, gb_free=15.6, wall=52211
2023-01-09 18:08:05 - progress_bar.py[line:272] - INFO: epoch 006:     93 / 3665 loss=5.149, loss_v1=0, loss_v2=0, nll_loss=4.249, ntokens=857.9, nsentences=32, sample_size=857.9, sample_size_v1=0, sample_size_v2=0, ppl=19.01, wps=437.6, ups=0.51, wpb=857.9, bsz=32, num_updates=18390, lr=2.65014e-05, gnorm=2.654, clip=100, loss_scale=256, train_wall=20, gb_free=14.6, wall=52231
2023-01-09 18:08:24 - progress_bar.py[line:272] - INFO: epoch 006:    103 / 3665 loss=5.107, loss_v1=0, loss_v2=0, nll_loss=4.202, ntokens=988.7, nsentences=32, sample_size=988.7, sample_size_v1=0, sample_size_v2=0, ppl=18.4, wps=503.2, ups=0.51, wpb=988.7, bsz=32, num_updates=18400, lr=2.64869e-05, gnorm=2.374, clip=100, loss_scale=256, train_wall=20, gb_free=15.4, wall=52251
2023-01-09 18:08:44 - progress_bar.py[line:272] - INFO: epoch 006:    113 / 3665 loss=5.086, loss_v1=0, loss_v2=0, nll_loss=4.176, ntokens=1099.1, nsentences=32, sample_size=1099.1, sample_size_v1=0, sample_size_v2=0, ppl=18.08, wps=559.6, ups=0.51, wpb=1099.1, bsz=32, num_updates=18410, lr=2.64724e-05, gnorm=2.159, clip=100, loss_scale=256, train_wall=20, gb_free=15.6, wall=52270
2023-01-09 18:09:04 - progress_bar.py[line:272] - INFO: epoch 006:    123 / 3665 loss=5.128, loss_v1=0, loss_v2=0, nll_loss=4.223, ntokens=926, nsentences=32, sample_size=926, sample_size_v1=0, sample_size_v2=0, ppl=18.67, wps=470.9, ups=0.51, wpb=926, bsz=32, num_updates=18420, lr=2.64579e-05, gnorm=2.466, clip=100, loss_scale=256, train_wall=20, gb_free=15.3, wall=52290
2023-01-09 18:09:23 - progress_bar.py[line:272] - INFO: epoch 006:    133 / 3665 loss=5.043, loss_v1=0, loss_v2=0, nll_loss=4.128, ntokens=885.7, nsentences=32, sample_size=885.7, sample_size_v1=0, sample_size_v2=0, ppl=17.49, wps=451.1, ups=0.51, wpb=885.7, bsz=32, num_updates=18430, lr=2.64434e-05, gnorm=2.478, clip=100, loss_scale=256, train_wall=20, gb_free=15.2, wall=52309
2023-01-09 18:09:43 - progress_bar.py[line:272] - INFO: epoch 006:    143 / 3665 loss=5.128, loss_v1=0, loss_v2=0, nll_loss=4.226, ntokens=1058.6, nsentences=32, sample_size=1058.6, sample_size_v1=0, sample_size_v2=0, ppl=18.72, wps=532, ups=0.5, wpb=1058.6, bsz=32, num_updates=18440, lr=2.64288e-05, gnorm=2.115, clip=100, loss_scale=256, train_wall=20, gb_free=15.4, wall=52329
2023-01-09 18:10:03 - progress_bar.py[line:272] - INFO: epoch 006:    153 / 3665 loss=5.093, loss_v1=0, loss_v2=0, nll_loss=4.187, ntokens=869.1, nsentences=32, sample_size=869.1, sample_size_v1=0, sample_size_v2=0, ppl=18.21, wps=429.5, ups=0.49, wpb=869.1, bsz=32, num_updates=18450, lr=2.64143e-05, gnorm=2.617, clip=100, loss_scale=256, train_wall=20, gb_free=15.7, wall=52350
2023-01-09 18:10:18 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 256.0
2023-01-09 18:10:26 - progress_bar.py[line:272] - INFO: epoch 006:    164 / 3665 loss=5.108, loss_v1=0, loss_v2=0, nll_loss=4.202, ntokens=1024.7, nsentences=32, sample_size=1024.7, sample_size_v1=0, sample_size_v2=0, ppl=18.4, wps=451.4, ups=0.44, wpb=1024.7, bsz=32, num_updates=18460, lr=2.63998e-05, gnorm=2.218, clip=100, loss_scale=256, train_wall=23, gb_free=15.4, wall=52372
2023-01-09 18:10:46 - progress_bar.py[line:272] - INFO: epoch 006:    174 / 3665 loss=5.11, loss_v1=0, loss_v2=0, nll_loss=4.206, ntokens=868.6, nsentences=32, sample_size=868.6, sample_size_v1=0, sample_size_v2=0, ppl=18.45, wps=433, ups=0.5, wpb=868.6, bsz=32, num_updates=18470, lr=2.63853e-05, gnorm=2.431, clip=100, loss_scale=256, train_wall=20, gb_free=15.6, wall=52392
2023-01-09 18:11:06 - progress_bar.py[line:272] - INFO: epoch 006:    184 / 3665 loss=5.023, loss_v1=0, loss_v2=0, nll_loss=4.105, ntokens=832.1, nsentences=32, sample_size=832.1, sample_size_v1=0, sample_size_v2=0, ppl=17.21, wps=427.2, ups=0.51, wpb=832.1, bsz=32, num_updates=18480, lr=2.63708e-05, gnorm=2.412, clip=100, loss_scale=256, train_wall=19, gb_free=15.7, wall=52412
2023-01-09 18:11:25 - progress_bar.py[line:272] - INFO: epoch 006:    194 / 3665 loss=5.092, loss_v1=0, loss_v2=0, nll_loss=4.187, ntokens=1093.8, nsentences=32, sample_size=1093.8, sample_size_v1=0, sample_size_v2=0, ppl=18.22, wps=556, ups=0.51, wpb=1093.8, bsz=32, num_updates=18490, lr=2.63563e-05, gnorm=2.087, clip=100, loss_scale=256, train_wall=20, gb_free=15.2, wall=52431
2023-01-09 18:11:45 - progress_bar.py[line:272] - INFO: epoch 006:    204 / 3665 loss=5.102, loss_v1=0, loss_v2=0, nll_loss=4.197, ntokens=783.9, nsentences=32, sample_size=783.9, sample_size_v1=0, sample_size_v2=0, ppl=18.34, wps=400.1, ups=0.51, wpb=783.9, bsz=32, num_updates=18500, lr=2.63418e-05, gnorm=2.599, clip=100, loss_scale=256, train_wall=20, gb_free=15.3, wall=52451
2023-01-09 18:11:45 - train.py[line:445] - INFO: begin validation on "valid" subset
slice_id 0 seek offset 0
slice_id 0 seek offset 0
2023-01-09 18:16:31 - progress_bar.py[line:282] - INFO: epoch 006 | valid on 'valid' subset | loss 5.084 | loss_v1 0 | loss_v2 0 | nll_loss 4.158 | ntokens 117.241 | nsentences 4 | sample_size 117.241 | sample_size_v1 0 | sample_size_v2 0 | AP 0 | total positives 21.7577 | TP 0 | FP 5.03393 | ppl 17.85 | wps 511.5 | wpb 117.2 | bsz 4 | num_updates 18500 | best_AP 0
2023-01-09 18:16:31 - checkpoint_utils.py[line:64] - INFO: Preparing to save checkpoint for epoch 6 @ 18500 updates
2023-01-09 18:16:31 - trainer.py[line:431] - INFO: Saving checkpoint to ../../checkpoints/OFA/detection_checkpoints/10_5e-5_512/checkpoint_6_18500.pt
2023-01-09 18:16:35 - trainer.py[line:441] - INFO: Finished saving checkpoint to ../../checkpoints/OFA/detection_checkpoints/10_5e-5_512/checkpoint_6_18500.pt
2023-01-09 18:17:46 - checkpoint_utils.py[line:133] - INFO: Saved checkpoint ../../checkpoints/OFA/detection_checkpoints/10_5e-5_512/checkpoint_6_18500.pt (epoch 6 @ 18500 updates, score 0.0) (writing took 75.19153003813699 seconds)
2023-01-09 18:18:06 - progress_bar.py[line:272] - INFO: epoch 006:    214 / 3665 loss=5.047, loss_v1=0, loss_v2=0, nll_loss=4.134, ntokens=834.1, nsentences=32, sample_size=834.1, sample_size_v1=0, sample_size_v2=0, ppl=17.56, wps=21.9, ups=0.03, wpb=834.1, bsz=32, num_updates=18510, lr=2.63272e-05, gnorm=2.558, clip=100, loss_scale=256, train_wall=19, gb_free=15.3, wall=52832
2023-01-09 18:18:25 - progress_bar.py[line:272] - INFO: epoch 006:    224 / 3665 loss=5.085, loss_v1=0, loss_v2=0, nll_loss=4.178, ntokens=1022.6, nsentences=32, sample_size=1022.6, sample_size_v1=0, sample_size_v2=0, ppl=18.1, wps=524.2, ups=0.51, wpb=1022.6, bsz=32, num_updates=18520, lr=2.63127e-05, gnorm=2.144, clip=100, loss_scale=256, train_wall=19, gb_free=15.1, wall=52852
2023-01-09 18:18:45 - progress_bar.py[line:272] - INFO: epoch 006:    234 / 3665 loss=5.12, loss_v1=0, loss_v2=0, nll_loss=4.215, ntokens=840.1, nsentences=32, sample_size=840.1, sample_size_v1=0, sample_size_v2=0, ppl=18.57, wps=429, ups=0.51, wpb=840.1, bsz=32, num_updates=18530, lr=2.62982e-05, gnorm=2.61, clip=100, loss_scale=256, train_wall=20, gb_free=15.4, wall=52871
2023-01-09 18:19:05 - progress_bar.py[line:272] - INFO: epoch 006:    244 / 3665 loss=5.005, loss_v1=0, loss_v2=0, nll_loss=4.086, ntokens=916.4, nsentences=32, sample_size=916.4, sample_size_v1=0, sample_size_v2=0, ppl=16.99, wps=467.8, ups=0.51, wpb=916.4, bsz=32, num_updates=18540, lr=2.62837e-05, gnorm=2.325, clip=100, loss_scale=256, train_wall=20, gb_free=15.3, wall=52891
2023-01-09 18:19:24 - progress_bar.py[line:272] - INFO: epoch 006:    254 / 3665 loss=5.182, loss_v1=0, loss_v2=0, nll_loss=4.284, ntokens=1071.2, nsentences=32, sample_size=1071.2, sample_size_v1=0, sample_size_v2=0, ppl=19.48, wps=540, ups=0.5, wpb=1071.2, bsz=32, num_updates=18550, lr=2.62692e-05, gnorm=2.002, clip=100, loss_scale=256, train_wall=20, gb_free=15.3, wall=52911
2023-01-09 18:19:44 - progress_bar.py[line:272] - INFO: epoch 006:    264 / 3665 loss=5.037, loss_v1=0, loss_v2=0, nll_loss=4.123, ntokens=726.3, nsentences=32, sample_size=726.3, sample_size_v1=0, sample_size_v2=0, ppl=17.42, wps=370.7, ups=0.51, wpb=726.3, bsz=32, num_updates=18560, lr=2.62547e-05, gnorm=3.021, clip=100, loss_scale=256, train_wall=20, gb_free=15.4, wall=52930
2023-01-09 18:20:04 - progress_bar.py[line:272] - INFO: epoch 006:    274 / 3665 loss=5.099, loss_v1=0, loss_v2=0, nll_loss=4.193, ntokens=967.3, nsentences=32, sample_size=967.3, sample_size_v1=0, sample_size_v2=0, ppl=18.29, wps=493, ups=0.51, wpb=967.3, bsz=32, num_updates=18570, lr=2.62402e-05, gnorm=2.402, clip=100, loss_scale=256, train_wall=20, gb_free=15.1, wall=52950
2023-01-09 18:20:23 - progress_bar.py[line:272] - INFO: epoch 006:    284 / 3665 loss=5.054, loss_v1=0, loss_v2=0, nll_loss=4.143, ntokens=865.4, nsentences=32, sample_size=865.4, sample_size_v1=0, sample_size_v2=0, ppl=17.66, wps=440.5, ups=0.51, wpb=865.4, bsz=32, num_updates=18580, lr=2.62257e-05, gnorm=2.288, clip=100, loss_scale=256, train_wall=20, gb_free=15.3, wall=52970
2023-01-09 18:20:43 - progress_bar.py[line:272] - INFO: epoch 006:    294 / 3665 loss=4.949, loss_v1=0, loss_v2=0, nll_loss=4.026, ntokens=761.6, nsentences=32, sample_size=761.6, sample_size_v1=0, sample_size_v2=0, ppl=16.29, wps=389.5, ups=0.51, wpb=761.6, bsz=32, num_updates=18590, lr=2.62111e-05, gnorm=2.626, clip=100, loss_scale=256, train_wall=20, gb_free=15.4, wall=52989
2023-01-09 18:21:03 - progress_bar.py[line:272] - INFO: epoch 006:    304 / 3665 loss=5.059, loss_v1=0, loss_v2=0, nll_loss=4.148, ntokens=1093.8, nsentences=32, sample_size=1093.8, sample_size_v1=0, sample_size_v2=0, ppl=17.72, wps=553.6, ups=0.51, wpb=1093.8, bsz=32, num_updates=18600, lr=2.61966e-05, gnorm=2.011, clip=100, loss_scale=256, train_wall=20, gb_free=14.8, wall=53009
2023-01-09 18:21:22 - progress_bar.py[line:272] - INFO: epoch 006:    314 / 3665 loss=5.154, loss_v1=0, loss_v2=0, nll_loss=4.252, ntokens=964.9, nsentences=32, sample_size=964.9, sample_size_v1=0, sample_size_v2=0, ppl=19.06, wps=488.3, ups=0.51, wpb=964.9, bsz=32, num_updates=18610, lr=2.61821e-05, gnorm=2.194, clip=100, loss_scale=256, train_wall=20, gb_free=15.5, wall=53029
2023-01-09 18:21:42 - progress_bar.py[line:272] - INFO: epoch 006:    324 / 3665 loss=5.094, loss_v1=0, loss_v2=0, nll_loss=4.188, ntokens=845.5, nsentences=32, sample_size=845.5, sample_size_v1=0, sample_size_v2=0, ppl=18.22, wps=431.5, ups=0.51, wpb=845.5, bsz=32, num_updates=18620, lr=2.61676e-05, gnorm=2.419, clip=100, loss_scale=256, train_wall=20, gb_free=15.4, wall=53048
2023-01-09 18:22:02 - progress_bar.py[line:272] - INFO: epoch 006:    334 / 3665 loss=4.963, loss_v1=0, loss_v2=0, nll_loss=4.04, ntokens=963.7, nsentences=32, sample_size=963.7, sample_size_v1=0, sample_size_v2=0, ppl=16.46, wps=488.4, ups=0.51, wpb=963.7, bsz=32, num_updates=18630, lr=2.61531e-05, gnorm=2.253, clip=100, loss_scale=256, train_wall=20, gb_free=15.6, wall=53068
2023-01-09 18:22:21 - progress_bar.py[line:272] - INFO: epoch 006:    344 / 3665 loss=5.096, loss_v1=0, loss_v2=0, nll_loss=4.187, ntokens=795.3, nsentences=32, sample_size=795.3, sample_size_v1=0, sample_size_v2=0, ppl=18.22, wps=405.3, ups=0.51, wpb=795.3, bsz=32, num_updates=18640, lr=2.61386e-05, gnorm=2.397, clip=100, loss_scale=256, train_wall=20, gb_free=15.2, wall=53088
2023-01-09 18:22:41 - progress_bar.py[line:272] - INFO: epoch 006:    354 / 3665 loss=5.011, loss_v1=0, loss_v2=0, nll_loss=4.096, ntokens=896.6, nsentences=32, sample_size=896.6, sample_size_v1=0, sample_size_v2=0, ppl=17.1, wps=452.9, ups=0.51, wpb=896.6, bsz=32, num_updates=18650, lr=2.61241e-05, gnorm=2.36, clip=100, loss_scale=256, train_wall=20, gb_free=15.4, wall=53107
2023-01-09 18:23:02 - progress_bar.py[line:272] - INFO: epoch 006:    364 / 3665 loss=5.113, loss_v1=0, loss_v2=0, nll_loss=4.211, ntokens=1033.9, nsentences=32, sample_size=1033.9, sample_size_v1=0, sample_size_v2=0, ppl=18.52, wps=507.4, ups=0.49, wpb=1033.9, bsz=32, num_updates=18660, lr=2.61095e-05, gnorm=2.204, clip=100, loss_scale=256, train_wall=20, gb_free=15.4, wall=53128
2023-01-09 18:23:22 - progress_bar.py[line:272] - INFO: epoch 006:    374 / 3665 loss=5.066, loss_v1=0, loss_v2=0, nll_loss=4.154, ntokens=798.9, nsentences=32, sample_size=798.9, sample_size_v1=0, sample_size_v2=0, ppl=17.8, wps=396.1, ups=0.5, wpb=798.9, bsz=32, num_updates=18670, lr=2.6095e-05, gnorm=2.651, clip=100, loss_scale=256, train_wall=20, gb_free=15.2, wall=53148
2023-01-09 18:23:42 - progress_bar.py[line:272] - INFO: epoch 006:    384 / 3665 loss=4.996, loss_v1=0, loss_v2=0, nll_loss=4.076, ntokens=949.8, nsentences=32, sample_size=949.8, sample_size_v1=0, sample_size_v2=0, ppl=16.87, wps=469.6, ups=0.49, wpb=949.8, bsz=32, num_updates=18680, lr=2.60805e-05, gnorm=2.322, clip=100, loss_scale=256, train_wall=20, gb_free=15.6, wall=53168
2023-01-09 18:24:02 - progress_bar.py[line:272] - INFO: epoch 006:    394 / 3665 loss=5.062, loss_v1=0, loss_v2=0, nll_loss=4.152, ntokens=852.5, nsentences=32, sample_size=852.5, sample_size_v1=0, sample_size_v2=0, ppl=17.77, wps=430.2, ups=0.5, wpb=852.5, bsz=32, num_updates=18690, lr=2.6066e-05, gnorm=2.451, clip=100, loss_scale=256, train_wall=20, gb_free=15.7, wall=53188
2023-01-09 18:24:21 - progress_bar.py[line:272] - INFO: epoch 006:    404 / 3665 loss=5.011, loss_v1=0, loss_v2=0, nll_loss=4.095, ntokens=764.4, nsentences=32, sample_size=764.4, sample_size_v1=0, sample_size_v2=0, ppl=17.09, wps=389.4, ups=0.51, wpb=764.4, bsz=32, num_updates=18700, lr=2.60515e-05, gnorm=2.66, clip=100, loss_scale=256, train_wall=20, gb_free=15.1, wall=53208
2023-01-09 18:24:41 - progress_bar.py[line:272] - INFO: epoch 006:    414 / 3665 loss=5.041, loss_v1=0, loss_v2=0, nll_loss=4.127, ntokens=1038.3, nsentences=32, sample_size=1038.3, sample_size_v1=0, sample_size_v2=0, ppl=17.48, wps=527.6, ups=0.51, wpb=1038.3, bsz=32, num_updates=18710, lr=2.6037e-05, gnorm=2.227, clip=100, loss_scale=256, train_wall=20, gb_free=15.3, wall=53227
2023-01-09 18:25:01 - progress_bar.py[line:272] - INFO: epoch 006:    424 / 3665 loss=5.122, loss_v1=0, loss_v2=0, nll_loss=4.22, ntokens=875.5, nsentences=32, sample_size=875.5, sample_size_v1=0, sample_size_v2=0, ppl=18.63, wps=447, ups=0.51, wpb=875.5, bsz=32, num_updates=18720, lr=2.60225e-05, gnorm=2.325, clip=100, loss_scale=256, train_wall=20, gb_free=14.9, wall=53247
2023-01-09 18:25:20 - progress_bar.py[line:272] - INFO: epoch 006:    434 / 3665 loss=5.059, loss_v1=0, loss_v2=0, nll_loss=4.147, ntokens=885.4, nsentences=32, sample_size=885.4, sample_size_v1=0, sample_size_v2=0, ppl=17.72, wps=450.1, ups=0.51, wpb=885.4, bsz=32, num_updates=18730, lr=2.6008e-05, gnorm=2.377, clip=100, loss_scale=256, train_wall=20, gb_free=15.6, wall=53267
2023-01-09 18:25:40 - progress_bar.py[line:272] - INFO: epoch 006:    444 / 3665 loss=5.054, loss_v1=0, loss_v2=0, nll_loss=4.142, ntokens=972.8, nsentences=32, sample_size=972.8, sample_size_v1=0, sample_size_v2=0, ppl=17.66, wps=495.3, ups=0.51, wpb=972.8, bsz=32, num_updates=18740, lr=2.59934e-05, gnorm=2.437, clip=100, loss_scale=256, train_wall=20, gb_free=15.5, wall=53286
2023-01-09 18:26:00 - progress_bar.py[line:272] - INFO: epoch 006:    454 / 3665 loss=5.079, loss_v1=0, loss_v2=0, nll_loss=4.17, ntokens=918.8, nsentences=32, sample_size=918.8, sample_size_v1=0, sample_size_v2=0, ppl=18, wps=466.6, ups=0.51, wpb=918.8, bsz=32, num_updates=18750, lr=2.59789e-05, gnorm=2.445, clip=100, loss_scale=256, train_wall=20, gb_free=15.2, wall=53306
2023-01-09 18:26:19 - progress_bar.py[line:272] - INFO: epoch 006:    464 / 3665 loss=5.073, loss_v1=0, loss_v2=0, nll_loss=4.162, ntokens=1049.8, nsentences=32, sample_size=1049.8, sample_size_v1=0, sample_size_v2=0, ppl=17.9, wps=532.1, ups=0.51, wpb=1049.8, bsz=32, num_updates=18760, lr=2.59644e-05, gnorm=2.159, clip=100, loss_scale=256, train_wall=20, gb_free=15.1, wall=53326
2023-01-09 18:26:39 - progress_bar.py[line:272] - INFO: epoch 006:    474 / 3665 loss=5.142, loss_v1=0, loss_v2=0, nll_loss=4.24, ntokens=1146.9, nsentences=32, sample_size=1146.9, sample_size_v1=0, sample_size_v2=0, ppl=18.9, wps=576.1, ups=0.5, wpb=1146.9, bsz=32, num_updates=18770, lr=2.59499e-05, gnorm=1.923, clip=100, loss_scale=256, train_wall=20, gb_free=15.4, wall=53346
2023-01-09 18:26:59 - progress_bar.py[line:272] - INFO: epoch 006:    484 / 3665 loss=5.1, loss_v1=0, loss_v2=0, nll_loss=4.196, ntokens=756.4, nsentences=32, sample_size=756.4, sample_size_v1=0, sample_size_v2=0, ppl=18.33, wps=383.1, ups=0.51, wpb=756.4, bsz=32, num_updates=18780, lr=2.59354e-05, gnorm=2.765, clip=100, loss_scale=256, train_wall=20, gb_free=15.5, wall=53365
2023-01-09 18:27:19 - progress_bar.py[line:272] - INFO: epoch 006:    494 / 3665 loss=5.014, loss_v1=0, loss_v2=0, nll_loss=4.098, ntokens=890.6, nsentences=32, sample_size=890.6, sample_size_v1=0, sample_size_v2=0, ppl=17.12, wps=451, ups=0.51, wpb=890.6, bsz=32, num_updates=18790, lr=2.59209e-05, gnorm=2.286, clip=100, loss_scale=256, train_wall=20, gb_free=15.6, wall=53385
2023-01-09 18:27:39 - progress_bar.py[line:272] - INFO: epoch 006:    504 / 3665 loss=5.137, loss_v1=0, loss_v2=0, nll_loss=4.234, ntokens=1037.2, nsentences=32, sample_size=1037.2, sample_size_v1=0, sample_size_v2=0, ppl=18.81, wps=522.3, ups=0.5, wpb=1037.2, bsz=32, num_updates=18800, lr=2.59064e-05, gnorm=2.181, clip=100, loss_scale=256, train_wall=20, gb_free=15.4, wall=53405
2023-01-09 18:27:58 - progress_bar.py[line:272] - INFO: epoch 006:    514 / 3665 loss=5.095, loss_v1=0, loss_v2=0, nll_loss=4.187, ntokens=864.6, nsentences=32, sample_size=864.6, sample_size_v1=0, sample_size_v2=0, ppl=18.22, wps=436.7, ups=0.51, wpb=864.6, bsz=32, num_updates=18810, lr=2.58918e-05, gnorm=2.453, clip=100, loss_scale=256, train_wall=20, gb_free=15.1, wall=53425
2023-01-09 18:28:18 - progress_bar.py[line:272] - INFO: epoch 006:    524 / 3665 loss=5.059, loss_v1=0, loss_v2=0, nll_loss=4.148, ntokens=976.2, nsentences=32, sample_size=976.2, sample_size_v1=0, sample_size_v2=0, ppl=17.73, wps=492.6, ups=0.5, wpb=976.2, bsz=32, num_updates=18820, lr=2.58773e-05, gnorm=2.267, clip=100, loss_scale=256, train_wall=20, gb_free=15, wall=53444
2023-01-09 18:28:38 - progress_bar.py[line:272] - INFO: epoch 006:    534 / 3665 loss=5.095, loss_v1=0, loss_v2=0, nll_loss=4.188, ntokens=924.6, nsentences=32, sample_size=924.6, sample_size_v1=0, sample_size_v2=0, ppl=18.23, wps=466.6, ups=0.5, wpb=924.6, bsz=32, num_updates=18830, lr=2.58628e-05, gnorm=2.504, clip=100, loss_scale=256, train_wall=20, gb_free=15.6, wall=53464
2023-01-09 18:28:58 - progress_bar.py[line:272] - INFO: epoch 006:    544 / 3665 loss=5.094, loss_v1=0, loss_v2=0, nll_loss=4.185, ntokens=816.8, nsentences=32, sample_size=816.8, sample_size_v1=0, sample_size_v2=0, ppl=18.19, wps=412.9, ups=0.51, wpb=816.8, bsz=32, num_updates=18840, lr=2.58483e-05, gnorm=2.584, clip=100, loss_scale=256, train_wall=20, gb_free=15.4, wall=53484
2023-01-09 18:29:18 - progress_bar.py[line:272] - INFO: epoch 006:    554 / 3665 loss=5.059, loss_v1=0, loss_v2=0, nll_loss=4.146, ntokens=1021.1, nsentences=32, sample_size=1021.1, sample_size_v1=0, sample_size_v2=0, ppl=17.71, wps=514.8, ups=0.5, wpb=1021.1, bsz=32, num_updates=18850, lr=2.58338e-05, gnorm=2.074, clip=100, loss_scale=256, train_wall=20, gb_free=15.5, wall=53504
2023-01-09 18:29:38 - progress_bar.py[line:272] - INFO: epoch 006:    564 / 3665 loss=5.086, loss_v1=0, loss_v2=0, nll_loss=4.179, ntokens=941.5, nsentences=32, sample_size=941.5, sample_size_v1=0, sample_size_v2=0, ppl=18.11, wps=473.9, ups=0.5, wpb=941.5, bsz=32, num_updates=18860, lr=2.58193e-05, gnorm=2.238, clip=100, loss_scale=256, train_wall=20, gb_free=15.2, wall=53524
2023-01-09 18:29:57 - progress_bar.py[line:272] - INFO: epoch 006:    574 / 3665 loss=5.015, loss_v1=0, loss_v2=0, nll_loss=4.1, ntokens=858, nsentences=32, sample_size=858, sample_size_v1=0, sample_size_v2=0, ppl=17.15, wps=434.2, ups=0.51, wpb=858, bsz=32, num_updates=18870, lr=2.58048e-05, gnorm=2.662, clip=100, loss_scale=256, train_wall=20, gb_free=15.5, wall=53544
2023-01-09 18:30:17 - progress_bar.py[line:272] - INFO: epoch 006:    584 / 3665 loss=5.052, loss_v1=0, loss_v2=0, nll_loss=4.141, ntokens=1058.3, nsentences=32, sample_size=1058.3, sample_size_v1=0, sample_size_v2=0, ppl=17.64, wps=533.1, ups=0.5, wpb=1058.3, bsz=32, num_updates=18880, lr=2.57903e-05, gnorm=2.168, clip=100, loss_scale=256, train_wall=20, gb_free=14.4, wall=53563
2023-01-09 18:30:37 - progress_bar.py[line:272] - INFO: epoch 006:    594 / 3665 loss=5.101, loss_v1=0, loss_v2=0, nll_loss=4.194, ntokens=752, nsentences=32, sample_size=752, sample_size_v1=0, sample_size_v2=0, ppl=18.3, wps=380.7, ups=0.51, wpb=752, bsz=32, num_updates=18890, lr=2.57757e-05, gnorm=2.73, clip=100, loss_scale=256, train_wall=20, gb_free=15.6, wall=53583
2023-01-09 18:30:57 - progress_bar.py[line:272] - INFO: epoch 006:    604 / 3665 loss=5.072, loss_v1=0, loss_v2=0, nll_loss=4.162, ntokens=960.9, nsentences=32, sample_size=960.9, sample_size_v1=0, sample_size_v2=0, ppl=17.91, wps=485.6, ups=0.51, wpb=960.9, bsz=32, num_updates=18900, lr=2.57612e-05, gnorm=2.286, clip=100, loss_scale=256, train_wall=20, gb_free=15.5, wall=53603
2023-01-09 18:31:17 - progress_bar.py[line:272] - INFO: epoch 006:    614 / 3665 loss=5.159, loss_v1=0, loss_v2=0, nll_loss=4.26, ntokens=1066.4, nsentences=32, sample_size=1066.4, sample_size_v1=0, sample_size_v2=0, ppl=19.15, wps=536.6, ups=0.5, wpb=1066.4, bsz=32, num_updates=18910, lr=2.57467e-05, gnorm=2.141, clip=100, loss_scale=256, train_wall=20, gb_free=15.1, wall=53623
2023-01-09 18:31:36 - progress_bar.py[line:272] - INFO: epoch 006:    624 / 3665 loss=5.059, loss_v1=0, loss_v2=0, nll_loss=4.147, ntokens=776.1, nsentences=32, sample_size=776.1, sample_size_v1=0, sample_size_v2=0, ppl=17.72, wps=393, ups=0.51, wpb=776.1, bsz=32, num_updates=18920, lr=2.57322e-05, gnorm=2.556, clip=100, loss_scale=256, train_wall=20, gb_free=15.4, wall=53643
2023-01-09 18:31:56 - progress_bar.py[line:272] - INFO: epoch 006:    634 / 3665 loss=4.976, loss_v1=0, loss_v2=0, nll_loss=4.055, ntokens=931.1, nsentences=32, sample_size=931.1, sample_size_v1=0, sample_size_v2=0, ppl=16.62, wps=466.4, ups=0.5, wpb=931.1, bsz=32, num_updates=18930, lr=2.57177e-05, gnorm=2.348, clip=100, loss_scale=256, train_wall=20, gb_free=15.6, wall=53663
2023-01-09 18:32:16 - progress_bar.py[line:272] - INFO: epoch 006:    644 / 3665 loss=5.234, loss_v1=0, loss_v2=0, nll_loss=4.342, ntokens=1168.4, nsentences=32, sample_size=1168.4, sample_size_v1=0, sample_size_v2=0, ppl=20.28, wps=586.9, ups=0.5, wpb=1168.4, bsz=32, num_updates=18940, lr=2.57032e-05, gnorm=2.101, clip=100, loss_scale=256, train_wall=20, gb_free=15.2, wall=53682
2023-01-09 18:32:36 - progress_bar.py[line:272] - INFO: epoch 006:    654 / 3665 loss=4.985, loss_v1=0, loss_v2=0, nll_loss=4.065, ntokens=680.2, nsentences=32, sample_size=680.2, sample_size_v1=0, sample_size_v2=0, ppl=16.74, wps=346.1, ups=0.51, wpb=680.2, bsz=32, num_updates=18950, lr=2.56887e-05, gnorm=2.949, clip=100, loss_scale=256, train_wall=20, gb_free=15.6, wall=53702
2023-01-09 18:32:56 - progress_bar.py[line:272] - INFO: epoch 006:    664 / 3665 loss=5.069, loss_v1=0, loss_v2=0, nll_loss=4.159, ntokens=1029.4, nsentences=32, sample_size=1029.4, sample_size_v1=0, sample_size_v2=0, ppl=17.87, wps=519.2, ups=0.5, wpb=1029.4, bsz=32, num_updates=18960, lr=2.56741e-05, gnorm=2.2, clip=100, loss_scale=256, train_wall=20, gb_free=14.8, wall=53722
2023-01-09 18:33:15 - progress_bar.py[line:272] - INFO: epoch 006:    674 / 3665 loss=5.128, loss_v1=0, loss_v2=0, nll_loss=4.223, ntokens=894, nsentences=32, sample_size=894, sample_size_v1=0, sample_size_v2=0, ppl=18.68, wps=452.4, ups=0.51, wpb=894, bsz=32, num_updates=18970, lr=2.56596e-05, gnorm=2.417, clip=100, loss_scale=512, train_wall=20, gb_free=15.5, wall=53742
2023-01-09 18:33:31 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 256.0
2023-01-09 18:33:37 - progress_bar.py[line:272] - INFO: epoch 006:    685 / 3665 loss=5.029, loss_v1=0, loss_v2=0, nll_loss=4.116, ntokens=888.4, nsentences=32, sample_size=888.4, sample_size_v1=0, sample_size_v2=0, ppl=17.34, wps=409.6, ups=0.46, wpb=888.4, bsz=32, num_updates=18980, lr=2.56451e-05, gnorm=2.359, clip=100, loss_scale=256, train_wall=22, gb_free=15.6, wall=53763
2023-01-09 18:33:57 - progress_bar.py[line:272] - INFO: epoch 006:    695 / 3665 loss=5.089, loss_v1=0, loss_v2=0, nll_loss=4.182, ntokens=990.5, nsentences=32, sample_size=990.5, sample_size_v1=0, sample_size_v2=0, ppl=18.15, wps=500.3, ups=0.51, wpb=990.5, bsz=32, num_updates=18990, lr=2.56306e-05, gnorm=2.278, clip=100, loss_scale=256, train_wall=20, gb_free=15.3, wall=53783
2023-01-09 18:34:17 - progress_bar.py[line:272] - INFO: epoch 006:    705 / 3665 loss=5.14, loss_v1=0, loss_v2=0, nll_loss=4.24, ntokens=870.7, nsentences=32, sample_size=870.7, sample_size_v1=0, sample_size_v2=0, ppl=18.89, wps=440, ups=0.51, wpb=870.7, bsz=32, num_updates=19000, lr=2.56161e-05, gnorm=2.398, clip=100, loss_scale=256, train_wall=20, gb_free=15.4, wall=53803
2023-01-09 18:34:17 - train.py[line:445] - INFO: begin validation on "valid" subset
slice_id 0 seek offset 0
slice_id 0 seek offset 0
2023-01-09 18:39:16 - progress_bar.py[line:282] - INFO: epoch 006 | valid on 'valid' subset | loss 5.064 | loss_v1 0 | loss_v2 0 | nll_loss 4.138 | ntokens 116.999 | nsentences 4 | sample_size 116.999 | sample_size_v1 0 | sample_size_v2 0 | AP 0 | total positives 21.7108 | TP 0 | FP 5.75848 | ppl 17.6 | wps 488.7 | wpb 117 | bsz 4 | num_updates 19000 | best_AP 0
2023-01-09 18:39:16 - checkpoint_utils.py[line:64] - INFO: Preparing to save checkpoint for epoch 6 @ 19000 updates
2023-01-09 18:39:16 - trainer.py[line:431] - INFO: Saving checkpoint to ../../checkpoints/OFA/detection_checkpoints/10_5e-5_512/checkpoint_6_19000.pt
2023-01-09 18:39:19 - trainer.py[line:441] - INFO: Finished saving checkpoint to ../../checkpoints/OFA/detection_checkpoints/10_5e-5_512/checkpoint_6_19000.pt
2023-01-09 18:40:33 - checkpoint_utils.py[line:133] - INFO: Saved checkpoint ../../checkpoints/OFA/detection_checkpoints/10_5e-5_512/checkpoint_6_19000.pt (epoch 6 @ 19000 updates, score 0.0) (writing took 76.72890231385827 seconds)
2023-01-09 18:40:52 - progress_bar.py[line:272] - INFO: epoch 006:    715 / 3665 loss=5.066, loss_v1=0, loss_v2=0, nll_loss=4.157, ntokens=923.3, nsentences=32, sample_size=923.3, sample_size_v1=0, sample_size_v2=0, ppl=17.84, wps=23.3, ups=0.03, wpb=923.3, bsz=32, num_updates=19010, lr=2.56016e-05, gnorm=2.453, clip=100, loss_scale=256, train_wall=19, gb_free=15.2, wall=54198
2023-01-09 18:41:12 - progress_bar.py[line:272] - INFO: epoch 006:    725 / 3665 loss=5.163, loss_v1=0, loss_v2=0, nll_loss=4.264, ntokens=1054.4, nsentences=32, sample_size=1054.4, sample_size_v1=0, sample_size_v2=0, ppl=19.21, wps=539.9, ups=0.51, wpb=1054.4, bsz=32, num_updates=19020, lr=2.55871e-05, gnorm=2.329, clip=100, loss_scale=256, train_wall=20, gb_free=15.3, wall=54218
2023-01-09 18:41:31 - progress_bar.py[line:272] - INFO: epoch 006:    735 / 3665 loss=5.071, loss_v1=0, loss_v2=0, nll_loss=4.16, ntokens=761.3, nsentences=32, sample_size=761.3, sample_size_v1=0, sample_size_v2=0, ppl=17.88, wps=390.1, ups=0.51, wpb=761.3, bsz=32, num_updates=19030, lr=2.55726e-05, gnorm=2.72, clip=100, loss_scale=256, train_wall=19, gb_free=15.5, wall=54238
2023-01-09 18:41:51 - progress_bar.py[line:272] - INFO: epoch 006:    745 / 3665 loss=5.004, loss_v1=0, loss_v2=0, nll_loss=4.086, ntokens=862.1, nsentences=32, sample_size=862.1, sample_size_v1=0, sample_size_v2=0, ppl=16.98, wps=439.8, ups=0.51, wpb=862.1, bsz=32, num_updates=19040, lr=2.5558e-05, gnorm=2.508, clip=100, loss_scale=256, train_wall=20, gb_free=15.5, wall=54257
2023-01-09 18:42:11 - progress_bar.py[line:272] - INFO: epoch 006:    755 / 3665 loss=5.153, loss_v1=0, loss_v2=0, nll_loss=4.254, ntokens=1026.6, nsentences=32, sample_size=1026.6, sample_size_v1=0, sample_size_v2=0, ppl=19.07, wps=521.2, ups=0.51, wpb=1026.6, bsz=32, num_updates=19050, lr=2.55435e-05, gnorm=2.11, clip=100, loss_scale=256, train_wall=20, gb_free=15.3, wall=54277
2023-01-09 18:42:30 - progress_bar.py[line:272] - INFO: epoch 006:    765 / 3665 loss=5.017, loss_v1=0, loss_v2=0, nll_loss=4.101, ntokens=824.9, nsentences=32, sample_size=824.9, sample_size_v1=0, sample_size_v2=0, ppl=17.16, wps=421.5, ups=0.51, wpb=824.9, bsz=32, num_updates=19060, lr=2.5529e-05, gnorm=2.57, clip=100, loss_scale=256, train_wall=20, gb_free=15.5, wall=54296
2023-01-09 18:42:50 - progress_bar.py[line:272] - INFO: epoch 006:    775 / 3665 loss=5.05, loss_v1=0, loss_v2=0, nll_loss=4.138, ntokens=998.5, nsentences=32, sample_size=998.5, sample_size_v1=0, sample_size_v2=0, ppl=17.6, wps=509.3, ups=0.51, wpb=998.5, bsz=32, num_updates=19070, lr=2.55145e-05, gnorm=2.143, clip=100, loss_scale=256, train_wall=20, gb_free=15.1, wall=54316
2023-01-09 18:43:09 - progress_bar.py[line:272] - INFO: epoch 006:    785 / 3665 loss=5.12, loss_v1=0, loss_v2=0, nll_loss=4.217, ntokens=876.1, nsentences=32, sample_size=876.1, sample_size_v1=0, sample_size_v2=0, ppl=18.6, wps=445.8, ups=0.51, wpb=876.1, bsz=32, num_updates=19080, lr=2.55e-05, gnorm=2.368, clip=100, loss_scale=256, train_wall=20, gb_free=14.7, wall=54336
2023-01-09 18:43:29 - progress_bar.py[line:272] - INFO: epoch 006:    795 / 3665 loss=5.063, loss_v1=0, loss_v2=0, nll_loss=4.15, ntokens=917.6, nsentences=32, sample_size=917.6, sample_size_v1=0, sample_size_v2=0, ppl=17.76, wps=467.3, ups=0.51, wpb=917.6, bsz=32, num_updates=19090, lr=2.54855e-05, gnorm=2.197, clip=100, loss_scale=256, train_wall=20, gb_free=15.6, wall=54355
2023-01-09 18:43:49 - progress_bar.py[line:272] - INFO: epoch 006:    805 / 3665 loss=5.069, loss_v1=0, loss_v2=0, nll_loss=4.159, ntokens=1030.8, nsentences=32, sample_size=1030.8, sample_size_v1=0, sample_size_v2=0, ppl=17.87, wps=523.6, ups=0.51, wpb=1030.8, bsz=32, num_updates=19100, lr=2.5471e-05, gnorm=2.101, clip=100, loss_scale=256, train_wall=20, gb_free=15.4, wall=54375
2023-01-09 18:44:08 - progress_bar.py[line:272] - INFO: epoch 006:    815 / 3665 loss=5.027, loss_v1=0, loss_v2=0, nll_loss=4.112, ntokens=805.3, nsentences=32, sample_size=805.3, sample_size_v1=0, sample_size_v2=0, ppl=17.29, wps=410.8, ups=0.51, wpb=805.3, bsz=32, num_updates=19110, lr=2.54564e-05, gnorm=2.622, clip=100, loss_scale=256, train_wall=20, gb_free=15.3, wall=54395
2023-01-09 18:44:28 - progress_bar.py[line:272] - INFO: epoch 006:    825 / 3665 loss=4.995, loss_v1=0, loss_v2=0, nll_loss=4.076, ntokens=836.1, nsentences=32, sample_size=836.1, sample_size_v1=0, sample_size_v2=0, ppl=16.87, wps=426.1, ups=0.51, wpb=836.1, bsz=32, num_updates=19120, lr=2.54419e-05, gnorm=2.502, clip=100, loss_scale=256, train_wall=20, gb_free=15.5, wall=54414
2023-01-09 18:44:48 - progress_bar.py[line:272] - INFO: epoch 006:    835 / 3665 loss=5.091, loss_v1=0, loss_v2=0, nll_loss=4.185, ntokens=1014.1, nsentences=32, sample_size=1014.1, sample_size_v1=0, sample_size_v2=0, ppl=18.19, wps=511.1, ups=0.5, wpb=1014.1, bsz=32, num_updates=19130, lr=2.54274e-05, gnorm=2.245, clip=100, loss_scale=256, train_wall=20, gb_free=15.1, wall=54434
2023-01-09 18:45:08 - progress_bar.py[line:272] - INFO: epoch 006:    845 / 3665 loss=5.045, loss_v1=0, loss_v2=0, nll_loss=4.134, ntokens=704.7, nsentences=32, sample_size=704.7, sample_size_v1=0, sample_size_v2=0, ppl=17.55, wps=351.7, ups=0.5, wpb=704.7, bsz=32, num_updates=19140, lr=2.54129e-05, gnorm=2.78, clip=100, loss_scale=256, train_wall=20, gb_free=15.4, wall=54454
2023-01-09 18:45:28 - progress_bar.py[line:272] - INFO: epoch 006:    855 / 3665 loss=5.003, loss_v1=0, loss_v2=0, nll_loss=4.083, ntokens=901.4, nsentences=32, sample_size=901.4, sample_size_v1=0, sample_size_v2=0, ppl=16.95, wps=449.4, ups=0.5, wpb=901.4, bsz=32, num_updates=19150, lr=2.53984e-05, gnorm=2.267, clip=100, loss_scale=256, train_wall=20, gb_free=15.5, wall=54474
2023-01-09 18:45:48 - progress_bar.py[line:272] - INFO: epoch 006:    865 / 3665 loss=5.177, loss_v1=0, loss_v2=0, nll_loss=4.28, ntokens=1211.5, nsentences=32, sample_size=1211.5, sample_size_v1=0, sample_size_v2=0, ppl=19.42, wps=598.8, ups=0.49, wpb=1211.5, bsz=32, num_updates=19160, lr=2.53839e-05, gnorm=1.941, clip=100, loss_scale=256, train_wall=20, gb_free=15.2, wall=54494
2023-01-09 18:46:08 - progress_bar.py[line:272] - INFO: epoch 006:    875 / 3665 loss=5.063, loss_v1=0, loss_v2=0, nll_loss=4.152, ntokens=831.4, nsentences=32, sample_size=831.4, sample_size_v1=0, sample_size_v2=0, ppl=17.78, wps=416.1, ups=0.5, wpb=831.4, bsz=32, num_updates=19170, lr=2.53694e-05, gnorm=2.478, clip=100, loss_scale=256, train_wall=20, gb_free=15.4, wall=54514
2023-01-09 18:46:28 - progress_bar.py[line:272] - INFO: epoch 006:    885 / 3665 loss=4.936, loss_v1=0, loss_v2=0, nll_loss=4.01, ntokens=874.4, nsentences=32, sample_size=874.4, sample_size_v1=0, sample_size_v2=0, ppl=16.11, wps=441.5, ups=0.5, wpb=874.4, bsz=32, num_updates=19180, lr=2.53549e-05, gnorm=2.316, clip=100, loss_scale=256, train_wall=20, gb_free=15.2, wall=54534
2023-01-09 18:46:48 - progress_bar.py[line:272] - INFO: epoch 006:    895 / 3665 loss=5.139, loss_v1=0, loss_v2=0, nll_loss=4.237, ntokens=1065.8, nsentences=32, sample_size=1065.8, sample_size_v1=0, sample_size_v2=0, ppl=18.86, wps=537.6, ups=0.5, wpb=1065.8, bsz=32, num_updates=19190, lr=2.53403e-05, gnorm=2.1, clip=100, loss_scale=256, train_wall=20, gb_free=15.3, wall=54554
2023-01-09 18:47:07 - progress_bar.py[line:272] - INFO: epoch 006:    905 / 3665 loss=5.045, loss_v1=0, loss_v2=0, nll_loss=4.133, ntokens=854.4, nsentences=32, sample_size=854.4, sample_size_v1=0, sample_size_v2=0, ppl=17.54, wps=432.9, ups=0.51, wpb=854.4, bsz=32, num_updates=19200, lr=2.53258e-05, gnorm=2.348, clip=100, loss_scale=256, train_wall=20, gb_free=15.4, wall=54574
2023-01-09 18:47:27 - progress_bar.py[line:272] - INFO: epoch 006:    915 / 3665 loss=5.045, loss_v1=0, loss_v2=0, nll_loss=4.132, ntokens=1010.1, nsentences=32, sample_size=1010.1, sample_size_v1=0, sample_size_v2=0, ppl=17.54, wps=510.9, ups=0.51, wpb=1010.1, bsz=32, num_updates=19210, lr=2.53113e-05, gnorm=2.082, clip=100, loss_scale=256, train_wall=20, gb_free=15.6, wall=54594
2023-01-09 18:47:47 - progress_bar.py[line:272] - INFO: epoch 006:    925 / 3665 loss=5.121, loss_v1=0, loss_v2=0, nll_loss=4.216, ntokens=937.9, nsentences=32, sample_size=937.9, sample_size_v1=0, sample_size_v2=0, ppl=18.59, wps=474, ups=0.51, wpb=937.9, bsz=32, num_updates=19220, lr=2.52968e-05, gnorm=2.248, clip=100, loss_scale=256, train_wall=20, gb_free=15.3, wall=54613
2023-01-09 18:48:07 - progress_bar.py[line:272] - INFO: epoch 006:    935 / 3665 loss=5.1, loss_v1=0, loss_v2=0, nll_loss=4.195, ntokens=878.4, nsentences=32, sample_size=878.4, sample_size_v1=0, sample_size_v2=0, ppl=18.31, wps=445, ups=0.51, wpb=878.4, bsz=32, num_updates=19230, lr=2.52823e-05, gnorm=2.263, clip=100, loss_scale=256, train_wall=20, gb_free=15.4, wall=54633
2023-01-09 18:48:27 - progress_bar.py[line:272] - INFO: epoch 006:    945 / 3665 loss=5.009, loss_v1=0, loss_v2=0, nll_loss=4.093, ntokens=977.6, nsentences=32, sample_size=977.6, sample_size_v1=0, sample_size_v2=0, ppl=17.06, wps=494.9, ups=0.51, wpb=977.6, bsz=32, num_updates=19240, lr=2.52678e-05, gnorm=2.279, clip=100, loss_scale=256, train_wall=20, gb_free=15.1, wall=54653
2023-01-09 18:48:46 - progress_bar.py[line:272] - INFO: epoch 006:    955 / 3665 loss=5.035, loss_v1=0, loss_v2=0, nll_loss=4.12, ntokens=771, nsentences=32, sample_size=771, sample_size_v1=0, sample_size_v2=0, ppl=17.38, wps=391.7, ups=0.51, wpb=771, bsz=32, num_updates=19250, lr=2.52533e-05, gnorm=2.648, clip=100, loss_scale=256, train_wall=20, gb_free=15.2, wall=54672
2023-01-09 18:49:06 - progress_bar.py[line:272] - INFO: epoch 006:    965 / 3665 loss=5.041, loss_v1=0, loss_v2=0, nll_loss=4.126, ntokens=939, nsentences=32, sample_size=939, sample_size_v1=0, sample_size_v2=0, ppl=17.46, wps=476.2, ups=0.51, wpb=939, bsz=32, num_updates=19260, lr=2.52387e-05, gnorm=2.211, clip=100, loss_scale=256, train_wall=20, gb_free=15.5, wall=54692
2023-01-09 18:49:26 - progress_bar.py[line:272] - INFO: epoch 006:    975 / 3665 loss=5.111, loss_v1=0, loss_v2=0, nll_loss=4.206, ntokens=950.4, nsentences=32, sample_size=950.4, sample_size_v1=0, sample_size_v2=0, ppl=18.46, wps=480.6, ups=0.51, wpb=950.4, bsz=32, num_updates=19270, lr=2.52242e-05, gnorm=2.295, clip=100, loss_scale=256, train_wall=20, gb_free=15.2, wall=54712
2023-01-09 18:49:45 - progress_bar.py[line:272] - INFO: epoch 006:    985 / 3665 loss=5.005, loss_v1=0, loss_v2=0, nll_loss=4.088, ntokens=790, nsentences=32, sample_size=790, sample_size_v1=0, sample_size_v2=0, ppl=17.01, wps=400.3, ups=0.51, wpb=790, bsz=32, num_updates=19280, lr=2.52097e-05, gnorm=2.713, clip=100, loss_scale=256, train_wall=20, gb_free=15.3, wall=54732
2023-01-09 18:50:05 - progress_bar.py[line:272] - INFO: epoch 006:    995 / 3665 loss=5.104, loss_v1=0, loss_v2=0, nll_loss=4.197, ntokens=967.2, nsentences=32, sample_size=967.2, sample_size_v1=0, sample_size_v2=0, ppl=18.33, wps=488.6, ups=0.51, wpb=967.2, bsz=32, num_updates=19290, lr=2.51952e-05, gnorm=2.068, clip=100, loss_scale=256, train_wall=20, gb_free=15.3, wall=54751
2023-01-09 18:50:25 - progress_bar.py[line:272] - INFO: epoch 006:   1005 / 3665 loss=5.158, loss_v1=0, loss_v2=0, nll_loss=4.257, ntokens=1000.4, nsentences=32, sample_size=1000.4, sample_size_v1=0, sample_size_v2=0, ppl=19.12, wps=505.1, ups=0.5, wpb=1000.4, bsz=32, num_updates=19300, lr=2.51807e-05, gnorm=2.128, clip=100, loss_scale=256, train_wall=20, gb_free=15.3, wall=54771
2023-01-09 18:50:45 - progress_bar.py[line:272] - INFO: epoch 006:   1015 / 3665 loss=4.991, loss_v1=0, loss_v2=0, nll_loss=4.073, ntokens=781.1, nsentences=32, sample_size=781.1, sample_size_v1=0, sample_size_v2=0, ppl=16.83, wps=395.8, ups=0.51, wpb=781.1, bsz=32, num_updates=19310, lr=2.51662e-05, gnorm=2.438, clip=100, loss_scale=256, train_wall=20, gb_free=15.3, wall=54791
2023-01-09 18:51:05 - progress_bar.py[line:272] - INFO: epoch 006:   1025 / 3665 loss=5.081, loss_v1=0, loss_v2=0, nll_loss=4.174, ntokens=1069.9, nsentences=32, sample_size=1069.9, sample_size_v1=0, sample_size_v2=0, ppl=18.05, wps=540.3, ups=0.5, wpb=1069.9, bsz=32, num_updates=19320, lr=2.51517e-05, gnorm=2.135, clip=100, loss_scale=256, train_wall=20, gb_free=15, wall=54811
2023-01-09 18:51:24 - progress_bar.py[line:272] - INFO: epoch 006:   1035 / 3665 loss=5.116, loss_v1=0, loss_v2=0, nll_loss=4.211, ntokens=883.1, nsentences=32, sample_size=883.1, sample_size_v1=0, sample_size_v2=0, ppl=18.52, wps=447.3, ups=0.51, wpb=883.1, bsz=32, num_updates=19330, lr=2.51372e-05, gnorm=2.484, clip=100, loss_scale=256, train_wall=20, gb_free=15.7, wall=54831
2023-01-09 18:51:44 - progress_bar.py[line:272] - INFO: epoch 006:   1045 / 3665 loss=4.886, loss_v1=0, loss_v2=0, nll_loss=3.953, ntokens=601.5, nsentences=32, sample_size=601.5, sample_size_v1=0, sample_size_v2=0, ppl=15.48, wps=306.3, ups=0.51, wpb=601.5, bsz=32, num_updates=19340, lr=2.51226e-05, gnorm=3.062, clip=100, loss_scale=256, train_wall=20, gb_free=15.6, wall=54850
2023-01-09 18:52:04 - progress_bar.py[line:272] - INFO: epoch 006:   1055 / 3665 loss=5.069, loss_v1=0, loss_v2=0, nll_loss=4.16, ntokens=1019.7, nsentences=32, sample_size=1019.7, sample_size_v1=0, sample_size_v2=0, ppl=17.87, wps=515.9, ups=0.51, wpb=1019.7, bsz=32, num_updates=19350, lr=2.51081e-05, gnorm=2.025, clip=100, loss_scale=256, train_wall=20, gb_free=15.2, wall=54870
2023-01-09 18:52:23 - progress_bar.py[line:272] - INFO: epoch 006:   1065 / 3665 loss=5.139, loss_v1=0, loss_v2=0, nll_loss=4.237, ntokens=952.3, nsentences=32, sample_size=952.3, sample_size_v1=0, sample_size_v2=0, ppl=18.86, wps=481.5, ups=0.51, wpb=952.3, bsz=32, num_updates=19360, lr=2.50936e-05, gnorm=2.442, clip=100, loss_scale=256, train_wall=20, gb_free=15, wall=54890
2023-01-09 18:52:43 - progress_bar.py[line:272] - INFO: epoch 006:   1075 / 3665 loss=4.962, loss_v1=0, loss_v2=0, nll_loss=4.04, ntokens=786, nsentences=32, sample_size=786, sample_size_v1=0, sample_size_v2=0, ppl=16.45, wps=396.8, ups=0.5, wpb=786, bsz=32, num_updates=19370, lr=2.50791e-05, gnorm=2.657, clip=100, loss_scale=256, train_wall=20, gb_free=15.1, wall=54910
2023-01-09 18:53:03 - progress_bar.py[line:272] - INFO: epoch 006:   1085 / 3665 loss=5.087, loss_v1=0, loss_v2=0, nll_loss=4.18, ntokens=1091.6, nsentences=32, sample_size=1091.6, sample_size_v1=0, sample_size_v2=0, ppl=18.13, wps=552.7, ups=0.51, wpb=1091.6, bsz=32, num_updates=19380, lr=2.50646e-05, gnorm=2.07, clip=100, loss_scale=256, train_wall=20, gb_free=15.2, wall=54929
2023-01-09 18:53:23 - progress_bar.py[line:272] - INFO: epoch 006:   1095 / 3665 loss=4.889, loss_v1=0, loss_v2=0, nll_loss=3.959, ntokens=674.1, nsentences=32, sample_size=674.1, sample_size_v1=0, sample_size_v2=0, ppl=15.56, wps=344.7, ups=0.51, wpb=674.1, bsz=32, num_updates=19390, lr=2.50501e-05, gnorm=2.929, clip=100, loss_scale=256, train_wall=20, gb_free=15.4, wall=54949
2023-01-09 18:53:42 - progress_bar.py[line:272] - INFO: epoch 006:   1105 / 3665 loss=5.103, loss_v1=0, loss_v2=0, nll_loss=4.197, ntokens=982.3, nsentences=32, sample_size=982.3, sample_size_v1=0, sample_size_v2=0, ppl=18.34, wps=497.1, ups=0.51, wpb=982.3, bsz=32, num_updates=19400, lr=2.50356e-05, gnorm=2.456, clip=100, loss_scale=256, train_wall=20, gb_free=15.6, wall=54969
2023-01-09 18:54:02 - progress_bar.py[line:272] - INFO: epoch 006:   1115 / 3665 loss=5.034, loss_v1=0, loss_v2=0, nll_loss=4.118, ntokens=883.3, nsentences=32, sample_size=883.3, sample_size_v1=0, sample_size_v2=0, ppl=17.36, wps=448.3, ups=0.51, wpb=883.3, bsz=32, num_updates=19410, lr=2.5021e-05, gnorm=2.527, clip=100, loss_scale=256, train_wall=20, gb_free=15.3, wall=54988
2023-01-09 18:54:22 - progress_bar.py[line:272] - INFO: epoch 006:   1125 / 3665 loss=4.986, loss_v1=0, loss_v2=0, nll_loss=4.068, ntokens=1062.5, nsentences=32, sample_size=1062.5, sample_size_v1=0, sample_size_v2=0, ppl=16.77, wps=538.7, ups=0.51, wpb=1062.5, bsz=32, num_updates=19420, lr=2.50065e-05, gnorm=2.007, clip=100, loss_scale=256, train_wall=20, gb_free=15.4, wall=55008
2023-01-09 18:54:42 - progress_bar.py[line:272] - INFO: epoch 006:   1135 / 3665 loss=5.16, loss_v1=0, loss_v2=0, nll_loss=4.262, ntokens=1103.2, nsentences=32, sample_size=1103.2, sample_size_v1=0, sample_size_v2=0, ppl=19.18, wps=557.4, ups=0.51, wpb=1103.2, bsz=32, num_updates=19430, lr=2.4992e-05, gnorm=2.165, clip=100, loss_scale=256, train_wall=20, gb_free=15.2, wall=55028
2023-01-09 18:55:01 - progress_bar.py[line:272] - INFO: epoch 006:   1145 / 3665 loss=5.007, loss_v1=0, loss_v2=0, nll_loss=4.089, ntokens=745.4, nsentences=32, sample_size=745.4, sample_size_v1=0, sample_size_v2=0, ppl=17.02, wps=379.1, ups=0.51, wpb=745.4, bsz=32, num_updates=19440, lr=2.49775e-05, gnorm=2.741, clip=100, loss_scale=256, train_wall=20, gb_free=15, wall=55048
2023-01-09 18:55:21 - progress_bar.py[line:272] - INFO: epoch 006:   1155 / 3665 loss=5.004, loss_v1=0, loss_v2=0, nll_loss=4.088, ntokens=853.1, nsentences=32, sample_size=853.1, sample_size_v1=0, sample_size_v2=0, ppl=17.01, wps=433.3, ups=0.51, wpb=853.1, bsz=32, num_updates=19450, lr=2.4963e-05, gnorm=2.478, clip=100, loss_scale=256, train_wall=20, gb_free=15.2, wall=55067
2023-01-09 18:55:41 - progress_bar.py[line:272] - INFO: epoch 006:   1165 / 3665 loss=5.071, loss_v1=0, loss_v2=0, nll_loss=4.159, ntokens=1048.8, nsentences=32, sample_size=1048.8, sample_size_v1=0, sample_size_v2=0, ppl=17.87, wps=530.6, ups=0.51, wpb=1048.8, bsz=32, num_updates=19460, lr=2.49485e-05, gnorm=2.188, clip=100, loss_scale=256, train_wall=20, gb_free=15.5, wall=55087
2023-01-09 18:56:00 - progress_bar.py[line:272] - INFO: epoch 006:   1175 / 3665 loss=4.946, loss_v1=0, loss_v2=0, nll_loss=4.022, ntokens=660, nsentences=32, sample_size=660, sample_size_v1=0, sample_size_v2=0, ppl=16.25, wps=336, ups=0.51, wpb=660, bsz=32, num_updates=19470, lr=2.4934e-05, gnorm=3.127, clip=100, loss_scale=256, train_wall=20, gb_free=15.3, wall=55107
2023-01-09 18:56:20 - progress_bar.py[line:272] - INFO: epoch 006:   1185 / 3665 loss=5.042, loss_v1=0, loss_v2=0, nll_loss=4.129, ntokens=944.7, nsentences=32, sample_size=944.7, sample_size_v1=0, sample_size_v2=0, ppl=17.49, wps=478.5, ups=0.51, wpb=944.7, bsz=32, num_updates=19480, lr=2.49195e-05, gnorm=2.314, clip=100, loss_scale=256, train_wall=20, gb_free=15.6, wall=55126
2023-01-09 18:56:40 - progress_bar.py[line:272] - INFO: epoch 006:   1195 / 3665 loss=5.125, loss_v1=0, loss_v2=0, nll_loss=4.222, ntokens=1241.4, nsentences=32, sample_size=1241.4, sample_size_v1=0, sample_size_v2=0, ppl=18.67, wps=624.9, ups=0.5, wpb=1241.4, bsz=32, num_updates=19490, lr=2.49049e-05, gnorm=1.911, clip=100, loss_scale=512, train_wall=20, gb_free=14.8, wall=55146
2023-01-09 18:57:00 - progress_bar.py[line:272] - INFO: epoch 006:   1205 / 3665 loss=5.18, loss_v1=0, loss_v2=0, nll_loss=4.282, ntokens=902.8, nsentences=32, sample_size=902.8, sample_size_v1=0, sample_size_v2=0, ppl=19.45, wps=457.7, ups=0.51, wpb=902.8, bsz=32, num_updates=19500, lr=2.48904e-05, gnorm=2.486, clip=100, loss_scale=512, train_wall=20, gb_free=15.3, wall=55166
2023-01-09 18:57:00 - train.py[line:445] - INFO: begin validation on "valid" subset
slice_id 0 seek offset 0
slice_id 0 seek offset 0
2023-01-09 19:01:56 - progress_bar.py[line:282] - INFO: epoch 006 | valid on 'valid' subset | loss 5.063 | loss_v1 0 | loss_v2 0 | nll_loss 4.134 | ntokens 116.851 | nsentences 4 | sample_size 116.851 | sample_size_v1 0 | sample_size_v2 0 | AP 0 | total positives 21.6834 | TP 0 | FP 5.47738 | ppl 17.56 | wps 491.8 | wpb 116.9 | bsz 4 | num_updates 19500 | best_AP 0
2023-01-09 19:01:56 - checkpoint_utils.py[line:64] - INFO: Preparing to save checkpoint for epoch 6 @ 19500 updates
2023-01-09 19:01:56 - trainer.py[line:431] - INFO: Saving checkpoint to ../../checkpoints/OFA/detection_checkpoints/10_5e-5_512/checkpoint_6_19500.pt
2023-01-09 19:02:00 - trainer.py[line:441] - INFO: Finished saving checkpoint to ../../checkpoints/OFA/detection_checkpoints/10_5e-5_512/checkpoint_6_19500.pt
2023-01-09 19:03:14 - checkpoint_utils.py[line:133] - INFO: Saved checkpoint ../../checkpoints/OFA/detection_checkpoints/10_5e-5_512/checkpoint_6_19500.pt (epoch 6 @ 19500 updates, score 0.0) (writing took 77.313123350963 seconds)
2023-01-09 19:03:33 - progress_bar.py[line:272] - INFO: epoch 006:   1215 / 3665 loss=5.069, loss_v1=0, loss_v2=0, nll_loss=4.158, ntokens=848.1, nsentences=32, sample_size=848.1, sample_size_v1=0, sample_size_v2=0, ppl=17.85, wps=21.6, ups=0.03, wpb=848.1, bsz=32, num_updates=19510, lr=2.48759e-05, gnorm=2.623, clip=100, loss_scale=512, train_wall=19, gb_free=15.5, wall=55559
2023-01-09 19:03:35 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 256.0
2023-01-09 19:03:55 - progress_bar.py[line:272] - INFO: epoch 006:   1226 / 3665 loss=5.029, loss_v1=0, loss_v2=0, nll_loss=4.113, ntokens=1052.1, nsentences=32, sample_size=1052.1, sample_size_v1=0, sample_size_v2=0, ppl=17.3, wps=489.5, ups=0.47, wpb=1052.1, bsz=32, num_updates=19520, lr=2.48614e-05, gnorm=2.209, clip=100, loss_scale=256, train_wall=21, gb_free=15.1, wall=55581
2023-01-09 19:04:14 - progress_bar.py[line:272] - INFO: epoch 006:   1236 / 3665 loss=5.185, loss_v1=0, loss_v2=0, nll_loss=4.288, ntokens=1084, nsentences=32, sample_size=1084, sample_size_v1=0, sample_size_v2=0, ppl=19.54, wps=550, ups=0.51, wpb=1084, bsz=32, num_updates=19530, lr=2.48469e-05, gnorm=2.096, clip=100, loss_scale=256, train_wall=20, gb_free=15.5, wall=55601
2023-01-09 19:04:34 - progress_bar.py[line:272] - INFO: epoch 006:   1246 / 3665 loss=5.11, loss_v1=0, loss_v2=0, nll_loss=4.205, ntokens=1002.6, nsentences=32, sample_size=1002.6, sample_size_v1=0, sample_size_v2=0, ppl=18.44, wps=509.4, ups=0.51, wpb=1002.6, bsz=32, num_updates=19540, lr=2.48324e-05, gnorm=2.323, clip=100, loss_scale=256, train_wall=20, gb_free=15.4, wall=55620
2023-01-09 19:04:54 - progress_bar.py[line:272] - INFO: epoch 006:   1256 / 3665 loss=5.074, loss_v1=0, loss_v2=0, nll_loss=4.164, ntokens=1062.3, nsentences=32, sample_size=1062.3, sample_size_v1=0, sample_size_v2=0, ppl=17.93, wps=538.5, ups=0.51, wpb=1062.3, bsz=32, num_updates=19550, lr=2.48179e-05, gnorm=2.194, clip=100, loss_scale=256, train_wall=20, gb_free=15, wall=55640
2023-01-09 19:05:13 - progress_bar.py[line:272] - INFO: epoch 006:   1266 / 3665 loss=5.052, loss_v1=0, loss_v2=0, nll_loss=4.139, ntokens=801.5, nsentences=32, sample_size=801.5, sample_size_v1=0, sample_size_v2=0, ppl=17.62, wps=409, ups=0.51, wpb=801.5, bsz=32, num_updates=19560, lr=2.48033e-05, gnorm=2.732, clip=100, loss_scale=256, train_wall=20, gb_free=15.6, wall=55660
2023-01-09 19:05:33 - progress_bar.py[line:272] - INFO: epoch 006:   1276 / 3665 loss=5.029, loss_v1=0, loss_v2=0, nll_loss=4.114, ntokens=733.5, nsentences=32, sample_size=733.5, sample_size_v1=0, sample_size_v2=0, ppl=17.31, wps=375.4, ups=0.51, wpb=733.5, bsz=32, num_updates=19570, lr=2.47888e-05, gnorm=2.792, clip=100, loss_scale=256, train_wall=20, gb_free=15.2, wall=55679
2023-01-09 19:05:53 - progress_bar.py[line:272] - INFO: epoch 006:   1286 / 3665 loss=5.061, loss_v1=0, loss_v2=0, nll_loss=4.152, ntokens=967.7, nsentences=32, sample_size=967.7, sample_size_v1=0, sample_size_v2=0, ppl=17.77, wps=492.3, ups=0.51, wpb=967.7, bsz=32, num_updates=19580, lr=2.47743e-05, gnorm=2.28, clip=100, loss_scale=256, train_wall=20, gb_free=15, wall=55699
2023-01-09 19:06:12 - progress_bar.py[line:272] - INFO: epoch 006:   1296 / 3665 loss=5.089, loss_v1=0, loss_v2=0, nll_loss=4.182, ntokens=1027.9, nsentences=32, sample_size=1027.9, sample_size_v1=0, sample_size_v2=0, ppl=18.15, wps=521.9, ups=0.51, wpb=1027.9, bsz=32, num_updates=19590, lr=2.47598e-05, gnorm=2.299, clip=100, loss_scale=256, train_wall=20, gb_free=15.3, wall=55718
2023-01-09 19:06:32 - progress_bar.py[line:272] - INFO: epoch 006:   1306 / 3665 loss=5.042, loss_v1=0, loss_v2=0, nll_loss=4.128, ntokens=775.9, nsentences=32, sample_size=775.9, sample_size_v1=0, sample_size_v2=0, ppl=17.49, wps=395.2, ups=0.51, wpb=775.9, bsz=32, num_updates=19600, lr=2.47453e-05, gnorm=2.743, clip=100, loss_scale=256, train_wall=20, gb_free=15.5, wall=55738
2023-01-09 19:06:51 - progress_bar.py[line:272] - INFO: epoch 006:   1316 / 3665 loss=4.987, loss_v1=0, loss_v2=0, nll_loss=4.068, ntokens=994.2, nsentences=32, sample_size=994.2, sample_size_v1=0, sample_size_v2=0, ppl=16.78, wps=505.8, ups=0.51, wpb=994.2, bsz=32, num_updates=19610, lr=2.47308e-05, gnorm=2.09, clip=100, loss_scale=256, train_wall=20, gb_free=15.6, wall=55758
2023-01-09 19:07:11 - progress_bar.py[line:272] - INFO: epoch 006:   1326 / 3665 loss=5.101, loss_v1=0, loss_v2=0, nll_loss=4.196, ntokens=974.3, nsentences=32, sample_size=974.3, sample_size_v1=0, sample_size_v2=0, ppl=18.33, wps=494.6, ups=0.51, wpb=974.3, bsz=32, num_updates=19620, lr=2.47163e-05, gnorm=2.378, clip=100, loss_scale=256, train_wall=20, gb_free=15.7, wall=55777
2023-01-09 19:07:31 - progress_bar.py[line:272] - INFO: epoch 006:   1336 / 3665 loss=5.039, loss_v1=0, loss_v2=0, nll_loss=4.125, ntokens=760.9, nsentences=32, sample_size=760.9, sample_size_v1=0, sample_size_v2=0, ppl=17.45, wps=386.1, ups=0.51, wpb=760.9, bsz=32, num_updates=19630, lr=2.47018e-05, gnorm=2.959, clip=100, loss_scale=256, train_wall=20, gb_free=15.3, wall=55797
2023-01-09 19:07:51 - progress_bar.py[line:272] - INFO: epoch 006:   1346 / 3665 loss=4.952, loss_v1=0, loss_v2=0, nll_loss=4.027, ntokens=916.6, nsentences=32, sample_size=916.6, sample_size_v1=0, sample_size_v2=0, ppl=16.31, wps=448.2, ups=0.49, wpb=916.6, bsz=32, num_updates=19640, lr=2.46872e-05, gnorm=2.289, clip=100, loss_scale=256, train_wall=20, gb_free=15.3, wall=55818
2023-01-09 19:08:12 - progress_bar.py[line:272] - INFO: epoch 006:   1356 / 3665 loss=5.054, loss_v1=0, loss_v2=0, nll_loss=4.143, ntokens=1130.4, nsentences=32, sample_size=1130.4, sample_size_v1=0, sample_size_v2=0, ppl=17.67, wps=550.1, ups=0.49, wpb=1130.4, bsz=32, num_updates=19650, lr=2.46727e-05, gnorm=1.902, clip=100, loss_scale=256, train_wall=21, gb_free=15.5, wall=55838
2023-01-09 19:08:32 - progress_bar.py[line:272] - INFO: epoch 006:   1366 / 3665 loss=5.075, loss_v1=0, loss_v2=0, nll_loss=4.166, ntokens=834.6, nsentences=32, sample_size=834.6, sample_size_v1=0, sample_size_v2=0, ppl=17.95, wps=413.1, ups=0.49, wpb=834.6, bsz=32, num_updates=19660, lr=2.46582e-05, gnorm=2.632, clip=100, loss_scale=256, train_wall=20, gb_free=15.6, wall=55858
2023-01-09 19:08:52 - progress_bar.py[line:272] - INFO: epoch 006:   1376 / 3665 loss=4.944, loss_v1=0, loss_v2=0, nll_loss=4.02, ntokens=841.9, nsentences=32, sample_size=841.9, sample_size_v1=0, sample_size_v2=0, ppl=16.22, wps=430.6, ups=0.51, wpb=841.9, bsz=32, num_updates=19670, lr=2.46437e-05, gnorm=2.561, clip=100, loss_scale=256, train_wall=20, gb_free=15.2, wall=55878
2023-01-09 19:09:11 - progress_bar.py[line:272] - INFO: epoch 006:   1386 / 3665 loss=5.044, loss_v1=0, loss_v2=0, nll_loss=4.132, ntokens=996.1, nsentences=32, sample_size=996.1, sample_size_v1=0, sample_size_v2=0, ppl=17.53, wps=510.6, ups=0.51, wpb=996.1, bsz=32, num_updates=19680, lr=2.46292e-05, gnorm=2.115, clip=100, loss_scale=256, train_wall=19, gb_free=15.4, wall=55897
2023-01-09 19:09:31 - progress_bar.py[line:272] - INFO: epoch 006:   1396 / 3665 loss=4.947, loss_v1=0, loss_v2=0, nll_loss=4.024, ntokens=665.1, nsentences=32, sample_size=665.1, sample_size_v1=0, sample_size_v2=0, ppl=16.27, wps=341.8, ups=0.51, wpb=665.1, bsz=32, num_updates=19690, lr=2.46147e-05, gnorm=2.826, clip=100, loss_scale=256, train_wall=19, gb_free=15.3, wall=55917
2023-01-09 19:09:50 - progress_bar.py[line:272] - INFO: epoch 006:   1406 / 3665 loss=5.011, loss_v1=0, loss_v2=0, nll_loss=4.094, ntokens=910.3, nsentences=32, sample_size=910.3, sample_size_v1=0, sample_size_v2=0, ppl=17.08, wps=464.4, ups=0.51, wpb=910.3, bsz=32, num_updates=19700, lr=2.46002e-05, gnorm=2.383, clip=100, loss_scale=256, train_wall=20, gb_free=15.5, wall=55937
2023-01-09 19:10:10 - progress_bar.py[line:272] - INFO: epoch 006:   1416 / 3665 loss=4.98, loss_v1=0, loss_v2=0, nll_loss=4.06, ntokens=854.7, nsentences=32, sample_size=854.7, sample_size_v1=0, sample_size_v2=0, ppl=16.68, wps=436.1, ups=0.51, wpb=854.7, bsz=32, num_updates=19710, lr=2.45856e-05, gnorm=2.585, clip=100, loss_scale=256, train_wall=20, gb_free=15.5, wall=55956
2023-01-09 19:10:29 - progress_bar.py[line:272] - INFO: epoch 006:   1426 / 3665 loss=5.062, loss_v1=0, loss_v2=0, nll_loss=4.151, ntokens=841.8, nsentences=32, sample_size=841.8, sample_size_v1=0, sample_size_v2=0, ppl=17.76, wps=428.5, ups=0.51, wpb=841.8, bsz=32, num_updates=19720, lr=2.45711e-05, gnorm=2.706, clip=100, loss_scale=256, train_wall=20, gb_free=15.5, wall=55976
2023-01-09 19:10:49 - progress_bar.py[line:272] - INFO: epoch 006:   1436 / 3665 loss=5.042, loss_v1=0, loss_v2=0, nll_loss=4.129, ntokens=820.9, nsentences=32, sample_size=820.9, sample_size_v1=0, sample_size_v2=0, ppl=17.49, wps=418.5, ups=0.51, wpb=820.9, bsz=32, num_updates=19730, lr=2.45566e-05, gnorm=2.847, clip=100, loss_scale=256, train_wall=20, gb_free=15.5, wall=55995
2023-01-09 19:11:09 - progress_bar.py[line:272] - INFO: epoch 006:   1446 / 3665 loss=5.076, loss_v1=0, loss_v2=0, nll_loss=4.169, ntokens=1058.3, nsentences=32, sample_size=1058.3, sample_size_v1=0, sample_size_v2=0, ppl=17.98, wps=534.1, ups=0.5, wpb=1058.3, bsz=32, num_updates=19740, lr=2.45421e-05, gnorm=2.297, clip=100, loss_scale=256, train_wall=20, gb_free=15.4, wall=56015
2023-01-09 19:11:29 - progress_bar.py[line:272] - INFO: epoch 006:   1456 / 3665 loss=5.072, loss_v1=0, loss_v2=0, nll_loss=4.162, ntokens=871.5, nsentences=32, sample_size=871.5, sample_size_v1=0, sample_size_v2=0, ppl=17.9, wps=439.2, ups=0.5, wpb=871.5, bsz=32, num_updates=19750, lr=2.45276e-05, gnorm=2.492, clip=100, loss_scale=256, train_wall=20, gb_free=15.3, wall=56035
2023-01-09 19:11:48 - progress_bar.py[line:272] - INFO: epoch 006:   1466 / 3665 loss=4.911, loss_v1=0, loss_v2=0, nll_loss=3.984, ntokens=656.2, nsentences=32, sample_size=656.2, sample_size_v1=0, sample_size_v2=0, ppl=15.82, wps=333, ups=0.51, wpb=656.2, bsz=32, num_updates=19760, lr=2.45131e-05, gnorm=3.296, clip=100, loss_scale=256, train_wall=20, gb_free=15.3, wall=56055
2023-01-09 19:12:08 - progress_bar.py[line:272] - INFO: epoch 006:   1476 / 3665 loss=5.027, loss_v1=0, loss_v2=0, nll_loss=4.111, ntokens=921.8, nsentences=32, sample_size=921.8, sample_size_v1=0, sample_size_v2=0, ppl=17.28, wps=465.9, ups=0.51, wpb=921.8, bsz=32, num_updates=19770, lr=2.44986e-05, gnorm=2.414, clip=100, loss_scale=256, train_wall=20, gb_free=15.4, wall=56075
2023-01-09 19:12:28 - progress_bar.py[line:272] - INFO: epoch 006:   1486 / 3665 loss=5.179, loss_v1=0, loss_v2=0, nll_loss=4.281, ntokens=1067.7, nsentences=32, sample_size=1067.7, sample_size_v1=0, sample_size_v2=0, ppl=19.45, wps=536.1, ups=0.5, wpb=1067.7, bsz=32, num_updates=19780, lr=2.4484e-05, gnorm=2.294, clip=100, loss_scale=256, train_wall=20, gb_free=15.2, wall=56094
2023-01-09 19:12:48 - progress_bar.py[line:272] - INFO: epoch 006:   1496 / 3665 loss=5.022, loss_v1=0, loss_v2=0, nll_loss=4.107, ntokens=705.5, nsentences=32, sample_size=705.5, sample_size_v1=0, sample_size_v2=0, ppl=17.23, wps=357.6, ups=0.51, wpb=705.5, bsz=32, num_updates=19790, lr=2.44695e-05, gnorm=3.016, clip=100, loss_scale=256, train_wall=20, gb_free=15.5, wall=56114
2023-01-09 19:13:08 - progress_bar.py[line:272] - INFO: epoch 006:   1506 / 3665 loss=4.978, loss_v1=0, loss_v2=0, nll_loss=4.058, ntokens=920.6, nsentences=32, sample_size=920.6, sample_size_v1=0, sample_size_v2=0, ppl=16.66, wps=465.3, ups=0.51, wpb=920.6, bsz=32, num_updates=19800, lr=2.4455e-05, gnorm=2.403, clip=100, loss_scale=256, train_wall=20, gb_free=15.4, wall=56134
2023-01-09 19:13:28 - progress_bar.py[line:272] - INFO: epoch 006:   1516 / 3665 loss=5.07, loss_v1=0, loss_v2=0, nll_loss=4.16, ntokens=961, nsentences=32, sample_size=961, sample_size_v1=0, sample_size_v2=0, ppl=17.88, wps=484.2, ups=0.5, wpb=961, bsz=32, num_updates=19810, lr=2.44405e-05, gnorm=2.296, clip=100, loss_scale=256, train_wall=20, gb_free=15.5, wall=56154
2023-01-09 19:13:47 - progress_bar.py[line:272] - INFO: epoch 006:   1526 / 3665 loss=5.059, loss_v1=0, loss_v2=0, nll_loss=4.149, ntokens=803.6, nsentences=32, sample_size=803.6, sample_size_v1=0, sample_size_v2=0, ppl=17.74, wps=406.6, ups=0.51, wpb=803.6, bsz=32, num_updates=19820, lr=2.4426e-05, gnorm=2.681, clip=100, loss_scale=256, train_wall=20, gb_free=15.4, wall=56174
2023-01-09 19:14:07 - progress_bar.py[line:272] - INFO: epoch 006:   1536 / 3665 loss=5.042, loss_v1=0, loss_v2=0, nll_loss=4.129, ntokens=918.4, nsentences=32, sample_size=918.4, sample_size_v1=0, sample_size_v2=0, ppl=17.5, wps=459.1, ups=0.5, wpb=918.4, bsz=32, num_updates=19830, lr=2.44115e-05, gnorm=2.503, clip=100, loss_scale=256, train_wall=20, gb_free=15.5, wall=56194
2023-01-09 19:14:27 - progress_bar.py[line:272] - INFO: epoch 006:   1546 / 3665 loss=5.135, loss_v1=0, loss_v2=0, nll_loss=4.23, ntokens=1055.3, nsentences=32, sample_size=1055.3, sample_size_v1=0, sample_size_v2=0, ppl=18.77, wps=532.9, ups=0.5, wpb=1055.3, bsz=32, num_updates=19840, lr=2.4397e-05, gnorm=2.182, clip=100, loss_scale=256, train_wall=20, gb_free=15.6, wall=56213
2023-01-09 19:14:47 - progress_bar.py[line:272] - INFO: epoch 006:   1556 / 3665 loss=5.055, loss_v1=0, loss_v2=0, nll_loss=4.142, ntokens=752.7, nsentences=32, sample_size=752.7, sample_size_v1=0, sample_size_v2=0, ppl=17.66, wps=381.7, ups=0.51, wpb=752.7, bsz=32, num_updates=19850, lr=2.43825e-05, gnorm=2.685, clip=100, loss_scale=256, train_wall=20, gb_free=15.7, wall=56233
2023-01-09 19:15:07 - progress_bar.py[line:272] - INFO: epoch 006:   1566 / 3665 loss=5.117, loss_v1=0, loss_v2=0, nll_loss=4.214, ntokens=958.8, nsentences=32, sample_size=958.8, sample_size_v1=0, sample_size_v2=0, ppl=18.55, wps=484.1, ups=0.5, wpb=958.8, bsz=32, num_updates=19860, lr=2.43679e-05, gnorm=2.433, clip=100, loss_scale=256, train_wall=20, gb_free=15.3, wall=56253
2023-01-09 19:15:26 - progress_bar.py[line:272] - INFO: epoch 006:   1576 / 3665 loss=5.073, loss_v1=0, loss_v2=0, nll_loss=4.164, ntokens=1081.8, nsentences=32, sample_size=1081.8, sample_size_v1=0, sample_size_v2=0, ppl=17.92, wps=545.4, ups=0.5, wpb=1081.8, bsz=32, num_updates=19870, lr=2.43534e-05, gnorm=2.098, clip=100, loss_scale=256, train_wall=20, gb_free=15.3, wall=56273
2023-01-09 19:15:46 - progress_bar.py[line:272] - INFO: epoch 006:   1586 / 3665 loss=5.082, loss_v1=0, loss_v2=0, nll_loss=4.172, ntokens=797.7, nsentences=32, sample_size=797.7, sample_size_v1=0, sample_size_v2=0, ppl=18.03, wps=403.9, ups=0.51, wpb=797.7, bsz=32, num_updates=19880, lr=2.43389e-05, gnorm=2.78, clip=100, loss_scale=256, train_wall=20, gb_free=15.3, wall=56292
2023-01-09 19:16:06 - progress_bar.py[line:272] - INFO: epoch 006:   1596 / 3665 loss=5.045, loss_v1=0, loss_v2=0, nll_loss=4.133, ntokens=886.5, nsentences=32, sample_size=886.5, sample_size_v1=0, sample_size_v2=0, ppl=17.54, wps=449, ups=0.51, wpb=886.5, bsz=32, num_updates=19890, lr=2.43244e-05, gnorm=2.693, clip=100, loss_scale=256, train_wall=20, gb_free=15.6, wall=56312
2023-01-09 19:16:26 - progress_bar.py[line:272] - INFO: epoch 006:   1606 / 3665 loss=4.985, loss_v1=0, loss_v2=0, nll_loss=4.066, ntokens=932.2, nsentences=32, sample_size=932.2, sample_size_v1=0, sample_size_v2=0, ppl=16.75, wps=472.6, ups=0.51, wpb=932.2, bsz=32, num_updates=19900, lr=2.43099e-05, gnorm=2.849, clip=100, loss_scale=256, train_wall=20, gb_free=15.5, wall=56332
2023-01-09 19:16:45 - progress_bar.py[line:272] - INFO: epoch 006:   1616 / 3665 loss=5.099, loss_v1=0, loss_v2=0, nll_loss=4.191, ntokens=954.6, nsentences=32, sample_size=954.6, sample_size_v1=0, sample_size_v2=0, ppl=18.26, wps=482.2, ups=0.51, wpb=954.6, bsz=32, num_updates=19910, lr=2.42954e-05, gnorm=2.467, clip=100, loss_scale=256, train_wall=20, gb_free=15.2, wall=56352
2023-01-09 19:17:05 - progress_bar.py[line:272] - INFO: epoch 006:   1626 / 3665 loss=5.069, loss_v1=0, loss_v2=0, nll_loss=4.159, ntokens=915.2, nsentences=32, sample_size=915.2, sample_size_v1=0, sample_size_v2=0, ppl=17.87, wps=463.7, ups=0.51, wpb=915.2, bsz=32, num_updates=19920, lr=2.42809e-05, gnorm=2.505, clip=100, loss_scale=256, train_wall=20, gb_free=15.5, wall=56371
2023-01-09 19:17:25 - progress_bar.py[line:272] - INFO: epoch 006:   1636 / 3665 loss=5.025, loss_v1=0, loss_v2=0, nll_loss=4.11, ntokens=1061.7, nsentences=32, sample_size=1061.7, sample_size_v1=0, sample_size_v2=0, ppl=17.27, wps=535.8, ups=0.5, wpb=1061.7, bsz=32, num_updates=19930, lr=2.42663e-05, gnorm=2.383, clip=100, loss_scale=256, train_wall=20, gb_free=15.1, wall=56391
2023-01-09 19:17:45 - progress_bar.py[line:272] - INFO: epoch 006:   1646 / 3665 loss=5.095, loss_v1=0, loss_v2=0, nll_loss=4.186, ntokens=1167.6, nsentences=32, sample_size=1167.6, sample_size_v1=0, sample_size_v2=0, ppl=18.21, wps=587.5, ups=0.5, wpb=1167.6, bsz=32, num_updates=19940, lr=2.42518e-05, gnorm=1.858, clip=100, loss_scale=256, train_wall=20, gb_free=15.4, wall=56411
2023-01-09 19:18:05 - progress_bar.py[line:272] - INFO: epoch 006:   1656 / 3665 loss=5.006, loss_v1=0, loss_v2=0, nll_loss=4.09, ntokens=852.1, nsentences=32, sample_size=852.1, sample_size_v1=0, sample_size_v2=0, ppl=17.03, wps=432.4, ups=0.51, wpb=852.1, bsz=32, num_updates=19950, lr=2.42373e-05, gnorm=2.489, clip=100, loss_scale=256, train_wall=20, gb_free=15.7, wall=56431
2023-01-09 19:18:24 - progress_bar.py[line:272] - INFO: epoch 006:   1666 / 3665 loss=5.013, loss_v1=0, loss_v2=0, nll_loss=4.097, ntokens=891.1, nsentences=32, sample_size=891.1, sample_size_v1=0, sample_size_v2=0, ppl=17.11, wps=451.3, ups=0.51, wpb=891.1, bsz=32, num_updates=19960, lr=2.42228e-05, gnorm=2.637, clip=100, loss_scale=256, train_wall=20, gb_free=15.1, wall=56451
2023-01-09 19:18:44 - progress_bar.py[line:272] - INFO: epoch 006:   1676 / 3665 loss=5.148, loss_v1=0, loss_v2=0, nll_loss=4.245, ntokens=960.4, nsentences=32, sample_size=960.4, sample_size_v1=0, sample_size_v2=0, ppl=18.97, wps=484.4, ups=0.5, wpb=960.4, bsz=32, num_updates=19970, lr=2.42083e-05, gnorm=2.54, clip=100, loss_scale=256, train_wall=20, gb_free=15.6, wall=56470
2023-01-09 19:19:04 - progress_bar.py[line:272] - INFO: epoch 006:   1686 / 3665 loss=5.107, loss_v1=0, loss_v2=0, nll_loss=4.201, ntokens=922, nsentences=32, sample_size=922, sample_size_v1=0, sample_size_v2=0, ppl=18.39, wps=466.8, ups=0.51, wpb=922, bsz=32, num_updates=19980, lr=2.41938e-05, gnorm=2.425, clip=100, loss_scale=256, train_wall=20, gb_free=15.4, wall=56490
2023-01-09 19:19:24 - progress_bar.py[line:272] - INFO: epoch 006:   1696 / 3665 loss=4.982, loss_v1=0, loss_v2=0, nll_loss=4.062, ntokens=926.1, nsentences=32, sample_size=926.1, sample_size_v1=0, sample_size_v2=0, ppl=16.7, wps=469.1, ups=0.51, wpb=926.1, bsz=32, num_updates=19990, lr=2.41793e-05, gnorm=2.6, clip=100, loss_scale=256, train_wall=20, gb_free=15.5, wall=56510
2023-01-09 19:19:43 - progress_bar.py[line:272] - INFO: epoch 006:   1706 / 3665 loss=5.059, loss_v1=0, loss_v2=0, nll_loss=4.149, ntokens=992.7, nsentences=32, sample_size=992.7, sample_size_v1=0, sample_size_v2=0, ppl=17.74, wps=501.4, ups=0.51, wpb=992.7, bsz=32, num_updates=20000, lr=2.41648e-05, gnorm=2.515, clip=100, loss_scale=256, train_wall=20, gb_free=15.6, wall=56530
2023-01-09 19:19:43 - train.py[line:445] - INFO: begin validation on "valid" subset
slice_id 0 seek offset 0
slice_id 0 seek offset 0
2023-01-09 19:24:29 - progress_bar.py[line:282] - INFO: epoch 006 | valid on 'valid' subset | loss 5.054 | loss_v1 0 | loss_v2 0 | nll_loss 4.125 | ntokens 117.381 | nsentences 4 | sample_size 117.381 | sample_size_v1 0 | sample_size_v2 0 | AP 0 | total positives 21.7803 | TP 0 | FP 5.11874 | ppl 17.45 | wps 513.3 | wpb 117.4 | bsz 4 | num_updates 20000 | best_AP 0
2023-01-09 19:24:29 - checkpoint_utils.py[line:64] - INFO: Preparing to save checkpoint for epoch 6 @ 20000 updates
2023-01-09 19:24:29 - trainer.py[line:431] - INFO: Saving checkpoint to ../../checkpoints/OFA/detection_checkpoints/10_5e-5_512/checkpoint_6_20000.pt
2023-01-09 19:24:33 - trainer.py[line:441] - INFO: Finished saving checkpoint to ../../checkpoints/OFA/detection_checkpoints/10_5e-5_512/checkpoint_6_20000.pt
2023-01-09 19:25:37 - checkpoint_utils.py[line:133] - INFO: Saved checkpoint ../../checkpoints/OFA/detection_checkpoints/10_5e-5_512/checkpoint_6_20000.pt (epoch 6 @ 20000 updates, score 0.0) (writing took 67.85295739909634 seconds)
2023-01-09 19:25:56 - progress_bar.py[line:272] - INFO: epoch 006:   1716 / 3665 loss=4.996, loss_v1=0, loss_v2=0, nll_loss=4.076, ntokens=701.8, nsentences=32, sample_size=701.8, sample_size_v1=0, sample_size_v2=0, ppl=16.87, wps=18.8, ups=0.03, wpb=701.8, bsz=32, num_updates=20010, lr=2.41502e-05, gnorm=3.077, clip=100, loss_scale=256, train_wall=19, gb_free=15.5, wall=56902
2023-01-09 19:26:16 - progress_bar.py[line:272] - INFO: epoch 006:   1726 / 3665 loss=5.017, loss_v1=0, loss_v2=0, nll_loss=4.104, ntokens=937.5, nsentences=32, sample_size=937.5, sample_size_v1=0, sample_size_v2=0, ppl=17.19, wps=478.7, ups=0.51, wpb=937.5, bsz=32, num_updates=20020, lr=2.41357e-05, gnorm=2.412, clip=100, loss_scale=256, train_wall=20, gb_free=15.5, wall=56922
2023-01-09 19:26:35 - progress_bar.py[line:272] - INFO: epoch 006:   1736 / 3665 loss=5.073, loss_v1=0, loss_v2=0, nll_loss=4.164, ntokens=1077.5, nsentences=32, sample_size=1077.5, sample_size_v1=0, sample_size_v2=0, ppl=17.93, wps=547.4, ups=0.51, wpb=1077.5, bsz=32, num_updates=20030, lr=2.41212e-05, gnorm=2.17, clip=100, loss_scale=512, train_wall=20, gb_free=15.5, wall=56942
2023-01-09 19:26:39 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 256.0
2023-01-09 19:26:57 - progress_bar.py[line:272] - INFO: epoch 006:   1747 / 3665 loss=5.087, loss_v1=0, loss_v2=0, nll_loss=4.177, ntokens=869.5, nsentences=32, sample_size=869.5, sample_size_v1=0, sample_size_v2=0, ppl=18.09, wps=403, ups=0.46, wpb=869.5, bsz=32, num_updates=20040, lr=2.41067e-05, gnorm=2.474, clip=100, loss_scale=256, train_wall=22, gb_free=15.5, wall=56963
2023-01-09 19:27:17 - progress_bar.py[line:272] - INFO: epoch 006:   1757 / 3665 loss=5.042, loss_v1=0, loss_v2=0, nll_loss=4.13, ntokens=953.9, nsentences=32, sample_size=953.9, sample_size_v1=0, sample_size_v2=0, ppl=17.5, wps=484.5, ups=0.51, wpb=953.9, bsz=32, num_updates=20050, lr=2.40922e-05, gnorm=2.461, clip=100, loss_scale=256, train_wall=20, gb_free=15.3, wall=56983
2023-01-09 19:27:36 - progress_bar.py[line:272] - INFO: epoch 006:   1767 / 3665 loss=5.124, loss_v1=0, loss_v2=0, nll_loss=4.221, ntokens=1071.2, nsentences=32, sample_size=1071.2, sample_size_v1=0, sample_size_v2=0, ppl=18.65, wps=543.7, ups=0.51, wpb=1071.2, bsz=32, num_updates=20060, lr=2.40777e-05, gnorm=2.138, clip=100, loss_scale=256, train_wall=20, gb_free=15.2, wall=57003
2023-01-09 19:27:56 - progress_bar.py[line:272] - INFO: epoch 006:   1777 / 3665 loss=5.123, loss_v1=0, loss_v2=0, nll_loss=4.218, ntokens=914.7, nsentences=32, sample_size=914.7, sample_size_v1=0, sample_size_v2=0, ppl=18.6, wps=466.3, ups=0.51, wpb=914.7, bsz=32, num_updates=20070, lr=2.40632e-05, gnorm=2.486, clip=100, loss_scale=256, train_wall=20, gb_free=15.4, wall=57022
2023-01-09 19:28:16 - progress_bar.py[line:272] - INFO: epoch 006:   1787 / 3665 loss=5.077, loss_v1=0, loss_v2=0, nll_loss=4.167, ntokens=888.1, nsentences=32, sample_size=888.1, sample_size_v1=0, sample_size_v2=0, ppl=17.97, wps=453.3, ups=0.51, wpb=888.1, bsz=32, num_updates=20080, lr=2.40486e-05, gnorm=2.493, clip=100, loss_scale=256, train_wall=20, gb_free=15.2, wall=57042
2023-01-09 19:28:35 - progress_bar.py[line:272] - INFO: epoch 006:   1797 / 3665 loss=4.981, loss_v1=0, loss_v2=0, nll_loss=4.06, ntokens=923.9, nsentences=32, sample_size=923.9, sample_size_v1=0, sample_size_v2=0, ppl=16.68, wps=470.9, ups=0.51, wpb=923.9, bsz=32, num_updates=20090, lr=2.40341e-05, gnorm=2.492, clip=100, loss_scale=256, train_wall=20, gb_free=15.4, wall=57061
2023-01-09 19:28:55 - progress_bar.py[line:272] - INFO: epoch 006:   1807 / 3665 loss=5.103, loss_v1=0, loss_v2=0, nll_loss=4.197, ntokens=888.9, nsentences=31.8, sample_size=888.9, sample_size_v1=0, sample_size_v2=0, ppl=18.34, wps=452.5, ups=0.51, wpb=888.9, bsz=31.8, num_updates=20100, lr=2.40196e-05, gnorm=2.481, clip=100, loss_scale=256, train_wall=20, gb_free=14.7, wall=57081
2023-01-09 19:29:15 - progress_bar.py[line:272] - INFO: epoch 006:   1817 / 3665 loss=5.051, loss_v1=0, loss_v2=0, nll_loss=4.14, ntokens=889.7, nsentences=32, sample_size=889.7, sample_size_v1=0, sample_size_v2=0, ppl=17.63, wps=452.6, ups=0.51, wpb=889.7, bsz=32, num_updates=20110, lr=2.40051e-05, gnorm=2.524, clip=100, loss_scale=256, train_wall=20, gb_free=14.5, wall=57101
2023-01-09 19:29:34 - progress_bar.py[line:272] - INFO: epoch 006:   1827 / 3665 loss=4.952, loss_v1=0, loss_v2=0, nll_loss=4.031, ntokens=1038.4, nsentences=32, sample_size=1038.4, sample_size_v1=0, sample_size_v2=0, ppl=16.34, wps=526.4, ups=0.51, wpb=1038.4, bsz=32, num_updates=20120, lr=2.39906e-05, gnorm=2.083, clip=100, loss_scale=256, train_wall=20, gb_free=15.2, wall=57121
2023-01-09 19:29:54 - progress_bar.py[line:272] - INFO: epoch 006:   1837 / 3665 loss=5.174, loss_v1=0, loss_v2=0, nll_loss=4.277, ntokens=961, nsentences=32, sample_size=961, sample_size_v1=0, sample_size_v2=0, ppl=19.38, wps=488.4, ups=0.51, wpb=961, bsz=32, num_updates=20130, lr=2.39761e-05, gnorm=3.127, clip=100, loss_scale=256, train_wall=20, gb_free=15.5, wall=57140
2023-01-09 19:30:14 - progress_bar.py[line:272] - INFO: epoch 006:   1847 / 3665 loss=5.009, loss_v1=0, loss_v2=0, nll_loss=4.09, ntokens=795.4, nsentences=32, sample_size=795.4, sample_size_v1=0, sample_size_v2=0, ppl=17.03, wps=400.2, ups=0.5, wpb=795.4, bsz=32, num_updates=20140, lr=2.39616e-05, gnorm=2.78, clip=100, loss_scale=256, train_wall=20, gb_free=15.3, wall=57160
2023-01-09 19:30:34 - progress_bar.py[line:272] - INFO: epoch 006:   1857 / 3665 loss=5.011, loss_v1=0, loss_v2=0, nll_loss=4.095, ntokens=973.4, nsentences=32, sample_size=973.4, sample_size_v1=0, sample_size_v2=0, ppl=17.09, wps=483.4, ups=0.5, wpb=973.4, bsz=32, num_updates=20150, lr=2.39471e-05, gnorm=2.276, clip=100, loss_scale=256, train_wall=20, gb_free=15.3, wall=57180
2023-01-09 19:30:54 - progress_bar.py[line:272] - INFO: epoch 006:   1867 / 3665 loss=5.11, loss_v1=0, loss_v2=0, nll_loss=4.206, ntokens=962.6, nsentences=32, sample_size=962.6, sample_size_v1=0, sample_size_v2=0, ppl=18.46, wps=478.1, ups=0.5, wpb=962.6, bsz=32, num_updates=20160, lr=2.39325e-05, gnorm=2.463, clip=100, loss_scale=256, train_wall=20, gb_free=15.5, wall=57200
2023-01-09 19:31:14 - progress_bar.py[line:272] - INFO: epoch 006:   1877 / 3665 loss=5.081, loss_v1=0, loss_v2=0, nll_loss=4.171, ntokens=895, nsentences=32, sample_size=895, sample_size_v1=0, sample_size_v2=0, ppl=18.01, wps=445.6, ups=0.5, wpb=895, bsz=32, num_updates=20170, lr=2.3918e-05, gnorm=2.597, clip=100, loss_scale=256, train_wall=20, gb_free=15.5, wall=57220
2023-01-09 19:31:34 - progress_bar.py[line:272] - INFO: epoch 006:   1887 / 3665 loss=5.07, loss_v1=0, loss_v2=0, nll_loss=4.16, ntokens=1080.5, nsentences=32, sample_size=1080.5, sample_size_v1=0, sample_size_v2=0, ppl=17.87, wps=536.6, ups=0.5, wpb=1080.5, bsz=32, num_updates=20180, lr=2.39035e-05, gnorm=2.212, clip=100, loss_scale=256, train_wall=20, gb_free=15.5, wall=57241
2023-01-09 19:31:54 - progress_bar.py[line:272] - INFO: epoch 006:   1897 / 3665 loss=5.112, loss_v1=0, loss_v2=0, nll_loss=4.207, ntokens=1001.9, nsentences=32, sample_size=1001.9, sample_size_v1=0, sample_size_v2=0, ppl=18.47, wps=508.5, ups=0.51, wpb=1001.9, bsz=32, num_updates=20190, lr=2.3889e-05, gnorm=2.34, clip=100, loss_scale=256, train_wall=20, gb_free=15.5, wall=57260
2023-01-09 19:32:13 - progress_bar.py[line:272] - INFO: epoch 006:   1907 / 3665 loss=5.045, loss_v1=0, loss_v2=0, nll_loss=4.131, ntokens=753.1, nsentences=32, sample_size=753.1, sample_size_v1=0, sample_size_v2=0, ppl=17.52, wps=386.3, ups=0.51, wpb=753.1, bsz=32, num_updates=20200, lr=2.38745e-05, gnorm=2.808, clip=100, loss_scale=256, train_wall=19, gb_free=15.2, wall=57280
2023-01-09 19:32:33 - progress_bar.py[line:272] - INFO: epoch 006:   1917 / 3665 loss=4.981, loss_v1=0, loss_v2=0, nll_loss=4.06, ntokens=847.6, nsentences=32, sample_size=847.6, sample_size_v1=0, sample_size_v2=0, ppl=16.68, wps=433, ups=0.51, wpb=847.6, bsz=32, num_updates=20210, lr=2.386e-05, gnorm=2.596, clip=100, loss_scale=256, train_wall=20, gb_free=15.6, wall=57299
2023-01-09 19:32:53 - progress_bar.py[line:272] - INFO: epoch 006:   1927 / 3665 loss=5.149, loss_v1=0, loss_v2=0, nll_loss=4.25, ntokens=1077, nsentences=32, sample_size=1077, sample_size_v1=0, sample_size_v2=0, ppl=19.03, wps=548.1, ups=0.51, wpb=1077, bsz=32, num_updates=20220, lr=2.38455e-05, gnorm=2.385, clip=100, loss_scale=256, train_wall=20, gb_free=15.4, wall=57319
2023-01-09 19:33:12 - progress_bar.py[line:272] - INFO: epoch 006:   1937 / 3665 loss=5.049, loss_v1=0, loss_v2=0, nll_loss=4.137, ntokens=793.7, nsentences=32, sample_size=793.7, sample_size_v1=0, sample_size_v2=0, ppl=17.59, wps=404.7, ups=0.51, wpb=793.7, bsz=32, num_updates=20230, lr=2.38309e-05, gnorm=2.528, clip=100, loss_scale=256, train_wall=20, gb_free=15.3, wall=57339
2023-01-09 19:33:32 - progress_bar.py[line:272] - INFO: epoch 006:   1947 / 3665 loss=4.965, loss_v1=0, loss_v2=0, nll_loss=4.042, ntokens=822.6, nsentences=32, sample_size=822.6, sample_size_v1=0, sample_size_v2=0, ppl=16.47, wps=420.7, ups=0.51, wpb=822.6, bsz=32, num_updates=20240, lr=2.38164e-05, gnorm=2.558, clip=100, loss_scale=256, train_wall=20, gb_free=15.6, wall=57358
2023-01-09 19:33:52 - progress_bar.py[line:272] - INFO: epoch 006:   1957 / 3665 loss=5.05, loss_v1=0, loss_v2=0, nll_loss=4.139, ntokens=1126.6, nsentences=32, sample_size=1126.6, sample_size_v1=0, sample_size_v2=0, ppl=17.62, wps=564.6, ups=0.5, wpb=1126.6, bsz=32, num_updates=20250, lr=2.38019e-05, gnorm=2.155, clip=100, loss_scale=256, train_wall=20, gb_free=14.8, wall=57378
2023-01-09 19:34:12 - progress_bar.py[line:272] - INFO: epoch 006:   1967 / 3665 loss=5.125, loss_v1=0, loss_v2=0, nll_loss=4.223, ntokens=913, nsentences=32, sample_size=913, sample_size_v1=0, sample_size_v2=0, ppl=18.67, wps=458.6, ups=0.5, wpb=913, bsz=32, num_updates=20260, lr=2.37874e-05, gnorm=2.366, clip=100, loss_scale=256, train_wall=20, gb_free=15.7, wall=57398
2023-01-09 19:34:32 - progress_bar.py[line:272] - INFO: epoch 006:   1977 / 3665 loss=5.079, loss_v1=0, loss_v2=0, nll_loss=4.17, ntokens=944.6, nsentences=32, sample_size=944.6, sample_size_v1=0, sample_size_v2=0, ppl=18, wps=475.1, ups=0.5, wpb=944.6, bsz=32, num_updates=20270, lr=2.37729e-05, gnorm=2.313, clip=100, loss_scale=256, train_wall=20, gb_free=15.5, wall=57418
2023-01-09 19:34:52 - progress_bar.py[line:272] - INFO: epoch 006:   1987 / 3665 loss=4.995, loss_v1=0, loss_v2=0, nll_loss=4.076, ntokens=1002.6, nsentences=32, sample_size=1002.6, sample_size_v1=0, sample_size_v2=0, ppl=16.87, wps=503.4, ups=0.5, wpb=1002.6, bsz=32, num_updates=20280, lr=2.37584e-05, gnorm=2.271, clip=100, loss_scale=256, train_wall=20, gb_free=15.4, wall=57438
2023-01-09 19:35:11 - progress_bar.py[line:272] - INFO: epoch 006:   1997 / 3665 loss=5.155, loss_v1=0, loss_v2=0, nll_loss=4.255, ntokens=1011.3, nsentences=32, sample_size=1011.3, sample_size_v1=0, sample_size_v2=0, ppl=19.1, wps=506.8, ups=0.5, wpb=1011.3, bsz=32, num_updates=20290, lr=2.37439e-05, gnorm=2.575, clip=100, loss_scale=256, train_wall=20, gb_free=15.6, wall=57458
2023-01-09 19:35:31 - progress_bar.py[line:272] - INFO: epoch 006:   2007 / 3665 loss=5.075, loss_v1=0, loss_v2=0, nll_loss=4.167, ntokens=911.5, nsentences=32, sample_size=911.5, sample_size_v1=0, sample_size_v2=0, ppl=17.96, wps=458.6, ups=0.5, wpb=911.5, bsz=32, num_updates=20300, lr=2.37294e-05, gnorm=2.549, clip=100, loss_scale=256, train_wall=20, gb_free=15.3, wall=57478
2023-01-09 19:35:51 - progress_bar.py[line:272] - INFO: epoch 006:   2017 / 3665 loss=4.982, loss_v1=0, loss_v2=0, nll_loss=4.062, ntokens=922.3, nsentences=32, sample_size=922.3, sample_size_v1=0, sample_size_v2=0, ppl=16.7, wps=464.4, ups=0.5, wpb=922.3, bsz=32, num_updates=20310, lr=2.37148e-05, gnorm=2.279, clip=100, loss_scale=256, train_wall=20, gb_free=15.4, wall=57498
2023-01-09 19:36:11 - progress_bar.py[line:272] - INFO: epoch 006:   2027 / 3665 loss=5.194, loss_v1=0, loss_v2=0, nll_loss=4.296, ntokens=1002.6, nsentences=32, sample_size=1002.6, sample_size_v1=0, sample_size_v2=0, ppl=19.65, wps=499.3, ups=0.5, wpb=1002.6, bsz=32, num_updates=20320, lr=2.37003e-05, gnorm=2.245, clip=100, loss_scale=256, train_wall=20, gb_free=15.5, wall=57518
2023-01-09 19:36:31 - progress_bar.py[line:272] - INFO: epoch 006:   2037 / 3665 loss=4.898, loss_v1=0, loss_v2=0, nll_loss=3.969, ntokens=666.5, nsentences=32, sample_size=666.5, sample_size_v1=0, sample_size_v2=0, ppl=15.66, wps=338.9, ups=0.51, wpb=666.5, bsz=32, num_updates=20330, lr=2.36858e-05, gnorm=3.215, clip=100, loss_scale=256, train_wall=20, gb_free=15.6, wall=57537
2023-01-09 19:36:51 - progress_bar.py[line:272] - INFO: epoch 006:   2047 / 3665 loss=5.013, loss_v1=0, loss_v2=0, nll_loss=4.098, ntokens=957.3, nsentences=32, sample_size=957.3, sample_size_v1=0, sample_size_v2=0, ppl=17.12, wps=482.9, ups=0.5, wpb=957.3, bsz=32, num_updates=20340, lr=2.36713e-05, gnorm=2.453, clip=100, loss_scale=256, train_wall=20, gb_free=15.4, wall=57557
2023-01-09 19:37:11 - progress_bar.py[line:272] - INFO: epoch 006:   2057 / 3665 loss=5.025, loss_v1=0, loss_v2=0, nll_loss=4.11, ntokens=885.9, nsentences=32, sample_size=885.9, sample_size_v1=0, sample_size_v2=0, ppl=17.27, wps=446.7, ups=0.5, wpb=885.9, bsz=32, num_updates=20350, lr=2.36568e-05, gnorm=2.289, clip=100, loss_scale=256, train_wall=20, gb_free=15.4, wall=57577
2023-01-09 19:37:30 - progress_bar.py[line:272] - INFO: epoch 006:   2067 / 3665 loss=5.019, loss_v1=0, loss_v2=0, nll_loss=4.103, ntokens=833, nsentences=32, sample_size=833, sample_size_v1=0, sample_size_v2=0, ppl=17.19, wps=420.5, ups=0.5, wpb=833, bsz=32, num_updates=20360, lr=2.36423e-05, gnorm=2.659, clip=100, loss_scale=256, train_wall=20, gb_free=15.6, wall=57597
2023-01-09 19:37:50 - progress_bar.py[line:272] - INFO: epoch 006:   2077 / 3665 loss=4.996, loss_v1=0, loss_v2=0, nll_loss=4.078, ntokens=937.1, nsentences=32, sample_size=937.1, sample_size_v1=0, sample_size_v2=0, ppl=16.89, wps=472.8, ups=0.5, wpb=937.1, bsz=32, num_updates=20370, lr=2.36278e-05, gnorm=2.264, clip=100, loss_scale=256, train_wall=20, gb_free=15.4, wall=57617
2023-01-09 19:38:10 - progress_bar.py[line:272] - INFO: epoch 006:   2087 / 3665 loss=5.209, loss_v1=0, loss_v2=0, nll_loss=4.315, ntokens=1080.4, nsentences=32, sample_size=1080.4, sample_size_v1=0, sample_size_v2=0, ppl=19.9, wps=542.5, ups=0.5, wpb=1080.4, bsz=32, num_updates=20380, lr=2.36132e-05, gnorm=2.225, clip=100, loss_scale=256, train_wall=20, gb_free=15.2, wall=57636
2023-01-09 19:38:30 - progress_bar.py[line:272] - INFO: epoch 006:   2097 / 3665 loss=5.001, loss_v1=0, loss_v2=0, nll_loss=4.083, ntokens=790.3, nsentences=32, sample_size=790.3, sample_size_v1=0, sample_size_v2=0, ppl=16.95, wps=399.2, ups=0.51, wpb=790.3, bsz=32, num_updates=20390, lr=2.35987e-05, gnorm=2.594, clip=100, loss_scale=256, train_wall=20, gb_free=15, wall=57656
2023-01-09 19:38:50 - progress_bar.py[line:272] - INFO: epoch 006:   2107 / 3665 loss=4.975, loss_v1=0, loss_v2=0, nll_loss=4.055, ntokens=958.4, nsentences=32, sample_size=958.4, sample_size_v1=0, sample_size_v2=0, ppl=16.62, wps=483.4, ups=0.5, wpb=958.4, bsz=32, num_updates=20400, lr=2.35842e-05, gnorm=2.358, clip=100, loss_scale=256, train_wall=20, gb_free=15.7, wall=57676
2023-01-09 19:39:10 - progress_bar.py[line:272] - INFO: epoch 006:   2117 / 3665 loss=5.09, loss_v1=0, loss_v2=0, nll_loss=4.182, ntokens=1062.8, nsentences=32, sample_size=1062.8, sample_size_v1=0, sample_size_v2=0, ppl=18.15, wps=533.9, ups=0.5, wpb=1062.8, bsz=32, num_updates=20410, lr=2.35697e-05, gnorm=2.114, clip=100, loss_scale=256, train_wall=20, gb_free=15.4, wall=57696
2023-01-09 19:39:29 - progress_bar.py[line:272] - INFO: epoch 006:   2127 / 3665 loss=5.061, loss_v1=0, loss_v2=0, nll_loss=4.151, ntokens=787.3, nsentences=32, sample_size=787.3, sample_size_v1=0, sample_size_v2=0, ppl=17.76, wps=398.1, ups=0.51, wpb=787.3, bsz=32, num_updates=20420, lr=2.35552e-05, gnorm=2.744, clip=100, loss_scale=256, train_wall=20, gb_free=15.5, wall=57716
2023-01-09 19:39:49 - progress_bar.py[line:272] - INFO: epoch 006:   2137 / 3665 loss=5.006, loss_v1=0, loss_v2=0, nll_loss=4.089, ntokens=935.3, nsentences=32, sample_size=935.3, sample_size_v1=0, sample_size_v2=0, ppl=17.01, wps=472, ups=0.5, wpb=935.3, bsz=32, num_updates=20430, lr=2.35407e-05, gnorm=2.22, clip=100, loss_scale=256, train_wall=20, gb_free=15.3, wall=57736
2023-01-09 19:40:09 - progress_bar.py[line:272] - INFO: epoch 006:   2147 / 3665 loss=5.003, loss_v1=0, loss_v2=0, nll_loss=4.086, ntokens=1104.9, nsentences=32, sample_size=1104.9, sample_size_v1=0, sample_size_v2=0, ppl=16.98, wps=555.6, ups=0.5, wpb=1104.9, bsz=32, num_updates=20440, lr=2.35262e-05, gnorm=2.226, clip=100, loss_scale=256, train_wall=20, gb_free=14.6, wall=57755
2023-01-09 19:40:29 - progress_bar.py[line:272] - INFO: epoch 006:   2157 / 3665 loss=5.114, loss_v1=0, loss_v2=0, nll_loss=4.208, ntokens=798.1, nsentences=32, sample_size=798.1, sample_size_v1=0, sample_size_v2=0, ppl=18.49, wps=402.8, ups=0.5, wpb=798.1, bsz=32, num_updates=20450, lr=2.35117e-05, gnorm=2.607, clip=100, loss_scale=256, train_wall=20, gb_free=15.4, wall=57775
2023-01-09 19:40:49 - progress_bar.py[line:272] - INFO: epoch 006:   2167 / 3665 loss=5.074, loss_v1=0, loss_v2=0, nll_loss=4.165, ntokens=943.3, nsentences=32, sample_size=943.3, sample_size_v1=0, sample_size_v2=0, ppl=17.94, wps=475.5, ups=0.5, wpb=943.3, bsz=32, num_updates=20460, lr=2.34971e-05, gnorm=2.472, clip=100, loss_scale=256, train_wall=20, gb_free=15.6, wall=57795
2023-01-09 19:41:09 - progress_bar.py[line:272] - INFO: epoch 006:   2177 / 3665 loss=5.001, loss_v1=0, loss_v2=0, nll_loss=4.086, ntokens=968, nsentences=32, sample_size=968, sample_size_v1=0, sample_size_v2=0, ppl=16.98, wps=488.7, ups=0.5, wpb=968, bsz=32, num_updates=20470, lr=2.34826e-05, gnorm=2.35, clip=100, loss_scale=256, train_wall=20, gb_free=15.5, wall=57815
2023-01-09 19:41:29 - progress_bar.py[line:272] - INFO: epoch 006:   2187 / 3665 loss=5.09, loss_v1=0, loss_v2=0, nll_loss=4.181, ntokens=863.3, nsentences=32, sample_size=863.3, sample_size_v1=0, sample_size_v2=0, ppl=18.14, wps=434.7, ups=0.5, wpb=863.3, bsz=32, num_updates=20480, lr=2.34681e-05, gnorm=2.693, clip=100, loss_scale=256, train_wall=20, gb_free=15.4, wall=57835
2023-01-09 19:41:48 - progress_bar.py[line:272] - INFO: epoch 006:   2197 / 3665 loss=5.129, loss_v1=0, loss_v2=0, nll_loss=4.224, ntokens=972.9, nsentences=32, sample_size=972.9, sample_size_v1=0, sample_size_v2=0, ppl=18.68, wps=490.2, ups=0.5, wpb=972.9, bsz=32, num_updates=20490, lr=2.34536e-05, gnorm=2.347, clip=100, loss_scale=256, train_wall=20, gb_free=15.2, wall=57855
2023-01-09 19:42:08 - progress_bar.py[line:272] - INFO: epoch 006:   2207 / 3665 loss=5.071, loss_v1=0, loss_v2=0, nll_loss=4.162, ntokens=1050.8, nsentences=32, sample_size=1050.8, sample_size_v1=0, sample_size_v2=0, ppl=17.91, wps=528.6, ups=0.5, wpb=1050.8, bsz=32, num_updates=20500, lr=2.34391e-05, gnorm=2.412, clip=100, loss_scale=256, train_wall=20, gb_free=15.1, wall=57875
2023-01-09 19:42:08 - train.py[line:445] - INFO: begin validation on "valid" subset
slice_id 0 seek offset 0
slice_id 0 seek offset 0
2023-01-09 19:47:02 - progress_bar.py[line:282] - INFO: epoch 006 | valid on 'valid' subset | loss 5.04 | loss_v1 0 | loss_v2 0 | nll_loss 4.113 | ntokens 117.058 | nsentences 4 | sample_size 117.058 | sample_size_v1 0 | sample_size_v2 0 | AP 0 | total positives 21.7237 | TP 0 | FP 5.57593 | ppl 17.3 | wps 498.1 | wpb 117.1 | bsz 4 | num_updates 20500 | best_AP 0
2023-01-09 19:47:02 - checkpoint_utils.py[line:64] - INFO: Preparing to save checkpoint for epoch 6 @ 20500 updates
2023-01-09 19:47:02 - trainer.py[line:431] - INFO: Saving checkpoint to ../../checkpoints/OFA/detection_checkpoints/10_5e-5_512/checkpoint_6_20500.pt
2023-01-09 19:47:06 - trainer.py[line:441] - INFO: Finished saving checkpoint to ../../checkpoints/OFA/detection_checkpoints/10_5e-5_512/checkpoint_6_20500.pt
2023-01-09 19:48:08 - checkpoint_utils.py[line:133] - INFO: Saved checkpoint ../../checkpoints/OFA/detection_checkpoints/10_5e-5_512/checkpoint_6_20500.pt (epoch 6 @ 20500 updates, score 0.0) (writing took 66.51979769021273 seconds)
2023-01-09 19:48:28 - progress_bar.py[line:272] - INFO: epoch 006:   2217 / 3665 loss=5.117, loss_v1=0, loss_v2=0, nll_loss=4.213, ntokens=857.3, nsentences=32, sample_size=857.3, sample_size_v1=0, sample_size_v2=0, ppl=18.54, wps=22.6, ups=0.03, wpb=857.3, bsz=32, num_updates=20510, lr=2.34246e-05, gnorm=2.599, clip=100, loss_scale=256, train_wall=20, gb_free=15.5, wall=58254
2023-01-09 19:48:48 - progress_bar.py[line:272] - INFO: epoch 006:   2227 / 3665 loss=4.997, loss_v1=0, loss_v2=0, nll_loss=4.077, ntokens=845.7, nsentences=32, sample_size=845.7, sample_size_v1=0, sample_size_v2=0, ppl=16.87, wps=434.3, ups=0.51, wpb=845.7, bsz=32, num_updates=20520, lr=2.34101e-05, gnorm=2.659, clip=100, loss_scale=256, train_wall=19, gb_free=15.6, wall=58274
2023-01-09 19:49:07 - progress_bar.py[line:272] - INFO: epoch 006:   2237 / 3665 loss=5.053, loss_v1=0, loss_v2=0, nll_loss=4.141, ntokens=1049.1, nsentences=32, sample_size=1049.1, sample_size_v1=0, sample_size_v2=0, ppl=17.64, wps=531.9, ups=0.51, wpb=1049.1, bsz=32, num_updates=20530, lr=2.33955e-05, gnorm=2.1, clip=100, loss_scale=256, train_wall=20, gb_free=15.3, wall=58294
2023-01-09 19:49:27 - progress_bar.py[line:272] - INFO: epoch 006:   2247 / 3665 loss=5.023, loss_v1=0, loss_v2=0, nll_loss=4.109, ntokens=841.4, nsentences=32, sample_size=841.4, sample_size_v1=0, sample_size_v2=0, ppl=17.26, wps=427.4, ups=0.51, wpb=841.4, bsz=32, num_updates=20540, lr=2.3381e-05, gnorm=2.658, clip=100, loss_scale=256, train_wall=20, gb_free=15.1, wall=58313
2023-01-09 19:49:47 - progress_bar.py[line:272] - INFO: epoch 006:   2257 / 3665 loss=5.065, loss_v1=0, loss_v2=0, nll_loss=4.155, ntokens=855.9, nsentences=32, sample_size=855.9, sample_size_v1=0, sample_size_v2=0, ppl=17.82, wps=434.6, ups=0.51, wpb=855.9, bsz=32, num_updates=20550, lr=2.33665e-05, gnorm=2.678, clip=100, loss_scale=512, train_wall=20, gb_free=15.5, wall=58333
2023-01-09 19:50:06 - progress_bar.py[line:272] - INFO: epoch 006:   2267 / 3665 loss=4.99, loss_v1=0, loss_v2=0, nll_loss=4.07, ntokens=968.1, nsentences=32, sample_size=968.1, sample_size_v1=0, sample_size_v2=0, ppl=16.8, wps=490.5, ups=0.51, wpb=968.1, bsz=32, num_updates=20560, lr=2.3352e-05, gnorm=2.447, clip=100, loss_scale=512, train_wall=20, gb_free=15.3, wall=58353
2023-01-09 19:50:10 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 256.0
2023-01-09 19:50:28 - progress_bar.py[line:272] - INFO: epoch 006:   2278 / 3665 loss=5.16, loss_v1=0, loss_v2=0, nll_loss=4.262, ntokens=1075.2, nsentences=32, sample_size=1075.2, sample_size_v1=0, sample_size_v2=0, ppl=19.18, wps=496.8, ups=0.46, wpb=1075.2, bsz=32, num_updates=20570, lr=2.33375e-05, gnorm=2.43, clip=100, loss_scale=256, train_wall=22, gb_free=15.5, wall=58374
2023-01-09 19:50:48 - progress_bar.py[line:272] - INFO: epoch 006:   2288 / 3665 loss=5.072, loss_v1=0, loss_v2=0, nll_loss=4.162, ntokens=915.8, nsentences=32, sample_size=915.8, sample_size_v1=0, sample_size_v2=0, ppl=17.9, wps=463.6, ups=0.51, wpb=915.8, bsz=32, num_updates=20580, lr=2.3323e-05, gnorm=2.383, clip=100, loss_scale=256, train_wall=20, gb_free=15.2, wall=58394
2023-01-09 19:51:07 - progress_bar.py[line:272] - INFO: epoch 006:   2298 / 3665 loss=4.937, loss_v1=0, loss_v2=0, nll_loss=4.011, ntokens=848.5, nsentences=32, sample_size=848.5, sample_size_v1=0, sample_size_v2=0, ppl=16.13, wps=432.2, ups=0.51, wpb=848.5, bsz=32, num_updates=20590, lr=2.33085e-05, gnorm=2.555, clip=100, loss_scale=256, train_wall=20, gb_free=15.7, wall=58414
2023-01-09 19:51:27 - progress_bar.py[line:272] - INFO: epoch 006:   2308 / 3665 loss=5.004, loss_v1=0, loss_v2=0, nll_loss=4.086, ntokens=883.5, nsentences=32, sample_size=883.5, sample_size_v1=0, sample_size_v2=0, ppl=16.99, wps=447.6, ups=0.51, wpb=883.5, bsz=32, num_updates=20600, lr=2.3294e-05, gnorm=2.81, clip=100, loss_scale=256, train_wall=20, gb_free=15.6, wall=58433
2023-01-09 19:51:47 - progress_bar.py[line:272] - INFO: epoch 006:   2318 / 3665 loss=5.062, loss_v1=0, loss_v2=0, nll_loss=4.151, ntokens=823.1, nsentences=32, sample_size=823.1, sample_size_v1=0, sample_size_v2=0, ppl=17.76, wps=417.8, ups=0.51, wpb=823.1, bsz=32, num_updates=20610, lr=2.32794e-05, gnorm=2.992, clip=100, loss_scale=256, train_wall=20, gb_free=15, wall=58453
2023-01-09 19:52:07 - progress_bar.py[line:272] - INFO: epoch 006:   2328 / 3665 loss=4.981, loss_v1=0, loss_v2=0, nll_loss=4.061, ntokens=925.7, nsentences=32, sample_size=925.7, sample_size_v1=0, sample_size_v2=0, ppl=16.7, wps=471.3, ups=0.51, wpb=925.7, bsz=32, num_updates=20620, lr=2.32649e-05, gnorm=2.46, clip=100, loss_scale=256, train_wall=20, gb_free=15.7, wall=58473
2023-01-09 19:52:27 - progress_bar.py[line:272] - INFO: epoch 006:   2338 / 3665 loss=5.16, loss_v1=0, loss_v2=0, nll_loss=4.26, ntokens=1239.1, nsentences=32, sample_size=1239.1, sample_size_v1=0, sample_size_v2=0, ppl=19.16, wps=594.6, ups=0.48, wpb=1239.1, bsz=32, num_updates=20630, lr=2.32504e-05, gnorm=1.956, clip=100, loss_scale=256, train_wall=21, gb_free=15.1, wall=58494
2023-01-09 19:52:48 - progress_bar.py[line:272] - INFO: epoch 006:   2348 / 3665 loss=5.056, loss_v1=0, loss_v2=0, nll_loss=4.144, ntokens=917.2, nsentences=32, sample_size=917.2, sample_size_v1=0, sample_size_v2=0, ppl=17.68, wps=447.5, ups=0.49, wpb=917.2, bsz=32, num_updates=20640, lr=2.32359e-05, gnorm=2.396, clip=100, loss_scale=256, train_wall=20, gb_free=15.1, wall=58514
2023-01-09 19:53:08 - progress_bar.py[line:272] - INFO: epoch 006:   2358 / 3665 loss=5.116, loss_v1=0, loss_v2=0, nll_loss=4.211, ntokens=1111.6, nsentences=32, sample_size=1111.6, sample_size_v1=0, sample_size_v2=0, ppl=18.52, wps=550.1, ups=0.49, wpb=1111.6, bsz=32, num_updates=20650, lr=2.32214e-05, gnorm=2.345, clip=100, loss_scale=256, train_wall=20, gb_free=15.4, wall=58534
2023-01-09 19:53:28 - progress_bar.py[line:272] - INFO: epoch 006:   2368 / 3665 loss=4.947, loss_v1=0, loss_v2=0, nll_loss=4.023, ntokens=912.3, nsentences=32, sample_size=912.3, sample_size_v1=0, sample_size_v2=0, ppl=16.25, wps=466.5, ups=0.51, wpb=912.3, bsz=32, num_updates=20660, lr=2.32069e-05, gnorm=2.461, clip=100, loss_scale=256, train_wall=20, gb_free=15.5, wall=58554
2023-01-09 19:53:47 - progress_bar.py[line:272] - INFO: epoch 006:   2378 / 3665 loss=5.108, loss_v1=0, loss_v2=0, nll_loss=4.201, ntokens=858, nsentences=32, sample_size=858, sample_size_v1=0, sample_size_v2=0, ppl=18.4, wps=434.2, ups=0.51, wpb=858, bsz=32, num_updates=20670, lr=2.31924e-05, gnorm=2.76, clip=100, loss_scale=256, train_wall=20, gb_free=15.5, wall=58574
2023-01-09 19:54:07 - progress_bar.py[line:272] - INFO: epoch 006:   2388 / 3665 loss=5.032, loss_v1=0, loss_v2=0, nll_loss=4.117, ntokens=867.6, nsentences=32, sample_size=867.6, sample_size_v1=0, sample_size_v2=0, ppl=17.35, wps=439.4, ups=0.51, wpb=867.6, bsz=32, num_updates=20680, lr=2.31778e-05, gnorm=2.738, clip=100, loss_scale=256, train_wall=20, gb_free=14.9, wall=58593
2023-01-09 19:54:27 - progress_bar.py[line:272] - INFO: epoch 006:   2398 / 3665 loss=5.001, loss_v1=0, loss_v2=0, nll_loss=4.083, ntokens=1048.3, nsentences=32, sample_size=1048.3, sample_size_v1=0, sample_size_v2=0, ppl=16.95, wps=532.9, ups=0.51, wpb=1048.3, bsz=32, num_updates=20690, lr=2.31633e-05, gnorm=2.117, clip=100, loss_scale=256, train_wall=20, gb_free=15.1, wall=58613
2023-01-09 19:54:47 - progress_bar.py[line:272] - INFO: epoch 006:   2408 / 3665 loss=5.055, loss_v1=0, loss_v2=0, nll_loss=4.145, ntokens=818.2, nsentences=32, sample_size=818.2, sample_size_v1=0, sample_size_v2=0, ppl=17.69, wps=413.7, ups=0.51, wpb=818.2, bsz=32, num_updates=20700, lr=2.31488e-05, gnorm=2.744, clip=100, loss_scale=256, train_wall=20, gb_free=15.7, wall=58633
2023-01-09 19:55:06 - progress_bar.py[line:272] - INFO: epoch 006:   2418 / 3665 loss=4.982, loss_v1=0, loss_v2=0, nll_loss=4.061, ntokens=742.5, nsentences=32, sample_size=742.5, sample_size_v1=0, sample_size_v2=0, ppl=16.69, wps=378.7, ups=0.51, wpb=742.5, bsz=32, num_updates=20710, lr=2.31343e-05, gnorm=3.153, clip=100, loss_scale=256, train_wall=20, gb_free=15.4, wall=58652
2023-01-09 19:55:26 - progress_bar.py[line:272] - INFO: epoch 006:   2428 / 3665 loss=4.913, loss_v1=0, loss_v2=0, nll_loss=3.986, ntokens=885.2, nsentences=32, sample_size=885.2, sample_size_v1=0, sample_size_v2=0, ppl=15.84, wps=449.1, ups=0.51, wpb=885.2, bsz=32, num_updates=20720, lr=2.31198e-05, gnorm=2.527, clip=100, loss_scale=256, train_wall=20, gb_free=15.4, wall=58672
2023-01-09 19:55:46 - progress_bar.py[line:272] - INFO: epoch 006:   2438 / 3665 loss=4.983, loss_v1=0, loss_v2=0, nll_loss=4.065, ntokens=883.7, nsentences=32, sample_size=883.7, sample_size_v1=0, sample_size_v2=0, ppl=16.74, wps=442.3, ups=0.5, wpb=883.7, bsz=32, num_updates=20730, lr=2.31053e-05, gnorm=2.449, clip=100, loss_scale=256, train_wall=20, gb_free=15.7, wall=58692
2023-01-09 19:56:06 - progress_bar.py[line:272] - INFO: epoch 006:   2448 / 3665 loss=4.98, loss_v1=0, loss_v2=0, nll_loss=4.061, ntokens=791.7, nsentences=32, sample_size=791.7, sample_size_v1=0, sample_size_v2=0, ppl=16.69, wps=392.2, ups=0.5, wpb=791.7, bsz=32, num_updates=20740, lr=2.30908e-05, gnorm=2.793, clip=100, loss_scale=256, train_wall=20, gb_free=15.5, wall=58712
2023-01-09 19:56:26 - progress_bar.py[line:272] - INFO: epoch 006:   2458 / 3665 loss=4.996, loss_v1=0, loss_v2=0, nll_loss=4.078, ntokens=932, nsentences=32, sample_size=932, sample_size_v1=0, sample_size_v2=0, ppl=16.89, wps=461.7, ups=0.5, wpb=932, bsz=32, num_updates=20750, lr=2.30763e-05, gnorm=2.496, clip=100, loss_scale=256, train_wall=20, gb_free=15.2, wall=58733
2023-01-09 19:56:46 - progress_bar.py[line:272] - INFO: epoch 006:   2468 / 3665 loss=5.111, loss_v1=0, loss_v2=0, nll_loss=4.205, ntokens=989.5, nsentences=32, sample_size=989.5, sample_size_v1=0, sample_size_v2=0, ppl=18.44, wps=491.7, ups=0.5, wpb=989.5, bsz=32, num_updates=20760, lr=2.30617e-05, gnorm=2.414, clip=100, loss_scale=256, train_wall=20, gb_free=15.4, wall=58753
2023-01-09 19:57:06 - progress_bar.py[line:272] - INFO: epoch 006:   2478 / 3665 loss=4.946, loss_v1=0, loss_v2=0, nll_loss=4.021, ntokens=763, nsentences=32, sample_size=763, sample_size_v1=0, sample_size_v2=0, ppl=16.24, wps=380.3, ups=0.5, wpb=763, bsz=32, num_updates=20770, lr=2.30472e-05, gnorm=2.704, clip=100, loss_scale=256, train_wall=20, gb_free=15.7, wall=58773
2023-01-09 19:57:26 - progress_bar.py[line:272] - INFO: epoch 006:   2488 / 3665 loss=5.032, loss_v1=0, loss_v2=0, nll_loss=4.118, ntokens=887.6, nsentences=32, sample_size=887.6, sample_size_v1=0, sample_size_v2=0, ppl=17.36, wps=446, ups=0.5, wpb=887.6, bsz=32, num_updates=20780, lr=2.30327e-05, gnorm=2.449, clip=100, loss_scale=256, train_wall=20, gb_free=15.6, wall=58793
2023-01-09 19:57:46 - progress_bar.py[line:272] - INFO: epoch 006:   2498 / 3665 loss=5.147, loss_v1=0, loss_v2=0, nll_loss=4.245, ntokens=1175.1, nsentences=32, sample_size=1175.1, sample_size_v1=0, sample_size_v2=0, ppl=18.96, wps=590.9, ups=0.5, wpb=1175.1, bsz=32, num_updates=20790, lr=2.30182e-05, gnorm=2.152, clip=100, loss_scale=256, train_wall=20, gb_free=15.3, wall=58813
2023-01-09 19:58:06 - progress_bar.py[line:272] - INFO: epoch 006:   2508 / 3665 loss=4.994, loss_v1=0, loss_v2=0, nll_loss=4.075, ntokens=701.7, nsentences=32, sample_size=701.7, sample_size_v1=0, sample_size_v2=0, ppl=16.86, wps=359.4, ups=0.51, wpb=701.7, bsz=32, num_updates=20800, lr=2.30037e-05, gnorm=3.067, clip=100, loss_scale=256, train_wall=19, gb_free=15.5, wall=58832
2023-01-09 19:58:26 - progress_bar.py[line:272] - INFO: epoch 006:   2518 / 3665 loss=5.086, loss_v1=0, loss_v2=0, nll_loss=4.179, ntokens=940.4, nsentences=32, sample_size=940.4, sample_size_v1=0, sample_size_v2=0, ppl=18.12, wps=472.2, ups=0.5, wpb=940.4, bsz=32, num_updates=20810, lr=2.29892e-05, gnorm=2.403, clip=100, loss_scale=256, train_wall=20, gb_free=15.5, wall=58852
2023-01-09 19:58:46 - progress_bar.py[line:272] - INFO: epoch 006:   2528 / 3665 loss=5.081, loss_v1=0, loss_v2=0, nll_loss=4.173, ntokens=1008.1, nsentences=32, sample_size=1008.1, sample_size_v1=0, sample_size_v2=0, ppl=18.04, wps=508.5, ups=0.5, wpb=1008.1, bsz=32, num_updates=20820, lr=2.29747e-05, gnorm=2.306, clip=100, loss_scale=256, train_wall=20, gb_free=15.2, wall=58872
2023-01-09 19:59:05 - progress_bar.py[line:272] - INFO: epoch 006:   2538 / 3665 loss=5.116, loss_v1=0, loss_v2=0, nll_loss=4.21, ntokens=891.7, nsentences=32, sample_size=891.7, sample_size_v1=0, sample_size_v2=0, ppl=18.51, wps=452.7, ups=0.51, wpb=891.7, bsz=32, num_updates=20830, lr=2.29601e-05, gnorm=2.537, clip=100, loss_scale=256, train_wall=20, gb_free=15.5, wall=58891
2023-01-09 19:59:25 - progress_bar.py[line:272] - INFO: epoch 006:   2548 / 3665 loss=5.009, loss_v1=0, loss_v2=0, nll_loss=4.092, ntokens=916.7, nsentences=32, sample_size=916.7, sample_size_v1=0, sample_size_v2=0, ppl=17.05, wps=463, ups=0.51, wpb=916.7, bsz=32, num_updates=20840, lr=2.29456e-05, gnorm=2.512, clip=100, loss_scale=256, train_wall=20, gb_free=15.5, wall=58911
2023-01-09 19:59:45 - progress_bar.py[line:272] - INFO: epoch 006:   2558 / 3665 loss=5.011, loss_v1=0, loss_v2=0, nll_loss=4.096, ntokens=1074.3, nsentences=32, sample_size=1074.3, sample_size_v1=0, sample_size_v2=0, ppl=17.1, wps=544.5, ups=0.51, wpb=1074.3, bsz=32, num_updates=20850, lr=2.29311e-05, gnorm=2.137, clip=100, loss_scale=256, train_wall=20, gb_free=15.5, wall=58931
2023-01-09 20:00:05 - progress_bar.py[line:272] - INFO: epoch 006:   2568 / 3665 loss=5.051, loss_v1=0, loss_v2=0, nll_loss=4.14, ntokens=854.7, nsentences=32, sample_size=854.7, sample_size_v1=0, sample_size_v2=0, ppl=17.63, wps=419.7, ups=0.49, wpb=854.7, bsz=32, num_updates=20860, lr=2.29166e-05, gnorm=2.738, clip=100, loss_scale=256, train_wall=20, gb_free=15.7, wall=58951
2023-01-09 20:00:25 - progress_bar.py[line:272] - INFO: epoch 006:   2578 / 3665 loss=4.908, loss_v1=0, loss_v2=0, nll_loss=3.98, ntokens=729.9, nsentences=32, sample_size=729.9, sample_size_v1=0, sample_size_v2=0, ppl=15.78, wps=361.3, ups=0.5, wpb=729.9, bsz=32, num_updates=20870, lr=2.29021e-05, gnorm=2.989, clip=100, loss_scale=256, train_wall=20, gb_free=15.6, wall=58972
2023-01-09 20:00:31 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 128.0
2023-01-09 20:00:48 - progress_bar.py[line:272] - INFO: epoch 006:   2589 / 3665 loss=4.944, loss_v1=0, loss_v2=0, nll_loss=4.021, ntokens=926, nsentences=32, sample_size=926, sample_size_v1=0, sample_size_v2=0, ppl=16.23, wps=414.8, ups=0.45, wpb=926, bsz=32, num_updates=20880, lr=2.28876e-05, gnorm=2.432, clip=100, loss_scale=128, train_wall=22, gb_free=15.3, wall=58994
2023-01-09 20:01:08 - progress_bar.py[line:272] - INFO: epoch 006:   2599 / 3665 loss=5.094, loss_v1=0, loss_v2=0, nll_loss=4.188, ntokens=835.3, nsentences=32, sample_size=835.3, sample_size_v1=0, sample_size_v2=0, ppl=18.23, wps=417.5, ups=0.5, wpb=835.3, bsz=32, num_updates=20890, lr=2.28731e-05, gnorm=2.649, clip=100, loss_scale=128, train_wall=20, gb_free=15.5, wall=59014
2023-01-09 20:01:27 - progress_bar.py[line:272] - INFO: epoch 006:   2609 / 3665 loss=5.073, loss_v1=0, loss_v2=0, nll_loss=4.162, ntokens=886.1, nsentences=32, sample_size=886.1, sample_size_v1=0, sample_size_v2=0, ppl=17.9, wps=453.4, ups=0.51, wpb=886.1, bsz=32, num_updates=20900, lr=2.28586e-05, gnorm=3.038, clip=100, loss_scale=128, train_wall=20, gb_free=15.5, wall=59033
2023-01-09 20:01:47 - progress_bar.py[line:272] - INFO: epoch 006:   2619 / 3665 loss=5.074, loss_v1=0, loss_v2=0, nll_loss=4.164, ntokens=1104.9, nsentences=32, sample_size=1104.9, sample_size_v1=0, sample_size_v2=0, ppl=17.92, wps=560.3, ups=0.51, wpb=1104.9, bsz=32, num_updates=20910, lr=2.2844e-05, gnorm=2.225, clip=100, loss_scale=128, train_wall=20, gb_free=15.5, wall=59053
2023-01-09 20:02:07 - progress_bar.py[line:272] - INFO: epoch 006:   2629 / 3665 loss=5.16, loss_v1=0, loss_v2=0, nll_loss=4.26, ntokens=1064.6, nsentences=32, sample_size=1064.6, sample_size_v1=0, sample_size_v2=0, ppl=19.16, wps=538.9, ups=0.51, wpb=1064.6, bsz=32, num_updates=20920, lr=2.28295e-05, gnorm=2.347, clip=100, loss_scale=128, train_wall=20, gb_free=15.3, wall=59073
2023-01-09 20:02:26 - progress_bar.py[line:272] - INFO: epoch 006:   2639 / 3665 loss=5.045, loss_v1=0, loss_v2=0, nll_loss=4.132, ntokens=798.7, nsentences=32, sample_size=798.7, sample_size_v1=0, sample_size_v2=0, ppl=17.53, wps=404.5, ups=0.51, wpb=798.7, bsz=32, num_updates=20930, lr=2.2815e-05, gnorm=2.881, clip=100, loss_scale=128, train_wall=20, gb_free=15.2, wall=59093
2023-01-09 20:02:46 - progress_bar.py[line:272] - INFO: epoch 006:   2649 / 3665 loss=5.021, loss_v1=0, loss_v2=0, nll_loss=4.107, ntokens=1055.8, nsentences=32, sample_size=1055.8, sample_size_v1=0, sample_size_v2=0, ppl=17.23, wps=535.6, ups=0.51, wpb=1055.8, bsz=32, num_updates=20940, lr=2.28005e-05, gnorm=2.272, clip=100, loss_scale=128, train_wall=20, gb_free=15.2, wall=59112
2023-01-09 20:03:07 - progress_bar.py[line:272] - INFO: epoch 006:   2659 / 3665 loss=5.139, loss_v1=0, loss_v2=0, nll_loss=4.238, ntokens=985, nsentences=32, sample_size=985, sample_size_v1=0, sample_size_v2=0, ppl=18.86, wps=481.3, ups=0.49, wpb=985, bsz=32, num_updates=20950, lr=2.2786e-05, gnorm=2.472, clip=100, loss_scale=128, train_wall=20, gb_free=14.8, wall=59133
2023-01-09 20:03:27 - progress_bar.py[line:272] - INFO: epoch 006:   2669 / 3665 loss=5.014, loss_v1=0, loss_v2=0, nll_loss=4.096, ntokens=780.2, nsentences=32, sample_size=780.2, sample_size_v1=0, sample_size_v2=0, ppl=17.11, wps=377.9, ups=0.48, wpb=780.2, bsz=32, num_updates=20960, lr=2.27715e-05, gnorm=2.791, clip=100, loss_scale=128, train_wall=21, gb_free=15.5, wall=59153
2023-01-09 20:03:47 - progress_bar.py[line:272] - INFO: epoch 006:   2679 / 3665 loss=5, loss_v1=0, loss_v2=0, nll_loss=4.08, ntokens=910.4, nsentences=32, sample_size=910.4, sample_size_v1=0, sample_size_v2=0, ppl=16.92, wps=450.2, ups=0.49, wpb=910.4, bsz=32, num_updates=20970, lr=2.2757e-05, gnorm=2.649, clip=100, loss_scale=128, train_wall=20, gb_free=15.2, wall=59174
2023-01-09 20:04:07 - progress_bar.py[line:272] - INFO: epoch 006:   2689 / 3665 loss=5.116, loss_v1=0, loss_v2=0, nll_loss=4.213, ntokens=1104.1, nsentences=32, sample_size=1104.1, sample_size_v1=0, sample_size_v2=0, ppl=18.55, wps=559.1, ups=0.51, wpb=1104.1, bsz=32, num_updates=20980, lr=2.27424e-05, gnorm=2.301, clip=100, loss_scale=128, train_wall=20, gb_free=15.6, wall=59193
2023-01-09 20:04:27 - progress_bar.py[line:272] - INFO: epoch 006:   2699 / 3665 loss=4.938, loss_v1=0, loss_v2=0, nll_loss=4.013, ntokens=691.3, nsentences=32, sample_size=691.3, sample_size_v1=0, sample_size_v2=0, ppl=16.15, wps=354.7, ups=0.51, wpb=691.3, bsz=32, num_updates=20990, lr=2.27279e-05, gnorm=3.153, clip=100, loss_scale=128, train_wall=19, gb_free=15.6, wall=59213
2023-01-09 20:04:46 - progress_bar.py[line:272] - INFO: epoch 006:   2709 / 3665 loss=5.037, loss_v1=0, loss_v2=0, nll_loss=4.123, ntokens=1019.4, nsentences=32, sample_size=1019.4, sample_size_v1=0, sample_size_v2=0, ppl=17.43, wps=515.6, ups=0.51, wpb=1019.4, bsz=32, num_updates=21000, lr=2.27134e-05, gnorm=2.402, clip=100, loss_scale=128, train_wall=20, gb_free=15.4, wall=59233
2023-01-09 20:04:46 - train.py[line:445] - INFO: begin validation on "valid" subset
slice_id 0 seek offset 0
slice_id 0 seek offset 0
2023-01-09 20:09:43 - progress_bar.py[line:282] - INFO: epoch 006 | valid on 'valid' subset | loss 5.034 | loss_v1 0 | loss_v2 0 | nll_loss 4.102 | ntokens 117.19 | nsentences 4 | sample_size 117.19 | sample_size_v1 0 | sample_size_v2 0 | AP 0 | total positives 21.7464 | TP 0 | FP 5.45153 | ppl 17.18 | wps 493.5 | wpb 117.2 | bsz 4 | num_updates 21000 | best_AP 0
2023-01-09 20:09:43 - checkpoint_utils.py[line:64] - INFO: Preparing to save checkpoint for epoch 6 @ 21000 updates
2023-01-09 20:09:43 - trainer.py[line:431] - INFO: Saving checkpoint to ../../checkpoints/OFA/detection_checkpoints/10_5e-5_512/checkpoint_6_21000.pt
2023-01-09 20:09:46 - trainer.py[line:441] - INFO: Finished saving checkpoint to ../../checkpoints/OFA/detection_checkpoints/10_5e-5_512/checkpoint_6_21000.pt
2023-01-09 20:10:56 - checkpoint_utils.py[line:133] - INFO: Saved checkpoint ../../checkpoints/OFA/detection_checkpoints/10_5e-5_512/checkpoint_6_21000.pt (epoch 6 @ 21000 updates, score 0.0) (writing took 72.74955852283165 seconds)
2023-01-09 20:11:15 - progress_bar.py[line:272] - INFO: epoch 006:   2719 / 3665 loss=5.093, loss_v1=0, loss_v2=0, nll_loss=4.184, ntokens=1179.6, nsentences=32, sample_size=1179.6, sample_size_v1=0, sample_size_v2=0, ppl=18.18, wps=30.3, ups=0.03, wpb=1179.6, bsz=32, num_updates=21010, lr=2.26989e-05, gnorm=2.046, clip=100, loss_scale=128, train_wall=19, gb_free=15.1, wall=59622
2023-01-09 20:11:35 - progress_bar.py[line:272] - INFO: epoch 006:   2729 / 3665 loss=5.011, loss_v1=0, loss_v2=0, nll_loss=4.094, ntokens=723.5, nsentences=32, sample_size=723.5, sample_size_v1=0, sample_size_v2=0, ppl=17.08, wps=372.2, ups=0.51, wpb=723.5, bsz=32, num_updates=21020, lr=2.26844e-05, gnorm=3.026, clip=100, loss_scale=128, train_wall=19, gb_free=15.5, wall=59641
2023-01-09 20:11:54 - progress_bar.py[line:272] - INFO: epoch 006:   2739 / 3665 loss=5.032, loss_v1=0, loss_v2=0, nll_loss=4.118, ntokens=919.8, nsentences=32, sample_size=919.8, sample_size_v1=0, sample_size_v2=0, ppl=17.36, wps=471.3, ups=0.51, wpb=919.8, bsz=32, num_updates=21030, lr=2.26699e-05, gnorm=2.675, clip=100, loss_scale=128, train_wall=19, gb_free=15.6, wall=59661
2023-01-09 20:12:14 - progress_bar.py[line:272] - INFO: epoch 006:   2749 / 3665 loss=5, loss_v1=0, loss_v2=0, nll_loss=4.082, ntokens=965.9, nsentences=32, sample_size=965.9, sample_size_v1=0, sample_size_v2=0, ppl=16.93, wps=491.4, ups=0.51, wpb=965.9, bsz=32, num_updates=21040, lr=2.26554e-05, gnorm=2.406, clip=100, loss_scale=128, train_wall=20, gb_free=14.5, wall=59680
2023-01-09 20:12:34 - progress_bar.py[line:272] - INFO: epoch 006:   2759 / 3665 loss=5.082, loss_v1=0, loss_v2=0, nll_loss=4.175, ntokens=799.1, nsentences=32, sample_size=799.1, sample_size_v1=0, sample_size_v2=0, ppl=18.07, wps=408.4, ups=0.51, wpb=799.1, bsz=32, num_updates=21050, lr=2.26409e-05, gnorm=2.774, clip=100, loss_scale=128, train_wall=20, gb_free=15.2, wall=59700
2023-01-09 20:12:53 - progress_bar.py[line:272] - INFO: epoch 006:   2769 / 3665 loss=5.016, loss_v1=0, loss_v2=0, nll_loss=4.099, ntokens=808.1, nsentences=32, sample_size=808.1, sample_size_v1=0, sample_size_v2=0, ppl=17.13, wps=414, ups=0.51, wpb=808.1, bsz=32, num_updates=21060, lr=2.26263e-05, gnorm=2.923, clip=100, loss_scale=128, train_wall=19, gb_free=15.3, wall=59719
2023-01-09 20:13:13 - progress_bar.py[line:272] - INFO: epoch 006:   2779 / 3665 loss=5.013, loss_v1=0, loss_v2=0, nll_loss=4.097, ntokens=1039.2, nsentences=32, sample_size=1039.2, sample_size_v1=0, sample_size_v2=0, ppl=17.11, wps=530.4, ups=0.51, wpb=1039.2, bsz=32, num_updates=21070, lr=2.26118e-05, gnorm=2.342, clip=100, loss_scale=128, train_wall=20, gb_free=15.6, wall=59739
2023-01-09 20:13:32 - progress_bar.py[line:272] - INFO: epoch 006:   2789 / 3665 loss=5.106, loss_v1=0, loss_v2=0, nll_loss=4.202, ntokens=948.9, nsentences=32, sample_size=948.9, sample_size_v1=0, sample_size_v2=0, ppl=18.4, wps=483.6, ups=0.51, wpb=948.9, bsz=32, num_updates=21080, lr=2.25973e-05, gnorm=2.486, clip=100, loss_scale=128, train_wall=20, gb_free=15.5, wall=59759
2023-01-09 20:13:52 - progress_bar.py[line:272] - INFO: epoch 006:   2799 / 3665 loss=5.008, loss_v1=0, loss_v2=0, nll_loss=4.091, ntokens=867.1, nsentences=32, sample_size=867.1, sample_size_v1=0, sample_size_v2=0, ppl=17.04, wps=441.9, ups=0.51, wpb=867.1, bsz=32, num_updates=21090, lr=2.25828e-05, gnorm=2.568, clip=100, loss_scale=128, train_wall=20, gb_free=15.4, wall=59778
2023-01-09 20:14:12 - progress_bar.py[line:272] - INFO: epoch 006:   2809 / 3665 loss=5.041, loss_v1=0, loss_v2=0, nll_loss=4.129, ntokens=1065.6, nsentences=32, sample_size=1065.6, sample_size_v1=0, sample_size_v2=0, ppl=17.49, wps=541.6, ups=0.51, wpb=1065.6, bsz=32, num_updates=21100, lr=2.25683e-05, gnorm=2.228, clip=100, loss_scale=128, train_wall=20, gb_free=15.1, wall=59798
2023-01-09 20:14:31 - progress_bar.py[line:272] - INFO: epoch 006:   2819 / 3665 loss=5.015, loss_v1=0, loss_v2=0, nll_loss=4.099, ntokens=858.9, nsentences=32, sample_size=858.9, sample_size_v1=0, sample_size_v2=0, ppl=17.13, wps=437.5, ups=0.51, wpb=858.9, bsz=32, num_updates=21110, lr=2.25538e-05, gnorm=2.476, clip=100, loss_scale=128, train_wall=20, gb_free=15.4, wall=59818
2023-01-09 20:14:51 - progress_bar.py[line:272] - INFO: epoch 006:   2829 / 3665 loss=5.051, loss_v1=0, loss_v2=0, nll_loss=4.14, ntokens=802.6, nsentences=32, sample_size=802.6, sample_size_v1=0, sample_size_v2=0, ppl=17.63, wps=407.2, ups=0.51, wpb=802.6, bsz=32, num_updates=21120, lr=2.25393e-05, gnorm=2.841, clip=100, loss_scale=128, train_wall=20, gb_free=15.7, wall=59837
2023-01-09 20:15:11 - progress_bar.py[line:272] - INFO: epoch 006:   2839 / 3665 loss=5.006, loss_v1=0, loss_v2=0, nll_loss=4.088, ntokens=997.1, nsentences=32, sample_size=997.1, sample_size_v1=0, sample_size_v2=0, ppl=17.01, wps=501.5, ups=0.5, wpb=997.1, bsz=32, num_updates=21130, lr=2.25247e-05, gnorm=2.378, clip=100, loss_scale=128, train_wall=20, gb_free=15.4, wall=59857
2023-01-09 20:15:31 - progress_bar.py[line:272] - INFO: epoch 006:   2849 / 3665 loss=5.126, loss_v1=0, loss_v2=0, nll_loss=4.221, ntokens=993.9, nsentences=32, sample_size=993.9, sample_size_v1=0, sample_size_v2=0, ppl=18.65, wps=500.7, ups=0.5, wpb=993.9, bsz=32, num_updates=21140, lr=2.25102e-05, gnorm=2.493, clip=100, loss_scale=128, train_wall=20, gb_free=15.1, wall=59877
2023-01-09 20:15:50 - progress_bar.py[line:272] - INFO: epoch 006:   2859 / 3665 loss=4.991, loss_v1=0, loss_v2=0, nll_loss=4.07, ntokens=751.5, nsentences=32, sample_size=751.5, sample_size_v1=0, sample_size_v2=0, ppl=16.8, wps=380.5, ups=0.51, wpb=751.5, bsz=32, num_updates=21150, lr=2.24957e-05, gnorm=2.765, clip=100, loss_scale=128, train_wall=20, gb_free=15.4, wall=59897
2023-01-09 20:16:10 - progress_bar.py[line:272] - INFO: epoch 006:   2869 / 3665 loss=4.929, loss_v1=0, loss_v2=0, nll_loss=4.005, ntokens=820.5, nsentences=32, sample_size=820.5, sample_size_v1=0, sample_size_v2=0, ppl=16.06, wps=414.8, ups=0.51, wpb=820.5, bsz=32, num_updates=21160, lr=2.24812e-05, gnorm=2.535, clip=100, loss_scale=128, train_wall=20, gb_free=15.2, wall=59917
2023-01-09 20:16:30 - progress_bar.py[line:272] - INFO: epoch 006:   2879 / 3665 loss=5.144, loss_v1=0, loss_v2=0, nll_loss=4.244, ntokens=1068.3, nsentences=32, sample_size=1068.3, sample_size_v1=0, sample_size_v2=0, ppl=18.95, wps=538.2, ups=0.5, wpb=1068.3, bsz=32, num_updates=21170, lr=2.24667e-05, gnorm=2.216, clip=100, loss_scale=128, train_wall=20, gb_free=15.5, wall=59936
2023-01-09 20:16:50 - progress_bar.py[line:272] - INFO: epoch 006:   2889 / 3665 loss=5.012, loss_v1=0, loss_v2=0, nll_loss=4.094, ntokens=787.5, nsentences=32, sample_size=787.5, sample_size_v1=0, sample_size_v2=0, ppl=17.07, wps=398.7, ups=0.51, wpb=787.5, bsz=32, num_updates=21180, lr=2.24522e-05, gnorm=2.663, clip=100, loss_scale=128, train_wall=20, gb_free=15.5, wall=59956
2023-01-09 20:17:10 - progress_bar.py[line:272] - INFO: epoch 006:   2899 / 3665 loss=4.952, loss_v1=0, loss_v2=0, nll_loss=4.028, ntokens=818.2, nsentences=32, sample_size=818.2, sample_size_v1=0, sample_size_v2=0, ppl=16.32, wps=415.6, ups=0.51, wpb=818.2, bsz=32, num_updates=21190, lr=2.24377e-05, gnorm=2.737, clip=100, loss_scale=128, train_wall=20, gb_free=15.2, wall=59976
2023-01-09 20:17:29 - progress_bar.py[line:272] - INFO: epoch 006:   2909 / 3665 loss=5.076, loss_v1=0, loss_v2=0, nll_loss=4.167, ntokens=1168.9, nsentences=32, sample_size=1168.9, sample_size_v1=0, sample_size_v2=0, ppl=17.96, wps=587.2, ups=0.5, wpb=1168.9, bsz=32, num_updates=21200, lr=2.24232e-05, gnorm=2.061, clip=100, loss_scale=128, train_wall=20, gb_free=15.3, wall=59996
2023-01-09 20:17:49 - progress_bar.py[line:272] - INFO: epoch 006:   2919 / 3665 loss=5.101, loss_v1=0, loss_v2=0, nll_loss=4.195, ntokens=893.5, nsentences=32, sample_size=893.5, sample_size_v1=0, sample_size_v2=0, ppl=18.31, wps=451.2, ups=0.5, wpb=893.5, bsz=32, num_updates=21210, lr=2.24086e-05, gnorm=2.527, clip=100, loss_scale=128, train_wall=20, gb_free=15.4, wall=60016
2023-01-09 20:18:09 - progress_bar.py[line:272] - INFO: epoch 006:   2929 / 3665 loss=5.003, loss_v1=0, loss_v2=0, nll_loss=4.086, ntokens=794.2, nsentences=32, sample_size=794.2, sample_size_v1=0, sample_size_v2=0, ppl=16.99, wps=402.3, ups=0.51, wpb=794.2, bsz=32, num_updates=21220, lr=2.23941e-05, gnorm=2.948, clip=100, loss_scale=128, train_wall=20, gb_free=15.7, wall=60035
2023-01-09 20:18:29 - progress_bar.py[line:272] - INFO: epoch 006:   2939 / 3665 loss=4.975, loss_v1=0, loss_v2=0, nll_loss=4.054, ntokens=1033, nsentences=32, sample_size=1033, sample_size_v1=0, sample_size_v2=0, ppl=16.61, wps=520.8, ups=0.5, wpb=1033, bsz=32, num_updates=21230, lr=2.23796e-05, gnorm=2.256, clip=100, loss_scale=128, train_wall=20, gb_free=15.2, wall=60055
2023-01-09 20:18:49 - progress_bar.py[line:272] - INFO: epoch 006:   2949 / 3665 loss=5.177, loss_v1=0, loss_v2=0, nll_loss=4.279, ntokens=1110.6, nsentences=32, sample_size=1110.6, sample_size_v1=0, sample_size_v2=0, ppl=19.41, wps=558.3, ups=0.5, wpb=1110.6, bsz=32, num_updates=21240, lr=2.23651e-05, gnorm=2.321, clip=100, loss_scale=128, train_wall=20, gb_free=15.5, wall=60075
2023-01-09 20:19:09 - progress_bar.py[line:272] - INFO: epoch 006:   2959 / 3665 loss=5.078, loss_v1=0, loss_v2=0, nll_loss=4.169, ntokens=952.6, nsentences=32, sample_size=952.6, sample_size_v1=0, sample_size_v2=0, ppl=17.99, wps=481.1, ups=0.51, wpb=952.6, bsz=32, num_updates=21250, lr=2.23506e-05, gnorm=2.532, clip=100, loss_scale=128, train_wall=20, gb_free=15.2, wall=60095
2023-01-09 20:19:28 - progress_bar.py[line:272] - INFO: epoch 006:   2969 / 3665 loss=4.998, loss_v1=0, loss_v2=0, nll_loss=4.08, ntokens=1032.1, nsentences=32, sample_size=1032.1, sample_size_v1=0, sample_size_v2=0, ppl=16.92, wps=521.1, ups=0.5, wpb=1032.1, bsz=32, num_updates=21260, lr=2.23361e-05, gnorm=2.08, clip=100, loss_scale=128, train_wall=20, gb_free=14.7, wall=60115
2023-01-09 20:19:48 - progress_bar.py[line:272] - INFO: epoch 006:   2979 / 3665 loss=5.128, loss_v1=0, loss_v2=0, nll_loss=4.225, ntokens=1043.3, nsentences=32, sample_size=1043.3, sample_size_v1=0, sample_size_v2=0, ppl=18.7, wps=526.4, ups=0.5, wpb=1043.3, bsz=32, num_updates=21270, lr=2.23216e-05, gnorm=2.529, clip=100, loss_scale=128, train_wall=20, gb_free=15.4, wall=60134
2023-01-09 20:20:08 - progress_bar.py[line:272] - INFO: epoch 006:   2989 / 3665 loss=4.985, loss_v1=0, loss_v2=0, nll_loss=4.065, ntokens=862.5, nsentences=32, sample_size=862.5, sample_size_v1=0, sample_size_v2=0, ppl=16.74, wps=435.8, ups=0.51, wpb=862.5, bsz=32, num_updates=21280, lr=2.2307e-05, gnorm=2.564, clip=100, loss_scale=128, train_wall=20, gb_free=15.2, wall=60154
2023-01-09 20:20:28 - progress_bar.py[line:272] - INFO: epoch 006:   2999 / 3665 loss=5.065, loss_v1=0, loss_v2=0, nll_loss=4.155, ntokens=1072.6, nsentences=32, sample_size=1072.6, sample_size_v1=0, sample_size_v2=0, ppl=17.81, wps=539.7, ups=0.5, wpb=1072.6, bsz=32, num_updates=21290, lr=2.22925e-05, gnorm=2.23, clip=100, loss_scale=128, train_wall=20, gb_free=14.2, wall=60174
2023-01-09 20:20:48 - progress_bar.py[line:272] - INFO: epoch 006:   3009 / 3665 loss=5.047, loss_v1=0, loss_v2=0, nll_loss=4.134, ntokens=911.4, nsentences=32, sample_size=911.4, sample_size_v1=0, sample_size_v2=0, ppl=17.56, wps=456.7, ups=0.5, wpb=911.4, bsz=32, num_updates=21300, lr=2.2278e-05, gnorm=2.572, clip=100, loss_scale=128, train_wall=20, gb_free=15.7, wall=60194
2023-01-09 20:21:07 - progress_bar.py[line:272] - INFO: epoch 006:   3019 / 3665 loss=4.981, loss_v1=0, loss_v2=0, nll_loss=4.061, ntokens=760.9, nsentences=32, sample_size=760.9, sample_size_v1=0, sample_size_v2=0, ppl=16.69, wps=386.6, ups=0.51, wpb=760.9, bsz=32, num_updates=21310, lr=2.22635e-05, gnorm=2.864, clip=100, loss_scale=128, train_wall=20, gb_free=15.3, wall=60214
2023-01-09 20:21:27 - progress_bar.py[line:272] - INFO: epoch 006:   3029 / 3665 loss=4.999, loss_v1=0, loss_v2=0, nll_loss=4.082, ntokens=997.8, nsentences=32, sample_size=997.8, sample_size_v1=0, sample_size_v2=0, ppl=16.93, wps=503.9, ups=0.5, wpb=997.8, bsz=32, num_updates=21320, lr=2.2249e-05, gnorm=2.45, clip=100, loss_scale=128, train_wall=20, gb_free=15.5, wall=60234
2023-01-09 20:21:47 - progress_bar.py[line:272] - INFO: epoch 006:   3039 / 3665 loss=5.048, loss_v1=0, loss_v2=0, nll_loss=4.136, ntokens=1054.6, nsentences=32, sample_size=1054.6, sample_size_v1=0, sample_size_v2=0, ppl=17.58, wps=532.7, ups=0.51, wpb=1054.6, bsz=32, num_updates=21330, lr=2.22345e-05, gnorm=2.356, clip=100, loss_scale=128, train_wall=20, gb_free=15.1, wall=60253
2023-01-09 20:22:07 - progress_bar.py[line:272] - INFO: epoch 006:   3049 / 3665 loss=5.027, loss_v1=0, loss_v2=0, nll_loss=4.111, ntokens=791.6, nsentences=32, sample_size=791.6, sample_size_v1=0, sample_size_v2=0, ppl=17.28, wps=401.5, ups=0.51, wpb=791.6, bsz=32, num_updates=21340, lr=2.222e-05, gnorm=2.661, clip=100, loss_scale=128, train_wall=20, gb_free=15.7, wall=60273
2023-01-09 20:22:26 - progress_bar.py[line:272] - INFO: epoch 006:   3059 / 3665 loss=4.958, loss_v1=0, loss_v2=0, nll_loss=4.034, ntokens=939.7, nsentences=32, sample_size=939.7, sample_size_v1=0, sample_size_v2=0, ppl=16.38, wps=476.6, ups=0.51, wpb=939.7, bsz=32, num_updates=21350, lr=2.22055e-05, gnorm=2.423, clip=100, loss_scale=128, train_wall=20, gb_free=15.3, wall=60293
2023-01-09 20:22:46 - progress_bar.py[line:272] - INFO: epoch 006:   3069 / 3665 loss=5.111, loss_v1=0, loss_v2=0, nll_loss=4.208, ntokens=1157, nsentences=32, sample_size=1157, sample_size_v1=0, sample_size_v2=0, ppl=18.48, wps=582.7, ups=0.5, wpb=1157, bsz=32, num_updates=21360, lr=2.21909e-05, gnorm=2.04, clip=100, loss_scale=128, train_wall=20, gb_free=15.6, wall=60313
2023-01-09 20:23:06 - progress_bar.py[line:272] - INFO: epoch 006:   3079 / 3665 loss=5.057, loss_v1=0, loss_v2=0, nll_loss=4.146, ntokens=838.4, nsentences=32, sample_size=838.4, sample_size_v1=0, sample_size_v2=0, ppl=17.71, wps=425, ups=0.51, wpb=838.4, bsz=32, num_updates=21370, lr=2.21764e-05, gnorm=2.764, clip=100, loss_scale=128, train_wall=20, gb_free=15.5, wall=60332
2023-01-09 20:23:26 - progress_bar.py[line:272] - INFO: epoch 006:   3089 / 3665 loss=5.025, loss_v1=0, loss_v2=0, nll_loss=4.11, ntokens=952.5, nsentences=32, sample_size=952.5, sample_size_v1=0, sample_size_v2=0, ppl=17.26, wps=481.5, ups=0.51, wpb=952.5, bsz=32, num_updates=21380, lr=2.21619e-05, gnorm=2.409, clip=100, loss_scale=128, train_wall=20, gb_free=15.4, wall=60352
2023-01-09 20:23:46 - progress_bar.py[line:272] - INFO: epoch 006:   3099 / 3665 loss=5.092, loss_v1=0, loss_v2=0, nll_loss=4.183, ntokens=1079, nsentences=32, sample_size=1079, sample_size_v1=0, sample_size_v2=0, ppl=18.17, wps=544.7, ups=0.5, wpb=1079, bsz=32, num_updates=21390, lr=2.21474e-05, gnorm=2.158, clip=100, loss_scale=256, train_wall=20, gb_free=15.2, wall=60372
2023-01-09 20:24:05 - progress_bar.py[line:272] - INFO: epoch 006:   3109 / 3665 loss=5.081, loss_v1=0, loss_v2=0, nll_loss=4.173, ntokens=884.4, nsentences=32, sample_size=884.4, sample_size_v1=0, sample_size_v2=0, ppl=18.04, wps=447.7, ups=0.51, wpb=884.4, bsz=32, num_updates=21400, lr=2.21329e-05, gnorm=2.45, clip=100, loss_scale=256, train_wall=20, gb_free=15.4, wall=60392
2023-01-09 20:24:25 - progress_bar.py[line:272] - INFO: epoch 006:   3119 / 3665 loss=5.059, loss_v1=0, loss_v2=0, nll_loss=4.148, ntokens=866.3, nsentences=32, sample_size=866.3, sample_size_v1=0, sample_size_v2=0, ppl=17.73, wps=438.6, ups=0.51, wpb=866.3, bsz=32, num_updates=21410, lr=2.21184e-05, gnorm=2.554, clip=100, loss_scale=256, train_wall=20, gb_free=15.4, wall=60411
2023-01-09 20:24:45 - progress_bar.py[line:272] - INFO: epoch 006:   3129 / 3665 loss=5.046, loss_v1=0, loss_v2=0, nll_loss=4.134, ntokens=1059, nsentences=32, sample_size=1059, sample_size_v1=0, sample_size_v2=0, ppl=17.56, wps=533.4, ups=0.5, wpb=1059, bsz=32, num_updates=21420, lr=2.21039e-05, gnorm=2.177, clip=100, loss_scale=256, train_wall=20, gb_free=15.6, wall=60431
2023-01-09 20:25:05 - progress_bar.py[line:272] - INFO: epoch 006:   3139 / 3665 loss=5.131, loss_v1=0, loss_v2=0, nll_loss=4.226, ntokens=982.4, nsentences=32, sample_size=982.4, sample_size_v1=0, sample_size_v2=0, ppl=18.72, wps=495.6, ups=0.5, wpb=982.4, bsz=32, num_updates=21430, lr=2.20893e-05, gnorm=2.433, clip=100, loss_scale=256, train_wall=20, gb_free=15.7, wall=60451
2023-01-09 20:25:25 - progress_bar.py[line:272] - INFO: epoch 006:   3149 / 3665 loss=5.031, loss_v1=0, loss_v2=0, nll_loss=4.118, ntokens=840.8, nsentences=32, sample_size=840.8, sample_size_v1=0, sample_size_v2=0, ppl=17.36, wps=426.3, ups=0.51, wpb=840.8, bsz=32, num_updates=21440, lr=2.20748e-05, gnorm=2.644, clip=100, loss_scale=256, train_wall=20, gb_free=15.5, wall=60471
2023-01-09 20:25:44 - progress_bar.py[line:272] - INFO: epoch 006:   3159 / 3665 loss=5.03, loss_v1=0, loss_v2=0, nll_loss=4.115, ntokens=989.7, nsentences=32, sample_size=989.7, sample_size_v1=0, sample_size_v2=0, ppl=17.32, wps=500.1, ups=0.51, wpb=989.7, bsz=32, num_updates=21450, lr=2.20603e-05, gnorm=2.362, clip=100, loss_scale=256, train_wall=20, gb_free=15.3, wall=60491
2023-01-09 20:26:04 - progress_bar.py[line:272] - INFO: epoch 006:   3169 / 3665 loss=5.103, loss_v1=0, loss_v2=0, nll_loss=4.196, ntokens=987.8, nsentences=32, sample_size=987.8, sample_size_v1=0, sample_size_v2=0, ppl=18.33, wps=498.7, ups=0.5, wpb=987.8, bsz=32, num_updates=21460, lr=2.20458e-05, gnorm=2.33, clip=100, loss_scale=256, train_wall=20, gb_free=15.3, wall=60510
2023-01-09 20:26:24 - progress_bar.py[line:272] - INFO: epoch 006:   3179 / 3665 loss=4.995, loss_v1=0, loss_v2=0, nll_loss=4.078, ntokens=767, nsentences=32, sample_size=767, sample_size_v1=0, sample_size_v2=0, ppl=16.88, wps=389.6, ups=0.51, wpb=767, bsz=32, num_updates=21470, lr=2.20313e-05, gnorm=3.093, clip=100, loss_scale=256, train_wall=20, gb_free=15.3, wall=60530
2023-01-09 20:26:44 - progress_bar.py[line:272] - INFO: epoch 006:   3189 / 3665 loss=4.953, loss_v1=0, loss_v2=0, nll_loss=4.03, ntokens=894.1, nsentences=32, sample_size=894.1, sample_size_v1=0, sample_size_v2=0, ppl=16.33, wps=453.7, ups=0.51, wpb=894.1, bsz=32, num_updates=21480, lr=2.20168e-05, gnorm=2.464, clip=100, loss_scale=256, train_wall=20, gb_free=15.5, wall=60550
2023-01-09 20:27:03 - progress_bar.py[line:272] - INFO: epoch 006:   3199 / 3665 loss=5.111, loss_v1=0, loss_v2=0, nll_loss=4.205, ntokens=1026.9, nsentences=32, sample_size=1026.9, sample_size_v1=0, sample_size_v2=0, ppl=18.44, wps=517.6, ups=0.5, wpb=1026.9, bsz=32, num_updates=21490, lr=2.20023e-05, gnorm=2.25, clip=100, loss_scale=256, train_wall=20, gb_free=15.5, wall=60570
2023-01-09 20:27:23 - progress_bar.py[line:272] - INFO: epoch 006:   3209 / 3665 loss=4.921, loss_v1=0, loss_v2=0, nll_loss=3.993, ntokens=786.4, nsentences=32, sample_size=786.4, sample_size_v1=0, sample_size_v2=0, ppl=15.93, wps=398.1, ups=0.51, wpb=786.4, bsz=32, num_updates=21500, lr=2.19878e-05, gnorm=2.792, clip=100, loss_scale=256, train_wall=20, gb_free=15.6, wall=60589
2023-01-09 20:27:23 - train.py[line:445] - INFO: begin validation on "valid" subset
slice_id 0 seek offset 0
slice_id 0 seek offset 0
2023-01-09 20:32:06 - progress_bar.py[line:282] - INFO: epoch 006 | valid on 'valid' subset | loss 5.03 | loss_v1 0 | loss_v2 0 | nll_loss 4.1 | ntokens 116.565 | nsentences 4 | sample_size 116.565 | sample_size_v1 0 | sample_size_v2 0 | AP 0 | total positives 21.6292 | TP 0 | FP 5.22132 | ppl 17.15 | wps 514.3 | wpb 116.6 | bsz 4 | num_updates 21500 | best_AP 0
2023-01-09 20:32:06 - checkpoint_utils.py[line:64] - INFO: Preparing to save checkpoint for epoch 6 @ 21500 updates
2023-01-09 20:32:06 - trainer.py[line:431] - INFO: Saving checkpoint to ../../checkpoints/OFA/detection_checkpoints/10_5e-5_512/checkpoint_6_21500.pt
2023-01-09 20:32:10 - trainer.py[line:441] - INFO: Finished saving checkpoint to ../../checkpoints/OFA/detection_checkpoints/10_5e-5_512/checkpoint_6_21500.pt
2023-01-09 20:33:18 - checkpoint_utils.py[line:133] - INFO: Saved checkpoint ../../checkpoints/OFA/detection_checkpoints/10_5e-5_512/checkpoint_6_21500.pt (epoch 6 @ 21500 updates, score 0.0) (writing took 71.79179122019559 seconds)
2023-01-09 20:33:38 - progress_bar.py[line:272] - INFO: epoch 006:   3219 / 3665 loss=5.087, loss_v1=0, loss_v2=0, nll_loss=4.179, ntokens=1231.7, nsentences=32, sample_size=1231.7, sample_size_v1=0, sample_size_v2=0, ppl=18.12, wps=32.9, ups=0.03, wpb=1231.7, bsz=32, num_updates=21510, lr=2.19732e-05, gnorm=1.984, clip=100, loss_scale=256, train_wall=19, gb_free=15.2, wall=60964
2023-01-09 20:33:57 - progress_bar.py[line:272] - INFO: epoch 006:   3229 / 3665 loss=5.045, loss_v1=0, loss_v2=0, nll_loss=4.133, ntokens=1070.9, nsentences=32, sample_size=1070.9, sample_size_v1=0, sample_size_v2=0, ppl=17.55, wps=544.8, ups=0.51, wpb=1070.9, bsz=32, num_updates=21520, lr=2.19587e-05, gnorm=2.148, clip=100, loss_scale=256, train_wall=20, gb_free=15.3, wall=60984
2023-01-09 20:34:17 - progress_bar.py[line:272] - INFO: epoch 006:   3239 / 3665 loss=4.996, loss_v1=0, loss_v2=0, nll_loss=4.079, ntokens=790.7, nsentences=32, sample_size=790.7, sample_size_v1=0, sample_size_v2=0, ppl=16.9, wps=403.7, ups=0.51, wpb=790.7, bsz=32, num_updates=21530, lr=2.19442e-05, gnorm=2.79, clip=100, loss_scale=256, train_wall=20, gb_free=15.4, wall=61003
2023-01-09 20:34:37 - progress_bar.py[line:272] - INFO: epoch 006:   3249 / 3665 loss=4.929, loss_v1=0, loss_v2=0, nll_loss=4.002, ntokens=923.5, nsentences=32, sample_size=923.5, sample_size_v1=0, sample_size_v2=0, ppl=16.03, wps=467.9, ups=0.51, wpb=923.5, bsz=32, num_updates=21540, lr=2.19297e-05, gnorm=2.422, clip=100, loss_scale=256, train_wall=20, gb_free=15.3, wall=61023
2023-01-09 20:34:56 - progress_bar.py[line:272] - INFO: epoch 006:   3259 / 3665 loss=5.083, loss_v1=0, loss_v2=0, nll_loss=4.174, ntokens=1061.9, nsentences=32, sample_size=1061.9, sample_size_v1=0, sample_size_v2=0, ppl=18.05, wps=539.7, ups=0.51, wpb=1061.9, bsz=32, num_updates=21550, lr=2.19152e-05, gnorm=2.143, clip=100, loss_scale=256, train_wall=20, gb_free=15.3, wall=61043
2023-01-09 20:35:16 - progress_bar.py[line:272] - INFO: epoch 006:   3269 / 3665 loss=5.017, loss_v1=0, loss_v2=0, nll_loss=4.1, ntokens=816.6, nsentences=32, sample_size=816.6, sample_size_v1=0, sample_size_v2=0, ppl=17.15, wps=414.7, ups=0.51, wpb=816.6, bsz=32, num_updates=21560, lr=2.19007e-05, gnorm=2.785, clip=100, loss_scale=256, train_wall=20, gb_free=15.4, wall=61062
2023-01-09 20:35:36 - progress_bar.py[line:272] - INFO: epoch 006:   3279 / 3665 loss=5.084, loss_v1=0, loss_v2=0, nll_loss=4.176, ntokens=882.2, nsentences=32, sample_size=882.2, sample_size_v1=0, sample_size_v2=0, ppl=18.07, wps=447.7, ups=0.51, wpb=882.2, bsz=32, num_updates=21570, lr=2.18862e-05, gnorm=2.715, clip=100, loss_scale=256, train_wall=20, gb_free=15.3, wall=61082
2023-01-09 20:35:55 - progress_bar.py[line:272] - INFO: epoch 006:   3289 / 3665 loss=5.026, loss_v1=0, loss_v2=0, nll_loss=4.111, ntokens=1009.8, nsentences=32, sample_size=1009.8, sample_size_v1=0, sample_size_v2=0, ppl=17.28, wps=514, ups=0.51, wpb=1009.8, bsz=32, num_updates=21580, lr=2.18716e-05, gnorm=2.26, clip=100, loss_scale=256, train_wall=20, gb_free=15.2, wall=61102
2023-01-09 20:36:15 - progress_bar.py[line:272] - INFO: epoch 006:   3299 / 3665 loss=5.048, loss_v1=0, loss_v2=0, nll_loss=4.136, ntokens=808.4, nsentences=32, sample_size=808.4, sample_size_v1=0, sample_size_v2=0, ppl=17.58, wps=410.5, ups=0.51, wpb=808.4, bsz=32, num_updates=21590, lr=2.18571e-05, gnorm=2.49, clip=100, loss_scale=256, train_wall=20, gb_free=15.5, wall=61121
2023-01-09 20:36:35 - progress_bar.py[line:272] - INFO: epoch 006:   3309 / 3665 loss=4.952, loss_v1=0, loss_v2=0, nll_loss=4.03, ntokens=808, nsentences=32, sample_size=808, sample_size_v1=0, sample_size_v2=0, ppl=16.33, wps=412.6, ups=0.51, wpb=808, bsz=32, num_updates=21600, lr=2.18426e-05, gnorm=2.692, clip=100, loss_scale=256, train_wall=20, gb_free=15.4, wall=61141
2023-01-09 20:36:54 - progress_bar.py[line:272] - INFO: epoch 006:   3319 / 3665 loss=5.05, loss_v1=0, loss_v2=0, nll_loss=4.138, ntokens=1041, nsentences=32, sample_size=1041, sample_size_v1=0, sample_size_v2=0, ppl=17.6, wps=526.8, ups=0.51, wpb=1041, bsz=32, num_updates=21610, lr=2.18281e-05, gnorm=2.167, clip=100, loss_scale=256, train_wall=20, gb_free=15.7, wall=61161
2023-01-09 20:37:14 - progress_bar.py[line:272] - INFO: epoch 006:   3329 / 3665 loss=5.183, loss_v1=0, loss_v2=0, nll_loss=4.286, ntokens=938.5, nsentences=32, sample_size=938.5, sample_size_v1=0, sample_size_v2=0, ppl=19.51, wps=474.6, ups=0.51, wpb=938.5, bsz=32, num_updates=21620, lr=2.18136e-05, gnorm=2.367, clip=100, loss_scale=256, train_wall=20, gb_free=15.2, wall=61180
2023-01-09 20:37:34 - progress_bar.py[line:272] - INFO: epoch 006:   3339 / 3665 loss=5.034, loss_v1=0, loss_v2=0, nll_loss=4.12, ntokens=862, nsentences=32, sample_size=862, sample_size_v1=0, sample_size_v2=0, ppl=17.38, wps=434.4, ups=0.5, wpb=862, bsz=32, num_updates=21630, lr=2.17991e-05, gnorm=2.628, clip=100, loss_scale=256, train_wall=20, gb_free=15.6, wall=61200
2023-01-09 20:37:54 - progress_bar.py[line:272] - INFO: epoch 006:   3349 / 3665 loss=5.051, loss_v1=0, loss_v2=0, nll_loss=4.138, ntokens=1009, nsentences=32, sample_size=1009, sample_size_v1=0, sample_size_v2=0, ppl=17.61, wps=495.8, ups=0.49, wpb=1009, bsz=32, num_updates=21640, lr=2.17846e-05, gnorm=2.399, clip=100, loss_scale=256, train_wall=20, gb_free=15.6, wall=61221
2023-01-09 20:38:15 - progress_bar.py[line:272] - INFO: epoch 006:   3359 / 3665 loss=5.14, loss_v1=0, loss_v2=0, nll_loss=4.238, ntokens=1027, nsentences=32, sample_size=1027, sample_size_v1=0, sample_size_v2=0, ppl=18.86, wps=504.8, ups=0.49, wpb=1027, bsz=32, num_updates=21650, lr=2.17701e-05, gnorm=2.205, clip=100, loss_scale=256, train_wall=20, gb_free=15.1, wall=61241
2023-01-09 20:38:35 - progress_bar.py[line:272] - INFO: epoch 006:   3369 / 3665 loss=4.988, loss_v1=0, loss_v2=0, nll_loss=4.07, ntokens=773.4, nsentences=32, sample_size=773.4, sample_size_v1=0, sample_size_v2=0, ppl=16.79, wps=385.1, ups=0.5, wpb=773.4, bsz=32, num_updates=21660, lr=2.17555e-05, gnorm=2.755, clip=100, loss_scale=256, train_wall=20, gb_free=15.6, wall=61261
2023-01-09 20:38:55 - progress_bar.py[line:272] - INFO: epoch 006:   3379 / 3665 loss=5.013, loss_v1=0, loss_v2=0, nll_loss=4.096, ntokens=1022.8, nsentences=32, sample_size=1022.8, sample_size_v1=0, sample_size_v2=0, ppl=17.1, wps=513.6, ups=0.5, wpb=1022.8, bsz=32, num_updates=21670, lr=2.1741e-05, gnorm=2.245, clip=100, loss_scale=256, train_wall=20, gb_free=15.2, wall=61281
2023-01-09 20:39:14 - progress_bar.py[line:272] - INFO: epoch 006:   3389 / 3665 loss=5.064, loss_v1=0, loss_v2=0, nll_loss=4.153, ntokens=959.3, nsentences=32, sample_size=959.3, sample_size_v1=0, sample_size_v2=0, ppl=17.79, wps=487.2, ups=0.51, wpb=959.3, bsz=32, num_updates=21680, lr=2.17265e-05, gnorm=2.453, clip=100, loss_scale=256, train_wall=20, gb_free=15.1, wall=61301
2023-01-09 20:39:34 - progress_bar.py[line:272] - INFO: epoch 006:   3399 / 3665 loss=4.96, loss_v1=0, loss_v2=0, nll_loss=4.039, ntokens=793.9, nsentences=32, sample_size=793.9, sample_size_v1=0, sample_size_v2=0, ppl=16.44, wps=404.1, ups=0.51, wpb=793.9, bsz=32, num_updates=21690, lr=2.1712e-05, gnorm=2.778, clip=100, loss_scale=256, train_wall=20, gb_free=15.5, wall=61320
2023-01-09 20:39:54 - progress_bar.py[line:272] - INFO: epoch 006:   3409 / 3665 loss=4.988, loss_v1=0, loss_v2=0, nll_loss=4.07, ntokens=964.7, nsentences=32, sample_size=964.7, sample_size_v1=0, sample_size_v2=0, ppl=16.8, wps=488.9, ups=0.51, wpb=964.7, bsz=32, num_updates=21700, lr=2.16975e-05, gnorm=2.416, clip=100, loss_scale=256, train_wall=20, gb_free=15.3, wall=61340
2023-01-09 20:40:13 - progress_bar.py[line:272] - INFO: epoch 006:   3419 / 3665 loss=5.074, loss_v1=0, loss_v2=0, nll_loss=4.165, ntokens=1032.7, nsentences=32, sample_size=1032.7, sample_size_v1=0, sample_size_v2=0, ppl=17.93, wps=523.4, ups=0.51, wpb=1032.7, bsz=32, num_updates=21710, lr=2.1683e-05, gnorm=2.389, clip=100, loss_scale=256, train_wall=20, gb_free=15, wall=61360
2023-01-09 20:40:33 - progress_bar.py[line:272] - INFO: epoch 006:   3429 / 3665 loss=4.993, loss_v1=0, loss_v2=0, nll_loss=4.073, ntokens=766.3, nsentences=32, sample_size=766.3, sample_size_v1=0, sample_size_v2=0, ppl=16.83, wps=388.9, ups=0.51, wpb=766.3, bsz=32, num_updates=21720, lr=2.16685e-05, gnorm=3.053, clip=100, loss_scale=256, train_wall=20, gb_free=15.5, wall=61379
2023-01-09 20:40:53 - progress_bar.py[line:272] - INFO: epoch 006:   3439 / 3665 loss=5.043, loss_v1=0, loss_v2=0, nll_loss=4.131, ntokens=973.9, nsentences=32, sample_size=973.9, sample_size_v1=0, sample_size_v2=0, ppl=17.52, wps=494.2, ups=0.51, wpb=973.9, bsz=32, num_updates=21730, lr=2.16539e-05, gnorm=2.379, clip=100, loss_scale=256, train_wall=20, gb_free=15.5, wall=61399
2023-01-09 20:41:13 - progress_bar.py[line:272] - INFO: epoch 006:   3449 / 3665 loss=5.01, loss_v1=0, loss_v2=0, nll_loss=4.093, ntokens=1043.6, nsentences=32, sample_size=1043.6, sample_size_v1=0, sample_size_v2=0, ppl=17.07, wps=526.8, ups=0.5, wpb=1043.6, bsz=32, num_updates=21740, lr=2.16394e-05, gnorm=2.28, clip=100, loss_scale=256, train_wall=20, gb_free=15.6, wall=61419
2023-01-09 20:41:32 - progress_bar.py[line:272] - INFO: epoch 006:   3459 / 3665 loss=5.009, loss_v1=0, loss_v2=0, nll_loss=4.09, ntokens=723, nsentences=32, sample_size=723, sample_size_v1=0, sample_size_v2=0, ppl=17.03, wps=367.8, ups=0.51, wpb=723, bsz=32, num_updates=21750, lr=2.16249e-05, gnorm=2.928, clip=100, loss_scale=256, train_wall=20, gb_free=14.8, wall=61439
2023-01-09 20:41:52 - progress_bar.py[line:272] - INFO: epoch 006:   3469 / 3665 loss=4.875, loss_v1=0, loss_v2=0, nll_loss=3.943, ntokens=777.5, nsentences=32, sample_size=777.5, sample_size_v1=0, sample_size_v2=0, ppl=15.38, wps=391.5, ups=0.5, wpb=777.5, bsz=32, num_updates=21760, lr=2.16104e-05, gnorm=2.83, clip=100, loss_scale=256, train_wall=20, gb_free=15.5, wall=61458
2023-01-09 20:42:12 - progress_bar.py[line:272] - INFO: epoch 006:   3479 / 3665 loss=5.033, loss_v1=0, loss_v2=0, nll_loss=4.12, ntokens=993.2, nsentences=32, sample_size=993.2, sample_size_v1=0, sample_size_v2=0, ppl=17.39, wps=501.8, ups=0.51, wpb=993.2, bsz=32, num_updates=21770, lr=2.15959e-05, gnorm=2.46, clip=100, loss_scale=256, train_wall=20, gb_free=15.1, wall=61478
2023-01-09 20:42:33 - progress_bar.py[line:272] - INFO: epoch 006:   3489 / 3665 loss=5.085, loss_v1=0, loss_v2=0, nll_loss=4.175, ntokens=803.8, nsentences=32, sample_size=803.8, sample_size_v1=0, sample_size_v2=0, ppl=18.07, wps=390.5, ups=0.49, wpb=803.8, bsz=32, num_updates=21780, lr=2.15814e-05, gnorm=2.76, clip=100, loss_scale=256, train_wall=21, gb_free=15.5, wall=61499
2023-01-09 20:42:53 - progress_bar.py[line:272] - INFO: epoch 006:   3499 / 3665 loss=4.934, loss_v1=0, loss_v2=0, nll_loss=4.008, ntokens=712.3, nsentences=32, sample_size=712.3, sample_size_v1=0, sample_size_v2=0, ppl=16.09, wps=344.2, ups=0.48, wpb=712.3, bsz=32, num_updates=21790, lr=2.15669e-05, gnorm=2.847, clip=100, loss_scale=256, train_wall=21, gb_free=15.5, wall=61520
2023-01-09 20:43:13 - progress_bar.py[line:272] - INFO: epoch 006:   3509 / 3665 loss=4.985, loss_v1=0, loss_v2=0, nll_loss=4.068, ntokens=1000.5, nsentences=32, sample_size=1000.5, sample_size_v1=0, sample_size_v2=0, ppl=16.77, wps=501.9, ups=0.5, wpb=1000.5, bsz=32, num_updates=21800, lr=2.15523e-05, gnorm=2.237, clip=100, loss_scale=256, train_wall=20, gb_free=15.6, wall=61539
2023-01-09 20:43:33 - progress_bar.py[line:272] - INFO: epoch 006:   3519 / 3665 loss=5.114, loss_v1=0, loss_v2=0, nll_loss=4.209, ntokens=1035, nsentences=32, sample_size=1035, sample_size_v1=0, sample_size_v2=0, ppl=18.5, wps=528, ups=0.51, wpb=1035, bsz=32, num_updates=21810, lr=2.15378e-05, gnorm=2.351, clip=100, loss_scale=256, train_wall=20, gb_free=15.4, wall=61559
2023-01-09 20:43:52 - progress_bar.py[line:272] - INFO: epoch 006:   3529 / 3665 loss=4.978, loss_v1=0, loss_v2=0, nll_loss=4.057, ntokens=832.1, nsentences=32, sample_size=832.1, sample_size_v1=0, sample_size_v2=0, ppl=16.64, wps=423.9, ups=0.51, wpb=832.1, bsz=32, num_updates=21820, lr=2.15233e-05, gnorm=2.691, clip=100, loss_scale=256, train_wall=20, gb_free=15.4, wall=61579
2023-01-09 20:44:12 - progress_bar.py[line:272] - INFO: epoch 006:   3539 / 3665 loss=5.054, loss_v1=0, loss_v2=0, nll_loss=4.142, ntokens=1064.2, nsentences=32, sample_size=1064.2, sample_size_v1=0, sample_size_v2=0, ppl=17.65, wps=539.8, ups=0.51, wpb=1064.2, bsz=32, num_updates=21830, lr=2.15088e-05, gnorm=2.258, clip=100, loss_scale=256, train_wall=20, gb_free=15.4, wall=61598
2023-01-09 20:44:32 - progress_bar.py[line:272] - INFO: epoch 006:   3549 / 3665 loss=5.091, loss_v1=0, loss_v2=0, nll_loss=4.183, ntokens=1070.8, nsentences=32, sample_size=1070.8, sample_size_v1=0, sample_size_v2=0, ppl=18.17, wps=541, ups=0.51, wpb=1070.8, bsz=32, num_updates=21840, lr=2.14943e-05, gnorm=2.113, clip=100, loss_scale=256, train_wall=20, gb_free=15.4, wall=61618
2023-01-09 20:44:52 - progress_bar.py[line:272] - INFO: epoch 006:   3559 / 3665 loss=4.976, loss_v1=0, loss_v2=0, nll_loss=4.056, ntokens=829.3, nsentences=32, sample_size=829.3, sample_size_v1=0, sample_size_v2=0, ppl=16.64, wps=421.6, ups=0.51, wpb=829.3, bsz=32, num_updates=21850, lr=2.14798e-05, gnorm=2.734, clip=100, loss_scale=256, train_wall=20, gb_free=15.4, wall=61638
2023-01-09 20:45:11 - progress_bar.py[line:272] - INFO: epoch 006:   3569 / 3665 loss=4.975, loss_v1=0, loss_v2=0, nll_loss=4.055, ntokens=977.7, nsentences=32, sample_size=977.7, sample_size_v1=0, sample_size_v2=0, ppl=16.62, wps=492.6, ups=0.5, wpb=977.7, bsz=32, num_updates=21860, lr=2.14653e-05, gnorm=2.47, clip=100, loss_scale=256, train_wall=20, gb_free=15.2, wall=61658
2023-01-09 20:45:32 - progress_bar.py[line:272] - INFO: epoch 006:   3579 / 3665 loss=5.118, loss_v1=0, loss_v2=0, nll_loss=4.213, ntokens=1024.7, nsentences=32, sample_size=1024.7, sample_size_v1=0, sample_size_v2=0, ppl=18.54, wps=504.6, ups=0.49, wpb=1024.7, bsz=32, num_updates=21870, lr=2.14508e-05, gnorm=2.229, clip=100, loss_scale=256, train_wall=20, gb_free=15.3, wall=61678
2023-01-09 20:45:52 - progress_bar.py[line:272] - INFO: epoch 006:   3589 / 3665 loss=5.03, loss_v1=0, loss_v2=0, nll_loss=4.116, ntokens=831.5, nsentences=32, sample_size=831.5, sample_size_v1=0, sample_size_v2=0, ppl=17.33, wps=411.9, ups=0.5, wpb=831.5, bsz=32, num_updates=21880, lr=2.14362e-05, gnorm=2.673, clip=100, loss_scale=256, train_wall=20, gb_free=15.1, wall=61698
2023-01-09 20:46:12 - progress_bar.py[line:272] - INFO: epoch 006:   3599 / 3665 loss=4.94, loss_v1=0, loss_v2=0, nll_loss=4.017, ntokens=804, nsentences=32, sample_size=804, sample_size_v1=0, sample_size_v2=0, ppl=16.19, wps=398.8, ups=0.5, wpb=804, bsz=32, num_updates=21890, lr=2.14217e-05, gnorm=2.657, clip=100, loss_scale=256, train_wall=20, gb_free=15.5, wall=61718
2023-01-09 20:46:32 - progress_bar.py[line:272] - INFO: epoch 006:   3609 / 3665 loss=5.084, loss_v1=0, loss_v2=0, nll_loss=4.175, ntokens=1061.7, nsentences=32, sample_size=1061.7, sample_size_v1=0, sample_size_v2=0, ppl=18.07, wps=523.8, ups=0.49, wpb=1061.7, bsz=32, num_updates=21900, lr=2.14072e-05, gnorm=2.11, clip=100, loss_scale=512, train_wall=20, gb_free=15.3, wall=61739
2023-01-09 20:46:38 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 256.0
2023-01-09 20:46:54 - progress_bar.py[line:272] - INFO: epoch 006:   3620 / 3665 loss=5.001, loss_v1=0, loss_v2=0, nll_loss=4.084, ntokens=790.7, nsentences=32, sample_size=790.7, sample_size_v1=0, sample_size_v2=0, ppl=16.96, wps=363.1, ups=0.46, wpb=790.7, bsz=32, num_updates=21910, lr=2.13927e-05, gnorm=2.787, clip=100, loss_scale=256, train_wall=22, gb_free=15.6, wall=61760
2023-01-09 20:47:14 - progress_bar.py[line:272] - INFO: epoch 006:   3630 / 3665 loss=4.942, loss_v1=0, loss_v2=0, nll_loss=4.018, ntokens=971.8, nsentences=32, sample_size=971.8, sample_size_v1=0, sample_size_v2=0, ppl=16.2, wps=491.9, ups=0.51, wpb=971.8, bsz=32, num_updates=21920, lr=2.13782e-05, gnorm=2.378, clip=100, loss_scale=256, train_wall=20, gb_free=15.3, wall=61780
2023-01-09 20:47:34 - progress_bar.py[line:272] - INFO: epoch 006:   3640 / 3665 loss=5.055, loss_v1=0, loss_v2=0, nll_loss=4.144, ntokens=1152.1, nsentences=32, sample_size=1152.1, sample_size_v1=0, sample_size_v2=0, ppl=17.68, wps=581.4, ups=0.5, wpb=1152.1, bsz=32, num_updates=21930, lr=2.13637e-05, gnorm=2.017, clip=100, loss_scale=256, train_wall=20, gb_free=15.4, wall=61800
2023-01-09 20:47:53 - progress_bar.py[line:272] - INFO: epoch 006:   3650 / 3665 loss=4.954, loss_v1=0, loss_v2=0, nll_loss=4.03, ntokens=731.5, nsentences=32, sample_size=731.5, sample_size_v1=0, sample_size_v2=0, ppl=16.33, wps=372.9, ups=0.51, wpb=731.5, bsz=32, num_updates=21940, lr=2.13492e-05, gnorm=2.801, clip=100, loss_scale=256, train_wall=20, gb_free=15.7, wall=61820
2023-01-09 20:48:13 - progress_bar.py[line:272] - INFO: epoch 006:   3660 / 3665 loss=5.041, loss_v1=0, loss_v2=0, nll_loss=4.127, ntokens=978.1, nsentences=32, sample_size=978.1, sample_size_v1=0, sample_size_v2=0, ppl=17.47, wps=494.1, ups=0.51, wpb=978.1, bsz=32, num_updates=21950, lr=2.13346e-05, gnorm=2.527, clip=100, loss_scale=256, train_wall=20, gb_free=15.4, wall=61839
2023-01-09 20:48:22 - train.py[line:445] - INFO: begin validation on "valid" subset
slice_id 0 seek offset 0
slice_id 0 seek offset 0
2023-01-09 20:53:23 - progress_bar.py[line:282] - INFO: epoch 006 | valid on 'valid' subset | loss 5.027 | loss_v1 0 | loss_v2 0 | nll_loss 4.096 | ntokens 116.942 | nsentences 4 | sample_size 116.942 | sample_size_v1 0 | sample_size_v2 0 | AP 0 | total positives 21.7003 | TP 0 | FP 5.67367 | ppl 17.1 | wps 485.8 | wpb 116.9 | bsz 4 | num_updates 21955 | best_AP 0
2023-01-09 20:53:23 - checkpoint_utils.py[line:64] - INFO: Preparing to save checkpoint for epoch 6 @ 21955 updates
2023-01-09 20:53:23 - trainer.py[line:431] - INFO: Saving checkpoint to ../../checkpoints/OFA/detection_checkpoints/10_5e-5_512/checkpoint_best.pt
2023-01-09 20:53:44 - trainer.py[line:441] - INFO: Finished saving checkpoint to ../../checkpoints/OFA/detection_checkpoints/10_5e-5_512/checkpoint_best.pt
2023-01-09 20:54:12 - checkpoint_utils.py[line:133] - INFO: Saved checkpoint ../../checkpoints/OFA/detection_checkpoints/10_5e-5_512/checkpoint_best.pt (epoch 6 @ 21955 updates, score 0.0) (writing took 49.25194636406377 seconds)
2023-01-09 20:54:12 - train.py[line:332] - INFO: end of epoch 6 (average epoch stats below)
2023-01-09 20:54:12 - progress_bar.py[line:282] - INFO: epoch 006 | loss 5.055 | loss_v1 0 | loss_v2 0 | nll_loss 4.144 | ntokens 924.39 | nsentences 31.996 | sample_size 924.39 | sample_size_v1 0 | sample_size_v2 0 | AP 0 | ppl 17.68 | wps 330.6 | ups 0.36 | wpb 924.4 | bsz 32 | num_updates 21955 | lr 2.13274e-05 | gnorm 2.457 | clip 100 | loss_scale 256 | train_wall 7241 | gb_free 14.7 | wall 62198
2023-01-09 20:54:12 - trainer.py[line:639] - INFO: loading train data for epoch 7
local datafile ../../dataset/OFA_data/train.tsv slice_id 0 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../dataset/OFA_data/train.tsv slice_id 0 finished initializing row_count and line_idx-to-offset mapping
file ../../dataset/OFA_data/train.tsv slice_id 0 row count 117266 total row count 117266
slice_id 0 seek offset 0
2023-01-09 20:55:16 - trainer.py[line:703] - INFO: begin training epoch 7
2023-01-09 20:55:16 - train.py[line:305] - INFO: Start iterating over samples
2023-01-09 20:55:26 - progress_bar.py[line:272] - INFO: epoch 007:      5 / 3665 loss=5.101, loss_v1=0, loss_v2=0, nll_loss=4.194, ntokens=1009.7, nsentences=30.8, sample_size=1009.7, sample_size_v1=0, sample_size_v2=0, ppl=18.31, wps=23.3, ups=0.02, wpb=1009.7, bsz=30.8, num_updates=21960, lr=2.13201e-05, gnorm=2.391, clip=100, loss_scale=256, train_wall=19, gb_free=15.3, wall=62273
2023-01-09 20:55:46 - progress_bar.py[line:272] - INFO: epoch 007:     15 / 3665 loss=4.982, loss_v1=0, loss_v2=0, nll_loss=4.062, ntokens=777.1, nsentences=32, sample_size=777.1, sample_size_v1=0, sample_size_v2=0, ppl=16.71, wps=401.4, ups=0.52, wpb=777.1, bsz=32, num_updates=21970, lr=2.13056e-05, gnorm=2.723, clip=100, loss_scale=256, train_wall=19, gb_free=15.5, wall=62292
2023-01-09 20:56:05 - progress_bar.py[line:272] - INFO: epoch 007:     25 / 3665 loss=4.986, loss_v1=0, loss_v2=0, nll_loss=4.067, ntokens=1021.6, nsentences=32, sample_size=1021.6, sample_size_v1=0, sample_size_v2=0, ppl=16.76, wps=523.7, ups=0.51, wpb=1021.6, bsz=32, num_updates=21980, lr=2.12911e-05, gnorm=2.294, clip=100, loss_scale=256, train_wall=19, gb_free=15.1, wall=62311
2023-01-09 20:56:25 - progress_bar.py[line:272] - INFO: epoch 007:     35 / 3665 loss=5.042, loss_v1=0, loss_v2=0, nll_loss=4.129, ntokens=822.1, nsentences=32, sample_size=822.1, sample_size_v1=0, sample_size_v2=0, ppl=17.49, wps=421.4, ups=0.51, wpb=822.1, bsz=32, num_updates=21990, lr=2.12766e-05, gnorm=2.68, clip=100, loss_scale=256, train_wall=19, gb_free=15.7, wall=62331
2023-01-09 20:56:44 - progress_bar.py[line:272] - INFO: epoch 007:     45 / 3665 loss=5.011, loss_v1=0, loss_v2=0, nll_loss=4.094, ntokens=879.6, nsentences=32, sample_size=879.6, sample_size_v1=0, sample_size_v2=0, ppl=17.07, wps=447.5, ups=0.51, wpb=879.6, bsz=32, num_updates=22000, lr=2.12621e-05, gnorm=2.591, clip=100, loss_scale=256, train_wall=20, gb_free=15.3, wall=62351
2023-01-09 20:56:44 - train.py[line:445] - INFO: begin validation on "valid" subset
slice_id 0 seek offset 0
slice_id 0 seek offset 0
2023-01-09 21:01:38 - progress_bar.py[line:282] - INFO: epoch 007 | valid on 'valid' subset | loss 5.018 | loss_v1 0 | loss_v2 0 | nll_loss 4.085 | ntokens 116.71 | nsentences 4 | sample_size 116.71 | sample_size_v1 0 | sample_size_v2 0 | AP 0 | total positives 21.647 | TP 0 | FP 5.39176 | ppl 16.97 | wps 495.9 | wpb 116.7 | bsz 4 | num_updates 22000 | best_AP 0
2023-01-09 21:01:38 - checkpoint_utils.py[line:64] - INFO: Preparing to save checkpoint for epoch 7 @ 22000 updates
2023-01-09 21:01:38 - trainer.py[line:431] - INFO: Saving checkpoint to ../../checkpoints/OFA/detection_checkpoints/10_5e-5_512/checkpoint_7_22000.pt
2023-01-09 21:01:42 - trainer.py[line:441] - INFO: Finished saving checkpoint to ../../checkpoints/OFA/detection_checkpoints/10_5e-5_512/checkpoint_7_22000.pt
2023-01-09 21:02:48 - checkpoint_utils.py[line:133] - INFO: Saved checkpoint ../../checkpoints/OFA/detection_checkpoints/10_5e-5_512/checkpoint_7_22000.pt (epoch 7 @ 22000 updates, score 0.0) (writing took 69.930038258899 seconds)
2023-01-09 21:03:08 - progress_bar.py[line:272] - INFO: epoch 007:     55 / 3665 loss=4.981, loss_v1=0, loss_v2=0, nll_loss=4.061, ntokens=961.5, nsentences=32, sample_size=961.5, sample_size_v1=0, sample_size_v2=0, ppl=16.69, wps=25.1, ups=0.03, wpb=961.5, bsz=32, num_updates=22010, lr=2.12476e-05, gnorm=2.365, clip=100, loss_scale=256, train_wall=20, gb_free=15.7, wall=62734
2023-01-09 21:03:27 - progress_bar.py[line:272] - INFO: epoch 007:     65 / 3665 loss=5.091, loss_v1=0, loss_v2=0, nll_loss=4.183, ntokens=854.9, nsentences=32, sample_size=854.9, sample_size_v1=0, sample_size_v2=0, ppl=18.17, wps=439.8, ups=0.51, wpb=854.9, bsz=32, num_updates=22020, lr=2.12331e-05, gnorm=2.567, clip=100, loss_scale=256, train_wall=19, gb_free=15.5, wall=62754
2023-01-09 21:03:47 - progress_bar.py[line:272] - INFO: epoch 007:     75 / 3665 loss=4.987, loss_v1=0, loss_v2=0, nll_loss=4.069, ntokens=933.7, nsentences=32, sample_size=933.7, sample_size_v1=0, sample_size_v2=0, ppl=16.78, wps=475.5, ups=0.51, wpb=933.7, bsz=32, num_updates=22030, lr=2.12185e-05, gnorm=2.418, clip=100, loss_scale=256, train_wall=20, gb_free=15.6, wall=62773
2023-01-09 21:04:07 - progress_bar.py[line:272] - INFO: epoch 007:     85 / 3665 loss=5.069, loss_v1=0, loss_v2=0, nll_loss=4.159, ntokens=1011.5, nsentences=32, sample_size=1011.5, sample_size_v1=0, sample_size_v2=0, ppl=17.87, wps=514.1, ups=0.51, wpb=1011.5, bsz=32, num_updates=22040, lr=2.1204e-05, gnorm=2.541, clip=100, loss_scale=256, train_wall=20, gb_free=15, wall=62793
2023-01-09 21:04:26 - progress_bar.py[line:272] - INFO: epoch 007:     95 / 3665 loss=5.058, loss_v1=0, loss_v2=0, nll_loss=4.146, ntokens=782.1, nsentences=32, sample_size=782.1, sample_size_v1=0, sample_size_v2=0, ppl=17.7, wps=396.7, ups=0.51, wpb=782.1, bsz=32, num_updates=22050, lr=2.11895e-05, gnorm=2.945, clip=100, loss_scale=256, train_wall=20, gb_free=15.2, wall=62813
2023-01-09 21:04:46 - progress_bar.py[line:272] - INFO: epoch 007:    105 / 3665 loss=5.039, loss_v1=0, loss_v2=0, nll_loss=4.126, ntokens=997, nsentences=32, sample_size=997, sample_size_v1=0, sample_size_v2=0, ppl=17.46, wps=508.2, ups=0.51, wpb=997, bsz=32, num_updates=22060, lr=2.1175e-05, gnorm=2.599, clip=100, loss_scale=256, train_wall=20, gb_free=15.5, wall=62832
2023-01-09 21:05:06 - progress_bar.py[line:272] - INFO: epoch 007:    115 / 3665 loss=5.049, loss_v1=0, loss_v2=0, nll_loss=4.137, ntokens=1098.4, nsentences=32, sample_size=1098.4, sample_size_v1=0, sample_size_v2=0, ppl=17.59, wps=554.6, ups=0.5, wpb=1098.4, bsz=32, num_updates=22070, lr=2.11605e-05, gnorm=2.263, clip=100, loss_scale=256, train_wall=20, gb_free=15.4, wall=62852
2023-01-09 21:05:26 - progress_bar.py[line:272] - INFO: epoch 007:    125 / 3665 loss=5.008, loss_v1=0, loss_v2=0, nll_loss=4.089, ntokens=842.7, nsentences=32, sample_size=842.7, sample_size_v1=0, sample_size_v2=0, ppl=17.01, wps=426.8, ups=0.51, wpb=842.7, bsz=32, num_updates=22080, lr=2.1146e-05, gnorm=2.742, clip=100, loss_scale=256, train_wall=20, gb_free=15.5, wall=62872
2023-01-09 21:05:45 - progress_bar.py[line:272] - INFO: epoch 007:    135 / 3665 loss=5.009, loss_v1=0, loss_v2=0, nll_loss=4.093, ntokens=1002.1, nsentences=32, sample_size=1002.1, sample_size_v1=0, sample_size_v2=0, ppl=17.06, wps=510, ups=0.51, wpb=1002.1, bsz=32, num_updates=22090, lr=2.11315e-05, gnorm=2.376, clip=100, loss_scale=256, train_wall=20, gb_free=14.6, wall=62891
2023-01-09 21:06:05 - progress_bar.py[line:272] - INFO: epoch 007:    145 / 3665 loss=5.043, loss_v1=0, loss_v2=0, nll_loss=4.132, ntokens=975.6, nsentences=32, sample_size=975.6, sample_size_v1=0, sample_size_v2=0, ppl=17.54, wps=492.7, ups=0.51, wpb=975.6, bsz=32, num_updates=22100, lr=2.11169e-05, gnorm=2.363, clip=100, loss_scale=256, train_wall=20, gb_free=15.5, wall=62911
2023-01-09 21:06:25 - progress_bar.py[line:272] - INFO: epoch 007:    155 / 3665 loss=5.022, loss_v1=0, loss_v2=0, nll_loss=4.108, ntokens=833.5, nsentences=32, sample_size=833.5, sample_size_v1=0, sample_size_v2=0, ppl=17.24, wps=424.9, ups=0.51, wpb=833.5, bsz=32, num_updates=22110, lr=2.11024e-05, gnorm=2.741, clip=100, loss_scale=256, train_wall=20, gb_free=15.5, wall=62931
2023-01-09 21:06:45 - progress_bar.py[line:272] - INFO: epoch 007:    165 / 3665 loss=5.033, loss_v1=0, loss_v2=0, nll_loss=4.118, ntokens=1050.1, nsentences=32, sample_size=1050.1, sample_size_v1=0, sample_size_v2=0, ppl=17.37, wps=522.5, ups=0.5, wpb=1050.1, bsz=32, num_updates=22120, lr=2.10879e-05, gnorm=2.446, clip=100, loss_scale=256, train_wall=20, gb_free=15.5, wall=62951
2023-01-09 21:07:05 - progress_bar.py[line:272] - INFO: epoch 007:    175 / 3665 loss=4.983, loss_v1=0, loss_v2=0, nll_loss=4.063, ntokens=799.3, nsentences=32, sample_size=799.3, sample_size_v1=0, sample_size_v2=0, ppl=16.72, wps=402, ups=0.5, wpb=799.3, bsz=32, num_updates=22130, lr=2.10734e-05, gnorm=2.716, clip=100, loss_scale=256, train_wall=20, gb_free=15.5, wall=62971
2023-01-09 21:07:25 - progress_bar.py[line:272] - INFO: epoch 007:    185 / 3665 loss=4.966, loss_v1=0, loss_v2=0, nll_loss=4.043, ntokens=877.7, nsentences=32, sample_size=877.7, sample_size_v1=0, sample_size_v2=0, ppl=16.49, wps=438.5, ups=0.5, wpb=877.7, bsz=32, num_updates=22140, lr=2.10589e-05, gnorm=2.495, clip=100, loss_scale=256, train_wall=20, gb_free=15.4, wall=62991
2023-01-09 21:07:45 - progress_bar.py[line:272] - INFO: epoch 007:    195 / 3665 loss=5.026, loss_v1=0, loss_v2=0, nll_loss=4.113, ntokens=1055.1, nsentences=32, sample_size=1055.1, sample_size_v1=0, sample_size_v2=0, ppl=17.3, wps=524.1, ups=0.5, wpb=1055.1, bsz=32, num_updates=22150, lr=2.10444e-05, gnorm=2.24, clip=100, loss_scale=256, train_wall=20, gb_free=15.7, wall=63011
2023-01-09 21:08:05 - progress_bar.py[line:272] - INFO: epoch 007:    205 / 3665 loss=5.104, loss_v1=0, loss_v2=0, nll_loss=4.197, ntokens=807.6, nsentences=32, sample_size=807.6, sample_size_v1=0, sample_size_v2=0, ppl=18.34, wps=406.6, ups=0.5, wpb=807.6, bsz=32, num_updates=22160, lr=2.10299e-05, gnorm=2.767, clip=100, loss_scale=256, train_wall=20, gb_free=15.6, wall=63031
2023-01-09 21:08:25 - progress_bar.py[line:272] - INFO: epoch 007:    215 / 3665 loss=4.962, loss_v1=0, loss_v2=0, nll_loss=4.04, ntokens=858.5, nsentences=32, sample_size=858.5, sample_size_v1=0, sample_size_v2=0, ppl=16.45, wps=428.8, ups=0.5, wpb=858.5, bsz=32, num_updates=22170, lr=2.10154e-05, gnorm=2.719, clip=100, loss_scale=256, train_wall=20, gb_free=15.6, wall=63051
2023-01-09 21:08:45 - progress_bar.py[line:272] - INFO: epoch 007:    225 / 3665 loss=5.064, loss_v1=0, loss_v2=0, nll_loss=4.154, ntokens=1103.5, nsentences=32, sample_size=1103.5, sample_size_v1=0, sample_size_v2=0, ppl=17.8, wps=551.2, ups=0.5, wpb=1103.5, bsz=32, num_updates=22180, lr=2.10008e-05, gnorm=2.272, clip=100, loss_scale=256, train_wall=20, gb_free=14.9, wall=63071
2023-01-09 21:09:05 - progress_bar.py[line:272] - INFO: epoch 007:    235 / 3665 loss=5.016, loss_v1=0, loss_v2=0, nll_loss=4.099, ntokens=776, nsentences=32, sample_size=776, sample_size_v1=0, sample_size_v2=0, ppl=17.13, wps=389.9, ups=0.5, wpb=776, bsz=32, num_updates=22190, lr=2.09863e-05, gnorm=2.892, clip=100, loss_scale=256, train_wall=20, gb_free=15.5, wall=63091
2023-01-09 21:09:24 - progress_bar.py[line:272] - INFO: epoch 007:    245 / 3665 loss=4.947, loss_v1=0, loss_v2=0, nll_loss=4.023, ntokens=970.6, nsentences=32, sample_size=970.6, sample_size_v1=0, sample_size_v2=0, ppl=16.25, wps=488.6, ups=0.5, wpb=970.6, bsz=32, num_updates=22200, lr=2.09718e-05, gnorm=2.394, clip=100, loss_scale=256, train_wall=20, gb_free=15.3, wall=63111
2023-01-09 21:09:44 - progress_bar.py[line:272] - INFO: epoch 007:    255 / 3665 loss=5.137, loss_v1=0, loss_v2=0, nll_loss=4.235, ntokens=1033.4, nsentences=32, sample_size=1033.4, sample_size_v1=0, sample_size_v2=0, ppl=18.82, wps=518.2, ups=0.5, wpb=1033.4, bsz=32, num_updates=22210, lr=2.09573e-05, gnorm=2.3, clip=100, loss_scale=256, train_wall=20, gb_free=15, wall=63131
2023-01-09 21:10:04 - progress_bar.py[line:272] - INFO: epoch 007:    265 / 3665 loss=4.948, loss_v1=0, loss_v2=0, nll_loss=4.024, ntokens=721, nsentences=32, sample_size=721, sample_size_v1=0, sample_size_v2=0, ppl=16.27, wps=365.2, ups=0.51, wpb=721, bsz=32, num_updates=22220, lr=2.09428e-05, gnorm=3.166, clip=100, loss_scale=256, train_wall=20, gb_free=15.6, wall=63150
2023-01-09 21:10:24 - progress_bar.py[line:272] - INFO: epoch 007:    275 / 3665 loss=5.053, loss_v1=0, loss_v2=0, nll_loss=4.142, ntokens=1022.9, nsentences=32, sample_size=1022.9, sample_size_v1=0, sample_size_v2=0, ppl=17.65, wps=515.4, ups=0.5, wpb=1022.9, bsz=32, num_updates=22230, lr=2.09283e-05, gnorm=2.435, clip=100, loss_scale=256, train_wall=20, gb_free=15.5, wall=63170
2023-01-09 21:10:44 - progress_bar.py[line:272] - INFO: epoch 007:    285 / 3665 loss=4.979, loss_v1=0, loss_v2=0, nll_loss=4.059, ntokens=855.2, nsentences=32, sample_size=855.2, sample_size_v1=0, sample_size_v2=0, ppl=16.66, wps=431.8, ups=0.5, wpb=855.2, bsz=32, num_updates=22240, lr=2.09138e-05, gnorm=2.642, clip=100, loss_scale=256, train_wall=20, gb_free=15.6, wall=63190
2023-01-09 21:11:04 - progress_bar.py[line:272] - INFO: epoch 007:    295 / 3665 loss=4.969, loss_v1=0, loss_v2=0, nll_loss=4.049, ntokens=801.6, nsentences=32, sample_size=801.6, sample_size_v1=0, sample_size_v2=0, ppl=16.55, wps=405.2, ups=0.51, wpb=801.6, bsz=32, num_updates=22250, lr=2.08992e-05, gnorm=2.932, clip=100, loss_scale=256, train_wall=20, gb_free=15.3, wall=63210
2023-01-09 21:11:23 - progress_bar.py[line:272] - INFO: epoch 007:    305 / 3665 loss=4.968, loss_v1=0, loss_v2=0, nll_loss=4.046, ntokens=1040.7, nsentences=32, sample_size=1040.7, sample_size_v1=0, sample_size_v2=0, ppl=16.52, wps=523.5, ups=0.5, wpb=1040.7, bsz=32, num_updates=22260, lr=2.08847e-05, gnorm=2.176, clip=100, loss_scale=256, train_wall=20, gb_free=15.5, wall=63230
2023-01-09 21:11:43 - progress_bar.py[line:272] - INFO: epoch 007:    315 / 3665 loss=5.052, loss_v1=0, loss_v2=0, nll_loss=4.139, ntokens=913.4, nsentences=32, sample_size=913.4, sample_size_v1=0, sample_size_v2=0, ppl=17.62, wps=460.3, ups=0.5, wpb=913.4, bsz=32, num_updates=22270, lr=2.08702e-05, gnorm=2.711, clip=100, loss_scale=256, train_wall=20, gb_free=15.4, wall=63250
2023-01-09 21:12:03 - progress_bar.py[line:272] - INFO: epoch 007:    325 / 3665 loss=4.991, loss_v1=0, loss_v2=0, nll_loss=4.071, ntokens=853.6, nsentences=32, sample_size=853.6, sample_size_v1=0, sample_size_v2=0, ppl=16.81, wps=431.8, ups=0.51, wpb=853.6, bsz=32, num_updates=22280, lr=2.08557e-05, gnorm=2.855, clip=100, loss_scale=256, train_wall=20, gb_free=15.4, wall=63269
2023-01-09 21:12:23 - progress_bar.py[line:272] - INFO: epoch 007:    335 / 3665 loss=4.955, loss_v1=0, loss_v2=0, nll_loss=4.032, ntokens=969.9, nsentences=32, sample_size=969.9, sample_size_v1=0, sample_size_v2=0, ppl=16.36, wps=489, ups=0.5, wpb=969.9, bsz=32, num_updates=22290, lr=2.08412e-05, gnorm=2.41, clip=100, loss_scale=256, train_wall=20, gb_free=15.4, wall=63289
2023-01-09 21:12:43 - progress_bar.py[line:272] - INFO: epoch 007:    345 / 3665 loss=4.98, loss_v1=0, loss_v2=0, nll_loss=4.059, ntokens=725, nsentences=32, sample_size=725, sample_size_v1=0, sample_size_v2=0, ppl=16.67, wps=367, ups=0.51, wpb=725, bsz=32, num_updates=22300, lr=2.08267e-05, gnorm=2.826, clip=100, loss_scale=256, train_wall=20, gb_free=15.5, wall=63309
2023-01-09 21:13:02 - progress_bar.py[line:272] - INFO: epoch 007:    355 / 3665 loss=4.952, loss_v1=0, loss_v2=0, nll_loss=4.029, ntokens=896.1, nsentences=32, sample_size=896.1, sample_size_v1=0, sample_size_v2=0, ppl=16.33, wps=452.7, ups=0.51, wpb=896.1, bsz=32, num_updates=22310, lr=2.08122e-05, gnorm=2.569, clip=100, loss_scale=256, train_wall=20, gb_free=15.6, wall=63329
2023-01-09 21:13:22 - progress_bar.py[line:272] - INFO: epoch 007:    365 / 3665 loss=5.102, loss_v1=0, loss_v2=0, nll_loss=4.197, ntokens=1046.7, nsentences=32, sample_size=1046.7, sample_size_v1=0, sample_size_v2=0, ppl=18.34, wps=526.2, ups=0.5, wpb=1046.7, bsz=32, num_updates=22320, lr=2.07977e-05, gnorm=2.239, clip=100, loss_scale=256, train_wall=20, gb_free=15.4, wall=63349
2023-01-09 21:13:42 - progress_bar.py[line:272] - INFO: epoch 007:    375 / 3665 loss=4.969, loss_v1=0, loss_v2=0, nll_loss=4.047, ntokens=814, nsentences=32, sample_size=814, sample_size_v1=0, sample_size_v2=0, ppl=16.53, wps=411.2, ups=0.51, wpb=814, bsz=32, num_updates=22330, lr=2.07831e-05, gnorm=2.75, clip=100, loss_scale=256, train_wall=20, gb_free=15.5, wall=63368
2023-01-09 21:14:02 - progress_bar.py[line:272] - INFO: epoch 007:    385 / 3665 loss=4.954, loss_v1=0, loss_v2=0, nll_loss=4.031, ntokens=943.8, nsentences=32, sample_size=943.8, sample_size_v1=0, sample_size_v2=0, ppl=16.35, wps=476.4, ups=0.5, wpb=943.8, bsz=32, num_updates=22340, lr=2.07686e-05, gnorm=2.487, clip=100, loss_scale=256, train_wall=20, gb_free=15.6, wall=63388
2023-01-09 21:14:22 - progress_bar.py[line:272] - INFO: epoch 007:    395 / 3665 loss=4.944, loss_v1=0, loss_v2=0, nll_loss=4.02, ntokens=848.6, nsentences=32, sample_size=848.6, sample_size_v1=0, sample_size_v2=0, ppl=16.22, wps=428.9, ups=0.51, wpb=848.6, bsz=32, num_updates=22350, lr=2.07541e-05, gnorm=2.772, clip=100, loss_scale=256, train_wall=20, gb_free=15.7, wall=63408
2023-01-09 21:14:41 - progress_bar.py[line:272] - INFO: epoch 007:    405 / 3665 loss=4.933, loss_v1=0, loss_v2=0, nll_loss=4.009, ntokens=805.7, nsentences=32, sample_size=805.7, sample_size_v1=0, sample_size_v2=0, ppl=16.1, wps=407.1, ups=0.51, wpb=805.7, bsz=32, num_updates=22360, lr=2.07396e-05, gnorm=2.685, clip=100, loss_scale=256, train_wall=20, gb_free=15.3, wall=63428
2023-01-09 21:15:01 - progress_bar.py[line:272] - INFO: epoch 007:    415 / 3665 loss=4.959, loss_v1=0, loss_v2=0, nll_loss=4.036, ntokens=979.2, nsentences=32, sample_size=979.2, sample_size_v1=0, sample_size_v2=0, ppl=16.4, wps=492.5, ups=0.5, wpb=979.2, bsz=32, num_updates=22370, lr=2.07251e-05, gnorm=2.414, clip=100, loss_scale=256, train_wall=20, gb_free=15.6, wall=63448
2023-01-09 21:15:21 - progress_bar.py[line:272] - INFO: epoch 007:    425 / 3665 loss=5.07, loss_v1=0, loss_v2=0, nll_loss=4.159, ntokens=886.6, nsentences=32, sample_size=886.6, sample_size_v1=0, sample_size_v2=0, ppl=17.87, wps=447.4, ups=0.5, wpb=886.6, bsz=32, num_updates=22380, lr=2.07106e-05, gnorm=2.612, clip=100, loss_scale=256, train_wall=20, gb_free=15.4, wall=63467
2023-01-09 21:15:41 - progress_bar.py[line:272] - INFO: epoch 007:    435 / 3665 loss=5.038, loss_v1=0, loss_v2=0, nll_loss=4.125, ntokens=912.2, nsentences=32, sample_size=912.2, sample_size_v1=0, sample_size_v2=0, ppl=17.44, wps=459.2, ups=0.5, wpb=912.2, bsz=32, num_updates=22390, lr=2.06961e-05, gnorm=2.597, clip=100, loss_scale=256, train_wall=20, gb_free=15.3, wall=63487
2023-01-09 21:16:01 - progress_bar.py[line:272] - INFO: epoch 007:    445 / 3665 loss=5.02, loss_v1=0, loss_v2=0, nll_loss=4.106, ntokens=1075.7, nsentences=32, sample_size=1075.7, sample_size_v1=0, sample_size_v2=0, ppl=17.21, wps=540.5, ups=0.5, wpb=1075.7, bsz=32, num_updates=22400, lr=2.06815e-05, gnorm=2.76, clip=100, loss_scale=256, train_wall=20, gb_free=14.8, wall=63507
2023-01-09 21:16:21 - progress_bar.py[line:272] - INFO: epoch 007:    455 / 3665 loss=5.044, loss_v1=0, loss_v2=0, nll_loss=4.132, ntokens=840.9, nsentences=32, sample_size=840.9, sample_size_v1=0, sample_size_v2=0, ppl=17.53, wps=425.4, ups=0.51, wpb=840.9, bsz=32, num_updates=22410, lr=2.0667e-05, gnorm=2.714, clip=100, loss_scale=256, train_wall=20, gb_free=15.4, wall=63527
2023-01-09 21:16:41 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 256.0
2023-01-09 21:16:43 - progress_bar.py[line:272] - INFO: epoch 007:    466 / 3665 loss=4.987, loss_v1=0, loss_v2=0, nll_loss=4.067, ntokens=1001, nsentences=32, sample_size=1001, sample_size_v1=0, sample_size_v2=0, ppl=16.77, wps=458.6, ups=0.46, wpb=1001, bsz=32, num_updates=22420, lr=2.06525e-05, gnorm=2.293, clip=100, loss_scale=256, train_wall=22, gb_free=15.4, wall=63549
2023-01-09 21:17:02 - progress_bar.py[line:272] - INFO: epoch 007:    476 / 3665 loss=5.079, loss_v1=0, loss_v2=0, nll_loss=4.169, ntokens=1120.1, nsentences=32, sample_size=1120.1, sample_size_v1=0, sample_size_v2=0, ppl=17.99, wps=563.2, ups=0.5, wpb=1120.1, bsz=32, num_updates=22430, lr=2.0638e-05, gnorm=2.173, clip=100, loss_scale=256, train_wall=20, gb_free=15.3, wall=63569
2023-01-09 21:17:22 - progress_bar.py[line:272] - INFO: epoch 007:    486 / 3665 loss=5.009, loss_v1=0, loss_v2=0, nll_loss=4.092, ntokens=761.7, nsentences=32, sample_size=761.7, sample_size_v1=0, sample_size_v2=0, ppl=17.06, wps=385.2, ups=0.51, wpb=761.7, bsz=32, num_updates=22440, lr=2.06235e-05, gnorm=2.881, clip=100, loss_scale=256, train_wall=20, gb_free=15.4, wall=63588
2023-01-09 21:17:42 - progress_bar.py[line:272] - INFO: epoch 007:    496 / 3665 loss=4.954, loss_v1=0, loss_v2=0, nll_loss=4.03, ntokens=937.6, nsentences=32, sample_size=937.6, sample_size_v1=0, sample_size_v2=0, ppl=16.34, wps=473.1, ups=0.5, wpb=937.6, bsz=32, num_updates=22450, lr=2.0609e-05, gnorm=2.494, clip=100, loss_scale=256, train_wall=20, gb_free=15.7, wall=63608
2023-01-09 21:18:02 - progress_bar.py[line:272] - INFO: epoch 007:    506 / 3665 loss=5.104, loss_v1=0, loss_v2=0, nll_loss=4.199, ntokens=1052.8, nsentences=32, sample_size=1052.8, sample_size_v1=0, sample_size_v2=0, ppl=18.36, wps=529.2, ups=0.5, wpb=1052.8, bsz=32, num_updates=22460, lr=2.05945e-05, gnorm=2.549, clip=100, loss_scale=256, train_wall=20, gb_free=15.5, wall=63628
2023-01-09 21:18:22 - progress_bar.py[line:272] - INFO: epoch 007:    516 / 3665 loss=5.032, loss_v1=0, loss_v2=0, nll_loss=4.118, ntokens=887.2, nsentences=32, sample_size=887.2, sample_size_v1=0, sample_size_v2=0, ppl=17.36, wps=448.2, ups=0.51, wpb=887.2, bsz=32, num_updates=22470, lr=2.058e-05, gnorm=2.655, clip=100, loss_scale=256, train_wall=20, gb_free=15.5, wall=63648
2023-01-09 21:18:42 - progress_bar.py[line:272] - INFO: epoch 007:    526 / 3665 loss=5.002, loss_v1=0, loss_v2=0, nll_loss=4.084, ntokens=981.6, nsentences=32, sample_size=981.6, sample_size_v1=0, sample_size_v2=0, ppl=16.96, wps=494.9, ups=0.5, wpb=981.6, bsz=32, num_updates=22480, lr=2.05654e-05, gnorm=2.396, clip=100, loss_scale=256, train_wall=20, gb_free=15.4, wall=63668
2023-01-09 21:19:01 - progress_bar.py[line:272] - INFO: epoch 007:    536 / 3665 loss=5.02, loss_v1=0, loss_v2=0, nll_loss=4.105, ntokens=900.5, nsentences=32, sample_size=900.5, sample_size_v1=0, sample_size_v2=0, ppl=17.21, wps=454.3, ups=0.5, wpb=900.5, bsz=32, num_updates=22490, lr=2.05509e-05, gnorm=2.601, clip=100, loss_scale=256, train_wall=20, gb_free=15.3, wall=63688
2023-01-09 21:19:21 - progress_bar.py[line:272] - INFO: epoch 007:    546 / 3665 loss=5.064, loss_v1=0, loss_v2=0, nll_loss=4.152, ntokens=861.7, nsentences=32, sample_size=861.7, sample_size_v1=0, sample_size_v2=0, ppl=17.77, wps=434.5, ups=0.5, wpb=861.7, bsz=32, num_updates=22500, lr=2.05364e-05, gnorm=2.85, clip=100, loss_scale=256, train_wall=20, gb_free=15.4, wall=63707
2023-01-09 21:19:21 - train.py[line:445] - INFO: begin validation on "valid" subset
slice_id 0 seek offset 0
slice_id 0 seek offset 0
2023-01-09 21:24:02 - progress_bar.py[line:282] - INFO: epoch 007 | valid on 'valid' subset | loss 5.011 | loss_v1 0 | loss_v2 0 | nll_loss 4.076 | ntokens 117.202 | nsentences 4 | sample_size 117.202 | sample_size_v1 0 | sample_size_v2 0 | AP 0 | total positives 21.7447 | TP 0 | FP 5.07593 | ppl 16.87 | wps 521.4 | wpb 117.2 | bsz 4 | num_updates 22500 | best_AP 0
2023-01-09 21:24:02 - checkpoint_utils.py[line:64] - INFO: Preparing to save checkpoint for epoch 7 @ 22500 updates
2023-01-09 21:24:02 - trainer.py[line:431] - INFO: Saving checkpoint to ../../checkpoints/OFA/detection_checkpoints/10_5e-5_512/checkpoint_7_22500.pt
2023-01-09 21:24:05 - trainer.py[line:441] - INFO: Finished saving checkpoint to ../../checkpoints/OFA/detection_checkpoints/10_5e-5_512/checkpoint_7_22500.pt
2023-01-09 21:25:12 - checkpoint_utils.py[line:133] - INFO: Saved checkpoint ../../checkpoints/OFA/detection_checkpoints/10_5e-5_512/checkpoint_7_22500.pt (epoch 7 @ 22500 updates, score 0.0) (writing took 70.0240334016271 seconds)
2023-01-09 21:25:32 - progress_bar.py[line:272] - INFO: epoch 007:    556 / 3665 loss=4.945, loss_v1=0, loss_v2=0, nll_loss=4.021, ntokens=968, nsentences=32, sample_size=968, sample_size_v1=0, sample_size_v2=0, ppl=16.23, wps=26.1, ups=0.03, wpb=968, bsz=32, num_updates=22510, lr=2.05219e-05, gnorm=2.476, clip=100, loss_scale=256, train_wall=19, gb_free=15, wall=64078
2023-01-09 21:25:51 - progress_bar.py[line:272] - INFO: epoch 007:    566 / 3665 loss=5.016, loss_v1=0, loss_v2=0, nll_loss=4.102, ntokens=811.7, nsentences=32, sample_size=811.7, sample_size_v1=0, sample_size_v2=0, ppl=17.17, wps=415.7, ups=0.51, wpb=811.7, bsz=32, num_updates=22520, lr=2.05074e-05, gnorm=2.852, clip=100, loss_scale=256, train_wall=20, gb_free=15.7, wall=64097
2023-01-09 21:26:11 - progress_bar.py[line:272] - INFO: epoch 007:    576 / 3665 loss=4.954, loss_v1=0, loss_v2=0, nll_loss=4.031, ntokens=958.3, nsentences=32, sample_size=958.3, sample_size_v1=0, sample_size_v2=0, ppl=16.35, wps=490.2, ups=0.51, wpb=958.3, bsz=32, num_updates=22530, lr=2.04929e-05, gnorm=2.47, clip=100, loss_scale=256, train_wall=20, gb_free=15.6, wall=64117
2023-01-09 21:26:30 - progress_bar.py[line:272] - INFO: epoch 007:    586 / 3665 loss=5.083, loss_v1=0, loss_v2=0, nll_loss=4.175, ntokens=1067, nsentences=32, sample_size=1067, sample_size_v1=0, sample_size_v2=0, ppl=18.06, wps=540, ups=0.51, wpb=1067, bsz=32, num_updates=22540, lr=2.04784e-05, gnorm=2.392, clip=100, loss_scale=256, train_wall=20, gb_free=15.4, wall=64137
2023-01-09 21:26:50 - progress_bar.py[line:272] - INFO: epoch 007:    596 / 3665 loss=5, loss_v1=0, loss_v2=0, nll_loss=4.082, ntokens=757.7, nsentences=32, sample_size=757.7, sample_size_v1=0, sample_size_v2=0, ppl=16.94, wps=386.7, ups=0.51, wpb=757.7, bsz=32, num_updates=22550, lr=2.04638e-05, gnorm=3.08, clip=100, loss_scale=256, train_wall=20, gb_free=15.1, wall=64156
2023-01-09 21:27:10 - progress_bar.py[line:272] - INFO: epoch 007:    606 / 3665 loss=4.968, loss_v1=0, loss_v2=0, nll_loss=4.046, ntokens=951, nsentences=32, sample_size=951, sample_size_v1=0, sample_size_v2=0, ppl=16.52, wps=483.1, ups=0.51, wpb=951, bsz=32, num_updates=22560, lr=2.04493e-05, gnorm=2.474, clip=100, loss_scale=256, train_wall=20, gb_free=15.4, wall=64176
2023-01-09 21:27:29 - progress_bar.py[line:272] - INFO: epoch 007:    616 / 3665 loss=5.105, loss_v1=0, loss_v2=0, nll_loss=4.198, ntokens=1098.4, nsentences=32, sample_size=1098.4, sample_size_v1=0, sample_size_v2=0, ppl=18.35, wps=555.8, ups=0.51, wpb=1098.4, bsz=32, num_updates=22570, lr=2.04348e-05, gnorm=2.213, clip=100, loss_scale=256, train_wall=20, gb_free=15.3, wall=64196
2023-01-09 21:27:49 - progress_bar.py[line:272] - INFO: epoch 007:    626 / 3665 loss=4.958, loss_v1=0, loss_v2=0, nll_loss=4.036, ntokens=748.3, nsentences=32, sample_size=748.3, sample_size_v1=0, sample_size_v2=0, ppl=16.4, wps=382.1, ups=0.51, wpb=748.3, bsz=32, num_updates=22580, lr=2.04203e-05, gnorm=2.861, clip=100, loss_scale=256, train_wall=20, gb_free=15.5, wall=64215
2023-01-09 21:28:09 - progress_bar.py[line:272] - INFO: epoch 007:    636 / 3665 loss=5.004, loss_v1=0, loss_v2=0, nll_loss=4.087, ntokens=1044.4, nsentences=32, sample_size=1044.4, sample_size_v1=0, sample_size_v2=0, ppl=16.99, wps=528.2, ups=0.51, wpb=1044.4, bsz=32, num_updates=22590, lr=2.04058e-05, gnorm=2.415, clip=100, loss_scale=256, train_wall=20, gb_free=15.4, wall=64235
2023-01-09 21:28:28 - progress_bar.py[line:272] - INFO: epoch 007:    646 / 3665 loss=5.124, loss_v1=0, loss_v2=0, nll_loss=4.219, ntokens=1013.6, nsentences=32, sample_size=1013.6, sample_size_v1=0, sample_size_v2=0, ppl=18.63, wps=513.5, ups=0.51, wpb=1013.6, bsz=32, num_updates=22600, lr=2.03913e-05, gnorm=2.457, clip=100, loss_scale=256, train_wall=20, gb_free=15.3, wall=64255
2023-01-09 21:28:48 - progress_bar.py[line:272] - INFO: epoch 007:    656 / 3665 loss=4.927, loss_v1=0, loss_v2=0, nll_loss=4, ntokens=720.3, nsentences=32, sample_size=720.3, sample_size_v1=0, sample_size_v2=0, ppl=16, wps=365.8, ups=0.51, wpb=720.3, bsz=32, num_updates=22610, lr=2.03768e-05, gnorm=3.145, clip=100, loss_scale=256, train_wall=20, gb_free=15.4, wall=64274
2023-01-09 21:29:08 - progress_bar.py[line:272] - INFO: epoch 007:    666 / 3665 loss=5.017, loss_v1=0, loss_v2=0, nll_loss=4.101, ntokens=1005.7, nsentences=32, sample_size=1005.7, sample_size_v1=0, sample_size_v2=0, ppl=17.16, wps=505, ups=0.5, wpb=1005.7, bsz=32, num_updates=22620, lr=2.03623e-05, gnorm=2.419, clip=100, loss_scale=256, train_wall=20, gb_free=15, wall=64294
2023-01-09 21:29:28 - progress_bar.py[line:272] - INFO: epoch 007:    676 / 3665 loss=5.048, loss_v1=0, loss_v2=0, nll_loss=4.136, ntokens=840.2, nsentences=32, sample_size=840.2, sample_size_v1=0, sample_size_v2=0, ppl=17.58, wps=425.4, ups=0.51, wpb=840.2, bsz=32, num_updates=22630, lr=2.03477e-05, gnorm=2.86, clip=100, loss_scale=256, train_wall=20, gb_free=15.4, wall=64314
2023-01-09 21:29:48 - progress_bar.py[line:272] - INFO: epoch 007:    686 / 3665 loss=4.955, loss_v1=0, loss_v2=0, nll_loss=4.033, ntokens=939.8, nsentences=32, sample_size=939.8, sample_size_v1=0, sample_size_v2=0, ppl=16.37, wps=466.1, ups=0.5, wpb=939.8, bsz=32, num_updates=22640, lr=2.03332e-05, gnorm=2.637, clip=100, loss_scale=256, train_wall=20, gb_free=15.5, wall=64334
2023-01-09 21:30:08 - progress_bar.py[line:272] - INFO: epoch 007:    696 / 3665 loss=5.046, loss_v1=0, loss_v2=0, nll_loss=4.134, ntokens=980.1, nsentences=32, sample_size=980.1, sample_size_v1=0, sample_size_v2=0, ppl=17.56, wps=479.9, ups=0.49, wpb=980.1, bsz=32, num_updates=22650, lr=2.03187e-05, gnorm=2.533, clip=100, loss_scale=256, train_wall=20, gb_free=15.3, wall=64355
2023-01-09 21:30:29 - progress_bar.py[line:272] - INFO: epoch 007:    706 / 3665 loss=5.038, loss_v1=0, loss_v2=0, nll_loss=4.125, ntokens=844, nsentences=32, sample_size=844, sample_size_v1=0, sample_size_v2=0, ppl=17.44, wps=414, ups=0.49, wpb=844, bsz=32, num_updates=22660, lr=2.03042e-05, gnorm=2.68, clip=100, loss_scale=256, train_wall=20, gb_free=15.5, wall=64375
2023-01-09 21:30:49 - progress_bar.py[line:272] - INFO: epoch 007:    716 / 3665 loss=5.034, loss_v1=0, loss_v2=0, nll_loss=4.12, ntokens=924.5, nsentences=32, sample_size=924.5, sample_size_v1=0, sample_size_v2=0, ppl=17.38, wps=459.6, ups=0.5, wpb=924.5, bsz=32, num_updates=22670, lr=2.02897e-05, gnorm=2.657, clip=100, loss_scale=256, train_wall=20, gb_free=15.6, wall=64395
2023-01-09 21:31:09 - progress_bar.py[line:272] - INFO: epoch 007:    726 / 3665 loss=5.126, loss_v1=0, loss_v2=0, nll_loss=4.221, ntokens=1047.6, nsentences=32, sample_size=1047.6, sample_size_v1=0, sample_size_v2=0, ppl=18.65, wps=529, ups=0.5, wpb=1047.6, bsz=32, num_updates=22680, lr=2.02752e-05, gnorm=2.467, clip=100, loss_scale=256, train_wall=20, gb_free=15.5, wall=64415
2023-01-09 21:31:28 - progress_bar.py[line:272] - INFO: epoch 007:    736 / 3665 loss=4.972, loss_v1=0, loss_v2=0, nll_loss=4.049, ntokens=764, nsentences=32, sample_size=764, sample_size_v1=0, sample_size_v2=0, ppl=16.56, wps=387.9, ups=0.51, wpb=764, bsz=32, num_updates=22690, lr=2.02607e-05, gnorm=2.975, clip=100, loss_scale=256, train_wall=20, gb_free=15.5, wall=64435
2023-01-09 21:31:48 - progress_bar.py[line:272] - INFO: epoch 007:    746 / 3665 loss=4.991, loss_v1=0, loss_v2=0, nll_loss=4.072, ntokens=907.5, nsentences=32, sample_size=907.5, sample_size_v1=0, sample_size_v2=0, ppl=16.82, wps=461.6, ups=0.51, wpb=907.5, bsz=32, num_updates=22700, lr=2.02461e-05, gnorm=2.551, clip=100, loss_scale=256, train_wall=20, gb_free=15.4, wall=64454
2023-01-09 21:32:08 - progress_bar.py[line:272] - INFO: epoch 007:    756 / 3665 loss=5.08, loss_v1=0, loss_v2=0, nll_loss=4.171, ntokens=1055.2, nsentences=32, sample_size=1055.2, sample_size_v1=0, sample_size_v2=0, ppl=18.01, wps=532.9, ups=0.51, wpb=1055.2, bsz=32, num_updates=22710, lr=2.02316e-05, gnorm=2.262, clip=100, loss_scale=256, train_wall=20, gb_free=15, wall=64474
2023-01-09 21:32:28 - progress_bar.py[line:272] - INFO: epoch 007:    766 / 3665 loss=4.949, loss_v1=0, loss_v2=0, nll_loss=4.027, ntokens=779.9, nsentences=32, sample_size=779.9, sample_size_v1=0, sample_size_v2=0, ppl=16.3, wps=395.2, ups=0.51, wpb=779.9, bsz=32, num_updates=22720, lr=2.02171e-05, gnorm=3.04, clip=100, loss_scale=256, train_wall=20, gb_free=15.3, wall=64494
2023-01-09 21:32:47 - progress_bar.py[line:272] - INFO: epoch 007:    776 / 3665 loss=5.009, loss_v1=0, loss_v2=0, nll_loss=4.091, ntokens=1011.3, nsentences=32, sample_size=1011.3, sample_size_v1=0, sample_size_v2=0, ppl=17.04, wps=512.2, ups=0.51, wpb=1011.3, bsz=32, num_updates=22730, lr=2.02026e-05, gnorm=2.33, clip=100, loss_scale=256, train_wall=20, gb_free=15.1, wall=64514
2023-01-09 21:33:07 - progress_bar.py[line:272] - INFO: epoch 007:    786 / 3665 loss=5.004, loss_v1=0, loss_v2=0, nll_loss=4.087, ntokens=827.1, nsentences=32, sample_size=827.1, sample_size_v1=0, sample_size_v2=0, ppl=17, wps=418.5, ups=0.51, wpb=827.1, bsz=32, num_updates=22740, lr=2.01881e-05, gnorm=2.811, clip=100, loss_scale=256, train_wall=20, gb_free=15.5, wall=64533
2023-01-09 21:33:27 - progress_bar.py[line:272] - INFO: epoch 007:    796 / 3665 loss=4.993, loss_v1=0, loss_v2=0, nll_loss=4.073, ntokens=977, nsentences=32, sample_size=977, sample_size_v1=0, sample_size_v2=0, ppl=16.83, wps=493.4, ups=0.5, wpb=977, bsz=32, num_updates=22750, lr=2.01736e-05, gnorm=2.697, clip=100, loss_scale=256, train_wall=20, gb_free=15.1, wall=64553
2023-01-09 21:33:47 - progress_bar.py[line:272] - INFO: epoch 007:    806 / 3665 loss=5.069, loss_v1=0, loss_v2=0, nll_loss=4.158, ntokens=1069.9, nsentences=32, sample_size=1069.9, sample_size_v1=0, sample_size_v2=0, ppl=17.86, wps=534.3, ups=0.5, wpb=1069.9, bsz=32, num_updates=22760, lr=2.01591e-05, gnorm=2.391, clip=100, loss_scale=256, train_wall=20, gb_free=15.1, wall=64573
2023-01-09 21:34:07 - progress_bar.py[line:272] - INFO: epoch 007:    816 / 3665 loss=4.891, loss_v1=0, loss_v2=0, nll_loss=3.962, ntokens=693.8, nsentences=32, sample_size=693.8, sample_size_v1=0, sample_size_v2=0, ppl=15.58, wps=349.3, ups=0.5, wpb=693.8, bsz=32, num_updates=22770, lr=2.01446e-05, gnorm=3.264, clip=100, loss_scale=256, train_wall=20, gb_free=15.6, wall=64593
2023-01-09 21:34:27 - progress_bar.py[line:272] - INFO: epoch 007:    826 / 3665 loss=4.972, loss_v1=0, loss_v2=0, nll_loss=4.051, ntokens=864.7, nsentences=32, sample_size=864.7, sample_size_v1=0, sample_size_v2=0, ppl=16.58, wps=434.8, ups=0.5, wpb=864.7, bsz=32, num_updates=22780, lr=2.013e-05, gnorm=2.636, clip=100, loss_scale=256, train_wall=20, gb_free=15.5, wall=64613
2023-01-09 21:34:47 - progress_bar.py[line:272] - INFO: epoch 007:    836 / 3665 loss=5.046, loss_v1=0, loss_v2=0, nll_loss=4.133, ntokens=1012.8, nsentences=32, sample_size=1012.8, sample_size_v1=0, sample_size_v2=0, ppl=17.54, wps=506.3, ups=0.5, wpb=1012.8, bsz=32, num_updates=22790, lr=2.01155e-05, gnorm=2.453, clip=100, loss_scale=256, train_wall=20, gb_free=15.3, wall=64633
2023-01-09 21:35:07 - progress_bar.py[line:272] - INFO: epoch 007:    846 / 3665 loss=4.95, loss_v1=0, loss_v2=0, nll_loss=4.027, ntokens=723.2, nsentences=32, sample_size=723.2, sample_size_v1=0, sample_size_v2=0, ppl=16.3, wps=364.7, ups=0.5, wpb=723.2, bsz=32, num_updates=22800, lr=2.0101e-05, gnorm=3.322, clip=100, loss_scale=256, train_wall=20, gb_free=15.4, wall=64653
2023-01-09 21:35:27 - progress_bar.py[line:272] - INFO: epoch 007:    856 / 3665 loss=4.945, loss_v1=0, loss_v2=0, nll_loss=4.022, ntokens=905, nsentences=32, sample_size=905, sample_size_v1=0, sample_size_v2=0, ppl=16.24, wps=453, ups=0.5, wpb=905, bsz=32, num_updates=22810, lr=2.00865e-05, gnorm=2.845, clip=100, loss_scale=256, train_wall=20, gb_free=15.4, wall=64673
2023-01-09 21:35:47 - progress_bar.py[line:272] - INFO: epoch 007:    866 / 3665 loss=5.076, loss_v1=0, loss_v2=0, nll_loss=4.168, ntokens=1152.5, nsentences=32, sample_size=1152.5, sample_size_v1=0, sample_size_v2=0, ppl=17.97, wps=572.9, ups=0.5, wpb=1152.5, bsz=32, num_updates=22820, lr=2.0072e-05, gnorm=2.278, clip=100, loss_scale=256, train_wall=20, gb_free=15.6, wall=64693
2023-01-09 21:36:07 - progress_bar.py[line:272] - INFO: epoch 007:    876 / 3665 loss=4.95, loss_v1=0, loss_v2=0, nll_loss=4.027, ntokens=808.2, nsentences=32, sample_size=808.2, sample_size_v1=0, sample_size_v2=0, ppl=16.31, wps=407.2, ups=0.5, wpb=808.2, bsz=32, num_updates=22830, lr=2.00575e-05, gnorm=2.892, clip=100, loss_scale=256, train_wall=20, gb_free=15.5, wall=64713
2023-01-09 21:36:26 - progress_bar.py[line:272] - INFO: epoch 007:    886 / 3665 loss=4.871, loss_v1=0, loss_v2=0, nll_loss=3.939, ntokens=924.6, nsentences=32, sample_size=924.6, sample_size_v1=0, sample_size_v2=0, ppl=15.33, wps=462.9, ups=0.5, wpb=924.6, bsz=32, num_updates=22840, lr=2.0043e-05, gnorm=2.477, clip=100, loss_scale=256, train_wall=20, gb_free=15.3, wall=64733
2023-01-09 21:36:46 - progress_bar.py[line:272] - INFO: epoch 007:    896 / 3665 loss=5.118, loss_v1=0, loss_v2=0, nll_loss=4.213, ntokens=1025.1, nsentences=31.8, sample_size=1025.1, sample_size_v1=0, sample_size_v2=0, ppl=18.55, wps=514.3, ups=0.5, wpb=1025.1, bsz=31.8, num_updates=22850, lr=2.00284e-05, gnorm=2.487, clip=100, loss_scale=256, train_wall=20, gb_free=15.2, wall=64753
2023-01-09 21:37:06 - progress_bar.py[line:272] - INFO: epoch 007:    906 / 3665 loss=5.014, loss_v1=0, loss_v2=0, nll_loss=4.097, ntokens=928.5, nsentences=32, sample_size=928.5, sample_size_v1=0, sample_size_v2=0, ppl=17.11, wps=466, ups=0.5, wpb=928.5, bsz=32, num_updates=22860, lr=2.00139e-05, gnorm=2.584, clip=100, loss_scale=256, train_wall=20, gb_free=15.2, wall=64773
2023-01-09 21:37:26 - progress_bar.py[line:272] - INFO: epoch 007:    916 / 3665 loss=4.945, loss_v1=0, loss_v2=0, nll_loss=4.021, ntokens=968.4, nsentences=32, sample_size=968.4, sample_size_v1=0, sample_size_v2=0, ppl=16.23, wps=485.2, ups=0.5, wpb=968.4, bsz=32, num_updates=22870, lr=1.99994e-05, gnorm=2.358, clip=100, loss_scale=256, train_wall=20, gb_free=15.4, wall=64793
2023-01-09 21:37:46 - progress_bar.py[line:272] - INFO: epoch 007:    926 / 3665 loss=5.094, loss_v1=0, loss_v2=0, nll_loss=4.187, ntokens=994.2, nsentences=32, sample_size=994.2, sample_size_v1=0, sample_size_v2=0, ppl=18.21, wps=497.1, ups=0.5, wpb=994.2, bsz=32, num_updates=22880, lr=1.99849e-05, gnorm=2.426, clip=100, loss_scale=256, train_wall=20, gb_free=15.3, wall=64813
2023-01-09 21:38:06 - progress_bar.py[line:272] - INFO: epoch 007:    936 / 3665 loss=4.993, loss_v1=0, loss_v2=0, nll_loss=4.077, ntokens=867.1, nsentences=32, sample_size=867.1, sample_size_v1=0, sample_size_v2=0, ppl=16.87, wps=435.4, ups=0.5, wpb=867.1, bsz=32, num_updates=22890, lr=1.99704e-05, gnorm=2.606, clip=100, loss_scale=256, train_wall=20, gb_free=15.7, wall=64832
2023-01-09 21:38:26 - progress_bar.py[line:272] - INFO: epoch 007:    946 / 3665 loss=4.995, loss_v1=0, loss_v2=0, nll_loss=4.078, ntokens=1017, nsentences=32, sample_size=1017, sample_size_v1=0, sample_size_v2=0, ppl=16.88, wps=507.8, ups=0.5, wpb=1017, bsz=32, num_updates=22900, lr=1.99559e-05, gnorm=2.394, clip=100, loss_scale=256, train_wall=20, gb_free=15.3, wall=64853
2023-01-09 21:38:46 - progress_bar.py[line:272] - INFO: epoch 007:    956 / 3665 loss=4.941, loss_v1=0, loss_v2=0, nll_loss=4.016, ntokens=734.8, nsentences=32, sample_size=734.8, sample_size_v1=0, sample_size_v2=0, ppl=16.18, wps=370.9, ups=0.5, wpb=734.8, bsz=32, num_updates=22910, lr=1.99414e-05, gnorm=2.988, clip=100, loss_scale=256, train_wall=20, gb_free=15.3, wall=64872
2023-01-09 21:39:06 - progress_bar.py[line:272] - INFO: epoch 007:    966 / 3665 loss=4.959, loss_v1=0, loss_v2=0, nll_loss=4.038, ntokens=911.9, nsentences=32, sample_size=911.9, sample_size_v1=0, sample_size_v2=0, ppl=16.42, wps=457.1, ups=0.5, wpb=911.9, bsz=32, num_updates=22920, lr=1.99269e-05, gnorm=2.695, clip=100, loss_scale=256, train_wall=20, gb_free=15.4, wall=64892
2023-01-09 21:39:26 - progress_bar.py[line:272] - INFO: epoch 007:    976 / 3665 loss=5.069, loss_v1=0, loss_v2=0, nll_loss=4.159, ntokens=940.5, nsentences=32, sample_size=940.5, sample_size_v1=0, sample_size_v2=0, ppl=17.86, wps=471.8, ups=0.5, wpb=940.5, bsz=32, num_updates=22930, lr=1.99123e-05, gnorm=2.596, clip=100, loss_scale=256, train_wall=20, gb_free=15.5, wall=64912
2023-01-09 21:39:46 - progress_bar.py[line:272] - INFO: epoch 007:    986 / 3665 loss=4.987, loss_v1=0, loss_v2=0, nll_loss=4.067, ntokens=852.5, nsentences=32, sample_size=852.5, sample_size_v1=0, sample_size_v2=0, ppl=16.76, wps=428, ups=0.5, wpb=852.5, bsz=32, num_updates=22940, lr=1.98978e-05, gnorm=2.829, clip=100, loss_scale=512, train_wall=20, gb_free=15, wall=64932
2023-01-09 21:40:06 - progress_bar.py[line:272] - INFO: epoch 007:    996 / 3665 loss=5.021, loss_v1=0, loss_v2=0, nll_loss=4.105, ntokens=938, nsentences=32, sample_size=938, sample_size_v1=0, sample_size_v2=0, ppl=17.21, wps=469.6, ups=0.5, wpb=938, bsz=32, num_updates=22950, lr=1.98833e-05, gnorm=2.51, clip=100, loss_scale=512, train_wall=20, gb_free=15.5, wall=64952
2023-01-09 21:40:16 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 256.0
2023-01-09 21:40:28 - progress_bar.py[line:272] - INFO: epoch 007:   1007 / 3665 loss=5.031, loss_v1=0, loss_v2=0, nll_loss=4.116, ntokens=922.8, nsentences=32, sample_size=922.8, sample_size_v1=0, sample_size_v2=0, ppl=17.34, wps=420.1, ups=0.46, wpb=922.8, bsz=32, num_updates=22960, lr=1.98688e-05, gnorm=2.606, clip=100, loss_scale=256, train_wall=22, gb_free=15.2, wall=64974
2023-01-09 21:40:48 - progress_bar.py[line:272] - INFO: epoch 007:   1017 / 3665 loss=4.932, loss_v1=0, loss_v2=0, nll_loss=4.008, ntokens=814.8, nsentences=32, sample_size=814.8, sample_size_v1=0, sample_size_v2=0, ppl=16.09, wps=408.2, ups=0.5, wpb=814.8, bsz=32, num_updates=22970, lr=1.98543e-05, gnorm=2.743, clip=100, loss_scale=256, train_wall=20, gb_free=15.4, wall=64994
2023-01-09 21:41:08 - progress_bar.py[line:272] - INFO: epoch 007:   1027 / 3665 loss=4.999, loss_v1=0, loss_v2=0, nll_loss=4.083, ntokens=996.5, nsentences=32, sample_size=996.5, sample_size_v1=0, sample_size_v2=0, ppl=16.94, wps=499.1, ups=0.5, wpb=996.5, bsz=32, num_updates=22980, lr=1.98398e-05, gnorm=2.354, clip=100, loss_scale=256, train_wall=20, gb_free=15.7, wall=65014
2023-01-09 21:41:28 - progress_bar.py[line:272] - INFO: epoch 007:   1037 / 3665 loss=5.069, loss_v1=0, loss_v2=0, nll_loss=4.158, ntokens=836.1, nsentences=32, sample_size=836.1, sample_size_v1=0, sample_size_v2=0, ppl=17.86, wps=421, ups=0.5, wpb=836.1, bsz=32, num_updates=22990, lr=1.98253e-05, gnorm=2.706, clip=100, loss_scale=256, train_wall=20, gb_free=15.6, wall=65034
2023-01-09 21:41:47 - progress_bar.py[line:272] - INFO: epoch 007:   1047 / 3665 loss=4.914, loss_v1=0, loss_v2=0, nll_loss=3.984, ntokens=707.2, nsentences=32, sample_size=707.2, sample_size_v1=0, sample_size_v2=0, ppl=15.82, wps=357.4, ups=0.51, wpb=707.2, bsz=32, num_updates=23000, lr=1.98107e-05, gnorm=3.111, clip=100, loss_scale=256, train_wall=20, gb_free=15.4, wall=65054
2023-01-09 21:41:47 - train.py[line:445] - INFO: begin validation on "valid" subset
slice_id 0 seek offset 0
slice_id 0 seek offset 0
2023-01-09 21:46:31 - progress_bar.py[line:282] - INFO: epoch 007 | valid on 'valid' subset | loss 5.006 | loss_v1 0 | loss_v2 0 | nll_loss 4.072 | ntokens 116.76 | nsentences 4 | sample_size 116.76 | sample_size_v1 0 | sample_size_v2 0 | AP 0 | total positives 21.6656 | TP 0 | FP 4.68901 | ppl 16.82 | wps 513.2 | wpb 116.8 | bsz 4 | num_updates 23000 | best_AP 0
2023-01-09 21:46:31 - checkpoint_utils.py[line:64] - INFO: Preparing to save checkpoint for epoch 7 @ 23000 updates
2023-01-09 21:46:31 - trainer.py[line:431] - INFO: Saving checkpoint to ../../checkpoints/OFA/detection_checkpoints/10_5e-5_512/checkpoint_7_23000.pt
2023-01-09 21:46:35 - trainer.py[line:441] - INFO: Finished saving checkpoint to ../../checkpoints/OFA/detection_checkpoints/10_5e-5_512/checkpoint_7_23000.pt
2023-01-09 21:47:40 - checkpoint_utils.py[line:133] - INFO: Saved checkpoint ../../checkpoints/OFA/detection_checkpoints/10_5e-5_512/checkpoint_7_23000.pt (epoch 7 @ 23000 updates, score 0.0) (writing took 68.88371949922293 seconds)
2023-01-09 21:48:00 - progress_bar.py[line:272] - INFO: epoch 007:   1057 / 3665 loss=4.983, loss_v1=0, loss_v2=0, nll_loss=4.063, ntokens=1044.9, nsentences=32, sample_size=1044.9, sample_size_v1=0, sample_size_v2=0, ppl=16.71, wps=28.1, ups=0.03, wpb=1044.9, bsz=32, num_updates=23010, lr=1.97962e-05, gnorm=2.448, clip=100, loss_scale=256, train_wall=19, gb_free=15.2, wall=65426
2023-01-09 21:48:19 - progress_bar.py[line:272] - INFO: epoch 007:   1067 / 3665 loss=5.066, loss_v1=0, loss_v2=0, nll_loss=4.156, ntokens=853.3, nsentences=32, sample_size=853.3, sample_size_v1=0, sample_size_v2=0, ppl=17.82, wps=439, ups=0.51, wpb=853.3, bsz=32, num_updates=23020, lr=1.97817e-05, gnorm=2.766, clip=100, loss_scale=256, train_wall=19, gb_free=15.6, wall=65445
2023-01-09 21:48:39 - progress_bar.py[line:272] - INFO: epoch 007:   1077 / 3665 loss=4.932, loss_v1=0, loss_v2=0, nll_loss=4.006, ntokens=854.2, nsentences=32, sample_size=854.2, sample_size_v1=0, sample_size_v2=0, ppl=16.06, wps=438.4, ups=0.51, wpb=854.2, bsz=32, num_updates=23030, lr=1.97672e-05, gnorm=2.587, clip=100, loss_scale=256, train_wall=19, gb_free=15.4, wall=65465
2023-01-09 21:48:58 - progress_bar.py[line:272] - INFO: epoch 007:   1087 / 3665 loss=5.068, loss_v1=0, loss_v2=0, nll_loss=4.158, ntokens=1056.2, nsentences=32, sample_size=1056.2, sample_size_v1=0, sample_size_v2=0, ppl=17.85, wps=536.2, ups=0.51, wpb=1056.2, bsz=32, num_updates=23040, lr=1.97527e-05, gnorm=2.412, clip=100, loss_scale=256, train_wall=20, gb_free=15.6, wall=65485
2023-01-09 21:49:18 - progress_bar.py[line:272] - INFO: epoch 007:   1097 / 3665 loss=4.938, loss_v1=0, loss_v2=0, nll_loss=4.014, ntokens=808.6, nsentences=32, sample_size=808.6, sample_size_v1=0, sample_size_v2=0, ppl=16.16, wps=412.5, ups=0.51, wpb=808.6, bsz=32, num_updates=23050, lr=1.97382e-05, gnorm=3.004, clip=100, loss_scale=256, train_wall=20, gb_free=15.4, wall=65504
2023-01-09 21:49:37 - progress_bar.py[line:272] - INFO: epoch 007:   1107 / 3665 loss=5.049, loss_v1=0, loss_v2=0, nll_loss=4.136, ntokens=909.2, nsentences=32, sample_size=909.2, sample_size_v1=0, sample_size_v2=0, ppl=17.58, wps=463.6, ups=0.51, wpb=909.2, bsz=32, num_updates=23060, lr=1.97237e-05, gnorm=2.772, clip=100, loss_scale=256, train_wall=20, gb_free=15.6, wall=65524
2023-01-09 21:49:57 - progress_bar.py[line:272] - INFO: epoch 007:   1117 / 3665 loss=5.027, loss_v1=0, loss_v2=0, nll_loss=4.111, ntokens=969.9, nsentences=32, sample_size=969.9, sample_size_v1=0, sample_size_v2=0, ppl=17.29, wps=492.7, ups=0.51, wpb=969.9, bsz=32, num_updates=23070, lr=1.97092e-05, gnorm=2.58, clip=100, loss_scale=256, train_wall=20, gb_free=15.2, wall=65543
2023-01-09 21:50:17 - progress_bar.py[line:272] - INFO: epoch 007:   1127 / 3665 loss=4.985, loss_v1=0, loss_v2=0, nll_loss=4.067, ntokens=1142.3, nsentences=32, sample_size=1142.3, sample_size_v1=0, sample_size_v2=0, ppl=16.76, wps=580, ups=0.51, wpb=1142.3, bsz=32, num_updates=23080, lr=1.96946e-05, gnorm=2.233, clip=100, loss_scale=256, train_wall=20, gb_free=15.3, wall=65563
2023-01-09 21:50:37 - progress_bar.py[line:272] - INFO: epoch 007:   1137 / 3665 loss=5.027, loss_v1=0, loss_v2=0, nll_loss=4.114, ntokens=924.9, nsentences=32, sample_size=924.9, sample_size_v1=0, sample_size_v2=0, ppl=17.32, wps=470.8, ups=0.51, wpb=924.9, bsz=32, num_updates=23090, lr=1.96801e-05, gnorm=2.798, clip=100, loss_scale=256, train_wall=20, gb_free=15.2, wall=65583
2023-01-09 21:50:56 - progress_bar.py[line:272] - INFO: epoch 007:   1147 / 3665 loss=4.919, loss_v1=0, loss_v2=0, nll_loss=3.991, ntokens=745.3, nsentences=32, sample_size=745.3, sample_size_v1=0, sample_size_v2=0, ppl=15.9, wps=379.4, ups=0.51, wpb=745.3, bsz=32, num_updates=23100, lr=1.96656e-05, gnorm=3.246, clip=100, loss_scale=256, train_wall=20, gb_free=15.4, wall=65602
2023-01-09 21:51:16 - progress_bar.py[line:272] - INFO: epoch 007:   1157 / 3665 loss=4.967, loss_v1=0, loss_v2=0, nll_loss=4.046, ntokens=896, nsentences=32, sample_size=896, sample_size_v1=0, sample_size_v2=0, ppl=16.51, wps=456, ups=0.51, wpb=896, bsz=32, num_updates=23110, lr=1.96511e-05, gnorm=2.672, clip=100, loss_scale=256, train_wall=20, gb_free=15.4, wall=65622
2023-01-09 21:51:36 - progress_bar.py[line:272] - INFO: epoch 007:   1167 / 3665 loss=5.052, loss_v1=0, loss_v2=0, nll_loss=4.139, ntokens=993.6, nsentences=32, sample_size=993.6, sample_size_v1=0, sample_size_v2=0, ppl=17.62, wps=494.7, ups=0.5, wpb=993.6, bsz=32, num_updates=23120, lr=1.96366e-05, gnorm=2.335, clip=100, loss_scale=256, train_wall=20, gb_free=15.3, wall=65642
2023-01-09 21:51:56 - progress_bar.py[line:272] - INFO: epoch 007:   1177 / 3665 loss=4.897, loss_v1=0, loss_v2=0, nll_loss=3.969, ntokens=741.2, nsentences=32, sample_size=741.2, sample_size_v1=0, sample_size_v2=0, ppl=15.66, wps=367.4, ups=0.5, wpb=741.2, bsz=32, num_updates=23130, lr=1.96221e-05, gnorm=3.056, clip=100, loss_scale=256, train_wall=20, gb_free=15.3, wall=65662
2023-01-09 21:52:16 - progress_bar.py[line:272] - INFO: epoch 007:   1187 / 3665 loss=4.97, loss_v1=0, loss_v2=0, nll_loss=4.048, ntokens=995.1, nsentences=32, sample_size=995.1, sample_size_v1=0, sample_size_v2=0, ppl=16.55, wps=491.8, ups=0.49, wpb=995.1, bsz=32, num_updates=23140, lr=1.96076e-05, gnorm=2.44, clip=100, loss_scale=256, train_wall=20, gb_free=15, wall=65683
2023-01-09 21:52:37 - progress_bar.py[line:272] - INFO: epoch 007:   1197 / 3665 loss=5.12, loss_v1=0, loss_v2=0, nll_loss=4.216, ntokens=1211.3, nsentences=32, sample_size=1211.3, sample_size_v1=0, sample_size_v2=0, ppl=18.59, wps=596.5, ups=0.49, wpb=1211.3, bsz=32, num_updates=23150, lr=1.9593e-05, gnorm=2.26, clip=100, loss_scale=256, train_wall=20, gb_free=15.6, wall=65703
2023-01-09 21:52:57 - progress_bar.py[line:272] - INFO: epoch 007:   1207 / 3665 loss=4.997, loss_v1=0, loss_v2=0, nll_loss=4.078, ntokens=794.3, nsentences=32, sample_size=794.3, sample_size_v1=0, sample_size_v2=0, ppl=16.89, wps=397.3, ups=0.5, wpb=794.3, bsz=32, num_updates=23160, lr=1.95785e-05, gnorm=2.988, clip=100, loss_scale=256, train_wall=20, gb_free=15.5, wall=65723
2023-01-09 21:53:16 - progress_bar.py[line:272] - INFO: epoch 007:   1217 / 3665 loss=5.012, loss_v1=0, loss_v2=0, nll_loss=4.095, ntokens=927.1, nsentences=32, sample_size=927.1, sample_size_v1=0, sample_size_v2=0, ppl=17.09, wps=471.5, ups=0.51, wpb=927.1, bsz=32, num_updates=23170, lr=1.9564e-05, gnorm=2.811, clip=100, loss_scale=256, train_wall=20, gb_free=15.4, wall=65743
2023-01-09 21:53:36 - progress_bar.py[line:272] - INFO: epoch 007:   1227 / 3665 loss=5.02, loss_v1=0, loss_v2=0, nll_loss=4.104, ntokens=1105.4, nsentences=32, sample_size=1105.4, sample_size_v1=0, sample_size_v2=0, ppl=17.19, wps=559.4, ups=0.51, wpb=1105.4, bsz=32, num_updates=23180, lr=1.95495e-05, gnorm=2.48, clip=100, loss_scale=256, train_wall=20, gb_free=14.8, wall=65762
2023-01-09 21:53:56 - progress_bar.py[line:272] - INFO: epoch 007:   1237 / 3665 loss=5.112, loss_v1=0, loss_v2=0, nll_loss=4.207, ntokens=939.1, nsentences=32, sample_size=939.1, sample_size_v1=0, sample_size_v2=0, ppl=18.47, wps=475.1, ups=0.51, wpb=939.1, bsz=32, num_updates=23190, lr=1.9535e-05, gnorm=2.492, clip=100, loss_scale=256, train_wall=20, gb_free=15.6, wall=65782
2023-01-09 21:54:16 - progress_bar.py[line:272] - INFO: epoch 007:   1247 / 3665 loss=5.065, loss_v1=0, loss_v2=0, nll_loss=4.154, ntokens=1069.7, nsentences=32, sample_size=1069.7, sample_size_v1=0, sample_size_v2=0, ppl=17.8, wps=540.9, ups=0.51, wpb=1069.7, bsz=32, num_updates=23200, lr=1.95205e-05, gnorm=2.299, clip=100, loss_scale=256, train_wall=20, gb_free=15.3, wall=65802
2023-01-09 21:54:35 - progress_bar.py[line:272] - INFO: epoch 007:   1257 / 3665 loss=4.955, loss_v1=0, loss_v2=0, nll_loss=4.032, ntokens=1019.1, nsentences=32, sample_size=1019.1, sample_size_v1=0, sample_size_v2=0, ppl=16.36, wps=515.8, ups=0.51, wpb=1019.1, bsz=32, num_updates=23210, lr=1.9506e-05, gnorm=2.413, clip=100, loss_scale=256, train_wall=20, gb_free=15.4, wall=65822
2023-01-09 21:54:55 - progress_bar.py[line:272] - INFO: epoch 007:   1267 / 3665 loss=5.021, loss_v1=0, loss_v2=0, nll_loss=4.106, ntokens=790.7, nsentences=32, sample_size=790.7, sample_size_v1=0, sample_size_v2=0, ppl=17.22, wps=402.3, ups=0.51, wpb=790.7, bsz=32, num_updates=23220, lr=1.94915e-05, gnorm=2.997, clip=100, loss_scale=256, train_wall=20, gb_free=15.7, wall=65841
2023-01-09 21:55:15 - progress_bar.py[line:272] - INFO: epoch 007:   1277 / 3665 loss=5.03, loss_v1=0, loss_v2=0, nll_loss=4.116, ntokens=848.8, nsentences=32, sample_size=848.8, sample_size_v1=0, sample_size_v2=0, ppl=17.34, wps=430.5, ups=0.51, wpb=848.8, bsz=32, num_updates=23230, lr=1.94769e-05, gnorm=2.723, clip=100, loss_scale=256, train_wall=20, gb_free=15.1, wall=65861
2023-01-09 21:55:34 - progress_bar.py[line:272] - INFO: epoch 007:   1287 / 3665 loss=4.971, loss_v1=0, loss_v2=0, nll_loss=4.05, ntokens=949.5, nsentences=32, sample_size=949.5, sample_size_v1=0, sample_size_v2=0, ppl=16.56, wps=483.1, ups=0.51, wpb=949.5, bsz=32, num_updates=23240, lr=1.94624e-05, gnorm=2.538, clip=100, loss_scale=256, train_wall=20, gb_free=15.4, wall=65881
2023-01-09 21:55:54 - progress_bar.py[line:272] - INFO: epoch 007:   1297 / 3665 loss=5.036, loss_v1=0, loss_v2=0, nll_loss=4.123, ntokens=974.4, nsentences=32, sample_size=974.4, sample_size_v1=0, sample_size_v2=0, ppl=17.42, wps=493.4, ups=0.51, wpb=974.4, bsz=32, num_updates=23250, lr=1.94479e-05, gnorm=2.474, clip=100, loss_scale=256, train_wall=20, gb_free=15.2, wall=65900
2023-01-09 21:56:14 - progress_bar.py[line:272] - INFO: epoch 007:   1307 / 3665 loss=4.939, loss_v1=0, loss_v2=0, nll_loss=4.013, ntokens=807.9, nsentences=32, sample_size=807.9, sample_size_v1=0, sample_size_v2=0, ppl=16.15, wps=410.8, ups=0.51, wpb=807.9, bsz=32, num_updates=23260, lr=1.94334e-05, gnorm=2.978, clip=100, loss_scale=256, train_wall=20, gb_free=15.1, wall=65920
2023-01-09 21:56:34 - progress_bar.py[line:272] - INFO: epoch 007:   1317 / 3665 loss=4.959, loss_v1=0, loss_v2=0, nll_loss=4.036, ntokens=1034.5, nsentences=32, sample_size=1034.5, sample_size_v1=0, sample_size_v2=0, ppl=16.41, wps=504.4, ups=0.49, wpb=1034.5, bsz=32, num_updates=23270, lr=1.94189e-05, gnorm=2.26, clip=100, loss_scale=256, train_wall=20, gb_free=15.4, wall=65941
2023-01-09 21:56:55 - progress_bar.py[line:272] - INFO: epoch 007:   1327 / 3665 loss=5.045, loss_v1=0, loss_v2=0, nll_loss=4.135, ntokens=942, nsentences=32, sample_size=942, sample_size_v1=0, sample_size_v2=0, ppl=17.57, wps=459.1, ups=0.49, wpb=942, bsz=32, num_updates=23280, lr=1.94044e-05, gnorm=2.605, clip=100, loss_scale=256, train_wall=20, gb_free=15.6, wall=65961
2023-01-09 21:57:15 - progress_bar.py[line:272] - INFO: epoch 007:   1337 / 3665 loss=4.977, loss_v1=0, loss_v2=0, nll_loss=4.056, ntokens=741.4, nsentences=32, sample_size=741.4, sample_size_v1=0, sample_size_v2=0, ppl=16.63, wps=368.8, ups=0.5, wpb=741.4, bsz=32, num_updates=23290, lr=1.93899e-05, gnorm=3.161, clip=100, loss_scale=256, train_wall=20, gb_free=15.6, wall=65981
2023-01-09 21:57:34 - progress_bar.py[line:272] - INFO: epoch 007:   1347 / 3665 loss=4.94, loss_v1=0, loss_v2=0, nll_loss=4.014, ntokens=990.6, nsentences=32, sample_size=990.6, sample_size_v1=0, sample_size_v2=0, ppl=16.15, wps=506.3, ups=0.51, wpb=990.6, bsz=32, num_updates=23300, lr=1.93753e-05, gnorm=2.601, clip=100, loss_scale=256, train_wall=20, gb_free=15.3, wall=66001
2023-01-09 21:57:54 - progress_bar.py[line:272] - INFO: epoch 007:   1357 / 3665 loss=5.013, loss_v1=0, loss_v2=0, nll_loss=4.095, ntokens=1110.2, nsentences=32, sample_size=1110.2, sample_size_v1=0, sample_size_v2=0, ppl=17.09, wps=563.8, ups=0.51, wpb=1110.2, bsz=32, num_updates=23310, lr=1.93608e-05, gnorm=2.359, clip=100, loss_scale=256, train_wall=20, gb_free=15.1, wall=66020
2023-01-09 21:58:14 - progress_bar.py[line:272] - INFO: epoch 007:   1367 / 3665 loss=5.01, loss_v1=0, loss_v2=0, nll_loss=4.091, ntokens=875.5, nsentences=32, sample_size=875.5, sample_size_v1=0, sample_size_v2=0, ppl=17.04, wps=446, ups=0.51, wpb=875.5, bsz=32, num_updates=23320, lr=1.93463e-05, gnorm=2.737, clip=100, loss_scale=256, train_wall=20, gb_free=15.3, wall=66040
2023-01-09 21:58:33 - progress_bar.py[line:272] - INFO: epoch 007:   1377 / 3665 loss=4.907, loss_v1=0, loss_v2=0, nll_loss=3.981, ntokens=878.3, nsentences=32, sample_size=878.3, sample_size_v1=0, sample_size_v2=0, ppl=15.79, wps=446.8, ups=0.51, wpb=878.3, bsz=32, num_updates=23330, lr=1.93318e-05, gnorm=2.807, clip=100, loss_scale=256, train_wall=20, gb_free=15.3, wall=66060
2023-01-09 21:58:53 - progress_bar.py[line:272] - INFO: epoch 007:   1387 / 3665 loss=5.008, loss_v1=0, loss_v2=0, nll_loss=4.092, ntokens=980.6, nsentences=32, sample_size=980.6, sample_size_v1=0, sample_size_v2=0, ppl=17.05, wps=498.9, ups=0.51, wpb=980.6, bsz=32, num_updates=23340, lr=1.93173e-05, gnorm=2.268, clip=100, loss_scale=256, train_wall=20, gb_free=15.5, wall=66079
2023-01-09 21:59:13 - progress_bar.py[line:272] - INFO: epoch 007:   1397 / 3665 loss=4.869, loss_v1=0, loss_v2=0, nll_loss=3.937, ntokens=637.4, nsentences=32, sample_size=637.4, sample_size_v1=0, sample_size_v2=0, ppl=15.32, wps=325.6, ups=0.51, wpb=637.4, bsz=32, num_updates=23350, lr=1.93028e-05, gnorm=3.241, clip=100, loss_scale=256, train_wall=20, gb_free=15.6, wall=66099
2023-01-09 21:59:33 - progress_bar.py[line:272] - INFO: epoch 007:   1407 / 3665 loss=4.914, loss_v1=0, loss_v2=0, nll_loss=3.987, ntokens=906.4, nsentences=32, sample_size=906.4, sample_size_v1=0, sample_size_v2=0, ppl=15.86, wps=446.5, ups=0.49, wpb=906.4, bsz=32, num_updates=23360, lr=1.92883e-05, gnorm=2.584, clip=100, loss_scale=256, train_wall=20, gb_free=15.5, wall=66119
2023-01-09 21:59:53 - progress_bar.py[line:272] - INFO: epoch 007:   1417 / 3665 loss=4.996, loss_v1=0, loss_v2=0, nll_loss=4.078, ntokens=991.4, nsentences=32, sample_size=991.4, sample_size_v1=0, sample_size_v2=0, ppl=16.89, wps=487.6, ups=0.49, wpb=991.4, bsz=32, num_updates=23370, lr=1.92738e-05, gnorm=2.588, clip=100, loss_scale=256, train_wall=20, gb_free=14.5, wall=66140
2023-01-09 22:00:13 - progress_bar.py[line:272] - INFO: epoch 007:   1427 / 3665 loss=4.977, loss_v1=0, loss_v2=0, nll_loss=4.057, ntokens=728.5, nsentences=32, sample_size=728.5, sample_size_v1=0, sample_size_v2=0, ppl=16.65, wps=361.4, ups=0.5, wpb=728.5, bsz=32, num_updates=23380, lr=1.92592e-05, gnorm=3.121, clip=100, loss_scale=256, train_wall=20, gb_free=15.5, wall=66160
2023-01-09 22:00:34 - progress_bar.py[line:272] - INFO: epoch 007:   1437 / 3665 loss=4.979, loss_v1=0, loss_v2=0, nll_loss=4.058, ntokens=810, nsentences=32, sample_size=810, sample_size_v1=0, sample_size_v2=0, ppl=16.66, wps=403.7, ups=0.5, wpb=810, bsz=32, num_updates=23390, lr=1.92447e-05, gnorm=3.013, clip=100, loss_scale=256, train_wall=20, gb_free=15.6, wall=66180
2023-01-09 22:00:53 - progress_bar.py[line:272] - INFO: epoch 007:   1447 / 3665 loss=4.972, loss_v1=0, loss_v2=0, nll_loss=4.051, ntokens=1081.6, nsentences=32, sample_size=1081.6, sample_size_v1=0, sample_size_v2=0, ppl=16.57, wps=547.3, ups=0.51, wpb=1081.6, bsz=32, num_updates=23400, lr=1.92302e-05, gnorm=2.148, clip=100, loss_scale=256, train_wall=20, gb_free=15.6, wall=66200
2023-01-09 22:01:13 - progress_bar.py[line:272] - INFO: epoch 007:   1457 / 3665 loss=5.073, loss_v1=0, loss_v2=0, nll_loss=4.163, ntokens=893.7, nsentences=32, sample_size=893.7, sample_size_v1=0, sample_size_v2=0, ppl=17.91, wps=454.9, ups=0.51, wpb=893.7, bsz=32, num_updates=23410, lr=1.92157e-05, gnorm=2.615, clip=100, loss_scale=256, train_wall=20, gb_free=15.5, wall=66219
2023-01-09 22:01:32 - progress_bar.py[line:272] - INFO: epoch 007:   1467 / 3665 loss=4.861, loss_v1=0, loss_v2=0, nll_loss=3.928, ntokens=645.5, nsentences=32, sample_size=645.5, sample_size_v1=0, sample_size_v2=0, ppl=15.22, wps=331.2, ups=0.51, wpb=645.5, bsz=32, num_updates=23420, lr=1.92012e-05, gnorm=3.365, clip=100, loss_scale=256, train_wall=19, gb_free=15.5, wall=66239
2023-01-09 22:01:52 - progress_bar.py[line:272] - INFO: epoch 007:   1477 / 3665 loss=4.986, loss_v1=0, loss_v2=0, nll_loss=4.066, ntokens=959.7, nsentences=32, sample_size=959.7, sample_size_v1=0, sample_size_v2=0, ppl=16.75, wps=489, ups=0.51, wpb=959.7, bsz=32, num_updates=23430, lr=1.91867e-05, gnorm=2.509, clip=100, loss_scale=256, train_wall=20, gb_free=15.4, wall=66258
2023-01-09 22:02:12 - progress_bar.py[line:272] - INFO: epoch 007:   1487 / 3665 loss=5.095, loss_v1=0, loss_v2=0, nll_loss=4.187, ntokens=997.2, nsentences=32, sample_size=997.2, sample_size_v1=0, sample_size_v2=0, ppl=18.22, wps=505.1, ups=0.51, wpb=997.2, bsz=32, num_updates=23440, lr=1.91722e-05, gnorm=2.478, clip=100, loss_scale=256, train_wall=20, gb_free=15.3, wall=66278
2023-01-09 22:02:31 - progress_bar.py[line:272] - INFO: epoch 007:   1497 / 3665 loss=4.959, loss_v1=0, loss_v2=0, nll_loss=4.037, ntokens=723.8, nsentences=32, sample_size=723.8, sample_size_v1=0, sample_size_v2=0, ppl=16.42, wps=368.8, ups=0.51, wpb=723.8, bsz=32, num_updates=23450, lr=1.91576e-05, gnorm=3.348, clip=100, loss_scale=256, train_wall=20, gb_free=15.5, wall=66298
2023-01-09 22:02:51 - progress_bar.py[line:272] - INFO: epoch 007:   1507 / 3665 loss=4.988, loss_v1=0, loss_v2=0, nll_loss=4.069, ntokens=993.3, nsentences=32, sample_size=993.3, sample_size_v1=0, sample_size_v2=0, ppl=16.78, wps=503.4, ups=0.51, wpb=993.3, bsz=32, num_updates=23460, lr=1.91431e-05, gnorm=2.597, clip=100, loss_scale=256, train_wall=20, gb_free=15.4, wall=66317
2023-01-09 22:03:07 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 256.0
2023-01-09 22:03:13 - progress_bar.py[line:272] - INFO: epoch 007:   1518 / 3665 loss=5.015, loss_v1=0, loss_v2=0, nll_loss=4.098, ntokens=954.1, nsentences=32, sample_size=954.1, sample_size_v1=0, sample_size_v2=0, ppl=17.13, wps=436.4, ups=0.46, wpb=954.1, bsz=32, num_updates=23470, lr=1.91286e-05, gnorm=2.521, clip=100, loss_scale=256, train_wall=22, gb_free=15.3, wall=66339
2023-01-09 22:03:33 - progress_bar.py[line:272] - INFO: epoch 007:   1528 / 3665 loss=5.005, loss_v1=0, loss_v2=0, nll_loss=4.088, ntokens=814.7, nsentences=32, sample_size=814.7, sample_size_v1=0, sample_size_v2=0, ppl=17.01, wps=411.4, ups=0.5, wpb=814.7, bsz=32, num_updates=23480, lr=1.91141e-05, gnorm=2.853, clip=100, loss_scale=256, train_wall=20, gb_free=15.3, wall=66359
2023-01-09 22:03:53 - progress_bar.py[line:272] - INFO: epoch 007:   1538 / 3665 loss=4.999, loss_v1=0, loss_v2=0, nll_loss=4.081, ntokens=925.6, nsentences=32, sample_size=925.6, sample_size_v1=0, sample_size_v2=0, ppl=16.93, wps=467.1, ups=0.5, wpb=925.6, bsz=32, num_updates=23490, lr=1.90996e-05, gnorm=2.624, clip=100, loss_scale=256, train_wall=20, gb_free=15.2, wall=66379
2023-01-09 22:04:13 - progress_bar.py[line:272] - INFO: epoch 007:   1548 / 3665 loss=5.118, loss_v1=0, loss_v2=0, nll_loss=4.212, ntokens=1051.6, nsentences=32, sample_size=1051.6, sample_size_v1=0, sample_size_v2=0, ppl=18.53, wps=529, ups=0.5, wpb=1051.6, bsz=32, num_updates=23500, lr=1.90851e-05, gnorm=2.33, clip=100, loss_scale=256, train_wall=20, gb_free=15.5, wall=66399
2023-01-09 22:04:13 - train.py[line:445] - INFO: begin validation on "valid" subset
slice_id 0 seek offset 0
slice_id 0 seek offset 0
2023-01-09 22:09:19 - progress_bar.py[line:282] - INFO: epoch 007 | valid on 'valid' subset | loss 5.01 | loss_v1 0 | loss_v2 0 | nll_loss 4.078 | ntokens 116.512 | nsentences 4 | sample_size 116.512 | sample_size_v1 0 | sample_size_v2 0 | AP 0 | total positives 21.6171 | TP 0 | FP 6.09532 | ppl 16.89 | wps 476.1 | wpb 116.5 | bsz 4 | num_updates 23500 | best_AP 0
2023-01-09 22:09:19 - checkpoint_utils.py[line:64] - INFO: Preparing to save checkpoint for epoch 7 @ 23500 updates
2023-01-09 22:09:19 - trainer.py[line:431] - INFO: Saving checkpoint to ../../checkpoints/OFA/detection_checkpoints/10_5e-5_512/checkpoint_7_23500.pt
2023-01-09 22:09:22 - trainer.py[line:441] - INFO: Finished saving checkpoint to ../../checkpoints/OFA/detection_checkpoints/10_5e-5_512/checkpoint_7_23500.pt
2023-01-09 22:10:30 - checkpoint_utils.py[line:133] - INFO: Saved checkpoint ../../checkpoints/OFA/detection_checkpoints/10_5e-5_512/checkpoint_7_23500.pt (epoch 7 @ 23500 updates, score 0.0) (writing took 70.87987448880449 seconds)
2023-01-09 22:10:50 - progress_bar.py[line:272] - INFO: epoch 007:   1558 / 3665 loss=5.009, loss_v1=0, loss_v2=0, nll_loss=4.092, ntokens=819.7, nsentences=32, sample_size=819.7, sample_size_v1=0, sample_size_v2=0, ppl=17.06, wps=20.6, ups=0.03, wpb=819.7, bsz=32, num_updates=23510, lr=1.90706e-05, gnorm=2.747, clip=100, loss_scale=256, train_wall=20, gb_free=15.5, wall=66796
2023-01-09 22:11:09 - progress_bar.py[line:272] - INFO: epoch 007:   1568 / 3665 loss=5.012, loss_v1=0, loss_v2=0, nll_loss=4.096, ntokens=993.9, nsentences=32, sample_size=993.9, sample_size_v1=0, sample_size_v2=0, ppl=17.11, wps=505.8, ups=0.51, wpb=993.9, bsz=32, num_updates=23520, lr=1.90561e-05, gnorm=2.892, clip=100, loss_scale=256, train_wall=20, gb_free=15.5, wall=66816
2023-01-09 22:11:29 - progress_bar.py[line:272] - INFO: epoch 007:   1578 / 3665 loss=5.067, loss_v1=0, loss_v2=0, nll_loss=4.157, ntokens=998.2, nsentences=32, sample_size=998.2, sample_size_v1=0, sample_size_v2=0, ppl=17.84, wps=504.1, ups=0.51, wpb=998.2, bsz=32, num_updates=23530, lr=1.90415e-05, gnorm=2.691, clip=100, loss_scale=256, train_wall=20, gb_free=15.6, wall=66835
2023-01-09 22:11:49 - progress_bar.py[line:272] - INFO: epoch 007:   1588 / 3665 loss=5.024, loss_v1=0, loss_v2=0, nll_loss=4.108, ntokens=838, nsentences=32, sample_size=838, sample_size_v1=0, sample_size_v2=0, ppl=17.25, wps=425.4, ups=0.51, wpb=838, bsz=32, num_updates=23540, lr=1.9027e-05, gnorm=2.889, clip=100, loss_scale=256, train_wall=20, gb_free=15.3, wall=66855
2023-01-09 22:12:08 - progress_bar.py[line:272] - INFO: epoch 007:   1598 / 3665 loss=4.912, loss_v1=0, loss_v2=0, nll_loss=3.985, ntokens=823.1, nsentences=32, sample_size=823.1, sample_size_v1=0, sample_size_v2=0, ppl=15.83, wps=419.3, ups=0.51, wpb=823.1, bsz=32, num_updates=23550, lr=1.90125e-05, gnorm=2.886, clip=100, loss_scale=256, train_wall=20, gb_free=15.7, wall=66875
2023-01-09 22:12:28 - progress_bar.py[line:272] - INFO: epoch 007:   1608 / 3665 loss=5.078, loss_v1=0, loss_v2=0, nll_loss=4.169, ntokens=1147.6, nsentences=32, sample_size=1147.6, sample_size_v1=0, sample_size_v2=0, ppl=17.98, wps=579.3, ups=0.5, wpb=1147.6, bsz=32, num_updates=23560, lr=1.8998e-05, gnorm=2.731, clip=100, loss_scale=256, train_wall=20, gb_free=15.2, wall=66895
2023-01-09 22:12:48 - progress_bar.py[line:272] - INFO: epoch 007:   1618 / 3665 loss=4.954, loss_v1=0, loss_v2=0, nll_loss=4.03, ntokens=737.9, nsentences=32, sample_size=737.9, sample_size_v1=0, sample_size_v2=0, ppl=16.34, wps=377.2, ups=0.51, wpb=737.9, bsz=32, num_updates=23570, lr=1.89835e-05, gnorm=2.943, clip=100, loss_scale=256, train_wall=20, gb_free=15.5, wall=66914
2023-01-09 22:13:08 - progress_bar.py[line:272] - INFO: epoch 007:   1628 / 3665 loss=5.009, loss_v1=0, loss_v2=0, nll_loss=4.093, ntokens=968.6, nsentences=32, sample_size=968.6, sample_size_v1=0, sample_size_v2=0, ppl=17.06, wps=491.6, ups=0.51, wpb=968.6, bsz=32, num_updates=23580, lr=1.8969e-05, gnorm=2.575, clip=100, loss_scale=256, train_wall=20, gb_free=15.4, wall=66934
2023-01-09 22:13:27 - progress_bar.py[line:272] - INFO: epoch 007:   1638 / 3665 loss=4.953, loss_v1=0, loss_v2=0, nll_loss=4.03, ntokens=1106.4, nsentences=32, sample_size=1106.4, sample_size_v1=0, sample_size_v2=0, ppl=16.33, wps=559.2, ups=0.51, wpb=1106.4, bsz=32, num_updates=23590, lr=1.89545e-05, gnorm=2.353, clip=100, loss_scale=256, train_wall=20, gb_free=15.5, wall=66954
2023-01-09 22:13:47 - progress_bar.py[line:272] - INFO: epoch 007:   1648 / 3665 loss=5.067, loss_v1=0, loss_v2=0, nll_loss=4.156, ntokens=1102.6, nsentences=32, sample_size=1102.6, sample_size_v1=0, sample_size_v2=0, ppl=17.83, wps=556.1, ups=0.5, wpb=1102.6, bsz=32, num_updates=23600, lr=1.89399e-05, gnorm=2.324, clip=100, loss_scale=256, train_wall=20, gb_free=15.2, wall=66973
2023-01-09 22:14:07 - progress_bar.py[line:272] - INFO: epoch 007:   1658 / 3665 loss=4.954, loss_v1=0, loss_v2=0, nll_loss=4.032, ntokens=833.8, nsentences=32, sample_size=833.8, sample_size_v1=0, sample_size_v2=0, ppl=16.36, wps=424.6, ups=0.51, wpb=833.8, bsz=32, num_updates=23610, lr=1.89254e-05, gnorm=2.637, clip=100, loss_scale=256, train_wall=20, gb_free=15.7, wall=66993
2023-01-09 22:14:26 - progress_bar.py[line:272] - INFO: epoch 007:   1668 / 3665 loss=4.99, loss_v1=0, loss_v2=0, nll_loss=4.07, ntokens=959.5, nsentences=32, sample_size=959.5, sample_size_v1=0, sample_size_v2=0, ppl=16.8, wps=487.6, ups=0.51, wpb=959.5, bsz=32, num_updates=23620, lr=1.89109e-05, gnorm=2.563, clip=100, loss_scale=256, train_wall=20, gb_free=15.3, wall=67013
2023-01-09 22:14:46 - progress_bar.py[line:272] - INFO: epoch 007:   1678 / 3665 loss=5.061, loss_v1=0, loss_v2=0, nll_loss=4.148, ntokens=858.8, nsentences=32, sample_size=858.8, sample_size_v1=0, sample_size_v2=0, ppl=17.73, wps=435, ups=0.51, wpb=858.8, bsz=32, num_updates=23630, lr=1.88964e-05, gnorm=2.89, clip=100, loss_scale=256, train_wall=20, gb_free=15.6, wall=67032
2023-01-09 22:15:06 - progress_bar.py[line:272] - INFO: epoch 007:   1688 / 3665 loss=5.019, loss_v1=0, loss_v2=0, nll_loss=4.103, ntokens=953.3, nsentences=32, sample_size=953.3, sample_size_v1=0, sample_size_v2=0, ppl=17.18, wps=474.4, ups=0.5, wpb=953.3, bsz=32, num_updates=23640, lr=1.88819e-05, gnorm=2.598, clip=100, loss_scale=256, train_wall=20, gb_free=15.4, wall=67053
2023-01-09 22:15:27 - progress_bar.py[line:272] - INFO: epoch 007:   1698 / 3665 loss=4.912, loss_v1=0, loss_v2=0, nll_loss=3.985, ntokens=988.7, nsentences=32, sample_size=988.7, sample_size_v1=0, sample_size_v2=0, ppl=15.83, wps=484.9, ups=0.49, wpb=988.7, bsz=32, num_updates=23650, lr=1.88674e-05, gnorm=2.831, clip=100, loss_scale=256, train_wall=20, gb_free=15.4, wall=67073
2023-01-09 22:15:47 - progress_bar.py[line:272] - INFO: epoch 007:   1708 / 3665 loss=5.032, loss_v1=0, loss_v2=0, nll_loss=4.117, ntokens=921.2, nsentences=32, sample_size=921.2, sample_size_v1=0, sample_size_v2=0, ppl=17.35, wps=453.2, ups=0.49, wpb=921.2, bsz=32, num_updates=23660, lr=1.88529e-05, gnorm=2.851, clip=100, loss_scale=256, train_wall=20, gb_free=15.6, wall=67093
2023-01-09 22:16:07 - progress_bar.py[line:272] - INFO: epoch 007:   1718 / 3665 loss=4.932, loss_v1=0, loss_v2=0, nll_loss=4.007, ntokens=714.1, nsentences=32, sample_size=714.1, sample_size_v1=0, sample_size_v2=0, ppl=16.08, wps=358.6, ups=0.5, wpb=714.1, bsz=32, num_updates=23670, lr=1.88384e-05, gnorm=3.105, clip=100, loss_scale=256, train_wall=20, gb_free=15.5, wall=67113
2023-01-09 22:16:27 - progress_bar.py[line:272] - INFO: epoch 007:   1728 / 3665 loss=4.929, loss_v1=0, loss_v2=0, nll_loss=4.005, ntokens=955.3, nsentences=32, sample_size=955.3, sample_size_v1=0, sample_size_v2=0, ppl=16.05, wps=484.7, ups=0.51, wpb=955.3, bsz=32, num_updates=23680, lr=1.88238e-05, gnorm=2.448, clip=100, loss_scale=256, train_wall=20, gb_free=15.3, wall=67133
2023-01-09 22:16:46 - progress_bar.py[line:272] - INFO: epoch 007:   1738 / 3665 loss=4.994, loss_v1=0, loss_v2=0, nll_loss=4.075, ntokens=1013.3, nsentences=32, sample_size=1013.3, sample_size_v1=0, sample_size_v2=0, ppl=16.85, wps=512.1, ups=0.51, wpb=1013.3, bsz=32, num_updates=23690, lr=1.88093e-05, gnorm=2.66, clip=100, loss_scale=256, train_wall=20, gb_free=15.5, wall=67153
2023-01-09 22:17:06 - progress_bar.py[line:272] - INFO: epoch 007:   1748 / 3665 loss=5.019, loss_v1=0, loss_v2=0, nll_loss=4.102, ntokens=887.1, nsentences=32, sample_size=887.1, sample_size_v1=0, sample_size_v2=0, ppl=17.17, wps=448.8, ups=0.51, wpb=887.1, bsz=32, num_updates=23700, lr=1.87948e-05, gnorm=2.775, clip=100, loss_scale=256, train_wall=20, gb_free=15.3, wall=67172
2023-01-09 22:17:26 - progress_bar.py[line:272] - INFO: epoch 007:   1758 / 3665 loss=4.925, loss_v1=0, loss_v2=0, nll_loss=3.998, ntokens=886.5, nsentences=32, sample_size=886.5, sample_size_v1=0, sample_size_v2=0, ppl=15.98, wps=449.9, ups=0.51, wpb=886.5, bsz=32, num_updates=23710, lr=1.87803e-05, gnorm=2.805, clip=100, loss_scale=256, train_wall=20, gb_free=15.4, wall=67192
2023-01-09 22:17:46 - progress_bar.py[line:272] - INFO: epoch 007:   1768 / 3665 loss=5.085, loss_v1=0, loss_v2=0, nll_loss=4.176, ntokens=1096.4, nsentences=32, sample_size=1096.4, sample_size_v1=0, sample_size_v2=0, ppl=18.08, wps=542.8, ups=0.5, wpb=1096.4, bsz=32, num_updates=23720, lr=1.87658e-05, gnorm=2.366, clip=100, loss_scale=256, train_wall=20, gb_free=15.3, wall=67212
2023-01-09 22:18:06 - progress_bar.py[line:272] - INFO: epoch 007:   1778 / 3665 loss=5.015, loss_v1=0, loss_v2=0, nll_loss=4.1, ntokens=867.3, nsentences=32, sample_size=867.3, sample_size_v1=0, sample_size_v2=0, ppl=17.15, wps=439.9, ups=0.51, wpb=867.3, bsz=32, num_updates=23730, lr=1.87513e-05, gnorm=2.801, clip=100, loss_scale=256, train_wall=20, gb_free=15.3, wall=67232
2023-01-09 22:18:26 - progress_bar.py[line:272] - INFO: epoch 007:   1788 / 3665 loss=4.98, loss_v1=0, loss_v2=0, nll_loss=4.06, ntokens=892.1, nsentences=32, sample_size=892.1, sample_size_v1=0, sample_size_v2=0, ppl=16.68, wps=450.6, ups=0.51, wpb=892.1, bsz=32, num_updates=23740, lr=1.87368e-05, gnorm=2.79, clip=100, loss_scale=256, train_wall=20, gb_free=15.7, wall=67252
2023-01-09 22:18:45 - progress_bar.py[line:272] - INFO: epoch 007:   1798 / 3665 loss=4.968, loss_v1=0, loss_v2=0, nll_loss=4.045, ntokens=1020.2, nsentences=32, sample_size=1020.2, sample_size_v1=0, sample_size_v2=0, ppl=16.51, wps=515.3, ups=0.51, wpb=1020.2, bsz=32, num_updates=23750, lr=1.87222e-05, gnorm=2.431, clip=100, loss_scale=256, train_wall=20, gb_free=14.8, wall=67272
2023-01-09 22:19:05 - progress_bar.py[line:272] - INFO: epoch 007:   1808 / 3665 loss=4.968, loss_v1=0, loss_v2=0, nll_loss=4.046, ntokens=734.9, nsentences=32, sample_size=734.9, sample_size_v1=0, sample_size_v2=0, ppl=16.51, wps=372.4, ups=0.51, wpb=734.9, bsz=32, num_updates=23760, lr=1.87077e-05, gnorm=2.928, clip=100, loss_scale=256, train_wall=20, gb_free=15.4, wall=67291
2023-01-09 22:19:25 - progress_bar.py[line:272] - INFO: epoch 007:   1818 / 3665 loss=4.999, loss_v1=0, loss_v2=0, nll_loss=4.081, ntokens=892.7, nsentences=32, sample_size=892.7, sample_size_v1=0, sample_size_v2=0, ppl=16.92, wps=450.4, ups=0.5, wpb=892.7, bsz=32, num_updates=23770, lr=1.86932e-05, gnorm=2.541, clip=100, loss_scale=256, train_wall=20, gb_free=15.5, wall=67311
2023-01-09 22:19:45 - progress_bar.py[line:272] - INFO: epoch 007:   1828 / 3665 loss=4.933, loss_v1=0, loss_v2=0, nll_loss=4.009, ntokens=1018.2, nsentences=32, sample_size=1018.2, sample_size_v1=0, sample_size_v2=0, ppl=16.1, wps=511.5, ups=0.5, wpb=1018.2, bsz=32, num_updates=23780, lr=1.86787e-05, gnorm=2.415, clip=100, loss_scale=256, train_wall=20, gb_free=15.4, wall=67331
2023-01-09 22:20:05 - progress_bar.py[line:272] - INFO: epoch 007:   1838 / 3665 loss=5.092, loss_v1=0, loss_v2=0, nll_loss=4.184, ntokens=920.3, nsentences=32, sample_size=920.3, sample_size_v1=0, sample_size_v2=0, ppl=18.17, wps=463.1, ups=0.5, wpb=920.3, bsz=32, num_updates=23790, lr=1.86642e-05, gnorm=2.879, clip=100, loss_scale=256, train_wall=20, gb_free=15.4, wall=67351
2023-01-09 22:20:25 - progress_bar.py[line:272] - INFO: epoch 007:   1848 / 3665 loss=4.985, loss_v1=0, loss_v2=0, nll_loss=4.065, ntokens=799.6, nsentences=32, sample_size=799.6, sample_size_v1=0, sample_size_v2=0, ppl=16.74, wps=403.5, ups=0.5, wpb=799.6, bsz=32, num_updates=23800, lr=1.86497e-05, gnorm=3.035, clip=100, loss_scale=256, train_wall=20, gb_free=15.2, wall=67371
2023-01-09 22:20:44 - progress_bar.py[line:272] - INFO: epoch 007:   1858 / 3665 loss=4.941, loss_v1=0, loss_v2=0, nll_loss=4.018, ntokens=956.2, nsentences=32, sample_size=956.2, sample_size_v1=0, sample_size_v2=0, ppl=16.2, wps=483.7, ups=0.51, wpb=956.2, bsz=32, num_updates=23810, lr=1.86352e-05, gnorm=2.553, clip=100, loss_scale=256, train_wall=20, gb_free=15.4, wall=67391
2023-01-09 22:21:04 - progress_bar.py[line:272] - INFO: epoch 007:   1868 / 3665 loss=5.045, loss_v1=0, loss_v2=0, nll_loss=4.133, ntokens=947.3, nsentences=32, sample_size=947.3, sample_size_v1=0, sample_size_v2=0, ppl=17.55, wps=478, ups=0.5, wpb=947.3, bsz=32, num_updates=23820, lr=1.86206e-05, gnorm=2.762, clip=100, loss_scale=256, train_wall=20, gb_free=15.4, wall=67410
2023-01-09 22:21:24 - progress_bar.py[line:272] - INFO: epoch 007:   1878 / 3665 loss=4.99, loss_v1=0, loss_v2=0, nll_loss=4.07, ntokens=878.8, nsentences=32, sample_size=878.8, sample_size_v1=0, sample_size_v2=0, ppl=16.79, wps=443.9, ups=0.51, wpb=878.8, bsz=32, num_updates=23830, lr=1.86061e-05, gnorm=2.947, clip=100, loss_scale=256, train_wall=20, gb_free=15.5, wall=67430
2023-01-09 22:21:44 - progress_bar.py[line:272] - INFO: epoch 007:   1888 / 3665 loss=5.023, loss_v1=0, loss_v2=0, nll_loss=4.107, ntokens=1109, nsentences=32, sample_size=1109, sample_size_v1=0, sample_size_v2=0, ppl=17.23, wps=556.6, ups=0.5, wpb=1109, bsz=32, num_updates=23840, lr=1.85916e-05, gnorm=2.367, clip=100, loss_scale=256, train_wall=20, gb_free=15.1, wall=67450
2023-01-09 22:22:04 - progress_bar.py[line:272] - INFO: epoch 007:   1898 / 3665 loss=5.069, loss_v1=0, loss_v2=0, nll_loss=4.159, ntokens=936.2, nsentences=32, sample_size=936.2, sample_size_v1=0, sample_size_v2=0, ppl=17.87, wps=471.2, ups=0.5, wpb=936.2, bsz=32, num_updates=23850, lr=1.85771e-05, gnorm=2.642, clip=100, loss_scale=256, train_wall=20, gb_free=15.4, wall=67470
2023-01-09 22:22:23 - progress_bar.py[line:272] - INFO: epoch 007:   1908 / 3665 loss=4.982, loss_v1=0, loss_v2=0, nll_loss=4.062, ntokens=763.7, nsentences=32, sample_size=763.7, sample_size_v1=0, sample_size_v2=0, ppl=16.71, wps=387.6, ups=0.51, wpb=763.7, bsz=32, num_updates=23860, lr=1.85626e-05, gnorm=3.105, clip=100, loss_scale=256, train_wall=20, gb_free=15.5, wall=67490
2023-01-09 22:22:43 - progress_bar.py[line:272] - INFO: epoch 007:   1918 / 3665 loss=4.867, loss_v1=0, loss_v2=0, nll_loss=3.935, ntokens=814.1, nsentences=32, sample_size=814.1, sample_size_v1=0, sample_size_v2=0, ppl=15.29, wps=412.3, ups=0.51, wpb=814.1, bsz=32, num_updates=23870, lr=1.85481e-05, gnorm=2.758, clip=100, loss_scale=256, train_wall=20, gb_free=15.4, wall=67509
2023-01-09 22:23:03 - progress_bar.py[line:272] - INFO: epoch 007:   1928 / 3665 loss=5.095, loss_v1=0, loss_v2=0, nll_loss=4.189, ntokens=1057.3, nsentences=32, sample_size=1057.3, sample_size_v1=0, sample_size_v2=0, ppl=18.24, wps=531.1, ups=0.5, wpb=1057.3, bsz=32, num_updates=23880, lr=1.85336e-05, gnorm=2.603, clip=100, loss_scale=256, train_wall=20, gb_free=15.4, wall=67529
2023-01-09 22:23:23 - progress_bar.py[line:272] - INFO: epoch 007:   1938 / 3665 loss=4.995, loss_v1=0, loss_v2=0, nll_loss=4.075, ntokens=777.1, nsentences=32, sample_size=777.1, sample_size_v1=0, sample_size_v2=0, ppl=16.86, wps=391.7, ups=0.5, wpb=777.1, bsz=32, num_updates=23890, lr=1.85191e-05, gnorm=2.825, clip=100, loss_scale=256, train_wall=20, gb_free=15.4, wall=67549
2023-01-09 22:23:43 - progress_bar.py[line:272] - INFO: epoch 007:   1948 / 3665 loss=4.94, loss_v1=0, loss_v2=0, nll_loss=4.013, ntokens=824.7, nsentences=32, sample_size=824.7, sample_size_v1=0, sample_size_v2=0, ppl=16.15, wps=416.2, ups=0.5, wpb=824.7, bsz=32, num_updates=23900, lr=1.85045e-05, gnorm=3.216, clip=100, loss_scale=256, train_wall=20, gb_free=15.5, wall=67569
2023-01-09 22:24:03 - progress_bar.py[line:272] - INFO: epoch 007:   1958 / 3665 loss=5.035, loss_v1=0, loss_v2=0, nll_loss=4.121, ntokens=1200.8, nsentences=32, sample_size=1200.8, sample_size_v1=0, sample_size_v2=0, ppl=17.41, wps=599.5, ups=0.5, wpb=1200.8, bsz=32, num_updates=23910, lr=1.849e-05, gnorm=2.377, clip=100, loss_scale=256, train_wall=20, gb_free=15, wall=67589
2023-01-09 22:24:23 - progress_bar.py[line:272] - INFO: epoch 007:   1968 / 3665 loss=5.058, loss_v1=0, loss_v2=0, nll_loss=4.146, ntokens=876.9, nsentences=32, sample_size=876.9, sample_size_v1=0, sample_size_v2=0, ppl=17.7, wps=442.7, ups=0.5, wpb=876.9, bsz=32, num_updates=23920, lr=1.84755e-05, gnorm=2.947, clip=100, loss_scale=256, train_wall=20, gb_free=15.4, wall=67609
2023-01-09 22:24:43 - progress_bar.py[line:272] - INFO: epoch 007:   1978 / 3665 loss=4.97, loss_v1=0, loss_v2=0, nll_loss=4.049, ntokens=972.5, nsentences=32, sample_size=972.5, sample_size_v1=0, sample_size_v2=0, ppl=16.56, wps=488.1, ups=0.5, wpb=972.5, bsz=32, num_updates=23930, lr=1.8461e-05, gnorm=2.687, clip=100, loss_scale=256, train_wall=20, gb_free=15.2, wall=67629
2023-01-09 22:25:02 - progress_bar.py[line:272] - INFO: epoch 007:   1988 / 3665 loss=4.964, loss_v1=0, loss_v2=0, nll_loss=4.041, ntokens=1019, nsentences=32, sample_size=1019, sample_size_v1=0, sample_size_v2=0, ppl=16.46, wps=514.1, ups=0.5, wpb=1019, bsz=32, num_updates=23940, lr=1.84465e-05, gnorm=2.665, clip=100, loss_scale=256, train_wall=20, gb_free=15.2, wall=67649
2023-01-09 22:25:22 - progress_bar.py[line:272] - INFO: epoch 007:   1998 / 3665 loss=5.072, loss_v1=0, loss_v2=0, nll_loss=4.162, ntokens=877.1, nsentences=32, sample_size=877.1, sample_size_v1=0, sample_size_v2=0, ppl=17.9, wps=442.7, ups=0.5, wpb=877.1, bsz=32, num_updates=23950, lr=1.8432e-05, gnorm=3, clip=100, loss_scale=256, train_wall=20, gb_free=15.2, wall=67668
2023-01-09 22:25:42 - progress_bar.py[line:272] - INFO: epoch 007:   2008 / 3665 loss=5.035, loss_v1=0, loss_v2=0, nll_loss=4.12, ntokens=913.4, nsentences=32, sample_size=913.4, sample_size_v1=0, sample_size_v2=0, ppl=17.39, wps=461.1, ups=0.5, wpb=913.4, bsz=32, num_updates=23960, lr=1.84175e-05, gnorm=2.677, clip=100, loss_scale=256, train_wall=20, gb_free=15.4, wall=67688
2023-01-09 22:26:02 - progress_bar.py[line:272] - INFO: epoch 007:   2018 / 3665 loss=4.944, loss_v1=0, loss_v2=0, nll_loss=4.021, ntokens=982, nsentences=32, sample_size=982, sample_size_v1=0, sample_size_v2=0, ppl=16.23, wps=496.2, ups=0.51, wpb=982, bsz=32, num_updates=23970, lr=1.84029e-05, gnorm=2.28, clip=100, loss_scale=256, train_wall=20, gb_free=15.5, wall=67708
2023-01-09 22:26:22 - progress_bar.py[line:272] - INFO: epoch 007:   2028 / 3665 loss=5.141, loss_v1=0, loss_v2=0, nll_loss=4.239, ntokens=994.3, nsentences=32, sample_size=994.3, sample_size_v1=0, sample_size_v2=0, ppl=18.88, wps=500.7, ups=0.5, wpb=994.3, bsz=32, num_updates=23980, lr=1.83884e-05, gnorm=2.655, clip=100, loss_scale=512, train_wall=20, gb_free=15.4, wall=67728
2023-01-09 22:26:24 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 256.0
2023-01-09 22:26:43 - progress_bar.py[line:272] - INFO: epoch 007:   2039 / 3665 loss=4.889, loss_v1=0, loss_v2=0, nll_loss=3.958, ntokens=709.3, nsentences=32, sample_size=709.3, sample_size_v1=0, sample_size_v2=0, ppl=15.55, wps=326.6, ups=0.46, wpb=709.3, bsz=32, num_updates=23990, lr=1.83739e-05, gnorm=3.376, clip=100, loss_scale=256, train_wall=22, gb_free=15.4, wall=67750
2023-01-09 22:27:03 - progress_bar.py[line:272] - INFO: epoch 007:   2049 / 3665 loss=4.956, loss_v1=0, loss_v2=0, nll_loss=4.033, ntokens=956, nsentences=32, sample_size=956, sample_size_v1=0, sample_size_v2=0, ppl=16.37, wps=480.5, ups=0.5, wpb=956, bsz=32, num_updates=24000, lr=1.83594e-05, gnorm=2.501, clip=100, loss_scale=256, train_wall=20, gb_free=15.3, wall=67769
2023-01-09 22:27:03 - train.py[line:445] - INFO: begin validation on "valid" subset
slice_id 0 seek offset 0
slice_id 0 seek offset 0
2023-01-09 22:32:01 - progress_bar.py[line:282] - INFO: epoch 007 | valid on 'valid' subset | loss 4.994 | loss_v1 0 | loss_v2 0 | nll_loss 4.059 | ntokens 117.023 | nsentences 4 | sample_size 117.023 | sample_size_v1 0 | sample_size_v2 0 | AP 0 | total positives 21.7165 | TP 0 | FP 5.32633 | ppl 16.67 | wps 490.9 | wpb 117 | bsz 4 | num_updates 24000 | best_AP 0
2023-01-09 22:32:01 - checkpoint_utils.py[line:64] - INFO: Preparing to save checkpoint for epoch 7 @ 24000 updates
2023-01-09 22:32:01 - trainer.py[line:431] - INFO: Saving checkpoint to ../../checkpoints/OFA/detection_checkpoints/10_5e-5_512/checkpoint_7_24000.pt
2023-01-09 22:32:04 - trainer.py[line:441] - INFO: Finished saving checkpoint to ../../checkpoints/OFA/detection_checkpoints/10_5e-5_512/checkpoint_7_24000.pt
2023-01-09 22:33:11 - checkpoint_utils.py[line:133] - INFO: Saved checkpoint ../../checkpoints/OFA/detection_checkpoints/10_5e-5_512/checkpoint_7_24000.pt (epoch 7 @ 24000 updates, score 0.0) (writing took 69.86079014418647 seconds)
2023-01-09 22:33:30 - progress_bar.py[line:272] - INFO: epoch 007:   2059 / 3665 loss=5.003, loss_v1=0, loss_v2=0, nll_loss=4.086, ntokens=937.7, nsentences=32, sample_size=937.7, sample_size_v1=0, sample_size_v2=0, ppl=16.98, wps=24.2, ups=0.03, wpb=937.7, bsz=32, num_updates=24010, lr=1.83449e-05, gnorm=2.621, clip=100, loss_scale=256, train_wall=19, gb_free=15.5, wall=68156
2023-01-09 22:33:50 - progress_bar.py[line:272] - INFO: epoch 007:   2069 / 3665 loss=4.979, loss_v1=0, loss_v2=0, nll_loss=4.059, ntokens=867.3, nsentences=32, sample_size=867.3, sample_size_v1=0, sample_size_v2=0, ppl=16.67, wps=444.8, ups=0.51, wpb=867.3, bsz=32, num_updates=24020, lr=1.83304e-05, gnorm=2.709, clip=100, loss_scale=256, train_wall=19, gb_free=15.5, wall=68176
2023-01-09 22:34:09 - progress_bar.py[line:272] - INFO: epoch 007:   2079 / 3665 loss=4.991, loss_v1=0, loss_v2=0, nll_loss=4.071, ntokens=1001.4, nsentences=32, sample_size=1001.4, sample_size_v1=0, sample_size_v2=0, ppl=16.81, wps=511.9, ups=0.51, wpb=1001.4, bsz=32, num_updates=24030, lr=1.83159e-05, gnorm=2.298, clip=100, loss_scale=256, train_wall=20, gb_free=15.4, wall=68195
2023-01-09 22:34:29 - progress_bar.py[line:272] - INFO: epoch 007:   2089 / 3665 loss=5.162, loss_v1=0, loss_v2=0, nll_loss=4.264, ntokens=1022.6, nsentences=32, sample_size=1022.6, sample_size_v1=0, sample_size_v2=0, ppl=19.21, wps=518.2, ups=0.51, wpb=1022.6, bsz=32, num_updates=24040, lr=1.83014e-05, gnorm=2.782, clip=100, loss_scale=256, train_wall=20, gb_free=15.7, wall=68215
2023-01-09 22:34:49 - progress_bar.py[line:272] - INFO: epoch 007:   2099 / 3665 loss=4.907, loss_v1=0, loss_v2=0, nll_loss=3.978, ntokens=809.8, nsentences=32, sample_size=809.8, sample_size_v1=0, sample_size_v2=0, ppl=15.76, wps=412.2, ups=0.51, wpb=809.8, bsz=32, num_updates=24050, lr=1.82868e-05, gnorm=3.017, clip=100, loss_scale=256, train_wall=20, gb_free=15.5, wall=68235
2023-01-09 22:35:08 - progress_bar.py[line:272] - INFO: epoch 007:   2109 / 3665 loss=4.955, loss_v1=0, loss_v2=0, nll_loss=4.031, ntokens=982.2, nsentences=32, sample_size=982.2, sample_size_v1=0, sample_size_v2=0, ppl=16.35, wps=500.6, ups=0.51, wpb=982.2, bsz=32, num_updates=24060, lr=1.82723e-05, gnorm=2.616, clip=100, loss_scale=256, train_wall=20, gb_free=15.5, wall=68254
2023-01-09 22:35:28 - progress_bar.py[line:272] - INFO: epoch 007:   2119 / 3665 loss=5.047, loss_v1=0, loss_v2=0, nll_loss=4.134, ntokens=1060, nsentences=32, sample_size=1060, sample_size_v1=0, sample_size_v2=0, ppl=17.55, wps=536.7, ups=0.51, wpb=1060, bsz=32, num_updates=24070, lr=1.82578e-05, gnorm=2.594, clip=100, loss_scale=256, train_wall=20, gb_free=15.7, wall=68274
2023-01-09 22:35:48 - progress_bar.py[line:272] - INFO: epoch 007:   2129 / 3665 loss=4.994, loss_v1=0, loss_v2=0, nll_loss=4.077, ntokens=824.5, nsentences=32, sample_size=824.5, sample_size_v1=0, sample_size_v2=0, ppl=16.87, wps=420.2, ups=0.51, wpb=824.5, bsz=32, num_updates=24080, lr=1.82433e-05, gnorm=3.063, clip=100, loss_scale=256, train_wall=20, gb_free=15.5, wall=68294
2023-01-09 22:36:07 - progress_bar.py[line:272] - INFO: epoch 007:   2139 / 3665 loss=4.897, loss_v1=0, loss_v2=0, nll_loss=3.968, ntokens=881.1, nsentences=32, sample_size=881.1, sample_size_v1=0, sample_size_v2=0, ppl=15.65, wps=448.3, ups=0.51, wpb=881.1, bsz=32, num_updates=24090, lr=1.82288e-05, gnorm=2.558, clip=100, loss_scale=256, train_wall=20, gb_free=15.4, wall=68314
2023-01-09 22:36:27 - progress_bar.py[line:272] - INFO: epoch 007:   2149 / 3665 loss=5.014, loss_v1=0, loss_v2=0, nll_loss=4.098, ntokens=1145.1, nsentences=32, sample_size=1145.1, sample_size_v1=0, sample_size_v2=0, ppl=17.12, wps=578.9, ups=0.51, wpb=1145.1, bsz=32, num_updates=24100, lr=1.82143e-05, gnorm=2.305, clip=100, loss_scale=256, train_wall=20, gb_free=15.3, wall=68333
2023-01-09 22:36:47 - progress_bar.py[line:272] - INFO: epoch 007:   2159 / 3665 loss=5.013, loss_v1=0, loss_v2=0, nll_loss=4.096, ntokens=831.9, nsentences=32, sample_size=831.9, sample_size_v1=0, sample_size_v2=0, ppl=17.11, wps=421.9, ups=0.51, wpb=831.9, bsz=32, num_updates=24110, lr=1.81998e-05, gnorm=2.785, clip=100, loss_scale=256, train_wall=20, gb_free=14.5, wall=68353
2023-01-09 22:37:06 - progress_bar.py[line:272] - INFO: epoch 007:   2169 / 3665 loss=4.96, loss_v1=0, loss_v2=0, nll_loss=4.039, ntokens=894.6, nsentences=32, sample_size=894.6, sample_size_v1=0, sample_size_v2=0, ppl=16.44, wps=455.1, ups=0.51, wpb=894.6, bsz=32, num_updates=24120, lr=1.81852e-05, gnorm=2.709, clip=100, loss_scale=256, train_wall=20, gb_free=15.5, wall=68373
2023-01-09 22:37:26 - progress_bar.py[line:272] - INFO: epoch 007:   2179 / 3665 loss=5.042, loss_v1=0, loss_v2=0, nll_loss=4.13, ntokens=1088, nsentences=32, sample_size=1088, sample_size_v1=0, sample_size_v2=0, ppl=17.51, wps=543.4, ups=0.5, wpb=1088, bsz=32, num_updates=24130, lr=1.81707e-05, gnorm=2.444, clip=100, loss_scale=256, train_wall=20, gb_free=14.9, wall=68393
2023-01-09 22:37:47 - progress_bar.py[line:272] - INFO: epoch 007:   2189 / 3665 loss=5, loss_v1=0, loss_v2=0, nll_loss=4.08, ntokens=744.9, nsentences=32, sample_size=744.9, sample_size_v1=0, sample_size_v2=0, ppl=16.91, wps=368.7, ups=0.49, wpb=744.9, bsz=32, num_updates=24140, lr=1.81562e-05, gnorm=2.982, clip=100, loss_scale=256, train_wall=20, gb_free=15.5, wall=68413
2023-01-09 22:38:07 - progress_bar.py[line:272] - INFO: epoch 007:   2199 / 3665 loss=5.074, loss_v1=0, loss_v2=0, nll_loss=4.161, ntokens=1031.7, nsentences=32, sample_size=1031.7, sample_size_v1=0, sample_size_v2=0, ppl=17.89, wps=508.1, ups=0.49, wpb=1031.7, bsz=32, num_updates=24150, lr=1.81417e-05, gnorm=2.398, clip=100, loss_scale=256, train_wall=20, gb_free=15.2, wall=68433
2023-01-09 22:38:27 - progress_bar.py[line:272] - INFO: epoch 007:   2209 / 3665 loss=5.011, loss_v1=0, loss_v2=0, nll_loss=4.096, ntokens=1029.6, nsentences=32, sample_size=1029.6, sample_size_v1=0, sample_size_v2=0, ppl=17.1, wps=507.4, ups=0.49, wpb=1029.6, bsz=32, num_updates=24160, lr=1.81272e-05, gnorm=2.621, clip=100, loss_scale=256, train_wall=20, gb_free=15.5, wall=68453
2023-01-09 22:38:47 - progress_bar.py[line:272] - INFO: epoch 007:   2219 / 3665 loss=5.043, loss_v1=0, loss_v2=0, nll_loss=4.131, ntokens=846.6, nsentences=32, sample_size=846.6, sample_size_v1=0, sample_size_v2=0, ppl=17.52, wps=425.6, ups=0.5, wpb=846.6, bsz=32, num_updates=24170, lr=1.81127e-05, gnorm=2.718, clip=100, loss_scale=256, train_wall=20, gb_free=15.2, wall=68473
2023-01-09 22:39:07 - progress_bar.py[line:272] - INFO: epoch 007:   2229 / 3665 loss=4.96, loss_v1=0, loss_v2=0, nll_loss=4.037, ntokens=867.2, nsentences=32, sample_size=867.2, sample_size_v1=0, sample_size_v2=0, ppl=16.42, wps=440.6, ups=0.51, wpb=867.2, bsz=32, num_updates=24180, lr=1.80982e-05, gnorm=2.701, clip=100, loss_scale=256, train_wall=20, gb_free=15.4, wall=68493
2023-01-09 22:39:26 - progress_bar.py[line:272] - INFO: epoch 007:   2239 / 3665 loss=4.922, loss_v1=0, loss_v2=0, nll_loss=3.996, ntokens=1000, nsentences=32, sample_size=1000, sample_size_v1=0, sample_size_v2=0, ppl=15.95, wps=508.4, ups=0.51, wpb=1000, bsz=32, num_updates=24190, lr=1.80837e-05, gnorm=2.472, clip=100, loss_scale=256, train_wall=20, gb_free=15.5, wall=68513
2023-01-09 22:39:46 - progress_bar.py[line:272] - INFO: epoch 007:   2249 / 3665 loss=5.007, loss_v1=0, loss_v2=0, nll_loss=4.091, ntokens=856.4, nsentences=32, sample_size=856.4, sample_size_v1=0, sample_size_v2=0, ppl=17.04, wps=436, ups=0.51, wpb=856.4, bsz=32, num_updates=24200, lr=1.80691e-05, gnorm=2.836, clip=100, loss_scale=256, train_wall=20, gb_free=15.4, wall=68532
2023-01-09 22:40:06 - progress_bar.py[line:272] - INFO: epoch 007:   2259 / 3665 loss=5.044, loss_v1=0, loss_v2=0, nll_loss=4.131, ntokens=953, nsentences=32, sample_size=953, sample_size_v1=0, sample_size_v2=0, ppl=17.52, wps=484.8, ups=0.51, wpb=953, bsz=32, num_updates=24210, lr=1.80546e-05, gnorm=2.588, clip=100, loss_scale=256, train_wall=20, gb_free=15.3, wall=68552
2023-01-09 22:40:25 - progress_bar.py[line:272] - INFO: epoch 007:   2269 / 3665 loss=4.96, loss_v1=0, loss_v2=0, nll_loss=4.037, ntokens=1020.1, nsentences=32, sample_size=1020.1, sample_size_v1=0, sample_size_v2=0, ppl=16.42, wps=517.3, ups=0.51, wpb=1020.1, bsz=32, num_updates=24220, lr=1.80401e-05, gnorm=2.394, clip=100, loss_scale=256, train_wall=20, gb_free=15.3, wall=68572
2023-01-09 22:40:45 - progress_bar.py[line:272] - INFO: epoch 007:   2279 / 3665 loss=5.071, loss_v1=0, loss_v2=0, nll_loss=4.161, ntokens=995.9, nsentences=32, sample_size=995.9, sample_size_v1=0, sample_size_v2=0, ppl=17.89, wps=503.4, ups=0.51, wpb=995.9, bsz=32, num_updates=24230, lr=1.80256e-05, gnorm=2.504, clip=100, loss_scale=256, train_wall=20, gb_free=15.4, wall=68592
2023-01-09 22:41:05 - progress_bar.py[line:272] - INFO: epoch 007:   2289 / 3665 loss=5.008, loss_v1=0, loss_v2=0, nll_loss=4.09, ntokens=893.8, nsentences=32, sample_size=893.8, sample_size_v1=0, sample_size_v2=0, ppl=17.03, wps=452.1, ups=0.51, wpb=893.8, bsz=32, num_updates=24240, lr=1.80111e-05, gnorm=2.738, clip=100, loss_scale=256, train_wall=20, gb_free=15.5, wall=68611
2023-01-09 22:41:25 - progress_bar.py[line:272] - INFO: epoch 007:   2299 / 3665 loss=4.923, loss_v1=0, loss_v2=0, nll_loss=3.996, ntokens=880.2, nsentences=32, sample_size=880.2, sample_size_v1=0, sample_size_v2=0, ppl=15.96, wps=446.7, ups=0.51, wpb=880.2, bsz=32, num_updates=24250, lr=1.79966e-05, gnorm=2.707, clip=100, loss_scale=256, train_wall=20, gb_free=15.6, wall=68631
2023-01-09 22:41:44 - progress_bar.py[line:272] - INFO: epoch 007:   2309 / 3665 loss=4.999, loss_v1=0, loss_v2=0, nll_loss=4.081, ntokens=876.7, nsentences=32, sample_size=876.7, sample_size_v1=0, sample_size_v2=0, ppl=16.92, wps=445.8, ups=0.51, wpb=876.7, bsz=32, num_updates=24260, lr=1.79821e-05, gnorm=2.735, clip=100, loss_scale=256, train_wall=20, gb_free=15.5, wall=68651
2023-01-09 22:42:05 - progress_bar.py[line:272] - INFO: epoch 007:   2319 / 3665 loss=4.999, loss_v1=0, loss_v2=0, nll_loss=4.081, ntokens=834.9, nsentences=32, sample_size=834.9, sample_size_v1=0, sample_size_v2=0, ppl=16.93, wps=413.2, ups=0.49, wpb=834.9, bsz=32, num_updates=24270, lr=1.79675e-05, gnorm=3.372, clip=100, loss_scale=256, train_wall=20, gb_free=15.1, wall=68671
2023-01-09 22:42:25 - progress_bar.py[line:272] - INFO: epoch 007:   2329 / 3665 loss=4.905, loss_v1=0, loss_v2=0, nll_loss=3.977, ntokens=935.9, nsentences=32, sample_size=935.9, sample_size_v1=0, sample_size_v2=0, ppl=15.75, wps=462.5, ups=0.49, wpb=935.9, bsz=32, num_updates=24280, lr=1.7953e-05, gnorm=2.521, clip=100, loss_scale=256, train_wall=20, gb_free=15.1, wall=68691
2023-01-09 22:42:45 - progress_bar.py[line:272] - INFO: epoch 007:   2339 / 3665 loss=5.104, loss_v1=0, loss_v2=0, nll_loss=4.198, ntokens=1196, nsentences=32, sample_size=1196, sample_size_v1=0, sample_size_v2=0, ppl=18.35, wps=586.5, ups=0.49, wpb=1196, bsz=32, num_updates=24290, lr=1.79385e-05, gnorm=2.205, clip=100, loss_scale=256, train_wall=20, gb_free=15.3, wall=68712
2023-01-09 22:43:05 - progress_bar.py[line:272] - INFO: epoch 007:   2349 / 3665 loss=5.023, loss_v1=0, loss_v2=0, nll_loss=4.107, ntokens=924.4, nsentences=32, sample_size=924.4, sample_size_v1=0, sample_size_v2=0, ppl=17.23, wps=457.6, ups=0.49, wpb=924.4, bsz=32, num_updates=24300, lr=1.7924e-05, gnorm=2.597, clip=100, loss_scale=256, train_wall=20, gb_free=14.7, wall=68732
2023-01-09 22:43:25 - progress_bar.py[line:272] - INFO: epoch 007:   2359 / 3665 loss=5.042, loss_v1=0, loss_v2=0, nll_loss=4.13, ntokens=1081, nsentences=32, sample_size=1081, sample_size_v1=0, sample_size_v2=0, ppl=17.51, wps=542.6, ups=0.5, wpb=1081, bsz=32, num_updates=24310, lr=1.79095e-05, gnorm=2.415, clip=100, loss_scale=256, train_wall=20, gb_free=15.5, wall=68752
2023-01-09 22:43:45 - progress_bar.py[line:272] - INFO: epoch 007:   2369 / 3665 loss=4.93, loss_v1=0, loss_v2=0, nll_loss=4.003, ntokens=972.8, nsentences=32, sample_size=972.8, sample_size_v1=0, sample_size_v2=0, ppl=16.03, wps=493.6, ups=0.51, wpb=972.8, bsz=32, num_updates=24320, lr=1.7895e-05, gnorm=2.789, clip=100, loss_scale=256, train_wall=20, gb_free=15, wall=68771
2023-01-09 22:44:05 - progress_bar.py[line:272] - INFO: epoch 007:   2379 / 3665 loss=4.982, loss_v1=0, loss_v2=0, nll_loss=4.061, ntokens=709.2, nsentences=32, sample_size=709.2, sample_size_v1=0, sample_size_v2=0, ppl=16.7, wps=362.3, ups=0.51, wpb=709.2, bsz=32, num_updates=24330, lr=1.78805e-05, gnorm=3.065, clip=100, loss_scale=256, train_wall=20, gb_free=15.7, wall=68791
2023-01-09 22:44:24 - progress_bar.py[line:272] - INFO: epoch 007:   2389 / 3665 loss=5.027, loss_v1=0, loss_v2=0, nll_loss=4.113, ntokens=957.8, nsentences=32, sample_size=957.8, sample_size_v1=0, sample_size_v2=0, ppl=17.3, wps=485.8, ups=0.51, wpb=957.8, bsz=32, num_updates=24340, lr=1.7866e-05, gnorm=2.467, clip=100, loss_scale=256, train_wall=20, gb_free=15.3, wall=68811
2023-01-09 22:44:44 - progress_bar.py[line:272] - INFO: epoch 007:   2399 / 3665 loss=4.925, loss_v1=0, loss_v2=0, nll_loss=3.999, ntokens=1052.6, nsentences=32, sample_size=1052.6, sample_size_v1=0, sample_size_v2=0, ppl=15.99, wps=533.7, ups=0.51, wpb=1052.6, bsz=32, num_updates=24350, lr=1.78514e-05, gnorm=2.401, clip=100, loss_scale=256, train_wall=20, gb_free=15.4, wall=68830
2023-01-09 22:45:04 - progress_bar.py[line:272] - INFO: epoch 007:   2409 / 3665 loss=5.015, loss_v1=0, loss_v2=0, nll_loss=4.099, ntokens=812.7, nsentences=32, sample_size=812.7, sample_size_v1=0, sample_size_v2=0, ppl=17.14, wps=413.8, ups=0.51, wpb=812.7, bsz=32, num_updates=24360, lr=1.78369e-05, gnorm=3.307, clip=100, loss_scale=256, train_wall=20, gb_free=15.3, wall=68850
2023-01-09 22:45:23 - progress_bar.py[line:272] - INFO: epoch 007:   2419 / 3665 loss=4.946, loss_v1=0, loss_v2=0, nll_loss=4.022, ntokens=765.1, nsentences=32, sample_size=765.1, sample_size_v1=0, sample_size_v2=0, ppl=16.25, wps=389.9, ups=0.51, wpb=765.1, bsz=32, num_updates=24370, lr=1.78224e-05, gnorm=3.344, clip=100, loss_scale=256, train_wall=20, gb_free=15.2, wall=68870
2023-01-09 22:45:43 - progress_bar.py[line:272] - INFO: epoch 007:   2429 / 3665 loss=4.859, loss_v1=0, loss_v2=0, nll_loss=3.926, ntokens=903.4, nsentences=32, sample_size=903.4, sample_size_v1=0, sample_size_v2=0, ppl=15.2, wps=459.1, ups=0.51, wpb=903.4, bsz=32, num_updates=24380, lr=1.78079e-05, gnorm=2.808, clip=100, loss_scale=256, train_wall=20, gb_free=15.4, wall=68889
2023-01-09 22:46:03 - progress_bar.py[line:272] - INFO: epoch 007:   2439 / 3665 loss=4.934, loss_v1=0, loss_v2=0, nll_loss=4.01, ntokens=805.6, nsentences=32, sample_size=805.6, sample_size_v1=0, sample_size_v2=0, ppl=16.11, wps=409.5, ups=0.51, wpb=805.6, bsz=32, num_updates=24390, lr=1.77934e-05, gnorm=2.923, clip=100, loss_scale=256, train_wall=20, gb_free=15.6, wall=68909
2023-01-09 22:46:22 - progress_bar.py[line:272] - INFO: epoch 007:   2449 / 3665 loss=4.992, loss_v1=0, loss_v2=0, nll_loss=4.074, ntokens=820.6, nsentences=32, sample_size=820.6, sample_size_v1=0, sample_size_v2=0, ppl=16.84, wps=414.6, ups=0.51, wpb=820.6, bsz=32, num_updates=24400, lr=1.77789e-05, gnorm=3.108, clip=100, loss_scale=256, train_wall=20, gb_free=15.4, wall=68929
2023-01-09 22:46:42 - progress_bar.py[line:272] - INFO: epoch 007:   2459 / 3665 loss=4.938, loss_v1=0, loss_v2=0, nll_loss=4.014, ntokens=921.5, nsentences=32, sample_size=921.5, sample_size_v1=0, sample_size_v2=0, ppl=16.16, wps=464.2, ups=0.5, wpb=921.5, bsz=32, num_updates=24410, lr=1.77644e-05, gnorm=2.579, clip=100, loss_scale=256, train_wall=20, gb_free=15.5, wall=68949
2023-01-09 22:47:02 - progress_bar.py[line:272] - INFO: epoch 007:   2469 / 3665 loss=5.098, loss_v1=0, loss_v2=0, nll_loss=4.19, ntokens=1022.9, nsentences=32, sample_size=1022.9, sample_size_v1=0, sample_size_v2=0, ppl=18.26, wps=512, ups=0.5, wpb=1022.9, bsz=32, num_updates=24420, lr=1.77498e-05, gnorm=2.599, clip=100, loss_scale=256, train_wall=20, gb_free=15.3, wall=68969
2023-01-09 22:47:22 - progress_bar.py[line:272] - INFO: epoch 007:   2479 / 3665 loss=4.968, loss_v1=0, loss_v2=0, nll_loss=4.046, ntokens=786.5, nsentences=32, sample_size=786.5, sample_size_v1=0, sample_size_v2=0, ppl=16.52, wps=396.6, ups=0.5, wpb=786.5, bsz=32, num_updates=24430, lr=1.77353e-05, gnorm=3.001, clip=100, loss_scale=256, train_wall=20, gb_free=15.2, wall=68988
2023-01-09 22:47:42 - progress_bar.py[line:272] - INFO: epoch 007:   2489 / 3665 loss=4.966, loss_v1=0, loss_v2=0, nll_loss=4.045, ntokens=893.7, nsentences=32, sample_size=893.7, sample_size_v1=0, sample_size_v2=0, ppl=16.51, wps=449.7, ups=0.5, wpb=893.7, bsz=32, num_updates=24440, lr=1.77208e-05, gnorm=2.856, clip=100, loss_scale=256, train_wall=20, gb_free=15.2, wall=69008
2023-01-09 22:48:02 - progress_bar.py[line:272] - INFO: epoch 007:   2499 / 3665 loss=5.077, loss_v1=0, loss_v2=0, nll_loss=4.168, ntokens=1200, nsentences=32, sample_size=1200, sample_size_v1=0, sample_size_v2=0, ppl=17.97, wps=601.4, ups=0.5, wpb=1200, bsz=32, num_updates=24450, lr=1.77063e-05, gnorm=2.447, clip=100, loss_scale=256, train_wall=20, gb_free=15.5, wall=69028
2023-01-09 22:48:22 - progress_bar.py[line:272] - INFO: epoch 007:   2509 / 3665 loss=4.894, loss_v1=0, loss_v2=0, nll_loss=3.964, ntokens=688, nsentences=32, sample_size=688, sample_size_v1=0, sample_size_v2=0, ppl=15.6, wps=346.2, ups=0.5, wpb=688, bsz=32, num_updates=24460, lr=1.76918e-05, gnorm=3.326, clip=100, loss_scale=256, train_wall=20, gb_free=15.5, wall=69048
2023-01-09 22:48:42 - progress_bar.py[line:272] - INFO: epoch 007:   2519 / 3665 loss=5.022, loss_v1=0, loss_v2=0, nll_loss=4.107, ntokens=983.2, nsentences=32, sample_size=983.2, sample_size_v1=0, sample_size_v2=0, ppl=17.23, wps=493.2, ups=0.5, wpb=983.2, bsz=32, num_updates=24470, lr=1.76773e-05, gnorm=2.695, clip=100, loss_scale=256, train_wall=20, gb_free=15.2, wall=69068
2023-01-09 22:49:02 - progress_bar.py[line:272] - INFO: epoch 007:   2529 / 3665 loss=5.027, loss_v1=0, loss_v2=0, nll_loss=4.112, ntokens=997.9, nsentences=32, sample_size=997.9, sample_size_v1=0, sample_size_v2=0, ppl=17.29, wps=499.7, ups=0.5, wpb=997.9, bsz=32, num_updates=24480, lr=1.76628e-05, gnorm=2.417, clip=100, loss_scale=256, train_wall=20, gb_free=15.2, wall=69088
2023-01-09 22:49:22 - progress_bar.py[line:272] - INFO: epoch 007:   2539 / 3665 loss=5.013, loss_v1=0, loss_v2=0, nll_loss=4.096, ntokens=860, nsentences=32, sample_size=860, sample_size_v1=0, sample_size_v2=0, ppl=17.1, wps=432.5, ups=0.5, wpb=860, bsz=32, num_updates=24490, lr=1.76483e-05, gnorm=2.686, clip=100, loss_scale=256, train_wall=20, gb_free=15.5, wall=69108
2023-01-09 22:49:28 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 256.0
2023-01-09 22:49:44 - progress_bar.py[line:272] - INFO: epoch 007:   2550 / 3665 loss=4.942, loss_v1=0, loss_v2=0, nll_loss=4.019, ntokens=1007.3, nsentences=32, sample_size=1007.3, sample_size_v1=0, sample_size_v2=0, ppl=16.21, wps=456.1, ups=0.45, wpb=1007.3, bsz=32, num_updates=24500, lr=1.76337e-05, gnorm=2.613, clip=100, loss_scale=256, train_wall=22, gb_free=15, wall=69130
2023-01-09 22:49:44 - train.py[line:445] - INFO: begin validation on "valid" subset
slice_id 0 seek offset 0
slice_id 0 seek offset 0
2023-01-09 22:54:33 - progress_bar.py[line:282] - INFO: epoch 007 | valid on 'valid' subset | loss 4.99 | loss_v1 0 | loss_v2 0 | nll_loss 4.055 | ntokens 116.986 | nsentences 4 | sample_size 116.986 | sample_size_v1 0 | sample_size_v2 0 | AP 0 | total positives 21.7052 | TP 0 | FP 5.22456 | ppl 16.62 | wps 504.8 | wpb 117 | bsz 4 | num_updates 24500 | best_AP 0
2023-01-09 22:54:33 - checkpoint_utils.py[line:64] - INFO: Preparing to save checkpoint for epoch 7 @ 24500 updates
2023-01-09 22:54:33 - trainer.py[line:431] - INFO: Saving checkpoint to ../../checkpoints/OFA/detection_checkpoints/10_5e-5_512/checkpoint_7_24500.pt
2023-01-09 22:54:36 - trainer.py[line:441] - INFO: Finished saving checkpoint to ../../checkpoints/OFA/detection_checkpoints/10_5e-5_512/checkpoint_7_24500.pt
2023-01-09 22:55:46 - checkpoint_utils.py[line:133] - INFO: Saved checkpoint ../../checkpoints/OFA/detection_checkpoints/10_5e-5_512/checkpoint_7_24500.pt (epoch 7 @ 24500 updates, score 0.0) (writing took 72.7888280688785 seconds)
2023-01-09 22:56:05 - progress_bar.py[line:272] - INFO: epoch 007:   2560 / 3665 loss=5.031, loss_v1=0, loss_v2=0, nll_loss=4.117, ntokens=1143.3, nsentences=32, sample_size=1143.3, sample_size_v1=0, sample_size_v2=0, ppl=17.35, wps=30, ups=0.03, wpb=1143.3, bsz=32, num_updates=24510, lr=1.76192e-05, gnorm=2.356, clip=100, loss_scale=256, train_wall=19, gb_free=14.9, wall=69512
2023-01-09 22:56:25 - progress_bar.py[line:272] - INFO: epoch 007:   2570 / 3665 loss=4.859, loss_v1=0, loss_v2=0, nll_loss=3.924, ntokens=643.5, nsentences=32, sample_size=643.5, sample_size_v1=0, sample_size_v2=0, ppl=15.18, wps=332.5, ups=0.52, wpb=643.5, bsz=32, num_updates=24520, lr=1.76047e-05, gnorm=3.468, clip=100, loss_scale=256, train_wall=19, gb_free=15.7, wall=69531
2023-01-09 22:56:44 - progress_bar.py[line:272] - INFO: epoch 007:   2580 / 3665 loss=4.893, loss_v1=0, loss_v2=0, nll_loss=3.963, ntokens=796.7, nsentences=32, sample_size=796.7, sample_size_v1=0, sample_size_v2=0, ppl=15.59, wps=409.5, ups=0.51, wpb=796.7, bsz=32, num_updates=24530, lr=1.75902e-05, gnorm=2.914, clip=100, loss_scale=256, train_wall=19, gb_free=15.2, wall=69550
2023-01-09 22:57:04 - progress_bar.py[line:272] - INFO: epoch 007:   2590 / 3665 loss=4.898, loss_v1=0, loss_v2=0, nll_loss=3.969, ntokens=938.2, nsentences=32, sample_size=938.2, sample_size_v1=0, sample_size_v2=0, ppl=15.66, wps=477.6, ups=0.51, wpb=938.2, bsz=32, num_updates=24540, lr=1.75757e-05, gnorm=2.833, clip=100, loss_scale=256, train_wall=20, gb_free=15.2, wall=69570
2023-01-09 22:57:23 - progress_bar.py[line:272] - INFO: epoch 007:   2600 / 3665 loss=5.071, loss_v1=0, loss_v2=0, nll_loss=4.161, ntokens=800.8, nsentences=32, sample_size=800.8, sample_size_v1=0, sample_size_v2=0, ppl=17.89, wps=409.2, ups=0.51, wpb=800.8, bsz=32, num_updates=24550, lr=1.75612e-05, gnorm=3.052, clip=100, loss_scale=256, train_wall=20, gb_free=15.6, wall=69590
2023-01-09 22:57:43 - progress_bar.py[line:272] - INFO: epoch 007:   2610 / 3665 loss=5.038, loss_v1=0, loss_v2=0, nll_loss=4.125, ntokens=967.1, nsentences=32, sample_size=967.1, sample_size_v1=0, sample_size_v2=0, ppl=17.44, wps=492.7, ups=0.51, wpb=967.1, bsz=32, num_updates=24560, lr=1.75467e-05, gnorm=2.641, clip=100, loss_scale=256, train_wall=20, gb_free=15.3, wall=69609
2023-01-09 22:58:03 - progress_bar.py[line:272] - INFO: epoch 007:   2620 / 3665 loss=4.988, loss_v1=0, loss_v2=0, nll_loss=4.07, ntokens=1076.7, nsentences=32, sample_size=1076.7, sample_size_v1=0, sample_size_v2=0, ppl=16.79, wps=546.9, ups=0.51, wpb=1076.7, bsz=32, num_updates=24570, lr=1.75321e-05, gnorm=2.594, clip=100, loss_scale=256, train_wall=20, gb_free=15.4, wall=69629
2023-01-09 22:58:23 - progress_bar.py[line:272] - INFO: epoch 007:   2630 / 3665 loss=5.137, loss_v1=0, loss_v2=0, nll_loss=4.233, ntokens=1084.5, nsentences=32, sample_size=1084.5, sample_size_v1=0, sample_size_v2=0, ppl=18.81, wps=546.4, ups=0.5, wpb=1084.5, bsz=32, num_updates=24580, lr=1.75176e-05, gnorm=2.635, clip=100, loss_scale=256, train_wall=20, gb_free=15.5, wall=69649
2023-01-09 22:58:42 - progress_bar.py[line:272] - INFO: epoch 007:   2640 / 3665 loss=4.985, loss_v1=0, loss_v2=0, nll_loss=4.065, ntokens=865.3, nsentences=32, sample_size=865.3, sample_size_v1=0, sample_size_v2=0, ppl=16.74, wps=436.7, ups=0.5, wpb=865.3, bsz=32, num_updates=24590, lr=1.75031e-05, gnorm=3.163, clip=100, loss_scale=256, train_wall=20, gb_free=15.3, wall=69669
2023-01-09 22:59:02 - progress_bar.py[line:272] - INFO: epoch 007:   2650 / 3665 loss=4.978, loss_v1=0, loss_v2=0, nll_loss=4.059, ntokens=1073, nsentences=32, sample_size=1073, sample_size_v1=0, sample_size_v2=0, ppl=16.67, wps=540.5, ups=0.5, wpb=1073, bsz=32, num_updates=24600, lr=1.74886e-05, gnorm=2.445, clip=100, loss_scale=256, train_wall=20, gb_free=15.4, wall=69688
2023-01-09 22:59:22 - progress_bar.py[line:272] - INFO: epoch 007:   2660 / 3665 loss=5.057, loss_v1=0, loss_v2=0, nll_loss=4.145, ntokens=995.9, nsentences=32, sample_size=995.9, sample_size_v1=0, sample_size_v2=0, ppl=17.7, wps=492.7, ups=0.49, wpb=995.9, bsz=32, num_updates=24610, lr=1.74741e-05, gnorm=2.531, clip=100, loss_scale=256, train_wall=20, gb_free=15.1, wall=69709
2023-01-09 22:59:43 - progress_bar.py[line:272] - INFO: epoch 007:   2670 / 3665 loss=4.998, loss_v1=0, loss_v2=0, nll_loss=4.079, ntokens=788.2, nsentences=32, sample_size=788.2, sample_size_v1=0, sample_size_v2=0, ppl=16.9, wps=383.4, ups=0.49, wpb=788.2, bsz=32, num_updates=24620, lr=1.74596e-05, gnorm=2.997, clip=100, loss_scale=256, train_wall=21, gb_free=15.4, wall=69729
2023-01-09 23:00:06 - progress_bar.py[line:272] - INFO: epoch 007:   2680 / 3665 loss=4.918, loss_v1=0, loss_v2=0, nll_loss=3.99, ntokens=870.1, nsentences=32, sample_size=870.1, sample_size_v1=0, sample_size_v2=0, ppl=15.89, wps=380.4, ups=0.44, wpb=870.1, bsz=32, num_updates=24630, lr=1.74451e-05, gnorm=2.721, clip=100, loss_scale=256, train_wall=23, gb_free=15.2, wall=69752
2023-01-09 23:00:29 - progress_bar.py[line:272] - INFO: epoch 007:   2690 / 3665 loss=5.023, loss_v1=0, loss_v2=0, nll_loss=4.11, ntokens=1065.4, nsentences=32, sample_size=1065.4, sample_size_v1=0, sample_size_v2=0, ppl=17.26, wps=458.8, ups=0.43, wpb=1065.4, bsz=32, num_updates=24640, lr=1.74306e-05, gnorm=2.364, clip=100, loss_scale=256, train_wall=23, gb_free=14.9, wall=69775
2023-01-09 23:00:51 - progress_bar.py[line:272] - INFO: epoch 007:   2700 / 3665 loss=4.919, loss_v1=0, loss_v2=0, nll_loss=3.992, ntokens=726.7, nsentences=32, sample_size=726.7, sample_size_v1=0, sample_size_v2=0, ppl=15.92, wps=333.1, ups=0.46, wpb=726.7, bsz=32, num_updates=24650, lr=1.7416e-05, gnorm=3.605, clip=100, loss_scale=256, train_wall=22, gb_free=15, wall=69797
2023-01-09 23:01:11 - progress_bar.py[line:272] - INFO: epoch 007:   2710 / 3665 loss=4.935, loss_v1=0, loss_v2=0, nll_loss=4.01, ntokens=973.8, nsentences=32, sample_size=973.8, sample_size_v1=0, sample_size_v2=0, ppl=16.11, wps=479.9, ups=0.49, wpb=973.8, bsz=32, num_updates=24660, lr=1.74015e-05, gnorm=2.577, clip=100, loss_scale=256, train_wall=20, gb_free=15.4, wall=69817
2023-01-09 23:01:32 - progress_bar.py[line:272] - INFO: epoch 007:   2720 / 3665 loss=5.056, loss_v1=0, loss_v2=0, nll_loss=4.144, ntokens=1160.7, nsentences=32, sample_size=1160.7, sample_size_v1=0, sample_size_v2=0, ppl=17.68, wps=569.9, ups=0.49, wpb=1160.7, bsz=32, num_updates=24670, lr=1.7387e-05, gnorm=2.274, clip=100, loss_scale=256, train_wall=20, gb_free=15.5, wall=69838
2023-01-09 23:01:52 - progress_bar.py[line:272] - INFO: epoch 007:   2730 / 3665 loss=4.951, loss_v1=0, loss_v2=0, nll_loss=4.029, ntokens=733.5, nsentences=32, sample_size=733.5, sample_size_v1=0, sample_size_v2=0, ppl=16.32, wps=363.7, ups=0.5, wpb=733.5, bsz=32, num_updates=24680, lr=1.73725e-05, gnorm=3.153, clip=100, loss_scale=256, train_wall=20, gb_free=15.7, wall=69858
2023-01-09 23:02:12 - progress_bar.py[line:272] - INFO: epoch 007:   2740 / 3665 loss=4.976, loss_v1=0, loss_v2=0, nll_loss=4.056, ntokens=938, nsentences=32, sample_size=938, sample_size_v1=0, sample_size_v2=0, ppl=16.63, wps=462.6, ups=0.49, wpb=938, bsz=32, num_updates=24690, lr=1.7358e-05, gnorm=2.863, clip=100, loss_scale=256, train_wall=20, gb_free=15.6, wall=69878
2023-01-09 23:02:32 - progress_bar.py[line:272] - INFO: epoch 007:   2750 / 3665 loss=5.01, loss_v1=0, loss_v2=0, nll_loss=4.093, ntokens=1058.5, nsentences=32, sample_size=1058.5, sample_size_v1=0, sample_size_v2=0, ppl=17.06, wps=522, ups=0.49, wpb=1058.5, bsz=32, num_updates=24700, lr=1.73435e-05, gnorm=2.369, clip=100, loss_scale=256, train_wall=20, gb_free=14.8, wall=69899
2023-01-09 23:02:56 - progress_bar.py[line:272] - INFO: epoch 007:   2760 / 3665 loss=4.961, loss_v1=0, loss_v2=0, nll_loss=4.039, ntokens=714.9, nsentences=32, sample_size=714.9, sample_size_v1=0, sample_size_v2=0, ppl=16.43, wps=301.5, ups=0.42, wpb=714.9, bsz=32, num_updates=24710, lr=1.7329e-05, gnorm=3.119, clip=100, loss_scale=256, train_wall=19, gb_free=15.6, wall=69922
2023-01-09 23:03:16 - progress_bar.py[line:272] - INFO: epoch 007:   2770 / 3665 loss=4.989, loss_v1=0, loss_v2=0, nll_loss=4.069, ntokens=918.8, nsentences=32, sample_size=918.8, sample_size_v1=0, sample_size_v2=0, ppl=16.78, wps=467.9, ups=0.51, wpb=918.8, bsz=32, num_updates=24720, lr=1.73144e-05, gnorm=2.799, clip=100, loss_scale=256, train_wall=20, gb_free=15.4, wall=69942
2023-01-09 23:03:35 - progress_bar.py[line:272] - INFO: epoch 007:   2780 / 3665 loss=4.925, loss_v1=0, loss_v2=0, nll_loss=3.999, ntokens=963.3, nsentences=32, sample_size=963.3, sample_size_v1=0, sample_size_v2=0, ppl=15.99, wps=488.9, ups=0.51, wpb=963.3, bsz=32, num_updates=24730, lr=1.72999e-05, gnorm=2.546, clip=100, loss_scale=256, train_wall=20, gb_free=15.5, wall=69962
2023-01-09 23:03:55 - progress_bar.py[line:272] - INFO: epoch 007:   2790 / 3665 loss=5.045, loss_v1=0, loss_v2=0, nll_loss=4.131, ntokens=988, nsentences=32, sample_size=988, sample_size_v1=0, sample_size_v2=0, ppl=17.52, wps=498.9, ups=0.5, wpb=988, bsz=32, num_updates=24740, lr=1.72854e-05, gnorm=2.624, clip=100, loss_scale=256, train_wall=20, gb_free=15.5, wall=69981
2023-01-09 23:04:15 - progress_bar.py[line:272] - INFO: epoch 007:   2800 / 3665 loss=4.97, loss_v1=0, loss_v2=0, nll_loss=4.049, ntokens=887.6, nsentences=32, sample_size=887.6, sample_size_v1=0, sample_size_v2=0, ppl=16.55, wps=446, ups=0.5, wpb=887.6, bsz=32, num_updates=24750, lr=1.72709e-05, gnorm=2.775, clip=100, loss_scale=256, train_wall=20, gb_free=15.1, wall=70001
2023-01-09 23:04:35 - progress_bar.py[line:272] - INFO: epoch 007:   2810 / 3665 loss=4.983, loss_v1=0, loss_v2=0, nll_loss=4.063, ntokens=1110.7, nsentences=32, sample_size=1110.7, sample_size_v1=0, sample_size_v2=0, ppl=16.71, wps=557.8, ups=0.5, wpb=1110.7, bsz=32, num_updates=24760, lr=1.72564e-05, gnorm=2.466, clip=100, loss_scale=256, train_wall=20, gb_free=15.5, wall=70021
2023-01-09 23:04:55 - progress_bar.py[line:272] - INFO: epoch 007:   2820 / 3665 loss=4.957, loss_v1=0, loss_v2=0, nll_loss=4.034, ntokens=883.4, nsentences=32, sample_size=883.4, sample_size_v1=0, sample_size_v2=0, ppl=16.38, wps=445.5, ups=0.5, wpb=883.4, bsz=32, num_updates=24770, lr=1.72419e-05, gnorm=2.636, clip=100, loss_scale=256, train_wall=20, gb_free=15.5, wall=70041
2023-01-09 23:05:15 - progress_bar.py[line:272] - INFO: epoch 007:   2830 / 3665 loss=5.017, loss_v1=0, loss_v2=0, nll_loss=4.101, ntokens=892.4, nsentences=32, sample_size=892.4, sample_size_v1=0, sample_size_v2=0, ppl=17.16, wps=450, ups=0.5, wpb=892.4, bsz=32, num_updates=24780, lr=1.72274e-05, gnorm=2.907, clip=100, loss_scale=256, train_wall=20, gb_free=14.8, wall=70061
2023-01-09 23:05:34 - progress_bar.py[line:272] - INFO: epoch 007:   2840 / 3665 loss=4.967, loss_v1=0, loss_v2=0, nll_loss=4.047, ntokens=1006.3, nsentences=32, sample_size=1006.3, sample_size_v1=0, sample_size_v2=0, ppl=16.53, wps=507.5, ups=0.5, wpb=1006.3, bsz=32, num_updates=24790, lr=1.72129e-05, gnorm=2.62, clip=100, loss_scale=256, train_wall=20, gb_free=15.4, wall=70081
2023-01-09 23:05:54 - progress_bar.py[line:272] - INFO: epoch 007:   2850 / 3665 loss=5.024, loss_v1=0, loss_v2=0, nll_loss=4.109, ntokens=927, nsentences=32, sample_size=927, sample_size_v1=0, sample_size_v2=0, ppl=17.25, wps=468.6, ups=0.51, wpb=927, bsz=32, num_updates=24800, lr=1.71983e-05, gnorm=2.944, clip=100, loss_scale=256, train_wall=20, gb_free=15.5, wall=70100
2023-01-09 23:06:14 - progress_bar.py[line:272] - INFO: epoch 007:   2860 / 3665 loss=4.952, loss_v1=0, loss_v2=0, nll_loss=4.027, ntokens=776.8, nsentences=32, sample_size=776.8, sample_size_v1=0, sample_size_v2=0, ppl=16.3, wps=392.9, ups=0.51, wpb=776.8, bsz=32, num_updates=24810, lr=1.71838e-05, gnorm=2.837, clip=100, loss_scale=256, train_wall=20, gb_free=15.4, wall=70120
2023-01-09 23:06:34 - progress_bar.py[line:272] - INFO: epoch 007:   2870 / 3665 loss=4.857, loss_v1=0, loss_v2=0, nll_loss=3.923, ntokens=845.7, nsentences=32, sample_size=845.7, sample_size_v1=0, sample_size_v2=0, ppl=15.17, wps=428.7, ups=0.51, wpb=845.7, bsz=32, num_updates=24820, lr=1.71693e-05, gnorm=2.686, clip=100, loss_scale=256, train_wall=20, gb_free=15.1, wall=70140
2023-01-09 23:06:54 - progress_bar.py[line:272] - INFO: epoch 007:   2880 / 3665 loss=5.057, loss_v1=0, loss_v2=0, nll_loss=4.146, ntokens=1029.2, nsentences=32, sample_size=1029.2, sample_size_v1=0, sample_size_v2=0, ppl=17.7, wps=518.1, ups=0.5, wpb=1029.2, bsz=32, num_updates=24830, lr=1.71548e-05, gnorm=2.569, clip=100, loss_scale=256, train_wall=20, gb_free=15.5, wall=70160
2023-01-09 23:07:13 - progress_bar.py[line:272] - INFO: epoch 007:   2890 / 3665 loss=4.919, loss_v1=0, loss_v2=0, nll_loss=3.991, ntokens=736.7, nsentences=32, sample_size=736.7, sample_size_v1=0, sample_size_v2=0, ppl=15.9, wps=372.5, ups=0.51, wpb=736.7, bsz=32, num_updates=24840, lr=1.71403e-05, gnorm=3.113, clip=100, loss_scale=256, train_wall=20, gb_free=15.6, wall=70180
2023-01-09 23:07:33 - progress_bar.py[line:272] - INFO: epoch 007:   2900 / 3665 loss=4.94, loss_v1=0, loss_v2=0, nll_loss=4.015, ntokens=871.9, nsentences=32, sample_size=871.9, sample_size_v1=0, sample_size_v2=0, ppl=16.17, wps=441, ups=0.51, wpb=871.9, bsz=32, num_updates=24850, lr=1.71258e-05, gnorm=2.649, clip=100, loss_scale=256, train_wall=20, gb_free=15.4, wall=70199
2023-01-09 23:07:53 - progress_bar.py[line:272] - INFO: epoch 007:   2910 / 3665 loss=5.035, loss_v1=0, loss_v2=0, nll_loss=4.122, ntokens=1148.7, nsentences=32, sample_size=1148.7, sample_size_v1=0, sample_size_v2=0, ppl=17.41, wps=577, ups=0.5, wpb=1148.7, bsz=32, num_updates=24860, lr=1.71113e-05, gnorm=2.364, clip=100, loss_scale=256, train_wall=20, gb_free=15.4, wall=70219
2023-01-09 23:08:13 - progress_bar.py[line:272] - INFO: epoch 007:   2920 / 3665 loss=5.013, loss_v1=0, loss_v2=0, nll_loss=4.097, ntokens=852.2, nsentences=32, sample_size=852.2, sample_size_v1=0, sample_size_v2=0, ppl=17.12, wps=428.8, ups=0.5, wpb=852.2, bsz=32, num_updates=24870, lr=1.70967e-05, gnorm=2.639, clip=100, loss_scale=256, train_wall=20, gb_free=15.2, wall=70239
2023-01-09 23:08:33 - progress_bar.py[line:272] - INFO: epoch 007:   2930 / 3665 loss=4.905, loss_v1=0, loss_v2=0, nll_loss=3.976, ntokens=811.8, nsentences=32, sample_size=811.8, sample_size_v1=0, sample_size_v2=0, ppl=15.73, wps=409.9, ups=0.5, wpb=811.8, bsz=32, num_updates=24880, lr=1.70822e-05, gnorm=3.219, clip=100, loss_scale=256, train_wall=20, gb_free=15.3, wall=70259
2023-01-09 23:08:53 - progress_bar.py[line:272] - INFO: epoch 007:   2940 / 3665 loss=5.02, loss_v1=0, loss_v2=0, nll_loss=4.103, ntokens=1156.2, nsentences=32, sample_size=1156.2, sample_size_v1=0, sample_size_v2=0, ppl=17.19, wps=580.8, ups=0.5, wpb=1156.2, bsz=32, num_updates=24890, lr=1.70677e-05, gnorm=2.396, clip=100, loss_scale=256, train_wall=20, gb_free=14.9, wall=70279
2023-01-09 23:09:12 - progress_bar.py[line:272] - INFO: epoch 007:   2950 / 3665 loss=5.047, loss_v1=0, loss_v2=0, nll_loss=4.134, ntokens=927.3, nsentences=32, sample_size=927.3, sample_size_v1=0, sample_size_v2=0, ppl=17.56, wps=466.4, ups=0.5, wpb=927.3, bsz=32, num_updates=24900, lr=1.70532e-05, gnorm=2.691, clip=100, loss_scale=256, train_wall=20, gb_free=15.4, wall=70299
2023-01-09 23:09:32 - progress_bar.py[line:272] - INFO: epoch 007:   2960 / 3665 loss=5.056, loss_v1=0, loss_v2=0, nll_loss=4.145, ntokens=998.1, nsentences=32, sample_size=998.1, sample_size_v1=0, sample_size_v2=0, ppl=17.7, wps=503.1, ups=0.5, wpb=998.1, bsz=32, num_updates=24910, lr=1.70387e-05, gnorm=2.736, clip=100, loss_scale=256, train_wall=20, gb_free=15.5, wall=70319
2023-01-09 23:09:52 - progress_bar.py[line:272] - INFO: epoch 007:   2970 / 3665 loss=4.948, loss_v1=0, loss_v2=0, nll_loss=4.024, ntokens=1028, nsentences=32, sample_size=1028, sample_size_v1=0, sample_size_v2=0, ppl=16.27, wps=518.3, ups=0.5, wpb=1028, bsz=32, num_updates=24920, lr=1.70242e-05, gnorm=2.343, clip=100, loss_scale=256, train_wall=20, gb_free=15.2, wall=70338
2023-01-09 23:10:12 - progress_bar.py[line:272] - INFO: epoch 007:   2980 / 3665 loss=5.035, loss_v1=0, loss_v2=0, nll_loss=4.122, ntokens=1024.8, nsentences=32, sample_size=1024.8, sample_size_v1=0, sample_size_v2=0, ppl=17.41, wps=515.4, ups=0.5, wpb=1024.8, bsz=32, num_updates=24930, lr=1.70097e-05, gnorm=2.711, clip=100, loss_scale=256, train_wall=20, gb_free=15.2, wall=70358
2023-01-09 23:10:32 - progress_bar.py[line:272] - INFO: epoch 007:   2990 / 3665 loss=4.968, loss_v1=0, loss_v2=0, nll_loss=4.048, ntokens=865, nsentences=32, sample_size=865, sample_size_v1=0, sample_size_v2=0, ppl=16.54, wps=437.6, ups=0.51, wpb=865, bsz=32, num_updates=24940, lr=1.69952e-05, gnorm=3.003, clip=100, loss_scale=256, train_wall=20, gb_free=14.9, wall=70378
2023-01-09 23:10:52 - progress_bar.py[line:272] - INFO: epoch 007:   3000 / 3665 loss=4.987, loss_v1=0, loss_v2=0, nll_loss=4.068, ntokens=1082.6, nsentences=32, sample_size=1082.6, sample_size_v1=0, sample_size_v2=0, ppl=16.77, wps=544.8, ups=0.5, wpb=1082.6, bsz=32, num_updates=24950, lr=1.69806e-05, gnorm=2.276, clip=100, loss_scale=256, train_wall=20, gb_free=15.1, wall=70398
2023-01-09 23:11:11 - progress_bar.py[line:272] - INFO: epoch 007:   3010 / 3665 loss=4.931, loss_v1=0, loss_v2=0, nll_loss=4.006, ntokens=845, nsentences=32, sample_size=845, sample_size_v1=0, sample_size_v2=0, ppl=16.06, wps=428, ups=0.51, wpb=845, bsz=32, num_updates=24960, lr=1.69661e-05, gnorm=2.875, clip=100, loss_scale=256, train_wall=20, gb_free=15.6, wall=70418
2023-01-09 23:11:31 - progress_bar.py[line:272] - INFO: epoch 007:   3020 / 3665 loss=4.897, loss_v1=0, loss_v2=0, nll_loss=3.966, ntokens=800.1, nsentences=32, sample_size=800.1, sample_size_v1=0, sample_size_v2=0, ppl=15.62, wps=403.8, ups=0.5, wpb=800.1, bsz=32, num_updates=24970, lr=1.69516e-05, gnorm=2.918, clip=100, loss_scale=256, train_wall=20, gb_free=15.6, wall=70438
2023-01-09 23:11:51 - progress_bar.py[line:272] - INFO: epoch 007:   3030 / 3665 loss=4.964, loss_v1=0, loss_v2=0, nll_loss=4.043, ntokens=1080, nsentences=32, sample_size=1080, sample_size_v1=0, sample_size_v2=0, ppl=16.48, wps=540.6, ups=0.5, wpb=1080, bsz=32, num_updates=24980, lr=1.69371e-05, gnorm=2.386, clip=100, loss_scale=256, train_wall=20, gb_free=15.3, wall=70457
2023-01-09 23:12:11 - progress_bar.py[line:272] - INFO: epoch 007:   3040 / 3665 loss=5.026, loss_v1=0, loss_v2=0, nll_loss=4.112, ntokens=990.9, nsentences=32, sample_size=990.9, sample_size_v1=0, sample_size_v2=0, ppl=17.29, wps=498, ups=0.5, wpb=990.9, bsz=32, num_updates=24990, lr=1.69226e-05, gnorm=2.459, clip=100, loss_scale=256, train_wall=20, gb_free=15.3, wall=70477
2023-01-09 23:12:31 - progress_bar.py[line:272] - INFO: epoch 007:   3050 / 3665 loss=4.963, loss_v1=0, loss_v2=0, nll_loss=4.04, ntokens=763.4, nsentences=32, sample_size=763.4, sample_size_v1=0, sample_size_v2=0, ppl=16.45, wps=376.8, ups=0.49, wpb=763.4, bsz=32, num_updates=25000, lr=1.69081e-05, gnorm=3.02, clip=100, loss_scale=256, train_wall=20, gb_free=15.3, wall=70498
2023-01-09 23:12:31 - train.py[line:445] - INFO: begin validation on "valid" subset
slice_id 0 seek offset 0
slice_id 0 seek offset 0
2023-01-09 23:17:41 - progress_bar.py[line:282] - INFO: epoch 007 | valid on 'valid' subset | loss 4.983 | loss_v1 0 | loss_v2 0 | nll_loss 4.046 | ntokens 116.674 | nsentences 4 | sample_size 116.674 | sample_size_v1 0 | sample_size_v2 0 | AP 0 | total positives 21.6454 | TP 0 | FP 5.063 | ppl 16.52 | wps 470.6 | wpb 116.7 | bsz 4 | num_updates 25000 | best_AP 0
2023-01-09 23:17:41 - checkpoint_utils.py[line:64] - INFO: Preparing to save checkpoint for epoch 7 @ 25000 updates
2023-01-09 23:17:41 - trainer.py[line:431] - INFO: Saving checkpoint to ../../checkpoints/OFA/detection_checkpoints/10_5e-5_512/checkpoint_7_25000.pt
2023-01-09 23:17:44 - trainer.py[line:441] - INFO: Finished saving checkpoint to ../../checkpoints/OFA/detection_checkpoints/10_5e-5_512/checkpoint_7_25000.pt
2023-01-09 23:18:52 - checkpoint_utils.py[line:133] - INFO: Saved checkpoint ../../checkpoints/OFA/detection_checkpoints/10_5e-5_512/checkpoint_7_25000.pt (epoch 7 @ 25000 updates, score 0.0) (writing took 71.4490546588786 seconds)
2023-01-09 23:19:12 - progress_bar.py[line:272] - INFO: epoch 007:   3060 / 3665 loss=4.899, loss_v1=0, loss_v2=0, nll_loss=3.968, ntokens=984.4, nsentences=32, sample_size=984.4, sample_size_v1=0, sample_size_v2=0, ppl=15.64, wps=24.6, ups=0.02, wpb=984.4, bsz=32, num_updates=25010, lr=1.68936e-05, gnorm=2.359, clip=100, loss_scale=512, train_wall=20, gb_free=15.1, wall=70898
2023-01-09 23:19:22 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 256.0
2023-01-09 23:19:34 - progress_bar.py[line:272] - INFO: epoch 007:   3071 / 3665 loss=5.064, loss_v1=0, loss_v2=0, nll_loss=4.153, ntokens=1098.9, nsentences=32, sample_size=1098.9, sample_size_v1=0, sample_size_v2=0, ppl=17.79, wps=494.2, ups=0.45, wpb=1098.9, bsz=32, num_updates=25020, lr=1.6879e-05, gnorm=2.266, clip=100, loss_scale=256, train_wall=22, gb_free=15.3, wall=70921
2023-01-09 23:19:55 - progress_bar.py[line:272] - INFO: epoch 007:   3081 / 3665 loss=4.99, loss_v1=0, loss_v2=0, nll_loss=4.072, ntokens=850.9, nsentences=32, sample_size=850.9, sample_size_v1=0, sample_size_v2=0, ppl=16.82, wps=416.9, ups=0.49, wpb=850.9, bsz=32, num_updates=25030, lr=1.68645e-05, gnorm=3.024, clip=100, loss_scale=256, train_wall=20, gb_free=15.3, wall=70941
2023-01-09 23:20:23 - progress_bar.py[line:272] - INFO: epoch 007:   3091 / 3665 loss=4.933, loss_v1=0, loss_v2=0, nll_loss=4.008, ntokens=937.2, nsentences=32, sample_size=937.2, sample_size_v1=0, sample_size_v2=0, ppl=16.09, wps=330.5, ups=0.35, wpb=937.2, bsz=32, num_updates=25040, lr=1.685e-05, gnorm=2.546, clip=100, loss_scale=256, train_wall=28, gb_free=15.2, wall=70969
2023-01-09 23:20:52 - progress_bar.py[line:272] - INFO: epoch 007:   3101 / 3665 loss=5.137, loss_v1=0, loss_v2=0, nll_loss=4.234, ntokens=1115.1, nsentences=32, sample_size=1115.1, sample_size_v1=0, sample_size_v2=0, ppl=18.82, wps=389.2, ups=0.35, wpb=1115.1, bsz=32, num_updates=25050, lr=1.68355e-05, gnorm=2.499, clip=100, loss_scale=256, train_wall=29, gb_free=14.9, wall=70998
2023-01-09 23:21:20 - progress_bar.py[line:272] - INFO: epoch 007:   3111 / 3665 loss=4.98, loss_v1=0, loss_v2=0, nll_loss=4.058, ntokens=789.9, nsentences=32, sample_size=789.9, sample_size_v1=0, sample_size_v2=0, ppl=16.65, wps=283.4, ups=0.36, wpb=789.9, bsz=32, num_updates=25060, lr=1.6821e-05, gnorm=2.834, clip=100, loss_scale=256, train_wall=28, gb_free=15.6, wall=71026
2023-01-09 23:21:46 - progress_bar.py[line:272] - INFO: epoch 007:   3121 / 3665 loss=5.035, loss_v1=0, loss_v2=0, nll_loss=4.122, ntokens=1002.3, nsentences=32, sample_size=1002.3, sample_size_v1=0, sample_size_v2=0, ppl=17.41, wps=385.7, ups=0.38, wpb=1002.3, bsz=32, num_updates=25070, lr=1.68065e-05, gnorm=2.576, clip=100, loss_scale=256, train_wall=26, gb_free=14.6, wall=71052
2023-01-09 23:22:11 - progress_bar.py[line:272] - INFO: epoch 007:   3131 / 3665 loss=4.978, loss_v1=0, loss_v2=0, nll_loss=4.059, ntokens=1067.2, nsentences=32, sample_size=1067.2, sample_size_v1=0, sample_size_v2=0, ppl=16.66, wps=411.8, ups=0.39, wpb=1067.2, bsz=32, num_updates=25080, lr=1.6792e-05, gnorm=2.59, clip=100, loss_scale=256, train_wall=26, gb_free=15.1, wall=71078
2023-01-09 23:22:37 - progress_bar.py[line:272] - INFO: epoch 007:   3141 / 3665 loss=5.037, loss_v1=0, loss_v2=0, nll_loss=4.122, ntokens=915.2, nsentences=32, sample_size=915.2, sample_size_v1=0, sample_size_v2=0, ppl=17.42, wps=354.8, ups=0.39, wpb=915.2, bsz=32, num_updates=25090, lr=1.67775e-05, gnorm=2.658, clip=100, loss_scale=256, train_wall=26, gb_free=14.9, wall=71104
2023-01-09 23:23:03 - progress_bar.py[line:272] - INFO: epoch 007:   3151 / 3665 loss=5.008, loss_v1=0, loss_v2=0, nll_loss=4.092, ntokens=900.6, nsentences=32, sample_size=900.6, sample_size_v1=0, sample_size_v2=0, ppl=17.06, wps=350, ups=0.39, wpb=900.6, bsz=32, num_updates=25100, lr=1.67629e-05, gnorm=2.701, clip=100, loss_scale=256, train_wall=26, gb_free=15.4, wall=71129
2023-01-09 23:23:29 - progress_bar.py[line:272] - INFO: epoch 007:   3161 / 3665 loss=4.892, loss_v1=0, loss_v2=0, nll_loss=3.962, ntokens=857.9, nsentences=32, sample_size=857.9, sample_size_v1=0, sample_size_v2=0, ppl=15.58, wps=333.1, ups=0.39, wpb=857.9, bsz=32, num_updates=25110, lr=1.67484e-05, gnorm=2.737, clip=100, loss_scale=256, train_wall=26, gb_free=15.5, wall=71155
2023-01-09 23:23:55 - progress_bar.py[line:272] - INFO: epoch 007:   3171 / 3665 loss=5.11, loss_v1=0, loss_v2=0, nll_loss=4.202, ntokens=1024.2, nsentences=32, sample_size=1024.2, sample_size_v1=0, sample_size_v2=0, ppl=18.41, wps=394.4, ups=0.39, wpb=1024.2, bsz=32, num_updates=25120, lr=1.67339e-05, gnorm=2.488, clip=100, loss_scale=256, train_wall=26, gb_free=15.4, wall=71181
2023-01-09 23:24:20 - progress_bar.py[line:272] - INFO: epoch 007:   3181 / 3665 loss=4.909, loss_v1=0, loss_v2=0, nll_loss=3.981, ntokens=733.7, nsentences=32, sample_size=733.7, sample_size_v1=0, sample_size_v2=0, ppl=15.79, wps=285.5, ups=0.39, wpb=733.7, bsz=32, num_updates=25130, lr=1.67194e-05, gnorm=3.066, clip=100, loss_scale=256, train_wall=26, gb_free=15.2, wall=71207
2023-01-09 23:24:46 - progress_bar.py[line:272] - INFO: epoch 007:   3191 / 3665 loss=4.953, loss_v1=0, loss_v2=0, nll_loss=4.03, ntokens=1018.8, nsentences=32, sample_size=1018.8, sample_size_v1=0, sample_size_v2=0, ppl=16.33, wps=391, ups=0.38, wpb=1018.8, bsz=32, num_updates=25140, lr=1.67049e-05, gnorm=2.639, clip=100, loss_scale=256, train_wall=26, gb_free=15.3, wall=71233
2023-01-09 23:25:12 - progress_bar.py[line:272] - INFO: epoch 007:   3201 / 3665 loss=5.067, loss_v1=0, loss_v2=0, nll_loss=4.157, ntokens=898.2, nsentences=32, sample_size=898.2, sample_size_v1=0, sample_size_v2=0, ppl=17.84, wps=346, ups=0.39, wpb=898.2, bsz=32, num_updates=25150, lr=1.66904e-05, gnorm=2.749, clip=100, loss_scale=256, train_wall=26, gb_free=15.5, wall=71259
2023-01-09 23:25:38 - progress_bar.py[line:272] - INFO: epoch 007:   3211 / 3665 loss=4.892, loss_v1=0, loss_v2=0, nll_loss=3.961, ntokens=811.4, nsentences=32, sample_size=811.4, sample_size_v1=0, sample_size_v2=0, ppl=15.58, wps=315.9, ups=0.39, wpb=811.4, bsz=32, num_updates=25160, lr=1.66759e-05, gnorm=2.872, clip=100, loss_scale=256, train_wall=26, gb_free=15.4, wall=71284
2023-01-09 23:26:03 - progress_bar.py[line:272] - INFO: epoch 007:   3221 / 3665 loss=5.004, loss_v1=0, loss_v2=0, nll_loss=4.086, ntokens=1354.2, nsentences=32, sample_size=1354.2, sample_size_v1=0, sample_size_v2=0, ppl=16.99, wps=538.6, ups=0.4, wpb=1354.2, bsz=32, num_updates=25170, lr=1.66613e-05, gnorm=2, clip=100, loss_scale=256, train_wall=25, gb_free=15.5, wall=71310
2023-01-09 23:26:26 - progress_bar.py[line:272] - INFO: epoch 007:   3231 / 3665 loss=4.982, loss_v1=0, loss_v2=0, nll_loss=4.063, ntokens=914.5, nsentences=32, sample_size=914.5, sample_size_v1=0, sample_size_v2=0, ppl=16.71, wps=405.4, ups=0.44, wpb=914.5, bsz=32, num_updates=25180, lr=1.66468e-05, gnorm=2.579, clip=100, loss_scale=256, train_wall=23, gb_free=15.5, wall=71332
2023-01-09 23:26:47 - progress_bar.py[line:272] - INFO: epoch 007:   3241 / 3665 loss=4.867, loss_v1=0, loss_v2=0, nll_loss=3.935, ntokens=709, nsentences=32, sample_size=709, sample_size_v1=0, sample_size_v2=0, ppl=15.3, wps=337.8, ups=0.48, wpb=709, bsz=32, num_updates=25190, lr=1.66323e-05, gnorm=3.253, clip=100, loss_scale=256, train_wall=21, gb_free=15.7, wall=71353
2023-01-09 23:27:07 - progress_bar.py[line:272] - INFO: epoch 007:   3251 / 3665 loss=4.941, loss_v1=0, loss_v2=0, nll_loss=4.016, ntokens=1055.3, nsentences=32, sample_size=1055.3, sample_size_v1=0, sample_size_v2=0, ppl=16.18, wps=514.5, ups=0.49, wpb=1055.3, bsz=32, num_updates=25200, lr=1.66178e-05, gnorm=2.307, clip=100, loss_scale=256, train_wall=20, gb_free=15.4, wall=71374
2023-01-09 23:27:28 - progress_bar.py[line:272] - INFO: epoch 007:   3261 / 3665 loss=5.019, loss_v1=0, loss_v2=0, nll_loss=4.102, ntokens=952, nsentences=32, sample_size=952, sample_size_v1=0, sample_size_v2=0, ppl=17.17, wps=467.9, ups=0.49, wpb=952, bsz=32, num_updates=25210, lr=1.66033e-05, gnorm=2.458, clip=100, loss_scale=256, train_wall=20, gb_free=15.6, wall=71394
2023-01-09 23:27:48 - progress_bar.py[line:272] - INFO: epoch 007:   3271 / 3665 loss=4.997, loss_v1=0, loss_v2=0, nll_loss=4.079, ntokens=871.8, nsentences=32, sample_size=871.8, sample_size_v1=0, sample_size_v2=0, ppl=16.9, wps=426.9, ups=0.49, wpb=871.8, bsz=32, num_updates=25220, lr=1.65888e-05, gnorm=2.773, clip=100, loss_scale=256, train_wall=20, gb_free=15.4, wall=71414
2023-01-09 23:28:08 - progress_bar.py[line:272] - INFO: epoch 007:   3281 / 3665 loss=4.968, loss_v1=0, loss_v2=0, nll_loss=4.047, ntokens=886.4, nsentences=32, sample_size=886.4, sample_size_v1=0, sample_size_v2=0, ppl=16.53, wps=435.4, ups=0.49, wpb=886.4, bsz=32, num_updates=25230, lr=1.65743e-05, gnorm=2.743, clip=100, loss_scale=256, train_wall=20, gb_free=15.5, wall=71435
2023-01-09 23:28:29 - progress_bar.py[line:272] - INFO: epoch 007:   3291 / 3665 loss=4.987, loss_v1=0, loss_v2=0, nll_loss=4.068, ntokens=988.2, nsentences=32, sample_size=988.2, sample_size_v1=0, sample_size_v2=0, ppl=16.77, wps=482.2, ups=0.49, wpb=988.2, bsz=32, num_updates=25240, lr=1.65598e-05, gnorm=2.509, clip=100, loss_scale=256, train_wall=20, gb_free=15.1, wall=71455
2023-01-09 23:28:49 - progress_bar.py[line:272] - INFO: epoch 007:   3301 / 3665 loss=4.975, loss_v1=0, loss_v2=0, nll_loss=4.055, ntokens=823, nsentences=32, sample_size=823, sample_size_v1=0, sample_size_v2=0, ppl=16.62, wps=403.9, ups=0.49, wpb=823, bsz=32, num_updates=25250, lr=1.65452e-05, gnorm=2.707, clip=100, loss_scale=256, train_wall=20, gb_free=15.6, wall=71476
2023-01-09 23:29:11 - progress_bar.py[line:272] - INFO: epoch 007:   3311 / 3665 loss=4.905, loss_v1=0, loss_v2=0, nll_loss=3.978, ntokens=869.9, nsentences=32, sample_size=869.9, sample_size_v1=0, sample_size_v2=0, ppl=15.75, wps=410, ups=0.47, wpb=869.9, bsz=32, num_updates=25260, lr=1.65307e-05, gnorm=2.677, clip=100, loss_scale=256, train_wall=21, gb_free=15.3, wall=71497
2023-01-09 23:29:35 - progress_bar.py[line:272] - INFO: epoch 007:   3321 / 3665 loss=5.076, loss_v1=0, loss_v2=0, nll_loss=4.168, ntokens=1075.2, nsentences=32, sample_size=1075.2, sample_size_v1=0, sample_size_v2=0, ppl=17.98, wps=442.6, ups=0.41, wpb=1075.2, bsz=32, num_updates=25270, lr=1.65162e-05, gnorm=2.404, clip=100, loss_scale=256, train_wall=24, gb_free=14.8, wall=71521
/data/hulab/zcai75/anaconda3/envs/vilt/lib/python3.8/site-packages/torch/distributed/launch.py:178: FutureWarning: The module torch.distributed.launch is deprecated
and will be removed in future. Use torchrun.
Note that --use_env is set by default in torchrun.
If your script expects `--local_rank` argument to be set, please
change it to read from `os.environ['LOCAL_RANK']` instead. See 
https://pytorch.org/docs/stable/distributed.html#launch-utility for 
further instructions

  warnings.warn(
WARNING:torch.distributed.elastic.agent.server.api:Received 2 death signal, shutting down workers
WARNING:torch.distributed.elastic.multiprocessing.api:Sending process 1211027 closing signal SIGINT
Traceback (most recent call last):
  File "../../train.py", line 537, in <module>
    cli_main()
  File "../../train.py", line 530, in cli_main
    distributed_utils.call_main(cfg, main)
  File "/home/zcai75/Github/OFA/fairseq/fairseq/distributed/utils.py", line 374, in call_main
    distributed_main(cfg.distributed_training.device_id, main, cfg, kwargs)
  File "/home/zcai75/Github/OFA/fairseq/fairseq/distributed/utils.py", line 348, in distributed_main
    main(cfg, **kwargs)
  File "../../train.py", line 199, in main
    valid_losses, should_stop = train(cfg, trainer, task, epoch_itr)
  File "/data/hulab/zcai75/anaconda3/envs/vilt/lib/python3.8/contextlib.py", line 75, in inner
    return func(*args, **kwds)
  File "../../train.py", line 310, in train
    log_output = trainer.train_step(samples)
  File "/data/hulab/zcai75/anaconda3/envs/vilt/lib/python3.8/contextlib.py", line 75, in inner
    return func(*args, **kwds)
  File "/home/zcai75/Github/OFA/trainer.py", line 773, in train_step
    loss, sample_size_i, logging_output = self.task.train_step(
  File "/home/zcai75/Github/OFA/tasks/ofa_task.py", line 334, in train_step
    loss, sample_size, logging_output = criterion(model, sample, update_num=update_num)
  File "/data/hulab/zcai75/anaconda3/envs/vilt/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/zcai75/Github/OFA/criterions/label_smoothed_cross_entropy.py", line 199, in forward
    net_output = model(**sample["net_input"])
  File "/data/hulab/zcai75/anaconda3/envs/vilt/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/zcai75/Github/OFA/models/ofa/ofa.py", line 89, in forward
    encoder_out = self.encoder(
  File "/data/hulab/zcai75/anaconda3/envs/vilt/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/zcai75/Github/OFA/models/ofa/unify_transformer.py", line 797, in forward
    return self.forward_scriptable(src_tokens,
  File "/home/zcai75/Github/OFA/models/ofa/unify_transformer.py", line 935, in forward_scriptable
    x = layer(x, encoder_padding_mask=encoder_padding_mask if has_pads else None, \
KeyboardInterrupt
Traceback (most recent call last):
  File "/data/hulab/zcai75/anaconda3/envs/vilt/lib/python3.8/runpy.py", line 194, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File "/data/hulab/zcai75/anaconda3/envs/vilt/lib/python3.8/runpy.py", line 87, in _run_code
    exec(code, run_globals)
  File "/data/hulab/zcai75/anaconda3/envs/vilt/lib/python3.8/site-packages/torch/distributed/launch.py", line 193, in <module>
    main()
  File "/data/hulab/zcai75/anaconda3/envs/vilt/lib/python3.8/site-packages/torch/distributed/launch.py", line 189, in main
    launch(args)
  File "/data/hulab/zcai75/anaconda3/envs/vilt/lib/python3.8/site-packages/torch/distributed/launch.py", line 174, in launch
    run(args)
  File "/data/hulab/zcai75/anaconda3/envs/vilt/lib/python3.8/site-packages/torch/distributed/run.py", line 752, in run
    elastic_launch(
  File "/data/hulab/zcai75/anaconda3/envs/vilt/lib/python3.8/site-packages/torch/distributed/launcher/api.py", line 131, in __call__
    return launch_agent(self._config, self._entrypoint, list(args))
  File "/data/hulab/zcai75/anaconda3/envs/vilt/lib/python3.8/site-packages/torch/distributed/launcher/api.py", line 236, in launch_agent
    result = agent.run()
  File "/data/hulab/zcai75/anaconda3/envs/vilt/lib/python3.8/site-packages/torch/distributed/elastic/metrics/api.py", line 125, in wrapper
    result = f(*args, **kwargs)
  File "/data/hulab/zcai75/anaconda3/envs/vilt/lib/python3.8/site-packages/torch/distributed/elastic/agent/server/api.py", line 709, in run
    result = self._invoke_run(role)
  File "/data/hulab/zcai75/anaconda3/envs/vilt/lib/python3.8/site-packages/torch/distributed/elastic/agent/server/api.py", line 850, in _invoke_run
    time.sleep(monitor_interval)
  File "/data/hulab/zcai75/anaconda3/envs/vilt/lib/python3.8/site-packages/torch/distributed/elastic/multiprocessing/api.py", line 60, in _terminate_process_handler
    raise SignalException(f"Process {os.getpid()} got signal: {sigval}", sigval=sigval)
torch.distributed.elastic.multiprocessing.api.SignalException: Process 1211010 got signal: 2

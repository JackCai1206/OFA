/data/hulab/zcai75/anaconda3/envs/vilt/lib/python3.8/site-packages/torch/distributed/launch.py:178: FutureWarning: The module torch.distributed.launch is deprecated
and will be removed in future. Use torchrun.
Note that --use_env is set by default in torchrun.
If your script expects `--local_rank` argument to be set, please
change it to read from `os.environ['LOCAL_RANK']` instead. See 
https://pytorch.org/docs/stable/distributed.html#launch-utility for 
further instructions

  warnings.warn(
WARNING:torch.distributed.run:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
2023-05-05 01:41:31 - utils.py[line:255] - INFO: distributed init (rank 0): env://
2023-05-05 01:41:31 - utils.py[line:261] - INFO: Start init
2023-05-05 01:41:31 - distributed_c10d.py[line:228] - INFO: Added key: store_based_barrier_key:1 to store for rank: 0
2023-05-05 01:41:31 - utils.py[line:255] - INFO: distributed init (rank 1): env://
2023-05-05 01:41:31 - utils.py[line:261] - INFO: Start init
2023-05-05 01:41:31 - distributed_c10d.py[line:228] - INFO: Added key: store_based_barrier_key:1 to store for rank: 1
2023-05-05 01:41:31 - distributed_c10d.py[line:262] - INFO: Rank 1: Completed store-based barrier for key:store_based_barrier_key:1 with 2 nodes.
2023-05-05 01:41:31 - utils.py[line:271] - INFO: initialized host AMD4RTX3090GPU14 as rank 1
single-machine distributed training is initialized.
2023-05-05 01:41:31 - distributed_c10d.py[line:262] - INFO: Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 2 nodes.
2023-05-05 01:41:31 - utils.py[line:271] - INFO: initialized host AMD4RTX3090GPU14 as rank 0
single-machine distributed training is initialized.
2023-05-05 01:41:33 - train.py[line:77] - INFO: {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 10, 'log_format': 'simple', 'log_file': None, 'tensorboard_logdir': './tensorboard/_10_3e-5_512', 'wandb_project': 'OFA-VG', 'azureml_logging': False, 'seed': 1, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': 512, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': '../../ofa_module', 'empty_cache_freq': 0, 'all_gather_list_size': 2097152, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 2, 'distributed_num_procs': 2, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': 'env://', 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': True, 'ddp_backend': 'pytorch_ddp', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': True, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_algorithm': 'LocalSGD', 'localsgd_frequency': 3, 'nprocs_per_node': 2, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False}, 'dataset': {'_name': None, 'num_workers': 0, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': None, 'batch_size': 6, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 10, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': 7, 'disable_validation': False, 'max_tokens_valid': None, 'batch_size_valid': 6, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0}, 'optimization': {'_name': None, 'max_epoch': 10, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 1.0, 'sentence_avg': False, 'update_freq': [8], 'lr': [3e-05], 'stop_min_lr': -1.0, 'use_bmuf': False}, 'checkpoint': {'_name': None, 'save_dir': '../../checkpoints/OFA/sgcls_checkpoints/_10_3e-5_512/tmp', 'restore_file': '../../checkpoints/OFA/sgcls_checkpoints/_20_3e-5_512/tmp/checkpoint8.pt', 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 2, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': 1, 'no_save': False, 'no_epoch_checkpoints': False, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': True, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1, 'use_ema_weights_to_init_param': False, 'use_latest_weights_to_init_ema': False}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 2}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': Namespace(_name='ofa_base', activation_fn='gelu', adam_betas='(0.9,0.999)', adam_eps=1e-08, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, add_type_embedding=True, all_gather_list_size=2097152, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, arch='ofa_base', attention_dropout=0.0, attn_scale_factor=2, azureml_logging=False, batch_size=6, batch_size_valid=6, best_checkpoint_metric='loss', bf16=False, bitfit=False, bpe=None, bpe_dir='../../utils/BPE', broadcast_buffers=False, bucket_cap_mb=25, checkpoint_shard_count=1, checkpoint_suffix='', clip_norm=1.0, code_dict_size=8192, code_image_size=128, code_layernorm_embedding=True, combine_valid_subsets=None, constraint_range=None, cpu=False, cpu_offload=False, criterion='adjust_label_smoothed_cross_entropy', cross_self_attention=False, curriculum=0, data='../../dataset/OFA_data/sgcls/vg_train_full.tsv,../../dataset/OFA_data/sgcls/vg_val_full.tsv', data_buffer_size=10, dataset_impl=None, ddp_backend='pytorch_ddp', ddp_comm_hook='none', decoder_attention_heads=12, decoder_drop_path_rate=0.1, decoder_embed_dim=768, decoder_embed_path=None, decoder_ffn_embed_dim=3072, decoder_input_dim=768, decoder_layerdrop=0, decoder_layers=6, decoder_layers_to_keep=None, decoder_learned_pos=True, decoder_normalize_before=True, decoder_output_dim=768, device_id=0, disable_entangle=True, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_num_procs=2, distributed_port=-1, distributed_rank=0, distributed_world_size=2, drop_worst_after=0, drop_worst_ratio=0.0, dropout=0.1, ema_decay=0.9999, ema_fp32=False, ema_seed_model=None, ema_start_update=0, ema_update_freq=1, empty_cache_freq=0, encoder_attention_heads=12, encoder_drop_path_rate=0.1, encoder_embed_dim=768, encoder_embed_path=None, encoder_ffn_embed_dim=3072, encoder_layerdrop=0, encoder_layers=6, encoder_layers_to_keep=None, encoder_learned_pos=True, encoder_normalize_before=True, end_learning_rate=0.0, entangle_position_embedding=False, eos=2, eval_args='{"beam":5,"max_len_a":0,"max_len_b":200}', eval_print_samples=False, fast_stat_sync=False, find_unused_parameters=True, finetune_from_model=None, fix_batches_to_gpus=False, fixed_validation_seed=7, force_anneal=None, fp16=True, fp16_adam_stats=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=512, fp32_reduce_scatter=False, freeze_decoder_embedding=False, freeze_encoder_embedding=False, gen_subset='test', gradient_as_bucket_view=False, heartbeat_timeout=-1, ignore_eos=False, ignore_prefix_size=0, ignore_unused_valid_subsets=False, image_bucket_size=42, imagenet_default_mean_and_std=False, keep_best_checkpoints=1, keep_interval_updates=-1, keep_interval_updates_pattern=-1, keep_last_epochs=-1, label_smoothing=0.1, layernorm_embedding=True, load_checkpoint_on_all_dp_ranks=False, localsgd_frequency=3, log_file=None, log_format='simple', log_interval=10, lr=[3e-05], lr_scheduler='polynomial_decay', max_epoch=10, max_source_positions=1024, max_src_length=100, max_target_positions=1024, max_tgt_length=100, max_tokens=None, max_tokens_valid=None, max_update=0, max_valid_steps=None, maximize_best_checkpoint_metric=True, memory_efficient_bf16=False, memory_efficient_fp16=False, min_loss_scale=0.0001, min_params_to_wrap=100000000, model_parallel_size=1, no_cross_attention=False, no_epoch_checkpoints=False, no_last_checkpoints=False, no_progress_bar=False, no_reshard_after_forward=False, no_save=False, no_save_optimizer_state=False, no_scale_embedding=True, no_seed_provided=False, no_token_positional_embeddings=False, nprocs_per_node=2, num_bins=480, num_shards=1, num_workers=0, on_cpu_convert_precision=False, optimizer='adam', optimizer_overrides='{}', orig_patch_image_size=256, pad=1, patch_image_size=512, patch_layernorm_embedding=True, patience=-1, pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, plasma_path='/tmp/plasma', pooler_activation_fn='tanh', pooler_classifier='mlp', pooler_dropout=0.0, power=1.0, profile=False, quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, quantization_config_path=None, reg_alpha=1.0, relu_dropout=0.0, report_accuracy=False, required_batch_size_multiple=8, required_seq_len_multiple=1, reset_dataloader=False, reset_logging=False, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, resnet_drop_path_rate=0.0, resnet_type='resnet101', restore_file='../../checkpoints/OFA/sgcls_checkpoints/_20_3e-5_512/tmp/checkpoint8.pt', sample_patch_num=196, save_dir='../../checkpoints/OFA/sgcls_checkpoints/_10_3e-5_512/tmp', save_interval=2, save_interval_updates=0, scale_attn=True, scale_fc=True, scale_heads=True, scale_resids=False, scoring='bleu', seed=1, selected_cols=None, sentence_avg=False, shard_id=0, share_all_embeddings=True, share_decoder_input_output_embed=True, simul_type=None, skip_invalid_size_inputs_valid_test=False, slowmo_algorithm='LocalSGD', slowmo_momentum=None, stop_min_lr=-1.0, stop_time_hours=0, store_ema=False, suppress_crashes=False, sync_bn=False, task='sgcls', tensorboard_logdir='./tensorboard/_10_3e-5_512', threshold_loss_scale=None, token_bucket_size=256, tokenizer=None, total_num_update=1000000, tpu=False, train_subset='train', unk=3, update_freq=[8], use_bmuf=False, use_ema_weights_to_init_param=False, use_latest_weights_to_init_ema=False, use_old_adam=False, use_plasma_view=False, use_rdrop=False, use_sharded_state=False, user_dir='../../ofa_module', valid_subset='valid', validate_after_updates=0, validate_interval=10, validate_interval_updates=0, vg_json_dir=None, wandb_project='OFA-VG', warmup_ratio=0.06, warmup_updates=0, weight_decay=0.01, write_checkpoints_asynchronously=False, zero_sharding='none'), 'task': {'_name': 'sgcls', 'data': '../../dataset/OFA_data/sgcls/vg_train_full.tsv,../../dataset/OFA_data/sgcls/vg_val_full.tsv', 'selected_cols': None, 'bpe': None, 'bpe_dir': '../../utils/BPE', 'max_source_positions': 1024, 'max_target_positions': 1024, 'max_src_length': 100, 'max_tgt_length': 100, 'code_dict_size': 8192, 'patch_image_size': 512, 'orig_patch_image_size': 256, 'num_bins': 480, 'imagenet_default_mean_and_std': False, 'constraint_range': None, 'eval_args': '{"beam":5,"max_len_a":0,"max_len_b":200}', 'eval_print_samples': False, 'vg_json_dir': None}, 'criterion': {'_name': 'adjust_label_smoothed_cross_entropy', 'label_smoothing': 0.1, 'report_accuracy': False, 'ignore_prefix_size': 0, 'ignore_eos': False, 'sentence_avg': False, 'drop_worst_ratio': 0.0, 'drop_worst_after': 0, 'use_rdrop': False, 'reg_alpha': 1.0, 'sample_patch_num': 196, 'constraint_range': None}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9,0.999)', 'adam_eps': 1e-08, 'weight_decay': 0.01, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': False, 'lr': [3e-05]}, 'lr_scheduler': {'_name': 'polynomial_decay', 'warmup_updates': 0, 'warmup_ratio': 0.06, 'force_anneal': None, 'end_learning_rate': 0.0, 'power': 1.0, 'total_num_update': 1000000.0, 'lr': [3e-05]}, 'scoring': {'_name': 'bleu', 'pad': 1, 'eos': 2, 'unk': 3}, 'bpe': None, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}, 'simul_type': None}
2023-05-05 01:41:33 - sg_cls.py[line:82] - INFO: sgcls setup: source dictionary: 50747 types
2023-05-05 01:41:33 - sg_cls.py[line:83] - INFO: sgcls setup: target dictionary: 50747 types
/data/hulab/zcai75/anaconda3/envs/vilt/lib/python3.8/site-packages/torch/functional.py:478: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at  ../aten/src/ATen/native/TensorShape.cpp:2894.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/data/hulab/zcai75/anaconda3/envs/vilt/lib/python3.8/site-packages/torch/functional.py:478: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at  ../aten/src/ATen/native/TensorShape.cpp:2894.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
2023-05-05 01:41:35 - train.py[line:110] - INFO: OFAModel(
  (encoder): TransformerEncoder(
    (encoder_dropout): Dropout(p=0.2, inplace=False)
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(50747, 768, padding_idx=1)
    (layernorm_embedding): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (type_embedding): Embedding(2, 768)
    (embed_images): ResNet(
      (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)
      (layer1): Sequential(
        (0): Bottleneck(
          (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (downsample): Sequential(
            (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (drop_path): Identity()
        )
        (1): Bottleneck(
          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (2): Bottleneck(
          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
      )
      (layer2): Sequential(
        (0): Bottleneck(
          (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (downsample): Sequential(
            (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
            (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (drop_path): Identity()
        )
        (1): Bottleneck(
          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (2): Bottleneck(
          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (3): Bottleneck(
          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
      )
      (layer3): Sequential(
        (0): Bottleneck(
          (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (downsample): Sequential(
            (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)
            (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (drop_path): Identity()
        )
        (1): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (2): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (3): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (4): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (5): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (6): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (7): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (8): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (9): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (10): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (11): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (12): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (13): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (14): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (15): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (16): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (17): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (18): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (19): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (20): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (21): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (22): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
      )
    )
    (image_proj): Linear(in_features=1024, out_features=768, bias=True)
    (patch_layernorm_embedding): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (embed_positions): Embedding(1026, 768)
    (embed_image_positions): Embedding(1765, 768)
    (pos_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (image_pos_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (pos_q_linear): Linear(in_features=768, out_features=768, bias=True)
    (pos_k_linear): Linear(in_features=768, out_features=768, bias=True)
    (layers): ModuleList(
      (0): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): Identity()
      )
      (1): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(p=0.019999999552965164)
      )
      (2): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(p=0.03999999910593033)
      )
      (3): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(p=0.06000000238418579)
      )
      (4): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(p=0.07999999821186066)
      )
      (5): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(p=0.10000000149011612)
      )
    )
    (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (token_rel_pos_table_list): ModuleList(
      (0): Embedding(511, 12)
      (1): Embedding(511, 12)
      (2): Embedding(511, 12)
      (3): Embedding(511, 12)
      (4): Embedding(511, 12)
      (5): Embedding(511, 12)
    )
    (image_rel_pos_table_list): ModuleList(
      (0): Embedding(6892, 12)
      (1): Embedding(6892, 12)
      (2): Embedding(6892, 12)
      (3): Embedding(6892, 12)
      (4): Embedding(6892, 12)
      (5): Embedding(6892, 12)
    )
  )
  (decoder): TransformerDecoder(
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(50747, 768, padding_idx=1)
    (layernorm_embedding): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (embed_positions): Embedding(1026, 768)
    (embed_image_positions): Embedding(1765, 768)
    (pos_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (image_pos_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (self_pos_q_linear): Linear(in_features=768, out_features=768, bias=True)
    (self_pos_k_linear): Linear(in_features=768, out_features=768, bias=True)
    (cross_pos_q_linear): Linear(in_features=768, out_features=768, bias=True)
    (cross_pos_k_linear): Linear(in_features=768, out_features=768, bias=True)
    (code_layernorm_embedding): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (layers): ModuleList(
      (0): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (cross_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): Identity()
      )
      (1): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (cross_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(p=0.019999999552965164)
      )
      (2): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (cross_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(p=0.03999999910593033)
      )
      (3): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (cross_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(p=0.06000000238418579)
      )
      (4): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (cross_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(p=0.07999999821186066)
      )
      (5): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (cross_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(p=0.10000000149011612)
      )
    )
    (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (output_projection): Linear(in_features=768, out_features=50747, bias=False)
    (token_rel_pos_table_list): ModuleList(
      (0): Embedding(511, 12)
      (1): Embedding(511, 12)
      (2): Embedding(511, 12)
      (3): Embedding(511, 12)
      (4): Embedding(511, 12)
      (5): Embedding(511, 12)
    )
    (image_rel_pos_table_list): ModuleList(
      (0): Embedding(6892, 12)
      (1): Embedding(6892, 12)
      (2): Embedding(6892, 12)
      (3): Embedding(6892, 12)
      (4): Embedding(6892, 12)
      (5): Embedding(6892, 12)
    )
  )
  (classification_heads): ModuleDict()
)
2023-05-05 01:41:35 - train.py[line:111] - INFO: task: SGClsTask
2023-05-05 01:41:35 - train.py[line:112] - INFO: model: OFAModel
2023-05-05 01:41:35 - train.py[line:113] - INFO: criterion: AdjustLabelSmoothedCrossEntropyCriterion
2023-05-05 01:41:35 - train.py[line:114] - INFO: num. shared model params: 175,549,256 (num. trained: 175,549,256)
2023-05-05 01:41:35 - train.py[line:121] - INFO: num. expert model params: 0 (num. trained: 0)
local datafile ../../dataset/OFA_data/sgcls/vg_val_full.tsv slice_id 0 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../dataset/OFA_data/sgcls/vg_val_full.tsv slice_id 1 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../dataset/OFA_data/sgcls/vg_val_full.tsv slice_id 0 finished initializing row_count and line_idx-to-offset mapping
file ../../dataset/OFA_data/sgcls/vg_val_full.tsv slice_id 0 row count 11440 total row count 22880
/data/hulab/zcai75/anaconda3/envs/vilt/lib/python3.8/site-packages/torchvision/transforms/transforms.py:332: UserWarning: Argument 'interpolation' of type int is deprecated since 0.13 and will be removed in 0.15. Please use InterpolationMode enum.
  warnings.warn(
2023-05-05 01:41:36 - distributed_c10d.py[line:228] - INFO: Added key: store_based_barrier_key:2 to store for rank: 0
local datafile ../../dataset/OFA_data/sgcls/vg_val_full.tsv slice_id 1 finished initializing row_count and line_idx-to-offset mapping
file ../../dataset/OFA_data/sgcls/vg_val_full.tsv slice_id 1 row count 11440 total row count 22880
/data/hulab/zcai75/anaconda3/envs/vilt/lib/python3.8/site-packages/torchvision/transforms/transforms.py:332: UserWarning: Argument 'interpolation' of type int is deprecated since 0.13 and will be removed in 0.15. Please use InterpolationMode enum.
  warnings.warn(
2023-05-05 01:41:36 - distributed_c10d.py[line:262] - INFO: Rank 0: Completed store-based barrier for key:store_based_barrier_key:2 with 2 nodes.
2023-05-05 01:41:36 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_tokens.weight <- decoder.embed_tokens.weight
2023-05-05 01:41:36 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_tokens.weight <- decoder.output_projection.weight
2023-05-05 01:41:36 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer1.0.conv1.bias
2023-05-05 01:41:36 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer1.0.conv2.bias
2023-05-05 01:41:36 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer1.0.conv3.bias
2023-05-05 01:41:36 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer1.0.downsample.0.bias
2023-05-05 01:41:36 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer1.1.conv1.bias
2023-05-05 01:41:36 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer1.1.conv2.bias
2023-05-05 01:41:36 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer1.1.conv3.bias
2023-05-05 01:41:36 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer1.2.conv1.bias
2023-05-05 01:41:36 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer1.2.conv2.bias
2023-05-05 01:41:36 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer1.2.conv3.bias
2023-05-05 01:41:36 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.0.conv1.bias
2023-05-05 01:41:36 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.0.conv2.bias
2023-05-05 01:41:36 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.0.conv3.bias
2023-05-05 01:41:36 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.0.downsample.0.bias
2023-05-05 01:41:36 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.1.conv1.bias
2023-05-05 01:41:36 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.1.conv2.bias
2023-05-05 01:41:36 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.1.conv3.bias
2023-05-05 01:41:36 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.2.conv1.bias
2023-05-05 01:41:36 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.2.conv2.bias
2023-05-05 01:41:36 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.2.conv3.bias
2023-05-05 01:41:36 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.3.conv1.bias
2023-05-05 01:41:36 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.3.conv2.bias
2023-05-05 01:41:36 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.3.conv3.bias
2023-05-05 01:41:36 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.0.conv1.bias
2023-05-05 01:41:36 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.0.conv2.bias
2023-05-05 01:41:36 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.0.conv3.bias
2023-05-05 01:41:36 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.0.downsample.0.bias
2023-05-05 01:41:36 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.1.conv1.bias
2023-05-05 01:41:36 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.1.conv2.bias
2023-05-05 01:41:36 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.1.conv3.bias
2023-05-05 01:41:36 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.2.conv1.bias
2023-05-05 01:41:36 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.2.conv2.bias
2023-05-05 01:41:36 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.2.conv3.bias
2023-05-05 01:41:36 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.3.conv1.bias
2023-05-05 01:41:36 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.3.conv2.bias
2023-05-05 01:41:36 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.3.conv3.bias
2023-05-05 01:41:36 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.4.conv1.bias
2023-05-05 01:41:36 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.4.conv2.bias
2023-05-05 01:41:36 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.4.conv3.bias
2023-05-05 01:41:36 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.5.conv1.bias
2023-05-05 01:41:36 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.5.conv2.bias
2023-05-05 01:41:36 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.5.conv3.bias
2023-05-05 01:41:36 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.6.conv1.bias
2023-05-05 01:41:36 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.6.conv2.bias
2023-05-05 01:41:36 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.6.conv3.bias
2023-05-05 01:41:36 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.7.conv1.bias
2023-05-05 01:41:36 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.7.conv2.bias
2023-05-05 01:41:36 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.7.conv3.bias
2023-05-05 01:41:36 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.8.conv1.bias
2023-05-05 01:41:36 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.8.conv2.bias
2023-05-05 01:41:36 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.8.conv3.bias
2023-05-05 01:41:36 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.9.conv1.bias
2023-05-05 01:41:36 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.9.conv2.bias
2023-05-05 01:41:36 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.9.conv3.bias
2023-05-05 01:41:36 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.10.conv1.bias
2023-05-05 01:41:36 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.10.conv2.bias
2023-05-05 01:41:36 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.10.conv3.bias
2023-05-05 01:41:36 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.11.conv1.bias
2023-05-05 01:41:36 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.11.conv2.bias
2023-05-05 01:41:36 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.11.conv3.bias
2023-05-05 01:41:36 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.12.conv1.bias
2023-05-05 01:41:36 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.12.conv2.bias
2023-05-05 01:41:36 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.12.conv3.bias
2023-05-05 01:41:36 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.13.conv1.bias
2023-05-05 01:41:36 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.13.conv2.bias
2023-05-05 01:41:36 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.13.conv3.bias
2023-05-05 01:41:36 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.14.conv1.bias
2023-05-05 01:41:36 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.14.conv2.bias
2023-05-05 01:41:36 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.14.conv3.bias
2023-05-05 01:41:36 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.15.conv1.bias
2023-05-05 01:41:36 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.15.conv2.bias
2023-05-05 01:41:36 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.15.conv3.bias
2023-05-05 01:41:36 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.16.conv1.bias
2023-05-05 01:41:36 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.16.conv2.bias
2023-05-05 01:41:36 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.16.conv3.bias
2023-05-05 01:41:36 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.17.conv1.bias
2023-05-05 01:41:36 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.17.conv2.bias
2023-05-05 01:41:36 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.17.conv3.bias
2023-05-05 01:41:36 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.18.conv1.bias
2023-05-05 01:41:36 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.18.conv2.bias
2023-05-05 01:41:36 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.18.conv3.bias
2023-05-05 01:41:36 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.19.conv1.bias
2023-05-05 01:41:36 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.19.conv2.bias
2023-05-05 01:41:36 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.19.conv3.bias
2023-05-05 01:41:36 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.20.conv1.bias
2023-05-05 01:41:36 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.20.conv2.bias
2023-05-05 01:41:36 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.20.conv3.bias
2023-05-05 01:41:36 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.21.conv1.bias
2023-05-05 01:41:36 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.21.conv2.bias
2023-05-05 01:41:36 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.21.conv3.bias
2023-05-05 01:41:36 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.22.conv1.bias
2023-05-05 01:41:36 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.22.conv2.bias
2023-05-05 01:41:36 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.22.conv3.bias
2023-05-05 01:41:36 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- decoder.output_projection.bias
2023-05-05 01:41:36 - utils.py[line:759] - INFO: ***********************CUDA enviroments for all 2 workers***********************
2023-05-05 01:41:36 - utils.py[line:761] - INFO: rank   0: capabilities =  8.6  ; total memory = 23.688 GB ; name = NVIDIA GeForce RTX 3090 Ti              
2023-05-05 01:41:36 - utils.py[line:761] - INFO: rank   1: capabilities =  8.6  ; total memory = 23.688 GB ; name = NVIDIA GeForce RTX 3090 Ti              
2023-05-05 01:41:36 - utils.py[line:767] - INFO: ***********************CUDA enviroments for all 2 workers***********************
2023-05-05 01:41:36 - train.py[line:152] - INFO: training on 2 devices (GPUs/TPUs)
2023-05-05 01:41:36 - train.py[line:157] - INFO: max tokens per device = None and max sentences per device = 6
2023-05-05 01:41:36 - trainer.py[line:458] - INFO: Preparing to load checkpoint ../../checkpoints/OFA/sgcls_checkpoints/_20_3e-5_512/tmp/checkpoint8.pt
local datafile ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 1 begin to initialize row_count and line_idx-to-offset mapping
2023-05-05 01:41:46 - trainer.py[line:617] - INFO: Loaded checkpoint ../../checkpoints/OFA/sgcls_checkpoints/_20_3e-5_512/tmp/checkpoint8.pt (epoch 9 @ 4615 updates)
2023-05-05 01:41:46 - trainer.py[line:639] - INFO: loading train data for epoch 9
local datafile ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 0 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 1 finished initializing row_count and line_idx-to-offset mappinglocal datafile ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 0 finished initializing row_count and line_idx-to-offset mapping

file ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 0 row count 27700 total row count 55400file ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 1 row count 27700 total row count 55400

slice_id 1 seek offset 27700
slice_id 1 seek offset 27700
Total steps 5780, warmup steps 346, warmup_factor 1.0
slice_id 0 seek offset 0
slice_id 0 seek offset 0
Total steps 5780, warmup steps 346, warmup_factor 1.0
wandb: Currently logged in as: jackcai1206. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.15.1 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /home/zcai75/Github/OFA_forked/run_scripts/sgcls/wandb/run-20230505_014158-l6rk9wzv
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run tmp
wandb: ⭐️ View project at https://wandb.ai/jackcai1206/OFA-VG
wandb: 🚀 View run at https://wandb.ai/jackcai1206/OFA-VG/runs/l6rk9wzv
2023-05-05 01:42:04 - trainer.py[line:703] - INFO: begin training epoch 9
2023-05-05 01:42:04 - train.py[line:305] - INFO: Start iterating over samples
2023-05-05 01:42:39 - progress_bar.py[line:272] - INFO: epoch 009:      5 / 578 loss=2.19, loss_v1=0, loss_v2=0, nll_loss=0.969, ntokens=3213.6, nsentences=96, sample_size=3213.6, sample_size_v1=0, sample_size_v2=0, ppl=1.96, wps=505.5, ups=0.16, wpb=3213.6, bsz=96, num_updates=4620, lr=6.40412e-06, gnorm=3.015, clip=100, loss_scale=64, train_wall=35, gb_free=11.5, wall=63
2023-05-05 01:43:41 - progress_bar.py[line:272] - INFO: epoch 009:     15 / 578 loss=2.187, loss_v1=0, loss_v2=0, nll_loss=0.965, ntokens=3079.1, nsentences=96, sample_size=3079.1, sample_size_v1=0, sample_size_v2=0, ppl=1.95, wps=499, ups=0.16, wpb=3079.1, bsz=96, num_updates=4630, lr=6.34891e-06, gnorm=3.301, clip=100, loss_scale=64, train_wall=62, gb_free=12.3, wall=125
2023-05-05 01:44:44 - progress_bar.py[line:272] - INFO: epoch 009:     25 / 578 loss=2.159, loss_v1=0, loss_v2=0, nll_loss=0.935, ntokens=3195.1, nsentences=96, sample_size=3195.1, sample_size_v1=0, sample_size_v2=0, ppl=1.91, wps=511.5, ups=0.16, wpb=3195.1, bsz=96, num_updates=4640, lr=6.29371e-06, gnorm=2.931, clip=100, loss_scale=64, train_wall=62, gb_free=12.1, wall=187
2023-05-05 01:45:46 - progress_bar.py[line:272] - INFO: epoch 009:     35 / 578 loss=2.172, loss_v1=0, loss_v2=0, nll_loss=0.951, ntokens=3011.1, nsentences=96, sample_size=3011.1, sample_size_v1=0, sample_size_v2=0, ppl=1.93, wps=485.2, ups=0.16, wpb=3011.1, bsz=96, num_updates=4650, lr=6.2385e-06, gnorm=2.926, clip=100, loss_scale=64, train_wall=62, gb_free=12.3, wall=249
2023-05-05 01:46:49 - progress_bar.py[line:272] - INFO: epoch 009:     45 / 578 loss=2.069, loss_v1=0, loss_v2=0, nll_loss=0.836, ntokens=3458.2, nsentences=96, sample_size=3458.2, sample_size_v1=0, sample_size_v2=0, ppl=1.78, wps=548, ups=0.16, wpb=3458.2, bsz=96, num_updates=4660, lr=6.18329e-06, gnorm=2.67, clip=100, loss_scale=64, train_wall=63, gb_free=11, wall=313
2023-05-05 01:47:52 - progress_bar.py[line:272] - INFO: epoch 009:     55 / 578 loss=2.149, loss_v1=0, loss_v2=0, nll_loss=0.923, ntokens=3445.3, nsentences=96, sample_size=3445.3, sample_size_v1=0, sample_size_v2=0, ppl=1.9, wps=542.2, ups=0.16, wpb=3445.3, bsz=96, num_updates=4670, lr=6.12808e-06, gnorm=2.698, clip=100, loss_scale=64, train_wall=63, gb_free=11.4, wall=376
2023-05-05 01:48:55 - progress_bar.py[line:272] - INFO: epoch 009:     65 / 578 loss=2.162, loss_v1=0, loss_v2=0, nll_loss=0.937, ntokens=3190.5, nsentences=96, sample_size=3190.5, sample_size_v1=0, sample_size_v2=0, ppl=1.92, wps=512.9, ups=0.16, wpb=3190.5, bsz=96, num_updates=4680, lr=6.07287e-06, gnorm=3.081, clip=100, loss_scale=64, train_wall=62, gb_free=11.3, wall=438
2023-05-05 01:49:56 - progress_bar.py[line:272] - INFO: epoch 009:     75 / 578 loss=2.235, loss_v1=0, loss_v2=0, nll_loss=1.02, ntokens=3039.6, nsentences=96, sample_size=3039.6, sample_size_v1=0, sample_size_v2=0, ppl=2.03, wps=494.7, ups=0.16, wpb=3039.6, bsz=96, num_updates=4690, lr=6.01767e-06, gnorm=2.938, clip=100, loss_scale=64, train_wall=61, gb_free=11.4, wall=500
2023-05-05 01:50:59 - progress_bar.py[line:272] - INFO: epoch 009:     85 / 578 loss=2.229, loss_v1=0, loss_v2=0, nll_loss=1.013, ntokens=3278.3, nsentences=96, sample_size=3278.3, sample_size_v1=0, sample_size_v2=0, ppl=2.02, wps=519.9, ups=0.16, wpb=3278.3, bsz=96, num_updates=4700, lr=5.96246e-06, gnorm=3.047, clip=100, loss_scale=64, train_wall=63, gb_free=12.1, wall=563
2023-05-05 01:52:02 - progress_bar.py[line:272] - INFO: epoch 009:     95 / 578 loss=2.187, loss_v1=0, loss_v2=0, nll_loss=0.967, ntokens=3368.4, nsentences=96, sample_size=3368.4, sample_size_v1=0, sample_size_v2=0, ppl=1.95, wps=531.5, ups=0.16, wpb=3368.4, bsz=96, num_updates=4710, lr=5.90725e-06, gnorm=2.948, clip=100, loss_scale=64, train_wall=63, gb_free=11.7, wall=626
2023-05-05 01:53:06 - progress_bar.py[line:272] - INFO: epoch 009:    105 / 578 loss=2.193, loss_v1=0, loss_v2=0, nll_loss=0.972, ntokens=3303, nsentences=96, sample_size=3303, sample_size_v1=0, sample_size_v2=0, ppl=1.96, wps=521.8, ups=0.16, wpb=3303, bsz=96, num_updates=4720, lr=5.85204e-06, gnorm=2.812, clip=100, loss_scale=64, train_wall=63, gb_free=12.1, wall=690
2023-05-05 01:54:07 - progress_bar.py[line:272] - INFO: epoch 009:    115 / 578 loss=2.2, loss_v1=0, loss_v2=0, nll_loss=0.982, ntokens=3078.1, nsentences=96, sample_size=3078.1, sample_size_v1=0, sample_size_v2=0, ppl=1.97, wps=499.1, ups=0.16, wpb=3078.1, bsz=96, num_updates=4730, lr=5.79683e-06, gnorm=2.809, clip=100, loss_scale=64, train_wall=62, gb_free=11.8, wall=751
2023-05-05 01:55:07 - progress_bar.py[line:272] - INFO: epoch 009:    125 / 578 loss=2.171, loss_v1=0, loss_v2=0, nll_loss=0.95, ntokens=3312.7, nsentences=96, sample_size=3312.7, sample_size_v1=0, sample_size_v2=0, ppl=1.93, wps=560.6, ups=0.17, wpb=3312.7, bsz=96, num_updates=4740, lr=5.74163e-06, gnorm=2.719, clip=100, loss_scale=64, train_wall=59, gb_free=11.7, wall=810
2023-05-05 01:56:04 - progress_bar.py[line:272] - INFO: epoch 009:    135 / 578 loss=2.214, loss_v1=0, loss_v2=0, nll_loss=0.996, ntokens=3195.6, nsentences=96, sample_size=3195.6, sample_size_v1=0, sample_size_v2=0, ppl=1.99, wps=556.8, ups=0.17, wpb=3195.6, bsz=96, num_updates=4750, lr=5.68642e-06, gnorm=2.728, clip=100, loss_scale=64, train_wall=57, gb_free=11.8, wall=868
2023-05-05 01:57:01 - progress_bar.py[line:272] - INFO: epoch 009:    145 / 578 loss=2.234, loss_v1=0, loss_v2=0, nll_loss=1.018, ntokens=3156.7, nsentences=96, sample_size=3156.7, sample_size_v1=0, sample_size_v2=0, ppl=2.03, wps=558.5, ups=0.18, wpb=3156.7, bsz=96, num_updates=4760, lr=5.63121e-06, gnorm=2.721, clip=100, loss_scale=64, train_wall=56, gb_free=12.2, wall=924
2023-05-05 01:57:57 - progress_bar.py[line:272] - INFO: epoch 009:    155 / 578 loss=2.242, loss_v1=0, loss_v2=0, nll_loss=1.028, ntokens=3224.3, nsentences=96, sample_size=3224.3, sample_size_v1=0, sample_size_v2=0, ppl=2.04, wps=571.1, ups=0.18, wpb=3224.3, bsz=96, num_updates=4770, lr=5.576e-06, gnorm=2.594, clip=100, loss_scale=64, train_wall=56, gb_free=12.2, wall=981
2023-05-05 01:58:54 - progress_bar.py[line:272] - INFO: epoch 009:    165 / 578 loss=2.244, loss_v1=0, loss_v2=0, nll_loss=1.029, ntokens=3252.9, nsentences=96, sample_size=3252.9, sample_size_v1=0, sample_size_v2=0, ppl=2.04, wps=571.4, ups=0.18, wpb=3252.9, bsz=96, num_updates=4780, lr=5.52079e-06, gnorm=2.629, clip=100, loss_scale=64, train_wall=57, gb_free=12, wall=1038
2023-05-05 01:59:51 - progress_bar.py[line:272] - INFO: epoch 009:    175 / 578 loss=2.243, loss_v1=0, loss_v2=0, nll_loss=1.029, ntokens=3190.5, nsentences=96, sample_size=3190.5, sample_size_v1=0, sample_size_v2=0, ppl=2.04, wps=563.1, ups=0.18, wpb=3190.5, bsz=96, num_updates=4790, lr=5.46559e-06, gnorm=2.722, clip=100, loss_scale=64, train_wall=57, gb_free=12.3, wall=1094
2023-05-05 02:00:44 - progress_bar.py[line:272] - INFO: epoch 009:    185 / 578 loss=2.233, loss_v1=0, loss_v2=0, nll_loss=1.019, ntokens=3230.5, nsentences=96, sample_size=3230.5, sample_size_v1=0, sample_size_v2=0, ppl=2.03, wps=610, ups=0.19, wpb=3230.5, bsz=96, num_updates=4800, lr=5.41038e-06, gnorm=2.798, clip=100, loss_scale=64, train_wall=53, gb_free=12.2, wall=1147
2023-05-05 02:01:12 - progress_bar.py[line:272] - INFO: epoch 009:    195 / 578 loss=2.229, loss_v1=0, loss_v2=0, nll_loss=1.014, ntokens=3200.6, nsentences=96, sample_size=3200.6, sample_size_v1=0, sample_size_v2=0, ppl=2.02, wps=1113, ups=0.35, wpb=3200.6, bsz=96, num_updates=4810, lr=5.35517e-06, gnorm=2.539, clip=100, loss_scale=64, train_wall=29, gb_free=12.3, wall=1176
2023-05-05 02:01:41 - progress_bar.py[line:272] - INFO: epoch 009:    205 / 578 loss=2.211, loss_v1=0, loss_v2=0, nll_loss=0.994, ntokens=3225.2, nsentences=96, sample_size=3225.2, sample_size_v1=0, sample_size_v2=0, ppl=1.99, wps=1125.6, ups=0.35, wpb=3225.2, bsz=96, num_updates=4820, lr=5.29996e-06, gnorm=2.672, clip=100, loss_scale=64, train_wall=29, gb_free=12.5, wall=1205
2023-05-05 02:02:09 - progress_bar.py[line:272] - INFO: epoch 009:    215 / 578 loss=2.235, loss_v1=0, loss_v2=0, nll_loss=1.02, ntokens=3009.8, nsentences=96, sample_size=3009.8, sample_size_v1=0, sample_size_v2=0, ppl=2.03, wps=1054.4, ups=0.35, wpb=3009.8, bsz=96, num_updates=4830, lr=5.24476e-06, gnorm=2.815, clip=100, loss_scale=64, train_wall=29, gb_free=12.2, wall=1233
2023-05-05 02:02:38 - progress_bar.py[line:272] - INFO: epoch 009:    225 / 578 loss=2.222, loss_v1=0, loss_v2=0, nll_loss=1.006, ntokens=3194.7, nsentences=96, sample_size=3194.7, sample_size_v1=0, sample_size_v2=0, ppl=2.01, wps=1117, ups=0.35, wpb=3194.7, bsz=96, num_updates=4840, lr=5.18955e-06, gnorm=2.621, clip=100, loss_scale=64, train_wall=29, gb_free=11.7, wall=1262
2023-05-05 02:03:07 - progress_bar.py[line:272] - INFO: epoch 009:    235 / 578 loss=2.232, loss_v1=0, loss_v2=0, nll_loss=1.017, ntokens=2935.7, nsentences=96, sample_size=2935.7, sample_size_v1=0, sample_size_v2=0, ppl=2.02, wps=1033.5, ups=0.35, wpb=2935.7, bsz=96, num_updates=4850, lr=5.13434e-06, gnorm=2.87, clip=100, loss_scale=64, train_wall=28, gb_free=12.5, wall=1290
2023-05-05 02:03:35 - progress_bar.py[line:272] - INFO: epoch 009:    245 / 578 loss=2.238, loss_v1=0, loss_v2=0, nll_loss=1.024, ntokens=2950.7, nsentences=96, sample_size=2950.7, sample_size_v1=0, sample_size_v2=0, ppl=2.03, wps=1037.6, ups=0.35, wpb=2950.7, bsz=96, num_updates=4860, lr=5.07913e-06, gnorm=2.805, clip=100, loss_scale=64, train_wall=28, gb_free=12.4, wall=1319
2023-05-05 02:04:03 - progress_bar.py[line:272] - INFO: epoch 009:    255 / 578 loss=2.216, loss_v1=0, loss_v2=0, nll_loss=0.999, ntokens=3188.3, nsentences=96, sample_size=3188.3, sample_size_v1=0, sample_size_v2=0, ppl=2, wps=1118.7, ups=0.35, wpb=3188.3, bsz=96, num_updates=4870, lr=5.02392e-06, gnorm=2.54, clip=100, loss_scale=64, train_wall=28, gb_free=12.2, wall=1347
2023-05-05 02:04:32 - progress_bar.py[line:272] - INFO: epoch 009:    265 / 578 loss=2.23, loss_v1=0, loss_v2=0, nll_loss=1.015, ntokens=3105.2, nsentences=96, sample_size=3105.2, sample_size_v1=0, sample_size_v2=0, ppl=2.02, wps=1090.5, ups=0.35, wpb=3105.2, bsz=96, num_updates=4880, lr=4.96872e-06, gnorm=2.63, clip=100, loss_scale=64, train_wall=28, gb_free=12.1, wall=1376
2023-05-05 02:05:01 - progress_bar.py[line:272] - INFO: epoch 009:    275 / 578 loss=2.229, loss_v1=0, loss_v2=0, nll_loss=1.014, ntokens=3161, nsentences=96, sample_size=3161, sample_size_v1=0, sample_size_v2=0, ppl=2.02, wps=1104.5, ups=0.35, wpb=3161, bsz=96, num_updates=4890, lr=4.91351e-06, gnorm=2.592, clip=100, loss_scale=64, train_wall=29, gb_free=12.3, wall=1404
2023-05-05 02:05:29 - progress_bar.py[line:272] - INFO: epoch 009:    285 / 578 loss=2.206, loss_v1=0, loss_v2=0, nll_loss=0.987, ntokens=3113.8, nsentences=96, sample_size=3113.8, sample_size_v1=0, sample_size_v2=0, ppl=1.98, wps=1086.4, ups=0.35, wpb=3113.8, bsz=96, num_updates=4900, lr=4.8583e-06, gnorm=2.587, clip=100, loss_scale=64, train_wall=29, gb_free=12.2, wall=1433
2023-05-05 02:05:58 - progress_bar.py[line:272] - INFO: epoch 009:    295 / 578 loss=2.235, loss_v1=0, loss_v2=0, nll_loss=1.02, ntokens=3121.3, nsentences=95.6, sample_size=3121.3, sample_size_v1=0, sample_size_v2=0, ppl=2.03, wps=1094.6, ups=0.35, wpb=3121.3, bsz=95.6, num_updates=4910, lr=4.80309e-06, gnorm=2.557, clip=100, loss_scale=64, train_wall=28, gb_free=12.1, wall=1462
2023-05-05 02:06:26 - progress_bar.py[line:272] - INFO: epoch 009:    305 / 578 loss=2.222, loss_v1=0, loss_v2=0, nll_loss=1.006, ntokens=3086, nsentences=96, sample_size=3086, sample_size_v1=0, sample_size_v2=0, ppl=2.01, wps=1078.3, ups=0.35, wpb=3086, bsz=96, num_updates=4920, lr=4.74788e-06, gnorm=2.338, clip=100, loss_scale=64, train_wall=29, gb_free=11.7, wall=1490
2023-05-05 02:06:55 - progress_bar.py[line:272] - INFO: epoch 009:    315 / 578 loss=2.224, loss_v1=0, loss_v2=0, nll_loss=1.009, ntokens=3259.5, nsentences=96, sample_size=3259.5, sample_size_v1=0, sample_size_v2=0, ppl=2.01, wps=1138.9, ups=0.35, wpb=3259.5, bsz=96, num_updates=4930, lr=4.69268e-06, gnorm=2.544, clip=100, loss_scale=64, train_wall=29, gb_free=12.1, wall=1519
2023-05-05 02:07:24 - progress_bar.py[line:272] - INFO: epoch 009:    325 / 578 loss=2.208, loss_v1=0, loss_v2=0, nll_loss=0.99, ntokens=3188.7, nsentences=96, sample_size=3188.7, sample_size_v1=0, sample_size_v2=0, ppl=1.99, wps=1112.5, ups=0.35, wpb=3188.7, bsz=96, num_updates=4940, lr=4.63747e-06, gnorm=2.46, clip=100, loss_scale=64, train_wall=29, gb_free=12.7, wall=1547
2023-05-05 02:07:52 - progress_bar.py[line:272] - INFO: epoch 009:    335 / 578 loss=2.198, loss_v1=0, loss_v2=0, nll_loss=0.979, ntokens=3098.2, nsentences=96, sample_size=3098.2, sample_size_v1=0, sample_size_v2=0, ppl=1.97, wps=1085.1, ups=0.35, wpb=3098.2, bsz=96, num_updates=4950, lr=4.58226e-06, gnorm=2.596, clip=100, loss_scale=64, train_wall=29, gb_free=12.4, wall=1576
2023-05-05 02:08:21 - progress_bar.py[line:272] - INFO: epoch 009:    345 / 578 loss=2.22, loss_v1=0, loss_v2=0, nll_loss=1.004, ntokens=3257.1, nsentences=96, sample_size=3257.1, sample_size_v1=0, sample_size_v2=0, ppl=2.01, wps=1139.3, ups=0.35, wpb=3257.1, bsz=96, num_updates=4960, lr=4.52705e-06, gnorm=2.397, clip=100, loss_scale=64, train_wall=29, gb_free=12.5, wall=1605
2023-05-05 02:08:49 - progress_bar.py[line:272] - INFO: epoch 009:    355 / 578 loss=2.201, loss_v1=0, loss_v2=0, nll_loss=0.982, ntokens=3059.5, nsentences=96, sample_size=3059.5, sample_size_v1=0, sample_size_v2=0, ppl=1.98, wps=1076.3, ups=0.35, wpb=3059.5, bsz=96, num_updates=4970, lr=4.47184e-06, gnorm=2.616, clip=100, loss_scale=64, train_wall=28, gb_free=12.6, wall=1633
2023-05-05 02:09:18 - progress_bar.py[line:272] - INFO: epoch 009:    365 / 578 loss=2.228, loss_v1=0, loss_v2=0, nll_loss=1.012, ntokens=3327.1, nsentences=96, sample_size=3327.1, sample_size_v1=0, sample_size_v2=0, ppl=2.02, wps=1165, ups=0.35, wpb=3327.1, bsz=96, num_updates=4980, lr=4.41664e-06, gnorm=2.494, clip=100, loss_scale=64, train_wall=29, gb_free=12.2, wall=1662
2023-05-05 02:09:46 - progress_bar.py[line:272] - INFO: epoch 009:    375 / 578 loss=2.225, loss_v1=0, loss_v2=0, nll_loss=1.01, ntokens=3378.1, nsentences=96, sample_size=3378.1, sample_size_v1=0, sample_size_v2=0, ppl=2.01, wps=1177.3, ups=0.35, wpb=3378.1, bsz=96, num_updates=4990, lr=4.36143e-06, gnorm=2.556, clip=100, loss_scale=64, train_wall=29, gb_free=12.7, wall=1690
2023-05-05 02:10:15 - progress_bar.py[line:272] - INFO: epoch 009:    385 / 578 loss=2.217, loss_v1=0, loss_v2=0, nll_loss=1.001, ntokens=3261, nsentences=96, sample_size=3261, sample_size_v1=0, sample_size_v2=0, ppl=2, wps=1137, ups=0.35, wpb=3261, bsz=96, num_updates=5000, lr=4.30622e-06, gnorm=2.627, clip=100, loss_scale=64, train_wall=29, gb_free=12.1, wall=1719
2023-05-05 02:10:44 - progress_bar.py[line:272] - INFO: epoch 009:    395 / 578 loss=2.21, loss_v1=0, loss_v2=0, nll_loss=0.991, ntokens=3162, nsentences=96, sample_size=3162, sample_size_v1=0, sample_size_v2=0, ppl=1.99, wps=1105.8, ups=0.35, wpb=3162, bsz=96, num_updates=5010, lr=4.25101e-06, gnorm=2.859, clip=100, loss_scale=64, train_wall=29, gb_free=12, wall=1748
2023-05-05 02:11:12 - progress_bar.py[line:272] - INFO: epoch 009:    405 / 578 loss=2.194, loss_v1=0, loss_v2=0, nll_loss=0.975, ntokens=3061.5, nsentences=96, sample_size=3061.5, sample_size_v1=0, sample_size_v2=0, ppl=1.97, wps=1071.3, ups=0.35, wpb=3061.5, bsz=96, num_updates=5020, lr=4.1958e-06, gnorm=2.876, clip=100, loss_scale=64, train_wall=29, gb_free=12, wall=1776
2023-05-05 02:11:41 - progress_bar.py[line:272] - INFO: epoch 009:    415 / 578 loss=2.226, loss_v1=0, loss_v2=0, nll_loss=1.012, ntokens=3003.6, nsentences=96, sample_size=3003.6, sample_size_v1=0, sample_size_v2=0, ppl=2.02, wps=1053.4, ups=0.35, wpb=3003.6, bsz=96, num_updates=5030, lr=4.1406e-06, gnorm=3.013, clip=100, loss_scale=64, train_wall=28, gb_free=12, wall=1805
2023-05-05 02:12:09 - progress_bar.py[line:272] - INFO: epoch 009:    425 / 578 loss=2.192, loss_v1=0, loss_v2=0, nll_loss=0.972, ntokens=3063, nsentences=96, sample_size=3063, sample_size_v1=0, sample_size_v2=0, ppl=1.96, wps=1072.3, ups=0.35, wpb=3063, bsz=96, num_updates=5040, lr=4.08539e-06, gnorm=2.641, clip=100, loss_scale=64, train_wall=29, gb_free=12.3, wall=1833
2023-05-05 02:12:38 - progress_bar.py[line:272] - INFO: epoch 009:    435 / 578 loss=2.207, loss_v1=0, loss_v2=0, nll_loss=0.989, ntokens=3017.4, nsentences=96, sample_size=3017.4, sample_size_v1=0, sample_size_v2=0, ppl=1.99, wps=1062.5, ups=0.35, wpb=3017.4, bsz=96, num_updates=5050, lr=4.03018e-06, gnorm=2.761, clip=100, loss_scale=64, train_wall=28, gb_free=12.7, wall=1862
2023-05-05 02:13:06 - progress_bar.py[line:272] - INFO: epoch 009:    445 / 578 loss=2.218, loss_v1=0, loss_v2=0, nll_loss=1.001, ntokens=2914.2, nsentences=96, sample_size=2914.2, sample_size_v1=0, sample_size_v2=0, ppl=2, wps=1026.1, ups=0.35, wpb=2914.2, bsz=96, num_updates=5060, lr=3.97497e-06, gnorm=3.13, clip=100, loss_scale=64, train_wall=28, gb_free=12.4, wall=1890
2023-05-05 02:13:35 - progress_bar.py[line:272] - INFO: epoch 009:    455 / 578 loss=2.205, loss_v1=0, loss_v2=0, nll_loss=0.987, ntokens=3109.7, nsentences=96, sample_size=3109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.98, wps=1091.8, ups=0.35, wpb=3109.7, bsz=96, num_updates=5070, lr=3.91976e-06, gnorm=3.125, clip=100, loss_scale=64, train_wall=28, gb_free=12.4, wall=1918
2023-05-05 02:14:03 - progress_bar.py[line:272] - INFO: epoch 009:    465 / 578 loss=2.208, loss_v1=0, loss_v2=0, nll_loss=0.991, ntokens=3096.4, nsentences=96, sample_size=3096.4, sample_size_v1=0, sample_size_v2=0, ppl=1.99, wps=1081.9, ups=0.35, wpb=3096.4, bsz=96, num_updates=5080, lr=3.86456e-06, gnorm=2.761, clip=100, loss_scale=64, train_wall=29, gb_free=11.9, wall=1947
2023-05-05 02:14:32 - progress_bar.py[line:272] - INFO: epoch 009:    475 / 578 loss=2.215, loss_v1=0, loss_v2=0, nll_loss=0.999, ntokens=2883.1, nsentences=96, sample_size=2883.1, sample_size_v1=0, sample_size_v2=0, ppl=2, wps=1014.7, ups=0.35, wpb=2883.1, bsz=96, num_updates=5090, lr=3.80935e-06, gnorm=3.239, clip=100, loss_scale=64, train_wall=28, gb_free=12.7, wall=1976
2023-05-05 02:15:00 - progress_bar.py[line:272] - INFO: epoch 009:    485 / 578 loss=2.185, loss_v1=0, loss_v2=0, nll_loss=0.965, ntokens=2967.7, nsentences=96, sample_size=2967.7, sample_size_v1=0, sample_size_v2=0, ppl=1.95, wps=1045.2, ups=0.35, wpb=2967.7, bsz=96, num_updates=5100, lr=3.75414e-06, gnorm=2.879, clip=100, loss_scale=64, train_wall=28, gb_free=12.6, wall=2004
2023-05-05 02:15:29 - progress_bar.py[line:272] - INFO: epoch 009:    495 / 578 loss=2.186, loss_v1=0, loss_v2=0, nll_loss=0.967, ntokens=3159.6, nsentences=96, sample_size=3159.6, sample_size_v1=0, sample_size_v2=0, ppl=1.95, wps=1106.7, ups=0.35, wpb=3159.6, bsz=96, num_updates=5110, lr=3.69893e-06, gnorm=2.934, clip=100, loss_scale=64, train_wall=29, gb_free=12.2, wall=2032
2023-05-05 02:15:57 - progress_bar.py[line:272] - INFO: epoch 009:    505 / 578 loss=2.182, loss_v1=0, loss_v2=0, nll_loss=0.961, ntokens=3120, nsentences=96, sample_size=3120, sample_size_v1=0, sample_size_v2=0, ppl=1.95, wps=1093.3, ups=0.35, wpb=3120, bsz=96, num_updates=5120, lr=3.64372e-06, gnorm=2.822, clip=100, loss_scale=64, train_wall=29, gb_free=12.5, wall=2061
2023-05-05 02:16:26 - progress_bar.py[line:272] - INFO: epoch 009:    515 / 578 loss=2.186, loss_v1=0, loss_v2=0, nll_loss=0.967, ntokens=3191.5, nsentences=96, sample_size=3191.5, sample_size_v1=0, sample_size_v2=0, ppl=1.95, wps=1118.8, ups=0.35, wpb=3191.5, bsz=96, num_updates=5130, lr=3.58852e-06, gnorm=2.839, clip=100, loss_scale=128, train_wall=28, gb_free=11.5, wall=2090
2023-05-05 02:16:54 - progress_bar.py[line:272] - INFO: epoch 009:    525 / 578 loss=2.2, loss_v1=0, loss_v2=0, nll_loss=0.981, ntokens=3201.5, nsentences=96, sample_size=3201.5, sample_size_v1=0, sample_size_v2=0, ppl=1.97, wps=1119.5, ups=0.35, wpb=3201.5, bsz=96, num_updates=5140, lr=3.53331e-06, gnorm=3.076, clip=100, loss_scale=128, train_wall=29, gb_free=12.3, wall=2118
2023-05-05 02:17:03 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2023-05-05 02:17:26 - progress_bar.py[line:272] - INFO: epoch 009:    536 / 578 loss=2.201, loss_v1=0, loss_v2=0, nll_loss=0.983, ntokens=3029.9, nsentences=96, sample_size=3029.9, sample_size_v1=0, sample_size_v2=0, ppl=1.98, wps=970.4, ups=0.32, wpb=3029.9, bsz=96, num_updates=5150, lr=3.4781e-06, gnorm=3.328, clip=100, loss_scale=64, train_wall=31, gb_free=11.9, wall=2149
2023-05-05 02:17:54 - progress_bar.py[line:272] - INFO: epoch 009:    546 / 578 loss=2.193, loss_v1=0, loss_v2=0, nll_loss=0.974, ntokens=3115.7, nsentences=96, sample_size=3115.7, sample_size_v1=0, sample_size_v2=0, ppl=1.96, wps=1083.1, ups=0.35, wpb=3115.7, bsz=96, num_updates=5160, lr=3.42289e-06, gnorm=3.196, clip=100, loss_scale=64, train_wall=29, gb_free=12.3, wall=2178
2023-05-05 02:18:23 - progress_bar.py[line:272] - INFO: epoch 009:    556 / 578 loss=2.196, loss_v1=0, loss_v2=0, nll_loss=0.976, ntokens=3293.5, nsentences=96, sample_size=3293.5, sample_size_v1=0, sample_size_v2=0, ppl=1.97, wps=1137.8, ups=0.35, wpb=3293.5, bsz=96, num_updates=5170, lr=3.36768e-06, gnorm=2.989, clip=100, loss_scale=64, train_wall=29, gb_free=12.5, wall=2207
2023-05-05 02:18:52 - progress_bar.py[line:272] - INFO: epoch 009:    566 / 578 loss=2.196, loss_v1=0, loss_v2=0, nll_loss=0.977, ntokens=3228.4, nsentences=96, sample_size=3228.4, sample_size_v1=0, sample_size_v2=0, ppl=1.97, wps=1126.6, ups=0.35, wpb=3228.4, bsz=96, num_updates=5180, lr=3.31248e-06, gnorm=3.074, clip=100, loss_scale=64, train_wall=29, gb_free=11.9, wall=2236
2023-05-05 02:19:21 - progress_bar.py[line:272] - INFO: epoch 009:    576 / 578 loss=2.215, loss_v1=0, loss_v2=0, nll_loss=0.999, ntokens=3137.9, nsentences=96, sample_size=3137.9, sample_size_v1=0, sample_size_v2=0, ppl=2, wps=1096.4, ups=0.35, wpb=3137.9, bsz=96, num_updates=5190, lr=3.25727e-06, gnorm=3.174, clip=100, loss_scale=64, train_wall=29, gb_free=12.3, wall=2264
2023-05-05 02:19:24 - train.py[line:332] - INFO: end of epoch 9 (average epoch stats below)
local datafile ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 1 begin to initialize row_count and line_idx-to-offset mapping
2023-05-05 02:19:24 - progress_bar.py[line:282] - INFO: epoch 009 | loss 2.206 | loss_v1 0 | loss_v2 0 | nll_loss 0.988 | ntokens 3151.6 | nsentences 95.847 | sample_size 3151.6 | sample_size_v1 0 | sample_size_v2 0 | ppl 1.98 | wps 814.1 | ups 0.26 | wpb 3151.6 | bsz 95.8 | num_updates 5192 | lr 3.24623e-06 | gnorm 2.809 | clip 100 | loss_scale 64 | train_wall 2237 | gb_free 13.1 | wall 2268
2023-05-05 02:19:24 - trainer.py[line:639] - INFO: loading train data for epoch 10
local datafile ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 0 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 0 finished initializing row_count and line_idx-to-offset mapping
file ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 0 row count 27700 total row count 55400
/data/hulab/zcai75/anaconda3/envs/vilt/lib/python3.8/site-packages/torchvision/transforms/transforms.py:332: UserWarning: Argument 'interpolation' of type int is deprecated since 0.13 and will be removed in 0.15. Please use InterpolationMode enum.
  warnings.warn(
slice_id 0 seek offset 0
2023-05-05 02:19:26 - trainer.py[line:703] - INFO: begin training epoch 10
2023-05-05 02:19:26 - train.py[line:305] - INFO: Start iterating over samples
local datafile ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 1 finished initializing row_count and line_idx-to-offset mapping
file ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 1 row count 27700 total row count 55400
slice_id 1 seek offset 27700
2023-05-05 02:19:49 - progress_bar.py[line:272] - INFO: epoch 010:      8 / 578 loss=2.196, loss_v1=0, loss_v2=0, nll_loss=0.977, ntokens=2869, nsentences=87.6, sample_size=2869, sample_size_v1=0, sample_size_v2=0, ppl=1.97, wps=997.8, ups=0.35, wpb=2869, bsz=87.6, num_updates=5200, lr=3.20206e-06, gnorm=3.678, clip=100, loss_scale=64, train_wall=27, gb_free=12.2, wall=2293
2023-05-05 02:20:18 - progress_bar.py[line:272] - INFO: epoch 010:     18 / 578 loss=2.174, loss_v1=0, loss_v2=0, nll_loss=0.951, ntokens=3032.5, nsentences=96, sample_size=3032.5, sample_size_v1=0, sample_size_v2=0, ppl=1.93, wps=1052.6, ups=0.35, wpb=3032.5, bsz=96, num_updates=5210, lr=3.14685e-06, gnorm=3.477, clip=100, loss_scale=64, train_wall=29, gb_free=11.9, wall=2322
2023-05-05 02:20:47 - progress_bar.py[line:272] - INFO: epoch 010:     28 / 578 loss=2.121, loss_v1=0, loss_v2=0, nll_loss=0.891, ntokens=3249.3, nsentences=96, sample_size=3249.3, sample_size_v1=0, sample_size_v2=0, ppl=1.85, wps=1120.4, ups=0.34, wpb=3249.3, bsz=96, num_updates=5220, lr=3.09165e-06, gnorm=2.884, clip=100, loss_scale=64, train_wall=29, gb_free=12, wall=2351
2023-05-05 02:21:16 - progress_bar.py[line:272] - INFO: epoch 010:     38 / 578 loss=2.142, loss_v1=0, loss_v2=0, nll_loss=0.916, ntokens=3042.7, nsentences=96, sample_size=3042.7, sample_size_v1=0, sample_size_v2=0, ppl=1.89, wps=1052.4, ups=0.35, wpb=3042.7, bsz=96, num_updates=5230, lr=3.03644e-06, gnorm=3.037, clip=100, loss_scale=64, train_wall=29, gb_free=12.2, wall=2380
2023-05-05 02:21:46 - progress_bar.py[line:272] - INFO: epoch 010:     48 / 578 loss=2.087, loss_v1=0, loss_v2=0, nll_loss=0.855, ntokens=3610.6, nsentences=96, sample_size=3610.6, sample_size_v1=0, sample_size_v2=0, ppl=1.81, wps=1219.5, ups=0.34, wpb=3610.6, bsz=96, num_updates=5240, lr=2.98123e-06, gnorm=2.594, clip=100, loss_scale=64, train_wall=30, gb_free=11.6, wall=2409
2023-05-05 02:22:15 - progress_bar.py[line:272] - INFO: epoch 010:     58 / 578 loss=2.134, loss_v1=0, loss_v2=0, nll_loss=0.908, ntokens=3273.1, nsentences=96, sample_size=3273.1, sample_size_v1=0, sample_size_v2=0, ppl=1.88, wps=1118.2, ups=0.34, wpb=3273.1, bsz=96, num_updates=5250, lr=2.92602e-06, gnorm=2.852, clip=100, loss_scale=64, train_wall=29, gb_free=11.6, wall=2439
2023-05-05 02:22:44 - progress_bar.py[line:272] - INFO: epoch 010:     68 / 578 loss=2.167, loss_v1=0, loss_v2=0, nll_loss=0.943, ntokens=3149.2, nsentences=96, sample_size=3149.2, sample_size_v1=0, sample_size_v2=0, ppl=1.92, wps=1093.7, ups=0.35, wpb=3149.2, bsz=96, num_updates=5260, lr=2.87081e-06, gnorm=3.026, clip=100, loss_scale=64, train_wall=29, gb_free=12.1, wall=2468
2023-05-05 02:23:13 - progress_bar.py[line:272] - INFO: epoch 010:     78 / 578 loss=2.218, loss_v1=0, loss_v2=0, nll_loss=1.002, ntokens=3106.3, nsentences=96, sample_size=3106.3, sample_size_v1=0, sample_size_v2=0, ppl=2, wps=1072.4, ups=0.35, wpb=3106.3, bsz=96, num_updates=5270, lr=2.81561e-06, gnorm=3.01, clip=100, loss_scale=64, train_wall=29, gb_free=11.7, wall=2497
2023-05-05 02:23:42 - progress_bar.py[line:272] - INFO: epoch 010:     88 / 578 loss=2.203, loss_v1=0, loss_v2=0, nll_loss=0.984, ntokens=3333.6, nsentences=96, sample_size=3333.6, sample_size_v1=0, sample_size_v2=0, ppl=1.98, wps=1134.3, ups=0.34, wpb=3333.6, bsz=96, num_updates=5280, lr=2.7604e-06, gnorm=3.037, clip=100, loss_scale=64, train_wall=29, gb_free=11.8, wall=2526
2023-05-05 02:24:11 - progress_bar.py[line:272] - INFO: epoch 010:     98 / 578 loss=2.173, loss_v1=0, loss_v2=0, nll_loss=0.95, ntokens=3301.9, nsentences=96, sample_size=3301.9, sample_size_v1=0, sample_size_v2=0, ppl=1.93, wps=1125.7, ups=0.34, wpb=3301.9, bsz=96, num_updates=5290, lr=2.70519e-06, gnorm=3, clip=100, loss_scale=64, train_wall=29, gb_free=12, wall=2555
2023-05-05 02:24:41 - progress_bar.py[line:272] - INFO: epoch 010:    108 / 578 loss=2.184, loss_v1=0, loss_v2=0, nll_loss=0.962, ntokens=3295.4, nsentences=96, sample_size=3295.4, sample_size_v1=0, sample_size_v2=0, ppl=1.95, wps=1125.4, ups=0.34, wpb=3295.4, bsz=96, num_updates=5300, lr=2.64998e-06, gnorm=2.979, clip=100, loss_scale=64, train_wall=29, gb_free=12, wall=2585
2023-05-05 02:25:10 - progress_bar.py[line:272] - INFO: epoch 010:    118 / 578 loss=2.186, loss_v1=0, loss_v2=0, nll_loss=0.965, ntokens=3146.8, nsentences=96, sample_size=3146.8, sample_size_v1=0, sample_size_v2=0, ppl=1.95, wps=1086.5, ups=0.35, wpb=3146.8, bsz=96, num_updates=5310, lr=2.59477e-06, gnorm=3.182, clip=100, loss_scale=64, train_wall=29, gb_free=11.9, wall=2614
2023-05-05 02:25:39 - progress_bar.py[line:272] - INFO: epoch 010:    128 / 578 loss=2.171, loss_v1=0, loss_v2=0, nll_loss=0.949, ntokens=3314.9, nsentences=96, sample_size=3314.9, sample_size_v1=0, sample_size_v2=0, ppl=1.93, wps=1137.3, ups=0.34, wpb=3314.9, bsz=96, num_updates=5320, lr=2.53957e-06, gnorm=2.97, clip=100, loss_scale=64, train_wall=29, gb_free=11.7, wall=2643
2023-05-05 02:26:08 - progress_bar.py[line:272] - INFO: epoch 010:    138 / 578 loss=2.209, loss_v1=0, loss_v2=0, nll_loss=0.992, ntokens=3034.5, nsentences=96, sample_size=3034.5, sample_size_v1=0, sample_size_v2=0, ppl=1.99, wps=1055, ups=0.35, wpb=3034.5, bsz=96, num_updates=5330, lr=2.48436e-06, gnorm=3.087, clip=100, loss_scale=64, train_wall=29, gb_free=11.8, wall=2671
2023-05-05 02:26:36 - progress_bar.py[line:272] - INFO: epoch 010:    148 / 578 loss=2.224, loss_v1=0, loss_v2=0, nll_loss=1.008, ntokens=3289.2, nsentences=96, sample_size=3289.2, sample_size_v1=0, sample_size_v2=0, ppl=2.01, wps=1142, ups=0.35, wpb=3289.2, bsz=96, num_updates=5340, lr=2.42915e-06, gnorm=2.825, clip=100, loss_scale=64, train_wall=29, gb_free=11.9, wall=2700
2023-05-05 02:27:05 - progress_bar.py[line:272] - INFO: epoch 010:    158 / 578 loss=2.239, loss_v1=0, loss_v2=0, nll_loss=1.024, ntokens=3194, nsentences=96, sample_size=3194, sample_size_v1=0, sample_size_v2=0, ppl=2.03, wps=1118.5, ups=0.35, wpb=3194, bsz=96, num_updates=5350, lr=2.37394e-06, gnorm=2.888, clip=100, loss_scale=64, train_wall=29, gb_free=11.8, wall=2729
2023-05-05 02:27:34 - progress_bar.py[line:272] - INFO: epoch 010:    168 / 578 loss=2.228, loss_v1=0, loss_v2=0, nll_loss=1.011, ntokens=3233.2, nsentences=96, sample_size=3233.2, sample_size_v1=0, sample_size_v2=0, ppl=2.02, wps=1125.5, ups=0.35, wpb=3233.2, bsz=96, num_updates=5360, lr=2.31873e-06, gnorm=3.023, clip=100, loss_scale=64, train_wall=29, gb_free=12.2, wall=2758
2023-05-05 02:28:02 - progress_bar.py[line:272] - INFO: epoch 010:    178 / 578 loss=2.225, loss_v1=0, loss_v2=0, nll_loss=1.007, ntokens=3184.5, nsentences=96, sample_size=3184.5, sample_size_v1=0, sample_size_v2=0, ppl=2.01, wps=1109.8, ups=0.35, wpb=3184.5, bsz=96, num_updates=5370, lr=2.26353e-06, gnorm=2.786, clip=100, loss_scale=64, train_wall=29, gb_free=12.1, wall=2786
2023-05-05 02:28:31 - progress_bar.py[line:272] - INFO: epoch 010:    188 / 578 loss=2.231, loss_v1=0, loss_v2=0, nll_loss=1.015, ntokens=3275.1, nsentences=96, sample_size=3275.1, sample_size_v1=0, sample_size_v2=0, ppl=2.02, wps=1135, ups=0.35, wpb=3275.1, bsz=96, num_updates=5380, lr=2.20832e-06, gnorm=2.934, clip=100, loss_scale=64, train_wall=29, gb_free=11.8, wall=2815
2023-05-05 02:29:00 - progress_bar.py[line:272] - INFO: epoch 010:    198 / 578 loss=2.202, loss_v1=0, loss_v2=0, nll_loss=0.983, ntokens=3209.2, nsentences=96, sample_size=3209.2, sample_size_v1=0, sample_size_v2=0, ppl=1.98, wps=1117.9, ups=0.35, wpb=3209.2, bsz=96, num_updates=5390, lr=2.15311e-06, gnorm=2.732, clip=100, loss_scale=64, train_wall=29, gb_free=11.9, wall=2844
2023-05-05 02:29:29 - progress_bar.py[line:272] - INFO: epoch 010:    208 / 578 loss=2.199, loss_v1=0, loss_v2=0, nll_loss=0.98, ntokens=3178.6, nsentences=96, sample_size=3178.6, sample_size_v1=0, sample_size_v2=0, ppl=1.97, wps=1111.6, ups=0.35, wpb=3178.6, bsz=96, num_updates=5400, lr=2.0979e-06, gnorm=3.148, clip=100, loss_scale=64, train_wall=29, gb_free=12.4, wall=2872
2023-05-05 02:29:57 - progress_bar.py[line:272] - INFO: epoch 010:    218 / 578 loss=2.233, loss_v1=0, loss_v2=0, nll_loss=1.018, ntokens=3047.8, nsentences=96, sample_size=3047.8, sample_size_v1=0, sample_size_v2=0, ppl=2.03, wps=1066.2, ups=0.35, wpb=3047.8, bsz=96, num_updates=5410, lr=2.04269e-06, gnorm=3.171, clip=100, loss_scale=64, train_wall=29, gb_free=12.3, wall=2901
2023-05-05 02:30:26 - progress_bar.py[line:272] - INFO: epoch 010:    228 / 578 loss=2.202, loss_v1=0, loss_v2=0, nll_loss=0.983, ntokens=3085.7, nsentences=96, sample_size=3085.7, sample_size_v1=0, sample_size_v2=0, ppl=1.98, wps=1079.2, ups=0.35, wpb=3085.7, bsz=96, num_updates=5420, lr=1.98749e-06, gnorm=2.892, clip=100, loss_scale=64, train_wall=29, gb_free=12.5, wall=2930
2023-05-05 02:30:54 - progress_bar.py[line:272] - INFO: epoch 010:    238 / 578 loss=2.226, loss_v1=0, loss_v2=0, nll_loss=1.011, ntokens=2931.9, nsentences=96, sample_size=2931.9, sample_size_v1=0, sample_size_v2=0, ppl=2.02, wps=1030, ups=0.35, wpb=2931.9, bsz=96, num_updates=5430, lr=1.93228e-06, gnorm=3.315, clip=100, loss_scale=64, train_wall=28, gb_free=12.5, wall=2958
2023-05-05 02:31:23 - progress_bar.py[line:272] - INFO: epoch 010:    248 / 578 loss=2.223, loss_v1=0, loss_v2=0, nll_loss=1.006, ntokens=3028.6, nsentences=96, sample_size=3028.6, sample_size_v1=0, sample_size_v2=0, ppl=2.01, wps=1064.5, ups=0.35, wpb=3028.6, bsz=96, num_updates=5440, lr=1.87707e-06, gnorm=2.964, clip=100, loss_scale=64, train_wall=28, gb_free=12.2, wall=2986
2023-05-05 02:31:51 - progress_bar.py[line:272] - INFO: epoch 010:    258 / 578 loss=2.205, loss_v1=0, loss_v2=0, nll_loss=0.986, ntokens=3246.1, nsentences=96, sample_size=3246.1, sample_size_v1=0, sample_size_v2=0, ppl=1.98, wps=1138.4, ups=0.35, wpb=3246.1, bsz=96, num_updates=5450, lr=1.82186e-06, gnorm=2.858, clip=100, loss_scale=64, train_wall=28, gb_free=12.4, wall=3015
2023-05-05 02:32:20 - progress_bar.py[line:272] - INFO: epoch 010:    268 / 578 loss=2.214, loss_v1=0, loss_v2=0, nll_loss=0.997, ntokens=3021.9, nsentences=96, sample_size=3021.9, sample_size_v1=0, sample_size_v2=0, ppl=2, wps=1061.1, ups=0.35, wpb=3021.9, bsz=96, num_updates=5460, lr=1.76665e-06, gnorm=3.142, clip=100, loss_scale=64, train_wall=28, gb_free=12.1, wall=3043
2023-05-05 02:32:48 - progress_bar.py[line:272] - INFO: epoch 010:    278 / 578 loss=2.211, loss_v1=0, loss_v2=0, nll_loss=0.994, ntokens=3194.8, nsentences=96, sample_size=3194.8, sample_size_v1=0, sample_size_v2=0, ppl=1.99, wps=1118.8, ups=0.35, wpb=3194.8, bsz=96, num_updates=5470, lr=1.71145e-06, gnorm=2.853, clip=100, loss_scale=64, train_wall=29, gb_free=12.5, wall=3072
2023-05-05 02:33:17 - progress_bar.py[line:272] - INFO: epoch 010:    288 / 578 loss=2.2, loss_v1=0, loss_v2=0, nll_loss=0.98, ntokens=3154.1, nsentences=96, sample_size=3154.1, sample_size_v1=0, sample_size_v2=0, ppl=1.97, wps=1101.6, ups=0.35, wpb=3154.1, bsz=96, num_updates=5480, lr=1.65624e-06, gnorm=2.946, clip=100, loss_scale=64, train_wall=29, gb_free=12.5, wall=3101
2023-05-05 02:33:46 - progress_bar.py[line:272] - INFO: epoch 010:    298 / 578 loss=2.236, loss_v1=0, loss_v2=0, nll_loss=1.022, ntokens=3065.2, nsentences=96, sample_size=3065.2, sample_size_v1=0, sample_size_v2=0, ppl=2.03, wps=1072.5, ups=0.35, wpb=3065.2, bsz=96, num_updates=5490, lr=1.60103e-06, gnorm=3.049, clip=100, loss_scale=64, train_wall=29, gb_free=11.9, wall=3129
2023-05-05 02:34:14 - progress_bar.py[line:272] - INFO: epoch 010:    308 / 578 loss=2.22, loss_v1=0, loss_v2=0, nll_loss=1.003, ntokens=3172.9, nsentences=96, sample_size=3172.9, sample_size_v1=0, sample_size_v2=0, ppl=2, wps=1107.7, ups=0.35, wpb=3172.9, bsz=96, num_updates=5500, lr=1.54582e-06, gnorm=2.818, clip=100, loss_scale=64, train_wall=29, gb_free=12, wall=3158
2023-05-05 02:34:43 - progress_bar.py[line:272] - INFO: epoch 010:    318 / 578 loss=2.229, loss_v1=0, loss_v2=0, nll_loss=1.013, ntokens=3286.2, nsentences=96, sample_size=3286.2, sample_size_v1=0, sample_size_v2=0, ppl=2.02, wps=1145.8, ups=0.35, wpb=3286.2, bsz=96, num_updates=5510, lr=1.49061e-06, gnorm=3.108, clip=100, loss_scale=64, train_wall=29, gb_free=12.1, wall=3187
2023-05-05 02:35:11 - progress_bar.py[line:272] - INFO: epoch 010:    328 / 578 loss=2.203, loss_v1=0, loss_v2=0, nll_loss=0.984, ntokens=3088.9, nsentences=96, sample_size=3088.9, sample_size_v1=0, sample_size_v2=0, ppl=1.98, wps=1078.9, ups=0.35, wpb=3088.9, bsz=96, num_updates=5520, lr=1.43541e-06, gnorm=2.914, clip=100, loss_scale=64, train_wall=29, gb_free=12.1, wall=3215
2023-05-05 02:35:40 - progress_bar.py[line:272] - INFO: epoch 010:    338 / 578 loss=2.217, loss_v1=0, loss_v2=0, nll_loss=1, ntokens=3121.3, nsentences=96, sample_size=3121.3, sample_size_v1=0, sample_size_v2=0, ppl=2, wps=1095.2, ups=0.35, wpb=3121.3, bsz=96, num_updates=5530, lr=1.3802e-06, gnorm=2.909, clip=100, loss_scale=64, train_wall=28, gb_free=12.2, wall=3244
2023-05-05 02:36:08 - progress_bar.py[line:272] - INFO: epoch 010:    348 / 578 loss=2.222, loss_v1=0, loss_v2=0, nll_loss=1.006, ntokens=3222.3, nsentences=96, sample_size=3222.3, sample_size_v1=0, sample_size_v2=0, ppl=2.01, wps=1132.6, ups=0.35, wpb=3222.3, bsz=96, num_updates=5540, lr=1.32499e-06, gnorm=2.933, clip=100, loss_scale=64, train_wall=28, gb_free=12.5, wall=3272
2023-05-05 02:36:37 - progress_bar.py[line:272] - INFO: epoch 010:    358 / 578 loss=2.213, loss_v1=0, loss_v2=0, nll_loss=0.995, ntokens=3069.5, nsentences=96, sample_size=3069.5, sample_size_v1=0, sample_size_v2=0, ppl=1.99, wps=1078.2, ups=0.35, wpb=3069.5, bsz=96, num_updates=5550, lr=1.26978e-06, gnorm=3.151, clip=100, loss_scale=64, train_wall=28, gb_free=12.6, wall=3301
2023-05-05 02:37:06 - progress_bar.py[line:272] - INFO: epoch 010:    368 / 578 loss=2.245, loss_v1=0, loss_v2=0, nll_loss=1.031, ntokens=3434.3, nsentences=96, sample_size=3434.3, sample_size_v1=0, sample_size_v2=0, ppl=2.04, wps=1199.6, ups=0.35, wpb=3434.3, bsz=96, num_updates=5560, lr=1.21457e-06, gnorm=2.848, clip=100, loss_scale=64, train_wall=29, gb_free=11.9, wall=3329
2023-05-05 02:37:34 - progress_bar.py[line:272] - INFO: epoch 010:    378 / 578 loss=2.227, loss_v1=0, loss_v2=0, nll_loss=1.011, ntokens=3347.9, nsentences=96, sample_size=3347.9, sample_size_v1=0, sample_size_v2=0, ppl=2.02, wps=1163.8, ups=0.35, wpb=3347.9, bsz=96, num_updates=5570, lr=1.15937e-06, gnorm=2.864, clip=100, loss_scale=64, train_wall=29, gb_free=12.1, wall=3358
2023-05-05 02:38:03 - progress_bar.py[line:272] - INFO: epoch 010:    388 / 578 loss=2.232, loss_v1=0, loss_v2=0, nll_loss=1.017, ntokens=3221.5, nsentences=96, sample_size=3221.5, sample_size_v1=0, sample_size_v2=0, ppl=2.02, wps=1122.6, ups=0.35, wpb=3221.5, bsz=96, num_updates=5580, lr=1.10416e-06, gnorm=2.898, clip=100, loss_scale=64, train_wall=29, gb_free=12.1, wall=3387
2023-05-05 02:38:32 - progress_bar.py[line:272] - INFO: epoch 010:    398 / 578 loss=2.206, loss_v1=0, loss_v2=0, nll_loss=0.988, ntokens=3163.1, nsentences=96, sample_size=3163.1, sample_size_v1=0, sample_size_v2=0, ppl=1.98, wps=1104, ups=0.35, wpb=3163.1, bsz=96, num_updates=5590, lr=1.04895e-06, gnorm=2.9, clip=100, loss_scale=64, train_wall=29, gb_free=12.3, wall=3415
2023-05-05 02:39:00 - progress_bar.py[line:272] - INFO: epoch 010:    408 / 578 loss=2.215, loss_v1=0, loss_v2=0, nll_loss=0.998, ntokens=2981.3, nsentences=96, sample_size=2981.3, sample_size_v1=0, sample_size_v2=0, ppl=2, wps=1044.7, ups=0.35, wpb=2981.3, bsz=96, num_updates=5600, lr=9.93743e-07, gnorm=3.165, clip=100, loss_scale=64, train_wall=29, gb_free=12.4, wall=3444
2023-05-05 02:39:29 - progress_bar.py[line:272] - INFO: epoch 010:    418 / 578 loss=2.227, loss_v1=0, loss_v2=0, nll_loss=1.01, ntokens=3024.6, nsentences=96, sample_size=3024.6, sample_size_v1=0, sample_size_v2=0, ppl=2.01, wps=1058.3, ups=0.35, wpb=3024.6, bsz=96, num_updates=5610, lr=9.38535e-07, gnorm=3.093, clip=100, loss_scale=64, train_wall=29, gb_free=12.4, wall=3473
2023-05-05 02:39:57 - progress_bar.py[line:272] - INFO: epoch 010:    428 / 578 loss=2.204, loss_v1=0, loss_v2=0, nll_loss=0.985, ntokens=3057.8, nsentences=96, sample_size=3057.8, sample_size_v1=0, sample_size_v2=0, ppl=1.98, wps=1072.4, ups=0.35, wpb=3057.8, bsz=96, num_updates=5620, lr=8.83327e-07, gnorm=3.028, clip=100, loss_scale=64, train_wall=28, gb_free=12.2, wall=3501
2023-05-05 02:40:26 - progress_bar.py[line:272] - INFO: epoch 010:    438 / 578 loss=2.228, loss_v1=0, loss_v2=0, nll_loss=1.013, ntokens=2936.4, nsentences=96, sample_size=2936.4, sample_size_v1=0, sample_size_v2=0, ppl=2.02, wps=1037.1, ups=0.35, wpb=2936.4, bsz=96, num_updates=5630, lr=8.28119e-07, gnorm=2.926, clip=100, loss_scale=64, train_wall=28, gb_free=12.4, wall=3529
2023-05-05 02:40:54 - progress_bar.py[line:272] - INFO: epoch 010:    448 / 578 loss=2.225, loss_v1=0, loss_v2=0, nll_loss=1.009, ntokens=3043.6, nsentences=96, sample_size=3043.6, sample_size_v1=0, sample_size_v2=0, ppl=2.01, wps=1066.1, ups=0.35, wpb=3043.6, bsz=96, num_updates=5640, lr=7.72911e-07, gnorm=3.065, clip=100, loss_scale=64, train_wall=29, gb_free=12.3, wall=3558
2023-05-05 02:41:23 - progress_bar.py[line:272] - INFO: epoch 010:    458 / 578 loss=2.21, loss_v1=0, loss_v2=0, nll_loss=0.991, ntokens=3029.5, nsentences=96, sample_size=3029.5, sample_size_v1=0, sample_size_v2=0, ppl=1.99, wps=1063.1, ups=0.35, wpb=3029.5, bsz=96, num_updates=5650, lr=7.17703e-07, gnorm=2.832, clip=100, loss_scale=64, train_wall=28, gb_free=12, wall=3586
2023-05-05 02:41:51 - progress_bar.py[line:272] - INFO: epoch 010:    468 / 578 loss=2.221, loss_v1=0, loss_v2=0, nll_loss=1.004, ntokens=3101.1, nsentences=96, sample_size=3101.1, sample_size_v1=0, sample_size_v2=0, ppl=2.01, wps=1085.1, ups=0.35, wpb=3101.1, bsz=96, num_updates=5660, lr=6.62495e-07, gnorm=2.769, clip=100, loss_scale=128, train_wall=29, gb_free=12.4, wall=3615
2023-05-05 02:42:08 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2023-05-05 02:42:23 - progress_bar.py[line:272] - INFO: epoch 010:    479 / 578 loss=2.224, loss_v1=0, loss_v2=0, nll_loss=1.007, ntokens=2917.2, nsentences=96, sample_size=2917.2, sample_size_v1=0, sample_size_v2=0, ppl=2.01, wps=930.5, ups=0.32, wpb=2917.2, bsz=96, num_updates=5670, lr=6.07287e-07, gnorm=3.02, clip=100, loss_scale=64, train_wall=31, gb_free=12.7, wall=3646
2023-05-05 02:42:51 - progress_bar.py[line:272] - INFO: epoch 010:    489 / 578 loss=2.2, loss_v1=0, loss_v2=0, nll_loss=0.98, ntokens=3018.1, nsentences=96, sample_size=3018.1, sample_size_v1=0, sample_size_v2=0, ppl=1.97, wps=1060.3, ups=0.35, wpb=3018.1, bsz=96, num_updates=5680, lr=5.52079e-07, gnorm=2.88, clip=100, loss_scale=64, train_wall=28, gb_free=12, wall=3675
2023-05-05 02:43:20 - progress_bar.py[line:272] - INFO: epoch 010:    499 / 578 loss=2.193, loss_v1=0, loss_v2=0, nll_loss=0.972, ntokens=3225.7, nsentences=96, sample_size=3225.7, sample_size_v1=0, sample_size_v2=0, ppl=1.96, wps=1125, ups=0.35, wpb=3225.7, bsz=96, num_updates=5690, lr=4.96872e-07, gnorm=2.851, clip=100, loss_scale=64, train_wall=29, gb_free=12.5, wall=3704
2023-05-05 02:43:48 - progress_bar.py[line:272] - INFO: epoch 010:    509 / 578 loss=2.212, loss_v1=0, loss_v2=0, nll_loss=0.994, ntokens=3152.4, nsentences=96, sample_size=3152.4, sample_size_v1=0, sample_size_v2=0, ppl=1.99, wps=1100.9, ups=0.35, wpb=3152.4, bsz=96, num_updates=5700, lr=4.41664e-07, gnorm=2.944, clip=100, loss_scale=64, train_wall=29, gb_free=12.5, wall=3732
2023-05-05 02:44:17 - progress_bar.py[line:272] - INFO: epoch 010:    519 / 578 loss=2.204, loss_v1=0, loss_v2=0, nll_loss=0.986, ntokens=3275, nsentences=96, sample_size=3275, sample_size_v1=0, sample_size_v2=0, ppl=1.98, wps=1142.8, ups=0.35, wpb=3275, bsz=96, num_updates=5710, lr=3.86456e-07, gnorm=2.84, clip=100, loss_scale=64, train_wall=29, gb_free=12.7, wall=3761
2023-05-05 02:44:45 - progress_bar.py[line:272] - INFO: epoch 010:    529 / 578 loss=2.228, loss_v1=0, loss_v2=0, nll_loss=1.013, ntokens=3051.6, nsentences=96, sample_size=3051.6, sample_size_v1=0, sample_size_v2=0, ppl=2.02, wps=1072.9, ups=0.35, wpb=3051.6, bsz=96, num_updates=5720, lr=3.31248e-07, gnorm=2.964, clip=100, loss_scale=64, train_wall=28, gb_free=12.4, wall=3789
2023-05-05 02:45:14 - progress_bar.py[line:272] - INFO: epoch 010:    539 / 578 loss=2.215, loss_v1=0, loss_v2=0, nll_loss=0.999, ntokens=3000.4, nsentences=96, sample_size=3000.4, sample_size_v1=0, sample_size_v2=0, ppl=2, wps=1057, ups=0.35, wpb=3000.4, bsz=96, num_updates=5730, lr=2.7604e-07, gnorm=3, clip=100, loss_scale=64, train_wall=28, gb_free=12.3, wall=3818
2023-05-05 02:45:43 - progress_bar.py[line:272] - INFO: epoch 010:    549 / 578 loss=2.209, loss_v1=0, loss_v2=0, nll_loss=0.991, ntokens=3177.9, nsentences=96, sample_size=3177.9, sample_size_v1=0, sample_size_v2=0, ppl=1.99, wps=1107.1, ups=0.35, wpb=3177.9, bsz=96, num_updates=5740, lr=2.20832e-07, gnorm=3.07, clip=100, loss_scale=64, train_wall=29, gb_free=12, wall=3846
2023-05-05 02:46:11 - progress_bar.py[line:272] - INFO: epoch 010:    559 / 578 loss=2.205, loss_v1=0, loss_v2=0, nll_loss=0.987, ntokens=3212.4, nsentences=96, sample_size=3212.4, sample_size_v1=0, sample_size_v2=0, ppl=1.98, wps=1115.4, ups=0.35, wpb=3212.4, bsz=96, num_updates=5750, lr=1.65624e-07, gnorm=2.887, clip=100, loss_scale=64, train_wall=29, gb_free=12.5, wall=3875
2023-05-05 02:46:40 - progress_bar.py[line:272] - INFO: epoch 010:    569 / 578 loss=2.208, loss_v1=0, loss_v2=0, nll_loss=0.99, ntokens=3294.7, nsentences=96, sample_size=3294.7, sample_size_v1=0, sample_size_v2=0, ppl=1.99, wps=1147.7, ups=0.35, wpb=3294.7, bsz=96, num_updates=5760, lr=1.10416e-07, gnorm=2.785, clip=100, loss_scale=64, train_wall=29, gb_free=12.1, wall=3904
slice_id 1 seek offset 11440
2023-05-05 02:47:03 - train.py[line:445] - INFO: begin validation on "valid" subset
slice_id 0 seek offset 0
slice_id 0 seek offset 0
slice_id 1 seek offset 11440
/home/zcai75/Github/OFA/fairseq/fairseq/search.py:140: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  beams_buf = indices_buf // vocab_size
/home/zcai75/Github/OFA/fairseq/fairseq/search.py:140: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  beams_buf = indices_buf // vocab_size
/home/zcai75/Github/OFA_forked/models/sequence_generator.py:705: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  unfin_idx = bbsz_idx // beam_size
/home/zcai75/Github/OFA_forked/models/sequence_generator.py:705: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  unfin_idx = bbsz_idx // beam_size
2343729 <sub> train<pred> has<obj> door<pred> has<obj> window<pred> has<obj> window<pred> has<obj> window<pred> has<obj> window<pred> has<obj> window<pred> has<obj> window<pred> has<obj> door ['<sub> windshield<pred> on<obj> train<sub> window<pred> on<obj> train<sub> train<pred> has<obj> window<sub> house<pred> near<obj> train<sub> tree<pred> near<obj> house']
2325977 <sub> player<pred> wearing<obj> helmet<pred> wearing<obj> pant<pred> wearing<obj> shirt<pred> wearing<obj> pant ['<sub> head<pred> of<obj> bear<sub> bear<pred> in<obj> bowl<sub> bowl<pred> with<obj> bear']
2023-05-05 02:47:14 - progress_bar.py[line:272] - INFO: epoch 010 | valid on 'valid' subset:     11 / 1907 loss=2.302, loss_v1=0, loss_v2=0, nll_loss=1.071, ntokens=426, nsentences=12, sample_size=426.0, sample_size_v1=0, sample_size_v2=0
2023-05-05 02:47:23 - progress_bar.py[line:272] - INFO: epoch 010 | valid on 'valid' subset:     21 / 1907 loss=2.333, loss_v1=0, loss_v2=0, nll_loss=1.101, ntokens=527, nsentences=12, sample_size=527.0, sample_size_v1=0, sample_size_v2=0
2023-05-05 02:47:32 - progress_bar.py[line:272] - INFO: epoch 010 | valid on 'valid' subset:     31 / 1907 loss=2.356, loss_v1=0, loss_v2=0, nll_loss=1.129, ntokens=420, nsentences=12, sample_size=420.0, sample_size_v1=0, sample_size_v2=0
2023-05-05 02:47:41 - progress_bar.py[line:272] - INFO: epoch 010 | valid on 'valid' subset:     41 / 1907 loss=2.222, loss_v1=0, loss_v2=0, nll_loss=0.98, ntokens=426, nsentences=12, sample_size=426.0, sample_size_v1=0, sample_size_v2=0
2325510 <sub> window<pred> on<obj> building<sub> window<pred> on<obj> building<sub> window<pred> on<obj> building<sub> window<pred> on<obj> building<sub> window<pred> on<obj> building<sub> window<pred> on<obj> building<sub> window<pred> on<obj> building<sub> window<pred> on<obj> building ['<sub> window<pred> on<obj> building<sub> window<pred> on<obj> building<sub> window<pred> on<obj> building<sub> window<pred> on<obj> building<sub> window<pred> on<obj> building<sub> window<pred> on<obj> building<sub> light<pred> on<obj> street']
2343357 <sub> elephant<pred> has<obj> ear<pred> has<obj> trunk<pred> has<obj> eye<pred> has<obj> eye<pred> has<obj> eye<pred> has<obj> mouth<pred> has<obj> trunk<pred> has<obj> mouth ['<sub> bird<pred> has<obj> head<pred> near<obj> tree<sub> neck<pred> of<obj> bird<sub> branch<pred> near<obj> bird<sub> hair<pred> on<obj> bird']
2023-05-05 02:47:51 - progress_bar.py[line:272] - INFO: epoch 010 | valid on 'valid' subset:     51 / 1907 loss=2.225, loss_v1=0, loss_v2=0, nll_loss=0.983, ntokens=447, nsentences=12, sample_size=447.0, sample_size_v1=0, sample_size_v2=0
2023-05-05 02:48:01 - progress_bar.py[line:272] - INFO: epoch 010 | valid on 'valid' subset:     61 / 1907 loss=2.309, loss_v1=0, loss_v2=0, nll_loss=1.074, ntokens=458, nsentences=12, sample_size=458.0, sample_size_v1=0, sample_size_v2=0
2023-05-05 02:48:14 - progress_bar.py[line:272] - INFO: epoch 010 | valid on 'valid' subset:     71 / 1907 loss=2.304, loss_v1=0, loss_v2=0, nll_loss=1.074, ntokens=442, nsentences=12, sample_size=442.0, sample_size_v1=0, sample_size_v2=0
2023-05-05 02:48:24 - progress_bar.py[line:272] - INFO: epoch 010 | valid on 'valid' subset:     81 / 1907 loss=2.353, loss_v1=0, loss_v2=0, nll_loss=1.129, ntokens=377, nsentences=12, sample_size=377.0, sample_size_v1=0, sample_size_v2=0
2023-05-05 02:48:33 - progress_bar.py[line:272] - INFO: epoch 010 | valid on 'valid' subset:     91 / 1907 loss=2.256, loss_v1=0, loss_v2=0, nll_loss=1.01, ntokens=389, nsentences=12, sample_size=389.0, sample_size_v1=0, sample_size_v2=0
2325083 <sub> eye<pred> of<obj> cat<sub> eye<pred> of<obj> cat<sub> eye<pred> of<obj> cat<sub> nose<pred> of<obj> cat<sub> cat<pred> has<obj> eye<pred> has<obj> eye<pred> has<obj> eye<pred> has<obj> eye<pred> has<obj> eye<pred> has<obj> nose<pred> has<obj> eye<pred> has<obj> eye<pred> has<obj> eye<pred> has<obj> nose<pred> has<obj> eye<pred> has<obj> eye<pred> has<obj> eye ['<sub> cat<pred> in front of<obj> window<pred> laying on<obj> desk<pred> has<obj> ear<pred> has<obj> eye<pred> has<obj> eye<pred> has<obj> nose<pred> has<obj> paw<pred> has<obj> paw<pred> has<obj> head']
2342980 <sub> tree<pred> covered in<obj> snow<sub> tree<pred> covered in<obj> snow<sub> tree<pred> covered in<obj> snow<sub> tree<pred> covered in<obj> snow<sub> tree<pred> covered in<obj> snow<sub> tree<pred> covered in<obj> snow<sub> tree<pred> covered in<obj> snow<sub> tree<pred> covered in<obj> snow ['<sub> snow<pred> covering<obj> mountain<sub> snow<pred> on<obj> roof<sub> roof<pred> on<obj> building<sub> railing<pred> of<obj> building<sub> pant<pred> of<obj> skier<sub> skier<pred> holding<obj> pole<sub> person<pred> holding<obj> pole<pred> using<obj> ski<sub> person<pred> on<obj> ski<sub> people<pred> on<obj> snow<sub> man<pred> wearing<obj> pant<sub> snow<pred> covering<obj> tree<sub> pole<pred> on<obj> man<sub> snow<pred> on<obj> roof']
2023-05-05 02:48:42 - progress_bar.py[line:272] - INFO: epoch 010 | valid on 'valid' subset:    101 / 1907 loss=2.283, loss_v1=0, loss_v2=0, nll_loss=1.043, ntokens=514, nsentences=12, sample_size=514.0, sample_size_v1=0, sample_size_v2=0
2023-05-05 02:48:52 - progress_bar.py[line:272] - INFO: epoch 010 | valid on 'valid' subset:    111 / 1907 loss=2.387, loss_v1=0, loss_v2=0, nll_loss=1.163, ntokens=547, nsentences=12, sample_size=547.0, sample_size_v1=0, sample_size_v2=0
2023-05-05 02:49:02 - progress_bar.py[line:272] - INFO: epoch 010 | valid on 'valid' subset:    121 / 1907 loss=2.291, loss_v1=0, loss_v2=0, nll_loss=1.051, ntokens=528, nsentences=12, sample_size=528.0, sample_size_v1=0, sample_size_v2=0
2023-05-05 02:49:11 - progress_bar.py[line:272] - INFO: epoch 010 | valid on 'valid' subset:    131 / 1907 loss=2.309, loss_v1=0, loss_v2=0, nll_loss=1.08, ntokens=359, nsentences=12, sample_size=359.0, sample_size_v1=0, sample_size_v2=0
2023-05-05 02:49:21 - progress_bar.py[line:272] - INFO: epoch 010 | valid on 'valid' subset:    141 / 1907 loss=2.213, loss_v1=0, loss_v2=0, nll_loss=0.97, ntokens=733, nsentences=12, sample_size=733.0, sample_size_v1=0, sample_size_v2=0
2342579 <sub> head<pred> of<obj> giraffe<sub> leg<pred> of<obj> giraffe<sub> leg<pred> of<obj> giraffe<sub> leg<pred> of<obj> giraffe<sub> leg<pred> of<obj> giraffe<sub> leg<pred> of<obj> giraffe<sub> leg<pred> of<obj> giraffe<sub> leg<pred> of<obj> giraffe<sub> leg<pred> of<obj> giraffe<sub> leg<pred> of<obj> giraffe ['<sub> tree<pred> behind<obj> giraffe<pred> behind<obj> giraffe<pred> behind<obj> giraffe<sub> leg<pred> of<obj> giraffe<sub> leg<pred> on<obj> giraffe<sub> leg<pred> of<obj> giraffe<sub> leg<pred> of<obj> giraffe<sub> leg<pred> of<obj> giraffe<sub> leg<pred> of<obj> giraffe<sub> giraffe<pred> has<obj> tail<pred> has<obj> neck<sub> giraffe<pred> has<obj> head<pred> near<obj> giraffe']
2324656 <sub> bench<pred> on<obj> sidewalk<sub> bench<pred> on<obj> sidewalk<sub> bench<pred> on<obj> sidewalk<sub> bench<pred> on<obj> sidewalk<sub> bench<pred> on<obj> sidewalk<sub> bench<pred> on<obj> sidewalk<sub> bench<pred> on<obj> sidewalk<sub> bench<pred> on<obj> sidewalk<sub> bench<pred> on<obj> sidewalk<sub> bench<pred> on<obj> sidewalk<sub> bench<pred> on<obj> sidewalk<sub> bench<pred> on<obj> sidewalk<sub> bench<pred> on<obj> sidewalk ['<sub> rock<pred> on<obj> hill<sub> building<pred> in<obj> snow<sub> boy<pred> on<obj> ski<sub> roof<pred> on<obj> building<sub> tree<pred> near<obj> building<sub> tree<pred> on<obj> hill']
2023-05-05 02:49:30 - progress_bar.py[line:272] - INFO: epoch 010 | valid on 'valid' subset:    151 / 1907 loss=2.218, loss_v1=0, loss_v2=0, nll_loss=0.975, ntokens=475, nsentences=12, sample_size=475.0, sample_size_v1=0, sample_size_v2=0
2023-05-05 02:49:40 - progress_bar.py[line:272] - INFO: epoch 010 | valid on 'valid' subset:    161 / 1907 loss=2.281, loss_v1=0, loss_v2=0, nll_loss=1.047, ntokens=538, nsentences=12, sample_size=538.0, sample_size_v1=0, sample_size_v2=0
2023-05-05 02:49:49 - progress_bar.py[line:272] - INFO: epoch 010 | valid on 'valid' subset:    171 / 1907 loss=2.401, loss_v1=0, loss_v2=0, nll_loss=1.176, ntokens=520, nsentences=12, sample_size=520.0, sample_size_v1=0, sample_size_v2=0
2023-05-05 02:49:58 - progress_bar.py[line:272] - INFO: epoch 010 | valid on 'valid' subset:    181 / 1907 loss=2.364, loss_v1=0, loss_v2=0, nll_loss=1.138, ntokens=568, nsentences=12, sample_size=568.0, sample_size_v1=0, sample_size_v2=0
2023-05-05 02:50:08 - progress_bar.py[line:272] - INFO: epoch 010 | valid on 'valid' subset:    191 / 1907 loss=2.308, loss_v1=0, loss_v2=0, nll_loss=1.08, ntokens=304, nsentences=12, sample_size=304.0, sample_size_v1=0, sample_size_v2=0
2324219 <sub> dog<pred> has<obj> nose<pred> has<obj> mouth<pred> has<obj> ear<pred> has<obj> ear<pred> has<obj> head ['<sub> boy<pred> carrying<obj> helmet<pred> wearing<obj> glove<sub> player<pred> behind<obj> boy']
2342212 <sub> people<pred> walking on<obj> sidewalk<sub> person<pred> walking on<obj> sidewalk<sub> person<pred> walking on<obj> sidewalk<sub> person<pred> walking on<obj> sidewalk<sub> person<pred> walking on<obj> sidewalk<sub> person<pred> walking on<obj> sidewalk<sub> person<pred> walking on<obj> sidewalk<sub> person<pred> walking on<obj> sidewalk<sub> person<pred> walking on<obj> sidewalk ['<sub> kid<pred> near<obj> bike<sub> sign<pred> near<obj> building<sub> man<pred> on<obj> street<sub> bike<pred> has<obj> tire<pred> near<obj> stand<pred> parked on<obj> street<sub> people<pred> under<obj> umbrella<pred> walking on<obj> street<sub> boy<pred> near<obj> bike<sub> man<pred> wears<obj> shirt<pred> wears<obj> short<sub> woman<pred> wearing<obj> shirt<sub> person<pred> wearing<obj> shirt']
2023-05-05 02:50:19 - progress_bar.py[line:272] - INFO: epoch 010 | valid on 'valid' subset:    201 / 1907 loss=2.461, loss_v1=0, loss_v2=0, nll_loss=1.242, ntokens=525, nsentences=12, sample_size=525.0, sample_size_v1=0, sample_size_v2=0
2023-05-05 02:50:28 - progress_bar.py[line:272] - INFO: epoch 010 | valid on 'valid' subset:    211 / 1907 loss=2.403, loss_v1=0, loss_v2=0, nll_loss=1.179, ntokens=337, nsentences=12, sample_size=337.0, sample_size_v1=0, sample_size_v2=0
2023-05-05 02:50:38 - progress_bar.py[line:272] - INFO: epoch 010 | valid on 'valid' subset:    221 / 1907 loss=2.362, loss_v1=0, loss_v2=0, nll_loss=1.134, ntokens=478, nsentences=12, sample_size=478.0, sample_size_v1=0, sample_size_v2=0
2023-05-05 02:50:47 - progress_bar.py[line:272] - INFO: epoch 010 | valid on 'valid' subset:    231 / 1907 loss=2.227, loss_v1=0, loss_v2=0, nll_loss=0.989, ntokens=329, nsentences=12, sample_size=329.0, sample_size_v1=0, sample_size_v2=0
2023-05-05 02:50:57 - progress_bar.py[line:272] - INFO: epoch 010 | valid on 'valid' subset:    241 / 1907 loss=2.356, loss_v1=0, loss_v2=0, nll_loss=1.129, ntokens=373, nsentences=12, sample_size=373.0, sample_size_v1=0, sample_size_v2=0
2323784 <sub> drawer<pred> under<obj> counter<sub> drawer<pred> under<obj> counter<sub> drawer<pred> under<obj> counter<sub> drawer<pred> under<obj> counter ['<sub> cat<pred> at<obj> window<pred> near<obj> door<sub> window<pred> covering<obj> window']
2341845 <sub> man<pred> wearing<obj> hat<pred> wearing<obj> jacket<pred> wearing<obj> glove<pred> wearing<obj> glove<pred> wearing<obj> glove<sub> woman<pred> wearing<obj> glove<pred> wearing<obj> glove<pred> wearing<obj> glove<pred> wearing<obj> glove<pred> wearing<obj> glove<pred> wearing<obj> glove<sub> woman<pred> wearing<obj> glove<pred> wearing<obj> glove ['<sub> man<pred> on<obj> ski<pred> on<obj> snow<sub> ski<pred> on<obj> snow<sub> man<pred> wearing<obj> jacket<pred> on<obj> snow<sub> woman<pred> standing on<obj> snow<sub> hat<pred> on<obj> man<sub> tree<pred> behind<obj> man']
2023-05-05 02:51:06 - progress_bar.py[line:272] - INFO: epoch 010 | valid on 'valid' subset:    251 / 1907 loss=2.444, loss_v1=0, loss_v2=0, nll_loss=1.227, ntokens=456, nsentences=12, sample_size=456.0, sample_size_v1=0, sample_size_v2=0
2023-05-05 02:51:16 - progress_bar.py[line:272] - INFO: epoch 010 | valid on 'valid' subset:    261 / 1907 loss=2.283, loss_v1=0, loss_v2=0, nll_loss=1.048, ntokens=630, nsentences=12, sample_size=630.0, sample_size_v1=0, sample_size_v2=0
2023-05-05 02:51:26 - progress_bar.py[line:272] - INFO: epoch 010 | valid on 'valid' subset:    271 / 1907 loss=2.417, loss_v1=0, loss_v2=0, nll_loss=1.199, ntokens=375, nsentences=12, sample_size=375.0, sample_size_v1=0, sample_size_v2=0
2023-05-05 02:51:37 - progress_bar.py[line:272] - INFO: epoch 010 | valid on 'valid' subset:    281 / 1907 loss=2.397, loss_v1=0, loss_v2=0, nll_loss=1.175, ntokens=356, nsentences=12, sample_size=356.0, sample_size_v1=0, sample_size_v2=0
2023-05-05 02:51:46 - progress_bar.py[line:272] - INFO: epoch 010 | valid on 'valid' subset:    291 / 1907 loss=2.319, loss_v1=0, loss_v2=0, nll_loss=1.088, ntokens=387, nsentences=12, sample_size=387.0, sample_size_v1=0, sample_size_v2=0
2341458 <sub> giraffe<pred> has<obj> head<pred> has<obj> neck<pred> has<obj> leg<pred> has<obj> leg<pred> has<obj> leg<pred> has<obj> leg<pred> has<obj> leg<pred> has<obj> leg ['<sub> man<pred> wearing<obj> shirt<pred> near<obj> truck<sub> man<pred> wearing<obj> shirt<sub> truck<pred> has<obj> tire<sub> windshield<pred> on<obj> truck']
2323363 <sub> train<pred> on<obj> track<sub> window<pred> on<obj> train<sub> window<pred> on<obj> train<sub> window<pred> on<obj> train<sub> window<pred> on<obj> train<sub> window<pred> on<obj> train<sub> window<pred> on<obj> train<sub> window<pred> on<obj> train ['<sub> rock<pred> on<obj> track<pred> on<obj> track<pred> on<obj> track<sub> rock<pred> on<obj> track<sub> man<pred> near<obj> train<sub> window<pred> on<obj> train<sub> window<pred> on<obj> train<sub> window<pred> on<obj> train']
2023-05-05 02:51:55 - progress_bar.py[line:272] - INFO: epoch 010 | valid on 'valid' subset:    301 / 1907 loss=2.225, loss_v1=0, loss_v2=0, nll_loss=0.981, ntokens=457, nsentences=12, sample_size=457.0, sample_size_v1=0, sample_size_v2=0
2023-05-05 02:52:05 - progress_bar.py[line:272] - INFO: epoch 010 | valid on 'valid' subset:    311 / 1907 loss=2.317, loss_v1=0, loss_v2=0, nll_loss=1.079, ntokens=554, nsentences=12, sample_size=554.0, sample_size_v1=0, sample_size_v2=0
2023-05-05 02:52:14 - progress_bar.py[line:272] - INFO: epoch 010 | valid on 'valid' subset:    321 / 1907 loss=2.181, loss_v1=0, loss_v2=0, nll_loss=0.939, ntokens=405, nsentences=12, sample_size=405.0, sample_size_v1=0, sample_size_v2=0
2023-05-05 02:52:24 - progress_bar.py[line:272] - INFO: epoch 010 | valid on 'valid' subset:    331 / 1907 loss=2.29, loss_v1=0, loss_v2=0, nll_loss=1.052, ntokens=394, nsentences=12, sample_size=394.0, sample_size_v1=0, sample_size_v2=0
2023-05-05 02:52:33 - progress_bar.py[line:272] - INFO: epoch 010 | valid on 'valid' subset:    341 / 1907 loss=2.229, loss_v1=0, loss_v2=0, nll_loss=0.979, ntokens=341, nsentences=12, sample_size=341.0, sample_size_v1=0, sample_size_v2=0
2322919 <sub> skier<pred> on<obj> snow<sub> skier<pred> on<obj> snow<sub> skier<pred> on<obj> snow<sub> skier<pred> on<obj> snow<sub> skier<pred> on<obj> snow ['<sub> child<pred> wearing<obj> helmet<sub> skier<pred> wears<obj> boot<sub> ski<pred> of<obj> child<sub> ski<pred> of<obj> child<sub> boot<pred> of<obj> skier<pred> of<obj> skier']
2341014 <sub> person<pred> on<obj> ski<sub> person<pred> on<obj> ski<sub> person<pred> on<obj> ski<sub> person<pred> on<obj> ski<sub> person<pred> on<obj> ski ['<sub> person<pred> wearing<obj> jacket<pred> holding<obj> pole<pred> wearing<obj> pant<sub> person<pred> wearing<obj> jacket<pred> has<obj> ski<pred> wearing<obj> jacket']
2023-05-05 02:52:42 - progress_bar.py[line:272] - INFO: epoch 010 | valid on 'valid' subset:    351 / 1907 loss=2.303, loss_v1=0, loss_v2=0, nll_loss=1.069, ntokens=463, nsentences=12, sample_size=463.0, sample_size_v1=0, sample_size_v2=0
2023-05-05 02:52:51 - progress_bar.py[line:272] - INFO: epoch 010 | valid on 'valid' subset:    361 / 1907 loss=2.374, loss_v1=0, loss_v2=0, nll_loss=1.149, ntokens=356, nsentences=12, sample_size=356.0, sample_size_v1=0, sample_size_v2=0
2023-05-05 02:53:00 - progress_bar.py[line:272] - INFO: epoch 010 | valid on 'valid' subset:    371 / 1907 loss=2.27, loss_v1=0, loss_v2=0, nll_loss=1.035, ntokens=423, nsentences=12, sample_size=423.0, sample_size_v1=0, sample_size_v2=0
2023-05-05 02:53:10 - progress_bar.py[line:272] - INFO: epoch 010 | valid on 'valid' subset:    381 / 1907 loss=2.239, loss_v1=0, loss_v2=0, nll_loss=0.998, ntokens=461, nsentences=12, sample_size=461.0, sample_size_v1=0, sample_size_v2=0
2023-05-05 02:53:20 - progress_bar.py[line:272] - INFO: epoch 010 | valid on 'valid' subset:    391 / 1907 loss=2.156, loss_v1=0, loss_v2=0, nll_loss=0.906, ntokens=406, nsentences=12, sample_size=406.0, sample_size_v1=0, sample_size_v2=0
2340556 <sub> man<pred> wearing<obj> shirt<pred> wearing<obj> short<pred> wearing<obj> shoe<pred> wearing<obj> shoe<pred> wearing<obj> shoe<pred> wearing<obj> shoe<pred> wearing<obj> shoe<sub> man<pred> wearing<obj> shirt<sub> man<pred> wearing<obj> shirt<sub> man<pred> wearing<obj> shirt<sub> man<pred> wearing<obj> shirt ['<sub> person<pred> holding<obj> jacket<pred> wearing<obj> shirt<pred> wearing<obj> pant<pred> wearing<obj> shoe<sub> woman<pred> carrying<obj> bag<pred> wearing<obj> pant<sub> person<pred> holding<obj> bag<sub> wheel<pred> on<obj> airplane<sub> guy<pred> wearing<obj> short<sub> guy<pred> wearing<obj> shirt<pred> wearing<obj> pant']
2322487 <sub> head<pred> of<obj> horse<sub> leg<pred> of<obj> horse<sub> leg<pred> of<obj> horse<sub> leg<pred> of<obj> horse<sub> leg<pred> of<obj> horse<sub> leg<pred> of<obj> horse<sub> leg<pred> of<obj> horse<sub> leg<pred> of<obj> horse ['<sub> man<pred> holding<obj> bottle<pred> holding<obj> umbrella<pred> holding<obj> umbrella<sub> umbrella<pred> over<obj> man<sub> umbrella<pred> over<obj> man<sub> man<pred> holding<obj> umbrella<sub> man<pred> holding<obj> bottle']
2023-05-05 02:53:30 - progress_bar.py[line:272] - INFO: epoch 010 | valid on 'valid' subset:    401 / 1907 loss=2.417, loss_v1=0, loss_v2=0, nll_loss=1.198, ntokens=421, nsentences=12, sample_size=421.0, sample_size_v1=0, sample_size_v2=0
2023-05-05 02:53:39 - progress_bar.py[line:272] - INFO: epoch 010 | valid on 'valid' subset:    411 / 1907 loss=2.437, loss_v1=0, loss_v2=0, nll_loss=1.216, ntokens=310, nsentences=12, sample_size=310.0, sample_size_v1=0, sample_size_v2=0
2023-05-05 02:53:50 - progress_bar.py[line:272] - INFO: epoch 010 | valid on 'valid' subset:    421 / 1907 loss=2.349, loss_v1=0, loss_v2=0, nll_loss=1.122, ntokens=394, nsentences=12, sample_size=394.0, sample_size_v1=0, sample_size_v2=0
2023-05-05 02:54:00 - progress_bar.py[line:272] - INFO: epoch 010 | valid on 'valid' subset:    431 / 1907 loss=2.274, loss_v1=0, loss_v2=0, nll_loss=1.034, ntokens=494, nsentences=12, sample_size=494.0, sample_size_v1=0, sample_size_v2=0
2023-05-05 02:54:10 - progress_bar.py[line:272] - INFO: epoch 010 | valid on 'valid' subset:    441 / 1907 loss=2.409, loss_v1=0, loss_v2=0, nll_loss=1.188, ntokens=391, nsentences=12, sample_size=391.0, sample_size_v1=0, sample_size_v2=0
2322052 <sub> man<pred> wearing<obj> jacket<pred> wearing<obj> pant<pred> wearing<obj> jacket<pred> wearing<obj> pant<sub> snow<pred> on<obj> mountain ['<sub> track<pred> on<obj> snow<sub> pant<pred> on<obj> man<sub> coat<pred> on<obj> man']
2340058 <sub> ear<pred> of<obj> elephant<sub> ear<pred> of<obj> elephant<sub> leg<pred> of<obj> elephant<sub> leg<pred> of<obj> elephant<sub> leg<pred> of<obj> elephant<sub> leg<pred> of<obj> elephant<sub> leg<pred> of<obj> elephant<sub> leg<pred> of<obj> elephant<sub> leg<pred> of<obj> elephant<sub> leg<pred> of<obj> elephant<sub> leg<pred> of<obj> elephant<sub> leg<pred> of<obj> elephant ['<sub> nose<pred> of<obj> sheep<sub> head<pred> of<obj> sheep<sub> ear<pred> of<obj> sheep<sub> ear<pred> of<obj> sheep<sub> sheep<pred> has<obj> leg<pred> has<obj> ear<pred> has<obj> eye<pred> has<obj> nose<sub> sheep<pred> has<obj> ear<pred> has<obj> ear<sub> person<pred> has<obj> hand<pred> wearing<obj> arm']
2023-05-05 02:54:18 - progress_bar.py[line:272] - INFO: epoch 010 | valid on 'valid' subset:    451 / 1907 loss=2.301, loss_v1=0, loss_v2=0, nll_loss=1.071, ntokens=405, nsentences=12, sample_size=405.0, sample_size_v1=0, sample_size_v2=0
2023-05-05 02:54:27 - progress_bar.py[line:272] - INFO: epoch 010 | valid on 'valid' subset:    461 / 1907 loss=2.363, loss_v1=0, loss_v2=0, nll_loss=1.137, ntokens=565, nsentences=12, sample_size=565.0, sample_size_v1=0, sample_size_v2=0
2023-05-05 02:54:37 - progress_bar.py[line:272] - INFO: epoch 010 | valid on 'valid' subset:    471 / 1907 loss=2.329, loss_v1=0, loss_v2=0, nll_loss=1.098, ntokens=398, nsentences=12, sample_size=398.0, sample_size_v1=0, sample_size_v2=0
2023-05-05 02:54:46 - progress_bar.py[line:272] - INFO: epoch 010 | valid on 'valid' subset:    481 / 1907 loss=2.353, loss_v1=0, loss_v2=0, nll_loss=1.12, ntokens=370, nsentences=12, sample_size=370.0, sample_size_v1=0, sample_size_v2=0
2023-05-05 02:54:56 - progress_bar.py[line:272] - INFO: epoch 010 | valid on 'valid' subset:    491 / 1907 loss=2.418, loss_v1=0, loss_v2=0, nll_loss=1.194, ntokens=328, nsentences=12, sample_size=328.0, sample_size_v1=0, sample_size_v2=0
2321636 <sub> bus<pred> on<obj> street<sub> window<pred> on<obj> building<sub> window<pred> on<obj> building<sub> window<pred> on<obj> building<sub> window<pred> on<obj> building ['<sub> car<pred> parked on<obj> street<sub> building<pred> near<obj> bus<sub> bus<pred> above<obj> street<pred> has<obj> window<sub> tree<pred> behind<obj> bus<sub> tree<pred> in front of<obj> building<sub> window<pred> on<obj> bus<sub> window<pred> on<obj> bus']
2339501 <sub> person<pred> holding<obj> surfboard<sub> person<pred> holding<obj> surfboard<sub> person<pred> holding<obj> surfboard<sub> person<pred> holding<obj> surfboard<sub> person<pred> holding<obj> surfboard<sub> person<pred> holding<obj> surfboard<sub> person<pred> holding<obj> surfboard<sub> person<pred> holding<obj> surfboard<sub> person<pred> holding<obj> surfboard ['<sub> man<pred> riding<obj> wave<sub> man<pred> standing on<obj> board<sub> board<pred> under<obj> arm<sub> man<pred> under<obj> arm<pred> holding<obj> board<sub> arm<pred> under<obj> board<pred> of<obj> person<sub> surfboard<pred> behind<obj> man<sub> man<pred> in<obj> wave<pred> watching<obj> man<sub> person<pred> has<obj> head<sub> person<pred> has<obj> arm<sub> leg<pred> of<obj> person<sub> leg<pred> of<obj> person<sub> leg<pred> of<obj> man<sub> man<pred> watching<obj> man<sub> person<pred> above<obj> surfboard']
2023-05-05 02:55:05 - progress_bar.py[line:272] - INFO: epoch 010 | valid on 'valid' subset:    501 / 1907 loss=2.284, loss_v1=0, loss_v2=0, nll_loss=1.048, ntokens=609, nsentences=12, sample_size=609.0, sample_size_v1=0, sample_size_v2=0
2023-05-05 02:55:14 - progress_bar.py[line:272] - INFO: epoch 010 | valid on 'valid' subset:    511 / 1907 loss=2.403, loss_v1=0, loss_v2=0, nll_loss=1.18, ntokens=337, nsentences=12, sample_size=337.0, sample_size_v1=0, sample_size_v2=0
2023-05-05 02:55:24 - progress_bar.py[line:272] - INFO: epoch 010 | valid on 'valid' subset:    521 / 1907 loss=2.228, loss_v1=0, loss_v2=0, nll_loss=0.991, ntokens=459, nsentences=12, sample_size=459.0, sample_size_v1=0, sample_size_v2=0
2023-05-05 02:55:33 - progress_bar.py[line:272] - INFO: epoch 010 | valid on 'valid' subset:    531 / 1907 loss=2.406, loss_v1=0, loss_v2=0, nll_loss=1.186, ntokens=446, nsentences=12, sample_size=446.0, sample_size_v1=0, sample_size_v2=0
2023-05-05 02:55:43 - progress_bar.py[line:272] - INFO: epoch 010 | valid on 'valid' subset:    541 / 1907 loss=2.311, loss_v1=0, loss_v2=0, nll_loss=1.076, ntokens=429, nsentences=12, sample_size=429.0, sample_size_v1=0, sample_size_v2=0
2338969 <sub> box<pred> on<obj> shelf<sub> box<pred> on<obj> shelf<sub> box<pred> on<obj> shelf<sub> box<pred> on<obj> shelf<sub> box<pred> on<obj> shelf<sub> box<pred> on<obj> shelf ['<sub> neck<pred> of<obj> bottle<sub> cap<pred> on<obj> bottle']
2321195 <sub> window<pred> on<obj> building<sub> window<pred> on<obj> building<sub> window<pred> on<obj> building<sub> window<pred> on<obj> building<sub> window<pred> on<obj> building<sub> window<pred> on<obj> building<sub> window<pred> on<obj> building<sub> window<pred> on<obj> building ['<sub> hand<pred> of<obj> clock<sub> face<pred> of<obj> clock<sub> building<pred> near<obj> tower<pred> with<obj> window<sub> clock<pred> on<obj> tower<pred> on<obj> tower<sub> window<pred> on<obj> building<sub> plate<pred> near<obj> clock<sub> tower<pred> has<obj> clock<sub> tower<pred> with<obj> clock']
2023-05-05 02:55:52 - progress_bar.py[line:272] - INFO: epoch 010 | valid on 'valid' subset:    551 / 1907 loss=2.29, loss_v1=0, loss_v2=0, nll_loss=1.053, ntokens=305, nsentences=12, sample_size=305.0, sample_size_v1=0, sample_size_v2=0
2023-05-05 02:56:01 - progress_bar.py[line:272] - INFO: epoch 010 | valid on 'valid' subset:    561 / 1907 loss=2.387, loss_v1=0, loss_v2=0, nll_loss=1.163, ntokens=349, nsentences=12, sample_size=349.0, sample_size_v1=0, sample_size_v2=0
2023-05-05 02:56:10 - progress_bar.py[line:272] - INFO: epoch 010 | valid on 'valid' subset:    571 / 1907 loss=2.154, loss_v1=0, loss_v2=0, nll_loss=0.906, ntokens=708, nsentences=12, sample_size=708.0, sample_size_v1=0, sample_size_v2=0
2023-05-05 02:56:20 - progress_bar.py[line:272] - INFO: epoch 010 | valid on 'valid' subset:    581 / 1907 loss=2.267, loss_v1=0, loss_v2=0, nll_loss=1.028, ntokens=425, nsentences=12, sample_size=425.0, sample_size_v1=0, sample_size_v2=0
2023-05-05 02:56:29 - progress_bar.py[line:272] - INFO: epoch 010 | valid on 'valid' subset:    591 / 1907 loss=2.393, loss_v1=0, loss_v2=0, nll_loss=1.167, ntokens=422, nsentences=12, sample_size=422.0, sample_size_v1=0, sample_size_v2=0
2338457 <sub> pillow<pred> on<obj> bed<sub> pillow<pred> on<obj> bed<sub> pillow<pred> on<obj> bed<sub> pillow<pred> on<obj> bed ['<sub> towel<pred> on<obj> bed<sub> bed<pred> in<obj> room<sub> bed<pred> in<obj> room<sub> table<pred> near<obj> bed']
2320764 <sub> man<pred> wearing<obj> shirt<sub> man<pred> wearing<obj> shirt<sub> man<pred> wearing<obj> shirt<sub> man<pred> wearing<obj> shirt<sub> man<pred> wearing<obj> shirt<sub> man<pred> wearing<obj> shirt<sub> man<pred> wearing<obj> shirt<sub> man<pred> wearing<obj> shirt<sub> man<pred> wearing<obj> shirt<sub> man<pred> wearing<obj> shirt<sub> man<pred> wearing<obj> shirt<sub> man<pred> wearing<obj> shirt ['<sub> person<pred> on<obj> sidewalk<pred> wearing<obj> shirt<pred> riding<obj> skateboard<pred> has<obj> jean<pred> on<obj> skateboard<sub> man<pred> wearing<obj> jacket<sub> woman<pred> standing on<obj> jacket<sub> person<pred> on<obj> skateboard<sub> person<pred> has<obj> shirt<sub> window<pred> of<obj> building<sub> man<pred> has<obj> shirt<pred> wearing<obj> shirt<pred> wearing<obj> shirt<sub> person<pred> watching<obj> man<sub> person<pred> watching<obj> man<sub> man<pred> in<obj> shirt<sub> people<pred> in<obj> building<sub> kid<pred> in<obj>']
2023-05-05 02:56:39 - progress_bar.py[line:272] - INFO: epoch 010 | valid on 'valid' subset:    601 / 1907 loss=2.358, loss_v1=0, loss_v2=0, nll_loss=1.132, ntokens=440, nsentences=12, sample_size=440.0, sample_size_v1=0, sample_size_v2=0
2023-05-05 02:56:49 - progress_bar.py[line:272] - INFO: epoch 010 | valid on 'valid' subset:    611 / 1907 loss=2.397, loss_v1=0, loss_v2=0, nll_loss=1.171, ntokens=456, nsentences=12, sample_size=456.0, sample_size_v1=0, sample_size_v2=0
2023-05-05 02:56:59 - progress_bar.py[line:272] - INFO: epoch 010 | valid on 'valid' subset:    621 / 1907 loss=2.323, loss_v1=0, loss_v2=0, nll_loss=1.089, ntokens=465, nsentences=12, sample_size=465.0, sample_size_v1=0, sample_size_v2=0
2023-05-05 02:57:09 - progress_bar.py[line:272] - INFO: epoch 010 | valid on 'valid' subset:    631 / 1907 loss=2.294, loss_v1=0, loss_v2=0, nll_loss=1.058, ntokens=367, nsentences=12, sample_size=367.0, sample_size_v1=0, sample_size_v2=0
2023-05-05 02:57:18 - progress_bar.py[line:272] - INFO: epoch 010 | valid on 'valid' subset:    641 / 1907 loss=2.224, loss_v1=0, loss_v2=0, nll_loss=0.983, ntokens=461, nsentences=12, sample_size=461.0, sample_size_v1=0, sample_size_v2=0
2337935 <sub> woman<pred> wearing<obj> hat<pred> wearing<obj> shirt<sub> hat<pred> on<obj> woman<sub> hat<pred> on<obj> woman ['<sub> leg<pred> on<obj> person<sub> person<pred> has<obj> leg<sub> man<pred> wearing<obj> hat<sub> player<pred> wearing<obj> hat']
2320355 <sub> window<pred> on<obj> building<sub> window<pred> on<obj> building<sub> window<pred> on<obj> building<sub> window<pred> on<obj> building<sub> window<pred> on<obj> building<sub> window<pred> on<obj> building ['<sub> car<pred> parked on<obj> street<sub> tree<pred> behind<obj> car<sub> trunk<pred> of<obj> car<sub> wheel<pred> on<obj> car<sub> wheel<pred> on<obj> car']
2023-05-05 02:57:28 - progress_bar.py[line:272] - INFO: epoch 010 | valid on 'valid' subset:    651 / 1907 loss=2.187, loss_v1=0, loss_v2=0, nll_loss=0.934, ntokens=506, nsentences=12, sample_size=506.0, sample_size_v1=0, sample_size_v2=0
2023-05-05 02:57:38 - progress_bar.py[line:272] - INFO: epoch 010 | valid on 'valid' subset:    661 / 1907 loss=2.415, loss_v1=0, loss_v2=0, nll_loss=1.196, ntokens=390, nsentences=12, sample_size=390.0, sample_size_v1=0, sample_size_v2=0
2023-05-05 02:57:48 - progress_bar.py[line:272] - INFO: epoch 010 | valid on 'valid' subset:    671 / 1907 loss=2.149, loss_v1=0, loss_v2=0, nll_loss=0.893, ntokens=550, nsentences=12, sample_size=550.0, sample_size_v1=0, sample_size_v2=0
2023-05-05 02:57:57 - progress_bar.py[line:272] - INFO: epoch 010 | valid on 'valid' subset:    681 / 1907 loss=2.506, loss_v1=0, loss_v2=0, nll_loss=1.296, ntokens=453, nsentences=12, sample_size=453.0, sample_size_v1=0, sample_size_v2=0
2023-05-05 02:58:07 - progress_bar.py[line:272] - INFO: epoch 010 | valid on 'valid' subset:    691 / 1907 loss=2.198, loss_v1=0, loss_v2=0, nll_loss=0.957, ntokens=361, nsentences=12, sample_size=361.0, sample_size_v1=0, sample_size_v2=0
2337395 <sub> wing<pred> of<obj> bird<sub> wing<pred> of<obj> bird<sub> wing<pred> of<obj> bird<sub> wing<pred> of<obj> bird<sub> wing<pred> of<obj> bird ['<sub> boat<pred> sitting on<obj> snow<pred> on<obj> snow<sub> tree<pred> on<obj> mountain<sub> tree<pred> on<obj> mountain<sub> tree<pred> on<obj> mountain<sub> tree<pred> on<obj> mountain<sub> tree<pred> on<obj> mountain<sub> tree<pred> on<obj> mountain']
2319934 <sub> man<pred> wearing<obj> jacket<pred> wearing<obj> pant<sub> man<pred> wearing<obj> jacket<pred> wearing<obj> pant<pred> wearing<obj> jacket<sub> man<pred> wearing<obj> jacket<pred> wearing<obj> pant ['<sub> man<pred> has<obj> helmet<sub> snow<pred> has<obj> track']
2023-05-05 02:58:16 - progress_bar.py[line:272] - INFO: epoch 010 | valid on 'valid' subset:    701 / 1907 loss=2.344, loss_v1=0, loss_v2=0, nll_loss=1.113, ntokens=447, nsentences=12, sample_size=447.0, sample_size_v1=0, sample_size_v2=0
2023-05-05 02:58:25 - progress_bar.py[line:272] - INFO: epoch 010 | valid on 'valid' subset:    711 / 1907 loss=2.252, loss_v1=0, loss_v2=0, nll_loss=1.007, ntokens=532, nsentences=12, sample_size=532.0, sample_size_v1=0, sample_size_v2=0
2023-05-05 02:58:35 - progress_bar.py[line:272] - INFO: epoch 010 | valid on 'valid' subset:    721 / 1907 loss=2.447, loss_v1=0, loss_v2=0, nll_loss=1.229, ntokens=342, nsentences=12, sample_size=342.0, sample_size_v1=0, sample_size_v2=0
2023-05-05 02:58:45 - progress_bar.py[line:272] - INFO: epoch 010 | valid on 'valid' subset:    731 / 1907 loss=2.415, loss_v1=0, loss_v2=0, nll_loss=1.193, ntokens=357, nsentences=12, sample_size=357.0, sample_size_v1=0, sample_size_v2=0
2023-05-05 02:58:54 - progress_bar.py[line:272] - INFO: epoch 010 | valid on 'valid' subset:    741 / 1907 loss=2.359, loss_v1=0, loss_v2=0, nll_loss=1.132, ntokens=562, nsentences=12, sample_size=562.0, sample_size_v1=0, sample_size_v2=0
2336932 <sub> pizza<pred> on<obj> plate<sub> plate<pred> on<obj> table<sub> pizza<pred> on<obj> plate ['<sub> plate<pred> of<obj> food<sub> shirt<pred> on<obj> man']
2319536 <sub> plane<pred> has<obj> tail<pred> has<obj> engine<pred> has<obj> wing<pred> has<obj> engine<pred> has<obj> engine<pred> has<obj> engine<pred> has<obj> wing<pred> has<obj> engine<sub> engine<pred> under<obj> wing<sub> engine<pred> under<obj> wing<sub> engine<pred> under<obj> wing ['<sub> leaf<pred> on<obj> tail<sub> engine<pred> of<obj> plane<sub> engine<pred> of<obj> plane<sub> window<pred> on<obj> plane<sub> wing<pred> on<obj> plane<sub> tail<pred> on<obj> plane<sub> nose<pred> of<obj> plane']
2023-05-05 02:59:04 - progress_bar.py[line:272] - INFO: epoch 010 | valid on 'valid' subset:    751 / 1907 loss=2.164, loss_v1=0, loss_v2=0, nll_loss=0.919, ntokens=441, nsentences=12, sample_size=441.0, sample_size_v1=0, sample_size_v2=0
2023-05-05 02:59:13 - progress_bar.py[line:272] - INFO: epoch 010 | valid on 'valid' subset:    761 / 1907 loss=2.217, loss_v1=0, loss_v2=0, nll_loss=0.97, ntokens=390, nsentences=12, sample_size=390.0, sample_size_v1=0, sample_size_v2=0
2023-05-05 02:59:23 - progress_bar.py[line:272] - INFO: epoch 010 | valid on 'valid' subset:    771 / 1907 loss=2.309, loss_v1=0, loss_v2=0, nll_loss=1.074, ntokens=486, nsentences=12, sample_size=486.0, sample_size_v1=0, sample_size_v2=0
2023-05-05 02:59:33 - progress_bar.py[line:272] - INFO: epoch 010 | valid on 'valid' subset:    781 / 1907 loss=2.157, loss_v1=0, loss_v2=0, nll_loss=0.904, ntokens=567, nsentences=12, sample_size=567.0, sample_size_v1=0, sample_size_v2=0
2023-05-05 02:59:42 - progress_bar.py[line:272] - INFO: epoch 010 | valid on 'valid' subset:    791 / 1907 loss=2.193, loss_v1=0, loss_v2=0, nll_loss=0.944, ntokens=460, nsentences=12, sample_size=460.0, sample_size_v1=0, sample_size_v2=0
2319123 <sub> head<pred> of<obj> giraffe<sub> leg<pred> of<obj> giraffe<sub> leg<pred> of<obj> giraffe<sub> leg<pred> of<obj> giraffe<sub> leg<pred> of<obj> giraffe<sub> leg<pred> of<obj> giraffe<sub> leg<pred> of<obj> giraffe ['<sub> giraffe<pred> has<obj> head<sub> tree<pred> near<obj> giraffe<sub> leg<pred> on<obj> giraffe<sub> leg<pred> on<obj> giraffe<sub> leg<pred> of<obj> giraffe<sub> tail<pred> of<obj> giraffe<sub> head<pred> of<obj> giraffe']
2336515 <sub> man<pred> wearing<obj> shirt<pred> wearing<obj> short<pred> wearing<obj> sneaker<pred> wearing<obj> sneaker<pred> wearing<obj> sock<pred> wearing<obj> sock<pred> wearing<obj> sock<pred> wearing<obj> sock<pred> wearing<obj> sock<pred> wearing<obj> sock<pred> wearing<obj> sock<pred> wearing<obj> sock<pred> wearing<obj> sock<pred> wearing<obj> sock<pred> wearing<obj> sock<pred> wearing<obj> sock<pred> wearing<obj> sock<pred> wearing<obj> sock<pred> wearing<obj> sock<pred> wearing<obj> sock<pred> wearing<obj> sock<pred> wearing<obj> sock<pred> wearing<obj> sock<pred> wearing<obj> sock ['<sub> man<pred> wearing<obj> shoe<pred> in<obj> shirt<pred> wearing<obj> short<pred> has<obj> hair<sub> shoe<pred> of<obj> man<sub> leg<pred> on<obj> man<sub> leg<pred> on<obj> man<sub> arm<pred> on<obj> man<sub> arm<pred> on<obj> person']
2023-05-05 02:59:52 - progress_bar.py[line:272] - INFO: epoch 010 | valid on 'valid' subset:    801 / 1907 loss=2.16, loss_v1=0, loss_v2=0, nll_loss=0.906, ntokens=420, nsentences=12, sample_size=420.0, sample_size_v1=0, sample_size_v2=0
2023-05-05 03:00:02 - progress_bar.py[line:272] - INFO: epoch 010 | valid on 'valid' subset:    811 / 1907 loss=2.28, loss_v1=0, loss_v2=0, nll_loss=1.048, ntokens=435, nsentences=12, sample_size=435.0, sample_size_v1=0, sample_size_v2=0
2023-05-05 03:00:12 - progress_bar.py[line:272] - INFO: epoch 010 | valid on 'valid' subset:    821 / 1907 loss=2.317, loss_v1=0, loss_v2=0, nll_loss=1.086, ntokens=443, nsentences=12, sample_size=443.0, sample_size_v1=0, sample_size_v2=0
2023-05-05 03:00:23 - progress_bar.py[line:272] - INFO: epoch 010 | valid on 'valid' subset:    831 / 1907 loss=2.315, loss_v1=0, loss_v2=0, nll_loss=1.077, ntokens=417, nsentences=12, sample_size=417.0, sample_size_v1=0, sample_size_v2=0
2023-05-05 03:00:34 - progress_bar.py[line:272] - INFO: epoch 010 | valid on 'valid' subset:    841 / 1907 loss=2.46, loss_v1=0, loss_v2=0, nll_loss=1.247, ntokens=343, nsentences=12, sample_size=343.0, sample_size_v1=0, sample_size_v2=0
2318710 <sub> leg<pred> of<obj> giraffe<sub> leg<pred> of<obj> giraffe<sub> leg<pred> of<obj> giraffe<sub> leg<pred> of<obj> giraffe<sub> leg<pred> of<obj> giraffe<sub> leg<pred> of<obj> giraffe ['<sub> head<pred> of<obj> giraffe<sub> leg<pred> of<obj> giraffe<sub> neck<pred> of<obj> giraffe<sub> giraffe<pred> has<obj> tail']
2336101 <sub> man<pred> wearing<obj> tie<pred> wearing<obj> shirt<pred> wearing<obj> tie<pred> wearing<obj> shirt<pred> has<obj> hair<sub> tie<pred> on<obj> man<sub> tie<pred> on<obj> man<sub> tie<pred> on<obj> man<sub> tie<pred> on<obj> man ['<sub> man<pred> has<obj> hand<pred> wearing<obj> tie<sub> finger<pred> of<obj> man']
2023-05-05 03:00:44 - progress_bar.py[line:272] - INFO: epoch 010 | valid on 'valid' subset:    851 / 1907 loss=2.35, loss_v1=0, loss_v2=0, nll_loss=1.12, ntokens=379, nsentences=12, sample_size=379.0, sample_size_v1=0, sample_size_v2=0
2023-05-05 03:00:54 - progress_bar.py[line:272] - INFO: epoch 010 | valid on 'valid' subset:    861 / 1907 loss=2.375, loss_v1=0, loss_v2=0, nll_loss=1.144, ntokens=480, nsentences=12, sample_size=480.0, sample_size_v1=0, sample_size_v2=0
2023-05-05 03:01:04 - progress_bar.py[line:272] - INFO: epoch 010 | valid on 'valid' subset:    871 / 1907 loss=2.335, loss_v1=0, loss_v2=0, nll_loss=1.107, ntokens=395, nsentences=12, sample_size=395.0, sample_size_v1=0, sample_size_v2=0
2023-05-05 03:01:14 - progress_bar.py[line:272] - INFO: epoch 010 | valid on 'valid' subset:    881 / 1907 loss=2.283, loss_v1=0, loss_v2=0, nll_loss=1.045, ntokens=468, nsentences=12, sample_size=468.0, sample_size_v1=0, sample_size_v2=0
2023-05-05 03:01:25 - progress_bar.py[line:272] - INFO: epoch 010 | valid on 'valid' subset:    891 / 1907 loss=2.285, loss_v1=0, loss_v2=0, nll_loss=1.048, ntokens=465, nsentences=12, sample_size=465.0, sample_size_v1=0, sample_size_v2=0
2318313 <sub> man<pred> holding<obj> surfboard<sub> man<pred> holding<obj> surfboard<pred> holding<obj> surfboard<sub> man<pred> holding<obj> surfboard<sub> man<pred> holding<obj> surfboard<sub> man<pred> holding<obj> surfboard ['<sub> flag<pred> hanging from<obj> tree<pred> hanging from<obj> tree<pred> hanging from<obj> tree<sub> fence<pred> in<obj> building<sub> board<pred> on<obj> trunk<pred> on<obj> trunk<sub> trunk<pred> under<obj> board<sub> trunk<pred> on<obj> tree<sub> railing<pred> on<obj> building<sub> tree<pred> along<obj> building<sub> tree<pred> along<obj> building<sub> tree<pred> along<obj> building<sub> tree<pred> along<obj> building']
2335683 <sub> car<pred> parked on<obj> street<sub> car<pred> parked on<obj> street<sub> car<pred> parked on<obj> street<sub> car<pred> parked on<obj> street<sub> car<pred> parked on<obj> street<sub> car<pred> parked on<obj> street<sub> car<pred> parked on<obj> street<sub> car<pred> parked on<obj> street<sub> car<pred> parked on<obj> street<sub> car<pred> parked on<obj> street<sub> car<pred> parked on<obj> street<sub> car<pred> parked on<obj> street ['<sub> tower<pred> above<obj> hill<sub> car<pred> in<obj> street<sub> car<pred> with<obj> light']
2023-05-05 03:01:36 - progress_bar.py[line:272] - INFO: epoch 010 | valid on 'valid' subset:    901 / 1907 loss=2.46, loss_v1=0, loss_v2=0, nll_loss=1.248, ntokens=435, nsentences=12, sample_size=435.0, sample_size_v1=0, sample_size_v2=0
2023-05-05 03:01:46 - progress_bar.py[line:272] - INFO: epoch 010 | valid on 'valid' subset:    911 / 1907 loss=2.356, loss_v1=0, loss_v2=0, nll_loss=1.132, ntokens=572, nsentences=12, sample_size=572.0, sample_size_v1=0, sample_size_v2=0
2023-05-05 03:01:55 - progress_bar.py[line:272] - INFO: epoch 010 | valid on 'valid' subset:    921 / 1907 loss=2.294, loss_v1=0, loss_v2=0, nll_loss=1.06, ntokens=483, nsentences=12, sample_size=483.0, sample_size_v1=0, sample_size_v2=0
2023-05-05 03:02:06 - progress_bar.py[line:272] - INFO: epoch 010 | valid on 'valid' subset:    931 / 1907 loss=2.376, loss_v1=0, loss_v2=0, nll_loss=1.147, ntokens=611, nsentences=12, sample_size=611.0, sample_size_v1=0, sample_size_v2=0
2023-05-05 03:02:16 - progress_bar.py[line:272] - INFO: epoch 010 | valid on 'valid' subset:    941 / 1907 loss=2.435, loss_v1=0, loss_v2=0, nll_loss=1.217, ntokens=431, nsentences=12, sample_size=431.0, sample_size_v1=0, sample_size_v2=0
2317943 <sub> tower<pred> near<obj> building<sub> tree<pred> near<obj> building<sub> clock<pred> on<obj> tower ['<sub> dog<pred> on<obj> bench<sub> tree<pred> behind<obj> bench']
2335268 <sub> man<pred> wearing<obj> short<pred> wearing<obj> shirt<pred> wearing<obj> sock<pred> wearing<obj> sock<pred> wearing<obj> sock<pred> wearing<obj> sock<pred> wearing<obj> sock<pred> wearing<obj> sock ['<sub> sock<pred> on<obj> leg<sub> boy<pred> wearing<obj> shirt']
2023-05-05 03:02:25 - progress_bar.py[line:272] - INFO: epoch 010 | valid on 'valid' subset:    951 / 1907 loss=2.404, loss_v1=0, loss_v2=0, nll_loss=1.179, ntokens=359, nsentences=12, sample_size=359.0, sample_size_v1=0, sample_size_v2=0
2023-05-05 03:02:34 - progress_bar.py[line:272] - INFO: epoch 010 | valid on 'valid' subset:    961 / 1907 loss=2.319, loss_v1=0, loss_v2=0, nll_loss=1.085, ntokens=488, nsentences=12, sample_size=488.0, sample_size_v1=0, sample_size_v2=0
2023-05-05 03:02:44 - progress_bar.py[line:272] - INFO: epoch 010 | valid on 'valid' subset:    971 / 1907 loss=2.224, loss_v1=0, loss_v2=0, nll_loss=0.982, ntokens=351, nsentences=12, sample_size=351.0, sample_size_v1=0, sample_size_v2=0
2023-05-05 03:02:54 - progress_bar.py[line:272] - INFO: epoch 010 | valid on 'valid' subset:    981 / 1907 loss=2.283, loss_v1=0, loss_v2=0, nll_loss=1.044, ntokens=451, nsentences=12, sample_size=451.0, sample_size_v1=0, sample_size_v2=0
2023-05-05 03:03:04 - progress_bar.py[line:272] - INFO: epoch 010 | valid on 'valid' subset:    991 / 1907 loss=2.407, loss_v1=0, loss_v2=0, nll_loss=1.185, ntokens=390, nsentences=12, sample_size=390.0, sample_size_v1=0, sample_size_v2=0
2334815 <sub> man<pred> wearing<obj> glass<pred> wearing<obj> tie<pred> wearing<obj> shirt<pred> has<obj> hair<sub> man<pred> wearing<obj> tie<pred> wearing<obj> glass<pred> wearing<obj> shirt<sub> glass<pred> on<obj> face<sub> glass<pred> on<obj> face<sub> glass<pred> on<obj> face ['<sub> leg<pred> of<obj> person<sub> leg<pred> of<obj> person<sub> leg<pred> of<obj> person<sub> leg<pred> of<obj> person<sub> leg<pred> of<obj> woman<sub> person<pred> in<obj> house']
2317554 <sub> food<pred> on<obj> plate ['<sub> pizza<pred> in<obj> table<sub> table<pred> under<obj> pizza']
2023-05-05 03:03:14 - progress_bar.py[line:272] - INFO: epoch 010 | valid on 'valid' subset:   1001 / 1907 loss=2.181, loss_v1=0, loss_v2=0, nll_loss=0.933, ntokens=396, nsentences=12, sample_size=396.0, sample_size_v1=0, sample_size_v2=0
2023-05-05 03:03:24 - progress_bar.py[line:272] - INFO: epoch 010 | valid on 'valid' subset:   1011 / 1907 loss=2.187, loss_v1=0, loss_v2=0, nll_loss=0.945, ntokens=521, nsentences=12, sample_size=521.0, sample_size_v1=0, sample_size_v2=0
2023-05-05 03:03:34 - progress_bar.py[line:272] - INFO: epoch 010 | valid on 'valid' subset:   1021 / 1907 loss=2.329, loss_v1=0, loss_v2=0, nll_loss=1.099, ntokens=488, nsentences=12, sample_size=488.0, sample_size_v1=0, sample_size_v2=0
2023-05-05 03:03:43 - progress_bar.py[line:272] - INFO: epoch 010 | valid on 'valid' subset:   1031 / 1907 loss=2.271, loss_v1=0, loss_v2=0, nll_loss=1.03, ntokens=500, nsentences=12, sample_size=500.0, sample_size_v1=0, sample_size_v2=0
2023-05-05 03:03:52 - progress_bar.py[line:272] - INFO: epoch 010 | valid on 'valid' subset:   1041 / 1907 loss=2.294, loss_v1=0, loss_v2=0, nll_loss=1.061, ntokens=440, nsentences=12, sample_size=440.0, sample_size_v1=0, sample_size_v2=0
2334375 <sub> man<pred> wearing<obj> tie<pred> wearing<obj> shirt<pred> has<obj> hair<pred> wearing<obj> shirt<sub> man<pred> wearing<obj> shirt<pred> wearing<obj> tie<pred> wearing<obj> shirt<sub> tie<pred> on<obj> man<sub> shirt<pred> on<obj> man<sub> shirt<pred> on<obj> man ['<sub> dog<pred> on<obj> table<pred> has<obj> nose<pred> has<obj> eye<pred> has<obj> ear<pred> has<obj> ear<pred> has<obj> neck<pred> has<obj> eye<pred> near<obj> laptop<sub> laptop<pred> has<obj> screen<sub> nose<pred> on<obj> dog<sub> eye<pred> on<obj> dog']
2317175 <sub> car<pred> on<obj> street<sub> car<pred> on<obj> street<sub> car<pred> on<obj> street<sub> car<pred> on<obj> street<sub> car<pred> on<obj> street<sub> car<pred> on<obj> street<sub> car<pred> on<obj> street<sub> car<pred> on<obj> street ['<sub> sign<pred> near<obj> building<sub> sign<pred> above<obj> building<sub> bench<pred> on<obj> sidewalk']
2023-05-05 03:04:03 - progress_bar.py[line:272] - INFO: epoch 010 | valid on 'valid' subset:   1051 / 1907 loss=2.386, loss_v1=0, loss_v2=0, nll_loss=1.162, ntokens=432, nsentences=12, sample_size=432.0, sample_size_v1=0, sample_size_v2=0
2023-05-05 03:04:12 - progress_bar.py[line:272] - INFO: epoch 010 | valid on 'valid' subset:   1061 / 1907 loss=2.197, loss_v1=0, loss_v2=0, nll_loss=0.95, ntokens=620, nsentences=12, sample_size=620.0, sample_size_v1=0, sample_size_v2=0
2023-05-05 03:04:22 - progress_bar.py[line:272] - INFO: epoch 010 | valid on 'valid' subset:   1071 / 1907 loss=2.357, loss_v1=0, loss_v2=0, nll_loss=1.13, ntokens=382, nsentences=12, sample_size=382.0, sample_size_v1=0, sample_size_v2=0
2023-05-05 03:04:32 - progress_bar.py[line:272] - INFO: epoch 010 | valid on 'valid' subset:   1081 / 1907 loss=2.261, loss_v1=0, loss_v2=0, nll_loss=1.018, ntokens=366, nsentences=12, sample_size=366.0, sample_size_v1=0, sample_size_v2=0
2023-05-05 03:04:42 - progress_bar.py[line:272] - INFO: epoch 010 | valid on 'valid' subset:   1091 / 1907 loss=2.407, loss_v1=0, loss_v2=0, nll_loss=1.19, ntokens=357, nsentences=12, sample_size=357.0, sample_size_v1=0, sample_size_v2=0
2316790 <sub> window<pred> on<obj> building<sub> window<pred> on<obj> building<sub> window<pred> on<obj> building<sub> window<pred> on<obj> building<sub> window<pred> on<obj> building<sub> window<pred> on<obj> building<sub> window<pred> on<obj> building<sub> window<pred> on<obj> building ['<sub> car<pred> has<obj> wheel<pred> has<obj> door<pred> has<obj> window<pred> has<obj> window<sub> man<pred> on<obj> sidewalk<sub> door<pred> has<obj> handle<sub> car<pred> parked on<obj> street']
2333942 <sub> man<pred> wearing<obj> shirt<pred> wearing<obj> sneaker<pred> wearing<obj> sneaker<pred> wearing<obj> sneaker<sub> man<pred> wearing<obj> shirt ['<sub> pant<pred> on<obj> woman<sub> seat<pred> of<obj> bike<sub> woman<pred> wearing<obj> sneaker<pred> wearing<obj> shirt<sub> basket<pred> on<obj> bike']
2023-05-05 03:04:52 - progress_bar.py[line:272] - INFO: epoch 010 | valid on 'valid' subset:   1101 / 1907 loss=2.344, loss_v1=0, loss_v2=0, nll_loss=1.116, ntokens=533, nsentences=12, sample_size=533.0, sample_size_v1=0, sample_size_v2=0
2023-05-05 03:05:02 - progress_bar.py[line:272] - INFO: epoch 010 | valid on 'valid' subset:   1111 / 1907 loss=2.301, loss_v1=0, loss_v2=0, nll_loss=1.07, ntokens=483, nsentences=12, sample_size=483.0, sample_size_v1=0, sample_size_v2=0
2023-05-05 03:05:12 - progress_bar.py[line:272] - INFO: epoch 010 | valid on 'valid' subset:   1121 / 1907 loss=2.379, loss_v1=0, loss_v2=0, nll_loss=1.155, ntokens=360, nsentences=12, sample_size=360.0, sample_size_v1=0, sample_size_v2=0
2023-05-05 03:05:22 - progress_bar.py[line:272] - INFO: epoch 010 | valid on 'valid' subset:   1131 / 1907 loss=2.33, loss_v1=0, loss_v2=0, nll_loss=1.098, ntokens=360, nsentences=12, sample_size=360.0, sample_size_v1=0, sample_size_v2=0
2023-05-05 03:05:32 - progress_bar.py[line:272] - INFO: epoch 010 | valid on 'valid' subset:   1141 / 1907 loss=2.302, loss_v1=0, loss_v2=0, nll_loss=1.066, ntokens=511, nsentences=12, sample_size=511.0, sample_size_v1=0, sample_size_v2=0
2333484 <sub> man<pred> wearing<obj> short<pred> wearing<obj> shirt<pred> wearing<obj> shoe<pred> wearing<obj> shoe<pred> wearing<obj> shoe<sub> fence<pred> behind<obj> man ['<sub> handle<pred> on<obj> bag<sub> dog<pred> walking on<obj> sidewalk<pred> with<obj> bag<sub> tail<pred> of<obj> dog<sub> bag<pred> on<obj> dog']
2316407 <sub> man<pred> wearing<obj> shirt<pred> wearing<obj> short<pred> has<obj> hair<sub> man<pred> wearing<obj> shirt<pred> has<obj> hair ['<sub> hair<pred> on<obj> girl<pred> on<obj> head']
2023-05-05 03:05:43 - progress_bar.py[line:272] - INFO: epoch 010 | valid on 'valid' subset:   1151 / 1907 loss=2.416, loss_v1=0, loss_v2=0, nll_loss=1.196, ntokens=433, nsentences=12, sample_size=433.0, sample_size_v1=0, sample_size_v2=0
2023-05-05 03:05:52 - progress_bar.py[line:272] - INFO: epoch 010 | valid on 'valid' subset:   1161 / 1907 loss=2.314, loss_v1=0, loss_v2=0, nll_loss=1.077, ntokens=473, nsentences=12, sample_size=473.0, sample_size_v1=0, sample_size_v2=0
2023-05-05 03:06:03 - progress_bar.py[line:272] - INFO: epoch 010 | valid on 'valid' subset:   1171 / 1907 loss=2.306, loss_v1=0, loss_v2=0, nll_loss=1.07, ntokens=581, nsentences=12, sample_size=581.0, sample_size_v1=0, sample_size_v2=0
2023-05-05 03:06:13 - progress_bar.py[line:272] - INFO: epoch 010 | valid on 'valid' subset:   1181 / 1907 loss=2.173, loss_v1=0, loss_v2=0, nll_loss=0.93, ntokens=324, nsentences=12, sample_size=324.0, sample_size_v1=0, sample_size_v2=0
2023-05-05 03:06:22 - progress_bar.py[line:272] - INFO: epoch 010 | valid on 'valid' subset:   1191 / 1907 loss=2.392, loss_v1=0, loss_v2=0, nll_loss=1.169, ntokens=658, nsentences=12, sample_size=658.0, sample_size_v1=0, sample_size_v2=0
2333035 <sub> car<pred> on<obj> street<sub> car<pred> on<obj> street<sub> car<pred> on<obj> street<sub> car<pred> on<obj> street<sub> car<pred> on<obj> street<sub> car<pred> on<obj> street<sub> car<pred> on<obj> street<sub> car<pred> on<obj> street<sub> car<pred> on<obj> street<sub> car<pred> on<obj> street ['<sub> tree<pred> near<obj> street<sub> sign<pred> on<obj> pole<sub> man<pred> wears<obj> shirt<sub> man<pred> has<obj> head<sub> man<pred> has<obj> arm<pred> has<obj> leg<pred> with<obj> hat']
2316002 <sub> car<pred> parked on<obj> street<sub> car<pred> parked on<obj> street<sub> car<pred> parked on<obj> street<sub> car<pred> parked on<obj> street<sub> car<pred> parked on<obj> street ['<sub> sign<pred> on<obj> sidewalk<sub> sign<pred> on<obj> sidewalk<sub> tree<pred> in front of<obj> building<sub> street<pred> near<obj> sign<sub> street<pred> near<obj> sidewalk']
2023-05-05 03:06:31 - progress_bar.py[line:272] - INFO: epoch 010 | valid on 'valid' subset:   1201 / 1907 loss=2.301, loss_v1=0, loss_v2=0, nll_loss=1.068, ntokens=468, nsentences=12, sample_size=468.0, sample_size_v1=0, sample_size_v2=0
2023-05-05 03:06:42 - progress_bar.py[line:272] - INFO: epoch 010 | valid on 'valid' subset:   1211 / 1907 loss=2.199, loss_v1=0, loss_v2=0, nll_loss=0.954, ntokens=356, nsentences=12, sample_size=356.0, sample_size_v1=0, sample_size_v2=0
2023-05-05 03:06:51 - progress_bar.py[line:272] - INFO: epoch 010 | valid on 'valid' subset:   1221 / 1907 loss=2.314, loss_v1=0, loss_v2=0, nll_loss=1.082, ntokens=391, nsentences=12, sample_size=391.0, sample_size_v1=0, sample_size_v2=0
2023-05-05 03:07:00 - progress_bar.py[line:272] - INFO: epoch 010 | valid on 'valid' subset:   1231 / 1907 loss=2.354, loss_v1=0, loss_v2=0, nll_loss=1.126, ntokens=328, nsentences=12, sample_size=328.0, sample_size_v1=0, sample_size_v2=0
2023-05-05 03:07:09 - progress_bar.py[line:272] - INFO: epoch 010 | valid on 'valid' subset:   1241 / 1907 loss=2.254, loss_v1=0, loss_v2=0, nll_loss=1.014, ntokens=404, nsentences=12, sample_size=404.0, sample_size_v1=0, sample_size_v2=0
2332511 <sub> paper<pred> on<obj> table<sub> paper<pred> on<obj> table<sub> paper<pred> on<obj> table<sub> paper<pred> on<obj> table<sub> paper<pred> on<obj> table ['<sub> plate<pred> of<obj> food<pred> on<obj> table<sub> vegetable<pred> on<obj> plate<sub> fork<pred> on<obj> plate<sub> chair<pred> at<obj> table<sub> food<pred> on<obj> plate<sub> glass<pred> on<obj> table<sub> vegetable<pred> on<obj> plate']
2315534 <sub> tree<pred> behind<obj> giraffe<sub> giraffe<pred> has<obj> tail ['<sub> rock<pred> near<obj> rock<sub> rock<pred> near<obj> rock']
2023-05-05 03:07:17 - progress_bar.py[line:272] - INFO: epoch 010 | valid on 'valid' subset:   1251 / 1907 loss=2.166, loss_v1=0, loss_v2=0, nll_loss=0.915, ntokens=425, nsentences=12, sample_size=425.0, sample_size_v1=0, sample_size_v2=0
2023-05-05 03:07:27 - progress_bar.py[line:272] - INFO: epoch 010 | valid on 'valid' subset:   1261 / 1907 loss=2.158, loss_v1=0, loss_v2=0, nll_loss=0.898, ntokens=411, nsentences=12, sample_size=411.0, sample_size_v1=0, sample_size_v2=0
2023-05-05 03:07:35 - progress_bar.py[line:272] - INFO: epoch 010 | valid on 'valid' subset:   1271 / 1907 loss=2.198, loss_v1=0, loss_v2=0, nll_loss=0.952, ntokens=417, nsentences=12, sample_size=417.0, sample_size_v1=0, sample_size_v2=0
2023-05-05 03:07:44 - progress_bar.py[line:272] - INFO: epoch 010 | valid on 'valid' subset:   1281 / 1907 loss=2.393, loss_v1=0, loss_v2=0, nll_loss=1.163, ntokens=282, nsentences=12, sample_size=282.0, sample_size_v1=0, sample_size_v2=0
2023-05-05 03:07:52 - progress_bar.py[line:272] - INFO: epoch 010 | valid on 'valid' subset:   1291 / 1907 loss=2.238, loss_v1=0, loss_v2=0, nll_loss=1, ntokens=409, nsentences=12, sample_size=409.0, sample_size_v1=0, sample_size_v2=0
2331944 <sub> boy<pred> has<obj> hair<pred> wearing<obj> shirt<pred> wearing<obj> jean<pred> has<obj> hand<pred> has<obj> hand<pred> has<obj> arm<pred> has<obj> arm<pred> has<obj> arm<pred> has<obj> arm<pred> has<obj> arm<sub> tree<pred> behind<obj> boy<sub> tree<pred> behind<obj> boy ['<sub> person<pred> has<obj> hair<sub> boy<pred> wearing<obj> jean<pred> has<obj> hand<pred> has<obj> hand<sub> hand<pred> holding<obj> plate<sub> fork<pred> on<obj> hand']
2414722 <sub> man<pred> on<obj> surfboard<pred> on<obj> wave<pred> on<obj> surfboard<sub> wave<pred> behind<obj> man<sub> wave<pred> behind<obj> man ['<sub> man<pred> holding<obj> surfboard<sub> surfboard<pred> under<obj> arm']
2023-05-05 03:08:01 - progress_bar.py[line:272] - INFO: epoch 010 | valid on 'valid' subset:   1301 / 1907 loss=2.288, loss_v1=0, loss_v2=0, nll_loss=1.054, ntokens=332, nsentences=12, sample_size=332.0, sample_size_v1=0, sample_size_v2=0
2023-05-05 03:08:09 - progress_bar.py[line:272] - INFO: epoch 010 | valid on 'valid' subset:   1311 / 1907 loss=2.567, loss_v1=0, loss_v2=0, nll_loss=1.365, ntokens=299, nsentences=12, sample_size=299.0, sample_size_v1=0, sample_size_v2=0
2023-05-05 03:08:17 - progress_bar.py[line:272] - INFO: epoch 010 | valid on 'valid' subset:   1321 / 1907 loss=2.375, loss_v1=0, loss_v2=0, nll_loss=1.149, ntokens=271, nsentences=12, sample_size=271.0, sample_size_v1=0, sample_size_v2=0
2023-05-05 03:08:27 - progress_bar.py[line:272] - INFO: epoch 010 | valid on 'valid' subset:   1331 / 1907 loss=2.372, loss_v1=0, loss_v2=0, nll_loss=1.145, ntokens=395, nsentences=12, sample_size=395.0, sample_size_v1=0, sample_size_v2=0
2023-05-05 03:08:36 - progress_bar.py[line:272] - INFO: epoch 010 | valid on 'valid' subset:   1341 / 1907 loss=2.388, loss_v1=0, loss_v2=0, nll_loss=1.162, ntokens=412, nsentences=12, sample_size=412.0, sample_size_v1=0, sample_size_v2=0
2414130 <sub> man<pred> on<obj> surfboard<pred> has<obj> arm<pred> has<obj> arm<pred> has<obj> arm<pred> has<obj> arm<pred> has<obj> arm<pred> has<obj> arm<pred> has<obj> arm ['<sub> man<pred> wears<obj> short<pred> has<obj> hair<pred> has<obj> hand<pred> on<obj> surfboard']
2331327 <sub> tail<pred> of<obj> bird<sub> wing<pred> of<obj> bird<sub> wing<pred> of<obj> bird<sub> wing<pred> of<obj> bird<sub> wing<pred> of<obj> bird ['<sub> wheel<pred> on<obj> bike<sub> leg<pred> of<obj> man']
2023-05-05 03:08:44 - progress_bar.py[line:272] - INFO: epoch 010 | valid on 'valid' subset:   1351 / 1907 loss=2.425, loss_v1=0, loss_v2=0, nll_loss=1.207, ntokens=358, nsentences=12, sample_size=358.0, sample_size_v1=0, sample_size_v2=0
2023-05-05 03:08:52 - progress_bar.py[line:272] - INFO: epoch 010 | valid on 'valid' subset:   1361 / 1907 loss=2.122, loss_v1=0, loss_v2=0, nll_loss=0.869, ntokens=291, nsentences=12, sample_size=291.0, sample_size_v1=0, sample_size_v2=0
2023-05-05 03:09:00 - progress_bar.py[line:272] - INFO: epoch 010 | valid on 'valid' subset:   1371 / 1907 loss=2.247, loss_v1=0, loss_v2=0, nll_loss=1.007, ntokens=460, nsentences=12, sample_size=460.0, sample_size_v1=0, sample_size_v2=0
2023-05-05 03:09:09 - progress_bar.py[line:272] - INFO: epoch 010 | valid on 'valid' subset:   1381 / 1907 loss=2.232, loss_v1=0, loss_v2=0, nll_loss=0.984, ntokens=406, nsentences=12, sample_size=406.0, sample_size_v1=0, sample_size_v2=0
2023-05-05 03:09:16 - progress_bar.py[line:272] - INFO: epoch 010 | valid on 'valid' subset:   1391 / 1907 loss=2.139, loss_v1=0, loss_v2=0, nll_loss=0.882, ntokens=353, nsentences=12, sample_size=353.0, sample_size_v1=0, sample_size_v2=0
2413537 <sub> glass<pred> on<obj> face<sub> face<pred> of<obj> man<sub> face<pred> of<obj> man<sub> face<pred> of<obj> man<sub> face<pred> of<obj> man ['<sub> person<pred> wearing<obj> shirt<pred> wearing<obj> glove<pred> wearing<obj> glove<sub> person<pred> wearing<obj> shirt<pred> wearing<obj> pant<sub> box<pred> near<obj> person']
2330749 <sub> letter<pred> on<obj> sign<sub> letter<pred> on<obj> sign<sub> letter<pred> on<obj> sign<sub> letter<pred> on<obj> sign<sub> letter<pred> on<obj> sign<sub> letter<pred> on<obj> sign<sub> letter<pred> on<obj> sign<sub> letter<pred> on<obj> sign<sub> letter<pred> on<obj> sign<sub> letter<pred> on<obj> sign ['<sub> window<pred> of<obj> building<sub> window<pred> on<obj> building<sub> window<pred> on<obj> building<sub> window<pred> on<obj> building<sub> window<pred> of<obj> building<sub> window<pred> of<obj> building<sub> window<pred> on<obj> building<sub> sign<pred> on<obj> pole<sub> window<pred> on<obj> building<sub> window<pred> on<obj> building<sub> window<pred> on<obj> building<sub> window<pred> on<obj> building<sub> building<pred> has<obj> window<sub> window<pred> on<obj> building']
2023-05-05 03:09:24 - progress_bar.py[line:272] - INFO: epoch 010 | valid on 'valid' subset:   1401 / 1907 loss=2.183, loss_v1=0, loss_v2=0, nll_loss=0.944, ntokens=352, nsentences=12, sample_size=352.0, sample_size_v1=0, sample_size_v2=0
2023-05-05 03:09:32 - progress_bar.py[line:272] - INFO: epoch 010 | valid on 'valid' subset:   1411 / 1907 loss=2.32, loss_v1=0, loss_v2=0, nll_loss=1.084, ntokens=457, nsentences=12, sample_size=457.0, sample_size_v1=0, sample_size_v2=0
2023-05-05 03:09:40 - progress_bar.py[line:272] - INFO: epoch 010 | valid on 'valid' subset:   1421 / 1907 loss=2.287, loss_v1=0, loss_v2=0, nll_loss=1.05, ntokens=351, nsentences=12, sample_size=351.0, sample_size_v1=0, sample_size_v2=0
2023-05-05 03:09:49 - progress_bar.py[line:272] - INFO: epoch 010 | valid on 'valid' subset:   1431 / 1907 loss=2.393, loss_v1=0, loss_v2=0, nll_loss=1.17, ntokens=329, nsentences=12, sample_size=329.0, sample_size_v1=0, sample_size_v2=0
2023-05-05 03:09:59 - progress_bar.py[line:272] - INFO: epoch 010 | valid on 'valid' subset:   1441 / 1907 loss=2.269, loss_v1=0, loss_v2=0, nll_loss=1.035, ntokens=476, nsentences=12, sample_size=476.0, sample_size_v1=0, sample_size_v2=0
2330214 <sub> man<pred> has<obj> hair<pred> wearing<obj> shirt<pred> wearing<obj> short<pred> wearing<obj> shoe<sub> tree<pred> behind<obj> man<sub> short<pred> on<obj> man<sub> short<pred> on<obj> man ['<sub> leg<pred> of<obj> dog<sub> leg<pred> of<obj> person']
2413030 <sub> giraffe<pred> has<obj> neck<pred> has<obj> leg<pred> has<obj> leg<pred> has<obj> leg<pred> has<obj> leg<pred> has<obj> leg<pred> has<obj> leg<pred> has<obj> leg<pred> has<obj> leg<pred> has<obj> leg<pred> has<obj> leg<pred> has<obj> leg<pred> has<obj> leg<pred> has<obj> leg<sub> giraffe<pred> has<obj> leg<pred> has<obj> leg<pred> has<obj> leg<pred> has<obj> leg<pred> has<obj> leg<pred> has<obj> leg<pred> has<obj> leg ['<sub> giraffe<pred> has<obj> hair<pred> has<obj> ear<pred> in<obj> building<sub> giraffe<pred> has<obj> ear<sub> wire<pred> attached to<obj> tree<pred> behind<obj> giraffe<sub> door<pred> in<obj> building<sub> door<pred> in<obj> building<sub> wire<pred> behind<obj> giraffe<sub> wire<pred> behind<obj> giraffe<pred> behind<obj> giraffe<sub> building<pred> has<obj> door<pred> has<obj> door<sub> tree<pred> has<obj> trunk<sub> tree<pred> has<obj> trunk']
2023-05-05 03:10:08 - progress_bar.py[line:272] - INFO: epoch 010 | valid on 'valid' subset:   1451 / 1907 loss=2.274, loss_v1=0, loss_v2=0, nll_loss=1.036, ntokens=525, nsentences=12, sample_size=525.0, sample_size_v1=0, sample_size_v2=0
2023-05-05 03:10:19 - progress_bar.py[line:272] - INFO: epoch 010 | valid on 'valid' subset:   1461 / 1907 loss=2.299, loss_v1=0, loss_v2=0, nll_loss=1.068, ntokens=330, nsentences=12, sample_size=330.0, sample_size_v1=0, sample_size_v2=0
2023-05-05 03:10:29 - progress_bar.py[line:272] - INFO: epoch 010 | valid on 'valid' subset:   1471 / 1907 loss=2.279, loss_v1=0, loss_v2=0, nll_loss=1.047, ntokens=369, nsentences=12, sample_size=369.0, sample_size_v1=0, sample_size_v2=0
2023-05-05 03:10:37 - progress_bar.py[line:272] - INFO: epoch 010 | valid on 'valid' subset:   1481 / 1907 loss=2.416, loss_v1=0, loss_v2=0, nll_loss=1.198, ntokens=324, nsentences=12, sample_size=324.0, sample_size_v1=0, sample_size_v2=0
2023-05-05 03:10:47 - progress_bar.py[line:272] - INFO: epoch 010 | valid on 'valid' subset:   1491 / 1907 loss=2.579, loss_v1=0, loss_v2=0, nll_loss=1.381, ntokens=322, nsentences=12, sample_size=322.0, sample_size_v1=0, sample_size_v2=0
2412516 <sub> plane<pred> has<obj> wing<pred> has<obj> wing ['<sub> airplane<pred> in front of<obj> plane<sub> plane<pred> near<obj> airplane']
2329672 <sub> pizza<pred> in<obj> box<sub> pizza<pred> in<obj> box<sub> pizza<pred> in<obj> box<sub> pizza<pred> in<obj> box<sub> pizza<pred> in<obj> box<sub> pizza<pred> in<obj> box<sub> pizza<pred> in<obj> box<sub> pizza<pred> in<obj> box<sub> pizza<pred> in<obj> box<sub> pizza<pred> in<obj> box<sub> pizza<pred> in<obj> box<sub> pizza<pred> in<obj> box ['<sub> pizza<pred> on<obj> paper<sub> pizza<pred> on<obj> paper<sub> pizza<pred> on<obj> paper<sub> table<pred> with<obj> leg']
2023-05-05 03:10:56 - progress_bar.py[line:272] - INFO: epoch 010 | valid on 'valid' subset:   1501 / 1907 loss=2.313, loss_v1=0, loss_v2=0, nll_loss=1.08, ntokens=430, nsentences=12, sample_size=430.0, sample_size_v1=0, sample_size_v2=0
2023-05-05 03:11:05 - progress_bar.py[line:272] - INFO: epoch 010 | valid on 'valid' subset:   1511 / 1907 loss=2.339, loss_v1=0, loss_v2=0, nll_loss=1.11, ntokens=430, nsentences=12, sample_size=430.0, sample_size_v1=0, sample_size_v2=0
2023-05-05 03:11:14 - progress_bar.py[line:272] - INFO: epoch 010 | valid on 'valid' subset:   1521 / 1907 loss=2.388, loss_v1=0, loss_v2=0, nll_loss=1.162, ntokens=442, nsentences=12, sample_size=442.0, sample_size_v1=0, sample_size_v2=0
2023-05-05 03:11:23 - progress_bar.py[line:272] - INFO: epoch 010 | valid on 'valid' subset:   1531 / 1907 loss=2.391, loss_v1=0, loss_v2=0, nll_loss=1.166, ntokens=371, nsentences=12, sample_size=371.0, sample_size_v1=0, sample_size_v2=0
2023-05-05 03:11:33 - progress_bar.py[line:272] - INFO: epoch 010 | valid on 'valid' subset:   1541 / 1907 loss=2.35, loss_v1=0, loss_v2=0, nll_loss=1.121, ntokens=551, nsentences=12, sample_size=551.0, sample_size_v1=0, sample_size_v2=0
2412002 <sub> man<pred> wearing<obj> shirt<sub> man<pred> wearing<obj> shirt<sub> man<pred> wearing<obj> shirt ['<sub> motorcycle<pred> near<obj> men<sub> man<pred> near<obj> truck<sub> helmet<pred> on<obj> motorcycle<sub> man<pred> wears<obj> shirt<sub> windshield<pred> on<obj> motorcycle']
2329175 <sub> bird<pred> standing on<obj> snow<pred> has<obj> head<pred> has<obj> tail<pred> has<obj> wing<pred> has<obj> wing<sub> snow<pred> under<obj> bird ['<sub> lady<pred> on<obj> snow']
2023-05-05 03:11:42 - progress_bar.py[line:272] - INFO: epoch 010 | valid on 'valid' subset:   1551 / 1907 loss=2.534, loss_v1=0, loss_v2=0, nll_loss=1.331, ntokens=310, nsentences=12, sample_size=310.0, sample_size_v1=0, sample_size_v2=0
2023-05-05 03:11:52 - progress_bar.py[line:272] - INFO: epoch 010 | valid on 'valid' subset:   1561 / 1907 loss=2.255, loss_v1=0, loss_v2=0, nll_loss=1.014, ntokens=469, nsentences=12, sample_size=469.0, sample_size_v1=0, sample_size_v2=0
2023-05-05 03:12:01 - progress_bar.py[line:272] - INFO: epoch 010 | valid on 'valid' subset:   1571 / 1907 loss=2.15, loss_v1=0, loss_v2=0, nll_loss=0.901, ntokens=569, nsentences=12, sample_size=569.0, sample_size_v1=0, sample_size_v2=0
2023-05-05 03:12:10 - progress_bar.py[line:272] - INFO: epoch 010 | valid on 'valid' subset:   1581 / 1907 loss=2.355, loss_v1=0, loss_v2=0, nll_loss=1.129, ntokens=541, nsentences=12, sample_size=541.0, sample_size_v1=0, sample_size_v2=0
2023-05-05 03:12:20 - progress_bar.py[line:272] - INFO: epoch 010 | valid on 'valid' subset:   1591 / 1907 loss=2.473, loss_v1=0, loss_v2=0, nll_loss=1.254, ntokens=361, nsentences=12, sample_size=361.0, sample_size_v1=0, sample_size_v2=0
2328738 <sub> horse<pred> has<obj> leg<pred> has<obj> leg<pred> has<obj> leg<pred> has<obj> leg<pred> has<obj> leg<pred> has<obj> leg<pred> has<obj> leg<pred> has<obj> leg<pred> has<obj> leg<pred> has<obj> leg<pred> has<obj> leg<pred> has<obj> leg<pred> has<obj> leg<pred> has<obj> leg<pred> has<obj> leg<pred> has<obj> leg<pred> has<obj> leg<pred> has<obj> leg<pred> has<obj> leg<pred> has<obj> leg<pred> has<obj> leg<pred> has<obj> leg ['<sub> trunk<pred> on<obj> elephant<sub> person<pred> wearing<obj> hat<sub> person<pred> wearing<obj> shirt<sub> person<pred> riding<obj> elephant<sub> head<pred> of<obj> elephant<sub> head<pred> of<obj> elephant<sub> eye<pred> of<obj> elephant<sub> elephant<pred> has<obj> trunk<sub> mouth<pred> of<obj> elephant<sub> leg<pred> of<obj> elephant']
2411524 <sub> food<pred> on<obj> plate<sub> food<pred> on<obj> plate<sub> food<pred> on<obj> plate<sub> food<pred> on<obj> plate<sub> food<pred> on<obj> plate<sub> food<pred> on<obj> plate<sub> food<pred> on<obj> plate<sub> food<pred> on<obj> plate ['<sub> plate<pred> in<obj> cabinet<sub> window<pred> above<obj> sink<sub> cabinet<pred> has<obj> handle<sub> woman<pred> near<obj> window<sub> light<pred> over<obj> counter<sub> board<pred> on<obj> counter']
2023-05-05 03:12:29 - progress_bar.py[line:272] - INFO: epoch 010 | valid on 'valid' subset:   1601 / 1907 loss=2.524, loss_v1=0, loss_v2=0, nll_loss=1.32, ntokens=483, nsentences=12, sample_size=483.0, sample_size_v1=0, sample_size_v2=0
2023-05-05 03:12:37 - progress_bar.py[line:272] - INFO: epoch 010 | valid on 'valid' subset:   1611 / 1907 loss=2.275, loss_v1=0, loss_v2=0, nll_loss=1.037, ntokens=480, nsentences=12, sample_size=480.0, sample_size_v1=0, sample_size_v2=0
2023-05-05 03:12:46 - progress_bar.py[line:272] - INFO: epoch 010 | valid on 'valid' subset:   1621 / 1907 loss=2.248, loss_v1=0, loss_v2=0, nll_loss=1.011, ntokens=493, nsentences=12, sample_size=493.0, sample_size_v1=0, sample_size_v2=0
2023-05-05 03:12:56 - progress_bar.py[line:272] - INFO: epoch 010 | valid on 'valid' subset:   1631 / 1907 loss=2.489, loss_v1=0, loss_v2=0, nll_loss=1.278, ntokens=322, nsentences=12, sample_size=322.0, sample_size_v1=0, sample_size_v2=0
2023-05-05 03:13:05 - progress_bar.py[line:272] - INFO: epoch 010 | valid on 'valid' subset:   1641 / 1907 loss=2.376, loss_v1=0, loss_v2=0, nll_loss=1.149, ntokens=477, nsentences=12, sample_size=477.0, sample_size_v1=0, sample_size_v2=0
2328261 <sub> man<pred> wearing<obj> shirt<pred> wearing<obj> pant ['<sub> man<pred> has<obj> head<pred> has<obj> hand<sub> seat<pred> for<obj> man']
2415628 <sub> man<pred> has<obj> hair<pred> has<obj> eye<pred> has<obj> nose<pred> has<obj> mouth<pred> has<obj> face ['<sub> phone<pred> near<obj> ear<pred> in<obj> hand<sub> man<pred> on<obj> phone<pred> has<obj> ear<pred> has<obj> hand<pred> has<obj> ear<pred> has<obj> hair<sub> ear<pred> has<obj> phone']
2023-05-05 03:13:15 - progress_bar.py[line:272] - INFO: epoch 010 | valid on 'valid' subset:   1651 / 1907 loss=2.203, loss_v1=0, loss_v2=0, nll_loss=0.956, ntokens=420, nsentences=12, sample_size=420.0, sample_size_v1=0, sample_size_v2=0
2023-05-05 03:13:24 - progress_bar.py[line:272] - INFO: epoch 010 | valid on 'valid' subset:   1661 / 1907 loss=2.35, loss_v1=0, loss_v2=0, nll_loss=1.123, ntokens=411, nsentences=12, sample_size=411.0, sample_size_v1=0, sample_size_v2=0
2023-05-05 03:13:34 - progress_bar.py[line:272] - INFO: epoch 010 | valid on 'valid' subset:   1671 / 1907 loss=2.323, loss_v1=0, loss_v2=0, nll_loss=1.087, ntokens=384, nsentences=12, sample_size=384.0, sample_size_v1=0, sample_size_v2=0
2023-05-05 03:13:43 - progress_bar.py[line:272] - INFO: epoch 010 | valid on 'valid' subset:   1681 / 1907 loss=2.263, loss_v1=0, loss_v2=0, nll_loss=1.026, ntokens=336, nsentences=12, sample_size=336.0, sample_size_v1=0, sample_size_v2=0
2023-05-05 03:13:53 - progress_bar.py[line:272] - INFO: epoch 010 | valid on 'valid' subset:   1691 / 1907 loss=2.277, loss_v1=0, loss_v2=0, nll_loss=1.036, ntokens=399, nsentences=12, sample_size=399.0, sample_size_v1=0, sample_size_v2=0
2416102 <sub> plane<pred> has<obj> engine<pred> has<obj> engine<pred> has<obj> engine<pred> has<obj> engine<pred> has<obj> engine<pred> has<obj> engine<pred> has<obj> engine<pred> has<obj> engine<pred> has<obj> engine<pred> has<obj> engine<pred> has<obj> engine<pred> has<obj> engine<pred> has<obj> engine<pred> has<obj> engine<pred> has<obj> engine ['<sub> wing<pred> on<obj> plane<sub> wing<pred> on<obj> plane<sub> wing<pred> on<obj> plane<sub> wheel<pred> on<obj> plane']
2327847 <sub> trunk<pred> of<obj> elephant<sub> ear<pred> of<obj> elephant<sub> ear<pred> of<obj> elephant<sub> leg<pred> of<obj> elephant<sub> leg<pred> of<obj> elephant<sub> leg<pred> of<obj> elephant<sub> leg<pred> of<obj> elephant<sub> leg<pred> of<obj> elephant<sub> leg<pred> of<obj> elephant<sub> leg<pred> of<obj> elephant<sub> leg<pred> of<obj> elephant<sub> leg<pred> of<obj> elephant<sub> leg<pred> of<obj> elephant<sub> leg<pred> of<obj> elephant<sub> leg<pred> of<obj> elephant<sub> leg<pred> of<obj> elephant<sub> leg<pred> of ['<sub> people<pred> riding<obj> elephant<sub> person<pred> wearing<obj> shirt<sub> seat<pred> mounted on<obj> elephant<sub> man<pred> riding<obj> elephant<pred> wearing<obj> shirt<pred> has<obj> hair<pred> has<obj> head<sub> woman<pred> sitting on<obj> elephant<pred> riding<obj> elephant<sub> ear<pred> belonging to<obj> elephant<sub> trunk<pred> belonging to<obj> elephant<sub> leaf<pred> on<obj> tree<sub> leaf<pred> on<obj> tree<sub> leaf<pred> on<obj> tree<sub> leaf<pred> on<obj> tree<sub> man<pred> wearing<obj> shirt<sub> hair<pred> on<obj> head<sub> woman']
2023-05-05 03:14:02 - progress_bar.py[line:272] - INFO: epoch 010 | valid on 'valid' subset:   1701 / 1907 loss=2.123, loss_v1=0, loss_v2=0, nll_loss=0.869, ntokens=626, nsentences=12, sample_size=626.0, sample_size_v1=0, sample_size_v2=0
2023-05-05 03:14:12 - progress_bar.py[line:272] - INFO: epoch 010 | valid on 'valid' subset:   1711 / 1907 loss=2.343, loss_v1=0, loss_v2=0, nll_loss=1.113, ntokens=283, nsentences=12, sample_size=283.0, sample_size_v1=0, sample_size_v2=0
2023-05-05 03:14:23 - progress_bar.py[line:272] - INFO: epoch 010 | valid on 'valid' subset:   1721 / 1907 loss=2.41, loss_v1=0, loss_v2=0, nll_loss=1.186, ntokens=254, nsentences=12, sample_size=254.0, sample_size_v1=0, sample_size_v2=0
2023-05-05 03:14:32 - progress_bar.py[line:272] - INFO: epoch 010 | valid on 'valid' subset:   1731 / 1907 loss=2.202, loss_v1=0, loss_v2=0, nll_loss=0.96, ntokens=358, nsentences=12, sample_size=358.0, sample_size_v1=0, sample_size_v2=0
2023-05-05 03:14:41 - progress_bar.py[line:272] - INFO: epoch 010 | valid on 'valid' subset:   1741 / 1907 loss=2.221, loss_v1=0, loss_v2=0, nll_loss=0.978, ntokens=440, nsentences=12, sample_size=440.0, sample_size_v1=0, sample_size_v2=0
2416544 <sub> man<pred> on<obj> skateboard<pred> wearing<obj> jean<pred> wearing<obj> shirt<pred> wearing<obj> jean<sub> man<pred> wearing<obj> shirt<pred> wearing<obj> jean<sub> man<pred> wearing<obj> shirt ['<sub> man<pred> riding<obj> skateboard<pred> has<obj> head<sub> man<pred> has<obj> head<sub> head<pred> on<obj> man<sub> head<pred> on<obj> dog']
2327393 <sub> head<pred> of<obj> man<sub> leg<pred> of<obj> man<sub> leg<pred> of<obj> man<sub> leg<pred> of<obj> man<sub> leg<pred> of<obj> man<sub> leg<pred> of<obj> man<sub> leg<pred> of<obj> man<sub> leg<pred> of<obj> man<sub> leg<pred> of<obj> man<sub> leg<pred> of<obj> man ['<sub> person<pred> has<obj> leg<pred> has<obj> leg<sub> person<pred> has<obj> leg<pred> has<obj> leg<sub> person<pred> has<obj> leg<pred> has<obj> leg<sub> person<pred> has<obj> leg<pred> wearing<obj> shirt<sub> person<pred> has<obj> leg<sub> person<pred> has<obj> leg<sub> car<pred> behind<obj> person<pred> on<obj> street<sub> car<pred> on<obj> street']
2023-05-05 03:14:51 - progress_bar.py[line:272] - INFO: epoch 010 | valid on 'valid' subset:   1751 / 1907 loss=2.237, loss_v1=0, loss_v2=0, nll_loss=0.993, ntokens=372, nsentences=12, sample_size=372.0, sample_size_v1=0, sample_size_v2=0
2023-05-05 03:15:00 - progress_bar.py[line:272] - INFO: epoch 010 | valid on 'valid' subset:   1761 / 1907 loss=2.415, loss_v1=0, loss_v2=0, nll_loss=1.195, ntokens=326, nsentences=12, sample_size=326.0, sample_size_v1=0, sample_size_v2=0
2023-05-05 03:15:09 - progress_bar.py[line:272] - INFO: epoch 010 | valid on 'valid' subset:   1771 / 1907 loss=2.221, loss_v1=0, loss_v2=0, nll_loss=0.979, ntokens=302, nsentences=12, sample_size=302.0, sample_size_v1=0, sample_size_v2=0
2023-05-05 03:15:17 - progress_bar.py[line:272] - INFO: epoch 010 | valid on 'valid' subset:   1781 / 1907 loss=2.26, loss_v1=0, loss_v2=0, nll_loss=1.022, ntokens=347, nsentences=12, sample_size=347.0, sample_size_v1=0, sample_size_v2=0
2023-05-05 03:15:27 - progress_bar.py[line:272] - INFO: epoch 010 | valid on 'valid' subset:   1791 / 1907 loss=2.045, loss_v1=0, loss_v2=0, nll_loss=0.777, ntokens=410, nsentences=12, sample_size=410.0, sample_size_v1=0, sample_size_v2=0
2326906 <sub> pillow<pred> on<obj> bed<sub> pillow<pred> on<obj> bed<sub> pillow<pred> on<obj> bed<sub> pillow<pred> on<obj> bed<sub> pillow<pred> on<obj> bed<sub> pillow<pred> on<obj> bed<sub> pillow<pred> on<obj> bed<sub> pillow<pred> on<obj> bed ['<sub> handle<pred> on<obj> cabinet<pred> on<obj> cabinet<pred> on<obj> door<sub> leg<pred> of<obj> chair<sub> door<pred> with<obj> handle']
2417019 <sub> cow<pred> on<obj> beach<sub> cow<pred> on<obj> beach<sub> cow<pred> on<obj> beach<sub> cow<pred> on<obj> beach<sub> cow<pred> on<obj> beach ['<sub> airplane<pred> has<obj> wing<sub> tree<pred> under<obj> airplane']
2023-05-05 03:15:36 - progress_bar.py[line:272] - INFO: epoch 010 | valid on 'valid' subset:   1801 / 1907 loss=2.595, loss_v1=0, loss_v2=0, nll_loss=1.394, ntokens=240, nsentences=12, sample_size=240.0, sample_size_v1=0, sample_size_v2=0
2023-05-05 03:15:44 - progress_bar.py[line:272] - INFO: epoch 010 | valid on 'valid' subset:   1811 / 1907 loss=2.246, loss_v1=0, loss_v2=0, nll_loss=1.011, ntokens=393, nsentences=12, sample_size=393.0, sample_size_v1=0, sample_size_v2=0
2023-05-05 03:15:54 - progress_bar.py[line:272] - INFO: epoch 010 | valid on 'valid' subset:   1821 / 1907 loss=2.245, loss_v1=0, loss_v2=0, nll_loss=1.003, ntokens=417, nsentences=12, sample_size=417.0, sample_size_v1=0, sample_size_v2=0
2023-05-05 03:16:03 - progress_bar.py[line:272] - INFO: epoch 010 | valid on 'valid' subset:   1831 / 1907 loss=2.167, loss_v1=0, loss_v2=0, nll_loss=0.918, ntokens=585, nsentences=12, sample_size=585.0, sample_size_v1=0, sample_size_v2=0
2023-05-05 03:16:13 - progress_bar.py[line:272] - INFO: epoch 010 | valid on 'valid' subset:   1841 / 1907 loss=2.26, loss_v1=0, loss_v2=0, nll_loss=1.021, ntokens=351, nsentences=12, sample_size=351.0, sample_size_v1=0, sample_size_v2=0
2326463 <sub> bench<pred> near<obj> tree<sub> tree<pred> near<obj> bench ['<sub> bench<pred> under<obj> tree<sub> tree<pred> above<obj> bench']
2417485 <sub> car<pred> on<obj> street<sub> car<pred> on<obj> street<sub> car<pred> on<obj> street<sub> car<pred> on<obj> street ['<sub> light<pred> over<obj> street<sub> car<pred> on<obj> street<sub> car<pred> on<obj> street<sub> car<pred> of<obj> street']
2023-05-05 03:16:22 - progress_bar.py[line:272] - INFO: epoch 010 | valid on 'valid' subset:   1851 / 1907 loss=2.249, loss_v1=0, loss_v2=0, nll_loss=1.008, ntokens=363, nsentences=12, sample_size=363.0, sample_size_v1=0, sample_size_v2=0
2023-05-05 03:16:31 - progress_bar.py[line:272] - INFO: epoch 010 | valid on 'valid' subset:   1861 / 1907 loss=2.297, loss_v1=0, loss_v2=0, nll_loss=1.062, ntokens=356, nsentences=12, sample_size=356.0, sample_size_v1=0, sample_size_v2=0
2023-05-05 03:16:42 - progress_bar.py[line:272] - INFO: epoch 010 | valid on 'valid' subset:   1871 / 1907 loss=2.08, loss_v1=0, loss_v2=0, nll_loss=0.818, ntokens=568, nsentences=12, sample_size=568.0, sample_size_v1=0, sample_size_v2=0
2023-05-05 03:16:51 - progress_bar.py[line:272] - INFO: epoch 010 | valid on 'valid' subset:   1881 / 1907 loss=2.318, loss_v1=0, loss_v2=0, nll_loss=1.086, ntokens=414, nsentences=12, sample_size=414.0, sample_size_v1=0, sample_size_v2=0
2023-05-05 03:17:01 - progress_bar.py[line:272] - INFO: epoch 010 | valid on 'valid' subset:   1891 / 1907 loss=2.215, loss_v1=0, loss_v2=0, nll_loss=0.965, ntokens=444, nsentences=12, sample_size=444.0, sample_size_v1=0, sample_size_v2=0
2326034 <sub> woman<pred> wearing<obj> jacket<pred> wearing<obj> glove<pred> wearing<obj> glove<pred> wearing<obj> glove<pred> wearing<obj> glove<pred> wearing<obj> glove<pred> wearing<obj> glove<pred> wearing<obj> glove<pred> wearing<obj> glove<pred> wearing<obj> glove<pred> wearing<obj> glove<pred> wearing<obj> glove<pred> wearing<obj> glove<pred> wearing<obj> glove<pred> wearing<obj> glove<pred> wearing<obj> glove<pred> wearing<obj> glove<pred> wearing<obj> glove<pred> wearing<obj> glove<pred> wearing<obj> glove<pred> wearing<obj> glove<pred> wearing<obj> glove<pred> wearing<obj> glove<pred> wearing<obj> glove<pred> wearing ['<sub> snow<pred> covering<obj> snow<sub> snow<pred> covering<obj> snow<sub> snow<pred> covering<obj> snow<sub> snow<pred> covering<obj> snow<sub> snow<pred> covered in<obj> snow<sub> tree<pred> in<obj> snow<sub> head<pred> of<obj> person<pred> of<obj> man<sub> leg<pred> of<obj> man<sub> leg<pred> of<obj> man<pred> of<obj> person<sub> leg<pred> of<obj> person<sub> hand<pred> of<obj> man<sub> head<pred> of<obj> person<sub> arm<pred> of<obj> person<pred> of<obj> man<sub> arm<pred> of<obj> man<sub> arm<pred>']
2417938 <sub> banana<pred> on<obj> plate<sub> banana<pred> on<obj> plate<sub> banana<pred> on<obj> plate<sub> banana<pred> on<obj> plate ['<sub> banana<pred> has<obj> banana<sub> chair<pred> at<obj> table']
2023-05-05 03:17:11 - progress_bar.py[line:272] - INFO: epoch 010 | valid on 'valid' subset:   1901 / 1907 loss=2.426, loss_v1=0, loss_v2=0, nll_loss=1.205, ntokens=447, nsentences=12, sample_size=447.0, sample_size_v1=0, sample_size_v2=0
local datafile ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 1 begin to initialize row_count and line_idx-to-offset mapping
2023-05-05 03:17:17 - progress_bar.py[line:282] - INFO: epoch 010 | valid on 'valid' subset | loss 2.305 | loss_v1 0 | loss_v2 0 | nll_loss 1.071 | ntokens 430.208 | nsentences 11.998 | sample_size 430.208 | sample_size_v1 0 | sample_size_v2 0 | ppl 2.1 | wps 452.4 | wpb 430.2 | bsz 12 | num_updates 5769
2023-05-05 03:17:17 - checkpoint_utils.py[line:64] - INFO: Preparing to save checkpoint for epoch 10 @ 5769 updates
2023-05-05 03:17:17 - trainer.py[line:431] - INFO: Saving checkpoint to ../../checkpoints/OFA/sgcls_checkpoints/_10_3e-5_512/tmp/checkpoint10.pt
local datafile ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 1 finished initializing row_count and line_idx-to-offset mapping
file ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 1 row count 27700 total row count 55400
slice_id 1 seek offset 27700
2023-05-05 03:17:20 - trainer.py[line:441] - INFO: Finished saving checkpoint to ../../checkpoints/OFA/sgcls_checkpoints/_10_3e-5_512/tmp/checkpoint10.pt
2023-05-05 03:17:23 - checkpoint_utils.py[line:133] - INFO: Saved checkpoint ../../checkpoints/OFA/sgcls_checkpoints/_10_3e-5_512/tmp/checkpoint10.pt (epoch 10 @ 5769 updates, score 2.305) (writing took 6.845859301000019 seconds)
2023-05-05 03:17:23 - train.py[line:332] - INFO: end of epoch 10 (average epoch stats below)
2023-05-05 03:17:23 - progress_bar.py[line:282] - INFO: epoch 010 | loss 2.205 | loss_v1 0 | loss_v2 0 | nll_loss 0.987 | ntokens 3152.01 | nsentences 95.847 | sample_size 3152.01 | sample_size_v1 0 | sample_size_v2 0 | ppl 1.98 | wps 522.7 | ups 0.17 | wpb 3152 | bsz 95.8 | num_updates 5769 | lr 6.07287e-08 | gnorm 2.979 | clip 100 | loss_scale 64 | train_wall 1655 | gb_free 13.1 | wall 5747
2023-05-05 03:17:23 - trainer.py[line:639] - INFO: loading train data for epoch 11
local datafile ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 0 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 0 finished initializing row_count and line_idx-to-offset mapping
file ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 0 row count 27700 total row count 55400
slice_id 0 seek offset 0
2023-05-05 03:17:25 - train.py[line:214] - INFO: done training in 5727.8 seconds
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.007 MB of 0.007 MB uploaded (0.000 MB deduped)wandb: \ 0.007 MB of 0.007 MB uploaded (0.000 MB deduped)wandb: | 0.007 MB of 0.007 MB uploaded (0.000 MB deduped)wandb: / 0.007 MB of 0.007 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run history:
wandb:                  train/bsz ▁▁
wandb:                 train/clip ▁▁
wandb:              train/gb_free ▁▁
wandb:                train/gnorm ▁█
wandb:                 train/loss █▁
wandb:           train/loss_scale ▁▁
wandb:              train/loss_v1 ▁▁
wandb:              train/loss_v2 ▁▁
wandb:                   train/lr █▁
wandb:             train/nll_loss █▁
wandb:           train/nsentences ▁▁
wandb:              train/ntokens ▁█
wandb:                  train/ppl ▁▁
wandb:          train/sample_size ▁█
wandb:       train/sample_size_v1 ▁▁
wandb:       train/sample_size_v2 ▁▁
wandb:           train/train_wall █▁
wandb:                  train/ups █▁
wandb:                 train/wall ▁█
wandb:                  train/wpb ▁█
wandb:                  train/wps █▁
wandb:            train_inner/bsz ████████████████████▁███████████████████
wandb:           train_inner/clip ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:        train_inner/gb_free ▂▅▁▅▃▅▆▇▇▅▅█▇▅▄█▄▅▆▇▅▅▅▄▃▃▃▆▇▅▄▅▇▅▆▆█▇▆▅
wandb:          train_inner/gnorm ▄▄▂▄▃▂▃▂▃▂▂▁▂▂▃▃▃▄▅▄█▄▄▄▄▃▄▅▆▅▄▄▅▄▅▄▄▄▄▃
wandb:           train_inner/loss ▄▂▁▇▅▇█▆▇▇▇▆▅▆▅▆▆▄▅▅▅▁▃▃▃█▇▅▇▆█▅▆▇▇▇▇▆▆▆
wandb:     train_inner/loss_scale ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:        train_inner/loss_v1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:        train_inner/loss_v2 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:             train_inner/lr ████▇▇▇▇▇▆▆▆▆▆▆▅▅▅▅▅▄▄▄▄▄▄▃▃▃▃▃▂▂▂▂▂▂▁▁▁
wandb:       train_inner/nll_loss ▄▂▁▇▅▇█▆▇▇▇▆▅▆▅▆▆▄▅▅▅▁▃▃▃█▇▅▇▆█▅▆▇▇▇▇▆▆▆
wandb:     train_inner/nsentences ████████████████████▁███████████████████
wandb:        train_inner/ntokens ▅▅█▆▄▄▅▅▂▄▄▅▃▆▃▃▄▅▅▆▁▃▄▆▆▅▆▅▂▃▃▄▃▅▃▃▂▄▃▆
wandb:            train_inner/ppl ▄▂▁▇▅██▆▇▇█▆▅▆▅▆▆▄▅▅▅▁▂▃▃█▇▅▇▆█▅▆▇▇▇▇▆▆▆
wandb:    train_inner/sample_size ▅▅█▆▄▄▅▅▂▄▄▅▃▆▃▃▄▅▅▆▁▃▄▆▆▅▆▅▂▃▃▄▃▅▃▃▂▄▃▆
wandb: train_inner/sample_size_v1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: train_inner/sample_size_v2 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     train_inner/train_wall ▃████▇▇▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▁▁▁
wandb:            train_inner/ups ▁▁▁▁▁▂▂█████████████████████████████▇███
wandb:           train_inner/wall ▁▁▂▂▂▃▃▃▃▃▄▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▆▇▇▇▇▇▇████
wandb:            train_inner/wpb ▅▅█▆▄▄▅▅▂▄▄▅▃▆▃▃▄▅▅▆▁▃▄▆▆▅▆▅▂▃▃▄▃▅▃▃▂▄▃▆
wandb:            train_inner/wps ▁▁▁▁▁▂▂█▇▇▇█▇█▇▇▇███▆▇▇█████▇▇▇▇▇█▇▇▆▇▇█
wandb:                  valid/bsz ▁
wandb:                 valid/loss ▁
wandb:              valid/loss_v1 ▁
wandb:              valid/loss_v2 ▁
wandb:             valid/nll_loss ▁
wandb:           valid/nsentences ▁
wandb:              valid/ntokens ▁
wandb:                  valid/ppl ▁
wandb:          valid/sample_size ▁
wandb:       valid/sample_size_v1 ▁
wandb:       valid/sample_size_v2 ▁
wandb:                  valid/wpb ▁
wandb:                  valid/wps ▁
wandb: 
wandb: Run summary:
wandb:                  train/bsz 95.8
wandb:                 train/clip 100.0
wandb:              train/gb_free 13.1
wandb:                train/gnorm 2.979
wandb:                 train/loss 2.205
wandb:           train/loss_scale 64.0
wandb:              train/loss_v1 0.0
wandb:              train/loss_v2 0.0
wandb:                   train/lr 0.0
wandb:             train/nll_loss 0.987
wandb:           train/nsentences 95.847
wandb:              train/ntokens 3152.007
wandb:                  train/ppl 1.98
wandb:          train/sample_size 3152.007
wandb:       train/sample_size_v1 0.0
wandb:       train/sample_size_v2 0.0
wandb:           train/train_wall 1655.0
wandb:                  train/ups 0.17
wandb:                 train/wall 5747.0
wandb:                  train/wpb 3152.0
wandb:                  train/wps 522.7
wandb:            train_inner/bsz 96.0
wandb:           train_inner/clip 100.0
wandb:        train_inner/gb_free 12.1
wandb:          train_inner/gnorm 2.785
wandb:           train_inner/loss 2.208
wandb:     train_inner/loss_scale 64.0
wandb:        train_inner/loss_v1 0.0
wandb:        train_inner/loss_v2 0.0
wandb:             train_inner/lr 0.0
wandb:       train_inner/nll_loss 0.99
wandb:     train_inner/nsentences 96.0
wandb:        train_inner/ntokens 3294.7
wandb:            train_inner/ppl 1.99
wandb:    train_inner/sample_size 3294.7
wandb: train_inner/sample_size_v1 0.0
wandb: train_inner/sample_size_v2 0.0
wandb:     train_inner/train_wall 29.0
wandb:            train_inner/ups 0.35
wandb:           train_inner/wall 3904.0
wandb:            train_inner/wpb 3294.7
wandb:            train_inner/wps 1147.7
wandb:                  valid/bsz 12.0
wandb:                 valid/loss 2.305
wandb:              valid/loss_v1 0.0
wandb:              valid/loss_v2 0.0
wandb:             valid/nll_loss 1.071
wandb:           valid/nsentences 11.998
wandb:              valid/ntokens 430.208
wandb:                  valid/ppl 2.1
wandb:          valid/sample_size 430.208
wandb:       valid/sample_size_v1 0.0
wandb:       valid/sample_size_v2 0.0
wandb:                  valid/wpb 430.2
wandb:                  valid/wps 452.4
wandb: 
wandb: 🚀 View run tmp at: https://wandb.ai/jackcai1206/OFA-VG/runs/l6rk9wzv
wandb: Synced 6 W&B file(s), 0 media file(s), 2 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230505_014158-l6rk9wzv/logs

/data/hulab/zcai75/anaconda3/envs/vilt/lib/python3.8/site-packages/torch/distributed/launch.py:178: FutureWarning: The module torch.distributed.launch is deprecated
and will be removed in future. Use torchrun.
Note that --use_env is set by default in torchrun.
If your script expects `--local_rank` argument to be set, please
change it to read from `os.environ['LOCAL_RANK']` instead. See 
https://pytorch.org/docs/stable/distributed.html#launch-utility for 
further instructions

  warnings.warn(
WARNING:torch.distributed.run:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
2023-04-08 16:02:46 - utils.py[line:255] - INFO: distributed init (rank 0): env://
2023-04-08 16:02:46 - utils.py[line:261] - INFO: Start init
2023-04-08 16:02:46 - distributed_c10d.py[line:228] - INFO: Added key: store_based_barrier_key:1 to store for rank: 0
2023-04-08 16:02:46 - utils.py[line:255] - INFO: distributed init (rank 1): env://
2023-04-08 16:02:46 - utils.py[line:261] - INFO: Start init
2023-04-08 16:02:46 - distributed_c10d.py[line:228] - INFO: Added key: store_based_barrier_key:1 to store for rank: 1
2023-04-08 16:02:46 - distributed_c10d.py[line:262] - INFO: Rank 1: Completed store-based barrier for key:store_based_barrier_key:1 with 2 nodes.
2023-04-08 16:02:46 - utils.py[line:271] - INFO: initialized host AMD4RTX3090GPU14 as rank 1
single-machine distributed training is initialized.
2023-04-08 16:02:46 - distributed_c10d.py[line:262] - INFO: Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 2 nodes.
2023-04-08 16:02:46 - utils.py[line:271] - INFO: initialized host AMD4RTX3090GPU14 as rank 0
single-machine distributed training is initialized.
2023-04-08 16:02:46 - train.py[line:77] - INFO: {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 10, 'log_format': 'simple', 'log_file': None, 'tensorboard_logdir': './tensorboard/_12_3e-5_512', 'wandb_project': 'OFA-VG', 'azureml_logging': False, 'seed': 1, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': 512, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': '../../ofa_module', 'empty_cache_freq': 0, 'all_gather_list_size': 2097152, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 2, 'distributed_num_procs': 2, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': 'env://', 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': True, 'ddp_backend': 'pytorch_ddp', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': True, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_algorithm': 'LocalSGD', 'localsgd_frequency': 3, 'nprocs_per_node': 2, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False}, 'dataset': {'_name': None, 'num_workers': 0, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': None, 'batch_size': 6, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 4, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': 7, 'disable_validation': False, 'max_tokens_valid': None, 'batch_size_valid': 6, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0}, 'optimization': {'_name': None, 'max_epoch': 12, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 1.0, 'sentence_avg': False, 'update_freq': [8], 'lr': [3e-05], 'stop_min_lr': -1.0, 'use_bmuf': False}, 'checkpoint': {'_name': None, 'save_dir': '../../checkpoints/OFA/sgcls_checkpoints/_12_3e-5_512', 'restore_file': '../../checkpoints/ofa_base.pt', 'finetune_from_model': None, 'reset_dataloader': True, 'reset_lr_scheduler': False, 'reset_meters': True, 'reset_optimizer': True, 'optimizer_overrides': '{}', 'save_interval': 4, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': 1, 'no_save': False, 'no_epoch_checkpoints': True, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': True, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1, 'use_ema_weights_to_init_param': False, 'use_latest_weights_to_init_ema': False}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 2}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': Namespace(_name='ofa_base', activation_fn='gelu', adam_betas='(0.9,0.999)', adam_eps=1e-08, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, add_type_embedding=True, all_gather_list_size=2097152, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, arch='ofa_base', attention_dropout=0.0, attn_scale_factor=2, azureml_logging=False, batch_size=6, batch_size_valid=6, best_checkpoint_metric='loss', bf16=False, bitfit=False, bpe=None, bpe_dir='../../utils/BPE', broadcast_buffers=False, bucket_cap_mb=25, checkpoint_shard_count=1, checkpoint_suffix='', clip_norm=1.0, code_dict_size=8192, code_image_size=128, code_layernorm_embedding=True, combine_valid_subsets=None, constraint_range=None, cpu=False, cpu_offload=False, criterion='adjust_label_smoothed_cross_entropy', cross_self_attention=False, curriculum=0, data='../../dataset/OFA_data/sgcls/vg_train_full.tsv,../../dataset/OFA_data/sgcls/vg_val_full.tsv', data_buffer_size=10, dataset_impl=None, ddp_backend='pytorch_ddp', ddp_comm_hook='none', decoder_attention_heads=12, decoder_drop_path_rate=0.1, decoder_embed_dim=768, decoder_embed_path=None, decoder_ffn_embed_dim=3072, decoder_input_dim=768, decoder_layerdrop=0, decoder_layers=6, decoder_layers_to_keep=None, decoder_learned_pos=True, decoder_normalize_before=True, decoder_output_dim=768, device_id=0, disable_entangle=True, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_num_procs=2, distributed_port=-1, distributed_rank=0, distributed_world_size=2, drop_worst_after=0, drop_worst_ratio=0.0, dropout=0.1, ema_decay=0.9999, ema_fp32=False, ema_seed_model=None, ema_start_update=0, ema_update_freq=1, empty_cache_freq=0, encoder_attention_heads=12, encoder_drop_path_rate=0.1, encoder_embed_dim=768, encoder_embed_path=None, encoder_ffn_embed_dim=3072, encoder_layerdrop=0, encoder_layers=6, encoder_layers_to_keep=None, encoder_learned_pos=True, encoder_normalize_before=True, end_learning_rate=0.0, entangle_position_embedding=False, eos=2, eval_args='{"beam":5,"max_len_a":0,"max_len_b":200}', eval_bleu=False, eval_cider=False, eval_cider_cached_tokens=None, eval_print_samples=False, fast_stat_sync=False, find_unused_parameters=True, finetune_from_model=None, fix_batches_to_gpus=False, fixed_validation_seed=7, force_anneal=None, fp16=True, fp16_adam_stats=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=512, fp32_reduce_scatter=False, freeze_decoder_embedding=False, freeze_encoder_embedding=False, gen_subset='test', gradient_as_bucket_view=False, heartbeat_timeout=-1, ignore_eos=False, ignore_prefix_size=0, ignore_unused_valid_subsets=False, image_bucket_size=42, imagenet_default_mean_and_std=False, keep_best_checkpoints=1, keep_interval_updates=-1, keep_interval_updates_pattern=-1, keep_last_epochs=-1, label_smoothing=0.1, layernorm_embedding=True, load_checkpoint_on_all_dp_ranks=False, localsgd_frequency=3, log_file=None, log_format='simple', log_interval=10, lr=[3e-05], lr_scheduler='polynomial_decay', max_epoch=12, max_source_positions=1024, max_src_length=100, max_target_positions=1024, max_tgt_length=100, max_tokens=None, max_tokens_valid=None, max_update=0, max_valid_steps=None, maximize_best_checkpoint_metric=True, memory_efficient_bf16=False, memory_efficient_fp16=False, min_loss_scale=0.0001, min_params_to_wrap=100000000, model_parallel_size=1, no_cross_attention=False, no_epoch_checkpoints=True, no_last_checkpoints=False, no_progress_bar=False, no_reshard_after_forward=False, no_save=False, no_save_optimizer_state=False, no_scale_embedding=True, no_seed_provided=False, no_token_positional_embeddings=False, nprocs_per_node=2, num_bins=480, num_shards=1, num_workers=0, on_cpu_convert_precision=False, optimizer='adam', optimizer_overrides='{}', orig_patch_image_size=256, pad=1, patch_image_size=512, patch_layernorm_embedding=True, patience=-1, pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, plasma_path='/tmp/plasma', pooler_activation_fn='tanh', pooler_classifier='mlp', pooler_dropout=0.0, power=1.0, profile=False, quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, quantization_config_path=None, reg_alpha=1.0, relu_dropout=0.0, report_accuracy=False, required_batch_size_multiple=8, required_seq_len_multiple=1, reset_dataloader=True, reset_logging=False, reset_lr_scheduler=False, reset_meters=True, reset_optimizer=True, resnet_drop_path_rate=0.0, resnet_type='resnet101', restore_file='../../checkpoints/ofa_base.pt', sample_patch_num=196, save_dir='../../checkpoints/OFA/sgcls_checkpoints/_12_3e-5_512', save_interval=4, save_interval_updates=0, scale_attn=True, scale_fc=True, scale_heads=True, scale_resids=False, scoring='bleu', scst=False, scst_args='{}', seed=1, selected_cols=None, sentence_avg=False, shard_id=0, share_all_embeddings=True, share_decoder_input_output_embed=True, simul_type=None, skip_invalid_size_inputs_valid_test=False, slowmo_algorithm='LocalSGD', slowmo_momentum=None, stop_min_lr=-1.0, stop_time_hours=0, store_ema=False, suppress_crashes=False, sync_bn=False, task='sgcls', tensorboard_logdir='./tensorboard/_12_3e-5_512', threshold_loss_scale=None, token_bucket_size=256, tokenizer=None, total_num_update=1000000, tpu=False, train_subset='train', unk=3, update_freq=[8], use_bmuf=False, use_ema_weights_to_init_param=False, use_latest_weights_to_init_ema=False, use_old_adam=False, use_plasma_view=False, use_rdrop=False, use_sharded_state=False, user_dir='../../ofa_module', valid_subset='valid', validate_after_updates=0, validate_interval=4, validate_interval_updates=0, wandb_project='OFA-VG', warmup_ratio=0.06, warmup_updates=0, weight_decay=0.01, write_checkpoints_asynchronously=False, zero_sharding='none'), 'task': {'_name': 'sgcls', 'data': '../../dataset/OFA_data/sgcls/vg_train_full.tsv,../../dataset/OFA_data/sgcls/vg_val_full.tsv', 'selected_cols': None, 'bpe': None, 'bpe_dir': '../../utils/BPE', 'max_source_positions': 1024, 'max_target_positions': 1024, 'max_src_length': 100, 'max_tgt_length': 100, 'code_dict_size': 8192, 'patch_image_size': 512, 'orig_patch_image_size': 256, 'num_bins': 480, 'imagenet_default_mean_and_std': False, 'constraint_range': None, 'eval_bleu': False, 'eval_cider': False, 'eval_args': '{"beam":5,"max_len_a":0,"max_len_b":200}', 'eval_print_samples': False, 'eval_cider_cached_tokens': None, 'scst': False, 'scst_args': '{}'}, 'criterion': {'_name': 'adjust_label_smoothed_cross_entropy', 'label_smoothing': 0.1, 'report_accuracy': False, 'ignore_prefix_size': 0, 'ignore_eos': False, 'sentence_avg': False, 'drop_worst_ratio': 0.0, 'drop_worst_after': 0, 'use_rdrop': False, 'reg_alpha': 1.0, 'sample_patch_num': 196, 'constraint_range': None}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9,0.999)', 'adam_eps': 1e-08, 'weight_decay': 0.01, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': False, 'lr': [3e-05]}, 'lr_scheduler': {'_name': 'polynomial_decay', 'warmup_updates': 0, 'warmup_ratio': 0.06, 'force_anneal': None, 'end_learning_rate': 0.0, 'power': 1.0, 'total_num_update': 1000000.0, 'lr': [3e-05]}, 'scoring': {'_name': 'bleu', 'pad': 1, 'eos': 2, 'unk': 3}, 'bpe': None, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}, 'simul_type': None}
2023-04-08 16:02:47 - sg_cls.py[line:92] - INFO: sgcls setup: source dictionary: 50747 types
2023-04-08 16:02:47 - sg_cls.py[line:93] - INFO: sgcls setup: target dictionary: 50747 types
/data/hulab/zcai75/anaconda3/envs/vilt/lib/python3.8/site-packages/torch/functional.py:478: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at  ../aten/src/ATen/native/TensorShape.cpp:2894.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/data/hulab/zcai75/anaconda3/envs/vilt/lib/python3.8/site-packages/torch/functional.py:478: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at  ../aten/src/ATen/native/TensorShape.cpp:2894.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
2023-04-08 16:02:49 - train.py[line:110] - INFO: OFAModel(
  (encoder): TransformerEncoder(
    (encoder_dropout): Dropout(p=0.2, inplace=False)
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(50747, 768, padding_idx=1)
    (layernorm_embedding): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (type_embedding): Embedding(2, 768)
    (embed_images): ResNet(
      (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)
      (layer1): Sequential(
        (0): Bottleneck(
          (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (downsample): Sequential(
            (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (drop_path): Identity()
        )
        (1): Bottleneck(
          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (2): Bottleneck(
          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
      )
      (layer2): Sequential(
        (0): Bottleneck(
          (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (downsample): Sequential(
            (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
            (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (drop_path): Identity()
        )
        (1): Bottleneck(
          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (2): Bottleneck(
          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (3): Bottleneck(
          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
      )
      (layer3): Sequential(
        (0): Bottleneck(
          (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (downsample): Sequential(
            (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)
            (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (drop_path): Identity()
        )
        (1): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (2): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (3): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (4): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (5): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (6): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (7): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (8): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (9): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (10): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (11): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (12): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (13): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (14): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (15): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (16): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (17): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (18): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (19): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (20): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (21): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (22): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
      )
    )
    (image_proj): Linear(in_features=1024, out_features=768, bias=True)
    (patch_layernorm_embedding): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (embed_positions): Embedding(1026, 768)
    (embed_image_positions): Embedding(1765, 768)
    (pos_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (image_pos_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (pos_q_linear): Linear(in_features=768, out_features=768, bias=True)
    (pos_k_linear): Linear(in_features=768, out_features=768, bias=True)
    (layers): ModuleList(
      (0): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): Identity()
      )
      (1): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(p=0.019999999552965164)
      )
      (2): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(p=0.03999999910593033)
      )
      (3): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(p=0.06000000238418579)
      )
      (4): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(p=0.07999999821186066)
      )
      (5): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(p=0.10000000149011612)
      )
    )
    (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (token_rel_pos_table_list): ModuleList(
      (0): Embedding(511, 12)
      (1): Embedding(511, 12)
      (2): Embedding(511, 12)
      (3): Embedding(511, 12)
      (4): Embedding(511, 12)
      (5): Embedding(511, 12)
    )
    (image_rel_pos_table_list): ModuleList(
      (0): Embedding(6892, 12)
      (1): Embedding(6892, 12)
      (2): Embedding(6892, 12)
      (3): Embedding(6892, 12)
      (4): Embedding(6892, 12)
      (5): Embedding(6892, 12)
    )
  )
  (decoder): TransformerDecoder(
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(50747, 768, padding_idx=1)
    (layernorm_embedding): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (embed_positions): Embedding(1026, 768)
    (embed_image_positions): Embedding(1765, 768)
    (pos_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (image_pos_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (self_pos_q_linear): Linear(in_features=768, out_features=768, bias=True)
    (self_pos_k_linear): Linear(in_features=768, out_features=768, bias=True)
    (cross_pos_q_linear): Linear(in_features=768, out_features=768, bias=True)
    (cross_pos_k_linear): Linear(in_features=768, out_features=768, bias=True)
    (code_layernorm_embedding): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (layers): ModuleList(
      (0): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (cross_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): Identity()
      )
      (1): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (cross_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(p=0.019999999552965164)
      )
      (2): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (cross_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(p=0.03999999910593033)
      )
      (3): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (cross_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(p=0.06000000238418579)
      )
      (4): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (cross_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(p=0.07999999821186066)
      )
      (5): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (cross_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(p=0.10000000149011612)
      )
    )
    (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (output_projection): Linear(in_features=768, out_features=50747, bias=False)
    (token_rel_pos_table_list): ModuleList(
      (0): Embedding(511, 12)
      (1): Embedding(511, 12)
      (2): Embedding(511, 12)
      (3): Embedding(511, 12)
      (4): Embedding(511, 12)
      (5): Embedding(511, 12)
    )
    (image_rel_pos_table_list): ModuleList(
      (0): Embedding(6892, 12)
      (1): Embedding(6892, 12)
      (2): Embedding(6892, 12)
      (3): Embedding(6892, 12)
      (4): Embedding(6892, 12)
      (5): Embedding(6892, 12)
    )
  )
  (classification_heads): ModuleDict()
)
2023-04-08 16:02:49 - train.py[line:111] - INFO: task: SGClsTask
2023-04-08 16:02:49 - train.py[line:112] - INFO: model: OFAModel
2023-04-08 16:02:49 - train.py[line:113] - INFO: criterion: AdjustLabelSmoothedCrossEntropyCriterion
2023-04-08 16:02:49 - train.py[line:114] - INFO: num. shared model params: 175,549,256 (num. trained: 175,549,256)
2023-04-08 16:02:49 - train.py[line:121] - INFO: num. expert model params: 0 (num. trained: 0)
local datafile ../../dataset/OFA_data/sgcls/vg_val_full.tsv slice_id 0 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../dataset/OFA_data/sgcls/vg_val_full.tsv slice_id 1 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../dataset/OFA_data/sgcls/vg_val_full.tsv slice_id 0 finished initializing row_count and line_idx-to-offset mapping
file ../../dataset/OFA_data/sgcls/vg_val_full.tsv slice_id 0 row count 11440 total row count 22880
/data/hulab/zcai75/anaconda3/envs/vilt/lib/python3.8/site-packages/torchvision/transforms/transforms.py:332: UserWarning: Argument 'interpolation' of type int is deprecated since 0.13 and will be removed in 0.15. Please use InterpolationMode enum.
  warnings.warn(
2023-04-08 16:02:50 - distributed_c10d.py[line:228] - INFO: Added key: store_based_barrier_key:2 to store for rank: 0
local datafile ../../dataset/OFA_data/sgcls/vg_val_full.tsv slice_id 1 finished initializing row_count and line_idx-to-offset mapping
file ../../dataset/OFA_data/sgcls/vg_val_full.tsv slice_id 1 row count 11440 total row count 22880
/data/hulab/zcai75/anaconda3/envs/vilt/lib/python3.8/site-packages/torchvision/transforms/transforms.py:332: UserWarning: Argument 'interpolation' of type int is deprecated since 0.13 and will be removed in 0.15. Please use InterpolationMode enum.
  warnings.warn(
2023-04-08 16:02:50 - distributed_c10d.py[line:262] - INFO: Rank 0: Completed store-based barrier for key:store_based_barrier_key:2 with 2 nodes.
2023-04-08 16:02:50 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_tokens.weight <- decoder.embed_tokens.weight
2023-04-08 16:02:50 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_tokens.weight <- decoder.output_projection.weight
2023-04-08 16:02:50 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer1.0.conv1.bias
2023-04-08 16:02:50 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer1.0.conv2.bias
2023-04-08 16:02:50 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer1.0.conv3.bias
2023-04-08 16:02:50 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer1.0.downsample.0.bias
2023-04-08 16:02:50 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer1.1.conv1.bias
2023-04-08 16:02:50 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer1.1.conv2.bias
2023-04-08 16:02:50 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer1.1.conv3.bias
2023-04-08 16:02:50 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer1.2.conv1.bias
2023-04-08 16:02:50 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer1.2.conv2.bias
2023-04-08 16:02:50 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer1.2.conv3.bias
2023-04-08 16:02:50 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.0.conv1.bias
2023-04-08 16:02:50 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.0.conv2.bias
2023-04-08 16:02:50 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.0.conv3.bias
2023-04-08 16:02:50 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.0.downsample.0.bias
2023-04-08 16:02:50 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.1.conv1.bias
2023-04-08 16:02:50 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.1.conv2.bias
2023-04-08 16:02:50 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.1.conv3.bias
2023-04-08 16:02:50 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.2.conv1.bias
2023-04-08 16:02:50 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.2.conv2.bias
2023-04-08 16:02:50 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.2.conv3.bias
2023-04-08 16:02:50 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.3.conv1.bias
2023-04-08 16:02:50 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.3.conv2.bias
2023-04-08 16:02:50 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.3.conv3.bias
2023-04-08 16:02:50 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.0.conv1.bias
2023-04-08 16:02:50 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.0.conv2.bias
2023-04-08 16:02:50 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.0.conv3.bias
2023-04-08 16:02:50 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.0.downsample.0.bias
2023-04-08 16:02:50 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.1.conv1.bias
2023-04-08 16:02:50 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.1.conv2.bias
2023-04-08 16:02:50 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.1.conv3.bias
2023-04-08 16:02:50 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.2.conv1.bias
2023-04-08 16:02:50 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.2.conv2.bias
2023-04-08 16:02:50 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.2.conv3.bias
2023-04-08 16:02:50 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.3.conv1.bias
2023-04-08 16:02:50 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.3.conv2.bias
2023-04-08 16:02:50 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.3.conv3.bias
2023-04-08 16:02:50 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.4.conv1.bias
2023-04-08 16:02:50 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.4.conv2.bias
2023-04-08 16:02:50 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.4.conv3.bias
2023-04-08 16:02:50 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.5.conv1.bias
2023-04-08 16:02:50 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.5.conv2.bias
2023-04-08 16:02:50 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.5.conv3.bias
2023-04-08 16:02:50 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.6.conv1.bias
2023-04-08 16:02:50 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.6.conv2.bias
2023-04-08 16:02:50 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.6.conv3.bias
2023-04-08 16:02:50 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.7.conv1.bias
2023-04-08 16:02:50 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.7.conv2.bias
2023-04-08 16:02:50 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.7.conv3.bias
2023-04-08 16:02:50 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.8.conv1.bias
2023-04-08 16:02:50 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.8.conv2.bias
2023-04-08 16:02:50 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.8.conv3.bias
2023-04-08 16:02:50 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.9.conv1.bias
2023-04-08 16:02:50 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.9.conv2.bias
2023-04-08 16:02:50 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.9.conv3.bias
2023-04-08 16:02:50 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.10.conv1.bias
2023-04-08 16:02:50 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.10.conv2.bias
2023-04-08 16:02:50 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.10.conv3.bias
2023-04-08 16:02:50 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.11.conv1.bias
2023-04-08 16:02:50 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.11.conv2.bias
2023-04-08 16:02:50 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.11.conv3.bias
2023-04-08 16:02:50 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.12.conv1.bias
2023-04-08 16:02:50 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.12.conv2.bias
2023-04-08 16:02:50 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.12.conv3.bias
2023-04-08 16:02:50 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.13.conv1.bias
2023-04-08 16:02:50 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.13.conv2.bias
2023-04-08 16:02:50 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.13.conv3.bias
2023-04-08 16:02:50 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.14.conv1.bias
2023-04-08 16:02:50 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.14.conv2.bias
2023-04-08 16:02:50 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.14.conv3.bias
2023-04-08 16:02:50 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.15.conv1.bias
2023-04-08 16:02:50 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.15.conv2.bias
2023-04-08 16:02:50 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.15.conv3.bias
2023-04-08 16:02:50 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.16.conv1.bias
2023-04-08 16:02:50 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.16.conv2.bias
2023-04-08 16:02:50 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.16.conv3.bias
2023-04-08 16:02:50 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.17.conv1.bias
2023-04-08 16:02:50 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.17.conv2.bias
2023-04-08 16:02:50 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.17.conv3.bias
2023-04-08 16:02:50 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.18.conv1.bias
2023-04-08 16:02:50 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.18.conv2.bias
2023-04-08 16:02:50 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.18.conv3.bias
2023-04-08 16:02:50 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.19.conv1.bias
2023-04-08 16:02:50 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.19.conv2.bias
2023-04-08 16:02:50 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.19.conv3.bias
2023-04-08 16:02:50 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.20.conv1.bias
2023-04-08 16:02:50 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.20.conv2.bias
2023-04-08 16:02:50 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.20.conv3.bias
2023-04-08 16:02:50 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.21.conv1.bias
2023-04-08 16:02:50 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.21.conv2.bias
2023-04-08 16:02:50 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.21.conv3.bias
2023-04-08 16:02:50 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.22.conv1.bias
2023-04-08 16:02:50 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.22.conv2.bias
2023-04-08 16:02:50 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.22.conv3.bias
2023-04-08 16:02:50 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- decoder.output_projection.bias
2023-04-08 16:02:50 - utils.py[line:759] - INFO: ***********************CUDA enviroments for all 2 workers***********************
2023-04-08 16:02:50 - utils.py[line:761] - INFO: rank   0: capabilities =  8.6  ; total memory = 23.688 GB ; name = NVIDIA GeForce RTX 3090 Ti              
2023-04-08 16:02:50 - utils.py[line:761] - INFO: rank   1: capabilities =  8.6  ; total memory = 23.688 GB ; name = NVIDIA GeForce RTX 3090 Ti              
2023-04-08 16:02:50 - utils.py[line:767] - INFO: ***********************CUDA enviroments for all 2 workers***********************
2023-04-08 16:02:50 - train.py[line:152] - INFO: training on 2 devices (GPUs/TPUs)
2023-04-08 16:02:50 - train.py[line:157] - INFO: max tokens per device = None and max sentences per device = 6
2023-04-08 16:02:50 - trainer.py[line:458] - INFO: Preparing to load checkpoint ../../checkpoints/ofa_base.pt
2023-04-08 16:02:50 - trainer.py[line:624] - INFO: No existing checkpoint found ../../checkpoints/ofa_base.pt
2023-04-08 16:02:50 - trainer.py[line:639] - INFO: loading train data for epoch 1
local datafile ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 1 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 0 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 1 finished initializing row_count and line_idx-to-offset mapping
file ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 1 row count 27700 total row count 55400
local datafile ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 0 finished initializing row_count and line_idx-to-offset mapping
file ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 0 row count 27700 total row count 55400
slice_id 1 seek offset 27700
slice_id 0 seek offset 0
Total steps 6936, warmup steps 416, warmup_factor 0.002403846153846154
Total steps 6936, warmup steps 416, warmup_factor 0.002403846153846154
wandb: Currently logged in as: jackcai1206. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.14.2 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /home/zcai75/Github/OFA_forked/run_scripts/sgcls/wandb/run-20230408_160253-hv2tyegz
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run _12_3e-5_512
wandb:  View project at https://wandb.ai/jackcai1206/OFA-VG
wandb:  View run at https://wandb.ai/jackcai1206/OFA-VG/runs/hv2tyegz
2023-04-08 16:02:59 - trainer.py[line:703] - INFO: begin training epoch 1
2023-04-08 16:02:59 - train.py[line:305] - INFO: Start iterating over samples
2023-04-08 16:03:05 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2023-04-08 16:03:34 - progress_bar.py[line:272] - INFO: epoch 001:     11 / 578 loss=10.996, loss_v1=0, loss_v2=0, nll_loss=10.997, ntokens=2417.4, nsentences=96, sample_size=2417.4, sample_size_v1=0, sample_size_v2=0, ppl=2043.54, wps=845.8, ups=0.35, wpb=2417.4, bsz=96, num_updates=10, lr=7.21154e-07, gnorm=17.545, clip=100, loss_scale=64, train_wall=34, gb_free=12.4, wall=43
2023-04-08 16:04:02 - progress_bar.py[line:272] - INFO: epoch 001:     21 / 578 loss=10.565, loss_v1=0, loss_v2=0, nll_loss=10.518, ntokens=2349.3, nsentences=96, sample_size=2349.3, sample_size_v1=0, sample_size_v2=0, ppl=1466.71, wps=821.2, ups=0.35, wpb=2349.3, bsz=96, num_updates=20, lr=1.44231e-06, gnorm=16.27, clip=100, loss_scale=64, train_wall=29, gb_free=12, wall=72
2023-04-08 16:04:31 - progress_bar.py[line:272] - INFO: epoch 001:     31 / 578 loss=9.711, loss_v1=0, loss_v2=0, nll_loss=9.568, ntokens=2290.8, nsentences=96, sample_size=2290.8, sample_size_v1=0, sample_size_v2=0, ppl=759.25, wps=794, ups=0.35, wpb=2290.8, bsz=96, num_updates=30, lr=2.16346e-06, gnorm=12.32, clip=100, loss_scale=64, train_wall=29, gb_free=12.3, wall=101
2023-04-08 16:05:00 - progress_bar.py[line:272] - INFO: epoch 001:     41 / 578 loss=8.9, loss_v1=0, loss_v2=0, nll_loss=8.666, ntokens=2192.1, nsentences=96, sample_size=2192.1, sample_size_v1=0, sample_size_v2=0, ppl=406.27, wps=765.3, ups=0.35, wpb=2192.1, bsz=96, num_updates=40, lr=2.88462e-06, gnorm=9.378, clip=100, loss_scale=64, train_wall=29, gb_free=11.7, wall=129
2023-04-08 16:05:29 - progress_bar.py[line:272] - INFO: epoch 001:     51 / 578 loss=8.219, loss_v1=0, loss_v2=0, nll_loss=7.908, ntokens=2406.9, nsentences=96, sample_size=2406.9, sample_size_v1=0, sample_size_v2=0, ppl=240.12, wps=821, ups=0.34, wpb=2406.9, bsz=96, num_updates=50, lr=3.60577e-06, gnorm=7.553, clip=100, loss_scale=64, train_wall=29, gb_free=11.7, wall=159
2023-04-08 16:05:58 - progress_bar.py[line:272] - INFO: epoch 001:     61 / 578 loss=7.779, loss_v1=0, loss_v2=0, nll_loss=7.414, ntokens=2280.2, nsentences=96, sample_size=2280.2, sample_size_v1=0, sample_size_v2=0, ppl=170.59, wps=791.8, ups=0.35, wpb=2280.2, bsz=96, num_updates=60, lr=4.32692e-06, gnorm=6.341, clip=100, loss_scale=64, train_wall=29, gb_free=12.5, wall=188
2023-04-08 16:06:26 - progress_bar.py[line:272] - INFO: epoch 001:     71 / 578 loss=7.471, loss_v1=0, loss_v2=0, nll_loss=7.068, ntokens=2317.4, nsentences=95.6, sample_size=2317.4, sample_size_v1=0, sample_size_v2=0, ppl=134.19, wps=813, ups=0.35, wpb=2317.4, bsz=95.6, num_updates=70, lr=5.04808e-06, gnorm=5.643, clip=100, loss_scale=64, train_wall=28, gb_free=11.7, wall=216
2023-04-08 16:06:55 - progress_bar.py[line:272] - INFO: epoch 001:     81 / 578 loss=7.212, loss_v1=0, loss_v2=0, nll_loss=6.777, ntokens=2530.1, nsentences=96, sample_size=2530.1, sample_size_v1=0, sample_size_v2=0, ppl=109.7, wps=878.8, ups=0.35, wpb=2530.1, bsz=96, num_updates=80, lr=5.76923e-06, gnorm=5.086, clip=100, loss_scale=64, train_wall=29, gb_free=12.2, wall=245
2023-04-08 16:07:24 - progress_bar.py[line:272] - INFO: epoch 001:     91 / 578 loss=6.974, loss_v1=0, loss_v2=0, nll_loss=6.512, ntokens=2516.1, nsentences=96, sample_size=2516.1, sample_size_v1=0, sample_size_v2=0, ppl=91.28, wps=870.2, ups=0.35, wpb=2516.1, bsz=96, num_updates=90, lr=6.49038e-06, gnorm=4.934, clip=100, loss_scale=64, train_wall=29, gb_free=11.9, wall=274
2023-04-08 16:07:53 - progress_bar.py[line:272] - INFO: epoch 001:    101 / 578 loss=6.728, loss_v1=0, loss_v2=0, nll_loss=6.237, ntokens=2422.6, nsentences=96, sample_size=2422.6, sample_size_v1=0, sample_size_v2=0, ppl=75.4, wps=832.9, ups=0.34, wpb=2422.6, bsz=96, num_updates=100, lr=7.21154e-06, gnorm=4.777, clip=100, loss_scale=64, train_wall=29, gb_free=11.5, wall=303
2023-04-08 16:08:22 - progress_bar.py[line:272] - INFO: epoch 001:    111 / 578 loss=6.36, loss_v1=0, loss_v2=0, nll_loss=5.822, ntokens=2433, nsentences=96, sample_size=2433, sample_size_v1=0, sample_size_v2=0, ppl=56.56, wps=842.4, ups=0.35, wpb=2433, bsz=96, num_updates=110, lr=7.93269e-06, gnorm=4.434, clip=100, loss_scale=64, train_wall=29, gb_free=11.7, wall=332
2023-04-08 16:08:51 - progress_bar.py[line:272] - INFO: epoch 001:    121 / 578 loss=5.898, loss_v1=0, loss_v2=0, nll_loss=5.294, ntokens=2330.1, nsentences=96, sample_size=2330.1, sample_size_v1=0, sample_size_v2=0, ppl=39.23, wps=810.9, ups=0.35, wpb=2330.1, bsz=96, num_updates=120, lr=8.65385e-06, gnorm=3.855, clip=100, loss_scale=64, train_wall=29, gb_free=12.2, wall=361
2023-04-08 16:09:20 - progress_bar.py[line:272] - INFO: epoch 001:    131 / 578 loss=5.561, loss_v1=0, loss_v2=0, nll_loss=4.904, ntokens=2424.5, nsentences=96, sample_size=2424.5, sample_size_v1=0, sample_size_v2=0, ppl=29.95, wps=839.3, ups=0.35, wpb=2424.5, bsz=96, num_updates=130, lr=9.375e-06, gnorm=3.272, clip=100, loss_scale=64, train_wall=29, gb_free=12.3, wall=389
2023-04-08 16:09:48 - progress_bar.py[line:272] - INFO: epoch 001:    141 / 578 loss=5.349, loss_v1=0, loss_v2=0, nll_loss=4.658, ntokens=2413.2, nsentences=96, sample_size=2413.2, sample_size_v1=0, sample_size_v2=0, ppl=25.24, wps=847.9, ups=0.35, wpb=2413.2, bsz=96, num_updates=140, lr=1.00962e-05, gnorm=3.137, clip=100, loss_scale=64, train_wall=28, gb_free=12.1, wall=418
2023-04-08 16:10:17 - progress_bar.py[line:272] - INFO: epoch 001:    151 / 578 loss=5.156, loss_v1=0, loss_v2=0, nll_loss=4.438, ntokens=2654.2, nsentences=96, sample_size=2654.2, sample_size_v1=0, sample_size_v2=0, ppl=21.67, wps=932.3, ups=0.35, wpb=2654.2, bsz=96, num_updates=150, lr=1.08173e-05, gnorm=2.903, clip=100, loss_scale=64, train_wall=28, gb_free=12.3, wall=446
2023-04-08 16:10:45 - progress_bar.py[line:272] - INFO: epoch 001:    161 / 578 loss=4.958, loss_v1=0, loss_v2=0, nll_loss=4.212, ntokens=2712.2, nsentences=96, sample_size=2712.2, sample_size_v1=0, sample_size_v2=0, ppl=18.54, wps=951.7, ups=0.35, wpb=2712.2, bsz=96, num_updates=160, lr=1.15385e-05, gnorm=2.539, clip=100, loss_scale=64, train_wall=28, gb_free=12.2, wall=475
2023-04-08 16:11:14 - progress_bar.py[line:272] - INFO: epoch 001:    171 / 578 loss=4.794, loss_v1=0, loss_v2=0, nll_loss=4.022, ntokens=2598.7, nsentences=96, sample_size=2598.7, sample_size_v1=0, sample_size_v2=0, ppl=16.25, wps=911.4, ups=0.35, wpb=2598.7, bsz=96, num_updates=170, lr=1.22596e-05, gnorm=2.338, clip=100, loss_scale=64, train_wall=28, gb_free=12.4, wall=503
2023-04-08 16:11:42 - progress_bar.py[line:272] - INFO: epoch 001:    181 / 578 loss=4.68, loss_v1=0, loss_v2=0, nll_loss=3.891, ntokens=2627.6, nsentences=96, sample_size=2627.6, sample_size_v1=0, sample_size_v2=0, ppl=14.84, wps=921.4, ups=0.35, wpb=2627.6, bsz=96, num_updates=180, lr=1.29808e-05, gnorm=2.175, clip=100, loss_scale=64, train_wall=28, gb_free=12.3, wall=532
2023-04-08 16:12:11 - progress_bar.py[line:272] - INFO: epoch 001:    191 / 578 loss=4.531, loss_v1=0, loss_v2=0, nll_loss=3.721, ntokens=2657.2, nsentences=96, sample_size=2657.2, sample_size_v1=0, sample_size_v2=0, ppl=13.18, wps=928.3, ups=0.35, wpb=2657.2, bsz=96, num_updates=190, lr=1.37019e-05, gnorm=2.005, clip=100, loss_scale=64, train_wall=29, gb_free=11.8, wall=561
2023-04-08 16:12:39 - progress_bar.py[line:272] - INFO: epoch 001:    201 / 578 loss=4.425, loss_v1=0, loss_v2=0, nll_loss=3.597, ntokens=2568.6, nsentences=96, sample_size=2568.6, sample_size_v1=0, sample_size_v2=0, ppl=12.1, wps=904, ups=0.35, wpb=2568.6, bsz=96, num_updates=200, lr=1.44231e-05, gnorm=1.978, clip=100, loss_scale=64, train_wall=28, gb_free=12.5, wall=589
2023-04-08 16:13:08 - progress_bar.py[line:272] - INFO: epoch 001:    211 / 578 loss=4.297, loss_v1=0, loss_v2=0, nll_loss=3.451, ntokens=2514.1, nsentences=96, sample_size=2514.1, sample_size_v1=0, sample_size_v2=0, ppl=10.94, wps=886.6, ups=0.35, wpb=2514.1, bsz=96, num_updates=210, lr=1.51442e-05, gnorm=1.927, clip=100, loss_scale=64, train_wall=28, gb_free=12.2, wall=617
2023-04-08 16:13:36 - progress_bar.py[line:272] - INFO: epoch 001:    221 / 578 loss=4.158, loss_v1=0, loss_v2=0, nll_loss=3.292, ntokens=2574.1, nsentences=96, sample_size=2574.1, sample_size_v1=0, sample_size_v2=0, ppl=9.79, wps=906.9, ups=0.35, wpb=2574.1, bsz=96, num_updates=220, lr=1.58654e-05, gnorm=1.86, clip=100, loss_scale=64, train_wall=28, gb_free=12.1, wall=646
2023-04-08 16:14:04 - progress_bar.py[line:272] - INFO: epoch 001:    231 / 578 loss=4.032, loss_v1=0, loss_v2=0, nll_loss=3.148, ntokens=2443.6, nsentences=96, sample_size=2443.6, sample_size_v1=0, sample_size_v2=0, ppl=8.86, wps=864.2, ups=0.35, wpb=2443.6, bsz=96, num_updates=230, lr=1.65865e-05, gnorm=1.828, clip=100, loss_scale=64, train_wall=28, gb_free=12.5, wall=674
2023-04-08 16:14:33 - progress_bar.py[line:272] - INFO: epoch 001:    241 / 578 loss=3.937, loss_v1=0, loss_v2=0, nll_loss=3.036, ntokens=2489.2, nsentences=96, sample_size=2489.2, sample_size_v1=0, sample_size_v2=0, ppl=8.2, wps=878.5, ups=0.35, wpb=2489.2, bsz=96, num_updates=240, lr=1.73077e-05, gnorm=1.502, clip=100, loss_scale=64, train_wall=28, gb_free=12.4, wall=702
2023-04-08 16:15:01 - progress_bar.py[line:272] - INFO: epoch 001:    251 / 578 loss=3.807, loss_v1=0, loss_v2=0, nll_loss=2.887, ntokens=2535.5, nsentences=96, sample_size=2535.5, sample_size_v1=0, sample_size_v2=0, ppl=7.4, wps=897.2, ups=0.35, wpb=2535.5, bsz=96, num_updates=250, lr=1.80288e-05, gnorm=1.442, clip=100, loss_scale=64, train_wall=28, gb_free=12.3, wall=731
2023-04-08 16:15:29 - progress_bar.py[line:272] - INFO: epoch 001:    261 / 578 loss=3.663, loss_v1=0, loss_v2=0, nll_loss=2.72, ntokens=2517.8, nsentences=96, sample_size=2517.8, sample_size_v1=0, sample_size_v2=0, ppl=6.59, wps=890.3, ups=0.35, wpb=2517.8, bsz=96, num_updates=260, lr=1.875e-05, gnorm=1.452, clip=100, loss_scale=64, train_wall=28, gb_free=12.7, wall=759
2023-04-08 16:15:58 - progress_bar.py[line:272] - INFO: epoch 001:    271 / 578 loss=3.571, loss_v1=0, loss_v2=0, nll_loss=2.609, ntokens=2570, nsentences=96, sample_size=2570, sample_size_v1=0, sample_size_v2=0, ppl=6.1, wps=906.9, ups=0.35, wpb=2570, bsz=96, num_updates=270, lr=1.94712e-05, gnorm=1.363, clip=100, loss_scale=64, train_wall=28, gb_free=12.4, wall=787
2023-04-08 16:16:26 - progress_bar.py[line:272] - INFO: epoch 001:    281 / 578 loss=3.477, loss_v1=0, loss_v2=0, nll_loss=2.495, ntokens=2572.9, nsentences=96, sample_size=2572.9, sample_size_v1=0, sample_size_v2=0, ppl=5.64, wps=904.9, ups=0.35, wpb=2572.9, bsz=96, num_updates=280, lr=2.01923e-05, gnorm=1.301, clip=100, loss_scale=64, train_wall=28, gb_free=12.2, wall=816
2023-04-08 16:16:54 - progress_bar.py[line:272] - INFO: epoch 001:    291 / 578 loss=3.39, loss_v1=0, loss_v2=0, nll_loss=2.39, ntokens=2614.3, nsentences=96, sample_size=2614.3, sample_size_v1=0, sample_size_v2=0, ppl=5.24, wps=919.4, ups=0.35, wpb=2614.3, bsz=96, num_updates=290, lr=2.09135e-05, gnorm=1.23, clip=100, loss_scale=64, train_wall=28, gb_free=12.2, wall=844
2023-04-08 16:17:23 - progress_bar.py[line:272] - INFO: epoch 001:    301 / 578 loss=3.338, loss_v1=0, loss_v2=0, nll_loss=2.325, ntokens=2493.7, nsentences=96, sample_size=2493.7, sample_size_v1=0, sample_size_v2=0, ppl=5.01, wps=873.6, ups=0.35, wpb=2493.7, bsz=96, num_updates=300, lr=2.16346e-05, gnorm=1.178, clip=60, loss_scale=64, train_wall=29, gb_free=12.1, wall=873
2023-04-08 16:17:52 - progress_bar.py[line:272] - INFO: epoch 001:    311 / 578 loss=3.254, loss_v1=0, loss_v2=0, nll_loss=2.225, ntokens=2623, nsentences=96, sample_size=2623, sample_size_v1=0, sample_size_v2=0, ppl=4.67, wps=917.3, ups=0.35, wpb=2623, bsz=96, num_updates=310, lr=2.23558e-05, gnorm=1.116, clip=80, loss_scale=64, train_wall=29, gb_free=12.2, wall=901
2023-04-08 16:18:20 - progress_bar.py[line:272] - INFO: epoch 001:    321 / 578 loss=3.214, loss_v1=0, loss_v2=0, nll_loss=2.174, ntokens=2644.8, nsentences=96, sample_size=2644.8, sample_size_v1=0, sample_size_v2=0, ppl=4.51, wps=928.9, ups=0.35, wpb=2644.8, bsz=96, num_updates=320, lr=2.30769e-05, gnorm=1.182, clip=90, loss_scale=64, train_wall=28, gb_free=12.7, wall=930
2023-04-08 16:18:48 - progress_bar.py[line:272] - INFO: epoch 001:    331 / 578 loss=3.141, loss_v1=0, loss_v2=0, nll_loss=2.085, ntokens=2542.6, nsentences=96, sample_size=2542.6, sample_size_v1=0, sample_size_v2=0, ppl=4.24, wps=894.2, ups=0.35, wpb=2542.6, bsz=96, num_updates=330, lr=2.37981e-05, gnorm=1.219, clip=100, loss_scale=64, train_wall=28, gb_free=12.3, wall=958
2023-04-08 16:19:17 - progress_bar.py[line:272] - INFO: epoch 001:    341 / 578 loss=3.138, loss_v1=0, loss_v2=0, nll_loss=2.077, ntokens=2652.7, nsentences=96, sample_size=2652.7, sample_size_v1=0, sample_size_v2=0, ppl=4.22, wps=937.3, ups=0.35, wpb=2652.7, bsz=96, num_updates=340, lr=2.45192e-05, gnorm=1.056, clip=70, loss_scale=64, train_wall=28, gb_free=12.8, wall=986
2023-04-08 16:19:45 - progress_bar.py[line:272] - INFO: epoch 001:    351 / 578 loss=3.077, loss_v1=0, loss_v2=0, nll_loss=2.009, ntokens=2617.4, nsentences=96, sample_size=2617.4, sample_size_v1=0, sample_size_v2=0, ppl=4.03, wps=925.6, ups=0.35, wpb=2617.4, bsz=96, num_updates=350, lr=2.52404e-05, gnorm=1.161, clip=80, loss_scale=64, train_wall=28, gb_free=12.5, wall=1015
2023-04-08 16:20:13 - progress_bar.py[line:272] - INFO: epoch 001:    361 / 578 loss=3.024, loss_v1=0, loss_v2=0, nll_loss=1.944, ntokens=2665.9, nsentences=96, sample_size=2665.9, sample_size_v1=0, sample_size_v2=0, ppl=3.85, wps=941.6, ups=0.35, wpb=2665.9, bsz=96, num_updates=360, lr=2.59615e-05, gnorm=1.137, clip=80, loss_scale=64, train_wall=28, gb_free=12.3, wall=1043
2023-04-08 16:20:42 - progress_bar.py[line:272] - INFO: epoch 001:    371 / 578 loss=3.02, loss_v1=0, loss_v2=0, nll_loss=1.935, ntokens=2822.2, nsentences=96, sample_size=2822.2, sample_size_v1=0, sample_size_v2=0, ppl=3.82, wps=987.4, ups=0.35, wpb=2822.2, bsz=96, num_updates=370, lr=2.66827e-05, gnorm=1.147, clip=90, loss_scale=64, train_wall=29, gb_free=12.1, wall=1072
2023-04-08 16:21:10 - progress_bar.py[line:272] - INFO: epoch 001:    381 / 578 loss=2.984, loss_v1=0, loss_v2=0, nll_loss=1.894, ntokens=2713.8, nsentences=96, sample_size=2713.8, sample_size_v1=0, sample_size_v2=0, ppl=3.72, wps=953.4, ups=0.35, wpb=2713.8, bsz=96, num_updates=380, lr=2.74038e-05, gnorm=1.163, clip=90, loss_scale=64, train_wall=28, gb_free=12.4, wall=1100
2023-04-08 16:21:39 - progress_bar.py[line:272] - INFO: epoch 001:    391 / 578 loss=2.972, loss_v1=0, loss_v2=0, nll_loss=1.877, ntokens=2590.7, nsentences=96, sample_size=2590.7, sample_size_v1=0, sample_size_v2=0, ppl=3.67, wps=910.3, ups=0.35, wpb=2590.7, bsz=96, num_updates=390, lr=2.8125e-05, gnorm=1.162, clip=80, loss_scale=64, train_wall=28, gb_free=12.3, wall=1129
2023-04-08 16:22:07 - progress_bar.py[line:272] - INFO: epoch 001:    401 / 578 loss=2.918, loss_v1=0, loss_v2=0, nll_loss=1.817, ntokens=2517.1, nsentences=96, sample_size=2517.1, sample_size_v1=0, sample_size_v2=0, ppl=3.52, wps=887.4, ups=0.35, wpb=2517.1, bsz=96, num_updates=400, lr=2.88462e-05, gnorm=1.144, clip=90, loss_scale=64, train_wall=28, gb_free=12.6, wall=1157
2023-04-08 16:22:36 - progress_bar.py[line:272] - INFO: epoch 001:    411 / 578 loss=2.899, loss_v1=0, loss_v2=0, nll_loss=1.79, ntokens=2435.2, nsentences=96, sample_size=2435.2, sample_size_v1=0, sample_size_v2=0, ppl=3.46, wps=860.2, ups=0.35, wpb=2435.2, bsz=96, num_updates=410, lr=2.95673e-05, gnorm=1.084, clip=80, loss_scale=64, train_wall=28, gb_free=12.7, wall=1185
2023-04-08 16:23:04 - progress_bar.py[line:272] - INFO: epoch 001:    421 / 578 loss=2.89, loss_v1=0, loss_v2=0, nll_loss=1.779, ntokens=2490.9, nsentences=96, sample_size=2490.9, sample_size_v1=0, sample_size_v2=0, ppl=3.43, wps=878.5, ups=0.35, wpb=2490.9, bsz=96, num_updates=420, lr=2.99816e-05, gnorm=1.069, clip=80, loss_scale=64, train_wall=28, gb_free=12.3, wall=1214
2023-04-08 16:23:32 - progress_bar.py[line:272] - INFO: epoch 001:    431 / 578 loss=2.863, loss_v1=0, loss_v2=0, nll_loss=1.747, ntokens=2547.6, nsentences=96, sample_size=2547.6, sample_size_v1=0, sample_size_v2=0, ppl=3.36, wps=896.4, ups=0.35, wpb=2547.6, bsz=96, num_updates=430, lr=2.99356e-05, gnorm=1.076, clip=90, loss_scale=64, train_wall=28, gb_free=12.7, wall=1242
2023-04-08 16:24:00 - progress_bar.py[line:272] - INFO: epoch 001:    441 / 578 loss=2.866, loss_v1=0, loss_v2=0, nll_loss=1.748, ntokens=2465.5, nsentences=96, sample_size=2465.5, sample_size_v1=0, sample_size_v2=0, ppl=3.36, wps=876.1, ups=0.36, wpb=2465.5, bsz=96, num_updates=440, lr=2.98896e-05, gnorm=1.055, clip=50, loss_scale=64, train_wall=28, gb_free=12.5, wall=1270
2023-04-08 16:24:29 - progress_bar.py[line:272] - INFO: epoch 001:    451 / 578 loss=2.841, loss_v1=0, loss_v2=0, nll_loss=1.719, ntokens=2510.8, nsentences=96, sample_size=2510.8, sample_size_v1=0, sample_size_v2=0, ppl=3.29, wps=884.2, ups=0.35, wpb=2510.8, bsz=96, num_updates=450, lr=2.98436e-05, gnorm=1.095, clip=80, loss_scale=64, train_wall=28, gb_free=12.1, wall=1299
2023-04-08 16:24:57 - progress_bar.py[line:272] - INFO: epoch 001:    461 / 578 loss=2.827, loss_v1=0, loss_v2=0, nll_loss=1.702, ntokens=2458.1, nsentences=96, sample_size=2458.1, sample_size_v1=0, sample_size_v2=0, ppl=3.25, wps=868.3, ups=0.35, wpb=2458.1, bsz=96, num_updates=460, lr=2.97975e-05, gnorm=1.073, clip=70, loss_scale=64, train_wall=28, gb_free=12.5, wall=1327
2023-04-08 16:25:26 - progress_bar.py[line:272] - INFO: epoch 001:    471 / 578 loss=2.818, loss_v1=0, loss_v2=0, nll_loss=1.693, ntokens=2500.4, nsentences=96, sample_size=2500.4, sample_size_v1=0, sample_size_v2=0, ppl=3.23, wps=881.1, ups=0.35, wpb=2500.4, bsz=96, num_updates=470, lr=2.97515e-05, gnorm=1.012, clip=60, loss_scale=64, train_wall=28, gb_free=12.7, wall=1355
2023-04-08 16:25:54 - progress_bar.py[line:272] - INFO: epoch 001:    481 / 578 loss=2.813, loss_v1=0, loss_v2=0, nll_loss=1.686, ntokens=2334.2, nsentences=96, sample_size=2334.2, sample_size_v1=0, sample_size_v2=0, ppl=3.22, wps=823.1, ups=0.35, wpb=2334.2, bsz=96, num_updates=480, lr=2.97055e-05, gnorm=1.005, clip=50, loss_scale=64, train_wall=28, gb_free=12.5, wall=1384
2023-04-08 16:26:22 - progress_bar.py[line:272] - INFO: epoch 001:    491 / 578 loss=2.777, loss_v1=0, loss_v2=0, nll_loss=1.643, ntokens=2524.6, nsentences=96, sample_size=2524.6, sample_size_v1=0, sample_size_v2=0, ppl=3.12, wps=894.8, ups=0.35, wpb=2524.6, bsz=96, num_updates=490, lr=2.96595e-05, gnorm=0.998, clip=40, loss_scale=64, train_wall=28, gb_free=12.4, wall=1412
2023-04-08 16:26:51 - progress_bar.py[line:272] - INFO: epoch 001:    501 / 578 loss=2.765, loss_v1=0, loss_v2=0, nll_loss=1.629, ntokens=2520.8, nsentences=96, sample_size=2520.8, sample_size_v1=0, sample_size_v2=0, ppl=3.09, wps=886, ups=0.35, wpb=2520.8, bsz=96, num_updates=500, lr=2.96135e-05, gnorm=1.007, clip=40, loss_scale=64, train_wall=28, gb_free=12.4, wall=1440
2023-04-08 16:27:19 - progress_bar.py[line:272] - INFO: epoch 001:    511 / 578 loss=2.764, loss_v1=0, loss_v2=0, nll_loss=1.627, ntokens=2555.3, nsentences=96, sample_size=2555.3, sample_size_v1=0, sample_size_v2=0, ppl=3.09, wps=900.4, ups=0.35, wpb=2555.3, bsz=96, num_updates=510, lr=2.95675e-05, gnorm=1.103, clip=70, loss_scale=64, train_wall=28, gb_free=12.5, wall=1469
2023-04-08 16:27:47 - progress_bar.py[line:272] - INFO: epoch 001:    521 / 578 loss=2.733, loss_v1=0, loss_v2=0, nll_loss=1.593, ntokens=2726.4, nsentences=96, sample_size=2726.4, sample_size_v1=0, sample_size_v2=0, ppl=3.02, wps=958.9, ups=0.35, wpb=2726.4, bsz=96, num_updates=520, lr=2.95215e-05, gnorm=0.898, clip=10, loss_scale=128, train_wall=28, gb_free=12.6, wall=1497
2023-04-08 16:28:16 - progress_bar.py[line:272] - INFO: epoch 001:    531 / 578 loss=2.746, loss_v1=0, loss_v2=0, nll_loss=1.602, ntokens=2565.2, nsentences=96, sample_size=2565.2, sample_size_v1=0, sample_size_v2=0, ppl=3.03, wps=906.9, ups=0.35, wpb=2565.2, bsz=96, num_updates=530, lr=2.94755e-05, gnorm=0.932, clip=20, loss_scale=128, train_wall=28, gb_free=12.5, wall=1525
2023-04-08 16:28:44 - progress_bar.py[line:272] - INFO: epoch 001:    541 / 578 loss=2.729, loss_v1=0, loss_v2=0, nll_loss=1.587, ntokens=2461.1, nsentences=96, sample_size=2461.1, sample_size_v1=0, sample_size_v2=0, ppl=3, wps=866.2, ups=0.35, wpb=2461.1, bsz=96, num_updates=540, lr=2.94294e-05, gnorm=0.937, clip=30, loss_scale=128, train_wall=28, gb_free=12.5, wall=1554
2023-04-08 16:29:13 - progress_bar.py[line:272] - INFO: epoch 001:    551 / 578 loss=2.722, loss_v1=0, loss_v2=0, nll_loss=1.578, ntokens=2574.1, nsentences=96, sample_size=2574.1, sample_size_v1=0, sample_size_v2=0, ppl=2.98, wps=902.7, ups=0.35, wpb=2574.1, bsz=96, num_updates=550, lr=2.93834e-05, gnorm=1.023, clip=60, loss_scale=128, train_wall=28, gb_free=12.5, wall=1582
2023-04-08 16:29:41 - progress_bar.py[line:272] - INFO: epoch 001:    561 / 578 loss=2.709, loss_v1=0, loss_v2=0, nll_loss=1.562, ntokens=2646.2, nsentences=96, sample_size=2646.2, sample_size_v1=0, sample_size_v2=0, ppl=2.95, wps=929.2, ups=0.35, wpb=2646.2, bsz=96, num_updates=560, lr=2.93374e-05, gnorm=1.023, clip=60, loss_scale=128, train_wall=28, gb_free=12.4, wall=1611
2023-04-08 16:30:10 - progress_bar.py[line:272] - INFO: epoch 001:    571 / 578 loss=2.718, loss_v1=0, loss_v2=0, nll_loss=1.573, ntokens=2602.8, nsentences=96, sample_size=2602.8, sample_size_v1=0, sample_size_v2=0, ppl=2.98, wps=914.1, ups=0.35, wpb=2602.8, bsz=96, num_updates=570, lr=2.92914e-05, gnorm=0.928, clip=30, loss_scale=128, train_wall=28, gb_free=12.4, wall=1639
2023-04-08 16:30:27 - train.py[line:332] - INFO: end of epoch 1 (average epoch stats below)
local datafile ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 1 begin to initialize row_count and line_idx-to-offset mapping
2023-04-08 16:30:27 - progress_bar.py[line:282] - INFO: epoch 001 | loss 4.345 | loss_v1 0 | loss_v2 0 | nll_loss 3.468 | ntokens 2519.58 | nsentences 95.847 | sample_size 2519.58 | sample_size_v1 0 | sample_size_v2 0 | ppl 11.07 | wps 885.5 | ups 0.35 | wpb 2519.6 | bsz 95.8 | num_updates 577 | lr 2.92592e-05 | gnorm 2.828 | clip 82.5 | loss_scale 128 | train_wall 1646 | gb_free 13.1 | wall 1657
2023-04-08 16:30:27 - trainer.py[line:639] - INFO: loading train data for epoch 2
local datafile ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 0 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 1 finished initializing row_count and line_idx-to-offset mapping
file ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 1 row count 27700 total row count 55400
slice_id 1 seek offset 27700
local datafile ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 0 finished initializing row_count and line_idx-to-offset mapping
file ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 0 row count 27700 total row count 55400
/data/hulab/zcai75/anaconda3/envs/vilt/lib/python3.8/site-packages/torchvision/transforms/transforms.py:332: UserWarning: Argument 'interpolation' of type int is deprecated since 0.13 and will be removed in 0.15. Please use InterpolationMode enum.
  warnings.warn(
slice_id 0 seek offset 0
2023-04-08 16:30:29 - trainer.py[line:703] - INFO: begin training epoch 2
2023-04-08 16:30:29 - train.py[line:305] - INFO: Start iterating over samples
2023-04-08 16:30:38 - progress_bar.py[line:272] - INFO: epoch 002:      3 / 578 loss=2.72, loss_v1=0, loss_v2=0, nll_loss=1.571, ntokens=2362.9, nsentences=87.6, sample_size=2362.9, sample_size_v1=0, sample_size_v2=0, ppl=2.97, wps=827.3, ups=0.35, wpb=2362.9, bsz=87.6, num_updates=580, lr=2.92454e-05, gnorm=1.155, clip=60, loss_scale=128, train_wall=26, gb_free=12.3, wall=1668
2023-04-08 16:31:07 - progress_bar.py[line:272] - INFO: epoch 002:     13 / 578 loss=2.687, loss_v1=0, loss_v2=0, nll_loss=1.535, ntokens=2397.6, nsentences=96, sample_size=2397.6, sample_size_v1=0, sample_size_v2=0, ppl=2.9, wps=837.4, ups=0.35, wpb=2397.6, bsz=96, num_updates=590, lr=2.91994e-05, gnorm=1.121, clip=90, loss_scale=128, train_wall=29, gb_free=12.5, wall=1696
2023-04-08 16:31:36 - progress_bar.py[line:272] - INFO: epoch 002:     23 / 578 loss=2.685, loss_v1=0, loss_v2=0, nll_loss=1.534, ntokens=2387.9, nsentences=96, sample_size=2387.9, sample_size_v1=0, sample_size_v2=0, ppl=2.9, wps=817.6, ups=0.34, wpb=2387.9, bsz=96, num_updates=600, lr=2.91534e-05, gnorm=1.189, clip=100, loss_scale=128, train_wall=29, gb_free=12.1, wall=1726
2023-04-08 16:32:06 - progress_bar.py[line:272] - INFO: epoch 002:     33 / 578 loss=2.7, loss_v1=0, loss_v2=0, nll_loss=1.546, ntokens=2290.1, nsentences=96, sample_size=2290.1, sample_size_v1=0, sample_size_v2=0, ppl=2.92, wps=762.4, ups=0.33, wpb=2290.1, bsz=96, num_updates=610, lr=2.91074e-05, gnorm=1.23, clip=80, loss_scale=128, train_wall=30, gb_free=12.1, wall=1756
2023-04-08 16:32:37 - progress_bar.py[line:272] - INFO: epoch 002:     43 / 578 loss=2.633, loss_v1=0, loss_v2=0, nll_loss=1.473, ntokens=2170.6, nsentences=96, sample_size=2170.6, sample_size_v1=0, sample_size_v2=0, ppl=2.78, wps=704.5, ups=0.32, wpb=2170.6, bsz=96, num_updates=620, lr=2.90613e-05, gnorm=1.203, clip=80, loss_scale=128, train_wall=31, gb_free=12.2, wall=1787
2023-04-08 16:33:08 - progress_bar.py[line:272] - INFO: epoch 002:     53 / 578 loss=2.676, loss_v1=0, loss_v2=0, nll_loss=1.52, ntokens=2397.2, nsentences=96, sample_size=2397.2, sample_size_v1=0, sample_size_v2=0, ppl=2.87, wps=774.6, ups=0.32, wpb=2397.2, bsz=96, num_updates=630, lr=2.90153e-05, gnorm=1.118, clip=80, loss_scale=128, train_wall=31, gb_free=11.9, wall=1817
2023-04-08 16:33:39 - progress_bar.py[line:272] - INFO: epoch 002:     63 / 578 loss=2.672, loss_v1=0, loss_v2=0, nll_loss=1.518, ntokens=2262.7, nsentences=96, sample_size=2262.7, sample_size_v1=0, sample_size_v2=0, ppl=2.86, wps=728.2, ups=0.32, wpb=2262.7, bsz=96, num_updates=640, lr=2.89693e-05, gnorm=1.054, clip=60, loss_scale=128, train_wall=31, gb_free=12.5, wall=1849
2023-04-08 16:34:10 - progress_bar.py[line:272] - INFO: epoch 002:     73 / 578 loss=2.712, loss_v1=0, loss_v2=0, nll_loss=1.563, ntokens=2409.8, nsentences=96, sample_size=2409.8, sample_size_v1=0, sample_size_v2=0, ppl=2.95, wps=778.5, ups=0.32, wpb=2409.8, bsz=96, num_updates=650, lr=2.89233e-05, gnorm=1.002, clip=40, loss_scale=128, train_wall=31, gb_free=12.5, wall=1880
2023-04-08 16:34:41 - progress_bar.py[line:272] - INFO: epoch 002:     83 / 578 loss=2.691, loss_v1=0, loss_v2=0, nll_loss=1.535, ntokens=2522.3, nsentences=96, sample_size=2522.3, sample_size_v1=0, sample_size_v2=0, ppl=2.9, wps=812.9, ups=0.32, wpb=2522.3, bsz=96, num_updates=660, lr=2.88773e-05, gnorm=0.943, clip=30, loss_scale=128, train_wall=31, gb_free=12.1, wall=1911
2023-04-08 16:35:12 - progress_bar.py[line:272] - INFO: epoch 002:     93 / 578 loss=2.67, loss_v1=0, loss_v2=0, nll_loss=1.512, ntokens=2501.4, nsentences=96, sample_size=2501.4, sample_size_v1=0, sample_size_v2=0, ppl=2.85, wps=811.8, ups=0.32, wpb=2501.4, bsz=96, num_updates=670, lr=2.88313e-05, gnorm=0.937, clip=20, loss_scale=128, train_wall=31, gb_free=11.9, wall=1941
2023-04-08 16:35:42 - progress_bar.py[line:272] - INFO: epoch 002:    103 / 578 loss=2.667, loss_v1=0, loss_v2=0, nll_loss=1.51, ntokens=2419.6, nsentences=96, sample_size=2419.6, sample_size_v1=0, sample_size_v2=0, ppl=2.85, wps=786.5, ups=0.33, wpb=2419.6, bsz=96, num_updates=680, lr=2.87853e-05, gnorm=0.937, clip=20, loss_scale=128, train_wall=31, gb_free=12, wall=1972
2023-04-08 16:36:14 - progress_bar.py[line:272] - INFO: epoch 002:    113 / 578 loss=2.667, loss_v1=0, loss_v2=0, nll_loss=1.507, ntokens=2393.5, nsentences=96, sample_size=2393.5, sample_size_v1=0, sample_size_v2=0, ppl=2.84, wps=768.5, ups=0.32, wpb=2393.5, bsz=96, num_updates=690, lr=2.87393e-05, gnorm=0.944, clip=30, loss_scale=128, train_wall=31, gb_free=12.3, wall=2003
2023-04-08 16:36:44 - progress_bar.py[line:272] - INFO: epoch 002:    123 / 578 loss=2.657, loss_v1=0, loss_v2=0, nll_loss=1.499, ntokens=2337.6, nsentences=96, sample_size=2337.6, sample_size_v1=0, sample_size_v2=0, ppl=2.83, wps=757.8, ups=0.32, wpb=2337.6, bsz=96, num_updates=700, lr=2.86933e-05, gnorm=0.896, clip=10, loss_scale=128, train_wall=31, gb_free=12.3, wall=2034
2023-04-08 16:37:16 - progress_bar.py[line:272] - INFO: epoch 002:    133 / 578 loss=2.657, loss_v1=0, loss_v2=0, nll_loss=1.498, ntokens=2438.3, nsentences=96, sample_size=2438.3, sample_size_v1=0, sample_size_v2=0, ppl=2.83, wps=769.5, ups=0.32, wpb=2438.3, bsz=96, num_updates=710, lr=2.86472e-05, gnorm=0.958, clip=30, loss_scale=128, train_wall=32, gb_free=12.6, wall=2066
2023-04-08 16:37:49 - progress_bar.py[line:272] - INFO: epoch 002:    143 / 578 loss=2.684, loss_v1=0, loss_v2=0, nll_loss=1.528, ntokens=2481.3, nsentences=96, sample_size=2481.3, sample_size_v1=0, sample_size_v2=0, ppl=2.88, wps=760.3, ups=0.31, wpb=2481.3, bsz=96, num_updates=720, lr=2.86012e-05, gnorm=0.948, clip=10, loss_scale=128, train_wall=33, gb_free=12.5, wall=2098
2023-04-08 16:38:21 - progress_bar.py[line:272] - INFO: epoch 002:    153 / 578 loss=2.677, loss_v1=0, loss_v2=0, nll_loss=1.519, ntokens=2665, nsentences=96, sample_size=2665, sample_size_v1=0, sample_size_v2=0, ppl=2.87, wps=815.8, ups=0.31, wpb=2665, bsz=96, num_updates=730, lr=2.85552e-05, gnorm=0.85, clip=0, loss_scale=128, train_wall=33, gb_free=12.1, wall=2131
2023-04-08 16:38:54 - progress_bar.py[line:272] - INFO: epoch 002:    163 / 578 loss=2.677, loss_v1=0, loss_v2=0, nll_loss=1.52, ntokens=2695.5, nsentences=96, sample_size=2695.5, sample_size_v1=0, sample_size_v2=0, ppl=2.87, wps=827, ups=0.31, wpb=2695.5, bsz=96, num_updates=740, lr=2.85092e-05, gnorm=0.864, clip=10, loss_scale=128, train_wall=33, gb_free=12, wall=2164
2023-04-08 16:39:27 - progress_bar.py[line:272] - INFO: epoch 002:    173 / 578 loss=2.674, loss_v1=0, loss_v2=0, nll_loss=1.518, ntokens=2576.6, nsentences=96, sample_size=2576.6, sample_size_v1=0, sample_size_v2=0, ppl=2.86, wps=793.2, ups=0.31, wpb=2576.6, bsz=96, num_updates=750, lr=2.84632e-05, gnorm=0.95, clip=10, loss_scale=128, train_wall=32, gb_free=12.3, wall=2196
2023-04-08 16:39:59 - progress_bar.py[line:272] - INFO: epoch 002:    183 / 578 loss=2.664, loss_v1=0, loss_v2=0, nll_loss=1.506, ntokens=2644.5, nsentences=96, sample_size=2644.5, sample_size_v1=0, sample_size_v2=0, ppl=2.84, wps=813.3, ups=0.31, wpb=2644.5, bsz=96, num_updates=760, lr=2.84172e-05, gnorm=0.949, clip=20, loss_scale=128, train_wall=32, gb_free=11.2, wall=2229
2023-04-08 16:40:32 - progress_bar.py[line:272] - INFO: epoch 002:    193 / 578 loss=2.655, loss_v1=0, loss_v2=0, nll_loss=1.493, ntokens=2633.1, nsentences=96, sample_size=2633.1, sample_size_v1=0, sample_size_v2=0, ppl=2.81, wps=809, ups=0.31, wpb=2633.1, bsz=96, num_updates=770, lr=2.83712e-05, gnorm=0.858, clip=0, loss_scale=128, train_wall=33, gb_free=12.6, wall=2261
2023-04-08 16:41:04 - progress_bar.py[line:272] - INFO: epoch 002:    203 / 578 loss=2.659, loss_v1=0, loss_v2=0, nll_loss=1.5, ntokens=2590.1, nsentences=96, sample_size=2590.1, sample_size_v1=0, sample_size_v2=0, ppl=2.83, wps=794.9, ups=0.31, wpb=2590.1, bsz=96, num_updates=780, lr=2.83252e-05, gnorm=0.867, clip=0, loss_scale=128, train_wall=33, gb_free=12.2, wall=2294
2023-04-08 16:41:37 - progress_bar.py[line:272] - INFO: epoch 002:    213 / 578 loss=2.658, loss_v1=0, loss_v2=0, nll_loss=1.496, ntokens=2453.4, nsentences=96, sample_size=2453.4, sample_size_v1=0, sample_size_v2=0, ppl=2.82, wps=758.5, ups=0.31, wpb=2453.4, bsz=96, num_updates=790, lr=2.82791e-05, gnorm=0.981, clip=50, loss_scale=128, train_wall=32, gb_free=12.5, wall=2326
2023-04-08 16:42:09 - progress_bar.py[line:272] - INFO: epoch 002:    223 / 578 loss=2.654, loss_v1=0, loss_v2=0, nll_loss=1.494, ntokens=2607.7, nsentences=96, sample_size=2607.7, sample_size_v1=0, sample_size_v2=0, ppl=2.82, wps=800.1, ups=0.31, wpb=2607.7, bsz=96, num_updates=800, lr=2.82331e-05, gnorm=1, clip=50, loss_scale=128, train_wall=33, gb_free=12.5, wall=2359
2023-04-08 16:42:42 - progress_bar.py[line:272] - INFO: epoch 002:    233 / 578 loss=2.629, loss_v1=0, loss_v2=0, nll_loss=1.465, ntokens=2416.3, nsentences=96, sample_size=2416.3, sample_size_v1=0, sample_size_v2=0, ppl=2.76, wps=743.1, ups=0.31, wpb=2416.3, bsz=96, num_updates=810, lr=2.81871e-05, gnorm=1.021, clip=60, loss_scale=128, train_wall=32, gb_free=12.5, wall=2391
2023-04-08 16:43:14 - progress_bar.py[line:272] - INFO: epoch 002:    243 / 578 loss=2.653, loss_v1=0, loss_v2=0, nll_loss=1.492, ntokens=2509.6, nsentences=96, sample_size=2509.6, sample_size_v1=0, sample_size_v2=0, ppl=2.81, wps=771.3, ups=0.31, wpb=2509.6, bsz=96, num_updates=820, lr=2.81411e-05, gnorm=0.971, clip=40, loss_scale=128, train_wall=33, gb_free=12.2, wall=2424
2023-04-08 16:43:47 - progress_bar.py[line:272] - INFO: epoch 002:    253 / 578 loss=2.644, loss_v1=0, loss_v2=0, nll_loss=1.481, ntokens=2553, nsentences=96, sample_size=2553, sample_size_v1=0, sample_size_v2=0, ppl=2.79, wps=787, ups=0.31, wpb=2553, bsz=96, num_updates=830, lr=2.80951e-05, gnorm=0.895, clip=10, loss_scale=128, train_wall=32, gb_free=12.2, wall=2456
2023-04-08 16:44:19 - progress_bar.py[line:272] - INFO: epoch 002:    263 / 578 loss=2.633, loss_v1=0, loss_v2=0, nll_loss=1.469, ntokens=2477.3, nsentences=96, sample_size=2477.3, sample_size_v1=0, sample_size_v2=0, ppl=2.77, wps=762.1, ups=0.31, wpb=2477.3, bsz=96, num_updates=840, lr=2.80491e-05, gnorm=0.913, clip=10, loss_scale=128, train_wall=32, gb_free=12.5, wall=2489
2023-04-08 16:44:52 - progress_bar.py[line:272] - INFO: epoch 002:    273 / 578 loss=2.631, loss_v1=0, loss_v2=0, nll_loss=1.468, ntokens=2630.6, nsentences=96, sample_size=2630.6, sample_size_v1=0, sample_size_v2=0, ppl=2.77, wps=808.4, ups=0.31, wpb=2630.6, bsz=96, num_updates=850, lr=2.80031e-05, gnorm=0.919, clip=20, loss_scale=128, train_wall=33, gb_free=12.2, wall=2521
2023-04-08 16:45:24 - progress_bar.py[line:272] - INFO: epoch 002:    283 / 578 loss=2.625, loss_v1=0, loss_v2=0, nll_loss=1.461, ntokens=2546.1, nsentences=96, sample_size=2546.1, sample_size_v1=0, sample_size_v2=0, ppl=2.75, wps=778, ups=0.31, wpb=2546.1, bsz=96, num_updates=860, lr=2.79571e-05, gnorm=0.973, clip=20, loss_scale=128, train_wall=33, gb_free=12.5, wall=2554
2023-04-08 16:45:57 - progress_bar.py[line:272] - INFO: epoch 002:    293 / 578 loss=2.629, loss_v1=0, loss_v2=0, nll_loss=1.463, ntokens=2624.1, nsentences=96, sample_size=2624.1, sample_size_v1=0, sample_size_v2=0, ppl=2.76, wps=804.4, ups=0.31, wpb=2624.1, bsz=96, num_updates=870, lr=2.7911e-05, gnorm=0.866, clip=0, loss_scale=128, train_wall=33, gb_free=11.9, wall=2587
2023-04-08 16:46:30 - progress_bar.py[line:272] - INFO: epoch 002:    303 / 578 loss=2.618, loss_v1=0, loss_v2=0, nll_loss=1.452, ntokens=2476.5, nsentences=96, sample_size=2476.5, sample_size_v1=0, sample_size_v2=0, ppl=2.74, wps=758.4, ups=0.31, wpb=2476.5, bsz=96, num_updates=880, lr=2.7865e-05, gnorm=0.943, clip=30, loss_scale=128, train_wall=33, gb_free=12.5, wall=2619
2023-04-08 16:47:02 - progress_bar.py[line:272] - INFO: epoch 002:    313 / 578 loss=2.626, loss_v1=0, loss_v2=0, nll_loss=1.459, ntokens=2673.1, nsentences=96, sample_size=2673.1, sample_size_v1=0, sample_size_v2=0, ppl=2.75, wps=817.7, ups=0.31, wpb=2673.1, bsz=96, num_updates=890, lr=2.7819e-05, gnorm=0.921, clip=10, loss_scale=128, train_wall=33, gb_free=12, wall=2652
2023-04-08 16:47:35 - progress_bar.py[line:272] - INFO: epoch 002:    323 / 578 loss=2.626, loss_v1=0, loss_v2=0, nll_loss=1.461, ntokens=2618, nsentences=96, sample_size=2618, sample_size_v1=0, sample_size_v2=0, ppl=2.75, wps=798.2, ups=0.3, wpb=2618, bsz=96, num_updates=900, lr=2.7773e-05, gnorm=0.948, clip=30, loss_scale=128, train_wall=33, gb_free=12.4, wall=2685
2023-04-08 16:48:08 - progress_bar.py[line:272] - INFO: epoch 002:    333 / 578 loss=2.596, loss_v1=0, loss_v2=0, nll_loss=1.428, ntokens=2514.4, nsentences=96, sample_size=2514.4, sample_size_v1=0, sample_size_v2=0, ppl=2.69, wps=770.5, ups=0.31, wpb=2514.4, bsz=96, num_updates=910, lr=2.7727e-05, gnorm=0.965, clip=20, loss_scale=128, train_wall=33, gb_free=12.4, wall=2718
2023-04-08 16:48:40 - progress_bar.py[line:272] - INFO: epoch 002:    343 / 578 loss=2.63, loss_v1=0, loss_v2=0, nll_loss=1.464, ntokens=2720.2, nsentences=96, sample_size=2720.2, sample_size_v1=0, sample_size_v2=0, ppl=2.76, wps=834.5, ups=0.31, wpb=2720.2, bsz=96, num_updates=920, lr=2.7681e-05, gnorm=0.897, clip=0, loss_scale=128, train_wall=33, gb_free=12.5, wall=2750
2023-04-08 16:49:13 - progress_bar.py[line:272] - INFO: epoch 002:    353 / 578 loss=2.595, loss_v1=0, loss_v2=0, nll_loss=1.428, ntokens=2572.4, nsentences=96, sample_size=2572.4, sample_size_v1=0, sample_size_v2=0, ppl=2.69, wps=792.1, ups=0.31, wpb=2572.4, bsz=96, num_updates=930, lr=2.7635e-05, gnorm=1.027, clip=60, loss_scale=128, train_wall=32, gb_free=12.5, wall=2783
2023-04-08 16:49:46 - progress_bar.py[line:272] - INFO: epoch 002:    363 / 578 loss=2.606, loss_v1=0, loss_v2=0, nll_loss=1.438, ntokens=2713.2, nsentences=96, sample_size=2713.2, sample_size_v1=0, sample_size_v2=0, ppl=2.71, wps=829.8, ups=0.31, wpb=2713.2, bsz=96, num_updates=940, lr=2.7589e-05, gnorm=0.943, clip=10, loss_scale=128, train_wall=33, gb_free=12.4, wall=2815
2023-04-08 16:50:19 - progress_bar.py[line:272] - INFO: epoch 002:    373 / 578 loss=2.624, loss_v1=0, loss_v2=0, nll_loss=1.457, ntokens=2789.7, nsentences=96, sample_size=2789.7, sample_size_v1=0, sample_size_v2=0, ppl=2.75, wps=843.6, ups=0.3, wpb=2789.7, bsz=96, num_updates=950, lr=2.75429e-05, gnorm=0.993, clip=50, loss_scale=128, train_wall=33, gb_free=12.4, wall=2848
2023-04-08 16:50:51 - progress_bar.py[line:272] - INFO: epoch 002:    383 / 578 loss=2.616, loss_v1=0, loss_v2=0, nll_loss=1.448, ntokens=2710.3, nsentences=96, sample_size=2710.3, sample_size_v1=0, sample_size_v2=0, ppl=2.73, wps=829.8, ups=0.31, wpb=2710.3, bsz=96, num_updates=960, lr=2.74969e-05, gnorm=0.985, clip=60, loss_scale=128, train_wall=33, gb_free=12.5, wall=2881
2023-04-08 16:51:24 - progress_bar.py[line:272] - INFO: epoch 002:    393 / 578 loss=2.621, loss_v1=0, loss_v2=0, nll_loss=1.453, ntokens=2548.7, nsentences=96, sample_size=2548.7, sample_size_v1=0, sample_size_v2=0, ppl=2.74, wps=779, ups=0.31, wpb=2548.7, bsz=96, num_updates=970, lr=2.74509e-05, gnorm=0.946, clip=30, loss_scale=128, train_wall=33, gb_free=12, wall=2914
2023-04-08 16:51:57 - progress_bar.py[line:272] - INFO: epoch 002:    403 / 578 loss=2.585, loss_v1=0, loss_v2=0, nll_loss=1.417, ntokens=2529.8, nsentences=96, sample_size=2529.8, sample_size_v1=0, sample_size_v2=0, ppl=2.67, wps=771.6, ups=0.31, wpb=2529.8, bsz=96, num_updates=980, lr=2.74049e-05, gnorm=0.912, clip=0, loss_scale=128, train_wall=33, gb_free=12.4, wall=2947
2023-04-08 16:52:29 - progress_bar.py[line:272] - INFO: epoch 002:    413 / 578 loss=2.603, loss_v1=0, loss_v2=0, nll_loss=1.432, ntokens=2423.5, nsentences=96, sample_size=2423.5, sample_size_v1=0, sample_size_v2=0, ppl=2.7, wps=745.3, ups=0.31, wpb=2423.5, bsz=96, num_updates=990, lr=2.73589e-05, gnorm=0.958, clip=20, loss_scale=128, train_wall=32, gb_free=12.6, wall=2979
2023-04-08 16:53:02 - progress_bar.py[line:272] - INFO: epoch 002:    423 / 578 loss=2.597, loss_v1=0, loss_v2=0, nll_loss=1.427, ntokens=2478.1, nsentences=96, sample_size=2478.1, sample_size_v1=0, sample_size_v2=0, ppl=2.69, wps=758.6, ups=0.31, wpb=2478.1, bsz=96, num_updates=1000, lr=2.73129e-05, gnorm=0.989, clip=40, loss_scale=128, train_wall=33, gb_free=12.6, wall=3012
2023-04-08 16:53:35 - progress_bar.py[line:272] - INFO: epoch 002:    433 / 578 loss=2.594, loss_v1=0, loss_v2=0, nll_loss=1.422, ntokens=2566.6, nsentences=96, sample_size=2566.6, sample_size_v1=0, sample_size_v2=0, ppl=2.68, wps=788.8, ups=0.31, wpb=2566.6, bsz=96, num_updates=1010, lr=2.72669e-05, gnorm=1.031, clip=50, loss_scale=128, train_wall=33, gb_free=12.4, wall=3044
2023-04-08 16:54:07 - progress_bar.py[line:272] - INFO: epoch 002:    443 / 578 loss=2.611, loss_v1=0, loss_v2=0, nll_loss=1.444, ntokens=2429.2, nsentences=96, sample_size=2429.2, sample_size_v1=0, sample_size_v2=0, ppl=2.72, wps=746.4, ups=0.31, wpb=2429.2, bsz=96, num_updates=1020, lr=2.72209e-05, gnorm=1.041, clip=70, loss_scale=128, train_wall=33, gb_free=12.7, wall=3077
2023-04-08 16:54:40 - progress_bar.py[line:272] - INFO: epoch 002:    453 / 578 loss=2.597, loss_v1=0, loss_v2=0, nll_loss=1.427, ntokens=2529.8, nsentences=96, sample_size=2529.8, sample_size_v1=0, sample_size_v2=0, ppl=2.69, wps=775.4, ups=0.31, wpb=2529.8, bsz=96, num_updates=1030, lr=2.71748e-05, gnorm=1.025, clip=70, loss_scale=256, train_wall=33, gb_free=12.7, wall=3109
2023-04-08 16:55:12 - progress_bar.py[line:272] - INFO: epoch 002:    463 / 578 loss=2.601, loss_v1=0, loss_v2=0, nll_loss=1.432, ntokens=2532.3, nsentences=96, sample_size=2532.3, sample_size_v1=0, sample_size_v2=0, ppl=2.7, wps=776, ups=0.31, wpb=2532.3, bsz=96, num_updates=1040, lr=2.71288e-05, gnorm=0.997, clip=40, loss_scale=256, train_wall=33, gb_free=11.7, wall=3142
2023-04-08 16:55:45 - progress_bar.py[line:272] - INFO: epoch 002:    473 / 578 loss=2.6, loss_v1=0, loss_v2=0, nll_loss=1.43, ntokens=2423.5, nsentences=96, sample_size=2423.5, sample_size_v1=0, sample_size_v2=0, ppl=2.7, wps=744.3, ups=0.31, wpb=2423.5, bsz=96, num_updates=1050, lr=2.70828e-05, gnorm=1.083, clip=90, loss_scale=256, train_wall=33, gb_free=12.3, wall=3175
2023-04-08 16:56:18 - progress_bar.py[line:272] - INFO: epoch 002:    483 / 578 loss=2.595, loss_v1=0, loss_v2=0, nll_loss=1.425, ntokens=2368.7, nsentences=96, sample_size=2368.7, sample_size_v1=0, sample_size_v2=0, ppl=2.69, wps=726.3, ups=0.31, wpb=2368.7, bsz=96, num_updates=1060, lr=2.70368e-05, gnorm=1.016, clip=60, loss_scale=256, train_wall=33, gb_free=12.6, wall=3207
2023-04-08 16:56:50 - progress_bar.py[line:272] - INFO: epoch 002:    493 / 578 loss=2.576, loss_v1=0, loss_v2=0, nll_loss=1.404, ntokens=2516.7, nsentences=96, sample_size=2516.7, sample_size_v1=0, sample_size_v2=0, ppl=2.65, wps=772, ups=0.31, wpb=2516.7, bsz=96, num_updates=1070, lr=2.69908e-05, gnorm=1.019, clip=50, loss_scale=256, train_wall=33, gb_free=12.3, wall=3240
2023-04-08 16:57:23 - progress_bar.py[line:272] - INFO: epoch 002:    503 / 578 loss=2.568, loss_v1=0, loss_v2=0, nll_loss=1.394, ntokens=2525.6, nsentences=95.6, sample_size=2525.6, sample_size_v1=0, sample_size_v2=0, ppl=2.63, wps=771.9, ups=0.31, wpb=2525.6, bsz=95.6, num_updates=1080, lr=2.69448e-05, gnorm=1.079, clip=80, loss_scale=256, train_wall=33, gb_free=12.5, wall=3273
2023-04-08 16:57:56 - progress_bar.py[line:272] - INFO: epoch 002:    513 / 578 loss=2.583, loss_v1=0, loss_v2=0, nll_loss=1.41, ntokens=2546.3, nsentences=96, sample_size=2546.3, sample_size_v1=0, sample_size_v2=0, ppl=2.66, wps=778.8, ups=0.31, wpb=2546.3, bsz=96, num_updates=1090, lr=2.68988e-05, gnorm=1.016, clip=40, loss_scale=256, train_wall=33, gb_free=12.7, wall=3305
2023-04-08 16:58:28 - progress_bar.py[line:272] - INFO: epoch 002:    523 / 578 loss=2.558, loss_v1=0, loss_v2=0, nll_loss=1.382, ntokens=2700.2, nsentences=96, sample_size=2700.2, sample_size_v1=0, sample_size_v2=0, ppl=2.61, wps=824.4, ups=0.31, wpb=2700.2, bsz=96, num_updates=1100, lr=2.68528e-05, gnorm=0.965, clip=40, loss_scale=256, train_wall=33, gb_free=12.6, wall=3338
2023-04-08 16:59:01 - progress_bar.py[line:272] - INFO: epoch 002:    533 / 578 loss=2.579, loss_v1=0, loss_v2=0, nll_loss=1.403, ntokens=2559.7, nsentences=96, sample_size=2559.7, sample_size_v1=0, sample_size_v2=0, ppl=2.64, wps=786.7, ups=0.31, wpb=2559.7, bsz=96, num_updates=1110, lr=2.68067e-05, gnorm=0.987, clip=40, loss_scale=256, train_wall=33, gb_free=12.4, wall=3371
2023-04-08 16:59:34 - progress_bar.py[line:272] - INFO: epoch 002:    543 / 578 loss=2.561, loss_v1=0, loss_v2=0, nll_loss=1.387, ntokens=2506.1, nsentences=96, sample_size=2506.1, sample_size_v1=0, sample_size_v2=0, ppl=2.62, wps=767.8, ups=0.31, wpb=2506.1, bsz=96, num_updates=1120, lr=2.67607e-05, gnorm=1.051, clip=60, loss_scale=256, train_wall=33, gb_free=12.6, wall=3403
2023-04-08 17:00:07 - progress_bar.py[line:272] - INFO: epoch 002:    553 / 578 loss=2.57, loss_v1=0, loss_v2=0, nll_loss=1.397, ntokens=2569.7, nsentences=96, sample_size=2569.7, sample_size_v1=0, sample_size_v2=0, ppl=2.63, wps=776.8, ups=0.3, wpb=2569.7, bsz=96, num_updates=1130, lr=2.67147e-05, gnorm=1.042, clip=70, loss_scale=256, train_wall=33, gb_free=12.6, wall=3436
2023-04-08 17:00:40 - progress_bar.py[line:272] - INFO: epoch 002:    563 / 578 loss=2.56, loss_v1=0, loss_v2=0, nll_loss=1.385, ntokens=2657.9, nsentences=96, sample_size=2657.9, sample_size_v1=0, sample_size_v2=0, ppl=2.61, wps=806.9, ups=0.3, wpb=2657.9, bsz=96, num_updates=1140, lr=2.66687e-05, gnorm=1.01, clip=60, loss_scale=256, train_wall=33, gb_free=12.5, wall=3469
2023-04-08 17:01:12 - progress_bar.py[line:272] - INFO: epoch 002:    573 / 578 loss=2.568, loss_v1=0, loss_v2=0, nll_loss=1.395, ntokens=2565.8, nsentences=96, sample_size=2565.8, sample_size_v1=0, sample_size_v2=0, ppl=2.63, wps=782.8, ups=0.31, wpb=2565.8, bsz=96, num_updates=1150, lr=2.66227e-05, gnorm=1.021, clip=50, loss_scale=256, train_wall=33, gb_free=12.4, wall=3502
2023-04-08 17:01:26 - train.py[line:332] - INFO: end of epoch 2 (average epoch stats below)
2023-04-08 17:01:26 - progress_bar.py[line:282] - INFO: epoch 002 | loss 2.629 | loss_v1 0 | loss_v2 0 | nll_loss 1.465 | ntokens 2520.18 | nsentences 95.848 | sample_size 2520.18 | sample_size_v1 0 | sample_size_v2 0 | ppl 2.76 | wps 783.6 | ups 0.31 | wpb 2520.2 | bsz 95.8 | num_updates 1155 | lr 2.65997e-05 | gnorm 0.991 | clip 39.1 | loss_scale 256 | train_wall 1855 | gb_free 13.1 | wall 3516
2023-04-08 17:01:26 - trainer.py[line:639] - INFO: loading train data for epoch 3
local datafile ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 0 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 1 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 0 finished initializing row_count and line_idx-to-offset mapping
file ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 0 row count 27700 total row count 55400
slice_id 0 seek offset 0
2023-04-08 17:01:28 - trainer.py[line:703] - INFO: begin training epoch 3
2023-04-08 17:01:28 - train.py[line:305] - INFO: Start iterating over samples
local datafile ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 1 finished initializing row_count and line_idx-to-offset mapping
file ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 1 row count 27700 total row count 55400
slice_id 1 seek offset 27700
2023-04-08 17:01:44 - progress_bar.py[line:272] - INFO: epoch 003:      5 / 578 loss=2.573, loss_v1=0, loss_v2=0, nll_loss=1.397, ntokens=2353.1, nsentences=87.6, sample_size=2353.1, sample_size_v1=0, sample_size_v2=0, ppl=2.63, wps=739.1, ups=0.31, wpb=2353.1, bsz=87.6, num_updates=1160, lr=2.65767e-05, gnorm=1.321, clip=60, loss_scale=256, train_wall=30, gb_free=11.8, wall=3534
2023-04-08 17:02:16 - progress_bar.py[line:272] - INFO: epoch 003:     15 / 578 loss=2.557, loss_v1=0, loss_v2=0, nll_loss=1.38, ntokens=2393.3, nsentences=96, sample_size=2393.3, sample_size_v1=0, sample_size_v2=0, ppl=2.6, wps=743.5, ups=0.31, wpb=2393.3, bsz=96, num_updates=1170, lr=2.65307e-05, gnorm=1.174, clip=90, loss_scale=256, train_wall=32, gb_free=12.3, wall=3566
2023-04-08 17:02:49 - progress_bar.py[line:272] - INFO: epoch 003:     25 / 578 loss=2.549, loss_v1=0, loss_v2=0, nll_loss=1.374, ntokens=2390.4, nsentences=96, sample_size=2390.4, sample_size_v1=0, sample_size_v2=0, ppl=2.59, wps=741.7, ups=0.31, wpb=2390.4, bsz=96, num_updates=1180, lr=2.64847e-05, gnorm=1.115, clip=80, loss_scale=256, train_wall=32, gb_free=12.3, wall=3598
2023-04-08 17:03:21 - progress_bar.py[line:272] - INFO: epoch 003:     35 / 578 loss=2.572, loss_v1=0, loss_v2=0, nll_loss=1.396, ntokens=2235, nsentences=96, sample_size=2235, sample_size_v1=0, sample_size_v2=0, ppl=2.63, wps=695.8, ups=0.31, wpb=2235, bsz=96, num_updates=1190, lr=2.64387e-05, gnorm=1.319, clip=100, loss_scale=256, train_wall=32, gb_free=12.5, wall=3630
2023-04-08 17:03:53 - progress_bar.py[line:272] - INFO: epoch 003:     45 / 578 loss=2.506, loss_v1=0, loss_v2=0, nll_loss=1.324, ntokens=2216.1, nsentences=96, sample_size=2216.1, sample_size_v1=0, sample_size_v2=0, ppl=2.5, wps=683.5, ups=0.31, wpb=2216.1, bsz=96, num_updates=1200, lr=2.63926e-05, gnorm=1.145, clip=100, loss_scale=256, train_wall=32, gb_free=11.2, wall=3663
2023-04-08 17:04:26 - progress_bar.py[line:272] - INFO: epoch 003:     55 / 578 loss=2.574, loss_v1=0, loss_v2=0, nll_loss=1.399, ntokens=2396.9, nsentences=96, sample_size=2396.9, sample_size_v1=0, sample_size_v2=0, ppl=2.64, wps=737.9, ups=0.31, wpb=2396.9, bsz=96, num_updates=1210, lr=2.63466e-05, gnorm=1.016, clip=50, loss_scale=256, train_wall=32, gb_free=11.8, wall=3695
2023-04-08 17:04:58 - progress_bar.py[line:272] - INFO: epoch 003:     65 / 578 loss=2.561, loss_v1=0, loss_v2=0, nll_loss=1.384, ntokens=2276.9, nsentences=96, sample_size=2276.9, sample_size_v1=0, sample_size_v2=0, ppl=2.61, wps=699.5, ups=0.31, wpb=2276.9, bsz=96, num_updates=1220, lr=2.63006e-05, gnorm=1.136, clip=90, loss_scale=256, train_wall=33, gb_free=11.5, wall=3728
2023-04-08 17:05:31 - progress_bar.py[line:272] - INFO: epoch 003:     75 / 578 loss=2.59, loss_v1=0, loss_v2=0, nll_loss=1.419, ntokens=2423.2, nsentences=96, sample_size=2423.2, sample_size_v1=0, sample_size_v2=0, ppl=2.67, wps=743.6, ups=0.31, wpb=2423.2, bsz=96, num_updates=1230, lr=2.62546e-05, gnorm=1.04, clip=70, loss_scale=256, train_wall=33, gb_free=11.6, wall=3761
2023-04-08 17:06:03 - progress_bar.py[line:272] - INFO: epoch 003:     85 / 578 loss=2.581, loss_v1=0, loss_v2=0, nll_loss=1.405, ntokens=2518.1, nsentences=96, sample_size=2518.1, sample_size_v1=0, sample_size_v2=0, ppl=2.65, wps=774.3, ups=0.31, wpb=2518.1, bsz=96, num_updates=1240, lr=2.62086e-05, gnorm=1.031, clip=50, loss_scale=256, train_wall=32, gb_free=12.3, wall=3793
2023-04-08 17:06:36 - progress_bar.py[line:272] - INFO: epoch 003:     95 / 578 loss=2.557, loss_v1=0, loss_v2=0, nll_loss=1.381, ntokens=2481.6, nsentences=96, sample_size=2481.6, sample_size_v1=0, sample_size_v2=0, ppl=2.61, wps=766.9, ups=0.31, wpb=2481.6, bsz=96, num_updates=1250, lr=2.61626e-05, gnorm=0.949, clip=30, loss_scale=256, train_wall=32, gb_free=12, wall=3825
2023-04-08 17:07:08 - progress_bar.py[line:272] - INFO: epoch 003:    105 / 578 loss=2.559, loss_v1=0, loss_v2=0, nll_loss=1.383, ntokens=2443.9, nsentences=96, sample_size=2443.9, sample_size_v1=0, sample_size_v2=0, ppl=2.61, wps=753.7, ups=0.31, wpb=2443.9, bsz=96, num_updates=1260, lr=2.61166e-05, gnorm=0.985, clip=60, loss_scale=256, train_wall=32, gb_free=12.3, wall=3858
2023-04-08 17:07:41 - progress_bar.py[line:272] - INFO: epoch 003:    115 / 578 loss=2.568, loss_v1=0, loss_v2=0, nll_loss=1.389, ntokens=2335.1, nsentences=96, sample_size=2335.1, sample_size_v1=0, sample_size_v2=0, ppl=2.62, wps=715.4, ups=0.31, wpb=2335.1, bsz=96, num_updates=1270, lr=2.60706e-05, gnorm=1.065, clip=70, loss_scale=256, train_wall=33, gb_free=12, wall=3890
2023-04-08 17:08:13 - progress_bar.py[line:272] - INFO: epoch 003:    125 / 578 loss=2.561, loss_v1=0, loss_v2=0, nll_loss=1.386, ntokens=2384.1, nsentences=96, sample_size=2384.1, sample_size_v1=0, sample_size_v2=0, ppl=2.61, wps=735.3, ups=0.31, wpb=2384.1, bsz=96, num_updates=1280, lr=2.60245e-05, gnorm=1.109, clip=90, loss_scale=256, train_wall=32, gb_free=12, wall=3923
2023-04-08 17:08:46 - progress_bar.py[line:272] - INFO: epoch 003:    135 / 578 loss=2.566, loss_v1=0, loss_v2=0, nll_loss=1.392, ntokens=2448.6, nsentences=96, sample_size=2448.6, sample_size_v1=0, sample_size_v2=0, ppl=2.62, wps=753.1, ups=0.31, wpb=2448.6, bsz=96, num_updates=1290, lr=2.59785e-05, gnorm=1.135, clip=90, loss_scale=256, train_wall=32, gb_free=11.9, wall=3955
2023-04-08 17:09:18 - progress_bar.py[line:272] - INFO: epoch 003:    145 / 578 loss=2.581, loss_v1=0, loss_v2=0, nll_loss=1.406, ntokens=2529.3, nsentences=96, sample_size=2529.3, sample_size_v1=0, sample_size_v2=0, ppl=2.65, wps=774.1, ups=0.31, wpb=2529.3, bsz=96, num_updates=1300, lr=2.59325e-05, gnorm=1.06, clip=70, loss_scale=256, train_wall=33, gb_free=12.4, wall=3988
2023-04-08 17:09:51 - progress_bar.py[line:272] - INFO: epoch 003:    155 / 578 loss=2.574, loss_v1=0, loss_v2=0, nll_loss=1.398, ntokens=2647.9, nsentences=96, sample_size=2647.9, sample_size_v1=0, sample_size_v2=0, ppl=2.63, wps=816.3, ups=0.31, wpb=2647.9, bsz=96, num_updates=1310, lr=2.58865e-05, gnorm=1.057, clip=60, loss_scale=256, train_wall=32, gb_free=12.4, wall=4021
2023-04-08 17:10:23 - progress_bar.py[line:272] - INFO: epoch 003:    165 / 578 loss=2.575, loss_v1=0, loss_v2=0, nll_loss=1.402, ntokens=2681.7, nsentences=96, sample_size=2681.7, sample_size_v1=0, sample_size_v2=0, ppl=2.64, wps=823.1, ups=0.31, wpb=2681.7, bsz=96, num_updates=1320, lr=2.58405e-05, gnorm=0.982, clip=30, loss_scale=256, train_wall=33, gb_free=12.1, wall=4053
2023-04-08 17:10:56 - progress_bar.py[line:272] - INFO: epoch 003:    175 / 578 loss=2.578, loss_v1=0, loss_v2=0, nll_loss=1.406, ntokens=2604.9, nsentences=96, sample_size=2604.9, sample_size_v1=0, sample_size_v2=0, ppl=2.65, wps=800.4, ups=0.31, wpb=2604.9, bsz=96, num_updates=1330, lr=2.57945e-05, gnorm=1.015, clip=60, loss_scale=256, train_wall=33, gb_free=12.3, wall=4086
2023-04-08 17:11:28 - progress_bar.py[line:272] - INFO: epoch 003:    185 / 578 loss=2.564, loss_v1=0, loss_v2=0, nll_loss=1.388, ntokens=2637, nsentences=96, sample_size=2637, sample_size_v1=0, sample_size_v2=0, ppl=2.62, wps=813.2, ups=0.31, wpb=2637, bsz=96, num_updates=1340, lr=2.57485e-05, gnorm=0.988, clip=50, loss_scale=256, train_wall=32, gb_free=12.2, wall=4118
2023-04-08 17:12:01 - progress_bar.py[line:272] - INFO: epoch 003:    195 / 578 loss=2.56, loss_v1=0, loss_v2=0, nll_loss=1.383, ntokens=2610.4, nsentences=96, sample_size=2610.4, sample_size_v1=0, sample_size_v2=0, ppl=2.61, wps=803.3, ups=0.31, wpb=2610.4, bsz=96, num_updates=1350, lr=2.57025e-05, gnorm=1.037, clip=50, loss_scale=256, train_wall=32, gb_free=12.4, wall=4151
2023-04-08 17:12:34 - progress_bar.py[line:272] - INFO: epoch 003:    205 / 578 loss=2.563, loss_v1=0, loss_v2=0, nll_loss=1.389, ntokens=2579.9, nsentences=96, sample_size=2579.9, sample_size_v1=0, sample_size_v2=0, ppl=2.62, wps=791.6, ups=0.31, wpb=2579.9, bsz=96, num_updates=1360, lr=2.56564e-05, gnorm=1.095, clip=60, loss_scale=256, train_wall=33, gb_free=12.6, wall=4183
2023-04-08 17:13:06 - progress_bar.py[line:272] - INFO: epoch 003:    215 / 578 loss=2.585, loss_v1=0, loss_v2=0, nll_loss=1.412, ntokens=2467, nsentences=96, sample_size=2467, sample_size_v1=0, sample_size_v2=0, ppl=2.66, wps=760.1, ups=0.31, wpb=2467, bsz=96, num_updates=1370, lr=2.56104e-05, gnorm=1.093, clip=70, loss_scale=256, train_wall=32, gb_free=12.4, wall=4216
2023-04-08 17:13:39 - progress_bar.py[line:272] - INFO: epoch 003:    225 / 578 loss=2.544, loss_v1=0, loss_v2=0, nll_loss=1.367, ntokens=2600.2, nsentences=96, sample_size=2600.2, sample_size_v1=0, sample_size_v2=0, ppl=2.58, wps=794.4, ups=0.31, wpb=2600.2, bsz=96, num_updates=1380, lr=2.55644e-05, gnorm=1.1, clip=70, loss_scale=256, train_wall=33, gb_free=11.9, wall=4248
2023-04-08 17:14:11 - progress_bar.py[line:272] - INFO: epoch 003:    235 / 578 loss=2.557, loss_v1=0, loss_v2=0, nll_loss=1.379, ntokens=2432.2, nsentences=95.6, sample_size=2432.2, sample_size_v1=0, sample_size_v2=0, ppl=2.6, wps=752.7, ups=0.31, wpb=2432.2, bsz=95.6, num_updates=1390, lr=2.55184e-05, gnorm=1.114, clip=90, loss_scale=256, train_wall=32, gb_free=12.6, wall=4281
2023-04-08 17:14:43 - progress_bar.py[line:272] - INFO: epoch 003:    245 / 578 loss=2.563, loss_v1=0, loss_v2=0, nll_loss=1.388, ntokens=2464.3, nsentences=96, sample_size=2464.3, sample_size_v1=0, sample_size_v2=0, ppl=2.62, wps=759.6, ups=0.31, wpb=2464.3, bsz=96, num_updates=1400, lr=2.54724e-05, gnorm=1.096, clip=90, loss_scale=256, train_wall=32, gb_free=12.6, wall=4313
2023-04-08 17:15:16 - progress_bar.py[line:272] - INFO: epoch 003:    255 / 578 loss=2.566, loss_v1=0, loss_v2=0, nll_loss=1.391, ntokens=2561.5, nsentences=96, sample_size=2561.5, sample_size_v1=0, sample_size_v2=0, ppl=2.62, wps=787.8, ups=0.31, wpb=2561.5, bsz=96, num_updates=1410, lr=2.54264e-05, gnorm=1.052, clip=90, loss_scale=256, train_wall=32, gb_free=12.5, wall=4346
2023-04-08 17:15:49 - progress_bar.py[line:272] - INFO: epoch 003:    265 / 578 loss=2.553, loss_v1=0, loss_v2=0, nll_loss=1.376, ntokens=2527.2, nsentences=96, sample_size=2527.2, sample_size_v1=0, sample_size_v2=0, ppl=2.6, wps=777.4, ups=0.31, wpb=2527.2, bsz=96, num_updates=1420, lr=2.53804e-05, gnorm=1.047, clip=70, loss_scale=256, train_wall=32, gb_free=12.3, wall=4378
2023-04-08 17:16:21 - progress_bar.py[line:272] - INFO: epoch 003:    275 / 578 loss=2.552, loss_v1=0, loss_v2=0, nll_loss=1.374, ntokens=2603.6, nsentences=96, sample_size=2603.6, sample_size_v1=0, sample_size_v2=0, ppl=2.59, wps=800.5, ups=0.31, wpb=2603.6, bsz=96, num_updates=1430, lr=2.53344e-05, gnorm=1.143, clip=100, loss_scale=256, train_wall=32, gb_free=12.5, wall=4411
2023-04-08 17:16:54 - progress_bar.py[line:272] - INFO: epoch 003:    285 / 578 loss=2.546, loss_v1=0, loss_v2=0, nll_loss=1.371, ntokens=2528.1, nsentences=96, sample_size=2528.1, sample_size_v1=0, sample_size_v2=0, ppl=2.59, wps=774.3, ups=0.31, wpb=2528.1, bsz=96, num_updates=1440, lr=2.52883e-05, gnorm=1.127, clip=90, loss_scale=256, train_wall=33, gb_free=12.3, wall=4443
2023-04-08 17:17:26 - progress_bar.py[line:272] - INFO: epoch 003:    295 / 578 loss=2.559, loss_v1=0, loss_v2=0, nll_loss=1.38, ntokens=2597.9, nsentences=96, sample_size=2597.9, sample_size_v1=0, sample_size_v2=0, ppl=2.6, wps=792.4, ups=0.31, wpb=2597.9, bsz=96, num_updates=1450, lr=2.52423e-05, gnorm=1.105, clip=90, loss_scale=256, train_wall=33, gb_free=12.3, wall=4476
2023-04-08 17:17:59 - progress_bar.py[line:272] - INFO: epoch 003:    305 / 578 loss=2.546, loss_v1=0, loss_v2=0, nll_loss=1.37, ntokens=2551.7, nsentences=96, sample_size=2551.7, sample_size_v1=0, sample_size_v2=0, ppl=2.58, wps=778.1, ups=0.3, wpb=2551.7, bsz=96, num_updates=1460, lr=2.51963e-05, gnorm=1.164, clip=100, loss_scale=256, train_wall=33, gb_free=12, wall=4509
2023-04-08 17:18:32 - progress_bar.py[line:272] - INFO: epoch 003:    315 / 578 loss=2.553, loss_v1=0, loss_v2=0, nll_loss=1.373, ntokens=2644.8, nsentences=96, sample_size=2644.8, sample_size_v1=0, sample_size_v2=0, ppl=2.59, wps=812.7, ups=0.31, wpb=2644.8, bsz=96, num_updates=1470, lr=2.51503e-05, gnorm=1.046, clip=60, loss_scale=256, train_wall=33, gb_free=12.1, wall=4541
2023-04-08 17:19:05 - progress_bar.py[line:272] - INFO: epoch 003:    325 / 578 loss=2.549, loss_v1=0, loss_v2=0, nll_loss=1.372, ntokens=2580.4, nsentences=96, sample_size=2580.4, sample_size_v1=0, sample_size_v2=0, ppl=2.59, wps=787, ups=0.3, wpb=2580.4, bsz=96, num_updates=1480, lr=2.51043e-05, gnorm=1.08, clip=100, loss_scale=256, train_wall=33, gb_free=12.7, wall=4574
2023-04-08 17:19:37 - progress_bar.py[line:272] - INFO: epoch 003:    335 / 578 loss=2.529, loss_v1=0, loss_v2=0, nll_loss=1.35, ntokens=2573.7, nsentences=96, sample_size=2573.7, sample_size_v1=0, sample_size_v2=0, ppl=2.55, wps=786.2, ups=0.31, wpb=2573.7, bsz=96, num_updates=1490, lr=2.50583e-05, gnorm=1.068, clip=90, loss_scale=256, train_wall=33, gb_free=12.5, wall=4607
2023-04-08 17:20:10 - progress_bar.py[line:272] - INFO: epoch 003:    345 / 578 loss=2.55, loss_v1=0, loss_v2=0, nll_loss=1.372, ntokens=2706.2, nsentences=96, sample_size=2706.2, sample_size_v1=0, sample_size_v2=0, ppl=2.59, wps=828.3, ups=0.31, wpb=2706.2, bsz=96, num_updates=1500, lr=2.50123e-05, gnorm=1.051, clip=80, loss_scale=256, train_wall=33, gb_free=12.6, wall=4640
2023-04-08 17:20:43 - progress_bar.py[line:272] - INFO: epoch 003:    355 / 578 loss=2.526, loss_v1=0, loss_v2=0, nll_loss=1.346, ntokens=2572.3, nsentences=96, sample_size=2572.3, sample_size_v1=0, sample_size_v2=0, ppl=2.54, wps=787.9, ups=0.31, wpb=2572.3, bsz=96, num_updates=1510, lr=2.49663e-05, gnorm=1.103, clip=90, loss_scale=256, train_wall=33, gb_free=12.6, wall=4672
2023-04-08 17:21:15 - progress_bar.py[line:272] - INFO: epoch 003:    365 / 578 loss=2.545, loss_v1=0, loss_v2=0, nll_loss=1.368, ntokens=2763.7, nsentences=96, sample_size=2763.7, sample_size_v1=0, sample_size_v2=0, ppl=2.58, wps=844.3, ups=0.31, wpb=2763.7, bsz=96, num_updates=1520, lr=2.49202e-05, gnorm=1.046, clip=70, loss_scale=256, train_wall=33, gb_free=12.4, wall=4705
2023-04-08 17:21:48 - progress_bar.py[line:272] - INFO: epoch 003:    375 / 578 loss=2.558, loss_v1=0, loss_v2=0, nll_loss=1.381, ntokens=2750.6, nsentences=96, sample_size=2750.6, sample_size_v1=0, sample_size_v2=0, ppl=2.6, wps=835.2, ups=0.3, wpb=2750.6, bsz=96, num_updates=1530, lr=2.48742e-05, gnorm=1.093, clip=90, loss_scale=256, train_wall=33, gb_free=12.7, wall=4738
2023-04-08 17:22:21 - progress_bar.py[line:272] - INFO: epoch 003:    385 / 578 loss=2.546, loss_v1=0, loss_v2=0, nll_loss=1.366, ntokens=2665.2, nsentences=96, sample_size=2665.2, sample_size_v1=0, sample_size_v2=0, ppl=2.58, wps=814.2, ups=0.31, wpb=2665.2, bsz=96, num_updates=1540, lr=2.48282e-05, gnorm=1.064, clip=80, loss_scale=512, train_wall=33, gb_free=12.4, wall=4771
2023-04-08 17:22:34 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 256.0
2023-04-08 17:22:57 - progress_bar.py[line:272] - INFO: epoch 003:    396 / 578 loss=2.543, loss_v1=0, loss_v2=0, nll_loss=1.366, ntokens=2598.7, nsentences=96, sample_size=2598.7, sample_size_v1=0, sample_size_v2=0, ppl=2.58, wps=722, ups=0.28, wpb=2598.7, bsz=96, num_updates=1550, lr=2.47822e-05, gnorm=1.084, clip=100, loss_scale=256, train_wall=36, gb_free=12.1, wall=4807
2023-04-08 17:23:30 - progress_bar.py[line:272] - INFO: epoch 003:    406 / 578 loss=2.533, loss_v1=0, loss_v2=0, nll_loss=1.355, ntokens=2456, nsentences=96, sample_size=2456, sample_size_v1=0, sample_size_v2=0, ppl=2.56, wps=751.5, ups=0.31, wpb=2456, bsz=96, num_updates=1560, lr=2.47362e-05, gnorm=1.135, clip=80, loss_scale=256, train_wall=33, gb_free=12, wall=4839
2023-04-08 17:24:03 - progress_bar.py[line:272] - INFO: epoch 003:    416 / 578 loss=2.544, loss_v1=0, loss_v2=0, nll_loss=1.363, ntokens=2480.3, nsentences=96, sample_size=2480.3, sample_size_v1=0, sample_size_v2=0, ppl=2.57, wps=757.5, ups=0.31, wpb=2480.3, bsz=96, num_updates=1570, lr=2.46902e-05, gnorm=1.111, clip=100, loss_scale=256, train_wall=33, gb_free=12.3, wall=4872
2023-04-08 17:24:35 - progress_bar.py[line:272] - INFO: epoch 003:    426 / 578 loss=2.523, loss_v1=0, loss_v2=0, nll_loss=1.342, ntokens=2494.2, nsentences=96, sample_size=2494.2, sample_size_v1=0, sample_size_v2=0, ppl=2.54, wps=765.9, ups=0.31, wpb=2494.2, bsz=96, num_updates=1580, lr=2.46442e-05, gnorm=1.093, clip=70, loss_scale=256, train_wall=33, gb_free=12.3, wall=4905
2023-04-08 17:25:08 - progress_bar.py[line:272] - INFO: epoch 003:    436 / 578 loss=2.544, loss_v1=0, loss_v2=0, nll_loss=1.366, ntokens=2506.7, nsentences=96, sample_size=2506.7, sample_size_v1=0, sample_size_v2=0, ppl=2.58, wps=773.2, ups=0.31, wpb=2506.7, bsz=96, num_updates=1590, lr=2.45982e-05, gnorm=1.126, clip=90, loss_scale=256, train_wall=32, gb_free=12.5, wall=4937
2023-04-08 17:25:40 - progress_bar.py[line:272] - INFO: epoch 003:    446 / 578 loss=2.554, loss_v1=0, loss_v2=0, nll_loss=1.375, ntokens=2450.9, nsentences=96, sample_size=2450.9, sample_size_v1=0, sample_size_v2=0, ppl=2.59, wps=749.6, ups=0.31, wpb=2450.9, bsz=96, num_updates=1600, lr=2.45521e-05, gnorm=1.181, clip=90, loss_scale=256, train_wall=33, gb_free=12.2, wall=4970
2023-04-08 17:26:13 - progress_bar.py[line:272] - INFO: epoch 003:    456 / 578 loss=2.53, loss_v1=0, loss_v2=0, nll_loss=1.352, ntokens=2531.4, nsentences=96, sample_size=2531.4, sample_size_v1=0, sample_size_v2=0, ppl=2.55, wps=777.5, ups=0.31, wpb=2531.4, bsz=96, num_updates=1610, lr=2.45061e-05, gnorm=1.109, clip=90, loss_scale=256, train_wall=33, gb_free=12.7, wall=5002
2023-04-08 17:26:45 - progress_bar.py[line:272] - INFO: epoch 003:    466 / 578 loss=2.547, loss_v1=0, loss_v2=0, nll_loss=1.368, ntokens=2527.9, nsentences=96, sample_size=2527.9, sample_size_v1=0, sample_size_v2=0, ppl=2.58, wps=774.9, ups=0.31, wpb=2527.9, bsz=96, num_updates=1620, lr=2.44601e-05, gnorm=1.186, clip=100, loss_scale=256, train_wall=33, gb_free=12.4, wall=5035
2023-04-08 17:27:18 - progress_bar.py[line:272] - INFO: epoch 003:    476 / 578 loss=2.551, loss_v1=0, loss_v2=0, nll_loss=1.373, ntokens=2361.2, nsentences=96, sample_size=2361.2, sample_size_v1=0, sample_size_v2=0, ppl=2.59, wps=725.7, ups=0.31, wpb=2361.2, bsz=96, num_updates=1630, lr=2.44141e-05, gnorm=1.159, clip=100, loss_scale=256, train_wall=33, gb_free=12.4, wall=5068
2023-04-08 17:27:51 - progress_bar.py[line:272] - INFO: epoch 003:    486 / 578 loss=2.526, loss_v1=0, loss_v2=0, nll_loss=1.346, ntokens=2398.1, nsentences=96, sample_size=2398.1, sample_size_v1=0, sample_size_v2=0, ppl=2.54, wps=736.6, ups=0.31, wpb=2398.1, bsz=96, num_updates=1640, lr=2.43681e-05, gnorm=1.178, clip=100, loss_scale=256, train_wall=33, gb_free=12.5, wall=5100
2023-04-08 17:28:23 - progress_bar.py[line:272] - INFO: epoch 003:    496 / 578 loss=2.518, loss_v1=0, loss_v2=0, nll_loss=1.336, ntokens=2565.9, nsentences=96, sample_size=2565.9, sample_size_v1=0, sample_size_v2=0, ppl=2.52, wps=784.7, ups=0.31, wpb=2565.9, bsz=96, num_updates=1650, lr=2.43221e-05, gnorm=1.139, clip=100, loss_scale=256, train_wall=33, gb_free=12.3, wall=5133
2023-04-08 17:28:56 - progress_bar.py[line:272] - INFO: epoch 003:    506 / 578 loss=2.517, loss_v1=0, loss_v2=0, nll_loss=1.338, ntokens=2521.1, nsentences=96, sample_size=2521.1, sample_size_v1=0, sample_size_v2=0, ppl=2.53, wps=771, ups=0.31, wpb=2521.1, bsz=96, num_updates=1660, lr=2.42761e-05, gnorm=1.217, clip=100, loss_scale=256, train_wall=33, gb_free=12.5, wall=5166
2023-04-08 17:29:29 - progress_bar.py[line:272] - INFO: epoch 003:    516 / 578 loss=2.525, loss_v1=0, loss_v2=0, nll_loss=1.341, ntokens=2627.3, nsentences=96, sample_size=2627.3, sample_size_v1=0, sample_size_v2=0, ppl=2.53, wps=804.2, ups=0.31, wpb=2627.3, bsz=96, num_updates=1670, lr=2.42301e-05, gnorm=1.165, clip=100, loss_scale=256, train_wall=33, gb_free=12.3, wall=5198
2023-04-08 17:30:01 - progress_bar.py[line:272] - INFO: epoch 003:    526 / 578 loss=2.515, loss_v1=0, loss_v2=0, nll_loss=1.335, ntokens=2612, nsentences=96, sample_size=2612, sample_size_v1=0, sample_size_v2=0, ppl=2.52, wps=798.9, ups=0.31, wpb=2612, bsz=96, num_updates=1680, lr=2.4184e-05, gnorm=1.113, clip=80, loss_scale=256, train_wall=33, gb_free=12.5, wall=5231
2023-04-08 17:30:34 - progress_bar.py[line:272] - INFO: epoch 003:    536 / 578 loss=2.515, loss_v1=0, loss_v2=0, nll_loss=1.332, ntokens=2536.4, nsentences=96, sample_size=2536.4, sample_size_v1=0, sample_size_v2=0, ppl=2.52, wps=779.4, ups=0.31, wpb=2536.4, bsz=96, num_updates=1690, lr=2.4138e-05, gnorm=1.171, clip=100, loss_scale=256, train_wall=33, gb_free=12.3, wall=5263
2023-04-08 17:31:07 - progress_bar.py[line:272] - INFO: epoch 003:    546 / 578 loss=2.524, loss_v1=0, loss_v2=0, nll_loss=1.341, ntokens=2511.8, nsentences=96, sample_size=2511.8, sample_size_v1=0, sample_size_v2=0, ppl=2.53, wps=765.6, ups=0.3, wpb=2511.8, bsz=96, num_updates=1700, lr=2.4092e-05, gnorm=1.137, clip=90, loss_scale=256, train_wall=33, gb_free=12.6, wall=5296
2023-04-08 17:31:40 - progress_bar.py[line:272] - INFO: epoch 003:    556 / 578 loss=2.509, loss_v1=0, loss_v2=0, nll_loss=1.328, ntokens=2654.8, nsentences=96, sample_size=2654.8, sample_size_v1=0, sample_size_v2=0, ppl=2.51, wps=798.3, ups=0.3, wpb=2654.8, bsz=96, num_updates=1710, lr=2.4046e-05, gnorm=1.151, clip=100, loss_scale=256, train_wall=33, gb_free=12.6, wall=5330
2023-04-08 17:32:13 - progress_bar.py[line:272] - INFO: epoch 003:    566 / 578 loss=2.511, loss_v1=0, loss_v2=0, nll_loss=1.328, ntokens=2638.7, nsentences=96, sample_size=2638.7, sample_size_v1=0, sample_size_v2=0, ppl=2.51, wps=801.4, ups=0.3, wpb=2638.7, bsz=96, num_updates=1720, lr=2.4e-05, gnorm=1.091, clip=70, loss_scale=256, train_wall=33, gb_free=12, wall=5362
2023-04-08 17:32:46 - progress_bar.py[line:272] - INFO: epoch 003:    576 / 578 loss=2.525, loss_v1=0, loss_v2=0, nll_loss=1.345, ntokens=2591.6, nsentences=96, sample_size=2591.6, sample_size_v1=0, sample_size_v2=0, ppl=2.54, wps=787, ups=0.3, wpb=2591.6, bsz=96, num_updates=1730, lr=2.3954e-05, gnorm=1.128, clip=80, loss_scale=256, train_wall=33, gb_free=12.5, wall=5395
2023-04-08 17:32:50 - train.py[line:332] - INFO: end of epoch 3 (average epoch stats below)
2023-04-08 17:32:50 - progress_bar.py[line:282] - INFO: epoch 003 | loss 2.549 | loss_v1 0 | loss_v2 0 | nll_loss 1.371 | ntokens 2520.46 | nsentences 95.847 | sample_size 2520.46 | sample_size_v1 0 | sample_size_v2 0 | ppl 2.59 | wps 772.1 | ups 0.31 | wpb 2520.5 | bsz 95.8 | num_updates 1732 | lr 2.39448e-05 | gnorm 1.104 | clip 80.8 | loss_scale 256 | train_wall 1879 | gb_free 13.1 | wall 5399
2023-04-08 17:32:50 - trainer.py[line:639] - INFO: loading train data for epoch 4
local datafile ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 0 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 1 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 0 finished initializing row_count and line_idx-to-offset mapping
file ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 0 row count 27700 total row count 55400
local datafile ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 1 finished initializing row_count and line_idx-to-offset mapping
file ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 1 row count 27700 total row count 55400
slice_id 1 seek offset 27700
slice_id 0 seek offset 0
2023-04-08 17:32:51 - trainer.py[line:703] - INFO: begin training epoch 4
2023-04-08 17:32:51 - train.py[line:305] - INFO: Start iterating over samples
2023-04-08 17:33:17 - progress_bar.py[line:272] - INFO: epoch 004:      8 / 578 loss=2.516, loss_v1=0, loss_v2=0, nll_loss=1.33, ntokens=2274.5, nsentences=87.6, sample_size=2274.5, sample_size_v1=0, sample_size_v2=0, ppl=2.51, wps=718.6, ups=0.32, wpb=2274.5, bsz=87.6, num_updates=1740, lr=2.3908e-05, gnorm=1.431, clip=90, loss_scale=256, train_wall=29, gb_free=12.4, wall=5427
2023-04-08 17:33:50 - progress_bar.py[line:272] - INFO: epoch 004:     18 / 578 loss=2.514, loss_v1=0, loss_v2=0, nll_loss=1.332, ntokens=2350, nsentences=96, sample_size=2350, sample_size_v1=0, sample_size_v2=0, ppl=2.52, wps=729, ups=0.31, wpb=2350, bsz=96, num_updates=1750, lr=2.3862e-05, gnorm=1.27, clip=100, loss_scale=256, train_wall=32, gb_free=12, wall=5459
2023-04-08 17:34:22 - progress_bar.py[line:272] - INFO: epoch 004:     28 / 578 loss=2.484, loss_v1=0, loss_v2=0, nll_loss=1.299, ntokens=2357, nsentences=96, sample_size=2357, sample_size_v1=0, sample_size_v2=0, ppl=2.46, wps=731.3, ups=0.31, wpb=2357, bsz=96, num_updates=1760, lr=2.3816e-05, gnorm=1.224, clip=100, loss_scale=256, train_wall=32, gb_free=12.3, wall=5492
2023-04-08 17:34:54 - progress_bar.py[line:272] - INFO: epoch 004:     38 / 578 loss=2.508, loss_v1=0, loss_v2=0, nll_loss=1.323, ntokens=2186.9, nsentences=96, sample_size=2186.9, sample_size_v1=0, sample_size_v2=0, ppl=2.5, wps=678.5, ups=0.31, wpb=2186.9, bsz=96, num_updates=1770, lr=2.37699e-05, gnorm=1.374, clip=100, loss_scale=256, train_wall=32, gb_free=12.5, wall=5524
2023-04-08 17:35:27 - progress_bar.py[line:272] - INFO: epoch 004:     48 / 578 loss=2.48, loss_v1=0, loss_v2=0, nll_loss=1.294, ntokens=2411.7, nsentences=96, sample_size=2411.7, sample_size_v1=0, sample_size_v2=0, ppl=2.45, wps=741.5, ups=0.31, wpb=2411.7, bsz=96, num_updates=1780, lr=2.37239e-05, gnorm=1.252, clip=100, loss_scale=256, train_wall=32, gb_free=11.8, wall=5556
2023-04-08 17:35:59 - progress_bar.py[line:272] - INFO: epoch 004:     58 / 578 loss=2.527, loss_v1=0, loss_v2=0, nll_loss=1.343, ntokens=2244.7, nsentences=96, sample_size=2244.7, sample_size_v1=0, sample_size_v2=0, ppl=2.54, wps=689.9, ups=0.31, wpb=2244.7, bsz=96, num_updates=1790, lr=2.36779e-05, gnorm=1.303, clip=100, loss_scale=256, train_wall=33, gb_free=11.9, wall=5589
2023-04-08 17:36:32 - progress_bar.py[line:272] - INFO: epoch 004:     68 / 578 loss=2.525, loss_v1=0, loss_v2=0, nll_loss=1.345, ntokens=2323.5, nsentences=96, sample_size=2323.5, sample_size_v1=0, sample_size_v2=0, ppl=2.54, wps=714.6, ups=0.31, wpb=2323.5, bsz=96, num_updates=1800, lr=2.36319e-05, gnorm=1.357, clip=100, loss_scale=256, train_wall=32, gb_free=12.4, wall=5621
2023-04-08 17:37:04 - progress_bar.py[line:272] - INFO: epoch 004:     78 / 578 loss=2.53, loss_v1=0, loss_v2=0, nll_loss=1.35, ntokens=2468.3, nsentences=96, sample_size=2468.3, sample_size_v1=0, sample_size_v2=0, ppl=2.55, wps=754, ups=0.31, wpb=2468.3, bsz=96, num_updates=1810, lr=2.35859e-05, gnorm=1.247, clip=100, loss_scale=256, train_wall=33, gb_free=12.1, wall=5654
2023-04-08 17:37:37 - progress_bar.py[line:272] - INFO: epoch 004:     88 / 578 loss=2.526, loss_v1=0, loss_v2=0, nll_loss=1.343, ntokens=2524.1, nsentences=96, sample_size=2524.1, sample_size_v1=0, sample_size_v2=0, ppl=2.54, wps=776, ups=0.31, wpb=2524.1, bsz=96, num_updates=1820, lr=2.35399e-05, gnorm=1.184, clip=100, loss_scale=256, train_wall=32, gb_free=12, wall=5687
2023-04-08 17:38:09 - progress_bar.py[line:272] - INFO: epoch 004:     98 / 578 loss=2.521, loss_v1=0, loss_v2=0, nll_loss=1.34, ntokens=2422.9, nsentences=96, sample_size=2422.9, sample_size_v1=0, sample_size_v2=0, ppl=2.53, wps=748.3, ups=0.31, wpb=2422.9, bsz=96, num_updates=1830, lr=2.34939e-05, gnorm=1.216, clip=100, loss_scale=256, train_wall=32, gb_free=12.1, wall=5719
2023-04-08 17:38:42 - progress_bar.py[line:272] - INFO: epoch 004:    108 / 578 loss=2.518, loss_v1=0, loss_v2=0, nll_loss=1.337, ntokens=2446.6, nsentences=96, sample_size=2446.6, sample_size_v1=0, sample_size_v2=0, ppl=2.53, wps=749.3, ups=0.31, wpb=2446.6, bsz=96, num_updates=1840, lr=2.34479e-05, gnorm=1.239, clip=90, loss_scale=256, train_wall=33, gb_free=12.1, wall=5752
2023-04-08 17:39:15 - progress_bar.py[line:272] - INFO: epoch 004:    118 / 578 loss=2.524, loss_v1=0, loss_v2=0, nll_loss=1.339, ntokens=2356.2, nsentences=96, sample_size=2356.2, sample_size_v1=0, sample_size_v2=0, ppl=2.53, wps=722.6, ups=0.31, wpb=2356.2, bsz=96, num_updates=1850, lr=2.34018e-05, gnorm=1.333, clip=100, loss_scale=256, train_wall=33, gb_free=12, wall=5784
2023-04-08 17:39:47 - progress_bar.py[line:272] - INFO: epoch 004:    128 / 578 loss=2.519, loss_v1=0, loss_v2=0, nll_loss=1.337, ntokens=2410.1, nsentences=96, sample_size=2410.1, sample_size_v1=0, sample_size_v2=0, ppl=2.53, wps=742.8, ups=0.31, wpb=2410.1, bsz=96, num_updates=1860, lr=2.33558e-05, gnorm=1.197, clip=90, loss_scale=256, train_wall=32, gb_free=12.1, wall=5817
2023-04-08 17:40:20 - progress_bar.py[line:272] - INFO: epoch 004:    138 / 578 loss=2.531, loss_v1=0, loss_v2=0, nll_loss=1.352, ntokens=2371.2, nsentences=96, sample_size=2371.2, sample_size_v1=0, sample_size_v2=0, ppl=2.55, wps=729.3, ups=0.31, wpb=2371.2, bsz=96, num_updates=1870, lr=2.33098e-05, gnorm=1.307, clip=100, loss_scale=256, train_wall=32, gb_free=12.1, wall=5849
2023-04-08 17:40:52 - progress_bar.py[line:272] - INFO: epoch 004:    148 / 578 loss=2.533, loss_v1=0, loss_v2=0, nll_loss=1.352, ntokens=2650.2, nsentences=96, sample_size=2650.2, sample_size_v1=0, sample_size_v2=0, ppl=2.55, wps=810.6, ups=0.31, wpb=2650.2, bsz=96, num_updates=1880, lr=2.32638e-05, gnorm=1.22, clip=100, loss_scale=256, train_wall=33, gb_free=12.1, wall=5882
2023-04-08 17:41:25 - progress_bar.py[line:272] - INFO: epoch 004:    158 / 578 loss=2.533, loss_v1=0, loss_v2=0, nll_loss=1.352, ntokens=2670.1, nsentences=96, sample_size=2670.1, sample_size_v1=0, sample_size_v2=0, ppl=2.55, wps=821.5, ups=0.31, wpb=2670.1, bsz=96, num_updates=1890, lr=2.32178e-05, gnorm=1.209, clip=100, loss_scale=256, train_wall=32, gb_free=12.1, wall=5914
2023-04-08 17:41:57 - progress_bar.py[line:272] - INFO: epoch 004:    168 / 578 loss=2.526, loss_v1=0, loss_v2=0, nll_loss=1.346, ntokens=2635.4, nsentences=96, sample_size=2635.4, sample_size_v1=0, sample_size_v2=0, ppl=2.54, wps=808.6, ups=0.31, wpb=2635.4, bsz=96, num_updates=1900, lr=2.31718e-05, gnorm=1.18, clip=90, loss_scale=256, train_wall=33, gb_free=12.5, wall=5947
2023-04-08 17:42:30 - progress_bar.py[line:272] - INFO: epoch 004:    178 / 578 loss=2.529, loss_v1=0, loss_v2=0, nll_loss=1.349, ntokens=2591.5, nsentences=96, sample_size=2591.5, sample_size_v1=0, sample_size_v2=0, ppl=2.55, wps=796.7, ups=0.31, wpb=2591.5, bsz=96, num_updates=1910, lr=2.31258e-05, gnorm=1.145, clip=100, loss_scale=256, train_wall=32, gb_free=12.2, wall=5980
2023-04-08 17:43:02 - progress_bar.py[line:272] - INFO: epoch 004:    188 / 578 loss=2.534, loss_v1=0, loss_v2=0, nll_loss=1.354, ntokens=2683.2, nsentences=96, sample_size=2683.2, sample_size_v1=0, sample_size_v2=0, ppl=2.56, wps=827.9, ups=0.31, wpb=2683.2, bsz=96, num_updates=1920, lr=2.30798e-05, gnorm=1.116, clip=90, loss_scale=256, train_wall=32, gb_free=12.1, wall=6012
2023-04-08 17:43:35 - progress_bar.py[line:272] - INFO: epoch 004:    198 / 578 loss=2.512, loss_v1=0, loss_v2=0, nll_loss=1.329, ntokens=2580.6, nsentences=96, sample_size=2580.6, sample_size_v1=0, sample_size_v2=0, ppl=2.51, wps=792.6, ups=0.31, wpb=2580.6, bsz=96, num_updates=1930, lr=2.30337e-05, gnorm=1.242, clip=100, loss_scale=256, train_wall=33, gb_free=12.3, wall=6045
2023-04-08 17:44:07 - progress_bar.py[line:272] - INFO: epoch 004:    208 / 578 loss=2.517, loss_v1=0, loss_v2=0, nll_loss=1.337, ntokens=2574.3, nsentences=96, sample_size=2574.3, sample_size_v1=0, sample_size_v2=0, ppl=2.53, wps=792.2, ups=0.31, wpb=2574.3, bsz=96, num_updates=1940, lr=2.29877e-05, gnorm=1.249, clip=100, loss_scale=256, train_wall=32, gb_free=12.4, wall=6077
2023-04-08 17:44:40 - progress_bar.py[line:272] - INFO: epoch 004:    218 / 578 loss=2.541, loss_v1=0, loss_v2=0, nll_loss=1.36, ntokens=2506, nsentences=96, sample_size=2506, sample_size_v1=0, sample_size_v2=0, ppl=2.57, wps=772.5, ups=0.31, wpb=2506, bsz=96, num_updates=1950, lr=2.29417e-05, gnorm=1.318, clip=100, loss_scale=256, train_wall=32, gb_free=12.3, wall=6110
2023-04-08 17:45:13 - progress_bar.py[line:272] - INFO: epoch 004:    228 / 578 loss=2.501, loss_v1=0, loss_v2=0, nll_loss=1.318, ntokens=2513.2, nsentences=96, sample_size=2513.2, sample_size_v1=0, sample_size_v2=0, ppl=2.49, wps=768.7, ups=0.31, wpb=2513.2, bsz=96, num_updates=1960, lr=2.28957e-05, gnorm=1.25, clip=100, loss_scale=256, train_wall=33, gb_free=12.6, wall=6142
2023-04-08 17:45:45 - progress_bar.py[line:272] - INFO: epoch 004:    238 / 578 loss=2.528, loss_v1=0, loss_v2=0, nll_loss=1.346, ntokens=2453.8, nsentences=96, sample_size=2453.8, sample_size_v1=0, sample_size_v2=0, ppl=2.54, wps=754.7, ups=0.31, wpb=2453.8, bsz=96, num_updates=1970, lr=2.28497e-05, gnorm=1.26, clip=100, loss_scale=256, train_wall=32, gb_free=12.5, wall=6175
2023-04-08 17:46:18 - progress_bar.py[line:272] - INFO: epoch 004:    248 / 578 loss=2.525, loss_v1=0, loss_v2=0, nll_loss=1.345, ntokens=2499.3, nsentences=96, sample_size=2499.3, sample_size_v1=0, sample_size_v2=0, ppl=2.54, wps=769.9, ups=0.31, wpb=2499.3, bsz=96, num_updates=1980, lr=2.28037e-05, gnorm=1.244, clip=100, loss_scale=256, train_wall=32, gb_free=12.5, wall=6207
2023-04-08 17:46:50 - progress_bar.py[line:272] - INFO: epoch 004:    258 / 578 loss=2.515, loss_v1=0, loss_v2=0, nll_loss=1.332, ntokens=2593.4, nsentences=96, sample_size=2593.4, sample_size_v1=0, sample_size_v2=0, ppl=2.52, wps=797.8, ups=0.31, wpb=2593.4, bsz=96, num_updates=1990, lr=2.27577e-05, gnorm=1.214, clip=100, loss_scale=256, train_wall=32, gb_free=12.5, wall=6240
2023-04-08 17:47:23 - progress_bar.py[line:272] - INFO: epoch 004:    268 / 578 loss=2.512, loss_v1=0, loss_v2=0, nll_loss=1.332, ntokens=2481.6, nsentences=96, sample_size=2481.6, sample_size_v1=0, sample_size_v2=0, ppl=2.52, wps=763.6, ups=0.31, wpb=2481.6, bsz=96, num_updates=2000, lr=2.27117e-05, gnorm=1.249, clip=100, loss_scale=256, train_wall=32, gb_free=12.3, wall=6272
2023-04-08 17:47:55 - progress_bar.py[line:272] - INFO: epoch 004:    278 / 578 loss=2.514, loss_v1=0, loss_v2=0, nll_loss=1.33, ntokens=2622.5, nsentences=96, sample_size=2622.5, sample_size_v1=0, sample_size_v2=0, ppl=2.51, wps=803.4, ups=0.31, wpb=2622.5, bsz=96, num_updates=2010, lr=2.26656e-05, gnorm=1.262, clip=100, loss_scale=256, train_wall=33, gb_free=12.5, wall=6305
2023-04-08 17:48:28 - progress_bar.py[line:272] - INFO: epoch 004:    288 / 578 loss=2.506, loss_v1=0, loss_v2=0, nll_loss=1.324, ntokens=2558.3, nsentences=96, sample_size=2558.3, sample_size_v1=0, sample_size_v2=0, ppl=2.5, wps=779.8, ups=0.3, wpb=2558.3, bsz=96, num_updates=2020, lr=2.26196e-05, gnorm=1.163, clip=100, loss_scale=256, train_wall=33, gb_free=12.6, wall=6338
2023-04-08 17:49:01 - progress_bar.py[line:272] - INFO: epoch 004:    298 / 578 loss=2.524, loss_v1=0, loss_v2=0, nll_loss=1.341, ntokens=2574.7, nsentences=96, sample_size=2574.7, sample_size_v1=0, sample_size_v2=0, ppl=2.53, wps=786.4, ups=0.31, wpb=2574.7, bsz=96, num_updates=2030, lr=2.25736e-05, gnorm=1.163, clip=90, loss_scale=256, train_wall=33, gb_free=12, wall=6370
2023-04-08 17:49:34 - progress_bar.py[line:272] - INFO: epoch 004:    308 / 578 loss=2.511, loss_v1=0, loss_v2=0, nll_loss=1.331, ntokens=2573.1, nsentences=96, sample_size=2573.1, sample_size_v1=0, sample_size_v2=0, ppl=2.52, wps=786.2, ups=0.31, wpb=2573.1, bsz=96, num_updates=2040, lr=2.25276e-05, gnorm=1.207, clip=90, loss_scale=256, train_wall=33, gb_free=12.4, wall=6403
2023-04-08 17:50:06 - progress_bar.py[line:272] - INFO: epoch 004:    318 / 578 loss=2.521, loss_v1=0, loss_v2=0, nll_loss=1.336, ntokens=2660, nsentences=95.6, sample_size=2660, sample_size_v1=0, sample_size_v2=0, ppl=2.52, wps=815.9, ups=0.31, wpb=2660, bsz=95.6, num_updates=2050, lr=2.24816e-05, gnorm=1.185, clip=100, loss_scale=256, train_wall=33, gb_free=12.4, wall=6436
2023-04-08 17:50:26 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 256.0
2023-04-08 17:50:42 - progress_bar.py[line:272] - INFO: epoch 004:    329 / 578 loss=2.489, loss_v1=0, loss_v2=0, nll_loss=1.304, ntokens=2505.3, nsentences=96, sample_size=2505.3, sample_size_v1=0, sample_size_v2=0, ppl=2.47, wps=696.2, ups=0.28, wpb=2505.3, bsz=96, num_updates=2060, lr=2.24356e-05, gnorm=1.25, clip=100, loss_scale=256, train_wall=36, gb_free=12.6, wall=6472
2023-04-08 17:51:13 - progress_bar.py[line:272] - INFO: epoch 004:    339 / 578 loss=2.518, loss_v1=0, loss_v2=0, nll_loss=1.338, ntokens=2626.3, nsentences=96, sample_size=2626.3, sample_size_v1=0, sample_size_v2=0, ppl=2.53, wps=843.8, ups=0.32, wpb=2626.3, bsz=96, num_updates=2070, lr=2.23896e-05, gnorm=1.22, clip=100, loss_scale=256, train_wall=31, gb_free=12.4, wall=6503
2023-04-08 17:51:44 - progress_bar.py[line:272] - INFO: epoch 004:    349 / 578 loss=2.498, loss_v1=0, loss_v2=0, nll_loss=1.314, ntokens=2686.6, nsentences=96, sample_size=2686.6, sample_size_v1=0, sample_size_v2=0, ppl=2.49, wps=883.8, ups=0.33, wpb=2686.6, bsz=96, num_updates=2080, lr=2.23436e-05, gnorm=1.21, clip=100, loss_scale=256, train_wall=30, gb_free=12.6, wall=6533
2023-04-08 17:52:15 - progress_bar.py[line:272] - INFO: epoch 004:    359 / 578 loss=2.489, loss_v1=0, loss_v2=0, nll_loss=1.303, ntokens=2613.9, nsentences=96, sample_size=2613.9, sample_size_v1=0, sample_size_v2=0, ppl=2.47, wps=840.6, ups=0.32, wpb=2613.9, bsz=96, num_updates=2090, lr=2.22975e-05, gnorm=1.224, clip=100, loss_scale=256, train_wall=31, gb_free=12.2, wall=6564
2023-04-08 17:52:46 - progress_bar.py[line:272] - INFO: epoch 004:    369 / 578 loss=2.524, loss_v1=0, loss_v2=0, nll_loss=1.344, ntokens=2804.6, nsentences=96, sample_size=2804.6, sample_size_v1=0, sample_size_v2=0, ppl=2.54, wps=894.6, ups=0.32, wpb=2804.6, bsz=96, num_updates=2100, lr=2.22515e-05, gnorm=1.12, clip=90, loss_scale=256, train_wall=31, gb_free=12.6, wall=6596
2023-04-08 17:53:17 - progress_bar.py[line:272] - INFO: epoch 004:    379 / 578 loss=2.514, loss_v1=0, loss_v2=0, nll_loss=1.331, ntokens=2746.4, nsentences=96, sample_size=2746.4, sample_size_v1=0, sample_size_v2=0, ppl=2.52, wps=882.1, ups=0.32, wpb=2746.4, bsz=96, num_updates=2110, lr=2.22055e-05, gnorm=1.18, clip=100, loss_scale=256, train_wall=31, gb_free=12.3, wall=6627
2023-04-08 17:53:48 - progress_bar.py[line:272] - INFO: epoch 004:    389 / 578 loss=2.519, loss_v1=0, loss_v2=0, nll_loss=1.336, ntokens=2576.9, nsentences=96, sample_size=2576.9, sample_size_v1=0, sample_size_v2=0, ppl=2.52, wps=833.2, ups=0.32, wpb=2576.9, bsz=96, num_updates=2120, lr=2.21595e-05, gnorm=1.24, clip=100, loss_scale=256, train_wall=31, gb_free=12.5, wall=6658
2023-04-08 17:54:19 - progress_bar.py[line:272] - INFO: epoch 004:    399 / 578 loss=2.492, loss_v1=0, loss_v2=0, nll_loss=1.309, ntokens=2557.5, nsentences=96, sample_size=2557.5, sample_size_v1=0, sample_size_v2=0, ppl=2.48, wps=819.8, ups=0.32, wpb=2557.5, bsz=96, num_updates=2130, lr=2.21135e-05, gnorm=1.247, clip=100, loss_scale=256, train_wall=31, gb_free=12.7, wall=6689
2023-04-08 17:54:50 - progress_bar.py[line:272] - INFO: epoch 004:    409 / 578 loss=2.504, loss_v1=0, loss_v2=0, nll_loss=1.32, ntokens=2442.9, nsentences=96, sample_size=2442.9, sample_size_v1=0, sample_size_v2=0, ppl=2.5, wps=789.9, ups=0.32, wpb=2442.9, bsz=96, num_updates=2140, lr=2.20675e-05, gnorm=1.229, clip=100, loss_scale=256, train_wall=31, gb_free=12.3, wall=6720
2023-04-08 17:55:21 - progress_bar.py[line:272] - INFO: epoch 004:    419 / 578 loss=2.507, loss_v1=0, loss_v2=0, nll_loss=1.324, ntokens=2470.4, nsentences=96, sample_size=2470.4, sample_size_v1=0, sample_size_v2=0, ppl=2.5, wps=794.7, ups=0.32, wpb=2470.4, bsz=96, num_updates=2150, lr=2.20215e-05, gnorm=1.303, clip=100, loss_scale=256, train_wall=31, gb_free=12.6, wall=6751
2023-04-08 17:55:52 - progress_bar.py[line:272] - INFO: epoch 004:    429 / 578 loss=2.49, loss_v1=0, loss_v2=0, nll_loss=1.303, ntokens=2556.1, nsentences=96, sample_size=2556.1, sample_size_v1=0, sample_size_v2=0, ppl=2.47, wps=827.8, ups=0.32, wpb=2556.1, bsz=96, num_updates=2160, lr=2.19755e-05, gnorm=1.164, clip=100, loss_scale=256, train_wall=31, gb_free=12.5, wall=6782
2023-04-08 17:56:23 - progress_bar.py[line:272] - INFO: epoch 004:    439 / 578 loss=2.515, loss_v1=0, loss_v2=0, nll_loss=1.335, ntokens=2455.9, nsentences=96, sample_size=2455.9, sample_size_v1=0, sample_size_v2=0, ppl=2.52, wps=794.9, ups=0.32, wpb=2455.9, bsz=96, num_updates=2170, lr=2.19294e-05, gnorm=1.261, clip=100, loss_scale=256, train_wall=31, gb_free=12.6, wall=6813
2023-04-08 17:56:55 - progress_bar.py[line:272] - INFO: epoch 004:    449 / 578 loss=2.517, loss_v1=0, loss_v2=0, nll_loss=1.332, ntokens=2498.9, nsentences=96, sample_size=2498.9, sample_size_v1=0, sample_size_v2=0, ppl=2.52, wps=788.2, ups=0.32, wpb=2498.9, bsz=96, num_updates=2180, lr=2.18834e-05, gnorm=1.252, clip=100, loss_scale=256, train_wall=32, gb_free=12.6, wall=6845
2023-04-08 17:57:27 - progress_bar.py[line:272] - INFO: epoch 004:    459 / 578 loss=2.497, loss_v1=0, loss_v2=0, nll_loss=1.316, ntokens=2476.7, nsentences=96, sample_size=2476.7, sample_size_v1=0, sample_size_v2=0, ppl=2.49, wps=763.2, ups=0.31, wpb=2476.7, bsz=96, num_updates=2190, lr=2.18374e-05, gnorm=1.262, clip=100, loss_scale=256, train_wall=32, gb_free=12.4, wall=6877
2023-04-08 17:58:00 - progress_bar.py[line:272] - INFO: epoch 004:    469 / 578 loss=2.511, loss_v1=0, loss_v2=0, nll_loss=1.324, ntokens=2526.8, nsentences=96, sample_size=2526.8, sample_size_v1=0, sample_size_v2=0, ppl=2.5, wps=776.6, ups=0.31, wpb=2526.8, bsz=96, num_updates=2200, lr=2.17914e-05, gnorm=1.313, clip=100, loss_scale=256, train_wall=33, gb_free=12.4, wall=6910
2023-04-08 17:58:32 - progress_bar.py[line:272] - INFO: epoch 004:    479 / 578 loss=2.518, loss_v1=0, loss_v2=0, nll_loss=1.338, ntokens=2353.2, nsentences=96, sample_size=2353.2, sample_size_v1=0, sample_size_v2=0, ppl=2.53, wps=725.9, ups=0.31, wpb=2353.2, bsz=96, num_updates=2210, lr=2.17454e-05, gnorm=1.347, clip=100, loss_scale=256, train_wall=32, gb_free=12.7, wall=6942
2023-04-08 17:59:05 - progress_bar.py[line:272] - INFO: epoch 004:    489 / 578 loss=2.491, loss_v1=0, loss_v2=0, nll_loss=1.305, ntokens=2436.9, nsentences=96, sample_size=2436.9, sample_size_v1=0, sample_size_v2=0, ppl=2.47, wps=751.6, ups=0.31, wpb=2436.9, bsz=96, num_updates=2220, lr=2.16994e-05, gnorm=1.269, clip=100, loss_scale=256, train_wall=32, gb_free=12.2, wall=6974
2023-04-08 17:59:37 - progress_bar.py[line:272] - INFO: epoch 004:    499 / 578 loss=2.485, loss_v1=0, loss_v2=0, nll_loss=1.298, ntokens=2585.6, nsentences=96, sample_size=2585.6, sample_size_v1=0, sample_size_v2=0, ppl=2.46, wps=789.6, ups=0.31, wpb=2585.6, bsz=96, num_updates=2230, lr=2.16534e-05, gnorm=1.264, clip=100, loss_scale=256, train_wall=33, gb_free=12.5, wall=7007
2023-04-08 18:00:10 - progress_bar.py[line:272] - INFO: epoch 004:    509 / 578 loss=2.495, loss_v1=0, loss_v2=0, nll_loss=1.313, ntokens=2554.3, nsentences=96, sample_size=2554.3, sample_size_v1=0, sample_size_v2=0, ppl=2.49, wps=780.9, ups=0.31, wpb=2554.3, bsz=96, num_updates=2240, lr=2.16074e-05, gnorm=1.335, clip=100, loss_scale=256, train_wall=33, gb_free=12.5, wall=7040
2023-04-08 18:00:43 - progress_bar.py[line:272] - INFO: epoch 004:    519 / 578 loss=2.479, loss_v1=0, loss_v2=0, nll_loss=1.29, ntokens=2670.7, nsentences=96, sample_size=2670.7, sample_size_v1=0, sample_size_v2=0, ppl=2.45, wps=816.7, ups=0.31, wpb=2670.7, bsz=96, num_updates=2250, lr=2.15613e-05, gnorm=1.228, clip=100, loss_scale=256, train_wall=33, gb_free=12.7, wall=7073
2023-04-08 18:01:15 - progress_bar.py[line:272] - INFO: epoch 004:    529 / 578 loss=2.492, loss_v1=0, loss_v2=0, nll_loss=1.308, ntokens=2575.7, nsentences=96, sample_size=2575.7, sample_size_v1=0, sample_size_v2=0, ppl=2.48, wps=794.4, ups=0.31, wpb=2575.7, bsz=96, num_updates=2260, lr=2.15153e-05, gnorm=1.324, clip=100, loss_scale=256, train_wall=32, gb_free=12.4, wall=7105
2023-04-08 18:01:48 - progress_bar.py[line:272] - INFO: epoch 004:    539 / 578 loss=2.482, loss_v1=0, loss_v2=0, nll_loss=1.296, ntokens=2477.8, nsentences=96, sample_size=2477.8, sample_size_v1=0, sample_size_v2=0, ppl=2.46, wps=763.6, ups=0.31, wpb=2477.8, bsz=96, num_updates=2270, lr=2.14693e-05, gnorm=1.285, clip=100, loss_scale=256, train_wall=32, gb_free=12.4, wall=7137
2023-04-08 18:02:18 - progress_bar.py[line:272] - INFO: epoch 004:    549 / 578 loss=2.491, loss_v1=0, loss_v2=0, nll_loss=1.303, ntokens=2554.8, nsentences=96, sample_size=2554.8, sample_size_v1=0, sample_size_v2=0, ppl=2.47, wps=845.6, ups=0.33, wpb=2554.8, bsz=96, num_updates=2280, lr=2.14233e-05, gnorm=1.25, clip=90, loss_scale=256, train_wall=30, gb_free=12.2, wall=7168
2023-04-08 18:02:49 - progress_bar.py[line:272] - INFO: epoch 004:    559 / 578 loss=2.476, loss_v1=0, loss_v2=0, nll_loss=1.29, ntokens=2596.9, nsentences=96, sample_size=2596.9, sample_size_v1=0, sample_size_v2=0, ppl=2.45, wps=828.3, ups=0.32, wpb=2596.9, bsz=96, num_updates=2290, lr=2.13773e-05, gnorm=1.263, clip=100, loss_scale=256, train_wall=31, gb_free=12.5, wall=7199
2023-04-08 18:03:21 - progress_bar.py[line:272] - INFO: epoch 004:    569 / 578 loss=2.48, loss_v1=0, loss_v2=0, nll_loss=1.292, ntokens=2697.6, nsentences=96, sample_size=2697.6, sample_size_v1=0, sample_size_v2=0, ppl=2.45, wps=861.9, ups=0.32, wpb=2697.6, bsz=96, num_updates=2300, lr=2.13313e-05, gnorm=1.243, clip=100, loss_scale=256, train_wall=31, gb_free=12.5, wall=7230
2023-04-08 18:03:46 - train.py[line:445] - INFO: begin validation on "valid" subset
slice_id 0 seek offset 0
slice_id 1 seek offset 11440
slice_id 0 seek offset 0
slice_id 1 seek offset 11440
/home/zcai75/Github/OFA/fairseq/fairseq/search.py:140: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  beams_buf = indices_buf // vocab_size
/home/zcai75/Github/OFA/fairseq/fairseq/search.py:140: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  beams_buf = indices_buf // vocab_size
/home/zcai75/Github/OFA_forked/models/sequence_generator.py:705: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  unfin_idx = bbsz_idx // beam_size
/home/zcai75/Github/OFA_forked/models/sequence_generator.py:705: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  unfin_idx = bbsz_idx // beam_size
['<sub> train<pred> on<obj> track<sub> window<pred> on<obj> train<sub> door<pred> on<obj> train<sub> door<pred> on<obj> train<sub> window<pred> on<obj> train<sub> door<pred> on<obj> train', '<sub> man<pred> wearing<obj> shirt<pred> wearing<obj> jean<pred> wearing<obj> jean<pred> wearing<obj> shirt<pred> wearing<obj> jean<sub> woman<pred> wearing<obj> shirt<pred> wearing<obj> jean<pred> wearing<obj> jean<pred> wearing<obj> shirt', '<sub> zebra<pred> has<obj> tail<pred> has<obj> head<pred> has<obj> leg<pred> has<obj> head<pred> has<obj> leg<pred> has<obj> tail<pred> has<obj> head<pred> has<obj> leg<pred> has<obj> head<pred> has<obj> leg<pred> has<obj> head<pred> has<obj> leg<pred> has<obj> head<pred> has<obj> leg<pred> has<obj> leg<pred> has<obj> leg<pred> has<obj> head<pred> has<obj> neck<pred> has<obj> leg<pred> has<obj> zebra<sub> tree<pred> has<obj> zebra<pred> has<obj> tail<pred> has<obj> zebra<pred> has<obj> zebra<pred> has<obj> head<pred> has<obj> tail<pred> has<obj> head<pred> has<obj> zebra<sub> tree<pred> has<obj> head<pred> has<obj> head<pred> has<obj> head<pred> has<obj> tail<pred> has<obj> head<pred> has<obj> head<pred> has<obj> zebra<pred> has<obj> zebra<pred> has<obj> head<pred> has<obj> head<pred> has<obj> zebra<pred> has<obj> head<pred> has<obj> head<pred> has<obj> head<pred> has<obj> neck<pred> has<obj> head<pred> has<obj> head<pred> has<obj> head<pred>', '<sub> giraffe<pred> has<obj> neck<pred> has<obj> neck<pred> has<obj> head<pred> has<obj> neck<pred> has<obj> neck<pred> has<obj> head<pred> has<obj> neck<pred> has<obj> neck<pred> has<obj> head<pred> has<obj> neck<pred> has<obj> neck<sub> tree<pred> behind<obj> giraffe', '<sub> tree<pred> behind<obj> fence<sub> fence<pred> behind<obj> fence<sub> fence<pred> behind<obj> fence<sub> fence<pred> behind<obj> fence', '<sub> giraffe<pred> has<obj> neck<pred> has<obj> neck<pred> has<obj> head<pred> has<obj> neck<pred> has<obj> neck<pred> has<obj> head<pred> has<obj> neck<sub> tree<pred> behind<obj> giraffe'] [['<sub> windshield<pred> on<obj> train<sub> window<pred> on<obj> train<sub> train<pred> has<obj> window<sub> house<pred> near<obj> train<sub> tree<pred> near<obj> house'], ['<sub> bus<pred> under<obj> roof<sub> woman<pred> near<obj> bus<pred> wearing<obj> coat<sub> window<pred> on<obj> bus'], ['<sub> sign<pred> hanging from<obj> roof<sub> fence<pred> near<obj> cow'], ['<sub> wing<pred> on<obj> plane<sub> plane<pred> has<obj> tail<sub> fence<pred> in front of<obj> plane<sub> wheel<pred> on<obj> plane'], ['<sub> woman<pred> wearing<obj> shirt'], ['<sub> car<pred> on<obj> track<pred> near<obj> pole']]
['<sub> food<pred> on<obj> plate<sub> plate<pred> on<obj> table<sub> food<pred> on<obj> plate', '<sub> man<pred> wearing<obj> shirt<pred> wearing<obj> jean<pred> wearing<obj> jean<pred> wearing<obj> jean<pred> wearing<obj> shirt<pred> wearing<obj> jean<pred> wearing<obj> jean<pred> wearing<obj> shirt<pred> wearing<obj> jean<pred> wearing<obj> jean<pred> wearing<obj> jean<pred> wearing<obj> jean<pred> wearing<obj> jean<pred> wearing<obj> jean<pred> wearing<obj> jean<pred> wearing<obj> skateboard<pred> wearing<obj> skateboard<pred> wearing<obj> skateboard<pred> wearing<obj> skateboard<pred> wearing<obj> skateboard', '<sub> man<pred> wearing<obj> shirt<pred> wearing<obj> jean<pred> wearing<obj> jean<pred> wearing<obj> jean<pred> wearing<obj> shirt<pred> wearing<obj> jean<pred> wearing<obj> jean<pred> wearing<obj> shirt<pred> wearing<obj> jean<pred> wearing<obj> jean<pred> wearing<obj> jean<pred> wearing<obj> jean<pred> wearing<obj> jean<pred> wearing<obj> shirt<pred> wearing<obj> jean<pred> wearing<obj> skateboard<pred> wearing<obj> skateboard<pred> wearing<obj> skateboard<pred> wearing<obj> skateboard<pred> wearing<obj> skateboard<pred> wearing<obj> skateboard<pred> wearing<obj> skateboard', '<sub> window<pred> on<obj> train<sub> train<pred> on<obj> track<sub> windshield<pred> on<obj> train<sub> door<pred> on<obj> train<sub> door<pred> on<obj> train<sub> door<pred> on<obj> train<sub> window<pred> on<obj> train<sub> door<pred> on<obj> train', '<sub> man<pred> wearing<obj> shirt<pred> wearing<obj> short<pred> wearing<obj> short<pred> wearing<obj> shirt<pred> wearing<obj> short<pred> wearing<obj> sock<pred> wearing<obj> shoe<pred> wearing<obj> sock<pred> wearing<obj> shoe<pred> wearing<obj> short<pred> wearing<obj> shirt<pred> wearing<obj> short<pred> wearing<obj> sock<pred> wearing<obj> shoe<pred> wearing<obj> short<pred> wearing<obj> shoe<pred> wearing<obj> shoe<pred> wearing<obj> shoe<pred> wearing<obj> sock<pred> wearing<obj> sock<pred> wearing<obj> sock<pred> wearing<obj> sock<pred> wearing<obj> sock<pred> wearing<obj> sock<pred> wearing<obj> sock<pred> wearing<obj> sock<pred> wearing<obj> sock<pred> wearing<obj> sock<pred> wearing<obj> sock<pred> wearing<obj> sock<pred> wearing<obj> sock<pred> wearing<obj> sock<pred> wearing<obj> sock<pred> wearing<obj> sock<pred> wearing<obj> sock<pred> wearing<obj> sock<pred> wearing<obj> sock<pred> wearing<obj> sock<pred> wearing<obj> sock<pred> wearing<obj> sock<pred> wearing<obj> sock<pred> wearing<obj> sock<pred> wearing<obj> sock<pred> wearing<obj> sock<pred> wearing<obj> sock<pred> wearing<obj> sock<pred> wearing<obj> sock<pred> wearing<obj> sock<pred> wearing<obj> sock<pred> wearing', '<sub> man<pred> wearing<obj> shirt<pred> wearing<obj> jean<pred> wearing<obj> jean<pred> wearing<obj> jean<pred> wearing<obj> jean<pred> wearing<obj> shirt<pred> wearing<obj> jean<pred> wearing<obj> jean<pred> wearing<obj> shirt<pred> wearing<obj> jean<pred> wearing<obj> jean<pred> wearing<obj> jean<pred> wearing<obj> jean<pred> wearing<obj> jean<pred> wearing<obj> jean<pred> wearing<obj> skateboard<pred> wearing<obj> skateboard<pred> wearing<obj> skateboard<pred> wearing<obj> skateboard<pred> wearing<obj> skateboard<pred> wearing<obj> skateboard<pred> wearing<obj> skateboard<pred> wearing<obj> skateboard<pred> wearing<obj> skateboard<pred> wearing<obj> skateboard<pred> wearing<obj> skateboard<pred> wearing<obj> shoe<pred> wearing<obj> shoe<pred> wearing<obj> skateboard<pred> wearing<obj> shoe<pred> wearing<obj> skateboard<pred> wearing<obj> shoe<pred> wearing<obj> shoe<pred> wearing<obj> shoe<pred> wearing<obj> shoe<pred> wearing<obj> shoe<pred> wearing<obj> shoe<pred> wearing<obj> shoe<pred> wearing<obj> shoe<pred> wearing<obj> shoe<pred> wearing<obj> shoe<pred> wearing<obj> shoe<pred> wearing<obj> skateboard'] [['<sub> head<pred> of<obj> bear<sub> bear<pred> in<obj> bowl<sub> bowl<pred> with<obj> bear'], ['<sub> wheel<pred> of<obj> bus<sub> bus<pred> on<obj> street<sub> window<pred> of<obj> bus<sub> people<pred> near<obj> bus<sub> woman<pred> on<obj> bus<sub> letter<pred> on<obj> bus'], ['<sub> book<pred> under<obj> arm<sub> man<pred> wearing<obj> shirt<pred> wearing<obj> tie'], ['<sub> logo<pred> on<obj> bike<sub> woman<pred> on<obj> sidewalk<sub> sign<pred> on<obj> building<sub> bike<pred> has<obj> wheel<pred> has<obj> light<sub> wheel<pred> on<obj> bike'], ['<sub> man<pred> holding<obj> racket<pred> wearing<obj> short<pred> wearing<obj> sneaker<pred> wearing<obj> shirt<sub> men<pred> wearing<obj> short'], ['<sub> man<pred> wearing<obj> coat<pred> wearing<obj> jean<pred> on<obj> bus<pred> wearing<obj> sneaker<sub> seat<pred> near<obj> man<sub> light<pred> above<obj> man<sub> pole<pred> on<obj> bus<sub> sign<pred> on<obj> bus<sub> window<pred> on<obj> building<sub> hand<pred> of<obj> man']]
2023-04-08 18:04:11 - progress_bar.py[line:272] - INFO: epoch 004 | valid on 'valid' subset:     11 / 1907 loss=2.408, loss_v1=0, loss_v2=0, nll_loss=1.178, ntokens=336, nsentences=12, sample_size=336.0, sample_size_v1=0, sample_size_v2=0
2023-04-08 18:04:33 - progress_bar.py[line:272] - INFO: epoch 004 | valid on 'valid' subset:     21 / 1907 loss=2.502, loss_v1=0, loss_v2=0, nll_loss=1.287, ntokens=389, nsentences=12, sample_size=389.0, sample_size_v1=0, sample_size_v2=0
2023-04-08 18:04:57 - progress_bar.py[line:272] - INFO: epoch 004 | valid on 'valid' subset:     31 / 1907 loss=2.496, loss_v1=0, loss_v2=0, nll_loss=1.277, ntokens=372, nsentences=12, sample_size=372.0, sample_size_v1=0, sample_size_v2=0
2023-04-08 18:05:21 - progress_bar.py[line:272] - INFO: epoch 004 | valid on 'valid' subset:     41 / 1907 loss=2.395, loss_v1=0, loss_v2=0, nll_loss=1.166, ntokens=318, nsentences=12, sample_size=318.0, sample_size_v1=0, sample_size_v2=0
2023-04-08 18:05:44 - progress_bar.py[line:272] - INFO: epoch 004 | valid on 'valid' subset:     51 / 1907 loss=2.368, loss_v1=0, loss_v2=0, nll_loss=1.135, ntokens=352, nsentences=12, sample_size=352.0, sample_size_v1=0, sample_size_v2=0
2023-04-08 18:06:09 - progress_bar.py[line:272] - INFO: epoch 004 | valid on 'valid' subset:     61 / 1907 loss=2.471, loss_v1=0, loss_v2=0, nll_loss=1.249, ntokens=323, nsentences=12, sample_size=323.0, sample_size_v1=0, sample_size_v2=0
2023-04-08 18:06:33 - progress_bar.py[line:272] - INFO: epoch 004 | valid on 'valid' subset:     71 / 1907 loss=2.468, loss_v1=0, loss_v2=0, nll_loss=1.249, ntokens=354, nsentences=12, sample_size=354.0, sample_size_v1=0, sample_size_v2=0
2023-04-08 18:06:58 - progress_bar.py[line:272] - INFO: epoch 004 | valid on 'valid' subset:     81 / 1907 loss=2.468, loss_v1=0, loss_v2=0, nll_loss=1.25, ntokens=335, nsentences=12, sample_size=335.0, sample_size_v1=0, sample_size_v2=0
2023-04-08 18:07:23 - progress_bar.py[line:272] - INFO: epoch 004 | valid on 'valid' subset:     91 / 1907 loss=2.481, loss_v1=0, loss_v2=0, nll_loss=1.262, ntokens=296, nsentences=12, sample_size=296.0, sample_size_v1=0, sample_size_v2=0
2023-04-08 18:07:48 - progress_bar.py[line:272] - INFO: epoch 004 | valid on 'valid' subset:    101 / 1907 loss=2.516, loss_v1=0, loss_v2=0, nll_loss=1.298, ntokens=351, nsentences=12, sample_size=351.0, sample_size_v1=0, sample_size_v2=0
2023-04-08 18:08:13 - progress_bar.py[line:272] - INFO: epoch 004 | valid on 'valid' subset:    111 / 1907 loss=2.532, loss_v1=0, loss_v2=0, nll_loss=1.317, ntokens=476, nsentences=12, sample_size=476.0, sample_size_v1=0, sample_size_v2=0
2023-04-08 18:08:38 - progress_bar.py[line:272] - INFO: epoch 004 | valid on 'valid' subset:    121 / 1907 loss=2.524, loss_v1=0, loss_v2=0, nll_loss=1.306, ntokens=372, nsentences=12, sample_size=372.0, sample_size_v1=0, sample_size_v2=0
2023-04-08 18:09:02 - progress_bar.py[line:272] - INFO: epoch 004 | valid on 'valid' subset:    131 / 1907 loss=2.381, loss_v1=0, loss_v2=0, nll_loss=1.153, ntokens=297, nsentences=12, sample_size=297.0, sample_size_v1=0, sample_size_v2=0
2023-04-08 18:09:28 - progress_bar.py[line:272] - INFO: epoch 004 | valid on 'valid' subset:    141 / 1907 loss=2.463, loss_v1=0, loss_v2=0, nll_loss=1.241, ntokens=481, nsentences=12, sample_size=481.0, sample_size_v1=0, sample_size_v2=0
2023-04-08 18:09:53 - progress_bar.py[line:272] - INFO: epoch 004 | valid on 'valid' subset:    151 / 1907 loss=2.424, loss_v1=0, loss_v2=0, nll_loss=1.197, ntokens=325, nsentences=12, sample_size=325.0, sample_size_v1=0, sample_size_v2=0
2023-04-08 18:10:18 - progress_bar.py[line:272] - INFO: epoch 004 | valid on 'valid' subset:    161 / 1907 loss=2.5, loss_v1=0, loss_v2=0, nll_loss=1.283, ntokens=357, nsentences=12, sample_size=357.0, sample_size_v1=0, sample_size_v2=0
2023-04-08 18:10:43 - progress_bar.py[line:272] - INFO: epoch 004 | valid on 'valid' subset:    171 / 1907 loss=2.497, loss_v1=0, loss_v2=0, nll_loss=1.282, ntokens=405, nsentences=12, sample_size=405.0, sample_size_v1=0, sample_size_v2=0
2023-04-08 18:11:08 - progress_bar.py[line:272] - INFO: epoch 004 | valid on 'valid' subset:    181 / 1907 loss=2.586, loss_v1=0, loss_v2=0, nll_loss=1.378, ntokens=459, nsentences=12, sample_size=459.0, sample_size_v1=0, sample_size_v2=0
2023-04-08 18:11:31 - progress_bar.py[line:272] - INFO: epoch 004 | valid on 'valid' subset:    191 / 1907 loss=2.389, loss_v1=0, loss_v2=0, nll_loss=1.161, ntokens=238, nsentences=12, sample_size=238.0, sample_size_v1=0, sample_size_v2=0
2023-04-08 18:11:56 - progress_bar.py[line:272] - INFO: epoch 004 | valid on 'valid' subset:    201 / 1907 loss=2.669, loss_v1=0, loss_v2=0, nll_loss=1.468, ntokens=366, nsentences=12, sample_size=366.0, sample_size_v1=0, sample_size_v2=0
2023-04-08 18:12:20 - progress_bar.py[line:272] - INFO: epoch 004 | valid on 'valid' subset:    211 / 1907 loss=2.512, loss_v1=0, loss_v2=0, nll_loss=1.297, ntokens=315, nsentences=12, sample_size=315.0, sample_size_v1=0, sample_size_v2=0
2023-04-08 18:12:44 - progress_bar.py[line:272] - INFO: epoch 004 | valid on 'valid' subset:    221 / 1907 loss=2.531, loss_v1=0, loss_v2=0, nll_loss=1.32, ntokens=416, nsentences=12, sample_size=416.0, sample_size_v1=0, sample_size_v2=0
2023-04-08 18:13:08 - progress_bar.py[line:272] - INFO: epoch 004 | valid on 'valid' subset:    231 / 1907 loss=2.434, loss_v1=0, loss_v2=0, nll_loss=1.202, ntokens=246, nsentences=12, sample_size=246.0, sample_size_v1=0, sample_size_v2=0
2023-04-08 18:13:32 - progress_bar.py[line:272] - INFO: epoch 004 | valid on 'valid' subset:    241 / 1907 loss=2.441, loss_v1=0, loss_v2=0, nll_loss=1.217, ntokens=311, nsentences=12, sample_size=311.0, sample_size_v1=0, sample_size_v2=0
2023-04-08 18:13:55 - progress_bar.py[line:272] - INFO: epoch 004 | valid on 'valid' subset:    251 / 1907 loss=2.542, loss_v1=0, loss_v2=0, nll_loss=1.334, ntokens=378, nsentences=12, sample_size=378.0, sample_size_v1=0, sample_size_v2=0
2023-04-08 18:14:20 - progress_bar.py[line:272] - INFO: epoch 004 | valid on 'valid' subset:    261 / 1907 loss=2.446, loss_v1=0, loss_v2=0, nll_loss=1.223, ntokens=442, nsentences=12, sample_size=442.0, sample_size_v1=0, sample_size_v2=0
2023-04-08 18:14:45 - progress_bar.py[line:272] - INFO: epoch 004 | valid on 'valid' subset:    271 / 1907 loss=2.539, loss_v1=0, loss_v2=0, nll_loss=1.328, ntokens=313, nsentences=12, sample_size=313.0, sample_size_v1=0, sample_size_v2=0
2023-04-08 18:15:09 - progress_bar.py[line:272] - INFO: epoch 004 | valid on 'valid' subset:    281 / 1907 loss=2.449, loss_v1=0, loss_v2=0, nll_loss=1.224, ntokens=303, nsentences=12, sample_size=303.0, sample_size_v1=0, sample_size_v2=0
2023-04-08 18:15:34 - progress_bar.py[line:272] - INFO: epoch 004 | valid on 'valid' subset:    291 / 1907 loss=2.481, loss_v1=0, loss_v2=0, nll_loss=1.261, ntokens=313, nsentences=12, sample_size=313.0, sample_size_v1=0, sample_size_v2=0
2023-04-08 18:15:59 - progress_bar.py[line:272] - INFO: epoch 004 | valid on 'valid' subset:    301 / 1907 loss=2.384, loss_v1=0, loss_v2=0, nll_loss=1.156, ntokens=333, nsentences=12, sample_size=333.0, sample_size_v1=0, sample_size_v2=0
2023-04-08 18:16:23 - progress_bar.py[line:272] - INFO: epoch 004 | valid on 'valid' subset:    311 / 1907 loss=2.559, loss_v1=0, loss_v2=0, nll_loss=1.349, ntokens=364, nsentences=12, sample_size=364.0, sample_size_v1=0, sample_size_v2=0
2023-04-08 18:16:47 - progress_bar.py[line:272] - INFO: epoch 004 | valid on 'valid' subset:    321 / 1907 loss=2.303, loss_v1=0, loss_v2=0, nll_loss=1.063, ntokens=303, nsentences=12, sample_size=303.0, sample_size_v1=0, sample_size_v2=0
2023-04-08 18:17:11 - progress_bar.py[line:272] - INFO: epoch 004 | valid on 'valid' subset:    331 / 1907 loss=2.417, loss_v1=0, loss_v2=0, nll_loss=1.186, ntokens=300, nsentences=12, sample_size=300.0, sample_size_v1=0, sample_size_v2=0
2023-04-08 18:17:35 - progress_bar.py[line:272] - INFO: epoch 004 | valid on 'valid' subset:    341 / 1907 loss=2.385, loss_v1=0, loss_v2=0, nll_loss=1.155, ntokens=264, nsentences=12, sample_size=264.0, sample_size_v1=0, sample_size_v2=0
2023-04-08 18:17:59 - progress_bar.py[line:272] - INFO: epoch 004 | valid on 'valid' subset:    351 / 1907 loss=2.62, loss_v1=0, loss_v2=0, nll_loss=1.414, ntokens=320, nsentences=12, sample_size=320.0, sample_size_v1=0, sample_size_v2=0
2023-04-08 18:18:23 - progress_bar.py[line:272] - INFO: epoch 004 | valid on 'valid' subset:    361 / 1907 loss=2.558, loss_v1=0, loss_v2=0, nll_loss=1.348, ntokens=293, nsentences=12, sample_size=293.0, sample_size_v1=0, sample_size_v2=0
2023-04-08 18:18:48 - progress_bar.py[line:272] - INFO: epoch 004 | valid on 'valid' subset:    371 / 1907 loss=2.507, loss_v1=0, loss_v2=0, nll_loss=1.293, ntokens=314, nsentences=12, sample_size=314.0, sample_size_v1=0, sample_size_v2=0
2023-04-08 18:19:11 - progress_bar.py[line:272] - INFO: epoch 004 | valid on 'valid' subset:    381 / 1907 loss=2.382, loss_v1=0, loss_v2=0, nll_loss=1.151, ntokens=350, nsentences=12, sample_size=350.0, sample_size_v1=0, sample_size_v2=0
2023-04-08 18:19:36 - progress_bar.py[line:272] - INFO: epoch 004 | valid on 'valid' subset:    391 / 1907 loss=2.518, loss_v1=0, loss_v2=0, nll_loss=1.302, ntokens=235, nsentences=12, sample_size=235.0, sample_size_v1=0, sample_size_v2=0
2023-04-08 18:20:00 - progress_bar.py[line:272] - INFO: epoch 004 | valid on 'valid' subset:    401 / 1907 loss=2.554, loss_v1=0, loss_v2=0, nll_loss=1.344, ntokens=323, nsentences=12, sample_size=323.0, sample_size_v1=0, sample_size_v2=0
2023-04-08 18:20:25 - progress_bar.py[line:272] - INFO: epoch 004 | valid on 'valid' subset:    411 / 1907 loss=2.456, loss_v1=0, loss_v2=0, nll_loss=1.232, ntokens=268, nsentences=12, sample_size=268.0, sample_size_v1=0, sample_size_v2=0
2023-04-08 18:20:49 - progress_bar.py[line:272] - INFO: epoch 004 | valid on 'valid' subset:    421 / 1907 loss=2.501, loss_v1=0, loss_v2=0, nll_loss=1.288, ntokens=314, nsentences=12, sample_size=314.0, sample_size_v1=0, sample_size_v2=0
2023-04-08 18:21:13 - progress_bar.py[line:272] - INFO: epoch 004 | valid on 'valid' subset:    431 / 1907 loss=2.501, loss_v1=0, loss_v2=0, nll_loss=1.283, ntokens=362, nsentences=12, sample_size=362.0, sample_size_v1=0, sample_size_v2=0
2023-04-08 18:21:37 - progress_bar.py[line:272] - INFO: epoch 004 | valid on 'valid' subset:    441 / 1907 loss=2.532, loss_v1=0, loss_v2=0, nll_loss=1.316, ntokens=303, nsentences=12, sample_size=303.0, sample_size_v1=0, sample_size_v2=0
2023-04-08 18:22:02 - progress_bar.py[line:272] - INFO: epoch 004 | valid on 'valid' subset:    451 / 1907 loss=2.491, loss_v1=0, loss_v2=0, nll_loss=1.271, ntokens=307, nsentences=12, sample_size=307.0, sample_size_v1=0, sample_size_v2=0
2023-04-08 18:22:27 - progress_bar.py[line:272] - INFO: epoch 004 | valid on 'valid' subset:    461 / 1907 loss=2.568, loss_v1=0, loss_v2=0, nll_loss=1.361, ntokens=375, nsentences=12, sample_size=375.0, sample_size_v1=0, sample_size_v2=0
2023-04-08 18:22:52 - progress_bar.py[line:272] - INFO: epoch 004 | valid on 'valid' subset:    471 / 1907 loss=2.507, loss_v1=0, loss_v2=0, nll_loss=1.29, ntokens=343, nsentences=12, sample_size=343.0, sample_size_v1=0, sample_size_v2=0
2023-04-08 18:23:17 - progress_bar.py[line:272] - INFO: epoch 004 | valid on 'valid' subset:    481 / 1907 loss=2.473, loss_v1=0, loss_v2=0, nll_loss=1.252, ntokens=322, nsentences=12, sample_size=322.0, sample_size_v1=0, sample_size_v2=0
2023-04-08 18:23:41 - progress_bar.py[line:272] - INFO: epoch 004 | valid on 'valid' subset:    491 / 1907 loss=2.479, loss_v1=0, loss_v2=0, nll_loss=1.257, ntokens=271, nsentences=12, sample_size=271.0, sample_size_v1=0, sample_size_v2=0
2023-04-08 18:24:06 - progress_bar.py[line:272] - INFO: epoch 004 | valid on 'valid' subset:    501 / 1907 loss=2.469, loss_v1=0, loss_v2=0, nll_loss=1.25, ntokens=419, nsentences=12, sample_size=419.0, sample_size_v1=0, sample_size_v2=0
2023-04-08 18:24:31 - progress_bar.py[line:272] - INFO: epoch 004 | valid on 'valid' subset:    511 / 1907 loss=2.441, loss_v1=0, loss_v2=0, nll_loss=1.213, ntokens=304, nsentences=12, sample_size=304.0, sample_size_v1=0, sample_size_v2=0
2023-04-08 18:24:54 - progress_bar.py[line:272] - INFO: epoch 004 | valid on 'valid' subset:    521 / 1907 loss=2.324, loss_v1=0, loss_v2=0, nll_loss=1.087, ntokens=371, nsentences=12, sample_size=371.0, sample_size_v1=0, sample_size_v2=0
2023-04-08 18:25:19 - progress_bar.py[line:272] - INFO: epoch 004 | valid on 'valid' subset:    531 / 1907 loss=2.544, loss_v1=0, loss_v2=0, nll_loss=1.329, ntokens=376, nsentences=12, sample_size=376.0, sample_size_v1=0, sample_size_v2=0
2023-04-08 18:25:44 - progress_bar.py[line:272] - INFO: epoch 004 | valid on 'valid' subset:    541 / 1907 loss=2.426, loss_v1=0, loss_v2=0, nll_loss=1.198, ntokens=328, nsentences=12, sample_size=328.0, sample_size_v1=0, sample_size_v2=0
2023-04-08 18:26:08 - progress_bar.py[line:272] - INFO: epoch 004 | valid on 'valid' subset:    551 / 1907 loss=2.428, loss_v1=0, loss_v2=0, nll_loss=1.203, ntokens=221, nsentences=12, sample_size=221.0, sample_size_v1=0, sample_size_v2=0
2023-04-08 18:26:31 - progress_bar.py[line:272] - INFO: epoch 004 | valid on 'valid' subset:    561 / 1907 loss=2.505, loss_v1=0, loss_v2=0, nll_loss=1.289, ntokens=286, nsentences=12, sample_size=286.0, sample_size_v1=0, sample_size_v2=0
2023-04-08 18:26:50 - progress_bar.py[line:272] - INFO: epoch 004 | valid on 'valid' subset:    571 / 1907 loss=2.453, loss_v1=0, loss_v2=0, nll_loss=1.232, ntokens=413, nsentences=12, sample_size=413.0, sample_size_v1=0, sample_size_v2=0
2023-04-08 18:27:10 - progress_bar.py[line:272] - INFO: epoch 004 | valid on 'valid' subset:    581 / 1907 loss=2.505, loss_v1=0, loss_v2=0, nll_loss=1.285, ntokens=292, nsentences=12, sample_size=292.0, sample_size_v1=0, sample_size_v2=0
2023-04-08 18:27:29 - progress_bar.py[line:272] - INFO: epoch 004 | valid on 'valid' subset:    591 / 1907 loss=2.516, loss_v1=0, loss_v2=0, nll_loss=1.3, ntokens=342, nsentences=12, sample_size=342.0, sample_size_v1=0, sample_size_v2=0
2023-04-08 18:27:48 - progress_bar.py[line:272] - INFO: epoch 004 | valid on 'valid' subset:    601 / 1907 loss=2.517, loss_v1=0, loss_v2=0, nll_loss=1.304, ntokens=332, nsentences=12, sample_size=332.0, sample_size_v1=0, sample_size_v2=0
2023-04-08 18:28:08 - progress_bar.py[line:272] - INFO: epoch 004 | valid on 'valid' subset:    611 / 1907 loss=2.605, loss_v1=0, loss_v2=0, nll_loss=1.399, ntokens=309, nsentences=12, sample_size=309.0, sample_size_v1=0, sample_size_v2=0
2023-04-08 18:28:27 - progress_bar.py[line:272] - INFO: epoch 004 | valid on 'valid' subset:    621 / 1907 loss=2.415, loss_v1=0, loss_v2=0, nll_loss=1.189, ntokens=377, nsentences=12, sample_size=377.0, sample_size_v1=0, sample_size_v2=0
2023-04-08 18:28:47 - progress_bar.py[line:272] - INFO: epoch 004 | valid on 'valid' subset:    631 / 1907 loss=2.567, loss_v1=0, loss_v2=0, nll_loss=1.356, ntokens=277, nsentences=12, sample_size=277.0, sample_size_v1=0, sample_size_v2=0
2023-04-08 18:29:07 - progress_bar.py[line:272] - INFO: epoch 004 | valid on 'valid' subset:    641 / 1907 loss=2.362, loss_v1=0, loss_v2=0, nll_loss=1.131, ntokens=349, nsentences=12, sample_size=349.0, sample_size_v1=0, sample_size_v2=0
2023-04-08 18:29:27 - progress_bar.py[line:272] - INFO: epoch 004 | valid on 'valid' subset:    651 / 1907 loss=2.507, loss_v1=0, loss_v2=0, nll_loss=1.288, ntokens=330, nsentences=12, sample_size=330.0, sample_size_v1=0, sample_size_v2=0
2023-04-08 18:29:47 - progress_bar.py[line:272] - INFO: epoch 004 | valid on 'valid' subset:    661 / 1907 loss=2.49, loss_v1=0, loss_v2=0, nll_loss=1.268, ntokens=328, nsentences=12, sample_size=328.0, sample_size_v1=0, sample_size_v2=0
2023-04-08 18:30:06 - progress_bar.py[line:272] - INFO: epoch 004 | valid on 'valid' subset:    671 / 1907 loss=2.456, loss_v1=0, loss_v2=0, nll_loss=1.237, ntokens=367, nsentences=12, sample_size=367.0, sample_size_v1=0, sample_size_v2=0
2023-04-08 18:30:25 - progress_bar.py[line:272] - INFO: epoch 004 | valid on 'valid' subset:    681 / 1907 loss=2.561, loss_v1=0, loss_v2=0, nll_loss=1.352, ntokens=399, nsentences=12, sample_size=399.0, sample_size_v1=0, sample_size_v2=0
2023-04-08 18:30:44 - progress_bar.py[line:272] - INFO: epoch 004 | valid on 'valid' subset:    691 / 1907 loss=2.39, loss_v1=0, loss_v2=0, nll_loss=1.161, ntokens=267, nsentences=12, sample_size=267.0, sample_size_v1=0, sample_size_v2=0
2023-04-08 18:31:03 - progress_bar.py[line:272] - INFO: epoch 004 | valid on 'valid' subset:    701 / 1907 loss=2.56, loss_v1=0, loss_v2=0, nll_loss=1.352, ntokens=358, nsentences=12, sample_size=358.0, sample_size_v1=0, sample_size_v2=0
2023-04-08 18:31:23 - progress_bar.py[line:272] - INFO: epoch 004 | valid on 'valid' subset:    711 / 1907 loss=2.46, loss_v1=0, loss_v2=0, nll_loss=1.236, ntokens=398, nsentences=12, sample_size=398.0, sample_size_v1=0, sample_size_v2=0
2023-04-08 18:31:42 - progress_bar.py[line:272] - INFO: epoch 004 | valid on 'valid' subset:    721 / 1907 loss=2.601, loss_v1=0, loss_v2=0, nll_loss=1.396, ntokens=269, nsentences=12, sample_size=269.0, sample_size_v1=0, sample_size_v2=0
2023-04-08 18:32:02 - progress_bar.py[line:272] - INFO: epoch 004 | valid on 'valid' subset:    731 / 1907 loss=2.561, loss_v1=0, loss_v2=0, nll_loss=1.349, ntokens=293, nsentences=12, sample_size=293.0, sample_size_v1=0, sample_size_v2=0
2023-04-08 18:32:21 - progress_bar.py[line:272] - INFO: epoch 004 | valid on 'valid' subset:    741 / 1907 loss=2.597, loss_v1=0, loss_v2=0, nll_loss=1.394, ntokens=456, nsentences=12, sample_size=456.0, sample_size_v1=0, sample_size_v2=0
2023-04-08 18:32:41 - progress_bar.py[line:272] - INFO: epoch 004 | valid on 'valid' subset:    751 / 1907 loss=2.334, loss_v1=0, loss_v2=0, nll_loss=1.1, ntokens=310, nsentences=12, sample_size=310.0, sample_size_v1=0, sample_size_v2=0
2023-04-08 18:33:00 - progress_bar.py[line:272] - INFO: epoch 004 | valid on 'valid' subset:    761 / 1907 loss=2.467, loss_v1=0, loss_v2=0, nll_loss=1.242, ntokens=282, nsentences=12, sample_size=282.0, sample_size_v1=0, sample_size_v2=0
2023-04-08 18:33:19 - progress_bar.py[line:272] - INFO: epoch 004 | valid on 'valid' subset:    771 / 1907 loss=2.425, loss_v1=0, loss_v2=0, nll_loss=1.2, ntokens=348, nsentences=12, sample_size=348.0, sample_size_v1=0, sample_size_v2=0
2023-04-08 18:33:39 - progress_bar.py[line:272] - INFO: epoch 004 | valid on 'valid' subset:    781 / 1907 loss=2.43, loss_v1=0, loss_v2=0, nll_loss=1.203, ntokens=342, nsentences=12, sample_size=342.0, sample_size_v1=0, sample_size_v2=0
2023-04-08 18:33:58 - progress_bar.py[line:272] - INFO: epoch 004 | valid on 'valid' subset:    791 / 1907 loss=2.429, loss_v1=0, loss_v2=0, nll_loss=1.203, ntokens=329, nsentences=12, sample_size=329.0, sample_size_v1=0, sample_size_v2=0
2023-04-08 18:34:17 - progress_bar.py[line:272] - INFO: epoch 004 | valid on 'valid' subset:    801 / 1907 loss=2.295, loss_v1=0, loss_v2=0, nll_loss=1.052, ntokens=316, nsentences=12, sample_size=316.0, sample_size_v1=0, sample_size_v2=0
2023-04-08 18:34:36 - progress_bar.py[line:272] - INFO: epoch 004 | valid on 'valid' subset:    811 / 1907 loss=2.471, loss_v1=0, loss_v2=0, nll_loss=1.248, ntokens=300, nsentences=12, sample_size=300.0, sample_size_v1=0, sample_size_v2=0
2023-04-08 18:34:56 - progress_bar.py[line:272] - INFO: epoch 004 | valid on 'valid' subset:    821 / 1907 loss=2.481, loss_v1=0, loss_v2=0, nll_loss=1.262, ntokens=368, nsentences=12, sample_size=368.0, sample_size_v1=0, sample_size_v2=0
2023-04-08 18:35:15 - progress_bar.py[line:272] - INFO: epoch 004 | valid on 'valid' subset:    831 / 1907 loss=2.474, loss_v1=0, loss_v2=0, nll_loss=1.254, ntokens=317, nsentences=12, sample_size=317.0, sample_size_v1=0, sample_size_v2=0
2023-04-08 18:35:35 - progress_bar.py[line:272] - INFO: epoch 004 | valid on 'valid' subset:    841 / 1907 loss=2.52, loss_v1=0, loss_v2=0, nll_loss=1.31, ntokens=289, nsentences=12, sample_size=289.0, sample_size_v1=0, sample_size_v2=0
2023-04-08 18:35:54 - progress_bar.py[line:272] - INFO: epoch 004 | valid on 'valid' subset:    851 / 1907 loss=2.446, loss_v1=0, loss_v2=0, nll_loss=1.218, ntokens=333, nsentences=12, sample_size=333.0, sample_size_v1=0, sample_size_v2=0
2023-04-08 18:36:13 - progress_bar.py[line:272] - INFO: epoch 004 | valid on 'valid' subset:    861 / 1907 loss=2.527, loss_v1=0, loss_v2=0, nll_loss=1.316, ntokens=394, nsentences=12, sample_size=394.0, sample_size_v1=0, sample_size_v2=0
2023-04-08 18:36:32 - progress_bar.py[line:272] - INFO: epoch 004 | valid on 'valid' subset:    871 / 1907 loss=2.527, loss_v1=0, loss_v2=0, nll_loss=1.312, ntokens=339, nsentences=12, sample_size=339.0, sample_size_v1=0, sample_size_v2=0
2023-04-08 18:36:52 - progress_bar.py[line:272] - INFO: epoch 004 | valid on 'valid' subset:    881 / 1907 loss=2.43, loss_v1=0, loss_v2=0, nll_loss=1.209, ntokens=321, nsentences=12, sample_size=321.0, sample_size_v1=0, sample_size_v2=0
2023-04-08 18:37:11 - progress_bar.py[line:272] - INFO: epoch 004 | valid on 'valid' subset:    891 / 1907 loss=2.513, loss_v1=0, loss_v2=0, nll_loss=1.299, ntokens=334, nsentences=12, sample_size=334.0, sample_size_v1=0, sample_size_v2=0
2023-04-08 18:37:31 - progress_bar.py[line:272] - INFO: epoch 004 | valid on 'valid' subset:    901 / 1907 loss=2.496, loss_v1=0, loss_v2=0, nll_loss=1.274, ntokens=344, nsentences=12, sample_size=344.0, sample_size_v1=0, sample_size_v2=0
2023-04-08 18:37:51 - progress_bar.py[line:272] - INFO: epoch 004 | valid on 'valid' subset:    911 / 1907 loss=2.478, loss_v1=0, loss_v2=0, nll_loss=1.258, ntokens=408, nsentences=12, sample_size=408.0, sample_size_v1=0, sample_size_v2=0
2023-04-08 18:38:10 - progress_bar.py[line:272] - INFO: epoch 004 | valid on 'valid' subset:    921 / 1907 loss=2.443, loss_v1=0, loss_v2=0, nll_loss=1.22, ntokens=400, nsentences=12, sample_size=400.0, sample_size_v1=0, sample_size_v2=0
2023-04-08 18:38:30 - progress_bar.py[line:272] - INFO: epoch 004 | valid on 'valid' subset:    931 / 1907 loss=2.514, loss_v1=0, loss_v2=0, nll_loss=1.303, ntokens=547, nsentences=12, sample_size=547.0, sample_size_v1=0, sample_size_v2=0
2023-04-08 18:38:50 - progress_bar.py[line:272] - INFO: epoch 004 | valid on 'valid' subset:    941 / 1907 loss=2.584, loss_v1=0, loss_v2=0, nll_loss=1.376, ntokens=320, nsentences=12, sample_size=320.0, sample_size_v1=0, sample_size_v2=0
2023-04-08 18:39:09 - progress_bar.py[line:272] - INFO: epoch 004 | valid on 'valid' subset:    951 / 1907 loss=2.524, loss_v1=0, loss_v2=0, nll_loss=1.311, ntokens=289, nsentences=12, sample_size=289.0, sample_size_v1=0, sample_size_v2=0
2023-04-08 18:39:29 - progress_bar.py[line:272] - INFO: epoch 004 | valid on 'valid' subset:    961 / 1907 loss=2.464, loss_v1=0, loss_v2=0, nll_loss=1.244, ntokens=358, nsentences=12, sample_size=358.0, sample_size_v1=0, sample_size_v2=0
2023-04-08 18:39:49 - progress_bar.py[line:272] - INFO: epoch 004 | valid on 'valid' subset:    971 / 1907 loss=2.465, loss_v1=0, loss_v2=0, nll_loss=1.244, ntokens=256, nsentences=12, sample_size=256.0, sample_size_v1=0, sample_size_v2=0
2023-04-08 18:40:08 - progress_bar.py[line:272] - INFO: epoch 004 | valid on 'valid' subset:    981 / 1907 loss=2.48, loss_v1=0, loss_v2=0, nll_loss=1.256, ntokens=367, nsentences=12, sample_size=367.0, sample_size_v1=0, sample_size_v2=0
2023-04-08 18:40:28 - progress_bar.py[line:272] - INFO: epoch 004 | valid on 'valid' subset:    991 / 1907 loss=2.562, loss_v1=0, loss_v2=0, nll_loss=1.352, ntokens=338, nsentences=12, sample_size=338.0, sample_size_v1=0, sample_size_v2=0
2023-04-08 18:40:48 - progress_bar.py[line:272] - INFO: epoch 004 | valid on 'valid' subset:   1001 / 1907 loss=2.511, loss_v1=0, loss_v2=0, nll_loss=1.294, ntokens=242, nsentences=12, sample_size=242.0, sample_size_v1=0, sample_size_v2=0
2023-04-08 18:41:07 - progress_bar.py[line:272] - INFO: epoch 004 | valid on 'valid' subset:   1011 / 1907 loss=2.423, loss_v1=0, loss_v2=0, nll_loss=1.195, ntokens=359, nsentences=12, sample_size=359.0, sample_size_v1=0, sample_size_v2=0
2023-04-08 18:41:27 - progress_bar.py[line:272] - INFO: epoch 004 | valid on 'valid' subset:   1021 / 1907 loss=2.556, loss_v1=0, loss_v2=0, nll_loss=1.348, ntokens=363, nsentences=12, sample_size=363.0, sample_size_v1=0, sample_size_v2=0
2023-04-08 18:41:46 - progress_bar.py[line:272] - INFO: epoch 004 | valid on 'valid' subset:   1031 / 1907 loss=2.463, loss_v1=0, loss_v2=0, nll_loss=1.239, ntokens=354, nsentences=12, sample_size=354.0, sample_size_v1=0, sample_size_v2=0
2023-04-08 18:42:05 - progress_bar.py[line:272] - INFO: epoch 004 | valid on 'valid' subset:   1041 / 1907 loss=2.392, loss_v1=0, loss_v2=0, nll_loss=1.163, ntokens=362, nsentences=12, sample_size=362.0, sample_size_v1=0, sample_size_v2=0
2023-04-08 18:42:24 - progress_bar.py[line:272] - INFO: epoch 004 | valid on 'valid' subset:   1051 / 1907 loss=2.549, loss_v1=0, loss_v2=0, nll_loss=1.339, ntokens=318, nsentences=12, sample_size=318.0, sample_size_v1=0, sample_size_v2=0
2023-04-08 18:42:44 - progress_bar.py[line:272] - INFO: epoch 004 | valid on 'valid' subset:   1061 / 1907 loss=2.36, loss_v1=0, loss_v2=0, nll_loss=1.125, ntokens=426, nsentences=12, sample_size=426.0, sample_size_v1=0, sample_size_v2=0
2023-04-08 18:43:04 - progress_bar.py[line:272] - INFO: epoch 004 | valid on 'valid' subset:   1071 / 1907 loss=2.515, loss_v1=0, loss_v2=0, nll_loss=1.295, ntokens=269, nsentences=12, sample_size=269.0, sample_size_v1=0, sample_size_v2=0
2023-04-08 18:43:24 - progress_bar.py[line:272] - INFO: epoch 004 | valid on 'valid' subset:   1081 / 1907 loss=2.463, loss_v1=0, loss_v2=0, nll_loss=1.237, ntokens=282, nsentences=12, sample_size=282.0, sample_size_v1=0, sample_size_v2=0
2023-04-08 18:43:43 - progress_bar.py[line:272] - INFO: epoch 004 | valid on 'valid' subset:   1091 / 1907 loss=2.443, loss_v1=0, loss_v2=0, nll_loss=1.218, ntokens=297, nsentences=12, sample_size=297.0, sample_size_v1=0, sample_size_v2=0
2023-04-08 18:44:03 - progress_bar.py[line:272] - INFO: epoch 004 | valid on 'valid' subset:   1101 / 1907 loss=2.494, loss_v1=0, loss_v2=0, nll_loss=1.276, ntokens=373, nsentences=12, sample_size=373.0, sample_size_v1=0, sample_size_v2=0
2023-04-08 18:44:22 - progress_bar.py[line:272] - INFO: epoch 004 | valid on 'valid' subset:   1111 / 1907 loss=2.496, loss_v1=0, loss_v2=0, nll_loss=1.278, ntokens=351, nsentences=12, sample_size=351.0, sample_size_v1=0, sample_size_v2=0
2023-04-08 18:44:42 - progress_bar.py[line:272] - INFO: epoch 004 | valid on 'valid' subset:   1121 / 1907 loss=2.594, loss_v1=0, loss_v2=0, nll_loss=1.384, ntokens=268, nsentences=12, sample_size=268.0, sample_size_v1=0, sample_size_v2=0
2023-04-08 18:45:01 - progress_bar.py[line:272] - INFO: epoch 004 | valid on 'valid' subset:   1131 / 1907 loss=2.548, loss_v1=0, loss_v2=0, nll_loss=1.336, ntokens=253, nsentences=12, sample_size=253.0, sample_size_v1=0, sample_size_v2=0
2023-04-08 18:45:20 - progress_bar.py[line:272] - INFO: epoch 004 | valid on 'valid' subset:   1141 / 1907 loss=2.577, loss_v1=0, loss_v2=0, nll_loss=1.368, ntokens=326, nsentences=12, sample_size=326.0, sample_size_v1=0, sample_size_v2=0
2023-04-08 18:45:40 - progress_bar.py[line:272] - INFO: epoch 004 | valid on 'valid' subset:   1151 / 1907 loss=2.554, loss_v1=0, loss_v2=0, nll_loss=1.343, ntokens=334, nsentences=12, sample_size=334.0, sample_size_v1=0, sample_size_v2=0
2023-04-08 18:45:59 - progress_bar.py[line:272] - INFO: epoch 004 | valid on 'valid' subset:   1161 / 1907 loss=2.514, loss_v1=0, loss_v2=0, nll_loss=1.301, ntokens=346, nsentences=12, sample_size=346.0, sample_size_v1=0, sample_size_v2=0
2023-04-08 18:46:18 - progress_bar.py[line:272] - INFO: epoch 004 | valid on 'valid' subset:   1171 / 1907 loss=2.436, loss_v1=0, loss_v2=0, nll_loss=1.207, ntokens=391, nsentences=12, sample_size=391.0, sample_size_v1=0, sample_size_v2=0
2023-04-08 18:46:37 - progress_bar.py[line:272] - INFO: epoch 004 | valid on 'valid' subset:   1181 / 1907 loss=2.497, loss_v1=0, loss_v2=0, nll_loss=1.279, ntokens=212, nsentences=12, sample_size=212.0, sample_size_v1=0, sample_size_v2=0
2023-04-08 18:46:56 - progress_bar.py[line:272] - INFO: epoch 004 | valid on 'valid' subset:   1191 / 1907 loss=2.49, loss_v1=0, loss_v2=0, nll_loss=1.271, ntokens=536, nsentences=12, sample_size=536.0, sample_size_v1=0, sample_size_v2=0
2023-04-08 18:47:16 - progress_bar.py[line:272] - INFO: epoch 004 | valid on 'valid' subset:   1201 / 1907 loss=2.451, loss_v1=0, loss_v2=0, nll_loss=1.225, ntokens=376, nsentences=12, sample_size=376.0, sample_size_v1=0, sample_size_v2=0
2023-04-08 18:47:35 - progress_bar.py[line:272] - INFO: epoch 004 | valid on 'valid' subset:   1211 / 1907 loss=2.492, loss_v1=0, loss_v2=0, nll_loss=1.272, ntokens=240, nsentences=12, sample_size=240.0, sample_size_v1=0, sample_size_v2=0
2023-04-08 18:47:54 - progress_bar.py[line:272] - INFO: epoch 004 | valid on 'valid' subset:   1221 / 1907 loss=2.501, loss_v1=0, loss_v2=0, nll_loss=1.282, ntokens=297, nsentences=12, sample_size=297.0, sample_size_v1=0, sample_size_v2=0
2023-04-08 18:48:14 - progress_bar.py[line:272] - INFO: epoch 004 | valid on 'valid' subset:   1231 / 1907 loss=2.5, loss_v1=0, loss_v2=0, nll_loss=1.281, ntokens=288, nsentences=12, sample_size=288.0, sample_size_v1=0, sample_size_v2=0
2023-04-08 18:48:33 - progress_bar.py[line:272] - INFO: epoch 004 | valid on 'valid' subset:   1241 / 1907 loss=2.51, loss_v1=0, loss_v2=0, nll_loss=1.291, ntokens=288, nsentences=12, sample_size=288.0, sample_size_v1=0, sample_size_v2=0
2023-04-08 18:48:53 - progress_bar.py[line:272] - INFO: epoch 004 | valid on 'valid' subset:   1251 / 1907 loss=2.363, loss_v1=0, loss_v2=0, nll_loss=1.129, ntokens=290, nsentences=12, sample_size=290.0, sample_size_v1=0, sample_size_v2=0
2023-04-08 18:49:12 - progress_bar.py[line:272] - INFO: epoch 004 | valid on 'valid' subset:   1261 / 1907 loss=2.408, loss_v1=0, loss_v2=0, nll_loss=1.177, ntokens=278, nsentences=12, sample_size=278.0, sample_size_v1=0, sample_size_v2=0
2023-04-08 18:49:31 - progress_bar.py[line:272] - INFO: epoch 004 | valid on 'valid' subset:   1271 / 1907 loss=2.398, loss_v1=0, loss_v2=0, nll_loss=1.171, ntokens=309, nsentences=12, sample_size=309.0, sample_size_v1=0, sample_size_v2=0
2023-04-08 18:49:49 - progress_bar.py[line:272] - INFO: epoch 004 | valid on 'valid' subset:   1281 / 1907 loss=2.501, loss_v1=0, loss_v2=0, nll_loss=1.285, ntokens=247, nsentences=12, sample_size=247.0, sample_size_v1=0, sample_size_v2=0
2023-04-08 18:50:08 - progress_bar.py[line:272] - INFO: epoch 004 | valid on 'valid' subset:   1291 / 1907 loss=2.455, loss_v1=0, loss_v2=0, nll_loss=1.234, ntokens=259, nsentences=12, sample_size=259.0, sample_size_v1=0, sample_size_v2=0
2023-04-08 18:50:27 - progress_bar.py[line:272] - INFO: epoch 004 | valid on 'valid' subset:   1301 / 1907 loss=2.517, loss_v1=0, loss_v2=0, nll_loss=1.303, ntokens=253, nsentences=12, sample_size=253.0, sample_size_v1=0, sample_size_v2=0
2023-04-08 18:50:46 - progress_bar.py[line:272] - INFO: epoch 004 | valid on 'valid' subset:   1311 / 1907 loss=2.66, loss_v1=0, loss_v2=0, nll_loss=1.461, ntokens=253, nsentences=12, sample_size=253.0, sample_size_v1=0, sample_size_v2=0
2023-04-08 18:51:05 - progress_bar.py[line:272] - INFO: epoch 004 | valid on 'valid' subset:   1321 / 1907 loss=2.511, loss_v1=0, loss_v2=0, nll_loss=1.291, ntokens=241, nsentences=12, sample_size=241.0, sample_size_v1=0, sample_size_v2=0
2023-04-08 18:51:24 - progress_bar.py[line:272] - INFO: epoch 004 | valid on 'valid' subset:   1331 / 1907 loss=2.496, loss_v1=0, loss_v2=0, nll_loss=1.279, ntokens=356, nsentences=12, sample_size=356.0, sample_size_v1=0, sample_size_v2=0
2023-04-08 18:51:44 - progress_bar.py[line:272] - INFO: epoch 004 | valid on 'valid' subset:   1341 / 1907 loss=2.542, loss_v1=0, loss_v2=0, nll_loss=1.328, ntokens=335, nsentences=12, sample_size=335.0, sample_size_v1=0, sample_size_v2=0
2023-04-08 18:52:03 - progress_bar.py[line:272] - INFO: epoch 004 | valid on 'valid' subset:   1351 / 1907 loss=2.469, loss_v1=0, loss_v2=0, nll_loss=1.249, ntokens=331, nsentences=12, sample_size=331.0, sample_size_v1=0, sample_size_v2=0
2023-04-08 18:52:21 - progress_bar.py[line:272] - INFO: epoch 004 | valid on 'valid' subset:   1361 / 1907 loss=2.385, loss_v1=0, loss_v2=0, nll_loss=1.154, ntokens=219, nsentences=12, sample_size=219.0, sample_size_v1=0, sample_size_v2=0
2023-04-08 18:52:40 - progress_bar.py[line:272] - INFO: epoch 004 | valid on 'valid' subset:   1371 / 1907 loss=2.457, loss_v1=0, loss_v2=0, nll_loss=1.233, ntokens=292, nsentences=12, sample_size=292.0, sample_size_v1=0, sample_size_v2=0
2023-04-08 18:52:59 - progress_bar.py[line:272] - INFO: epoch 004 | valid on 'valid' subset:   1381 / 1907 loss=2.406, loss_v1=0, loss_v2=0, nll_loss=1.178, ntokens=314, nsentences=12, sample_size=314.0, sample_size_v1=0, sample_size_v2=0
2023-04-08 18:53:18 - progress_bar.py[line:272] - INFO: epoch 004 | valid on 'valid' subset:   1391 / 1907 loss=2.308, loss_v1=0, loss_v2=0, nll_loss=1.066, ntokens=275, nsentences=12, sample_size=275.0, sample_size_v1=0, sample_size_v2=0
2023-04-08 18:53:37 - progress_bar.py[line:272] - INFO: epoch 004 | valid on 'valid' subset:   1401 / 1907 loss=2.549, loss_v1=0, loss_v2=0, nll_loss=1.339, ntokens=230, nsentences=12, sample_size=230.0, sample_size_v1=0, sample_size_v2=0
2023-04-08 18:53:54 - progress_bar.py[line:272] - INFO: epoch 004 | valid on 'valid' subset:   1411 / 1907 loss=2.616, loss_v1=0, loss_v2=0, nll_loss=1.413, ntokens=321, nsentences=12, sample_size=321.0, sample_size_v1=0, sample_size_v2=0
2023-04-08 18:54:13 - progress_bar.py[line:272] - INFO: epoch 004 | valid on 'valid' subset:   1421 / 1907 loss=2.399, loss_v1=0, loss_v2=0, nll_loss=1.165, ntokens=309, nsentences=12, sample_size=309.0, sample_size_v1=0, sample_size_v2=0
2023-04-08 18:54:32 - progress_bar.py[line:272] - INFO: epoch 004 | valid on 'valid' subset:   1431 / 1907 loss=2.46, loss_v1=0, loss_v2=0, nll_loss=1.237, ntokens=313, nsentences=12, sample_size=313.0, sample_size_v1=0, sample_size_v2=0
2023-04-08 18:54:52 - progress_bar.py[line:272] - INFO: epoch 004 | valid on 'valid' subset:   1441 / 1907 loss=2.502, loss_v1=0, loss_v2=0, nll_loss=1.283, ntokens=329, nsentences=12, sample_size=329.0, sample_size_v1=0, sample_size_v2=0
2023-04-08 18:55:11 - progress_bar.py[line:272] - INFO: epoch 004 | valid on 'valid' subset:   1451 / 1907 loss=2.454, loss_v1=0, loss_v2=0, nll_loss=1.23, ntokens=383, nsentences=12, sample_size=383.0, sample_size_v1=0, sample_size_v2=0
2023-04-08 18:55:30 - progress_bar.py[line:272] - INFO: epoch 004 | valid on 'valid' subset:   1461 / 1907 loss=2.553, loss_v1=0, loss_v2=0, nll_loss=1.337, ntokens=245, nsentences=12, sample_size=245.0, sample_size_v1=0, sample_size_v2=0
2023-04-08 18:55:50 - progress_bar.py[line:272] - INFO: epoch 004 | valid on 'valid' subset:   1471 / 1907 loss=2.467, loss_v1=0, loss_v2=0, nll_loss=1.245, ntokens=279, nsentences=12, sample_size=279.0, sample_size_v1=0, sample_size_v2=0
2023-04-08 18:56:09 - progress_bar.py[line:272] - INFO: epoch 004 | valid on 'valid' subset:   1481 / 1907 loss=2.566, loss_v1=0, loss_v2=0, nll_loss=1.36, ntokens=268, nsentences=12, sample_size=268.0, sample_size_v1=0, sample_size_v2=0
2023-04-08 18:56:28 - progress_bar.py[line:272] - INFO: epoch 004 | valid on 'valid' subset:   1491 / 1907 loss=2.732, loss_v1=0, loss_v2=0, nll_loss=1.543, ntokens=274, nsentences=12, sample_size=274.0, sample_size_v1=0, sample_size_v2=0
2023-04-08 18:56:48 - progress_bar.py[line:272] - INFO: epoch 004 | valid on 'valid' subset:   1501 / 1907 loss=2.578, loss_v1=0, loss_v2=0, nll_loss=1.367, ntokens=317, nsentences=12, sample_size=317.0, sample_size_v1=0, sample_size_v2=0
2023-04-08 18:57:07 - progress_bar.py[line:272] - INFO: epoch 004 | valid on 'valid' subset:   1511 / 1907 loss=2.607, loss_v1=0, loss_v2=0, nll_loss=1.4, ntokens=248, nsentences=12, sample_size=248.0, sample_size_v1=0, sample_size_v2=0
2023-04-08 18:57:26 - progress_bar.py[line:272] - INFO: epoch 004 | valid on 'valid' subset:   1521 / 1907 loss=2.527, loss_v1=0, loss_v2=0, nll_loss=1.313, ntokens=306, nsentences=12, sample_size=306.0, sample_size_v1=0, sample_size_v2=0
2023-04-08 18:57:44 - progress_bar.py[line:272] - INFO: epoch 004 | valid on 'valid' subset:   1531 / 1907 loss=2.499, loss_v1=0, loss_v2=0, nll_loss=1.284, ntokens=311, nsentences=12, sample_size=311.0, sample_size_v1=0, sample_size_v2=0
2023-04-08 18:58:04 - progress_bar.py[line:272] - INFO: epoch 004 | valid on 'valid' subset:   1541 / 1907 loss=2.506, loss_v1=0, loss_v2=0, nll_loss=1.291, ntokens=441, nsentences=12, sample_size=441.0, sample_size_v1=0, sample_size_v2=0
2023-04-08 18:58:23 - progress_bar.py[line:272] - INFO: epoch 004 | valid on 'valid' subset:   1551 / 1907 loss=2.606, loss_v1=0, loss_v2=0, nll_loss=1.402, ntokens=270, nsentences=12, sample_size=270.0, sample_size_v1=0, sample_size_v2=0
2023-04-08 18:58:42 - progress_bar.py[line:272] - INFO: epoch 004 | valid on 'valid' subset:   1561 / 1907 loss=2.434, loss_v1=0, loss_v2=0, nll_loss=1.21, ntokens=371, nsentences=12, sample_size=371.0, sample_size_v1=0, sample_size_v2=0
2023-04-08 18:59:01 - progress_bar.py[line:272] - INFO: epoch 004 | valid on 'valid' subset:   1571 / 1907 loss=2.352, loss_v1=0, loss_v2=0, nll_loss=1.12, ntokens=396, nsentences=12, sample_size=396.0, sample_size_v1=0, sample_size_v2=0
2023-04-08 18:59:20 - progress_bar.py[line:272] - INFO: epoch 004 | valid on 'valid' subset:   1581 / 1907 loss=2.566, loss_v1=0, loss_v2=0, nll_loss=1.358, ntokens=411, nsentences=12, sample_size=411.0, sample_size_v1=0, sample_size_v2=0
2023-04-08 18:59:40 - progress_bar.py[line:272] - INFO: epoch 004 | valid on 'valid' subset:   1591 / 1907 loss=2.663, loss_v1=0, loss_v2=0, nll_loss=1.466, ntokens=282, nsentences=12, sample_size=282.0, sample_size_v1=0, sample_size_v2=0
2023-04-08 18:59:59 - progress_bar.py[line:272] - INFO: epoch 004 | valid on 'valid' subset:   1601 / 1907 loss=2.611, loss_v1=0, loss_v2=0, nll_loss=1.408, ntokens=399, nsentences=12, sample_size=399.0, sample_size_v1=0, sample_size_v2=0
2023-04-08 19:00:18 - progress_bar.py[line:272] - INFO: epoch 004 | valid on 'valid' subset:   1611 / 1907 loss=2.494, loss_v1=0, loss_v2=0, nll_loss=1.276, ntokens=343, nsentences=12, sample_size=343.0, sample_size_v1=0, sample_size_v2=0
2023-04-08 19:00:37 - progress_bar.py[line:272] - INFO: epoch 004 | valid on 'valid' subset:   1621 / 1907 loss=2.563, loss_v1=0, loss_v2=0, nll_loss=1.353, ntokens=309, nsentences=12, sample_size=309.0, sample_size_v1=0, sample_size_v2=0
2023-04-08 19:00:57 - progress_bar.py[line:272] - INFO: epoch 004 | valid on 'valid' subset:   1631 / 1907 loss=2.597, loss_v1=0, loss_v2=0, nll_loss=1.391, ntokens=270, nsentences=12, sample_size=270.0, sample_size_v1=0, sample_size_v2=0
2023-04-08 19:01:16 - progress_bar.py[line:272] - INFO: epoch 004 | valid on 'valid' subset:   1641 / 1907 loss=2.554, loss_v1=0, loss_v2=0, nll_loss=1.344, ntokens=359, nsentences=12, sample_size=359.0, sample_size_v1=0, sample_size_v2=0
2023-04-08 19:01:35 - progress_bar.py[line:272] - INFO: epoch 004 | valid on 'valid' subset:   1651 / 1907 loss=2.55, loss_v1=0, loss_v2=0, nll_loss=1.338, ntokens=268, nsentences=12, sample_size=268.0, sample_size_v1=0, sample_size_v2=0
2023-04-08 19:01:54 - progress_bar.py[line:272] - INFO: epoch 004 | valid on 'valid' subset:   1661 / 1907 loss=2.489, loss_v1=0, loss_v2=0, nll_loss=1.272, ntokens=300, nsentences=12, sample_size=300.0, sample_size_v1=0, sample_size_v2=0
2023-04-08 19:02:13 - progress_bar.py[line:272] - INFO: epoch 004 | valid on 'valid' subset:   1671 / 1907 loss=2.546, loss_v1=0, loss_v2=0, nll_loss=1.332, ntokens=282, nsentences=12, sample_size=282.0, sample_size_v1=0, sample_size_v2=0
2023-04-08 19:02:32 - progress_bar.py[line:272] - INFO: epoch 004 | valid on 'valid' subset:   1681 / 1907 loss=2.394, loss_v1=0, loss_v2=0, nll_loss=1.166, ntokens=244, nsentences=12, sample_size=244.0, sample_size_v1=0, sample_size_v2=0
2023-04-08 19:02:52 - progress_bar.py[line:272] - INFO: epoch 004 | valid on 'valid' subset:   1691 / 1907 loss=2.416, loss_v1=0, loss_v2=0, nll_loss=1.189, ntokens=285, nsentences=12, sample_size=285.0, sample_size_v1=0, sample_size_v2=0
2023-04-08 19:03:11 - progress_bar.py[line:272] - INFO: epoch 004 | valid on 'valid' subset:   1701 / 1907 loss=2.482, loss_v1=0, loss_v2=0, nll_loss=1.265, ntokens=364, nsentences=12, sample_size=364.0, sample_size_v1=0, sample_size_v2=0
2023-04-08 19:03:30 - progress_bar.py[line:272] - INFO: epoch 004 | valid on 'valid' subset:   1711 / 1907 loss=2.533, loss_v1=0, loss_v2=0, nll_loss=1.32, ntokens=234, nsentences=12, sample_size=234.0, sample_size_v1=0, sample_size_v2=0
2023-04-08 19:03:50 - progress_bar.py[line:272] - INFO: epoch 004 | valid on 'valid' subset:   1721 / 1907 loss=2.589, loss_v1=0, loss_v2=0, nll_loss=1.384, ntokens=190, nsentences=12, sample_size=190.0, sample_size_v1=0, sample_size_v2=0
2023-04-08 19:04:09 - progress_bar.py[line:272] - INFO: epoch 004 | valid on 'valid' subset:   1731 / 1907 loss=2.376, loss_v1=0, loss_v2=0, nll_loss=1.146, ntokens=255, nsentences=12, sample_size=255.0, sample_size_v1=0, sample_size_v2=0
2023-04-08 19:04:29 - progress_bar.py[line:272] - INFO: epoch 004 | valid on 'valid' subset:   1741 / 1907 loss=2.384, loss_v1=0, loss_v2=0, nll_loss=1.152, ntokens=337, nsentences=12, sample_size=337.0, sample_size_v1=0, sample_size_v2=0
2023-04-08 19:04:48 - progress_bar.py[line:272] - INFO: epoch 004 | valid on 'valid' subset:   1751 / 1907 loss=2.545, loss_v1=0, loss_v2=0, nll_loss=1.332, ntokens=233, nsentences=12, sample_size=233.0, sample_size_v1=0, sample_size_v2=0
2023-04-08 19:05:07 - progress_bar.py[line:272] - INFO: epoch 004 | valid on 'valid' subset:   1761 / 1907 loss=2.487, loss_v1=0, loss_v2=0, nll_loss=1.267, ntokens=298, nsentences=12, sample_size=298.0, sample_size_v1=0, sample_size_v2=0
2023-04-08 19:05:27 - progress_bar.py[line:272] - INFO: epoch 004 | valid on 'valid' subset:   1771 / 1907 loss=2.357, loss_v1=0, loss_v2=0, nll_loss=1.123, ntokens=253, nsentences=12, sample_size=253.0, sample_size_v1=0, sample_size_v2=0
2023-04-08 19:05:46 - progress_bar.py[line:272] - INFO: epoch 004 | valid on 'valid' subset:   1781 / 1907 loss=2.378, loss_v1=0, loss_v2=0, nll_loss=1.146, ntokens=287, nsentences=12, sample_size=287.0, sample_size_v1=0, sample_size_v2=0
2023-04-08 19:06:05 - progress_bar.py[line:272] - INFO: epoch 004 | valid on 'valid' subset:   1791 / 1907 loss=2.379, loss_v1=0, loss_v2=0, nll_loss=1.143, ntokens=230, nsentences=12, sample_size=230.0, sample_size_v1=0, sample_size_v2=0
2023-04-08 19:06:24 - progress_bar.py[line:272] - INFO: epoch 004 | valid on 'valid' subset:   1801 / 1907 loss=2.674, loss_v1=0, loss_v2=0, nll_loss=1.481, ntokens=216, nsentences=12, sample_size=216.0, sample_size_v1=0, sample_size_v2=0
2023-04-08 19:06:43 - progress_bar.py[line:272] - INFO: epoch 004 | valid on 'valid' subset:   1811 / 1907 loss=2.48, loss_v1=0, loss_v2=0, nll_loss=1.26, ntokens=285, nsentences=12, sample_size=285.0, sample_size_v1=0, sample_size_v2=0
2023-04-08 19:07:02 - progress_bar.py[line:272] - INFO: epoch 004 | valid on 'valid' subset:   1821 / 1907 loss=2.492, loss_v1=0, loss_v2=0, nll_loss=1.27, ntokens=300, nsentences=12, sample_size=300.0, sample_size_v1=0, sample_size_v2=0
2023-04-08 19:07:22 - progress_bar.py[line:272] - INFO: epoch 004 | valid on 'valid' subset:   1831 / 1907 loss=2.341, loss_v1=0, loss_v2=0, nll_loss=1.104, ntokens=422, nsentences=12, sample_size=422.0, sample_size_v1=0, sample_size_v2=0
2023-04-08 19:07:42 - progress_bar.py[line:272] - INFO: epoch 004 | valid on 'valid' subset:   1841 / 1907 loss=2.508, loss_v1=0, loss_v2=0, nll_loss=1.29, ntokens=275, nsentences=12, sample_size=275.0, sample_size_v1=0, sample_size_v2=0
2023-04-08 19:08:01 - progress_bar.py[line:272] - INFO: epoch 004 | valid on 'valid' subset:   1851 / 1907 loss=2.426, loss_v1=0, loss_v2=0, nll_loss=1.202, ntokens=273, nsentences=12, sample_size=273.0, sample_size_v1=0, sample_size_v2=0
2023-04-08 19:08:21 - progress_bar.py[line:272] - INFO: epoch 004 | valid on 'valid' subset:   1861 / 1907 loss=2.465, loss_v1=0, loss_v2=0, nll_loss=1.239, ntokens=278, nsentences=12, sample_size=278.0, sample_size_v1=0, sample_size_v2=0
2023-04-08 19:08:40 - progress_bar.py[line:272] - INFO: epoch 004 | valid on 'valid' subset:   1871 / 1907 loss=2.333, loss_v1=0, loss_v2=0, nll_loss=1.096, ntokens=385, nsentences=12, sample_size=385.0, sample_size_v1=0, sample_size_v2=0
2023-04-08 19:08:59 - progress_bar.py[line:272] - INFO: epoch 004 | valid on 'valid' subset:   1881 / 1907 loss=2.435, loss_v1=0, loss_v2=0, nll_loss=1.211, ntokens=359, nsentences=12, sample_size=359.0, sample_size_v1=0, sample_size_v2=0
2023-04-08 19:09:19 - progress_bar.py[line:272] - INFO: epoch 004 | valid on 'valid' subset:   1891 / 1907 loss=2.512, loss_v1=0, loss_v2=0, nll_loss=1.293, ntokens=268, nsentences=12, sample_size=268.0, sample_size_v1=0, sample_size_v2=0
2023-04-08 19:09:38 - progress_bar.py[line:272] - INFO: epoch 004 | valid on 'valid' subset:   1901 / 1907 loss=2.597, loss_v1=0, loss_v2=0, nll_loss=1.391, ntokens=351, nsentences=12, sample_size=351.0, sample_size_v1=0, sample_size_v2=0
local datafile ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 1 begin to initialize row_count and line_idx-to-offset mapping
2023-04-08 19:09:49 - progress_bar.py[line:282] - INFO: epoch 004 | valid on 'valid' subset | loss 2.486 | loss_v1 0 | loss_v2 0 | nll_loss 1.266 | ntokens 323.198 | nsentences 11.998 | sample_size 323.198 | sample_size_v1 0 | sample_size_v2 0 | ppl 2.41 | wps 155.5 | wpb 323.2 | bsz 12 | num_updates 2309
2023-04-08 19:09:49 - checkpoint_utils.py[line:64] - INFO: Preparing to save checkpoint for epoch 4 @ 2309 updates
2023-04-08 19:09:49 - trainer.py[line:431] - INFO: Saving checkpoint to ../../checkpoints/OFA/sgcls_checkpoints/_12_3e-5_512/checkpoint_best.pt
local datafile ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 1 finished initializing row_count and line_idx-to-offset mapping
file ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 1 row count 27700 total row count 55400
slice_id 1 seek offset 27700
2023-04-08 19:09:55 - trainer.py[line:441] - INFO: Finished saving checkpoint to ../../checkpoints/OFA/sgcls_checkpoints/_12_3e-5_512/checkpoint_best.pt
2023-04-08 19:10:02 - checkpoint_utils.py[line:133] - INFO: Saved checkpoint ../../checkpoints/OFA/sgcls_checkpoints/_12_3e-5_512/checkpoint_best.pt (epoch 4 @ 2309 updates, score 2.486) (writing took 13.00573756173253 seconds)
2023-04-08 19:10:02 - train.py[line:332] - INFO: end of epoch 4 (average epoch stats below)
2023-04-08 19:10:02 - progress_bar.py[line:282] - INFO: epoch 004 | loss 2.51 | loss_v1 0 | loss_v2 0 | nll_loss 1.327 | ntokens 2520.05 | nsentences 95.847 | sample_size 2520.05 | sample_size_v1 0 | sample_size_v2 0 | ppl 2.51 | wps 249.3 | ups 0.1 | wpb 2520.1 | bsz 95.8 | num_updates 2309 | lr 2.12899e-05 | gnorm 1.25 | clip 98.6 | loss_scale 256 | train_wall 1852 | gb_free 13.1 | wall 11231
2023-04-08 19:10:02 - trainer.py[line:639] - INFO: loading train data for epoch 5
local datafile ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 0 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 0 finished initializing row_count and line_idx-to-offset mapping
file ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 0 row count 27700 total row count 55400
slice_id 0 seek offset 0
2023-04-08 19:10:04 - trainer.py[line:703] - INFO: begin training epoch 5
2023-04-08 19:10:04 - train.py[line:305] - INFO: Start iterating over samples
2023-04-08 19:10:07 - progress_bar.py[line:272] - INFO: epoch 005:      1 / 578 loss=2.508, loss_v1=0, loss_v2=0, nll_loss=1.323, ntokens=2355.2, nsentences=87.2, sample_size=2355.2, sample_size_v1=0, sample_size_v2=0, ppl=2.5, wps=5.9, ups=0, wpb=2355.2, bsz=87.2, num_updates=2310, lr=2.12853e-05, gnorm=1.541, clip=100, loss_scale=256, train_wall=28, gb_free=12.3, wall=11236
2023-04-08 19:10:35 - progress_bar.py[line:272] - INFO: epoch 005:     11 / 578 loss=2.476, loss_v1=0, loss_v2=0, nll_loss=1.288, ntokens=2425.2, nsentences=96, sample_size=2425.2, sample_size_v1=0, sample_size_v2=0, ppl=2.44, wps=847.3, ups=0.35, wpb=2425.2, bsz=96, num_updates=2320, lr=2.12393e-05, gnorm=1.401, clip=100, loss_scale=256, train_wall=29, gb_free=12.4, wall=11265
2023-04-08 19:11:04 - progress_bar.py[line:272] - INFO: epoch 005:     21 / 578 loss=2.474, loss_v1=0, loss_v2=0, nll_loss=1.287, ntokens=2348.2, nsentences=96, sample_size=2348.2, sample_size_v1=0, sample_size_v2=0, ppl=2.44, wps=824, ups=0.35, wpb=2348.2, bsz=96, num_updates=2330, lr=2.11933e-05, gnorm=1.389, clip=100, loss_scale=256, train_wall=28, gb_free=12, wall=11294
2023-04-08 19:11:33 - progress_bar.py[line:272] - INFO: epoch 005:     31 / 578 loss=2.475, loss_v1=0, loss_v2=0, nll_loss=1.288, ntokens=2289.3, nsentences=96, sample_size=2289.3, sample_size_v1=0, sample_size_v2=0, ppl=2.44, wps=797.5, ups=0.35, wpb=2289.3, bsz=96, num_updates=2340, lr=2.11472e-05, gnorm=1.449, clip=100, loss_scale=256, train_wall=29, gb_free=12.3, wall=11322
2023-04-08 19:12:01 - progress_bar.py[line:272] - INFO: epoch 005:     41 / 578 loss=2.455, loss_v1=0, loss_v2=0, nll_loss=1.265, ntokens=2191.7, nsentences=96, sample_size=2191.7, sample_size_v1=0, sample_size_v2=0, ppl=2.4, wps=763.3, ups=0.35, wpb=2191.7, bsz=96, num_updates=2350, lr=2.11012e-05, gnorm=1.558, clip=100, loss_scale=256, train_wall=29, gb_free=11.7, wall=11351
2023-04-08 19:12:31 - progress_bar.py[line:272] - INFO: epoch 005:     51 / 578 loss=2.457, loss_v1=0, loss_v2=0, nll_loss=1.267, ntokens=2411.2, nsentences=96, sample_size=2411.2, sample_size_v1=0, sample_size_v2=0, ppl=2.41, wps=824.4, ups=0.34, wpb=2411.2, bsz=96, num_updates=2360, lr=2.10552e-05, gnorm=1.426, clip=100, loss_scale=256, train_wall=29, gb_free=11.7, wall=11380
2023-04-08 19:12:59 - progress_bar.py[line:272] - INFO: epoch 005:     61 / 578 loss=2.508, loss_v1=0, loss_v2=0, nll_loss=1.324, ntokens=2277.5, nsentences=96, sample_size=2277.5, sample_size_v1=0, sample_size_v2=0, ppl=2.5, wps=790.3, ups=0.35, wpb=2277.5, bsz=96, num_updates=2370, lr=2.10092e-05, gnorm=1.342, clip=100, loss_scale=256, train_wall=29, gb_free=12.5, wall=11409
2023-04-08 19:13:28 - progress_bar.py[line:272] - INFO: epoch 005:     71 / 578 loss=2.502, loss_v1=0, loss_v2=0, nll_loss=1.319, ntokens=2326.6, nsentences=96, sample_size=2326.6, sample_size_v1=0, sample_size_v2=0, ppl=2.49, wps=819.3, ups=0.35, wpb=2326.6, bsz=96, num_updates=2380, lr=2.09632e-05, gnorm=1.507, clip=100, loss_scale=256, train_wall=28, gb_free=11.7, wall=11437
2023-04-08 19:13:57 - progress_bar.py[line:272] - INFO: epoch 005:     81 / 578 loss=2.499, loss_v1=0, loss_v2=0, nll_loss=1.313, ntokens=2530.1, nsentences=96, sample_size=2530.1, sample_size_v1=0, sample_size_v2=0, ppl=2.48, wps=878.7, ups=0.35, wpb=2530.1, bsz=96, num_updates=2390, lr=2.09172e-05, gnorm=1.318, clip=100, loss_scale=256, train_wall=29, gb_free=12.2, wall=11466
2023-04-08 19:14:26 - progress_bar.py[line:272] - INFO: epoch 005:     91 / 578 loss=2.499, loss_v1=0, loss_v2=0, nll_loss=1.314, ntokens=2516.1, nsentences=96, sample_size=2516.1, sample_size_v1=0, sample_size_v2=0, ppl=2.49, wps=869.6, ups=0.35, wpb=2516.1, bsz=96, num_updates=2400, lr=2.08712e-05, gnorm=1.327, clip=100, loss_scale=256, train_wall=29, gb_free=11.9, wall=11495
2023-04-08 19:14:55 - progress_bar.py[line:272] - INFO: epoch 005:    101 / 578 loss=2.489, loss_v1=0, loss_v2=0, nll_loss=1.304, ntokens=2422.6, nsentences=96, sample_size=2422.6, sample_size_v1=0, sample_size_v2=0, ppl=2.47, wps=833.5, ups=0.34, wpb=2422.6, bsz=96, num_updates=2410, lr=2.08252e-05, gnorm=1.351, clip=100, loss_scale=256, train_wall=29, gb_free=11.5, wall=11524
2023-04-08 19:15:23 - progress_bar.py[line:272] - INFO: epoch 005:    111 / 578 loss=2.5, loss_v1=0, loss_v2=0, nll_loss=1.315, ntokens=2433, nsentences=96, sample_size=2433, sample_size_v1=0, sample_size_v2=0, ppl=2.49, wps=843.4, ups=0.35, wpb=2433, bsz=96, num_updates=2420, lr=2.07791e-05, gnorm=1.436, clip=100, loss_scale=256, train_wall=29, gb_free=11.7, wall=11553
2023-04-08 19:15:52 - progress_bar.py[line:272] - INFO: epoch 005:    121 / 578 loss=2.493, loss_v1=0, loss_v2=0, nll_loss=1.306, ntokens=2330.1, nsentences=96, sample_size=2330.1, sample_size_v1=0, sample_size_v2=0, ppl=2.47, wps=811.5, ups=0.35, wpb=2330.1, bsz=96, num_updates=2430, lr=2.07331e-05, gnorm=1.458, clip=100, loss_scale=256, train_wall=29, gb_free=12.2, wall=11582
2023-04-08 19:16:21 - progress_bar.py[line:272] - INFO: epoch 005:    131 / 578 loss=2.499, loss_v1=0, loss_v2=0, nll_loss=1.316, ntokens=2424.5, nsentences=96, sample_size=2424.5, sample_size_v1=0, sample_size_v2=0, ppl=2.49, wps=838.9, ups=0.35, wpb=2424.5, bsz=96, num_updates=2440, lr=2.06871e-05, gnorm=1.383, clip=100, loss_scale=256, train_wall=29, gb_free=12.3, wall=11611
2023-04-08 19:16:50 - progress_bar.py[line:272] - INFO: epoch 005:    141 / 578 loss=2.506, loss_v1=0, loss_v2=0, nll_loss=1.321, ntokens=2413.2, nsentences=96, sample_size=2413.2, sample_size_v1=0, sample_size_v2=0, ppl=2.5, wps=846.9, ups=0.35, wpb=2413.2, bsz=96, num_updates=2450, lr=2.06411e-05, gnorm=1.383, clip=100, loss_scale=256, train_wall=28, gb_free=12.1, wall=11639
2023-04-08 19:17:18 - progress_bar.py[line:272] - INFO: epoch 005:    151 / 578 loss=2.498, loss_v1=0, loss_v2=0, nll_loss=1.313, ntokens=2654.2, nsentences=96, sample_size=2654.2, sample_size_v1=0, sample_size_v2=0, ppl=2.49, wps=930.8, ups=0.35, wpb=2654.2, bsz=96, num_updates=2460, lr=2.05951e-05, gnorm=1.279, clip=100, loss_scale=256, train_wall=28, gb_free=12.3, wall=11668
2023-04-08 19:17:47 - progress_bar.py[line:272] - INFO: epoch 005:    161 / 578 loss=2.499, loss_v1=0, loss_v2=0, nll_loss=1.314, ntokens=2712.2, nsentences=96, sample_size=2712.2, sample_size_v1=0, sample_size_v2=0, ppl=2.49, wps=952.1, ups=0.35, wpb=2712.2, bsz=96, num_updates=2470, lr=2.05491e-05, gnorm=1.32, clip=100, loss_scale=256, train_wall=28, gb_free=12.2, wall=11696
2023-04-08 19:18:15 - progress_bar.py[line:272] - INFO: epoch 005:    171 / 578 loss=2.503, loss_v1=0, loss_v2=0, nll_loss=1.319, ntokens=2598.7, nsentences=96, sample_size=2598.7, sample_size_v1=0, sample_size_v2=0, ppl=2.49, wps=910.9, ups=0.35, wpb=2598.7, bsz=96, num_updates=2480, lr=2.05031e-05, gnorm=1.384, clip=100, loss_scale=256, train_wall=28, gb_free=12.4, wall=11725
2023-04-08 19:18:44 - progress_bar.py[line:272] - INFO: epoch 005:    181 / 578 loss=2.495, loss_v1=0, loss_v2=0, nll_loss=1.311, ntokens=2627.6, nsentences=96, sample_size=2627.6, sample_size_v1=0, sample_size_v2=0, ppl=2.48, wps=919.8, ups=0.35, wpb=2627.6, bsz=96, num_updates=2490, lr=2.04571e-05, gnorm=1.299, clip=100, loss_scale=256, train_wall=29, gb_free=12.3, wall=11753
2023-04-08 19:19:12 - progress_bar.py[line:272] - INFO: epoch 005:    191 / 578 loss=2.504, loss_v1=0, loss_v2=0, nll_loss=1.319, ntokens=2657.2, nsentences=96, sample_size=2657.2, sample_size_v1=0, sample_size_v2=0, ppl=2.5, wps=928.2, ups=0.35, wpb=2657.2, bsz=96, num_updates=2500, lr=2.0411e-05, gnorm=1.362, clip=100, loss_scale=256, train_wall=29, gb_free=11.8, wall=11782
2023-04-08 19:19:41 - progress_bar.py[line:272] - INFO: epoch 005:    201 / 578 loss=2.496, loss_v1=0, loss_v2=0, nll_loss=1.311, ntokens=2568.6, nsentences=96, sample_size=2568.6, sample_size_v1=0, sample_size_v2=0, ppl=2.48, wps=903.9, ups=0.35, wpb=2568.6, bsz=96, num_updates=2510, lr=2.0365e-05, gnorm=1.389, clip=100, loss_scale=256, train_wall=28, gb_free=12.5, wall=11810
2023-04-08 19:20:09 - progress_bar.py[line:272] - INFO: epoch 005:    211 / 578 loss=2.491, loss_v1=0, loss_v2=0, nll_loss=1.307, ntokens=2514.1, nsentences=96, sample_size=2514.1, sample_size_v1=0, sample_size_v2=0, ppl=2.47, wps=887.4, ups=0.35, wpb=2514.1, bsz=96, num_updates=2520, lr=2.0319e-05, gnorm=1.394, clip=100, loss_scale=256, train_wall=28, gb_free=12.2, wall=11839
2023-04-08 19:20:37 - progress_bar.py[line:272] - INFO: epoch 005:    221 / 578 loss=2.503, loss_v1=0, loss_v2=0, nll_loss=1.318, ntokens=2574.1, nsentences=96, sample_size=2574.1, sample_size_v1=0, sample_size_v2=0, ppl=2.49, wps=906.3, ups=0.35, wpb=2574.1, bsz=96, num_updates=2530, lr=2.0273e-05, gnorm=1.389, clip=100, loss_scale=256, train_wall=28, gb_free=12.1, wall=11867
2023-04-08 19:21:06 - progress_bar.py[line:272] - INFO: epoch 005:    231 / 578 loss=2.473, loss_v1=0, loss_v2=0, nll_loss=1.286, ntokens=2443.6, nsentences=96, sample_size=2443.6, sample_size_v1=0, sample_size_v2=0, ppl=2.44, wps=863.8, ups=0.35, wpb=2443.6, bsz=96, num_updates=2540, lr=2.0227e-05, gnorm=1.408, clip=100, loss_scale=256, train_wall=28, gb_free=12.5, wall=11895
2023-04-08 19:21:34 - progress_bar.py[line:272] - INFO: epoch 005:    241 / 578 loss=2.505, loss_v1=0, loss_v2=0, nll_loss=1.319, ntokens=2489.2, nsentences=96, sample_size=2489.2, sample_size_v1=0, sample_size_v2=0, ppl=2.5, wps=880.4, ups=0.35, wpb=2489.2, bsz=96, num_updates=2550, lr=2.0181e-05, gnorm=1.396, clip=100, loss_scale=256, train_wall=28, gb_free=12.4, wall=11924
2023-04-08 19:22:02 - progress_bar.py[line:272] - INFO: epoch 005:    251 / 578 loss=2.491, loss_v1=0, loss_v2=0, nll_loss=1.308, ntokens=2535.5, nsentences=96, sample_size=2535.5, sample_size_v1=0, sample_size_v2=0, ppl=2.48, wps=895.6, ups=0.35, wpb=2535.5, bsz=96, num_updates=2560, lr=2.0135e-05, gnorm=1.403, clip=100, loss_scale=256, train_wall=28, gb_free=12.3, wall=11952
2023-04-08 19:22:28 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 256.0
2023-04-08 19:22:34 - progress_bar.py[line:272] - INFO: epoch 005:    262 / 578 loss=2.485, loss_v1=0, loss_v2=0, nll_loss=1.297, ntokens=2517.6, nsentences=96, sample_size=2517.6, sample_size_v1=0, sample_size_v2=0, ppl=2.46, wps=808.1, ups=0.32, wpb=2517.6, bsz=96, num_updates=2570, lr=2.0089e-05, gnorm=1.41, clip=100, loss_scale=256, train_wall=31, gb_free=12.6, wall=11983
2023-04-08 19:23:02 - progress_bar.py[line:272] - INFO: epoch 005:    272 / 578 loss=2.492, loss_v1=0, loss_v2=0, nll_loss=1.309, ntokens=2585.1, nsentences=96, sample_size=2585.1, sample_size_v1=0, sample_size_v2=0, ppl=2.48, wps=911.9, ups=0.35, wpb=2585.1, bsz=96, num_updates=2580, lr=2.00429e-05, gnorm=1.377, clip=100, loss_scale=256, train_wall=28, gb_free=12.3, wall=12012
2023-04-08 19:23:30 - progress_bar.py[line:272] - INFO: epoch 005:    282 / 578 loss=2.478, loss_v1=0, loss_v2=0, nll_loss=1.29, ntokens=2570.8, nsentences=96, sample_size=2570.8, sample_size_v1=0, sample_size_v2=0, ppl=2.45, wps=902.5, ups=0.35, wpb=2570.8, bsz=96, num_updates=2590, lr=1.99969e-05, gnorm=1.313, clip=100, loss_scale=256, train_wall=28, gb_free=12.3, wall=12040
2023-04-08 19:23:59 - progress_bar.py[line:272] - INFO: epoch 005:    292 / 578 loss=2.484, loss_v1=0, loss_v2=0, nll_loss=1.3, ntokens=2619.7, nsentences=96, sample_size=2619.7, sample_size_v1=0, sample_size_v2=0, ppl=2.46, wps=925.3, ups=0.35, wpb=2619.7, bsz=96, num_updates=2600, lr=1.99509e-05, gnorm=1.367, clip=100, loss_scale=256, train_wall=28, gb_free=12.5, wall=12068
2023-04-08 19:24:27 - progress_bar.py[line:272] - INFO: epoch 005:    302 / 578 loss=2.488, loss_v1=0, loss_v2=0, nll_loss=1.301, ntokens=2477.8, nsentences=96, sample_size=2477.8, sample_size_v1=0, sample_size_v2=0, ppl=2.46, wps=874.6, ups=0.35, wpb=2477.8, bsz=96, num_updates=2610, lr=1.99049e-05, gnorm=1.382, clip=100, loss_scale=256, train_wall=28, gb_free=12.6, wall=12097
2023-04-08 19:24:56 - progress_bar.py[line:272] - INFO: epoch 005:    312 / 578 loss=2.494, loss_v1=0, loss_v2=0, nll_loss=1.309, ntokens=2655.5, nsentences=96, sample_size=2655.5, sample_size_v1=0, sample_size_v2=0, ppl=2.48, wps=931, ups=0.35, wpb=2655.5, bsz=96, num_updates=2620, lr=1.98589e-05, gnorm=1.349, clip=100, loss_scale=256, train_wall=28, gb_free=12.3, wall=12125
2023-04-08 19:25:24 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 128.0
2023-04-08 19:25:27 - progress_bar.py[line:272] - INFO: epoch 005:    323 / 578 loss=2.495, loss_v1=0, loss_v2=0, nll_loss=1.31, ntokens=2639.3, nsentences=96, sample_size=2639.3, sample_size_v1=0, sample_size_v2=0, ppl=2.48, wps=844.8, ups=0.32, wpb=2639.3, bsz=96, num_updates=2630, lr=1.98129e-05, gnorm=1.396, clip=100, loss_scale=128, train_wall=31, gb_free=12.5, wall=12156
2023-04-08 19:25:55 - progress_bar.py[line:272] - INFO: epoch 005:    333 / 578 loss=2.462, loss_v1=0, loss_v2=0, nll_loss=1.273, ntokens=2517.5, nsentences=96, sample_size=2517.5, sample_size_v1=0, sample_size_v2=0, ppl=2.42, wps=889.1, ups=0.35, wpb=2517.5, bsz=96, num_updates=2640, lr=1.97669e-05, gnorm=1.392, clip=100, loss_scale=128, train_wall=28, gb_free=12.4, wall=12185
2023-04-08 19:26:23 - progress_bar.py[line:272] - INFO: epoch 005:    343 / 578 loss=2.496, loss_v1=0, loss_v2=0, nll_loss=1.313, ntokens=2720.3, nsentences=96, sample_size=2720.3, sample_size_v1=0, sample_size_v2=0, ppl=2.48, wps=957.9, ups=0.35, wpb=2720.3, bsz=96, num_updates=2650, lr=1.97209e-05, gnorm=1.324, clip=100, loss_scale=128, train_wall=28, gb_free=12.5, wall=12213
2023-04-08 19:26:52 - progress_bar.py[line:272] - INFO: epoch 005:    353 / 578 loss=2.459, loss_v1=0, loss_v2=0, nll_loss=1.27, ntokens=2569.2, nsentences=96, sample_size=2569.2, sample_size_v1=0, sample_size_v2=0, ppl=2.41, wps=908.5, ups=0.35, wpb=2569.2, bsz=96, num_updates=2660, lr=1.96748e-05, gnorm=1.388, clip=100, loss_scale=128, train_wall=28, gb_free=12.5, wall=12241
2023-04-08 19:27:20 - progress_bar.py[line:272] - INFO: epoch 005:    363 / 578 loss=2.48, loss_v1=0, loss_v2=0, nll_loss=1.294, ntokens=2715.2, nsentences=96, sample_size=2715.2, sample_size_v1=0, sample_size_v2=0, ppl=2.45, wps=958.1, ups=0.35, wpb=2715.2, bsz=96, num_updates=2670, lr=1.96288e-05, gnorm=1.287, clip=100, loss_scale=128, train_wall=28, gb_free=12.4, wall=12270
2023-04-08 19:27:49 - progress_bar.py[line:272] - INFO: epoch 005:    373 / 578 loss=2.495, loss_v1=0, loss_v2=0, nll_loss=1.31, ntokens=2789, nsentences=96, sample_size=2789, sample_size_v1=0, sample_size_v2=0, ppl=2.48, wps=975.8, ups=0.35, wpb=2789, bsz=96, num_updates=2680, lr=1.95828e-05, gnorm=1.316, clip=100, loss_scale=128, train_wall=29, gb_free=12.4, wall=12298
2023-04-08 19:28:17 - progress_bar.py[line:272] - INFO: epoch 005:    383 / 578 loss=2.492, loss_v1=0, loss_v2=0, nll_loss=1.306, ntokens=2706.9, nsentences=96, sample_size=2706.9, sample_size_v1=0, sample_size_v2=0, ppl=2.47, wps=950, ups=0.35, wpb=2706.9, bsz=96, num_updates=2690, lr=1.95368e-05, gnorm=1.385, clip=100, loss_scale=128, train_wall=28, gb_free=12.4, wall=12327
2023-04-08 19:28:46 - progress_bar.py[line:272] - INFO: epoch 005:    393 / 578 loss=2.491, loss_v1=0, loss_v2=0, nll_loss=1.305, ntokens=2556.2, nsentences=96, sample_size=2556.2, sample_size_v1=0, sample_size_v2=0, ppl=2.47, wps=898.1, ups=0.35, wpb=2556.2, bsz=96, num_updates=2700, lr=1.94908e-05, gnorm=1.404, clip=100, loss_scale=128, train_wall=28, gb_free=12, wall=12355
2023-04-08 19:29:14 - progress_bar.py[line:272] - INFO: epoch 005:    403 / 578 loss=2.465, loss_v1=0, loss_v2=0, nll_loss=1.278, ntokens=2525.1, nsentences=96, sample_size=2525.1, sample_size_v1=0, sample_size_v2=0, ppl=2.43, wps=889.6, ups=0.35, wpb=2525.1, bsz=96, num_updates=2710, lr=1.94448e-05, gnorm=1.449, clip=100, loss_scale=128, train_wall=28, gb_free=12.4, wall=12384
2023-04-08 19:29:42 - progress_bar.py[line:272] - INFO: epoch 005:    413 / 578 loss=2.487, loss_v1=0, loss_v2=0, nll_loss=1.297, ntokens=2423.3, nsentences=96, sample_size=2423.3, sample_size_v1=0, sample_size_v2=0, ppl=2.46, wps=856.4, ups=0.35, wpb=2423.3, bsz=96, num_updates=2720, lr=1.93988e-05, gnorm=1.496, clip=100, loss_scale=128, train_wall=28, gb_free=12.6, wall=12412
2023-04-08 19:30:11 - progress_bar.py[line:272] - INFO: epoch 005:    423 / 578 loss=2.476, loss_v1=0, loss_v2=0, nll_loss=1.291, ntokens=2483.5, nsentences=96, sample_size=2483.5, sample_size_v1=0, sample_size_v2=0, ppl=2.45, wps=877.1, ups=0.35, wpb=2483.5, bsz=96, num_updates=2730, lr=1.93528e-05, gnorm=1.498, clip=100, loss_scale=128, train_wall=28, gb_free=12.6, wall=12440
2023-04-08 19:30:39 - progress_bar.py[line:272] - INFO: epoch 005:    433 / 578 loss=2.471, loss_v1=0, loss_v2=0, nll_loss=1.279, ntokens=2565.4, nsentences=96, sample_size=2565.4, sample_size_v1=0, sample_size_v2=0, ppl=2.43, wps=908.2, ups=0.35, wpb=2565.4, bsz=96, num_updates=2740, lr=1.93067e-05, gnorm=1.411, clip=100, loss_scale=128, train_wall=28, gb_free=12.4, wall=12469
2023-04-08 19:31:07 - progress_bar.py[line:272] - INFO: epoch 005:    443 / 578 loss=2.49, loss_v1=0, loss_v2=0, nll_loss=1.307, ntokens=2429.1, nsentences=96, sample_size=2429.1, sample_size_v1=0, sample_size_v2=0, ppl=2.47, wps=861.1, ups=0.35, wpb=2429.1, bsz=96, num_updates=2750, lr=1.92607e-05, gnorm=1.459, clip=100, loss_scale=128, train_wall=28, gb_free=12.6, wall=12497
2023-04-08 19:31:36 - progress_bar.py[line:272] - INFO: epoch 005:    453 / 578 loss=2.482, loss_v1=0, loss_v2=0, nll_loss=1.293, ntokens=2529.6, nsentences=96, sample_size=2529.6, sample_size_v1=0, sample_size_v2=0, ppl=2.45, wps=890.9, ups=0.35, wpb=2529.6, bsz=96, num_updates=2760, lr=1.92147e-05, gnorm=1.419, clip=100, loss_scale=128, train_wall=28, gb_free=12.6, wall=12525
2023-04-08 19:32:04 - progress_bar.py[line:272] - INFO: epoch 005:    463 / 578 loss=2.485, loss_v1=0, loss_v2=0, nll_loss=1.302, ntokens=2530.6, nsentences=96, sample_size=2530.6, sample_size_v1=0, sample_size_v2=0, ppl=2.47, wps=891.3, ups=0.35, wpb=2530.6, bsz=96, num_updates=2770, lr=1.91687e-05, gnorm=1.441, clip=100, loss_scale=128, train_wall=28, gb_free=11.7, wall=12554
2023-04-08 19:32:32 - progress_bar.py[line:272] - INFO: epoch 005:    473 / 578 loss=2.484, loss_v1=0, loss_v2=0, nll_loss=1.294, ntokens=2422.1, nsentences=96, sample_size=2422.1, sample_size_v1=0, sample_size_v2=0, ppl=2.45, wps=856.3, ups=0.35, wpb=2422.1, bsz=96, num_updates=2780, lr=1.91227e-05, gnorm=1.505, clip=100, loss_scale=128, train_wall=28, gb_free=12.2, wall=12582
2023-04-08 19:33:00 - progress_bar.py[line:272] - INFO: epoch 005:    483 / 578 loss=2.482, loss_v1=0, loss_v2=0, nll_loss=1.3, ntokens=2372, nsentences=96, sample_size=2372, sample_size_v1=0, sample_size_v2=0, ppl=2.46, wps=840.4, ups=0.35, wpb=2372, bsz=96, num_updates=2790, lr=1.90767e-05, gnorm=1.497, clip=100, loss_scale=128, train_wall=28, gb_free=12.6, wall=12610
2023-04-08 19:33:29 - progress_bar.py[line:272] - INFO: epoch 005:    493 / 578 loss=2.465, loss_v1=0, loss_v2=0, nll_loss=1.275, ntokens=2514.6, nsentences=96, sample_size=2514.6, sample_size_v1=0, sample_size_v2=0, ppl=2.42, wps=890.5, ups=0.35, wpb=2514.6, bsz=96, num_updates=2800, lr=1.90307e-05, gnorm=1.409, clip=100, loss_scale=128, train_wall=28, gb_free=12.3, wall=12638
2023-04-08 19:33:57 - progress_bar.py[line:272] - INFO: epoch 005:    503 / 578 loss=2.458, loss_v1=0, loss_v2=0, nll_loss=1.27, ntokens=2536.5, nsentences=96, sample_size=2536.5, sample_size_v1=0, sample_size_v2=0, ppl=2.41, wps=891.4, ups=0.35, wpb=2536.5, bsz=96, num_updates=2810, lr=1.89847e-05, gnorm=1.479, clip=100, loss_scale=128, train_wall=28, gb_free=12.5, wall=12667
2023-04-08 19:34:26 - progress_bar.py[line:272] - INFO: epoch 005:    513 / 578 loss=2.473, loss_v1=0, loss_v2=0, nll_loss=1.285, ntokens=2546.3, nsentences=96, sample_size=2546.3, sample_size_v1=0, sample_size_v2=0, ppl=2.44, wps=897.9, ups=0.35, wpb=2546.3, bsz=96, num_updates=2820, lr=1.89387e-05, gnorm=1.469, clip=100, loss_scale=128, train_wall=28, gb_free=12.7, wall=12695
2023-04-08 19:34:54 - progress_bar.py[line:272] - INFO: epoch 005:    523 / 578 loss=2.453, loss_v1=0, loss_v2=0, nll_loss=1.263, ntokens=2700.2, nsentences=96, sample_size=2700.2, sample_size_v1=0, sample_size_v2=0, ppl=2.4, wps=949.6, ups=0.35, wpb=2700.2, bsz=96, num_updates=2830, lr=1.88926e-05, gnorm=1.419, clip=100, loss_scale=128, train_wall=28, gb_free=12.6, wall=12724
2023-04-08 19:35:22 - progress_bar.py[line:272] - INFO: epoch 005:    533 / 578 loss=2.475, loss_v1=0, loss_v2=0, nll_loss=1.285, ntokens=2559.7, nsentences=96, sample_size=2559.7, sample_size_v1=0, sample_size_v2=0, ppl=2.44, wps=905.2, ups=0.35, wpb=2559.7, bsz=96, num_updates=2840, lr=1.88466e-05, gnorm=1.451, clip=100, loss_scale=128, train_wall=28, gb_free=12.4, wall=12752
2023-04-08 19:35:51 - progress_bar.py[line:272] - INFO: epoch 005:    543 / 578 loss=2.452, loss_v1=0, loss_v2=0, nll_loss=1.265, ntokens=2506.1, nsentences=96, sample_size=2506.1, sample_size_v1=0, sample_size_v2=0, ppl=2.4, wps=883.6, ups=0.35, wpb=2506.1, bsz=96, num_updates=2850, lr=1.88006e-05, gnorm=1.462, clip=100, loss_scale=128, train_wall=28, gb_free=12.6, wall=12780
2023-04-08 19:36:19 - progress_bar.py[line:272] - INFO: epoch 005:    553 / 578 loss=2.458, loss_v1=0, loss_v2=0, nll_loss=1.267, ntokens=2569.7, nsentences=96, sample_size=2569.7, sample_size_v1=0, sample_size_v2=0, ppl=2.41, wps=898.2, ups=0.35, wpb=2569.7, bsz=96, num_updates=2860, lr=1.87546e-05, gnorm=1.382, clip=100, loss_scale=128, train_wall=29, gb_free=12.6, wall=12809
2023-04-08 19:36:48 - progress_bar.py[line:272] - INFO: epoch 005:    563 / 578 loss=2.456, loss_v1=0, loss_v2=0, nll_loss=1.267, ntokens=2657.9, nsentences=96, sample_size=2657.9, sample_size_v1=0, sample_size_v2=0, ppl=2.41, wps=932.4, ups=0.35, wpb=2657.9, bsz=96, num_updates=2870, lr=1.87086e-05, gnorm=1.372, clip=100, loss_scale=128, train_wall=28, gb_free=12.5, wall=12837
2023-04-08 19:37:16 - progress_bar.py[line:272] - INFO: epoch 005:    573 / 578 loss=2.466, loss_v1=0, loss_v2=0, nll_loss=1.278, ntokens=2565.8, nsentences=96, sample_size=2565.8, sample_size_v1=0, sample_size_v2=0, ppl=2.42, wps=899.6, ups=0.35, wpb=2565.8, bsz=96, num_updates=2880, lr=1.86626e-05, gnorm=1.474, clip=100, loss_scale=128, train_wall=28, gb_free=12.4, wall=12866
2023-04-08 19:37:28 - train.py[line:332] - INFO: end of epoch 5 (average epoch stats below)
local datafile ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 1 begin to initialize row_count and line_idx-to-offset mapping
2023-04-08 19:37:28 - progress_bar.py[line:282] - INFO: epoch 005 | loss 2.484 | loss_v1 0 | loss_v2 0 | nll_loss 1.297 | ntokens 2520.32 | nsentences 95.847 | sample_size 2520.32 | sample_size_v1 0 | sample_size_v2 0 | ppl 2.46 | wps 881.8 | ups 0.35 | wpb 2520.3 | bsz 95.8 | num_updates 2885 | lr 1.86396e-05 | gnorm 1.405 | clip 100 | loss_scale 128 | train_wall 1642 | gb_free 13.1 | wall 12878
2023-04-08 19:37:28 - trainer.py[line:639] - INFO: loading train data for epoch 6
local datafile ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 0 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 1 finished initializing row_count and line_idx-to-offset mapping
file ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 1 row count 27700 total row count 55400
slice_id 1 seek offset 27700
local datafile ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 0 finished initializing row_count and line_idx-to-offset mapping
file ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 0 row count 27700 total row count 55400
slice_id 0 seek offset 0
2023-04-08 19:37:30 - trainer.py[line:703] - INFO: begin training epoch 6
2023-04-08 19:37:30 - train.py[line:305] - INFO: Start iterating over samples
2023-04-08 19:37:45 - progress_bar.py[line:272] - INFO: epoch 006:      5 / 578 loss=2.473, loss_v1=0, loss_v2=0, nll_loss=1.283, ntokens=2353.1, nsentences=87.6, sample_size=2353.1, sample_size_v1=0, sample_size_v2=0, ppl=2.43, wps=823.8, ups=0.35, wpb=2353.1, bsz=87.6, num_updates=2890, lr=1.86166e-05, gnorm=1.63, clip=100, loss_scale=128, train_wall=26, gb_free=11.8, wall=12894
2023-04-08 19:38:13 - progress_bar.py[line:272] - INFO: epoch 006:     15 / 578 loss=2.455, loss_v1=0, loss_v2=0, nll_loss=1.266, ntokens=2393.3, nsentences=96, sample_size=2393.3, sample_size_v1=0, sample_size_v2=0, ppl=2.4, wps=839.6, ups=0.35, wpb=2393.3, bsz=96, num_updates=2900, lr=1.85706e-05, gnorm=1.506, clip=100, loss_scale=128, train_wall=28, gb_free=12.3, wall=12923
2023-04-08 19:38:42 - progress_bar.py[line:272] - INFO: epoch 006:     25 / 578 loss=2.445, loss_v1=0, loss_v2=0, nll_loss=1.254, ntokens=2390.4, nsentences=96, sample_size=2390.4, sample_size_v1=0, sample_size_v2=0, ppl=2.38, wps=829.9, ups=0.35, wpb=2390.4, bsz=96, num_updates=2910, lr=1.85245e-05, gnorm=1.447, clip=100, loss_scale=128, train_wall=29, gb_free=12.3, wall=12952
2023-04-08 19:39:11 - progress_bar.py[line:272] - INFO: epoch 006:     35 / 578 loss=2.463, loss_v1=0, loss_v2=0, nll_loss=1.275, ntokens=2235, nsentences=96, sample_size=2235, sample_size_v1=0, sample_size_v2=0, ppl=2.42, wps=779.4, ups=0.35, wpb=2235, bsz=96, num_updates=2920, lr=1.84785e-05, gnorm=1.642, clip=100, loss_scale=128, train_wall=29, gb_free=12.5, wall=12980
2023-04-08 19:39:40 - progress_bar.py[line:272] - INFO: epoch 006:     45 / 578 loss=2.411, loss_v1=0, loss_v2=0, nll_loss=1.215, ntokens=2216.1, nsentences=96, sample_size=2216.1, sample_size_v1=0, sample_size_v2=0, ppl=2.32, wps=766.6, ups=0.35, wpb=2216.1, bsz=96, num_updates=2930, lr=1.84325e-05, gnorm=1.6, clip=100, loss_scale=128, train_wall=29, gb_free=11.2, wall=13009
2023-04-08 19:40:09 - progress_bar.py[line:272] - INFO: epoch 006:     55 / 578 loss=2.468, loss_v1=0, loss_v2=0, nll_loss=1.277, ntokens=2396.9, nsentences=96, sample_size=2396.9, sample_size_v1=0, sample_size_v2=0, ppl=2.42, wps=824.4, ups=0.34, wpb=2396.9, bsz=96, num_updates=2940, lr=1.83865e-05, gnorm=1.549, clip=100, loss_scale=128, train_wall=29, gb_free=11.8, wall=13038
2023-04-08 19:40:37 - progress_bar.py[line:272] - INFO: epoch 006:     65 / 578 loss=2.465, loss_v1=0, loss_v2=0, nll_loss=1.278, ntokens=2276.9, nsentences=96, sample_size=2276.9, sample_size_v1=0, sample_size_v2=0, ppl=2.43, wps=793.5, ups=0.35, wpb=2276.9, bsz=96, num_updates=2950, lr=1.83405e-05, gnorm=1.723, clip=100, loss_scale=128, train_wall=29, gb_free=11.5, wall=13067
2023-04-08 19:41:06 - progress_bar.py[line:272] - INFO: epoch 006:     75 / 578 loss=2.486, loss_v1=0, loss_v2=0, nll_loss=1.3, ntokens=2423.2, nsentences=96, sample_size=2423.2, sample_size_v1=0, sample_size_v2=0, ppl=2.46, wps=850.8, ups=0.35, wpb=2423.2, bsz=96, num_updates=2960, lr=1.82945e-05, gnorm=1.582, clip=100, loss_scale=128, train_wall=28, gb_free=11.6, wall=13096
2023-04-08 19:41:35 - progress_bar.py[line:272] - INFO: epoch 006:     85 / 578 loss=2.484, loss_v1=0, loss_v2=0, nll_loss=1.296, ntokens=2518.1, nsentences=96, sample_size=2518.1, sample_size_v1=0, sample_size_v2=0, ppl=2.46, wps=869.2, ups=0.35, wpb=2518.1, bsz=96, num_updates=2970, lr=1.82485e-05, gnorm=1.592, clip=100, loss_scale=128, train_wall=29, gb_free=12.3, wall=13125
2023-04-08 19:42:04 - progress_bar.py[line:272] - INFO: epoch 006:     95 / 578 loss=2.469, loss_v1=0, loss_v2=0, nll_loss=1.28, ntokens=2481.6, nsentences=96, sample_size=2481.6, sample_size_v1=0, sample_size_v2=0, ppl=2.43, wps=855.3, ups=0.34, wpb=2481.6, bsz=96, num_updates=2980, lr=1.82025e-05, gnorm=1.54, clip=100, loss_scale=128, train_wall=29, gb_free=12, wall=13154
2023-04-08 19:42:33 - progress_bar.py[line:272] - INFO: epoch 006:    105 / 578 loss=2.467, loss_v1=0, loss_v2=0, nll_loss=1.279, ntokens=2443.9, nsentences=96, sample_size=2443.9, sample_size_v1=0, sample_size_v2=0, ppl=2.43, wps=842.1, ups=0.34, wpb=2443.9, bsz=96, num_updates=2990, lr=1.81564e-05, gnorm=1.592, clip=100, loss_scale=128, train_wall=29, gb_free=12.3, wall=13183
2023-04-08 19:43:02 - progress_bar.py[line:272] - INFO: epoch 006:    115 / 578 loss=2.48, loss_v1=0, loss_v2=0, nll_loss=1.293, ntokens=2335.1, nsentences=96, sample_size=2335.1, sample_size_v1=0, sample_size_v2=0, ppl=2.45, wps=817.4, ups=0.35, wpb=2335.1, bsz=96, num_updates=3000, lr=1.81104e-05, gnorm=1.539, clip=100, loss_scale=128, train_wall=29, gb_free=12, wall=13211
2023-04-08 19:43:30 - progress_bar.py[line:272] - INFO: epoch 006:    125 / 578 loss=2.471, loss_v1=0, loss_v2=0, nll_loss=1.283, ntokens=2384.1, nsentences=96, sample_size=2384.1, sample_size_v1=0, sample_size_v2=0, ppl=2.43, wps=826.1, ups=0.35, wpb=2384.1, bsz=96, num_updates=3010, lr=1.80644e-05, gnorm=1.571, clip=100, loss_scale=128, train_wall=29, gb_free=12, wall=13240
2023-04-08 19:43:59 - progress_bar.py[line:272] - INFO: epoch 006:    135 / 578 loss=2.477, loss_v1=0, loss_v2=0, nll_loss=1.289, ntokens=2448.6, nsentences=96, sample_size=2448.6, sample_size_v1=0, sample_size_v2=0, ppl=2.44, wps=854.8, ups=0.35, wpb=2448.6, bsz=96, num_updates=3020, lr=1.80184e-05, gnorm=1.515, clip=100, loss_scale=128, train_wall=29, gb_free=11.9, wall=13269
2023-04-08 19:44:27 - progress_bar.py[line:272] - INFO: epoch 006:    145 / 578 loss=2.486, loss_v1=0, loss_v2=0, nll_loss=1.3, ntokens=2529.3, nsentences=96, sample_size=2529.3, sample_size_v1=0, sample_size_v2=0, ppl=2.46, wps=889.6, ups=0.35, wpb=2529.3, bsz=96, num_updates=3030, lr=1.79724e-05, gnorm=1.552, clip=100, loss_scale=128, train_wall=28, gb_free=12.4, wall=13297
2023-04-08 19:44:56 - progress_bar.py[line:272] - INFO: epoch 006:    155 / 578 loss=2.482, loss_v1=0, loss_v2=0, nll_loss=1.294, ntokens=2647.9, nsentences=96, sample_size=2647.9, sample_size_v1=0, sample_size_v2=0, ppl=2.45, wps=930.2, ups=0.35, wpb=2647.9, bsz=96, num_updates=3040, lr=1.79264e-05, gnorm=1.531, clip=100, loss_scale=128, train_wall=28, gb_free=12.4, wall=13326
2023-04-08 19:45:25 - progress_bar.py[line:272] - INFO: epoch 006:    165 / 578 loss=2.478, loss_v1=0, loss_v2=0, nll_loss=1.292, ntokens=2681.7, nsentences=96, sample_size=2681.7, sample_size_v1=0, sample_size_v2=0, ppl=2.45, wps=939.4, ups=0.35, wpb=2681.7, bsz=96, num_updates=3050, lr=1.78804e-05, gnorm=1.505, clip=100, loss_scale=128, train_wall=29, gb_free=12.1, wall=13354
2023-04-08 19:45:53 - progress_bar.py[line:272] - INFO: epoch 006:    175 / 578 loss=2.483, loss_v1=0, loss_v2=0, nll_loss=1.296, ntokens=2604.9, nsentences=96, sample_size=2604.9, sample_size_v1=0, sample_size_v2=0, ppl=2.46, wps=914.7, ups=0.35, wpb=2604.9, bsz=96, num_updates=3060, lr=1.78344e-05, gnorm=1.452, clip=100, loss_scale=128, train_wall=28, gb_free=12.3, wall=13383
2023-04-08 19:46:22 - progress_bar.py[line:272] - INFO: epoch 006:    185 / 578 loss=2.474, loss_v1=0, loss_v2=0, nll_loss=1.287, ntokens=2637, nsentences=96, sample_size=2637, sample_size_v1=0, sample_size_v2=0, ppl=2.44, wps=922.3, ups=0.35, wpb=2637, bsz=96, num_updates=3070, lr=1.77883e-05, gnorm=1.535, clip=100, loss_scale=128, train_wall=29, gb_free=12.2, wall=13411
2023-04-08 19:46:50 - progress_bar.py[line:272] - INFO: epoch 006:    195 / 578 loss=2.467, loss_v1=0, loss_v2=0, nll_loss=1.278, ntokens=2610.4, nsentences=96, sample_size=2610.4, sample_size_v1=0, sample_size_v2=0, ppl=2.43, wps=914.1, ups=0.35, wpb=2610.4, bsz=96, num_updates=3080, lr=1.77423e-05, gnorm=1.469, clip=100, loss_scale=128, train_wall=29, gb_free=12.4, wall=13440
2023-04-08 19:47:19 - progress_bar.py[line:272] - INFO: epoch 006:    205 / 578 loss=2.469, loss_v1=0, loss_v2=0, nll_loss=1.281, ntokens=2579.9, nsentences=96, sample_size=2579.9, sample_size_v1=0, sample_size_v2=0, ppl=2.43, wps=906.7, ups=0.35, wpb=2579.9, bsz=96, num_updates=3090, lr=1.76963e-05, gnorm=1.553, clip=100, loss_scale=128, train_wall=28, gb_free=12.6, wall=13468
2023-04-08 19:47:47 - progress_bar.py[line:272] - INFO: epoch 006:    215 / 578 loss=2.489, loss_v1=0, loss_v2=0, nll_loss=1.304, ntokens=2467, nsentences=96, sample_size=2467, sample_size_v1=0, sample_size_v2=0, ppl=2.47, wps=868.2, ups=0.35, wpb=2467, bsz=96, num_updates=3100, lr=1.76503e-05, gnorm=1.604, clip=100, loss_scale=128, train_wall=28, gb_free=12.4, wall=13497
2023-04-08 19:48:15 - progress_bar.py[line:272] - INFO: epoch 006:    225 / 578 loss=2.457, loss_v1=0, loss_v2=0, nll_loss=1.266, ntokens=2600.2, nsentences=96, sample_size=2600.2, sample_size_v1=0, sample_size_v2=0, ppl=2.41, wps=914.7, ups=0.35, wpb=2600.2, bsz=96, num_updates=3110, lr=1.76043e-05, gnorm=1.523, clip=100, loss_scale=128, train_wall=28, gb_free=11.9, wall=13525
2023-04-08 19:48:44 - progress_bar.py[line:272] - INFO: epoch 006:    235 / 578 loss=2.469, loss_v1=0, loss_v2=0, nll_loss=1.282, ntokens=2444.9, nsentences=96, sample_size=2444.9, sample_size_v1=0, sample_size_v2=0, ppl=2.43, wps=864.4, ups=0.35, wpb=2444.9, bsz=96, num_updates=3120, lr=1.75583e-05, gnorm=1.605, clip=100, loss_scale=128, train_wall=28, gb_free=12.6, wall=13553
2023-04-08 19:49:12 - progress_bar.py[line:272] - INFO: epoch 006:    245 / 578 loss=2.477, loss_v1=0, loss_v2=0, nll_loss=1.287, ntokens=2458.6, nsentences=96, sample_size=2458.6, sample_size_v1=0, sample_size_v2=0, ppl=2.44, wps=868.4, ups=0.35, wpb=2458.6, bsz=96, num_updates=3130, lr=1.75123e-05, gnorm=1.587, clip=100, loss_scale=128, train_wall=28, gb_free=12.5, wall=13582
2023-04-08 19:49:40 - progress_bar.py[line:272] - INFO: epoch 006:    255 / 578 loss=2.476, loss_v1=0, loss_v2=0, nll_loss=1.292, ntokens=2561, nsentences=96, sample_size=2561, sample_size_v1=0, sample_size_v2=0, ppl=2.45, wps=903.7, ups=0.35, wpb=2561, bsz=96, num_updates=3140, lr=1.74663e-05, gnorm=1.611, clip=100, loss_scale=128, train_wall=28, gb_free=12.5, wall=13610
2023-04-08 19:50:09 - progress_bar.py[line:272] - INFO: epoch 006:    265 / 578 loss=2.467, loss_v1=0, loss_v2=0, nll_loss=1.277, ntokens=2529.4, nsentences=96, sample_size=2529.4, sample_size_v1=0, sample_size_v2=0, ppl=2.42, wps=892.7, ups=0.35, wpb=2529.4, bsz=96, num_updates=3150, lr=1.74202e-05, gnorm=1.513, clip=100, loss_scale=256, train_wall=28, gb_free=12.3, wall=13638
2023-04-08 19:50:37 - progress_bar.py[line:272] - INFO: epoch 006:    275 / 578 loss=2.465, loss_v1=0, loss_v2=0, nll_loss=1.278, ntokens=2608.1, nsentences=96, sample_size=2608.1, sample_size_v1=0, sample_size_v2=0, ppl=2.43, wps=918.5, ups=0.35, wpb=2608.1, bsz=96, num_updates=3160, lr=1.73742e-05, gnorm=1.533, clip=100, loss_scale=256, train_wall=28, gb_free=12.6, wall=13667
2023-04-08 19:51:06 - progress_bar.py[line:272] - INFO: epoch 006:    285 / 578 loss=2.455, loss_v1=0, loss_v2=0, nll_loss=1.265, ntokens=2523.9, nsentences=96, sample_size=2523.9, sample_size_v1=0, sample_size_v2=0, ppl=2.4, wps=887.8, ups=0.35, wpb=2523.9, bsz=96, num_updates=3170, lr=1.73282e-05, gnorm=1.53, clip=100, loss_scale=256, train_wall=28, gb_free=12.3, wall=13695
2023-04-08 19:51:34 - progress_bar.py[line:272] - INFO: epoch 006:    295 / 578 loss=2.475, loss_v1=0, loss_v2=0, nll_loss=1.288, ntokens=2600, nsentences=96, sample_size=2600, sample_size_v1=0, sample_size_v2=0, ppl=2.44, wps=916.9, ups=0.35, wpb=2600, bsz=96, num_updates=3180, lr=1.72822e-05, gnorm=1.501, clip=100, loss_scale=256, train_wall=28, gb_free=12.1, wall=13724
2023-04-08 19:52:02 - progress_bar.py[line:272] - INFO: epoch 006:    305 / 578 loss=2.459, loss_v1=0, loss_v2=0, nll_loss=1.269, ntokens=2547.6, nsentences=96, sample_size=2547.6, sample_size_v1=0, sample_size_v2=0, ppl=2.41, wps=896, ups=0.35, wpb=2547.6, bsz=96, num_updates=3190, lr=1.72362e-05, gnorm=1.509, clip=100, loss_scale=256, train_wall=28, gb_free=12, wall=13752
2023-04-08 19:52:31 - progress_bar.py[line:272] - INFO: epoch 006:    315 / 578 loss=2.473, loss_v1=0, loss_v2=0, nll_loss=1.284, ntokens=2637.8, nsentences=95.6, sample_size=2637.8, sample_size_v1=0, sample_size_v2=0, ppl=2.44, wps=930.5, ups=0.35, wpb=2637.8, bsz=95.6, num_updates=3200, lr=1.71902e-05, gnorm=1.483, clip=100, loss_scale=256, train_wall=28, gb_free=12.1, wall=13780
2023-04-08 19:52:59 - progress_bar.py[line:272] - INFO: epoch 006:    325 / 578 loss=2.466, loss_v1=0, loss_v2=0, nll_loss=1.278, ntokens=2580.4, nsentences=96, sample_size=2580.4, sample_size_v1=0, sample_size_v2=0, ppl=2.43, wps=908.2, ups=0.35, wpb=2580.4, bsz=96, num_updates=3210, lr=1.71442e-05, gnorm=1.475, clip=100, loss_scale=256, train_wall=28, gb_free=12.7, wall=13809
2023-04-08 19:53:27 - progress_bar.py[line:272] - INFO: epoch 006:    335 / 578 loss=2.443, loss_v1=0, loss_v2=0, nll_loss=1.252, ntokens=2573.7, nsentences=96, sample_size=2573.7, sample_size_v1=0, sample_size_v2=0, ppl=2.38, wps=908.4, ups=0.35, wpb=2573.7, bsz=96, num_updates=3220, lr=1.70982e-05, gnorm=1.499, clip=100, loss_scale=256, train_wall=28, gb_free=12.5, wall=13837
2023-04-08 19:53:56 - progress_bar.py[line:272] - INFO: epoch 006:    345 / 578 loss=2.465, loss_v1=0, loss_v2=0, nll_loss=1.276, ntokens=2706.2, nsentences=96, sample_size=2706.2, sample_size_v1=0, sample_size_v2=0, ppl=2.42, wps=952.9, ups=0.35, wpb=2706.2, bsz=96, num_updates=3230, lr=1.70521e-05, gnorm=1.439, clip=100, loss_scale=256, train_wall=28, gb_free=12.6, wall=13866
2023-04-08 19:54:24 - progress_bar.py[line:272] - INFO: epoch 006:    355 / 578 loss=2.442, loss_v1=0, loss_v2=0, nll_loss=1.252, ntokens=2572.3, nsentences=96, sample_size=2572.3, sample_size_v1=0, sample_size_v2=0, ppl=2.38, wps=910.6, ups=0.35, wpb=2572.3, bsz=96, num_updates=3240, lr=1.70061e-05, gnorm=1.612, clip=100, loss_scale=256, train_wall=28, gb_free=12.6, wall=13894
2023-04-08 19:54:53 - progress_bar.py[line:272] - INFO: epoch 006:    365 / 578 loss=2.464, loss_v1=0, loss_v2=0, nll_loss=1.274, ntokens=2763.7, nsentences=96, sample_size=2763.7, sample_size_v1=0, sample_size_v2=0, ppl=2.42, wps=972.3, ups=0.35, wpb=2763.7, bsz=96, num_updates=3250, lr=1.69601e-05, gnorm=1.466, clip=100, loss_scale=256, train_wall=28, gb_free=12.4, wall=13922
2023-04-08 19:55:21 - progress_bar.py[line:272] - INFO: epoch 006:    375 / 578 loss=2.477, loss_v1=0, loss_v2=0, nll_loss=1.29, ntokens=2750.6, nsentences=96, sample_size=2750.6, sample_size_v1=0, sample_size_v2=0, ppl=2.45, wps=965.2, ups=0.35, wpb=2750.6, bsz=96, num_updates=3260, lr=1.69141e-05, gnorm=1.473, clip=100, loss_scale=256, train_wall=28, gb_free=12.7, wall=13951
2023-04-08 19:55:50 - progress_bar.py[line:272] - INFO: epoch 006:    385 / 578 loss=2.466, loss_v1=0, loss_v2=0, nll_loss=1.276, ntokens=2665.2, nsentences=96, sample_size=2665.2, sample_size_v1=0, sample_size_v2=0, ppl=2.42, wps=935, ups=0.35, wpb=2665.2, bsz=96, num_updates=3270, lr=1.68681e-05, gnorm=1.555, clip=100, loss_scale=256, train_wall=28, gb_free=12.4, wall=13979
2023-04-08 19:56:18 - progress_bar.py[line:272] - INFO: epoch 006:    395 / 578 loss=2.464, loss_v1=0, loss_v2=0, nll_loss=1.276, ntokens=2563.3, nsentences=96, sample_size=2563.3, sample_size_v1=0, sample_size_v2=0, ppl=2.42, wps=901.3, ups=0.35, wpb=2563.3, bsz=96, num_updates=3280, lr=1.68221e-05, gnorm=1.56, clip=100, loss_scale=256, train_wall=28, gb_free=12.3, wall=14008
2023-04-08 19:56:47 - progress_bar.py[line:272] - INFO: epoch 006:    405 / 578 loss=2.449, loss_v1=0, loss_v2=0, nll_loss=1.261, ntokens=2479, nsentences=96, sample_size=2479, sample_size_v1=0, sample_size_v2=0, ppl=2.4, wps=867.3, ups=0.35, wpb=2479, bsz=96, num_updates=3290, lr=1.67761e-05, gnorm=1.665, clip=100, loss_scale=256, train_wall=29, gb_free=12.4, wall=14036
2023-04-08 19:57:15 - progress_bar.py[line:272] - INFO: epoch 006:    415 / 578 loss=2.468, loss_v1=0, loss_v2=0, nll_loss=1.276, ntokens=2482, nsentences=96, sample_size=2482, sample_size_v1=0, sample_size_v2=0, ppl=2.42, wps=874.4, ups=0.35, wpb=2482, bsz=96, num_updates=3300, lr=1.67301e-05, gnorm=1.619, clip=100, loss_scale=256, train_wall=28, gb_free=12.1, wall=14065
2023-04-08 19:57:43 - progress_bar.py[line:272] - INFO: epoch 006:    425 / 578 loss=2.453, loss_v1=0, loss_v2=0, nll_loss=1.265, ntokens=2477.2, nsentences=96, sample_size=2477.2, sample_size_v1=0, sample_size_v2=0, ppl=2.4, wps=873.6, ups=0.35, wpb=2477.2, bsz=96, num_updates=3310, lr=1.6684e-05, gnorm=1.644, clip=100, loss_scale=256, train_wall=28, gb_free=12.6, wall=14093
2023-04-08 19:58:12 - progress_bar.py[line:272] - INFO: epoch 006:    435 / 578 loss=2.452, loss_v1=0, loss_v2=0, nll_loss=1.259, ntokens=2542.9, nsentences=96, sample_size=2542.9, sample_size_v1=0, sample_size_v2=0, ppl=2.39, wps=899.2, ups=0.35, wpb=2542.9, bsz=96, num_updates=3320, lr=1.6638e-05, gnorm=1.537, clip=100, loss_scale=256, train_wall=28, gb_free=12.7, wall=14121
2023-04-08 19:58:40 - progress_bar.py[line:272] - INFO: epoch 006:    445 / 578 loss=2.472, loss_v1=0, loss_v2=0, nll_loss=1.286, ntokens=2425.5, nsentences=96, sample_size=2425.5, sample_size_v1=0, sample_size_v2=0, ppl=2.44, wps=857.1, ups=0.35, wpb=2425.5, bsz=96, num_updates=3330, lr=1.6592e-05, gnorm=1.581, clip=100, loss_scale=256, train_wall=28, gb_free=12.5, wall=14150
2023-04-08 19:59:08 - progress_bar.py[line:272] - INFO: epoch 006:    455 / 578 loss=2.454, loss_v1=0, loss_v2=0, nll_loss=1.264, ntokens=2554.3, nsentences=96, sample_size=2554.3, sample_size_v1=0, sample_size_v2=0, ppl=2.4, wps=902.7, ups=0.35, wpb=2554.3, bsz=96, num_updates=3340, lr=1.6546e-05, gnorm=1.616, clip=100, loss_scale=256, train_wall=28, gb_free=12.5, wall=14178
2023-04-08 19:59:37 - progress_bar.py[line:272] - INFO: epoch 006:    465 / 578 loss=2.468, loss_v1=0, loss_v2=0, nll_loss=1.282, ntokens=2531.4, nsentences=96, sample_size=2531.4, sample_size_v1=0, sample_size_v2=0, ppl=2.43, wps=891.9, ups=0.35, wpb=2531.4, bsz=96, num_updates=3350, lr=1.65e-05, gnorm=1.596, clip=100, loss_scale=256, train_wall=28, gb_free=12.1, wall=14206
2023-04-08 19:59:48 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 128.0
2023-04-08 20:00:08 - progress_bar.py[line:272] - INFO: epoch 006:    476 / 578 loss=2.476, loss_v1=0, loss_v2=0, nll_loss=1.285, ntokens=2346.7, nsentences=96, sample_size=2346.7, sample_size_v1=0, sample_size_v2=0, ppl=2.44, wps=751.8, ups=0.32, wpb=2346.7, bsz=96, num_updates=3360, lr=1.6454e-05, gnorm=1.616, clip=100, loss_scale=128, train_wall=31, gb_free=12.4, wall=14237
2023-04-08 20:00:36 - progress_bar.py[line:272] - INFO: epoch 006:    486 / 578 loss=2.45, loss_v1=0, loss_v2=0, nll_loss=1.262, ntokens=2398.1, nsentences=96, sample_size=2398.1, sample_size_v1=0, sample_size_v2=0, ppl=2.4, wps=849.6, ups=0.35, wpb=2398.1, bsz=96, num_updates=3370, lr=1.6408e-05, gnorm=1.616, clip=100, loss_scale=128, train_wall=28, gb_free=12.5, wall=14266
2023-04-08 20:01:04 - progress_bar.py[line:272] - INFO: epoch 006:    496 / 578 loss=2.443, loss_v1=0, loss_v2=0, nll_loss=1.25, ntokens=2565.9, nsentences=96, sample_size=2565.9, sample_size_v1=0, sample_size_v2=0, ppl=2.38, wps=905.4, ups=0.35, wpb=2565.9, bsz=96, num_updates=3380, lr=1.6362e-05, gnorm=1.588, clip=100, loss_scale=128, train_wall=28, gb_free=12.3, wall=14294
2023-04-08 20:01:33 - progress_bar.py[line:272] - INFO: epoch 006:    506 / 578 loss=2.44, loss_v1=0, loss_v2=0, nll_loss=1.25, ntokens=2521.1, nsentences=96, sample_size=2521.1, sample_size_v1=0, sample_size_v2=0, ppl=2.38, wps=889.5, ups=0.35, wpb=2521.1, bsz=96, num_updates=3390, lr=1.6316e-05, gnorm=1.646, clip=100, loss_scale=128, train_wall=28, gb_free=12.5, wall=14322
2023-04-08 20:02:01 - progress_bar.py[line:272] - INFO: epoch 006:    516 / 578 loss=2.446, loss_v1=0, loss_v2=0, nll_loss=1.254, ntokens=2627.3, nsentences=96, sample_size=2627.3, sample_size_v1=0, sample_size_v2=0, ppl=2.38, wps=925.2, ups=0.35, wpb=2627.3, bsz=96, num_updates=3400, lr=1.62699e-05, gnorm=1.617, clip=100, loss_scale=128, train_wall=28, gb_free=12.3, wall=14351
2023-04-08 20:02:30 - progress_bar.py[line:272] - INFO: epoch 006:    526 / 578 loss=2.446, loss_v1=0, loss_v2=0, nll_loss=1.256, ntokens=2612, nsentences=96, sample_size=2612, sample_size_v1=0, sample_size_v2=0, ppl=2.39, wps=918.8, ups=0.35, wpb=2612, bsz=96, num_updates=3410, lr=1.62239e-05, gnorm=1.542, clip=100, loss_scale=128, train_wall=28, gb_free=12.5, wall=14379
2023-04-08 20:02:58 - progress_bar.py[line:272] - INFO: epoch 006:    536 / 578 loss=2.438, loss_v1=0, loss_v2=0, nll_loss=1.244, ntokens=2536.4, nsentences=96, sample_size=2536.4, sample_size_v1=0, sample_size_v2=0, ppl=2.37, wps=897.5, ups=0.35, wpb=2536.4, bsz=96, num_updates=3420, lr=1.61779e-05, gnorm=1.617, clip=100, loss_scale=128, train_wall=28, gb_free=12.3, wall=14408
2023-04-08 20:03:26 - progress_bar.py[line:272] - INFO: epoch 006:    546 / 578 loss=2.449, loss_v1=0, loss_v2=0, nll_loss=1.26, ntokens=2511.8, nsentences=96, sample_size=2511.8, sample_size_v1=0, sample_size_v2=0, ppl=2.4, wps=886, ups=0.35, wpb=2511.8, bsz=96, num_updates=3430, lr=1.61319e-05, gnorm=1.63, clip=100, loss_scale=128, train_wall=28, gb_free=12.6, wall=14436
2023-04-08 20:03:55 - progress_bar.py[line:272] - INFO: epoch 006:    556 / 578 loss=2.435, loss_v1=0, loss_v2=0, nll_loss=1.242, ntokens=2654.8, nsentences=96, sample_size=2654.8, sample_size_v1=0, sample_size_v2=0, ppl=2.37, wps=926.9, ups=0.35, wpb=2654.8, bsz=96, num_updates=3440, lr=1.60859e-05, gnorm=1.508, clip=100, loss_scale=128, train_wall=29, gb_free=12.6, wall=14465
2023-04-08 20:04:23 - progress_bar.py[line:272] - INFO: epoch 006:    566 / 578 loss=2.434, loss_v1=0, loss_v2=0, nll_loss=1.242, ntokens=2638.7, nsentences=96, sample_size=2638.7, sample_size_v1=0, sample_size_v2=0, ppl=2.37, wps=927.7, ups=0.35, wpb=2638.7, bsz=96, num_updates=3450, lr=1.60399e-05, gnorm=1.51, clip=100, loss_scale=128, train_wall=28, gb_free=12, wall=14493
2023-04-08 20:04:52 - progress_bar.py[line:272] - INFO: epoch 006:    576 / 578 loss=2.454, loss_v1=0, loss_v2=0, nll_loss=1.264, ntokens=2591.6, nsentences=96, sample_size=2591.6, sample_size_v1=0, sample_size_v2=0, ppl=2.4, wps=909.6, ups=0.35, wpb=2591.6, bsz=96, num_updates=3460, lr=1.59939e-05, gnorm=1.579, clip=100, loss_scale=128, train_wall=28, gb_free=12.5, wall=14521
2023-04-08 20:04:55 - train.py[line:332] - INFO: end of epoch 6 (average epoch stats below)
local datafile ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 1 begin to initialize row_count and line_idx-to-offset mapping
2023-04-08 20:04:55 - progress_bar.py[line:282] - INFO: epoch 006 | loss 2.462 | loss_v1 0 | loss_v2 0 | nll_loss 1.273 | ntokens 2520.37 | nsentences 95.847 | sample_size 2520.37 | sample_size_v1 0 | sample_size_v2 0 | ppl 2.42 | wps 883 | ups 0.35 | wpb 2520.4 | bsz 95.8 | num_updates 3462 | lr 1.59847e-05 | gnorm 1.562 | clip 100 | loss_scale 128 | train_wall 1643 | gb_free 13.1 | wall 14525
2023-04-08 20:04:55 - trainer.py[line:639] - INFO: loading train data for epoch 7
local datafile ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 0 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 1 finished initializing row_count and line_idx-to-offset mapping
file ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 1 row count 27700 total row count 55400
local datafile ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 0 finished initializing row_count and line_idx-to-offset mapping
file ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 0 row count 27700 total row count 55400
slice_id 1 seek offset 27700
slice_id 0 seek offset 0
2023-04-08 20:04:57 - trainer.py[line:703] - INFO: begin training epoch 7
2023-04-08 20:04:57 - train.py[line:305] - INFO: Start iterating over samples
2023-04-08 20:05:20 - progress_bar.py[line:272] - INFO: epoch 007:      8 / 578 loss=2.445, loss_v1=0, loss_v2=0, nll_loss=1.252, ntokens=2274.5, nsentences=87.6, sample_size=2274.5, sample_size_v1=0, sample_size_v2=0, ppl=2.38, wps=796.3, ups=0.35, wpb=2274.5, bsz=87.6, num_updates=3470, lr=1.59479e-05, gnorm=1.947, clip=100, loss_scale=128, train_wall=26, gb_free=12.4, wall=14550
2023-04-08 20:05:49 - progress_bar.py[line:272] - INFO: epoch 007:     18 / 578 loss=2.438, loss_v1=0, loss_v2=0, nll_loss=1.247, ntokens=2350, nsentences=96, sample_size=2350, sample_size_v1=0, sample_size_v2=0, ppl=2.37, wps=822.2, ups=0.35, wpb=2350, bsz=96, num_updates=3480, lr=1.59018e-05, gnorm=1.688, clip=100, loss_scale=128, train_wall=29, gb_free=12, wall=14579
2023-04-08 20:06:18 - progress_bar.py[line:272] - INFO: epoch 007:     28 / 578 loss=2.412, loss_v1=0, loss_v2=0, nll_loss=1.217, ntokens=2357, nsentences=96, sample_size=2357, sample_size_v1=0, sample_size_v2=0, ppl=2.32, wps=822.7, ups=0.35, wpb=2357, bsz=96, num_updates=3490, lr=1.58558e-05, gnorm=1.755, clip=100, loss_scale=128, train_wall=29, gb_free=12.3, wall=14607
2023-04-08 20:06:46 - progress_bar.py[line:272] - INFO: epoch 007:     38 / 578 loss=2.435, loss_v1=0, loss_v2=0, nll_loss=1.243, ntokens=2186.9, nsentences=96, sample_size=2186.9, sample_size_v1=0, sample_size_v2=0, ppl=2.37, wps=765.8, ups=0.35, wpb=2186.9, bsz=96, num_updates=3500, lr=1.58098e-05, gnorm=1.985, clip=100, loss_scale=128, train_wall=29, gb_free=12.5, wall=14636
2023-04-08 20:07:15 - progress_bar.py[line:272] - INFO: epoch 007:     48 / 578 loss=2.406, loss_v1=0, loss_v2=0, nll_loss=1.209, ntokens=2411.7, nsentences=96, sample_size=2411.7, sample_size_v1=0, sample_size_v2=0, ppl=2.31, wps=824, ups=0.34, wpb=2411.7, bsz=96, num_updates=3510, lr=1.57638e-05, gnorm=1.768, clip=100, loss_scale=128, train_wall=29, gb_free=11.8, wall=14665
2023-04-08 20:07:44 - progress_bar.py[line:272] - INFO: epoch 007:     58 / 578 loss=2.456, loss_v1=0, loss_v2=0, nll_loss=1.266, ntokens=2244.7, nsentences=96, sample_size=2244.7, sample_size_v1=0, sample_size_v2=0, ppl=2.4, wps=775.7, ups=0.35, wpb=2244.7, bsz=96, num_updates=3520, lr=1.57178e-05, gnorm=1.806, clip=100, loss_scale=128, train_wall=29, gb_free=11.9, wall=14694
2023-04-08 20:08:13 - progress_bar.py[line:272] - INFO: epoch 007:     68 / 578 loss=2.456, loss_v1=0, loss_v2=0, nll_loss=1.268, ntokens=2323.5, nsentences=96, sample_size=2323.5, sample_size_v1=0, sample_size_v2=0, ppl=2.41, wps=814.5, ups=0.35, wpb=2323.5, bsz=96, num_updates=3530, lr=1.56718e-05, gnorm=1.841, clip=100, loss_scale=128, train_wall=28, gb_free=12.4, wall=14723
2023-04-08 20:08:42 - progress_bar.py[line:272] - INFO: epoch 007:     78 / 578 loss=2.46, loss_v1=0, loss_v2=0, nll_loss=1.27, ntokens=2468.3, nsentences=96, sample_size=2468.3, sample_size_v1=0, sample_size_v2=0, ppl=2.41, wps=860.5, ups=0.35, wpb=2468.3, bsz=96, num_updates=3540, lr=1.56258e-05, gnorm=1.748, clip=100, loss_scale=128, train_wall=29, gb_free=12.1, wall=14751
2023-04-08 20:09:11 - progress_bar.py[line:272] - INFO: epoch 007:     88 / 578 loss=2.462, loss_v1=0, loss_v2=0, nll_loss=1.272, ntokens=2524.1, nsentences=96, sample_size=2524.1, sample_size_v1=0, sample_size_v2=0, ppl=2.41, wps=869.4, ups=0.34, wpb=2524.1, bsz=96, num_updates=3550, lr=1.55798e-05, gnorm=1.775, clip=100, loss_scale=128, train_wall=29, gb_free=12, wall=14780
2023-04-08 20:09:40 - progress_bar.py[line:272] - INFO: epoch 007:     98 / 578 loss=2.456, loss_v1=0, loss_v2=0, nll_loss=1.266, ntokens=2422.9, nsentences=96, sample_size=2422.9, sample_size_v1=0, sample_size_v2=0, ppl=2.41, wps=836.9, ups=0.35, wpb=2422.9, bsz=96, num_updates=3560, lr=1.55337e-05, gnorm=1.689, clip=100, loss_scale=128, train_wall=29, gb_free=12.1, wall=14809
2023-04-08 20:10:09 - progress_bar.py[line:272] - INFO: epoch 007:    108 / 578 loss=2.449, loss_v1=0, loss_v2=0, nll_loss=1.258, ntokens=2446.6, nsentences=96, sample_size=2446.6, sample_size_v1=0, sample_size_v2=0, ppl=2.39, wps=843.7, ups=0.34, wpb=2446.6, bsz=96, num_updates=3570, lr=1.54877e-05, gnorm=1.739, clip=100, loss_scale=128, train_wall=29, gb_free=12.1, wall=14838
2023-04-08 20:10:37 - progress_bar.py[line:272] - INFO: epoch 007:    118 / 578 loss=2.459, loss_v1=0, loss_v2=0, nll_loss=1.27, ntokens=2356.2, nsentences=96, sample_size=2356.2, sample_size_v1=0, sample_size_v2=0, ppl=2.41, wps=822.2, ups=0.35, wpb=2356.2, bsz=96, num_updates=3580, lr=1.54417e-05, gnorm=1.915, clip=100, loss_scale=128, train_wall=29, gb_free=12, wall=14867
2023-04-08 20:11:06 - progress_bar.py[line:272] - INFO: epoch 007:    128 / 578 loss=2.457, loss_v1=0, loss_v2=0, nll_loss=1.268, ntokens=2399.5, nsentences=95.6, sample_size=2399.5, sample_size_v1=0, sample_size_v2=0, ppl=2.41, wps=835.1, ups=0.35, wpb=2399.5, bsz=95.6, num_updates=3590, lr=1.53957e-05, gnorm=1.849, clip=100, loss_scale=128, train_wall=29, gb_free=12.1, wall=14896
2023-04-08 20:11:35 - progress_bar.py[line:272] - INFO: epoch 007:    138 / 578 loss=2.463, loss_v1=0, loss_v2=0, nll_loss=1.274, ntokens=2366.3, nsentences=96, sample_size=2366.3, sample_size_v1=0, sample_size_v2=0, ppl=2.42, wps=829.1, ups=0.35, wpb=2366.3, bsz=96, num_updates=3600, lr=1.53497e-05, gnorm=1.91, clip=100, loss_scale=128, train_wall=29, gb_free=12.6, wall=14924
2023-04-08 20:12:03 - progress_bar.py[line:272] - INFO: epoch 007:    148 / 578 loss=2.464, loss_v1=0, loss_v2=0, nll_loss=1.276, ntokens=2656.4, nsentences=96, sample_size=2656.4, sample_size_v1=0, sample_size_v2=0, ppl=2.42, wps=929.5, ups=0.35, wpb=2656.4, bsz=96, num_updates=3610, lr=1.53037e-05, gnorm=1.674, clip=100, loss_scale=128, train_wall=29, gb_free=12.1, wall=14953
2023-04-08 20:12:32 - progress_bar.py[line:272] - INFO: epoch 007:    158 / 578 loss=2.462, loss_v1=0, loss_v2=0, nll_loss=1.27, ntokens=2667.4, nsentences=96, sample_size=2667.4, sample_size_v1=0, sample_size_v2=0, ppl=2.41, wps=938.7, ups=0.35, wpb=2667.4, bsz=96, num_updates=3620, lr=1.52577e-05, gnorm=1.661, clip=100, loss_scale=128, train_wall=28, gb_free=12.1, wall=14981
2023-04-08 20:13:00 - progress_bar.py[line:272] - INFO: epoch 007:    168 / 578 loss=2.458, loss_v1=0, loss_v2=0, nll_loss=1.269, ntokens=2630.9, nsentences=96, sample_size=2630.9, sample_size_v1=0, sample_size_v2=0, ppl=2.41, wps=921.1, ups=0.35, wpb=2630.9, bsz=96, num_updates=3630, lr=1.52117e-05, gnorm=1.683, clip=100, loss_scale=128, train_wall=29, gb_free=12.4, wall=15010
2023-04-08 20:13:29 - progress_bar.py[line:272] - INFO: epoch 007:    178 / 578 loss=2.464, loss_v1=0, loss_v2=0, nll_loss=1.274, ntokens=2596.2, nsentences=96, sample_size=2596.2, sample_size_v1=0, sample_size_v2=0, ppl=2.42, wps=912, ups=0.35, wpb=2596.2, bsz=96, num_updates=3640, lr=1.51656e-05, gnorm=1.717, clip=100, loss_scale=128, train_wall=28, gb_free=12.2, wall=15038
2023-04-08 20:13:57 - progress_bar.py[line:272] - INFO: epoch 007:    188 / 578 loss=2.466, loss_v1=0, loss_v2=0, nll_loss=1.278, ntokens=2687, nsentences=96, sample_size=2687, sample_size_v1=0, sample_size_v2=0, ppl=2.42, wps=940.2, ups=0.35, wpb=2687, bsz=96, num_updates=3650, lr=1.51196e-05, gnorm=1.727, clip=100, loss_scale=128, train_wall=29, gb_free=12.1, wall=15067
2023-04-08 20:14:26 - progress_bar.py[line:272] - INFO: epoch 007:    198 / 578 loss=2.445, loss_v1=0, loss_v2=0, nll_loss=1.254, ntokens=2579, nsentences=96, sample_size=2579, sample_size_v1=0, sample_size_v2=0, ppl=2.39, wps=905.9, ups=0.35, wpb=2579, bsz=96, num_updates=3660, lr=1.50736e-05, gnorm=1.889, clip=100, loss_scale=128, train_wall=28, gb_free=12.6, wall=15095
2023-04-08 20:14:54 - progress_bar.py[line:272] - INFO: epoch 007:    208 / 578 loss=2.449, loss_v1=0, loss_v2=0, nll_loss=1.259, ntokens=2577.2, nsentences=96, sample_size=2577.2, sample_size_v1=0, sample_size_v2=0, ppl=2.39, wps=908.1, ups=0.35, wpb=2577.2, bsz=96, num_updates=3670, lr=1.50276e-05, gnorm=1.785, clip=100, loss_scale=128, train_wall=28, gb_free=12.4, wall=15124
2023-04-08 20:15:22 - progress_bar.py[line:272] - INFO: epoch 007:    218 / 578 loss=2.471, loss_v1=0, loss_v2=0, nll_loss=1.284, ntokens=2499, nsentences=96, sample_size=2499, sample_size_v1=0, sample_size_v2=0, ppl=2.44, wps=880.2, ups=0.35, wpb=2499, bsz=96, num_updates=3680, lr=1.49816e-05, gnorm=1.892, clip=100, loss_scale=128, train_wall=28, gb_free=12.4, wall=15152
2023-04-08 20:15:51 - progress_bar.py[line:272] - INFO: epoch 007:    228 / 578 loss=2.433, loss_v1=0, loss_v2=0, nll_loss=1.241, ntokens=2513.4, nsentences=96, sample_size=2513.4, sample_size_v1=0, sample_size_v2=0, ppl=2.36, wps=885.8, ups=0.35, wpb=2513.4, bsz=96, num_updates=3690, lr=1.49356e-05, gnorm=1.799, clip=100, loss_scale=128, train_wall=28, gb_free=12.6, wall=15180
2023-04-08 20:16:19 - progress_bar.py[line:272] - INFO: epoch 007:    238 / 578 loss=2.459, loss_v1=0, loss_v2=0, nll_loss=1.271, ntokens=2453.7, nsentences=96, sample_size=2453.7, sample_size_v1=0, sample_size_v2=0, ppl=2.41, wps=868.1, ups=0.35, wpb=2453.7, bsz=96, num_updates=3700, lr=1.48896e-05, gnorm=1.848, clip=100, loss_scale=128, train_wall=28, gb_free=12.5, wall=15209
2023-04-08 20:16:47 - progress_bar.py[line:272] - INFO: epoch 007:    248 / 578 loss=2.462, loss_v1=0, loss_v2=0, nll_loss=1.27, ntokens=2500.1, nsentences=96, sample_size=2500.1, sample_size_v1=0, sample_size_v2=0, ppl=2.41, wps=884.4, ups=0.35, wpb=2500.1, bsz=96, num_updates=3710, lr=1.48436e-05, gnorm=1.752, clip=100, loss_scale=128, train_wall=28, gb_free=12.5, wall=15237
2023-04-08 20:17:16 - progress_bar.py[line:272] - INFO: epoch 007:    258 / 578 loss=2.447, loss_v1=0, loss_v2=0, nll_loss=1.259, ntokens=2595.5, nsentences=96, sample_size=2595.5, sample_size_v1=0, sample_size_v2=0, ppl=2.39, wps=915.3, ups=0.35, wpb=2595.5, bsz=96, num_updates=3720, lr=1.47975e-05, gnorm=1.809, clip=100, loss_scale=128, train_wall=28, gb_free=12.5, wall=15265
2023-04-08 20:17:44 - progress_bar.py[line:272] - INFO: epoch 007:    268 / 578 loss=2.45, loss_v1=0, loss_v2=0, nll_loss=1.258, ntokens=2482.6, nsentences=96, sample_size=2482.6, sample_size_v1=0, sample_size_v2=0, ppl=2.39, wps=876.9, ups=0.35, wpb=2482.6, bsz=96, num_updates=3730, lr=1.47515e-05, gnorm=1.742, clip=100, loss_scale=128, train_wall=28, gb_free=12.3, wall=15294
2023-04-08 20:18:12 - progress_bar.py[line:272] - INFO: epoch 007:    278 / 578 loss=2.446, loss_v1=0, loss_v2=0, nll_loss=1.256, ntokens=2624.5, nsentences=96, sample_size=2624.5, sample_size_v1=0, sample_size_v2=0, ppl=2.39, wps=923.6, ups=0.35, wpb=2624.5, bsz=96, num_updates=3740, lr=1.47055e-05, gnorm=1.703, clip=100, loss_scale=128, train_wall=28, gb_free=12.6, wall=15322
2023-04-08 20:18:41 - progress_bar.py[line:272] - INFO: epoch 007:    288 / 578 loss=2.437, loss_v1=0, loss_v2=0, nll_loss=1.245, ntokens=2557.2, nsentences=96, sample_size=2557.2, sample_size_v1=0, sample_size_v2=0, ppl=2.37, wps=900.4, ups=0.35, wpb=2557.2, bsz=96, num_updates=3750, lr=1.46595e-05, gnorm=1.687, clip=100, loss_scale=128, train_wall=28, gb_free=12.6, wall=15350
2023-04-08 20:19:09 - progress_bar.py[line:272] - INFO: epoch 007:    298 / 578 loss=2.461, loss_v1=0, loss_v2=0, nll_loss=1.273, ntokens=2565.2, nsentences=96, sample_size=2565.2, sample_size_v1=0, sample_size_v2=0, ppl=2.42, wps=901.6, ups=0.35, wpb=2565.2, bsz=96, num_updates=3760, lr=1.46135e-05, gnorm=1.792, clip=100, loss_scale=128, train_wall=28, gb_free=12, wall=15379
2023-04-08 20:19:38 - progress_bar.py[line:272] - INFO: epoch 007:    308 / 578 loss=2.448, loss_v1=0, loss_v2=0, nll_loss=1.257, ntokens=2579.7, nsentences=96, sample_size=2579.7, sample_size_v1=0, sample_size_v2=0, ppl=2.39, wps=906.4, ups=0.35, wpb=2579.7, bsz=96, num_updates=3770, lr=1.45675e-05, gnorm=1.775, clip=100, loss_scale=128, train_wall=28, gb_free=12.4, wall=15407
2023-04-08 20:20:06 - progress_bar.py[line:272] - INFO: epoch 007:    318 / 578 loss=2.457, loss_v1=0, loss_v2=0, nll_loss=1.266, ntokens=2671.7, nsentences=96, sample_size=2671.7, sample_size_v1=0, sample_size_v2=0, ppl=2.41, wps=937.2, ups=0.35, wpb=2671.7, bsz=96, num_updates=3780, lr=1.45215e-05, gnorm=1.702, clip=100, loss_scale=128, train_wall=28, gb_free=12.4, wall=15436
2023-04-08 20:20:35 - progress_bar.py[line:272] - INFO: epoch 007:    328 / 578 loss=2.429, loss_v1=0, loss_v2=0, nll_loss=1.237, ntokens=2531.6, nsentences=96, sample_size=2531.6, sample_size_v1=0, sample_size_v2=0, ppl=2.36, wps=890.5, ups=0.35, wpb=2531.6, bsz=96, num_updates=3790, lr=1.44755e-05, gnorm=1.711, clip=100, loss_scale=128, train_wall=28, gb_free=12.1, wall=15464
2023-04-08 20:21:03 - progress_bar.py[line:272] - INFO: epoch 007:    338 / 578 loss=2.44, loss_v1=0, loss_v2=0, nll_loss=1.249, ntokens=2599.2, nsentences=96, sample_size=2599.2, sample_size_v1=0, sample_size_v2=0, ppl=2.38, wps=916.8, ups=0.35, wpb=2599.2, bsz=96, num_updates=3800, lr=1.44294e-05, gnorm=1.711, clip=100, loss_scale=128, train_wall=28, gb_free=12.3, wall=15493
2023-04-08 20:21:31 - progress_bar.py[line:272] - INFO: epoch 007:    348 / 578 loss=2.434, loss_v1=0, loss_v2=0, nll_loss=1.241, ntokens=2690.7, nsentences=96, sample_size=2690.7, sample_size_v1=0, sample_size_v2=0, ppl=2.36, wps=947.6, ups=0.35, wpb=2690.7, bsz=96, num_updates=3810, lr=1.43834e-05, gnorm=1.71, clip=100, loss_scale=128, train_wall=28, gb_free=12.5, wall=15521
2023-04-08 20:22:00 - progress_bar.py[line:272] - INFO: epoch 007:    358 / 578 loss=2.427, loss_v1=0, loss_v2=0, nll_loss=1.236, ntokens=2575.6, nsentences=96, sample_size=2575.6, sample_size_v1=0, sample_size_v2=0, ppl=2.35, wps=908.6, ups=0.35, wpb=2575.6, bsz=96, num_updates=3820, lr=1.43374e-05, gnorm=1.822, clip=100, loss_scale=128, train_wall=28, gb_free=12.7, wall=15549
2023-04-08 20:22:28 - progress_bar.py[line:272] - INFO: epoch 007:    368 / 578 loss=2.459, loss_v1=0, loss_v2=0, nll_loss=1.269, ntokens=2834.9, nsentences=96, sample_size=2834.9, sample_size_v1=0, sample_size_v2=0, ppl=2.41, wps=995.3, ups=0.35, wpb=2834.9, bsz=96, num_updates=3830, lr=1.42914e-05, gnorm=1.638, clip=100, loss_scale=128, train_wall=28, gb_free=12.2, wall=15578
2023-04-08 20:22:57 - progress_bar.py[line:272] - INFO: epoch 007:    378 / 578 loss=2.45, loss_v1=0, loss_v2=0, nll_loss=1.26, ntokens=2728.8, nsentences=96, sample_size=2728.8, sample_size_v1=0, sample_size_v2=0, ppl=2.4, wps=956.2, ups=0.35, wpb=2728.8, bsz=96, num_updates=3840, lr=1.42454e-05, gnorm=1.757, clip=100, loss_scale=128, train_wall=29, gb_free=11.8, wall=15606
2023-04-08 20:23:25 - progress_bar.py[line:272] - INFO: epoch 007:    388 / 578 loss=2.452, loss_v1=0, loss_v2=0, nll_loss=1.261, ntokens=2622.3, nsentences=96, sample_size=2622.3, sample_size_v1=0, sample_size_v2=0, ppl=2.4, wps=920.4, ups=0.35, wpb=2622.3, bsz=96, num_updates=3850, lr=1.41994e-05, gnorm=1.723, clip=100, loss_scale=128, train_wall=28, gb_free=12.1, wall=15635
2023-04-08 20:23:54 - progress_bar.py[line:272] - INFO: epoch 007:    398 / 578 loss=2.434, loss_v1=0, loss_v2=0, nll_loss=1.242, ntokens=2541.9, nsentences=96, sample_size=2541.9, sample_size_v1=0, sample_size_v2=0, ppl=2.37, wps=893.7, ups=0.35, wpb=2541.9, bsz=96, num_updates=3860, lr=1.41534e-05, gnorm=1.844, clip=100, loss_scale=128, train_wall=28, gb_free=12.5, wall=15663
2023-04-08 20:24:22 - progress_bar.py[line:272] - INFO: epoch 007:    408 / 578 loss=2.439, loss_v1=0, loss_v2=0, nll_loss=1.248, ntokens=2450.1, nsentences=96, sample_size=2450.1, sample_size_v1=0, sample_size_v2=0, ppl=2.38, wps=865.3, ups=0.35, wpb=2450.1, bsz=96, num_updates=3870, lr=1.41074e-05, gnorm=1.824, clip=100, loss_scale=256, train_wall=28, gb_free=12.5, wall=15692
2023-04-08 20:24:50 - progress_bar.py[line:272] - INFO: epoch 007:    418 / 578 loss=2.448, loss_v1=0, loss_v2=0, nll_loss=1.255, ntokens=2487.1, nsentences=96, sample_size=2487.1, sample_size_v1=0, sample_size_v2=0, ppl=2.39, wps=878.6, ups=0.35, wpb=2487.1, bsz=96, num_updates=3880, lr=1.40613e-05, gnorm=1.747, clip=100, loss_scale=256, train_wall=28, gb_free=12.6, wall=15720
2023-04-08 20:24:56 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 128.0
2023-04-08 20:25:22 - progress_bar.py[line:272] - INFO: epoch 007:    429 / 578 loss=2.432, loss_v1=0, loss_v2=0, nll_loss=1.241, ntokens=2517.6, nsentences=96, sample_size=2517.6, sample_size_v1=0, sample_size_v2=0, ppl=2.36, wps=809.9, ups=0.32, wpb=2517.6, bsz=96, num_updates=3890, lr=1.40153e-05, gnorm=1.789, clip=100, loss_scale=128, train_wall=31, gb_free=12.5, wall=15751
2023-04-08 20:25:50 - progress_bar.py[line:272] - INFO: epoch 007:    439 / 578 loss=2.452, loss_v1=0, loss_v2=0, nll_loss=1.261, ntokens=2455.9, nsentences=96, sample_size=2455.9, sample_size_v1=0, sample_size_v2=0, ppl=2.4, wps=871.7, ups=0.35, wpb=2455.9, bsz=96, num_updates=3900, lr=1.39693e-05, gnorm=1.741, clip=100, loss_scale=128, train_wall=28, gb_free=12.6, wall=15779
2023-04-08 20:26:18 - progress_bar.py[line:272] - INFO: epoch 007:    449 / 578 loss=2.452, loss_v1=0, loss_v2=0, nll_loss=1.262, ntokens=2498.9, nsentences=96, sample_size=2498.9, sample_size_v1=0, sample_size_v2=0, ppl=2.4, wps=880.6, ups=0.35, wpb=2498.9, bsz=96, num_updates=3910, lr=1.39233e-05, gnorm=1.854, clip=100, loss_scale=128, train_wall=28, gb_free=12.6, wall=15808
2023-04-08 20:26:46 - progress_bar.py[line:272] - INFO: epoch 007:    459 / 578 loss=2.437, loss_v1=0, loss_v2=0, nll_loss=1.246, ntokens=2476.7, nsentences=96, sample_size=2476.7, sample_size_v1=0, sample_size_v2=0, ppl=2.37, wps=876.3, ups=0.35, wpb=2476.7, bsz=96, num_updates=3920, lr=1.38773e-05, gnorm=1.827, clip=100, loss_scale=128, train_wall=28, gb_free=12.4, wall=15836
2023-04-08 20:27:15 - progress_bar.py[line:272] - INFO: epoch 007:    469 / 578 loss=2.451, loss_v1=0, loss_v2=0, nll_loss=1.261, ntokens=2526.8, nsentences=96, sample_size=2526.8, sample_size_v1=0, sample_size_v2=0, ppl=2.4, wps=889.7, ups=0.35, wpb=2526.8, bsz=96, num_updates=3930, lr=1.38313e-05, gnorm=1.845, clip=100, loss_scale=128, train_wall=28, gb_free=12.4, wall=15864
2023-04-08 20:27:43 - progress_bar.py[line:272] - INFO: epoch 007:    479 / 578 loss=2.458, loss_v1=0, loss_v2=0, nll_loss=1.268, ntokens=2353.2, nsentences=96, sample_size=2353.2, sample_size_v1=0, sample_size_v2=0, ppl=2.41, wps=834.9, ups=0.35, wpb=2353.2, bsz=96, num_updates=3940, lr=1.37853e-05, gnorm=1.877, clip=100, loss_scale=128, train_wall=28, gb_free=12.7, wall=15893
2023-04-08 20:28:11 - progress_bar.py[line:272] - INFO: epoch 007:    489 / 578 loss=2.429, loss_v1=0, loss_v2=0, nll_loss=1.239, ntokens=2436.9, nsentences=96, sample_size=2436.9, sample_size_v1=0, sample_size_v2=0, ppl=2.36, wps=863.6, ups=0.35, wpb=2436.9, bsz=96, num_updates=3950, lr=1.37393e-05, gnorm=1.804, clip=100, loss_scale=128, train_wall=28, gb_free=12.2, wall=15921
2023-04-08 20:28:40 - progress_bar.py[line:272] - INFO: epoch 007:    499 / 578 loss=2.424, loss_v1=0, loss_v2=0, nll_loss=1.227, ntokens=2585.6, nsentences=96, sample_size=2585.6, sample_size_v1=0, sample_size_v2=0, ppl=2.34, wps=910.1, ups=0.35, wpb=2585.6, bsz=96, num_updates=3960, lr=1.36933e-05, gnorm=1.783, clip=100, loss_scale=128, train_wall=28, gb_free=12.5, wall=15949
2023-04-08 20:29:08 - progress_bar.py[line:272] - INFO: epoch 007:    509 / 578 loss=2.432, loss_v1=0, loss_v2=0, nll_loss=1.243, ntokens=2554.3, nsentences=96, sample_size=2554.3, sample_size_v1=0, sample_size_v2=0, ppl=2.37, wps=899.2, ups=0.35, wpb=2554.3, bsz=96, num_updates=3970, lr=1.36472e-05, gnorm=1.852, clip=100, loss_scale=128, train_wall=28, gb_free=12.5, wall=15978
2023-04-08 20:29:36 - progress_bar.py[line:272] - INFO: epoch 007:    519 / 578 loss=2.418, loss_v1=0, loss_v2=0, nll_loss=1.222, ntokens=2670.7, nsentences=96, sample_size=2670.7, sample_size_v1=0, sample_size_v2=0, ppl=2.33, wps=941.1, ups=0.35, wpb=2670.7, bsz=96, num_updates=3980, lr=1.36012e-05, gnorm=1.809, clip=100, loss_scale=128, train_wall=28, gb_free=12.7, wall=16006
2023-04-08 20:30:05 - progress_bar.py[line:272] - INFO: epoch 007:    529 / 578 loss=2.433, loss_v1=0, loss_v2=0, nll_loss=1.243, ntokens=2575.7, nsentences=96, sample_size=2575.7, sample_size_v1=0, sample_size_v2=0, ppl=2.37, wps=912.1, ups=0.35, wpb=2575.7, bsz=96, num_updates=3990, lr=1.35552e-05, gnorm=1.901, clip=100, loss_scale=128, train_wall=28, gb_free=12.4, wall=16034
2023-04-08 20:30:33 - progress_bar.py[line:272] - INFO: epoch 007:    539 / 578 loss=2.42, loss_v1=0, loss_v2=0, nll_loss=1.225, ntokens=2477.8, nsentences=96, sample_size=2477.8, sample_size_v1=0, sample_size_v2=0, ppl=2.34, wps=876.5, ups=0.35, wpb=2477.8, bsz=96, num_updates=4000, lr=1.35092e-05, gnorm=1.788, clip=100, loss_scale=128, train_wall=28, gb_free=12.4, wall=16063
2023-04-08 20:31:01 - progress_bar.py[line:272] - INFO: epoch 007:    549 / 578 loss=2.43, loss_v1=0, loss_v2=0, nll_loss=1.237, ntokens=2554.8, nsentences=96, sample_size=2554.8, sample_size_v1=0, sample_size_v2=0, ppl=2.36, wps=897.8, ups=0.35, wpb=2554.8, bsz=96, num_updates=4010, lr=1.34632e-05, gnorm=1.889, clip=100, loss_scale=128, train_wall=28, gb_free=12.2, wall=16091
2023-04-08 20:31:30 - progress_bar.py[line:272] - INFO: epoch 007:    559 / 578 loss=2.415, loss_v1=0, loss_v2=0, nll_loss=1.221, ntokens=2596.9, nsentences=96, sample_size=2596.9, sample_size_v1=0, sample_size_v2=0, ppl=2.33, wps=911, ups=0.35, wpb=2596.9, bsz=96, num_updates=4020, lr=1.34172e-05, gnorm=1.747, clip=100, loss_scale=128, train_wall=28, gb_free=12.5, wall=16119
2023-04-08 20:31:58 - progress_bar.py[line:272] - INFO: epoch 007:    569 / 578 loss=2.418, loss_v1=0, loss_v2=0, nll_loss=1.225, ntokens=2697.6, nsentences=96, sample_size=2697.6, sample_size_v1=0, sample_size_v2=0, ppl=2.34, wps=945.5, ups=0.35, wpb=2697.6, bsz=96, num_updates=4030, lr=1.33712e-05, gnorm=1.725, clip=100, loss_scale=128, train_wall=29, gb_free=12.5, wall=16148
2023-04-08 20:32:21 - train.py[line:332] - INFO: end of epoch 7 (average epoch stats below)
local datafile ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 1 begin to initialize row_count and line_idx-to-offset mapping
2023-04-08 20:32:21 - progress_bar.py[line:282] - INFO: epoch 007 | loss 2.445 | loss_v1 0 | loss_v2 0 | nll_loss 1.254 | ntokens 2519.93 | nsentences 95.847 | sample_size 2519.93 | sample_size_v1 0 | sample_size_v2 0 | ppl 2.38 | wps 883.1 | ups 0.35 | wpb 2519.9 | bsz 95.8 | num_updates 4039 | lr 1.33298e-05 | gnorm 1.786 | clip 100 | loss_scale 128 | train_wall 1642 | gb_free 13.1 | wall 16171
2023-04-08 20:32:21 - trainer.py[line:639] - INFO: loading train data for epoch 8
local datafile ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 0 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 0 finished initializing row_count and line_idx-to-offset mapping
file ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 0 row count 27700 total row count 55400
slice_id 0 seek offset 0
2023-04-08 20:32:23 - trainer.py[line:703] - INFO: begin training epoch 8
2023-04-08 20:32:23 - train.py[line:305] - INFO: Start iterating over samples
local datafile ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 1 finished initializing row_count and line_idx-to-offset mapping
file ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 1 row count 27700 total row count 55400
slice_id 1 seek offset 27700
2023-04-08 20:32:27 - progress_bar.py[line:272] - INFO: epoch 008:      1 / 578 loss=2.447, loss_v1=0, loss_v2=0, nll_loss=1.256, ntokens=2370.8, nsentences=87.6, sample_size=2370.8, sample_size_v1=0, sample_size_v2=0, ppl=2.39, wps=839.7, ups=0.35, wpb=2370.8, bsz=87.6, num_updates=4040, lr=1.33252e-05, gnorm=2.012, clip=100, loss_scale=128, train_wall=26, gb_free=12.3, wall=16176
2023-04-08 20:32:55 - progress_bar.py[line:272] - INFO: epoch 008:     11 / 578 loss=2.415, loss_v1=0, loss_v2=0, nll_loss=1.219, ntokens=2417.4, nsentences=96, sample_size=2417.4, sample_size_v1=0, sample_size_v2=0, ppl=2.33, wps=845.5, ups=0.35, wpb=2417.4, bsz=96, num_updates=4050, lr=1.32791e-05, gnorm=1.82, clip=100, loss_scale=128, train_wall=29, gb_free=12.4, wall=16205
2023-04-08 20:33:24 - progress_bar.py[line:272] - INFO: epoch 008:     21 / 578 loss=2.417, loss_v1=0, loss_v2=0, nll_loss=1.223, ntokens=2340.4, nsentences=95.6, sample_size=2340.4, sample_size_v1=0, sample_size_v2=0, ppl=2.33, wps=823, ups=0.35, wpb=2340.4, bsz=95.6, num_updates=4060, lr=1.32331e-05, gnorm=1.979, clip=100, loss_scale=128, train_wall=28, gb_free=12, wall=16233
2023-04-08 20:33:52 - progress_bar.py[line:272] - INFO: epoch 008:     31 / 578 loss=2.418, loss_v1=0, loss_v2=0, nll_loss=1.225, ntokens=2289.3, nsentences=96, sample_size=2289.3, sample_size_v1=0, sample_size_v2=0, ppl=2.34, wps=798.4, ups=0.35, wpb=2289.3, bsz=96, num_updates=4070, lr=1.31871e-05, gnorm=1.95, clip=100, loss_scale=128, train_wall=29, gb_free=12.3, wall=16262
2023-04-08 20:34:21 - progress_bar.py[line:272] - INFO: epoch 008:     41 / 578 loss=2.397, loss_v1=0, loss_v2=0, nll_loss=1.2, ntokens=2191.7, nsentences=96, sample_size=2191.7, sample_size_v1=0, sample_size_v2=0, ppl=2.3, wps=763.1, ups=0.35, wpb=2191.7, bsz=96, num_updates=4080, lr=1.31411e-05, gnorm=2.125, clip=100, loss_scale=128, train_wall=29, gb_free=11.7, wall=16291
2023-04-08 20:34:50 - progress_bar.py[line:272] - INFO: epoch 008:     51 / 578 loss=2.395, loss_v1=0, loss_v2=0, nll_loss=1.198, ntokens=2411.2, nsentences=96, sample_size=2411.2, sample_size_v1=0, sample_size_v2=0, ppl=2.29, wps=822.1, ups=0.34, wpb=2411.2, bsz=96, num_updates=4090, lr=1.30951e-05, gnorm=2.013, clip=100, loss_scale=128, train_wall=29, gb_free=11.7, wall=16320
2023-04-08 20:35:19 - progress_bar.py[line:272] - INFO: epoch 008:     61 / 578 loss=2.451, loss_v1=0, loss_v2=0, nll_loss=1.259, ntokens=2277.5, nsentences=96, sample_size=2277.5, sample_size_v1=0, sample_size_v2=0, ppl=2.39, wps=787.4, ups=0.35, wpb=2277.5, bsz=96, num_updates=4100, lr=1.30491e-05, gnorm=1.984, clip=100, loss_scale=128, train_wall=29, gb_free=12.5, wall=16349
2023-04-08 20:35:48 - progress_bar.py[line:272] - INFO: epoch 008:     71 / 578 loss=2.442, loss_v1=0, loss_v2=0, nll_loss=1.253, ntokens=2326.6, nsentences=96, sample_size=2326.6, sample_size_v1=0, sample_size_v2=0, ppl=2.38, wps=816, ups=0.35, wpb=2326.6, bsz=96, num_updates=4110, lr=1.30031e-05, gnorm=2.043, clip=100, loss_scale=128, train_wall=28, gb_free=11.7, wall=16378
2023-04-08 20:36:17 - progress_bar.py[line:272] - INFO: epoch 008:     81 / 578 loss=2.445, loss_v1=0, loss_v2=0, nll_loss=1.253, ntokens=2530.1, nsentences=96, sample_size=2530.1, sample_size_v1=0, sample_size_v2=0, ppl=2.38, wps=876.1, ups=0.35, wpb=2530.1, bsz=96, num_updates=4120, lr=1.29571e-05, gnorm=2.034, clip=100, loss_scale=128, train_wall=29, gb_free=12.2, wall=16406
2023-04-08 20:36:46 - progress_bar.py[line:272] - INFO: epoch 008:     91 / 578 loss=2.446, loss_v1=0, loss_v2=0, nll_loss=1.253, ntokens=2516.1, nsentences=96, sample_size=2516.1, sample_size_v1=0, sample_size_v2=0, ppl=2.38, wps=867.1, ups=0.34, wpb=2516.1, bsz=96, num_updates=4130, lr=1.2911e-05, gnorm=1.81, clip=100, loss_scale=128, train_wall=29, gb_free=11.9, wall=16435
2023-04-08 20:37:15 - progress_bar.py[line:272] - INFO: epoch 008:    101 / 578 loss=2.434, loss_v1=0, loss_v2=0, nll_loss=1.243, ntokens=2422.6, nsentences=96, sample_size=2422.6, sample_size_v1=0, sample_size_v2=0, ppl=2.37, wps=830.5, ups=0.34, wpb=2422.6, bsz=96, num_updates=4140, lr=1.2865e-05, gnorm=1.862, clip=100, loss_scale=128, train_wall=29, gb_free=11.5, wall=16465
2023-04-08 20:37:44 - progress_bar.py[line:272] - INFO: epoch 008:    111 / 578 loss=2.448, loss_v1=0, loss_v2=0, nll_loss=1.256, ntokens=2433, nsentences=96, sample_size=2433, sample_size_v1=0, sample_size_v2=0, ppl=2.39, wps=841.7, ups=0.35, wpb=2433, bsz=96, num_updates=4150, lr=1.2819e-05, gnorm=1.892, clip=100, loss_scale=128, train_wall=29, gb_free=11.7, wall=16493
2023-04-08 20:38:13 - progress_bar.py[line:272] - INFO: epoch 008:    121 / 578 loss=2.442, loss_v1=0, loss_v2=0, nll_loss=1.25, ntokens=2330.1, nsentences=96, sample_size=2330.1, sample_size_v1=0, sample_size_v2=0, ppl=2.38, wps=810.2, ups=0.35, wpb=2330.1, bsz=96, num_updates=4160, lr=1.2773e-05, gnorm=1.955, clip=100, loss_scale=128, train_wall=29, gb_free=12.2, wall=16522
2023-04-08 20:38:42 - progress_bar.py[line:272] - INFO: epoch 008:    131 / 578 loss=2.445, loss_v1=0, loss_v2=0, nll_loss=1.254, ntokens=2424.5, nsentences=96, sample_size=2424.5, sample_size_v1=0, sample_size_v2=0, ppl=2.39, wps=837.2, ups=0.35, wpb=2424.5, bsz=96, num_updates=4170, lr=1.2727e-05, gnorm=1.874, clip=100, loss_scale=128, train_wall=29, gb_free=12.3, wall=16551
2023-04-08 20:39:10 - progress_bar.py[line:272] - INFO: epoch 008:    141 / 578 loss=2.453, loss_v1=0, loss_v2=0, nll_loss=1.263, ntokens=2413.2, nsentences=96, sample_size=2413.2, sample_size_v1=0, sample_size_v2=0, ppl=2.4, wps=847, ups=0.35, wpb=2413.2, bsz=96, num_updates=4180, lr=1.2681e-05, gnorm=1.932, clip=100, loss_scale=128, train_wall=28, gb_free=12.1, wall=16580
2023-04-08 20:39:39 - progress_bar.py[line:272] - INFO: epoch 008:    151 / 578 loss=2.442, loss_v1=0, loss_v2=0, nll_loss=1.25, ntokens=2654.2, nsentences=96, sample_size=2654.2, sample_size_v1=0, sample_size_v2=0, ppl=2.38, wps=932.3, ups=0.35, wpb=2654.2, bsz=96, num_updates=4190, lr=1.2635e-05, gnorm=1.876, clip=100, loss_scale=128, train_wall=28, gb_free=12.3, wall=16608
2023-04-08 20:40:07 - progress_bar.py[line:272] - INFO: epoch 008:    161 / 578 loss=2.445, loss_v1=0, loss_v2=0, nll_loss=1.253, ntokens=2712.2, nsentences=96, sample_size=2712.2, sample_size_v1=0, sample_size_v2=0, ppl=2.38, wps=950.9, ups=0.35, wpb=2712.2, bsz=96, num_updates=4200, lr=1.2589e-05, gnorm=1.674, clip=100, loss_scale=128, train_wall=28, gb_free=12.2, wall=16637
2023-04-08 20:40:36 - progress_bar.py[line:272] - INFO: epoch 008:    171 / 578 loss=2.45, loss_v1=0, loss_v2=0, nll_loss=1.259, ntokens=2598.7, nsentences=96, sample_size=2598.7, sample_size_v1=0, sample_size_v2=0, ppl=2.39, wps=910.4, ups=0.35, wpb=2598.7, bsz=96, num_updates=4210, lr=1.25429e-05, gnorm=1.846, clip=100, loss_scale=128, train_wall=29, gb_free=12.4, wall=16665
2023-04-08 20:41:04 - progress_bar.py[line:272] - INFO: epoch 008:    181 / 578 loss=2.441, loss_v1=0, loss_v2=0, nll_loss=1.249, ntokens=2627.6, nsentences=96, sample_size=2627.6, sample_size_v1=0, sample_size_v2=0, ppl=2.38, wps=920.1, ups=0.35, wpb=2627.6, bsz=96, num_updates=4220, lr=1.24969e-05, gnorm=1.778, clip=100, loss_scale=128, train_wall=29, gb_free=12.3, wall=16694
2023-04-08 20:41:33 - progress_bar.py[line:272] - INFO: epoch 008:    191 / 578 loss=2.447, loss_v1=0, loss_v2=0, nll_loss=1.257, ntokens=2657.2, nsentences=96, sample_size=2657.2, sample_size_v1=0, sample_size_v2=0, ppl=2.39, wps=927.7, ups=0.35, wpb=2657.2, bsz=96, num_updates=4230, lr=1.24509e-05, gnorm=1.836, clip=100, loss_scale=128, train_wall=29, gb_free=11.8, wall=16722
2023-04-08 20:42:01 - progress_bar.py[line:272] - INFO: epoch 008:    201 / 578 loss=2.44, loss_v1=0, loss_v2=0, nll_loss=1.248, ntokens=2568.6, nsentences=96, sample_size=2568.6, sample_size_v1=0, sample_size_v2=0, ppl=2.37, wps=903.3, ups=0.35, wpb=2568.6, bsz=96, num_updates=4240, lr=1.24049e-05, gnorm=1.965, clip=100, loss_scale=128, train_wall=28, gb_free=12.5, wall=16751
2023-04-08 20:42:30 - progress_bar.py[line:272] - INFO: epoch 008:    211 / 578 loss=2.435, loss_v1=0, loss_v2=0, nll_loss=1.242, ntokens=2514.1, nsentences=96, sample_size=2514.1, sample_size_v1=0, sample_size_v2=0, ppl=2.37, wps=887.4, ups=0.35, wpb=2514.1, bsz=96, num_updates=4250, lr=1.23589e-05, gnorm=1.896, clip=100, loss_scale=128, train_wall=28, gb_free=12.2, wall=16779
2023-04-08 20:42:58 - progress_bar.py[line:272] - INFO: epoch 008:    221 / 578 loss=2.448, loss_v1=0, loss_v2=0, nll_loss=1.257, ntokens=2574.1, nsentences=96, sample_size=2574.1, sample_size_v1=0, sample_size_v2=0, ppl=2.39, wps=907.8, ups=0.35, wpb=2574.1, bsz=96, num_updates=4260, lr=1.23129e-05, gnorm=1.935, clip=100, loss_scale=128, train_wall=28, gb_free=12.1, wall=16808
2023-04-08 20:43:26 - progress_bar.py[line:272] - INFO: epoch 008:    231 / 578 loss=2.417, loss_v1=0, loss_v2=0, nll_loss=1.224, ntokens=2443.6, nsentences=96, sample_size=2443.6, sample_size_v1=0, sample_size_v2=0, ppl=2.34, wps=864.2, ups=0.35, wpb=2443.6, bsz=96, num_updates=4270, lr=1.22669e-05, gnorm=1.944, clip=100, loss_scale=128, train_wall=28, gb_free=12.5, wall=16836
2023-04-08 20:43:54 - progress_bar.py[line:272] - INFO: epoch 008:    241 / 578 loss=2.45, loss_v1=0, loss_v2=0, nll_loss=1.26, ntokens=2489.2, nsentences=96, sample_size=2489.2, sample_size_v1=0, sample_size_v2=0, ppl=2.39, wps=881, ups=0.35, wpb=2489.2, bsz=96, num_updates=4280, lr=1.22209e-05, gnorm=1.939, clip=100, loss_scale=128, train_wall=28, gb_free=12.4, wall=16864
2023-04-08 20:44:23 - progress_bar.py[line:272] - INFO: epoch 008:    251 / 578 loss=2.439, loss_v1=0, loss_v2=0, nll_loss=1.245, ntokens=2535.5, nsentences=96, sample_size=2535.5, sample_size_v1=0, sample_size_v2=0, ppl=2.37, wps=898.1, ups=0.35, wpb=2535.5, bsz=96, num_updates=4290, lr=1.21748e-05, gnorm=1.92, clip=100, loss_scale=128, train_wall=28, gb_free=12.3, wall=16892
2023-04-08 20:44:51 - progress_bar.py[line:272] - INFO: epoch 008:    261 / 578 loss=2.434, loss_v1=0, loss_v2=0, nll_loss=1.244, ntokens=2517.8, nsentences=96, sample_size=2517.8, sample_size_v1=0, sample_size_v2=0, ppl=2.37, wps=891, ups=0.35, wpb=2517.8, bsz=96, num_updates=4300, lr=1.21288e-05, gnorm=1.966, clip=100, loss_scale=128, train_wall=28, gb_free=12.7, wall=16921
2023-04-08 20:45:19 - progress_bar.py[line:272] - INFO: epoch 008:    271 / 578 loss=2.439, loss_v1=0, loss_v2=0, nll_loss=1.246, ntokens=2570, nsentences=96, sample_size=2570, sample_size_v1=0, sample_size_v2=0, ppl=2.37, wps=906.5, ups=0.35, wpb=2570, bsz=96, num_updates=4310, lr=1.20828e-05, gnorm=1.906, clip=100, loss_scale=128, train_wall=28, gb_free=12.4, wall=16949
2023-04-08 20:45:48 - progress_bar.py[line:272] - INFO: epoch 008:    281 / 578 loss=2.43, loss_v1=0, loss_v2=0, nll_loss=1.239, ntokens=2572.9, nsentences=96, sample_size=2572.9, sample_size_v1=0, sample_size_v2=0, ppl=2.36, wps=905, ups=0.35, wpb=2572.9, bsz=96, num_updates=4320, lr=1.20368e-05, gnorm=1.802, clip=100, loss_scale=128, train_wall=28, gb_free=12.2, wall=16977
2023-04-08 20:46:16 - progress_bar.py[line:272] - INFO: epoch 008:    291 / 578 loss=2.429, loss_v1=0, loss_v2=0, nll_loss=1.237, ntokens=2614.3, nsentences=96, sample_size=2614.3, sample_size_v1=0, sample_size_v2=0, ppl=2.36, wps=921.2, ups=0.35, wpb=2614.3, bsz=96, num_updates=4330, lr=1.19908e-05, gnorm=1.771, clip=100, loss_scale=128, train_wall=28, gb_free=12.2, wall=17006
2023-04-08 20:46:45 - progress_bar.py[line:272] - INFO: epoch 008:    301 / 578 loss=2.434, loss_v1=0, loss_v2=0, nll_loss=1.24, ntokens=2493.7, nsentences=96, sample_size=2493.7, sample_size_v1=0, sample_size_v2=0, ppl=2.36, wps=878.1, ups=0.35, wpb=2493.7, bsz=96, num_updates=4340, lr=1.19448e-05, gnorm=2.01, clip=100, loss_scale=128, train_wall=28, gb_free=12.1, wall=17034
2023-04-08 20:47:13 - progress_bar.py[line:272] - INFO: epoch 008:    311 / 578 loss=2.44, loss_v1=0, loss_v2=0, nll_loss=1.249, ntokens=2623, nsentences=96, sample_size=2623, sample_size_v1=0, sample_size_v2=0, ppl=2.38, wps=921.6, ups=0.35, wpb=2623, bsz=96, num_updates=4350, lr=1.18988e-05, gnorm=1.841, clip=100, loss_scale=128, train_wall=28, gb_free=12.2, wall=17063
2023-04-08 20:47:42 - progress_bar.py[line:272] - INFO: epoch 008:    321 / 578 loss=2.44, loss_v1=0, loss_v2=0, nll_loss=1.248, ntokens=2644.8, nsentences=96, sample_size=2644.8, sample_size_v1=0, sample_size_v2=0, ppl=2.37, wps=928.7, ups=0.35, wpb=2644.8, bsz=96, num_updates=4360, lr=1.18528e-05, gnorm=1.819, clip=100, loss_scale=128, train_wall=28, gb_free=12.7, wall=17091
2023-04-08 20:48:10 - progress_bar.py[line:272] - INFO: epoch 008:    331 / 578 loss=2.406, loss_v1=0, loss_v2=0, nll_loss=1.211, ntokens=2542.6, nsentences=96, sample_size=2542.6, sample_size_v1=0, sample_size_v2=0, ppl=2.31, wps=893.1, ups=0.35, wpb=2542.6, bsz=96, num_updates=4370, lr=1.18067e-05, gnorm=2.01, clip=100, loss_scale=128, train_wall=28, gb_free=12.3, wall=17120
2023-04-08 20:48:38 - progress_bar.py[line:272] - INFO: epoch 008:    341 / 578 loss=2.446, loss_v1=0, loss_v2=0, nll_loss=1.256, ntokens=2652.7, nsentences=96, sample_size=2652.7, sample_size_v1=0, sample_size_v2=0, ppl=2.39, wps=935.9, ups=0.35, wpb=2652.7, bsz=96, num_updates=4380, lr=1.17607e-05, gnorm=1.937, clip=100, loss_scale=128, train_wall=28, gb_free=12.8, wall=17148
2023-04-08 20:49:07 - progress_bar.py[line:272] - INFO: epoch 008:    351 / 578 loss=2.41, loss_v1=0, loss_v2=0, nll_loss=1.214, ntokens=2617.4, nsentences=96, sample_size=2617.4, sample_size_v1=0, sample_size_v2=0, ppl=2.32, wps=924.8, ups=0.35, wpb=2617.4, bsz=96, num_updates=4390, lr=1.17147e-05, gnorm=1.897, clip=100, loss_scale=128, train_wall=28, gb_free=12.5, wall=17176
2023-04-08 20:49:18 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 128.0
2023-04-08 20:49:38 - progress_bar.py[line:272] - INFO: epoch 008:    362 / 578 loss=2.421, loss_v1=0, loss_v2=0, nll_loss=1.229, ntokens=2679.9, nsentences=96, sample_size=2679.9, sample_size_v1=0, sample_size_v2=0, ppl=2.34, wps=858.8, ups=0.32, wpb=2679.9, bsz=96, num_updates=4400, lr=1.16687e-05, gnorm=1.867, clip=100, loss_scale=128, train_wall=31, gb_free=12.1, wall=17207
2023-04-08 20:50:06 - progress_bar.py[line:272] - INFO: epoch 008:    372 / 578 loss=2.444, loss_v1=0, loss_v2=0, nll_loss=1.253, ntokens=2824.9, nsentences=96, sample_size=2824.9, sample_size_v1=0, sample_size_v2=0, ppl=2.38, wps=989, ups=0.35, wpb=2824.9, bsz=96, num_updates=4410, lr=1.16227e-05, gnorm=1.816, clip=100, loss_scale=128, train_wall=29, gb_free=12.3, wall=17236
2023-04-08 20:50:35 - progress_bar.py[line:272] - INFO: epoch 008:    382 / 578 loss=2.437, loss_v1=0, loss_v2=0, nll_loss=1.245, ntokens=2710.7, nsentences=96, sample_size=2710.7, sample_size_v1=0, sample_size_v2=0, ppl=2.37, wps=952.1, ups=0.35, wpb=2710.7, bsz=96, num_updates=4420, lr=1.15767e-05, gnorm=1.941, clip=100, loss_scale=128, train_wall=28, gb_free=12.3, wall=17265
2023-04-08 20:51:03 - progress_bar.py[line:272] - INFO: epoch 008:    392 / 578 loss=2.437, loss_v1=0, loss_v2=0, nll_loss=1.245, ntokens=2544.6, nsentences=96, sample_size=2544.6, sample_size_v1=0, sample_size_v2=0, ppl=2.37, wps=894.3, ups=0.35, wpb=2544.6, bsz=96, num_updates=4430, lr=1.15307e-05, gnorm=2.071, clip=100, loss_scale=128, train_wall=28, gb_free=12.6, wall=17293
2023-04-08 20:51:32 - progress_bar.py[line:272] - INFO: epoch 008:    402 / 578 loss=2.411, loss_v1=0, loss_v2=0, nll_loss=1.218, ntokens=2542.9, nsentences=96, sample_size=2542.9, sample_size_v1=0, sample_size_v2=0, ppl=2.33, wps=895.5, ups=0.35, wpb=2542.9, bsz=96, num_updates=4440, lr=1.14847e-05, gnorm=2.047, clip=100, loss_scale=128, train_wall=28, gb_free=12.4, wall=17321
2023-04-08 20:52:00 - progress_bar.py[line:272] - INFO: epoch 008:    412 / 578 loss=2.436, loss_v1=0, loss_v2=0, nll_loss=1.244, ntokens=2415.7, nsentences=96, sample_size=2415.7, sample_size_v1=0, sample_size_v2=0, ppl=2.37, wps=853.7, ups=0.35, wpb=2415.7, bsz=96, num_updates=4450, lr=1.14387e-05, gnorm=2.296, clip=100, loss_scale=128, train_wall=28, gb_free=12.5, wall=17350
2023-04-08 20:52:28 - progress_bar.py[line:272] - INFO: epoch 008:    422 / 578 loss=2.425, loss_v1=0, loss_v2=0, nll_loss=1.231, ntokens=2497.7, nsentences=96, sample_size=2497.7, sample_size_v1=0, sample_size_v2=0, ppl=2.35, wps=882.6, ups=0.35, wpb=2497.7, bsz=96, num_updates=4460, lr=1.13926e-05, gnorm=2.116, clip=100, loss_scale=128, train_wall=28, gb_free=12.5, wall=17378
2023-04-08 20:52:57 - progress_bar.py[line:272] - INFO: epoch 008:    432 / 578 loss=2.418, loss_v1=0, loss_v2=0, nll_loss=1.223, ntokens=2542.6, nsentences=96, sample_size=2542.6, sample_size_v1=0, sample_size_v2=0, ppl=2.33, wps=899.9, ups=0.35, wpb=2542.6, bsz=96, num_updates=4470, lr=1.13466e-05, gnorm=1.986, clip=100, loss_scale=128, train_wall=28, gb_free=12.6, wall=17406
2023-04-08 20:53:25 - progress_bar.py[line:272] - INFO: epoch 008:    442 / 578 loss=2.434, loss_v1=0, loss_v2=0, nll_loss=1.241, ntokens=2446.7, nsentences=96, sample_size=2446.7, sample_size_v1=0, sample_size_v2=0, ppl=2.36, wps=868, ups=0.35, wpb=2446.7, bsz=96, num_updates=4480, lr=1.13006e-05, gnorm=2.044, clip=100, loss_scale=128, train_wall=28, gb_free=12.4, wall=17434
2023-04-08 20:53:53 - progress_bar.py[line:272] - INFO: epoch 008:    452 / 578 loss=2.431, loss_v1=0, loss_v2=0, nll_loss=1.238, ntokens=2540.4, nsentences=96, sample_size=2540.4, sample_size_v1=0, sample_size_v2=0, ppl=2.36, wps=895.1, ups=0.35, wpb=2540.4, bsz=96, num_updates=4490, lr=1.12546e-05, gnorm=2.062, clip=100, loss_scale=128, train_wall=28, gb_free=12.6, wall=17463
2023-04-08 20:54:22 - progress_bar.py[line:272] - INFO: epoch 008:    462 / 578 loss=2.429, loss_v1=0, loss_v2=0, nll_loss=1.238, ntokens=2474.1, nsentences=96, sample_size=2474.1, sample_size_v1=0, sample_size_v2=0, ppl=2.36, wps=873.2, ups=0.35, wpb=2474.1, bsz=96, num_updates=4500, lr=1.12086e-05, gnorm=2.078, clip=100, loss_scale=128, train_wall=28, gb_free=12.4, wall=17491
2023-04-08 20:54:50 - progress_bar.py[line:272] - INFO: epoch 008:    472 / 578 loss=2.444, loss_v1=0, loss_v2=0, nll_loss=1.253, ntokens=2476.3, nsentences=96, sample_size=2476.3, sample_size_v1=0, sample_size_v2=0, ppl=2.38, wps=875.7, ups=0.35, wpb=2476.3, bsz=96, num_updates=4510, lr=1.11626e-05, gnorm=2.176, clip=100, loss_scale=128, train_wall=28, gb_free=12.6, wall=17519
2023-04-08 20:55:18 - progress_bar.py[line:272] - INFO: epoch 008:    482 / 578 loss=2.43, loss_v1=0, loss_v2=0, nll_loss=1.237, ntokens=2334.6, nsentences=96, sample_size=2334.6, sample_size_v1=0, sample_size_v2=0, ppl=2.36, wps=826.9, ups=0.35, wpb=2334.6, bsz=96, num_updates=4520, lr=1.11166e-05, gnorm=2.074, clip=100, loss_scale=128, train_wall=28, gb_free=12.6, wall=17548
2023-04-08 20:55:46 - progress_bar.py[line:272] - INFO: epoch 008:    492 / 578 loss=2.406, loss_v1=0, loss_v2=0, nll_loss=1.213, ntokens=2522.9, nsentences=96, sample_size=2522.9, sample_size_v1=0, sample_size_v2=0, ppl=2.32, wps=893, ups=0.35, wpb=2522.9, bsz=96, num_updates=4530, lr=1.10706e-05, gnorm=2.062, clip=100, loss_scale=128, train_wall=28, gb_free=12.6, wall=17576
2023-04-08 20:56:15 - progress_bar.py[line:272] - INFO: epoch 008:    502 / 578 loss=2.412, loss_v1=0, loss_v2=0, nll_loss=1.215, ntokens=2539.2, nsentences=96, sample_size=2539.2, sample_size_v1=0, sample_size_v2=0, ppl=2.32, wps=894.9, ups=0.35, wpb=2539.2, bsz=96, num_updates=4540, lr=1.10245e-05, gnorm=2.019, clip=100, loss_scale=128, train_wall=28, gb_free=12.6, wall=17604
2023-04-08 20:56:43 - progress_bar.py[line:272] - INFO: epoch 008:    512 / 578 loss=2.418, loss_v1=0, loss_v2=0, nll_loss=1.227, ntokens=2550.1, nsentences=96, sample_size=2550.1, sample_size_v1=0, sample_size_v2=0, ppl=2.34, wps=899.1, ups=0.35, wpb=2550.1, bsz=96, num_updates=4550, lr=1.09785e-05, gnorm=2.087, clip=100, loss_scale=128, train_wall=28, gb_free=12.3, wall=17633
2023-04-08 20:57:11 - progress_bar.py[line:272] - INFO: epoch 008:    522 / 578 loss=2.408, loss_v1=0, loss_v2=0, nll_loss=1.21, ntokens=2713, nsentences=96, sample_size=2713, sample_size_v1=0, sample_size_v2=0, ppl=2.31, wps=955.3, ups=0.35, wpb=2713, bsz=96, num_updates=4560, lr=1.09325e-05, gnorm=2.029, clip=100, loss_scale=128, train_wall=28, gb_free=12.2, wall=17661
2023-04-08 20:57:40 - progress_bar.py[line:272] - INFO: epoch 008:    532 / 578 loss=2.418, loss_v1=0, loss_v2=0, nll_loss=1.224, ntokens=2561.6, nsentences=96, sample_size=2561.6, sample_size_v1=0, sample_size_v2=0, ppl=2.34, wps=906.6, ups=0.35, wpb=2561.6, bsz=96, num_updates=4570, lr=1.08865e-05, gnorm=2.087, clip=100, loss_scale=128, train_wall=28, gb_free=12.6, wall=17689
2023-04-08 20:58:08 - progress_bar.py[line:272] - INFO: epoch 008:    542 / 578 loss=2.407, loss_v1=0, loss_v2=0, nll_loss=1.213, ntokens=2492.5, nsentences=96, sample_size=2492.5, sample_size_v1=0, sample_size_v2=0, ppl=2.32, wps=880.5, ups=0.35, wpb=2492.5, bsz=96, num_updates=4580, lr=1.08405e-05, gnorm=2.205, clip=100, loss_scale=128, train_wall=28, gb_free=12, wall=17718
2023-04-08 20:58:37 - progress_bar.py[line:272] - INFO: epoch 008:    552 / 578 loss=2.406, loss_v1=0, loss_v2=0, nll_loss=1.207, ntokens=2551.1, nsentences=96, sample_size=2551.1, sample_size_v1=0, sample_size_v2=0, ppl=2.31, wps=895.3, ups=0.35, wpb=2551.1, bsz=96, num_updates=4590, lr=1.07945e-05, gnorm=2.063, clip=100, loss_scale=128, train_wall=28, gb_free=12.5, wall=17746
2023-04-08 20:59:05 - progress_bar.py[line:272] - INFO: epoch 008:    562 / 578 loss=2.401, loss_v1=0, loss_v2=0, nll_loss=1.206, ntokens=2665.1, nsentences=96, sample_size=2665.1, sample_size_v1=0, sample_size_v2=0, ppl=2.31, wps=935.7, ups=0.35, wpb=2665.1, bsz=96, num_updates=4600, lr=1.07485e-05, gnorm=1.943, clip=100, loss_scale=128, train_wall=28, gb_free=12.7, wall=17775
2023-04-08 20:59:33 - progress_bar.py[line:272] - INFO: epoch 008:    572 / 578 loss=2.411, loss_v1=0, loss_v2=0, nll_loss=1.216, ntokens=2575.2, nsentences=96, sample_size=2575.2, sample_size_v1=0, sample_size_v2=0, ppl=2.32, wps=904.6, ups=0.35, wpb=2575.2, bsz=96, num_updates=4610, lr=1.07025e-05, gnorm=2.229, clip=100, loss_scale=128, train_wall=28, gb_free=12.5, wall=17803
2023-04-08 20:59:48 - train.py[line:445] - INFO: begin validation on "valid" subset
slice_id 1 seek offset 11440
slice_id 0 seek offset 0
slice_id 0 seek offset 0
slice_id 1 seek offset 11440
['<sub> train<pred> on<obj> track<sub> window<pred> on<obj> train<sub> door<pred> on<obj> train<sub> door<pred> on<obj> train', '<sub> tire<pred> on<obj> bike<sub> seat<pred> on<obj> bike<sub> bike<pred> on<obj> street<sub> tire<pred> on<obj> bike<sub> tire<pred> on<obj> bike<sub> tire<pred> on<obj> bike', '<sub> tail<pred> of<obj> zebra<sub> leg<pred> of<obj> zebra<sub> head<pred> of<obj> zebra<sub> leg<pred> of<obj> zebra', '<sub> giraffe<pred> has<obj> neck<pred> has<obj> head<pred> has<obj> neck<pred> has<obj> leg<pred> has<obj> neck<sub> tree<pred> behind<obj> giraffe<sub> fence<pred> behind<obj> giraffe', '<sub> man<pred> on<obj> skateboard<pred> wearing<obj> pant<pred> wearing<obj> shirt<sub> skateboard<pred> under<obj> man', '<sub> tree<pred> behind<obj> fence<sub> fence<pred> behind<obj> giraffe<sub> giraffe<pred> near<obj> fence'] [['<sub> windshield<pred> on<obj> train<sub> window<pred> on<obj> train<sub> train<pred> has<obj> window<sub> house<pred> near<obj> train<sub> tree<pred> near<obj> house'], ['<sub> bus<pred> under<obj> roof<sub> woman<pred> near<obj> bus<pred> wearing<obj> coat<sub> window<pred> on<obj> bus'], ['<sub> sign<pred> hanging from<obj> roof<sub> fence<pred> near<obj> cow'], ['<sub> wing<pred> on<obj> plane<sub> plane<pred> has<obj> tail<sub> fence<pred> in front of<obj> plane<sub> wheel<pred> on<obj> plane'], ['<sub> woman<pred> wearing<obj> shirt'], ['<sub> car<pred> on<obj> track<pred> near<obj> pole']]
['<sub> man<pred> wearing<obj> helmet<pred> wearing<obj> shirt<pred> wearing<obj> pant<pred> wearing<obj> glove<sub> helmet<pred> on<obj> man', '<sub> bus<pred> on<obj> street<sub> sign<pred> on<obj> bus<sub> window<pred> on<obj> bus<sub> tire<pred> on<obj> bus<sub> windshield<pred> on<obj> bus<sub> windshield<pred> on<obj> bus', '<sub> man<pred> wearing<obj> hat<pred> wearing<obj> shirt<pred> wearing<obj> jean<pred> wearing<obj> jean<pred> wearing<obj> shirt<pred> wearing<obj> jean<pred> has<obj> hair<sub> tree<pred> behind<obj> man', '<sub> window<pred> on<obj> bus<sub> tire<pred> on<obj> bus<sub> windshield<pred> on<obj> bus<sub> windshield<pred> on<obj> bus', '<sub> man<pred> wearing<obj> short<pred> wearing<obj> shirt<pred> wearing<obj> short<pred> wearing<obj> sock<pred> wearing<obj> shoe<pred> wearing<obj> sock<pred> wearing<obj> shoe<pred> wearing<obj> sock<pred> wearing<obj> sock<pred> wearing<obj> shoe<pred> wearing<obj> sock<pred> wearing<obj> sock<pred> wearing<obj> shoe<pred> wearing<obj> short<pred> wearing<obj> sock<pred> wearing<obj> sock<pred> wearing<obj> shoe<pred> wearing<obj> sock<pred> wearing<obj> sock<pred> wearing<obj> shoe<pred> wearing<obj> sock<pred> wearing<obj> sock<pred> wearing<obj> sock<pred> wearing<obj> sock<pred> wearing<obj> sock<pred> wearing<obj> sock<pred> wearing<obj> sock<pred> wearing<obj> sock<pred> wearing<obj> sock<pred> wearing<obj> sock<pred> wearing<obj> sock<pred> wearing<obj> sock<pred> wearing<obj> sock<pred> wearing<obj> sock<pred> wearing<obj> sock<pred> wearing<obj> sock<pred> wearing<obj> sock<pred> wearing<obj> sock<pred> wearing<obj> sock<pred> wearing<obj> sock<pred> wearing<obj> sock<pred> wearing<obj> sock<pred> wearing<obj> sock<pred> wearing<obj> sock<pred> wearing<obj> sock<pred> wearing<obj> sock<pred> wearing<obj> sock<pred> wearing<obj> sock<pred> wearing<obj> sock<pred> wearing', '<sub> man<pred> wearing<obj> tie<pred> wearing<obj> shirt<pred> wearing<obj> pant<pred> wearing<obj> tie<pred> has<obj> hair<pred> wearing<obj> shirt<sub> tie<pred> on<obj> man<sub> tie<pred> on<obj> man<sub> tie<pred> on<obj> man<sub> tie<pred> on<obj> man'] [['<sub> head<pred> of<obj> bear<sub> bear<pred> in<obj> bowl<sub> bowl<pred> with<obj> bear'], ['<sub> wheel<pred> of<obj> bus<sub> bus<pred> on<obj> street<sub> window<pred> of<obj> bus<sub> people<pred> near<obj> bus<sub> woman<pred> on<obj> bus<sub> letter<pred> on<obj> bus'], ['<sub> book<pred> under<obj> arm<sub> man<pred> wearing<obj> shirt<pred> wearing<obj> tie'], ['<sub> logo<pred> on<obj> bike<sub> woman<pred> on<obj> sidewalk<sub> sign<pred> on<obj> building<sub> bike<pred> has<obj> wheel<pred> has<obj> light<sub> wheel<pred> on<obj> bike'], ['<sub> man<pred> holding<obj> racket<pred> wearing<obj> short<pred> wearing<obj> sneaker<pred> wearing<obj> shirt<sub> men<pred> wearing<obj> short'], ['<sub> man<pred> wearing<obj> coat<pred> wearing<obj> jean<pred> on<obj> bus<pred> wearing<obj> sneaker<sub> seat<pred> near<obj> man<sub> light<pred> above<obj> man<sub> pole<pred> on<obj> bus<sub> sign<pred> on<obj> bus<sub> window<pred> on<obj> building<sub> hand<pred> of<obj> man']]
2023-04-08 21:00:09 - progress_bar.py[line:272] - INFO: epoch 008 | valid on 'valid' subset:     11 / 1907 loss=2.366, loss_v1=0, loss_v2=0, nll_loss=1.134, ntokens=336, nsentences=12, sample_size=336.0, sample_size_v1=0, sample_size_v2=0
2023-04-08 21:00:23 - progress_bar.py[line:272] - INFO: epoch 008 | valid on 'valid' subset:     21 / 1907 loss=2.45, loss_v1=0, loss_v2=0, nll_loss=1.232, ntokens=389, nsentences=12, sample_size=389.0, sample_size_v1=0, sample_size_v2=0
2023-04-08 21:00:41 - progress_bar.py[line:272] - INFO: epoch 008 | valid on 'valid' subset:     31 / 1907 loss=2.47, loss_v1=0, loss_v2=0, nll_loss=1.248, ntokens=372, nsentences=12, sample_size=372.0, sample_size_v1=0, sample_size_v2=0
2023-04-08 21:00:59 - progress_bar.py[line:272] - INFO: epoch 008 | valid on 'valid' subset:     41 / 1907 loss=2.315, loss_v1=0, loss_v2=0, nll_loss=1.08, ntokens=318, nsentences=12, sample_size=318.0, sample_size_v1=0, sample_size_v2=0
2023-04-08 21:01:16 - progress_bar.py[line:272] - INFO: epoch 008 | valid on 'valid' subset:     51 / 1907 loss=2.351, loss_v1=0, loss_v2=0, nll_loss=1.114, ntokens=352, nsentences=12, sample_size=352.0, sample_size_v1=0, sample_size_v2=0
2023-04-08 21:01:34 - progress_bar.py[line:272] - INFO: epoch 008 | valid on 'valid' subset:     61 / 1907 loss=2.423, loss_v1=0, loss_v2=0, nll_loss=1.197, ntokens=323, nsentences=12, sample_size=323.0, sample_size_v1=0, sample_size_v2=0
2023-04-08 21:01:52 - progress_bar.py[line:272] - INFO: epoch 008 | valid on 'valid' subset:     71 / 1907 loss=2.392, loss_v1=0, loss_v2=0, nll_loss=1.163, ntokens=354, nsentences=12, sample_size=354.0, sample_size_v1=0, sample_size_v2=0
2023-04-08 21:02:09 - progress_bar.py[line:272] - INFO: epoch 008 | valid on 'valid' subset:     81 / 1907 loss=2.411, loss_v1=0, loss_v2=0, nll_loss=1.188, ntokens=335, nsentences=12, sample_size=335.0, sample_size_v1=0, sample_size_v2=0
2023-04-08 21:02:27 - progress_bar.py[line:272] - INFO: epoch 008 | valid on 'valid' subset:     91 / 1907 loss=2.419, loss_v1=0, loss_v2=0, nll_loss=1.194, ntokens=296, nsentences=12, sample_size=296.0, sample_size_v1=0, sample_size_v2=0
2023-04-08 21:02:45 - progress_bar.py[line:272] - INFO: epoch 008 | valid on 'valid' subset:    101 / 1907 loss=2.466, loss_v1=0, loss_v2=0, nll_loss=1.243, ntokens=351, nsentences=12, sample_size=351.0, sample_size_v1=0, sample_size_v2=0
2023-04-08 21:03:04 - progress_bar.py[line:272] - INFO: epoch 008 | valid on 'valid' subset:    111 / 1907 loss=2.508, loss_v1=0, loss_v2=0, nll_loss=1.293, ntokens=476, nsentences=12, sample_size=476.0, sample_size_v1=0, sample_size_v2=0
2023-04-08 21:03:22 - progress_bar.py[line:272] - INFO: epoch 008 | valid on 'valid' subset:    121 / 1907 loss=2.469, loss_v1=0, loss_v2=0, nll_loss=1.248, ntokens=372, nsentences=12, sample_size=372.0, sample_size_v1=0, sample_size_v2=0
2023-04-08 21:03:41 - progress_bar.py[line:272] - INFO: epoch 008 | valid on 'valid' subset:    131 / 1907 loss=2.335, loss_v1=0, loss_v2=0, nll_loss=1.103, ntokens=297, nsentences=12, sample_size=297.0, sample_size_v1=0, sample_size_v2=0
2023-04-08 21:04:00 - progress_bar.py[line:272] - INFO: epoch 008 | valid on 'valid' subset:    141 / 1907 loss=2.42, loss_v1=0, loss_v2=0, nll_loss=1.194, ntokens=481, nsentences=12, sample_size=481.0, sample_size_v1=0, sample_size_v2=0
2023-04-08 21:04:17 - progress_bar.py[line:272] - INFO: epoch 008 | valid on 'valid' subset:    151 / 1907 loss=2.379, loss_v1=0, loss_v2=0, nll_loss=1.149, ntokens=325, nsentences=12, sample_size=325.0, sample_size_v1=0, sample_size_v2=0
2023-04-08 21:04:33 - progress_bar.py[line:272] - INFO: epoch 008 | valid on 'valid' subset:    161 / 1907 loss=2.454, loss_v1=0, loss_v2=0, nll_loss=1.236, ntokens=357, nsentences=12, sample_size=357.0, sample_size_v1=0, sample_size_v2=0
2023-04-08 21:04:48 - progress_bar.py[line:272] - INFO: epoch 008 | valid on 'valid' subset:    171 / 1907 loss=2.453, loss_v1=0, loss_v2=0, nll_loss=1.232, ntokens=405, nsentences=12, sample_size=405.0, sample_size_v1=0, sample_size_v2=0
2023-04-08 21:05:06 - progress_bar.py[line:272] - INFO: epoch 008 | valid on 'valid' subset:    181 / 1907 loss=2.525, loss_v1=0, loss_v2=0, nll_loss=1.311, ntokens=459, nsentences=12, sample_size=459.0, sample_size_v1=0, sample_size_v2=0
2023-04-08 21:05:22 - progress_bar.py[line:272] - INFO: epoch 008 | valid on 'valid' subset:    191 / 1907 loss=2.301, loss_v1=0, loss_v2=0, nll_loss=1.064, ntokens=238, nsentences=12, sample_size=238.0, sample_size_v1=0, sample_size_v2=0
2023-04-08 21:05:39 - progress_bar.py[line:272] - INFO: epoch 008 | valid on 'valid' subset:    201 / 1907 loss=2.632, loss_v1=0, loss_v2=0, nll_loss=1.429, ntokens=366, nsentences=12, sample_size=366.0, sample_size_v1=0, sample_size_v2=0
2023-04-08 21:05:54 - progress_bar.py[line:272] - INFO: epoch 008 | valid on 'valid' subset:    211 / 1907 loss=2.462, loss_v1=0, loss_v2=0, nll_loss=1.241, ntokens=315, nsentences=12, sample_size=315.0, sample_size_v1=0, sample_size_v2=0
2023-04-08 21:06:12 - progress_bar.py[line:272] - INFO: epoch 008 | valid on 'valid' subset:    221 / 1907 loss=2.485, loss_v1=0, loss_v2=0, nll_loss=1.271, ntokens=416, nsentences=12, sample_size=416.0, sample_size_v1=0, sample_size_v2=0
2023-04-08 21:06:31 - progress_bar.py[line:272] - INFO: epoch 008 | valid on 'valid' subset:    231 / 1907 loss=2.38, loss_v1=0, loss_v2=0, nll_loss=1.147, ntokens=246, nsentences=12, sample_size=246.0, sample_size_v1=0, sample_size_v2=0
2023-04-08 21:06:48 - progress_bar.py[line:272] - INFO: epoch 008 | valid on 'valid' subset:    241 / 1907 loss=2.411, loss_v1=0, loss_v2=0, nll_loss=1.184, ntokens=311, nsentences=12, sample_size=311.0, sample_size_v1=0, sample_size_v2=0
2023-04-08 21:07:05 - progress_bar.py[line:272] - INFO: epoch 008 | valid on 'valid' subset:    251 / 1907 loss=2.506, loss_v1=0, loss_v2=0, nll_loss=1.291, ntokens=378, nsentences=12, sample_size=378.0, sample_size_v1=0, sample_size_v2=0
2023-04-08 21:07:23 - progress_bar.py[line:272] - INFO: epoch 008 | valid on 'valid' subset:    261 / 1907 loss=2.392, loss_v1=0, loss_v2=0, nll_loss=1.163, ntokens=442, nsentences=12, sample_size=442.0, sample_size_v1=0, sample_size_v2=0
2023-04-08 21:07:41 - progress_bar.py[line:272] - INFO: epoch 008 | valid on 'valid' subset:    271 / 1907 loss=2.519, loss_v1=0, loss_v2=0, nll_loss=1.308, ntokens=313, nsentences=12, sample_size=313.0, sample_size_v1=0, sample_size_v2=0
2023-04-08 21:07:59 - progress_bar.py[line:272] - INFO: epoch 008 | valid on 'valid' subset:    281 / 1907 loss=2.381, loss_v1=0, loss_v2=0, nll_loss=1.151, ntokens=303, nsentences=12, sample_size=303.0, sample_size_v1=0, sample_size_v2=0
2023-04-08 21:08:16 - progress_bar.py[line:272] - INFO: epoch 008 | valid on 'valid' subset:    291 / 1907 loss=2.425, loss_v1=0, loss_v2=0, nll_loss=1.201, ntokens=313, nsentences=12, sample_size=313.0, sample_size_v1=0, sample_size_v2=0
2023-04-08 21:08:32 - progress_bar.py[line:272] - INFO: epoch 008 | valid on 'valid' subset:    301 / 1907 loss=2.326, loss_v1=0, loss_v2=0, nll_loss=1.091, ntokens=333, nsentences=12, sample_size=333.0, sample_size_v1=0, sample_size_v2=0
2023-04-08 21:08:50 - progress_bar.py[line:272] - INFO: epoch 008 | valid on 'valid' subset:    311 / 1907 loss=2.503, loss_v1=0, loss_v2=0, nll_loss=1.286, ntokens=364, nsentences=12, sample_size=364.0, sample_size_v1=0, sample_size_v2=0
2023-04-08 21:09:07 - progress_bar.py[line:272] - INFO: epoch 008 | valid on 'valid' subset:    321 / 1907 loss=2.254, loss_v1=0, loss_v2=0, nll_loss=1.008, ntokens=303, nsentences=12, sample_size=303.0, sample_size_v1=0, sample_size_v2=0
2023-04-08 21:09:25 - progress_bar.py[line:272] - INFO: epoch 008 | valid on 'valid' subset:    331 / 1907 loss=2.378, loss_v1=0, loss_v2=0, nll_loss=1.144, ntokens=300, nsentences=12, sample_size=300.0, sample_size_v1=0, sample_size_v2=0
2023-04-08 21:09:42 - progress_bar.py[line:272] - INFO: epoch 008 | valid on 'valid' subset:    341 / 1907 loss=2.318, loss_v1=0, loss_v2=0, nll_loss=1.083, ntokens=264, nsentences=12, sample_size=264.0, sample_size_v1=0, sample_size_v2=0
2023-04-08 21:09:57 - progress_bar.py[line:272] - INFO: epoch 008 | valid on 'valid' subset:    351 / 1907 loss=2.537, loss_v1=0, loss_v2=0, nll_loss=1.325, ntokens=320, nsentences=12, sample_size=320.0, sample_size_v1=0, sample_size_v2=0
2023-04-08 21:10:14 - progress_bar.py[line:272] - INFO: epoch 008 | valid on 'valid' subset:    361 / 1907 loss=2.527, loss_v1=0, loss_v2=0, nll_loss=1.313, ntokens=293, nsentences=12, sample_size=293.0, sample_size_v1=0, sample_size_v2=0
2023-04-08 21:10:32 - progress_bar.py[line:272] - INFO: epoch 008 | valid on 'valid' subset:    371 / 1907 loss=2.476, loss_v1=0, loss_v2=0, nll_loss=1.259, ntokens=314, nsentences=12, sample_size=314.0, sample_size_v1=0, sample_size_v2=0
2023-04-08 21:10:48 - progress_bar.py[line:272] - INFO: epoch 008 | valid on 'valid' subset:    381 / 1907 loss=2.311, loss_v1=0, loss_v2=0, nll_loss=1.074, ntokens=350, nsentences=12, sample_size=350.0, sample_size_v1=0, sample_size_v2=0
2023-04-08 21:11:06 - progress_bar.py[line:272] - INFO: epoch 008 | valid on 'valid' subset:    391 / 1907 loss=2.417, loss_v1=0, loss_v2=0, nll_loss=1.191, ntokens=235, nsentences=12, sample_size=235.0, sample_size_v1=0, sample_size_v2=0
2023-04-08 21:11:23 - progress_bar.py[line:272] - INFO: epoch 008 | valid on 'valid' subset:    401 / 1907 loss=2.509, loss_v1=0, loss_v2=0, nll_loss=1.295, ntokens=323, nsentences=12, sample_size=323.0, sample_size_v1=0, sample_size_v2=0
2023-04-08 21:11:40 - progress_bar.py[line:272] - INFO: epoch 008 | valid on 'valid' subset:    411 / 1907 loss=2.419, loss_v1=0, loss_v2=0, nll_loss=1.19, ntokens=268, nsentences=12, sample_size=268.0, sample_size_v1=0, sample_size_v2=0
2023-04-08 21:11:58 - progress_bar.py[line:272] - INFO: epoch 008 | valid on 'valid' subset:    421 / 1907 loss=2.464, loss_v1=0, loss_v2=0, nll_loss=1.248, ntokens=314, nsentences=12, sample_size=314.0, sample_size_v1=0, sample_size_v2=0
2023-04-08 21:12:16 - progress_bar.py[line:272] - INFO: epoch 008 | valid on 'valid' subset:    431 / 1907 loss=2.432, loss_v1=0, loss_v2=0, nll_loss=1.209, ntokens=362, nsentences=12, sample_size=362.0, sample_size_v1=0, sample_size_v2=0
2023-04-08 21:12:34 - progress_bar.py[line:272] - INFO: epoch 008 | valid on 'valid' subset:    441 / 1907 loss=2.509, loss_v1=0, loss_v2=0, nll_loss=1.294, ntokens=303, nsentences=12, sample_size=303.0, sample_size_v1=0, sample_size_v2=0
2023-04-08 21:12:51 - progress_bar.py[line:272] - INFO: epoch 008 | valid on 'valid' subset:    451 / 1907 loss=2.436, loss_v1=0, loss_v2=0, nll_loss=1.212, ntokens=307, nsentences=12, sample_size=307.0, sample_size_v1=0, sample_size_v2=0
2023-04-08 21:13:08 - progress_bar.py[line:272] - INFO: epoch 008 | valid on 'valid' subset:    461 / 1907 loss=2.543, loss_v1=0, loss_v2=0, nll_loss=1.335, ntokens=375, nsentences=12, sample_size=375.0, sample_size_v1=0, sample_size_v2=0
2023-04-08 21:13:26 - progress_bar.py[line:272] - INFO: epoch 008 | valid on 'valid' subset:    471 / 1907 loss=2.444, loss_v1=0, loss_v2=0, nll_loss=1.221, ntokens=343, nsentences=12, sample_size=343.0, sample_size_v1=0, sample_size_v2=0
2023-04-08 21:13:45 - progress_bar.py[line:272] - INFO: epoch 008 | valid on 'valid' subset:    481 / 1907 loss=2.423, loss_v1=0, loss_v2=0, nll_loss=1.197, ntokens=322, nsentences=12, sample_size=322.0, sample_size_v1=0, sample_size_v2=0
2023-04-08 21:14:02 - progress_bar.py[line:272] - INFO: epoch 008 | valid on 'valid' subset:    491 / 1907 loss=2.441, loss_v1=0, loss_v2=0, nll_loss=1.219, ntokens=271, nsentences=12, sample_size=271.0, sample_size_v1=0, sample_size_v2=0
2023-04-08 21:14:20 - progress_bar.py[line:272] - INFO: epoch 008 | valid on 'valid' subset:    501 / 1907 loss=2.408, loss_v1=0, loss_v2=0, nll_loss=1.182, ntokens=419, nsentences=12, sample_size=419.0, sample_size_v1=0, sample_size_v2=0
2023-04-08 21:14:39 - progress_bar.py[line:272] - INFO: epoch 008 | valid on 'valid' subset:    511 / 1907 loss=2.386, loss_v1=0, loss_v2=0, nll_loss=1.155, ntokens=304, nsentences=12, sample_size=304.0, sample_size_v1=0, sample_size_v2=0
2023-04-08 21:14:56 - progress_bar.py[line:272] - INFO: epoch 008 | valid on 'valid' subset:    521 / 1907 loss=2.275, loss_v1=0, loss_v2=0, nll_loss=1.034, ntokens=371, nsentences=12, sample_size=371.0, sample_size_v1=0, sample_size_v2=0
2023-04-08 21:15:15 - progress_bar.py[line:272] - INFO: epoch 008 | valid on 'valid' subset:    531 / 1907 loss=2.484, loss_v1=0, loss_v2=0, nll_loss=1.267, ntokens=376, nsentences=12, sample_size=376.0, sample_size_v1=0, sample_size_v2=0
2023-04-08 21:15:33 - progress_bar.py[line:272] - INFO: epoch 008 | valid on 'valid' subset:    541 / 1907 loss=2.374, loss_v1=0, loss_v2=0, nll_loss=1.144, ntokens=328, nsentences=12, sample_size=328.0, sample_size_v1=0, sample_size_v2=0
2023-04-08 21:15:52 - progress_bar.py[line:272] - INFO: epoch 008 | valid on 'valid' subset:    551 / 1907 loss=2.379, loss_v1=0, loss_v2=0, nll_loss=1.148, ntokens=221, nsentences=12, sample_size=221.0, sample_size_v1=0, sample_size_v2=0
2023-04-08 21:16:10 - progress_bar.py[line:272] - INFO: epoch 008 | valid on 'valid' subset:    561 / 1907 loss=2.452, loss_v1=0, loss_v2=0, nll_loss=1.232, ntokens=286, nsentences=12, sample_size=286.0, sample_size_v1=0, sample_size_v2=0
2023-04-08 21:16:27 - progress_bar.py[line:272] - INFO: epoch 008 | valid on 'valid' subset:    571 / 1907 loss=2.387, loss_v1=0, loss_v2=0, nll_loss=1.158, ntokens=413, nsentences=12, sample_size=413.0, sample_size_v1=0, sample_size_v2=0
2023-04-08 21:16:45 - progress_bar.py[line:272] - INFO: epoch 008 | valid on 'valid' subset:    581 / 1907 loss=2.464, loss_v1=0, loss_v2=0, nll_loss=1.243, ntokens=292, nsentences=12, sample_size=292.0, sample_size_v1=0, sample_size_v2=0
2023-04-08 21:17:02 - progress_bar.py[line:272] - INFO: epoch 008 | valid on 'valid' subset:    591 / 1907 loss=2.464, loss_v1=0, loss_v2=0, nll_loss=1.242, ntokens=342, nsentences=12, sample_size=342.0, sample_size_v1=0, sample_size_v2=0
2023-04-08 21:17:20 - progress_bar.py[line:272] - INFO: epoch 008 | valid on 'valid' subset:    601 / 1907 loss=2.471, loss_v1=0, loss_v2=0, nll_loss=1.254, ntokens=332, nsentences=12, sample_size=332.0, sample_size_v1=0, sample_size_v2=0
2023-04-08 21:17:39 - progress_bar.py[line:272] - INFO: epoch 008 | valid on 'valid' subset:    611 / 1907 loss=2.555, loss_v1=0, loss_v2=0, nll_loss=1.345, ntokens=309, nsentences=12, sample_size=309.0, sample_size_v1=0, sample_size_v2=0
2023-04-08 21:17:56 - progress_bar.py[line:272] - INFO: epoch 008 | valid on 'valid' subset:    621 / 1907 loss=2.363, loss_v1=0, loss_v2=0, nll_loss=1.129, ntokens=377, nsentences=12, sample_size=377.0, sample_size_v1=0, sample_size_v2=0
2023-04-08 21:18:13 - progress_bar.py[line:272] - INFO: epoch 008 | valid on 'valid' subset:    631 / 1907 loss=2.501, loss_v1=0, loss_v2=0, nll_loss=1.288, ntokens=277, nsentences=12, sample_size=277.0, sample_size_v1=0, sample_size_v2=0
2023-04-08 21:18:32 - progress_bar.py[line:272] - INFO: epoch 008 | valid on 'valid' subset:    641 / 1907 loss=2.28, loss_v1=0, loss_v2=0, nll_loss=1.044, ntokens=349, nsentences=12, sample_size=349.0, sample_size_v1=0, sample_size_v2=0
2023-04-08 21:18:50 - progress_bar.py[line:272] - INFO: epoch 008 | valid on 'valid' subset:    651 / 1907 loss=2.414, loss_v1=0, loss_v2=0, nll_loss=1.187, ntokens=330, nsentences=12, sample_size=330.0, sample_size_v1=0, sample_size_v2=0
2023-04-08 21:19:08 - progress_bar.py[line:272] - INFO: epoch 008 | valid on 'valid' subset:    661 / 1907 loss=2.436, loss_v1=0, loss_v2=0, nll_loss=1.212, ntokens=328, nsentences=12, sample_size=328.0, sample_size_v1=0, sample_size_v2=0
2023-04-08 21:19:25 - progress_bar.py[line:272] - INFO: epoch 008 | valid on 'valid' subset:    671 / 1907 loss=2.367, loss_v1=0, loss_v2=0, nll_loss=1.139, ntokens=367, nsentences=12, sample_size=367.0, sample_size_v1=0, sample_size_v2=0
2023-04-08 21:19:43 - progress_bar.py[line:272] - INFO: epoch 008 | valid on 'valid' subset:    681 / 1907 loss=2.527, loss_v1=0, loss_v2=0, nll_loss=1.314, ntokens=399, nsentences=12, sample_size=399.0, sample_size_v1=0, sample_size_v2=0
2023-04-08 21:20:00 - progress_bar.py[line:272] - INFO: epoch 008 | valid on 'valid' subset:    691 / 1907 loss=2.32, loss_v1=0, loss_v2=0, nll_loss=1.088, ntokens=267, nsentences=12, sample_size=267.0, sample_size_v1=0, sample_size_v2=0
2023-04-08 21:20:19 - progress_bar.py[line:272] - INFO: epoch 008 | valid on 'valid' subset:    701 / 1907 loss=2.455, loss_v1=0, loss_v2=0, nll_loss=1.237, ntokens=358, nsentences=12, sample_size=358.0, sample_size_v1=0, sample_size_v2=0
2023-04-08 21:20:36 - progress_bar.py[line:272] - INFO: epoch 008 | valid on 'valid' subset:    711 / 1907 loss=2.386, loss_v1=0, loss_v2=0, nll_loss=1.155, ntokens=398, nsentences=12, sample_size=398.0, sample_size_v1=0, sample_size_v2=0
2023-04-08 21:20:53 - progress_bar.py[line:272] - INFO: epoch 008 | valid on 'valid' subset:    721 / 1907 loss=2.537, loss_v1=0, loss_v2=0, nll_loss=1.326, ntokens=269, nsentences=12, sample_size=269.0, sample_size_v1=0, sample_size_v2=0
2023-04-08 21:21:12 - progress_bar.py[line:272] - INFO: epoch 008 | valid on 'valid' subset:    731 / 1907 loss=2.486, loss_v1=0, loss_v2=0, nll_loss=1.267, ntokens=293, nsentences=12, sample_size=293.0, sample_size_v1=0, sample_size_v2=0
2023-04-08 21:21:30 - progress_bar.py[line:272] - INFO: epoch 008 | valid on 'valid' subset:    741 / 1907 loss=2.534, loss_v1=0, loss_v2=0, nll_loss=1.325, ntokens=456, nsentences=12, sample_size=456.0, sample_size_v1=0, sample_size_v2=0
2023-04-08 21:21:47 - progress_bar.py[line:272] - INFO: epoch 008 | valid on 'valid' subset:    751 / 1907 loss=2.289, loss_v1=0, loss_v2=0, nll_loss=1.05, ntokens=310, nsentences=12, sample_size=310.0, sample_size_v1=0, sample_size_v2=0
2023-04-08 21:22:05 - progress_bar.py[line:272] - INFO: epoch 008 | valid on 'valid' subset:    761 / 1907 loss=2.431, loss_v1=0, loss_v2=0, nll_loss=1.204, ntokens=282, nsentences=12, sample_size=282.0, sample_size_v1=0, sample_size_v2=0
2023-04-08 21:22:22 - progress_bar.py[line:272] - INFO: epoch 008 | valid on 'valid' subset:    771 / 1907 loss=2.393, loss_v1=0, loss_v2=0, nll_loss=1.166, ntokens=348, nsentences=12, sample_size=348.0, sample_size_v1=0, sample_size_v2=0
2023-04-08 21:22:40 - progress_bar.py[line:272] - INFO: epoch 008 | valid on 'valid' subset:    781 / 1907 loss=2.382, loss_v1=0, loss_v2=0, nll_loss=1.152, ntokens=342, nsentences=12, sample_size=342.0, sample_size_v1=0, sample_size_v2=0
2023-04-08 21:22:59 - progress_bar.py[line:272] - INFO: epoch 008 | valid on 'valid' subset:    791 / 1907 loss=2.348, loss_v1=0, loss_v2=0, nll_loss=1.116, ntokens=329, nsentences=12, sample_size=329.0, sample_size_v1=0, sample_size_v2=0
2023-04-08 21:23:17 - progress_bar.py[line:272] - INFO: epoch 008 | valid on 'valid' subset:    801 / 1907 loss=2.228, loss_v1=0, loss_v2=0, nll_loss=0.979, ntokens=316, nsentences=12, sample_size=316.0, sample_size_v1=0, sample_size_v2=0
2023-04-08 21:23:36 - progress_bar.py[line:272] - INFO: epoch 008 | valid on 'valid' subset:    811 / 1907 loss=2.434, loss_v1=0, loss_v2=0, nll_loss=1.208, ntokens=300, nsentences=12, sample_size=300.0, sample_size_v1=0, sample_size_v2=0
2023-04-08 21:23:53 - progress_bar.py[line:272] - INFO: epoch 008 | valid on 'valid' subset:    821 / 1907 loss=2.452, loss_v1=0, loss_v2=0, nll_loss=1.231, ntokens=368, nsentences=12, sample_size=368.0, sample_size_v1=0, sample_size_v2=0
2023-04-08 21:24:10 - progress_bar.py[line:272] - INFO: epoch 008 | valid on 'valid' subset:    831 / 1907 loss=2.407, loss_v1=0, loss_v2=0, nll_loss=1.179, ntokens=317, nsentences=12, sample_size=317.0, sample_size_v1=0, sample_size_v2=0
2023-04-08 21:24:28 - progress_bar.py[line:272] - INFO: epoch 008 | valid on 'valid' subset:    841 / 1907 loss=2.505, loss_v1=0, loss_v2=0, nll_loss=1.293, ntokens=289, nsentences=12, sample_size=289.0, sample_size_v1=0, sample_size_v2=0
2023-04-08 21:24:47 - progress_bar.py[line:272] - INFO: epoch 008 | valid on 'valid' subset:    851 / 1907 loss=2.404, loss_v1=0, loss_v2=0, nll_loss=1.175, ntokens=333, nsentences=12, sample_size=333.0, sample_size_v1=0, sample_size_v2=0
2023-04-08 21:25:05 - progress_bar.py[line:272] - INFO: epoch 008 | valid on 'valid' subset:    861 / 1907 loss=2.465, loss_v1=0, loss_v2=0, nll_loss=1.247, ntokens=394, nsentences=12, sample_size=394.0, sample_size_v1=0, sample_size_v2=0
2023-04-08 21:25:23 - progress_bar.py[line:272] - INFO: epoch 008 | valid on 'valid' subset:    871 / 1907 loss=2.493, loss_v1=0, loss_v2=0, nll_loss=1.279, ntokens=339, nsentences=12, sample_size=339.0, sample_size_v1=0, sample_size_v2=0
2023-04-08 21:25:40 - progress_bar.py[line:272] - INFO: epoch 008 | valid on 'valid' subset:    881 / 1907 loss=2.356, loss_v1=0, loss_v2=0, nll_loss=1.125, ntokens=321, nsentences=12, sample_size=321.0, sample_size_v1=0, sample_size_v2=0
2023-04-08 21:25:59 - progress_bar.py[line:272] - INFO: epoch 008 | valid on 'valid' subset:    891 / 1907 loss=2.473, loss_v1=0, loss_v2=0, nll_loss=1.254, ntokens=334, nsentences=12, sample_size=334.0, sample_size_v1=0, sample_size_v2=0
2023-04-08 21:26:16 - progress_bar.py[line:272] - INFO: epoch 008 | valid on 'valid' subset:    901 / 1907 loss=2.468, loss_v1=0, loss_v2=0, nll_loss=1.243, ntokens=344, nsentences=12, sample_size=344.0, sample_size_v1=0, sample_size_v2=0
2023-04-08 21:26:34 - progress_bar.py[line:272] - INFO: epoch 008 | valid on 'valid' subset:    911 / 1907 loss=2.44, loss_v1=0, loss_v2=0, nll_loss=1.219, ntokens=408, nsentences=12, sample_size=408.0, sample_size_v1=0, sample_size_v2=0
2023-04-08 21:26:52 - progress_bar.py[line:272] - INFO: epoch 008 | valid on 'valid' subset:    921 / 1907 loss=2.375, loss_v1=0, loss_v2=0, nll_loss=1.147, ntokens=400, nsentences=12, sample_size=400.0, sample_size_v1=0, sample_size_v2=0
2023-04-08 21:27:10 - progress_bar.py[line:272] - INFO: epoch 008 | valid on 'valid' subset:    931 / 1907 loss=2.461, loss_v1=0, loss_v2=0, nll_loss=1.244, ntokens=547, nsentences=12, sample_size=547.0, sample_size_v1=0, sample_size_v2=0
2023-04-08 21:27:29 - progress_bar.py[line:272] - INFO: epoch 008 | valid on 'valid' subset:    941 / 1907 loss=2.554, loss_v1=0, loss_v2=0, nll_loss=1.345, ntokens=320, nsentences=12, sample_size=320.0, sample_size_v1=0, sample_size_v2=0
2023-04-08 21:27:45 - progress_bar.py[line:272] - INFO: epoch 008 | valid on 'valid' subset:    951 / 1907 loss=2.475, loss_v1=0, loss_v2=0, nll_loss=1.253, ntokens=289, nsentences=12, sample_size=289.0, sample_size_v1=0, sample_size_v2=0
2023-04-08 21:28:02 - progress_bar.py[line:272] - INFO: epoch 008 | valid on 'valid' subset:    961 / 1907 loss=2.39, loss_v1=0, loss_v2=0, nll_loss=1.163, ntokens=358, nsentences=12, sample_size=358.0, sample_size_v1=0, sample_size_v2=0
2023-04-08 21:28:21 - progress_bar.py[line:272] - INFO: epoch 008 | valid on 'valid' subset:    971 / 1907 loss=2.415, loss_v1=0, loss_v2=0, nll_loss=1.191, ntokens=256, nsentences=12, sample_size=256.0, sample_size_v1=0, sample_size_v2=0
2023-04-08 21:28:39 - progress_bar.py[line:272] - INFO: epoch 008 | valid on 'valid' subset:    981 / 1907 loss=2.416, loss_v1=0, loss_v2=0, nll_loss=1.187, ntokens=367, nsentences=12, sample_size=367.0, sample_size_v1=0, sample_size_v2=0
2023-04-08 21:28:56 - progress_bar.py[line:272] - INFO: epoch 008 | valid on 'valid' subset:    991 / 1907 loss=2.511, loss_v1=0, loss_v2=0, nll_loss=1.297, ntokens=338, nsentences=12, sample_size=338.0, sample_size_v1=0, sample_size_v2=0
2023-04-08 21:29:15 - progress_bar.py[line:272] - INFO: epoch 008 | valid on 'valid' subset:   1001 / 1907 loss=2.447, loss_v1=0, loss_v2=0, nll_loss=1.225, ntokens=242, nsentences=12, sample_size=242.0, sample_size_v1=0, sample_size_v2=0
2023-04-08 21:29:30 - progress_bar.py[line:272] - INFO: epoch 008 | valid on 'valid' subset:   1011 / 1907 loss=2.37, loss_v1=0, loss_v2=0, nll_loss=1.138, ntokens=359, nsentences=12, sample_size=359.0, sample_size_v1=0, sample_size_v2=0
2023-04-08 21:29:48 - progress_bar.py[line:272] - INFO: epoch 008 | valid on 'valid' subset:   1021 / 1907 loss=2.507, loss_v1=0, loss_v2=0, nll_loss=1.294, ntokens=363, nsentences=12, sample_size=363.0, sample_size_v1=0, sample_size_v2=0
2023-04-08 21:30:06 - progress_bar.py[line:272] - INFO: epoch 008 | valid on 'valid' subset:   1031 / 1907 loss=2.405, loss_v1=0, loss_v2=0, nll_loss=1.177, ntokens=354, nsentences=12, sample_size=354.0, sample_size_v1=0, sample_size_v2=0
2023-04-08 21:30:25 - progress_bar.py[line:272] - INFO: epoch 008 | valid on 'valid' subset:   1041 / 1907 loss=2.353, loss_v1=0, loss_v2=0, nll_loss=1.121, ntokens=362, nsentences=12, sample_size=362.0, sample_size_v1=0, sample_size_v2=0
2023-04-08 21:30:42 - progress_bar.py[line:272] - INFO: epoch 008 | valid on 'valid' subset:   1051 / 1907 loss=2.531, loss_v1=0, loss_v2=0, nll_loss=1.318, ntokens=318, nsentences=12, sample_size=318.0, sample_size_v1=0, sample_size_v2=0
2023-04-08 21:31:00 - progress_bar.py[line:272] - INFO: epoch 008 | valid on 'valid' subset:   1061 / 1907 loss=2.305, loss_v1=0, loss_v2=0, nll_loss=1.066, ntokens=426, nsentences=12, sample_size=426.0, sample_size_v1=0, sample_size_v2=0
2023-04-08 21:31:19 - progress_bar.py[line:272] - INFO: epoch 008 | valid on 'valid' subset:   1071 / 1907 loss=2.458, loss_v1=0, loss_v2=0, nll_loss=1.234, ntokens=269, nsentences=12, sample_size=269.0, sample_size_v1=0, sample_size_v2=0
2023-04-08 21:31:36 - progress_bar.py[line:272] - INFO: epoch 008 | valid on 'valid' subset:   1081 / 1907 loss=2.418, loss_v1=0, loss_v2=0, nll_loss=1.187, ntokens=282, nsentences=12, sample_size=282.0, sample_size_v1=0, sample_size_v2=0
2023-04-08 21:31:55 - progress_bar.py[line:272] - INFO: epoch 008 | valid on 'valid' subset:   1091 / 1907 loss=2.397, loss_v1=0, loss_v2=0, nll_loss=1.173, ntokens=297, nsentences=12, sample_size=297.0, sample_size_v1=0, sample_size_v2=0
2023-04-08 21:32:13 - progress_bar.py[line:272] - INFO: epoch 008 | valid on 'valid' subset:   1101 / 1907 loss=2.435, loss_v1=0, loss_v2=0, nll_loss=1.212, ntokens=373, nsentences=12, sample_size=373.0, sample_size_v1=0, sample_size_v2=0
2023-04-08 21:32:32 - progress_bar.py[line:272] - INFO: epoch 008 | valid on 'valid' subset:   1111 / 1907 loss=2.445, loss_v1=0, loss_v2=0, nll_loss=1.225, ntokens=351, nsentences=12, sample_size=351.0, sample_size_v1=0, sample_size_v2=0
2023-04-08 21:32:49 - progress_bar.py[line:272] - INFO: epoch 008 | valid on 'valid' subset:   1121 / 1907 loss=2.535, loss_v1=0, loss_v2=0, nll_loss=1.322, ntokens=268, nsentences=12, sample_size=268.0, sample_size_v1=0, sample_size_v2=0
2023-04-08 21:33:07 - progress_bar.py[line:272] - INFO: epoch 008 | valid on 'valid' subset:   1131 / 1907 loss=2.493, loss_v1=0, loss_v2=0, nll_loss=1.278, ntokens=253, nsentences=12, sample_size=253.0, sample_size_v1=0, sample_size_v2=0
2023-04-08 21:33:24 - progress_bar.py[line:272] - INFO: epoch 008 | valid on 'valid' subset:   1141 / 1907 loss=2.51, loss_v1=0, loss_v2=0, nll_loss=1.295, ntokens=326, nsentences=12, sample_size=326.0, sample_size_v1=0, sample_size_v2=0
2023-04-08 21:33:40 - progress_bar.py[line:272] - INFO: epoch 008 | valid on 'valid' subset:   1151 / 1907 loss=2.491, loss_v1=0, loss_v2=0, nll_loss=1.277, ntokens=334, nsentences=12, sample_size=334.0, sample_size_v1=0, sample_size_v2=0
2023-04-08 21:33:58 - progress_bar.py[line:272] - INFO: epoch 008 | valid on 'valid' subset:   1161 / 1907 loss=2.423, loss_v1=0, loss_v2=0, nll_loss=1.199, ntokens=346, nsentences=12, sample_size=346.0, sample_size_v1=0, sample_size_v2=0
2023-04-08 21:34:17 - progress_bar.py[line:272] - INFO: epoch 008 | valid on 'valid' subset:   1171 / 1907 loss=2.372, loss_v1=0, loss_v2=0, nll_loss=1.137, ntokens=391, nsentences=12, sample_size=391.0, sample_size_v1=0, sample_size_v2=0
2023-04-08 21:34:32 - progress_bar.py[line:272] - INFO: epoch 008 | valid on 'valid' subset:   1181 / 1907 loss=2.434, loss_v1=0, loss_v2=0, nll_loss=1.213, ntokens=212, nsentences=12, sample_size=212.0, sample_size_v1=0, sample_size_v2=0
2023-04-08 21:34:49 - progress_bar.py[line:272] - INFO: epoch 008 | valid on 'valid' subset:   1191 / 1907 loss=2.457, loss_v1=0, loss_v2=0, nll_loss=1.235, ntokens=536, nsentences=12, sample_size=536.0, sample_size_v1=0, sample_size_v2=0
2023-04-08 21:35:06 - progress_bar.py[line:272] - INFO: epoch 008 | valid on 'valid' subset:   1201 / 1907 loss=2.384, loss_v1=0, loss_v2=0, nll_loss=1.154, ntokens=376, nsentences=12, sample_size=376.0, sample_size_v1=0, sample_size_v2=0
2023-04-08 21:35:22 - progress_bar.py[line:272] - INFO: epoch 008 | valid on 'valid' subset:   1211 / 1907 loss=2.418, loss_v1=0, loss_v2=0, nll_loss=1.19, ntokens=240, nsentences=12, sample_size=240.0, sample_size_v1=0, sample_size_v2=0
2023-04-08 21:35:38 - progress_bar.py[line:272] - INFO: epoch 008 | valid on 'valid' subset:   1221 / 1907 loss=2.438, loss_v1=0, loss_v2=0, nll_loss=1.215, ntokens=297, nsentences=12, sample_size=297.0, sample_size_v1=0, sample_size_v2=0
2023-04-08 21:35:55 - progress_bar.py[line:272] - INFO: epoch 008 | valid on 'valid' subset:   1231 / 1907 loss=2.472, loss_v1=0, loss_v2=0, nll_loss=1.252, ntokens=288, nsentences=12, sample_size=288.0, sample_size_v1=0, sample_size_v2=0
2023-04-08 21:36:13 - progress_bar.py[line:272] - INFO: epoch 008 | valid on 'valid' subset:   1241 / 1907 loss=2.453, loss_v1=0, loss_v2=0, nll_loss=1.23, ntokens=288, nsentences=12, sample_size=288.0, sample_size_v1=0, sample_size_v2=0
2023-04-08 21:36:29 - progress_bar.py[line:272] - INFO: epoch 008 | valid on 'valid' subset:   1251 / 1907 loss=2.328, loss_v1=0, loss_v2=0, nll_loss=1.095, ntokens=290, nsentences=12, sample_size=290.0, sample_size_v1=0, sample_size_v2=0
2023-04-08 21:36:48 - progress_bar.py[line:272] - INFO: epoch 008 | valid on 'valid' subset:   1261 / 1907 loss=2.329, loss_v1=0, loss_v2=0, nll_loss=1.092, ntokens=278, nsentences=12, sample_size=278.0, sample_size_v1=0, sample_size_v2=0
2023-04-08 21:37:05 - progress_bar.py[line:272] - INFO: epoch 008 | valid on 'valid' subset:   1271 / 1907 loss=2.35, loss_v1=0, loss_v2=0, nll_loss=1.12, ntokens=309, nsentences=12, sample_size=309.0, sample_size_v1=0, sample_size_v2=0
2023-04-08 21:37:23 - progress_bar.py[line:272] - INFO: epoch 008 | valid on 'valid' subset:   1281 / 1907 loss=2.462, loss_v1=0, loss_v2=0, nll_loss=1.245, ntokens=247, nsentences=12, sample_size=247.0, sample_size_v1=0, sample_size_v2=0
2023-04-08 21:37:38 - progress_bar.py[line:272] - INFO: epoch 008 | valid on 'valid' subset:   1291 / 1907 loss=2.377, loss_v1=0, loss_v2=0, nll_loss=1.152, ntokens=259, nsentences=12, sample_size=259.0, sample_size_v1=0, sample_size_v2=0
2023-04-08 21:37:52 - progress_bar.py[line:272] - INFO: epoch 008 | valid on 'valid' subset:   1301 / 1907 loss=2.433, loss_v1=0, loss_v2=0, nll_loss=1.211, ntokens=253, nsentences=12, sample_size=253.0, sample_size_v1=0, sample_size_v2=0
2023-04-08 21:38:09 - progress_bar.py[line:272] - INFO: epoch 008 | valid on 'valid' subset:   1311 / 1907 loss=2.628, loss_v1=0, loss_v2=0, nll_loss=1.432, ntokens=253, nsentences=12, sample_size=253.0, sample_size_v1=0, sample_size_v2=0
2023-04-08 21:38:26 - progress_bar.py[line:272] - INFO: epoch 008 | valid on 'valid' subset:   1321 / 1907 loss=2.445, loss_v1=0, loss_v2=0, nll_loss=1.222, ntokens=241, nsentences=12, sample_size=241.0, sample_size_v1=0, sample_size_v2=0
2023-04-08 21:38:44 - progress_bar.py[line:272] - INFO: epoch 008 | valid on 'valid' subset:   1331 / 1907 loss=2.42, loss_v1=0, loss_v2=0, nll_loss=1.197, ntokens=356, nsentences=12, sample_size=356.0, sample_size_v1=0, sample_size_v2=0
2023-04-08 21:39:01 - progress_bar.py[line:272] - INFO: epoch 008 | valid on 'valid' subset:   1341 / 1907 loss=2.472, loss_v1=0, loss_v2=0, nll_loss=1.253, ntokens=335, nsentences=12, sample_size=335.0, sample_size_v1=0, sample_size_v2=0
2023-04-08 21:39:19 - progress_bar.py[line:272] - INFO: epoch 008 | valid on 'valid' subset:   1351 / 1907 loss=2.417, loss_v1=0, loss_v2=0, nll_loss=1.192, ntokens=331, nsentences=12, sample_size=331.0, sample_size_v1=0, sample_size_v2=0
2023-04-08 21:39:32 - progress_bar.py[line:272] - INFO: epoch 008 | valid on 'valid' subset:   1361 / 1907 loss=2.299, loss_v1=0, loss_v2=0, nll_loss=1.063, ntokens=219, nsentences=12, sample_size=219.0, sample_size_v1=0, sample_size_v2=0
2023-04-08 21:39:48 - progress_bar.py[line:272] - INFO: epoch 008 | valid on 'valid' subset:   1371 / 1907 loss=2.396, loss_v1=0, loss_v2=0, nll_loss=1.17, ntokens=292, nsentences=12, sample_size=292.0, sample_size_v1=0, sample_size_v2=0
2023-04-08 21:40:05 - progress_bar.py[line:272] - INFO: epoch 008 | valid on 'valid' subset:   1381 / 1907 loss=2.338, loss_v1=0, loss_v2=0, nll_loss=1.102, ntokens=314, nsentences=12, sample_size=314.0, sample_size_v1=0, sample_size_v2=0
2023-04-08 21:40:17 - progress_bar.py[line:272] - INFO: epoch 008 | valid on 'valid' subset:   1391 / 1907 loss=2.228, loss_v1=0, loss_v2=0, nll_loss=0.979, ntokens=275, nsentences=12, sample_size=275.0, sample_size_v1=0, sample_size_v2=0
2023-04-08 21:40:34 - progress_bar.py[line:272] - INFO: epoch 008 | valid on 'valid' subset:   1401 / 1907 loss=2.475, loss_v1=0, loss_v2=0, nll_loss=1.262, ntokens=230, nsentences=12, sample_size=230.0, sample_size_v1=0, sample_size_v2=0
2023-04-08 21:40:49 - progress_bar.py[line:272] - INFO: epoch 008 | valid on 'valid' subset:   1411 / 1907 loss=2.574, loss_v1=0, loss_v2=0, nll_loss=1.369, ntokens=321, nsentences=12, sample_size=321.0, sample_size_v1=0, sample_size_v2=0
2023-04-08 21:41:04 - progress_bar.py[line:272] - INFO: epoch 008 | valid on 'valid' subset:   1421 / 1907 loss=2.361, loss_v1=0, loss_v2=0, nll_loss=1.124, ntokens=309, nsentences=12, sample_size=309.0, sample_size_v1=0, sample_size_v2=0
2023-04-08 21:41:19 - progress_bar.py[line:272] - INFO: epoch 008 | valid on 'valid' subset:   1431 / 1907 loss=2.431, loss_v1=0, loss_v2=0, nll_loss=1.204, ntokens=313, nsentences=12, sample_size=313.0, sample_size_v1=0, sample_size_v2=0
2023-04-08 21:41:35 - progress_bar.py[line:272] - INFO: epoch 008 | valid on 'valid' subset:   1441 / 1907 loss=2.446, loss_v1=0, loss_v2=0, nll_loss=1.224, ntokens=329, nsentences=12, sample_size=329.0, sample_size_v1=0, sample_size_v2=0
2023-04-08 21:41:52 - progress_bar.py[line:272] - INFO: epoch 008 | valid on 'valid' subset:   1451 / 1907 loss=2.415, loss_v1=0, loss_v2=0, nll_loss=1.187, ntokens=383, nsentences=12, sample_size=383.0, sample_size_v1=0, sample_size_v2=0
2023-04-08 21:42:10 - progress_bar.py[line:272] - INFO: epoch 008 | valid on 'valid' subset:   1461 / 1907 loss=2.467, loss_v1=0, loss_v2=0, nll_loss=1.25, ntokens=245, nsentences=12, sample_size=245.0, sample_size_v1=0, sample_size_v2=0
2023-04-08 21:42:29 - progress_bar.py[line:272] - INFO: epoch 008 | valid on 'valid' subset:   1471 / 1907 loss=2.406, loss_v1=0, loss_v2=0, nll_loss=1.178, ntokens=279, nsentences=12, sample_size=279.0, sample_size_v1=0, sample_size_v2=0
2023-04-08 21:42:47 - progress_bar.py[line:272] - INFO: epoch 008 | valid on 'valid' subset:   1481 / 1907 loss=2.502, loss_v1=0, loss_v2=0, nll_loss=1.292, ntokens=268, nsentences=12, sample_size=268.0, sample_size_v1=0, sample_size_v2=0
2023-04-08 21:43:05 - progress_bar.py[line:272] - INFO: epoch 008 | valid on 'valid' subset:   1491 / 1907 loss=2.67, loss_v1=0, loss_v2=0, nll_loss=1.476, ntokens=274, nsentences=12, sample_size=274.0, sample_size_v1=0, sample_size_v2=0
2023-04-08 21:43:22 - progress_bar.py[line:272] - INFO: epoch 008 | valid on 'valid' subset:   1501 / 1907 loss=2.499, loss_v1=0, loss_v2=0, nll_loss=1.281, ntokens=317, nsentences=12, sample_size=317.0, sample_size_v1=0, sample_size_v2=0
2023-04-08 21:43:40 - progress_bar.py[line:272] - INFO: epoch 008 | valid on 'valid' subset:   1511 / 1907 loss=2.545, loss_v1=0, loss_v2=0, nll_loss=1.331, ntokens=248, nsentences=12, sample_size=248.0, sample_size_v1=0, sample_size_v2=0
2023-04-08 21:43:58 - progress_bar.py[line:272] - INFO: epoch 008 | valid on 'valid' subset:   1521 / 1907 loss=2.488, loss_v1=0, loss_v2=0, nll_loss=1.27, ntokens=306, nsentences=12, sample_size=306.0, sample_size_v1=0, sample_size_v2=0
2023-04-08 21:44:14 - progress_bar.py[line:272] - INFO: epoch 008 | valid on 'valid' subset:   1531 / 1907 loss=2.435, loss_v1=0, loss_v2=0, nll_loss=1.213, ntokens=311, nsentences=12, sample_size=311.0, sample_size_v1=0, sample_size_v2=0
2023-04-08 21:44:31 - progress_bar.py[line:272] - INFO: epoch 008 | valid on 'valid' subset:   1541 / 1907 loss=2.441, loss_v1=0, loss_v2=0, nll_loss=1.219, ntokens=441, nsentences=12, sample_size=441.0, sample_size_v1=0, sample_size_v2=0
2023-04-08 21:44:49 - progress_bar.py[line:272] - INFO: epoch 008 | valid on 'valid' subset:   1551 / 1907 loss=2.562, loss_v1=0, loss_v2=0, nll_loss=1.354, ntokens=270, nsentences=12, sample_size=270.0, sample_size_v1=0, sample_size_v2=0
2023-04-08 21:45:06 - progress_bar.py[line:272] - INFO: epoch 008 | valid on 'valid' subset:   1561 / 1907 loss=2.382, loss_v1=0, loss_v2=0, nll_loss=1.155, ntokens=371, nsentences=12, sample_size=371.0, sample_size_v1=0, sample_size_v2=0
2023-04-08 21:45:24 - progress_bar.py[line:272] - INFO: epoch 008 | valid on 'valid' subset:   1571 / 1907 loss=2.285, loss_v1=0, loss_v2=0, nll_loss=1.047, ntokens=396, nsentences=12, sample_size=396.0, sample_size_v1=0, sample_size_v2=0
2023-04-08 21:45:42 - progress_bar.py[line:272] - INFO: epoch 008 | valid on 'valid' subset:   1581 / 1907 loss=2.509, loss_v1=0, loss_v2=0, nll_loss=1.298, ntokens=411, nsentences=12, sample_size=411.0, sample_size_v1=0, sample_size_v2=0
2023-04-08 21:45:58 - progress_bar.py[line:272] - INFO: epoch 008 | valid on 'valid' subset:   1591 / 1907 loss=2.599, loss_v1=0, loss_v2=0, nll_loss=1.396, ntokens=282, nsentences=12, sample_size=282.0, sample_size_v1=0, sample_size_v2=0
2023-04-08 21:46:16 - progress_bar.py[line:272] - INFO: epoch 008 | valid on 'valid' subset:   1601 / 1907 loss=2.565, loss_v1=0, loss_v2=0, nll_loss=1.359, ntokens=399, nsentences=12, sample_size=399.0, sample_size_v1=0, sample_size_v2=0
2023-04-08 21:46:33 - progress_bar.py[line:272] - INFO: epoch 008 | valid on 'valid' subset:   1611 / 1907 loss=2.447, loss_v1=0, loss_v2=0, nll_loss=1.226, ntokens=343, nsentences=12, sample_size=343.0, sample_size_v1=0, sample_size_v2=0
2023-04-08 21:46:47 - progress_bar.py[line:272] - INFO: epoch 008 | valid on 'valid' subset:   1621 / 1907 loss=2.507, loss_v1=0, loss_v2=0, nll_loss=1.293, ntokens=309, nsentences=12, sample_size=309.0, sample_size_v1=0, sample_size_v2=0
2023-04-08 21:47:04 - progress_bar.py[line:272] - INFO: epoch 008 | valid on 'valid' subset:   1631 / 1907 loss=2.553, loss_v1=0, loss_v2=0, nll_loss=1.342, ntokens=270, nsentences=12, sample_size=270.0, sample_size_v1=0, sample_size_v2=0
2023-04-08 21:47:21 - progress_bar.py[line:272] - INFO: epoch 008 | valid on 'valid' subset:   1641 / 1907 loss=2.512, loss_v1=0, loss_v2=0, nll_loss=1.297, ntokens=359, nsentences=12, sample_size=359.0, sample_size_v1=0, sample_size_v2=0
2023-04-08 21:47:38 - progress_bar.py[line:272] - INFO: epoch 008 | valid on 'valid' subset:   1651 / 1907 loss=2.476, loss_v1=0, loss_v2=0, nll_loss=1.261, ntokens=268, nsentences=12, sample_size=268.0, sample_size_v1=0, sample_size_v2=0
2023-04-08 21:47:54 - progress_bar.py[line:272] - INFO: epoch 008 | valid on 'valid' subset:   1661 / 1907 loss=2.455, loss_v1=0, loss_v2=0, nll_loss=1.236, ntokens=300, nsentences=12, sample_size=300.0, sample_size_v1=0, sample_size_v2=0
2023-04-08 21:48:09 - progress_bar.py[line:272] - INFO: epoch 008 | valid on 'valid' subset:   1671 / 1907 loss=2.488, loss_v1=0, loss_v2=0, nll_loss=1.268, ntokens=282, nsentences=12, sample_size=282.0, sample_size_v1=0, sample_size_v2=0
2023-04-08 21:48:26 - progress_bar.py[line:272] - INFO: epoch 008 | valid on 'valid' subset:   1681 / 1907 loss=2.342, loss_v1=0, loss_v2=0, nll_loss=1.109, ntokens=244, nsentences=12, sample_size=244.0, sample_size_v1=0, sample_size_v2=0
2023-04-08 21:48:42 - progress_bar.py[line:272] - INFO: epoch 008 | valid on 'valid' subset:   1691 / 1907 loss=2.352, loss_v1=0, loss_v2=0, nll_loss=1.118, ntokens=285, nsentences=12, sample_size=285.0, sample_size_v1=0, sample_size_v2=0
2023-04-08 21:49:01 - progress_bar.py[line:272] - INFO: epoch 008 | valid on 'valid' subset:   1701 / 1907 loss=2.447, loss_v1=0, loss_v2=0, nll_loss=1.227, ntokens=364, nsentences=12, sample_size=364.0, sample_size_v1=0, sample_size_v2=0
2023-04-08 21:49:18 - progress_bar.py[line:272] - INFO: epoch 008 | valid on 'valid' subset:   1711 / 1907 loss=2.464, loss_v1=0, loss_v2=0, nll_loss=1.242, ntokens=234, nsentences=12, sample_size=234.0, sample_size_v1=0, sample_size_v2=0
2023-04-08 21:49:35 - progress_bar.py[line:272] - INFO: epoch 008 | valid on 'valid' subset:   1721 / 1907 loss=2.53, loss_v1=0, loss_v2=0, nll_loss=1.32, ntokens=190, nsentences=12, sample_size=190.0, sample_size_v1=0, sample_size_v2=0
2023-04-08 21:49:52 - progress_bar.py[line:272] - INFO: epoch 008 | valid on 'valid' subset:   1731 / 1907 loss=2.297, loss_v1=0, loss_v2=0, nll_loss=1.059, ntokens=255, nsentences=12, sample_size=255.0, sample_size_v1=0, sample_size_v2=0
2023-04-08 21:50:10 - progress_bar.py[line:272] - INFO: epoch 008 | valid on 'valid' subset:   1741 / 1907 loss=2.334, loss_v1=0, loss_v2=0, nll_loss=1.1, ntokens=337, nsentences=12, sample_size=337.0, sample_size_v1=0, sample_size_v2=0
2023-04-08 21:50:28 - progress_bar.py[line:272] - INFO: epoch 008 | valid on 'valid' subset:   1751 / 1907 loss=2.491, loss_v1=0, loss_v2=0, nll_loss=1.276, ntokens=233, nsentences=12, sample_size=233.0, sample_size_v1=0, sample_size_v2=0
2023-04-08 21:50:46 - progress_bar.py[line:272] - INFO: epoch 008 | valid on 'valid' subset:   1761 / 1907 loss=2.419, loss_v1=0, loss_v2=0, nll_loss=1.194, ntokens=298, nsentences=12, sample_size=298.0, sample_size_v1=0, sample_size_v2=0
2023-04-08 21:51:05 - progress_bar.py[line:272] - INFO: epoch 008 | valid on 'valid' subset:   1771 / 1907 loss=2.289, loss_v1=0, loss_v2=0, nll_loss=1.049, ntokens=253, nsentences=12, sample_size=253.0, sample_size_v1=0, sample_size_v2=0
2023-04-08 21:51:23 - progress_bar.py[line:272] - INFO: epoch 008 | valid on 'valid' subset:   1781 / 1907 loss=2.296, loss_v1=0, loss_v2=0, nll_loss=1.055, ntokens=287, nsentences=12, sample_size=287.0, sample_size_v1=0, sample_size_v2=0
2023-04-08 21:51:40 - progress_bar.py[line:272] - INFO: epoch 008 | valid on 'valid' subset:   1791 / 1907 loss=2.292, loss_v1=0, loss_v2=0, nll_loss=1.05, ntokens=230, nsentences=12, sample_size=230.0, sample_size_v1=0, sample_size_v2=0
2023-04-08 21:51:56 - progress_bar.py[line:272] - INFO: epoch 008 | valid on 'valid' subset:   1801 / 1907 loss=2.615, loss_v1=0, loss_v2=0, nll_loss=1.416, ntokens=216, nsentences=12, sample_size=216.0, sample_size_v1=0, sample_size_v2=0
2023-04-08 21:52:12 - progress_bar.py[line:272] - INFO: epoch 008 | valid on 'valid' subset:   1811 / 1907 loss=2.44, loss_v1=0, loss_v2=0, nll_loss=1.217, ntokens=285, nsentences=12, sample_size=285.0, sample_size_v1=0, sample_size_v2=0
2023-04-08 21:52:31 - progress_bar.py[line:272] - INFO: epoch 008 | valid on 'valid' subset:   1821 / 1907 loss=2.421, loss_v1=0, loss_v2=0, nll_loss=1.194, ntokens=300, nsentences=12, sample_size=300.0, sample_size_v1=0, sample_size_v2=0
2023-04-08 21:52:49 - progress_bar.py[line:272] - INFO: epoch 008 | valid on 'valid' subset:   1831 / 1907 loss=2.289, loss_v1=0, loss_v2=0, nll_loss=1.048, ntokens=422, nsentences=12, sample_size=422.0, sample_size_v1=0, sample_size_v2=0
2023-04-08 21:53:06 - progress_bar.py[line:272] - INFO: epoch 008 | valid on 'valid' subset:   1841 / 1907 loss=2.467, loss_v1=0, loss_v2=0, nll_loss=1.247, ntokens=275, nsentences=12, sample_size=275.0, sample_size_v1=0, sample_size_v2=0
2023-04-08 21:53:24 - progress_bar.py[line:272] - INFO: epoch 008 | valid on 'valid' subset:   1851 / 1907 loss=2.349, loss_v1=0, loss_v2=0, nll_loss=1.114, ntokens=273, nsentences=12, sample_size=273.0, sample_size_v1=0, sample_size_v2=0
2023-04-08 21:53:41 - progress_bar.py[line:272] - INFO: epoch 008 | valid on 'valid' subset:   1861 / 1907 loss=2.391, loss_v1=0, loss_v2=0, nll_loss=1.162, ntokens=278, nsentences=12, sample_size=278.0, sample_size_v1=0, sample_size_v2=0
2023-04-08 21:53:59 - progress_bar.py[line:272] - INFO: epoch 008 | valid on 'valid' subset:   1871 / 1907 loss=2.289, loss_v1=0, loss_v2=0, nll_loss=1.048, ntokens=385, nsentences=12, sample_size=385.0, sample_size_v1=0, sample_size_v2=0
2023-04-08 21:54:17 - progress_bar.py[line:272] - INFO: epoch 008 | valid on 'valid' subset:   1881 / 1907 loss=2.376, loss_v1=0, loss_v2=0, nll_loss=1.146, ntokens=359, nsentences=12, sample_size=359.0, sample_size_v1=0, sample_size_v2=0
2023-04-08 21:54:35 - progress_bar.py[line:272] - INFO: epoch 008 | valid on 'valid' subset:   1891 / 1907 loss=2.44, loss_v1=0, loss_v2=0, nll_loss=1.213, ntokens=268, nsentences=12, sample_size=268.0, sample_size_v1=0, sample_size_v2=0
2023-04-08 21:54:51 - progress_bar.py[line:272] - INFO: epoch 008 | valid on 'valid' subset:   1901 / 1907 loss=2.556, loss_v1=0, loss_v2=0, nll_loss=1.347, ntokens=351, nsentences=12, sample_size=351.0, sample_size_v1=0, sample_size_v2=0
local datafile ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 1 begin to initialize row_count and line_idx-to-offset mapping
2023-04-08 21:55:02 - progress_bar.py[line:282] - INFO: epoch 008 | valid on 'valid' subset | loss 2.433 | loss_v1 0 | loss_v2 0 | nll_loss 1.21 | ntokens 323.198 | nsentences 11.998 | sample_size 323.198 | sample_size_v1 0 | sample_size_v2 0 | ppl 2.31 | wps 186 | wpb 323.2 | bsz 12 | num_updates 4616 | best_loss 2.486
2023-04-08 21:55:02 - checkpoint_utils.py[line:64] - INFO: Preparing to save checkpoint for epoch 8 @ 4616 updates
2023-04-08 21:55:02 - trainer.py[line:431] - INFO: Saving checkpoint to ../../checkpoints/OFA/sgcls_checkpoints/_12_3e-5_512/checkpoint_last.pt
local datafile ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 1 finished initializing row_count and line_idx-to-offset mapping
file ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 1 row count 27700 total row count 55400
slice_id 1 seek offset 27700
2023-04-08 21:55:11 - trainer.py[line:441] - INFO: Finished saving checkpoint to ../../checkpoints/OFA/sgcls_checkpoints/_12_3e-5_512/checkpoint_last.pt
2023-04-08 21:55:12 - checkpoint_utils.py[line:133] - INFO: Saved checkpoint ../../checkpoints/OFA/sgcls_checkpoints/_12_3e-5_512/checkpoint_last.pt (epoch 8 @ 4616 updates, score 2.433) (writing took 10.02047554217279 seconds)
2023-04-08 21:55:12 - train.py[line:332] - INFO: end of epoch 8 (average epoch stats below)
2023-04-08 21:55:12 - progress_bar.py[line:282] - INFO: epoch 008 | loss 2.43 | loss_v1 0 | loss_v2 0 | nll_loss 1.237 | ntokens 2519.89 | nsentences 95.847 | sample_size 2519.89 | sample_size_v1 0 | sample_size_v2 0 | ppl 2.36 | wps 292.5 | ups 0.12 | wpb 2519.9 | bsz 95.8 | num_updates 4616 | lr 1.06748e-05 | gnorm 1.972 | clip 100 | loss_scale 128 | train_wall 1642 | gb_free 13.1 | wall 21141
2023-04-08 21:55:12 - trainer.py[line:639] - INFO: loading train data for epoch 9
local datafile ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 0 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 0 finished initializing row_count and line_idx-to-offset mapping
file ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 0 row count 27700 total row count 55400
slice_id 0 seek offset 0
2023-04-08 21:55:14 - trainer.py[line:703] - INFO: begin training epoch 9
2023-04-08 21:55:14 - train.py[line:305] - INFO: Start iterating over samples
2023-04-08 21:55:26 - progress_bar.py[line:272] - INFO: epoch 009:      4 / 578 loss=2.433, loss_v1=0, loss_v2=0, nll_loss=1.239, ntokens=2356.8, nsentences=87.6, sample_size=2356.8, sample_size_v1=0, sample_size_v2=0, ppl=2.36, wps=7, ups=0, wpb=2356.8, bsz=87.6, num_updates=4620, lr=1.06564e-05, gnorm=2.407, clip=100, loss_scale=128, train_wall=26, gb_free=12.3, wall=21155
2023-04-08 21:55:54 - progress_bar.py[line:272] - INFO: epoch 009:     14 / 578 loss=2.401, loss_v1=0, loss_v2=0, nll_loss=1.205, ntokens=2416.3, nsentences=96, sample_size=2416.3, sample_size_v1=0, sample_size_v2=0, ppl=2.3, wps=843.5, ups=0.35, wpb=2416.3, bsz=96, num_updates=4630, lr=1.06104e-05, gnorm=2.155, clip=100, loss_scale=128, train_wall=29, gb_free=12.4, wall=21184
2023-04-08 21:56:23 - progress_bar.py[line:272] - INFO: epoch 009:     24 / 578 loss=2.398, loss_v1=0, loss_v2=0, nll_loss=1.202, ntokens=2360.9, nsentences=96, sample_size=2360.9, sample_size_v1=0, sample_size_v2=0, ppl=2.3, wps=820.3, ups=0.35, wpb=2360.9, bsz=96, num_updates=4640, lr=1.05644e-05, gnorm=2.214, clip=100, loss_scale=128, train_wall=29, gb_free=11.9, wall=21213
2023-04-08 21:56:52 - progress_bar.py[line:272] - INFO: epoch 009:     34 / 578 loss=2.409, loss_v1=0, loss_v2=0, nll_loss=1.215, ntokens=2282.6, nsentences=96, sample_size=2282.6, sample_size_v1=0, sample_size_v2=0, ppl=2.32, wps=793.8, ups=0.35, wpb=2282.6, bsz=96, num_updates=4650, lr=1.05184e-05, gnorm=2.309, clip=100, loss_scale=128, train_wall=29, gb_free=12.3, wall=21241
2023-04-08 21:57:20 - progress_bar.py[line:272] - INFO: epoch 009:     44 / 578 loss=2.369, loss_v1=0, loss_v2=0, nll_loss=1.167, ntokens=2176.8, nsentences=96, sample_size=2176.8, sample_size_v1=0, sample_size_v2=0, ppl=2.25, wps=756.8, ups=0.35, wpb=2176.8, bsz=96, num_updates=4660, lr=1.04724e-05, gnorm=2.463, clip=100, loss_scale=128, train_wall=29, gb_free=12, wall=21270
2023-04-08 21:57:50 - progress_bar.py[line:272] - INFO: epoch 009:     54 / 578 loss=2.415, loss_v1=0, loss_v2=0, nll_loss=1.22, ntokens=2425, nsentences=96, sample_size=2425, sample_size_v1=0, sample_size_v2=0, ppl=2.33, wps=830.9, ups=0.34, wpb=2425, bsz=96, num_updates=4670, lr=1.04264e-05, gnorm=2.375, clip=100, loss_scale=128, train_wall=29, gb_free=11.8, wall=21299
2023-04-08 21:58:18 - progress_bar.py[line:272] - INFO: epoch 009:     64 / 578 loss=2.414, loss_v1=0, loss_v2=0, nll_loss=1.22, ntokens=2232.6, nsentences=96, sample_size=2232.6, sample_size_v1=0, sample_size_v2=0, ppl=2.33, wps=779.5, ups=0.35, wpb=2232.6, bsz=96, num_updates=4680, lr=1.03804e-05, gnorm=2.355, clip=100, loss_scale=128, train_wall=29, gb_free=12, wall=21328
2023-04-08 21:58:47 - progress_bar.py[line:272] - INFO: epoch 009:     74 / 578 loss=2.444, loss_v1=0, loss_v2=0, nll_loss=1.254, ntokens=2451, nsentences=96, sample_size=2451, sample_size_v1=0, sample_size_v2=0, ppl=2.39, wps=860.4, ups=0.35, wpb=2451, bsz=96, num_updates=4690, lr=1.03344e-05, gnorm=2.219, clip=100, loss_scale=128, train_wall=28, gb_free=12.2, wall=21356
2023-04-08 21:59:16 - progress_bar.py[line:272] - INFO: epoch 009:     84 / 578 loss=2.438, loss_v1=0, loss_v2=0, nll_loss=1.245, ntokens=2493.8, nsentences=96, sample_size=2493.8, sample_size_v1=0, sample_size_v2=0, ppl=2.37, wps=860.7, ups=0.35, wpb=2493.8, bsz=96, num_updates=4700, lr=1.02883e-05, gnorm=2.267, clip=100, loss_scale=128, train_wall=29, gb_free=11.9, wall=21385
2023-04-08 21:59:45 - progress_bar.py[line:272] - INFO: epoch 009:     94 / 578 loss=2.424, loss_v1=0, loss_v2=0, nll_loss=1.229, ntokens=2498.7, nsentences=96, sample_size=2498.7, sample_size_v1=0, sample_size_v2=0, ppl=2.34, wps=861.4, ups=0.34, wpb=2498.7, bsz=96, num_updates=4710, lr=1.02423e-05, gnorm=2.264, clip=100, loss_scale=128, train_wall=29, gb_free=11.7, wall=21414
2023-04-08 22:00:14 - progress_bar.py[line:272] - INFO: epoch 009:    104 / 578 loss=2.424, loss_v1=0, loss_v2=0, nll_loss=1.231, ntokens=2443.1, nsentences=96, sample_size=2443.1, sample_size_v1=0, sample_size_v2=0, ppl=2.35, wps=837.5, ups=0.34, wpb=2443.1, bsz=96, num_updates=4720, lr=1.01963e-05, gnorm=2.198, clip=100, loss_scale=128, train_wall=29, gb_free=12.1, wall=21444
2023-04-08 22:00:43 - progress_bar.py[line:272] - INFO: epoch 009:    114 / 578 loss=2.432, loss_v1=0, loss_v2=0, nll_loss=1.239, ntokens=2367.9, nsentences=96, sample_size=2367.9, sample_size_v1=0, sample_size_v2=0, ppl=2.36, wps=826.1, ups=0.35, wpb=2367.9, bsz=96, num_updates=4730, lr=1.01503e-05, gnorm=2.334, clip=100, loss_scale=128, train_wall=29, gb_free=12.4, wall=21472
2023-04-08 22:01:11 - progress_bar.py[line:272] - INFO: epoch 009:    124 / 578 loss=2.437, loss_v1=0, loss_v2=0, nll_loss=1.244, ntokens=2347.2, nsentences=96, sample_size=2347.2, sample_size_v1=0, sample_size_v2=0, ppl=2.37, wps=813.9, ups=0.35, wpb=2347.2, bsz=96, num_updates=4740, lr=1.01043e-05, gnorm=2.368, clip=100, loss_scale=128, train_wall=29, gb_free=11.4, wall=21501
2023-04-08 22:01:40 - progress_bar.py[line:272] - INFO: epoch 009:    134 / 578 loss=2.425, loss_v1=0, loss_v2=0, nll_loss=1.232, ntokens=2432.5, nsentences=96, sample_size=2432.5, sample_size_v1=0, sample_size_v2=0, ppl=2.35, wps=848.1, ups=0.35, wpb=2432.5, bsz=96, num_updates=4750, lr=1.00583e-05, gnorm=2.31, clip=100, loss_scale=128, train_wall=29, gb_free=12.4, wall=21530
2023-04-08 22:02:09 - progress_bar.py[line:272] - INFO: epoch 009:    144 / 578 loss=2.44, loss_v1=0, loss_v2=0, nll_loss=1.249, ntokens=2524.1, nsentences=96, sample_size=2524.1, sample_size_v1=0, sample_size_v2=0, ppl=2.38, wps=883.4, ups=0.35, wpb=2524.1, bsz=96, num_updates=4760, lr=1.00123e-05, gnorm=2.261, clip=100, loss_scale=128, train_wall=29, gb_free=12.3, wall=21558
2023-04-08 22:02:37 - progress_bar.py[line:272] - INFO: epoch 009:    154 / 578 loss=2.437, loss_v1=0, loss_v2=0, nll_loss=1.243, ntokens=2632.8, nsentences=96, sample_size=2632.8, sample_size_v1=0, sample_size_v2=0, ppl=2.37, wps=924.6, ups=0.35, wpb=2632.8, bsz=96, num_updates=4770, lr=9.96626e-06, gnorm=2.081, clip=100, loss_scale=128, train_wall=28, gb_free=12.5, wall=21587
2023-04-08 22:03:06 - progress_bar.py[line:272] - INFO: epoch 009:    164 / 578 loss=2.434, loss_v1=0, loss_v2=0, nll_loss=1.242, ntokens=2705.9, nsentences=96, sample_size=2705.9, sample_size_v1=0, sample_size_v2=0, ppl=2.36, wps=947.3, ups=0.35, wpb=2705.9, bsz=96, num_updates=4780, lr=9.92025e-06, gnorm=1.974, clip=100, loss_scale=128, train_wall=29, gb_free=12.5, wall=21615
2023-04-08 22:03:34 - progress_bar.py[line:272] - INFO: epoch 009:    174 / 578 loss=2.437, loss_v1=0, loss_v2=0, nll_loss=1.246, ntokens=2595.7, nsentences=96, sample_size=2595.7, sample_size_v1=0, sample_size_v2=0, ppl=2.37, wps=910.3, ups=0.35, wpb=2595.7, bsz=96, num_updates=4790, lr=9.87423e-06, gnorm=2.07, clip=100, loss_scale=128, train_wall=28, gb_free=12.5, wall=21644
2023-04-08 22:04:03 - progress_bar.py[line:272] - INFO: epoch 009:    184 / 578 loss=2.434, loss_v1=0, loss_v2=0, nll_loss=1.24, ntokens=2622.3, nsentences=96, sample_size=2622.3, sample_size_v1=0, sample_size_v2=0, ppl=2.36, wps=916.6, ups=0.35, wpb=2622.3, bsz=96, num_updates=4800, lr=9.82822e-06, gnorm=2.175, clip=100, loss_scale=128, train_wall=29, gb_free=12.3, wall=21673
2023-04-08 22:04:31 - progress_bar.py[line:272] - INFO: epoch 009:    194 / 578 loss=2.425, loss_v1=0, loss_v2=0, nll_loss=1.232, ntokens=2623.4, nsentences=96, sample_size=2623.4, sample_size_v1=0, sample_size_v2=0, ppl=2.35, wps=918.5, ups=0.35, wpb=2623.4, bsz=96, num_updates=4810, lr=9.78221e-06, gnorm=2.133, clip=100, loss_scale=128, train_wall=29, gb_free=12.3, wall=21701
2023-04-08 22:05:00 - progress_bar.py[line:272] - INFO: epoch 009:    204 / 578 loss=2.425, loss_v1=0, loss_v2=0, nll_loss=1.232, ntokens=2596.4, nsentences=96, sample_size=2596.4, sample_size_v1=0, sample_size_v2=0, ppl=2.35, wps=911.4, ups=0.35, wpb=2596.4, bsz=96, num_updates=4820, lr=9.7362e-06, gnorm=2.157, clip=100, loss_scale=128, train_wall=28, gb_free=12.3, wall=21730
2023-04-08 22:05:28 - progress_bar.py[line:272] - INFO: epoch 009:    214 / 578 loss=2.441, loss_v1=0, loss_v2=0, nll_loss=1.25, ntokens=2460.3, nsentences=96, sample_size=2460.3, sample_size_v1=0, sample_size_v2=0, ppl=2.38, wps=867.5, ups=0.35, wpb=2460.3, bsz=96, num_updates=4830, lr=9.69018e-06, gnorm=2.289, clip=100, loss_scale=128, train_wall=28, gb_free=12.5, wall=21758
2023-04-08 22:05:57 - progress_bar.py[line:272] - INFO: epoch 009:    224 / 578 loss=2.42, loss_v1=0, loss_v2=0, nll_loss=1.225, ntokens=2602.3, nsentences=96, sample_size=2602.3, sample_size_v1=0, sample_size_v2=0, ppl=2.34, wps=916.1, ups=0.35, wpb=2602.3, bsz=96, num_updates=4840, lr=9.64417e-06, gnorm=2.175, clip=100, loss_scale=128, train_wall=28, gb_free=12.7, wall=21786
2023-04-08 22:06:25 - progress_bar.py[line:272] - INFO: epoch 009:    234 / 578 loss=2.418, loss_v1=0, loss_v2=0, nll_loss=1.225, ntokens=2439, nsentences=96, sample_size=2439, sample_size_v1=0, sample_size_v2=0, ppl=2.34, wps=859.2, ups=0.35, wpb=2439, bsz=96, num_updates=4850, lr=9.59816e-06, gnorm=2.315, clip=100, loss_scale=128, train_wall=28, gb_free=12.4, wall=21815
2023-04-08 22:06:53 - progress_bar.py[line:272] - INFO: epoch 009:    244 / 578 loss=2.435, loss_v1=0, loss_v2=0, nll_loss=1.243, ntokens=2472.3, nsentences=96, sample_size=2472.3, sample_size_v1=0, sample_size_v2=0, ppl=2.37, wps=873.6, ups=0.35, wpb=2472.3, bsz=96, num_updates=4860, lr=9.55215e-06, gnorm=2.213, clip=100, loss_scale=128, train_wall=28, gb_free=12.5, wall=21843
2023-04-08 22:07:22 - progress_bar.py[line:272] - INFO: epoch 009:    254 / 578 loss=2.435, loss_v1=0, loss_v2=0, nll_loss=1.241, ntokens=2592.9, nsentences=96, sample_size=2592.9, sample_size_v1=0, sample_size_v2=0, ppl=2.36, wps=916, ups=0.35, wpb=2592.9, bsz=96, num_updates=4870, lr=9.50613e-06, gnorm=2.172, clip=100, loss_scale=128, train_wall=28, gb_free=12.5, wall=21871
2023-04-08 22:07:50 - progress_bar.py[line:272] - INFO: epoch 009:    264 / 578 loss=2.424, loss_v1=0, loss_v2=0, nll_loss=1.232, ntokens=2482.8, nsentences=96, sample_size=2482.8, sample_size_v1=0, sample_size_v2=0, ppl=2.35, wps=879.2, ups=0.35, wpb=2482.8, bsz=96, num_updates=4880, lr=9.46012e-06, gnorm=2.205, clip=100, loss_scale=128, train_wall=28, gb_free=12.3, wall=21900
2023-04-08 22:08:18 - progress_bar.py[line:272] - INFO: epoch 009:    274 / 578 loss=2.422, loss_v1=0, loss_v2=0, nll_loss=1.229, ntokens=2612.4, nsentences=96, sample_size=2612.4, sample_size_v1=0, sample_size_v2=0, ppl=2.34, wps=919.6, ups=0.35, wpb=2612.4, bsz=96, num_updates=4890, lr=9.41411e-06, gnorm=1.989, clip=100, loss_scale=128, train_wall=28, gb_free=12.5, wall=21928
2023-04-08 22:08:47 - progress_bar.py[line:272] - INFO: epoch 009:    284 / 578 loss=2.407, loss_v1=0, loss_v2=0, nll_loss=1.211, ntokens=2527.6, nsentences=96, sample_size=2527.6, sample_size_v1=0, sample_size_v2=0, ppl=2.32, wps=888.6, ups=0.35, wpb=2527.6, bsz=96, num_updates=4900, lr=9.3681e-06, gnorm=2.188, clip=100, loss_scale=128, train_wall=28, gb_free=12.2, wall=21957
2023-04-08 22:09:07 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 128.0
2023-04-08 22:09:18 - progress_bar.py[line:272] - INFO: epoch 009:    295 / 578 loss=2.424, loss_v1=0, loss_v2=0, nll_loss=1.23, ntokens=2565, nsentences=95.6, sample_size=2565, sample_size_v1=0, sample_size_v2=0, ppl=2.35, wps=823.1, ups=0.32, wpb=2565, bsz=95.6, num_updates=4910, lr=9.32209e-06, gnorm=2.119, clip=100, loss_scale=128, train_wall=31, gb_free=12.3, wall=21988
2023-04-08 22:09:47 - progress_bar.py[line:272] - INFO: epoch 009:    305 / 578 loss=2.415, loss_v1=0, loss_v2=0, nll_loss=1.221, ntokens=2551.7, nsentences=96, sample_size=2551.7, sample_size_v1=0, sample_size_v2=0, ppl=2.33, wps=895.7, ups=0.35, wpb=2551.7, bsz=96, num_updates=4920, lr=9.27607e-06, gnorm=2.233, clip=100, loss_scale=128, train_wall=28, gb_free=12, wall=22016
2023-04-08 22:10:15 - progress_bar.py[line:272] - INFO: epoch 009:    315 / 578 loss=2.429, loss_v1=0, loss_v2=0, nll_loss=1.236, ntokens=2644.8, nsentences=96, sample_size=2644.8, sample_size_v1=0, sample_size_v2=0, ppl=2.36, wps=927.9, ups=0.35, wpb=2644.8, bsz=96, num_updates=4930, lr=9.23006e-06, gnorm=2.323, clip=100, loss_scale=128, train_wall=28, gb_free=12.1, wall=22045
2023-04-08 22:10:43 - progress_bar.py[line:272] - INFO: epoch 009:    325 / 578 loss=2.418, loss_v1=0, loss_v2=0, nll_loss=1.224, ntokens=2580.4, nsentences=96, sample_size=2580.4, sample_size_v1=0, sample_size_v2=0, ppl=2.34, wps=908.4, ups=0.35, wpb=2580.4, bsz=96, num_updates=4940, lr=9.18405e-06, gnorm=2.153, clip=100, loss_scale=128, train_wall=28, gb_free=12.7, wall=22073
2023-04-08 22:11:12 - progress_bar.py[line:272] - INFO: epoch 009:    335 / 578 loss=2.399, loss_v1=0, loss_v2=0, nll_loss=1.203, ntokens=2573.7, nsentences=96, sample_size=2573.7, sample_size_v1=0, sample_size_v2=0, ppl=2.3, wps=909.1, ups=0.35, wpb=2573.7, bsz=96, num_updates=4950, lr=9.13804e-06, gnorm=2.192, clip=100, loss_scale=128, train_wall=28, gb_free=12.5, wall=22101
2023-04-08 22:11:40 - progress_bar.py[line:272] - INFO: epoch 009:    345 / 578 loss=2.419, loss_v1=0, loss_v2=0, nll_loss=1.224, ntokens=2706.2, nsentences=96, sample_size=2706.2, sample_size_v1=0, sample_size_v2=0, ppl=2.34, wps=954.2, ups=0.35, wpb=2706.2, bsz=96, num_updates=4960, lr=9.09202e-06, gnorm=2.094, clip=100, loss_scale=128, train_wall=28, gb_free=12.6, wall=22130
2023-04-08 22:12:09 - progress_bar.py[line:272] - INFO: epoch 009:    355 / 578 loss=2.396, loss_v1=0, loss_v2=0, nll_loss=1.2, ntokens=2572.3, nsentences=96, sample_size=2572.3, sample_size_v1=0, sample_size_v2=0, ppl=2.3, wps=904, ups=0.35, wpb=2572.3, bsz=96, num_updates=4970, lr=9.04601e-06, gnorm=2.126, clip=100, loss_scale=128, train_wall=28, gb_free=12.6, wall=22158
2023-04-08 22:12:37 - progress_bar.py[line:272] - INFO: epoch 009:    365 / 578 loss=2.421, loss_v1=0, loss_v2=0, nll_loss=1.228, ntokens=2763.7, nsentences=96, sample_size=2763.7, sample_size_v1=0, sample_size_v2=0, ppl=2.34, wps=969.1, ups=0.35, wpb=2763.7, bsz=96, num_updates=4980, lr=9e-06, gnorm=2.027, clip=100, loss_scale=128, train_wall=28, gb_free=12.4, wall=22187
2023-04-08 22:13:06 - progress_bar.py[line:272] - INFO: epoch 009:    375 / 578 loss=2.432, loss_v1=0, loss_v2=0, nll_loss=1.239, ntokens=2750.6, nsentences=96, sample_size=2750.6, sample_size_v1=0, sample_size_v2=0, ppl=2.36, wps=961.1, ups=0.35, wpb=2750.6, bsz=96, num_updates=4990, lr=8.95399e-06, gnorm=2.005, clip=100, loss_scale=128, train_wall=29, gb_free=12.7, wall=22215
2023-04-08 22:13:34 - progress_bar.py[line:272] - INFO: epoch 009:    385 / 578 loss=2.421, loss_v1=0, loss_v2=0, nll_loss=1.226, ntokens=2665.2, nsentences=96, sample_size=2665.2, sample_size_v1=0, sample_size_v2=0, ppl=2.34, wps=931.7, ups=0.35, wpb=2665.2, bsz=96, num_updates=5000, lr=8.90798e-06, gnorm=2.131, clip=100, loss_scale=128, train_wall=29, gb_free=12.4, wall=22244
2023-04-08 22:14:03 - progress_bar.py[line:272] - INFO: epoch 009:    395 / 578 loss=2.42, loss_v1=0, loss_v2=0, nll_loss=1.225, ntokens=2563.3, nsentences=96, sample_size=2563.3, sample_size_v1=0, sample_size_v2=0, ppl=2.34, wps=898.9, ups=0.35, wpb=2563.3, bsz=96, num_updates=5010, lr=8.86196e-06, gnorm=2.226, clip=100, loss_scale=128, train_wall=28, gb_free=12.3, wall=22272
2023-04-08 22:14:31 - progress_bar.py[line:272] - INFO: epoch 009:    405 / 578 loss=2.406, loss_v1=0, loss_v2=0, nll_loss=1.214, ntokens=2479, nsentences=96, sample_size=2479, sample_size_v1=0, sample_size_v2=0, ppl=2.32, wps=871.7, ups=0.35, wpb=2479, bsz=96, num_updates=5020, lr=8.81595e-06, gnorm=2.4, clip=100, loss_scale=128, train_wall=28, gb_free=12.4, wall=22301
2023-04-08 22:15:00 - progress_bar.py[line:272] - INFO: epoch 009:    415 / 578 loss=2.422, loss_v1=0, loss_v2=0, nll_loss=1.227, ntokens=2482, nsentences=96, sample_size=2482, sample_size_v1=0, sample_size_v2=0, ppl=2.34, wps=869.6, ups=0.35, wpb=2482, bsz=96, num_updates=5030, lr=8.76994e-06, gnorm=2.231, clip=100, loss_scale=128, train_wall=29, gb_free=12.1, wall=22329
2023-04-08 22:15:28 - progress_bar.py[line:272] - INFO: epoch 009:    425 / 578 loss=2.407, loss_v1=0, loss_v2=0, nll_loss=1.212, ntokens=2477.2, nsentences=96, sample_size=2477.2, sample_size_v1=0, sample_size_v2=0, ppl=2.32, wps=872.9, ups=0.35, wpb=2477.2, bsz=96, num_updates=5040, lr=8.72393e-06, gnorm=2.432, clip=100, loss_scale=128, train_wall=28, gb_free=12.6, wall=22358
2023-04-08 22:15:56 - progress_bar.py[line:272] - INFO: epoch 009:    435 / 578 loss=2.406, loss_v1=0, loss_v2=0, nll_loss=1.209, ntokens=2542.9, nsentences=96, sample_size=2542.9, sample_size_v1=0, sample_size_v2=0, ppl=2.31, wps=900.7, ups=0.35, wpb=2542.9, bsz=96, num_updates=5050, lr=8.67791e-06, gnorm=2.271, clip=100, loss_scale=128, train_wall=28, gb_free=12.7, wall=22386
2023-04-08 22:16:25 - progress_bar.py[line:272] - INFO: epoch 009:    445 / 578 loss=2.424, loss_v1=0, loss_v2=0, nll_loss=1.23, ntokens=2425.5, nsentences=96, sample_size=2425.5, sample_size_v1=0, sample_size_v2=0, ppl=2.35, wps=856.1, ups=0.35, wpb=2425.5, bsz=96, num_updates=5060, lr=8.6319e-06, gnorm=2.366, clip=100, loss_scale=128, train_wall=28, gb_free=12.5, wall=22414
2023-04-08 22:16:53 - progress_bar.py[line:272] - INFO: epoch 009:    455 / 578 loss=2.414, loss_v1=0, loss_v2=0, nll_loss=1.219, ntokens=2554.3, nsentences=96, sample_size=2554.3, sample_size_v1=0, sample_size_v2=0, ppl=2.33, wps=901.8, ups=0.35, wpb=2554.3, bsz=96, num_updates=5070, lr=8.58589e-06, gnorm=2.368, clip=100, loss_scale=128, train_wall=28, gb_free=12.5, wall=22443
2023-04-08 22:17:22 - progress_bar.py[line:272] - INFO: epoch 009:    465 / 578 loss=2.425, loss_v1=0, loss_v2=0, nll_loss=1.232, ntokens=2531.4, nsentences=96, sample_size=2531.4, sample_size_v1=0, sample_size_v2=0, ppl=2.35, wps=890.1, ups=0.35, wpb=2531.4, bsz=96, num_updates=5080, lr=8.53988e-06, gnorm=2.253, clip=100, loss_scale=128, train_wall=28, gb_free=12.1, wall=22471
2023-04-08 22:17:50 - progress_bar.py[line:272] - INFO: epoch 009:    475 / 578 loss=2.428, loss_v1=0, loss_v2=0, nll_loss=1.236, ntokens=2359.4, nsentences=96, sample_size=2359.4, sample_size_v1=0, sample_size_v2=0, ppl=2.36, wps=834.4, ups=0.35, wpb=2359.4, bsz=96, num_updates=5090, lr=8.49387e-06, gnorm=2.489, clip=100, loss_scale=128, train_wall=28, gb_free=12.7, wall=22499
2023-04-08 22:18:18 - progress_bar.py[line:272] - INFO: epoch 009:    485 / 578 loss=2.408, loss_v1=0, loss_v2=0, nll_loss=1.212, ntokens=2391.2, nsentences=96, sample_size=2391.2, sample_size_v1=0, sample_size_v2=0, ppl=2.32, wps=845.8, ups=0.35, wpb=2391.2, bsz=96, num_updates=5100, lr=8.44785e-06, gnorm=2.462, clip=100, loss_scale=128, train_wall=28, gb_free=12.7, wall=22528
2023-04-08 22:18:46 - progress_bar.py[line:272] - INFO: epoch 009:    495 / 578 loss=2.402, loss_v1=0, loss_v2=0, nll_loss=1.208, ntokens=2550.1, nsentences=96, sample_size=2550.1, sample_size_v1=0, sample_size_v2=0, ppl=2.31, wps=898.8, ups=0.35, wpb=2550.1, bsz=96, num_updates=5110, lr=8.40184e-06, gnorm=2.479, clip=100, loss_scale=128, train_wall=28, gb_free=12.5, wall=22556
2023-04-08 22:19:15 - progress_bar.py[line:272] - INFO: epoch 009:    505 / 578 loss=2.396, loss_v1=0, loss_v2=0, nll_loss=1.198, ntokens=2528.3, nsentences=96, sample_size=2528.3, sample_size_v1=0, sample_size_v2=0, ppl=2.29, wps=890.3, ups=0.35, wpb=2528.3, bsz=96, num_updates=5120, lr=8.35583e-06, gnorm=2.433, clip=100, loss_scale=128, train_wall=28, gb_free=12.6, wall=22585
2023-04-08 22:19:43 - progress_bar.py[line:272] - INFO: epoch 009:    515 / 578 loss=2.405, loss_v1=0, loss_v2=0, nll_loss=1.211, ntokens=2584.9, nsentences=96, sample_size=2584.9, sample_size_v1=0, sample_size_v2=0, ppl=2.31, wps=909.2, ups=0.35, wpb=2584.9, bsz=96, num_updates=5130, lr=8.30982e-06, gnorm=2.303, clip=100, loss_scale=128, train_wall=28, gb_free=11.8, wall=22613
2023-04-08 22:20:12 - progress_bar.py[line:272] - INFO: epoch 009:    525 / 578 loss=2.4, loss_v1=0, loss_v2=0, nll_loss=1.203, ntokens=2652.2, nsentences=96, sample_size=2652.2, sample_size_v1=0, sample_size_v2=0, ppl=2.3, wps=933.7, ups=0.35, wpb=2652.2, bsz=96, num_updates=5140, lr=8.2638e-06, gnorm=2.381, clip=100, loss_scale=128, train_wall=28, gb_free=12.5, wall=22641
2023-04-08 22:20:40 - progress_bar.py[line:272] - INFO: epoch 009:    535 / 578 loss=2.396, loss_v1=0, loss_v2=0, nll_loss=1.2, ntokens=2535, nsentences=96, sample_size=2535, sample_size_v1=0, sample_size_v2=0, ppl=2.3, wps=896.8, ups=0.35, wpb=2535, bsz=96, num_updates=5150, lr=8.21779e-06, gnorm=2.385, clip=100, loss_scale=128, train_wall=28, gb_free=12.5, wall=22670
2023-04-08 22:21:08 - progress_bar.py[line:272] - INFO: epoch 009:    545 / 578 loss=2.403, loss_v1=0, loss_v2=0, nll_loss=1.208, ntokens=2517.6, nsentences=96, sample_size=2517.6, sample_size_v1=0, sample_size_v2=0, ppl=2.31, wps=886.5, ups=0.35, wpb=2517.6, bsz=96, num_updates=5160, lr=8.17178e-06, gnorm=2.551, clip=100, loss_scale=128, train_wall=28, gb_free=12.5, wall=22698
2023-04-08 22:21:37 - progress_bar.py[line:272] - INFO: epoch 009:    555 / 578 loss=2.39, loss_v1=0, loss_v2=0, nll_loss=1.19, ntokens=2651.1, nsentences=96, sample_size=2651.1, sample_size_v1=0, sample_size_v2=0, ppl=2.28, wps=923.9, ups=0.35, wpb=2651.1, bsz=96, num_updates=5170, lr=8.12577e-06, gnorm=2.228, clip=100, loss_scale=128, train_wall=29, gb_free=12.7, wall=22727
2023-04-08 22:22:06 - progress_bar.py[line:272] - INFO: epoch 009:    565 / 578 loss=2.387, loss_v1=0, loss_v2=0, nll_loss=1.191, ntokens=2626.8, nsentences=96, sample_size=2626.8, sample_size_v1=0, sample_size_v2=0, ppl=2.28, wps=921.9, ups=0.35, wpb=2626.8, bsz=96, num_updates=5180, lr=8.07975e-06, gnorm=2.361, clip=100, loss_scale=128, train_wall=28, gb_free=11.8, wall=22755
2023-04-08 22:22:34 - progress_bar.py[line:272] - INFO: epoch 009:    575 / 578 loss=2.406, loss_v1=0, loss_v2=0, nll_loss=1.21, ntokens=2565, nsentences=96, sample_size=2565, sample_size_v1=0, sample_size_v2=0, ppl=2.31, wps=901.1, ups=0.35, wpb=2565, bsz=96, num_updates=5190, lr=8.03374e-06, gnorm=2.591, clip=100, loss_scale=128, train_wall=28, gb_free=12.1, wall=22784
2023-04-08 22:22:40 - train.py[line:332] - INFO: end of epoch 9 (average epoch stats below)
local datafile ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 1 begin to initialize row_count and line_idx-to-offset mapping
2023-04-08 22:22:40 - progress_bar.py[line:282] - INFO: epoch 009 | loss 2.417 | loss_v1 0 | loss_v2 0 | nll_loss 1.223 | ntokens 2519.63 | nsentences 95.847 | sample_size 2519.63 | sample_size_v1 0 | sample_size_v2 0 | ppl 2.33 | wps 881.9 | ups 0.35 | wpb 2519.6 | bsz 95.8 | num_updates 5193 | lr 8.01994e-06 | gnorm 2.266 | clip 100 | loss_scale 128 | train_wall 1644 | gb_free 13.1 | wall 22790
2023-04-08 22:22:40 - trainer.py[line:639] - INFO: loading train data for epoch 10
local datafile ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 0 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 1 finished initializing row_count and line_idx-to-offset mapping
file ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 1 row count 27700 total row count 55400
local datafile ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 0 finished initializing row_count and line_idx-to-offset mapping
file ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 0 row count 27700 total row count 55400
slice_id 1 seek offset 27700
slice_id 0 seek offset 0
2023-04-08 22:22:42 - trainer.py[line:703] - INFO: begin training epoch 10
2023-04-08 22:22:42 - train.py[line:305] - INFO: Start iterating over samples
2023-04-08 22:23:03 - progress_bar.py[line:272] - INFO: epoch 010:      7 / 578 loss=2.41, loss_v1=0, loss_v2=0, nll_loss=1.214, ntokens=2346.5, nsentences=87.6, sample_size=2346.5, sample_size_v1=0, sample_size_v2=0, ppl=2.32, wps=818, ups=0.35, wpb=2346.5, bsz=87.6, num_updates=5200, lr=7.98773e-06, gnorm=2.733, clip=100, loss_scale=128, train_wall=26, gb_free=11.8, wall=22812
2023-04-08 22:23:31 - progress_bar.py[line:272] - INFO: epoch 010:     17 / 578 loss=2.395, loss_v1=0, loss_v2=0, nll_loss=1.198, ntokens=2324.3, nsentences=96, sample_size=2324.3, sample_size_v1=0, sample_size_v2=0, ppl=2.29, wps=814.2, ups=0.35, wpb=2324.3, bsz=96, num_updates=5210, lr=7.94172e-06, gnorm=2.581, clip=100, loss_scale=128, train_wall=29, gb_free=12.3, wall=22841
2023-04-08 22:24:00 - progress_bar.py[line:272] - INFO: epoch 010:     27 / 578 loss=2.371, loss_v1=0, loss_v2=0, nll_loss=1.171, ntokens=2386.2, nsentences=96, sample_size=2386.2, sample_size_v1=0, sample_size_v2=0, ppl=2.25, wps=827.3, ups=0.35, wpb=2386.2, bsz=96, num_updates=5220, lr=7.89571e-06, gnorm=2.592, clip=100, loss_scale=128, train_wall=29, gb_free=12.3, wall=22870
2023-04-08 22:24:29 - progress_bar.py[line:272] - INFO: epoch 010:     37 / 578 loss=2.4, loss_v1=0, loss_v2=0, nll_loss=1.205, ntokens=2186.6, nsentences=96, sample_size=2186.6, sample_size_v1=0, sample_size_v2=0, ppl=2.31, wps=759.9, ups=0.35, wpb=2186.6, bsz=96, num_updates=5230, lr=7.84969e-06, gnorm=2.761, clip=100, loss_scale=128, train_wall=29, gb_free=12.3, wall=22899
2023-04-08 22:24:58 - progress_bar.py[line:272] - INFO: epoch 010:     47 / 578 loss=2.361, loss_v1=0, loss_v2=0, nll_loss=1.159, ntokens=2345, nsentences=96, sample_size=2345, sample_size_v1=0, sample_size_v2=0, ppl=2.23, wps=805.2, ups=0.34, wpb=2345, bsz=96, num_updates=5240, lr=7.80368e-06, gnorm=2.691, clip=100, loss_scale=128, train_wall=29, gb_free=11.7, wall=22928
2023-04-08 22:25:27 - progress_bar.py[line:272] - INFO: epoch 010:     57 / 578 loss=2.409, loss_v1=0, loss_v2=0, nll_loss=1.213, ntokens=2295.9, nsentences=96, sample_size=2295.9, sample_size_v1=0, sample_size_v2=0, ppl=2.32, wps=793.5, ups=0.35, wpb=2295.9, bsz=96, num_updates=5250, lr=7.75767e-06, gnorm=2.893, clip=100, loss_scale=128, train_wall=29, gb_free=12.3, wall=22957
2023-04-08 22:25:56 - progress_bar.py[line:272] - INFO: epoch 010:     67 / 578 loss=2.418, loss_v1=0, loss_v2=0, nll_loss=1.224, ntokens=2295.2, nsentences=96, sample_size=2295.2, sample_size_v1=0, sample_size_v2=0, ppl=2.34, wps=804.2, ups=0.35, wpb=2295.2, bsz=96, num_updates=5260, lr=7.71166e-06, gnorm=2.949, clip=100, loss_scale=128, train_wall=29, gb_free=12.3, wall=22985
2023-04-08 22:26:24 - progress_bar.py[line:272] - INFO: epoch 010:     77 / 578 loss=2.42, loss_v1=0, loss_v2=0, nll_loss=1.229, ntokens=2464.8, nsentences=96, sample_size=2464.8, sample_size_v1=0, sample_size_v2=0, ppl=2.34, wps=860.6, ups=0.35, wpb=2464.8, bsz=96, num_updates=5270, lr=7.66564e-06, gnorm=2.999, clip=100, loss_scale=128, train_wall=29, gb_free=11.8, wall=23014
2023-04-08 22:26:53 - progress_bar.py[line:272] - INFO: epoch 010:     87 / 578 loss=2.426, loss_v1=0, loss_v2=0, nll_loss=1.232, ntokens=2542.1, nsentences=96, sample_size=2542.1, sample_size_v1=0, sample_size_v2=0, ppl=2.35, wps=876.3, ups=0.34, wpb=2542.1, bsz=96, num_updates=5280, lr=7.61963e-06, gnorm=2.727, clip=100, loss_scale=128, train_wall=29, gb_free=11.7, wall=23043
2023-04-08 22:27:22 - progress_bar.py[line:272] - INFO: epoch 010:     97 / 578 loss=2.417, loss_v1=0, loss_v2=0, nll_loss=1.22, ntokens=2420.1, nsentences=96, sample_size=2420.1, sample_size_v1=0, sample_size_v2=0, ppl=2.33, wps=835.4, ups=0.35, wpb=2420.1, bsz=96, num_updates=5290, lr=7.57362e-06, gnorm=2.744, clip=100, loss_scale=128, train_wall=29, gb_free=12.1, wall=23072
2023-04-08 22:27:51 - progress_bar.py[line:272] - INFO: epoch 010:    107 / 578 loss=2.41, loss_v1=0, loss_v2=0, nll_loss=1.216, ntokens=2457, nsentences=96, sample_size=2457, sample_size_v1=0, sample_size_v2=0, ppl=2.32, wps=849.2, ups=0.35, wpb=2457, bsz=96, num_updates=5300, lr=7.52761e-06, gnorm=2.584, clip=100, loss_scale=128, train_wall=29, gb_free=12.3, wall=23101
2023-04-08 22:28:20 - progress_bar.py[line:272] - INFO: epoch 010:    117 / 578 loss=2.418, loss_v1=0, loss_v2=0, nll_loss=1.224, ntokens=2339.6, nsentences=96, sample_size=2339.6, sample_size_v1=0, sample_size_v2=0, ppl=2.34, wps=814.2, ups=0.35, wpb=2339.6, bsz=96, num_updates=5310, lr=7.4816e-06, gnorm=2.816, clip=100, loss_scale=128, train_wall=29, gb_free=12, wall=23130
2023-04-08 22:28:49 - progress_bar.py[line:272] - INFO: epoch 010:    127 / 578 loss=2.421, loss_v1=0, loss_v2=0, nll_loss=1.227, ntokens=2395.8, nsentences=96, sample_size=2395.8, sample_size_v1=0, sample_size_v2=0, ppl=2.34, wps=830.4, ups=0.35, wpb=2395.8, bsz=96, num_updates=5320, lr=7.43558e-06, gnorm=2.964, clip=100, loss_scale=128, train_wall=29, gb_free=12.1, wall=23158
2023-04-08 22:29:17 - progress_bar.py[line:272] - INFO: epoch 010:    137 / 578 loss=2.424, loss_v1=0, loss_v2=0, nll_loss=1.231, ntokens=2397.1, nsentences=96, sample_size=2397.1, sample_size_v1=0, sample_size_v2=0, ppl=2.35, wps=838.9, ups=0.35, wpb=2397.1, bsz=96, num_updates=5330, lr=7.38957e-06, gnorm=2.689, clip=100, loss_scale=128, train_wall=29, gb_free=12.7, wall=23187
2023-04-08 22:29:46 - progress_bar.py[line:272] - INFO: epoch 010:    147 / 578 loss=2.422, loss_v1=0, loss_v2=0, nll_loss=1.228, ntokens=2619.7, nsentences=96, sample_size=2619.7, sample_size_v1=0, sample_size_v2=0, ppl=2.34, wps=912.2, ups=0.35, wpb=2619.7, bsz=96, num_updates=5340, lr=7.34356e-06, gnorm=2.538, clip=100, loss_scale=128, train_wall=29, gb_free=12.5, wall=23216
2023-04-08 22:30:14 - progress_bar.py[line:272] - INFO: epoch 010:    157 / 578 loss=2.42, loss_v1=0, loss_v2=0, nll_loss=1.226, ntokens=2648.4, nsentences=96, sample_size=2648.4, sample_size_v1=0, sample_size_v2=0, ppl=2.34, wps=930.5, ups=0.35, wpb=2648.4, bsz=96, num_updates=5350, lr=7.29755e-06, gnorm=2.484, clip=100, loss_scale=128, train_wall=28, gb_free=12.3, wall=23244
2023-04-08 22:30:43 - progress_bar.py[line:272] - INFO: epoch 010:    167 / 578 loss=2.419, loss_v1=0, loss_v2=0, nll_loss=1.225, ntokens=2658.3, nsentences=96, sample_size=2658.3, sample_size_v1=0, sample_size_v2=0, ppl=2.34, wps=931.3, ups=0.35, wpb=2658.3, bsz=96, num_updates=5360, lr=7.25153e-06, gnorm=2.565, clip=100, loss_scale=128, train_wall=29, gb_free=12.3, wall=23273
2023-04-08 22:31:11 - progress_bar.py[line:272] - INFO: epoch 010:    177 / 578 loss=2.429, loss_v1=0, loss_v2=0, nll_loss=1.235, ntokens=2593.8, nsentences=96, sample_size=2593.8, sample_size_v1=0, sample_size_v2=0, ppl=2.35, wps=911, ups=0.35, wpb=2593.8, bsz=96, num_updates=5370, lr=7.20552e-06, gnorm=2.519, clip=100, loss_scale=128, train_wall=28, gb_free=12, wall=23301
2023-04-08 22:31:40 - progress_bar.py[line:272] - INFO: epoch 010:    187 / 578 loss=2.422, loss_v1=0, loss_v2=0, nll_loss=1.228, ntokens=2675.1, nsentences=96, sample_size=2675.1, sample_size_v1=0, sample_size_v2=0, ppl=2.34, wps=933.6, ups=0.35, wpb=2675.1, bsz=96, num_updates=5380, lr=7.15951e-06, gnorm=2.448, clip=100, loss_scale=128, train_wall=29, gb_free=12.1, wall=23330
2023-04-08 22:32:09 - progress_bar.py[line:272] - INFO: epoch 010:    197 / 578 loss=2.41, loss_v1=0, loss_v2=0, nll_loss=1.215, ntokens=2609.2, nsentences=96, sample_size=2609.2, sample_size_v1=0, sample_size_v2=0, ppl=2.32, wps=911.3, ups=0.35, wpb=2609.2, bsz=96, num_updates=5390, lr=7.1135e-06, gnorm=2.514, clip=100, loss_scale=128, train_wall=29, gb_free=12.4, wall=23358
2023-04-08 22:32:37 - progress_bar.py[line:272] - INFO: epoch 010:    207 / 578 loss=2.409, loss_v1=0, loss_v2=0, nll_loss=1.215, ntokens=2567.2, nsentences=96, sample_size=2567.2, sample_size_v1=0, sample_size_v2=0, ppl=2.32, wps=904.8, ups=0.35, wpb=2567.2, bsz=96, num_updates=5400, lr=7.06748e-06, gnorm=2.587, clip=100, loss_scale=128, train_wall=28, gb_free=12.2, wall=23387
2023-04-08 22:33:06 - progress_bar.py[line:272] - INFO: epoch 010:    217 / 578 loss=2.435, loss_v1=0, loss_v2=0, nll_loss=1.244, ntokens=2474.3, nsentences=96, sample_size=2474.3, sample_size_v1=0, sample_size_v2=0, ppl=2.37, wps=872.3, ups=0.35, wpb=2474.3, bsz=96, num_updates=5410, lr=7.02147e-06, gnorm=2.974, clip=100, loss_scale=128, train_wall=28, gb_free=12.5, wall=23415
2023-04-08 22:33:31 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 128.0
2023-04-08 22:33:37 - progress_bar.py[line:272] - INFO: epoch 010:    228 / 578 loss=2.399, loss_v1=0, loss_v2=0, nll_loss=1.202, ntokens=2557, nsentences=96, sample_size=2557, sample_size_v1=0, sample_size_v2=0, ppl=2.3, wps=820.3, ups=0.32, wpb=2557, bsz=96, num_updates=5420, lr=6.97546e-06, gnorm=2.774, clip=100, loss_scale=128, train_wall=31, gb_free=12.6, wall=23446
2023-04-08 22:34:05 - progress_bar.py[line:272] - INFO: epoch 010:    238 / 578 loss=2.42, loss_v1=0, loss_v2=0, nll_loss=1.227, ntokens=2453.8, nsentences=96, sample_size=2453.8, sample_size_v1=0, sample_size_v2=0, ppl=2.34, wps=867.9, ups=0.35, wpb=2453.8, bsz=96, num_updates=5430, lr=6.92945e-06, gnorm=2.811, clip=100, loss_scale=128, train_wall=28, gb_free=12.5, wall=23475
2023-04-08 22:34:33 - progress_bar.py[line:272] - INFO: epoch 010:    248 / 578 loss=2.42, loss_v1=0, loss_v2=0, nll_loss=1.226, ntokens=2499.3, nsentences=96, sample_size=2499.3, sample_size_v1=0, sample_size_v2=0, ppl=2.34, wps=884.8, ups=0.35, wpb=2499.3, bsz=96, num_updates=5440, lr=6.88344e-06, gnorm=2.692, clip=100, loss_scale=128, train_wall=28, gb_free=12.5, wall=23503
2023-04-08 22:35:02 - progress_bar.py[line:272] - INFO: epoch 010:    258 / 578 loss=2.411, loss_v1=0, loss_v2=0, nll_loss=1.215, ntokens=2593.4, nsentences=96, sample_size=2593.4, sample_size_v1=0, sample_size_v2=0, ppl=2.32, wps=916, ups=0.35, wpb=2593.4, bsz=96, num_updates=5450, lr=6.83742e-06, gnorm=2.538, clip=100, loss_scale=128, train_wall=28, gb_free=12.5, wall=23531
2023-04-08 22:35:13 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2023-04-08 22:35:33 - progress_bar.py[line:272] - INFO: epoch 010:    269 / 578 loss=2.412, loss_v1=0, loss_v2=0, nll_loss=1.218, ntokens=2522.1, nsentences=96, sample_size=2522.1, sample_size_v1=0, sample_size_v2=0, ppl=2.33, wps=809, ups=0.32, wpb=2522.1, bsz=96, num_updates=5460, lr=6.79141e-06, gnorm=2.733, clip=100, loss_scale=64, train_wall=31, gb_free=12.4, wall=23562
2023-04-08 22:36:01 - progress_bar.py[line:272] - INFO: epoch 010:    279 / 578 loss=2.405, loss_v1=0, loss_v2=0, nll_loss=1.21, ntokens=2570.6, nsentences=96, sample_size=2570.6, sample_size_v1=0, sample_size_v2=0, ppl=2.31, wps=904.8, ups=0.35, wpb=2570.6, bsz=96, num_updates=5470, lr=6.7454e-06, gnorm=2.61, clip=100, loss_scale=64, train_wall=28, gb_free=12.1, wall=23591
2023-04-08 22:36:30 - progress_bar.py[line:272] - INFO: epoch 010:    289 / 578 loss=2.393, loss_v1=0, loss_v2=0, nll_loss=1.194, ntokens=2581.6, nsentences=96, sample_size=2581.6, sample_size_v1=0, sample_size_v2=0, ppl=2.29, wps=908.7, ups=0.35, wpb=2581.6, bsz=96, num_updates=5480, lr=6.69939e-06, gnorm=2.753, clip=100, loss_scale=64, train_wall=28, gb_free=12.6, wall=23619
2023-04-08 22:36:58 - progress_bar.py[line:272] - INFO: epoch 010:    299 / 578 loss=2.433, loss_v1=0, loss_v2=0, nll_loss=1.241, ntokens=2553.7, nsentences=96, sample_size=2553.7, sample_size_v1=0, sample_size_v2=0, ppl=2.36, wps=898.4, ups=0.35, wpb=2553.7, bsz=96, num_updates=5490, lr=6.65337e-06, gnorm=2.626, clip=100, loss_scale=64, train_wall=28, gb_free=12.4, wall=23648
2023-04-08 22:37:26 - progress_bar.py[line:272] - INFO: epoch 010:    309 / 578 loss=2.412, loss_v1=0, loss_v2=0, nll_loss=1.219, ntokens=2584, nsentences=96, sample_size=2584, sample_size_v1=0, sample_size_v2=0, ppl=2.33, wps=908.2, ups=0.35, wpb=2584, bsz=96, num_updates=5500, lr=6.60736e-06, gnorm=2.692, clip=100, loss_scale=64, train_wall=28, gb_free=12.3, wall=23676
2023-04-08 22:37:55 - progress_bar.py[line:272] - INFO: epoch 010:    319 / 578 loss=2.427, loss_v1=0, loss_v2=0, nll_loss=1.232, ntokens=2673.7, nsentences=96, sample_size=2673.7, sample_size_v1=0, sample_size_v2=0, ppl=2.35, wps=939.9, ups=0.35, wpb=2673.7, bsz=96, num_updates=5510, lr=6.56135e-06, gnorm=2.501, clip=100, loss_scale=64, train_wall=28, gb_free=12.5, wall=23705
2023-04-08 22:38:23 - progress_bar.py[line:272] - INFO: epoch 010:    329 / 578 loss=2.391, loss_v1=0, loss_v2=0, nll_loss=1.193, ntokens=2523.8, nsentences=96, sample_size=2523.8, sample_size_v1=0, sample_size_v2=0, ppl=2.29, wps=889.6, ups=0.35, wpb=2523.8, bsz=96, num_updates=5520, lr=6.51534e-06, gnorm=2.644, clip=100, loss_scale=64, train_wall=28, gb_free=12.3, wall=23733
2023-04-08 22:38:52 - progress_bar.py[line:272] - INFO: epoch 010:    339 / 578 loss=2.415, loss_v1=0, loss_v2=0, nll_loss=1.221, ntokens=2619, nsentences=96, sample_size=2619, sample_size_v1=0, sample_size_v2=0, ppl=2.33, wps=926.3, ups=0.35, wpb=2619, bsz=96, num_updates=5530, lr=6.46933e-06, gnorm=2.61, clip=100, loss_scale=64, train_wall=28, gb_free=12.4, wall=23761
2023-04-08 22:39:20 - progress_bar.py[line:272] - INFO: epoch 010:    349 / 578 loss=2.403, loss_v1=0, loss_v2=0, nll_loss=1.206, ntokens=2686.2, nsentences=96, sample_size=2686.2, sample_size_v1=0, sample_size_v2=0, ppl=2.31, wps=949.7, ups=0.35, wpb=2686.2, bsz=96, num_updates=5540, lr=6.42331e-06, gnorm=2.524, clip=100, loss_scale=64, train_wall=28, gb_free=12.6, wall=23789
2023-04-08 22:39:48 - progress_bar.py[line:272] - INFO: epoch 010:    359 / 578 loss=2.389, loss_v1=0, loss_v2=0, nll_loss=1.192, ntokens=2619.4, nsentences=96, sample_size=2619.4, sample_size_v1=0, sample_size_v2=0, ppl=2.28, wps=925.5, ups=0.35, wpb=2619.4, bsz=96, num_updates=5550, lr=6.3773e-06, gnorm=2.549, clip=100, loss_scale=64, train_wall=28, gb_free=12.2, wall=23818
2023-04-08 22:40:17 - progress_bar.py[line:272] - INFO: epoch 010:    369 / 578 loss=2.431, loss_v1=0, loss_v2=0, nll_loss=1.239, ntokens=2799.5, nsentences=96, sample_size=2799.5, sample_size_v1=0, sample_size_v2=0, ppl=2.36, wps=981.4, ups=0.35, wpb=2799.5, bsz=96, num_updates=5560, lr=6.33129e-06, gnorm=2.507, clip=100, loss_scale=64, train_wall=28, gb_free=12.6, wall=23846
2023-04-08 22:40:45 - progress_bar.py[line:272] - INFO: epoch 010:    379 / 578 loss=2.42, loss_v1=0, loss_v2=0, nll_loss=1.227, ntokens=2752.3, nsentences=96, sample_size=2752.3, sample_size_v1=0, sample_size_v2=0, ppl=2.34, wps=966.5, ups=0.35, wpb=2752.3, bsz=96, num_updates=5570, lr=6.28528e-06, gnorm=2.321, clip=100, loss_scale=64, train_wall=28, gb_free=12.3, wall=23875
2023-04-08 22:41:14 - progress_bar.py[line:272] - INFO: epoch 010:    389 / 578 loss=2.422, loss_v1=0, loss_v2=0, nll_loss=1.227, ntokens=2574.2, nsentences=96, sample_size=2574.2, sample_size_v1=0, sample_size_v2=0, ppl=2.34, wps=905.3, ups=0.35, wpb=2574.2, bsz=96, num_updates=5580, lr=6.23926e-06, gnorm=2.424, clip=100, loss_scale=64, train_wall=28, gb_free=12.6, wall=23903
2023-04-08 22:41:42 - progress_bar.py[line:272] - INFO: epoch 010:    399 / 578 loss=2.402, loss_v1=0, loss_v2=0, nll_loss=1.205, ntokens=2554, nsentences=96, sample_size=2554, sample_size_v1=0, sample_size_v2=0, ppl=2.3, wps=895.1, ups=0.35, wpb=2554, bsz=96, num_updates=5590, lr=6.19325e-06, gnorm=2.351, clip=100, loss_scale=64, train_wall=29, gb_free=12.7, wall=23932
2023-04-08 22:42:10 - progress_bar.py[line:272] - INFO: epoch 010:    409 / 578 loss=2.412, loss_v1=0, loss_v2=0, nll_loss=1.219, ntokens=2443.2, nsentences=96, sample_size=2443.2, sample_size_v1=0, sample_size_v2=0, ppl=2.33, wps=862.2, ups=0.35, wpb=2443.2, bsz=96, num_updates=5600, lr=6.14724e-06, gnorm=2.68, clip=100, loss_scale=64, train_wall=28, gb_free=12.5, wall=23960
2023-04-08 22:42:39 - progress_bar.py[line:272] - INFO: epoch 010:    419 / 578 loss=2.414, loss_v1=0, loss_v2=0, nll_loss=1.22, ntokens=2469.6, nsentences=96, sample_size=2469.6, sample_size_v1=0, sample_size_v2=0, ppl=2.33, wps=872.2, ups=0.35, wpb=2469.6, bsz=96, num_updates=5610, lr=6.10123e-06, gnorm=2.627, clip=100, loss_scale=64, train_wall=28, gb_free=12.6, wall=23988
2023-04-08 22:43:07 - progress_bar.py[line:272] - INFO: epoch 010:    429 / 578 loss=2.398, loss_v1=0, loss_v2=0, nll_loss=1.202, ntokens=2556.6, nsentences=96, sample_size=2556.6, sample_size_v1=0, sample_size_v2=0, ppl=2.3, wps=903.7, ups=0.35, wpb=2556.6, bsz=96, num_updates=5620, lr=6.05521e-06, gnorm=2.435, clip=100, loss_scale=64, train_wall=28, gb_free=12.5, wall=24017
2023-04-08 22:43:35 - progress_bar.py[line:272] - INFO: epoch 010:    439 / 578 loss=2.421, loss_v1=0, loss_v2=0, nll_loss=1.226, ntokens=2454.1, nsentences=96, sample_size=2454.1, sample_size_v1=0, sample_size_v2=0, ppl=2.34, wps=873.4, ups=0.36, wpb=2454.1, bsz=96, num_updates=5630, lr=6.0092e-06, gnorm=2.456, clip=100, loss_scale=64, train_wall=28, gb_free=12.6, wall=24045
2023-04-08 22:44:03 - progress_bar.py[line:272] - INFO: epoch 010:    449 / 578 loss=2.425, loss_v1=0, loss_v2=0, nll_loss=1.231, ntokens=2501.2, nsentences=96, sample_size=2501.2, sample_size_v1=0, sample_size_v2=0, ppl=2.35, wps=883.9, ups=0.35, wpb=2501.2, bsz=96, num_updates=5640, lr=5.96319e-06, gnorm=2.46, clip=100, loss_scale=64, train_wall=28, gb_free=12.6, wall=24073
2023-04-08 22:44:32 - progress_bar.py[line:272] - INFO: epoch 010:    459 / 578 loss=2.407, loss_v1=0, loss_v2=0, nll_loss=1.211, ntokens=2476.9, nsentences=96, sample_size=2476.9, sample_size_v1=0, sample_size_v2=0, ppl=2.32, wps=877, ups=0.35, wpb=2476.9, bsz=96, num_updates=5650, lr=5.91718e-06, gnorm=2.547, clip=100, loss_scale=64, train_wall=28, gb_free=12.4, wall=24101
2023-04-08 22:45:00 - progress_bar.py[line:272] - INFO: epoch 010:    469 / 578 loss=2.422, loss_v1=0, loss_v2=0, nll_loss=1.228, ntokens=2530.7, nsentences=96, sample_size=2530.7, sample_size_v1=0, sample_size_v2=0, ppl=2.34, wps=890.1, ups=0.35, wpb=2530.7, bsz=96, num_updates=5660, lr=5.87117e-06, gnorm=2.414, clip=100, loss_scale=64, train_wall=28, gb_free=12.3, wall=24130
2023-04-08 22:45:28 - progress_bar.py[line:272] - INFO: epoch 010:    479 / 578 loss=2.43, loss_v1=0, loss_v2=0, nll_loss=1.237, ntokens=2347.9, nsentences=96, sample_size=2347.9, sample_size_v1=0, sample_size_v2=0, ppl=2.36, wps=830.9, ups=0.35, wpb=2347.9, bsz=96, num_updates=5670, lr=5.82515e-06, gnorm=2.636, clip=100, loss_scale=64, train_wall=28, gb_free=12.7, wall=24158
2023-04-08 22:45:57 - progress_bar.py[line:272] - INFO: epoch 010:    489 / 578 loss=2.402, loss_v1=0, loss_v2=0, nll_loss=1.206, ntokens=2438.6, nsentences=96, sample_size=2438.6, sample_size_v1=0, sample_size_v2=0, ppl=2.31, wps=862.6, ups=0.35, wpb=2438.6, bsz=96, num_updates=5680, lr=5.77914e-06, gnorm=2.527, clip=100, loss_scale=64, train_wall=28, gb_free=12.2, wall=24186
2023-04-08 22:46:25 - progress_bar.py[line:272] - INFO: epoch 010:    499 / 578 loss=2.392, loss_v1=0, loss_v2=0, nll_loss=1.195, ntokens=2585.4, nsentences=96, sample_size=2585.4, sample_size_v1=0, sample_size_v2=0, ppl=2.29, wps=909.9, ups=0.35, wpb=2585.4, bsz=96, num_updates=5690, lr=5.73313e-06, gnorm=2.35, clip=100, loss_scale=64, train_wall=28, gb_free=12.5, wall=24215
2023-04-08 22:46:54 - progress_bar.py[line:272] - INFO: epoch 010:    509 / 578 loss=2.405, loss_v1=0, loss_v2=0, nll_loss=1.21, ntokens=2554.2, nsentences=96, sample_size=2554.2, sample_size_v1=0, sample_size_v2=0, ppl=2.31, wps=899.6, ups=0.35, wpb=2554.2, bsz=96, num_updates=5700, lr=5.68712e-06, gnorm=2.349, clip=100, loss_scale=64, train_wall=28, gb_free=12.5, wall=24243
2023-04-08 22:47:22 - progress_bar.py[line:272] - INFO: epoch 010:    519 / 578 loss=2.39, loss_v1=0, loss_v2=0, nll_loss=1.194, ntokens=2674.6, nsentences=96, sample_size=2674.6, sample_size_v1=0, sample_size_v2=0, ppl=2.29, wps=939.6, ups=0.35, wpb=2674.6, bsz=96, num_updates=5710, lr=5.6411e-06, gnorm=2.429, clip=100, loss_scale=64, train_wall=28, gb_free=12.7, wall=24272
2023-04-08 22:47:50 - progress_bar.py[line:272] - INFO: epoch 010:    529 / 578 loss=2.408, loss_v1=0, loss_v2=0, nll_loss=1.212, ntokens=2571.1, nsentences=96, sample_size=2571.1, sample_size_v1=0, sample_size_v2=0, ppl=2.32, wps=908.7, ups=0.35, wpb=2571.1, bsz=96, num_updates=5720, lr=5.59509e-06, gnorm=2.601, clip=100, loss_scale=64, train_wall=28, gb_free=12.5, wall=24300
2023-04-08 22:48:18 - progress_bar.py[line:272] - INFO: epoch 010:    539 / 578 loss=2.391, loss_v1=0, loss_v2=0, nll_loss=1.194, ntokens=2480.6, nsentences=96, sample_size=2480.6, sample_size_v1=0, sample_size_v2=0, ppl=2.29, wps=880.6, ups=0.36, wpb=2480.6, bsz=96, num_updates=5730, lr=5.54908e-06, gnorm=2.547, clip=100, loss_scale=64, train_wall=28, gb_free=12.4, wall=24328
2023-04-08 22:48:47 - progress_bar.py[line:272] - INFO: epoch 010:    549 / 578 loss=2.405, loss_v1=0, loss_v2=0, nll_loss=1.209, ntokens=2551.4, nsentences=96, sample_size=2551.4, sample_size_v1=0, sample_size_v2=0, ppl=2.31, wps=896, ups=0.35, wpb=2551.4, bsz=96, num_updates=5740, lr=5.50307e-06, gnorm=2.513, clip=100, loss_scale=64, train_wall=28, gb_free=12.3, wall=24357
2023-04-08 22:49:15 - progress_bar.py[line:272] - INFO: epoch 010:    559 / 578 loss=2.386, loss_v1=0, loss_v2=0, nll_loss=1.188, ntokens=2597.7, nsentences=96, sample_size=2597.7, sample_size_v1=0, sample_size_v2=0, ppl=2.28, wps=911, ups=0.35, wpb=2597.7, bsz=96, num_updates=5750, lr=5.45706e-06, gnorm=2.249, clip=100, loss_scale=64, train_wall=28, gb_free=12.5, wall=24385
2023-04-08 22:49:44 - progress_bar.py[line:272] - INFO: epoch 010:    569 / 578 loss=2.39, loss_v1=0, loss_v2=0, nll_loss=1.192, ntokens=2700.5, nsentences=96, sample_size=2700.5, sample_size_v1=0, sample_size_v2=0, ppl=2.29, wps=947, ups=0.35, wpb=2700.5, bsz=96, num_updates=5760, lr=5.41104e-06, gnorm=2.265, clip=100, loss_scale=64, train_wall=28, gb_free=12.5, wall=24414
2023-04-08 22:50:07 - train.py[line:332] - INFO: end of epoch 10 (average epoch stats below)
local datafile ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 1 begin to initialize row_count and line_idx-to-offset mapping
2023-04-08 22:50:07 - progress_bar.py[line:282] - INFO: epoch 010 | loss 2.41 | loss_v1 0 | loss_v2 0 | nll_loss 1.215 | ntokens 2520.62 | nsentences 95.847 | sample_size 2520.62 | sample_size_v1 0 | sample_size_v2 0 | ppl 2.32 | wps 881.6 | ups 0.35 | wpb 2520.6 | bsz 95.8 | num_updates 5769 | lr 5.36963e-06 | gnorm 2.598 | clip 100 | loss_scale 64 | train_wall 1642 | gb_free 13.1 | wall 24437
2023-04-08 22:50:07 - trainer.py[line:639] - INFO: loading train data for epoch 11
local datafile ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 0 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 1 finished initializing row_count and line_idx-to-offset mapping
file ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 1 row count 27700 total row count 55400
slice_id 1 seek offset 27700
local datafile ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 0 finished initializing row_count and line_idx-to-offset mapping
file ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 0 row count 27700 total row count 55400
slice_id 0 seek offset 0
2023-04-08 22:50:09 - trainer.py[line:703] - INFO: begin training epoch 11
2023-04-08 22:50:09 - train.py[line:305] - INFO: Start iterating over samples
2023-04-08 22:50:12 - progress_bar.py[line:272] - INFO: epoch 011:      1 / 578 loss=2.418, loss_v1=0, loss_v2=0, nll_loss=1.224, ntokens=2358.7, nsentences=87.2, sample_size=2358.7, sample_size_v1=0, sample_size_v2=0, ppl=2.34, wps=833.3, ups=0.35, wpb=2358.7, bsz=87.2, num_updates=5770, lr=5.36503e-06, gnorm=2.785, clip=100, loss_scale=64, train_wall=26, gb_free=12.3, wall=24442
2023-04-08 22:50:41 - progress_bar.py[line:272] - INFO: epoch 011:     11 / 578 loss=2.381, loss_v1=0, loss_v2=0, nll_loss=1.182, ntokens=2417.4, nsentences=96, sample_size=2417.4, sample_size_v1=0, sample_size_v2=0, ppl=2.27, wps=843.6, ups=0.35, wpb=2417.4, bsz=96, num_updates=5780, lr=5.31902e-06, gnorm=2.329, clip=100, loss_scale=64, train_wall=29, gb_free=12.4, wall=24471
2023-04-08 22:51:09 - progress_bar.py[line:272] - INFO: epoch 011:     21 / 578 loss=2.382, loss_v1=0, loss_v2=0, nll_loss=1.184, ntokens=2349.3, nsentences=96, sample_size=2349.3, sample_size_v1=0, sample_size_v2=0, ppl=2.27, wps=822.7, ups=0.35, wpb=2349.3, bsz=96, num_updates=5790, lr=5.27301e-06, gnorm=2.519, clip=100, loss_scale=64, train_wall=29, gb_free=12, wall=24499
2023-04-08 22:51:38 - progress_bar.py[line:272] - INFO: epoch 011:     31 / 578 loss=2.386, loss_v1=0, loss_v2=0, nll_loss=1.189, ntokens=2290.8, nsentences=96, sample_size=2290.8, sample_size_v1=0, sample_size_v2=0, ppl=2.28, wps=798.6, ups=0.35, wpb=2290.8, bsz=96, num_updates=5800, lr=5.22699e-06, gnorm=2.576, clip=100, loss_scale=64, train_wall=29, gb_free=12.3, wall=24528
2023-04-08 22:52:07 - progress_bar.py[line:272] - INFO: epoch 011:     41 / 578 loss=2.364, loss_v1=0, loss_v2=0, nll_loss=1.164, ntokens=2192.1, nsentences=96, sample_size=2192.1, sample_size_v1=0, sample_size_v2=0, ppl=2.24, wps=764.7, ups=0.35, wpb=2192.1, bsz=96, num_updates=5810, lr=5.18098e-06, gnorm=2.796, clip=100, loss_scale=64, train_wall=29, gb_free=11.7, wall=24556
2023-04-08 22:52:36 - progress_bar.py[line:272] - INFO: epoch 011:     51 / 578 loss=2.362, loss_v1=0, loss_v2=0, nll_loss=1.161, ntokens=2406.9, nsentences=96, sample_size=2406.9, sample_size_v1=0, sample_size_v2=0, ppl=2.24, wps=822.4, ups=0.34, wpb=2406.9, bsz=96, num_updates=5820, lr=5.13497e-06, gnorm=2.851, clip=100, loss_scale=64, train_wall=29, gb_free=11.7, wall=24586
2023-04-08 22:53:05 - progress_bar.py[line:272] - INFO: epoch 011:     61 / 578 loss=2.419, loss_v1=0, loss_v2=0, nll_loss=1.224, ntokens=2280.2, nsentences=96, sample_size=2280.2, sample_size_v1=0, sample_size_v2=0, ppl=2.34, wps=789.5, ups=0.35, wpb=2280.2, bsz=96, num_updates=5830, lr=5.08896e-06, gnorm=2.803, clip=100, loss_scale=64, train_wall=29, gb_free=12.5, wall=24615
2023-04-08 22:53:34 - progress_bar.py[line:272] - INFO: epoch 011:     71 / 578 loss=2.407, loss_v1=0, loss_v2=0, nll_loss=1.211, ntokens=2326.2, nsentences=96, sample_size=2326.2, sample_size_v1=0, sample_size_v2=0, ppl=2.32, wps=814.9, ups=0.35, wpb=2326.2, bsz=96, num_updates=5840, lr=5.04294e-06, gnorm=2.821, clip=100, loss_scale=64, train_wall=29, gb_free=11.7, wall=24643
2023-04-08 22:54:02 - progress_bar.py[line:272] - INFO: epoch 011:     81 / 578 loss=2.411, loss_v1=0, loss_v2=0, nll_loss=1.219, ntokens=2534.1, nsentences=96, sample_size=2534.1, sample_size_v1=0, sample_size_v2=0, ppl=2.33, wps=878.6, ups=0.35, wpb=2534.1, bsz=96, num_updates=5850, lr=4.99693e-06, gnorm=2.708, clip=100, loss_scale=64, train_wall=29, gb_free=12.2, wall=24672
2023-04-08 22:54:31 - progress_bar.py[line:272] - INFO: epoch 011:     91 / 578 loss=2.416, loss_v1=0, loss_v2=0, nll_loss=1.221, ntokens=2513.5, nsentences=96, sample_size=2513.5, sample_size_v1=0, sample_size_v2=0, ppl=2.33, wps=866.4, ups=0.34, wpb=2513.5, bsz=96, num_updates=5860, lr=4.95092e-06, gnorm=2.622, clip=100, loss_scale=64, train_wall=29, gb_free=11.9, wall=24701
2023-04-08 22:55:01 - progress_bar.py[line:272] - INFO: epoch 011:    101 / 578 loss=2.403, loss_v1=0, loss_v2=0, nll_loss=1.205, ntokens=2425.9, nsentences=96, sample_size=2425.9, sample_size_v1=0, sample_size_v2=0, ppl=2.31, wps=833.5, ups=0.34, wpb=2425.9, bsz=96, num_updates=5870, lr=4.90491e-06, gnorm=2.615, clip=100, loss_scale=64, train_wall=29, gb_free=11.5, wall=24730
2023-04-08 22:55:29 - progress_bar.py[line:272] - INFO: epoch 011:    111 / 578 loss=2.412, loss_v1=0, loss_v2=0, nll_loss=1.218, ntokens=2427.3, nsentences=96, sample_size=2427.3, sample_size_v1=0, sample_size_v2=0, ppl=2.33, wps=839.2, ups=0.35, wpb=2427.3, bsz=96, num_updates=5880, lr=4.8589e-06, gnorm=2.674, clip=100, loss_scale=64, train_wall=29, gb_free=11.7, wall=24759
2023-04-08 22:55:58 - progress_bar.py[line:272] - INFO: epoch 011:    121 / 578 loss=2.41, loss_v1=0, loss_v2=0, nll_loss=1.216, ntokens=2330.6, nsentences=96, sample_size=2330.6, sample_size_v1=0, sample_size_v2=0, ppl=2.32, wps=812, ups=0.35, wpb=2330.6, bsz=96, num_updates=5890, lr=4.81288e-06, gnorm=2.932, clip=100, loss_scale=64, train_wall=29, gb_free=12.2, wall=24788
2023-04-08 22:56:27 - progress_bar.py[line:272] - INFO: epoch 011:    131 / 578 loss=2.416, loss_v1=0, loss_v2=0, nll_loss=1.22, ntokens=2430.2, nsentences=96, sample_size=2430.2, sample_size_v1=0, sample_size_v2=0, ppl=2.33, wps=842.4, ups=0.35, wpb=2430.2, bsz=96, num_updates=5900, lr=4.76687e-06, gnorm=3.033, clip=100, loss_scale=64, train_wall=29, gb_free=12.3, wall=24817
2023-04-08 22:56:55 - progress_bar.py[line:272] - INFO: epoch 011:    141 / 578 loss=2.416, loss_v1=0, loss_v2=0, nll_loss=1.223, ntokens=2417.5, nsentences=96, sample_size=2417.5, sample_size_v1=0, sample_size_v2=0, ppl=2.33, wps=849.7, ups=0.35, wpb=2417.5, bsz=96, num_updates=5910, lr=4.72086e-06, gnorm=2.824, clip=100, loss_scale=64, train_wall=28, gb_free=12.1, wall=24845
2023-04-08 22:57:24 - progress_bar.py[line:272] - INFO: epoch 011:    151 / 578 loss=2.409, loss_v1=0, loss_v2=0, nll_loss=1.213, ntokens=2646.1, nsentences=96, sample_size=2646.1, sample_size_v1=0, sample_size_v2=0, ppl=2.32, wps=929.1, ups=0.35, wpb=2646.1, bsz=96, num_updates=5920, lr=4.67485e-06, gnorm=2.545, clip=100, loss_scale=64, train_wall=28, gb_free=12.3, wall=24874
2023-04-08 22:57:52 - progress_bar.py[line:272] - INFO: epoch 011:    161 / 578 loss=2.409, loss_v1=0, loss_v2=0, nll_loss=1.213, ntokens=2715.3, nsentences=96, sample_size=2715.3, sample_size_v1=0, sample_size_v2=0, ppl=2.32, wps=954.1, ups=0.35, wpb=2715.3, bsz=96, num_updates=5930, lr=4.62883e-06, gnorm=2.508, clip=100, loss_scale=64, train_wall=28, gb_free=12.2, wall=24902
2023-04-08 22:58:21 - progress_bar.py[line:272] - INFO: epoch 011:    171 / 578 loss=2.419, loss_v1=0, loss_v2=0, nll_loss=1.225, ntokens=2602.4, nsentences=96, sample_size=2602.4, sample_size_v1=0, sample_size_v2=0, ppl=2.34, wps=911.9, ups=0.35, wpb=2602.4, bsz=96, num_updates=5940, lr=4.58282e-06, gnorm=2.679, clip=100, loss_scale=64, train_wall=29, gb_free=12.2, wall=24931
2023-04-08 22:58:49 - progress_bar.py[line:272] - INFO: epoch 011:    181 / 578 loss=2.408, loss_v1=0, loss_v2=0, nll_loss=1.213, ntokens=2620.3, nsentences=96, sample_size=2620.3, sample_size_v1=0, sample_size_v2=0, ppl=2.32, wps=919, ups=0.35, wpb=2620.3, bsz=96, num_updates=5950, lr=4.53681e-06, gnorm=2.663, clip=100, loss_scale=64, train_wall=28, gb_free=12.3, wall=24959
2023-04-08 22:59:18 - progress_bar.py[line:272] - INFO: epoch 011:    191 / 578 loss=2.413, loss_v1=0, loss_v2=0, nll_loss=1.218, ntokens=2655.3, nsentences=96, sample_size=2655.3, sample_size_v1=0, sample_size_v2=0, ppl=2.33, wps=925.1, ups=0.35, wpb=2655.3, bsz=96, num_updates=5960, lr=4.4908e-06, gnorm=2.788, clip=100, loss_scale=64, train_wall=29, gb_free=11.8, wall=24988
2023-04-08 22:59:47 - progress_bar.py[line:272] - INFO: epoch 011:    201 / 578 loss=2.409, loss_v1=0, loss_v2=0, nll_loss=1.214, ntokens=2569.4, nsentences=96, sample_size=2569.4, sample_size_v1=0, sample_size_v2=0, ppl=2.32, wps=904.6, ups=0.35, wpb=2569.4, bsz=96, num_updates=5970, lr=4.44479e-06, gnorm=2.861, clip=100, loss_scale=128, train_wall=28, gb_free=12.5, wall=25016
2023-04-08 23:00:15 - progress_bar.py[line:272] - INFO: epoch 011:    211 / 578 loss=2.404, loss_v1=0, loss_v2=0, nll_loss=1.208, ntokens=2519.7, nsentences=96, sample_size=2519.7, sample_size_v1=0, sample_size_v2=0, ppl=2.31, wps=889.2, ups=0.35, wpb=2519.7, bsz=96, num_updates=5980, lr=4.39877e-06, gnorm=3.002, clip=100, loss_scale=128, train_wall=28, gb_free=12.2, wall=25045
2023-04-08 23:00:32 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2023-04-08 23:00:46 - progress_bar.py[line:272] - INFO: epoch 011:    222 / 578 loss=2.409, loss_v1=0, loss_v2=0, nll_loss=1.214, ntokens=2555.5, nsentences=96, sample_size=2555.5, sample_size_v1=0, sample_size_v2=0, ppl=2.32, wps=819.5, ups=0.32, wpb=2555.5, bsz=96, num_updates=5990, lr=4.35276e-06, gnorm=2.897, clip=100, loss_scale=64, train_wall=31, gb_free=12.7, wall=25076
2023-04-08 23:01:15 - progress_bar.py[line:272] - INFO: epoch 011:    232 / 578 loss=2.389, loss_v1=0, loss_v2=0, nll_loss=1.193, ntokens=2431.9, nsentences=96, sample_size=2431.9, sample_size_v1=0, sample_size_v2=0, ppl=2.29, wps=852.8, ups=0.35, wpb=2431.9, bsz=96, num_updates=6000, lr=4.30675e-06, gnorm=3.088, clip=100, loss_scale=64, train_wall=28, gb_free=12.5, wall=25104
2023-04-08 23:01:43 - progress_bar.py[line:272] - INFO: epoch 011:    242 / 578 loss=2.419, loss_v1=0, loss_v2=0, nll_loss=1.225, ntokens=2512, nsentences=96, sample_size=2512, sample_size_v1=0, sample_size_v2=0, ppl=2.34, wps=886.5, ups=0.35, wpb=2512, bsz=96, num_updates=6010, lr=4.26074e-06, gnorm=2.88, clip=100, loss_scale=64, train_wall=28, gb_free=12.4, wall=25133
2023-04-08 23:02:11 - progress_bar.py[line:272] - INFO: epoch 011:    252 / 578 loss=2.408, loss_v1=0, loss_v2=0, nll_loss=1.212, ntokens=2517.7, nsentences=96, sample_size=2517.7, sample_size_v1=0, sample_size_v2=0, ppl=2.32, wps=890.7, ups=0.35, wpb=2517.7, bsz=96, num_updates=6020, lr=4.21472e-06, gnorm=2.796, clip=100, loss_scale=64, train_wall=28, gb_free=12.5, wall=25161
2023-04-08 23:02:40 - progress_bar.py[line:272] - INFO: epoch 011:    262 / 578 loss=2.4, loss_v1=0, loss_v2=0, nll_loss=1.203, ntokens=2515.9, nsentences=96, sample_size=2515.9, sample_size_v1=0, sample_size_v2=0, ppl=2.3, wps=889.9, ups=0.35, wpb=2515.9, bsz=96, num_updates=6030, lr=4.16871e-06, gnorm=2.802, clip=100, loss_scale=64, train_wall=28, gb_free=12.6, wall=25189
2023-04-08 23:03:08 - progress_bar.py[line:272] - INFO: epoch 011:    272 / 578 loss=2.407, loss_v1=0, loss_v2=0, nll_loss=1.212, ntokens=2591.8, nsentences=96, sample_size=2591.8, sample_size_v1=0, sample_size_v2=0, ppl=2.32, wps=911.6, ups=0.35, wpb=2591.8, bsz=96, num_updates=6040, lr=4.1227e-06, gnorm=2.705, clip=100, loss_scale=64, train_wall=28, gb_free=12.3, wall=25218
2023-04-08 23:03:36 - progress_bar.py[line:272] - INFO: epoch 011:    282 / 578 loss=2.387, loss_v1=0, loss_v2=0, nll_loss=1.19, ntokens=2563, nsentences=96, sample_size=2563, sample_size_v1=0, sample_size_v2=0, ppl=2.28, wps=898.1, ups=0.35, wpb=2563, bsz=96, num_updates=6050, lr=4.07669e-06, gnorm=2.769, clip=100, loss_scale=64, train_wall=29, gb_free=12.3, wall=25246
2023-04-08 23:04:05 - progress_bar.py[line:272] - INFO: epoch 011:    292 / 578 loss=2.4, loss_v1=0, loss_v2=0, nll_loss=1.203, ntokens=2624.4, nsentences=96, sample_size=2624.4, sample_size_v1=0, sample_size_v2=0, ppl=2.3, wps=925.3, ups=0.35, wpb=2624.4, bsz=96, num_updates=6060, lr=4.03067e-06, gnorm=2.902, clip=100, loss_scale=64, train_wall=28, gb_free=12.5, wall=25275
2023-04-08 23:04:33 - progress_bar.py[line:272] - INFO: epoch 011:    302 / 578 loss=2.4, loss_v1=0, loss_v2=0, nll_loss=1.204, ntokens=2475.4, nsentences=96, sample_size=2475.4, sample_size_v1=0, sample_size_v2=0, ppl=2.3, wps=872.5, ups=0.35, wpb=2475.4, bsz=96, num_updates=6070, lr=3.98466e-06, gnorm=2.858, clip=100, loss_scale=64, train_wall=28, gb_free=12.7, wall=25303
2023-04-08 23:05:02 - progress_bar.py[line:272] - INFO: epoch 011:    312 / 578 loss=2.412, loss_v1=0, loss_v2=0, nll_loss=1.219, ntokens=2655.7, nsentences=96, sample_size=2655.7, sample_size_v1=0, sample_size_v2=0, ppl=2.33, wps=931.8, ups=0.35, wpb=2655.7, bsz=96, num_updates=6080, lr=3.93865e-06, gnorm=2.833, clip=100, loss_scale=64, train_wall=28, gb_free=12.3, wall=25331
2023-04-08 23:05:30 - progress_bar.py[line:272] - INFO: epoch 011:    322 / 578 loss=2.406, loss_v1=0, loss_v2=0, nll_loss=1.209, ntokens=2609.8, nsentences=96, sample_size=2609.8, sample_size_v1=0, sample_size_v2=0, ppl=2.31, wps=918.7, ups=0.35, wpb=2609.8, bsz=96, num_updates=6090, lr=3.89264e-06, gnorm=2.811, clip=100, loss_scale=64, train_wall=28, gb_free=12.6, wall=25360
2023-04-08 23:05:59 - progress_bar.py[line:272] - INFO: epoch 011:    332 / 578 loss=2.381, loss_v1=0, loss_v2=0, nll_loss=1.181, ntokens=2550.2, nsentences=96, sample_size=2550.2, sample_size_v1=0, sample_size_v2=0, ppl=2.27, wps=894, ups=0.35, wpb=2550.2, bsz=96, num_updates=6100, lr=3.84663e-06, gnorm=3.003, clip=100, loss_scale=64, train_wall=28, gb_free=12.8, wall=25388
2023-04-08 23:06:27 - progress_bar.py[line:272] - INFO: epoch 011:    342 / 578 loss=2.416, loss_v1=0, loss_v2=0, nll_loss=1.221, ntokens=2676.5, nsentences=96, sample_size=2676.5, sample_size_v1=0, sample_size_v2=0, ppl=2.33, wps=942.9, ups=0.35, wpb=2676.5, bsz=96, num_updates=6110, lr=3.80061e-06, gnorm=2.833, clip=100, loss_scale=64, train_wall=28, gb_free=11.8, wall=25417
2023-04-08 23:06:55 - progress_bar.py[line:272] - INFO: epoch 011:    352 / 578 loss=2.383, loss_v1=0, loss_v2=0, nll_loss=1.186, ntokens=2590.9, nsentences=96, sample_size=2590.9, sample_size_v1=0, sample_size_v2=0, ppl=2.27, wps=919, ups=0.35, wpb=2590.9, bsz=96, num_updates=6120, lr=3.7546e-06, gnorm=3.018, clip=100, loss_scale=64, train_wall=28, gb_free=12.7, wall=25445
2023-04-08 23:07:24 - progress_bar.py[line:272] - INFO: epoch 011:    362 / 578 loss=2.396, loss_v1=0, loss_v2=0, nll_loss=1.199, ntokens=2702.7, nsentences=96, sample_size=2702.7, sample_size_v1=0, sample_size_v2=0, ppl=2.3, wps=956.4, ups=0.35, wpb=2702.7, bsz=96, num_updates=6130, lr=3.70859e-06, gnorm=2.868, clip=100, loss_scale=64, train_wall=28, gb_free=12.1, wall=25473
2023-04-08 23:07:52 - progress_bar.py[line:272] - INFO: epoch 011:    372 / 578 loss=2.418, loss_v1=0, loss_v2=0, nll_loss=1.223, ntokens=2821.3, nsentences=96, sample_size=2821.3, sample_size_v1=0, sample_size_v2=0, ppl=2.33, wps=987.1, ups=0.35, wpb=2821.3, bsz=96, num_updates=6140, lr=3.66258e-06, gnorm=2.675, clip=100, loss_scale=64, train_wall=29, gb_free=12.3, wall=25502
2023-04-08 23:08:21 - progress_bar.py[line:272] - INFO: epoch 011:    382 / 578 loss=2.41, loss_v1=0, loss_v2=0, nll_loss=1.216, ntokens=2715.4, nsentences=96, sample_size=2715.4, sample_size_v1=0, sample_size_v2=0, ppl=2.32, wps=954, ups=0.35, wpb=2715.4, bsz=96, num_updates=6150, lr=3.61656e-06, gnorm=2.718, clip=100, loss_scale=64, train_wall=28, gb_free=12.3, wall=25530
2023-04-08 23:08:49 - progress_bar.py[line:272] - INFO: epoch 011:    392 / 578 loss=2.412, loss_v1=0, loss_v2=0, nll_loss=1.217, ntokens=2539.3, nsentences=96, sample_size=2539.3, sample_size_v1=0, sample_size_v2=0, ppl=2.33, wps=893.4, ups=0.35, wpb=2539.3, bsz=96, num_updates=6160, lr=3.57055e-06, gnorm=2.899, clip=100, loss_scale=64, train_wall=28, gb_free=12.6, wall=25559
2023-04-08 23:09:17 - progress_bar.py[line:272] - INFO: epoch 011:    402 / 578 loss=2.388, loss_v1=0, loss_v2=0, nll_loss=1.19, ntokens=2542.6, nsentences=96, sample_size=2542.6, sample_size_v1=0, sample_size_v2=0, ppl=2.28, wps=894.7, ups=0.35, wpb=2542.6, bsz=96, num_updates=6170, lr=3.52454e-06, gnorm=2.934, clip=100, loss_scale=64, train_wall=28, gb_free=12.4, wall=25587
2023-04-08 23:09:46 - progress_bar.py[line:272] - INFO: epoch 011:    412 / 578 loss=2.41, loss_v1=0, loss_v2=0, nll_loss=1.214, ntokens=2416, nsentences=96, sample_size=2416, sample_size_v1=0, sample_size_v2=0, ppl=2.32, wps=855.1, ups=0.35, wpb=2416, bsz=96, num_updates=6180, lr=3.47853e-06, gnorm=2.959, clip=100, loss_scale=64, train_wall=28, gb_free=12.6, wall=25615
2023-04-08 23:10:14 - progress_bar.py[line:272] - INFO: epoch 011:    422 / 578 loss=2.399, loss_v1=0, loss_v2=0, nll_loss=1.202, ntokens=2498, nsentences=96, sample_size=2498, sample_size_v1=0, sample_size_v2=0, ppl=2.3, wps=881.2, ups=0.35, wpb=2498, bsz=96, num_updates=6190, lr=3.43252e-06, gnorm=2.813, clip=100, loss_scale=64, train_wall=28, gb_free=12.5, wall=25644
2023-04-08 23:10:42 - progress_bar.py[line:272] - INFO: epoch 011:    432 / 578 loss=2.393, loss_v1=0, loss_v2=0, nll_loss=1.197, ntokens=2540.8, nsentences=96, sample_size=2540.8, sample_size_v1=0, sample_size_v2=0, ppl=2.29, wps=897.1, ups=0.35, wpb=2540.8, bsz=96, num_updates=6200, lr=3.3865e-06, gnorm=2.893, clip=100, loss_scale=64, train_wall=28, gb_free=12.6, wall=25672
2023-04-08 23:11:11 - progress_bar.py[line:272] - INFO: epoch 011:    442 / 578 loss=2.41, loss_v1=0, loss_v2=0, nll_loss=1.216, ntokens=2446.2, nsentences=96, sample_size=2446.2, sample_size_v1=0, sample_size_v2=0, ppl=2.32, wps=865.7, ups=0.35, wpb=2446.2, bsz=96, num_updates=6210, lr=3.34049e-06, gnorm=3.091, clip=100, loss_scale=64, train_wall=28, gb_free=12.6, wall=25700
2023-04-08 23:11:39 - progress_bar.py[line:272] - INFO: epoch 011:    452 / 578 loss=2.407, loss_v1=0, loss_v2=0, nll_loss=1.211, ntokens=2538.4, nsentences=96, sample_size=2538.4, sample_size_v1=0, sample_size_v2=0, ppl=2.31, wps=895.5, ups=0.35, wpb=2538.4, bsz=96, num_updates=6220, lr=3.29448e-06, gnorm=2.884, clip=100, loss_scale=64, train_wall=28, gb_free=12.6, wall=25729
2023-04-08 23:12:07 - progress_bar.py[line:272] - INFO: epoch 011:    462 / 578 loss=2.405, loss_v1=0, loss_v2=0, nll_loss=1.209, ntokens=2480.3, nsentences=96, sample_size=2480.3, sample_size_v1=0, sample_size_v2=0, ppl=2.31, wps=876.8, ups=0.35, wpb=2480.3, bsz=96, num_updates=6230, lr=3.24847e-06, gnorm=3.191, clip=100, loss_scale=64, train_wall=28, gb_free=12.4, wall=25757
2023-04-08 23:12:36 - progress_bar.py[line:272] - INFO: epoch 011:    472 / 578 loss=2.415, loss_v1=0, loss_v2=0, nll_loss=1.219, ntokens=2472.2, nsentences=96, sample_size=2472.2, sample_size_v1=0, sample_size_v2=0, ppl=2.33, wps=872.1, ups=0.35, wpb=2472.2, bsz=96, num_updates=6240, lr=3.20245e-06, gnorm=3.052, clip=100, loss_scale=64, train_wall=28, gb_free=12.6, wall=25785
2023-04-08 23:13:04 - progress_bar.py[line:272] - INFO: epoch 011:    482 / 578 loss=2.406, loss_v1=0, loss_v2=0, nll_loss=1.209, ntokens=2335.8, nsentences=96, sample_size=2335.8, sample_size_v1=0, sample_size_v2=0, ppl=2.31, wps=826.1, ups=0.35, wpb=2335.8, bsz=96, num_updates=6250, lr=3.15644e-06, gnorm=3.217, clip=100, loss_scale=64, train_wall=28, gb_free=12.6, wall=25814
2023-04-08 23:13:32 - progress_bar.py[line:272] - INFO: epoch 011:    492 / 578 loss=2.383, loss_v1=0, loss_v2=0, nll_loss=1.186, ntokens=2525.1, nsentences=96, sample_size=2525.1, sample_size_v1=0, sample_size_v2=0, ppl=2.27, wps=892.6, ups=0.35, wpb=2525.1, bsz=96, num_updates=6260, lr=3.11043e-06, gnorm=2.9, clip=100, loss_scale=64, train_wall=28, gb_free=12.6, wall=25842
2023-04-08 23:14:01 - progress_bar.py[line:272] - INFO: epoch 011:    502 / 578 loss=2.388, loss_v1=0, loss_v2=0, nll_loss=1.191, ntokens=2533.3, nsentences=96, sample_size=2533.3, sample_size_v1=0, sample_size_v2=0, ppl=2.28, wps=892.1, ups=0.35, wpb=2533.3, bsz=96, num_updates=6270, lr=3.06442e-06, gnorm=2.877, clip=100, loss_scale=64, train_wall=28, gb_free=12.5, wall=25870
2023-04-08 23:14:29 - progress_bar.py[line:272] - INFO: epoch 011:    512 / 578 loss=2.391, loss_v1=0, loss_v2=0, nll_loss=1.195, ntokens=2550.7, nsentences=96, sample_size=2550.7, sample_size_v1=0, sample_size_v2=0, ppl=2.29, wps=896.6, ups=0.35, wpb=2550.7, bsz=96, num_updates=6280, lr=3.0184e-06, gnorm=2.862, clip=100, loss_scale=64, train_wall=28, gb_free=12.3, wall=25899
2023-04-08 23:14:57 - progress_bar.py[line:272] - INFO: epoch 011:    522 / 578 loss=2.382, loss_v1=0, loss_v2=0, nll_loss=1.184, ntokens=2706.7, nsentences=95.6, sample_size=2706.7, sample_size_v1=0, sample_size_v2=0, ppl=2.27, wps=956.5, ups=0.35, wpb=2706.7, bsz=95.6, num_updates=6290, lr=2.97239e-06, gnorm=2.554, clip=100, loss_scale=64, train_wall=28, gb_free=12.2, wall=25927
2023-04-08 23:15:26 - progress_bar.py[line:272] - INFO: epoch 011:    532 / 578 loss=2.39, loss_v1=0, loss_v2=0, nll_loss=1.192, ntokens=2561.6, nsentences=96, sample_size=2561.6, sample_size_v1=0, sample_size_v2=0, ppl=2.29, wps=907.7, ups=0.35, wpb=2561.6, bsz=96, num_updates=6300, lr=2.92638e-06, gnorm=3.183, clip=100, loss_scale=64, train_wall=28, gb_free=12.6, wall=25955
2023-04-08 23:15:54 - progress_bar.py[line:272] - INFO: epoch 011:    542 / 578 loss=2.378, loss_v1=0, loss_v2=0, nll_loss=1.179, ntokens=2492.5, nsentences=96, sample_size=2492.5, sample_size_v1=0, sample_size_v2=0, ppl=2.26, wps=882.1, ups=0.35, wpb=2492.5, bsz=96, num_updates=6310, lr=2.88037e-06, gnorm=2.888, clip=100, loss_scale=64, train_wall=28, gb_free=12, wall=25983
2023-04-08 23:16:22 - progress_bar.py[line:272] - INFO: epoch 011:    552 / 578 loss=2.376, loss_v1=0, loss_v2=0, nll_loss=1.178, ntokens=2551.1, nsentences=96, sample_size=2551.1, sample_size_v1=0, sample_size_v2=0, ppl=2.26, wps=895.4, ups=0.35, wpb=2551.1, bsz=96, num_updates=6320, lr=2.83436e-06, gnorm=2.823, clip=100, loss_scale=64, train_wall=28, gb_free=12.5, wall=26012
2023-04-08 23:16:51 - progress_bar.py[line:272] - INFO: epoch 011:    562 / 578 loss=2.375, loss_v1=0, loss_v2=0, nll_loss=1.176, ntokens=2665.1, nsentences=96, sample_size=2665.1, sample_size_v1=0, sample_size_v2=0, ppl=2.26, wps=936.3, ups=0.35, wpb=2665.1, bsz=96, num_updates=6330, lr=2.78834e-06, gnorm=2.724, clip=100, loss_scale=64, train_wall=28, gb_free=12.7, wall=26040
2023-04-08 23:17:19 - progress_bar.py[line:272] - INFO: epoch 011:    572 / 578 loss=2.385, loss_v1=0, loss_v2=0, nll_loss=1.188, ntokens=2575.2, nsentences=96, sample_size=2575.2, sample_size_v1=0, sample_size_v2=0, ppl=2.28, wps=904.8, ups=0.35, wpb=2575.2, bsz=96, num_updates=6340, lr=2.74233e-06, gnorm=2.62, clip=100, loss_scale=64, train_wall=28, gb_free=12.5, wall=26069
2023-04-08 23:17:34 - train.py[line:332] - INFO: end of epoch 11 (average epoch stats below)
local datafile ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 1 begin to initialize row_count and line_idx-to-offset mapping
2023-04-08 23:17:34 - progress_bar.py[line:282] - INFO: epoch 011 | loss 2.4 | loss_v1 0 | loss_v2 0 | nll_loss 1.204 | ntokens 2519.93 | nsentences 95.847 | sample_size 2519.93 | sample_size_v1 0 | sample_size_v2 0 | ppl 2.3 | wps 882.9 | ups 0.35 | wpb 2519.9 | bsz 95.8 | num_updates 6346 | lr 2.71472e-06 | gnorm 2.83 | clip 100 | loss_scale 64 | train_wall 1643 | gb_free 13.1 | wall 26084
2023-04-08 23:17:34 - trainer.py[line:639] - INFO: loading train data for epoch 12
local datafile ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 0 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 1 finished initializing row_count and line_idx-to-offset mapping
file ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 1 row count 27700 total row count 55400
local datafile ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 0 finished initializing row_count and line_idx-to-offset mapping
file ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 0 row count 27700 total row count 55400
slice_id 1 seek offset 27700
slice_id 0 seek offset 0
2023-04-08 23:17:36 - trainer.py[line:703] - INFO: begin training epoch 12
2023-04-08 23:17:36 - train.py[line:305] - INFO: Start iterating over samples
2023-04-08 23:17:48 - progress_bar.py[line:272] - INFO: epoch 012:      4 / 578 loss=2.403, loss_v1=0, loss_v2=0, nll_loss=1.207, ntokens=2356.8, nsentences=87.6, sample_size=2356.8, sample_size_v1=0, sample_size_v2=0, ppl=2.31, wps=826.1, ups=0.35, wpb=2356.8, bsz=87.6, num_updates=6350, lr=2.69632e-06, gnorm=3.157, clip=100, loss_scale=64, train_wall=26, gb_free=12.3, wall=26097
2023-04-08 23:18:16 - progress_bar.py[line:272] - INFO: epoch 012:     14 / 578 loss=2.37, loss_v1=0, loss_v2=0, nll_loss=1.168, ntokens=2416.3, nsentences=96, sample_size=2416.3, sample_size_v1=0, sample_size_v2=0, ppl=2.25, wps=848.2, ups=0.35, wpb=2416.3, bsz=96, num_updates=6360, lr=2.65031e-06, gnorm=2.885, clip=100, loss_scale=64, train_wall=28, gb_free=12.4, wall=26126
2023-04-08 23:18:45 - progress_bar.py[line:272] - INFO: epoch 012:     24 / 578 loss=2.37, loss_v1=0, loss_v2=0, nll_loss=1.169, ntokens=2360.9, nsentences=96, sample_size=2360.9, sample_size_v1=0, sample_size_v2=0, ppl=2.25, wps=823.3, ups=0.35, wpb=2360.9, bsz=96, num_updates=6370, lr=2.60429e-06, gnorm=2.944, clip=100, loss_scale=64, train_wall=29, gb_free=11.9, wall=26155
2023-04-08 23:19:14 - progress_bar.py[line:272] - INFO: epoch 012:     34 / 578 loss=2.382, loss_v1=0, loss_v2=0, nll_loss=1.186, ntokens=2282.6, nsentences=96, sample_size=2282.6, sample_size_v1=0, sample_size_v2=0, ppl=2.27, wps=796.4, ups=0.35, wpb=2282.6, bsz=96, num_updates=6380, lr=2.55828e-06, gnorm=3.087, clip=100, loss_scale=64, train_wall=29, gb_free=12.3, wall=26183
2023-04-08 23:19:42 - progress_bar.py[line:272] - INFO: epoch 012:     44 / 578 loss=2.34, loss_v1=0, loss_v2=0, nll_loss=1.138, ntokens=2176.8, nsentences=96, sample_size=2176.8, sample_size_v1=0, sample_size_v2=0, ppl=2.2, wps=757.9, ups=0.35, wpb=2176.8, bsz=96, num_updates=6390, lr=2.51227e-06, gnorm=2.99, clip=100, loss_scale=64, train_wall=29, gb_free=12, wall=26212
2023-04-08 23:20:12 - progress_bar.py[line:272] - INFO: epoch 012:     54 / 578 loss=2.382, loss_v1=0, loss_v2=0, nll_loss=1.184, ntokens=2425, nsentences=96, sample_size=2425, sample_size_v1=0, sample_size_v2=0, ppl=2.27, wps=830.5, ups=0.34, wpb=2425, bsz=96, num_updates=6400, lr=2.46626e-06, gnorm=3.323, clip=100, loss_scale=64, train_wall=29, gb_free=11.8, wall=26241
2023-04-08 23:20:40 - progress_bar.py[line:272] - INFO: epoch 012:     64 / 578 loss=2.384, loss_v1=0, loss_v2=0, nll_loss=1.184, ntokens=2232.6, nsentences=96, sample_size=2232.6, sample_size_v1=0, sample_size_v2=0, ppl=2.27, wps=780.5, ups=0.35, wpb=2232.6, bsz=96, num_updates=6410, lr=2.42025e-06, gnorm=3.138, clip=100, loss_scale=64, train_wall=29, gb_free=12, wall=26270
2023-04-08 23:21:09 - progress_bar.py[line:272] - INFO: epoch 012:     74 / 578 loss=2.412, loss_v1=0, loss_v2=0, nll_loss=1.219, ntokens=2451, nsentences=96, sample_size=2451, sample_size_v1=0, sample_size_v2=0, ppl=2.33, wps=859.7, ups=0.35, wpb=2451, bsz=96, num_updates=6420, lr=2.37423e-06, gnorm=3.26, clip=100, loss_scale=64, train_wall=28, gb_free=12.2, wall=26298
2023-04-08 23:21:38 - progress_bar.py[line:272] - INFO: epoch 012:     84 / 578 loss=2.41, loss_v1=0, loss_v2=0, nll_loss=1.216, ntokens=2493.8, nsentences=96, sample_size=2493.8, sample_size_v1=0, sample_size_v2=0, ppl=2.32, wps=860, ups=0.34, wpb=2493.8, bsz=96, num_updates=6430, lr=2.32822e-06, gnorm=3.006, clip=100, loss_scale=64, train_wall=29, gb_free=11.9, wall=26327
2023-04-08 23:22:07 - progress_bar.py[line:272] - INFO: epoch 012:     94 / 578 loss=2.397, loss_v1=0, loss_v2=0, nll_loss=1.2, ntokens=2498.7, nsentences=96, sample_size=2498.7, sample_size_v1=0, sample_size_v2=0, ppl=2.3, wps=860.8, ups=0.34, wpb=2498.7, bsz=96, num_updates=6440, lr=2.28221e-06, gnorm=3.349, clip=100, loss_scale=64, train_wall=29, gb_free=11.7, wall=26356
2023-04-08 23:22:36 - progress_bar.py[line:272] - INFO: epoch 012:    104 / 578 loss=2.396, loss_v1=0, loss_v2=0, nll_loss=1.2, ntokens=2443.1, nsentences=96, sample_size=2443.1, sample_size_v1=0, sample_size_v2=0, ppl=2.3, wps=839.4, ups=0.34, wpb=2443.1, bsz=96, num_updates=6450, lr=2.2362e-06, gnorm=3.003, clip=100, loss_scale=64, train_wall=29, gb_free=12.1, wall=26385
2023-04-08 23:23:04 - progress_bar.py[line:272] - INFO: epoch 012:    114 / 578 loss=2.404, loss_v1=0, loss_v2=0, nll_loss=1.207, ntokens=2367.9, nsentences=96, sample_size=2367.9, sample_size_v1=0, sample_size_v2=0, ppl=2.31, wps=826.2, ups=0.35, wpb=2367.9, bsz=96, num_updates=6460, lr=2.19018e-06, gnorm=3.264, clip=100, loss_scale=64, train_wall=29, gb_free=12.4, wall=26414
2023-04-08 23:23:33 - progress_bar.py[line:272] - INFO: epoch 012:    124 / 578 loss=2.408, loss_v1=0, loss_v2=0, nll_loss=1.212, ntokens=2347.2, nsentences=96, sample_size=2347.2, sample_size_v1=0, sample_size_v2=0, ppl=2.32, wps=812.9, ups=0.35, wpb=2347.2, bsz=96, num_updates=6470, lr=2.14417e-06, gnorm=3.204, clip=100, loss_scale=64, train_wall=29, gb_free=11.4, wall=26443
2023-04-08 23:24:02 - progress_bar.py[line:272] - INFO: epoch 012:    134 / 578 loss=2.396, loss_v1=0, loss_v2=0, nll_loss=1.199, ntokens=2432.5, nsentences=96, sample_size=2432.5, sample_size_v1=0, sample_size_v2=0, ppl=2.3, wps=847.5, ups=0.35, wpb=2432.5, bsz=96, num_updates=6480, lr=2.09816e-06, gnorm=3.053, clip=100, loss_scale=64, train_wall=29, gb_free=12.4, wall=26472
2023-04-08 23:24:31 - progress_bar.py[line:272] - INFO: epoch 012:    144 / 578 loss=2.41, loss_v1=0, loss_v2=0, nll_loss=1.215, ntokens=2524.1, nsentences=96, sample_size=2524.1, sample_size_v1=0, sample_size_v2=0, ppl=2.32, wps=883.6, ups=0.35, wpb=2524.1, bsz=96, num_updates=6490, lr=2.05215e-06, gnorm=3.009, clip=100, loss_scale=64, train_wall=29, gb_free=12.3, wall=26500
2023-04-08 23:24:59 - progress_bar.py[line:272] - INFO: epoch 012:    154 / 578 loss=2.406, loss_v1=0, loss_v2=0, nll_loss=1.211, ntokens=2632.8, nsentences=96, sample_size=2632.8, sample_size_v1=0, sample_size_v2=0, ppl=2.31, wps=924.7, ups=0.35, wpb=2632.8, bsz=96, num_updates=6500, lr=2.00613e-06, gnorm=3.172, clip=100, loss_scale=128, train_wall=28, gb_free=12.5, wall=26529
2023-04-08 23:25:28 - progress_bar.py[line:272] - INFO: epoch 012:    164 / 578 loss=2.406, loss_v1=0, loss_v2=0, nll_loss=1.21, ntokens=2705.9, nsentences=96, sample_size=2705.9, sample_size_v1=0, sample_size_v2=0, ppl=2.31, wps=948.8, ups=0.35, wpb=2705.9, bsz=96, num_updates=6510, lr=1.96012e-06, gnorm=3.184, clip=100, loss_scale=128, train_wall=28, gb_free=12.5, wall=26557
2023-04-08 23:25:56 - progress_bar.py[line:272] - INFO: epoch 012:    174 / 578 loss=2.409, loss_v1=0, loss_v2=0, nll_loss=1.213, ntokens=2595.7, nsentences=96, sample_size=2595.7, sample_size_v1=0, sample_size_v2=0, ppl=2.32, wps=912.3, ups=0.35, wpb=2595.7, bsz=96, num_updates=6520, lr=1.91411e-06, gnorm=3.167, clip=100, loss_scale=128, train_wall=28, gb_free=12.5, wall=26586
2023-04-08 23:26:16 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2023-04-08 23:26:27 - progress_bar.py[line:272] - INFO: epoch 012:    185 / 578 loss=2.404, loss_v1=0, loss_v2=0, nll_loss=1.207, ntokens=2622.3, nsentences=96, sample_size=2622.3, sample_size_v1=0, sample_size_v2=0, ppl=2.31, wps=835, ups=0.32, wpb=2622.3, bsz=96, num_updates=6530, lr=1.8681e-06, gnorm=3.365, clip=100, loss_scale=64, train_wall=31, gb_free=12.2, wall=26617
2023-04-08 23:26:56 - progress_bar.py[line:272] - INFO: epoch 012:    195 / 578 loss=2.395, loss_v1=0, loss_v2=0, nll_loss=1.199, ntokens=2610.4, nsentences=96, sample_size=2610.4, sample_size_v1=0, sample_size_v2=0, ppl=2.3, wps=916.3, ups=0.35, wpb=2610.4, bsz=96, num_updates=6540, lr=1.82209e-06, gnorm=3.079, clip=100, loss_scale=64, train_wall=28, gb_free=12.4, wall=26646
2023-04-08 23:27:24 - progress_bar.py[line:272] - INFO: epoch 012:    205 / 578 loss=2.395, loss_v1=0, loss_v2=0, nll_loss=1.198, ntokens=2579.9, nsentences=96, sample_size=2579.9, sample_size_v1=0, sample_size_v2=0, ppl=2.29, wps=908.5, ups=0.35, wpb=2579.9, bsz=96, num_updates=6550, lr=1.77607e-06, gnorm=3.167, clip=100, loss_scale=64, train_wall=28, gb_free=12.6, wall=26674
2023-04-08 23:27:53 - progress_bar.py[line:272] - INFO: epoch 012:    215 / 578 loss=2.417, loss_v1=0, loss_v2=0, nll_loss=1.223, ntokens=2467, nsentences=96, sample_size=2467, sample_size_v1=0, sample_size_v2=0, ppl=2.33, wps=869.1, ups=0.35, wpb=2467, bsz=96, num_updates=6560, lr=1.73006e-06, gnorm=3.443, clip=100, loss_scale=64, train_wall=28, gb_free=12.4, wall=26702
2023-04-08 23:28:21 - progress_bar.py[line:272] - INFO: epoch 012:    225 / 578 loss=2.387, loss_v1=0, loss_v2=0, nll_loss=1.19, ntokens=2600.2, nsentences=96, sample_size=2600.2, sample_size_v1=0, sample_size_v2=0, ppl=2.28, wps=914.9, ups=0.35, wpb=2600.2, bsz=96, num_updates=6570, lr=1.68405e-06, gnorm=3.201, clip=100, loss_scale=64, train_wall=28, gb_free=11.9, wall=26731
2023-04-08 23:28:49 - progress_bar.py[line:272] - INFO: epoch 012:    235 / 578 loss=2.391, loss_v1=0, loss_v2=0, nll_loss=1.195, ntokens=2444.9, nsentences=96, sample_size=2444.9, sample_size_v1=0, sample_size_v2=0, ppl=2.29, wps=865.9, ups=0.35, wpb=2444.9, bsz=96, num_updates=6580, lr=1.63804e-06, gnorm=3.577, clip=100, loss_scale=64, train_wall=28, gb_free=12.6, wall=26759
2023-04-08 23:29:18 - progress_bar.py[line:272] - INFO: epoch 012:    245 / 578 loss=2.402, loss_v1=0, loss_v2=0, nll_loss=1.206, ntokens=2458.6, nsentences=96, sample_size=2458.6, sample_size_v1=0, sample_size_v2=0, ppl=2.31, wps=870.6, ups=0.35, wpb=2458.6, bsz=96, num_updates=6590, lr=1.59202e-06, gnorm=3.535, clip=100, loss_scale=64, train_wall=28, gb_free=12.5, wall=26787
2023-04-08 23:29:46 - progress_bar.py[line:272] - INFO: epoch 012:    255 / 578 loss=2.403, loss_v1=0, loss_v2=0, nll_loss=1.208, ntokens=2561, nsentences=96, sample_size=2561, sample_size_v1=0, sample_size_v2=0, ppl=2.31, wps=905.8, ups=0.35, wpb=2561, bsz=96, num_updates=6600, lr=1.54601e-06, gnorm=3.353, clip=100, loss_scale=64, train_wall=28, gb_free=12.5, wall=26816
2023-04-08 23:30:14 - progress_bar.py[line:272] - INFO: epoch 012:    265 / 578 loss=2.395, loss_v1=0, loss_v2=0, nll_loss=1.197, ntokens=2529.4, nsentences=96, sample_size=2529.4, sample_size_v1=0, sample_size_v2=0, ppl=2.29, wps=892, ups=0.35, wpb=2529.4, bsz=96, num_updates=6610, lr=1.5e-06, gnorm=3.119, clip=100, loss_scale=64, train_wall=28, gb_free=12.3, wall=26844
2023-04-08 23:30:43 - progress_bar.py[line:272] - INFO: epoch 012:    275 / 578 loss=2.392, loss_v1=0, loss_v2=0, nll_loss=1.196, ntokens=2608.1, nsentences=96, sample_size=2608.1, sample_size_v1=0, sample_size_v2=0, ppl=2.29, wps=917.1, ups=0.35, wpb=2608.1, bsz=96, num_updates=6620, lr=1.45399e-06, gnorm=3.093, clip=100, loss_scale=64, train_wall=28, gb_free=12.6, wall=26872
2023-04-08 23:31:11 - progress_bar.py[line:272] - INFO: epoch 012:    285 / 578 loss=2.384, loss_v1=0, loss_v2=0, nll_loss=1.186, ntokens=2523.9, nsentences=96, sample_size=2523.9, sample_size_v1=0, sample_size_v2=0, ppl=2.28, wps=885.6, ups=0.35, wpb=2523.9, bsz=96, num_updates=6630, lr=1.40798e-06, gnorm=3.198, clip=100, loss_scale=64, train_wall=28, gb_free=12.3, wall=26901
2023-04-08 23:31:40 - progress_bar.py[line:272] - INFO: epoch 012:    295 / 578 loss=2.403, loss_v1=0, loss_v2=0, nll_loss=1.207, ntokens=2600, nsentences=96, sample_size=2600, sample_size_v1=0, sample_size_v2=0, ppl=2.31, wps=916.1, ups=0.35, wpb=2600, bsz=96, num_updates=6640, lr=1.36196e-06, gnorm=3.292, clip=100, loss_scale=64, train_wall=28, gb_free=12.1, wall=26929
2023-04-08 23:32:08 - progress_bar.py[line:272] - INFO: epoch 012:    305 / 578 loss=2.393, loss_v1=0, loss_v2=0, nll_loss=1.196, ntokens=2547.6, nsentences=96, sample_size=2547.6, sample_size_v1=0, sample_size_v2=0, ppl=2.29, wps=896.4, ups=0.35, wpb=2547.6, bsz=96, num_updates=6650, lr=1.31595e-06, gnorm=3.35, clip=100, loss_scale=64, train_wall=28, gb_free=12, wall=26958
2023-04-08 23:32:36 - progress_bar.py[line:272] - INFO: epoch 012:    315 / 578 loss=2.41, loss_v1=0, loss_v2=0, nll_loss=1.215, ntokens=2647.9, nsentences=96, sample_size=2647.9, sample_size_v1=0, sample_size_v2=0, ppl=2.32, wps=931.6, ups=0.35, wpb=2647.9, bsz=96, num_updates=6660, lr=1.26994e-06, gnorm=3.473, clip=100, loss_scale=64, train_wall=28, gb_free=12.1, wall=26986
2023-04-08 23:33:05 - progress_bar.py[line:272] - INFO: epoch 012:    325 / 578 loss=2.397, loss_v1=0, loss_v2=0, nll_loss=1.2, ntokens=2577.7, nsentences=96, sample_size=2577.7, sample_size_v1=0, sample_size_v2=0, ppl=2.3, wps=907.2, ups=0.35, wpb=2577.7, bsz=96, num_updates=6670, lr=1.22393e-06, gnorm=3.259, clip=100, loss_scale=64, train_wall=28, gb_free=12.7, wall=27015
2023-04-08 23:33:33 - progress_bar.py[line:272] - INFO: epoch 012:    335 / 578 loss=2.375, loss_v1=0, loss_v2=0, nll_loss=1.176, ntokens=2574.8, nsentences=96, sample_size=2574.8, sample_size_v1=0, sample_size_v2=0, ppl=2.26, wps=908.4, ups=0.35, wpb=2574.8, bsz=96, num_updates=6680, lr=1.17791e-06, gnorm=3.102, clip=100, loss_scale=64, train_wall=28, gb_free=12.5, wall=27043
2023-04-08 23:34:02 - progress_bar.py[line:272] - INFO: epoch 012:    345 / 578 loss=2.398, loss_v1=0, loss_v2=0, nll_loss=1.201, ntokens=2710.5, nsentences=96, sample_size=2710.5, sample_size_v1=0, sample_size_v2=0, ppl=2.3, wps=954, ups=0.35, wpb=2710.5, bsz=96, num_updates=6690, lr=1.1319e-06, gnorm=3.162, clip=100, loss_scale=64, train_wall=28, gb_free=12.6, wall=27071
2023-04-08 23:34:30 - progress_bar.py[line:272] - INFO: epoch 012:    355 / 578 loss=2.377, loss_v1=0, loss_v2=0, nll_loss=1.177, ntokens=2572, nsentences=96, sample_size=2572, sample_size_v1=0, sample_size_v2=0, ppl=2.26, wps=909.1, ups=0.35, wpb=2572, bsz=96, num_updates=6700, lr=1.08589e-06, gnorm=3.386, clip=100, loss_scale=64, train_wall=28, gb_free=12.6, wall=27100
2023-04-08 23:34:58 - progress_bar.py[line:272] - INFO: epoch 012:    365 / 578 loss=2.403, loss_v1=0, loss_v2=0, nll_loss=1.207, ntokens=2762.5, nsentences=96, sample_size=2762.5, sample_size_v1=0, sample_size_v2=0, ppl=2.31, wps=972, ups=0.35, wpb=2762.5, bsz=96, num_updates=6710, lr=1.03988e-06, gnorm=3.165, clip=100, loss_scale=64, train_wall=28, gb_free=12.5, wall=27128
2023-04-08 23:35:27 - progress_bar.py[line:272] - INFO: epoch 012:    375 / 578 loss=2.415, loss_v1=0, loss_v2=0, nll_loss=1.22, ntokens=2747.2, nsentences=96, sample_size=2747.2, sample_size_v1=0, sample_size_v2=0, ppl=2.33, wps=963.2, ups=0.35, wpb=2747.2, bsz=96, num_updates=6720, lr=9.93865e-07, gnorm=3.257, clip=100, loss_scale=64, train_wall=28, gb_free=12.7, wall=27157
2023-04-08 23:35:55 - progress_bar.py[line:272] - INFO: epoch 012:    385 / 578 loss=2.4, loss_v1=0, loss_v2=0, nll_loss=1.203, ntokens=2666.6, nsentences=96, sample_size=2666.6, sample_size_v1=0, sample_size_v2=0, ppl=2.3, wps=935.1, ups=0.35, wpb=2666.6, bsz=96, num_updates=6730, lr=9.47853e-07, gnorm=3.171, clip=100, loss_scale=64, train_wall=28, gb_free=12.4, wall=27185
2023-04-08 23:36:24 - progress_bar.py[line:272] - INFO: epoch 012:    395 / 578 loss=2.401, loss_v1=0, loss_v2=0, nll_loss=1.205, ntokens=2566.2, nsentences=96, sample_size=2566.2, sample_size_v1=0, sample_size_v2=0, ppl=2.31, wps=901, ups=0.35, wpb=2566.2, bsz=96, num_updates=6740, lr=9.0184e-07, gnorm=3.369, clip=100, loss_scale=64, train_wall=28, gb_free=12.3, wall=27214
2023-04-08 23:36:52 - progress_bar.py[line:272] - INFO: epoch 012:    405 / 578 loss=2.383, loss_v1=0, loss_v2=0, nll_loss=1.185, ntokens=2473.5, nsentences=96, sample_size=2473.5, sample_size_v1=0, sample_size_v2=0, ppl=2.27, wps=873, ups=0.35, wpb=2473.5, bsz=96, num_updates=6750, lr=8.55828e-07, gnorm=3.403, clip=100, loss_scale=64, train_wall=28, gb_free=12.5, wall=27242
2023-04-08 23:37:21 - progress_bar.py[line:272] - INFO: epoch 012:    415 / 578 loss=2.407, loss_v1=0, loss_v2=0, nll_loss=1.211, ntokens=2487.1, nsentences=96, sample_size=2487.1, sample_size_v1=0, sample_size_v2=0, ppl=2.32, wps=876.2, ups=0.35, wpb=2487.1, bsz=96, num_updates=6760, lr=8.09816e-07, gnorm=3.297, clip=100, loss_scale=64, train_wall=28, gb_free=12.1, wall=27270
2023-04-08 23:37:49 - progress_bar.py[line:272] - INFO: epoch 012:    425 / 578 loss=2.39, loss_v1=0, loss_v2=0, nll_loss=1.193, ntokens=2471.6, nsentences=96, sample_size=2471.6, sample_size_v1=0, sample_size_v2=0, ppl=2.29, wps=874.1, ups=0.35, wpb=2471.6, bsz=96, num_updates=6770, lr=7.63804e-07, gnorm=3.148, clip=100, loss_scale=64, train_wall=28, gb_free=12.6, wall=27299
2023-04-08 23:38:17 - progress_bar.py[line:272] - INFO: epoch 012:    435 / 578 loss=2.389, loss_v1=0, loss_v2=0, nll_loss=1.191, ntokens=2547.1, nsentences=96, sample_size=2547.1, sample_size_v1=0, sample_size_v2=0, ppl=2.28, wps=903.4, ups=0.35, wpb=2547.1, bsz=96, num_updates=6780, lr=7.17791e-07, gnorm=3.33, clip=100, loss_scale=64, train_wall=28, gb_free=12.7, wall=27327
2023-04-08 23:38:45 - progress_bar.py[line:272] - INFO: epoch 012:    445 / 578 loss=2.409, loss_v1=0, loss_v2=0, nll_loss=1.214, ntokens=2423.5, nsentences=96, sample_size=2423.5, sample_size_v1=0, sample_size_v2=0, ppl=2.32, wps=859, ups=0.35, wpb=2423.5, bsz=96, num_updates=6790, lr=6.71779e-07, gnorm=3.633, clip=100, loss_scale=64, train_wall=28, gb_free=12.5, wall=27355
2023-04-08 23:39:14 - progress_bar.py[line:272] - INFO: epoch 012:    455 / 578 loss=2.396, loss_v1=0, loss_v2=0, nll_loss=1.199, ntokens=2553.1, nsentences=96, sample_size=2553.1, sample_size_v1=0, sample_size_v2=0, ppl=2.3, wps=902.7, ups=0.35, wpb=2553.1, bsz=96, num_updates=6800, lr=6.25767e-07, gnorm=3.329, clip=100, loss_scale=64, train_wall=28, gb_free=12.5, wall=27383
2023-04-08 23:39:42 - progress_bar.py[line:272] - INFO: epoch 012:    465 / 578 loss=2.404, loss_v1=0, loss_v2=0, nll_loss=1.207, ntokens=2532.8, nsentences=96, sample_size=2532.8, sample_size_v1=0, sample_size_v2=0, ppl=2.31, wps=892.3, ups=0.35, wpb=2532.8, bsz=96, num_updates=6810, lr=5.79755e-07, gnorm=3.154, clip=100, loss_scale=64, train_wall=28, gb_free=12.1, wall=27412
2023-04-08 23:40:10 - progress_bar.py[line:272] - INFO: epoch 012:    475 / 578 loss=2.409, loss_v1=0, loss_v2=0, nll_loss=1.213, ntokens=2350.8, nsentences=95.6, sample_size=2350.8, sample_size_v1=0, sample_size_v2=0, ppl=2.32, wps=835.1, ups=0.36, wpb=2350.8, bsz=95.6, num_updates=6820, lr=5.33742e-07, gnorm=3.546, clip=100, loss_scale=64, train_wall=28, gb_free=12.7, wall=27440
2023-04-08 23:40:38 - progress_bar.py[line:272] - INFO: epoch 012:    485 / 578 loss=2.389, loss_v1=0, loss_v2=0, nll_loss=1.191, ntokens=2391.2, nsentences=96, sample_size=2391.2, sample_size_v1=0, sample_size_v2=0, ppl=2.28, wps=846.6, ups=0.35, wpb=2391.2, bsz=96, num_updates=6830, lr=4.8773e-07, gnorm=3.077, clip=100, loss_scale=64, train_wall=28, gb_free=12.7, wall=27468
2023-04-08 23:41:07 - progress_bar.py[line:272] - INFO: epoch 012:    495 / 578 loss=2.382, loss_v1=0, loss_v2=0, nll_loss=1.183, ntokens=2550.1, nsentences=96, sample_size=2550.1, sample_size_v1=0, sample_size_v2=0, ppl=2.27, wps=899.9, ups=0.35, wpb=2550.1, bsz=96, num_updates=6840, lr=4.41718e-07, gnorm=3.204, clip=100, loss_scale=64, train_wall=28, gb_free=12.5, wall=27496
2023-04-08 23:41:35 - progress_bar.py[line:272] - INFO: epoch 012:    505 / 578 loss=2.374, loss_v1=0, loss_v2=0, nll_loss=1.174, ntokens=2528.3, nsentences=96, sample_size=2528.3, sample_size_v1=0, sample_size_v2=0, ppl=2.26, wps=891.3, ups=0.35, wpb=2528.3, bsz=96, num_updates=6850, lr=3.95706e-07, gnorm=3.072, clip=100, loss_scale=64, train_wall=28, gb_free=12.6, wall=27525
2023-04-08 23:42:04 - progress_bar.py[line:272] - INFO: epoch 012:    515 / 578 loss=2.385, loss_v1=0, loss_v2=0, nll_loss=1.187, ntokens=2584.9, nsentences=96, sample_size=2584.9, sample_size_v1=0, sample_size_v2=0, ppl=2.28, wps=910.8, ups=0.35, wpb=2584.9, bsz=96, num_updates=6860, lr=3.49693e-07, gnorm=2.993, clip=100, loss_scale=64, train_wall=28, gb_free=11.8, wall=27553
2023-04-08 23:42:32 - progress_bar.py[line:272] - INFO: epoch 012:    525 / 578 loss=2.38, loss_v1=0, loss_v2=0, nll_loss=1.182, ntokens=2652.2, nsentences=96, sample_size=2652.2, sample_size_v1=0, sample_size_v2=0, ppl=2.27, wps=934, ups=0.35, wpb=2652.2, bsz=96, num_updates=6870, lr=3.03681e-07, gnorm=3.059, clip=100, loss_scale=64, train_wall=28, gb_free=12.5, wall=27582
2023-04-08 23:43:00 - progress_bar.py[line:272] - INFO: epoch 012:    535 / 578 loss=2.377, loss_v1=0, loss_v2=0, nll_loss=1.179, ntokens=2535, nsentences=96, sample_size=2535, sample_size_v1=0, sample_size_v2=0, ppl=2.26, wps=896.2, ups=0.35, wpb=2535, bsz=96, num_updates=6880, lr=2.57669e-07, gnorm=3.352, clip=100, loss_scale=64, train_wall=28, gb_free=12.5, wall=27610
2023-04-08 23:43:29 - progress_bar.py[line:272] - INFO: epoch 012:    545 / 578 loss=2.383, loss_v1=0, loss_v2=0, nll_loss=1.186, ntokens=2517.6, nsentences=96, sample_size=2517.6, sample_size_v1=0, sample_size_v2=0, ppl=2.27, wps=886.2, ups=0.35, wpb=2517.6, bsz=96, num_updates=6890, lr=2.11656e-07, gnorm=3.165, clip=100, loss_scale=64, train_wall=28, gb_free=12.5, wall=27638
2023-04-08 23:43:57 - progress_bar.py[line:272] - INFO: epoch 012:    555 / 578 loss=2.371, loss_v1=0, loss_v2=0, nll_loss=1.171, ntokens=2651.1, nsentences=96, sample_size=2651.1, sample_size_v1=0, sample_size_v2=0, ppl=2.25, wps=924.3, ups=0.35, wpb=2651.1, bsz=96, num_updates=6900, lr=1.65644e-07, gnorm=3.068, clip=100, loss_scale=64, train_wall=29, gb_free=12.7, wall=27667
2023-04-08 23:44:26 - progress_bar.py[line:272] - INFO: epoch 012:    565 / 578 loss=2.371, loss_v1=0, loss_v2=0, nll_loss=1.172, ntokens=2626.8, nsentences=96, sample_size=2626.8, sample_size_v1=0, sample_size_v2=0, ppl=2.25, wps=922.8, ups=0.35, wpb=2626.8, bsz=96, num_updates=6910, lr=1.19632e-07, gnorm=3.014, clip=100, loss_scale=64, train_wall=28, gb_free=11.8, wall=27695
2023-04-08 23:44:54 - progress_bar.py[line:272] - INFO: epoch 012:    575 / 578 loss=2.389, loss_v1=0, loss_v2=0, nll_loss=1.193, ntokens=2565, nsentences=96, sample_size=2565, sample_size_v1=0, sample_size_v2=0, ppl=2.29, wps=901.7, ups=0.35, wpb=2565, bsz=96, num_updates=6920, lr=7.36196e-08, gnorm=2.933, clip=100, loss_scale=64, train_wall=28, gb_free=12.1, wall=27724
slice_id 1 seek offset 11440
2023-04-08 23:45:00 - train.py[line:445] - INFO: begin validation on "valid" subset
slice_id 0 seek offset 0
slice_id 0 seek offset 0
slice_id 1 seek offset 11440
['<sub> train<pred> on<obj> track<sub> window<pred> on<obj> train<sub> door<pred> on<obj> train', '<sub> man<pred> on<obj> motorcycle<pred> wearing<obj> helmet<pred> wearing<obj> jacket<pred> wearing<obj> pant<sub> motorcycle<pred> has<obj> wheel<sub> tire<pred> on<obj> motorcycle<sub> windshield<pred> on<obj> motorcycle<sub> windshield<pred> on<obj> motorcycle', '<sub> tail<pred> of<obj> plane<sub> engine<pred> of<obj> plane<sub> wing<pred> of<obj> plane<sub> tail<pred> of<obj> plane<sub> engine<pred> of<obj> plane<sub> wheel<pred> of<obj> plane', '<sub> fence<pred> behind<obj> zebra<sub> zebra<pred> has<obj> tail<pred> has<obj> head<pred> has<obj> ear<pred> has<obj> leg', '<sub> man<pred> on<obj> skateboard<pred> wearing<obj> shirt<pred> wearing<obj> pant<pred> wearing<obj> shoe<sub> skateboard<pred> under<obj> man', '<sub> bench<pred> in front of<obj> fence<sub> fence<pred> in front of<obj> bench<sub> tree<pred> behind<obj> fence'] [['<sub> windshield<pred> on<obj> train<sub> window<pred> on<obj> train<sub> train<pred> has<obj> window<sub> house<pred> near<obj> train<sub> tree<pred> near<obj> house'], ['<sub> bus<pred> under<obj> roof<sub> woman<pred> near<obj> bus<pred> wearing<obj> coat<sub> window<pred> on<obj> bus'], ['<sub> sign<pred> hanging from<obj> roof<sub> fence<pred> near<obj> cow'], ['<sub> wing<pred> on<obj> plane<sub> plane<pred> has<obj> tail<sub> fence<pred> in front of<obj> plane<sub> wheel<pred> on<obj> plane'], ['<sub> woman<pred> wearing<obj> shirt'], ['<sub> car<pred> on<obj> track<pred> near<obj> pole']]
['<sub> man<pred> wearing<obj> shirt<pred> wearing<obj> short<pred> wearing<obj> shoe<pred> wearing<obj> sock<pred> wearing<obj> shoe', '<sub> window<pred> on<obj> bus<sub> tire<pred> on<obj> bus<sub> windshield<pred> on<obj> bus<sub> windshield<pred> on<obj> bus<sub> bus<pred> on<obj> street<sub> tire<pred> on<obj> bus<sub> windshield<pred> on<obj> bus<sub> windshield<pred> on<obj> bus<sub> windshield<pred> on<obj> bus', '<sub> man<pred> wearing<obj> hat<pred> wearing<obj> shirt<pred> wearing<obj> pant<pred> wearing<obj> shoe<pred> wearing<obj> hat<pred> has<obj> head<sub> hat<pred> above<obj> head<sub> hat<pred> above<obj> head<sub> hat<pred> above<obj> head', '<sub> man<pred> on<obj> motorcycle<pred> wearing<obj> helmet<sub> wheel<pred> on<obj> motorcycle<sub> wheel<pred> on<obj> motorcycle', '<sub> man<pred> holding<obj> racket<pred> wearing<obj> short<pred> wearing<obj> shirt<pred> wearing<obj> short<pred> wearing<obj> sock<pred> wearing<obj> shoe<pred> wearing<obj> sock<pred> wearing<obj> shoe<pred> wearing<obj> sock<pred> wearing<obj> sock<pred> wearing<obj> shoe<pred> wearing<obj> sock<pred> wearing<obj> sock<pred> wearing<obj> short<pred> wearing<obj> sock<pred> wearing<obj> shoe<pred> wearing<obj> sock<pred> wearing<obj> shoe<pred> wearing<obj> sock<pred> wearing<obj> sock<pred> wearing<obj> sock<pred> wearing<obj> sock<pred> wearing<obj> sock<pred> wearing<obj> sock<pred> wearing<obj> shoe<pred> wearing<obj> sock<pred> wearing<obj> sock<pred> wearing<obj> sock<pred> wearing<obj> sock<pred> wearing<obj> sock<pred> wearing<obj> sock<pred> wearing<obj> sock<pred> wearing<obj> sock<pred> wearing<obj> sock<pred> wearing<obj> sock<pred> wearing<obj> sock<pred> wearing<obj> sock<pred> wearing<obj> sock<pred> wearing<obj> sock<pred> wearing<obj> sock<pred> wearing<obj> shoe<pred> wearing<obj> sock<pred> wearing<obj> sock<pred> wearing<obj> sock<pred> wearing<obj> sock<pred> wearing<obj> shoe<pred> wearing<obj> sock<pred> wearing<obj> sock<pred> wearing<obj> sock<pred> wearing', '<sub> man<pred> wearing<obj> tie<pred> wearing<obj> jacket<pred> wearing<obj> tie<pred> wearing<obj> shirt<pred> wearing<obj> tie<pred> has<obj> hair<sub> tie<pred> on<obj> man<sub> tie<pred> on<obj> man<sub> tie<pred> on<obj> man<sub> tie<pred> on<obj> man'] [['<sub> head<pred> of<obj> bear<sub> bear<pred> in<obj> bowl<sub> bowl<pred> with<obj> bear'], ['<sub> wheel<pred> of<obj> bus<sub> bus<pred> on<obj> street<sub> window<pred> of<obj> bus<sub> people<pred> near<obj> bus<sub> woman<pred> on<obj> bus<sub> letter<pred> on<obj> bus'], ['<sub> book<pred> under<obj> arm<sub> man<pred> wearing<obj> shirt<pred> wearing<obj> tie'], ['<sub> logo<pred> on<obj> bike<sub> woman<pred> on<obj> sidewalk<sub> sign<pred> on<obj> building<sub> bike<pred> has<obj> wheel<pred> has<obj> light<sub> wheel<pred> on<obj> bike'], ['<sub> man<pred> holding<obj> racket<pred> wearing<obj> short<pred> wearing<obj> sneaker<pred> wearing<obj> shirt<sub> men<pred> wearing<obj> short'], ['<sub> man<pred> wearing<obj> coat<pred> wearing<obj> jean<pred> on<obj> bus<pred> wearing<obj> sneaker<sub> seat<pred> near<obj> man<sub> light<pred> above<obj> man<sub> pole<pred> on<obj> bus<sub> sign<pred> on<obj> bus<sub> window<pred> on<obj> building<sub> hand<pred> of<obj> man']]
2023-04-08 23:45:21 - progress_bar.py[line:272] - INFO: epoch 012 | valid on 'valid' subset:     11 / 1907 loss=2.341, loss_v1=0, loss_v2=0, nll_loss=1.108, ntokens=336, nsentences=12, sample_size=336.0, sample_size_v1=0, sample_size_v2=0
2023-04-08 23:45:37 - progress_bar.py[line:272] - INFO: epoch 012 | valid on 'valid' subset:     21 / 1907 loss=2.439, loss_v1=0, loss_v2=0, nll_loss=1.221, ntokens=389, nsentences=12, sample_size=389.0, sample_size_v1=0, sample_size_v2=0
2023-04-08 23:45:53 - progress_bar.py[line:272] - INFO: epoch 012 | valid on 'valid' subset:     31 / 1907 loss=2.452, loss_v1=0, loss_v2=0, nll_loss=1.23, ntokens=372, nsentences=12, sample_size=372.0, sample_size_v1=0, sample_size_v2=0
2023-04-08 23:46:12 - progress_bar.py[line:272] - INFO: epoch 012 | valid on 'valid' subset:     41 / 1907 loss=2.307, loss_v1=0, loss_v2=0, nll_loss=1.072, ntokens=318, nsentences=12, sample_size=318.0, sample_size_v1=0, sample_size_v2=0
2023-04-08 23:46:29 - progress_bar.py[line:272] - INFO: epoch 012 | valid on 'valid' subset:     51 / 1907 loss=2.359, loss_v1=0, loss_v2=0, nll_loss=1.125, ntokens=352, nsentences=12, sample_size=352.0, sample_size_v1=0, sample_size_v2=0
2023-04-08 23:46:46 - progress_bar.py[line:272] - INFO: epoch 012 | valid on 'valid' subset:     61 / 1907 loss=2.397, loss_v1=0, loss_v2=0, nll_loss=1.169, ntokens=323, nsentences=12, sample_size=323.0, sample_size_v1=0, sample_size_v2=0
2023-04-08 23:47:04 - progress_bar.py[line:272] - INFO: epoch 012 | valid on 'valid' subset:     71 / 1907 loss=2.381, loss_v1=0, loss_v2=0, nll_loss=1.15, ntokens=354, nsentences=12, sample_size=354.0, sample_size_v1=0, sample_size_v2=0
2023-04-08 23:47:21 - progress_bar.py[line:272] - INFO: epoch 012 | valid on 'valid' subset:     81 / 1907 loss=2.404, loss_v1=0, loss_v2=0, nll_loss=1.183, ntokens=335, nsentences=12, sample_size=335.0, sample_size_v1=0, sample_size_v2=0
2023-04-08 23:47:36 - progress_bar.py[line:272] - INFO: epoch 012 | valid on 'valid' subset:     91 / 1907 loss=2.413, loss_v1=0, loss_v2=0, nll_loss=1.186, ntokens=296, nsentences=12, sample_size=296.0, sample_size_v1=0, sample_size_v2=0
2023-04-08 23:47:52 - progress_bar.py[line:272] - INFO: epoch 012 | valid on 'valid' subset:    101 / 1907 loss=2.452, loss_v1=0, loss_v2=0, nll_loss=1.229, ntokens=351, nsentences=12, sample_size=351.0, sample_size_v1=0, sample_size_v2=0
2023-04-08 23:48:10 - progress_bar.py[line:272] - INFO: epoch 012 | valid on 'valid' subset:    111 / 1907 loss=2.492, loss_v1=0, loss_v2=0, nll_loss=1.275, ntokens=476, nsentences=12, sample_size=476.0, sample_size_v1=0, sample_size_v2=0
2023-04-08 23:48:27 - progress_bar.py[line:272] - INFO: epoch 012 | valid on 'valid' subset:    121 / 1907 loss=2.452, loss_v1=0, loss_v2=0, nll_loss=1.23, ntokens=372, nsentences=12, sample_size=372.0, sample_size_v1=0, sample_size_v2=0
2023-04-08 23:48:45 - progress_bar.py[line:272] - INFO: epoch 012 | valid on 'valid' subset:    131 / 1907 loss=2.333, loss_v1=0, loss_v2=0, nll_loss=1.101, ntokens=297, nsentences=12, sample_size=297.0, sample_size_v1=0, sample_size_v2=0
2023-04-08 23:49:02 - progress_bar.py[line:272] - INFO: epoch 012 | valid on 'valid' subset:    141 / 1907 loss=2.4, loss_v1=0, loss_v2=0, nll_loss=1.174, ntokens=481, nsentences=12, sample_size=481.0, sample_size_v1=0, sample_size_v2=0
2023-04-08 23:49:21 - progress_bar.py[line:272] - INFO: epoch 012 | valid on 'valid' subset:    151 / 1907 loss=2.375, loss_v1=0, loss_v2=0, nll_loss=1.146, ntokens=325, nsentences=12, sample_size=325.0, sample_size_v1=0, sample_size_v2=0
2023-04-08 23:49:38 - progress_bar.py[line:272] - INFO: epoch 012 | valid on 'valid' subset:    161 / 1907 loss=2.439, loss_v1=0, loss_v2=0, nll_loss=1.22, ntokens=357, nsentences=12, sample_size=357.0, sample_size_v1=0, sample_size_v2=0
2023-04-08 23:49:54 - progress_bar.py[line:272] - INFO: epoch 012 | valid on 'valid' subset:    171 / 1907 loss=2.425, loss_v1=0, loss_v2=0, nll_loss=1.201, ntokens=405, nsentences=12, sample_size=405.0, sample_size_v1=0, sample_size_v2=0
2023-04-08 23:50:11 - progress_bar.py[line:272] - INFO: epoch 012 | valid on 'valid' subset:    181 / 1907 loss=2.518, loss_v1=0, loss_v2=0, nll_loss=1.306, ntokens=459, nsentences=12, sample_size=459.0, sample_size_v1=0, sample_size_v2=0
2023-04-08 23:50:26 - progress_bar.py[line:272] - INFO: epoch 012 | valid on 'valid' subset:    191 / 1907 loss=2.284, loss_v1=0, loss_v2=0, nll_loss=1.045, ntokens=238, nsentences=12, sample_size=238.0, sample_size_v1=0, sample_size_v2=0
2023-04-08 23:50:44 - progress_bar.py[line:272] - INFO: epoch 012 | valid on 'valid' subset:    201 / 1907 loss=2.644, loss_v1=0, loss_v2=0, nll_loss=1.444, ntokens=366, nsentences=12, sample_size=366.0, sample_size_v1=0, sample_size_v2=0
2023-04-08 23:51:01 - progress_bar.py[line:272] - INFO: epoch 012 | valid on 'valid' subset:    211 / 1907 loss=2.442, loss_v1=0, loss_v2=0, nll_loss=1.22, ntokens=315, nsentences=12, sample_size=315.0, sample_size_v1=0, sample_size_v2=0
2023-04-08 23:51:20 - progress_bar.py[line:272] - INFO: epoch 012 | valid on 'valid' subset:    221 / 1907 loss=2.475, loss_v1=0, loss_v2=0, nll_loss=1.26, ntokens=416, nsentences=12, sample_size=416.0, sample_size_v1=0, sample_size_v2=0
2023-04-08 23:51:38 - progress_bar.py[line:272] - INFO: epoch 012 | valid on 'valid' subset:    231 / 1907 loss=2.386, loss_v1=0, loss_v2=0, nll_loss=1.154, ntokens=246, nsentences=12, sample_size=246.0, sample_size_v1=0, sample_size_v2=0
2023-04-08 23:51:55 - progress_bar.py[line:272] - INFO: epoch 012 | valid on 'valid' subset:    241 / 1907 loss=2.407, loss_v1=0, loss_v2=0, nll_loss=1.18, ntokens=311, nsentences=12, sample_size=311.0, sample_size_v1=0, sample_size_v2=0
2023-04-08 23:52:12 - progress_bar.py[line:272] - INFO: epoch 012 | valid on 'valid' subset:    251 / 1907 loss=2.497, loss_v1=0, loss_v2=0, nll_loss=1.282, ntokens=378, nsentences=12, sample_size=378.0, sample_size_v1=0, sample_size_v2=0
2023-04-08 23:52:29 - progress_bar.py[line:272] - INFO: epoch 012 | valid on 'valid' subset:    261 / 1907 loss=2.386, loss_v1=0, loss_v2=0, nll_loss=1.158, ntokens=442, nsentences=12, sample_size=442.0, sample_size_v1=0, sample_size_v2=0
2023-04-08 23:52:45 - progress_bar.py[line:272] - INFO: epoch 012 | valid on 'valid' subset:    271 / 1907 loss=2.508, loss_v1=0, loss_v2=0, nll_loss=1.294, ntokens=313, nsentences=12, sample_size=313.0, sample_size_v1=0, sample_size_v2=0
2023-04-08 23:53:02 - progress_bar.py[line:272] - INFO: epoch 012 | valid on 'valid' subset:    281 / 1907 loss=2.364, loss_v1=0, loss_v2=0, nll_loss=1.135, ntokens=303, nsentences=12, sample_size=303.0, sample_size_v1=0, sample_size_v2=0
2023-04-08 23:53:21 - progress_bar.py[line:272] - INFO: epoch 012 | valid on 'valid' subset:    291 / 1907 loss=2.42, loss_v1=0, loss_v2=0, nll_loss=1.197, ntokens=313, nsentences=12, sample_size=313.0, sample_size_v1=0, sample_size_v2=0
2023-04-08 23:53:38 - progress_bar.py[line:272] - INFO: epoch 012 | valid on 'valid' subset:    301 / 1907 loss=2.321, loss_v1=0, loss_v2=0, nll_loss=1.086, ntokens=333, nsentences=12, sample_size=333.0, sample_size_v1=0, sample_size_v2=0
2023-04-08 23:53:56 - progress_bar.py[line:272] - INFO: epoch 012 | valid on 'valid' subset:    311 / 1907 loss=2.49, loss_v1=0, loss_v2=0, nll_loss=1.273, ntokens=364, nsentences=12, sample_size=364.0, sample_size_v1=0, sample_size_v2=0
2023-04-08 23:54:10 - progress_bar.py[line:272] - INFO: epoch 012 | valid on 'valid' subset:    321 / 1907 loss=2.256, loss_v1=0, loss_v2=0, nll_loss=1.012, ntokens=303, nsentences=12, sample_size=303.0, sample_size_v1=0, sample_size_v2=0
2023-04-08 23:54:28 - progress_bar.py[line:272] - INFO: epoch 012 | valid on 'valid' subset:    331 / 1907 loss=2.363, loss_v1=0, loss_v2=0, nll_loss=1.127, ntokens=300, nsentences=12, sample_size=300.0, sample_size_v1=0, sample_size_v2=0
2023-04-08 23:54:45 - progress_bar.py[line:272] - INFO: epoch 012 | valid on 'valid' subset:    341 / 1907 loss=2.305, loss_v1=0, loss_v2=0, nll_loss=1.067, ntokens=264, nsentences=12, sample_size=264.0, sample_size_v1=0, sample_size_v2=0
2023-04-08 23:55:00 - progress_bar.py[line:272] - INFO: epoch 012 | valid on 'valid' subset:    351 / 1907 loss=2.515, loss_v1=0, loss_v2=0, nll_loss=1.302, ntokens=320, nsentences=12, sample_size=320.0, sample_size_v1=0, sample_size_v2=0
2023-04-08 23:55:15 - progress_bar.py[line:272] - INFO: epoch 012 | valid on 'valid' subset:    361 / 1907 loss=2.516, loss_v1=0, loss_v2=0, nll_loss=1.303, ntokens=293, nsentences=12, sample_size=293.0, sample_size_v1=0, sample_size_v2=0
2023-04-08 23:55:29 - progress_bar.py[line:272] - INFO: epoch 012 | valid on 'valid' subset:    371 / 1907 loss=2.454, loss_v1=0, loss_v2=0, nll_loss=1.233, ntokens=314, nsentences=12, sample_size=314.0, sample_size_v1=0, sample_size_v2=0
2023-04-08 23:55:44 - progress_bar.py[line:272] - INFO: epoch 012 | valid on 'valid' subset:    381 / 1907 loss=2.293, loss_v1=0, loss_v2=0, nll_loss=1.056, ntokens=350, nsentences=12, sample_size=350.0, sample_size_v1=0, sample_size_v2=0
2023-04-08 23:56:01 - progress_bar.py[line:272] - INFO: epoch 012 | valid on 'valid' subset:    391 / 1907 loss=2.405, loss_v1=0, loss_v2=0, nll_loss=1.177, ntokens=235, nsentences=12, sample_size=235.0, sample_size_v1=0, sample_size_v2=0
2023-04-08 23:56:19 - progress_bar.py[line:272] - INFO: epoch 012 | valid on 'valid' subset:    401 / 1907 loss=2.485, loss_v1=0, loss_v2=0, nll_loss=1.27, ntokens=323, nsentences=12, sample_size=323.0, sample_size_v1=0, sample_size_v2=0
2023-04-08 23:56:38 - progress_bar.py[line:272] - INFO: epoch 012 | valid on 'valid' subset:    411 / 1907 loss=2.411, loss_v1=0, loss_v2=0, nll_loss=1.185, ntokens=268, nsentences=12, sample_size=268.0, sample_size_v1=0, sample_size_v2=0
2023-04-08 23:56:56 - progress_bar.py[line:272] - INFO: epoch 012 | valid on 'valid' subset:    421 / 1907 loss=2.454, loss_v1=0, loss_v2=0, nll_loss=1.239, ntokens=314, nsentences=12, sample_size=314.0, sample_size_v1=0, sample_size_v2=0
2023-04-08 23:57:15 - progress_bar.py[line:272] - INFO: epoch 012 | valid on 'valid' subset:    431 / 1907 loss=2.416, loss_v1=0, loss_v2=0, nll_loss=1.192, ntokens=362, nsentences=12, sample_size=362.0, sample_size_v1=0, sample_size_v2=0
2023-04-08 23:57:33 - progress_bar.py[line:272] - INFO: epoch 012 | valid on 'valid' subset:    441 / 1907 loss=2.485, loss_v1=0, loss_v2=0, nll_loss=1.268, ntokens=303, nsentences=12, sample_size=303.0, sample_size_v1=0, sample_size_v2=0
2023-04-08 23:57:47 - progress_bar.py[line:272] - INFO: epoch 012 | valid on 'valid' subset:    451 / 1907 loss=2.418, loss_v1=0, loss_v2=0, nll_loss=1.195, ntokens=307, nsentences=12, sample_size=307.0, sample_size_v1=0, sample_size_v2=0
2023-04-08 23:58:04 - progress_bar.py[line:272] - INFO: epoch 012 | valid on 'valid' subset:    461 / 1907 loss=2.537, loss_v1=0, loss_v2=0, nll_loss=1.329, ntokens=375, nsentences=12, sample_size=375.0, sample_size_v1=0, sample_size_v2=0
2023-04-08 23:58:22 - progress_bar.py[line:272] - INFO: epoch 012 | valid on 'valid' subset:    471 / 1907 loss=2.442, loss_v1=0, loss_v2=0, nll_loss=1.221, ntokens=343, nsentences=12, sample_size=343.0, sample_size_v1=0, sample_size_v2=0
2023-04-08 23:58:40 - progress_bar.py[line:272] - INFO: epoch 012 | valid on 'valid' subset:    481 / 1907 loss=2.405, loss_v1=0, loss_v2=0, nll_loss=1.179, ntokens=322, nsentences=12, sample_size=322.0, sample_size_v1=0, sample_size_v2=0
2023-04-08 23:58:58 - progress_bar.py[line:272] - INFO: epoch 012 | valid on 'valid' subset:    491 / 1907 loss=2.449, loss_v1=0, loss_v2=0, nll_loss=1.227, ntokens=271, nsentences=12, sample_size=271.0, sample_size_v1=0, sample_size_v2=0
2023-04-08 23:59:15 - progress_bar.py[line:272] - INFO: epoch 012 | valid on 'valid' subset:    501 / 1907 loss=2.409, loss_v1=0, loss_v2=0, nll_loss=1.184, ntokens=419, nsentences=12, sample_size=419.0, sample_size_v1=0, sample_size_v2=0
2023-04-08 23:59:33 - progress_bar.py[line:272] - INFO: epoch 012 | valid on 'valid' subset:    511 / 1907 loss=2.392, loss_v1=0, loss_v2=0, nll_loss=1.164, ntokens=304, nsentences=12, sample_size=304.0, sample_size_v1=0, sample_size_v2=0
2023-04-08 23:59:51 - progress_bar.py[line:272] - INFO: epoch 012 | valid on 'valid' subset:    521 / 1907 loss=2.274, loss_v1=0, loss_v2=0, nll_loss=1.035, ntokens=371, nsentences=12, sample_size=371.0, sample_size_v1=0, sample_size_v2=0
2023-04-09 00:00:09 - progress_bar.py[line:272] - INFO: epoch 012 | valid on 'valid' subset:    531 / 1907 loss=2.472, loss_v1=0, loss_v2=0, nll_loss=1.255, ntokens=376, nsentences=12, sample_size=376.0, sample_size_v1=0, sample_size_v2=0
2023-04-09 00:00:26 - progress_bar.py[line:272] - INFO: epoch 012 | valid on 'valid' subset:    541 / 1907 loss=2.365, loss_v1=0, loss_v2=0, nll_loss=1.134, ntokens=328, nsentences=12, sample_size=328.0, sample_size_v1=0, sample_size_v2=0
2023-04-09 00:00:42 - progress_bar.py[line:272] - INFO: epoch 012 | valid on 'valid' subset:    551 / 1907 loss=2.361, loss_v1=0, loss_v2=0, nll_loss=1.129, ntokens=221, nsentences=12, sample_size=221.0, sample_size_v1=0, sample_size_v2=0
2023-04-09 00:00:59 - progress_bar.py[line:272] - INFO: epoch 012 | valid on 'valid' subset:    561 / 1907 loss=2.443, loss_v1=0, loss_v2=0, nll_loss=1.22, ntokens=286, nsentences=12, sample_size=286.0, sample_size_v1=0, sample_size_v2=0
2023-04-09 00:01:16 - progress_bar.py[line:272] - INFO: epoch 012 | valid on 'valid' subset:    571 / 1907 loss=2.379, loss_v1=0, loss_v2=0, nll_loss=1.151, ntokens=413, nsentences=12, sample_size=413.0, sample_size_v1=0, sample_size_v2=0
2023-04-09 00:01:33 - progress_bar.py[line:272] - INFO: epoch 012 | valid on 'valid' subset:    581 / 1907 loss=2.46, loss_v1=0, loss_v2=0, nll_loss=1.239, ntokens=292, nsentences=12, sample_size=292.0, sample_size_v1=0, sample_size_v2=0
2023-04-09 00:01:47 - progress_bar.py[line:272] - INFO: epoch 012 | valid on 'valid' subset:    591 / 1907 loss=2.479, loss_v1=0, loss_v2=0, nll_loss=1.258, ntokens=342, nsentences=12, sample_size=342.0, sample_size_v1=0, sample_size_v2=0
2023-04-09 00:02:03 - progress_bar.py[line:272] - INFO: epoch 012 | valid on 'valid' subset:    601 / 1907 loss=2.48, loss_v1=0, loss_v2=0, nll_loss=1.266, ntokens=332, nsentences=12, sample_size=332.0, sample_size_v1=0, sample_size_v2=0
2023-04-09 00:02:22 - progress_bar.py[line:272] - INFO: epoch 012 | valid on 'valid' subset:    611 / 1907 loss=2.56, loss_v1=0, loss_v2=0, nll_loss=1.353, ntokens=309, nsentences=12, sample_size=309.0, sample_size_v1=0, sample_size_v2=0
2023-04-09 00:02:40 - progress_bar.py[line:272] - INFO: epoch 012 | valid on 'valid' subset:    621 / 1907 loss=2.357, loss_v1=0, loss_v2=0, nll_loss=1.125, ntokens=377, nsentences=12, sample_size=377.0, sample_size_v1=0, sample_size_v2=0
2023-04-09 00:02:58 - progress_bar.py[line:272] - INFO: epoch 012 | valid on 'valid' subset:    631 / 1907 loss=2.462, loss_v1=0, loss_v2=0, nll_loss=1.244, ntokens=277, nsentences=12, sample_size=277.0, sample_size_v1=0, sample_size_v2=0
2023-04-09 00:03:17 - progress_bar.py[line:272] - INFO: epoch 012 | valid on 'valid' subset:    641 / 1907 loss=2.268, loss_v1=0, loss_v2=0, nll_loss=1.03, ntokens=349, nsentences=12, sample_size=349.0, sample_size_v1=0, sample_size_v2=0
2023-04-09 00:03:35 - progress_bar.py[line:272] - INFO: epoch 012 | valid on 'valid' subset:    651 / 1907 loss=2.377, loss_v1=0, loss_v2=0, nll_loss=1.146, ntokens=330, nsentences=12, sample_size=330.0, sample_size_v1=0, sample_size_v2=0
2023-04-09 00:03:51 - progress_bar.py[line:272] - INFO: epoch 012 | valid on 'valid' subset:    661 / 1907 loss=2.419, loss_v1=0, loss_v2=0, nll_loss=1.194, ntokens=328, nsentences=12, sample_size=328.0, sample_size_v1=0, sample_size_v2=0
2023-04-09 00:04:08 - progress_bar.py[line:272] - INFO: epoch 012 | valid on 'valid' subset:    671 / 1907 loss=2.355, loss_v1=0, loss_v2=0, nll_loss=1.126, ntokens=367, nsentences=12, sample_size=367.0, sample_size_v1=0, sample_size_v2=0
2023-04-09 00:04:27 - progress_bar.py[line:272] - INFO: epoch 012 | valid on 'valid' subset:    681 / 1907 loss=2.519, loss_v1=0, loss_v2=0, nll_loss=1.306, ntokens=399, nsentences=12, sample_size=399.0, sample_size_v1=0, sample_size_v2=0
2023-04-09 00:04:45 - progress_bar.py[line:272] - INFO: epoch 012 | valid on 'valid' subset:    691 / 1907 loss=2.292, loss_v1=0, loss_v2=0, nll_loss=1.059, ntokens=267, nsentences=12, sample_size=267.0, sample_size_v1=0, sample_size_v2=0
2023-04-09 00:05:02 - progress_bar.py[line:272] - INFO: epoch 012 | valid on 'valid' subset:    701 / 1907 loss=2.436, loss_v1=0, loss_v2=0, nll_loss=1.216, ntokens=358, nsentences=12, sample_size=358.0, sample_size_v1=0, sample_size_v2=0
2023-04-09 00:05:20 - progress_bar.py[line:272] - INFO: epoch 012 | valid on 'valid' subset:    711 / 1907 loss=2.362, loss_v1=0, loss_v2=0, nll_loss=1.13, ntokens=398, nsentences=12, sample_size=398.0, sample_size_v1=0, sample_size_v2=0
2023-04-09 00:05:38 - progress_bar.py[line:272] - INFO: epoch 012 | valid on 'valid' subset:    721 / 1907 loss=2.52, loss_v1=0, loss_v2=0, nll_loss=1.309, ntokens=269, nsentences=12, sample_size=269.0, sample_size_v1=0, sample_size_v2=0
2023-04-09 00:05:54 - progress_bar.py[line:272] - INFO: epoch 012 | valid on 'valid' subset:    731 / 1907 loss=2.481, loss_v1=0, loss_v2=0, nll_loss=1.263, ntokens=293, nsentences=12, sample_size=293.0, sample_size_v1=0, sample_size_v2=0
2023-04-09 00:06:12 - progress_bar.py[line:272] - INFO: epoch 012 | valid on 'valid' subset:    741 / 1907 loss=2.52, loss_v1=0, loss_v2=0, nll_loss=1.311, ntokens=456, nsentences=12, sample_size=456.0, sample_size_v1=0, sample_size_v2=0
2023-04-09 00:06:28 - progress_bar.py[line:272] - INFO: epoch 012 | valid on 'valid' subset:    751 / 1907 loss=2.29, loss_v1=0, loss_v2=0, nll_loss=1.053, ntokens=310, nsentences=12, sample_size=310.0, sample_size_v1=0, sample_size_v2=0
2023-04-09 00:06:47 - progress_bar.py[line:272] - INFO: epoch 012 | valid on 'valid' subset:    761 / 1907 loss=2.407, loss_v1=0, loss_v2=0, nll_loss=1.18, ntokens=282, nsentences=12, sample_size=282.0, sample_size_v1=0, sample_size_v2=0
2023-04-09 00:07:04 - progress_bar.py[line:272] - INFO: epoch 012 | valid on 'valid' subset:    771 / 1907 loss=2.396, loss_v1=0, loss_v2=0, nll_loss=1.169, ntokens=348, nsentences=12, sample_size=348.0, sample_size_v1=0, sample_size_v2=0
2023-04-09 00:07:22 - progress_bar.py[line:272] - INFO: epoch 012 | valid on 'valid' subset:    781 / 1907 loss=2.36, loss_v1=0, loss_v2=0, nll_loss=1.129, ntokens=342, nsentences=12, sample_size=342.0, sample_size_v1=0, sample_size_v2=0
2023-04-09 00:07:40 - progress_bar.py[line:272] - INFO: epoch 012 | valid on 'valid' subset:    791 / 1907 loss=2.338, loss_v1=0, loss_v2=0, nll_loss=1.106, ntokens=329, nsentences=12, sample_size=329.0, sample_size_v1=0, sample_size_v2=0
2023-04-09 00:07:59 - progress_bar.py[line:272] - INFO: epoch 012 | valid on 'valid' subset:    801 / 1907 loss=2.217, loss_v1=0, loss_v2=0, nll_loss=0.967, ntokens=316, nsentences=12, sample_size=316.0, sample_size_v1=0, sample_size_v2=0
2023-04-09 00:08:17 - progress_bar.py[line:272] - INFO: epoch 012 | valid on 'valid' subset:    811 / 1907 loss=2.418, loss_v1=0, loss_v2=0, nll_loss=1.192, ntokens=300, nsentences=12, sample_size=300.0, sample_size_v1=0, sample_size_v2=0
2023-04-09 00:08:35 - progress_bar.py[line:272] - INFO: epoch 012 | valid on 'valid' subset:    821 / 1907 loss=2.425, loss_v1=0, loss_v2=0, nll_loss=1.202, ntokens=368, nsentences=12, sample_size=368.0, sample_size_v1=0, sample_size_v2=0
2023-04-09 00:08:51 - progress_bar.py[line:272] - INFO: epoch 012 | valid on 'valid' subset:    831 / 1907 loss=2.4, loss_v1=0, loss_v2=0, nll_loss=1.171, ntokens=317, nsentences=12, sample_size=317.0, sample_size_v1=0, sample_size_v2=0
2023-04-09 00:09:10 - progress_bar.py[line:272] - INFO: epoch 012 | valid on 'valid' subset:    841 / 1907 loss=2.501, loss_v1=0, loss_v2=0, nll_loss=1.289, ntokens=289, nsentences=12, sample_size=289.0, sample_size_v1=0, sample_size_v2=0
2023-04-09 00:09:26 - progress_bar.py[line:272] - INFO: epoch 012 | valid on 'valid' subset:    851 / 1907 loss=2.384, loss_v1=0, loss_v2=0, nll_loss=1.155, ntokens=333, nsentences=12, sample_size=333.0, sample_size_v1=0, sample_size_v2=0
2023-04-09 00:09:45 - progress_bar.py[line:272] - INFO: epoch 012 | valid on 'valid' subset:    861 / 1907 loss=2.447, loss_v1=0, loss_v2=0, nll_loss=1.227, ntokens=394, nsentences=12, sample_size=394.0, sample_size_v1=0, sample_size_v2=0
2023-04-09 00:10:02 - progress_bar.py[line:272] - INFO: epoch 012 | valid on 'valid' subset:    871 / 1907 loss=2.472, loss_v1=0, loss_v2=0, nll_loss=1.256, ntokens=339, nsentences=12, sample_size=339.0, sample_size_v1=0, sample_size_v2=0
2023-04-09 00:10:19 - progress_bar.py[line:272] - INFO: epoch 012 | valid on 'valid' subset:    881 / 1907 loss=2.343, loss_v1=0, loss_v2=0, nll_loss=1.111, ntokens=321, nsentences=12, sample_size=321.0, sample_size_v1=0, sample_size_v2=0
2023-04-09 00:10:35 - progress_bar.py[line:272] - INFO: epoch 012 | valid on 'valid' subset:    891 / 1907 loss=2.456, loss_v1=0, loss_v2=0, nll_loss=1.237, ntokens=334, nsentences=12, sample_size=334.0, sample_size_v1=0, sample_size_v2=0
2023-04-09 00:10:54 - progress_bar.py[line:272] - INFO: epoch 012 | valid on 'valid' subset:    901 / 1907 loss=2.455, loss_v1=0, loss_v2=0, nll_loss=1.231, ntokens=344, nsentences=12, sample_size=344.0, sample_size_v1=0, sample_size_v2=0
2023-04-09 00:11:11 - progress_bar.py[line:272] - INFO: epoch 012 | valid on 'valid' subset:    911 / 1907 loss=2.44, loss_v1=0, loss_v2=0, nll_loss=1.219, ntokens=408, nsentences=12, sample_size=408.0, sample_size_v1=0, sample_size_v2=0
2023-04-09 00:11:27 - progress_bar.py[line:272] - INFO: epoch 012 | valid on 'valid' subset:    921 / 1907 loss=2.358, loss_v1=0, loss_v2=0, nll_loss=1.129, ntokens=400, nsentences=12, sample_size=400.0, sample_size_v1=0, sample_size_v2=0
2023-04-09 00:11:45 - progress_bar.py[line:272] - INFO: epoch 012 | valid on 'valid' subset:    931 / 1907 loss=2.457, loss_v1=0, loss_v2=0, nll_loss=1.239, ntokens=547, nsentences=12, sample_size=547.0, sample_size_v1=0, sample_size_v2=0
2023-04-09 00:12:03 - progress_bar.py[line:272] - INFO: epoch 012 | valid on 'valid' subset:    941 / 1907 loss=2.538, loss_v1=0, loss_v2=0, nll_loss=1.327, ntokens=320, nsentences=12, sample_size=320.0, sample_size_v1=0, sample_size_v2=0
2023-04-09 00:12:19 - progress_bar.py[line:272] - INFO: epoch 012 | valid on 'valid' subset:    951 / 1907 loss=2.448, loss_v1=0, loss_v2=0, nll_loss=1.224, ntokens=289, nsentences=12, sample_size=289.0, sample_size_v1=0, sample_size_v2=0
2023-04-09 00:12:36 - progress_bar.py[line:272] - INFO: epoch 012 | valid on 'valid' subset:    961 / 1907 loss=2.378, loss_v1=0, loss_v2=0, nll_loss=1.149, ntokens=358, nsentences=12, sample_size=358.0, sample_size_v1=0, sample_size_v2=0
2023-04-09 00:12:53 - progress_bar.py[line:272] - INFO: epoch 012 | valid on 'valid' subset:    971 / 1907 loss=2.385, loss_v1=0, loss_v2=0, nll_loss=1.158, ntokens=256, nsentences=12, sample_size=256.0, sample_size_v1=0, sample_size_v2=0
2023-04-09 00:13:10 - progress_bar.py[line:272] - INFO: epoch 012 | valid on 'valid' subset:    981 / 1907 loss=2.397, loss_v1=0, loss_v2=0, nll_loss=1.168, ntokens=367, nsentences=12, sample_size=367.0, sample_size_v1=0, sample_size_v2=0
2023-04-09 00:13:27 - progress_bar.py[line:272] - INFO: epoch 012 | valid on 'valid' subset:    991 / 1907 loss=2.499, loss_v1=0, loss_v2=0, nll_loss=1.283, ntokens=338, nsentences=12, sample_size=338.0, sample_size_v1=0, sample_size_v2=0
2023-04-09 00:13:45 - progress_bar.py[line:272] - INFO: epoch 012 | valid on 'valid' subset:   1001 / 1907 loss=2.433, loss_v1=0, loss_v2=0, nll_loss=1.21, ntokens=242, nsentences=12, sample_size=242.0, sample_size_v1=0, sample_size_v2=0
2023-04-09 00:14:00 - progress_bar.py[line:272] - INFO: epoch 012 | valid on 'valid' subset:   1011 / 1907 loss=2.361, loss_v1=0, loss_v2=0, nll_loss=1.132, ntokens=359, nsentences=12, sample_size=359.0, sample_size_v1=0, sample_size_v2=0
2023-04-09 00:14:19 - progress_bar.py[line:272] - INFO: epoch 012 | valid on 'valid' subset:   1021 / 1907 loss=2.491, loss_v1=0, loss_v2=0, nll_loss=1.276, ntokens=363, nsentences=12, sample_size=363.0, sample_size_v1=0, sample_size_v2=0
2023-04-09 00:14:36 - progress_bar.py[line:272] - INFO: epoch 012 | valid on 'valid' subset:   1031 / 1907 loss=2.376, loss_v1=0, loss_v2=0, nll_loss=1.148, ntokens=354, nsentences=12, sample_size=354.0, sample_size_v1=0, sample_size_v2=0
2023-04-09 00:14:53 - progress_bar.py[line:272] - INFO: epoch 012 | valid on 'valid' subset:   1041 / 1907 loss=2.339, loss_v1=0, loss_v2=0, nll_loss=1.108, ntokens=362, nsentences=12, sample_size=362.0, sample_size_v1=0, sample_size_v2=0
2023-04-09 00:15:10 - progress_bar.py[line:272] - INFO: epoch 012 | valid on 'valid' subset:   1051 / 1907 loss=2.529, loss_v1=0, loss_v2=0, nll_loss=1.318, ntokens=318, nsentences=12, sample_size=318.0, sample_size_v1=0, sample_size_v2=0
2023-04-09 00:15:27 - progress_bar.py[line:272] - INFO: epoch 012 | valid on 'valid' subset:   1061 / 1907 loss=2.283, loss_v1=0, loss_v2=0, nll_loss=1.043, ntokens=426, nsentences=12, sample_size=426.0, sample_size_v1=0, sample_size_v2=0
2023-04-09 00:15:46 - progress_bar.py[line:272] - INFO: epoch 012 | valid on 'valid' subset:   1071 / 1907 loss=2.464, loss_v1=0, loss_v2=0, nll_loss=1.241, ntokens=269, nsentences=12, sample_size=269.0, sample_size_v1=0, sample_size_v2=0
2023-04-09 00:16:03 - progress_bar.py[line:272] - INFO: epoch 012 | valid on 'valid' subset:   1081 / 1907 loss=2.418, loss_v1=0, loss_v2=0, nll_loss=1.189, ntokens=282, nsentences=12, sample_size=282.0, sample_size_v1=0, sample_size_v2=0
2023-04-09 00:16:21 - progress_bar.py[line:272] - INFO: epoch 012 | valid on 'valid' subset:   1091 / 1907 loss=2.394, loss_v1=0, loss_v2=0, nll_loss=1.169, ntokens=297, nsentences=12, sample_size=297.0, sample_size_v1=0, sample_size_v2=0
2023-04-09 00:16:38 - progress_bar.py[line:272] - INFO: epoch 012 | valid on 'valid' subset:   1101 / 1907 loss=2.429, loss_v1=0, loss_v2=0, nll_loss=1.206, ntokens=373, nsentences=12, sample_size=373.0, sample_size_v1=0, sample_size_v2=0
2023-04-09 00:16:55 - progress_bar.py[line:272] - INFO: epoch 012 | valid on 'valid' subset:   1111 / 1907 loss=2.438, loss_v1=0, loss_v2=0, nll_loss=1.219, ntokens=351, nsentences=12, sample_size=351.0, sample_size_v1=0, sample_size_v2=0
2023-04-09 00:17:13 - progress_bar.py[line:272] - INFO: epoch 012 | valid on 'valid' subset:   1121 / 1907 loss=2.521, loss_v1=0, loss_v2=0, nll_loss=1.308, ntokens=268, nsentences=12, sample_size=268.0, sample_size_v1=0, sample_size_v2=0
2023-04-09 00:17:31 - progress_bar.py[line:272] - INFO: epoch 012 | valid on 'valid' subset:   1131 / 1907 loss=2.49, loss_v1=0, loss_v2=0, nll_loss=1.275, ntokens=253, nsentences=12, sample_size=253.0, sample_size_v1=0, sample_size_v2=0
2023-04-09 00:17:48 - progress_bar.py[line:272] - INFO: epoch 012 | valid on 'valid' subset:   1141 / 1907 loss=2.479, loss_v1=0, loss_v2=0, nll_loss=1.262, ntokens=326, nsentences=12, sample_size=326.0, sample_size_v1=0, sample_size_v2=0
2023-04-09 00:18:06 - progress_bar.py[line:272] - INFO: epoch 012 | valid on 'valid' subset:   1151 / 1907 loss=2.49, loss_v1=0, loss_v2=0, nll_loss=1.276, ntokens=334, nsentences=12, sample_size=334.0, sample_size_v1=0, sample_size_v2=0
2023-04-09 00:18:23 - progress_bar.py[line:272] - INFO: epoch 012 | valid on 'valid' subset:   1161 / 1907 loss=2.415, loss_v1=0, loss_v2=0, nll_loss=1.19, ntokens=346, nsentences=12, sample_size=346.0, sample_size_v1=0, sample_size_v2=0
2023-04-09 00:18:40 - progress_bar.py[line:272] - INFO: epoch 012 | valid on 'valid' subset:   1171 / 1907 loss=2.358, loss_v1=0, loss_v2=0, nll_loss=1.124, ntokens=391, nsentences=12, sample_size=391.0, sample_size_v1=0, sample_size_v2=0
2023-04-09 00:18:55 - progress_bar.py[line:272] - INFO: epoch 012 | valid on 'valid' subset:   1181 / 1907 loss=2.419, loss_v1=0, loss_v2=0, nll_loss=1.197, ntokens=212, nsentences=12, sample_size=212.0, sample_size_v1=0, sample_size_v2=0
2023-04-09 00:19:13 - progress_bar.py[line:272] - INFO: epoch 012 | valid on 'valid' subset:   1191 / 1907 loss=2.446, loss_v1=0, loss_v2=0, nll_loss=1.224, ntokens=536, nsentences=12, sample_size=536.0, sample_size_v1=0, sample_size_v2=0
2023-04-09 00:19:30 - progress_bar.py[line:272] - INFO: epoch 012 | valid on 'valid' subset:   1201 / 1907 loss=2.386, loss_v1=0, loss_v2=0, nll_loss=1.157, ntokens=376, nsentences=12, sample_size=376.0, sample_size_v1=0, sample_size_v2=0
2023-04-09 00:19:47 - progress_bar.py[line:272] - INFO: epoch 012 | valid on 'valid' subset:   1211 / 1907 loss=2.401, loss_v1=0, loss_v2=0, nll_loss=1.171, ntokens=240, nsentences=12, sample_size=240.0, sample_size_v1=0, sample_size_v2=0
2023-04-09 00:20:03 - progress_bar.py[line:272] - INFO: epoch 012 | valid on 'valid' subset:   1221 / 1907 loss=2.427, loss_v1=0, loss_v2=0, nll_loss=1.205, ntokens=297, nsentences=12, sample_size=297.0, sample_size_v1=0, sample_size_v2=0
2023-04-09 00:20:19 - progress_bar.py[line:272] - INFO: epoch 012 | valid on 'valid' subset:   1231 / 1907 loss=2.446, loss_v1=0, loss_v2=0, nll_loss=1.224, ntokens=288, nsentences=12, sample_size=288.0, sample_size_v1=0, sample_size_v2=0
2023-04-09 00:20:36 - progress_bar.py[line:272] - INFO: epoch 012 | valid on 'valid' subset:   1241 / 1907 loss=2.43, loss_v1=0, loss_v2=0, nll_loss=1.206, ntokens=288, nsentences=12, sample_size=288.0, sample_size_v1=0, sample_size_v2=0
2023-04-09 00:20:53 - progress_bar.py[line:272] - INFO: epoch 012 | valid on 'valid' subset:   1251 / 1907 loss=2.308, loss_v1=0, loss_v2=0, nll_loss=1.075, ntokens=290, nsentences=12, sample_size=290.0, sample_size_v1=0, sample_size_v2=0
2023-04-09 00:21:11 - progress_bar.py[line:272] - INFO: epoch 012 | valid on 'valid' subset:   1261 / 1907 loss=2.311, loss_v1=0, loss_v2=0, nll_loss=1.072, ntokens=278, nsentences=12, sample_size=278.0, sample_size_v1=0, sample_size_v2=0
2023-04-09 00:21:26 - progress_bar.py[line:272] - INFO: epoch 012 | valid on 'valid' subset:   1271 / 1907 loss=2.332, loss_v1=0, loss_v2=0, nll_loss=1.099, ntokens=309, nsentences=12, sample_size=309.0, sample_size_v1=0, sample_size_v2=0
2023-04-09 00:21:42 - progress_bar.py[line:272] - INFO: epoch 012 | valid on 'valid' subset:   1281 / 1907 loss=2.455, loss_v1=0, loss_v2=0, nll_loss=1.237, ntokens=247, nsentences=12, sample_size=247.0, sample_size_v1=0, sample_size_v2=0
2023-04-09 00:21:56 - progress_bar.py[line:272] - INFO: epoch 012 | valid on 'valid' subset:   1291 / 1907 loss=2.358, loss_v1=0, loss_v2=0, nll_loss=1.13, ntokens=259, nsentences=12, sample_size=259.0, sample_size_v1=0, sample_size_v2=0
2023-04-09 00:22:10 - progress_bar.py[line:272] - INFO: epoch 012 | valid on 'valid' subset:   1301 / 1907 loss=2.418, loss_v1=0, loss_v2=0, nll_loss=1.194, ntokens=253, nsentences=12, sample_size=253.0, sample_size_v1=0, sample_size_v2=0
2023-04-09 00:22:26 - progress_bar.py[line:272] - INFO: epoch 012 | valid on 'valid' subset:   1311 / 1907 loss=2.624, loss_v1=0, loss_v2=0, nll_loss=1.428, ntokens=253, nsentences=12, sample_size=253.0, sample_size_v1=0, sample_size_v2=0
2023-04-09 00:22:41 - progress_bar.py[line:272] - INFO: epoch 012 | valid on 'valid' subset:   1321 / 1907 loss=2.407, loss_v1=0, loss_v2=0, nll_loss=1.181, ntokens=241, nsentences=12, sample_size=241.0, sample_size_v1=0, sample_size_v2=0
2023-04-09 00:22:59 - progress_bar.py[line:272] - INFO: epoch 012 | valid on 'valid' subset:   1331 / 1907 loss=2.414, loss_v1=0, loss_v2=0, nll_loss=1.192, ntokens=356, nsentences=12, sample_size=356.0, sample_size_v1=0, sample_size_v2=0
2023-04-09 00:23:15 - progress_bar.py[line:272] - INFO: epoch 012 | valid on 'valid' subset:   1341 / 1907 loss=2.458, loss_v1=0, loss_v2=0, nll_loss=1.239, ntokens=335, nsentences=12, sample_size=335.0, sample_size_v1=0, sample_size_v2=0
2023-04-09 00:23:33 - progress_bar.py[line:272] - INFO: epoch 012 | valid on 'valid' subset:   1351 / 1907 loss=2.409, loss_v1=0, loss_v2=0, nll_loss=1.183, ntokens=331, nsentences=12, sample_size=331.0, sample_size_v1=0, sample_size_v2=0
2023-04-09 00:23:48 - progress_bar.py[line:272] - INFO: epoch 012 | valid on 'valid' subset:   1361 / 1907 loss=2.252, loss_v1=0, loss_v2=0, nll_loss=1.01, ntokens=219, nsentences=12, sample_size=219.0, sample_size_v1=0, sample_size_v2=0
2023-04-09 00:24:03 - progress_bar.py[line:272] - INFO: epoch 012 | valid on 'valid' subset:   1371 / 1907 loss=2.381, loss_v1=0, loss_v2=0, nll_loss=1.153, ntokens=292, nsentences=12, sample_size=292.0, sample_size_v1=0, sample_size_v2=0
2023-04-09 00:24:20 - progress_bar.py[line:272] - INFO: epoch 012 | valid on 'valid' subset:   1381 / 1907 loss=2.332, loss_v1=0, loss_v2=0, nll_loss=1.096, ntokens=314, nsentences=12, sample_size=314.0, sample_size_v1=0, sample_size_v2=0
2023-04-09 00:24:34 - progress_bar.py[line:272] - INFO: epoch 012 | valid on 'valid' subset:   1391 / 1907 loss=2.196, loss_v1=0, loss_v2=0, nll_loss=0.944, ntokens=275, nsentences=12, sample_size=275.0, sample_size_v1=0, sample_size_v2=0
2023-04-09 00:24:50 - progress_bar.py[line:272] - INFO: epoch 012 | valid on 'valid' subset:   1401 / 1907 loss=2.443, loss_v1=0, loss_v2=0, nll_loss=1.226, ntokens=230, nsentences=12, sample_size=230.0, sample_size_v1=0, sample_size_v2=0
2023-04-09 00:25:02 - progress_bar.py[line:272] - INFO: epoch 012 | valid on 'valid' subset:   1411 / 1907 loss=2.555, loss_v1=0, loss_v2=0, nll_loss=1.349, ntokens=321, nsentences=12, sample_size=321.0, sample_size_v1=0, sample_size_v2=0
2023-04-09 00:25:18 - progress_bar.py[line:272] - INFO: epoch 012 | valid on 'valid' subset:   1421 / 1907 loss=2.363, loss_v1=0, loss_v2=0, nll_loss=1.126, ntokens=309, nsentences=12, sample_size=309.0, sample_size_v1=0, sample_size_v2=0
2023-04-09 00:25:34 - progress_bar.py[line:272] - INFO: epoch 012 | valid on 'valid' subset:   1431 / 1907 loss=2.415, loss_v1=0, loss_v2=0, nll_loss=1.188, ntokens=313, nsentences=12, sample_size=313.0, sample_size_v1=0, sample_size_v2=0
2023-04-09 00:25:51 - progress_bar.py[line:272] - INFO: epoch 012 | valid on 'valid' subset:   1441 / 1907 loss=2.422, loss_v1=0, loss_v2=0, nll_loss=1.2, ntokens=329, nsentences=12, sample_size=329.0, sample_size_v1=0, sample_size_v2=0
2023-04-09 00:26:09 - progress_bar.py[line:272] - INFO: epoch 012 | valid on 'valid' subset:   1451 / 1907 loss=2.405, loss_v1=0, loss_v2=0, nll_loss=1.177, ntokens=383, nsentences=12, sample_size=383.0, sample_size_v1=0, sample_size_v2=0
2023-04-09 00:26:27 - progress_bar.py[line:272] - INFO: epoch 012 | valid on 'valid' subset:   1461 / 1907 loss=2.449, loss_v1=0, loss_v2=0, nll_loss=1.231, ntokens=245, nsentences=12, sample_size=245.0, sample_size_v1=0, sample_size_v2=0
2023-04-09 00:26:45 - progress_bar.py[line:272] - INFO: epoch 012 | valid on 'valid' subset:   1471 / 1907 loss=2.403, loss_v1=0, loss_v2=0, nll_loss=1.175, ntokens=279, nsentences=12, sample_size=279.0, sample_size_v1=0, sample_size_v2=0
2023-04-09 00:27:02 - progress_bar.py[line:272] - INFO: epoch 012 | valid on 'valid' subset:   1481 / 1907 loss=2.5, loss_v1=0, loss_v2=0, nll_loss=1.29, ntokens=268, nsentences=12, sample_size=268.0, sample_size_v1=0, sample_size_v2=0
2023-04-09 00:27:21 - progress_bar.py[line:272] - INFO: epoch 012 | valid on 'valid' subset:   1491 / 1907 loss=2.663, loss_v1=0, loss_v2=0, nll_loss=1.467, ntokens=274, nsentences=12, sample_size=274.0, sample_size_v1=0, sample_size_v2=0
2023-04-09 00:27:38 - progress_bar.py[line:272] - INFO: epoch 012 | valid on 'valid' subset:   1501 / 1907 loss=2.478, loss_v1=0, loss_v2=0, nll_loss=1.258, ntokens=317, nsentences=12, sample_size=317.0, sample_size_v1=0, sample_size_v2=0
2023-04-09 00:27:54 - progress_bar.py[line:272] - INFO: epoch 012 | valid on 'valid' subset:   1511 / 1907 loss=2.554, loss_v1=0, loss_v2=0, nll_loss=1.342, ntokens=248, nsentences=12, sample_size=248.0, sample_size_v1=0, sample_size_v2=0
2023-04-09 00:28:11 - progress_bar.py[line:272] - INFO: epoch 012 | valid on 'valid' subset:   1521 / 1907 loss=2.475, loss_v1=0, loss_v2=0, nll_loss=1.257, ntokens=306, nsentences=12, sample_size=306.0, sample_size_v1=0, sample_size_v2=0
2023-04-09 00:28:27 - progress_bar.py[line:272] - INFO: epoch 012 | valid on 'valid' subset:   1531 / 1907 loss=2.415, loss_v1=0, loss_v2=0, nll_loss=1.191, ntokens=311, nsentences=12, sample_size=311.0, sample_size_v1=0, sample_size_v2=0
2023-04-09 00:28:44 - progress_bar.py[line:272] - INFO: epoch 012 | valid on 'valid' subset:   1541 / 1907 loss=2.431, loss_v1=0, loss_v2=0, nll_loss=1.208, ntokens=441, nsentences=12, sample_size=441.0, sample_size_v1=0, sample_size_v2=0
2023-04-09 00:29:00 - progress_bar.py[line:272] - INFO: epoch 012 | valid on 'valid' subset:   1551 / 1907 loss=2.566, loss_v1=0, loss_v2=0, nll_loss=1.36, ntokens=270, nsentences=12, sample_size=270.0, sample_size_v1=0, sample_size_v2=0
2023-04-09 00:29:18 - progress_bar.py[line:272] - INFO: epoch 012 | valid on 'valid' subset:   1561 / 1907 loss=2.356, loss_v1=0, loss_v2=0, nll_loss=1.128, ntokens=371, nsentences=12, sample_size=371.0, sample_size_v1=0, sample_size_v2=0
2023-04-09 00:29:34 - progress_bar.py[line:272] - INFO: epoch 012 | valid on 'valid' subset:   1571 / 1907 loss=2.26, loss_v1=0, loss_v2=0, nll_loss=1.019, ntokens=396, nsentences=12, sample_size=396.0, sample_size_v1=0, sample_size_v2=0
2023-04-09 00:29:53 - progress_bar.py[line:272] - INFO: epoch 012 | valid on 'valid' subset:   1581 / 1907 loss=2.495, loss_v1=0, loss_v2=0, nll_loss=1.283, ntokens=411, nsentences=12, sample_size=411.0, sample_size_v1=0, sample_size_v2=0
2023-04-09 00:30:09 - progress_bar.py[line:272] - INFO: epoch 012 | valid on 'valid' subset:   1591 / 1907 loss=2.587, loss_v1=0, loss_v2=0, nll_loss=1.385, ntokens=282, nsentences=12, sample_size=282.0, sample_size_v1=0, sample_size_v2=0
2023-04-09 00:30:24 - progress_bar.py[line:272] - INFO: epoch 012 | valid on 'valid' subset:   1601 / 1907 loss=2.552, loss_v1=0, loss_v2=0, nll_loss=1.345, ntokens=399, nsentences=12, sample_size=399.0, sample_size_v1=0, sample_size_v2=0
2023-04-09 00:30:40 - progress_bar.py[line:272] - INFO: epoch 012 | valid on 'valid' subset:   1611 / 1907 loss=2.434, loss_v1=0, loss_v2=0, nll_loss=1.211, ntokens=343, nsentences=12, sample_size=343.0, sample_size_v1=0, sample_size_v2=0
2023-04-09 00:30:57 - progress_bar.py[line:272] - INFO: epoch 012 | valid on 'valid' subset:   1621 / 1907 loss=2.477, loss_v1=0, loss_v2=0, nll_loss=1.261, ntokens=309, nsentences=12, sample_size=309.0, sample_size_v1=0, sample_size_v2=0
2023-04-09 00:31:14 - progress_bar.py[line:272] - INFO: epoch 012 | valid on 'valid' subset:   1631 / 1907 loss=2.522, loss_v1=0, loss_v2=0, nll_loss=1.309, ntokens=270, nsentences=12, sample_size=270.0, sample_size_v1=0, sample_size_v2=0
2023-04-09 00:31:31 - progress_bar.py[line:272] - INFO: epoch 012 | valid on 'valid' subset:   1641 / 1907 loss=2.495, loss_v1=0, loss_v2=0, nll_loss=1.278, ntokens=359, nsentences=12, sample_size=359.0, sample_size_v1=0, sample_size_v2=0
2023-04-09 00:31:47 - progress_bar.py[line:272] - INFO: epoch 012 | valid on 'valid' subset:   1651 / 1907 loss=2.451, loss_v1=0, loss_v2=0, nll_loss=1.231, ntokens=268, nsentences=12, sample_size=268.0, sample_size_v1=0, sample_size_v2=0
2023-04-09 00:32:03 - progress_bar.py[line:272] - INFO: epoch 012 | valid on 'valid' subset:   1661 / 1907 loss=2.447, loss_v1=0, loss_v2=0, nll_loss=1.229, ntokens=300, nsentences=12, sample_size=300.0, sample_size_v1=0, sample_size_v2=0
2023-04-09 00:32:20 - progress_bar.py[line:272] - INFO: epoch 012 | valid on 'valid' subset:   1671 / 1907 loss=2.463, loss_v1=0, loss_v2=0, nll_loss=1.243, ntokens=282, nsentences=12, sample_size=282.0, sample_size_v1=0, sample_size_v2=0
2023-04-09 00:32:37 - progress_bar.py[line:272] - INFO: epoch 012 | valid on 'valid' subset:   1681 / 1907 loss=2.349, loss_v1=0, loss_v2=0, nll_loss=1.118, ntokens=244, nsentences=12, sample_size=244.0, sample_size_v1=0, sample_size_v2=0
2023-04-09 00:32:50 - progress_bar.py[line:272] - INFO: epoch 012 | valid on 'valid' subset:   1691 / 1907 loss=2.339, loss_v1=0, loss_v2=0, nll_loss=1.106, ntokens=285, nsentences=12, sample_size=285.0, sample_size_v1=0, sample_size_v2=0
2023-04-09 00:33:08 - progress_bar.py[line:272] - INFO: epoch 012 | valid on 'valid' subset:   1701 / 1907 loss=2.436, loss_v1=0, loss_v2=0, nll_loss=1.218, ntokens=364, nsentences=12, sample_size=364.0, sample_size_v1=0, sample_size_v2=0
2023-04-09 00:33:26 - progress_bar.py[line:272] - INFO: epoch 012 | valid on 'valid' subset:   1711 / 1907 loss=2.442, loss_v1=0, loss_v2=0, nll_loss=1.218, ntokens=234, nsentences=12, sample_size=234.0, sample_size_v1=0, sample_size_v2=0
2023-04-09 00:33:42 - progress_bar.py[line:272] - INFO: epoch 012 | valid on 'valid' subset:   1721 / 1907 loss=2.514, loss_v1=0, loss_v2=0, nll_loss=1.303, ntokens=190, nsentences=12, sample_size=190.0, sample_size_v1=0, sample_size_v2=0
2023-04-09 00:33:57 - progress_bar.py[line:272] - INFO: epoch 012 | valid on 'valid' subset:   1731 / 1907 loss=2.281, loss_v1=0, loss_v2=0, nll_loss=1.043, ntokens=255, nsentences=12, sample_size=255.0, sample_size_v1=0, sample_size_v2=0
2023-04-09 00:34:16 - progress_bar.py[line:272] - INFO: epoch 012 | valid on 'valid' subset:   1741 / 1907 loss=2.316, loss_v1=0, loss_v2=0, nll_loss=1.081, ntokens=337, nsentences=12, sample_size=337.0, sample_size_v1=0, sample_size_v2=0
2023-04-09 00:34:33 - progress_bar.py[line:272] - INFO: epoch 012 | valid on 'valid' subset:   1751 / 1907 loss=2.47, loss_v1=0, loss_v2=0, nll_loss=1.253, ntokens=233, nsentences=12, sample_size=233.0, sample_size_v1=0, sample_size_v2=0
2023-04-09 00:34:50 - progress_bar.py[line:272] - INFO: epoch 012 | valid on 'valid' subset:   1761 / 1907 loss=2.399, loss_v1=0, loss_v2=0, nll_loss=1.173, ntokens=298, nsentences=12, sample_size=298.0, sample_size_v1=0, sample_size_v2=0
2023-04-09 00:35:08 - progress_bar.py[line:272] - INFO: epoch 012 | valid on 'valid' subset:   1771 / 1907 loss=2.275, loss_v1=0, loss_v2=0, nll_loss=1.033, ntokens=253, nsentences=12, sample_size=253.0, sample_size_v1=0, sample_size_v2=0
2023-04-09 00:35:25 - progress_bar.py[line:272] - INFO: epoch 012 | valid on 'valid' subset:   1781 / 1907 loss=2.283, loss_v1=0, loss_v2=0, nll_loss=1.042, ntokens=287, nsentences=12, sample_size=287.0, sample_size_v1=0, sample_size_v2=0
2023-04-09 00:35:43 - progress_bar.py[line:272] - INFO: epoch 012 | valid on 'valid' subset:   1791 / 1907 loss=2.29, loss_v1=0, loss_v2=0, nll_loss=1.048, ntokens=230, nsentences=12, sample_size=230.0, sample_size_v1=0, sample_size_v2=0
2023-04-09 00:36:00 - progress_bar.py[line:272] - INFO: epoch 012 | valid on 'valid' subset:   1801 / 1907 loss=2.622, loss_v1=0, loss_v2=0, nll_loss=1.423, ntokens=216, nsentences=12, sample_size=216.0, sample_size_v1=0, sample_size_v2=0
2023-04-09 00:36:18 - progress_bar.py[line:272] - INFO: epoch 012 | valid on 'valid' subset:   1811 / 1907 loss=2.419, loss_v1=0, loss_v2=0, nll_loss=1.197, ntokens=285, nsentences=12, sample_size=285.0, sample_size_v1=0, sample_size_v2=0
2023-04-09 00:36:37 - progress_bar.py[line:272] - INFO: epoch 012 | valid on 'valid' subset:   1821 / 1907 loss=2.405, loss_v1=0, loss_v2=0, nll_loss=1.178, ntokens=300, nsentences=12, sample_size=300.0, sample_size_v1=0, sample_size_v2=0
2023-04-09 00:36:54 - progress_bar.py[line:272] - INFO: epoch 012 | valid on 'valid' subset:   1831 / 1907 loss=2.278, loss_v1=0, loss_v2=0, nll_loss=1.038, ntokens=422, nsentences=12, sample_size=422.0, sample_size_v1=0, sample_size_v2=0
2023-04-09 00:37:13 - progress_bar.py[line:272] - INFO: epoch 012 | valid on 'valid' subset:   1841 / 1907 loss=2.441, loss_v1=0, loss_v2=0, nll_loss=1.218, ntokens=275, nsentences=12, sample_size=275.0, sample_size_v1=0, sample_size_v2=0
2023-04-09 00:37:31 - progress_bar.py[line:272] - INFO: epoch 012 | valid on 'valid' subset:   1851 / 1907 loss=2.347, loss_v1=0, loss_v2=0, nll_loss=1.113, ntokens=273, nsentences=12, sample_size=273.0, sample_size_v1=0, sample_size_v2=0
2023-04-09 00:37:49 - progress_bar.py[line:272] - INFO: epoch 012 | valid on 'valid' subset:   1861 / 1907 loss=2.377, loss_v1=0, loss_v2=0, nll_loss=1.149, ntokens=278, nsentences=12, sample_size=278.0, sample_size_v1=0, sample_size_v2=0
2023-04-09 00:38:08 - progress_bar.py[line:272] - INFO: epoch 012 | valid on 'valid' subset:   1871 / 1907 loss=2.276, loss_v1=0, loss_v2=0, nll_loss=1.035, ntokens=385, nsentences=12, sample_size=385.0, sample_size_v1=0, sample_size_v2=0
2023-04-09 00:38:25 - progress_bar.py[line:272] - INFO: epoch 012 | valid on 'valid' subset:   1881 / 1907 loss=2.37, loss_v1=0, loss_v2=0, nll_loss=1.142, ntokens=359, nsentences=12, sample_size=359.0, sample_size_v1=0, sample_size_v2=0
2023-04-09 00:38:42 - progress_bar.py[line:272] - INFO: epoch 012 | valid on 'valid' subset:   1891 / 1907 loss=2.427, loss_v1=0, loss_v2=0, nll_loss=1.201, ntokens=268, nsentences=12, sample_size=268.0, sample_size_v1=0, sample_size_v2=0
2023-04-09 00:38:58 - progress_bar.py[line:272] - INFO: epoch 012 | valid on 'valid' subset:   1901 / 1907 loss=2.54, loss_v1=0, loss_v2=0, nll_loss=1.331, ntokens=351, nsentences=12, sample_size=351.0, sample_size_v1=0, sample_size_v2=0
local datafile ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 1 begin to initialize row_count and line_idx-to-offset mapping
2023-04-09 00:39:08 - progress_bar.py[line:282] - INFO: epoch 012 | valid on 'valid' subset | loss 2.42 | loss_v1 0 | loss_v2 0 | nll_loss 1.196 | ntokens 323.198 | nsentences 11.998 | sample_size 323.198 | sample_size_v1 0 | sample_size_v2 0 | ppl 2.29 | wps 189.7 | wpb 323.2 | bsz 12 | num_updates 6923 | best_loss 2.486
2023-04-09 00:39:08 - checkpoint_utils.py[line:64] - INFO: Preparing to save checkpoint for epoch 12 @ 6923 updates
2023-04-09 00:39:08 - trainer.py[line:431] - INFO: Saving checkpoint to ../../checkpoints/OFA/sgcls_checkpoints/_12_3e-5_512/checkpoint_last.pt
local datafile ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 1 finished initializing row_count and line_idx-to-offset mapping
file ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 1 row count 27700 total row count 55400
slice_id 1 seek offset 27700
2023-04-09 00:39:13 - trainer.py[line:441] - INFO: Finished saving checkpoint to ../../checkpoints/OFA/sgcls_checkpoints/_12_3e-5_512/checkpoint_last.pt
2023-04-09 00:39:13 - checkpoint_utils.py[line:133] - INFO: Saved checkpoint ../../checkpoints/OFA/sgcls_checkpoints/_12_3e-5_512/checkpoint_last.pt (epoch 12 @ 6923 updates, score 2.42) (writing took 4.337591982446611 seconds)
2023-04-09 00:39:13 - train.py[line:332] - INFO: end of epoch 12 (average epoch stats below)
2023-04-09 00:39:13 - progress_bar.py[line:282] - INFO: epoch 012 | loss 2.393 | loss_v1 0 | loss_v2 0 | nll_loss 1.196 | ntokens 2519.6 | nsentences 95.847 | sample_size 2519.6 | sample_size_v1 0 | sample_size_v2 0 | ppl 2.29 | wps 296.8 | ups 0.12 | wpb 2519.6 | bsz 95.8 | num_updates 6923 | lr 5.9816e-08 | gnorm 3.21 | clip 100 | loss_scale 64 | train_wall 1642 | gb_free 13.1 | wall 30982
2023-04-09 00:39:13 - trainer.py[line:639] - INFO: loading train data for epoch 13
local datafile ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 0 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 0 finished initializing row_count and line_idx-to-offset mapping
file ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 0 row count 27700 total row count 55400
slice_id 0 seek offset 0
2023-04-09 00:39:15 - train.py[line:214] - INFO: done training in 30982.3 seconds
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                  train/bsz 
wandb:                 train/clip 
wandb:              train/gb_free 
wandb:                train/gnorm 
wandb:                 train/loss 
wandb:           train/loss_scale 
wandb:              train/loss_v1 
wandb:              train/loss_v2 
wandb:                   train/lr 
wandb:             train/nll_loss 
wandb:           train/nsentences 
wandb:              train/ntokens 
wandb:                  train/ppl 
wandb:          train/sample_size 
wandb:       train/sample_size_v1 
wandb:       train/sample_size_v2 
wandb:           train/train_wall 
wandb:                  train/ups 
wandb:                 train/wall 
wandb:                  train/wpb 
wandb:                  train/wps 
wandb:            train_inner/bsz 
wandb:           train_inner/clip 
wandb:        train_inner/gb_free 
wandb:          train_inner/gnorm 
wandb:           train_inner/loss 
wandb:     train_inner/loss_scale 
wandb:        train_inner/loss_v1 
wandb:        train_inner/loss_v2 
wandb:             train_inner/lr 
wandb:       train_inner/nll_loss 
wandb:     train_inner/nsentences 
wandb:        train_inner/ntokens 
wandb:            train_inner/ppl 
wandb:    train_inner/sample_size 
wandb: train_inner/sample_size_v1 
wandb: train_inner/sample_size_v2 
wandb:     train_inner/train_wall 
wandb:            train_inner/ups 
wandb:           train_inner/wall 
wandb:            train_inner/wpb 
wandb:            train_inner/wps 
wandb:            valid/best_loss 
wandb:                  valid/bsz 
wandb:                 valid/loss 
wandb:              valid/loss_v1 
wandb:              valid/loss_v2 
wandb:             valid/nll_loss 
wandb:           valid/nsentences 
wandb:              valid/ntokens 
wandb:                  valid/ppl 
wandb:          valid/sample_size 
wandb:       valid/sample_size_v1 
wandb:       valid/sample_size_v2 
wandb:                  valid/wpb 
wandb:                  valid/wps 
wandb: 
wandb: Run summary:
wandb:                  train/bsz 95.8
wandb:                 train/clip 100.0
wandb:              train/gb_free 13.1
wandb:                train/gnorm 3.21
wandb:                 train/loss 2.393
wandb:           train/loss_scale 64.0
wandb:              train/loss_v1 0.0
wandb:              train/loss_v2 0.0
wandb:                   train/lr 0.0
wandb:             train/nll_loss 1.196
wandb:           train/nsentences 95.847
wandb:              train/ntokens 2519.598
wandb:                  train/ppl 2.29
wandb:          train/sample_size 2519.598
wandb:       train/sample_size_v1 0.0
wandb:       train/sample_size_v2 0.0
wandb:           train/train_wall 1642.0
wandb:                  train/ups 0.12
wandb:                 train/wall 30982.0
wandb:                  train/wpb 2519.6
wandb:                  train/wps 296.8
wandb:            train_inner/bsz 96.0
wandb:           train_inner/clip 100.0
wandb:        train_inner/gb_free 12.1
wandb:          train_inner/gnorm 2.933
wandb:           train_inner/loss 2.389
wandb:     train_inner/loss_scale 64.0
wandb:        train_inner/loss_v1 0.0
wandb:        train_inner/loss_v2 0.0
wandb:             train_inner/lr 0.0
wandb:       train_inner/nll_loss 1.193
wandb:     train_inner/nsentences 96.0
wandb:        train_inner/ntokens 2565.0
wandb:            train_inner/ppl 2.29
wandb:    train_inner/sample_size 2565.0
wandb: train_inner/sample_size_v1 0.0
wandb: train_inner/sample_size_v2 0.0
wandb:     train_inner/train_wall 28.0
wandb:            train_inner/ups 0.35
wandb:           train_inner/wall 27724.0
wandb:            train_inner/wpb 2565.0
wandb:            train_inner/wps 901.7
wandb:            valid/best_loss 2.486
wandb:                  valid/bsz 12.0
wandb:                 valid/loss 2.42
wandb:              valid/loss_v1 0.0
wandb:              valid/loss_v2 0.0
wandb:             valid/nll_loss 1.196
wandb:           valid/nsentences 11.998
wandb:              valid/ntokens 323.198
wandb:                  valid/ppl 2.29
wandb:          valid/sample_size 323.198
wandb:       valid/sample_size_v1 0.0
wandb:       valid/sample_size_v2 0.0
wandb:                  valid/wpb 323.2
wandb:                  valid/wps 189.7
wandb: 
wandb:  View run _12_3e-5_512 at: https://wandb.ai/jackcai1206/OFA-VG/runs/hv2tyegz
wandb: Synced 6 W&B file(s), 0 media file(s), 2 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230408_160253-hv2tyegz/logs

/data/hulab/zcai75/anaconda3/envs/vilt/lib/python3.8/site-packages/torch/distributed/launch.py:178: FutureWarning: The module torch.distributed.launch is deprecated
and will be removed in future. Use torchrun.
Note that --use_env is set by default in torchrun.
If your script expects `--local_rank` argument to be set, please
change it to read from `os.environ['LOCAL_RANK']` instead. See 
https://pytorch.org/docs/stable/distributed.html#launch-utility for 
further instructions

  warnings.warn(
WARNING:torch.distributed.run:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
2023-04-19 00:26:27 - utils.py[line:255] - INFO: distributed init (rank 1): env://
2023-04-19 00:26:27 - utils.py[line:261] - INFO: Start init
2023-04-19 00:26:27 - distributed_c10d.py[line:228] - INFO: Added key: store_based_barrier_key:1 to store for rank: 1
2023-04-19 00:26:27 - utils.py[line:255] - INFO: distributed init (rank 0): env://
2023-04-19 00:26:27 - utils.py[line:261] - INFO: Start init
2023-04-19 00:26:27 - distributed_c10d.py[line:228] - INFO: Added key: store_based_barrier_key:1 to store for rank: 0
2023-04-19 00:26:27 - distributed_c10d.py[line:262] - INFO: Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 2 nodes.
2023-04-19 00:26:27 - utils.py[line:271] - INFO: initialized host AMD4RTX3090GPU14 as rank 0
single-machine distributed training is initialized.
2023-04-19 00:26:27 - distributed_c10d.py[line:262] - INFO: Rank 1: Completed store-based barrier for key:store_based_barrier_key:1 with 2 nodes.
2023-04-19 00:26:27 - utils.py[line:271] - INFO: initialized host AMD4RTX3090GPU14 as rank 1
single-machine distributed training is initialized.
2023-04-19 00:26:28 - train.py[line:77] - INFO: {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 10, 'log_format': 'simple', 'log_file': None, 'tensorboard_logdir': './tensorboard/_12_3e-5_512', 'wandb_project': 'OFA-VG', 'azureml_logging': False, 'seed': 1, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': 512, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': '../../ofa_module', 'empty_cache_freq': 0, 'all_gather_list_size': 2097152, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 2, 'distributed_num_procs': 2, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': 'env://', 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': True, 'ddp_backend': 'pytorch_ddp', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': True, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_algorithm': 'LocalSGD', 'localsgd_frequency': 3, 'nprocs_per_node': 2, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False}, 'dataset': {'_name': None, 'num_workers': 0, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': None, 'batch_size': 6, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 10, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': 7, 'disable_validation': False, 'max_tokens_valid': None, 'batch_size_valid': 6, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0}, 'optimization': {'_name': None, 'max_epoch': 12, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 1.0, 'sentence_avg': False, 'update_freq': [8], 'lr': [3e-05], 'stop_min_lr': -1.0, 'use_bmuf': False}, 'checkpoint': {'_name': None, 'save_dir': '../../checkpoints/OFA/sgcls_checkpoints/_12_3e-5_512', 'restore_file': '../../checkpoints/ofa_base.pt', 'finetune_from_model': None, 'reset_dataloader': True, 'reset_lr_scheduler': False, 'reset_meters': True, 'reset_optimizer': True, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': 1, 'no_save': False, 'no_epoch_checkpoints': False, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': True, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1, 'use_ema_weights_to_init_param': False, 'use_latest_weights_to_init_ema': False}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 2}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': Namespace(_name='ofa_base', activation_fn='gelu', adam_betas='(0.9,0.999)', adam_eps=1e-08, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, add_type_embedding=True, all_gather_list_size=2097152, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, arch='ofa_base', attention_dropout=0.0, attn_scale_factor=2, azureml_logging=False, batch_size=6, batch_size_valid=6, best_checkpoint_metric='loss', bf16=False, bitfit=False, bpe=None, bpe_dir='../../utils/BPE', broadcast_buffers=False, bucket_cap_mb=25, checkpoint_shard_count=1, checkpoint_suffix='', clip_norm=1.0, code_dict_size=8192, code_image_size=128, code_layernorm_embedding=True, combine_valid_subsets=None, constraint_range=None, cpu=False, cpu_offload=False, criterion='adjust_label_smoothed_cross_entropy', cross_self_attention=False, curriculum=0, data='../../dataset/OFA_data/sgcls/vg_train_full.tsv,../../dataset/OFA_data/sgcls/vg_val_full.tsv', data_buffer_size=10, dataset_impl=None, ddp_backend='pytorch_ddp', ddp_comm_hook='none', decoder_attention_heads=12, decoder_drop_path_rate=0.1, decoder_embed_dim=768, decoder_embed_path=None, decoder_ffn_embed_dim=3072, decoder_input_dim=768, decoder_layerdrop=0, decoder_layers=6, decoder_layers_to_keep=None, decoder_learned_pos=True, decoder_normalize_before=True, decoder_output_dim=768, device_id=0, disable_entangle=True, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_num_procs=2, distributed_port=-1, distributed_rank=0, distributed_world_size=2, drop_worst_after=0, drop_worst_ratio=0.0, dropout=0.1, ema_decay=0.9999, ema_fp32=False, ema_seed_model=None, ema_start_update=0, ema_update_freq=1, empty_cache_freq=0, encoder_attention_heads=12, encoder_drop_path_rate=0.1, encoder_embed_dim=768, encoder_embed_path=None, encoder_ffn_embed_dim=3072, encoder_layerdrop=0, encoder_layers=6, encoder_layers_to_keep=None, encoder_learned_pos=True, encoder_normalize_before=True, end_learning_rate=0.0, entangle_position_embedding=False, eos=2, eval_args='{"beam":5,"max_len_a":0,"max_len_b":200}', eval_print_samples=False, fast_stat_sync=False, find_unused_parameters=True, finetune_from_model=None, fix_batches_to_gpus=False, fixed_validation_seed=7, force_anneal=None, fp16=True, fp16_adam_stats=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=512, fp32_reduce_scatter=False, freeze_decoder_embedding=False, freeze_encoder_embedding=False, gen_subset='test', gradient_as_bucket_view=False, heartbeat_timeout=-1, ignore_eos=False, ignore_prefix_size=0, ignore_unused_valid_subsets=False, image_bucket_size=42, imagenet_default_mean_and_std=False, keep_best_checkpoints=1, keep_interval_updates=-1, keep_interval_updates_pattern=-1, keep_last_epochs=-1, label_smoothing=0.1, layernorm_embedding=True, load_checkpoint_on_all_dp_ranks=False, localsgd_frequency=3, log_file=None, log_format='simple', log_interval=10, lr=[3e-05], lr_scheduler='polynomial_decay', max_epoch=12, max_source_positions=1024, max_src_length=100, max_target_positions=1024, max_tgt_length=100, max_tokens=None, max_tokens_valid=None, max_update=0, max_valid_steps=None, maximize_best_checkpoint_metric=True, memory_efficient_bf16=False, memory_efficient_fp16=False, min_loss_scale=0.0001, min_params_to_wrap=100000000, model_parallel_size=1, no_cross_attention=False, no_epoch_checkpoints=False, no_last_checkpoints=False, no_progress_bar=False, no_reshard_after_forward=False, no_save=False, no_save_optimizer_state=False, no_scale_embedding=True, no_seed_provided=False, no_token_positional_embeddings=False, nprocs_per_node=2, num_bins=480, num_shards=1, num_workers=0, on_cpu_convert_precision=False, optimizer='adam', optimizer_overrides='{}', orig_patch_image_size=256, pad=1, patch_image_size=512, patch_layernorm_embedding=True, patience=-1, pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, plasma_path='/tmp/plasma', pooler_activation_fn='tanh', pooler_classifier='mlp', pooler_dropout=0.0, power=1.0, profile=False, quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, quantization_config_path=None, reg_alpha=1.0, relu_dropout=0.0, report_accuracy=False, required_batch_size_multiple=8, required_seq_len_multiple=1, reset_dataloader=True, reset_logging=False, reset_lr_scheduler=False, reset_meters=True, reset_optimizer=True, resnet_drop_path_rate=0.0, resnet_type='resnet101', restore_file='../../checkpoints/ofa_base.pt', sample_patch_num=196, save_dir='../../checkpoints/OFA/sgcls_checkpoints/_12_3e-5_512', save_interval=1, save_interval_updates=0, scale_attn=True, scale_fc=True, scale_heads=True, scale_resids=False, scoring='bleu', seed=1, selected_cols=None, sentence_avg=False, shard_id=0, share_all_embeddings=True, share_decoder_input_output_embed=True, simul_type=None, skip_invalid_size_inputs_valid_test=False, slowmo_algorithm='LocalSGD', slowmo_momentum=None, stop_min_lr=-1.0, stop_time_hours=0, store_ema=False, suppress_crashes=False, sync_bn=False, task='sgcls', tensorboard_logdir='./tensorboard/_12_3e-5_512', threshold_loss_scale=None, token_bucket_size=256, tokenizer=None, total_num_update=1000000, tpu=False, train_subset='train', unk=3, update_freq=[8], use_bmuf=False, use_ema_weights_to_init_param=False, use_latest_weights_to_init_ema=False, use_old_adam=False, use_plasma_view=False, use_rdrop=False, use_sharded_state=False, user_dir='../../ofa_module', valid_subset='valid', validate_after_updates=0, validate_interval=10, validate_interval_updates=0, vg_json_dir=None, wandb_project='OFA-VG', warmup_ratio=0.06, warmup_updates=0, weight_decay=0.01, write_checkpoints_asynchronously=False, zero_sharding='none'), 'task': {'_name': 'sgcls', 'data': '../../dataset/OFA_data/sgcls/vg_train_full.tsv,../../dataset/OFA_data/sgcls/vg_val_full.tsv', 'selected_cols': None, 'bpe': None, 'bpe_dir': '../../utils/BPE', 'max_source_positions': 1024, 'max_target_positions': 1024, 'max_src_length': 100, 'max_tgt_length': 100, 'code_dict_size': 8192, 'patch_image_size': 512, 'orig_patch_image_size': 256, 'num_bins': 480, 'imagenet_default_mean_and_std': False, 'constraint_range': None, 'eval_args': '{"beam":5,"max_len_a":0,"max_len_b":200}', 'eval_print_samples': False, 'vg_json_dir': None}, 'criterion': {'_name': 'adjust_label_smoothed_cross_entropy', 'label_smoothing': 0.1, 'report_accuracy': False, 'ignore_prefix_size': 0, 'ignore_eos': False, 'sentence_avg': False, 'drop_worst_ratio': 0.0, 'drop_worst_after': 0, 'use_rdrop': False, 'reg_alpha': 1.0, 'sample_patch_num': 196, 'constraint_range': None}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9,0.999)', 'adam_eps': 1e-08, 'weight_decay': 0.01, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': False, 'lr': [3e-05]}, 'lr_scheduler': {'_name': 'polynomial_decay', 'warmup_updates': 0, 'warmup_ratio': 0.06, 'force_anneal': None, 'end_learning_rate': 0.0, 'power': 1.0, 'total_num_update': 1000000.0, 'lr': [3e-05]}, 'scoring': {'_name': 'bleu', 'pad': 1, 'eos': 2, 'unk': 3}, 'bpe': None, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}, 'simul_type': None}
2023-04-19 00:26:28 - sg_cls.py[line:82] - INFO: sgcls setup: source dictionary: 50747 types
2023-04-19 00:26:28 - sg_cls.py[line:83] - INFO: sgcls setup: target dictionary: 50747 types
/data/hulab/zcai75/anaconda3/envs/vilt/lib/python3.8/site-packages/torch/functional.py:478: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at  ../aten/src/ATen/native/TensorShape.cpp:2894.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/data/hulab/zcai75/anaconda3/envs/vilt/lib/python3.8/site-packages/torch/functional.py:478: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at  ../aten/src/ATen/native/TensorShape.cpp:2894.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
2023-04-19 00:26:31 - train.py[line:110] - INFO: OFAModel(
  (encoder): TransformerEncoder(
    (encoder_dropout): Dropout(p=0.2, inplace=False)
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(50747, 768, padding_idx=1)
    (layernorm_embedding): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (type_embedding): Embedding(2, 768)
    (embed_images): ResNet(
      (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)
      (layer1): Sequential(
        (0): Bottleneck(
          (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (downsample): Sequential(
            (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (drop_path): Identity()
        )
        (1): Bottleneck(
          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (2): Bottleneck(
          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
      )
      (layer2): Sequential(
        (0): Bottleneck(
          (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (downsample): Sequential(
            (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
            (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (drop_path): Identity()
        )
        (1): Bottleneck(
          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (2): Bottleneck(
          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (3): Bottleneck(
          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
      )
      (layer3): Sequential(
        (0): Bottleneck(
          (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (downsample): Sequential(
            (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)
            (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (drop_path): Identity()
        )
        (1): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (2): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (3): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (4): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (5): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (6): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (7): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (8): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (9): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (10): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (11): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (12): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (13): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (14): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (15): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (16): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (17): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (18): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (19): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (20): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (21): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (22): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
      )
    )
    (image_proj): Linear(in_features=1024, out_features=768, bias=True)
    (patch_layernorm_embedding): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (embed_positions): Embedding(1026, 768)
    (embed_image_positions): Embedding(1765, 768)
    (pos_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (image_pos_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (pos_q_linear): Linear(in_features=768, out_features=768, bias=True)
    (pos_k_linear): Linear(in_features=768, out_features=768, bias=True)
    (layers): ModuleList(
      (0): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): Identity()
      )
      (1): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(p=0.019999999552965164)
      )
      (2): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(p=0.03999999910593033)
      )
      (3): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(p=0.06000000238418579)
      )
      (4): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(p=0.07999999821186066)
      )
      (5): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(p=0.10000000149011612)
      )
    )
    (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (token_rel_pos_table_list): ModuleList(
      (0): Embedding(511, 12)
      (1): Embedding(511, 12)
      (2): Embedding(511, 12)
      (3): Embedding(511, 12)
      (4): Embedding(511, 12)
      (5): Embedding(511, 12)
    )
    (image_rel_pos_table_list): ModuleList(
      (0): Embedding(6892, 12)
      (1): Embedding(6892, 12)
      (2): Embedding(6892, 12)
      (3): Embedding(6892, 12)
      (4): Embedding(6892, 12)
      (5): Embedding(6892, 12)
    )
  )
  (decoder): TransformerDecoder(
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(50747, 768, padding_idx=1)
    (layernorm_embedding): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (embed_positions): Embedding(1026, 768)
    (embed_image_positions): Embedding(1765, 768)
    (pos_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (image_pos_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (self_pos_q_linear): Linear(in_features=768, out_features=768, bias=True)
    (self_pos_k_linear): Linear(in_features=768, out_features=768, bias=True)
    (cross_pos_q_linear): Linear(in_features=768, out_features=768, bias=True)
    (cross_pos_k_linear): Linear(in_features=768, out_features=768, bias=True)
    (code_layernorm_embedding): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (layers): ModuleList(
      (0): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (cross_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): Identity()
      )
      (1): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (cross_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(p=0.019999999552965164)
      )
      (2): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (cross_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(p=0.03999999910593033)
      )
      (3): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (cross_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(p=0.06000000238418579)
      )
      (4): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (cross_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(p=0.07999999821186066)
      )
      (5): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (cross_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(p=0.10000000149011612)
      )
    )
    (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (output_projection): Linear(in_features=768, out_features=50747, bias=False)
    (token_rel_pos_table_list): ModuleList(
      (0): Embedding(511, 12)
      (1): Embedding(511, 12)
      (2): Embedding(511, 12)
      (3): Embedding(511, 12)
      (4): Embedding(511, 12)
      (5): Embedding(511, 12)
    )
    (image_rel_pos_table_list): ModuleList(
      (0): Embedding(6892, 12)
      (1): Embedding(6892, 12)
      (2): Embedding(6892, 12)
      (3): Embedding(6892, 12)
      (4): Embedding(6892, 12)
      (5): Embedding(6892, 12)
    )
  )
  (classification_heads): ModuleDict()
)
2023-04-19 00:26:31 - train.py[line:111] - INFO: task: SGClsTask
2023-04-19 00:26:31 - train.py[line:112] - INFO: model: OFAModel
2023-04-19 00:26:31 - train.py[line:113] - INFO: criterion: AdjustLabelSmoothedCrossEntropyCriterion
2023-04-19 00:26:31 - train.py[line:114] - INFO: num. shared model params: 175,549,256 (num. trained: 175,549,256)
2023-04-19 00:26:31 - train.py[line:121] - INFO: num. expert model params: 0 (num. trained: 0)
local datafile ../../dataset/OFA_data/sgcls/vg_val_full.tsv slice_id 0 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../dataset/OFA_data/sgcls/vg_val_full.tsv slice_id 1 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../dataset/OFA_data/sgcls/vg_val_full.tsv slice_id 0 finished initializing row_count and line_idx-to-offset mapping
file ../../dataset/OFA_data/sgcls/vg_val_full.tsv slice_id 0 row count 11440 total row count 22880
/data/hulab/zcai75/anaconda3/envs/vilt/lib/python3.8/site-packages/torchvision/transforms/transforms.py:332: UserWarning: Argument 'interpolation' of type int is deprecated since 0.13 and will be removed in 0.15. Please use InterpolationMode enum.
  warnings.warn(
local datafile ../../dataset/OFA_data/sgcls/vg_val_full.tsv slice_id 1 finished initializing row_count and line_idx-to-offset mapping
file ../../dataset/OFA_data/sgcls/vg_val_full.tsv slice_id 1 row count 11440 total row count 22880
/data/hulab/zcai75/anaconda3/envs/vilt/lib/python3.8/site-packages/torchvision/transforms/transforms.py:332: UserWarning: Argument 'interpolation' of type int is deprecated since 0.13 and will be removed in 0.15. Please use InterpolationMode enum.
  warnings.warn(
2023-04-19 00:26:31 - distributed_c10d.py[line:228] - INFO: Added key: store_based_barrier_key:2 to store for rank: 0
2023-04-19 00:26:31 - distributed_c10d.py[line:262] - INFO: Rank 0: Completed store-based barrier for key:store_based_barrier_key:2 with 2 nodes.
2023-04-19 00:26:31 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_tokens.weight <- decoder.embed_tokens.weight
2023-04-19 00:26:31 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_tokens.weight <- decoder.output_projection.weight
2023-04-19 00:26:31 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer1.0.conv1.bias
2023-04-19 00:26:31 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer1.0.conv2.bias
2023-04-19 00:26:31 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer1.0.conv3.bias
2023-04-19 00:26:31 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer1.0.downsample.0.bias
2023-04-19 00:26:31 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer1.1.conv1.bias
2023-04-19 00:26:31 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer1.1.conv2.bias
2023-04-19 00:26:31 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer1.1.conv3.bias
2023-04-19 00:26:31 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer1.2.conv1.bias
2023-04-19 00:26:31 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer1.2.conv2.bias
2023-04-19 00:26:31 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer1.2.conv3.bias
2023-04-19 00:26:31 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.0.conv1.bias
2023-04-19 00:26:31 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.0.conv2.bias
2023-04-19 00:26:31 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.0.conv3.bias
2023-04-19 00:26:31 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.0.downsample.0.bias
2023-04-19 00:26:31 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.1.conv1.bias
2023-04-19 00:26:31 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.1.conv2.bias
2023-04-19 00:26:31 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.1.conv3.bias
2023-04-19 00:26:31 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.2.conv1.bias
2023-04-19 00:26:31 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.2.conv2.bias
2023-04-19 00:26:31 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.2.conv3.bias
2023-04-19 00:26:31 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.3.conv1.bias
2023-04-19 00:26:31 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.3.conv2.bias
2023-04-19 00:26:31 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.3.conv3.bias
2023-04-19 00:26:31 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.0.conv1.bias
2023-04-19 00:26:31 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.0.conv2.bias
2023-04-19 00:26:31 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.0.conv3.bias
2023-04-19 00:26:31 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.0.downsample.0.bias
2023-04-19 00:26:31 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.1.conv1.bias
2023-04-19 00:26:31 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.1.conv2.bias
2023-04-19 00:26:31 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.1.conv3.bias
2023-04-19 00:26:31 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.2.conv1.bias
2023-04-19 00:26:31 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.2.conv2.bias
2023-04-19 00:26:31 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.2.conv3.bias
2023-04-19 00:26:31 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.3.conv1.bias
2023-04-19 00:26:31 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.3.conv2.bias
2023-04-19 00:26:31 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.3.conv3.bias
2023-04-19 00:26:31 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.4.conv1.bias
2023-04-19 00:26:31 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.4.conv2.bias
2023-04-19 00:26:31 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.4.conv3.bias
2023-04-19 00:26:31 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.5.conv1.bias
2023-04-19 00:26:31 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.5.conv2.bias
2023-04-19 00:26:31 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.5.conv3.bias
2023-04-19 00:26:31 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.6.conv1.bias
2023-04-19 00:26:31 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.6.conv2.bias
2023-04-19 00:26:31 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.6.conv3.bias
2023-04-19 00:26:31 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.7.conv1.bias
2023-04-19 00:26:31 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.7.conv2.bias
2023-04-19 00:26:31 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.7.conv3.bias
2023-04-19 00:26:31 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.8.conv1.bias
2023-04-19 00:26:31 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.8.conv2.bias
2023-04-19 00:26:31 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.8.conv3.bias
2023-04-19 00:26:31 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.9.conv1.bias
2023-04-19 00:26:31 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.9.conv2.bias
2023-04-19 00:26:31 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.9.conv3.bias
2023-04-19 00:26:31 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.10.conv1.bias
2023-04-19 00:26:31 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.10.conv2.bias
2023-04-19 00:26:31 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.10.conv3.bias
2023-04-19 00:26:31 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.11.conv1.bias
2023-04-19 00:26:31 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.11.conv2.bias
2023-04-19 00:26:31 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.11.conv3.bias
2023-04-19 00:26:31 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.12.conv1.bias
2023-04-19 00:26:31 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.12.conv2.bias
2023-04-19 00:26:31 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.12.conv3.bias
2023-04-19 00:26:31 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.13.conv1.bias
2023-04-19 00:26:31 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.13.conv2.bias
2023-04-19 00:26:31 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.13.conv3.bias
2023-04-19 00:26:31 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.14.conv1.bias
2023-04-19 00:26:31 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.14.conv2.bias
2023-04-19 00:26:31 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.14.conv3.bias
2023-04-19 00:26:31 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.15.conv1.bias
2023-04-19 00:26:31 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.15.conv2.bias
2023-04-19 00:26:31 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.15.conv3.bias
2023-04-19 00:26:31 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.16.conv1.bias
2023-04-19 00:26:31 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.16.conv2.bias
2023-04-19 00:26:31 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.16.conv3.bias
2023-04-19 00:26:31 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.17.conv1.bias
2023-04-19 00:26:31 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.17.conv2.bias
2023-04-19 00:26:31 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.17.conv3.bias
2023-04-19 00:26:31 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.18.conv1.bias
2023-04-19 00:26:31 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.18.conv2.bias
2023-04-19 00:26:31 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.18.conv3.bias
2023-04-19 00:26:31 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.19.conv1.bias
2023-04-19 00:26:31 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.19.conv2.bias
2023-04-19 00:26:31 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.19.conv3.bias
2023-04-19 00:26:31 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.20.conv1.bias
2023-04-19 00:26:31 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.20.conv2.bias
2023-04-19 00:26:31 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.20.conv3.bias
2023-04-19 00:26:31 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.21.conv1.bias
2023-04-19 00:26:31 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.21.conv2.bias
2023-04-19 00:26:31 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.21.conv3.bias
2023-04-19 00:26:31 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.22.conv1.bias
2023-04-19 00:26:31 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.22.conv2.bias
2023-04-19 00:26:31 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.22.conv3.bias
2023-04-19 00:26:31 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- decoder.output_projection.bias
2023-04-19 00:26:31 - utils.py[line:759] - INFO: ***********************CUDA enviroments for all 2 workers***********************
2023-04-19 00:26:31 - utils.py[line:761] - INFO: rank   0: capabilities =  8.6  ; total memory = 23.688 GB ; name = NVIDIA GeForce RTX 3090 Ti              
2023-04-19 00:26:31 - utils.py[line:761] - INFO: rank   1: capabilities =  8.6  ; total memory = 23.688 GB ; name = NVIDIA GeForce RTX 3090 Ti              
2023-04-19 00:26:31 - utils.py[line:767] - INFO: ***********************CUDA enviroments for all 2 workers***********************
2023-04-19 00:26:31 - train.py[line:152] - INFO: training on 2 devices (GPUs/TPUs)
2023-04-19 00:26:31 - train.py[line:157] - INFO: max tokens per device = None and max sentences per device = 6
2023-04-19 00:26:31 - trainer.py[line:458] - INFO: Preparing to load checkpoint ../../checkpoints/ofa_base.pt
2023-04-19 00:26:31 - trainer.py[line:624] - INFO: No existing checkpoint found ../../checkpoints/ofa_base.pt
2023-04-19 00:26:31 - trainer.py[line:639] - INFO: loading train data for epoch 1
local datafile ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 1 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 0 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 0 finished initializing row_count and line_idx-to-offset mapping
file ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 0 row count 27700 total row count 55400
local datafile ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 1 finished initializing row_count and line_idx-to-offset mapping
file ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 1 row count 27700 total row count 55400
slice_id 1 seek offset 27700
Total steps 6936, warmup steps 416, warmup_factor 0.002403846153846154
slice_id 0 seek offset 0
Total steps 6936, warmup steps 416, warmup_factor 0.002403846153846154
wandb: W&B API key is configured. Use `wandb login --relogin` to force relogin
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.14.2 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /home/zcai75/Github/OFA_forked/run_scripts/sgcls/wandb/run-20230419_002639-d5xxftpb
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run _12_3e-5_512
wandb:  View project at https://wandb.ai/jackcai1206/OFA-VG
wandb:  View run at https://wandb.ai/jackcai1206/OFA-VG/runs/d5xxftpb
2023-04-19 00:26:46 - trainer.py[line:703] - INFO: begin training epoch 1
2023-04-19 00:26:46 - train.py[line:305] - INFO: Start iterating over samples
2023-04-19 00:26:52 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2023-04-19 00:27:21 - progress_bar.py[line:272] - INFO: epoch 001:     11 / 578 loss=11.007, loss_v1=0, loss_v2=0, nll_loss=11.009, ntokens=3133.3, nsentences=96, sample_size=3133.3, sample_size_v1=0, sample_size_v2=0, ppl=2060.54, wps=1096.8, ups=0.35, wpb=3133.3, bsz=96, num_updates=10, lr=7.21154e-07, gnorm=17.874, clip=100, loss_scale=64, train_wall=34, gb_free=12.1, wall=49
2023-04-19 00:27:23 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2023-04-19 00:27:52 - progress_bar.py[line:272] - INFO: epoch 001:     22 / 578 loss=10.566, loss_v1=0, loss_v2=0, nll_loss=10.52, ntokens=3084.1, nsentences=96, sample_size=3084.1, sample_size_v1=0, sample_size_v2=0, ppl=1467.88, wps=990.7, ups=0.32, wpb=3084.1, bsz=96, num_updates=20, lr=1.44231e-06, gnorm=16.506, clip=100, loss_scale=32, train_wall=31, gb_free=11.4, wall=80
2023-04-19 00:28:20 - progress_bar.py[line:272] - INFO: epoch 001:     32 / 578 loss=9.71, loss_v1=0, loss_v2=0, nll_loss=9.567, ntokens=3106.8, nsentences=96, sample_size=3106.8, sample_size_v1=0, sample_size_v2=0, ppl=758.68, wps=1083.2, ups=0.35, wpb=3106.8, bsz=96, num_updates=30, lr=2.16346e-06, gnorm=12.661, clip=100, loss_scale=32, train_wall=29, gb_free=11.9, wall=109
2023-04-19 00:28:49 - progress_bar.py[line:272] - INFO: epoch 001:     42 / 578 loss=8.837, loss_v1=0, loss_v2=0, nll_loss=8.597, ntokens=3282.2, nsentences=96, sample_size=3282.2, sample_size_v1=0, sample_size_v2=0, ppl=387.16, wps=1143.1, ups=0.35, wpb=3282.2, bsz=96, num_updates=40, lr=2.88462e-06, gnorm=9.85, clip=100, loss_scale=32, train_wall=29, gb_free=11.5, wall=138
2023-04-19 00:29:18 - progress_bar.py[line:272] - INFO: epoch 001:     52 / 578 loss=8.205, loss_v1=0, loss_v2=0, nll_loss=7.893, ntokens=3542, nsentences=96, sample_size=3542, sample_size_v1=0, sample_size_v2=0, ppl=237.68, wps=1214.5, ups=0.34, wpb=3542, bsz=96, num_updates=50, lr=3.60577e-06, gnorm=7.824, clip=100, loss_scale=32, train_wall=29, gb_free=11.2, wall=167
2023-04-19 00:29:47 - progress_bar.py[line:272] - INFO: epoch 001:     62 / 578 loss=7.751, loss_v1=0, loss_v2=0, nll_loss=7.385, ntokens=3262.4, nsentences=96, sample_size=3262.4, sample_size_v1=0, sample_size_v2=0, ppl=167.11, wps=1139.7, ups=0.35, wpb=3262.4, bsz=96, num_updates=60, lr=4.32692e-06, gnorm=6.635, clip=100, loss_scale=32, train_wall=29, gb_free=11.8, wall=196
2023-04-19 00:30:16 - progress_bar.py[line:272] - INFO: epoch 001:     72 / 578 loss=7.483, loss_v1=0, loss_v2=0, nll_loss=7.082, ntokens=3013.8, nsentences=95.6, sample_size=3013.8, sample_size_v1=0, sample_size_v2=0, ppl=135.52, wps=1053.1, ups=0.35, wpb=3013.8, bsz=95.6, num_updates=70, lr=5.04808e-06, gnorm=5.725, clip=100, loss_scale=32, train_wall=29, gb_free=12.3, wall=224
2023-04-19 00:30:44 - progress_bar.py[line:272] - INFO: epoch 001:     82 / 578 loss=7.227, loss_v1=0, loss_v2=0, nll_loss=6.794, ntokens=3232.2, nsentences=96, sample_size=3232.2, sample_size_v1=0, sample_size_v2=0, ppl=110.99, wps=1123.4, ups=0.35, wpb=3232.2, bsz=96, num_updates=80, lr=5.76923e-06, gnorm=5.195, clip=100, loss_scale=32, train_wall=29, gb_free=11.7, wall=253
2023-04-19 00:31:13 - progress_bar.py[line:272] - INFO: epoch 001:     92 / 578 loss=6.971, loss_v1=0, loss_v2=0, nll_loss=6.509, ntokens=3338.5, nsentences=96, sample_size=3338.5, sample_size_v1=0, sample_size_v2=0, ppl=91.09, wps=1162.2, ups=0.35, wpb=3338.5, bsz=96, num_updates=90, lr=6.49038e-06, gnorm=5.117, clip=100, loss_scale=32, train_wall=29, gb_free=12, wall=282
2023-04-19 00:31:42 - progress_bar.py[line:272] - INFO: epoch 001:    102 / 578 loss=6.75, loss_v1=0, loss_v2=0, nll_loss=6.262, ntokens=3303.2, nsentences=96, sample_size=3303.2, sample_size_v1=0, sample_size_v2=0, ppl=76.76, wps=1136.7, ups=0.34, wpb=3303.2, bsz=96, num_updates=100, lr=7.21154e-06, gnorm=4.955, clip=100, loss_scale=32, train_wall=29, gb_free=11.5, wall=311
2023-04-19 00:32:11 - progress_bar.py[line:272] - INFO: epoch 001:    112 / 578 loss=6.433, loss_v1=0, loss_v2=0, nll_loss=5.906, ntokens=3236.8, nsentences=96, sample_size=3236.8, sample_size_v1=0, sample_size_v2=0, ppl=59.95, wps=1128.1, ups=0.35, wpb=3236.8, bsz=96, num_updates=110, lr=7.93269e-06, gnorm=4.679, clip=100, loss_scale=32, train_wall=29, gb_free=11.5, wall=339
2023-04-19 00:32:39 - progress_bar.py[line:272] - INFO: epoch 001:    122 / 578 loss=5.961, loss_v1=0, loss_v2=0, nll_loss=5.369, ntokens=3166, nsentences=96, sample_size=3166, sample_size_v1=0, sample_size_v2=0, ppl=41.33, wps=1103.7, ups=0.35, wpb=3166, bsz=96, num_updates=120, lr=8.65385e-06, gnorm=4.185, clip=100, loss_scale=32, train_wall=29, gb_free=12.1, wall=368
2023-04-19 00:33:08 - progress_bar.py[line:272] - INFO: epoch 001:    132 / 578 loss=5.625, loss_v1=0, loss_v2=0, nll_loss=4.978, ntokens=3298.2, nsentences=96, sample_size=3298.2, sample_size_v1=0, sample_size_v2=0, ppl=31.52, wps=1145.2, ups=0.35, wpb=3298.2, bsz=96, num_updates=130, lr=9.375e-06, gnorm=3.346, clip=100, loss_scale=32, train_wall=29, gb_free=12, wall=397
2023-04-19 00:33:37 - progress_bar.py[line:272] - INFO: epoch 001:    142 / 578 loss=5.417, loss_v1=0, loss_v2=0, nll_loss=4.737, ntokens=3041.6, nsentences=96, sample_size=3041.6, sample_size_v1=0, sample_size_v2=0, ppl=26.67, wps=1069.8, ups=0.35, wpb=3041.6, bsz=96, num_updates=140, lr=1.00962e-05, gnorm=3.286, clip=100, loss_scale=32, train_wall=28, gb_free=12.1, wall=425
2023-04-19 00:34:05 - progress_bar.py[line:272] - INFO: epoch 001:    152 / 578 loss=5.217, loss_v1=0, loss_v2=0, nll_loss=4.508, ntokens=3291.4, nsentences=96, sample_size=3291.4, sample_size_v1=0, sample_size_v2=0, ppl=22.76, wps=1156, ups=0.35, wpb=3291.4, bsz=96, num_updates=150, lr=1.08173e-05, gnorm=2.759, clip=100, loss_scale=32, train_wall=28, gb_free=12.3, wall=454
2023-04-19 00:34:34 - progress_bar.py[line:272] - INFO: epoch 001:    162 / 578 loss=4.983, loss_v1=0, loss_v2=0, nll_loss=4.242, ntokens=3228, nsentences=96, sample_size=3228, sample_size_v1=0, sample_size_v2=0, ppl=18.92, wps=1134.3, ups=0.35, wpb=3228, bsz=96, num_updates=160, lr=1.15385e-05, gnorm=2.552, clip=100, loss_scale=32, train_wall=28, gb_free=11.9, wall=482
2023-04-19 00:35:02 - progress_bar.py[line:272] - INFO: epoch 001:    172 / 578 loss=4.832, loss_v1=0, loss_v2=0, nll_loss=4.065, ntokens=3189.4, nsentences=96, sample_size=3189.4, sample_size_v1=0, sample_size_v2=0, ppl=16.74, wps=1122.5, ups=0.35, wpb=3189.4, bsz=96, num_updates=170, lr=1.22596e-05, gnorm=2.346, clip=100, loss_scale=32, train_wall=28, gb_free=12.3, wall=511
2023-04-19 00:35:30 - progress_bar.py[line:272] - INFO: epoch 001:    182 / 578 loss=4.708, loss_v1=0, loss_v2=0, nll_loss=3.924, ntokens=3218, nsentences=96, sample_size=3218, sample_size_v1=0, sample_size_v2=0, ppl=15.18, wps=1131.8, ups=0.35, wpb=3218, bsz=96, num_updates=180, lr=1.29808e-05, gnorm=2.227, clip=100, loss_scale=32, train_wall=28, gb_free=11.8, wall=539
2023-04-19 00:35:59 - progress_bar.py[line:272] - INFO: epoch 001:    192 / 578 loss=4.552, loss_v1=0, loss_v2=0, nll_loss=3.746, ntokens=3272.2, nsentences=96, sample_size=3272.2, sample_size_v1=0, sample_size_v2=0, ppl=13.42, wps=1143.8, ups=0.35, wpb=3272.2, bsz=96, num_updates=190, lr=1.37019e-05, gnorm=2.032, clip=100, loss_scale=32, train_wall=29, gb_free=12.3, wall=568
2023-04-19 00:36:27 - progress_bar.py[line:272] - INFO: epoch 001:    202 / 578 loss=4.437, loss_v1=0, loss_v2=0, nll_loss=3.613, ntokens=3161.4, nsentences=96, sample_size=3161.4, sample_size_v1=0, sample_size_v2=0, ppl=12.24, wps=1116.5, ups=0.35, wpb=3161.4, bsz=96, num_updates=200, lr=1.44231e-05, gnorm=1.924, clip=100, loss_scale=32, train_wall=28, gb_free=12.1, wall=596
2023-04-19 00:36:56 - progress_bar.py[line:272] - INFO: epoch 001:    212 / 578 loss=4.3, loss_v1=0, loss_v2=0, nll_loss=3.456, ntokens=3090.3, nsentences=96, sample_size=3090.3, sample_size_v1=0, sample_size_v2=0, ppl=10.97, wps=1091.9, ups=0.35, wpb=3090.3, bsz=96, num_updates=210, lr=1.51442e-05, gnorm=1.905, clip=100, loss_scale=32, train_wall=28, gb_free=12.1, wall=624
2023-04-19 00:37:24 - progress_bar.py[line:272] - INFO: epoch 001:    222 / 578 loss=4.142, loss_v1=0, loss_v2=0, nll_loss=3.275, ntokens=3140.3, nsentences=96, sample_size=3140.3, sample_size_v1=0, sample_size_v2=0, ppl=9.68, wps=1109.2, ups=0.35, wpb=3140.3, bsz=96, num_updates=220, lr=1.58654e-05, gnorm=1.745, clip=100, loss_scale=32, train_wall=28, gb_free=12.3, wall=653
2023-04-19 00:37:52 - progress_bar.py[line:272] - INFO: epoch 001:    232 / 578 loss=4.03, loss_v1=0, loss_v2=0, nll_loss=3.145, ntokens=2964.7, nsentences=96, sample_size=2964.7, sample_size_v1=0, sample_size_v2=0, ppl=8.85, wps=1044.8, ups=0.35, wpb=2964.7, bsz=96, num_updates=230, lr=1.65865e-05, gnorm=1.793, clip=100, loss_scale=32, train_wall=28, gb_free=12.5, wall=681
2023-04-19 00:38:21 - progress_bar.py[line:272] - INFO: epoch 001:    242 / 578 loss=3.937, loss_v1=0, loss_v2=0, nll_loss=3.039, ntokens=2989.7, nsentences=96, sample_size=2989.7, sample_size_v1=0, sample_size_v2=0, ppl=8.22, wps=1059.4, ups=0.35, wpb=2989.7, bsz=96, num_updates=240, lr=1.73077e-05, gnorm=1.607, clip=100, loss_scale=32, train_wall=28, gb_free=12.4, wall=709
2023-04-19 00:38:49 - progress_bar.py[line:272] - INFO: epoch 001:    252 / 578 loss=3.796, loss_v1=0, loss_v2=0, nll_loss=2.874, ntokens=3092, nsentences=96, sample_size=3092, sample_size_v1=0, sample_size_v2=0, ppl=7.33, wps=1092.9, ups=0.35, wpb=3092, bsz=96, num_updates=250, lr=1.80288e-05, gnorm=1.448, clip=100, loss_scale=32, train_wall=28, gb_free=12.1, wall=738
2023-04-19 00:39:17 - progress_bar.py[line:272] - INFO: epoch 001:    262 / 578 loss=3.658, loss_v1=0, loss_v2=0, nll_loss=2.714, ntokens=3128.4, nsentences=96, sample_size=3128.4, sample_size_v1=0, sample_size_v2=0, ppl=6.56, wps=1100.3, ups=0.35, wpb=3128.4, bsz=96, num_updates=260, lr=1.875e-05, gnorm=1.428, clip=100, loss_scale=32, train_wall=28, gb_free=12.6, wall=766
2023-04-19 00:39:46 - progress_bar.py[line:272] - INFO: epoch 001:    272 / 578 loss=3.557, loss_v1=0, loss_v2=0, nll_loss=2.592, ntokens=3140.5, nsentences=96, sample_size=3140.5, sample_size_v1=0, sample_size_v2=0, ppl=6.03, wps=1106.7, ups=0.35, wpb=3140.5, bsz=96, num_updates=270, lr=1.94712e-05, gnorm=1.461, clip=100, loss_scale=32, train_wall=28, gb_free=12.1, wall=794
2023-04-19 00:40:14 - progress_bar.py[line:272] - INFO: epoch 001:    282 / 578 loss=3.457, loss_v1=0, loss_v2=0, nll_loss=2.473, ntokens=3157.2, nsentences=96, sample_size=3157.2, sample_size_v1=0, sample_size_v2=0, ppl=5.55, wps=1107.5, ups=0.35, wpb=3157.2, bsz=96, num_updates=280, lr=2.01923e-05, gnorm=1.45, clip=100, loss_scale=32, train_wall=28, gb_free=12.2, wall=823
2023-04-19 00:40:43 - progress_bar.py[line:272] - INFO: epoch 001:    292 / 578 loss=3.38, loss_v1=0, loss_v2=0, nll_loss=2.38, ntokens=3181.9, nsentences=96, sample_size=3181.9, sample_size_v1=0, sample_size_v2=0, ppl=5.21, wps=1120.8, ups=0.35, wpb=3181.9, bsz=96, num_updates=290, lr=2.09135e-05, gnorm=1.199, clip=100, loss_scale=32, train_wall=28, gb_free=12.4, wall=851
2023-04-19 00:41:11 - progress_bar.py[line:272] - INFO: epoch 001:    302 / 578 loss=3.327, loss_v1=0, loss_v2=0, nll_loss=2.316, ntokens=2987.2, nsentences=96, sample_size=2987.2, sample_size_v1=0, sample_size_v2=0, ppl=4.98, wps=1048.6, ups=0.35, wpb=2987.2, bsz=96, num_updates=300, lr=2.16346e-05, gnorm=1.311, clip=100, loss_scale=32, train_wall=28, gb_free=12.5, wall=880
2023-04-19 00:41:40 - progress_bar.py[line:272] - INFO: epoch 001:    312 / 578 loss=3.225, loss_v1=0, loss_v2=0, nll_loss=2.195, ntokens=3259.9, nsentences=96, sample_size=3259.9, sample_size_v1=0, sample_size_v2=0, ppl=4.58, wps=1143.1, ups=0.35, wpb=3259.9, bsz=96, num_updates=310, lr=2.23558e-05, gnorm=1.198, clip=100, loss_scale=32, train_wall=28, gb_free=12.1, wall=908
2023-04-19 00:42:08 - progress_bar.py[line:272] - INFO: epoch 001:    322 / 578 loss=3.187, loss_v1=0, loss_v2=0, nll_loss=2.145, ntokens=3250.5, nsentences=96, sample_size=3250.5, sample_size_v1=0, sample_size_v2=0, ppl=4.42, wps=1138.4, ups=0.35, wpb=3250.5, bsz=96, num_updates=320, lr=2.30769e-05, gnorm=1.155, clip=100, loss_scale=32, train_wall=29, gb_free=12.5, wall=937
2023-04-19 00:42:37 - progress_bar.py[line:272] - INFO: epoch 001:    332 / 578 loss=3.12, loss_v1=0, loss_v2=0, nll_loss=2.067, ntokens=3072.7, nsentences=96, sample_size=3072.7, sample_size_v1=0, sample_size_v2=0, ppl=4.19, wps=1080.2, ups=0.35, wpb=3072.7, bsz=96, num_updates=330, lr=2.37981e-05, gnorm=1.225, clip=100, loss_scale=32, train_wall=28, gb_free=12.8, wall=965
2023-04-19 00:43:05 - progress_bar.py[line:272] - INFO: epoch 001:    342 / 578 loss=3.087, loss_v1=0, loss_v2=0, nll_loss=2.026, ntokens=3208.2, nsentences=96, sample_size=3208.2, sample_size_v1=0, sample_size_v2=0, ppl=4.07, wps=1131.6, ups=0.35, wpb=3208.2, bsz=96, num_updates=340, lr=2.45192e-05, gnorm=1.113, clip=90, loss_scale=32, train_wall=28, gb_free=11.8, wall=994
2023-04-19 00:43:33 - progress_bar.py[line:272] - INFO: epoch 001:    352 / 578 loss=3.043, loss_v1=0, loss_v2=0, nll_loss=1.972, ntokens=3071.9, nsentences=96, sample_size=3071.9, sample_size_v1=0, sample_size_v2=0, ppl=3.92, wps=1084.9, ups=0.35, wpb=3071.9, bsz=96, num_updates=350, lr=2.52404e-05, gnorm=1.141, clip=90, loss_scale=32, train_wall=28, gb_free=12.6, wall=1022
2023-04-19 00:44:02 - progress_bar.py[line:272] - INFO: epoch 001:    362 / 578 loss=2.978, loss_v1=0, loss_v2=0, nll_loss=1.893, ntokens=3245.4, nsentences=96, sample_size=3245.4, sample_size_v1=0, sample_size_v2=0, ppl=3.71, wps=1140.2, ups=0.35, wpb=3245.4, bsz=96, num_updates=360, lr=2.59615e-05, gnorm=1.224, clip=90, loss_scale=32, train_wall=28, gb_free=12.1, wall=1050
2023-04-19 00:44:31 - progress_bar.py[line:272] - INFO: epoch 001:    372 / 578 loss=2.966, loss_v1=0, loss_v2=0, nll_loss=1.879, ntokens=3472.2, nsentences=96, sample_size=3472.2, sample_size_v1=0, sample_size_v2=0, ppl=3.68, wps=1207.7, ups=0.35, wpb=3472.2, bsz=96, num_updates=370, lr=2.66827e-05, gnorm=1.248, clip=100, loss_scale=32, train_wall=29, gb_free=11.9, wall=1079
2023-04-19 00:44:59 - progress_bar.py[line:272] - INFO: epoch 001:    382 / 578 loss=2.927, loss_v1=0, loss_v2=0, nll_loss=1.832, ntokens=3300.3, nsentences=96, sample_size=3300.3, sample_size_v1=0, sample_size_v2=0, ppl=3.56, wps=1158.1, ups=0.35, wpb=3300.3, bsz=96, num_updates=380, lr=2.74038e-05, gnorm=1.213, clip=90, loss_scale=32, train_wall=28, gb_free=12, wall=1108
2023-04-19 00:45:28 - progress_bar.py[line:272] - INFO: epoch 001:    392 / 578 loss=2.902, loss_v1=0, loss_v2=0, nll_loss=1.8, ntokens=3120.5, nsentences=96, sample_size=3120.5, sample_size_v1=0, sample_size_v2=0, ppl=3.48, wps=1096.7, ups=0.35, wpb=3120.5, bsz=96, num_updates=390, lr=2.8125e-05, gnorm=1.111, clip=80, loss_scale=32, train_wall=28, gb_free=12.3, wall=1136
2023-04-19 00:45:56 - progress_bar.py[line:272] - INFO: epoch 001:    402 / 578 loss=2.849, loss_v1=0, loss_v2=0, nll_loss=1.739, ntokens=3184.1, nsentences=96, sample_size=3184.1, sample_size_v1=0, sample_size_v2=0, ppl=3.34, wps=1112.5, ups=0.35, wpb=3184.1, bsz=96, num_updates=400, lr=2.88462e-05, gnorm=1.06, clip=60, loss_scale=32, train_wall=29, gb_free=12.4, wall=1165
2023-04-19 00:46:25 - progress_bar.py[line:272] - INFO: epoch 001:    412 / 578 loss=2.845, loss_v1=0, loss_v2=0, nll_loss=1.732, ntokens=2904.3, nsentences=96, sample_size=2904.3, sample_size_v1=0, sample_size_v2=0, ppl=3.32, wps=1023.2, ups=0.35, wpb=2904.3, bsz=96, num_updates=410, lr=2.95673e-05, gnorm=1.199, clip=80, loss_scale=32, train_wall=28, gb_free=12.4, wall=1193
2023-04-19 00:46:53 - progress_bar.py[line:272] - INFO: epoch 001:    422 / 578 loss=2.825, loss_v1=0, loss_v2=0, nll_loss=1.707, ntokens=3057.8, nsentences=96, sample_size=3057.8, sample_size_v1=0, sample_size_v2=0, ppl=3.26, wps=1072.2, ups=0.35, wpb=3057.8, bsz=96, num_updates=420, lr=2.99816e-05, gnorm=1.008, clip=50, loss_scale=32, train_wall=28, gb_free=12.4, wall=1222
2023-04-19 00:47:21 - progress_bar.py[line:272] - INFO: epoch 001:    432 / 578 loss=2.806, loss_v1=0, loss_v2=0, nll_loss=1.685, ntokens=3092.9, nsentences=96, sample_size=3092.9, sample_size_v1=0, sample_size_v2=0, ppl=3.21, wps=1091.8, ups=0.35, wpb=3092.9, bsz=96, num_updates=430, lr=2.99356e-05, gnorm=1.092, clip=70, loss_scale=32, train_wall=28, gb_free=12.4, wall=1250
2023-04-19 00:47:50 - progress_bar.py[line:272] - INFO: epoch 001:    442 / 578 loss=2.807, loss_v1=0, loss_v2=0, nll_loss=1.683, ntokens=2916.1, nsentences=96, sample_size=2916.1, sample_size_v1=0, sample_size_v2=0, ppl=3.21, wps=1030.4, ups=0.35, wpb=2916.1, bsz=96, num_updates=440, lr=2.98896e-05, gnorm=1.065, clip=80, loss_scale=32, train_wall=28, gb_free=12.1, wall=1278
2023-04-19 00:48:18 - progress_bar.py[line:272] - INFO: epoch 001:    452 / 578 loss=2.783, loss_v1=0, loss_v2=0, nll_loss=1.657, ntokens=3077.2, nsentences=96, sample_size=3077.2, sample_size_v1=0, sample_size_v2=0, ppl=3.15, wps=1080, ups=0.35, wpb=3077.2, bsz=96, num_updates=450, lr=2.98436e-05, gnorm=1.081, clip=70, loss_scale=32, train_wall=28, gb_free=12.5, wall=1307
2023-04-19 00:48:47 - progress_bar.py[line:272] - INFO: epoch 001:    462 / 578 loss=2.761, loss_v1=0, loss_v2=0, nll_loss=1.629, ntokens=3043.6, nsentences=96, sample_size=3043.6, sample_size_v1=0, sample_size_v2=0, ppl=3.09, wps=1072.6, ups=0.35, wpb=3043.6, bsz=96, num_updates=460, lr=2.97975e-05, gnorm=1.027, clip=60, loss_scale=32, train_wall=28, gb_free=12.1, wall=1335
2023-04-19 00:49:15 - progress_bar.py[line:272] - INFO: epoch 001:    472 / 578 loss=2.76, loss_v1=0, loss_v2=0, nll_loss=1.628, ntokens=3027.5, nsentences=96, sample_size=3027.5, sample_size_v1=0, sample_size_v2=0, ppl=3.09, wps=1064.6, ups=0.35, wpb=3027.5, bsz=96, num_updates=470, lr=2.97515e-05, gnorm=1.043, clip=60, loss_scale=32, train_wall=28, gb_free=12.5, wall=1364
2023-04-19 00:49:43 - progress_bar.py[line:272] - INFO: epoch 001:    482 / 578 loss=2.757, loss_v1=0, loss_v2=0, nll_loss=1.625, ntokens=2876.5, nsentences=96, sample_size=2876.5, sample_size_v1=0, sample_size_v2=0, ppl=3.08, wps=1013.8, ups=0.35, wpb=2876.5, bsz=96, num_updates=480, lr=2.97055e-05, gnorm=1.125, clip=90, loss_scale=32, train_wall=28, gb_free=12.4, wall=1392
2023-04-19 00:50:12 - progress_bar.py[line:272] - INFO: epoch 001:    492 / 578 loss=2.707, loss_v1=0, loss_v2=0, nll_loss=1.566, ntokens=3095.4, nsentences=96, sample_size=3095.4, sample_size_v1=0, sample_size_v2=0, ppl=2.96, wps=1089.1, ups=0.35, wpb=3095.4, bsz=96, num_updates=490, lr=2.96595e-05, gnorm=1.052, clip=70, loss_scale=32, train_wall=28, gb_free=12.4, wall=1420
2023-04-19 00:50:40 - progress_bar.py[line:272] - INFO: epoch 001:    502 / 578 loss=2.692, loss_v1=0, loss_v2=0, nll_loss=1.546, ntokens=3168.8, nsentences=96, sample_size=3168.8, sample_size_v1=0, sample_size_v2=0, ppl=2.92, wps=1110, ups=0.35, wpb=3168.8, bsz=96, num_updates=500, lr=2.96135e-05, gnorm=0.99, clip=40, loss_scale=32, train_wall=29, gb_free=12.4, wall=1449
2023-04-19 00:51:09 - progress_bar.py[line:272] - INFO: epoch 001:    512 / 578 loss=2.693, loss_v1=0, loss_v2=0, nll_loss=1.548, ntokens=3153.4, nsentences=96, sample_size=3153.4, sample_size_v1=0, sample_size_v2=0, ppl=2.92, wps=1105.7, ups=0.35, wpb=3153.4, bsz=96, num_updates=510, lr=2.95675e-05, gnorm=1.04, clip=50, loss_scale=32, train_wall=28, gb_free=12.2, wall=1478
2023-04-19 00:51:37 - progress_bar.py[line:272] - INFO: epoch 001:    522 / 578 loss=2.67, loss_v1=0, loss_v2=0, nll_loss=1.521, ntokens=3309, nsentences=96, sample_size=3309, sample_size_v1=0, sample_size_v2=0, ppl=2.87, wps=1157.4, ups=0.35, wpb=3309, bsz=96, num_updates=520, lr=2.95215e-05, gnorm=0.921, clip=10, loss_scale=32, train_wall=29, gb_free=12.2, wall=1506
2023-04-19 00:52:06 - progress_bar.py[line:272] - INFO: epoch 001:    532 / 578 loss=2.685, loss_v1=0, loss_v2=0, nll_loss=1.534, ntokens=3043, nsentences=96, sample_size=3043, sample_size_v1=0, sample_size_v2=0, ppl=2.9, wps=1075.5, ups=0.35, wpb=3043, bsz=96, num_updates=530, lr=2.94755e-05, gnorm=0.928, clip=20, loss_scale=64, train_wall=28, gb_free=12.5, wall=1534
2023-04-19 00:52:34 - progress_bar.py[line:272] - INFO: epoch 001:    542 / 578 loss=2.673, loss_v1=0, loss_v2=0, nll_loss=1.524, ntokens=3043.8, nsentences=96, sample_size=3043.8, sample_size_v1=0, sample_size_v2=0, ppl=2.88, wps=1068.9, ups=0.35, wpb=3043.8, bsz=96, num_updates=540, lr=2.94294e-05, gnorm=0.965, clip=20, loss_scale=64, train_wall=28, gb_free=11.6, wall=1563
2023-04-19 00:53:03 - progress_bar.py[line:272] - INFO: epoch 001:    552 / 578 loss=2.666, loss_v1=0, loss_v2=0, nll_loss=1.515, ntokens=3170.7, nsentences=96, sample_size=3170.7, sample_size_v1=0, sample_size_v2=0, ppl=2.86, wps=1103.7, ups=0.35, wpb=3170.7, bsz=96, num_updates=550, lr=2.93834e-05, gnorm=1.004, clip=40, loss_scale=64, train_wall=29, gb_free=12.6, wall=1592
2023-04-19 00:53:32 - progress_bar.py[line:272] - INFO: epoch 001:    562 / 578 loss=2.645, loss_v1=0, loss_v2=0, nll_loss=1.491, ntokens=3255.1, nsentences=96, sample_size=3255.1, sample_size_v1=0, sample_size_v2=0, ppl=2.81, wps=1134.4, ups=0.35, wpb=3255.1, bsz=96, num_updates=560, lr=2.93374e-05, gnorm=0.972, clip=40, loss_scale=64, train_wall=29, gb_free=12.6, wall=1620
2023-04-19 00:54:00 - progress_bar.py[line:272] - INFO: epoch 001:    572 / 578 loss=2.65, loss_v1=0, loss_v2=0, nll_loss=1.496, ntokens=3155.1, nsentences=96, sample_size=3155.1, sample_size_v1=0, sample_size_v2=0, ppl=2.82, wps=1103.1, ups=0.35, wpb=3155.1, bsz=96, num_updates=570, lr=2.92914e-05, gnorm=0.967, clip=40, loss_scale=64, train_wall=29, gb_free=12.5, wall=1649
2023-04-19 00:54:15 - checkpoint_utils.py[line:64] - INFO: Preparing to save checkpoint for epoch 1 @ 576 updates
2023-04-19 00:54:15 - trainer.py[line:431] - INFO: Saving checkpoint to ../../checkpoints/OFA/sgcls_checkpoints/_12_3e-5_512/checkpoint1.pt
local datafile ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 1 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 1 finished initializing row_count and line_idx-to-offset mapping
file ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 1 row count 27700 total row count 55400
slice_id 1 seek offset 27700
2023-04-19 00:54:18 - trainer.py[line:441] - INFO: Finished saving checkpoint to ../../checkpoints/OFA/sgcls_checkpoints/_12_3e-5_512/checkpoint1.pt
2023-04-19 00:54:21 - checkpoint_utils.py[line:133] - INFO: Saved checkpoint ../../checkpoints/OFA/sgcls_checkpoints/_12_3e-5_512/checkpoint1.pt (epoch 1 @ 576 updates, score None) (writing took 5.594843879342079 seconds)
2023-04-19 00:54:21 - train.py[line:332] - INFO: end of epoch 1 (average epoch stats below)
2023-04-19 00:54:21 - progress_bar.py[line:282] - INFO: epoch 001 | loss 4.41 | loss_v1 0 | loss_v2 0 | nll_loss 3.545 | ntokens 3150.88 | nsentences 95.847 | sample_size 3150.88 | sample_size_v1 0 | sample_size_v2 0 | ppl 11.67 | wps 1100.9 | ups 0.35 | wpb 3150.9 | bsz 95.8 | num_updates 576 | lr 2.92638e-05 | gnorm 2.897 | clip 83.5 | loss_scale 64 | train_wall 1647 | gb_free 13.1 | wall 1669
2023-04-19 00:54:21 - trainer.py[line:639] - INFO: loading train data for epoch 2
local datafile ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 0 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 0 finished initializing row_count and line_idx-to-offset mapping
file ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 0 row count 27700 total row count 55400
/data/hulab/zcai75/anaconda3/envs/vilt/lib/python3.8/site-packages/torchvision/transforms/transforms.py:332: UserWarning: Argument 'interpolation' of type int is deprecated since 0.13 and will be removed in 0.15. Please use InterpolationMode enum.
  warnings.warn(
slice_id 0 seek offset 0
2023-04-19 00:54:22 - trainer.py[line:703] - INFO: begin training epoch 2
2023-04-19 00:54:22 - train.py[line:305] - INFO: Start iterating over samples
2023-04-19 00:54:34 - progress_bar.py[line:272] - INFO: epoch 002:      4 / 578 loss=2.64, loss_v1=0, loss_v2=0, nll_loss=1.482, ntokens=2919.2, nsentences=87.6, sample_size=2919.2, sample_size_v1=0, sample_size_v2=0, ppl=2.79, wps=859.8, ups=0.29, wpb=2919.2, bsz=87.6, num_updates=580, lr=2.92454e-05, gnorm=1.102, clip=60, loss_scale=64, train_wall=26, gb_free=12.1, wall=1683
2023-04-19 00:55:03 - progress_bar.py[line:272] - INFO: epoch 002:     14 / 578 loss=2.569, loss_v1=0, loss_v2=0, nll_loss=1.403, ntokens=3125.3, nsentences=96, sample_size=3125.3, sample_size_v1=0, sample_size_v2=0, ppl=2.64, wps=1102.4, ups=0.35, wpb=3125.3, bsz=96, num_updates=590, lr=2.91994e-05, gnorm=1.04, clip=70, loss_scale=64, train_wall=28, gb_free=12.2, wall=1711
2023-04-19 00:55:31 - progress_bar.py[line:272] - INFO: epoch 002:     24 / 578 loss=2.55, loss_v1=0, loss_v2=0, nll_loss=1.382, ntokens=3130.1, nsentences=96, sample_size=3130.1, sample_size_v1=0, sample_size_v2=0, ppl=2.61, wps=1098.2, ups=0.35, wpb=3130.1, bsz=96, num_updates=600, lr=2.91534e-05, gnorm=1.192, clip=100, loss_scale=64, train_wall=28, gb_free=11.6, wall=1740
2023-04-19 00:56:00 - progress_bar.py[line:272] - INFO: epoch 002:     34 / 578 loss=2.563, loss_v1=0, loss_v2=0, nll_loss=1.394, ntokens=3061, nsentences=96, sample_size=3061, sample_size_v1=0, sample_size_v2=0, ppl=2.63, wps=1071.9, ups=0.35, wpb=3061, bsz=96, num_updates=610, lr=2.91074e-05, gnorm=1.212, clip=80, loss_scale=64, train_wall=29, gb_free=12.1, wall=1768
2023-04-19 00:56:28 - progress_bar.py[line:272] - INFO: epoch 002:     44 / 578 loss=2.415, loss_v1=0, loss_v2=0, nll_loss=1.229, ntokens=3371.1, nsentences=96, sample_size=3371.1, sample_size_v1=0, sample_size_v2=0, ppl=2.34, wps=1171.1, ups=0.35, wpb=3371.1, bsz=96, num_updates=620, lr=2.90613e-05, gnorm=1.016, clip=30, loss_scale=64, train_wall=29, gb_free=11.6, wall=1797
2023-04-19 00:56:58 - progress_bar.py[line:272] - INFO: epoch 002:     54 / 578 loss=2.523, loss_v1=0, loss_v2=0, nll_loss=1.352, ntokens=3519.7, nsentences=96, sample_size=3519.7, sample_size_v1=0, sample_size_v2=0, ppl=2.55, wps=1207.4, ups=0.34, wpb=3519.7, bsz=96, num_updates=630, lr=2.90153e-05, gnorm=1.002, clip=60, loss_scale=64, train_wall=29, gb_free=11.8, wall=1826
2023-04-19 00:57:26 - progress_bar.py[line:272] - INFO: epoch 002:     64 / 578 loss=2.519, loss_v1=0, loss_v2=0, nll_loss=1.347, ntokens=3149.4, nsentences=96, sample_size=3149.4, sample_size_v1=0, sample_size_v2=0, ppl=2.54, wps=1100.1, ups=0.35, wpb=3149.4, bsz=96, num_updates=640, lr=2.89693e-05, gnorm=1.007, clip=50, loss_scale=64, train_wall=29, gb_free=11.6, wall=1855
2023-04-19 00:57:55 - progress_bar.py[line:272] - INFO: epoch 002:     74 / 578 loss=2.621, loss_v1=0, loss_v2=0, nll_loss=1.461, ntokens=3083.5, nsentences=96, sample_size=3083.5, sample_size_v1=0, sample_size_v2=0, ppl=2.75, wps=1082.1, ups=0.35, wpb=3083.5, bsz=96, num_updates=650, lr=2.89233e-05, gnorm=0.962, clip=20, loss_scale=64, train_wall=28, gb_free=12, wall=1883
2023-04-19 00:58:24 - progress_bar.py[line:272] - INFO: epoch 002:     84 / 578 loss=2.581, loss_v1=0, loss_v2=0, nll_loss=1.412, ntokens=3253.5, nsentences=96, sample_size=3253.5, sample_size_v1=0, sample_size_v2=0, ppl=2.66, wps=1125.5, ups=0.35, wpb=3253.5, bsz=96, num_updates=660, lr=2.88773e-05, gnorm=0.844, clip=0, loss_scale=64, train_wall=29, gb_free=11.6, wall=1912
2023-04-19 00:58:53 - progress_bar.py[line:272] - INFO: epoch 002:     94 / 578 loss=2.549, loss_v1=0, loss_v2=0, nll_loss=1.376, ntokens=3364, nsentences=96, sample_size=3364, sample_size_v1=0, sample_size_v2=0, ppl=2.6, wps=1156.9, ups=0.34, wpb=3364, bsz=96, num_updates=670, lr=2.88313e-05, gnorm=0.859, clip=10, loss_scale=64, train_wall=29, gb_free=11.4, wall=1941
2023-04-19 00:59:22 - progress_bar.py[line:272] - INFO: epoch 002:    104 / 578 loss=2.55, loss_v1=0, loss_v2=0, nll_loss=1.381, ntokens=3292, nsentences=96, sample_size=3292, sample_size_v1=0, sample_size_v2=0, ppl=2.6, wps=1134.8, ups=0.34, wpb=3292, bsz=96, num_updates=680, lr=2.87853e-05, gnorm=0.913, clip=0, loss_scale=64, train_wall=29, gb_free=11.9, wall=1970
2023-04-19 00:59:50 - progress_bar.py[line:272] - INFO: epoch 002:    114 / 578 loss=2.538, loss_v1=0, loss_v2=0, nll_loss=1.363, ntokens=3160.4, nsentences=96, sample_size=3160.4, sample_size_v1=0, sample_size_v2=0, ppl=2.57, wps=1106.1, ups=0.35, wpb=3160.4, bsz=96, num_updates=690, lr=2.87393e-05, gnorm=0.919, clip=20, loss_scale=64, train_wall=29, gb_free=12.2, wall=1999
2023-04-19 01:00:19 - progress_bar.py[line:272] - INFO: epoch 002:    124 / 578 loss=2.527, loss_v1=0, loss_v2=0, nll_loss=1.353, ntokens=3238.2, nsentences=96, sample_size=3238.2, sample_size_v1=0, sample_size_v2=0, ppl=2.55, wps=1127.3, ups=0.35, wpb=3238.2, bsz=96, num_updates=700, lr=2.86933e-05, gnorm=0.935, clip=20, loss_scale=64, train_wall=29, gb_free=11.1, wall=2028
2023-04-19 01:00:48 - progress_bar.py[line:272] - INFO: epoch 002:    134 / 578 loss=2.545, loss_v1=0, loss_v2=0, nll_loss=1.373, ntokens=3223.3, nsentences=96, sample_size=3223.3, sample_size_v1=0, sample_size_v2=0, ppl=2.59, wps=1125.3, ups=0.35, wpb=3223.3, bsz=96, num_updates=710, lr=2.86472e-05, gnorm=0.904, clip=10, loss_scale=64, train_wall=29, gb_free=12.2, wall=2056
2023-04-19 01:01:16 - progress_bar.py[line:272] - INFO: epoch 002:    144 / 578 loss=2.612, loss_v1=0, loss_v2=0, nll_loss=1.448, ntokens=3126.5, nsentences=96, sample_size=3126.5, sample_size_v1=0, sample_size_v2=0, ppl=2.73, wps=1096.9, ups=0.35, wpb=3126.5, bsz=96, num_updates=720, lr=2.86012e-05, gnorm=0.914, clip=10, loss_scale=64, train_wall=28, gb_free=11.9, wall=2085
2023-04-19 01:01:45 - progress_bar.py[line:272] - INFO: epoch 002:    154 / 578 loss=2.604, loss_v1=0, loss_v2=0, nll_loss=1.438, ntokens=3230.1, nsentences=96, sample_size=3230.1, sample_size_v1=0, sample_size_v2=0, ppl=2.71, wps=1136, ups=0.35, wpb=3230.1, bsz=96, num_updates=730, lr=2.85552e-05, gnorm=0.828, clip=0, loss_scale=64, train_wall=28, gb_free=12.3, wall=2113
2023-04-19 01:02:13 - progress_bar.py[line:272] - INFO: epoch 002:    164 / 578 loss=2.615, loss_v1=0, loss_v2=0, nll_loss=1.451, ntokens=3269.4, nsentences=96, sample_size=3269.4, sample_size_v1=0, sample_size_v2=0, ppl=2.73, wps=1148.9, ups=0.35, wpb=3269.4, bsz=96, num_updates=740, lr=2.85092e-05, gnorm=0.82, clip=0, loss_scale=64, train_wall=28, gb_free=12.5, wall=2142
2023-04-19 01:02:42 - progress_bar.py[line:272] - INFO: epoch 002:    174 / 578 loss=2.605, loss_v1=0, loss_v2=0, nll_loss=1.439, ntokens=3188.2, nsentences=96, sample_size=3188.2, sample_size_v1=0, sample_size_v2=0, ppl=2.71, wps=1122.7, ups=0.35, wpb=3188.2, bsz=96, num_updates=750, lr=2.84632e-05, gnorm=0.912, clip=10, loss_scale=64, train_wall=28, gb_free=12.1, wall=2170
2023-04-19 01:03:10 - progress_bar.py[line:272] - INFO: epoch 002:    184 / 578 loss=2.604, loss_v1=0, loss_v2=0, nll_loss=1.439, ntokens=3198.2, nsentences=96, sample_size=3198.2, sample_size_v1=0, sample_size_v2=0, ppl=2.71, wps=1121.2, ups=0.35, wpb=3198.2, bsz=96, num_updates=760, lr=2.84172e-05, gnorm=0.892, clip=0, loss_scale=64, train_wall=28, gb_free=11.9, wall=2199
2023-04-19 01:03:38 - progress_bar.py[line:272] - INFO: epoch 002:    194 / 578 loss=2.577, loss_v1=0, loss_v2=0, nll_loss=1.409, ntokens=3235.3, nsentences=96, sample_size=3235.3, sample_size_v1=0, sample_size_v2=0, ppl=2.66, wps=1138.7, ups=0.35, wpb=3235.3, bsz=96, num_updates=770, lr=2.83712e-05, gnorm=0.825, clip=0, loss_scale=64, train_wall=28, gb_free=12.3, wall=2227
2023-04-19 01:04:07 - progress_bar.py[line:272] - INFO: epoch 002:    204 / 578 loss=2.585, loss_v1=0, loss_v2=0, nll_loss=1.416, ntokens=3221.9, nsentences=96, sample_size=3221.9, sample_size_v1=0, sample_size_v2=0, ppl=2.67, wps=1135.4, ups=0.35, wpb=3221.9, bsz=96, num_updates=780, lr=2.83252e-05, gnorm=0.848, clip=0, loss_scale=64, train_wall=28, gb_free=12, wall=2255
2023-04-19 01:04:35 - progress_bar.py[line:272] - INFO: epoch 002:    214 / 578 loss=2.6, loss_v1=0, loss_v2=0, nll_loss=1.433, ntokens=3015.8, nsentences=96, sample_size=3015.8, sample_size_v1=0, sample_size_v2=0, ppl=2.7, wps=1067.3, ups=0.35, wpb=3015.8, bsz=96, num_updates=790, lr=2.82791e-05, gnorm=0.88, clip=10, loss_scale=64, train_wall=28, gb_free=12.5, wall=2284
2023-04-19 01:05:03 - progress_bar.py[line:272] - INFO: epoch 002:    224 / 578 loss=2.572, loss_v1=0, loss_v2=0, nll_loss=1.403, ntokens=3179.6, nsentences=96, sample_size=3179.6, sample_size_v1=0, sample_size_v2=0, ppl=2.64, wps=1120.3, ups=0.35, wpb=3179.6, bsz=96, num_updates=800, lr=2.82331e-05, gnorm=0.911, clip=10, loss_scale=64, train_wall=28, gb_free=12.3, wall=2312
2023-04-19 01:05:32 - progress_bar.py[line:272] - INFO: epoch 002:    234 / 578 loss=2.577, loss_v1=0, loss_v2=0, nll_loss=1.408, ntokens=2948.5, nsentences=96, sample_size=2948.5, sample_size_v1=0, sample_size_v2=0, ppl=2.65, wps=1039.4, ups=0.35, wpb=2948.5, bsz=96, num_updates=810, lr=2.81871e-05, gnorm=0.898, clip=10, loss_scale=64, train_wall=28, gb_free=12.2, wall=2340
2023-04-19 01:06:00 - progress_bar.py[line:272] - INFO: epoch 002:    244 / 578 loss=2.578, loss_v1=0, loss_v2=0, nll_loss=1.407, ntokens=2962.6, nsentences=96, sample_size=2962.6, sample_size_v1=0, sample_size_v2=0, ppl=2.65, wps=1049.2, ups=0.35, wpb=2962.6, bsz=96, num_updates=820, lr=2.81411e-05, gnorm=0.9, clip=0, loss_scale=64, train_wall=28, gb_free=12.3, wall=2369
2023-04-19 01:06:28 - progress_bar.py[line:272] - INFO: epoch 002:    254 / 578 loss=2.566, loss_v1=0, loss_v2=0, nll_loss=1.394, ntokens=3219, nsentences=96, sample_size=3219, sample_size_v1=0, sample_size_v2=0, ppl=2.63, wps=1134, ups=0.35, wpb=3219, bsz=96, num_updates=830, lr=2.80951e-05, gnorm=0.859, clip=10, loss_scale=64, train_wall=28, gb_free=12.3, wall=2397
2023-04-19 01:06:57 - progress_bar.py[line:272] - INFO: epoch 002:    264 / 578 loss=2.565, loss_v1=0, loss_v2=0, nll_loss=1.395, ntokens=3051.3, nsentences=96, sample_size=3051.3, sample_size_v1=0, sample_size_v2=0, ppl=2.63, wps=1078.1, ups=0.35, wpb=3051.3, bsz=96, num_updates=840, lr=2.80491e-05, gnorm=0.887, clip=0, loss_scale=64, train_wall=28, gb_free=12, wall=2425
2023-04-19 01:07:25 - progress_bar.py[line:272] - INFO: epoch 002:    274 / 578 loss=2.562, loss_v1=0, loss_v2=0, nll_loss=1.388, ntokens=3174.8, nsentences=96, sample_size=3174.8, sample_size_v1=0, sample_size_v2=0, ppl=2.62, wps=1120.6, ups=0.35, wpb=3174.8, bsz=96, num_updates=850, lr=2.80031e-05, gnorm=0.885, clip=10, loss_scale=64, train_wall=28, gb_free=12.4, wall=2454
2023-04-19 01:07:54 - progress_bar.py[line:272] - INFO: epoch 002:    284 / 578 loss=2.546, loss_v1=0, loss_v2=0, nll_loss=1.372, ntokens=3116.9, nsentences=96, sample_size=3116.9, sample_size_v1=0, sample_size_v2=0, ppl=2.59, wps=1095.7, ups=0.35, wpb=3116.9, bsz=96, num_updates=860, lr=2.79571e-05, gnorm=0.915, clip=20, loss_scale=64, train_wall=28, gb_free=12, wall=2482
2023-04-19 01:08:22 - progress_bar.py[line:272] - INFO: epoch 002:    294 / 578 loss=2.571, loss_v1=0, loss_v2=0, nll_loss=1.4, ntokens=3166.8, nsentences=96, sample_size=3166.8, sample_size_v1=0, sample_size_v2=0, ppl=2.64, wps=1111.8, ups=0.35, wpb=3166.8, bsz=96, num_updates=870, lr=2.7911e-05, gnorm=0.86, clip=0, loss_scale=64, train_wall=28, gb_free=12.4, wall=2511
2023-04-19 01:08:51 - progress_bar.py[line:272] - INFO: epoch 002:    304 / 578 loss=2.564, loss_v1=0, loss_v2=0, nll_loss=1.392, ntokens=3036.7, nsentences=96, sample_size=3036.7, sample_size_v1=0, sample_size_v2=0, ppl=2.62, wps=1063.1, ups=0.35, wpb=3036.7, bsz=96, num_updates=880, lr=2.7865e-05, gnorm=0.837, clip=0, loss_scale=64, train_wall=29, gb_free=12.4, wall=2539
2023-04-19 01:09:19 - progress_bar.py[line:272] - INFO: epoch 002:    314 / 578 loss=2.55, loss_v1=0, loss_v2=0, nll_loss=1.375, ntokens=3246.9, nsentences=96, sample_size=3246.9, sample_size_v1=0, sample_size_v2=0, ppl=2.59, wps=1140.9, ups=0.35, wpb=3246.9, bsz=96, num_updates=890, lr=2.7819e-05, gnorm=0.833, clip=0, loss_scale=64, train_wall=28, gb_free=12.6, wall=2568
2023-04-19 01:09:48 - progress_bar.py[line:272] - INFO: epoch 002:    324 / 578 loss=2.556, loss_v1=0, loss_v2=0, nll_loss=1.383, ntokens=3239.5, nsentences=96, sample_size=3239.5, sample_size_v1=0, sample_size_v2=0, ppl=2.61, wps=1131.7, ups=0.35, wpb=3239.5, bsz=96, num_updates=900, lr=2.7773e-05, gnorm=0.871, clip=0, loss_scale=64, train_wall=29, gb_free=12.2, wall=2596
2023-04-19 01:10:16 - progress_bar.py[line:272] - INFO: epoch 002:    334 / 578 loss=2.535, loss_v1=0, loss_v2=0, nll_loss=1.358, ntokens=3063.1, nsentences=96, sample_size=3063.1, sample_size_v1=0, sample_size_v2=0, ppl=2.56, wps=1074.2, ups=0.35, wpb=3063.1, bsz=96, num_updates=910, lr=2.7727e-05, gnorm=0.866, clip=0, loss_scale=64, train_wall=28, gb_free=12.4, wall=2625
2023-04-19 01:10:45 - progress_bar.py[line:272] - INFO: epoch 002:    344 / 578 loss=2.565, loss_v1=0, loss_v2=0, nll_loss=1.393, ntokens=3279.4, nsentences=96, sample_size=3279.4, sample_size_v1=0, sample_size_v2=0, ppl=2.63, wps=1153.6, ups=0.35, wpb=3279.4, bsz=96, num_updates=920, lr=2.7681e-05, gnorm=0.813, clip=0, loss_scale=64, train_wall=28, gb_free=12.2, wall=2653
2023-04-19 01:11:13 - progress_bar.py[line:272] - INFO: epoch 002:    354 / 578 loss=2.537, loss_v1=0, loss_v2=0, nll_loss=1.362, ntokens=3043.8, nsentences=96, sample_size=3043.8, sample_size_v1=0, sample_size_v2=0, ppl=2.57, wps=1077, ups=0.35, wpb=3043.8, bsz=96, num_updates=930, lr=2.7635e-05, gnorm=0.881, clip=0, loss_scale=64, train_wall=28, gb_free=12.3, wall=2682
2023-04-19 01:11:41 - progress_bar.py[line:272] - INFO: epoch 002:    364 / 578 loss=2.547, loss_v1=0, loss_v2=0, nll_loss=1.371, ntokens=3314.1, nsentences=96, sample_size=3314.1, sample_size_v1=0, sample_size_v2=0, ppl=2.59, wps=1165.1, ups=0.35, wpb=3314.1, bsz=96, num_updates=940, lr=2.7589e-05, gnorm=0.89, clip=20, loss_scale=64, train_wall=28, gb_free=12.2, wall=2710
2023-04-19 01:12:10 - progress_bar.py[line:272] - INFO: epoch 002:    374 / 578 loss=2.554, loss_v1=0, loss_v2=0, nll_loss=1.379, ntokens=3377.5, nsentences=96, sample_size=3377.5, sample_size_v1=0, sample_size_v2=0, ppl=2.6, wps=1176.7, ups=0.35, wpb=3377.5, bsz=96, num_updates=950, lr=2.75429e-05, gnorm=0.88, clip=0, loss_scale=64, train_wall=29, gb_free=12.2, wall=2739
2023-04-19 01:12:39 - progress_bar.py[line:272] - INFO: epoch 002:    384 / 578 loss=2.542, loss_v1=0, loss_v2=0, nll_loss=1.365, ntokens=3284.1, nsentences=96, sample_size=3284.1, sample_size_v1=0, sample_size_v2=0, ppl=2.58, wps=1151.7, ups=0.35, wpb=3284.1, bsz=96, num_updates=960, lr=2.74969e-05, gnorm=0.818, clip=0, loss_scale=64, train_wall=28, gb_free=12.1, wall=2767
2023-04-19 01:13:07 - progress_bar.py[line:272] - INFO: epoch 002:    394 / 578 loss=2.547, loss_v1=0, loss_v2=0, nll_loss=1.371, ntokens=3094.4, nsentences=96, sample_size=3094.4, sample_size_v1=0, sample_size_v2=0, ppl=2.59, wps=1086.6, ups=0.35, wpb=3094.4, bsz=96, num_updates=970, lr=2.74509e-05, gnorm=0.811, clip=0, loss_scale=64, train_wall=28, gb_free=11.8, wall=2796
2023-04-19 01:13:36 - progress_bar.py[line:272] - INFO: epoch 002:    404 / 578 loss=2.508, loss_v1=0, loss_v2=0, nll_loss=1.329, ntokens=3155.2, nsentences=96, sample_size=3155.2, sample_size_v1=0, sample_size_v2=0, ppl=2.51, wps=1103.1, ups=0.35, wpb=3155.2, bsz=96, num_updates=980, lr=2.74049e-05, gnorm=0.905, clip=20, loss_scale=64, train_wall=29, gb_free=12.6, wall=2824
2023-04-19 01:14:04 - progress_bar.py[line:272] - INFO: epoch 002:    414 / 578 loss=2.543, loss_v1=0, loss_v2=0, nll_loss=1.367, ntokens=2978.3, nsentences=96, sample_size=2978.3, sample_size_v1=0, sample_size_v2=0, ppl=2.58, wps=1045.5, ups=0.35, wpb=2978.3, bsz=96, num_updates=990, lr=2.73589e-05, gnorm=0.918, clip=20, loss_scale=64, train_wall=28, gb_free=12.6, wall=2853
2023-04-19 01:14:33 - progress_bar.py[line:272] - INFO: epoch 002:    424 / 578 loss=2.515, loss_v1=0, loss_v2=0, nll_loss=1.337, ntokens=3051.2, nsentences=96, sample_size=3051.2, sample_size_v1=0, sample_size_v2=0, ppl=2.53, wps=1069.8, ups=0.35, wpb=3051.2, bsz=96, num_updates=1000, lr=2.73129e-05, gnorm=0.936, clip=20, loss_scale=64, train_wall=28, gb_free=12.3, wall=2881
2023-04-19 01:15:01 - progress_bar.py[line:272] - INFO: epoch 002:    434 / 578 loss=2.535, loss_v1=0, loss_v2=0, nll_loss=1.357, ntokens=3065.7, nsentences=96, sample_size=3065.7, sample_size_v1=0, sample_size_v2=0, ppl=2.56, wps=1086, ups=0.35, wpb=3065.7, bsz=96, num_updates=1010, lr=2.72669e-05, gnorm=0.927, clip=0, loss_scale=64, train_wall=28, gb_free=12.2, wall=2910
2023-04-19 01:15:29 - progress_bar.py[line:272] - INFO: epoch 002:    444 / 578 loss=2.558, loss_v1=0, loss_v2=0, nll_loss=1.382, ntokens=2879.7, nsentences=96, sample_size=2879.7, sample_size_v1=0, sample_size_v2=0, ppl=2.61, wps=1016.7, ups=0.35, wpb=2879.7, bsz=96, num_updates=1020, lr=2.72209e-05, gnorm=0.968, clip=20, loss_scale=64, train_wall=28, gb_free=12.2, wall=2938
2023-04-19 01:15:58 - progress_bar.py[line:272] - INFO: epoch 002:    454 / 578 loss=2.519, loss_v1=0, loss_v2=0, nll_loss=1.343, ntokens=3106, nsentences=96, sample_size=3106, sample_size_v1=0, sample_size_v2=0, ppl=2.54, wps=1094.1, ups=0.35, wpb=3106, bsz=96, num_updates=1030, lr=2.71748e-05, gnorm=0.973, clip=50, loss_scale=64, train_wall=28, gb_free=12, wall=2966
2023-04-19 01:16:26 - progress_bar.py[line:272] - INFO: epoch 002:    464 / 578 loss=2.535, loss_v1=0, loss_v2=0, nll_loss=1.357, ntokens=3094.5, nsentences=96, sample_size=3094.5, sample_size_v1=0, sample_size_v2=0, ppl=2.56, wps=1088.6, ups=0.35, wpb=3094.5, bsz=96, num_updates=1040, lr=2.71288e-05, gnorm=0.908, clip=10, loss_scale=128, train_wall=28, gb_free=12.5, wall=2995
2023-04-19 01:16:54 - progress_bar.py[line:272] - INFO: epoch 002:    474 / 578 loss=2.543, loss_v1=0, loss_v2=0, nll_loss=1.366, ntokens=2922.6, nsentences=96, sample_size=2922.6, sample_size_v1=0, sample_size_v2=0, ppl=2.58, wps=1033.5, ups=0.35, wpb=2922.6, bsz=96, num_updates=1050, lr=2.70828e-05, gnorm=0.958, clip=20, loss_scale=128, train_wall=28, gb_free=12.2, wall=3023
2023-04-19 01:17:23 - progress_bar.py[line:272] - INFO: epoch 002:    484 / 578 loss=2.512, loss_v1=0, loss_v2=0, nll_loss=1.334, ntokens=2952.9, nsentences=96, sample_size=2952.9, sample_size_v1=0, sample_size_v2=0, ppl=2.52, wps=1036.6, ups=0.35, wpb=2952.9, bsz=96, num_updates=1060, lr=2.70368e-05, gnorm=0.937, clip=20, loss_scale=128, train_wall=28, gb_free=12.1, wall=3051
2023-04-19 01:17:51 - progress_bar.py[line:272] - INFO: epoch 002:    494 / 578 loss=2.5, loss_v1=0, loss_v2=0, nll_loss=1.318, ntokens=3118.2, nsentences=96, sample_size=3118.2, sample_size_v1=0, sample_size_v2=0, ppl=2.49, wps=1098.2, ups=0.35, wpb=3118.2, bsz=96, num_updates=1070, lr=2.69908e-05, gnorm=0.877, clip=0, loss_scale=128, train_wall=28, gb_free=12.4, wall=3080
2023-04-19 01:18:20 - progress_bar.py[line:272] - INFO: epoch 002:    504 / 578 loss=2.489, loss_v1=0, loss_v2=0, nll_loss=1.306, ntokens=3145.4, nsentences=95.6, sample_size=3145.4, sample_size_v1=0, sample_size_v2=0, ppl=2.47, wps=1107.6, ups=0.35, wpb=3145.4, bsz=95.6, num_updates=1080, lr=2.69448e-05, gnorm=0.915, clip=10, loss_scale=128, train_wall=28, gb_free=12.2, wall=3108
2023-04-19 01:18:48 - progress_bar.py[line:272] - INFO: epoch 002:    514 / 578 loss=2.5, loss_v1=0, loss_v2=0, nll_loss=1.319, ntokens=3113.7, nsentences=96, sample_size=3113.7, sample_size_v1=0, sample_size_v2=0, ppl=2.5, wps=1095.4, ups=0.35, wpb=3113.7, bsz=96, num_updates=1090, lr=2.68988e-05, gnorm=0.908, clip=0, loss_scale=128, train_wall=28, gb_free=12.3, wall=3137
2023-04-19 01:19:17 - progress_bar.py[line:272] - INFO: epoch 002:    524 / 578 loss=2.493, loss_v1=0, loss_v2=0, nll_loss=1.309, ntokens=3300.8, nsentences=96, sample_size=3300.8, sample_size_v1=0, sample_size_v2=0, ppl=2.48, wps=1160.3, ups=0.35, wpb=3300.8, bsz=96, num_updates=1100, lr=2.68528e-05, gnorm=0.844, clip=10, loss_scale=128, train_wall=28, gb_free=12.2, wall=3165
2023-04-19 01:19:45 - progress_bar.py[line:272] - INFO: epoch 002:    534 / 578 loss=2.509, loss_v1=0, loss_v2=0, nll_loss=1.326, ntokens=3027.1, nsentences=96, sample_size=3027.1, sample_size_v1=0, sample_size_v2=0, ppl=2.51, wps=1066.9, ups=0.35, wpb=3027.1, bsz=96, num_updates=1110, lr=2.68067e-05, gnorm=0.884, clip=10, loss_scale=128, train_wall=28, gb_free=12.1, wall=3194
2023-04-19 01:20:13 - progress_bar.py[line:272] - INFO: epoch 002:    544 / 578 loss=2.494, loss_v1=0, loss_v2=0, nll_loss=1.312, ntokens=3060.2, nsentences=96, sample_size=3060.2, sample_size_v1=0, sample_size_v2=0, ppl=2.48, wps=1073.5, ups=0.35, wpb=3060.2, bsz=96, num_updates=1120, lr=2.67607e-05, gnorm=0.944, clip=10, loss_scale=128, train_wall=28, gb_free=12.1, wall=3222
2023-04-19 01:20:42 - progress_bar.py[line:272] - INFO: epoch 002:    554 / 578 loss=2.489, loss_v1=0, loss_v2=0, nll_loss=1.304, ntokens=3269.4, nsentences=96, sample_size=3269.4, sample_size_v1=0, sample_size_v2=0, ppl=2.47, wps=1134, ups=0.35, wpb=3269.4, bsz=96, num_updates=1130, lr=2.67147e-05, gnorm=0.921, clip=20, loss_scale=128, train_wall=29, gb_free=12.5, wall=3251
2023-04-19 01:21:11 - progress_bar.py[line:272] - INFO: epoch 002:    564 / 578 loss=2.488, loss_v1=0, loss_v2=0, nll_loss=1.303, ntokens=3220.8, nsentences=96, sample_size=3220.8, sample_size_v1=0, sample_size_v2=0, ppl=2.47, wps=1124.5, ups=0.35, wpb=3220.8, bsz=96, num_updates=1140, lr=2.66687e-05, gnorm=0.886, clip=10, loss_scale=128, train_wall=29, gb_free=12.2, wall=3280
2023-04-19 01:21:39 - progress_bar.py[line:272] - INFO: epoch 002:    574 / 578 loss=2.499, loss_v1=0, loss_v2=0, nll_loss=1.319, ntokens=3160.1, nsentences=96, sample_size=3160.1, sample_size_v1=0, sample_size_v2=0, ppl=2.49, wps=1106.5, ups=0.35, wpb=3160.1, bsz=96, num_updates=1150, lr=2.66227e-05, gnorm=0.885, clip=10, loss_scale=128, train_wall=29, gb_free=12.2, wall=3308
2023-04-19 01:21:48 - checkpoint_utils.py[line:64] - INFO: Preparing to save checkpoint for epoch 2 @ 1154 updates
2023-04-19 01:21:48 - trainer.py[line:431] - INFO: Saving checkpoint to ../../checkpoints/OFA/sgcls_checkpoints/_12_3e-5_512/checkpoint2.pt
local datafile ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 1 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 1 finished initializing row_count and line_idx-to-offset mapping
file ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 1 row count 27700 total row count 55400
slice_id 1 seek offset 27700
2023-04-19 01:21:52 - trainer.py[line:441] - INFO: Finished saving checkpoint to ../../checkpoints/OFA/sgcls_checkpoints/_12_3e-5_512/checkpoint2.pt
2023-04-19 01:21:55 - checkpoint_utils.py[line:133] - INFO: Saved checkpoint ../../checkpoints/OFA/sgcls_checkpoints/_12_3e-5_512/checkpoint2.pt (epoch 2 @ 1154 updates, score None) (writing took 6.799828403629363 seconds)
2023-04-19 01:21:55 - train.py[line:332] - INFO: end of epoch 2 (average epoch stats below)
2023-04-19 01:21:55 - progress_bar.py[line:282] - INFO: epoch 002 | loss 2.546 | loss_v1 0 | loss_v2 0 | nll_loss 1.372 | ntokens 3151.21 | nsentences 95.848 | sample_size 3151.21 | sample_size_v1 0 | sample_size_v2 0 | ppl 2.59 | wps 1100.7 | ups 0.35 | wpb 3151.2 | bsz 95.8 | num_updates 1154 | lr 2.66043e-05 | gnorm 0.914 | clip 15.4 | loss_scale 128 | train_wall 1644 | gb_free 13.1 | wall 3324
2023-04-19 01:21:55 - trainer.py[line:639] - INFO: loading train data for epoch 3
local datafile ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 0 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 0 finished initializing row_count and line_idx-to-offset mapping
file ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 0 row count 27700 total row count 55400
slice_id 0 seek offset 0
2023-04-19 01:21:57 - trainer.py[line:703] - INFO: begin training epoch 3
2023-04-19 01:21:57 - train.py[line:305] - INFO: Start iterating over samples
2023-04-19 01:22:15 - progress_bar.py[line:272] - INFO: epoch 003:      6 / 578 loss=2.476, loss_v1=0, loss_v2=0, nll_loss=1.288, ntokens=2906.4, nsentences=87.6, sample_size=2906.4, sample_size_v1=0, sample_size_v2=0, ppl=2.44, wps=825.4, ups=0.28, wpb=2906.4, bsz=87.6, num_updates=1160, lr=2.65767e-05, gnorm=1.176, clip=30, loss_scale=128, train_wall=26, gb_free=12, wall=3343
2023-04-19 01:22:43 - progress_bar.py[line:272] - INFO: epoch 003:     16 / 578 loss=2.428, loss_v1=0, loss_v2=0, nll_loss=1.237, ntokens=3043.5, nsentences=96, sample_size=3043.5, sample_size_v1=0, sample_size_v2=0, ppl=2.36, wps=1075.5, ups=0.35, wpb=3043.5, bsz=96, num_updates=1170, lr=2.65307e-05, gnorm=0.996, clip=40, loss_scale=128, train_wall=28, gb_free=12.3, wall=3372
2023-04-19 01:23:12 - progress_bar.py[line:272] - INFO: epoch 003:     26 / 578 loss=2.385, loss_v1=0, loss_v2=0, nll_loss=1.188, ntokens=3272.1, nsentences=96, sample_size=3272.1, sample_size_v1=0, sample_size_v2=0, ppl=2.28, wps=1142.1, ups=0.35, wpb=3272.1, bsz=96, num_updates=1180, lr=2.64847e-05, gnorm=0.959, clip=30, loss_scale=128, train_wall=29, gb_free=11.6, wall=3400
2023-04-19 01:23:40 - progress_bar.py[line:272] - INFO: epoch 003:     36 / 578 loss=2.428, loss_v1=0, loss_v2=0, nll_loss=1.235, ntokens=2974.5, nsentences=96, sample_size=2974.5, sample_size_v1=0, sample_size_v2=0, ppl=2.35, wps=1044.5, ups=0.35, wpb=2974.5, bsz=96, num_updates=1190, lr=2.64387e-05, gnorm=1.173, clip=90, loss_scale=128, train_wall=28, gb_free=12.2, wall=3429
2023-04-19 01:24:09 - progress_bar.py[line:272] - INFO: epoch 003:     46 / 578 loss=2.296, loss_v1=0, loss_v2=0, nll_loss=1.088, ntokens=3494.6, nsentences=96, sample_size=3494.6, sample_size_v1=0, sample_size_v2=0, ppl=2.13, wps=1201.2, ups=0.34, wpb=3494.6, bsz=96, num_updates=1200, lr=2.63926e-05, gnorm=0.882, clip=0, loss_scale=128, train_wall=29, gb_free=11.8, wall=3458
2023-04-19 01:24:38 - progress_bar.py[line:272] - INFO: epoch 003:     56 / 578 loss=2.39, loss_v1=0, loss_v2=0, nll_loss=1.196, ntokens=3396.7, nsentences=96, sample_size=3396.7, sample_size_v1=0, sample_size_v2=0, ppl=2.29, wps=1171.4, ups=0.34, wpb=3396.7, bsz=96, num_updates=1210, lr=2.63466e-05, gnorm=0.91, clip=10, loss_scale=128, train_wall=29, gb_free=11.7, wall=3487
2023-04-19 01:25:07 - progress_bar.py[line:272] - INFO: epoch 003:     66 / 578 loss=2.409, loss_v1=0, loss_v2=0, nll_loss=1.214, ntokens=3170.1, nsentences=96, sample_size=3170.1, sample_size_v1=0, sample_size_v2=0, ppl=2.32, wps=1110, ups=0.35, wpb=3170.1, bsz=96, num_updates=1220, lr=2.63006e-05, gnorm=0.946, clip=40, loss_scale=128, train_wall=29, gb_free=12.6, wall=3515
2023-04-19 01:25:35 - progress_bar.py[line:272] - INFO: epoch 003:     76 / 578 loss=2.495, loss_v1=0, loss_v2=0, nll_loss=1.311, ntokens=3051.3, nsentences=96, sample_size=3051.3, sample_size_v1=0, sample_size_v2=0, ppl=2.48, wps=1071.8, ups=0.35, wpb=3051.3, bsz=96, num_updates=1230, lr=2.62546e-05, gnorm=0.878, clip=0, loss_scale=128, train_wall=28, gb_free=11.9, wall=3544
2023-04-19 01:26:04 - progress_bar.py[line:272] - INFO: epoch 003:     86 / 578 loss=2.455, loss_v1=0, loss_v2=0, nll_loss=1.265, ntokens=3321.4, nsentences=96, sample_size=3321.4, sample_size_v1=0, sample_size_v2=0, ppl=2.4, wps=1154.5, ups=0.35, wpb=3321.4, bsz=96, num_updates=1240, lr=2.62086e-05, gnorm=0.824, clip=0, loss_scale=128, train_wall=29, gb_free=11.7, wall=3573
2023-04-19 01:26:33 - progress_bar.py[line:272] - INFO: epoch 003:     96 / 578 loss=2.424, loss_v1=0, loss_v2=0, nll_loss=1.234, ntokens=3344.4, nsentences=96, sample_size=3344.4, sample_size_v1=0, sample_size_v2=0, ppl=2.35, wps=1154, ups=0.35, wpb=3344.4, bsz=96, num_updates=1250, lr=2.61626e-05, gnorm=0.845, clip=0, loss_scale=128, train_wall=29, gb_free=11.4, wall=3602
2023-04-19 01:27:02 - progress_bar.py[line:272] - INFO: epoch 003:    106 / 578 loss=2.424, loss_v1=0, loss_v2=0, nll_loss=1.232, ntokens=3294.4, nsentences=96, sample_size=3294.4, sample_size_v1=0, sample_size_v2=0, ppl=2.35, wps=1136.2, ups=0.34, wpb=3294.4, bsz=96, num_updates=1260, lr=2.61166e-05, gnorm=0.808, clip=0, loss_scale=128, train_wall=29, gb_free=12.1, wall=3631
2023-04-19 01:27:31 - progress_bar.py[line:272] - INFO: epoch 003:    116 / 578 loss=2.43, loss_v1=0, loss_v2=0, nll_loss=1.237, ntokens=3081, nsentences=96, sample_size=3081, sample_size_v1=0, sample_size_v2=0, ppl=2.36, wps=1077.8, ups=0.35, wpb=3081, bsz=96, num_updates=1270, lr=2.60706e-05, gnorm=0.862, clip=0, loss_scale=128, train_wall=29, gb_free=12.2, wall=3659
2023-04-19 01:27:59 - progress_bar.py[line:272] - INFO: epoch 003:    126 / 578 loss=2.41, loss_v1=0, loss_v2=0, nll_loss=1.216, ntokens=3323.6, nsentences=96, sample_size=3323.6, sample_size_v1=0, sample_size_v2=0, ppl=2.32, wps=1152.3, ups=0.35, wpb=3323.6, bsz=96, num_updates=1280, lr=2.60245e-05, gnorm=0.922, clip=20, loss_scale=128, train_wall=29, gb_free=12.1, wall=3688
2023-04-19 01:28:28 - progress_bar.py[line:272] - INFO: epoch 003:    136 / 578 loss=2.453, loss_v1=0, loss_v2=0, nll_loss=1.265, ntokens=3136.6, nsentences=96, sample_size=3136.6, sample_size_v1=0, sample_size_v2=0, ppl=2.4, wps=1097.5, ups=0.35, wpb=3136.6, bsz=96, num_updates=1290, lr=2.59785e-05, gnorm=0.909, clip=20, loss_scale=128, train_wall=29, gb_free=12, wall=3717
2023-04-19 01:28:57 - progress_bar.py[line:272] - INFO: epoch 003:    146 / 578 loss=2.497, loss_v1=0, loss_v2=0, nll_loss=1.314, ntokens=3205.6, nsentences=96, sample_size=3205.6, sample_size_v1=0, sample_size_v2=0, ppl=2.49, wps=1124.5, ups=0.35, wpb=3205.6, bsz=96, num_updates=1300, lr=2.59325e-05, gnorm=0.956, clip=30, loss_scale=128, train_wall=28, gb_free=12.3, wall=3745
2023-04-19 01:29:25 - progress_bar.py[line:272] - INFO: epoch 003:    156 / 578 loss=2.503, loss_v1=0, loss_v2=0, nll_loss=1.318, ntokens=3209.2, nsentences=96, sample_size=3209.2, sample_size_v1=0, sample_size_v2=0, ppl=2.49, wps=1134.6, ups=0.35, wpb=3209.2, bsz=96, num_updates=1310, lr=2.58865e-05, gnorm=0.966, clip=20, loss_scale=128, train_wall=28, gb_free=12.2, wall=3773
2023-04-19 01:29:53 - progress_bar.py[line:272] - INFO: epoch 003:    166 / 578 loss=2.502, loss_v1=0, loss_v2=0, nll_loss=1.32, ntokens=3255.7, nsentences=96, sample_size=3255.7, sample_size_v1=0, sample_size_v2=0, ppl=2.5, wps=1143.6, ups=0.35, wpb=3255.7, bsz=96, num_updates=1320, lr=2.58405e-05, gnorm=0.9, clip=10, loss_scale=128, train_wall=28, gb_free=12.2, wall=3802
2023-04-19 01:30:22 - progress_bar.py[line:272] - INFO: epoch 003:    176 / 578 loss=2.503, loss_v1=0, loss_v2=0, nll_loss=1.32, ntokens=3216, nsentences=96, sample_size=3216, sample_size_v1=0, sample_size_v2=0, ppl=2.5, wps=1130.2, ups=0.35, wpb=3216, bsz=96, num_updates=1330, lr=2.57945e-05, gnorm=0.899, clip=0, loss_scale=128, train_wall=28, gb_free=11.8, wall=3830
2023-04-19 01:30:50 - progress_bar.py[line:272] - INFO: epoch 003:    186 / 578 loss=2.499, loss_v1=0, loss_v2=0, nll_loss=1.316, ntokens=3215.6, nsentences=96, sample_size=3215.6, sample_size_v1=0, sample_size_v2=0, ppl=2.49, wps=1131.7, ups=0.35, wpb=3215.6, bsz=96, num_updates=1340, lr=2.57485e-05, gnorm=0.855, clip=0, loss_scale=128, train_wall=28, gb_free=11.9, wall=3859
2023-04-19 01:31:19 - progress_bar.py[line:272] - INFO: epoch 003:    196 / 578 loss=2.483, loss_v1=0, loss_v2=0, nll_loss=1.299, ntokens=3216.4, nsentences=96, sample_size=3216.4, sample_size_v1=0, sample_size_v2=0, ppl=2.46, wps=1132.4, ups=0.35, wpb=3216.4, bsz=96, num_updates=1350, lr=2.57025e-05, gnorm=0.895, clip=20, loss_scale=128, train_wall=28, gb_free=11.5, wall=3887
2023-04-19 01:31:47 - progress_bar.py[line:272] - INFO: epoch 003:    206 / 578 loss=2.473, loss_v1=0, loss_v2=0, nll_loss=1.287, ntokens=3233.6, nsentences=96, sample_size=3233.6, sample_size_v1=0, sample_size_v2=0, ppl=2.44, wps=1139.5, ups=0.35, wpb=3233.6, bsz=96, num_updates=1360, lr=2.56564e-05, gnorm=0.889, clip=0, loss_scale=128, train_wall=28, gb_free=12.2, wall=3916
2023-04-19 01:32:15 - progress_bar.py[line:272] - INFO: epoch 003:    216 / 578 loss=2.51, loss_v1=0, loss_v2=0, nll_loss=1.327, ntokens=2982.9, nsentences=96, sample_size=2982.9, sample_size_v1=0, sample_size_v2=0, ppl=2.51, wps=1056.4, ups=0.35, wpb=2982.9, bsz=96, num_updates=1370, lr=2.56104e-05, gnorm=0.926, clip=0, loss_scale=128, train_wall=28, gb_free=12.2, wall=3944
2023-04-19 01:32:44 - progress_bar.py[line:272] - INFO: epoch 003:    226 / 578 loss=2.469, loss_v1=0, loss_v2=0, nll_loss=1.282, ntokens=3160.5, nsentences=96, sample_size=3160.5, sample_size_v1=0, sample_size_v2=0, ppl=2.43, wps=1112.7, ups=0.35, wpb=3160.5, bsz=96, num_updates=1380, lr=2.55644e-05, gnorm=0.922, clip=10, loss_scale=128, train_wall=28, gb_free=12.5, wall=3972
2023-04-19 01:33:12 - progress_bar.py[line:272] - INFO: epoch 003:    236 / 578 loss=2.495, loss_v1=0, loss_v2=0, nll_loss=1.311, ntokens=2934.7, nsentences=95.6, sample_size=2934.7, sample_size_v1=0, sample_size_v2=0, ppl=2.48, wps=1043.9, ups=0.36, wpb=2934.7, bsz=95.6, num_updates=1390, lr=2.55184e-05, gnorm=0.978, clip=30, loss_scale=128, train_wall=28, gb_free=11.8, wall=4000
2023-04-19 01:33:40 - progress_bar.py[line:272] - INFO: epoch 003:    246 / 578 loss=2.494, loss_v1=0, loss_v2=0, nll_loss=1.309, ntokens=2949, nsentences=96, sample_size=2949, sample_size_v1=0, sample_size_v2=0, ppl=2.48, wps=1045.7, ups=0.35, wpb=2949, bsz=96, num_updates=1400, lr=2.54724e-05, gnorm=0.945, clip=20, loss_scale=128, train_wall=28, gb_free=12.5, wall=4029
2023-04-19 01:34:08 - progress_bar.py[line:272] - INFO: epoch 003:    256 / 578 loss=2.477, loss_v1=0, loss_v2=0, nll_loss=1.289, ntokens=3239.8, nsentences=96, sample_size=3239.8, sample_size_v1=0, sample_size_v2=0, ppl=2.44, wps=1139.7, ups=0.35, wpb=3239.8, bsz=96, num_updates=1410, lr=2.54264e-05, gnorm=0.862, clip=0, loss_scale=128, train_wall=28, gb_free=12, wall=4057
2023-04-19 01:34:37 - progress_bar.py[line:272] - INFO: epoch 003:    266 / 578 loss=2.473, loss_v1=0, loss_v2=0, nll_loss=1.289, ntokens=3085.1, nsentences=96, sample_size=3085.1, sample_size_v1=0, sample_size_v2=0, ppl=2.44, wps=1085.2, ups=0.35, wpb=3085.1, bsz=96, num_updates=1420, lr=2.53804e-05, gnorm=0.905, clip=0, loss_scale=128, train_wall=28, gb_free=12.3, wall=4085
2023-04-19 01:35:05 - progress_bar.py[line:272] - INFO: epoch 003:    276 / 578 loss=2.469, loss_v1=0, loss_v2=0, nll_loss=1.281, ntokens=3178.2, nsentences=96, sample_size=3178.2, sample_size_v1=0, sample_size_v2=0, ppl=2.43, wps=1121.9, ups=0.35, wpb=3178.2, bsz=96, num_updates=1430, lr=2.53344e-05, gnorm=0.892, clip=10, loss_scale=128, train_wall=28, gb_free=10.9, wall=4114
2023-04-19 01:35:34 - progress_bar.py[line:272] - INFO: epoch 003:    286 / 578 loss=2.468, loss_v1=0, loss_v2=0, nll_loss=1.282, ntokens=3112.2, nsentences=96, sample_size=3112.2, sample_size_v1=0, sample_size_v2=0, ppl=2.43, wps=1097.1, ups=0.35, wpb=3112.2, bsz=96, num_updates=1440, lr=2.52883e-05, gnorm=0.942, clip=20, loss_scale=128, train_wall=28, gb_free=12.3, wall=4142
2023-04-19 01:36:02 - progress_bar.py[line:272] - INFO: epoch 003:    296 / 578 loss=2.494, loss_v1=0, loss_v2=0, nll_loss=1.308, ntokens=3085.7, nsentences=96, sample_size=3085.7, sample_size_v1=0, sample_size_v2=0, ppl=2.48, wps=1081.2, ups=0.35, wpb=3085.7, bsz=96, num_updates=1450, lr=2.52423e-05, gnorm=0.915, clip=10, loss_scale=128, train_wall=29, gb_free=12.5, wall=4171
2023-04-19 01:36:31 - progress_bar.py[line:272] - INFO: epoch 003:    306 / 578 loss=2.477, loss_v1=0, loss_v2=0, nll_loss=1.291, ntokens=3130.2, nsentences=96, sample_size=3130.2, sample_size_v1=0, sample_size_v2=0, ppl=2.45, wps=1099.8, ups=0.35, wpb=3130.2, bsz=96, num_updates=1460, lr=2.51963e-05, gnorm=0.923, clip=20, loss_scale=128, train_wall=28, gb_free=12.2, wall=4199
2023-04-19 01:36:59 - progress_bar.py[line:272] - INFO: epoch 003:    316 / 578 loss=2.47, loss_v1=0, loss_v2=0, nll_loss=1.283, ntokens=3262, nsentences=96, sample_size=3262, sample_size_v1=0, sample_size_v2=0, ppl=2.43, wps=1148.2, ups=0.35, wpb=3262, bsz=96, num_updates=1470, lr=2.51503e-05, gnorm=0.896, clip=10, loss_scale=128, train_wall=28, gb_free=12, wall=4228
2023-04-19 01:37:27 - progress_bar.py[line:272] - INFO: epoch 003:    326 / 578 loss=2.463, loss_v1=0, loss_v2=0, nll_loss=1.275, ntokens=3153.1, nsentences=96, sample_size=3153.1, sample_size_v1=0, sample_size_v2=0, ppl=2.42, wps=1105.3, ups=0.35, wpb=3153.1, bsz=96, num_updates=1480, lr=2.51043e-05, gnorm=0.911, clip=0, loss_scale=128, train_wall=28, gb_free=12.5, wall=4256
2023-04-19 01:37:56 - progress_bar.py[line:272] - INFO: epoch 003:    336 / 578 loss=2.472, loss_v1=0, loss_v2=0, nll_loss=1.285, ntokens=3112.2, nsentences=96, sample_size=3112.2, sample_size_v1=0, sample_size_v2=0, ppl=2.44, wps=1094, ups=0.35, wpb=3112.2, bsz=96, num_updates=1490, lr=2.50583e-05, gnorm=0.973, clip=30, loss_scale=128, train_wall=28, gb_free=12.3, wall=4285
2023-04-19 01:38:24 - progress_bar.py[line:272] - INFO: epoch 003:    346 / 578 loss=2.477, loss_v1=0, loss_v2=0, nll_loss=1.291, ntokens=3237, nsentences=96, sample_size=3237, sample_size_v1=0, sample_size_v2=0, ppl=2.45, wps=1141.2, ups=0.35, wpb=3237, bsz=96, num_updates=1500, lr=2.50123e-05, gnorm=0.902, clip=0, loss_scale=128, train_wall=28, gb_free=12.6, wall=4313
2023-04-19 01:38:53 - progress_bar.py[line:272] - INFO: epoch 003:    356 / 578 loss=2.463, loss_v1=0, loss_v2=0, nll_loss=1.275, ntokens=3083.9, nsentences=96, sample_size=3083.9, sample_size_v1=0, sample_size_v2=0, ppl=2.42, wps=1087.8, ups=0.35, wpb=3083.9, bsz=96, num_updates=1510, lr=2.49663e-05, gnorm=0.963, clip=40, loss_scale=128, train_wall=28, gb_free=12.1, wall=4341
2023-04-19 01:39:21 - progress_bar.py[line:272] - INFO: epoch 003:    366 / 578 loss=2.488, loss_v1=0, loss_v2=0, nll_loss=1.303, ntokens=3381.6, nsentences=96, sample_size=3381.6, sample_size_v1=0, sample_size_v2=0, ppl=2.47, wps=1184, ups=0.35, wpb=3381.6, bsz=96, num_updates=1520, lr=2.49202e-05, gnorm=0.885, clip=0, loss_scale=128, train_wall=29, gb_free=12.4, wall=4370
2023-04-19 01:39:50 - progress_bar.py[line:272] - INFO: epoch 003:    376 / 578 loss=2.474, loss_v1=0, loss_v2=0, nll_loss=1.286, ntokens=3369.1, nsentences=96, sample_size=3369.1, sample_size_v1=0, sample_size_v2=0, ppl=2.44, wps=1174.1, ups=0.35, wpb=3369.1, bsz=96, num_updates=1530, lr=2.48742e-05, gnorm=0.952, clip=20, loss_scale=128, train_wall=29, gb_free=12, wall=4399
2023-04-19 01:40:18 - progress_bar.py[line:272] - INFO: epoch 003:    386 / 578 loss=2.471, loss_v1=0, loss_v2=0, nll_loss=1.282, ntokens=3230, nsentences=96, sample_size=3230, sample_size_v1=0, sample_size_v2=0, ppl=2.43, wps=1135.7, ups=0.35, wpb=3230, bsz=96, num_updates=1540, lr=2.48282e-05, gnorm=0.893, clip=0, loss_scale=128, train_wall=28, gb_free=12.1, wall=4427
2023-04-19 01:40:47 - progress_bar.py[line:272] - INFO: epoch 003:    396 / 578 loss=2.456, loss_v1=0, loss_v2=0, nll_loss=1.268, ntokens=3176.8, nsentences=96, sample_size=3176.8, sample_size_v1=0, sample_size_v2=0, ppl=2.41, wps=1116.1, ups=0.35, wpb=3176.8, bsz=96, num_updates=1550, lr=2.47822e-05, gnorm=0.887, clip=0, loss_scale=256, train_wall=28, gb_free=12.1, wall=4455
2023-04-19 01:41:15 - progress_bar.py[line:272] - INFO: epoch 003:    406 / 578 loss=2.457, loss_v1=0, loss_v2=0, nll_loss=1.268, ntokens=3029.1, nsentences=96, sample_size=3029.1, sample_size_v1=0, sample_size_v2=0, ppl=2.41, wps=1064.1, ups=0.35, wpb=3029.1, bsz=96, num_updates=1560, lr=2.47362e-05, gnorm=0.978, clip=40, loss_scale=256, train_wall=28, gb_free=11.7, wall=4484
2023-04-19 01:41:44 - progress_bar.py[line:272] - INFO: epoch 003:    416 / 578 loss=2.474, loss_v1=0, loss_v2=0, nll_loss=1.288, ntokens=2989.8, nsentences=96, sample_size=2989.8, sample_size_v1=0, sample_size_v2=0, ppl=2.44, wps=1049.6, ups=0.35, wpb=2989.8, bsz=96, num_updates=1570, lr=2.46902e-05, gnorm=1.002, clip=50, loss_scale=256, train_wall=28, gb_free=12.3, wall=4512
2023-04-19 01:42:12 - progress_bar.py[line:272] - INFO: epoch 003:    426 / 578 loss=2.44, loss_v1=0, loss_v2=0, nll_loss=1.249, ntokens=3071, nsentences=96, sample_size=3071, sample_size_v1=0, sample_size_v2=0, ppl=2.38, wps=1081.8, ups=0.35, wpb=3071, bsz=96, num_updates=1580, lr=2.46442e-05, gnorm=0.966, clip=30, loss_scale=256, train_wall=28, gb_free=12.1, wall=4541
2023-04-19 01:42:40 - progress_bar.py[line:272] - INFO: epoch 003:    436 / 578 loss=2.482, loss_v1=0, loss_v2=0, nll_loss=1.295, ntokens=2980.4, nsentences=96, sample_size=2980.4, sample_size_v1=0, sample_size_v2=0, ppl=2.45, wps=1056.2, ups=0.35, wpb=2980.4, bsz=96, num_updates=1590, lr=2.45982e-05, gnorm=0.942, clip=10, loss_scale=256, train_wall=28, gb_free=12.3, wall=4569
2023-04-19 01:43:09 - progress_bar.py[line:272] - INFO: epoch 003:    446 / 578 loss=2.483, loss_v1=0, loss_v2=0, nll_loss=1.295, ntokens=2950.9, nsentences=96, sample_size=2950.9, sample_size_v1=0, sample_size_v2=0, ppl=2.45, wps=1037.2, ups=0.35, wpb=2950.9, bsz=96, num_updates=1600, lr=2.45521e-05, gnorm=1.03, clip=60, loss_scale=256, train_wall=28, gb_free=12.1, wall=4597
2023-04-19 01:43:37 - progress_bar.py[line:272] - INFO: epoch 003:    456 / 578 loss=2.453, loss_v1=0, loss_v2=0, nll_loss=1.266, ntokens=3100.2, nsentences=96, sample_size=3100.2, sample_size_v1=0, sample_size_v2=0, ppl=2.4, wps=1092.7, ups=0.35, wpb=3100.2, bsz=96, num_updates=1610, lr=2.45061e-05, gnorm=0.945, clip=10, loss_scale=256, train_wall=28, gb_free=12.6, wall=4626
2023-04-19 01:44:06 - progress_bar.py[line:272] - INFO: epoch 003:    466 / 578 loss=2.474, loss_v1=0, loss_v2=0, nll_loss=1.286, ntokens=3081, nsentences=96, sample_size=3081, sample_size_v1=0, sample_size_v2=0, ppl=2.44, wps=1083.9, ups=0.35, wpb=3081, bsz=96, num_updates=1620, lr=2.44601e-05, gnorm=0.941, clip=30, loss_scale=256, train_wall=28, gb_free=12.4, wall=4654
2023-04-19 01:44:34 - progress_bar.py[line:272] - INFO: epoch 003:    476 / 578 loss=2.481, loss_v1=0, loss_v2=0, nll_loss=1.296, ntokens=2881, nsentences=96, sample_size=2881, sample_size_v1=0, sample_size_v2=0, ppl=2.46, wps=1017, ups=0.35, wpb=2881, bsz=96, num_updates=1630, lr=2.44141e-05, gnorm=0.984, clip=60, loss_scale=256, train_wall=28, gb_free=12.2, wall=4683
2023-04-19 01:45:02 - progress_bar.py[line:272] - INFO: epoch 003:    486 / 578 loss=2.445, loss_v1=0, loss_v2=0, nll_loss=1.254, ntokens=2980.5, nsentences=96, sample_size=2980.5, sample_size_v1=0, sample_size_v2=0, ppl=2.39, wps=1052.4, ups=0.35, wpb=2980.5, bsz=96, num_updates=1640, lr=2.43681e-05, gnorm=0.9, clip=0, loss_scale=256, train_wall=28, gb_free=12.4, wall=4711
2023-04-19 01:45:31 - progress_bar.py[line:272] - INFO: epoch 003:    496 / 578 loss=2.439, loss_v1=0, loss_v2=0, nll_loss=1.247, ntokens=3181.8, nsentences=96, sample_size=3181.8, sample_size_v1=0, sample_size_v2=0, ppl=2.37, wps=1114.8, ups=0.35, wpb=3181.8, bsz=96, num_updates=1650, lr=2.43221e-05, gnorm=0.96, clip=20, loss_scale=256, train_wall=29, gb_free=12.3, wall=4739
2023-04-19 01:45:59 - progress_bar.py[line:272] - INFO: epoch 003:    506 / 578 loss=2.438, loss_v1=0, loss_v2=0, nll_loss=1.249, ntokens=3112.7, nsentences=96, sample_size=3112.7, sample_size_v1=0, sample_size_v2=0, ppl=2.38, wps=1094.9, ups=0.35, wpb=3112.7, bsz=96, num_updates=1660, lr=2.42761e-05, gnorm=0.989, clip=50, loss_scale=256, train_wall=28, gb_free=12.3, wall=4768
2023-04-19 01:46:28 - progress_bar.py[line:272] - INFO: epoch 003:    516 / 578 loss=2.437, loss_v1=0, loss_v2=0, nll_loss=1.244, ntokens=3254, nsentences=96, sample_size=3254, sample_size_v1=0, sample_size_v2=0, ppl=2.37, wps=1144.6, ups=0.35, wpb=3254, bsz=96, num_updates=1670, lr=2.42301e-05, gnorm=0.946, clip=20, loss_scale=256, train_wall=28, gb_free=12.3, wall=4796
2023-04-19 01:46:56 - progress_bar.py[line:272] - INFO: epoch 003:    526 / 578 loss=2.448, loss_v1=0, loss_v2=0, nll_loss=1.259, ntokens=3131.8, nsentences=96, sample_size=3131.8, sample_size_v1=0, sample_size_v2=0, ppl=2.39, wps=1102.3, ups=0.35, wpb=3131.8, bsz=96, num_updates=1680, lr=2.4184e-05, gnorm=0.947, clip=50, loss_scale=256, train_wall=28, gb_free=12.4, wall=4825
2023-04-19 01:47:24 - progress_bar.py[line:272] - INFO: epoch 003:    536 / 578 loss=2.45, loss_v1=0, loss_v2=0, nll_loss=1.259, ntokens=3025.8, nsentences=96, sample_size=3025.8, sample_size_v1=0, sample_size_v2=0, ppl=2.39, wps=1069.6, ups=0.35, wpb=3025.8, bsz=96, num_updates=1690, lr=2.4138e-05, gnorm=1, clip=50, loss_scale=256, train_wall=28, gb_free=11.9, wall=4853
2023-04-19 01:47:53 - progress_bar.py[line:272] - INFO: epoch 003:    546 / 578 loss=2.434, loss_v1=0, loss_v2=0, nll_loss=1.241, ntokens=3115.7, nsentences=96, sample_size=3115.7, sample_size_v1=0, sample_size_v2=0, ppl=2.36, wps=1091.8, ups=0.35, wpb=3115.7, bsz=96, num_updates=1700, lr=2.4092e-05, gnorm=0.977, clip=40, loss_scale=256, train_wall=29, gb_free=12.3, wall=4882
2023-04-19 01:48:22 - progress_bar.py[line:272] - INFO: epoch 003:    556 / 578 loss=2.437, loss_v1=0, loss_v2=0, nll_loss=1.245, ntokens=3293.5, nsentences=96, sample_size=3293.5, sample_size_v1=0, sample_size_v2=0, ppl=2.37, wps=1138, ups=0.35, wpb=3293.5, bsz=96, num_updates=1710, lr=2.4046e-05, gnorm=0.951, clip=10, loss_scale=256, train_wall=29, gb_free=12.5, wall=4911
2023-04-19 01:48:51 - progress_bar.py[line:272] - INFO: epoch 003:    566 / 578 loss=2.438, loss_v1=0, loss_v2=0, nll_loss=1.247, ntokens=3228.4, nsentences=96, sample_size=3228.4, sample_size_v1=0, sample_size_v2=0, ppl=2.37, wps=1129.1, ups=0.35, wpb=3228.4, bsz=96, num_updates=1720, lr=2.4e-05, gnorm=0.906, clip=20, loss_scale=256, train_wall=29, gb_free=11.9, wall=4939
2023-04-19 01:49:19 - progress_bar.py[line:272] - INFO: epoch 003:    576 / 578 loss=2.453, loss_v1=0, loss_v2=0, nll_loss=1.264, ntokens=3137.9, nsentences=96, sample_size=3137.9, sample_size_v1=0, sample_size_v2=0, ppl=2.4, wps=1098.3, ups=0.35, wpb=3137.9, bsz=96, num_updates=1730, lr=2.3954e-05, gnorm=0.969, clip=50, loss_scale=256, train_wall=29, gb_free=12.3, wall=4968
2023-04-19 01:49:22 - checkpoint_utils.py[line:64] - INFO: Preparing to save checkpoint for epoch 3 @ 1732 updates
2023-04-19 01:49:22 - trainer.py[line:431] - INFO: Saving checkpoint to ../../checkpoints/OFA/sgcls_checkpoints/_12_3e-5_512/checkpoint3.pt
local datafile ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 1 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 1 finished initializing row_count and line_idx-to-offset mapping
file ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 1 row count 27700 total row count 55400
slice_id 1 seek offset 27700
2023-04-19 01:49:25 - trainer.py[line:441] - INFO: Finished saving checkpoint to ../../checkpoints/OFA/sgcls_checkpoints/_12_3e-5_512/checkpoint3.pt
2023-04-19 01:49:30 - checkpoint_utils.py[line:133] - INFO: Saved checkpoint ../../checkpoints/OFA/sgcls_checkpoints/_12_3e-5_512/checkpoint3.pt (epoch 3 @ 1732 updates, score None) (writing took 7.173941398970783 seconds)
2023-04-19 01:49:30 - train.py[line:332] - INFO: end of epoch 3 (average epoch stats below)
2023-04-19 01:49:30 - progress_bar.py[line:282] - INFO: epoch 003 | loss 2.457 | loss_v1 0 | loss_v2 0 | nll_loss 1.269 | ntokens 3151.21 | nsentences 95.848 | sample_size 3151.21 | sample_size_v1 0 | sample_size_v2 0 | ppl 2.41 | wps 1101 | ups 0.35 | wpb 3151.2 | bsz 95.8 | num_updates 1732 | lr 2.39448e-05 | gnorm 0.934 | clip 20.4 | loss_scale 256 | train_wall 1643 | gb_free 13.1 | wall 4978
2023-04-19 01:49:30 - trainer.py[line:639] - INFO: loading train data for epoch 4
local datafile ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 0 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 0 finished initializing row_count and line_idx-to-offset mapping
file ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 0 row count 27700 total row count 55400
slice_id 0 seek offset 0
2023-04-19 01:49:31 - trainer.py[line:703] - INFO: begin training epoch 4
2023-04-19 01:49:31 - train.py[line:305] - INFO: Start iterating over samples
2023-04-19 01:49:55 - progress_bar.py[line:272] - INFO: epoch 004:      8 / 578 loss=2.406, loss_v1=0, loss_v2=0, nll_loss=1.209, ntokens=2869, nsentences=87.6, sample_size=2869, sample_size_v1=0, sample_size_v2=0, ppl=2.31, wps=805.9, ups=0.28, wpb=2869, bsz=87.6, num_updates=1740, lr=2.3908e-05, gnorm=1.171, clip=60, loss_scale=256, train_wall=26, gb_free=12.2, wall=5003
2023-04-19 01:50:23 - progress_bar.py[line:272] - INFO: epoch 004:     18 / 578 loss=2.387, loss_v1=0, loss_v2=0, nll_loss=1.189, ntokens=3032.5, nsentences=96, sample_size=3032.5, sample_size_v1=0, sample_size_v2=0, ppl=2.28, wps=1061.7, ups=0.35, wpb=3032.5, bsz=96, num_updates=1750, lr=2.3862e-05, gnorm=1.017, clip=70, loss_scale=256, train_wall=29, gb_free=11.9, wall=5032
2023-04-19 01:50:52 - progress_bar.py[line:272] - INFO: epoch 004:     28 / 578 loss=2.321, loss_v1=0, loss_v2=0, nll_loss=1.118, ntokens=3249.3, nsentences=96, sample_size=3249.3, sample_size_v1=0, sample_size_v2=0, ppl=2.17, wps=1135.1, ups=0.35, wpb=3249.3, bsz=96, num_updates=1760, lr=2.3816e-05, gnorm=0.979, clip=50, loss_scale=256, train_wall=29, gb_free=12, wall=5060
2023-04-19 01:51:20 - progress_bar.py[line:272] - INFO: epoch 004:     38 / 578 loss=2.346, loss_v1=0, loss_v2=0, nll_loss=1.141, ntokens=3042.7, nsentences=96, sample_size=3042.7, sample_size_v1=0, sample_size_v2=0, ppl=2.21, wps=1064.3, ups=0.35, wpb=3042.7, bsz=96, num_updates=1770, lr=2.37699e-05, gnorm=1.088, clip=70, loss_scale=256, train_wall=29, gb_free=12.2, wall=5089
2023-04-19 01:51:50 - progress_bar.py[line:272] - INFO: epoch 004:     48 / 578 loss=2.276, loss_v1=0, loss_v2=0, nll_loss=1.065, ntokens=3610.6, nsentences=96, sample_size=3610.6, sample_size_v1=0, sample_size_v2=0, ppl=2.09, wps=1227.6, ups=0.34, wpb=3610.6, bsz=96, num_updates=1780, lr=2.37239e-05, gnorm=0.849, clip=10, loss_scale=256, train_wall=29, gb_free=11.6, wall=5119
2023-04-19 01:52:19 - progress_bar.py[line:272] - INFO: epoch 004:     58 / 578 loss=2.342, loss_v1=0, loss_v2=0, nll_loss=1.139, ntokens=3273.1, nsentences=96, sample_size=3273.1, sample_size_v1=0, sample_size_v2=0, ppl=2.2, wps=1134.2, ups=0.35, wpb=3273.1, bsz=96, num_updates=1790, lr=2.36779e-05, gnorm=0.924, clip=20, loss_scale=256, train_wall=29, gb_free=11.6, wall=5147
2023-04-19 01:52:47 - progress_bar.py[line:272] - INFO: epoch 004:     68 / 578 loss=2.375, loss_v1=0, loss_v2=0, nll_loss=1.176, ntokens=3149.2, nsentences=96, sample_size=3149.2, sample_size_v1=0, sample_size_v2=0, ppl=2.26, wps=1104.6, ups=0.35, wpb=3149.2, bsz=96, num_updates=1800, lr=2.36319e-05, gnorm=0.969, clip=30, loss_scale=256, train_wall=28, gb_free=12.1, wall=5176
2023-04-19 01:53:16 - progress_bar.py[line:272] - INFO: epoch 004:     78 / 578 loss=2.439, loss_v1=0, loss_v2=0, nll_loss=1.247, ntokens=3106.3, nsentences=96, sample_size=3106.3, sample_size_v1=0, sample_size_v2=0, ppl=2.37, wps=1084.1, ups=0.35, wpb=3106.3, bsz=96, num_updates=1810, lr=2.35859e-05, gnorm=0.958, clip=30, loss_scale=256, train_wall=29, gb_free=11.8, wall=5205
2023-04-19 01:53:45 - progress_bar.py[line:272] - INFO: epoch 004:     88 / 578 loss=2.4, loss_v1=0, loss_v2=0, nll_loss=1.203, ntokens=3333.6, nsentences=96, sample_size=3333.6, sample_size_v1=0, sample_size_v2=0, ppl=2.3, wps=1152.2, ups=0.35, wpb=3333.6, bsz=96, num_updates=1820, lr=2.35399e-05, gnorm=0.898, clip=0, loss_scale=256, train_wall=29, gb_free=11.8, wall=5233
2023-04-19 01:54:14 - progress_bar.py[line:272] - INFO: epoch 004:     98 / 578 loss=2.38, loss_v1=0, loss_v2=0, nll_loss=1.183, ntokens=3301.9, nsentences=96, sample_size=3301.9, sample_size_v1=0, sample_size_v2=0, ppl=2.27, wps=1143.2, ups=0.35, wpb=3301.9, bsz=96, num_updates=1830, lr=2.34939e-05, gnorm=0.881, clip=0, loss_scale=256, train_wall=29, gb_free=12, wall=5262
2023-04-19 01:54:43 - progress_bar.py[line:272] - INFO: epoch 004:    108 / 578 loss=2.386, loss_v1=0, loss_v2=0, nll_loss=1.188, ntokens=3295.4, nsentences=96, sample_size=3295.4, sample_size_v1=0, sample_size_v2=0, ppl=2.28, wps=1138.3, ups=0.35, wpb=3295.4, bsz=96, num_updates=1840, lr=2.34479e-05, gnorm=0.929, clip=20, loss_scale=256, train_wall=29, gb_free=12, wall=5291
2023-04-19 01:55:11 - progress_bar.py[line:272] - INFO: epoch 004:    118 / 578 loss=2.386, loss_v1=0, loss_v2=0, nll_loss=1.187, ntokens=3146.8, nsentences=96, sample_size=3146.8, sample_size_v1=0, sample_size_v2=0, ppl=2.28, wps=1099, ups=0.35, wpb=3146.8, bsz=96, num_updates=1850, lr=2.34018e-05, gnorm=0.985, clip=30, loss_scale=256, train_wall=29, gb_free=11.9, wall=5320
2023-04-19 01:55:40 - progress_bar.py[line:272] - INFO: epoch 004:    128 / 578 loss=2.37, loss_v1=0, loss_v2=0, nll_loss=1.17, ntokens=3314.9, nsentences=96, sample_size=3314.9, sample_size_v1=0, sample_size_v2=0, ppl=2.25, wps=1150.4, ups=0.35, wpb=3314.9, bsz=96, num_updates=1860, lr=2.33558e-05, gnorm=0.904, clip=20, loss_scale=256, train_wall=29, gb_free=11.7, wall=5349
2023-04-19 01:56:09 - progress_bar.py[line:272] - INFO: epoch 004:    138 / 578 loss=2.425, loss_v1=0, loss_v2=0, nll_loss=1.233, ntokens=3034.5, nsentences=96, sample_size=3034.5, sample_size_v1=0, sample_size_v2=0, ppl=2.35, wps=1062.7, ups=0.35, wpb=3034.5, bsz=96, num_updates=1870, lr=2.33098e-05, gnorm=1, clip=60, loss_scale=256, train_wall=29, gb_free=11.8, wall=5377
2023-04-19 01:56:37 - progress_bar.py[line:272] - INFO: epoch 004:    148 / 578 loss=2.447, loss_v1=0, loss_v2=0, nll_loss=1.257, ntokens=3289.2, nsentences=96, sample_size=3289.2, sample_size_v1=0, sample_size_v2=0, ppl=2.39, wps=1150.5, ups=0.35, wpb=3289.2, bsz=96, num_updates=1880, lr=2.32638e-05, gnorm=0.989, clip=40, loss_scale=256, train_wall=29, gb_free=11.9, wall=5406
2023-04-19 01:57:06 - progress_bar.py[line:272] - INFO: epoch 004:    158 / 578 loss=2.471, loss_v1=0, loss_v2=0, nll_loss=1.282, ntokens=3194, nsentences=96, sample_size=3194, sample_size_v1=0, sample_size_v2=0, ppl=2.43, wps=1127.2, ups=0.35, wpb=3194, bsz=96, num_updates=1890, lr=2.32178e-05, gnorm=1.02, clip=60, loss_scale=256, train_wall=28, gb_free=11.8, wall=5434
2023-04-19 01:57:34 - progress_bar.py[line:272] - INFO: epoch 004:    168 / 578 loss=2.45, loss_v1=0, loss_v2=0, nll_loss=1.26, ntokens=3233.2, nsentences=96, sample_size=3233.2, sample_size_v1=0, sample_size_v2=0, ppl=2.39, wps=1137.4, ups=0.35, wpb=3233.2, bsz=96, num_updates=1900, lr=2.31718e-05, gnorm=0.973, clip=30, loss_scale=256, train_wall=28, gb_free=12.2, wall=5463
2023-04-19 01:58:03 - progress_bar.py[line:272] - INFO: epoch 004:    178 / 578 loss=2.458, loss_v1=0, loss_v2=0, nll_loss=1.268, ntokens=3184.5, nsentences=96, sample_size=3184.5, sample_size_v1=0, sample_size_v2=0, ppl=2.41, wps=1118.8, ups=0.35, wpb=3184.5, bsz=96, num_updates=1910, lr=2.31258e-05, gnorm=0.93, clip=30, loss_scale=256, train_wall=28, gb_free=12.1, wall=5491
2023-04-19 01:58:31 - progress_bar.py[line:272] - INFO: epoch 004:    188 / 578 loss=2.461, loss_v1=0, loss_v2=0, nll_loss=1.273, ntokens=3275.1, nsentences=96, sample_size=3275.1, sample_size_v1=0, sample_size_v2=0, ppl=2.42, wps=1148.9, ups=0.35, wpb=3275.1, bsz=96, num_updates=1920, lr=2.30798e-05, gnorm=0.939, clip=10, loss_scale=256, train_wall=28, gb_free=11.8, wall=5520
2023-04-19 01:58:59 - progress_bar.py[line:272] - INFO: epoch 004:    198 / 578 loss=2.43, loss_v1=0, loss_v2=0, nll_loss=1.238, ntokens=3209.2, nsentences=96, sample_size=3209.2, sample_size_v1=0, sample_size_v2=0, ppl=2.36, wps=1130.3, ups=0.35, wpb=3209.2, bsz=96, num_updates=1930, lr=2.30337e-05, gnorm=0.941, clip=20, loss_scale=256, train_wall=28, gb_free=11.9, wall=5548
2023-04-19 01:59:28 - progress_bar.py[line:272] - INFO: epoch 004:    208 / 578 loss=2.433, loss_v1=0, loss_v2=0, nll_loss=1.242, ntokens=3178.6, nsentences=96, sample_size=3178.6, sample_size_v1=0, sample_size_v2=0, ppl=2.36, wps=1120, ups=0.35, wpb=3178.6, bsz=96, num_updates=1940, lr=2.29877e-05, gnorm=0.959, clip=20, loss_scale=256, train_wall=28, gb_free=12.4, wall=5576
2023-04-19 01:59:56 - progress_bar.py[line:272] - INFO: epoch 004:    218 / 578 loss=2.466, loss_v1=0, loss_v2=0, nll_loss=1.277, ntokens=3047.8, nsentences=96, sample_size=3047.8, sample_size_v1=0, sample_size_v2=0, ppl=2.42, wps=1077.1, ups=0.35, wpb=3047.8, bsz=96, num_updates=1950, lr=2.29417e-05, gnorm=0.999, clip=50, loss_scale=256, train_wall=28, gb_free=12.3, wall=5605
2023-04-19 02:00:25 - progress_bar.py[line:272] - INFO: epoch 004:    228 / 578 loss=2.427, loss_v1=0, loss_v2=0, nll_loss=1.234, ntokens=3085.7, nsentences=96, sample_size=3085.7, sample_size_v1=0, sample_size_v2=0, ppl=2.35, wps=1084.3, ups=0.35, wpb=3085.7, bsz=96, num_updates=1960, lr=2.28957e-05, gnorm=0.978, clip=30, loss_scale=256, train_wall=28, gb_free=12.5, wall=5633
2023-04-19 02:00:53 - progress_bar.py[line:272] - INFO: epoch 004:    238 / 578 loss=2.46, loss_v1=0, loss_v2=0, nll_loss=1.27, ntokens=2931.9, nsentences=96, sample_size=2931.9, sample_size_v1=0, sample_size_v2=0, ppl=2.41, wps=1035.6, ups=0.35, wpb=2931.9, bsz=96, num_updates=1970, lr=2.28497e-05, gnorm=1.064, clip=90, loss_scale=256, train_wall=28, gb_free=12.5, wall=5662
2023-04-19 02:01:21 - progress_bar.py[line:272] - INFO: epoch 004:    248 / 578 loss=2.45, loss_v1=0, loss_v2=0, nll_loss=1.259, ntokens=3028.6, nsentences=96, sample_size=3028.6, sample_size_v1=0, sample_size_v2=0, ppl=2.39, wps=1068.5, ups=0.35, wpb=3028.6, bsz=96, num_updates=1980, lr=2.28037e-05, gnorm=0.972, clip=20, loss_scale=256, train_wall=28, gb_free=12.2, wall=5690
2023-04-19 02:01:50 - progress_bar.py[line:272] - INFO: epoch 004:    258 / 578 loss=2.427, loss_v1=0, loss_v2=0, nll_loss=1.234, ntokens=3246.1, nsentences=96, sample_size=3246.1, sample_size_v1=0, sample_size_v2=0, ppl=2.35, wps=1140.3, ups=0.35, wpb=3246.1, bsz=96, num_updates=1990, lr=2.27577e-05, gnorm=0.93, clip=30, loss_scale=256, train_wall=28, gb_free=12.4, wall=5718
2023-04-19 02:02:18 - progress_bar.py[line:272] - INFO: epoch 004:    268 / 578 loss=2.438, loss_v1=0, loss_v2=0, nll_loss=1.247, ntokens=3021.9, nsentences=96, sample_size=3021.9, sample_size_v1=0, sample_size_v2=0, ppl=2.37, wps=1065.6, ups=0.35, wpb=3021.9, bsz=96, num_updates=2000, lr=2.27117e-05, gnorm=0.96, clip=20, loss_scale=256, train_wall=28, gb_free=12.1, wall=5747
2023-04-19 02:02:47 - progress_bar.py[line:272] - INFO: epoch 004:    278 / 578 loss=2.438, loss_v1=0, loss_v2=0, nll_loss=1.246, ntokens=3194.8, nsentences=96, sample_size=3194.8, sample_size_v1=0, sample_size_v2=0, ppl=2.37, wps=1122.7, ups=0.35, wpb=3194.8, bsz=96, num_updates=2010, lr=2.26656e-05, gnorm=0.97, clip=40, loss_scale=256, train_wall=28, gb_free=12.5, wall=5775
2023-04-19 02:03:15 - progress_bar.py[line:272] - INFO: epoch 004:    288 / 578 loss=2.427, loss_v1=0, loss_v2=0, nll_loss=1.235, ntokens=3154.1, nsentences=96, sample_size=3154.1, sample_size_v1=0, sample_size_v2=0, ppl=2.35, wps=1110.6, ups=0.35, wpb=3154.1, bsz=96, num_updates=2020, lr=2.26196e-05, gnorm=0.935, clip=0, loss_scale=256, train_wall=28, gb_free=12.6, wall=5804
2023-04-19 02:03:44 - progress_bar.py[line:272] - INFO: epoch 004:    298 / 578 loss=2.459, loss_v1=0, loss_v2=0, nll_loss=1.268, ntokens=3065.2, nsentences=96, sample_size=3065.2, sample_size_v1=0, sample_size_v2=0, ppl=2.41, wps=1072.3, ups=0.35, wpb=3065.2, bsz=96, num_updates=2030, lr=2.25736e-05, gnorm=0.987, clip=30, loss_scale=256, train_wall=29, gb_free=12, wall=5832
2023-04-19 02:04:12 - progress_bar.py[line:272] - INFO: epoch 004:    308 / 578 loss=2.434, loss_v1=0, loss_v2=0, nll_loss=1.242, ntokens=3172.9, nsentences=96, sample_size=3172.9, sample_size_v1=0, sample_size_v2=0, ppl=2.37, wps=1111.3, ups=0.35, wpb=3172.9, bsz=96, num_updates=2040, lr=2.25276e-05, gnorm=0.958, clip=40, loss_scale=256, train_wall=29, gb_free=12, wall=5861
2023-04-19 02:04:41 - progress_bar.py[line:272] - INFO: epoch 004:    318 / 578 loss=2.439, loss_v1=0, loss_v2=0, nll_loss=1.247, ntokens=3275.4, nsentences=95.6, sample_size=3275.4, sample_size_v1=0, sample_size_v2=0, ppl=2.37, wps=1143.6, ups=0.35, wpb=3275.4, bsz=95.6, num_updates=2050, lr=2.24816e-05, gnorm=0.961, clip=30, loss_scale=256, train_wall=29, gb_free=12.2, wall=5889
2023-04-19 02:05:09 - progress_bar.py[line:272] - INFO: epoch 004:    328 / 578 loss=2.421, loss_v1=0, loss_v2=0, nll_loss=1.229, ntokens=3088, nsentences=96, sample_size=3088, sample_size_v1=0, sample_size_v2=0, ppl=2.34, wps=1082.4, ups=0.35, wpb=3088, bsz=96, num_updates=2060, lr=2.24356e-05, gnorm=0.967, clip=20, loss_scale=512, train_wall=28, gb_free=12.1, wall=5918
2023-04-19 02:05:38 - progress_bar.py[line:272] - INFO: epoch 004:    338 / 578 loss=2.438, loss_v1=0, loss_v2=0, nll_loss=1.244, ntokens=3124, nsentences=96, sample_size=3124, sample_size_v1=0, sample_size_v2=0, ppl=2.37, wps=1095.8, ups=0.35, wpb=3124, bsz=96, num_updates=2070, lr=2.23896e-05, gnorm=0.976, clip=40, loss_scale=512, train_wall=28, gb_free=12.2, wall=5946
2023-04-19 02:05:49 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 256.0
2023-04-19 02:06:09 - progress_bar.py[line:272] - INFO: epoch 004:    349 / 578 loss=2.444, loss_v1=0, loss_v2=0, nll_loss=1.255, ntokens=3195.1, nsentences=96, sample_size=3195.1, sample_size_v1=0, sample_size_v2=0, ppl=2.39, wps=1024.2, ups=0.32, wpb=3195.1, bsz=96, num_updates=2080, lr=2.23436e-05, gnorm=0.971, clip=30, loss_scale=256, train_wall=31, gb_free=12.6, wall=5978
2023-04-19 02:06:37 - progress_bar.py[line:272] - INFO: epoch 004:    359 / 578 loss=2.426, loss_v1=0, loss_v2=0, nll_loss=1.231, ntokens=3118.5, nsentences=96, sample_size=3118.5, sample_size_v1=0, sample_size_v2=0, ppl=2.35, wps=1094.6, ups=0.35, wpb=3118.5, bsz=96, num_updates=2090, lr=2.22975e-05, gnorm=0.994, clip=60, loss_scale=256, train_wall=28, gb_free=12.2, wall=6006
2023-04-19 02:07:06 - progress_bar.py[line:272] - INFO: epoch 004:    369 / 578 loss=2.457, loss_v1=0, loss_v2=0, nll_loss=1.268, ntokens=3403.4, nsentences=96, sample_size=3403.4, sample_size_v1=0, sample_size_v2=0, ppl=2.41, wps=1186.2, ups=0.35, wpb=3403.4, bsz=96, num_updates=2100, lr=2.22515e-05, gnorm=0.974, clip=40, loss_scale=256, train_wall=29, gb_free=12.6, wall=6035
2023-04-19 02:07:35 - progress_bar.py[line:272] - INFO: epoch 004:    379 / 578 loss=2.431, loss_v1=0, loss_v2=0, nll_loss=1.238, ntokens=3373.9, nsentences=96, sample_size=3373.9, sample_size_v1=0, sample_size_v2=0, ppl=2.36, wps=1179.9, ups=0.35, wpb=3373.9, bsz=96, num_updates=2110, lr=2.22055e-05, gnorm=0.935, clip=20, loss_scale=256, train_wall=29, gb_free=12.1, wall=6063
2023-04-19 02:08:03 - progress_bar.py[line:272] - INFO: epoch 004:    389 / 578 loss=2.44, loss_v1=0, loss_v2=0, nll_loss=1.248, ntokens=3161, nsentences=96, sample_size=3161, sample_size_v1=0, sample_size_v2=0, ppl=2.37, wps=1111.5, ups=0.35, wpb=3161, bsz=96, num_updates=2120, lr=2.21595e-05, gnorm=0.97, clip=40, loss_scale=256, train_wall=28, gb_free=12.4, wall=6092
2023-04-19 02:08:32 - progress_bar.py[line:272] - INFO: epoch 004:    399 / 578 loss=2.403, loss_v1=0, loss_v2=0, nll_loss=1.21, ntokens=3179, nsentences=96, sample_size=3179, sample_size_v1=0, sample_size_v2=0, ppl=2.31, wps=1110.4, ups=0.35, wpb=3179, bsz=96, num_updates=2130, lr=2.21135e-05, gnorm=0.963, clip=20, loss_scale=256, train_wall=29, gb_free=12.7, wall=6120
2023-04-19 02:09:00 - progress_bar.py[line:272] - INFO: epoch 004:    409 / 578 loss=2.437, loss_v1=0, loss_v2=0, nll_loss=1.243, ntokens=2968.3, nsentences=96, sample_size=2968.3, sample_size_v1=0, sample_size_v2=0, ppl=2.37, wps=1044.8, ups=0.35, wpb=2968.3, bsz=96, num_updates=2140, lr=2.20675e-05, gnorm=1.035, clip=50, loss_scale=256, train_wall=28, gb_free=12.3, wall=6149
2023-04-19 02:09:29 - progress_bar.py[line:272] - INFO: epoch 004:    419 / 578 loss=2.432, loss_v1=0, loss_v2=0, nll_loss=1.241, ntokens=3011.5, nsentences=96, sample_size=3011.5, sample_size_v1=0, sample_size_v2=0, ppl=2.36, wps=1057, ups=0.35, wpb=3011.5, bsz=96, num_updates=2150, lr=2.20215e-05, gnorm=1.048, clip=50, loss_scale=256, train_wall=28, gb_free=12.6, wall=6177
2023-04-19 02:09:57 - progress_bar.py[line:272] - INFO: epoch 004:    429 / 578 loss=2.414, loss_v1=0, loss_v2=0, nll_loss=1.218, ntokens=3123.2, nsentences=96, sample_size=3123.2, sample_size_v1=0, sample_size_v2=0, ppl=2.33, wps=1099.6, ups=0.35, wpb=3123.2, bsz=96, num_updates=2160, lr=2.19755e-05, gnorm=1.029, clip=60, loss_scale=256, train_wall=28, gb_free=12.4, wall=6206
2023-04-19 02:10:26 - progress_bar.py[line:272] - INFO: epoch 004:    439 / 578 loss=2.46, loss_v1=0, loss_v2=0, nll_loss=1.27, ntokens=2916.3, nsentences=96, sample_size=2916.3, sample_size_v1=0, sample_size_v2=0, ppl=2.41, wps=1028.2, ups=0.35, wpb=2916.3, bsz=96, num_updates=2170, lr=2.19294e-05, gnorm=1.057, clip=90, loss_scale=256, train_wall=28, gb_free=12.3, wall=6234
2023-04-19 02:10:54 - progress_bar.py[line:272] - INFO: epoch 004:    449 / 578 loss=2.44, loss_v1=0, loss_v2=0, nll_loss=1.248, ntokens=3038.1, nsentences=96, sample_size=3038.1, sample_size_v1=0, sample_size_v2=0, ppl=2.37, wps=1062.9, ups=0.35, wpb=3038.1, bsz=96, num_updates=2180, lr=2.18834e-05, gnorm=1.031, clip=60, loss_scale=256, train_wall=29, gb_free=12.4, wall=6263
2023-04-19 02:11:23 - progress_bar.py[line:272] - INFO: epoch 004:    459 / 578 loss=2.418, loss_v1=0, loss_v2=0, nll_loss=1.226, ntokens=3022.7, nsentences=96, sample_size=3022.7, sample_size_v1=0, sample_size_v2=0, ppl=2.34, wps=1063.6, ups=0.35, wpb=3022.7, bsz=96, num_updates=2190, lr=2.18374e-05, gnorm=1.022, clip=60, loss_scale=256, train_wall=28, gb_free=12.2, wall=6291
2023-04-19 02:11:51 - progress_bar.py[line:272] - INFO: epoch 004:    469 / 578 loss=2.438, loss_v1=0, loss_v2=0, nll_loss=1.243, ntokens=3094.1, nsentences=96, sample_size=3094.1, sample_size_v1=0, sample_size_v2=0, ppl=2.37, wps=1083.8, ups=0.35, wpb=3094.1, bsz=96, num_updates=2200, lr=2.17914e-05, gnorm=1.021, clip=70, loss_scale=256, train_wall=29, gb_free=12.4, wall=6320
2023-04-19 02:12:19 - progress_bar.py[line:272] - INFO: epoch 004:    479 / 578 loss=2.441, loss_v1=0, loss_v2=0, nll_loss=1.253, ntokens=2889.2, nsentences=96, sample_size=2889.2, sample_size_v1=0, sample_size_v2=0, ppl=2.38, wps=1018.2, ups=0.35, wpb=2889.2, bsz=96, num_updates=2210, lr=2.17454e-05, gnorm=1.043, clip=70, loss_scale=256, train_wall=28, gb_free=12.7, wall=6348
2023-04-19 02:12:48 - progress_bar.py[line:272] - INFO: epoch 004:    489 / 578 loss=2.414, loss_v1=0, loss_v2=0, nll_loss=1.22, ntokens=3014.8, nsentences=96, sample_size=3014.8, sample_size_v1=0, sample_size_v2=0, ppl=2.33, wps=1060.7, ups=0.35, wpb=3014.8, bsz=96, num_updates=2220, lr=2.16994e-05, gnorm=0.988, clip=40, loss_scale=256, train_wall=28, gb_free=12, wall=6377
2023-04-19 02:13:17 - progress_bar.py[line:272] - INFO: epoch 004:    499 / 578 loss=2.4, loss_v1=0, loss_v2=0, nll_loss=1.202, ntokens=3225.3, nsentences=96, sample_size=3225.3, sample_size_v1=0, sample_size_v2=0, ppl=2.3, wps=1127, ups=0.35, wpb=3225.3, bsz=96, num_updates=2230, lr=2.16534e-05, gnorm=1.006, clip=60, loss_scale=256, train_wall=29, gb_free=12.5, wall=6405
2023-04-19 02:13:45 - progress_bar.py[line:272] - INFO: epoch 004:    509 / 578 loss=2.414, loss_v1=0, loss_v2=0, nll_loss=1.22, ntokens=3147, nsentences=96, sample_size=3147, sample_size_v1=0, sample_size_v2=0, ppl=2.33, wps=1102.5, ups=0.35, wpb=3147, bsz=96, num_updates=2240, lr=2.16074e-05, gnorm=1.055, clip=80, loss_scale=256, train_wall=29, gb_free=12.5, wall=6434
2023-04-19 02:14:14 - progress_bar.py[line:272] - INFO: epoch 004:    519 / 578 loss=2.401, loss_v1=0, loss_v2=0, nll_loss=1.204, ntokens=3278.5, nsentences=96, sample_size=3278.5, sample_size_v1=0, sample_size_v2=0, ppl=2.3, wps=1149, ups=0.35, wpb=3278.5, bsz=96, num_updates=2250, lr=2.15613e-05, gnorm=0.988, clip=40, loss_scale=256, train_wall=29, gb_free=12.7, wall=6462
2023-04-19 02:14:42 - progress_bar.py[line:272] - INFO: epoch 004:    529 / 578 loss=2.428, loss_v1=0, loss_v2=0, nll_loss=1.234, ntokens=3053.2, nsentences=96, sample_size=3053.2, sample_size_v1=0, sample_size_v2=0, ppl=2.35, wps=1080.3, ups=0.35, wpb=3053.2, bsz=96, num_updates=2260, lr=2.15153e-05, gnorm=1.084, clip=90, loss_scale=256, train_wall=28, gb_free=12.3, wall=6490
2023-04-19 02:15:10 - progress_bar.py[line:272] - INFO: epoch 004:    539 / 578 loss=2.413, loss_v1=0, loss_v2=0, nll_loss=1.217, ntokens=3001.3, nsentences=96, sample_size=3001.3, sample_size_v1=0, sample_size_v2=0, ppl=2.33, wps=1058.7, ups=0.35, wpb=3001.3, bsz=96, num_updates=2270, lr=2.14693e-05, gnorm=1.083, clip=100, loss_scale=256, train_wall=28, gb_free=12.3, wall=6519
2023-04-19 02:15:39 - progress_bar.py[line:272] - INFO: epoch 004:    549 / 578 loss=2.408, loss_v1=0, loss_v2=0, nll_loss=1.213, ntokens=3181.5, nsentences=96, sample_size=3181.5, sample_size_v1=0, sample_size_v2=0, ppl=2.32, wps=1107.9, ups=0.35, wpb=3181.5, bsz=96, num_updates=2280, lr=2.14233e-05, gnorm=1.053, clip=60, loss_scale=256, train_wall=29, gb_free=12, wall=6548
2023-04-19 02:16:08 - progress_bar.py[line:272] - INFO: epoch 004:    559 / 578 loss=2.405, loss_v1=0, loss_v2=0, nll_loss=1.209, ntokens=3211.2, nsentences=96, sample_size=3211.2, sample_size_v1=0, sample_size_v2=0, ppl=2.31, wps=1114.4, ups=0.35, wpb=3211.2, bsz=96, num_updates=2290, lr=2.13773e-05, gnorm=1.023, clip=60, loss_scale=256, train_wall=29, gb_free=12.5, wall=6576
2023-04-19 02:16:36 - progress_bar.py[line:272] - INFO: epoch 004:    569 / 578 loss=2.402, loss_v1=0, loss_v2=0, nll_loss=1.206, ntokens=3290.7, nsentences=96, sample_size=3290.7, sample_size_v1=0, sample_size_v2=0, ppl=2.31, wps=1146.3, ups=0.35, wpb=3290.7, bsz=96, num_updates=2300, lr=2.13313e-05, gnorm=0.937, clip=0, loss_scale=256, train_wall=29, gb_free=12.1, wall=6605
2023-04-19 02:17:00 - checkpoint_utils.py[line:64] - INFO: Preparing to save checkpoint for epoch 4 @ 2309 updates
2023-04-19 02:17:00 - trainer.py[line:431] - INFO: Saving checkpoint to ../../checkpoints/OFA/sgcls_checkpoints/_12_3e-5_512/checkpoint4.pt
local datafile ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 1 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 1 finished initializing row_count and line_idx-to-offset mapping
file ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 1 row count 27700 total row count 55400
slice_id 1 seek offset 27700
2023-04-19 02:17:06 - trainer.py[line:441] - INFO: Finished saving checkpoint to ../../checkpoints/OFA/sgcls_checkpoints/_12_3e-5_512/checkpoint4.pt
2023-04-19 02:17:11 - checkpoint_utils.py[line:133] - INFO: Saved checkpoint ../../checkpoints/OFA/sgcls_checkpoints/_12_3e-5_512/checkpoint4.pt (epoch 4 @ 2309 updates, score None) (writing took 11.0866112485528 seconds)
2023-04-19 02:17:11 - train.py[line:332] - INFO: end of epoch 4 (average epoch stats below)
2023-04-19 02:17:11 - progress_bar.py[line:282] - INFO: epoch 004 | loss 2.418 | loss_v1 0 | loss_v2 0 | nll_loss 1.224 | ntokens 3151.04 | nsentences 95.847 | sample_size 3151.04 | sample_size_v1 0 | sample_size_v2 0 | ppl 2.34 | wps 1094.4 | ups 0.35 | wpb 3151 | bsz 95.8 | num_updates 2309 | lr 2.12899e-05 | gnorm 0.988 | clip 41.9 | loss_scale 256 | train_wall 1646 | gb_free 13.1 | wall 6639
2023-04-19 02:17:11 - trainer.py[line:639] - INFO: loading train data for epoch 5
local datafile ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 0 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 0 finished initializing row_count and line_idx-to-offset mapping
file ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 0 row count 27700 total row count 55400
slice_id 0 seek offset 0
2023-04-19 02:17:13 - trainer.py[line:703] - INFO: begin training epoch 5
2023-04-19 02:17:13 - train.py[line:305] - INFO: Start iterating over samples
2023-04-19 02:17:16 - progress_bar.py[line:272] - INFO: epoch 005:      1 / 578 loss=2.442, loss_v1=0, loss_v2=0, nll_loss=1.249, ntokens=2818.3, nsentences=87.2, sample_size=2818.3, sample_size_v1=0, sample_size_v2=0, ppl=2.38, wps=713.5, ups=0.25, wpb=2818.3, bsz=87.2, num_updates=2310, lr=2.12853e-05, gnorm=1.194, clip=70, loss_scale=256, train_wall=26, gb_free=12.3, wall=6645
2023-04-19 02:17:45 - progress_bar.py[line:272] - INFO: epoch 005:     11 / 578 loss=2.348, loss_v1=0, loss_v2=0, nll_loss=1.145, ntokens=3146.9, nsentences=96, sample_size=3146.9, sample_size_v1=0, sample_size_v2=0, ppl=2.21, wps=1101.8, ups=0.35, wpb=3146.9, bsz=96, num_updates=2320, lr=2.12393e-05, gnorm=1.043, clip=60, loss_scale=256, train_wall=29, gb_free=12.1, wall=6673
2023-04-19 02:18:13 - progress_bar.py[line:272] - INFO: epoch 005:     21 / 578 loss=2.352, loss_v1=0, loss_v2=0, nll_loss=1.149, ntokens=3044.2, nsentences=96, sample_size=3044.2, sample_size_v1=0, sample_size_v2=0, ppl=2.22, wps=1073.3, ups=0.35, wpb=3044.2, bsz=96, num_updates=2330, lr=2.11933e-05, gnorm=1.127, clip=100, loss_scale=256, train_wall=28, gb_free=11.9, wall=6702
2023-04-19 02:18:41 - progress_bar.py[line:272] - INFO: epoch 005:     31 / 578 loss=2.32, loss_v1=0, loss_v2=0, nll_loss=1.115, ntokens=3136.1, nsentences=96, sample_size=3136.1, sample_size_v1=0, sample_size_v2=0, ppl=2.17, wps=1098.3, ups=0.35, wpb=3136.1, bsz=96, num_updates=2340, lr=2.11472e-05, gnorm=1.063, clip=60, loss_scale=256, train_wall=29, gb_free=12.3, wall=6730
2023-04-19 02:19:10 - progress_bar.py[line:272] - INFO: epoch 005:     41 / 578 loss=2.26, loss_v1=0, loss_v2=0, nll_loss=1.047, ntokens=3235.3, nsentences=96, sample_size=3235.3, sample_size_v1=0, sample_size_v2=0, ppl=2.07, wps=1126.5, ups=0.35, wpb=3235.3, bsz=96, num_updates=2350, lr=2.11012e-05, gnorm=1.112, clip=80, loss_scale=256, train_wall=29, gb_free=11.4, wall=6759
2023-04-19 02:19:40 - progress_bar.py[line:272] - INFO: epoch 005:     51 / 578 loss=2.262, loss_v1=0, loss_v2=0, nll_loss=1.047, ntokens=3587, nsentences=96, sample_size=3587, sample_size_v1=0, sample_size_v2=0, ppl=2.07, wps=1223.3, ups=0.34, wpb=3587, bsz=96, num_updates=2360, lr=2.10552e-05, gnorm=0.964, clip=30, loss_scale=256, train_wall=29, gb_free=11.4, wall=6788
2023-04-19 02:20:08 - progress_bar.py[line:272] - INFO: epoch 005:     61 / 578 loss=2.34, loss_v1=0, loss_v2=0, nll_loss=1.138, ntokens=3229.4, nsentences=96, sample_size=3229.4, sample_size_v1=0, sample_size_v2=0, ppl=2.2, wps=1122, ups=0.35, wpb=3229.4, bsz=96, num_updates=2370, lr=2.10092e-05, gnorm=1.062, clip=80, loss_scale=256, train_wall=29, gb_free=12.3, wall=6817
2023-04-19 02:20:37 - progress_bar.py[line:272] - INFO: epoch 005:     71 / 578 loss=2.372, loss_v1=0, loss_v2=0, nll_loss=1.173, ntokens=3064.1, nsentences=96, sample_size=3064.1, sample_size_v1=0, sample_size_v2=0, ppl=2.25, wps=1075.2, ups=0.35, wpb=3064.1, bsz=96, num_updates=2380, lr=2.09632e-05, gnorm=1.113, clip=90, loss_scale=256, train_wall=28, gb_free=11.6, wall=6845
2023-04-19 02:21:05 - progress_bar.py[line:272] - INFO: epoch 005:     81 / 578 loss=2.405, loss_v1=0, loss_v2=0, nll_loss=1.207, ntokens=3199.2, nsentences=96, sample_size=3199.2, sample_size_v1=0, sample_size_v2=0, ppl=2.31, wps=1115.2, ups=0.35, wpb=3199.2, bsz=96, num_updates=2390, lr=2.09172e-05, gnorm=1.044, clip=60, loss_scale=256, train_wall=29, gb_free=12, wall=6874
2023-04-19 02:21:34 - progress_bar.py[line:272] - INFO: epoch 005:     91 / 578 loss=2.369, loss_v1=0, loss_v2=0, nll_loss=1.169, ntokens=3356.4, nsentences=96, sample_size=3356.4, sample_size_v1=0, sample_size_v2=0, ppl=2.25, wps=1164.2, ups=0.35, wpb=3356.4, bsz=96, num_updates=2400, lr=2.08712e-05, gnorm=0.985, clip=40, loss_scale=256, train_wall=29, gb_free=11.6, wall=6903
2023-04-19 02:22:03 - progress_bar.py[line:272] - INFO: epoch 005:    101 / 578 loss=2.348, loss_v1=0, loss_v2=0, nll_loss=1.147, ntokens=3318.9, nsentences=96, sample_size=3318.9, sample_size_v1=0, sample_size_v2=0, ppl=2.22, wps=1139.7, ups=0.34, wpb=3318.9, bsz=96, num_updates=2410, lr=2.08252e-05, gnorm=0.977, clip=40, loss_scale=256, train_wall=29, gb_free=11.2, wall=6932
2023-04-19 02:22:32 - progress_bar.py[line:272] - INFO: epoch 005:    111 / 578 loss=2.365, loss_v1=0, loss_v2=0, nll_loss=1.163, ntokens=3258.2, nsentences=96, sample_size=3258.2, sample_size_v1=0, sample_size_v2=0, ppl=2.24, wps=1130.5, ups=0.35, wpb=3258.2, bsz=96, num_updates=2420, lr=2.07791e-05, gnorm=1.03, clip=50, loss_scale=256, train_wall=29, gb_free=11.6, wall=6961
2023-04-19 02:23:01 - progress_bar.py[line:272] - INFO: epoch 005:    121 / 578 loss=2.35, loss_v1=0, loss_v2=0, nll_loss=1.148, ntokens=3153.5, nsentences=96, sample_size=3153.5, sample_size_v1=0, sample_size_v2=0, ppl=2.22, wps=1097.9, ups=0.35, wpb=3153.5, bsz=96, num_updates=2430, lr=2.07331e-05, gnorm=1.029, clip=70, loss_scale=256, train_wall=29, gb_free=12, wall=6990
2023-04-19 02:23:30 - progress_bar.py[line:272] - INFO: epoch 005:    131 / 578 loss=2.359, loss_v1=0, loss_v2=0, nll_loss=1.157, ntokens=3290.7, nsentences=96, sample_size=3290.7, sample_size_v1=0, sample_size_v2=0, ppl=2.23, wps=1142.5, ups=0.35, wpb=3290.7, bsz=96, num_updates=2440, lr=2.06871e-05, gnorm=1.031, clip=70, loss_scale=256, train_wall=29, gb_free=12, wall=7018
2023-04-19 02:23:58 - progress_bar.py[line:272] - INFO: epoch 005:    141 / 578 loss=2.418, loss_v1=0, loss_v2=0, nll_loss=1.223, ntokens=3021.3, nsentences=96, sample_size=3021.3, sample_size_v1=0, sample_size_v2=0, ppl=2.33, wps=1060.1, ups=0.35, wpb=3021.3, bsz=96, num_updates=2450, lr=2.06411e-05, gnorm=1.073, clip=80, loss_scale=256, train_wall=28, gb_free=12, wall=7047
2023-04-19 02:24:27 - progress_bar.py[line:272] - INFO: epoch 005:    151 / 578 loss=2.417, loss_v1=0, loss_v2=0, nll_loss=1.222, ntokens=3292.4, nsentences=96, sample_size=3292.4, sample_size_v1=0, sample_size_v2=0, ppl=2.33, wps=1153, ups=0.35, wpb=3292.4, bsz=96, num_updates=2460, lr=2.05951e-05, gnorm=1.058, clip=60, loss_scale=256, train_wall=29, gb_free=12.3, wall=7075
2023-04-19 02:24:55 - progress_bar.py[line:272] - INFO: epoch 005:    161 / 578 loss=2.435, loss_v1=0, loss_v2=0, nll_loss=1.243, ntokens=3248, nsentences=96, sample_size=3248, sample_size_v1=0, sample_size_v2=0, ppl=2.37, wps=1144.1, ups=0.35, wpb=3248, bsz=96, num_updates=2470, lr=2.05491e-05, gnorm=1.068, clip=60, loss_scale=256, train_wall=28, gb_free=11.9, wall=7104
2023-04-19 02:25:24 - progress_bar.py[line:272] - INFO: epoch 005:    171 / 578 loss=2.432, loss_v1=0, loss_v2=0, nll_loss=1.239, ntokens=3175.8, nsentences=96, sample_size=3175.8, sample_size_v1=0, sample_size_v2=0, ppl=2.36, wps=1118.4, ups=0.35, wpb=3175.8, bsz=96, num_updates=2480, lr=2.05031e-05, gnorm=1.116, clip=100, loss_scale=256, train_wall=28, gb_free=12.3, wall=7132
2023-04-19 02:25:52 - progress_bar.py[line:272] - INFO: epoch 005:    181 / 578 loss=2.426, loss_v1=0, loss_v2=0, nll_loss=1.233, ntokens=3231.9, nsentences=96, sample_size=3231.9, sample_size_v1=0, sample_size_v2=0, ppl=2.35, wps=1134.8, ups=0.35, wpb=3231.9, bsz=96, num_updates=2490, lr=2.04571e-05, gnorm=1.019, clip=60, loss_scale=256, train_wall=28, gb_free=12.1, wall=7161
2023-04-19 02:26:21 - progress_bar.py[line:272] - INFO: epoch 005:    191 / 578 loss=2.425, loss_v1=0, loss_v2=0, nll_loss=1.232, ntokens=3253.3, nsentences=96, sample_size=3253.3, sample_size_v1=0, sample_size_v2=0, ppl=2.35, wps=1142.9, ups=0.35, wpb=3253.3, bsz=96, num_updates=2500, lr=2.0411e-05, gnorm=1.049, clip=70, loss_scale=256, train_wall=28, gb_free=11.5, wall=7189
2023-04-19 02:26:49 - progress_bar.py[line:272] - INFO: epoch 005:    201 / 578 loss=2.415, loss_v1=0, loss_v2=0, nll_loss=1.222, ntokens=3182.1, nsentences=96, sample_size=3182.1, sample_size_v1=0, sample_size_v2=0, ppl=2.33, wps=1120.9, ups=0.35, wpb=3182.1, bsz=96, num_updates=2510, lr=2.0365e-05, gnorm=1.082, clip=80, loss_scale=256, train_wall=28, gb_free=12.3, wall=7218
2023-04-19 02:27:17 - progress_bar.py[line:272] - INFO: epoch 005:    211 / 578 loss=2.408, loss_v1=0, loss_v2=0, nll_loss=1.212, ntokens=3118.6, nsentences=96, sample_size=3118.6, sample_size_v1=0, sample_size_v2=0, ppl=2.32, wps=1099.2, ups=0.35, wpb=3118.6, bsz=96, num_updates=2520, lr=2.0319e-05, gnorm=1.071, clip=80, loss_scale=256, train_wall=28, gb_free=11.9, wall=7246
2023-04-19 02:27:46 - progress_bar.py[line:272] - INFO: epoch 005:    221 / 578 loss=2.435, loss_v1=0, loss_v2=0, nll_loss=1.243, ntokens=3110.8, nsentences=96, sample_size=3110.8, sample_size_v1=0, sample_size_v2=0, ppl=2.37, wps=1096.4, ups=0.35, wpb=3110.8, bsz=96, num_updates=2530, lr=2.0273e-05, gnorm=1.137, clip=80, loss_scale=256, train_wall=28, gb_free=11.9, wall=7274
2023-04-19 02:28:14 - progress_bar.py[line:272] - INFO: epoch 005:    231 / 578 loss=2.399, loss_v1=0, loss_v2=0, nll_loss=1.203, ntokens=2994.4, nsentences=96, sample_size=2994.4, sample_size_v1=0, sample_size_v2=0, ppl=2.3, wps=1050.4, ups=0.35, wpb=2994.4, bsz=96, num_updates=2540, lr=2.0227e-05, gnorm=1.083, clip=100, loss_scale=256, train_wall=28, gb_free=12.3, wall=7303
2023-04-19 02:28:43 - progress_bar.py[line:272] - INFO: epoch 005:    241 / 578 loss=2.438, loss_v1=0, loss_v2=0, nll_loss=1.245, ntokens=2963.7, nsentences=96, sample_size=2963.7, sample_size_v1=0, sample_size_v2=0, ppl=2.37, wps=1047.8, ups=0.35, wpb=2963.7, bsz=96, num_updates=2550, lr=2.0181e-05, gnorm=1.129, clip=100, loss_scale=256, train_wall=28, gb_free=12.3, wall=7331
2023-04-19 02:29:11 - progress_bar.py[line:272] - INFO: epoch 005:    251 / 578 loss=2.409, loss_v1=0, loss_v2=0, nll_loss=1.215, ntokens=3107.1, nsentences=96, sample_size=3107.1, sample_size_v1=0, sample_size_v2=0, ppl=2.32, wps=1094.7, ups=0.35, wpb=3107.1, bsz=96, num_updates=2560, lr=2.0135e-05, gnorm=1.124, clip=90, loss_scale=256, train_wall=28, gb_free=12.3, wall=7360
2023-04-19 02:29:39 - progress_bar.py[line:272] - INFO: epoch 005:    261 / 578 loss=2.405, loss_v1=0, loss_v2=0, nll_loss=1.208, ntokens=3139, nsentences=96, sample_size=3139, sample_size_v1=0, sample_size_v2=0, ppl=2.31, wps=1105.3, ups=0.35, wpb=3139, bsz=96, num_updates=2570, lr=2.0089e-05, gnorm=1.103, clip=90, loss_scale=256, train_wall=28, gb_free=12.5, wall=7388
2023-04-19 02:30:08 - progress_bar.py[line:272] - INFO: epoch 005:    271 / 578 loss=2.419, loss_v1=0, loss_v2=0, nll_loss=1.226, ntokens=3108.5, nsentences=96, sample_size=3108.5, sample_size_v1=0, sample_size_v2=0, ppl=2.34, wps=1094.7, ups=0.35, wpb=3108.5, bsz=96, num_updates=2580, lr=2.00429e-05, gnorm=1.124, clip=100, loss_scale=256, train_wall=28, gb_free=12.2, wall=7416
2023-04-19 02:30:25 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 256.0
2023-04-19 02:30:39 - progress_bar.py[line:272] - INFO: epoch 005:    282 / 578 loss=2.401, loss_v1=0, loss_v2=0, nll_loss=1.205, ntokens=3185, nsentences=96, sample_size=3185, sample_size_v1=0, sample_size_v2=0, ppl=2.3, wps=1015, ups=0.32, wpb=3185, bsz=96, num_updates=2590, lr=1.99969e-05, gnorm=1.073, clip=80, loss_scale=256, train_wall=31, gb_free=12.2, wall=7448
2023-04-19 02:31:08 - progress_bar.py[line:272] - INFO: epoch 005:    292 / 578 loss=2.415, loss_v1=0, loss_v2=0, nll_loss=1.222, ntokens=3181.9, nsentences=96, sample_size=3181.9, sample_size_v1=0, sample_size_v2=0, ppl=2.33, wps=1120.2, ups=0.35, wpb=3181.9, bsz=96, num_updates=2600, lr=1.99509e-05, gnorm=1.05, clip=80, loss_scale=256, train_wall=28, gb_free=12.4, wall=7476
2023-04-19 02:31:36 - progress_bar.py[line:272] - INFO: epoch 005:    302 / 578 loss=2.423, loss_v1=0, loss_v2=0, nll_loss=1.229, ntokens=2987.2, nsentences=96, sample_size=2987.2, sample_size_v1=0, sample_size_v2=0, ppl=2.34, wps=1045.2, ups=0.35, wpb=2987.2, bsz=96, num_updates=2610, lr=1.99049e-05, gnorm=1.14, clip=90, loss_scale=256, train_wall=29, gb_free=12.5, wall=7505
2023-04-19 02:32:05 - progress_bar.py[line:272] - INFO: epoch 005:    312 / 578 loss=2.413, loss_v1=0, loss_v2=0, nll_loss=1.218, ntokens=3259.9, nsentences=96, sample_size=3259.9, sample_size_v1=0, sample_size_v2=0, ppl=2.33, wps=1141.3, ups=0.35, wpb=3259.9, bsz=96, num_updates=2620, lr=1.98589e-05, gnorm=1.026, clip=70, loss_scale=256, train_wall=29, gb_free=12.1, wall=7533
2023-04-19 02:32:33 - progress_bar.py[line:272] - INFO: epoch 005:    322 / 578 loss=2.411, loss_v1=0, loss_v2=0, nll_loss=1.215, ntokens=3250.5, nsentences=96, sample_size=3250.5, sample_size_v1=0, sample_size_v2=0, ppl=2.32, wps=1138.5, ups=0.35, wpb=3250.5, bsz=96, num_updates=2630, lr=1.98129e-05, gnorm=1.076, clip=70, loss_scale=256, train_wall=29, gb_free=12.5, wall=7562
2023-04-19 02:33:02 - progress_bar.py[line:272] - INFO: epoch 005:    332 / 578 loss=2.396, loss_v1=0, loss_v2=0, nll_loss=1.202, ntokens=3072.7, nsentences=96, sample_size=3072.7, sample_size_v1=0, sample_size_v2=0, ppl=2.3, wps=1078.6, ups=0.35, wpb=3072.7, bsz=96, num_updates=2640, lr=1.97669e-05, gnorm=1.081, clip=80, loss_scale=256, train_wall=28, gb_free=12.8, wall=7590
2023-04-19 02:33:30 - progress_bar.py[line:272] - INFO: epoch 005:    342 / 578 loss=2.429, loss_v1=0, loss_v2=0, nll_loss=1.234, ntokens=3208.2, nsentences=96, sample_size=3208.2, sample_size_v1=0, sample_size_v2=0, ppl=2.35, wps=1130.4, ups=0.35, wpb=3208.2, bsz=96, num_updates=2650, lr=1.97209e-05, gnorm=1.078, clip=80, loss_scale=256, train_wall=28, gb_free=11.8, wall=7619
2023-04-19 02:33:58 - progress_bar.py[line:272] - INFO: epoch 005:    352 / 578 loss=2.408, loss_v1=0, loss_v2=0, nll_loss=1.215, ntokens=3071.9, nsentences=96, sample_size=3071.9, sample_size_v1=0, sample_size_v2=0, ppl=2.32, wps=1084.5, ups=0.35, wpb=3071.9, bsz=96, num_updates=2660, lr=1.96748e-05, gnorm=1.072, clip=90, loss_scale=256, train_wall=28, gb_free=12.6, wall=7647
2023-04-19 02:34:27 - progress_bar.py[line:272] - INFO: epoch 005:    362 / 578 loss=2.407, loss_v1=0, loss_v2=0, nll_loss=1.212, ntokens=3245.4, nsentences=96, sample_size=3245.4, sample_size_v1=0, sample_size_v2=0, ppl=2.32, wps=1139.6, ups=0.35, wpb=3245.4, bsz=96, num_updates=2670, lr=1.96288e-05, gnorm=1.084, clip=80, loss_scale=256, train_wall=28, gb_free=12.1, wall=7676
2023-04-19 02:34:56 - progress_bar.py[line:272] - INFO: epoch 005:    372 / 578 loss=2.418, loss_v1=0, loss_v2=0, nll_loss=1.224, ntokens=3472.2, nsentences=96, sample_size=3472.2, sample_size_v1=0, sample_size_v2=0, ppl=2.34, wps=1206.1, ups=0.35, wpb=3472.2, bsz=96, num_updates=2680, lr=1.95828e-05, gnorm=1.013, clip=50, loss_scale=256, train_wall=29, gb_free=11.9, wall=7704
2023-04-19 02:35:24 - progress_bar.py[line:272] - INFO: epoch 005:    382 / 578 loss=2.414, loss_v1=0, loss_v2=0, nll_loss=1.219, ntokens=3300.3, nsentences=96, sample_size=3300.3, sample_size_v1=0, sample_size_v2=0, ppl=2.33, wps=1156.3, ups=0.35, wpb=3300.3, bsz=96, num_updates=2690, lr=1.95368e-05, gnorm=1.074, clip=80, loss_scale=256, train_wall=29, gb_free=12, wall=7733
2023-04-19 02:35:53 - progress_bar.py[line:272] - INFO: epoch 005:    392 / 578 loss=2.414, loss_v1=0, loss_v2=0, nll_loss=1.219, ntokens=3120.5, nsentences=96, sample_size=3120.5, sample_size_v1=0, sample_size_v2=0, ppl=2.33, wps=1096.1, ups=0.35, wpb=3120.5, bsz=96, num_updates=2700, lr=1.94908e-05, gnorm=1.135, clip=100, loss_scale=256, train_wall=28, gb_free=12.3, wall=7761
2023-04-19 02:36:21 - progress_bar.py[line:272] - INFO: epoch 005:    402 / 578 loss=2.38, loss_v1=0, loss_v2=0, nll_loss=1.182, ntokens=3184.1, nsentences=96, sample_size=3184.1, sample_size_v1=0, sample_size_v2=0, ppl=2.27, wps=1111.8, ups=0.35, wpb=3184.1, bsz=96, num_updates=2710, lr=1.94448e-05, gnorm=1.115, clip=90, loss_scale=256, train_wall=29, gb_free=12.4, wall=7790
2023-04-19 02:36:50 - progress_bar.py[line:272] - INFO: epoch 005:    412 / 578 loss=2.424, loss_v1=0, loss_v2=0, nll_loss=1.227, ntokens=2904.3, nsentences=96, sample_size=2904.3, sample_size_v1=0, sample_size_v2=0, ppl=2.34, wps=1023.2, ups=0.35, wpb=2904.3, bsz=96, num_updates=2720, lr=1.93988e-05, gnorm=1.227, clip=90, loss_scale=256, train_wall=28, gb_free=12.4, wall=7818
2023-04-19 02:37:18 - progress_bar.py[line:272] - INFO: epoch 005:    422 / 578 loss=2.401, loss_v1=0, loss_v2=0, nll_loss=1.207, ntokens=3057.8, nsentences=96, sample_size=3057.8, sample_size_v1=0, sample_size_v2=0, ppl=2.31, wps=1071.1, ups=0.35, wpb=3057.8, bsz=96, num_updates=2730, lr=1.93528e-05, gnorm=1.204, clip=100, loss_scale=256, train_wall=29, gb_free=12.4, wall=7847
2023-04-19 02:37:47 - progress_bar.py[line:272] - INFO: epoch 005:    432 / 578 loss=2.402, loss_v1=0, loss_v2=0, nll_loss=1.204, ntokens=3092.9, nsentences=96, sample_size=3092.9, sample_size_v1=0, sample_size_v2=0, ppl=2.3, wps=1089.1, ups=0.35, wpb=3092.9, bsz=96, num_updates=2740, lr=1.93067e-05, gnorm=1.131, clip=90, loss_scale=256, train_wall=28, gb_free=12.4, wall=7875
2023-04-19 02:38:15 - progress_bar.py[line:272] - INFO: epoch 005:    442 / 578 loss=2.427, loss_v1=0, loss_v2=0, nll_loss=1.233, ntokens=2916.1, nsentences=96, sample_size=2916.1, sample_size_v1=0, sample_size_v2=0, ppl=2.35, wps=1026.4, ups=0.35, wpb=2916.1, bsz=96, num_updates=2750, lr=1.92607e-05, gnorm=1.204, clip=100, loss_scale=256, train_wall=28, gb_free=12.1, wall=7904
2023-04-19 02:38:44 - progress_bar.py[line:272] - INFO: epoch 005:    452 / 578 loss=2.41, loss_v1=0, loss_v2=0, nll_loss=1.214, ntokens=3077.2, nsentences=96, sample_size=3077.2, sample_size_v1=0, sample_size_v2=0, ppl=2.32, wps=1077.1, ups=0.35, wpb=3077.2, bsz=96, num_updates=2760, lr=1.92147e-05, gnorm=1.132, clip=100, loss_scale=256, train_wall=29, gb_free=12.5, wall=7932
2023-04-19 02:39:12 - progress_bar.py[line:272] - INFO: epoch 005:    462 / 578 loss=2.401, loss_v1=0, loss_v2=0, nll_loss=1.207, ntokens=3043.6, nsentences=96, sample_size=3043.6, sample_size_v1=0, sample_size_v2=0, ppl=2.31, wps=1071, ups=0.35, wpb=3043.6, bsz=96, num_updates=2770, lr=1.91687e-05, gnorm=1.134, clip=90, loss_scale=256, train_wall=28, gb_free=12.1, wall=7961
2023-04-19 02:39:41 - progress_bar.py[line:272] - INFO: epoch 005:    472 / 578 loss=2.422, loss_v1=0, loss_v2=0, nll_loss=1.225, ntokens=3027.5, nsentences=96, sample_size=3027.5, sample_size_v1=0, sample_size_v2=0, ppl=2.34, wps=1064.1, ups=0.35, wpb=3027.5, bsz=96, num_updates=2780, lr=1.91227e-05, gnorm=1.159, clip=100, loss_scale=256, train_wall=28, gb_free=12.5, wall=7989
2023-04-19 02:40:09 - progress_bar.py[line:272] - INFO: epoch 005:    482 / 578 loss=2.407, loss_v1=0, loss_v2=0, nll_loss=1.215, ntokens=2876.5, nsentences=96, sample_size=2876.5, sample_size_v1=0, sample_size_v2=0, ppl=2.32, wps=1014.6, ups=0.35, wpb=2876.5, bsz=96, num_updates=2790, lr=1.90767e-05, gnorm=1.188, clip=100, loss_scale=256, train_wall=28, gb_free=12.4, wall=8018
2023-04-19 02:40:37 - progress_bar.py[line:272] - INFO: epoch 005:    492 / 578 loss=2.384, loss_v1=0, loss_v2=0, nll_loss=1.185, ntokens=3095.4, nsentences=96, sample_size=3095.4, sample_size_v1=0, sample_size_v2=0, ppl=2.27, wps=1091.9, ups=0.35, wpb=3095.4, bsz=96, num_updates=2800, lr=1.90307e-05, gnorm=1.096, clip=100, loss_scale=256, train_wall=28, gb_free=12.4, wall=8046
2023-04-19 02:41:06 - progress_bar.py[line:272] - INFO: epoch 005:    502 / 578 loss=2.379, loss_v1=0, loss_v2=0, nll_loss=1.18, ntokens=3168.8, nsentences=96, sample_size=3168.8, sample_size_v1=0, sample_size_v2=0, ppl=2.27, wps=1110.5, ups=0.35, wpb=3168.8, bsz=96, num_updates=2810, lr=1.89847e-05, gnorm=1.175, clip=100, loss_scale=256, train_wall=29, gb_free=12.4, wall=8074
2023-04-19 02:41:34 - progress_bar.py[line:272] - INFO: epoch 005:    512 / 578 loss=2.388, loss_v1=0, loss_v2=0, nll_loss=1.19, ntokens=3153.4, nsentences=96, sample_size=3153.4, sample_size_v1=0, sample_size_v2=0, ppl=2.28, wps=1104.6, ups=0.35, wpb=3153.4, bsz=96, num_updates=2820, lr=1.89387e-05, gnorm=1.17, clip=100, loss_scale=256, train_wall=29, gb_free=12.2, wall=8103
2023-04-19 02:42:03 - progress_bar.py[line:272] - INFO: epoch 005:    522 / 578 loss=2.382, loss_v1=0, loss_v2=0, nll_loss=1.185, ntokens=3309, nsentences=96, sample_size=3309, sample_size_v1=0, sample_size_v2=0, ppl=2.27, wps=1158.9, ups=0.35, wpb=3309, bsz=96, num_updates=2830, lr=1.88926e-05, gnorm=1.143, clip=100, loss_scale=256, train_wall=29, gb_free=12.2, wall=8132
2023-04-19 02:42:31 - progress_bar.py[line:272] - INFO: epoch 005:    532 / 578 loss=2.408, loss_v1=0, loss_v2=0, nll_loss=1.212, ntokens=3043, nsentences=96, sample_size=3043, sample_size_v1=0, sample_size_v2=0, ppl=2.32, wps=1077.2, ups=0.35, wpb=3043, bsz=96, num_updates=2840, lr=1.88466e-05, gnorm=1.277, clip=100, loss_scale=256, train_wall=28, gb_free=12.5, wall=8160
2023-04-19 02:43:00 - progress_bar.py[line:272] - INFO: epoch 005:    542 / 578 loss=2.382, loss_v1=0, loss_v2=0, nll_loss=1.183, ntokens=3043.8, nsentences=96, sample_size=3043.8, sample_size_v1=0, sample_size_v2=0, ppl=2.27, wps=1069.7, ups=0.35, wpb=3043.8, bsz=96, num_updates=2850, lr=1.88006e-05, gnorm=1.272, clip=100, loss_scale=256, train_wall=28, gb_free=11.6, wall=8188
2023-04-19 02:43:28 - progress_bar.py[line:272] - INFO: epoch 005:    552 / 578 loss=2.384, loss_v1=0, loss_v2=0, nll_loss=1.186, ntokens=3170.7, nsentences=96, sample_size=3170.7, sample_size_v1=0, sample_size_v2=0, ppl=2.27, wps=1102, ups=0.35, wpb=3170.7, bsz=96, num_updates=2860, lr=1.87546e-05, gnorm=1.174, clip=100, loss_scale=256, train_wall=29, gb_free=12.6, wall=8217
2023-04-19 02:43:57 - progress_bar.py[line:272] - INFO: epoch 005:    562 / 578 loss=2.388, loss_v1=0, loss_v2=0, nll_loss=1.19, ntokens=3255.1, nsentences=96, sample_size=3255.1, sample_size_v1=0, sample_size_v2=0, ppl=2.28, wps=1132.4, ups=0.35, wpb=3255.1, bsz=96, num_updates=2870, lr=1.87086e-05, gnorm=1.163, clip=90, loss_scale=256, train_wall=29, gb_free=12.6, wall=8246
2023-04-19 02:44:26 - progress_bar.py[line:272] - INFO: epoch 005:    572 / 578 loss=2.385, loss_v1=0, loss_v2=0, nll_loss=1.188, ntokens=3155.1, nsentences=96, sample_size=3155.1, sample_size_v1=0, sample_size_v2=0, ppl=2.28, wps=1101.7, ups=0.35, wpb=3155.1, bsz=96, num_updates=2880, lr=1.86626e-05, gnorm=1.133, clip=90, loss_scale=256, train_wall=29, gb_free=12.5, wall=8274
2023-04-19 02:44:40 - checkpoint_utils.py[line:64] - INFO: Preparing to save checkpoint for epoch 5 @ 2886 updates
2023-04-19 02:44:40 - trainer.py[line:431] - INFO: Saving checkpoint to ../../checkpoints/OFA/sgcls_checkpoints/_12_3e-5_512/checkpoint5.pt
local datafile ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 1 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 1 finished initializing row_count and line_idx-to-offset mapping
file ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 1 row count 27700 total row count 55400
slice_id 1 seek offset 27700
2023-04-19 02:44:44 - trainer.py[line:441] - INFO: Finished saving checkpoint to ../../checkpoints/OFA/sgcls_checkpoints/_12_3e-5_512/checkpoint5.pt
2023-04-19 02:44:48 - checkpoint_utils.py[line:133] - INFO: Saved checkpoint ../../checkpoints/OFA/sgcls_checkpoints/_12_3e-5_512/checkpoint5.pt (epoch 5 @ 2886 updates, score None) (writing took 7.993993155658245 seconds)
2023-04-19 02:44:48 - train.py[line:332] - INFO: end of epoch 5 (average epoch stats below)
2023-04-19 02:44:48 - progress_bar.py[line:282] - INFO: epoch 005 | loss 2.393 | loss_v1 0 | loss_v2 0 | nll_loss 1.196 | ntokens 3151.59 | nsentences 95.847 | sample_size 3151.59 | sample_size_v1 0 | sample_size_v2 0 | ppl 2.29 | wps 1097 | ups 0.35 | wpb 3151.6 | bsz 95.8 | num_updates 2886 | lr 1.8635e-05 | gnorm 1.107 | clip 82.1 | loss_scale 256 | train_wall 1645 | gb_free 13.1 | wall 8297
2023-04-19 02:44:48 - trainer.py[line:639] - INFO: loading train data for epoch 6
local datafile ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 0 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 0 finished initializing row_count and line_idx-to-offset mapping
file ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 0 row count 27700 total row count 55400
slice_id 0 seek offset 0
2023-04-19 02:44:50 - trainer.py[line:703] - INFO: begin training epoch 6
2023-04-19 02:44:50 - train.py[line:305] - INFO: Start iterating over samples
2023-04-19 02:45:02 - progress_bar.py[line:272] - INFO: epoch 006:      4 / 578 loss=2.388, loss_v1=0, loss_v2=0, nll_loss=1.189, ntokens=2919.2, nsentences=87.6, sample_size=2919.2, sample_size_v1=0, sample_size_v2=0, ppl=2.28, wps=803.5, ups=0.28, wpb=2919.2, bsz=87.6, num_updates=2890, lr=1.86166e-05, gnorm=1.46, clip=100, loss_scale=256, train_wall=26, gb_free=12.1, wall=8311
2023-04-19 02:45:31 - progress_bar.py[line:272] - INFO: epoch 006:     14 / 578 loss=2.329, loss_v1=0, loss_v2=0, nll_loss=1.125, ntokens=3125.3, nsentences=96, sample_size=3125.3, sample_size_v1=0, sample_size_v2=0, ppl=2.18, wps=1097.5, ups=0.35, wpb=3125.3, bsz=96, num_updates=2900, lr=1.85706e-05, gnorm=1.145, clip=80, loss_scale=256, train_wall=28, gb_free=12.2, wall=8339
2023-04-19 02:45:59 - progress_bar.py[line:272] - INFO: epoch 006:     24 / 578 loss=2.31, loss_v1=0, loss_v2=0, nll_loss=1.101, ntokens=3130.1, nsentences=96, sample_size=3130.1, sample_size_v1=0, sample_size_v2=0, ppl=2.15, wps=1093.7, ups=0.35, wpb=3130.1, bsz=96, num_updates=2910, lr=1.85245e-05, gnorm=1.232, clip=90, loss_scale=256, train_wall=29, gb_free=11.6, wall=8368
2023-04-19 02:46:28 - progress_bar.py[line:272] - INFO: epoch 006:     34 / 578 loss=2.318, loss_v1=0, loss_v2=0, nll_loss=1.114, ntokens=3061, nsentences=96, sample_size=3061, sample_size_v1=0, sample_size_v2=0, ppl=2.16, wps=1069.6, ups=0.35, wpb=3061, bsz=96, num_updates=2920, lr=1.84785e-05, gnorm=1.264, clip=80, loss_scale=256, train_wall=29, gb_free=12.1, wall=8396
2023-04-19 02:46:57 - progress_bar.py[line:272] - INFO: epoch 006:     44 / 578 loss=2.202, loss_v1=0, loss_v2=0, nll_loss=0.982, ntokens=3371.1, nsentences=96, sample_size=3371.1, sample_size_v1=0, sample_size_v2=0, ppl=1.98, wps=1166.6, ups=0.35, wpb=3371.1, bsz=96, num_updates=2930, lr=1.84325e-05, gnorm=1.104, clip=70, loss_scale=256, train_wall=29, gb_free=11.6, wall=8425
2023-04-19 02:47:26 - progress_bar.py[line:272] - INFO: epoch 006:     54 / 578 loss=2.284, loss_v1=0, loss_v2=0, nll_loss=1.072, ntokens=3519.7, nsentences=96, sample_size=3519.7, sample_size_v1=0, sample_size_v2=0, ppl=2.1, wps=1204.7, ups=0.34, wpb=3519.7, bsz=96, num_updates=2940, lr=1.83865e-05, gnorm=1.099, clip=80, loss_scale=256, train_wall=29, gb_free=11.8, wall=8455
2023-04-19 02:47:55 - progress_bar.py[line:272] - INFO: epoch 006:     64 / 578 loss=2.297, loss_v1=0, loss_v2=0, nll_loss=1.091, ntokens=3149.4, nsentences=96, sample_size=3149.4, sample_size_v1=0, sample_size_v2=0, ppl=2.13, wps=1098.5, ups=0.35, wpb=3149.4, bsz=96, num_updates=2950, lr=1.83405e-05, gnorm=1.207, clip=90, loss_scale=256, train_wall=29, gb_free=11.6, wall=8483
2023-04-19 02:48:23 - progress_bar.py[line:272] - INFO: epoch 006:     74 / 578 loss=2.394, loss_v1=0, loss_v2=0, nll_loss=1.196, ntokens=3083.5, nsentences=96, sample_size=3083.5, sample_size_v1=0, sample_size_v2=0, ppl=2.29, wps=1078.3, ups=0.35, wpb=3083.5, bsz=96, num_updates=2960, lr=1.82945e-05, gnorm=1.261, clip=100, loss_scale=256, train_wall=29, gb_free=12, wall=8512
2023-04-19 02:48:52 - progress_bar.py[line:272] - INFO: epoch 006:     84 / 578 loss=2.369, loss_v1=0, loss_v2=0, nll_loss=1.168, ntokens=3253.5, nsentences=96, sample_size=3253.5, sample_size_v1=0, sample_size_v2=0, ppl=2.25, wps=1123.3, ups=0.35, wpb=3253.5, bsz=96, num_updates=2970, lr=1.82485e-05, gnorm=1.174, clip=90, loss_scale=256, train_wall=29, gb_free=11.6, wall=8541
2023-04-19 02:49:21 - progress_bar.py[line:272] - INFO: epoch 006:     94 / 578 loss=2.339, loss_v1=0, loss_v2=0, nll_loss=1.135, ntokens=3364, nsentences=96, sample_size=3364, sample_size_v1=0, sample_size_v2=0, ppl=2.2, wps=1163.9, ups=0.35, wpb=3364, bsz=96, num_updates=2980, lr=1.82025e-05, gnorm=1.156, clip=100, loss_scale=256, train_wall=29, gb_free=11.4, wall=8570
2023-04-19 02:49:50 - progress_bar.py[line:272] - INFO: epoch 006:    104 / 578 loss=2.345, loss_v1=0, loss_v2=0, nll_loss=1.143, ntokens=3292, nsentences=96, sample_size=3292, sample_size_v1=0, sample_size_v2=0, ppl=2.21, wps=1131.8, ups=0.34, wpb=3292, bsz=96, num_updates=2990, lr=1.81564e-05, gnorm=1.119, clip=100, loss_scale=256, train_wall=29, gb_free=11.9, wall=8599
2023-04-19 02:50:19 - progress_bar.py[line:272] - INFO: epoch 006:    114 / 578 loss=2.343, loss_v1=0, loss_v2=0, nll_loss=1.141, ntokens=3160.4, nsentences=96, sample_size=3160.4, sample_size_v1=0, sample_size_v2=0, ppl=2.2, wps=1103.7, ups=0.35, wpb=3160.4, bsz=96, num_updates=3000, lr=1.81104e-05, gnorm=1.211, clip=100, loss_scale=256, train_wall=29, gb_free=12.2, wall=8627
2023-04-19 02:50:48 - progress_bar.py[line:272] - INFO: epoch 006:    124 / 578 loss=2.33, loss_v1=0, loss_v2=0, nll_loss=1.125, ntokens=3238.2, nsentences=96, sample_size=3238.2, sample_size_v1=0, sample_size_v2=0, ppl=2.18, wps=1126, ups=0.35, wpb=3238.2, bsz=96, num_updates=3010, lr=1.80644e-05, gnorm=1.186, clip=100, loss_scale=256, train_wall=29, gb_free=11.1, wall=8656
2023-04-19 02:51:16 - progress_bar.py[line:272] - INFO: epoch 006:    134 / 578 loss=2.351, loss_v1=0, loss_v2=0, nll_loss=1.148, ntokens=3223.3, nsentences=96, sample_size=3223.3, sample_size_v1=0, sample_size_v2=0, ppl=2.22, wps=1122.6, ups=0.35, wpb=3223.3, bsz=96, num_updates=3020, lr=1.80184e-05, gnorm=1.164, clip=100, loss_scale=256, train_wall=29, gb_free=12.2, wall=8685
2023-04-19 02:51:45 - progress_bar.py[line:272] - INFO: epoch 006:    144 / 578 loss=2.404, loss_v1=0, loss_v2=0, nll_loss=1.208, ntokens=3126.5, nsentences=96, sample_size=3126.5, sample_size_v1=0, sample_size_v2=0, ppl=2.31, wps=1096, ups=0.35, wpb=3126.5, bsz=96, num_updates=3030, lr=1.79724e-05, gnorm=1.171, clip=90, loss_scale=256, train_wall=28, gb_free=11.9, wall=8713
2023-04-19 02:52:13 - progress_bar.py[line:272] - INFO: epoch 006:    154 / 578 loss=2.407, loss_v1=0, loss_v2=0, nll_loss=1.21, ntokens=3230.1, nsentences=96, sample_size=3230.1, sample_size_v1=0, sample_size_v2=0, ppl=2.31, wps=1132, ups=0.35, wpb=3230.1, bsz=96, num_updates=3040, lr=1.79264e-05, gnorm=1.22, clip=90, loss_scale=256, train_wall=29, gb_free=12.3, wall=8742
2023-04-19 02:52:42 - progress_bar.py[line:272] - INFO: epoch 006:    164 / 578 loss=2.411, loss_v1=0, loss_v2=0, nll_loss=1.216, ntokens=3269.4, nsentences=96, sample_size=3269.4, sample_size_v1=0, sample_size_v2=0, ppl=2.32, wps=1146.3, ups=0.35, wpb=3269.4, bsz=96, num_updates=3050, lr=1.78804e-05, gnorm=1.132, clip=100, loss_scale=256, train_wall=28, gb_free=12.5, wall=8771
2023-04-19 02:53:10 - progress_bar.py[line:272] - INFO: epoch 006:    174 / 578 loss=2.407, loss_v1=0, loss_v2=0, nll_loss=1.213, ntokens=3188.2, nsentences=96, sample_size=3188.2, sample_size_v1=0, sample_size_v2=0, ppl=2.32, wps=1121.1, ups=0.35, wpb=3188.2, bsz=96, num_updates=3060, lr=1.78344e-05, gnorm=1.28, clip=100, loss_scale=256, train_wall=28, gb_free=12.1, wall=8799
2023-04-19 02:53:39 - progress_bar.py[line:272] - INFO: epoch 006:    184 / 578 loss=2.407, loss_v1=0, loss_v2=0, nll_loss=1.211, ntokens=3198.2, nsentences=96, sample_size=3198.2, sample_size_v1=0, sample_size_v2=0, ppl=2.32, wps=1120, ups=0.35, wpb=3198.2, bsz=96, num_updates=3070, lr=1.77883e-05, gnorm=1.16, clip=90, loss_scale=256, train_wall=29, gb_free=11.9, wall=8828
2023-04-19 02:54:07 - progress_bar.py[line:272] - INFO: epoch 006:    194 / 578 loss=2.392, loss_v1=0, loss_v2=0, nll_loss=1.194, ntokens=3235.3, nsentences=96, sample_size=3235.3, sample_size_v1=0, sample_size_v2=0, ppl=2.29, wps=1136.9, ups=0.35, wpb=3235.3, bsz=96, num_updates=3080, lr=1.77423e-05, gnorm=1.197, clip=90, loss_scale=256, train_wall=28, gb_free=12.3, wall=8856
2023-04-19 02:54:36 - progress_bar.py[line:272] - INFO: epoch 006:    204 / 578 loss=2.389, loss_v1=0, loss_v2=0, nll_loss=1.193, ntokens=3221.9, nsentences=96, sample_size=3221.9, sample_size_v1=0, sample_size_v2=0, ppl=2.29, wps=1134.7, ups=0.35, wpb=3221.9, bsz=96, num_updates=3090, lr=1.76963e-05, gnorm=1.201, clip=100, loss_scale=256, train_wall=28, gb_free=12, wall=8884
2023-04-19 02:54:59 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 256.0
2023-04-19 02:55:07 - progress_bar.py[line:272] - INFO: epoch 006:    215 / 578 loss=2.411, loss_v1=0, loss_v2=0, nll_loss=1.216, ntokens=3047.9, nsentences=96, sample_size=3047.9, sample_size_v1=0, sample_size_v2=0, ppl=2.32, wps=971.4, ups=0.32, wpb=3047.9, bsz=96, num_updates=3100, lr=1.76503e-05, gnorm=1.25, clip=100, loss_scale=256, train_wall=31, gb_free=12.3, wall=8916
2023-04-19 02:55:36 - progress_bar.py[line:272] - INFO: epoch 006:    225 / 578 loss=2.383, loss_v1=0, loss_v2=0, nll_loss=1.184, ntokens=3194.7, nsentences=96, sample_size=3194.7, sample_size_v1=0, sample_size_v2=0, ppl=2.27, wps=1120.5, ups=0.35, wpb=3194.7, bsz=96, num_updates=3110, lr=1.76043e-05, gnorm=1.223, clip=100, loss_scale=256, train_wall=28, gb_free=11.8, wall=8944
2023-04-19 02:56:04 - progress_bar.py[line:272] - INFO: epoch 006:    235 / 578 loss=2.404, loss_v1=0, loss_v2=0, nll_loss=1.208, ntokens=2935.7, nsentences=96, sample_size=2935.7, sample_size_v1=0, sample_size_v2=0, ppl=2.31, wps=1034.7, ups=0.35, wpb=2935.7, bsz=96, num_updates=3120, lr=1.75583e-05, gnorm=1.257, clip=100, loss_scale=256, train_wall=28, gb_free=12.5, wall=8973
2023-04-19 02:56:32 - progress_bar.py[line:272] - INFO: epoch 006:    245 / 578 loss=2.411, loss_v1=0, loss_v2=0, nll_loss=1.213, ntokens=2950.7, nsentences=96, sample_size=2950.7, sample_size_v1=0, sample_size_v2=0, ppl=2.32, wps=1039.4, ups=0.35, wpb=2950.7, bsz=96, num_updates=3130, lr=1.75123e-05, gnorm=1.305, clip=100, loss_scale=256, train_wall=28, gb_free=12.4, wall=9001
2023-04-19 02:57:01 - progress_bar.py[line:272] - INFO: epoch 006:    255 / 578 loss=2.387, loss_v1=0, loss_v2=0, nll_loss=1.191, ntokens=3188.3, nsentences=96, sample_size=3188.3, sample_size_v1=0, sample_size_v2=0, ppl=2.28, wps=1117.2, ups=0.35, wpb=3188.3, bsz=96, num_updates=3140, lr=1.74663e-05, gnorm=1.158, clip=100, loss_scale=256, train_wall=29, gb_free=12.2, wall=9030
2023-04-19 02:57:29 - progress_bar.py[line:272] - INFO: epoch 006:    265 / 578 loss=2.396, loss_v1=0, loss_v2=0, nll_loss=1.199, ntokens=3105.2, nsentences=96, sample_size=3105.2, sample_size_v1=0, sample_size_v2=0, ppl=2.3, wps=1092.5, ups=0.35, wpb=3105.2, bsz=96, num_updates=3150, lr=1.74202e-05, gnorm=1.225, clip=100, loss_scale=256, train_wall=28, gb_free=12.1, wall=9058
2023-04-19 02:57:58 - progress_bar.py[line:272] - INFO: epoch 006:    275 / 578 loss=2.396, loss_v1=0, loss_v2=0, nll_loss=1.2, ntokens=3161, nsentences=96, sample_size=3161, sample_size_v1=0, sample_size_v2=0, ppl=2.3, wps=1109.5, ups=0.35, wpb=3161, bsz=96, num_updates=3160, lr=1.73742e-05, gnorm=1.228, clip=100, loss_scale=256, train_wall=28, gb_free=12.3, wall=9087
2023-04-19 02:58:26 - progress_bar.py[line:272] - INFO: epoch 006:    285 / 578 loss=2.377, loss_v1=0, loss_v2=0, nll_loss=1.178, ntokens=3113.8, nsentences=96, sample_size=3113.8, sample_size_v1=0, sample_size_v2=0, ppl=2.26, wps=1089.6, ups=0.35, wpb=3113.8, bsz=96, num_updates=3170, lr=1.73282e-05, gnorm=1.234, clip=100, loss_scale=256, train_wall=29, gb_free=12.2, wall=9115
2023-04-19 02:58:55 - progress_bar.py[line:272] - INFO: epoch 006:    295 / 578 loss=2.409, loss_v1=0, loss_v2=0, nll_loss=1.213, ntokens=3133.2, nsentences=96, sample_size=3133.2, sample_size_v1=0, sample_size_v2=0, ppl=2.32, wps=1098.4, ups=0.35, wpb=3133.2, bsz=96, num_updates=3180, lr=1.72822e-05, gnorm=1.171, clip=100, loss_scale=256, train_wall=28, gb_free=11.9, wall=9144
2023-04-19 02:59:24 - progress_bar.py[line:272] - INFO: epoch 006:    305 / 578 loss=2.397, loss_v1=0, loss_v2=0, nll_loss=1.202, ntokens=3082.3, nsentences=96, sample_size=3082.3, sample_size_v1=0, sample_size_v2=0, ppl=2.3, wps=1077.9, ups=0.35, wpb=3082.3, bsz=96, num_updates=3190, lr=1.72362e-05, gnorm=1.227, clip=100, loss_scale=256, train_wall=29, gb_free=11.7, wall=9172
2023-04-19 02:59:52 - progress_bar.py[line:272] - INFO: epoch 006:    315 / 578 loss=2.391, loss_v1=0, loss_v2=0, nll_loss=1.192, ntokens=3251.3, nsentences=95.6, sample_size=3251.3, sample_size_v1=0, sample_size_v2=0, ppl=2.28, wps=1148.3, ups=0.35, wpb=3251.3, bsz=95.6, num_updates=3200, lr=1.71902e-05, gnorm=1.245, clip=100, loss_scale=256, train_wall=28, gb_free=12.1, wall=9201
2023-04-19 03:00:21 - progress_bar.py[line:272] - INFO: epoch 006:    325 / 578 loss=2.392, loss_v1=0, loss_v2=0, nll_loss=1.194, ntokens=3188.7, nsentences=96, sample_size=3188.7, sample_size_v1=0, sample_size_v2=0, ppl=2.29, wps=1112.5, ups=0.35, wpb=3188.7, bsz=96, num_updates=3210, lr=1.71442e-05, gnorm=1.236, clip=100, loss_scale=256, train_wall=29, gb_free=12.7, wall=9229
2023-04-19 03:00:49 - progress_bar.py[line:272] - INFO: epoch 006:    335 / 578 loss=2.381, loss_v1=0, loss_v2=0, nll_loss=1.183, ntokens=3098.2, nsentences=96, sample_size=3098.2, sample_size_v1=0, sample_size_v2=0, ppl=2.27, wps=1087.2, ups=0.35, wpb=3098.2, bsz=96, num_updates=3220, lr=1.70982e-05, gnorm=1.255, clip=100, loss_scale=256, train_wall=28, gb_free=12.4, wall=9258
2023-04-19 03:01:18 - progress_bar.py[line:272] - INFO: epoch 006:    345 / 578 loss=2.402, loss_v1=0, loss_v2=0, nll_loss=1.205, ntokens=3257.1, nsentences=96, sample_size=3257.1, sample_size_v1=0, sample_size_v2=0, ppl=2.3, wps=1145.9, ups=0.35, wpb=3257.1, bsz=96, num_updates=3230, lr=1.70521e-05, gnorm=1.2, clip=100, loss_scale=256, train_wall=28, gb_free=12.5, wall=9286
2023-04-19 03:01:46 - progress_bar.py[line:272] - INFO: epoch 006:    355 / 578 loss=2.381, loss_v1=0, loss_v2=0, nll_loss=1.184, ntokens=3059.5, nsentences=96, sample_size=3059.5, sample_size_v1=0, sample_size_v2=0, ppl=2.27, wps=1076.9, ups=0.35, wpb=3059.5, bsz=96, num_updates=3240, lr=1.70061e-05, gnorm=1.214, clip=100, loss_scale=256, train_wall=28, gb_free=12.6, wall=9315
2023-04-19 03:02:15 - progress_bar.py[line:272] - INFO: epoch 006:    365 / 578 loss=2.402, loss_v1=0, loss_v2=0, nll_loss=1.206, ntokens=3327.1, nsentences=96, sample_size=3327.1, sample_size_v1=0, sample_size_v2=0, ppl=2.31, wps=1164.6, ups=0.35, wpb=3327.1, bsz=96, num_updates=3250, lr=1.69601e-05, gnorm=1.186, clip=90, loss_scale=256, train_wall=29, gb_free=12.2, wall=9343
2023-04-19 03:02:43 - progress_bar.py[line:272] - INFO: epoch 006:    375 / 578 loss=2.398, loss_v1=0, loss_v2=0, nll_loss=1.202, ntokens=3378.1, nsentences=96, sample_size=3378.1, sample_size_v1=0, sample_size_v2=0, ppl=2.3, wps=1175.7, ups=0.35, wpb=3378.1, bsz=96, num_updates=3260, lr=1.69141e-05, gnorm=1.186, clip=100, loss_scale=256, train_wall=29, gb_free=12.7, wall=9372
2023-04-19 03:03:12 - progress_bar.py[line:272] - INFO: epoch 006:    385 / 578 loss=2.396, loss_v1=0, loss_v2=0, nll_loss=1.198, ntokens=3261, nsentences=96, sample_size=3261, sample_size_v1=0, sample_size_v2=0, ppl=2.29, wps=1140.9, ups=0.35, wpb=3261, bsz=96, num_updates=3270, lr=1.68681e-05, gnorm=1.245, clip=100, loss_scale=256, train_wall=29, gb_free=12.2, wall=9400
2023-04-19 03:03:40 - progress_bar.py[line:272] - INFO: epoch 006:    395 / 578 loss=2.383, loss_v1=0, loss_v2=0, nll_loss=1.186, ntokens=3162, nsentences=96, sample_size=3162, sample_size_v1=0, sample_size_v2=0, ppl=2.28, wps=1106.3, ups=0.35, wpb=3162, bsz=96, num_updates=3280, lr=1.68221e-05, gnorm=1.227, clip=90, loss_scale=256, train_wall=29, gb_free=12, wall=9429
2023-04-19 03:04:09 - progress_bar.py[line:272] - INFO: epoch 006:    405 / 578 loss=2.375, loss_v1=0, loss_v2=0, nll_loss=1.176, ntokens=3061.5, nsentences=96, sample_size=3061.5, sample_size_v1=0, sample_size_v2=0, ppl=2.26, wps=1071.7, ups=0.35, wpb=3061.5, bsz=96, num_updates=3290, lr=1.67761e-05, gnorm=1.346, clip=100, loss_scale=256, train_wall=29, gb_free=12, wall=9458
2023-04-19 03:04:38 - progress_bar.py[line:272] - INFO: epoch 006:    415 / 578 loss=2.403, loss_v1=0, loss_v2=0, nll_loss=1.205, ntokens=3003.6, nsentences=96, sample_size=3003.6, sample_size_v1=0, sample_size_v2=0, ppl=2.31, wps=1050.9, ups=0.35, wpb=3003.6, bsz=96, num_updates=3300, lr=1.67301e-05, gnorm=1.299, clip=100, loss_scale=256, train_wall=29, gb_free=12, wall=9486
2023-04-19 03:05:06 - progress_bar.py[line:272] - INFO: epoch 006:    425 / 578 loss=2.372, loss_v1=0, loss_v2=0, nll_loss=1.173, ntokens=3063, nsentences=96, sample_size=3063, sample_size_v1=0, sample_size_v2=0, ppl=2.25, wps=1072.8, ups=0.35, wpb=3063, bsz=96, num_updates=3310, lr=1.6684e-05, gnorm=1.318, clip=100, loss_scale=256, train_wall=29, gb_free=12.3, wall=9515
2023-04-19 03:05:34 - progress_bar.py[line:272] - INFO: epoch 006:    435 / 578 loss=2.398, loss_v1=0, loss_v2=0, nll_loss=1.2, ntokens=3017.4, nsentences=96, sample_size=3017.4, sample_size_v1=0, sample_size_v2=0, ppl=2.3, wps=1064.6, ups=0.35, wpb=3017.4, bsz=96, num_updates=3320, lr=1.6638e-05, gnorm=1.299, clip=100, loss_scale=256, train_wall=28, gb_free=12.7, wall=9543
2023-04-19 03:06:03 - progress_bar.py[line:272] - INFO: epoch 006:    445 / 578 loss=2.408, loss_v1=0, loss_v2=0, nll_loss=1.212, ntokens=2914.2, nsentences=96, sample_size=2914.2, sample_size_v1=0, sample_size_v2=0, ppl=2.32, wps=1021.7, ups=0.35, wpb=2914.2, bsz=96, num_updates=3330, lr=1.6592e-05, gnorm=1.345, clip=100, loss_scale=256, train_wall=28, gb_free=12.4, wall=9572
2023-04-19 03:06:31 - progress_bar.py[line:272] - INFO: epoch 006:    455 / 578 loss=2.383, loss_v1=0, loss_v2=0, nll_loss=1.185, ntokens=3109.7, nsentences=96, sample_size=3109.7, sample_size_v1=0, sample_size_v2=0, ppl=2.27, wps=1092.1, ups=0.35, wpb=3109.7, bsz=96, num_updates=3340, lr=1.6546e-05, gnorm=1.28, clip=100, loss_scale=256, train_wall=28, gb_free=12.4, wall=9600
2023-04-19 03:07:00 - progress_bar.py[line:272] - INFO: epoch 006:    465 / 578 loss=2.395, loss_v1=0, loss_v2=0, nll_loss=1.198, ntokens=3096.4, nsentences=96, sample_size=3096.4, sample_size_v1=0, sample_size_v2=0, ppl=2.29, wps=1085.2, ups=0.35, wpb=3096.4, bsz=96, num_updates=3350, lr=1.65e-05, gnorm=1.204, clip=100, loss_scale=256, train_wall=29, gb_free=11.9, wall=9629
2023-04-19 03:07:28 - progress_bar.py[line:272] - INFO: epoch 006:    475 / 578 loss=2.404, loss_v1=0, loss_v2=0, nll_loss=1.207, ntokens=2883.1, nsentences=96, sample_size=2883.1, sample_size_v1=0, sample_size_v2=0, ppl=2.31, wps=1016.7, ups=0.35, wpb=2883.1, bsz=96, num_updates=3360, lr=1.6454e-05, gnorm=1.27, clip=100, loss_scale=256, train_wall=28, gb_free=12.7, wall=9657
2023-04-19 03:07:57 - progress_bar.py[line:272] - INFO: epoch 006:    485 / 578 loss=2.375, loss_v1=0, loss_v2=0, nll_loss=1.178, ntokens=2967.7, nsentences=96, sample_size=2967.7, sample_size_v1=0, sample_size_v2=0, ppl=2.26, wps=1046, ups=0.35, wpb=2967.7, bsz=96, num_updates=3370, lr=1.6408e-05, gnorm=1.28, clip=100, loss_scale=256, train_wall=28, gb_free=12.6, wall=9685
2023-04-19 03:08:25 - progress_bar.py[line:272] - INFO: epoch 006:    495 / 578 loss=2.368, loss_v1=0, loss_v2=0, nll_loss=1.166, ntokens=3159.6, nsentences=96, sample_size=3159.6, sample_size_v1=0, sample_size_v2=0, ppl=2.24, wps=1109.1, ups=0.35, wpb=3159.6, bsz=96, num_updates=3380, lr=1.6362e-05, gnorm=1.271, clip=100, loss_scale=256, train_wall=28, gb_free=12.3, wall=9714
2023-04-19 03:08:54 - progress_bar.py[line:272] - INFO: epoch 006:    505 / 578 loss=2.362, loss_v1=0, loss_v2=0, nll_loss=1.162, ntokens=3120, nsentences=96, sample_size=3120, sample_size_v1=0, sample_size_v2=0, ppl=2.24, wps=1094.6, ups=0.35, wpb=3120, bsz=96, num_updates=3390, lr=1.6316e-05, gnorm=1.329, clip=100, loss_scale=256, train_wall=28, gb_free=12.5, wall=9742
2023-04-19 03:09:22 - progress_bar.py[line:272] - INFO: epoch 006:    515 / 578 loss=2.371, loss_v1=0, loss_v2=0, nll_loss=1.17, ntokens=3191.5, nsentences=96, sample_size=3191.5, sample_size_v1=0, sample_size_v2=0, ppl=2.25, wps=1122.7, ups=0.35, wpb=3191.5, bsz=96, num_updates=3400, lr=1.62699e-05, gnorm=1.343, clip=100, loss_scale=256, train_wall=28, gb_free=11.6, wall=9771
2023-04-19 03:09:51 - progress_bar.py[line:272] - INFO: epoch 006:    525 / 578 loss=2.374, loss_v1=0, loss_v2=0, nll_loss=1.175, ntokens=3201.5, nsentences=96, sample_size=3201.5, sample_size_v1=0, sample_size_v2=0, ppl=2.26, wps=1123.9, ups=0.35, wpb=3201.5, bsz=96, num_updates=3410, lr=1.62239e-05, gnorm=1.357, clip=100, loss_scale=256, train_wall=28, gb_free=12.3, wall=9799
2023-04-19 03:10:19 - progress_bar.py[line:272] - INFO: epoch 006:    535 / 578 loss=2.383, loss_v1=0, loss_v2=0, nll_loss=1.184, ntokens=3022.9, nsentences=96, sample_size=3022.9, sample_size_v1=0, sample_size_v2=0, ppl=2.27, wps=1065.1, ups=0.35, wpb=3022.9, bsz=96, num_updates=3420, lr=1.61779e-05, gnorm=1.406, clip=100, loss_scale=256, train_wall=28, gb_free=12.4, wall=9828
2023-04-19 03:10:48 - progress_bar.py[line:272] - INFO: epoch 006:    545 / 578 loss=2.362, loss_v1=0, loss_v2=0, nll_loss=1.16, ntokens=3112, nsentences=96, sample_size=3112, sample_size_v1=0, sample_size_v2=0, ppl=2.24, wps=1087.2, ups=0.35, wpb=3112, bsz=96, num_updates=3430, lr=1.61319e-05, gnorm=1.397, clip=100, loss_scale=256, train_wall=29, gb_free=12.4, wall=9856
2023-04-19 03:11:17 - progress_bar.py[line:272] - INFO: epoch 006:    555 / 578 loss=2.364, loss_v1=0, loss_v2=0, nll_loss=1.163, ntokens=3300.6, nsentences=96, sample_size=3300.6, sample_size_v1=0, sample_size_v2=0, ppl=2.24, wps=1139.5, ups=0.35, wpb=3300.6, bsz=96, num_updates=3440, lr=1.60859e-05, gnorm=1.255, clip=100, loss_scale=256, train_wall=29, gb_free=12.7, wall=9885
2023-04-19 03:11:45 - progress_bar.py[line:272] - INFO: epoch 006:    565 / 578 loss=2.369, loss_v1=0, loss_v2=0, nll_loss=1.167, ntokens=3193.3, nsentences=96, sample_size=3193.3, sample_size_v1=0, sample_size_v2=0, ppl=2.25, wps=1114.8, ups=0.35, wpb=3193.3, bsz=96, num_updates=3450, lr=1.60399e-05, gnorm=1.316, clip=100, loss_scale=256, train_wall=29, gb_free=11.8, wall=9914
2023-04-19 03:12:14 - progress_bar.py[line:272] - INFO: epoch 006:    575 / 578 loss=2.38, loss_v1=0, loss_v2=0, nll_loss=1.183, ntokens=3139.7, nsentences=96, sample_size=3139.7, sample_size_v1=0, sample_size_v2=0, ppl=2.27, wps=1093.2, ups=0.35, wpb=3139.7, bsz=96, num_updates=3460, lr=1.59939e-05, gnorm=1.345, clip=100, loss_scale=256, train_wall=29, gb_free=12, wall=9943
2023-04-19 03:12:20 - checkpoint_utils.py[line:64] - INFO: Preparing to save checkpoint for epoch 6 @ 3463 updates
2023-04-19 03:12:20 - trainer.py[line:431] - INFO: Saving checkpoint to ../../checkpoints/OFA/sgcls_checkpoints/_12_3e-5_512/checkpoint6.pt
local datafile ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 1 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 1 finished initializing row_count and line_idx-to-offset mapping
file ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 1 row count 27700 total row count 55400
slice_id 1 seek offset 27700
2023-04-19 03:12:23 - trainer.py[line:441] - INFO: Finished saving checkpoint to ../../checkpoints/OFA/sgcls_checkpoints/_12_3e-5_512/checkpoint6.pt
2023-04-19 03:12:28 - checkpoint_utils.py[line:133] - INFO: Saved checkpoint ../../checkpoints/OFA/sgcls_checkpoints/_12_3e-5_512/checkpoint6.pt (epoch 6 @ 3463 updates, score None) (writing took 7.539269329048693 seconds)
2023-04-19 03:12:28 - train.py[line:332] - INFO: end of epoch 6 (average epoch stats below)
2023-04-19 03:12:28 - progress_bar.py[line:282] - INFO: epoch 006 | loss 2.374 | loss_v1 0 | loss_v2 0 | nll_loss 1.175 | ntokens 3151.73 | nsentences 95.847 | sample_size 3151.73 | sample_size_v1 0 | sample_size_v2 0 | ppl 2.26 | wps 1096 | ups 0.35 | wpb 3151.7 | bsz 95.8 | num_updates 3463 | lr 1.59801e-05 | gnorm 1.242 | clip 96.9 | loss_scale 256 | train_wall 1648 | gb_free 13.1 | wall 9956
2023-04-19 03:12:28 - trainer.py[line:639] - INFO: loading train data for epoch 7
local datafile ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 0 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 0 finished initializing row_count and line_idx-to-offset mapping
file ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 0 row count 27700 total row count 55400
slice_id 0 seek offset 0
2023-04-19 03:12:29 - trainer.py[line:703] - INFO: begin training epoch 7
2023-04-19 03:12:29 - train.py[line:305] - INFO: Start iterating over samples
2023-04-19 03:12:50 - progress_bar.py[line:272] - INFO: epoch 007:      7 / 578 loss=2.349, loss_v1=0, loss_v2=0, nll_loss=1.145, ntokens=2933.8, nsentences=87.6, sample_size=2933.8, sample_size_v1=0, sample_size_v2=0, ppl=2.21, wps=814.9, ups=0.28, wpb=2933.8, bsz=87.6, num_updates=3470, lr=1.59479e-05, gnorm=1.461, clip=100, loss_scale=256, train_wall=26, gb_free=11.4, wall=9979
2023-04-19 03:13:18 - progress_bar.py[line:272] - INFO: epoch 007:     17 / 578 loss=2.324, loss_v1=0, loss_v2=0, nll_loss=1.12, ntokens=2994, nsentences=96, sample_size=2994, sample_size_v1=0, sample_size_v2=0, ppl=2.17, wps=1055.8, ups=0.35, wpb=2994, bsz=96, num_updates=3480, lr=1.59018e-05, gnorm=1.328, clip=100, loss_scale=256, train_wall=28, gb_free=12.3, wall=10007
2023-04-19 03:13:33 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 128.0
2023-04-19 03:13:50 - progress_bar.py[line:272] - INFO: epoch 007:     28 / 578 loss=2.266, loss_v1=0, loss_v2=0, nll_loss=1.054, ntokens=3203.7, nsentences=96, sample_size=3203.7, sample_size_v1=0, sample_size_v2=0, ppl=2.08, wps=1016.3, ups=0.32, wpb=3203.7, bsz=96, num_updates=3490, lr=1.58558e-05, gnorm=1.304, clip=90, loss_scale=128, train_wall=31, gb_free=12, wall=10039
2023-04-19 03:14:19 - progress_bar.py[line:272] - INFO: epoch 007:     38 / 578 loss=2.282, loss_v1=0, loss_v2=0, nll_loss=1.071, ntokens=3042.7, nsentences=96, sample_size=3042.7, sample_size_v1=0, sample_size_v2=0, ppl=2.1, wps=1062.9, ups=0.35, wpb=3042.7, bsz=96, num_updates=3500, lr=1.58098e-05, gnorm=1.52, clip=100, loss_scale=128, train_wall=29, gb_free=12.2, wall=10067
2023-04-19 03:14:48 - progress_bar.py[line:272] - INFO: epoch 007:     48 / 578 loss=2.218, loss_v1=0, loss_v2=0, nll_loss=1.001, ntokens=3610.6, nsentences=96, sample_size=3610.6, sample_size_v1=0, sample_size_v2=0, ppl=2, wps=1231.8, ups=0.34, wpb=3610.6, bsz=96, num_updates=3510, lr=1.57638e-05, gnorm=1.151, clip=80, loss_scale=128, train_wall=29, gb_free=11.6, wall=10096
2023-04-19 03:15:17 - progress_bar.py[line:272] - INFO: epoch 007:     58 / 578 loss=2.279, loss_v1=0, loss_v2=0, nll_loss=1.066, ntokens=3273.1, nsentences=96, sample_size=3273.1, sample_size_v1=0, sample_size_v2=0, ppl=2.09, wps=1130.2, ups=0.35, wpb=3273.1, bsz=96, num_updates=3520, lr=1.57178e-05, gnorm=1.35, clip=100, loss_scale=128, train_wall=29, gb_free=11.6, wall=10125
2023-04-19 03:15:45 - progress_bar.py[line:272] - INFO: epoch 007:     68 / 578 loss=2.311, loss_v1=0, loss_v2=0, nll_loss=1.105, ntokens=3149.2, nsentences=96, sample_size=3149.2, sample_size_v1=0, sample_size_v2=0, ppl=2.15, wps=1103.7, ups=0.35, wpb=3149.2, bsz=96, num_updates=3530, lr=1.56718e-05, gnorm=1.404, clip=100, loss_scale=128, train_wall=29, gb_free=12.1, wall=10154
2023-04-19 03:16:14 - progress_bar.py[line:272] - INFO: epoch 007:     78 / 578 loss=2.374, loss_v1=0, loss_v2=0, nll_loss=1.175, ntokens=3106.3, nsentences=96, sample_size=3106.3, sample_size_v1=0, sample_size_v2=0, ppl=2.26, wps=1081.5, ups=0.35, wpb=3106.3, bsz=96, num_updates=3540, lr=1.56258e-05, gnorm=1.321, clip=100, loss_scale=128, train_wall=29, gb_free=11.8, wall=10183
2023-04-19 03:16:43 - progress_bar.py[line:272] - INFO: epoch 007:     88 / 578 loss=2.341, loss_v1=0, loss_v2=0, nll_loss=1.136, ntokens=3333.6, nsentences=96, sample_size=3333.6, sample_size_v1=0, sample_size_v2=0, ppl=2.2, wps=1151.2, ups=0.35, wpb=3333.6, bsz=96, num_updates=3550, lr=1.55798e-05, gnorm=1.232, clip=100, loss_scale=128, train_wall=29, gb_free=11.8, wall=10212
2023-04-19 03:17:12 - progress_bar.py[line:272] - INFO: epoch 007:     98 / 578 loss=2.319, loss_v1=0, loss_v2=0, nll_loss=1.114, ntokens=3301.9, nsentences=96, sample_size=3301.9, sample_size_v1=0, sample_size_v2=0, ppl=2.16, wps=1141.8, ups=0.35, wpb=3301.9, bsz=96, num_updates=3560, lr=1.55337e-05, gnorm=1.262, clip=100, loss_scale=128, train_wall=29, gb_free=12, wall=10241
2023-04-19 03:17:41 - progress_bar.py[line:272] - INFO: epoch 007:    108 / 578 loss=2.327, loss_v1=0, loss_v2=0, nll_loss=1.121, ntokens=3295.4, nsentences=96, sample_size=3295.4, sample_size_v1=0, sample_size_v2=0, ppl=2.18, wps=1136.8, ups=0.34, wpb=3295.4, bsz=96, num_updates=3570, lr=1.54877e-05, gnorm=1.303, clip=100, loss_scale=128, train_wall=29, gb_free=12, wall=10270
2023-04-19 03:18:10 - progress_bar.py[line:272] - INFO: epoch 007:    118 / 578 loss=2.329, loss_v1=0, loss_v2=0, nll_loss=1.124, ntokens=3146.8, nsentences=96, sample_size=3146.8, sample_size_v1=0, sample_size_v2=0, ppl=2.18, wps=1098.5, ups=0.35, wpb=3146.8, bsz=96, num_updates=3580, lr=1.54417e-05, gnorm=1.349, clip=100, loss_scale=128, train_wall=29, gb_free=11.9, wall=10298
2023-04-19 03:18:38 - progress_bar.py[line:272] - INFO: epoch 007:    128 / 578 loss=2.312, loss_v1=0, loss_v2=0, nll_loss=1.106, ntokens=3303.1, nsentences=95.6, sample_size=3303.1, sample_size_v1=0, sample_size_v2=0, ppl=2.15, wps=1150.6, ups=0.35, wpb=3303.1, bsz=95.6, num_updates=3590, lr=1.53957e-05, gnorm=1.317, clip=100, loss_scale=128, train_wall=29, gb_free=11.7, wall=10327
2023-04-19 03:19:07 - progress_bar.py[line:272] - INFO: epoch 007:    138 / 578 loss=2.365, loss_v1=0, loss_v2=0, nll_loss=1.164, ntokens=3024.3, nsentences=96, sample_size=3024.3, sample_size_v1=0, sample_size_v2=0, ppl=2.24, wps=1059.4, ups=0.35, wpb=3024.3, bsz=96, num_updates=3600, lr=1.53497e-05, gnorm=1.397, clip=100, loss_scale=128, train_wall=29, gb_free=12.3, wall=10356
2023-04-19 03:19:36 - progress_bar.py[line:272] - INFO: epoch 007:    148 / 578 loss=2.382, loss_v1=0, loss_v2=0, nll_loss=1.184, ntokens=3300.7, nsentences=96, sample_size=3300.7, sample_size_v1=0, sample_size_v2=0, ppl=2.27, wps=1152.9, ups=0.35, wpb=3300.7, bsz=96, num_updates=3610, lr=1.53037e-05, gnorm=1.336, clip=100, loss_scale=128, train_wall=29, gb_free=11.9, wall=10384
2023-04-19 03:20:04 - progress_bar.py[line:272] - INFO: epoch 007:    158 / 578 loss=2.402, loss_v1=0, loss_v2=0, nll_loss=1.204, ntokens=3190.7, nsentences=96, sample_size=3190.7, sample_size_v1=0, sample_size_v2=0, ppl=2.3, wps=1123.3, ups=0.35, wpb=3190.7, bsz=96, num_updates=3620, lr=1.52577e-05, gnorm=1.32, clip=100, loss_scale=128, train_wall=28, gb_free=11.8, wall=10413
2023-04-19 03:20:32 - progress_bar.py[line:272] - INFO: epoch 007:    168 / 578 loss=2.383, loss_v1=0, loss_v2=0, nll_loss=1.186, ntokens=3226.4, nsentences=96, sample_size=3226.4, sample_size_v1=0, sample_size_v2=0, ppl=2.28, wps=1130.9, ups=0.35, wpb=3226.4, bsz=96, num_updates=3630, lr=1.52117e-05, gnorm=1.331, clip=100, loss_scale=128, train_wall=28, gb_free=12.2, wall=10441
2023-04-19 03:21:01 - progress_bar.py[line:272] - INFO: epoch 007:    178 / 578 loss=2.393, loss_v1=0, loss_v2=0, nll_loss=1.195, ntokens=3192.7, nsentences=96, sample_size=3192.7, sample_size_v1=0, sample_size_v2=0, ppl=2.29, wps=1119.7, ups=0.35, wpb=3192.7, bsz=96, num_updates=3640, lr=1.51656e-05, gnorm=1.294, clip=100, loss_scale=128, train_wall=28, gb_free=12.1, wall=10470
2023-04-19 03:21:30 - progress_bar.py[line:272] - INFO: epoch 007:    188 / 578 loss=2.394, loss_v1=0, loss_v2=0, nll_loss=1.198, ntokens=3279.5, nsentences=96, sample_size=3279.5, sample_size_v1=0, sample_size_v2=0, ppl=2.29, wps=1150, ups=0.35, wpb=3279.5, bsz=96, num_updates=3650, lr=1.51196e-05, gnorm=1.307, clip=100, loss_scale=128, train_wall=28, gb_free=11.8, wall=10498
2023-04-19 03:21:58 - progress_bar.py[line:272] - INFO: epoch 007:    198 / 578 loss=2.367, loss_v1=0, loss_v2=0, nll_loss=1.166, ntokens=3199.1, nsentences=96, sample_size=3199.1, sample_size_v1=0, sample_size_v2=0, ppl=2.24, wps=1122.8, ups=0.35, wpb=3199.1, bsz=96, num_updates=3660, lr=1.50736e-05, gnorm=1.328, clip=100, loss_scale=128, train_wall=28, gb_free=12.3, wall=10527
2023-04-19 03:22:26 - progress_bar.py[line:272] - INFO: epoch 007:    208 / 578 loss=2.37, loss_v1=0, loss_v2=0, nll_loss=1.172, ntokens=3189.4, nsentences=96, sample_size=3189.4, sample_size_v1=0, sample_size_v2=0, ppl=2.25, wps=1124.1, ups=0.35, wpb=3189.4, bsz=96, num_updates=3670, lr=1.50276e-05, gnorm=1.285, clip=100, loss_scale=128, train_wall=28, gb_free=12.4, wall=10555
2023-04-19 03:22:55 - progress_bar.py[line:272] - INFO: epoch 007:    218 / 578 loss=2.399, loss_v1=0, loss_v2=0, nll_loss=1.202, ntokens=3040.6, nsentences=96, sample_size=3040.6, sample_size_v1=0, sample_size_v2=0, ppl=2.3, wps=1074.5, ups=0.35, wpb=3040.6, bsz=96, num_updates=3680, lr=1.49816e-05, gnorm=1.476, clip=100, loss_scale=128, train_wall=28, gb_free=12.3, wall=10583
2023-04-19 03:23:23 - progress_bar.py[line:272] - INFO: epoch 007:    228 / 578 loss=2.362, loss_v1=0, loss_v2=0, nll_loss=1.162, ntokens=3082.5, nsentences=96, sample_size=3082.5, sample_size_v1=0, sample_size_v2=0, ppl=2.24, wps=1081.2, ups=0.35, wpb=3082.5, bsz=96, num_updates=3690, lr=1.49356e-05, gnorm=1.418, clip=100, loss_scale=128, train_wall=28, gb_free=12.5, wall=10612
2023-04-19 03:23:51 - progress_bar.py[line:272] - INFO: epoch 007:    238 / 578 loss=2.395, loss_v1=0, loss_v2=0, nll_loss=1.197, ntokens=2934.7, nsentences=96, sample_size=2934.7, sample_size_v1=0, sample_size_v2=0, ppl=2.29, wps=1038.6, ups=0.35, wpb=2934.7, bsz=96, num_updates=3700, lr=1.48896e-05, gnorm=1.446, clip=100, loss_scale=128, train_wall=28, gb_free=12.4, wall=10640
2023-04-19 03:24:20 - progress_bar.py[line:272] - INFO: epoch 007:    248 / 578 loss=2.389, loss_v1=0, loss_v2=0, nll_loss=1.189, ntokens=3024.8, nsentences=96, sample_size=3024.8, sample_size_v1=0, sample_size_v2=0, ppl=2.28, wps=1066.7, ups=0.35, wpb=3024.8, bsz=96, num_updates=3710, lr=1.48436e-05, gnorm=1.376, clip=100, loss_scale=128, train_wall=28, gb_free=12.2, wall=10668
2023-04-19 03:24:48 - progress_bar.py[line:272] - INFO: epoch 007:    258 / 578 loss=2.362, loss_v1=0, loss_v2=0, nll_loss=1.162, ntokens=3251.9, nsentences=96, sample_size=3251.9, sample_size_v1=0, sample_size_v2=0, ppl=2.24, wps=1141.6, ups=0.35, wpb=3251.9, bsz=96, num_updates=3720, lr=1.47975e-05, gnorm=1.32, clip=100, loss_scale=128, train_wall=28, gb_free=12.3, wall=10697
2023-04-19 03:25:17 - progress_bar.py[line:272] - INFO: epoch 007:    268 / 578 loss=2.379, loss_v1=0, loss_v2=0, nll_loss=1.181, ntokens=3021.5, nsentences=96, sample_size=3021.5, sample_size_v1=0, sample_size_v2=0, ppl=2.27, wps=1064.4, ups=0.35, wpb=3021.5, bsz=96, num_updates=3730, lr=1.47515e-05, gnorm=1.456, clip=100, loss_scale=128, train_wall=28, gb_free=12.1, wall=10725
2023-04-19 03:25:45 - progress_bar.py[line:272] - INFO: epoch 007:    278 / 578 loss=2.374, loss_v1=0, loss_v2=0, nll_loss=1.174, ntokens=3198.1, nsentences=96, sample_size=3198.1, sample_size_v1=0, sample_size_v2=0, ppl=2.26, wps=1124.9, ups=0.35, wpb=3198.1, bsz=96, num_updates=3740, lr=1.47055e-05, gnorm=1.47, clip=100, loss_scale=128, train_wall=28, gb_free=12.6, wall=10754
2023-04-19 03:26:14 - progress_bar.py[line:272] - INFO: epoch 007:    288 / 578 loss=2.363, loss_v1=0, loss_v2=0, nll_loss=1.164, ntokens=3155.1, nsentences=96, sample_size=3155.1, sample_size_v1=0, sample_size_v2=0, ppl=2.24, wps=1108.4, ups=0.35, wpb=3155.1, bsz=96, num_updates=3750, lr=1.46595e-05, gnorm=1.38, clip=100, loss_scale=128, train_wall=28, gb_free=12.6, wall=10782
2023-04-19 03:26:42 - progress_bar.py[line:272] - INFO: epoch 007:    298 / 578 loss=2.401, loss_v1=0, loss_v2=0, nll_loss=1.203, ntokens=3051.9, nsentences=96, sample_size=3051.9, sample_size_v1=0, sample_size_v2=0, ppl=2.3, wps=1064.3, ups=0.35, wpb=3051.9, bsz=96, num_updates=3760, lr=1.46135e-05, gnorm=1.438, clip=100, loss_scale=128, train_wall=29, gb_free=12, wall=10811
2023-04-19 03:27:11 - progress_bar.py[line:272] - INFO: epoch 007:    308 / 578 loss=2.373, loss_v1=0, loss_v2=0, nll_loss=1.174, ntokens=3174.6, nsentences=96, sample_size=3174.6, sample_size_v1=0, sample_size_v2=0, ppl=2.26, wps=1109.8, ups=0.35, wpb=3174.6, bsz=96, num_updates=3770, lr=1.45675e-05, gnorm=1.386, clip=100, loss_scale=128, train_wall=29, gb_free=12, wall=10840
2023-04-19 03:27:39 - progress_bar.py[line:272] - INFO: epoch 007:    318 / 578 loss=2.379, loss_v1=0, loss_v2=0, nll_loss=1.18, ntokens=3296, nsentences=96, sample_size=3296, sample_size_v1=0, sample_size_v2=0, ppl=2.27, wps=1152.7, ups=0.35, wpb=3296, bsz=96, num_updates=3780, lr=1.45215e-05, gnorm=1.422, clip=100, loss_scale=128, train_wall=29, gb_free=12.2, wall=10868
2023-04-19 03:28:08 - progress_bar.py[line:272] - INFO: epoch 007:    328 / 578 loss=2.363, loss_v1=0, loss_v2=0, nll_loss=1.162, ntokens=3088, nsentences=96, sample_size=3088, sample_size_v1=0, sample_size_v2=0, ppl=2.24, wps=1083.2, ups=0.35, wpb=3088, bsz=96, num_updates=3790, lr=1.44755e-05, gnorm=1.402, clip=100, loss_scale=128, train_wall=28, gb_free=12.1, wall=10897
2023-04-19 03:28:36 - progress_bar.py[line:272] - INFO: epoch 007:    338 / 578 loss=2.377, loss_v1=0, loss_v2=0, nll_loss=1.179, ntokens=3124, nsentences=96, sample_size=3124, sample_size_v1=0, sample_size_v2=0, ppl=2.26, wps=1096.4, ups=0.35, wpb=3124, bsz=96, num_updates=3800, lr=1.44294e-05, gnorm=1.394, clip=100, loss_scale=128, train_wall=28, gb_free=12.2, wall=10925
2023-04-19 03:29:05 - progress_bar.py[line:272] - INFO: epoch 007:    348 / 578 loss=2.376, loss_v1=0, loss_v2=0, nll_loss=1.175, ntokens=3220.7, nsentences=96, sample_size=3220.7, sample_size_v1=0, sample_size_v2=0, ppl=2.26, wps=1136, ups=0.35, wpb=3220.7, bsz=96, num_updates=3810, lr=1.43834e-05, gnorm=1.384, clip=100, loss_scale=128, train_wall=28, gb_free=12.5, wall=10953
2023-04-19 03:29:33 - progress_bar.py[line:272] - INFO: epoch 007:    358 / 578 loss=2.365, loss_v1=0, loss_v2=0, nll_loss=1.166, ntokens=3066.9, nsentences=96, sample_size=3066.9, sample_size_v1=0, sample_size_v2=0, ppl=2.24, wps=1077.4, ups=0.35, wpb=3066.9, bsz=96, num_updates=3820, lr=1.43374e-05, gnorm=1.396, clip=100, loss_scale=128, train_wall=28, gb_free=12.6, wall=10982
2023-04-19 03:30:02 - progress_bar.py[line:272] - INFO: epoch 007:    368 / 578 loss=2.393, loss_v1=0, loss_v2=0, nll_loss=1.195, ntokens=3435.7, nsentences=96, sample_size=3435.7, sample_size_v1=0, sample_size_v2=0, ppl=2.29, wps=1201.2, ups=0.35, wpb=3435.7, bsz=96, num_updates=3830, lr=1.42914e-05, gnorm=1.322, clip=100, loss_scale=128, train_wall=29, gb_free=12.1, wall=11011
2023-04-19 03:30:31 - progress_bar.py[line:272] - INFO: epoch 007:    378 / 578 loss=2.374, loss_v1=0, loss_v2=0, nll_loss=1.175, ntokens=3343.6, nsentences=96, sample_size=3343.6, sample_size_v1=0, sample_size_v2=0, ppl=2.26, wps=1164.7, ups=0.35, wpb=3343.6, bsz=96, num_updates=3840, lr=1.42454e-05, gnorm=1.363, clip=100, loss_scale=128, train_wall=29, gb_free=11.8, wall=11039
2023-04-19 03:30:59 - progress_bar.py[line:272] - INFO: epoch 007:    388 / 578 loss=2.381, loss_v1=0, loss_v2=0, nll_loss=1.181, ntokens=3226.2, nsentences=96, sample_size=3226.2, sample_size_v1=0, sample_size_v2=0, ppl=2.27, wps=1133.4, ups=0.35, wpb=3226.2, bsz=96, num_updates=3850, lr=1.41994e-05, gnorm=1.355, clip=100, loss_scale=128, train_wall=28, gb_free=11.8, wall=11068
2023-04-19 03:31:28 - progress_bar.py[line:272] - INFO: epoch 007:    398 / 578 loss=2.35, loss_v1=0, loss_v2=0, nll_loss=1.151, ntokens=3161.7, nsentences=96, sample_size=3161.7, sample_size_v1=0, sample_size_v2=0, ppl=2.22, wps=1105.6, ups=0.35, wpb=3161.7, bsz=96, num_updates=3860, lr=1.41534e-05, gnorm=1.344, clip=100, loss_scale=128, train_wall=29, gb_free=12.3, wall=11096
2023-04-19 03:31:56 - progress_bar.py[line:272] - INFO: epoch 007:    408 / 578 loss=2.374, loss_v1=0, loss_v2=0, nll_loss=1.173, ntokens=2979.2, nsentences=96, sample_size=2979.2, sample_size_v1=0, sample_size_v2=0, ppl=2.26, wps=1047.4, ups=0.35, wpb=2979.2, bsz=96, num_updates=3870, lr=1.41074e-05, gnorm=1.497, clip=100, loss_scale=128, train_wall=28, gb_free=12.5, wall=11125
2023-04-19 03:32:25 - progress_bar.py[line:272] - INFO: epoch 007:    418 / 578 loss=2.378, loss_v1=0, loss_v2=0, nll_loss=1.178, ntokens=3028.2, nsentences=96, sample_size=3028.2, sample_size_v1=0, sample_size_v2=0, ppl=2.26, wps=1059.4, ups=0.35, wpb=3028.2, bsz=96, num_updates=3880, lr=1.40613e-05, gnorm=1.389, clip=100, loss_scale=128, train_wall=29, gb_free=12.4, wall=11153
2023-04-19 03:32:53 - progress_bar.py[line:272] - INFO: epoch 007:    428 / 578 loss=2.356, loss_v1=0, loss_v2=0, nll_loss=1.155, ntokens=3055.1, nsentences=96, sample_size=3055.1, sample_size_v1=0, sample_size_v2=0, ppl=2.23, wps=1075.3, ups=0.35, wpb=3055.1, bsz=96, num_updates=3890, lr=1.40153e-05, gnorm=1.445, clip=100, loss_scale=128, train_wall=28, gb_free=12.2, wall=11182
2023-04-19 03:33:21 - progress_bar.py[line:272] - INFO: epoch 007:    438 / 578 loss=2.395, loss_v1=0, loss_v2=0, nll_loss=1.197, ntokens=2939.4, nsentences=96, sample_size=2939.4, sample_size_v1=0, sample_size_v2=0, ppl=2.29, wps=1037.7, ups=0.35, wpb=2939.4, bsz=96, num_updates=3900, lr=1.39693e-05, gnorm=1.507, clip=100, loss_scale=128, train_wall=28, gb_free=12.3, wall=11210
2023-04-19 03:33:50 - progress_bar.py[line:272] - INFO: epoch 007:    448 / 578 loss=2.378, loss_v1=0, loss_v2=0, nll_loss=1.179, ntokens=3043.7, nsentences=96, sample_size=3043.7, sample_size_v1=0, sample_size_v2=0, ppl=2.26, wps=1065.9, ups=0.35, wpb=3043.7, bsz=96, num_updates=3910, lr=1.39233e-05, gnorm=1.457, clip=100, loss_scale=128, train_wall=29, gb_free=12.3, wall=11239
2023-04-19 03:34:18 - progress_bar.py[line:272] - INFO: epoch 007:    458 / 578 loss=2.363, loss_v1=0, loss_v2=0, nll_loss=1.163, ntokens=3029.9, nsentences=96, sample_size=3029.9, sample_size_v1=0, sample_size_v2=0, ppl=2.24, wps=1065.9, ups=0.35, wpb=3029.9, bsz=96, num_updates=3920, lr=1.38773e-05, gnorm=1.429, clip=100, loss_scale=128, train_wall=28, gb_free=12.2, wall=11267
2023-04-19 03:34:47 - progress_bar.py[line:272] - INFO: epoch 007:    468 / 578 loss=2.376, loss_v1=0, loss_v2=0, nll_loss=1.177, ntokens=3093.3, nsentences=96, sample_size=3093.3, sample_size_v1=0, sample_size_v2=0, ppl=2.26, wps=1085.7, ups=0.35, wpb=3093.3, bsz=96, num_updates=3930, lr=1.38313e-05, gnorm=1.417, clip=100, loss_scale=128, train_wall=28, gb_free=12.5, wall=11296
2023-04-19 03:35:15 - progress_bar.py[line:272] - INFO: epoch 007:    478 / 578 loss=2.389, loss_v1=0, loss_v2=0, nll_loss=1.191, ntokens=2898.6, nsentences=96, sample_size=2898.6, sample_size_v1=0, sample_size_v2=0, ppl=2.28, wps=1019.8, ups=0.35, wpb=2898.6, bsz=96, num_updates=3940, lr=1.37853e-05, gnorm=1.455, clip=100, loss_scale=128, train_wall=28, gb_free=12.4, wall=11324
2023-04-19 03:35:44 - progress_bar.py[line:272] - INFO: epoch 007:    488 / 578 loss=2.353, loss_v1=0, loss_v2=0, nll_loss=1.154, ntokens=2994.8, nsentences=96, sample_size=2994.8, sample_size_v1=0, sample_size_v2=0, ppl=2.23, wps=1055.8, ups=0.35, wpb=2994.8, bsz=96, num_updates=3950, lr=1.37393e-05, gnorm=1.458, clip=100, loss_scale=128, train_wall=28, gb_free=12.1, wall=11352
2023-04-19 03:36:12 - progress_bar.py[line:272] - INFO: epoch 007:    498 / 578 loss=2.343, loss_v1=0, loss_v2=0, nll_loss=1.136, ntokens=3213.1, nsentences=96, sample_size=3213.1, sample_size_v1=0, sample_size_v2=0, ppl=2.2, wps=1125.4, ups=0.35, wpb=3213.1, bsz=96, num_updates=3960, lr=1.36933e-05, gnorm=1.395, clip=100, loss_scale=128, train_wall=29, gb_free=12.1, wall=11381
2023-04-19 03:36:41 - progress_bar.py[line:272] - INFO: epoch 007:    508 / 578 loss=2.36, loss_v1=0, loss_v2=0, nll_loss=1.163, ntokens=3146.9, nsentences=96, sample_size=3146.9, sample_size_v1=0, sample_size_v2=0, ppl=2.24, wps=1101.9, ups=0.35, wpb=3146.9, bsz=96, num_updates=3970, lr=1.36472e-05, gnorm=1.423, clip=100, loss_scale=128, train_wall=29, gb_free=12.6, wall=11409
2023-04-19 03:37:09 - progress_bar.py[line:272] - INFO: epoch 007:    518 / 578 loss=2.345, loss_v1=0, loss_v2=0, nll_loss=1.139, ntokens=3278.5, nsentences=96, sample_size=3278.5, sample_size_v1=0, sample_size_v2=0, ppl=2.2, wps=1146.9, ups=0.35, wpb=3278.5, bsz=96, num_updates=3980, lr=1.36012e-05, gnorm=1.479, clip=100, loss_scale=128, train_wall=29, gb_free=12.4, wall=11438
2023-04-19 03:37:38 - progress_bar.py[line:272] - INFO: epoch 007:    528 / 578 loss=2.368, loss_v1=0, loss_v2=0, nll_loss=1.17, ntokens=3060.3, nsentences=96, sample_size=3060.3, sample_size_v1=0, sample_size_v2=0, ppl=2.25, wps=1078.9, ups=0.35, wpb=3060.3, bsz=96, num_updates=3990, lr=1.35552e-05, gnorm=1.551, clip=100, loss_scale=128, train_wall=28, gb_free=12.3, wall=11466
2023-04-19 03:38:06 - progress_bar.py[line:272] - INFO: epoch 007:    538 / 578 loss=2.357, loss_v1=0, loss_v2=0, nll_loss=1.154, ntokens=3004.3, nsentences=96, sample_size=3004.3, sample_size_v1=0, sample_size_v2=0, ppl=2.23, wps=1058.9, ups=0.35, wpb=3004.3, bsz=96, num_updates=4000, lr=1.35092e-05, gnorm=1.519, clip=100, loss_scale=256, train_wall=28, gb_free=12.4, wall=11495
2023-04-19 03:38:35 - progress_bar.py[line:272] - INFO: epoch 007:    548 / 578 loss=2.351, loss_v1=0, loss_v2=0, nll_loss=1.148, ntokens=3171.8, nsentences=96, sample_size=3171.8, sample_size_v1=0, sample_size_v2=0, ppl=2.22, wps=1103.8, ups=0.35, wpb=3171.8, bsz=96, num_updates=4010, lr=1.34632e-05, gnorm=1.479, clip=100, loss_scale=256, train_wall=29, gb_free=11.4, wall=11524
2023-04-19 03:39:04 - progress_bar.py[line:272] - INFO: epoch 007:    558 / 578 loss=2.349, loss_v1=0, loss_v2=0, nll_loss=1.147, ntokens=3243.3, nsentences=96, sample_size=3243.3, sample_size_v1=0, sample_size_v2=0, ppl=2.21, wps=1118.3, ups=0.34, wpb=3243.3, bsz=96, num_updates=4020, lr=1.34172e-05, gnorm=1.314, clip=100, loss_scale=256, train_wall=29, gb_free=12.6, wall=11553
2023-04-19 03:39:33 - progress_bar.py[line:272] - INFO: epoch 007:    568 / 578 loss=2.349, loss_v1=0, loss_v2=0, nll_loss=1.146, ntokens=3281.5, nsentences=96, sample_size=3281.5, sample_size_v1=0, sample_size_v2=0, ppl=2.21, wps=1143.9, ups=0.35, wpb=3281.5, bsz=96, num_updates=4030, lr=1.33712e-05, gnorm=1.365, clip=100, loss_scale=256, train_wall=29, gb_free=12.6, wall=11581
local datafile ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 1 begin to initialize row_count and line_idx-to-offset mapping
2023-04-19 03:39:59 - progress_bar.py[line:272] - INFO: epoch 007:    578 / 578 loss=2.371, loss_v1=0, loss_v2=0, nll_loss=1.173, ntokens=2815.7, nsentences=87.6, sample_size=2815.7, sample_size_v1=0, sample_size_v2=0, ppl=2.25, wps=1078.8, ups=0.38, wpb=2815.7, bsz=87.6, num_updates=4040, lr=1.33252e-05, gnorm=1.673, clip=100, loss_scale=256, train_wall=26, gb_free=13.1, wall=11607
2023-04-19 03:39:59 - checkpoint_utils.py[line:64] - INFO: Preparing to save checkpoint for epoch 7 @ 4040 updates
2023-04-19 03:39:59 - trainer.py[line:431] - INFO: Saving checkpoint to ../../checkpoints/OFA/sgcls_checkpoints/_12_3e-5_512/checkpoint7.pt
local datafile ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 1 finished initializing row_count and line_idx-to-offset mapping
file ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 1 row count 27700 total row count 55400
slice_id 1 seek offset 27700
2023-04-19 03:40:02 - trainer.py[line:441] - INFO: Finished saving checkpoint to ../../checkpoints/OFA/sgcls_checkpoints/_12_3e-5_512/checkpoint7.pt
2023-04-19 03:40:04 - checkpoint_utils.py[line:133] - INFO: Saved checkpoint ../../checkpoints/OFA/sgcls_checkpoints/_12_3e-5_512/checkpoint7.pt (epoch 7 @ 4040 updates, score None) (writing took 5.600817329250276 seconds)
2023-04-19 03:40:04 - train.py[line:332] - INFO: end of epoch 7 (average epoch stats below)
2023-04-19 03:40:04 - progress_bar.py[line:282] - INFO: epoch 007 | loss 2.358 | loss_v1 0 | loss_v2 0 | nll_loss 1.156 | ntokens 3150.62 | nsentences 95.847 | sample_size 3150.62 | sample_size_v1 0 | sample_size_v2 0 | ppl 2.23 | wps 1097.4 | ups 0.35 | wpb 3150.6 | bsz 95.8 | num_updates 4040 | lr 1.33252e-05 | gnorm 1.389 | clip 99.5 | loss_scale 256 | train_wall 1647 | gb_free 13.1 | wall 11613
2023-04-19 03:40:04 - trainer.py[line:639] - INFO: loading train data for epoch 8
local datafile ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 0 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 0 finished initializing row_count and line_idx-to-offset mapping
file ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 0 row count 27700 total row count 55400
slice_id 0 seek offset 0
2023-04-19 03:40:06 - trainer.py[line:703] - INFO: begin training epoch 8
2023-04-19 03:40:06 - train.py[line:305] - INFO: Start iterating over samples
2023-04-19 03:40:32 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 128.0
2023-04-19 03:40:38 - progress_bar.py[line:272] - INFO: epoch 008:     11 / 578 loss=2.307, loss_v1=0, loss_v2=0, nll_loss=1.099, ntokens=3138.3, nsentences=96, sample_size=3138.3, sample_size_v1=0, sample_size_v2=0, ppl=2.14, wps=798.8, ups=0.25, wpb=3138.3, bsz=96, num_updates=4050, lr=1.32791e-05, gnorm=1.46, clip=100, loss_scale=128, train_wall=31, gb_free=12.1, wall=11647
2023-04-19 03:41:06 - progress_bar.py[line:272] - INFO: epoch 008:     21 / 578 loss=2.301, loss_v1=0, loss_v2=0, nll_loss=1.094, ntokens=3033.4, nsentences=95.6, sample_size=3033.4, sample_size_v1=0, sample_size_v2=0, ppl=2.13, wps=1072.7, ups=0.35, wpb=3033.4, bsz=95.6, num_updates=4060, lr=1.32331e-05, gnorm=1.511, clip=100, loss_scale=128, train_wall=28, gb_free=11.9, wall=11675
2023-04-19 03:41:35 - progress_bar.py[line:272] - INFO: epoch 008:     31 / 578 loss=2.271, loss_v1=0, loss_v2=0, nll_loss=1.06, ntokens=3136.1, nsentences=96, sample_size=3136.1, sample_size_v1=0, sample_size_v2=0, ppl=2.09, wps=1094.3, ups=0.35, wpb=3136.1, bsz=96, num_updates=4070, lr=1.31871e-05, gnorm=1.451, clip=100, loss_scale=128, train_wall=29, gb_free=12.3, wall=11704
2023-04-19 03:42:04 - progress_bar.py[line:272] - INFO: epoch 008:     41 / 578 loss=2.212, loss_v1=0, loss_v2=0, nll_loss=0.992, ntokens=3235.3, nsentences=96, sample_size=3235.3, sample_size_v1=0, sample_size_v2=0, ppl=1.99, wps=1125.9, ups=0.35, wpb=3235.3, bsz=96, num_updates=4080, lr=1.31411e-05, gnorm=1.419, clip=90, loss_scale=128, train_wall=29, gb_free=11.4, wall=11732
2023-04-19 03:42:33 - progress_bar.py[line:272] - INFO: epoch 008:     51 / 578 loss=2.218, loss_v1=0, loss_v2=0, nll_loss=1.002, ntokens=3587, nsentences=96, sample_size=3587, sample_size_v1=0, sample_size_v2=0, ppl=2, wps=1222.7, ups=0.34, wpb=3587, bsz=96, num_updates=4090, lr=1.30951e-05, gnorm=1.273, clip=100, loss_scale=128, train_wall=29, gb_free=11.4, wall=11762
2023-04-19 03:43:02 - progress_bar.py[line:272] - INFO: epoch 008:     61 / 578 loss=2.291, loss_v1=0, loss_v2=0, nll_loss=1.08, ntokens=3229.4, nsentences=96, sample_size=3229.4, sample_size_v1=0, sample_size_v2=0, ppl=2.11, wps=1121.4, ups=0.35, wpb=3229.4, bsz=96, num_updates=4100, lr=1.30491e-05, gnorm=1.472, clip=100, loss_scale=128, train_wall=29, gb_free=12.3, wall=11790
2023-04-19 03:43:30 - progress_bar.py[line:272] - INFO: epoch 008:     71 / 578 loss=2.317, loss_v1=0, loss_v2=0, nll_loss=1.112, ntokens=3064.1, nsentences=96, sample_size=3064.1, sample_size_v1=0, sample_size_v2=0, ppl=2.16, wps=1074.8, ups=0.35, wpb=3064.1, bsz=96, num_updates=4110, lr=1.30031e-05, gnorm=1.605, clip=100, loss_scale=128, train_wall=28, gb_free=11.6, wall=11819
2023-04-19 03:43:59 - progress_bar.py[line:272] - INFO: epoch 008:     81 / 578 loss=2.357, loss_v1=0, loss_v2=0, nll_loss=1.155, ntokens=3199.2, nsentences=96, sample_size=3199.2, sample_size_v1=0, sample_size_v2=0, ppl=2.23, wps=1114.7, ups=0.35, wpb=3199.2, bsz=96, num_updates=4120, lr=1.29571e-05, gnorm=1.467, clip=100, loss_scale=128, train_wall=29, gb_free=12, wall=11848
2023-04-19 03:44:28 - progress_bar.py[line:272] - INFO: epoch 008:     91 / 578 loss=2.32, loss_v1=0, loss_v2=0, nll_loss=1.113, ntokens=3356.4, nsentences=96, sample_size=3356.4, sample_size_v1=0, sample_size_v2=0, ppl=2.16, wps=1163.1, ups=0.35, wpb=3356.4, bsz=96, num_updates=4130, lr=1.2911e-05, gnorm=1.418, clip=100, loss_scale=128, train_wall=29, gb_free=11.6, wall=11877
2023-04-19 03:44:57 - progress_bar.py[line:272] - INFO: epoch 008:    101 / 578 loss=2.302, loss_v1=0, loss_v2=0, nll_loss=1.096, ntokens=3318.9, nsentences=96, sample_size=3318.9, sample_size_v1=0, sample_size_v2=0, ppl=2.14, wps=1140.8, ups=0.34, wpb=3318.9, bsz=96, num_updates=4140, lr=1.2865e-05, gnorm=1.451, clip=100, loss_scale=128, train_wall=29, gb_free=11.2, wall=11906
2023-04-19 03:45:26 - progress_bar.py[line:272] - INFO: epoch 008:    111 / 578 loss=2.319, loss_v1=0, loss_v2=0, nll_loss=1.113, ntokens=3258.2, nsentences=96, sample_size=3258.2, sample_size_v1=0, sample_size_v2=0, ppl=2.16, wps=1130.9, ups=0.35, wpb=3258.2, bsz=96, num_updates=4150, lr=1.2819e-05, gnorm=1.498, clip=100, loss_scale=128, train_wall=29, gb_free=11.6, wall=11934
2023-04-19 03:45:55 - progress_bar.py[line:272] - INFO: epoch 008:    121 / 578 loss=2.304, loss_v1=0, loss_v2=0, nll_loss=1.096, ntokens=3153.5, nsentences=96, sample_size=3153.5, sample_size_v1=0, sample_size_v2=0, ppl=2.14, wps=1098.7, ups=0.35, wpb=3153.5, bsz=96, num_updates=4160, lr=1.2773e-05, gnorm=1.439, clip=100, loss_scale=128, train_wall=29, gb_free=12, wall=11963
2023-04-19 03:46:23 - progress_bar.py[line:272] - INFO: epoch 008:    131 / 578 loss=2.313, loss_v1=0, loss_v2=0, nll_loss=1.107, ntokens=3290.7, nsentences=96, sample_size=3290.7, sample_size_v1=0, sample_size_v2=0, ppl=2.15, wps=1140.7, ups=0.35, wpb=3290.7, bsz=96, num_updates=4170, lr=1.2727e-05, gnorm=1.501, clip=100, loss_scale=128, train_wall=29, gb_free=12, wall=11992
2023-04-19 03:46:52 - progress_bar.py[line:272] - INFO: epoch 008:    141 / 578 loss=2.366, loss_v1=0, loss_v2=0, nll_loss=1.166, ntokens=3021.3, nsentences=96, sample_size=3021.3, sample_size_v1=0, sample_size_v2=0, ppl=2.24, wps=1061.3, ups=0.35, wpb=3021.3, bsz=96, num_updates=4180, lr=1.2681e-05, gnorm=1.493, clip=100, loss_scale=128, train_wall=28, gb_free=12, wall=12020
2023-04-19 03:47:20 - progress_bar.py[line:272] - INFO: epoch 008:    151 / 578 loss=2.363, loss_v1=0, loss_v2=0, nll_loss=1.163, ntokens=3292.4, nsentences=96, sample_size=3292.4, sample_size_v1=0, sample_size_v2=0, ppl=2.24, wps=1152.6, ups=0.35, wpb=3292.4, bsz=96, num_updates=4190, lr=1.2635e-05, gnorm=1.466, clip=100, loss_scale=128, train_wall=29, gb_free=12.3, wall=12049
2023-04-19 03:47:49 - progress_bar.py[line:272] - INFO: epoch 008:    161 / 578 loss=2.382, loss_v1=0, loss_v2=0, nll_loss=1.182, ntokens=3248, nsentences=96, sample_size=3248, sample_size_v1=0, sample_size_v2=0, ppl=2.27, wps=1143, ups=0.35, wpb=3248, bsz=96, num_updates=4200, lr=1.2589e-05, gnorm=1.323, clip=100, loss_scale=128, train_wall=28, gb_free=11.9, wall=12077
2023-04-19 03:48:17 - progress_bar.py[line:272] - INFO: epoch 008:    171 / 578 loss=2.379, loss_v1=0, loss_v2=0, nll_loss=1.18, ntokens=3175.8, nsentences=96, sample_size=3175.8, sample_size_v1=0, sample_size_v2=0, ppl=2.27, wps=1118, ups=0.35, wpb=3175.8, bsz=96, num_updates=4210, lr=1.25429e-05, gnorm=1.508, clip=100, loss_scale=128, train_wall=28, gb_free=12.3, wall=12106
2023-04-19 03:48:46 - progress_bar.py[line:272] - INFO: epoch 008:    181 / 578 loss=2.37, loss_v1=0, loss_v2=0, nll_loss=1.169, ntokens=3231.9, nsentences=96, sample_size=3231.9, sample_size_v1=0, sample_size_v2=0, ppl=2.25, wps=1133.6, ups=0.35, wpb=3231.9, bsz=96, num_updates=4220, lr=1.24969e-05, gnorm=1.42, clip=100, loss_scale=128, train_wall=28, gb_free=12.1, wall=12134
2023-04-19 03:49:14 - progress_bar.py[line:272] - INFO: epoch 008:    191 / 578 loss=2.372, loss_v1=0, loss_v2=0, nll_loss=1.174, ntokens=3253.3, nsentences=96, sample_size=3253.3, sample_size_v1=0, sample_size_v2=0, ppl=2.26, wps=1141.2, ups=0.35, wpb=3253.3, bsz=96, num_updates=4230, lr=1.24509e-05, gnorm=1.395, clip=100, loss_scale=128, train_wall=28, gb_free=11.5, wall=12163
2023-04-19 03:49:43 - progress_bar.py[line:272] - INFO: epoch 008:    201 / 578 loss=2.362, loss_v1=0, loss_v2=0, nll_loss=1.161, ntokens=3182.1, nsentences=96, sample_size=3182.1, sample_size_v1=0, sample_size_v2=0, ppl=2.24, wps=1121.3, ups=0.35, wpb=3182.1, bsz=96, num_updates=4240, lr=1.24049e-05, gnorm=1.475, clip=100, loss_scale=128, train_wall=28, gb_free=12.3, wall=12191
2023-04-19 03:50:11 - progress_bar.py[line:272] - INFO: epoch 008:    211 / 578 loss=2.351, loss_v1=0, loss_v2=0, nll_loss=1.149, ntokens=3118.6, nsentences=96, sample_size=3118.6, sample_size_v1=0, sample_size_v2=0, ppl=2.22, wps=1097.7, ups=0.35, wpb=3118.6, bsz=96, num_updates=4250, lr=1.23589e-05, gnorm=1.42, clip=100, loss_scale=128, train_wall=28, gb_free=11.9, wall=12220
2023-04-19 03:50:40 - progress_bar.py[line:272] - INFO: epoch 008:    221 / 578 loss=2.382, loss_v1=0, loss_v2=0, nll_loss=1.184, ntokens=3110.8, nsentences=96, sample_size=3110.8, sample_size_v1=0, sample_size_v2=0, ppl=2.27, wps=1094, ups=0.35, wpb=3110.8, bsz=96, num_updates=4260, lr=1.23129e-05, gnorm=1.522, clip=100, loss_scale=128, train_wall=28, gb_free=11.9, wall=12248
2023-04-19 03:51:08 - progress_bar.py[line:272] - INFO: epoch 008:    231 / 578 loss=2.345, loss_v1=0, loss_v2=0, nll_loss=1.142, ntokens=2994.4, nsentences=96, sample_size=2994.4, sample_size_v1=0, sample_size_v2=0, ppl=2.21, wps=1049.8, ups=0.35, wpb=2994.4, bsz=96, num_updates=4270, lr=1.22669e-05, gnorm=1.561, clip=100, loss_scale=128, train_wall=28, gb_free=12.3, wall=12277
2023-04-19 03:51:36 - progress_bar.py[line:272] - INFO: epoch 008:    241 / 578 loss=2.387, loss_v1=0, loss_v2=0, nll_loss=1.189, ntokens=2963.7, nsentences=96, sample_size=2963.7, sample_size_v1=0, sample_size_v2=0, ppl=2.28, wps=1048.1, ups=0.35, wpb=2963.7, bsz=96, num_updates=4280, lr=1.22209e-05, gnorm=1.563, clip=100, loss_scale=128, train_wall=28, gb_free=12.3, wall=12305
2023-04-19 03:52:05 - progress_bar.py[line:272] - INFO: epoch 008:    251 / 578 loss=2.359, loss_v1=0, loss_v2=0, nll_loss=1.157, ntokens=3107.1, nsentences=96, sample_size=3107.1, sample_size_v1=0, sample_size_v2=0, ppl=2.23, wps=1096.4, ups=0.35, wpb=3107.1, bsz=96, num_updates=4290, lr=1.21748e-05, gnorm=1.438, clip=100, loss_scale=128, train_wall=28, gb_free=12.3, wall=12333
2023-04-19 03:52:33 - progress_bar.py[line:272] - INFO: epoch 008:    261 / 578 loss=2.354, loss_v1=0, loss_v2=0, nll_loss=1.153, ntokens=3139, nsentences=96, sample_size=3139, sample_size_v1=0, sample_size_v2=0, ppl=2.22, wps=1102.7, ups=0.35, wpb=3139, bsz=96, num_updates=4300, lr=1.21288e-05, gnorm=1.438, clip=100, loss_scale=128, train_wall=28, gb_free=12.5, wall=12362
2023-04-19 03:53:02 - progress_bar.py[line:272] - INFO: epoch 008:    271 / 578 loss=2.372, loss_v1=0, loss_v2=0, nll_loss=1.172, ntokens=3108.5, nsentences=96, sample_size=3108.5, sample_size_v1=0, sample_size_v2=0, ppl=2.25, wps=1095.4, ups=0.35, wpb=3108.5, bsz=96, num_updates=4310, lr=1.20828e-05, gnorm=1.504, clip=100, loss_scale=128, train_wall=28, gb_free=12.2, wall=12390
2023-04-19 03:53:30 - progress_bar.py[line:272] - INFO: epoch 008:    281 / 578 loss=2.352, loss_v1=0, loss_v2=0, nll_loss=1.15, ntokens=3176.3, nsentences=96, sample_size=3176.3, sample_size_v1=0, sample_size_v2=0, ppl=2.22, wps=1116.7, ups=0.35, wpb=3176.3, bsz=96, num_updates=4320, lr=1.20368e-05, gnorm=1.484, clip=100, loss_scale=128, train_wall=28, gb_free=12, wall=12419
2023-04-19 03:53:59 - progress_bar.py[line:272] - INFO: epoch 008:    291 / 578 loss=2.362, loss_v1=0, loss_v2=0, nll_loss=1.162, ntokens=3172.6, nsentences=96, sample_size=3172.6, sample_size_v1=0, sample_size_v2=0, ppl=2.24, wps=1112.4, ups=0.35, wpb=3172.6, bsz=96, num_updates=4330, lr=1.19908e-05, gnorm=1.526, clip=100, loss_scale=128, train_wall=28, gb_free=12.1, wall=12447
2023-04-19 03:54:27 - progress_bar.py[line:272] - INFO: epoch 008:    301 / 578 loss=2.374, loss_v1=0, loss_v2=0, nll_loss=1.173, ntokens=2987.4, nsentences=96, sample_size=2987.4, sample_size_v1=0, sample_size_v2=0, ppl=2.25, wps=1042.8, ups=0.35, wpb=2987.4, bsz=96, num_updates=4340, lr=1.19448e-05, gnorm=1.558, clip=100, loss_scale=128, train_wall=29, gb_free=12, wall=12476
2023-04-19 03:54:56 - progress_bar.py[line:272] - INFO: epoch 008:    311 / 578 loss=2.362, loss_v1=0, loss_v2=0, nll_loss=1.161, ntokens=3236.3, nsentences=96, sample_size=3236.3, sample_size_v1=0, sample_size_v2=0, ppl=2.24, wps=1132.8, ups=0.35, wpb=3236.3, bsz=96, num_updates=4350, lr=1.18988e-05, gnorm=1.45, clip=100, loss_scale=128, train_wall=29, gb_free=12.1, wall=12504
2023-04-19 03:55:24 - progress_bar.py[line:272] - INFO: epoch 008:    321 / 578 loss=2.367, loss_v1=0, loss_v2=0, nll_loss=1.167, ntokens=3266.5, nsentences=96, sample_size=3266.5, sample_size_v1=0, sample_size_v2=0, ppl=2.25, wps=1142, ups=0.35, wpb=3266.5, bsz=96, num_updates=4360, lr=1.18528e-05, gnorm=1.539, clip=100, loss_scale=128, train_wall=29, gb_free=12.7, wall=12533
2023-04-19 03:55:53 - progress_bar.py[line:272] - INFO: epoch 008:    331 / 578 loss=2.344, loss_v1=0, loss_v2=0, nll_loss=1.141, ntokens=3078, nsentences=96, sample_size=3078, sample_size_v1=0, sample_size_v2=0, ppl=2.21, wps=1077.7, ups=0.35, wpb=3078, bsz=96, num_updates=4370, lr=1.18067e-05, gnorm=1.481, clip=100, loss_scale=128, train_wall=29, gb_free=12, wall=12562
2023-04-19 03:56:21 - progress_bar.py[line:272] - INFO: epoch 008:    341 / 578 loss=2.377, loss_v1=0, loss_v2=0, nll_loss=1.179, ntokens=3196.3, nsentences=96, sample_size=3196.3, sample_size_v1=0, sample_size_v2=0, ppl=2.26, wps=1124.7, ups=0.35, wpb=3196.3, bsz=96, num_updates=4380, lr=1.17607e-05, gnorm=1.536, clip=100, loss_scale=128, train_wall=28, gb_free=12.8, wall=12590
2023-04-19 03:56:50 - progress_bar.py[line:272] - INFO: epoch 008:    351 / 578 loss=2.354, loss_v1=0, loss_v2=0, nll_loss=1.151, ntokens=3114, nsentences=96, sample_size=3114, sample_size_v1=0, sample_size_v2=0, ppl=2.22, wps=1095.9, ups=0.35, wpb=3114, bsz=96, num_updates=4390, lr=1.17147e-05, gnorm=1.544, clip=100, loss_scale=128, train_wall=28, gb_free=12.5, wall=12618
2023-04-19 03:57:18 - progress_bar.py[line:272] - INFO: epoch 008:    361 / 578 loss=2.35, loss_v1=0, loss_v2=0, nll_loss=1.149, ntokens=3193, nsentences=96, sample_size=3193, sample_size_v1=0, sample_size_v2=0, ppl=2.22, wps=1113.8, ups=0.35, wpb=3193, bsz=96, num_updates=4400, lr=1.16687e-05, gnorm=1.471, clip=100, loss_scale=128, train_wall=29, gb_free=11.9, wall=12647
2023-04-19 03:57:47 - progress_bar.py[line:272] - INFO: epoch 008:    371 / 578 loss=2.378, loss_v1=0, loss_v2=0, nll_loss=1.179, ntokens=3441, nsentences=96, sample_size=3441, sample_size_v1=0, sample_size_v2=0, ppl=2.26, wps=1194.6, ups=0.35, wpb=3441, bsz=96, num_updates=4410, lr=1.16227e-05, gnorm=1.474, clip=100, loss_scale=128, train_wall=29, gb_free=12.1, wall=12676
2023-04-19 03:58:16 - progress_bar.py[line:272] - INFO: epoch 008:    381 / 578 loss=2.36, loss_v1=0, loss_v2=0, nll_loss=1.159, ntokens=3327, nsentences=96, sample_size=3327, sample_size_v1=0, sample_size_v2=0, ppl=2.23, wps=1160.6, ups=0.35, wpb=3327, bsz=96, num_updates=4420, lr=1.15767e-05, gnorm=1.541, clip=100, loss_scale=128, train_wall=29, gb_free=12.4, wall=12705
2023-04-19 03:58:44 - progress_bar.py[line:272] - INFO: epoch 008:    391 / 578 loss=2.368, loss_v1=0, loss_v2=0, nll_loss=1.167, ntokens=3162.7, nsentences=96, sample_size=3162.7, sample_size_v1=0, sample_size_v2=0, ppl=2.25, wps=1107.6, ups=0.35, wpb=3162.7, bsz=96, num_updates=4430, lr=1.15307e-05, gnorm=1.6, clip=100, loss_scale=128, train_wall=29, gb_free=12.2, wall=12733
2023-04-19 03:59:13 - progress_bar.py[line:272] - INFO: epoch 008:    401 / 578 loss=2.33, loss_v1=0, loss_v2=0, nll_loss=1.127, ntokens=3159.4, nsentences=96, sample_size=3159.4, sample_size_v1=0, sample_size_v2=0, ppl=2.18, wps=1103.1, ups=0.35, wpb=3159.4, bsz=96, num_updates=4440, lr=1.14847e-05, gnorm=1.583, clip=100, loss_scale=128, train_wall=29, gb_free=12.4, wall=12762
2023-04-19 03:59:42 - progress_bar.py[line:272] - INFO: epoch 008:    411 / 578 loss=2.376, loss_v1=0, loss_v2=0, nll_loss=1.175, ntokens=2920.2, nsentences=96, sample_size=2920.2, sample_size_v1=0, sample_size_v2=0, ppl=2.26, wps=1025.1, ups=0.35, wpb=2920.2, bsz=96, num_updates=4450, lr=1.14387e-05, gnorm=1.742, clip=100, loss_scale=128, train_wall=28, gb_free=12.7, wall=12790
2023-04-19 04:00:10 - progress_bar.py[line:272] - INFO: epoch 008:    421 / 578 loss=2.357, loss_v1=0, loss_v2=0, nll_loss=1.155, ntokens=3063.8, nsentences=96, sample_size=3063.8, sample_size_v1=0, sample_size_v2=0, ppl=2.23, wps=1074.9, ups=0.35, wpb=3063.8, bsz=96, num_updates=4460, lr=1.13926e-05, gnorm=1.6, clip=100, loss_scale=128, train_wall=28, gb_free=12.2, wall=12819
2023-04-19 04:00:39 - progress_bar.py[line:272] - INFO: epoch 008:    431 / 578 loss=2.348, loss_v1=0, loss_v2=0, nll_loss=1.146, ntokens=3100.3, nsentences=96, sample_size=3100.3, sample_size_v1=0, sample_size_v2=0, ppl=2.21, wps=1091.4, ups=0.35, wpb=3100.3, bsz=96, num_updates=4470, lr=1.13466e-05, gnorm=1.553, clip=100, loss_scale=128, train_wall=28, gb_free=12.6, wall=12847
2023-04-19 04:01:07 - progress_bar.py[line:272] - INFO: epoch 008:    441 / 578 loss=2.382, loss_v1=0, loss_v2=0, nll_loss=1.182, ntokens=2919.3, nsentences=96, sample_size=2919.3, sample_size_v1=0, sample_size_v2=0, ppl=2.27, wps=1031.5, ups=0.35, wpb=2919.3, bsz=96, num_updates=4480, lr=1.13006e-05, gnorm=1.762, clip=100, loss_scale=128, train_wall=28, gb_free=12.4, wall=12875
2023-04-19 04:01:35 - progress_bar.py[line:272] - INFO: epoch 008:    451 / 578 loss=2.356, loss_v1=0, loss_v2=0, nll_loss=1.155, ntokens=3056.6, nsentences=96, sample_size=3056.6, sample_size_v1=0, sample_size_v2=0, ppl=2.23, wps=1069.8, ups=0.35, wpb=3056.6, bsz=96, num_updates=4490, lr=1.12546e-05, gnorm=1.543, clip=100, loss_scale=128, train_wall=29, gb_free=12.1, wall=12904
2023-04-19 04:02:04 - progress_bar.py[line:272] - INFO: epoch 008:    461 / 578 loss=2.349, loss_v1=0, loss_v2=0, nll_loss=1.149, ntokens=3024.6, nsentences=96, sample_size=3024.6, sample_size_v1=0, sample_size_v2=0, ppl=2.22, wps=1065.5, ups=0.35, wpb=3024.6, bsz=96, num_updates=4500, lr=1.12086e-05, gnorm=1.514, clip=100, loss_scale=128, train_wall=28, gb_free=12.5, wall=12932
2023-04-19 04:02:32 - progress_bar.py[line:272] - INFO: epoch 008:    471 / 578 loss=2.369, loss_v1=0, loss_v2=0, nll_loss=1.168, ntokens=3056.1, nsentences=96, sample_size=3056.1, sample_size_v1=0, sample_size_v2=0, ppl=2.25, wps=1073.4, ups=0.35, wpb=3056.1, bsz=96, num_updates=4510, lr=1.11626e-05, gnorm=1.549, clip=100, loss_scale=128, train_wall=28, gb_free=12.7, wall=12961
2023-04-19 04:03:01 - progress_bar.py[line:272] - INFO: epoch 008:    481 / 578 loss=2.365, loss_v1=0, loss_v2=0, nll_loss=1.166, ntokens=2868.2, nsentences=96, sample_size=2868.2, sample_size_v1=0, sample_size_v2=0, ppl=2.24, wps=1009.1, ups=0.35, wpb=2868.2, bsz=96, num_updates=4520, lr=1.11166e-05, gnorm=1.683, clip=100, loss_scale=128, train_wall=28, gb_free=12.3, wall=12989
2023-04-19 04:03:29 - progress_bar.py[line:272] - INFO: epoch 008:    491 / 578 loss=2.335, loss_v1=0, loss_v2=0, nll_loss=1.134, ntokens=3115.1, nsentences=96, sample_size=3115.1, sample_size_v1=0, sample_size_v2=0, ppl=2.19, wps=1096.3, ups=0.35, wpb=3115.1, bsz=96, num_updates=4530, lr=1.10706e-05, gnorm=1.571, clip=100, loss_scale=128, train_wall=28, gb_free=12.3, wall=13018
2023-04-19 04:03:58 - progress_bar.py[line:272] - INFO: epoch 008:    501 / 578 loss=2.339, loss_v1=0, loss_v2=0, nll_loss=1.132, ntokens=3132.6, nsentences=96, sample_size=3132.6, sample_size_v1=0, sample_size_v2=0, ppl=2.19, wps=1096.9, ups=0.35, wpb=3132.6, bsz=96, num_updates=4540, lr=1.10245e-05, gnorm=1.553, clip=100, loss_scale=128, train_wall=29, gb_free=12, wall=13046
2023-04-19 04:04:26 - progress_bar.py[line:272] - INFO: epoch 008:    511 / 578 loss=2.334, loss_v1=0, loss_v2=0, nll_loss=1.133, ntokens=3160, nsentences=96, sample_size=3160, sample_size_v1=0, sample_size_v2=0, ppl=2.19, wps=1106.1, ups=0.35, wpb=3160, bsz=96, num_updates=4550, lr=1.09785e-05, gnorm=1.573, clip=100, loss_scale=128, train_wall=29, gb_free=12.5, wall=13075
2023-04-19 04:04:55 - progress_bar.py[line:272] - INFO: epoch 008:    521 / 578 loss=2.336, loss_v1=0, loss_v2=0, nll_loss=1.13, ntokens=3347.6, nsentences=96, sample_size=3347.6, sample_size_v1=0, sample_size_v2=0, ppl=2.19, wps=1172.6, ups=0.35, wpb=3347.6, bsz=96, num_updates=4560, lr=1.09325e-05, gnorm=1.63, clip=100, loss_scale=256, train_wall=29, gb_free=12.4, wall=13103
2023-04-19 04:05:20 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 128.0
2023-04-19 04:05:26 - progress_bar.py[line:272] - INFO: epoch 008:    532 / 578 loss=2.365, loss_v1=0, loss_v2=0, nll_loss=1.166, ntokens=2996.2, nsentences=96, sample_size=2996.2, sample_size_v1=0, sample_size_v2=0, ppl=2.24, wps=965.6, ups=0.32, wpb=2996.2, bsz=96, num_updates=4570, lr=1.08865e-05, gnorm=1.755, clip=100, loss_scale=128, train_wall=31, gb_free=12.5, wall=13134
2023-04-19 04:05:54 - progress_bar.py[line:272] - INFO: epoch 008:    542 / 578 loss=2.335, loss_v1=0, loss_v2=0, nll_loss=1.13, ntokens=3043.8, nsentences=96, sample_size=3043.8, sample_size_v1=0, sample_size_v2=0, ppl=2.19, wps=1068.1, ups=0.35, wpb=3043.8, bsz=96, num_updates=4580, lr=1.08405e-05, gnorm=1.621, clip=100, loss_scale=128, train_wall=28, gb_free=11.6, wall=13163
2023-04-19 04:06:23 - progress_bar.py[line:272] - INFO: epoch 008:    552 / 578 loss=2.339, loss_v1=0, loss_v2=0, nll_loss=1.133, ntokens=3170.7, nsentences=96, sample_size=3170.7, sample_size_v1=0, sample_size_v2=0, ppl=2.19, wps=1101.7, ups=0.35, wpb=3170.7, bsz=96, num_updates=4590, lr=1.07945e-05, gnorm=1.652, clip=100, loss_scale=128, train_wall=29, gb_free=12.6, wall=13192
2023-04-19 04:06:52 - progress_bar.py[line:272] - INFO: epoch 008:    562 / 578 loss=2.339, loss_v1=0, loss_v2=0, nll_loss=1.136, ntokens=3255.1, nsentences=96, sample_size=3255.1, sample_size_v1=0, sample_size_v2=0, ppl=2.2, wps=1131.8, ups=0.35, wpb=3255.1, bsz=96, num_updates=4600, lr=1.07485e-05, gnorm=1.51, clip=100, loss_scale=128, train_wall=29, gb_free=12.6, wall=13220
2023-04-19 04:07:20 - progress_bar.py[line:272] - INFO: epoch 008:    572 / 578 loss=2.34, loss_v1=0, loss_v2=0, nll_loss=1.137, ntokens=3155.1, nsentences=96, sample_size=3155.1, sample_size_v1=0, sample_size_v2=0, ppl=2.2, wps=1102.3, ups=0.35, wpb=3155.1, bsz=96, num_updates=4610, lr=1.07025e-05, gnorm=1.605, clip=100, loss_scale=128, train_wall=29, gb_free=12.5, wall=13249
2023-04-19 04:07:35 - checkpoint_utils.py[line:64] - INFO: Preparing to save checkpoint for epoch 8 @ 4616 updates
2023-04-19 04:07:35 - trainer.py[line:431] - INFO: Saving checkpoint to ../../checkpoints/OFA/sgcls_checkpoints/_12_3e-5_512/checkpoint8.pt
local datafile ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 1 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 1 finished initializing row_count and line_idx-to-offset mapping
file ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 1 row count 27700 total row count 55400
slice_id 1 seek offset 27700
2023-04-19 04:07:41 - trainer.py[line:441] - INFO: Finished saving checkpoint to ../../checkpoints/OFA/sgcls_checkpoints/_12_3e-5_512/checkpoint8.pt
2023-04-19 04:07:46 - checkpoint_utils.py[line:133] - INFO: Saved checkpoint ../../checkpoints/OFA/sgcls_checkpoints/_12_3e-5_512/checkpoint8.pt (epoch 8 @ 4616 updates, score None) (writing took 10.527816915884614 seconds)
2023-04-19 04:07:46 - train.py[line:332] - INFO: end of epoch 8 (average epoch stats below)
2023-04-19 04:07:46 - progress_bar.py[line:282] - INFO: epoch 008 | loss 2.344 | loss_v1 0 | loss_v2 0 | nll_loss 1.141 | ntokens 3150.77 | nsentences 95.847 | sample_size 3150.77 | sample_size_v1 0 | sample_size_v2 0 | ppl 2.21 | wps 1092.4 | ups 0.35 | wpb 3150.8 | bsz 95.8 | num_updates 4616 | lr 1.06748e-05 | gnorm 1.526 | clip 99.8 | loss_scale 128 | train_wall 1647 | gb_free 13.1 | wall 13274
2023-04-19 04:07:46 - trainer.py[line:639] - INFO: loading train data for epoch 9
local datafile ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 0 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 0 finished initializing row_count and line_idx-to-offset mapping
file ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 0 row count 27700 total row count 55400
slice_id 0 seek offset 0
2023-04-19 04:07:47 - trainer.py[line:703] - INFO: begin training epoch 9
2023-04-19 04:07:47 - train.py[line:305] - INFO: Start iterating over samples
2023-04-19 04:08:00 - progress_bar.py[line:272] - INFO: epoch 009:      4 / 578 loss=2.343, loss_v1=0, loss_v2=0, nll_loss=1.14, ntokens=2919.2, nsentences=87.6, sample_size=2919.2, sample_size_v1=0, sample_size_v2=0, ppl=2.2, wps=747.4, ups=0.26, wpb=2919.2, bsz=87.6, num_updates=4620, lr=1.06564e-05, gnorm=1.9, clip=100, loss_scale=128, train_wall=26, gb_free=12.1, wall=13288
2023-04-19 04:08:28 - progress_bar.py[line:272] - INFO: epoch 009:     14 / 578 loss=2.288, loss_v1=0, loss_v2=0, nll_loss=1.079, ntokens=3125.3, nsentences=96, sample_size=3125.3, sample_size_v1=0, sample_size_v2=0, ppl=2.11, wps=1097.8, ups=0.35, wpb=3125.3, bsz=96, num_updates=4630, lr=1.06104e-05, gnorm=1.622, clip=100, loss_scale=128, train_wall=28, gb_free=12.2, wall=13317
2023-04-19 04:08:57 - progress_bar.py[line:272] - INFO: epoch 009:     24 / 578 loss=2.269, loss_v1=0, loss_v2=0, nll_loss=1.059, ntokens=3130.1, nsentences=96, sample_size=3130.1, sample_size_v1=0, sample_size_v2=0, ppl=2.08, wps=1095.5, ups=0.35, wpb=3130.1, bsz=96, num_updates=4640, lr=1.05644e-05, gnorm=1.611, clip=100, loss_scale=128, train_wall=29, gb_free=11.6, wall=13345
2023-04-19 04:09:25 - progress_bar.py[line:272] - INFO: epoch 009:     34 / 578 loss=2.275, loss_v1=0, loss_v2=0, nll_loss=1.064, ntokens=3061, nsentences=96, sample_size=3061, sample_size_v1=0, sample_size_v2=0, ppl=2.09, wps=1069.5, ups=0.35, wpb=3061, bsz=96, num_updates=4650, lr=1.05184e-05, gnorm=1.691, clip=100, loss_scale=128, train_wall=29, gb_free=12.1, wall=13374
2023-04-19 04:09:54 - progress_bar.py[line:272] - INFO: epoch 009:     44 / 578 loss=2.169, loss_v1=0, loss_v2=0, nll_loss=0.946, ntokens=3371.1, nsentences=96, sample_size=3371.1, sample_size_v1=0, sample_size_v2=0, ppl=1.93, wps=1168.5, ups=0.35, wpb=3371.1, bsz=96, num_updates=4660, lr=1.04724e-05, gnorm=1.484, clip=100, loss_scale=128, train_wall=29, gb_free=11.6, wall=13403
2023-04-19 04:10:23 - progress_bar.py[line:272] - INFO: epoch 009:     54 / 578 loss=2.247, loss_v1=0, loss_v2=0, nll_loss=1.032, ntokens=3519.7, nsentences=96, sample_size=3519.7, sample_size_v1=0, sample_size_v2=0, ppl=2.04, wps=1206.8, ups=0.34, wpb=3519.7, bsz=96, num_updates=4670, lr=1.04264e-05, gnorm=1.467, clip=100, loss_scale=128, train_wall=29, gb_free=11.8, wall=13432
2023-04-19 04:10:52 - progress_bar.py[line:272] - INFO: epoch 009:     64 / 578 loss=2.259, loss_v1=0, loss_v2=0, nll_loss=1.047, ntokens=3149.4, nsentences=96, sample_size=3149.4, sample_size_v1=0, sample_size_v2=0, ppl=2.07, wps=1099.9, ups=0.35, wpb=3149.4, bsz=96, num_updates=4680, lr=1.03804e-05, gnorm=1.657, clip=100, loss_scale=128, train_wall=29, gb_free=11.6, wall=13461
2023-04-19 04:11:20 - progress_bar.py[line:272] - INFO: epoch 009:     74 / 578 loss=2.348, loss_v1=0, loss_v2=0, nll_loss=1.146, ntokens=3083.5, nsentences=96, sample_size=3083.5, sample_size_v1=0, sample_size_v2=0, ppl=2.21, wps=1080.5, ups=0.35, wpb=3083.5, bsz=96, num_updates=4690, lr=1.03344e-05, gnorm=1.771, clip=100, loss_scale=128, train_wall=29, gb_free=12, wall=13489
2023-04-19 04:11:49 - progress_bar.py[line:272] - INFO: epoch 009:     84 / 578 loss=2.328, loss_v1=0, loss_v2=0, nll_loss=1.123, ntokens=3253.5, nsentences=96, sample_size=3253.5, sample_size_v1=0, sample_size_v2=0, ppl=2.18, wps=1123.7, ups=0.35, wpb=3253.5, bsz=96, num_updates=4700, lr=1.02883e-05, gnorm=1.554, clip=100, loss_scale=128, train_wall=29, gb_free=11.6, wall=13518
2023-04-19 04:12:18 - progress_bar.py[line:272] - INFO: epoch 009:     94 / 578 loss=2.299, loss_v1=0, loss_v2=0, nll_loss=1.089, ntokens=3364, nsentences=96, sample_size=3364, sample_size_v1=0, sample_size_v2=0, ppl=2.13, wps=1163.7, ups=0.35, wpb=3364, bsz=96, num_updates=4710, lr=1.02423e-05, gnorm=1.621, clip=100, loss_scale=128, train_wall=29, gb_free=11.4, wall=13547
2023-04-19 04:12:47 - progress_bar.py[line:272] - INFO: epoch 009:    104 / 578 loss=2.305, loss_v1=0, loss_v2=0, nll_loss=1.099, ntokens=3292, nsentences=96, sample_size=3292, sample_size_v1=0, sample_size_v2=0, ppl=2.14, wps=1131.5, ups=0.34, wpb=3292, bsz=96, num_updates=4720, lr=1.01963e-05, gnorm=1.62, clip=100, loss_scale=128, train_wall=29, gb_free=11.9, wall=13576
2023-04-19 04:13:16 - progress_bar.py[line:272] - INFO: epoch 009:    114 / 578 loss=2.304, loss_v1=0, loss_v2=0, nll_loss=1.096, ntokens=3160.4, nsentences=96, sample_size=3160.4, sample_size_v1=0, sample_size_v2=0, ppl=2.14, wps=1104.5, ups=0.35, wpb=3160.4, bsz=96, num_updates=4730, lr=1.01503e-05, gnorm=1.636, clip=100, loss_scale=128, train_wall=29, gb_free=12.2, wall=13605
2023-04-19 04:13:45 - progress_bar.py[line:272] - INFO: epoch 009:    124 / 578 loss=2.292, loss_v1=0, loss_v2=0, nll_loss=1.083, ntokens=3238.2, nsentences=96, sample_size=3238.2, sample_size_v1=0, sample_size_v2=0, ppl=2.12, wps=1122.3, ups=0.35, wpb=3238.2, bsz=96, num_updates=4740, lr=1.01043e-05, gnorm=1.609, clip=100, loss_scale=128, train_wall=29, gb_free=11.1, wall=13633
2023-04-19 04:14:14 - progress_bar.py[line:272] - INFO: epoch 009:    134 / 578 loss=2.313, loss_v1=0, loss_v2=0, nll_loss=1.107, ntokens=3223.3, nsentences=96, sample_size=3223.3, sample_size_v1=0, sample_size_v2=0, ppl=2.15, wps=1122.7, ups=0.35, wpb=3223.3, bsz=96, num_updates=4750, lr=1.00583e-05, gnorm=1.725, clip=100, loss_scale=128, train_wall=29, gb_free=12.2, wall=13662
2023-04-19 04:14:42 - progress_bar.py[line:272] - INFO: epoch 009:    144 / 578 loss=2.361, loss_v1=0, loss_v2=0, nll_loss=1.161, ntokens=3126.5, nsentences=96, sample_size=3126.5, sample_size_v1=0, sample_size_v2=0, ppl=2.24, wps=1097.5, ups=0.35, wpb=3126.5, bsz=96, num_updates=4760, lr=1.00123e-05, gnorm=1.681, clip=100, loss_scale=128, train_wall=28, gb_free=11.9, wall=13691
2023-04-19 04:15:11 - progress_bar.py[line:272] - INFO: epoch 009:    154 / 578 loss=2.364, loss_v1=0, loss_v2=0, nll_loss=1.163, ntokens=3230.1, nsentences=96, sample_size=3230.1, sample_size_v1=0, sample_size_v2=0, ppl=2.24, wps=1134.3, ups=0.35, wpb=3230.1, bsz=96, num_updates=4770, lr=9.96626e-06, gnorm=1.639, clip=100, loss_scale=128, train_wall=28, gb_free=12.3, wall=13719
2023-04-19 04:15:39 - progress_bar.py[line:272] - INFO: epoch 009:    164 / 578 loss=2.368, loss_v1=0, loss_v2=0, nll_loss=1.167, ntokens=3269.4, nsentences=96, sample_size=3269.4, sample_size_v1=0, sample_size_v2=0, ppl=2.25, wps=1147.8, ups=0.35, wpb=3269.4, bsz=96, num_updates=4780, lr=9.92025e-06, gnorm=1.502, clip=100, loss_scale=128, train_wall=28, gb_free=12.5, wall=13748
2023-04-19 04:16:07 - progress_bar.py[line:272] - INFO: epoch 009:    174 / 578 loss=2.366, loss_v1=0, loss_v2=0, nll_loss=1.167, ntokens=3188.2, nsentences=96, sample_size=3188.2, sample_size_v1=0, sample_size_v2=0, ppl=2.25, wps=1120.5, ups=0.35, wpb=3188.2, bsz=96, num_updates=4790, lr=9.87423e-06, gnorm=1.605, clip=100, loss_scale=128, train_wall=28, gb_free=12.1, wall=13776
2023-04-19 04:16:36 - progress_bar.py[line:272] - INFO: epoch 009:    184 / 578 loss=2.365, loss_v1=0, loss_v2=0, nll_loss=1.163, ntokens=3198.2, nsentences=96, sample_size=3198.2, sample_size_v1=0, sample_size_v2=0, ppl=2.24, wps=1119.2, ups=0.35, wpb=3198.2, bsz=96, num_updates=4800, lr=9.82822e-06, gnorm=1.6, clip=100, loss_scale=128, train_wall=29, gb_free=11.9, wall=13805
2023-04-19 04:17:05 - progress_bar.py[line:272] - INFO: epoch 009:    194 / 578 loss=2.351, loss_v1=0, loss_v2=0, nll_loss=1.149, ntokens=3235.3, nsentences=96, sample_size=3235.3, sample_size_v1=0, sample_size_v2=0, ppl=2.22, wps=1131.7, ups=0.35, wpb=3235.3, bsz=96, num_updates=4810, lr=9.78221e-06, gnorm=1.513, clip=100, loss_scale=128, train_wall=29, gb_free=12.3, wall=13833
2023-04-19 04:17:33 - progress_bar.py[line:272] - INFO: epoch 009:    204 / 578 loss=2.344, loss_v1=0, loss_v2=0, nll_loss=1.141, ntokens=3221.9, nsentences=96, sample_size=3221.9, sample_size_v1=0, sample_size_v2=0, ppl=2.21, wps=1133.3, ups=0.35, wpb=3221.9, bsz=96, num_updates=4820, lr=9.7362e-06, gnorm=1.602, clip=100, loss_scale=128, train_wall=28, gb_free=12, wall=13862
2023-04-19 04:18:01 - progress_bar.py[line:272] - INFO: epoch 009:    214 / 578 loss=2.362, loss_v1=0, loss_v2=0, nll_loss=1.162, ntokens=3015.8, nsentences=96, sample_size=3015.8, sample_size_v1=0, sample_size_v2=0, ppl=2.24, wps=1064.4, ups=0.35, wpb=3015.8, bsz=96, num_updates=4830, lr=9.69018e-06, gnorm=1.653, clip=100, loss_scale=128, train_wall=28, gb_free=12.5, wall=13890
2023-04-19 04:18:30 - progress_bar.py[line:272] - INFO: epoch 009:    224 / 578 loss=2.352, loss_v1=0, loss_v2=0, nll_loss=1.149, ntokens=3179.6, nsentences=96, sample_size=3179.6, sample_size_v1=0, sample_size_v2=0, ppl=2.22, wps=1118.9, ups=0.35, wpb=3179.6, bsz=96, num_updates=4840, lr=9.64417e-06, gnorm=1.592, clip=100, loss_scale=128, train_wall=28, gb_free=12.3, wall=13918
2023-04-19 04:18:58 - progress_bar.py[line:272] - INFO: epoch 009:    234 / 578 loss=2.354, loss_v1=0, loss_v2=0, nll_loss=1.153, ntokens=2948.5, nsentences=96, sample_size=2948.5, sample_size_v1=0, sample_size_v2=0, ppl=2.22, wps=1038.9, ups=0.35, wpb=2948.5, bsz=96, num_updates=4850, lr=9.59816e-06, gnorm=1.753, clip=100, loss_scale=128, train_wall=28, gb_free=12.2, wall=13947
2023-04-19 04:19:27 - progress_bar.py[line:272] - INFO: epoch 009:    244 / 578 loss=2.368, loss_v1=0, loss_v2=0, nll_loss=1.168, ntokens=2962.6, nsentences=96, sample_size=2962.6, sample_size_v1=0, sample_size_v2=0, ppl=2.25, wps=1045.7, ups=0.35, wpb=2962.6, bsz=96, num_updates=4860, lr=9.55215e-06, gnorm=1.658, clip=100, loss_scale=128, train_wall=28, gb_free=12.3, wall=13975
2023-04-19 04:19:55 - progress_bar.py[line:272] - INFO: epoch 009:    254 / 578 loss=2.348, loss_v1=0, loss_v2=0, nll_loss=1.143, ntokens=3219, nsentences=96, sample_size=3219, sample_size_v1=0, sample_size_v2=0, ppl=2.21, wps=1132, ups=0.35, wpb=3219, bsz=96, num_updates=4870, lr=9.50613e-06, gnorm=1.592, clip=100, loss_scale=128, train_wall=28, gb_free=12.3, wall=14004
2023-04-19 04:20:23 - progress_bar.py[line:272] - INFO: epoch 009:    264 / 578 loss=2.355, loss_v1=0, loss_v2=0, nll_loss=1.154, ntokens=3051.3, nsentences=96, sample_size=3051.3, sample_size_v1=0, sample_size_v2=0, ppl=2.23, wps=1076.5, ups=0.35, wpb=3051.3, bsz=96, num_updates=4880, lr=9.46012e-06, gnorm=1.722, clip=100, loss_scale=128, train_wall=28, gb_free=12, wall=14032
2023-04-19 04:20:52 - progress_bar.py[line:272] - INFO: epoch 009:    274 / 578 loss=2.354, loss_v1=0, loss_v2=0, nll_loss=1.153, ntokens=3174.8, nsentences=96, sample_size=3174.8, sample_size_v1=0, sample_size_v2=0, ppl=2.22, wps=1117.8, ups=0.35, wpb=3174.8, bsz=96, num_updates=4890, lr=9.41411e-06, gnorm=1.546, clip=100, loss_scale=128, train_wall=28, gb_free=12.4, wall=14060
2023-04-19 04:21:20 - progress_bar.py[line:272] - INFO: epoch 009:    284 / 578 loss=2.333, loss_v1=0, loss_v2=0, nll_loss=1.128, ntokens=3116.9, nsentences=96, sample_size=3116.9, sample_size_v1=0, sample_size_v2=0, ppl=2.18, wps=1093.4, ups=0.35, wpb=3116.9, bsz=96, num_updates=4900, lr=9.3681e-06, gnorm=1.696, clip=100, loss_scale=128, train_wall=28, gb_free=12, wall=14089
2023-04-19 04:21:49 - progress_bar.py[line:272] - INFO: epoch 009:    294 / 578 loss=2.366, loss_v1=0, loss_v2=0, nll_loss=1.167, ntokens=3157.3, nsentences=95.6, sample_size=3157.3, sample_size_v1=0, sample_size_v2=0, ppl=2.25, wps=1109.2, ups=0.35, wpb=3157.3, bsz=95.6, num_updates=4910, lr=9.32209e-06, gnorm=1.556, clip=100, loss_scale=128, train_wall=28, gb_free=12.4, wall=14117
2023-04-19 04:22:17 - progress_bar.py[line:272] - INFO: epoch 009:    304 / 578 loss=2.359, loss_v1=0, loss_v2=0, nll_loss=1.157, ntokens=3026.8, nsentences=96, sample_size=3026.8, sample_size_v1=0, sample_size_v2=0, ppl=2.23, wps=1058.7, ups=0.35, wpb=3026.8, bsz=96, num_updates=4920, lr=9.27607e-06, gnorm=1.788, clip=100, loss_scale=128, train_wall=29, gb_free=12.4, wall=14146
2023-04-19 04:22:46 - progress_bar.py[line:272] - INFO: epoch 009:    314 / 578 loss=2.35, loss_v1=0, loss_v2=0, nll_loss=1.148, ntokens=3251.8, nsentences=96, sample_size=3251.8, sample_size_v1=0, sample_size_v2=0, ppl=2.22, wps=1141.3, ups=0.35, wpb=3251.8, bsz=96, num_updates=4930, lr=9.23006e-06, gnorm=1.602, clip=100, loss_scale=128, train_wall=28, gb_free=12.5, wall=14174
2023-04-19 04:23:14 - progress_bar.py[line:272] - INFO: epoch 009:    324 / 578 loss=2.353, loss_v1=0, loss_v2=0, nll_loss=1.15, ntokens=3240.6, nsentences=96, sample_size=3240.6, sample_size_v1=0, sample_size_v2=0, ppl=2.22, wps=1133, ups=0.35, wpb=3240.6, bsz=96, num_updates=4940, lr=9.18405e-06, gnorm=1.665, clip=100, loss_scale=128, train_wall=29, gb_free=12.2, wall=14203
2023-04-19 04:23:43 - progress_bar.py[line:272] - INFO: epoch 009:    334 / 578 loss=2.33, loss_v1=0, loss_v2=0, nll_loss=1.127, ntokens=3058.9, nsentences=96, sample_size=3058.9, sample_size_v1=0, sample_size_v2=0, ppl=2.18, wps=1073.6, ups=0.35, wpb=3058.9, bsz=96, num_updates=4950, lr=9.13804e-06, gnorm=1.709, clip=100, loss_scale=128, train_wall=28, gb_free=12.4, wall=14232
2023-04-19 04:24:11 - progress_bar.py[line:272] - INFO: epoch 009:    344 / 578 loss=2.367, loss_v1=0, loss_v2=0, nll_loss=1.166, ntokens=3286.4, nsentences=96, sample_size=3286.4, sample_size_v1=0, sample_size_v2=0, ppl=2.24, wps=1154.2, ups=0.35, wpb=3286.4, bsz=96, num_updates=4960, lr=9.09202e-06, gnorm=1.578, clip=100, loss_scale=128, train_wall=28, gb_free=12.2, wall=14260
2023-04-19 04:24:40 - progress_bar.py[line:272] - INFO: epoch 009:    354 / 578 loss=2.339, loss_v1=0, loss_v2=0, nll_loss=1.134, ntokens=3040.9, nsentences=96, sample_size=3040.9, sample_size_v1=0, sample_size_v2=0, ppl=2.19, wps=1071.5, ups=0.35, wpb=3040.9, bsz=96, num_updates=4970, lr=9.04601e-06, gnorm=1.725, clip=100, loss_scale=128, train_wall=28, gb_free=12.3, wall=14288
2023-04-19 04:25:08 - progress_bar.py[line:272] - INFO: epoch 009:    364 / 578 loss=2.356, loss_v1=0, loss_v2=0, nll_loss=1.157, ntokens=3316.6, nsentences=96, sample_size=3316.6, sample_size_v1=0, sample_size_v2=0, ppl=2.23, wps=1166.3, ups=0.35, wpb=3316.6, bsz=96, num_updates=4980, lr=9e-06, gnorm=1.594, clip=100, loss_scale=128, train_wall=28, gb_free=12.1, wall=14317
2023-04-19 04:25:37 - progress_bar.py[line:272] - INFO: epoch 009:    374 / 578 loss=2.355, loss_v1=0, loss_v2=0, nll_loss=1.153, ntokens=3377.7, nsentences=96, sample_size=3377.7, sample_size_v1=0, sample_size_v2=0, ppl=2.22, wps=1175.2, ups=0.35, wpb=3377.7, bsz=96, num_updates=4990, lr=8.95399e-06, gnorm=1.58, clip=100, loss_scale=128, train_wall=29, gb_free=12.2, wall=14346
2023-04-19 04:26:06 - progress_bar.py[line:272] - INFO: epoch 009:    384 / 578 loss=2.356, loss_v1=0, loss_v2=0, nll_loss=1.154, ntokens=3283.1, nsentences=96, sample_size=3283.1, sample_size_v1=0, sample_size_v2=0, ppl=2.23, wps=1151.5, ups=0.35, wpb=3283.1, bsz=96, num_updates=5000, lr=8.90798e-06, gnorm=1.63, clip=100, loss_scale=128, train_wall=28, gb_free=12.1, wall=14374
2023-04-19 04:26:34 - progress_bar.py[line:272] - INFO: epoch 009:    394 / 578 loss=2.358, loss_v1=0, loss_v2=0, nll_loss=1.157, ntokens=3096.2, nsentences=96, sample_size=3096.2, sample_size_v1=0, sample_size_v2=0, ppl=2.23, wps=1084.8, ups=0.35, wpb=3096.2, bsz=96, num_updates=5010, lr=8.86196e-06, gnorm=1.87, clip=100, loss_scale=128, train_wall=29, gb_free=11.8, wall=14403
2023-04-19 04:27:03 - progress_bar.py[line:272] - INFO: epoch 009:    404 / 578 loss=2.317, loss_v1=0, loss_v2=0, nll_loss=1.113, ntokens=3154.7, nsentences=96, sample_size=3154.7, sample_size_v1=0, sample_size_v2=0, ppl=2.16, wps=1101.3, ups=0.35, wpb=3154.7, bsz=96, num_updates=5020, lr=8.81595e-06, gnorm=1.756, clip=100, loss_scale=128, train_wall=29, gb_free=12.6, wall=14431
2023-04-19 04:27:31 - progress_bar.py[line:272] - INFO: epoch 009:    414 / 578 loss=2.367, loss_v1=0, loss_v2=0, nll_loss=1.165, ntokens=2979.5, nsentences=96, sample_size=2979.5, sample_size_v1=0, sample_size_v2=0, ppl=2.24, wps=1046.3, ups=0.35, wpb=2979.5, bsz=96, num_updates=5030, lr=8.76994e-06, gnorm=1.842, clip=100, loss_scale=128, train_wall=28, gb_free=12.6, wall=14460
2023-04-19 04:28:00 - progress_bar.py[line:272] - INFO: epoch 009:    424 / 578 loss=2.333, loss_v1=0, loss_v2=0, nll_loss=1.129, ntokens=3038.4, nsentences=96, sample_size=3038.4, sample_size_v1=0, sample_size_v2=0, ppl=2.19, wps=1064.2, ups=0.35, wpb=3038.4, bsz=96, num_updates=5040, lr=8.72393e-06, gnorm=1.772, clip=100, loss_scale=128, train_wall=29, gb_free=12.3, wall=14488
2023-04-19 04:28:28 - progress_bar.py[line:272] - INFO: epoch 009:    434 / 578 loss=2.347, loss_v1=0, loss_v2=0, nll_loss=1.145, ntokens=3070, nsentences=96, sample_size=3070, sample_size_v1=0, sample_size_v2=0, ppl=2.21, wps=1085.3, ups=0.35, wpb=3070, bsz=96, num_updates=5050, lr=8.67791e-06, gnorm=1.681, clip=100, loss_scale=128, train_wall=28, gb_free=12.2, wall=14517
2023-04-19 04:28:56 - progress_bar.py[line:272] - INFO: epoch 009:    444 / 578 loss=2.367, loss_v1=0, loss_v2=0, nll_loss=1.167, ntokens=2885.6, nsentences=96, sample_size=2885.6, sample_size_v1=0, sample_size_v2=0, ppl=2.25, wps=1015, ups=0.35, wpb=2885.6, bsz=96, num_updates=5060, lr=8.6319e-06, gnorm=1.923, clip=100, loss_scale=128, train_wall=28, gb_free=12.2, wall=14545
2023-04-19 04:29:25 - progress_bar.py[line:272] - INFO: epoch 009:    454 / 578 loss=2.34, loss_v1=0, loss_v2=0, nll_loss=1.137, ntokens=3103.7, nsentences=96, sample_size=3103.7, sample_size_v1=0, sample_size_v2=0, ppl=2.2, wps=1089.8, ups=0.35, wpb=3103.7, bsz=96, num_updates=5070, lr=8.58589e-06, gnorm=1.76, clip=100, loss_scale=128, train_wall=28, gb_free=12, wall=14574
2023-04-19 04:29:53 - progress_bar.py[line:272] - INFO: epoch 009:    464 / 578 loss=2.349, loss_v1=0, loss_v2=0, nll_loss=1.149, ntokens=3095.3, nsentences=96, sample_size=3095.3, sample_size_v1=0, sample_size_v2=0, ppl=2.22, wps=1085.3, ups=0.35, wpb=3095.3, bsz=96, num_updates=5080, lr=8.53988e-06, gnorm=1.759, clip=100, loss_scale=256, train_wall=28, gb_free=12.5, wall=14602
2023-04-19 04:30:08 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 128.0
2023-04-19 04:30:25 - progress_bar.py[line:272] - INFO: epoch 009:    475 / 578 loss=2.362, loss_v1=0, loss_v2=0, nll_loss=1.159, ntokens=2891.3, nsentences=96, sample_size=2891.3, sample_size_v1=0, sample_size_v2=0, ppl=2.23, wps=927.7, ups=0.32, wpb=2891.3, bsz=96, num_updates=5090, lr=8.49387e-06, gnorm=1.84, clip=100, loss_scale=128, train_wall=31, gb_free=12.7, wall=14633
2023-04-19 04:30:53 - progress_bar.py[line:272] - INFO: epoch 009:    485 / 578 loss=2.332, loss_v1=0, loss_v2=0, nll_loss=1.129, ntokens=2967.7, nsentences=96, sample_size=2967.7, sample_size_v1=0, sample_size_v2=0, ppl=2.19, wps=1042.3, ups=0.35, wpb=2967.7, bsz=96, num_updates=5100, lr=8.44785e-06, gnorm=1.679, clip=100, loss_scale=128, train_wall=28, gb_free=12.6, wall=14662
2023-04-19 04:31:22 - progress_bar.py[line:272] - INFO: epoch 009:    495 / 578 loss=2.329, loss_v1=0, loss_v2=0, nll_loss=1.126, ntokens=3159.6, nsentences=96, sample_size=3159.6, sample_size_v1=0, sample_size_v2=0, ppl=2.18, wps=1108.1, ups=0.35, wpb=3159.6, bsz=96, num_updates=5110, lr=8.40184e-06, gnorm=1.716, clip=100, loss_scale=128, train_wall=28, gb_free=12.3, wall=14690
2023-04-19 04:31:50 - progress_bar.py[line:272] - INFO: epoch 009:    505 / 578 loss=2.322, loss_v1=0, loss_v2=0, nll_loss=1.114, ntokens=3120, nsentences=96, sample_size=3120, sample_size_v1=0, sample_size_v2=0, ppl=2.16, wps=1092.3, ups=0.35, wpb=3120, bsz=96, num_updates=5120, lr=8.35583e-06, gnorm=1.925, clip=100, loss_scale=128, train_wall=29, gb_free=12.5, wall=14719
2023-04-19 04:32:19 - progress_bar.py[line:272] - INFO: epoch 009:    515 / 578 loss=2.328, loss_v1=0, loss_v2=0, nll_loss=1.127, ntokens=3191.5, nsentences=96, sample_size=3191.5, sample_size_v1=0, sample_size_v2=0, ppl=2.18, wps=1118.4, ups=0.35, wpb=3191.5, bsz=96, num_updates=5130, lr=8.30982e-06, gnorm=1.881, clip=100, loss_scale=128, train_wall=29, gb_free=11.6, wall=14747
2023-04-19 04:32:47 - progress_bar.py[line:272] - INFO: epoch 009:    525 / 578 loss=2.335, loss_v1=0, loss_v2=0, nll_loss=1.13, ntokens=3201.5, nsentences=96, sample_size=3201.5, sample_size_v1=0, sample_size_v2=0, ppl=2.19, wps=1123, ups=0.35, wpb=3201.5, bsz=96, num_updates=5140, lr=8.2638e-06, gnorm=1.836, clip=100, loss_scale=128, train_wall=28, gb_free=12.3, wall=14776
2023-04-19 04:33:16 - progress_bar.py[line:272] - INFO: epoch 009:    535 / 578 loss=2.342, loss_v1=0, loss_v2=0, nll_loss=1.139, ntokens=3022.9, nsentences=96, sample_size=3022.9, sample_size_v1=0, sample_size_v2=0, ppl=2.2, wps=1065.7, ups=0.35, wpb=3022.9, bsz=96, num_updates=5150, lr=8.21779e-06, gnorm=1.96, clip=100, loss_scale=128, train_wall=28, gb_free=12.4, wall=14804
2023-04-19 04:33:44 - progress_bar.py[line:272] - INFO: epoch 009:    545 / 578 loss=2.323, loss_v1=0, loss_v2=0, nll_loss=1.119, ntokens=3112, nsentences=96, sample_size=3112, sample_size_v1=0, sample_size_v2=0, ppl=2.17, wps=1086.9, ups=0.35, wpb=3112, bsz=96, num_updates=5160, lr=8.17178e-06, gnorm=1.85, clip=100, loss_scale=128, train_wall=29, gb_free=12.4, wall=14833
2023-04-19 04:34:13 - progress_bar.py[line:272] - INFO: epoch 009:    555 / 578 loss=2.324, loss_v1=0, loss_v2=0, nll_loss=1.116, ntokens=3300.6, nsentences=96, sample_size=3300.6, sample_size_v1=0, sample_size_v2=0, ppl=2.17, wps=1139.3, ups=0.35, wpb=3300.6, bsz=96, num_updates=5170, lr=8.12577e-06, gnorm=1.718, clip=100, loss_scale=128, train_wall=29, gb_free=12.7, wall=14862
2023-04-19 04:34:42 - progress_bar.py[line:272] - INFO: epoch 009:    565 / 578 loss=2.33, loss_v1=0, loss_v2=0, nll_loss=1.126, ntokens=3193.3, nsentences=96, sample_size=3193.3, sample_size_v1=0, sample_size_v2=0, ppl=2.18, wps=1114.4, ups=0.35, wpb=3193.3, bsz=96, num_updates=5180, lr=8.07975e-06, gnorm=1.868, clip=100, loss_scale=128, train_wall=29, gb_free=11.8, wall=14891
2023-04-19 04:35:10 - progress_bar.py[line:272] - INFO: epoch 009:    575 / 578 loss=2.333, loss_v1=0, loss_v2=0, nll_loss=1.131, ntokens=3139.7, nsentences=96, sample_size=3139.7, sample_size_v1=0, sample_size_v2=0, ppl=2.19, wps=1099.7, ups=0.35, wpb=3139.7, bsz=96, num_updates=5190, lr=8.03374e-06, gnorm=1.927, clip=100, loss_scale=128, train_wall=29, gb_free=12, wall=14919
2023-04-19 04:35:17 - checkpoint_utils.py[line:64] - INFO: Preparing to save checkpoint for epoch 9 @ 5193 updates
2023-04-19 04:35:17 - trainer.py[line:431] - INFO: Saving checkpoint to ../../checkpoints/OFA/sgcls_checkpoints/_12_3e-5_512/checkpoint9.pt
local datafile ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 1 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 1 finished initializing row_count and line_idx-to-offset mapping
file ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 1 row count 27700 total row count 55400
slice_id 1 seek offset 27700
2023-04-19 04:35:20 - trainer.py[line:441] - INFO: Finished saving checkpoint to ../../checkpoints/OFA/sgcls_checkpoints/_12_3e-5_512/checkpoint9.pt
2023-04-19 04:35:22 - checkpoint_utils.py[line:133] - INFO: Saved checkpoint ../../checkpoints/OFA/sgcls_checkpoints/_12_3e-5_512/checkpoint9.pt (epoch 9 @ 5193 updates, score None) (writing took 5.920319588854909 seconds)
2023-04-19 04:35:22 - train.py[line:332] - INFO: end of epoch 9 (average epoch stats below)
2023-04-19 04:35:23 - progress_bar.py[line:282] - INFO: epoch 009 | loss 2.333 | loss_v1 0 | loss_v2 0 | nll_loss 1.129 | ntokens 3151.36 | nsentences 95.847 | sample_size 3151.36 | sample_size_v1 0 | sample_size_v2 0 | ppl 2.19 | wps 1097.5 | ups 0.35 | wpb 3151.4 | bsz 95.8 | num_updates 5193 | lr 8.01994e-06 | gnorm 1.697 | clip 100 | loss_scale 128 | train_wall 1647 | gb_free 13.1 | wall 14931
2023-04-19 04:35:23 - trainer.py[line:639] - INFO: loading train data for epoch 10
local datafile ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 0 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 0 finished initializing row_count and line_idx-to-offset mapping
file ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 0 row count 27700 total row count 55400
slice_id 0 seek offset 0
2023-04-19 04:35:24 - trainer.py[line:703] - INFO: begin training epoch 10
2023-04-19 04:35:24 - train.py[line:305] - INFO: Start iterating over samples
2023-04-19 04:35:45 - progress_bar.py[line:272] - INFO: epoch 010:      7 / 578 loss=2.311, loss_v1=0, loss_v2=0, nll_loss=1.104, ntokens=2933.8, nsentences=87.6, sample_size=2933.8, sample_size_v1=0, sample_size_v2=0, ppl=2.15, wps=853.2, ups=0.29, wpb=2933.8, bsz=87.6, num_updates=5200, lr=7.98773e-06, gnorm=2.132, clip=100, loss_scale=128, train_wall=26, gb_free=11.4, wall=14953
2023-04-19 04:36:13 - progress_bar.py[line:272] - INFO: epoch 010:     17 / 578 loss=2.287, loss_v1=0, loss_v2=0, nll_loss=1.077, ntokens=2994, nsentences=96, sample_size=2994, sample_size_v1=0, sample_size_v2=0, ppl=2.11, wps=1056.6, ups=0.35, wpb=2994, bsz=96, num_updates=5210, lr=7.94172e-06, gnorm=2.049, clip=100, loss_scale=128, train_wall=28, gb_free=12.3, wall=14982
2023-04-19 04:36:42 - progress_bar.py[line:272] - INFO: epoch 010:     27 / 578 loss=2.225, loss_v1=0, loss_v2=0, nll_loss=1.009, ntokens=3277.3, nsentences=96, sample_size=3277.3, sample_size_v1=0, sample_size_v2=0, ppl=2.01, wps=1140.5, ups=0.35, wpb=3277.3, bsz=96, num_updates=5220, lr=7.89571e-06, gnorm=1.791, clip=100, loss_scale=128, train_wall=29, gb_free=12, wall=15011
2023-04-19 04:37:10 - progress_bar.py[line:272] - INFO: epoch 010:     37 / 578 loss=2.26, loss_v1=0, loss_v2=0, nll_loss=1.048, ntokens=3002.4, nsentences=96, sample_size=3002.4, sample_size_v1=0, sample_size_v2=0, ppl=2.07, wps=1050.1, ups=0.35, wpb=3002.4, bsz=96, num_updates=5230, lr=7.84969e-06, gnorm=2.005, clip=100, loss_scale=128, train_wall=29, gb_free=11.9, wall=15039
2023-04-19 04:37:40 - progress_bar.py[line:272] - INFO: epoch 010:     47 / 578 loss=2.176, loss_v1=0, loss_v2=0, nll_loss=0.952, ntokens=3542.1, nsentences=96, sample_size=3542.1, sample_size_v1=0, sample_size_v2=0, ppl=1.94, wps=1212.5, ups=0.34, wpb=3542.1, bsz=96, num_updates=5240, lr=7.80368e-06, gnorm=1.63, clip=100, loss_scale=128, train_wall=29, gb_free=11.3, wall=15068
2023-04-19 04:38:09 - progress_bar.py[line:272] - INFO: epoch 010:     57 / 578 loss=2.239, loss_v1=0, loss_v2=0, nll_loss=1.024, ntokens=3330.4, nsentences=96, sample_size=3330.4, sample_size_v1=0, sample_size_v2=0, ppl=2.03, wps=1149.6, ups=0.35, wpb=3330.4, bsz=96, num_updates=5250, lr=7.75767e-06, gnorm=1.916, clip=100, loss_scale=128, train_wall=29, gb_free=11.9, wall=15097
2023-04-19 04:38:37 - progress_bar.py[line:272] - INFO: epoch 010:     67 / 578 loss=2.276, loss_v1=0, loss_v2=0, nll_loss=1.065, ntokens=3145.7, nsentences=96, sample_size=3145.7, sample_size_v1=0, sample_size_v2=0, ppl=2.09, wps=1097.7, ups=0.35, wpb=3145.7, bsz=96, num_updates=5260, lr=7.71166e-06, gnorm=2.023, clip=100, loss_scale=128, train_wall=29, gb_free=11.9, wall=15126
2023-04-19 04:39:06 - progress_bar.py[line:272] - INFO: epoch 010:     77 / 578 loss=2.334, loss_v1=0, loss_v2=0, nll_loss=1.131, ntokens=3099.9, nsentences=96, sample_size=3099.9, sample_size_v1=0, sample_size_v2=0, ppl=2.19, wps=1080.7, ups=0.35, wpb=3099.9, bsz=96, num_updates=5270, lr=7.66564e-06, gnorm=1.981, clip=100, loss_scale=128, train_wall=29, gb_free=11.7, wall=15155
2023-04-19 04:39:35 - progress_bar.py[line:272] - INFO: epoch 010:     87 / 578 loss=2.313, loss_v1=0, loss_v2=0, nll_loss=1.106, ntokens=3337.7, nsentences=96, sample_size=3337.7, sample_size_v1=0, sample_size_v2=0, ppl=2.15, wps=1154.9, ups=0.35, wpb=3337.7, bsz=96, num_updates=5280, lr=7.61963e-06, gnorm=1.914, clip=100, loss_scale=128, train_wall=29, gb_free=11.5, wall=15184
2023-04-19 04:40:04 - progress_bar.py[line:272] - INFO: epoch 010:     97 / 578 loss=2.283, loss_v1=0, loss_v2=0, nll_loss=1.073, ntokens=3308.6, nsentences=96, sample_size=3308.6, sample_size_v1=0, sample_size_v2=0, ppl=2.1, wps=1141.1, ups=0.34, wpb=3308.6, bsz=96, num_updates=5290, lr=7.57362e-06, gnorm=1.955, clip=100, loss_scale=128, train_wall=29, gb_free=11.8, wall=15213
2023-04-19 04:40:33 - progress_bar.py[line:272] - INFO: epoch 010:    107 / 578 loss=2.298, loss_v1=0, loss_v2=0, nll_loss=1.09, ntokens=3306.8, nsentences=96, sample_size=3306.8, sample_size_v1=0, sample_size_v2=0, ppl=2.13, wps=1141.2, ups=0.35, wpb=3306.8, bsz=96, num_updates=5300, lr=7.52761e-06, gnorm=1.835, clip=100, loss_scale=128, train_wall=29, gb_free=12.1, wall=15242
2023-04-19 04:41:02 - progress_bar.py[line:272] - INFO: epoch 010:    117 / 578 loss=2.294, loss_v1=0, loss_v2=0, nll_loss=1.085, ntokens=3105.7, nsentences=96, sample_size=3105.7, sample_size_v1=0, sample_size_v2=0, ppl=2.12, wps=1083.7, ups=0.35, wpb=3105.7, bsz=96, num_updates=5310, lr=7.4816e-06, gnorm=1.949, clip=100, loss_scale=128, train_wall=29, gb_free=11.8, wall=15270
2023-04-19 04:41:30 - progress_bar.py[line:272] - INFO: epoch 010:    127 / 578 loss=2.279, loss_v1=0, loss_v2=0, nll_loss=1.068, ntokens=3318.3, nsentences=96, sample_size=3318.3, sample_size_v1=0, sample_size_v2=0, ppl=2.1, wps=1151.4, ups=0.35, wpb=3318.3, bsz=96, num_updates=5320, lr=7.43558e-06, gnorm=1.919, clip=100, loss_scale=128, train_wall=29, gb_free=11.8, wall=15299
2023-04-19 04:41:59 - progress_bar.py[line:272] - INFO: epoch 010:    137 / 578 loss=2.327, loss_v1=0, loss_v2=0, nll_loss=1.121, ntokens=3093, nsentences=96, sample_size=3093, sample_size_v1=0, sample_size_v2=0, ppl=2.18, wps=1082.8, ups=0.35, wpb=3093, bsz=96, num_updates=5330, lr=7.38957e-06, gnorm=2.112, clip=100, loss_scale=128, train_wall=29, gb_free=12.6, wall=15328
2023-04-19 04:42:28 - progress_bar.py[line:272] - INFO: epoch 010:    147 / 578 loss=2.346, loss_v1=0, loss_v2=0, nll_loss=1.144, ntokens=3244.9, nsentences=96, sample_size=3244.9, sample_size_v1=0, sample_size_v2=0, ppl=2.21, wps=1134.8, ups=0.35, wpb=3244.9, bsz=96, num_updates=5340, lr=7.34356e-06, gnorm=1.851, clip=100, loss_scale=128, train_wall=29, gb_free=12.2, wall=15356
2023-04-19 04:42:56 - progress_bar.py[line:272] - INFO: epoch 010:    157 / 578 loss=2.359, loss_v1=0, loss_v2=0, nll_loss=1.157, ntokens=3186.7, nsentences=96, sample_size=3186.7, sample_size_v1=0, sample_size_v2=0, ppl=2.23, wps=1122.7, ups=0.35, wpb=3186.7, bsz=96, num_updates=5350, lr=7.29755e-06, gnorm=1.996, clip=100, loss_scale=128, train_wall=28, gb_free=12.2, wall=15385
2023-04-19 04:43:24 - progress_bar.py[line:272] - INFO: epoch 010:    167 / 578 loss=2.349, loss_v1=0, loss_v2=0, nll_loss=1.147, ntokens=3258.5, nsentences=96, sample_size=3258.5, sample_size_v1=0, sample_size_v2=0, ppl=2.21, wps=1143.5, ups=0.35, wpb=3258.5, bsz=96, num_updates=5360, lr=7.25153e-06, gnorm=1.847, clip=100, loss_scale=128, train_wall=28, gb_free=12.2, wall=15413
2023-04-19 04:43:53 - progress_bar.py[line:272] - INFO: epoch 010:    177 / 578 loss=2.358, loss_v1=0, loss_v2=0, nll_loss=1.158, ntokens=3191, nsentences=96, sample_size=3191, sample_size_v1=0, sample_size_v2=0, ppl=2.23, wps=1116.3, ups=0.35, wpb=3191, bsz=96, num_updates=5370, lr=7.20552e-06, gnorm=1.922, clip=100, loss_scale=128, train_wall=29, gb_free=11.7, wall=15442
2023-04-19 04:44:22 - progress_bar.py[line:272] - INFO: epoch 010:    187 / 578 loss=2.35, loss_v1=0, loss_v2=0, nll_loss=1.148, ntokens=3258.8, nsentences=96, sample_size=3258.8, sample_size_v1=0, sample_size_v2=0, ppl=2.22, wps=1142.5, ups=0.35, wpb=3258.8, bsz=96, num_updates=5380, lr=7.15951e-06, gnorm=1.851, clip=100, loss_scale=128, train_wall=28, gb_free=12, wall=15470
2023-04-19 04:44:50 - progress_bar.py[line:272] - INFO: epoch 010:    197 / 578 loss=2.337, loss_v1=0, loss_v2=0, nll_loss=1.134, ntokens=3224.4, nsentences=96, sample_size=3224.4, sample_size_v1=0, sample_size_v2=0, ppl=2.19, wps=1132.6, ups=0.35, wpb=3224.4, bsz=96, num_updates=5390, lr=7.1135e-06, gnorm=1.803, clip=100, loss_scale=128, train_wall=28, gb_free=11.9, wall=15499
2023-04-19 04:45:18 - progress_bar.py[line:272] - INFO: epoch 010:    207 / 578 loss=2.333, loss_v1=0, loss_v2=0, nll_loss=1.13, ntokens=3179.8, nsentences=96, sample_size=3179.8, sample_size_v1=0, sample_size_v2=0, ppl=2.19, wps=1120.3, ups=0.35, wpb=3179.8, bsz=96, num_updates=5400, lr=7.06748e-06, gnorm=1.891, clip=100, loss_scale=128, train_wall=28, gb_free=11.9, wall=15527
2023-04-19 04:45:47 - progress_bar.py[line:272] - INFO: epoch 010:    217 / 578 loss=2.358, loss_v1=0, loss_v2=0, nll_loss=1.157, ntokens=3021.4, nsentences=96, sample_size=3021.4, sample_size_v1=0, sample_size_v2=0, ppl=2.23, wps=1066.9, ups=0.35, wpb=3021.4, bsz=96, num_updates=5410, lr=7.02147e-06, gnorm=1.93, clip=100, loss_scale=128, train_wall=28, gb_free=12.4, wall=15555
2023-04-19 04:46:15 - progress_bar.py[line:272] - INFO: epoch 010:    227 / 578 loss=2.329, loss_v1=0, loss_v2=0, nll_loss=1.125, ntokens=3132, nsentences=96, sample_size=3132, sample_size_v1=0, sample_size_v2=0, ppl=2.18, wps=1099.5, ups=0.35, wpb=3132, bsz=96, num_updates=5420, lr=6.97546e-06, gnorm=1.919, clip=100, loss_scale=128, train_wall=28, gb_free=12.1, wall=15584
2023-04-19 04:46:44 - progress_bar.py[line:272] - INFO: epoch 010:    237 / 578 loss=2.358, loss_v1=0, loss_v2=0, nll_loss=1.158, ntokens=2943.4, nsentences=96, sample_size=2943.4, sample_size_v1=0, sample_size_v2=0, ppl=2.23, wps=1040.7, ups=0.35, wpb=2943.4, bsz=96, num_updates=5430, lr=6.92945e-06, gnorm=2.185, clip=100, loss_scale=128, train_wall=28, gb_free=12.1, wall=15612
2023-04-19 04:47:12 - progress_bar.py[line:272] - INFO: epoch 010:    247 / 578 loss=2.353, loss_v1=0, loss_v2=0, nll_loss=1.151, ntokens=2989.1, nsentences=96, sample_size=2989.1, sample_size_v1=0, sample_size_v2=0, ppl=2.22, wps=1055.6, ups=0.35, wpb=2989.1, bsz=96, num_updates=5440, lr=6.88344e-06, gnorm=1.964, clip=100, loss_scale=128, train_wall=28, gb_free=11.9, wall=15640
2023-04-19 04:47:40 - progress_bar.py[line:272] - INFO: epoch 010:    257 / 578 loss=2.337, loss_v1=0, loss_v2=0, nll_loss=1.132, ntokens=3224.2, nsentences=96, sample_size=3224.2, sample_size_v1=0, sample_size_v2=0, ppl=2.19, wps=1130.8, ups=0.35, wpb=3224.2, bsz=96, num_updates=5450, lr=6.83742e-06, gnorm=1.787, clip=100, loss_scale=128, train_wall=28, gb_free=12.3, wall=15669
2023-04-19 04:48:09 - progress_bar.py[line:272] - INFO: epoch 010:    267 / 578 loss=2.341, loss_v1=0, loss_v2=0, nll_loss=1.139, ntokens=3052.4, nsentences=96, sample_size=3052.4, sample_size_v1=0, sample_size_v2=0, ppl=2.2, wps=1075.6, ups=0.35, wpb=3052.4, bsz=96, num_updates=5460, lr=6.79141e-06, gnorm=2.052, clip=100, loss_scale=128, train_wall=28, gb_free=12.3, wall=15697
2023-04-19 04:48:37 - progress_bar.py[line:272] - INFO: epoch 010:    277 / 578 loss=2.334, loss_v1=0, loss_v2=0, nll_loss=1.131, ntokens=3191.8, nsentences=96, sample_size=3191.8, sample_size_v1=0, sample_size_v2=0, ppl=2.19, wps=1123.1, ups=0.35, wpb=3191.8, bsz=96, num_updates=5470, lr=6.7454e-06, gnorm=2, clip=100, loss_scale=128, train_wall=28, gb_free=12.6, wall=15726
2023-04-19 04:49:06 - progress_bar.py[line:272] - INFO: epoch 010:    287 / 578 loss=2.33, loss_v1=0, loss_v2=0, nll_loss=1.124, ntokens=3169.6, nsentences=96, sample_size=3169.6, sample_size_v1=0, sample_size_v2=0, ppl=2.18, wps=1114.2, ups=0.35, wpb=3169.6, bsz=96, num_updates=5480, lr=6.69939e-06, gnorm=2.014, clip=100, loss_scale=128, train_wall=28, gb_free=12.2, wall=15754
2023-04-19 04:49:34 - progress_bar.py[line:272] - INFO: epoch 010:    297 / 578 loss=2.362, loss_v1=0, loss_v2=0, nll_loss=1.163, ntokens=3062.3, nsentences=96, sample_size=3062.3, sample_size_v1=0, sample_size_v2=0, ppl=2.24, wps=1073.2, ups=0.35, wpb=3062.3, bsz=96, num_updates=5490, lr=6.65337e-06, gnorm=2.019, clip=100, loss_scale=128, train_wall=29, gb_free=12, wall=15783
2023-04-19 04:50:03 - progress_bar.py[line:272] - INFO: epoch 010:    307 / 578 loss=2.346, loss_v1=0, loss_v2=0, nll_loss=1.144, ntokens=3132.3, nsentences=96, sample_size=3132.3, sample_size_v1=0, sample_size_v2=0, ppl=2.21, wps=1096.2, ups=0.35, wpb=3132.3, bsz=96, num_updates=5500, lr=6.60736e-06, gnorm=1.995, clip=100, loss_scale=128, train_wall=29, gb_free=12.1, wall=15811
2023-04-19 04:50:31 - progress_bar.py[line:272] - INFO: epoch 010:    317 / 578 loss=2.346, loss_v1=0, loss_v2=0, nll_loss=1.143, ntokens=3291, nsentences=96, sample_size=3291, sample_size_v1=0, sample_size_v2=0, ppl=2.21, wps=1152.8, ups=0.35, wpb=3291, bsz=96, num_updates=5510, lr=6.56135e-06, gnorm=2.029, clip=100, loss_scale=128, train_wall=29, gb_free=12.3, wall=15840
2023-04-19 04:51:00 - progress_bar.py[line:272] - INFO: epoch 010:    327 / 578 loss=2.333, loss_v1=0, loss_v2=0, nll_loss=1.128, ntokens=3150.5, nsentences=96, sample_size=3150.5, sample_size_v1=0, sample_size_v2=0, ppl=2.19, wps=1102.5, ups=0.35, wpb=3150.5, bsz=96, num_updates=5520, lr=6.51534e-06, gnorm=1.999, clip=100, loss_scale=128, train_wall=29, gb_free=11.6, wall=15868
2023-04-19 04:51:29 - progress_bar.py[line:272] - INFO: epoch 010:    337 / 578 loss=2.342, loss_v1=0, loss_v2=0, nll_loss=1.14, ntokens=3078, nsentences=96, sample_size=3078, sample_size_v1=0, sample_size_v2=0, ppl=2.2, wps=1075.5, ups=0.35, wpb=3078, bsz=96, num_updates=5530, lr=6.46933e-06, gnorm=1.963, clip=100, loss_scale=128, train_wall=29, gb_free=12.2, wall=15897
2023-04-19 04:51:57 - progress_bar.py[line:272] - INFO: epoch 010:    347 / 578 loss=2.347, loss_v1=0, loss_v2=0, nll_loss=1.144, ntokens=3254, nsentences=96, sample_size=3254, sample_size_v1=0, sample_size_v2=0, ppl=2.21, wps=1148.6, ups=0.35, wpb=3254, bsz=96, num_updates=5540, lr=6.42331e-06, gnorm=1.827, clip=100, loss_scale=128, train_wall=28, gb_free=12.3, wall=15925
2023-04-19 04:52:25 - progress_bar.py[line:272] - INFO: epoch 010:    357 / 578 loss=2.336, loss_v1=0, loss_v2=0, nll_loss=1.131, ntokens=3051.1, nsentences=96, sample_size=3051.1, sample_size_v1=0, sample_size_v2=0, ppl=2.19, wps=1073.7, ups=0.35, wpb=3051.1, bsz=96, num_updates=5550, lr=6.3773e-06, gnorm=1.917, clip=100, loss_scale=128, train_wall=28, gb_free=12.3, wall=15954
2023-04-19 04:52:54 - progress_bar.py[line:272] - INFO: epoch 010:    367 / 578 loss=2.363, loss_v1=0, loss_v2=0, nll_loss=1.163, ntokens=3404, nsentences=96, sample_size=3404, sample_size_v1=0, sample_size_v2=0, ppl=2.24, wps=1187.2, ups=0.35, wpb=3404, bsz=96, num_updates=5560, lr=6.33129e-06, gnorm=1.831, clip=100, loss_scale=128, train_wall=29, gb_free=11.9, wall=15983
2023-04-19 04:53:23 - progress_bar.py[line:272] - INFO: epoch 010:    377 / 578 loss=2.348, loss_v1=0, loss_v2=0, nll_loss=1.145, ntokens=3377.5, nsentences=96, sample_size=3377.5, sample_size_v1=0, sample_size_v2=0, ppl=2.21, wps=1175.1, ups=0.35, wpb=3377.5, bsz=96, num_updates=5570, lr=6.28528e-06, gnorm=1.78, clip=100, loss_scale=128, train_wall=29, gb_free=12.2, wall=16011
2023-04-19 04:53:51 - progress_bar.py[line:272] - INFO: epoch 010:    387 / 578 loss=2.354, loss_v1=0, loss_v2=0, nll_loss=1.152, ntokens=3212.3, nsentences=96, sample_size=3212.3, sample_size_v1=0, sample_size_v2=0, ppl=2.22, wps=1127.2, ups=0.35, wpb=3212.3, bsz=96, num_updates=5580, lr=6.23926e-06, gnorm=1.949, clip=100, loss_scale=128, train_wall=28, gb_free=12.1, wall=16040
2023-04-19 04:54:20 - progress_bar.py[line:272] - INFO: epoch 010:    397 / 578 loss=2.33, loss_v1=0, loss_v2=0, nll_loss=1.125, ntokens=3167.2, nsentences=96, sample_size=3167.2, sample_size_v1=0, sample_size_v2=0, ppl=2.18, wps=1109.2, ups=0.35, wpb=3167.2, bsz=96, num_updates=5590, lr=6.19325e-06, gnorm=1.851, clip=100, loss_scale=128, train_wall=29, gb_free=12.1, wall=16068
2023-04-19 04:54:40 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 128.0
2023-04-19 04:54:51 - progress_bar.py[line:272] - INFO: epoch 010:    408 / 578 loss=2.338, loss_v1=0, loss_v2=0, nll_loss=1.135, ntokens=3022.8, nsentences=96, sample_size=3022.8, sample_size_v1=0, sample_size_v2=0, ppl=2.2, wps=966.2, ups=0.32, wpb=3022.8, bsz=96, num_updates=5600, lr=6.14724e-06, gnorm=2.005, clip=100, loss_scale=128, train_wall=31, gb_free=12.4, wall=16100
2023-04-19 04:55:20 - progress_bar.py[line:272] - INFO: epoch 010:    418 / 578 loss=2.352, loss_v1=0, loss_v2=0, nll_loss=1.149, ntokens=3024.6, nsentences=96, sample_size=3024.6, sample_size_v1=0, sample_size_v2=0, ppl=2.22, wps=1058.6, ups=0.35, wpb=3024.6, bsz=96, num_updates=5610, lr=6.10123e-06, gnorm=1.977, clip=100, loss_scale=128, train_wall=29, gb_free=12.4, wall=16128
2023-04-19 04:55:48 - progress_bar.py[line:272] - INFO: epoch 010:    428 / 578 loss=2.325, loss_v1=0, loss_v2=0, nll_loss=1.121, ntokens=3057.8, nsentences=96, sample_size=3057.8, sample_size_v1=0, sample_size_v2=0, ppl=2.17, wps=1078.8, ups=0.35, wpb=3057.8, bsz=96, num_updates=5620, lr=6.05521e-06, gnorm=1.897, clip=100, loss_scale=128, train_wall=28, gb_free=12.2, wall=16157
2023-04-19 04:56:16 - progress_bar.py[line:272] - INFO: epoch 010:    438 / 578 loss=2.363, loss_v1=0, loss_v2=0, nll_loss=1.162, ntokens=2936.4, nsentences=96, sample_size=2936.4, sample_size_v1=0, sample_size_v2=0, ppl=2.24, wps=1036.7, ups=0.35, wpb=2936.4, bsz=96, num_updates=5630, lr=6.0092e-06, gnorm=1.947, clip=100, loss_scale=128, train_wall=28, gb_free=12.4, wall=16185
2023-04-19 04:56:45 - progress_bar.py[line:272] - INFO: epoch 010:    448 / 578 loss=2.351, loss_v1=0, loss_v2=0, nll_loss=1.149, ntokens=3043.6, nsentences=96, sample_size=3043.6, sample_size_v1=0, sample_size_v2=0, ppl=2.22, wps=1066.1, ups=0.35, wpb=3043.6, bsz=96, num_updates=5640, lr=5.96319e-06, gnorm=1.866, clip=100, loss_scale=128, train_wall=29, gb_free=12.3, wall=16213
2023-04-19 04:57:13 - progress_bar.py[line:272] - INFO: epoch 010:    458 / 578 loss=2.332, loss_v1=0, loss_v2=0, nll_loss=1.129, ntokens=3029.5, nsentences=96, sample_size=3029.5, sample_size_v1=0, sample_size_v2=0, ppl=2.19, wps=1064.8, ups=0.35, wpb=3029.5, bsz=96, num_updates=5650, lr=5.91718e-06, gnorm=1.929, clip=100, loss_scale=128, train_wall=28, gb_free=12, wall=16242
2023-04-19 04:57:42 - progress_bar.py[line:272] - INFO: epoch 010:    468 / 578 loss=2.349, loss_v1=0, loss_v2=0, nll_loss=1.147, ntokens=3101.1, nsentences=96, sample_size=3101.1, sample_size_v1=0, sample_size_v2=0, ppl=2.21, wps=1081.1, ups=0.35, wpb=3101.1, bsz=96, num_updates=5660, lr=5.87117e-06, gnorm=1.799, clip=100, loss_scale=128, train_wall=29, gb_free=12.5, wall=16271
2023-04-19 04:58:10 - progress_bar.py[line:272] - INFO: epoch 010:    478 / 578 loss=2.362, loss_v1=0, loss_v2=0, nll_loss=1.159, ntokens=2890.6, nsentences=96, sample_size=2890.6, sample_size_v1=0, sample_size_v2=0, ppl=2.23, wps=1014, ups=0.35, wpb=2890.6, bsz=96, num_updates=5670, lr=5.82515e-06, gnorm=1.943, clip=100, loss_scale=128, train_wall=28, gb_free=12.5, wall=16299
2023-04-19 04:58:39 - progress_bar.py[line:272] - INFO: epoch 010:    488 / 578 loss=2.321, loss_v1=0, loss_v2=0, nll_loss=1.117, ntokens=2994.7, nsentences=96, sample_size=2994.7, sample_size_v1=0, sample_size_v2=0, ppl=2.17, wps=1052.3, ups=0.35, wpb=2994.7, bsz=96, num_updates=5680, lr=5.77914e-06, gnorm=1.801, clip=100, loss_scale=128, train_wall=28, gb_free=12.2, wall=16328
2023-04-19 04:59:08 - progress_bar.py[line:272] - INFO: epoch 010:    498 / 578 loss=2.316, loss_v1=0, loss_v2=0, nll_loss=1.112, ntokens=3221.3, nsentences=96, sample_size=3221.3, sample_size_v1=0, sample_size_v2=0, ppl=2.16, wps=1127.8, ups=0.35, wpb=3221.3, bsz=96, num_updates=5690, lr=5.73313e-06, gnorm=1.839, clip=100, loss_scale=128, train_wall=29, gb_free=12.1, wall=16356
2023-04-19 04:59:36 - progress_bar.py[line:272] - INFO: epoch 010:    508 / 578 loss=2.334, loss_v1=0, loss_v2=0, nll_loss=1.129, ntokens=3137.1, nsentences=96, sample_size=3137.1, sample_size_v1=0, sample_size_v2=0, ppl=2.19, wps=1096.1, ups=0.35, wpb=3137.1, bsz=96, num_updates=5700, lr=5.68712e-06, gnorm=1.753, clip=100, loss_scale=128, train_wall=29, gb_free=12.6, wall=16385
2023-04-19 05:00:05 - progress_bar.py[line:272] - INFO: epoch 010:    518 / 578 loss=2.317, loss_v1=0, loss_v2=0, nll_loss=1.111, ntokens=3282.2, nsentences=96, sample_size=3282.2, sample_size_v1=0, sample_size_v2=0, ppl=2.16, wps=1152.2, ups=0.35, wpb=3282.2, bsz=96, num_updates=5710, lr=5.6411e-06, gnorm=1.829, clip=100, loss_scale=128, train_wall=28, gb_free=12.4, wall=16413
2023-04-19 05:00:33 - progress_bar.py[line:272] - INFO: epoch 010:    528 / 578 loss=2.342, loss_v1=0, loss_v2=0, nll_loss=1.139, ntokens=3058.8, nsentences=96, sample_size=3058.8, sample_size_v1=0, sample_size_v2=0, ppl=2.2, wps=1080.5, ups=0.35, wpb=3058.8, bsz=96, num_updates=5720, lr=5.59509e-06, gnorm=1.956, clip=100, loss_scale=128, train_wall=28, gb_free=12.4, wall=16442
2023-04-19 05:01:01 - progress_bar.py[line:272] - INFO: epoch 010:    538 / 578 loss=2.33, loss_v1=0, loss_v2=0, nll_loss=1.125, ntokens=3009.9, nsentences=96, sample_size=3009.9, sample_size_v1=0, sample_size_v2=0, ppl=2.18, wps=1062, ups=0.35, wpb=3009.9, bsz=96, num_updates=5730, lr=5.54908e-06, gnorm=1.964, clip=100, loss_scale=128, train_wall=28, gb_free=12.4, wall=16470
2023-04-19 05:01:30 - progress_bar.py[line:272] - INFO: epoch 010:    548 / 578 loss=2.324, loss_v1=0, loss_v2=0, nll_loss=1.119, ntokens=3168.2, nsentences=96, sample_size=3168.2, sample_size_v1=0, sample_size_v2=0, ppl=2.17, wps=1103.6, ups=0.35, wpb=3168.2, bsz=96, num_updates=5740, lr=5.50307e-06, gnorm=1.889, clip=100, loss_scale=128, train_wall=29, gb_free=11.4, wall=16499
2023-04-19 05:01:59 - progress_bar.py[line:272] - INFO: epoch 010:    558 / 578 loss=2.322, loss_v1=0, loss_v2=0, nll_loss=1.115, ntokens=3241.8, nsentences=96, sample_size=3241.8, sample_size_v1=0, sample_size_v2=0, ppl=2.17, wps=1118.3, ups=0.34, wpb=3241.8, bsz=96, num_updates=5750, lr=5.45706e-06, gnorm=1.676, clip=100, loss_scale=128, train_wall=29, gb_free=12.6, wall=16528
2023-04-19 05:02:28 - progress_bar.py[line:272] - INFO: epoch 010:    568 / 578 loss=2.327, loss_v1=0, loss_v2=0, nll_loss=1.122, ntokens=3281.3, nsentences=96, sample_size=3281.3, sample_size_v1=0, sample_size_v2=0, ppl=2.18, wps=1141.9, ups=0.35, wpb=3281.3, bsz=96, num_updates=5760, lr=5.41104e-06, gnorm=1.8, clip=100, loss_scale=128, train_wall=29, gb_free=12.6, wall=16556
slice_id 1 seek offset 11440
2023-04-19 05:02:54 - progress_bar.py[line:272] - INFO: epoch 010:    578 / 578 loss=2.343, loss_v1=0, loss_v2=0, nll_loss=1.142, ntokens=2804.6, nsentences=87.2, sample_size=2804.6, sample_size_v1=0, sample_size_v2=0, ppl=2.21, wps=1080.8, ups=0.39, wpb=2804.6, bsz=87.2, num_updates=5770, lr=5.36503e-06, gnorm=2.029, clip=100, loss_scale=128, train_wall=26, gb_free=13.1, wall=16582
2023-04-19 05:02:54 - train.py[line:445] - INFO: begin validation on "valid" subset
slice_id 0 seek offset 0
slice_id 1 seek offset 11440
slice_id 0 seek offset 0
/home/zcai75/Github/OFA/fairseq/fairseq/search.py:140: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  beams_buf = indices_buf // vocab_size
/home/zcai75/Github/OFA/fairseq/fairseq/search.py:140: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  beams_buf = indices_buf // vocab_size
/home/zcai75/Github/OFA_forked/models/sequence_generator.py:705: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  unfin_idx = bbsz_idx // beam_size
/home/zcai75/Github/OFA_forked/models/sequence_generator.py:705: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  unfin_idx = bbsz_idx // beam_size
2343729 <sub> train<pred> on<obj> track<sub> window<pred> on<obj> train<sub> window<pred> on<obj> train<sub> window<pred> on<obj> train<sub> window<pred> on<obj> train ['<sub> windshield<pred> on<obj> train<sub> window<pred> on<obj> train<sub> train<pred> has<obj> window<sub> house<pred> near<obj> train<sub> tree<pred> near<obj> house']
2325977 <sub> man<pred> holding<obj> racket<pred> wearing<obj> shirt<pred> wearing<obj> short<pred> wearing<obj> shirt<sub> racket<pred> in<obj> hand ['<sub> head<pred> of<obj> bear<sub> bear<pred> in<obj> bowl<sub> bowl<pred> with<obj> bear']
2023-04-19 05:03:05 - progress_bar.py[line:272] - INFO: epoch 010 | valid on 'valid' subset:     11 / 1907 loss=2.295, loss_v1=0, loss_v2=0, nll_loss=1.057, ntokens=426, nsentences=12, sample_size=426.0, sample_size_v1=0, sample_size_v2=0
2023-04-19 05:03:15 - progress_bar.py[line:272] - INFO: epoch 010 | valid on 'valid' subset:     21 / 1907 loss=2.33, loss_v1=0, loss_v2=0, nll_loss=1.094, ntokens=527, nsentences=12, sample_size=527.0, sample_size_v1=0, sample_size_v2=0
2023-04-19 05:03:24 - progress_bar.py[line:272] - INFO: epoch 010 | valid on 'valid' subset:     31 / 1907 loss=2.406, loss_v1=0, loss_v2=0, nll_loss=1.18, ntokens=420, nsentences=12, sample_size=420.0, sample_size_v1=0, sample_size_v2=0
2023-04-19 05:03:36 - progress_bar.py[line:272] - INFO: epoch 010 | valid on 'valid' subset:     41 / 1907 loss=2.216, loss_v1=0, loss_v2=0, nll_loss=0.969, ntokens=426, nsentences=12, sample_size=426.0, sample_size_v1=0, sample_size_v2=0
2325510 <sub> window<pred> on<obj> building<sub> window<pred> on<obj> building<sub> window<pred> on<obj> building<sub> window<pred> on<obj> building<sub> window<pred> on<obj> building<sub> window<pred> on<obj> building ['<sub> window<pred> on<obj> building<sub> window<pred> on<obj> building<sub> window<pred> on<obj> building<sub> window<pred> on<obj> building<sub> window<pred> on<obj> building<sub> window<pred> on<obj> building<sub> light<pred> on<obj> street']
2343357 <sub> eye<pred> of<obj> cat<sub> eye<pred> of<obj> cat<sub> eye<pred> of<obj> cat<sub> eye<pred> of<obj> cat<sub> eye<pred> of<obj> cat<sub> eye<pred> of<obj> cat<sub> eye<pred> of<obj> cat<sub> eye<pred> of<obj> cat<sub> eye<pred> of<obj> cat<sub> eye<pred> of<obj> cat<sub> eye<pred> of<obj> cat<sub> eye<pred> of<obj> cat<sub> eye<pred> of<obj> cat<sub> eye<pred> of<obj> cat<sub> eye<pred> of<obj> cat<sub> eye<pred> of<obj> cat ['<sub> bird<pred> has<obj> head<pred> near<obj> tree<sub> neck<pred> of<obj> bird<sub> branch<pred> near<obj> bird<sub> hair<pred> on<obj> bird']
2023-04-19 05:03:46 - progress_bar.py[line:272] - INFO: epoch 010 | valid on 'valid' subset:     51 / 1907 loss=2.26, loss_v1=0, loss_v2=0, nll_loss=1.018, ntokens=447, nsentences=12, sample_size=447.0, sample_size_v1=0, sample_size_v2=0
2023-04-19 05:03:57 - progress_bar.py[line:272] - INFO: epoch 010 | valid on 'valid' subset:     61 / 1907 loss=2.298, loss_v1=0, loss_v2=0, nll_loss=1.06, ntokens=458, nsentences=12, sample_size=458.0, sample_size_v1=0, sample_size_v2=0
2023-04-19 05:04:08 - progress_bar.py[line:272] - INFO: epoch 010 | valid on 'valid' subset:     71 / 1907 loss=2.315, loss_v1=0, loss_v2=0, nll_loss=1.078, ntokens=442, nsentences=12, sample_size=442.0, sample_size_v1=0, sample_size_v2=0
2023-04-19 05:04:19 - progress_bar.py[line:272] - INFO: epoch 010 | valid on 'valid' subset:     81 / 1907 loss=2.356, loss_v1=0, loss_v2=0, nll_loss=1.129, ntokens=377, nsentences=12, sample_size=377.0, sample_size_v1=0, sample_size_v2=0
2023-04-19 05:04:30 - progress_bar.py[line:272] - INFO: epoch 010 | valid on 'valid' subset:     91 / 1907 loss=2.253, loss_v1=0, loss_v2=0, nll_loss=1.006, ntokens=389, nsentences=12, sample_size=389.0, sample_size_v1=0, sample_size_v2=0
2342980 <sub> skier<pred> on<obj> snow<sub> skier<pred> on<obj> snow<sub> skier<pred> on<obj> snow<sub> skier<pred> on<obj> snow<sub> skier<pred> on<obj> snow<sub> skier<pred> on<obj> snow<sub> skier<pred> on<obj> snow<sub> skier<pred> on<obj> snow<sub> skier<pred> on<obj> snow ['<sub> snow<pred> covering<obj> mountain<sub> snow<pred> on<obj> roof<sub> roof<pred> on<obj> building<sub> railing<pred> of<obj> building<sub> pant<pred> of<obj> skier<sub> skier<pred> holding<obj> pole<sub> person<pred> holding<obj> pole<pred> using<obj> ski<sub> person<pred> on<obj> ski<sub> people<pred> on<obj> snow<sub> man<pred> wearing<obj> pant<sub> snow<pred> covering<obj> tree<sub> pole<pred> on<obj> man<sub> snow<pred> on<obj> roof']
2325083 <sub> man<pred> wearing<obj> tie<pred> wearing<obj> shirt<pred> has<obj> nose<pred> has<obj> eye<pred> has<obj> eye<pred> has<obj> eye<pred> has<obj> eye<pred> has<obj> eye<pred> has<obj> eye<pred> has<obj> eye<pred> has<obj> eye<pred> has<obj> eye<pred> has<obj> eye<pred> has<obj> eye<pred> has<obj> eye<pred> has<obj> eye<pred> has<obj> eye<pred> has<obj> eye<pred> has<obj> eye<pred> has<obj> eye<pred> has<obj> eye<pred> has<obj> eye<pred> has<obj> eye<pred> has<obj> eye<pred> has<obj> tie<pred> has<obj> tie<pred> has<obj> tie<pred> has<obj> shirt<pred> has<obj> tie<pred> has<obj> tie<pred> has<obj> shirt<pred> has<obj> shirt<pred> has<obj> tie<pred> has<obj> tie<pred> has<obj> tie<pred> has<obj> tie<pred> has<obj> shirt<pred> has<obj> tie<pred> has<obj> tie<pred> has<obj> shirt<pred> has<obj> tie<pred> has<obj> tie<pred> has<obj> shirt<pred> has<obj> tie<pred> has<obj> tie<pred> has<obj> shirt<pred> has<obj> tie<pred> has<obj> tie<pred> has<obj> shirt<pred> has ['<sub> cat<pred> in front of<obj> window<pred> laying on<obj> desk<pred> has<obj> ear<pred> has<obj> eye<pred> has<obj> eye<pred> has<obj> nose<pred> has<obj> paw<pred> has<obj> paw<pred> has<obj> head']
2023-04-19 05:04:40 - progress_bar.py[line:272] - INFO: epoch 010 | valid on 'valid' subset:    101 / 1907 loss=2.278, loss_v1=0, loss_v2=0, nll_loss=1.032, ntokens=514, nsentences=12, sample_size=514.0, sample_size_v1=0, sample_size_v2=0
2023-04-19 05:04:51 - progress_bar.py[line:272] - INFO: epoch 010 | valid on 'valid' subset:    111 / 1907 loss=2.421, loss_v1=0, loss_v2=0, nll_loss=1.2, ntokens=547, nsentences=12, sample_size=547.0, sample_size_v1=0, sample_size_v2=0
2023-04-19 05:05:03 - progress_bar.py[line:272] - INFO: epoch 010 | valid on 'valid' subset:    121 / 1907 loss=2.291, loss_v1=0, loss_v2=0, nll_loss=1.051, ntokens=528, nsentences=12, sample_size=528.0, sample_size_v1=0, sample_size_v2=0
2023-04-19 05:05:13 - progress_bar.py[line:272] - INFO: epoch 010 | valid on 'valid' subset:    131 / 1907 loss=2.294, loss_v1=0, loss_v2=0, nll_loss=1.058, ntokens=359, nsentences=12, sample_size=359.0, sample_size_v1=0, sample_size_v2=0
2023-04-19 05:05:24 - progress_bar.py[line:272] - INFO: epoch 010 | valid on 'valid' subset:    141 / 1907 loss=2.229, loss_v1=0, loss_v2=0, nll_loss=0.977, ntokens=733, nsentences=12, sample_size=733.0, sample_size_v1=0, sample_size_v2=0
2324656 <sub> sign<pred> on<obj> pole<sub> sign<pred> on<obj> pole<sub> sign<pred> on<obj> pole<sub> sign<pred> on<obj> pole<sub> sign<pred> on<obj> pole<sub> sign<pred> on<obj> pole<sub> sign<pred> on<obj> pole ['<sub> rock<pred> on<obj> hill<sub> building<pred> in<obj> snow<sub> boy<pred> on<obj> ski<sub> roof<pred> on<obj> building<sub> tree<pred> near<obj> building<sub> tree<pred> on<obj> hill']
2342579 <sub> giraffe<pred> has<obj> leg<pred> has<obj> leg<pred> has<obj> leg<pred> has<obj> leg<pred> has<obj> leg<pred> has<obj> leg<pred> has<obj> leg<pred> has<obj> leg<pred> has<obj> leg<pred> has<obj> leg<pred> has<obj> leg<pred> has<obj> leg<pred> has<obj> leg<pred> has<obj> leg<pred> has<obj> leg<pred> has<obj> leg<pred> has<obj> leg<pred> has<obj> leg<pred> has<obj> leg<pred> has<obj> leg<pred> has<obj> leg<pred> has<obj> leg<pred> has<obj> leg<pred> has<obj> leg<pred> ['<sub> tree<pred> behind<obj> giraffe<pred> behind<obj> giraffe<pred> behind<obj> giraffe<sub> leg<pred> of<obj> giraffe<sub> leg<pred> on<obj> giraffe<sub> leg<pred> of<obj> giraffe<sub> leg<pred> of<obj> giraffe<sub> leg<pred> of<obj> giraffe<sub> leg<pred> of<obj> giraffe<sub> giraffe<pred> has<obj> tail<pred> has<obj> neck<sub> giraffe<pred> has<obj> head<pred> near<obj> giraffe']
2023-04-19 05:05:34 - progress_bar.py[line:272] - INFO: epoch 010 | valid on 'valid' subset:    151 / 1907 loss=2.196, loss_v1=0, loss_v2=0, nll_loss=0.942, ntokens=475, nsentences=12, sample_size=475.0, sample_size_v1=0, sample_size_v2=0
2023-04-19 05:05:44 - progress_bar.py[line:272] - INFO: epoch 010 | valid on 'valid' subset:    161 / 1907 loss=2.262, loss_v1=0, loss_v2=0, nll_loss=1.021, ntokens=538, nsentences=12, sample_size=538.0, sample_size_v1=0, sample_size_v2=0
2023-04-19 05:05:55 - progress_bar.py[line:272] - INFO: epoch 010 | valid on 'valid' subset:    171 / 1907 loss=2.394, loss_v1=0, loss_v2=0, nll_loss=1.166, ntokens=520, nsentences=12, sample_size=520.0, sample_size_v1=0, sample_size_v2=0
2023-04-19 05:06:06 - progress_bar.py[line:272] - INFO: epoch 010 | valid on 'valid' subset:    181 / 1907 loss=2.366, loss_v1=0, loss_v2=0, nll_loss=1.136, ntokens=568, nsentences=12, sample_size=568.0, sample_size_v1=0, sample_size_v2=0
2023-04-19 05:06:15 - progress_bar.py[line:272] - INFO: epoch 010 | valid on 'valid' subset:    191 / 1907 loss=2.307, loss_v1=0, loss_v2=0, nll_loss=1.072, ntokens=304, nsentences=12, sample_size=304.0, sample_size_v1=0, sample_size_v2=0
2342212 <sub> window<pred> on<obj> building<sub> window<pred> on<obj> building<sub> window<pred> on<obj> building<sub> window<pred> on<obj> building<sub> window<pred> on<obj> building<sub> window<pred> on<obj> building<sub> window<pred> on<obj> building<sub> window<pred> on<obj> building<sub> window<pred> on<obj> building<sub> window<pred> on<obj> building ['<sub> kid<pred> near<obj> bike<sub> sign<pred> near<obj> building<sub> man<pred> on<obj> street<sub> bike<pred> has<obj> tire<pred> near<obj> stand<pred> parked on<obj> street<sub> people<pred> under<obj> umbrella<pred> walking on<obj> street<sub> boy<pred> near<obj> bike<sub> man<pred> wears<obj> shirt<pred> wears<obj> short<sub> woman<pred> wearing<obj> shirt<sub> person<pred> wearing<obj> shirt']
2324219 <sub> dog<pred> has<obj> nose<pred> has<obj> ear<pred> has<obj> ear<pred> has<obj> ear<pred> has<obj> ear<pred> has<obj> ear ['<sub> boy<pred> carrying<obj> helmet<pred> wearing<obj> glove<sub> player<pred> behind<obj> boy']
2023-04-19 05:06:26 - progress_bar.py[line:272] - INFO: epoch 010 | valid on 'valid' subset:    201 / 1907 loss=2.423, loss_v1=0, loss_v2=0, nll_loss=1.196, ntokens=525, nsentences=12, sample_size=525.0, sample_size_v1=0, sample_size_v2=0
2023-04-19 05:06:36 - progress_bar.py[line:272] - INFO: epoch 010 | valid on 'valid' subset:    211 / 1907 loss=2.434, loss_v1=0, loss_v2=0, nll_loss=1.213, ntokens=337, nsentences=12, sample_size=337.0, sample_size_v1=0, sample_size_v2=0
2023-04-19 05:06:47 - progress_bar.py[line:272] - INFO: epoch 010 | valid on 'valid' subset:    221 / 1907 loss=2.361, loss_v1=0, loss_v2=0, nll_loss=1.132, ntokens=478, nsentences=12, sample_size=478.0, sample_size_v1=0, sample_size_v2=0
2023-04-19 05:06:58 - progress_bar.py[line:272] - INFO: epoch 010 | valid on 'valid' subset:    231 / 1907 loss=2.196, loss_v1=0, loss_v2=0, nll_loss=0.946, ntokens=329, nsentences=12, sample_size=329.0, sample_size_v1=0, sample_size_v2=0
2023-04-19 05:07:08 - progress_bar.py[line:272] - INFO: epoch 010 | valid on 'valid' subset:    241 / 1907 loss=2.365, loss_v1=0, loss_v2=0, nll_loss=1.137, ntokens=373, nsentences=12, sample_size=373.0, sample_size_v1=0, sample_size_v2=0
2323784 <sub> chair<pred> near<obj> table<sub> chair<pred> near<obj> table<sub> chair<pred> near<obj> table<sub> chair<pred> near<obj> table<sub> chair<pred> near<obj> table<sub> chair<pred> near<obj> table ['<sub> cat<pred> at<obj> window<pred> near<obj> door<sub> window<pred> covering<obj> window']
2341845 <sub> man<pred> wearing<obj> jacket<pred> wearing<obj> pant<pred> wearing<obj> jacket<sub> man<pred> wearing<obj> jacket<pred> wearing<obj> pant<pred> wearing<obj> jacket<pred> wearing<obj> pant<pred> wearing<obj> jacket<sub> tree<pred> behind<obj> man<sub> tree<pred> behind<obj> man<sub> tree<pred> behind<obj> man<sub> tree<pred> behind<obj> man ['<sub> man<pred> on<obj> ski<pred> on<obj> snow<sub> ski<pred> on<obj> snow<sub> man<pred> wearing<obj> jacket<pred> on<obj> snow<sub> woman<pred> standing on<obj> snow<sub> hat<pred> on<obj> man<sub> tree<pred> behind<obj> man']
2023-04-19 05:07:20 - progress_bar.py[line:272] - INFO: epoch 010 | valid on 'valid' subset:    251 / 1907 loss=2.461, loss_v1=0, loss_v2=0, nll_loss=1.241, ntokens=456, nsentences=12, sample_size=456.0, sample_size_v1=0, sample_size_v2=0
2023-04-19 05:07:30 - progress_bar.py[line:272] - INFO: epoch 010 | valid on 'valid' subset:    261 / 1907 loss=2.282, loss_v1=0, loss_v2=0, nll_loss=1.046, ntokens=630, nsentences=12, sample_size=630.0, sample_size_v1=0, sample_size_v2=0
2023-04-19 05:07:40 - progress_bar.py[line:272] - INFO: epoch 010 | valid on 'valid' subset:    271 / 1907 loss=2.402, loss_v1=0, loss_v2=0, nll_loss=1.179, ntokens=375, nsentences=12, sample_size=375.0, sample_size_v1=0, sample_size_v2=0
2023-04-19 05:07:52 - progress_bar.py[line:272] - INFO: epoch 010 | valid on 'valid' subset:    281 / 1907 loss=2.362, loss_v1=0, loss_v2=0, nll_loss=1.132, ntokens=356, nsentences=12, sample_size=356.0, sample_size_v1=0, sample_size_v2=0
2023-04-19 05:08:03 - progress_bar.py[line:272] - INFO: epoch 010 | valid on 'valid' subset:    291 / 1907 loss=2.337, loss_v1=0, loss_v2=0, nll_loss=1.105, ntokens=387, nsentences=12, sample_size=387.0, sample_size_v1=0, sample_size_v2=0
2323363 <sub> train<pred> on<obj> track<sub> window<pred> on<obj> train<sub> window<pred> on<obj> train<sub> window<pred> on<obj> train<sub> window<pred> on<obj> train<sub> window<pred> on<obj> train<sub> window<pred> on<obj> train ['<sub> rock<pred> on<obj> track<pred> on<obj> track<pred> on<obj> track<sub> rock<pred> on<obj> track<sub> man<pred> near<obj> train<sub> window<pred> on<obj> train<sub> window<pred> on<obj> train<sub> window<pred> on<obj> train']
2341458 <sub> giraffe<pred> has<obj> leg<pred> has<obj> leg<pred> has<obj> leg<pred> has<obj> leg<pred> has<obj> leg<pred> has<obj> leg<pred> has<obj> leg<pred> has<obj> leg<pred> has<obj> leg ['<sub> man<pred> wearing<obj> shirt<pred> near<obj> truck<sub> man<pred> wearing<obj> shirt<sub> truck<pred> has<obj> tire<sub> windshield<pred> on<obj> truck']
2023-04-19 05:08:13 - progress_bar.py[line:272] - INFO: epoch 010 | valid on 'valid' subset:    301 / 1907 loss=2.244, loss_v1=0, loss_v2=0, nll_loss=1.001, ntokens=457, nsentences=12, sample_size=457.0, sample_size_v1=0, sample_size_v2=0
2023-04-19 05:08:22 - progress_bar.py[line:272] - INFO: epoch 010 | valid on 'valid' subset:    311 / 1907 loss=2.336, loss_v1=0, loss_v2=0, nll_loss=1.099, ntokens=554, nsentences=12, sample_size=554.0, sample_size_v1=0, sample_size_v2=0
2023-04-19 05:08:33 - progress_bar.py[line:272] - INFO: epoch 010 | valid on 'valid' subset:    321 / 1907 loss=2.2, loss_v1=0, loss_v2=0, nll_loss=0.949, ntokens=405, nsentences=12, sample_size=405.0, sample_size_v1=0, sample_size_v2=0
2023-04-19 05:08:43 - progress_bar.py[line:272] - INFO: epoch 010 | valid on 'valid' subset:    331 / 1907 loss=2.291, loss_v1=0, loss_v2=0, nll_loss=1.053, ntokens=394, nsentences=12, sample_size=394.0, sample_size_v1=0, sample_size_v2=0
2023-04-19 05:08:52 - progress_bar.py[line:272] - INFO: epoch 010 | valid on 'valid' subset:    341 / 1907 loss=2.272, loss_v1=0, loss_v2=0, nll_loss=1.028, ntokens=341, nsentences=12, sample_size=341.0, sample_size_v1=0, sample_size_v2=0
2322919 <sub> skier<pred> on<obj> snow<sub> skier<pred> on<obj> snow<sub> skier<pred> on<obj> snow<sub> skier<pred> on<obj> snow<sub> skier<pred> on<obj> snow<sub> skier<pred> on<obj> snow<sub> skier<pred> on<obj> snow ['<sub> child<pred> wearing<obj> helmet<sub> skier<pred> wears<obj> boot<sub> ski<pred> of<obj> child<sub> ski<pred> of<obj> child<sub> boot<pred> of<obj> skier<pred> of<obj> skier']
2341014 <sub> man<pred> wearing<obj> jacket<pred> wearing<obj> pant<pred> wearing<obj> jacket<pred> wearing<obj> pant<sub> man<pred> wearing<obj> jacket<pred> wearing<obj> pant<pred> wearing<obj> jacket<pred> wearing<obj> pant<pred> wearing<obj> jacket<pred> wearing<obj> pant<pred> wearing<obj> jacket<pred> wearing<obj> pant<sub> tree<pred> behind<obj> man<sub> tree<pred> behind<obj> man<sub> tree<pred> behind<obj> man<sub> tree<pred> behind<obj> man ['<sub> person<pred> wearing<obj> jacket<pred> holding<obj> pole<pred> wearing<obj> pant<sub> person<pred> wearing<obj> jacket<pred> has<obj> ski<pred> wearing<obj> jacket']
2023-04-19 05:09:01 - progress_bar.py[line:272] - INFO: epoch 010 | valid on 'valid' subset:    351 / 1907 loss=2.31, loss_v1=0, loss_v2=0, nll_loss=1.074, ntokens=463, nsentences=12, sample_size=463.0, sample_size_v1=0, sample_size_v2=0
2023-04-19 05:09:10 - progress_bar.py[line:272] - INFO: epoch 010 | valid on 'valid' subset:    361 / 1907 loss=2.381, loss_v1=0, loss_v2=0, nll_loss=1.154, ntokens=356, nsentences=12, sample_size=356.0, sample_size_v1=0, sample_size_v2=0
2023-04-19 05:09:18 - progress_bar.py[line:272] - INFO: epoch 010 | valid on 'valid' subset:    371 / 1907 loss=2.281, loss_v1=0, loss_v2=0, nll_loss=1.044, ntokens=423, nsentences=12, sample_size=423.0, sample_size_v1=0, sample_size_v2=0
2023-04-19 05:09:26 - progress_bar.py[line:272] - INFO: epoch 010 | valid on 'valid' subset:    381 / 1907 loss=2.249, loss_v1=0, loss_v2=0, nll_loss=1.008, ntokens=461, nsentences=12, sample_size=461.0, sample_size_v1=0, sample_size_v2=0
2023-04-19 05:09:37 - progress_bar.py[line:272] - INFO: epoch 010 | valid on 'valid' subset:    391 / 1907 loss=2.175, loss_v1=0, loss_v2=0, nll_loss=0.92, ntokens=406, nsentences=12, sample_size=406.0, sample_size_v1=0, sample_size_v2=0
2340556 <sub> window<pred> on<obj> building<sub> window<pred> on<obj> building<sub> window<pred> on<obj> building<sub> window<pred> on<obj> building<sub> window<pred> on<obj> building<sub> window<pred> on<obj> building<sub> window<pred> on<obj> building ['<sub> person<pred> holding<obj> jacket<pred> wearing<obj> shirt<pred> wearing<obj> pant<pred> wearing<obj> shoe<sub> woman<pred> carrying<obj> bag<pred> wearing<obj> pant<sub> person<pred> holding<obj> bag<sub> wheel<pred> on<obj> airplane<sub> guy<pred> wearing<obj> short<sub> guy<pred> wearing<obj> shirt<pred> wearing<obj> pant']
2322487 <sub> sheep<pred> has<obj> leg<pred> has<obj> leg<pred> has<obj> leg<pred> has<obj> leg<pred> has<obj> leg<pred> has<obj> leg<pred> has<obj> leg<pred> has<obj> leg<pred> has<obj> leg<pred> has<obj> leg<pred> has<obj> leg<pred> has<obj> leg<pred> has<obj> leg<pred> has<obj> leg<pred> has<obj> leg<pred> has<obj> leg<pred> has<obj> leg<pred> has<obj> leg<pred> has<obj> leg<pred> has<obj> leg<pred> has<obj> leg<pred> has<obj> leg<pred> has<obj> leg<pred> has<obj> leg<pred> has ['<sub> man<pred> holding<obj> bottle<pred> holding<obj> umbrella<pred> holding<obj> umbrella<sub> umbrella<pred> over<obj> man<sub> umbrella<pred> over<obj> man<sub> man<pred> holding<obj> umbrella<sub> man<pred> holding<obj> bottle']
2023-04-19 05:09:48 - progress_bar.py[line:272] - INFO: epoch 010 | valid on 'valid' subset:    401 / 1907 loss=2.404, loss_v1=0, loss_v2=0, nll_loss=1.179, ntokens=421, nsentences=12, sample_size=421.0, sample_size_v1=0, sample_size_v2=0
2023-04-19 05:09:58 - progress_bar.py[line:272] - INFO: epoch 010 | valid on 'valid' subset:    411 / 1907 loss=2.388, loss_v1=0, loss_v2=0, nll_loss=1.156, ntokens=310, nsentences=12, sample_size=310.0, sample_size_v1=0, sample_size_v2=0
2023-04-19 05:10:08 - progress_bar.py[line:272] - INFO: epoch 010 | valid on 'valid' subset:    421 / 1907 loss=2.326, loss_v1=0, loss_v2=0, nll_loss=1.091, ntokens=394, nsentences=12, sample_size=394.0, sample_size_v1=0, sample_size_v2=0
2023-04-19 05:10:18 - progress_bar.py[line:272] - INFO: epoch 010 | valid on 'valid' subset:    431 / 1907 loss=2.301, loss_v1=0, loss_v2=0, nll_loss=1.061, ntokens=494, nsentences=12, sample_size=494.0, sample_size_v1=0, sample_size_v2=0
2023-04-19 05:10:30 - progress_bar.py[line:272] - INFO: epoch 010 | valid on 'valid' subset:    441 / 1907 loss=2.409, loss_v1=0, loss_v2=0, nll_loss=1.183, ntokens=391, nsentences=12, sample_size=391.0, sample_size_v1=0, sample_size_v2=0
2322052 <sub> track<pred> in<obj> snow<sub> track<pred> in<obj> snow<sub> track<pred> in<obj> snow<sub> track<pred> in<obj> snow<sub> track<pred> in<obj> snow ['<sub> track<pred> on<obj> snow<sub> pant<pred> on<obj> man<sub> coat<pred> on<obj> man']
2340058 <sub> ear<pred> of<obj> sheep<sub> ear<pred> of<obj> sheep<sub> ear<pred> of<obj> sheep<sub> ear<pred> of<obj> sheep<sub> ear<pred> of<obj> sheep<sub> ear<pred> of<obj> sheep<sub> leg<pred> of<obj> sheep<sub> leg<pred> of<obj> sheep<sub> leg<pred> of<obj> sheep<sub> leg<pred> of<obj> sheep<sub> leg<pred> of<obj> sheep<sub> leg<pred> of<obj> sheep<sub> leg<pred> of<obj> sheep<sub> leg<pred> of<obj> sheep ['<sub> nose<pred> of<obj> sheep<sub> head<pred> of<obj> sheep<sub> ear<pred> of<obj> sheep<sub> ear<pred> of<obj> sheep<sub> sheep<pred> has<obj> leg<pred> has<obj> ear<pred> has<obj> eye<pred> has<obj> nose<sub> sheep<pred> has<obj> ear<pred> has<obj> ear<sub> person<pred> has<obj> hand<pred> wearing<obj> arm']
2023-04-19 05:10:39 - progress_bar.py[line:272] - INFO: epoch 010 | valid on 'valid' subset:    451 / 1907 loss=2.299, loss_v1=0, loss_v2=0, nll_loss=1.063, ntokens=405, nsentences=12, sample_size=405.0, sample_size_v1=0, sample_size_v2=0
2023-04-19 05:10:49 - progress_bar.py[line:272] - INFO: epoch 010 | valid on 'valid' subset:    461 / 1907 loss=2.351, loss_v1=0, loss_v2=0, nll_loss=1.121, ntokens=565, nsentences=12, sample_size=565.0, sample_size_v1=0, sample_size_v2=0
2023-04-19 05:11:00 - progress_bar.py[line:272] - INFO: epoch 010 | valid on 'valid' subset:    471 / 1907 loss=2.33, loss_v1=0, loss_v2=0, nll_loss=1.095, ntokens=398, nsentences=12, sample_size=398.0, sample_size_v1=0, sample_size_v2=0
2023-04-19 05:11:09 - progress_bar.py[line:272] - INFO: epoch 010 | valid on 'valid' subset:    481 / 1907 loss=2.354, loss_v1=0, loss_v2=0, nll_loss=1.119, ntokens=370, nsentences=12, sample_size=370.0, sample_size_v1=0, sample_size_v2=0
2023-04-19 05:11:21 - progress_bar.py[line:272] - INFO: epoch 010 | valid on 'valid' subset:    491 / 1907 loss=2.387, loss_v1=0, loss_v2=0, nll_loss=1.156, ntokens=328, nsentences=12, sample_size=328.0, sample_size_v1=0, sample_size_v2=0
2339501 <sub> man<pred> holding<obj> surfboard<sub> man<pred> holding<obj> surfboard<sub> man<pred> holding<obj> surfboard<sub> man<pred> holding<obj> surfboard<sub> man<pred> holding<obj> surfboard<sub> man<pred> holding<obj> surfboard<sub> man<pred> holding<obj> surfboard<sub> man<pred> holding<obj> surfboard<sub> man<pred> holding<obj> surfboard ['<sub> man<pred> riding<obj> wave<sub> man<pred> standing on<obj> board<sub> board<pred> under<obj> arm<sub> man<pred> under<obj> arm<pred> holding<obj> board<sub> arm<pred> under<obj> board<pred> of<obj> person<sub> surfboard<pred> behind<obj> man<sub> man<pred> in<obj> wave<pred> watching<obj> man<sub> person<pred> has<obj> head<sub> person<pred> has<obj> arm<sub> leg<pred> of<obj> person<sub> leg<pred> of<obj> person<sub> leg<pred> of<obj> man<sub> man<pred> watching<obj> man<sub> person<pred> above<obj> surfboard']
2321636 <sub> window<pred> on<obj> building<sub> window<pred> on<obj> building<sub> window<pred> on<obj> building<sub> window<pred> on<obj> building ['<sub> car<pred> parked on<obj> street<sub> building<pred> near<obj> bus<sub> bus<pred> above<obj> street<pred> has<obj> window<sub> tree<pred> behind<obj> bus<sub> tree<pred> in front of<obj> building<sub> window<pred> on<obj> bus<sub> window<pred> on<obj> bus']
2023-04-19 05:11:33 - progress_bar.py[line:272] - INFO: epoch 010 | valid on 'valid' subset:    501 / 1907 loss=2.276, loss_v1=0, loss_v2=0, nll_loss=1.036, ntokens=609, nsentences=12, sample_size=609.0, sample_size_v1=0, sample_size_v2=0
2023-04-19 05:11:46 - progress_bar.py[line:272] - INFO: epoch 010 | valid on 'valid' subset:    511 / 1907 loss=2.36, loss_v1=0, loss_v2=0, nll_loss=1.129, ntokens=337, nsentences=12, sample_size=337.0, sample_size_v1=0, sample_size_v2=0
2023-04-19 05:11:57 - progress_bar.py[line:272] - INFO: epoch 010 | valid on 'valid' subset:    521 / 1907 loss=2.234, loss_v1=0, loss_v2=0, nll_loss=0.99, ntokens=459, nsentences=12, sample_size=459.0, sample_size_v1=0, sample_size_v2=0
2023-04-19 05:12:06 - progress_bar.py[line:272] - INFO: epoch 010 | valid on 'valid' subset:    531 / 1907 loss=2.427, loss_v1=0, loss_v2=0, nll_loss=1.205, ntokens=446, nsentences=12, sample_size=446.0, sample_size_v1=0, sample_size_v2=0
2023-04-19 05:12:17 - progress_bar.py[line:272] - INFO: epoch 010 | valid on 'valid' subset:    541 / 1907 loss=2.314, loss_v1=0, loss_v2=0, nll_loss=1.074, ntokens=429, nsentences=12, sample_size=429.0, sample_size_v1=0, sample_size_v2=0
2338969 <sub> book<pred> on<obj> shelf<sub> book<pred> on<obj> shelf<sub> book<pred> on<obj> shelf<sub> book<pred> on<obj> shelf ['<sub> neck<pred> of<obj> bottle<sub> cap<pred> on<obj> bottle']
2321195 <sub> window<pred> on<obj> building<sub> window<pred> on<obj> building<sub> window<pred> on<obj> building<sub> window<pred> on<obj> building<sub> window<pred> on<obj> building<sub> window<pred> on<obj> building<sub> window<pred> on<obj> building<sub> window<pred> on<obj> building ['<sub> hand<pred> of<obj> clock<sub> face<pred> of<obj> clock<sub> building<pred> near<obj> tower<pred> with<obj> window<sub> clock<pred> on<obj> tower<pred> on<obj> tower<sub> window<pred> on<obj> building<sub> plate<pred> near<obj> clock<sub> tower<pred> has<obj> clock<sub> tower<pred> with<obj> clock']
2023-04-19 05:12:25 - progress_bar.py[line:272] - INFO: epoch 010 | valid on 'valid' subset:    551 / 1907 loss=2.286, loss_v1=0, loss_v2=0, nll_loss=1.044, ntokens=305, nsentences=12, sample_size=305.0, sample_size_v1=0, sample_size_v2=0
2023-04-19 05:12:36 - progress_bar.py[line:272] - INFO: epoch 010 | valid on 'valid' subset:    561 / 1907 loss=2.362, loss_v1=0, loss_v2=0, nll_loss=1.134, ntokens=349, nsentences=12, sample_size=349.0, sample_size_v1=0, sample_size_v2=0
2023-04-19 05:12:47 - progress_bar.py[line:272] - INFO: epoch 010 | valid on 'valid' subset:    571 / 1907 loss=2.195, loss_v1=0, loss_v2=0, nll_loss=0.944, ntokens=708, nsentences=12, sample_size=708.0, sample_size_v1=0, sample_size_v2=0
2023-04-19 05:12:59 - progress_bar.py[line:272] - INFO: epoch 010 | valid on 'valid' subset:    581 / 1907 loss=2.249, loss_v1=0, loss_v2=0, nll_loss=1.002, ntokens=425, nsentences=12, sample_size=425.0, sample_size_v1=0, sample_size_v2=0
2023-04-19 05:13:09 - progress_bar.py[line:272] - INFO: epoch 010 | valid on 'valid' subset:    591 / 1907 loss=2.351, loss_v1=0, loss_v2=0, nll_loss=1.12, ntokens=422, nsentences=12, sample_size=422.0, sample_size_v1=0, sample_size_v2=0
2338457 <sub> pillow<pred> on<obj> bed<sub> pillow<pred> on<obj> bed<sub> pillow<pred> on<obj> bed<sub> pillow<pred> on<obj> bed<sub> pillow<pred> on<obj> bed ['<sub> towel<pred> on<obj> bed<sub> bed<pred> in<obj> room<sub> bed<pred> in<obj> room<sub> table<pred> near<obj> bed']
2320764 <sub> man<pred> wearing<obj> shirt<sub> man<pred> wearing<obj> shirt<sub> man<pred> wearing<obj> shirt<sub> man<pred> wearing<obj> shirt<sub> man<pred> wearing<obj> shirt<sub> man<pred> wearing<obj> shirt<sub> man<pred> wearing<obj> shirt<sub> man<pred> wearing<obj> shirt<sub> man<pred> wearing<obj> shirt<sub> man<pred> wearing<obj> shirt<sub> man<pred> wearing<obj> shirt<sub> man<pred> wearing<obj> shirt<sub> man<pred> wearing<obj> shirt<sub> man<pred> wearing<obj> shirt<sub> man<pred> wearing<obj> shirt ['<sub> person<pred> on<obj> sidewalk<pred> wearing<obj> shirt<pred> riding<obj> skateboard<pred> has<obj> jean<pred> on<obj> skateboard<sub> man<pred> wearing<obj> jacket<sub> woman<pred> standing on<obj> jacket<sub> person<pred> on<obj> skateboard<sub> person<pred> has<obj> shirt<sub> window<pred> of<obj> building<sub> man<pred> has<obj> shirt<pred> wearing<obj> shirt<pred> wearing<obj> shirt<sub> person<pred> watching<obj> man<sub> person<pred> watching<obj> man<sub> man<pred> in<obj> shirt<sub> people<pred> in<obj> building<sub> kid<pred> in<obj>']
2023-04-19 05:13:20 - progress_bar.py[line:272] - INFO: epoch 010 | valid on 'valid' subset:    601 / 1907 loss=2.392, loss_v1=0, loss_v2=0, nll_loss=1.161, ntokens=440, nsentences=12, sample_size=440.0, sample_size_v1=0, sample_size_v2=0
2023-04-19 05:13:31 - progress_bar.py[line:272] - INFO: epoch 010 | valid on 'valid' subset:    611 / 1907 loss=2.395, loss_v1=0, loss_v2=0, nll_loss=1.164, ntokens=456, nsentences=12, sample_size=456.0, sample_size_v1=0, sample_size_v2=0
2023-04-19 05:13:43 - progress_bar.py[line:272] - INFO: epoch 010 | valid on 'valid' subset:    621 / 1907 loss=2.336, loss_v1=0, loss_v2=0, nll_loss=1.101, ntokens=465, nsentences=12, sample_size=465.0, sample_size_v1=0, sample_size_v2=0
2023-04-19 05:13:52 - progress_bar.py[line:272] - INFO: epoch 010 | valid on 'valid' subset:    631 / 1907 loss=2.329, loss_v1=0, loss_v2=0, nll_loss=1.097, ntokens=367, nsentences=12, sample_size=367.0, sample_size_v1=0, sample_size_v2=0
2023-04-19 05:14:03 - progress_bar.py[line:272] - INFO: epoch 010 | valid on 'valid' subset:    641 / 1907 loss=2.245, loss_v1=0, loss_v2=0, nll_loss=1.006, ntokens=461, nsentences=12, sample_size=461.0, sample_size_v1=0, sample_size_v2=0
2337935 <sub> man<pred> wearing<obj> shoe<pred> wearing<obj> shoe<pred> wearing<obj> shoe<pred> wearing<obj> shoe<pred> wearing<obj> shoe<pred> wearing<obj> shoe<pred> wearing<obj> shoe<pred> wearing<obj> shoe ['<sub> leg<pred> on<obj> person<sub> person<pred> has<obj> leg<sub> man<pred> wearing<obj> hat<sub> player<pred> wearing<obj> hat']
2320355 <sub> window<pred> on<obj> building<sub> window<pred> on<obj> building<sub> window<pred> on<obj> building<sub> window<pred> on<obj> building<sub> window<pred> on<obj> building<sub> window<pred> on<obj> building ['<sub> car<pred> parked on<obj> street<sub> tree<pred> behind<obj> car<sub> trunk<pred> of<obj> car<sub> wheel<pred> on<obj> car<sub> wheel<pred> on<obj> car']
2023-04-19 05:14:15 - progress_bar.py[line:272] - INFO: epoch 010 | valid on 'valid' subset:    651 / 1907 loss=2.198, loss_v1=0, loss_v2=0, nll_loss=0.941, ntokens=506, nsentences=12, sample_size=506.0, sample_size_v1=0, sample_size_v2=0
2023-04-19 05:14:25 - progress_bar.py[line:272] - INFO: epoch 010 | valid on 'valid' subset:    661 / 1907 loss=2.404, loss_v1=0, loss_v2=0, nll_loss=1.177, ntokens=390, nsentences=12, sample_size=390.0, sample_size_v1=0, sample_size_v2=0
2023-04-19 05:14:36 - progress_bar.py[line:272] - INFO: epoch 010 | valid on 'valid' subset:    671 / 1907 loss=2.193, loss_v1=0, loss_v2=0, nll_loss=0.936, ntokens=550, nsentences=12, sample_size=550.0, sample_size_v1=0, sample_size_v2=0
2023-04-19 05:14:47 - progress_bar.py[line:272] - INFO: epoch 010 | valid on 'valid' subset:    681 / 1907 loss=2.498, loss_v1=0, loss_v2=0, nll_loss=1.283, ntokens=453, nsentences=12, sample_size=453.0, sample_size_v1=0, sample_size_v2=0
2023-04-19 05:14:58 - progress_bar.py[line:272] - INFO: epoch 010 | valid on 'valid' subset:    691 / 1907 loss=2.207, loss_v1=0, loss_v2=0, nll_loss=0.966, ntokens=361, nsentences=12, sample_size=361.0, sample_size_v1=0, sample_size_v2=0
2337395 <sub> window<pred> on<obj> building<sub> window<pred> on<obj> building<sub> window<pred> on<obj> building<sub> window<pred> on<obj> building<sub> window<pred> on<obj> building<sub> window<pred> on<obj> building ['<sub> boat<pred> sitting on<obj> snow<pred> on<obj> snow<sub> tree<pred> on<obj> mountain<sub> tree<pred> on<obj> mountain<sub> tree<pred> on<obj> mountain<sub> tree<pred> on<obj> mountain<sub> tree<pred> on<obj> mountain<sub> tree<pred> on<obj> mountain']
2319934 <sub> man<pred> wearing<obj> shirt<pred> wearing<obj> pant<sub> man<pred> wearing<obj> shirt<sub> man<pred> wearing<obj> shirt<sub> man<pred> wearing<obj> shirt ['<sub> man<pred> has<obj> helmet<sub> snow<pred> has<obj> track']
2023-04-19 05:15:08 - progress_bar.py[line:272] - INFO: epoch 010 | valid on 'valid' subset:    701 / 1907 loss=2.379, loss_v1=0, loss_v2=0, nll_loss=1.15, ntokens=447, nsentences=12, sample_size=447.0, sample_size_v1=0, sample_size_v2=0
2023-04-19 05:15:20 - progress_bar.py[line:272] - INFO: epoch 010 | valid on 'valid' subset:    711 / 1907 loss=2.24, loss_v1=0, loss_v2=0, nll_loss=0.988, ntokens=532, nsentences=12, sample_size=532.0, sample_size_v1=0, sample_size_v2=0
2023-04-19 05:15:31 - progress_bar.py[line:272] - INFO: epoch 010 | valid on 'valid' subset:    721 / 1907 loss=2.404, loss_v1=0, loss_v2=0, nll_loss=1.177, ntokens=342, nsentences=12, sample_size=342.0, sample_size_v1=0, sample_size_v2=0
2023-04-19 05:15:42 - progress_bar.py[line:272] - INFO: epoch 010 | valid on 'valid' subset:    731 / 1907 loss=2.41, loss_v1=0, loss_v2=0, nll_loss=1.186, ntokens=357, nsentences=12, sample_size=357.0, sample_size_v1=0, sample_size_v2=0
2023-04-19 05:15:53 - progress_bar.py[line:272] - INFO: epoch 010 | valid on 'valid' subset:    741 / 1907 loss=2.409, loss_v1=0, loss_v2=0, nll_loss=1.185, ntokens=562, nsentences=12, sample_size=562.0, sample_size_v1=0, sample_size_v2=0
2336932 <sub> pizza<pred> on<obj> table<sub> pizza<pred> on<obj> table<sub> pizza<pred> on<obj> table<sub> pizza<pred> on<obj> table ['<sub> plate<pred> of<obj> food<sub> shirt<pred> on<obj> man']
2319536 <sub> wing<pred> of<obj> plane<sub> wing<pred> of<obj> plane<sub> wing<pred> of<obj> plane<sub> wing<pred> of<obj> plane<sub> wing<pred> of<obj> plane<sub> wing<pred> of<obj> plane ['<sub> leaf<pred> on<obj> tail<sub> engine<pred> of<obj> plane<sub> engine<pred> of<obj> plane<sub> window<pred> on<obj> plane<sub> wing<pred> on<obj> plane<sub> tail<pred> on<obj> plane<sub> nose<pred> of<obj> plane']
2023-04-19 05:16:05 - progress_bar.py[line:272] - INFO: epoch 010 | valid on 'valid' subset:    751 / 1907 loss=2.173, loss_v1=0, loss_v2=0, nll_loss=0.925, ntokens=441, nsentences=12, sample_size=441.0, sample_size_v1=0, sample_size_v2=0
2023-04-19 05:16:15 - progress_bar.py[line:272] - INFO: epoch 010 | valid on 'valid' subset:    761 / 1907 loss=2.209, loss_v1=0, loss_v2=0, nll_loss=0.955, ntokens=390, nsentences=12, sample_size=390.0, sample_size_v1=0, sample_size_v2=0
2023-04-19 05:16:24 - progress_bar.py[line:272] - INFO: epoch 010 | valid on 'valid' subset:    771 / 1907 loss=2.293, loss_v1=0, loss_v2=0, nll_loss=1.053, ntokens=486, nsentences=12, sample_size=486.0, sample_size_v1=0, sample_size_v2=0
2023-04-19 05:16:37 - progress_bar.py[line:272] - INFO: epoch 010 | valid on 'valid' subset:    781 / 1907 loss=2.162, loss_v1=0, loss_v2=0, nll_loss=0.907, ntokens=567, nsentences=12, sample_size=567.0, sample_size_v1=0, sample_size_v2=0
2023-04-19 05:16:46 - progress_bar.py[line:272] - INFO: epoch 010 | valid on 'valid' subset:    791 / 1907 loss=2.189, loss_v1=0, loss_v2=0, nll_loss=0.938, ntokens=460, nsentences=12, sample_size=460.0, sample_size_v1=0, sample_size_v2=0
2319123 <sub> giraffe<pred> has<obj> leg<pred> has<obj> leg<pred> has<obj> leg<pred> has<obj> leg<pred> has<obj> leg<pred> has<obj> leg<pred> has<obj> leg<pred> has<obj> leg<pred> has<obj> leg<pred> has<obj> leg<pred> has<obj> leg<pred> has<obj> leg ['<sub> giraffe<pred> has<obj> head<sub> tree<pred> near<obj> giraffe<sub> leg<pred> on<obj> giraffe<sub> leg<pred> on<obj> giraffe<sub> leg<pred> of<obj> giraffe<sub> tail<pred> of<obj> giraffe<sub> head<pred> of<obj> giraffe']
2336515 <sub> man<pred> wearing<obj> shirt<pred> wearing<obj> short<pred> wearing<obj> sneaker<pred> wearing<obj> sneaker<pred> wearing<obj> sock<pred> wearing<obj> sock<pred> wearing<obj> sock<pred> wearing<obj> sock<pred> wearing<obj> sock<pred> wearing<obj> sock<pred> wearing<obj> sock<pred> wearing<obj> sock<pred> wearing<obj> sock<pred> wearing<obj> sock<pred> wearing<obj> sock<pred> wearing<obj> sock<pred> wearing<obj> sock<pred> wearing<obj> sock<pred> wearing<obj> sock<pred> wearing<obj> sock<pred> wearing<obj> sock<pred> wearing<obj> sock<pred> wearing<obj> sock<pred> wearing<obj> sock ['<sub> man<pred> wearing<obj> shoe<pred> in<obj> shirt<pred> wearing<obj> short<pred> has<obj> hair<sub> shoe<pred> of<obj> man<sub> leg<pred> on<obj> man<sub> leg<pred> on<obj> man<sub> arm<pred> on<obj> man<sub> arm<pred> on<obj> person']
2023-04-19 05:16:57 - progress_bar.py[line:272] - INFO: epoch 010 | valid on 'valid' subset:    801 / 1907 loss=2.161, loss_v1=0, loss_v2=0, nll_loss=0.905, ntokens=420, nsentences=12, sample_size=420.0, sample_size_v1=0, sample_size_v2=0
2023-04-19 05:17:09 - progress_bar.py[line:272] - INFO: epoch 010 | valid on 'valid' subset:    811 / 1907 loss=2.276, loss_v1=0, loss_v2=0, nll_loss=1.035, ntokens=435, nsentences=12, sample_size=435.0, sample_size_v1=0, sample_size_v2=0
2023-04-19 05:17:19 - progress_bar.py[line:272] - INFO: epoch 010 | valid on 'valid' subset:    821 / 1907 loss=2.324, loss_v1=0, loss_v2=0, nll_loss=1.087, ntokens=443, nsentences=12, sample_size=443.0, sample_size_v1=0, sample_size_v2=0
2023-04-19 05:17:29 - progress_bar.py[line:272] - INFO: epoch 010 | valid on 'valid' subset:    831 / 1907 loss=2.334, loss_v1=0, loss_v2=0, nll_loss=1.095, ntokens=417, nsentences=12, sample_size=417.0, sample_size_v1=0, sample_size_v2=0
2023-04-19 05:17:40 - progress_bar.py[line:272] - INFO: epoch 010 | valid on 'valid' subset:    841 / 1907 loss=2.435, loss_v1=0, loss_v2=0, nll_loss=1.217, ntokens=343, nsentences=12, sample_size=343.0, sample_size_v1=0, sample_size_v2=0
2336101 <sub> man<pred> wearing<obj> tie<pred> wearing<obj> shirt<pred> wearing<obj> tie<pred> wearing<obj> shirt<pred> wearing<obj> tie<sub> tie<pred> on<obj> man<sub> tie<pred> on<obj> man<sub> tie<pred> on<obj> man ['<sub> man<pred> has<obj> hand<pred> wearing<obj> tie<sub> finger<pred> of<obj> man']
2318710 <sub> head<pred> of<obj> giraffe<sub> leg<pred> of<obj> giraffe<sub> leg<pred> of<obj> giraffe<sub> leg<pred> of<obj> giraffe<sub> leg<pred> of<obj> giraffe<sub> leg<pred> of<obj> giraffe<sub> leg<pred> of<obj> giraffe<sub> leg<pred> of<obj> giraffe ['<sub> head<pred> of<obj> giraffe<sub> leg<pred> of<obj> giraffe<sub> neck<pred> of<obj> giraffe<sub> giraffe<pred> has<obj> tail']
2023-04-19 05:17:50 - progress_bar.py[line:272] - INFO: epoch 010 | valid on 'valid' subset:    851 / 1907 loss=2.369, loss_v1=0, loss_v2=0, nll_loss=1.138, ntokens=379, nsentences=12, sample_size=379.0, sample_size_v1=0, sample_size_v2=0
2023-04-19 05:17:59 - progress_bar.py[line:272] - INFO: epoch 010 | valid on 'valid' subset:    861 / 1907 loss=2.4, loss_v1=0, loss_v2=0, nll_loss=1.172, ntokens=480, nsentences=12, sample_size=480.0, sample_size_v1=0, sample_size_v2=0
2023-04-19 05:18:10 - progress_bar.py[line:272] - INFO: epoch 010 | valid on 'valid' subset:    871 / 1907 loss=2.345, loss_v1=0, loss_v2=0, nll_loss=1.115, ntokens=395, nsentences=12, sample_size=395.0, sample_size_v1=0, sample_size_v2=0
2023-04-19 05:18:22 - progress_bar.py[line:272] - INFO: epoch 010 | valid on 'valid' subset:    881 / 1907 loss=2.291, loss_v1=0, loss_v2=0, nll_loss=1.052, ntokens=468, nsentences=12, sample_size=468.0, sample_size_v1=0, sample_size_v2=0
2023-04-19 05:18:33 - progress_bar.py[line:272] - INFO: epoch 010 | valid on 'valid' subset:    891 / 1907 loss=2.286, loss_v1=0, loss_v2=0, nll_loss=1.044, ntokens=465, nsentences=12, sample_size=465.0, sample_size_v1=0, sample_size_v2=0
2318313 <sub> leaf<pred> on<obj> tree<sub> leaf<pred> on<obj> tree<sub> leaf<pred> on<obj> tree<sub> leaf<pred> on<obj> tree<sub> leaf<pred> on<obj> tree<sub> leaf<pred> on<obj> tree<sub> leaf<pred> on<obj> tree ['<sub> flag<pred> hanging from<obj> tree<pred> hanging from<obj> tree<pred> hanging from<obj> tree<sub> fence<pred> in<obj> building<sub> board<pred> on<obj> trunk<pred> on<obj> trunk<sub> trunk<pred> under<obj> board<sub> trunk<pred> on<obj> tree<sub> railing<pred> on<obj> building<sub> tree<pred> along<obj> building<sub> tree<pred> along<obj> building<sub> tree<pred> along<obj> building<sub> tree<pred> along<obj> building']
2335683 <sub> window<pred> on<obj> building<sub> window<pred> on<obj> building<sub> window<pred> on<obj> building<sub> window<pred> on<obj> building<sub> window<pred> on<obj> building<sub> window<pred> on<obj> building<sub> window<pred> on<obj> building<sub> window<pred> on<obj> building<sub> window<pred> on<obj> building<sub> window<pred> on<obj> building<sub> window<pred> on<obj> building<sub> window<pred> on<obj> building<sub> window<pred> on<obj> building ['<sub> tower<pred> above<obj> hill<sub> car<pred> in<obj> street<sub> car<pred> with<obj> light']
2023-04-19 05:18:43 - progress_bar.py[line:272] - INFO: epoch 010 | valid on 'valid' subset:    901 / 1907 loss=2.407, loss_v1=0, loss_v2=0, nll_loss=1.184, ntokens=435, nsentences=12, sample_size=435.0, sample_size_v1=0, sample_size_v2=0
2023-04-19 05:18:53 - progress_bar.py[line:272] - INFO: epoch 010 | valid on 'valid' subset:    911 / 1907 loss=2.359, loss_v1=0, loss_v2=0, nll_loss=1.129, ntokens=572, nsentences=12, sample_size=572.0, sample_size_v1=0, sample_size_v2=0
2023-04-19 05:19:03 - progress_bar.py[line:272] - INFO: epoch 010 | valid on 'valid' subset:    921 / 1907 loss=2.302, loss_v1=0, loss_v2=0, nll_loss=1.067, ntokens=483, nsentences=12, sample_size=483.0, sample_size_v1=0, sample_size_v2=0
2023-04-19 05:19:14 - progress_bar.py[line:272] - INFO: epoch 010 | valid on 'valid' subset:    931 / 1907 loss=2.389, loss_v1=0, loss_v2=0, nll_loss=1.16, ntokens=611, nsentences=12, sample_size=611.0, sample_size_v1=0, sample_size_v2=0
2023-04-19 05:19:25 - progress_bar.py[line:272] - INFO: epoch 010 | valid on 'valid' subset:    941 / 1907 loss=2.426, loss_v1=0, loss_v2=0, nll_loss=1.201, ntokens=431, nsentences=12, sample_size=431.0, sample_size_v1=0, sample_size_v2=0
2335268 <sub> man<pred> wearing<obj> short<pred> wearing<obj> shirt<pred> wearing<obj> sock<pred> wearing<obj> sock<pred> wearing<obj> sock<pred> wearing<obj> sock<pred> wearing<obj> sock<pred> wearing<obj> sock<pred> wearing<obj> sock ['<sub> sock<pred> on<obj> leg<sub> boy<pred> wearing<obj> shirt']
2317943 <sub> window<pred> on<obj> building<sub> window<pred> on<obj> building<sub> window<pred> on<obj> building ['<sub> dog<pred> on<obj> bench<sub> tree<pred> behind<obj> bench']
2023-04-19 05:19:34 - progress_bar.py[line:272] - INFO: epoch 010 | valid on 'valid' subset:    951 / 1907 loss=2.414, loss_v1=0, loss_v2=0, nll_loss=1.19, ntokens=359, nsentences=12, sample_size=359.0, sample_size_v1=0, sample_size_v2=0
2023-04-19 05:19:46 - progress_bar.py[line:272] - INFO: epoch 010 | valid on 'valid' subset:    961 / 1907 loss=2.309, loss_v1=0, loss_v2=0, nll_loss=1.075, ntokens=488, nsentences=12, sample_size=488.0, sample_size_v1=0, sample_size_v2=0
2023-04-19 05:19:56 - progress_bar.py[line:272] - INFO: epoch 010 | valid on 'valid' subset:    971 / 1907 loss=2.241, loss_v1=0, loss_v2=0, nll_loss=0.997, ntokens=351, nsentences=12, sample_size=351.0, sample_size_v1=0, sample_size_v2=0
2023-04-19 05:20:08 - progress_bar.py[line:272] - INFO: epoch 010 | valid on 'valid' subset:    981 / 1907 loss=2.306, loss_v1=0, loss_v2=0, nll_loss=1.065, ntokens=451, nsentences=12, sample_size=451.0, sample_size_v1=0, sample_size_v2=0
2023-04-19 05:20:20 - progress_bar.py[line:272] - INFO: epoch 010 | valid on 'valid' subset:    991 / 1907 loss=2.414, loss_v1=0, loss_v2=0, nll_loss=1.19, ntokens=390, nsentences=12, sample_size=390.0, sample_size_v1=0, sample_size_v2=0
2334815 <sub> glass<pred> on<obj> table<sub> glass<pred> on<obj> table<sub> glass<pred> on<obj> table<sub> glass<pred> on<obj> table<sub> glass<pred> on<obj> table<sub> glass<pred> on<obj> table<sub> glass<pred> on<obj> table ['<sub> leg<pred> of<obj> person<sub> leg<pred> of<obj> person<sub> leg<pred> of<obj> person<sub> leg<pred> of<obj> person<sub> leg<pred> of<obj> woman<sub> person<pred> in<obj> house']
2317554 <sub> food<pred> on<obj> plate<sub> plate<pred> on<obj> table ['<sub> pizza<pred> in<obj> table<sub> table<pred> under<obj> pizza']
2023-04-19 05:20:31 - progress_bar.py[line:272] - INFO: epoch 010 | valid on 'valid' subset:   1001 / 1907 loss=2.206, loss_v1=0, loss_v2=0, nll_loss=0.956, ntokens=396, nsentences=12, sample_size=396.0, sample_size_v1=0, sample_size_v2=0
2023-04-19 05:20:41 - progress_bar.py[line:272] - INFO: epoch 010 | valid on 'valid' subset:   1011 / 1907 loss=2.2, loss_v1=0, loss_v2=0, nll_loss=0.949, ntokens=521, nsentences=12, sample_size=521.0, sample_size_v1=0, sample_size_v2=0
2023-04-19 05:20:51 - progress_bar.py[line:272] - INFO: epoch 010 | valid on 'valid' subset:   1021 / 1907 loss=2.348, loss_v1=0, loss_v2=0, nll_loss=1.117, ntokens=488, nsentences=12, sample_size=488.0, sample_size_v1=0, sample_size_v2=0
2023-04-19 05:21:01 - progress_bar.py[line:272] - INFO: epoch 010 | valid on 'valid' subset:   1031 / 1907 loss=2.314, loss_v1=0, loss_v2=0, nll_loss=1.073, ntokens=500, nsentences=12, sample_size=500.0, sample_size_v1=0, sample_size_v2=0
2023-04-19 05:21:12 - progress_bar.py[line:272] - INFO: epoch 010 | valid on 'valid' subset:   1041 / 1907 loss=2.312, loss_v1=0, loss_v2=0, nll_loss=1.075, ntokens=440, nsentences=12, sample_size=440.0, sample_size_v1=0, sample_size_v2=0
2317175 <sub> car<pred> on<obj> street<sub> car<pred> on<obj> street<sub> car<pred> on<obj> street<sub> car<pred> on<obj> street<sub> car<pred> on<obj> street<sub> car<pred> on<obj> street<sub> car<pred> on<obj> street ['<sub> sign<pred> near<obj> building<sub> sign<pred> above<obj> building<sub> bench<pred> on<obj> sidewalk']
2334375 <sub> man<pred> wearing<obj> shirt<pred> wearing<obj> tie<pred> wearing<obj> shirt<pred> has<obj> eye<pred> has<obj> eye<pred> has<obj> eye<pred> has<obj> eye<pred> has<obj> eye<pred> has<obj> eye<pred> has<obj> eye<pred> has<obj> eye<pred> has<obj> eye<pred> has<obj> eye<pred> has<obj> eye<pred> has<obj> eye<pred> has<obj> eye<pred> has<obj> eye<pred> has<obj> eye<pred> has<obj> eye<pred> has<obj> eye<pred> has<obj> eye<pred> has<obj> eye<pred> has<obj> eye<pred> has<obj> eye<pred> has<obj> tie<pred> has<obj> shirt<pred> has<obj> tie<pred> has<obj> shirt<pred> has<obj> tie<pred> has<obj> shirt<pred> has<obj> shirt<pred> has<obj> tie<pred> has<obj> shirt<pred> has<obj> tie<pred> has<obj> shirt<pred> has<obj> tie<pred> has<obj> shirt<pred> has<obj> tie<pred> has<obj> shirt<pred> has<obj> shirt<pred> has<obj> tie<pred> has<obj> tie<pred> has<obj> shirt<pred> has<obj> tie<pred> has<obj> shirt<pred> has<obj> shirt<pred> has<obj> shirt<pred> has<obj> tie<pred> has<obj> shirt<pred> has ['<sub> dog<pred> on<obj> table<pred> has<obj> nose<pred> has<obj> eye<pred> has<obj> ear<pred> has<obj> ear<pred> has<obj> neck<pred> has<obj> eye<pred> near<obj> laptop<sub> laptop<pred> has<obj> screen<sub> nose<pred> on<obj> dog<sub> eye<pred> on<obj> dog']
2023-04-19 05:21:25 - progress_bar.py[line:272] - INFO: epoch 010 | valid on 'valid' subset:   1051 / 1907 loss=2.361, loss_v1=0, loss_v2=0, nll_loss=1.128, ntokens=432, nsentences=12, sample_size=432.0, sample_size_v1=0, sample_size_v2=0
2023-04-19 05:21:36 - progress_bar.py[line:272] - INFO: epoch 010 | valid on 'valid' subset:   1061 / 1907 loss=2.2, loss_v1=0, loss_v2=0, nll_loss=0.951, ntokens=620, nsentences=12, sample_size=620.0, sample_size_v1=0, sample_size_v2=0
2023-04-19 05:21:46 - progress_bar.py[line:272] - INFO: epoch 010 | valid on 'valid' subset:   1071 / 1907 loss=2.338, loss_v1=0, loss_v2=0, nll_loss=1.104, ntokens=382, nsentences=12, sample_size=382.0, sample_size_v1=0, sample_size_v2=0
2023-04-19 05:21:56 - progress_bar.py[line:272] - INFO: epoch 010 | valid on 'valid' subset:   1081 / 1907 loss=2.264, loss_v1=0, loss_v2=0, nll_loss=1.018, ntokens=366, nsentences=12, sample_size=366.0, sample_size_v1=0, sample_size_v2=0
2023-04-19 05:22:09 - progress_bar.py[line:272] - INFO: epoch 010 | valid on 'valid' subset:   1091 / 1907 loss=2.373, loss_v1=0, loss_v2=0, nll_loss=1.149, ntokens=357, nsentences=12, sample_size=357.0, sample_size_v1=0, sample_size_v2=0
2316790 <sub> window<pred> on<obj> building<sub> window<pred> on<obj> building<sub> window<pred> on<obj> building<sub> window<pred> on<obj> building<sub> window<pred> on<obj> building<sub> window<pred> on<obj> building<sub> window<pred> on<obj> building ['<sub> car<pred> has<obj> wheel<pred> has<obj> door<pred> has<obj> window<pred> has<obj> window<sub> man<pred> on<obj> sidewalk<sub> door<pred> has<obj> handle<sub> car<pred> parked on<obj> street']
2333942 <sub> window<pred> on<obj> building<sub> window<pred> on<obj> building<sub> window<pred> on<obj> building<sub> window<pred> on<obj> building<sub> window<pred> on<obj> building<sub> window<pred> on<obj> building<sub> window<pred> on<obj> building ['<sub> pant<pred> on<obj> woman<sub> seat<pred> of<obj> bike<sub> woman<pred> wearing<obj> sneaker<pred> wearing<obj> shirt<sub> basket<pred> on<obj> bike']
2023-04-19 05:22:20 - progress_bar.py[line:272] - INFO: epoch 010 | valid on 'valid' subset:   1101 / 1907 loss=2.31, loss_v1=0, loss_v2=0, nll_loss=1.074, ntokens=533, nsentences=12, sample_size=533.0, sample_size_v1=0, sample_size_v2=0
2023-04-19 05:22:29 - progress_bar.py[line:272] - INFO: epoch 010 | valid on 'valid' subset:   1111 / 1907 loss=2.318, loss_v1=0, loss_v2=0, nll_loss=1.084, ntokens=483, nsentences=12, sample_size=483.0, sample_size_v1=0, sample_size_v2=0
2023-04-19 05:22:38 - progress_bar.py[line:272] - INFO: epoch 010 | valid on 'valid' subset:   1121 / 1907 loss=2.404, loss_v1=0, loss_v2=0, nll_loss=1.178, ntokens=360, nsentences=12, sample_size=360.0, sample_size_v1=0, sample_size_v2=0
2023-04-19 05:22:48 - progress_bar.py[line:272] - INFO: epoch 010 | valid on 'valid' subset:   1131 / 1907 loss=2.305, loss_v1=0, loss_v2=0, nll_loss=1.068, ntokens=360, nsentences=12, sample_size=360.0, sample_size_v1=0, sample_size_v2=0
2023-04-19 05:22:58 - progress_bar.py[line:272] - INFO: epoch 010 | valid on 'valid' subset:   1141 / 1907 loss=2.326, loss_v1=0, loss_v2=0, nll_loss=1.09, ntokens=511, nsentences=12, sample_size=511.0, sample_size_v1=0, sample_size_v2=0
2333484 <sub> man<pred> wearing<obj> short<pred> wearing<obj> shirt<pred> wearing<obj> short<pred> wearing<obj> shirt<pred> wearing<obj> short<pred> wearing<obj> shirt<sub> short<pred> on<obj> man<sub> short<pred> on<obj> man ['<sub> handle<pred> on<obj> bag<sub> dog<pred> walking on<obj> sidewalk<pred> with<obj> bag<sub> tail<pred> of<obj> dog<sub> bag<pred> on<obj> dog']
2316407 <sub> glass<pred> on<obj> table<sub> glass<pred> on<obj> table<sub> glass<pred> on<obj> table<sub> glass<pred> on<obj> table<sub> glass<pred> on<obj> table<sub> glass<pred> on<obj> table ['<sub> hair<pred> on<obj> girl<pred> on<obj> head']
2023-04-19 05:23:08 - progress_bar.py[line:272] - INFO: epoch 010 | valid on 'valid' subset:   1151 / 1907 loss=2.417, loss_v1=0, loss_v2=0, nll_loss=1.193, ntokens=433, nsentences=12, sample_size=433.0, sample_size_v1=0, sample_size_v2=0
2023-04-19 05:23:19 - progress_bar.py[line:272] - INFO: epoch 010 | valid on 'valid' subset:   1161 / 1907 loss=2.324, loss_v1=0, loss_v2=0, nll_loss=1.089, ntokens=473, nsentences=12, sample_size=473.0, sample_size_v1=0, sample_size_v2=0
2023-04-19 05:23:30 - progress_bar.py[line:272] - INFO: epoch 010 | valid on 'valid' subset:   1171 / 1907 loss=2.306, loss_v1=0, loss_v2=0, nll_loss=1.067, ntokens=581, nsentences=12, sample_size=581.0, sample_size_v1=0, sample_size_v2=0
2023-04-19 05:23:39 - progress_bar.py[line:272] - INFO: epoch 010 | valid on 'valid' subset:   1181 / 1907 loss=2.174, loss_v1=0, loss_v2=0, nll_loss=0.924, ntokens=324, nsentences=12, sample_size=324.0, sample_size_v1=0, sample_size_v2=0
2023-04-19 05:23:49 - progress_bar.py[line:272] - INFO: epoch 010 | valid on 'valid' subset:   1191 / 1907 loss=2.38, loss_v1=0, loss_v2=0, nll_loss=1.15, ntokens=658, nsentences=12, sample_size=658.0, sample_size_v1=0, sample_size_v2=0
2333035 <sub> sign<pred> on<obj> pole<sub> sign<pred> on<obj> pole<sub> sign<pred> on<obj> pole<sub> sign<pred> on<obj> pole<sub> sign<pred> on<obj> pole<sub> sign<pred> on<obj> pole<sub> sign<pred> on<obj> pole ['<sub> tree<pred> near<obj> street<sub> sign<pred> on<obj> pole<sub> man<pred> wears<obj> shirt<sub> man<pred> has<obj> head<sub> man<pred> has<obj> arm<pred> has<obj> leg<pred> with<obj> hat']
2316002 <sub> car<pred> on<obj> street<sub> car<pred> on<obj> street<sub> car<pred> on<obj> street<sub> car<pred> on<obj> street<sub> car<pred> on<obj> street ['<sub> sign<pred> on<obj> sidewalk<sub> sign<pred> on<obj> sidewalk<sub> tree<pred> in front of<obj> building<sub> street<pred> near<obj> sign<sub> street<pred> near<obj> sidewalk']
2023-04-19 05:24:01 - progress_bar.py[line:272] - INFO: epoch 010 | valid on 'valid' subset:   1201 / 1907 loss=2.283, loss_v1=0, loss_v2=0, nll_loss=1.044, ntokens=468, nsentences=12, sample_size=468.0, sample_size_v1=0, sample_size_v2=0
2023-04-19 05:24:12 - progress_bar.py[line:272] - INFO: epoch 010 | valid on 'valid' subset:   1211 / 1907 loss=2.187, loss_v1=0, loss_v2=0, nll_loss=0.94, ntokens=356, nsentences=12, sample_size=356.0, sample_size_v1=0, sample_size_v2=0
2023-04-19 05:24:22 - progress_bar.py[line:272] - INFO: epoch 010 | valid on 'valid' subset:   1221 / 1907 loss=2.352, loss_v1=0, loss_v2=0, nll_loss=1.121, ntokens=391, nsentences=12, sample_size=391.0, sample_size_v1=0, sample_size_v2=0
2023-04-19 05:24:32 - progress_bar.py[line:272] - INFO: epoch 010 | valid on 'valid' subset:   1231 / 1907 loss=2.405, loss_v1=0, loss_v2=0, nll_loss=1.183, ntokens=328, nsentences=12, sample_size=328.0, sample_size_v1=0, sample_size_v2=0
2023-04-19 05:24:42 - progress_bar.py[line:272] - INFO: epoch 010 | valid on 'valid' subset:   1241 / 1907 loss=2.286, loss_v1=0, loss_v2=0, nll_loss=1.04, ntokens=404, nsentences=12, sample_size=404.0, sample_size_v1=0, sample_size_v2=0
2315534 <sub> tree<pred> behind<obj> giraffe<sub> giraffe<pred> has<obj> tail ['<sub> rock<pred> near<obj> rock<sub> rock<pred> near<obj> rock']
2332511 <sub> glass<pred> on<obj> table<sub> glass<pred> on<obj> table<sub> glass<pred> on<obj> table<sub> glass<pred> on<obj> table<sub> glass<pred> on<obj> table ['<sub> plate<pred> of<obj> food<pred> on<obj> table<sub> vegetable<pred> on<obj> plate<sub> fork<pred> on<obj> plate<sub> chair<pred> at<obj> table<sub> food<pred> on<obj> plate<sub> glass<pred> on<obj> table<sub> vegetable<pred> on<obj> plate']
2023-04-19 05:24:53 - progress_bar.py[line:272] - INFO: epoch 010 | valid on 'valid' subset:   1251 / 1907 loss=2.165, loss_v1=0, loss_v2=0, nll_loss=0.908, ntokens=425, nsentences=12, sample_size=425.0, sample_size_v1=0, sample_size_v2=0
2023-04-19 05:25:04 - progress_bar.py[line:272] - INFO: epoch 010 | valid on 'valid' subset:   1261 / 1907 loss=2.172, loss_v1=0, loss_v2=0, nll_loss=0.913, ntokens=411, nsentences=12, sample_size=411.0, sample_size_v1=0, sample_size_v2=0
2023-04-19 05:25:13 - progress_bar.py[line:272] - INFO: epoch 010 | valid on 'valid' subset:   1271 / 1907 loss=2.204, loss_v1=0, loss_v2=0, nll_loss=0.956, ntokens=417, nsentences=12, sample_size=417.0, sample_size_v1=0, sample_size_v2=0
2023-04-19 05:25:22 - progress_bar.py[line:272] - INFO: epoch 010 | valid on 'valid' subset:   1281 / 1907 loss=2.369, loss_v1=0, loss_v2=0, nll_loss=1.137, ntokens=282, nsentences=12, sample_size=282.0, sample_size_v1=0, sample_size_v2=0
2023-04-19 05:25:33 - progress_bar.py[line:272] - INFO: epoch 010 | valid on 'valid' subset:   1291 / 1907 loss=2.277, loss_v1=0, loss_v2=0, nll_loss=1.043, ntokens=409, nsentences=12, sample_size=409.0, sample_size_v1=0, sample_size_v2=0
2414722 <sub> man<pred> on<obj> surfboard<pred> on<obj> surfboard<sub> man<pred> on<obj> surfboard<sub> surfboard<pred> on<obj> wave ['<sub> man<pred> holding<obj> surfboard<sub> surfboard<pred> under<obj> arm']
2331944 <sub> man<pred> wearing<obj> shirt<pred> wearing<obj> jean<pred> has<obj> hand<pred> has<obj> hand<pred> has<obj> hand<pred> has<obj> hand<pred> has<obj> hand<pred> has<obj> hand<pred> has<obj> hand<pred> has<obj> hand<pred> has<obj> hand<pred> has<obj> hand<pred> has<obj> hand<pred> has<obj> hand<pred> has<obj> hand<pred> has<obj> hand<pred> has<obj> hand<pred> has<obj> hand<pred> has<obj> hand<pred> has<obj> hand<pred> has<obj> hand ['<sub> person<pred> has<obj> hair<sub> boy<pred> wearing<obj> jean<pred> has<obj> hand<pred> has<obj> hand<sub> hand<pred> holding<obj> plate<sub> fork<pred> on<obj> hand']
2023-04-19 05:25:42 - progress_bar.py[line:272] - INFO: epoch 010 | valid on 'valid' subset:   1301 / 1907 loss=2.31, loss_v1=0, loss_v2=0, nll_loss=1.075, ntokens=332, nsentences=12, sample_size=332.0, sample_size_v1=0, sample_size_v2=0
2023-04-19 05:25:53 - progress_bar.py[line:272] - INFO: epoch 010 | valid on 'valid' subset:   1311 / 1907 loss=2.547, loss_v1=0, loss_v2=0, nll_loss=1.341, ntokens=299, nsentences=12, sample_size=299.0, sample_size_v1=0, sample_size_v2=0
2023-04-19 05:26:03 - progress_bar.py[line:272] - INFO: epoch 010 | valid on 'valid' subset:   1321 / 1907 loss=2.363, loss_v1=0, loss_v2=0, nll_loss=1.129, ntokens=271, nsentences=12, sample_size=271.0, sample_size_v1=0, sample_size_v2=0
2023-04-19 05:26:15 - progress_bar.py[line:272] - INFO: epoch 010 | valid on 'valid' subset:   1331 / 1907 loss=2.373, loss_v1=0, loss_v2=0, nll_loss=1.145, ntokens=395, nsentences=12, sample_size=395.0, sample_size_v1=0, sample_size_v2=0
2023-04-19 05:26:25 - progress_bar.py[line:272] - INFO: epoch 010 | valid on 'valid' subset:   1341 / 1907 loss=2.394, loss_v1=0, loss_v2=0, nll_loss=1.166, ntokens=412, nsentences=12, sample_size=412.0, sample_size_v1=0, sample_size_v2=0
2414130 <sub> man<pred> on<obj> surfboard<pred> has<obj> arm<pred> has<obj> arm<pred> has<obj> arm<pred> has<obj> arm<pred> has<obj> arm<pred> has<obj> arm<pred> has<obj> arm ['<sub> man<pred> wears<obj> short<pred> has<obj> hair<pred> has<obj> hand<pred> on<obj> surfboard']
2331327 <sub> man<pred> wearing<obj> shirt<pred> wearing<obj> short<pred> wearing<obj> shoe<pred> wearing<obj> shoe<pred> wearing<obj> shoe<pred> wearing<obj> shoe<pred> wearing<obj> shoe<pred> wearing<obj> shoe<pred> wearing<obj> shoe<pred> wearing<obj> shoe<pred> wearing<obj> shoe<sub> shoe<pred> on<obj> man ['<sub> wheel<pred> on<obj> bike<sub> leg<pred> of<obj> man']
2023-04-19 05:26:36 - progress_bar.py[line:272] - INFO: epoch 010 | valid on 'valid' subset:   1351 / 1907 loss=2.433, loss_v1=0, loss_v2=0, nll_loss=1.213, ntokens=358, nsentences=12, sample_size=358.0, sample_size_v1=0, sample_size_v2=0
2023-04-19 05:26:45 - progress_bar.py[line:272] - INFO: epoch 010 | valid on 'valid' subset:   1361 / 1907 loss=2.196, loss_v1=0, loss_v2=0, nll_loss=0.948, ntokens=291, nsentences=12, sample_size=291.0, sample_size_v1=0, sample_size_v2=0
2023-04-19 05:26:54 - progress_bar.py[line:272] - INFO: epoch 010 | valid on 'valid' subset:   1371 / 1907 loss=2.238, loss_v1=0, loss_v2=0, nll_loss=0.995, ntokens=460, nsentences=12, sample_size=460.0, sample_size_v1=0, sample_size_v2=0
2023-04-19 05:27:03 - progress_bar.py[line:272] - INFO: epoch 010 | valid on 'valid' subset:   1381 / 1907 loss=2.244, loss_v1=0, loss_v2=0, nll_loss=0.995, ntokens=406, nsentences=12, sample_size=406.0, sample_size_v1=0, sample_size_v2=0
2023-04-19 05:27:10 - progress_bar.py[line:272] - INFO: epoch 010 | valid on 'valid' subset:   1391 / 1907 loss=2.123, loss_v1=0, loss_v2=0, nll_loss=0.858, ntokens=353, nsentences=12, sample_size=353.0, sample_size_v1=0, sample_size_v2=0
2413537 <sub> glass<pred> on<obj> table<sub> glass<pred> on<obj> table<sub> glass<pred> on<obj> table<sub> glass<pred> on<obj> table ['<sub> person<pred> wearing<obj> shirt<pred> wearing<obj> glove<pred> wearing<obj> glove<sub> person<pred> wearing<obj> shirt<pred> wearing<obj> pant<sub> box<pred> near<obj> person']
2330749 <sub> window<pred> on<obj> building<sub> window<pred> on<obj> building<sub> window<pred> on<obj> building<sub> window<pred> on<obj> building<sub> window<pred> on<obj> building<sub> window<pred> on<obj> building<sub> window<pred> on<obj> building<sub> window<pred> on<obj> building<sub> window<pred> on<obj> building<sub> window<pred> on<obj> building<sub> window<pred> on<obj> building<sub> window<pred> on<obj> building ['<sub> window<pred> of<obj> building<sub> window<pred> on<obj> building<sub> window<pred> on<obj> building<sub> window<pred> on<obj> building<sub> window<pred> of<obj> building<sub> window<pred> of<obj> building<sub> window<pred> on<obj> building<sub> sign<pred> on<obj> pole<sub> window<pred> on<obj> building<sub> window<pred> on<obj> building<sub> window<pred> on<obj> building<sub> window<pred> on<obj> building<sub> building<pred> has<obj> window<sub> window<pred> on<obj> building']
2023-04-19 05:27:19 - progress_bar.py[line:272] - INFO: epoch 010 | valid on 'valid' subset:   1401 / 1907 loss=2.21, loss_v1=0, loss_v2=0, nll_loss=0.968, ntokens=352, nsentences=12, sample_size=352.0, sample_size_v1=0, sample_size_v2=0
2023-04-19 05:27:27 - progress_bar.py[line:272] - INFO: epoch 010 | valid on 'valid' subset:   1411 / 1907 loss=2.349, loss_v1=0, loss_v2=0, nll_loss=1.115, ntokens=457, nsentences=12, sample_size=457.0, sample_size_v1=0, sample_size_v2=0
2023-04-19 05:27:36 - progress_bar.py[line:272] - INFO: epoch 010 | valid on 'valid' subset:   1421 / 1907 loss=2.303, loss_v1=0, loss_v2=0, nll_loss=1.062, ntokens=351, nsentences=12, sample_size=351.0, sample_size_v1=0, sample_size_v2=0
2023-04-19 05:27:45 - progress_bar.py[line:272] - INFO: epoch 010 | valid on 'valid' subset:   1431 / 1907 loss=2.387, loss_v1=0, loss_v2=0, nll_loss=1.161, ntokens=329, nsentences=12, sample_size=329.0, sample_size_v1=0, sample_size_v2=0
2023-04-19 05:27:56 - progress_bar.py[line:272] - INFO: epoch 010 | valid on 'valid' subset:   1441 / 1907 loss=2.321, loss_v1=0, loss_v2=0, nll_loss=1.089, ntokens=476, nsentences=12, sample_size=476.0, sample_size_v1=0, sample_size_v2=0
2330214 <sub> man<pred> wearing<obj> shirt<pred> wearing<obj> short<pred> wearing<obj> shirt<pred> wearing<obj> short<sub> man<pred> wearing<obj> shirt<pred> wearing<obj> short<sub> man<pred> wearing<obj> shirt<pred> wearing<obj> short ['<sub> leg<pred> of<obj> dog<sub> leg<pred> of<obj> person']
2413030 <sub> giraffe<pred> has<obj> leg<pred> has<obj> leg<pred> has<obj> leg<pred> has<obj> leg<pred> has<obj> leg<pred> has<obj> leg<pred> has<obj> leg<pred> has<obj> leg<pred> has<obj> leg<pred> has<obj> leg<pred> has<obj> leg<pred> has<obj> leg<pred> has<obj> leg<pred> has<obj> leg<pred> has<obj> leg<pred> has<obj> leg<pred> has<obj> leg<pred> has<obj> leg<pred> has<obj> leg<pred> has<obj> leg<pred> has<obj> leg<pred> has<obj> leg<pred> has<obj> leg<pred> has<obj> leg<pred> ['<sub> giraffe<pred> has<obj> hair<pred> has<obj> ear<pred> in<obj> building<sub> giraffe<pred> has<obj> ear<sub> wire<pred> attached to<obj> tree<pred> behind<obj> giraffe<sub> door<pred> in<obj> building<sub> door<pred> in<obj> building<sub> wire<pred> behind<obj> giraffe<sub> wire<pred> behind<obj> giraffe<pred> behind<obj> giraffe<sub> building<pred> has<obj> door<pred> has<obj> door<sub> tree<pred> has<obj> trunk<sub> tree<pred> has<obj> trunk']
2023-04-19 05:28:08 - progress_bar.py[line:272] - INFO: epoch 010 | valid on 'valid' subset:   1451 / 1907 loss=2.282, loss_v1=0, loss_v2=0, nll_loss=1.04, ntokens=525, nsentences=12, sample_size=525.0, sample_size_v1=0, sample_size_v2=0
2023-04-19 05:28:18 - progress_bar.py[line:272] - INFO: epoch 010 | valid on 'valid' subset:   1461 / 1907 loss=2.306, loss_v1=0, loss_v2=0, nll_loss=1.075, ntokens=330, nsentences=12, sample_size=330.0, sample_size_v1=0, sample_size_v2=0
2023-04-19 05:28:31 - progress_bar.py[line:272] - INFO: epoch 010 | valid on 'valid' subset:   1471 / 1907 loss=2.294, loss_v1=0, loss_v2=0, nll_loss=1.054, ntokens=369, nsentences=12, sample_size=369.0, sample_size_v1=0, sample_size_v2=0
2023-04-19 05:28:39 - progress_bar.py[line:272] - INFO: epoch 010 | valid on 'valid' subset:   1481 / 1907 loss=2.41, loss_v1=0, loss_v2=0, nll_loss=1.189, ntokens=324, nsentences=12, sample_size=324.0, sample_size_v1=0, sample_size_v2=0
2023-04-19 05:28:48 - progress_bar.py[line:272] - INFO: epoch 010 | valid on 'valid' subset:   1491 / 1907 loss=2.576, loss_v1=0, loss_v2=0, nll_loss=1.372, ntokens=322, nsentences=12, sample_size=322.0, sample_size_v1=0, sample_size_v2=0
2412516 <sub> plane<pred> has<obj> wing<pred> has<obj> wing ['<sub> airplane<pred> in front of<obj> plane<sub> plane<pred> near<obj> airplane']
2329672 <sub> glass<pred> on<obj> table<sub> glass<pred> on<obj> table<sub> glass<pred> on<obj> table<sub> glass<pred> on<obj> table<sub> glass<pred> on<obj> table<sub> glass<pred> on<obj> table<sub> glass<pred> on<obj> table<sub> glass<pred> on<obj> table<sub> glass<pred> on<obj> table<sub> glass<pred> on<obj> table<sub> glass<pred> on<obj> table<sub> glass<pred> on<obj> table<sub> glass<pred> on<obj> table ['<sub> pizza<pred> on<obj> paper<sub> pizza<pred> on<obj> paper<sub> pizza<pred> on<obj> paper<sub> table<pred> with<obj> leg']
2023-04-19 05:28:58 - progress_bar.py[line:272] - INFO: epoch 010 | valid on 'valid' subset:   1501 / 1907 loss=2.351, loss_v1=0, loss_v2=0, nll_loss=1.119, ntokens=430, nsentences=12, sample_size=430.0, sample_size_v1=0, sample_size_v2=0
2023-04-19 05:29:08 - progress_bar.py[line:272] - INFO: epoch 010 | valid on 'valid' subset:   1511 / 1907 loss=2.29, loss_v1=0, loss_v2=0, nll_loss=1.045, ntokens=430, nsentences=12, sample_size=430.0, sample_size_v1=0, sample_size_v2=0
2023-04-19 05:29:17 - progress_bar.py[line:272] - INFO: epoch 010 | valid on 'valid' subset:   1521 / 1907 loss=2.376, loss_v1=0, loss_v2=0, nll_loss=1.146, ntokens=442, nsentences=12, sample_size=442.0, sample_size_v1=0, sample_size_v2=0
2023-04-19 05:29:28 - progress_bar.py[line:272] - INFO: epoch 010 | valid on 'valid' subset:   1531 / 1907 loss=2.388, loss_v1=0, loss_v2=0, nll_loss=1.161, ntokens=371, nsentences=12, sample_size=371.0, sample_size_v1=0, sample_size_v2=0
2023-04-19 05:29:39 - progress_bar.py[line:272] - INFO: epoch 010 | valid on 'valid' subset:   1541 / 1907 loss=2.361, loss_v1=0, loss_v2=0, nll_loss=1.133, ntokens=551, nsentences=12, sample_size=551.0, sample_size_v1=0, sample_size_v2=0
2412002 <sub> wheel<pred> on<obj> motorcycle<sub> wheel<pred> on<obj> motorcycle<sub> wheel<pred> on<obj> motorcycle<sub> wheel<pred> on<obj> motorcycle ['<sub> motorcycle<pred> near<obj> men<sub> man<pred> near<obj> truck<sub> helmet<pred> on<obj> motorcycle<sub> man<pred> wears<obj> shirt<sub> windshield<pred> on<obj> motorcycle']
2329175 <sub> track<pred> in<obj> snow<sub> track<pred> in<obj> snow<sub> track<pred> in<obj> snow<sub> track<pred> in<obj> snow ['<sub> lady<pred> on<obj> snow']
2023-04-19 05:29:49 - progress_bar.py[line:272] - INFO: epoch 010 | valid on 'valid' subset:   1551 / 1907 loss=2.516, loss_v1=0, loss_v2=0, nll_loss=1.308, ntokens=310, nsentences=12, sample_size=310.0, sample_size_v1=0, sample_size_v2=0
2023-04-19 05:29:58 - progress_bar.py[line:272] - INFO: epoch 010 | valid on 'valid' subset:   1561 / 1907 loss=2.305, loss_v1=0, loss_v2=0, nll_loss=1.068, ntokens=469, nsentences=12, sample_size=469.0, sample_size_v1=0, sample_size_v2=0
2023-04-19 05:30:08 - progress_bar.py[line:272] - INFO: epoch 010 | valid on 'valid' subset:   1571 / 1907 loss=2.17, loss_v1=0, loss_v2=0, nll_loss=0.916, ntokens=569, nsentences=12, sample_size=569.0, sample_size_v1=0, sample_size_v2=0
2023-04-19 05:30:18 - progress_bar.py[line:272] - INFO: epoch 010 | valid on 'valid' subset:   1581 / 1907 loss=2.358, loss_v1=0, loss_v2=0, nll_loss=1.128, ntokens=541, nsentences=12, sample_size=541.0, sample_size_v1=0, sample_size_v2=0
2023-04-19 05:30:28 - progress_bar.py[line:272] - INFO: epoch 010 | valid on 'valid' subset:   1591 / 1907 loss=2.446, loss_v1=0, loss_v2=0, nll_loss=1.223, ntokens=361, nsentences=12, sample_size=361.0, sample_size_v1=0, sample_size_v2=0
2411524 <sub> glass<pred> on<obj> table<sub> glass<pred> on<obj> table<sub> glass<pred> on<obj> table<sub> glass<pred> on<obj> table<sub> glass<pred> on<obj> table<sub> glass<pred> on<obj> table<sub> glass<pred> on<obj> table ['<sub> plate<pred> in<obj> cabinet<sub> window<pred> above<obj> sink<sub> cabinet<pred> has<obj> handle<sub> woman<pred> near<obj> window<sub> light<pred> over<obj> counter<sub> board<pred> on<obj> counter']
2328738 <sub> man<pred> wearing<obj> shirt<sub> man<pred> wearing<obj> shirt<sub> man<pred> wearing<obj> shirt<sub> man<pred> wearing<obj> shirt<sub> man<pred> wearing<obj> shirt<sub> man<pred> wearing<obj> shirt<sub> man<pred> wearing<obj> shirt<sub> man<pred> wearing<obj> shirt ['<sub> trunk<pred> on<obj> elephant<sub> person<pred> wearing<obj> hat<sub> person<pred> wearing<obj> shirt<sub> person<pred> riding<obj> elephant<sub> head<pred> of<obj> elephant<sub> head<pred> of<obj> elephant<sub> eye<pred> of<obj> elephant<sub> elephant<pred> has<obj> trunk<sub> mouth<pred> of<obj> elephant<sub> leg<pred> of<obj> elephant']
2023-04-19 05:30:38 - progress_bar.py[line:272] - INFO: epoch 010 | valid on 'valid' subset:   1601 / 1907 loss=2.537, loss_v1=0, loss_v2=0, nll_loss=1.329, ntokens=483, nsentences=12, sample_size=483.0, sample_size_v1=0, sample_size_v2=0
2023-04-19 05:30:48 - progress_bar.py[line:272] - INFO: epoch 010 | valid on 'valid' subset:   1611 / 1907 loss=2.274, loss_v1=0, loss_v2=0, nll_loss=1.032, ntokens=480, nsentences=12, sample_size=480.0, sample_size_v1=0, sample_size_v2=0
2023-04-19 05:30:59 - progress_bar.py[line:272] - INFO: epoch 010 | valid on 'valid' subset:   1621 / 1907 loss=2.257, loss_v1=0, loss_v2=0, nll_loss=1.015, ntokens=493, nsentences=12, sample_size=493.0, sample_size_v1=0, sample_size_v2=0
2023-04-19 05:31:11 - progress_bar.py[line:272] - INFO: epoch 010 | valid on 'valid' subset:   1631 / 1907 loss=2.482, loss_v1=0, loss_v2=0, nll_loss=1.265, ntokens=322, nsentences=12, sample_size=322.0, sample_size_v1=0, sample_size_v2=0
2023-04-19 05:31:21 - progress_bar.py[line:272] - INFO: epoch 010 | valid on 'valid' subset:   1641 / 1907 loss=2.363, loss_v1=0, loss_v2=0, nll_loss=1.133, ntokens=477, nsentences=12, sample_size=477.0, sample_size_v1=0, sample_size_v2=0
2328261 <sub> man<pred> wearing<obj> shirt<pred> wearing<obj> pant ['<sub> man<pred> has<obj> head<pred> has<obj> hand<sub> seat<pred> for<obj> man']
2415628 <sub> ear<pred> of<obj> cat<sub> ear<pred> of<obj> cat<sub> ear<pred> of<obj> cat<sub> ear<pred> of<obj> cat<sub> ear<pred> of<obj> cat<sub> ear<pred> of<obj> cat<sub> ear<pred> of<obj> cat ['<sub> phone<pred> near<obj> ear<pred> in<obj> hand<sub> man<pred> on<obj> phone<pred> has<obj> ear<pred> has<obj> hand<pred> has<obj> ear<pred> has<obj> hair<sub> ear<pred> has<obj> phone']
2023-04-19 05:31:33 - progress_bar.py[line:272] - INFO: epoch 010 | valid on 'valid' subset:   1651 / 1907 loss=2.22, loss_v1=0, loss_v2=0, nll_loss=0.971, ntokens=420, nsentences=12, sample_size=420.0, sample_size_v1=0, sample_size_v2=0
2023-04-19 05:31:42 - progress_bar.py[line:272] - INFO: epoch 010 | valid on 'valid' subset:   1661 / 1907 loss=2.308, loss_v1=0, loss_v2=0, nll_loss=1.075, ntokens=411, nsentences=12, sample_size=411.0, sample_size_v1=0, sample_size_v2=0
2023-04-19 05:31:50 - progress_bar.py[line:272] - INFO: epoch 010 | valid on 'valid' subset:   1671 / 1907 loss=2.366, loss_v1=0, loss_v2=0, nll_loss=1.129, ntokens=384, nsentences=12, sample_size=384.0, sample_size_v1=0, sample_size_v2=0
2023-04-19 05:32:00 - progress_bar.py[line:272] - INFO: epoch 010 | valid on 'valid' subset:   1681 / 1907 loss=2.294, loss_v1=0, loss_v2=0, nll_loss=1.059, ntokens=336, nsentences=12, sample_size=336.0, sample_size_v1=0, sample_size_v2=0
2023-04-19 05:32:09 - progress_bar.py[line:272] - INFO: epoch 010 | valid on 'valid' subset:   1691 / 1907 loss=2.264, loss_v1=0, loss_v2=0, nll_loss=1.022, ntokens=399, nsentences=12, sample_size=399.0, sample_size_v1=0, sample_size_v2=0
2416102 <sub> man<pred> has<obj> hand<pred> has<obj> hand<pred> has<obj> hand<pred> has<obj> finger<pred> has<obj> finger<pred> has<obj> finger<pred> has<obj> finger<pred> has<obj> finger<pred> has<obj> finger<pred> has<obj> finger<pred> has<obj> finger ['<sub> wing<pred> on<obj> plane<sub> wing<pred> on<obj> plane<sub> wing<pred> on<obj> plane<sub> wheel<pred> on<obj> plane']
2327847 <sub> leg<pred> of<obj> elephant<sub> leg<pred> of<obj> elephant<sub> leg<pred> of<obj> elephant<sub> leg<pred> of<obj> elephant<sub> leg<pred> of<obj> elephant<sub> leg<pred> of<obj> elephant<sub> leg<pred> of<obj> elephant<sub> leg<pred> of<obj> elephant<sub> leg<pred> of<obj> elephant<sub> leg<pred> of<obj> elephant<sub> leg<pred> of<obj> elephant<sub> leg<pred> of<obj> elephant<sub> leg<pred> of<obj> elephant<sub> leg<pred> of<obj> elephant<sub> leg<pred> of<obj> elephant<sub> leg<pred> of<obj> elephant<sub> leg<pred> of ['<sub> people<pred> riding<obj> elephant<sub> person<pred> wearing<obj> shirt<sub> seat<pred> mounted on<obj> elephant<sub> man<pred> riding<obj> elephant<pred> wearing<obj> shirt<pred> has<obj> hair<pred> has<obj> head<sub> woman<pred> sitting on<obj> elephant<pred> riding<obj> elephant<sub> ear<pred> belonging to<obj> elephant<sub> trunk<pred> belonging to<obj> elephant<sub> leaf<pred> on<obj> tree<sub> leaf<pred> on<obj> tree<sub> leaf<pred> on<obj> tree<sub> leaf<pred> on<obj> tree<sub> man<pred> wearing<obj> shirt<sub> hair<pred> on<obj> head<sub> woman']
2023-04-19 05:32:19 - progress_bar.py[line:272] - INFO: epoch 010 | valid on 'valid' subset:   1701 / 1907 loss=2.123, loss_v1=0, loss_v2=0, nll_loss=0.862, ntokens=626, nsentences=12, sample_size=626.0, sample_size_v1=0, sample_size_v2=0
2023-04-19 05:32:30 - progress_bar.py[line:272] - INFO: epoch 010 | valid on 'valid' subset:   1711 / 1907 loss=2.366, loss_v1=0, loss_v2=0, nll_loss=1.135, ntokens=283, nsentences=12, sample_size=283.0, sample_size_v1=0, sample_size_v2=0
2023-04-19 05:32:42 - progress_bar.py[line:272] - INFO: epoch 010 | valid on 'valid' subset:   1721 / 1907 loss=2.375, loss_v1=0, loss_v2=0, nll_loss=1.148, ntokens=254, nsentences=12, sample_size=254.0, sample_size_v1=0, sample_size_v2=0
2023-04-19 05:32:52 - progress_bar.py[line:272] - INFO: epoch 010 | valid on 'valid' subset:   1731 / 1907 loss=2.225, loss_v1=0, loss_v2=0, nll_loss=0.98, ntokens=358, nsentences=12, sample_size=358.0, sample_size_v1=0, sample_size_v2=0
2023-04-19 05:33:04 - progress_bar.py[line:272] - INFO: epoch 010 | valid on 'valid' subset:   1741 / 1907 loss=2.241, loss_v1=0, loss_v2=0, nll_loss=0.999, ntokens=440, nsentences=12, sample_size=440.0, sample_size_v1=0, sample_size_v2=0
2416544 <sub> man<pred> wearing<obj> jean<pred> wearing<obj> shirt<pred> wearing<obj> jean<sub> man<pred> wearing<obj> shirt<pred> wearing<obj> jean<sub> man<pred> wearing<obj> shirt<pred> wearing<obj> jean<sub> man<pred> wearing<obj> shirt<pred> wearing<obj> jean<sub> man<pred> wearing<obj> shirt ['<sub> man<pred> riding<obj> skateboard<pred> has<obj> head<sub> man<pred> has<obj> head<sub> head<pred> on<obj> man<sub> head<pred> on<obj> dog']
2327393 <sub> man<pred> wearing<obj> shirt<sub> man<pred> wearing<obj> shirt<sub> man<pred> wearing<obj> shirt<sub> man<pred> wearing<obj> shirt<sub> man<pred> wearing<obj> shirt<sub> man<pred> wearing<obj> shirt<sub> man<pred> wearing<obj> shirt ['<sub> person<pred> has<obj> leg<pred> has<obj> leg<sub> person<pred> has<obj> leg<pred> has<obj> leg<sub> person<pred> has<obj> leg<pred> has<obj> leg<sub> person<pred> has<obj> leg<pred> wearing<obj> shirt<sub> person<pred> has<obj> leg<sub> person<pred> has<obj> leg<sub> car<pred> behind<obj> person<pred> on<obj> street<sub> car<pred> on<obj> street']
2023-04-19 05:33:14 - progress_bar.py[line:272] - INFO: epoch 010 | valid on 'valid' subset:   1751 / 1907 loss=2.235, loss_v1=0, loss_v2=0, nll_loss=0.99, ntokens=372, nsentences=12, sample_size=372.0, sample_size_v1=0, sample_size_v2=0
2023-04-19 05:33:25 - progress_bar.py[line:272] - INFO: epoch 010 | valid on 'valid' subset:   1761 / 1907 loss=2.433, loss_v1=0, loss_v2=0, nll_loss=1.211, ntokens=326, nsentences=12, sample_size=326.0, sample_size_v1=0, sample_size_v2=0
2023-04-19 05:33:35 - progress_bar.py[line:272] - INFO: epoch 010 | valid on 'valid' subset:   1771 / 1907 loss=2.235, loss_v1=0, loss_v2=0, nll_loss=0.99, ntokens=302, nsentences=12, sample_size=302.0, sample_size_v1=0, sample_size_v2=0
2023-04-19 05:33:45 - progress_bar.py[line:272] - INFO: epoch 010 | valid on 'valid' subset:   1781 / 1907 loss=2.271, loss_v1=0, loss_v2=0, nll_loss=1.029, ntokens=347, nsentences=12, sample_size=347.0, sample_size_v1=0, sample_size_v2=0
2023-04-19 05:33:54 - progress_bar.py[line:272] - INFO: epoch 010 | valid on 'valid' subset:   1791 / 1907 loss=2.067, loss_v1=0, loss_v2=0, nll_loss=0.798, ntokens=410, nsentences=12, sample_size=410.0, sample_size_v1=0, sample_size_v2=0
2326906 <sub> pillow<pred> on<obj> bed<sub> pillow<pred> on<obj> bed<sub> pillow<pred> on<obj> bed<sub> pillow<pred> on<obj> bed<sub> pillow<pred> on<obj> bed<sub> pillow<pred> on<obj> bed ['<sub> handle<pred> on<obj> cabinet<pred> on<obj> cabinet<pred> on<obj> door<sub> leg<pred> of<obj> chair<sub> door<pred> with<obj> handle']
2417019 <sub> horse<pred> on<obj> beach<sub> horse<pred> on<obj> beach<sub> horse<pred> on<obj> beach<sub> horse<pred> on<obj> beach ['<sub> airplane<pred> has<obj> wing<sub> tree<pred> under<obj> airplane']
2023-04-19 05:34:06 - progress_bar.py[line:272] - INFO: epoch 010 | valid on 'valid' subset:   1801 / 1907 loss=2.565, loss_v1=0, loss_v2=0, nll_loss=1.359, ntokens=240, nsentences=12, sample_size=240.0, sample_size_v1=0, sample_size_v2=0
2023-04-19 05:34:15 - progress_bar.py[line:272] - INFO: epoch 010 | valid on 'valid' subset:   1811 / 1907 loss=2.242, loss_v1=0, loss_v2=0, nll_loss=0.995, ntokens=393, nsentences=12, sample_size=393.0, sample_size_v1=0, sample_size_v2=0
2023-04-19 05:34:27 - progress_bar.py[line:272] - INFO: epoch 010 | valid on 'valid' subset:   1821 / 1907 loss=2.277, loss_v1=0, loss_v2=0, nll_loss=1.037, ntokens=417, nsentences=12, sample_size=417.0, sample_size_v1=0, sample_size_v2=0
2023-04-19 05:34:37 - progress_bar.py[line:272] - INFO: epoch 010 | valid on 'valid' subset:   1831 / 1907 loss=2.17, loss_v1=0, loss_v2=0, nll_loss=0.915, ntokens=585, nsentences=12, sample_size=585.0, sample_size_v1=0, sample_size_v2=0
2023-04-19 05:34:48 - progress_bar.py[line:272] - INFO: epoch 010 | valid on 'valid' subset:   1841 / 1907 loss=2.308, loss_v1=0, loss_v2=0, nll_loss=1.072, ntokens=351, nsentences=12, sample_size=351.0, sample_size_v1=0, sample_size_v2=0
2417485 <sub> window<pred> on<obj> building<sub> window<pred> on<obj> building<sub> window<pred> on<obj> building<sub> window<pred> on<obj> building ['<sub> light<pred> over<obj> street<sub> car<pred> on<obj> street<sub> car<pred> on<obj> street<sub> car<pred> of<obj> street']
2326463 <sub> leaf<pred> on<obj> tree<sub> leaf<pred> on<obj> tree ['<sub> bench<pred> under<obj> tree<sub> tree<pred> above<obj> bench']
2023-04-19 05:34:59 - progress_bar.py[line:272] - INFO: epoch 010 | valid on 'valid' subset:   1851 / 1907 loss=2.255, loss_v1=0, loss_v2=0, nll_loss=1.013, ntokens=363, nsentences=12, sample_size=363.0, sample_size_v1=0, sample_size_v2=0
2023-04-19 05:35:08 - progress_bar.py[line:272] - INFO: epoch 010 | valid on 'valid' subset:   1861 / 1907 loss=2.302, loss_v1=0, loss_v2=0, nll_loss=1.063, ntokens=356, nsentences=12, sample_size=356.0, sample_size_v1=0, sample_size_v2=0
2023-04-19 05:35:17 - progress_bar.py[line:272] - INFO: epoch 010 | valid on 'valid' subset:   1871 / 1907 loss=2.105, loss_v1=0, loss_v2=0, nll_loss=0.839, ntokens=568, nsentences=12, sample_size=568.0, sample_size_v1=0, sample_size_v2=0
2023-04-19 05:35:28 - progress_bar.py[line:272] - INFO: epoch 010 | valid on 'valid' subset:   1881 / 1907 loss=2.331, loss_v1=0, loss_v2=0, nll_loss=1.097, ntokens=414, nsentences=12, sample_size=414.0, sample_size_v1=0, sample_size_v2=0
2023-04-19 05:35:38 - progress_bar.py[line:272] - INFO: epoch 010 | valid on 'valid' subset:   1891 / 1907 loss=2.23, loss_v1=0, loss_v2=0, nll_loss=0.98, ntokens=444, nsentences=12, sample_size=444.0, sample_size_v1=0, sample_size_v2=0
2417938 <sub> food<pred> on<obj> plate<sub> food<pred> on<obj> plate<sub> food<pred> on<obj> plate<sub> food<pred> on<obj> plate ['<sub> banana<pred> has<obj> banana<sub> chair<pred> at<obj> table']
2326034 <sub> man<pred> wearing<obj> jacket<pred> wearing<obj> glove<pred> wearing<obj> glove<pred> wearing<obj> glove<pred> wearing<obj> glove<pred> wearing<obj> glove<pred> wearing<obj> glove<pred> wearing<obj> glove<pred> wearing<obj> glove<pred> wearing<obj> glove<pred> wearing<obj> glove<pred> wearing<obj> glove<pred> wearing<obj> glove<pred> wearing<obj> glove<pred> wearing<obj> glove<pred> wearing<obj> glove<pred> wearing<obj> glove<pred> wearing<obj> glove<pred> wearing<obj> glove<pred> wearing<obj> glove<pred> wearing<obj> glove<pred> wearing<obj> glove<pred> wearing<obj> glove<pred> wearing<obj> glove<pred> wearing ['<sub> snow<pred> covering<obj> snow<sub> snow<pred> covering<obj> snow<sub> snow<pred> covering<obj> snow<sub> snow<pred> covering<obj> snow<sub> snow<pred> covered in<obj> snow<sub> tree<pred> in<obj> snow<sub> head<pred> of<obj> person<pred> of<obj> man<sub> leg<pred> of<obj> man<sub> leg<pred> of<obj> man<pred> of<obj> person<sub> leg<pred> of<obj> person<sub> hand<pred> of<obj> man<sub> head<pred> of<obj> person<sub> arm<pred> of<obj> person<pred> of<obj> man<sub> arm<pred> of<obj> man<sub> arm<pred>']
2023-04-19 05:35:48 - progress_bar.py[line:272] - INFO: epoch 010 | valid on 'valid' subset:   1901 / 1907 loss=2.459, loss_v1=0, loss_v2=0, nll_loss=1.239, ntokens=447, nsentences=12, sample_size=447.0, sample_size_v1=0, sample_size_v2=0
local datafile ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 1 begin to initialize row_count and line_idx-to-offset mapping
2023-04-19 05:35:56 - progress_bar.py[line:282] - INFO: epoch 010 | valid on 'valid' subset | loss 2.31 | loss_v1 0 | loss_v2 0 | nll_loss 1.073 | ntokens 430.208 | nsentences 11.998 | sample_size 430.208 | sample_size_v1 0 | sample_size_v2 0 | ppl 2.1 | wps 413.9 | wpb 430.2 | bsz 12 | num_updates 5770
2023-04-19 05:35:56 - checkpoint_utils.py[line:64] - INFO: Preparing to save checkpoint for epoch 10 @ 5770 updates
2023-04-19 05:35:56 - trainer.py[line:431] - INFO: Saving checkpoint to ../../checkpoints/OFA/sgcls_checkpoints/_12_3e-5_512/checkpoint10.pt
local datafile ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 1 finished initializing row_count and line_idx-to-offset mapping
file ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 1 row count 27700 total row count 55400
slice_id 1 seek offset 27700
2023-04-19 05:35:59 - trainer.py[line:441] - INFO: Finished saving checkpoint to ../../checkpoints/OFA/sgcls_checkpoints/_12_3e-5_512/checkpoint10.pt
2023-04-19 05:36:04 - checkpoint_utils.py[line:133] - INFO: Saved checkpoint ../../checkpoints/OFA/sgcls_checkpoints/_12_3e-5_512/checkpoint10.pt (epoch 10 @ 5770 updates, score 2.31) (writing took 8.322819335386157 seconds)
2023-04-19 05:36:04 - train.py[line:332] - INFO: end of epoch 10 (average epoch stats below)
2023-04-19 05:36:04 - progress_bar.py[line:282] - INFO: epoch 010 | loss 2.326 | loss_v1 0 | loss_v2 0 | nll_loss 1.121 | ntokens 3151.96 | nsentences 95.847 | sample_size 3151.96 | sample_size_v1 0 | sample_size_v2 0 | ppl 2.17 | wps 499.4 | ups 0.16 | wpb 3152 | bsz 95.8 | num_updates 5770 | lr 5.36503e-06 | gnorm 1.915 | clip 100 | loss_scale 128 | train_wall 1647 | gb_free 13.1 | wall 18573
2023-04-19 05:36:04 - trainer.py[line:639] - INFO: loading train data for epoch 11
local datafile ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 0 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 0 finished initializing row_count and line_idx-to-offset mapping
file ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 0 row count 27700 total row count 55400
slice_id 0 seek offset 0
2023-04-19 05:36:06 - trainer.py[line:703] - INFO: begin training epoch 11
2023-04-19 05:36:06 - train.py[line:305] - INFO: Start iterating over samples
2023-04-19 05:36:35 - progress_bar.py[line:272] - INFO: epoch 011:     10 / 578 loss=2.292, loss_v1=0, loss_v2=0, nll_loss=1.082, ntokens=3155.9, nsentences=96, sample_size=3155.9, sample_size_v1=0, sample_size_v2=0, ppl=2.12, wps=15.6, ups=0, wpb=3155.9, bsz=96, num_updates=5780, lr=5.31902e-06, gnorm=1.967, clip=100, loss_scale=128, train_wall=28, gb_free=12, wall=18604
2023-04-19 05:37:04 - progress_bar.py[line:272] - INFO: epoch 011:     20 / 578 loss=2.27, loss_v1=0, loss_v2=0, nll_loss=1.059, ntokens=3019.9, nsentences=96, sample_size=3019.9, sample_size_v1=0, sample_size_v2=0, ppl=2.08, wps=1064.9, ups=0.35, wpb=3019.9, bsz=96, num_updates=5790, lr=5.27301e-06, gnorm=1.942, clip=100, loss_scale=128, train_wall=28, gb_free=12.1, wall=18632
2023-04-19 05:37:32 - progress_bar.py[line:272] - INFO: epoch 011:     30 / 578 loss=2.23, loss_v1=0, loss_v2=0, nll_loss=1.016, ntokens=3198.1, nsentences=96, sample_size=3198.1, sample_size_v1=0, sample_size_v2=0, ppl=2.02, wps=1116.1, ups=0.35, wpb=3198.1, bsz=96, num_updates=5800, lr=5.22699e-06, gnorm=1.769, clip=100, loss_scale=128, train_wall=29, gb_free=11.9, wall=18661
2023-04-19 05:38:01 - progress_bar.py[line:272] - INFO: epoch 011:     40 / 578 loss=2.204, loss_v1=0, loss_v2=0, nll_loss=0.986, ntokens=3098.5, nsentences=96, sample_size=3098.5, sample_size_v1=0, sample_size_v2=0, ppl=1.98, wps=1084.1, ups=0.35, wpb=3098.5, bsz=96, num_updates=5810, lr=5.18098e-06, gnorm=1.819, clip=100, loss_scale=128, train_wall=29, gb_free=11.5, wall=18690
2023-04-19 05:38:30 - progress_bar.py[line:272] - INFO: epoch 011:     50 / 578 loss=2.184, loss_v1=0, loss_v2=0, nll_loss=0.961, ntokens=3663.6, nsentences=96, sample_size=3663.6, sample_size_v1=0, sample_size_v2=0, ppl=1.95, wps=1244.1, ups=0.34, wpb=3663.6, bsz=96, num_updates=5820, lr=5.13497e-06, gnorm=1.607, clip=100, loss_scale=128, train_wall=29, gb_free=11.6, wall=18719
2023-04-19 05:38:59 - progress_bar.py[line:272] - INFO: epoch 011:     60 / 578 loss=2.254, loss_v1=0, loss_v2=0, nll_loss=1.041, ntokens=3257.5, nsentences=96, sample_size=3257.5, sample_size_v1=0, sample_size_v2=0, ppl=2.06, wps=1131.2, ups=0.35, wpb=3257.5, bsz=96, num_updates=5830, lr=5.08896e-06, gnorm=1.932, clip=100, loss_scale=128, train_wall=29, gb_free=11.3, wall=18748
2023-04-19 05:39:28 - progress_bar.py[line:272] - INFO: epoch 011:     70 / 578 loss=2.283, loss_v1=0, loss_v2=0, nll_loss=1.072, ntokens=3082.1, nsentences=96, sample_size=3082.1, sample_size_v1=0, sample_size_v2=0, ppl=2.1, wps=1082.2, ups=0.35, wpb=3082.1, bsz=96, num_updates=5840, lr=5.04294e-06, gnorm=2.128, clip=100, loss_scale=128, train_wall=28, gb_free=12.1, wall=18776
2023-04-19 05:39:57 - progress_bar.py[line:272] - INFO: epoch 011:     80 / 578 loss=2.325, loss_v1=0, loss_v2=0, nll_loss=1.12, ntokens=3194.5, nsentences=96, sample_size=3194.5, sample_size_v1=0, sample_size_v2=0, ppl=2.17, wps=1106.8, ups=0.35, wpb=3194.5, bsz=96, num_updates=5850, lr=4.99693e-06, gnorm=1.939, clip=100, loss_scale=128, train_wall=29, gb_free=11.5, wall=18805
2023-04-19 05:40:25 - progress_bar.py[line:272] - INFO: epoch 011:     90 / 578 loss=2.297, loss_v1=0, loss_v2=0, nll_loss=1.088, ntokens=3278.1, nsentences=96, sample_size=3278.1, sample_size_v1=0, sample_size_v2=0, ppl=2.13, wps=1134.8, ups=0.35, wpb=3278.1, bsz=96, num_updates=5860, lr=4.95092e-06, gnorm=1.941, clip=100, loss_scale=128, train_wall=29, gb_free=12.3, wall=18834
2023-04-19 05:40:55 - progress_bar.py[line:272] - INFO: epoch 011:    100 / 578 loss=2.278, loss_v1=0, loss_v2=0, nll_loss=1.066, ntokens=3340, nsentences=96, sample_size=3340, sample_size_v1=0, sample_size_v2=0, ppl=2.09, wps=1147.9, ups=0.34, wpb=3340, bsz=96, num_updates=5870, lr=4.90491e-06, gnorm=1.868, clip=100, loss_scale=128, train_wall=29, gb_free=12, wall=18863
2023-04-19 05:41:23 - progress_bar.py[line:272] - INFO: epoch 011:    110 / 578 loss=2.287, loss_v1=0, loss_v2=0, nll_loss=1.078, ntokens=3279, nsentences=96, sample_size=3279, sample_size_v1=0, sample_size_v2=0, ppl=2.11, wps=1133.4, ups=0.35, wpb=3279, bsz=96, num_updates=5880, lr=4.8589e-06, gnorm=1.867, clip=100, loss_scale=128, train_wall=29, gb_free=11.5, wall=18892
2023-04-19 05:41:52 - progress_bar.py[line:272] - INFO: epoch 011:    120 / 578 loss=2.277, loss_v1=0, loss_v2=0, nll_loss=1.067, ntokens=3135.8, nsentences=96, sample_size=3135.8, sample_size_v1=0, sample_size_v2=0, ppl=2.1, wps=1092.7, ups=0.35, wpb=3135.8, bsz=96, num_updates=5890, lr=4.81288e-06, gnorm=2.03, clip=100, loss_scale=128, train_wall=29, gb_free=12, wall=18921
2023-04-19 05:42:21 - progress_bar.py[line:272] - INFO: epoch 011:    130 / 578 loss=2.289, loss_v1=0, loss_v2=0, nll_loss=1.079, ntokens=3300.8, nsentences=96, sample_size=3300.8, sample_size_v1=0, sample_size_v2=0, ppl=2.11, wps=1145.1, ups=0.35, wpb=3300.8, bsz=96, num_updates=5900, lr=4.76687e-06, gnorm=1.959, clip=100, loss_scale=128, train_wall=29, gb_free=11.7, wall=18950
2023-04-19 05:42:50 - progress_bar.py[line:272] - INFO: epoch 011:    140 / 578 loss=2.33, loss_v1=0, loss_v2=0, nll_loss=1.126, ntokens=3050.7, nsentences=96, sample_size=3050.7, sample_size_v1=0, sample_size_v2=0, ppl=2.18, wps=1068.3, ups=0.35, wpb=3050.7, bsz=96, num_updates=5910, lr=4.72086e-06, gnorm=2.092, clip=100, loss_scale=128, train_wall=29, gb_free=12.2, wall=18978
2023-04-19 05:43:18 - progress_bar.py[line:272] - INFO: epoch 011:    150 / 578 loss=2.332, loss_v1=0, loss_v2=0, nll_loss=1.129, ntokens=3285.6, nsentences=96, sample_size=3285.6, sample_size_v1=0, sample_size_v2=0, ppl=2.19, wps=1148.6, ups=0.35, wpb=3285.6, bsz=96, num_updates=5920, lr=4.67485e-06, gnorm=1.943, clip=100, loss_scale=128, train_wall=29, gb_free=12, wall=19007
2023-04-19 05:43:47 - progress_bar.py[line:272] - INFO: epoch 011:    160 / 578 loss=2.355, loss_v1=0, loss_v2=0, nll_loss=1.152, ntokens=3249.9, nsentences=96, sample_size=3249.9, sample_size_v1=0, sample_size_v2=0, ppl=2.22, wps=1143, ups=0.35, wpb=3249.9, bsz=96, num_updates=5930, lr=4.62883e-06, gnorm=1.933, clip=100, loss_scale=128, train_wall=28, gb_free=11.9, wall=19035
2023-04-19 05:44:15 - progress_bar.py[line:272] - INFO: epoch 011:    170 / 578 loss=2.347, loss_v1=0, loss_v2=0, nll_loss=1.144, ntokens=3168.9, nsentences=96, sample_size=3168.9, sample_size_v1=0, sample_size_v2=0, ppl=2.21, wps=1114.6, ups=0.35, wpb=3168.9, bsz=96, num_updates=5940, lr=4.58282e-06, gnorm=1.954, clip=100, loss_scale=128, train_wall=28, gb_free=12.2, wall=19064
2023-04-19 05:44:44 - progress_bar.py[line:272] - INFO: epoch 011:    180 / 578 loss=2.344, loss_v1=0, loss_v2=0, nll_loss=1.142, ntokens=3200, nsentences=96, sample_size=3200, sample_size_v1=0, sample_size_v2=0, ppl=2.21, wps=1119.8, ups=0.35, wpb=3200, bsz=96, num_updates=5950, lr=4.53681e-06, gnorm=1.954, clip=100, loss_scale=128, train_wall=29, gb_free=11.9, wall=19092
2023-04-19 05:45:12 - progress_bar.py[line:272] - INFO: epoch 011:    190 / 578 loss=2.35, loss_v1=0, loss_v2=0, nll_loss=1.147, ntokens=3283.3, nsentences=96, sample_size=3283.3, sample_size_v1=0, sample_size_v2=0, ppl=2.21, wps=1151.5, ups=0.35, wpb=3283.3, bsz=96, num_updates=5960, lr=4.4908e-06, gnorm=2.002, clip=100, loss_scale=128, train_wall=28, gb_free=11.5, wall=19121
2023-04-19 05:45:41 - progress_bar.py[line:272] - INFO: epoch 011:    200 / 578 loss=2.321, loss_v1=0, loss_v2=0, nll_loss=1.116, ntokens=3195.8, nsentences=96, sample_size=3195.8, sample_size_v1=0, sample_size_v2=0, ppl=2.17, wps=1125.7, ups=0.35, wpb=3195.8, bsz=96, num_updates=5970, lr=4.44479e-06, gnorm=1.992, clip=100, loss_scale=128, train_wall=28, gb_free=11.7, wall=19149
2023-04-19 05:46:09 - progress_bar.py[line:272] - INFO: epoch 011:    210 / 578 loss=2.324, loss_v1=0, loss_v2=0, nll_loss=1.12, ntokens=3121.2, nsentences=96, sample_size=3121.2, sample_size_v1=0, sample_size_v2=0, ppl=2.17, wps=1101.7, ups=0.35, wpb=3121.2, bsz=96, num_updates=5980, lr=4.39877e-06, gnorm=2.039, clip=100, loss_scale=128, train_wall=28, gb_free=12.4, wall=19177
2023-04-19 05:46:37 - progress_bar.py[line:272] - INFO: epoch 011:    220 / 578 loss=2.355, loss_v1=0, loss_v2=0, nll_loss=1.154, ntokens=3082.3, nsentences=96, sample_size=3082.3, sample_size_v1=0, sample_size_v2=0, ppl=2.23, wps=1088.3, ups=0.35, wpb=3082.3, bsz=96, num_updates=5990, lr=4.35276e-06, gnorm=2.051, clip=100, loss_scale=128, train_wall=28, gb_free=11.8, wall=19206
2023-04-19 05:47:06 - progress_bar.py[line:272] - INFO: epoch 011:    230 / 578 loss=2.316, loss_v1=0, loss_v2=0, nll_loss=1.111, ntokens=3034.8, nsentences=96, sample_size=3034.8, sample_size_v1=0, sample_size_v2=0, ppl=2.16, wps=1063.4, ups=0.35, wpb=3034.8, bsz=96, num_updates=6000, lr=4.30675e-06, gnorm=2.168, clip=100, loss_scale=128, train_wall=29, gb_free=12.2, wall=19234
2023-04-19 05:47:34 - progress_bar.py[line:272] - INFO: epoch 011:    240 / 578 loss=2.354, loss_v1=0, loss_v2=0, nll_loss=1.153, ntokens=2951.6, nsentences=96, sample_size=2951.6, sample_size_v1=0, sample_size_v2=0, ppl=2.22, wps=1040.7, ups=0.35, wpb=2951.6, bsz=96, num_updates=6010, lr=4.26074e-06, gnorm=2.321, clip=100, loss_scale=128, train_wall=28, gb_free=12.1, wall=19263
2023-04-19 05:48:03 - progress_bar.py[line:272] - INFO: epoch 011:    250 / 578 loss=2.338, loss_v1=0, loss_v2=0, nll_loss=1.133, ntokens=3097.2, nsentences=96, sample_size=3097.2, sample_size_v1=0, sample_size_v2=0, ppl=2.19, wps=1089.2, ups=0.35, wpb=3097.2, bsz=96, num_updates=6020, lr=4.21472e-06, gnorm=2.097, clip=100, loss_scale=128, train_wall=28, gb_free=12.2, wall=19291
2023-04-19 05:48:31 - progress_bar.py[line:272] - INFO: epoch 011:    260 / 578 loss=2.328, loss_v1=0, loss_v2=0, nll_loss=1.123, ntokens=3165.4, nsentences=96, sample_size=3165.4, sample_size_v1=0, sample_size_v2=0, ppl=2.18, wps=1113.9, ups=0.35, wpb=3165.4, bsz=96, num_updates=6030, lr=4.16871e-06, gnorm=2.045, clip=100, loss_scale=128, train_wall=28, gb_free=12.1, wall=19320
2023-04-19 05:48:59 - progress_bar.py[line:272] - INFO: epoch 011:    270 / 578 loss=2.339, loss_v1=0, loss_v2=0, nll_loss=1.136, ntokens=3092, nsentences=96, sample_size=3092, sample_size_v1=0, sample_size_v2=0, ppl=2.2, wps=1087.1, ups=0.35, wpb=3092, bsz=96, num_updates=6040, lr=4.1227e-06, gnorm=2.115, clip=100, loss_scale=128, train_wall=28, gb_free=11.8, wall=19348
2023-04-19 05:49:28 - progress_bar.py[line:272] - INFO: epoch 011:    280 / 578 loss=2.331, loss_v1=0, loss_v2=0, nll_loss=1.128, ntokens=3162.6, nsentences=96, sample_size=3162.6, sample_size_v1=0, sample_size_v2=0, ppl=2.19, wps=1110.1, ups=0.35, wpb=3162.6, bsz=96, num_updates=6050, lr=4.07669e-06, gnorm=2.056, clip=100, loss_scale=128, train_wall=28, gb_free=11.8, wall=19377
2023-04-19 05:49:56 - progress_bar.py[line:272] - INFO: epoch 011:    290 / 578 loss=2.319, loss_v1=0, loss_v2=0, nll_loss=1.113, ntokens=3153.9, nsentences=96, sample_size=3153.9, sample_size_v1=0, sample_size_v2=0, ppl=2.16, wps=1107.6, ups=0.35, wpb=3153.9, bsz=96, num_updates=6060, lr=4.03067e-06, gnorm=2.076, clip=100, loss_scale=128, train_wall=28, gb_free=12.4, wall=19405
2023-04-19 05:50:25 - progress_bar.py[line:272] - INFO: epoch 011:    300 / 578 loss=2.354, loss_v1=0, loss_v2=0, nll_loss=1.152, ntokens=3017.7, nsentences=96, sample_size=3017.7, sample_size_v1=0, sample_size_v2=0, ppl=2.22, wps=1055.6, ups=0.35, wpb=3017.7, bsz=96, num_updates=6070, lr=3.98466e-06, gnorm=2.212, clip=100, loss_scale=128, train_wall=29, gb_free=12.2, wall=19434
2023-04-19 05:50:54 - progress_bar.py[line:272] - INFO: epoch 011:    310 / 578 loss=2.333, loss_v1=0, loss_v2=0, nll_loss=1.13, ntokens=3209.1, nsentences=96, sample_size=3209.1, sample_size_v1=0, sample_size_v2=0, ppl=2.19, wps=1124.4, ups=0.35, wpb=3209.1, bsz=96, num_updates=6080, lr=3.93865e-06, gnorm=2.017, clip=100, loss_scale=128, train_wall=29, gb_free=12.3, wall=19462
2023-04-19 05:51:22 - progress_bar.py[line:272] - INFO: epoch 011:    320 / 578 loss=2.338, loss_v1=0, loss_v2=0, nll_loss=1.134, ntokens=3312.3, nsentences=96, sample_size=3312.3, sample_size_v1=0, sample_size_v2=0, ppl=2.2, wps=1157.6, ups=0.35, wpb=3312.3, bsz=96, num_updates=6090, lr=3.89264e-06, gnorm=2.185, clip=100, loss_scale=128, train_wall=29, gb_free=11.2, wall=19491
2023-04-19 05:51:51 - progress_bar.py[line:272] - INFO: epoch 011:    330 / 578 loss=2.322, loss_v1=0, loss_v2=0, nll_loss=1.116, ntokens=3078.5, nsentences=96, sample_size=3078.5, sample_size_v1=0, sample_size_v2=0, ppl=2.17, wps=1075.8, ups=0.35, wpb=3078.5, bsz=96, num_updates=6100, lr=3.84663e-06, gnorm=2.132, clip=100, loss_scale=128, train_wall=29, gb_free=12.7, wall=19519
2023-04-19 05:52:19 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 128.0
2023-04-19 05:52:22 - progress_bar.py[line:272] - INFO: epoch 011:    341 / 578 loss=2.347, loss_v1=0, loss_v2=0, nll_loss=1.145, ntokens=3148.8, nsentences=96, sample_size=3148.8, sample_size_v1=0, sample_size_v2=0, ppl=2.21, wps=1007.6, ups=0.32, wpb=3148.8, bsz=96, num_updates=6110, lr=3.80061e-06, gnorm=2.113, clip=100, loss_scale=128, train_wall=31, gb_free=12, wall=19551
2023-04-19 05:52:50 - progress_bar.py[line:272] - INFO: epoch 011:    351 / 578 loss=2.33, loss_v1=0, loss_v2=0, nll_loss=1.127, ntokens=3109.1, nsentences=96, sample_size=3109.1, sample_size_v1=0, sample_size_v2=0, ppl=2.18, wps=1095.4, ups=0.35, wpb=3109.1, bsz=96, num_updates=6120, lr=3.7546e-06, gnorm=2.082, clip=100, loss_scale=128, train_wall=28, gb_free=12.6, wall=19579
2023-04-19 05:53:19 - progress_bar.py[line:272] - INFO: epoch 011:    361 / 578 loss=2.326, loss_v1=0, loss_v2=0, nll_loss=1.121, ntokens=3191.4, nsentences=96, sample_size=3191.4, sample_size_v1=0, sample_size_v2=0, ppl=2.17, wps=1121, ups=0.35, wpb=3191.4, bsz=96, num_updates=6130, lr=3.70859e-06, gnorm=1.968, clip=100, loss_scale=128, train_wall=28, gb_free=11.9, wall=19607
2023-04-19 05:53:48 - progress_bar.py[line:272] - INFO: epoch 011:    371 / 578 loss=2.354, loss_v1=0, loss_v2=0, nll_loss=1.153, ntokens=3444.8, nsentences=96, sample_size=3444.8, sample_size_v1=0, sample_size_v2=0, ppl=2.22, wps=1196.5, ups=0.35, wpb=3444.8, bsz=96, num_updates=6140, lr=3.66258e-06, gnorm=1.946, clip=100, loss_scale=128, train_wall=29, gb_free=12.1, wall=19636
2023-04-19 05:54:16 - progress_bar.py[line:272] - INFO: epoch 011:    381 / 578 loss=2.339, loss_v1=0, loss_v2=0, nll_loss=1.136, ntokens=3326.3, nsentences=96, sample_size=3326.3, sample_size_v1=0, sample_size_v2=0, ppl=2.2, wps=1163.3, ups=0.35, wpb=3326.3, bsz=96, num_updates=6150, lr=3.61656e-06, gnorm=2.121, clip=100, loss_scale=128, train_wall=29, gb_free=12.4, wall=19665
2023-04-19 05:54:45 - progress_bar.py[line:272] - INFO: epoch 011:    391 / 578 loss=2.345, loss_v1=0, loss_v2=0, nll_loss=1.142, ntokens=3157.5, nsentences=96, sample_size=3157.5, sample_size_v1=0, sample_size_v2=0, ppl=2.21, wps=1108.3, ups=0.35, wpb=3157.5, bsz=96, num_updates=6160, lr=3.57055e-06, gnorm=2.226, clip=100, loss_scale=128, train_wall=28, gb_free=12.2, wall=19693
2023-04-19 05:55:13 - progress_bar.py[line:272] - INFO: epoch 011:    401 / 578 loss=2.308, loss_v1=0, loss_v2=0, nll_loss=1.1, ntokens=3170.5, nsentences=96, sample_size=3170.5, sample_size_v1=0, sample_size_v2=0, ppl=2.14, wps=1109.4, ups=0.35, wpb=3170.5, bsz=96, num_updates=6170, lr=3.52454e-06, gnorm=2.18, clip=100, loss_scale=128, train_wall=29, gb_free=12.5, wall=19722
2023-04-19 05:55:42 - progress_bar.py[line:272] - INFO: epoch 011:    411 / 578 loss=2.351, loss_v1=0, loss_v2=0, nll_loss=1.149, ntokens=2914.3, nsentences=96, sample_size=2914.3, sample_size_v1=0, sample_size_v2=0, ppl=2.22, wps=1023.2, ups=0.35, wpb=2914.3, bsz=96, num_updates=6180, lr=3.47853e-06, gnorm=2.366, clip=100, loss_scale=128, train_wall=28, gb_free=12.7, wall=19750
2023-04-19 05:56:10 - progress_bar.py[line:272] - INFO: epoch 011:    421 / 578 loss=2.333, loss_v1=0, loss_v2=0, nll_loss=1.129, ntokens=3065.6, nsentences=96, sample_size=3065.6, sample_size_v1=0, sample_size_v2=0, ppl=2.19, wps=1073.2, ups=0.35, wpb=3065.6, bsz=96, num_updates=6190, lr=3.43252e-06, gnorm=2.201, clip=100, loss_scale=128, train_wall=29, gb_free=12.2, wall=19779
2023-04-19 05:56:39 - progress_bar.py[line:272] - INFO: epoch 011:    431 / 578 loss=2.323, loss_v1=0, loss_v2=0, nll_loss=1.118, ntokens=3096.5, nsentences=96, sample_size=3096.5, sample_size_v1=0, sample_size_v2=0, ppl=2.17, wps=1090, ups=0.35, wpb=3096.5, bsz=96, num_updates=6200, lr=3.3865e-06, gnorm=2.246, clip=100, loss_scale=128, train_wall=28, gb_free=12.6, wall=19807
2023-04-19 05:57:07 - progress_bar.py[line:272] - INFO: epoch 011:    441 / 578 loss=2.355, loss_v1=0, loss_v2=0, nll_loss=1.154, ntokens=2923, nsentences=96, sample_size=2923, sample_size_v1=0, sample_size_v2=0, ppl=2.23, wps=1025.6, ups=0.35, wpb=2923, bsz=96, num_updates=6210, lr=3.34049e-06, gnorm=2.349, clip=100, loss_scale=128, train_wall=28, gb_free=11.8, wall=19836
2023-04-19 05:57:36 - progress_bar.py[line:272] - INFO: epoch 011:    451 / 578 loss=2.335, loss_v1=0, loss_v2=0, nll_loss=1.13, ntokens=3056.4, nsentences=96, sample_size=3056.4, sample_size_v1=0, sample_size_v2=0, ppl=2.19, wps=1072.9, ups=0.35, wpb=3056.4, bsz=96, num_updates=6220, lr=3.29448e-06, gnorm=2.262, clip=100, loss_scale=128, train_wall=28, gb_free=12.3, wall=19864
2023-04-19 05:58:04 - progress_bar.py[line:272] - INFO: epoch 011:    461 / 578 loss=2.325, loss_v1=0, loss_v2=0, nll_loss=1.12, ntokens=3025, nsentences=96, sample_size=3025, sample_size_v1=0, sample_size_v2=0, ppl=2.17, wps=1065.2, ups=0.35, wpb=3025, bsz=96, num_updates=6230, lr=3.24847e-06, gnorm=2.162, clip=100, loss_scale=128, train_wall=28, gb_free=12.5, wall=19893
2023-04-19 05:58:33 - progress_bar.py[line:272] - INFO: epoch 011:    471 / 578 loss=2.348, loss_v1=0, loss_v2=0, nll_loss=1.146, ntokens=3057.1, nsentences=96, sample_size=3057.1, sample_size_v1=0, sample_size_v2=0, ppl=2.21, wps=1071, ups=0.35, wpb=3057.1, bsz=96, num_updates=6240, lr=3.20245e-06, gnorm=2.178, clip=100, loss_scale=128, train_wall=29, gb_free=12.7, wall=19921
2023-04-19 05:59:01 - progress_bar.py[line:272] - INFO: epoch 011:    481 / 578 loss=2.339, loss_v1=0, loss_v2=0, nll_loss=1.135, ntokens=2872.8, nsentences=96, sample_size=2872.8, sample_size_v1=0, sample_size_v2=0, ppl=2.2, wps=1008.4, ups=0.35, wpb=2872.8, bsz=96, num_updates=6250, lr=3.15644e-06, gnorm=2.219, clip=100, loss_scale=128, train_wall=28, gb_free=12.3, wall=19950
2023-04-19 05:59:30 - progress_bar.py[line:272] - INFO: epoch 011:    491 / 578 loss=2.315, loss_v1=0, loss_v2=0, nll_loss=1.111, ntokens=3108.2, nsentences=96, sample_size=3108.2, sample_size_v1=0, sample_size_v2=0, ppl=2.16, wps=1093.9, ups=0.35, wpb=3108.2, bsz=96, num_updates=6260, lr=3.11043e-06, gnorm=2.157, clip=100, loss_scale=128, train_wall=28, gb_free=12.3, wall=19978
2023-04-19 05:59:58 - progress_bar.py[line:272] - INFO: epoch 011:    501 / 578 loss=2.315, loss_v1=0, loss_v2=0, nll_loss=1.11, ntokens=3134.7, nsentences=96, sample_size=3134.7, sample_size_v1=0, sample_size_v2=0, ppl=2.16, wps=1101.7, ups=0.35, wpb=3134.7, bsz=96, num_updates=6270, lr=3.06442e-06, gnorm=2.14, clip=100, loss_scale=128, train_wall=28, gb_free=12, wall=20007
2023-04-19 06:00:27 - progress_bar.py[line:272] - INFO: epoch 011:    511 / 578 loss=2.311, loss_v1=0, loss_v2=0, nll_loss=1.105, ntokens=3161.3, nsentences=96, sample_size=3161.3, sample_size_v1=0, sample_size_v2=0, ppl=2.15, wps=1104.2, ups=0.35, wpb=3161.3, bsz=96, num_updates=6280, lr=3.0184e-06, gnorm=2.001, clip=100, loss_scale=128, train_wall=29, gb_free=12.5, wall=20035
2023-04-19 06:00:55 - progress_bar.py[line:272] - INFO: epoch 011:    521 / 578 loss=2.312, loss_v1=0, loss_v2=0, nll_loss=1.106, ntokens=3331.1, nsentences=95.6, sample_size=3331.1, sample_size_v1=0, sample_size_v2=0, ppl=2.15, wps=1167.8, ups=0.35, wpb=3331.1, bsz=95.6, num_updates=6290, lr=2.97239e-06, gnorm=2.026, clip=100, loss_scale=128, train_wall=28, gb_free=12.4, wall=20064
2023-04-19 06:01:24 - progress_bar.py[line:272] - INFO: epoch 011:    531 / 578 loss=2.339, loss_v1=0, loss_v2=0, nll_loss=1.136, ntokens=3032.2, nsentences=96, sample_size=3032.2, sample_size_v1=0, sample_size_v2=0, ppl=2.2, wps=1069.6, ups=0.35, wpb=3032.2, bsz=96, num_updates=6300, lr=2.92638e-06, gnorm=2.112, clip=100, loss_scale=128, train_wall=28, gb_free=12.2, wall=20092
2023-04-19 06:01:52 - progress_bar.py[line:272] - INFO: epoch 011:    541 / 578 loss=2.311, loss_v1=0, loss_v2=0, nll_loss=1.105, ntokens=3004.2, nsentences=96, sample_size=3004.2, sample_size_v1=0, sample_size_v2=0, ppl=2.15, wps=1054.2, ups=0.35, wpb=3004.2, bsz=96, num_updates=6310, lr=2.88037e-06, gnorm=2.166, clip=100, loss_scale=128, train_wall=28, gb_free=12.3, wall=20121
2023-04-19 06:02:21 - progress_bar.py[line:272] - INFO: epoch 011:    551 / 578 loss=2.316, loss_v1=0, loss_v2=0, nll_loss=1.109, ntokens=3193.9, nsentences=96, sample_size=3193.9, sample_size_v1=0, sample_size_v2=0, ppl=2.16, wps=1108.3, ups=0.35, wpb=3193.9, bsz=96, num_updates=6320, lr=2.83436e-06, gnorm=2.108, clip=100, loss_scale=128, train_wall=29, gb_free=12.4, wall=20150
2023-04-19 06:02:50 - progress_bar.py[line:272] - INFO: epoch 011:    561 / 578 loss=2.316, loss_v1=0, loss_v2=0, nll_loss=1.108, ntokens=3242.7, nsentences=96, sample_size=3242.7, sample_size_v1=0, sample_size_v2=0, ppl=2.16, wps=1127.9, ups=0.35, wpb=3242.7, bsz=96, num_updates=6330, lr=2.78834e-06, gnorm=2.041, clip=100, loss_scale=128, train_wall=29, gb_free=12.3, wall=20178
2023-04-19 06:03:18 - progress_bar.py[line:272] - INFO: epoch 011:    571 / 578 loss=2.321, loss_v1=0, loss_v2=0, nll_loss=1.115, ntokens=3186.9, nsentences=96, sample_size=3186.9, sample_size_v1=0, sample_size_v2=0, ppl=2.17, wps=1111.5, ups=0.35, wpb=3186.9, bsz=96, num_updates=6340, lr=2.74233e-06, gnorm=2.124, clip=100, loss_scale=128, train_wall=29, gb_free=12.4, wall=20207
2023-04-19 06:03:36 - checkpoint_utils.py[line:64] - INFO: Preparing to save checkpoint for epoch 11 @ 6347 updates
2023-04-19 06:03:36 - trainer.py[line:431] - INFO: Saving checkpoint to ../../checkpoints/OFA/sgcls_checkpoints/_12_3e-5_512/checkpoint11.pt
local datafile ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 1 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 1 finished initializing row_count and line_idx-to-offset mapping
file ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 1 row count 27700 total row count 55400
slice_id 1 seek offset 27700
2023-04-19 06:03:39 - trainer.py[line:441] - INFO: Finished saving checkpoint to ../../checkpoints/OFA/sgcls_checkpoints/_12_3e-5_512/checkpoint11.pt
2023-04-19 06:03:41 - checkpoint_utils.py[line:133] - INFO: Saved checkpoint ../../checkpoints/OFA/sgcls_checkpoints/_12_3e-5_512/checkpoint11.pt (epoch 11 @ 6347 updates, score None) (writing took 5.512719412334263 seconds)
2023-04-19 06:03:41 - train.py[line:332] - INFO: end of epoch 11 (average epoch stats below)
2023-04-19 06:03:41 - progress_bar.py[line:282] - INFO: epoch 011 | loss 2.318 | loss_v1 0 | loss_v2 0 | nll_loss 1.112 | ntokens 3150.79 | nsentences 95.847 | sample_size 3150.79 | sample_size_v1 0 | sample_size_v2 0 | ppl 2.16 | wps 1097 | ups 0.35 | wpb 3150.8 | bsz 95.8 | num_updates 6347 | lr 2.71012e-06 | gnorm 2.067 | clip 100 | loss_scale 128 | train_wall 1647 | gb_free 13.1 | wall 20230
2023-04-19 06:03:41 - trainer.py[line:639] - INFO: loading train data for epoch 12
local datafile ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 0 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 0 finished initializing row_count and line_idx-to-offset mapping
file ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 0 row count 27700 total row count 55400
slice_id 0 seek offset 0
2023-04-19 06:03:43 - trainer.py[line:703] - INFO: begin training epoch 12
2023-04-19 06:03:43 - train.py[line:305] - INFO: Start iterating over samples
2023-04-19 06:03:52 - progress_bar.py[line:272] - INFO: epoch 012:      3 / 578 loss=2.325, loss_v1=0, loss_v2=0, nll_loss=1.121, ntokens=2893.6, nsentences=87.6, sample_size=2893.6, sample_size_v1=0, sample_size_v2=0, ppl=2.18, wps=855.3, ups=0.3, wpb=2893.6, bsz=87.6, num_updates=6350, lr=2.69632e-06, gnorm=2.308, clip=100, loss_scale=128, train_wall=26, gb_free=11.9, wall=20241
2023-04-19 06:04:21 - progress_bar.py[line:272] - INFO: epoch 012:     13 / 578 loss=2.26, loss_v1=0, loss_v2=0, nll_loss=1.047, ntokens=3108.9, nsentences=96, sample_size=3108.9, sample_size_v1=0, sample_size_v2=0, ppl=2.07, wps=1090.7, ups=0.35, wpb=3108.9, bsz=96, num_updates=6360, lr=2.65031e-06, gnorm=2.224, clip=100, loss_scale=128, train_wall=28, gb_free=12.4, wall=20269
2023-04-19 06:04:49 - progress_bar.py[line:272] - INFO: epoch 012:     23 / 578 loss=2.254, loss_v1=0, loss_v2=0, nll_loss=1.04, ntokens=3134.5, nsentences=96, sample_size=3134.5, sample_size_v1=0, sample_size_v2=0, ppl=2.06, wps=1098, ups=0.35, wpb=3134.5, bsz=96, num_updates=6370, lr=2.60429e-06, gnorm=2.117, clip=100, loss_scale=128, train_wall=29, gb_free=11.8, wall=20298
2023-04-19 06:05:18 - progress_bar.py[line:272] - INFO: epoch 012:     33 / 578 loss=2.251, loss_v1=0, loss_v2=0, nll_loss=1.038, ntokens=3094.4, nsentences=96, sample_size=3094.4, sample_size_v1=0, sample_size_v2=0, ppl=2.05, wps=1077.3, ups=0.35, wpb=3094.4, bsz=96, num_updates=6380, lr=2.55828e-06, gnorm=2.177, clip=100, loss_scale=128, train_wall=29, gb_free=11.9, wall=20327
2023-04-19 06:05:47 - progress_bar.py[line:272] - INFO: epoch 012:     43 / 578 loss=2.158, loss_v1=0, loss_v2=0, nll_loss=0.934, ntokens=3307.4, nsentences=96, sample_size=3307.4, sample_size_v1=0, sample_size_v2=0, ppl=1.91, wps=1150.5, ups=0.35, wpb=3307.4, bsz=96, num_updates=6390, lr=2.51227e-06, gnorm=2.017, clip=100, loss_scale=128, train_wall=29, gb_free=11.8, wall=20355
2023-04-19 06:06:16 - progress_bar.py[line:272] - INFO: epoch 012:     53 / 578 loss=2.201, loss_v1=0, loss_v2=0, nll_loss=0.982, ntokens=3544.8, nsentences=96, sample_size=3544.8, sample_size_v1=0, sample_size_v2=0, ppl=1.97, wps=1214.4, ups=0.34, wpb=3544.8, bsz=96, num_updates=6400, lr=2.46626e-06, gnorm=2.033, clip=100, loss_scale=128, train_wall=29, gb_free=11.5, wall=20385
2023-04-19 06:06:45 - progress_bar.py[line:272] - INFO: epoch 012:     63 / 578 loss=2.24, loss_v1=0, loss_v2=0, nll_loss=1.026, ntokens=3194.3, nsentences=96, sample_size=3194.3, sample_size_v1=0, sample_size_v2=0, ppl=2.04, wps=1115.8, ups=0.35, wpb=3194.3, bsz=96, num_updates=6410, lr=2.42025e-06, gnorm=2.203, clip=100, loss_scale=128, train_wall=29, gb_free=12.5, wall=20413
2023-04-19 06:07:13 - progress_bar.py[line:272] - INFO: epoch 012:     73 / 578 loss=2.316, loss_v1=0, loss_v2=0, nll_loss=1.111, ntokens=3052.4, nsentences=96, sample_size=3052.4, sample_size_v1=0, sample_size_v2=0, ppl=2.16, wps=1070.6, ups=0.35, wpb=3052.4, bsz=96, num_updates=6420, lr=2.37423e-06, gnorm=2.46, clip=100, loss_scale=128, train_wall=28, gb_free=12.4, wall=20442
2023-04-19 06:07:42 - progress_bar.py[line:272] - INFO: epoch 012:     83 / 578 loss=2.316, loss_v1=0, loss_v2=0, nll_loss=1.11, ntokens=3246.2, nsentences=96, sample_size=3246.2, sample_size_v1=0, sample_size_v2=0, ppl=2.16, wps=1125.4, ups=0.35, wpb=3246.2, bsz=96, num_updates=6430, lr=2.32822e-06, gnorm=2.248, clip=100, loss_scale=128, train_wall=29, gb_free=11.9, wall=20471
2023-04-19 06:08:11 - progress_bar.py[line:272] - INFO: epoch 012:     93 / 578 loss=2.277, loss_v1=0, loss_v2=0, nll_loss=1.066, ntokens=3350.2, nsentences=96, sample_size=3350.2, sample_size_v1=0, sample_size_v2=0, ppl=2.09, wps=1160.8, ups=0.35, wpb=3350.2, bsz=96, num_updates=6440, lr=2.28221e-06, gnorm=2.178, clip=100, loss_scale=128, train_wall=29, gb_free=11.5, wall=20499
2023-04-19 06:08:40 - progress_bar.py[line:272] - INFO: epoch 012:    103 / 578 loss=2.277, loss_v1=0, loss_v2=0, nll_loss=1.066, ntokens=3307.6, nsentences=96, sample_size=3307.6, sample_size_v1=0, sample_size_v2=0, ppl=2.09, wps=1135.4, ups=0.34, wpb=3307.6, bsz=96, num_updates=6450, lr=2.2362e-06, gnorm=2.214, clip=100, loss_scale=128, train_wall=29, gb_free=11.6, wall=20529
2023-04-19 06:09:09 - progress_bar.py[line:272] - INFO: epoch 012:    113 / 578 loss=2.286, loss_v1=0, loss_v2=0, nll_loss=1.076, ntokens=3181.7, nsentences=96, sample_size=3181.7, sample_size_v1=0, sample_size_v2=0, ppl=2.11, wps=1109.4, ups=0.35, wpb=3181.7, bsz=96, num_updates=6460, lr=2.19018e-06, gnorm=2.327, clip=100, loss_scale=128, train_wall=29, gb_free=12.3, wall=20557
2023-04-19 06:09:37 - progress_bar.py[line:272] - INFO: epoch 012:    123 / 578 loss=2.271, loss_v1=0, loss_v2=0, nll_loss=1.06, ntokens=3206.2, nsentences=96, sample_size=3206.2, sample_size_v1=0, sample_size_v2=0, ppl=2.08, wps=1116.2, ups=0.35, wpb=3206.2, bsz=96, num_updates=6470, lr=2.14417e-06, gnorm=2.384, clip=100, loss_scale=128, train_wall=29, gb_free=12.1, wall=20586
2023-04-19 06:10:06 - progress_bar.py[line:272] - INFO: epoch 012:    133 / 578 loss=2.287, loss_v1=0, loss_v2=0, nll_loss=1.078, ntokens=3255.8, nsentences=96, sample_size=3255.8, sample_size_v1=0, sample_size_v2=0, ppl=2.11, wps=1131, ups=0.35, wpb=3255.8, bsz=96, num_updates=6480, lr=2.09816e-06, gnorm=2.353, clip=100, loss_scale=128, train_wall=29, gb_free=12.4, wall=20615
2023-04-19 06:10:35 - progress_bar.py[line:272] - INFO: epoch 012:    143 / 578 loss=2.331, loss_v1=0, loss_v2=0, nll_loss=1.127, ntokens=3098.6, nsentences=96, sample_size=3098.6, sample_size_v1=0, sample_size_v2=0, ppl=2.18, wps=1084.9, ups=0.35, wpb=3098.6, bsz=96, num_updates=6490, lr=2.05215e-06, gnorm=2.252, clip=100, loss_scale=128, train_wall=29, gb_free=12.2, wall=20643
2023-04-19 06:11:03 - progress_bar.py[line:272] - INFO: epoch 012:    153 / 578 loss=2.339, loss_v1=0, loss_v2=0, nll_loss=1.136, ntokens=3263.9, nsentences=96, sample_size=3263.9, sample_size_v1=0, sample_size_v2=0, ppl=2.2, wps=1145.5, ups=0.35, wpb=3263.9, bsz=96, num_updates=6500, lr=2.00613e-06, gnorm=2.225, clip=100, loss_scale=128, train_wall=28, gb_free=12, wall=20672
2023-04-19 06:11:32 - progress_bar.py[line:272] - INFO: epoch 012:    163 / 578 loss=2.342, loss_v1=0, loss_v2=0, nll_loss=1.139, ntokens=3260.5, nsentences=96, sample_size=3260.5, sample_size_v1=0, sample_size_v2=0, ppl=2.2, wps=1145.4, ups=0.35, wpb=3260.5, bsz=96, num_updates=6510, lr=1.96012e-06, gnorm=2.214, clip=100, loss_scale=128, train_wall=28, gb_free=11.8, wall=20700
2023-04-19 06:12:00 - progress_bar.py[line:272] - INFO: epoch 012:    173 / 578 loss=2.347, loss_v1=0, loss_v2=0, nll_loss=1.143, ntokens=3152.8, nsentences=96, sample_size=3152.8, sample_size_v1=0, sample_size_v2=0, ppl=2.21, wps=1107.4, ups=0.35, wpb=3152.8, bsz=96, num_updates=6520, lr=1.91411e-06, gnorm=2.305, clip=100, loss_scale=128, train_wall=28, gb_free=12.1, wall=20729
2023-04-19 06:12:29 - progress_bar.py[line:272] - INFO: epoch 012:    183 / 578 loss=2.337, loss_v1=0, loss_v2=0, nll_loss=1.133, ntokens=3234, nsentences=96, sample_size=3234, sample_size_v1=0, sample_size_v2=0, ppl=2.19, wps=1132.2, ups=0.35, wpb=3234, bsz=96, num_updates=6530, lr=1.8681e-06, gnorm=2.242, clip=100, loss_scale=128, train_wall=29, gb_free=10.9, wall=20757
2023-04-19 06:12:57 - progress_bar.py[line:272] - INFO: epoch 012:    193 / 578 loss=2.328, loss_v1=0, loss_v2=0, nll_loss=1.124, ntokens=3253.6, nsentences=96, sample_size=3253.6, sample_size_v1=0, sample_size_v2=0, ppl=2.18, wps=1142.1, ups=0.35, wpb=3253.6, bsz=96, num_updates=6540, lr=1.82209e-06, gnorm=2.235, clip=100, loss_scale=128, train_wall=28, gb_free=12.6, wall=20786
2023-04-19 06:13:26 - progress_bar.py[line:272] - INFO: epoch 012:    203 / 578 loss=2.325, loss_v1=0, loss_v2=0, nll_loss=1.12, ntokens=3200, nsentences=96, sample_size=3200, sample_size_v1=0, sample_size_v2=0, ppl=2.17, wps=1126.9, ups=0.35, wpb=3200, bsz=96, num_updates=6550, lr=1.77607e-06, gnorm=2.322, clip=100, loss_scale=128, train_wall=28, gb_free=12.1, wall=20814
2023-04-19 06:13:54 - progress_bar.py[line:272] - INFO: epoch 012:    213 / 578 loss=2.322, loss_v1=0, loss_v2=0, nll_loss=1.118, ntokens=3021.3, nsentences=96, sample_size=3021.3, sample_size_v1=0, sample_size_v2=0, ppl=2.17, wps=1068.1, ups=0.35, wpb=3021.3, bsz=96, num_updates=6560, lr=1.73006e-06, gnorm=2.474, clip=100, loss_scale=128, train_wall=28, gb_free=12.5, wall=20843
2023-04-19 06:14:22 - progress_bar.py[line:272] - INFO: epoch 012:    223 / 578 loss=2.339, loss_v1=0, loss_v2=0, nll_loss=1.136, ntokens=3164.6, nsentences=96, sample_size=3164.6, sample_size_v1=0, sample_size_v2=0, ppl=2.2, wps=1115, ups=0.35, wpb=3164.6, bsz=96, num_updates=6570, lr=1.68405e-06, gnorm=2.147, clip=100, loss_scale=128, train_wall=28, gb_free=12.4, wall=20871
2023-04-19 06:14:51 - progress_bar.py[line:272] - INFO: epoch 012:    233 / 578 loss=2.32, loss_v1=0, loss_v2=0, nll_loss=1.115, ntokens=2933.4, nsentences=96, sample_size=2933.4, sample_size_v1=0, sample_size_v2=0, ppl=2.17, wps=1032.9, ups=0.35, wpb=2933.4, bsz=96, num_updates=6580, lr=1.63804e-06, gnorm=2.517, clip=100, loss_scale=128, train_wall=28, gb_free=12.5, wall=20899
2023-04-19 06:15:19 - progress_bar.py[line:272] - INFO: epoch 012:    243 / 578 loss=2.35, loss_v1=0, loss_v2=0, nll_loss=1.149, ntokens=3008.4, nsentences=96, sample_size=3008.4, sample_size_v1=0, sample_size_v2=0, ppl=2.22, wps=1060.3, ups=0.35, wpb=3008.4, bsz=96, num_updates=6590, lr=1.59202e-06, gnorm=2.522, clip=100, loss_scale=128, train_wall=28, gb_free=12, wall=20928
2023-04-19 06:15:48 - progress_bar.py[line:272] - INFO: epoch 012:    253 / 578 loss=2.322, loss_v1=0, loss_v2=0, nll_loss=1.117, ntokens=3160.2, nsentences=96, sample_size=3160.2, sample_size_v1=0, sample_size_v2=0, ppl=2.17, wps=1110.2, ups=0.35, wpb=3160.2, bsz=96, num_updates=6600, lr=1.54601e-06, gnorm=2.393, clip=100, loss_scale=128, train_wall=28, gb_free=12, wall=20956
2023-04-19 06:16:16 - progress_bar.py[line:272] - INFO: epoch 012:    263 / 578 loss=2.328, loss_v1=0, loss_v2=0, nll_loss=1.123, ntokens=3048.9, nsentences=96, sample_size=3048.9, sample_size_v1=0, sample_size_v2=0, ppl=2.18, wps=1073.4, ups=0.35, wpb=3048.9, bsz=96, num_updates=6610, lr=1.5e-06, gnorm=2.372, clip=100, loss_scale=128, train_wall=28, gb_free=12.5, wall=20985
2023-04-19 06:16:44 - progress_bar.py[line:272] - INFO: epoch 012:    273 / 578 loss=2.331, loss_v1=0, loss_v2=0, nll_loss=1.126, ntokens=3206.1, nsentences=96, sample_size=3206.1, sample_size_v1=0, sample_size_v2=0, ppl=2.18, wps=1130.3, ups=0.35, wpb=3206.1, bsz=96, num_updates=6620, lr=1.45399e-06, gnorm=2.344, clip=100, loss_scale=128, train_wall=28, gb_free=12.2, wall=21013
2023-04-19 06:16:50 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 128.0
2023-04-19 06:17:16 - progress_bar.py[line:272] - INFO: epoch 012:    284 / 578 loss=2.31, loss_v1=0, loss_v2=0, nll_loss=1.103, ntokens=3115.7, nsentences=96, sample_size=3115.7, sample_size_v1=0, sample_size_v2=0, ppl=2.15, wps=991.8, ups=0.32, wpb=3115.7, bsz=96, num_updates=6630, lr=1.40798e-06, gnorm=2.383, clip=100, loss_scale=128, train_wall=31, gb_free=12, wall=21044
2023-04-19 06:17:44 - progress_bar.py[line:272] - INFO: epoch 012:    294 / 578 loss=2.343, loss_v1=0, loss_v2=0, nll_loss=1.141, ntokens=3166.8, nsentences=96, sample_size=3166.8, sample_size_v1=0, sample_size_v2=0, ppl=2.21, wps=1108.5, ups=0.35, wpb=3166.8, bsz=96, num_updates=6640, lr=1.36196e-06, gnorm=2.295, clip=100, loss_scale=128, train_wall=29, gb_free=12.4, wall=21073
2023-04-19 06:18:13 - progress_bar.py[line:272] - INFO: epoch 012:    304 / 578 loss=2.336, loss_v1=0, loss_v2=0, nll_loss=1.132, ntokens=3036.7, nsentences=96, sample_size=3036.7, sample_size_v1=0, sample_size_v2=0, ppl=2.19, wps=1061.8, ups=0.35, wpb=3036.7, bsz=96, num_updates=6650, lr=1.31595e-06, gnorm=2.354, clip=100, loss_scale=128, train_wall=29, gb_free=12.4, wall=21102
2023-04-19 06:18:41 - progress_bar.py[line:272] - INFO: epoch 012:    314 / 578 loss=2.33, loss_v1=0, loss_v2=0, nll_loss=1.126, ntokens=3246.9, nsentences=96, sample_size=3246.9, sample_size_v1=0, sample_size_v2=0, ppl=2.18, wps=1139.8, ups=0.35, wpb=3246.9, bsz=96, num_updates=6660, lr=1.26994e-06, gnorm=2.346, clip=100, loss_scale=128, train_wall=28, gb_free=12.6, wall=21130
2023-04-19 06:19:10 - progress_bar.py[line:272] - INFO: epoch 012:    324 / 578 loss=2.332, loss_v1=0, loss_v2=0, nll_loss=1.128, ntokens=3239.5, nsentences=96, sample_size=3239.5, sample_size_v1=0, sample_size_v2=0, ppl=2.19, wps=1132.2, ups=0.35, wpb=3239.5, bsz=96, num_updates=6670, lr=1.22393e-06, gnorm=2.402, clip=100, loss_scale=128, train_wall=29, gb_free=12.2, wall=21159
2023-04-19 06:19:39 - progress_bar.py[line:272] - INFO: epoch 012:    334 / 578 loss=2.311, loss_v1=0, loss_v2=0, nll_loss=1.104, ntokens=3063.1, nsentences=96, sample_size=3063.1, sample_size_v1=0, sample_size_v2=0, ppl=2.15, wps=1074.7, ups=0.35, wpb=3063.1, bsz=96, num_updates=6680, lr=1.17791e-06, gnorm=2.365, clip=100, loss_scale=128, train_wall=28, gb_free=12.4, wall=21187
2023-04-19 06:20:07 - progress_bar.py[line:272] - INFO: epoch 012:    344 / 578 loss=2.346, loss_v1=0, loss_v2=0, nll_loss=1.144, ntokens=3279.4, nsentences=96, sample_size=3279.4, sample_size_v1=0, sample_size_v2=0, ppl=2.21, wps=1151.9, ups=0.35, wpb=3279.4, bsz=96, num_updates=6690, lr=1.1319e-06, gnorm=2.426, clip=100, loss_scale=128, train_wall=28, gb_free=12.2, wall=21216
2023-04-19 06:20:35 - progress_bar.py[line:272] - INFO: epoch 012:    354 / 578 loss=2.322, loss_v1=0, loss_v2=0, nll_loss=1.116, ntokens=3043.8, nsentences=96, sample_size=3043.8, sample_size_v1=0, sample_size_v2=0, ppl=2.17, wps=1073.6, ups=0.35, wpb=3043.8, bsz=96, num_updates=6700, lr=1.08589e-06, gnorm=2.393, clip=100, loss_scale=128, train_wall=28, gb_free=12.3, wall=21244
2023-04-19 06:21:04 - progress_bar.py[line:272] - INFO: epoch 012:    364 / 578 loss=2.338, loss_v1=0, loss_v2=0, nll_loss=1.134, ntokens=3314.1, nsentences=96, sample_size=3314.1, sample_size_v1=0, sample_size_v2=0, ppl=2.2, wps=1163, ups=0.35, wpb=3314.1, bsz=96, num_updates=6710, lr=1.03988e-06, gnorm=2.144, clip=100, loss_scale=128, train_wall=28, gb_free=12.2, wall=21272
2023-04-19 06:21:33 - progress_bar.py[line:272] - INFO: epoch 012:    374 / 578 loss=2.34, loss_v1=0, loss_v2=0, nll_loss=1.136, ntokens=3377.5, nsentences=96, sample_size=3377.5, sample_size_v1=0, sample_size_v2=0, ppl=2.2, wps=1172.3, ups=0.35, wpb=3377.5, bsz=96, num_updates=6720, lr=9.93865e-07, gnorm=2.151, clip=100, loss_scale=128, train_wall=29, gb_free=12.2, wall=21301
2023-04-19 06:22:01 - progress_bar.py[line:272] - INFO: epoch 012:    384 / 578 loss=2.339, loss_v1=0, loss_v2=0, nll_loss=1.135, ntokens=3284.1, nsentences=96, sample_size=3284.1, sample_size_v1=0, sample_size_v2=0, ppl=2.2, wps=1148.6, ups=0.35, wpb=3284.1, bsz=96, num_updates=6730, lr=9.47853e-07, gnorm=2.345, clip=100, loss_scale=128, train_wall=29, gb_free=12.1, wall=21330
2023-04-19 06:22:30 - progress_bar.py[line:272] - INFO: epoch 012:    394 / 578 loss=2.343, loss_v1=0, loss_v2=0, nll_loss=1.14, ntokens=3094.4, nsentences=96, sample_size=3094.4, sample_size_v1=0, sample_size_v2=0, ppl=2.2, wps=1085.3, ups=0.35, wpb=3094.4, bsz=96, num_updates=6740, lr=9.0184e-07, gnorm=2.376, clip=100, loss_scale=128, train_wall=28, gb_free=11.8, wall=21358
2023-04-19 06:22:58 - progress_bar.py[line:272] - INFO: epoch 012:    404 / 578 loss=2.303, loss_v1=0, loss_v2=0, nll_loss=1.095, ntokens=3155.2, nsentences=96, sample_size=3155.2, sample_size_v1=0, sample_size_v2=0, ppl=2.14, wps=1099, ups=0.35, wpb=3155.2, bsz=96, num_updates=6750, lr=8.55828e-07, gnorm=2.381, clip=100, loss_scale=128, train_wall=29, gb_free=12.6, wall=21387
2023-04-19 06:23:27 - progress_bar.py[line:272] - INFO: epoch 012:    414 / 578 loss=2.348, loss_v1=0, loss_v2=0, nll_loss=1.146, ntokens=2978.3, nsentences=96, sample_size=2978.3, sample_size_v1=0, sample_size_v2=0, ppl=2.21, wps=1042, ups=0.35, wpb=2978.3, bsz=96, num_updates=6760, lr=8.09816e-07, gnorm=2.411, clip=100, loss_scale=128, train_wall=29, gb_free=12.6, wall=21416
2023-04-19 06:23:56 - progress_bar.py[line:272] - INFO: epoch 012:    424 / 578 loss=2.316, loss_v1=0, loss_v2=0, nll_loss=1.11, ntokens=3051.2, nsentences=96, sample_size=3051.2, sample_size_v1=0, sample_size_v2=0, ppl=2.16, wps=1066.6, ups=0.35, wpb=3051.2, bsz=96, num_updates=6770, lr=7.63804e-07, gnorm=2.203, clip=100, loss_scale=128, train_wall=29, gb_free=12.3, wall=21444
2023-04-19 06:24:24 - progress_bar.py[line:272] - INFO: epoch 012:    434 / 578 loss=2.327, loss_v1=0, loss_v2=0, nll_loss=1.123, ntokens=3065.7, nsentences=96, sample_size=3065.7, sample_size_v1=0, sample_size_v2=0, ppl=2.18, wps=1081.7, ups=0.35, wpb=3065.7, bsz=96, num_updates=6780, lr=7.17791e-07, gnorm=2.262, clip=100, loss_scale=128, train_wall=28, gb_free=12.2, wall=21473
2023-04-19 06:24:52 - progress_bar.py[line:272] - INFO: epoch 012:    444 / 578 loss=2.352, loss_v1=0, loss_v2=0, nll_loss=1.15, ntokens=2879.7, nsentences=96, sample_size=2879.7, sample_size_v1=0, sample_size_v2=0, ppl=2.22, wps=1014.3, ups=0.35, wpb=2879.7, bsz=96, num_updates=6790, lr=6.71779e-07, gnorm=2.54, clip=100, loss_scale=128, train_wall=28, gb_free=12.2, wall=21501
2023-04-19 06:25:21 - progress_bar.py[line:272] - INFO: epoch 012:    454 / 578 loss=2.323, loss_v1=0, loss_v2=0, nll_loss=1.118, ntokens=3106, nsentences=96, sample_size=3106, sample_size_v1=0, sample_size_v2=0, ppl=2.17, wps=1090.3, ups=0.35, wpb=3106, bsz=96, num_updates=6800, lr=6.25767e-07, gnorm=2.335, clip=100, loss_scale=128, train_wall=28, gb_free=12, wall=21530
2023-04-19 06:25:49 - progress_bar.py[line:272] - INFO: epoch 012:    464 / 578 loss=2.335, loss_v1=0, loss_v2=0, nll_loss=1.132, ntokens=3094.5, nsentences=96, sample_size=3094.5, sample_size_v1=0, sample_size_v2=0, ppl=2.19, wps=1083.5, ups=0.35, wpb=3094.5, bsz=96, num_updates=6810, lr=5.79755e-07, gnorm=2.186, clip=100, loss_scale=128, train_wall=29, gb_free=12.5, wall=21558
2023-04-19 06:26:18 - progress_bar.py[line:272] - INFO: epoch 012:    474 / 578 loss=2.344, loss_v1=0, loss_v2=0, nll_loss=1.14, ntokens=2913.1, nsentences=95.6, sample_size=2913.1, sample_size_v1=0, sample_size_v2=0, ppl=2.2, wps=1028.7, ups=0.35, wpb=2913.1, bsz=95.6, num_updates=6820, lr=5.33742e-07, gnorm=2.677, clip=100, loss_scale=128, train_wall=28, gb_free=12.2, wall=21586
2023-04-19 06:26:46 - progress_bar.py[line:272] - INFO: epoch 012:    484 / 578 loss=2.314, loss_v1=0, loss_v2=0, nll_loss=1.107, ntokens=2952.3, nsentences=96, sample_size=2952.3, sample_size_v1=0, sample_size_v2=0, ppl=2.15, wps=1037.9, ups=0.35, wpb=2952.3, bsz=96, num_updates=6830, lr=4.8773e-07, gnorm=2.337, clip=100, loss_scale=128, train_wall=28, gb_free=12.1, wall=21615
2023-04-19 06:27:15 - progress_bar.py[line:272] - INFO: epoch 012:    494 / 578 loss=2.313, loss_v1=0, loss_v2=0, nll_loss=1.106, ntokens=3116.6, nsentences=96, sample_size=3116.6, sample_size_v1=0, sample_size_v2=0, ppl=2.15, wps=1096.1, ups=0.35, wpb=3116.6, bsz=96, num_updates=6840, lr=4.41718e-07, gnorm=2.342, clip=100, loss_scale=128, train_wall=28, gb_free=12.3, wall=21643
2023-04-19 06:27:44 - progress_bar.py[line:272] - INFO: epoch 012:    504 / 578 loss=2.302, loss_v1=0, loss_v2=0, nll_loss=1.094, ntokens=3157.1, nsentences=96, sample_size=3157.1, sample_size_v1=0, sample_size_v2=0, ppl=2.14, wps=1096.2, ups=0.35, wpb=3157.1, bsz=96, num_updates=6850, lr=3.95706e-07, gnorm=2.173, clip=100, loss_scale=128, train_wall=29, gb_free=12.2, wall=21672
2023-04-19 06:28:12 - progress_bar.py[line:272] - INFO: epoch 012:    514 / 578 loss=2.314, loss_v1=0, loss_v2=0, nll_loss=1.108, ntokens=3113.7, nsentences=96, sample_size=3113.7, sample_size_v1=0, sample_size_v2=0, ppl=2.16, wps=1085.1, ups=0.35, wpb=3113.7, bsz=96, num_updates=6860, lr=3.49693e-07, gnorm=2.422, clip=100, loss_scale=128, train_wall=29, gb_free=12.3, wall=21701
2023-04-19 06:28:41 - progress_bar.py[line:272] - INFO: epoch 012:    524 / 578 loss=2.315, loss_v1=0, loss_v2=0, nll_loss=1.109, ntokens=3300.8, nsentences=96, sample_size=3300.8, sample_size_v1=0, sample_size_v2=0, ppl=2.16, wps=1155.2, ups=0.35, wpb=3300.8, bsz=96, num_updates=6870, lr=3.03681e-07, gnorm=2.159, clip=100, loss_scale=128, train_wall=29, gb_free=12.2, wall=21729
2023-04-19 06:29:09 - progress_bar.py[line:272] - INFO: epoch 012:    534 / 578 loss=2.327, loss_v1=0, loss_v2=0, nll_loss=1.123, ntokens=3027.1, nsentences=96, sample_size=3027.1, sample_size_v1=0, sample_size_v2=0, ppl=2.18, wps=1063.9, ups=0.35, wpb=3027.1, bsz=96, num_updates=6880, lr=2.57669e-07, gnorm=2.361, clip=100, loss_scale=128, train_wall=28, gb_free=12.1, wall=21758
2023-04-19 06:29:38 - progress_bar.py[line:272] - INFO: epoch 012:    544 / 578 loss=2.31, loss_v1=0, loss_v2=0, nll_loss=1.104, ntokens=3060.2, nsentences=96, sample_size=3060.2, sample_size_v1=0, sample_size_v2=0, ppl=2.15, wps=1073.1, ups=0.35, wpb=3060.2, bsz=96, num_updates=6890, lr=2.11656e-07, gnorm=2.36, clip=100, loss_scale=128, train_wall=28, gb_free=12.1, wall=21786
2023-04-19 06:30:07 - progress_bar.py[line:272] - INFO: epoch 012:    554 / 578 loss=2.306, loss_v1=0, loss_v2=0, nll_loss=1.099, ntokens=3269.4, nsentences=96, sample_size=3269.4, sample_size_v1=0, sample_size_v2=0, ppl=2.14, wps=1132.4, ups=0.35, wpb=3269.4, bsz=96, num_updates=6900, lr=1.65644e-07, gnorm=2.332, clip=100, loss_scale=128, train_wall=29, gb_free=12.5, wall=21815
2023-04-19 06:30:35 - progress_bar.py[line:272] - INFO: epoch 012:    564 / 578 loss=2.317, loss_v1=0, loss_v2=0, nll_loss=1.112, ntokens=3220.8, nsentences=96, sample_size=3220.8, sample_size_v1=0, sample_size_v2=0, ppl=2.16, wps=1124.1, ups=0.35, wpb=3220.8, bsz=96, num_updates=6910, lr=1.19632e-07, gnorm=2.262, clip=100, loss_scale=128, train_wall=29, gb_free=12.2, wall=21844
2023-04-19 06:31:04 - progress_bar.py[line:272] - INFO: epoch 012:    574 / 578 loss=2.316, loss_v1=0, loss_v2=0, nll_loss=1.11, ntokens=3160.1, nsentences=96, sample_size=3160.1, sample_size_v1=0, sample_size_v2=0, ppl=2.16, wps=1103.6, ups=0.35, wpb=3160.1, bsz=96, num_updates=6920, lr=7.36196e-08, gnorm=2.256, clip=100, loss_scale=128, train_wall=29, gb_free=12.2, wall=21873
2023-04-19 06:31:13 - checkpoint_utils.py[line:64] - INFO: Preparing to save checkpoint for epoch 12 @ 6924 updates
2023-04-19 06:31:13 - trainer.py[line:431] - INFO: Saving checkpoint to ../../checkpoints/OFA/sgcls_checkpoints/_12_3e-5_512/checkpoint12.pt
local datafile ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 1 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 1 finished initializing row_count and line_idx-to-offset mapping
file ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 1 row count 27700 total row count 55400
slice_id 1 seek offset 27700
2023-04-19 06:31:31 - trainer.py[line:441] - INFO: Finished saving checkpoint to ../../checkpoints/OFA/sgcls_checkpoints/_12_3e-5_512/checkpoint12.pt
2023-04-19 06:31:35 - checkpoint_utils.py[line:133] - INFO: Saved checkpoint ../../checkpoints/OFA/sgcls_checkpoints/_12_3e-5_512/checkpoint12.pt (epoch 12 @ 6924 updates, score None) (writing took 22.23260591737926 seconds)
2023-04-19 06:31:35 - train.py[line:332] - INFO: end of epoch 12 (average epoch stats below)
2023-04-19 06:31:35 - progress_bar.py[line:282] - INFO: epoch 012 | loss 2.312 | loss_v1 0 | loss_v2 0 | nll_loss 1.106 | ntokens 3151.18 | nsentences 95.847 | sample_size 3151.18 | sample_size_v1 0 | sample_size_v2 0 | ppl 2.15 | wps 1086.4 | ups 0.34 | wpb 3151.2 | bsz 95.8 | num_updates 6924 | lr 5.52147e-08 | gnorm 2.31 | clip 100 | loss_scale 128 | train_wall 1647 | gb_free 13.1 | wall 21904
2023-04-19 06:31:35 - trainer.py[line:639] - INFO: loading train data for epoch 13
local datafile ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 0 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 0 finished initializing row_count and line_idx-to-offset mapping
file ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 0 row count 27700 total row count 55400
slice_id 0 seek offset 0
2023-04-19 06:31:37 - train.py[line:214] - INFO: done training in 21903.6 seconds
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                  train/bsz 
wandb:                 train/clip 
wandb:              train/gb_free 
wandb:                train/gnorm 
wandb:                 train/loss 
wandb:           train/loss_scale 
wandb:              train/loss_v1 
wandb:              train/loss_v2 
wandb:                   train/lr 
wandb:             train/nll_loss 
wandb:           train/nsentences 
wandb:              train/ntokens 
wandb:                  train/ppl 
wandb:          train/sample_size 
wandb:       train/sample_size_v1 
wandb:       train/sample_size_v2 
wandb:           train/train_wall 
wandb:                  train/ups 
wandb:                 train/wall 
wandb:                  train/wpb 
wandb:                  train/wps 
wandb:            train_inner/bsz 
wandb:           train_inner/clip 
wandb:        train_inner/gb_free 
wandb:          train_inner/gnorm 
wandb:           train_inner/loss 
wandb:     train_inner/loss_scale 
wandb:        train_inner/loss_v1 
wandb:        train_inner/loss_v2 
wandb:             train_inner/lr 
wandb:       train_inner/nll_loss 
wandb:     train_inner/nsentences 
wandb:        train_inner/ntokens 
wandb:            train_inner/ppl 
wandb:    train_inner/sample_size 
wandb: train_inner/sample_size_v1 
wandb: train_inner/sample_size_v2 
wandb:     train_inner/train_wall 
wandb:            train_inner/ups 
wandb:           train_inner/wall 
wandb:            train_inner/wpb 
wandb:            train_inner/wps 
wandb:                  valid/bsz 
wandb:                 valid/loss 
wandb:              valid/loss_v1 
wandb:              valid/loss_v2 
wandb:             valid/nll_loss 
wandb:           valid/nsentences 
wandb:              valid/ntokens 
wandb:                  valid/ppl 
wandb:          valid/sample_size 
wandb:       valid/sample_size_v1 
wandb:       valid/sample_size_v2 
wandb:                  valid/wpb 
wandb:                  valid/wps 
wandb: 
wandb: Run summary:
wandb:                  train/bsz 95.8
wandb:                 train/clip 100.0
wandb:              train/gb_free 13.1
wandb:                train/gnorm 2.31
wandb:                 train/loss 2.312
wandb:           train/loss_scale 128.0
wandb:              train/loss_v1 0.0
wandb:              train/loss_v2 0.0
wandb:                   train/lr 0.0
wandb:             train/nll_loss 1.106
wandb:           train/nsentences 95.847
wandb:              train/ntokens 3151.177
wandb:                  train/ppl 2.15
wandb:          train/sample_size 3151.177
wandb:       train/sample_size_v1 0.0
wandb:       train/sample_size_v2 0.0
wandb:           train/train_wall 1647.0
wandb:                  train/ups 0.34
wandb:                 train/wall 21904.0
wandb:                  train/wpb 3151.2
wandb:                  train/wps 1086.4
wandb:            train_inner/bsz 96.0
wandb:           train_inner/clip 100.0
wandb:        train_inner/gb_free 12.2
wandb:          train_inner/gnorm 2.256
wandb:           train_inner/loss 2.316
wandb:     train_inner/loss_scale 128.0
wandb:        train_inner/loss_v1 0.0
wandb:        train_inner/loss_v2 0.0
wandb:             train_inner/lr 0.0
wandb:       train_inner/nll_loss 1.11
wandb:     train_inner/nsentences 96.0
wandb:        train_inner/ntokens 3160.1
wandb:            train_inner/ppl 2.16
wandb:    train_inner/sample_size 3160.1
wandb: train_inner/sample_size_v1 0.0
wandb: train_inner/sample_size_v2 0.0
wandb:     train_inner/train_wall 29.0
wandb:            train_inner/ups 0.35
wandb:           train_inner/wall 21873.0
wandb:            train_inner/wpb 3160.1
wandb:            train_inner/wps 1103.6
wandb:                  valid/bsz 12.0
wandb:                 valid/loss 2.31
wandb:              valid/loss_v1 0.0
wandb:              valid/loss_v2 0.0
wandb:             valid/nll_loss 1.073
wandb:           valid/nsentences 11.998
wandb:              valid/ntokens 430.208
wandb:                  valid/ppl 2.1
wandb:          valid/sample_size 430.208
wandb:       valid/sample_size_v1 0.0
wandb:       valid/sample_size_v2 0.0
wandb:                  valid/wpb 430.2
wandb:                  valid/wps 413.9
wandb: 
wandb:  View run _12_3e-5_512 at: https://wandb.ai/jackcai1206/OFA-VG/runs/d5xxftpb
wandb: Synced 6 W&B file(s), 0 media file(s), 2 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230419_002639-d5xxftpb/logs

/data/hulab/zcai75/anaconda3/envs/vilt/lib/python3.8/site-packages/torch/distributed/launch.py:178: FutureWarning: The module torch.distributed.launch is deprecated
and will be removed in future. Use torchrun.
Note that --use_env is set by default in torchrun.
If your script expects `--local_rank` argument to be set, please
change it to read from `os.environ['LOCAL_RANK']` instead. See 
https://pytorch.org/docs/stable/distributed.html#launch-utility for 
further instructions

  warnings.warn(
WARNING:torch.distributed.run:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
2023-06-27 16:18:33 - utils.py[line:255] - INFO: distributed init (rank 1): env://
2023-06-27 16:18:33 - utils.py[line:261] - INFO: Start init
2023-06-27 16:18:33 - distributed_c10d.py[line:228] - INFO: Added key: store_based_barrier_key:1 to store for rank: 1
2023-06-27 16:18:33 - utils.py[line:255] - INFO: distributed init (rank 0): env://
2023-06-27 16:18:33 - utils.py[line:261] - INFO: Start init
2023-06-27 16:18:33 - distributed_c10d.py[line:228] - INFO: Added key: store_based_barrier_key:1 to store for rank: 0
2023-06-27 16:18:33 - distributed_c10d.py[line:262] - INFO: Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 2 nodes.
2023-06-27 16:18:33 - utils.py[line:271] - INFO: initialized host AMD4RTX3090GPU14 as rank 0
single-machine distributed training is initialized.
2023-06-27 16:18:33 - distributed_c10d.py[line:262] - INFO: Rank 1: Completed store-based barrier for key:store_based_barrier_key:1 with 2 nodes.
2023-06-27 16:18:33 - utils.py[line:271] - INFO: initialized host AMD4RTX3090GPU14 as rank 1
single-machine distributed training is initialized.
2023-06-27 16:18:34 - train.py[line:77] - INFO: {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 10, 'log_format': 'simple', 'log_file': None, 'tensorboard_logdir': './tensorboard/_16_3e-5_512', 'wandb_project': 'OFA-VG', 'azureml_logging': False, 'seed': 1, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': True, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': 512, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': '../../ofa_module', 'empty_cache_freq': 0, 'all_gather_list_size': 2097152, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 2, 'distributed_num_procs': 2, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': 'env://', 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': True, 'ddp_backend': 'pytorch_ddp', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': True, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_algorithm': 'LocalSGD', 'localsgd_frequency': 3, 'nprocs_per_node': 2, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': True, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False}, 'dataset': {'_name': None, 'num_workers': 0, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': None, 'batch_size': 7, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 30, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': 7, 'disable_validation': False, 'max_tokens_valid': None, 'batch_size_valid': 7, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0}, 'optimization': {'_name': None, 'max_epoch': 16, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 1.0, 'sentence_avg': False, 'update_freq': [4], 'lr': [3e-05], 'stop_min_lr': -1.0, 'use_bmuf': False}, 'checkpoint': {'_name': None, 'save_dir': '../../checkpoints/OFA/sgcls_checkpoints/_16_3e-5_512_base', 'restore_file': '../../checkpoints/ofa_base.pt', 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 4, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': 1, 'no_save': False, 'no_epoch_checkpoints': False, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': True, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1, 'use_ema_weights_to_init_param': False, 'use_latest_weights_to_init_ema': False}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 2}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': Namespace(_name='ofa_base', activation_fn='gelu', adam_betas='(0.9,0.999)', adam_eps=1e-08, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, add_type_embedding=True, all_gather_list_size=2097152, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, arch='ofa_base', attention_dropout=0.0, attn_scale_factor=2, azureml_logging=False, batch_size=7, batch_size_valid=7, best_checkpoint_metric='loss', bf16=False, bitfit=False, bpe=None, bpe_dir='../../utils/BPE', broadcast_buffers=False, bucket_cap_mb=25, checkpoint_shard_count=1, checkpoint_suffix='', clip_norm=1.0, code_dict_size=8192, code_image_size=128, code_layernorm_embedding=True, combine_valid_subsets=None, constraint_range=None, cpu=False, cpu_offload=False, criterion='adjust_label_smoothed_cross_entropy', cross_self_attention=False, curriculum=0, data='../../dataset/OFA_data/sgcls/vg_train_full.tsv,../../dataset/OFA_data/sgcls/vg_val_full.tsv', data_buffer_size=10, dataset_impl=None, ddp_backend='pytorch_ddp', ddp_comm_hook='none', decoder_attention_heads=12, decoder_drop_path_rate=0.1, decoder_embed_dim=768, decoder_embed_path=None, decoder_ffn_embed_dim=3072, decoder_input_dim=768, decoder_layerdrop=0, decoder_layers=6, decoder_layers_to_keep=None, decoder_learned_pos=True, decoder_normalize_before=True, decoder_output_dim=768, device_id=0, disable_entangle=True, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_num_procs=2, distributed_port=-1, distributed_rank=0, distributed_world_size=2, drop_worst_after=0, drop_worst_ratio=0.0, dropout=0.1, ema_decay=0.9999, ema_fp32=False, ema_seed_model=None, ema_start_update=0, ema_update_freq=1, empty_cache_freq=0, encoder_attention_heads=12, encoder_drop_path_rate=0.1, encoder_embed_dim=768, encoder_embed_path=None, encoder_ffn_embed_dim=3072, encoder_layerdrop=0, encoder_layers=6, encoder_layers_to_keep=None, encoder_learned_pos=True, encoder_normalize_before=True, end_learning_rate=0.0, entangle_position_embedding=False, eos=2, eval_args='{"beam":5,"max_len_a":0,"max_len_b":200}', eval_print_samples=False, fast_stat_sync=False, find_unused_parameters=True, finetune_from_model=None, fix_batches_to_gpus=False, fixed_validation_seed=7, force_anneal=None, fp16=True, fp16_adam_stats=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=512, fp32_reduce_scatter=False, freeze_decoder_embedding=False, freeze_encoder_embedding=False, gen_subset='test', gradient_as_bucket_view=False, heartbeat_timeout=-1, ignore_eos=False, ignore_prefix_size=0, ignore_unused_valid_subsets=False, image_bucket_size=42, imagenet_default_mean_and_std=False, keep_best_checkpoints=1, keep_interval_updates=-1, keep_interval_updates_pattern=-1, keep_last_epochs=-1, label_smoothing=0.1, layernorm_embedding=True, load_checkpoint_on_all_dp_ranks=False, localsgd_frequency=3, log_file=None, log_format='simple', log_interval=10, lr=[3e-05], lr_scheduler='polynomial_decay', max_epoch=16, max_source_positions=1024, max_src_length=150, max_target_positions=1024, max_tgt_length=150, max_tokens=None, max_tokens_valid=None, max_update=0, max_valid_steps=None, maximize_best_checkpoint_metric=True, memory_efficient_bf16=False, memory_efficient_fp16=True, min_loss_scale=0.0001, min_params_to_wrap=100000000, model_parallel_size=1, no_cross_attention=False, no_epoch_checkpoints=False, no_last_checkpoints=False, no_progress_bar=False, no_reshard_after_forward=False, no_save=False, no_save_optimizer_state=False, no_scale_embedding=True, no_seed_provided=False, no_token_positional_embeddings=False, nprocs_per_node=2, num_bins=1000, num_shards=1, num_workers=0, on_cpu_convert_precision=False, optimizer='adam', optimizer_overrides='{}', orig_patch_image_size=256, pad=1, patch_image_size=512, patch_layernorm_embedding=True, patience=-1, pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, plasma_path='/tmp/plasma', pooler_activation_fn='tanh', pooler_classifier='mlp', pooler_dropout=0.0, power=1.0, profile=False, quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, quantization_config_path=None, reg_alpha=1.0, relu_dropout=0.0, report_accuracy=False, required_batch_size_multiple=8, required_seq_len_multiple=1, reset_dataloader=False, reset_logging=False, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, resnet_drop_path_rate=0.0, resnet_type='resnet101', restore_file='../../checkpoints/ofa_base.pt', sample_patch_num=196, save_dir='../../checkpoints/OFA/sgcls_checkpoints/_16_3e-5_512_base', save_interval=4, save_interval_updates=0, scale_attn=True, scale_fc=True, scale_heads=True, scale_resids=False, scoring='bleu', seed=1, selected_cols=None, sentence_avg=False, shard_id=0, share_all_embeddings=True, share_decoder_input_output_embed=True, simul_type=None, skip_invalid_size_inputs_valid_test=False, slowmo_algorithm='LocalSGD', slowmo_momentum=None, stop_min_lr=-1.0, stop_time_hours=0, store_ema=False, suppress_crashes=False, sync_bn=False, task='sgcls', tensorboard_logdir='./tensorboard/_16_3e-5_512', threshold_loss_scale=None, token_bucket_size=256, tokenizer=None, total_num_update=1000000, tpu=False, train_subset='train', unk=3, update_freq=[4], use_bmuf=False, use_ema_weights_to_init_param=False, use_latest_weights_to_init_ema=False, use_old_adam=False, use_plasma_view=False, use_rdrop=False, use_sharded_state=False, user_dir='../../ofa_module', valid_subset='valid', validate_after_updates=0, validate_interval=30, validate_interval_updates=0, vg_json_dir=None, wandb_project='OFA-VG', warmup_ratio=0.06, warmup_updates=0, weight_decay=0.01, write_checkpoints_asynchronously=False, zero_sharding='none'), 'task': {'_name': 'sgcls', 'data': '../../dataset/OFA_data/sgcls/vg_train_full.tsv,../../dataset/OFA_data/sgcls/vg_val_full.tsv', 'selected_cols': None, 'bpe': None, 'bpe_dir': '../../utils/BPE', 'max_source_positions': 1024, 'max_target_positions': 1024, 'max_src_length': 150, 'max_tgt_length': 150, 'code_dict_size': 8192, 'patch_image_size': 512, 'orig_patch_image_size': 256, 'num_bins': 1000, 'imagenet_default_mean_and_std': False, 'constraint_range': None, 'eval_args': '{"beam":5,"max_len_a":0,"max_len_b":200}', 'eval_print_samples': False, 'vg_json_dir': None}, 'criterion': {'_name': 'adjust_label_smoothed_cross_entropy', 'label_smoothing': 0.1, 'report_accuracy': False, 'ignore_prefix_size': 0, 'ignore_eos': False, 'sentence_avg': False, 'drop_worst_ratio': 0.0, 'drop_worst_after': 0, 'use_rdrop': False, 'reg_alpha': 1.0, 'sample_patch_num': 196, 'constraint_range': None}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9,0.999)', 'adam_eps': 1e-08, 'weight_decay': 0.01, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': False, 'lr': [3e-05]}, 'lr_scheduler': {'_name': 'polynomial_decay', 'warmup_updates': 0, 'warmup_ratio': 0.06, 'force_anneal': None, 'end_learning_rate': 0.0, 'power': 1.0, 'total_num_update': 1000000.0, 'lr': [3e-05]}, 'scoring': {'_name': 'bleu', 'pad': 1, 'eos': 2, 'unk': 3}, 'bpe': None, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}, 'simul_type': None}
2023-06-27 16:18:34 - sg_cls.py[line:82] - INFO: sgcls setup: source dictionary: 51267 types
2023-06-27 16:18:34 - sg_cls.py[line:83] - INFO: sgcls setup: target dictionary: 51267 types
/data/hulab/zcai75/anaconda3/envs/vilt/lib/python3.8/site-packages/torch/functional.py:478: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at  ../aten/src/ATen/native/TensorShape.cpp:2894.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/data/hulab/zcai75/anaconda3/envs/vilt/lib/python3.8/site-packages/torch/functional.py:478: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at  ../aten/src/ATen/native/TensorShape.cpp:2894.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
local datafile ../../dataset/OFA_data/sgcls/vg_val_full.tsv slice_id 1 begin to initialize row_count and line_idx-to-offset mapping
2023-06-27 16:18:37 - train.py[line:110] - INFO: OFAModel(
  (encoder): TransformerEncoder(
    (encoder_dropout): Dropout(p=0.2, inplace=False)
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(51267, 768, padding_idx=1)
    (layernorm_embedding): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (type_embedding): Embedding(2, 768)
    (embed_images): ResNet(
      (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)
      (layer1): Sequential(
        (0): Bottleneck(
          (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (downsample): Sequential(
            (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (drop_path): Identity()
        )
        (1): Bottleneck(
          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (2): Bottleneck(
          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
      )
      (layer2): Sequential(
        (0): Bottleneck(
          (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (downsample): Sequential(
            (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
            (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (drop_path): Identity()
        )
        (1): Bottleneck(
          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (2): Bottleneck(
          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (3): Bottleneck(
          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
      )
      (layer3): Sequential(
        (0): Bottleneck(
          (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (downsample): Sequential(
            (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)
            (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (drop_path): Identity()
        )
        (1): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (2): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (3): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (4): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (5): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (6): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (7): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (8): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (9): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (10): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (11): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (12): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (13): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (14): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (15): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (16): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (17): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (18): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (19): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (20): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (21): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (22): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
      )
    )
    (image_proj): Linear(in_features=1024, out_features=768, bias=True)
    (patch_layernorm_embedding): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (embed_positions): Embedding(1026, 768)
    (embed_image_positions): Embedding(1765, 768)
    (pos_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (image_pos_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (pos_q_linear): Linear(in_features=768, out_features=768, bias=True)
    (pos_k_linear): Linear(in_features=768, out_features=768, bias=True)
    (layers): ModuleList(
      (0): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): Identity()
      )
      (1): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(p=0.019999999552965164)
      )
      (2): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(p=0.03999999910593033)
      )
      (3): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(p=0.06000000238418579)
      )
      (4): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(p=0.07999999821186066)
      )
      (5): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(p=0.10000000149011612)
      )
    )
    (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (token_rel_pos_table_list): ModuleList(
      (0): Embedding(511, 12)
      (1): Embedding(511, 12)
      (2): Embedding(511, 12)
      (3): Embedding(511, 12)
      (4): Embedding(511, 12)
      (5): Embedding(511, 12)
    )
    (image_rel_pos_table_list): ModuleList(
      (0): Embedding(6892, 12)
      (1): Embedding(6892, 12)
      (2): Embedding(6892, 12)
      (3): Embedding(6892, 12)
      (4): Embedding(6892, 12)
      (5): Embedding(6892, 12)
    )
  )
  (decoder): TransformerDecoder(
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(51267, 768, padding_idx=1)
    (layernorm_embedding): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (embed_positions): Embedding(1026, 768)
    (embed_image_positions): Embedding(1765, 768)
    (pos_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (image_pos_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (self_pos_q_linear): Linear(in_features=768, out_features=768, bias=True)
    (self_pos_k_linear): Linear(in_features=768, out_features=768, bias=True)
    (cross_pos_q_linear): Linear(in_features=768, out_features=768, bias=True)
    (cross_pos_k_linear): Linear(in_features=768, out_features=768, bias=True)
    (code_layernorm_embedding): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (layers): ModuleList(
      (0): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (cross_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): Identity()
      )
      (1): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (cross_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(p=0.019999999552965164)
      )
      (2): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (cross_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(p=0.03999999910593033)
      )
      (3): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (cross_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(p=0.06000000238418579)
      )
      (4): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (cross_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(p=0.07999999821186066)
      )
      (5): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (cross_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(p=0.10000000149011612)
      )
    )
    (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (output_projection): Linear(in_features=768, out_features=51267, bias=False)
    (token_rel_pos_table_list): ModuleList(
      (0): Embedding(511, 12)
      (1): Embedding(511, 12)
      (2): Embedding(511, 12)
      (3): Embedding(511, 12)
      (4): Embedding(511, 12)
      (5): Embedding(511, 12)
    )
    (image_rel_pos_table_list): ModuleList(
      (0): Embedding(6892, 12)
      (1): Embedding(6892, 12)
      (2): Embedding(6892, 12)
      (3): Embedding(6892, 12)
      (4): Embedding(6892, 12)
      (5): Embedding(6892, 12)
    )
  )
  (classification_heads): ModuleDict()
)
2023-06-27 16:18:37 - train.py[line:111] - INFO: task: SGClsTask
2023-06-27 16:18:37 - train.py[line:112] - INFO: model: OFAModel
2023-06-27 16:18:37 - train.py[line:113] - INFO: criterion: AdjustLabelSmoothedCrossEntropyCriterion
2023-06-27 16:18:37 - train.py[line:114] - INFO: num. shared model params: 175,948,616 (num. trained: 175,948,616)
2023-06-27 16:18:37 - train.py[line:121] - INFO: num. expert model params: 0 (num. trained: 0)
local datafile ../../dataset/OFA_data/sgcls/vg_val_full.tsv slice_id 0 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../dataset/OFA_data/sgcls/vg_val_full.tsv slice_id 1 finished initializing row_count and line_idx-to-offset mapping
file ../../dataset/OFA_data/sgcls/vg_val_full.tsv slice_id 1 row count 11440 total row count 22880
/data/hulab/zcai75/anaconda3/envs/vilt/lib/python3.8/site-packages/torchvision/transforms/transforms.py:332: UserWarning: Argument 'interpolation' of type int is deprecated since 0.13 and will be removed in 0.15. Please use InterpolationMode enum.
  warnings.warn(
local datafile ../../dataset/OFA_data/sgcls/vg_val_full.tsv slice_id 0 finished initializing row_count and line_idx-to-offset mapping
file ../../dataset/OFA_data/sgcls/vg_val_full.tsv slice_id 0 row count 11440 total row count 22880
/data/hulab/zcai75/anaconda3/envs/vilt/lib/python3.8/site-packages/torchvision/transforms/transforms.py:332: UserWarning: Argument 'interpolation' of type int is deprecated since 0.13 and will be removed in 0.15. Please use InterpolationMode enum.
  warnings.warn(
2023-06-27 16:18:37 - distributed_c10d.py[line:228] - INFO: Added key: store_based_barrier_key:2 to store for rank: 0
2023-06-27 16:18:37 - distributed_c10d.py[line:262] - INFO: Rank 0: Completed store-based barrier for key:store_based_barrier_key:2 with 2 nodes.
2023-06-27 16:18:37 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_tokens.weight <- decoder.embed_tokens.weight
2023-06-27 16:18:37 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_tokens.weight <- decoder.output_projection.weight
2023-06-27 16:18:37 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer1.0.conv1.bias
2023-06-27 16:18:37 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer1.0.conv2.bias
2023-06-27 16:18:37 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer1.0.conv3.bias
2023-06-27 16:18:37 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer1.0.downsample.0.bias
2023-06-27 16:18:37 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer1.1.conv1.bias
2023-06-27 16:18:37 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer1.1.conv2.bias
2023-06-27 16:18:37 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer1.1.conv3.bias
2023-06-27 16:18:37 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer1.2.conv1.bias
2023-06-27 16:18:37 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer1.2.conv2.bias
2023-06-27 16:18:37 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer1.2.conv3.bias
2023-06-27 16:18:37 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.0.conv1.bias
2023-06-27 16:18:37 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.0.conv2.bias
2023-06-27 16:18:37 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.0.conv3.bias
2023-06-27 16:18:37 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.0.downsample.0.bias
2023-06-27 16:18:37 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.1.conv1.bias
2023-06-27 16:18:37 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.1.conv2.bias
2023-06-27 16:18:37 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.1.conv3.bias
2023-06-27 16:18:37 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.2.conv1.bias
2023-06-27 16:18:37 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.2.conv2.bias
2023-06-27 16:18:37 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.2.conv3.bias
2023-06-27 16:18:37 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.3.conv1.bias
2023-06-27 16:18:37 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.3.conv2.bias
2023-06-27 16:18:37 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.3.conv3.bias
2023-06-27 16:18:37 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.0.conv1.bias
2023-06-27 16:18:37 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.0.conv2.bias
2023-06-27 16:18:37 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.0.conv3.bias
2023-06-27 16:18:37 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.0.downsample.0.bias
2023-06-27 16:18:37 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.1.conv1.bias
2023-06-27 16:18:37 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.1.conv2.bias
2023-06-27 16:18:37 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.1.conv3.bias
2023-06-27 16:18:37 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.2.conv1.bias
2023-06-27 16:18:37 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.2.conv2.bias
2023-06-27 16:18:37 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.2.conv3.bias
2023-06-27 16:18:37 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.3.conv1.bias
2023-06-27 16:18:37 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.3.conv2.bias
2023-06-27 16:18:37 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.3.conv3.bias
2023-06-27 16:18:37 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.4.conv1.bias
2023-06-27 16:18:37 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.4.conv2.bias
2023-06-27 16:18:37 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.4.conv3.bias
2023-06-27 16:18:37 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.5.conv1.bias
2023-06-27 16:18:37 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.5.conv2.bias
2023-06-27 16:18:37 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.5.conv3.bias
2023-06-27 16:18:37 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.6.conv1.bias
2023-06-27 16:18:37 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.6.conv2.bias
2023-06-27 16:18:37 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.6.conv3.bias
2023-06-27 16:18:37 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.7.conv1.bias
2023-06-27 16:18:37 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.7.conv2.bias
2023-06-27 16:18:37 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.7.conv3.bias
2023-06-27 16:18:37 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.8.conv1.bias
2023-06-27 16:18:37 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.8.conv2.bias
2023-06-27 16:18:37 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.8.conv3.bias
2023-06-27 16:18:37 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.9.conv1.bias
2023-06-27 16:18:37 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.9.conv2.bias
2023-06-27 16:18:37 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.9.conv3.bias
2023-06-27 16:18:37 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.10.conv1.bias
2023-06-27 16:18:37 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.10.conv2.bias
2023-06-27 16:18:37 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.10.conv3.bias
2023-06-27 16:18:37 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.11.conv1.bias
2023-06-27 16:18:37 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.11.conv2.bias
2023-06-27 16:18:37 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.11.conv3.bias
2023-06-27 16:18:37 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.12.conv1.bias
2023-06-27 16:18:37 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.12.conv2.bias
2023-06-27 16:18:37 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.12.conv3.bias
2023-06-27 16:18:37 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.13.conv1.bias
2023-06-27 16:18:37 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.13.conv2.bias
2023-06-27 16:18:37 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.13.conv3.bias
2023-06-27 16:18:37 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.14.conv1.bias
2023-06-27 16:18:37 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.14.conv2.bias
2023-06-27 16:18:37 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.14.conv3.bias
2023-06-27 16:18:37 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.15.conv1.bias
2023-06-27 16:18:37 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.15.conv2.bias
2023-06-27 16:18:37 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.15.conv3.bias
2023-06-27 16:18:37 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.16.conv1.bias
2023-06-27 16:18:37 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.16.conv2.bias
2023-06-27 16:18:37 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.16.conv3.bias
2023-06-27 16:18:37 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.17.conv1.bias
2023-06-27 16:18:37 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.17.conv2.bias
2023-06-27 16:18:37 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.17.conv3.bias
2023-06-27 16:18:37 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.18.conv1.bias
2023-06-27 16:18:37 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.18.conv2.bias
2023-06-27 16:18:37 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.18.conv3.bias
2023-06-27 16:18:37 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.19.conv1.bias
2023-06-27 16:18:37 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.19.conv2.bias
2023-06-27 16:18:37 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.19.conv3.bias
2023-06-27 16:18:37 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.20.conv1.bias
2023-06-27 16:18:37 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.20.conv2.bias
2023-06-27 16:18:37 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.20.conv3.bias
2023-06-27 16:18:37 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.21.conv1.bias
2023-06-27 16:18:37 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.21.conv2.bias
2023-06-27 16:18:37 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.21.conv3.bias
2023-06-27 16:18:37 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.22.conv1.bias
2023-06-27 16:18:37 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.22.conv2.bias
2023-06-27 16:18:37 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.22.conv3.bias
2023-06-27 16:18:37 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- decoder.output_projection.bias
2023-06-27 16:18:37 - utils.py[line:759] - INFO: ***********************CUDA enviroments for all 2 workers***********************
2023-06-27 16:18:37 - utils.py[line:761] - INFO: rank   0: capabilities =  8.6  ; total memory = 23.688 GB ; name = NVIDIA GeForce RTX 3090 Ti              
2023-06-27 16:18:37 - utils.py[line:761] - INFO: rank   1: capabilities =  8.6  ; total memory = 23.688 GB ; name = NVIDIA GeForce RTX 3090 Ti              
2023-06-27 16:18:37 - utils.py[line:767] - INFO: ***********************CUDA enviroments for all 2 workers***********************
2023-06-27 16:18:37 - train.py[line:152] - INFO: training on 2 devices (GPUs/TPUs)
2023-06-27 16:18:37 - train.py[line:157] - INFO: max tokens per device = None and max sentences per device = 7
2023-06-27 16:18:37 - trainer.py[line:458] - INFO: Preparing to load checkpoint ../../checkpoints/ofa_base.pt
2023-06-27 16:18:37 - trainer.py[line:624] - INFO: No existing checkpoint found ../../checkpoints/ofa_base.pt
2023-06-27 16:18:37 - trainer.py[line:639] - INFO: loading train data for epoch 1
local datafile ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 0 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 1 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 0 finished initializing row_count and line_idx-to-offset mapping
file ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 0 row count 27700 total row count 55400
local datafile ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 1 finished initializing row_count and line_idx-to-offset mapping
file ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 1 row count 27700 total row count 55400
slice_id 1 seek offset 27700
Total steps 15840, warmup steps 950, warmup_factor 0.0010526315789473684
slice_id 0 seek offset 0
Total steps 15840, warmup steps 950, warmup_factor 0.0010526315789473684
wandb: Currently logged in as: jackcai1206. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /home/zcai75/Github/OFA_forked/run_scripts/sgcls/wandb/run-20230627_161840-egphhs3z
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run _16_3e-5_512_base
wandb: ⭐️ View project at https://wandb.ai/jackcai1206/OFA-VG
wandb: 🚀 View run at https://wandb.ai/jackcai1206/OFA-VG/runs/egphhs3z
2023-06-27 16:18:46 - trainer.py[line:703] - INFO: begin training epoch 1
2023-06-27 16:18:46 - train.py[line:305] - INFO: Start iterating over samples
/home/zcai75/Github/OFA/fairseq/fairseq/utils.py:372: UserWarning: amp_C fused kernels unavailable, disabling multi_tensor_l2norm; you may get better performance by installing NVIDIA's apex library
  warnings.warn(
/home/zcai75/Github/OFA/fairseq/fairseq/utils.py:372: UserWarning: amp_C fused kernels unavailable, disabling multi_tensor_l2norm; you may get better performance by installing NVIDIA's apex library
  warnings.warn(
2023-06-27 16:18:50 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2023-06-27 16:19:08 - progress_bar.py[line:272] - INFO: epoch 001:     11 / 990 loss=11.238, loss_v1=0, loss_v2=0, nll_loss=11.264, ntokens=1878.8, nsentences=56, sample_size=1878.8, sample_size_v1=0, sample_size_v2=0, ppl=2459.94, wps=1076, ups=0.58, wpb=1878.8, bsz=56, num_updates=10, lr=3.15789e-07, gnorm=19.192, clip=100, loss_scale=64, train_wall=22, gb_free=12.5, wall=31
2023-06-27 16:19:15 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2023-06-27 16:19:27 - progress_bar.py[line:272] - INFO: epoch 001:     22 / 990 loss=11.229, loss_v1=0, loss_v2=0, nll_loss=11.255, ntokens=1797.6, nsentences=56, sample_size=1797.6, sample_size_v1=0, sample_size_v2=0, ppl=2443.84, wps=950.3, ups=0.53, wpb=1797.6, bsz=56, num_updates=20, lr=6.31579e-07, gnorm=19.46, clip=100, loss_scale=32, train_wall=19, gb_free=12.7, wall=50
2023-06-27 16:19:44 - progress_bar.py[line:272] - INFO: epoch 001:     32 / 990 loss=11.174, loss_v1=0, loss_v2=0, nll_loss=11.194, ntokens=1723.3, nsentences=56, sample_size=1723.3, sample_size_v1=0, sample_size_v2=0, ppl=2342.62, wps=1012.3, ups=0.59, wpb=1723.3, bsz=56, num_updates=30, lr=9.47368e-07, gnorm=19.096, clip=100, loss_scale=32, train_wall=17, gb_free=12.2, wall=67
2023-06-27 16:20:01 - progress_bar.py[line:272] - INFO: epoch 001:     42 / 990 loss=11.088, loss_v1=0, loss_v2=0, nll_loss=11.098, ntokens=1984, nsentences=56, sample_size=1984, sample_size_v1=0, sample_size_v2=0, ppl=2192.28, wps=1137.6, ups=0.57, wpb=1984, bsz=56, num_updates=40, lr=1.26316e-06, gnorm=19.466, clip=100, loss_scale=32, train_wall=17, gb_free=11.4, wall=84
2023-06-27 16:20:19 - progress_bar.py[line:272] - INFO: epoch 001:     52 / 990 loss=10.913, loss_v1=0, loss_v2=0, nll_loss=10.904, ntokens=1757.8, nsentences=56, sample_size=1757.8, sample_size_v1=0, sample_size_v2=0, ppl=1916, wps=1019.5, ups=0.58, wpb=1757.8, bsz=56, num_updates=50, lr=1.57895e-06, gnorm=19.548, clip=100, loss_scale=32, train_wall=17, gb_free=12.8, wall=101
2023-06-27 16:20:36 - progress_bar.py[line:272] - INFO: epoch 001:     62 / 990 loss=10.67, loss_v1=0, loss_v2=0, nll_loss=10.633, ntokens=1799.6, nsentences=56, sample_size=1799.6, sample_size_v1=0, sample_size_v2=0, ppl=1588.28, wps=1043.4, ups=0.58, wpb=1799.6, bsz=56, num_updates=60, lr=1.89474e-06, gnorm=19.344, clip=100, loss_scale=32, train_wall=17, gb_free=12.4, wall=119
2023-06-27 16:20:54 - progress_bar.py[line:272] - INFO: epoch 001:     72 / 990 loss=10.195, loss_v1=0, loss_v2=0, nll_loss=10.105, ntokens=2037.7, nsentences=56, sample_size=2037.7, sample_size_v1=0, sample_size_v2=0, ppl=1101.4, wps=1154.9, ups=0.57, wpb=2037.7, bsz=56, num_updates=70, lr=2.21053e-06, gnorm=19.682, clip=100, loss_scale=32, train_wall=18, gb_free=11.5, wall=136
2023-06-27 16:21:11 - progress_bar.py[line:272] - INFO: epoch 001:     82 / 990 loss=9.641, loss_v1=0, loss_v2=0, nll_loss=9.49, ntokens=2177.1, nsentences=56, sample_size=2177.1, sample_size_v1=0, sample_size_v2=0, ppl=719.21, wps=1229.6, ups=0.56, wpb=2177.1, bsz=56, num_updates=80, lr=2.52632e-06, gnorm=16.588, clip=100, loss_scale=32, train_wall=18, gb_free=11.6, wall=154
2023-06-27 16:21:29 - progress_bar.py[line:272] - INFO: epoch 001:     92 / 990 loss=9.014, loss_v1=0, loss_v2=0, nll_loss=8.792, ntokens=2019.4, nsentences=56, sample_size=2019.4, sample_size_v1=0, sample_size_v2=0, ppl=443.25, wps=1140.6, ups=0.56, wpb=2019.4, bsz=56, num_updates=90, lr=2.84211e-06, gnorm=13.029, clip=100, loss_scale=32, train_wall=18, gb_free=12.5, wall=172
2023-06-27 16:21:46 - progress_bar.py[line:272] - INFO: epoch 001:    102 / 990 loss=8.434, loss_v1=0, loss_v2=0, nll_loss=8.146, ntokens=1873.6, nsentences=56, sample_size=1873.6, sample_size_v1=0, sample_size_v2=0, ppl=283.24, wps=1082.3, ups=0.58, wpb=1873.6, bsz=56, num_updates=100, lr=3.15789e-06, gnorm=9.762, clip=100, loss_scale=32, train_wall=17, gb_free=11.9, wall=189
2023-06-27 16:22:04 - progress_bar.py[line:272] - INFO: epoch 001:    112 / 990 loss=7.995, loss_v1=0, loss_v2=0, nll_loss=7.655, ntokens=1869, nsentences=56, sample_size=1869, sample_size_v1=0, sample_size_v2=0, ppl=201.56, wps=1085.4, ups=0.58, wpb=1869, bsz=56, num_updates=110, lr=3.47368e-06, gnorm=8.461, clip=100, loss_scale=32, train_wall=17, gb_free=12.6, wall=206
2023-06-27 16:22:21 - progress_bar.py[line:272] - INFO: epoch 001:    122 / 990 loss=7.75, loss_v1=0, loss_v2=0, nll_loss=7.38, ntokens=1761.5, nsentences=56, sample_size=1761.5, sample_size_v1=0, sample_size_v2=0, ppl=166.62, wps=1028.2, ups=0.58, wpb=1761.5, bsz=56, num_updates=120, lr=3.78947e-06, gnorm=7.032, clip=100, loss_scale=32, train_wall=17, gb_free=11.8, wall=223
2023-06-27 16:22:38 - progress_bar.py[line:272] - INFO: epoch 001:    132 / 990 loss=7.499, loss_v1=0, loss_v2=0, nll_loss=7.098, ntokens=1815.9, nsentences=56, sample_size=1815.9, sample_size_v1=0, sample_size_v2=0, ppl=136.99, wps=1056, ups=0.58, wpb=1815.9, bsz=56, num_updates=130, lr=4.10526e-06, gnorm=6.294, clip=100, loss_scale=32, train_wall=17, gb_free=11.9, wall=241
2023-06-27 16:22:55 - progress_bar.py[line:272] - INFO: epoch 001:    142 / 990 loss=7.286, loss_v1=0, loss_v2=0, nll_loss=6.859, ntokens=1956.5, nsentences=56, sample_size=1956.5, sample_size_v1=0, sample_size_v2=0, ppl=116.08, wps=1121.4, ups=0.57, wpb=1956.5, bsz=56, num_updates=140, lr=4.42105e-06, gnorm=5.804, clip=100, loss_scale=32, train_wall=17, gb_free=12.3, wall=258
2023-06-27 16:23:13 - progress_bar.py[line:272] - INFO: epoch 001:    152 / 990 loss=7.094, loss_v1=0, loss_v2=0, nll_loss=6.645, ntokens=1960.6, nsentences=56, sample_size=1960.6, sample_size_v1=0, sample_size_v2=0, ppl=100.09, wps=1116.9, ups=0.57, wpb=1960.6, bsz=56, num_updates=150, lr=4.73684e-06, gnorm=5.686, clip=100, loss_scale=32, train_wall=18, gb_free=11.5, wall=276
2023-06-27 16:23:30 - progress_bar.py[line:272] - INFO: epoch 001:    162 / 990 loss=6.9, loss_v1=0, loss_v2=0, nll_loss=6.428, ntokens=1989.5, nsentences=56, sample_size=1989.5, sample_size_v1=0, sample_size_v2=0, ppl=86.1, wps=1141, ups=0.57, wpb=1989.5, bsz=56, num_updates=160, lr=5.05263e-06, gnorm=5.45, clip=100, loss_scale=32, train_wall=17, gb_free=12.2, wall=293
2023-06-27 16:23:48 - progress_bar.py[line:272] - INFO: epoch 001:    172 / 990 loss=6.778, loss_v1=0, loss_v2=0, nll_loss=6.292, ntokens=1891.1, nsentences=56, sample_size=1891.1, sample_size_v1=0, sample_size_v2=0, ppl=78.37, wps=1088.3, ups=0.58, wpb=1891.1, bsz=56, num_updates=170, lr=5.36842e-06, gnorm=5.298, clip=100, loss_scale=32, train_wall=17, gb_free=12.7, wall=310
2023-06-27 16:24:05 - progress_bar.py[line:272] - INFO: epoch 001:    182 / 990 loss=6.613, loss_v1=0, loss_v2=0, nll_loss=6.107, ntokens=1964.6, nsentences=56, sample_size=1964.6, sample_size_v1=0, sample_size_v2=0, ppl=68.94, wps=1127.6, ups=0.57, wpb=1964.6, bsz=56, num_updates=180, lr=5.68421e-06, gnorm=5.016, clip=100, loss_scale=32, train_wall=17, gb_free=12.9, wall=328
2023-06-27 16:24:22 - progress_bar.py[line:272] - INFO: epoch 001:    192 / 990 loss=6.343, loss_v1=0, loss_v2=0, nll_loss=5.804, ntokens=1901, nsentences=56, sample_size=1901, sample_size_v1=0, sample_size_v2=0, ppl=55.89, wps=1100, ups=0.58, wpb=1901, bsz=56, num_updates=190, lr=6e-06, gnorm=5.003, clip=100, loss_scale=32, train_wall=17, gb_free=12.8, wall=345
2023-06-27 16:24:40 - progress_bar.py[line:272] - INFO: epoch 001:    202 / 990 loss=6.063, loss_v1=0, loss_v2=0, nll_loss=5.487, ntokens=1816.8, nsentences=56, sample_size=1816.8, sample_size_v1=0, sample_size_v2=0, ppl=44.85, wps=1058.3, ups=0.58, wpb=1816.8, bsz=56, num_updates=200, lr=6.31579e-06, gnorm=4.658, clip=100, loss_scale=32, train_wall=17, gb_free=11.8, wall=362
2023-06-27 16:24:57 - progress_bar.py[line:272] - INFO: epoch 001:    212 / 990 loss=5.754, loss_v1=0, loss_v2=0, nll_loss=5.134, ntokens=1921.3, nsentences=56, sample_size=1921.3, sample_size_v1=0, sample_size_v2=0, ppl=35.11, wps=1106, ups=0.58, wpb=1921.3, bsz=56, num_updates=210, lr=6.63158e-06, gnorm=4.364, clip=100, loss_scale=32, train_wall=17, gb_free=11.3, wall=380
2023-06-27 16:25:14 - progress_bar.py[line:272] - INFO: epoch 001:    222 / 990 loss=5.584, loss_v1=0, loss_v2=0, nll_loss=4.932, ntokens=1933.9, nsentences=56, sample_size=1933.9, sample_size_v1=0, sample_size_v2=0, ppl=30.53, wps=1113.3, ups=0.58, wpb=1933.9, bsz=56, num_updates=220, lr=6.94737e-06, gnorm=3.882, clip=100, loss_scale=32, train_wall=17, gb_free=12.7, wall=397
2023-06-27 16:25:32 - progress_bar.py[line:272] - INFO: epoch 001:    232 / 990 loss=5.395, loss_v1=0, loss_v2=0, nll_loss=4.712, ntokens=1800, nsentences=56, sample_size=1800, sample_size_v1=0, sample_size_v2=0, ppl=26.22, wps=1044.6, ups=0.58, wpb=1800, bsz=56, num_updates=230, lr=7.26316e-06, gnorm=3.72, clip=100, loss_scale=32, train_wall=17, gb_free=12.8, wall=414
2023-06-27 16:25:49 - progress_bar.py[line:272] - INFO: epoch 001:    242 / 990 loss=5.257, loss_v1=0, loss_v2=0, nll_loss=4.555, ntokens=1776, nsentences=56, sample_size=1776, sample_size_v1=0, sample_size_v2=0, ppl=23.51, wps=1033.7, ups=0.58, wpb=1776, bsz=56, num_updates=240, lr=7.57895e-06, gnorm=3.396, clip=100, loss_scale=32, train_wall=17, gb_free=12.6, wall=431
2023-06-27 16:26:06 - progress_bar.py[line:272] - INFO: epoch 001:    252 / 990 loss=5.129, loss_v1=0, loss_v2=0, nll_loss=4.407, ntokens=1951.4, nsentences=56, sample_size=1951.4, sample_size_v1=0, sample_size_v2=0, ppl=21.22, wps=1135, ups=0.58, wpb=1951.4, bsz=56, num_updates=250, lr=7.89474e-06, gnorm=3.167, clip=100, loss_scale=32, train_wall=17, gb_free=12.6, wall=449
2023-06-27 16:26:23 - progress_bar.py[line:272] - INFO: epoch 001:    262 / 990 loss=4.992, loss_v1=0, loss_v2=0, nll_loss=4.251, ntokens=1898.3, nsentences=56, sample_size=1898.3, sample_size_v1=0, sample_size_v2=0, ppl=19.04, wps=1103.2, ups=0.58, wpb=1898.3, bsz=56, num_updates=260, lr=8.21053e-06, gnorm=2.932, clip=100, loss_scale=32, train_wall=17, gb_free=12.9, wall=466
2023-06-27 16:26:40 - progress_bar.py[line:272] - INFO: epoch 001:    272 / 990 loss=4.875, loss_v1=0, loss_v2=0, nll_loss=4.116, ntokens=1883.4, nsentences=56, sample_size=1883.4, sample_size_v1=0, sample_size_v2=0, ppl=17.35, wps=1090.7, ups=0.58, wpb=1883.4, bsz=56, num_updates=270, lr=8.52632e-06, gnorm=2.743, clip=100, loss_scale=32, train_wall=17, gb_free=12.5, wall=483
2023-06-27 16:26:58 - progress_bar.py[line:272] - INFO: epoch 001:    282 / 990 loss=4.74, loss_v1=0, loss_v2=0, nll_loss=3.96, ntokens=1918, nsentences=56, sample_size=1918, sample_size_v1=0, sample_size_v2=0, ppl=15.56, wps=1105.9, ups=0.58, wpb=1918, bsz=56, num_updates=280, lr=8.84211e-06, gnorm=2.652, clip=100, loss_scale=32, train_wall=17, gb_free=12.1, wall=500
2023-06-27 16:27:15 - progress_bar.py[line:272] - INFO: epoch 001:    292 / 990 loss=4.67, loss_v1=0, loss_v2=0, nll_loss=3.88, ntokens=1834.9, nsentences=56, sample_size=1834.9, sample_size_v1=0, sample_size_v2=0, ppl=14.73, wps=1071.5, ups=0.58, wpb=1834.9, bsz=56, num_updates=290, lr=9.15789e-06, gnorm=2.553, clip=100, loss_scale=32, train_wall=17, gb_free=12.7, wall=518
2023-06-27 16:27:32 - progress_bar.py[line:272] - INFO: epoch 001:    302 / 990 loss=4.592, loss_v1=0, loss_v2=0, nll_loss=3.789, ntokens=1925.9, nsentences=56, sample_size=1925.9, sample_size_v1=0, sample_size_v2=0, ppl=13.82, wps=1116.8, ups=0.58, wpb=1925.9, bsz=56, num_updates=300, lr=9.47368e-06, gnorm=2.573, clip=100, loss_scale=32, train_wall=17, gb_free=11.9, wall=535
2023-06-27 16:27:49 - progress_bar.py[line:272] - INFO: epoch 001:    312 / 990 loss=4.531, loss_v1=0, loss_v2=0, nll_loss=3.72, ntokens=1880, nsentences=56, sample_size=1880, sample_size_v1=0, sample_size_v2=0, ppl=13.18, wps=1093.2, ups=0.58, wpb=1880, bsz=56, num_updates=310, lr=9.78947e-06, gnorm=2.481, clip=100, loss_scale=32, train_wall=17, gb_free=12.6, wall=552
2023-06-27 16:28:07 - progress_bar.py[line:272] - INFO: epoch 001:    322 / 990 loss=4.392, loss_v1=0, loss_v2=0, nll_loss=3.561, ntokens=1910.2, nsentences=56, sample_size=1910.2, sample_size_v1=0, sample_size_v2=0, ppl=11.81, wps=1106.8, ups=0.58, wpb=1910.2, bsz=56, num_updates=320, lr=1.01053e-05, gnorm=2.301, clip=100, loss_scale=32, train_wall=17, gb_free=11.8, wall=569
2023-06-27 16:28:24 - progress_bar.py[line:272] - INFO: epoch 001:    332 / 990 loss=4.343, loss_v1=0, loss_v2=0, nll_loss=3.503, ntokens=1876.3, nsentences=56, sample_size=1876.3, sample_size_v1=0, sample_size_v2=0, ppl=11.34, wps=1093.7, ups=0.58, wpb=1876.3, bsz=56, num_updates=330, lr=1.04211e-05, gnorm=2.102, clip=100, loss_scale=32, train_wall=17, gb_free=12.9, wall=586
2023-06-27 16:28:41 - progress_bar.py[line:272] - INFO: epoch 001:    342 / 990 loss=4.248, loss_v1=0, loss_v2=0, nll_loss=3.394, ntokens=1898.9, nsentences=56, sample_size=1898.9, sample_size_v1=0, sample_size_v2=0, ppl=10.51, wps=1102.2, ups=0.58, wpb=1898.9, bsz=56, num_updates=340, lr=1.07368e-05, gnorm=2.193, clip=100, loss_scale=32, train_wall=17, gb_free=12.3, wall=604
2023-06-27 16:28:58 - progress_bar.py[line:272] - INFO: epoch 001:    352 / 990 loss=4.149, loss_v1=0, loss_v2=0, nll_loss=3.281, ntokens=1879.4, nsentences=56, sample_size=1879.4, sample_size_v1=0, sample_size_v2=0, ppl=9.72, wps=1094.1, ups=0.58, wpb=1879.4, bsz=56, num_updates=350, lr=1.10526e-05, gnorm=2.15, clip=100, loss_scale=32, train_wall=17, gb_free=12.6, wall=621
2023-06-27 16:29:15 - progress_bar.py[line:272] - INFO: epoch 001:    362 / 990 loss=4.118, loss_v1=0, loss_v2=0, nll_loss=3.243, ntokens=1783.9, nsentences=56, sample_size=1783.9, sample_size_v1=0, sample_size_v2=0, ppl=9.47, wps=1043.8, ups=0.59, wpb=1783.9, bsz=56, num_updates=360, lr=1.13684e-05, gnorm=2.036, clip=100, loss_scale=32, train_wall=17, gb_free=12.7, wall=638
2023-06-27 16:29:32 - progress_bar.py[line:272] - INFO: epoch 001:    372 / 990 loss=4.008, loss_v1=0, loss_v2=0, nll_loss=3.117, ntokens=1756.1, nsentences=56, sample_size=1756.1, sample_size_v1=0, sample_size_v2=0, ppl=8.68, wps=1030.8, ups=0.59, wpb=1756.1, bsz=56, num_updates=370, lr=1.16842e-05, gnorm=1.874, clip=100, loss_scale=32, train_wall=17, gb_free=12.6, wall=655
2023-06-27 16:29:49 - progress_bar.py[line:272] - INFO: epoch 001:    382 / 990 loss=3.896, loss_v1=0, loss_v2=0, nll_loss=2.986, ntokens=1868.9, nsentences=56, sample_size=1868.9, sample_size_v1=0, sample_size_v2=0, ppl=7.92, wps=1094.6, ups=0.59, wpb=1868.9, bsz=56, num_updates=380, lr=1.2e-05, gnorm=1.86, clip=100, loss_scale=32, train_wall=17, gb_free=12.6, wall=672
2023-06-27 16:30:06 - progress_bar.py[line:272] - INFO: epoch 001:    392 / 990 loss=3.83, loss_v1=0, loss_v2=0, nll_loss=2.91, ntokens=1758.6, nsentences=56, sample_size=1758.6, sample_size_v1=0, sample_size_v2=0, ppl=7.52, wps=1032.6, ups=0.59, wpb=1758.6, bsz=56, num_updates=390, lr=1.23158e-05, gnorm=1.927, clip=100, loss_scale=32, train_wall=17, gb_free=12.9, wall=689
2023-06-27 16:30:23 - progress_bar.py[line:272] - INFO: epoch 001:    402 / 990 loss=3.806, loss_v1=0, loss_v2=0, nll_loss=2.879, ntokens=1733.9, nsentences=56, sample_size=1733.9, sample_size_v1=0, sample_size_v2=0, ppl=7.36, wps=1019.4, ups=0.59, wpb=1733.9, bsz=56, num_updates=400, lr=1.26316e-05, gnorm=1.933, clip=100, loss_scale=32, train_wall=17, gb_free=12.8, wall=706
2023-06-27 16:30:40 - progress_bar.py[line:272] - INFO: epoch 001:    412 / 990 loss=3.739, loss_v1=0, loss_v2=0, nll_loss=2.802, ntokens=1702.7, nsentences=56, sample_size=1702.7, sample_size_v1=0, sample_size_v2=0, ppl=6.97, wps=1000.2, ups=0.59, wpb=1702.7, bsz=56, num_updates=410, lr=1.29474e-05, gnorm=1.96, clip=100, loss_scale=32, train_wall=17, gb_free=12.6, wall=723
2023-06-27 16:30:58 - progress_bar.py[line:272] - INFO: epoch 001:    422 / 990 loss=3.673, loss_v1=0, loss_v2=0, nll_loss=2.726, ntokens=1751.8, nsentences=56, sample_size=1751.8, sample_size_v1=0, sample_size_v2=0, ppl=6.62, wps=1027.4, ups=0.59, wpb=1751.8, bsz=56, num_updates=420, lr=1.32632e-05, gnorm=1.737, clip=100, loss_scale=32, train_wall=17, gb_free=12.7, wall=740
2023-06-27 16:31:15 - progress_bar.py[line:272] - INFO: epoch 001:    432 / 990 loss=3.597, loss_v1=0, loss_v2=0, nll_loss=2.635, ntokens=1888.6, nsentences=56, sample_size=1888.6, sample_size_v1=0, sample_size_v2=0, ppl=6.21, wps=1101.4, ups=0.58, wpb=1888.6, bsz=56, num_updates=430, lr=1.35789e-05, gnorm=1.631, clip=100, loss_scale=32, train_wall=17, gb_free=12.9, wall=757
2023-06-27 16:31:32 - progress_bar.py[line:272] - INFO: epoch 001:    442 / 990 loss=3.525, loss_v1=0, loss_v2=0, nll_loss=2.552, ntokens=1918.5, nsentences=56, sample_size=1918.5, sample_size_v1=0, sample_size_v2=0, ppl=5.86, wps=1121, ups=0.58, wpb=1918.5, bsz=56, num_updates=440, lr=1.38947e-05, gnorm=1.705, clip=100, loss_scale=32, train_wall=17, gb_free=12.7, wall=774
2023-06-27 16:31:49 - progress_bar.py[line:272] - INFO: epoch 001:    452 / 990 loss=3.447, loss_v1=0, loss_v2=0, nll_loss=2.457, ntokens=1723.6, nsentences=56, sample_size=1723.6, sample_size_v1=0, sample_size_v2=0, ppl=5.49, wps=1004.4, ups=0.58, wpb=1723.6, bsz=56, num_updates=450, lr=1.42105e-05, gnorm=1.596, clip=100, loss_scale=32, train_wall=17, gb_free=12.3, wall=792
2023-06-27 16:32:06 - progress_bar.py[line:272] - INFO: epoch 001:    462 / 990 loss=3.411, loss_v1=0, loss_v2=0, nll_loss=2.415, ntokens=1871.7, nsentences=56, sample_size=1871.7, sample_size_v1=0, sample_size_v2=0, ppl=5.33, wps=1089.1, ups=0.58, wpb=1871.7, bsz=56, num_updates=460, lr=1.45263e-05, gnorm=1.603, clip=100, loss_scale=32, train_wall=17, gb_free=12.5, wall=809
2023-06-27 16:32:23 - progress_bar.py[line:272] - INFO: epoch 001:    472 / 990 loss=3.357, loss_v1=0, loss_v2=0, nll_loss=2.35, ntokens=1880.6, nsentences=56, sample_size=1880.6, sample_size_v1=0, sample_size_v2=0, ppl=5.1, wps=1094.8, ups=0.58, wpb=1880.6, bsz=56, num_updates=470, lr=1.48421e-05, gnorm=1.602, clip=100, loss_scale=32, train_wall=17, gb_free=12.4, wall=826
2023-06-27 16:32:41 - progress_bar.py[line:272] - INFO: epoch 001:    482 / 990 loss=3.339, loss_v1=0, loss_v2=0, nll_loss=2.327, ntokens=1844.1, nsentences=56, sample_size=1844.1, sample_size_v1=0, sample_size_v2=0, ppl=5.02, wps=1054.3, ups=0.57, wpb=1844.1, bsz=56, num_updates=480, lr=1.51579e-05, gnorm=1.659, clip=100, loss_scale=32, train_wall=17, gb_free=11.5, wall=844
2023-06-27 16:32:58 - progress_bar.py[line:272] - INFO: epoch 001:    492 / 990 loss=3.282, loss_v1=0, loss_v2=0, nll_loss=2.26, ntokens=1857.1, nsentences=56, sample_size=1857.1, sample_size_v1=0, sample_size_v2=0, ppl=4.79, wps=1076.4, ups=0.58, wpb=1857.1, bsz=56, num_updates=490, lr=1.54737e-05, gnorm=1.583, clip=100, loss_scale=32, train_wall=17, gb_free=12.6, wall=861
2023-06-27 16:33:15 - progress_bar.py[line:272] - INFO: epoch 001:    502 / 990 loss=3.265, loss_v1=0, loss_v2=0, nll_loss=2.235, ntokens=1840.8, nsentences=56, sample_size=1840.8, sample_size_v1=0, sample_size_v2=0, ppl=4.71, wps=1078.6, ups=0.59, wpb=1840.8, bsz=56, num_updates=500, lr=1.57895e-05, gnorm=1.542, clip=100, loss_scale=32, train_wall=17, gb_free=12.7, wall=878
2023-06-27 16:33:32 - progress_bar.py[line:272] - INFO: epoch 001:    512 / 990 loss=3.253, loss_v1=0, loss_v2=0, nll_loss=2.221, ntokens=1741.1, nsentences=56, sample_size=1741.1, sample_size_v1=0, sample_size_v2=0, ppl=4.66, wps=1019.5, ups=0.59, wpb=1741.1, bsz=56, num_updates=510, lr=1.61053e-05, gnorm=1.782, clip=100, loss_scale=32, train_wall=17, gb_free=12.8, wall=895
2023-06-27 16:33:49 - progress_bar.py[line:272] - INFO: epoch 001:    522 / 990 loss=3.223, loss_v1=0, loss_v2=0, nll_loss=2.185, ntokens=1827, nsentences=56, sample_size=1827, sample_size_v1=0, sample_size_v2=0, ppl=4.55, wps=1071.9, ups=0.59, wpb=1827, bsz=56, num_updates=520, lr=1.64211e-05, gnorm=1.85, clip=100, loss_scale=32, train_wall=17, gb_free=11.9, wall=912
2023-06-27 16:34:06 - progress_bar.py[line:272] - INFO: epoch 001:    532 / 990 loss=3.149, loss_v1=0, loss_v2=0, nll_loss=2.101, ntokens=1880.3, nsentences=56, sample_size=1880.3, sample_size_v1=0, sample_size_v2=0, ppl=4.29, wps=1097.6, ups=0.58, wpb=1880.3, bsz=56, num_updates=530, lr=1.67368e-05, gnorm=1.65, clip=100, loss_scale=64, train_wall=17, gb_free=12.6, wall=929
2023-06-27 16:34:24 - progress_bar.py[line:272] - INFO: epoch 001:    542 / 990 loss=3.169, loss_v1=0, loss_v2=0, nll_loss=2.118, ntokens=1953.7, nsentences=56, sample_size=1953.7, sample_size_v1=0, sample_size_v2=0, ppl=4.34, wps=1138.9, ups=0.58, wpb=1953.7, bsz=56, num_updates=540, lr=1.70526e-05, gnorm=1.648, clip=100, loss_scale=64, train_wall=17, gb_free=12.7, wall=946
2023-06-27 16:34:41 - progress_bar.py[line:272] - INFO: epoch 001:    552 / 990 loss=3.128, loss_v1=0, loss_v2=0, nll_loss=2.07, ntokens=1879, nsentences=56, sample_size=1879, sample_size_v1=0, sample_size_v2=0, ppl=4.2, wps=1100.6, ups=0.59, wpb=1879, bsz=56, num_updates=550, lr=1.73684e-05, gnorm=1.984, clip=100, loss_scale=64, train_wall=17, gb_free=12.8, wall=963
2023-06-27 16:34:58 - progress_bar.py[line:272] - INFO: epoch 001:    562 / 990 loss=3.109, loss_v1=0, loss_v2=0, nll_loss=2.047, ntokens=1815, nsentences=56, sample_size=1815, sample_size_v1=0, sample_size_v2=0, ppl=4.13, wps=1062.2, ups=0.59, wpb=1815, bsz=56, num_updates=560, lr=1.76842e-05, gnorm=1.916, clip=100, loss_scale=64, train_wall=17, gb_free=12.9, wall=980
2023-06-27 16:35:15 - progress_bar.py[line:272] - INFO: epoch 001:    572 / 990 loss=3.077, loss_v1=0, loss_v2=0, nll_loss=2.01, ntokens=1798.2, nsentences=56, sample_size=1798.2, sample_size_v1=0, sample_size_v2=0, ppl=4.03, wps=1056.4, ups=0.59, wpb=1798.2, bsz=56, num_updates=570, lr=1.8e-05, gnorm=2.058, clip=100, loss_scale=64, train_wall=17, gb_free=12.8, wall=997
2023-06-27 16:35:32 - progress_bar.py[line:272] - INFO: epoch 001:    582 / 990 loss=3.1, loss_v1=0, loss_v2=0, nll_loss=2.036, ntokens=1836.1, nsentences=56, sample_size=1836.1, sample_size_v1=0, sample_size_v2=0, ppl=4.1, wps=1078.6, ups=0.59, wpb=1836.1, bsz=56, num_updates=580, lr=1.83158e-05, gnorm=1.797, clip=100, loss_scale=64, train_wall=17, gb_free=12.6, wall=1014
2023-06-27 16:35:49 - progress_bar.py[line:272] - INFO: epoch 001:    592 / 990 loss=3.069, loss_v1=0, loss_v2=0, nll_loss=2.001, ntokens=1962.3, nsentences=56, sample_size=1962.3, sample_size_v1=0, sample_size_v2=0, ppl=4, wps=1147.1, ups=0.58, wpb=1962.3, bsz=56, num_updates=590, lr=1.86316e-05, gnorm=1.764, clip=100, loss_scale=64, train_wall=17, gb_free=12.7, wall=1032
2023-06-27 16:36:06 - progress_bar.py[line:272] - INFO: epoch 001:    602 / 990 loss=3.037, loss_v1=0, loss_v2=0, nll_loss=1.964, ntokens=1729.9, nsentences=56, sample_size=1729.9, sample_size_v1=0, sample_size_v2=0, ppl=3.9, wps=1019.5, ups=0.59, wpb=1729.9, bsz=56, num_updates=600, lr=1.89474e-05, gnorm=1.828, clip=100, loss_scale=64, train_wall=17, gb_free=12.8, wall=1049
2023-06-27 16:36:23 - progress_bar.py[line:272] - INFO: epoch 001:    612 / 990 loss=2.991, loss_v1=0, loss_v2=0, nll_loss=1.907, ntokens=1851.1, nsentences=56, sample_size=1851.1, sample_size_v1=0, sample_size_v2=0, ppl=3.75, wps=1083.7, ups=0.59, wpb=1851.1, bsz=56, num_updates=610, lr=1.92632e-05, gnorm=2.053, clip=100, loss_scale=64, train_wall=17, gb_free=12.9, wall=1066
2023-06-27 16:36:40 - progress_bar.py[line:272] - INFO: epoch 001:    622 / 990 loss=3.002, loss_v1=0, loss_v2=0, nll_loss=1.918, ntokens=1907.4, nsentences=54.8, sample_size=1907.4, sample_size_v1=0, sample_size_v2=0, ppl=3.78, wps=1129.2, ups=0.59, wpb=1907.4, bsz=54.8, num_updates=620, lr=1.95789e-05, gnorm=1.835, clip=100, loss_scale=64, train_wall=17, gb_free=12.9, wall=1083
2023-06-27 16:36:57 - progress_bar.py[line:272] - INFO: epoch 001:    632 / 990 loss=3.002, loss_v1=0, loss_v2=0, nll_loss=1.919, ntokens=2018.5, nsentences=56, sample_size=2018.5, sample_size_v1=0, sample_size_v2=0, ppl=3.78, wps=1173, ups=0.58, wpb=2018.5, bsz=56, num_updates=630, lr=1.98947e-05, gnorm=1.766, clip=100, loss_scale=64, train_wall=17, gb_free=13, wall=1100
2023-06-27 16:37:14 - progress_bar.py[line:272] - INFO: epoch 001:    642 / 990 loss=2.966, loss_v1=0, loss_v2=0, nll_loss=1.878, ntokens=2016.5, nsentences=56, sample_size=2016.5, sample_size_v1=0, sample_size_v2=0, ppl=3.68, wps=1166.1, ups=0.58, wpb=2016.5, bsz=56, num_updates=640, lr=2.02105e-05, gnorm=1.744, clip=100, loss_scale=64, train_wall=17, gb_free=12.6, wall=1117
2023-06-27 16:37:32 - progress_bar.py[line:272] - INFO: epoch 001:    652 / 990 loss=2.936, loss_v1=0, loss_v2=0, nll_loss=1.842, ntokens=1953.9, nsentences=56, sample_size=1953.9, sample_size_v1=0, sample_size_v2=0, ppl=3.58, wps=1140.4, ups=0.58, wpb=1953.9, bsz=56, num_updates=650, lr=2.05263e-05, gnorm=1.66, clip=100, loss_scale=64, train_wall=17, gb_free=13, wall=1134
2023-06-27 16:37:49 - progress_bar.py[line:272] - INFO: epoch 001:    662 / 990 loss=2.945, loss_v1=0, loss_v2=0, nll_loss=1.851, ntokens=1859.6, nsentences=56, sample_size=1859.6, sample_size_v1=0, sample_size_v2=0, ppl=3.61, wps=1082.9, ups=0.58, wpb=1859.6, bsz=56, num_updates=660, lr=2.08421e-05, gnorm=1.712, clip=100, loss_scale=64, train_wall=17, gb_free=12.5, wall=1151
2023-06-27 16:38:06 - progress_bar.py[line:272] - INFO: epoch 001:    672 / 990 loss=2.913, loss_v1=0, loss_v2=0, nll_loss=1.813, ntokens=1822.7, nsentences=56, sample_size=1822.7, sample_size_v1=0, sample_size_v2=0, ppl=3.51, wps=1061.2, ups=0.58, wpb=1822.7, bsz=56, num_updates=670, lr=2.11579e-05, gnorm=1.925, clip=100, loss_scale=64, train_wall=17, gb_free=12.6, wall=1169
2023-06-27 16:38:23 - progress_bar.py[line:272] - INFO: epoch 001:    682 / 990 loss=2.861, loss_v1=0, loss_v2=0, nll_loss=1.754, ntokens=1905.1, nsentences=56, sample_size=1905.1, sample_size_v1=0, sample_size_v2=0, ppl=3.37, wps=1105.7, ups=0.58, wpb=1905.1, bsz=56, num_updates=680, lr=2.14737e-05, gnorm=1.916, clip=100, loss_scale=64, train_wall=17, gb_free=12.4, wall=1186
2023-06-27 16:38:40 - progress_bar.py[line:272] - INFO: epoch 001:    692 / 990 loss=2.878, loss_v1=0, loss_v2=0, nll_loss=1.772, ntokens=1786.7, nsentences=56, sample_size=1786.7, sample_size_v1=0, sample_size_v2=0, ppl=3.41, wps=1034.5, ups=0.58, wpb=1786.7, bsz=56, num_updates=690, lr=2.17895e-05, gnorm=2.052, clip=100, loss_scale=64, train_wall=17, gb_free=13.1, wall=1203
2023-06-27 16:38:57 - progress_bar.py[line:272] - INFO: epoch 001:    702 / 990 loss=2.868, loss_v1=0, loss_v2=0, nll_loss=1.76, ntokens=1687.9, nsentences=56, sample_size=1687.9, sample_size_v1=0, sample_size_v2=0, ppl=3.39, wps=987.9, ups=0.59, wpb=1687.9, bsz=56, num_updates=700, lr=2.21053e-05, gnorm=1.997, clip=100, loss_scale=64, train_wall=17, gb_free=12.8, wall=1220
2023-06-27 16:39:15 - progress_bar.py[line:272] - INFO: epoch 001:    712 / 990 loss=2.864, loss_v1=0, loss_v2=0, nll_loss=1.753, ntokens=1792.5, nsentences=56, sample_size=1792.5, sample_size_v1=0, sample_size_v2=0, ppl=3.37, wps=1052.6, ups=0.59, wpb=1792.5, bsz=56, num_updates=710, lr=2.24211e-05, gnorm=2.222, clip=100, loss_scale=64, train_wall=17, gb_free=12.4, wall=1237
2023-06-27 16:39:32 - progress_bar.py[line:272] - INFO: epoch 001:    722 / 990 loss=2.863, loss_v1=0, loss_v2=0, nll_loss=1.754, ntokens=1762.8, nsentences=56, sample_size=1762.8, sample_size_v1=0, sample_size_v2=0, ppl=3.37, wps=1037.2, ups=0.59, wpb=1762.8, bsz=56, num_updates=720, lr=2.27368e-05, gnorm=2.454, clip=100, loss_scale=64, train_wall=17, gb_free=12, wall=1254
2023-06-27 16:39:49 - progress_bar.py[line:272] - INFO: epoch 001:    732 / 990 loss=2.815, loss_v1=0, loss_v2=0, nll_loss=1.697, ntokens=1812.7, nsentences=56, sample_size=1812.7, sample_size_v1=0, sample_size_v2=0, ppl=3.24, wps=1061, ups=0.59, wpb=1812.7, bsz=56, num_updates=730, lr=2.30526e-05, gnorm=1.873, clip=100, loss_scale=64, train_wall=17, gb_free=12.6, wall=1271
2023-06-27 16:40:06 - progress_bar.py[line:272] - INFO: epoch 001:    742 / 990 loss=2.851, loss_v1=0, loss_v2=0, nll_loss=1.737, ntokens=1784.4, nsentences=56, sample_size=1784.4, sample_size_v1=0, sample_size_v2=0, ppl=3.33, wps=1047.3, ups=0.59, wpb=1784.4, bsz=56, num_updates=740, lr=2.33684e-05, gnorm=1.762, clip=100, loss_scale=64, train_wall=17, gb_free=12.5, wall=1288
2023-06-27 16:40:23 - progress_bar.py[line:272] - INFO: epoch 001:    752 / 990 loss=2.837, loss_v1=0, loss_v2=0, nll_loss=1.722, ntokens=1674.4, nsentences=56, sample_size=1674.4, sample_size_v1=0, sample_size_v2=0, ppl=3.3, wps=986.6, ups=0.59, wpb=1674.4, bsz=56, num_updates=750, lr=2.36842e-05, gnorm=1.869, clip=100, loss_scale=64, train_wall=17, gb_free=12.6, wall=1305
2023-06-27 16:40:40 - progress_bar.py[line:272] - INFO: epoch 001:    762 / 990 loss=2.836, loss_v1=0, loss_v2=0, nll_loss=1.719, ntokens=1734.2, nsentences=56, sample_size=1734.2, sample_size_v1=0, sample_size_v2=0, ppl=3.29, wps=1018.9, ups=0.59, wpb=1734.2, bsz=56, num_updates=760, lr=2.4e-05, gnorm=1.723, clip=100, loss_scale=64, train_wall=17, gb_free=12.6, wall=1322
2023-06-27 16:40:57 - progress_bar.py[line:272] - INFO: epoch 001:    772 / 990 loss=2.799, loss_v1=0, loss_v2=0, nll_loss=1.677, ntokens=1825.8, nsentences=56, sample_size=1825.8, sample_size_v1=0, sample_size_v2=0, ppl=3.2, wps=1069.7, ups=0.59, wpb=1825.8, bsz=56, num_updates=770, lr=2.43158e-05, gnorm=1.763, clip=100, loss_scale=64, train_wall=17, gb_free=12.9, wall=1339
2023-06-27 16:41:14 - progress_bar.py[line:272] - INFO: epoch 001:    782 / 990 loss=2.784, loss_v1=0, loss_v2=0, nll_loss=1.662, ntokens=1795.7, nsentences=56, sample_size=1795.7, sample_size_v1=0, sample_size_v2=0, ppl=3.16, wps=1052.1, ups=0.59, wpb=1795.7, bsz=56, num_updates=780, lr=2.46316e-05, gnorm=1.765, clip=100, loss_scale=64, train_wall=17, gb_free=12.9, wall=1356
2023-06-27 16:41:31 - progress_bar.py[line:272] - INFO: epoch 001:    792 / 990 loss=2.799, loss_v1=0, loss_v2=0, nll_loss=1.672, ntokens=1792.8, nsentences=56, sample_size=1792.8, sample_size_v1=0, sample_size_v2=0, ppl=3.19, wps=1052.3, ups=0.59, wpb=1792.8, bsz=56, num_updates=790, lr=2.49474e-05, gnorm=2.013, clip=100, loss_scale=64, train_wall=17, gb_free=12.5, wall=1373
2023-06-27 16:41:48 - progress_bar.py[line:272] - INFO: epoch 001:    802 / 990 loss=2.773, loss_v1=0, loss_v2=0, nll_loss=1.648, ntokens=1811.4, nsentences=56, sample_size=1811.4, sample_size_v1=0, sample_size_v2=0, ppl=3.13, wps=1058.9, ups=0.58, wpb=1811.4, bsz=56, num_updates=800, lr=2.52632e-05, gnorm=1.803, clip=100, loss_scale=64, train_wall=17, gb_free=13, wall=1391
2023-06-27 16:42:05 - progress_bar.py[line:272] - INFO: epoch 001:    812 / 990 loss=2.798, loss_v1=0, loss_v2=0, nll_loss=1.67, ntokens=1688.9, nsentences=56, sample_size=1688.9, sample_size_v1=0, sample_size_v2=0, ppl=3.18, wps=990.8, ups=0.59, wpb=1688.9, bsz=56, num_updates=810, lr=2.55789e-05, gnorm=2.359, clip=100, loss_scale=64, train_wall=17, gb_free=12.4, wall=1408
2023-06-27 16:42:22 - progress_bar.py[line:272] - INFO: epoch 001:    822 / 990 loss=2.773, loss_v1=0, loss_v2=0, nll_loss=1.647, ntokens=1691, nsentences=56, sample_size=1691, sample_size_v1=0, sample_size_v2=0, ppl=3.13, wps=988.8, ups=0.58, wpb=1691, bsz=56, num_updates=820, lr=2.58947e-05, gnorm=1.953, clip=100, loss_scale=64, train_wall=17, gb_free=13.1, wall=1425
2023-06-27 16:42:39 - progress_bar.py[line:272] - INFO: epoch 001:    832 / 990 loss=2.757, loss_v1=0, loss_v2=0, nll_loss=1.625, ntokens=1752.4, nsentences=56, sample_size=1752.4, sample_size_v1=0, sample_size_v2=0, ppl=3.08, wps=1032.6, ups=0.59, wpb=1752.4, bsz=56, num_updates=830, lr=2.62105e-05, gnorm=2.005, clip=100, loss_scale=64, train_wall=17, gb_free=12.8, wall=1442
2023-06-27 16:42:56 - progress_bar.py[line:272] - INFO: epoch 001:    842 / 990 loss=2.723, loss_v1=0, loss_v2=0, nll_loss=1.587, ntokens=1855, nsentences=56, sample_size=1855, sample_size_v1=0, sample_size_v2=0, ppl=3, wps=1087.4, ups=0.59, wpb=1855, bsz=56, num_updates=840, lr=2.65263e-05, gnorm=1.712, clip=100, loss_scale=64, train_wall=17, gb_free=12.3, wall=1459
2023-06-27 16:43:13 - progress_bar.py[line:272] - INFO: epoch 001:    852 / 990 loss=2.708, loss_v1=0, loss_v2=0, nll_loss=1.571, ntokens=1858.2, nsentences=56, sample_size=1858.2, sample_size_v1=0, sample_size_v2=0, ppl=2.97, wps=1083.3, ups=0.58, wpb=1858.2, bsz=56, num_updates=850, lr=2.68421e-05, gnorm=1.592, clip=100, loss_scale=64, train_wall=17, gb_free=12.4, wall=1476
2023-06-27 16:43:30 - progress_bar.py[line:272] - INFO: epoch 001:    862 / 990 loss=2.707, loss_v1=0, loss_v2=0, nll_loss=1.567, ntokens=1841.4, nsentences=56, sample_size=1841.4, sample_size_v1=0, sample_size_v2=0, ppl=2.96, wps=1074.6, ups=0.58, wpb=1841.4, bsz=56, num_updates=860, lr=2.71579e-05, gnorm=1.607, clip=100, loss_scale=64, train_wall=17, gb_free=12.7, wall=1493
2023-06-27 16:43:48 - progress_bar.py[line:272] - INFO: epoch 001:    872 / 990 loss=2.71, loss_v1=0, loss_v2=0, nll_loss=1.572, ntokens=1853.2, nsentences=56, sample_size=1853.2, sample_size_v1=0, sample_size_v2=0, ppl=2.97, wps=1082.8, ups=0.58, wpb=1853.2, bsz=56, num_updates=870, lr=2.74737e-05, gnorm=1.805, clip=100, loss_scale=64, train_wall=17, gb_free=13, wall=1510
2023-06-27 16:44:05 - progress_bar.py[line:272] - INFO: epoch 001:    882 / 990 loss=2.682, loss_v1=0, loss_v2=0, nll_loss=1.537, ntokens=1789.3, nsentences=56, sample_size=1789.3, sample_size_v1=0, sample_size_v2=0, ppl=2.9, wps=1053.7, ups=0.59, wpb=1789.3, bsz=56, num_updates=880, lr=2.77895e-05, gnorm=1.734, clip=100, loss_scale=64, train_wall=17, gb_free=12.6, wall=1527
2023-06-27 16:44:22 - progress_bar.py[line:272] - INFO: epoch 001:    892 / 990 loss=2.687, loss_v1=0, loss_v2=0, nll_loss=1.541, ntokens=2113.8, nsentences=56, sample_size=2113.8, sample_size_v1=0, sample_size_v2=0, ppl=2.91, wps=1228.2, ups=0.58, wpb=2113.8, bsz=56, num_updates=890, lr=2.81053e-05, gnorm=1.71, clip=100, loss_scale=64, train_wall=17, gb_free=12.1, wall=1544
2023-06-27 16:44:39 - progress_bar.py[line:272] - INFO: epoch 001:    902 / 990 loss=2.701, loss_v1=0, loss_v2=0, nll_loss=1.554, ntokens=1662.3, nsentences=56, sample_size=1662.3, sample_size_v1=0, sample_size_v2=0, ppl=2.94, wps=979.6, ups=0.59, wpb=1662.3, bsz=56, num_updates=900, lr=2.84211e-05, gnorm=1.763, clip=100, loss_scale=64, train_wall=17, gb_free=12.9, wall=1561
2023-06-27 16:44:56 - progress_bar.py[line:272] - INFO: epoch 001:    912 / 990 loss=2.697, loss_v1=0, loss_v2=0, nll_loss=1.555, ntokens=1835.4, nsentences=56, sample_size=1835.4, sample_size_v1=0, sample_size_v2=0, ppl=2.94, wps=1080.2, ups=0.59, wpb=1835.4, bsz=56, num_updates=910, lr=2.87368e-05, gnorm=1.805, clip=100, loss_scale=64, train_wall=17, gb_free=12.8, wall=1578
2023-06-27 16:45:13 - progress_bar.py[line:272] - INFO: epoch 001:    922 / 990 loss=2.681, loss_v1=0, loss_v2=0, nll_loss=1.538, ntokens=1696.9, nsentences=56, sample_size=1696.9, sample_size_v1=0, sample_size_v2=0, ppl=2.9, wps=993.7, ups=0.59, wpb=1696.9, bsz=56, num_updates=920, lr=2.90526e-05, gnorm=1.777, clip=100, loss_scale=64, train_wall=17, gb_free=12.4, wall=1595
2023-06-27 16:45:30 - progress_bar.py[line:272] - INFO: epoch 001:    932 / 990 loss=2.677, loss_v1=0, loss_v2=0, nll_loss=1.529, ntokens=1857.8, nsentences=56, sample_size=1857.8, sample_size_v1=0, sample_size_v2=0, ppl=2.89, wps=1083.5, ups=0.58, wpb=1857.8, bsz=56, num_updates=930, lr=2.93684e-05, gnorm=2.103, clip=100, loss_scale=64, train_wall=17, gb_free=13.1, wall=1613
2023-06-27 16:45:47 - progress_bar.py[line:272] - INFO: epoch 001:    942 / 990 loss=2.679, loss_v1=0, loss_v2=0, nll_loss=1.531, ntokens=1907.4, nsentences=56, sample_size=1907.4, sample_size_v1=0, sample_size_v2=0, ppl=2.89, wps=1111.2, ups=0.58, wpb=1907.4, bsz=56, num_updates=940, lr=2.96842e-05, gnorm=1.886, clip=100, loss_scale=64, train_wall=17, gb_free=12.2, wall=1630
2023-06-27 16:46:04 - progress_bar.py[line:272] - INFO: epoch 001:    952 / 990 loss=2.65, loss_v1=0, loss_v2=0, nll_loss=1.502, ntokens=1928.6, nsentences=56, sample_size=1928.6, sample_size_v1=0, sample_size_v2=0, ppl=2.83, wps=1124.6, ups=0.58, wpb=1928.6, bsz=56, num_updates=950, lr=3e-05, gnorm=1.63, clip=100, loss_scale=64, train_wall=17, gb_free=12.7, wall=1647
2023-06-27 16:46:21 - progress_bar.py[line:272] - INFO: epoch 001:    962 / 990 loss=2.637, loss_v1=0, loss_v2=0, nll_loss=1.481, ntokens=1862.4, nsentences=56, sample_size=1862.4, sample_size_v1=0, sample_size_v2=0, ppl=2.79, wps=1091.2, ups=0.59, wpb=1862.4, bsz=56, num_updates=960, lr=2.99799e-05, gnorm=1.486, clip=100, loss_scale=64, train_wall=17, gb_free=12.5, wall=1664
2023-06-27 16:46:39 - progress_bar.py[line:272] - INFO: epoch 001:    972 / 990 loss=2.655, loss_v1=0, loss_v2=0, nll_loss=1.506, ntokens=1919.1, nsentences=56, sample_size=1919.1, sample_size_v1=0, sample_size_v2=0, ppl=2.84, wps=1108.9, ups=0.58, wpb=1919.1, bsz=56, num_updates=970, lr=2.99597e-05, gnorm=1.484, clip=100, loss_scale=64, train_wall=17, gb_free=13, wall=1681
2023-06-27 16:46:56 - progress_bar.py[line:272] - INFO: epoch 001:    982 / 990 loss=2.651, loss_v1=0, loss_v2=0, nll_loss=1.494, ntokens=1779, nsentences=56, sample_size=1779, sample_size_v1=0, sample_size_v2=0, ppl=2.82, wps=1044.5, ups=0.59, wpb=1779, bsz=56, num_updates=980, lr=2.99396e-05, gnorm=1.6, clip=100, loss_scale=64, train_wall=17, gb_free=12.5, wall=1698
2023-06-27 16:47:08 - train.py[line:332] - INFO: end of epoch 1 (average epoch stats below)
local datafile ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 1 begin to initialize row_count and line_idx-to-offset mapping
2023-06-27 16:47:08 - progress_bar.py[line:282] - INFO: epoch 001 | loss 4.49 | loss_v1 0 | loss_v2 0 | nll_loss 3.631 | ntokens 1849.87 | nsentences 55.96 | sample_size 1849.87 | sample_size_v1 0 | sample_size_v2 0 | ppl 12.39 | wps 1076.4 | ups 0.58 | wpb 1849.9 | bsz 56 | num_updates 988 | lr 2.99234e-05 | gnorm 3.976 | clip 100 | loss_scale 64 | train_wall 1699 | gb_free 13.3 | wall 1711
2023-06-27 16:47:08 - trainer.py[line:639] - INFO: loading train data for epoch 2
local datafile ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 0 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 1 finished initializing row_count and line_idx-to-offset mapping
file ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 1 row count 27700 total row count 55400
local datafile ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 0 finished initializing row_count and line_idx-to-offset mapping
file ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 0 row count 27700 total row count 55400
/data/hulab/zcai75/anaconda3/envs/vilt/lib/python3.8/site-packages/torchvision/transforms/transforms.py:332: UserWarning: Argument 'interpolation' of type int is deprecated since 0.13 and will be removed in 0.15. Please use InterpolationMode enum.
  warnings.warn(
slice_id 1 seek offset 27700
slice_id 0 seek offset 0
2023-06-27 16:47:10 - trainer.py[line:703] - INFO: begin training epoch 2
2023-06-27 16:47:10 - train.py[line:305] - INFO: Start iterating over samples
2023-06-27 16:47:14 - progress_bar.py[line:272] - INFO: epoch 002:      2 / 990 loss=2.67, loss_v1=0, loss_v2=0, nll_loss=1.521, ntokens=1795.1, nsentences=53.2, sample_size=1795.1, sample_size_v1=0, sample_size_v2=0, ppl=2.87, wps=970, ups=0.54, wpb=1795.1, bsz=53.2, num_updates=990, lr=2.99194e-05, gnorm=1.667, clip=100, loss_scale=64, train_wall=16, gb_free=12.1, wall=1717
2023-06-27 16:47:31 - progress_bar.py[line:272] - INFO: epoch 002:     12 / 990 loss=2.581, loss_v1=0, loss_v2=0, nll_loss=1.419, ntokens=1878.7, nsentences=56, sample_size=1878.7, sample_size_v1=0, sample_size_v2=0, ppl=2.67, wps=1085.4, ups=0.58, wpb=1878.7, bsz=56, num_updates=1000, lr=2.98993e-05, gnorm=1.623, clip=100, loss_scale=64, train_wall=17, gb_free=12, wall=1734
2023-06-27 16:47:49 - progress_bar.py[line:272] - INFO: epoch 002:     22 / 990 loss=2.543, loss_v1=0, loss_v2=0, nll_loss=1.374, ntokens=1787.5, nsentences=56, sample_size=1787.5, sample_size_v1=0, sample_size_v2=0, ppl=2.59, wps=1037.4, ups=0.58, wpb=1787.5, bsz=56, num_updates=1010, lr=2.98791e-05, gnorm=1.665, clip=100, loss_scale=64, train_wall=17, gb_free=12.7, wall=1751
2023-06-27 16:48:06 - progress_bar.py[line:272] - INFO: epoch 002:     32 / 990 loss=2.608, loss_v1=0, loss_v2=0, nll_loss=1.449, ntokens=1723.3, nsentences=56, sample_size=1723.3, sample_size_v1=0, sample_size_v2=0, ppl=2.73, wps=990.2, ups=0.57, wpb=1723.3, bsz=56, num_updates=1020, lr=2.9859e-05, gnorm=1.825, clip=100, loss_scale=64, train_wall=17, gb_free=12.2, wall=1769
2023-06-27 16:48:23 - progress_bar.py[line:272] - INFO: epoch 002:     42 / 990 loss=2.479, loss_v1=0, loss_v2=0, nll_loss=1.304, ntokens=1984, nsentences=56, sample_size=1984, sample_size_v1=0, sample_size_v2=0, ppl=2.47, wps=1144.1, ups=0.58, wpb=1984, bsz=56, num_updates=1030, lr=2.98388e-05, gnorm=1.586, clip=100, loss_scale=64, train_wall=17, gb_free=11.4, wall=1786
2023-06-27 16:48:41 - progress_bar.py[line:272] - INFO: epoch 002:     52 / 990 loss=2.551, loss_v1=0, loss_v2=0, nll_loss=1.382, ntokens=1757.8, nsentences=56, sample_size=1757.8, sample_size_v1=0, sample_size_v2=0, ppl=2.61, wps=1022.4, ups=0.58, wpb=1757.8, bsz=56, num_updates=1040, lr=2.98187e-05, gnorm=1.682, clip=100, loss_scale=128, train_wall=17, gb_free=12.8, wall=1803
2023-06-27 16:48:58 - progress_bar.py[line:272] - INFO: epoch 002:     62 / 990 loss=2.525, loss_v1=0, loss_v2=0, nll_loss=1.354, ntokens=1799.6, nsentences=56, sample_size=1799.6, sample_size_v1=0, sample_size_v2=0, ppl=2.56, wps=1044.4, ups=0.58, wpb=1799.6, bsz=56, num_updates=1050, lr=2.97985e-05, gnorm=1.65, clip=100, loss_scale=128, train_wall=17, gb_free=12.4, wall=1821
2023-06-27 16:49:15 - progress_bar.py[line:272] - INFO: epoch 002:     72 / 990 loss=2.376, loss_v1=0, loss_v2=0, nll_loss=1.183, ntokens=2037.7, nsentences=56, sample_size=2037.7, sample_size_v1=0, sample_size_v2=0, ppl=2.27, wps=1166.7, ups=0.57, wpb=2037.7, bsz=56, num_updates=1060, lr=2.97784e-05, gnorm=1.749, clip=100, loss_scale=128, train_wall=17, gb_free=11.4, wall=1838
2023-06-27 16:49:33 - progress_bar.py[line:272] - INFO: epoch 002:     82 / 990 loss=2.49, loss_v1=0, loss_v2=0, nll_loss=1.315, ntokens=2177.1, nsentences=56, sample_size=2177.1, sample_size_v1=0, sample_size_v2=0, ppl=2.49, wps=1228, ups=0.56, wpb=2177.1, bsz=56, num_updates=1070, lr=2.97582e-05, gnorm=1.667, clip=100, loss_scale=128, train_wall=18, gb_free=11.6, wall=1856
2023-06-27 16:49:51 - progress_bar.py[line:272] - INFO: epoch 002:     92 / 990 loss=2.484, loss_v1=0, loss_v2=0, nll_loss=1.303, ntokens=2019.4, nsentences=56, sample_size=2019.4, sample_size_v1=0, sample_size_v2=0, ppl=2.47, wps=1146.5, ups=0.57, wpb=2019.4, bsz=56, num_updates=1080, lr=2.97381e-05, gnorm=1.696, clip=100, loss_scale=128, train_wall=18, gb_free=12.5, wall=1873
2023-06-27 16:50:08 - progress_bar.py[line:272] - INFO: epoch 002:    102 / 990 loss=2.523, loss_v1=0, loss_v2=0, nll_loss=1.352, ntokens=1873.6, nsentences=56, sample_size=1873.6, sample_size_v1=0, sample_size_v2=0, ppl=2.55, wps=1083.3, ups=0.58, wpb=1873.6, bsz=56, num_updates=1090, lr=2.97179e-05, gnorm=1.628, clip=100, loss_scale=128, train_wall=17, gb_free=11.9, wall=1891
2023-06-27 16:50:25 - progress_bar.py[line:272] - INFO: epoch 002:    112 / 990 loss=2.513, loss_v1=0, loss_v2=0, nll_loss=1.34, ntokens=1869, nsentences=56, sample_size=1869, sample_size_v1=0, sample_size_v2=0, ppl=2.53, wps=1087.2, ups=0.58, wpb=1869, bsz=56, num_updates=1100, lr=2.96978e-05, gnorm=1.811, clip=100, loss_scale=128, train_wall=17, gb_free=12.6, wall=1908
2023-06-27 16:50:42 - progress_bar.py[line:272] - INFO: epoch 002:    122 / 990 loss=2.617, loss_v1=0, loss_v2=0, nll_loss=1.455, ntokens=1761.5, nsentences=56, sample_size=1761.5, sample_size_v1=0, sample_size_v2=0, ppl=2.74, wps=1028.7, ups=0.58, wpb=1761.5, bsz=56, num_updates=1110, lr=2.96776e-05, gnorm=1.46, clip=100, loss_scale=128, train_wall=17, gb_free=11.8, wall=1925
2023-06-27 16:51:00 - progress_bar.py[line:272] - INFO: epoch 002:    132 / 990 loss=2.591, loss_v1=0, loss_v2=0, nll_loss=1.425, ntokens=1815.9, nsentences=56, sample_size=1815.9, sample_size_v1=0, sample_size_v2=0, ppl=2.69, wps=1054.7, ups=0.58, wpb=1815.9, bsz=56, num_updates=1120, lr=2.96575e-05, gnorm=1.314, clip=100, loss_scale=128, train_wall=17, gb_free=11.9, wall=1942
2023-06-27 16:51:17 - progress_bar.py[line:272] - INFO: epoch 002:    142 / 990 loss=2.57, loss_v1=0, loss_v2=0, nll_loss=1.404, ntokens=1956.5, nsentences=56, sample_size=1956.5, sample_size_v1=0, sample_size_v2=0, ppl=2.65, wps=1121, ups=0.57, wpb=1956.5, bsz=56, num_updates=1130, lr=2.96373e-05, gnorm=1.384, clip=100, loss_scale=128, train_wall=17, gb_free=12.3, wall=1960
2023-06-27 16:51:34 - progress_bar.py[line:272] - INFO: epoch 002:    152 / 990 loss=2.536, loss_v1=0, loss_v2=0, nll_loss=1.364, ntokens=1960.6, nsentences=56, sample_size=1960.6, sample_size_v1=0, sample_size_v2=0, ppl=2.57, wps=1122.9, ups=0.57, wpb=1960.6, bsz=56, num_updates=1140, lr=2.96172e-05, gnorm=1.742, clip=100, loss_scale=128, train_wall=17, gb_free=11.5, wall=1977
2023-06-27 16:51:52 - progress_bar.py[line:272] - INFO: epoch 002:    162 / 990 loss=2.515, loss_v1=0, loss_v2=0, nll_loss=1.34, ntokens=1989.5, nsentences=56, sample_size=1989.5, sample_size_v1=0, sample_size_v2=0, ppl=2.53, wps=1138.4, ups=0.57, wpb=1989.5, bsz=56, num_updates=1150, lr=2.9597e-05, gnorm=1.421, clip=100, loss_scale=128, train_wall=17, gb_free=12.2, wall=1995
2023-06-27 16:52:09 - progress_bar.py[line:272] - INFO: epoch 002:    172 / 990 loss=2.528, loss_v1=0, loss_v2=0, nll_loss=1.353, ntokens=1891.1, nsentences=56, sample_size=1891.1, sample_size_v1=0, sample_size_v2=0, ppl=2.55, wps=1087.1, ups=0.57, wpb=1891.1, bsz=56, num_updates=1160, lr=2.95769e-05, gnorm=1.46, clip=100, loss_scale=128, train_wall=17, gb_free=12.7, wall=2012
2023-06-27 16:52:27 - progress_bar.py[line:272] - INFO: epoch 002:    182 / 990 loss=2.528, loss_v1=0, loss_v2=0, nll_loss=1.358, ntokens=1964.6, nsentences=56, sample_size=1964.6, sample_size_v1=0, sample_size_v2=0, ppl=2.56, wps=1129.1, ups=0.57, wpb=1964.6, bsz=56, num_updates=1170, lr=2.95567e-05, gnorm=1.66, clip=100, loss_scale=128, train_wall=17, gb_free=12.9, wall=2029
2023-06-27 16:52:44 - progress_bar.py[line:272] - INFO: epoch 002:    192 / 990 loss=2.509, loss_v1=0, loss_v2=0, nll_loss=1.33, ntokens=1901, nsentences=56, sample_size=1901, sample_size_v1=0, sample_size_v2=0, ppl=2.51, wps=1100.1, ups=0.58, wpb=1901, bsz=56, num_updates=1180, lr=2.95366e-05, gnorm=1.462, clip=100, loss_scale=128, train_wall=17, gb_free=12.8, wall=2047
2023-06-27 16:53:01 - progress_bar.py[line:272] - INFO: epoch 002:    202 / 990 loss=2.52, loss_v1=0, loss_v2=0, nll_loss=1.344, ntokens=1816.8, nsentences=56, sample_size=1816.8, sample_size_v1=0, sample_size_v2=0, ppl=2.54, wps=1058.4, ups=0.58, wpb=1816.8, bsz=56, num_updates=1190, lr=2.95165e-05, gnorm=1.702, clip=100, loss_scale=128, train_wall=17, gb_free=11.8, wall=2064
2023-06-27 16:53:19 - progress_bar.py[line:272] - INFO: epoch 002:    212 / 990 loss=2.497, loss_v1=0, loss_v2=0, nll_loss=1.32, ntokens=1921.3, nsentences=56, sample_size=1921.3, sample_size_v1=0, sample_size_v2=0, ppl=2.5, wps=1104.9, ups=0.58, wpb=1921.3, bsz=56, num_updates=1200, lr=2.94963e-05, gnorm=1.563, clip=100, loss_scale=128, train_wall=17, gb_free=11.3, wall=2081
2023-06-27 16:53:36 - progress_bar.py[line:272] - INFO: epoch 002:    222 / 990 loss=2.513, loss_v1=0, loss_v2=0, nll_loss=1.338, ntokens=1933.9, nsentences=56, sample_size=1933.9, sample_size_v1=0, sample_size_v2=0, ppl=2.53, wps=1114.5, ups=0.58, wpb=1933.9, bsz=56, num_updates=1210, lr=2.94762e-05, gnorm=1.471, clip=100, loss_scale=128, train_wall=17, gb_free=12.7, wall=2099
2023-06-27 16:53:53 - progress_bar.py[line:272] - INFO: epoch 002:    232 / 990 loss=2.557, loss_v1=0, loss_v2=0, nll_loss=1.387, ntokens=1800, nsentences=56, sample_size=1800, sample_size_v1=0, sample_size_v2=0, ppl=2.61, wps=1046.2, ups=0.58, wpb=1800, bsz=56, num_updates=1220, lr=2.9456e-05, gnorm=1.554, clip=100, loss_scale=128, train_wall=17, gb_free=12.7, wall=2116
2023-06-27 16:54:10 - progress_bar.py[line:272] - INFO: epoch 002:    242 / 990 loss=2.594, loss_v1=0, loss_v2=0, nll_loss=1.429, ntokens=1776, nsentences=56, sample_size=1776, sample_size_v1=0, sample_size_v2=0, ppl=2.69, wps=1034.8, ups=0.58, wpb=1776, bsz=56, num_updates=1230, lr=2.94359e-05, gnorm=1.742, clip=100, loss_scale=128, train_wall=17, gb_free=12.6, wall=2133
2023-06-27 16:54:27 - progress_bar.py[line:272] - INFO: epoch 002:    252 / 990 loss=2.581, loss_v1=0, loss_v2=0, nll_loss=1.413, ntokens=1951.4, nsentences=56, sample_size=1951.4, sample_size_v1=0, sample_size_v2=0, ppl=2.66, wps=1138.5, ups=0.58, wpb=1951.4, bsz=56, num_updates=1240, lr=2.94157e-05, gnorm=1.383, clip=100, loss_scale=128, train_wall=17, gb_free=12.6, wall=2150
2023-06-27 16:54:45 - progress_bar.py[line:272] - INFO: epoch 002:    262 / 990 loss=2.59, loss_v1=0, loss_v2=0, nll_loss=1.421, ntokens=1898.3, nsentences=56, sample_size=1898.3, sample_size_v1=0, sample_size_v2=0, ppl=2.68, wps=1106.1, ups=0.58, wpb=1898.3, bsz=56, num_updates=1250, lr=2.93956e-05, gnorm=1.44, clip=100, loss_scale=128, train_wall=17, gb_free=12.9, wall=2167
2023-06-27 16:55:02 - progress_bar.py[line:272] - INFO: epoch 002:    272 / 990 loss=2.609, loss_v1=0, loss_v2=0, nll_loss=1.446, ntokens=1883.4, nsentences=56, sample_size=1883.4, sample_size_v1=0, sample_size_v2=0, ppl=2.73, wps=1089.9, ups=0.58, wpb=1883.4, bsz=56, num_updates=1260, lr=2.93754e-05, gnorm=1.276, clip=100, loss_scale=128, train_wall=17, gb_free=12.5, wall=2185
2023-06-27 16:55:19 - progress_bar.py[line:272] - INFO: epoch 002:    282 / 990 loss=2.587, loss_v1=0, loss_v2=0, nll_loss=1.421, ntokens=1918, nsentences=56, sample_size=1918, sample_size_v1=0, sample_size_v2=0, ppl=2.68, wps=1108.3, ups=0.58, wpb=1918, bsz=56, num_updates=1270, lr=2.93553e-05, gnorm=1.507, clip=100, loss_scale=128, train_wall=17, gb_free=12.1, wall=2202
2023-06-27 16:55:36 - progress_bar.py[line:272] - INFO: epoch 002:    292 / 990 loss=2.576, loss_v1=0, loss_v2=0, nll_loss=1.406, ntokens=1834.9, nsentences=56, sample_size=1834.9, sample_size_v1=0, sample_size_v2=0, ppl=2.65, wps=1072.1, ups=0.58, wpb=1834.9, bsz=56, num_updates=1280, lr=2.93351e-05, gnorm=1.416, clip=100, loss_scale=128, train_wall=17, gb_free=12.7, wall=2219
2023-06-27 16:55:54 - progress_bar.py[line:272] - INFO: epoch 002:    302 / 990 loss=2.585, loss_v1=0, loss_v2=0, nll_loss=1.419, ntokens=1925.9, nsentences=56, sample_size=1925.9, sample_size_v1=0, sample_size_v2=0, ppl=2.67, wps=1116.6, ups=0.58, wpb=1925.9, bsz=56, num_updates=1290, lr=2.9315e-05, gnorm=1.356, clip=100, loss_scale=128, train_wall=17, gb_free=11.9, wall=2236
2023-06-27 16:56:11 - progress_bar.py[line:272] - INFO: epoch 002:    312 / 990 loss=2.582, loss_v1=0, loss_v2=0, nll_loss=1.41, ntokens=1880, nsentences=56, sample_size=1880, sample_size_v1=0, sample_size_v2=0, ppl=2.66, wps=1092.6, ups=0.58, wpb=1880, bsz=56, num_updates=1300, lr=2.92948e-05, gnorm=1.441, clip=100, loss_scale=128, train_wall=17, gb_free=12.6, wall=2254
2023-06-27 16:56:28 - progress_bar.py[line:272] - INFO: epoch 002:    322 / 990 loss=2.579, loss_v1=0, loss_v2=0, nll_loss=1.414, ntokens=1910.2, nsentences=56, sample_size=1910.2, sample_size_v1=0, sample_size_v2=0, ppl=2.66, wps=1105.8, ups=0.58, wpb=1910.2, bsz=56, num_updates=1310, lr=2.92747e-05, gnorm=1.345, clip=100, loss_scale=128, train_wall=17, gb_free=11.8, wall=2271
2023-06-27 16:56:45 - progress_bar.py[line:272] - INFO: epoch 002:    332 / 990 loss=2.548, loss_v1=0, loss_v2=0, nll_loss=1.373, ntokens=1876.3, nsentences=56, sample_size=1876.3, sample_size_v1=0, sample_size_v2=0, ppl=2.59, wps=1092.6, ups=0.58, wpb=1876.3, bsz=56, num_updates=1320, lr=2.92545e-05, gnorm=1.248, clip=100, loss_scale=128, train_wall=17, gb_free=12.9, wall=2288
2023-06-27 16:57:03 - progress_bar.py[line:272] - INFO: epoch 002:    342 / 990 loss=2.562, loss_v1=0, loss_v2=0, nll_loss=1.391, ntokens=1898.9, nsentences=56, sample_size=1898.9, sample_size_v1=0, sample_size_v2=0, ppl=2.62, wps=1102.5, ups=0.58, wpb=1898.9, bsz=56, num_updates=1330, lr=2.92344e-05, gnorm=1.374, clip=100, loss_scale=128, train_wall=17, gb_free=12.3, wall=2305
2023-06-27 16:57:20 - progress_bar.py[line:272] - INFO: epoch 002:    352 / 990 loss=2.558, loss_v1=0, loss_v2=0, nll_loss=1.386, ntokens=1879.4, nsentences=56, sample_size=1879.4, sample_size_v1=0, sample_size_v2=0, ppl=2.61, wps=1095.5, ups=0.58, wpb=1879.4, bsz=56, num_updates=1340, lr=2.92142e-05, gnorm=1.356, clip=100, loss_scale=128, train_wall=17, gb_free=12.6, wall=2322
2023-06-27 16:57:37 - progress_bar.py[line:272] - INFO: epoch 002:    362 / 990 loss=2.569, loss_v1=0, loss_v2=0, nll_loss=1.398, ntokens=1783.9, nsentences=56, sample_size=1783.9, sample_size_v1=0, sample_size_v2=0, ppl=2.64, wps=1044.1, ups=0.59, wpb=1783.9, bsz=56, num_updates=1350, lr=2.91941e-05, gnorm=1.442, clip=100, loss_scale=128, train_wall=17, gb_free=12.7, wall=2339
2023-06-27 16:57:54 - progress_bar.py[line:272] - INFO: epoch 002:    372 / 990 loss=2.58, loss_v1=0, loss_v2=0, nll_loss=1.411, ntokens=1756.1, nsentences=56, sample_size=1756.1, sample_size_v1=0, sample_size_v2=0, ppl=2.66, wps=1029.6, ups=0.59, wpb=1756.1, bsz=56, num_updates=1360, lr=2.91739e-05, gnorm=1.571, clip=100, loss_scale=128, train_wall=17, gb_free=12.6, wall=2356
2023-06-27 16:58:11 - progress_bar.py[line:272] - INFO: epoch 002:    382 / 990 loss=2.537, loss_v1=0, loss_v2=0, nll_loss=1.363, ntokens=1868.9, nsentences=56, sample_size=1868.9, sample_size_v1=0, sample_size_v2=0, ppl=2.57, wps=1092.2, ups=0.58, wpb=1868.9, bsz=56, num_updates=1370, lr=2.91538e-05, gnorm=1.266, clip=100, loss_scale=128, train_wall=17, gb_free=12.6, wall=2374
2023-06-27 16:58:28 - progress_bar.py[line:272] - INFO: epoch 002:    392 / 990 loss=2.52, loss_v1=0, loss_v2=0, nll_loss=1.342, ntokens=1758.6, nsentences=56, sample_size=1758.6, sample_size_v1=0, sample_size_v2=0, ppl=2.54, wps=1030.5, ups=0.59, wpb=1758.6, bsz=56, num_updates=1380, lr=2.91336e-05, gnorm=1.347, clip=100, loss_scale=128, train_wall=17, gb_free=12.9, wall=2391
2023-06-27 16:58:45 - progress_bar.py[line:272] - INFO: epoch 002:    402 / 990 loss=2.567, loss_v1=0, loss_v2=0, nll_loss=1.393, ntokens=1733.9, nsentences=56, sample_size=1733.9, sample_size_v1=0, sample_size_v2=0, ppl=2.63, wps=1018.2, ups=0.59, wpb=1733.9, bsz=56, num_updates=1390, lr=2.91135e-05, gnorm=1.376, clip=100, loss_scale=128, train_wall=17, gb_free=12.8, wall=2408
2023-06-27 16:59:02 - progress_bar.py[line:272] - INFO: epoch 002:    412 / 990 loss=2.564, loss_v1=0, loss_v2=0, nll_loss=1.394, ntokens=1702.7, nsentences=56, sample_size=1702.7, sample_size_v1=0, sample_size_v2=0, ppl=2.63, wps=1001.6, ups=0.59, wpb=1702.7, bsz=56, num_updates=1400, lr=2.90934e-05, gnorm=1.376, clip=100, loss_scale=128, train_wall=17, gb_free=12.6, wall=2425
2023-06-27 16:59:19 - progress_bar.py[line:272] - INFO: epoch 002:    422 / 990 loss=2.554, loss_v1=0, loss_v2=0, nll_loss=1.379, ntokens=1751.8, nsentences=56, sample_size=1751.8, sample_size_v1=0, sample_size_v2=0, ppl=2.6, wps=1028.7, ups=0.59, wpb=1751.8, bsz=56, num_updates=1410, lr=2.90732e-05, gnorm=1.327, clip=100, loss_scale=128, train_wall=17, gb_free=12.7, wall=2442
2023-06-27 16:59:36 - progress_bar.py[line:272] - INFO: epoch 002:    432 / 990 loss=2.536, loss_v1=0, loss_v2=0, nll_loss=1.361, ntokens=1888.6, nsentences=56, sample_size=1888.6, sample_size_v1=0, sample_size_v2=0, ppl=2.57, wps=1102.1, ups=0.58, wpb=1888.6, bsz=56, num_updates=1420, lr=2.90531e-05, gnorm=1.207, clip=100, loss_scale=128, train_wall=17, gb_free=12.9, wall=2459
2023-06-27 16:59:53 - progress_bar.py[line:272] - INFO: epoch 002:    442 / 990 loss=2.533, loss_v1=0, loss_v2=0, nll_loss=1.357, ntokens=1918.5, nsentences=56, sample_size=1918.5, sample_size_v1=0, sample_size_v2=0, ppl=2.56, wps=1120.9, ups=0.58, wpb=1918.5, bsz=56, num_updates=1430, lr=2.90329e-05, gnorm=1.249, clip=100, loss_scale=128, train_wall=17, gb_free=12.7, wall=2476
2023-06-27 17:00:10 - progress_bar.py[line:272] - INFO: epoch 002:    452 / 990 loss=2.536, loss_v1=0, loss_v2=0, nll_loss=1.361, ntokens=1723.6, nsentences=56, sample_size=1723.6, sample_size_v1=0, sample_size_v2=0, ppl=2.57, wps=1016.4, ups=0.59, wpb=1723.6, bsz=56, num_updates=1440, lr=2.90128e-05, gnorm=1.369, clip=100, loss_scale=128, train_wall=17, gb_free=12.3, wall=2493
2023-06-27 17:00:27 - progress_bar.py[line:272] - INFO: epoch 002:    462 / 990 loss=2.528, loss_v1=0, loss_v2=0, nll_loss=1.351, ntokens=1871.7, nsentences=56, sample_size=1871.7, sample_size_v1=0, sample_size_v2=0, ppl=2.55, wps=1089.9, ups=0.58, wpb=1871.7, bsz=56, num_updates=1450, lr=2.89926e-05, gnorm=1.391, clip=100, loss_scale=128, train_wall=17, gb_free=12.5, wall=2510
2023-06-27 17:00:45 - progress_bar.py[line:272] - INFO: epoch 002:    472 / 990 loss=2.535, loss_v1=0, loss_v2=0, nll_loss=1.359, ntokens=1880.6, nsentences=56, sample_size=1880.6, sample_size_v1=0, sample_size_v2=0, ppl=2.56, wps=1095.2, ups=0.58, wpb=1880.6, bsz=56, num_updates=1460, lr=2.89725e-05, gnorm=1.322, clip=100, loss_scale=128, train_wall=17, gb_free=12.4, wall=2527
2023-06-27 17:01:02 - progress_bar.py[line:272] - INFO: epoch 002:    482 / 990 loss=2.528, loss_v1=0, loss_v2=0, nll_loss=1.35, ntokens=1844.1, nsentences=56, sample_size=1844.1, sample_size_v1=0, sample_size_v2=0, ppl=2.55, wps=1073.3, ups=0.58, wpb=1844.1, bsz=56, num_updates=1470, lr=2.89523e-05, gnorm=1.378, clip=100, loss_scale=128, train_wall=17, gb_free=11.5, wall=2544
2023-06-27 17:01:19 - progress_bar.py[line:272] - INFO: epoch 002:    492 / 990 loss=2.526, loss_v1=0, loss_v2=0, nll_loss=1.349, ntokens=1857.1, nsentences=56, sample_size=1857.1, sample_size_v1=0, sample_size_v2=0, ppl=2.55, wps=1082.5, ups=0.58, wpb=1857.1, bsz=56, num_updates=1480, lr=2.89322e-05, gnorm=1.331, clip=100, loss_scale=128, train_wall=17, gb_free=12.6, wall=2562
2023-06-27 17:01:36 - progress_bar.py[line:272] - INFO: epoch 002:    502 / 990 loss=2.551, loss_v1=0, loss_v2=0, nll_loss=1.377, ntokens=1840.8, nsentences=56, sample_size=1840.8, sample_size_v1=0, sample_size_v2=0, ppl=2.6, wps=1077.8, ups=0.59, wpb=1840.8, bsz=56, num_updates=1490, lr=2.8912e-05, gnorm=1.342, clip=100, loss_scale=128, train_wall=17, gb_free=12.7, wall=2579
2023-06-27 17:01:53 - progress_bar.py[line:272] - INFO: epoch 002:    512 / 990 loss=2.551, loss_v1=0, loss_v2=0, nll_loss=1.373, ntokens=1741.1, nsentences=56, sample_size=1741.1, sample_size_v1=0, sample_size_v2=0, ppl=2.59, wps=1018.4, ups=0.58, wpb=1741.1, bsz=56, num_updates=1500, lr=2.88919e-05, gnorm=1.364, clip=100, loss_scale=128, train_wall=17, gb_free=12.8, wall=2596
2023-06-27 17:02:10 - progress_bar.py[line:272] - INFO: epoch 002:    522 / 990 loss=2.523, loss_v1=0, loss_v2=0, nll_loss=1.347, ntokens=1827, nsentences=56, sample_size=1827, sample_size_v1=0, sample_size_v2=0, ppl=2.54, wps=1068.9, ups=0.59, wpb=1827, bsz=56, num_updates=1510, lr=2.88717e-05, gnorm=1.531, clip=100, loss_scale=128, train_wall=17, gb_free=11.9, wall=2613
2023-06-27 17:02:27 - progress_bar.py[line:272] - INFO: epoch 002:    532 / 990 loss=2.514, loss_v1=0, loss_v2=0, nll_loss=1.336, ntokens=1880.3, nsentences=56, sample_size=1880.3, sample_size_v1=0, sample_size_v2=0, ppl=2.52, wps=1094, ups=0.58, wpb=1880.3, bsz=56, num_updates=1520, lr=2.88516e-05, gnorm=1.362, clip=100, loss_scale=128, train_wall=17, gb_free=12.6, wall=2630
2023-06-27 17:02:45 - progress_bar.py[line:272] - INFO: epoch 002:    542 / 990 loss=2.531, loss_v1=0, loss_v2=0, nll_loss=1.352, ntokens=1953.7, nsentences=56, sample_size=1953.7, sample_size_v1=0, sample_size_v2=0, ppl=2.55, wps=1138.8, ups=0.58, wpb=1953.7, bsz=56, num_updates=1530, lr=2.88314e-05, gnorm=1.383, clip=100, loss_scale=128, train_wall=17, gb_free=12.7, wall=2647
2023-06-27 17:03:01 - progress_bar.py[line:272] - INFO: epoch 002:    552 / 990 loss=2.513, loss_v1=0, loss_v2=0, nll_loss=1.335, ntokens=1841.3, nsentences=54.8, sample_size=1841.3, sample_size_v1=0, sample_size_v2=0, ppl=2.52, wps=1092.2, ups=0.59, wpb=1841.3, bsz=54.8, num_updates=1540, lr=2.88113e-05, gnorm=1.267, clip=100, loss_scale=128, train_wall=17, gb_free=13.2, wall=2664
2023-06-27 17:03:19 - progress_bar.py[line:272] - INFO: epoch 002:    562 / 990 loss=2.512, loss_v1=0, loss_v2=0, nll_loss=1.332, ntokens=1828.2, nsentences=56, sample_size=1828.2, sample_size_v1=0, sample_size_v2=0, ppl=2.52, wps=1068.1, ups=0.58, wpb=1828.2, bsz=56, num_updates=1550, lr=2.87911e-05, gnorm=1.28, clip=100, loss_scale=256, train_wall=17, gb_free=12.9, wall=2681
2023-06-27 17:03:36 - progress_bar.py[line:272] - INFO: epoch 002:    572 / 990 loss=2.512, loss_v1=0, loss_v2=0, nll_loss=1.332, ntokens=1775.2, nsentences=56, sample_size=1775.2, sample_size_v1=0, sample_size_v2=0, ppl=2.52, wps=1043.3, ups=0.59, wpb=1775.2, bsz=56, num_updates=1560, lr=2.8771e-05, gnorm=1.467, clip=100, loss_scale=256, train_wall=17, gb_free=12.8, wall=2698
2023-06-27 17:03:53 - progress_bar.py[line:272] - INFO: epoch 002:    582 / 990 loss=2.538, loss_v1=0, loss_v2=0, nll_loss=1.361, ntokens=1848, nsentences=56, sample_size=1848, sample_size_v1=0, sample_size_v2=0, ppl=2.57, wps=1082.3, ups=0.59, wpb=1848, bsz=56, num_updates=1570, lr=2.87508e-05, gnorm=1.461, clip=100, loss_scale=256, train_wall=17, gb_free=12.9, wall=2715
2023-06-27 17:04:10 - progress_bar.py[line:272] - INFO: epoch 002:    592 / 990 loss=2.53, loss_v1=0, loss_v2=0, nll_loss=1.352, ntokens=1956.3, nsentences=56, sample_size=1956.3, sample_size_v1=0, sample_size_v2=0, ppl=2.55, wps=1142.7, ups=0.58, wpb=1956.3, bsz=56, num_updates=1580, lr=2.87307e-05, gnorm=1.237, clip=100, loss_scale=256, train_wall=17, gb_free=12.7, wall=2732
2023-06-27 17:04:27 - progress_bar.py[line:272] - INFO: epoch 002:    602 / 990 loss=2.516, loss_v1=0, loss_v2=0, nll_loss=1.338, ntokens=1739.6, nsentences=56, sample_size=1739.6, sample_size_v1=0, sample_size_v2=0, ppl=2.53, wps=1013.7, ups=0.58, wpb=1739.6, bsz=56, num_updates=1590, lr=2.87105e-05, gnorm=1.486, clip=100, loss_scale=256, train_wall=17, gb_free=12.9, wall=2750
2023-06-27 17:04:44 - progress_bar.py[line:272] - INFO: epoch 002:    612 / 990 loss=2.5, loss_v1=0, loss_v2=0, nll_loss=1.317, ntokens=1842.3, nsentences=56, sample_size=1842.3, sample_size_v1=0, sample_size_v2=0, ppl=2.49, wps=1082.5, ups=0.59, wpb=1842.3, bsz=56, num_updates=1600, lr=2.86904e-05, gnorm=1.406, clip=100, loss_scale=256, train_wall=17, gb_free=12.9, wall=2767
2023-06-27 17:05:01 - progress_bar.py[line:272] - INFO: epoch 002:    622 / 990 loss=2.531, loss_v1=0, loss_v2=0, nll_loss=1.35, ntokens=1948.1, nsentences=56, sample_size=1948.1, sample_size_v1=0, sample_size_v2=0, ppl=2.55, wps=1140.1, ups=0.59, wpb=1948.1, bsz=56, num_updates=1610, lr=2.86702e-05, gnorm=1.242, clip=100, loss_scale=256, train_wall=17, gb_free=12.9, wall=2784
2023-06-27 17:05:18 - progress_bar.py[line:272] - INFO: epoch 002:    632 / 990 loss=2.535, loss_v1=0, loss_v2=0, nll_loss=1.361, ntokens=2018.5, nsentences=56, sample_size=2018.5, sample_size_v1=0, sample_size_v2=0, ppl=2.57, wps=1174.1, ups=0.58, wpb=2018.5, bsz=56, num_updates=1620, lr=2.86501e-05, gnorm=1.298, clip=100, loss_scale=256, train_wall=17, gb_free=13, wall=2801
2023-06-27 17:05:36 - progress_bar.py[line:272] - INFO: epoch 002:    642 / 990 loss=2.515, loss_v1=0, loss_v2=0, nll_loss=1.334, ntokens=2016.5, nsentences=56, sample_size=2016.5, sample_size_v1=0, sample_size_v2=0, ppl=2.52, wps=1168.1, ups=0.58, wpb=2016.5, bsz=56, num_updates=1630, lr=2.863e-05, gnorm=1.392, clip=100, loss_scale=256, train_wall=17, gb_free=12.6, wall=2818
2023-06-27 17:05:53 - progress_bar.py[line:272] - INFO: epoch 002:    652 / 990 loss=2.511, loss_v1=0, loss_v2=0, nll_loss=1.331, ntokens=1953.9, nsentences=56, sample_size=1953.9, sample_size_v1=0, sample_size_v2=0, ppl=2.52, wps=1140.2, ups=0.58, wpb=1953.9, bsz=56, num_updates=1640, lr=2.86098e-05, gnorm=1.31, clip=100, loss_scale=256, train_wall=17, gb_free=13, wall=2835
2023-06-27 17:06:10 - progress_bar.py[line:272] - INFO: epoch 002:    662 / 990 loss=2.525, loss_v1=0, loss_v2=0, nll_loss=1.346, ntokens=1859.6, nsentences=56, sample_size=1859.6, sample_size_v1=0, sample_size_v2=0, ppl=2.54, wps=1081.7, ups=0.58, wpb=1859.6, bsz=56, num_updates=1650, lr=2.85897e-05, gnorm=1.387, clip=100, loss_scale=256, train_wall=17, gb_free=12.5, wall=2853
2023-06-27 17:06:27 - progress_bar.py[line:272] - INFO: epoch 002:    672 / 990 loss=2.52, loss_v1=0, loss_v2=0, nll_loss=1.338, ntokens=1822.7, nsentences=56, sample_size=1822.7, sample_size_v1=0, sample_size_v2=0, ppl=2.53, wps=1063.8, ups=0.58, wpb=1822.7, bsz=56, num_updates=1660, lr=2.85695e-05, gnorm=1.345, clip=100, loss_scale=256, train_wall=17, gb_free=12.6, wall=2870
2023-06-27 17:06:44 - progress_bar.py[line:272] - INFO: epoch 002:    682 / 990 loss=2.475, loss_v1=0, loss_v2=0, nll_loss=1.29, ntokens=1905.1, nsentences=56, sample_size=1905.1, sample_size_v1=0, sample_size_v2=0, ppl=2.45, wps=1106.2, ups=0.58, wpb=1905.1, bsz=56, num_updates=1670, lr=2.85494e-05, gnorm=1.216, clip=100, loss_scale=256, train_wall=17, gb_free=12.4, wall=2887
2023-06-27 17:07:01 - progress_bar.py[line:272] - INFO: epoch 002:    692 / 990 loss=2.494, loss_v1=0, loss_v2=0, nll_loss=1.315, ntokens=1786.7, nsentences=56, sample_size=1786.7, sample_size_v1=0, sample_size_v2=0, ppl=2.49, wps=1046.5, ups=0.59, wpb=1786.7, bsz=56, num_updates=1680, lr=2.85292e-05, gnorm=1.473, clip=100, loss_scale=256, train_wall=17, gb_free=13.1, wall=2904
2023-06-27 17:07:18 - progress_bar.py[line:272] - INFO: epoch 002:    702 / 990 loss=2.518, loss_v1=0, loss_v2=0, nll_loss=1.334, ntokens=1687.9, nsentences=56, sample_size=1687.9, sample_size_v1=0, sample_size_v2=0, ppl=2.52, wps=990.3, ups=0.59, wpb=1687.9, bsz=56, num_updates=1690, lr=2.85091e-05, gnorm=1.398, clip=100, loss_scale=256, train_wall=17, gb_free=12.8, wall=2921
2023-06-27 17:07:35 - progress_bar.py[line:272] - INFO: epoch 002:    712 / 990 loss=2.508, loss_v1=0, loss_v2=0, nll_loss=1.328, ntokens=1792.5, nsentences=56, sample_size=1792.5, sample_size_v1=0, sample_size_v2=0, ppl=2.51, wps=1054.8, ups=0.59, wpb=1792.5, bsz=56, num_updates=1700, lr=2.84889e-05, gnorm=1.266, clip=100, loss_scale=256, train_wall=17, gb_free=12.4, wall=2938
2023-06-27 17:07:52 - progress_bar.py[line:272] - INFO: epoch 002:    722 / 990 loss=2.495, loss_v1=0, loss_v2=0, nll_loss=1.313, ntokens=1762.8, nsentences=56, sample_size=1762.8, sample_size_v1=0, sample_size_v2=0, ppl=2.49, wps=1040.5, ups=0.59, wpb=1762.8, bsz=56, num_updates=1710, lr=2.84688e-05, gnorm=1.443, clip=100, loss_scale=256, train_wall=17, gb_free=12, wall=2955
2023-06-27 17:08:09 - progress_bar.py[line:272] - INFO: epoch 002:    732 / 990 loss=2.467, loss_v1=0, loss_v2=0, nll_loss=1.28, ntokens=1812.7, nsentences=56, sample_size=1812.7, sample_size_v1=0, sample_size_v2=0, ppl=2.43, wps=1061.9, ups=0.59, wpb=1812.7, bsz=56, num_updates=1720, lr=2.84486e-05, gnorm=1.44, clip=100, loss_scale=256, train_wall=17, gb_free=12.6, wall=2972
2023-06-27 17:08:26 - progress_bar.py[line:272] - INFO: epoch 002:    742 / 990 loss=2.517, loss_v1=0, loss_v2=0, nll_loss=1.338, ntokens=1784.4, nsentences=56, sample_size=1784.4, sample_size_v1=0, sample_size_v2=0, ppl=2.53, wps=1046.9, ups=0.59, wpb=1784.4, bsz=56, num_updates=1730, lr=2.84285e-05, gnorm=1.412, clip=100, loss_scale=256, train_wall=17, gb_free=12.5, wall=2989
2023-06-27 17:08:43 - progress_bar.py[line:272] - INFO: epoch 002:    752 / 990 loss=2.528, loss_v1=0, loss_v2=0, nll_loss=1.346, ntokens=1674.4, nsentences=56, sample_size=1674.4, sample_size_v1=0, sample_size_v2=0, ppl=2.54, wps=984.2, ups=0.59, wpb=1674.4, bsz=56, num_updates=1740, lr=2.84083e-05, gnorm=1.358, clip=100, loss_scale=256, train_wall=17, gb_free=12.6, wall=3006
2023-06-27 17:09:01 - progress_bar.py[line:272] - INFO: epoch 002:    762 / 990 loss=2.514, loss_v1=0, loss_v2=0, nll_loss=1.337, ntokens=1734.2, nsentences=56, sample_size=1734.2, sample_size_v1=0, sample_size_v2=0, ppl=2.53, wps=1017.1, ups=0.59, wpb=1734.2, bsz=56, num_updates=1750, lr=2.83882e-05, gnorm=1.403, clip=100, loss_scale=256, train_wall=17, gb_free=12.6, wall=3023
2023-06-27 17:09:18 - progress_bar.py[line:272] - INFO: epoch 002:    772 / 990 loss=2.497, loss_v1=0, loss_v2=0, nll_loss=1.312, ntokens=1825.8, nsentences=56, sample_size=1825.8, sample_size_v1=0, sample_size_v2=0, ppl=2.48, wps=1066.7, ups=0.58, wpb=1825.8, bsz=56, num_updates=1760, lr=2.8368e-05, gnorm=1.409, clip=100, loss_scale=256, train_wall=17, gb_free=12.9, wall=3040
2023-06-27 17:09:35 - progress_bar.py[line:272] - INFO: epoch 002:    782 / 990 loss=2.489, loss_v1=0, loss_v2=0, nll_loss=1.307, ntokens=1795.7, nsentences=56, sample_size=1795.7, sample_size_v1=0, sample_size_v2=0, ppl=2.48, wps=1053.4, ups=0.59, wpb=1795.7, bsz=56, num_updates=1770, lr=2.83479e-05, gnorm=1.389, clip=100, loss_scale=256, train_wall=17, gb_free=12.9, wall=3057
2023-06-27 17:09:52 - progress_bar.py[line:272] - INFO: epoch 002:    792 / 990 loss=2.504, loss_v1=0, loss_v2=0, nll_loss=1.32, ntokens=1792.8, nsentences=56, sample_size=1792.8, sample_size_v1=0, sample_size_v2=0, ppl=2.5, wps=1051.9, ups=0.59, wpb=1792.8, bsz=56, num_updates=1780, lr=2.83277e-05, gnorm=1.307, clip=100, loss_scale=256, train_wall=17, gb_free=12.5, wall=3074
2023-06-27 17:10:09 - progress_bar.py[line:272] - INFO: epoch 002:    802 / 990 loss=2.51, loss_v1=0, loss_v2=0, nll_loss=1.329, ntokens=1811.4, nsentences=56, sample_size=1811.4, sample_size_v1=0, sample_size_v2=0, ppl=2.51, wps=1060.4, ups=0.59, wpb=1811.4, bsz=56, num_updates=1790, lr=2.83076e-05, gnorm=1.291, clip=100, loss_scale=256, train_wall=17, gb_free=13, wall=3091
2023-06-27 17:10:26 - progress_bar.py[line:272] - INFO: epoch 002:    812 / 990 loss=2.528, loss_v1=0, loss_v2=0, nll_loss=1.348, ntokens=1688.9, nsentences=56, sample_size=1688.9, sample_size_v1=0, sample_size_v2=0, ppl=2.55, wps=993.6, ups=0.59, wpb=1688.9, bsz=56, num_updates=1800, lr=2.82874e-05, gnorm=1.472, clip=100, loss_scale=256, train_wall=17, gb_free=12.4, wall=3108
2023-06-27 17:10:43 - progress_bar.py[line:272] - INFO: epoch 002:    822 / 990 loss=2.499, loss_v1=0, loss_v2=0, nll_loss=1.318, ntokens=1691, nsentences=56, sample_size=1691, sample_size_v1=0, sample_size_v2=0, ppl=2.49, wps=992.4, ups=0.59, wpb=1691, bsz=56, num_updates=1810, lr=2.82673e-05, gnorm=1.377, clip=100, loss_scale=256, train_wall=17, gb_free=13.1, wall=3126
2023-06-27 17:11:00 - progress_bar.py[line:272] - INFO: epoch 002:    832 / 990 loss=2.481, loss_v1=0, loss_v2=0, nll_loss=1.296, ntokens=1752.4, nsentences=56, sample_size=1752.4, sample_size_v1=0, sample_size_v2=0, ppl=2.46, wps=1031.9, ups=0.59, wpb=1752.4, bsz=56, num_updates=1820, lr=2.82471e-05, gnorm=1.443, clip=100, loss_scale=256, train_wall=17, gb_free=12.8, wall=3143
2023-06-27 17:11:17 - progress_bar.py[line:272] - INFO: epoch 002:    842 / 990 loss=2.471, loss_v1=0, loss_v2=0, nll_loss=1.284, ntokens=1855, nsentences=56, sample_size=1855, sample_size_v1=0, sample_size_v2=0, ppl=2.43, wps=1085.8, ups=0.59, wpb=1855, bsz=56, num_updates=1830, lr=2.8227e-05, gnorm=1.243, clip=100, loss_scale=256, train_wall=17, gb_free=12.3, wall=3160
2023-06-27 17:11:34 - progress_bar.py[line:272] - INFO: epoch 002:    852 / 990 loss=2.461, loss_v1=0, loss_v2=0, nll_loss=1.273, ntokens=1858.2, nsentences=56, sample_size=1858.2, sample_size_v1=0, sample_size_v2=0, ppl=2.42, wps=1082.6, ups=0.58, wpb=1858.2, bsz=56, num_updates=1840, lr=2.82069e-05, gnorm=1.22, clip=100, loss_scale=256, train_wall=17, gb_free=12.4, wall=3177
2023-06-27 17:11:51 - progress_bar.py[line:272] - INFO: epoch 002:    862 / 990 loss=2.468, loss_v1=0, loss_v2=0, nll_loss=1.283, ntokens=1841.4, nsentences=56, sample_size=1841.4, sample_size_v1=0, sample_size_v2=0, ppl=2.43, wps=1074.2, ups=0.58, wpb=1841.4, bsz=56, num_updates=1850, lr=2.81867e-05, gnorm=1.317, clip=100, loss_scale=256, train_wall=17, gb_free=12.7, wall=3194
2023-06-27 17:12:08 - progress_bar.py[line:272] - INFO: epoch 002:    872 / 990 loss=2.486, loss_v1=0, loss_v2=0, nll_loss=1.303, ntokens=1853.2, nsentences=56, sample_size=1853.2, sample_size_v1=0, sample_size_v2=0, ppl=2.47, wps=1084, ups=0.58, wpb=1853.2, bsz=56, num_updates=1860, lr=2.81666e-05, gnorm=1.463, clip=100, loss_scale=256, train_wall=17, gb_free=13, wall=3211
2023-06-27 17:12:25 - progress_bar.py[line:272] - INFO: epoch 002:    882 / 990 loss=2.463, loss_v1=0, loss_v2=0, nll_loss=1.271, ntokens=1789.3, nsentences=56, sample_size=1789.3, sample_size_v1=0, sample_size_v2=0, ppl=2.41, wps=1053.8, ups=0.59, wpb=1789.3, bsz=56, num_updates=1870, lr=2.81464e-05, gnorm=1.423, clip=100, loss_scale=256, train_wall=17, gb_free=12.6, wall=3228
2023-06-27 17:12:43 - progress_bar.py[line:272] - INFO: epoch 002:    892 / 990 loss=2.46, loss_v1=0, loss_v2=0, nll_loss=1.275, ntokens=2113.8, nsentences=56, sample_size=2113.8, sample_size_v1=0, sample_size_v2=0, ppl=2.42, wps=1227, ups=0.58, wpb=2113.8, bsz=56, num_updates=1880, lr=2.81263e-05, gnorm=1.27, clip=100, loss_scale=256, train_wall=17, gb_free=12.1, wall=3245
2023-06-27 17:13:00 - progress_bar.py[line:272] - INFO: epoch 002:    902 / 990 loss=2.497, loss_v1=0, loss_v2=0, nll_loss=1.309, ntokens=1662.3, nsentences=56, sample_size=1662.3, sample_size_v1=0, sample_size_v2=0, ppl=2.48, wps=978.8, ups=0.59, wpb=1662.3, bsz=56, num_updates=1890, lr=2.81061e-05, gnorm=1.304, clip=100, loss_scale=256, train_wall=17, gb_free=12.9, wall=3262
2023-06-27 17:13:17 - progress_bar.py[line:272] - INFO: epoch 002:    912 / 990 loss=2.491, loss_v1=0, loss_v2=0, nll_loss=1.308, ntokens=1835.4, nsentences=56, sample_size=1835.4, sample_size_v1=0, sample_size_v2=0, ppl=2.48, wps=1079.1, ups=0.59, wpb=1835.4, bsz=56, num_updates=1900, lr=2.8086e-05, gnorm=1.327, clip=100, loss_scale=256, train_wall=17, gb_free=12.8, wall=3279
2023-06-27 17:13:34 - progress_bar.py[line:272] - INFO: epoch 002:    922 / 990 loss=2.467, loss_v1=0, loss_v2=0, nll_loss=1.281, ntokens=1696.9, nsentences=56, sample_size=1696.9, sample_size_v1=0, sample_size_v2=0, ppl=2.43, wps=997.5, ups=0.59, wpb=1696.9, bsz=56, num_updates=1910, lr=2.80658e-05, gnorm=1.353, clip=100, loss_scale=256, train_wall=17, gb_free=12.4, wall=3296
2023-06-27 17:13:51 - progress_bar.py[line:272] - INFO: epoch 002:    932 / 990 loss=2.464, loss_v1=0, loss_v2=0, nll_loss=1.277, ntokens=1857.8, nsentences=56, sample_size=1857.8, sample_size_v1=0, sample_size_v2=0, ppl=2.42, wps=1084.9, ups=0.58, wpb=1857.8, bsz=56, num_updates=1920, lr=2.80457e-05, gnorm=1.435, clip=100, loss_scale=256, train_wall=17, gb_free=13.1, wall=3313
2023-06-27 17:14:08 - progress_bar.py[line:272] - INFO: epoch 002:    942 / 990 loss=2.48, loss_v1=0, loss_v2=0, nll_loss=1.295, ntokens=1907.4, nsentences=56, sample_size=1907.4, sample_size_v1=0, sample_size_v2=0, ppl=2.45, wps=1111.4, ups=0.58, wpb=1907.4, bsz=56, num_updates=1930, lr=2.80255e-05, gnorm=1.442, clip=100, loss_scale=256, train_wall=17, gb_free=12.2, wall=3331
2023-06-27 17:14:25 - progress_bar.py[line:272] - INFO: epoch 002:    952 / 990 loss=2.46, loss_v1=0, loss_v2=0, nll_loss=1.273, ntokens=1928.6, nsentences=56, sample_size=1928.6, sample_size_v1=0, sample_size_v2=0, ppl=2.42, wps=1122.8, ups=0.58, wpb=1928.6, bsz=56, num_updates=1940, lr=2.80054e-05, gnorm=1.372, clip=100, loss_scale=256, train_wall=17, gb_free=12.7, wall=3348
2023-06-27 17:14:42 - progress_bar.py[line:272] - INFO: epoch 002:    962 / 990 loss=2.461, loss_v1=0, loss_v2=0, nll_loss=1.271, ntokens=1862.4, nsentences=56, sample_size=1862.4, sample_size_v1=0, sample_size_v2=0, ppl=2.41, wps=1088.9, ups=0.58, wpb=1862.4, bsz=56, num_updates=1950, lr=2.79852e-05, gnorm=1.329, clip=100, loss_scale=256, train_wall=17, gb_free=12.5, wall=3365
2023-06-27 17:14:59 - progress_bar.py[line:272] - INFO: epoch 002:    972 / 990 loss=2.463, loss_v1=0, loss_v2=0, nll_loss=1.276, ntokens=1919.1, nsentences=56, sample_size=1919.1, sample_size_v1=0, sample_size_v2=0, ppl=2.42, wps=1115.3, ups=0.58, wpb=1919.1, bsz=56, num_updates=1960, lr=2.79651e-05, gnorm=1.242, clip=100, loss_scale=256, train_wall=17, gb_free=13, wall=3382
2023-06-27 17:15:16 - progress_bar.py[line:272] - INFO: epoch 002:    982 / 990 loss=2.472, loss_v1=0, loss_v2=0, nll_loss=1.285, ntokens=1779, nsentences=56, sample_size=1779, sample_size_v1=0, sample_size_v2=0, ppl=2.44, wps=1043.3, ups=0.59, wpb=1779, bsz=56, num_updates=1970, lr=2.79449e-05, gnorm=1.367, clip=100, loss_scale=256, train_wall=17, gb_free=12.5, wall=3399
local datafile ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 1 begin to initialize row_count and line_idx-to-offset mapping
2023-06-27 17:15:29 - train.py[line:332] - INFO: end of epoch 2 (average epoch stats below)
2023-06-27 17:15:29 - progress_bar.py[line:282] - INFO: epoch 002 | loss 2.523 | loss_v1 0 | loss_v2 0 | nll_loss 1.345 | ntokens 1849.9 | nsentences 55.96 | sample_size 1849.9 | sample_size_v1 0 | sample_size_v2 0 | ppl 2.54 | wps 1076.8 | ups 0.58 | wpb 1849.9 | bsz 56 | num_updates 1978 | lr 2.79288e-05 | gnorm 1.422 | clip 100 | loss_scale 256 | train_wall 1695 | gb_free 13.3 | wall 3412
2023-06-27 17:15:29 - trainer.py[line:639] - INFO: loading train data for epoch 3
local datafile ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 0 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 1 finished initializing row_count and line_idx-to-offset mapping
file ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 1 row count 27700 total row count 55400
slice_id 1 seek offset 27700
local datafile ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 0 finished initializing row_count and line_idx-to-offset mapping
file ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 0 row count 27700 total row count 55400
slice_id 0 seek offset 0
2023-06-27 17:15:31 - trainer.py[line:703] - INFO: begin training epoch 3
2023-06-27 17:15:31 - train.py[line:305] - INFO: Start iterating over samples
2023-06-27 17:15:35 - progress_bar.py[line:272] - INFO: epoch 003:      2 / 990 loss=2.499, loss_v1=0, loss_v2=0, nll_loss=1.315, ntokens=1795.1, nsentences=53.2, sample_size=1795.1, sample_size_v1=0, sample_size_v2=0, ppl=2.49, wps=955.6, ups=0.53, wpb=1795.1, bsz=53.2, num_updates=1980, lr=2.79248e-05, gnorm=1.396, clip=100, loss_scale=256, train_wall=16, gb_free=12.1, wall=3418
2023-06-27 17:15:53 - progress_bar.py[line:272] - INFO: epoch 003:     12 / 990 loss=2.405, loss_v1=0, loss_v2=0, nll_loss=1.209, ntokens=1878.7, nsentences=56, sample_size=1878.7, sample_size_v1=0, sample_size_v2=0, ppl=2.31, wps=1085.2, ups=0.58, wpb=1878.7, bsz=56, num_updates=1990, lr=2.79046e-05, gnorm=1.366, clip=100, loss_scale=256, train_wall=17, gb_free=12, wall=3435
2023-06-27 17:16:10 - progress_bar.py[line:272] - INFO: epoch 003:     22 / 990 loss=2.375, loss_v1=0, loss_v2=0, nll_loss=1.178, ntokens=1787.5, nsentences=56, sample_size=1787.5, sample_size_v1=0, sample_size_v2=0, ppl=2.26, wps=1037.6, ups=0.58, wpb=1787.5, bsz=56, num_updates=2000, lr=2.78845e-05, gnorm=1.421, clip=100, loss_scale=256, train_wall=17, gb_free=12.7, wall=3452
2023-06-27 17:16:27 - progress_bar.py[line:272] - INFO: epoch 003:     32 / 990 loss=2.444, loss_v1=0, loss_v2=0, nll_loss=1.25, ntokens=1723.3, nsentences=56, sample_size=1723.3, sample_size_v1=0, sample_size_v2=0, ppl=2.38, wps=1014.6, ups=0.59, wpb=1723.3, bsz=56, num_updates=2010, lr=2.78643e-05, gnorm=1.471, clip=100, loss_scale=256, train_wall=17, gb_free=12.2, wall=3469
2023-06-27 17:16:44 - progress_bar.py[line:272] - INFO: epoch 003:     42 / 990 loss=2.323, loss_v1=0, loss_v2=0, nll_loss=1.12, ntokens=1984, nsentences=56, sample_size=1984, sample_size_v1=0, sample_size_v2=0, ppl=2.17, wps=1142.5, ups=0.58, wpb=1984, bsz=56, num_updates=2020, lr=2.78442e-05, gnorm=1.249, clip=100, loss_scale=256, train_wall=17, gb_free=11.4, wall=3487
2023-06-27 17:17:02 - progress_bar.py[line:272] - INFO: epoch 003:     52 / 990 loss=2.396, loss_v1=0, loss_v2=0, nll_loss=1.197, ntokens=1757.8, nsentences=56, sample_size=1757.8, sample_size_v1=0, sample_size_v2=0, ppl=2.29, wps=1009.3, ups=0.57, wpb=1757.8, bsz=56, num_updates=2030, lr=2.7824e-05, gnorm=1.564, clip=100, loss_scale=256, train_wall=17, gb_free=12.8, wall=3504
2023-06-27 17:17:19 - progress_bar.py[line:272] - INFO: epoch 003:     62 / 990 loss=2.372, loss_v1=0, loss_v2=0, nll_loss=1.175, ntokens=1799.6, nsentences=56, sample_size=1799.6, sample_size_v1=0, sample_size_v2=0, ppl=2.26, wps=1046.3, ups=0.58, wpb=1799.6, bsz=56, num_updates=2040, lr=2.78039e-05, gnorm=1.605, clip=100, loss_scale=256, train_wall=17, gb_free=12.4, wall=3521
2023-06-27 17:17:36 - progress_bar.py[line:272] - INFO: epoch 003:     72 / 990 loss=2.243, loss_v1=0, loss_v2=0, nll_loss=1.028, ntokens=2037.7, nsentences=56, sample_size=2037.7, sample_size_v1=0, sample_size_v2=0, ppl=2.04, wps=1170.4, ups=0.57, wpb=2037.7, bsz=56, num_updates=2050, lr=2.77837e-05, gnorm=1.309, clip=100, loss_scale=256, train_wall=17, gb_free=11.5, wall=3539
2023-06-27 17:17:54 - progress_bar.py[line:272] - INFO: epoch 003:     82 / 990 loss=2.329, loss_v1=0, loss_v2=0, nll_loss=1.122, ntokens=2177.1, nsentences=56, sample_size=2177.1, sample_size_v1=0, sample_size_v2=0, ppl=2.18, wps=1232, ups=0.57, wpb=2177.1, bsz=56, num_updates=2060, lr=2.77636e-05, gnorm=1.186, clip=90, loss_scale=256, train_wall=18, gb_free=11.6, wall=3557
2023-06-27 17:18:11 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 256.0
2023-06-27 17:18:13 - progress_bar.py[line:272] - INFO: epoch 003:     93 / 990 loss=2.328, loss_v1=0, loss_v2=0, nll_loss=1.126, ntokens=2024.7, nsentences=56, sample_size=2024.7, sample_size_v1=0, sample_size_v2=0, ppl=2.18, wps=1052.9, ups=0.52, wpb=2024.7, bsz=56, num_updates=2070, lr=2.77435e-05, gnorm=1.406, clip=100, loss_scale=256, train_wall=19, gb_free=12.5, wall=3576
2023-06-27 17:18:30 - progress_bar.py[line:272] - INFO: epoch 003:    103 / 990 loss=2.378, loss_v1=0, loss_v2=0, nll_loss=1.177, ntokens=1881.8, nsentences=56, sample_size=1881.8, sample_size_v1=0, sample_size_v2=0, ppl=2.26, wps=1088.5, ups=0.58, wpb=1881.8, bsz=56, num_updates=2080, lr=2.77233e-05, gnorm=1.489, clip=100, loss_scale=256, train_wall=17, gb_free=12.7, wall=3593
2023-06-27 17:18:48 - progress_bar.py[line:272] - INFO: epoch 003:    113 / 990 loss=2.382, loss_v1=0, loss_v2=0, nll_loss=1.184, ntokens=1850.1, nsentences=56, sample_size=1850.1, sample_size_v1=0, sample_size_v2=0, ppl=2.27, wps=1077.7, ups=0.58, wpb=1850.1, bsz=56, num_updates=2090, lr=2.77032e-05, gnorm=1.818, clip=100, loss_scale=256, train_wall=17, gb_free=12.8, wall=3610
2023-06-27 17:19:05 - progress_bar.py[line:272] - INFO: epoch 003:    123 / 990 loss=2.465, loss_v1=0, loss_v2=0, nll_loss=1.278, ntokens=1767.5, nsentences=56, sample_size=1767.5, sample_size_v1=0, sample_size_v2=0, ppl=2.43, wps=1032.1, ups=0.58, wpb=1767.5, bsz=56, num_updates=2100, lr=2.7683e-05, gnorm=1.659, clip=100, loss_scale=256, train_wall=17, gb_free=12.7, wall=3627
2023-06-27 17:19:22 - progress_bar.py[line:272] - INFO: epoch 003:    133 / 990 loss=2.457, loss_v1=0, loss_v2=0, nll_loss=1.266, ntokens=1835.5, nsentences=56, sample_size=1835.5, sample_size_v1=0, sample_size_v2=0, ppl=2.4, wps=1061.2, ups=0.58, wpb=1835.5, bsz=56, num_updates=2110, lr=2.76629e-05, gnorm=1.399, clip=100, loss_scale=256, train_wall=17, gb_free=12, wall=3645
2023-06-27 17:19:39 - progress_bar.py[line:272] - INFO: epoch 003:    143 / 990 loss=2.422, loss_v1=0, loss_v2=0, nll_loss=1.229, ntokens=1950, nsentences=56, sample_size=1950, sample_size_v1=0, sample_size_v2=0, ppl=2.34, wps=1115.5, ups=0.57, wpb=1950, bsz=56, num_updates=2120, lr=2.76427e-05, gnorm=1.349, clip=100, loss_scale=256, train_wall=17, gb_free=11.2, wall=3662
2023-06-27 17:19:57 - progress_bar.py[line:272] - INFO: epoch 003:    153 / 990 loss=2.411, loss_v1=0, loss_v2=0, nll_loss=1.214, ntokens=1940.2, nsentences=56, sample_size=1940.2, sample_size_v1=0, sample_size_v2=0, ppl=2.32, wps=1115.4, ups=0.57, wpb=1940.2, bsz=56, num_updates=2130, lr=2.76226e-05, gnorm=1.416, clip=100, loss_scale=256, train_wall=17, gb_free=12.5, wall=3680
2023-06-27 17:20:14 - progress_bar.py[line:272] - INFO: epoch 003:    163 / 990 loss=2.396, loss_v1=0, loss_v2=0, nll_loss=1.202, ntokens=2005.3, nsentences=56, sample_size=2005.3, sample_size_v1=0, sample_size_v2=0, ppl=2.3, wps=1148.5, ups=0.57, wpb=2005.3, bsz=56, num_updates=2140, lr=2.76024e-05, gnorm=1.325, clip=100, loss_scale=256, train_wall=17, gb_free=12.3, wall=3697
2023-06-27 17:20:32 - progress_bar.py[line:272] - INFO: epoch 003:    173 / 990 loss=2.392, loss_v1=0, loss_v2=0, nll_loss=1.196, ntokens=1937.6, nsentences=56, sample_size=1937.6, sample_size_v1=0, sample_size_v2=0, ppl=2.29, wps=1111.2, ups=0.57, wpb=1937.6, bsz=56, num_updates=2150, lr=2.75823e-05, gnorm=1.349, clip=100, loss_scale=256, train_wall=17, gb_free=11.2, wall=3714
2023-06-27 17:20:49 - progress_bar.py[line:272] - INFO: epoch 003:    183 / 990 loss=2.413, loss_v1=0, loss_v2=0, nll_loss=1.22, ntokens=1929.9, nsentences=56, sample_size=1929.9, sample_size_v1=0, sample_size_v2=0, ppl=2.33, wps=1110.3, ups=0.58, wpb=1929.9, bsz=56, num_updates=2160, lr=2.75621e-05, gnorm=1.382, clip=100, loss_scale=256, train_wall=17, gb_free=12.3, wall=3732
2023-06-27 17:21:06 - progress_bar.py[line:272] - INFO: epoch 003:    193 / 990 loss=2.393, loss_v1=0, loss_v2=0, nll_loss=1.194, ntokens=1852.1, nsentences=56, sample_size=1852.1, sample_size_v1=0, sample_size_v2=0, ppl=2.29, wps=1075.8, ups=0.58, wpb=1852.1, bsz=56, num_updates=2170, lr=2.7542e-05, gnorm=1.315, clip=100, loss_scale=256, train_wall=17, gb_free=13.2, wall=3749
2023-06-27 17:21:24 - progress_bar.py[line:272] - INFO: epoch 003:    203 / 990 loss=2.392, loss_v1=0, loss_v2=0, nll_loss=1.194, ntokens=1850.5, nsentences=56, sample_size=1850.5, sample_size_v1=0, sample_size_v2=0, ppl=2.29, wps=1070.1, ups=0.58, wpb=1850.5, bsz=56, num_updates=2180, lr=2.75218e-05, gnorm=1.344, clip=100, loss_scale=256, train_wall=17, gb_free=12.3, wall=3766
2023-06-27 17:21:41 - progress_bar.py[line:272] - INFO: epoch 003:    213 / 990 loss=2.383, loss_v1=0, loss_v2=0, nll_loss=1.185, ntokens=1937.7, nsentences=56, sample_size=1937.7, sample_size_v1=0, sample_size_v2=0, ppl=2.27, wps=1109.5, ups=0.57, wpb=1937.7, bsz=56, num_updates=2190, lr=2.75017e-05, gnorm=1.566, clip=100, loss_scale=256, train_wall=17, gb_free=12.1, wall=3784
2023-06-27 17:21:58 - progress_bar.py[line:272] - INFO: epoch 003:    223 / 990 loss=2.407, loss_v1=0, loss_v2=0, nll_loss=1.213, ntokens=1910.3, nsentences=56, sample_size=1910.3, sample_size_v1=0, sample_size_v2=0, ppl=2.32, wps=1099.5, ups=0.58, wpb=1910.3, bsz=56, num_updates=2200, lr=2.74815e-05, gnorm=1.556, clip=100, loss_scale=256, train_wall=17, gb_free=12.2, wall=3801
2023-06-27 17:22:16 - progress_bar.py[line:272] - INFO: epoch 003:    233 / 990 loss=2.442, loss_v1=0, loss_v2=0, nll_loss=1.249, ntokens=1771.8, nsentences=56, sample_size=1771.8, sample_size_v1=0, sample_size_v2=0, ppl=2.38, wps=1033.1, ups=0.58, wpb=1771.8, bsz=56, num_updates=2210, lr=2.74614e-05, gnorm=1.492, clip=100, loss_scale=256, train_wall=17, gb_free=13, wall=3818
2023-06-27 17:22:33 - progress_bar.py[line:272] - INFO: epoch 003:    243 / 990 loss=2.471, loss_v1=0, loss_v2=0, nll_loss=1.285, ntokens=1826.4, nsentences=56, sample_size=1826.4, sample_size_v1=0, sample_size_v2=0, ppl=2.44, wps=1060.6, ups=0.58, wpb=1826.4, bsz=56, num_updates=2220, lr=2.74412e-05, gnorm=1.36, clip=100, loss_scale=256, train_wall=17, gb_free=12.2, wall=3836
2023-06-27 17:22:50 - progress_bar.py[line:272] - INFO: epoch 003:    253 / 990 loss=2.466, loss_v1=0, loss_v2=0, nll_loss=1.276, ntokens=1939.5, nsentences=56, sample_size=1939.5, sample_size_v1=0, sample_size_v2=0, ppl=2.42, wps=1126.5, ups=0.58, wpb=1939.5, bsz=56, num_updates=2230, lr=2.74211e-05, gnorm=1.274, clip=100, loss_scale=256, train_wall=17, gb_free=12, wall=3853
2023-06-27 17:23:07 - progress_bar.py[line:272] - INFO: epoch 003:    263 / 990 loss=2.476, loss_v1=0, loss_v2=0, nll_loss=1.291, ntokens=1883.4, nsentences=56, sample_size=1883.4, sample_size_v1=0, sample_size_v2=0, ppl=2.45, wps=1096.1, ups=0.58, wpb=1883.4, bsz=56, num_updates=2240, lr=2.74009e-05, gnorm=1.259, clip=100, loss_scale=256, train_wall=17, gb_free=12.5, wall=3870
2023-06-27 17:23:25 - progress_bar.py[line:272] - INFO: epoch 003:    273 / 990 loss=2.484, loss_v1=0, loss_v2=0, nll_loss=1.299, ntokens=1901.2, nsentences=56, sample_size=1901.2, sample_size_v1=0, sample_size_v2=0, ppl=2.46, wps=1101.2, ups=0.58, wpb=1901.2, bsz=56, num_updates=2250, lr=2.73808e-05, gnorm=1.272, clip=100, loss_scale=256, train_wall=17, gb_free=12.5, wall=3887
2023-06-27 17:23:42 - progress_bar.py[line:272] - INFO: epoch 003:    283 / 990 loss=2.472, loss_v1=0, loss_v2=0, nll_loss=1.285, ntokens=1912.9, nsentences=56, sample_size=1912.9, sample_size_v1=0, sample_size_v2=0, ppl=2.44, wps=1103.3, ups=0.58, wpb=1912.9, bsz=56, num_updates=2260, lr=2.73606e-05, gnorm=1.267, clip=100, loss_scale=256, train_wall=17, gb_free=12.1, wall=3905
2023-06-27 17:23:59 - progress_bar.py[line:272] - INFO: epoch 003:    293 / 990 loss=2.478, loss_v1=0, loss_v2=0, nll_loss=1.293, ntokens=1832.5, nsentences=56, sample_size=1832.5, sample_size_v1=0, sample_size_v2=0, ppl=2.45, wps=1072.6, ups=0.59, wpb=1832.5, bsz=56, num_updates=2270, lr=2.73405e-05, gnorm=1.422, clip=100, loss_scale=256, train_wall=17, gb_free=12.6, wall=3922
2023-06-27 17:24:16 - progress_bar.py[line:272] - INFO: epoch 003:    303 / 990 loss=2.482, loss_v1=0, loss_v2=0, nll_loss=1.295, ntokens=1906.4, nsentences=56, sample_size=1906.4, sample_size_v1=0, sample_size_v2=0, ppl=2.45, wps=1104.9, ups=0.58, wpb=1906.4, bsz=56, num_updates=2280, lr=2.73203e-05, gnorm=1.399, clip=100, loss_scale=256, train_wall=17, gb_free=12.8, wall=3939
2023-06-27 17:24:33 - progress_bar.py[line:272] - INFO: epoch 003:    313 / 990 loss=2.477, loss_v1=0, loss_v2=0, nll_loss=1.291, ntokens=1902.5, nsentences=56, sample_size=1902.5, sample_size_v1=0, sample_size_v2=0, ppl=2.45, wps=1103.7, ups=0.58, wpb=1902.5, bsz=56, num_updates=2290, lr=2.73002e-05, gnorm=1.513, clip=100, loss_scale=256, train_wall=17, gb_free=10.8, wall=3956
2023-06-27 17:24:51 - progress_bar.py[line:272] - INFO: epoch 003:    323 / 990 loss=2.488, loss_v1=0, loss_v2=0, nll_loss=1.303, ntokens=1903.2, nsentences=56, sample_size=1903.2, sample_size_v1=0, sample_size_v2=0, ppl=2.47, wps=1101.9, ups=0.58, wpb=1903.2, bsz=56, num_updates=2300, lr=2.72801e-05, gnorm=1.444, clip=100, loss_scale=256, train_wall=17, gb_free=12.4, wall=3973
2023-06-27 17:25:08 - progress_bar.py[line:272] - INFO: epoch 003:    333 / 990 loss=2.442, loss_v1=0, loss_v2=0, nll_loss=1.25, ntokens=1876.3, nsentences=56, sample_size=1876.3, sample_size_v1=0, sample_size_v2=0, ppl=2.38, wps=1092.7, ups=0.58, wpb=1876.3, bsz=56, num_updates=2310, lr=2.72599e-05, gnorm=1.273, clip=100, loss_scale=256, train_wall=17, gb_free=11.7, wall=3991
2023-06-27 17:25:25 - progress_bar.py[line:272] - INFO: epoch 003:    343 / 990 loss=2.47, loss_v1=0, loss_v2=0, nll_loss=1.284, ntokens=1906.7, nsentences=56, sample_size=1906.7, sample_size_v1=0, sample_size_v2=0, ppl=2.43, wps=1103.6, ups=0.58, wpb=1906.7, bsz=56, num_updates=2320, lr=2.72398e-05, gnorm=1.343, clip=100, loss_scale=256, train_wall=17, gb_free=11.4, wall=4008
2023-06-27 17:25:42 - progress_bar.py[line:272] - INFO: epoch 003:    353 / 990 loss=2.449, loss_v1=0, loss_v2=0, nll_loss=1.258, ntokens=1898.6, nsentences=56, sample_size=1898.6, sample_size_v1=0, sample_size_v2=0, ppl=2.39, wps=1107.8, ups=0.58, wpb=1898.6, bsz=56, num_updates=2330, lr=2.72196e-05, gnorm=1.357, clip=100, loss_scale=256, train_wall=17, gb_free=12.5, wall=4025
2023-06-27 17:25:59 - progress_bar.py[line:272] - INFO: epoch 003:    363 / 990 loss=2.475, loss_v1=0, loss_v2=0, nll_loss=1.289, ntokens=1735.4, nsentences=56, sample_size=1735.4, sample_size_v1=0, sample_size_v2=0, ppl=2.44, wps=1015.3, ups=0.59, wpb=1735.4, bsz=56, num_updates=2340, lr=2.71995e-05, gnorm=1.429, clip=100, loss_scale=256, train_wall=17, gb_free=12.9, wall=4042
2023-06-27 17:26:17 - progress_bar.py[line:272] - INFO: epoch 003:    373 / 990 loss=2.487, loss_v1=0, loss_v2=0, nll_loss=1.3, ntokens=1789.3, nsentences=56, sample_size=1789.3, sample_size_v1=0, sample_size_v2=0, ppl=2.46, wps=1048.4, ups=0.59, wpb=1789.3, bsz=56, num_updates=2350, lr=2.71793e-05, gnorm=1.423, clip=100, loss_scale=256, train_wall=17, gb_free=12.8, wall=4059
2023-06-27 17:26:34 - progress_bar.py[line:272] - INFO: epoch 003:    383 / 990 loss=2.446, loss_v1=0, loss_v2=0, nll_loss=1.256, ntokens=1858.6, nsentences=56, sample_size=1858.6, sample_size_v1=0, sample_size_v2=0, ppl=2.39, wps=1087.7, ups=0.59, wpb=1858.6, bsz=56, num_updates=2360, lr=2.71592e-05, gnorm=1.25, clip=100, loss_scale=256, train_wall=17, gb_free=12.9, wall=4076
2023-06-27 17:26:51 - progress_bar.py[line:272] - INFO: epoch 003:    393 / 990 loss=2.437, loss_v1=0, loss_v2=0, nll_loss=1.245, ntokens=1742.1, nsentences=56, sample_size=1742.1, sample_size_v1=0, sample_size_v2=0, ppl=2.37, wps=1021.5, ups=0.59, wpb=1742.1, bsz=56, num_updates=2370, lr=2.7139e-05, gnorm=1.326, clip=100, loss_scale=256, train_wall=17, gb_free=12.6, wall=4093
2023-06-27 17:27:08 - progress_bar.py[line:272] - INFO: epoch 003:    403 / 990 loss=2.48, loss_v1=0, loss_v2=0, nll_loss=1.292, ntokens=1750.8, nsentences=56, sample_size=1750.8, sample_size_v1=0, sample_size_v2=0, ppl=2.45, wps=1029.5, ups=0.59, wpb=1750.8, bsz=56, num_updates=2380, lr=2.71189e-05, gnorm=1.464, clip=100, loss_scale=256, train_wall=17, gb_free=12.7, wall=4110
2023-06-27 17:27:25 - progress_bar.py[line:272] - INFO: epoch 003:    413 / 990 loss=2.478, loss_v1=0, loss_v2=0, nll_loss=1.291, ntokens=1704.5, nsentences=56, sample_size=1704.5, sample_size_v1=0, sample_size_v2=0, ppl=2.45, wps=1000.9, ups=0.59, wpb=1704.5, bsz=56, num_updates=2390, lr=2.70987e-05, gnorm=1.394, clip=100, loss_scale=256, train_wall=17, gb_free=12.4, wall=4127
2023-06-27 17:27:42 - progress_bar.py[line:272] - INFO: epoch 003:    423 / 990 loss=2.467, loss_v1=0, loss_v2=0, nll_loss=1.277, ntokens=1737.2, nsentences=56, sample_size=1737.2, sample_size_v1=0, sample_size_v2=0, ppl=2.42, wps=1021.3, ups=0.59, wpb=1737.2, bsz=56, num_updates=2400, lr=2.70786e-05, gnorm=1.328, clip=100, loss_scale=256, train_wall=17, gb_free=12.4, wall=4144
2023-06-27 17:27:59 - progress_bar.py[line:272] - INFO: epoch 003:    433 / 990 loss=2.444, loss_v1=0, loss_v2=0, nll_loss=1.255, ntokens=1926, nsentences=56, sample_size=1926, sample_size_v1=0, sample_size_v2=0, ppl=2.39, wps=1123.6, ups=0.58, wpb=1926, bsz=56, num_updates=2410, lr=2.70584e-05, gnorm=1.206, clip=100, loss_scale=256, train_wall=17, gb_free=12.7, wall=4162
2023-06-27 17:28:16 - progress_bar.py[line:272] - INFO: epoch 003:    443 / 990 loss=2.45, loss_v1=0, loss_v2=0, nll_loss=1.26, ntokens=1862.8, nsentences=56, sample_size=1862.8, sample_size_v1=0, sample_size_v2=0, ppl=2.39, wps=1074.7, ups=0.58, wpb=1862.8, bsz=56, num_updates=2420, lr=2.70383e-05, gnorm=1.257, clip=100, loss_scale=256, train_wall=17, gb_free=13, wall=4179
2023-06-27 17:28:33 - progress_bar.py[line:272] - INFO: epoch 003:    453 / 990 loss=2.458, loss_v1=0, loss_v2=0, nll_loss=1.27, ntokens=1793.1, nsentences=56, sample_size=1793.1, sample_size_v1=0, sample_size_v2=0, ppl=2.41, wps=1055.1, ups=0.59, wpb=1793.1, bsz=56, num_updates=2430, lr=2.70181e-05, gnorm=1.365, clip=100, loss_scale=256, train_wall=17, gb_free=12, wall=4196
2023-06-27 17:28:50 - progress_bar.py[line:272] - INFO: epoch 003:    463 / 990 loss=2.45, loss_v1=0, loss_v2=0, nll_loss=1.259, ntokens=1817.2, nsentences=56, sample_size=1817.2, sample_size_v1=0, sample_size_v2=0, ppl=2.39, wps=1060, ups=0.58, wpb=1817.2, bsz=56, num_updates=2440, lr=2.6998e-05, gnorm=1.48, clip=100, loss_scale=256, train_wall=17, gb_free=13.1, wall=4213
2023-06-27 17:29:08 - progress_bar.py[line:272] - INFO: epoch 003:    473 / 990 loss=2.448, loss_v1=0, loss_v2=0, nll_loss=1.258, ntokens=1902.8, nsentences=56, sample_size=1902.8, sample_size_v1=0, sample_size_v2=0, ppl=2.39, wps=1105.5, ups=0.58, wpb=1902.8, bsz=56, num_updates=2450, lr=2.69778e-05, gnorm=1.387, clip=100, loss_scale=256, train_wall=17, gb_free=11.1, wall=4230
2023-06-27 17:29:24 - progress_bar.py[line:272] - INFO: epoch 003:    483 / 990 loss=2.451, loss_v1=0, loss_v2=0, nll_loss=1.261, ntokens=1766, nsentences=54.8, sample_size=1766, sample_size_v1=0, sample_size_v2=0, ppl=2.4, wps=1049.1, ups=0.59, wpb=1766, bsz=54.8, num_updates=2460, lr=2.69577e-05, gnorm=1.407, clip=100, loss_scale=256, train_wall=17, gb_free=12.9, wall=4247
2023-06-27 17:29:42 - progress_bar.py[line:272] - INFO: epoch 003:    493 / 990 loss=2.448, loss_v1=0, loss_v2=0, nll_loss=1.256, ntokens=1863.1, nsentences=56, sample_size=1863.1, sample_size_v1=0, sample_size_v2=0, ppl=2.39, wps=1086.5, ups=0.58, wpb=1863.1, bsz=56, num_updates=2470, lr=2.69375e-05, gnorm=1.359, clip=100, loss_scale=256, train_wall=17, gb_free=12.9, wall=4264
2023-06-27 17:29:59 - progress_bar.py[line:272] - INFO: epoch 003:    503 / 990 loss=2.466, loss_v1=0, loss_v2=0, nll_loss=1.279, ntokens=1852.3, nsentences=56, sample_size=1852.3, sample_size_v1=0, sample_size_v2=0, ppl=2.43, wps=1086.1, ups=0.59, wpb=1852.3, bsz=56, num_updates=2480, lr=2.69174e-05, gnorm=1.268, clip=100, loss_scale=256, train_wall=17, gb_free=13.1, wall=4281
2023-06-27 17:30:16 - progress_bar.py[line:272] - INFO: epoch 003:    513 / 990 loss=2.479, loss_v1=0, loss_v2=0, nll_loss=1.29, ntokens=1724, nsentences=56, sample_size=1724, sample_size_v1=0, sample_size_v2=0, ppl=2.45, wps=1009.8, ups=0.59, wpb=1724, bsz=56, num_updates=2490, lr=2.68972e-05, gnorm=1.49, clip=100, loss_scale=256, train_wall=17, gb_free=13.1, wall=4298
2023-06-27 17:30:33 - progress_bar.py[line:272] - INFO: epoch 003:    523 / 990 loss=2.448, loss_v1=0, loss_v2=0, nll_loss=1.258, ntokens=1858.7, nsentences=56, sample_size=1858.7, sample_size_v1=0, sample_size_v2=0, ppl=2.39, wps=1087.3, ups=0.59, wpb=1858.7, bsz=56, num_updates=2500, lr=2.68771e-05, gnorm=1.54, clip=100, loss_scale=256, train_wall=17, gb_free=12.7, wall=4315
2023-06-27 17:30:50 - progress_bar.py[line:272] - INFO: epoch 003:    533 / 990 loss=2.441, loss_v1=0, loss_v2=0, nll_loss=1.249, ntokens=1878.2, nsentences=56, sample_size=1878.2, sample_size_v1=0, sample_size_v2=0, ppl=2.38, wps=1096.5, ups=0.58, wpb=1878.2, bsz=56, num_updates=2510, lr=2.6857e-05, gnorm=1.308, clip=100, loss_scale=256, train_wall=17, gb_free=12.3, wall=4333
2023-06-27 17:31:07 - progress_bar.py[line:272] - INFO: epoch 003:    543 / 990 loss=2.458, loss_v1=0, loss_v2=0, nll_loss=1.267, ntokens=1961.7, nsentences=56, sample_size=1961.7, sample_size_v1=0, sample_size_v2=0, ppl=2.41, wps=1145.4, ups=0.58, wpb=1961.7, bsz=56, num_updates=2520, lr=2.68368e-05, gnorm=1.373, clip=100, loss_scale=256, train_wall=17, gb_free=12.7, wall=4350
2023-06-27 17:31:24 - progress_bar.py[line:272] - INFO: epoch 003:    553 / 990 loss=2.434, loss_v1=0, loss_v2=0, nll_loss=1.243, ntokens=1881.5, nsentences=56, sample_size=1881.5, sample_size_v1=0, sample_size_v2=0, ppl=2.37, wps=1100.4, ups=0.58, wpb=1881.5, bsz=56, num_updates=2530, lr=2.68167e-05, gnorm=1.381, clip=100, loss_scale=256, train_wall=17, gb_free=13, wall=4367
2023-06-27 17:31:41 - progress_bar.py[line:272] - INFO: epoch 003:    563 / 990 loss=2.433, loss_v1=0, loss_v2=0, nll_loss=1.24, ntokens=1779.1, nsentences=56, sample_size=1779.1, sample_size_v1=0, sample_size_v2=0, ppl=2.36, wps=1042.4, ups=0.59, wpb=1779.1, bsz=56, num_updates=2540, lr=2.67965e-05, gnorm=1.379, clip=100, loss_scale=256, train_wall=17, gb_free=13.1, wall=4384
2023-06-27 17:31:58 - progress_bar.py[line:272] - INFO: epoch 003:    573 / 990 loss=2.439, loss_v1=0, loss_v2=0, nll_loss=1.249, ntokens=1815.8, nsentences=56, sample_size=1815.8, sample_size_v1=0, sample_size_v2=0, ppl=2.38, wps=1055.7, ups=0.58, wpb=1815.8, bsz=56, num_updates=2550, lr=2.67764e-05, gnorm=1.379, clip=100, loss_scale=256, train_wall=17, gb_free=12.9, wall=4401
2023-06-27 17:32:16 - progress_bar.py[line:272] - INFO: epoch 003:    583 / 990 loss=2.476, loss_v1=0, loss_v2=0, nll_loss=1.287, ntokens=1883.5, nsentences=56, sample_size=1883.5, sample_size_v1=0, sample_size_v2=0, ppl=2.44, wps=1103.4, ups=0.59, wpb=1883.5, bsz=56, num_updates=2560, lr=2.67562e-05, gnorm=1.426, clip=100, loss_scale=256, train_wall=17, gb_free=12, wall=4418
2023-06-27 17:32:33 - progress_bar.py[line:272] - INFO: epoch 003:    593 / 990 loss=2.443, loss_v1=0, loss_v2=0, nll_loss=1.253, ntokens=1909.6, nsentences=56, sample_size=1909.6, sample_size_v1=0, sample_size_v2=0, ppl=2.38, wps=1117.8, ups=0.59, wpb=1909.6, bsz=56, num_updates=2570, lr=2.67361e-05, gnorm=1.375, clip=100, loss_scale=256, train_wall=17, gb_free=12.9, wall=4435
2023-06-27 17:32:50 - progress_bar.py[line:272] - INFO: epoch 003:    603 / 990 loss=2.45, loss_v1=0, loss_v2=0, nll_loss=1.259, ntokens=1732.9, nsentences=56, sample_size=1732.9, sample_size_v1=0, sample_size_v2=0, ppl=2.39, wps=1021.5, ups=0.59, wpb=1732.9, bsz=56, num_updates=2580, lr=2.67159e-05, gnorm=1.56, clip=100, loss_scale=256, train_wall=17, gb_free=12.8, wall=4452
2023-06-27 17:33:07 - progress_bar.py[line:272] - INFO: epoch 003:    613 / 990 loss=2.434, loss_v1=0, loss_v2=0, nll_loss=1.241, ntokens=1853.2, nsentences=56, sample_size=1853.2, sample_size_v1=0, sample_size_v2=0, ppl=2.36, wps=1088.2, ups=0.59, wpb=1853.2, bsz=56, num_updates=2590, lr=2.66958e-05, gnorm=1.444, clip=100, loss_scale=512, train_wall=17, gb_free=13.1, wall=4469
2023-06-27 17:33:24 - progress_bar.py[line:272] - INFO: epoch 003:    623 / 990 loss=2.46, loss_v1=0, loss_v2=0, nll_loss=1.271, ntokens=1991.1, nsentences=56, sample_size=1991.1, sample_size_v1=0, sample_size_v2=0, ppl=2.41, wps=1162.4, ups=0.58, wpb=1991.1, bsz=56, num_updates=2600, lr=2.66756e-05, gnorm=1.353, clip=100, loss_scale=512, train_wall=17, gb_free=12.4, wall=4486
2023-06-27 17:33:41 - progress_bar.py[line:272] - INFO: epoch 003:    633 / 990 loss=2.475, loss_v1=0, loss_v2=0, nll_loss=1.288, ntokens=2015.6, nsentences=56, sample_size=2015.6, sample_size_v1=0, sample_size_v2=0, ppl=2.44, wps=1171.9, ups=0.58, wpb=2015.6, bsz=56, num_updates=2610, lr=2.66555e-05, gnorm=1.359, clip=100, loss_scale=512, train_wall=17, gb_free=13, wall=4504
2023-06-27 17:33:58 - progress_bar.py[line:272] - INFO: epoch 003:    643 / 990 loss=2.445, loss_v1=0, loss_v2=0, nll_loss=1.255, ntokens=1989.3, nsentences=56, sample_size=1989.3, sample_size_v1=0, sample_size_v2=0, ppl=2.39, wps=1153.9, ups=0.58, wpb=1989.3, bsz=56, num_updates=2620, lr=2.66353e-05, gnorm=1.286, clip=100, loss_scale=512, train_wall=17, gb_free=13.1, wall=4521
2023-06-27 17:34:15 - progress_bar.py[line:272] - INFO: epoch 003:    653 / 990 loss=2.444, loss_v1=0, loss_v2=0, nll_loss=1.253, ntokens=1933.5, nsentences=56, sample_size=1933.5, sample_size_v1=0, sample_size_v2=0, ppl=2.38, wps=1128.9, ups=0.58, wpb=1933.5, bsz=56, num_updates=2630, lr=2.66152e-05, gnorm=1.301, clip=100, loss_scale=512, train_wall=17, gb_free=12.9, wall=4538
2023-06-27 17:34:32 - progress_bar.py[line:272] - INFO: epoch 003:    663 / 990 loss=2.453, loss_v1=0, loss_v2=0, nll_loss=1.262, ntokens=1893.4, nsentences=56, sample_size=1893.4, sample_size_v1=0, sample_size_v2=0, ppl=2.4, wps=1104, ups=0.58, wpb=1893.4, bsz=56, num_updates=2640, lr=2.6595e-05, gnorm=1.395, clip=100, loss_scale=512, train_wall=17, gb_free=12.4, wall=4555
2023-06-27 17:34:50 - progress_bar.py[line:272] - INFO: epoch 003:    673 / 990 loss=2.448, loss_v1=0, loss_v2=0, nll_loss=1.257, ntokens=1819.5, nsentences=56, sample_size=1819.5, sample_size_v1=0, sample_size_v2=0, ppl=2.39, wps=1063, ups=0.58, wpb=1819.5, bsz=56, num_updates=2650, lr=2.65749e-05, gnorm=1.356, clip=100, loss_scale=512, train_wall=17, gb_free=11.6, wall=4572
2023-06-27 17:35:07 - progress_bar.py[line:272] - INFO: epoch 003:    683 / 990 loss=2.404, loss_v1=0, loss_v2=0, nll_loss=1.209, ntokens=1889.2, nsentences=56, sample_size=1889.2, sample_size_v1=0, sample_size_v2=0, ppl=2.31, wps=1100.5, ups=0.58, wpb=1889.2, bsz=56, num_updates=2660, lr=2.65547e-05, gnorm=1.389, clip=100, loss_scale=512, train_wall=17, gb_free=13.1, wall=4589
2023-06-27 17:35:24 - progress_bar.py[line:272] - INFO: epoch 003:    693 / 990 loss=2.434, loss_v1=0, loss_v2=0, nll_loss=1.242, ntokens=1764.1, nsentences=56, sample_size=1764.1, sample_size_v1=0, sample_size_v2=0, ppl=2.37, wps=1035.5, ups=0.59, wpb=1764.1, bsz=56, num_updates=2670, lr=2.65346e-05, gnorm=1.431, clip=100, loss_scale=512, train_wall=17, gb_free=12.1, wall=4606
2023-06-27 17:35:41 - progress_bar.py[line:272] - INFO: epoch 003:    703 / 990 loss=2.453, loss_v1=0, loss_v2=0, nll_loss=1.261, ntokens=1714.9, nsentences=56, sample_size=1714.9, sample_size_v1=0, sample_size_v2=0, ppl=2.4, wps=1005.3, ups=0.59, wpb=1714.9, bsz=56, num_updates=2680, lr=2.65144e-05, gnorm=1.618, clip=100, loss_scale=512, train_wall=17, gb_free=12.9, wall=4624
2023-06-27 17:35:58 - progress_bar.py[line:272] - INFO: epoch 003:    713 / 990 loss=2.446, loss_v1=0, loss_v2=0, nll_loss=1.254, ntokens=1778.6, nsentences=56, sample_size=1778.6, sample_size_v1=0, sample_size_v2=0, ppl=2.38, wps=1045.4, ups=0.59, wpb=1778.6, bsz=56, num_updates=2690, lr=2.64943e-05, gnorm=1.542, clip=100, loss_scale=512, train_wall=17, gb_free=12.6, wall=4641
2023-06-27 17:36:15 - progress_bar.py[line:272] - INFO: epoch 003:    723 / 990 loss=2.434, loss_v1=0, loss_v2=0, nll_loss=1.244, ntokens=1751.9, nsentences=56, sample_size=1751.9, sample_size_v1=0, sample_size_v2=0, ppl=2.37, wps=1032.6, ups=0.59, wpb=1751.9, bsz=56, num_updates=2700, lr=2.64741e-05, gnorm=1.555, clip=100, loss_scale=512, train_wall=17, gb_free=12.8, wall=4658
2023-06-27 17:36:32 - progress_bar.py[line:272] - INFO: epoch 003:    733 / 990 loss=2.405, loss_v1=0, loss_v2=0, nll_loss=1.207, ntokens=1818.1, nsentences=56, sample_size=1818.1, sample_size_v1=0, sample_size_v2=0, ppl=2.31, wps=1064.3, ups=0.59, wpb=1818.1, bsz=56, num_updates=2710, lr=2.6454e-05, gnorm=1.517, clip=100, loss_scale=512, train_wall=17, gb_free=12.9, wall=4675
2023-06-27 17:36:49 - progress_bar.py[line:272] - INFO: epoch 003:    743 / 990 loss=2.462, loss_v1=0, loss_v2=0, nll_loss=1.272, ntokens=1794.8, nsentences=56, sample_size=1794.8, sample_size_v1=0, sample_size_v2=0, ppl=2.42, wps=1053, ups=0.59, wpb=1794.8, bsz=56, num_updates=2720, lr=2.64338e-05, gnorm=1.446, clip=100, loss_scale=512, train_wall=17, gb_free=12.6, wall=4692
2023-06-27 17:37:06 - progress_bar.py[line:272] - INFO: epoch 003:    753 / 990 loss=2.466, loss_v1=0, loss_v2=0, nll_loss=1.276, ntokens=1659.3, nsentences=56, sample_size=1659.3, sample_size_v1=0, sample_size_v2=0, ppl=2.42, wps=977.6, ups=0.59, wpb=1659.3, bsz=56, num_updates=2730, lr=2.64137e-05, gnorm=1.564, clip=100, loss_scale=512, train_wall=17, gb_free=12.9, wall=4709
2023-06-27 17:37:23 - progress_bar.py[line:272] - INFO: epoch 003:    763 / 990 loss=2.446, loss_v1=0, loss_v2=0, nll_loss=1.256, ntokens=1746.8, nsentences=56, sample_size=1746.8, sample_size_v1=0, sample_size_v2=0, ppl=2.39, wps=1024.9, ups=0.59, wpb=1746.8, bsz=56, num_updates=2740, lr=2.63936e-05, gnorm=1.497, clip=100, loss_scale=512, train_wall=17, gb_free=13, wall=4726
2023-06-27 17:37:40 - progress_bar.py[line:272] - INFO: epoch 003:    773 / 990 loss=2.444, loss_v1=0, loss_v2=0, nll_loss=1.25, ntokens=1838.2, nsentences=56, sample_size=1838.2, sample_size_v1=0, sample_size_v2=0, ppl=2.38, wps=1072.7, ups=0.58, wpb=1838.2, bsz=56, num_updates=2750, lr=2.63734e-05, gnorm=1.459, clip=100, loss_scale=512, train_wall=17, gb_free=12.6, wall=4743
2023-06-27 17:37:57 - progress_bar.py[line:272] - INFO: epoch 003:    783 / 990 loss=2.43, loss_v1=0, loss_v2=0, nll_loss=1.243, ntokens=1775.1, nsentences=56, sample_size=1775.1, sample_size_v1=0, sample_size_v2=0, ppl=2.37, wps=1043.8, ups=0.59, wpb=1775.1, bsz=56, num_updates=2760, lr=2.63533e-05, gnorm=1.463, clip=100, loss_scale=512, train_wall=17, gb_free=12.6, wall=4760
2023-06-27 17:38:14 - progress_bar.py[line:272] - INFO: epoch 003:    793 / 990 loss=2.445, loss_v1=0, loss_v2=0, nll_loss=1.249, ntokens=1828.9, nsentences=56, sample_size=1828.9, sample_size_v1=0, sample_size_v2=0, ppl=2.38, wps=1070.3, ups=0.59, wpb=1828.9, bsz=56, num_updates=2770, lr=2.63331e-05, gnorm=1.466, clip=100, loss_scale=512, train_wall=17, gb_free=12.4, wall=4777
2023-06-27 17:38:31 - progress_bar.py[line:272] - INFO: epoch 003:    803 / 990 loss=2.447, loss_v1=0, loss_v2=0, nll_loss=1.258, ntokens=1766.6, nsentences=56, sample_size=1766.6, sample_size_v1=0, sample_size_v2=0, ppl=2.39, wps=1032.8, ups=0.58, wpb=1766.6, bsz=56, num_updates=2780, lr=2.6313e-05, gnorm=1.476, clip=100, loss_scale=512, train_wall=17, gb_free=12.9, wall=4794
2023-06-27 17:38:48 - progress_bar.py[line:272] - INFO: epoch 003:    813 / 990 loss=2.469, loss_v1=0, loss_v2=0, nll_loss=1.279, ntokens=1687.3, nsentences=56, sample_size=1687.3, sample_size_v1=0, sample_size_v2=0, ppl=2.43, wps=993.1, ups=0.59, wpb=1687.3, bsz=56, num_updates=2790, lr=2.62928e-05, gnorm=1.585, clip=100, loss_scale=512, train_wall=17, gb_free=12.9, wall=4811
2023-06-27 17:39:05 - progress_bar.py[line:272] - INFO: epoch 003:    823 / 990 loss=2.431, loss_v1=0, loss_v2=0, nll_loss=1.242, ntokens=1695.7, nsentences=56, sample_size=1695.7, sample_size_v1=0, sample_size_v2=0, ppl=2.36, wps=993.8, ups=0.59, wpb=1695.7, bsz=56, num_updates=2800, lr=2.62727e-05, gnorm=1.566, clip=100, loss_scale=512, train_wall=17, gb_free=12.5, wall=4828
2023-06-27 17:39:22 - progress_bar.py[line:272] - INFO: epoch 003:    833 / 990 loss=2.417, loss_v1=0, loss_v2=0, nll_loss=1.221, ntokens=1764.5, nsentences=56, sample_size=1764.5, sample_size_v1=0, sample_size_v2=0, ppl=2.33, wps=1038.5, ups=0.59, wpb=1764.5, bsz=56, num_updates=2810, lr=2.62525e-05, gnorm=1.552, clip=100, loss_scale=512, train_wall=17, gb_free=13, wall=4845
2023-06-27 17:39:40 - progress_bar.py[line:272] - INFO: epoch 003:    843 / 990 loss=2.418, loss_v1=0, loss_v2=0, nll_loss=1.223, ntokens=1851.4, nsentences=56, sample_size=1851.4, sample_size_v1=0, sample_size_v2=0, ppl=2.33, wps=1081.9, ups=0.58, wpb=1851.4, bsz=56, num_updates=2820, lr=2.62324e-05, gnorm=1.467, clip=100, loss_scale=512, train_wall=17, gb_free=12.6, wall=4862
2023-06-27 17:39:57 - progress_bar.py[line:272] - INFO: epoch 003:    853 / 990 loss=2.408, loss_v1=0, loss_v2=0, nll_loss=1.212, ntokens=1876.2, nsentences=56, sample_size=1876.2, sample_size_v1=0, sample_size_v2=0, ppl=2.32, wps=1092.9, ups=0.58, wpb=1876.2, bsz=56, num_updates=2830, lr=2.62122e-05, gnorm=1.491, clip=100, loss_scale=512, train_wall=17, gb_free=12.4, wall=4879
2023-06-27 17:40:10 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 256.0
2023-06-27 17:40:15 - progress_bar.py[line:272] - INFO: epoch 003:    864 / 990 loss=2.407, loss_v1=0, loss_v2=0, nll_loss=1.212, ntokens=1816.4, nsentences=56, sample_size=1816.4, sample_size_v1=0, sample_size_v2=0, ppl=2.32, wps=966.9, ups=0.53, wpb=1816.4, bsz=56, num_updates=2840, lr=2.61921e-05, gnorm=1.466, clip=100, loss_scale=256, train_wall=19, gb_free=12.5, wall=4898
2023-06-27 17:40:33 - progress_bar.py[line:272] - INFO: epoch 003:    874 / 990 loss=2.419, loss_v1=0, loss_v2=0, nll_loss=1.225, ntokens=1864.1, nsentences=56, sample_size=1864.1, sample_size_v1=0, sample_size_v2=0, ppl=2.34, wps=1086.1, ups=0.58, wpb=1864.1, bsz=56, num_updates=2850, lr=2.61719e-05, gnorm=1.495, clip=100, loss_scale=256, train_wall=17, gb_free=12.3, wall=4915
2023-06-27 17:40:50 - progress_bar.py[line:272] - INFO: epoch 003:    884 / 990 loss=2.415, loss_v1=0, loss_v2=0, nll_loss=1.218, ntokens=1882.5, nsentences=56, sample_size=1882.5, sample_size_v1=0, sample_size_v2=0, ppl=2.33, wps=1101.6, ups=0.59, wpb=1882.5, bsz=56, num_updates=2860, lr=2.61518e-05, gnorm=1.408, clip=100, loss_scale=256, train_wall=17, gb_free=12.8, wall=4932
2023-06-27 17:41:07 - progress_bar.py[line:272] - INFO: epoch 003:    894 / 990 loss=2.401, loss_v1=0, loss_v2=0, nll_loss=1.207, ntokens=1974.3, nsentences=56, sample_size=1974.3, sample_size_v1=0, sample_size_v2=0, ppl=2.31, wps=1151.7, ups=0.58, wpb=1974.3, bsz=56, num_updates=2870, lr=2.61316e-05, gnorm=1.309, clip=100, loss_scale=256, train_wall=17, gb_free=12.8, wall=4950
2023-06-27 17:41:24 - progress_bar.py[line:272] - INFO: epoch 003:    904 / 990 loss=2.445, loss_v1=0, loss_v2=0, nll_loss=1.252, ntokens=1736.5, nsentences=56, sample_size=1736.5, sample_size_v1=0, sample_size_v2=0, ppl=2.38, wps=1017.4, ups=0.59, wpb=1736.5, bsz=56, num_updates=2880, lr=2.61115e-05, gnorm=1.491, clip=100, loss_scale=256, train_wall=17, gb_free=12.5, wall=4967
2023-06-27 17:41:41 - progress_bar.py[line:272] - INFO: epoch 003:    914 / 990 loss=2.435, loss_v1=0, loss_v2=0, nll_loss=1.242, ntokens=1771.2, nsentences=56, sample_size=1771.2, sample_size_v1=0, sample_size_v2=0, ppl=2.37, wps=1042.9, ups=0.59, wpb=1771.2, bsz=56, num_updates=2890, lr=2.60913e-05, gnorm=1.496, clip=100, loss_scale=256, train_wall=17, gb_free=12.9, wall=4984
2023-06-27 17:41:58 - progress_bar.py[line:272] - INFO: epoch 003:    924 / 990 loss=2.404, loss_v1=0, loss_v2=0, nll_loss=1.211, ntokens=1753.4, nsentences=56, sample_size=1753.4, sample_size_v1=0, sample_size_v2=0, ppl=2.32, wps=1029.5, ups=0.59, wpb=1753.4, bsz=56, num_updates=2900, lr=2.60712e-05, gnorm=1.562, clip=100, loss_scale=256, train_wall=17, gb_free=12.9, wall=5001
2023-06-27 17:42:15 - progress_bar.py[line:272] - INFO: epoch 003:    934 / 990 loss=2.408, loss_v1=0, loss_v2=0, nll_loss=1.21, ntokens=1845.8, nsentences=56, sample_size=1845.8, sample_size_v1=0, sample_size_v2=0, ppl=2.31, wps=1079, ups=0.58, wpb=1845.8, bsz=56, num_updates=2910, lr=2.6051e-05, gnorm=1.559, clip=100, loss_scale=256, train_wall=17, gb_free=13.1, wall=5018
2023-06-27 17:42:32 - progress_bar.py[line:272] - INFO: epoch 003:    944 / 990 loss=2.418, loss_v1=0, loss_v2=0, nll_loss=1.225, ntokens=1882.7, nsentences=56, sample_size=1882.7, sample_size_v1=0, sample_size_v2=0, ppl=2.34, wps=1095.1, ups=0.58, wpb=1882.7, bsz=56, num_updates=2920, lr=2.60309e-05, gnorm=1.572, clip=100, loss_scale=256, train_wall=17, gb_free=12.9, wall=5035
2023-06-27 17:42:49 - progress_bar.py[line:272] - INFO: epoch 003:    954 / 990 loss=2.414, loss_v1=0, loss_v2=0, nll_loss=1.217, ntokens=1927.3, nsentences=56, sample_size=1927.3, sample_size_v1=0, sample_size_v2=0, ppl=2.32, wps=1120.7, ups=0.58, wpb=1927.3, bsz=56, num_updates=2930, lr=2.60107e-05, gnorm=1.502, clip=100, loss_scale=256, train_wall=17, gb_free=13.1, wall=5052
2023-06-27 17:43:07 - progress_bar.py[line:272] - INFO: epoch 003:    964 / 990 loss=2.421, loss_v1=0, loss_v2=0, nll_loss=1.228, ntokens=1878.2, nsentences=56, sample_size=1878.2, sample_size_v1=0, sample_size_v2=0, ppl=2.34, wps=1085.1, ups=0.58, wpb=1878.2, bsz=56, num_updates=2940, lr=2.59906e-05, gnorm=1.467, clip=100, loss_scale=256, train_wall=17, gb_free=13, wall=5069
2023-06-27 17:43:24 - progress_bar.py[line:272] - INFO: epoch 003:    974 / 990 loss=2.404, loss_v1=0, loss_v2=0, nll_loss=1.207, ntokens=1945, nsentences=56, sample_size=1945, sample_size_v1=0, sample_size_v2=0, ppl=2.31, wps=1131.4, ups=0.58, wpb=1945, bsz=56, num_updates=2950, lr=2.59704e-05, gnorm=1.525, clip=100, loss_scale=256, train_wall=17, gb_free=12.8, wall=5087
2023-06-27 17:43:41 - progress_bar.py[line:272] - INFO: epoch 003:    984 / 990 loss=2.431, loss_v1=0, loss_v2=0, nll_loss=1.237, ntokens=1795.5, nsentences=56, sample_size=1795.5, sample_size_v1=0, sample_size_v2=0, ppl=2.36, wps=1055.5, ups=0.59, wpb=1795.5, bsz=56, num_updates=2960, lr=2.59503e-05, gnorm=1.557, clip=100, loss_scale=256, train_wall=17, gb_free=12.4, wall=5104
local datafile ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 1 begin to initialize row_count and line_idx-to-offset mapping
2023-06-27 17:43:50 - train.py[line:332] - INFO: end of epoch 3 (average epoch stats below)
2023-06-27 17:43:50 - progress_bar.py[line:282] - INFO: epoch 003 | loss 2.432 | loss_v1 0 | loss_v2 0 | nll_loss 1.24 | ntokens 1849.87 | nsentences 55.96 | sample_size 1849.87 | sample_size_v1 0 | sample_size_v2 0 | ppl 2.36 | wps 1074.4 | ups 0.58 | wpb 1849.9 | bsz 56 | num_updates 2966 | lr 2.59382e-05 | gnorm 1.427 | clip 99.9 | loss_scale 256 | train_wall 1695 | gb_free 13.3 | wall 5113
2023-06-27 17:43:50 - trainer.py[line:639] - INFO: loading train data for epoch 4
local datafile ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 0 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 1 finished initializing row_count and line_idx-to-offset mapping
file ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 1 row count 27700 total row count 55400
slice_id 1 seek offset 27700
local datafile ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 0 finished initializing row_count and line_idx-to-offset mapping
file ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 0 row count 27700 total row count 55400
slice_id 0 seek offset 0
2023-06-27 17:43:52 - trainer.py[line:703] - INFO: begin training epoch 4
2023-06-27 17:43:52 - train.py[line:305] - INFO: Start iterating over samples
2023-06-27 17:44:00 - progress_bar.py[line:272] - INFO: epoch 004:      4 / 990 loss=2.43, loss_v1=0, loss_v2=0, nll_loss=1.236, ntokens=1789.4, nsentences=53.2, sample_size=1789.4, sample_size_v1=0, sample_size_v2=0, ppl=2.36, wps=960.4, ups=0.54, wpb=1789.4, bsz=53.2, num_updates=2970, lr=2.59302e-05, gnorm=1.63, clip=100, loss_scale=256, train_wall=16, gb_free=12.4, wall=5122
2023-06-27 17:44:17 - progress_bar.py[line:272] - INFO: epoch 004:     14 / 990 loss=2.372, loss_v1=0, loss_v2=0, nll_loss=1.173, ntokens=1790.5, nsentences=56, sample_size=1790.5, sample_size_v1=0, sample_size_v2=0, ppl=2.25, wps=1038.8, ups=0.58, wpb=1790.5, bsz=56, num_updates=2980, lr=2.591e-05, gnorm=1.505, clip=100, loss_scale=256, train_wall=17, gb_free=12.7, wall=5140
2023-06-27 17:44:34 - progress_bar.py[line:272] - INFO: epoch 004:     24 / 990 loss=2.333, loss_v1=0, loss_v2=0, nll_loss=1.128, ntokens=1851.2, nsentences=56, sample_size=1851.2, sample_size_v1=0, sample_size_v2=0, ppl=2.19, wps=1073.2, ups=0.58, wpb=1851.2, bsz=56, num_updates=2990, lr=2.58899e-05, gnorm=1.546, clip=100, loss_scale=256, train_wall=17, gb_free=12.4, wall=5157
2023-06-27 17:44:51 - progress_bar.py[line:272] - INFO: epoch 004:     34 / 990 loss=2.376, loss_v1=0, loss_v2=0, nll_loss=1.177, ntokens=1720.7, nsentences=56, sample_size=1720.7, sample_size_v1=0, sample_size_v2=0, ppl=2.26, wps=1010.7, ups=0.59, wpb=1720.7, bsz=56, num_updates=3000, lr=2.58697e-05, gnorm=1.52, clip=100, loss_scale=256, train_wall=17, gb_free=12.4, wall=5174
2023-06-27 17:45:09 - progress_bar.py[line:272] - INFO: epoch 004:     44 / 990 loss=2.282, loss_v1=0, loss_v2=0, nll_loss=1.071, ntokens=2014.5, nsentences=56, sample_size=2014.5, sample_size_v1=0, sample_size_v2=0, ppl=2.1, wps=1157, ups=0.57, wpb=2014.5, bsz=56, num_updates=3010, lr=2.58496e-05, gnorm=1.33, clip=100, loss_scale=256, train_wall=17, gb_free=11.6, wall=5191
2023-06-27 17:45:26 - progress_bar.py[line:272] - INFO: epoch 004:     54 / 990 loss=2.382, loss_v1=0, loss_v2=0, nll_loss=1.181, ntokens=1709.6, nsentences=56, sample_size=1709.6, sample_size_v1=0, sample_size_v2=0, ppl=2.27, wps=992.4, ups=0.58, wpb=1709.6, bsz=56, num_updates=3020, lr=2.58294e-05, gnorm=1.756, clip=100, loss_scale=256, train_wall=17, gb_free=11.6, wall=5208
2023-06-27 17:45:43 - progress_bar.py[line:272] - INFO: epoch 004:     64 / 990 loss=2.285, loss_v1=0, loss_v2=0, nll_loss=1.076, ntokens=1839.5, nsentences=56, sample_size=1839.5, sample_size_v1=0, sample_size_v2=0, ppl=2.11, wps=1066.1, ups=0.58, wpb=1839.5, bsz=56, num_updates=3030, lr=2.58093e-05, gnorm=1.588, clip=100, loss_scale=256, train_wall=17, gb_free=12.5, wall=5226
2023-06-27 17:46:01 - progress_bar.py[line:272] - INFO: epoch 004:     74 / 990 loss=2.212, loss_v1=0, loss_v2=0, nll_loss=0.991, ntokens=2066, nsentences=56, sample_size=2066, sample_size_v1=0, sample_size_v2=0, ppl=1.99, wps=1181.1, ups=0.57, wpb=2066, bsz=56, num_updates=3040, lr=2.57891e-05, gnorm=1.313, clip=80, loss_scale=256, train_wall=17, gb_free=11.9, wall=5243
2023-06-27 17:46:18 - progress_bar.py[line:272] - INFO: epoch 004:     84 / 990 loss=2.286, loss_v1=0, loss_v2=0, nll_loss=1.074, ntokens=2172.9, nsentences=56, sample_size=2172.9, sample_size_v1=0, sample_size_v2=0, ppl=2.1, wps=1224.6, ups=0.56, wpb=2172.9, bsz=56, num_updates=3050, lr=2.5769e-05, gnorm=1.37, clip=90, loss_scale=256, train_wall=18, gb_free=11.3, wall=5261
2023-06-27 17:46:36 - progress_bar.py[line:272] - INFO: epoch 004:     94 / 990 loss=2.31, loss_v1=0, loss_v2=0, nll_loss=1.104, ntokens=1971.6, nsentences=56, sample_size=1971.6, sample_size_v1=0, sample_size_v2=0, ppl=2.15, wps=1130, ups=0.57, wpb=1971.6, bsz=56, num_updates=3060, lr=2.57488e-05, gnorm=1.429, clip=100, loss_scale=256, train_wall=17, gb_free=11.8, wall=5278
2023-06-27 17:46:53 - progress_bar.py[line:272] - INFO: epoch 004:    104 / 990 loss=2.34, loss_v1=0, loss_v2=0, nll_loss=1.135, ntokens=1862.3, nsentences=56, sample_size=1862.3, sample_size_v1=0, sample_size_v2=0, ppl=2.2, wps=1079.2, ups=0.58, wpb=1862.3, bsz=56, num_updates=3070, lr=2.57287e-05, gnorm=1.392, clip=100, loss_scale=256, train_wall=17, gb_free=12.5, wall=5296
2023-06-27 17:47:10 - progress_bar.py[line:272] - INFO: epoch 004:    114 / 990 loss=2.35, loss_v1=0, loss_v2=0, nll_loss=1.148, ntokens=1840.7, nsentences=56, sample_size=1840.7, sample_size_v1=0, sample_size_v2=0, ppl=2.22, wps=1072.2, ups=0.58, wpb=1840.7, bsz=56, num_updates=3080, lr=2.57085e-05, gnorm=1.591, clip=100, loss_scale=256, train_wall=17, gb_free=13, wall=5313
2023-06-27 17:47:27 - progress_bar.py[line:272] - INFO: epoch 004:    124 / 990 loss=2.41, loss_v1=0, loss_v2=0, nll_loss=1.215, ntokens=1803.4, nsentences=56, sample_size=1803.4, sample_size_v1=0, sample_size_v2=0, ppl=2.32, wps=1050.9, ups=0.58, wpb=1803.4, bsz=56, num_updates=3090, lr=2.56884e-05, gnorm=1.41, clip=100, loss_scale=256, train_wall=17, gb_free=12.8, wall=5330
2023-06-27 17:47:45 - progress_bar.py[line:272] - INFO: epoch 004:    134 / 990 loss=2.417, loss_v1=0, loss_v2=0, nll_loss=1.219, ntokens=1845, nsentences=56, sample_size=1845, sample_size_v1=0, sample_size_v2=0, ppl=2.33, wps=1065.3, ups=0.58, wpb=1845, bsz=56, num_updates=3100, lr=2.56682e-05, gnorm=1.317, clip=100, loss_scale=256, train_wall=17, gb_free=12.4, wall=5347
2023-06-27 17:48:02 - progress_bar.py[line:272] - INFO: epoch 004:    144 / 990 loss=2.376, loss_v1=0, loss_v2=0, nll_loss=1.176, ntokens=1943.1, nsentences=56, sample_size=1943.1, sample_size_v1=0, sample_size_v2=0, ppl=2.26, wps=1110.5, ups=0.57, wpb=1943.1, bsz=56, num_updates=3110, lr=2.56481e-05, gnorm=1.363, clip=100, loss_scale=256, train_wall=17, gb_free=12.5, wall=5365
2023-06-27 17:48:20 - progress_bar.py[line:272] - INFO: epoch 004:    154 / 990 loss=2.371, loss_v1=0, loss_v2=0, nll_loss=1.17, ntokens=1938.2, nsentences=56, sample_size=1938.2, sample_size_v1=0, sample_size_v2=0, ppl=2.25, wps=1112.8, ups=0.57, wpb=1938.2, bsz=56, num_updates=3120, lr=2.56279e-05, gnorm=1.399, clip=100, loss_scale=256, train_wall=17, gb_free=12.5, wall=5382
2023-06-27 17:48:37 - progress_bar.py[line:272] - INFO: epoch 004:    164 / 990 loss=2.355, loss_v1=0, loss_v2=0, nll_loss=1.154, ntokens=2009, nsentences=56, sample_size=2009, sample_size_v1=0, sample_size_v2=0, ppl=2.22, wps=1147.1, ups=0.57, wpb=2009, bsz=56, num_updates=3130, lr=2.56078e-05, gnorm=1.374, clip=100, loss_scale=256, train_wall=17, gb_free=11.9, wall=5400
2023-06-27 17:48:55 - progress_bar.py[line:272] - INFO: epoch 004:    174 / 990 loss=2.35, loss_v1=0, loss_v2=0, nll_loss=1.147, ntokens=1935.6, nsentences=56, sample_size=1935.6, sample_size_v1=0, sample_size_v2=0, ppl=2.21, wps=1111.1, ups=0.57, wpb=1935.6, bsz=56, num_updates=3140, lr=2.55876e-05, gnorm=1.521, clip=100, loss_scale=256, train_wall=17, gb_free=12, wall=5417
2023-06-27 17:49:12 - progress_bar.py[line:272] - INFO: epoch 004:    184 / 990 loss=2.371, loss_v1=0, loss_v2=0, nll_loss=1.173, ntokens=1902.2, nsentences=56, sample_size=1902.2, sample_size_v1=0, sample_size_v2=0, ppl=2.25, wps=1096.5, ups=0.58, wpb=1902.2, bsz=56, num_updates=3150, lr=2.55675e-05, gnorm=1.49, clip=100, loss_scale=256, train_wall=17, gb_free=12.7, wall=5435
2023-06-27 17:49:29 - progress_bar.py[line:272] - INFO: epoch 004:    194 / 990 loss=2.362, loss_v1=0, loss_v2=0, nll_loss=1.157, ntokens=1869, nsentences=56, sample_size=1869, sample_size_v1=0, sample_size_v2=0, ppl=2.23, wps=1086.5, ups=0.58, wpb=1869, bsz=56, num_updates=3160, lr=2.55473e-05, gnorm=1.472, clip=100, loss_scale=256, train_wall=17, gb_free=12.8, wall=5452
2023-06-27 17:49:46 - progress_bar.py[line:272] - INFO: epoch 004:    204 / 990 loss=2.337, loss_v1=0, loss_v2=0, nll_loss=1.133, ntokens=1885.2, nsentences=56, sample_size=1885.2, sample_size_v1=0, sample_size_v2=0, ppl=2.19, wps=1090.3, ups=0.58, wpb=1885.2, bsz=56, num_updates=3170, lr=2.55272e-05, gnorm=1.52, clip=100, loss_scale=256, train_wall=17, gb_free=12.5, wall=5469
2023-06-27 17:50:04 - progress_bar.py[line:272] - INFO: epoch 004:    214 / 990 loss=2.352, loss_v1=0, loss_v2=0, nll_loss=1.149, ntokens=1912.5, nsentences=56, sample_size=1912.5, sample_size_v1=0, sample_size_v2=0, ppl=2.22, wps=1098.3, ups=0.57, wpb=1912.5, bsz=56, num_updates=3180, lr=2.55071e-05, gnorm=1.57, clip=100, loss_scale=256, train_wall=17, gb_free=12.6, wall=5486
2023-06-27 17:50:21 - progress_bar.py[line:272] - INFO: epoch 004:    224 / 990 loss=2.371, loss_v1=0, loss_v2=0, nll_loss=1.172, ntokens=1924.5, nsentences=56, sample_size=1924.5, sample_size_v1=0, sample_size_v2=0, ppl=2.25, wps=1108.1, ups=0.58, wpb=1924.5, bsz=56, num_updates=3190, lr=2.54869e-05, gnorm=1.522, clip=100, loss_scale=256, train_wall=17, gb_free=12.2, wall=5504
2023-06-27 17:50:38 - progress_bar.py[line:272] - INFO: epoch 004:    234 / 990 loss=2.407, loss_v1=0, loss_v2=0, nll_loss=1.21, ntokens=1750, nsentences=56, sample_size=1750, sample_size_v1=0, sample_size_v2=0, ppl=2.31, wps=1021, ups=0.58, wpb=1750, bsz=56, num_updates=3200, lr=2.54668e-05, gnorm=1.603, clip=100, loss_scale=256, train_wall=17, gb_free=12.6, wall=5521
2023-06-27 17:50:56 - progress_bar.py[line:272] - INFO: epoch 004:    244 / 990 loss=2.425, loss_v1=0, loss_v2=0, nll_loss=1.232, ntokens=1872.4, nsentences=56, sample_size=1872.4, sample_size_v1=0, sample_size_v2=0, ppl=2.35, wps=1087.4, ups=0.58, wpb=1872.4, bsz=56, num_updates=3210, lr=2.54466e-05, gnorm=1.571, clip=100, loss_scale=256, train_wall=17, gb_free=12.2, wall=5538
2023-06-27 17:51:13 - progress_bar.py[line:272] - INFO: epoch 004:    254 / 990 loss=2.41, loss_v1=0, loss_v2=0, nll_loss=1.213, ntokens=1923.2, nsentences=56, sample_size=1923.2, sample_size_v1=0, sample_size_v2=0, ppl=2.32, wps=1118, ups=0.58, wpb=1923.2, bsz=56, num_updates=3220, lr=2.54265e-05, gnorm=1.447, clip=100, loss_scale=256, train_wall=17, gb_free=12.4, wall=5555
2023-06-27 17:51:30 - progress_bar.py[line:272] - INFO: epoch 004:    264 / 990 loss=2.44, loss_v1=0, loss_v2=0, nll_loss=1.248, ntokens=1848.1, nsentences=56, sample_size=1848.1, sample_size_v1=0, sample_size_v2=0, ppl=2.38, wps=1065.7, ups=0.58, wpb=1848.1, bsz=56, num_updates=3230, lr=2.54063e-05, gnorm=1.485, clip=100, loss_scale=256, train_wall=17, gb_free=12.6, wall=5573
2023-06-27 17:51:47 - progress_bar.py[line:272] - INFO: epoch 004:    274 / 990 loss=2.441, loss_v1=0, loss_v2=0, nll_loss=1.249, ntokens=1924.2, nsentences=56, sample_size=1924.2, sample_size_v1=0, sample_size_v2=0, ppl=2.38, wps=1113.3, ups=0.58, wpb=1924.2, bsz=56, num_updates=3240, lr=2.53862e-05, gnorm=1.409, clip=100, loss_scale=256, train_wall=17, gb_free=12.3, wall=5590
2023-06-27 17:52:05 - progress_bar.py[line:272] - INFO: epoch 004:    284 / 990 loss=2.435, loss_v1=0, loss_v2=0, nll_loss=1.244, ntokens=1893.2, nsentences=56, sample_size=1893.2, sample_size_v1=0, sample_size_v2=0, ppl=2.37, wps=1090, ups=0.58, wpb=1893.2, bsz=56, num_updates=3250, lr=2.5366e-05, gnorm=1.522, clip=100, loss_scale=256, train_wall=17, gb_free=12.6, wall=5607
2023-06-27 17:52:22 - progress_bar.py[line:272] - INFO: epoch 004:    294 / 990 loss=2.435, loss_v1=0, loss_v2=0, nll_loss=1.243, ntokens=1850.5, nsentences=56, sample_size=1850.5, sample_size_v1=0, sample_size_v2=0, ppl=2.37, wps=1079.2, ups=0.58, wpb=1850.5, bsz=56, num_updates=3260, lr=2.53459e-05, gnorm=1.61, clip=100, loss_scale=256, train_wall=17, gb_free=12.6, wall=5625
2023-06-27 17:52:39 - progress_bar.py[line:272] - INFO: epoch 004:    304 / 990 loss=2.436, loss_v1=0, loss_v2=0, nll_loss=1.243, ntokens=1868.2, nsentences=56, sample_size=1868.2, sample_size_v1=0, sample_size_v2=0, ppl=2.37, wps=1081.7, ups=0.58, wpb=1868.2, bsz=56, num_updates=3270, lr=2.53257e-05, gnorm=1.6, clip=100, loss_scale=256, train_wall=17, gb_free=12.2, wall=5642
2023-06-27 17:52:56 - progress_bar.py[line:272] - INFO: epoch 004:    314 / 990 loss=2.436, loss_v1=0, loss_v2=0, nll_loss=1.244, ntokens=1930, nsentences=56, sample_size=1930, sample_size_v1=0, sample_size_v2=0, ppl=2.37, wps=1118.6, ups=0.58, wpb=1930, bsz=56, num_updates=3280, lr=2.53056e-05, gnorm=1.723, clip=100, loss_scale=256, train_wall=17, gb_free=12.9, wall=5659
2023-06-27 17:53:14 - progress_bar.py[line:272] - INFO: epoch 004:    324 / 990 loss=2.444, loss_v1=0, loss_v2=0, nll_loss=1.252, ntokens=1902.7, nsentences=56, sample_size=1902.7, sample_size_v1=0, sample_size_v2=0, ppl=2.38, wps=1100.6, ups=0.58, wpb=1902.7, bsz=56, num_updates=3290, lr=2.52854e-05, gnorm=1.527, clip=100, loss_scale=256, train_wall=17, gb_free=12.1, wall=5676
2023-06-27 17:53:31 - progress_bar.py[line:272] - INFO: epoch 004:    334 / 990 loss=2.402, loss_v1=0, loss_v2=0, nll_loss=1.207, ntokens=1878.2, nsentences=56, sample_size=1878.2, sample_size_v1=0, sample_size_v2=0, ppl=2.31, wps=1092.6, ups=0.58, wpb=1878.2, bsz=56, num_updates=3300, lr=2.52653e-05, gnorm=1.573, clip=100, loss_scale=256, train_wall=17, gb_free=12.8, wall=5694
2023-06-27 17:53:48 - progress_bar.py[line:272] - INFO: epoch 004:    344 / 990 loss=2.425, loss_v1=0, loss_v2=0, nll_loss=1.229, ntokens=1902.3, nsentences=56, sample_size=1902.3, sample_size_v1=0, sample_size_v2=0, ppl=2.34, wps=1100.5, ups=0.58, wpb=1902.3, bsz=56, num_updates=3310, lr=2.52451e-05, gnorm=1.586, clip=100, loss_scale=256, train_wall=17, gb_free=12.8, wall=5711
2023-06-27 17:54:05 - progress_bar.py[line:272] - INFO: epoch 004:    354 / 990 loss=2.393, loss_v1=0, loss_v2=0, nll_loss=1.197, ntokens=1883.9, nsentences=56, sample_size=1883.9, sample_size_v1=0, sample_size_v2=0, ppl=2.29, wps=1094.2, ups=0.58, wpb=1883.9, bsz=56, num_updates=3320, lr=2.5225e-05, gnorm=1.514, clip=100, loss_scale=256, train_wall=17, gb_free=11.7, wall=5728
2023-06-27 17:54:23 - progress_bar.py[line:272] - INFO: epoch 004:    364 / 990 loss=2.441, loss_v1=0, loss_v2=0, nll_loss=1.248, ntokens=1743.6, nsentences=56, sample_size=1743.6, sample_size_v1=0, sample_size_v2=0, ppl=2.37, wps=1020.7, ups=0.59, wpb=1743.6, bsz=56, num_updates=3330, lr=2.52048e-05, gnorm=1.51, clip=100, loss_scale=256, train_wall=17, gb_free=12.5, wall=5745
2023-06-27 17:54:40 - progress_bar.py[line:272] - INFO: epoch 004:    374 / 990 loss=2.443, loss_v1=0, loss_v2=0, nll_loss=1.25, ntokens=1801.2, nsentences=56, sample_size=1801.2, sample_size_v1=0, sample_size_v2=0, ppl=2.38, wps=1056.6, ups=0.59, wpb=1801.2, bsz=56, num_updates=3340, lr=2.51847e-05, gnorm=1.707, clip=100, loss_scale=256, train_wall=17, gb_free=12.8, wall=5762
2023-06-27 17:54:57 - progress_bar.py[line:272] - INFO: epoch 004:    384 / 990 loss=2.396, loss_v1=0, loss_v2=0, nll_loss=1.201, ntokens=1857.3, nsentences=56, sample_size=1857.3, sample_size_v1=0, sample_size_v2=0, ppl=2.3, wps=1086.8, ups=0.59, wpb=1857.3, bsz=56, num_updates=3350, lr=2.51645e-05, gnorm=1.517, clip=100, loss_scale=512, train_wall=17, gb_free=12.5, wall=5779
2023-06-27 17:55:14 - progress_bar.py[line:272] - INFO: epoch 004:    394 / 990 loss=2.41, loss_v1=0, loss_v2=0, nll_loss=1.214, ntokens=1712, nsentences=56, sample_size=1712, sample_size_v1=0, sample_size_v2=0, ppl=2.32, wps=1003, ups=0.59, wpb=1712, bsz=56, num_updates=3360, lr=2.51444e-05, gnorm=1.559, clip=100, loss_scale=512, train_wall=17, gb_free=12.7, wall=5796
2023-06-27 17:55:17 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 256.0
2023-06-27 17:55:32 - progress_bar.py[line:272] - INFO: epoch 004:    405 / 990 loss=2.447, loss_v1=0, loss_v2=0, nll_loss=1.253, ntokens=1732, nsentences=56, sample_size=1732, sample_size_v1=0, sample_size_v2=0, ppl=2.38, wps=927.4, ups=0.54, wpb=1732, bsz=56, num_updates=3370, lr=2.51242e-05, gnorm=1.605, clip=100, loss_scale=256, train_wall=19, gb_free=12.9, wall=5815
2023-06-27 17:55:49 - progress_bar.py[line:272] - INFO: epoch 004:    415 / 990 loss=2.438, loss_v1=0, loss_v2=0, nll_loss=1.246, ntokens=1745.2, nsentences=56, sample_size=1745.2, sample_size_v1=0, sample_size_v2=0, ppl=2.37, wps=1022.7, ups=0.59, wpb=1745.2, bsz=56, num_updates=3380, lr=2.51041e-05, gnorm=1.673, clip=100, loss_scale=256, train_wall=17, gb_free=12.7, wall=5832
2023-06-27 17:56:07 - progress_bar.py[line:272] - INFO: epoch 004:    425 / 990 loss=2.418, loss_v1=0, loss_v2=0, nll_loss=1.224, ntokens=1771.6, nsentences=56, sample_size=1771.6, sample_size_v1=0, sample_size_v2=0, ppl=2.34, wps=1035.2, ups=0.58, wpb=1771.6, bsz=56, num_updates=3390, lr=2.50839e-05, gnorm=1.549, clip=100, loss_scale=256, train_wall=17, gb_free=13, wall=5849
2023-06-27 17:56:24 - progress_bar.py[line:272] - INFO: epoch 004:    435 / 990 loss=2.403, loss_v1=0, loss_v2=0, nll_loss=1.206, ntokens=1932.1, nsentences=56, sample_size=1932.1, sample_size_v1=0, sample_size_v2=0, ppl=2.31, wps=1125.3, ups=0.58, wpb=1932.1, bsz=56, num_updates=3400, lr=2.50638e-05, gnorm=1.453, clip=100, loss_scale=256, train_wall=17, gb_free=12.6, wall=5866
2023-06-27 17:56:41 - progress_bar.py[line:272] - INFO: epoch 004:    445 / 990 loss=2.401, loss_v1=0, loss_v2=0, nll_loss=1.206, ntokens=1821, nsentences=56, sample_size=1821, sample_size_v1=0, sample_size_v2=0, ppl=2.31, wps=1064.7, ups=0.58, wpb=1821, bsz=56, num_updates=3410, lr=2.50437e-05, gnorm=1.533, clip=100, loss_scale=256, train_wall=17, gb_free=12.3, wall=5884
2023-06-27 17:56:58 - progress_bar.py[line:272] - INFO: epoch 004:    455 / 990 loss=2.43, loss_v1=0, loss_v2=0, nll_loss=1.236, ntokens=1816.3, nsentences=56, sample_size=1816.3, sample_size_v1=0, sample_size_v2=0, ppl=2.36, wps=1065.1, ups=0.59, wpb=1816.3, bsz=56, num_updates=3420, lr=2.50235e-05, gnorm=1.779, clip=100, loss_scale=256, train_wall=17, gb_free=12.2, wall=5901
2023-06-27 17:57:15 - progress_bar.py[line:272] - INFO: epoch 004:    465 / 990 loss=2.414, loss_v1=0, loss_v2=0, nll_loss=1.22, ntokens=1798.4, nsentences=56, sample_size=1798.4, sample_size_v1=0, sample_size_v2=0, ppl=2.33, wps=1051, ups=0.58, wpb=1798.4, bsz=56, num_updates=3430, lr=2.50034e-05, gnorm=1.762, clip=100, loss_scale=256, train_wall=17, gb_free=12.5, wall=5918
2023-06-27 17:57:32 - progress_bar.py[line:272] - INFO: epoch 004:    475 / 990 loss=2.403, loss_v1=0, loss_v2=0, nll_loss=1.207, ntokens=1873.4, nsentences=56, sample_size=1873.4, sample_size_v1=0, sample_size_v2=0, ppl=2.31, wps=1087.6, ups=0.58, wpb=1873.4, bsz=56, num_updates=3440, lr=2.49832e-05, gnorm=1.476, clip=100, loss_scale=256, train_wall=17, gb_free=12.5, wall=5935
2023-06-27 17:57:49 - progress_bar.py[line:272] - INFO: epoch 004:    485 / 990 loss=2.41, loss_v1=0, loss_v2=0, nll_loss=1.215, ntokens=1852.3, nsentences=56, sample_size=1852.3, sample_size_v1=0, sample_size_v2=0, ppl=2.32, wps=1083.1, ups=0.58, wpb=1852.3, bsz=56, num_updates=3450, lr=2.49631e-05, gnorm=1.639, clip=100, loss_scale=256, train_wall=17, gb_free=12.5, wall=5952
2023-06-27 17:58:07 - progress_bar.py[line:272] - INFO: epoch 004:    495 / 990 loss=2.407, loss_v1=0, loss_v2=0, nll_loss=1.21, ntokens=1851.6, nsentences=56, sample_size=1851.6, sample_size_v1=0, sample_size_v2=0, ppl=2.31, wps=1082.4, ups=0.58, wpb=1851.6, bsz=56, num_updates=3460, lr=2.49429e-05, gnorm=1.472, clip=100, loss_scale=256, train_wall=17, gb_free=12.6, wall=5969
2023-06-27 17:58:24 - progress_bar.py[line:272] - INFO: epoch 004:    505 / 990 loss=2.446, loss_v1=0, loss_v2=0, nll_loss=1.255, ntokens=1820.3, nsentences=56, sample_size=1820.3, sample_size_v1=0, sample_size_v2=0, ppl=2.39, wps=1062.7, ups=0.58, wpb=1820.3, bsz=56, num_updates=3470, lr=2.49228e-05, gnorm=1.57, clip=100, loss_scale=256, train_wall=17, gb_free=12.3, wall=5986
2023-06-27 17:58:40 - progress_bar.py[line:272] - INFO: epoch 004:    515 / 990 loss=2.42, loss_v1=0, loss_v2=0, nll_loss=1.225, ntokens=1689.4, nsentences=54.8, sample_size=1689.4, sample_size_v1=0, sample_size_v2=0, ppl=2.34, wps=1010, ups=0.6, wpb=1689.4, bsz=54.8, num_updates=3480, lr=2.49026e-05, gnorm=1.659, clip=100, loss_scale=256, train_wall=17, gb_free=13, wall=6003
2023-06-27 17:58:58 - progress_bar.py[line:272] - INFO: epoch 004:    525 / 990 loss=2.424, loss_v1=0, loss_v2=0, nll_loss=1.23, ntokens=1905.9, nsentences=56, sample_size=1905.9, sample_size_v1=0, sample_size_v2=0, ppl=2.34, wps=1109.6, ups=0.58, wpb=1905.9, bsz=56, num_updates=3490, lr=2.48825e-05, gnorm=1.625, clip=100, loss_scale=256, train_wall=17, gb_free=12.7, wall=6020
2023-06-27 17:59:15 - progress_bar.py[line:272] - INFO: epoch 004:    535 / 990 loss=2.406, loss_v1=0, loss_v2=0, nll_loss=1.208, ntokens=1893.8, nsentences=56, sample_size=1893.8, sample_size_v1=0, sample_size_v2=0, ppl=2.31, wps=1104.1, ups=0.58, wpb=1893.8, bsz=56, num_updates=3500, lr=2.48623e-05, gnorm=1.577, clip=100, loss_scale=256, train_wall=17, gb_free=12.4, wall=6037
2023-06-27 17:59:32 - progress_bar.py[line:272] - INFO: epoch 004:    545 / 990 loss=2.42, loss_v1=0, loss_v2=0, nll_loss=1.225, ntokens=1958, nsentences=56, sample_size=1958, sample_size_v1=0, sample_size_v2=0, ppl=2.34, wps=1130.1, ups=0.58, wpb=1958, bsz=56, num_updates=3510, lr=2.48422e-05, gnorm=1.661, clip=100, loss_scale=256, train_wall=17, gb_free=12.6, wall=6055
2023-06-27 17:59:49 - progress_bar.py[line:272] - INFO: epoch 004:    555 / 990 loss=2.403, loss_v1=0, loss_v2=0, nll_loss=1.208, ntokens=1836.4, nsentences=56, sample_size=1836.4, sample_size_v1=0, sample_size_v2=0, ppl=2.31, wps=1074.3, ups=0.58, wpb=1836.4, bsz=56, num_updates=3520, lr=2.4822e-05, gnorm=1.653, clip=100, loss_scale=256, train_wall=17, gb_free=12.9, wall=6072
2023-06-27 18:00:06 - progress_bar.py[line:272] - INFO: epoch 004:    565 / 990 loss=2.383, loss_v1=0, loss_v2=0, nll_loss=1.185, ntokens=1788.1, nsentences=56, sample_size=1788.1, sample_size_v1=0, sample_size_v2=0, ppl=2.27, wps=1046.6, ups=0.59, wpb=1788.1, bsz=56, num_updates=3530, lr=2.48019e-05, gnorm=1.636, clip=100, loss_scale=256, train_wall=17, gb_free=12.7, wall=6089
2023-06-27 18:00:23 - progress_bar.py[line:272] - INFO: epoch 004:    575 / 990 loss=2.421, loss_v1=0, loss_v2=0, nll_loss=1.225, ntokens=1841.8, nsentences=56, sample_size=1841.8, sample_size_v1=0, sample_size_v2=0, ppl=2.34, wps=1083.2, ups=0.59, wpb=1841.8, bsz=56, num_updates=3540, lr=2.47817e-05, gnorm=1.625, clip=100, loss_scale=256, train_wall=17, gb_free=12.8, wall=6106
2023-06-27 18:00:40 - progress_bar.py[line:272] - INFO: epoch 004:    585 / 990 loss=2.437, loss_v1=0, loss_v2=0, nll_loss=1.244, ntokens=1880.7, nsentences=56, sample_size=1880.7, sample_size_v1=0, sample_size_v2=0, ppl=2.37, wps=1102.9, ups=0.59, wpb=1880.7, bsz=56, num_updates=3550, lr=2.47616e-05, gnorm=1.591, clip=100, loss_scale=256, train_wall=17, gb_free=12.6, wall=6123
2023-06-27 18:00:57 - progress_bar.py[line:272] - INFO: epoch 004:    595 / 990 loss=2.402, loss_v1=0, loss_v2=0, nll_loss=1.206, ntokens=1899.2, nsentences=56, sample_size=1899.2, sample_size_v1=0, sample_size_v2=0, ppl=2.31, wps=1109.4, ups=0.58, wpb=1899.2, bsz=56, num_updates=3560, lr=2.47414e-05, gnorm=1.539, clip=100, loss_scale=256, train_wall=17, gb_free=12.8, wall=6140
2023-06-27 18:01:14 - progress_bar.py[line:272] - INFO: epoch 004:    605 / 990 loss=2.42, loss_v1=0, loss_v2=0, nll_loss=1.225, ntokens=1726.9, nsentences=56, sample_size=1726.9, sample_size_v1=0, sample_size_v2=0, ppl=2.34, wps=1013.8, ups=0.59, wpb=1726.9, bsz=56, num_updates=3570, lr=2.47213e-05, gnorm=1.67, clip=100, loss_scale=256, train_wall=17, gb_free=12.6, wall=6157
2023-06-27 18:01:31 - progress_bar.py[line:272] - INFO: epoch 004:    615 / 990 loss=2.4, loss_v1=0, loss_v2=0, nll_loss=1.202, ntokens=1854.5, nsentences=56, sample_size=1854.5, sample_size_v1=0, sample_size_v2=0, ppl=2.3, wps=1088.5, ups=0.59, wpb=1854.5, bsz=56, num_updates=3580, lr=2.47011e-05, gnorm=1.595, clip=100, loss_scale=256, train_wall=17, gb_free=12.5, wall=6174
2023-06-27 18:01:49 - progress_bar.py[line:272] - INFO: epoch 004:    625 / 990 loss=2.428, loss_v1=0, loss_v2=0, nll_loss=1.235, ntokens=2030.1, nsentences=56, sample_size=2030.1, sample_size_v1=0, sample_size_v2=0, ppl=2.35, wps=1185.8, ups=0.58, wpb=2030.1, bsz=56, num_updates=3590, lr=2.4681e-05, gnorm=1.525, clip=100, loss_scale=256, train_wall=17, gb_free=12.6, wall=6191
2023-06-27 18:02:06 - progress_bar.py[line:272] - INFO: epoch 004:    635 / 990 loss=2.433, loss_v1=0, loss_v2=0, nll_loss=1.24, ntokens=2005.1, nsentences=56, sample_size=2005.1, sample_size_v1=0, sample_size_v2=0, ppl=2.36, wps=1162.4, ups=0.58, wpb=2005.1, bsz=56, num_updates=3600, lr=2.46608e-05, gnorm=1.681, clip=100, loss_scale=256, train_wall=17, gb_free=12.8, wall=6209
2023-06-27 18:02:23 - progress_bar.py[line:272] - INFO: epoch 004:    645 / 990 loss=2.413, loss_v1=0, loss_v2=0, nll_loss=1.218, ntokens=1999.9, nsentences=56, sample_size=1999.9, sample_size_v1=0, sample_size_v2=0, ppl=2.33, wps=1162.3, ups=0.58, wpb=1999.9, bsz=56, num_updates=3610, lr=2.46407e-05, gnorm=1.562, clip=100, loss_scale=256, train_wall=17, gb_free=12.1, wall=6226
2023-06-27 18:02:40 - progress_bar.py[line:272] - INFO: epoch 004:    655 / 990 loss=2.42, loss_v1=0, loss_v2=0, nll_loss=1.225, ntokens=1916.2, nsentences=56, sample_size=1916.2, sample_size_v1=0, sample_size_v2=0, ppl=2.34, wps=1104.3, ups=0.58, wpb=1916.2, bsz=56, num_updates=3620, lr=2.46206e-05, gnorm=1.525, clip=100, loss_scale=256, train_wall=17, gb_free=12.2, wall=6243
2023-06-27 18:02:58 - progress_bar.py[line:272] - INFO: epoch 004:    665 / 990 loss=2.417, loss_v1=0, loss_v2=0, nll_loss=1.222, ntokens=1866.1, nsentences=56, sample_size=1866.1, sample_size_v1=0, sample_size_v2=0, ppl=2.33, wps=1089.8, ups=0.58, wpb=1866.1, bsz=56, num_updates=3630, lr=2.46004e-05, gnorm=1.599, clip=100, loss_scale=256, train_wall=17, gb_free=12.7, wall=6260
2023-06-27 18:03:15 - progress_bar.py[line:272] - INFO: epoch 004:    675 / 990 loss=2.422, loss_v1=0, loss_v2=0, nll_loss=1.227, ntokens=1768.2, nsentences=56, sample_size=1768.2, sample_size_v1=0, sample_size_v2=0, ppl=2.34, wps=1034.4, ups=0.58, wpb=1768.2, bsz=56, num_updates=3640, lr=2.45803e-05, gnorm=1.718, clip=100, loss_scale=256, train_wall=17, gb_free=12.9, wall=6277
2023-06-27 18:03:32 - progress_bar.py[line:272] - INFO: epoch 004:    685 / 990 loss=2.356, loss_v1=0, loss_v2=0, nll_loss=1.156, ntokens=1911.4, nsentences=56, sample_size=1911.4, sample_size_v1=0, sample_size_v2=0, ppl=2.23, wps=1108.7, ups=0.58, wpb=1911.4, bsz=56, num_updates=3650, lr=2.45601e-05, gnorm=1.647, clip=100, loss_scale=256, train_wall=17, gb_free=12.6, wall=6295
2023-06-27 18:03:49 - progress_bar.py[line:272] - INFO: epoch 004:    695 / 990 loss=2.411, loss_v1=0, loss_v2=0, nll_loss=1.214, ntokens=1738.9, nsentences=56, sample_size=1738.9, sample_size_v1=0, sample_size_v2=0, ppl=2.32, wps=1018.1, ups=0.59, wpb=1738.9, bsz=56, num_updates=3660, lr=2.454e-05, gnorm=1.933, clip=100, loss_scale=256, train_wall=17, gb_free=12.9, wall=6312
2023-06-27 18:04:06 - progress_bar.py[line:272] - INFO: epoch 004:    705 / 990 loss=2.43, loss_v1=0, loss_v2=0, nll_loss=1.234, ntokens=1723, nsentences=56, sample_size=1723, sample_size_v1=0, sample_size_v2=0, ppl=2.35, wps=1009.8, ups=0.59, wpb=1723, bsz=56, num_updates=3670, lr=2.45198e-05, gnorm=1.808, clip=100, loss_scale=256, train_wall=17, gb_free=12.6, wall=6329
2023-06-27 18:04:23 - progress_bar.py[line:272] - INFO: epoch 004:    715 / 990 loss=2.399, loss_v1=0, loss_v2=0, nll_loss=1.204, ntokens=1807.7, nsentences=56, sample_size=1807.7, sample_size_v1=0, sample_size_v2=0, ppl=2.3, wps=1060.4, ups=0.59, wpb=1807.7, bsz=56, num_updates=3680, lr=2.44997e-05, gnorm=1.771, clip=100, loss_scale=256, train_wall=17, gb_free=12.6, wall=6346
2023-06-27 18:04:40 - progress_bar.py[line:272] - INFO: epoch 004:    725 / 990 loss=2.39, loss_v1=0, loss_v2=0, nll_loss=1.191, ntokens=1765.3, nsentences=56, sample_size=1765.3, sample_size_v1=0, sample_size_v2=0, ppl=2.28, wps=1038.4, ups=0.59, wpb=1765.3, bsz=56, num_updates=3690, lr=2.44795e-05, gnorm=1.826, clip=100, loss_scale=256, train_wall=17, gb_free=13.1, wall=6363
2023-06-27 18:04:57 - progress_bar.py[line:272] - INFO: epoch 004:    735 / 990 loss=2.387, loss_v1=0, loss_v2=0, nll_loss=1.188, ntokens=1849.9, nsentences=56, sample_size=1849.9, sample_size_v1=0, sample_size_v2=0, ppl=2.28, wps=1084, ups=0.59, wpb=1849.9, bsz=56, num_updates=3700, lr=2.44594e-05, gnorm=1.668, clip=100, loss_scale=256, train_wall=17, gb_free=13, wall=6380
2023-06-27 18:05:14 - progress_bar.py[line:272] - INFO: epoch 004:    745 / 990 loss=2.424, loss_v1=0, loss_v2=0, nll_loss=1.229, ntokens=1743.8, nsentences=56, sample_size=1743.8, sample_size_v1=0, sample_size_v2=0, ppl=2.34, wps=1023.7, ups=0.59, wpb=1743.8, bsz=56, num_updates=3710, lr=2.44392e-05, gnorm=1.766, clip=100, loss_scale=256, train_wall=17, gb_free=13.3, wall=6397
2023-06-27 18:05:31 - progress_bar.py[line:272] - INFO: epoch 004:    755 / 990 loss=2.443, loss_v1=0, loss_v2=0, nll_loss=1.253, ntokens=1670.3, nsentences=56, sample_size=1670.3, sample_size_v1=0, sample_size_v2=0, ppl=2.38, wps=983.9, ups=0.59, wpb=1670.3, bsz=56, num_updates=3720, lr=2.44191e-05, gnorm=1.897, clip=100, loss_scale=256, train_wall=17, gb_free=13.2, wall=6414
2023-06-27 18:05:48 - progress_bar.py[line:272] - INFO: epoch 004:    765 / 990 loss=2.409, loss_v1=0, loss_v2=0, nll_loss=1.212, ntokens=1746.4, nsentences=56, sample_size=1746.4, sample_size_v1=0, sample_size_v2=0, ppl=2.32, wps=1027.4, ups=0.59, wpb=1746.4, bsz=56, num_updates=3730, lr=2.43989e-05, gnorm=1.714, clip=100, loss_scale=256, train_wall=17, gb_free=13, wall=6431
2023-06-27 18:06:05 - progress_bar.py[line:272] - INFO: epoch 004:    775 / 990 loss=2.406, loss_v1=0, loss_v2=0, nll_loss=1.21, ntokens=1857, nsentences=56, sample_size=1857, sample_size_v1=0, sample_size_v2=0, ppl=2.31, wps=1085.1, ups=0.58, wpb=1857, bsz=56, num_updates=3740, lr=2.43788e-05, gnorm=1.724, clip=100, loss_scale=256, train_wall=17, gb_free=12.8, wall=6448
2023-06-27 18:06:22 - progress_bar.py[line:272] - INFO: epoch 004:    785 / 990 loss=2.403, loss_v1=0, loss_v2=0, nll_loss=1.209, ntokens=1747.4, nsentences=56, sample_size=1747.4, sample_size_v1=0, sample_size_v2=0, ppl=2.31, wps=1027.5, ups=0.59, wpb=1747.4, bsz=56, num_updates=3750, lr=2.43586e-05, gnorm=1.805, clip=100, loss_scale=256, train_wall=17, gb_free=12.4, wall=6465
2023-06-27 18:06:39 - progress_bar.py[line:272] - INFO: epoch 004:    795 / 990 loss=2.413, loss_v1=0, loss_v2=0, nll_loss=1.216, ntokens=1857.3, nsentences=56, sample_size=1857.3, sample_size_v1=0, sample_size_v2=0, ppl=2.32, wps=1084.5, ups=0.58, wpb=1857.3, bsz=56, num_updates=3760, lr=2.43385e-05, gnorm=1.751, clip=100, loss_scale=256, train_wall=17, gb_free=12.9, wall=6482
2023-06-27 18:06:56 - progress_bar.py[line:272] - INFO: epoch 004:    805 / 990 loss=2.415, loss_v1=0, loss_v2=0, nll_loss=1.219, ntokens=1765, nsentences=56, sample_size=1765, sample_size_v1=0, sample_size_v2=0, ppl=2.33, wps=1036, ups=0.59, wpb=1765, bsz=56, num_updates=3770, lr=2.43183e-05, gnorm=1.812, clip=100, loss_scale=256, train_wall=17, gb_free=13, wall=6499
2023-06-27 18:07:13 - progress_bar.py[line:272] - INFO: epoch 004:    815 / 990 loss=2.426, loss_v1=0, loss_v2=0, nll_loss=1.235, ntokens=1642.6, nsentences=56, sample_size=1642.6, sample_size_v1=0, sample_size_v2=0, ppl=2.35, wps=967.8, ups=0.59, wpb=1642.6, bsz=56, num_updates=3780, lr=2.42982e-05, gnorm=2.029, clip=100, loss_scale=256, train_wall=17, gb_free=12.8, wall=6516
2023-06-27 18:07:31 - progress_bar.py[line:272] - INFO: epoch 004:    825 / 990 loss=2.4, loss_v1=0, loss_v2=0, nll_loss=1.204, ntokens=1720.2, nsentences=56, sample_size=1720.2, sample_size_v1=0, sample_size_v2=0, ppl=2.3, wps=1006.7, ups=0.59, wpb=1720.2, bsz=56, num_updates=3790, lr=2.4278e-05, gnorm=1.835, clip=100, loss_scale=256, train_wall=17, gb_free=12.9, wall=6533
2023-06-27 18:07:48 - progress_bar.py[line:272] - INFO: epoch 004:    835 / 990 loss=2.384, loss_v1=0, loss_v2=0, nll_loss=1.184, ntokens=1750.5, nsentences=56, sample_size=1750.5, sample_size_v1=0, sample_size_v2=0, ppl=2.27, wps=1031.5, ups=0.59, wpb=1750.5, bsz=56, num_updates=3800, lr=2.42579e-05, gnorm=1.735, clip=100, loss_scale=256, train_wall=17, gb_free=13.2, wall=6550
2023-06-27 18:08:05 - progress_bar.py[line:272] - INFO: epoch 004:    845 / 990 loss=2.394, loss_v1=0, loss_v2=0, nll_loss=1.195, ntokens=1877.1, nsentences=56, sample_size=1877.1, sample_size_v1=0, sample_size_v2=0, ppl=2.29, wps=1096.2, ups=0.58, wpb=1877.1, bsz=56, num_updates=3810, lr=2.42377e-05, gnorm=1.718, clip=100, loss_scale=256, train_wall=17, gb_free=12.8, wall=6567
2023-06-27 18:08:22 - progress_bar.py[line:272] - INFO: epoch 004:    855 / 990 loss=2.37, loss_v1=0, loss_v2=0, nll_loss=1.171, ntokens=1886, nsentences=56, sample_size=1886, sample_size_v1=0, sample_size_v2=0, ppl=2.25, wps=1094.2, ups=0.58, wpb=1886, bsz=56, num_updates=3820, lr=2.42176e-05, gnorm=1.695, clip=100, loss_scale=256, train_wall=17, gb_free=12.7, wall=6585
2023-06-27 18:08:39 - progress_bar.py[line:272] - INFO: epoch 004:    865 / 990 loss=2.377, loss_v1=0, loss_v2=0, nll_loss=1.178, ntokens=1805.6, nsentences=56, sample_size=1805.6, sample_size_v1=0, sample_size_v2=0, ppl=2.26, wps=1058.5, ups=0.59, wpb=1805.6, bsz=56, num_updates=3830, lr=2.41974e-05, gnorm=1.771, clip=100, loss_scale=256, train_wall=17, gb_free=12.6, wall=6602
2023-06-27 18:08:56 - progress_bar.py[line:272] - INFO: epoch 004:    875 / 990 loss=2.39, loss_v1=0, loss_v2=0, nll_loss=1.193, ntokens=1858.2, nsentences=56, sample_size=1858.2, sample_size_v1=0, sample_size_v2=0, ppl=2.29, wps=1086.2, ups=0.58, wpb=1858.2, bsz=56, num_updates=3840, lr=2.41773e-05, gnorm=1.822, clip=100, loss_scale=256, train_wall=17, gb_free=12.7, wall=6619
2023-06-27 18:09:13 - progress_bar.py[line:272] - INFO: epoch 004:    885 / 990 loss=2.384, loss_v1=0, loss_v2=0, nll_loss=1.184, ntokens=1916.4, nsentences=56, sample_size=1916.4, sample_size_v1=0, sample_size_v2=0, ppl=2.27, wps=1121.8, ups=0.59, wpb=1916.4, bsz=56, num_updates=3850, lr=2.41572e-05, gnorm=1.78, clip=100, loss_scale=256, train_wall=17, gb_free=12.5, wall=6636
2023-06-27 18:09:30 - progress_bar.py[line:272] - INFO: epoch 004:    895 / 990 loss=2.383, loss_v1=0, loss_v2=0, nll_loss=1.184, ntokens=1930, nsentences=56, sample_size=1930, sample_size_v1=0, sample_size_v2=0, ppl=2.27, wps=1126.7, ups=0.58, wpb=1930, bsz=56, num_updates=3860, lr=2.4137e-05, gnorm=1.711, clip=100, loss_scale=256, train_wall=17, gb_free=12.7, wall=6653
2023-06-27 18:09:47 - progress_bar.py[line:272] - INFO: epoch 004:    905 / 990 loss=2.413, loss_v1=0, loss_v2=0, nll_loss=1.218, ntokens=1740.4, nsentences=56, sample_size=1740.4, sample_size_v1=0, sample_size_v2=0, ppl=2.33, wps=1020.5, ups=0.59, wpb=1740.4, bsz=56, num_updates=3870, lr=2.41169e-05, gnorm=1.842, clip=100, loss_scale=256, train_wall=17, gb_free=13, wall=6670
2023-06-27 18:09:54 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 256.0
2023-06-27 18:10:06 - progress_bar.py[line:272] - INFO: epoch 004:    916 / 990 loss=2.395, loss_v1=0, loss_v2=0, nll_loss=1.195, ntokens=1743, nsentences=56, sample_size=1743, sample_size_v1=0, sample_size_v2=0, ppl=2.29, wps=937, ups=0.54, wpb=1743, bsz=56, num_updates=3880, lr=2.40967e-05, gnorm=1.904, clip=100, loss_scale=256, train_wall=19, gb_free=12.2, wall=6689
2023-06-27 18:10:23 - progress_bar.py[line:272] - INFO: epoch 004:    926 / 990 loss=2.378, loss_v1=0, loss_v2=0, nll_loss=1.18, ntokens=1796.9, nsentences=56, sample_size=1796.9, sample_size_v1=0, sample_size_v2=0, ppl=2.27, wps=1052.4, ups=0.59, wpb=1796.9, bsz=56, num_updates=3890, lr=2.40766e-05, gnorm=1.739, clip=100, loss_scale=256, train_wall=17, gb_free=13, wall=6706
2023-06-27 18:10:40 - progress_bar.py[line:272] - INFO: epoch 004:    936 / 990 loss=2.379, loss_v1=0, loss_v2=0, nll_loss=1.18, ntokens=1821, nsentences=56, sample_size=1821, sample_size_v1=0, sample_size_v2=0, ppl=2.27, wps=1054.9, ups=0.58, wpb=1821, bsz=56, num_updates=3900, lr=2.40564e-05, gnorm=1.749, clip=100, loss_scale=256, train_wall=17, gb_free=12.8, wall=6723
2023-06-27 18:10:57 - progress_bar.py[line:272] - INFO: epoch 004:    946 / 990 loss=2.386, loss_v1=0, loss_v2=0, nll_loss=1.188, ntokens=1920.2, nsentences=56, sample_size=1920.2, sample_size_v1=0, sample_size_v2=0, ppl=2.28, wps=1117.5, ups=0.58, wpb=1920.2, bsz=56, num_updates=3910, lr=2.40363e-05, gnorm=1.651, clip=100, loss_scale=256, train_wall=17, gb_free=12.8, wall=6740
2023-06-27 18:11:15 - progress_bar.py[line:272] - INFO: epoch 004:    956 / 990 loss=2.387, loss_v1=0, loss_v2=0, nll_loss=1.187, ntokens=1904.3, nsentences=56, sample_size=1904.3, sample_size_v1=0, sample_size_v2=0, ppl=2.28, wps=1114, ups=0.58, wpb=1904.3, bsz=56, num_updates=3920, lr=2.40161e-05, gnorm=1.65, clip=100, loss_scale=256, train_wall=17, gb_free=13.2, wall=6757
2023-06-27 18:11:32 - progress_bar.py[line:272] - INFO: epoch 004:    966 / 990 loss=2.392, loss_v1=0, loss_v2=0, nll_loss=1.196, ntokens=1897.3, nsentences=56, sample_size=1897.3, sample_size_v1=0, sample_size_v2=0, ppl=2.29, wps=1103.8, ups=0.58, wpb=1897.3, bsz=56, num_updates=3930, lr=2.3996e-05, gnorm=1.673, clip=100, loss_scale=256, train_wall=17, gb_free=12.4, wall=6774
2023-06-27 18:11:49 - progress_bar.py[line:272] - INFO: epoch 004:    976 / 990 loss=2.38, loss_v1=0, loss_v2=0, nll_loss=1.179, ntokens=1907.1, nsentences=56, sample_size=1907.1, sample_size_v1=0, sample_size_v2=0, ppl=2.26, wps=1108.1, ups=0.58, wpb=1907.1, bsz=56, num_updates=3940, lr=2.39758e-05, gnorm=1.582, clip=100, loss_scale=256, train_wall=17, gb_free=12.7, wall=6792
2023-06-27 18:12:06 - progress_bar.py[line:272] - INFO: epoch 004:    986 / 990 loss=2.415, loss_v1=0, loss_v2=0, nll_loss=1.22, ntokens=1789.1, nsentences=56, sample_size=1789.1, sample_size_v1=0, sample_size_v2=0, ppl=2.33, wps=1049.9, ups=0.59, wpb=1789.1, bsz=56, num_updates=3950, lr=2.39557e-05, gnorm=1.812, clip=100, loss_scale=256, train_wall=17, gb_free=12.9, wall=6809
local datafile ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 1 begin to initialize row_count and line_idx-to-offset mapping
2023-06-27 18:12:12 - checkpoint_utils.py[line:64] - INFO: Preparing to save checkpoint for epoch 4 @ 3954 updates
2023-06-27 18:12:12 - trainer.py[line:431] - INFO: Saving checkpoint to ../../checkpoints/OFA/sgcls_checkpoints/_16_3e-5_512_base/checkpoint4.pt
local datafile ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 1 finished initializing row_count and line_idx-to-offset mapping
file ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 1 row count 27700 total row count 55400
slice_id 1 seek offset 27700
2023-06-27 18:12:18 - trainer.py[line:441] - INFO: Finished saving checkpoint to ../../checkpoints/OFA/sgcls_checkpoints/_16_3e-5_512_base/checkpoint4.pt
2023-06-27 18:12:23 - checkpoint_utils.py[line:133] - INFO: Saved checkpoint ../../checkpoints/OFA/sgcls_checkpoints/_16_3e-5_512_base/checkpoint4.pt (epoch 4 @ 3954 updates, score None) (writing took 11.071494058705866 seconds)
2023-06-27 18:12:23 - train.py[line:332] - INFO: end of epoch 4 (average epoch stats below)
2023-06-27 18:12:23 - progress_bar.py[line:282] - INFO: epoch 004 | loss 2.395 | loss_v1 0 | loss_v2 0 | nll_loss 1.198 | ntokens 1849.76 | nsentences 55.96 | sample_size 1849.76 | sample_size_v1 0 | sample_size_v2 0 | ppl 2.29 | wps 1067 | ups 0.58 | wpb 1849.8 | bsz 56 | num_updates 3954 | lr 2.39476e-05 | gnorm 1.619 | clip 99.7 | loss_scale 256 | train_wall 1696 | gb_free 13.3 | wall 6826
2023-06-27 18:12:23 - trainer.py[line:639] - INFO: loading train data for epoch 5
local datafile ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 0 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 0 finished initializing row_count and line_idx-to-offset mapping
file ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 0 row count 27700 total row count 55400
slice_id 0 seek offset 0
2023-06-27 18:12:25 - trainer.py[line:703] - INFO: begin training epoch 5
2023-06-27 18:12:25 - train.py[line:305] - INFO: Start iterating over samples
2023-06-27 18:12:36 - progress_bar.py[line:272] - INFO: epoch 005:      6 / 990 loss=2.375, loss_v1=0, loss_v2=0, nll_loss=1.174, ntokens=1797.7, nsentences=53.2, sample_size=1797.7, sample_size_v1=0, sample_size_v2=0, ppl=2.26, wps=604.9, ups=0.34, wpb=1797.7, bsz=53.2, num_updates=3960, lr=2.39355e-05, gnorm=1.9, clip=100, loss_scale=256, train_wall=16, gb_free=12.5, wall=6838
2023-06-27 18:12:53 - progress_bar.py[line:272] - INFO: epoch 005:     16 / 990 loss=2.351, loss_v1=0, loss_v2=0, nll_loss=1.149, ntokens=1823.1, nsentences=56, sample_size=1823.1, sample_size_v1=0, sample_size_v2=0, ppl=2.22, wps=1053.9, ups=0.58, wpb=1823.1, bsz=56, num_updates=3970, lr=2.39154e-05, gnorm=1.694, clip=100, loss_scale=256, train_wall=17, gb_free=12, wall=6856
2023-06-27 18:13:10 - progress_bar.py[line:272] - INFO: epoch 005:     26 / 990 loss=2.308, loss_v1=0, loss_v2=0, nll_loss=1.098, ntokens=1790.4, nsentences=56, sample_size=1790.4, sample_size_v1=0, sample_size_v2=0, ppl=2.14, wps=1041.7, ups=0.58, wpb=1790.4, bsz=56, num_updates=3980, lr=2.38952e-05, gnorm=1.826, clip=100, loss_scale=256, train_wall=17, gb_free=12.9, wall=6873
2023-06-27 18:13:27 - progress_bar.py[line:272] - INFO: epoch 005:     36 / 990 loss=2.326, loss_v1=0, loss_v2=0, nll_loss=1.121, ntokens=1793.5, nsentences=56, sample_size=1793.5, sample_size_v1=0, sample_size_v2=0, ppl=2.18, wps=1047.1, ups=0.58, wpb=1793.5, bsz=56, num_updates=3990, lr=2.38751e-05, gnorm=1.787, clip=100, loss_scale=256, train_wall=17, gb_free=12.5, wall=6890
2023-06-27 18:13:45 - progress_bar.py[line:272] - INFO: epoch 005:     46 / 990 loss=2.256, loss_v1=0, loss_v2=0, nll_loss=1.042, ntokens=1977.1, nsentences=56, sample_size=1977.1, sample_size_v1=0, sample_size_v2=0, ppl=2.06, wps=1132.2, ups=0.57, wpb=1977.1, bsz=56, num_updates=4000, lr=2.38549e-05, gnorm=1.561, clip=100, loss_scale=256, train_wall=17, gb_free=12.6, wall=6908
2023-06-27 18:14:02 - progress_bar.py[line:272] - INFO: epoch 005:     56 / 990 loss=2.351, loss_v1=0, loss_v2=0, nll_loss=1.148, ntokens=1753.7, nsentences=56, sample_size=1753.7, sample_size_v1=0, sample_size_v2=0, ppl=2.22, wps=1016.1, ups=0.58, wpb=1753.7, bsz=56, num_updates=4010, lr=2.38348e-05, gnorm=1.935, clip=100, loss_scale=256, train_wall=17, gb_free=11.9, wall=6925
2023-06-27 18:14:19 - progress_bar.py[line:272] - INFO: epoch 005:     66 / 990 loss=2.238, loss_v1=0, loss_v2=0, nll_loss=1.023, ntokens=1771.6, nsentences=56, sample_size=1771.6, sample_size_v1=0, sample_size_v2=0, ppl=2.03, wps=1035.1, ups=0.58, wpb=1771.6, bsz=56, num_updates=4020, lr=2.38146e-05, gnorm=1.952, clip=100, loss_scale=256, train_wall=17, gb_free=12.6, wall=6942
2023-06-27 18:14:37 - progress_bar.py[line:272] - INFO: epoch 005:     76 / 990 loss=2.184, loss_v1=0, loss_v2=0, nll_loss=0.961, ntokens=2157.8, nsentences=56, sample_size=2157.8, sample_size_v1=0, sample_size_v2=0, ppl=1.95, wps=1221.6, ups=0.57, wpb=2157.8, bsz=56, num_updates=4030, lr=2.37945e-05, gnorm=1.603, clip=100, loss_scale=256, train_wall=18, gb_free=11.3, wall=6960
2023-06-27 18:14:55 - progress_bar.py[line:272] - INFO: epoch 005:     86 / 990 loss=2.268, loss_v1=0, loss_v2=0, nll_loss=1.054, ntokens=2145.4, nsentences=56, sample_size=2145.4, sample_size_v1=0, sample_size_v2=0, ppl=2.08, wps=1211.4, ups=0.56, wpb=2145.4, bsz=56, num_updates=4040, lr=2.37743e-05, gnorm=1.473, clip=100, loss_scale=256, train_wall=18, gb_free=11.4, wall=6977
2023-06-27 18:15:12 - progress_bar.py[line:272] - INFO: epoch 005:     96 / 990 loss=2.303, loss_v1=0, loss_v2=0, nll_loss=1.097, ntokens=1944, nsentences=56, sample_size=1944, sample_size_v1=0, sample_size_v2=0, ppl=2.14, wps=1114.9, ups=0.57, wpb=1944, bsz=56, num_updates=4050, lr=2.37542e-05, gnorm=1.874, clip=100, loss_scale=256, train_wall=17, gb_free=11.7, wall=6995
2023-06-27 18:15:29 - progress_bar.py[line:272] - INFO: epoch 005:    106 / 990 loss=2.281, loss_v1=0, loss_v2=0, nll_loss=1.069, ntokens=1925.1, nsentences=56, sample_size=1925.1, sample_size_v1=0, sample_size_v2=0, ppl=2.1, wps=1115.7, ups=0.58, wpb=1925.1, bsz=56, num_updates=4060, lr=2.3734e-05, gnorm=1.596, clip=100, loss_scale=256, train_wall=17, gb_free=12, wall=7012
2023-06-27 18:15:46 - progress_bar.py[line:272] - INFO: epoch 005:    116 / 990 loss=2.377, loss_v1=0, loss_v2=0, nll_loss=1.178, ntokens=1750.2, nsentences=56, sample_size=1750.2, sample_size_v1=0, sample_size_v2=0, ppl=2.26, wps=1022, ups=0.58, wpb=1750.2, bsz=56, num_updates=4070, lr=2.37139e-05, gnorm=1.915, clip=100, loss_scale=256, train_wall=17, gb_free=12.4, wall=7029
2023-06-27 18:16:04 - progress_bar.py[line:272] - INFO: epoch 005:    126 / 990 loss=2.396, loss_v1=0, loss_v2=0, nll_loss=1.198, ntokens=1812.3, nsentences=56, sample_size=1812.3, sample_size_v1=0, sample_size_v2=0, ppl=2.29, wps=1054.1, ups=0.58, wpb=1812.3, bsz=56, num_updates=4080, lr=2.36938e-05, gnorm=1.72, clip=100, loss_scale=256, train_wall=17, gb_free=12.2, wall=7046
2023-06-27 18:16:21 - progress_bar.py[line:272] - INFO: epoch 005:    136 / 990 loss=2.364, loss_v1=0, loss_v2=0, nll_loss=1.163, ntokens=1884.6, nsentences=56, sample_size=1884.6, sample_size_v1=0, sample_size_v2=0, ppl=2.24, wps=1083.7, ups=0.58, wpb=1884.6, bsz=56, num_updates=4090, lr=2.36736e-05, gnorm=1.598, clip=100, loss_scale=256, train_wall=17, gb_free=11.1, wall=7064
2023-06-27 18:16:38 - progress_bar.py[line:272] - INFO: epoch 005:    146 / 990 loss=2.37, loss_v1=0, loss_v2=0, nll_loss=1.168, ntokens=1945.2, nsentences=56, sample_size=1945.2, sample_size_v1=0, sample_size_v2=0, ppl=2.25, wps=1116.2, ups=0.57, wpb=1945.2, bsz=56, num_updates=4100, lr=2.36535e-05, gnorm=1.662, clip=100, loss_scale=256, train_wall=17, gb_free=12.7, wall=7081
2023-06-27 18:16:56 - progress_bar.py[line:272] - INFO: epoch 005:    156 / 990 loss=2.338, loss_v1=0, loss_v2=0, nll_loss=1.133, ntokens=1970.4, nsentences=56, sample_size=1970.4, sample_size_v1=0, sample_size_v2=0, ppl=2.19, wps=1129.8, ups=0.57, wpb=1970.4, bsz=56, num_updates=4110, lr=2.36333e-05, gnorm=1.573, clip=100, loss_scale=256, train_wall=17, gb_free=12, wall=7099
2023-06-27 18:17:13 - progress_bar.py[line:272] - INFO: epoch 005:    166 / 990 loss=2.33, loss_v1=0, loss_v2=0, nll_loss=1.125, ntokens=1946, nsentences=56, sample_size=1946, sample_size_v1=0, sample_size_v2=0, ppl=2.18, wps=1114.8, ups=0.57, wpb=1946, bsz=56, num_updates=4120, lr=2.36132e-05, gnorm=1.673, clip=100, loss_scale=256, train_wall=17, gb_free=12.2, wall=7116
2023-06-27 18:17:31 - progress_bar.py[line:272] - INFO: epoch 005:    176 / 990 loss=2.335, loss_v1=0, loss_v2=0, nll_loss=1.131, ntokens=1974.8, nsentences=56, sample_size=1974.8, sample_size_v1=0, sample_size_v2=0, ppl=2.19, wps=1130.5, ups=0.57, wpb=1974.8, bsz=56, num_updates=4130, lr=2.3593e-05, gnorm=1.498, clip=100, loss_scale=256, train_wall=17, gb_free=12.1, wall=7134
2023-06-27 18:17:48 - progress_bar.py[line:272] - INFO: epoch 005:    186 / 990 loss=2.333, loss_v1=0, loss_v2=0, nll_loss=1.128, ntokens=1876.2, nsentences=56, sample_size=1876.2, sample_size_v1=0, sample_size_v2=0, ppl=2.19, wps=1081, ups=0.58, wpb=1876.2, bsz=56, num_updates=4140, lr=2.35729e-05, gnorm=1.688, clip=100, loss_scale=256, train_wall=17, gb_free=13.1, wall=7151
2023-06-27 18:18:05 - progress_bar.py[line:272] - INFO: epoch 005:    196 / 990 loss=2.349, loss_v1=0, loss_v2=0, nll_loss=1.145, ntokens=1830.9, nsentences=56, sample_size=1830.9, sample_size_v1=0, sample_size_v2=0, ppl=2.21, wps=1064.7, ups=0.58, wpb=1830.9, bsz=56, num_updates=4150, lr=2.35527e-05, gnorm=1.664, clip=100, loss_scale=256, train_wall=17, gb_free=12.4, wall=7168
2023-06-27 18:18:23 - progress_bar.py[line:272] - INFO: epoch 005:    206 / 990 loss=2.304, loss_v1=0, loss_v2=0, nll_loss=1.095, ntokens=1898.5, nsentences=56, sample_size=1898.5, sample_size_v1=0, sample_size_v2=0, ppl=2.14, wps=1090.6, ups=0.57, wpb=1898.5, bsz=56, num_updates=4160, lr=2.35326e-05, gnorm=1.753, clip=100, loss_scale=256, train_wall=17, gb_free=12.1, wall=7185
2023-06-27 18:18:40 - progress_bar.py[line:272] - INFO: epoch 005:    216 / 990 loss=2.334, loss_v1=0, loss_v2=0, nll_loss=1.128, ntokens=1940.5, nsentences=56, sample_size=1940.5, sample_size_v1=0, sample_size_v2=0, ppl=2.19, wps=1115.8, ups=0.58, wpb=1940.5, bsz=56, num_updates=4170, lr=2.35124e-05, gnorm=1.663, clip=100, loss_scale=256, train_wall=17, gb_free=12.7, wall=7203
2023-06-27 18:18:58 - progress_bar.py[line:272] - INFO: epoch 005:    226 / 990 loss=2.34, loss_v1=0, loss_v2=0, nll_loss=1.138, ntokens=1928.3, nsentences=56, sample_size=1928.3, sample_size_v1=0, sample_size_v2=0, ppl=2.2, wps=1109.5, ups=0.58, wpb=1928.3, bsz=56, num_updates=4180, lr=2.34923e-05, gnorm=1.676, clip=100, loss_scale=256, train_wall=17, gb_free=12.3, wall=7220
2023-06-27 18:19:15 - progress_bar.py[line:272] - INFO: epoch 005:    236 / 990 loss=2.394, loss_v1=0, loss_v2=0, nll_loss=1.195, ntokens=1689.4, nsentences=56, sample_size=1689.4, sample_size_v1=0, sample_size_v2=0, ppl=2.29, wps=989.6, ups=0.59, wpb=1689.4, bsz=56, num_updates=4190, lr=2.34721e-05, gnorm=1.844, clip=100, loss_scale=256, train_wall=17, gb_free=13.3, wall=7237
2023-06-27 18:19:32 - progress_bar.py[line:272] - INFO: epoch 005:    246 / 990 loss=2.397, loss_v1=0, loss_v2=0, nll_loss=1.2, ntokens=1922.3, nsentences=56, sample_size=1922.3, sample_size_v1=0, sample_size_v2=0, ppl=2.3, wps=1115.1, ups=0.58, wpb=1922.3, bsz=56, num_updates=4200, lr=2.3452e-05, gnorm=1.717, clip=100, loss_scale=256, train_wall=17, gb_free=11.9, wall=7255
2023-06-27 18:19:49 - progress_bar.py[line:272] - INFO: epoch 005:    256 / 990 loss=2.395, loss_v1=0, loss_v2=0, nll_loss=1.196, ntokens=1899.1, nsentences=56, sample_size=1899.1, sample_size_v1=0, sample_size_v2=0, ppl=2.29, wps=1109.2, ups=0.58, wpb=1899.1, bsz=56, num_updates=4210, lr=2.34318e-05, gnorm=1.624, clip=100, loss_scale=256, train_wall=17, gb_free=12.6, wall=7272
2023-06-27 18:20:06 - progress_bar.py[line:272] - INFO: epoch 005:    266 / 990 loss=2.42, loss_v1=0, loss_v2=0, nll_loss=1.226, ntokens=1876.3, nsentences=56, sample_size=1876.3, sample_size_v1=0, sample_size_v2=0, ppl=2.34, wps=1082.5, ups=0.58, wpb=1876.3, bsz=56, num_updates=4220, lr=2.34117e-05, gnorm=1.683, clip=100, loss_scale=256, train_wall=17, gb_free=13.1, wall=7289
2023-06-27 18:20:24 - progress_bar.py[line:272] - INFO: epoch 005:    276 / 990 loss=2.406, loss_v1=0, loss_v2=0, nll_loss=1.208, ntokens=1940.2, nsentences=56, sample_size=1940.2, sample_size_v1=0, sample_size_v2=0, ppl=2.31, wps=1119.1, ups=0.58, wpb=1940.2, bsz=56, num_updates=4230, lr=2.33915e-05, gnorm=1.629, clip=100, loss_scale=256, train_wall=17, gb_free=11.5, wall=7306
2023-06-27 18:20:41 - progress_bar.py[line:272] - INFO: epoch 005:    286 / 990 loss=2.414, loss_v1=0, loss_v2=0, nll_loss=1.22, ntokens=1855.2, nsentences=56, sample_size=1855.2, sample_size_v1=0, sample_size_v2=0, ppl=2.33, wps=1073.4, ups=0.58, wpb=1855.2, bsz=56, num_updates=4240, lr=2.33714e-05, gnorm=1.605, clip=100, loss_scale=256, train_wall=17, gb_free=12.6, wall=7324
2023-06-27 18:20:58 - progress_bar.py[line:272] - INFO: epoch 005:    296 / 990 loss=2.415, loss_v1=0, loss_v2=0, nll_loss=1.22, ntokens=1872, nsentences=56, sample_size=1872, sample_size_v1=0, sample_size_v2=0, ppl=2.33, wps=1091.2, ups=0.58, wpb=1872, bsz=56, num_updates=4250, lr=2.33512e-05, gnorm=1.648, clip=100, loss_scale=256, train_wall=17, gb_free=12, wall=7341
2023-06-27 18:21:15 - progress_bar.py[line:272] - INFO: epoch 005:    306 / 990 loss=2.411, loss_v1=0, loss_v2=0, nll_loss=1.214, ntokens=1886, nsentences=56, sample_size=1886, sample_size_v1=0, sample_size_v2=0, ppl=2.32, wps=1094.7, ups=0.58, wpb=1886, bsz=56, num_updates=4260, lr=2.33311e-05, gnorm=1.772, clip=100, loss_scale=256, train_wall=17, gb_free=12.5, wall=7358
2023-06-27 18:21:33 - progress_bar.py[line:272] - INFO: epoch 005:    316 / 990 loss=2.414, loss_v1=0, loss_v2=0, nll_loss=1.219, ntokens=1908.9, nsentences=56, sample_size=1908.9, sample_size_v1=0, sample_size_v2=0, ppl=2.33, wps=1110.2, ups=0.58, wpb=1908.9, bsz=56, num_updates=4270, lr=2.33109e-05, gnorm=1.703, clip=100, loss_scale=256, train_wall=17, gb_free=12, wall=7375
2023-06-27 18:21:50 - progress_bar.py[line:272] - INFO: epoch 005:    326 / 990 loss=2.407, loss_v1=0, loss_v2=0, nll_loss=1.211, ntokens=1936.7, nsentences=56, sample_size=1936.7, sample_size_v1=0, sample_size_v2=0, ppl=2.32, wps=1121.5, ups=0.58, wpb=1936.7, bsz=56, num_updates=4280, lr=2.32908e-05, gnorm=1.684, clip=100, loss_scale=256, train_wall=17, gb_free=12.1, wall=7393
2023-06-27 18:22:07 - progress_bar.py[line:272] - INFO: epoch 005:    336 / 990 loss=2.391, loss_v1=0, loss_v2=0, nll_loss=1.194, ntokens=1859.4, nsentences=56, sample_size=1859.4, sample_size_v1=0, sample_size_v2=0, ppl=2.29, wps=1080.5, ups=0.58, wpb=1859.4, bsz=56, num_updates=4290, lr=2.32707e-05, gnorm=1.728, clip=100, loss_scale=256, train_wall=17, gb_free=12.5, wall=7410
2023-06-27 18:22:24 - progress_bar.py[line:272] - INFO: epoch 005:    346 / 990 loss=2.397, loss_v1=0, loss_v2=0, nll_loss=1.198, ntokens=1868.4, nsentences=56, sample_size=1868.4, sample_size_v1=0, sample_size_v2=0, ppl=2.29, wps=1086.9, ups=0.58, wpb=1868.4, bsz=56, num_updates=4300, lr=2.32505e-05, gnorm=1.694, clip=100, loss_scale=256, train_wall=17, gb_free=12.6, wall=7427
2023-06-27 18:22:41 - progress_bar.py[line:272] - INFO: epoch 005:    356 / 990 loss=2.377, loss_v1=0, loss_v2=0, nll_loss=1.178, ntokens=1887.8, nsentences=56, sample_size=1887.8, sample_size_v1=0, sample_size_v2=0, ppl=2.26, wps=1098.7, ups=0.58, wpb=1887.8, bsz=56, num_updates=4310, lr=2.32304e-05, gnorm=1.712, clip=100, loss_scale=256, train_wall=17, gb_free=12.9, wall=7444
2023-06-27 18:22:58 - progress_bar.py[line:272] - INFO: epoch 005:    366 / 990 loss=2.41, loss_v1=0, loss_v2=0, nll_loss=1.213, ntokens=1716.6, nsentences=56, sample_size=1716.6, sample_size_v1=0, sample_size_v2=0, ppl=2.32, wps=1009.3, ups=0.59, wpb=1716.6, bsz=56, num_updates=4320, lr=2.32102e-05, gnorm=1.701, clip=100, loss_scale=256, train_wall=17, gb_free=12.8, wall=7461
2023-06-27 18:23:16 - progress_bar.py[line:272] - INFO: epoch 005:    376 / 990 loss=2.417, loss_v1=0, loss_v2=0, nll_loss=1.221, ntokens=1833.5, nsentences=56, sample_size=1833.5, sample_size_v1=0, sample_size_v2=0, ppl=2.33, wps=1076.5, ups=0.59, wpb=1833.5, bsz=56, num_updates=4330, lr=2.31901e-05, gnorm=1.75, clip=100, loss_scale=256, train_wall=17, gb_free=12.6, wall=7478
2023-06-27 18:23:33 - progress_bar.py[line:272] - INFO: epoch 005:    386 / 990 loss=2.369, loss_v1=0, loss_v2=0, nll_loss=1.17, ntokens=1874.3, nsentences=56, sample_size=1874.3, sample_size_v1=0, sample_size_v2=0, ppl=2.25, wps=1091.7, ups=0.58, wpb=1874.3, bsz=56, num_updates=4340, lr=2.31699e-05, gnorm=1.777, clip=100, loss_scale=256, train_wall=17, gb_free=12.9, wall=7495
2023-06-27 18:23:50 - progress_bar.py[line:272] - INFO: epoch 005:    396 / 990 loss=2.392, loss_v1=0, loss_v2=0, nll_loss=1.195, ntokens=1674.9, nsentences=56, sample_size=1674.9, sample_size_v1=0, sample_size_v2=0, ppl=2.29, wps=982.9, ups=0.59, wpb=1674.9, bsz=56, num_updates=4350, lr=2.31498e-05, gnorm=1.756, clip=100, loss_scale=256, train_wall=17, gb_free=12.5, wall=7512
2023-06-27 18:24:07 - progress_bar.py[line:272] - INFO: epoch 005:    406 / 990 loss=2.424, loss_v1=0, loss_v2=0, nll_loss=1.227, ntokens=1747.3, nsentences=56, sample_size=1747.3, sample_size_v1=0, sample_size_v2=0, ppl=2.34, wps=1027.6, ups=0.59, wpb=1747.3, bsz=56, num_updates=4360, lr=2.31296e-05, gnorm=1.82, clip=100, loss_scale=256, train_wall=17, gb_free=12.3, wall=7529
2023-06-27 18:24:24 - progress_bar.py[line:272] - INFO: epoch 005:    416 / 990 loss=2.409, loss_v1=0, loss_v2=0, nll_loss=1.214, ntokens=1733.6, nsentences=56, sample_size=1733.6, sample_size_v1=0, sample_size_v2=0, ppl=2.32, wps=1018.8, ups=0.59, wpb=1733.6, bsz=56, num_updates=4370, lr=2.31095e-05, gnorm=1.797, clip=100, loss_scale=256, train_wall=17, gb_free=12.8, wall=7546
2023-06-27 18:24:41 - progress_bar.py[line:272] - INFO: epoch 005:    426 / 990 loss=2.388, loss_v1=0, loss_v2=0, nll_loss=1.189, ntokens=1789.8, nsentences=56, sample_size=1789.8, sample_size_v1=0, sample_size_v2=0, ppl=2.28, wps=1046.6, ups=0.58, wpb=1789.8, bsz=56, num_updates=4380, lr=2.30893e-05, gnorm=1.755, clip=100, loss_scale=256, train_wall=17, gb_free=13, wall=7564
2023-06-27 18:24:53 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 256.0
2023-06-27 18:25:00 - progress_bar.py[line:272] - INFO: epoch 005:    437 / 990 loss=2.388, loss_v1=0, loss_v2=0, nll_loss=1.189, ntokens=1881.1, nsentences=56, sample_size=1881.1, sample_size_v1=0, sample_size_v2=0, ppl=2.28, wps=999.9, ups=0.53, wpb=1881.1, bsz=56, num_updates=4390, lr=2.30692e-05, gnorm=1.723, clip=100, loss_scale=256, train_wall=19, gb_free=13, wall=7582
2023-06-27 18:25:17 - progress_bar.py[line:272] - INFO: epoch 005:    447 / 990 loss=2.382, loss_v1=0, loss_v2=0, nll_loss=1.184, ntokens=1814.6, nsentences=56, sample_size=1814.6, sample_size_v1=0, sample_size_v2=0, ppl=2.27, wps=1061.7, ups=0.59, wpb=1814.6, bsz=56, num_updates=4400, lr=2.3049e-05, gnorm=1.807, clip=100, loss_scale=256, train_wall=17, gb_free=12.8, wall=7599
2023-06-27 18:25:34 - progress_bar.py[line:272] - INFO: epoch 005:    457 / 990 loss=2.411, loss_v1=0, loss_v2=0, nll_loss=1.215, ntokens=1806.6, nsentences=56, sample_size=1806.6, sample_size_v1=0, sample_size_v2=0, ppl=2.32, wps=1058.5, ups=0.59, wpb=1806.6, bsz=56, num_updates=4410, lr=2.30289e-05, gnorm=1.921, clip=100, loss_scale=256, train_wall=17, gb_free=13, wall=7616
2023-06-27 18:25:51 - progress_bar.py[line:272] - INFO: epoch 005:    467 / 990 loss=2.389, loss_v1=0, loss_v2=0, nll_loss=1.189, ntokens=1849.8, nsentences=56, sample_size=1849.8, sample_size_v1=0, sample_size_v2=0, ppl=2.28, wps=1077.2, ups=0.58, wpb=1849.8, bsz=56, num_updates=4420, lr=2.30087e-05, gnorm=1.794, clip=100, loss_scale=256, train_wall=17, gb_free=12.6, wall=7634
2023-06-27 18:26:08 - progress_bar.py[line:272] - INFO: epoch 005:    477 / 990 loss=2.384, loss_v1=0, loss_v2=0, nll_loss=1.186, ntokens=1858.7, nsentences=56, sample_size=1858.7, sample_size_v1=0, sample_size_v2=0, ppl=2.27, wps=1080.7, ups=0.58, wpb=1858.7, bsz=56, num_updates=4430, lr=2.29886e-05, gnorm=1.746, clip=100, loss_scale=256, train_wall=17, gb_free=13.1, wall=7651
2023-06-27 18:26:25 - progress_bar.py[line:272] - INFO: epoch 005:    487 / 990 loss=2.379, loss_v1=0, loss_v2=0, nll_loss=1.179, ntokens=1851.9, nsentences=56, sample_size=1851.9, sample_size_v1=0, sample_size_v2=0, ppl=2.26, wps=1079.7, ups=0.58, wpb=1851.9, bsz=56, num_updates=4440, lr=2.29684e-05, gnorm=1.789, clip=100, loss_scale=256, train_wall=17, gb_free=12.2, wall=7668
2023-06-27 18:26:42 - progress_bar.py[line:272] - INFO: epoch 005:    497 / 990 loss=2.391, loss_v1=0, loss_v2=0, nll_loss=1.193, ntokens=1844.4, nsentences=56, sample_size=1844.4, sample_size_v1=0, sample_size_v2=0, ppl=2.29, wps=1078, ups=0.58, wpb=1844.4, bsz=56, num_updates=4450, lr=2.29483e-05, gnorm=1.727, clip=100, loss_scale=256, train_wall=17, gb_free=13, wall=7685
2023-06-27 18:27:00 - progress_bar.py[line:272] - INFO: epoch 005:    507 / 990 loss=2.425, loss_v1=0, loss_v2=0, nll_loss=1.231, ntokens=1791.9, nsentences=56, sample_size=1791.9, sample_size_v1=0, sample_size_v2=0, ppl=2.35, wps=1045.1, ups=0.58, wpb=1791.9, bsz=56, num_updates=4460, lr=2.29281e-05, gnorm=1.886, clip=100, loss_scale=256, train_wall=17, gb_free=13, wall=7702
2023-06-27 18:27:17 - progress_bar.py[line:272] - INFO: epoch 005:    517 / 990 loss=2.388, loss_v1=0, loss_v2=0, nll_loss=1.191, ntokens=1771.1, nsentences=56, sample_size=1771.1, sample_size_v1=0, sample_size_v2=0, ppl=2.28, wps=1039.9, ups=0.59, wpb=1771.1, bsz=56, num_updates=4470, lr=2.2908e-05, gnorm=1.877, clip=100, loss_scale=256, train_wall=17, gb_free=13.2, wall=7719
2023-06-27 18:27:34 - progress_bar.py[line:272] - INFO: epoch 005:    527 / 990 loss=2.403, loss_v1=0, loss_v2=0, nll_loss=1.204, ntokens=1912.3, nsentences=56, sample_size=1912.3, sample_size_v1=0, sample_size_v2=0, ppl=2.3, wps=1113.4, ups=0.58, wpb=1912.3, bsz=56, num_updates=4480, lr=2.28878e-05, gnorm=1.885, clip=100, loss_scale=256, train_wall=17, gb_free=12.8, wall=7737
2023-06-27 18:27:51 - progress_bar.py[line:272] - INFO: epoch 005:    537 / 990 loss=2.384, loss_v1=0, loss_v2=0, nll_loss=1.186, ntokens=1893.7, nsentences=56, sample_size=1893.7, sample_size_v1=0, sample_size_v2=0, ppl=2.27, wps=1099.8, ups=0.58, wpb=1893.7, bsz=56, num_updates=4490, lr=2.28677e-05, gnorm=1.826, clip=100, loss_scale=256, train_wall=17, gb_free=12.9, wall=7754
2023-06-27 18:28:08 - progress_bar.py[line:272] - INFO: epoch 005:    547 / 990 loss=2.402, loss_v1=0, loss_v2=0, nll_loss=1.202, ntokens=1964.2, nsentences=56, sample_size=1964.2, sample_size_v1=0, sample_size_v2=0, ppl=2.3, wps=1147.7, ups=0.58, wpb=1964.2, bsz=56, num_updates=4500, lr=2.28475e-05, gnorm=1.849, clip=100, loss_scale=256, train_wall=17, gb_free=12.7, wall=7771
2023-06-27 18:28:25 - progress_bar.py[line:272] - INFO: epoch 005:    557 / 990 loss=2.377, loss_v1=0, loss_v2=0, nll_loss=1.18, ntokens=1804.7, nsentences=56, sample_size=1804.7, sample_size_v1=0, sample_size_v2=0, ppl=2.27, wps=1058.9, ups=0.59, wpb=1804.7, bsz=56, num_updates=4510, lr=2.28274e-05, gnorm=1.813, clip=100, loss_scale=256, train_wall=17, gb_free=13.1, wall=7788
2023-06-27 18:28:42 - progress_bar.py[line:272] - INFO: epoch 005:    567 / 990 loss=2.367, loss_v1=0, loss_v2=0, nll_loss=1.166, ntokens=1792.1, nsentences=56, sample_size=1792.1, sample_size_v1=0, sample_size_v2=0, ppl=2.24, wps=1048.4, ups=0.59, wpb=1792.1, bsz=56, num_updates=4520, lr=2.28073e-05, gnorm=1.912, clip=100, loss_scale=256, train_wall=17, gb_free=13.2, wall=7805
2023-06-27 18:28:59 - progress_bar.py[line:272] - INFO: epoch 005:    577 / 990 loss=2.399, loss_v1=0, loss_v2=0, nll_loss=1.201, ntokens=1799.8, nsentences=54.8, sample_size=1799.8, sample_size_v1=0, sample_size_v2=0, ppl=2.3, wps=1076.6, ups=0.6, wpb=1799.8, bsz=54.8, num_updates=4530, lr=2.27871e-05, gnorm=1.843, clip=100, loss_scale=256, train_wall=17, gb_free=12.8, wall=7822
2023-06-27 18:29:16 - progress_bar.py[line:272] - INFO: epoch 005:    587 / 990 loss=2.419, loss_v1=0, loss_v2=0, nll_loss=1.224, ntokens=1905.2, nsentences=56, sample_size=1905.2, sample_size_v1=0, sample_size_v2=0, ppl=2.34, wps=1116.1, ups=0.59, wpb=1905.2, bsz=56, num_updates=4540, lr=2.2767e-05, gnorm=1.86, clip=100, loss_scale=256, train_wall=17, gb_free=12.8, wall=7839
2023-06-27 18:29:33 - progress_bar.py[line:272] - INFO: epoch 005:    597 / 990 loss=2.378, loss_v1=0, loss_v2=0, nll_loss=1.178, ntokens=1867.5, nsentences=56, sample_size=1867.5, sample_size_v1=0, sample_size_v2=0, ppl=2.26, wps=1094.9, ups=0.59, wpb=1867.5, bsz=56, num_updates=4550, lr=2.27468e-05, gnorm=1.868, clip=100, loss_scale=256, train_wall=17, gb_free=12.9, wall=7856
2023-06-27 18:29:50 - progress_bar.py[line:272] - INFO: epoch 005:    607 / 990 loss=2.386, loss_v1=0, loss_v2=0, nll_loss=1.187, ntokens=1774, nsentences=56, sample_size=1774, sample_size_v1=0, sample_size_v2=0, ppl=2.28, wps=1040.9, ups=0.59, wpb=1774, bsz=56, num_updates=4560, lr=2.27267e-05, gnorm=1.972, clip=100, loss_scale=256, train_wall=17, gb_free=12.6, wall=7873
2023-06-27 18:30:07 - progress_bar.py[line:272] - INFO: epoch 005:    617 / 990 loss=2.391, loss_v1=0, loss_v2=0, nll_loss=1.193, ntokens=1874.4, nsentences=56, sample_size=1874.4, sample_size_v1=0, sample_size_v2=0, ppl=2.29, wps=1099.8, ups=0.59, wpb=1874.4, bsz=56, num_updates=4570, lr=2.27065e-05, gnorm=1.824, clip=100, loss_scale=256, train_wall=17, gb_free=13, wall=7890
2023-06-27 18:30:24 - progress_bar.py[line:272] - INFO: epoch 005:    627 / 990 loss=2.41, loss_v1=0, loss_v2=0, nll_loss=1.214, ntokens=2043.5, nsentences=56, sample_size=2043.5, sample_size_v1=0, sample_size_v2=0, ppl=2.32, wps=1194.3, ups=0.58, wpb=2043.5, bsz=56, num_updates=4580, lr=2.26864e-05, gnorm=1.762, clip=100, loss_scale=256, train_wall=17, gb_free=12.6, wall=7907
2023-06-27 18:30:42 - progress_bar.py[line:272] - INFO: epoch 005:    637 / 990 loss=2.394, loss_v1=0, loss_v2=0, nll_loss=1.198, ntokens=1993.4, nsentences=56, sample_size=1993.4, sample_size_v1=0, sample_size_v2=0, ppl=2.29, wps=1159.5, ups=0.58, wpb=1993.4, bsz=56, num_updates=4590, lr=2.26662e-05, gnorm=1.726, clip=100, loss_scale=256, train_wall=17, gb_free=13, wall=7924
2023-06-27 18:30:59 - progress_bar.py[line:272] - INFO: epoch 005:    647 / 990 loss=2.399, loss_v1=0, loss_v2=0, nll_loss=1.202, ntokens=1970.7, nsentences=56, sample_size=1970.7, sample_size_v1=0, sample_size_v2=0, ppl=2.3, wps=1146.2, ups=0.58, wpb=1970.7, bsz=56, num_updates=4600, lr=2.26461e-05, gnorm=1.784, clip=100, loss_scale=256, train_wall=17, gb_free=12.4, wall=7941
2023-06-27 18:31:16 - progress_bar.py[line:272] - INFO: epoch 005:    657 / 990 loss=2.388, loss_v1=0, loss_v2=0, nll_loss=1.189, ntokens=1906.6, nsentences=56, sample_size=1906.6, sample_size_v1=0, sample_size_v2=0, ppl=2.28, wps=1111.6, ups=0.58, wpb=1906.6, bsz=56, num_updates=4610, lr=2.26259e-05, gnorm=1.748, clip=100, loss_scale=256, train_wall=17, gb_free=12.5, wall=7959
2023-06-27 18:31:33 - progress_bar.py[line:272] - INFO: epoch 005:    667 / 990 loss=2.407, loss_v1=0, loss_v2=0, nll_loss=1.21, ntokens=1818.2, nsentences=56, sample_size=1818.2, sample_size_v1=0, sample_size_v2=0, ppl=2.31, wps=1066.2, ups=0.59, wpb=1818.2, bsz=56, num_updates=4620, lr=2.26058e-05, gnorm=1.993, clip=100, loss_scale=256, train_wall=17, gb_free=12.8, wall=7976
2023-06-27 18:31:50 - progress_bar.py[line:272] - INFO: epoch 005:    677 / 990 loss=2.374, loss_v1=0, loss_v2=0, nll_loss=1.173, ntokens=1867.7, nsentences=56, sample_size=1867.7, sample_size_v1=0, sample_size_v2=0, ppl=2.26, wps=1088.5, ups=0.58, wpb=1867.7, bsz=56, num_updates=4630, lr=2.25856e-05, gnorm=1.829, clip=100, loss_scale=256, train_wall=17, gb_free=12.5, wall=7993
2023-06-27 18:32:07 - progress_bar.py[line:272] - INFO: epoch 005:    687 / 990 loss=2.356, loss_v1=0, loss_v2=0, nll_loss=1.157, ntokens=1855.2, nsentences=56, sample_size=1855.2, sample_size_v1=0, sample_size_v2=0, ppl=2.23, wps=1081.8, ups=0.58, wpb=1855.2, bsz=56, num_updates=4640, lr=2.25655e-05, gnorm=1.938, clip=100, loss_scale=256, train_wall=17, gb_free=12.6, wall=8010
2023-06-27 18:32:24 - progress_bar.py[line:272] - INFO: epoch 005:    697 / 990 loss=2.391, loss_v1=0, loss_v2=0, nll_loss=1.191, ntokens=1742.1, nsentences=56, sample_size=1742.1, sample_size_v1=0, sample_size_v2=0, ppl=2.28, wps=1018.1, ups=0.58, wpb=1742.1, bsz=56, num_updates=4650, lr=2.25453e-05, gnorm=2.268, clip=100, loss_scale=256, train_wall=17, gb_free=12.9, wall=8027
2023-06-27 18:32:41 - progress_bar.py[line:272] - INFO: epoch 005:    707 / 990 loss=2.407, loss_v1=0, loss_v2=0, nll_loss=1.209, ntokens=1710.3, nsentences=56, sample_size=1710.3, sample_size_v1=0, sample_size_v2=0, ppl=2.31, wps=1007.6, ups=0.59, wpb=1710.3, bsz=56, num_updates=4660, lr=2.25252e-05, gnorm=2.193, clip=100, loss_scale=256, train_wall=17, gb_free=12.7, wall=8044
2023-06-27 18:32:58 - progress_bar.py[line:272] - INFO: epoch 005:    717 / 990 loss=2.38, loss_v1=0, loss_v2=0, nll_loss=1.183, ntokens=1787.9, nsentences=56, sample_size=1787.9, sample_size_v1=0, sample_size_v2=0, ppl=2.27, wps=1053, ups=0.59, wpb=1787.9, bsz=56, num_updates=4670, lr=2.2505e-05, gnorm=2.004, clip=100, loss_scale=256, train_wall=17, gb_free=13.1, wall=8061
2023-06-27 18:33:15 - progress_bar.py[line:272] - INFO: epoch 005:    727 / 990 loss=2.371, loss_v1=0, loss_v2=0, nll_loss=1.169, ntokens=1797, nsentences=56, sample_size=1797, sample_size_v1=0, sample_size_v2=0, ppl=2.25, wps=1057.3, ups=0.59, wpb=1797, bsz=56, num_updates=4680, lr=2.24849e-05, gnorm=2.055, clip=100, loss_scale=256, train_wall=17, gb_free=12.7, wall=8078
2023-06-27 18:33:32 - progress_bar.py[line:272] - INFO: epoch 005:    737 / 990 loss=2.383, loss_v1=0, loss_v2=0, nll_loss=1.183, ntokens=1836, nsentences=56, sample_size=1836, sample_size_v1=0, sample_size_v2=0, ppl=2.27, wps=1075.9, ups=0.59, wpb=1836, bsz=56, num_updates=4690, lr=2.24647e-05, gnorm=1.812, clip=100, loss_scale=256, train_wall=17, gb_free=12.8, wall=8095
2023-06-27 18:33:49 - progress_bar.py[line:272] - INFO: epoch 005:    747 / 990 loss=2.399, loss_v1=0, loss_v2=0, nll_loss=1.202, ntokens=1704.5, nsentences=56, sample_size=1704.5, sample_size_v1=0, sample_size_v2=0, ppl=2.3, wps=1003.6, ups=0.59, wpb=1704.5, bsz=56, num_updates=4700, lr=2.24446e-05, gnorm=2.112, clip=100, loss_scale=256, train_wall=17, gb_free=13.1, wall=8112
2023-06-27 18:34:06 - progress_bar.py[line:272] - INFO: epoch 005:    757 / 990 loss=2.42, loss_v1=0, loss_v2=0, nll_loss=1.226, ntokens=1695.8, nsentences=56, sample_size=1695.8, sample_size_v1=0, sample_size_v2=0, ppl=2.34, wps=997.3, ups=0.59, wpb=1695.8, bsz=56, num_updates=4710, lr=2.24244e-05, gnorm=2.15, clip=100, loss_scale=256, train_wall=17, gb_free=12.6, wall=8129
2023-06-27 18:34:23 - progress_bar.py[line:272] - INFO: epoch 005:    767 / 990 loss=2.387, loss_v1=0, loss_v2=0, nll_loss=1.188, ntokens=1792, nsentences=56, sample_size=1792, sample_size_v1=0, sample_size_v2=0, ppl=2.28, wps=1053, ups=0.59, wpb=1792, bsz=56, num_updates=4720, lr=2.24043e-05, gnorm=1.884, clip=100, loss_scale=256, train_wall=17, gb_free=12.6, wall=8146
2023-06-27 18:34:41 - progress_bar.py[line:272] - INFO: epoch 005:    777 / 990 loss=2.379, loss_v1=0, loss_v2=0, nll_loss=1.179, ntokens=1799.7, nsentences=56, sample_size=1799.7, sample_size_v1=0, sample_size_v2=0, ppl=2.26, wps=1055.3, ups=0.59, wpb=1799.7, bsz=56, num_updates=4730, lr=2.23842e-05, gnorm=2.11, clip=100, loss_scale=256, train_wall=17, gb_free=13.2, wall=8163
2023-06-27 18:34:58 - progress_bar.py[line:272] - INFO: epoch 005:    787 / 990 loss=2.384, loss_v1=0, loss_v2=0, nll_loss=1.188, ntokens=1758.7, nsentences=56, sample_size=1758.7, sample_size_v1=0, sample_size_v2=0, ppl=2.28, wps=1034.2, ups=0.59, wpb=1758.7, bsz=56, num_updates=4740, lr=2.2364e-05, gnorm=2.097, clip=100, loss_scale=256, train_wall=17, gb_free=12.6, wall=8180
2023-06-27 18:35:15 - progress_bar.py[line:272] - INFO: epoch 005:    797 / 990 loss=2.397, loss_v1=0, loss_v2=0, nll_loss=1.197, ntokens=1888.2, nsentences=56, sample_size=1888.2, sample_size_v1=0, sample_size_v2=0, ppl=2.29, wps=1101.9, ups=0.58, wpb=1888.2, bsz=56, num_updates=4750, lr=2.23439e-05, gnorm=1.819, clip=100, loss_scale=256, train_wall=17, gb_free=12.7, wall=8197
2023-06-27 18:35:32 - progress_bar.py[line:272] - INFO: epoch 005:    807 / 990 loss=2.394, loss_v1=0, loss_v2=0, nll_loss=1.196, ntokens=1726, nsentences=56, sample_size=1726, sample_size_v1=0, sample_size_v2=0, ppl=2.29, wps=1012.9, ups=0.59, wpb=1726, bsz=56, num_updates=4760, lr=2.23237e-05, gnorm=2.088, clip=100, loss_scale=256, train_wall=17, gb_free=13, wall=8214
2023-06-27 18:35:49 - progress_bar.py[line:272] - INFO: epoch 005:    817 / 990 loss=2.411, loss_v1=0, loss_v2=0, nll_loss=1.218, ntokens=1629.3, nsentences=56, sample_size=1629.3, sample_size_v1=0, sample_size_v2=0, ppl=2.33, wps=956.4, ups=0.59, wpb=1629.3, bsz=56, num_updates=4770, lr=2.23036e-05, gnorm=2.192, clip=100, loss_scale=256, train_wall=17, gb_free=12.8, wall=8231
2023-06-27 18:36:06 - progress_bar.py[line:272] - INFO: epoch 005:    827 / 990 loss=2.37, loss_v1=0, loss_v2=0, nll_loss=1.17, ntokens=1754, nsentences=56, sample_size=1754, sample_size_v1=0, sample_size_v2=0, ppl=2.25, wps=1025.4, ups=0.58, wpb=1754, bsz=56, num_updates=4780, lr=2.22834e-05, gnorm=2.108, clip=100, loss_scale=256, train_wall=17, gb_free=13, wall=8249
2023-06-27 18:36:23 - progress_bar.py[line:272] - INFO: epoch 005:    837 / 990 loss=2.372, loss_v1=0, loss_v2=0, nll_loss=1.171, ntokens=1757.1, nsentences=56, sample_size=1757.1, sample_size_v1=0, sample_size_v2=0, ppl=2.25, wps=1031.9, ups=0.59, wpb=1757.1, bsz=56, num_updates=4790, lr=2.22633e-05, gnorm=2.07, clip=100, loss_scale=256, train_wall=17, gb_free=12.8, wall=8266
2023-06-27 18:36:40 - progress_bar.py[line:272] - INFO: epoch 005:    847 / 990 loss=2.366, loss_v1=0, loss_v2=0, nll_loss=1.162, ntokens=1882.3, nsentences=56, sample_size=1882.3, sample_size_v1=0, sample_size_v2=0, ppl=2.24, wps=1100.1, ups=0.58, wpb=1882.3, bsz=56, num_updates=4800, lr=2.22431e-05, gnorm=1.842, clip=100, loss_scale=256, train_wall=17, gb_free=12.6, wall=8283
2023-06-27 18:36:57 - progress_bar.py[line:272] - INFO: epoch 005:    857 / 990 loss=2.351, loss_v1=0, loss_v2=0, nll_loss=1.149, ntokens=1887.2, nsentences=56, sample_size=1887.2, sample_size_v1=0, sample_size_v2=0, ppl=2.22, wps=1097, ups=0.58, wpb=1887.2, bsz=56, num_updates=4810, lr=2.2223e-05, gnorm=1.968, clip=100, loss_scale=256, train_wall=17, gb_free=12.9, wall=8300
2023-06-27 18:37:14 - progress_bar.py[line:272] - INFO: epoch 005:    867 / 990 loss=2.37, loss_v1=0, loss_v2=0, nll_loss=1.17, ntokens=1769.9, nsentences=56, sample_size=1769.9, sample_size_v1=0, sample_size_v2=0, ppl=2.25, wps=1034.3, ups=0.58, wpb=1769.9, bsz=56, num_updates=4820, lr=2.22028e-05, gnorm=2.106, clip=100, loss_scale=256, train_wall=17, gb_free=12.5, wall=8317
2023-06-27 18:37:31 - progress_bar.py[line:272] - INFO: epoch 005:    877 / 990 loss=2.366, loss_v1=0, loss_v2=0, nll_loss=1.165, ntokens=1882.8, nsentences=56, sample_size=1882.8, sample_size_v1=0, sample_size_v2=0, ppl=2.24, wps=1099.9, ups=0.58, wpb=1882.8, bsz=56, num_updates=4830, lr=2.21827e-05, gnorm=2.13, clip=100, loss_scale=256, train_wall=17, gb_free=12.4, wall=8334
2023-06-27 18:37:49 - progress_bar.py[line:272] - INFO: epoch 005:    887 / 990 loss=2.368, loss_v1=0, loss_v2=0, nll_loss=1.166, ntokens=1976.8, nsentences=56, sample_size=1976.8, sample_size_v1=0, sample_size_v2=0, ppl=2.24, wps=1154.3, ups=0.58, wpb=1976.8, bsz=56, num_updates=4840, lr=2.21625e-05, gnorm=2.025, clip=100, loss_scale=256, train_wall=17, gb_free=12.5, wall=8351
2023-06-27 18:38:06 - progress_bar.py[line:272] - INFO: epoch 005:    897 / 990 loss=2.363, loss_v1=0, loss_v2=0, nll_loss=1.161, ntokens=1841.2, nsentences=56, sample_size=1841.2, sample_size_v1=0, sample_size_v2=0, ppl=2.24, wps=1062.1, ups=0.58, wpb=1841.2, bsz=56, num_updates=4850, lr=2.21424e-05, gnorm=2.098, clip=100, loss_scale=256, train_wall=17, gb_free=12.6, wall=8369
2023-06-27 18:38:23 - progress_bar.py[line:272] - INFO: epoch 005:    907 / 990 loss=2.402, loss_v1=0, loss_v2=0, nll_loss=1.206, ntokens=1785.9, nsentences=56, sample_size=1785.9, sample_size_v1=0, sample_size_v2=0, ppl=2.31, wps=1046.8, ups=0.59, wpb=1785.9, bsz=56, num_updates=4860, lr=2.21222e-05, gnorm=2.015, clip=100, loss_scale=256, train_wall=17, gb_free=12.8, wall=8386
2023-06-27 18:38:40 - progress_bar.py[line:272] - INFO: epoch 005:    917 / 990 loss=2.376, loss_v1=0, loss_v2=0, nll_loss=1.174, ntokens=1718.9, nsentences=56, sample_size=1718.9, sample_size_v1=0, sample_size_v2=0, ppl=2.26, wps=1010.7, ups=0.59, wpb=1718.9, bsz=56, num_updates=4870, lr=2.21021e-05, gnorm=2.013, clip=100, loss_scale=256, train_wall=17, gb_free=13.2, wall=8403
2023-06-27 18:38:57 - progress_bar.py[line:272] - INFO: epoch 005:    927 / 990 loss=2.353, loss_v1=0, loss_v2=0, nll_loss=1.153, ntokens=1859.9, nsentences=56, sample_size=1859.9, sample_size_v1=0, sample_size_v2=0, ppl=2.22, wps=1080.5, ups=0.58, wpb=1859.9, bsz=56, num_updates=4880, lr=2.20819e-05, gnorm=1.999, clip=100, loss_scale=256, train_wall=17, gb_free=12.7, wall=8420
2023-06-27 18:39:14 - progress_bar.py[line:272] - INFO: epoch 005:    937 / 990 loss=2.369, loss_v1=0, loss_v2=0, nll_loss=1.166, ntokens=1778.3, nsentences=56, sample_size=1778.3, sample_size_v1=0, sample_size_v2=0, ppl=2.24, wps=1041.7, ups=0.59, wpb=1778.3, bsz=56, num_updates=4890, lr=2.20618e-05, gnorm=2.011, clip=100, loss_scale=256, train_wall=17, gb_free=12.4, wall=8437
2023-06-27 18:39:30 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 256.0
2023-06-27 18:39:33 - progress_bar.py[line:272] - INFO: epoch 005:    948 / 990 loss=2.366, loss_v1=0, loss_v2=0, nll_loss=1.166, ntokens=1945.3, nsentences=56, sample_size=1945.3, sample_size_v1=0, sample_size_v2=0, ppl=2.24, wps=1029.2, ups=0.53, wpb=1945.3, bsz=56, num_updates=4900, lr=2.20416e-05, gnorm=1.939, clip=100, loss_scale=256, train_wall=19, gb_free=13.1, wall=8456
2023-06-27 18:39:50 - progress_bar.py[line:272] - INFO: epoch 005:    958 / 990 loss=2.367, loss_v1=0, loss_v2=0, nll_loss=1.165, ntokens=1880.2, nsentences=56, sample_size=1880.2, sample_size_v1=0, sample_size_v2=0, ppl=2.24, wps=1099.9, ups=0.58, wpb=1880.2, bsz=56, num_updates=4910, lr=2.20215e-05, gnorm=2.019, clip=100, loss_scale=256, train_wall=17, gb_free=13.1, wall=8473
2023-06-27 18:40:07 - progress_bar.py[line:272] - INFO: epoch 005:    968 / 990 loss=2.362, loss_v1=0, loss_v2=0, nll_loss=1.162, ntokens=1919.7, nsentences=56, sample_size=1919.7, sample_size_v1=0, sample_size_v2=0, ppl=2.24, wps=1118.3, ups=0.58, wpb=1919.7, bsz=56, num_updates=4920, lr=2.20013e-05, gnorm=1.931, clip=100, loss_scale=256, train_wall=17, gb_free=12.7, wall=8490
2023-06-27 18:40:25 - progress_bar.py[line:272] - INFO: epoch 005:    978 / 990 loss=2.369, loss_v1=0, loss_v2=0, nll_loss=1.167, ntokens=1868.9, nsentences=56, sample_size=1868.9, sample_size_v1=0, sample_size_v2=0, ppl=2.25, wps=1089.1, ups=0.58, wpb=1868.9, bsz=56, num_updates=4930, lr=2.19812e-05, gnorm=1.886, clip=100, loss_scale=256, train_wall=17, gb_free=12.9, wall=8507
2023-06-27 18:40:42 - progress_bar.py[line:272] - INFO: epoch 005:    988 / 990 loss=2.405, loss_v1=0, loss_v2=0, nll_loss=1.207, ntokens=1858.7, nsentences=56, sample_size=1858.7, sample_size_v1=0, sample_size_v2=0, ppl=2.31, wps=1089.2, ups=0.59, wpb=1858.7, bsz=56, num_updates=4940, lr=2.1961e-05, gnorm=1.993, clip=100, loss_scale=256, train_wall=17, gb_free=12.6, wall=8524
local datafile ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 1 begin to initialize row_count and line_idx-to-offset mapping
2023-06-27 18:40:44 - train.py[line:332] - INFO: end of epoch 5 (average epoch stats below)
2023-06-27 18:40:44 - progress_bar.py[line:282] - INFO: epoch 005 | loss 2.373 | loss_v1 0 | loss_v2 0 | nll_loss 1.173 | ntokens 1849.73 | nsentences 55.96 | sample_size 1849.73 | sample_size_v1 0 | sample_size_v2 0 | ppl 2.25 | wps 1074.3 | ups 0.58 | wpb 1849.7 | bsz 56 | num_updates 4942 | lr 2.1957e-05 | gnorm 1.843 | clip 100 | loss_scale 256 | train_wall 1695 | gb_free 13.3 | wall 8527
2023-06-27 18:40:44 - trainer.py[line:639] - INFO: loading train data for epoch 6
local datafile ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 0 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 0 finished initializing row_count and line_idx-to-offset mapping
file ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 0 row count 27700 total row count 55400
slice_id 0 seek offset 0
2023-06-27 18:40:46 - trainer.py[line:703] - INFO: begin training epoch 6
2023-06-27 18:40:46 - train.py[line:305] - INFO: Start iterating over samples
local datafile ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 1 finished initializing row_count and line_idx-to-offset mapping
file ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 1 row count 27700 total row count 55400
slice_id 1 seek offset 27700
2023-06-27 18:41:00 - progress_bar.py[line:272] - INFO: epoch 006:      8 / 990 loss=2.331, loss_v1=0, loss_v2=0, nll_loss=1.126, ntokens=1763.9, nsentences=53.2, sample_size=1763.9, sample_size_v1=0, sample_size_v2=0, ppl=2.18, wps=950.3, ups=0.54, wpb=1763.9, bsz=53.2, num_updates=4950, lr=2.19409e-05, gnorm=2.138, clip=100, loss_scale=256, train_wall=16, gb_free=12.6, wall=8543
2023-06-27 18:41:18 - progress_bar.py[line:272] - INFO: epoch 006:     18 / 990 loss=2.33, loss_v1=0, loss_v2=0, nll_loss=1.126, ntokens=1819.5, nsentences=56, sample_size=1819.5, sample_size_v1=0, sample_size_v2=0, ppl=2.18, wps=1054.1, ups=0.58, wpb=1819.5, bsz=56, num_updates=4960, lr=2.19208e-05, gnorm=1.854, clip=100, loss_scale=256, train_wall=17, gb_free=12.5, wall=8560
2023-06-27 18:41:35 - progress_bar.py[line:272] - INFO: epoch 006:     28 / 990 loss=2.316, loss_v1=0, loss_v2=0, nll_loss=1.106, ntokens=1760.2, nsentences=56, sample_size=1760.2, sample_size_v1=0, sample_size_v2=0, ppl=2.15, wps=1030, ups=0.59, wpb=1760.2, bsz=56, num_updates=4970, lr=2.19006e-05, gnorm=1.86, clip=100, loss_scale=256, train_wall=17, gb_free=12.8, wall=8577
2023-06-27 18:41:52 - progress_bar.py[line:272] - INFO: epoch 006:     38 / 990 loss=2.271, loss_v1=0, loss_v2=0, nll_loss=1.059, ntokens=1872.9, nsentences=56, sample_size=1872.9, sample_size_v1=0, sample_size_v2=0, ppl=2.08, wps=1089.6, ups=0.58, wpb=1872.9, bsz=56, num_updates=4980, lr=2.18805e-05, gnorm=1.88, clip=100, loss_scale=256, train_wall=17, gb_free=11.7, wall=8594
2023-06-27 18:42:09 - progress_bar.py[line:272] - INFO: epoch 006:     48 / 990 loss=2.258, loss_v1=0, loss_v2=0, nll_loss=1.046, ntokens=1890.8, nsentences=56, sample_size=1890.8, sample_size_v1=0, sample_size_v2=0, ppl=2.06, wps=1089.2, ups=0.58, wpb=1890.8, bsz=56, num_updates=4990, lr=2.18603e-05, gnorm=1.922, clip=100, loss_scale=256, train_wall=17, gb_free=13, wall=8612
2023-06-27 18:42:26 - progress_bar.py[line:272] - INFO: epoch 006:     58 / 990 loss=2.324, loss_v1=0, loss_v2=0, nll_loss=1.116, ntokens=1750.6, nsentences=56, sample_size=1750.6, sample_size_v1=0, sample_size_v2=0, ppl=2.17, wps=1017, ups=0.58, wpb=1750.6, bsz=56, num_updates=5000, lr=2.18402e-05, gnorm=2.068, clip=100, loss_scale=256, train_wall=17, gb_free=13, wall=8629
2023-06-27 18:42:44 - progress_bar.py[line:272] - INFO: epoch 006:     68 / 990 loss=2.206, loss_v1=0, loss_v2=0, nll_loss=0.987, ntokens=1793, nsentences=56, sample_size=1793, sample_size_v1=0, sample_size_v2=0, ppl=1.98, wps=1046, ups=0.58, wpb=1793, bsz=56, num_updates=5010, lr=2.182e-05, gnorm=2.016, clip=100, loss_scale=256, train_wall=17, gb_free=12.4, wall=8646
2023-06-27 18:43:01 - progress_bar.py[line:272] - INFO: epoch 006:     78 / 990 loss=2.177, loss_v1=0, loss_v2=0, nll_loss=0.954, ntokens=2257.8, nsentences=56, sample_size=2257.8, sample_size_v1=0, sample_size_v2=0, ppl=1.94, wps=1268.4, ups=0.56, wpb=2257.8, bsz=56, num_updates=5020, lr=2.17999e-05, gnorm=1.533, clip=100, loss_scale=256, train_wall=18, gb_free=11.9, wall=8664
2023-06-27 18:43:19 - progress_bar.py[line:272] - INFO: epoch 006:     88 / 990 loss=2.245, loss_v1=0, loss_v2=0, nll_loss=1.028, ntokens=2060.7, nsentences=56, sample_size=2060.7, sample_size_v1=0, sample_size_v2=0, ppl=2.04, wps=1172.2, ups=0.57, wpb=2060.7, bsz=56, num_updates=5030, lr=2.17797e-05, gnorm=1.678, clip=100, loss_scale=256, train_wall=18, gb_free=12.7, wall=8682
2023-06-27 18:43:36 - progress_bar.py[line:272] - INFO: epoch 006:     98 / 990 loss=2.295, loss_v1=0, loss_v2=0, nll_loss=1.087, ntokens=1935.3, nsentences=56, sample_size=1935.3, sample_size_v1=0, sample_size_v2=0, ppl=2.13, wps=1114.5, ups=0.58, wpb=1935.3, bsz=56, num_updates=5040, lr=2.17596e-05, gnorm=2.07, clip=100, loss_scale=256, train_wall=17, gb_free=11.5, wall=8699
2023-06-27 18:43:53 - progress_bar.py[line:272] - INFO: epoch 006:    108 / 990 loss=2.269, loss_v1=0, loss_v2=0, nll_loss=1.054, ntokens=1907.6, nsentences=56, sample_size=1907.6, sample_size_v1=0, sample_size_v2=0, ppl=2.08, wps=1109.3, ups=0.58, wpb=1907.6, bsz=56, num_updates=5050, lr=2.17394e-05, gnorm=1.983, clip=100, loss_scale=256, train_wall=17, gb_free=13, wall=8716
2023-06-27 18:44:11 - progress_bar.py[line:272] - INFO: epoch 006:    118 / 990 loss=2.372, loss_v1=0, loss_v2=0, nll_loss=1.173, ntokens=1777.1, nsentences=56, sample_size=1777.1, sample_size_v1=0, sample_size_v2=0, ppl=2.26, wps=1034, ups=0.58, wpb=1777.1, bsz=56, num_updates=5060, lr=2.17193e-05, gnorm=2.006, clip=100, loss_scale=256, train_wall=17, gb_free=12.6, wall=8733
2023-06-27 18:44:28 - progress_bar.py[line:272] - INFO: epoch 006:    128 / 990 loss=2.374, loss_v1=0, loss_v2=0, nll_loss=1.173, ntokens=1827.3, nsentences=56, sample_size=1827.3, sample_size_v1=0, sample_size_v2=0, ppl=2.26, wps=1061, ups=0.58, wpb=1827.3, bsz=56, num_updates=5070, lr=2.16991e-05, gnorm=1.847, clip=100, loss_scale=256, train_wall=17, gb_free=11.6, wall=8751
2023-06-27 18:44:45 - progress_bar.py[line:272] - INFO: epoch 006:    138 / 990 loss=2.345, loss_v1=0, loss_v2=0, nll_loss=1.14, ntokens=1885.3, nsentences=56, sample_size=1885.3, sample_size_v1=0, sample_size_v2=0, ppl=2.2, wps=1082.6, ups=0.57, wpb=1885.3, bsz=56, num_updates=5080, lr=2.1679e-05, gnorm=1.757, clip=100, loss_scale=256, train_wall=17, gb_free=12.3, wall=8768
2023-06-27 18:45:03 - progress_bar.py[line:272] - INFO: epoch 006:    148 / 990 loss=2.348, loss_v1=0, loss_v2=0, nll_loss=1.145, ntokens=1959, nsentences=56, sample_size=1959, sample_size_v1=0, sample_size_v2=0, ppl=2.21, wps=1122.7, ups=0.57, wpb=1959, bsz=56, num_updates=5090, lr=2.16588e-05, gnorm=1.798, clip=100, loss_scale=256, train_wall=17, gb_free=11, wall=8785
2023-06-27 18:45:20 - progress_bar.py[line:272] - INFO: epoch 006:    158 / 990 loss=2.317, loss_v1=0, loss_v2=0, nll_loss=1.109, ntokens=1964.5, nsentences=56, sample_size=1964.5, sample_size_v1=0, sample_size_v2=0, ppl=2.16, wps=1126.5, ups=0.57, wpb=1964.5, bsz=56, num_updates=5100, lr=2.16387e-05, gnorm=1.755, clip=100, loss_scale=256, train_wall=17, gb_free=12.2, wall=8803
2023-06-27 18:45:38 - progress_bar.py[line:272] - INFO: epoch 006:    168 / 990 loss=2.311, loss_v1=0, loss_v2=0, nll_loss=1.105, ntokens=1934.6, nsentences=56, sample_size=1934.6, sample_size_v1=0, sample_size_v2=0, ppl=2.15, wps=1093.4, ups=0.57, wpb=1934.6, bsz=56, num_updates=5110, lr=2.16185e-05, gnorm=1.809, clip=100, loss_scale=256, train_wall=18, gb_free=12.2, wall=8821
2023-06-27 18:45:55 - progress_bar.py[line:272] - INFO: epoch 006:    178 / 990 loss=2.33, loss_v1=0, loss_v2=0, nll_loss=1.125, ntokens=1972.4, nsentences=56, sample_size=1972.4, sample_size_v1=0, sample_size_v2=0, ppl=2.18, wps=1128.4, ups=0.57, wpb=1972.4, bsz=56, num_updates=5120, lr=2.15984e-05, gnorm=1.798, clip=100, loss_scale=256, train_wall=17, gb_free=12.1, wall=8838
2023-06-27 18:46:13 - progress_bar.py[line:272] - INFO: epoch 006:    188 / 990 loss=2.311, loss_v1=0, loss_v2=0, nll_loss=1.104, ntokens=1916.2, nsentences=56, sample_size=1916.2, sample_size_v1=0, sample_size_v2=0, ppl=2.15, wps=1104.4, ups=0.58, wpb=1916.2, bsz=56, num_updates=5130, lr=2.15782e-05, gnorm=1.902, clip=100, loss_scale=256, train_wall=17, gb_free=11.3, wall=8855
2023-06-27 18:46:30 - progress_bar.py[line:272] - INFO: epoch 006:    198 / 990 loss=2.341, loss_v1=0, loss_v2=0, nll_loss=1.135, ntokens=1739.5, nsentences=56, sample_size=1739.5, sample_size_v1=0, sample_size_v2=0, ppl=2.2, wps=1020, ups=0.59, wpb=1739.5, bsz=56, num_updates=5140, lr=2.15581e-05, gnorm=2.068, clip=100, loss_scale=256, train_wall=17, gb_free=12.6, wall=8872
2023-06-27 18:46:47 - progress_bar.py[line:272] - INFO: epoch 006:    208 / 990 loss=2.286, loss_v1=0, loss_v2=0, nll_loss=1.077, ntokens=1976.6, nsentences=56, sample_size=1976.6, sample_size_v1=0, sample_size_v2=0, ppl=2.11, wps=1133.9, ups=0.57, wpb=1976.6, bsz=56, num_updates=5150, lr=2.15379e-05, gnorm=1.881, clip=100, loss_scale=256, train_wall=17, gb_free=11.9, wall=8890
2023-06-27 18:47:05 - progress_bar.py[line:272] - INFO: epoch 006:    218 / 990 loss=2.312, loss_v1=0, loss_v2=0, nll_loss=1.102, ntokens=1936.9, nsentences=56, sample_size=1936.9, sample_size_v1=0, sample_size_v2=0, ppl=2.15, wps=1114, ups=0.58, wpb=1936.9, bsz=56, num_updates=5160, lr=2.15178e-05, gnorm=1.849, clip=100, loss_scale=256, train_wall=17, gb_free=12.3, wall=8907
2023-06-27 18:47:22 - progress_bar.py[line:272] - INFO: epoch 006:    228 / 990 loss=2.349, loss_v1=0, loss_v2=0, nll_loss=1.146, ntokens=1867.9, nsentences=56, sample_size=1867.9, sample_size_v1=0, sample_size_v2=0, ppl=2.21, wps=1079.7, ups=0.58, wpb=1867.9, bsz=56, num_updates=5170, lr=2.14976e-05, gnorm=1.891, clip=100, loss_scale=256, train_wall=17, gb_free=12.7, wall=8925
2023-06-27 18:47:39 - progress_bar.py[line:272] - INFO: epoch 006:    238 / 990 loss=2.376, loss_v1=0, loss_v2=0, nll_loss=1.176, ntokens=1736.4, nsentences=56, sample_size=1736.4, sample_size_v1=0, sample_size_v2=0, ppl=2.26, wps=1013.3, ups=0.58, wpb=1736.4, bsz=56, num_updates=5180, lr=2.14775e-05, gnorm=2.037, clip=100, loss_scale=256, train_wall=17, gb_free=12.7, wall=8942
2023-06-27 18:47:56 - progress_bar.py[line:272] - INFO: epoch 006:    248 / 990 loss=2.389, loss_v1=0, loss_v2=0, nll_loss=1.191, ntokens=1948.2, nsentences=56, sample_size=1948.2, sample_size_v1=0, sample_size_v2=0, ppl=2.28, wps=1132.6, ups=0.58, wpb=1948.2, bsz=56, num_updates=5190, lr=2.14574e-05, gnorm=1.903, clip=100, loss_scale=256, train_wall=17, gb_free=12.2, wall=8959
2023-06-27 18:48:13 - progress_bar.py[line:272] - INFO: epoch 006:    258 / 990 loss=2.362, loss_v1=0, loss_v2=0, nll_loss=1.16, ntokens=1894.2, nsentences=56, sample_size=1894.2, sample_size_v1=0, sample_size_v2=0, ppl=2.23, wps=1104.1, ups=0.58, wpb=1894.2, bsz=56, num_updates=5200, lr=2.14372e-05, gnorm=1.904, clip=100, loss_scale=256, train_wall=17, gb_free=12.5, wall=8976
2023-06-27 18:48:31 - progress_bar.py[line:272] - INFO: epoch 006:    268 / 990 loss=2.404, loss_v1=0, loss_v2=0, nll_loss=1.207, ntokens=1839.7, nsentences=56, sample_size=1839.7, sample_size_v1=0, sample_size_v2=0, ppl=2.31, wps=1071, ups=0.58, wpb=1839.7, bsz=56, num_updates=5210, lr=2.14171e-05, gnorm=1.908, clip=100, loss_scale=256, train_wall=17, gb_free=12.3, wall=8993
2023-06-27 18:48:48 - progress_bar.py[line:272] - INFO: epoch 006:    278 / 990 loss=2.394, loss_v1=0, loss_v2=0, nll_loss=1.196, ntokens=1941.5, nsentences=56, sample_size=1941.5, sample_size_v1=0, sample_size_v2=0, ppl=2.29, wps=1119.7, ups=0.58, wpb=1941.5, bsz=56, num_updates=5220, lr=2.13969e-05, gnorm=1.929, clip=100, loss_scale=256, train_wall=17, gb_free=12.7, wall=9011
2023-06-27 18:49:05 - progress_bar.py[line:272] - INFO: epoch 006:    288 / 990 loss=2.392, loss_v1=0, loss_v2=0, nll_loss=1.195, ntokens=1851.2, nsentences=56, sample_size=1851.2, sample_size_v1=0, sample_size_v2=0, ppl=2.29, wps=1076, ups=0.58, wpb=1851.2, bsz=56, num_updates=5230, lr=2.13768e-05, gnorm=2.029, clip=100, loss_scale=256, train_wall=17, gb_free=12.6, wall=9028
2023-06-27 18:49:22 - progress_bar.py[line:272] - INFO: epoch 006:    298 / 990 loss=2.393, loss_v1=0, loss_v2=0, nll_loss=1.196, ntokens=1889.9, nsentences=56, sample_size=1889.9, sample_size_v1=0, sample_size_v2=0, ppl=2.29, wps=1101.8, ups=0.58, wpb=1889.9, bsz=56, num_updates=5240, lr=2.13566e-05, gnorm=1.957, clip=100, loss_scale=256, train_wall=17, gb_free=12.5, wall=9045
2023-06-27 18:49:40 - progress_bar.py[line:272] - INFO: epoch 006:    308 / 990 loss=2.383, loss_v1=0, loss_v2=0, nll_loss=1.183, ntokens=1878.7, nsentences=56, sample_size=1878.7, sample_size_v1=0, sample_size_v2=0, ppl=2.27, wps=1089.2, ups=0.58, wpb=1878.7, bsz=56, num_updates=5250, lr=2.13365e-05, gnorm=1.899, clip=100, loss_scale=256, train_wall=17, gb_free=12.5, wall=9062
2023-06-27 18:49:57 - progress_bar.py[line:272] - INFO: epoch 006:    318 / 990 loss=2.389, loss_v1=0, loss_v2=0, nll_loss=1.192, ntokens=1926.7, nsentences=56, sample_size=1926.7, sample_size_v1=0, sample_size_v2=0, ppl=2.28, wps=1116.8, ups=0.58, wpb=1926.7, bsz=56, num_updates=5260, lr=2.13163e-05, gnorm=2.056, clip=100, loss_scale=256, train_wall=17, gb_free=11.4, wall=9080
2023-06-27 18:50:14 - progress_bar.py[line:272] - INFO: epoch 006:    328 / 990 loss=2.375, loss_v1=0, loss_v2=0, nll_loss=1.174, ntokens=1920.6, nsentences=56, sample_size=1920.6, sample_size_v1=0, sample_size_v2=0, ppl=2.26, wps=1110.7, ups=0.58, wpb=1920.6, bsz=56, num_updates=5270, lr=2.12962e-05, gnorm=1.9, clip=100, loss_scale=256, train_wall=17, gb_free=12.5, wall=9097
2023-06-27 18:50:31 - progress_bar.py[line:272] - INFO: epoch 006:    338 / 990 loss=2.377, loss_v1=0, loss_v2=0, nll_loss=1.179, ntokens=1873.3, nsentences=56, sample_size=1873.3, sample_size_v1=0, sample_size_v2=0, ppl=2.26, wps=1087.2, ups=0.58, wpb=1873.3, bsz=56, num_updates=5280, lr=2.1276e-05, gnorm=2.001, clip=100, loss_scale=256, train_wall=17, gb_free=12.1, wall=9114
2023-06-27 18:50:49 - progress_bar.py[line:272] - INFO: epoch 006:    348 / 990 loss=2.378, loss_v1=0, loss_v2=0, nll_loss=1.177, ntokens=1887.5, nsentences=56, sample_size=1887.5, sample_size_v1=0, sample_size_v2=0, ppl=2.26, wps=1097.9, ups=0.58, wpb=1887.5, bsz=56, num_updates=5290, lr=2.12559e-05, gnorm=1.963, clip=100, loss_scale=256, train_wall=17, gb_free=12.2, wall=9131
2023-06-27 18:51:06 - progress_bar.py[line:272] - INFO: epoch 006:    358 / 990 loss=2.363, loss_v1=0, loss_v2=0, nll_loss=1.163, ntokens=1816.8, nsentences=56, sample_size=1816.8, sample_size_v1=0, sample_size_v2=0, ppl=2.24, wps=1059.8, ups=0.58, wpb=1816.8, bsz=56, num_updates=5300, lr=2.12357e-05, gnorm=2.039, clip=100, loss_scale=256, train_wall=17, gb_free=12.9, wall=9148
2023-06-27 18:51:23 - progress_bar.py[line:272] - INFO: epoch 006:    368 / 990 loss=2.404, loss_v1=0, loss_v2=0, nll_loss=1.207, ntokens=1709.4, nsentences=56, sample_size=1709.4, sample_size_v1=0, sample_size_v2=0, ppl=2.31, wps=1000.3, ups=0.59, wpb=1709.4, bsz=56, num_updates=5310, lr=2.12156e-05, gnorm=2.1, clip=100, loss_scale=256, train_wall=17, gb_free=12.5, wall=9165
2023-06-27 18:51:40 - progress_bar.py[line:272] - INFO: epoch 006:    378 / 990 loss=2.385, loss_v1=0, loss_v2=0, nll_loss=1.183, ntokens=1882.9, nsentences=56, sample_size=1882.9, sample_size_v1=0, sample_size_v2=0, ppl=2.27, wps=1100.9, ups=0.58, wpb=1882.9, bsz=56, num_updates=5320, lr=2.11954e-05, gnorm=2.17, clip=100, loss_scale=256, train_wall=17, gb_free=12.8, wall=9183
2023-06-27 18:51:57 - progress_bar.py[line:272] - INFO: epoch 006:    388 / 990 loss=2.351, loss_v1=0, loss_v2=0, nll_loss=1.15, ntokens=1828.9, nsentences=56, sample_size=1828.9, sample_size_v1=0, sample_size_v2=0, ppl=2.22, wps=1068.1, ups=0.58, wpb=1828.9, bsz=56, num_updates=5330, lr=2.11753e-05, gnorm=2.063, clip=100, loss_scale=256, train_wall=17, gb_free=12.1, wall=9200
2023-06-27 18:52:14 - progress_bar.py[line:272] - INFO: epoch 006:    398 / 990 loss=2.378, loss_v1=0, loss_v2=0, nll_loss=1.178, ntokens=1668.9, nsentences=56, sample_size=1668.9, sample_size_v1=0, sample_size_v2=0, ppl=2.26, wps=978.5, ups=0.59, wpb=1668.9, bsz=56, num_updates=5340, lr=2.11551e-05, gnorm=2.077, clip=100, loss_scale=256, train_wall=17, gb_free=12.9, wall=9217
2023-06-27 18:52:31 - progress_bar.py[line:272] - INFO: epoch 006:    408 / 990 loss=2.407, loss_v1=0, loss_v2=0, nll_loss=1.209, ntokens=1744.9, nsentences=56, sample_size=1744.9, sample_size_v1=0, sample_size_v2=0, ppl=2.31, wps=1023.9, ups=0.59, wpb=1744.9, bsz=56, num_updates=5350, lr=2.1135e-05, gnorm=2.147, clip=100, loss_scale=256, train_wall=17, gb_free=13.1, wall=9234
2023-06-27 18:52:48 - progress_bar.py[line:272] - INFO: epoch 006:    418 / 990 loss=2.382, loss_v1=0, loss_v2=0, nll_loss=1.184, ntokens=1737.8, nsentences=56, sample_size=1737.8, sample_size_v1=0, sample_size_v2=0, ppl=2.27, wps=1020.1, ups=0.59, wpb=1737.8, bsz=56, num_updates=5360, lr=2.11148e-05, gnorm=1.98, clip=100, loss_scale=256, train_wall=17, gb_free=12.8, wall=9251
2023-06-27 18:53:05 - progress_bar.py[line:272] - INFO: epoch 006:    428 / 990 loss=2.371, loss_v1=0, loss_v2=0, nll_loss=1.169, ntokens=1872, nsentences=56, sample_size=1872, sample_size_v1=0, sample_size_v2=0, ppl=2.25, wps=1091.6, ups=0.58, wpb=1872, bsz=56, num_updates=5370, lr=2.10947e-05, gnorm=2.048, clip=100, loss_scale=256, train_wall=17, gb_free=12.2, wall=9268
2023-06-27 18:53:22 - progress_bar.py[line:272] - INFO: epoch 006:    438 / 990 loss=2.37, loss_v1=0, loss_v2=0, nll_loss=1.171, ntokens=1860.7, nsentences=56, sample_size=1860.7, sample_size_v1=0, sample_size_v2=0, ppl=2.25, wps=1088.9, ups=0.59, wpb=1860.7, bsz=56, num_updates=5380, lr=2.10745e-05, gnorm=2.009, clip=100, loss_scale=256, train_wall=17, gb_free=12.9, wall=9285
2023-06-27 18:53:39 - progress_bar.py[line:272] - INFO: epoch 006:    448 / 990 loss=2.366, loss_v1=0, loss_v2=0, nll_loss=1.164, ntokens=1822.7, nsentences=56, sample_size=1822.7, sample_size_v1=0, sample_size_v2=0, ppl=2.24, wps=1068.4, ups=0.59, wpb=1822.7, bsz=56, num_updates=5390, lr=2.10544e-05, gnorm=2.009, clip=100, loss_scale=256, train_wall=17, gb_free=12.8, wall=9302
2023-06-27 18:53:57 - progress_bar.py[line:272] - INFO: epoch 006:    458 / 990 loss=2.388, loss_v1=0, loss_v2=0, nll_loss=1.19, ntokens=1786.2, nsentences=56, sample_size=1786.2, sample_size_v1=0, sample_size_v2=0, ppl=2.28, wps=1034.6, ups=0.58, wpb=1786.2, bsz=56, num_updates=5400, lr=2.10343e-05, gnorm=2.26, clip=100, loss_scale=256, train_wall=17, gb_free=12.3, wall=9319
2023-06-27 18:54:14 - progress_bar.py[line:272] - INFO: epoch 006:    468 / 990 loss=2.377, loss_v1=0, loss_v2=0, nll_loss=1.176, ntokens=1879.8, nsentences=56, sample_size=1879.8, sample_size_v1=0, sample_size_v2=0, ppl=2.26, wps=1093.8, ups=0.58, wpb=1879.8, bsz=56, num_updates=5410, lr=2.10141e-05, gnorm=2.102, clip=100, loss_scale=512, train_wall=17, gb_free=12.1, wall=9337
2023-06-27 18:54:16 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 256.0
2023-06-27 18:54:33 - progress_bar.py[line:272] - INFO: epoch 006:    479 / 990 loss=2.37, loss_v1=0, loss_v2=0, nll_loss=1.17, ntokens=1813.4, nsentences=56, sample_size=1813.4, sample_size_v1=0, sample_size_v2=0, ppl=2.25, wps=963.1, ups=0.53, wpb=1813.4, bsz=56, num_updates=5420, lr=2.0994e-05, gnorm=1.981, clip=100, loss_scale=256, train_wall=19, gb_free=12.8, wall=9355
2023-06-27 18:54:50 - progress_bar.py[line:272] - INFO: epoch 006:    489 / 990 loss=2.355, loss_v1=0, loss_v2=0, nll_loss=1.154, ntokens=1870.3, nsentences=56, sample_size=1870.3, sample_size_v1=0, sample_size_v2=0, ppl=2.22, wps=1087.4, ups=0.58, wpb=1870.3, bsz=56, num_updates=5430, lr=2.09738e-05, gnorm=1.925, clip=100, loss_scale=256, train_wall=17, gb_free=12, wall=9373
2023-06-27 18:55:07 - progress_bar.py[line:272] - INFO: epoch 006:    499 / 990 loss=2.381, loss_v1=0, loss_v2=0, nll_loss=1.182, ntokens=1869.2, nsentences=56, sample_size=1869.2, sample_size_v1=0, sample_size_v2=0, ppl=2.27, wps=1088.1, ups=0.58, wpb=1869.2, bsz=56, num_updates=5440, lr=2.09537e-05, gnorm=1.901, clip=100, loss_scale=256, train_wall=17, gb_free=12.2, wall=9390
2023-06-27 18:55:24 - progress_bar.py[line:272] - INFO: epoch 006:    509 / 990 loss=2.402, loss_v1=0, loss_v2=0, nll_loss=1.206, ntokens=1759.5, nsentences=56, sample_size=1759.5, sample_size_v1=0, sample_size_v2=0, ppl=2.31, wps=1027.8, ups=0.58, wpb=1759.5, bsz=56, num_updates=5450, lr=2.09335e-05, gnorm=2.143, clip=100, loss_scale=256, train_wall=17, gb_free=12.4, wall=9407
2023-06-27 18:55:41 - progress_bar.py[line:272] - INFO: epoch 006:    519 / 990 loss=2.375, loss_v1=0, loss_v2=0, nll_loss=1.175, ntokens=1748.2, nsentences=56, sample_size=1748.2, sample_size_v1=0, sample_size_v2=0, ppl=2.26, wps=1029, ups=0.59, wpb=1748.2, bsz=56, num_updates=5460, lr=2.09134e-05, gnorm=2.306, clip=100, loss_scale=256, train_wall=17, gb_free=12.2, wall=9424
2023-06-27 18:55:59 - progress_bar.py[line:272] - INFO: epoch 006:    529 / 990 loss=2.373, loss_v1=0, loss_v2=0, nll_loss=1.172, ntokens=1934.5, nsentences=56, sample_size=1934.5, sample_size_v1=0, sample_size_v2=0, ppl=2.25, wps=1123.4, ups=0.58, wpb=1934.5, bsz=56, num_updates=5470, lr=2.08932e-05, gnorm=2.026, clip=100, loss_scale=256, train_wall=17, gb_free=12, wall=9441
2023-06-27 18:56:16 - progress_bar.py[line:272] - INFO: epoch 006:    539 / 990 loss=2.375, loss_v1=0, loss_v2=0, nll_loss=1.174, ntokens=1925.1, nsentences=56, sample_size=1925.1, sample_size_v1=0, sample_size_v2=0, ppl=2.26, wps=1123, ups=0.58, wpb=1925.1, bsz=56, num_updates=5480, lr=2.08731e-05, gnorm=2.116, clip=100, loss_scale=256, train_wall=17, gb_free=12.5, wall=9458
2023-06-27 18:56:33 - progress_bar.py[line:272] - INFO: epoch 006:    549 / 990 loss=2.374, loss_v1=0, loss_v2=0, nll_loss=1.175, ntokens=1940.8, nsentences=56, sample_size=1940.8, sample_size_v1=0, sample_size_v2=0, ppl=2.26, wps=1132.4, ups=0.58, wpb=1940.8, bsz=56, num_updates=5490, lr=2.08529e-05, gnorm=2.118, clip=100, loss_scale=256, train_wall=17, gb_free=11.2, wall=9475
2023-06-27 18:56:50 - progress_bar.py[line:272] - INFO: epoch 006:    559 / 990 loss=2.355, loss_v1=0, loss_v2=0, nll_loss=1.153, ntokens=1778.5, nsentences=56, sample_size=1778.5, sample_size_v1=0, sample_size_v2=0, ppl=2.22, wps=1034.3, ups=0.58, wpb=1778.5, bsz=56, num_updates=5500, lr=2.08328e-05, gnorm=2.31, clip=100, loss_scale=256, train_wall=17, gb_free=12.7, wall=9493
2023-06-27 18:57:07 - progress_bar.py[line:272] - INFO: epoch 006:    569 / 990 loss=2.358, loss_v1=0, loss_v2=0, nll_loss=1.157, ntokens=1809.2, nsentences=56, sample_size=1809.2, sample_size_v1=0, sample_size_v2=0, ppl=2.23, wps=1058.6, ups=0.59, wpb=1809.2, bsz=56, num_updates=5510, lr=2.08126e-05, gnorm=2.059, clip=100, loss_scale=256, train_wall=17, gb_free=13.1, wall=9510
2023-06-27 18:57:24 - progress_bar.py[line:272] - INFO: epoch 006:    579 / 990 loss=2.393, loss_v1=0, loss_v2=0, nll_loss=1.195, ntokens=1834.9, nsentences=56, sample_size=1834.9, sample_size_v1=0, sample_size_v2=0, ppl=2.29, wps=1076.8, ups=0.59, wpb=1834.9, bsz=56, num_updates=5520, lr=2.07925e-05, gnorm=2.121, clip=100, loss_scale=256, train_wall=17, gb_free=12.7, wall=9527
2023-06-27 18:57:41 - progress_bar.py[line:272] - INFO: epoch 006:    589 / 990 loss=2.391, loss_v1=0, loss_v2=0, nll_loss=1.191, ntokens=1960.7, nsentences=56, sample_size=1960.7, sample_size_v1=0, sample_size_v2=0, ppl=2.28, wps=1145.9, ups=0.58, wpb=1960.7, bsz=56, num_updates=5530, lr=2.07723e-05, gnorm=2.065, clip=100, loss_scale=256, train_wall=17, gb_free=12, wall=9544
2023-06-27 18:57:58 - progress_bar.py[line:272] - INFO: epoch 006:    599 / 990 loss=2.37, loss_v1=0, loss_v2=0, nll_loss=1.17, ntokens=1806.5, nsentences=56, sample_size=1806.5, sample_size_v1=0, sample_size_v2=0, ppl=2.25, wps=1064.6, ups=0.59, wpb=1806.5, bsz=56, num_updates=5540, lr=2.07522e-05, gnorm=2.308, clip=100, loss_scale=256, train_wall=17, gb_free=12.7, wall=9561
2023-06-27 18:58:15 - progress_bar.py[line:272] - INFO: epoch 006:    609 / 990 loss=2.36, loss_v1=0, loss_v2=0, nll_loss=1.157, ntokens=1788.9, nsentences=56, sample_size=1788.9, sample_size_v1=0, sample_size_v2=0, ppl=2.23, wps=1050.4, ups=0.59, wpb=1788.9, bsz=56, num_updates=5550, lr=2.0732e-05, gnorm=2.077, clip=100, loss_scale=256, train_wall=17, gb_free=12.9, wall=9578
2023-06-27 18:58:32 - progress_bar.py[line:272] - INFO: epoch 006:    619 / 990 loss=2.379, loss_v1=0, loss_v2=0, nll_loss=1.18, ntokens=1869.2, nsentences=56, sample_size=1869.2, sample_size_v1=0, sample_size_v2=0, ppl=2.27, wps=1095.1, ups=0.59, wpb=1869.2, bsz=56, num_updates=5560, lr=2.07119e-05, gnorm=2.053, clip=100, loss_scale=256, train_wall=17, gb_free=12.1, wall=9595
2023-06-27 18:58:50 - progress_bar.py[line:272] - INFO: epoch 006:    629 / 990 loss=2.393, loss_v1=0, loss_v2=0, nll_loss=1.196, ntokens=2074.2, nsentences=56, sample_size=2074.2, sample_size_v1=0, sample_size_v2=0, ppl=2.29, wps=1204, ups=0.58, wpb=2074.2, bsz=56, num_updates=5570, lr=2.06917e-05, gnorm=1.897, clip=100, loss_scale=256, train_wall=17, gb_free=12.2, wall=9612
2023-06-27 18:59:06 - progress_bar.py[line:272] - INFO: epoch 006:    639 / 990 loss=2.375, loss_v1=0, loss_v2=0, nll_loss=1.175, ntokens=1971.3, nsentences=54.8, sample_size=1971.3, sample_size_v1=0, sample_size_v2=0, ppl=2.26, wps=1165.4, ups=0.59, wpb=1971.3, bsz=54.8, num_updates=5580, lr=2.06716e-05, gnorm=2.098, clip=100, loss_scale=256, train_wall=17, gb_free=11.6, wall=9629
2023-06-27 18:59:24 - progress_bar.py[line:272] - INFO: epoch 006:    649 / 990 loss=2.386, loss_v1=0, loss_v2=0, nll_loss=1.189, ntokens=1950.5, nsentences=56, sample_size=1950.5, sample_size_v1=0, sample_size_v2=0, ppl=2.28, wps=1139.9, ups=0.58, wpb=1950.5, bsz=56, num_updates=5590, lr=2.06514e-05, gnorm=1.971, clip=100, loss_scale=256, train_wall=17, gb_free=12.5, wall=9646
2023-06-27 18:59:41 - progress_bar.py[line:272] - INFO: epoch 006:    659 / 990 loss=2.375, loss_v1=0, loss_v2=0, nll_loss=1.174, ntokens=1861.3, nsentences=56, sample_size=1861.3, sample_size_v1=0, sample_size_v2=0, ppl=2.26, wps=1084.9, ups=0.58, wpb=1861.3, bsz=56, num_updates=5600, lr=2.06313e-05, gnorm=2.029, clip=100, loss_scale=256, train_wall=17, gb_free=13.2, wall=9663
2023-06-27 18:59:58 - progress_bar.py[line:272] - INFO: epoch 006:    669 / 990 loss=2.384, loss_v1=0, loss_v2=0, nll_loss=1.184, ntokens=1878.3, nsentences=56, sample_size=1878.3, sample_size_v1=0, sample_size_v2=0, ppl=2.27, wps=1095.6, ups=0.58, wpb=1878.3, bsz=56, num_updates=5610, lr=2.06111e-05, gnorm=2.104, clip=100, loss_scale=256, train_wall=17, gb_free=12.7, wall=9681
2023-06-27 19:00:15 - progress_bar.py[line:272] - INFO: epoch 006:    679 / 990 loss=2.352, loss_v1=0, loss_v2=0, nll_loss=1.15, ntokens=1856.6, nsentences=56, sample_size=1856.6, sample_size_v1=0, sample_size_v2=0, ppl=2.22, wps=1082.5, ups=0.58, wpb=1856.6, bsz=56, num_updates=5620, lr=2.0591e-05, gnorm=1.951, clip=100, loss_scale=256, train_wall=17, gb_free=12.6, wall=9698
2023-06-27 19:00:32 - progress_bar.py[line:272] - INFO: epoch 006:    689 / 990 loss=2.344, loss_v1=0, loss_v2=0, nll_loss=1.143, ntokens=1830.2, nsentences=56, sample_size=1830.2, sample_size_v1=0, sample_size_v2=0, ppl=2.21, wps=1069.8, ups=0.58, wpb=1830.2, bsz=56, num_updates=5630, lr=2.05709e-05, gnorm=2.17, clip=100, loss_scale=256, train_wall=17, gb_free=12.5, wall=9715
2023-06-27 19:00:49 - progress_bar.py[line:272] - INFO: epoch 006:    699 / 990 loss=2.382, loss_v1=0, loss_v2=0, nll_loss=1.182, ntokens=1695.1, nsentences=56, sample_size=1695.1, sample_size_v1=0, sample_size_v2=0, ppl=2.27, wps=993.7, ups=0.59, wpb=1695.1, bsz=56, num_updates=5640, lr=2.05507e-05, gnorm=2.409, clip=100, loss_scale=256, train_wall=17, gb_free=13, wall=9732
2023-06-27 19:01:06 - progress_bar.py[line:272] - INFO: epoch 006:    709 / 990 loss=2.389, loss_v1=0, loss_v2=0, nll_loss=1.189, ntokens=1741.5, nsentences=56, sample_size=1741.5, sample_size_v1=0, sample_size_v2=0, ppl=2.28, wps=1024.2, ups=0.59, wpb=1741.5, bsz=56, num_updates=5650, lr=2.05306e-05, gnorm=2.257, clip=100, loss_scale=256, train_wall=17, gb_free=13.1, wall=9749
2023-06-27 19:01:23 - progress_bar.py[line:272] - INFO: epoch 006:    719 / 990 loss=2.363, loss_v1=0, loss_v2=0, nll_loss=1.163, ntokens=1770.1, nsentences=56, sample_size=1770.1, sample_size_v1=0, sample_size_v2=0, ppl=2.24, wps=1042.9, ups=0.59, wpb=1770.1, bsz=56, num_updates=5660, lr=2.05104e-05, gnorm=2.211, clip=100, loss_scale=256, train_wall=17, gb_free=13, wall=9766
2023-06-27 19:01:40 - progress_bar.py[line:272] - INFO: epoch 006:    729 / 990 loss=2.348, loss_v1=0, loss_v2=0, nll_loss=1.143, ntokens=1841.5, nsentences=56, sample_size=1841.5, sample_size_v1=0, sample_size_v2=0, ppl=2.21, wps=1078.5, ups=0.59, wpb=1841.5, bsz=56, num_updates=5670, lr=2.04903e-05, gnorm=2.248, clip=100, loss_scale=256, train_wall=17, gb_free=12.5, wall=9783
2023-06-27 19:01:57 - progress_bar.py[line:272] - INFO: epoch 006:    739 / 990 loss=2.375, loss_v1=0, loss_v2=0, nll_loss=1.175, ntokens=1797.2, nsentences=56, sample_size=1797.2, sample_size_v1=0, sample_size_v2=0, ppl=2.26, wps=1053.6, ups=0.59, wpb=1797.2, bsz=56, num_updates=5680, lr=2.04701e-05, gnorm=2.219, clip=100, loss_scale=256, train_wall=17, gb_free=13, wall=9800
2023-06-27 19:02:14 - progress_bar.py[line:272] - INFO: epoch 006:    749 / 990 loss=2.391, loss_v1=0, loss_v2=0, nll_loss=1.194, ntokens=1680.6, nsentences=56, sample_size=1680.6, sample_size_v1=0, sample_size_v2=0, ppl=2.29, wps=988.4, ups=0.59, wpb=1680.6, bsz=56, num_updates=5690, lr=2.045e-05, gnorm=2.236, clip=100, loss_scale=256, train_wall=17, gb_free=12.8, wall=9817
2023-06-27 19:02:31 - progress_bar.py[line:272] - INFO: epoch 006:    759 / 990 loss=2.391, loss_v1=0, loss_v2=0, nll_loss=1.191, ntokens=1704, nsentences=56, sample_size=1704, sample_size_v1=0, sample_size_v2=0, ppl=2.28, wps=1002.1, ups=0.59, wpb=1704, bsz=56, num_updates=5700, lr=2.04298e-05, gnorm=2.281, clip=100, loss_scale=256, train_wall=17, gb_free=12.9, wall=9834
2023-06-27 19:02:48 - progress_bar.py[line:272] - INFO: epoch 006:    769 / 990 loss=2.381, loss_v1=0, loss_v2=0, nll_loss=1.182, ntokens=1824.9, nsentences=56, sample_size=1824.9, sample_size_v1=0, sample_size_v2=0, ppl=2.27, wps=1068.3, ups=0.59, wpb=1824.9, bsz=56, num_updates=5710, lr=2.04097e-05, gnorm=2.083, clip=100, loss_scale=256, train_wall=17, gb_free=12.8, wall=9851
2023-06-27 19:03:06 - progress_bar.py[line:272] - INFO: epoch 006:    779 / 990 loss=2.355, loss_v1=0, loss_v2=0, nll_loss=1.153, ntokens=1825.6, nsentences=56, sample_size=1825.6, sample_size_v1=0, sample_size_v2=0, ppl=2.22, wps=1067.3, ups=0.58, wpb=1825.6, bsz=56, num_updates=5720, lr=2.03895e-05, gnorm=2.448, clip=100, loss_scale=256, train_wall=17, gb_free=12.2, wall=9868
2023-06-27 19:03:23 - progress_bar.py[line:272] - INFO: epoch 006:    789 / 990 loss=2.376, loss_v1=0, loss_v2=0, nll_loss=1.179, ntokens=1741.4, nsentences=56, sample_size=1741.4, sample_size_v1=0, sample_size_v2=0, ppl=2.26, wps=1021.6, ups=0.59, wpb=1741.4, bsz=56, num_updates=5730, lr=2.03694e-05, gnorm=2.406, clip=100, loss_scale=256, train_wall=17, gb_free=11.8, wall=9885
2023-06-27 19:03:40 - progress_bar.py[line:272] - INFO: epoch 006:    799 / 990 loss=2.389, loss_v1=0, loss_v2=0, nll_loss=1.188, ntokens=1838.7, nsentences=56, sample_size=1838.7, sample_size_v1=0, sample_size_v2=0, ppl=2.28, wps=1076.6, ups=0.59, wpb=1838.7, bsz=56, num_updates=5740, lr=2.03492e-05, gnorm=2.206, clip=100, loss_scale=256, train_wall=17, gb_free=12.9, wall=9902
2023-06-27 19:03:57 - progress_bar.py[line:272] - INFO: epoch 006:    809 / 990 loss=2.382, loss_v1=0, loss_v2=0, nll_loss=1.182, ntokens=1747.9, nsentences=56, sample_size=1747.9, sample_size_v1=0, sample_size_v2=0, ppl=2.27, wps=1026, ups=0.59, wpb=1747.9, bsz=56, num_updates=5750, lr=2.03291e-05, gnorm=2.324, clip=100, loss_scale=256, train_wall=17, gb_free=13, wall=9919
2023-06-27 19:04:14 - progress_bar.py[line:272] - INFO: epoch 006:    819 / 990 loss=2.39, loss_v1=0, loss_v2=0, nll_loss=1.195, ntokens=1648.8, nsentences=56, sample_size=1648.8, sample_size_v1=0, sample_size_v2=0, ppl=2.29, wps=967.6, ups=0.59, wpb=1648.8, bsz=56, num_updates=5760, lr=2.03089e-05, gnorm=2.402, clip=100, loss_scale=256, train_wall=17, gb_free=12.8, wall=9936
2023-06-27 19:04:31 - progress_bar.py[line:272] - INFO: epoch 006:    829 / 990 loss=2.346, loss_v1=0, loss_v2=0, nll_loss=1.142, ntokens=1759, nsentences=56, sample_size=1759, sample_size_v1=0, sample_size_v2=0, ppl=2.21, wps=1032.9, ups=0.59, wpb=1759, bsz=56, num_updates=5770, lr=2.02888e-05, gnorm=2.206, clip=100, loss_scale=256, train_wall=17, gb_free=12.8, wall=9953
2023-06-27 19:04:48 - progress_bar.py[line:272] - INFO: epoch 006:    839 / 990 loss=2.365, loss_v1=0, loss_v2=0, nll_loss=1.163, ntokens=1765, nsentences=56, sample_size=1765, sample_size_v1=0, sample_size_v2=0, ppl=2.24, wps=1035.2, ups=0.59, wpb=1765, bsz=56, num_updates=5780, lr=2.02686e-05, gnorm=2.108, clip=100, loss_scale=256, train_wall=17, gb_free=12.6, wall=9971
2023-06-27 19:05:05 - progress_bar.py[line:272] - INFO: epoch 006:    849 / 990 loss=2.346, loss_v1=0, loss_v2=0, nll_loss=1.14, ntokens=1902.3, nsentences=56, sample_size=1902.3, sample_size_v1=0, sample_size_v2=0, ppl=2.2, wps=1112.3, ups=0.58, wpb=1902.3, bsz=56, num_updates=5790, lr=2.02485e-05, gnorm=2.213, clip=100, loss_scale=256, train_wall=17, gb_free=13, wall=9988
2023-06-27 19:05:22 - progress_bar.py[line:272] - INFO: epoch 006:    859 / 990 loss=2.343, loss_v1=0, loss_v2=0, nll_loss=1.141, ntokens=1808.2, nsentences=56, sample_size=1808.2, sample_size_v1=0, sample_size_v2=0, ppl=2.2, wps=1043.4, ups=0.58, wpb=1808.2, bsz=56, num_updates=5800, lr=2.02283e-05, gnorm=2.305, clip=100, loss_scale=256, train_wall=17, gb_free=12.4, wall=10005
2023-06-27 19:05:39 - progress_bar.py[line:272] - INFO: epoch 006:    869 / 990 loss=2.355, loss_v1=0, loss_v2=0, nll_loss=1.153, ntokens=1863.9, nsentences=56, sample_size=1863.9, sample_size_v1=0, sample_size_v2=0, ppl=2.22, wps=1089.1, ups=0.58, wpb=1863.9, bsz=56, num_updates=5810, lr=2.02082e-05, gnorm=2.285, clip=100, loss_scale=256, train_wall=17, gb_free=12.4, wall=10022
2023-06-27 19:05:56 - progress_bar.py[line:272] - INFO: epoch 006:    879 / 990 loss=2.346, loss_v1=0, loss_v2=0, nll_loss=1.142, ntokens=1825.2, nsentences=56, sample_size=1825.2, sample_size_v1=0, sample_size_v2=0, ppl=2.21, wps=1073.8, ups=0.59, wpb=1825.2, bsz=56, num_updates=5820, lr=2.0188e-05, gnorm=2.171, clip=100, loss_scale=256, train_wall=17, gb_free=13.1, wall=10039
2023-06-27 19:06:14 - progress_bar.py[line:272] - INFO: epoch 006:    889 / 990 loss=2.346, loss_v1=0, loss_v2=0, nll_loss=1.141, ntokens=2016.1, nsentences=56, sample_size=2016.1, sample_size_v1=0, sample_size_v2=0, ppl=2.21, wps=1175.4, ups=0.58, wpb=2016.1, bsz=56, num_updates=5830, lr=2.01679e-05, gnorm=2.075, clip=100, loss_scale=256, train_wall=17, gb_free=13, wall=10056
2023-06-27 19:06:31 - progress_bar.py[line:272] - INFO: epoch 006:    899 / 990 loss=2.366, loss_v1=0, loss_v2=0, nll_loss=1.167, ntokens=1785.3, nsentences=56, sample_size=1785.3, sample_size_v1=0, sample_size_v2=0, ppl=2.25, wps=1045, ups=0.59, wpb=1785.3, bsz=56, num_updates=5840, lr=2.01478e-05, gnorm=2.287, clip=100, loss_scale=256, train_wall=17, gb_free=13.1, wall=10073
2023-06-27 19:06:48 - progress_bar.py[line:272] - INFO: epoch 006:    909 / 990 loss=2.373, loss_v1=0, loss_v2=0, nll_loss=1.171, ntokens=1833.1, nsentences=56, sample_size=1833.1, sample_size_v1=0, sample_size_v2=0, ppl=2.25, wps=1075.2, ups=0.59, wpb=1833.1, bsz=56, num_updates=5850, lr=2.01276e-05, gnorm=2.162, clip=100, loss_scale=256, train_wall=17, gb_free=12.4, wall=10090
2023-06-27 19:07:05 - progress_bar.py[line:272] - INFO: epoch 006:    919 / 990 loss=2.361, loss_v1=0, loss_v2=0, nll_loss=1.16, ntokens=1682.9, nsentences=56, sample_size=1682.9, sample_size_v1=0, sample_size_v2=0, ppl=2.23, wps=992.4, ups=0.59, wpb=1682.9, bsz=56, num_updates=5860, lr=2.01075e-05, gnorm=2.316, clip=100, loss_scale=256, train_wall=17, gb_free=12.7, wall=10107
2023-06-27 19:07:22 - progress_bar.py[line:272] - INFO: epoch 006:    929 / 990 loss=2.341, loss_v1=0, loss_v2=0, nll_loss=1.136, ntokens=1885, nsentences=56, sample_size=1885, sample_size_v1=0, sample_size_v2=0, ppl=2.2, wps=1097, ups=0.58, wpb=1885, bsz=56, num_updates=5870, lr=2.00873e-05, gnorm=2.177, clip=100, loss_scale=256, train_wall=17, gb_free=11.2, wall=10125
2023-06-27 19:07:39 - progress_bar.py[line:272] - INFO: epoch 006:    939 / 990 loss=2.357, loss_v1=0, loss_v2=0, nll_loss=1.155, ntokens=1813.2, nsentences=56, sample_size=1813.2, sample_size_v1=0, sample_size_v2=0, ppl=2.23, wps=1065.6, ups=0.59, wpb=1813.2, bsz=56, num_updates=5880, lr=2.00672e-05, gnorm=2.171, clip=100, loss_scale=256, train_wall=17, gb_free=12, wall=10142
2023-06-27 19:07:56 - progress_bar.py[line:272] - INFO: epoch 006:    949 / 990 loss=2.344, loss_v1=0, loss_v2=0, nll_loss=1.14, ntokens=1919.5, nsentences=56, sample_size=1919.5, sample_size_v1=0, sample_size_v2=0, ppl=2.2, wps=1116.4, ups=0.58, wpb=1919.5, bsz=56, num_updates=5890, lr=2.0047e-05, gnorm=2.03, clip=100, loss_scale=256, train_wall=17, gb_free=13, wall=10159
2023-06-27 19:08:13 - progress_bar.py[line:272] - INFO: epoch 006:    959 / 990 loss=2.359, loss_v1=0, loss_v2=0, nll_loss=1.157, ntokens=1852.6, nsentences=56, sample_size=1852.6, sample_size_v1=0, sample_size_v2=0, ppl=2.23, wps=1084.4, ups=0.59, wpb=1852.6, bsz=56, num_updates=5900, lr=2.00269e-05, gnorm=2.34, clip=100, loss_scale=256, train_wall=17, gb_free=12.8, wall=10176
2023-06-27 19:08:30 - progress_bar.py[line:272] - INFO: epoch 006:    969 / 990 loss=2.352, loss_v1=0, loss_v2=0, nll_loss=1.15, ntokens=1955.5, nsentences=56, sample_size=1955.5, sample_size_v1=0, sample_size_v2=0, ppl=2.22, wps=1139.6, ups=0.58, wpb=1955.5, bsz=56, num_updates=5910, lr=2.00067e-05, gnorm=2.114, clip=100, loss_scale=256, train_wall=17, gb_free=12.1, wall=10193
2023-06-27 19:08:47 - progress_bar.py[line:272] - INFO: epoch 006:    979 / 990 loss=2.355, loss_v1=0, loss_v2=0, nll_loss=1.154, ntokens=1834.6, nsentences=56, sample_size=1834.6, sample_size_v1=0, sample_size_v2=0, ppl=2.22, wps=1073.2, ups=0.58, wpb=1834.6, bsz=56, num_updates=5920, lr=1.99866e-05, gnorm=2.138, clip=100, loss_scale=256, train_wall=17, gb_free=12.8, wall=10210
2023-06-27 19:08:54 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 256.0
local datafile ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 1 begin to initialize row_count and line_idx-to-offset mapping
2023-06-27 19:09:05 - progress_bar.py[line:272] - INFO: epoch 006:    990 / 990 loss=2.382, loss_v1=0, loss_v2=0, nll_loss=1.181, ntokens=1760, nsentences=53.2, sample_size=1760, sample_size_v1=0, sample_size_v2=0, ppl=2.27, wps=985.8, ups=0.56, wpb=1760, bsz=53.2, num_updates=5930, lr=1.99664e-05, gnorm=2.248, clip=100, loss_scale=256, train_wall=18, gb_free=13.3, wall=10228
2023-06-27 19:09:05 - train.py[line:332] - INFO: end of epoch 6 (average epoch stats below)
2023-06-27 19:09:05 - progress_bar.py[line:282] - INFO: epoch 006 | loss 2.356 | loss_v1 0 | loss_v2 0 | nll_loss 1.154 | ntokens 1849.8 | nsentences 55.96 | sample_size 1849.8 | sample_size_v1 0 | sample_size_v2 0 | ppl 2.23 | wps 1074.4 | ups 0.58 | wpb 1849.8 | bsz 56 | num_updates 5930 | lr 1.99664e-05 | gnorm 2.066 | clip 100 | loss_scale 256 | train_wall 1696 | gb_free 13.3 | wall 10228
2023-06-27 19:09:05 - trainer.py[line:639] - INFO: loading train data for epoch 7
local datafile ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 0 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 1 finished initializing row_count and line_idx-to-offset mapping
file ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 1 row count 27700 total row count 55400
slice_id 1 seek offset 27700
local datafile ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 0 finished initializing row_count and line_idx-to-offset mapping
file ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 0 row count 27700 total row count 55400
slice_id 0 seek offset 0
2023-06-27 19:09:07 - trainer.py[line:703] - INFO: begin training epoch 7
2023-06-27 19:09:07 - train.py[line:305] - INFO: Start iterating over samples
2023-06-27 19:09:25 - progress_bar.py[line:272] - INFO: epoch 007:     10 / 990 loss=2.317, loss_v1=0, loss_v2=0, nll_loss=1.109, ntokens=1881.7, nsentences=56, sample_size=1881.7, sample_size_v1=0, sample_size_v2=0, ppl=2.16, wps=960.8, ups=0.51, wpb=1881.7, bsz=56, num_updates=5940, lr=1.99463e-05, gnorm=2.283, clip=100, loss_scale=256, train_wall=17, gb_free=12.3, wall=10248
2023-06-27 19:09:42 - progress_bar.py[line:272] - INFO: epoch 007:     20 / 990 loss=2.279, loss_v1=0, loss_v2=0, nll_loss=1.069, ntokens=1826.5, nsentences=56, sample_size=1826.5, sample_size_v1=0, sample_size_v2=0, ppl=2.1, wps=1055.7, ups=0.58, wpb=1826.5, bsz=56, num_updates=5950, lr=1.99261e-05, gnorm=2.15, clip=100, loss_scale=256, train_wall=17, gb_free=12.5, wall=10265
2023-06-27 19:09:59 - progress_bar.py[line:272] - INFO: epoch 007:     30 / 990 loss=2.338, loss_v1=0, loss_v2=0, nll_loss=1.131, ntokens=1697, nsentences=56, sample_size=1697, sample_size_v1=0, sample_size_v2=0, ppl=2.19, wps=996.2, ups=0.59, wpb=1697, bsz=56, num_updates=5960, lr=1.9906e-05, gnorm=2.328, clip=100, loss_scale=256, train_wall=17, gb_free=13, wall=10282
2023-06-27 19:10:17 - progress_bar.py[line:272] - INFO: epoch 007:     40 / 990 loss=2.24, loss_v1=0, loss_v2=0, nll_loss=1.026, ntokens=1930.1, nsentences=56, sample_size=1930.1, sample_size_v1=0, sample_size_v2=0, ppl=2.04, wps=1116.4, ups=0.58, wpb=1930.1, bsz=56, num_updates=5970, lr=1.98858e-05, gnorm=1.914, clip=100, loss_scale=256, train_wall=17, gb_free=12.1, wall=10299
2023-06-27 19:10:34 - progress_bar.py[line:272] - INFO: epoch 007:     50 / 990 loss=2.248, loss_v1=0, loss_v2=0, nll_loss=1.033, ntokens=1862.3, nsentences=56, sample_size=1862.3, sample_size_v1=0, sample_size_v2=0, ppl=2.05, wps=1073.4, ups=0.58, wpb=1862.3, bsz=56, num_updates=5980, lr=1.98657e-05, gnorm=2.1, clip=100, loss_scale=256, train_wall=17, gb_free=12.2, wall=10317
2023-06-27 19:10:51 - progress_bar.py[line:272] - INFO: epoch 007:     60 / 990 loss=2.308, loss_v1=0, loss_v2=0, nll_loss=1.102, ntokens=1754.8, nsentences=56, sample_size=1754.8, sample_size_v1=0, sample_size_v2=0, ppl=2.15, wps=1017.8, ups=0.58, wpb=1754.8, bsz=56, num_updates=5990, lr=1.98455e-05, gnorm=2.359, clip=100, loss_scale=256, train_wall=17, gb_free=12.7, wall=10334
2023-06-27 19:11:08 - progress_bar.py[line:272] - INFO: epoch 007:     70 / 990 loss=2.164, loss_v1=0, loss_v2=0, nll_loss=0.939, ntokens=1947.6, nsentences=56, sample_size=1947.6, sample_size_v1=0, sample_size_v2=0, ppl=1.92, wps=1122.5, ups=0.58, wpb=1947.6, bsz=56, num_updates=6000, lr=1.98254e-05, gnorm=2.064, clip=100, loss_scale=256, train_wall=17, gb_free=11.2, wall=10351
2023-06-27 19:11:26 - progress_bar.py[line:272] - INFO: epoch 007:     80 / 990 loss=2.194, loss_v1=0, loss_v2=0, nll_loss=0.972, ntokens=2179.3, nsentences=56, sample_size=2179.3, sample_size_v1=0, sample_size_v2=0, ppl=1.96, wps=1234.5, ups=0.57, wpb=2179.3, bsz=56, num_updates=6010, lr=1.98052e-05, gnorm=1.664, clip=100, loss_scale=256, train_wall=18, gb_free=11.7, wall=10369
2023-06-27 19:11:44 - progress_bar.py[line:272] - INFO: epoch 007:     90 / 990 loss=2.229, loss_v1=0, loss_v2=0, nll_loss=1.013, ntokens=2082.6, nsentences=56, sample_size=2082.6, sample_size_v1=0, sample_size_v2=0, ppl=2.02, wps=1178.8, ups=0.57, wpb=2082.6, bsz=56, num_updates=6020, lr=1.97851e-05, gnorm=1.895, clip=100, loss_scale=256, train_wall=18, gb_free=11.6, wall=10386
2023-06-27 19:12:01 - progress_bar.py[line:272] - INFO: epoch 007:    100 / 990 loss=2.287, loss_v1=0, loss_v2=0, nll_loss=1.077, ntokens=1854.4, nsentences=56, sample_size=1854.4, sample_size_v1=0, sample_size_v2=0, ppl=2.11, wps=1073, ups=0.58, wpb=1854.4, bsz=56, num_updates=6030, lr=1.97649e-05, gnorm=2.16, clip=100, loss_scale=256, train_wall=17, gb_free=12.5, wall=10404
2023-06-27 19:12:18 - progress_bar.py[line:272] - INFO: epoch 007:    110 / 990 loss=2.259, loss_v1=0, loss_v2=0, nll_loss=1.044, ntokens=1883, nsentences=56, sample_size=1883, sample_size_v1=0, sample_size_v2=0, ppl=2.06, wps=1095.7, ups=0.58, wpb=1883, bsz=56, num_updates=6040, lr=1.97448e-05, gnorm=2.039, clip=100, loss_scale=256, train_wall=17, gb_free=12.1, wall=10421
2023-06-27 19:12:35 - progress_bar.py[line:272] - INFO: epoch 007:    120 / 990 loss=2.352, loss_v1=0, loss_v2=0, nll_loss=1.152, ntokens=1794, nsentences=56, sample_size=1794, sample_size_v1=0, sample_size_v2=0, ppl=2.22, wps=1046.5, ups=0.58, wpb=1794, bsz=56, num_updates=6050, lr=1.97246e-05, gnorm=2.191, clip=100, loss_scale=256, train_wall=17, gb_free=12.6, wall=10438
2023-06-27 19:12:53 - progress_bar.py[line:272] - INFO: epoch 007:    130 / 990 loss=2.366, loss_v1=0, loss_v2=0, nll_loss=1.165, ntokens=1808.4, nsentences=56, sample_size=1808.4, sample_size_v1=0, sample_size_v2=0, ppl=2.24, wps=1050.2, ups=0.58, wpb=1808.4, bsz=56, num_updates=6060, lr=1.97045e-05, gnorm=2.082, clip=100, loss_scale=256, train_wall=17, gb_free=12.7, wall=10455
2023-06-27 19:13:10 - progress_bar.py[line:272] - INFO: epoch 007:    140 / 990 loss=2.339, loss_v1=0, loss_v2=0, nll_loss=1.132, ntokens=1930.2, nsentences=56, sample_size=1930.2, sample_size_v1=0, sample_size_v2=0, ppl=2.19, wps=1109.7, ups=0.57, wpb=1930.2, bsz=56, num_updates=6070, lr=1.96844e-05, gnorm=1.92, clip=100, loss_scale=256, train_wall=17, gb_free=11.7, wall=10473
2023-06-27 19:13:28 - progress_bar.py[line:272] - INFO: epoch 007:    150 / 990 loss=2.317, loss_v1=0, loss_v2=0, nll_loss=1.11, ntokens=1959.9, nsentences=56, sample_size=1959.9, sample_size_v1=0, sample_size_v2=0, ppl=2.16, wps=1122.4, ups=0.57, wpb=1959.9, bsz=56, num_updates=6080, lr=1.96642e-05, gnorm=1.996, clip=100, loss_scale=256, train_wall=17, gb_free=12.2, wall=10490
2023-06-27 19:13:45 - progress_bar.py[line:272] - INFO: epoch 007:    160 / 990 loss=2.304, loss_v1=0, loss_v2=0, nll_loss=1.095, ntokens=1996, nsentences=56, sample_size=1996, sample_size_v1=0, sample_size_v2=0, ppl=2.14, wps=1142.6, ups=0.57, wpb=1996, bsz=56, num_updates=6090, lr=1.96441e-05, gnorm=1.903, clip=100, loss_scale=256, train_wall=17, gb_free=11.3, wall=10508
2023-06-27 19:14:02 - progress_bar.py[line:272] - INFO: epoch 007:    170 / 990 loss=2.297, loss_v1=0, loss_v2=0, nll_loss=1.089, ntokens=1907.6, nsentences=56, sample_size=1907.6, sample_size_v1=0, sample_size_v2=0, ppl=2.13, wps=1097.2, ups=0.58, wpb=1907.6, bsz=56, num_updates=6100, lr=1.96239e-05, gnorm=1.944, clip=100, loss_scale=256, train_wall=17, gb_free=12.1, wall=10525
2023-06-27 19:14:20 - progress_bar.py[line:272] - INFO: epoch 007:    180 / 990 loss=2.314, loss_v1=0, loss_v2=0, nll_loss=1.106, ntokens=1986.2, nsentences=56, sample_size=1986.2, sample_size_v1=0, sample_size_v2=0, ppl=2.15, wps=1137.7, ups=0.57, wpb=1986.2, bsz=56, num_updates=6110, lr=1.96038e-05, gnorm=1.976, clip=100, loss_scale=256, train_wall=17, gb_free=12.6, wall=10542
2023-06-27 19:14:37 - progress_bar.py[line:272] - INFO: epoch 007:    190 / 990 loss=2.31, loss_v1=0, loss_v2=0, nll_loss=1.101, ntokens=1882.3, nsentences=56, sample_size=1882.3, sample_size_v1=0, sample_size_v2=0, ppl=2.15, wps=1091.4, ups=0.58, wpb=1882.3, bsz=56, num_updates=6120, lr=1.95836e-05, gnorm=2.043, clip=100, loss_scale=256, train_wall=17, gb_free=12.6, wall=10560
2023-06-27 19:14:54 - progress_bar.py[line:272] - INFO: epoch 007:    200 / 990 loss=2.308, loss_v1=0, loss_v2=0, nll_loss=1.099, ntokens=1760.5, nsentences=56, sample_size=1760.5, sample_size_v1=0, sample_size_v2=0, ppl=2.14, wps=1026, ups=0.58, wpb=1760.5, bsz=56, num_updates=6130, lr=1.95635e-05, gnorm=2.21, clip=100, loss_scale=256, train_wall=17, gb_free=12.1, wall=10577
2023-06-27 19:15:12 - progress_bar.py[line:272] - INFO: epoch 007:    210 / 990 loss=2.293, loss_v1=0, loss_v2=0, nll_loss=1.083, ntokens=1940.2, nsentences=56, sample_size=1940.2, sample_size_v1=0, sample_size_v2=0, ppl=2.12, wps=1117.9, ups=0.58, wpb=1940.2, bsz=56, num_updates=6140, lr=1.95433e-05, gnorm=1.937, clip=100, loss_scale=256, train_wall=17, gb_free=12.6, wall=10594
2023-06-27 19:15:29 - progress_bar.py[line:272] - INFO: epoch 007:    220 / 990 loss=2.299, loss_v1=0, loss_v2=0, nll_loss=1.087, ntokens=1961.1, nsentences=56, sample_size=1961.1, sample_size_v1=0, sample_size_v2=0, ppl=2.13, wps=1126.5, ups=0.57, wpb=1961.1, bsz=56, num_updates=6150, lr=1.95232e-05, gnorm=2.036, clip=100, loss_scale=256, train_wall=17, gb_free=12, wall=10612
2023-06-27 19:15:46 - progress_bar.py[line:272] - INFO: epoch 007:    230 / 990 loss=2.326, loss_v1=0, loss_v2=0, nll_loss=1.122, ntokens=1856, nsentences=56, sample_size=1856, sample_size_v1=0, sample_size_v2=0, ppl=2.18, wps=1074.6, ups=0.58, wpb=1856, bsz=56, num_updates=6160, lr=1.9503e-05, gnorm=2.18, clip=100, loss_scale=256, train_wall=17, gb_free=12.4, wall=10629
2023-06-27 19:16:03 - progress_bar.py[line:272] - INFO: epoch 007:    240 / 990 loss=2.374, loss_v1=0, loss_v2=0, nll_loss=1.173, ntokens=1736.9, nsentences=56, sample_size=1736.9, sample_size_v1=0, sample_size_v2=0, ppl=2.25, wps=1013.2, ups=0.58, wpb=1736.9, bsz=56, num_updates=6170, lr=1.94829e-05, gnorm=2.345, clip=100, loss_scale=256, train_wall=17, gb_free=12.6, wall=10646
2023-06-27 19:16:21 - progress_bar.py[line:272] - INFO: epoch 007:    250 / 990 loss=2.368, loss_v1=0, loss_v2=0, nll_loss=1.167, ntokens=1933.7, nsentences=56, sample_size=1933.7, sample_size_v1=0, sample_size_v2=0, ppl=2.25, wps=1125.2, ups=0.58, wpb=1933.7, bsz=56, num_updates=6180, lr=1.94627e-05, gnorm=2.143, clip=100, loss_scale=256, train_wall=17, gb_free=12.4, wall=10663
2023-06-27 19:16:38 - progress_bar.py[line:272] - INFO: epoch 007:    260 / 990 loss=2.363, loss_v1=0, loss_v2=0, nll_loss=1.161, ntokens=1914.5, nsentences=56, sample_size=1914.5, sample_size_v1=0, sample_size_v2=0, ppl=2.24, wps=1112.7, ups=0.58, wpb=1914.5, bsz=56, num_updates=6190, lr=1.94426e-05, gnorm=1.984, clip=100, loss_scale=256, train_wall=17, gb_free=12.8, wall=10681
2023-06-27 19:16:55 - progress_bar.py[line:272] - INFO: epoch 007:    270 / 990 loss=2.395, loss_v1=0, loss_v2=0, nll_loss=1.197, ntokens=1837.2, nsentences=56, sample_size=1837.2, sample_size_v1=0, sample_size_v2=0, ppl=2.29, wps=1069, ups=0.58, wpb=1837.2, bsz=56, num_updates=6200, lr=1.94224e-05, gnorm=2.236, clip=100, loss_scale=256, train_wall=17, gb_free=12.6, wall=10698
2023-06-27 19:17:12 - progress_bar.py[line:272] - INFO: epoch 007:    280 / 990 loss=2.371, loss_v1=0, loss_v2=0, nll_loss=1.169, ntokens=1965.8, nsentences=56, sample_size=1965.8, sample_size_v1=0, sample_size_v2=0, ppl=2.25, wps=1134.1, ups=0.58, wpb=1965.8, bsz=56, num_updates=6210, lr=1.94023e-05, gnorm=2.009, clip=100, loss_scale=256, train_wall=17, gb_free=12.4, wall=10715
2023-06-27 19:17:30 - progress_bar.py[line:272] - INFO: epoch 007:    290 / 990 loss=2.374, loss_v1=0, loss_v2=0, nll_loss=1.176, ntokens=1835.2, nsentences=56, sample_size=1835.2, sample_size_v1=0, sample_size_v2=0, ppl=2.26, wps=1066.8, ups=0.58, wpb=1835.2, bsz=56, num_updates=6220, lr=1.93821e-05, gnorm=2.301, clip=100, loss_scale=256, train_wall=17, gb_free=12.5, wall=10732
2023-06-27 19:17:47 - progress_bar.py[line:272] - INFO: epoch 007:    300 / 990 loss=2.385, loss_v1=0, loss_v2=0, nll_loss=1.186, ntokens=1894.2, nsentences=56, sample_size=1894.2, sample_size_v1=0, sample_size_v2=0, ppl=2.28, wps=1104.5, ups=0.58, wpb=1894.2, bsz=56, num_updates=6230, lr=1.9362e-05, gnorm=2.244, clip=100, loss_scale=256, train_wall=17, gb_free=12.8, wall=10749
2023-06-27 19:17:57 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 128.0
2023-06-27 19:18:06 - progress_bar.py[line:272] - INFO: epoch 007:    311 / 990 loss=2.364, loss_v1=0, loss_v2=0, nll_loss=1.161, ntokens=1883.2, nsentences=56, sample_size=1883.2, sample_size_v1=0, sample_size_v2=0, ppl=2.24, wps=993.9, ups=0.53, wpb=1883.2, bsz=56, num_updates=6240, lr=1.93418e-05, gnorm=2.277, clip=100, loss_scale=128, train_wall=19, gb_free=12.2, wall=10768
2023-06-27 19:18:23 - progress_bar.py[line:272] - INFO: epoch 007:    321 / 990 loss=2.377, loss_v1=0, loss_v2=0, nll_loss=1.179, ntokens=1903.2, nsentences=56, sample_size=1903.2, sample_size_v1=0, sample_size_v2=0, ppl=2.26, wps=1099.8, ups=0.58, wpb=1903.2, bsz=56, num_updates=6250, lr=1.93217e-05, gnorm=2.212, clip=100, loss_scale=128, train_wall=17, gb_free=12.9, wall=10786
2023-06-27 19:18:40 - progress_bar.py[line:272] - INFO: epoch 007:    331 / 990 loss=2.356, loss_v1=0, loss_v2=0, nll_loss=1.153, ntokens=1913.6, nsentences=56, sample_size=1913.6, sample_size_v1=0, sample_size_v2=0, ppl=2.22, wps=1107.5, ups=0.58, wpb=1913.6, bsz=56, num_updates=6260, lr=1.93015e-05, gnorm=2.314, clip=100, loss_scale=128, train_wall=17, gb_free=12.9, wall=10803
2023-06-27 19:18:57 - progress_bar.py[line:272] - INFO: epoch 007:    341 / 990 loss=2.36, loss_v1=0, loss_v2=0, nll_loss=1.159, ntokens=1857.3, nsentences=56, sample_size=1857.3, sample_size_v1=0, sample_size_v2=0, ppl=2.23, wps=1078.3, ups=0.58, wpb=1857.3, bsz=56, num_updates=6270, lr=1.92814e-05, gnorm=2.333, clip=100, loss_scale=128, train_wall=17, gb_free=12.1, wall=10820
2023-06-27 19:19:15 - progress_bar.py[line:272] - INFO: epoch 007:    351 / 990 loss=2.361, loss_v1=0, loss_v2=0, nll_loss=1.16, ntokens=1894.1, nsentences=56, sample_size=1894.1, sample_size_v1=0, sample_size_v2=0, ppl=2.24, wps=1100.6, ups=0.58, wpb=1894.1, bsz=56, num_updates=6280, lr=1.92612e-05, gnorm=2.171, clip=100, loss_scale=128, train_wall=17, gb_free=12.8, wall=10837
2023-06-27 19:19:32 - progress_bar.py[line:272] - INFO: epoch 007:    361 / 990 loss=2.358, loss_v1=0, loss_v2=0, nll_loss=1.155, ntokens=1794.2, nsentences=56, sample_size=1794.2, sample_size_v1=0, sample_size_v2=0, ppl=2.23, wps=1048.5, ups=0.58, wpb=1794.2, bsz=56, num_updates=6290, lr=1.92411e-05, gnorm=2.289, clip=100, loss_scale=128, train_wall=17, gb_free=12.2, wall=10854
2023-06-27 19:19:49 - progress_bar.py[line:272] - INFO: epoch 007:    371 / 990 loss=2.388, loss_v1=0, loss_v2=0, nll_loss=1.189, ntokens=1727.3, nsentences=56, sample_size=1727.3, sample_size_v1=0, sample_size_v2=0, ppl=2.28, wps=1014.3, ups=0.59, wpb=1727.3, bsz=56, num_updates=6300, lr=1.9221e-05, gnorm=2.455, clip=100, loss_scale=128, train_wall=17, gb_free=12.9, wall=10872
2023-06-27 19:20:06 - progress_bar.py[line:272] - INFO: epoch 007:    381 / 990 loss=2.359, loss_v1=0, loss_v2=0, nll_loss=1.157, ntokens=1897.6, nsentences=56, sample_size=1897.6, sample_size_v1=0, sample_size_v2=0, ppl=2.23, wps=1108, ups=0.58, wpb=1897.6, bsz=56, num_updates=6310, lr=1.92008e-05, gnorm=2.217, clip=100, loss_scale=128, train_wall=17, gb_free=12.7, wall=10889
2023-06-27 19:20:23 - progress_bar.py[line:272] - INFO: epoch 007:    391 / 990 loss=2.346, loss_v1=0, loss_v2=0, nll_loss=1.145, ntokens=1766.6, nsentences=56, sample_size=1766.6, sample_size_v1=0, sample_size_v2=0, ppl=2.21, wps=1034.5, ups=0.59, wpb=1766.6, bsz=56, num_updates=6320, lr=1.91807e-05, gnorm=2.333, clip=100, loss_scale=128, train_wall=17, gb_free=13.1, wall=10906
2023-06-27 19:20:40 - progress_bar.py[line:272] - INFO: epoch 007:    401 / 990 loss=2.376, loss_v1=0, loss_v2=0, nll_loss=1.173, ntokens=1711.8, nsentences=56, sample_size=1711.8, sample_size_v1=0, sample_size_v2=0, ppl=2.26, wps=1004, ups=0.59, wpb=1711.8, bsz=56, num_updates=6330, lr=1.91605e-05, gnorm=2.376, clip=100, loss_scale=128, train_wall=17, gb_free=12.6, wall=10923
2023-06-27 19:20:57 - progress_bar.py[line:272] - INFO: epoch 007:    411 / 990 loss=2.382, loss_v1=0, loss_v2=0, nll_loss=1.182, ntokens=1706.8, nsentences=56, sample_size=1706.8, sample_size_v1=0, sample_size_v2=0, ppl=2.27, wps=1003.6, ups=0.59, wpb=1706.8, bsz=56, num_updates=6340, lr=1.91404e-05, gnorm=2.308, clip=100, loss_scale=128, train_wall=17, gb_free=12.5, wall=10940
2023-06-27 19:21:14 - progress_bar.py[line:272] - INFO: epoch 007:    421 / 990 loss=2.376, loss_v1=0, loss_v2=0, nll_loss=1.177, ntokens=1745.8, nsentences=56, sample_size=1745.8, sample_size_v1=0, sample_size_v2=0, ppl=2.26, wps=1023.1, ups=0.59, wpb=1745.8, bsz=56, num_updates=6350, lr=1.91202e-05, gnorm=2.362, clip=100, loss_scale=128, train_wall=17, gb_free=12.7, wall=10957
2023-06-27 19:21:31 - progress_bar.py[line:272] - INFO: epoch 007:    431 / 990 loss=2.353, loss_v1=0, loss_v2=0, nll_loss=1.148, ntokens=1897.2, nsentences=56, sample_size=1897.2, sample_size_v1=0, sample_size_v2=0, ppl=2.22, wps=1103.8, ups=0.58, wpb=1897.2, bsz=56, num_updates=6360, lr=1.91001e-05, gnorm=2.162, clip=100, loss_scale=128, train_wall=17, gb_free=12.5, wall=10974
2023-06-27 19:21:48 - progress_bar.py[line:272] - INFO: epoch 007:    441 / 990 loss=2.357, loss_v1=0, loss_v2=0, nll_loss=1.156, ntokens=1892.3, nsentences=56, sample_size=1892.3, sample_size_v1=0, sample_size_v2=0, ppl=2.23, wps=1106.3, ups=0.58, wpb=1892.3, bsz=56, num_updates=6370, lr=1.90799e-05, gnorm=2.182, clip=100, loss_scale=128, train_wall=17, gb_free=12.4, wall=10991
2023-06-27 19:22:05 - progress_bar.py[line:272] - INFO: epoch 007:    451 / 990 loss=2.354, loss_v1=0, loss_v2=0, nll_loss=1.152, ntokens=1723.9, nsentences=56, sample_size=1723.9, sample_size_v1=0, sample_size_v2=0, ppl=2.22, wps=1016.4, ups=0.59, wpb=1723.9, bsz=56, num_updates=6380, lr=1.90598e-05, gnorm=2.391, clip=100, loss_scale=128, train_wall=17, gb_free=13, wall=11008
2023-06-27 19:22:23 - progress_bar.py[line:272] - INFO: epoch 007:    461 / 990 loss=2.36, loss_v1=0, loss_v2=0, nll_loss=1.158, ntokens=1889.2, nsentences=56, sample_size=1889.2, sample_size_v1=0, sample_size_v2=0, ppl=2.23, wps=1101.2, ups=0.58, wpb=1889.2, bsz=56, num_updates=6390, lr=1.90396e-05, gnorm=2.37, clip=100, loss_scale=128, train_wall=17, gb_free=12.4, wall=11025
2023-06-27 19:22:40 - progress_bar.py[line:272] - INFO: epoch 007:    471 / 990 loss=2.36, loss_v1=0, loss_v2=0, nll_loss=1.158, ntokens=1868.6, nsentences=56, sample_size=1868.6, sample_size_v1=0, sample_size_v2=0, ppl=2.23, wps=1089.7, ups=0.58, wpb=1868.6, bsz=56, num_updates=6400, lr=1.90195e-05, gnorm=2.125, clip=100, loss_scale=128, train_wall=17, gb_free=12.2, wall=11042
2023-06-27 19:22:57 - progress_bar.py[line:272] - INFO: epoch 007:    481 / 990 loss=2.351, loss_v1=0, loss_v2=0, nll_loss=1.148, ntokens=1810.1, nsentences=56, sample_size=1810.1, sample_size_v1=0, sample_size_v2=0, ppl=2.22, wps=1054.3, ups=0.58, wpb=1810.1, bsz=56, num_updates=6410, lr=1.89993e-05, gnorm=2.242, clip=100, loss_scale=128, train_wall=17, gb_free=12.6, wall=11060
2023-06-27 19:23:14 - progress_bar.py[line:272] - INFO: epoch 007:    491 / 990 loss=2.346, loss_v1=0, loss_v2=0, nll_loss=1.144, ntokens=1906.7, nsentences=56, sample_size=1906.7, sample_size_v1=0, sample_size_v2=0, ppl=2.21, wps=1112.7, ups=0.58, wpb=1906.7, bsz=56, num_updates=6420, lr=1.89792e-05, gnorm=2.113, clip=100, loss_scale=128, train_wall=17, gb_free=12.8, wall=11077
2023-06-27 19:23:31 - progress_bar.py[line:272] - INFO: epoch 007:    501 / 990 loss=2.377, loss_v1=0, loss_v2=0, nll_loss=1.177, ntokens=1838.8, nsentences=56, sample_size=1838.8, sample_size_v1=0, sample_size_v2=0, ppl=2.26, wps=1073.1, ups=0.58, wpb=1838.8, bsz=56, num_updates=6430, lr=1.8959e-05, gnorm=2.211, clip=100, loss_scale=128, train_wall=17, gb_free=11.8, wall=11094
2023-06-27 19:23:48 - progress_bar.py[line:272] - INFO: epoch 007:    511 / 990 loss=2.384, loss_v1=0, loss_v2=0, nll_loss=1.185, ntokens=1755, nsentences=56, sample_size=1755, sample_size_v1=0, sample_size_v2=0, ppl=2.27, wps=1027.3, ups=0.59, wpb=1755, bsz=56, num_updates=6440, lr=1.89389e-05, gnorm=2.544, clip=100, loss_scale=128, train_wall=17, gb_free=12.6, wall=11111
2023-06-27 19:24:05 - progress_bar.py[line:272] - INFO: epoch 007:    521 / 990 loss=2.365, loss_v1=0, loss_v2=0, nll_loss=1.166, ntokens=1793.5, nsentences=56, sample_size=1793.5, sample_size_v1=0, sample_size_v2=0, ppl=2.24, wps=1052.3, ups=0.59, wpb=1793.5, bsz=56, num_updates=6450, lr=1.89187e-05, gnorm=2.391, clip=100, loss_scale=128, train_wall=17, gb_free=12.7, wall=11128
2023-06-27 19:24:23 - progress_bar.py[line:272] - INFO: epoch 007:    531 / 990 loss=2.353, loss_v1=0, loss_v2=0, nll_loss=1.148, ntokens=1888.9, nsentences=56, sample_size=1888.9, sample_size_v1=0, sample_size_v2=0, ppl=2.22, wps=1100.6, ups=0.58, wpb=1888.9, bsz=56, num_updates=6460, lr=1.88986e-05, gnorm=2.212, clip=100, loss_scale=128, train_wall=17, gb_free=12.5, wall=11145
2023-06-27 19:24:40 - progress_bar.py[line:272] - INFO: epoch 007:    541 / 990 loss=2.361, loss_v1=0, loss_v2=0, nll_loss=1.159, ntokens=1940.7, nsentences=56, sample_size=1940.7, sample_size_v1=0, sample_size_v2=0, ppl=2.23, wps=1129.9, ups=0.58, wpb=1940.7, bsz=56, num_updates=6470, lr=1.88784e-05, gnorm=2.29, clip=100, loss_scale=128, train_wall=17, gb_free=12.7, wall=11162
2023-06-27 19:24:57 - progress_bar.py[line:272] - INFO: epoch 007:    551 / 990 loss=2.357, loss_v1=0, loss_v2=0, nll_loss=1.155, ntokens=1912.4, nsentences=56, sample_size=1912.4, sample_size_v1=0, sample_size_v2=0, ppl=2.23, wps=1118.9, ups=0.59, wpb=1912.4, bsz=56, num_updates=6480, lr=1.88583e-05, gnorm=2.458, clip=100, loss_scale=128, train_wall=17, gb_free=12.9, wall=11179
2023-06-27 19:25:14 - progress_bar.py[line:272] - INFO: epoch 007:    561 / 990 loss=2.35, loss_v1=0, loss_v2=0, nll_loss=1.146, ntokens=1821.7, nsentences=56, sample_size=1821.7, sample_size_v1=0, sample_size_v2=0, ppl=2.21, wps=1067.8, ups=0.59, wpb=1821.7, bsz=56, num_updates=6490, lr=1.88381e-05, gnorm=2.289, clip=100, loss_scale=128, train_wall=17, gb_free=12, wall=11197
2023-06-27 19:25:31 - progress_bar.py[line:272] - INFO: epoch 007:    571 / 990 loss=2.343, loss_v1=0, loss_v2=0, nll_loss=1.141, ntokens=1761.4, nsentences=56, sample_size=1761.4, sample_size_v1=0, sample_size_v2=0, ppl=2.21, wps=1035.6, ups=0.59, wpb=1761.4, bsz=56, num_updates=6500, lr=1.8818e-05, gnorm=2.289, clip=100, loss_scale=128, train_wall=17, gb_free=12.8, wall=11214
2023-06-27 19:25:48 - progress_bar.py[line:272] - INFO: epoch 007:    581 / 990 loss=2.388, loss_v1=0, loss_v2=0, nll_loss=1.189, ntokens=1863.7, nsentences=56, sample_size=1863.7, sample_size_v1=0, sample_size_v2=0, ppl=2.28, wps=1094.1, ups=0.59, wpb=1863.7, bsz=56, num_updates=6510, lr=1.87979e-05, gnorm=2.381, clip=100, loss_scale=128, train_wall=17, gb_free=12.6, wall=11231
2023-06-27 19:26:05 - progress_bar.py[line:272] - INFO: epoch 007:    591 / 990 loss=2.371, loss_v1=0, loss_v2=0, nll_loss=1.168, ntokens=1965, nsentences=56, sample_size=1965, sample_size_v1=0, sample_size_v2=0, ppl=2.25, wps=1147.8, ups=0.58, wpb=1965, bsz=56, num_updates=6520, lr=1.87777e-05, gnorm=2.32, clip=100, loss_scale=128, train_wall=17, gb_free=12.6, wall=11248
2023-06-27 19:26:22 - progress_bar.py[line:272] - INFO: epoch 007:    601 / 990 loss=2.367, loss_v1=0, loss_v2=0, nll_loss=1.168, ntokens=1747.4, nsentences=56, sample_size=1747.4, sample_size_v1=0, sample_size_v2=0, ppl=2.25, wps=1030, ups=0.59, wpb=1747.4, bsz=56, num_updates=6530, lr=1.87576e-05, gnorm=2.414, clip=100, loss_scale=128, train_wall=17, gb_free=13, wall=11265
2023-06-27 19:26:39 - progress_bar.py[line:272] - INFO: epoch 007:    611 / 990 loss=2.338, loss_v1=0, loss_v2=0, nll_loss=1.133, ntokens=1837.5, nsentences=56, sample_size=1837.5, sample_size_v1=0, sample_size_v2=0, ppl=2.19, wps=1066.3, ups=0.58, wpb=1837.5, bsz=56, num_updates=6540, lr=1.87374e-05, gnorm=2.392, clip=100, loss_scale=128, train_wall=17, gb_free=12.7, wall=11282
2023-06-27 19:26:56 - progress_bar.py[line:272] - INFO: epoch 007:    621 / 990 loss=2.378, loss_v1=0, loss_v2=0, nll_loss=1.178, ntokens=1909.3, nsentences=56, sample_size=1909.3, sample_size_v1=0, sample_size_v2=0, ppl=2.26, wps=1116.3, ups=0.58, wpb=1909.3, bsz=56, num_updates=6550, lr=1.87173e-05, gnorm=2.318, clip=100, loss_scale=128, train_wall=17, gb_free=12.5, wall=11299
2023-06-27 19:27:14 - progress_bar.py[line:272] - INFO: epoch 007:    631 / 990 loss=2.379, loss_v1=0, loss_v2=0, nll_loss=1.18, ntokens=2053.9, nsentences=56, sample_size=2053.9, sample_size_v1=0, sample_size_v2=0, ppl=2.27, wps=1194.5, ups=0.58, wpb=2053.9, bsz=56, num_updates=6560, lr=1.86971e-05, gnorm=2.167, clip=100, loss_scale=128, train_wall=17, gb_free=12.5, wall=11316
2023-06-27 19:27:31 - progress_bar.py[line:272] - INFO: epoch 007:    641 / 990 loss=2.354, loss_v1=0, loss_v2=0, nll_loss=1.153, ntokens=1998.8, nsentences=56, sample_size=1998.8, sample_size_v1=0, sample_size_v2=0, ppl=2.22, wps=1159.7, ups=0.58, wpb=1998.8, bsz=56, num_updates=6570, lr=1.8677e-05, gnorm=2.147, clip=100, loss_scale=128, train_wall=17, gb_free=12.4, wall=11333
2023-06-27 19:27:48 - progress_bar.py[line:272] - INFO: epoch 007:    651 / 990 loss=2.374, loss_v1=0, loss_v2=0, nll_loss=1.174, ntokens=1966.7, nsentences=56, sample_size=1966.7, sample_size_v1=0, sample_size_v2=0, ppl=2.26, wps=1150.4, ups=0.58, wpb=1966.7, bsz=56, num_updates=6580, lr=1.86568e-05, gnorm=2.235, clip=100, loss_scale=128, train_wall=17, gb_free=12.2, wall=11351
2023-06-27 19:28:05 - progress_bar.py[line:272] - INFO: epoch 007:    661 / 990 loss=2.365, loss_v1=0, loss_v2=0, nll_loss=1.162, ntokens=1855, nsentences=56, sample_size=1855, sample_size_v1=0, sample_size_v2=0, ppl=2.24, wps=1080.9, ups=0.58, wpb=1855, bsz=56, num_updates=6590, lr=1.86367e-05, gnorm=2.196, clip=100, loss_scale=128, train_wall=17, gb_free=12.2, wall=11368
2023-06-27 19:28:22 - progress_bar.py[line:272] - INFO: epoch 007:    671 / 990 loss=2.376, loss_v1=0, loss_v2=0, nll_loss=1.176, ntokens=1803.1, nsentences=56, sample_size=1803.1, sample_size_v1=0, sample_size_v2=0, ppl=2.26, wps=1056.4, ups=0.59, wpb=1803.1, bsz=56, num_updates=6600, lr=1.86165e-05, gnorm=2.718, clip=100, loss_scale=128, train_wall=17, gb_free=13.2, wall=11385
2023-06-27 19:28:39 - progress_bar.py[line:272] - INFO: epoch 007:    681 / 990 loss=2.322, loss_v1=0, loss_v2=0, nll_loss=1.117, ntokens=1912.8, nsentences=56, sample_size=1912.8, sample_size_v1=0, sample_size_v2=0, ppl=2.17, wps=1112, ups=0.58, wpb=1912.8, bsz=56, num_updates=6610, lr=1.85964e-05, gnorm=2.169, clip=100, loss_scale=128, train_wall=17, gb_free=12.3, wall=11402
2023-06-27 19:28:56 - progress_bar.py[line:272] - INFO: epoch 007:    691 / 990 loss=2.342, loss_v1=0, loss_v2=0, nll_loss=1.14, ntokens=1811.9, nsentences=56, sample_size=1811.9, sample_size_v1=0, sample_size_v2=0, ppl=2.2, wps=1059.1, ups=0.58, wpb=1811.9, bsz=56, num_updates=6620, lr=1.85762e-05, gnorm=2.489, clip=100, loss_scale=128, train_wall=17, gb_free=13, wall=11419
2023-06-27 19:29:13 - progress_bar.py[line:272] - INFO: epoch 007:    701 / 990 loss=2.377, loss_v1=0, loss_v2=0, nll_loss=1.175, ntokens=1682.5, nsentences=56, sample_size=1682.5, sample_size_v1=0, sample_size_v2=0, ppl=2.26, wps=989.6, ups=0.59, wpb=1682.5, bsz=56, num_updates=6630, lr=1.85561e-05, gnorm=2.576, clip=100, loss_scale=128, train_wall=17, gb_free=12.6, wall=11436
2023-06-27 19:29:31 - progress_bar.py[line:272] - INFO: epoch 007:    711 / 990 loss=2.37, loss_v1=0, loss_v2=0, nll_loss=1.169, ntokens=1771.8, nsentences=56, sample_size=1771.8, sample_size_v1=0, sample_size_v2=0, ppl=2.25, wps=1038.6, ups=0.59, wpb=1771.8, bsz=56, num_updates=6640, lr=1.85359e-05, gnorm=2.45, clip=100, loss_scale=128, train_wall=17, gb_free=12.5, wall=11453
2023-06-27 19:29:47 - progress_bar.py[line:272] - INFO: epoch 007:    721 / 990 loss=2.346, loss_v1=0, loss_v2=0, nll_loss=1.144, ntokens=1783, nsentences=56, sample_size=1783, sample_size_v1=0, sample_size_v2=0, ppl=2.21, wps=1049.4, ups=0.59, wpb=1783, bsz=56, num_updates=6650, lr=1.85158e-05, gnorm=2.348, clip=100, loss_scale=128, train_wall=17, gb_free=12.5, wall=11470
2023-06-27 19:30:05 - progress_bar.py[line:272] - INFO: epoch 007:    731 / 990 loss=2.335, loss_v1=0, loss_v2=0, nll_loss=1.129, ntokens=1812.9, nsentences=56, sample_size=1812.9, sample_size_v1=0, sample_size_v2=0, ppl=2.19, wps=1060.3, ups=0.58, wpb=1812.9, bsz=56, num_updates=6660, lr=1.84956e-05, gnorm=2.394, clip=100, loss_scale=128, train_wall=17, gb_free=12.4, wall=11487
2023-06-27 19:30:22 - progress_bar.py[line:272] - INFO: epoch 007:    741 / 990 loss=2.375, loss_v1=0, loss_v2=0, nll_loss=1.174, ntokens=1784.4, nsentences=56, sample_size=1784.4, sample_size_v1=0, sample_size_v2=0, ppl=2.26, wps=1050.3, ups=0.59, wpb=1784.4, bsz=56, num_updates=6670, lr=1.84755e-05, gnorm=2.271, clip=100, loss_scale=128, train_wall=17, gb_free=12.5, wall=11504
2023-06-27 19:30:39 - progress_bar.py[line:272] - INFO: epoch 007:    751 / 990 loss=2.385, loss_v1=0, loss_v2=0, nll_loss=1.187, ntokens=1657.5, nsentences=56, sample_size=1657.5, sample_size_v1=0, sample_size_v2=0, ppl=2.28, wps=978.4, ups=0.59, wpb=1657.5, bsz=56, num_updates=6680, lr=1.84553e-05, gnorm=2.582, clip=100, loss_scale=128, train_wall=17, gb_free=13.1, wall=11521
2023-06-27 19:30:56 - progress_bar.py[line:272] - INFO: epoch 007:    761 / 990 loss=2.364, loss_v1=0, loss_v2=0, nll_loss=1.161, ntokens=1743.1, nsentences=56, sample_size=1743.1, sample_size_v1=0, sample_size_v2=0, ppl=2.24, wps=1022.7, ups=0.59, wpb=1743.1, bsz=56, num_updates=6690, lr=1.84352e-05, gnorm=2.42, clip=100, loss_scale=128, train_wall=17, gb_free=12.2, wall=11538
2023-06-27 19:31:12 - progress_bar.py[line:272] - INFO: epoch 007:    771 / 990 loss=2.356, loss_v1=0, loss_v2=0, nll_loss=1.154, ntokens=1814.1, nsentences=54.8, sample_size=1814.1, sample_size_v1=0, sample_size_v2=0, ppl=2.22, wps=1082.2, ups=0.6, wpb=1814.1, bsz=54.8, num_updates=6700, lr=1.8415e-05, gnorm=2.391, clip=100, loss_scale=128, train_wall=17, gb_free=12.1, wall=11555
2023-06-27 19:31:29 - progress_bar.py[line:272] - INFO: epoch 007:    781 / 990 loss=2.348, loss_v1=0, loss_v2=0, nll_loss=1.145, ntokens=1772.9, nsentences=56, sample_size=1772.9, sample_size_v1=0, sample_size_v2=0, ppl=2.21, wps=1040.4, ups=0.59, wpb=1772.9, bsz=56, num_updates=6710, lr=1.83949e-05, gnorm=2.852, clip=100, loss_scale=128, train_wall=17, gb_free=12.9, wall=11572
2023-06-27 19:31:46 - progress_bar.py[line:272] - INFO: epoch 007:    791 / 990 loss=2.36, loss_v1=0, loss_v2=0, nll_loss=1.16, ntokens=1776.5, nsentences=56, sample_size=1776.5, sample_size_v1=0, sample_size_v2=0, ppl=2.23, wps=1042.2, ups=0.59, wpb=1776.5, bsz=56, num_updates=6720, lr=1.83747e-05, gnorm=2.48, clip=100, loss_scale=128, train_wall=17, gb_free=13, wall=11589
2023-06-27 19:32:04 - progress_bar.py[line:272] - INFO: epoch 007:    801 / 990 loss=2.372, loss_v1=0, loss_v2=0, nll_loss=1.17, ntokens=1825.9, nsentences=56, sample_size=1825.9, sample_size_v1=0, sample_size_v2=0, ppl=2.25, wps=1069.7, ups=0.59, wpb=1825.9, bsz=56, num_updates=6730, lr=1.83546e-05, gnorm=2.27, clip=100, loss_scale=128, train_wall=17, gb_free=12.9, wall=11606
2023-06-27 19:32:21 - progress_bar.py[line:272] - INFO: epoch 007:    811 / 990 loss=2.375, loss_v1=0, loss_v2=0, nll_loss=1.176, ntokens=1718, nsentences=56, sample_size=1718, sample_size_v1=0, sample_size_v2=0, ppl=2.26, wps=1008.8, ups=0.59, wpb=1718, bsz=56, num_updates=6740, lr=1.83345e-05, gnorm=2.561, clip=100, loss_scale=128, train_wall=17, gb_free=12.5, wall=11623
2023-06-27 19:32:38 - progress_bar.py[line:272] - INFO: epoch 007:    821 / 990 loss=2.372, loss_v1=0, loss_v2=0, nll_loss=1.173, ntokens=1672, nsentences=56, sample_size=1672, sample_size_v1=0, sample_size_v2=0, ppl=2.26, wps=984.9, ups=0.59, wpb=1672, bsz=56, num_updates=6750, lr=1.83143e-05, gnorm=2.446, clip=100, loss_scale=256, train_wall=17, gb_free=13, wall=11640
2023-06-27 19:32:55 - progress_bar.py[line:272] - INFO: epoch 007:    831 / 990 loss=2.337, loss_v1=0, loss_v2=0, nll_loss=1.131, ntokens=1744.9, nsentences=56, sample_size=1744.9, sample_size_v1=0, sample_size_v2=0, ppl=2.19, wps=1025.9, ups=0.59, wpb=1744.9, bsz=56, num_updates=6760, lr=1.82942e-05, gnorm=2.409, clip=100, loss_scale=256, train_wall=17, gb_free=13, wall=11657
2023-06-27 19:33:12 - progress_bar.py[line:272] - INFO: epoch 007:    841 / 990 loss=2.339, loss_v1=0, loss_v2=0, nll_loss=1.134, ntokens=1833, nsentences=56, sample_size=1833, sample_size_v1=0, sample_size_v2=0, ppl=2.2, wps=1076.1, ups=0.59, wpb=1833, bsz=56, num_updates=6770, lr=1.8274e-05, gnorm=2.273, clip=100, loss_scale=256, train_wall=17, gb_free=12.9, wall=11674
2023-06-27 19:33:17 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 128.0
2023-06-27 19:33:30 - progress_bar.py[line:272] - INFO: epoch 007:    852 / 990 loss=2.327, loss_v1=0, loss_v2=0, nll_loss=1.12, ntokens=1886.1, nsentences=56, sample_size=1886.1, sample_size_v1=0, sample_size_v2=0, ppl=2.17, wps=1002.9, ups=0.53, wpb=1886.1, bsz=56, num_updates=6780, lr=1.82539e-05, gnorm=2.267, clip=100, loss_scale=128, train_wall=19, gb_free=12.4, wall=11693
2023-06-27 19:33:47 - progress_bar.py[line:272] - INFO: epoch 007:    862 / 990 loss=2.336, loss_v1=0, loss_v2=0, nll_loss=1.133, ntokens=1841.4, nsentences=56, sample_size=1841.4, sample_size_v1=0, sample_size_v2=0, ppl=2.19, wps=1076.7, ups=0.58, wpb=1841.4, bsz=56, num_updates=6790, lr=1.82337e-05, gnorm=2.465, clip=100, loss_scale=128, train_wall=17, gb_free=12.7, wall=11710
2023-06-27 19:34:05 - progress_bar.py[line:272] - INFO: epoch 007:    872 / 990 loss=2.349, loss_v1=0, loss_v2=0, nll_loss=1.147, ntokens=1853.2, nsentences=56, sample_size=1853.2, sample_size_v1=0, sample_size_v2=0, ppl=2.21, wps=1084.3, ups=0.59, wpb=1853.2, bsz=56, num_updates=6800, lr=1.82136e-05, gnorm=2.417, clip=100, loss_scale=128, train_wall=17, gb_free=13, wall=11727
2023-06-27 19:34:22 - progress_bar.py[line:272] - INFO: epoch 007:    882 / 990 loss=2.335, loss_v1=0, loss_v2=0, nll_loss=1.13, ntokens=1789.3, nsentences=56, sample_size=1789.3, sample_size_v1=0, sample_size_v2=0, ppl=2.19, wps=1053.9, ups=0.59, wpb=1789.3, bsz=56, num_updates=6810, lr=1.81934e-05, gnorm=2.356, clip=100, loss_scale=128, train_wall=17, gb_free=12.6, wall=11744
2023-06-27 19:34:39 - progress_bar.py[line:272] - INFO: epoch 007:    892 / 990 loss=2.331, loss_v1=0, loss_v2=0, nll_loss=1.125, ntokens=2113.8, nsentences=56, sample_size=2113.8, sample_size_v1=0, sample_size_v2=0, ppl=2.18, wps=1228.3, ups=0.58, wpb=2113.8, bsz=56, num_updates=6820, lr=1.81733e-05, gnorm=2.19, clip=100, loss_scale=128, train_wall=17, gb_free=12.1, wall=11761
2023-06-27 19:34:56 - progress_bar.py[line:272] - INFO: epoch 007:    902 / 990 loss=2.365, loss_v1=0, loss_v2=0, nll_loss=1.165, ntokens=1662.3, nsentences=56, sample_size=1662.3, sample_size_v1=0, sample_size_v2=0, ppl=2.24, wps=966.5, ups=0.58, wpb=1662.3, bsz=56, num_updates=6830, lr=1.81531e-05, gnorm=2.56, clip=100, loss_scale=128, train_wall=17, gb_free=12.9, wall=11779
2023-06-27 19:35:13 - progress_bar.py[line:272] - INFO: epoch 007:    912 / 990 loss=2.362, loss_v1=0, loss_v2=0, nll_loss=1.158, ntokens=1835.4, nsentences=56, sample_size=1835.4, sample_size_v1=0, sample_size_v2=0, ppl=2.23, wps=1075.1, ups=0.59, wpb=1835.4, bsz=56, num_updates=6840, lr=1.8133e-05, gnorm=2.466, clip=100, loss_scale=128, train_wall=17, gb_free=12.8, wall=11796
2023-06-27 19:35:30 - progress_bar.py[line:272] - INFO: epoch 007:    922 / 990 loss=2.337, loss_v1=0, loss_v2=0, nll_loss=1.135, ntokens=1696.9, nsentences=56, sample_size=1696.9, sample_size_v1=0, sample_size_v2=0, ppl=2.2, wps=998.5, ups=0.59, wpb=1696.9, bsz=56, num_updates=6850, lr=1.81128e-05, gnorm=2.58, clip=100, loss_scale=128, train_wall=17, gb_free=12.4, wall=11813
2023-06-27 19:35:47 - progress_bar.py[line:272] - INFO: epoch 007:    932 / 990 loss=2.327, loss_v1=0, loss_v2=0, nll_loss=1.119, ntokens=1857.8, nsentences=56, sample_size=1857.8, sample_size_v1=0, sample_size_v2=0, ppl=2.17, wps=1085, ups=0.58, wpb=1857.8, bsz=56, num_updates=6860, lr=1.80927e-05, gnorm=2.355, clip=100, loss_scale=128, train_wall=17, gb_free=13.1, wall=11830
2023-06-27 19:36:04 - progress_bar.py[line:272] - INFO: epoch 007:    942 / 990 loss=2.345, loss_v1=0, loss_v2=0, nll_loss=1.142, ntokens=1907.4, nsentences=56, sample_size=1907.4, sample_size_v1=0, sample_size_v2=0, ppl=2.21, wps=1111.5, ups=0.58, wpb=1907.4, bsz=56, num_updates=6870, lr=1.80725e-05, gnorm=2.231, clip=100, loss_scale=128, train_wall=17, gb_free=12.2, wall=11847
2023-06-27 19:36:21 - progress_bar.py[line:272] - INFO: epoch 007:    952 / 990 loss=2.334, loss_v1=0, loss_v2=0, nll_loss=1.129, ntokens=1928.6, nsentences=56, sample_size=1928.6, sample_size_v1=0, sample_size_v2=0, ppl=2.19, wps=1125.6, ups=0.58, wpb=1928.6, bsz=56, num_updates=6880, lr=1.80524e-05, gnorm=2.292, clip=100, loss_scale=128, train_wall=17, gb_free=12.7, wall=11864
2023-06-27 19:36:39 - progress_bar.py[line:272] - INFO: epoch 007:    962 / 990 loss=2.342, loss_v1=0, loss_v2=0, nll_loss=1.138, ntokens=1862.4, nsentences=56, sample_size=1862.4, sample_size_v1=0, sample_size_v2=0, ppl=2.2, wps=1091.2, ups=0.59, wpb=1862.4, bsz=56, num_updates=6890, lr=1.80322e-05, gnorm=2.532, clip=100, loss_scale=128, train_wall=17, gb_free=12.5, wall=11881
2023-06-27 19:36:56 - progress_bar.py[line:272] - INFO: epoch 007:    972 / 990 loss=2.34, loss_v1=0, loss_v2=0, nll_loss=1.137, ntokens=1919.1, nsentences=56, sample_size=1919.1, sample_size_v1=0, sample_size_v2=0, ppl=2.2, wps=1115.7, ups=0.58, wpb=1919.1, bsz=56, num_updates=6900, lr=1.80121e-05, gnorm=2.299, clip=100, loss_scale=128, train_wall=17, gb_free=13, wall=11898
2023-06-27 19:37:13 - progress_bar.py[line:272] - INFO: epoch 007:    982 / 990 loss=2.344, loss_v1=0, loss_v2=0, nll_loss=1.139, ntokens=1779, nsentences=56, sample_size=1779, sample_size_v1=0, sample_size_v2=0, ppl=2.2, wps=1042.6, ups=0.59, wpb=1779, bsz=56, num_updates=6910, lr=1.79919e-05, gnorm=2.373, clip=100, loss_scale=128, train_wall=17, gb_free=12.5, wall=11916
local datafile ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 1 begin to initialize row_count and line_idx-to-offset mapping
2023-06-27 19:37:26 - train.py[line:332] - INFO: end of epoch 7 (average epoch stats below)
2023-06-27 19:37:26 - progress_bar.py[line:282] - INFO: epoch 007 | loss 2.343 | loss_v1 0 | loss_v2 0 | nll_loss 1.139 | ntokens 1849.83 | nsentences 55.96 | sample_size 1849.83 | sample_size_v1 0 | sample_size_v2 0 | ppl 2.2 | wps 1074.8 | ups 0.58 | wpb 1849.8 | bsz 56 | num_updates 6918 | lr 1.79758e-05 | gnorm 2.274 | clip 100 | loss_scale 128 | train_wall 1695 | gb_free 13.3 | wall 11928
2023-06-27 19:37:26 - trainer.py[line:639] - INFO: loading train data for epoch 8
local datafile ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 0 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 1 finished initializing row_count and line_idx-to-offset mapping
file ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 1 row count 27700 total row count 55400
slice_id 1 seek offset 27700
local datafile ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 0 finished initializing row_count and line_idx-to-offset mapping
file ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 0 row count 27700 total row count 55400
slice_id 0 seek offset 0
2023-06-27 19:37:28 - trainer.py[line:703] - INFO: begin training epoch 8
2023-06-27 19:37:28 - train.py[line:305] - INFO: Start iterating over samples
2023-06-27 19:37:31 - progress_bar.py[line:272] - INFO: epoch 008:      2 / 990 loss=2.381, loss_v1=0, loss_v2=0, nll_loss=1.18, ntokens=1795.1, nsentences=53.2, sample_size=1795.1, sample_size_v1=0, sample_size_v2=0, ppl=2.27, wps=965.5, ups=0.54, wpb=1795.1, bsz=53.2, num_updates=6920, lr=1.79718e-05, gnorm=2.574, clip=100, loss_scale=128, train_wall=16, gb_free=12.1, wall=11934
2023-06-27 19:37:49 - progress_bar.py[line:272] - INFO: epoch 008:     12 / 990 loss=2.291, loss_v1=0, loss_v2=0, nll_loss=1.082, ntokens=1878.7, nsentences=56, sample_size=1878.7, sample_size_v1=0, sample_size_v2=0, ppl=2.12, wps=1083.2, ups=0.58, wpb=1878.7, bsz=56, num_updates=6930, lr=1.79516e-05, gnorm=2.359, clip=100, loss_scale=128, train_wall=17, gb_free=12, wall=11951
2023-06-27 19:38:06 - progress_bar.py[line:272] - INFO: epoch 008:     22 / 990 loss=2.261, loss_v1=0, loss_v2=0, nll_loss=1.048, ntokens=1787.5, nsentences=56, sample_size=1787.5, sample_size_v1=0, sample_size_v2=0, ppl=2.07, wps=1034.8, ups=0.58, wpb=1787.5, bsz=56, num_updates=6940, lr=1.79315e-05, gnorm=2.425, clip=100, loss_scale=128, train_wall=17, gb_free=12.7, wall=11969
2023-06-27 19:38:23 - progress_bar.py[line:272] - INFO: epoch 008:     32 / 990 loss=2.324, loss_v1=0, loss_v2=0, nll_loss=1.117, ntokens=1723.3, nsentences=56, sample_size=1723.3, sample_size_v1=0, sample_size_v2=0, ppl=2.17, wps=1014, ups=0.59, wpb=1723.3, bsz=56, num_updates=6950, lr=1.79113e-05, gnorm=2.486, clip=100, loss_scale=128, train_wall=17, gb_free=12.2, wall=11986
2023-06-27 19:38:40 - progress_bar.py[line:272] - INFO: epoch 008:     42 / 990 loss=2.212, loss_v1=0, loss_v2=0, nll_loss=0.994, ntokens=1984, nsentences=56, sample_size=1984, sample_size_v1=0, sample_size_v2=0, ppl=1.99, wps=1141.6, ups=0.58, wpb=1984, bsz=56, num_updates=6960, lr=1.78912e-05, gnorm=2.127, clip=100, loss_scale=128, train_wall=17, gb_free=11.4, wall=12003
2023-06-27 19:38:58 - progress_bar.py[line:272] - INFO: epoch 008:     52 / 990 loss=2.267, loss_v1=0, loss_v2=0, nll_loss=1.054, ntokens=1757.8, nsentences=56, sample_size=1757.8, sample_size_v1=0, sample_size_v2=0, ppl=2.08, wps=1019.3, ups=0.58, wpb=1757.8, bsz=56, num_updates=6970, lr=1.78711e-05, gnorm=2.583, clip=100, loss_scale=128, train_wall=17, gb_free=12.8, wall=12020
2023-06-27 19:39:15 - progress_bar.py[line:272] - INFO: epoch 008:     62 / 990 loss=2.257, loss_v1=0, loss_v2=0, nll_loss=1.043, ntokens=1799.6, nsentences=56, sample_size=1799.6, sample_size_v1=0, sample_size_v2=0, ppl=2.06, wps=1044.8, ups=0.58, wpb=1799.6, bsz=56, num_updates=6980, lr=1.78509e-05, gnorm=2.513, clip=100, loss_scale=128, train_wall=17, gb_free=12.4, wall=12038
2023-06-27 19:39:32 - progress_bar.py[line:272] - INFO: epoch 008:     72 / 990 loss=2.144, loss_v1=0, loss_v2=0, nll_loss=0.916, ntokens=2037.7, nsentences=56, sample_size=2037.7, sample_size_v1=0, sample_size_v2=0, ppl=1.89, wps=1166.6, ups=0.57, wpb=2037.7, bsz=56, num_updates=6990, lr=1.78308e-05, gnorm=1.953, clip=100, loss_scale=128, train_wall=17, gb_free=11.5, wall=12055
2023-06-27 19:39:50 - progress_bar.py[line:272] - INFO: epoch 008:     82 / 990 loss=2.215, loss_v1=0, loss_v2=0, nll_loss=0.998, ntokens=2177.1, nsentences=56, sample_size=2177.1, sample_size_v1=0, sample_size_v2=0, ppl=2, wps=1229.7, ups=0.56, wpb=2177.1, bsz=56, num_updates=7000, lr=1.78106e-05, gnorm=1.995, clip=100, loss_scale=128, train_wall=18, gb_free=11.6, wall=12073
2023-06-27 19:40:08 - progress_bar.py[line:272] - INFO: epoch 008:     92 / 990 loss=2.214, loss_v1=0, loss_v2=0, nll_loss=0.993, ntokens=2019.4, nsentences=56, sample_size=2019.4, sample_size_v1=0, sample_size_v2=0, ppl=1.99, wps=1147.7, ups=0.57, wpb=2019.4, bsz=56, num_updates=7010, lr=1.77905e-05, gnorm=2.239, clip=100, loss_scale=128, train_wall=18, gb_free=12.5, wall=12090
2023-06-27 19:40:25 - progress_bar.py[line:272] - INFO: epoch 008:    102 / 990 loss=2.27, loss_v1=0, loss_v2=0, nll_loss=1.059, ntokens=1873.6, nsentences=56, sample_size=1873.6, sample_size_v1=0, sample_size_v2=0, ppl=2.08, wps=1080.3, ups=0.58, wpb=1873.6, bsz=56, num_updates=7020, lr=1.77703e-05, gnorm=2.387, clip=100, loss_scale=128, train_wall=17, gb_free=11.9, wall=12108
2023-06-27 19:40:42 - progress_bar.py[line:272] - INFO: epoch 008:    112 / 990 loss=2.262, loss_v1=0, loss_v2=0, nll_loss=1.046, ntokens=1869, nsentences=56, sample_size=1869, sample_size_v1=0, sample_size_v2=0, ppl=2.06, wps=1085.9, ups=0.58, wpb=1869, bsz=56, num_updates=7030, lr=1.77502e-05, gnorm=2.44, clip=100, loss_scale=128, train_wall=17, gb_free=12.6, wall=12125
2023-06-27 19:40:59 - progress_bar.py[line:272] - INFO: epoch 008:    122 / 990 loss=2.345, loss_v1=0, loss_v2=0, nll_loss=1.145, ntokens=1761.5, nsentences=56, sample_size=1761.5, sample_size_v1=0, sample_size_v2=0, ppl=2.21, wps=1027.1, ups=0.58, wpb=1761.5, bsz=56, num_updates=7040, lr=1.773e-05, gnorm=2.574, clip=100, loss_scale=128, train_wall=17, gb_free=11.8, wall=12142
2023-06-27 19:41:17 - progress_bar.py[line:272] - INFO: epoch 008:    132 / 990 loss=2.35, loss_v1=0, loss_v2=0, nll_loss=1.146, ntokens=1815.9, nsentences=56, sample_size=1815.9, sample_size_v1=0, sample_size_v2=0, ppl=2.21, wps=1053.1, ups=0.58, wpb=1815.9, bsz=56, num_updates=7050, lr=1.77099e-05, gnorm=2.406, clip=100, loss_scale=128, train_wall=17, gb_free=11.9, wall=12159
2023-06-27 19:41:34 - progress_bar.py[line:272] - INFO: epoch 008:    142 / 990 loss=2.332, loss_v1=0, loss_v2=0, nll_loss=1.125, ntokens=1956.5, nsentences=56, sample_size=1956.5, sample_size_v1=0, sample_size_v2=0, ppl=2.18, wps=1119.6, ups=0.57, wpb=1956.5, bsz=56, num_updates=7060, lr=1.76897e-05, gnorm=2.176, clip=100, loss_scale=128, train_wall=17, gb_free=12.3, wall=12177
2023-06-27 19:41:52 - progress_bar.py[line:272] - INFO: epoch 008:    152 / 990 loss=2.294, loss_v1=0, loss_v2=0, nll_loss=1.085, ntokens=1960.6, nsentences=56, sample_size=1960.6, sample_size_v1=0, sample_size_v2=0, ppl=2.12, wps=1122.5, ups=0.57, wpb=1960.6, bsz=56, num_updates=7070, lr=1.76696e-05, gnorm=2.27, clip=100, loss_scale=128, train_wall=17, gb_free=11.5, wall=12194
2023-06-27 19:42:09 - progress_bar.py[line:272] - INFO: epoch 008:    162 / 990 loss=2.282, loss_v1=0, loss_v2=0, nll_loss=1.071, ntokens=1989.5, nsentences=56, sample_size=1989.5, sample_size_v1=0, sample_size_v2=0, ppl=2.1, wps=1141.4, ups=0.57, wpb=1989.5, bsz=56, num_updates=7080, lr=1.76494e-05, gnorm=2.018, clip=100, loss_scale=128, train_wall=17, gb_free=12.2, wall=12212
2023-06-27 19:42:26 - progress_bar.py[line:272] - INFO: epoch 008:    172 / 990 loss=2.293, loss_v1=0, loss_v2=0, nll_loss=1.085, ntokens=1891.1, nsentences=56, sample_size=1891.1, sample_size_v1=0, sample_size_v2=0, ppl=2.12, wps=1088.8, ups=0.58, wpb=1891.1, bsz=56, num_updates=7090, lr=1.76293e-05, gnorm=2.257, clip=100, loss_scale=128, train_wall=17, gb_free=12.7, wall=12229
2023-06-27 19:42:44 - progress_bar.py[line:272] - INFO: epoch 008:    182 / 990 loss=2.305, loss_v1=0, loss_v2=0, nll_loss=1.096, ntokens=1964.6, nsentences=56, sample_size=1964.6, sample_size_v1=0, sample_size_v2=0, ppl=2.14, wps=1128.8, ups=0.57, wpb=1964.6, bsz=56, num_updates=7100, lr=1.76091e-05, gnorm=2.252, clip=100, loss_scale=128, train_wall=17, gb_free=12.9, wall=12246
2023-06-27 19:43:01 - progress_bar.py[line:272] - INFO: epoch 008:    192 / 990 loss=2.295, loss_v1=0, loss_v2=0, nll_loss=1.086, ntokens=1901, nsentences=56, sample_size=1901, sample_size_v1=0, sample_size_v2=0, ppl=2.12, wps=1099.7, ups=0.58, wpb=1901, bsz=56, num_updates=7110, lr=1.7589e-05, gnorm=2.354, clip=100, loss_scale=128, train_wall=17, gb_free=12.8, wall=12264
2023-06-27 19:43:18 - progress_bar.py[line:272] - INFO: epoch 008:    202 / 990 loss=2.293, loss_v1=0, loss_v2=0, nll_loss=1.081, ntokens=1816.8, nsentences=56, sample_size=1816.8, sample_size_v1=0, sample_size_v2=0, ppl=2.12, wps=1057.9, ups=0.58, wpb=1816.8, bsz=56, num_updates=7120, lr=1.75688e-05, gnorm=2.469, clip=100, loss_scale=128, train_wall=17, gb_free=11.8, wall=12281
2023-06-27 19:43:36 - progress_bar.py[line:272] - INFO: epoch 008:    212 / 990 loss=2.279, loss_v1=0, loss_v2=0, nll_loss=1.069, ntokens=1921.3, nsentences=56, sample_size=1921.3, sample_size_v1=0, sample_size_v2=0, ppl=2.1, wps=1104.9, ups=0.58, wpb=1921.3, bsz=56, num_updates=7130, lr=1.75487e-05, gnorm=2.374, clip=100, loss_scale=128, train_wall=17, gb_free=11.3, wall=12298
2023-06-27 19:43:53 - progress_bar.py[line:272] - INFO: epoch 008:    222 / 990 loss=2.3, loss_v1=0, loss_v2=0, nll_loss=1.089, ntokens=1933.9, nsentences=56, sample_size=1933.9, sample_size_v1=0, sample_size_v2=0, ppl=2.13, wps=1114.1, ups=0.58, wpb=1933.9, bsz=56, num_updates=7140, lr=1.75285e-05, gnorm=2.3, clip=100, loss_scale=128, train_wall=17, gb_free=12.7, wall=12316
2023-06-27 19:44:10 - progress_bar.py[line:272] - INFO: epoch 008:    232 / 990 loss=2.333, loss_v1=0, loss_v2=0, nll_loss=1.13, ntokens=1800, nsentences=56, sample_size=1800, sample_size_v1=0, sample_size_v2=0, ppl=2.19, wps=1047.6, ups=0.58, wpb=1800, bsz=56, num_updates=7150, lr=1.75084e-05, gnorm=2.37, clip=100, loss_scale=128, train_wall=17, gb_free=12.7, wall=12333
2023-06-27 19:44:27 - progress_bar.py[line:272] - INFO: epoch 008:    242 / 990 loss=2.352, loss_v1=0, loss_v2=0, nll_loss=1.15, ntokens=1776, nsentences=56, sample_size=1776, sample_size_v1=0, sample_size_v2=0, ppl=2.22, wps=1035.1, ups=0.58, wpb=1776, bsz=56, num_updates=7160, lr=1.74882e-05, gnorm=2.532, clip=100, loss_scale=128, train_wall=17, gb_free=12.6, wall=12350
2023-06-27 19:44:45 - progress_bar.py[line:272] - INFO: epoch 008:    252 / 990 loss=2.349, loss_v1=0, loss_v2=0, nll_loss=1.145, ntokens=1951.4, nsentences=56, sample_size=1951.4, sample_size_v1=0, sample_size_v2=0, ppl=2.21, wps=1138.7, ups=0.58, wpb=1951.4, bsz=56, num_updates=7170, lr=1.74681e-05, gnorm=2.445, clip=100, loss_scale=128, train_wall=17, gb_free=12.6, wall=12367
2023-06-27 19:45:02 - progress_bar.py[line:272] - INFO: epoch 008:    262 / 990 loss=2.36, loss_v1=0, loss_v2=0, nll_loss=1.156, ntokens=1898.3, nsentences=56, sample_size=1898.3, sample_size_v1=0, sample_size_v2=0, ppl=2.23, wps=1105.8, ups=0.58, wpb=1898.3, bsz=56, num_updates=7180, lr=1.7448e-05, gnorm=2.433, clip=100, loss_scale=128, train_wall=17, gb_free=12.9, wall=12384
2023-06-27 19:45:19 - progress_bar.py[line:272] - INFO: epoch 008:    272 / 990 loss=2.381, loss_v1=0, loss_v2=0, nll_loss=1.182, ntokens=1883.4, nsentences=56, sample_size=1883.4, sample_size_v1=0, sample_size_v2=0, ppl=2.27, wps=1085.5, ups=0.58, wpb=1883.4, bsz=56, num_updates=7190, lr=1.74278e-05, gnorm=2.524, clip=100, loss_scale=128, train_wall=17, gb_free=12.5, wall=12402
2023-06-27 19:45:36 - progress_bar.py[line:272] - INFO: epoch 008:    282 / 990 loss=2.357, loss_v1=0, loss_v2=0, nll_loss=1.155, ntokens=1918, nsentences=56, sample_size=1918, sample_size_v1=0, sample_size_v2=0, ppl=2.23, wps=1104.5, ups=0.58, wpb=1918, bsz=56, num_updates=7200, lr=1.74077e-05, gnorm=2.219, clip=100, loss_scale=128, train_wall=17, gb_free=12.1, wall=12419
2023-06-27 19:45:54 - progress_bar.py[line:272] - INFO: epoch 008:    292 / 990 loss=2.36, loss_v1=0, loss_v2=0, nll_loss=1.158, ntokens=1834.9, nsentences=56, sample_size=1834.9, sample_size_v1=0, sample_size_v2=0, ppl=2.23, wps=1070.2, ups=0.58, wpb=1834.9, bsz=56, num_updates=7210, lr=1.73875e-05, gnorm=2.701, clip=100, loss_scale=128, train_wall=17, gb_free=12.7, wall=12436
2023-06-27 19:46:11 - progress_bar.py[line:272] - INFO: epoch 008:    302 / 990 loss=2.359, loss_v1=0, loss_v2=0, nll_loss=1.157, ntokens=1925.9, nsentences=56, sample_size=1925.9, sample_size_v1=0, sample_size_v2=0, ppl=2.23, wps=1118.5, ups=0.58, wpb=1925.9, bsz=56, num_updates=7220, lr=1.73674e-05, gnorm=2.473, clip=100, loss_scale=128, train_wall=17, gb_free=11.9, wall=12453
2023-06-27 19:46:28 - progress_bar.py[line:272] - INFO: epoch 008:    312 / 990 loss=2.366, loss_v1=0, loss_v2=0, nll_loss=1.165, ntokens=1880, nsentences=56, sample_size=1880, sample_size_v1=0, sample_size_v2=0, ppl=2.24, wps=1092.1, ups=0.58, wpb=1880, bsz=56, num_updates=7230, lr=1.73472e-05, gnorm=2.542, clip=100, loss_scale=128, train_wall=17, gb_free=12.6, wall=12471
2023-06-27 19:46:45 - progress_bar.py[line:272] - INFO: epoch 008:    322 / 990 loss=2.367, loss_v1=0, loss_v2=0, nll_loss=1.167, ntokens=1910.2, nsentences=56, sample_size=1910.2, sample_size_v1=0, sample_size_v2=0, ppl=2.25, wps=1104.5, ups=0.58, wpb=1910.2, bsz=56, num_updates=7240, lr=1.73271e-05, gnorm=2.468, clip=100, loss_scale=128, train_wall=17, gb_free=11.8, wall=12488
2023-06-27 19:47:03 - progress_bar.py[line:272] - INFO: epoch 008:    332 / 990 loss=2.337, loss_v1=0, loss_v2=0, nll_loss=1.132, ntokens=1876.3, nsentences=56, sample_size=1876.3, sample_size_v1=0, sample_size_v2=0, ppl=2.19, wps=1079.7, ups=0.58, wpb=1876.3, bsz=56, num_updates=7250, lr=1.73069e-05, gnorm=2.435, clip=100, loss_scale=128, train_wall=17, gb_free=12.9, wall=12505
2023-06-27 19:47:20 - progress_bar.py[line:272] - INFO: epoch 008:    342 / 990 loss=2.343, loss_v1=0, loss_v2=0, nll_loss=1.139, ntokens=1898.9, nsentences=56, sample_size=1898.9, sample_size_v1=0, sample_size_v2=0, ppl=2.2, wps=1100.6, ups=0.58, wpb=1898.9, bsz=56, num_updates=7260, lr=1.72868e-05, gnorm=2.442, clip=100, loss_scale=128, train_wall=17, gb_free=12.3, wall=12523
2023-06-27 19:47:37 - progress_bar.py[line:272] - INFO: epoch 008:    352 / 990 loss=2.352, loss_v1=0, loss_v2=0, nll_loss=1.15, ntokens=1879.4, nsentences=56, sample_size=1879.4, sample_size_v1=0, sample_size_v2=0, ppl=2.22, wps=1093.1, ups=0.58, wpb=1879.4, bsz=56, num_updates=7270, lr=1.72666e-05, gnorm=2.581, clip=100, loss_scale=128, train_wall=17, gb_free=12.6, wall=12540
2023-06-27 19:47:54 - progress_bar.py[line:272] - INFO: epoch 008:    362 / 990 loss=2.345, loss_v1=0, loss_v2=0, nll_loss=1.142, ntokens=1783.9, nsentences=56, sample_size=1783.9, sample_size_v1=0, sample_size_v2=0, ppl=2.21, wps=1046.4, ups=0.59, wpb=1783.9, bsz=56, num_updates=7280, lr=1.72465e-05, gnorm=2.68, clip=100, loss_scale=128, train_wall=17, gb_free=12.7, wall=12557
2023-06-27 19:48:11 - progress_bar.py[line:272] - INFO: epoch 008:    372 / 990 loss=2.376, loss_v1=0, loss_v2=0, nll_loss=1.176, ntokens=1756.1, nsentences=56, sample_size=1756.1, sample_size_v1=0, sample_size_v2=0, ppl=2.26, wps=1032.4, ups=0.59, wpb=1756.1, bsz=56, num_updates=7290, lr=1.72263e-05, gnorm=2.771, clip=100, loss_scale=256, train_wall=17, gb_free=12.6, wall=12574
2023-06-27 19:48:20 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 128.0
2023-06-27 19:48:30 - progress_bar.py[line:272] - INFO: epoch 008:    383 / 990 loss=2.343, loss_v1=0, loss_v2=0, nll_loss=1.139, ntokens=1872.8, nsentences=56, sample_size=1872.8, sample_size_v1=0, sample_size_v2=0, ppl=2.2, wps=1000.3, ups=0.53, wpb=1872.8, bsz=56, num_updates=7300, lr=1.72062e-05, gnorm=2.641, clip=100, loss_scale=128, train_wall=19, gb_free=12.9, wall=12593
2023-06-27 19:48:47 - progress_bar.py[line:272] - INFO: epoch 008:    393 / 990 loss=2.328, loss_v1=0, loss_v2=0, nll_loss=1.124, ntokens=1742.1, nsentences=56, sample_size=1742.1, sample_size_v1=0, sample_size_v2=0, ppl=2.18, wps=1021.2, ups=0.59, wpb=1742.1, bsz=56, num_updates=7310, lr=1.7186e-05, gnorm=2.596, clip=100, loss_scale=128, train_wall=17, gb_free=12.6, wall=12610
2023-06-27 19:49:04 - progress_bar.py[line:272] - INFO: epoch 008:    403 / 990 loss=2.375, loss_v1=0, loss_v2=0, nll_loss=1.175, ntokens=1750.8, nsentences=56, sample_size=1750.8, sample_size_v1=0, sample_size_v2=0, ppl=2.26, wps=1031, ups=0.59, wpb=1750.8, bsz=56, num_updates=7320, lr=1.71659e-05, gnorm=2.738, clip=100, loss_scale=128, train_wall=17, gb_free=12.7, wall=12627
2023-06-27 19:49:21 - progress_bar.py[line:272] - INFO: epoch 008:    413 / 990 loss=2.376, loss_v1=0, loss_v2=0, nll_loss=1.174, ntokens=1704.5, nsentences=56, sample_size=1704.5, sample_size_v1=0, sample_size_v2=0, ppl=2.26, wps=1001.4, ups=0.59, wpb=1704.5, bsz=56, num_updates=7330, lr=1.71457e-05, gnorm=2.759, clip=100, loss_scale=128, train_wall=17, gb_free=12.4, wall=12644
2023-06-27 19:49:38 - progress_bar.py[line:272] - INFO: epoch 008:    423 / 990 loss=2.356, loss_v1=0, loss_v2=0, nll_loss=1.154, ntokens=1737.2, nsentences=56, sample_size=1737.2, sample_size_v1=0, sample_size_v2=0, ppl=2.23, wps=1021, ups=0.59, wpb=1737.2, bsz=56, num_updates=7340, lr=1.71256e-05, gnorm=2.796, clip=100, loss_scale=128, train_wall=17, gb_free=12.4, wall=12661
2023-06-27 19:49:55 - progress_bar.py[line:272] - INFO: epoch 008:    433 / 990 loss=2.337, loss_v1=0, loss_v2=0, nll_loss=1.132, ntokens=1879.2, nsentences=54.8, sample_size=1879.2, sample_size_v1=0, sample_size_v2=0, ppl=2.19, wps=1114.9, ups=0.59, wpb=1879.2, bsz=54.8, num_updates=7350, lr=1.71054e-05, gnorm=2.619, clip=100, loss_scale=128, train_wall=17, gb_free=12.7, wall=12678
2023-06-27 19:50:12 - progress_bar.py[line:272] - INFO: epoch 008:    443 / 990 loss=2.341, loss_v1=0, loss_v2=0, nll_loss=1.137, ntokens=1879.6, nsentences=56, sample_size=1879.6, sample_size_v1=0, sample_size_v2=0, ppl=2.2, wps=1095.4, ups=0.58, wpb=1879.6, bsz=56, num_updates=7360, lr=1.70853e-05, gnorm=2.523, clip=100, loss_scale=128, train_wall=17, gb_free=12.9, wall=12695
2023-06-27 19:50:29 - progress_bar.py[line:272] - INFO: epoch 008:    453 / 990 loss=2.355, loss_v1=0, loss_v2=0, nll_loss=1.155, ntokens=1754.1, nsentences=56, sample_size=1754.1, sample_size_v1=0, sample_size_v2=0, ppl=2.23, wps=1033.3, ups=0.59, wpb=1754.1, bsz=56, num_updates=7370, lr=1.70651e-05, gnorm=2.702, clip=100, loss_scale=128, train_wall=17, gb_free=12.5, wall=12712
2023-06-27 19:50:46 - progress_bar.py[line:272] - INFO: epoch 008:    463 / 990 loss=2.35, loss_v1=0, loss_v2=0, nll_loss=1.146, ntokens=1848, nsentences=56, sample_size=1848, sample_size_v1=0, sample_size_v2=0, ppl=2.21, wps=1066.4, ups=0.58, wpb=1848, bsz=56, num_updates=7380, lr=1.7045e-05, gnorm=2.511, clip=100, loss_scale=128, train_wall=17, gb_free=13.1, wall=12729
2023-06-27 19:51:04 - progress_bar.py[line:272] - INFO: epoch 008:    473 / 990 loss=2.343, loss_v1=0, loss_v2=0, nll_loss=1.138, ntokens=1909.5, nsentences=56, sample_size=1909.5, sample_size_v1=0, sample_size_v2=0, ppl=2.2, wps=1106.8, ups=0.58, wpb=1909.5, bsz=56, num_updates=7390, lr=1.70248e-05, gnorm=2.533, clip=100, loss_scale=128, train_wall=17, gb_free=10.7, wall=12746
2023-06-27 19:51:21 - progress_bar.py[line:272] - INFO: epoch 008:    483 / 990 loss=2.338, loss_v1=0, loss_v2=0, nll_loss=1.134, ntokens=1797.5, nsentences=56, sample_size=1797.5, sample_size_v1=0, sample_size_v2=0, ppl=2.2, wps=1049, ups=0.58, wpb=1797.5, bsz=56, num_updates=7400, lr=1.70047e-05, gnorm=2.593, clip=100, loss_scale=128, train_wall=17, gb_free=12.9, wall=12763
2023-06-27 19:51:38 - progress_bar.py[line:272] - INFO: epoch 008:    493 / 990 loss=2.341, loss_v1=0, loss_v2=0, nll_loss=1.138, ntokens=1863.1, nsentences=56, sample_size=1863.1, sample_size_v1=0, sample_size_v2=0, ppl=2.2, wps=1084.5, ups=0.58, wpb=1863.1, bsz=56, num_updates=7410, lr=1.69846e-05, gnorm=2.48, clip=100, loss_scale=128, train_wall=17, gb_free=12.9, wall=12781
2023-06-27 19:51:55 - progress_bar.py[line:272] - INFO: epoch 008:    503 / 990 loss=2.371, loss_v1=0, loss_v2=0, nll_loss=1.169, ntokens=1852.3, nsentences=56, sample_size=1852.3, sample_size_v1=0, sample_size_v2=0, ppl=2.25, wps=1082.6, ups=0.58, wpb=1852.3, bsz=56, num_updates=7420, lr=1.69644e-05, gnorm=2.529, clip=100, loss_scale=128, train_wall=17, gb_free=13.1, wall=12798
2023-06-27 19:52:12 - progress_bar.py[line:272] - INFO: epoch 008:    513 / 990 loss=2.376, loss_v1=0, loss_v2=0, nll_loss=1.177, ntokens=1724, nsentences=56, sample_size=1724, sample_size_v1=0, sample_size_v2=0, ppl=2.26, wps=1008.5, ups=0.58, wpb=1724, bsz=56, num_updates=7430, lr=1.69443e-05, gnorm=2.984, clip=100, loss_scale=128, train_wall=17, gb_free=13.1, wall=12815
2023-06-27 19:52:29 - progress_bar.py[line:272] - INFO: epoch 008:    523 / 990 loss=2.346, loss_v1=0, loss_v2=0, nll_loss=1.144, ntokens=1858.7, nsentences=56, sample_size=1858.7, sample_size_v1=0, sample_size_v2=0, ppl=2.21, wps=1086, ups=0.58, wpb=1858.7, bsz=56, num_updates=7440, lr=1.69241e-05, gnorm=2.488, clip=100, loss_scale=128, train_wall=17, gb_free=12.7, wall=12832
2023-06-27 19:52:46 - progress_bar.py[line:272] - INFO: epoch 008:    533 / 990 loss=2.338, loss_v1=0, loss_v2=0, nll_loss=1.132, ntokens=1878.2, nsentences=56, sample_size=1878.2, sample_size_v1=0, sample_size_v2=0, ppl=2.19, wps=1096.3, ups=0.58, wpb=1878.2, bsz=56, num_updates=7450, lr=1.6904e-05, gnorm=2.439, clip=100, loss_scale=128, train_wall=17, gb_free=12.3, wall=12849
2023-06-27 19:53:04 - progress_bar.py[line:272] - INFO: epoch 008:    543 / 990 loss=2.361, loss_v1=0, loss_v2=0, nll_loss=1.158, ntokens=1961.7, nsentences=56, sample_size=1961.7, sample_size_v1=0, sample_size_v2=0, ppl=2.23, wps=1145.2, ups=0.58, wpb=1961.7, bsz=56, num_updates=7460, lr=1.68838e-05, gnorm=2.668, clip=100, loss_scale=128, train_wall=17, gb_free=12.7, wall=12866
2023-06-27 19:53:21 - progress_bar.py[line:272] - INFO: epoch 008:    553 / 990 loss=2.334, loss_v1=0, loss_v2=0, nll_loss=1.13, ntokens=1881.5, nsentences=56, sample_size=1881.5, sample_size_v1=0, sample_size_v2=0, ppl=2.19, wps=1100.5, ups=0.58, wpb=1881.5, bsz=56, num_updates=7470, lr=1.68637e-05, gnorm=2.637, clip=100, loss_scale=128, train_wall=17, gb_free=13, wall=12883
2023-06-27 19:53:38 - progress_bar.py[line:272] - INFO: epoch 008:    563 / 990 loss=2.337, loss_v1=0, loss_v2=0, nll_loss=1.134, ntokens=1779.1, nsentences=56, sample_size=1779.1, sample_size_v1=0, sample_size_v2=0, ppl=2.19, wps=1042.3, ups=0.59, wpb=1779.1, bsz=56, num_updates=7480, lr=1.68435e-05, gnorm=2.731, clip=100, loss_scale=128, train_wall=17, gb_free=13.1, wall=12900
2023-06-27 19:53:55 - progress_bar.py[line:272] - INFO: epoch 008:    573 / 990 loss=2.34, loss_v1=0, loss_v2=0, nll_loss=1.136, ntokens=1815.8, nsentences=56, sample_size=1815.8, sample_size_v1=0, sample_size_v2=0, ppl=2.2, wps=1067.1, ups=0.59, wpb=1815.8, bsz=56, num_updates=7490, lr=1.68234e-05, gnorm=2.645, clip=100, loss_scale=128, train_wall=17, gb_free=12.9, wall=12917
2023-06-27 19:54:12 - progress_bar.py[line:272] - INFO: epoch 008:    583 / 990 loss=2.38, loss_v1=0, loss_v2=0, nll_loss=1.18, ntokens=1883.5, nsentences=56, sample_size=1883.5, sample_size_v1=0, sample_size_v2=0, ppl=2.27, wps=1102.5, ups=0.59, wpb=1883.5, bsz=56, num_updates=7500, lr=1.68032e-05, gnorm=2.702, clip=100, loss_scale=128, train_wall=17, gb_free=12, wall=12934
2023-06-27 19:54:29 - progress_bar.py[line:272] - INFO: epoch 008:    593 / 990 loss=2.344, loss_v1=0, loss_v2=0, nll_loss=1.138, ntokens=1909.6, nsentences=56, sample_size=1909.6, sample_size_v1=0, sample_size_v2=0, ppl=2.2, wps=1114.8, ups=0.58, wpb=1909.6, bsz=56, num_updates=7510, lr=1.67831e-05, gnorm=2.445, clip=100, loss_scale=128, train_wall=17, gb_free=12.9, wall=12952
2023-06-27 19:54:46 - progress_bar.py[line:272] - INFO: epoch 008:    603 / 990 loss=2.356, loss_v1=0, loss_v2=0, nll_loss=1.156, ntokens=1732.9, nsentences=56, sample_size=1732.9, sample_size_v1=0, sample_size_v2=0, ppl=2.23, wps=1019.5, ups=0.59, wpb=1732.9, bsz=56, num_updates=7520, lr=1.67629e-05, gnorm=2.735, clip=100, loss_scale=128, train_wall=17, gb_free=12.8, wall=12969
2023-06-27 19:55:03 - progress_bar.py[line:272] - INFO: epoch 008:    613 / 990 loss=2.336, loss_v1=0, loss_v2=0, nll_loss=1.131, ntokens=1853.2, nsentences=56, sample_size=1853.2, sample_size_v1=0, sample_size_v2=0, ppl=2.19, wps=1088, ups=0.59, wpb=1853.2, bsz=56, num_updates=7530, lr=1.67428e-05, gnorm=2.642, clip=100, loss_scale=128, train_wall=17, gb_free=13.1, wall=12986
2023-06-27 19:55:20 - progress_bar.py[line:272] - INFO: epoch 008:    623 / 990 loss=2.363, loss_v1=0, loss_v2=0, nll_loss=1.161, ntokens=1991.1, nsentences=56, sample_size=1991.1, sample_size_v1=0, sample_size_v2=0, ppl=2.24, wps=1165.5, ups=0.59, wpb=1991.1, bsz=56, num_updates=7540, lr=1.67226e-05, gnorm=2.534, clip=100, loss_scale=128, train_wall=17, gb_free=12.4, wall=13003
2023-06-27 19:55:37 - progress_bar.py[line:272] - INFO: epoch 008:    633 / 990 loss=2.373, loss_v1=0, loss_v2=0, nll_loss=1.175, ntokens=2015.6, nsentences=56, sample_size=2015.6, sample_size_v1=0, sample_size_v2=0, ppl=2.26, wps=1173.9, ups=0.58, wpb=2015.6, bsz=56, num_updates=7550, lr=1.67025e-05, gnorm=2.459, clip=100, loss_scale=128, train_wall=17, gb_free=13, wall=13020
2023-06-27 19:55:54 - progress_bar.py[line:272] - INFO: epoch 008:    643 / 990 loss=2.343, loss_v1=0, loss_v2=0, nll_loss=1.139, ntokens=1989.3, nsentences=56, sample_size=1989.3, sample_size_v1=0, sample_size_v2=0, ppl=2.2, wps=1156.8, ups=0.58, wpb=1989.3, bsz=56, num_updates=7560, lr=1.66823e-05, gnorm=2.424, clip=100, loss_scale=128, train_wall=17, gb_free=13.1, wall=13037
2023-06-27 19:56:12 - progress_bar.py[line:272] - INFO: epoch 008:    653 / 990 loss=2.354, loss_v1=0, loss_v2=0, nll_loss=1.152, ntokens=1933.5, nsentences=56, sample_size=1933.5, sample_size_v1=0, sample_size_v2=0, ppl=2.22, wps=1130.4, ups=0.58, wpb=1933.5, bsz=56, num_updates=7570, lr=1.66622e-05, gnorm=2.518, clip=100, loss_scale=128, train_wall=17, gb_free=12.9, wall=13054
2023-06-27 19:56:29 - progress_bar.py[line:272] - INFO: epoch 008:    663 / 990 loss=2.354, loss_v1=0, loss_v2=0, nll_loss=1.151, ntokens=1893.4, nsentences=56, sample_size=1893.4, sample_size_v1=0, sample_size_v2=0, ppl=2.22, wps=1104.1, ups=0.58, wpb=1893.4, bsz=56, num_updates=7580, lr=1.6642e-05, gnorm=2.566, clip=100, loss_scale=128, train_wall=17, gb_free=12.4, wall=13071
2023-06-27 19:56:46 - progress_bar.py[line:272] - INFO: epoch 008:    673 / 990 loss=2.355, loss_v1=0, loss_v2=0, nll_loss=1.151, ntokens=1819.5, nsentences=56, sample_size=1819.5, sample_size_v1=0, sample_size_v2=0, ppl=2.22, wps=1062.1, ups=0.58, wpb=1819.5, bsz=56, num_updates=7590, lr=1.66219e-05, gnorm=2.87, clip=100, loss_scale=128, train_wall=17, gb_free=11.6, wall=13089
2023-06-27 19:57:03 - progress_bar.py[line:272] - INFO: epoch 008:    683 / 990 loss=2.308, loss_v1=0, loss_v2=0, nll_loss=1.102, ntokens=1889.2, nsentences=56, sample_size=1889.2, sample_size_v1=0, sample_size_v2=0, ppl=2.15, wps=1100.7, ups=0.58, wpb=1889.2, bsz=56, num_updates=7600, lr=1.66017e-05, gnorm=2.513, clip=100, loss_scale=128, train_wall=17, gb_free=13.1, wall=13106
2023-06-27 19:57:20 - progress_bar.py[line:272] - INFO: epoch 008:    693 / 990 loss=2.341, loss_v1=0, loss_v2=0, nll_loss=1.138, ntokens=1764.1, nsentences=56, sample_size=1764.1, sample_size_v1=0, sample_size_v2=0, ppl=2.2, wps=1035.9, ups=0.59, wpb=1764.1, bsz=56, num_updates=7610, lr=1.65816e-05, gnorm=2.708, clip=100, loss_scale=128, train_wall=17, gb_free=12.1, wall=13123
2023-06-27 19:57:37 - progress_bar.py[line:272] - INFO: epoch 008:    703 / 990 loss=2.359, loss_v1=0, loss_v2=0, nll_loss=1.155, ntokens=1714.9, nsentences=56, sample_size=1714.9, sample_size_v1=0, sample_size_v2=0, ppl=2.23, wps=1006.1, ups=0.59, wpb=1714.9, bsz=56, num_updates=7620, lr=1.65615e-05, gnorm=2.665, clip=100, loss_scale=128, train_wall=17, gb_free=12.9, wall=13140
2023-06-27 19:57:54 - progress_bar.py[line:272] - INFO: epoch 008:    713 / 990 loss=2.357, loss_v1=0, loss_v2=0, nll_loss=1.155, ntokens=1778.6, nsentences=56, sample_size=1778.6, sample_size_v1=0, sample_size_v2=0, ppl=2.23, wps=1047, ups=0.59, wpb=1778.6, bsz=56, num_updates=7630, lr=1.65413e-05, gnorm=2.763, clip=100, loss_scale=128, train_wall=17, gb_free=12.6, wall=13157
2023-06-27 19:58:11 - progress_bar.py[line:272] - INFO: epoch 008:    723 / 990 loss=2.344, loss_v1=0, loss_v2=0, nll_loss=1.14, ntokens=1751.9, nsentences=56, sample_size=1751.9, sample_size_v1=0, sample_size_v2=0, ppl=2.2, wps=1033.5, ups=0.59, wpb=1751.9, bsz=56, num_updates=7640, lr=1.65212e-05, gnorm=2.886, clip=100, loss_scale=128, train_wall=17, gb_free=12.8, wall=13174
2023-06-27 19:58:28 - progress_bar.py[line:272] - INFO: epoch 008:    733 / 990 loss=2.315, loss_v1=0, loss_v2=0, nll_loss=1.107, ntokens=1818.1, nsentences=56, sample_size=1818.1, sample_size_v1=0, sample_size_v2=0, ppl=2.15, wps=1065.5, ups=0.59, wpb=1818.1, bsz=56, num_updates=7650, lr=1.6501e-05, gnorm=2.6, clip=100, loss_scale=128, train_wall=17, gb_free=12.9, wall=13191
2023-06-27 19:58:45 - progress_bar.py[line:272] - INFO: epoch 008:    743 / 990 loss=2.366, loss_v1=0, loss_v2=0, nll_loss=1.164, ntokens=1794.8, nsentences=56, sample_size=1794.8, sample_size_v1=0, sample_size_v2=0, ppl=2.24, wps=1053, ups=0.59, wpb=1794.8, bsz=56, num_updates=7660, lr=1.64809e-05, gnorm=2.601, clip=100, loss_scale=128, train_wall=17, gb_free=12.6, wall=13208
2023-06-27 19:59:02 - progress_bar.py[line:272] - INFO: epoch 008:    753 / 990 loss=2.373, loss_v1=0, loss_v2=0, nll_loss=1.175, ntokens=1659.3, nsentences=56, sample_size=1659.3, sample_size_v1=0, sample_size_v2=0, ppl=2.26, wps=979.5, ups=0.59, wpb=1659.3, bsz=56, num_updates=7670, lr=1.64607e-05, gnorm=2.837, clip=100, loss_scale=128, train_wall=17, gb_free=12.9, wall=13225
2023-06-27 19:59:19 - progress_bar.py[line:272] - INFO: epoch 008:    763 / 990 loss=2.353, loss_v1=0, loss_v2=0, nll_loss=1.149, ntokens=1746.8, nsentences=56, sample_size=1746.8, sample_size_v1=0, sample_size_v2=0, ppl=2.22, wps=1026.5, ups=0.59, wpb=1746.8, bsz=56, num_updates=7680, lr=1.64406e-05, gnorm=2.753, clip=100, loss_scale=128, train_wall=17, gb_free=13, wall=13242
2023-06-27 19:59:36 - progress_bar.py[line:272] - INFO: epoch 008:    773 / 990 loss=2.351, loss_v1=0, loss_v2=0, nll_loss=1.148, ntokens=1838.2, nsentences=56, sample_size=1838.2, sample_size_v1=0, sample_size_v2=0, ppl=2.22, wps=1075.5, ups=0.59, wpb=1838.2, bsz=56, num_updates=7690, lr=1.64204e-05, gnorm=2.66, clip=100, loss_scale=128, train_wall=17, gb_free=12.6, wall=13259
2023-06-27 19:59:53 - progress_bar.py[line:272] - INFO: epoch 008:    783 / 990 loss=2.337, loss_v1=0, loss_v2=0, nll_loss=1.133, ntokens=1775.1, nsentences=56, sample_size=1775.1, sample_size_v1=0, sample_size_v2=0, ppl=2.19, wps=1045.4, ups=0.59, wpb=1775.1, bsz=56, num_updates=7700, lr=1.64003e-05, gnorm=2.831, clip=100, loss_scale=128, train_wall=17, gb_free=12.6, wall=13276
2023-06-27 20:00:10 - progress_bar.py[line:272] - INFO: epoch 008:    793 / 990 loss=2.353, loss_v1=0, loss_v2=0, nll_loss=1.152, ntokens=1828.9, nsentences=56, sample_size=1828.9, sample_size_v1=0, sample_size_v2=0, ppl=2.22, wps=1070.4, ups=0.59, wpb=1828.9, bsz=56, num_updates=7710, lr=1.63801e-05, gnorm=2.614, clip=100, loss_scale=128, train_wall=17, gb_free=12.4, wall=13293
2023-06-27 20:00:27 - progress_bar.py[line:272] - INFO: epoch 008:    803 / 990 loss=2.356, loss_v1=0, loss_v2=0, nll_loss=1.151, ntokens=1766.6, nsentences=56, sample_size=1766.6, sample_size_v1=0, sample_size_v2=0, ppl=2.22, wps=1033.2, ups=0.58, wpb=1766.6, bsz=56, num_updates=7720, lr=1.636e-05, gnorm=2.507, clip=100, loss_scale=128, train_wall=17, gb_free=12.9, wall=13310
2023-06-27 20:00:44 - progress_bar.py[line:272] - INFO: epoch 008:    813 / 990 loss=2.372, loss_v1=0, loss_v2=0, nll_loss=1.173, ntokens=1687.3, nsentences=56, sample_size=1687.3, sample_size_v1=0, sample_size_v2=0, ppl=2.26, wps=993.2, ups=0.59, wpb=1687.3, bsz=56, num_updates=7730, lr=1.63398e-05, gnorm=2.769, clip=100, loss_scale=128, train_wall=17, gb_free=12.9, wall=13327
2023-06-27 20:01:01 - progress_bar.py[line:272] - INFO: epoch 008:    823 / 990 loss=2.341, loss_v1=0, loss_v2=0, nll_loss=1.139, ntokens=1695.7, nsentences=56, sample_size=1695.7, sample_size_v1=0, sample_size_v2=0, ppl=2.2, wps=994.4, ups=0.59, wpb=1695.7, bsz=56, num_updates=7740, lr=1.63197e-05, gnorm=2.76, clip=100, loss_scale=128, train_wall=17, gb_free=12.5, wall=13344
2023-06-27 20:01:18 - progress_bar.py[line:272] - INFO: epoch 008:    833 / 990 loss=2.324, loss_v1=0, loss_v2=0, nll_loss=1.117, ntokens=1764.5, nsentences=56, sample_size=1764.5, sample_size_v1=0, sample_size_v2=0, ppl=2.17, wps=1038.1, ups=0.59, wpb=1764.5, bsz=56, num_updates=7750, lr=1.62995e-05, gnorm=2.723, clip=100, loss_scale=128, train_wall=17, gb_free=13, wall=13361
2023-06-27 20:01:36 - progress_bar.py[line:272] - INFO: epoch 008:    843 / 990 loss=2.33, loss_v1=0, loss_v2=0, nll_loss=1.124, ntokens=1851.4, nsentences=56, sample_size=1851.4, sample_size_v1=0, sample_size_v2=0, ppl=2.18, wps=1085.2, ups=0.59, wpb=1851.4, bsz=56, num_updates=7760, lr=1.62794e-05, gnorm=2.543, clip=100, loss_scale=128, train_wall=17, gb_free=12.6, wall=13378
2023-06-27 20:01:53 - progress_bar.py[line:272] - INFO: epoch 008:    853 / 990 loss=2.321, loss_v1=0, loss_v2=0, nll_loss=1.113, ntokens=1876.2, nsentences=56, sample_size=1876.2, sample_size_v1=0, sample_size_v2=0, ppl=2.16, wps=1093.2, ups=0.58, wpb=1876.2, bsz=56, num_updates=7770, lr=1.62592e-05, gnorm=2.559, clip=100, loss_scale=128, train_wall=17, gb_free=12.4, wall=13395
2023-06-27 20:02:10 - progress_bar.py[line:272] - INFO: epoch 008:    863 / 990 loss=2.322, loss_v1=0, loss_v2=0, nll_loss=1.117, ntokens=1835.6, nsentences=56, sample_size=1835.6, sample_size_v1=0, sample_size_v2=0, ppl=2.17, wps=1059.9, ups=0.58, wpb=1835.6, bsz=56, num_updates=7780, lr=1.62391e-05, gnorm=2.813, clip=100, loss_scale=128, train_wall=17, gb_free=12.9, wall=13413
2023-06-27 20:02:27 - progress_bar.py[line:272] - INFO: epoch 008:    873 / 990 loss=2.339, loss_v1=0, loss_v2=0, nll_loss=1.136, ntokens=1868.2, nsentences=56, sample_size=1868.2, sample_size_v1=0, sample_size_v2=0, ppl=2.2, wps=1091, ups=0.58, wpb=1868.2, bsz=56, num_updates=7790, lr=1.62189e-05, gnorm=2.577, clip=100, loss_scale=128, train_wall=17, gb_free=13, wall=13430
2023-06-27 20:02:44 - progress_bar.py[line:272] - INFO: epoch 008:    883 / 990 loss=2.326, loss_v1=0, loss_v2=0, nll_loss=1.12, ntokens=1829.9, nsentences=56, sample_size=1829.9, sample_size_v1=0, sample_size_v2=0, ppl=2.17, wps=1075.5, ups=0.59, wpb=1829.9, bsz=56, num_updates=7800, lr=1.61988e-05, gnorm=2.654, clip=100, loss_scale=128, train_wall=17, gb_free=11.3, wall=13447
2023-06-27 20:02:56 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 128.0
2023-06-27 20:03:03 - progress_bar.py[line:272] - INFO: epoch 008:    894 / 990 loss=2.317, loss_v1=0, loss_v2=0, nll_loss=1.109, ntokens=1996.7, nsentences=56, sample_size=1996.7, sample_size_v1=0, sample_size_v2=0, ppl=2.16, wps=1063.4, ups=0.53, wpb=1996.7, bsz=56, num_updates=7810, lr=1.61786e-05, gnorm=2.466, clip=100, loss_scale=128, train_wall=19, gb_free=12.8, wall=13466
2023-06-27 20:03:20 - progress_bar.py[line:272] - INFO: epoch 008:    904 / 990 loss=2.358, loss_v1=0, loss_v2=0, nll_loss=1.158, ntokens=1736.5, nsentences=56, sample_size=1736.5, sample_size_v1=0, sample_size_v2=0, ppl=2.23, wps=1004.8, ups=0.58, wpb=1736.5, bsz=56, num_updates=7820, lr=1.61585e-05, gnorm=2.763, clip=100, loss_scale=128, train_wall=17, gb_free=12.5, wall=13483
2023-06-27 20:03:37 - progress_bar.py[line:272] - INFO: epoch 008:    914 / 990 loss=2.35, loss_v1=0, loss_v2=0, nll_loss=1.146, ntokens=1771.2, nsentences=56, sample_size=1771.2, sample_size_v1=0, sample_size_v2=0, ppl=2.21, wps=1043.4, ups=0.59, wpb=1771.2, bsz=56, num_updates=7830, lr=1.61383e-05, gnorm=2.705, clip=100, loss_scale=128, train_wall=17, gb_free=12.9, wall=13500
2023-06-27 20:03:54 - progress_bar.py[line:272] - INFO: epoch 008:    924 / 990 loss=2.32, loss_v1=0, loss_v2=0, nll_loss=1.114, ntokens=1753.4, nsentences=56, sample_size=1753.4, sample_size_v1=0, sample_size_v2=0, ppl=2.16, wps=1030.2, ups=0.59, wpb=1753.4, bsz=56, num_updates=7840, lr=1.61182e-05, gnorm=2.831, clip=100, loss_scale=128, train_wall=17, gb_free=12.9, wall=13517
2023-06-27 20:04:11 - progress_bar.py[line:272] - INFO: epoch 008:    934 / 990 loss=2.317, loss_v1=0, loss_v2=0, nll_loss=1.111, ntokens=1845.8, nsentences=56, sample_size=1845.8, sample_size_v1=0, sample_size_v2=0, ppl=2.16, wps=1080.2, ups=0.59, wpb=1845.8, bsz=56, num_updates=7850, lr=1.60981e-05, gnorm=2.547, clip=100, loss_scale=128, train_wall=17, gb_free=13.1, wall=13534
2023-06-27 20:04:28 - progress_bar.py[line:272] - INFO: epoch 008:    944 / 990 loss=2.326, loss_v1=0, loss_v2=0, nll_loss=1.121, ntokens=1882.7, nsentences=56, sample_size=1882.7, sample_size_v1=0, sample_size_v2=0, ppl=2.17, wps=1097.5, ups=0.58, wpb=1882.7, bsz=56, num_updates=7860, lr=1.60779e-05, gnorm=2.457, clip=100, loss_scale=128, train_wall=17, gb_free=12.9, wall=13551
2023-06-27 20:04:46 - progress_bar.py[line:272] - INFO: epoch 008:    954 / 990 loss=2.33, loss_v1=0, loss_v2=0, nll_loss=1.124, ntokens=1927.3, nsentences=56, sample_size=1927.3, sample_size_v1=0, sample_size_v2=0, ppl=2.18, wps=1124.5, ups=0.58, wpb=1927.3, bsz=56, num_updates=7870, lr=1.60578e-05, gnorm=2.685, clip=100, loss_scale=128, train_wall=17, gb_free=13.1, wall=13568
2023-06-27 20:05:03 - progress_bar.py[line:272] - INFO: epoch 008:    964 / 990 loss=2.339, loss_v1=0, loss_v2=0, nll_loss=1.135, ntokens=1878.2, nsentences=56, sample_size=1878.2, sample_size_v1=0, sample_size_v2=0, ppl=2.2, wps=1098.1, ups=0.58, wpb=1878.2, bsz=56, num_updates=7880, lr=1.60376e-05, gnorm=2.627, clip=100, loss_scale=128, train_wall=17, gb_free=13, wall=13585
2023-06-27 20:05:20 - progress_bar.py[line:272] - INFO: epoch 008:    974 / 990 loss=2.321, loss_v1=0, loss_v2=0, nll_loss=1.117, ntokens=1945, nsentences=56, sample_size=1945, sample_size_v1=0, sample_size_v2=0, ppl=2.17, wps=1129.1, ups=0.58, wpb=1945, bsz=56, num_updates=7890, lr=1.60175e-05, gnorm=2.537, clip=100, loss_scale=128, train_wall=17, gb_free=12.8, wall=13603
2023-06-27 20:05:37 - progress_bar.py[line:272] - INFO: epoch 008:    984 / 990 loss=2.341, loss_v1=0, loss_v2=0, nll_loss=1.136, ntokens=1795.5, nsentences=56, sample_size=1795.5, sample_size_v1=0, sample_size_v2=0, ppl=2.2, wps=1054, ups=0.59, wpb=1795.5, bsz=56, num_updates=7900, lr=1.59973e-05, gnorm=2.63, clip=100, loss_scale=128, train_wall=17, gb_free=12.4, wall=13620
local datafile ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 1 begin to initialize row_count and line_idx-to-offset mapping
2023-06-27 20:05:46 - checkpoint_utils.py[line:64] - INFO: Preparing to save checkpoint for epoch 8 @ 7906 updates
2023-06-27 20:05:46 - trainer.py[line:431] - INFO: Saving checkpoint to ../../checkpoints/OFA/sgcls_checkpoints/_16_3e-5_512_base/checkpoint8.pt
local datafile ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 1 finished initializing row_count and line_idx-to-offset mapping
file ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 1 row count 27700 total row count 55400
slice_id 1 seek offset 27700
2023-06-27 20:05:51 - trainer.py[line:441] - INFO: Finished saving checkpoint to ../../checkpoints/OFA/sgcls_checkpoints/_16_3e-5_512_base/checkpoint8.pt
2023-06-27 20:05:53 - checkpoint_utils.py[line:133] - INFO: Saved checkpoint ../../checkpoints/OFA/sgcls_checkpoints/_16_3e-5_512_base/checkpoint8.pt (epoch 8 @ 7906 updates, score None) (writing took 6.5708122150972486 seconds)
2023-06-27 20:05:53 - train.py[line:332] - INFO: end of epoch 8 (average epoch stats below)
2023-06-27 20:05:53 - progress_bar.py[line:282] - INFO: epoch 008 | loss 2.331 | loss_v1 0 | loss_v2 0 | nll_loss 1.126 | ntokens 1849.82 | nsentences 55.96 | sample_size 1849.82 | sample_size_v1 0 | sample_size_v2 0 | ppl 2.18 | wps 1070.5 | ups 0.58 | wpb 1849.8 | bsz 56 | num_updates 7906 | lr 1.59852e-05 | gnorm 2.55 | clip 100 | loss_scale 128 | train_wall 1695 | gb_free 13.3 | wall 13636
2023-06-27 20:05:53 - trainer.py[line:639] - INFO: loading train data for epoch 9
local datafile ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 0 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 0 finished initializing row_count and line_idx-to-offset mapping
file ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 0 row count 27700 total row count 55400
slice_id 0 seek offset 0
2023-06-27 20:05:55 - trainer.py[line:703] - INFO: begin training epoch 9
2023-06-27 20:05:55 - train.py[line:305] - INFO: Start iterating over samples
2023-06-27 20:06:02 - progress_bar.py[line:272] - INFO: epoch 009:      4 / 990 loss=2.346, loss_v1=0, loss_v2=0, nll_loss=1.142, ntokens=1789.4, nsentences=53.2, sample_size=1789.4, sample_size_v1=0, sample_size_v2=0, ppl=2.21, wps=714.2, ups=0.4, wpb=1789.4, bsz=53.2, num_updates=7910, lr=1.59772e-05, gnorm=2.816, clip=100, loss_scale=128, train_wall=16, gb_free=12.4, wall=13645
2023-06-27 20:06:19 - progress_bar.py[line:272] - INFO: epoch 009:     14 / 990 loss=2.291, loss_v1=0, loss_v2=0, nll_loss=1.082, ntokens=1790.5, nsentences=56, sample_size=1790.5, sample_size_v1=0, sample_size_v2=0, ppl=2.12, wps=1040.8, ups=0.58, wpb=1790.5, bsz=56, num_updates=7920, lr=1.5957e-05, gnorm=2.69, clip=100, loss_scale=128, train_wall=17, gb_free=12.7, wall=13662
2023-06-27 20:06:36 - progress_bar.py[line:272] - INFO: epoch 009:     24 / 990 loss=2.254, loss_v1=0, loss_v2=0, nll_loss=1.04, ntokens=1851.2, nsentences=56, sample_size=1851.2, sample_size_v1=0, sample_size_v2=0, ppl=2.06, wps=1074.5, ups=0.58, wpb=1851.2, bsz=56, num_updates=7930, lr=1.59369e-05, gnorm=2.419, clip=100, loss_scale=128, train_wall=17, gb_free=12.4, wall=13679
2023-06-27 20:06:53 - progress_bar.py[line:272] - INFO: epoch 009:     34 / 990 loss=2.289, loss_v1=0, loss_v2=0, nll_loss=1.077, ntokens=1720.7, nsentences=56, sample_size=1720.7, sample_size_v1=0, sample_size_v2=0, ppl=2.11, wps=1011, ups=0.59, wpb=1720.7, bsz=56, num_updates=7940, lr=1.59167e-05, gnorm=2.714, clip=100, loss_scale=128, train_wall=17, gb_free=12.4, wall=13696
2023-06-27 20:07:11 - progress_bar.py[line:272] - INFO: epoch 009:     44 / 990 loss=2.201, loss_v1=0, loss_v2=0, nll_loss=0.983, ntokens=2014.5, nsentences=56, sample_size=2014.5, sample_size_v1=0, sample_size_v2=0, ppl=1.98, wps=1159.1, ups=0.58, wpb=2014.5, bsz=56, num_updates=7950, lr=1.58966e-05, gnorm=2.302, clip=100, loss_scale=128, train_wall=17, gb_free=11.6, wall=13714
2023-06-27 20:07:28 - progress_bar.py[line:272] - INFO: epoch 009:     54 / 990 loss=2.282, loss_v1=0, loss_v2=0, nll_loss=1.07, ntokens=1709.6, nsentences=56, sample_size=1709.6, sample_size_v1=0, sample_size_v2=0, ppl=2.1, wps=993.2, ups=0.58, wpb=1709.6, bsz=56, num_updates=7960, lr=1.58764e-05, gnorm=2.886, clip=100, loss_scale=128, train_wall=17, gb_free=11.6, wall=13731
2023-06-27 20:07:45 - progress_bar.py[line:272] - INFO: epoch 009:     64 / 990 loss=2.206, loss_v1=0, loss_v2=0, nll_loss=0.985, ntokens=1839.5, nsentences=56, sample_size=1839.5, sample_size_v1=0, sample_size_v2=0, ppl=1.98, wps=1067.9, ups=0.58, wpb=1839.5, bsz=56, num_updates=7970, lr=1.58563e-05, gnorm=2.687, clip=100, loss_scale=128, train_wall=17, gb_free=12.5, wall=13748
2023-06-27 20:08:03 - progress_bar.py[line:272] - INFO: epoch 009:     74 / 990 loss=2.137, loss_v1=0, loss_v2=0, nll_loss=0.91, ntokens=2066, nsentences=56, sample_size=2066, sample_size_v1=0, sample_size_v2=0, ppl=1.88, wps=1180.6, ups=0.57, wpb=2066, bsz=56, num_updates=7980, lr=1.58361e-05, gnorm=2.185, clip=100, loss_scale=128, train_wall=17, gb_free=11.9, wall=13765
2023-06-27 20:08:21 - progress_bar.py[line:272] - INFO: epoch 009:     84 / 990 loss=2.203, loss_v1=0, loss_v2=0, nll_loss=0.983, ntokens=2172.9, nsentences=56, sample_size=2172.9, sample_size_v1=0, sample_size_v2=0, ppl=1.98, wps=1224.1, ups=0.56, wpb=2172.9, bsz=56, num_updates=7990, lr=1.5816e-05, gnorm=2.214, clip=100, loss_scale=128, train_wall=18, gb_free=11.3, wall=13783
2023-06-27 20:08:38 - progress_bar.py[line:272] - INFO: epoch 009:     94 / 990 loss=2.232, loss_v1=0, loss_v2=0, nll_loss=1.014, ntokens=1971.6, nsentences=56, sample_size=1971.6, sample_size_v1=0, sample_size_v2=0, ppl=2.02, wps=1129.1, ups=0.57, wpb=1971.6, bsz=56, num_updates=8000, lr=1.57958e-05, gnorm=2.594, clip=100, loss_scale=128, train_wall=17, gb_free=11.8, wall=13801
2023-06-27 20:08:55 - progress_bar.py[line:272] - INFO: epoch 009:    104 / 990 loss=2.261, loss_v1=0, loss_v2=0, nll_loss=1.047, ntokens=1862.3, nsentences=56, sample_size=1862.3, sample_size_v1=0, sample_size_v2=0, ppl=2.07, wps=1079.7, ups=0.58, wpb=1862.3, bsz=56, num_updates=8010, lr=1.57757e-05, gnorm=2.506, clip=100, loss_scale=128, train_wall=17, gb_free=12.5, wall=13818
2023-06-27 20:09:12 - progress_bar.py[line:272] - INFO: epoch 009:    114 / 990 loss=2.267, loss_v1=0, loss_v2=0, nll_loss=1.054, ntokens=1840.7, nsentences=56, sample_size=1840.7, sample_size_v1=0, sample_size_v2=0, ppl=2.08, wps=1072.5, ups=0.58, wpb=1840.7, bsz=56, num_updates=8020, lr=1.57555e-05, gnorm=2.653, clip=100, loss_scale=128, train_wall=17, gb_free=13, wall=13835
2023-06-27 20:09:30 - progress_bar.py[line:272] - INFO: epoch 009:    124 / 990 loss=2.322, loss_v1=0, loss_v2=0, nll_loss=1.118, ntokens=1803.4, nsentences=56, sample_size=1803.4, sample_size_v1=0, sample_size_v2=0, ppl=2.17, wps=1052, ups=0.58, wpb=1803.4, bsz=56, num_updates=8030, lr=1.57354e-05, gnorm=2.585, clip=100, loss_scale=128, train_wall=17, gb_free=12.8, wall=13852
2023-06-27 20:09:47 - progress_bar.py[line:272] - INFO: epoch 009:    134 / 990 loss=2.338, loss_v1=0, loss_v2=0, nll_loss=1.132, ntokens=1845, nsentences=56, sample_size=1845, sample_size_v1=0, sample_size_v2=0, ppl=2.19, wps=1068, ups=0.58, wpb=1845, bsz=56, num_updates=8040, lr=1.57152e-05, gnorm=2.437, clip=100, loss_scale=128, train_wall=17, gb_free=12.4, wall=13870
2023-06-27 20:10:04 - progress_bar.py[line:272] - INFO: epoch 009:    144 / 990 loss=2.306, loss_v1=0, loss_v2=0, nll_loss=1.095, ntokens=1943.1, nsentences=56, sample_size=1943.1, sample_size_v1=0, sample_size_v2=0, ppl=2.14, wps=1112.1, ups=0.57, wpb=1943.1, bsz=56, num_updates=8050, lr=1.56951e-05, gnorm=2.436, clip=100, loss_scale=128, train_wall=17, gb_free=12.5, wall=13887
2023-06-27 20:10:22 - progress_bar.py[line:272] - INFO: epoch 009:    154 / 990 loss=2.295, loss_v1=0, loss_v2=0, nll_loss=1.086, ntokens=1938.2, nsentences=56, sample_size=1938.2, sample_size_v1=0, sample_size_v2=0, ppl=2.12, wps=1113.5, ups=0.57, wpb=1938.2, bsz=56, num_updates=8060, lr=1.56749e-05, gnorm=2.34, clip=100, loss_scale=128, train_wall=17, gb_free=12.5, wall=13904
2023-06-27 20:10:39 - progress_bar.py[line:272] - INFO: epoch 009:    164 / 990 loss=2.284, loss_v1=0, loss_v2=0, nll_loss=1.074, ntokens=2009, nsentences=56, sample_size=2009, sample_size_v1=0, sample_size_v2=0, ppl=2.1, wps=1150.3, ups=0.57, wpb=2009, bsz=56, num_updates=8070, lr=1.56548e-05, gnorm=2.333, clip=100, loss_scale=128, train_wall=17, gb_free=11.9, wall=13922
2023-06-27 20:10:57 - progress_bar.py[line:272] - INFO: epoch 009:    174 / 990 loss=2.27, loss_v1=0, loss_v2=0, nll_loss=1.058, ntokens=1935.6, nsentences=56, sample_size=1935.6, sample_size_v1=0, sample_size_v2=0, ppl=2.08, wps=1112.6, ups=0.57, wpb=1935.6, bsz=56, num_updates=8080, lr=1.56347e-05, gnorm=2.389, clip=100, loss_scale=128, train_wall=17, gb_free=12, wall=13939
2023-06-27 20:11:14 - progress_bar.py[line:272] - INFO: epoch 009:    184 / 990 loss=2.299, loss_v1=0, loss_v2=0, nll_loss=1.089, ntokens=1902.2, nsentences=56, sample_size=1902.2, sample_size_v1=0, sample_size_v2=0, ppl=2.13, wps=1097.4, ups=0.58, wpb=1902.2, bsz=56, num_updates=8090, lr=1.56145e-05, gnorm=2.514, clip=100, loss_scale=128, train_wall=17, gb_free=12.7, wall=13957
2023-06-27 20:11:31 - progress_bar.py[line:272] - INFO: epoch 009:    194 / 990 loss=2.288, loss_v1=0, loss_v2=0, nll_loss=1.078, ntokens=1869, nsentences=56, sample_size=1869, sample_size_v1=0, sample_size_v2=0, ppl=2.11, wps=1086.7, ups=0.58, wpb=1869, bsz=56, num_updates=8100, lr=1.55944e-05, gnorm=2.556, clip=100, loss_scale=128, train_wall=17, gb_free=12.8, wall=13974
2023-06-27 20:11:48 - progress_bar.py[line:272] - INFO: epoch 009:    204 / 990 loss=2.27, loss_v1=0, loss_v2=0, nll_loss=1.057, ntokens=1885.2, nsentences=56, sample_size=1885.2, sample_size_v1=0, sample_size_v2=0, ppl=2.08, wps=1090, ups=0.58, wpb=1885.2, bsz=56, num_updates=8110, lr=1.55742e-05, gnorm=2.681, clip=100, loss_scale=128, train_wall=17, gb_free=12.5, wall=13991
2023-06-27 20:12:06 - progress_bar.py[line:272] - INFO: epoch 009:    214 / 990 loss=2.278, loss_v1=0, loss_v2=0, nll_loss=1.068, ntokens=1912.5, nsentences=56, sample_size=1912.5, sample_size_v1=0, sample_size_v2=0, ppl=2.1, wps=1101.1, ups=0.58, wpb=1912.5, bsz=56, num_updates=8120, lr=1.55541e-05, gnorm=2.551, clip=100, loss_scale=128, train_wall=17, gb_free=12.6, wall=14009
2023-06-27 20:12:23 - progress_bar.py[line:272] - INFO: epoch 009:    224 / 990 loss=2.298, loss_v1=0, loss_v2=0, nll_loss=1.087, ntokens=1924.5, nsentences=56, sample_size=1924.5, sample_size_v1=0, sample_size_v2=0, ppl=2.12, wps=1110.6, ups=0.58, wpb=1924.5, bsz=56, num_updates=8130, lr=1.55339e-05, gnorm=2.524, clip=100, loss_scale=128, train_wall=17, gb_free=12.2, wall=14026
2023-06-27 20:12:40 - progress_bar.py[line:272] - INFO: epoch 009:    234 / 990 loss=2.33, loss_v1=0, loss_v2=0, nll_loss=1.126, ntokens=1750, nsentences=56, sample_size=1750, sample_size_v1=0, sample_size_v2=0, ppl=2.18, wps=1022.4, ups=0.58, wpb=1750, bsz=56, num_updates=8140, lr=1.55138e-05, gnorm=2.719, clip=100, loss_scale=128, train_wall=17, gb_free=12.6, wall=14043
2023-06-27 20:12:58 - progress_bar.py[line:272] - INFO: epoch 009:    244 / 990 loss=2.341, loss_v1=0, loss_v2=0, nll_loss=1.138, ntokens=1872.4, nsentences=56, sample_size=1872.4, sample_size_v1=0, sample_size_v2=0, ppl=2.2, wps=1088.1, ups=0.58, wpb=1872.4, bsz=56, num_updates=8150, lr=1.54936e-05, gnorm=2.552, clip=100, loss_scale=128, train_wall=17, gb_free=12.2, wall=14060
2023-06-27 20:13:15 - progress_bar.py[line:272] - INFO: epoch 009:    254 / 990 loss=2.331, loss_v1=0, loss_v2=0, nll_loss=1.126, ntokens=1923.2, nsentences=56, sample_size=1923.2, sample_size_v1=0, sample_size_v2=0, ppl=2.18, wps=1121.6, ups=0.58, wpb=1923.2, bsz=56, num_updates=8160, lr=1.54735e-05, gnorm=2.538, clip=100, loss_scale=128, train_wall=17, gb_free=12.4, wall=14077
2023-06-27 20:13:32 - progress_bar.py[line:272] - INFO: epoch 009:    264 / 990 loss=2.362, loss_v1=0, loss_v2=0, nll_loss=1.159, ntokens=1848.1, nsentences=56, sample_size=1848.1, sample_size_v1=0, sample_size_v2=0, ppl=2.23, wps=1079.1, ups=0.58, wpb=1848.1, bsz=56, num_updates=8170, lr=1.54533e-05, gnorm=2.602, clip=100, loss_scale=128, train_wall=17, gb_free=12.6, wall=14094
2023-06-27 20:13:49 - progress_bar.py[line:272] - INFO: epoch 009:    274 / 990 loss=2.362, loss_v1=0, loss_v2=0, nll_loss=1.161, ntokens=1924.2, nsentences=56, sample_size=1924.2, sample_size_v1=0, sample_size_v2=0, ppl=2.24, wps=1114.6, ups=0.58, wpb=1924.2, bsz=56, num_updates=8180, lr=1.54332e-05, gnorm=2.493, clip=100, loss_scale=128, train_wall=17, gb_free=12.3, wall=14112
2023-06-27 20:14:06 - progress_bar.py[line:272] - INFO: epoch 009:    284 / 990 loss=2.353, loss_v1=0, loss_v2=0, nll_loss=1.151, ntokens=1893.2, nsentences=56, sample_size=1893.2, sample_size_v1=0, sample_size_v2=0, ppl=2.22, wps=1090.6, ups=0.58, wpb=1893.2, bsz=56, num_updates=8190, lr=1.5413e-05, gnorm=2.5, clip=100, loss_scale=128, train_wall=17, gb_free=12.6, wall=14129
2023-06-27 20:14:24 - progress_bar.py[line:272] - INFO: epoch 009:    294 / 990 loss=2.353, loss_v1=0, loss_v2=0, nll_loss=1.15, ntokens=1850.5, nsentences=56, sample_size=1850.5, sample_size_v1=0, sample_size_v2=0, ppl=2.22, wps=1068.6, ups=0.58, wpb=1850.5, bsz=56, num_updates=8200, lr=1.53929e-05, gnorm=2.772, clip=100, loss_scale=128, train_wall=17, gb_free=12.6, wall=14146
2023-06-27 20:14:41 - progress_bar.py[line:272] - INFO: epoch 009:    304 / 990 loss=2.354, loss_v1=0, loss_v2=0, nll_loss=1.152, ntokens=1868.2, nsentences=56, sample_size=1868.2, sample_size_v1=0, sample_size_v2=0, ppl=2.22, wps=1083.3, ups=0.58, wpb=1868.2, bsz=56, num_updates=8210, lr=1.53727e-05, gnorm=2.506, clip=100, loss_scale=128, train_wall=17, gb_free=12.2, wall=14164
2023-06-27 20:14:58 - progress_bar.py[line:272] - INFO: epoch 009:    314 / 990 loss=2.35, loss_v1=0, loss_v2=0, nll_loss=1.146, ntokens=1930, nsentences=56, sample_size=1930, sample_size_v1=0, sample_size_v2=0, ppl=2.21, wps=1120.2, ups=0.58, wpb=1930, bsz=56, num_updates=8220, lr=1.53526e-05, gnorm=2.673, clip=100, loss_scale=128, train_wall=17, gb_free=12.9, wall=14181
2023-06-27 20:15:15 - progress_bar.py[line:272] - INFO: epoch 009:    324 / 990 loss=2.362, loss_v1=0, loss_v2=0, nll_loss=1.161, ntokens=1902.7, nsentences=56, sample_size=1902.7, sample_size_v1=0, sample_size_v2=0, ppl=2.24, wps=1102.6, ups=0.58, wpb=1902.7, bsz=56, num_updates=8230, lr=1.53324e-05, gnorm=2.703, clip=100, loss_scale=128, train_wall=17, gb_free=12.1, wall=14198
2023-06-27 20:15:33 - progress_bar.py[line:272] - INFO: epoch 009:    334 / 990 loss=2.326, loss_v1=0, loss_v2=0, nll_loss=1.12, ntokens=1878.2, nsentences=56, sample_size=1878.2, sample_size_v1=0, sample_size_v2=0, ppl=2.17, wps=1095, ups=0.58, wpb=1878.2, bsz=56, num_updates=8240, lr=1.53123e-05, gnorm=2.611, clip=100, loss_scale=128, train_wall=17, gb_free=12.8, wall=14215
2023-06-27 20:15:50 - progress_bar.py[line:272] - INFO: epoch 009:    344 / 990 loss=2.338, loss_v1=0, loss_v2=0, nll_loss=1.133, ntokens=1902.3, nsentences=56, sample_size=1902.3, sample_size_v1=0, sample_size_v2=0, ppl=2.19, wps=1103.6, ups=0.58, wpb=1902.3, bsz=56, num_updates=8250, lr=1.52921e-05, gnorm=2.627, clip=100, loss_scale=128, train_wall=17, gb_free=12.8, wall=14233
2023-06-27 20:16:07 - progress_bar.py[line:272] - INFO: epoch 009:    354 / 990 loss=2.313, loss_v1=0, loss_v2=0, nll_loss=1.107, ntokens=1883.9, nsentences=56, sample_size=1883.9, sample_size_v1=0, sample_size_v2=0, ppl=2.15, wps=1096.3, ups=0.58, wpb=1883.9, bsz=56, num_updates=8260, lr=1.5272e-05, gnorm=2.623, clip=100, loss_scale=128, train_wall=17, gb_free=11.7, wall=14250
2023-06-27 20:16:24 - progress_bar.py[line:272] - INFO: epoch 009:    364 / 990 loss=2.352, loss_v1=0, loss_v2=0, nll_loss=1.15, ntokens=1743.6, nsentences=56, sample_size=1743.6, sample_size_v1=0, sample_size_v2=0, ppl=2.22, wps=1025, ups=0.59, wpb=1743.6, bsz=56, num_updates=8270, lr=1.52518e-05, gnorm=2.908, clip=100, loss_scale=128, train_wall=17, gb_free=12.5, wall=14267
2023-06-27 20:16:41 - progress_bar.py[line:272] - INFO: epoch 009:    374 / 990 loss=2.365, loss_v1=0, loss_v2=0, nll_loss=1.163, ntokens=1770.4, nsentences=54.8, sample_size=1770.4, sample_size_v1=0, sample_size_v2=0, ppl=2.24, wps=1057, ups=0.6, wpb=1770.4, bsz=54.8, num_updates=8280, lr=1.52317e-05, gnorm=2.981, clip=100, loss_scale=128, train_wall=17, gb_free=12.8, wall=14284
2023-06-27 20:16:58 - progress_bar.py[line:272] - INFO: epoch 009:    384 / 990 loss=2.327, loss_v1=0, loss_v2=0, nll_loss=1.12, ntokens=1847.7, nsentences=56, sample_size=1847.7, sample_size_v1=0, sample_size_v2=0, ppl=2.17, wps=1084.5, ups=0.59, wpb=1847.7, bsz=56, num_updates=8290, lr=1.52116e-05, gnorm=2.871, clip=100, loss_scale=128, train_wall=17, gb_free=12.5, wall=14301
2023-06-27 20:17:15 - progress_bar.py[line:272] - INFO: epoch 009:    394 / 990 loss=2.324, loss_v1=0, loss_v2=0, nll_loss=1.12, ntokens=1718, nsentences=56, sample_size=1718, sample_size_v1=0, sample_size_v2=0, ppl=2.17, wps=1008.9, ups=0.59, wpb=1718, bsz=56, num_updates=8300, lr=1.51914e-05, gnorm=2.917, clip=100, loss_scale=128, train_wall=17, gb_free=12.7, wall=14318
2023-06-27 20:17:32 - progress_bar.py[line:272] - INFO: epoch 009:    404 / 990 loss=2.368, loss_v1=0, loss_v2=0, nll_loss=1.167, ntokens=1745.1, nsentences=56, sample_size=1745.1, sample_size_v1=0, sample_size_v2=0, ppl=2.25, wps=1026.4, ups=0.59, wpb=1745.1, bsz=56, num_updates=8310, lr=1.51713e-05, gnorm=2.926, clip=100, loss_scale=128, train_wall=17, gb_free=12, wall=14335
2023-06-27 20:17:49 - progress_bar.py[line:272] - INFO: epoch 009:    414 / 990 loss=2.357, loss_v1=0, loss_v2=0, nll_loss=1.153, ntokens=1712.2, nsentences=56, sample_size=1712.2, sample_size_v1=0, sample_size_v2=0, ppl=2.22, wps=1007.4, ups=0.59, wpb=1712.2, bsz=56, num_updates=8320, lr=1.51511e-05, gnorm=2.947, clip=100, loss_scale=256, train_wall=17, gb_free=12.7, wall=14352
2023-06-27 20:18:06 - progress_bar.py[line:272] - INFO: epoch 009:    424 / 990 loss=2.349, loss_v1=0, loss_v2=0, nll_loss=1.146, ntokens=1773.6, nsentences=56, sample_size=1773.6, sample_size_v1=0, sample_size_v2=0, ppl=2.21, wps=1036.3, ups=0.58, wpb=1773.6, bsz=56, num_updates=8330, lr=1.5131e-05, gnorm=2.731, clip=100, loss_scale=256, train_wall=17, gb_free=11.8, wall=14369
2023-06-27 20:18:23 - progress_bar.py[line:272] - INFO: epoch 009:    434 / 990 loss=2.326, loss_v1=0, loss_v2=0, nll_loss=1.121, ntokens=1930.8, nsentences=56, sample_size=1930.8, sample_size_v1=0, sample_size_v2=0, ppl=2.18, wps=1126.6, ups=0.58, wpb=1930.8, bsz=56, num_updates=8340, lr=1.51108e-05, gnorm=2.545, clip=100, loss_scale=256, train_wall=17, gb_free=11.9, wall=14386
2023-06-27 20:18:40 - progress_bar.py[line:272] - INFO: epoch 009:    444 / 990 loss=2.328, loss_v1=0, loss_v2=0, nll_loss=1.122, ntokens=1840.6, nsentences=56, sample_size=1840.6, sample_size_v1=0, sample_size_v2=0, ppl=2.18, wps=1074.5, ups=0.58, wpb=1840.6, bsz=56, num_updates=8350, lr=1.50907e-05, gnorm=2.501, clip=100, loss_scale=256, train_wall=17, gb_free=12.1, wall=14403
2023-06-27 20:18:45 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 128.0
2023-06-27 20:18:59 - progress_bar.py[line:272] - INFO: epoch 009:    455 / 990 loss=2.356, loss_v1=0, loss_v2=0, nll_loss=1.154, ntokens=1819, nsentences=56, sample_size=1819, sample_size_v1=0, sample_size_v2=0, ppl=2.23, wps=975.1, ups=0.54, wpb=1819, bsz=56, num_updates=8360, lr=1.50705e-05, gnorm=2.987, clip=100, loss_scale=128, train_wall=19, gb_free=12.2, wall=14422
2023-06-27 20:19:16 - progress_bar.py[line:272] - INFO: epoch 009:    465 / 990 loss=2.338, loss_v1=0, loss_v2=0, nll_loss=1.134, ntokens=1795.8, nsentences=56, sample_size=1795.8, sample_size_v1=0, sample_size_v2=0, ppl=2.19, wps=1051.5, ups=0.59, wpb=1795.8, bsz=56, num_updates=8370, lr=1.50504e-05, gnorm=2.584, clip=100, loss_scale=128, train_wall=17, gb_free=12.8, wall=14439
2023-06-27 20:19:33 - progress_bar.py[line:272] - INFO: epoch 009:    475 / 990 loss=2.325, loss_v1=0, loss_v2=0, nll_loss=1.119, ntokens=1888.6, nsentences=56, sample_size=1888.6, sample_size_v1=0, sample_size_v2=0, ppl=2.17, wps=1094.8, ups=0.58, wpb=1888.6, bsz=56, num_updates=8380, lr=1.50302e-05, gnorm=2.846, clip=100, loss_scale=128, train_wall=17, gb_free=13, wall=14456
2023-06-27 20:19:51 - progress_bar.py[line:272] - INFO: epoch 009:    485 / 990 loss=2.323, loss_v1=0, loss_v2=0, nll_loss=1.116, ntokens=1846.9, nsentences=56, sample_size=1846.9, sample_size_v1=0, sample_size_v2=0, ppl=2.17, wps=1073.9, ups=0.58, wpb=1846.9, bsz=56, num_updates=8390, lr=1.50101e-05, gnorm=2.494, clip=100, loss_scale=128, train_wall=17, gb_free=12.9, wall=14473
2023-06-27 20:20:08 - progress_bar.py[line:272] - INFO: epoch 009:    495 / 990 loss=2.331, loss_v1=0, loss_v2=0, nll_loss=1.127, ntokens=1853, nsentences=56, sample_size=1853, sample_size_v1=0, sample_size_v2=0, ppl=2.18, wps=1084.4, ups=0.59, wpb=1853, bsz=56, num_updates=8400, lr=1.49899e-05, gnorm=2.713, clip=100, loss_scale=128, train_wall=17, gb_free=12.9, wall=14490
2023-06-27 20:20:25 - progress_bar.py[line:272] - INFO: epoch 009:    505 / 990 loss=2.373, loss_v1=0, loss_v2=0, nll_loss=1.172, ntokens=1829.3, nsentences=56, sample_size=1829.3, sample_size_v1=0, sample_size_v2=0, ppl=2.25, wps=1068.6, ups=0.58, wpb=1829.3, bsz=56, num_updates=8410, lr=1.49698e-05, gnorm=2.902, clip=100, loss_scale=128, train_wall=17, gb_free=12, wall=14507
2023-06-27 20:20:42 - progress_bar.py[line:272] - INFO: epoch 009:    515 / 990 loss=2.348, loss_v1=0, loss_v2=0, nll_loss=1.145, ntokens=1720.8, nsentences=56, sample_size=1720.8, sample_size_v1=0, sample_size_v2=0, ppl=2.21, wps=1009.7, ups=0.59, wpb=1720.8, bsz=56, num_updates=8420, lr=1.49496e-05, gnorm=2.98, clip=100, loss_scale=128, train_wall=17, gb_free=13, wall=14524
2023-06-27 20:20:59 - progress_bar.py[line:272] - INFO: epoch 009:    525 / 990 loss=2.352, loss_v1=0, loss_v2=0, nll_loss=1.151, ntokens=1905.9, nsentences=56, sample_size=1905.9, sample_size_v1=0, sample_size_v2=0, ppl=2.22, wps=1111.3, ups=0.58, wpb=1905.9, bsz=56, num_updates=8430, lr=1.49295e-05, gnorm=2.618, clip=100, loss_scale=128, train_wall=17, gb_free=12.7, wall=14542
2023-06-27 20:21:16 - progress_bar.py[line:272] - INFO: epoch 009:    535 / 990 loss=2.333, loss_v1=0, loss_v2=0, nll_loss=1.125, ntokens=1893.8, nsentences=56, sample_size=1893.8, sample_size_v1=0, sample_size_v2=0, ppl=2.18, wps=1105.7, ups=0.58, wpb=1893.8, bsz=56, num_updates=8440, lr=1.49093e-05, gnorm=2.645, clip=100, loss_scale=128, train_wall=17, gb_free=12.4, wall=14559
2023-06-27 20:21:33 - progress_bar.py[line:272] - INFO: epoch 009:    545 / 990 loss=2.349, loss_v1=0, loss_v2=0, nll_loss=1.146, ntokens=1958, nsentences=56, sample_size=1958, sample_size_v1=0, sample_size_v2=0, ppl=2.21, wps=1144.7, ups=0.58, wpb=1958, bsz=56, num_updates=8450, lr=1.48892e-05, gnorm=2.66, clip=100, loss_scale=128, train_wall=17, gb_free=12.6, wall=14576
2023-06-27 20:21:50 - progress_bar.py[line:272] - INFO: epoch 009:    555 / 990 loss=2.334, loss_v1=0, loss_v2=0, nll_loss=1.13, ntokens=1836.4, nsentences=56, sample_size=1836.4, sample_size_v1=0, sample_size_v2=0, ppl=2.19, wps=1075.5, ups=0.59, wpb=1836.4, bsz=56, num_updates=8460, lr=1.4869e-05, gnorm=2.775, clip=100, loss_scale=128, train_wall=17, gb_free=12.9, wall=14593
2023-06-27 20:22:07 - progress_bar.py[line:272] - INFO: epoch 009:    565 / 990 loss=2.315, loss_v1=0, loss_v2=0, nll_loss=1.107, ntokens=1788.1, nsentences=56, sample_size=1788.1, sample_size_v1=0, sample_size_v2=0, ppl=2.15, wps=1047.5, ups=0.59, wpb=1788.1, bsz=56, num_updates=8470, lr=1.48489e-05, gnorm=2.919, clip=100, loss_scale=128, train_wall=17, gb_free=12.7, wall=14610
2023-06-27 20:22:24 - progress_bar.py[line:272] - INFO: epoch 009:    575 / 990 loss=2.347, loss_v1=0, loss_v2=0, nll_loss=1.145, ntokens=1841.8, nsentences=56, sample_size=1841.8, sample_size_v1=0, sample_size_v2=0, ppl=2.21, wps=1082.7, ups=0.59, wpb=1841.8, bsz=56, num_updates=8480, lr=1.48287e-05, gnorm=2.777, clip=100, loss_scale=128, train_wall=17, gb_free=12.8, wall=14627
2023-06-27 20:22:41 - progress_bar.py[line:272] - INFO: epoch 009:    585 / 990 loss=2.365, loss_v1=0, loss_v2=0, nll_loss=1.162, ntokens=1880.7, nsentences=56, sample_size=1880.7, sample_size_v1=0, sample_size_v2=0, ppl=2.24, wps=1102.4, ups=0.59, wpb=1880.7, bsz=56, num_updates=8490, lr=1.48086e-05, gnorm=2.932, clip=100, loss_scale=128, train_wall=17, gb_free=12.6, wall=14644
2023-06-27 20:22:58 - progress_bar.py[line:272] - INFO: epoch 009:    595 / 990 loss=2.331, loss_v1=0, loss_v2=0, nll_loss=1.126, ntokens=1899.2, nsentences=56, sample_size=1899.2, sample_size_v1=0, sample_size_v2=0, ppl=2.18, wps=1111.2, ups=0.59, wpb=1899.2, bsz=56, num_updates=8500, lr=1.47884e-05, gnorm=2.565, clip=100, loss_scale=128, train_wall=17, gb_free=12.8, wall=14661
2023-06-27 20:23:16 - progress_bar.py[line:272] - INFO: epoch 009:    605 / 990 loss=2.344, loss_v1=0, loss_v2=0, nll_loss=1.142, ntokens=1726.9, nsentences=56, sample_size=1726.9, sample_size_v1=0, sample_size_v2=0, ppl=2.21, wps=1014.8, ups=0.59, wpb=1726.9, bsz=56, num_updates=8510, lr=1.47683e-05, gnorm=2.922, clip=100, loss_scale=128, train_wall=17, gb_free=12.6, wall=14678
2023-06-27 20:23:33 - progress_bar.py[line:272] - INFO: epoch 009:    615 / 990 loss=2.328, loss_v1=0, loss_v2=0, nll_loss=1.12, ntokens=1854.5, nsentences=56, sample_size=1854.5, sample_size_v1=0, sample_size_v2=0, ppl=2.17, wps=1087.4, ups=0.59, wpb=1854.5, bsz=56, num_updates=8520, lr=1.47482e-05, gnorm=2.908, clip=100, loss_scale=128, train_wall=17, gb_free=12.5, wall=14695
2023-06-27 20:23:50 - progress_bar.py[line:272] - INFO: epoch 009:    625 / 990 loss=2.356, loss_v1=0, loss_v2=0, nll_loss=1.153, ntokens=2030.1, nsentences=56, sample_size=2030.1, sample_size_v1=0, sample_size_v2=0, ppl=2.22, wps=1186.1, ups=0.58, wpb=2030.1, bsz=56, num_updates=8530, lr=1.4728e-05, gnorm=2.521, clip=100, loss_scale=128, train_wall=17, gb_free=12.6, wall=14712
2023-06-27 20:24:07 - progress_bar.py[line:272] - INFO: epoch 009:    635 / 990 loss=2.36, loss_v1=0, loss_v2=0, nll_loss=1.159, ntokens=2005.1, nsentences=56, sample_size=2005.1, sample_size_v1=0, sample_size_v2=0, ppl=2.23, wps=1164.6, ups=0.58, wpb=2005.1, bsz=56, num_updates=8540, lr=1.47079e-05, gnorm=2.686, clip=100, loss_scale=128, train_wall=17, gb_free=12.8, wall=14730
2023-06-27 20:24:24 - progress_bar.py[line:272] - INFO: epoch 009:    645 / 990 loss=2.342, loss_v1=0, loss_v2=0, nll_loss=1.139, ntokens=1999.9, nsentences=56, sample_size=1999.9, sample_size_v1=0, sample_size_v2=0, ppl=2.2, wps=1163.7, ups=0.58, wpb=1999.9, bsz=56, num_updates=8550, lr=1.46877e-05, gnorm=2.603, clip=100, loss_scale=128, train_wall=17, gb_free=12.1, wall=14747
2023-06-27 20:24:41 - progress_bar.py[line:272] - INFO: epoch 009:    655 / 990 loss=2.349, loss_v1=0, loss_v2=0, nll_loss=1.145, ntokens=1916.2, nsentences=56, sample_size=1916.2, sample_size_v1=0, sample_size_v2=0, ppl=2.21, wps=1117.6, ups=0.58, wpb=1916.2, bsz=56, num_updates=8560, lr=1.46676e-05, gnorm=2.704, clip=100, loss_scale=128, train_wall=17, gb_free=12.2, wall=14764
2023-06-27 20:24:58 - progress_bar.py[line:272] - INFO: epoch 009:    665 / 990 loss=2.343, loss_v1=0, loss_v2=0, nll_loss=1.138, ntokens=1866.1, nsentences=56, sample_size=1866.1, sample_size_v1=0, sample_size_v2=0, ppl=2.2, wps=1093.5, ups=0.59, wpb=1866.1, bsz=56, num_updates=8570, lr=1.46474e-05, gnorm=2.793, clip=100, loss_scale=128, train_wall=17, gb_free=12.7, wall=14781
2023-06-27 20:25:15 - progress_bar.py[line:272] - INFO: epoch 009:    675 / 990 loss=2.353, loss_v1=0, loss_v2=0, nll_loss=1.151, ntokens=1768.2, nsentences=56, sample_size=1768.2, sample_size_v1=0, sample_size_v2=0, ppl=2.22, wps=1036.5, ups=0.59, wpb=1768.2, bsz=56, num_updates=8580, lr=1.46273e-05, gnorm=3.152, clip=100, loss_scale=128, train_wall=17, gb_free=12.9, wall=14798
2023-06-27 20:25:33 - progress_bar.py[line:272] - INFO: epoch 009:    685 / 990 loss=2.286, loss_v1=0, loss_v2=0, nll_loss=1.076, ntokens=1911.4, nsentences=56, sample_size=1911.4, sample_size_v1=0, sample_size_v2=0, ppl=2.11, wps=1112.3, ups=0.58, wpb=1911.4, bsz=56, num_updates=8590, lr=1.46071e-05, gnorm=2.571, clip=100, loss_scale=128, train_wall=17, gb_free=12.6, wall=14815
2023-06-27 20:25:50 - progress_bar.py[line:272] - INFO: epoch 009:    695 / 990 loss=2.339, loss_v1=0, loss_v2=0, nll_loss=1.136, ntokens=1738.9, nsentences=56, sample_size=1738.9, sample_size_v1=0, sample_size_v2=0, ppl=2.2, wps=1020.1, ups=0.59, wpb=1738.9, bsz=56, num_updates=8600, lr=1.4587e-05, gnorm=2.823, clip=100, loss_scale=128, train_wall=17, gb_free=12.9, wall=14832
2023-06-27 20:26:07 - progress_bar.py[line:272] - INFO: epoch 009:    705 / 990 loss=2.359, loss_v1=0, loss_v2=0, nll_loss=1.154, ntokens=1723, nsentences=56, sample_size=1723, sample_size_v1=0, sample_size_v2=0, ppl=2.23, wps=1009.2, ups=0.59, wpb=1723, bsz=56, num_updates=8610, lr=1.45668e-05, gnorm=3.128, clip=100, loss_scale=128, train_wall=17, gb_free=12.6, wall=14849
2023-06-27 20:26:24 - progress_bar.py[line:272] - INFO: epoch 009:    715 / 990 loss=2.339, loss_v1=0, loss_v2=0, nll_loss=1.135, ntokens=1807.7, nsentences=56, sample_size=1807.7, sample_size_v1=0, sample_size_v2=0, ppl=2.2, wps=1061.4, ups=0.59, wpb=1807.7, bsz=56, num_updates=8620, lr=1.45467e-05, gnorm=3, clip=100, loss_scale=128, train_wall=17, gb_free=12.6, wall=14866
2023-06-27 20:26:41 - progress_bar.py[line:272] - INFO: epoch 009:    725 / 990 loss=2.327, loss_v1=0, loss_v2=0, nll_loss=1.121, ntokens=1765.3, nsentences=56, sample_size=1765.3, sample_size_v1=0, sample_size_v2=0, ppl=2.18, wps=1039, ups=0.59, wpb=1765.3, bsz=56, num_updates=8630, lr=1.45265e-05, gnorm=2.894, clip=100, loss_scale=128, train_wall=17, gb_free=13.1, wall=14883
2023-06-27 20:26:58 - progress_bar.py[line:272] - INFO: epoch 009:    735 / 990 loss=2.316, loss_v1=0, loss_v2=0, nll_loss=1.108, ntokens=1849.9, nsentences=56, sample_size=1849.9, sample_size_v1=0, sample_size_v2=0, ppl=2.16, wps=1083.3, ups=0.59, wpb=1849.9, bsz=56, num_updates=8640, lr=1.45064e-05, gnorm=2.546, clip=100, loss_scale=128, train_wall=17, gb_free=13, wall=14900
2023-06-27 20:27:15 - progress_bar.py[line:272] - INFO: epoch 009:    745 / 990 loss=2.351, loss_v1=0, loss_v2=0, nll_loss=1.147, ntokens=1743.8, nsentences=56, sample_size=1743.8, sample_size_v1=0, sample_size_v2=0, ppl=2.21, wps=1022.4, ups=0.59, wpb=1743.8, bsz=56, num_updates=8650, lr=1.44862e-05, gnorm=2.843, clip=100, loss_scale=128, train_wall=17, gb_free=13.3, wall=14918
2023-06-27 20:27:32 - progress_bar.py[line:272] - INFO: epoch 009:    755 / 990 loss=2.37, loss_v1=0, loss_v2=0, nll_loss=1.171, ntokens=1670.3, nsentences=56, sample_size=1670.3, sample_size_v1=0, sample_size_v2=0, ppl=2.25, wps=984.6, ups=0.59, wpb=1670.3, bsz=56, num_updates=8660, lr=1.44661e-05, gnorm=2.919, clip=100, loss_scale=128, train_wall=17, gb_free=13.2, wall=14935
2023-06-27 20:27:49 - progress_bar.py[line:272] - INFO: epoch 009:    765 / 990 loss=2.339, loss_v1=0, loss_v2=0, nll_loss=1.133, ntokens=1746.4, nsentences=56, sample_size=1746.4, sample_size_v1=0, sample_size_v2=0, ppl=2.19, wps=1026.2, ups=0.59, wpb=1746.4, bsz=56, num_updates=8670, lr=1.44459e-05, gnorm=2.892, clip=100, loss_scale=128, train_wall=17, gb_free=13, wall=14952
2023-06-27 20:28:06 - progress_bar.py[line:272] - INFO: epoch 009:    775 / 990 loss=2.338, loss_v1=0, loss_v2=0, nll_loss=1.133, ntokens=1857, nsentences=56, sample_size=1857, sample_size_v1=0, sample_size_v2=0, ppl=2.19, wps=1084.8, ups=0.58, wpb=1857, bsz=56, num_updates=8680, lr=1.44258e-05, gnorm=2.833, clip=100, loss_scale=128, train_wall=17, gb_free=12.8, wall=14969
2023-06-27 20:28:23 - progress_bar.py[line:272] - INFO: epoch 009:    785 / 990 loss=2.336, loss_v1=0, loss_v2=0, nll_loss=1.132, ntokens=1747.4, nsentences=56, sample_size=1747.4, sample_size_v1=0, sample_size_v2=0, ppl=2.19, wps=1028.9, ups=0.59, wpb=1747.4, bsz=56, num_updates=8690, lr=1.44056e-05, gnorm=3.132, clip=100, loss_scale=128, train_wall=17, gb_free=12.4, wall=14986
2023-06-27 20:28:40 - progress_bar.py[line:272] - INFO: epoch 009:    795 / 990 loss=2.342, loss_v1=0, loss_v2=0, nll_loss=1.139, ntokens=1857.3, nsentences=56, sample_size=1857.3, sample_size_v1=0, sample_size_v2=0, ppl=2.2, wps=1083.6, ups=0.58, wpb=1857.3, bsz=56, num_updates=8700, lr=1.43855e-05, gnorm=2.756, clip=100, loss_scale=128, train_wall=17, gb_free=12.9, wall=15003
2023-06-27 20:28:57 - progress_bar.py[line:272] - INFO: epoch 009:    805 / 990 loss=2.342, loss_v1=0, loss_v2=0, nll_loss=1.136, ntokens=1765, nsentences=56, sample_size=1765, sample_size_v1=0, sample_size_v2=0, ppl=2.2, wps=1033.1, ups=0.59, wpb=1765, bsz=56, num_updates=8710, lr=1.43653e-05, gnorm=2.751, clip=100, loss_scale=128, train_wall=17, gb_free=13, wall=15020
2023-06-27 20:29:14 - progress_bar.py[line:272] - INFO: epoch 009:    815 / 990 loss=2.353, loss_v1=0, loss_v2=0, nll_loss=1.152, ntokens=1642.6, nsentences=56, sample_size=1642.6, sample_size_v1=0, sample_size_v2=0, ppl=2.22, wps=969, ups=0.59, wpb=1642.6, bsz=56, num_updates=8720, lr=1.43452e-05, gnorm=3.148, clip=100, loss_scale=128, train_wall=17, gb_free=12.8, wall=15037
2023-06-27 20:29:31 - progress_bar.py[line:272] - INFO: epoch 009:    825 / 990 loss=2.332, loss_v1=0, loss_v2=0, nll_loss=1.129, ntokens=1720.2, nsentences=56, sample_size=1720.2, sample_size_v1=0, sample_size_v2=0, ppl=2.19, wps=996.7, ups=0.58, wpb=1720.2, bsz=56, num_updates=8730, lr=1.43251e-05, gnorm=2.962, clip=100, loss_scale=128, train_wall=17, gb_free=12.9, wall=15054
2023-06-27 20:29:48 - progress_bar.py[line:272] - INFO: epoch 009:    835 / 990 loss=2.315, loss_v1=0, loss_v2=0, nll_loss=1.108, ntokens=1750.5, nsentences=56, sample_size=1750.5, sample_size_v1=0, sample_size_v2=0, ppl=2.16, wps=1031.9, ups=0.59, wpb=1750.5, bsz=56, num_updates=8740, lr=1.43049e-05, gnorm=2.79, clip=100, loss_scale=128, train_wall=17, gb_free=13.2, wall=15071
2023-06-27 20:30:05 - progress_bar.py[line:272] - INFO: epoch 009:    845 / 990 loss=2.326, loss_v1=0, loss_v2=0, nll_loss=1.12, ntokens=1877.1, nsentences=56, sample_size=1877.1, sample_size_v1=0, sample_size_v2=0, ppl=2.17, wps=1098.6, ups=0.59, wpb=1877.1, bsz=56, num_updates=8750, lr=1.42848e-05, gnorm=2.711, clip=100, loss_scale=128, train_wall=17, gb_free=12.8, wall=15088
2023-06-27 20:30:23 - progress_bar.py[line:272] - INFO: epoch 009:    855 / 990 loss=2.305, loss_v1=0, loss_v2=0, nll_loss=1.095, ntokens=1886, nsentences=56, sample_size=1886, sample_size_v1=0, sample_size_v2=0, ppl=2.14, wps=1098.8, ups=0.58, wpb=1886, bsz=56, num_updates=8760, lr=1.42646e-05, gnorm=2.662, clip=100, loss_scale=128, train_wall=17, gb_free=12.7, wall=15105
2023-06-27 20:30:40 - progress_bar.py[line:272] - INFO: epoch 009:    865 / 990 loss=2.316, loss_v1=0, loss_v2=0, nll_loss=1.11, ntokens=1805.6, nsentences=56, sample_size=1805.6, sample_size_v1=0, sample_size_v2=0, ppl=2.16, wps=1060.3, ups=0.59, wpb=1805.6, bsz=56, num_updates=8770, lr=1.42445e-05, gnorm=2.708, clip=100, loss_scale=128, train_wall=17, gb_free=12.6, wall=15122
2023-06-27 20:30:57 - progress_bar.py[line:272] - INFO: epoch 009:    875 / 990 loss=2.322, loss_v1=0, loss_v2=0, nll_loss=1.117, ntokens=1858.2, nsentences=56, sample_size=1858.2, sample_size_v1=0, sample_size_v2=0, ppl=2.17, wps=1086.3, ups=0.58, wpb=1858.2, bsz=56, num_updates=8780, lr=1.42243e-05, gnorm=2.665, clip=100, loss_scale=128, train_wall=17, gb_free=12.7, wall=15139
2023-06-27 20:31:14 - progress_bar.py[line:272] - INFO: epoch 009:    885 / 990 loss=2.317, loss_v1=0, loss_v2=0, nll_loss=1.109, ntokens=1916.4, nsentences=56, sample_size=1916.4, sample_size_v1=0, sample_size_v2=0, ppl=2.16, wps=1123.5, ups=0.59, wpb=1916.4, bsz=56, num_updates=8790, lr=1.42042e-05, gnorm=2.876, clip=100, loss_scale=128, train_wall=17, gb_free=12.5, wall=15157
2023-06-27 20:31:31 - progress_bar.py[line:272] - INFO: epoch 009:    895 / 990 loss=2.321, loss_v1=0, loss_v2=0, nll_loss=1.114, ntokens=1930, nsentences=56, sample_size=1930, sample_size_v1=0, sample_size_v2=0, ppl=2.17, wps=1127.9, ups=0.58, wpb=1930, bsz=56, num_updates=8800, lr=1.4184e-05, gnorm=2.696, clip=100, loss_scale=128, train_wall=17, gb_free=12.7, wall=15174
2023-06-27 20:31:48 - progress_bar.py[line:272] - INFO: epoch 009:    905 / 990 loss=2.348, loss_v1=0, loss_v2=0, nll_loss=1.146, ntokens=1740.4, nsentences=56, sample_size=1740.4, sample_size_v1=0, sample_size_v2=0, ppl=2.21, wps=1021.2, ups=0.59, wpb=1740.4, bsz=56, num_updates=8810, lr=1.41639e-05, gnorm=3.049, clip=100, loss_scale=128, train_wall=17, gb_free=13, wall=15191
2023-06-27 20:32:05 - progress_bar.py[line:272] - INFO: epoch 009:    915 / 990 loss=2.336, loss_v1=0, loss_v2=0, nll_loss=1.131, ntokens=1766.6, nsentences=56, sample_size=1766.6, sample_size_v1=0, sample_size_v2=0, ppl=2.19, wps=1041.3, ups=0.59, wpb=1766.6, bsz=56, num_updates=8820, lr=1.41437e-05, gnorm=2.905, clip=100, loss_scale=128, train_wall=17, gb_free=12.8, wall=15208
2023-06-27 20:32:22 - progress_bar.py[line:272] - INFO: epoch 009:    925 / 990 loss=2.303, loss_v1=0, loss_v2=0, nll_loss=1.095, ntokens=1796.5, nsentences=56, sample_size=1796.5, sample_size_v1=0, sample_size_v2=0, ppl=2.14, wps=1050.1, ups=0.58, wpb=1796.5, bsz=56, num_updates=8830, lr=1.41236e-05, gnorm=3.026, clip=100, loss_scale=128, train_wall=17, gb_free=12.7, wall=15225
2023-06-27 20:32:39 - progress_bar.py[line:272] - INFO: epoch 009:    935 / 990 loss=2.314, loss_v1=0, loss_v2=0, nll_loss=1.106, ntokens=1813.3, nsentences=56, sample_size=1813.3, sample_size_v1=0, sample_size_v2=0, ppl=2.15, wps=1062.6, ups=0.59, wpb=1813.3, bsz=56, num_updates=8840, lr=1.41034e-05, gnorm=2.784, clip=100, loss_scale=128, train_wall=17, gb_free=12.8, wall=15242
2023-06-27 20:32:56 - progress_bar.py[line:272] - INFO: epoch 009:    945 / 990 loss=2.314, loss_v1=0, loss_v2=0, nll_loss=1.106, ntokens=1927.8, nsentences=56, sample_size=1927.8, sample_size_v1=0, sample_size_v2=0, ppl=2.15, wps=1121.6, ups=0.58, wpb=1927.8, bsz=56, num_updates=8850, lr=1.40833e-05, gnorm=2.686, clip=100, loss_scale=128, train_wall=17, gb_free=13.1, wall=15259
2023-06-27 20:33:13 - progress_bar.py[line:272] - INFO: epoch 009:    955 / 990 loss=2.327, loss_v1=0, loss_v2=0, nll_loss=1.122, ntokens=1899.8, nsentences=56, sample_size=1899.8, sample_size_v1=0, sample_size_v2=0, ppl=2.18, wps=1111.6, ups=0.59, wpb=1899.8, bsz=56, num_updates=8860, lr=1.40631e-05, gnorm=2.845, clip=100, loss_scale=128, train_wall=17, gb_free=13, wall=15276
2023-06-27 20:33:31 - progress_bar.py[line:272] - INFO: epoch 009:    965 / 990 loss=2.325, loss_v1=0, loss_v2=0, nll_loss=1.119, ntokens=1895.8, nsentences=56, sample_size=1895.8, sample_size_v1=0, sample_size_v2=0, ppl=2.17, wps=1104, ups=0.58, wpb=1895.8, bsz=56, num_updates=8870, lr=1.4043e-05, gnorm=2.802, clip=100, loss_scale=256, train_wall=17, gb_free=12.6, wall=15293
2023-06-27 20:33:36 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 128.0
2023-06-27 20:33:49 - progress_bar.py[line:272] - INFO: epoch 009:    976 / 990 loss=2.314, loss_v1=0, loss_v2=0, nll_loss=1.109, ntokens=1910, nsentences=56, sample_size=1910, sample_size_v1=0, sample_size_v2=0, ppl=2.16, wps=1015.5, ups=0.53, wpb=1910, bsz=56, num_updates=8880, lr=1.40228e-05, gnorm=2.841, clip=100, loss_scale=128, train_wall=19, gb_free=12.7, wall=15312
2023-06-27 20:34:06 - progress_bar.py[line:272] - INFO: epoch 009:    986 / 990 loss=2.348, loss_v1=0, loss_v2=0, nll_loss=1.144, ntokens=1789.1, nsentences=56, sample_size=1789.1, sample_size_v1=0, sample_size_v2=0, ppl=2.21, wps=1051.4, ups=0.59, wpb=1789.1, bsz=56, num_updates=8890, lr=1.40027e-05, gnorm=2.99, clip=100, loss_scale=128, train_wall=17, gb_free=12.9, wall=15329
local datafile ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 1 begin to initialize row_count and line_idx-to-offset mapping
2023-06-27 20:34:12 - train.py[line:332] - INFO: end of epoch 9 (average epoch stats below)
2023-06-27 20:34:12 - progress_bar.py[line:282] - INFO: epoch 009 | loss 2.321 | loss_v1 0 | loss_v2 0 | nll_loss 1.115 | ntokens 1850.14 | nsentences 55.96 | sample_size 1850.14 | sample_size_v1 0 | sample_size_v2 0 | ppl 2.17 | wps 1075.6 | ups 0.58 | wpb 1850.1 | bsz 56 | num_updates 8894 | lr 1.39946e-05 | gnorm 2.719 | clip 100 | loss_scale 128 | train_wall 1694 | gb_free 13.3 | wall 15335
2023-06-27 20:34:12 - trainer.py[line:639] - INFO: loading train data for epoch 10
local datafile ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 0 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 1 finished initializing row_count and line_idx-to-offset mapping
file ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 1 row count 27700 total row count 55400
slice_id 1 seek offset 27700
local datafile ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 0 finished initializing row_count and line_idx-to-offset mapping
file ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 0 row count 27700 total row count 55400
slice_id 0 seek offset 0
2023-06-27 20:34:14 - trainer.py[line:703] - INFO: begin training epoch 10
2023-06-27 20:34:14 - train.py[line:305] - INFO: Start iterating over samples
2023-06-27 20:34:25 - progress_bar.py[line:272] - INFO: epoch 010:      6 / 990 loss=2.31, loss_v1=0, loss_v2=0, nll_loss=1.103, ntokens=1797.7, nsentences=53.2, sample_size=1797.7, sample_size_v1=0, sample_size_v2=0, ppl=2.15, wps=962.6, ups=0.54, wpb=1797.7, bsz=53.2, num_updates=8900, lr=1.39825e-05, gnorm=3.078, clip=100, loss_scale=128, train_wall=16, gb_free=12.5, wall=15348
2023-06-27 20:34:42 - progress_bar.py[line:272] - INFO: epoch 010:     16 / 990 loss=2.287, loss_v1=0, loss_v2=0, nll_loss=1.077, ntokens=1823.1, nsentences=56, sample_size=1823.1, sample_size_v1=0, sample_size_v2=0, ppl=2.11, wps=1055.1, ups=0.58, wpb=1823.1, bsz=56, num_updates=8910, lr=1.39624e-05, gnorm=2.875, clip=100, loss_scale=128, train_wall=17, gb_free=12, wall=15365
2023-06-27 20:35:00 - progress_bar.py[line:272] - INFO: epoch 010:     26 / 990 loss=2.248, loss_v1=0, loss_v2=0, nll_loss=1.033, ntokens=1790.4, nsentences=56, sample_size=1790.4, sample_size_v1=0, sample_size_v2=0, ppl=2.05, wps=1043.5, ups=0.58, wpb=1790.4, bsz=56, num_updates=8920, lr=1.39422e-05, gnorm=2.825, clip=100, loss_scale=128, train_wall=17, gb_free=12.9, wall=15382
2023-06-27 20:35:17 - progress_bar.py[line:272] - INFO: epoch 010:     36 / 990 loss=2.259, loss_v1=0, loss_v2=0, nll_loss=1.045, ntokens=1793.5, nsentences=56, sample_size=1793.5, sample_size_v1=0, sample_size_v2=0, ppl=2.06, wps=1049.3, ups=0.59, wpb=1793.5, bsz=56, num_updates=8930, lr=1.39221e-05, gnorm=2.92, clip=100, loss_scale=128, train_wall=17, gb_free=12.5, wall=15399
2023-06-27 20:35:34 - progress_bar.py[line:272] - INFO: epoch 010:     46 / 990 loss=2.188, loss_v1=0, loss_v2=0, nll_loss=0.968, ntokens=1977.1, nsentences=56, sample_size=1977.1, sample_size_v1=0, sample_size_v2=0, ppl=1.96, wps=1134.3, ups=0.57, wpb=1977.1, bsz=56, num_updates=8940, lr=1.39019e-05, gnorm=2.431, clip=100, loss_scale=128, train_wall=17, gb_free=12.6, wall=15417
2023-06-27 20:35:51 - progress_bar.py[line:272] - INFO: epoch 010:     56 / 990 loss=2.281, loss_v1=0, loss_v2=0, nll_loss=1.068, ntokens=1753.7, nsentences=56, sample_size=1753.7, sample_size_v1=0, sample_size_v2=0, ppl=2.1, wps=1018.4, ups=0.58, wpb=1753.7, bsz=56, num_updates=8950, lr=1.38818e-05, gnorm=2.963, clip=100, loss_scale=128, train_wall=17, gb_free=11.9, wall=15434
2023-06-27 20:36:08 - progress_bar.py[line:272] - INFO: epoch 010:     66 / 990 loss=2.178, loss_v1=0, loss_v2=0, nll_loss=0.956, ntokens=1771.6, nsentences=56, sample_size=1771.6, sample_size_v1=0, sample_size_v2=0, ppl=1.94, wps=1035, ups=0.58, wpb=1771.6, bsz=56, num_updates=8960, lr=1.38617e-05, gnorm=2.894, clip=100, loss_scale=128, train_wall=17, gb_free=12.6, wall=15451
2023-06-27 20:36:26 - progress_bar.py[line:272] - INFO: epoch 010:     76 / 990 loss=2.128, loss_v1=0, loss_v2=0, nll_loss=0.898, ntokens=2157.8, nsentences=56, sample_size=2157.8, sample_size_v1=0, sample_size_v2=0, ppl=1.86, wps=1219, ups=0.56, wpb=2157.8, bsz=56, num_updates=8970, lr=1.38415e-05, gnorm=2.307, clip=100, loss_scale=128, train_wall=18, gb_free=11.3, wall=15469
2023-06-27 20:36:44 - progress_bar.py[line:272] - INFO: epoch 010:     86 / 990 loss=2.206, loss_v1=0, loss_v2=0, nll_loss=0.986, ntokens=2145.4, nsentences=56, sample_size=2145.4, sample_size_v1=0, sample_size_v2=0, ppl=1.98, wps=1211.7, ups=0.56, wpb=2145.4, bsz=56, num_updates=8980, lr=1.38214e-05, gnorm=2.524, clip=100, loss_scale=128, train_wall=18, gb_free=11.4, wall=15487
2023-06-27 20:37:01 - progress_bar.py[line:272] - INFO: epoch 010:     96 / 990 loss=2.242, loss_v1=0, loss_v2=0, nll_loss=1.026, ntokens=1944, nsentences=56, sample_size=1944, sample_size_v1=0, sample_size_v2=0, ppl=2.04, wps=1114.5, ups=0.57, wpb=1944, bsz=56, num_updates=8990, lr=1.38012e-05, gnorm=2.899, clip=100, loss_scale=128, train_wall=17, gb_free=11.7, wall=15504
2023-06-27 20:37:19 - progress_bar.py[line:272] - INFO: epoch 010:    106 / 990 loss=2.217, loss_v1=0, loss_v2=0, nll_loss=0.999, ntokens=1925.1, nsentences=56, sample_size=1925.1, sample_size_v1=0, sample_size_v2=0, ppl=2, wps=1114.2, ups=0.58, wpb=1925.1, bsz=56, num_updates=9000, lr=1.37811e-05, gnorm=2.548, clip=100, loss_scale=128, train_wall=17, gb_free=12, wall=15521
2023-06-27 20:37:36 - progress_bar.py[line:272] - INFO: epoch 010:    116 / 990 loss=2.307, loss_v1=0, loss_v2=0, nll_loss=1.098, ntokens=1750.2, nsentences=56, sample_size=1750.2, sample_size_v1=0, sample_size_v2=0, ppl=2.14, wps=1020.8, ups=0.58, wpb=1750.2, bsz=56, num_updates=9010, lr=1.37609e-05, gnorm=2.961, clip=100, loss_scale=128, train_wall=17, gb_free=12.4, wall=15538
2023-06-27 20:37:53 - progress_bar.py[line:272] - INFO: epoch 010:    126 / 990 loss=2.325, loss_v1=0, loss_v2=0, nll_loss=1.121, ntokens=1812.3, nsentences=56, sample_size=1812.3, sample_size_v1=0, sample_size_v2=0, ppl=2.18, wps=1056.5, ups=0.58, wpb=1812.3, bsz=56, num_updates=9020, lr=1.37408e-05, gnorm=2.984, clip=100, loss_scale=128, train_wall=17, gb_free=12.2, wall=15556
2023-06-27 20:38:10 - progress_bar.py[line:272] - INFO: epoch 010:    136 / 990 loss=2.302, loss_v1=0, loss_v2=0, nll_loss=1.091, ntokens=1884.6, nsentences=56, sample_size=1884.6, sample_size_v1=0, sample_size_v2=0, ppl=2.13, wps=1083, ups=0.57, wpb=1884.6, bsz=56, num_updates=9030, lr=1.37206e-05, gnorm=2.799, clip=100, loss_scale=128, train_wall=17, gb_free=11.1, wall=15573
2023-06-27 20:38:28 - progress_bar.py[line:272] - INFO: epoch 010:    146 / 990 loss=2.309, loss_v1=0, loss_v2=0, nll_loss=1.1, ntokens=1945.2, nsentences=56, sample_size=1945.2, sample_size_v1=0, sample_size_v2=0, ppl=2.14, wps=1113.2, ups=0.57, wpb=1945.2, bsz=56, num_updates=9040, lr=1.37005e-05, gnorm=2.801, clip=100, loss_scale=128, train_wall=17, gb_free=12.7, wall=15590
2023-06-27 20:38:45 - progress_bar.py[line:272] - INFO: epoch 010:    156 / 990 loss=2.275, loss_v1=0, loss_v2=0, nll_loss=1.063, ntokens=1970.4, nsentences=56, sample_size=1970.4, sample_size_v1=0, sample_size_v2=0, ppl=2.09, wps=1124.2, ups=0.57, wpb=1970.4, bsz=56, num_updates=9050, lr=1.36803e-05, gnorm=2.584, clip=100, loss_scale=128, train_wall=17, gb_free=12, wall=15608
2023-06-27 20:39:03 - progress_bar.py[line:272] - INFO: epoch 010:    166 / 990 loss=2.266, loss_v1=0, loss_v2=0, nll_loss=1.054, ntokens=1946, nsentences=56, sample_size=1946, sample_size_v1=0, sample_size_v2=0, ppl=2.08, wps=1115, ups=0.57, wpb=1946, bsz=56, num_updates=9060, lr=1.36602e-05, gnorm=2.615, clip=100, loss_scale=128, train_wall=17, gb_free=12.2, wall=15625
2023-06-27 20:39:20 - progress_bar.py[line:272] - INFO: epoch 010:    176 / 990 loss=2.272, loss_v1=0, loss_v2=0, nll_loss=1.06, ntokens=1974.8, nsentences=56, sample_size=1974.8, sample_size_v1=0, sample_size_v2=0, ppl=2.09, wps=1130, ups=0.57, wpb=1974.8, bsz=56, num_updates=9070, lr=1.364e-05, gnorm=2.661, clip=100, loss_scale=128, train_wall=17, gb_free=12.1, wall=15643
2023-06-27 20:39:38 - progress_bar.py[line:272] - INFO: epoch 010:    186 / 990 loss=2.277, loss_v1=0, loss_v2=0, nll_loss=1.065, ntokens=1876.2, nsentences=56, sample_size=1876.2, sample_size_v1=0, sample_size_v2=0, ppl=2.09, wps=1085.7, ups=0.58, wpb=1876.2, bsz=56, num_updates=9080, lr=1.36199e-05, gnorm=2.795, clip=100, loss_scale=128, train_wall=17, gb_free=13.1, wall=15660
2023-06-27 20:39:55 - progress_bar.py[line:272] - INFO: epoch 010:    196 / 990 loss=2.289, loss_v1=0, loss_v2=0, nll_loss=1.08, ntokens=1830.9, nsentences=56, sample_size=1830.9, sample_size_v1=0, sample_size_v2=0, ppl=2.11, wps=1056.3, ups=0.58, wpb=1830.9, bsz=56, num_updates=9090, lr=1.35997e-05, gnorm=2.9, clip=100, loss_scale=128, train_wall=17, gb_free=12.4, wall=15678
2023-06-27 20:40:12 - progress_bar.py[line:272] - INFO: epoch 010:    206 / 990 loss=2.252, loss_v1=0, loss_v2=0, nll_loss=1.035, ntokens=1898.5, nsentences=56, sample_size=1898.5, sample_size_v1=0, sample_size_v2=0, ppl=2.05, wps=1091.4, ups=0.57, wpb=1898.5, bsz=56, num_updates=9100, lr=1.35796e-05, gnorm=2.898, clip=100, loss_scale=128, train_wall=17, gb_free=12.1, wall=15695
2023-06-27 20:40:30 - progress_bar.py[line:272] - INFO: epoch 010:    216 / 990 loss=2.28, loss_v1=0, loss_v2=0, nll_loss=1.069, ntokens=1940.5, nsentences=56, sample_size=1940.5, sample_size_v1=0, sample_size_v2=0, ppl=2.1, wps=1116, ups=0.58, wpb=1940.5, bsz=56, num_updates=9110, lr=1.35594e-05, gnorm=2.643, clip=100, loss_scale=128, train_wall=17, gb_free=12.7, wall=15712
2023-06-27 20:40:47 - progress_bar.py[line:272] - INFO: epoch 010:    226 / 990 loss=2.282, loss_v1=0, loss_v2=0, nll_loss=1.07, ntokens=1928.3, nsentences=56, sample_size=1928.3, sample_size_v1=0, sample_size_v2=0, ppl=2.1, wps=1108.5, ups=0.57, wpb=1928.3, bsz=56, num_updates=9120, lr=1.35393e-05, gnorm=2.624, clip=100, loss_scale=128, train_wall=17, gb_free=12.3, wall=15730
2023-06-27 20:41:04 - progress_bar.py[line:272] - INFO: epoch 010:    236 / 990 loss=2.327, loss_v1=0, loss_v2=0, nll_loss=1.122, ntokens=1689.4, nsentences=56, sample_size=1689.4, sample_size_v1=0, sample_size_v2=0, ppl=2.18, wps=988.1, ups=0.58, wpb=1689.4, bsz=56, num_updates=9130, lr=1.35191e-05, gnorm=2.897, clip=100, loss_scale=128, train_wall=17, gb_free=13.3, wall=15747
2023-06-27 20:41:21 - progress_bar.py[line:272] - INFO: epoch 010:    246 / 990 loss=2.333, loss_v1=0, loss_v2=0, nll_loss=1.129, ntokens=1922.3, nsentences=56, sample_size=1922.3, sample_size_v1=0, sample_size_v2=0, ppl=2.19, wps=1113.5, ups=0.58, wpb=1922.3, bsz=56, num_updates=9140, lr=1.3499e-05, gnorm=2.75, clip=100, loss_scale=128, train_wall=17, gb_free=11.9, wall=15764
2023-06-27 20:41:39 - progress_bar.py[line:272] - INFO: epoch 010:    256 / 990 loss=2.331, loss_v1=0, loss_v2=0, nll_loss=1.126, ntokens=1899.1, nsentences=56, sample_size=1899.1, sample_size_v1=0, sample_size_v2=0, ppl=2.18, wps=1106.9, ups=0.58, wpb=1899.1, bsz=56, num_updates=9150, lr=1.34788e-05, gnorm=2.769, clip=100, loss_scale=128, train_wall=17, gb_free=12.6, wall=15781
2023-06-27 20:41:56 - progress_bar.py[line:272] - INFO: epoch 010:    266 / 990 loss=2.355, loss_v1=0, loss_v2=0, nll_loss=1.152, ntokens=1876.3, nsentences=56, sample_size=1876.3, sample_size_v1=0, sample_size_v2=0, ppl=2.22, wps=1080, ups=0.58, wpb=1876.3, bsz=56, num_updates=9160, lr=1.34587e-05, gnorm=2.808, clip=100, loss_scale=128, train_wall=17, gb_free=13.1, wall=15799
2023-06-27 20:42:13 - progress_bar.py[line:272] - INFO: epoch 010:    276 / 990 loss=2.338, loss_v1=0, loss_v2=0, nll_loss=1.134, ntokens=1940.2, nsentences=56, sample_size=1940.2, sample_size_v1=0, sample_size_v2=0, ppl=2.19, wps=1118, ups=0.58, wpb=1940.2, bsz=56, num_updates=9170, lr=1.34385e-05, gnorm=2.676, clip=100, loss_scale=128, train_wall=17, gb_free=11.5, wall=15816
2023-06-27 20:42:31 - progress_bar.py[line:272] - INFO: epoch 010:    286 / 990 loss=2.348, loss_v1=0, loss_v2=0, nll_loss=1.146, ntokens=1855.2, nsentences=56, sample_size=1855.2, sample_size_v1=0, sample_size_v2=0, ppl=2.21, wps=1073.2, ups=0.58, wpb=1855.2, bsz=56, num_updates=9180, lr=1.34184e-05, gnorm=2.804, clip=100, loss_scale=128, train_wall=17, gb_free=12.6, wall=15833
2023-06-27 20:42:48 - progress_bar.py[line:272] - INFO: epoch 010:    296 / 990 loss=2.343, loss_v1=0, loss_v2=0, nll_loss=1.139, ntokens=1872, nsentences=56, sample_size=1872, sample_size_v1=0, sample_size_v2=0, ppl=2.2, wps=1090.1, ups=0.58, wpb=1872, bsz=56, num_updates=9190, lr=1.33983e-05, gnorm=2.738, clip=100, loss_scale=128, train_wall=17, gb_free=12, wall=15850
2023-06-27 20:43:06 - progress_bar.py[line:272] - INFO: epoch 010:    306 / 990 loss=2.344, loss_v1=0, loss_v2=0, nll_loss=1.14, ntokens=1886, nsentences=56, sample_size=1886, sample_size_v1=0, sample_size_v2=0, ppl=2.2, wps=1041.7, ups=0.55, wpb=1886, bsz=56, num_updates=9200, lr=1.33781e-05, gnorm=2.943, clip=100, loss_scale=128, train_wall=18, gb_free=12.5, wall=15869
2023-06-27 20:43:23 - progress_bar.py[line:272] - INFO: epoch 010:    316 / 990 loss=2.342, loss_v1=0, loss_v2=0, nll_loss=1.138, ntokens=1908.9, nsentences=56, sample_size=1908.9, sample_size_v1=0, sample_size_v2=0, ppl=2.2, wps=1102.4, ups=0.58, wpb=1908.9, bsz=56, num_updates=9210, lr=1.3358e-05, gnorm=2.963, clip=100, loss_scale=128, train_wall=17, gb_free=12, wall=15886
2023-06-27 20:43:40 - progress_bar.py[line:272] - INFO: epoch 010:    326 / 990 loss=2.337, loss_v1=0, loss_v2=0, nll_loss=1.134, ntokens=1936.7, nsentences=56, sample_size=1936.7, sample_size_v1=0, sample_size_v2=0, ppl=2.19, wps=1121.5, ups=0.58, wpb=1936.7, bsz=56, num_updates=9220, lr=1.33378e-05, gnorm=2.953, clip=100, loss_scale=128, train_wall=17, gb_free=12.1, wall=15903
2023-06-27 20:43:58 - progress_bar.py[line:272] - INFO: epoch 010:    336 / 990 loss=2.325, loss_v1=0, loss_v2=0, nll_loss=1.119, ntokens=1859.4, nsentences=56, sample_size=1859.4, sample_size_v1=0, sample_size_v2=0, ppl=2.17, wps=1070.5, ups=0.58, wpb=1859.4, bsz=56, num_updates=9230, lr=1.33177e-05, gnorm=2.994, clip=100, loss_scale=128, train_wall=17, gb_free=12.5, wall=15921
2023-06-27 20:44:15 - progress_bar.py[line:272] - INFO: epoch 010:    346 / 990 loss=2.327, loss_v1=0, loss_v2=0, nll_loss=1.121, ntokens=1868.4, nsentences=56, sample_size=1868.4, sample_size_v1=0, sample_size_v2=0, ppl=2.17, wps=1085.5, ups=0.58, wpb=1868.4, bsz=56, num_updates=9240, lr=1.32975e-05, gnorm=3.081, clip=100, loss_scale=128, train_wall=17, gb_free=12.6, wall=15938
2023-06-27 20:44:32 - progress_bar.py[line:272] - INFO: epoch 010:    356 / 990 loss=2.314, loss_v1=0, loss_v2=0, nll_loss=1.107, ntokens=1887.8, nsentences=56, sample_size=1887.8, sample_size_v1=0, sample_size_v2=0, ppl=2.15, wps=1098.6, ups=0.58, wpb=1887.8, bsz=56, num_updates=9250, lr=1.32774e-05, gnorm=2.939, clip=100, loss_scale=128, train_wall=17, gb_free=12.9, wall=15955
2023-06-27 20:44:49 - progress_bar.py[line:272] - INFO: epoch 010:    366 / 990 loss=2.343, loss_v1=0, loss_v2=0, nll_loss=1.141, ntokens=1716.6, nsentences=56, sample_size=1716.6, sample_size_v1=0, sample_size_v2=0, ppl=2.2, wps=1008.2, ups=0.59, wpb=1716.6, bsz=56, num_updates=9260, lr=1.32572e-05, gnorm=3.198, clip=100, loss_scale=128, train_wall=17, gb_free=12.8, wall=15972
2023-06-27 20:45:06 - progress_bar.py[line:272] - INFO: epoch 010:    376 / 990 loss=2.352, loss_v1=0, loss_v2=0, nll_loss=1.148, ntokens=1833.5, nsentences=56, sample_size=1833.5, sample_size_v1=0, sample_size_v2=0, ppl=2.22, wps=1072.5, ups=0.58, wpb=1833.5, bsz=56, num_updates=9270, lr=1.32371e-05, gnorm=2.993, clip=100, loss_scale=128, train_wall=17, gb_free=12.6, wall=15989
2023-06-27 20:45:24 - progress_bar.py[line:272] - INFO: epoch 010:    386 / 990 loss=2.309, loss_v1=0, loss_v2=0, nll_loss=1.1, ntokens=1874.3, nsentences=56, sample_size=1874.3, sample_size_v1=0, sample_size_v2=0, ppl=2.14, wps=1092.7, ups=0.58, wpb=1874.3, bsz=56, num_updates=9280, lr=1.32169e-05, gnorm=2.982, clip=100, loss_scale=128, train_wall=17, gb_free=12.9, wall=16006
2023-06-27 20:45:41 - progress_bar.py[line:272] - INFO: epoch 010:    396 / 990 loss=2.328, loss_v1=0, loss_v2=0, nll_loss=1.124, ntokens=1674.9, nsentences=56, sample_size=1674.9, sample_size_v1=0, sample_size_v2=0, ppl=2.18, wps=983.1, ups=0.59, wpb=1674.9, bsz=56, num_updates=9290, lr=1.31968e-05, gnorm=3.119, clip=100, loss_scale=128, train_wall=17, gb_free=12.5, wall=16023
2023-06-27 20:45:58 - progress_bar.py[line:272] - INFO: epoch 010:    406 / 990 loss=2.36, loss_v1=0, loss_v2=0, nll_loss=1.158, ntokens=1747.3, nsentences=56, sample_size=1747.3, sample_size_v1=0, sample_size_v2=0, ppl=2.23, wps=1027, ups=0.59, wpb=1747.3, bsz=56, num_updates=9300, lr=1.31766e-05, gnorm=3.216, clip=100, loss_scale=128, train_wall=17, gb_free=12.3, wall=16040
2023-06-27 20:46:15 - progress_bar.py[line:272] - INFO: epoch 010:    416 / 990 loss=2.347, loss_v1=0, loss_v2=0, nll_loss=1.142, ntokens=1733.6, nsentences=56, sample_size=1733.6, sample_size_v1=0, sample_size_v2=0, ppl=2.21, wps=1018.5, ups=0.59, wpb=1733.6, bsz=56, num_updates=9310, lr=1.31565e-05, gnorm=2.951, clip=100, loss_scale=128, train_wall=17, gb_free=12.8, wall=16057
2023-06-27 20:46:32 - progress_bar.py[line:272] - INFO: epoch 010:    426 / 990 loss=2.325, loss_v1=0, loss_v2=0, nll_loss=1.119, ntokens=1789.8, nsentences=56, sample_size=1789.8, sample_size_v1=0, sample_size_v2=0, ppl=2.17, wps=1047.1, ups=0.59, wpb=1789.8, bsz=56, num_updates=9320, lr=1.31363e-05, gnorm=3.1, clip=100, loss_scale=128, train_wall=17, gb_free=13, wall=16074
2023-06-27 20:46:49 - progress_bar.py[line:272] - INFO: epoch 010:    436 / 990 loss=2.327, loss_v1=0, loss_v2=0, nll_loss=1.122, ntokens=1937.4, nsentences=56, sample_size=1937.4, sample_size_v1=0, sample_size_v2=0, ppl=2.18, wps=1128.3, ups=0.58, wpb=1937.4, bsz=56, num_updates=9330, lr=1.31162e-05, gnorm=2.938, clip=100, loss_scale=128, train_wall=17, gb_free=12.4, wall=16092
2023-06-27 20:47:06 - progress_bar.py[line:272] - INFO: epoch 010:    446 / 990 loss=2.319, loss_v1=0, loss_v2=0, nll_loss=1.113, ntokens=1804.3, nsentences=56, sample_size=1804.3, sample_size_v1=0, sample_size_v2=0, ppl=2.16, wps=1056.6, ups=0.59, wpb=1804.3, bsz=56, num_updates=9340, lr=1.3096e-05, gnorm=2.834, clip=100, loss_scale=128, train_wall=17, gb_free=13.2, wall=16109
2023-06-27 20:47:23 - progress_bar.py[line:272] - INFO: epoch 010:    456 / 990 loss=2.34, loss_v1=0, loss_v2=0, nll_loss=1.136, ntokens=1806.7, nsentences=56, sample_size=1806.7, sample_size_v1=0, sample_size_v2=0, ppl=2.2, wps=1060.7, ups=0.59, wpb=1806.7, bsz=56, num_updates=9350, lr=1.30759e-05, gnorm=3.17, clip=100, loss_scale=128, train_wall=17, gb_free=12.5, wall=16126
2023-06-27 20:47:40 - progress_bar.py[line:272] - INFO: epoch 010:    466 / 990 loss=2.337, loss_v1=0, loss_v2=0, nll_loss=1.132, ntokens=1812.1, nsentences=56, sample_size=1812.1, sample_size_v1=0, sample_size_v2=0, ppl=2.19, wps=1056.8, ups=0.58, wpb=1812.1, bsz=56, num_updates=9360, lr=1.30557e-05, gnorm=3.161, clip=100, loss_scale=128, train_wall=17, gb_free=12.4, wall=16143
2023-06-27 20:47:57 - progress_bar.py[line:272] - INFO: epoch 010:    476 / 990 loss=2.314, loss_v1=0, loss_v2=0, nll_loss=1.106, ntokens=1881.7, nsentences=56, sample_size=1881.7, sample_size_v1=0, sample_size_v2=0, ppl=2.15, wps=1094, ups=0.58, wpb=1881.7, bsz=56, num_updates=9370, lr=1.30356e-05, gnorm=2.849, clip=100, loss_scale=128, train_wall=17, gb_free=12.9, wall=16160
2023-06-27 20:48:15 - progress_bar.py[line:272] - INFO: epoch 010:    486 / 990 loss=2.314, loss_v1=0, loss_v2=0, nll_loss=1.106, ntokens=1842.3, nsentences=56, sample_size=1842.3, sample_size_v1=0, sample_size_v2=0, ppl=2.15, wps=1075.5, ups=0.58, wpb=1842.3, bsz=56, num_updates=9380, lr=1.30154e-05, gnorm=2.833, clip=100, loss_scale=128, train_wall=17, gb_free=12.8, wall=16177
2023-06-27 20:48:32 - progress_bar.py[line:272] - INFO: epoch 010:    496 / 990 loss=2.326, loss_v1=0, loss_v2=0, nll_loss=1.122, ntokens=1855.6, nsentences=56, sample_size=1855.6, sample_size_v1=0, sample_size_v2=0, ppl=2.18, wps=1034.9, ups=0.56, wpb=1855.6, bsz=56, num_updates=9390, lr=1.29953e-05, gnorm=2.965, clip=100, loss_scale=256, train_wall=18, gb_free=12.8, wall=16195
2023-06-27 20:48:34 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 128.0
2023-06-27 20:48:51 - progress_bar.py[line:272] - INFO: epoch 010:    507 / 990 loss=2.364, loss_v1=0, loss_v2=0, nll_loss=1.162, ntokens=1791.9, nsentences=56, sample_size=1791.9, sample_size_v1=0, sample_size_v2=0, ppl=2.24, wps=954.9, ups=0.53, wpb=1791.9, bsz=56, num_updates=9400, lr=1.29752e-05, gnorm=3.012, clip=100, loss_scale=128, train_wall=19, gb_free=13, wall=16214
2023-06-27 20:49:08 - progress_bar.py[line:272] - INFO: epoch 010:    517 / 990 loss=2.327, loss_v1=0, loss_v2=0, nll_loss=1.121, ntokens=1771.1, nsentences=56, sample_size=1771.1, sample_size_v1=0, sample_size_v2=0, ppl=2.18, wps=1040, ups=0.59, wpb=1771.1, bsz=56, num_updates=9410, lr=1.2955e-05, gnorm=2.975, clip=100, loss_scale=128, train_wall=17, gb_free=13.2, wall=16231
2023-06-27 20:49:25 - progress_bar.py[line:272] - INFO: epoch 010:    527 / 990 loss=2.344, loss_v1=0, loss_v2=0, nll_loss=1.141, ntokens=1912.3, nsentences=56, sample_size=1912.3, sample_size_v1=0, sample_size_v2=0, ppl=2.21, wps=1113.5, ups=0.58, wpb=1912.3, bsz=56, num_updates=9420, lr=1.29349e-05, gnorm=3.025, clip=100, loss_scale=128, train_wall=17, gb_free=12.8, wall=16248
2023-06-27 20:49:43 - progress_bar.py[line:272] - INFO: epoch 010:    537 / 990 loss=2.321, loss_v1=0, loss_v2=0, nll_loss=1.113, ntokens=1893.7, nsentences=56, sample_size=1893.7, sample_size_v1=0, sample_size_v2=0, ppl=2.16, wps=1099.9, ups=0.58, wpb=1893.7, bsz=56, num_updates=9430, lr=1.29147e-05, gnorm=2.939, clip=100, loss_scale=128, train_wall=17, gb_free=12.9, wall=16265
2023-06-27 20:50:00 - progress_bar.py[line:272] - INFO: epoch 010:    547 / 990 loss=2.338, loss_v1=0, loss_v2=0, nll_loss=1.135, ntokens=1964.2, nsentences=56, sample_size=1964.2, sample_size_v1=0, sample_size_v2=0, ppl=2.2, wps=1145.5, ups=0.58, wpb=1964.2, bsz=56, num_updates=9440, lr=1.28946e-05, gnorm=3.042, clip=100, loss_scale=128, train_wall=17, gb_free=12.7, wall=16282
2023-06-27 20:50:17 - progress_bar.py[line:272] - INFO: epoch 010:    557 / 990 loss=2.322, loss_v1=0, loss_v2=0, nll_loss=1.117, ntokens=1804.7, nsentences=56, sample_size=1804.7, sample_size_v1=0, sample_size_v2=0, ppl=2.17, wps=1056.9, ups=0.59, wpb=1804.7, bsz=56, num_updates=9450, lr=1.28744e-05, gnorm=3.05, clip=100, loss_scale=128, train_wall=17, gb_free=13.1, wall=16300
2023-06-27 20:50:34 - progress_bar.py[line:272] - INFO: epoch 010:    567 / 990 loss=2.308, loss_v1=0, loss_v2=0, nll_loss=1.1, ntokens=1792.1, nsentences=56, sample_size=1792.1, sample_size_v1=0, sample_size_v2=0, ppl=2.14, wps=1046.4, ups=0.58, wpb=1792.1, bsz=56, num_updates=9460, lr=1.28543e-05, gnorm=2.813, clip=100, loss_scale=128, train_wall=17, gb_free=13.2, wall=16317
2023-06-27 20:50:51 - progress_bar.py[line:272] - INFO: epoch 010:    577 / 990 loss=2.343, loss_v1=0, loss_v2=0, nll_loss=1.14, ntokens=1836.2, nsentences=56, sample_size=1836.2, sample_size_v1=0, sample_size_v2=0, ppl=2.2, wps=1067, ups=0.58, wpb=1836.2, bsz=56, num_updates=9470, lr=1.28341e-05, gnorm=2.939, clip=100, loss_scale=128, train_wall=17, gb_free=12.8, wall=16334
2023-06-27 20:51:08 - progress_bar.py[line:272] - INFO: epoch 010:    587 / 990 loss=2.367, loss_v1=0, loss_v2=0, nll_loss=1.164, ntokens=1920.7, nsentences=56, sample_size=1920.7, sample_size_v1=0, sample_size_v2=0, ppl=2.24, wps=1119.6, ups=0.58, wpb=1920.7, bsz=56, num_updates=9480, lr=1.2814e-05, gnorm=2.892, clip=100, loss_scale=128, train_wall=17, gb_free=12.8, wall=16351
2023-06-27 20:51:25 - progress_bar.py[line:272] - INFO: epoch 010:    597 / 990 loss=2.32, loss_v1=0, loss_v2=0, nll_loss=1.113, ntokens=1856.3, nsentences=56, sample_size=1856.3, sample_size_v1=0, sample_size_v2=0, ppl=2.16, wps=1087.8, ups=0.59, wpb=1856.3, bsz=56, num_updates=9490, lr=1.27938e-05, gnorm=3.04, clip=100, loss_scale=128, train_wall=17, gb_free=12.8, wall=16368
2023-06-27 20:51:42 - progress_bar.py[line:272] - INFO: epoch 010:    607 / 990 loss=2.325, loss_v1=0, loss_v2=0, nll_loss=1.12, ntokens=1771.5, nsentences=56, sample_size=1771.5, sample_size_v1=0, sample_size_v2=0, ppl=2.17, wps=1040.9, ups=0.59, wpb=1771.5, bsz=56, num_updates=9500, lr=1.27737e-05, gnorm=3.122, clip=100, loss_scale=128, train_wall=17, gb_free=13, wall=16385
2023-06-27 20:52:00 - progress_bar.py[line:272] - INFO: epoch 010:    617 / 990 loss=2.328, loss_v1=0, loss_v2=0, nll_loss=1.122, ntokens=1885.1, nsentences=56, sample_size=1885.1, sample_size_v1=0, sample_size_v2=0, ppl=2.18, wps=1104.3, ups=0.59, wpb=1885.1, bsz=56, num_updates=9510, lr=1.27535e-05, gnorm=2.953, clip=100, loss_scale=128, train_wall=17, gb_free=13.1, wall=16402
2023-06-27 20:52:17 - progress_bar.py[line:272] - INFO: epoch 010:    627 / 990 loss=2.353, loss_v1=0, loss_v2=0, nll_loss=1.149, ntokens=2031.3, nsentences=56, sample_size=2031.3, sample_size_v1=0, sample_size_v2=0, ppl=2.22, wps=1184.3, ups=0.58, wpb=2031.3, bsz=56, num_updates=9520, lr=1.27334e-05, gnorm=2.803, clip=100, loss_scale=128, train_wall=17, gb_free=12.6, wall=16419
2023-06-27 20:52:34 - progress_bar.py[line:272] - INFO: epoch 010:    637 / 990 loss=2.337, loss_v1=0, loss_v2=0, nll_loss=1.134, ntokens=2001.2, nsentences=56, sample_size=2001.2, sample_size_v1=0, sample_size_v2=0, ppl=2.19, wps=1162.3, ups=0.58, wpb=2001.2, bsz=56, num_updates=9530, lr=1.27132e-05, gnorm=2.804, clip=100, loss_scale=128, train_wall=17, gb_free=13, wall=16437
2023-06-27 20:52:52 - progress_bar.py[line:272] - INFO: epoch 010:    647 / 990 loss=2.338, loss_v1=0, loss_v2=0, nll_loss=1.133, ntokens=1969.6, nsentences=56, sample_size=1969.6, sample_size_v1=0, sample_size_v2=0, ppl=2.19, wps=1115.1, ups=0.57, wpb=1969.6, bsz=56, num_updates=9540, lr=1.26931e-05, gnorm=2.943, clip=100, loss_scale=128, train_wall=18, gb_free=12.4, wall=16454
2023-06-27 20:53:09 - progress_bar.py[line:272] - INFO: epoch 010:    657 / 990 loss=2.336, loss_v1=0, loss_v2=0, nll_loss=1.132, ntokens=1897.8, nsentences=56, sample_size=1897.8, sample_size_v1=0, sample_size_v2=0, ppl=2.19, wps=1079.1, ups=0.57, wpb=1897.8, bsz=56, num_updates=9550, lr=1.26729e-05, gnorm=2.836, clip=100, loss_scale=128, train_wall=18, gb_free=12.5, wall=16472
2023-06-27 20:53:26 - progress_bar.py[line:272] - INFO: epoch 010:    667 / 990 loss=2.347, loss_v1=0, loss_v2=0, nll_loss=1.142, ntokens=1833.3, nsentences=56, sample_size=1833.3, sample_size_v1=0, sample_size_v2=0, ppl=2.21, wps=1073.6, ups=0.59, wpb=1833.3, bsz=56, num_updates=9560, lr=1.26528e-05, gnorm=2.838, clip=100, loss_scale=128, train_wall=17, gb_free=12.7, wall=16489
2023-06-27 20:53:43 - progress_bar.py[line:272] - INFO: epoch 010:    677 / 990 loss=2.315, loss_v1=0, loss_v2=0, nll_loss=1.108, ntokens=1862.8, nsentences=56, sample_size=1862.8, sample_size_v1=0, sample_size_v2=0, ppl=2.16, wps=1085.2, ups=0.58, wpb=1862.8, bsz=56, num_updates=9570, lr=1.26326e-05, gnorm=2.984, clip=100, loss_scale=128, train_wall=17, gb_free=12.7, wall=16506
2023-06-27 20:54:01 - progress_bar.py[line:272] - INFO: epoch 010:    687 / 990 loss=2.301, loss_v1=0, loss_v2=0, nll_loss=1.094, ntokens=1846.9, nsentences=56, sample_size=1846.9, sample_size_v1=0, sample_size_v2=0, ppl=2.13, wps=1079.8, ups=0.58, wpb=1846.9, bsz=56, num_updates=9580, lr=1.26125e-05, gnorm=2.763, clip=100, loss_scale=128, train_wall=17, gb_free=12.6, wall=16523
2023-06-27 20:54:18 - progress_bar.py[line:272] - INFO: epoch 010:    697 / 990 loss=2.337, loss_v1=0, loss_v2=0, nll_loss=1.133, ntokens=1739.1, nsentences=56, sample_size=1739.1, sample_size_v1=0, sample_size_v2=0, ppl=2.19, wps=1017.7, ups=0.59, wpb=1739.1, bsz=56, num_updates=9590, lr=1.25923e-05, gnorm=3.299, clip=100, loss_scale=128, train_wall=17, gb_free=12.9, wall=16540
2023-06-27 20:54:35 - progress_bar.py[line:272] - INFO: epoch 010:    707 / 990 loss=2.355, loss_v1=0, loss_v2=0, nll_loss=1.151, ntokens=1710.4, nsentences=56, sample_size=1710.4, sample_size_v1=0, sample_size_v2=0, ppl=2.22, wps=1004.6, ups=0.59, wpb=1710.4, bsz=56, num_updates=9600, lr=1.25722e-05, gnorm=3.249, clip=100, loss_scale=128, train_wall=17, gb_free=12.8, wall=16557
2023-06-27 20:54:52 - progress_bar.py[line:272] - INFO: epoch 010:    717 / 990 loss=2.324, loss_v1=0, loss_v2=0, nll_loss=1.117, ntokens=1787.7, nsentences=56, sample_size=1787.7, sample_size_v1=0, sample_size_v2=0, ppl=2.17, wps=1048.7, ups=0.59, wpb=1787.7, bsz=56, num_updates=9610, lr=1.2552e-05, gnorm=2.928, clip=100, loss_scale=128, train_wall=17, gb_free=13.1, wall=16574
2023-06-27 20:55:09 - progress_bar.py[line:272] - INFO: epoch 010:    727 / 990 loss=2.314, loss_v1=0, loss_v2=0, nll_loss=1.108, ntokens=1826.3, nsentences=56, sample_size=1826.3, sample_size_v1=0, sample_size_v2=0, ppl=2.15, wps=1069.9, ups=0.59, wpb=1826.3, bsz=56, num_updates=9620, lr=1.25319e-05, gnorm=3.037, clip=100, loss_scale=128, train_wall=17, gb_free=12.7, wall=16591
2023-06-27 20:55:26 - progress_bar.py[line:272] - INFO: epoch 010:    737 / 990 loss=2.328, loss_v1=0, loss_v2=0, nll_loss=1.122, ntokens=1817.3, nsentences=56, sample_size=1817.3, sample_size_v1=0, sample_size_v2=0, ppl=2.18, wps=1063.8, ups=0.59, wpb=1817.3, bsz=56, num_updates=9630, lr=1.25118e-05, gnorm=3.104, clip=100, loss_scale=128, train_wall=17, gb_free=12.8, wall=16609
2023-06-27 20:55:43 - progress_bar.py[line:272] - INFO: epoch 010:    747 / 990 loss=2.344, loss_v1=0, loss_v2=0, nll_loss=1.138, ntokens=1681.1, nsentences=56, sample_size=1681.1, sample_size_v1=0, sample_size_v2=0, ppl=2.2, wps=992.5, ups=0.59, wpb=1681.1, bsz=56, num_updates=9640, lr=1.24916e-05, gnorm=3.12, clip=100, loss_scale=128, train_wall=17, gb_free=13.2, wall=16625
2023-06-27 20:56:00 - progress_bar.py[line:272] - INFO: epoch 010:    757 / 990 loss=2.361, loss_v1=0, loss_v2=0, nll_loss=1.16, ntokens=1712.8, nsentences=56, sample_size=1712.8, sample_size_v1=0, sample_size_v2=0, ppl=2.23, wps=1006.8, ups=0.59, wpb=1712.8, bsz=56, num_updates=9650, lr=1.24715e-05, gnorm=3.297, clip=100, loss_scale=128, train_wall=17, gb_free=12.8, wall=16642
2023-06-27 20:56:17 - progress_bar.py[line:272] - INFO: epoch 010:    767 / 990 loss=2.333, loss_v1=0, loss_v2=0, nll_loss=1.128, ntokens=1791.5, nsentences=56, sample_size=1791.5, sample_size_v1=0, sample_size_v2=0, ppl=2.19, wps=1049.9, ups=0.59, wpb=1791.5, bsz=56, num_updates=9660, lr=1.24513e-05, gnorm=2.849, clip=100, loss_scale=128, train_wall=17, gb_free=12.6, wall=16660
2023-06-27 20:56:34 - progress_bar.py[line:272] - INFO: epoch 010:    777 / 990 loss=2.324, loss_v1=0, loss_v2=0, nll_loss=1.116, ntokens=1798.1, nsentences=56, sample_size=1798.1, sample_size_v1=0, sample_size_v2=0, ppl=2.17, wps=1052.6, ups=0.59, wpb=1798.1, bsz=56, num_updates=9670, lr=1.24312e-05, gnorm=3.13, clip=100, loss_scale=128, train_wall=17, gb_free=13.1, wall=16677
2023-06-27 20:56:51 - progress_bar.py[line:272] - INFO: epoch 010:    787 / 990 loss=2.332, loss_v1=0, loss_v2=0, nll_loss=1.128, ntokens=1753.2, nsentences=56, sample_size=1753.2, sample_size_v1=0, sample_size_v2=0, ppl=2.19, wps=1030, ups=0.59, wpb=1753.2, bsz=56, num_updates=9680, lr=1.2411e-05, gnorm=3.452, clip=100, loss_scale=128, train_wall=17, gb_free=12.6, wall=16694
2023-06-27 20:57:08 - progress_bar.py[line:272] - INFO: epoch 010:    797 / 990 loss=2.338, loss_v1=0, loss_v2=0, nll_loss=1.134, ntokens=1893.4, nsentences=56, sample_size=1893.4, sample_size_v1=0, sample_size_v2=0, ppl=2.19, wps=1102, ups=0.58, wpb=1893.4, bsz=56, num_updates=9690, lr=1.23909e-05, gnorm=2.91, clip=100, loss_scale=128, train_wall=17, gb_free=13.1, wall=16711
2023-06-27 20:57:25 - progress_bar.py[line:272] - INFO: epoch 010:    807 / 990 loss=2.337, loss_v1=0, loss_v2=0, nll_loss=1.13, ntokens=1724.5, nsentences=56, sample_size=1724.5, sample_size_v1=0, sample_size_v2=0, ppl=2.19, wps=1014.6, ups=0.59, wpb=1724.5, bsz=56, num_updates=9700, lr=1.23707e-05, gnorm=3.193, clip=100, loss_scale=128, train_wall=17, gb_free=13.3, wall=16728
2023-06-27 20:57:42 - progress_bar.py[line:272] - INFO: epoch 010:    817 / 990 loss=2.356, loss_v1=0, loss_v2=0, nll_loss=1.154, ntokens=1634.5, nsentences=56, sample_size=1634.5, sample_size_v1=0, sample_size_v2=0, ppl=2.22, wps=965, ups=0.59, wpb=1634.5, bsz=56, num_updates=9710, lr=1.23506e-05, gnorm=3.214, clip=100, loss_scale=128, train_wall=17, gb_free=12.8, wall=16745
2023-06-27 20:57:59 - progress_bar.py[line:272] - INFO: epoch 010:    827 / 990 loss=2.316, loss_v1=0, loss_v2=0, nll_loss=1.111, ntokens=1750.9, nsentences=56, sample_size=1750.9, sample_size_v1=0, sample_size_v2=0, ppl=2.16, wps=1026.2, ups=0.59, wpb=1750.9, bsz=56, num_updates=9720, lr=1.23304e-05, gnorm=2.992, clip=100, loss_scale=128, train_wall=17, gb_free=13, wall=16762
2023-06-27 20:58:16 - progress_bar.py[line:272] - INFO: epoch 010:    837 / 990 loss=2.315, loss_v1=0, loss_v2=0, nll_loss=1.106, ntokens=1765.8, nsentences=56, sample_size=1765.8, sample_size_v1=0, sample_size_v2=0, ppl=2.15, wps=1038.3, ups=0.59, wpb=1765.8, bsz=56, num_updates=9730, lr=1.23103e-05, gnorm=2.979, clip=100, loss_scale=128, train_wall=17, gb_free=12.2, wall=16779
2023-06-27 20:58:33 - progress_bar.py[line:272] - INFO: epoch 010:    847 / 990 loss=2.309, loss_v1=0, loss_v2=0, nll_loss=1.102, ntokens=1881.1, nsentences=56, sample_size=1881.1, sample_size_v1=0, sample_size_v2=0, ppl=2.15, wps=1102.8, ups=0.59, wpb=1881.1, bsz=56, num_updates=9740, lr=1.22901e-05, gnorm=2.847, clip=100, loss_scale=128, train_wall=17, gb_free=12.7, wall=16796
2023-06-27 20:58:50 - progress_bar.py[line:272] - INFO: epoch 010:    857 / 990 loss=2.294, loss_v1=0, loss_v2=0, nll_loss=1.084, ntokens=1878.2, nsentences=56, sample_size=1878.2, sample_size_v1=0, sample_size_v2=0, ppl=2.12, wps=1095, ups=0.58, wpb=1878.2, bsz=56, num_updates=9750, lr=1.227e-05, gnorm=2.904, clip=100, loss_scale=128, train_wall=17, gb_free=12.9, wall=16813
2023-06-27 20:59:08 - progress_bar.py[line:272] - INFO: epoch 010:    867 / 990 loss=2.315, loss_v1=0, loss_v2=0, nll_loss=1.109, ntokens=1782.2, nsentences=56, sample_size=1782.2, sample_size_v1=0, sample_size_v2=0, ppl=2.16, wps=1041.6, ups=0.58, wpb=1782.2, bsz=56, num_updates=9760, lr=1.22498e-05, gnorm=3.015, clip=100, loss_scale=128, train_wall=17, gb_free=12.7, wall=16830
2023-06-27 20:59:25 - progress_bar.py[line:272] - INFO: epoch 010:    877 / 990 loss=2.307, loss_v1=0, loss_v2=0, nll_loss=1.1, ntokens=1882.1, nsentences=56, sample_size=1882.1, sample_size_v1=0, sample_size_v2=0, ppl=2.14, wps=1099.1, ups=0.58, wpb=1882.1, bsz=56, num_updates=9770, lr=1.22297e-05, gnorm=2.85, clip=100, loss_scale=128, train_wall=17, gb_free=12.1, wall=16847
2023-06-27 20:59:42 - progress_bar.py[line:272] - INFO: epoch 010:    887 / 990 loss=2.311, loss_v1=0, loss_v2=0, nll_loss=1.103, ntokens=1981.2, nsentences=56, sample_size=1981.2, sample_size_v1=0, sample_size_v2=0, ppl=2.15, wps=1155.6, ups=0.58, wpb=1981.2, bsz=56, num_updates=9780, lr=1.22095e-05, gnorm=2.811, clip=100, loss_scale=128, train_wall=17, gb_free=12.5, wall=16864
2023-06-27 20:59:59 - progress_bar.py[line:272] - INFO: epoch 010:    897 / 990 loss=2.315, loss_v1=0, loss_v2=0, nll_loss=1.107, ntokens=1829.3, nsentences=56, sample_size=1829.3, sample_size_v1=0, sample_size_v2=0, ppl=2.15, wps=1069.2, ups=0.58, wpb=1829.3, bsz=56, num_updates=9790, lr=1.21894e-05, gnorm=3.004, clip=100, loss_scale=128, train_wall=17, gb_free=12.6, wall=16882
2023-06-27 21:00:16 - progress_bar.py[line:272] - INFO: epoch 010:    907 / 990 loss=2.343, loss_v1=0, loss_v2=0, nll_loss=1.141, ntokens=1790.5, nsentences=56, sample_size=1790.5, sample_size_v1=0, sample_size_v2=0, ppl=2.21, wps=1050.7, ups=0.59, wpb=1790.5, bsz=56, num_updates=9800, lr=1.21692e-05, gnorm=3.086, clip=100, loss_scale=128, train_wall=17, gb_free=12.8, wall=16899
2023-06-27 21:00:33 - progress_bar.py[line:272] - INFO: epoch 010:    917 / 990 loss=2.327, loss_v1=0, loss_v2=0, nll_loss=1.12, ntokens=1708, nsentences=56, sample_size=1708, sample_size_v1=0, sample_size_v2=0, ppl=2.17, wps=1007.1, ups=0.59, wpb=1708, bsz=56, num_updates=9810, lr=1.21491e-05, gnorm=3.088, clip=100, loss_scale=128, train_wall=17, gb_free=13.1, wall=16916
2023-06-27 21:00:50 - progress_bar.py[line:272] - INFO: epoch 010:    927 / 990 loss=2.294, loss_v1=0, loss_v2=0, nll_loss=1.084, ntokens=1860.7, nsentences=56, sample_size=1860.7, sample_size_v1=0, sample_size_v2=0, ppl=2.12, wps=1084.9, ups=0.58, wpb=1860.7, bsz=56, num_updates=9820, lr=1.21289e-05, gnorm=3.026, clip=100, loss_scale=128, train_wall=17, gb_free=12.7, wall=16933
2023-06-27 21:01:07 - progress_bar.py[line:272] - INFO: epoch 010:    937 / 990 loss=2.31, loss_v1=0, loss_v2=0, nll_loss=1.102, ntokens=1794.4, nsentences=56, sample_size=1794.4, sample_size_v1=0, sample_size_v2=0, ppl=2.15, wps=1055.3, ups=0.59, wpb=1794.4, bsz=56, num_updates=9830, lr=1.21088e-05, gnorm=3.053, clip=100, loss_scale=128, train_wall=17, gb_free=12.8, wall=16950
2023-06-27 21:01:24 - progress_bar.py[line:272] - INFO: epoch 010:    947 / 990 loss=2.314, loss_v1=0, loss_v2=0, nll_loss=1.108, ntokens=1932.6, nsentences=56, sample_size=1932.6, sample_size_v1=0, sample_size_v2=0, ppl=2.16, wps=1122.6, ups=0.58, wpb=1932.6, bsz=56, num_updates=9840, lr=1.20887e-05, gnorm=2.781, clip=100, loss_scale=128, train_wall=17, gb_free=13, wall=16967
2023-06-27 21:01:41 - progress_bar.py[line:272] - INFO: epoch 010:    957 / 990 loss=2.323, loss_v1=0, loss_v2=0, nll_loss=1.116, ntokens=1881.5, nsentences=56, sample_size=1881.5, sample_size_v1=0, sample_size_v2=0, ppl=2.17, wps=1103.8, ups=0.59, wpb=1881.5, bsz=56, num_updates=9850, lr=1.20685e-05, gnorm=3.037, clip=100, loss_scale=128, train_wall=17, gb_free=12.9, wall=16984
2023-06-27 21:01:58 - progress_bar.py[line:272] - INFO: epoch 010:    967 / 990 loss=2.312, loss_v1=0, loss_v2=0, nll_loss=1.103, ntokens=1914.2, nsentences=56, sample_size=1914.2, sample_size_v1=0, sample_size_v2=0, ppl=2.15, wps=1117.1, ups=0.58, wpb=1914.2, bsz=56, num_updates=9860, lr=1.20484e-05, gnorm=2.967, clip=100, loss_scale=128, train_wall=17, gb_free=12.7, wall=17001
2023-06-27 21:02:15 - progress_bar.py[line:272] - INFO: epoch 010:    977 / 990 loss=2.308, loss_v1=0, loss_v2=0, nll_loss=1.101, ntokens=1847.6, nsentences=54.8, sample_size=1847.6, sample_size_v1=0, sample_size_v2=0, ppl=2.15, wps=1095.9, ups=0.59, wpb=1847.6, bsz=54.8, num_updates=9870, lr=1.20282e-05, gnorm=3.009, clip=100, loss_scale=128, train_wall=17, gb_free=12.9, wall=17018
2023-06-27 21:02:32 - progress_bar.py[line:272] - INFO: epoch 010:    987 / 990 loss=2.345, loss_v1=0, loss_v2=0, nll_loss=1.142, ntokens=1805.9, nsentences=56, sample_size=1805.9, sample_size_v1=0, sample_size_v2=0, ppl=2.21, wps=1062.4, ups=0.59, wpb=1805.9, bsz=56, num_updates=9880, lr=1.20081e-05, gnorm=2.961, clip=100, loss_scale=128, train_wall=17, gb_free=12.6, wall=17035
2023-06-27 21:02:37 - train.py[line:332] - INFO: end of epoch 10 (average epoch stats below)
2023-06-27 21:02:37 - progress_bar.py[line:282] - INFO: epoch 010 | loss 2.313 | loss_v1 0 | loss_v2 0 | nll_loss 1.105 | ntokens 1849.98 | nsentences 55.96 | sample_size 1849.98 | sample_size_v1 0 | sample_size_v2 0 | ppl 2.15 | wps 1073.4 | ups 0.58 | wpb 1850 | bsz 56 | num_updates 9883 | lr 1.2002e-05 | gnorm 2.931 | clip 100 | loss_scale 128 | train_wall 1699 | gb_free 13.3 | wall 17040
2023-06-27 21:02:37 - trainer.py[line:639] - INFO: loading train data for epoch 11
local datafile ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 0 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 1 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 0 finished initializing row_count and line_idx-to-offset mapping
file ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 0 row count 27700 total row count 55400
local datafile ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 1 finished initializing row_count and line_idx-to-offset mapping
file ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 1 row count 27700 total row count 55400
slice_id 0 seek offset 0
2023-06-27 21:02:39 - trainer.py[line:703] - INFO: begin training epoch 11
2023-06-27 21:02:39 - train.py[line:305] - INFO: Start iterating over samples
slice_id 1 seek offset 27700
2023-06-27 21:02:51 - progress_bar.py[line:272] - INFO: epoch 011:      7 / 990 loss=2.296, loss_v1=0, loss_v2=0, nll_loss=1.085, ntokens=1781.9, nsentences=53.2, sample_size=1781.9, sample_size_v1=0, sample_size_v2=0, ppl=2.12, wps=940.9, ups=0.53, wpb=1781.9, bsz=53.2, num_updates=9890, lr=1.19879e-05, gnorm=3.05, clip=100, loss_scale=128, train_wall=17, gb_free=12.5, wall=17054
2023-06-27 21:03:09 - progress_bar.py[line:272] - INFO: epoch 011:     17 / 990 loss=2.275, loss_v1=0, loss_v2=0, nll_loss=1.064, ntokens=1849.7, nsentences=56, sample_size=1849.7, sample_size_v1=0, sample_size_v2=0, ppl=2.09, wps=1073.3, ups=0.58, wpb=1849.7, bsz=56, num_updates=9900, lr=1.19678e-05, gnorm=2.97, clip=100, loss_scale=128, train_wall=17, gb_free=12.2, wall=17071
2023-06-27 21:03:18 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 128.0
2023-06-27 21:03:28 - progress_bar.py[line:272] - INFO: epoch 011:     28 / 990 loss=2.247, loss_v1=0, loss_v2=0, nll_loss=1.033, ntokens=1751.5, nsentences=56, sample_size=1751.5, sample_size_v1=0, sample_size_v2=0, ppl=2.05, wps=901, ups=0.51, wpb=1751.5, bsz=56, num_updates=9910, lr=1.19476e-05, gnorm=2.885, clip=100, loss_scale=128, train_wall=19, gb_free=12.8, wall=17091
2023-06-27 21:03:45 - progress_bar.py[line:272] - INFO: epoch 011:     38 / 990 loss=2.212, loss_v1=0, loss_v2=0, nll_loss=0.993, ntokens=1872.9, nsentences=56, sample_size=1872.9, sample_size_v1=0, sample_size_v2=0, ppl=1.99, wps=1089.2, ups=0.58, wpb=1872.9, bsz=56, num_updates=9920, lr=1.19275e-05, gnorm=2.96, clip=100, loss_scale=128, train_wall=17, gb_free=11.7, wall=17108
2023-06-27 21:04:03 - progress_bar.py[line:272] - INFO: epoch 011:     48 / 990 loss=2.204, loss_v1=0, loss_v2=0, nll_loss=0.986, ntokens=1890.8, nsentences=56, sample_size=1890.8, sample_size_v1=0, sample_size_v2=0, ppl=1.98, wps=1044.2, ups=0.55, wpb=1890.8, bsz=56, num_updates=9930, lr=1.19073e-05, gnorm=2.85, clip=100, loss_scale=128, train_wall=18, gb_free=13, wall=17126
2023-06-27 21:04:21 - progress_bar.py[line:272] - INFO: epoch 011:     58 / 990 loss=2.266, loss_v1=0, loss_v2=0, nll_loss=1.054, ntokens=1750.6, nsentences=56, sample_size=1750.6, sample_size_v1=0, sample_size_v2=0, ppl=2.08, wps=1016.6, ups=0.58, wpb=1750.6, bsz=56, num_updates=9940, lr=1.18872e-05, gnorm=3.193, clip=100, loss_scale=128, train_wall=17, gb_free=13, wall=17143
2023-06-27 21:04:38 - progress_bar.py[line:272] - INFO: epoch 011:     68 / 990 loss=2.154, loss_v1=0, loss_v2=0, nll_loss=0.927, ntokens=1793, nsentences=56, sample_size=1793, sample_size_v1=0, sample_size_v2=0, ppl=1.9, wps=1045.9, ups=0.58, wpb=1793, bsz=56, num_updates=9950, lr=1.1867e-05, gnorm=2.863, clip=100, loss_scale=128, train_wall=17, gb_free=12.4, wall=17160
2023-06-27 21:04:55 - progress_bar.py[line:272] - INFO: epoch 011:     78 / 990 loss=2.126, loss_v1=0, loss_v2=0, nll_loss=0.897, ntokens=2257.8, nsentences=56, sample_size=2257.8, sample_size_v1=0, sample_size_v2=0, ppl=1.86, wps=1268.3, ups=0.56, wpb=2257.8, bsz=56, num_updates=9960, lr=1.18469e-05, gnorm=2.384, clip=100, loss_scale=128, train_wall=18, gb_free=11.9, wall=17178
2023-06-27 21:05:13 - progress_bar.py[line:272] - INFO: epoch 011:     88 / 990 loss=2.194, loss_v1=0, loss_v2=0, nll_loss=0.974, ntokens=2060.7, nsentences=56, sample_size=2060.7, sample_size_v1=0, sample_size_v2=0, ppl=1.96, wps=1171.1, ups=0.57, wpb=2060.7, bsz=56, num_updates=9970, lr=1.18267e-05, gnorm=2.691, clip=100, loss_scale=128, train_wall=18, gb_free=12.7, wall=17196
2023-06-27 21:05:30 - progress_bar.py[line:272] - INFO: epoch 011:     98 / 990 loss=2.242, loss_v1=0, loss_v2=0, nll_loss=1.024, ntokens=1935.3, nsentences=56, sample_size=1935.3, sample_size_v1=0, sample_size_v2=0, ppl=2.03, wps=1113.7, ups=0.58, wpb=1935.3, bsz=56, num_updates=9980, lr=1.18066e-05, gnorm=2.954, clip=100, loss_scale=128, train_wall=17, gb_free=11.5, wall=17213
2023-06-27 21:05:48 - progress_bar.py[line:272] - INFO: epoch 011:    108 / 990 loss=2.218, loss_v1=0, loss_v2=0, nll_loss=1.001, ntokens=1907.6, nsentences=56, sample_size=1907.6, sample_size_v1=0, sample_size_v2=0, ppl=2, wps=1105.7, ups=0.58, wpb=1907.6, bsz=56, num_updates=9990, lr=1.17864e-05, gnorm=2.974, clip=100, loss_scale=128, train_wall=17, gb_free=13, wall=17230
2023-06-27 21:06:05 - progress_bar.py[line:272] - INFO: epoch 011:    118 / 990 loss=2.308, loss_v1=0, loss_v2=0, nll_loss=1.1, ntokens=1777.1, nsentences=56, sample_size=1777.1, sample_size_v1=0, sample_size_v2=0, ppl=2.14, wps=1024.5, ups=0.58, wpb=1777.1, bsz=56, num_updates=10000, lr=1.17663e-05, gnorm=3.086, clip=100, loss_scale=128, train_wall=17, gb_free=12.6, wall=17248
2023-06-27 21:06:22 - progress_bar.py[line:272] - INFO: epoch 011:    128 / 990 loss=2.317, loss_v1=0, loss_v2=0, nll_loss=1.112, ntokens=1827.3, nsentences=56, sample_size=1827.3, sample_size_v1=0, sample_size_v2=0, ppl=2.16, wps=1062.8, ups=0.58, wpb=1827.3, bsz=56, num_updates=10010, lr=1.17461e-05, gnorm=3.009, clip=100, loss_scale=128, train_wall=17, gb_free=11.6, wall=17265
2023-06-27 21:06:40 - progress_bar.py[line:272] - INFO: epoch 011:    138 / 990 loss=2.297, loss_v1=0, loss_v2=0, nll_loss=1.086, ntokens=1885.3, nsentences=56, sample_size=1885.3, sample_size_v1=0, sample_size_v2=0, ppl=2.12, wps=1083.7, ups=0.57, wpb=1885.3, bsz=56, num_updates=10020, lr=1.1726e-05, gnorm=2.905, clip=100, loss_scale=128, train_wall=17, gb_free=12.3, wall=17282
2023-06-27 21:06:57 - progress_bar.py[line:272] - INFO: epoch 011:    148 / 990 loss=2.295, loss_v1=0, loss_v2=0, nll_loss=1.084, ntokens=1959, nsentences=56, sample_size=1959, sample_size_v1=0, sample_size_v2=0, ppl=2.12, wps=1121.8, ups=0.57, wpb=1959, bsz=56, num_updates=10030, lr=1.17058e-05, gnorm=2.888, clip=100, loss_scale=128, train_wall=17, gb_free=11, wall=17300
2023-06-27 21:07:15 - progress_bar.py[line:272] - INFO: epoch 011:    158 / 990 loss=2.262, loss_v1=0, loss_v2=0, nll_loss=1.049, ntokens=1964.5, nsentences=56, sample_size=1964.5, sample_size_v1=0, sample_size_v2=0, ppl=2.07, wps=1127.1, ups=0.57, wpb=1964.5, bsz=56, num_updates=10040, lr=1.16857e-05, gnorm=2.748, clip=100, loss_scale=128, train_wall=17, gb_free=12.2, wall=17317
2023-06-27 21:07:32 - progress_bar.py[line:272] - INFO: epoch 011:    168 / 990 loss=2.256, loss_v1=0, loss_v2=0, nll_loss=1.044, ntokens=1934.6, nsentences=56, sample_size=1934.6, sample_size_v1=0, sample_size_v2=0, ppl=2.06, wps=1106.7, ups=0.57, wpb=1934.6, bsz=56, num_updates=10050, lr=1.16655e-05, gnorm=2.737, clip=100, loss_scale=128, train_wall=17, gb_free=12.2, wall=17335
2023-06-27 21:07:49 - progress_bar.py[line:272] - INFO: epoch 011:    178 / 990 loss=2.275, loss_v1=0, loss_v2=0, nll_loss=1.064, ntokens=1972.4, nsentences=56, sample_size=1972.4, sample_size_v1=0, sample_size_v2=0, ppl=2.09, wps=1130.5, ups=0.57, wpb=1972.4, bsz=56, num_updates=10060, lr=1.16454e-05, gnorm=2.762, clip=100, loss_scale=128, train_wall=17, gb_free=12.1, wall=17352
2023-06-27 21:08:07 - progress_bar.py[line:272] - INFO: epoch 011:    188 / 990 loss=2.261, loss_v1=0, loss_v2=0, nll_loss=1.046, ntokens=1916.2, nsentences=56, sample_size=1916.2, sample_size_v1=0, sample_size_v2=0, ppl=2.06, wps=1106.9, ups=0.58, wpb=1916.2, bsz=56, num_updates=10070, lr=1.16253e-05, gnorm=3.062, clip=100, loss_scale=128, train_wall=17, gb_free=11.3, wall=17369
2023-06-27 21:08:24 - progress_bar.py[line:272] - INFO: epoch 011:    198 / 990 loss=2.294, loss_v1=0, loss_v2=0, nll_loss=1.086, ntokens=1739.5, nsentences=56, sample_size=1739.5, sample_size_v1=0, sample_size_v2=0, ppl=2.12, wps=1018.3, ups=0.59, wpb=1739.5, bsz=56, num_updates=10080, lr=1.16051e-05, gnorm=3.237, clip=100, loss_scale=128, train_wall=17, gb_free=12.6, wall=17387
2023-06-27 21:08:41 - progress_bar.py[line:272] - INFO: epoch 011:    208 / 990 loss=2.239, loss_v1=0, loss_v2=0, nll_loss=1.023, ntokens=1976.6, nsentences=56, sample_size=1976.6, sample_size_v1=0, sample_size_v2=0, ppl=2.03, wps=1136.4, ups=0.57, wpb=1976.6, bsz=56, num_updates=10090, lr=1.1585e-05, gnorm=2.917, clip=100, loss_scale=128, train_wall=17, gb_free=11.9, wall=17404
2023-06-27 21:08:59 - progress_bar.py[line:272] - INFO: epoch 011:    218 / 990 loss=2.262, loss_v1=0, loss_v2=0, nll_loss=1.048, ntokens=1936.9, nsentences=56, sample_size=1936.9, sample_size_v1=0, sample_size_v2=0, ppl=2.07, wps=1113.4, ups=0.57, wpb=1936.9, bsz=56, num_updates=10100, lr=1.15648e-05, gnorm=2.894, clip=100, loss_scale=128, train_wall=17, gb_free=12.3, wall=17421
2023-06-27 21:09:16 - progress_bar.py[line:272] - INFO: epoch 011:    228 / 990 loss=2.294, loss_v1=0, loss_v2=0, nll_loss=1.084, ntokens=1867.9, nsentences=56, sample_size=1867.9, sample_size_v1=0, sample_size_v2=0, ppl=2.12, wps=1081.2, ups=0.58, wpb=1867.9, bsz=56, num_updates=10110, lr=1.15447e-05, gnorm=3.052, clip=100, loss_scale=128, train_wall=17, gb_free=12.7, wall=17439
2023-06-27 21:09:33 - progress_bar.py[line:272] - INFO: epoch 011:    238 / 990 loss=2.318, loss_v1=0, loss_v2=0, nll_loss=1.113, ntokens=1736.4, nsentences=56, sample_size=1736.4, sample_size_v1=0, sample_size_v2=0, ppl=2.16, wps=1013.1, ups=0.58, wpb=1736.4, bsz=56, num_updates=10120, lr=1.15245e-05, gnorm=3.316, clip=100, loss_scale=128, train_wall=17, gb_free=12.7, wall=17456
2023-06-27 21:09:50 - progress_bar.py[line:272] - INFO: epoch 011:    248 / 990 loss=2.335, loss_v1=0, loss_v2=0, nll_loss=1.131, ntokens=1948.2, nsentences=56, sample_size=1948.2, sample_size_v1=0, sample_size_v2=0, ppl=2.19, wps=1133.2, ups=0.58, wpb=1948.2, bsz=56, num_updates=10130, lr=1.15044e-05, gnorm=2.972, clip=100, loss_scale=128, train_wall=17, gb_free=12.2, wall=17473
2023-06-27 21:10:07 - progress_bar.py[line:272] - INFO: epoch 011:    258 / 990 loss=2.309, loss_v1=0, loss_v2=0, nll_loss=1.102, ntokens=1894.2, nsentences=56, sample_size=1894.2, sample_size_v1=0, sample_size_v2=0, ppl=2.15, wps=1102.9, ups=0.58, wpb=1894.2, bsz=56, num_updates=10140, lr=1.14842e-05, gnorm=3.073, clip=100, loss_scale=128, train_wall=17, gb_free=12.5, wall=17490
2023-06-27 21:10:25 - progress_bar.py[line:272] - INFO: epoch 011:    268 / 990 loss=2.346, loss_v1=0, loss_v2=0, nll_loss=1.142, ntokens=1839.7, nsentences=56, sample_size=1839.7, sample_size_v1=0, sample_size_v2=0, ppl=2.21, wps=1069.4, ups=0.58, wpb=1839.7, bsz=56, num_updates=10150, lr=1.14641e-05, gnorm=2.929, clip=100, loss_scale=128, train_wall=17, gb_free=12.3, wall=17507
2023-06-27 21:10:42 - progress_bar.py[line:272] - INFO: epoch 011:    278 / 990 loss=2.338, loss_v1=0, loss_v2=0, nll_loss=1.134, ntokens=1941.5, nsentences=56, sample_size=1941.5, sample_size_v1=0, sample_size_v2=0, ppl=2.19, wps=1120.4, ups=0.58, wpb=1941.5, bsz=56, num_updates=10160, lr=1.14439e-05, gnorm=2.913, clip=100, loss_scale=128, train_wall=17, gb_free=12.7, wall=17525
2023-06-27 21:10:59 - progress_bar.py[line:272] - INFO: epoch 011:    288 / 990 loss=2.339, loss_v1=0, loss_v2=0, nll_loss=1.135, ntokens=1851.2, nsentences=56, sample_size=1851.2, sample_size_v1=0, sample_size_v2=0, ppl=2.2, wps=1074.4, ups=0.58, wpb=1851.2, bsz=56, num_updates=10170, lr=1.14238e-05, gnorm=3.103, clip=100, loss_scale=128, train_wall=17, gb_free=12.6, wall=17542
2023-06-27 21:11:16 - progress_bar.py[line:272] - INFO: epoch 011:    298 / 990 loss=2.338, loss_v1=0, loss_v2=0, nll_loss=1.134, ntokens=1889.9, nsentences=56, sample_size=1889.9, sample_size_v1=0, sample_size_v2=0, ppl=2.2, wps=1101.5, ups=0.58, wpb=1889.9, bsz=56, num_updates=10180, lr=1.14036e-05, gnorm=2.981, clip=100, loss_scale=128, train_wall=17, gb_free=12.5, wall=17559
2023-06-27 21:11:34 - progress_bar.py[line:272] - INFO: epoch 011:    308 / 990 loss=2.324, loss_v1=0, loss_v2=0, nll_loss=1.117, ntokens=1878.7, nsentences=56, sample_size=1878.7, sample_size_v1=0, sample_size_v2=0, ppl=2.17, wps=1087.7, ups=0.58, wpb=1878.7, bsz=56, num_updates=10190, lr=1.13835e-05, gnorm=2.893, clip=100, loss_scale=128, train_wall=17, gb_free=12.5, wall=17576
2023-06-27 21:11:51 - progress_bar.py[line:272] - INFO: epoch 011:    318 / 990 loss=2.338, loss_v1=0, loss_v2=0, nll_loss=1.134, ntokens=1926.7, nsentences=56, sample_size=1926.7, sample_size_v1=0, sample_size_v2=0, ppl=2.19, wps=1117.5, ups=0.58, wpb=1926.7, bsz=56, num_updates=10200, lr=1.13633e-05, gnorm=3.211, clip=100, loss_scale=128, train_wall=17, gb_free=11.4, wall=17594
2023-06-27 21:12:08 - progress_bar.py[line:272] - INFO: epoch 011:    328 / 990 loss=2.32, loss_v1=0, loss_v2=0, nll_loss=1.114, ntokens=1920.6, nsentences=56, sample_size=1920.6, sample_size_v1=0, sample_size_v2=0, ppl=2.16, wps=1111.3, ups=0.58, wpb=1920.6, bsz=56, num_updates=10210, lr=1.13432e-05, gnorm=3.011, clip=100, loss_scale=128, train_wall=17, gb_free=12.5, wall=17611
2023-06-27 21:12:25 - progress_bar.py[line:272] - INFO: epoch 011:    338 / 990 loss=2.323, loss_v1=0, loss_v2=0, nll_loss=1.118, ntokens=1873.3, nsentences=56, sample_size=1873.3, sample_size_v1=0, sample_size_v2=0, ppl=2.17, wps=1085.7, ups=0.58, wpb=1873.3, bsz=56, num_updates=10220, lr=1.1323e-05, gnorm=3.279, clip=100, loss_scale=128, train_wall=17, gb_free=12.1, wall=17628
2023-06-27 21:12:43 - progress_bar.py[line:272] - INFO: epoch 011:    348 / 990 loss=2.32, loss_v1=0, loss_v2=0, nll_loss=1.114, ntokens=1887.5, nsentences=56, sample_size=1887.5, sample_size_v1=0, sample_size_v2=0, ppl=2.17, wps=1097.7, ups=0.58, wpb=1887.5, bsz=56, num_updates=10230, lr=1.13029e-05, gnorm=3.036, clip=100, loss_scale=128, train_wall=17, gb_free=12.2, wall=17645
2023-06-27 21:13:00 - progress_bar.py[line:272] - INFO: epoch 011:    358 / 990 loss=2.308, loss_v1=0, loss_v2=0, nll_loss=1.1, ntokens=1816.8, nsentences=56, sample_size=1816.8, sample_size_v1=0, sample_size_v2=0, ppl=2.14, wps=1057.7, ups=0.58, wpb=1816.8, bsz=56, num_updates=10240, lr=1.12827e-05, gnorm=3.217, clip=100, loss_scale=128, train_wall=17, gb_free=12.9, wall=17663
2023-06-27 21:13:17 - progress_bar.py[line:272] - INFO: epoch 011:    368 / 990 loss=2.344, loss_v1=0, loss_v2=0, nll_loss=1.141, ntokens=1709.4, nsentences=56, sample_size=1709.4, sample_size_v1=0, sample_size_v2=0, ppl=2.2, wps=1001.7, ups=0.59, wpb=1709.4, bsz=56, num_updates=10250, lr=1.12626e-05, gnorm=3.51, clip=100, loss_scale=128, train_wall=17, gb_free=12.5, wall=17680
2023-06-27 21:13:34 - progress_bar.py[line:272] - INFO: epoch 011:    378 / 990 loss=2.334, loss_v1=0, loss_v2=0, nll_loss=1.13, ntokens=1882.9, nsentences=56, sample_size=1882.9, sample_size_v1=0, sample_size_v2=0, ppl=2.19, wps=1103.6, ups=0.59, wpb=1882.9, bsz=56, num_updates=10260, lr=1.12424e-05, gnorm=3.44, clip=100, loss_scale=128, train_wall=17, gb_free=12.8, wall=17697
2023-06-27 21:13:51 - progress_bar.py[line:272] - INFO: epoch 011:    388 / 990 loss=2.3, loss_v1=0, loss_v2=0, nll_loss=1.091, ntokens=1828.9, nsentences=56, sample_size=1828.9, sample_size_v1=0, sample_size_v2=0, ppl=2.13, wps=1069.8, ups=0.58, wpb=1828.9, bsz=56, num_updates=10270, lr=1.12223e-05, gnorm=3.098, clip=100, loss_scale=128, train_wall=17, gb_free=12.1, wall=17714
2023-06-27 21:14:08 - progress_bar.py[line:272] - INFO: epoch 011:    398 / 990 loss=2.324, loss_v1=0, loss_v2=0, nll_loss=1.119, ntokens=1668.9, nsentences=56, sample_size=1668.9, sample_size_v1=0, sample_size_v2=0, ppl=2.17, wps=977.2, ups=0.59, wpb=1668.9, bsz=56, num_updates=10280, lr=1.12021e-05, gnorm=3.508, clip=100, loss_scale=128, train_wall=17, gb_free=12.9, wall=17731
2023-06-27 21:14:25 - progress_bar.py[line:272] - INFO: epoch 011:    408 / 990 loss=2.352, loss_v1=0, loss_v2=0, nll_loss=1.149, ntokens=1744.9, nsentences=56, sample_size=1744.9, sample_size_v1=0, sample_size_v2=0, ppl=2.22, wps=1025.3, ups=0.59, wpb=1744.9, bsz=56, num_updates=10290, lr=1.1182e-05, gnorm=3.441, clip=100, loss_scale=128, train_wall=17, gb_free=13.1, wall=17748
2023-06-27 21:14:42 - progress_bar.py[line:272] - INFO: epoch 011:    418 / 990 loss=2.331, loss_v1=0, loss_v2=0, nll_loss=1.125, ntokens=1737.8, nsentences=56, sample_size=1737.8, sample_size_v1=0, sample_size_v2=0, ppl=2.18, wps=1019.1, ups=0.59, wpb=1737.8, bsz=56, num_updates=10300, lr=1.11619e-05, gnorm=3.069, clip=100, loss_scale=128, train_wall=17, gb_free=12.8, wall=17765
2023-06-27 21:14:59 - progress_bar.py[line:272] - INFO: epoch 011:    428 / 990 loss=2.321, loss_v1=0, loss_v2=0, nll_loss=1.115, ntokens=1872, nsentences=56, sample_size=1872, sample_size_v1=0, sample_size_v2=0, ppl=2.17, wps=1092.9, ups=0.58, wpb=1872, bsz=56, num_updates=10310, lr=1.11417e-05, gnorm=3.145, clip=100, loss_scale=128, train_wall=17, gb_free=12.2, wall=17782
2023-06-27 21:15:16 - progress_bar.py[line:272] - INFO: epoch 011:    438 / 990 loss=2.319, loss_v1=0, loss_v2=0, nll_loss=1.112, ntokens=1860.7, nsentences=56, sample_size=1860.7, sample_size_v1=0, sample_size_v2=0, ppl=2.16, wps=1089.2, ups=0.59, wpb=1860.7, bsz=56, num_updates=10320, lr=1.11216e-05, gnorm=3.171, clip=100, loss_scale=128, train_wall=17, gb_free=12.9, wall=17799
2023-06-27 21:15:34 - progress_bar.py[line:272] - INFO: epoch 011:    448 / 990 loss=2.312, loss_v1=0, loss_v2=0, nll_loss=1.105, ntokens=1822.7, nsentences=56, sample_size=1822.7, sample_size_v1=0, sample_size_v2=0, ppl=2.15, wps=1068.7, ups=0.59, wpb=1822.7, bsz=56, num_updates=10330, lr=1.11014e-05, gnorm=3.225, clip=100, loss_scale=128, train_wall=17, gb_free=12.8, wall=17816
2023-06-27 21:15:51 - progress_bar.py[line:272] - INFO: epoch 011:    458 / 990 loss=2.334, loss_v1=0, loss_v2=0, nll_loss=1.13, ntokens=1786.2, nsentences=56, sample_size=1786.2, sample_size_v1=0, sample_size_v2=0, ppl=2.19, wps=1046.6, ups=0.59, wpb=1786.2, bsz=56, num_updates=10340, lr=1.10813e-05, gnorm=3.33, clip=100, loss_scale=128, train_wall=17, gb_free=12.3, wall=17833
2023-06-27 21:16:08 - progress_bar.py[line:272] - INFO: epoch 011:    468 / 990 loss=2.325, loss_v1=0, loss_v2=0, nll_loss=1.12, ntokens=1879.8, nsentences=56, sample_size=1879.8, sample_size_v1=0, sample_size_v2=0, ppl=2.17, wps=1092.8, ups=0.58, wpb=1879.8, bsz=56, num_updates=10350, lr=1.10611e-05, gnorm=3.164, clip=100, loss_scale=128, train_wall=17, gb_free=12.1, wall=17850
2023-06-27 21:16:25 - progress_bar.py[line:272] - INFO: epoch 011:    478 / 990 loss=2.314, loss_v1=0, loss_v2=0, nll_loss=1.106, ntokens=1826.4, nsentences=56, sample_size=1826.4, sample_size_v1=0, sample_size_v2=0, ppl=2.15, wps=1062.9, ups=0.58, wpb=1826.4, bsz=56, num_updates=10360, lr=1.1041e-05, gnorm=3.283, clip=100, loss_scale=128, train_wall=17, gb_free=12.4, wall=17868
2023-06-27 21:16:42 - progress_bar.py[line:272] - INFO: epoch 011:    488 / 990 loss=2.305, loss_v1=0, loss_v2=0, nll_loss=1.096, ntokens=1868.2, nsentences=56, sample_size=1868.2, sample_size_v1=0, sample_size_v2=0, ppl=2.14, wps=1089.9, ups=0.58, wpb=1868.2, bsz=56, num_updates=10370, lr=1.10208e-05, gnorm=3.043, clip=100, loss_scale=128, train_wall=17, gb_free=12.2, wall=17885
2023-06-27 21:16:59 - progress_bar.py[line:272] - INFO: epoch 011:    498 / 990 loss=2.326, loss_v1=0, loss_v2=0, nll_loss=1.12, ntokens=1855.6, nsentences=56, sample_size=1855.6, sample_size_v1=0, sample_size_v2=0, ppl=2.17, wps=1084.3, ups=0.58, wpb=1855.6, bsz=56, num_updates=10380, lr=1.10007e-05, gnorm=3.134, clip=100, loss_scale=128, train_wall=17, gb_free=12.5, wall=17902
2023-06-27 21:17:16 - progress_bar.py[line:272] - INFO: epoch 011:    508 / 990 loss=2.35, loss_v1=0, loss_v2=0, nll_loss=1.148, ntokens=1767.2, nsentences=56, sample_size=1767.2, sample_size_v1=0, sample_size_v2=0, ppl=2.22, wps=1030.9, ups=0.58, wpb=1767.2, bsz=56, num_updates=10390, lr=1.09805e-05, gnorm=3.395, clip=100, loss_scale=128, train_wall=17, gb_free=12.7, wall=17919
2023-06-27 21:17:33 - progress_bar.py[line:272] - INFO: epoch 011:    518 / 990 loss=2.321, loss_v1=0, loss_v2=0, nll_loss=1.115, ntokens=1767.4, nsentences=56, sample_size=1767.4, sample_size_v1=0, sample_size_v2=0, ppl=2.17, wps=1039.8, ups=0.59, wpb=1767.4, bsz=56, num_updates=10400, lr=1.09604e-05, gnorm=3.458, clip=100, loss_scale=128, train_wall=17, gb_free=12.9, wall=17936
2023-06-27 21:17:51 - progress_bar.py[line:272] - INFO: epoch 011:    528 / 990 loss=2.328, loss_v1=0, loss_v2=0, nll_loss=1.123, ntokens=1949.4, nsentences=56, sample_size=1949.4, sample_size_v1=0, sample_size_v2=0, ppl=2.18, wps=1132.2, ups=0.58, wpb=1949.4, bsz=56, num_updates=10410, lr=1.09402e-05, gnorm=3.108, clip=100, loss_scale=128, train_wall=17, gb_free=12.1, wall=17953
2023-06-27 21:18:04 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 128.0
2023-06-27 21:18:09 - progress_bar.py[line:272] - INFO: epoch 011:    539 / 990 loss=2.323, loss_v1=0, loss_v2=0, nll_loss=1.115, ntokens=1908.7, nsentences=56, sample_size=1908.7, sample_size_v1=0, sample_size_v2=0, ppl=2.17, wps=1015.7, ups=0.53, wpb=1908.7, bsz=56, num_updates=10420, lr=1.09201e-05, gnorm=3.387, clip=100, loss_scale=128, train_wall=19, gb_free=12.5, wall=17972
2023-06-27 21:18:27 - progress_bar.py[line:272] - INFO: epoch 011:    549 / 990 loss=2.325, loss_v1=0, loss_v2=0, nll_loss=1.119, ntokens=1940.8, nsentences=56, sample_size=1940.8, sample_size_v1=0, sample_size_v2=0, ppl=2.17, wps=1131.4, ups=0.58, wpb=1940.8, bsz=56, num_updates=10430, lr=1.08999e-05, gnorm=3.118, clip=100, loss_scale=128, train_wall=17, gb_free=11.2, wall=17989
2023-06-27 21:18:44 - progress_bar.py[line:272] - INFO: epoch 011:    559 / 990 loss=2.31, loss_v1=0, loss_v2=0, nll_loss=1.103, ntokens=1778.5, nsentences=56, sample_size=1778.5, sample_size_v1=0, sample_size_v2=0, ppl=2.15, wps=1043.6, ups=0.59, wpb=1778.5, bsz=56, num_updates=10440, lr=1.08798e-05, gnorm=3.269, clip=100, loss_scale=128, train_wall=17, gb_free=12.7, wall=18006
2023-06-27 21:19:01 - progress_bar.py[line:272] - INFO: epoch 011:    569 / 990 loss=2.307, loss_v1=0, loss_v2=0, nll_loss=1.1, ntokens=1809.2, nsentences=56, sample_size=1809.2, sample_size_v1=0, sample_size_v2=0, ppl=2.14, wps=1056.8, ups=0.58, wpb=1809.2, bsz=56, num_updates=10450, lr=1.08596e-05, gnorm=3.103, clip=100, loss_scale=128, train_wall=17, gb_free=13.1, wall=18023
2023-06-27 21:19:18 - progress_bar.py[line:272] - INFO: epoch 011:    579 / 990 loss=2.342, loss_v1=0, loss_v2=0, nll_loss=1.138, ntokens=1834.9, nsentences=56, sample_size=1834.9, sample_size_v1=0, sample_size_v2=0, ppl=2.2, wps=1075, ups=0.59, wpb=1834.9, bsz=56, num_updates=10460, lr=1.08395e-05, gnorm=3.486, clip=100, loss_scale=128, train_wall=17, gb_free=12.7, wall=18040
2023-06-27 21:19:35 - progress_bar.py[line:272] - INFO: epoch 011:    589 / 990 loss=2.341, loss_v1=0, loss_v2=0, nll_loss=1.136, ntokens=1921.2, nsentences=54.8, sample_size=1921.2, sample_size_v1=0, sample_size_v2=0, ppl=2.2, wps=1142.2, ups=0.59, wpb=1921.2, bsz=54.8, num_updates=10470, lr=1.08193e-05, gnorm=3.193, clip=100, loss_scale=128, train_wall=17, gb_free=12, wall=18057
2023-06-27 21:19:52 - progress_bar.py[line:272] - INFO: epoch 011:    599 / 990 loss=2.325, loss_v1=0, loss_v2=0, nll_loss=1.118, ntokens=1808.2, nsentences=56, sample_size=1808.2, sample_size_v1=0, sample_size_v2=0, ppl=2.17, wps=1065.4, ups=0.59, wpb=1808.2, bsz=56, num_updates=10480, lr=1.07992e-05, gnorm=3.464, clip=100, loss_scale=128, train_wall=17, gb_free=12.7, wall=18074
2023-06-27 21:20:09 - progress_bar.py[line:272] - INFO: epoch 011:    609 / 990 loss=2.31, loss_v1=0, loss_v2=0, nll_loss=1.104, ntokens=1785.9, nsentences=56, sample_size=1785.9, sample_size_v1=0, sample_size_v2=0, ppl=2.15, wps=1051.1, ups=0.59, wpb=1785.9, bsz=56, num_updates=10490, lr=1.0779e-05, gnorm=3.326, clip=100, loss_scale=128, train_wall=17, gb_free=12.8, wall=18091
2023-06-27 21:20:26 - progress_bar.py[line:272] - INFO: epoch 011:    619 / 990 loss=2.329, loss_v1=0, loss_v2=0, nll_loss=1.124, ntokens=1881.1, nsentences=56, sample_size=1881.1, sample_size_v1=0, sample_size_v2=0, ppl=2.18, wps=1102.9, ups=0.59, wpb=1881.1, bsz=56, num_updates=10500, lr=1.07589e-05, gnorm=3.384, clip=100, loss_scale=128, train_wall=17, gb_free=12.1, wall=18108
2023-06-27 21:20:43 - progress_bar.py[line:272] - INFO: epoch 011:    629 / 990 loss=2.345, loss_v1=0, loss_v2=0, nll_loss=1.14, ntokens=2052.2, nsentences=56, sample_size=2052.2, sample_size_v1=0, sample_size_v2=0, ppl=2.2, wps=1183, ups=0.58, wpb=2052.2, bsz=56, num_updates=10510, lr=1.07388e-05, gnorm=3.191, clip=100, loss_scale=128, train_wall=17, gb_free=12.2, wall=18126
2023-06-27 21:21:00 - progress_bar.py[line:272] - INFO: epoch 011:    639 / 990 loss=2.324, loss_v1=0, loss_v2=0, nll_loss=1.117, ntokens=2022.2, nsentences=56, sample_size=2022.2, sample_size_v1=0, sample_size_v2=0, ppl=2.17, wps=1174.3, ups=0.58, wpb=2022.2, bsz=56, num_updates=10520, lr=1.07186e-05, gnorm=3.066, clip=100, loss_scale=128, train_wall=17, gb_free=11.6, wall=18143
2023-06-27 21:21:17 - progress_bar.py[line:272] - INFO: epoch 011:    649 / 990 loss=2.336, loss_v1=0, loss_v2=0, nll_loss=1.132, ntokens=1950.5, nsentences=56, sample_size=1950.5, sample_size_v1=0, sample_size_v2=0, ppl=2.19, wps=1139.7, ups=0.58, wpb=1950.5, bsz=56, num_updates=10530, lr=1.06985e-05, gnorm=3.082, clip=100, loss_scale=128, train_wall=17, gb_free=12.5, wall=18160
2023-06-27 21:21:35 - progress_bar.py[line:272] - INFO: epoch 011:    659 / 990 loss=2.322, loss_v1=0, loss_v2=0, nll_loss=1.117, ntokens=1861.3, nsentences=56, sample_size=1861.3, sample_size_v1=0, sample_size_v2=0, ppl=2.17, wps=1082.5, ups=0.58, wpb=1861.3, bsz=56, num_updates=10540, lr=1.06783e-05, gnorm=3.165, clip=100, loss_scale=128, train_wall=17, gb_free=13.2, wall=18177
2023-06-27 21:21:52 - progress_bar.py[line:272] - INFO: epoch 011:    669 / 990 loss=2.333, loss_v1=0, loss_v2=0, nll_loss=1.126, ntokens=1878.3, nsentences=56, sample_size=1878.3, sample_size_v1=0, sample_size_v2=0, ppl=2.18, wps=1095.1, ups=0.58, wpb=1878.3, bsz=56, num_updates=10550, lr=1.06582e-05, gnorm=3.447, clip=100, loss_scale=128, train_wall=17, gb_free=12.7, wall=18194
2023-06-27 21:22:09 - progress_bar.py[line:272] - INFO: epoch 011:    679 / 990 loss=2.304, loss_v1=0, loss_v2=0, nll_loss=1.095, ntokens=1856.6, nsentences=56, sample_size=1856.6, sample_size_v1=0, sample_size_v2=0, ppl=2.14, wps=1083.3, ups=0.58, wpb=1856.6, bsz=56, num_updates=10560, lr=1.0638e-05, gnorm=3.24, clip=100, loss_scale=128, train_wall=17, gb_free=12.6, wall=18212
2023-06-27 21:22:26 - progress_bar.py[line:272] - INFO: epoch 011:    689 / 990 loss=2.293, loss_v1=0, loss_v2=0, nll_loss=1.085, ntokens=1830.2, nsentences=56, sample_size=1830.2, sample_size_v1=0, sample_size_v2=0, ppl=2.12, wps=1071.5, ups=0.59, wpb=1830.2, bsz=56, num_updates=10570, lr=1.06179e-05, gnorm=3.293, clip=100, loss_scale=128, train_wall=17, gb_free=12.5, wall=18229
2023-06-27 21:22:44 - progress_bar.py[line:272] - INFO: epoch 011:    699 / 990 loss=2.33, loss_v1=0, loss_v2=0, nll_loss=1.126, ntokens=1695.1, nsentences=56, sample_size=1695.1, sample_size_v1=0, sample_size_v2=0, ppl=2.18, wps=948.7, ups=0.56, wpb=1695.1, bsz=56, num_updates=10580, lr=1.05977e-05, gnorm=3.644, clip=100, loss_scale=128, train_wall=18, gb_free=13, wall=18246
2023-06-27 21:23:01 - progress_bar.py[line:272] - INFO: epoch 011:    709 / 990 loss=2.341, loss_v1=0, loss_v2=0, nll_loss=1.135, ntokens=1741.5, nsentences=56, sample_size=1741.5, sample_size_v1=0, sample_size_v2=0, ppl=2.2, wps=1021.1, ups=0.59, wpb=1741.5, bsz=56, num_updates=10590, lr=1.05776e-05, gnorm=3.433, clip=100, loss_scale=128, train_wall=17, gb_free=13.1, wall=18264
2023-06-27 21:23:19 - progress_bar.py[line:272] - INFO: epoch 011:    719 / 990 loss=2.314, loss_v1=0, loss_v2=0, nll_loss=1.106, ntokens=1770.1, nsentences=56, sample_size=1770.1, sample_size_v1=0, sample_size_v2=0, ppl=2.15, wps=994.3, ups=0.56, wpb=1770.1, bsz=56, num_updates=10600, lr=1.05574e-05, gnorm=3.233, clip=100, loss_scale=128, train_wall=18, gb_free=13, wall=18281
2023-06-27 21:23:36 - progress_bar.py[line:272] - INFO: epoch 011:    729 / 990 loss=2.302, loss_v1=0, loss_v2=0, nll_loss=1.094, ntokens=1841.5, nsentences=56, sample_size=1841.5, sample_size_v1=0, sample_size_v2=0, ppl=2.13, wps=1077.9, ups=0.59, wpb=1841.5, bsz=56, num_updates=10610, lr=1.05373e-05, gnorm=3.196, clip=100, loss_scale=128, train_wall=17, gb_free=12.5, wall=18298
2023-06-27 21:23:53 - progress_bar.py[line:272] - INFO: epoch 011:    739 / 990 loss=2.327, loss_v1=0, loss_v2=0, nll_loss=1.121, ntokens=1797.2, nsentences=56, sample_size=1797.2, sample_size_v1=0, sample_size_v2=0, ppl=2.17, wps=1054, ups=0.59, wpb=1797.2, bsz=56, num_updates=10620, lr=1.05171e-05, gnorm=3.493, clip=100, loss_scale=128, train_wall=17, gb_free=13, wall=18315
2023-06-27 21:24:10 - progress_bar.py[line:272] - INFO: epoch 011:    749 / 990 loss=2.341, loss_v1=0, loss_v2=0, nll_loss=1.136, ntokens=1680.6, nsentences=56, sample_size=1680.6, sample_size_v1=0, sample_size_v2=0, ppl=2.2, wps=985.8, ups=0.59, wpb=1680.6, bsz=56, num_updates=10630, lr=1.0497e-05, gnorm=3.397, clip=100, loss_scale=128, train_wall=17, gb_free=12.8, wall=18333
2023-06-27 21:24:27 - progress_bar.py[line:272] - INFO: epoch 011:    759 / 990 loss=2.337, loss_v1=0, loss_v2=0, nll_loss=1.134, ntokens=1704, nsentences=56, sample_size=1704, sample_size_v1=0, sample_size_v2=0, ppl=2.19, wps=1000, ups=0.59, wpb=1704, bsz=56, num_updates=10640, lr=1.04768e-05, gnorm=3.296, clip=100, loss_scale=128, train_wall=17, gb_free=12.9, wall=18350
2023-06-27 21:24:44 - progress_bar.py[line:272] - INFO: epoch 011:    769 / 990 loss=2.33, loss_v1=0, loss_v2=0, nll_loss=1.124, ntokens=1824.9, nsentences=56, sample_size=1824.9, sample_size_v1=0, sample_size_v2=0, ppl=2.18, wps=1067.9, ups=0.59, wpb=1824.9, bsz=56, num_updates=10650, lr=1.04567e-05, gnorm=3.12, clip=100, loss_scale=128, train_wall=17, gb_free=12.8, wall=18367
2023-06-27 21:25:01 - progress_bar.py[line:272] - INFO: epoch 011:    779 / 990 loss=2.308, loss_v1=0, loss_v2=0, nll_loss=1.1, ntokens=1825.6, nsentences=56, sample_size=1825.6, sample_size_v1=0, sample_size_v2=0, ppl=2.14, wps=1065.9, ups=0.58, wpb=1825.6, bsz=56, num_updates=10660, lr=1.04365e-05, gnorm=3.56, clip=100, loss_scale=128, train_wall=17, gb_free=12.2, wall=18384
2023-06-27 21:25:18 - progress_bar.py[line:272] - INFO: epoch 011:    789 / 990 loss=2.324, loss_v1=0, loss_v2=0, nll_loss=1.119, ntokens=1741.4, nsentences=56, sample_size=1741.4, sample_size_v1=0, sample_size_v2=0, ppl=2.17, wps=1022.1, ups=0.59, wpb=1741.4, bsz=56, num_updates=10670, lr=1.04164e-05, gnorm=3.492, clip=100, loss_scale=128, train_wall=17, gb_free=11.8, wall=18401
2023-06-27 21:25:35 - progress_bar.py[line:272] - INFO: epoch 011:    799 / 990 loss=2.338, loss_v1=0, loss_v2=0, nll_loss=1.135, ntokens=1838.7, nsentences=56, sample_size=1838.7, sample_size_v1=0, sample_size_v2=0, ppl=2.2, wps=1076.1, ups=0.59, wpb=1838.7, bsz=56, num_updates=10680, lr=1.03962e-05, gnorm=3.2, clip=100, loss_scale=128, train_wall=17, gb_free=12.9, wall=18418
2023-06-27 21:25:52 - progress_bar.py[line:272] - INFO: epoch 011:    809 / 990 loss=2.331, loss_v1=0, loss_v2=0, nll_loss=1.125, ntokens=1747.9, nsentences=56, sample_size=1747.9, sample_size_v1=0, sample_size_v2=0, ppl=2.18, wps=1024.4, ups=0.59, wpb=1747.9, bsz=56, num_updates=10690, lr=1.03761e-05, gnorm=3.352, clip=100, loss_scale=128, train_wall=17, gb_free=13, wall=18435
2023-06-27 21:26:09 - progress_bar.py[line:272] - INFO: epoch 011:    819 / 990 loss=2.34, loss_v1=0, loss_v2=0, nll_loss=1.137, ntokens=1648.8, nsentences=56, sample_size=1648.8, sample_size_v1=0, sample_size_v2=0, ppl=2.2, wps=967.8, ups=0.59, wpb=1648.8, bsz=56, num_updates=10700, lr=1.03559e-05, gnorm=3.532, clip=100, loss_scale=128, train_wall=17, gb_free=12.8, wall=18452
2023-06-27 21:26:26 - progress_bar.py[line:272] - INFO: epoch 011:    829 / 990 loss=2.297, loss_v1=0, loss_v2=0, nll_loss=1.089, ntokens=1759, nsentences=56, sample_size=1759, sample_size_v1=0, sample_size_v2=0, ppl=2.13, wps=1031, ups=0.59, wpb=1759, bsz=56, num_updates=10710, lr=1.03358e-05, gnorm=3.389, clip=100, loss_scale=128, train_wall=17, gb_free=12.8, wall=18469
2023-06-27 21:26:44 - progress_bar.py[line:272] - INFO: epoch 011:    839 / 990 loss=2.315, loss_v1=0, loss_v2=0, nll_loss=1.108, ntokens=1765, nsentences=56, sample_size=1765, sample_size_v1=0, sample_size_v2=0, ppl=2.16, wps=1034.5, ups=0.59, wpb=1765, bsz=56, num_updates=10720, lr=1.03156e-05, gnorm=3.27, clip=100, loss_scale=128, train_wall=17, gb_free=12.6, wall=18486
2023-06-27 21:27:01 - progress_bar.py[line:272] - INFO: epoch 011:    849 / 990 loss=2.298, loss_v1=0, loss_v2=0, nll_loss=1.089, ntokens=1902.3, nsentences=56, sample_size=1902.3, sample_size_v1=0, sample_size_v2=0, ppl=2.13, wps=1113.6, ups=0.59, wpb=1902.3, bsz=56, num_updates=10730, lr=1.02955e-05, gnorm=3.4, clip=100, loss_scale=128, train_wall=17, gb_free=13, wall=18503
2023-06-27 21:27:18 - progress_bar.py[line:272] - INFO: epoch 011:    859 / 990 loss=2.293, loss_v1=0, loss_v2=0, nll_loss=1.082, ntokens=1808.2, nsentences=56, sample_size=1808.2, sample_size_v1=0, sample_size_v2=0, ppl=2.12, wps=1054.3, ups=0.58, wpb=1808.2, bsz=56, num_updates=10740, lr=1.02754e-05, gnorm=3.104, clip=100, loss_scale=128, train_wall=17, gb_free=12.4, wall=18520
2023-06-27 21:27:35 - progress_bar.py[line:272] - INFO: epoch 011:    869 / 990 loss=2.311, loss_v1=0, loss_v2=0, nll_loss=1.104, ntokens=1863.9, nsentences=56, sample_size=1863.9, sample_size_v1=0, sample_size_v2=0, ppl=2.15, wps=1086.5, ups=0.58, wpb=1863.9, bsz=56, num_updates=10750, lr=1.02552e-05, gnorm=3.211, clip=100, loss_scale=128, train_wall=17, gb_free=12.4, wall=18538
2023-06-27 21:27:52 - progress_bar.py[line:272] - INFO: epoch 011:    879 / 990 loss=2.297, loss_v1=0, loss_v2=0, nll_loss=1.089, ntokens=1825.2, nsentences=56, sample_size=1825.2, sample_size_v1=0, sample_size_v2=0, ppl=2.13, wps=1071.5, ups=0.59, wpb=1825.2, bsz=56, num_updates=10760, lr=1.02351e-05, gnorm=3.211, clip=100, loss_scale=128, train_wall=17, gb_free=13.1, wall=18555
2023-06-27 21:28:09 - progress_bar.py[line:272] - INFO: epoch 011:    889 / 990 loss=2.298, loss_v1=0, loss_v2=0, nll_loss=1.088, ntokens=2016.1, nsentences=56, sample_size=2016.1, sample_size_v1=0, sample_size_v2=0, ppl=2.13, wps=1172.8, ups=0.58, wpb=2016.1, bsz=56, num_updates=10770, lr=1.02149e-05, gnorm=3, clip=100, loss_scale=128, train_wall=17, gb_free=13, wall=18572
2023-06-27 21:28:26 - progress_bar.py[line:272] - INFO: epoch 011:    899 / 990 loss=2.322, loss_v1=0, loss_v2=0, nll_loss=1.116, ntokens=1785.3, nsentences=56, sample_size=1785.3, sample_size_v1=0, sample_size_v2=0, ppl=2.17, wps=1043.7, ups=0.58, wpb=1785.3, bsz=56, num_updates=10780, lr=1.01948e-05, gnorm=3.282, clip=100, loss_scale=128, train_wall=17, gb_free=13.1, wall=18589
2023-06-27 21:28:43 - progress_bar.py[line:272] - INFO: epoch 011:    909 / 990 loss=2.326, loss_v1=0, loss_v2=0, nll_loss=1.121, ntokens=1833.1, nsentences=56, sample_size=1833.1, sample_size_v1=0, sample_size_v2=0, ppl=2.18, wps=1073.2, ups=0.59, wpb=1833.1, bsz=56, num_updates=10790, lr=1.01746e-05, gnorm=3.339, clip=100, loss_scale=128, train_wall=17, gb_free=12.4, wall=18606
2023-06-27 21:29:00 - progress_bar.py[line:272] - INFO: epoch 011:    919 / 990 loss=2.311, loss_v1=0, loss_v2=0, nll_loss=1.103, ntokens=1682.9, nsentences=56, sample_size=1682.9, sample_size_v1=0, sample_size_v2=0, ppl=2.15, wps=990.7, ups=0.59, wpb=1682.9, bsz=56, num_updates=10800, lr=1.01545e-05, gnorm=3.323, clip=100, loss_scale=128, train_wall=17, gb_free=12.7, wall=18623
2023-06-27 21:29:18 - progress_bar.py[line:272] - INFO: epoch 011:    929 / 990 loss=2.29, loss_v1=0, loss_v2=0, nll_loss=1.08, ntokens=1885, nsentences=56, sample_size=1885, sample_size_v1=0, sample_size_v2=0, ppl=2.11, wps=1095.8, ups=0.58, wpb=1885, bsz=56, num_updates=10810, lr=1.01343e-05, gnorm=3.431, clip=100, loss_scale=128, train_wall=17, gb_free=11.2, wall=18640
2023-06-27 21:29:35 - progress_bar.py[line:272] - INFO: epoch 011:    939 / 990 loss=2.309, loss_v1=0, loss_v2=0, nll_loss=1.1, ntokens=1813.2, nsentences=56, sample_size=1813.2, sample_size_v1=0, sample_size_v2=0, ppl=2.14, wps=1062.3, ups=0.59, wpb=1813.2, bsz=56, num_updates=10820, lr=1.01142e-05, gnorm=3.385, clip=100, loss_scale=128, train_wall=17, gb_free=12, wall=18657
2023-06-27 21:29:52 - progress_bar.py[line:272] - INFO: epoch 011:    949 / 990 loss=2.297, loss_v1=0, loss_v2=0, nll_loss=1.088, ntokens=1919.5, nsentences=56, sample_size=1919.5, sample_size_v1=0, sample_size_v2=0, ppl=2.13, wps=1115.4, ups=0.58, wpb=1919.5, bsz=56, num_updates=10830, lr=1.0094e-05, gnorm=3.168, clip=100, loss_scale=128, train_wall=17, gb_free=13, wall=18674
2023-06-27 21:30:09 - progress_bar.py[line:272] - INFO: epoch 011:    959 / 990 loss=2.314, loss_v1=0, loss_v2=0, nll_loss=1.107, ntokens=1852.6, nsentences=56, sample_size=1852.6, sample_size_v1=0, sample_size_v2=0, ppl=2.15, wps=1084.3, ups=0.59, wpb=1852.6, bsz=56, num_updates=10840, lr=1.00739e-05, gnorm=3.363, clip=100, loss_scale=128, train_wall=17, gb_free=12.8, wall=18692
2023-06-27 21:30:26 - progress_bar.py[line:272] - INFO: epoch 011:    969 / 990 loss=2.304, loss_v1=0, loss_v2=0, nll_loss=1.096, ntokens=1955.5, nsentences=56, sample_size=1955.5, sample_size_v1=0, sample_size_v2=0, ppl=2.14, wps=1139.1, ups=0.58, wpb=1955.5, bsz=56, num_updates=10850, lr=1.00537e-05, gnorm=3.162, clip=100, loss_scale=128, train_wall=17, gb_free=12.1, wall=18709
2023-06-27 21:30:43 - progress_bar.py[line:272] - INFO: epoch 011:    979 / 990 loss=2.306, loss_v1=0, loss_v2=0, nll_loss=1.099, ntokens=1834.6, nsentences=56, sample_size=1834.6, sample_size_v1=0, sample_size_v2=0, ppl=2.14, wps=1072.8, ups=0.58, wpb=1834.6, bsz=56, num_updates=10860, lr=1.00336e-05, gnorm=3.348, clip=100, loss_scale=128, train_wall=17, gb_free=12.8, wall=18726
2023-06-27 21:31:00 - progress_bar.py[line:272] - INFO: epoch 011:    989 / 990 loss=2.338, loss_v1=0, loss_v2=0, nll_loss=1.132, ntokens=1847.5, nsentences=56, sample_size=1847.5, sample_size_v1=0, sample_size_v2=0, ppl=2.19, wps=1085.3, ups=0.59, wpb=1847.5, bsz=56, num_updates=10870, lr=1.00134e-05, gnorm=3.296, clip=100, loss_scale=128, train_wall=17, gb_free=13, wall=18743
local datafile ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 1 begin to initialize row_count and line_idx-to-offset mapping
2023-06-27 21:31:01 - train.py[line:332] - INFO: end of epoch 11 (average epoch stats below)
2023-06-27 21:31:01 - progress_bar.py[line:282] - INFO: epoch 011 | loss 2.305 | loss_v1 0 | loss_v2 0 | nll_loss 1.096 | ntokens 1849.99 | nsentences 55.96 | sample_size 1849.99 | sample_size_v1 0 | sample_size_v2 0 | ppl 2.14 | wps 1072.6 | ups 0.58 | wpb 1850 | bsz 56 | num_updates 10871 | lr 1.00114e-05 | gnorm 3.177 | clip 100 | loss_scale 128 | train_wall 1698 | gb_free 13.3 | wall 18744
2023-06-27 21:31:01 - trainer.py[line:639] - INFO: loading train data for epoch 12
local datafile ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 0 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 1 finished initializing row_count and line_idx-to-offset mapping
file ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 1 row count 27700 total row count 55400
local datafile ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 0 finished initializing row_count and line_idx-to-offset mapping
file ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 0 row count 27700 total row count 55400
slice_id 1 seek offset 27700
slice_id 0 seek offset 0
2023-06-27 21:31:03 - trainer.py[line:703] - INFO: begin training epoch 12
2023-06-27 21:31:03 - train.py[line:305] - INFO: Start iterating over samples
2023-06-27 21:31:19 - progress_bar.py[line:272] - INFO: epoch 012:      9 / 990 loss=2.266, loss_v1=0, loss_v2=0, nll_loss=1.053, ntokens=1801.7, nsentences=53.2, sample_size=1801.7, sample_size_v1=0, sample_size_v2=0, ppl=2.08, wps=960.6, ups=0.53, wpb=1801.7, bsz=53.2, num_updates=10880, lr=9.99328e-06, gnorm=3.409, clip=100, loss_scale=128, train_wall=16, gb_free=11.8, wall=18762
2023-06-27 21:31:36 - progress_bar.py[line:272] - INFO: epoch 012:     19 / 990 loss=2.251, loss_v1=0, loss_v2=0, nll_loss=1.038, ntokens=1799.4, nsentences=56, sample_size=1799.4, sample_size_v1=0, sample_size_v2=0, ppl=2.05, wps=1042.9, ups=0.58, wpb=1799.4, bsz=56, num_updates=10890, lr=9.97314e-06, gnorm=3.334, clip=100, loss_scale=128, train_wall=17, gb_free=12.1, wall=18779
2023-06-27 21:31:53 - progress_bar.py[line:272] - INFO: epoch 012:     29 / 990 loss=2.272, loss_v1=0, loss_v2=0, nll_loss=1.061, ntokens=1733.6, nsentences=56, sample_size=1733.6, sample_size_v1=0, sample_size_v2=0, ppl=2.09, wps=1015.4, ups=0.59, wpb=1733.6, bsz=56, num_updates=10900, lr=9.95299e-06, gnorm=3.294, clip=100, loss_scale=128, train_wall=17, gb_free=12.9, wall=18796
2023-06-27 21:32:11 - progress_bar.py[line:272] - INFO: epoch 012:     39 / 990 loss=2.196, loss_v1=0, loss_v2=0, nll_loss=0.974, ntokens=1907.3, nsentences=56, sample_size=1907.3, sample_size_v1=0, sample_size_v2=0, ppl=1.96, wps=1104.2, ups=0.58, wpb=1907.3, bsz=56, num_updates=10910, lr=9.93284e-06, gnorm=2.98, clip=100, loss_scale=128, train_wall=17, gb_free=11.9, wall=18813
2023-06-27 21:32:28 - progress_bar.py[line:272] - INFO: epoch 012:     49 / 990 loss=2.206, loss_v1=0, loss_v2=0, nll_loss=0.99, ntokens=1848.4, nsentences=56, sample_size=1848.4, sample_size_v1=0, sample_size_v2=0, ppl=1.99, wps=1066.5, ups=0.58, wpb=1848.4, bsz=56, num_updates=10920, lr=9.91269e-06, gnorm=3.042, clip=100, loss_scale=128, train_wall=17, gb_free=12.4, wall=18831
2023-06-27 21:32:45 - progress_bar.py[line:272] - INFO: epoch 012:     59 / 990 loss=2.254, loss_v1=0, loss_v2=0, nll_loss=1.04, ntokens=1763.3, nsentences=56, sample_size=1763.3, sample_size_v1=0, sample_size_v2=0, ppl=2.06, wps=1022.2, ups=0.58, wpb=1763.3, bsz=56, num_updates=10930, lr=9.89255e-06, gnorm=3.408, clip=100, loss_scale=256, train_wall=17, gb_free=12.5, wall=18848
2023-06-27 21:32:47 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 128.0
2023-06-27 21:33:04 - progress_bar.py[line:272] - INFO: epoch 012:     70 / 990 loss=2.116, loss_v1=0, loss_v2=0, nll_loss=0.886, ntokens=1947.6, nsentences=56, sample_size=1947.6, sample_size_v1=0, sample_size_v2=0, ppl=1.85, wps=1014, ups=0.52, wpb=1947.6, bsz=56, num_updates=10940, lr=9.8724e-06, gnorm=3.126, clip=100, loss_scale=128, train_wall=19, gb_free=11.2, wall=18867
2023-06-27 21:33:22 - progress_bar.py[line:272] - INFO: epoch 012:     80 / 990 loss=2.149, loss_v1=0, loss_v2=0, nll_loss=0.922, ntokens=2179.3, nsentences=56, sample_size=2179.3, sample_size_v1=0, sample_size_v2=0, ppl=1.9, wps=1230.3, ups=0.56, wpb=2179.3, bsz=56, num_updates=10950, lr=9.85225e-06, gnorm=2.759, clip=100, loss_scale=128, train_wall=18, gb_free=11.7, wall=18885
2023-06-27 21:33:40 - progress_bar.py[line:272] - INFO: epoch 012:     90 / 990 loss=2.187, loss_v1=0, loss_v2=0, nll_loss=0.965, ntokens=2082.6, nsentences=56, sample_size=2082.6, sample_size_v1=0, sample_size_v2=0, ppl=1.95, wps=1174.8, ups=0.56, wpb=2082.6, bsz=56, num_updates=10960, lr=9.8321e-06, gnorm=3.061, clip=100, loss_scale=128, train_wall=18, gb_free=11.6, wall=18903
2023-06-27 21:33:57 - progress_bar.py[line:272] - INFO: epoch 012:    100 / 990 loss=2.242, loss_v1=0, loss_v2=0, nll_loss=1.025, ntokens=1854.4, nsentences=56, sample_size=1854.4, sample_size_v1=0, sample_size_v2=0, ppl=2.04, wps=1073.7, ups=0.58, wpb=1854.4, bsz=56, num_updates=10970, lr=9.81195e-06, gnorm=3.471, clip=100, loss_scale=128, train_wall=17, gb_free=12.5, wall=18920
2023-06-27 21:34:14 - progress_bar.py[line:272] - INFO: epoch 012:    110 / 990 loss=2.213, loss_v1=0, loss_v2=0, nll_loss=0.994, ntokens=1883, nsentences=56, sample_size=1883, sample_size_v1=0, sample_size_v2=0, ppl=1.99, wps=1094.8, ups=0.58, wpb=1883, bsz=56, num_updates=10980, lr=9.79181e-06, gnorm=3.422, clip=100, loss_scale=128, train_wall=17, gb_free=12.1, wall=18937
2023-06-27 21:34:31 - progress_bar.py[line:272] - INFO: epoch 012:    120 / 990 loss=2.301, loss_v1=0, loss_v2=0, nll_loss=1.092, ntokens=1794, nsentences=56, sample_size=1794, sample_size_v1=0, sample_size_v2=0, ppl=2.13, wps=1044.6, ups=0.58, wpb=1794, bsz=56, num_updates=10990, lr=9.77166e-06, gnorm=3.518, clip=100, loss_scale=128, train_wall=17, gb_free=12.6, wall=18954
2023-06-27 21:34:49 - progress_bar.py[line:272] - INFO: epoch 012:    130 / 990 loss=2.319, loss_v1=0, loss_v2=0, nll_loss=1.113, ntokens=1808.4, nsentences=56, sample_size=1808.4, sample_size_v1=0, sample_size_v2=0, ppl=2.16, wps=1049, ups=0.58, wpb=1808.4, bsz=56, num_updates=11000, lr=9.75151e-06, gnorm=3.195, clip=100, loss_scale=128, train_wall=17, gb_free=12.7, wall=18971
2023-06-27 21:35:06 - progress_bar.py[line:272] - INFO: epoch 012:    140 / 990 loss=2.294, loss_v1=0, loss_v2=0, nll_loss=1.083, ntokens=1930.2, nsentences=56, sample_size=1930.2, sample_size_v1=0, sample_size_v2=0, ppl=2.12, wps=1108.4, ups=0.57, wpb=1930.2, bsz=56, num_updates=11010, lr=9.73136e-06, gnorm=3.167, clip=100, loss_scale=128, train_wall=17, gb_free=11.7, wall=18989
2023-06-27 21:35:24 - progress_bar.py[line:272] - INFO: epoch 012:    150 / 990 loss=2.272, loss_v1=0, loss_v2=0, nll_loss=1.058, ntokens=1959.9, nsentences=56, sample_size=1959.9, sample_size_v1=0, sample_size_v2=0, ppl=2.08, wps=1123.4, ups=0.57, wpb=1959.9, bsz=56, num_updates=11020, lr=9.71122e-06, gnorm=2.988, clip=100, loss_scale=128, train_wall=17, gb_free=12.2, wall=19006
2023-06-27 21:35:41 - progress_bar.py[line:272] - INFO: epoch 012:    160 / 990 loss=2.259, loss_v1=0, loss_v2=0, nll_loss=1.045, ntokens=1996, nsentences=56, sample_size=1996, sample_size_v1=0, sample_size_v2=0, ppl=2.06, wps=1142.1, ups=0.57, wpb=1996, bsz=56, num_updates=11030, lr=9.69107e-06, gnorm=3.082, clip=100, loss_scale=128, train_wall=17, gb_free=11.3, wall=19024
2023-06-27 21:35:58 - progress_bar.py[line:272] - INFO: epoch 012:    170 / 990 loss=2.248, loss_v1=0, loss_v2=0, nll_loss=1.035, ntokens=1907.6, nsentences=56, sample_size=1907.6, sample_size_v1=0, sample_size_v2=0, ppl=2.05, wps=1095.9, ups=0.57, wpb=1907.6, bsz=56, num_updates=11040, lr=9.67092e-06, gnorm=3.029, clip=100, loss_scale=128, train_wall=17, gb_free=12.1, wall=19041
2023-06-27 21:36:16 - progress_bar.py[line:272] - INFO: epoch 012:    180 / 990 loss=2.271, loss_v1=0, loss_v2=0, nll_loss=1.06, ntokens=1986.2, nsentences=56, sample_size=1986.2, sample_size_v1=0, sample_size_v2=0, ppl=2.08, wps=1137.4, ups=0.57, wpb=1986.2, bsz=56, num_updates=11050, lr=9.65077e-06, gnorm=3.04, clip=100, loss_scale=128, train_wall=17, gb_free=12.6, wall=19059
2023-06-27 21:36:33 - progress_bar.py[line:272] - INFO: epoch 012:    190 / 990 loss=2.267, loss_v1=0, loss_v2=0, nll_loss=1.053, ntokens=1882.3, nsentences=56, sample_size=1882.3, sample_size_v1=0, sample_size_v2=0, ppl=2.07, wps=1092.6, ups=0.58, wpb=1882.3, bsz=56, num_updates=11060, lr=9.63062e-06, gnorm=3.369, clip=100, loss_scale=128, train_wall=17, gb_free=12.6, wall=19076
2023-06-27 21:36:50 - progress_bar.py[line:272] - INFO: epoch 012:    200 / 990 loss=2.265, loss_v1=0, loss_v2=0, nll_loss=1.051, ntokens=1760.5, nsentences=56, sample_size=1760.5, sample_size_v1=0, sample_size_v2=0, ppl=2.07, wps=1026.6, ups=0.58, wpb=1760.5, bsz=56, num_updates=11070, lr=9.61048e-06, gnorm=3.523, clip=100, loss_scale=128, train_wall=17, gb_free=12.1, wall=19093
2023-06-27 21:37:08 - progress_bar.py[line:272] - INFO: epoch 012:    210 / 990 loss=2.254, loss_v1=0, loss_v2=0, nll_loss=1.04, ntokens=1940.2, nsentences=56, sample_size=1940.2, sample_size_v1=0, sample_size_v2=0, ppl=2.06, wps=1117.1, ups=0.58, wpb=1940.2, bsz=56, num_updates=11080, lr=9.59033e-06, gnorm=3.24, clip=100, loss_scale=128, train_wall=17, gb_free=12.6, wall=19110
2023-06-27 21:37:25 - progress_bar.py[line:272] - INFO: epoch 012:    220 / 990 loss=2.252, loss_v1=0, loss_v2=0, nll_loss=1.039, ntokens=1961.1, nsentences=56, sample_size=1961.1, sample_size_v1=0, sample_size_v2=0, ppl=2.05, wps=1128.1, ups=0.58, wpb=1961.1, bsz=56, num_updates=11090, lr=9.57018e-06, gnorm=3.058, clip=100, loss_scale=128, train_wall=17, gb_free=12, wall=19128
2023-06-27 21:37:42 - progress_bar.py[line:272] - INFO: epoch 012:    230 / 990 loss=2.283, loss_v1=0, loss_v2=0, nll_loss=1.071, ntokens=1856, nsentences=56, sample_size=1856, sample_size_v1=0, sample_size_v2=0, ppl=2.1, wps=1076.8, ups=0.58, wpb=1856, bsz=56, num_updates=11100, lr=9.55003e-06, gnorm=3.395, clip=100, loss_scale=128, train_wall=17, gb_free=12.4, wall=19145
2023-06-27 21:38:00 - progress_bar.py[line:272] - INFO: epoch 012:    240 / 990 loss=2.324, loss_v1=0, loss_v2=0, nll_loss=1.118, ntokens=1736.9, nsentences=56, sample_size=1736.9, sample_size_v1=0, sample_size_v2=0, ppl=2.17, wps=1012.5, ups=0.58, wpb=1736.9, bsz=56, num_updates=11110, lr=9.52989e-06, gnorm=3.457, clip=100, loss_scale=128, train_wall=17, gb_free=12.6, wall=19162
2023-06-27 21:38:17 - progress_bar.py[line:272] - INFO: epoch 012:    250 / 990 loss=2.32, loss_v1=0, loss_v2=0, nll_loss=1.114, ntokens=1933.7, nsentences=56, sample_size=1933.7, sample_size_v1=0, sample_size_v2=0, ppl=2.16, wps=1126.1, ups=0.58, wpb=1933.7, bsz=56, num_updates=11120, lr=9.50974e-06, gnorm=3.393, clip=100, loss_scale=128, train_wall=17, gb_free=12.4, wall=19179
2023-06-27 21:38:34 - progress_bar.py[line:272] - INFO: epoch 012:    260 / 990 loss=2.312, loss_v1=0, loss_v2=0, nll_loss=1.104, ntokens=1914.5, nsentences=56, sample_size=1914.5, sample_size_v1=0, sample_size_v2=0, ppl=2.15, wps=1114.3, ups=0.58, wpb=1914.5, bsz=56, num_updates=11130, lr=9.48959e-06, gnorm=3.168, clip=100, loss_scale=128, train_wall=17, gb_free=12.8, wall=19197
2023-06-27 21:38:51 - progress_bar.py[line:272] - INFO: epoch 012:    270 / 990 loss=2.346, loss_v1=0, loss_v2=0, nll_loss=1.142, ntokens=1837.2, nsentences=56, sample_size=1837.2, sample_size_v1=0, sample_size_v2=0, ppl=2.21, wps=1068.4, ups=0.58, wpb=1837.2, bsz=56, num_updates=11140, lr=9.46944e-06, gnorm=3.525, clip=100, loss_scale=128, train_wall=17, gb_free=12.6, wall=19214
2023-06-27 21:39:08 - progress_bar.py[line:272] - INFO: epoch 012:    280 / 990 loss=2.32, loss_v1=0, loss_v2=0, nll_loss=1.114, ntokens=1965.8, nsentences=56, sample_size=1965.8, sample_size_v1=0, sample_size_v2=0, ppl=2.16, wps=1132.9, ups=0.58, wpb=1965.8, bsz=56, num_updates=11150, lr=9.44929e-06, gnorm=2.943, clip=100, loss_scale=128, train_wall=17, gb_free=12.4, wall=19231
2023-06-27 21:39:26 - progress_bar.py[line:272] - INFO: epoch 012:    290 / 990 loss=2.327, loss_v1=0, loss_v2=0, nll_loss=1.123, ntokens=1835.2, nsentences=56, sample_size=1835.2, sample_size_v1=0, sample_size_v2=0, ppl=2.18, wps=1068.9, ups=0.58, wpb=1835.2, bsz=56, num_updates=11160, lr=9.42915e-06, gnorm=3.425, clip=100, loss_scale=128, train_wall=17, gb_free=12.5, wall=19248
2023-06-27 21:39:43 - progress_bar.py[line:272] - INFO: epoch 012:    300 / 990 loss=2.338, loss_v1=0, loss_v2=0, nll_loss=1.133, ntokens=1894.2, nsentences=56, sample_size=1894.2, sample_size_v1=0, sample_size_v2=0, ppl=2.19, wps=1105.4, ups=0.58, wpb=1894.2, bsz=56, num_updates=11170, lr=9.409e-06, gnorm=3.308, clip=100, loss_scale=128, train_wall=17, gb_free=12.8, wall=19265
2023-06-27 21:40:00 - progress_bar.py[line:272] - INFO: epoch 012:    310 / 990 loss=2.312, loss_v1=0, loss_v2=0, nll_loss=1.105, ntokens=1893.1, nsentences=56, sample_size=1893.1, sample_size_v1=0, sample_size_v2=0, ppl=2.15, wps=1096.1, ups=0.58, wpb=1893.1, bsz=56, num_updates=11180, lr=9.38885e-06, gnorm=3.088, clip=100, loss_scale=128, train_wall=17, gb_free=12.4, wall=19283
2023-06-27 21:40:17 - progress_bar.py[line:272] - INFO: epoch 012:    320 / 990 loss=2.333, loss_v1=0, loss_v2=0, nll_loss=1.128, ntokens=1919, nsentences=56, sample_size=1919, sample_size_v1=0, sample_size_v2=0, ppl=2.19, wps=1112.3, ups=0.58, wpb=1919, bsz=56, num_updates=11190, lr=9.3687e-06, gnorm=3.29, clip=100, loss_scale=128, train_wall=17, gb_free=11.9, wall=19300
2023-06-27 21:40:34 - progress_bar.py[line:272] - INFO: epoch 012:    330 / 990 loss=2.312, loss_v1=0, loss_v2=0, nll_loss=1.106, ntokens=1916.4, nsentences=56, sample_size=1916.4, sample_size_v1=0, sample_size_v2=0, ppl=2.15, wps=1112.3, ups=0.58, wpb=1916.4, bsz=56, num_updates=11200, lr=9.34856e-06, gnorm=3.078, clip=100, loss_scale=128, train_wall=17, gb_free=13.1, wall=19317
2023-06-27 21:40:52 - progress_bar.py[line:272] - INFO: epoch 012:    340 / 990 loss=2.311, loss_v1=0, loss_v2=0, nll_loss=1.106, ntokens=1836.1, nsentences=56, sample_size=1836.1, sample_size_v1=0, sample_size_v2=0, ppl=2.15, wps=1068.4, ups=0.58, wpb=1836.1, bsz=56, num_updates=11210, lr=9.32841e-06, gnorm=3.399, clip=100, loss_scale=128, train_wall=17, gb_free=12, wall=19334
2023-06-27 21:41:09 - progress_bar.py[line:272] - INFO: epoch 012:    350 / 990 loss=2.304, loss_v1=0, loss_v2=0, nll_loss=1.096, ntokens=1897.3, nsentences=56, sample_size=1897.3, sample_size_v1=0, sample_size_v2=0, ppl=2.14, wps=1102, ups=0.58, wpb=1897.3, bsz=56, num_updates=11220, lr=9.30826e-06, gnorm=3.275, clip=100, loss_scale=128, train_wall=17, gb_free=12.5, wall=19352
2023-06-27 21:41:26 - progress_bar.py[line:272] - INFO: epoch 012:    360 / 990 loss=2.313, loss_v1=0, loss_v2=0, nll_loss=1.106, ntokens=1794.9, nsentences=56, sample_size=1794.9, sample_size_v1=0, sample_size_v2=0, ppl=2.15, wps=1053.1, ups=0.59, wpb=1794.9, bsz=56, num_updates=11230, lr=9.28811e-06, gnorm=3.678, clip=100, loss_scale=128, train_wall=17, gb_free=12.6, wall=19369
2023-06-27 21:41:43 - progress_bar.py[line:272] - INFO: epoch 012:    370 / 990 loss=2.34, loss_v1=0, loss_v2=0, nll_loss=1.136, ntokens=1751.6, nsentences=56, sample_size=1751.6, sample_size_v1=0, sample_size_v2=0, ppl=2.2, wps=1016.1, ups=0.58, wpb=1751.6, bsz=56, num_updates=11240, lr=9.26797e-06, gnorm=3.811, clip=100, loss_scale=128, train_wall=17, gb_free=12.8, wall=19386
2023-06-27 21:42:00 - progress_bar.py[line:272] - INFO: epoch 012:    380 / 990 loss=2.319, loss_v1=0, loss_v2=0, nll_loss=1.113, ntokens=1896.8, nsentences=56, sample_size=1896.8, sample_size_v1=0, sample_size_v2=0, ppl=2.16, wps=1108.7, ups=0.58, wpb=1896.8, bsz=56, num_updates=11250, lr=9.24782e-06, gnorm=3.518, clip=100, loss_scale=128, train_wall=17, gb_free=12.4, wall=19403
2023-06-27 21:42:17 - progress_bar.py[line:272] - INFO: epoch 012:    390 / 990 loss=2.3, loss_v1=0, loss_v2=0, nll_loss=1.091, ntokens=1762.4, nsentences=56, sample_size=1762.4, sample_size_v1=0, sample_size_v2=0, ppl=2.13, wps=1033.6, ups=0.59, wpb=1762.4, bsz=56, num_updates=11260, lr=9.22767e-06, gnorm=3.55, clip=100, loss_scale=128, train_wall=17, gb_free=12.8, wall=19420
2023-06-27 21:42:34 - progress_bar.py[line:272] - INFO: epoch 012:    400 / 990 loss=2.325, loss_v1=0, loss_v2=0, nll_loss=1.119, ntokens=1702.5, nsentences=56, sample_size=1702.5, sample_size_v1=0, sample_size_v2=0, ppl=2.17, wps=1000.5, ups=0.59, wpb=1702.5, bsz=56, num_updates=11270, lr=9.20752e-06, gnorm=3.781, clip=100, loss_scale=128, train_wall=17, gb_free=12.8, wall=19437
2023-06-27 21:42:51 - progress_bar.py[line:272] - INFO: epoch 012:    410 / 990 loss=2.34, loss_v1=0, loss_v2=0, nll_loss=1.137, ntokens=1730.1, nsentences=56, sample_size=1730.1, sample_size_v1=0, sample_size_v2=0, ppl=2.2, wps=1016.8, ups=0.59, wpb=1730.1, bsz=56, num_updates=11280, lr=9.18737e-06, gnorm=3.768, clip=100, loss_scale=128, train_wall=17, gb_free=13, wall=19454
2023-06-27 21:43:08 - progress_bar.py[line:272] - INFO: epoch 012:    420 / 990 loss=2.327, loss_v1=0, loss_v2=0, nll_loss=1.12, ntokens=1752.9, nsentences=56, sample_size=1752.9, sample_size_v1=0, sample_size_v2=0, ppl=2.17, wps=1028.7, ups=0.59, wpb=1752.9, bsz=56, num_updates=11290, lr=9.16723e-06, gnorm=3.608, clip=100, loss_scale=128, train_wall=17, gb_free=12.6, wall=19471
2023-06-27 21:43:26 - progress_bar.py[line:272] - INFO: epoch 012:    430 / 990 loss=2.309, loss_v1=0, loss_v2=0, nll_loss=1.1, ntokens=1883.8, nsentences=56, sample_size=1883.8, sample_size_v1=0, sample_size_v2=0, ppl=2.14, wps=1099.2, ups=0.58, wpb=1883.8, bsz=56, num_updates=11300, lr=9.14708e-06, gnorm=3.499, clip=100, loss_scale=128, train_wall=17, gb_free=12.5, wall=19488
2023-06-27 21:43:43 - progress_bar.py[line:272] - INFO: epoch 012:    440 / 990 loss=2.311, loss_v1=0, loss_v2=0, nll_loss=1.104, ntokens=1885.3, nsentences=56, sample_size=1885.3, sample_size_v1=0, sample_size_v2=0, ppl=2.15, wps=1103.2, ups=0.59, wpb=1885.3, bsz=56, num_updates=11310, lr=9.12693e-06, gnorm=3.324, clip=100, loss_scale=128, train_wall=17, gb_free=12.7, wall=19505
2023-06-27 21:44:00 - progress_bar.py[line:272] - INFO: epoch 012:    450 / 990 loss=2.31, loss_v1=0, loss_v2=0, nll_loss=1.104, ntokens=1737, nsentences=56, sample_size=1737, sample_size_v1=0, sample_size_v2=0, ppl=2.15, wps=1023.1, ups=0.59, wpb=1737, bsz=56, num_updates=11320, lr=9.10678e-06, gnorm=3.804, clip=100, loss_scale=128, train_wall=17, gb_free=12.7, wall=19522
2023-06-27 21:44:17 - progress_bar.py[line:272] - INFO: epoch 012:    460 / 990 loss=2.31, loss_v1=0, loss_v2=0, nll_loss=1.103, ntokens=1842.5, nsentences=56, sample_size=1842.5, sample_size_v1=0, sample_size_v2=0, ppl=2.15, wps=1074.4, ups=0.58, wpb=1842.5, bsz=56, num_updates=11330, lr=9.08664e-06, gnorm=3.244, clip=100, loss_scale=128, train_wall=17, gb_free=12.6, wall=19539
2023-06-27 21:44:34 - progress_bar.py[line:272] - INFO: epoch 012:    470 / 990 loss=2.326, loss_v1=0, loss_v2=0, nll_loss=1.121, ntokens=1889.2, nsentences=56, sample_size=1889.2, sample_size_v1=0, sample_size_v2=0, ppl=2.18, wps=1101.3, ups=0.58, wpb=1889.2, bsz=56, num_updates=11340, lr=9.06649e-06, gnorm=3.732, clip=100, loss_scale=128, train_wall=17, gb_free=12.1, wall=19557
2023-06-27 21:44:51 - progress_bar.py[line:272] - INFO: epoch 012:    480 / 990 loss=2.309, loss_v1=0, loss_v2=0, nll_loss=1.101, ntokens=1825.5, nsentences=56, sample_size=1825.5, sample_size_v1=0, sample_size_v2=0, ppl=2.14, wps=1063.1, ups=0.58, wpb=1825.5, bsz=56, num_updates=11350, lr=9.04634e-06, gnorm=3.453, clip=100, loss_scale=128, train_wall=17, gb_free=12.3, wall=19574
2023-06-27 21:45:08 - progress_bar.py[line:272] - INFO: epoch 012:    490 / 990 loss=2.298, loss_v1=0, loss_v2=0, nll_loss=1.088, ntokens=1858.3, nsentences=56, sample_size=1858.3, sample_size_v1=0, sample_size_v2=0, ppl=2.13, wps=1085.1, ups=0.58, wpb=1858.3, bsz=56, num_updates=11360, lr=9.02619e-06, gnorm=3.203, clip=100, loss_scale=128, train_wall=17, gb_free=12.6, wall=19591
2023-06-27 21:45:25 - progress_bar.py[line:272] - INFO: epoch 012:    500 / 990 loss=2.322, loss_v1=0, loss_v2=0, nll_loss=1.116, ntokens=1880.2, nsentences=56, sample_size=1880.2, sample_size_v1=0, sample_size_v2=0, ppl=2.17, wps=1095.3, ups=0.58, wpb=1880.2, bsz=56, num_updates=11370, lr=9.00604e-06, gnorm=3.342, clip=100, loss_scale=128, train_wall=17, gb_free=12.5, wall=19608
2023-06-27 21:45:43 - progress_bar.py[line:272] - INFO: epoch 012:    510 / 990 loss=2.347, loss_v1=0, loss_v2=0, nll_loss=1.145, ntokens=1748.2, nsentences=56, sample_size=1748.2, sample_size_v1=0, sample_size_v2=0, ppl=2.21, wps=1024.8, ups=0.59, wpb=1748.2, bsz=56, num_updates=11380, lr=8.9859e-06, gnorm=3.561, clip=100, loss_scale=128, train_wall=17, gb_free=12, wall=19625
2023-06-27 21:45:59 - progress_bar.py[line:272] - INFO: epoch 012:    520 / 990 loss=2.314, loss_v1=0, loss_v2=0, nll_loss=1.109, ntokens=1777.1, nsentences=56, sample_size=1777.1, sample_size_v1=0, sample_size_v2=0, ppl=2.16, wps=1046.5, ups=0.59, wpb=1777.1, bsz=56, num_updates=11390, lr=8.96575e-06, gnorm=3.682, clip=100, loss_scale=128, train_wall=17, gb_free=12.4, wall=19642
2023-06-27 21:46:17 - progress_bar.py[line:272] - INFO: epoch 012:    530 / 990 loss=2.313, loss_v1=0, loss_v2=0, nll_loss=1.106, ntokens=1897.6, nsentences=56, sample_size=1897.6, sample_size_v1=0, sample_size_v2=0, ppl=2.15, wps=1104.6, ups=0.58, wpb=1897.6, bsz=56, num_updates=11400, lr=8.9456e-06, gnorm=3.431, clip=100, loss_scale=128, train_wall=17, gb_free=12.7, wall=19659
2023-06-27 21:46:34 - progress_bar.py[line:272] - INFO: epoch 012:    540 / 990 loss=2.322, loss_v1=0, loss_v2=0, nll_loss=1.115, ntokens=1947.3, nsentences=56, sample_size=1947.3, sample_size_v1=0, sample_size_v2=0, ppl=2.17, wps=1135.2, ups=0.58, wpb=1947.3, bsz=56, num_updates=11410, lr=8.92545e-06, gnorm=3.352, clip=100, loss_scale=128, train_wall=17, gb_free=12.5, wall=19677
2023-06-27 21:46:51 - progress_bar.py[line:272] - INFO: epoch 012:    550 / 990 loss=2.315, loss_v1=0, loss_v2=0, nll_loss=1.107, ntokens=1908, nsentences=56, sample_size=1908, sample_size_v1=0, sample_size_v2=0, ppl=2.15, wps=1117.1, ups=0.59, wpb=1908, bsz=56, num_updates=11420, lr=8.90531e-06, gnorm=3.499, clip=100, loss_scale=128, train_wall=17, gb_free=13.3, wall=19694
2023-06-27 21:47:08 - progress_bar.py[line:272] - INFO: epoch 012:    560 / 990 loss=2.301, loss_v1=0, loss_v2=0, nll_loss=1.092, ntokens=1822.8, nsentences=56, sample_size=1822.8, sample_size_v1=0, sample_size_v2=0, ppl=2.13, wps=1070.4, ups=0.59, wpb=1822.8, bsz=56, num_updates=11430, lr=8.88516e-06, gnorm=3.414, clip=100, loss_scale=128, train_wall=17, gb_free=11.7, wall=19711
2023-06-27 21:47:25 - progress_bar.py[line:272] - INFO: epoch 012:    570 / 990 loss=2.295, loss_v1=0, loss_v2=0, nll_loss=1.087, ntokens=1776.7, nsentences=56, sample_size=1776.7, sample_size_v1=0, sample_size_v2=0, ppl=2.12, wps=1042.5, ups=0.59, wpb=1776.7, bsz=56, num_updates=11440, lr=8.86501e-06, gnorm=3.484, clip=100, loss_scale=128, train_wall=17, gb_free=12.9, wall=19728
2023-06-27 21:47:30 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 128.0
2023-06-27 21:47:44 - progress_bar.py[line:272] - INFO: epoch 012:    581 / 990 loss=2.344, loss_v1=0, loss_v2=0, nll_loss=1.141, ntokens=1861.7, nsentences=56, sample_size=1861.7, sample_size_v1=0, sample_size_v2=0, ppl=2.21, wps=996, ups=0.53, wpb=1861.7, bsz=56, num_updates=11450, lr=8.84486e-06, gnorm=3.562, clip=100, loss_scale=128, train_wall=19, gb_free=12.6, wall=19746
2023-06-27 21:48:01 - progress_bar.py[line:272] - INFO: epoch 012:    591 / 990 loss=2.333, loss_v1=0, loss_v2=0, nll_loss=1.127, ntokens=1965, nsentences=56, sample_size=1965, sample_size_v1=0, sample_size_v2=0, ppl=2.18, wps=1147.8, ups=0.58, wpb=1965, bsz=56, num_updates=11460, lr=8.82471e-06, gnorm=3.403, clip=100, loss_scale=128, train_wall=17, gb_free=12.6, wall=19763
2023-06-27 21:48:18 - progress_bar.py[line:272] - INFO: epoch 012:    601 / 990 loss=2.323, loss_v1=0, loss_v2=0, nll_loss=1.115, ntokens=1747.4, nsentences=56, sample_size=1747.4, sample_size_v1=0, sample_size_v2=0, ppl=2.17, wps=1031, ups=0.59, wpb=1747.4, bsz=56, num_updates=11470, lr=8.80457e-06, gnorm=3.794, clip=100, loss_scale=128, train_wall=17, gb_free=13, wall=19780
2023-06-27 21:48:35 - progress_bar.py[line:272] - INFO: epoch 012:    611 / 990 loss=2.296, loss_v1=0, loss_v2=0, nll_loss=1.086, ntokens=1837.5, nsentences=56, sample_size=1837.5, sample_size_v1=0, sample_size_v2=0, ppl=2.12, wps=1077.4, ups=0.59, wpb=1837.5, bsz=56, num_updates=11480, lr=8.78442e-06, gnorm=3.76, clip=100, loss_scale=128, train_wall=17, gb_free=12.7, wall=19797
2023-06-27 21:48:52 - progress_bar.py[line:272] - INFO: epoch 012:    621 / 990 loss=2.335, loss_v1=0, loss_v2=0, nll_loss=1.131, ntokens=1909.3, nsentences=56, sample_size=1909.3, sample_size_v1=0, sample_size_v2=0, ppl=2.19, wps=1117.4, ups=0.59, wpb=1909.3, bsz=56, num_updates=11490, lr=8.76427e-06, gnorm=3.681, clip=100, loss_scale=128, train_wall=17, gb_free=12.5, wall=19815
2023-06-27 21:49:09 - progress_bar.py[line:272] - INFO: epoch 012:    631 / 990 loss=2.337, loss_v1=0, loss_v2=0, nll_loss=1.132, ntokens=2053.9, nsentences=56, sample_size=2053.9, sample_size_v1=0, sample_size_v2=0, ppl=2.19, wps=1194.5, ups=0.58, wpb=2053.9, bsz=56, num_updates=11500, lr=8.74412e-06, gnorm=3.484, clip=100, loss_scale=128, train_wall=17, gb_free=12.5, wall=19832
2023-06-27 21:49:26 - progress_bar.py[line:272] - INFO: epoch 012:    641 / 990 loss=2.314, loss_v1=0, loss_v2=0, nll_loss=1.107, ntokens=1998.8, nsentences=56, sample_size=1998.8, sample_size_v1=0, sample_size_v2=0, ppl=2.15, wps=1159.5, ups=0.58, wpb=1998.8, bsz=56, num_updates=11510, lr=8.72398e-06, gnorm=3.403, clip=100, loss_scale=128, train_wall=17, gb_free=12.4, wall=19849
2023-06-27 21:49:43 - progress_bar.py[line:272] - INFO: epoch 012:    651 / 990 loss=2.332, loss_v1=0, loss_v2=0, nll_loss=1.126, ntokens=1966.7, nsentences=56, sample_size=1966.7, sample_size_v1=0, sample_size_v2=0, ppl=2.18, wps=1148.9, ups=0.58, wpb=1966.7, bsz=56, num_updates=11520, lr=8.70383e-06, gnorm=3.506, clip=100, loss_scale=128, train_wall=17, gb_free=12.2, wall=19866
2023-06-27 21:50:01 - progress_bar.py[line:272] - INFO: epoch 012:    661 / 990 loss=2.319, loss_v1=0, loss_v2=0, nll_loss=1.113, ntokens=1855, nsentences=56, sample_size=1855, sample_size_v1=0, sample_size_v2=0, ppl=2.16, wps=1078.9, ups=0.58, wpb=1855, bsz=56, num_updates=11530, lr=8.68368e-06, gnorm=3.25, clip=100, loss_scale=128, train_wall=17, gb_free=12.2, wall=19883
2023-06-27 21:50:18 - progress_bar.py[line:272] - INFO: epoch 012:    671 / 990 loss=2.335, loss_v1=0, loss_v2=0, nll_loss=1.13, ntokens=1803.1, nsentences=56, sample_size=1803.1, sample_size_v1=0, sample_size_v2=0, ppl=2.19, wps=1056.4, ups=0.59, wpb=1803.1, bsz=56, num_updates=11540, lr=8.66353e-06, gnorm=3.722, clip=100, loss_scale=128, train_wall=17, gb_free=13.2, wall=19900
2023-06-27 21:50:35 - progress_bar.py[line:272] - INFO: epoch 012:    681 / 990 loss=2.281, loss_v1=0, loss_v2=0, nll_loss=1.07, ntokens=1912.8, nsentences=56, sample_size=1912.8, sample_size_v1=0, sample_size_v2=0, ppl=2.1, wps=1111.6, ups=0.58, wpb=1912.8, bsz=56, num_updates=11550, lr=8.64338e-06, gnorm=3.431, clip=100, loss_scale=128, train_wall=17, gb_free=12.3, wall=19918
2023-06-27 21:50:52 - progress_bar.py[line:272] - INFO: epoch 012:    691 / 990 loss=2.296, loss_v1=0, loss_v2=0, nll_loss=1.088, ntokens=1811.9, nsentences=56, sample_size=1811.9, sample_size_v1=0, sample_size_v2=0, ppl=2.13, wps=1057.2, ups=0.58, wpb=1811.9, bsz=56, num_updates=11560, lr=8.62324e-06, gnorm=3.652, clip=100, loss_scale=128, train_wall=17, gb_free=13, wall=19935
2023-06-27 21:51:09 - progress_bar.py[line:272] - INFO: epoch 012:    701 / 990 loss=2.335, loss_v1=0, loss_v2=0, nll_loss=1.13, ntokens=1682.5, nsentences=56, sample_size=1682.5, sample_size_v1=0, sample_size_v2=0, ppl=2.19, wps=988.8, ups=0.59, wpb=1682.5, bsz=56, num_updates=11570, lr=8.60309e-06, gnorm=3.841, clip=100, loss_scale=128, train_wall=17, gb_free=12.6, wall=19952
2023-06-27 21:51:26 - progress_bar.py[line:272] - INFO: epoch 012:    711 / 990 loss=2.328, loss_v1=0, loss_v2=0, nll_loss=1.121, ntokens=1771.8, nsentences=56, sample_size=1771.8, sample_size_v1=0, sample_size_v2=0, ppl=2.18, wps=1039.3, ups=0.59, wpb=1771.8, bsz=56, num_updates=11580, lr=8.58294e-06, gnorm=3.888, clip=100, loss_scale=128, train_wall=17, gb_free=12.5, wall=19969
2023-06-27 21:51:43 - progress_bar.py[line:272] - INFO: epoch 012:    721 / 990 loss=2.308, loss_v1=0, loss_v2=0, nll_loss=1.1, ntokens=1783, nsentences=56, sample_size=1783, sample_size_v1=0, sample_size_v2=0, ppl=2.14, wps=1048.5, ups=0.59, wpb=1783, bsz=56, num_updates=11590, lr=8.56279e-06, gnorm=3.563, clip=100, loss_scale=128, train_wall=17, gb_free=12.5, wall=19986
2023-06-27 21:52:00 - progress_bar.py[line:272] - INFO: epoch 012:    731 / 990 loss=2.293, loss_v1=0, loss_v2=0, nll_loss=1.083, ntokens=1766.9, nsentences=54.8, sample_size=1766.9, sample_size_v1=0, sample_size_v2=0, ppl=2.12, wps=1052.8, ups=0.6, wpb=1766.9, bsz=54.8, num_updates=11600, lr=8.54265e-06, gnorm=3.564, clip=100, loss_scale=128, train_wall=17, gb_free=12.7, wall=20003
2023-06-27 21:52:17 - progress_bar.py[line:272] - INFO: epoch 012:    741 / 990 loss=2.327, loss_v1=0, loss_v2=0, nll_loss=1.122, ntokens=1796.5, nsentences=56, sample_size=1796.5, sample_size_v1=0, sample_size_v2=0, ppl=2.18, wps=1055.4, ups=0.59, wpb=1796.5, bsz=56, num_updates=11610, lr=8.5225e-06, gnorm=3.759, clip=100, loss_scale=128, train_wall=17, gb_free=12.5, wall=20020
2023-06-27 21:52:34 - progress_bar.py[line:272] - INFO: epoch 012:    751 / 990 loss=2.346, loss_v1=0, loss_v2=0, nll_loss=1.141, ntokens=1654, nsentences=56, sample_size=1654, sample_size_v1=0, sample_size_v2=0, ppl=2.21, wps=974, ups=0.59, wpb=1654, bsz=56, num_updates=11620, lr=8.50235e-06, gnorm=3.702, clip=100, loss_scale=128, train_wall=17, gb_free=12.9, wall=20037
2023-06-27 21:52:51 - progress_bar.py[line:272] - INFO: epoch 012:    761 / 990 loss=2.32, loss_v1=0, loss_v2=0, nll_loss=1.113, ntokens=1744.8, nsentences=56, sample_size=1744.8, sample_size_v1=0, sample_size_v2=0, ppl=2.16, wps=1025.8, ups=0.59, wpb=1744.8, bsz=56, num_updates=11630, lr=8.4822e-06, gnorm=3.747, clip=100, loss_scale=128, train_wall=17, gb_free=12.8, wall=20054
2023-06-27 21:53:08 - progress_bar.py[line:272] - INFO: epoch 012:    771 / 990 loss=2.315, loss_v1=0, loss_v2=0, nll_loss=1.108, ntokens=1849.8, nsentences=56, sample_size=1849.8, sample_size_v1=0, sample_size_v2=0, ppl=2.16, wps=1081.7, ups=0.58, wpb=1849.8, bsz=56, num_updates=11640, lr=8.46206e-06, gnorm=3.477, clip=100, loss_scale=128, train_wall=17, gb_free=12.1, wall=20071
2023-06-27 21:53:25 - progress_bar.py[line:272] - INFO: epoch 012:    781 / 990 loss=2.308, loss_v1=0, loss_v2=0, nll_loss=1.1, ntokens=1772.9, nsentences=56, sample_size=1772.9, sample_size_v1=0, sample_size_v2=0, ppl=2.14, wps=1039.8, ups=0.59, wpb=1772.9, bsz=56, num_updates=11650, lr=8.44191e-06, gnorm=3.914, clip=100, loss_scale=128, train_wall=17, gb_free=12.9, wall=20088
2023-06-27 21:53:42 - progress_bar.py[line:272] - INFO: epoch 012:    791 / 990 loss=2.315, loss_v1=0, loss_v2=0, nll_loss=1.108, ntokens=1776.5, nsentences=56, sample_size=1776.5, sample_size_v1=0, sample_size_v2=0, ppl=2.16, wps=1042.4, ups=0.59, wpb=1776.5, bsz=56, num_updates=11660, lr=8.42176e-06, gnorm=3.601, clip=100, loss_scale=128, train_wall=17, gb_free=13, wall=20105
2023-06-27 21:53:59 - progress_bar.py[line:272] - INFO: epoch 012:    801 / 990 loss=2.328, loss_v1=0, loss_v2=0, nll_loss=1.123, ntokens=1825.9, nsentences=56, sample_size=1825.9, sample_size_v1=0, sample_size_v2=0, ppl=2.18, wps=1068.3, ups=0.59, wpb=1825.9, bsz=56, num_updates=11670, lr=8.40161e-06, gnorm=3.526, clip=100, loss_scale=128, train_wall=17, gb_free=12.9, wall=20122
2023-06-27 21:54:16 - progress_bar.py[line:272] - INFO: epoch 012:    811 / 990 loss=2.33, loss_v1=0, loss_v2=0, nll_loss=1.124, ntokens=1718, nsentences=56, sample_size=1718, sample_size_v1=0, sample_size_v2=0, ppl=2.18, wps=1008.5, ups=0.59, wpb=1718, bsz=56, num_updates=11680, lr=8.38146e-06, gnorm=3.96, clip=100, loss_scale=128, train_wall=17, gb_free=12.5, wall=20139
2023-06-27 21:54:33 - progress_bar.py[line:272] - INFO: epoch 012:    821 / 990 loss=2.326, loss_v1=0, loss_v2=0, nll_loss=1.12, ntokens=1672, nsentences=56, sample_size=1672, sample_size_v1=0, sample_size_v2=0, ppl=2.17, wps=981.9, ups=0.59, wpb=1672, bsz=56, num_updates=11690, lr=8.36132e-06, gnorm=3.775, clip=100, loss_scale=128, train_wall=17, gb_free=13, wall=20156
2023-06-27 21:54:50 - progress_bar.py[line:272] - INFO: epoch 012:    831 / 990 loss=2.294, loss_v1=0, loss_v2=0, nll_loss=1.085, ntokens=1744.9, nsentences=56, sample_size=1744.9, sample_size_v1=0, sample_size_v2=0, ppl=2.12, wps=1023.8, ups=0.59, wpb=1744.9, bsz=56, num_updates=11700, lr=8.34117e-06, gnorm=3.664, clip=100, loss_scale=128, train_wall=17, gb_free=13, wall=20173
2023-06-27 21:55:07 - progress_bar.py[line:272] - INFO: epoch 012:    841 / 990 loss=2.298, loss_v1=0, loss_v2=0, nll_loss=1.09, ntokens=1833, nsentences=56, sample_size=1833, sample_size_v1=0, sample_size_v2=0, ppl=2.13, wps=1074.7, ups=0.59, wpb=1833, bsz=56, num_updates=11710, lr=8.32102e-06, gnorm=3.664, clip=100, loss_scale=128, train_wall=17, gb_free=12.9, wall=20190
2023-06-27 21:55:25 - progress_bar.py[line:272] - INFO: epoch 012:    851 / 990 loss=2.295, loss_v1=0, loss_v2=0, nll_loss=1.086, ntokens=1870.4, nsentences=56, sample_size=1870.4, sample_size_v1=0, sample_size_v2=0, ppl=2.12, wps=1091.5, ups=0.58, wpb=1870.4, bsz=56, num_updates=11720, lr=8.30087e-06, gnorm=3.357, clip=100, loss_scale=128, train_wall=17, gb_free=12.3, wall=20207
2023-06-27 21:55:42 - progress_bar.py[line:272] - INFO: epoch 012:    861 / 990 loss=2.29, loss_v1=0, loss_v2=0, nll_loss=1.079, ntokens=1819.7, nsentences=56, sample_size=1819.7, sample_size_v1=0, sample_size_v2=0, ppl=2.11, wps=1064.5, ups=0.59, wpb=1819.7, bsz=56, num_updates=11730, lr=8.28073e-06, gnorm=3.678, clip=100, loss_scale=128, train_wall=17, gb_free=12.5, wall=20224
2023-06-27 21:55:59 - progress_bar.py[line:272] - INFO: epoch 012:    871 / 990 loss=2.309, loss_v1=0, loss_v2=0, nll_loss=1.102, ntokens=1874, nsentences=56, sample_size=1874, sample_size_v1=0, sample_size_v2=0, ppl=2.15, wps=1092.4, ups=0.58, wpb=1874, bsz=56, num_updates=11740, lr=8.26058e-06, gnorm=3.503, clip=100, loss_scale=128, train_wall=17, gb_free=12.9, wall=20242
2023-06-27 21:56:16 - progress_bar.py[line:272] - INFO: epoch 012:    881 / 990 loss=2.288, loss_v1=0, loss_v2=0, nll_loss=1.079, ntokens=1792.2, nsentences=56, sample_size=1792.2, sample_size_v1=0, sample_size_v2=0, ppl=2.11, wps=1052.9, ups=0.59, wpb=1792.2, bsz=56, num_updates=11750, lr=8.24043e-06, gnorm=3.532, clip=100, loss_scale=128, train_wall=17, gb_free=12.9, wall=20259
2023-06-27 21:56:33 - progress_bar.py[line:272] - INFO: epoch 012:    891 / 990 loss=2.299, loss_v1=0, loss_v2=0, nll_loss=1.09, ntokens=2071.6, nsentences=56, sample_size=2071.6, sample_size_v1=0, sample_size_v2=0, ppl=2.13, wps=1200, ups=0.58, wpb=2071.6, bsz=56, num_updates=11760, lr=8.22028e-06, gnorm=3.184, clip=100, loss_scale=128, train_wall=17, gb_free=12.7, wall=20276
2023-06-27 21:56:50 - progress_bar.py[line:272] - INFO: epoch 012:    901 / 990 loss=2.322, loss_v1=0, loss_v2=0, nll_loss=1.115, ntokens=1715.1, nsentences=56, sample_size=1715.1, sample_size_v1=0, sample_size_v2=0, ppl=2.17, wps=1005.2, ups=0.59, wpb=1715.1, bsz=56, num_updates=11770, lr=8.20013e-06, gnorm=3.751, clip=100, loss_scale=128, train_wall=17, gb_free=13, wall=20293
2023-06-27 21:57:07 - progress_bar.py[line:272] - INFO: epoch 012:    911 / 990 loss=2.315, loss_v1=0, loss_v2=0, nll_loss=1.108, ntokens=1849.7, nsentences=56, sample_size=1849.7, sample_size_v1=0, sample_size_v2=0, ppl=2.15, wps=1084.7, ups=0.59, wpb=1849.7, bsz=56, num_updates=11780, lr=8.17999e-06, gnorm=3.362, clip=100, loss_scale=128, train_wall=17, gb_free=12.6, wall=20310
2023-06-27 21:57:24 - progress_bar.py[line:272] - INFO: epoch 012:    921 / 990 loss=2.31, loss_v1=0, loss_v2=0, nll_loss=1.102, ntokens=1665.6, nsentences=56, sample_size=1665.6, sample_size_v1=0, sample_size_v2=0, ppl=2.15, wps=980, ups=0.59, wpb=1665.6, bsz=56, num_updates=11790, lr=8.15984e-06, gnorm=3.691, clip=100, loss_scale=128, train_wall=17, gb_free=13, wall=20327
2023-06-27 21:57:41 - progress_bar.py[line:272] - INFO: epoch 012:    931 / 990 loss=2.276, loss_v1=0, loss_v2=0, nll_loss=1.065, ntokens=1897.7, nsentences=56, sample_size=1897.7, sample_size_v1=0, sample_size_v2=0, ppl=2.09, wps=1104.7, ups=0.58, wpb=1897.7, bsz=56, num_updates=11800, lr=8.13969e-06, gnorm=3.672, clip=100, loss_scale=128, train_wall=17, gb_free=13.2, wall=20344
2023-06-27 21:57:59 - progress_bar.py[line:272] - INFO: epoch 012:    941 / 990 loss=2.309, loss_v1=0, loss_v2=0, nll_loss=1.102, ntokens=1857.7, nsentences=56, sample_size=1857.7, sample_size_v1=0, sample_size_v2=0, ppl=2.15, wps=1084.2, ups=0.58, wpb=1857.7, bsz=56, num_updates=11810, lr=8.11954e-06, gnorm=3.492, clip=100, loss_scale=128, train_wall=17, gb_free=12.2, wall=20361
2023-06-27 21:58:16 - progress_bar.py[line:272] - INFO: epoch 012:    951 / 990 loss=2.293, loss_v1=0, loss_v2=0, nll_loss=1.083, ntokens=1949.2, nsentences=56, sample_size=1949.2, sample_size_v1=0, sample_size_v2=0, ppl=2.12, wps=1122.4, ups=0.58, wpb=1949.2, bsz=56, num_updates=11820, lr=8.0994e-06, gnorm=3.187, clip=100, loss_scale=128, train_wall=17, gb_free=13, wall=20379
2023-06-27 21:58:33 - progress_bar.py[line:272] - INFO: epoch 012:    961 / 990 loss=2.305, loss_v1=0, loss_v2=0, nll_loss=1.096, ntokens=1806.8, nsentences=56, sample_size=1806.8, sample_size_v1=0, sample_size_v2=0, ppl=2.14, wps=1059.4, ups=0.59, wpb=1806.8, bsz=56, num_updates=11830, lr=8.07925e-06, gnorm=3.769, clip=100, loss_scale=128, train_wall=17, gb_free=12.7, wall=20396
2023-06-27 21:58:50 - progress_bar.py[line:272] - INFO: epoch 012:    971 / 990 loss=2.299, loss_v1=0, loss_v2=0, nll_loss=1.09, ntokens=1961.4, nsentences=56, sample_size=1961.4, sample_size_v1=0, sample_size_v2=0, ppl=2.13, wps=1141.9, ups=0.58, wpb=1961.4, bsz=56, num_updates=11840, lr=8.0591e-06, gnorm=3.457, clip=100, loss_scale=128, train_wall=17, gb_free=12.5, wall=20413
2023-06-27 21:59:07 - progress_bar.py[line:272] - INFO: epoch 012:    981 / 990 loss=2.302, loss_v1=0, loss_v2=0, nll_loss=1.094, ntokens=1789.3, nsentences=56, sample_size=1789.3, sample_size_v1=0, sample_size_v2=0, ppl=2.14, wps=1048.7, ups=0.59, wpb=1789.3, bsz=56, num_updates=11850, lr=8.03895e-06, gnorm=3.778, clip=100, loss_scale=128, train_wall=17, gb_free=12.6, wall=20430
local datafile ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 1 begin to initialize row_count and line_idx-to-offset mapping
2023-06-27 21:59:22 - checkpoint_utils.py[line:64] - INFO: Preparing to save checkpoint for epoch 12 @ 11859 updates
2023-06-27 21:59:22 - trainer.py[line:431] - INFO: Saving checkpoint to ../../checkpoints/OFA/sgcls_checkpoints/_16_3e-5_512_base/checkpoint12.pt
local datafile ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 1 finished initializing row_count and line_idx-to-offset mapping
file ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 1 row count 27700 total row count 55400
slice_id 1 seek offset 27700
2023-06-27 21:59:25 - trainer.py[line:441] - INFO: Finished saving checkpoint to ../../checkpoints/OFA/sgcls_checkpoints/_16_3e-5_512_base/checkpoint12.pt
2023-06-27 21:59:28 - checkpoint_utils.py[line:133] - INFO: Saved checkpoint ../../checkpoints/OFA/sgcls_checkpoints/_16_3e-5_512_base/checkpoint12.pt (epoch 12 @ 11859 updates, score None) (writing took 5.9375386238098145 seconds)
2023-06-27 21:59:28 - train.py[line:332] - INFO: end of epoch 12 (average epoch stats below)
2023-06-27 21:59:28 - progress_bar.py[line:282] - INFO: epoch 012 | loss 2.298 | loss_v1 0 | loss_v2 0 | nll_loss 1.089 | ntokens 1849.98 | nsentences 55.96 | sample_size 1849.98 | sample_size_v1 0 | sample_size_v2 0 | ppl 2.13 | wps 1071 | ups 0.58 | wpb 1850 | bsz 56 | num_updates 11859 | lr 8.02082e-06 | gnorm 3.455 | clip 100 | loss_scale 128 | train_wall 1695 | gb_free 13.3 | wall 20450
2023-06-27 21:59:28 - trainer.py[line:639] - INFO: loading train data for epoch 13
local datafile ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 0 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 0 finished initializing row_count and line_idx-to-offset mapping
file ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 0 row count 27700 total row count 55400
slice_id 0 seek offset 0
2023-06-27 21:59:30 - trainer.py[line:703] - INFO: begin training epoch 13
2023-06-27 21:59:30 - train.py[line:305] - INFO: Start iterating over samples
2023-06-27 21:59:32 - progress_bar.py[line:272] - INFO: epoch 013:      1 / 990 loss=2.342, loss_v1=0, loss_v2=0, nll_loss=1.139, ntokens=1784.6, nsentences=53.2, sample_size=1784.6, sample_size_v1=0, sample_size_v2=0, ppl=2.2, wps=733.4, ups=0.41, wpb=1784.6, bsz=53.2, num_updates=11860, lr=8.0188e-06, gnorm=3.523, clip=100, loss_scale=128, train_wall=16, gb_free=12.6, wall=20454
2023-06-27 21:59:49 - progress_bar.py[line:272] - INFO: epoch 013:     11 / 990 loss=2.254, loss_v1=0, loss_v2=0, nll_loss=1.039, ntokens=1878.8, nsentences=56, sample_size=1878.8, sample_size_v1=0, sample_size_v2=0, ppl=2.05, wps=1088.5, ups=0.58, wpb=1878.8, bsz=56, num_updates=11870, lr=7.99866e-06, gnorm=3.809, clip=100, loss_scale=128, train_wall=17, gb_free=12.5, wall=20472
2023-06-27 22:00:06 - progress_bar.py[line:272] - INFO: epoch 013:     21 / 990 loss=2.223, loss_v1=0, loss_v2=0, nll_loss=1.005, ntokens=1803.4, nsentences=56, sample_size=1803.4, sample_size_v1=0, sample_size_v2=0, ppl=2.01, wps=1037.7, ups=0.58, wpb=1803.4, bsz=56, num_updates=11880, lr=7.97851e-06, gnorm=3.592, clip=100, loss_scale=128, train_wall=17, gb_free=12.4, wall=20489
2023-06-27 22:00:23 - progress_bar.py[line:272] - INFO: epoch 013:     31 / 990 loss=2.287, loss_v1=0, loss_v2=0, nll_loss=1.077, ntokens=1717.2, nsentences=56, sample_size=1717.2, sample_size_v1=0, sample_size_v2=0, ppl=2.11, wps=1009.9, ups=0.59, wpb=1717.2, bsz=56, num_updates=11890, lr=7.95836e-06, gnorm=3.806, clip=100, loss_scale=128, train_wall=17, gb_free=12.2, wall=20506
2023-06-27 22:00:41 - progress_bar.py[line:272] - INFO: epoch 013:     41 / 990 loss=2.177, loss_v1=0, loss_v2=0, nll_loss=0.954, ntokens=1953.2, nsentences=56, sample_size=1953.2, sample_size_v1=0, sample_size_v2=0, ppl=1.94, wps=1129.2, ups=0.58, wpb=1953.2, bsz=56, num_updates=11900, lr=7.93821e-06, gnorm=3.311, clip=100, loss_scale=128, train_wall=17, gb_free=11.9, wall=20523
2023-06-27 22:00:58 - progress_bar.py[line:272] - INFO: epoch 013:     51 / 990 loss=2.217, loss_v1=0, loss_v2=0, nll_loss=1.001, ntokens=1820.6, nsentences=56, sample_size=1820.6, sample_size_v1=0, sample_size_v2=0, ppl=2, wps=1051.9, ups=0.58, wpb=1820.6, bsz=56, num_updates=11910, lr=7.91807e-06, gnorm=3.449, clip=100, loss_scale=128, train_wall=17, gb_free=12.4, wall=20541
2023-06-27 22:01:15 - progress_bar.py[line:272] - INFO: epoch 013:     61 / 990 loss=2.229, loss_v1=0, loss_v2=0, nll_loss=1.012, ntokens=1772.8, nsentences=56, sample_size=1772.8, sample_size_v1=0, sample_size_v2=0, ppl=2.02, wps=1028.3, ups=0.58, wpb=1772.8, bsz=56, num_updates=11920, lr=7.89792e-06, gnorm=3.494, clip=100, loss_scale=128, train_wall=17, gb_free=12.8, wall=20558
2023-06-27 22:01:33 - progress_bar.py[line:272] - INFO: epoch 013:     71 / 990 loss=2.107, loss_v1=0, loss_v2=0, nll_loss=0.875, ntokens=2002.7, nsentences=56, sample_size=2002.7, sample_size_v1=0, sample_size_v2=0, ppl=1.83, wps=1150.2, ups=0.57, wpb=2002.7, bsz=56, num_updates=11930, lr=7.87777e-06, gnorm=3.254, clip=100, loss_scale=128, train_wall=17, gb_free=11.9, wall=20575
2023-06-27 22:01:50 - progress_bar.py[line:272] - INFO: epoch 013:     81 / 990 loss=2.164, loss_v1=0, loss_v2=0, nll_loss=0.939, ntokens=2131.5, nsentences=56, sample_size=2131.5, sample_size_v1=0, sample_size_v2=0, ppl=1.92, wps=1207.6, ups=0.57, wpb=2131.5, bsz=56, num_updates=11940, lr=7.85762e-06, gnorm=3.071, clip=100, loss_scale=128, train_wall=18, gb_free=11.8, wall=20593
2023-06-27 22:02:08 - progress_bar.py[line:272] - INFO: epoch 013:     91 / 990 loss=2.172, loss_v1=0, loss_v2=0, nll_loss=0.949, ntokens=2097.7, nsentences=56, sample_size=2097.7, sample_size_v1=0, sample_size_v2=0, ppl=1.93, wps=1187.8, ups=0.57, wpb=2097.7, bsz=56, num_updates=11950, lr=7.83747e-06, gnorm=3.136, clip=100, loss_scale=128, train_wall=18, gb_free=12.3, wall=20611
2023-06-27 22:02:16 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 128.0
2023-06-27 22:02:26 - progress_bar.py[line:272] - INFO: epoch 013:    102 / 990 loss=2.247, loss_v1=0, loss_v2=0, nll_loss=1.031, ntokens=1826.4, nsentences=54.8, sample_size=1826.4, sample_size_v1=0, sample_size_v2=0, ppl=2.04, wps=980.7, ups=0.54, wpb=1826.4, bsz=54.8, num_updates=11960, lr=7.81733e-06, gnorm=3.653, clip=100, loss_scale=128, train_wall=19, gb_free=12, wall=20629
2023-06-27 22:02:44 - progress_bar.py[line:272] - INFO: epoch 013:    112 / 990 loss=2.215, loss_v1=0, loss_v2=0, nll_loss=0.995, ntokens=1877.1, nsentences=56, sample_size=1877.1, sample_size_v1=0, sample_size_v2=0, ppl=1.99, wps=1088.7, ups=0.58, wpb=1877.1, bsz=56, num_updates=11970, lr=7.79718e-06, gnorm=3.534, clip=100, loss_scale=128, train_wall=17, gb_free=11.9, wall=20646
2023-06-27 22:03:01 - progress_bar.py[line:272] - INFO: epoch 013:    122 / 990 loss=2.303, loss_v1=0, loss_v2=0, nll_loss=1.094, ntokens=1739.9, nsentences=56, sample_size=1739.9, sample_size_v1=0, sample_size_v2=0, ppl=2.14, wps=1017.8, ups=0.58, wpb=1739.9, bsz=56, num_updates=11980, lr=7.77703e-06, gnorm=3.832, clip=100, loss_scale=128, train_wall=17, gb_free=12.3, wall=20664
2023-06-27 22:03:18 - progress_bar.py[line:272] - INFO: epoch 013:    132 / 990 loss=2.311, loss_v1=0, loss_v2=0, nll_loss=1.105, ntokens=1819.6, nsentences=56, sample_size=1819.6, sample_size_v1=0, sample_size_v2=0, ppl=2.15, wps=1054.9, ups=0.58, wpb=1819.6, bsz=56, num_updates=11990, lr=7.75688e-06, gnorm=3.938, clip=100, loss_scale=128, train_wall=17, gb_free=12.4, wall=20681
2023-06-27 22:03:36 - progress_bar.py[line:272] - INFO: epoch 013:    142 / 990 loss=2.291, loss_v1=0, loss_v2=0, nll_loss=1.081, ntokens=1982.5, nsentences=56, sample_size=1982.5, sample_size_v1=0, sample_size_v2=0, ppl=2.12, wps=1134, ups=0.57, wpb=1982.5, bsz=56, num_updates=12000, lr=7.73674e-06, gnorm=3.383, clip=100, loss_scale=128, train_wall=17, gb_free=11.9, wall=20698
2023-06-27 22:03:53 - progress_bar.py[line:272] - INFO: epoch 013:    152 / 990 loss=2.261, loss_v1=0, loss_v2=0, nll_loss=1.048, ntokens=1939.9, nsentences=56, sample_size=1939.9, sample_size_v1=0, sample_size_v2=0, ppl=2.07, wps=1116.7, ups=0.58, wpb=1939.9, bsz=56, num_updates=12010, lr=7.71659e-06, gnorm=3.528, clip=100, loss_scale=128, train_wall=17, gb_free=12.5, wall=20716
2023-06-27 22:04:10 - progress_bar.py[line:272] - INFO: epoch 013:    162 / 990 loss=2.247, loss_v1=0, loss_v2=0, nll_loss=1.031, ntokens=1998.5, nsentences=56, sample_size=1998.5, sample_size_v1=0, sample_size_v2=0, ppl=2.04, wps=1143.3, ups=0.57, wpb=1998.5, bsz=56, num_updates=12020, lr=7.69644e-06, gnorm=3.482, clip=100, loss_scale=128, train_wall=17, gb_free=12.2, wall=20733
2023-06-27 22:04:28 - progress_bar.py[line:272] - INFO: epoch 013:    172 / 990 loss=2.256, loss_v1=0, loss_v2=0, nll_loss=1.042, ntokens=1894.3, nsentences=56, sample_size=1894.3, sample_size_v1=0, sample_size_v2=0, ppl=2.06, wps=1087.4, ups=0.57, wpb=1894.3, bsz=56, num_updates=12030, lr=7.67629e-06, gnorm=3.371, clip=100, loss_scale=128, train_wall=17, gb_free=12.4, wall=20751
2023-06-27 22:04:45 - progress_bar.py[line:272] - INFO: epoch 013:    182 / 990 loss=2.271, loss_v1=0, loss_v2=0, nll_loss=1.059, ntokens=1973.9, nsentences=56, sample_size=1973.9, sample_size_v1=0, sample_size_v2=0, ppl=2.08, wps=1133.8, ups=0.57, wpb=1973.9, bsz=56, num_updates=12040, lr=7.65615e-06, gnorm=3.481, clip=100, loss_scale=128, train_wall=17, gb_free=12.9, wall=20768
2023-06-27 22:05:03 - progress_bar.py[line:272] - INFO: epoch 013:    192 / 990 loss=2.261, loss_v1=0, loss_v2=0, nll_loss=1.048, ntokens=1890.5, nsentences=56, sample_size=1890.5, sample_size_v1=0, sample_size_v2=0, ppl=2.07, wps=1093.4, ups=0.58, wpb=1890.5, bsz=56, num_updates=12050, lr=7.636e-06, gnorm=3.529, clip=100, loss_scale=128, train_wall=17, gb_free=13.1, wall=20785
2023-06-27 22:05:20 - progress_bar.py[line:272] - INFO: epoch 013:    202 / 990 loss=2.258, loss_v1=0, loss_v2=0, nll_loss=1.044, ntokens=1822.3, nsentences=56, sample_size=1822.3, sample_size_v1=0, sample_size_v2=0, ppl=2.06, wps=1060.6, ups=0.58, wpb=1822.3, bsz=56, num_updates=12060, lr=7.61585e-06, gnorm=3.762, clip=100, loss_scale=128, train_wall=17, gb_free=11.8, wall=20802
2023-06-27 22:05:35 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2023-06-27 22:05:39 - progress_bar.py[line:272] - INFO: epoch 013:    213 / 990 loss=2.252, loss_v1=0, loss_v2=0, nll_loss=1.037, ntokens=1917.2, nsentences=56, sample_size=1917.2, sample_size_v1=0, sample_size_v2=0, ppl=2.05, wps=1003.7, ups=0.52, wpb=1917.2, bsz=56, num_updates=12070, lr=7.5957e-06, gnorm=3.431, clip=100, loss_scale=64, train_wall=19, gb_free=12.1, wall=20822
2023-06-27 22:05:56 - progress_bar.py[line:272] - INFO: epoch 013:    223 / 990 loss=2.268, loss_v1=0, loss_v2=0, nll_loss=1.055, ntokens=1912.7, nsentences=56, sample_size=1912.7, sample_size_v1=0, sample_size_v2=0, ppl=2.08, wps=1103.3, ups=0.58, wpb=1912.7, bsz=56, num_updates=12080, lr=7.57555e-06, gnorm=3.78, clip=100, loss_scale=64, train_wall=17, gb_free=12.2, wall=20839
2023-06-27 22:06:13 - progress_bar.py[line:272] - INFO: epoch 013:    233 / 990 loss=2.295, loss_v1=0, loss_v2=0, nll_loss=1.085, ntokens=1776.7, nsentences=56, sample_size=1776.7, sample_size_v1=0, sample_size_v2=0, ppl=2.12, wps=1038.5, ups=0.58, wpb=1776.7, bsz=56, num_updates=12090, lr=7.55541e-06, gnorm=3.847, clip=100, loss_scale=64, train_wall=17, gb_free=13, wall=20856
2023-06-27 22:06:30 - progress_bar.py[line:272] - INFO: epoch 013:    243 / 990 loss=2.319, loss_v1=0, loss_v2=0, nll_loss=1.112, ntokens=1804.8, nsentences=56, sample_size=1804.8, sample_size_v1=0, sample_size_v2=0, ppl=2.16, wps=1053.4, ups=0.58, wpb=1804.8, bsz=56, num_updates=12100, lr=7.53526e-06, gnorm=3.657, clip=100, loss_scale=64, train_wall=17, gb_free=12.4, wall=20873
2023-06-27 22:06:48 - progress_bar.py[line:272] - INFO: epoch 013:    253 / 990 loss=2.316, loss_v1=0, loss_v2=0, nll_loss=1.109, ntokens=1951.6, nsentences=56, sample_size=1951.6, sample_size_v1=0, sample_size_v2=0, ppl=2.16, wps=1134.9, ups=0.58, wpb=1951.6, bsz=56, num_updates=12110, lr=7.51511e-06, gnorm=3.639, clip=100, loss_scale=64, train_wall=17, gb_free=11.7, wall=20890
2023-06-27 22:07:05 - progress_bar.py[line:272] - INFO: epoch 013:    263 / 990 loss=2.321, loss_v1=0, loss_v2=0, nll_loss=1.115, ntokens=1883.2, nsentences=56, sample_size=1883.2, sample_size_v1=0, sample_size_v2=0, ppl=2.17, wps=1096.8, ups=0.58, wpb=1883.2, bsz=56, num_updates=12120, lr=7.49496e-06, gnorm=3.56, clip=100, loss_scale=64, train_wall=17, gb_free=12.1, wall=20907
2023-06-27 22:07:22 - progress_bar.py[line:272] - INFO: epoch 013:    273 / 990 loss=2.338, loss_v1=0, loss_v2=0, nll_loss=1.133, ntokens=1892.3, nsentences=56, sample_size=1892.3, sample_size_v1=0, sample_size_v2=0, ppl=2.19, wps=1102.1, ups=0.58, wpb=1892.3, bsz=56, num_updates=12130, lr=7.47482e-06, gnorm=3.821, clip=100, loss_scale=64, train_wall=17, gb_free=12.8, wall=20925
2023-06-27 22:07:39 - progress_bar.py[line:272] - INFO: epoch 013:    283 / 990 loss=2.318, loss_v1=0, loss_v2=0, nll_loss=1.11, ntokens=1924.5, nsentences=56, sample_size=1924.5, sample_size_v1=0, sample_size_v2=0, ppl=2.16, wps=1111.8, ups=0.58, wpb=1924.5, bsz=56, num_updates=12140, lr=7.45467e-06, gnorm=3.5, clip=100, loss_scale=64, train_wall=17, gb_free=12.5, wall=20942
2023-06-27 22:07:56 - progress_bar.py[line:272] - INFO: epoch 013:    293 / 990 loss=2.321, loss_v1=0, loss_v2=0, nll_loss=1.114, ntokens=1832.1, nsentences=56, sample_size=1832.1, sample_size_v1=0, sample_size_v2=0, ppl=2.16, wps=1070.9, ups=0.58, wpb=1832.1, bsz=56, num_updates=12150, lr=7.43452e-06, gnorm=3.775, clip=100, loss_scale=64, train_wall=17, gb_free=12.7, wall=20959
2023-06-27 22:08:14 - progress_bar.py[line:272] - INFO: epoch 013:    303 / 990 loss=2.324, loss_v1=0, loss_v2=0, nll_loss=1.119, ntokens=1914.8, nsentences=56, sample_size=1914.8, sample_size_v1=0, sample_size_v2=0, ppl=2.17, wps=1110.5, ups=0.58, wpb=1914.8, bsz=56, num_updates=12160, lr=7.41437e-06, gnorm=3.37, clip=100, loss_scale=64, train_wall=17, gb_free=12.6, wall=20976
2023-06-27 22:08:31 - progress_bar.py[line:272] - INFO: epoch 013:    313 / 990 loss=2.324, loss_v1=0, loss_v2=0, nll_loss=1.118, ntokens=1903.6, nsentences=56, sample_size=1903.6, sample_size_v1=0, sample_size_v2=0, ppl=2.17, wps=1105.2, ups=0.58, wpb=1903.6, bsz=56, num_updates=12170, lr=7.39422e-06, gnorm=3.591, clip=100, loss_scale=64, train_wall=17, gb_free=10.8, wall=20994
2023-06-27 22:08:48 - progress_bar.py[line:272] - INFO: epoch 013:    323 / 990 loss=2.33, loss_v1=0, loss_v2=0, nll_loss=1.124, ntokens=1892.1, nsentences=56, sample_size=1892.1, sample_size_v1=0, sample_size_v2=0, ppl=2.18, wps=1098.4, ups=0.58, wpb=1892.1, bsz=56, num_updates=12180, lr=7.37408e-06, gnorm=3.652, clip=100, loss_scale=64, train_wall=17, gb_free=12.4, wall=21011
2023-06-27 22:09:05 - progress_bar.py[line:272] - INFO: epoch 013:    333 / 990 loss=2.297, loss_v1=0, loss_v2=0, nll_loss=1.09, ntokens=1888, nsentences=56, sample_size=1888, sample_size_v1=0, sample_size_v2=0, ppl=2.13, wps=1097.1, ups=0.58, wpb=1888, bsz=56, num_updates=12190, lr=7.35393e-06, gnorm=3.795, clip=100, loss_scale=64, train_wall=17, gb_free=11.7, wall=21028
2023-06-27 22:09:23 - progress_bar.py[line:272] - INFO: epoch 013:    343 / 990 loss=2.315, loss_v1=0, loss_v2=0, nll_loss=1.109, ntokens=1896.3, nsentences=56, sample_size=1896.3, sample_size_v1=0, sample_size_v2=0, ppl=2.16, wps=1085.1, ups=0.57, wpb=1896.3, bsz=56, num_updates=12200, lr=7.33378e-06, gnorm=3.509, clip=100, loss_scale=64, train_wall=17, gb_free=11.4, wall=21045
2023-06-27 22:09:40 - progress_bar.py[line:272] - INFO: epoch 013:    353 / 990 loss=2.306, loss_v1=0, loss_v2=0, nll_loss=1.098, ntokens=1891.3, nsentences=56, sample_size=1891.3, sample_size_v1=0, sample_size_v2=0, ppl=2.14, wps=1099.6, ups=0.58, wpb=1891.3, bsz=56, num_updates=12210, lr=7.31363e-06, gnorm=3.546, clip=100, loss_scale=64, train_wall=17, gb_free=12.5, wall=21063
2023-06-27 22:09:57 - progress_bar.py[line:272] - INFO: epoch 013:    363 / 990 loss=2.311, loss_v1=0, loss_v2=0, nll_loss=1.104, ntokens=1740.8, nsentences=56, sample_size=1740.8, sample_size_v1=0, sample_size_v2=0, ppl=2.15, wps=1018.9, ups=0.59, wpb=1740.8, bsz=56, num_updates=12220, lr=7.29349e-06, gnorm=3.731, clip=100, loss_scale=64, train_wall=17, gb_free=12.9, wall=21080
2023-06-27 22:10:14 - progress_bar.py[line:272] - INFO: epoch 013:    373 / 990 loss=2.34, loss_v1=0, loss_v2=0, nll_loss=1.137, ntokens=1798.8, nsentences=56, sample_size=1798.8, sample_size_v1=0, sample_size_v2=0, ppl=2.2, wps=1052.1, ups=0.58, wpb=1798.8, bsz=56, num_updates=12230, lr=7.27334e-06, gnorm=3.72, clip=100, loss_scale=64, train_wall=17, gb_free=12.8, wall=21097
2023-06-27 22:10:31 - progress_bar.py[line:272] - INFO: epoch 013:    383 / 990 loss=2.312, loss_v1=0, loss_v2=0, nll_loss=1.104, ntokens=1857.6, nsentences=56, sample_size=1857.6, sample_size_v1=0, sample_size_v2=0, ppl=2.15, wps=1088.6, ups=0.59, wpb=1857.6, bsz=56, num_updates=12240, lr=7.25319e-06, gnorm=3.684, clip=100, loss_scale=64, train_wall=17, gb_free=12.9, wall=21114
2023-06-27 22:10:48 - progress_bar.py[line:272] - INFO: epoch 013:    393 / 990 loss=2.288, loss_v1=0, loss_v2=0, nll_loss=1.078, ntokens=1733.4, nsentences=56, sample_size=1733.4, sample_size_v1=0, sample_size_v2=0, ppl=2.11, wps=1015.4, ups=0.59, wpb=1733.4, bsz=56, num_updates=12250, lr=7.23304e-06, gnorm=3.621, clip=100, loss_scale=64, train_wall=17, gb_free=12.6, wall=21131
2023-06-27 22:11:05 - progress_bar.py[line:272] - INFO: epoch 013:    403 / 990 loss=2.335, loss_v1=0, loss_v2=0, nll_loss=1.131, ntokens=1749.2, nsentences=56, sample_size=1749.2, sample_size_v1=0, sample_size_v2=0, ppl=2.19, wps=1029.3, ups=0.59, wpb=1749.2, bsz=56, num_updates=12260, lr=7.21289e-06, gnorm=3.702, clip=100, loss_scale=64, train_wall=17, gb_free=12.7, wall=21148
2023-06-27 22:11:22 - progress_bar.py[line:272] - INFO: epoch 013:    413 / 990 loss=2.339, loss_v1=0, loss_v2=0, nll_loss=1.135, ntokens=1698.3, nsentences=56, sample_size=1698.3, sample_size_v1=0, sample_size_v2=0, ppl=2.2, wps=997.8, ups=0.59, wpb=1698.3, bsz=56, num_updates=12270, lr=7.19275e-06, gnorm=3.918, clip=100, loss_scale=64, train_wall=17, gb_free=12.8, wall=21165
2023-06-27 22:11:39 - progress_bar.py[line:272] - INFO: epoch 013:    423 / 990 loss=2.322, loss_v1=0, loss_v2=0, nll_loss=1.115, ntokens=1744, nsentences=56, sample_size=1744, sample_size_v1=0, sample_size_v2=0, ppl=2.17, wps=1022.7, ups=0.59, wpb=1744, bsz=56, num_updates=12280, lr=7.1726e-06, gnorm=3.857, clip=100, loss_scale=64, train_wall=17, gb_free=13, wall=21182
2023-06-27 22:11:57 - progress_bar.py[line:272] - INFO: epoch 013:    433 / 990 loss=2.299, loss_v1=0, loss_v2=0, nll_loss=1.091, ntokens=1920.4, nsentences=56, sample_size=1920.4, sample_size_v1=0, sample_size_v2=0, ppl=2.13, wps=1117.7, ups=0.58, wpb=1920.4, bsz=56, num_updates=12290, lr=7.15245e-06, gnorm=3.481, clip=100, loss_scale=64, train_wall=17, gb_free=12.7, wall=21199
2023-06-27 22:12:14 - progress_bar.py[line:272] - INFO: epoch 013:    443 / 990 loss=2.303, loss_v1=0, loss_v2=0, nll_loss=1.094, ntokens=1879.6, nsentences=56, sample_size=1879.6, sample_size_v1=0, sample_size_v2=0, ppl=2.13, wps=1095.9, ups=0.58, wpb=1879.6, bsz=56, num_updates=12300, lr=7.1323e-06, gnorm=3.567, clip=100, loss_scale=64, train_wall=17, gb_free=12.9, wall=21216
2023-06-27 22:12:31 - progress_bar.py[line:272] - INFO: epoch 013:    453 / 990 loss=2.319, loss_v1=0, loss_v2=0, nll_loss=1.113, ntokens=1754.1, nsentences=56, sample_size=1754.1, sample_size_v1=0, sample_size_v2=0, ppl=2.16, wps=1031.2, ups=0.59, wpb=1754.1, bsz=56, num_updates=12310, lr=7.11216e-06, gnorm=3.704, clip=100, loss_scale=64, train_wall=17, gb_free=12.5, wall=21233
2023-06-27 22:12:48 - progress_bar.py[line:272] - INFO: epoch 013:    463 / 990 loss=2.313, loss_v1=0, loss_v2=0, nll_loss=1.107, ntokens=1848, nsentences=56, sample_size=1848, sample_size_v1=0, sample_size_v2=0, ppl=2.15, wps=1076.9, ups=0.58, wpb=1848, bsz=56, num_updates=12320, lr=7.09201e-06, gnorm=3.37, clip=100, loss_scale=64, train_wall=17, gb_free=13.1, wall=21251
2023-06-27 22:13:05 - progress_bar.py[line:272] - INFO: epoch 013:    473 / 990 loss=2.306, loss_v1=0, loss_v2=0, nll_loss=1.098, ntokens=1909.5, nsentences=56, sample_size=1909.5, sample_size_v1=0, sample_size_v2=0, ppl=2.14, wps=1106, ups=0.58, wpb=1909.5, bsz=56, num_updates=12330, lr=7.07186e-06, gnorm=3.574, clip=100, loss_scale=64, train_wall=17, gb_free=10.7, wall=21268
2023-06-27 22:13:22 - progress_bar.py[line:272] - INFO: epoch 013:    483 / 990 loss=2.302, loss_v1=0, loss_v2=0, nll_loss=1.092, ntokens=1797.5, nsentences=56, sample_size=1797.5, sample_size_v1=0, sample_size_v2=0, ppl=2.13, wps=1051.1, ups=0.58, wpb=1797.5, bsz=56, num_updates=12340, lr=7.05171e-06, gnorm=3.436, clip=100, loss_scale=64, train_wall=17, gb_free=12.9, wall=21285
2023-06-27 22:13:39 - progress_bar.py[line:272] - INFO: epoch 013:    493 / 990 loss=2.3, loss_v1=0, loss_v2=0, nll_loss=1.091, ntokens=1863.1, nsentences=56, sample_size=1863.1, sample_size_v1=0, sample_size_v2=0, ppl=2.13, wps=1085.2, ups=0.58, wpb=1863.1, bsz=56, num_updates=12350, lr=7.03156e-06, gnorm=3.519, clip=100, loss_scale=64, train_wall=17, gb_free=12.9, wall=21302
2023-06-27 22:13:57 - progress_bar.py[line:272] - INFO: epoch 013:    503 / 990 loss=2.337, loss_v1=0, loss_v2=0, nll_loss=1.133, ntokens=1852.3, nsentences=56, sample_size=1852.3, sample_size_v1=0, sample_size_v2=0, ppl=2.19, wps=1084.5, ups=0.59, wpb=1852.3, bsz=56, num_updates=12360, lr=7.01142e-06, gnorm=3.444, clip=100, loss_scale=64, train_wall=17, gb_free=13.1, wall=21319
2023-06-27 22:14:14 - progress_bar.py[line:272] - INFO: epoch 013:    513 / 990 loss=2.341, loss_v1=0, loss_v2=0, nll_loss=1.138, ntokens=1724, nsentences=56, sample_size=1724, sample_size_v1=0, sample_size_v2=0, ppl=2.2, wps=1008.4, ups=0.58, wpb=1724, bsz=56, num_updates=12370, lr=6.99127e-06, gnorm=3.668, clip=100, loss_scale=64, train_wall=17, gb_free=13.1, wall=21336
2023-06-27 22:14:31 - progress_bar.py[line:272] - INFO: epoch 013:    523 / 990 loss=2.311, loss_v1=0, loss_v2=0, nll_loss=1.105, ntokens=1858.7, nsentences=56, sample_size=1858.7, sample_size_v1=0, sample_size_v2=0, ppl=2.15, wps=1088.6, ups=0.59, wpb=1858.7, bsz=56, num_updates=12380, lr=6.97112e-06, gnorm=3.623, clip=100, loss_scale=64, train_wall=17, gb_free=12.7, wall=21353
2023-06-27 22:14:48 - progress_bar.py[line:272] - INFO: epoch 013:    533 / 990 loss=2.305, loss_v1=0, loss_v2=0, nll_loss=1.097, ntokens=1878.2, nsentences=56, sample_size=1878.2, sample_size_v1=0, sample_size_v2=0, ppl=2.14, wps=1096.2, ups=0.58, wpb=1878.2, bsz=56, num_updates=12390, lr=6.95097e-06, gnorm=3.645, clip=100, loss_scale=64, train_wall=17, gb_free=12.3, wall=21371
2023-06-27 22:15:05 - progress_bar.py[line:272] - INFO: epoch 013:    543 / 990 loss=2.325, loss_v1=0, loss_v2=0, nll_loss=1.118, ntokens=1961.7, nsentences=56, sample_size=1961.7, sample_size_v1=0, sample_size_v2=0, ppl=2.17, wps=1145.2, ups=0.58, wpb=1961.7, bsz=56, num_updates=12400, lr=6.93083e-06, gnorm=3.613, clip=100, loss_scale=64, train_wall=17, gb_free=12.7, wall=21388
2023-06-27 22:15:22 - progress_bar.py[line:272] - INFO: epoch 013:    553 / 990 loss=2.299, loss_v1=0, loss_v2=0, nll_loss=1.089, ntokens=1881.5, nsentences=56, sample_size=1881.5, sample_size_v1=0, sample_size_v2=0, ppl=2.13, wps=1100.8, ups=0.59, wpb=1881.5, bsz=56, num_updates=12410, lr=6.91068e-06, gnorm=3.552, clip=100, loss_scale=64, train_wall=17, gb_free=13, wall=21405
2023-06-27 22:15:39 - progress_bar.py[line:272] - INFO: epoch 013:    563 / 990 loss=2.303, loss_v1=0, loss_v2=0, nll_loss=1.095, ntokens=1779.1, nsentences=56, sample_size=1779.1, sample_size_v1=0, sample_size_v2=0, ppl=2.14, wps=1042.3, ups=0.59, wpb=1779.1, bsz=56, num_updates=12420, lr=6.89053e-06, gnorm=3.587, clip=100, loss_scale=64, train_wall=17, gb_free=13.1, wall=21422
2023-06-27 22:15:56 - progress_bar.py[line:272] - INFO: epoch 013:    573 / 990 loss=2.308, loss_v1=0, loss_v2=0, nll_loss=1.1, ntokens=1815.8, nsentences=56, sample_size=1815.8, sample_size_v1=0, sample_size_v2=0, ppl=2.14, wps=1066.6, ups=0.59, wpb=1815.8, bsz=56, num_updates=12430, lr=6.87038e-06, gnorm=3.627, clip=100, loss_scale=64, train_wall=17, gb_free=12.9, wall=21439
2023-06-27 22:16:13 - progress_bar.py[line:272] - INFO: epoch 013:    583 / 990 loss=2.344, loss_v1=0, loss_v2=0, nll_loss=1.142, ntokens=1883.5, nsentences=56, sample_size=1883.5, sample_size_v1=0, sample_size_v2=0, ppl=2.21, wps=1104.1, ups=0.59, wpb=1883.5, bsz=56, num_updates=12440, lr=6.85024e-06, gnorm=3.598, clip=100, loss_scale=64, train_wall=17, gb_free=12, wall=21456
2023-06-27 22:16:30 - progress_bar.py[line:272] - INFO: epoch 013:    593 / 990 loss=2.309, loss_v1=0, loss_v2=0, nll_loss=1.101, ntokens=1909.6, nsentences=56, sample_size=1909.6, sample_size_v1=0, sample_size_v2=0, ppl=2.15, wps=1117.6, ups=0.59, wpb=1909.6, bsz=56, num_updates=12450, lr=6.83009e-06, gnorm=3.278, clip=100, loss_scale=64, train_wall=17, gb_free=12.9, wall=21473
2023-06-27 22:16:47 - progress_bar.py[line:272] - INFO: epoch 013:    603 / 990 loss=2.322, loss_v1=0, loss_v2=0, nll_loss=1.115, ntokens=1732.9, nsentences=56, sample_size=1732.9, sample_size_v1=0, sample_size_v2=0, ppl=2.17, wps=1021.1, ups=0.59, wpb=1732.9, bsz=56, num_updates=12460, lr=6.80994e-06, gnorm=3.759, clip=100, loss_scale=64, train_wall=17, gb_free=12.8, wall=21490
2023-06-27 22:17:04 - progress_bar.py[line:272] - INFO: epoch 013:    613 / 990 loss=2.3, loss_v1=0, loss_v2=0, nll_loss=1.091, ntokens=1853.2, nsentences=56, sample_size=1853.2, sample_size_v1=0, sample_size_v2=0, ppl=2.13, wps=1091.3, ups=0.59, wpb=1853.2, bsz=56, num_updates=12470, lr=6.78979e-06, gnorm=3.806, clip=100, loss_scale=64, train_wall=17, gb_free=13.1, wall=21507
2023-06-27 22:17:21 - progress_bar.py[line:272] - INFO: epoch 013:    623 / 990 loss=2.329, loss_v1=0, loss_v2=0, nll_loss=1.124, ntokens=1991.1, nsentences=56, sample_size=1991.1, sample_size_v1=0, sample_size_v2=0, ppl=2.18, wps=1164.7, ups=0.58, wpb=1991.1, bsz=56, num_updates=12480, lr=6.76964e-06, gnorm=3.561, clip=100, loss_scale=64, train_wall=17, gb_free=12.4, wall=21524
2023-06-27 22:17:39 - progress_bar.py[line:272] - INFO: epoch 013:    633 / 990 loss=2.341, loss_v1=0, loss_v2=0, nll_loss=1.136, ntokens=2015.6, nsentences=56, sample_size=2015.6, sample_size_v1=0, sample_size_v2=0, ppl=2.2, wps=1172.8, ups=0.58, wpb=2015.6, bsz=56, num_updates=12490, lr=6.7495e-06, gnorm=3.334, clip=100, loss_scale=64, train_wall=17, gb_free=13, wall=21541
2023-06-27 22:17:56 - progress_bar.py[line:272] - INFO: epoch 013:    643 / 990 loss=2.31, loss_v1=0, loss_v2=0, nll_loss=1.103, ntokens=1989.3, nsentences=56, sample_size=1989.3, sample_size_v1=0, sample_size_v2=0, ppl=2.15, wps=1156.3, ups=0.58, wpb=1989.3, bsz=56, num_updates=12500, lr=6.72935e-06, gnorm=3.293, clip=100, loss_scale=64, train_wall=17, gb_free=13.1, wall=21558
2023-06-27 22:18:13 - progress_bar.py[line:272] - INFO: epoch 013:    653 / 990 loss=2.319, loss_v1=0, loss_v2=0, nll_loss=1.113, ntokens=1933.5, nsentences=56, sample_size=1933.5, sample_size_v1=0, sample_size_v2=0, ppl=2.16, wps=1131.1, ups=0.59, wpb=1933.5, bsz=56, num_updates=12510, lr=6.7092e-06, gnorm=3.558, clip=100, loss_scale=64, train_wall=17, gb_free=12.9, wall=21576
2023-06-27 22:18:30 - progress_bar.py[line:272] - INFO: epoch 013:    663 / 990 loss=2.317, loss_v1=0, loss_v2=0, nll_loss=1.11, ntokens=1893.4, nsentences=56, sample_size=1893.4, sample_size_v1=0, sample_size_v2=0, ppl=2.16, wps=1103.4, ups=0.58, wpb=1893.4, bsz=56, num_updates=12520, lr=6.68905e-06, gnorm=3.199, clip=100, loss_scale=64, train_wall=17, gb_free=12.4, wall=21593
2023-06-27 22:18:47 - progress_bar.py[line:272] - INFO: epoch 013:    673 / 990 loss=2.321, loss_v1=0, loss_v2=0, nll_loss=1.115, ntokens=1819.5, nsentences=56, sample_size=1819.5, sample_size_v1=0, sample_size_v2=0, ppl=2.17, wps=1061.5, ups=0.58, wpb=1819.5, bsz=56, num_updates=12530, lr=6.66891e-06, gnorm=3.643, clip=100, loss_scale=64, train_wall=17, gb_free=11.6, wall=21610
2023-06-27 22:19:04 - progress_bar.py[line:272] - INFO: epoch 013:    683 / 990 loss=2.275, loss_v1=0, loss_v2=0, nll_loss=1.063, ntokens=1889.2, nsentences=56, sample_size=1889.2, sample_size_v1=0, sample_size_v2=0, ppl=2.09, wps=1100.7, ups=0.58, wpb=1889.2, bsz=56, num_updates=12540, lr=6.64876e-06, gnorm=3.443, clip=100, loss_scale=64, train_wall=17, gb_free=13.1, wall=21627
2023-06-27 22:19:21 - progress_bar.py[line:272] - INFO: epoch 013:    693 / 990 loss=2.303, loss_v1=0, loss_v2=0, nll_loss=1.096, ntokens=1764.1, nsentences=56, sample_size=1764.1, sample_size_v1=0, sample_size_v2=0, ppl=2.14, wps=1035.4, ups=0.59, wpb=1764.1, bsz=56, num_updates=12550, lr=6.62861e-06, gnorm=3.576, clip=100, loss_scale=64, train_wall=17, gb_free=12.1, wall=21644
2023-06-27 22:19:38 - progress_bar.py[line:272] - INFO: epoch 013:    703 / 990 loss=2.326, loss_v1=0, loss_v2=0, nll_loss=1.121, ntokens=1714.9, nsentences=56, sample_size=1714.9, sample_size_v1=0, sample_size_v2=0, ppl=2.17, wps=1007.2, ups=0.59, wpb=1714.9, bsz=56, num_updates=12560, lr=6.60846e-06, gnorm=3.857, clip=100, loss_scale=64, train_wall=17, gb_free=12.9, wall=21661
2023-06-27 22:19:55 - progress_bar.py[line:272] - INFO: epoch 013:    713 / 990 loss=2.32, loss_v1=0, loss_v2=0, nll_loss=1.113, ntokens=1778.6, nsentences=56, sample_size=1778.6, sample_size_v1=0, sample_size_v2=0, ppl=2.16, wps=1047.4, ups=0.59, wpb=1778.6, bsz=56, num_updates=12570, lr=6.58831e-06, gnorm=4.024, clip=100, loss_scale=64, train_wall=17, gb_free=12.6, wall=21678
2023-06-27 22:20:12 - progress_bar.py[line:272] - INFO: epoch 013:    723 / 990 loss=2.309, loss_v1=0, loss_v2=0, nll_loss=1.101, ntokens=1751.9, nsentences=56, sample_size=1751.9, sample_size_v1=0, sample_size_v2=0, ppl=2.15, wps=1034.3, ups=0.59, wpb=1751.9, bsz=56, num_updates=12580, lr=6.56817e-06, gnorm=3.709, clip=100, loss_scale=128, train_wall=17, gb_free=12.8, wall=21695
2023-06-27 22:20:29 - progress_bar.py[line:272] - INFO: epoch 013:    733 / 990 loss=2.279, loss_v1=0, loss_v2=0, nll_loss=1.068, ntokens=1818.1, nsentences=56, sample_size=1818.1, sample_size_v1=0, sample_size_v2=0, ppl=2.1, wps=1064.9, ups=0.59, wpb=1818.1, bsz=56, num_updates=12590, lr=6.54802e-06, gnorm=3.772, clip=100, loss_scale=128, train_wall=17, gb_free=12.9, wall=21712
2023-06-27 22:20:46 - progress_bar.py[line:272] - INFO: epoch 013:    743 / 990 loss=2.326, loss_v1=0, loss_v2=0, nll_loss=1.121, ntokens=1794.8, nsentences=56, sample_size=1794.8, sample_size_v1=0, sample_size_v2=0, ppl=2.18, wps=1054.6, ups=0.59, wpb=1794.8, bsz=56, num_updates=12600, lr=6.52787e-06, gnorm=3.671, clip=100, loss_scale=128, train_wall=17, gb_free=12.6, wall=21729
2023-06-27 22:21:03 - progress_bar.py[line:272] - INFO: epoch 013:    753 / 990 loss=2.337, loss_v1=0, loss_v2=0, nll_loss=1.131, ntokens=1659.3, nsentences=56, sample_size=1659.3, sample_size_v1=0, sample_size_v2=0, ppl=2.19, wps=979.8, ups=0.59, wpb=1659.3, bsz=56, num_updates=12610, lr=6.50772e-06, gnorm=3.841, clip=100, loss_scale=128, train_wall=17, gb_free=12.9, wall=21746
2023-06-27 22:21:20 - progress_bar.py[line:272] - INFO: epoch 013:    763 / 990 loss=2.314, loss_v1=0, loss_v2=0, nll_loss=1.106, ntokens=1746.8, nsentences=56, sample_size=1746.8, sample_size_v1=0, sample_size_v2=0, ppl=2.15, wps=1027.1, ups=0.59, wpb=1746.8, bsz=56, num_updates=12620, lr=6.48758e-06, gnorm=3.624, clip=100, loss_scale=128, train_wall=17, gb_free=13, wall=21763
2023-06-27 22:21:38 - progress_bar.py[line:272] - INFO: epoch 013:    773 / 990 loss=2.316, loss_v1=0, loss_v2=0, nll_loss=1.109, ntokens=1838.2, nsentences=56, sample_size=1838.2, sample_size_v1=0, sample_size_v2=0, ppl=2.16, wps=1076.3, ups=0.59, wpb=1838.2, bsz=56, num_updates=12630, lr=6.46743e-06, gnorm=3.611, clip=100, loss_scale=128, train_wall=17, gb_free=12.6, wall=21780
2023-06-27 22:21:39 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2023-06-27 22:21:56 - progress_bar.py[line:272] - INFO: epoch 013:    784 / 990 loss=2.305, loss_v1=0, loss_v2=0, nll_loss=1.097, ntokens=1760.8, nsentences=56, sample_size=1760.8, sample_size_v1=0, sample_size_v2=0, ppl=2.14, wps=944.3, ups=0.54, wpb=1760.8, bsz=56, num_updates=12640, lr=6.44728e-06, gnorm=3.811, clip=100, loss_scale=64, train_wall=19, gb_free=12.4, wall=21799
2023-06-27 22:22:13 - progress_bar.py[line:272] - INFO: epoch 013:    794 / 990 loss=2.321, loss_v1=0, loss_v2=0, nll_loss=1.115, ntokens=1847.5, nsentences=56, sample_size=1847.5, sample_size_v1=0, sample_size_v2=0, ppl=2.17, wps=1078, ups=0.58, wpb=1847.5, bsz=56, num_updates=12650, lr=6.42713e-06, gnorm=3.56, clip=100, loss_scale=64, train_wall=17, gb_free=11.4, wall=21816
2023-06-27 22:22:30 - progress_bar.py[line:272] - INFO: epoch 013:    804 / 990 loss=2.314, loss_v1=0, loss_v2=0, nll_loss=1.107, ntokens=1748.1, nsentences=56, sample_size=1748.1, sample_size_v1=0, sample_size_v2=0, ppl=2.15, wps=1027.8, ups=0.59, wpb=1748.1, bsz=56, num_updates=12660, lr=6.40698e-06, gnorm=3.748, clip=100, loss_scale=64, train_wall=17, gb_free=12.5, wall=21833
2023-06-27 22:22:47 - progress_bar.py[line:272] - INFO: epoch 013:    814 / 990 loss=2.334, loss_v1=0, loss_v2=0, nll_loss=1.129, ntokens=1668.7, nsentences=56, sample_size=1668.7, sample_size_v1=0, sample_size_v2=0, ppl=2.19, wps=985.1, ups=0.59, wpb=1668.7, bsz=56, num_updates=12670, lr=6.38684e-06, gnorm=4.002, clip=100, loss_scale=64, train_wall=17, gb_free=13, wall=21850
2023-06-27 22:23:04 - progress_bar.py[line:272] - INFO: epoch 013:    824 / 990 loss=2.307, loss_v1=0, loss_v2=0, nll_loss=1.098, ntokens=1697.5, nsentences=56, sample_size=1697.5, sample_size_v1=0, sample_size_v2=0, ppl=2.14, wps=994.4, ups=0.59, wpb=1697.5, bsz=56, num_updates=12680, lr=6.36669e-06, gnorm=3.697, clip=100, loss_scale=64, train_wall=17, gb_free=12.6, wall=21867
2023-06-27 22:23:21 - progress_bar.py[line:272] - INFO: epoch 013:    834 / 990 loss=2.282, loss_v1=0, loss_v2=0, nll_loss=1.071, ntokens=1772, nsentences=56, sample_size=1772, sample_size_v1=0, sample_size_v2=0, ppl=2.1, wps=1044.2, ups=0.59, wpb=1772, bsz=56, num_updates=12690, lr=6.34654e-06, gnorm=3.643, clip=100, loss_scale=64, train_wall=17, gb_free=12.9, wall=21884
2023-06-27 22:23:38 - progress_bar.py[line:272] - INFO: epoch 013:    844 / 990 loss=2.299, loss_v1=0, loss_v2=0, nll_loss=1.092, ntokens=1853.7, nsentences=56, sample_size=1853.7, sample_size_v1=0, sample_size_v2=0, ppl=2.13, wps=1086.4, ups=0.59, wpb=1853.7, bsz=56, num_updates=12700, lr=6.32639e-06, gnorm=3.864, clip=100, loss_scale=64, train_wall=17, gb_free=12.9, wall=21901
2023-06-27 22:23:56 - progress_bar.py[line:272] - INFO: epoch 013:    854 / 990 loss=2.277, loss_v1=0, loss_v2=0, nll_loss=1.066, ntokens=1887.7, nsentences=56, sample_size=1887.7, sample_size_v1=0, sample_size_v2=0, ppl=2.09, wps=1098.8, ups=0.58, wpb=1887.7, bsz=56, num_updates=12710, lr=6.30625e-06, gnorm=3.613, clip=100, loss_scale=64, train_wall=17, gb_free=12.4, wall=21918
2023-06-27 22:24:13 - progress_bar.py[line:272] - INFO: epoch 013:    864 / 990 loss=2.297, loss_v1=0, loss_v2=0, nll_loss=1.087, ntokens=1822, nsentences=56, sample_size=1822, sample_size_v1=0, sample_size_v2=0, ppl=2.12, wps=1065.5, ups=0.58, wpb=1822, bsz=56, num_updates=12720, lr=6.2861e-06, gnorm=3.84, clip=100, loss_scale=64, train_wall=17, gb_free=12.5, wall=21935
2023-06-27 22:24:30 - progress_bar.py[line:272] - INFO: epoch 013:    874 / 990 loss=2.293, loss_v1=0, loss_v2=0, nll_loss=1.084, ntokens=1864.1, nsentences=56, sample_size=1864.1, sample_size_v1=0, sample_size_v2=0, ppl=2.12, wps=1087.2, ups=0.58, wpb=1864.1, bsz=56, num_updates=12730, lr=6.26595e-06, gnorm=3.404, clip=100, loss_scale=64, train_wall=17, gb_free=12.3, wall=21952
2023-06-27 22:24:47 - progress_bar.py[line:272] - INFO: epoch 013:    884 / 990 loss=2.293, loss_v1=0, loss_v2=0, nll_loss=1.084, ntokens=1882.5, nsentences=56, sample_size=1882.5, sample_size_v1=0, sample_size_v2=0, ppl=2.12, wps=1103.7, ups=0.59, wpb=1882.5, bsz=56, num_updates=12740, lr=6.2458e-06, gnorm=3.648, clip=100, loss_scale=64, train_wall=17, gb_free=12.8, wall=21970
2023-06-27 22:25:04 - progress_bar.py[line:272] - INFO: epoch 013:    894 / 990 loss=2.289, loss_v1=0, loss_v2=0, nll_loss=1.079, ntokens=1974.3, nsentences=56, sample_size=1974.3, sample_size_v1=0, sample_size_v2=0, ppl=2.11, wps=1151.5, ups=0.58, wpb=1974.3, bsz=56, num_updates=12750, lr=6.22565e-06, gnorm=3.463, clip=100, loss_scale=64, train_wall=17, gb_free=12.8, wall=21987
2023-06-27 22:25:21 - progress_bar.py[line:272] - INFO: epoch 013:    904 / 990 loss=2.322, loss_v1=0, loss_v2=0, nll_loss=1.115, ntokens=1736.5, nsentences=56, sample_size=1736.5, sample_size_v1=0, sample_size_v2=0, ppl=2.17, wps=1017.3, ups=0.59, wpb=1736.5, bsz=56, num_updates=12760, lr=6.20551e-06, gnorm=4.056, clip=100, loss_scale=64, train_wall=17, gb_free=12.5, wall=22004
2023-06-27 22:25:38 - progress_bar.py[line:272] - INFO: epoch 013:    914 / 990 loss=2.315, loss_v1=0, loss_v2=0, nll_loss=1.108, ntokens=1771.2, nsentences=56, sample_size=1771.2, sample_size_v1=0, sample_size_v2=0, ppl=2.16, wps=1042.5, ups=0.59, wpb=1771.2, bsz=56, num_updates=12770, lr=6.18536e-06, gnorm=3.748, clip=100, loss_scale=64, train_wall=17, gb_free=12.9, wall=22021
2023-06-27 22:25:55 - progress_bar.py[line:272] - INFO: epoch 013:    924 / 990 loss=2.282, loss_v1=0, loss_v2=0, nll_loss=1.071, ntokens=1753.4, nsentences=56, sample_size=1753.4, sample_size_v1=0, sample_size_v2=0, ppl=2.1, wps=1027.5, ups=0.59, wpb=1753.4, bsz=56, num_updates=12780, lr=6.16521e-06, gnorm=3.774, clip=100, loss_scale=64, train_wall=17, gb_free=12.9, wall=22038
2023-06-27 22:26:12 - progress_bar.py[line:272] - INFO: epoch 013:    934 / 990 loss=2.282, loss_v1=0, loss_v2=0, nll_loss=1.071, ntokens=1845.8, nsentences=56, sample_size=1845.8, sample_size_v1=0, sample_size_v2=0, ppl=2.1, wps=1080.6, ups=0.59, wpb=1845.8, bsz=56, num_updates=12790, lr=6.14506e-06, gnorm=3.794, clip=100, loss_scale=64, train_wall=17, gb_free=13.1, wall=22055
2023-06-27 22:26:29 - progress_bar.py[line:272] - INFO: epoch 013:    944 / 990 loss=2.291, loss_v1=0, loss_v2=0, nll_loss=1.082, ntokens=1882.7, nsentences=56, sample_size=1882.7, sample_size_v1=0, sample_size_v2=0, ppl=2.12, wps=1096.3, ups=0.58, wpb=1882.7, bsz=56, num_updates=12800, lr=6.12492e-06, gnorm=3.781, clip=100, loss_scale=64, train_wall=17, gb_free=12.9, wall=22072
2023-06-27 22:26:47 - progress_bar.py[line:272] - INFO: epoch 013:    954 / 990 loss=2.299, loss_v1=0, loss_v2=0, nll_loss=1.09, ntokens=1927.3, nsentences=56, sample_size=1927.3, sample_size_v1=0, sample_size_v2=0, ppl=2.13, wps=1125.1, ups=0.58, wpb=1927.3, bsz=56, num_updates=12810, lr=6.10477e-06, gnorm=3.689, clip=100, loss_scale=64, train_wall=17, gb_free=13.1, wall=22089
2023-06-27 22:27:04 - progress_bar.py[line:272] - INFO: epoch 013:    964 / 990 loss=2.306, loss_v1=0, loss_v2=0, nll_loss=1.098, ntokens=1878.2, nsentences=56, sample_size=1878.2, sample_size_v1=0, sample_size_v2=0, ppl=2.14, wps=1099.4, ups=0.59, wpb=1878.2, bsz=56, num_updates=12820, lr=6.08462e-06, gnorm=3.644, clip=100, loss_scale=64, train_wall=17, gb_free=13, wall=22106
2023-06-27 22:27:21 - progress_bar.py[line:272] - INFO: epoch 013:    974 / 990 loss=2.289, loss_v1=0, loss_v2=0, nll_loss=1.08, ntokens=1945, nsentences=56, sample_size=1945, sample_size_v1=0, sample_size_v2=0, ppl=2.11, wps=1131.6, ups=0.58, wpb=1945, bsz=56, num_updates=12830, lr=6.06447e-06, gnorm=3.76, clip=100, loss_scale=64, train_wall=17, gb_free=12.8, wall=22124
2023-06-27 22:27:38 - progress_bar.py[line:272] - INFO: epoch 013:    984 / 990 loss=2.305, loss_v1=0, loss_v2=0, nll_loss=1.097, ntokens=1795.5, nsentences=56, sample_size=1795.5, sample_size_v1=0, sample_size_v2=0, ppl=2.14, wps=1055.1, ups=0.59, wpb=1795.5, bsz=56, num_updates=12840, lr=6.04433e-06, gnorm=4.007, clip=100, loss_scale=64, train_wall=17, gb_free=12.4, wall=22141
local datafile ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 1 begin to initialize row_count and line_idx-to-offset mapping
2023-06-27 22:27:47 - train.py[line:332] - INFO: end of epoch 13 (average epoch stats below)
2023-06-27 22:27:47 - progress_bar.py[line:282] - INFO: epoch 013 | loss 2.295 | loss_v1 0 | loss_v2 0 | nll_loss 1.085 | ntokens 1849.61 | nsentences 55.959 | sample_size 1849.61 | sample_size_v1 0 | sample_size_v2 0 | ppl 2.12 | wps 1074.2 | ups 0.58 | wpb 1849.6 | bsz 56 | num_updates 12846 | lr 6.03224e-06 | gnorm 3.628 | clip 100 | loss_scale 64 | train_wall 1694 | gb_free 13.3 | wall 22150
2023-06-27 22:27:47 - trainer.py[line:639] - INFO: loading train data for epoch 14
local datafile ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 0 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 1 finished initializing row_count and line_idx-to-offset mapping
file ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 1 row count 27700 total row count 55400
local datafile ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 0 finished initializing row_count and line_idx-to-offset mapping
file ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 0 row count 27700 total row count 55400
slice_id 1 seek offset 27700
slice_id 0 seek offset 0
2023-06-27 22:27:49 - trainer.py[line:703] - INFO: begin training epoch 14
2023-06-27 22:27:49 - train.py[line:305] - INFO: Start iterating over samples
2023-06-27 22:27:56 - progress_bar.py[line:272] - INFO: epoch 014:      4 / 990 loss=2.313, loss_v1=0, loss_v2=0, nll_loss=1.106, ntokens=1789.4, nsentences=53.2, sample_size=1789.4, sample_size_v1=0, sample_size_v2=0, ppl=2.15, wps=961.7, ups=0.54, wpb=1789.4, bsz=53.2, num_updates=12850, lr=6.02418e-06, gnorm=4.114, clip=100, loss_scale=64, train_wall=16, gb_free=12.4, wall=22159
2023-06-27 22:28:14 - progress_bar.py[line:272] - INFO: epoch 014:     14 / 990 loss=2.257, loss_v1=0, loss_v2=0, nll_loss=1.043, ntokens=1790.5, nsentences=56, sample_size=1790.5, sample_size_v1=0, sample_size_v2=0, ppl=2.06, wps=1042.1, ups=0.58, wpb=1790.5, bsz=56, num_updates=12860, lr=6.00403e-06, gnorm=3.797, clip=100, loss_scale=64, train_wall=17, gb_free=12.7, wall=22176
2023-06-27 22:28:31 - progress_bar.py[line:272] - INFO: epoch 014:     24 / 990 loss=2.224, loss_v1=0, loss_v2=0, nll_loss=1.006, ntokens=1851.2, nsentences=56, sample_size=1851.2, sample_size_v1=0, sample_size_v2=0, ppl=2.01, wps=1061.4, ups=0.57, wpb=1851.2, bsz=56, num_updates=12870, lr=5.98388e-06, gnorm=3.547, clip=100, loss_scale=64, train_wall=17, gb_free=12.4, wall=22194
2023-06-27 22:28:48 - progress_bar.py[line:272] - INFO: epoch 014:     34 / 990 loss=2.256, loss_v1=0, loss_v2=0, nll_loss=1.041, ntokens=1720.7, nsentences=56, sample_size=1720.7, sample_size_v1=0, sample_size_v2=0, ppl=2.06, wps=1011.5, ups=0.59, wpb=1720.7, bsz=56, num_updates=12880, lr=5.96373e-06, gnorm=3.796, clip=100, loss_scale=64, train_wall=17, gb_free=12.4, wall=22211
2023-06-27 22:29:05 - progress_bar.py[line:272] - INFO: epoch 014:     44 / 990 loss=2.17, loss_v1=0, loss_v2=0, nll_loss=0.945, ntokens=2014.5, nsentences=56, sample_size=2014.5, sample_size_v1=0, sample_size_v2=0, ppl=1.93, wps=1160.5, ups=0.58, wpb=2014.5, bsz=56, num_updates=12890, lr=5.94359e-06, gnorm=3.244, clip=100, loss_scale=64, train_wall=17, gb_free=11.6, wall=22228
2023-06-27 22:29:23 - progress_bar.py[line:272] - INFO: epoch 014:     54 / 990 loss=2.247, loss_v1=0, loss_v2=0, nll_loss=1.035, ntokens=1709.6, nsentences=56, sample_size=1709.6, sample_size_v1=0, sample_size_v2=0, ppl=2.05, wps=994.1, ups=0.58, wpb=1709.6, bsz=56, num_updates=12900, lr=5.92344e-06, gnorm=3.904, clip=100, loss_scale=64, train_wall=17, gb_free=11.6, wall=22245
2023-06-27 22:29:40 - progress_bar.py[line:272] - INFO: epoch 014:     64 / 990 loss=2.173, loss_v1=0, loss_v2=0, nll_loss=0.951, ntokens=1839.5, nsentences=56, sample_size=1839.5, sample_size_v1=0, sample_size_v2=0, ppl=1.93, wps=1068.3, ups=0.58, wpb=1839.5, bsz=56, num_updates=12910, lr=5.90329e-06, gnorm=3.584, clip=100, loss_scale=64, train_wall=17, gb_free=12.5, wall=22263
2023-06-27 22:29:57 - progress_bar.py[line:272] - INFO: epoch 014:     74 / 990 loss=2.106, loss_v1=0, loss_v2=0, nll_loss=0.875, ntokens=2066, nsentences=56, sample_size=2066, sample_size_v1=0, sample_size_v2=0, ppl=1.83, wps=1180.9, ups=0.57, wpb=2066, bsz=56, num_updates=12920, lr=5.88314e-06, gnorm=3.263, clip=100, loss_scale=64, train_wall=17, gb_free=11.9, wall=22280
2023-06-27 22:30:15 - progress_bar.py[line:272] - INFO: epoch 014:     84 / 990 loss=2.172, loss_v1=0, loss_v2=0, nll_loss=0.948, ntokens=2172.9, nsentences=56, sample_size=2172.9, sample_size_v1=0, sample_size_v2=0, ppl=1.93, wps=1224.7, ups=0.56, wpb=2172.9, bsz=56, num_updates=12930, lr=5.863e-06, gnorm=3.231, clip=100, loss_scale=64, train_wall=18, gb_free=11.3, wall=22298
2023-06-27 22:30:33 - progress_bar.py[line:272] - INFO: epoch 014:     94 / 990 loss=2.196, loss_v1=0, loss_v2=0, nll_loss=0.975, ntokens=1971.6, nsentences=56, sample_size=1971.6, sample_size_v1=0, sample_size_v2=0, ppl=1.97, wps=1129.2, ups=0.57, wpb=1971.6, bsz=56, num_updates=12940, lr=5.84285e-06, gnorm=3.813, clip=100, loss_scale=64, train_wall=17, gb_free=11.8, wall=22315
2023-06-27 22:30:50 - progress_bar.py[line:272] - INFO: epoch 014:    104 / 990 loss=2.228, loss_v1=0, loss_v2=0, nll_loss=1.011, ntokens=1862.3, nsentences=56, sample_size=1862.3, sample_size_v1=0, sample_size_v2=0, ppl=2.02, wps=1080.4, ups=0.58, wpb=1862.3, bsz=56, num_updates=12950, lr=5.8227e-06, gnorm=3.789, clip=100, loss_scale=64, train_wall=17, gb_free=12.5, wall=22333
2023-06-27 22:31:07 - progress_bar.py[line:272] - INFO: epoch 014:    114 / 990 loss=2.231, loss_v1=0, loss_v2=0, nll_loss=1.015, ntokens=1840.7, nsentences=56, sample_size=1840.7, sample_size_v1=0, sample_size_v2=0, ppl=2.02, wps=1074.2, ups=0.58, wpb=1840.7, bsz=56, num_updates=12960, lr=5.80255e-06, gnorm=4.291, clip=100, loss_scale=64, train_wall=17, gb_free=13, wall=22350
2023-06-27 22:31:24 - progress_bar.py[line:272] - INFO: epoch 014:    124 / 990 loss=2.284, loss_v1=0, loss_v2=0, nll_loss=1.075, ntokens=1803.4, nsentences=56, sample_size=1803.4, sample_size_v1=0, sample_size_v2=0, ppl=2.11, wps=1052.3, ups=0.58, wpb=1803.4, bsz=56, num_updates=12970, lr=5.7824e-06, gnorm=4.124, clip=100, loss_scale=64, train_wall=17, gb_free=12.8, wall=22367
2023-06-27 22:31:41 - progress_bar.py[line:272] - INFO: epoch 014:    134 / 990 loss=2.302, loss_v1=0, loss_v2=0, nll_loss=1.093, ntokens=1845, nsentences=56, sample_size=1845, sample_size_v1=0, sample_size_v2=0, ppl=2.13, wps=1068, ups=0.58, wpb=1845, bsz=56, num_updates=12980, lr=5.76226e-06, gnorm=3.81, clip=100, loss_scale=64, train_wall=17, gb_free=12.4, wall=22384
2023-06-27 22:31:59 - progress_bar.py[line:272] - INFO: epoch 014:    144 / 990 loss=2.273, loss_v1=0, loss_v2=0, nll_loss=1.059, ntokens=1943.1, nsentences=56, sample_size=1943.1, sample_size_v1=0, sample_size_v2=0, ppl=2.08, wps=1113.8, ups=0.57, wpb=1943.1, bsz=56, num_updates=12990, lr=5.74211e-06, gnorm=3.836, clip=100, loss_scale=64, train_wall=17, gb_free=12.5, wall=22402
2023-06-27 22:32:16 - progress_bar.py[line:272] - INFO: epoch 014:    154 / 990 loss=2.261, loss_v1=0, loss_v2=0, nll_loss=1.047, ntokens=1938.2, nsentences=56, sample_size=1938.2, sample_size_v1=0, sample_size_v2=0, ppl=2.07, wps=1113.8, ups=0.57, wpb=1938.2, bsz=56, num_updates=13000, lr=5.72196e-06, gnorm=3.768, clip=100, loss_scale=64, train_wall=17, gb_free=12.5, wall=22419
2023-06-27 22:32:34 - progress_bar.py[line:272] - INFO: epoch 014:    164 / 990 loss=2.253, loss_v1=0, loss_v2=0, nll_loss=1.038, ntokens=2009, nsentences=56, sample_size=2009, sample_size_v1=0, sample_size_v2=0, ppl=2.05, wps=1148.9, ups=0.57, wpb=2009, bsz=56, num_updates=13010, lr=5.70181e-06, gnorm=3.489, clip=100, loss_scale=64, train_wall=17, gb_free=11.9, wall=22436
2023-06-27 22:32:51 - progress_bar.py[line:272] - INFO: epoch 014:    174 / 990 loss=2.238, loss_v1=0, loss_v2=0, nll_loss=1.023, ntokens=1935.6, nsentences=56, sample_size=1935.6, sample_size_v1=0, sample_size_v2=0, ppl=2.03, wps=1112.9, ups=0.57, wpb=1935.6, bsz=56, num_updates=13020, lr=5.68167e-06, gnorm=3.513, clip=100, loss_scale=64, train_wall=17, gb_free=12, wall=22454
2023-06-27 22:33:09 - progress_bar.py[line:272] - INFO: epoch 014:    184 / 990 loss=2.267, loss_v1=0, loss_v2=0, nll_loss=1.054, ntokens=1902.2, nsentences=56, sample_size=1902.2, sample_size_v1=0, sample_size_v2=0, ppl=2.08, wps=1096.1, ups=0.58, wpb=1902.2, bsz=56, num_updates=13030, lr=5.66152e-06, gnorm=3.875, clip=100, loss_scale=64, train_wall=17, gb_free=12.7, wall=22471
2023-06-27 22:33:26 - progress_bar.py[line:272] - INFO: epoch 014:    194 / 990 loss=2.257, loss_v1=0, loss_v2=0, nll_loss=1.043, ntokens=1869, nsentences=56, sample_size=1869, sample_size_v1=0, sample_size_v2=0, ppl=2.06, wps=1085.1, ups=0.58, wpb=1869, bsz=56, num_updates=13040, lr=5.64137e-06, gnorm=3.604, clip=100, loss_scale=64, train_wall=17, gb_free=12.8, wall=22488
2023-06-27 22:33:43 - progress_bar.py[line:272] - INFO: epoch 014:    204 / 990 loss=2.242, loss_v1=0, loss_v2=0, nll_loss=1.026, ntokens=1885.2, nsentences=56, sample_size=1885.2, sample_size_v1=0, sample_size_v2=0, ppl=2.04, wps=1089.7, ups=0.58, wpb=1885.2, bsz=56, num_updates=13050, lr=5.62122e-06, gnorm=4.015, clip=100, loss_scale=64, train_wall=17, gb_free=12.5, wall=22506
2023-06-27 22:34:01 - progress_bar.py[line:272] - INFO: epoch 014:    214 / 990 loss=2.249, loss_v1=0, loss_v2=0, nll_loss=1.034, ntokens=1912.5, nsentences=56, sample_size=1912.5, sample_size_v1=0, sample_size_v2=0, ppl=2.05, wps=1087.7, ups=0.57, wpb=1912.5, bsz=56, num_updates=13060, lr=5.60107e-06, gnorm=3.732, clip=100, loss_scale=64, train_wall=18, gb_free=12.6, wall=22523
2023-06-27 22:34:18 - progress_bar.py[line:272] - INFO: epoch 014:    224 / 990 loss=2.264, loss_v1=0, loss_v2=0, nll_loss=1.051, ntokens=1924.5, nsentences=56, sample_size=1924.5, sample_size_v1=0, sample_size_v2=0, ppl=2.07, wps=1108, ups=0.58, wpb=1924.5, bsz=56, num_updates=13070, lr=5.58093e-06, gnorm=3.592, clip=100, loss_scale=64, train_wall=17, gb_free=12.2, wall=22541
2023-06-27 22:34:35 - progress_bar.py[line:272] - INFO: epoch 014:    234 / 990 loss=2.298, loss_v1=0, loss_v2=0, nll_loss=1.088, ntokens=1750, nsentences=56, sample_size=1750, sample_size_v1=0, sample_size_v2=0, ppl=2.13, wps=1021.9, ups=0.58, wpb=1750, bsz=56, num_updates=13080, lr=5.56078e-06, gnorm=4.103, clip=100, loss_scale=64, train_wall=17, gb_free=12.6, wall=22558
2023-06-27 22:34:52 - progress_bar.py[line:272] - INFO: epoch 014:    244 / 990 loss=2.312, loss_v1=0, loss_v2=0, nll_loss=1.104, ntokens=1872.4, nsentences=56, sample_size=1872.4, sample_size_v1=0, sample_size_v2=0, ppl=2.15, wps=1086.4, ups=0.58, wpb=1872.4, bsz=56, num_updates=13090, lr=5.54063e-06, gnorm=3.839, clip=100, loss_scale=64, train_wall=17, gb_free=12.2, wall=22575
2023-06-27 22:35:10 - progress_bar.py[line:272] - INFO: epoch 014:    254 / 990 loss=2.298, loss_v1=0, loss_v2=0, nll_loss=1.09, ntokens=1923.2, nsentences=56, sample_size=1923.2, sample_size_v1=0, sample_size_v2=0, ppl=2.13, wps=1118.9, ups=0.58, wpb=1923.2, bsz=56, num_updates=13100, lr=5.52048e-06, gnorm=3.724, clip=100, loss_scale=64, train_wall=17, gb_free=12.4, wall=22592
2023-06-27 22:35:27 - progress_bar.py[line:272] - INFO: epoch 014:    264 / 990 loss=2.325, loss_v1=0, loss_v2=0, nll_loss=1.119, ntokens=1848.1, nsentences=56, sample_size=1848.1, sample_size_v1=0, sample_size_v2=0, ppl=2.17, wps=1077.2, ups=0.58, wpb=1848.1, bsz=56, num_updates=13110, lr=5.50034e-06, gnorm=3.861, clip=100, loss_scale=64, train_wall=17, gb_free=12.6, wall=22609
2023-06-27 22:35:44 - progress_bar.py[line:272] - INFO: epoch 014:    274 / 990 loss=2.324, loss_v1=0, loss_v2=0, nll_loss=1.117, ntokens=1924.2, nsentences=56, sample_size=1924.2, sample_size_v1=0, sample_size_v2=0, ppl=2.17, wps=1115.7, ups=0.58, wpb=1924.2, bsz=56, num_updates=13120, lr=5.48019e-06, gnorm=3.774, clip=100, loss_scale=64, train_wall=17, gb_free=12.3, wall=22627
2023-06-27 22:36:01 - progress_bar.py[line:272] - INFO: epoch 014:    284 / 990 loss=2.316, loss_v1=0, loss_v2=0, nll_loss=1.109, ntokens=1893.2, nsentences=56, sample_size=1893.2, sample_size_v1=0, sample_size_v2=0, ppl=2.16, wps=1092, ups=0.58, wpb=1893.2, bsz=56, num_updates=13130, lr=5.46004e-06, gnorm=3.622, clip=100, loss_scale=64, train_wall=17, gb_free=12.6, wall=22644
2023-06-27 22:36:18 - progress_bar.py[line:272] - INFO: epoch 014:    294 / 990 loss=2.321, loss_v1=0, loss_v2=0, nll_loss=1.115, ntokens=1850.5, nsentences=56, sample_size=1850.5, sample_size_v1=0, sample_size_v2=0, ppl=2.17, wps=1082.3, ups=0.58, wpb=1850.5, bsz=56, num_updates=13140, lr=5.43989e-06, gnorm=3.88, clip=100, loss_scale=64, train_wall=17, gb_free=12.6, wall=22661
2023-06-27 22:36:36 - progress_bar.py[line:272] - INFO: epoch 014:    304 / 990 loss=2.32, loss_v1=0, loss_v2=0, nll_loss=1.114, ntokens=1868.2, nsentences=56, sample_size=1868.2, sample_size_v1=0, sample_size_v2=0, ppl=2.16, wps=1082.2, ups=0.58, wpb=1868.2, bsz=56, num_updates=13150, lr=5.41974e-06, gnorm=3.526, clip=100, loss_scale=128, train_wall=17, gb_free=12.2, wall=22678
2023-06-27 22:36:53 - progress_bar.py[line:272] - INFO: epoch 014:    314 / 990 loss=2.315, loss_v1=0, loss_v2=0, nll_loss=1.108, ntokens=1930, nsentences=56, sample_size=1930, sample_size_v1=0, sample_size_v2=0, ppl=2.16, wps=1120.7, ups=0.58, wpb=1930, bsz=56, num_updates=13160, lr=5.3996e-06, gnorm=3.68, clip=100, loss_scale=128, train_wall=17, gb_free=12.9, wall=22696
2023-06-27 22:37:10 - progress_bar.py[line:272] - INFO: epoch 014:    324 / 990 loss=2.326, loss_v1=0, loss_v2=0, nll_loss=1.12, ntokens=1902.7, nsentences=56, sample_size=1902.7, sample_size_v1=0, sample_size_v2=0, ppl=2.17, wps=1102.8, ups=0.58, wpb=1902.7, bsz=56, num_updates=13170, lr=5.37945e-06, gnorm=3.739, clip=100, loss_scale=128, train_wall=17, gb_free=12.1, wall=22713
2023-06-27 22:37:27 - progress_bar.py[line:272] - INFO: epoch 014:    334 / 990 loss=2.291, loss_v1=0, loss_v2=0, nll_loss=1.082, ntokens=1878.2, nsentences=56, sample_size=1878.2, sample_size_v1=0, sample_size_v2=0, ppl=2.12, wps=1094.7, ups=0.58, wpb=1878.2, bsz=56, num_updates=13180, lr=5.3593e-06, gnorm=4.023, clip=100, loss_scale=128, train_wall=17, gb_free=12.8, wall=22730
2023-06-27 22:37:45 - progress_bar.py[line:272] - INFO: epoch 014:    344 / 990 loss=2.305, loss_v1=0, loss_v2=0, nll_loss=1.097, ntokens=1902.3, nsentences=56, sample_size=1902.3, sample_size_v1=0, sample_size_v2=0, ppl=2.14, wps=1104.1, ups=0.58, wpb=1902.3, bsz=56, num_updates=13190, lr=5.33915e-06, gnorm=3.674, clip=100, loss_scale=128, train_wall=17, gb_free=12.8, wall=22747
2023-06-27 22:38:02 - progress_bar.py[line:272] - INFO: epoch 014:    354 / 990 loss=2.282, loss_v1=0, loss_v2=0, nll_loss=1.072, ntokens=1883.9, nsentences=56, sample_size=1883.9, sample_size_v1=0, sample_size_v2=0, ppl=2.1, wps=1096.4, ups=0.58, wpb=1883.9, bsz=56, num_updates=13200, lr=5.31901e-06, gnorm=3.642, clip=100, loss_scale=128, train_wall=17, gb_free=11.7, wall=22764
2023-06-27 22:38:19 - progress_bar.py[line:272] - INFO: epoch 014:    364 / 990 loss=2.317, loss_v1=0, loss_v2=0, nll_loss=1.11, ntokens=1743.6, nsentences=56, sample_size=1743.6, sample_size_v1=0, sample_size_v2=0, ppl=2.16, wps=1023, ups=0.59, wpb=1743.6, bsz=56, num_updates=13210, lr=5.29886e-06, gnorm=4.241, clip=100, loss_scale=128, train_wall=17, gb_free=12.5, wall=22781
2023-06-27 22:38:36 - progress_bar.py[line:272] - INFO: epoch 014:    374 / 990 loss=2.331, loss_v1=0, loss_v2=0, nll_loss=1.127, ntokens=1801.2, nsentences=56, sample_size=1801.2, sample_size_v1=0, sample_size_v2=0, ppl=2.18, wps=1058.5, ups=0.59, wpb=1801.2, bsz=56, num_updates=13220, lr=5.27871e-06, gnorm=4.065, clip=100, loss_scale=128, train_wall=17, gb_free=12.8, wall=22798
2023-06-27 22:38:53 - progress_bar.py[line:272] - INFO: epoch 014:    384 / 990 loss=2.3, loss_v1=0, loss_v2=0, nll_loss=1.092, ntokens=1857.3, nsentences=56, sample_size=1857.3, sample_size_v1=0, sample_size_v2=0, ppl=2.13, wps=1088.2, ups=0.59, wpb=1857.3, bsz=56, num_updates=13230, lr=5.25856e-06, gnorm=4.005, clip=100, loss_scale=128, train_wall=17, gb_free=12.5, wall=22816
2023-06-27 22:39:10 - progress_bar.py[line:272] - INFO: epoch 014:    394 / 990 loss=2.299, loss_v1=0, loss_v2=0, nll_loss=1.091, ntokens=1712, nsentences=56, sample_size=1712, sample_size_v1=0, sample_size_v2=0, ppl=2.13, wps=1005, ups=0.59, wpb=1712, bsz=56, num_updates=13240, lr=5.23842e-06, gnorm=3.943, clip=100, loss_scale=128, train_wall=17, gb_free=12.7, wall=22833
2023-06-27 22:39:27 - progress_bar.py[line:272] - INFO: epoch 014:    404 / 990 loss=2.334, loss_v1=0, loss_v2=0, nll_loss=1.13, ntokens=1755.8, nsentences=56, sample_size=1755.8, sample_size_v1=0, sample_size_v2=0, ppl=2.19, wps=1031.5, ups=0.59, wpb=1755.8, bsz=56, num_updates=13250, lr=5.21827e-06, gnorm=4.399, clip=100, loss_scale=128, train_wall=17, gb_free=12, wall=22850
2023-06-27 22:39:44 - progress_bar.py[line:272] - INFO: epoch 014:    414 / 990 loss=2.326, loss_v1=0, loss_v2=0, nll_loss=1.121, ntokens=1698.9, nsentences=56, sample_size=1698.9, sample_size_v1=0, sample_size_v2=0, ppl=2.17, wps=1000.9, ups=0.59, wpb=1698.9, bsz=56, num_updates=13260, lr=5.19812e-06, gnorm=4.277, clip=100, loss_scale=128, train_wall=17, gb_free=12.8, wall=22867
2023-06-27 22:40:01 - progress_bar.py[line:272] - INFO: epoch 014:    424 / 990 loss=2.314, loss_v1=0, loss_v2=0, nll_loss=1.107, ntokens=1785.7, nsentences=56, sample_size=1785.7, sample_size_v1=0, sample_size_v2=0, ppl=2.15, wps=1045.1, ups=0.59, wpb=1785.7, bsz=56, num_updates=13270, lr=5.17797e-06, gnorm=3.883, clip=100, loss_scale=128, train_wall=17, gb_free=11.8, wall=22884
2023-06-27 22:40:18 - progress_bar.py[line:272] - INFO: epoch 014:    434 / 990 loss=2.292, loss_v1=0, loss_v2=0, nll_loss=1.082, ntokens=1935.6, nsentences=56, sample_size=1935.6, sample_size_v1=0, sample_size_v2=0, ppl=2.12, wps=1131.5, ups=0.58, wpb=1935.6, bsz=56, num_updates=13280, lr=5.15782e-06, gnorm=3.738, clip=100, loss_scale=128, train_wall=17, gb_free=11.9, wall=22901
2023-06-27 22:40:35 - progress_bar.py[line:272] - INFO: epoch 014:    444 / 990 loss=2.294, loss_v1=0, loss_v2=0, nll_loss=1.084, ntokens=1826.7, nsentences=56, sample_size=1826.7, sample_size_v1=0, sample_size_v2=0, ppl=2.12, wps=1066.6, ups=0.58, wpb=1826.7, bsz=56, num_updates=13290, lr=5.13768e-06, gnorm=3.971, clip=100, loss_scale=128, train_wall=17, gb_free=12.2, wall=22918
2023-06-27 22:40:52 - progress_bar.py[line:272] - INFO: epoch 014:    454 / 990 loss=2.321, loss_v1=0, loss_v2=0, nll_loss=1.115, ntokens=1798.3, nsentences=56, sample_size=1798.3, sample_size_v1=0, sample_size_v2=0, ppl=2.17, wps=1056.9, ups=0.59, wpb=1798.3, bsz=56, num_updates=13300, lr=5.11753e-06, gnorm=3.958, clip=100, loss_scale=128, train_wall=17, gb_free=12.7, wall=22935
2023-06-27 22:41:09 - progress_bar.py[line:272] - INFO: epoch 014:    464 / 990 loss=2.308, loss_v1=0, loss_v2=0, nll_loss=1.1, ntokens=1795, nsentences=56, sample_size=1795, sample_size_v1=0, sample_size_v2=0, ppl=2.14, wps=1046.8, ups=0.58, wpb=1795, bsz=56, num_updates=13310, lr=5.09738e-06, gnorm=3.874, clip=100, loss_scale=128, train_wall=17, gb_free=12.5, wall=22952
2023-06-27 22:41:27 - progress_bar.py[line:272] - INFO: epoch 014:    474 / 990 loss=2.296, loss_v1=0, loss_v2=0, nll_loss=1.088, ntokens=1891.6, nsentences=56, sample_size=1891.6, sample_size_v1=0, sample_size_v2=0, ppl=2.13, wps=1097.5, ups=0.58, wpb=1891.6, bsz=56, num_updates=13320, lr=5.07723e-06, gnorm=3.772, clip=100, loss_scale=128, train_wall=17, gb_free=12.7, wall=22969
2023-06-27 22:41:44 - progress_bar.py[line:272] - INFO: epoch 014:    484 / 990 loss=2.292, loss_v1=0, loss_v2=0, nll_loss=1.083, ntokens=1850.3, nsentences=56, sample_size=1850.3, sample_size_v1=0, sample_size_v2=0, ppl=2.12, wps=1079, ups=0.58, wpb=1850.3, bsz=56, num_updates=13330, lr=5.05709e-06, gnorm=3.744, clip=100, loss_scale=128, train_wall=17, gb_free=12.5, wall=22986
2023-06-27 22:42:01 - progress_bar.py[line:272] - INFO: epoch 014:    494 / 990 loss=2.3, loss_v1=0, loss_v2=0, nll_loss=1.091, ntokens=1863.4, nsentences=56, sample_size=1863.4, sample_size_v1=0, sample_size_v2=0, ppl=2.13, wps=1087.4, ups=0.58, wpb=1863.4, bsz=56, num_updates=13340, lr=5.03694e-06, gnorm=3.649, clip=100, loss_scale=128, train_wall=17, gb_free=12.7, wall=23004
2023-06-27 22:42:18 - progress_bar.py[line:272] - INFO: epoch 014:    504 / 990 loss=2.334, loss_v1=0, loss_v2=0, nll_loss=1.129, ntokens=1828.2, nsentences=56, sample_size=1828.2, sample_size_v1=0, sample_size_v2=0, ppl=2.19, wps=1070.4, ups=0.59, wpb=1828.2, bsz=56, num_updates=13350, lr=5.01679e-06, gnorm=3.892, clip=100, loss_scale=128, train_wall=17, gb_free=12.9, wall=23021
2023-06-27 22:42:35 - progress_bar.py[line:272] - INFO: epoch 014:    514 / 990 loss=2.327, loss_v1=0, loss_v2=0, nll_loss=1.121, ntokens=1708.6, nsentences=56, sample_size=1708.6, sample_size_v1=0, sample_size_v2=0, ppl=2.18, wps=1001.6, ups=0.59, wpb=1708.6, bsz=56, num_updates=13360, lr=4.99664e-06, gnorm=4.183, clip=100, loss_scale=128, train_wall=17, gb_free=13, wall=23038
2023-06-27 22:42:52 - progress_bar.py[line:272] - INFO: epoch 014:    524 / 990 loss=2.311, loss_v1=0, loss_v2=0, nll_loss=1.105, ntokens=1892.9, nsentences=56, sample_size=1892.9, sample_size_v1=0, sample_size_v2=0, ppl=2.15, wps=1105.3, ups=0.58, wpb=1892.9, bsz=56, num_updates=13370, lr=4.97649e-06, gnorm=3.786, clip=100, loss_scale=128, train_wall=17, gb_free=12.4, wall=23055
2023-06-27 22:43:09 - progress_bar.py[line:272] - INFO: epoch 014:    534 / 990 loss=2.305, loss_v1=0, loss_v2=0, nll_loss=1.097, ntokens=1898, nsentences=56, sample_size=1898, sample_size_v1=0, sample_size_v2=0, ppl=2.14, wps=1100.5, ups=0.58, wpb=1898, bsz=56, num_updates=13380, lr=4.95635e-06, gnorm=3.908, clip=100, loss_scale=128, train_wall=17, gb_free=12.6, wall=23072
2023-06-27 22:43:27 - progress_bar.py[line:272] - INFO: epoch 014:    544 / 990 loss=2.317, loss_v1=0, loss_v2=0, nll_loss=1.109, ntokens=1962.5, nsentences=56, sample_size=1962.5, sample_size_v1=0, sample_size_v2=0, ppl=2.16, wps=1145.2, ups=0.58, wpb=1962.5, bsz=56, num_updates=13390, lr=4.9362e-06, gnorm=3.983, clip=100, loss_scale=128, train_wall=17, gb_free=12.5, wall=23089
2023-06-27 22:43:43 - progress_bar.py[line:272] - INFO: epoch 014:    554 / 990 loss=2.302, loss_v1=0, loss_v2=0, nll_loss=1.093, ntokens=1822.6, nsentences=54.8, sample_size=1822.6, sample_size_v1=0, sample_size_v2=0, ppl=2.13, wps=1085.2, ups=0.6, wpb=1822.6, bsz=54.8, num_updates=13400, lr=4.91605e-06, gnorm=4.219, clip=100, loss_scale=128, train_wall=17, gb_free=12.3, wall=23106
2023-06-27 22:44:00 - progress_bar.py[line:272] - INFO: epoch 014:    564 / 990 loss=2.285, loss_v1=0, loss_v2=0, nll_loss=1.074, ntokens=1767.8, nsentences=56, sample_size=1767.8, sample_size_v1=0, sample_size_v2=0, ppl=2.11, wps=1035.9, ups=0.59, wpb=1767.8, bsz=56, num_updates=13410, lr=4.8959e-06, gnorm=3.779, clip=100, loss_scale=128, train_wall=17, gb_free=13, wall=23123
2023-06-27 22:44:18 - progress_bar.py[line:272] - INFO: epoch 014:    574 / 990 loss=2.317, loss_v1=0, loss_v2=0, nll_loss=1.111, ntokens=1835.4, nsentences=56, sample_size=1835.4, sample_size_v1=0, sample_size_v2=0, ppl=2.16, wps=1078.3, ups=0.59, wpb=1835.4, bsz=56, num_updates=13420, lr=4.87576e-06, gnorm=4.057, clip=100, loss_scale=128, train_wall=17, gb_free=12.6, wall=23140
2023-06-27 22:44:35 - progress_bar.py[line:272] - INFO: epoch 014:    584 / 990 loss=2.343, loss_v1=0, loss_v2=0, nll_loss=1.141, ntokens=1871.5, nsentences=56, sample_size=1871.5, sample_size_v1=0, sample_size_v2=0, ppl=2.2, wps=1098.8, ups=0.59, wpb=1871.5, bsz=56, num_updates=13430, lr=4.85561e-06, gnorm=4.077, clip=100, loss_scale=128, train_wall=17, gb_free=13, wall=23157
2023-06-27 22:44:52 - progress_bar.py[line:272] - INFO: epoch 014:    594 / 990 loss=2.304, loss_v1=0, loss_v2=0, nll_loss=1.095, ntokens=1897, nsentences=56, sample_size=1897, sample_size_v1=0, sample_size_v2=0, ppl=2.14, wps=1112, ups=0.59, wpb=1897, bsz=56, num_updates=13440, lr=4.83546e-06, gnorm=3.654, clip=100, loss_scale=128, train_wall=17, gb_free=13.1, wall=23174
2023-06-27 22:45:09 - progress_bar.py[line:272] - INFO: epoch 014:    604 / 990 loss=2.313, loss_v1=0, loss_v2=0, nll_loss=1.105, ntokens=1734.2, nsentences=56, sample_size=1734.2, sample_size_v1=0, sample_size_v2=0, ppl=2.15, wps=1011.1, ups=0.58, wpb=1734.2, bsz=56, num_updates=13450, lr=4.81531e-06, gnorm=4.104, clip=100, loss_scale=128, train_wall=17, gb_free=13.1, wall=23191
2023-06-27 22:45:26 - progress_bar.py[line:272] - INFO: epoch 014:    614 / 990 loss=2.3, loss_v1=0, loss_v2=0, nll_loss=1.091, ntokens=1867, nsentences=56, sample_size=1867, sample_size_v1=0, sample_size_v2=0, ppl=2.13, wps=1096.9, ups=0.59, wpb=1867, bsz=56, num_updates=13460, lr=4.79516e-06, gnorm=3.791, clip=100, loss_scale=128, train_wall=17, gb_free=12.9, wall=23208
2023-06-27 22:45:43 - progress_bar.py[line:272] - INFO: epoch 014:    624 / 990 loss=2.329, loss_v1=0, loss_v2=0, nll_loss=1.124, ntokens=2013.5, nsentences=56, sample_size=2013.5, sample_size_v1=0, sample_size_v2=0, ppl=2.18, wps=1176.9, ups=0.58, wpb=2013.5, bsz=56, num_updates=13470, lr=4.77502e-06, gnorm=3.624, clip=100, loss_scale=128, train_wall=17, gb_free=12.5, wall=23226
2023-06-27 22:46:00 - progress_bar.py[line:272] - INFO: epoch 014:    634 / 990 loss=2.333, loss_v1=0, loss_v2=0, nll_loss=1.128, ntokens=2014.9, nsentences=56, sample_size=2014.9, sample_size_v1=0, sample_size_v2=0, ppl=2.19, wps=1171.4, ups=0.58, wpb=2014.9, bsz=56, num_updates=13480, lr=4.75487e-06, gnorm=3.649, clip=100, loss_scale=128, train_wall=17, gb_free=12.4, wall=23243
2023-06-27 22:46:17 - progress_bar.py[line:272] - INFO: epoch 014:    644 / 990 loss=2.312, loss_v1=0, loss_v2=0, nll_loss=1.105, ntokens=1953.3, nsentences=56, sample_size=1953.3, sample_size_v1=0, sample_size_v2=0, ppl=2.15, wps=1139, ups=0.58, wpb=1953.3, bsz=56, num_updates=13490, lr=4.73472e-06, gnorm=3.807, clip=100, loss_scale=128, train_wall=17, gb_free=13.1, wall=23260
2023-06-27 22:46:34 - progress_bar.py[line:272] - INFO: epoch 014:    654 / 990 loss=2.304, loss_v1=0, loss_v2=0, nll_loss=1.096, ntokens=1949.6, nsentences=56, sample_size=1949.6, sample_size_v1=0, sample_size_v2=0, ppl=2.14, wps=1138.1, ups=0.58, wpb=1949.6, bsz=56, num_updates=13500, lr=4.71457e-06, gnorm=3.661, clip=100, loss_scale=128, train_wall=17, gb_free=12.1, wall=23277
2023-06-27 22:46:52 - progress_bar.py[line:272] - INFO: epoch 014:    664 / 990 loss=2.318, loss_v1=0, loss_v2=0, nll_loss=1.111, ntokens=1877.2, nsentences=56, sample_size=1877.2, sample_size_v1=0, sample_size_v2=0, ppl=2.16, wps=1094.4, ups=0.58, wpb=1877.2, bsz=56, num_updates=13510, lr=4.69443e-06, gnorm=3.742, clip=100, loss_scale=128, train_wall=17, gb_free=12.2, wall=23294
2023-06-27 22:47:09 - progress_bar.py[line:272] - INFO: epoch 014:    674 / 990 loss=2.317, loss_v1=0, loss_v2=0, nll_loss=1.111, ntokens=1801, nsentences=56, sample_size=1801, sample_size_v1=0, sample_size_v2=0, ppl=2.16, wps=1052.1, ups=0.58, wpb=1801, bsz=56, num_updates=13520, lr=4.67428e-06, gnorm=4.236, clip=100, loss_scale=128, train_wall=17, gb_free=13.1, wall=23311
2023-06-27 22:47:26 - progress_bar.py[line:272] - INFO: epoch 014:    684 / 990 loss=2.269, loss_v1=0, loss_v2=0, nll_loss=1.057, ntokens=1896.1, nsentences=56, sample_size=1896.1, sample_size_v1=0, sample_size_v2=0, ppl=2.08, wps=1102.3, ups=0.58, wpb=1896.1, bsz=56, num_updates=13530, lr=4.65413e-06, gnorm=3.633, clip=100, loss_scale=128, train_wall=17, gb_free=13, wall=23329
2023-06-27 22:47:43 - progress_bar.py[line:272] - INFO: epoch 014:    694 / 990 loss=2.297, loss_v1=0, loss_v2=0, nll_loss=1.089, ntokens=1764.3, nsentences=56, sample_size=1764.3, sample_size_v1=0, sample_size_v2=0, ppl=2.13, wps=1033.7, ups=0.59, wpb=1764.3, bsz=56, num_updates=13540, lr=4.63398e-06, gnorm=3.993, clip=100, loss_scale=128, train_wall=17, gb_free=12.8, wall=23346
2023-06-27 22:48:00 - progress_bar.py[line:272] - INFO: epoch 014:    704 / 990 loss=2.324, loss_v1=0, loss_v2=0, nll_loss=1.118, ntokens=1695.2, nsentences=56, sample_size=1695.2, sample_size_v1=0, sample_size_v2=0, ppl=2.17, wps=995, ups=0.59, wpb=1695.2, bsz=56, num_updates=13550, lr=4.61383e-06, gnorm=4.246, clip=100, loss_scale=128, train_wall=17, gb_free=13.3, wall=23363
2023-06-27 22:48:17 - progress_bar.py[line:272] - INFO: epoch 014:    714 / 990 loss=2.316, loss_v1=0, loss_v2=0, nll_loss=1.109, ntokens=1795, nsentences=56, sample_size=1795, sample_size_v1=0, sample_size_v2=0, ppl=2.16, wps=1054.9, ups=0.59, wpb=1795, bsz=56, num_updates=13560, lr=4.59369e-06, gnorm=4.179, clip=100, loss_scale=128, train_wall=17, gb_free=13, wall=23380
2023-06-27 22:48:34 - progress_bar.py[line:272] - INFO: epoch 014:    724 / 990 loss=2.302, loss_v1=0, loss_v2=0, nll_loss=1.094, ntokens=1776.7, nsentences=56, sample_size=1776.7, sample_size_v1=0, sample_size_v2=0, ppl=2.13, wps=1046.5, ups=0.59, wpb=1776.7, bsz=56, num_updates=13570, lr=4.57354e-06, gnorm=3.854, clip=100, loss_scale=128, train_wall=17, gb_free=13, wall=23397
2023-06-27 22:48:51 - progress_bar.py[line:272] - INFO: epoch 014:    734 / 990 loss=2.285, loss_v1=0, loss_v2=0, nll_loss=1.074, ntokens=1813.9, nsentences=56, sample_size=1813.9, sample_size_v1=0, sample_size_v2=0, ppl=2.11, wps=1062.9, ups=0.59, wpb=1813.9, bsz=56, num_updates=13580, lr=4.55339e-06, gnorm=4.008, clip=100, loss_scale=128, train_wall=17, gb_free=12.4, wall=23414
2023-06-27 22:49:08 - progress_bar.py[line:272] - INFO: epoch 014:    744 / 990 loss=2.32, loss_v1=0, loss_v2=0, nll_loss=1.115, ntokens=1789, nsentences=56, sample_size=1789, sample_size_v1=0, sample_size_v2=0, ppl=2.17, wps=1051.8, ups=0.59, wpb=1789, bsz=56, num_updates=13590, lr=4.53324e-06, gnorm=4.023, clip=100, loss_scale=128, train_wall=17, gb_free=12.8, wall=23431
2023-06-27 22:49:25 - progress_bar.py[line:272] - INFO: epoch 014:    754 / 990 loss=2.339, loss_v1=0, loss_v2=0, nll_loss=1.135, ntokens=1642.8, nsentences=56, sample_size=1642.8, sample_size_v1=0, sample_size_v2=0, ppl=2.2, wps=968.7, ups=0.59, wpb=1642.8, bsz=56, num_updates=13600, lr=4.5131e-06, gnorm=4.24, clip=100, loss_scale=128, train_wall=17, gb_free=13.2, wall=23448
2023-06-27 22:49:42 - progress_bar.py[line:272] - INFO: epoch 014:    764 / 990 loss=2.306, loss_v1=0, loss_v2=0, nll_loss=1.096, ntokens=1785.4, nsentences=56, sample_size=1785.4, sample_size_v1=0, sample_size_v2=0, ppl=2.14, wps=1047.9, ups=0.59, wpb=1785.4, bsz=56, num_updates=13610, lr=4.49295e-06, gnorm=3.804, clip=100, loss_scale=128, train_wall=17, gb_free=12.7, wall=23465
2023-06-27 22:49:59 - progress_bar.py[line:272] - INFO: epoch 014:    774 / 990 loss=2.311, loss_v1=0, loss_v2=0, nll_loss=1.104, ntokens=1832.9, nsentences=56, sample_size=1832.9, sample_size_v1=0, sample_size_v2=0, ppl=2.15, wps=1071.8, ups=0.58, wpb=1832.9, bsz=56, num_updates=13620, lr=4.4728e-06, gnorm=4.064, clip=100, loss_scale=128, train_wall=17, gb_free=12.9, wall=23482
2023-06-27 22:50:16 - progress_bar.py[line:272] - INFO: epoch 014:    784 / 990 loss=2.299, loss_v1=0, loss_v2=0, nll_loss=1.09, ntokens=1760.8, nsentences=56, sample_size=1760.8, sample_size_v1=0, sample_size_v2=0, ppl=2.13, wps=1034.3, ups=0.59, wpb=1760.8, bsz=56, num_updates=13630, lr=4.45265e-06, gnorm=4.096, clip=100, loss_scale=128, train_wall=17, gb_free=12.4, wall=23499
2023-06-27 22:50:33 - progress_bar.py[line:272] - INFO: epoch 014:    794 / 990 loss=2.317, loss_v1=0, loss_v2=0, nll_loss=1.111, ntokens=1847.5, nsentences=56, sample_size=1847.5, sample_size_v1=0, sample_size_v2=0, ppl=2.16, wps=1076.6, ups=0.58, wpb=1847.5, bsz=56, num_updates=13640, lr=4.43251e-06, gnorm=4.026, clip=100, loss_scale=128, train_wall=17, gb_free=11.4, wall=23516
2023-06-27 22:50:50 - progress_bar.py[line:272] - INFO: epoch 014:    804 / 990 loss=2.308, loss_v1=0, loss_v2=0, nll_loss=1.1, ntokens=1748.1, nsentences=56, sample_size=1748.1, sample_size_v1=0, sample_size_v2=0, ppl=2.14, wps=1024.7, ups=0.59, wpb=1748.1, bsz=56, num_updates=13650, lr=4.41236e-06, gnorm=4.123, clip=100, loss_scale=128, train_wall=17, gb_free=12.5, wall=23533
2023-06-27 22:51:01 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 128.0
2023-06-27 22:51:09 - progress_bar.py[line:272] - INFO: epoch 014:    815 / 990 loss=2.328, loss_v1=0, loss_v2=0, nll_loss=1.122, ntokens=1690.4, nsentences=56, sample_size=1690.4, sample_size_v1=0, sample_size_v2=0, ppl=2.18, wps=907.9, ups=0.54, wpb=1690.4, bsz=56, num_updates=13660, lr=4.39221e-06, gnorm=4.054, clip=100, loss_scale=128, train_wall=19, gb_free=12.8, wall=23552
2023-06-27 22:51:26 - progress_bar.py[line:272] - INFO: epoch 014:    825 / 990 loss=2.303, loss_v1=0, loss_v2=0, nll_loss=1.094, ntokens=1720.2, nsentences=56, sample_size=1720.2, sample_size_v1=0, sample_size_v2=0, ppl=2.13, wps=1007.1, ups=0.59, wpb=1720.2, bsz=56, num_updates=13670, lr=4.37206e-06, gnorm=3.917, clip=100, loss_scale=128, train_wall=17, gb_free=12.9, wall=23569
2023-06-27 22:51:43 - progress_bar.py[line:272] - INFO: epoch 014:    835 / 990 loss=2.286, loss_v1=0, loss_v2=0, nll_loss=1.075, ntokens=1750.5, nsentences=56, sample_size=1750.5, sample_size_v1=0, sample_size_v2=0, ppl=2.11, wps=1033.2, ups=0.59, wpb=1750.5, bsz=56, num_updates=13680, lr=4.35191e-06, gnorm=4.139, clip=100, loss_scale=128, train_wall=17, gb_free=13.2, wall=23586
2023-06-27 22:52:00 - progress_bar.py[line:272] - INFO: epoch 014:    845 / 990 loss=2.296, loss_v1=0, loss_v2=0, nll_loss=1.088, ntokens=1877.1, nsentences=56, sample_size=1877.1, sample_size_v1=0, sample_size_v2=0, ppl=2.13, wps=1099.1, ups=0.59, wpb=1877.1, bsz=56, num_updates=13690, lr=4.33177e-06, gnorm=4.004, clip=100, loss_scale=128, train_wall=17, gb_free=12.8, wall=23603
2023-06-27 22:52:17 - progress_bar.py[line:272] - INFO: epoch 014:    855 / 990 loss=2.275, loss_v1=0, loss_v2=0, nll_loss=1.063, ntokens=1886, nsentences=56, sample_size=1886, sample_size_v1=0, sample_size_v2=0, ppl=2.09, wps=1096.6, ups=0.58, wpb=1886, bsz=56, num_updates=13700, lr=4.31162e-06, gnorm=4.035, clip=100, loss_scale=128, train_wall=17, gb_free=12.7, wall=23620
2023-06-27 22:52:34 - progress_bar.py[line:272] - INFO: epoch 014:    865 / 990 loss=2.286, loss_v1=0, loss_v2=0, nll_loss=1.075, ntokens=1805.6, nsentences=56, sample_size=1805.6, sample_size_v1=0, sample_size_v2=0, ppl=2.11, wps=1057.7, ups=0.59, wpb=1805.6, bsz=56, num_updates=13710, lr=4.29147e-06, gnorm=4.357, clip=100, loss_scale=128, train_wall=17, gb_free=12.6, wall=23637
2023-06-27 22:52:52 - progress_bar.py[line:272] - INFO: epoch 014:    875 / 990 loss=2.29, loss_v1=0, loss_v2=0, nll_loss=1.081, ntokens=1858.2, nsentences=56, sample_size=1858.2, sample_size_v1=0, sample_size_v2=0, ppl=2.11, wps=1087.3, ups=0.59, wpb=1858.2, bsz=56, num_updates=13720, lr=4.27132e-06, gnorm=3.774, clip=100, loss_scale=128, train_wall=17, gb_free=12.7, wall=23654
2023-06-27 22:53:09 - progress_bar.py[line:272] - INFO: epoch 014:    885 / 990 loss=2.287, loss_v1=0, loss_v2=0, nll_loss=1.077, ntokens=1916.4, nsentences=56, sample_size=1916.4, sample_size_v1=0, sample_size_v2=0, ppl=2.11, wps=1122.6, ups=0.59, wpb=1916.4, bsz=56, num_updates=13730, lr=4.25118e-06, gnorm=3.772, clip=100, loss_scale=128, train_wall=17, gb_free=12.5, wall=23671
2023-06-27 22:53:26 - progress_bar.py[line:272] - INFO: epoch 014:    895 / 990 loss=2.292, loss_v1=0, loss_v2=0, nll_loss=1.084, ntokens=1930, nsentences=56, sample_size=1930, sample_size_v1=0, sample_size_v2=0, ppl=2.12, wps=1128.4, ups=0.58, wpb=1930, bsz=56, num_updates=13740, lr=4.23103e-06, gnorm=3.822, clip=100, loss_scale=128, train_wall=17, gb_free=12.7, wall=23688
2023-06-27 22:53:43 - progress_bar.py[line:272] - INFO: epoch 014:    905 / 990 loss=2.318, loss_v1=0, loss_v2=0, nll_loss=1.112, ntokens=1740.4, nsentences=56, sample_size=1740.4, sample_size_v1=0, sample_size_v2=0, ppl=2.16, wps=1022.4, ups=0.59, wpb=1740.4, bsz=56, num_updates=13750, lr=4.21088e-06, gnorm=4.15, clip=100, loss_scale=128, train_wall=17, gb_free=13, wall=23705
2023-06-27 22:54:00 - progress_bar.py[line:272] - INFO: epoch 014:    915 / 990 loss=2.308, loss_v1=0, loss_v2=0, nll_loss=1.101, ntokens=1766.6, nsentences=56, sample_size=1766.6, sample_size_v1=0, sample_size_v2=0, ppl=2.14, wps=1041.8, ups=0.59, wpb=1766.6, bsz=56, num_updates=13760, lr=4.19073e-06, gnorm=4.192, clip=100, loss_scale=128, train_wall=17, gb_free=12.8, wall=23722
2023-06-27 22:54:17 - progress_bar.py[line:272] - INFO: epoch 014:    925 / 990 loss=2.273, loss_v1=0, loss_v2=0, nll_loss=1.06, ntokens=1796.5, nsentences=56, sample_size=1796.5, sample_size_v1=0, sample_size_v2=0, ppl=2.09, wps=1050.7, ups=0.58, wpb=1796.5, bsz=56, num_updates=13770, lr=4.17058e-06, gnorm=4.028, clip=100, loss_scale=128, train_wall=17, gb_free=12.7, wall=23739
2023-06-27 22:54:34 - progress_bar.py[line:272] - INFO: epoch 014:    935 / 990 loss=2.282, loss_v1=0, loss_v2=0, nll_loss=1.071, ntokens=1813.3, nsentences=56, sample_size=1813.3, sample_size_v1=0, sample_size_v2=0, ppl=2.1, wps=1063.1, ups=0.59, wpb=1813.3, bsz=56, num_updates=13780, lr=4.15044e-06, gnorm=4.011, clip=100, loss_scale=128, train_wall=17, gb_free=12.8, wall=23757
2023-06-27 22:54:51 - progress_bar.py[line:272] - INFO: epoch 014:    945 / 990 loss=2.284, loss_v1=0, loss_v2=0, nll_loss=1.074, ntokens=1927.8, nsentences=56, sample_size=1927.8, sample_size_v1=0, sample_size_v2=0, ppl=2.11, wps=1121.1, ups=0.58, wpb=1927.8, bsz=56, num_updates=13790, lr=4.13029e-06, gnorm=3.836, clip=100, loss_scale=128, train_wall=17, gb_free=13.1, wall=23774
2023-06-27 22:55:08 - progress_bar.py[line:272] - INFO: epoch 014:    955 / 990 loss=2.303, loss_v1=0, loss_v2=0, nll_loss=1.095, ntokens=1899.8, nsentences=56, sample_size=1899.8, sample_size_v1=0, sample_size_v2=0, ppl=2.14, wps=1112, ups=0.59, wpb=1899.8, bsz=56, num_updates=13800, lr=4.11014e-06, gnorm=3.976, clip=100, loss_scale=128, train_wall=17, gb_free=13, wall=23791
2023-06-27 22:55:25 - progress_bar.py[line:272] - INFO: epoch 014:    965 / 990 loss=2.297, loss_v1=0, loss_v2=0, nll_loss=1.088, ntokens=1895.8, nsentences=56, sample_size=1895.8, sample_size_v1=0, sample_size_v2=0, ppl=2.13, wps=1103.8, ups=0.58, wpb=1895.8, bsz=56, num_updates=13810, lr=4.08999e-06, gnorm=3.952, clip=100, loss_scale=128, train_wall=17, gb_free=12.6, wall=23808
2023-06-27 22:55:43 - progress_bar.py[line:272] - INFO: epoch 014:    975 / 990 loss=2.285, loss_v1=0, loss_v2=0, nll_loss=1.074, ntokens=1936.2, nsentences=56, sample_size=1936.2, sample_size_v1=0, sample_size_v2=0, ppl=2.11, wps=1125.8, ups=0.58, wpb=1936.2, bsz=56, num_updates=13820, lr=4.06985e-06, gnorm=3.965, clip=100, loss_scale=128, train_wall=17, gb_free=12.2, wall=23825
2023-06-27 22:56:00 - progress_bar.py[line:272] - INFO: epoch 014:    985 / 990 loss=2.313, loss_v1=0, loss_v2=0, nll_loss=1.106, ntokens=1763.8, nsentences=56, sample_size=1763.8, sample_size_v1=0, sample_size_v2=0, ppl=2.15, wps=1037, ups=0.59, wpb=1763.8, bsz=56, num_updates=13830, lr=4.0497e-06, gnorm=4.388, clip=100, loss_scale=128, train_wall=17, gb_free=12.9, wall=23842
local datafile ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 1 begin to initialize row_count and line_idx-to-offset mapping
2023-06-27 22:56:07 - train.py[line:332] - INFO: end of epoch 14 (average epoch stats below)
2023-06-27 22:56:07 - progress_bar.py[line:282] - INFO: epoch 014 | loss 2.29 | loss_v1 0 | loss_v2 0 | nll_loss 1.08 | ntokens 1850.26 | nsentences 55.96 | sample_size 1850.26 | sample_size_v1 0 | sample_size_v2 0 | ppl 2.11 | wps 1076.4 | ups 0.58 | wpb 1850.3 | bsz 56 | num_updates 13835 | lr 4.03962e-06 | gnorm 3.892 | clip 100 | loss_scale 128 | train_wall 1694 | gb_free 13.3 | wall 23850
2023-06-27 22:56:07 - trainer.py[line:639] - INFO: loading train data for epoch 15
local datafile ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 0 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 1 finished initializing row_count and line_idx-to-offset mapping
file ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 1 row count 27700 total row count 55400
slice_id 1 seek offset 27700
local datafile ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 0 finished initializing row_count and line_idx-to-offset mapping
file ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 0 row count 27700 total row count 55400
slice_id 0 seek offset 0
2023-06-27 22:56:09 - trainer.py[line:703] - INFO: begin training epoch 15
2023-06-27 22:56:09 - train.py[line:305] - INFO: Start iterating over samples
2023-06-27 22:56:18 - progress_bar.py[line:272] - INFO: epoch 015:      5 / 990 loss=2.295, loss_v1=0, loss_v2=0, nll_loss=1.086, ntokens=1787.7, nsentences=53.2, sample_size=1787.7, sample_size_v1=0, sample_size_v2=0, ppl=2.12, wps=957, ups=0.54, wpb=1787.7, bsz=53.2, num_updates=13840, lr=4.02955e-06, gnorm=4.272, clip=100, loss_scale=128, train_wall=16, gb_free=11.4, wall=23861
2023-06-27 22:56:35 - progress_bar.py[line:272] - INFO: epoch 015:     15 / 990 loss=2.254, loss_v1=0, loss_v2=0, nll_loss=1.04, ntokens=1811.7, nsentences=56, sample_size=1811.7, sample_size_v1=0, sample_size_v2=0, ppl=2.06, wps=1053.7, ups=0.58, wpb=1811.7, bsz=56, num_updates=13850, lr=4.0094e-06, gnorm=3.93, clip=100, loss_scale=128, train_wall=17, gb_free=12, wall=23878
2023-06-27 22:56:53 - progress_bar.py[line:272] - INFO: epoch 015:     25 / 990 loss=2.221, loss_v1=0, loss_v2=0, nll_loss=1.003, ntokens=1821.9, nsentences=56, sample_size=1821.9, sample_size_v1=0, sample_size_v2=0, ppl=2, wps=1058.6, ups=0.58, wpb=1821.9, bsz=56, num_updates=13860, lr=3.98925e-06, gnorm=3.85, clip=100, loss_scale=128, train_wall=17, gb_free=12.9, wall=23895
2023-06-27 22:57:10 - progress_bar.py[line:272] - INFO: epoch 015:     35 / 990 loss=2.248, loss_v1=0, loss_v2=0, nll_loss=1.033, ntokens=1748.8, nsentences=56, sample_size=1748.8, sample_size_v1=0, sample_size_v2=0, ppl=2.05, wps=1016.3, ups=0.58, wpb=1748.8, bsz=56, num_updates=13870, lr=3.96911e-06, gnorm=3.914, clip=100, loss_scale=128, train_wall=17, gb_free=12.5, wall=23913
2023-06-27 22:57:27 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2023-06-27 22:57:29 - progress_bar.py[line:272] - INFO: epoch 015:     46 / 990 loss=2.163, loss_v1=0, loss_v2=0, nll_loss=0.938, ntokens=1999.5, nsentences=56, sample_size=1999.5, sample_size_v1=0, sample_size_v2=0, ppl=1.92, wps=1047.6, ups=0.52, wpb=1999.5, bsz=56, num_updates=13880, lr=3.94896e-06, gnorm=3.665, clip=100, loss_scale=64, train_wall=19, gb_free=11.8, wall=23932
2023-06-27 22:57:46 - progress_bar.py[line:272] - INFO: epoch 015:     56 / 990 loss=2.251, loss_v1=0, loss_v2=0, nll_loss=1.037, ntokens=1753.7, nsentences=56, sample_size=1753.7, sample_size_v1=0, sample_size_v2=0, ppl=2.05, wps=1019.7, ups=0.58, wpb=1753.7, bsz=56, num_updates=13890, lr=3.92881e-06, gnorm=4.167, clip=100, loss_scale=64, train_wall=17, gb_free=11.9, wall=23949
2023-06-27 22:58:03 - progress_bar.py[line:272] - INFO: epoch 015:     66 / 990 loss=2.151, loss_v1=0, loss_v2=0, nll_loss=0.925, ntokens=1771.6, nsentences=56, sample_size=1771.6, sample_size_v1=0, sample_size_v2=0, ppl=1.9, wps=1035.6, ups=0.58, wpb=1771.6, bsz=56, num_updates=13900, lr=3.90866e-06, gnorm=3.92, clip=100, loss_scale=64, train_wall=17, gb_free=12.6, wall=23966
2023-06-27 22:58:21 - progress_bar.py[line:272] - INFO: epoch 015:     76 / 990 loss=2.102, loss_v1=0, loss_v2=0, nll_loss=0.87, ntokens=2157.8, nsentences=56, sample_size=2157.8, sample_size_v1=0, sample_size_v2=0, ppl=1.83, wps=1223, ups=0.57, wpb=2157.8, bsz=56, num_updates=13910, lr=3.88852e-06, gnorm=3.544, clip=100, loss_scale=64, train_wall=18, gb_free=11.3, wall=23984
2023-06-27 22:58:39 - progress_bar.py[line:272] - INFO: epoch 015:     86 / 990 loss=2.175, loss_v1=0, loss_v2=0, nll_loss=0.952, ntokens=2145.4, nsentences=56, sample_size=2145.4, sample_size_v1=0, sample_size_v2=0, ppl=1.93, wps=1213.7, ups=0.57, wpb=2145.4, bsz=56, num_updates=13920, lr=3.86837e-06, gnorm=3.704, clip=100, loss_scale=64, train_wall=18, gb_free=11.4, wall=24001
2023-06-27 22:58:56 - progress_bar.py[line:272] - INFO: epoch 015:     96 / 990 loss=2.215, loss_v1=0, loss_v2=0, nll_loss=0.997, ntokens=1944, nsentences=56, sample_size=1944, sample_size_v1=0, sample_size_v2=0, ppl=2, wps=1115.4, ups=0.57, wpb=1944, bsz=56, num_updates=13930, lr=3.84822e-06, gnorm=4.043, clip=100, loss_scale=64, train_wall=17, gb_free=11.7, wall=24019
2023-06-27 22:59:13 - progress_bar.py[line:272] - INFO: epoch 015:    106 / 990 loss=2.192, loss_v1=0, loss_v2=0, nll_loss=0.971, ntokens=1925.1, nsentences=56, sample_size=1925.1, sample_size_v1=0, sample_size_v2=0, ppl=1.96, wps=1115.3, ups=0.58, wpb=1925.1, bsz=56, num_updates=13940, lr=3.82807e-06, gnorm=4.021, clip=100, loss_scale=64, train_wall=17, gb_free=12, wall=24036
2023-06-27 22:59:30 - progress_bar.py[line:272] - INFO: epoch 015:    116 / 990 loss=2.275, loss_v1=0, loss_v2=0, nll_loss=1.065, ntokens=1750.2, nsentences=56, sample_size=1750.2, sample_size_v1=0, sample_size_v2=0, ppl=2.09, wps=1021.8, ups=0.58, wpb=1750.2, bsz=56, num_updates=13950, lr=3.80792e-06, gnorm=4.6, clip=100, loss_scale=64, train_wall=17, gb_free=12.4, wall=24053
2023-06-27 22:59:48 - progress_bar.py[line:272] - INFO: epoch 015:    126 / 990 loss=2.298, loss_v1=0, loss_v2=0, nll_loss=1.09, ntokens=1812.3, nsentences=56, sample_size=1812.3, sample_size_v1=0, sample_size_v2=0, ppl=2.13, wps=1056.5, ups=0.58, wpb=1812.3, bsz=56, num_updates=13960, lr=3.78778e-06, gnorm=4.102, clip=100, loss_scale=64, train_wall=17, gb_free=12.2, wall=24070
2023-06-27 23:00:05 - progress_bar.py[line:272] - INFO: epoch 015:    136 / 990 loss=2.276, loss_v1=0, loss_v2=0, nll_loss=1.065, ntokens=1884.6, nsentences=56, sample_size=1884.6, sample_size_v1=0, sample_size_v2=0, ppl=2.09, wps=1084.4, ups=0.58, wpb=1884.6, bsz=56, num_updates=13970, lr=3.76763e-06, gnorm=4.163, clip=100, loss_scale=64, train_wall=17, gb_free=11.1, wall=24088
2023-06-27 23:00:22 - progress_bar.py[line:272] - INFO: epoch 015:    146 / 990 loss=2.285, loss_v1=0, loss_v2=0, nll_loss=1.074, ntokens=1945.2, nsentences=56, sample_size=1945.2, sample_size_v1=0, sample_size_v2=0, ppl=2.1, wps=1117, ups=0.57, wpb=1945.2, bsz=56, num_updates=13980, lr=3.74748e-06, gnorm=4.153, clip=100, loss_scale=64, train_wall=17, gb_free=12.7, wall=24105
2023-06-27 23:00:40 - progress_bar.py[line:272] - INFO: epoch 015:    156 / 990 loss=2.249, loss_v1=0, loss_v2=0, nll_loss=1.034, ntokens=1970.4, nsentences=56, sample_size=1970.4, sample_size_v1=0, sample_size_v2=0, ppl=2.05, wps=1130.4, ups=0.57, wpb=1970.4, bsz=56, num_updates=13990, lr=3.72733e-06, gnorm=3.957, clip=100, loss_scale=64, train_wall=17, gb_free=12, wall=24122
2023-06-27 23:00:57 - progress_bar.py[line:272] - INFO: epoch 015:    166 / 990 loss=2.242, loss_v1=0, loss_v2=0, nll_loss=1.025, ntokens=1946, nsentences=56, sample_size=1946, sample_size_v1=0, sample_size_v2=0, ppl=2.04, wps=1115.2, ups=0.57, wpb=1946, bsz=56, num_updates=14000, lr=3.70719e-06, gnorm=3.692, clip=100, loss_scale=64, train_wall=17, gb_free=12.2, wall=24140
2023-06-27 23:01:15 - progress_bar.py[line:272] - INFO: epoch 015:    176 / 990 loss=2.248, loss_v1=0, loss_v2=0, nll_loss=1.033, ntokens=1974.8, nsentences=56, sample_size=1974.8, sample_size_v1=0, sample_size_v2=0, ppl=2.05, wps=1130.4, ups=0.57, wpb=1974.8, bsz=56, num_updates=14010, lr=3.68704e-06, gnorm=3.719, clip=100, loss_scale=64, train_wall=17, gb_free=12.1, wall=24157
2023-06-27 23:01:32 - progress_bar.py[line:272] - INFO: epoch 015:    186 / 990 loss=2.253, loss_v1=0, loss_v2=0, nll_loss=1.039, ntokens=1876.2, nsentences=56, sample_size=1876.2, sample_size_v1=0, sample_size_v2=0, ppl=2.05, wps=1083.5, ups=0.58, wpb=1876.2, bsz=56, num_updates=14020, lr=3.66689e-06, gnorm=3.902, clip=100, loss_scale=64, train_wall=17, gb_free=13.1, wall=24175
2023-06-27 23:01:49 - progress_bar.py[line:272] - INFO: epoch 015:    196 / 990 loss=2.265, loss_v1=0, loss_v2=0, nll_loss=1.052, ntokens=1830.9, nsentences=56, sample_size=1830.9, sample_size_v1=0, sample_size_v2=0, ppl=2.07, wps=1067, ups=0.58, wpb=1830.9, bsz=56, num_updates=14030, lr=3.64674e-06, gnorm=4.174, clip=100, loss_scale=64, train_wall=17, gb_free=12.4, wall=24192
2023-06-27 23:02:07 - progress_bar.py[line:272] - INFO: epoch 015:    206 / 990 loss=2.228, loss_v1=0, loss_v2=0, nll_loss=1.01, ntokens=1898.5, nsentences=56, sample_size=1898.5, sample_size_v1=0, sample_size_v2=0, ppl=2.01, wps=1093.7, ups=0.58, wpb=1898.5, bsz=56, num_updates=14040, lr=3.6266e-06, gnorm=4.09, clip=100, loss_scale=64, train_wall=17, gb_free=12.1, wall=24209
2023-06-27 23:02:24 - progress_bar.py[line:272] - INFO: epoch 015:    216 / 990 loss=2.255, loss_v1=0, loss_v2=0, nll_loss=1.041, ntokens=1940.5, nsentences=56, sample_size=1940.5, sample_size_v1=0, sample_size_v2=0, ppl=2.06, wps=1116.4, ups=0.58, wpb=1940.5, bsz=56, num_updates=14050, lr=3.60645e-06, gnorm=4.07, clip=100, loss_scale=64, train_wall=17, gb_free=12.7, wall=24227
2023-06-27 23:02:41 - progress_bar.py[line:272] - INFO: epoch 015:    226 / 990 loss=2.255, loss_v1=0, loss_v2=0, nll_loss=1.041, ntokens=1928.3, nsentences=56, sample_size=1928.3, sample_size_v1=0, sample_size_v2=0, ppl=2.06, wps=1108.6, ups=0.57, wpb=1928.3, bsz=56, num_updates=14060, lr=3.5863e-06, gnorm=3.889, clip=100, loss_scale=64, train_wall=17, gb_free=12.3, wall=24244
2023-06-27 23:02:58 - progress_bar.py[line:272] - INFO: epoch 015:    236 / 990 loss=2.303, loss_v1=0, loss_v2=0, nll_loss=1.094, ntokens=1689.4, nsentences=56, sample_size=1689.4, sample_size_v1=0, sample_size_v2=0, ppl=2.14, wps=989.9, ups=0.59, wpb=1689.4, bsz=56, num_updates=14070, lr=3.56615e-06, gnorm=4.215, clip=100, loss_scale=64, train_wall=17, gb_free=13.3, wall=24261
2023-06-27 23:03:16 - progress_bar.py[line:272] - INFO: epoch 015:    246 / 990 loss=2.308, loss_v1=0, loss_v2=0, nll_loss=1.1, ntokens=1922.3, nsentences=56, sample_size=1922.3, sample_size_v1=0, sample_size_v2=0, ppl=2.14, wps=1116.7, ups=0.58, wpb=1922.3, bsz=56, num_updates=14080, lr=3.546e-06, gnorm=3.924, clip=100, loss_scale=64, train_wall=17, gb_free=11.9, wall=24278
2023-06-27 23:03:33 - progress_bar.py[line:272] - INFO: epoch 015:    256 / 990 loss=2.303, loss_v1=0, loss_v2=0, nll_loss=1.095, ntokens=1899.1, nsentences=56, sample_size=1899.1, sample_size_v1=0, sample_size_v2=0, ppl=2.14, wps=1106.4, ups=0.58, wpb=1899.1, bsz=56, num_updates=14090, lr=3.52586e-06, gnorm=4.201, clip=100, loss_scale=64, train_wall=17, gb_free=12.6, wall=24295
2023-06-27 23:03:50 - progress_bar.py[line:272] - INFO: epoch 015:    266 / 990 loss=2.33, loss_v1=0, loss_v2=0, nll_loss=1.125, ntokens=1876.3, nsentences=56, sample_size=1876.3, sample_size_v1=0, sample_size_v2=0, ppl=2.18, wps=1092.7, ups=0.58, wpb=1876.3, bsz=56, num_updates=14100, lr=3.50571e-06, gnorm=4.118, clip=100, loss_scale=64, train_wall=17, gb_free=13.1, wall=24313
2023-06-27 23:04:07 - progress_bar.py[line:272] - INFO: epoch 015:    276 / 990 loss=2.307, loss_v1=0, loss_v2=0, nll_loss=1.1, ntokens=1940.2, nsentences=56, sample_size=1940.2, sample_size_v1=0, sample_size_v2=0, ppl=2.14, wps=1116.8, ups=0.58, wpb=1940.2, bsz=56, num_updates=14110, lr=3.48556e-06, gnorm=3.819, clip=100, loss_scale=64, train_wall=17, gb_free=11.5, wall=24330
2023-06-27 23:04:25 - progress_bar.py[line:272] - INFO: epoch 015:    286 / 990 loss=2.318, loss_v1=0, loss_v2=0, nll_loss=1.111, ntokens=1855.2, nsentences=56, sample_size=1855.2, sample_size_v1=0, sample_size_v2=0, ppl=2.16, wps=1073, ups=0.58, wpb=1855.2, bsz=56, num_updates=14120, lr=3.46541e-06, gnorm=3.931, clip=100, loss_scale=64, train_wall=17, gb_free=12.6, wall=24347
2023-06-27 23:04:42 - progress_bar.py[line:272] - INFO: epoch 015:    296 / 990 loss=2.317, loss_v1=0, loss_v2=0, nll_loss=1.109, ntokens=1872, nsentences=56, sample_size=1872, sample_size_v1=0, sample_size_v2=0, ppl=2.16, wps=1090.1, ups=0.58, wpb=1872, bsz=56, num_updates=14130, lr=3.44527e-06, gnorm=4.102, clip=100, loss_scale=64, train_wall=17, gb_free=12, wall=24365
2023-06-27 23:04:59 - progress_bar.py[line:272] - INFO: epoch 015:    306 / 990 loss=2.318, loss_v1=0, loss_v2=0, nll_loss=1.111, ntokens=1886, nsentences=56, sample_size=1886, sample_size_v1=0, sample_size_v2=0, ppl=2.16, wps=1094.1, ups=0.58, wpb=1886, bsz=56, num_updates=14140, lr=3.42512e-06, gnorm=3.933, clip=100, loss_scale=64, train_wall=17, gb_free=12.5, wall=24382
2023-06-27 23:05:16 - progress_bar.py[line:272] - INFO: epoch 015:    316 / 990 loss=2.319, loss_v1=0, loss_v2=0, nll_loss=1.112, ntokens=1908.9, nsentences=56, sample_size=1908.9, sample_size_v1=0, sample_size_v2=0, ppl=2.16, wps=1110.6, ups=0.58, wpb=1908.9, bsz=56, num_updates=14150, lr=3.40497e-06, gnorm=3.795, clip=100, loss_scale=64, train_wall=17, gb_free=12, wall=24399
2023-06-27 23:05:34 - progress_bar.py[line:272] - INFO: epoch 015:    326 / 990 loss=2.314, loss_v1=0, loss_v2=0, nll_loss=1.106, ntokens=1936.7, nsentences=56, sample_size=1936.7, sample_size_v1=0, sample_size_v2=0, ppl=2.15, wps=1122.2, ups=0.58, wpb=1936.7, bsz=56, num_updates=14160, lr=3.38482e-06, gnorm=3.939, clip=100, loss_scale=64, train_wall=17, gb_free=12.1, wall=24416
2023-06-27 23:05:51 - progress_bar.py[line:272] - INFO: epoch 015:    336 / 990 loss=2.298, loss_v1=0, loss_v2=0, nll_loss=1.089, ntokens=1859.4, nsentences=56, sample_size=1859.4, sample_size_v1=0, sample_size_v2=0, ppl=2.13, wps=1079.5, ups=0.58, wpb=1859.4, bsz=56, num_updates=14170, lr=3.36467e-06, gnorm=4.041, clip=100, loss_scale=64, train_wall=17, gb_free=12.5, wall=24433
2023-06-27 23:06:08 - progress_bar.py[line:272] - INFO: epoch 015:    346 / 990 loss=2.297, loss_v1=0, loss_v2=0, nll_loss=1.087, ntokens=1868.4, nsentences=56, sample_size=1868.4, sample_size_v1=0, sample_size_v2=0, ppl=2.12, wps=1085.5, ups=0.58, wpb=1868.4, bsz=56, num_updates=14180, lr=3.34453e-06, gnorm=4.095, clip=100, loss_scale=64, train_wall=17, gb_free=12.6, wall=24451
2023-06-27 23:06:25 - progress_bar.py[line:272] - INFO: epoch 015:    356 / 990 loss=2.289, loss_v1=0, loss_v2=0, nll_loss=1.079, ntokens=1887.8, nsentences=56, sample_size=1887.8, sample_size_v1=0, sample_size_v2=0, ppl=2.11, wps=1099.3, ups=0.58, wpb=1887.8, bsz=56, num_updates=14190, lr=3.32438e-06, gnorm=3.71, clip=100, loss_scale=64, train_wall=17, gb_free=12.9, wall=24468
2023-06-27 23:06:42 - progress_bar.py[line:272] - INFO: epoch 015:    366 / 990 loss=2.315, loss_v1=0, loss_v2=0, nll_loss=1.109, ntokens=1716.6, nsentences=56, sample_size=1716.6, sample_size_v1=0, sample_size_v2=0, ppl=2.16, wps=1011.4, ups=0.59, wpb=1716.6, bsz=56, num_updates=14200, lr=3.30423e-06, gnorm=4.472, clip=100, loss_scale=64, train_wall=17, gb_free=12.8, wall=24485
2023-06-27 23:06:59 - progress_bar.py[line:272] - INFO: epoch 015:    376 / 990 loss=2.328, loss_v1=0, loss_v2=0, nll_loss=1.123, ntokens=1833.5, nsentences=56, sample_size=1833.5, sample_size_v1=0, sample_size_v2=0, ppl=2.18, wps=1074.6, ups=0.59, wpb=1833.5, bsz=56, num_updates=14210, lr=3.28408e-06, gnorm=4.281, clip=100, loss_scale=64, train_wall=17, gb_free=12.6, wall=24502
2023-06-27 23:07:16 - progress_bar.py[line:272] - INFO: epoch 015:    386 / 990 loss=2.287, loss_v1=0, loss_v2=0, nll_loss=1.077, ntokens=1874.3, nsentences=56, sample_size=1874.3, sample_size_v1=0, sample_size_v2=0, ppl=2.11, wps=1093, ups=0.58, wpb=1874.3, bsz=56, num_updates=14220, lr=3.26394e-06, gnorm=4.028, clip=100, loss_scale=64, train_wall=17, gb_free=12.9, wall=24519
2023-06-27 23:07:33 - progress_bar.py[line:272] - INFO: epoch 015:    396 / 990 loss=2.304, loss_v1=0, loss_v2=0, nll_loss=1.096, ntokens=1674.9, nsentences=56, sample_size=1674.9, sample_size_v1=0, sample_size_v2=0, ppl=2.14, wps=982.7, ups=0.59, wpb=1674.9, bsz=56, num_updates=14230, lr=3.24379e-06, gnorm=4.562, clip=100, loss_scale=64, train_wall=17, gb_free=12.5, wall=24536
2023-06-27 23:07:50 - progress_bar.py[line:272] - INFO: epoch 015:    406 / 990 loss=2.334, loss_v1=0, loss_v2=0, nll_loss=1.13, ntokens=1747.3, nsentences=56, sample_size=1747.3, sample_size_v1=0, sample_size_v2=0, ppl=2.19, wps=1027.8, ups=0.59, wpb=1747.3, bsz=56, num_updates=14240, lr=3.22364e-06, gnorm=4.614, clip=100, loss_scale=64, train_wall=17, gb_free=12.3, wall=24553
2023-06-27 23:08:07 - progress_bar.py[line:272] - INFO: epoch 015:    416 / 990 loss=2.324, loss_v1=0, loss_v2=0, nll_loss=1.119, ntokens=1733.6, nsentences=56, sample_size=1733.6, sample_size_v1=0, sample_size_v2=0, ppl=2.17, wps=1020.4, ups=0.59, wpb=1733.6, bsz=56, num_updates=14250, lr=3.20349e-06, gnorm=4.294, clip=100, loss_scale=64, train_wall=17, gb_free=12.8, wall=24570
2023-06-27 23:08:24 - progress_bar.py[line:272] - INFO: epoch 015:    426 / 990 loss=2.303, loss_v1=0, loss_v2=0, nll_loss=1.095, ntokens=1789.8, nsentences=56, sample_size=1789.8, sample_size_v1=0, sample_size_v2=0, ppl=2.14, wps=1048.4, ups=0.59, wpb=1789.8, bsz=56, num_updates=14260, lr=3.18334e-06, gnorm=4.252, clip=100, loss_scale=64, train_wall=17, gb_free=13, wall=24587
2023-06-27 23:08:42 - progress_bar.py[line:272] - INFO: epoch 015:    436 / 990 loss=2.302, loss_v1=0, loss_v2=0, nll_loss=1.093, ntokens=1937.4, nsentences=56, sample_size=1937.4, sample_size_v1=0, sample_size_v2=0, ppl=2.13, wps=1128.9, ups=0.58, wpb=1937.4, bsz=56, num_updates=14270, lr=3.1632e-06, gnorm=3.975, clip=100, loss_scale=64, train_wall=17, gb_free=12.4, wall=24604
2023-06-27 23:08:59 - progress_bar.py[line:272] - INFO: epoch 015:    446 / 990 loss=2.293, loss_v1=0, loss_v2=0, nll_loss=1.083, ntokens=1804.3, nsentences=56, sample_size=1804.3, sample_size_v1=0, sample_size_v2=0, ppl=2.12, wps=1056.6, ups=0.59, wpb=1804.3, bsz=56, num_updates=14280, lr=3.14305e-06, gnorm=3.855, clip=100, loss_scale=64, train_wall=17, gb_free=13.2, wall=24621
2023-06-27 23:09:15 - progress_bar.py[line:272] - INFO: epoch 015:    456 / 990 loss=2.316, loss_v1=0, loss_v2=0, nll_loss=1.11, ntokens=1769.4, nsentences=54.8, sample_size=1769.4, sample_size_v1=0, sample_size_v2=0, ppl=2.16, wps=1056.6, ups=0.6, wpb=1769.4, bsz=54.8, num_updates=14290, lr=3.1229e-06, gnorm=4.148, clip=100, loss_scale=64, train_wall=17, gb_free=13.1, wall=24638
2023-06-27 23:09:33 - progress_bar.py[line:272] - INFO: epoch 015:    466 / 990 loss=2.312, loss_v1=0, loss_v2=0, nll_loss=1.106, ntokens=1806.9, nsentences=56, sample_size=1806.9, sample_size_v1=0, sample_size_v2=0, ppl=2.15, wps=1054, ups=0.58, wpb=1806.9, bsz=56, num_updates=14300, lr=3.10275e-06, gnorm=4.15, clip=100, loss_scale=64, train_wall=17, gb_free=12.3, wall=24655
2023-06-27 23:09:50 - progress_bar.py[line:272] - INFO: epoch 015:    476 / 990 loss=2.295, loss_v1=0, loss_v2=0, nll_loss=1.086, ntokens=1870.2, nsentences=56, sample_size=1870.2, sample_size_v1=0, sample_size_v2=0, ppl=2.12, wps=1086.5, ups=0.58, wpb=1870.2, bsz=56, num_updates=14310, lr=3.08261e-06, gnorm=4.328, clip=100, loss_scale=64, train_wall=17, gb_free=12.9, wall=24673
2023-06-27 23:10:07 - progress_bar.py[line:272] - INFO: epoch 015:    486 / 990 loss=2.287, loss_v1=0, loss_v2=0, nll_loss=1.077, ntokens=1850.6, nsentences=56, sample_size=1850.6, sample_size_v1=0, sample_size_v2=0, ppl=2.11, wps=1078.3, ups=0.58, wpb=1850.6, bsz=56, num_updates=14320, lr=3.06246e-06, gnorm=4.109, clip=100, loss_scale=64, train_wall=17, gb_free=12.8, wall=24690
2023-06-27 23:10:24 - progress_bar.py[line:272] - INFO: epoch 015:    496 / 990 loss=2.303, loss_v1=0, loss_v2=0, nll_loss=1.094, ntokens=1853.8, nsentences=56, sample_size=1853.8, sample_size_v1=0, sample_size_v2=0, ppl=2.13, wps=1083.6, ups=0.58, wpb=1853.8, bsz=56, num_updates=14330, lr=3.04231e-06, gnorm=4.113, clip=100, loss_scale=64, train_wall=17, gb_free=12.9, wall=24707
2023-06-27 23:10:41 - progress_bar.py[line:272] - INFO: epoch 015:    506 / 990 loss=2.344, loss_v1=0, loss_v2=0, nll_loss=1.141, ntokens=1818.5, nsentences=56, sample_size=1818.5, sample_size_v1=0, sample_size_v2=0, ppl=2.2, wps=1062.7, ups=0.58, wpb=1818.5, bsz=56, num_updates=14340, lr=3.02216e-06, gnorm=4.019, clip=100, loss_scale=64, train_wall=17, gb_free=13.2, wall=24724
2023-06-27 23:10:58 - progress_bar.py[line:272] - INFO: epoch 015:    516 / 990 loss=2.307, loss_v1=0, loss_v2=0, nll_loss=1.098, ntokens=1736.4, nsentences=56, sample_size=1736.4, sample_size_v1=0, sample_size_v2=0, ppl=2.14, wps=1019.1, ups=0.59, wpb=1736.4, bsz=56, num_updates=14350, lr=3.00201e-06, gnorm=4.317, clip=100, loss_scale=64, train_wall=17, gb_free=12.7, wall=24741
2023-06-27 23:11:15 - progress_bar.py[line:272] - INFO: epoch 015:    526 / 990 loss=2.322, loss_v1=0, loss_v2=0, nll_loss=1.117, ntokens=1916.7, nsentences=56, sample_size=1916.7, sample_size_v1=0, sample_size_v2=0, ppl=2.17, wps=1116, ups=0.58, wpb=1916.7, bsz=56, num_updates=14360, lr=2.98187e-06, gnorm=3.872, clip=100, loss_scale=64, train_wall=17, gb_free=12.7, wall=24758
2023-06-27 23:11:33 - progress_bar.py[line:272] - INFO: epoch 015:    536 / 990 loss=2.3, loss_v1=0, loss_v2=0, nll_loss=1.091, ntokens=1875.1, nsentences=56, sample_size=1875.1, sample_size_v1=0, sample_size_v2=0, ppl=2.13, wps=1092, ups=0.58, wpb=1875.1, bsz=56, num_updates=14370, lr=2.96172e-06, gnorm=4.275, clip=100, loss_scale=64, train_wall=17, gb_free=12.9, wall=24775
2023-06-27 23:11:50 - progress_bar.py[line:272] - INFO: epoch 015:    546 / 990 loss=2.321, loss_v1=0, loss_v2=0, nll_loss=1.115, ntokens=1985.6, nsentences=56, sample_size=1985.6, sample_size_v1=0, sample_size_v2=0, ppl=2.17, wps=1156.3, ups=0.58, wpb=1985.6, bsz=56, num_updates=14380, lr=2.94157e-06, gnorm=3.891, clip=100, loss_scale=64, train_wall=17, gb_free=13, wall=24792
2023-06-27 23:12:07 - progress_bar.py[line:272] - INFO: epoch 015:    556 / 990 loss=2.297, loss_v1=0, loss_v2=0, nll_loss=1.088, ntokens=1825.9, nsentences=56, sample_size=1825.9, sample_size_v1=0, sample_size_v2=0, ppl=2.13, wps=1064.7, ups=0.58, wpb=1825.9, bsz=56, num_updates=14390, lr=2.92142e-06, gnorm=4.13, clip=100, loss_scale=64, train_wall=17, gb_free=12.3, wall=24810
2023-06-27 23:12:24 - progress_bar.py[line:272] - INFO: epoch 015:    566 / 990 loss=2.283, loss_v1=0, loss_v2=0, nll_loss=1.072, ntokens=1801.5, nsentences=56, sample_size=1801.5, sample_size_v1=0, sample_size_v2=0, ppl=2.1, wps=1054.1, ups=0.59, wpb=1801.5, bsz=56, num_updates=14400, lr=2.90128e-06, gnorm=3.897, clip=100, loss_scale=128, train_wall=17, gb_free=12.8, wall=24827
2023-06-27 23:12:41 - progress_bar.py[line:272] - INFO: epoch 015:    576 / 990 loss=2.318, loss_v1=0, loss_v2=0, nll_loss=1.111, ntokens=1805.5, nsentences=56, sample_size=1805.5, sample_size_v1=0, sample_size_v2=0, ppl=2.16, wps=1060.9, ups=0.59, wpb=1805.5, bsz=56, num_updates=14410, lr=2.88113e-06, gnorm=4.291, clip=100, loss_scale=128, train_wall=17, gb_free=12.5, wall=24844
2023-06-27 23:12:53 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2023-06-27 23:13:00 - progress_bar.py[line:272] - INFO: epoch 015:    587 / 990 loss=2.326, loss_v1=0, loss_v2=0, nll_loss=1.121, ntokens=1875.7, nsentences=56, sample_size=1875.7, sample_size_v1=0, sample_size_v2=0, ppl=2.18, wps=999.6, ups=0.53, wpb=1875.7, bsz=56, num_updates=14420, lr=2.86098e-06, gnorm=3.858, clip=100, loss_scale=64, train_wall=19, gb_free=12.8, wall=24863
2023-06-27 23:13:17 - progress_bar.py[line:272] - INFO: epoch 015:    597 / 990 loss=2.297, loss_v1=0, loss_v2=0, nll_loss=1.088, ntokens=1867.5, nsentences=56, sample_size=1867.5, sample_size_v1=0, sample_size_v2=0, ppl=2.13, wps=1092.6, ups=0.59, wpb=1867.5, bsz=56, num_updates=14430, lr=2.84083e-06, gnorm=4.175, clip=100, loss_scale=64, train_wall=17, gb_free=12.9, wall=24880
2023-06-27 23:13:34 - progress_bar.py[line:272] - INFO: epoch 015:    607 / 990 loss=2.303, loss_v1=0, loss_v2=0, nll_loss=1.095, ntokens=1774, nsentences=56, sample_size=1774, sample_size_v1=0, sample_size_v2=0, ppl=2.14, wps=1042.4, ups=0.59, wpb=1774, bsz=56, num_updates=14440, lr=2.82069e-06, gnorm=4.263, clip=100, loss_scale=64, train_wall=17, gb_free=12.6, wall=24897
2023-06-27 23:13:51 - progress_bar.py[line:272] - INFO: epoch 015:    617 / 990 loss=2.307, loss_v1=0, loss_v2=0, nll_loss=1.1, ntokens=1874.4, nsentences=56, sample_size=1874.4, sample_size_v1=0, sample_size_v2=0, ppl=2.14, wps=1100.4, ups=0.59, wpb=1874.4, bsz=56, num_updates=14450, lr=2.80054e-06, gnorm=3.822, clip=100, loss_scale=64, train_wall=17, gb_free=13, wall=24914
2023-06-27 23:14:08 - progress_bar.py[line:272] - INFO: epoch 015:    627 / 990 loss=2.329, loss_v1=0, loss_v2=0, nll_loss=1.123, ntokens=2043.5, nsentences=56, sample_size=2043.5, sample_size_v1=0, sample_size_v2=0, ppl=2.18, wps=1194.6, ups=0.58, wpb=2043.5, bsz=56, num_updates=14460, lr=2.78039e-06, gnorm=3.613, clip=100, loss_scale=64, train_wall=17, gb_free=12.6, wall=24931
2023-06-27 23:14:25 - progress_bar.py[line:272] - INFO: epoch 015:    637 / 990 loss=2.312, loss_v1=0, loss_v2=0, nll_loss=1.106, ntokens=1993.4, nsentences=56, sample_size=1993.4, sample_size_v1=0, sample_size_v2=0, ppl=2.15, wps=1159.6, ups=0.58, wpb=1993.4, bsz=56, num_updates=14470, lr=2.76024e-06, gnorm=3.756, clip=100, loss_scale=64, train_wall=17, gb_free=13, wall=24948
2023-06-27 23:14:43 - progress_bar.py[line:272] - INFO: epoch 015:    647 / 990 loss=2.318, loss_v1=0, loss_v2=0, nll_loss=1.111, ntokens=1970.7, nsentences=56, sample_size=1970.7, sample_size_v1=0, sample_size_v2=0, ppl=2.16, wps=1146.5, ups=0.58, wpb=1970.7, bsz=56, num_updates=14480, lr=2.74009e-06, gnorm=3.95, clip=100, loss_scale=64, train_wall=17, gb_free=12.4, wall=24965
2023-06-27 23:15:00 - progress_bar.py[line:272] - INFO: epoch 015:    657 / 990 loss=2.305, loss_v1=0, loss_v2=0, nll_loss=1.097, ntokens=1906.6, nsentences=56, sample_size=1906.6, sample_size_v1=0, sample_size_v2=0, ppl=2.14, wps=1099.3, ups=0.58, wpb=1906.6, bsz=56, num_updates=14490, lr=2.71995e-06, gnorm=3.826, clip=100, loss_scale=64, train_wall=17, gb_free=12.5, wall=24983
2023-06-27 23:15:17 - progress_bar.py[line:272] - INFO: epoch 015:    667 / 990 loss=2.32, loss_v1=0, loss_v2=0, nll_loss=1.114, ntokens=1818.2, nsentences=56, sample_size=1818.2, sample_size_v1=0, sample_size_v2=0, ppl=2.16, wps=1064.7, ups=0.59, wpb=1818.2, bsz=56, num_updates=14500, lr=2.6998e-06, gnorm=4.067, clip=100, loss_scale=64, train_wall=17, gb_free=12.8, wall=25000
2023-06-27 23:15:34 - progress_bar.py[line:272] - INFO: epoch 015:    677 / 990 loss=2.292, loss_v1=0, loss_v2=0, nll_loss=1.082, ntokens=1867.7, nsentences=56, sample_size=1867.7, sample_size_v1=0, sample_size_v2=0, ppl=2.12, wps=1088.9, ups=0.58, wpb=1867.7, bsz=56, num_updates=14510, lr=2.67965e-06, gnorm=4.165, clip=100, loss_scale=64, train_wall=17, gb_free=12.5, wall=25017
2023-06-27 23:15:51 - progress_bar.py[line:272] - INFO: epoch 015:    687 / 990 loss=2.276, loss_v1=0, loss_v2=0, nll_loss=1.064, ntokens=1855.2, nsentences=56, sample_size=1855.2, sample_size_v1=0, sample_size_v2=0, ppl=2.09, wps=1082.1, ups=0.58, wpb=1855.2, bsz=56, num_updates=14520, lr=2.6595e-06, gnorm=3.774, clip=100, loss_scale=64, train_wall=17, gb_free=12.6, wall=25034
2023-06-27 23:16:08 - progress_bar.py[line:272] - INFO: epoch 015:    697 / 990 loss=2.307, loss_v1=0, loss_v2=0, nll_loss=1.099, ntokens=1742.1, nsentences=56, sample_size=1742.1, sample_size_v1=0, sample_size_v2=0, ppl=2.14, wps=1019.4, ups=0.59, wpb=1742.1, bsz=56, num_updates=14530, lr=2.63936e-06, gnorm=4.394, clip=100, loss_scale=64, train_wall=17, gb_free=12.9, wall=25051
2023-06-27 23:16:25 - progress_bar.py[line:272] - INFO: epoch 015:    707 / 990 loss=2.328, loss_v1=0, loss_v2=0, nll_loss=1.124, ntokens=1710.3, nsentences=56, sample_size=1710.3, sample_size_v1=0, sample_size_v2=0, ppl=2.18, wps=1008, ups=0.59, wpb=1710.3, bsz=56, num_updates=14540, lr=2.61921e-06, gnorm=4.277, clip=100, loss_scale=64, train_wall=17, gb_free=12.7, wall=25068
2023-06-27 23:16:42 - progress_bar.py[line:272] - INFO: epoch 015:    717 / 990 loss=2.299, loss_v1=0, loss_v2=0, nll_loss=1.09, ntokens=1787.9, nsentences=56, sample_size=1787.9, sample_size_v1=0, sample_size_v2=0, ppl=2.13, wps=1052.8, ups=0.59, wpb=1787.9, bsz=56, num_updates=14550, lr=2.59906e-06, gnorm=4.116, clip=100, loss_scale=64, train_wall=17, gb_free=13.1, wall=25085
2023-06-27 23:16:59 - progress_bar.py[line:272] - INFO: epoch 015:    727 / 990 loss=2.29, loss_v1=0, loss_v2=0, nll_loss=1.079, ntokens=1797, nsentences=56, sample_size=1797, sample_size_v1=0, sample_size_v2=0, ppl=2.11, wps=1056, ups=0.59, wpb=1797, bsz=56, num_updates=14560, lr=2.57891e-06, gnorm=3.986, clip=100, loss_scale=64, train_wall=17, gb_free=12.7, wall=25102
2023-06-27 23:17:16 - progress_bar.py[line:272] - INFO: epoch 015:    737 / 990 loss=2.3, loss_v1=0, loss_v2=0, nll_loss=1.091, ntokens=1836, nsentences=56, sample_size=1836, sample_size_v1=0, sample_size_v2=0, ppl=2.13, wps=1075.3, ups=0.59, wpb=1836, bsz=56, num_updates=14570, lr=2.55876e-06, gnorm=3.924, clip=100, loss_scale=64, train_wall=17, gb_free=12.8, wall=25119
2023-06-27 23:17:33 - progress_bar.py[line:272] - INFO: epoch 015:    747 / 990 loss=2.318, loss_v1=0, loss_v2=0, nll_loss=1.112, ntokens=1704.5, nsentences=56, sample_size=1704.5, sample_size_v1=0, sample_size_v2=0, ppl=2.16, wps=1002.8, ups=0.59, wpb=1704.5, bsz=56, num_updates=14580, lr=2.53862e-06, gnorm=4.492, clip=100, loss_scale=64, train_wall=17, gb_free=13.1, wall=25136
2023-06-27 23:17:50 - progress_bar.py[line:272] - INFO: epoch 015:    757 / 990 loss=2.334, loss_v1=0, loss_v2=0, nll_loss=1.13, ntokens=1695.8, nsentences=56, sample_size=1695.8, sample_size_v1=0, sample_size_v2=0, ppl=2.19, wps=997.9, ups=0.59, wpb=1695.8, bsz=56, num_updates=14590, lr=2.51847e-06, gnorm=4.403, clip=100, loss_scale=64, train_wall=17, gb_free=12.6, wall=25153
2023-06-27 23:18:07 - progress_bar.py[line:272] - INFO: epoch 015:    767 / 990 loss=2.307, loss_v1=0, loss_v2=0, nll_loss=1.099, ntokens=1792, nsentences=56, sample_size=1792, sample_size_v1=0, sample_size_v2=0, ppl=2.14, wps=1050, ups=0.59, wpb=1792, bsz=56, num_updates=14600, lr=2.49832e-06, gnorm=4.094, clip=100, loss_scale=64, train_wall=17, gb_free=12.6, wall=25170
2023-06-27 23:18:25 - progress_bar.py[line:272] - INFO: epoch 015:    777 / 990 loss=2.301, loss_v1=0, loss_v2=0, nll_loss=1.093, ntokens=1799.7, nsentences=56, sample_size=1799.7, sample_size_v1=0, sample_size_v2=0, ppl=2.13, wps=1053.4, ups=0.59, wpb=1799.7, bsz=56, num_updates=14610, lr=2.47817e-06, gnorm=4.155, clip=100, loss_scale=64, train_wall=17, gb_free=13.2, wall=25187
2023-06-27 23:18:42 - progress_bar.py[line:272] - INFO: epoch 015:    787 / 990 loss=2.306, loss_v1=0, loss_v2=0, nll_loss=1.098, ntokens=1758.7, nsentences=56, sample_size=1758.7, sample_size_v1=0, sample_size_v2=0, ppl=2.14, wps=1032.2, ups=0.59, wpb=1758.7, bsz=56, num_updates=14620, lr=2.45803e-06, gnorm=4.465, clip=100, loss_scale=64, train_wall=17, gb_free=12.6, wall=25204
2023-06-27 23:18:59 - progress_bar.py[line:272] - INFO: epoch 015:    797 / 990 loss=2.313, loss_v1=0, loss_v2=0, nll_loss=1.107, ntokens=1888.2, nsentences=56, sample_size=1888.2, sample_size_v1=0, sample_size_v2=0, ppl=2.15, wps=1099.9, ups=0.58, wpb=1888.2, bsz=56, num_updates=14630, lr=2.43788e-06, gnorm=4.037, clip=100, loss_scale=64, train_wall=17, gb_free=12.7, wall=25221
2023-06-27 23:19:16 - progress_bar.py[line:272] - INFO: epoch 015:    807 / 990 loss=2.312, loss_v1=0, loss_v2=0, nll_loss=1.105, ntokens=1726, nsentences=56, sample_size=1726, sample_size_v1=0, sample_size_v2=0, ppl=2.15, wps=1013.7, ups=0.59, wpb=1726, bsz=56, num_updates=14640, lr=2.41773e-06, gnorm=4.191, clip=100, loss_scale=64, train_wall=17, gb_free=13, wall=25238
2023-06-27 23:19:33 - progress_bar.py[line:272] - INFO: epoch 015:    817 / 990 loss=2.328, loss_v1=0, loss_v2=0, nll_loss=1.122, ntokens=1629.3, nsentences=56, sample_size=1629.3, sample_size_v1=0, sample_size_v2=0, ppl=2.18, wps=960.3, ups=0.59, wpb=1629.3, bsz=56, num_updates=14650, lr=2.39758e-06, gnorm=4.636, clip=100, loss_scale=64, train_wall=17, gb_free=12.8, wall=25255
2023-06-27 23:19:50 - progress_bar.py[line:272] - INFO: epoch 015:    827 / 990 loss=2.29, loss_v1=0, loss_v2=0, nll_loss=1.078, ntokens=1754, nsentences=56, sample_size=1754, sample_size_v1=0, sample_size_v2=0, ppl=2.11, wps=1028.7, ups=0.59, wpb=1754, bsz=56, num_updates=14660, lr=2.37743e-06, gnorm=4.203, clip=100, loss_scale=64, train_wall=17, gb_free=13, wall=25272
2023-06-27 23:20:07 - progress_bar.py[line:272] - INFO: epoch 015:    837 / 990 loss=2.291, loss_v1=0, loss_v2=0, nll_loss=1.081, ntokens=1757.1, nsentences=56, sample_size=1757.1, sample_size_v1=0, sample_size_v2=0, ppl=2.12, wps=1033.1, ups=0.59, wpb=1757.1, bsz=56, num_updates=14670, lr=2.35729e-06, gnorm=4.294, clip=100, loss_scale=64, train_wall=17, gb_free=12.8, wall=25289
2023-06-27 23:20:24 - progress_bar.py[line:272] - INFO: epoch 015:    847 / 990 loss=2.289, loss_v1=0, loss_v2=0, nll_loss=1.08, ntokens=1882.3, nsentences=56, sample_size=1882.3, sample_size_v1=0, sample_size_v2=0, ppl=2.11, wps=1100.7, ups=0.58, wpb=1882.3, bsz=56, num_updates=14680, lr=2.33714e-06, gnorm=4.255, clip=100, loss_scale=64, train_wall=17, gb_free=12.6, wall=25307
2023-06-27 23:20:41 - progress_bar.py[line:272] - INFO: epoch 015:    857 / 990 loss=2.268, loss_v1=0, loss_v2=0, nll_loss=1.055, ntokens=1887.2, nsentences=56, sample_size=1887.2, sample_size_v1=0, sample_size_v2=0, ppl=2.08, wps=1100.5, ups=0.58, wpb=1887.2, bsz=56, num_updates=14690, lr=2.31699e-06, gnorm=4.073, clip=100, loss_scale=64, train_wall=17, gb_free=12.9, wall=25324
2023-06-27 23:20:58 - progress_bar.py[line:272] - INFO: epoch 015:    867 / 990 loss=2.294, loss_v1=0, loss_v2=0, nll_loss=1.084, ntokens=1769.9, nsentences=56, sample_size=1769.9, sample_size_v1=0, sample_size_v2=0, ppl=2.12, wps=1036.3, ups=0.59, wpb=1769.9, bsz=56, num_updates=14700, lr=2.29684e-06, gnorm=4.373, clip=100, loss_scale=64, train_wall=17, gb_free=12.5, wall=25341
2023-06-27 23:21:15 - progress_bar.py[line:272] - INFO: epoch 015:    877 / 990 loss=2.283, loss_v1=0, loss_v2=0, nll_loss=1.073, ntokens=1882.8, nsentences=56, sample_size=1882.8, sample_size_v1=0, sample_size_v2=0, ppl=2.1, wps=1100.1, ups=0.58, wpb=1882.8, bsz=56, num_updates=14710, lr=2.2767e-06, gnorm=3.88, clip=100, loss_scale=64, train_wall=17, gb_free=12.4, wall=25358
2023-06-27 23:21:32 - progress_bar.py[line:272] - INFO: epoch 015:    887 / 990 loss=2.289, loss_v1=0, loss_v2=0, nll_loss=1.078, ntokens=1976.8, nsentences=56, sample_size=1976.8, sample_size_v1=0, sample_size_v2=0, ppl=2.11, wps=1154.9, ups=0.58, wpb=1976.8, bsz=56, num_updates=14720, lr=2.25655e-06, gnorm=3.873, clip=100, loss_scale=64, train_wall=17, gb_free=12.5, wall=25375
2023-06-27 23:21:50 - progress_bar.py[line:272] - INFO: epoch 015:    897 / 990 loss=2.287, loss_v1=0, loss_v2=0, nll_loss=1.077, ntokens=1841.2, nsentences=56, sample_size=1841.2, sample_size_v1=0, sample_size_v2=0, ppl=2.11, wps=1073.5, ups=0.58, wpb=1841.2, bsz=56, num_updates=14730, lr=2.2364e-06, gnorm=4.153, clip=100, loss_scale=64, train_wall=17, gb_free=12.6, wall=25392
2023-06-27 23:22:07 - progress_bar.py[line:272] - INFO: epoch 015:    907 / 990 loss=2.322, loss_v1=0, loss_v2=0, nll_loss=1.117, ntokens=1785.9, nsentences=56, sample_size=1785.9, sample_size_v1=0, sample_size_v2=0, ppl=2.17, wps=1047.8, ups=0.59, wpb=1785.9, bsz=56, num_updates=14740, lr=2.21625e-06, gnorm=4.181, clip=100, loss_scale=64, train_wall=17, gb_free=12.8, wall=25409
2023-06-27 23:22:24 - progress_bar.py[line:272] - INFO: epoch 015:    917 / 990 loss=2.296, loss_v1=0, loss_v2=0, nll_loss=1.088, ntokens=1718.9, nsentences=56, sample_size=1718.9, sample_size_v1=0, sample_size_v2=0, ppl=2.13, wps=1012.3, ups=0.59, wpb=1718.9, bsz=56, num_updates=14750, lr=2.1961e-06, gnorm=4.197, clip=100, loss_scale=64, train_wall=17, gb_free=13.2, wall=25426
2023-06-27 23:22:41 - progress_bar.py[line:272] - INFO: epoch 015:    927 / 990 loss=2.273, loss_v1=0, loss_v2=0, nll_loss=1.062, ntokens=1859.9, nsentences=56, sample_size=1859.9, sample_size_v1=0, sample_size_v2=0, ppl=2.09, wps=1081.5, ups=0.58, wpb=1859.9, bsz=56, num_updates=14760, lr=2.17596e-06, gnorm=4.142, clip=100, loss_scale=64, train_wall=17, gb_free=12.7, wall=25443
2023-06-27 23:22:58 - progress_bar.py[line:272] - INFO: epoch 015:    937 / 990 loss=2.288, loss_v1=0, loss_v2=0, nll_loss=1.078, ntokens=1778.3, nsentences=56, sample_size=1778.3, sample_size_v1=0, sample_size_v2=0, ppl=2.11, wps=1044.4, ups=0.59, wpb=1778.3, bsz=56, num_updates=14770, lr=2.15581e-06, gnorm=4.014, clip=100, loss_scale=64, train_wall=17, gb_free=12.4, wall=25460
2023-06-27 23:23:15 - progress_bar.py[line:272] - INFO: epoch 015:    947 / 990 loss=2.282, loss_v1=0, loss_v2=0, nll_loss=1.072, ntokens=1942, nsentences=56, sample_size=1942, sample_size_v1=0, sample_size_v2=0, ppl=2.1, wps=1128.2, ups=0.58, wpb=1942, bsz=56, num_updates=14780, lr=2.13566e-06, gnorm=3.693, clip=100, loss_scale=64, train_wall=17, gb_free=13, wall=25478
2023-06-27 23:23:32 - progress_bar.py[line:272] - INFO: epoch 015:    957 / 990 loss=2.306, loss_v1=0, loss_v2=0, nll_loss=1.099, ntokens=1883.8, nsentences=56, sample_size=1883.8, sample_size_v1=0, sample_size_v2=0, ppl=2.14, wps=1103.5, ups=0.59, wpb=1883.8, bsz=56, num_updates=14790, lr=2.11551e-06, gnorm=4.041, clip=100, loss_scale=64, train_wall=17, gb_free=12.9, wall=25495
2023-06-27 23:23:49 - progress_bar.py[line:272] - INFO: epoch 015:    967 / 990 loss=2.29, loss_v1=0, loss_v2=0, nll_loss=1.08, ntokens=1916.3, nsentences=56, sample_size=1916.3, sample_size_v1=0, sample_size_v2=0, ppl=2.11, wps=1115.9, ups=0.58, wpb=1916.3, bsz=56, num_updates=14800, lr=2.09537e-06, gnorm=3.724, clip=100, loss_scale=64, train_wall=17, gb_free=12.6, wall=25512
2023-06-27 23:24:06 - progress_bar.py[line:272] - INFO: epoch 015:    977 / 990 loss=2.287, loss_v1=0, loss_v2=0, nll_loss=1.078, ntokens=1882.8, nsentences=56, sample_size=1882.8, sample_size_v1=0, sample_size_v2=0, ppl=2.11, wps=1097.3, ups=0.58, wpb=1882.8, bsz=56, num_updates=14810, lr=2.07522e-06, gnorm=3.897, clip=100, loss_scale=64, train_wall=17, gb_free=12.9, wall=25529
2023-06-27 23:24:23 - progress_bar.py[line:272] - INFO: epoch 015:    987 / 990 loss=2.322, loss_v1=0, loss_v2=0, nll_loss=1.117, ntokens=1805.9, nsentences=56, sample_size=1805.9, sample_size_v1=0, sample_size_v2=0, ppl=2.17, wps=1063.1, ups=0.59, wpb=1805.9, bsz=56, num_updates=14820, lr=2.05507e-06, gnorm=3.918, clip=100, loss_scale=64, train_wall=17, gb_free=12.6, wall=25546
local datafile ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 1 begin to initialize row_count and line_idx-to-offset mapping
2023-06-27 23:24:28 - train.py[line:332] - INFO: end of epoch 15 (average epoch stats below)
2023-06-27 23:24:28 - progress_bar.py[line:282] - INFO: epoch 015 | loss 2.288 | loss_v1 0 | loss_v2 0 | nll_loss 1.078 | ntokens 1849.5 | nsentences 55.96 | sample_size 1849.5 | sample_size_v1 0 | sample_size_v2 0 | ppl 2.11 | wps 1074.6 | ups 0.58 | wpb 1849.5 | bsz 56 | num_updates 14823 | lr 2.04903e-06 | gnorm 4.066 | clip 100 | loss_scale 64 | train_wall 1695 | gb_free 13.3 | wall 25550
2023-06-27 23:24:28 - trainer.py[line:639] - INFO: loading train data for epoch 16
local datafile ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 0 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 1 finished initializing row_count and line_idx-to-offset mapping
file ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 1 row count 27700 total row count 55400
local datafile ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 0 finished initializing row_count and line_idx-to-offset mapping
file ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 0 row count 27700 total row count 55400
slice_id 1 seek offset 27700
slice_id 0 seek offset 0
2023-06-27 23:24:30 - trainer.py[line:703] - INFO: begin training epoch 16
2023-06-27 23:24:30 - train.py[line:305] - INFO: Start iterating over samples
2023-06-27 23:24:42 - progress_bar.py[line:272] - INFO: epoch 016:      7 / 990 loss=2.273, loss_v1=0, loss_v2=0, nll_loss=1.061, ntokens=1781.9, nsentences=53.2, sample_size=1781.9, sample_size_v1=0, sample_size_v2=0, ppl=2.09, wps=953.8, ups=0.54, wpb=1781.9, bsz=53.2, num_updates=14830, lr=2.03492e-06, gnorm=4.297, clip=100, loss_scale=64, train_wall=16, gb_free=12.5, wall=25565
2023-06-27 23:24:59 - progress_bar.py[line:272] - INFO: epoch 016:     17 / 990 loss=2.257, loss_v1=0, loss_v2=0, nll_loss=1.043, ntokens=1849.7, nsentences=56, sample_size=1849.7, sample_size_v1=0, sample_size_v2=0, ppl=2.06, wps=1073.3, ups=0.58, wpb=1849.7, bsz=56, num_updates=14840, lr=2.01478e-06, gnorm=4.288, clip=100, loss_scale=64, train_wall=17, gb_free=12.2, wall=25582
2023-06-27 23:25:17 - progress_bar.py[line:272] - INFO: epoch 016:     27 / 990 loss=2.221, loss_v1=0, loss_v2=0, nll_loss=1.003, ntokens=1751.6, nsentences=56, sample_size=1751.6, sample_size_v1=0, sample_size_v2=0, ppl=2, wps=1013.9, ups=0.58, wpb=1751.6, bsz=56, num_updates=14850, lr=1.99463e-06, gnorm=4.491, clip=100, loss_scale=64, train_wall=17, gb_free=13.1, wall=25599
2023-06-27 23:25:34 - progress_bar.py[line:272] - INFO: epoch 016:     37 / 990 loss=2.222, loss_v1=0, loss_v2=0, nll_loss=1.003, ntokens=1846.2, nsentences=56, sample_size=1846.2, sample_size_v1=0, sample_size_v2=0, ppl=2, wps=1078.1, ups=0.58, wpb=1846.2, bsz=56, num_updates=14860, lr=1.97448e-06, gnorm=3.981, clip=100, loss_scale=64, train_wall=17, gb_free=12.2, wall=25616
2023-06-27 23:25:51 - progress_bar.py[line:272] - INFO: epoch 016:     47 / 990 loss=2.171, loss_v1=0, loss_v2=0, nll_loss=0.947, ntokens=1958.5, nsentences=56, sample_size=1958.5, sample_size_v1=0, sample_size_v2=0, ppl=1.93, wps=1127.5, ups=0.58, wpb=1958.5, bsz=56, num_updates=14870, lr=1.95433e-06, gnorm=3.795, clip=100, loss_scale=64, train_wall=17, gb_free=12.4, wall=25634
2023-06-27 23:26:08 - progress_bar.py[line:272] - INFO: epoch 016:     57 / 990 loss=2.243, loss_v1=0, loss_v2=0, nll_loss=1.027, ntokens=1733.6, nsentences=56, sample_size=1733.6, sample_size_v1=0, sample_size_v2=0, ppl=2.04, wps=1006.5, ups=0.58, wpb=1733.6, bsz=56, num_updates=14880, lr=1.93418e-06, gnorm=4.201, clip=100, loss_scale=64, train_wall=17, gb_free=12.4, wall=25651
2023-06-27 23:26:25 - progress_bar.py[line:272] - INFO: epoch 016:     67 / 990 loss=2.144, loss_v1=0, loss_v2=0, nll_loss=0.916, ntokens=1801.2, nsentences=56, sample_size=1801.2, sample_size_v1=0, sample_size_v2=0, ppl=1.89, wps=1052.8, ups=0.58, wpb=1801.2, bsz=56, num_updates=14890, lr=1.91404e-06, gnorm=4.099, clip=100, loss_scale=64, train_wall=17, gb_free=12.2, wall=25668
2023-06-27 23:26:43 - progress_bar.py[line:272] - INFO: epoch 016:     77 / 990 loss=2.107, loss_v1=0, loss_v2=0, nll_loss=0.876, ntokens=2202.5, nsentences=56, sample_size=2202.5, sample_size_v1=0, sample_size_v2=0, ppl=1.83, wps=1240.2, ups=0.56, wpb=2202.5, bsz=56, num_updates=14900, lr=1.89389e-06, gnorm=3.292, clip=100, loss_scale=64, train_wall=18, gb_free=11, wall=25686
2023-06-27 23:27:01 - progress_bar.py[line:272] - INFO: epoch 016:     87 / 990 loss=2.173, loss_v1=0, loss_v2=0, nll_loss=0.949, ntokens=2110.4, nsentences=56, sample_size=2110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.93, wps=1196.9, ups=0.57, wpb=2110.4, bsz=56, num_updates=14910, lr=1.87374e-06, gnorm=3.519, clip=100, loss_scale=64, train_wall=18, gb_free=11.5, wall=25704
2023-06-27 23:27:18 - progress_bar.py[line:272] - INFO: epoch 016:     97 / 990 loss=2.226, loss_v1=0, loss_v2=0, nll_loss=1.009, ntokens=1906.7, nsentences=56, sample_size=1906.7, sample_size_v1=0, sample_size_v2=0, ppl=2.01, wps=1102.2, ups=0.58, wpb=1906.7, bsz=56, num_updates=14920, lr=1.85359e-06, gnorm=4.304, clip=100, loss_scale=64, train_wall=17, gb_free=12.8, wall=25721
2023-06-27 23:27:35 - progress_bar.py[line:272] - INFO: epoch 016:    107 / 990 loss=2.19, loss_v1=0, loss_v2=0, nll_loss=0.968, ntokens=1925.5, nsentences=56, sample_size=1925.5, sample_size_v1=0, sample_size_v2=0, ppl=1.96, wps=1116.2, ups=0.58, wpb=1925.5, bsz=56, num_updates=14930, lr=1.83345e-06, gnorm=4.015, clip=100, loss_scale=128, train_wall=17, gb_free=12.9, wall=25738
2023-06-27 23:27:53 - progress_bar.py[line:272] - INFO: epoch 016:    117 / 990 loss=2.283, loss_v1=0, loss_v2=0, nll_loss=1.073, ntokens=1763.3, nsentences=56, sample_size=1763.3, sample_size_v1=0, sample_size_v2=0, ppl=2.1, wps=1026.7, ups=0.58, wpb=1763.3, bsz=56, num_updates=14940, lr=1.8133e-06, gnorm=4.718, clip=100, loss_scale=128, train_wall=17, gb_free=12.4, wall=25755
2023-06-27 23:28:06 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2023-06-27 23:28:12 - progress_bar.py[line:272] - INFO: epoch 016:    128 / 990 loss=2.293, loss_v1=0, loss_v2=0, nll_loss=1.084, ntokens=1837.3, nsentences=56, sample_size=1837.3, sample_size_v1=0, sample_size_v2=0, ppl=2.12, wps=971.8, ups=0.53, wpb=1837.3, bsz=56, num_updates=14950, lr=1.79315e-06, gnorm=4.024, clip=100, loss_scale=64, train_wall=19, gb_free=11.6, wall=25774
2023-06-27 23:28:29 - progress_bar.py[line:272] - INFO: epoch 016:    138 / 990 loss=2.275, loss_v1=0, loss_v2=0, nll_loss=1.064, ntokens=1885.3, nsentences=56, sample_size=1885.3, sample_size_v1=0, sample_size_v2=0, ppl=2.09, wps=1084.8, ups=0.58, wpb=1885.3, bsz=56, num_updates=14960, lr=1.773e-06, gnorm=4.021, clip=100, loss_scale=64, train_wall=17, gb_free=12.3, wall=25792
2023-06-27 23:28:46 - progress_bar.py[line:272] - INFO: epoch 016:    148 / 990 loss=2.28, loss_v1=0, loss_v2=0, nll_loss=1.069, ntokens=1959, nsentences=56, sample_size=1959, sample_size_v1=0, sample_size_v2=0, ppl=2.1, wps=1122, ups=0.57, wpb=1959, bsz=56, num_updates=14970, lr=1.75285e-06, gnorm=3.985, clip=100, loss_scale=64, train_wall=17, gb_free=11, wall=25809
2023-06-27 23:29:04 - progress_bar.py[line:272] - INFO: epoch 016:    158 / 990 loss=2.244, loss_v1=0, loss_v2=0, nll_loss=1.03, ntokens=1964.5, nsentences=56, sample_size=1964.5, sample_size_v1=0, sample_size_v2=0, ppl=2.04, wps=1127.1, ups=0.57, wpb=1964.5, bsz=56, num_updates=14980, lr=1.73271e-06, gnorm=4.015, clip=100, loss_scale=64, train_wall=17, gb_free=12.2, wall=25826
2023-06-27 23:29:21 - progress_bar.py[line:272] - INFO: epoch 016:    168 / 990 loss=2.237, loss_v1=0, loss_v2=0, nll_loss=1.021, ntokens=1934.6, nsentences=56, sample_size=1934.6, sample_size_v1=0, sample_size_v2=0, ppl=2.03, wps=1104.2, ups=0.57, wpb=1934.6, bsz=56, num_updates=14990, lr=1.71256e-06, gnorm=3.799, clip=100, loss_scale=64, train_wall=17, gb_free=12.2, wall=25844
2023-06-27 23:29:39 - progress_bar.py[line:272] - INFO: epoch 016:    178 / 990 loss=2.257, loss_v1=0, loss_v2=0, nll_loss=1.043, ntokens=1972.4, nsentences=56, sample_size=1972.4, sample_size_v1=0, sample_size_v2=0, ppl=2.06, wps=1129.4, ups=0.57, wpb=1972.4, bsz=56, num_updates=15000, lr=1.69241e-06, gnorm=3.657, clip=100, loss_scale=64, train_wall=17, gb_free=12.1, wall=25861
2023-06-27 23:29:56 - progress_bar.py[line:272] - INFO: epoch 016:    188 / 990 loss=2.247, loss_v1=0, loss_v2=0, nll_loss=1.031, ntokens=1916.2, nsentences=56, sample_size=1916.2, sample_size_v1=0, sample_size_v2=0, ppl=2.04, wps=1105.7, ups=0.58, wpb=1916.2, bsz=56, num_updates=15010, lr=1.67226e-06, gnorm=4.191, clip=100, loss_scale=64, train_wall=17, gb_free=11.3, wall=25879
2023-06-27 23:30:13 - progress_bar.py[line:272] - INFO: epoch 016:    198 / 990 loss=2.274, loss_v1=0, loss_v2=0, nll_loss=1.061, ntokens=1739.5, nsentences=56, sample_size=1739.5, sample_size_v1=0, sample_size_v2=0, ppl=2.09, wps=1017.6, ups=0.58, wpb=1739.5, bsz=56, num_updates=15020, lr=1.65212e-06, gnorm=4.309, clip=100, loss_scale=64, train_wall=17, gb_free=12.6, wall=25896
2023-06-27 23:30:31 - progress_bar.py[line:272] - INFO: epoch 016:    208 / 990 loss=2.223, loss_v1=0, loss_v2=0, nll_loss=1.005, ntokens=1976.6, nsentences=56, sample_size=1976.6, sample_size_v1=0, sample_size_v2=0, ppl=2.01, wps=1135.6, ups=0.57, wpb=1976.6, bsz=56, num_updates=15030, lr=1.63197e-06, gnorm=3.935, clip=100, loss_scale=64, train_wall=17, gb_free=11.9, wall=25913
2023-06-27 23:30:48 - progress_bar.py[line:272] - INFO: epoch 016:    218 / 990 loss=2.246, loss_v1=0, loss_v2=0, nll_loss=1.03, ntokens=1936.9, nsentences=56, sample_size=1936.9, sample_size_v1=0, sample_size_v2=0, ppl=2.04, wps=1113.9, ups=0.58, wpb=1936.9, bsz=56, num_updates=15040, lr=1.61182e-06, gnorm=4.137, clip=100, loss_scale=64, train_wall=17, gb_free=12.3, wall=25931
2023-06-27 23:31:06 - progress_bar.py[line:272] - INFO: epoch 016:    228 / 990 loss=2.276, loss_v1=0, loss_v2=0, nll_loss=1.065, ntokens=1867.9, nsentences=56, sample_size=1867.9, sample_size_v1=0, sample_size_v2=0, ppl=2.09, wps=1067.4, ups=0.57, wpb=1867.9, bsz=56, num_updates=15050, lr=1.59167e-06, gnorm=3.907, clip=100, loss_scale=64, train_wall=17, gb_free=12.7, wall=25948
2023-06-27 23:31:23 - progress_bar.py[line:272] - INFO: epoch 016:    238 / 990 loss=2.297, loss_v1=0, loss_v2=0, nll_loss=1.088, ntokens=1736.4, nsentences=56, sample_size=1736.4, sample_size_v1=0, sample_size_v2=0, ppl=2.13, wps=1012.4, ups=0.58, wpb=1736.4, bsz=56, num_updates=15060, lr=1.57152e-06, gnorm=4.432, clip=100, loss_scale=64, train_wall=17, gb_free=12.7, wall=25965
2023-06-27 23:31:40 - progress_bar.py[line:272] - INFO: epoch 016:    248 / 990 loss=2.315, loss_v1=0, loss_v2=0, nll_loss=1.109, ntokens=1948.2, nsentences=56, sample_size=1948.2, sample_size_v1=0, sample_size_v2=0, ppl=2.16, wps=1132.8, ups=0.58, wpb=1948.2, bsz=56, num_updates=15070, lr=1.55138e-06, gnorm=3.961, clip=100, loss_scale=64, train_wall=17, gb_free=12.2, wall=25983
2023-06-27 23:31:57 - progress_bar.py[line:272] - INFO: epoch 016:    258 / 990 loss=2.288, loss_v1=0, loss_v2=0, nll_loss=1.077, ntokens=1894.2, nsentences=56, sample_size=1894.2, sample_size_v1=0, sample_size_v2=0, ppl=2.11, wps=1103.6, ups=0.58, wpb=1894.2, bsz=56, num_updates=15080, lr=1.53123e-06, gnorm=3.852, clip=100, loss_scale=64, train_wall=17, gb_free=12.5, wall=26000
2023-06-27 23:32:14 - progress_bar.py[line:272] - INFO: epoch 016:    268 / 990 loss=2.327, loss_v1=0, loss_v2=0, nll_loss=1.123, ntokens=1839.7, nsentences=56, sample_size=1839.7, sample_size_v1=0, sample_size_v2=0, ppl=2.18, wps=1069.9, ups=0.58, wpb=1839.7, bsz=56, num_updates=15090, lr=1.51108e-06, gnorm=4.182, clip=100, loss_scale=64, train_wall=17, gb_free=12.3, wall=26017
2023-06-27 23:32:32 - progress_bar.py[line:272] - INFO: epoch 016:    278 / 990 loss=2.316, loss_v1=0, loss_v2=0, nll_loss=1.111, ntokens=1941.5, nsentences=56, sample_size=1941.5, sample_size_v1=0, sample_size_v2=0, ppl=2.16, wps=1119.3, ups=0.58, wpb=1941.5, bsz=56, num_updates=15100, lr=1.49093e-06, gnorm=3.991, clip=100, loss_scale=64, train_wall=17, gb_free=12.7, wall=26034
2023-06-27 23:32:49 - progress_bar.py[line:272] - INFO: epoch 016:    288 / 990 loss=2.317, loss_v1=0, loss_v2=0, nll_loss=1.111, ntokens=1851.2, nsentences=56, sample_size=1851.2, sample_size_v1=0, sample_size_v2=0, ppl=2.16, wps=1075.3, ups=0.58, wpb=1851.2, bsz=56, num_updates=15110, lr=1.47079e-06, gnorm=4.02, clip=100, loss_scale=64, train_wall=17, gb_free=12.6, wall=26052
2023-06-27 23:33:06 - progress_bar.py[line:272] - INFO: epoch 016:    298 / 990 loss=2.319, loss_v1=0, loss_v2=0, nll_loss=1.112, ntokens=1889.9, nsentences=56, sample_size=1889.9, sample_size_v1=0, sample_size_v2=0, ppl=2.16, wps=1102.4, ups=0.58, wpb=1889.9, bsz=56, num_updates=15120, lr=1.45064e-06, gnorm=4.201, clip=100, loss_scale=64, train_wall=17, gb_free=12.5, wall=26069
2023-06-27 23:33:23 - progress_bar.py[line:272] - INFO: epoch 016:    308 / 990 loss=2.306, loss_v1=0, loss_v2=0, nll_loss=1.099, ntokens=1878.7, nsentences=56, sample_size=1878.7, sample_size_v1=0, sample_size_v2=0, ppl=2.14, wps=1090, ups=0.58, wpb=1878.7, bsz=56, num_updates=15130, lr=1.43049e-06, gnorm=3.905, clip=100, loss_scale=64, train_wall=17, gb_free=12.5, wall=26086
2023-06-27 23:33:40 - progress_bar.py[line:272] - INFO: epoch 016:    318 / 990 loss=2.317, loss_v1=0, loss_v2=0, nll_loss=1.11, ntokens=1926.7, nsentences=56, sample_size=1926.7, sample_size_v1=0, sample_size_v2=0, ppl=2.16, wps=1118.1, ups=0.58, wpb=1926.7, bsz=56, num_updates=15140, lr=1.41034e-06, gnorm=4.289, clip=100, loss_scale=64, train_wall=17, gb_free=11.4, wall=26103
2023-06-27 23:33:58 - progress_bar.py[line:272] - INFO: epoch 016:    328 / 990 loss=2.3, loss_v1=0, loss_v2=0, nll_loss=1.092, ntokens=1920.6, nsentences=56, sample_size=1920.6, sample_size_v1=0, sample_size_v2=0, ppl=2.13, wps=1111.8, ups=0.58, wpb=1920.6, bsz=56, num_updates=15150, lr=1.39019e-06, gnorm=3.758, clip=100, loss_scale=64, train_wall=17, gb_free=12.5, wall=26120
2023-06-27 23:34:15 - progress_bar.py[line:272] - INFO: epoch 016:    338 / 990 loss=2.304, loss_v1=0, loss_v2=0, nll_loss=1.096, ntokens=1873.3, nsentences=56, sample_size=1873.3, sample_size_v1=0, sample_size_v2=0, ppl=2.14, wps=1088.4, ups=0.58, wpb=1873.3, bsz=56, num_updates=15160, lr=1.37005e-06, gnorm=4.149, clip=100, loss_scale=64, train_wall=17, gb_free=12.1, wall=26138
2023-06-27 23:34:32 - progress_bar.py[line:272] - INFO: epoch 016:    348 / 990 loss=2.3, loss_v1=0, loss_v2=0, nll_loss=1.092, ntokens=1887.5, nsentences=56, sample_size=1887.5, sample_size_v1=0, sample_size_v2=0, ppl=2.13, wps=1098.4, ups=0.58, wpb=1887.5, bsz=56, num_updates=15170, lr=1.3499e-06, gnorm=4.101, clip=100, loss_scale=64, train_wall=17, gb_free=12.2, wall=26155
2023-06-27 23:34:49 - progress_bar.py[line:272] - INFO: epoch 016:    358 / 990 loss=2.289, loss_v1=0, loss_v2=0, nll_loss=1.08, ntokens=1816.8, nsentences=56, sample_size=1816.8, sample_size_v1=0, sample_size_v2=0, ppl=2.11, wps=1060.7, ups=0.58, wpb=1816.8, bsz=56, num_updates=15180, lr=1.32975e-06, gnorm=4.224, clip=100, loss_scale=64, train_wall=17, gb_free=12.9, wall=26172
2023-06-27 23:35:06 - progress_bar.py[line:272] - INFO: epoch 016:    368 / 990 loss=2.326, loss_v1=0, loss_v2=0, nll_loss=1.119, ntokens=1709.4, nsentences=56, sample_size=1709.4, sample_size_v1=0, sample_size_v2=0, ppl=2.17, wps=1003.2, ups=0.59, wpb=1709.4, bsz=56, num_updates=15190, lr=1.3096e-06, gnorm=4.435, clip=100, loss_scale=64, train_wall=17, gb_free=12.5, wall=26189
2023-06-27 23:35:23 - progress_bar.py[line:272] - INFO: epoch 016:    378 / 990 loss=2.317, loss_v1=0, loss_v2=0, nll_loss=1.11, ntokens=1882.9, nsentences=56, sample_size=1882.9, sample_size_v1=0, sample_size_v2=0, ppl=2.16, wps=1103.4, ups=0.59, wpb=1882.9, bsz=56, num_updates=15200, lr=1.28946e-06, gnorm=4.012, clip=100, loss_scale=64, train_wall=17, gb_free=12.8, wall=26206
2023-06-27 23:35:40 - progress_bar.py[line:272] - INFO: epoch 016:    388 / 990 loss=2.28, loss_v1=0, loss_v2=0, nll_loss=1.07, ntokens=1828.9, nsentences=56, sample_size=1828.9, sample_size_v1=0, sample_size_v2=0, ppl=2.1, wps=1070.6, ups=0.59, wpb=1828.9, bsz=56, num_updates=15210, lr=1.26931e-06, gnorm=4.037, clip=100, loss_scale=64, train_wall=17, gb_free=12.1, wall=26223
2023-06-27 23:35:57 - progress_bar.py[line:272] - INFO: epoch 016:    398 / 990 loss=2.306, loss_v1=0, loss_v2=0, nll_loss=1.098, ntokens=1668.9, nsentences=56, sample_size=1668.9, sample_size_v1=0, sample_size_v2=0, ppl=2.14, wps=981.2, ups=0.59, wpb=1668.9, bsz=56, num_updates=15220, lr=1.24916e-06, gnorm=4.46, clip=100, loss_scale=64, train_wall=17, gb_free=12.9, wall=26240
2023-06-27 23:36:14 - progress_bar.py[line:272] - INFO: epoch 016:    408 / 990 loss=2.334, loss_v1=0, loss_v2=0, nll_loss=1.13, ntokens=1744.9, nsentences=56, sample_size=1744.9, sample_size_v1=0, sample_size_v2=0, ppl=2.19, wps=1026.1, ups=0.59, wpb=1744.9, bsz=56, num_updates=15230, lr=1.22901e-06, gnorm=4.511, clip=100, loss_scale=64, train_wall=17, gb_free=13.1, wall=26257
2023-06-27 23:36:31 - progress_bar.py[line:272] - INFO: epoch 016:    418 / 990 loss=2.311, loss_v1=0, loss_v2=0, nll_loss=1.104, ntokens=1737.8, nsentences=56, sample_size=1737.8, sample_size_v1=0, sample_size_v2=0, ppl=2.15, wps=1021.9, ups=0.59, wpb=1737.8, bsz=56, num_updates=15240, lr=1.20887e-06, gnorm=4.425, clip=100, loss_scale=64, train_wall=17, gb_free=12.8, wall=26274
2023-06-27 23:36:49 - progress_bar.py[line:272] - INFO: epoch 016:    428 / 990 loss=2.303, loss_v1=0, loss_v2=0, nll_loss=1.095, ntokens=1872, nsentences=56, sample_size=1872, sample_size_v1=0, sample_size_v2=0, ppl=2.14, wps=1093.6, ups=0.58, wpb=1872, bsz=56, num_updates=15250, lr=1.18872e-06, gnorm=4.185, clip=100, loss_scale=64, train_wall=17, gb_free=12.2, wall=26291
2023-06-27 23:37:06 - progress_bar.py[line:272] - INFO: epoch 016:    438 / 990 loss=2.299, loss_v1=0, loss_v2=0, nll_loss=1.091, ntokens=1860.7, nsentences=56, sample_size=1860.7, sample_size_v1=0, sample_size_v2=0, ppl=2.13, wps=1090, ups=0.59, wpb=1860.7, bsz=56, num_updates=15260, lr=1.16857e-06, gnorm=4.216, clip=100, loss_scale=64, train_wall=17, gb_free=12.9, wall=26308
2023-06-27 23:37:23 - progress_bar.py[line:272] - INFO: epoch 016:    448 / 990 loss=2.294, loss_v1=0, loss_v2=0, nll_loss=1.084, ntokens=1822.7, nsentences=56, sample_size=1822.7, sample_size_v1=0, sample_size_v2=0, ppl=2.12, wps=1069.9, ups=0.59, wpb=1822.7, bsz=56, num_updates=15270, lr=1.14842e-06, gnorm=4.193, clip=100, loss_scale=64, train_wall=17, gb_free=12.8, wall=26325
2023-06-27 23:37:40 - progress_bar.py[line:272] - INFO: epoch 016:    458 / 990 loss=2.314, loss_v1=0, loss_v2=0, nll_loss=1.106, ntokens=1786.2, nsentences=56, sample_size=1786.2, sample_size_v1=0, sample_size_v2=0, ppl=2.15, wps=1046.5, ups=0.59, wpb=1786.2, bsz=56, num_updates=15280, lr=1.12827e-06, gnorm=4.36, clip=100, loss_scale=64, train_wall=17, gb_free=12.3, wall=26342
2023-06-27 23:37:57 - progress_bar.py[line:272] - INFO: epoch 016:    468 / 990 loss=2.306, loss_v1=0, loss_v2=0, nll_loss=1.098, ntokens=1879.8, nsentences=56, sample_size=1879.8, sample_size_v1=0, sample_size_v2=0, ppl=2.14, wps=1095.8, ups=0.58, wpb=1879.8, bsz=56, num_updates=15290, lr=1.10813e-06, gnorm=4.089, clip=100, loss_scale=64, train_wall=17, gb_free=12.1, wall=26360
2023-06-27 23:38:14 - progress_bar.py[line:272] - INFO: epoch 016:    478 / 990 loss=2.292, loss_v1=0, loss_v2=0, nll_loss=1.082, ntokens=1826.4, nsentences=56, sample_size=1826.4, sample_size_v1=0, sample_size_v2=0, ppl=2.12, wps=1065, ups=0.58, wpb=1826.4, bsz=56, num_updates=15300, lr=1.08798e-06, gnorm=4.299, clip=100, loss_scale=64, train_wall=17, gb_free=12.4, wall=26377
2023-06-27 23:38:31 - progress_bar.py[line:272] - INFO: epoch 016:    488 / 990 loss=2.286, loss_v1=0, loss_v2=0, nll_loss=1.076, ntokens=1868.2, nsentences=56, sample_size=1868.2, sample_size_v1=0, sample_size_v2=0, ppl=2.11, wps=1091.8, ups=0.58, wpb=1868.2, bsz=56, num_updates=15310, lr=1.06783e-06, gnorm=3.99, clip=100, loss_scale=64, train_wall=17, gb_free=12.2, wall=26394
2023-06-27 23:38:48 - progress_bar.py[line:272] - INFO: epoch 016:    498 / 990 loss=2.31, loss_v1=0, loss_v2=0, nll_loss=1.103, ntokens=1855.6, nsentences=56, sample_size=1855.6, sample_size_v1=0, sample_size_v2=0, ppl=2.15, wps=1085.3, ups=0.58, wpb=1855.6, bsz=56, num_updates=15320, lr=1.04768e-06, gnorm=4.04, clip=100, loss_scale=64, train_wall=17, gb_free=12.5, wall=26411
2023-06-27 23:39:05 - progress_bar.py[line:272] - INFO: epoch 016:    508 / 990 loss=2.331, loss_v1=0, loss_v2=0, nll_loss=1.126, ntokens=1767.2, nsentences=56, sample_size=1767.2, sample_size_v1=0, sample_size_v2=0, ppl=2.18, wps=1032.2, ups=0.58, wpb=1767.2, bsz=56, num_updates=15330, lr=1.02754e-06, gnorm=4.287, clip=100, loss_scale=64, train_wall=17, gb_free=12.7, wall=26428
2023-06-27 23:39:22 - progress_bar.py[line:272] - INFO: epoch 016:    518 / 990 loss=2.303, loss_v1=0, loss_v2=0, nll_loss=1.094, ntokens=1767.4, nsentences=56, sample_size=1767.4, sample_size_v1=0, sample_size_v2=0, ppl=2.13, wps=1039.3, ups=0.59, wpb=1767.4, bsz=56, num_updates=15340, lr=1.00739e-06, gnorm=4.342, clip=100, loss_scale=64, train_wall=17, gb_free=12.9, wall=26445
2023-06-27 23:39:40 - progress_bar.py[line:272] - INFO: epoch 016:    528 / 990 loss=2.311, loss_v1=0, loss_v2=0, nll_loss=1.104, ntokens=1949.4, nsentences=56, sample_size=1949.4, sample_size_v1=0, sample_size_v2=0, ppl=2.15, wps=1131.3, ups=0.58, wpb=1949.4, bsz=56, num_updates=15350, lr=9.8724e-07, gnorm=3.698, clip=100, loss_scale=64, train_wall=17, gb_free=12.1, wall=26462
2023-06-27 23:39:57 - progress_bar.py[line:272] - INFO: epoch 016:    538 / 990 loss=2.307, loss_v1=0, loss_v2=0, nll_loss=1.1, ntokens=1887.4, nsentences=56, sample_size=1887.4, sample_size_v1=0, sample_size_v2=0, ppl=2.14, wps=1100.4, ups=0.58, wpb=1887.4, bsz=56, num_updates=15360, lr=9.67092e-07, gnorm=4.415, clip=100, loss_scale=64, train_wall=17, gb_free=12.7, wall=26480
2023-06-27 23:40:14 - progress_bar.py[line:272] - INFO: epoch 016:    548 / 990 loss=2.309, loss_v1=0, loss_v2=0, nll_loss=1.101, ntokens=1954.3, nsentences=56, sample_size=1954.3, sample_size_v1=0, sample_size_v2=0, ppl=2.15, wps=1140.1, ups=0.58, wpb=1954.3, bsz=56, num_updates=15370, lr=9.46944e-07, gnorm=3.969, clip=100, loss_scale=64, train_wall=17, gb_free=12.9, wall=26497
2023-06-27 23:40:31 - progress_bar.py[line:272] - INFO: epoch 016:    558 / 990 loss=2.295, loss_v1=0, loss_v2=0, nll_loss=1.086, ntokens=1736, nsentences=54.8, sample_size=1736, sample_size_v1=0, sample_size_v2=0, ppl=2.12, wps=1034.4, ups=0.6, wpb=1736, bsz=54.8, num_updates=15380, lr=9.26797e-07, gnorm=4.14, clip=100, loss_scale=64, train_wall=17, gb_free=13.2, wall=26513
2023-06-27 23:40:48 - progress_bar.py[line:272] - INFO: epoch 016:    568 / 990 loss=2.29, loss_v1=0, loss_v2=0, nll_loss=1.081, ntokens=1815.6, nsentences=56, sample_size=1815.6, sample_size_v1=0, sample_size_v2=0, ppl=2.11, wps=1060.5, ups=0.58, wpb=1815.6, bsz=56, num_updates=15390, lr=9.06649e-07, gnorm=4.008, clip=100, loss_scale=64, train_wall=17, gb_free=12.1, wall=26531
2023-06-27 23:41:05 - progress_bar.py[line:272] - INFO: epoch 016:    578 / 990 loss=2.316, loss_v1=0, loss_v2=0, nll_loss=1.11, ntokens=1839, nsentences=56, sample_size=1839, sample_size_v1=0, sample_size_v2=0, ppl=2.16, wps=1079.6, ups=0.59, wpb=1839, bsz=56, num_updates=15400, lr=8.86501e-07, gnorm=4.27, clip=100, loss_scale=64, train_wall=17, gb_free=12.7, wall=26548
2023-06-27 23:41:22 - progress_bar.py[line:272] - INFO: epoch 016:    588 / 990 loss=2.335, loss_v1=0, loss_v2=0, nll_loss=1.13, ntokens=1929.1, nsentences=56, sample_size=1929.1, sample_size_v1=0, sample_size_v2=0, ppl=2.19, wps=1125.2, ups=0.58, wpb=1929.1, bsz=56, num_updates=15410, lr=8.66353e-07, gnorm=3.852, clip=100, loss_scale=64, train_wall=17, gb_free=12.9, wall=26565
2023-06-27 23:41:39 - progress_bar.py[line:272] - INFO: epoch 016:    598 / 990 loss=2.301, loss_v1=0, loss_v2=0, nll_loss=1.093, ntokens=1837.1, nsentences=56, sample_size=1837.1, sample_size_v1=0, sample_size_v2=0, ppl=2.13, wps=1077.8, ups=0.59, wpb=1837.1, bsz=56, num_updates=15420, lr=8.46206e-07, gnorm=4.257, clip=100, loss_scale=64, train_wall=17, gb_free=13, wall=26582
2023-06-27 23:41:56 - progress_bar.py[line:272] - INFO: epoch 016:    608 / 990 loss=2.296, loss_v1=0, loss_v2=0, nll_loss=1.087, ntokens=1773, nsentences=56, sample_size=1773, sample_size_v1=0, sample_size_v2=0, ppl=2.12, wps=1044.7, ups=0.59, wpb=1773, bsz=56, num_updates=15430, lr=8.26058e-07, gnorm=4.066, clip=100, loss_scale=64, train_wall=17, gb_free=12.9, wall=26599
2023-06-27 23:42:13 - progress_bar.py[line:272] - INFO: epoch 016:    618 / 990 loss=2.313, loss_v1=0, loss_v2=0, nll_loss=1.107, ntokens=1894.8, nsentences=56, sample_size=1894.8, sample_size_v1=0, sample_size_v2=0, ppl=2.15, wps=1100, ups=0.58, wpb=1894.8, bsz=56, num_updates=15440, lr=8.0591e-07, gnorm=3.872, clip=100, loss_scale=64, train_wall=17, gb_free=12.9, wall=26616
2023-06-27 23:42:30 - progress_bar.py[line:272] - INFO: epoch 016:    628 / 990 loss=2.328, loss_v1=0, loss_v2=0, nll_loss=1.122, ntokens=2065.7, nsentences=56, sample_size=2065.7, sample_size_v1=0, sample_size_v2=0, ppl=2.18, wps=1205.1, ups=0.58, wpb=2065.7, bsz=56, num_updates=15450, lr=7.85762e-07, gnorm=3.679, clip=100, loss_scale=64, train_wall=17, gb_free=13, wall=26633
2023-06-27 23:42:48 - progress_bar.py[line:272] - INFO: epoch 016:    638 / 990 loss=2.307, loss_v1=0, loss_v2=0, nll_loss=1.098, ntokens=1985.8, nsentences=56, sample_size=1985.8, sample_size_v1=0, sample_size_v2=0, ppl=2.14, wps=1155.4, ups=0.58, wpb=1985.8, bsz=56, num_updates=15460, lr=7.65615e-07, gnorm=3.883, clip=100, loss_scale=128, train_wall=17, gb_free=11.9, wall=26650
2023-06-27 23:43:05 - progress_bar.py[line:272] - INFO: epoch 016:    648 / 990 loss=2.319, loss_v1=0, loss_v2=0, nll_loss=1.113, ntokens=1935.1, nsentences=56, sample_size=1935.1, sample_size_v1=0, sample_size_v2=0, ppl=2.16, wps=1129.2, ups=0.58, wpb=1935.1, bsz=56, num_updates=15470, lr=7.45467e-07, gnorm=4.098, clip=100, loss_scale=128, train_wall=17, gb_free=12.8, wall=26667
2023-06-27 23:43:22 - progress_bar.py[line:272] - INFO: epoch 016:    658 / 990 loss=2.302, loss_v1=0, loss_v2=0, nll_loss=1.094, ntokens=1915.7, nsentences=56, sample_size=1915.7, sample_size_v1=0, sample_size_v2=0, ppl=2.14, wps=1114.8, ups=0.58, wpb=1915.7, bsz=56, num_updates=15480, lr=7.25319e-07, gnorm=3.685, clip=100, loss_scale=128, train_wall=17, gb_free=12.3, wall=26685
2023-06-27 23:43:39 - progress_bar.py[line:272] - INFO: epoch 016:    668 / 990 loss=2.323, loss_v1=0, loss_v2=0, nll_loss=1.117, ntokens=1835.6, nsentences=56, sample_size=1835.6, sample_size_v1=0, sample_size_v2=0, ppl=2.17, wps=1073.5, ups=0.58, wpb=1835.6, bsz=56, num_updates=15490, lr=7.05171e-07, gnorm=4.004, clip=100, loss_scale=128, train_wall=17, gb_free=12, wall=26702
2023-06-27 23:43:56 - progress_bar.py[line:272] - INFO: epoch 016:    678 / 990 loss=2.286, loss_v1=0, loss_v2=0, nll_loss=1.076, ntokens=1856.5, nsentences=56, sample_size=1856.5, sample_size_v1=0, sample_size_v2=0, ppl=2.11, wps=1082.6, ups=0.58, wpb=1856.5, bsz=56, num_updates=15500, lr=6.85024e-07, gnorm=4.035, clip=100, loss_scale=128, train_wall=17, gb_free=12.8, wall=26719
2023-06-27 23:44:13 - progress_bar.py[line:272] - INFO: epoch 016:    688 / 990 loss=2.276, loss_v1=0, loss_v2=0, nll_loss=1.065, ntokens=1855.3, nsentences=56, sample_size=1855.3, sample_size_v1=0, sample_size_v2=0, ppl=2.09, wps=1083.9, ups=0.58, wpb=1855.3, bsz=56, num_updates=15510, lr=6.64876e-07, gnorm=3.622, clip=100, loss_scale=128, train_wall=17, gb_free=12.8, wall=26736
2023-06-27 23:44:30 - progress_bar.py[line:272] - INFO: epoch 016:    698 / 990 loss=2.314, loss_v1=0, loss_v2=0, nll_loss=1.107, ntokens=1720.6, nsentences=56, sample_size=1720.6, sample_size_v1=0, sample_size_v2=0, ppl=2.15, wps=1008.3, ups=0.59, wpb=1720.6, bsz=56, num_updates=15520, lr=6.44728e-07, gnorm=4.364, clip=100, loss_scale=128, train_wall=17, gb_free=12.9, wall=26753
2023-06-27 23:44:47 - progress_bar.py[line:272] - INFO: epoch 016:    708 / 990 loss=2.325, loss_v1=0, loss_v2=0, nll_loss=1.119, ntokens=1715.7, nsentences=56, sample_size=1715.7, sample_size_v1=0, sample_size_v2=0, ppl=2.17, wps=1009.7, ups=0.59, wpb=1715.7, bsz=56, num_updates=15530, lr=6.2458e-07, gnorm=4.171, clip=100, loss_scale=128, train_wall=17, gb_free=12.9, wall=26770
2023-06-27 23:45:04 - progress_bar.py[line:272] - INFO: epoch 016:    718 / 990 loss=2.298, loss_v1=0, loss_v2=0, nll_loss=1.089, ntokens=1776.8, nsentences=56, sample_size=1776.8, sample_size_v1=0, sample_size_v2=0, ppl=2.13, wps=1044.4, ups=0.59, wpb=1776.8, bsz=56, num_updates=15540, lr=6.04433e-07, gnorm=4.194, clip=100, loss_scale=128, train_wall=17, gb_free=12.7, wall=26787
2023-06-27 23:45:22 - progress_bar.py[line:272] - INFO: epoch 016:    728 / 990 loss=2.289, loss_v1=0, loss_v2=0, nll_loss=1.078, ntokens=1823.8, nsentences=56, sample_size=1823.8, sample_size_v1=0, sample_size_v2=0, ppl=2.11, wps=1068.8, ups=0.59, wpb=1823.8, bsz=56, num_updates=15550, lr=5.84285e-07, gnorm=4.045, clip=100, loss_scale=128, train_wall=17, gb_free=12.6, wall=26804
2023-06-27 23:45:39 - progress_bar.py[line:272] - INFO: epoch 016:    738 / 990 loss=2.304, loss_v1=0, loss_v2=0, nll_loss=1.096, ntokens=1831, nsentences=56, sample_size=1831, sample_size_v1=0, sample_size_v2=0, ppl=2.14, wps=1072, ups=0.59, wpb=1831, bsz=56, num_updates=15560, lr=5.64137e-07, gnorm=4.243, clip=100, loss_scale=128, train_wall=17, gb_free=12.8, wall=26821
2023-06-27 23:45:56 - progress_bar.py[line:272] - INFO: epoch 016:    748 / 990 loss=2.321, loss_v1=0, loss_v2=0, nll_loss=1.115, ntokens=1675.2, nsentences=56, sample_size=1675.2, sample_size_v1=0, sample_size_v2=0, ppl=2.17, wps=985.2, ups=0.59, wpb=1675.2, bsz=56, num_updates=15570, lr=5.43989e-07, gnorm=4.913, clip=100, loss_scale=128, train_wall=17, gb_free=12.5, wall=26838
2023-06-27 23:46:13 - progress_bar.py[line:272] - INFO: epoch 016:    758 / 990 loss=2.318, loss_v1=0, loss_v2=0, nll_loss=1.111, ntokens=1713.5, nsentences=56, sample_size=1713.5, sample_size_v1=0, sample_size_v2=0, ppl=2.16, wps=1006.5, ups=0.59, wpb=1713.5, bsz=56, num_updates=15580, lr=5.23842e-07, gnorm=4.543, clip=100, loss_scale=128, train_wall=17, gb_free=12.8, wall=26855
2023-06-27 23:46:30 - progress_bar.py[line:272] - INFO: epoch 016:    768 / 990 loss=2.311, loss_v1=0, loss_v2=0, nll_loss=1.103, ntokens=1792.1, nsentences=56, sample_size=1792.1, sample_size_v1=0, sample_size_v2=0, ppl=2.15, wps=1050.7, ups=0.59, wpb=1792.1, bsz=56, num_updates=15590, lr=5.03694e-07, gnorm=4.23, clip=100, loss_scale=128, train_wall=17, gb_free=12.7, wall=26872
2023-06-27 23:46:47 - progress_bar.py[line:272] - INFO: epoch 016:    778 / 990 loss=2.294, loss_v1=0, loss_v2=0, nll_loss=1.084, ntokens=1807.3, nsentences=56, sample_size=1807.3, sample_size_v1=0, sample_size_v2=0, ppl=2.12, wps=1055.7, ups=0.58, wpb=1807.3, bsz=56, num_updates=15600, lr=4.83546e-07, gnorm=4.55, clip=100, loss_scale=128, train_wall=17, gb_free=12.5, wall=26890
2023-06-27 23:47:04 - progress_bar.py[line:272] - INFO: epoch 016:    788 / 990 loss=2.308, loss_v1=0, loss_v2=0, nll_loss=1.101, ntokens=1757.2, nsentences=56, sample_size=1757.2, sample_size_v1=0, sample_size_v2=0, ppl=2.15, wps=1030.7, ups=0.59, wpb=1757.2, bsz=56, num_updates=15610, lr=4.63398e-07, gnorm=4.183, clip=100, loss_scale=128, train_wall=17, gb_free=11.7, wall=26907
2023-06-27 23:47:21 - progress_bar.py[line:272] - INFO: epoch 016:    798 / 990 loss=2.31, loss_v1=0, loss_v2=0, nll_loss=1.103, ntokens=1870.7, nsentences=56, sample_size=1870.7, sample_size_v1=0, sample_size_v2=0, ppl=2.15, wps=1095.5, ups=0.59, wpb=1870.7, bsz=56, num_updates=15620, lr=4.43251e-07, gnorm=4.108, clip=100, loss_scale=128, train_wall=17, gb_free=12.7, wall=26924
2023-06-27 23:47:38 - progress_bar.py[line:272] - INFO: epoch 016:    808 / 990 loss=2.316, loss_v1=0, loss_v2=0, nll_loss=1.109, ntokens=1742.4, nsentences=56, sample_size=1742.4, sample_size_v1=0, sample_size_v2=0, ppl=2.16, wps=1024.9, ups=0.59, wpb=1742.4, bsz=56, num_updates=15630, lr=4.23103e-07, gnorm=4.191, clip=100, loss_scale=128, train_wall=17, gb_free=12.6, wall=26941
2023-06-27 23:47:55 - progress_bar.py[line:272] - INFO: epoch 016:    818 / 990 loss=2.325, loss_v1=0, loss_v2=0, nll_loss=1.12, ntokens=1627.4, nsentences=56, sample_size=1627.4, sample_size_v1=0, sample_size_v2=0, ppl=2.17, wps=959.3, ups=0.59, wpb=1627.4, bsz=56, num_updates=15640, lr=4.02955e-07, gnorm=4.445, clip=100, loss_scale=128, train_wall=17, gb_free=13, wall=26958
2023-06-27 23:48:12 - progress_bar.py[line:272] - INFO: epoch 016:    828 / 990 loss=2.29, loss_v1=0, loss_v2=0, nll_loss=1.08, ntokens=1759.4, nsentences=56, sample_size=1759.4, sample_size_v1=0, sample_size_v2=0, ppl=2.11, wps=1033.7, ups=0.59, wpb=1759.4, bsz=56, num_updates=15650, lr=3.82807e-07, gnorm=4.158, clip=100, loss_scale=128, train_wall=17, gb_free=12.9, wall=26975
2023-06-27 23:48:29 - progress_bar.py[line:272] - INFO: epoch 016:    838 / 990 loss=2.285, loss_v1=0, loss_v2=0, nll_loss=1.075, ntokens=1772.1, nsentences=56, sample_size=1772.1, sample_size_v1=0, sample_size_v2=0, ppl=2.11, wps=1039.6, ups=0.59, wpb=1772.1, bsz=56, num_updates=15660, lr=3.6266e-07, gnorm=4.12, clip=100, loss_scale=128, train_wall=17, gb_free=12.3, wall=26992
2023-06-27 23:48:46 - progress_bar.py[line:272] - INFO: epoch 016:    848 / 990 loss=2.285, loss_v1=0, loss_v2=0, nll_loss=1.074, ntokens=1877.4, nsentences=56, sample_size=1877.4, sample_size_v1=0, sample_size_v2=0, ppl=2.11, wps=1099.3, ups=0.59, wpb=1877.4, bsz=56, num_updates=15670, lr=3.42512e-07, gnorm=4.29, clip=100, loss_scale=128, train_wall=17, gb_free=12.3, wall=27009
2023-06-27 23:49:03 - progress_bar.py[line:272] - INFO: epoch 016:    858 / 990 loss=2.274, loss_v1=0, loss_v2=0, nll_loss=1.062, ntokens=1855.8, nsentences=56, sample_size=1855.8, sample_size_v1=0, sample_size_v2=0, ppl=2.09, wps=1085.1, ups=0.58, wpb=1855.8, bsz=56, num_updates=15680, lr=3.22364e-07, gnorm=4.129, clip=100, loss_scale=128, train_wall=17, gb_free=13, wall=27026
2023-06-27 23:49:20 - progress_bar.py[line:272] - INFO: epoch 016:    868 / 990 loss=2.289, loss_v1=0, loss_v2=0, nll_loss=1.079, ntokens=1799.2, nsentences=56, sample_size=1799.2, sample_size_v1=0, sample_size_v2=0, ppl=2.11, wps=1052, ups=0.58, wpb=1799.2, bsz=56, num_updates=15690, lr=3.02216e-07, gnorm=4.037, clip=100, loss_scale=128, train_wall=17, gb_free=12.5, wall=27043
2023-06-27 23:49:37 - progress_bar.py[line:272] - INFO: epoch 016:    878 / 990 loss=2.281, loss_v1=0, loss_v2=0, nll_loss=1.071, ntokens=1880.8, nsentences=56, sample_size=1880.8, sample_size_v1=0, sample_size_v2=0, ppl=2.1, wps=1101.3, ups=0.59, wpb=1880.8, bsz=56, num_updates=15700, lr=2.82069e-07, gnorm=3.894, clip=100, loss_scale=128, train_wall=17, gb_free=12.5, wall=27060
2023-06-27 23:49:55 - progress_bar.py[line:272] - INFO: epoch 016:    888 / 990 loss=2.284, loss_v1=0, loss_v2=0, nll_loss=1.073, ntokens=1988.6, nsentences=56, sample_size=1988.6, sample_size_v1=0, sample_size_v2=0, ppl=2.1, wps=1160.8, ups=0.58, wpb=1988.6, bsz=56, num_updates=15710, lr=2.61921e-07, gnorm=3.838, clip=100, loss_scale=128, train_wall=17, gb_free=12.4, wall=27077
2023-06-27 23:50:12 - progress_bar.py[line:272] - INFO: epoch 016:    898 / 990 loss=2.302, loss_v1=0, loss_v2=0, nll_loss=1.093, ntokens=1813.1, nsentences=56, sample_size=1813.1, sample_size_v1=0, sample_size_v2=0, ppl=2.13, wps=1059.6, ups=0.58, wpb=1813.1, bsz=56, num_updates=15720, lr=2.41773e-07, gnorm=4.169, clip=100, loss_scale=128, train_wall=17, gb_free=12.9, wall=27094
2023-06-27 23:50:29 - progress_bar.py[line:272] - INFO: epoch 016:    908 / 990 loss=2.305, loss_v1=0, loss_v2=0, nll_loss=1.097, ntokens=1799.7, nsentences=56, sample_size=1799.7, sample_size_v1=0, sample_size_v2=0, ppl=2.14, wps=1057.1, ups=0.59, wpb=1799.7, bsz=56, num_updates=15730, lr=2.21625e-07, gnorm=4.372, clip=100, loss_scale=128, train_wall=17, gb_free=12.7, wall=27111
2023-06-27 23:50:46 - progress_bar.py[line:272] - INFO: epoch 016:    918 / 990 loss=2.3, loss_v1=0, loss_v2=0, nll_loss=1.091, ntokens=1706.5, nsentences=56, sample_size=1706.5, sample_size_v1=0, sample_size_v2=0, ppl=2.13, wps=1005.3, ups=0.59, wpb=1706.5, bsz=56, num_updates=15740, lr=2.01478e-07, gnorm=4.164, clip=100, loss_scale=128, train_wall=17, gb_free=12.1, wall=27128
2023-06-27 23:51:03 - progress_bar.py[line:272] - INFO: epoch 016:    928 / 990 loss=2.273, loss_v1=0, loss_v2=0, nll_loss=1.061, ntokens=1862.9, nsentences=56, sample_size=1862.9, sample_size_v1=0, sample_size_v2=0, ppl=2.09, wps=1084.7, ups=0.58, wpb=1862.9, bsz=56, num_updates=15750, lr=1.8133e-07, gnorm=4.266, clip=100, loss_scale=128, train_wall=17, gb_free=12.9, wall=27145
2023-06-27 23:51:20 - progress_bar.py[line:272] - INFO: epoch 016:    938 / 990 loss=2.285, loss_v1=0, loss_v2=0, nll_loss=1.074, ntokens=1793.1, nsentences=56, sample_size=1793.1, sample_size_v1=0, sample_size_v2=0, ppl=2.11, wps=1052.4, ups=0.59, wpb=1793.1, bsz=56, num_updates=15760, lr=1.61182e-07, gnorm=4.066, clip=100, loss_scale=128, train_wall=17, gb_free=12.9, wall=27163
2023-06-27 23:51:37 - progress_bar.py[line:272] - INFO: epoch 016:    948 / 990 loss=2.292, loss_v1=0, loss_v2=0, nll_loss=1.083, ntokens=1931.4, nsentences=56, sample_size=1931.4, sample_size_v1=0, sample_size_v2=0, ppl=2.12, wps=1122.4, ups=0.58, wpb=1931.4, bsz=56, num_updates=15770, lr=1.41034e-07, gnorm=3.871, clip=100, loss_scale=128, train_wall=17, gb_free=13.1, wall=27180
2023-06-27 23:51:54 - progress_bar.py[line:272] - INFO: epoch 016:    958 / 990 loss=2.294, loss_v1=0, loss_v2=0, nll_loss=1.084, ntokens=1880.2, nsentences=56, sample_size=1880.2, sample_size_v1=0, sample_size_v2=0, ppl=2.12, wps=1099.9, ups=0.58, wpb=1880.2, bsz=56, num_updates=15780, lr=1.20887e-07, gnorm=4.299, clip=100, loss_scale=128, train_wall=17, gb_free=13.1, wall=27197
2023-06-27 23:52:11 - progress_bar.py[line:272] - INFO: epoch 016:    968 / 990 loss=2.289, loss_v1=0, loss_v2=0, nll_loss=1.079, ntokens=1919.7, nsentences=56, sample_size=1919.7, sample_size_v1=0, sample_size_v2=0, ppl=2.11, wps=1116.8, ups=0.58, wpb=1919.7, bsz=56, num_updates=15790, lr=1.00739e-07, gnorm=3.799, clip=100, loss_scale=128, train_wall=17, gb_free=12.7, wall=27214
2023-06-27 23:52:29 - progress_bar.py[line:272] - INFO: epoch 016:    978 / 990 loss=2.29, loss_v1=0, loss_v2=0, nll_loss=1.081, ntokens=1868.9, nsentences=56, sample_size=1868.9, sample_size_v1=0, sample_size_v2=0, ppl=2.12, wps=1088.6, ups=0.58, wpb=1868.9, bsz=56, num_updates=15800, lr=8.0591e-08, gnorm=3.913, clip=100, loss_scale=128, train_wall=17, gb_free=12.9, wall=27231
2023-06-27 23:52:46 - progress_bar.py[line:272] - INFO: epoch 016:    988 / 990 loss=2.322, loss_v1=0, loss_v2=0, nll_loss=1.115, ntokens=1858.7, nsentences=56, sample_size=1858.7, sample_size_v1=0, sample_size_v2=0, ppl=2.17, wps=1089.3, ups=0.59, wpb=1858.7, bsz=56, num_updates=15810, lr=6.04433e-08, gnorm=4.072, clip=100, loss_scale=128, train_wall=17, gb_free=12.6, wall=27248
local datafile ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 1 begin to initialize row_count and line_idx-to-offset mapping
2023-06-27 23:52:48 - checkpoint_utils.py[line:64] - INFO: Preparing to save checkpoint for epoch 16 @ 15812 updates
2023-06-27 23:52:48 - trainer.py[line:431] - INFO: Saving checkpoint to ../../checkpoints/OFA/sgcls_checkpoints/_16_3e-5_512_base/checkpoint16.pt
local datafile ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 1 finished initializing row_count and line_idx-to-offset mapping
file ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 1 row count 27700 total row count 55400
slice_id 1 seek offset 27700
2023-06-27 23:53:06 - trainer.py[line:441] - INFO: Finished saving checkpoint to ../../checkpoints/OFA/sgcls_checkpoints/_16_3e-5_512_base/checkpoint16.pt
2023-06-27 23:53:11 - checkpoint_utils.py[line:133] - INFO: Saved checkpoint ../../checkpoints/OFA/sgcls_checkpoints/_16_3e-5_512_base/checkpoint16.pt (epoch 16 @ 15812 updates, score None) (writing took 22.613166416995227 seconds)
2023-06-27 23:53:11 - train.py[line:332] - INFO: end of epoch 16 (average epoch stats below)
2023-06-27 23:53:11 - progress_bar.py[line:282] - INFO: epoch 016 | loss 2.287 | loss_v1 0 | loss_v2 0 | nll_loss 1.076 | ntokens 1850.08 | nsentences 55.96 | sample_size 1850.08 | sample_size_v1 0 | sample_size_v2 0 | ppl 2.11 | wps 1061.9 | ups 0.57 | wpb 1850.1 | bsz 56 | num_updates 15812 | lr 5.64137e-08 | gnorm 4.115 | clip 100 | loss_scale 128 | train_wall 1695 | gb_free 13.3 | wall 27273
2023-06-27 23:53:11 - trainer.py[line:639] - INFO: loading train data for epoch 17
local datafile ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 0 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 0 finished initializing row_count and line_idx-to-offset mapping
file ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 0 row count 27700 total row count 55400
slice_id 0 seek offset 0
2023-06-27 23:53:13 - train.py[line:214] - INFO: done training in 27273.5 seconds
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                  train/bsz ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:                 train/clip ██▆▁████████████
wandb:              train/gb_free ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:                train/gnorm █▁▁▂▂▃▃▄▄▅▆▆▇▇██
wandb:                 train/loss █▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:           train/loss_scale ▁█████▃▃▃▃▃▃▁▃▁▃
wandb:              train/loss_v1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:              train/loss_v2 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:                   train/lr ██▇▇▆▆▅▅▄▄▃▃▂▂▁▁
wandb:             train/nll_loss █▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:           train/nsentences ████████████▁███
wandb:              train/ntokens ▄▅▄▃▃▄▄▄▇▅▆▅▂█▁▆
wandb:                  train/ppl █▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:          train/sample_size ▄▅▄▃▃▄▄▄▇▅▆▅▂█▁▆
wandb:       train/sample_size_v1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/sample_size_v2 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:           train/train_wall █▂▂▄▂▄▂▂▁█▇▂▁▁▂▂
wandb:                  train/ups ███████████████▁
wandb:                 train/wall ▁▁▂▂▃▃▄▄▅▅▆▆▇▇██
wandb:                  train/wpb ▅▅▅▄▃▄▄▄▆▅▅▅▂█▁▆
wandb:                  train/wps ██▇▃▇▇▇▅▇▆▆▅▇█▇▁
wandb:            train_inner/bsz ███████████████████████████▁████████████
wandb:           train_inner/clip ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:        train_inner/gb_free ▄▁▇▆▇▆▅▅▆▆▆▆▆▃█▄▄▆▃▇▂▆▆▇▆▆▇▂█▅▃▅▇▃█▃▆▅▆▇
wandb:          train_inner/gnorm █▂▂▁▁▁▁▁▁▂▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▅▅▄▅▄▅▅▅▆▅▅▆▆▆
wandb:           train_inner/loss █▃▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     train_inner/loss_scale ▁▁▂▄████████████▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▂▂▄▄▂▄▂▂▄
wandb:        train_inner/loss_v1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:        train_inner/loss_v2 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:             train_inner/lr ▂▅▇███▇▇▇▇▇▆▆▆▆▆▆▅▅▅▅▅▄▄▄▄▄▃▃▃▃▃▂▂▂▂▂▁▁▁
wandb:       train_inner/nll_loss █▃▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     train_inner/nsentences ███████████████████████████▁████████████
wandb:        train_inner/ntokens █▅▄▅▅▆▃▃▃▄█▆▆▆▅▇▆▇▇▃█▅▇▆▂▃▄▄▆▃██▆▇▁▇▄▃▆▅
wandb:            train_inner/ppl █▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:    train_inner/sample_size █▅▄▅▅▆▃▃▃▄█▆▆▆▅▇▆▇▇▃█▅▇▆▂▃▄▄▆▃██▆▇▁▇▄▃▆▅
wandb: train_inner/sample_size_v1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: train_inner/sample_size_v2 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     train_inner/train_wall ███████████████████████████▁████████████
wandb:            train_inner/ups ▆▆▇▇█▇██▇█▆▇▇▇▇▆▇▇▇█▆█▇▇███▁▇█▆▇▇▇█▇█▇█▇
wandb:           train_inner/wall ▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███
wandb:            train_inner/wpb █▅▄▅▅▆▃▃▃▄█▆▆▆▅▇▆▇▇▃█▅▇▆▂▃▄▄▆▃██▆▇▁▇▄▃▆▅
wandb:            train_inner/wps ▇▄▄▅▅▅▃▃▃▄▇▆▆▅▅▇▅▇▆▃▇▅▇▆▃▃▄▁▆▃▇█▆▇▁▆▄▃▆▅
wandb: 
wandb: Run summary:
wandb:                  train/bsz 56.0
wandb:                 train/clip 100.0
wandb:              train/gb_free 13.3
wandb:                train/gnorm 4.115
wandb:                 train/loss 2.287
wandb:           train/loss_scale 128.0
wandb:              train/loss_v1 0.0
wandb:              train/loss_v2 0.0
wandb:                   train/lr 0.0
wandb:             train/nll_loss 1.076
wandb:           train/nsentences 55.96
wandb:              train/ntokens 1850.075
wandb:                  train/ppl 2.11
wandb:          train/sample_size 1850.075
wandb:       train/sample_size_v1 0.0
wandb:       train/sample_size_v2 0.0
wandb:           train/train_wall 1695.0
wandb:                  train/ups 0.57
wandb:                 train/wall 27273.0
wandb:                  train/wpb 1850.1
wandb:                  train/wps 1061.9
wandb:            train_inner/bsz 56.0
wandb:           train_inner/clip 100.0
wandb:        train_inner/gb_free 12.6
wandb:          train_inner/gnorm 4.072
wandb:           train_inner/loss 2.322
wandb:     train_inner/loss_scale 128.0
wandb:        train_inner/loss_v1 0.0
wandb:        train_inner/loss_v2 0.0
wandb:             train_inner/lr 0.0
wandb:       train_inner/nll_loss 1.115
wandb:     train_inner/nsentences 56.0
wandb:        train_inner/ntokens 1858.7
wandb:            train_inner/ppl 2.17
wandb:    train_inner/sample_size 1858.7
wandb: train_inner/sample_size_v1 0.0
wandb: train_inner/sample_size_v2 0.0
wandb:     train_inner/train_wall 17.0
wandb:            train_inner/ups 0.59
wandb:           train_inner/wall 27248.0
wandb:            train_inner/wpb 1858.7
wandb:            train_inner/wps 1089.3
wandb: 
wandb: 🚀 View run _16_3e-5_512_base at: https://wandb.ai/jackcai1206/OFA-VG/runs/egphhs3z
wandb: Synced 6 W&B file(s), 0 media file(s), 2 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230627_161840-egphhs3z/logs

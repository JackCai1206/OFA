2023-05-20 17:57:15 - utils.py[line:255] - INFO: distributed init (rank 0): env://
2023-05-20 17:57:15 - utils.py[line:261] - INFO: Start init
2023-05-20 17:57:15 - distributed_c10d.py[line:228] - INFO: Added key: store_based_barrier_key:1 to store for rank: 0
2023-05-20 17:57:15 - distributed_c10d.py[line:262] - INFO: Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 1 nodes.
2023-05-20 17:57:15 - utils.py[line:271] - INFO: initialized host AMD4RTX3090GPU14 as rank 0
single-machine distributed training is initialized.
2023-05-20 17:57:16 - train.py[line:77] - INFO: {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 10, 'log_format': 'simple', 'log_file': None, 'tensorboard_logdir': './tensorboard/_30_1e-5_480', 'wandb_project': 'OFA-VG', 'azureml_logging': False, 'seed': 1, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': True, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': 512, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': '../../ofa_module', 'empty_cache_freq': 0, 'all_gather_list_size': 2097152, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': 'env://', 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': True, 'ddp_backend': 'pytorch_ddp', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': True, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_algorithm': 'LocalSGD', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': True, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False}, 'dataset': {'_name': None, 'num_workers': 0, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': None, 'batch_size': 4, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 30, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': 7, 'disable_validation': False, 'max_tokens_valid': None, 'batch_size_valid': 4, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0}, 'optimization': {'_name': None, 'max_epoch': 30, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 1.0, 'sentence_avg': False, 'update_freq': [8], 'lr': [1e-05], 'stop_min_lr': -1.0, 'use_bmuf': False}, 'checkpoint': {'_name': None, 'save_dir': '../../checkpoints/OFA/sgcls_checkpoints/_30_1e-5_480', 'restore_file': '../../checkpoints/ofa_large.pt', 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 10, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': 1, 'no_save': False, 'no_epoch_checkpoints': False, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': True, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1, 'use_ema_weights_to_init_param': False, 'use_latest_weights_to_init_ema': False}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': Namespace(_name='ofa_large', activation_fn='gelu', adam_betas='(0.9,0.999)', adam_eps=1e-08, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, add_type_embedding=True, all_gather_list_size=2097152, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, arch='ofa_large', attention_dropout=0.0, attn_scale_factor=2, azureml_logging=False, batch_size=4, batch_size_valid=4, best_checkpoint_metric='loss', bf16=False, bitfit=False, bpe=None, bpe_dir='../../utils/BPE', broadcast_buffers=False, bucket_cap_mb=25, checkpoint_shard_count=1, checkpoint_suffix='', clip_norm=1.0, code_dict_size=8192, code_image_size=128, code_layernorm_embedding=True, combine_valid_subsets=None, constraint_range=None, cpu=False, cpu_offload=False, criterion='adjust_label_smoothed_cross_entropy', cross_self_attention=False, curriculum=0, data='../../dataset/OFA_data/sgcls/vg_train_full.tsv,../../dataset/OFA_data/sgcls/vg_val_full.tsv', data_buffer_size=10, dataset_impl=None, ddp_backend='pytorch_ddp', ddp_comm_hook='none', decoder_attention_heads=16, decoder_drop_path_rate=0.1, decoder_embed_dim=1024, decoder_embed_path=None, decoder_ffn_embed_dim=4096, decoder_input_dim=1024, decoder_layerdrop=0, decoder_layers=12, decoder_layers_to_keep=None, decoder_learned_pos=True, decoder_normalize_before=True, decoder_output_dim=1024, device_id=0, disable_entangle=True, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_num_procs=1, distributed_port=-1, distributed_rank=0, distributed_world_size=1, drop_worst_after=0, drop_worst_ratio=0.0, dropout=0.1, ema_decay=0.9999, ema_fp32=False, ema_seed_model=None, ema_start_update=0, ema_update_freq=1, empty_cache_freq=0, encoder_attention_heads=16, encoder_drop_path_rate=0.1, encoder_embed_dim=1024, encoder_embed_path=None, encoder_ffn_embed_dim=4096, encoder_layerdrop=0, encoder_layers=12, encoder_layers_to_keep=None, encoder_learned_pos=True, encoder_normalize_before=True, end_learning_rate=0.0, entangle_position_embedding=False, eos=2, eval_args='{"beam":5,"max_len_a":0,"max_len_b":200}', eval_print_samples=False, fast_stat_sync=False, find_unused_parameters=True, finetune_from_model=None, fix_batches_to_gpus=False, fixed_validation_seed=7, force_anneal=None, fp16=True, fp16_adam_stats=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=512, fp32_reduce_scatter=False, freeze_decoder_embedding=False, freeze_encoder_embedding=False, gen_subset='test', gradient_as_bucket_view=False, heartbeat_timeout=-1, ignore_eos=False, ignore_prefix_size=0, ignore_unused_valid_subsets=False, image_bucket_size=42, imagenet_default_mean_and_std=False, keep_best_checkpoints=1, keep_interval_updates=-1, keep_interval_updates_pattern=-1, keep_last_epochs=-1, label_smoothing=0.1, layernorm_embedding=True, load_checkpoint_on_all_dp_ranks=False, localsgd_frequency=3, log_file=None, log_format='simple', log_interval=10, lr=[1e-05], lr_scheduler='polynomial_decay', max_epoch=30, max_source_positions=1024, max_src_length=100, max_target_positions=1024, max_tgt_length=100, max_tokens=None, max_tokens_valid=None, max_update=0, max_valid_steps=None, maximize_best_checkpoint_metric=True, memory_efficient_bf16=False, memory_efficient_fp16=True, min_loss_scale=0.0001, min_params_to_wrap=100000000, model_parallel_size=1, no_cross_attention=False, no_epoch_checkpoints=False, no_last_checkpoints=False, no_progress_bar=False, no_reshard_after_forward=False, no_save=False, no_save_optimizer_state=False, no_scale_embedding=True, no_seed_provided=False, no_token_positional_embeddings=False, nprocs_per_node=1, num_bins=1000, num_shards=1, num_workers=0, on_cpu_convert_precision=False, optimizer='adam', optimizer_overrides='{}', orig_patch_image_size=256, pad=1, patch_image_size=480, patch_layernorm_embedding=True, patience=-1, pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, plasma_path='/tmp/plasma', pooler_activation_fn='tanh', pooler_classifier='mlp', pooler_dropout=0.0, power=1.0, profile=False, quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, quantization_config_path=None, reg_alpha=1.0, relu_dropout=0.0, report_accuracy=False, required_batch_size_multiple=8, required_seq_len_multiple=1, reset_dataloader=False, reset_logging=False, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, resnet_drop_path_rate=0.0, resnet_type='resnet152', restore_file='../../checkpoints/ofa_large.pt', sample_patch_num=196, save_dir='../../checkpoints/OFA/sgcls_checkpoints/_30_1e-5_480', save_interval=10, save_interval_updates=0, scale_attn=True, scale_fc=True, scale_heads=True, scale_resids=False, scoring='bleu', seed=1, selected_cols=None, sentence_avg=False, shard_id=0, share_all_embeddings=True, share_decoder_input_output_embed=True, simul_type=None, skip_invalid_size_inputs_valid_test=False, slowmo_algorithm='LocalSGD', slowmo_momentum=None, stop_min_lr=-1.0, stop_time_hours=0, store_ema=False, suppress_crashes=False, sync_bn=False, task='sgcls', tensorboard_logdir='./tensorboard/_30_1e-5_480', threshold_loss_scale=None, token_bucket_size=256, tokenizer=None, total_num_update=1000000, tpu=False, train_subset='train', unk=3, update_freq=[8], use_bmuf=False, use_ema_weights_to_init_param=False, use_latest_weights_to_init_ema=False, use_old_adam=False, use_plasma_view=False, use_rdrop=False, use_sharded_state=False, user_dir='../../ofa_module', valid_subset='valid', validate_after_updates=0, validate_interval=30, validate_interval_updates=0, vg_json_dir=None, wandb_project='OFA-VG', warmup_ratio=0.06, warmup_updates=0, weight_decay=0.01, write_checkpoints_asynchronously=False, zero_sharding='none'), 'task': {'_name': 'sgcls', 'data': '../../dataset/OFA_data/sgcls/vg_train_full.tsv,../../dataset/OFA_data/sgcls/vg_val_full.tsv', 'selected_cols': None, 'bpe': None, 'bpe_dir': '../../utils/BPE', 'max_source_positions': 1024, 'max_target_positions': 1024, 'max_src_length': 100, 'max_tgt_length': 100, 'code_dict_size': 8192, 'patch_image_size': 480, 'orig_patch_image_size': 256, 'num_bins': 1000, 'imagenet_default_mean_and_std': False, 'constraint_range': None, 'eval_args': '{"beam":5,"max_len_a":0,"max_len_b":200}', 'eval_print_samples': False, 'vg_json_dir': None}, 'criterion': {'_name': 'adjust_label_smoothed_cross_entropy', 'label_smoothing': 0.1, 'report_accuracy': False, 'ignore_prefix_size': 0, 'ignore_eos': False, 'sentence_avg': False, 'drop_worst_ratio': 0.0, 'drop_worst_after': 0, 'use_rdrop': False, 'reg_alpha': 1.0, 'sample_patch_num': 196, 'constraint_range': None}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9,0.999)', 'adam_eps': 1e-08, 'weight_decay': 0.01, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': False, 'lr': [1e-05]}, 'lr_scheduler': {'_name': 'polynomial_decay', 'warmup_updates': 0, 'warmup_ratio': 0.06, 'force_anneal': None, 'end_learning_rate': 0.0, 'power': 1.0, 'total_num_update': 1000000.0, 'lr': [1e-05]}, 'scoring': {'_name': 'bleu', 'pad': 1, 'eos': 2, 'unk': 3}, 'bpe': None, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}, 'simul_type': None}
2023-05-20 17:57:16 - sg_cls.py[line:82] - INFO: sgcls setup: source dictionary: 51267 types
2023-05-20 17:57:16 - sg_cls.py[line:83] - INFO: sgcls setup: target dictionary: 51267 types
/data/hulab/zcai75/anaconda3/envs/vilt/lib/python3.8/site-packages/torch/functional.py:478: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at  ../aten/src/ATen/native/TensorShape.cpp:2894.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
2023-05-20 17:57:22 - train.py[line:110] - INFO: OFAModel(
  (encoder): TransformerEncoder(
    (encoder_dropout): Dropout(p=0.2, inplace=False)
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(51267, 1024, padding_idx=1)
    (layernorm_embedding): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (type_embedding): Embedding(2, 1024)
    (embed_images): ResNet(
      (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)
      (layer1): Sequential(
        (0): Bottleneck(
          (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (downsample): Sequential(
            (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (drop_path): Identity()
        )
        (1): Bottleneck(
          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (2): Bottleneck(
          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
      )
      (layer2): Sequential(
        (0): Bottleneck(
          (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (downsample): Sequential(
            (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
            (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (drop_path): Identity()
        )
        (1): Bottleneck(
          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (2): Bottleneck(
          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (3): Bottleneck(
          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (4): Bottleneck(
          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (5): Bottleneck(
          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (6): Bottleneck(
          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (7): Bottleneck(
          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
      )
      (layer3): Sequential(
        (0): Bottleneck(
          (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (downsample): Sequential(
            (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)
            (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (drop_path): Identity()
        )
        (1): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (2): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (3): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (4): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (5): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (6): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (7): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (8): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (9): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (10): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (11): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (12): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (13): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (14): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (15): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (16): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (17): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (18): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (19): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (20): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (21): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (22): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (23): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (24): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (25): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (26): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (27): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (28): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (29): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (30): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (31): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (32): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (33): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (34): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (35): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
      )
    )
    (image_proj): Linear(in_features=1024, out_features=1024, bias=True)
    (patch_layernorm_embedding): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (embed_positions): Embedding(1026, 1024)
    (embed_image_positions): Embedding(1765, 1024)
    (pos_ln): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (image_pos_ln): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (pos_q_linear): Linear(in_features=1024, out_features=1024, bias=True)
    (pos_k_linear): Linear(in_features=1024, out_features=1024, bias=True)
    (layers): ModuleList(
      (0): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=1024, out_features=4096, bias=True)
        (fc2): Linear(in_features=4096, out_features=1024, bias=True)
        (attn_ln): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)
        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (drop_path): Identity()
      )
      (1): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=1024, out_features=4096, bias=True)
        (fc2): Linear(in_features=4096, out_features=1024, bias=True)
        (attn_ln): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)
        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(p=0.00909090880304575)
      )
      (2): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=1024, out_features=4096, bias=True)
        (fc2): Linear(in_features=4096, out_features=1024, bias=True)
        (attn_ln): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)
        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(p=0.0181818176060915)
      )
      (3): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=1024, out_features=4096, bias=True)
        (fc2): Linear(in_features=4096, out_features=1024, bias=True)
        (attn_ln): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)
        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(p=0.027272727340459824)
      )
      (4): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=1024, out_features=4096, bias=True)
        (fc2): Linear(in_features=4096, out_features=1024, bias=True)
        (attn_ln): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)
        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(p=0.036363635212183)
      )
      (5): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=1024, out_features=4096, bias=True)
        (fc2): Linear(in_features=4096, out_features=1024, bias=True)
        (attn_ln): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)
        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(p=0.045454543083906174)
      )
      (6): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=1024, out_features=4096, bias=True)
        (fc2): Linear(in_features=4096, out_features=1024, bias=True)
        (attn_ln): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)
        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(p=0.054545458406209946)
      )
      (7): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=1024, out_features=4096, bias=True)
        (fc2): Linear(in_features=4096, out_features=1024, bias=True)
        (attn_ln): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)
        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(p=0.06363636255264282)
      )
      (8): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=1024, out_features=4096, bias=True)
        (fc2): Linear(in_features=4096, out_features=1024, bias=True)
        (attn_ln): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)
        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(p=0.0727272778749466)
      )
      (9): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=1024, out_features=4096, bias=True)
        (fc2): Linear(in_features=4096, out_features=1024, bias=True)
        (attn_ln): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)
        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(p=0.08181818574666977)
      )
      (10): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=1024, out_features=4096, bias=True)
        (fc2): Linear(in_features=4096, out_features=1024, bias=True)
        (attn_ln): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)
        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(p=0.09090909361839294)
      )
      (11): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=1024, out_features=4096, bias=True)
        (fc2): Linear(in_features=4096, out_features=1024, bias=True)
        (attn_ln): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)
        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(p=0.10000000149011612)
      )
    )
    (layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (token_rel_pos_table_list): ModuleList(
      (0): Embedding(511, 16)
      (1): Embedding(511, 16)
      (2): Embedding(511, 16)
      (3): Embedding(511, 16)
      (4): Embedding(511, 16)
      (5): Embedding(511, 16)
      (6): Embedding(511, 16)
      (7): Embedding(511, 16)
      (8): Embedding(511, 16)
      (9): Embedding(511, 16)
      (10): Embedding(511, 16)
      (11): Embedding(511, 16)
    )
    (image_rel_pos_table_list): ModuleList(
      (0): Embedding(6892, 16)
      (1): Embedding(6892, 16)
      (2): Embedding(6892, 16)
      (3): Embedding(6892, 16)
      (4): Embedding(6892, 16)
      (5): Embedding(6892, 16)
      (6): Embedding(6892, 16)
      (7): Embedding(6892, 16)
      (8): Embedding(6892, 16)
      (9): Embedding(6892, 16)
      (10): Embedding(6892, 16)
      (11): Embedding(6892, 16)
    )
  )
  (decoder): TransformerDecoder(
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(51267, 1024, padding_idx=1)
    (layernorm_embedding): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (embed_positions): Embedding(1026, 1024)
    (embed_image_positions): Embedding(1765, 1024)
    (pos_ln): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (image_pos_ln): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (self_pos_q_linear): Linear(in_features=1024, out_features=1024, bias=True)
    (self_pos_k_linear): Linear(in_features=1024, out_features=1024, bias=True)
    (cross_pos_q_linear): Linear(in_features=1024, out_features=1024, bias=True)
    (cross_pos_k_linear): Linear(in_features=1024, out_features=1024, bias=True)
    (code_layernorm_embedding): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (layers): ModuleList(
      (0): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)
        )
        (self_attn_ln): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (cross_attn_ln): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=1024, out_features=4096, bias=True)
        (fc2): Linear(in_features=4096, out_features=1024, bias=True)
        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (drop_path): Identity()
      )
      (1): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)
        )
        (self_attn_ln): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (cross_attn_ln): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=1024, out_features=4096, bias=True)
        (fc2): Linear(in_features=4096, out_features=1024, bias=True)
        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(p=0.00909090880304575)
      )
      (2): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)
        )
        (self_attn_ln): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (cross_attn_ln): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=1024, out_features=4096, bias=True)
        (fc2): Linear(in_features=4096, out_features=1024, bias=True)
        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(p=0.0181818176060915)
      )
      (3): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)
        )
        (self_attn_ln): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (cross_attn_ln): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=1024, out_features=4096, bias=True)
        (fc2): Linear(in_features=4096, out_features=1024, bias=True)
        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(p=0.027272727340459824)
      )
      (4): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)
        )
        (self_attn_ln): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (cross_attn_ln): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=1024, out_features=4096, bias=True)
        (fc2): Linear(in_features=4096, out_features=1024, bias=True)
        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(p=0.036363635212183)
      )
      (5): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)
        )
        (self_attn_ln): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (cross_attn_ln): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=1024, out_features=4096, bias=True)
        (fc2): Linear(in_features=4096, out_features=1024, bias=True)
        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(p=0.045454543083906174)
      )
      (6): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)
        )
        (self_attn_ln): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (cross_attn_ln): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=1024, out_features=4096, bias=True)
        (fc2): Linear(in_features=4096, out_features=1024, bias=True)
        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(p=0.054545458406209946)
      )
      (7): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)
        )
        (self_attn_ln): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (cross_attn_ln): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=1024, out_features=4096, bias=True)
        (fc2): Linear(in_features=4096, out_features=1024, bias=True)
        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(p=0.06363636255264282)
      )
      (8): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)
        )
        (self_attn_ln): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (cross_attn_ln): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=1024, out_features=4096, bias=True)
        (fc2): Linear(in_features=4096, out_features=1024, bias=True)
        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(p=0.0727272778749466)
      )
      (9): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)
        )
        (self_attn_ln): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (cross_attn_ln): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=1024, out_features=4096, bias=True)
        (fc2): Linear(in_features=4096, out_features=1024, bias=True)
        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(p=0.08181818574666977)
      )
      (10): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)
        )
        (self_attn_ln): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (cross_attn_ln): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=1024, out_features=4096, bias=True)
        (fc2): Linear(in_features=4096, out_features=1024, bias=True)
        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(p=0.09090909361839294)
      )
      (11): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)
        )
        (self_attn_ln): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (cross_attn_ln): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=1024, out_features=4096, bias=True)
        (fc2): Linear(in_features=4096, out_features=1024, bias=True)
        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(p=0.10000000149011612)
      )
    )
    (layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (output_projection): Linear(in_features=1024, out_features=51267, bias=False)
    (token_rel_pos_table_list): ModuleList(
      (0): Embedding(511, 16)
      (1): Embedding(511, 16)
      (2): Embedding(511, 16)
      (3): Embedding(511, 16)
      (4): Embedding(511, 16)
      (5): Embedding(511, 16)
      (6): Embedding(511, 16)
      (7): Embedding(511, 16)
      (8): Embedding(511, 16)
      (9): Embedding(511, 16)
      (10): Embedding(511, 16)
      (11): Embedding(511, 16)
    )
    (image_rel_pos_table_list): ModuleList(
      (0): Embedding(6892, 16)
      (1): Embedding(6892, 16)
      (2): Embedding(6892, 16)
      (3): Embedding(6892, 16)
      (4): Embedding(6892, 16)
      (5): Embedding(6892, 16)
      (6): Embedding(6892, 16)
      (7): Embedding(6892, 16)
      (8): Embedding(6892, 16)
      (9): Embedding(6892, 16)
      (10): Embedding(6892, 16)
      (11): Embedding(6892, 16)
    )
  )
  (classification_heads): ModuleDict()
)
2023-05-20 17:57:22 - train.py[line:111] - INFO: task: SGClsTask
2023-05-20 17:57:22 - train.py[line:112] - INFO: model: OFAModel
2023-05-20 17:57:22 - train.py[line:113] - INFO: criterion: AdjustLabelSmoothedCrossEntropyCriterion
2023-05-20 17:57:22 - train.py[line:114] - INFO: num. shared model params: 464,590,592 (num. trained: 464,590,592)
2023-05-20 17:57:22 - train.py[line:121] - INFO: num. expert model params: 0 (num. trained: 0)
local datafile ../../dataset/OFA_data/sgcls/vg_val_full.tsv slice_id 0 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../dataset/OFA_data/sgcls/vg_val_full.tsv slice_id 0 finished initializing row_count and line_idx-to-offset mapping
file ../../dataset/OFA_data/sgcls/vg_val_full.tsv slice_id 0 row count 22880 total row count 22880
/data/hulab/zcai75/anaconda3/envs/vilt/lib/python3.8/site-packages/torchvision/transforms/transforms.py:332: UserWarning: Argument 'interpolation' of type int is deprecated since 0.13 and will be removed in 0.15. Please use InterpolationMode enum.
  warnings.warn(
2023-05-20 17:57:23 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_tokens.weight <- decoder.embed_tokens.weight
2023-05-20 17:57:23 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_tokens.weight <- decoder.output_projection.weight
2023-05-20 17:57:23 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer1.0.conv1.bias
2023-05-20 17:57:23 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer1.0.conv2.bias
2023-05-20 17:57:23 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer1.0.conv3.bias
2023-05-20 17:57:23 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer1.0.downsample.0.bias
2023-05-20 17:57:23 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer1.1.conv1.bias
2023-05-20 17:57:23 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer1.1.conv2.bias
2023-05-20 17:57:23 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer1.1.conv3.bias
2023-05-20 17:57:23 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer1.2.conv1.bias
2023-05-20 17:57:23 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer1.2.conv2.bias
2023-05-20 17:57:23 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer1.2.conv3.bias
2023-05-20 17:57:23 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.0.conv1.bias
2023-05-20 17:57:23 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.0.conv2.bias
2023-05-20 17:57:23 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.0.conv3.bias
2023-05-20 17:57:23 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.0.downsample.0.bias
2023-05-20 17:57:23 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.1.conv1.bias
2023-05-20 17:57:23 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.1.conv2.bias
2023-05-20 17:57:23 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.1.conv3.bias
2023-05-20 17:57:23 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.2.conv1.bias
2023-05-20 17:57:23 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.2.conv2.bias
2023-05-20 17:57:23 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.2.conv3.bias
2023-05-20 17:57:23 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.3.conv1.bias
2023-05-20 17:57:23 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.3.conv2.bias
2023-05-20 17:57:23 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.3.conv3.bias
2023-05-20 17:57:23 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.4.conv1.bias
2023-05-20 17:57:23 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.4.conv2.bias
2023-05-20 17:57:23 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.4.conv3.bias
2023-05-20 17:57:23 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.5.conv1.bias
2023-05-20 17:57:23 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.5.conv2.bias
2023-05-20 17:57:23 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.5.conv3.bias
2023-05-20 17:57:23 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.6.conv1.bias
2023-05-20 17:57:23 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.6.conv2.bias
2023-05-20 17:57:23 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.6.conv3.bias
2023-05-20 17:57:23 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.7.conv1.bias
2023-05-20 17:57:23 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.7.conv2.bias
2023-05-20 17:57:23 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.7.conv3.bias
2023-05-20 17:57:23 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.0.conv1.bias
2023-05-20 17:57:23 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.0.conv2.bias
2023-05-20 17:57:23 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.0.conv3.bias
2023-05-20 17:57:23 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.0.downsample.0.bias
2023-05-20 17:57:23 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.1.conv1.bias
2023-05-20 17:57:23 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.1.conv2.bias
2023-05-20 17:57:23 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.1.conv3.bias
2023-05-20 17:57:23 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.2.conv1.bias
2023-05-20 17:57:23 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.2.conv2.bias
2023-05-20 17:57:23 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.2.conv3.bias
2023-05-20 17:57:23 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.3.conv1.bias
2023-05-20 17:57:23 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.3.conv2.bias
2023-05-20 17:57:23 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.3.conv3.bias
2023-05-20 17:57:23 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.4.conv1.bias
2023-05-20 17:57:23 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.4.conv2.bias
2023-05-20 17:57:23 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.4.conv3.bias
2023-05-20 17:57:23 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.5.conv1.bias
2023-05-20 17:57:23 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.5.conv2.bias
2023-05-20 17:57:23 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.5.conv3.bias
2023-05-20 17:57:23 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.6.conv1.bias
2023-05-20 17:57:23 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.6.conv2.bias
2023-05-20 17:57:23 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.6.conv3.bias
2023-05-20 17:57:23 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.7.conv1.bias
2023-05-20 17:57:23 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.7.conv2.bias
2023-05-20 17:57:23 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.7.conv3.bias
2023-05-20 17:57:23 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.8.conv1.bias
2023-05-20 17:57:23 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.8.conv2.bias
2023-05-20 17:57:23 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.8.conv3.bias
2023-05-20 17:57:23 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.9.conv1.bias
2023-05-20 17:57:23 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.9.conv2.bias
2023-05-20 17:57:23 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.9.conv3.bias
2023-05-20 17:57:23 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.10.conv1.bias
2023-05-20 17:57:23 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.10.conv2.bias
2023-05-20 17:57:23 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.10.conv3.bias
2023-05-20 17:57:23 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.11.conv1.bias
2023-05-20 17:57:23 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.11.conv2.bias
2023-05-20 17:57:23 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.11.conv3.bias
2023-05-20 17:57:23 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.12.conv1.bias
2023-05-20 17:57:23 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.12.conv2.bias
2023-05-20 17:57:23 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.12.conv3.bias
2023-05-20 17:57:23 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.13.conv1.bias
2023-05-20 17:57:23 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.13.conv2.bias
2023-05-20 17:57:23 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.13.conv3.bias
2023-05-20 17:57:23 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.14.conv1.bias
2023-05-20 17:57:23 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.14.conv2.bias
2023-05-20 17:57:23 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.14.conv3.bias
2023-05-20 17:57:23 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.15.conv1.bias
2023-05-20 17:57:23 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.15.conv2.bias
2023-05-20 17:57:23 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.15.conv3.bias
2023-05-20 17:57:23 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.16.conv1.bias
2023-05-20 17:57:23 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.16.conv2.bias
2023-05-20 17:57:23 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.16.conv3.bias
2023-05-20 17:57:23 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.17.conv1.bias
2023-05-20 17:57:23 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.17.conv2.bias
2023-05-20 17:57:23 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.17.conv3.bias
2023-05-20 17:57:23 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.18.conv1.bias
2023-05-20 17:57:23 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.18.conv2.bias
2023-05-20 17:57:23 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.18.conv3.bias
2023-05-20 17:57:23 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.19.conv1.bias
2023-05-20 17:57:23 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.19.conv2.bias
2023-05-20 17:57:23 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.19.conv3.bias
2023-05-20 17:57:23 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.20.conv1.bias
2023-05-20 17:57:23 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.20.conv2.bias
2023-05-20 17:57:23 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.20.conv3.bias
2023-05-20 17:57:23 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.21.conv1.bias
2023-05-20 17:57:23 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.21.conv2.bias
2023-05-20 17:57:23 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.21.conv3.bias
2023-05-20 17:57:23 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.22.conv1.bias
2023-05-20 17:57:23 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.22.conv2.bias
2023-05-20 17:57:23 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.22.conv3.bias
2023-05-20 17:57:23 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.23.conv1.bias
2023-05-20 17:57:23 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.23.conv2.bias
2023-05-20 17:57:23 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.23.conv3.bias
2023-05-20 17:57:23 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.24.conv1.bias
2023-05-20 17:57:23 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.24.conv2.bias
2023-05-20 17:57:23 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.24.conv3.bias
2023-05-20 17:57:23 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.25.conv1.bias
2023-05-20 17:57:23 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.25.conv2.bias
2023-05-20 17:57:23 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.25.conv3.bias
2023-05-20 17:57:23 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.26.conv1.bias
2023-05-20 17:57:23 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.26.conv2.bias
2023-05-20 17:57:23 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.26.conv3.bias
2023-05-20 17:57:23 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.27.conv1.bias
2023-05-20 17:57:23 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.27.conv2.bias
2023-05-20 17:57:23 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.27.conv3.bias
2023-05-20 17:57:23 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.28.conv1.bias
2023-05-20 17:57:23 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.28.conv2.bias
2023-05-20 17:57:23 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.28.conv3.bias
2023-05-20 17:57:23 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.29.conv1.bias
2023-05-20 17:57:23 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.29.conv2.bias
2023-05-20 17:57:23 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.29.conv3.bias
2023-05-20 17:57:23 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.30.conv1.bias
2023-05-20 17:57:23 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.30.conv2.bias
2023-05-20 17:57:23 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.30.conv3.bias
2023-05-20 17:57:23 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.31.conv1.bias
2023-05-20 17:57:23 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.31.conv2.bias
2023-05-20 17:57:23 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.31.conv3.bias
2023-05-20 17:57:23 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.32.conv1.bias
2023-05-20 17:57:23 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.32.conv2.bias
2023-05-20 17:57:23 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.32.conv3.bias
2023-05-20 17:57:23 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.33.conv1.bias
2023-05-20 17:57:23 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.33.conv2.bias
2023-05-20 17:57:23 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.33.conv3.bias
2023-05-20 17:57:23 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.34.conv1.bias
2023-05-20 17:57:23 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.34.conv2.bias
2023-05-20 17:57:23 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.34.conv3.bias
2023-05-20 17:57:23 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.35.conv1.bias
2023-05-20 17:57:23 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.35.conv2.bias
2023-05-20 17:57:23 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.35.conv3.bias
2023-05-20 17:57:23 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- decoder.output_projection.bias
2023-05-20 17:57:23 - utils.py[line:759] - INFO: ***********************CUDA enviroments for all 1 workers***********************
2023-05-20 17:57:23 - utils.py[line:761] - INFO: rank   0: capabilities =  8.6  ; total memory = 23.688 GB ; name = NVIDIA GeForce RTX 3090 Ti              
2023-05-20 17:57:23 - utils.py[line:767] - INFO: ***********************CUDA enviroments for all 1 workers***********************
2023-05-20 17:57:23 - train.py[line:152] - INFO: training on 1 devices (GPUs/TPUs)
2023-05-20 17:57:23 - train.py[line:157] - INFO: max tokens per device = None and max sentences per device = 4
2023-05-20 17:57:23 - trainer.py[line:458] - INFO: Preparing to load checkpoint ../../checkpoints/ofa_large.pt
2023-05-20 17:57:23 - trainer.py[line:624] - INFO: No existing checkpoint found ../../checkpoints/ofa_large.pt
2023-05-20 17:57:23 - trainer.py[line:639] - INFO: loading train data for epoch 1
local datafile ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 0 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 0 finished initializing row_count and line_idx-to-offset mapping
file ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 0 row count 55400 total row count 55400
slice_id 0 seek offset 0
Total steps 51960, warmup steps 3117, warmup_factor 0.0003208213025344883
wandb: Currently logged in as: jackcai1206. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.15.3 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /home/zcai75/Github/OFA_forked/run_scripts/sgcls/wandb/run-20230520_175725-w7yh51h4
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run _30_1e-5_480
wandb: ⭐️ View project at https://wandb.ai/jackcai1206/OFA-VG
wandb: 🚀 View run at https://wandb.ai/jackcai1206/OFA-VG/runs/w7yh51h4
2023-05-20 17:57:31 - trainer.py[line:703] - INFO: begin training epoch 1
2023-05-20 17:57:31 - train.py[line:305] - INFO: Start iterating over samples
/home/zcai75/Github/OFA/fairseq/fairseq/utils.py:372: UserWarning: amp_C fused kernels unavailable, disabling multi_tensor_l2norm; you may get better performance by installing NVIDIA's apex library
  warnings.warn(
2023-05-20 17:57:40 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2023-05-20 17:57:46 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2023-05-20 17:57:57 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2023-05-20 17:58:32 - progress_bar.py[line:272] - INFO: epoch 001:     13 / 1732 loss=11.068, loss_v1=0, loss_v2=0, nll_loss=11.07, ntokens=1056.4, nsentences=32, sample_size=1056.4, sample_size_v1=0, sample_size_v2=0, ppl=2149.19, wps=239.3, ups=0.23, wpb=1056.4, bsz=32, num_updates=10, lr=3.20821e-08, gnorm=48.384, clip=100, loss_scale=16, train_wall=60, gb_free=8.2, wall=69
2023-05-20 17:59:11 - progress_bar.py[line:272] - INFO: epoch 001:     23 / 1732 loss=11.044, loss_v1=0, loss_v2=0, nll_loss=11.044, ntokens=1082, nsentences=32, sample_size=1082, sample_size_v1=0, sample_size_v2=0, ppl=2110.82, wps=277.9, ups=0.26, wpb=1082, bsz=32, num_updates=20, lr=6.41643e-08, gnorm=45.591, clip=100, loss_scale=16, train_wall=39, gb_free=8.6, wall=108
2023-05-20 17:59:50 - progress_bar.py[line:272] - INFO: epoch 001:     33 / 1732 loss=11.065, loss_v1=0, loss_v2=0, nll_loss=11.067, ntokens=1032.3, nsentences=32, sample_size=1032.3, sample_size_v1=0, sample_size_v2=0, ppl=2145.46, wps=265.3, ups=0.26, wpb=1032.3, bsz=32, num_updates=30, lr=9.62464e-08, gnorm=47.385, clip=100, loss_scale=16, train_wall=39, gb_free=7.2, wall=147
2023-05-20 18:00:13 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2023-05-20 18:00:32 - progress_bar.py[line:272] - INFO: epoch 001:     44 / 1732 loss=11.062, loss_v1=0, loss_v2=0, nll_loss=11.063, ntokens=1105.2, nsentences=32, sample_size=1105.2, sample_size_v1=0, sample_size_v2=0, ppl=2139.41, wps=259, ups=0.23, wpb=1105.2, bsz=32, num_updates=40, lr=1.28329e-07, gnorm=48.82, clip=100, loss_scale=8, train_wall=43, gb_free=8.1, wall=189
2023-05-20 18:01:11 - progress_bar.py[line:272] - INFO: epoch 001:     54 / 1732 loss=11.047, loss_v1=0, loss_v2=0, nll_loss=11.047, ntokens=1025.8, nsentences=32, sample_size=1025.8, sample_size_v1=0, sample_size_v2=0, ppl=2115.41, wps=263.1, ups=0.26, wpb=1025.8, bsz=32, num_updates=50, lr=1.60411e-07, gnorm=49.909, clip=100, loss_scale=8, train_wall=39, gb_free=8.4, wall=228
2023-05-20 18:01:51 - progress_bar.py[line:272] - INFO: epoch 001:     64 / 1732 loss=11.024, loss_v1=0, loss_v2=0, nll_loss=11.021, ntokens=1253.8, nsentences=32, sample_size=1253.8, sample_size_v1=0, sample_size_v2=0, ppl=2077.9, wps=319.2, ups=0.25, wpb=1253.8, bsz=32, num_updates=60, lr=1.92493e-07, gnorm=53.773, clip=100, loss_scale=8, train_wall=39, gb_free=7.8, wall=268
2023-05-20 18:02:31 - progress_bar.py[line:272] - INFO: epoch 001:     74 / 1732 loss=11.021, loss_v1=0, loss_v2=0, nll_loss=11.018, ntokens=1358.9, nsentences=32, sample_size=1358.9, sample_size_v1=0, sample_size_v2=0, ppl=2073.83, wps=336.4, ups=0.25, wpb=1358.9, bsz=32, num_updates=70, lr=2.24575e-07, gnorm=50.048, clip=100, loss_scale=8, train_wall=40, gb_free=7.3, wall=308
2023-05-20 18:03:10 - progress_bar.py[line:272] - INFO: epoch 001:     84 / 1732 loss=11.031, loss_v1=0, loss_v2=0, nll_loss=11.029, ntokens=1166.6, nsentences=32, sample_size=1166.6, sample_size_v1=0, sample_size_v2=0, ppl=2089.39, wps=296.5, ups=0.25, wpb=1166.6, bsz=32, num_updates=80, lr=2.56657e-07, gnorm=49.499, clip=100, loss_scale=8, train_wall=39, gb_free=7.6, wall=348
2023-05-20 18:03:49 - progress_bar.py[line:272] - INFO: epoch 001:     94 / 1732 loss=11.004, loss_v1=0, loss_v2=0, nll_loss=10.998, ntokens=1099.4, nsentences=32, sample_size=1099.4, sample_size_v1=0, sample_size_v2=0, ppl=2045.5, wps=283.5, ups=0.26, wpb=1099.4, bsz=32, num_updates=90, lr=2.88739e-07, gnorm=50.117, clip=100, loss_scale=8, train_wall=39, gb_free=8.8, wall=386
2023-05-20 18:04:27 - progress_bar.py[line:272] - INFO: epoch 001:    104 / 1732 loss=10.99, loss_v1=0, loss_v2=0, nll_loss=10.983, ntokens=968, nsentences=32, sample_size=968, sample_size_v1=0, sample_size_v2=0, ppl=2023.53, wps=253.4, ups=0.26, wpb=968, bsz=32, num_updates=100, lr=3.20821e-07, gnorm=47.968, clip=100, loss_scale=8, train_wall=38, gb_free=8.7, wall=425
2023-05-20 18:05:06 - progress_bar.py[line:272] - INFO: epoch 001:    114 / 1732 loss=10.972, loss_v1=0, loss_v2=0, nll_loss=10.963, ntokens=1043.8, nsentences=32, sample_size=1043.8, sample_size_v1=0, sample_size_v2=0, ppl=1995.83, wps=270.4, ups=0.26, wpb=1043.8, bsz=32, num_updates=110, lr=3.52903e-07, gnorm=48.216, clip=100, loss_scale=8, train_wall=39, gb_free=8.4, wall=463
2023-05-20 18:05:45 - progress_bar.py[line:272] - INFO: epoch 001:    124 / 1732 loss=10.944, loss_v1=0, loss_v2=0, nll_loss=10.932, ntokens=1156.9, nsentences=32, sample_size=1156.9, sample_size_v1=0, sample_size_v2=0, ppl=1954.17, wps=294.9, ups=0.25, wpb=1156.9, bsz=32, num_updates=120, lr=3.84986e-07, gnorm=46.483, clip=100, loss_scale=8, train_wall=39, gb_free=8, wall=502
2023-05-20 18:06:24 - progress_bar.py[line:272] - INFO: epoch 001:    134 / 1732 loss=10.902, loss_v1=0, loss_v2=0, nll_loss=10.885, ntokens=1187.1, nsentences=32, sample_size=1187.1, sample_size_v1=0, sample_size_v2=0, ppl=1891.11, wps=302.6, ups=0.25, wpb=1187.1, bsz=32, num_updates=130, lr=4.17068e-07, gnorm=45.869, clip=100, loss_scale=8, train_wall=39, gb_free=8.7, wall=542
2023-05-20 18:07:04 - progress_bar.py[line:272] - INFO: epoch 001:    144 / 1732 loss=10.841, loss_v1=0, loss_v2=0, nll_loss=10.817, ntokens=1239.8, nsentences=32, sample_size=1239.8, sample_size_v1=0, sample_size_v2=0, ppl=1804.16, wps=313, ups=0.25, wpb=1239.8, bsz=32, num_updates=140, lr=4.4915e-07, gnorm=45.776, clip=100, loss_scale=8, train_wall=40, gb_free=7.6, wall=581
2023-05-20 18:07:43 - progress_bar.py[line:272] - INFO: epoch 001:    154 / 1732 loss=10.795, loss_v1=0, loss_v2=0, nll_loss=10.766, ntokens=1177.9, nsentences=32, sample_size=1177.9, sample_size_v1=0, sample_size_v2=0, ppl=1741.58, wps=298.3, ups=0.25, wpb=1177.9, bsz=32, num_updates=150, lr=4.81232e-07, gnorm=47.317, clip=100, loss_scale=8, train_wall=39, gb_free=7.6, wall=621
2023-05-20 18:08:22 - progress_bar.py[line:272] - INFO: epoch 001:    164 / 1732 loss=10.735, loss_v1=0, loss_v2=0, nll_loss=10.7, ntokens=1064.5, nsentences=32, sample_size=1064.5, sample_size_v1=0, sample_size_v2=0, ppl=1663.34, wps=273.3, ups=0.26, wpb=1064.5, bsz=32, num_updates=160, lr=5.13314e-07, gnorm=43.939, clip=100, loss_scale=8, train_wall=39, gb_free=7.2, wall=660
2023-05-20 18:09:01 - progress_bar.py[line:272] - INFO: epoch 001:    174 / 1732 loss=10.644, loss_v1=0, loss_v2=0, nll_loss=10.599, ntokens=918.2, nsentences=32, sample_size=918.2, sample_size_v1=0, sample_size_v2=0, ppl=1551.09, wps=238.6, ups=0.26, wpb=918.2, bsz=32, num_updates=170, lr=5.45396e-07, gnorm=46.789, clip=100, loss_scale=8, train_wall=38, gb_free=8.5, wall=698
2023-05-20 18:09:40 - progress_bar.py[line:272] - INFO: epoch 001:    184 / 1732 loss=10.533, loss_v1=0, loss_v2=0, nll_loss=10.476, ntokens=1196.7, nsentences=32, sample_size=1196.7, sample_size_v1=0, sample_size_v2=0, ppl=1423.92, wps=303.2, ups=0.25, wpb=1196.7, bsz=32, num_updates=180, lr=5.77478e-07, gnorm=46.222, clip=100, loss_scale=8, train_wall=39, gb_free=8.3, wall=738
2023-05-20 18:10:20 - progress_bar.py[line:272] - INFO: epoch 001:    194 / 1732 loss=10.439, loss_v1=0, loss_v2=0, nll_loss=10.371, ntokens=1132.8, nsentences=32, sample_size=1132.8, sample_size_v1=0, sample_size_v2=0, ppl=1324.41, wps=286.8, ups=0.25, wpb=1132.8, bsz=32, num_updates=190, lr=6.0956e-07, gnorm=46.464, clip=100, loss_scale=8, train_wall=39, gb_free=7.5, wall=777
2023-05-20 18:10:59 - progress_bar.py[line:272] - INFO: epoch 001:    204 / 1732 loss=10.34, loss_v1=0, loss_v2=0, nll_loss=10.261, ntokens=1052.4, nsentences=32, sample_size=1052.4, sample_size_v1=0, sample_size_v2=0, ppl=1226.82, wps=271.7, ups=0.26, wpb=1052.4, bsz=32, num_updates=200, lr=6.41643e-07, gnorm=45.542, clip=100, loss_scale=8, train_wall=39, gb_free=8.2, wall=816
2023-05-20 18:11:37 - progress_bar.py[line:272] - INFO: epoch 001:    214 / 1732 loss=10.218, loss_v1=0, loss_v2=0, nll_loss=10.126, ntokens=1074.9, nsentences=32, sample_size=1074.9, sample_size_v1=0, sample_size_v2=0, ppl=1117.4, wps=279.7, ups=0.26, wpb=1074.9, bsz=32, num_updates=210, lr=6.73725e-07, gnorm=43.814, clip=100, loss_scale=8, train_wall=38, gb_free=8.5, wall=854
2023-05-20 18:12:15 - progress_bar.py[line:272] - INFO: epoch 001:    224 / 1732 loss=10.096, loss_v1=0, loss_v2=0, nll_loss=9.99, ntokens=1100.1, nsentences=32, sample_size=1100.1, sample_size_v1=0, sample_size_v2=0, ppl=1017.04, wps=286.8, ups=0.26, wpb=1100.1, bsz=32, num_updates=220, lr=7.05807e-07, gnorm=46.052, clip=100, loss_scale=8, train_wall=38, gb_free=8.5, wall=893
2023-05-20 18:12:54 - progress_bar.py[line:272] - INFO: epoch 001:    234 / 1732 loss=9.926, loss_v1=0, loss_v2=0, nll_loss=9.801, ntokens=1090.7, nsentences=32, sample_size=1090.7, sample_size_v1=0, sample_size_v2=0, ppl=892.02, wps=285.9, ups=0.26, wpb=1090.7, bsz=32, num_updates=230, lr=7.37889e-07, gnorm=44.465, clip=100, loss_scale=8, train_wall=38, gb_free=8.4, wall=931
2023-05-20 18:13:32 - progress_bar.py[line:272] - INFO: epoch 001:    244 / 1732 loss=9.756, loss_v1=0, loss_v2=0, nll_loss=9.612, ntokens=1157.9, nsentences=32, sample_size=1157.9, sample_size_v1=0, sample_size_v2=0, ppl=782.53, wps=300.4, ups=0.26, wpb=1157.9, bsz=32, num_updates=240, lr=7.69971e-07, gnorm=42.951, clip=100, loss_scale=8, train_wall=38, gb_free=7.8, wall=969
2023-05-20 18:14:11 - progress_bar.py[line:272] - INFO: epoch 001:    254 / 1732 loss=9.568, loss_v1=0, loss_v2=0, nll_loss=9.403, ntokens=1151.4, nsentences=32, sample_size=1151.4, sample_size_v1=0, sample_size_v2=0, ppl=676.9, wps=299.6, ups=0.26, wpb=1151.4, bsz=32, num_updates=250, lr=8.02053e-07, gnorm=43.366, clip=100, loss_scale=8, train_wall=38, gb_free=8.4, wall=1008
2023-05-20 18:14:49 - progress_bar.py[line:272] - INFO: epoch 001:    264 / 1732 loss=9.375, loss_v1=0, loss_v2=0, nll_loss=9.188, ntokens=1137.5, nsentences=32, sample_size=1137.5, sample_size_v1=0, sample_size_v2=0, ppl=583.44, wps=297, ups=0.26, wpb=1137.5, bsz=32, num_updates=260, lr=8.34135e-07, gnorm=42.691, clip=100, loss_scale=8, train_wall=38, gb_free=7.8, wall=1046
2023-05-20 18:15:27 - progress_bar.py[line:272] - INFO: epoch 001:    274 / 1732 loss=9.152, loss_v1=0, loss_v2=0, nll_loss=8.941, ntokens=1136.4, nsentences=32, sample_size=1136.4, sample_size_v1=0, sample_size_v2=0, ppl=491.44, wps=294.7, ups=0.26, wpb=1136.4, bsz=32, num_updates=270, lr=8.66218e-07, gnorm=40.12, clip=100, loss_scale=8, train_wall=39, gb_free=6.3, wall=1085
2023-05-20 18:16:06 - progress_bar.py[line:272] - INFO: epoch 001:    284 / 1732 loss=8.944, loss_v1=0, loss_v2=0, nll_loss=8.709, ntokens=1138.6, nsentences=32, sample_size=1138.6, sample_size_v1=0, sample_size_v2=0, ppl=418.51, wps=296.2, ups=0.26, wpb=1138.6, bsz=32, num_updates=280, lr=8.983e-07, gnorm=37.901, clip=100, loss_scale=8, train_wall=38, gb_free=8.4, wall=1123
2023-05-20 18:16:44 - progress_bar.py[line:272] - INFO: epoch 001:    294 / 1732 loss=8.752, loss_v1=0, loss_v2=0, nll_loss=8.494, ntokens=1144.7, nsentences=32, sample_size=1144.7, sample_size_v1=0, sample_size_v2=0, ppl=360.66, wps=298.9, ups=0.26, wpb=1144.7, bsz=32, num_updates=290, lr=9.30382e-07, gnorm=37.623, clip=100, loss_scale=8, train_wall=38, gb_free=8.8, wall=1161
2023-05-20 18:17:23 - progress_bar.py[line:272] - INFO: epoch 001:    304 / 1732 loss=8.531, loss_v1=0, loss_v2=0, nll_loss=8.248, ntokens=1100.1, nsentences=32, sample_size=1100.1, sample_size_v1=0, sample_size_v2=0, ppl=304.05, wps=286.6, ups=0.26, wpb=1100.1, bsz=32, num_updates=300, lr=9.62464e-07, gnorm=36.113, clip=100, loss_scale=8, train_wall=38, gb_free=8.6, wall=1200
2023-05-20 18:18:01 - progress_bar.py[line:272] - INFO: epoch 001:    314 / 1732 loss=8.393, loss_v1=0, loss_v2=0, nll_loss=8.093, ntokens=1016.6, nsentences=32, sample_size=1016.6, sample_size_v1=0, sample_size_v2=0, ppl=273.05, wps=265.5, ups=0.26, wpb=1016.6, bsz=32, num_updates=310, lr=9.94546e-07, gnorm=35.163, clip=100, loss_scale=8, train_wall=38, gb_free=9.3, wall=1238
2023-05-20 18:18:39 - progress_bar.py[line:272] - INFO: epoch 001:    324 / 1732 loss=8.198, loss_v1=0, loss_v2=0, nll_loss=7.874, ntokens=1018.7, nsentences=32, sample_size=1018.7, sample_size_v1=0, sample_size_v2=0, ppl=234.65, wps=267.5, ups=0.26, wpb=1018.7, bsz=32, num_updates=320, lr=1.02663e-06, gnorm=31.958, clip=100, loss_scale=8, train_wall=38, gb_free=8.5, wall=1276
2023-05-20 18:19:17 - progress_bar.py[line:272] - INFO: epoch 001:    334 / 1732 loss=8.02, loss_v1=0, loss_v2=0, nll_loss=7.675, ntokens=1018.9, nsentences=32, sample_size=1018.9, sample_size_v1=0, sample_size_v2=0, ppl=204.33, wps=268.3, ups=0.26, wpb=1018.9, bsz=32, num_updates=330, lr=1.05871e-06, gnorm=28.751, clip=100, loss_scale=8, train_wall=38, gb_free=8.8, wall=1314
2023-05-20 18:19:55 - progress_bar.py[line:272] - INFO: epoch 001:    344 / 1732 loss=7.911, loss_v1=0, loss_v2=0, nll_loss=7.551, ntokens=921, nsentences=32, sample_size=921, sample_size_v1=0, sample_size_v2=0, ppl=187.57, wps=242.5, ups=0.26, wpb=921, bsz=32, num_updates=340, lr=1.09079e-06, gnorm=29.832, clip=100, loss_scale=8, train_wall=38, gb_free=8.7, wall=1352
2023-05-20 18:20:33 - progress_bar.py[line:272] - INFO: epoch 001:    354 / 1732 loss=7.764, loss_v1=0, loss_v2=0, nll_loss=7.385, ntokens=961.9, nsentences=32, sample_size=961.9, sample_size_v1=0, sample_size_v2=0, ppl=167.16, wps=252.3, ups=0.26, wpb=961.9, bsz=32, num_updates=350, lr=1.12287e-06, gnorm=27.738, clip=100, loss_scale=8, train_wall=38, gb_free=8.6, wall=1390
2023-05-20 18:21:11 - progress_bar.py[line:272] - INFO: epoch 001:    364 / 1732 loss=7.678, loss_v1=0, loss_v2=0, nll_loss=7.288, ntokens=927.9, nsentences=32, sample_size=927.9, sample_size_v1=0, sample_size_v2=0, ppl=156.23, wps=244.9, ups=0.26, wpb=927.9, bsz=32, num_updates=360, lr=1.15496e-06, gnorm=26.412, clip=100, loss_scale=8, train_wall=38, gb_free=9, wall=1428
2023-05-20 18:21:49 - progress_bar.py[line:272] - INFO: epoch 001:    374 / 1732 loss=7.58, loss_v1=0, loss_v2=0, nll_loss=7.176, ntokens=1000.4, nsentences=32, sample_size=1000.4, sample_size_v1=0, sample_size_v2=0, ppl=144.6, wps=262.3, ups=0.26, wpb=1000.4, bsz=32, num_updates=370, lr=1.18704e-06, gnorm=27.405, clip=100, loss_scale=8, train_wall=38, gb_free=8.7, wall=1466
2023-05-20 18:22:27 - progress_bar.py[line:272] - INFO: epoch 001:    384 / 1732 loss=7.461, loss_v1=0, loss_v2=0, nll_loss=7.042, ntokens=1084.8, nsentences=32, sample_size=1084.8, sample_size_v1=0, sample_size_v2=0, ppl=131.77, wps=285.3, ups=0.26, wpb=1084.8, bsz=32, num_updates=380, lr=1.21912e-06, gnorm=23.659, clip=100, loss_scale=8, train_wall=38, gb_free=8.1, wall=1504
2023-05-20 18:23:05 - progress_bar.py[line:272] - INFO: epoch 001:    394 / 1732 loss=7.379, loss_v1=0, loss_v2=0, nll_loss=6.949, ntokens=950.6, nsentences=32, sample_size=950.6, sample_size_v1=0, sample_size_v2=0, ppl=123.59, wps=251.1, ups=0.26, wpb=950.6, bsz=32, num_updates=390, lr=1.2512e-06, gnorm=24.395, clip=100, loss_scale=8, train_wall=38, gb_free=8.9, wall=1542
2023-05-20 18:23:43 - progress_bar.py[line:272] - INFO: epoch 001:    404 / 1732 loss=7.301, loss_v1=0, loss_v2=0, nll_loss=6.861, ntokens=1060.5, nsentences=32, sample_size=1060.5, sample_size_v1=0, sample_size_v2=0, ppl=116.26, wps=276.9, ups=0.26, wpb=1060.5, bsz=32, num_updates=400, lr=1.28329e-06, gnorm=22.689, clip=100, loss_scale=8, train_wall=38, gb_free=8.1, wall=1580
2023-05-20 18:24:22 - progress_bar.py[line:272] - INFO: epoch 001:    414 / 1732 loss=7.201, loss_v1=0, loss_v2=0, nll_loss=6.749, ntokens=1066.1, nsentences=32, sample_size=1066.1, sample_size_v1=0, sample_size_v2=0, ppl=107.59, wps=278.1, ups=0.26, wpb=1066.1, bsz=32, num_updates=410, lr=1.31537e-06, gnorm=22.549, clip=100, loss_scale=8, train_wall=38, gb_free=6.5, wall=1619
2023-05-20 18:25:00 - progress_bar.py[line:272] - INFO: epoch 001:    424 / 1732 loss=7.195, loss_v1=0, loss_v2=0, nll_loss=6.741, ntokens=992.6, nsentences=32, sample_size=992.6, sample_size_v1=0, sample_size_v2=0, ppl=106.99, wps=260.6, ups=0.26, wpb=992.6, bsz=32, num_updates=420, lr=1.34745e-06, gnorm=23.222, clip=100, loss_scale=8, train_wall=38, gb_free=8.6, wall=1657
2023-05-20 18:25:38 - progress_bar.py[line:272] - INFO: epoch 001:    434 / 1732 loss=7.142, loss_v1=0, loss_v2=0, nll_loss=6.681, ntokens=1018.1, nsentences=32, sample_size=1018.1, sample_size_v1=0, sample_size_v2=0, ppl=102.59, wps=266.8, ups=0.26, wpb=1018.1, bsz=32, num_updates=430, lr=1.37953e-06, gnorm=20.297, clip=100, loss_scale=8, train_wall=38, gb_free=9, wall=1695
2023-05-20 18:26:16 - progress_bar.py[line:272] - INFO: epoch 001:    444 / 1732 loss=7.12, loss_v1=0, loss_v2=0, nll_loss=6.657, ntokens=952.1, nsentences=32, sample_size=952.1, sample_size_v1=0, sample_size_v2=0, ppl=100.89, wps=250.2, ups=0.26, wpb=952.1, bsz=32, num_updates=440, lr=1.41161e-06, gnorm=19.468, clip=100, loss_scale=8, train_wall=38, gb_free=9.1, wall=1733
2023-05-20 18:26:54 - progress_bar.py[line:272] - INFO: epoch 001:    454 / 1732 loss=7.056, loss_v1=0, loss_v2=0, nll_loss=6.585, ntokens=919.5, nsentences=32, sample_size=919.5, sample_size_v1=0, sample_size_v2=0, ppl=95.98, wps=242.2, ups=0.26, wpb=919.5, bsz=32, num_updates=450, lr=1.4437e-06, gnorm=19.661, clip=100, loss_scale=8, train_wall=38, gb_free=8.6, wall=1771
2023-05-20 18:27:32 - progress_bar.py[line:272] - INFO: epoch 001:    464 / 1732 loss=6.965, loss_v1=0, loss_v2=0, nll_loss=6.482, ntokens=1076.9, nsentences=32, sample_size=1076.9, sample_size_v1=0, sample_size_v2=0, ppl=89.4, wps=283.5, ups=0.26, wpb=1076.9, bsz=32, num_updates=460, lr=1.47578e-06, gnorm=18.133, clip=100, loss_scale=8, train_wall=38, gb_free=8.9, wall=1809
2023-05-20 18:28:10 - progress_bar.py[line:272] - INFO: epoch 001:    474 / 1732 loss=6.923, loss_v1=0, loss_v2=0, nll_loss=6.436, ntokens=1067.6, nsentences=32, sample_size=1067.6, sample_size_v1=0, sample_size_v2=0, ppl=86.55, wps=279.9, ups=0.26, wpb=1067.6, bsz=32, num_updates=470, lr=1.50786e-06, gnorm=18.978, clip=100, loss_scale=8, train_wall=38, gb_free=9.1, wall=1847
2023-05-20 18:28:48 - progress_bar.py[line:272] - INFO: epoch 001:    484 / 1732 loss=6.898, loss_v1=0, loss_v2=0, nll_loss=6.407, ntokens=966.8, nsentences=32, sample_size=966.8, sample_size_v1=0, sample_size_v2=0, ppl=84.85, wps=255, ups=0.26, wpb=966.8, bsz=32, num_updates=480, lr=1.53994e-06, gnorm=17.255, clip=100, loss_scale=8, train_wall=38, gb_free=8.7, wall=1885
2023-05-20 18:29:26 - progress_bar.py[line:272] - INFO: epoch 001:    494 / 1732 loss=6.837, loss_v1=0, loss_v2=0, nll_loss=6.34, ntokens=937.9, nsentences=32, sample_size=937.9, sample_size_v1=0, sample_size_v2=0, ppl=80.99, wps=244.5, ups=0.26, wpb=937.9, bsz=32, num_updates=490, lr=1.57202e-06, gnorm=18.177, clip=100, loss_scale=8, train_wall=38, gb_free=8.5, wall=1923
2023-05-20 18:30:04 - progress_bar.py[line:272] - INFO: epoch 001:    504 / 1732 loss=6.778, loss_v1=0, loss_v2=0, nll_loss=6.274, ntokens=981, nsentences=32, sample_size=981, sample_size_v1=0, sample_size_v2=0, ppl=77.38, wps=259.8, ups=0.26, wpb=981, bsz=32, num_updates=500, lr=1.60411e-06, gnorm=17.786, clip=100, loss_scale=8, train_wall=38, gb_free=8.6, wall=1961
2023-05-20 18:30:42 - progress_bar.py[line:272] - INFO: epoch 001:    514 / 1732 loss=6.762, loss_v1=0, loss_v2=0, nll_loss=6.256, ntokens=1052.2, nsentences=32, sample_size=1052.2, sample_size_v1=0, sample_size_v2=0, ppl=76.4, wps=276.2, ups=0.26, wpb=1052.2, bsz=32, num_updates=510, lr=1.63619e-06, gnorm=16.075, clip=100, loss_scale=8, train_wall=38, gb_free=9, wall=1999
2023-05-20 18:31:20 - progress_bar.py[line:272] - INFO: epoch 001:    524 / 1732 loss=6.708, loss_v1=0, loss_v2=0, nll_loss=6.195, ntokens=980.8, nsentences=32, sample_size=980.8, sample_size_v1=0, sample_size_v2=0, ppl=73.25, wps=259.4, ups=0.26, wpb=980.8, bsz=32, num_updates=520, lr=1.66827e-06, gnorm=16.866, clip=100, loss_scale=8, train_wall=38, gb_free=8.8, wall=2037
2023-05-20 18:31:58 - progress_bar.py[line:272] - INFO: epoch 001:    534 / 1732 loss=6.675, loss_v1=0, loss_v2=0, nll_loss=6.158, ntokens=944.9, nsentences=32, sample_size=944.9, sample_size_v1=0, sample_size_v2=0, ppl=71.43, wps=250, ups=0.26, wpb=944.9, bsz=32, num_updates=530, lr=1.70035e-06, gnorm=16.042, clip=100, loss_scale=8, train_wall=38, gb_free=8.3, wall=2075
2023-05-20 18:32:36 - progress_bar.py[line:272] - INFO: epoch 001:    544 / 1732 loss=6.614, loss_v1=0, loss_v2=0, nll_loss=6.091, ntokens=998.9, nsentences=32, sample_size=998.9, sample_size_v1=0, sample_size_v2=0, ppl=68.15, wps=263, ups=0.26, wpb=998.9, bsz=32, num_updates=540, lr=1.73244e-06, gnorm=15.997, clip=100, loss_scale=8, train_wall=38, gb_free=8.6, wall=2113
2023-05-20 18:33:14 - progress_bar.py[line:272] - INFO: epoch 001:    554 / 1732 loss=6.626, loss_v1=0, loss_v2=0, nll_loss=6.103, ntokens=1026.7, nsentences=32, sample_size=1026.7, sample_size_v1=0, sample_size_v2=0, ppl=68.75, wps=270.2, ups=0.26, wpb=1026.7, bsz=32, num_updates=550, lr=1.76452e-06, gnorm=15.404, clip=100, loss_scale=16, train_wall=38, gb_free=8.5, wall=2151
2023-05-20 18:33:52 - progress_bar.py[line:272] - INFO: epoch 001:    564 / 1732 loss=6.541, loss_v1=0, loss_v2=0, nll_loss=6.009, ntokens=1028.3, nsentences=32, sample_size=1028.3, sample_size_v1=0, sample_size_v2=0, ppl=64.4, wps=269.1, ups=0.26, wpb=1028.3, bsz=32, num_updates=560, lr=1.7966e-06, gnorm=15.267, clip=100, loss_scale=16, train_wall=38, gb_free=8.2, wall=2189
2023-05-20 18:34:30 - progress_bar.py[line:272] - INFO: epoch 001:    574 / 1732 loss=6.505, loss_v1=0, loss_v2=0, nll_loss=5.968, ntokens=1015.5, nsentences=32, sample_size=1015.5, sample_size_v1=0, sample_size_v2=0, ppl=62.6, wps=265.6, ups=0.26, wpb=1015.5, bsz=32, num_updates=570, lr=1.82868e-06, gnorm=15.97, clip=100, loss_scale=16, train_wall=38, gb_free=8.2, wall=2227
2023-05-20 18:35:08 - progress_bar.py[line:272] - INFO: epoch 001:    584 / 1732 loss=6.481, loss_v1=0, loss_v2=0, nll_loss=5.941, ntokens=991.8, nsentences=32, sample_size=991.8, sample_size_v1=0, sample_size_v2=0, ppl=61.45, wps=260, ups=0.26, wpb=991.8, bsz=32, num_updates=580, lr=1.86076e-06, gnorm=15.562, clip=100, loss_scale=16, train_wall=38, gb_free=7.8, wall=2266
2023-05-20 18:35:47 - progress_bar.py[line:272] - INFO: epoch 001:    594 / 1732 loss=6.432, loss_v1=0, loss_v2=0, nll_loss=5.886, ntokens=957.2, nsentences=32, sample_size=957.2, sample_size_v1=0, sample_size_v2=0, ppl=59.14, wps=250.2, ups=0.26, wpb=957.2, bsz=32, num_updates=590, lr=1.89285e-06, gnorm=14.756, clip=100, loss_scale=16, train_wall=38, gb_free=8.5, wall=2304
2023-05-20 18:36:24 - progress_bar.py[line:272] - INFO: epoch 001:    604 / 1732 loss=6.353, loss_v1=0, loss_v2=0, nll_loss=5.8, ntokens=888.6, nsentences=32, sample_size=888.6, sample_size_v1=0, sample_size_v2=0, ppl=55.71, wps=235.7, ups=0.27, wpb=888.6, bsz=32, num_updates=600, lr=1.92493e-06, gnorm=16.677, clip=100, loss_scale=16, train_wall=38, gb_free=8.4, wall=2341
2023-05-20 18:37:02 - progress_bar.py[line:272] - INFO: epoch 001:    614 / 1732 loss=6.299, loss_v1=0, loss_v2=0, nll_loss=5.737, ntokens=891, nsentences=32, sample_size=891, sample_size_v1=0, sample_size_v2=0, ppl=53.35, wps=234.3, ups=0.26, wpb=891, bsz=32, num_updates=610, lr=1.95701e-06, gnorm=14.817, clip=100, loss_scale=16, train_wall=38, gb_free=8.8, wall=2380
2023-05-20 18:37:40 - progress_bar.py[line:272] - INFO: epoch 001:    624 / 1732 loss=6.231, loss_v1=0, loss_v2=0, nll_loss=5.663, ntokens=899.1, nsentences=32, sample_size=899.1, sample_size_v1=0, sample_size_v2=0, ppl=50.66, wps=238.9, ups=0.27, wpb=899.1, bsz=32, num_updates=620, lr=1.98909e-06, gnorm=14.523, clip=100, loss_scale=16, train_wall=38, gb_free=9, wall=2417
2023-05-20 18:38:18 - progress_bar.py[line:272] - INFO: epoch 001:    634 / 1732 loss=6.223, loss_v1=0, loss_v2=0, nll_loss=5.654, ntokens=904.7, nsentences=32, sample_size=904.7, sample_size_v1=0, sample_size_v2=0, ppl=50.34, wps=240, ups=0.27, wpb=904.7, bsz=32, num_updates=630, lr=2.02117e-06, gnorm=15.935, clip=100, loss_scale=16, train_wall=38, gb_free=9.1, wall=2455
2023-05-20 18:38:56 - progress_bar.py[line:272] - INFO: epoch 001:    644 / 1732 loss=6.117, loss_v1=0, loss_v2=0, nll_loss=5.534, ntokens=979.3, nsentences=32, sample_size=979.3, sample_size_v1=0, sample_size_v2=0, ppl=46.33, wps=257.6, ups=0.26, wpb=979.3, bsz=32, num_updates=640, lr=2.05326e-06, gnorm=14.649, clip=100, loss_scale=16, train_wall=38, gb_free=8.7, wall=2493
2023-05-20 18:39:33 - progress_bar.py[line:272] - INFO: epoch 001:    654 / 1732 loss=6.068, loss_v1=0, loss_v2=0, nll_loss=5.478, ntokens=909.5, nsentences=32, sample_size=909.5, sample_size_v1=0, sample_size_v2=0, ppl=44.57, wps=242.5, ups=0.27, wpb=909.5, bsz=32, num_updates=650, lr=2.08534e-06, gnorm=14.073, clip=100, loss_scale=16, train_wall=37, gb_free=8.6, wall=2530
2023-05-20 18:40:11 - progress_bar.py[line:272] - INFO: epoch 001:    664 / 1732 loss=6.02, loss_v1=0, loss_v2=0, nll_loss=5.424, ntokens=889.3, nsentences=32, sample_size=889.3, sample_size_v1=0, sample_size_v2=0, ppl=42.92, wps=236.8, ups=0.27, wpb=889.3, bsz=32, num_updates=660, lr=2.11742e-06, gnorm=15.436, clip=100, loss_scale=16, train_wall=38, gb_free=9.1, wall=2568
2023-05-20 18:40:49 - progress_bar.py[line:272] - INFO: epoch 001:    674 / 1732 loss=5.938, loss_v1=0, loss_v2=0, nll_loss=5.331, ntokens=964.6, nsentences=32, sample_size=964.6, sample_size_v1=0, sample_size_v2=0, ppl=40.24, wps=255.5, ups=0.26, wpb=964.6, bsz=32, num_updates=670, lr=2.1495e-06, gnorm=14.786, clip=100, loss_scale=16, train_wall=38, gb_free=8.7, wall=2606
2023-05-20 18:41:26 - progress_bar.py[line:272] - INFO: epoch 001:    684 / 1732 loss=5.85, loss_v1=0, loss_v2=0, nll_loss=5.231, ntokens=968.6, nsentences=32, sample_size=968.6, sample_size_v1=0, sample_size_v2=0, ppl=37.55, wps=255.3, ups=0.26, wpb=968.6, bsz=32, num_updates=680, lr=2.18158e-06, gnorm=14.997, clip=100, loss_scale=16, train_wall=38, gb_free=9.1, wall=2644
2023-05-20 18:42:05 - progress_bar.py[line:272] - INFO: epoch 001:    694 / 1732 loss=5.784, loss_v1=0, loss_v2=0, nll_loss=5.154, ntokens=975.2, nsentences=32, sample_size=975.2, sample_size_v1=0, sample_size_v2=0, ppl=35.59, wps=255.6, ups=0.26, wpb=975.2, bsz=32, num_updates=690, lr=2.21367e-06, gnorm=14.564, clip=100, loss_scale=16, train_wall=38, gb_free=8.1, wall=2682
2023-05-20 18:42:43 - progress_bar.py[line:272] - INFO: epoch 001:    704 / 1732 loss=5.693, loss_v1=0, loss_v2=0, nll_loss=5.05, ntokens=954.2, nsentences=32, sample_size=954.2, sample_size_v1=0, sample_size_v2=0, ppl=33.12, wps=251, ups=0.26, wpb=954.2, bsz=32, num_updates=700, lr=2.24575e-06, gnorm=14.384, clip=100, loss_scale=16, train_wall=38, gb_free=9.1, wall=2720
2023-05-20 18:43:20 - progress_bar.py[line:272] - INFO: epoch 001:    714 / 1732 loss=5.652, loss_v1=0, loss_v2=0, nll_loss=5.002, ntokens=885.5, nsentences=32, sample_size=885.5, sample_size_v1=0, sample_size_v2=0, ppl=32.05, wps=235.2, ups=0.27, wpb=885.5, bsz=32, num_updates=710, lr=2.27783e-06, gnorm=14.831, clip=100, loss_scale=16, train_wall=38, gb_free=8.5, wall=2757
2023-05-20 18:43:58 - progress_bar.py[line:272] - INFO: epoch 001:    724 / 1732 loss=5.587, loss_v1=0, loss_v2=0, nll_loss=4.926, ntokens=897.8, nsentences=32, sample_size=897.8, sample_size_v1=0, sample_size_v2=0, ppl=30.39, wps=238.4, ups=0.27, wpb=897.8, bsz=32, num_updates=720, lr=2.30991e-06, gnorm=15.084, clip=100, loss_scale=16, train_wall=38, gb_free=8.9, wall=2795
2023-05-20 18:44:36 - progress_bar.py[line:272] - INFO: epoch 001:    734 / 1732 loss=5.491, loss_v1=0, loss_v2=0, nll_loss=4.817, ntokens=952.3, nsentences=32, sample_size=952.3, sample_size_v1=0, sample_size_v2=0, ppl=28.19, wps=251.6, ups=0.26, wpb=952.3, bsz=32, num_updates=730, lr=2.342e-06, gnorm=14.534, clip=100, loss_scale=16, train_wall=38, gb_free=8.8, wall=2833
2023-05-20 18:45:14 - progress_bar.py[line:272] - INFO: epoch 001:    744 / 1732 loss=5.459, loss_v1=0, loss_v2=0, nll_loss=4.78, ntokens=999.9, nsentences=32, sample_size=999.9, sample_size_v1=0, sample_size_v2=0, ppl=27.47, wps=264.1, ups=0.26, wpb=999.9, bsz=32, num_updates=740, lr=2.37408e-06, gnorm=14.099, clip=100, loss_scale=16, train_wall=38, gb_free=8.1, wall=2871
2023-05-20 18:45:52 - progress_bar.py[line:272] - INFO: epoch 001:    754 / 1732 loss=5.366, loss_v1=0, loss_v2=0, nll_loss=4.671, ntokens=976.3, nsentences=32, sample_size=976.3, sample_size_v1=0, sample_size_v2=0, ppl=25.48, wps=257.6, ups=0.26, wpb=976.3, bsz=32, num_updates=750, lr=2.40616e-06, gnorm=13.567, clip=100, loss_scale=16, train_wall=38, gb_free=8.7, wall=2909
2023-05-20 18:46:29 - progress_bar.py[line:272] - INFO: epoch 001:    764 / 1732 loss=5.394, loss_v1=0, loss_v2=0, nll_loss=4.702, ntokens=943.8, nsentences=32, sample_size=943.8, sample_size_v1=0, sample_size_v2=0, ppl=26.02, wps=249.5, ups=0.26, wpb=943.8, bsz=32, num_updates=760, lr=2.43824e-06, gnorm=13.681, clip=100, loss_scale=16, train_wall=38, gb_free=9.1, wall=2947
2023-05-20 18:47:07 - progress_bar.py[line:272] - INFO: epoch 001:    774 / 1732 loss=5.272, loss_v1=0, loss_v2=0, nll_loss=4.563, ntokens=1000.5, nsentences=32, sample_size=1000.5, sample_size_v1=0, sample_size_v2=0, ppl=23.63, wps=263.3, ups=0.26, wpb=1000.5, bsz=32, num_updates=770, lr=2.47032e-06, gnorm=14.297, clip=100, loss_scale=16, train_wall=38, gb_free=8.6, wall=2985
2023-05-20 18:47:46 - progress_bar.py[line:272] - INFO: epoch 001:    784 / 1732 loss=5.306, loss_v1=0, loss_v2=0, nll_loss=4.599, ntokens=1008.3, nsentences=32, sample_size=1008.3, sample_size_v1=0, sample_size_v2=0, ppl=24.24, wps=264.4, ups=0.26, wpb=1008.3, bsz=32, num_updates=780, lr=2.50241e-06, gnorm=14.502, clip=100, loss_scale=16, train_wall=38, gb_free=8.8, wall=3023
2023-05-20 18:48:23 - progress_bar.py[line:272] - INFO: epoch 001:    794 / 1732 loss=5.191, loss_v1=0, loss_v2=0, nll_loss=4.468, ntokens=1024.7, nsentences=32, sample_size=1024.7, sample_size_v1=0, sample_size_v2=0, ppl=22.14, wps=270.3, ups=0.26, wpb=1024.7, bsz=32, num_updates=790, lr=2.53449e-06, gnorm=13.168, clip=100, loss_scale=16, train_wall=38, gb_free=8.9, wall=3061
2023-05-20 18:49:01 - progress_bar.py[line:272] - INFO: epoch 001:    804 / 1732 loss=5.175, loss_v1=0, loss_v2=0, nll_loss=4.446, ntokens=947.8, nsentences=32, sample_size=947.8, sample_size_v1=0, sample_size_v2=0, ppl=21.79, wps=250.5, ups=0.26, wpb=947.8, bsz=32, num_updates=800, lr=2.56657e-06, gnorm=12.725, clip=100, loss_scale=16, train_wall=38, gb_free=8.8, wall=3098
2023-05-20 18:49:39 - progress_bar.py[line:272] - INFO: epoch 001:    814 / 1732 loss=5.114, loss_v1=0, loss_v2=0, nll_loss=4.38, ntokens=938.1, nsentences=32, sample_size=938.1, sample_size_v1=0, sample_size_v2=0, ppl=20.81, wps=247.4, ups=0.26, wpb=938.1, bsz=32, num_updates=810, lr=2.59865e-06, gnorm=14.152, clip=100, loss_scale=16, train_wall=38, gb_free=9.1, wall=3136
2023-05-20 18:50:17 - progress_bar.py[line:272] - INFO: epoch 001:    824 / 1732 loss=5.073, loss_v1=0, loss_v2=0, nll_loss=4.329, ntokens=923.7, nsentences=32, sample_size=923.7, sample_size_v1=0, sample_size_v2=0, ppl=20.1, wps=243.3, ups=0.26, wpb=923.7, bsz=32, num_updates=820, lr=2.63073e-06, gnorm=14.492, clip=100, loss_scale=16, train_wall=38, gb_free=8.3, wall=3174
2023-05-20 18:50:55 - progress_bar.py[line:272] - INFO: epoch 001:    834 / 1732 loss=5.069, loss_v1=0, loss_v2=0, nll_loss=4.326, ntokens=890.1, nsentences=32, sample_size=890.1, sample_size_v1=0, sample_size_v2=0, ppl=20.06, wps=236.4, ups=0.27, wpb=890.1, bsz=32, num_updates=830, lr=2.66282e-06, gnorm=13.1, clip=100, loss_scale=16, train_wall=38, gb_free=9.1, wall=3212
2023-05-20 18:51:33 - progress_bar.py[line:272] - INFO: epoch 001:    844 / 1732 loss=4.99, loss_v1=0, loss_v2=0, nll_loss=4.238, ntokens=972.2, nsentences=32, sample_size=972.2, sample_size_v1=0, sample_size_v2=0, ppl=18.87, wps=257.6, ups=0.26, wpb=972.2, bsz=32, num_updates=840, lr=2.6949e-06, gnorm=12.05, clip=100, loss_scale=16, train_wall=38, gb_free=9, wall=3250
2023-05-20 18:52:11 - progress_bar.py[line:272] - INFO: epoch 001:    854 / 1732 loss=5.02, loss_v1=0, loss_v2=0, nll_loss=4.269, ntokens=976.8, nsentences=32, sample_size=976.8, sample_size_v1=0, sample_size_v2=0, ppl=19.28, wps=257.1, ups=0.26, wpb=976.8, bsz=32, num_updates=850, lr=2.72698e-06, gnorm=13.091, clip=100, loss_scale=16, train_wall=38, gb_free=8.7, wall=3288
2023-05-20 18:52:48 - progress_bar.py[line:272] - INFO: epoch 001:    864 / 1732 loss=4.9, loss_v1=0, loss_v2=0, nll_loss=4.131, ntokens=958.7, nsentences=32, sample_size=958.7, sample_size_v1=0, sample_size_v2=0, ppl=17.52, wps=253.2, ups=0.26, wpb=958.7, bsz=32, num_updates=860, lr=2.75906e-06, gnorm=12.321, clip=100, loss_scale=16, train_wall=38, gb_free=8.6, wall=3326
2023-05-20 18:53:26 - progress_bar.py[line:272] - INFO: epoch 001:    874 / 1732 loss=4.867, loss_v1=0, loss_v2=0, nll_loss=4.095, ntokens=975.5, nsentences=32, sample_size=975.5, sample_size_v1=0, sample_size_v2=0, ppl=17.09, wps=256.9, ups=0.26, wpb=975.5, bsz=32, num_updates=870, lr=2.79115e-06, gnorm=12.563, clip=100, loss_scale=16, train_wall=38, gb_free=8.2, wall=3364
2023-05-20 18:54:04 - progress_bar.py[line:272] - INFO: epoch 001:    884 / 1732 loss=4.782, loss_v1=0, loss_v2=0, nll_loss=3.997, ntokens=977.6, nsentences=32, sample_size=977.6, sample_size_v1=0, sample_size_v2=0, ppl=15.96, wps=257.5, ups=0.26, wpb=977.6, bsz=32, num_updates=880, lr=2.82323e-06, gnorm=12.609, clip=100, loss_scale=16, train_wall=38, gb_free=8.6, wall=3402
2023-05-20 18:54:42 - progress_bar.py[line:272] - INFO: epoch 001:    894 / 1732 loss=4.817, loss_v1=0, loss_v2=0, nll_loss=4.033, ntokens=1010, nsentences=32, sample_size=1010, sample_size_v1=0, sample_size_v2=0, ppl=16.37, wps=265.3, ups=0.26, wpb=1010, bsz=32, num_updates=890, lr=2.85531e-06, gnorm=13.298, clip=100, loss_scale=16, train_wall=38, gb_free=8.1, wall=3440
2023-05-20 18:55:21 - progress_bar.py[line:272] - INFO: epoch 001:    904 / 1732 loss=4.76, loss_v1=0, loss_v2=0, nll_loss=3.969, ntokens=1055.2, nsentences=32, sample_size=1055.2, sample_size_v1=0, sample_size_v2=0, ppl=15.66, wps=277.4, ups=0.26, wpb=1055.2, bsz=32, num_updates=900, lr=2.88739e-06, gnorm=12.389, clip=100, loss_scale=16, train_wall=38, gb_free=8.7, wall=3478
2023-05-20 18:55:58 - progress_bar.py[line:272] - INFO: epoch 001:    914 / 1732 loss=4.788, loss_v1=0, loss_v2=0, nll_loss=4.002, ntokens=927.8, nsentences=32, sample_size=927.8, sample_size_v1=0, sample_size_v2=0, ppl=16.02, wps=244.7, ups=0.26, wpb=927.8, bsz=32, num_updates=910, lr=2.91947e-06, gnorm=11.711, clip=100, loss_scale=16, train_wall=38, gb_free=9, wall=3516
2023-05-20 18:56:37 - progress_bar.py[line:272] - INFO: epoch 001:    924 / 1732 loss=4.75, loss_v1=0, loss_v2=0, nll_loss=3.961, ntokens=1031.4, nsentences=32, sample_size=1031.4, sample_size_v1=0, sample_size_v2=0, ppl=15.57, wps=267.5, ups=0.26, wpb=1031.4, bsz=32, num_updates=920, lr=2.95156e-06, gnorm=10.618, clip=100, loss_scale=16, train_wall=39, gb_free=8.7, wall=3554
2023-05-20 18:57:16 - progress_bar.py[line:272] - INFO: epoch 001:    934 / 1732 loss=4.751, loss_v1=0, loss_v2=0, nll_loss=3.958, ntokens=1020.2, nsentences=32, sample_size=1020.2, sample_size_v1=0, sample_size_v2=0, ppl=15.54, wps=264.6, ups=0.26, wpb=1020.2, bsz=32, num_updates=930, lr=2.98364e-06, gnorm=11.102, clip=100, loss_scale=16, train_wall=39, gb_free=8.9, wall=3593
2023-05-20 18:57:54 - progress_bar.py[line:272] - INFO: epoch 001:    944 / 1732 loss=4.701, loss_v1=0, loss_v2=0, nll_loss=3.898, ntokens=1062, nsentences=32, sample_size=1062, sample_size_v1=0, sample_size_v2=0, ppl=14.91, wps=273.9, ups=0.26, wpb=1062, bsz=32, num_updates=940, lr=3.01572e-06, gnorm=11.2, clip=100, loss_scale=16, train_wall=39, gb_free=8, wall=3632
2023-05-20 18:58:33 - progress_bar.py[line:272] - INFO: epoch 001:    954 / 1732 loss=4.673, loss_v1=0, loss_v2=0, nll_loss=3.869, ntokens=1041, nsentences=32, sample_size=1041, sample_size_v1=0, sample_size_v2=0, ppl=14.61, wps=270.4, ups=0.26, wpb=1041, bsz=32, num_updates=950, lr=3.0478e-06, gnorm=11.678, clip=100, loss_scale=16, train_wall=38, gb_free=8.2, wall=3670
2023-05-20 18:59:11 - progress_bar.py[line:272] - INFO: epoch 001:    964 / 1732 loss=4.691, loss_v1=0, loss_v2=0, nll_loss=3.889, ntokens=1053, nsentences=32, sample_size=1053, sample_size_v1=0, sample_size_v2=0, ppl=14.81, wps=273.1, ups=0.26, wpb=1053, bsz=32, num_updates=960, lr=3.07988e-06, gnorm=11.603, clip=100, loss_scale=16, train_wall=39, gb_free=8.6, wall=3709
2023-05-20 18:59:50 - progress_bar.py[line:272] - INFO: epoch 001:    974 / 1732 loss=4.666, loss_v1=0, loss_v2=0, nll_loss=3.86, ntokens=1051.9, nsentences=32, sample_size=1051.9, sample_size_v1=0, sample_size_v2=0, ppl=14.52, wps=271.2, ups=0.26, wpb=1051.9, bsz=32, num_updates=970, lr=3.11197e-06, gnorm=11.123, clip=100, loss_scale=16, train_wall=39, gb_free=8.7, wall=3747
2023-05-20 19:00:29 - progress_bar.py[line:272] - INFO: epoch 001:    984 / 1732 loss=4.635, loss_v1=0, loss_v2=0, nll_loss=3.824, ntokens=1029.3, nsentences=32, sample_size=1029.3, sample_size_v1=0, sample_size_v2=0, ppl=14.16, wps=265.3, ups=0.26, wpb=1029.3, bsz=32, num_updates=980, lr=3.14405e-06, gnorm=10.942, clip=100, loss_scale=16, train_wall=39, gb_free=7.9, wall=3786
2023-05-20 19:01:07 - progress_bar.py[line:272] - INFO: epoch 001:    994 / 1732 loss=4.575, loss_v1=0, loss_v2=0, nll_loss=3.756, ntokens=1030.4, nsentences=32, sample_size=1030.4, sample_size_v1=0, sample_size_v2=0, ppl=13.51, wps=267.6, ups=0.26, wpb=1030.4, bsz=32, num_updates=990, lr=3.17613e-06, gnorm=9.927, clip=100, loss_scale=16, train_wall=38, gb_free=8.7, wall=3825
2023-05-20 19:01:46 - progress_bar.py[line:272] - INFO: epoch 001:   1004 / 1732 loss=4.56, loss_v1=0, loss_v2=0, nll_loss=3.736, ntokens=995.4, nsentences=32, sample_size=995.4, sample_size_v1=0, sample_size_v2=0, ppl=13.32, wps=258.2, ups=0.26, wpb=995.4, bsz=32, num_updates=1000, lr=3.20821e-06, gnorm=10.265, clip=100, loss_scale=16, train_wall=39, gb_free=9.1, wall=3863
2023-05-20 19:02:24 - progress_bar.py[line:272] - INFO: epoch 001:   1014 / 1732 loss=4.526, loss_v1=0, loss_v2=0, nll_loss=3.699, ntokens=997.1, nsentences=32, sample_size=997.1, sample_size_v1=0, sample_size_v2=0, ppl=12.99, wps=260.2, ups=0.26, wpb=997.1, bsz=32, num_updates=1010, lr=3.2403e-06, gnorm=9.684, clip=100, loss_scale=16, train_wall=38, gb_free=8.5, wall=3902
2023-05-20 19:03:03 - progress_bar.py[line:272] - INFO: epoch 001:   1024 / 1732 loss=4.547, loss_v1=0, loss_v2=0, nll_loss=3.723, ntokens=1086.7, nsentences=32, sample_size=1086.7, sample_size_v1=0, sample_size_v2=0, ppl=13.2, wps=280.8, ups=0.26, wpb=1086.7, bsz=32, num_updates=1020, lr=3.27238e-06, gnorm=9.666, clip=100, loss_scale=16, train_wall=39, gb_free=8.6, wall=3940
2023-05-20 19:03:42 - progress_bar.py[line:272] - INFO: epoch 001:   1034 / 1732 loss=4.533, loss_v1=0, loss_v2=0, nll_loss=3.706, ntokens=1103.2, nsentences=32, sample_size=1103.2, sample_size_v1=0, sample_size_v2=0, ppl=13.05, wps=284.3, ups=0.26, wpb=1103.2, bsz=32, num_updates=1030, lr=3.30446e-06, gnorm=9.772, clip=100, loss_scale=16, train_wall=39, gb_free=7.9, wall=3979
2023-05-20 19:04:20 - progress_bar.py[line:272] - INFO: epoch 001:   1044 / 1732 loss=4.445, loss_v1=0, loss_v2=0, nll_loss=3.604, ntokens=1052.8, nsentences=32, sample_size=1052.8, sample_size_v1=0, sample_size_v2=0, ppl=12.16, wps=272.9, ups=0.26, wpb=1052.8, bsz=32, num_updates=1040, lr=3.33654e-06, gnorm=10.118, clip=100, loss_scale=16, train_wall=39, gb_free=8.4, wall=4018
2023-05-20 19:04:59 - progress_bar.py[line:272] - INFO: epoch 001:   1054 / 1732 loss=4.439, loss_v1=0, loss_v2=0, nll_loss=3.598, ntokens=1068, nsentences=32, sample_size=1068, sample_size_v1=0, sample_size_v2=0, ppl=12.11, wps=279.1, ups=0.26, wpb=1068, bsz=32, num_updates=1050, lr=3.36862e-06, gnorm=9.703, clip=100, loss_scale=16, train_wall=38, gb_free=7, wall=4056
2023-05-20 19:05:37 - progress_bar.py[line:272] - INFO: epoch 001:   1064 / 1732 loss=4.477, loss_v1=0, loss_v2=0, nll_loss=3.642, ntokens=1024.1, nsentences=32, sample_size=1024.1, sample_size_v1=0, sample_size_v2=0, ppl=12.48, wps=267.1, ups=0.26, wpb=1024.1, bsz=32, num_updates=1060, lr=3.40071e-06, gnorm=10.295, clip=100, loss_scale=32, train_wall=38, gb_free=8.7, wall=4094
2023-05-20 19:06:16 - progress_bar.py[line:272] - INFO: epoch 001:   1074 / 1732 loss=4.401, loss_v1=0, loss_v2=0, nll_loss=3.553, ntokens=1002.8, nsentences=32, sample_size=1002.8, sample_size_v1=0, sample_size_v2=0, ppl=11.74, wps=260.7, ups=0.26, wpb=1002.8, bsz=32, num_updates=1070, lr=3.43279e-06, gnorm=9.586, clip=100, loss_scale=32, train_wall=38, gb_free=8.4, wall=4133
2023-05-20 19:06:55 - progress_bar.py[line:272] - INFO: epoch 001:   1084 / 1732 loss=4.43, loss_v1=0, loss_v2=0, nll_loss=3.583, ntokens=1060.4, nsentences=32, sample_size=1060.4, sample_size_v1=0, sample_size_v2=0, ppl=11.98, wps=271.9, ups=0.26, wpb=1060.4, bsz=32, num_updates=1080, lr=3.46487e-06, gnorm=9.166, clip=100, loss_scale=32, train_wall=39, gb_free=7.2, wall=4172
2023-05-20 19:07:33 - progress_bar.py[line:272] - INFO: epoch 001:   1094 / 1732 loss=4.357, loss_v1=0, loss_v2=0, nll_loss=3.501, ntokens=1050.5, nsentences=32, sample_size=1050.5, sample_size_v1=0, sample_size_v2=0, ppl=11.32, wps=273.6, ups=0.26, wpb=1050.5, bsz=32, num_updates=1090, lr=3.49695e-06, gnorm=8.403, clip=100, loss_scale=32, train_wall=38, gb_free=7.8, wall=4210
2023-05-20 19:08:12 - progress_bar.py[line:272] - INFO: epoch 001:   1104 / 1732 loss=4.389, loss_v1=0, loss_v2=0, nll_loss=3.539, ntokens=1042.3, nsentences=32, sample_size=1042.3, sample_size_v1=0, sample_size_v2=0, ppl=11.62, wps=270.2, ups=0.26, wpb=1042.3, bsz=32, num_updates=1100, lr=3.52903e-06, gnorm=9.178, clip=100, loss_scale=32, train_wall=39, gb_free=8.4, wall=4249
2023-05-20 19:08:50 - progress_bar.py[line:272] - INFO: epoch 001:   1114 / 1732 loss=4.32, loss_v1=0, loss_v2=0, nll_loss=3.46, ntokens=1000.7, nsentences=32, sample_size=1000.7, sample_size_v1=0, sample_size_v2=0, ppl=11.01, wps=258.2, ups=0.26, wpb=1000.7, bsz=32, num_updates=1110, lr=3.56112e-06, gnorm=8.551, clip=100, loss_scale=32, train_wall=39, gb_free=8.5, wall=4287
2023-05-20 19:09:29 - progress_bar.py[line:272] - INFO: epoch 001:   1124 / 1732 loss=4.364, loss_v1=0, loss_v2=0, nll_loss=3.507, ntokens=989.1, nsentences=32, sample_size=989.1, sample_size_v1=0, sample_size_v2=0, ppl=11.37, wps=256.3, ups=0.26, wpb=989.1, bsz=32, num_updates=1120, lr=3.5932e-06, gnorm=9.249, clip=100, loss_scale=32, train_wall=39, gb_free=8.4, wall=4326
2023-05-20 19:10:07 - progress_bar.py[line:272] - INFO: epoch 001:   1134 / 1732 loss=4.307, loss_v1=0, loss_v2=0, nll_loss=3.445, ntokens=968.8, nsentences=32, sample_size=968.8, sample_size_v1=0, sample_size_v2=0, ppl=10.89, wps=251.7, ups=0.26, wpb=968.8, bsz=32, num_updates=1130, lr=3.62528e-06, gnorm=9.042, clip=100, loss_scale=32, train_wall=38, gb_free=8.5, wall=4365
2023-05-20 19:10:46 - progress_bar.py[line:272] - INFO: epoch 001:   1144 / 1732 loss=4.355, loss_v1=0, loss_v2=0, nll_loss=3.5, ntokens=1034.3, nsentences=32, sample_size=1034.3, sample_size_v1=0, sample_size_v2=0, ppl=11.32, wps=268.4, ups=0.26, wpb=1034.3, bsz=32, num_updates=1140, lr=3.65736e-06, gnorm=9.655, clip=100, loss_scale=32, train_wall=38, gb_free=8.7, wall=4403
2023-05-20 19:11:24 - progress_bar.py[line:272] - INFO: epoch 001:   1154 / 1732 loss=4.27, loss_v1=0, loss_v2=0, nll_loss=3.404, ntokens=1025.8, nsentences=32, sample_size=1025.8, sample_size_v1=0, sample_size_v2=0, ppl=10.58, wps=266.7, ups=0.26, wpb=1025.8, bsz=32, num_updates=1150, lr=3.68944e-06, gnorm=8.567, clip=100, loss_scale=32, train_wall=38, gb_free=7.4, wall=4442
2023-05-20 19:12:03 - progress_bar.py[line:272] - INFO: epoch 001:   1164 / 1732 loss=4.24, loss_v1=0, loss_v2=0, nll_loss=3.365, ntokens=1008, nsentences=32, sample_size=1008, sample_size_v1=0, sample_size_v2=0, ppl=10.31, wps=261.1, ups=0.26, wpb=1008, bsz=32, num_updates=1160, lr=3.72153e-06, gnorm=8.545, clip=100, loss_scale=32, train_wall=39, gb_free=8.7, wall=4480
2023-05-20 19:12:42 - progress_bar.py[line:272] - INFO: epoch 001:   1174 / 1732 loss=4.229, loss_v1=0, loss_v2=0, nll_loss=3.356, ntokens=1081.1, nsentences=32, sample_size=1081.1, sample_size_v1=0, sample_size_v2=0, ppl=10.24, wps=278.4, ups=0.26, wpb=1081.1, bsz=32, num_updates=1170, lr=3.75361e-06, gnorm=8.894, clip=100, loss_scale=32, train_wall=39, gb_free=8.1, wall=4519
2023-05-20 19:13:20 - progress_bar.py[line:272] - INFO: epoch 001:   1184 / 1732 loss=4.252, loss_v1=0, loss_v2=0, nll_loss=3.381, ntokens=962, nsentences=32, sample_size=962, sample_size_v1=0, sample_size_v2=0, ppl=10.41, wps=251, ups=0.26, wpb=962, bsz=32, num_updates=1180, lr=3.78569e-06, gnorm=9.333, clip=100, loss_scale=32, train_wall=38, gb_free=8.8, wall=4557
2023-05-20 19:13:59 - progress_bar.py[line:272] - INFO: epoch 001:   1194 / 1732 loss=4.21, loss_v1=0, loss_v2=0, nll_loss=3.334, ntokens=1042.6, nsentences=32, sample_size=1042.6, sample_size_v1=0, sample_size_v2=0, ppl=10.08, wps=270.4, ups=0.26, wpb=1042.6, bsz=32, num_updates=1190, lr=3.81777e-06, gnorm=8.103, clip=100, loss_scale=32, train_wall=39, gb_free=8.7, wall=4596
2023-05-20 19:14:38 - progress_bar.py[line:272] - INFO: epoch 001:   1204 / 1732 loss=4.102, loss_v1=0, loss_v2=0, nll_loss=3.209, ntokens=1150.2, nsentences=32, sample_size=1150.2, sample_size_v1=0, sample_size_v2=0, ppl=9.25, wps=294.3, ups=0.26, wpb=1150.2, bsz=32, num_updates=1200, lr=3.84986e-06, gnorm=7.664, clip=100, loss_scale=32, train_wall=39, gb_free=8.4, wall=4635
2023-05-20 19:15:16 - progress_bar.py[line:272] - INFO: epoch 001:   1214 / 1732 loss=4.14, loss_v1=0, loss_v2=0, nll_loss=3.253, ntokens=996.3, nsentences=32, sample_size=996.3, sample_size_v1=0, sample_size_v2=0, ppl=9.53, wps=259, ups=0.26, wpb=996.3, bsz=32, num_updates=1210, lr=3.88194e-06, gnorm=8.172, clip=100, loss_scale=32, train_wall=38, gb_free=8.9, wall=4673
2023-05-20 19:15:55 - progress_bar.py[line:272] - INFO: epoch 001:   1224 / 1732 loss=4.192, loss_v1=0, loss_v2=0, nll_loss=3.313, ntokens=1056.3, nsentences=32, sample_size=1056.3, sample_size_v1=0, sample_size_v2=0, ppl=9.94, wps=271.1, ups=0.26, wpb=1056.3, bsz=32, num_updates=1220, lr=3.91402e-06, gnorm=8.669, clip=100, loss_scale=32, train_wall=39, gb_free=8.7, wall=4712
2023-05-20 19:16:34 - progress_bar.py[line:272] - INFO: epoch 001:   1234 / 1732 loss=4.107, loss_v1=0, loss_v2=0, nll_loss=3.215, ntokens=1012.2, nsentences=32, sample_size=1012.2, sample_size_v1=0, sample_size_v2=0, ppl=9.29, wps=263.2, ups=0.26, wpb=1012.2, bsz=32, num_updates=1230, lr=3.9461e-06, gnorm=7.684, clip=100, loss_scale=32, train_wall=38, gb_free=8.7, wall=4751
2023-05-20 19:17:12 - progress_bar.py[line:272] - INFO: epoch 001:   1244 / 1732 loss=4.094, loss_v1=0, loss_v2=0, nll_loss=3.2, ntokens=1090.2, nsentences=32, sample_size=1090.2, sample_size_v1=0, sample_size_v2=0, ppl=9.19, wps=281.5, ups=0.26, wpb=1090.2, bsz=32, num_updates=1240, lr=3.97818e-06, gnorm=8.469, clip=100, loss_scale=32, train_wall=39, gb_free=8.6, wall=4790
2023-05-20 19:17:51 - progress_bar.py[line:272] - INFO: epoch 001:   1254 / 1732 loss=4.063, loss_v1=0, loss_v2=0, nll_loss=3.164, ntokens=1076, nsentences=32, sample_size=1076, sample_size_v1=0, sample_size_v2=0, ppl=8.97, wps=278, ups=0.26, wpb=1076, bsz=32, num_updates=1250, lr=4.01027e-06, gnorm=7.982, clip=100, loss_scale=32, train_wall=39, gb_free=8.8, wall=4828
2023-05-20 19:18:30 - progress_bar.py[line:272] - INFO: epoch 001:   1264 / 1732 loss=4.053, loss_v1=0, loss_v2=0, nll_loss=3.15, ntokens=1095.2, nsentences=32, sample_size=1095.2, sample_size_v1=0, sample_size_v2=0, ppl=8.88, wps=282, ups=0.26, wpb=1095.2, bsz=32, num_updates=1260, lr=4.04235e-06, gnorm=7.562, clip=100, loss_scale=32, train_wall=39, gb_free=7.8, wall=4867
2023-05-20 19:19:08 - progress_bar.py[line:272] - INFO: epoch 001:   1274 / 1732 loss=4.029, loss_v1=0, loss_v2=0, nll_loss=3.125, ntokens=1014.1, nsentences=32, sample_size=1014.1, sample_size_v1=0, sample_size_v2=0, ppl=8.72, wps=263.8, ups=0.26, wpb=1014.1, bsz=32, num_updates=1270, lr=4.07443e-06, gnorm=7.476, clip=100, loss_scale=32, train_wall=38, gb_free=8.1, wall=4906
2023-05-20 19:19:47 - progress_bar.py[line:272] - INFO: epoch 001:   1284 / 1732 loss=4.003, loss_v1=0, loss_v2=0, nll_loss=3.096, ntokens=1057.3, nsentences=32, sample_size=1057.3, sample_size_v1=0, sample_size_v2=0, ppl=8.55, wps=271.4, ups=0.26, wpb=1057.3, bsz=32, num_updates=1280, lr=4.10651e-06, gnorm=7.78, clip=100, loss_scale=32, train_wall=39, gb_free=8.8, wall=4945
2023-05-20 19:20:26 - progress_bar.py[line:272] - INFO: epoch 001:   1294 / 1732 loss=4.015, loss_v1=0, loss_v2=0, nll_loss=3.108, ntokens=1109.4, nsentences=32, sample_size=1109.4, sample_size_v1=0, sample_size_v2=0, ppl=8.62, wps=287, ups=0.26, wpb=1109.4, bsz=32, num_updates=1290, lr=4.13859e-06, gnorm=7.528, clip=100, loss_scale=32, train_wall=39, gb_free=8.3, wall=4983
2023-05-20 19:21:05 - progress_bar.py[line:272] - INFO: epoch 001:   1304 / 1732 loss=3.958, loss_v1=0, loss_v2=0, nll_loss=3.044, ntokens=1090.1, nsentences=32, sample_size=1090.1, sample_size_v1=0, sample_size_v2=0, ppl=8.25, wps=279.9, ups=0.26, wpb=1090.1, bsz=32, num_updates=1300, lr=4.17068e-06, gnorm=7.217, clip=100, loss_scale=32, train_wall=39, gb_free=8.3, wall=5022
2023-05-20 19:21:44 - progress_bar.py[line:272] - INFO: epoch 001:   1314 / 1732 loss=3.981, loss_v1=0, loss_v2=0, nll_loss=3.069, ntokens=1051.4, nsentences=32, sample_size=1051.4, sample_size_v1=0, sample_size_v2=0, ppl=8.39, wps=269.9, ups=0.26, wpb=1051.4, bsz=32, num_updates=1310, lr=4.20276e-06, gnorm=7.954, clip=100, loss_scale=32, train_wall=39, gb_free=8, wall=5061
2023-05-20 19:22:23 - progress_bar.py[line:272] - INFO: epoch 001:   1324 / 1732 loss=3.968, loss_v1=0, loss_v2=0, nll_loss=3.053, ntokens=1117, nsentences=32, sample_size=1117, sample_size_v1=0, sample_size_v2=0, ppl=8.3, wps=284.9, ups=0.26, wpb=1117, bsz=32, num_updates=1320, lr=4.23484e-06, gnorm=7.48, clip=100, loss_scale=32, train_wall=39, gb_free=8.5, wall=5100
2023-05-20 19:23:02 - progress_bar.py[line:272] - INFO: epoch 001:   1334 / 1732 loss=3.911, loss_v1=0, loss_v2=0, nll_loss=2.989, ntokens=1097.8, nsentences=32, sample_size=1097.8, sample_size_v1=0, sample_size_v2=0, ppl=7.94, wps=283.2, ups=0.26, wpb=1097.8, bsz=32, num_updates=1330, lr=4.26692e-06, gnorm=7.571, clip=100, loss_scale=32, train_wall=39, gb_free=8.8, wall=5139
2023-05-20 19:23:41 - progress_bar.py[line:272] - INFO: epoch 001:   1344 / 1732 loss=3.946, loss_v1=0, loss_v2=0, nll_loss=3.027, ntokens=1201.2, nsentences=32, sample_size=1201.2, sample_size_v1=0, sample_size_v2=0, ppl=8.15, wps=307.5, ups=0.26, wpb=1201.2, bsz=32, num_updates=1340, lr=4.29901e-06, gnorm=7.656, clip=100, loss_scale=32, train_wall=39, gb_free=8, wall=5178
2023-05-20 19:24:20 - progress_bar.py[line:272] - INFO: epoch 001:   1354 / 1732 loss=3.936, loss_v1=0, loss_v2=0, nll_loss=3.016, ntokens=1101.2, nsentences=32, sample_size=1101.2, sample_size_v1=0, sample_size_v2=0, ppl=8.09, wps=283.2, ups=0.26, wpb=1101.2, bsz=32, num_updates=1350, lr=4.33109e-06, gnorm=6.944, clip=100, loss_scale=32, train_wall=39, gb_free=8.6, wall=5217
2023-05-20 19:24:59 - progress_bar.py[line:272] - INFO: epoch 001:   1364 / 1732 loss=3.873, loss_v1=0, loss_v2=0, nll_loss=2.944, ntokens=1115.3, nsentences=32, sample_size=1115.3, sample_size_v1=0, sample_size_v2=0, ppl=7.7, wps=285.4, ups=0.26, wpb=1115.3, bsz=32, num_updates=1360, lr=4.36317e-06, gnorm=6.699, clip=100, loss_scale=32, train_wall=39, gb_free=8.2, wall=5256
2023-05-20 19:25:38 - progress_bar.py[line:272] - INFO: epoch 001:   1374 / 1732 loss=3.94, loss_v1=0, loss_v2=0, nll_loss=3.022, ntokens=1075.1, nsentences=32, sample_size=1075.1, sample_size_v1=0, sample_size_v2=0, ppl=8.12, wps=276.4, ups=0.26, wpb=1075.1, bsz=32, num_updates=1370, lr=4.39525e-06, gnorm=7.251, clip=100, loss_scale=32, train_wall=39, gb_free=8.9, wall=5295
2023-05-20 19:26:17 - progress_bar.py[line:272] - INFO: epoch 001:   1384 / 1732 loss=3.914, loss_v1=0, loss_v2=0, nll_loss=2.991, ntokens=1167.1, nsentences=32, sample_size=1167.1, sample_size_v1=0, sample_size_v2=0, ppl=7.95, wps=300.5, ups=0.26, wpb=1167.1, bsz=32, num_updates=1380, lr=4.42733e-06, gnorm=7.098, clip=100, loss_scale=32, train_wall=39, gb_free=7.9, wall=5334
2023-05-20 19:26:55 - progress_bar.py[line:272] - INFO: epoch 001:   1394 / 1732 loss=3.842, loss_v1=0, loss_v2=0, nll_loss=2.909, ntokens=1039.3, nsentences=32, sample_size=1039.3, sample_size_v1=0, sample_size_v2=0, ppl=7.51, wps=270.2, ups=0.26, wpb=1039.3, bsz=32, num_updates=1390, lr=4.45942e-06, gnorm=7.112, clip=100, loss_scale=32, train_wall=38, gb_free=7.7, wall=5372
2023-05-20 19:27:34 - progress_bar.py[line:272] - INFO: epoch 001:   1404 / 1732 loss=3.828, loss_v1=0, loss_v2=0, nll_loss=2.894, ntokens=1161.9, nsentences=32, sample_size=1161.9, sample_size_v1=0, sample_size_v2=0, ppl=7.43, wps=298.4, ups=0.26, wpb=1161.9, bsz=32, num_updates=1400, lr=4.4915e-06, gnorm=7.052, clip=100, loss_scale=32, train_wall=39, gb_free=7.1, wall=5411
2023-05-20 19:28:13 - progress_bar.py[line:272] - INFO: epoch 001:   1414 / 1732 loss=3.807, loss_v1=0, loss_v2=0, nll_loss=2.869, ntokens=1276, nsentences=32, sample_size=1276, sample_size_v1=0, sample_size_v2=0, ppl=7.31, wps=327, ups=0.26, wpb=1276, bsz=32, num_updates=1410, lr=4.52358e-06, gnorm=6.396, clip=100, loss_scale=32, train_wall=39, gb_free=7.7, wall=5450
2023-05-20 19:28:52 - progress_bar.py[line:272] - INFO: epoch 001:   1424 / 1732 loss=3.837, loss_v1=0, loss_v2=0, nll_loss=2.903, ntokens=1261.9, nsentences=32, sample_size=1261.9, sample_size_v1=0, sample_size_v2=0, ppl=7.48, wps=321.3, ups=0.25, wpb=1261.9, bsz=32, num_updates=1420, lr=4.55566e-06, gnorm=7.242, clip=100, loss_scale=32, train_wall=39, gb_free=7.7, wall=5490
2023-05-20 19:29:31 - progress_bar.py[line:272] - INFO: epoch 001:   1434 / 1732 loss=3.789, loss_v1=0, loss_v2=0, nll_loss=2.851, ntokens=1196.2, nsentences=32, sample_size=1196.2, sample_size_v1=0, sample_size_v2=0, ppl=7.22, wps=308.4, ups=0.26, wpb=1196.2, bsz=32, num_updates=1430, lr=4.58774e-06, gnorm=7.3, clip=100, loss_scale=32, train_wall=39, gb_free=8.2, wall=5528
2023-05-20 19:30:10 - progress_bar.py[line:272] - INFO: epoch 001:   1444 / 1732 loss=3.767, loss_v1=0, loss_v2=0, nll_loss=2.824, ntokens=1129.1, nsentences=32, sample_size=1129.1, sample_size_v1=0, sample_size_v2=0, ppl=7.08, wps=291.7, ups=0.26, wpb=1129.1, bsz=32, num_updates=1440, lr=4.61983e-06, gnorm=6.859, clip=100, loss_scale=32, train_wall=39, gb_free=7.7, wall=5567
2023-05-20 19:30:49 - progress_bar.py[line:272] - INFO: epoch 001:   1454 / 1732 loss=3.743, loss_v1=0, loss_v2=0, nll_loss=2.796, ntokens=1122, nsentences=32, sample_size=1122, sample_size_v1=0, sample_size_v2=0, ppl=6.94, wps=289.8, ups=0.26, wpb=1122, bsz=32, num_updates=1450, lr=4.65191e-06, gnorm=7.097, clip=100, loss_scale=32, train_wall=39, gb_free=7.9, wall=5606
2023-05-20 19:31:28 - progress_bar.py[line:272] - INFO: epoch 001:   1464 / 1732 loss=3.685, loss_v1=0, loss_v2=0, nll_loss=2.73, ntokens=1182.3, nsentences=32, sample_size=1182.3, sample_size_v1=0, sample_size_v2=0, ppl=6.63, wps=303, ups=0.26, wpb=1182.3, bsz=32, num_updates=1460, lr=4.68399e-06, gnorm=6.631, clip=100, loss_scale=32, train_wall=39, gb_free=8.5, wall=5645
2023-05-20 19:32:06 - progress_bar.py[line:272] - INFO: epoch 001:   1474 / 1732 loss=3.686, loss_v1=0, loss_v2=0, nll_loss=2.727, ntokens=1095.3, nsentences=32, sample_size=1095.3, sample_size_v1=0, sample_size_v2=0, ppl=6.62, wps=283.3, ups=0.26, wpb=1095.3, bsz=32, num_updates=1470, lr=4.71607e-06, gnorm=6.541, clip=100, loss_scale=32, train_wall=39, gb_free=8.6, wall=5684
2023-05-20 19:32:45 - progress_bar.py[line:272] - INFO: epoch 001:   1484 / 1732 loss=3.705, loss_v1=0, loss_v2=0, nll_loss=2.753, ntokens=1096.5, nsentences=32, sample_size=1096.5, sample_size_v1=0, sample_size_v2=0, ppl=6.74, wps=282.5, ups=0.26, wpb=1096.5, bsz=32, num_updates=1480, lr=4.74816e-06, gnorm=7.359, clip=100, loss_scale=32, train_wall=39, gb_free=7.9, wall=5722
2023-05-20 19:33:24 - progress_bar.py[line:272] - INFO: epoch 001:   1494 / 1732 loss=3.681, loss_v1=0, loss_v2=0, nll_loss=2.721, ntokens=1106.4, nsentences=32, sample_size=1106.4, sample_size_v1=0, sample_size_v2=0, ppl=6.6, wps=284.5, ups=0.26, wpb=1106.4, bsz=32, num_updates=1490, lr=4.78024e-06, gnorm=6.747, clip=100, loss_scale=32, train_wall=39, gb_free=8.2, wall=5761
2023-05-20 19:34:03 - progress_bar.py[line:272] - INFO: epoch 001:   1504 / 1732 loss=3.668, loss_v1=0, loss_v2=0, nll_loss=2.711, ntokens=1153.1, nsentences=32, sample_size=1153.1, sample_size_v1=0, sample_size_v2=0, ppl=6.55, wps=297.9, ups=0.26, wpb=1153.1, bsz=32, num_updates=1500, lr=4.81232e-06, gnorm=7.033, clip=100, loss_scale=32, train_wall=39, gb_free=8.1, wall=5800
2023-05-20 19:34:41 - progress_bar.py[line:272] - INFO: epoch 001:   1514 / 1732 loss=3.688, loss_v1=0, loss_v2=0, nll_loss=2.729, ntokens=1041.2, nsentences=32, sample_size=1041.2, sample_size_v1=0, sample_size_v2=0, ppl=6.63, wps=269.5, ups=0.26, wpb=1041.2, bsz=32, num_updates=1510, lr=4.8444e-06, gnorm=6.532, clip=100, loss_scale=32, train_wall=39, gb_free=8.9, wall=5839
2023-05-20 19:35:20 - progress_bar.py[line:272] - INFO: epoch 001:   1524 / 1732 loss=3.659, loss_v1=0, loss_v2=0, nll_loss=2.698, ntokens=1034.8, nsentences=32, sample_size=1034.8, sample_size_v1=0, sample_size_v2=0, ppl=6.49, wps=268, ups=0.26, wpb=1034.8, bsz=32, num_updates=1520, lr=4.87648e-06, gnorm=6.698, clip=100, loss_scale=32, train_wall=39, gb_free=7.5, wall=5877
2023-05-20 19:35:59 - progress_bar.py[line:272] - INFO: epoch 001:   1534 / 1732 loss=3.63, loss_v1=0, loss_v2=0, nll_loss=2.662, ntokens=1092.4, nsentences=32, sample_size=1092.4, sample_size_v1=0, sample_size_v2=0, ppl=6.33, wps=280.4, ups=0.26, wpb=1092.4, bsz=32, num_updates=1530, lr=4.90857e-06, gnorm=6.783, clip=100, loss_scale=32, train_wall=39, gb_free=8.3, wall=5916
2023-05-20 19:36:38 - progress_bar.py[line:272] - INFO: epoch 001:   1544 / 1732 loss=3.626, loss_v1=0, loss_v2=0, nll_loss=2.66, ntokens=1091.8, nsentences=32, sample_size=1091.8, sample_size_v1=0, sample_size_v2=0, ppl=6.32, wps=281.9, ups=0.26, wpb=1091.8, bsz=32, num_updates=1540, lr=4.94065e-06, gnorm=6.828, clip=100, loss_scale=32, train_wall=39, gb_free=8.7, wall=5955
2023-05-20 19:37:16 - progress_bar.py[line:272] - INFO: epoch 001:   1554 / 1732 loss=3.603, loss_v1=0, loss_v2=0, nll_loss=2.63, ntokens=1040, nsentences=32, sample_size=1040, sample_size_v1=0, sample_size_v2=0, ppl=6.19, wps=269.9, ups=0.26, wpb=1040, bsz=32, num_updates=1550, lr=4.97273e-06, gnorm=6.492, clip=100, loss_scale=32, train_wall=38, gb_free=8.7, wall=5993
2023-05-20 19:37:55 - progress_bar.py[line:272] - INFO: epoch 001:   1564 / 1732 loss=3.596, loss_v1=0, loss_v2=0, nll_loss=2.621, ntokens=1120.2, nsentences=32, sample_size=1120.2, sample_size_v1=0, sample_size_v2=0, ppl=6.15, wps=287.7, ups=0.26, wpb=1120.2, bsz=32, num_updates=1560, lr=5.00481e-06, gnorm=6.688, clip=100, loss_scale=32, train_wall=39, gb_free=8.8, wall=6032
2023-05-20 19:38:34 - progress_bar.py[line:272] - INFO: epoch 001:   1574 / 1732 loss=3.588, loss_v1=0, loss_v2=0, nll_loss=2.614, ntokens=1055.9, nsentences=32, sample_size=1055.9, sample_size_v1=0, sample_size_v2=0, ppl=6.12, wps=271.1, ups=0.26, wpb=1055.9, bsz=32, num_updates=1570, lr=5.03689e-06, gnorm=7.149, clip=100, loss_scale=32, train_wall=39, gb_free=8.3, wall=6071
2023-05-20 19:39:13 - progress_bar.py[line:272] - INFO: epoch 001:   1584 / 1732 loss=3.608, loss_v1=0, loss_v2=0, nll_loss=2.635, ntokens=1026.8, nsentences=32, sample_size=1026.8, sample_size_v1=0, sample_size_v2=0, ppl=6.21, wps=265.2, ups=0.26, wpb=1026.8, bsz=32, num_updates=1580, lr=5.06898e-06, gnorm=6.727, clip=100, loss_scale=64, train_wall=39, gb_free=7.9, wall=6110
2023-05-20 19:39:52 - progress_bar.py[line:272] - INFO: epoch 001:   1594 / 1732 loss=3.597, loss_v1=0, loss_v2=0, nll_loss=2.627, ntokens=1068.7, nsentences=32, sample_size=1068.7, sample_size_v1=0, sample_size_v2=0, ppl=6.18, wps=275.8, ups=0.26, wpb=1068.7, bsz=32, num_updates=1590, lr=5.10106e-06, gnorm=6.876, clip=100, loss_scale=64, train_wall=39, gb_free=8.4, wall=6149
2023-05-20 19:40:30 - progress_bar.py[line:272] - INFO: epoch 001:   1604 / 1732 loss=3.521, loss_v1=0, loss_v2=0, nll_loss=2.535, ntokens=1089, nsentences=32, sample_size=1089, sample_size_v1=0, sample_size_v2=0, ppl=5.8, wps=280.4, ups=0.26, wpb=1089, bsz=32, num_updates=1600, lr=5.13314e-06, gnorm=6.286, clip=100, loss_scale=64, train_wall=39, gb_free=7.9, wall=6188
2023-05-20 19:41:10 - progress_bar.py[line:272] - INFO: epoch 001:   1614 / 1732 loss=3.503, loss_v1=0, loss_v2=0, nll_loss=2.515, ntokens=1186.1, nsentences=32, sample_size=1186.1, sample_size_v1=0, sample_size_v2=0, ppl=5.72, wps=303.6, ups=0.26, wpb=1186.1, bsz=32, num_updates=1610, lr=5.16522e-06, gnorm=7.134, clip=100, loss_scale=64, train_wall=39, gb_free=8, wall=6227
2023-05-20 19:41:48 - progress_bar.py[line:272] - INFO: epoch 001:   1624 / 1732 loss=3.46, loss_v1=0, loss_v2=0, nll_loss=2.469, ntokens=1074.1, nsentences=32, sample_size=1074.1, sample_size_v1=0, sample_size_v2=0, ppl=5.54, wps=277.7, ups=0.26, wpb=1074.1, bsz=32, num_updates=1620, lr=5.19731e-06, gnorm=6.346, clip=100, loss_scale=64, train_wall=39, gb_free=8.7, wall=6265
2023-05-20 19:42:27 - progress_bar.py[line:272] - INFO: epoch 001:   1634 / 1732 loss=3.493, loss_v1=0, loss_v2=0, nll_loss=2.499, ntokens=1178.9, nsentences=32, sample_size=1178.9, sample_size_v1=0, sample_size_v2=0, ppl=5.65, wps=303.8, ups=0.26, wpb=1178.9, bsz=32, num_updates=1630, lr=5.22939e-06, gnorm=6.571, clip=100, loss_scale=64, train_wall=39, gb_free=8.7, wall=6304
2023-05-20 19:43:06 - progress_bar.py[line:272] - INFO: epoch 001:   1644 / 1732 loss=3.419, loss_v1=0, loss_v2=0, nll_loss=2.417, ntokens=1265.1, nsentences=32, sample_size=1265.1, sample_size_v1=0, sample_size_v2=0, ppl=5.34, wps=324, ups=0.26, wpb=1265.1, bsz=32, num_updates=1640, lr=5.26147e-06, gnorm=6.641, clip=100, loss_scale=64, train_wall=39, gb_free=8, wall=6343
2023-05-20 19:43:45 - progress_bar.py[line:272] - INFO: epoch 001:   1654 / 1732 loss=3.519, loss_v1=0, loss_v2=0, nll_loss=2.531, ntokens=974.9, nsentences=32, sample_size=974.9, sample_size_v1=0, sample_size_v2=0, ppl=5.78, wps=253.5, ups=0.26, wpb=974.9, bsz=32, num_updates=1650, lr=5.29355e-06, gnorm=7.005, clip=100, loss_scale=64, train_wall=38, gb_free=8.6, wall=6382
2023-05-20 19:44:23 - progress_bar.py[line:272] - INFO: epoch 001:   1664 / 1732 loss=3.456, loss_v1=0, loss_v2=0, nll_loss=2.454, ntokens=1041.8, nsentences=32, sample_size=1041.8, sample_size_v1=0, sample_size_v2=0, ppl=5.48, wps=267.9, ups=0.26, wpb=1041.8, bsz=32, num_updates=1660, lr=5.32563e-06, gnorm=6.508, clip=100, loss_scale=64, train_wall=39, gb_free=8.3, wall=6421
2023-05-20 19:45:02 - progress_bar.py[line:272] - INFO: epoch 001:   1674 / 1732 loss=3.433, loss_v1=0, loss_v2=0, nll_loss=2.435, ntokens=1052.3, nsentences=32, sample_size=1052.3, sample_size_v1=0, sample_size_v2=0, ppl=5.41, wps=272.6, ups=0.26, wpb=1052.3, bsz=32, num_updates=1670, lr=5.35772e-06, gnorm=6.855, clip=100, loss_scale=64, train_wall=39, gb_free=8.1, wall=6459
2023-05-20 19:45:41 - progress_bar.py[line:272] - INFO: epoch 001:   1684 / 1732 loss=3.464, loss_v1=0, loss_v2=0, nll_loss=2.465, ntokens=1169.1, nsentences=32, sample_size=1169.1, sample_size_v1=0, sample_size_v2=0, ppl=5.52, wps=299.3, ups=0.26, wpb=1169.1, bsz=32, num_updates=1680, lr=5.3898e-06, gnorm=6.731, clip=100, loss_scale=64, train_wall=39, gb_free=8.8, wall=6498
2023-05-20 19:46:21 - progress_bar.py[line:272] - INFO: epoch 001:   1694 / 1732 loss=3.441, loss_v1=0, loss_v2=0, nll_loss=2.44, ntokens=1257.3, nsentences=32, sample_size=1257.3, sample_size_v1=0, sample_size_v2=0, ppl=5.43, wps=318.4, ups=0.25, wpb=1257.3, bsz=32, num_updates=1690, lr=5.42188e-06, gnorm=6.295, clip=100, loss_scale=64, train_wall=39, gb_free=7, wall=6538
2023-05-20 19:47:00 - progress_bar.py[line:272] - INFO: epoch 001:   1704 / 1732 loss=3.403, loss_v1=0, loss_v2=0, nll_loss=2.402, ntokens=1232.6, nsentences=32, sample_size=1232.6, sample_size_v1=0, sample_size_v2=0, ppl=5.29, wps=314.5, ups=0.26, wpb=1232.6, bsz=32, num_updates=1700, lr=5.45396e-06, gnorm=6.149, clip=100, loss_scale=64, train_wall=39, gb_free=8.4, wall=6577
2023-05-20 19:47:39 - progress_bar.py[line:272] - INFO: epoch 001:   1714 / 1732 loss=3.402, loss_v1=0, loss_v2=0, nll_loss=2.391, ntokens=1181.2, nsentences=32, sample_size=1181.2, sample_size_v1=0, sample_size_v2=0, ppl=5.25, wps=302.2, ups=0.26, wpb=1181.2, bsz=32, num_updates=1710, lr=5.48604e-06, gnorm=5.792, clip=100, loss_scale=64, train_wall=39, gb_free=8.3, wall=6616
2023-05-20 19:48:18 - progress_bar.py[line:272] - INFO: epoch 001:   1724 / 1732 loss=3.404, loss_v1=0, loss_v2=0, nll_loss=2.396, ntokens=1135.1, nsentences=32, sample_size=1135.1, sample_size_v1=0, sample_size_v2=0, ppl=5.26, wps=291.8, ups=0.26, wpb=1135.1, bsz=32, num_updates=1720, lr=5.51813e-06, gnorm=6.675, clip=100, loss_scale=64, train_wall=39, gb_free=8.6, wall=6655
2023-05-20 19:48:46 - train.py[line:332] - INFO: end of epoch 1 (average epoch stats below)
2023-05-20 19:48:46 - progress_bar.py[line:282] - INFO: epoch 001 | loss 5.914 | loss_v1 0 | loss_v2 0 | nll_loss 5.266 | ntokens 1051.05 | nsentences 31.986 | sample_size 1051.05 | sample_size_v1 0 | sample_size_v2 0 | ppl 38.49 | wps 272.8 | ups 0.26 | wpb 1051 | bsz 32 | num_updates 1728 | lr 5.54379e-06 | gnorm 17.854 | clip 100 | loss_scale 64 | train_wall 6665 | gb_free 8.9 | wall 6683
2023-05-20 19:48:46 - trainer.py[line:639] - INFO: loading train data for epoch 2
local datafile ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 0 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 0 finished initializing row_count and line_idx-to-offset mapping
file ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 0 row count 55400 total row count 55400
/data/hulab/zcai75/anaconda3/envs/vilt/lib/python3.8/site-packages/torchvision/transforms/transforms.py:332: UserWarning: Argument 'interpolation' of type int is deprecated since 0.13 and will be removed in 0.15. Please use InterpolationMode enum.
  warnings.warn(
slice_id 0 seek offset 0
2023-05-20 19:48:48 - trainer.py[line:703] - INFO: begin training epoch 2
2023-05-20 19:48:48 - train.py[line:305] - INFO: Start iterating over samples
2023-05-20 19:48:56 - progress_bar.py[line:272] - INFO: epoch 002:      2 / 1732 loss=3.421, loss_v1=0, loss_v2=0, nll_loss=2.415, ntokens=1104.4, nsentences=29.6, sample_size=1104.4, sample_size_v1=0, sample_size_v2=0, ppl=5.33, wps=290.1, ups=0.26, wpb=1104.4, bsz=29.6, num_updates=1730, lr=5.55021e-06, gnorm=6.518, clip=100, loss_scale=64, train_wall=36, gb_free=8, wall=6693
2023-05-20 19:49:35 - progress_bar.py[line:272] - INFO: epoch 002:     12 / 1732 loss=3.257, loss_v1=0, loss_v2=0, nll_loss=2.238, ntokens=1057.9, nsentences=32, sample_size=1057.9, sample_size_v1=0, sample_size_v2=0, ppl=4.72, wps=272.9, ups=0.26, wpb=1057.9, bsz=32, num_updates=1740, lr=5.58229e-06, gnorm=7.39, clip=100, loss_scale=64, train_wall=39, gb_free=8.8, wall=6732
2023-05-20 19:50:13 - progress_bar.py[line:272] - INFO: epoch 002:     22 / 1732 loss=3.082, loss_v1=0, loss_v2=0, nll_loss=2.036, ntokens=1106.7, nsentences=32, sample_size=1106.7, sample_size_v1=0, sample_size_v2=0, ppl=4.1, wps=285.1, ups=0.26, wpb=1106.7, bsz=32, num_updates=1750, lr=5.61437e-06, gnorm=6.537, clip=100, loss_scale=64, train_wall=39, gb_free=8.5, wall=6771
2023-05-20 19:50:52 - progress_bar.py[line:272] - INFO: epoch 002:     32 / 1732 loss=3.156, loss_v1=0, loss_v2=0, nll_loss=2.11, ntokens=985.4, nsentences=32, sample_size=985.4, sample_size_v1=0, sample_size_v2=0, ppl=4.32, wps=253.7, ups=0.26, wpb=985.4, bsz=32, num_updates=1760, lr=5.64645e-06, gnorm=7.082, clip=100, loss_scale=64, train_wall=39, gb_free=7.6, wall=6809
2023-05-20 19:51:31 - progress_bar.py[line:272] - INFO: epoch 002:     42 / 1732 loss=2.952, loss_v1=0, loss_v2=0, nll_loss=1.88, ntokens=1168.8, nsentences=32, sample_size=1168.8, sample_size_v1=0, sample_size_v2=0, ppl=3.68, wps=298.7, ups=0.26, wpb=1168.8, bsz=32, num_updates=1770, lr=5.67854e-06, gnorm=5.789, clip=100, loss_scale=64, train_wall=39, gb_free=8.7, wall=6849
2023-05-20 19:52:10 - progress_bar.py[line:272] - INFO: epoch 002:     52 / 1732 loss=3.113, loss_v1=0, loss_v2=0, nll_loss=2.059, ntokens=1030.1, nsentences=32, sample_size=1030.1, sample_size_v1=0, sample_size_v2=0, ppl=4.17, wps=265.7, ups=0.26, wpb=1030.1, bsz=32, num_updates=1780, lr=5.71062e-06, gnorm=6.751, clip=100, loss_scale=64, train_wall=39, gb_free=8.8, wall=6887
2023-05-20 19:52:49 - progress_bar.py[line:272] - INFO: epoch 002:     62 / 1732 loss=2.608, loss_v1=0, loss_v2=0, nll_loss=1.486, ntokens=1192.6, nsentences=32, sample_size=1192.6, sample_size_v1=0, sample_size_v2=0, ppl=2.8, wps=305.2, ups=0.26, wpb=1192.6, bsz=32, num_updates=1790, lr=5.7427e-06, gnorm=6.082, clip=100, loss_scale=64, train_wall=39, gb_free=7.3, wall=6926
2023-05-20 19:53:30 - progress_bar.py[line:272] - INFO: epoch 002:     72 / 1732 loss=2.899, loss_v1=0, loss_v2=0, nll_loss=1.817, ntokens=1389.6, nsentences=32, sample_size=1389.6, sample_size_v1=0, sample_size_v2=0, ppl=3.52, wps=344.1, ups=0.25, wpb=1389.6, bsz=32, num_updates=1800, lr=5.77478e-06, gnorm=5.918, clip=100, loss_scale=64, train_wall=40, gb_free=7.4, wall=6967
2023-05-20 19:54:09 - progress_bar.py[line:272] - INFO: epoch 002:     82 / 1732 loss=3.009, loss_v1=0, loss_v2=0, nll_loss=1.935, ntokens=1199, nsentences=32, sample_size=1199, sample_size_v1=0, sample_size_v2=0, ppl=3.82, wps=303.5, ups=0.25, wpb=1199, bsz=32, num_updates=1810, lr=5.80687e-06, gnorm=6.119, clip=100, loss_scale=64, train_wall=39, gb_free=8, wall=7006
2023-05-20 19:54:48 - progress_bar.py[line:272] - INFO: epoch 002:     92 / 1732 loss=3.029, loss_v1=0, loss_v2=0, nll_loss=1.964, ntokens=1081.9, nsentences=32, sample_size=1081.9, sample_size_v1=0, sample_size_v2=0, ppl=3.9, wps=276.6, ups=0.26, wpb=1081.9, bsz=32, num_updates=1820, lr=5.83895e-06, gnorm=6.25, clip=100, loss_scale=64, train_wall=39, gb_free=8.3, wall=7045
2023-05-20 19:55:27 - progress_bar.py[line:272] - INFO: epoch 002:    102 / 1732 loss=3.189, loss_v1=0, loss_v2=0, nll_loss=2.144, ntokens=1017.7, nsentences=32, sample_size=1017.7, sample_size_v1=0, sample_size_v2=0, ppl=4.42, wps=265.1, ups=0.26, wpb=1017.7, bsz=32, num_updates=1830, lr=5.87103e-06, gnorm=6.172, clip=100, loss_scale=64, train_wall=38, gb_free=8.3, wall=7084
2023-05-20 19:56:05 - progress_bar.py[line:272] - INFO: epoch 002:    112 / 1732 loss=3.299, loss_v1=0, loss_v2=0, nll_loss=2.271, ntokens=1026.3, nsentences=32, sample_size=1026.3, sample_size_v1=0, sample_size_v2=0, ppl=4.83, wps=266.1, ups=0.26, wpb=1026.3, bsz=32, num_updates=1840, lr=5.90311e-06, gnorm=5.663, clip=100, loss_scale=64, train_wall=39, gb_free=7.2, wall=7122
2023-05-20 19:56:44 - progress_bar.py[line:272] - INFO: epoch 002:    122 / 1732 loss=3.192, loss_v1=0, loss_v2=0, nll_loss=2.149, ntokens=1103.7, nsentences=32, sample_size=1103.7, sample_size_v1=0, sample_size_v2=0, ppl=4.44, wps=281.4, ups=0.25, wpb=1103.7, bsz=32, num_updates=1850, lr=5.93519e-06, gnorm=4.908, clip=100, loss_scale=64, train_wall=39, gb_free=7.8, wall=7162
2023-05-20 19:57:24 - progress_bar.py[line:272] - INFO: epoch 002:    132 / 1732 loss=3.114, loss_v1=0, loss_v2=0, nll_loss=2.054, ntokens=1224.5, nsentences=32, sample_size=1224.5, sample_size_v1=0, sample_size_v2=0, ppl=4.15, wps=310.2, ups=0.25, wpb=1224.5, bsz=32, num_updates=1860, lr=5.96728e-06, gnorm=4.504, clip=100, loss_scale=64, train_wall=39, gb_free=7.8, wall=7201
2023-05-20 19:58:03 - progress_bar.py[line:272] - INFO: epoch 002:    142 / 1732 loss=3.091, loss_v1=0, loss_v2=0, nll_loss=2.032, ntokens=1223.2, nsentences=32, sample_size=1223.2, sample_size_v1=0, sample_size_v2=0, ppl=4.09, wps=310.4, ups=0.25, wpb=1223.2, bsz=32, num_updates=1870, lr=5.99936e-06, gnorm=4.753, clip=100, loss_scale=64, train_wall=39, gb_free=7.8, wall=7241
2023-05-20 19:58:43 - progress_bar.py[line:272] - INFO: epoch 002:    152 / 1732 loss=3.053, loss_v1=0, loss_v2=0, nll_loss=1.987, ntokens=1158.5, nsentences=32, sample_size=1158.5, sample_size_v1=0, sample_size_v2=0, ppl=3.96, wps=292.5, ups=0.25, wpb=1158.5, bsz=32, num_updates=1880, lr=6.03144e-06, gnorm=4.856, clip=100, loss_scale=64, train_wall=40, gb_free=7.8, wall=7280
2023-05-20 19:59:22 - progress_bar.py[line:272] - INFO: epoch 002:    162 / 1732 loss=3.045, loss_v1=0, loss_v2=0, nll_loss=1.98, ntokens=1101.3, nsentences=32, sample_size=1101.3, sample_size_v1=0, sample_size_v2=0, ppl=3.94, wps=279.9, ups=0.25, wpb=1101.3, bsz=32, num_updates=1890, lr=6.06352e-06, gnorm=4.803, clip=100, loss_scale=64, train_wall=39, gb_free=8.2, wall=7320
2023-05-20 20:00:01 - progress_bar.py[line:272] - INFO: epoch 002:    172 / 1732 loss=3.05, loss_v1=0, loss_v2=0, nll_loss=1.983, ntokens=937.9, nsentences=32, sample_size=937.9, sample_size_v1=0, sample_size_v2=0, ppl=3.95, wps=242.9, ups=0.26, wpb=937.9, bsz=32, num_updates=1900, lr=6.0956e-06, gnorm=5.162, clip=100, loss_scale=64, train_wall=39, gb_free=8.3, wall=7358
2023-05-20 20:00:40 - progress_bar.py[line:272] - INFO: epoch 002:    182 / 1732 loss=2.982, loss_v1=0, loss_v2=0, nll_loss=1.906, ntokens=1177.8, nsentences=32, sample_size=1177.8, sample_size_v1=0, sample_size_v2=0, ppl=3.75, wps=298.5, ups=0.25, wpb=1177.8, bsz=32, num_updates=1910, lr=6.12769e-06, gnorm=5.478, clip=100, loss_scale=64, train_wall=39, gb_free=8.1, wall=7398
2023-05-20 20:01:20 - progress_bar.py[line:272] - INFO: epoch 002:    192 / 1732 loss=3.051, loss_v1=0, loss_v2=0, nll_loss=1.984, ntokens=1116, nsentences=32, sample_size=1116, sample_size_v1=0, sample_size_v2=0, ppl=3.95, wps=284.8, ups=0.26, wpb=1116, bsz=32, num_updates=1920, lr=6.15977e-06, gnorm=5.486, clip=100, loss_scale=64, train_wall=39, gb_free=7.7, wall=7437
2023-05-20 20:01:59 - progress_bar.py[line:272] - INFO: epoch 002:    202 / 1732 loss=3.109, loss_v1=0, loss_v2=0, nll_loss=2.05, ntokens=1088.7, nsentences=32, sample_size=1088.7, sample_size_v1=0, sample_size_v2=0, ppl=4.14, wps=279.2, ups=0.26, wpb=1088.7, bsz=32, num_updates=1930, lr=6.19185e-06, gnorm=5.571, clip=100, loss_scale=64, train_wall=39, gb_free=7.8, wall=7476
2023-05-20 20:02:37 - progress_bar.py[line:272] - INFO: epoch 002:    212 / 1732 loss=3.209, loss_v1=0, loss_v2=0, nll_loss=2.164, ntokens=1014.1, nsentences=32, sample_size=1014.1, sample_size_v1=0, sample_size_v2=0, ppl=4.48, wps=262.9, ups=0.26, wpb=1014.1, bsz=32, num_updates=1940, lr=6.22393e-06, gnorm=5.093, clip=100, loss_scale=64, train_wall=39, gb_free=8.1, wall=7514
2023-05-20 20:03:16 - progress_bar.py[line:272] - INFO: epoch 002:    222 / 1732 loss=3.204, loss_v1=0, loss_v2=0, nll_loss=2.158, ntokens=1144.1, nsentences=32, sample_size=1144.1, sample_size_v1=0, sample_size_v2=0, ppl=4.46, wps=297, ups=0.26, wpb=1144.1, bsz=32, num_updates=1950, lr=6.25602e-06, gnorm=5.267, clip=100, loss_scale=64, train_wall=38, gb_free=7.9, wall=7553
2023-05-20 20:03:54 - progress_bar.py[line:272] - INFO: epoch 002:    232 / 1732 loss=3.255, loss_v1=0, loss_v2=0, nll_loss=2.216, ntokens=1097.8, nsentences=32, sample_size=1097.8, sample_size_v1=0, sample_size_v2=0, ppl=4.65, wps=286.8, ups=0.26, wpb=1097.8, bsz=32, num_updates=1960, lr=6.2881e-06, gnorm=4.978, clip=100, loss_scale=64, train_wall=38, gb_free=8.4, wall=7591
2023-05-20 20:04:33 - progress_bar.py[line:272] - INFO: epoch 002:    242 / 1732 loss=3.234, loss_v1=0, loss_v2=0, nll_loss=2.188, ntokens=1115.1, nsentences=32, sample_size=1115.1, sample_size_v1=0, sample_size_v2=0, ppl=4.56, wps=289.4, ups=0.26, wpb=1115.1, bsz=32, num_updates=1970, lr=6.32018e-06, gnorm=5.04, clip=100, loss_scale=64, train_wall=38, gb_free=8, wall=7630
2023-05-20 20:05:11 - progress_bar.py[line:272] - INFO: epoch 002:    252 / 1732 loss=3.212, loss_v1=0, loss_v2=0, nll_loss=2.165, ntokens=1167.7, nsentences=32, sample_size=1167.7, sample_size_v1=0, sample_size_v2=0, ppl=4.49, wps=303.2, ups=0.26, wpb=1167.7, bsz=32, num_updates=1980, lr=6.35226e-06, gnorm=5.013, clip=100, loss_scale=64, train_wall=38, gb_free=8.4, wall=7668
2023-05-20 20:05:49 - progress_bar.py[line:272] - INFO: epoch 002:    262 / 1732 loss=3.204, loss_v1=0, loss_v2=0, nll_loss=2.159, ntokens=1134.1, nsentences=32, sample_size=1134.1, sample_size_v1=0, sample_size_v2=0, ppl=4.47, wps=296, ups=0.26, wpb=1134.1, bsz=32, num_updates=1990, lr=6.38434e-06, gnorm=5.344, clip=100, loss_scale=64, train_wall=38, gb_free=8.5, wall=7707
2023-05-20 20:06:28 - progress_bar.py[line:272] - INFO: epoch 002:    272 / 1732 loss=3.165, loss_v1=0, loss_v2=0, nll_loss=2.114, ntokens=1139, nsentences=32, sample_size=1139, sample_size_v1=0, sample_size_v2=0, ppl=4.33, wps=297, ups=0.26, wpb=1139, bsz=32, num_updates=2000, lr=6.41643e-06, gnorm=5.06, clip=100, loss_scale=64, train_wall=38, gb_free=8.9, wall=7745
2023-05-20 20:07:06 - progress_bar.py[line:272] - INFO: epoch 002:    282 / 1732 loss=3.18, loss_v1=0, loss_v2=0, nll_loss=2.126, ntokens=1161.5, nsentences=32, sample_size=1161.5, sample_size_v1=0, sample_size_v2=0, ppl=4.36, wps=300.2, ups=0.26, wpb=1161.5, bsz=32, num_updates=2010, lr=6.44851e-06, gnorm=4.965, clip=100, loss_scale=64, train_wall=39, gb_free=7.8, wall=7784
2023-05-20 20:07:45 - progress_bar.py[line:272] - INFO: epoch 002:    292 / 1732 loss=3.139, loss_v1=0, loss_v2=0, nll_loss=2.084, ntokens=1114.9, nsentences=32, sample_size=1114.9, sample_size_v1=0, sample_size_v2=0, ppl=4.24, wps=290.7, ups=0.26, wpb=1114.9, bsz=32, num_updates=2020, lr=6.48059e-06, gnorm=5.336, clip=100, loss_scale=64, train_wall=38, gb_free=8.6, wall=7822
2023-05-20 20:08:23 - progress_bar.py[line:272] - INFO: epoch 002:    302 / 1732 loss=3.183, loss_v1=0, loss_v2=0, nll_loss=2.13, ntokens=1109.4, nsentences=32, sample_size=1109.4, sample_size_v1=0, sample_size_v2=0, ppl=4.38, wps=289.6, ups=0.26, wpb=1109.4, bsz=32, num_updates=2030, lr=6.51267e-06, gnorm=4.972, clip=100, loss_scale=64, train_wall=38, gb_free=8.8, wall=7860
2023-05-20 20:09:02 - progress_bar.py[line:272] - INFO: epoch 002:    312 / 1732 loss=3.115, loss_v1=0, loss_v2=0, nll_loss=2.055, ntokens=1061.9, nsentences=32, sample_size=1061.9, sample_size_v1=0, sample_size_v2=0, ppl=4.16, wps=275.8, ups=0.26, wpb=1061.9, bsz=32, num_updates=2040, lr=6.54475e-06, gnorm=5.167, clip=100, loss_scale=64, train_wall=38, gb_free=8.6, wall=7899
2023-05-20 20:09:40 - progress_bar.py[line:272] - INFO: epoch 002:    322 / 1732 loss=3.164, loss_v1=0, loss_v2=0, nll_loss=2.108, ntokens=1000.1, nsentences=32, sample_size=1000.1, sample_size_v1=0, sample_size_v2=0, ppl=4.31, wps=262.9, ups=0.26, wpb=1000.1, bsz=32, num_updates=2050, lr=6.57684e-06, gnorm=5.296, clip=100, loss_scale=64, train_wall=38, gb_free=8.5, wall=7937
2023-05-20 20:10:18 - progress_bar.py[line:272] - INFO: epoch 002:    332 / 1732 loss=3.126, loss_v1=0, loss_v2=0, nll_loss=2.062, ntokens=1031.9, nsentences=32, sample_size=1031.9, sample_size_v1=0, sample_size_v2=0, ppl=4.18, wps=269.3, ups=0.26, wpb=1031.9, bsz=32, num_updates=2060, lr=6.60892e-06, gnorm=5.191, clip=100, loss_scale=64, train_wall=38, gb_free=8.5, wall=7975
2023-05-20 20:10:56 - progress_bar.py[line:272] - INFO: epoch 002:    342 / 1732 loss=3.092, loss_v1=0, loss_v2=0, nll_loss=2.028, ntokens=926.6, nsentences=32, sample_size=926.6, sample_size_v1=0, sample_size_v2=0, ppl=4.08, wps=243.2, ups=0.26, wpb=926.6, bsz=32, num_updates=2070, lr=6.641e-06, gnorm=5.22, clip=100, loss_scale=64, train_wall=38, gb_free=9.1, wall=8013
2023-05-20 20:11:34 - progress_bar.py[line:272] - INFO: epoch 002:    352 / 1732 loss=3.113, loss_v1=0, loss_v2=0, nll_loss=2.049, ntokens=952.9, nsentences=32, sample_size=952.9, sample_size_v1=0, sample_size_v2=0, ppl=4.14, wps=250.5, ups=0.26, wpb=952.9, bsz=32, num_updates=2080, lr=6.67308e-06, gnorm=5.318, clip=100, loss_scale=64, train_wall=38, gb_free=9, wall=8051
2023-05-20 20:12:12 - progress_bar.py[line:272] - INFO: epoch 002:    362 / 1732 loss=3.111, loss_v1=0, loss_v2=0, nll_loss=2.045, ntokens=940.7, nsentences=32, sample_size=940.7, sample_size_v1=0, sample_size_v2=0, ppl=4.13, wps=247, ups=0.26, wpb=940.7, bsz=32, num_updates=2090, lr=6.70517e-06, gnorm=5.67, clip=100, loss_scale=128, train_wall=38, gb_free=8.5, wall=8089
2023-05-20 20:12:50 - progress_bar.py[line:272] - INFO: epoch 002:    372 / 1732 loss=3.121, loss_v1=0, loss_v2=0, nll_loss=2.061, ntokens=975.5, nsentences=32, sample_size=975.5, sample_size_v1=0, sample_size_v2=0, ppl=4.17, wps=256.7, ups=0.26, wpb=975.5, bsz=32, num_updates=2100, lr=6.73725e-06, gnorm=5.523, clip=100, loss_scale=128, train_wall=38, gb_free=8.9, wall=8127
2023-05-20 20:13:28 - progress_bar.py[line:272] - INFO: epoch 002:    382 / 1732 loss=3.1, loss_v1=0, loss_v2=0, nll_loss=2.031, ntokens=1062, nsentences=32, sample_size=1062, sample_size_v1=0, sample_size_v2=0, ppl=4.09, wps=279.1, ups=0.26, wpb=1062, bsz=32, num_updates=2110, lr=6.76933e-06, gnorm=4.929, clip=100, loss_scale=128, train_wall=38, gb_free=8.4, wall=8165
2023-05-20 20:14:06 - progress_bar.py[line:272] - INFO: epoch 002:    392 / 1732 loss=3.062, loss_v1=0, loss_v2=0, nll_loss=1.988, ntokens=1004.1, nsentences=32, sample_size=1004.1, sample_size_v1=0, sample_size_v2=0, ppl=3.97, wps=264.1, ups=0.26, wpb=1004.1, bsz=32, num_updates=2120, lr=6.80141e-06, gnorm=5.279, clip=100, loss_scale=128, train_wall=38, gb_free=9.1, wall=8203
2023-05-20 20:14:44 - progress_bar.py[line:272] - INFO: epoch 002:    402 / 1732 loss=3.026, loss_v1=0, loss_v2=0, nll_loss=1.949, ntokens=1005.2, nsentences=32, sample_size=1005.2, sample_size_v1=0, sample_size_v2=0, ppl=3.86, wps=263.7, ups=0.26, wpb=1005.2, bsz=32, num_updates=2130, lr=6.83349e-06, gnorm=5.158, clip=100, loss_scale=128, train_wall=38, gb_free=8.5, wall=8242
2023-05-20 20:15:23 - progress_bar.py[line:272] - INFO: epoch 002:    412 / 1732 loss=3.045, loss_v1=0, loss_v2=0, nll_loss=1.971, ntokens=1091.2, nsentences=32, sample_size=1091.2, sample_size_v1=0, sample_size_v2=0, ppl=3.92, wps=285.3, ups=0.26, wpb=1091.2, bsz=32, num_updates=2140, lr=6.86558e-06, gnorm=4.98, clip=100, loss_scale=128, train_wall=38, gb_free=8.4, wall=8280
2023-05-20 20:16:01 - progress_bar.py[line:272] - INFO: epoch 002:    422 / 1732 loss=3.048, loss_v1=0, loss_v2=0, nll_loss=1.968, ntokens=1011.2, nsentences=32, sample_size=1011.2, sample_size_v1=0, sample_size_v2=0, ppl=3.91, wps=264.3, ups=0.26, wpb=1011.2, bsz=32, num_updates=2150, lr=6.89766e-06, gnorm=5.126, clip=100, loss_scale=128, train_wall=38, gb_free=8.1, wall=8318
2023-05-20 20:16:39 - progress_bar.py[line:272] - INFO: epoch 002:    432 / 1732 loss=3.049, loss_v1=0, loss_v2=0, nll_loss=1.974, ntokens=1006.8, nsentences=32, sample_size=1006.8, sample_size_v1=0, sample_size_v2=0, ppl=3.93, wps=264.6, ups=0.26, wpb=1006.8, bsz=32, num_updates=2160, lr=6.92974e-06, gnorm=5.882, clip=100, loss_scale=128, train_wall=38, gb_free=9, wall=8356
2023-05-20 20:17:17 - progress_bar.py[line:272] - INFO: epoch 002:    442 / 1732 loss=3.065, loss_v1=0, loss_v2=0, nll_loss=1.991, ntokens=979.7, nsentences=32, sample_size=979.7, sample_size_v1=0, sample_size_v2=0, ppl=3.97, wps=257.2, ups=0.26, wpb=979.7, bsz=32, num_updates=2170, lr=6.96182e-06, gnorm=5.593, clip=100, loss_scale=128, train_wall=38, gb_free=8.2, wall=8394
2023-05-20 20:17:55 - progress_bar.py[line:272] - INFO: epoch 002:    452 / 1732 loss=3.04, loss_v1=0, loss_v2=0, nll_loss=1.965, ntokens=913.2, nsentences=32, sample_size=913.2, sample_size_v1=0, sample_size_v2=0, ppl=3.9, wps=240.1, ups=0.26, wpb=913.2, bsz=32, num_updates=2180, lr=6.9939e-06, gnorm=5.956, clip=100, loss_scale=128, train_wall=38, gb_free=9.2, wall=8432
2023-05-20 20:18:33 - progress_bar.py[line:272] - INFO: epoch 002:    462 / 1732 loss=3.038, loss_v1=0, loss_v2=0, nll_loss=1.959, ntokens=1070.3, nsentences=32, sample_size=1070.3, sample_size_v1=0, sample_size_v2=0, ppl=3.89, wps=280.9, ups=0.26, wpb=1070.3, bsz=32, num_updates=2190, lr=7.02599e-06, gnorm=4.692, clip=100, loss_scale=128, train_wall=38, gb_free=8.2, wall=8470
2023-05-20 20:19:11 - progress_bar.py[line:272] - INFO: epoch 002:    472 / 1732 loss=3.017, loss_v1=0, loss_v2=0, nll_loss=1.934, ntokens=1036.2, nsentences=32, sample_size=1036.2, sample_size_v1=0, sample_size_v2=0, ppl=3.82, wps=271, ups=0.26, wpb=1036.2, bsz=32, num_updates=2200, lr=7.05807e-06, gnorm=4.811, clip=100, loss_scale=128, train_wall=38, gb_free=8.2, wall=8509
2023-05-20 20:19:49 - progress_bar.py[line:272] - INFO: epoch 002:    482 / 1732 loss=3.032, loss_v1=0, loss_v2=0, nll_loss=1.954, ntokens=990.8, nsentences=32, sample_size=990.8, sample_size_v1=0, sample_size_v2=0, ppl=3.88, wps=261.1, ups=0.26, wpb=990.8, bsz=32, num_updates=2210, lr=7.09015e-06, gnorm=5.361, clip=100, loss_scale=128, train_wall=38, gb_free=9.1, wall=8547
2023-05-20 20:20:28 - progress_bar.py[line:272] - INFO: epoch 002:    492 / 1732 loss=2.999, loss_v1=0, loss_v2=0, nll_loss=1.913, ntokens=948.5, nsentences=32, sample_size=948.5, sample_size_v1=0, sample_size_v2=0, ppl=3.77, wps=249, ups=0.26, wpb=948.5, bsz=32, num_updates=2220, lr=7.12223e-06, gnorm=5.133, clip=100, loss_scale=128, train_wall=38, gb_free=8.3, wall=8585
2023-05-20 20:21:05 - progress_bar.py[line:272] - INFO: epoch 002:    502 / 1732 loss=2.963, loss_v1=0, loss_v2=0, nll_loss=1.873, ntokens=961.7, nsentences=32, sample_size=961.7, sample_size_v1=0, sample_size_v2=0, ppl=3.66, wps=254.9, ups=0.27, wpb=961.7, bsz=32, num_updates=2230, lr=7.15432e-06, gnorm=5.421, clip=100, loss_scale=128, train_wall=38, gb_free=8.8, wall=8622
2023-05-20 20:21:43 - progress_bar.py[line:272] - INFO: epoch 002:    512 / 1732 loss=3.015, loss_v1=0, loss_v2=0, nll_loss=1.932, ntokens=1041.1, nsentences=32, sample_size=1041.1, sample_size_v1=0, sample_size_v2=0, ppl=3.82, wps=272.5, ups=0.26, wpb=1041.1, bsz=32, num_updates=2240, lr=7.1864e-06, gnorm=5.077, clip=100, loss_scale=128, train_wall=38, gb_free=7.9, wall=8661
2023-05-20 20:22:21 - progress_bar.py[line:272] - INFO: epoch 002:    522 / 1732 loss=2.973, loss_v1=0, loss_v2=0, nll_loss=1.883, ntokens=995.3, nsentences=32, sample_size=995.3, sample_size_v1=0, sample_size_v2=0, ppl=3.69, wps=263, ups=0.26, wpb=995.3, bsz=32, num_updates=2250, lr=7.21848e-06, gnorm=4.779, clip=100, loss_scale=128, train_wall=38, gb_free=8.9, wall=8698
2023-05-20 20:22:59 - progress_bar.py[line:272] - INFO: epoch 002:    532 / 1732 loss=2.979, loss_v1=0, loss_v2=0, nll_loss=1.891, ntokens=942.5, nsentences=32, sample_size=942.5, sample_size_v1=0, sample_size_v2=0, ppl=3.71, wps=250.3, ups=0.27, wpb=942.5, bsz=32, num_updates=2260, lr=7.25056e-06, gnorm=5.647, clip=100, loss_scale=128, train_wall=38, gb_free=9.2, wall=8736
2023-05-20 20:23:37 - progress_bar.py[line:272] - INFO: epoch 002:    542 / 1732 loss=2.976, loss_v1=0, loss_v2=0, nll_loss=1.886, ntokens=994, nsentences=32, sample_size=994, sample_size_v1=0, sample_size_v2=0, ppl=3.7, wps=261.8, ups=0.26, wpb=994, bsz=32, num_updates=2270, lr=7.28264e-06, gnorm=5.129, clip=100, loss_scale=128, train_wall=38, gb_free=8.2, wall=8774
2023-05-20 20:24:15 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2023-05-20 20:24:19 - progress_bar.py[line:272] - INFO: epoch 002:    553 / 1732 loss=2.991, loss_v1=0, loss_v2=0, nll_loss=1.899, ntokens=1010.4, nsentences=32, sample_size=1010.4, sample_size_v1=0, sample_size_v2=0, ppl=3.73, wps=241.1, ups=0.24, wpb=1010.4, bsz=32, num_updates=2280, lr=7.31473e-06, gnorm=4.965, clip=100, loss_scale=64, train_wall=42, gb_free=8.3, wall=8816
2023-05-20 20:24:57 - progress_bar.py[line:272] - INFO: epoch 002:    563 / 1732 loss=2.965, loss_v1=0, loss_v2=0, nll_loss=1.875, ntokens=1008.2, nsentences=32, sample_size=1008.2, sample_size_v1=0, sample_size_v2=0, ppl=3.67, wps=264.9, ups=0.26, wpb=1008.2, bsz=32, num_updates=2290, lr=7.34681e-06, gnorm=5.328, clip=100, loss_scale=64, train_wall=38, gb_free=9.3, wall=8854
2023-05-20 20:25:35 - progress_bar.py[line:272] - INFO: epoch 002:    573 / 1732 loss=2.986, loss_v1=0, loss_v2=0, nll_loss=1.896, ntokens=1041.3, nsentences=32, sample_size=1041.3, sample_size_v1=0, sample_size_v2=0, ppl=3.72, wps=272.6, ups=0.26, wpb=1041.3, bsz=32, num_updates=2300, lr=7.37889e-06, gnorm=5.422, clip=100, loss_scale=64, train_wall=38, gb_free=8.1, wall=8892
2023-05-20 20:26:13 - progress_bar.py[line:272] - INFO: epoch 002:    583 / 1732 loss=2.987, loss_v1=0, loss_v2=0, nll_loss=1.898, ntokens=981.7, nsentences=32, sample_size=981.7, sample_size_v1=0, sample_size_v2=0, ppl=3.73, wps=256.1, ups=0.26, wpb=981.7, bsz=32, num_updates=2310, lr=7.41097e-06, gnorm=5.302, clip=100, loss_scale=64, train_wall=38, gb_free=9, wall=8931
2023-05-20 20:26:52 - progress_bar.py[line:272] - INFO: epoch 002:    593 / 1732 loss=2.935, loss_v1=0, loss_v2=0, nll_loss=1.838, ntokens=957.4, nsentences=32, sample_size=957.4, sample_size_v1=0, sample_size_v2=0, ppl=3.58, wps=249.4, ups=0.26, wpb=957.4, bsz=32, num_updates=2320, lr=7.44305e-06, gnorm=5.229, clip=100, loss_scale=64, train_wall=38, gb_free=8.9, wall=8969
2023-05-20 20:27:30 - progress_bar.py[line:272] - INFO: epoch 002:    603 / 1732 loss=2.951, loss_v1=0, loss_v2=0, nll_loss=1.858, ntokens=911.2, nsentences=32, sample_size=911.2, sample_size_v1=0, sample_size_v2=0, ppl=3.62, wps=241.1, ups=0.26, wpb=911.2, bsz=32, num_updates=2330, lr=7.47514e-06, gnorm=4.943, clip=100, loss_scale=64, train_wall=38, gb_free=8.7, wall=9007
2023-05-20 20:28:08 - progress_bar.py[line:272] - INFO: epoch 002:    613 / 1732 loss=2.929, loss_v1=0, loss_v2=0, nll_loss=1.831, ntokens=893.3, nsentences=32, sample_size=893.3, sample_size_v1=0, sample_size_v2=0, ppl=3.56, wps=234.8, ups=0.26, wpb=893.3, bsz=32, num_updates=2340, lr=7.50722e-06, gnorm=5.827, clip=100, loss_scale=64, train_wall=38, gb_free=9.1, wall=9045
2023-05-20 20:28:45 - progress_bar.py[line:272] - INFO: epoch 002:    623 / 1732 loss=2.955, loss_v1=0, loss_v2=0, nll_loss=1.861, ntokens=887.2, nsentences=32, sample_size=887.2, sample_size_v1=0, sample_size_v2=0, ppl=3.63, wps=235, ups=0.26, wpb=887.2, bsz=32, num_updates=2350, lr=7.5393e-06, gnorm=5.436, clip=100, loss_scale=64, train_wall=38, gb_free=8.3, wall=9083
2023-05-20 20:29:23 - progress_bar.py[line:272] - INFO: epoch 002:    633 / 1732 loss=2.955, loss_v1=0, loss_v2=0, nll_loss=1.86, ntokens=925, nsentences=32, sample_size=925, sample_size_v1=0, sample_size_v2=0, ppl=3.63, wps=244.5, ups=0.26, wpb=925, bsz=32, num_updates=2360, lr=7.57138e-06, gnorm=5.646, clip=100, loss_scale=64, train_wall=38, gb_free=8.7, wall=9120
2023-05-20 20:30:01 - progress_bar.py[line:272] - INFO: epoch 002:    643 / 1732 loss=2.932, loss_v1=0, loss_v2=0, nll_loss=1.836, ntokens=963.8, nsentences=32, sample_size=963.8, sample_size_v1=0, sample_size_v2=0, ppl=3.57, wps=254.6, ups=0.26, wpb=963.8, bsz=32, num_updates=2370, lr=7.60346e-06, gnorm=5.392, clip=100, loss_scale=64, train_wall=38, gb_free=9, wall=9158
2023-05-20 20:30:39 - progress_bar.py[line:272] - INFO: epoch 002:    653 / 1732 loss=2.941, loss_v1=0, loss_v2=0, nll_loss=1.843, ntokens=928, nsentences=32, sample_size=928, sample_size_v1=0, sample_size_v2=0, ppl=3.59, wps=245.3, ups=0.26, wpb=928, bsz=32, num_updates=2380, lr=7.63555e-06, gnorm=5.634, clip=100, loss_scale=64, train_wall=38, gb_free=9.1, wall=9196
2023-05-20 20:31:17 - progress_bar.py[line:272] - INFO: epoch 002:    663 / 1732 loss=2.944, loss_v1=0, loss_v2=0, nll_loss=1.847, ntokens=882.9, nsentences=32, sample_size=882.9, sample_size_v1=0, sample_size_v2=0, ppl=3.6, wps=233, ups=0.26, wpb=882.9, bsz=32, num_updates=2390, lr=7.66763e-06, gnorm=6.015, clip=100, loss_scale=64, train_wall=38, gb_free=8.8, wall=9234
2023-05-20 20:31:55 - progress_bar.py[line:272] - INFO: epoch 002:    673 / 1732 loss=2.944, loss_v1=0, loss_v2=0, nll_loss=1.847, ntokens=954.3, nsentences=32, sample_size=954.3, sample_size_v1=0, sample_size_v2=0, ppl=3.6, wps=251.1, ups=0.26, wpb=954.3, bsz=32, num_updates=2400, lr=7.69971e-06, gnorm=5.438, clip=100, loss_scale=64, train_wall=38, gb_free=9, wall=9272
2023-05-20 20:32:33 - progress_bar.py[line:272] - INFO: epoch 002:    683 / 1732 loss=2.904, loss_v1=0, loss_v2=0, nll_loss=1.801, ntokens=960.5, nsentences=32, sample_size=960.5, sample_size_v1=0, sample_size_v2=0, ppl=3.48, wps=252.7, ups=0.26, wpb=960.5, bsz=32, num_updates=2410, lr=7.73179e-06, gnorm=5.3, clip=100, loss_scale=64, train_wall=38, gb_free=9.2, wall=9310
2023-05-20 20:33:11 - progress_bar.py[line:272] - INFO: epoch 002:    693 / 1732 loss=2.95, loss_v1=0, loss_v2=0, nll_loss=1.853, ntokens=962.9, nsentences=32, sample_size=962.9, sample_size_v1=0, sample_size_v2=0, ppl=3.61, wps=252.6, ups=0.26, wpb=962.9, bsz=32, num_updates=2420, lr=7.76388e-06, gnorm=5.583, clip=100, loss_scale=64, train_wall=38, gb_free=8.3, wall=9348
2023-05-20 20:33:49 - progress_bar.py[line:272] - INFO: epoch 002:    703 / 1732 loss=2.861, loss_v1=0, loss_v2=0, nll_loss=1.752, ntokens=972.9, nsentences=32, sample_size=972.9, sample_size_v1=0, sample_size_v2=0, ppl=3.37, wps=255.7, ups=0.26, wpb=972.9, bsz=32, num_updates=2430, lr=7.79596e-06, gnorm=5.076, clip=100, loss_scale=64, train_wall=38, gb_free=8.9, wall=9386
2023-05-20 20:34:27 - progress_bar.py[line:272] - INFO: epoch 002:    713 / 1732 loss=2.935, loss_v1=0, loss_v2=0, nll_loss=1.836, ntokens=898.6, nsentences=32, sample_size=898.6, sample_size_v1=0, sample_size_v2=0, ppl=3.57, wps=236.9, ups=0.26, wpb=898.6, bsz=32, num_updates=2440, lr=7.82804e-06, gnorm=5.227, clip=100, loss_scale=64, train_wall=38, gb_free=9.1, wall=9424
2023-05-20 20:35:05 - progress_bar.py[line:272] - INFO: epoch 002:    723 / 1732 loss=2.899, loss_v1=0, loss_v2=0, nll_loss=1.794, ntokens=877.5, nsentences=32, sample_size=877.5, sample_size_v1=0, sample_size_v2=0, ppl=3.47, wps=231.9, ups=0.26, wpb=877.5, bsz=32, num_updates=2450, lr=7.86012e-06, gnorm=5.543, clip=100, loss_scale=64, train_wall=38, gb_free=9.2, wall=9462
2023-05-20 20:35:43 - progress_bar.py[line:272] - INFO: epoch 002:    733 / 1732 loss=2.875, loss_v1=0, loss_v2=0, nll_loss=1.768, ntokens=959.6, nsentences=32, sample_size=959.6, sample_size_v1=0, sample_size_v2=0, ppl=3.41, wps=252.7, ups=0.26, wpb=959.6, bsz=32, num_updates=2460, lr=7.8922e-06, gnorm=5.028, clip=100, loss_scale=64, train_wall=38, gb_free=8.1, wall=9500
2023-05-20 20:36:21 - progress_bar.py[line:272] - INFO: epoch 002:    743 / 1732 loss=2.891, loss_v1=0, loss_v2=0, nll_loss=1.782, ntokens=991.8, nsentences=32, sample_size=991.8, sample_size_v1=0, sample_size_v2=0, ppl=3.44, wps=261.4, ups=0.26, wpb=991.8, bsz=32, num_updates=2470, lr=7.92429e-06, gnorm=5.352, clip=100, loss_scale=64, train_wall=38, gb_free=8.7, wall=9538
2023-05-20 20:36:59 - progress_bar.py[line:272] - INFO: epoch 002:    753 / 1732 loss=2.894, loss_v1=0, loss_v2=0, nll_loss=1.787, ntokens=968.6, nsentences=32, sample_size=968.6, sample_size_v1=0, sample_size_v2=0, ppl=3.45, wps=253, ups=0.26, wpb=968.6, bsz=32, num_updates=2480, lr=7.95637e-06, gnorm=4.989, clip=100, loss_scale=64, train_wall=38, gb_free=8.7, wall=9576
2023-05-20 20:37:37 - progress_bar.py[line:272] - INFO: epoch 002:    763 / 1732 loss=2.875, loss_v1=0, loss_v2=0, nll_loss=1.769, ntokens=964, nsentences=32, sample_size=964, sample_size_v1=0, sample_size_v2=0, ppl=3.41, wps=254.3, ups=0.26, wpb=964, bsz=32, num_updates=2490, lr=7.98845e-06, gnorm=5.233, clip=100, loss_scale=64, train_wall=38, gb_free=8.8, wall=9614
2023-05-20 20:38:15 - progress_bar.py[line:272] - INFO: epoch 002:    773 / 1732 loss=2.85, loss_v1=0, loss_v2=0, nll_loss=1.737, ntokens=971.7, nsentences=32, sample_size=971.7, sample_size_v1=0, sample_size_v2=0, ppl=3.33, wps=255.6, ups=0.26, wpb=971.7, bsz=32, num_updates=2500, lr=8.02053e-06, gnorm=5.078, clip=100, loss_scale=64, train_wall=38, gb_free=8.8, wall=9652
2023-05-20 20:38:53 - progress_bar.py[line:272] - INFO: epoch 002:    783 / 1732 loss=2.886, loss_v1=0, loss_v2=0, nll_loss=1.776, ntokens=1008.4, nsentences=32, sample_size=1008.4, sample_size_v1=0, sample_size_v2=0, ppl=3.43, wps=265.1, ups=0.26, wpb=1008.4, bsz=32, num_updates=2510, lr=8.05261e-06, gnorm=5.312, clip=100, loss_scale=64, train_wall=38, gb_free=8.4, wall=9690
2023-05-20 20:39:31 - progress_bar.py[line:272] - INFO: epoch 002:    793 / 1732 loss=2.847, loss_v1=0, loss_v2=0, nll_loss=1.732, ntokens=1034.6, nsentences=32, sample_size=1034.6, sample_size_v1=0, sample_size_v2=0, ppl=3.32, wps=271.2, ups=0.26, wpb=1034.6, bsz=32, num_updates=2520, lr=8.0847e-06, gnorm=4.777, clip=100, loss_scale=64, train_wall=38, gb_free=8.8, wall=9728
2023-05-20 20:40:09 - progress_bar.py[line:272] - INFO: epoch 002:    803 / 1732 loss=2.867, loss_v1=0, loss_v2=0, nll_loss=1.755, ntokens=964.4, nsentences=32, sample_size=964.4, sample_size_v1=0, sample_size_v2=0, ppl=3.38, wps=253.8, ups=0.26, wpb=964.4, bsz=32, num_updates=2530, lr=8.11678e-06, gnorm=5.067, clip=100, loss_scale=64, train_wall=38, gb_free=8.1, wall=9766
2023-05-20 20:40:47 - progress_bar.py[line:272] - INFO: epoch 002:    813 / 1732 loss=2.881, loss_v1=0, loss_v2=0, nll_loss=1.769, ntokens=940.9, nsentences=32, sample_size=940.9, sample_size_v1=0, sample_size_v2=0, ppl=3.41, wps=247.7, ups=0.26, wpb=940.9, bsz=32, num_updates=2540, lr=8.14886e-06, gnorm=5.519, clip=100, loss_scale=64, train_wall=38, gb_free=7.6, wall=9804
2023-05-20 20:41:25 - progress_bar.py[line:272] - INFO: epoch 002:    823 / 1732 loss=2.862, loss_v1=0, loss_v2=0, nll_loss=1.748, ntokens=915.1, nsentences=32, sample_size=915.1, sample_size_v1=0, sample_size_v2=0, ppl=3.36, wps=240.8, ups=0.26, wpb=915.1, bsz=32, num_updates=2550, lr=8.18094e-06, gnorm=5.398, clip=100, loss_scale=64, train_wall=38, gb_free=8.3, wall=9842
2023-05-20 20:42:03 - progress_bar.py[line:272] - INFO: epoch 002:    833 / 1732 loss=2.828, loss_v1=0, loss_v2=0, nll_loss=1.711, ntokens=907.5, nsentences=32, sample_size=907.5, sample_size_v1=0, sample_size_v2=0, ppl=3.27, wps=240.3, ups=0.26, wpb=907.5, bsz=32, num_updates=2560, lr=8.21303e-06, gnorm=5.439, clip=100, loss_scale=64, train_wall=38, gb_free=9.1, wall=9880
2023-05-20 20:42:41 - progress_bar.py[line:272] - INFO: epoch 002:    843 / 1732 loss=2.793, loss_v1=0, loss_v2=0, nll_loss=1.667, ntokens=950.7, nsentences=32, sample_size=950.7, sample_size_v1=0, sample_size_v2=0, ppl=3.18, wps=251.2, ups=0.26, wpb=950.7, bsz=32, num_updates=2570, lr=8.24511e-06, gnorm=4.831, clip=100, loss_scale=64, train_wall=38, gb_free=9, wall=9918
2023-05-20 20:43:19 - progress_bar.py[line:272] - INFO: epoch 002:    853 / 1732 loss=2.867, loss_v1=0, loss_v2=0, nll_loss=1.757, ntokens=1006.3, nsentences=32, sample_size=1006.3, sample_size_v1=0, sample_size_v2=0, ppl=3.38, wps=264.4, ups=0.26, wpb=1006.3, bsz=32, num_updates=2580, lr=8.27719e-06, gnorm=4.987, clip=100, loss_scale=64, train_wall=38, gb_free=8.3, wall=9956
2023-05-20 20:43:57 - progress_bar.py[line:272] - INFO: epoch 002:    863 / 1732 loss=2.827, loss_v1=0, loss_v2=0, nll_loss=1.708, ntokens=933.3, nsentences=32, sample_size=933.3, sample_size_v1=0, sample_size_v2=0, ppl=3.27, wps=247.1, ups=0.26, wpb=933.3, bsz=32, num_updates=2590, lr=8.30927e-06, gnorm=5.176, clip=100, loss_scale=64, train_wall=38, gb_free=8.6, wall=9994
2023-05-20 20:44:35 - progress_bar.py[line:272] - INFO: epoch 002:    873 / 1732 loss=2.814, loss_v1=0, loss_v2=0, nll_loss=1.693, ntokens=966.4, nsentences=32, sample_size=966.4, sample_size_v1=0, sample_size_v2=0, ppl=3.23, wps=254.2, ups=0.26, wpb=966.4, bsz=32, num_updates=2600, lr=8.34135e-06, gnorm=4.842, clip=100, loss_scale=64, train_wall=38, gb_free=8.6, wall=10032
2023-05-20 20:45:13 - progress_bar.py[line:272] - INFO: epoch 002:    883 / 1732 loss=2.778, loss_v1=0, loss_v2=0, nll_loss=1.65, ntokens=985.5, nsentences=32, sample_size=985.5, sample_size_v1=0, sample_size_v2=0, ppl=3.14, wps=257.9, ups=0.26, wpb=985.5, bsz=32, num_updates=2610, lr=8.37344e-06, gnorm=5.107, clip=100, loss_scale=64, train_wall=38, gb_free=8.5, wall=10070
2023-05-20 20:45:51 - progress_bar.py[line:272] - INFO: epoch 002:    893 / 1732 loss=2.792, loss_v1=0, loss_v2=0, nll_loss=1.671, ntokens=1009.8, nsentences=32, sample_size=1009.8, sample_size_v1=0, sample_size_v2=0, ppl=3.18, wps=264.5, ups=0.26, wpb=1009.8, bsz=32, num_updates=2620, lr=8.40552e-06, gnorm=4.735, clip=100, loss_scale=64, train_wall=38, gb_free=8.3, wall=10108
2023-05-20 20:46:29 - progress_bar.py[line:272] - INFO: epoch 002:    903 / 1732 loss=2.768, loss_v1=0, loss_v2=0, nll_loss=1.64, ntokens=1049.7, nsentences=32, sample_size=1049.7, sample_size_v1=0, sample_size_v2=0, ppl=3.12, wps=275, ups=0.26, wpb=1049.7, bsz=32, num_updates=2630, lr=8.4376e-06, gnorm=4.915, clip=100, loss_scale=64, train_wall=38, gb_free=8.7, wall=10146
2023-05-20 20:47:07 - progress_bar.py[line:272] - INFO: epoch 002:    913 / 1732 loss=2.856, loss_v1=0, loss_v2=0, nll_loss=1.739, ntokens=930.6, nsentences=32, sample_size=930.6, sample_size_v1=0, sample_size_v2=0, ppl=3.34, wps=244, ups=0.26, wpb=930.6, bsz=32, num_updates=2640, lr=8.46968e-06, gnorm=4.929, clip=100, loss_scale=64, train_wall=38, gb_free=8.2, wall=10185
2023-05-20 20:47:46 - progress_bar.py[line:272] - INFO: epoch 002:    923 / 1732 loss=2.81, loss_v1=0, loss_v2=0, nll_loss=1.684, ntokens=1023.3, nsentences=32, sample_size=1023.3, sample_size_v1=0, sample_size_v2=0, ppl=3.21, wps=266.8, ups=0.26, wpb=1023.3, bsz=32, num_updates=2650, lr=8.50176e-06, gnorm=4.679, clip=100, loss_scale=64, train_wall=38, gb_free=8.3, wall=10223
2023-05-20 20:48:24 - progress_bar.py[line:272] - INFO: epoch 002:    933 / 1732 loss=2.793, loss_v1=0, loss_v2=0, nll_loss=1.671, ntokens=1034.6, nsentences=32, sample_size=1034.6, sample_size_v1=0, sample_size_v2=0, ppl=3.18, wps=267.9, ups=0.26, wpb=1034.6, bsz=32, num_updates=2660, lr=8.53385e-06, gnorm=4.994, clip=100, loss_scale=64, train_wall=39, gb_free=8.2, wall=10262
2023-05-20 20:49:03 - progress_bar.py[line:272] - INFO: epoch 002:    943 / 1732 loss=2.831, loss_v1=0, loss_v2=0, nll_loss=1.711, ntokens=1054.1, nsentences=32, sample_size=1054.1, sample_size_v1=0, sample_size_v2=0, ppl=3.27, wps=272.2, ups=0.26, wpb=1054.1, bsz=32, num_updates=2670, lr=8.56593e-06, gnorm=4.305, clip=100, loss_scale=64, train_wall=39, gb_free=8.4, wall=10300
2023-05-20 20:49:42 - progress_bar.py[line:272] - INFO: epoch 002:    953 / 1732 loss=2.796, loss_v1=0, loss_v2=0, nll_loss=1.67, ntokens=1032.2, nsentences=32, sample_size=1032.2, sample_size_v1=0, sample_size_v2=0, ppl=3.18, wps=266.4, ups=0.26, wpb=1032.2, bsz=32, num_updates=2680, lr=8.59801e-06, gnorm=4.393, clip=100, loss_scale=64, train_wall=39, gb_free=8.1, wall=10339
2023-05-20 20:50:21 - progress_bar.py[line:272] - INFO: epoch 002:    963 / 1732 loss=2.813, loss_v1=0, loss_v2=0, nll_loss=1.691, ntokens=1069.2, nsentences=32, sample_size=1069.2, sample_size_v1=0, sample_size_v2=0, ppl=3.23, wps=276.3, ups=0.26, wpb=1069.2, bsz=32, num_updates=2690, lr=8.63009e-06, gnorm=4.645, clip=100, loss_scale=64, train_wall=39, gb_free=8.4, wall=10378
2023-05-20 20:50:59 - progress_bar.py[line:272] - INFO: epoch 002:    973 / 1732 loss=2.818, loss_v1=0, loss_v2=0, nll_loss=1.694, ntokens=1034.1, nsentences=32, sample_size=1034.1, sample_size_v1=0, sample_size_v2=0, ppl=3.24, wps=268.2, ups=0.26, wpb=1034.1, bsz=32, num_updates=2700, lr=8.66218e-06, gnorm=4.564, clip=100, loss_scale=64, train_wall=39, gb_free=8.3, wall=10416
2023-05-20 20:51:38 - progress_bar.py[line:272] - INFO: epoch 002:    983 / 1732 loss=2.794, loss_v1=0, loss_v2=0, nll_loss=1.669, ntokens=1026.6, nsentences=32, sample_size=1026.6, sample_size_v1=0, sample_size_v2=0, ppl=3.18, wps=264.2, ups=0.26, wpb=1026.6, bsz=32, num_updates=2710, lr=8.69426e-06, gnorm=4.481, clip=100, loss_scale=64, train_wall=39, gb_free=8.3, wall=10455
2023-05-20 20:52:17 - progress_bar.py[line:272] - INFO: epoch 002:    993 / 1732 loss=2.771, loss_v1=0, loss_v2=0, nll_loss=1.643, ntokens=1041.8, nsentences=32, sample_size=1041.8, sample_size_v1=0, sample_size_v2=0, ppl=3.12, wps=269.9, ups=0.26, wpb=1041.8, bsz=32, num_updates=2720, lr=8.72634e-06, gnorm=4.48, clip=100, loss_scale=64, train_wall=39, gb_free=8.4, wall=10494
2023-05-20 20:52:55 - progress_bar.py[line:272] - INFO: epoch 002:   1003 / 1732 loss=2.764, loss_v1=0, loss_v2=0, nll_loss=1.633, ntokens=1018, nsentences=32, sample_size=1018, sample_size_v1=0, sample_size_v2=0, ppl=3.1, wps=265, ups=0.26, wpb=1018, bsz=32, num_updates=2730, lr=8.75842e-06, gnorm=4.588, clip=100, loss_scale=64, train_wall=38, gb_free=8.4, wall=10532
2023-05-20 20:53:33 - progress_bar.py[line:272] - INFO: epoch 002:   1013 / 1732 loss=2.77, loss_v1=0, loss_v2=0, nll_loss=1.642, ntokens=965, nsentences=32, sample_size=965, sample_size_v1=0, sample_size_v2=0, ppl=3.12, wps=252.2, ups=0.26, wpb=965, bsz=32, num_updates=2740, lr=8.7905e-06, gnorm=4.336, clip=100, loss_scale=64, train_wall=38, gb_free=9.1, wall=10570
2023-05-20 20:54:12 - progress_bar.py[line:272] - INFO: epoch 002:   1023 / 1732 loss=2.771, loss_v1=0, loss_v2=0, nll_loss=1.641, ntokens=1087.1, nsentences=32, sample_size=1087.1, sample_size_v1=0, sample_size_v2=0, ppl=3.12, wps=279.9, ups=0.26, wpb=1087.1, bsz=32, num_updates=2750, lr=8.82259e-06, gnorm=4.277, clip=100, loss_scale=64, train_wall=39, gb_free=8.1, wall=10609
2023-05-20 20:54:51 - progress_bar.py[line:272] - INFO: epoch 002:   1033 / 1732 loss=2.77, loss_v1=0, loss_v2=0, nll_loss=1.642, ntokens=1100.3, nsentences=32, sample_size=1100.3, sample_size_v1=0, sample_size_v2=0, ppl=3.12, wps=282.3, ups=0.26, wpb=1100.3, bsz=32, num_updates=2760, lr=8.85467e-06, gnorm=4.755, clip=100, loss_scale=64, train_wall=39, gb_free=8.8, wall=10648
2023-05-20 20:55:30 - progress_bar.py[line:272] - INFO: epoch 002:   1043 / 1732 loss=2.782, loss_v1=0, loss_v2=0, nll_loss=1.651, ntokens=1068.2, nsentences=32, sample_size=1068.2, sample_size_v1=0, sample_size_v2=0, ppl=3.14, wps=274.9, ups=0.26, wpb=1068.2, bsz=32, num_updates=2770, lr=8.88675e-06, gnorm=4.503, clip=100, loss_scale=64, train_wall=39, gb_free=8.3, wall=10687
2023-05-20 20:56:08 - progress_bar.py[line:272] - INFO: epoch 002:   1053 / 1732 loss=2.753, loss_v1=0, loss_v2=0, nll_loss=1.619, ntokens=1062.8, nsentences=32, sample_size=1062.8, sample_size_v1=0, sample_size_v2=0, ppl=3.07, wps=277.2, ups=0.26, wpb=1062.8, bsz=32, num_updates=2780, lr=8.91883e-06, gnorm=4.488, clip=100, loss_scale=64, train_wall=38, gb_free=8.6, wall=10726
2023-05-20 20:56:47 - progress_bar.py[line:272] - INFO: epoch 002:   1063 / 1732 loss=2.76, loss_v1=0, loss_v2=0, nll_loss=1.627, ntokens=1030.9, nsentences=32, sample_size=1030.9, sample_size_v1=0, sample_size_v2=0, ppl=3.09, wps=268, ups=0.26, wpb=1030.9, bsz=32, num_updates=2790, lr=8.95091e-06, gnorm=4.327, clip=100, loss_scale=64, train_wall=38, gb_free=8.3, wall=10764
2023-05-20 20:57:25 - progress_bar.py[line:272] - INFO: epoch 002:   1073 / 1732 loss=2.76, loss_v1=0, loss_v2=0, nll_loss=1.63, ntokens=999.3, nsentences=32, sample_size=999.3, sample_size_v1=0, sample_size_v2=0, ppl=3.1, wps=259.1, ups=0.26, wpb=999.3, bsz=32, num_updates=2800, lr=8.983e-06, gnorm=4.487, clip=100, loss_scale=128, train_wall=39, gb_free=8.5, wall=10803
2023-05-20 20:58:04 - progress_bar.py[line:272] - INFO: epoch 002:   1083 / 1732 loss=2.791, loss_v1=0, loss_v2=0, nll_loss=1.661, ntokens=1054.9, nsentences=32, sample_size=1054.9, sample_size_v1=0, sample_size_v2=0, ppl=3.16, wps=272.4, ups=0.26, wpb=1054.9, bsz=32, num_updates=2810, lr=9.01508e-06, gnorm=4.389, clip=100, loss_scale=128, train_wall=39, gb_free=7.6, wall=10841
2023-05-20 20:58:43 - progress_bar.py[line:272] - INFO: epoch 002:   1093 / 1732 loss=2.76, loss_v1=0, loss_v2=0, nll_loss=1.623, ntokens=1060.6, nsentences=32, sample_size=1060.6, sample_size_v1=0, sample_size_v2=0, ppl=3.08, wps=273.6, ups=0.26, wpb=1060.6, bsz=32, num_updates=2820, lr=9.04716e-06, gnorm=3.894, clip=100, loss_scale=128, train_wall=39, gb_free=8.3, wall=10880
2023-05-20 20:59:21 - progress_bar.py[line:272] - INFO: epoch 002:   1103 / 1732 loss=2.767, loss_v1=0, loss_v2=0, nll_loss=1.638, ntokens=1039.1, nsentences=32, sample_size=1039.1, sample_size_v1=0, sample_size_v2=0, ppl=3.11, wps=269.4, ups=0.26, wpb=1039.1, bsz=32, num_updates=2830, lr=9.07924e-06, gnorm=3.932, clip=100, loss_scale=128, train_wall=39, gb_free=8.9, wall=10919
2023-05-20 21:00:00 - progress_bar.py[line:272] - INFO: epoch 002:   1113 / 1732 loss=2.74, loss_v1=0, loss_v2=0, nll_loss=1.598, ntokens=1008.5, nsentences=32, sample_size=1008.5, sample_size_v1=0, sample_size_v2=0, ppl=3.03, wps=261.3, ups=0.26, wpb=1008.5, bsz=32, num_updates=2840, lr=9.11132e-06, gnorm=4.272, clip=100, loss_scale=128, train_wall=39, gb_free=8.5, wall=10957
2023-05-20 21:00:39 - progress_bar.py[line:272] - INFO: epoch 002:   1123 / 1732 loss=2.755, loss_v1=0, loss_v2=0, nll_loss=1.621, ntokens=976.6, nsentences=32, sample_size=976.6, sample_size_v1=0, sample_size_v2=0, ppl=3.08, wps=252.4, ups=0.26, wpb=976.6, bsz=32, num_updates=2850, lr=9.14341e-06, gnorm=4.424, clip=100, loss_scale=128, train_wall=39, gb_free=8.2, wall=10996
2023-05-20 21:01:17 - progress_bar.py[line:272] - INFO: epoch 002:   1133 / 1732 loss=2.747, loss_v1=0, loss_v2=0, nll_loss=1.61, ntokens=965.2, nsentences=32, sample_size=965.2, sample_size_v1=0, sample_size_v2=0, ppl=3.05, wps=250.6, ups=0.26, wpb=965.2, bsz=32, num_updates=2860, lr=9.17549e-06, gnorm=4.071, clip=100, loss_scale=128, train_wall=38, gb_free=7.7, wall=11034
2023-05-20 21:01:56 - progress_bar.py[line:272] - INFO: epoch 002:   1143 / 1732 loss=2.763, loss_v1=0, loss_v2=0, nll_loss=1.628, ntokens=1060.3, nsentences=32, sample_size=1060.3, sample_size_v1=0, sample_size_v2=0, ppl=3.09, wps=274.7, ups=0.26, wpb=1060.3, bsz=32, num_updates=2870, lr=9.20757e-06, gnorm=4.143, clip=100, loss_scale=128, train_wall=39, gb_free=7.9, wall=11073
2023-05-20 21:02:34 - progress_bar.py[line:272] - INFO: epoch 002:   1153 / 1732 loss=2.737, loss_v1=0, loss_v2=0, nll_loss=1.597, ntokens=1009.1, nsentences=32, sample_size=1009.1, sample_size_v1=0, sample_size_v2=0, ppl=3.03, wps=263.2, ups=0.26, wpb=1009.1, bsz=32, num_updates=2880, lr=9.23965e-06, gnorm=4.1, clip=100, loss_scale=128, train_wall=38, gb_free=8.9, wall=11111
2023-05-20 21:03:13 - progress_bar.py[line:272] - INFO: epoch 002:   1163 / 1732 loss=2.706, loss_v1=0, loss_v2=0, nll_loss=1.565, ntokens=999.2, nsentences=32, sample_size=999.2, sample_size_v1=0, sample_size_v2=0, ppl=2.96, wps=258.8, ups=0.26, wpb=999.2, bsz=32, num_updates=2890, lr=9.27174e-06, gnorm=4.39, clip=100, loss_scale=128, train_wall=39, gb_free=8.4, wall=11150
2023-05-20 21:03:52 - progress_bar.py[line:272] - INFO: epoch 002:   1173 / 1732 loss=2.733, loss_v1=0, loss_v2=0, nll_loss=1.592, ntokens=1077.2, nsentences=32, sample_size=1077.2, sample_size_v1=0, sample_size_v2=0, ppl=3.01, wps=277.9, ups=0.26, wpb=1077.2, bsz=32, num_updates=2900, lr=9.30382e-06, gnorm=4.255, clip=100, loss_scale=128, train_wall=39, gb_free=8.5, wall=11189
2023-05-20 21:04:30 - progress_bar.py[line:272] - INFO: epoch 002:   1183 / 1732 loss=2.747, loss_v1=0, loss_v2=0, nll_loss=1.609, ntokens=988.2, nsentences=32, sample_size=988.2, sample_size_v1=0, sample_size_v2=0, ppl=3.05, wps=257.8, ups=0.26, wpb=988.2, bsz=32, num_updates=2910, lr=9.3359e-06, gnorm=4.391, clip=100, loss_scale=128, train_wall=38, gb_free=8.3, wall=11227
2023-05-20 21:05:08 - progress_bar.py[line:272] - INFO: epoch 002:   1193 / 1732 loss=2.734, loss_v1=0, loss_v2=0, nll_loss=1.596, ntokens=1028.6, nsentences=32, sample_size=1028.6, sample_size_v1=0, sample_size_v2=0, ppl=3.02, wps=266.7, ups=0.26, wpb=1028.6, bsz=32, num_updates=2920, lr=9.36798e-06, gnorm=4.07, clip=100, loss_scale=128, train_wall=39, gb_free=8.5, wall=11266
2023-05-20 21:05:48 - progress_bar.py[line:272] - INFO: epoch 002:   1203 / 1732 loss=2.7, loss_v1=0, loss_v2=0, nll_loss=1.555, ntokens=1142.6, nsentences=32, sample_size=1142.6, sample_size_v1=0, sample_size_v2=0, ppl=2.94, wps=292.5, ups=0.26, wpb=1142.6, bsz=32, num_updates=2930, lr=9.40006e-06, gnorm=3.815, clip=100, loss_scale=128, train_wall=39, gb_free=7.4, wall=11305
2023-05-20 21:06:26 - progress_bar.py[line:272] - INFO: epoch 002:   1213 / 1732 loss=2.697, loss_v1=0, loss_v2=0, nll_loss=1.55, ntokens=1010.9, nsentences=32, sample_size=1010.9, sample_size_v1=0, sample_size_v2=0, ppl=2.93, wps=261.6, ups=0.26, wpb=1010.9, bsz=32, num_updates=2940, lr=9.43215e-06, gnorm=3.982, clip=100, loss_scale=128, train_wall=39, gb_free=8.9, wall=11343
2023-05-20 21:07:05 - progress_bar.py[line:272] - INFO: epoch 002:   1223 / 1732 loss=2.739, loss_v1=0, loss_v2=0, nll_loss=1.597, ntokens=1033.2, nsentences=32, sample_size=1033.2, sample_size_v1=0, sample_size_v2=0, ppl=3.03, wps=267.1, ups=0.26, wpb=1033.2, bsz=32, num_updates=2950, lr=9.46423e-06, gnorm=4.102, clip=100, loss_scale=128, train_wall=39, gb_free=8.4, wall=11382
2023-05-20 21:07:44 - progress_bar.py[line:272] - INFO: epoch 002:   1233 / 1732 loss=2.692, loss_v1=0, loss_v2=0, nll_loss=1.549, ntokens=1038.6, nsentences=32, sample_size=1038.6, sample_size_v1=0, sample_size_v2=0, ppl=2.93, wps=267.5, ups=0.26, wpb=1038.6, bsz=32, num_updates=2960, lr=9.49631e-06, gnorm=3.841, clip=100, loss_scale=128, train_wall=39, gb_free=8.2, wall=11421
2023-05-20 21:08:22 - progress_bar.py[line:272] - INFO: epoch 002:   1243 / 1732 loss=2.663, loss_v1=0, loss_v2=0, nll_loss=1.509, ntokens=1063.3, nsentences=32, sample_size=1063.3, sample_size_v1=0, sample_size_v2=0, ppl=2.85, wps=275.1, ups=0.26, wpb=1063.3, bsz=32, num_updates=2970, lr=9.52839e-06, gnorm=3.746, clip=100, loss_scale=128, train_wall=39, gb_free=8.8, wall=11460
2023-05-20 21:09:01 - progress_bar.py[line:272] - INFO: epoch 002:   1253 / 1732 loss=2.697, loss_v1=0, loss_v2=0, nll_loss=1.555, ntokens=1098.7, nsentences=32, sample_size=1098.7, sample_size_v1=0, sample_size_v2=0, ppl=2.94, wps=284.2, ups=0.26, wpb=1098.7, bsz=32, num_updates=2980, lr=9.56047e-06, gnorm=4.201, clip=100, loss_scale=128, train_wall=39, gb_free=8.5, wall=11498
2023-05-20 21:09:40 - progress_bar.py[line:272] - INFO: epoch 002:   1263 / 1732 loss=2.711, loss_v1=0, loss_v2=0, nll_loss=1.563, ntokens=1070.8, nsentences=32, sample_size=1070.8, sample_size_v1=0, sample_size_v2=0, ppl=2.95, wps=276.1, ups=0.26, wpb=1070.8, bsz=32, num_updates=2990, lr=9.59256e-06, gnorm=3.862, clip=100, loss_scale=128, train_wall=39, gb_free=8.3, wall=11537
2023-05-20 21:10:18 - progress_bar.py[line:272] - INFO: epoch 002:   1273 / 1732 loss=2.708, loss_v1=0, loss_v2=0, nll_loss=1.567, ntokens=1005.1, nsentences=32, sample_size=1005.1, sample_size_v1=0, sample_size_v2=0, ppl=2.96, wps=261, ups=0.26, wpb=1005.1, bsz=32, num_updates=3000, lr=9.62464e-06, gnorm=4.143, clip=100, loss_scale=128, train_wall=38, gb_free=7.9, wall=11576
2023-05-20 21:10:57 - progress_bar.py[line:272] - INFO: epoch 002:   1283 / 1732 loss=2.707, loss_v1=0, loss_v2=0, nll_loss=1.56, ntokens=1101.8, nsentences=32, sample_size=1101.8, sample_size_v1=0, sample_size_v2=0, ppl=2.95, wps=282.2, ups=0.26, wpb=1101.8, bsz=32, num_updates=3010, lr=9.65672e-06, gnorm=3.839, clip=100, loss_scale=128, train_wall=39, gb_free=8.6, wall=11615
2023-05-20 21:11:36 - progress_bar.py[line:272] - INFO: epoch 002:   1293 / 1732 loss=2.691, loss_v1=0, loss_v2=0, nll_loss=1.543, ntokens=1084.4, nsentences=32, sample_size=1084.4, sample_size_v1=0, sample_size_v2=0, ppl=2.91, wps=280.6, ups=0.26, wpb=1084.4, bsz=32, num_updates=3020, lr=9.6888e-06, gnorm=3.624, clip=100, loss_scale=128, train_wall=39, gb_free=8.5, wall=11653
2023-05-20 21:12:15 - progress_bar.py[line:272] - INFO: epoch 002:   1303 / 1732 loss=2.695, loss_v1=0, loss_v2=0, nll_loss=1.549, ntokens=1102.4, nsentences=32, sample_size=1102.4, sample_size_v1=0, sample_size_v2=0, ppl=2.93, wps=283.9, ups=0.26, wpb=1102.4, bsz=32, num_updates=3030, lr=9.72089e-06, gnorm=3.647, clip=100, loss_scale=128, train_wall=39, gb_free=8, wall=11692
2023-05-20 21:12:54 - progress_bar.py[line:272] - INFO: epoch 002:   1313 / 1732 loss=2.722, loss_v1=0, loss_v2=0, nll_loss=1.575, ntokens=1055.3, nsentences=32, sample_size=1055.3, sample_size_v1=0, sample_size_v2=0, ppl=2.98, wps=270.5, ups=0.26, wpb=1055.3, bsz=32, num_updates=3040, lr=9.75297e-06, gnorm=3.706, clip=100, loss_scale=128, train_wall=39, gb_free=7.8, wall=11731
2023-05-20 21:13:33 - progress_bar.py[line:272] - INFO: epoch 002:   1323 / 1732 loss=2.689, loss_v1=0, loss_v2=0, nll_loss=1.544, ntokens=1103.3, nsentences=32, sample_size=1103.3, sample_size_v1=0, sample_size_v2=0, ppl=2.92, wps=283, ups=0.26, wpb=1103.3, bsz=32, num_updates=3050, lr=9.78505e-06, gnorm=3.632, clip=100, loss_scale=128, train_wall=39, gb_free=8.4, wall=11770
2023-05-20 21:14:12 - progress_bar.py[line:272] - INFO: epoch 002:   1333 / 1732 loss=2.665, loss_v1=0, loss_v2=0, nll_loss=1.51, ntokens=1100.8, nsentences=32, sample_size=1100.8, sample_size_v1=0, sample_size_v2=0, ppl=2.85, wps=282.8, ups=0.26, wpb=1100.8, bsz=32, num_updates=3060, lr=9.81713e-06, gnorm=3.688, clip=100, loss_scale=128, train_wall=39, gb_free=8.5, wall=11809
2023-05-20 21:14:51 - progress_bar.py[line:272] - INFO: epoch 002:   1343 / 1732 loss=2.697, loss_v1=0, loss_v2=0, nll_loss=1.552, ntokens=1190.4, nsentences=32, sample_size=1190.4, sample_size_v1=0, sample_size_v2=0, ppl=2.93, wps=304.2, ups=0.26, wpb=1190.4, bsz=32, num_updates=3070, lr=9.84921e-06, gnorm=3.907, clip=100, loss_scale=128, train_wall=39, gb_free=8.4, wall=11848
2023-05-20 21:15:30 - progress_bar.py[line:272] - INFO: epoch 002:   1353 / 1732 loss=2.681, loss_v1=0, loss_v2=0, nll_loss=1.53, ntokens=1120.7, nsentences=32, sample_size=1120.7, sample_size_v1=0, sample_size_v2=0, ppl=2.89, wps=288.4, ups=0.26, wpb=1120.7, bsz=32, num_updates=3080, lr=9.8813e-06, gnorm=3.924, clip=100, loss_scale=128, train_wall=39, gb_free=8.6, wall=11887
2023-05-20 21:16:09 - progress_bar.py[line:272] - INFO: epoch 002:   1363 / 1732 loss=2.653, loss_v1=0, loss_v2=0, nll_loss=1.501, ntokens=1088.2, nsentences=32, sample_size=1088.2, sample_size_v1=0, sample_size_v2=0, ppl=2.83, wps=279.9, ups=0.26, wpb=1088.2, bsz=32, num_updates=3090, lr=9.91338e-06, gnorm=3.953, clip=100, loss_scale=128, train_wall=39, gb_free=8.9, wall=11926
2023-05-20 21:16:48 - progress_bar.py[line:272] - INFO: epoch 002:   1373 / 1732 loss=2.709, loss_v1=0, loss_v2=0, nll_loss=1.563, ntokens=1114.2, nsentences=32, sample_size=1114.2, sample_size_v1=0, sample_size_v2=0, ppl=2.96, wps=286.7, ups=0.26, wpb=1114.2, bsz=32, num_updates=3100, lr=9.94546e-06, gnorm=3.699, clip=100, loss_scale=128, train_wall=39, gb_free=8.6, wall=11965
2023-05-20 21:17:27 - progress_bar.py[line:272] - INFO: epoch 002:   1383 / 1732 loss=2.69, loss_v1=0, loss_v2=0, nll_loss=1.543, ntokens=1148.9, nsentences=32, sample_size=1148.9, sample_size_v1=0, sample_size_v2=0, ppl=2.91, wps=294.8, ups=0.26, wpb=1148.9, bsz=32, num_updates=3110, lr=9.97754e-06, gnorm=3.515, clip=100, loss_scale=128, train_wall=39, gb_free=8.7, wall=12004
2023-05-20 21:18:05 - progress_bar.py[line:272] - INFO: epoch 002:   1393 / 1732 loss=2.669, loss_v1=0, loss_v2=0, nll_loss=1.519, ntokens=1033.6, nsentences=32, sample_size=1033.6, sample_size_v1=0, sample_size_v2=0, ppl=2.87, wps=268.3, ups=0.26, wpb=1033.6, bsz=32, num_updates=3120, lr=9.99939e-06, gnorm=3.792, clip=100, loss_scale=128, train_wall=38, gb_free=8.1, wall=12042
2023-05-20 21:18:44 - progress_bar.py[line:272] - INFO: epoch 002:   1403 / 1732 loss=2.651, loss_v1=0, loss_v2=0, nll_loss=1.496, ntokens=1148.6, nsentences=32, sample_size=1148.6, sample_size_v1=0, sample_size_v2=0, ppl=2.82, wps=294.8, ups=0.26, wpb=1148.6, bsz=32, num_updates=3130, lr=9.99734e-06, gnorm=3.461, clip=100, loss_scale=128, train_wall=39, gb_free=8.7, wall=12081
2023-05-20 21:19:23 - progress_bar.py[line:272] - INFO: epoch 002:   1413 / 1732 loss=2.676, loss_v1=0, loss_v2=0, nll_loss=1.524, ntokens=1251.8, nsentences=32, sample_size=1251.8, sample_size_v1=0, sample_size_v2=0, ppl=2.88, wps=320.6, ups=0.26, wpb=1251.8, bsz=32, num_updates=3140, lr=9.99529e-06, gnorm=3.484, clip=100, loss_scale=128, train_wall=39, gb_free=8.3, wall=12120
2023-05-20 21:20:02 - progress_bar.py[line:272] - INFO: epoch 002:   1423 / 1732 loss=2.679, loss_v1=0, loss_v2=0, nll_loss=1.529, ntokens=1276.2, nsentences=32, sample_size=1276.2, sample_size_v1=0, sample_size_v2=0, ppl=2.89, wps=324.4, ups=0.25, wpb=1276.2, bsz=32, num_updates=3150, lr=9.99324e-06, gnorm=3.56, clip=100, loss_scale=128, train_wall=39, gb_free=8.5, wall=12160
2023-05-20 21:20:41 - progress_bar.py[line:272] - INFO: epoch 002:   1433 / 1732 loss=2.643, loss_v1=0, loss_v2=0, nll_loss=1.49, ntokens=1210.9, nsentences=32, sample_size=1210.9, sample_size_v1=0, sample_size_v2=0, ppl=2.81, wps=312.1, ups=0.26, wpb=1210.9, bsz=32, num_updates=3160, lr=9.9912e-06, gnorm=3.539, clip=100, loss_scale=128, train_wall=39, gb_free=8.4, wall=12198
2023-05-20 21:21:20 - progress_bar.py[line:272] - INFO: epoch 002:   1443 / 1732 loss=2.671, loss_v1=0, loss_v2=0, nll_loss=1.514, ntokens=1130.8, nsentences=32, sample_size=1130.8, sample_size_v1=0, sample_size_v2=0, ppl=2.86, wps=291.7, ups=0.26, wpb=1130.8, bsz=32, num_updates=3170, lr=9.98915e-06, gnorm=3.631, clip=100, loss_scale=128, train_wall=39, gb_free=7.8, wall=12237
2023-05-20 21:21:59 - progress_bar.py[line:272] - INFO: epoch 002:   1453 / 1732 loss=2.68, loss_v1=0, loss_v2=0, nll_loss=1.529, ntokens=1116.6, nsentences=32, sample_size=1116.6, sample_size_v1=0, sample_size_v2=0, ppl=2.89, wps=287.3, ups=0.26, wpb=1116.6, bsz=32, num_updates=3180, lr=9.9871e-06, gnorm=3.669, clip=100, loss_scale=128, train_wall=39, gb_free=7.9, wall=12276
2023-05-20 21:22:38 - progress_bar.py[line:272] - INFO: epoch 002:   1463 / 1732 loss=2.613, loss_v1=0, loss_v2=0, nll_loss=1.453, ntokens=1191.9, nsentences=32, sample_size=1191.9, sample_size_v1=0, sample_size_v2=0, ppl=2.74, wps=304.9, ups=0.26, wpb=1191.9, bsz=32, num_updates=3190, lr=9.98505e-06, gnorm=3.587, clip=100, loss_scale=128, train_wall=39, gb_free=7.4, wall=12315
2023-05-20 21:23:17 - progress_bar.py[line:272] - INFO: epoch 002:   1473 / 1732 loss=2.659, loss_v1=0, loss_v2=0, nll_loss=1.507, ntokens=1103.1, nsentences=32, sample_size=1103.1, sample_size_v1=0, sample_size_v2=0, ppl=2.84, wps=283.8, ups=0.26, wpb=1103.1, bsz=32, num_updates=3200, lr=9.98301e-06, gnorm=4.067, clip=100, loss_scale=128, train_wall=39, gb_free=8.5, wall=12354
2023-05-20 21:23:56 - progress_bar.py[line:272] - INFO: epoch 002:   1483 / 1732 loss=2.665, loss_v1=0, loss_v2=0, nll_loss=1.506, ntokens=1083.9, nsentences=32, sample_size=1083.9, sample_size_v1=0, sample_size_v2=0, ppl=2.84, wps=279.7, ups=0.26, wpb=1083.9, bsz=32, num_updates=3210, lr=9.98096e-06, gnorm=4.199, clip=100, loss_scale=128, train_wall=39, gb_free=8.9, wall=12393
2023-05-20 21:24:35 - progress_bar.py[line:272] - INFO: epoch 002:   1493 / 1732 loss=2.647, loss_v1=0, loss_v2=0, nll_loss=1.491, ntokens=1119.2, nsentences=32, sample_size=1119.2, sample_size_v1=0, sample_size_v2=0, ppl=2.81, wps=286.5, ups=0.26, wpb=1119.2, bsz=32, num_updates=3220, lr=9.97891e-06, gnorm=3.691, clip=100, loss_scale=128, train_wall=39, gb_free=8.7, wall=12432
2023-05-20 21:25:14 - progress_bar.py[line:272] - INFO: epoch 002:   1503 / 1732 loss=2.615, loss_v1=0, loss_v2=0, nll_loss=1.454, ntokens=1138.8, nsentences=32, sample_size=1138.8, sample_size_v1=0, sample_size_v2=0, ppl=2.74, wps=291.9, ups=0.26, wpb=1138.8, bsz=32, num_updates=3230, lr=9.97686e-06, gnorm=3.511, clip=100, loss_scale=128, train_wall=39, gb_free=8.8, wall=12471
2023-05-20 21:25:52 - progress_bar.py[line:272] - INFO: epoch 002:   1513 / 1732 loss=2.641, loss_v1=0, loss_v2=0, nll_loss=1.487, ntokens=1063.2, nsentences=32, sample_size=1063.2, sample_size_v1=0, sample_size_v2=0, ppl=2.8, wps=274.6, ups=0.26, wpb=1063.2, bsz=32, num_updates=3240, lr=9.97482e-06, gnorm=3.955, clip=100, loss_scale=128, train_wall=39, gb_free=8.4, wall=12510
2023-05-20 21:26:31 - progress_bar.py[line:272] - INFO: epoch 002:   1523 / 1732 loss=2.683, loss_v1=0, loss_v2=0, nll_loss=1.532, ntokens=1020.5, nsentences=32, sample_size=1020.5, sample_size_v1=0, sample_size_v2=0, ppl=2.89, wps=263, ups=0.26, wpb=1020.5, bsz=32, num_updates=3250, lr=9.97277e-06, gnorm=3.802, clip=100, loss_scale=128, train_wall=39, gb_free=8.4, wall=12548
2023-05-20 21:27:10 - progress_bar.py[line:272] - INFO: epoch 002:   1533 / 1732 loss=2.663, loss_v1=0, loss_v2=0, nll_loss=1.503, ntokens=1081, nsentences=32, sample_size=1081, sample_size_v1=0, sample_size_v2=0, ppl=2.83, wps=277.3, ups=0.26, wpb=1081, bsz=32, num_updates=3260, lr=9.97072e-06, gnorm=3.735, clip=100, loss_scale=128, train_wall=39, gb_free=8.1, wall=12587
2023-05-20 21:27:49 - progress_bar.py[line:272] - INFO: epoch 002:   1543 / 1732 loss=2.645, loss_v1=0, loss_v2=0, nll_loss=1.488, ntokens=1109.5, nsentences=32, sample_size=1109.5, sample_size_v1=0, sample_size_v2=0, ppl=2.8, wps=285.4, ups=0.26, wpb=1109.5, bsz=32, num_updates=3270, lr=9.96868e-06, gnorm=3.931, clip=100, loss_scale=128, train_wall=39, gb_free=8.5, wall=12626
2023-05-20 21:28:28 - progress_bar.py[line:272] - INFO: epoch 002:   1553 / 1732 loss=2.628, loss_v1=0, loss_v2=0, nll_loss=1.475, ntokens=1034.9, nsentences=32, sample_size=1034.9, sample_size_v1=0, sample_size_v2=0, ppl=2.78, wps=268.3, ups=0.26, wpb=1034.9, bsz=32, num_updates=3280, lr=9.96663e-06, gnorm=3.816, clip=100, loss_scale=128, train_wall=39, gb_free=8.4, wall=12665
2023-05-20 21:29:06 - progress_bar.py[line:272] - INFO: epoch 002:   1563 / 1732 loss=2.649, loss_v1=0, loss_v2=0, nll_loss=1.493, ntokens=1130.9, nsentences=32, sample_size=1130.9, sample_size_v1=0, sample_size_v2=0, ppl=2.82, wps=291.7, ups=0.26, wpb=1130.9, bsz=32, num_updates=3290, lr=9.96458e-06, gnorm=3.523, clip=100, loss_scale=128, train_wall=39, gb_free=8.9, wall=12704
2023-05-20 21:29:45 - progress_bar.py[line:272] - INFO: epoch 002:   1573 / 1732 loss=2.687, loss_v1=0, loss_v2=0, nll_loss=1.532, ntokens=1064.8, nsentences=32, sample_size=1064.8, sample_size_v1=0, sample_size_v2=0, ppl=2.89, wps=274.7, ups=0.26, wpb=1064.8, bsz=32, num_updates=3300, lr=9.96253e-06, gnorm=3.908, clip=100, loss_scale=128, train_wall=39, gb_free=8, wall=12742
2023-05-20 21:30:24 - progress_bar.py[line:272] - INFO: epoch 002:   1583 / 1732 loss=2.692, loss_v1=0, loss_v2=0, nll_loss=1.542, ntokens=1007.5, nsentences=32, sample_size=1007.5, sample_size_v1=0, sample_size_v2=0, ppl=2.91, wps=259.7, ups=0.26, wpb=1007.5, bsz=32, num_updates=3310, lr=9.96049e-06, gnorm=3.779, clip=100, loss_scale=256, train_wall=39, gb_free=8.4, wall=12781
2023-05-20 21:30:59 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 128.0
2023-05-20 21:31:07 - progress_bar.py[line:272] - INFO: epoch 002:   1594 / 1732 loss=2.635, loss_v1=0, loss_v2=0, nll_loss=1.476, ntokens=1073.8, nsentences=32, sample_size=1073.8, sample_size_v1=0, sample_size_v2=0, ppl=2.78, wps=251.8, ups=0.23, wpb=1073.8, bsz=32, num_updates=3320, lr=9.95844e-06, gnorm=3.679, clip=100, loss_scale=128, train_wall=43, gb_free=8.4, wall=12824
2023-05-20 21:31:45 - progress_bar.py[line:272] - INFO: epoch 002:   1604 / 1732 loss=2.622, loss_v1=0, loss_v2=0, nll_loss=1.461, ntokens=1089, nsentences=32, sample_size=1089, sample_size_v1=0, sample_size_v2=0, ppl=2.75, wps=282.3, ups=0.26, wpb=1089, bsz=32, num_updates=3330, lr=9.95639e-06, gnorm=3.685, clip=100, loss_scale=128, train_wall=39, gb_free=7.9, wall=12862
2023-05-20 21:32:24 - progress_bar.py[line:272] - INFO: epoch 002:   1614 / 1732 loss=2.611, loss_v1=0, loss_v2=0, nll_loss=1.45, ntokens=1186.1, nsentences=32, sample_size=1186.1, sample_size_v1=0, sample_size_v2=0, ppl=2.73, wps=303.8, ups=0.26, wpb=1186.1, bsz=32, num_updates=3340, lr=9.95434e-06, gnorm=3.465, clip=100, loss_scale=128, train_wall=39, gb_free=8, wall=12901
2023-05-20 21:33:03 - progress_bar.py[line:272] - INFO: epoch 002:   1624 / 1732 loss=2.611, loss_v1=0, loss_v2=0, nll_loss=1.449, ntokens=1074.1, nsentences=32, sample_size=1074.1, sample_size_v1=0, sample_size_v2=0, ppl=2.73, wps=277.5, ups=0.26, wpb=1074.1, bsz=32, num_updates=3350, lr=9.9523e-06, gnorm=3.68, clip=100, loss_scale=128, train_wall=39, gb_free=8.7, wall=12940
2023-05-20 21:33:42 - progress_bar.py[line:272] - INFO: epoch 002:   1634 / 1732 loss=2.613, loss_v1=0, loss_v2=0, nll_loss=1.45, ntokens=1178.9, nsentences=32, sample_size=1178.9, sample_size_v1=0, sample_size_v2=0, ppl=2.73, wps=303.5, ups=0.26, wpb=1178.9, bsz=32, num_updates=3360, lr=9.95025e-06, gnorm=3.625, clip=100, loss_scale=128, train_wall=39, gb_free=8.7, wall=12979
2023-05-20 21:34:21 - progress_bar.py[line:272] - INFO: epoch 002:   1644 / 1732 loss=2.572, loss_v1=0, loss_v2=0, nll_loss=1.406, ntokens=1265.1, nsentences=32, sample_size=1265.1, sample_size_v1=0, sample_size_v2=0, ppl=2.65, wps=322.8, ups=0.26, wpb=1265.1, bsz=32, num_updates=3370, lr=9.9482e-06, gnorm=3.319, clip=100, loss_scale=128, train_wall=39, gb_free=8, wall=13018
2023-05-20 21:35:00 - progress_bar.py[line:272] - INFO: epoch 002:   1654 / 1732 loss=2.651, loss_v1=0, loss_v2=0, nll_loss=1.49, ntokens=974.9, nsentences=32, sample_size=974.9, sample_size_v1=0, sample_size_v2=0, ppl=2.81, wps=253.1, ups=0.26, wpb=974.9, bsz=32, num_updates=3380, lr=9.94615e-06, gnorm=3.953, clip=100, loss_scale=128, train_wall=38, gb_free=8.6, wall=13057
2023-05-20 21:35:39 - progress_bar.py[line:272] - INFO: epoch 002:   1664 / 1732 loss=2.643, loss_v1=0, loss_v2=0, nll_loss=1.481, ntokens=1041.8, nsentences=32, sample_size=1041.8, sample_size_v1=0, sample_size_v2=0, ppl=2.79, wps=266.8, ups=0.26, wpb=1041.8, bsz=32, num_updates=3390, lr=9.94411e-06, gnorm=3.328, clip=100, loss_scale=128, train_wall=39, gb_free=8.3, wall=13096
2023-05-20 21:36:17 - progress_bar.py[line:272] - INFO: epoch 002:   1674 / 1732 loss=2.604, loss_v1=0, loss_v2=0, nll_loss=1.443, ntokens=1052.3, nsentences=32, sample_size=1052.3, sample_size_v1=0, sample_size_v2=0, ppl=2.72, wps=273.5, ups=0.26, wpb=1052.3, bsz=32, num_updates=3400, lr=9.94206e-06, gnorm=3.4, clip=100, loss_scale=128, train_wall=38, gb_free=8.2, wall=13134
2023-05-20 21:36:56 - progress_bar.py[line:272] - INFO: epoch 002:   1684 / 1732 loss=2.601, loss_v1=0, loss_v2=0, nll_loss=1.437, ntokens=1169.1, nsentences=32, sample_size=1169.1, sample_size_v1=0, sample_size_v2=0, ppl=2.71, wps=299.5, ups=0.26, wpb=1169.1, bsz=32, num_updates=3410, lr=9.94001e-06, gnorm=3.279, clip=100, loss_scale=128, train_wall=39, gb_free=8.8, wall=13173
2023-05-20 21:37:36 - progress_bar.py[line:272] - INFO: epoch 002:   1694 / 1732 loss=2.622, loss_v1=0, loss_v2=0, nll_loss=1.461, ntokens=1257.3, nsentences=32, sample_size=1257.3, sample_size_v1=0, sample_size_v2=0, ppl=2.75, wps=317.3, ups=0.25, wpb=1257.3, bsz=32, num_updates=3420, lr=9.93796e-06, gnorm=3.219, clip=100, loss_scale=128, train_wall=40, gb_free=7, wall=13213
2023-05-20 21:38:15 - progress_bar.py[line:272] - INFO: epoch 002:   1704 / 1732 loss=2.611, loss_v1=0, loss_v2=0, nll_loss=1.448, ntokens=1232.6, nsentences=32, sample_size=1232.6, sample_size_v1=0, sample_size_v2=0, ppl=2.73, wps=314.7, ups=0.26, wpb=1232.6, bsz=32, num_updates=3430, lr=9.93592e-06, gnorm=3.306, clip=100, loss_scale=128, train_wall=39, gb_free=8.4, wall=13252
2023-05-20 21:38:54 - progress_bar.py[line:272] - INFO: epoch 002:   1714 / 1732 loss=2.61, loss_v1=0, loss_v2=0, nll_loss=1.446, ntokens=1181.2, nsentences=32, sample_size=1181.2, sample_size_v1=0, sample_size_v2=0, ppl=2.73, wps=302.6, ups=0.26, wpb=1181.2, bsz=32, num_updates=3440, lr=9.93387e-06, gnorm=3.34, clip=100, loss_scale=128, train_wall=39, gb_free=8.3, wall=13291
2023-05-20 21:39:33 - progress_bar.py[line:272] - INFO: epoch 002:   1724 / 1732 loss=2.621, loss_v1=0, loss_v2=0, nll_loss=1.461, ntokens=1135.1, nsentences=32, sample_size=1135.1, sample_size_v1=0, sample_size_v2=0, ppl=2.75, wps=291.4, ups=0.26, wpb=1135.1, bsz=32, num_updates=3450, lr=9.93182e-06, gnorm=3.431, clip=100, loss_scale=128, train_wall=39, gb_free=8.6, wall=13330
2023-05-20 21:40:01 - train.py[line:332] - INFO: end of epoch 2 (average epoch stats below)
2023-05-20 21:40:01 - progress_bar.py[line:282] - INFO: epoch 002 | loss 2.857 | loss_v1 0 | loss_v2 0 | nll_loss 1.745 | ntokens 1051.6 | nsentences 31.986 | sample_size 1051.6 | sample_size_v1 0 | sample_size_v2 0 | ppl 3.35 | wps 272.5 | ups 0.26 | wpb 1051.6 | bsz 32 | num_updates 3458 | lr 9.93018e-06 | gnorm 4.679 | clip 100 | loss_scale 128 | train_wall 6664 | gb_free 8.9 | wall 13358
2023-05-20 21:40:01 - trainer.py[line:639] - INFO: loading train data for epoch 3
local datafile ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 0 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 0 finished initializing row_count and line_idx-to-offset mapping
file ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 0 row count 55400 total row count 55400
slice_id 0 seek offset 0
2023-05-20 21:40:03 - trainer.py[line:703] - INFO: begin training epoch 3
2023-05-20 21:40:03 - train.py[line:305] - INFO: Start iterating over samples
2023-05-20 21:40:11 - progress_bar.py[line:272] - INFO: epoch 003:      2 / 1732 loss=2.653, loss_v1=0, loss_v2=0, nll_loss=1.49, ntokens=1104.4, nsentences=29.6, sample_size=1104.4, sample_size_v1=0, sample_size_v2=0, ppl=2.81, wps=289, ups=0.26, wpb=1104.4, bsz=29.6, num_updates=3460, lr=9.92977e-06, gnorm=3.529, clip=100, loss_scale=128, train_wall=36, gb_free=8, wall=13368
2023-05-20 21:40:50 - progress_bar.py[line:272] - INFO: epoch 003:     12 / 1732 loss=2.544, loss_v1=0, loss_v2=0, nll_loss=1.376, ntokens=1057.9, nsentences=32, sample_size=1057.9, sample_size_v1=0, sample_size_v2=0, ppl=2.6, wps=273.2, ups=0.26, wpb=1057.9, bsz=32, num_updates=3470, lr=9.92773e-06, gnorm=3.705, clip=100, loss_scale=128, train_wall=39, gb_free=8.8, wall=13407
2023-05-20 21:41:29 - progress_bar.py[line:272] - INFO: epoch 003:     22 / 1732 loss=2.472, loss_v1=0, loss_v2=0, nll_loss=1.283, ntokens=1106.7, nsentences=32, sample_size=1106.7, sample_size_v1=0, sample_size_v2=0, ppl=2.43, wps=284.5, ups=0.26, wpb=1106.7, bsz=32, num_updates=3480, lr=9.92568e-06, gnorm=3.427, clip=100, loss_scale=128, train_wall=39, gb_free=8.5, wall=13446
2023-05-20 21:42:08 - progress_bar.py[line:272] - INFO: epoch 003:     32 / 1732 loss=2.523, loss_v1=0, loss_v2=0, nll_loss=1.348, ntokens=985.4, nsentences=32, sample_size=985.4, sample_size_v1=0, sample_size_v2=0, ppl=2.55, wps=253.9, ups=0.26, wpb=985.4, bsz=32, num_updates=3490, lr=9.92363e-06, gnorm=4.419, clip=100, loss_scale=128, train_wall=39, gb_free=7.6, wall=13485
2023-05-20 21:42:47 - progress_bar.py[line:272] - INFO: epoch 003:     42 / 1732 loss=2.386, loss_v1=0, loss_v2=0, nll_loss=1.195, ntokens=1168.8, nsentences=32, sample_size=1168.8, sample_size_v1=0, sample_size_v2=0, ppl=2.29, wps=297.4, ups=0.25, wpb=1168.8, bsz=32, num_updates=3500, lr=9.92159e-06, gnorm=2.953, clip=100, loss_scale=128, train_wall=39, gb_free=8.7, wall=13524
2023-05-20 21:43:26 - progress_bar.py[line:272] - INFO: epoch 003:     52 / 1732 loss=2.478, loss_v1=0, loss_v2=0, nll_loss=1.289, ntokens=1030.1, nsentences=32, sample_size=1030.1, sample_size_v1=0, sample_size_v2=0, ppl=2.44, wps=265.4, ups=0.26, wpb=1030.1, bsz=32, num_updates=3510, lr=9.91954e-06, gnorm=3.698, clip=100, loss_scale=128, train_wall=39, gb_free=8.8, wall=13563
2023-05-20 21:44:05 - progress_bar.py[line:272] - INFO: epoch 003:     62 / 1732 loss=2.202, loss_v1=0, loss_v2=0, nll_loss=0.989, ntokens=1192.6, nsentences=32, sample_size=1192.6, sample_size_v1=0, sample_size_v2=0, ppl=1.98, wps=305.9, ups=0.26, wpb=1192.6, bsz=32, num_updates=3520, lr=9.91749e-06, gnorm=3.102, clip=100, loss_scale=128, train_wall=39, gb_free=7.4, wall=13602
2023-05-20 21:44:45 - progress_bar.py[line:272] - INFO: epoch 003:     72 / 1732 loss=2.352, loss_v1=0, loss_v2=0, nll_loss=1.142, ntokens=1389.6, nsentences=32, sample_size=1389.6, sample_size_v1=0, sample_size_v2=0, ppl=2.21, wps=344.3, ups=0.25, wpb=1389.6, bsz=32, num_updates=3530, lr=9.91544e-06, gnorm=2.977, clip=100, loss_scale=128, train_wall=40, gb_free=7.4, wall=13642
2023-05-20 21:45:25 - progress_bar.py[line:272] - INFO: epoch 003:     82 / 1732 loss=2.403, loss_v1=0, loss_v2=0, nll_loss=1.214, ntokens=1199, nsentences=32, sample_size=1199, sample_size_v1=0, sample_size_v2=0, ppl=2.32, wps=302.8, ups=0.25, wpb=1199, bsz=32, num_updates=3540, lr=9.9134e-06, gnorm=3.27, clip=100, loss_scale=128, train_wall=40, gb_free=8, wall=13682
2023-05-20 21:46:04 - progress_bar.py[line:272] - INFO: epoch 003:     92 / 1732 loss=2.411, loss_v1=0, loss_v2=0, nll_loss=1.218, ntokens=1081.9, nsentences=32, sample_size=1081.9, sample_size_v1=0, sample_size_v2=0, ppl=2.33, wps=276.4, ups=0.26, wpb=1081.9, bsz=32, num_updates=3550, lr=9.91135e-06, gnorm=3.216, clip=100, loss_scale=128, train_wall=39, gb_free=8.3, wall=13721
2023-05-20 21:46:42 - progress_bar.py[line:272] - INFO: epoch 003:    102 / 1732 loss=2.523, loss_v1=0, loss_v2=0, nll_loss=1.354, ntokens=1017.7, nsentences=32, sample_size=1017.7, sample_size_v1=0, sample_size_v2=0, ppl=2.56, wps=264, ups=0.26, wpb=1017.7, bsz=32, num_updates=3560, lr=9.9093e-06, gnorm=3.99, clip=100, loss_scale=128, train_wall=38, gb_free=8.3, wall=13759
2023-05-20 21:47:21 - progress_bar.py[line:272] - INFO: epoch 003:    112 / 1732 loss=2.623, loss_v1=0, loss_v2=0, nll_loss=1.458, ntokens=1026.3, nsentences=32, sample_size=1026.3, sample_size_v1=0, sample_size_v2=0, ppl=2.75, wps=265.5, ups=0.26, wpb=1026.3, bsz=32, num_updates=3570, lr=9.90725e-06, gnorm=3.305, clip=100, loss_scale=128, train_wall=39, gb_free=7.2, wall=13798
2023-05-20 21:48:00 - progress_bar.py[line:272] - INFO: epoch 003:    122 / 1732 loss=2.573, loss_v1=0, loss_v2=0, nll_loss=1.4, ntokens=1103.7, nsentences=32, sample_size=1103.7, sample_size_v1=0, sample_size_v2=0, ppl=2.64, wps=281.8, ups=0.26, wpb=1103.7, bsz=32, num_updates=3580, lr=9.90521e-06, gnorm=3.119, clip=100, loss_scale=128, train_wall=39, gb_free=7.8, wall=13837
2023-05-20 21:48:40 - progress_bar.py[line:272] - INFO: epoch 003:    132 / 1732 loss=2.519, loss_v1=0, loss_v2=0, nll_loss=1.34, ntokens=1224.5, nsentences=32, sample_size=1224.5, sample_size_v1=0, sample_size_v2=0, ppl=2.53, wps=309.8, ups=0.25, wpb=1224.5, bsz=32, num_updates=3590, lr=9.90316e-06, gnorm=2.748, clip=100, loss_scale=128, train_wall=39, gb_free=7.8, wall=13877
2023-05-20 21:49:19 - progress_bar.py[line:272] - INFO: epoch 003:    142 / 1732 loss=2.504, loss_v1=0, loss_v2=0, nll_loss=1.321, ntokens=1223.2, nsentences=32, sample_size=1223.2, sample_size_v1=0, sample_size_v2=0, ppl=2.5, wps=310.3, ups=0.25, wpb=1223.2, bsz=32, num_updates=3600, lr=9.90111e-06, gnorm=2.85, clip=100, loss_scale=128, train_wall=39, gb_free=7.8, wall=13916
2023-05-20 21:49:59 - progress_bar.py[line:272] - INFO: epoch 003:    152 / 1732 loss=2.503, loss_v1=0, loss_v2=0, nll_loss=1.323, ntokens=1158.5, nsentences=32, sample_size=1158.5, sample_size_v1=0, sample_size_v2=0, ppl=2.5, wps=292.5, ups=0.25, wpb=1158.5, bsz=32, num_updates=3610, lr=9.89906e-06, gnorm=2.775, clip=100, loss_scale=128, train_wall=40, gb_free=7.8, wall=13956
2023-05-20 21:50:38 - progress_bar.py[line:272] - INFO: epoch 003:    162 / 1732 loss=2.493, loss_v1=0, loss_v2=0, nll_loss=1.31, ntokens=1101.3, nsentences=32, sample_size=1101.3, sample_size_v1=0, sample_size_v2=0, ppl=2.48, wps=280.5, ups=0.25, wpb=1101.3, bsz=32, num_updates=3620, lr=9.89702e-06, gnorm=2.81, clip=100, loss_scale=128, train_wall=39, gb_free=8.2, wall=13995
2023-05-20 21:51:17 - progress_bar.py[line:272] - INFO: epoch 003:    172 / 1732 loss=2.516, loss_v1=0, loss_v2=0, nll_loss=1.337, ntokens=937.9, nsentences=32, sample_size=937.9, sample_size_v1=0, sample_size_v2=0, ppl=2.53, wps=242.7, ups=0.26, wpb=937.9, bsz=32, num_updates=3630, lr=9.89497e-06, gnorm=3.365, clip=100, loss_scale=128, train_wall=39, gb_free=8.3, wall=14034
2023-05-20 21:51:56 - progress_bar.py[line:272] - INFO: epoch 003:    182 / 1732 loss=2.452, loss_v1=0, loss_v2=0, nll_loss=1.262, ntokens=1177.8, nsentences=32, sample_size=1177.8, sample_size_v1=0, sample_size_v2=0, ppl=2.4, wps=299.3, ups=0.25, wpb=1177.8, bsz=32, num_updates=3640, lr=9.89292e-06, gnorm=3.108, clip=100, loss_scale=128, train_wall=39, gb_free=8.1, wall=14073
2023-05-20 21:52:35 - progress_bar.py[line:272] - INFO: epoch 003:    192 / 1732 loss=2.492, loss_v1=0, loss_v2=0, nll_loss=1.314, ntokens=1116, nsentences=32, sample_size=1116, sample_size_v1=0, sample_size_v2=0, ppl=2.49, wps=285.3, ups=0.26, wpb=1116, bsz=32, num_updates=3650, lr=9.89087e-06, gnorm=3.18, clip=100, loss_scale=128, train_wall=39, gb_free=7.7, wall=14112
2023-05-20 21:53:14 - progress_bar.py[line:272] - INFO: epoch 003:    202 / 1732 loss=2.564, loss_v1=0, loss_v2=0, nll_loss=1.393, ntokens=1088.7, nsentences=32, sample_size=1088.7, sample_size_v1=0, sample_size_v2=0, ppl=2.63, wps=278.8, ups=0.26, wpb=1088.7, bsz=32, num_updates=3660, lr=9.88883e-06, gnorm=3.386, clip=100, loss_scale=128, train_wall=39, gb_free=7.8, wall=14151
2023-05-20 21:53:53 - progress_bar.py[line:272] - INFO: epoch 003:    212 / 1732 loss=2.643, loss_v1=0, loss_v2=0, nll_loss=1.482, ntokens=1014.1, nsentences=32, sample_size=1014.1, sample_size_v1=0, sample_size_v2=0, ppl=2.79, wps=262.9, ups=0.26, wpb=1014.1, bsz=32, num_updates=3670, lr=9.88678e-06, gnorm=3.55, clip=100, loss_scale=128, train_wall=39, gb_free=8.1, wall=14190
2023-05-20 21:54:31 - progress_bar.py[line:272] - INFO: epoch 003:    222 / 1732 loss=2.631, loss_v1=0, loss_v2=0, nll_loss=1.468, ntokens=1144.1, nsentences=32, sample_size=1144.1, sample_size_v1=0, sample_size_v2=0, ppl=2.77, wps=297.5, ups=0.26, wpb=1144.1, bsz=32, num_updates=3680, lr=9.88473e-06, gnorm=3.315, clip=100, loss_scale=128, train_wall=38, gb_free=7.9, wall=14228
2023-05-20 21:55:09 - progress_bar.py[line:272] - INFO: epoch 003:    232 / 1732 loss=2.672, loss_v1=0, loss_v2=0, nll_loss=1.511, ntokens=1097.8, nsentences=32, sample_size=1097.8, sample_size_v1=0, sample_size_v2=0, ppl=2.85, wps=286.8, ups=0.26, wpb=1097.8, bsz=32, num_updates=3690, lr=9.88269e-06, gnorm=3.242, clip=100, loss_scale=128, train_wall=38, gb_free=8.5, wall=14267
2023-05-20 21:55:48 - progress_bar.py[line:272] - INFO: epoch 003:    242 / 1732 loss=2.665, loss_v1=0, loss_v2=0, nll_loss=1.508, ntokens=1115.1, nsentences=32, sample_size=1115.1, sample_size_v1=0, sample_size_v2=0, ppl=2.84, wps=288.8, ups=0.26, wpb=1115.1, bsz=32, num_updates=3700, lr=9.88064e-06, gnorm=3.375, clip=100, loss_scale=128, train_wall=39, gb_free=7.9, wall=14305
2023-05-20 21:56:27 - progress_bar.py[line:272] - INFO: epoch 003:    252 / 1732 loss=2.655, loss_v1=0, loss_v2=0, nll_loss=1.496, ntokens=1167.7, nsentences=32, sample_size=1167.7, sample_size_v1=0, sample_size_v2=0, ppl=2.82, wps=302.9, ups=0.26, wpb=1167.7, bsz=32, num_updates=3710, lr=9.87859e-06, gnorm=2.884, clip=100, loss_scale=128, train_wall=39, gb_free=8.4, wall=14344
2023-05-20 21:57:05 - progress_bar.py[line:272] - INFO: epoch 003:    262 / 1732 loss=2.667, loss_v1=0, loss_v2=0, nll_loss=1.507, ntokens=1134.1, nsentences=32, sample_size=1134.1, sample_size_v1=0, sample_size_v2=0, ppl=2.84, wps=295.5, ups=0.26, wpb=1134.1, bsz=32, num_updates=3720, lr=9.87654e-06, gnorm=3.095, clip=100, loss_scale=128, train_wall=38, gb_free=8.5, wall=14382
2023-05-20 21:57:43 - progress_bar.py[line:272] - INFO: epoch 003:    272 / 1732 loss=2.619, loss_v1=0, loss_v2=0, nll_loss=1.454, ntokens=1139, nsentences=32, sample_size=1139, sample_size_v1=0, sample_size_v2=0, ppl=2.74, wps=295.8, ups=0.26, wpb=1139, bsz=32, num_updates=3730, lr=9.8745e-06, gnorm=2.973, clip=100, loss_scale=128, train_wall=38, gb_free=8.9, wall=14421
2023-05-20 21:58:22 - progress_bar.py[line:272] - INFO: epoch 003:    282 / 1732 loss=2.65, loss_v1=0, loss_v2=0, nll_loss=1.489, ntokens=1161.5, nsentences=32, sample_size=1161.5, sample_size_v1=0, sample_size_v2=0, ppl=2.81, wps=299, ups=0.26, wpb=1161.5, bsz=32, num_updates=3740, lr=9.87245e-06, gnorm=2.814, clip=100, loss_scale=128, train_wall=39, gb_free=7.8, wall=14460
2023-05-20 21:59:01 - progress_bar.py[line:272] - INFO: epoch 003:    292 / 1732 loss=2.612, loss_v1=0, loss_v2=0, nll_loss=1.447, ntokens=1114.9, nsentences=32, sample_size=1114.9, sample_size_v1=0, sample_size_v2=0, ppl=2.73, wps=290.1, ups=0.26, wpb=1114.9, bsz=32, num_updates=3750, lr=9.8704e-06, gnorm=2.885, clip=100, loss_scale=128, train_wall=38, gb_free=8.6, wall=14498
2023-05-20 21:59:39 - progress_bar.py[line:272] - INFO: epoch 003:    302 / 1732 loss=2.651, loss_v1=0, loss_v2=0, nll_loss=1.491, ntokens=1109.4, nsentences=32, sample_size=1109.4, sample_size_v1=0, sample_size_v2=0, ppl=2.81, wps=289.7, ups=0.26, wpb=1109.4, bsz=32, num_updates=3760, lr=9.86835e-06, gnorm=3.094, clip=100, loss_scale=128, train_wall=38, gb_free=8.8, wall=14536
2023-05-20 22:00:18 - progress_bar.py[line:272] - INFO: epoch 003:    312 / 1732 loss=2.605, loss_v1=0, loss_v2=0, nll_loss=1.436, ntokens=1061.9, nsentences=32, sample_size=1061.9, sample_size_v1=0, sample_size_v2=0, ppl=2.71, wps=275.6, ups=0.26, wpb=1061.9, bsz=32, num_updates=3770, lr=9.86631e-06, gnorm=3.006, clip=100, loss_scale=128, train_wall=38, gb_free=8.6, wall=14575
2023-05-20 22:00:56 - progress_bar.py[line:272] - INFO: epoch 003:    322 / 1732 loss=2.67, loss_v1=0, loss_v2=0, nll_loss=1.509, ntokens=1000.1, nsentences=32, sample_size=1000.1, sample_size_v1=0, sample_size_v2=0, ppl=2.85, wps=262.2, ups=0.26, wpb=1000.1, bsz=32, num_updates=3780, lr=9.86426e-06, gnorm=3.427, clip=100, loss_scale=128, train_wall=38, gb_free=8.5, wall=14613
2023-05-20 22:01:34 - progress_bar.py[line:272] - INFO: epoch 003:    332 / 1732 loss=2.629, loss_v1=0, loss_v2=0, nll_loss=1.465, ntokens=1031.9, nsentences=32, sample_size=1031.9, sample_size_v1=0, sample_size_v2=0, ppl=2.76, wps=269.6, ups=0.26, wpb=1031.9, bsz=32, num_updates=3790, lr=9.86221e-06, gnorm=3.068, clip=100, loss_scale=128, train_wall=38, gb_free=8.5, wall=14651
2023-05-20 22:02:12 - progress_bar.py[line:272] - INFO: epoch 003:    342 / 1732 loss=2.606, loss_v1=0, loss_v2=0, nll_loss=1.441, ntokens=926.6, nsentences=32, sample_size=926.6, sample_size_v1=0, sample_size_v2=0, ppl=2.71, wps=244, ups=0.26, wpb=926.6, bsz=32, num_updates=3800, lr=9.86016e-06, gnorm=3.496, clip=100, loss_scale=128, train_wall=38, gb_free=9.1, wall=14689
2023-05-20 22:02:50 - progress_bar.py[line:272] - INFO: epoch 003:    352 / 1732 loss=2.625, loss_v1=0, loss_v2=0, nll_loss=1.463, ntokens=952.9, nsentences=32, sample_size=952.9, sample_size_v1=0, sample_size_v2=0, ppl=2.76, wps=250.3, ups=0.26, wpb=952.9, bsz=32, num_updates=3810, lr=9.85812e-06, gnorm=3.37, clip=100, loss_scale=128, train_wall=38, gb_free=9, wall=14727
2023-05-20 22:03:28 - progress_bar.py[line:272] - INFO: epoch 003:    362 / 1732 loss=2.652, loss_v1=0, loss_v2=0, nll_loss=1.486, ntokens=940.7, nsentences=32, sample_size=940.7, sample_size_v1=0, sample_size_v2=0, ppl=2.8, wps=246.8, ups=0.26, wpb=940.7, bsz=32, num_updates=3820, lr=9.85607e-06, gnorm=3.514, clip=100, loss_scale=128, train_wall=38, gb_free=8.5, wall=14765
2023-05-20 22:04:06 - progress_bar.py[line:272] - INFO: epoch 003:    372 / 1732 loss=2.664, loss_v1=0, loss_v2=0, nll_loss=1.506, ntokens=975.5, nsentences=32, sample_size=975.5, sample_size_v1=0, sample_size_v2=0, ppl=2.84, wps=256.7, ups=0.26, wpb=975.5, bsz=32, num_updates=3830, lr=9.85402e-06, gnorm=3.439, clip=100, loss_scale=256, train_wall=38, gb_free=8.9, wall=14803
2023-05-20 22:04:44 - progress_bar.py[line:272] - INFO: epoch 003:    382 / 1732 loss=2.636, loss_v1=0, loss_v2=0, nll_loss=1.471, ntokens=1062, nsentences=32, sample_size=1062, sample_size_v1=0, sample_size_v2=0, ppl=2.77, wps=279.1, ups=0.26, wpb=1062, bsz=32, num_updates=3840, lr=9.85197e-06, gnorm=2.9, clip=100, loss_scale=256, train_wall=38, gb_free=8.4, wall=14841
2023-05-20 22:05:22 - progress_bar.py[line:272] - INFO: epoch 003:    392 / 1732 loss=2.629, loss_v1=0, loss_v2=0, nll_loss=1.466, ntokens=1004.1, nsentences=32, sample_size=1004.1, sample_size_v1=0, sample_size_v2=0, ppl=2.76, wps=263.5, ups=0.26, wpb=1004.1, bsz=32, num_updates=3850, lr=9.84993e-06, gnorm=3.426, clip=100, loss_scale=256, train_wall=38, gb_free=9.1, wall=14880
2023-05-20 22:05:45 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 128.0
2023-05-20 22:06:04 - progress_bar.py[line:272] - INFO: epoch 003:    403 / 1732 loss=2.603, loss_v1=0, loss_v2=0, nll_loss=1.434, ntokens=1015.5, nsentences=32, sample_size=1015.5, sample_size_v1=0, sample_size_v2=0, ppl=2.7, wps=242.9, ups=0.24, wpb=1015.5, bsz=32, num_updates=3860, lr=9.84788e-06, gnorm=3.132, clip=100, loss_scale=128, train_wall=42, gb_free=8.4, wall=14921
2023-05-20 22:06:42 - progress_bar.py[line:272] - INFO: epoch 003:    413 / 1732 loss=2.605, loss_v1=0, loss_v2=0, nll_loss=1.437, ntokens=1078.5, nsentences=32, sample_size=1078.5, sample_size_v1=0, sample_size_v2=0, ppl=2.71, wps=281.8, ups=0.26, wpb=1078.5, bsz=32, num_updates=3870, lr=9.84583e-06, gnorm=2.904, clip=100, loss_scale=128, train_wall=38, gb_free=8.6, wall=14960
2023-05-20 22:07:21 - progress_bar.py[line:272] - INFO: epoch 003:    423 / 1732 loss=2.593, loss_v1=0, loss_v2=0, nll_loss=1.425, ntokens=985.4, nsentences=32, sample_size=985.4, sample_size_v1=0, sample_size_v2=0, ppl=2.69, wps=258.1, ups=0.26, wpb=985.4, bsz=32, num_updates=3880, lr=9.84379e-06, gnorm=3.214, clip=100, loss_scale=128, train_wall=38, gb_free=8.3, wall=14998
2023-05-20 22:07:59 - progress_bar.py[line:272] - INFO: epoch 003:    433 / 1732 loss=2.611, loss_v1=0, loss_v2=0, nll_loss=1.446, ntokens=1024.2, nsentences=32, sample_size=1024.2, sample_size_v1=0, sample_size_v2=0, ppl=2.72, wps=268.6, ups=0.26, wpb=1024.2, bsz=32, num_updates=3890, lr=9.84174e-06, gnorm=3.436, clip=100, loss_scale=128, train_wall=38, gb_free=9, wall=15036
2023-05-20 22:08:37 - progress_bar.py[line:272] - INFO: epoch 003:    443 / 1732 loss=2.64, loss_v1=0, loss_v2=0, nll_loss=1.477, ntokens=966.7, nsentences=32, sample_size=966.7, sample_size_v1=0, sample_size_v2=0, ppl=2.78, wps=254.3, ups=0.26, wpb=966.7, bsz=32, num_updates=3900, lr=9.83969e-06, gnorm=3.282, clip=100, loss_scale=128, train_wall=38, gb_free=8.9, wall=15074
2023-05-20 22:09:15 - progress_bar.py[line:272] - INFO: epoch 003:    453 / 1732 loss=2.608, loss_v1=0, loss_v2=0, nll_loss=1.441, ntokens=911.8, nsentences=32, sample_size=911.8, sample_size_v1=0, sample_size_v2=0, ppl=2.72, wps=240.2, ups=0.26, wpb=911.8, bsz=32, num_updates=3910, lr=9.83764e-06, gnorm=3.531, clip=100, loss_scale=128, train_wall=38, gb_free=9.1, wall=15112
2023-05-20 22:09:53 - progress_bar.py[line:272] - INFO: epoch 003:    463 / 1732 loss=2.634, loss_v1=0, loss_v2=0, nll_loss=1.468, ntokens=1072.4, nsentences=32, sample_size=1072.4, sample_size_v1=0, sample_size_v2=0, ppl=2.77, wps=280.6, ups=0.26, wpb=1072.4, bsz=32, num_updates=3920, lr=9.8356e-06, gnorm=2.993, clip=100, loss_scale=128, train_wall=38, gb_free=8.8, wall=15150
2023-05-20 22:10:32 - progress_bar.py[line:272] - INFO: epoch 003:    473 / 1732 loss=2.617, loss_v1=0, loss_v2=0, nll_loss=1.448, ntokens=1059.2, nsentences=32, sample_size=1059.2, sample_size_v1=0, sample_size_v2=0, ppl=2.73, wps=274.2, ups=0.26, wpb=1059.2, bsz=32, num_updates=3930, lr=9.83355e-06, gnorm=2.788, clip=100, loss_scale=128, train_wall=39, gb_free=7.5, wall=15189
2023-05-20 22:11:10 - progress_bar.py[line:272] - INFO: epoch 003:    483 / 1732 loss=2.618, loss_v1=0, loss_v2=0, nll_loss=1.453, ntokens=966.6, nsentences=32, sample_size=966.6, sample_size_v1=0, sample_size_v2=0, ppl=2.74, wps=254.2, ups=0.26, wpb=966.6, bsz=32, num_updates=3940, lr=9.8315e-06, gnorm=3.327, clip=100, loss_scale=128, train_wall=38, gb_free=8.8, wall=15227
2023-05-20 22:11:48 - progress_bar.py[line:272] - INFO: epoch 003:    493 / 1732 loss=2.616, loss_v1=0, loss_v2=0, nll_loss=1.451, ntokens=940.2, nsentences=32, sample_size=940.2, sample_size_v1=0, sample_size_v2=0, ppl=2.73, wps=247.2, ups=0.26, wpb=940.2, bsz=32, num_updates=3950, lr=9.82945e-06, gnorm=3.448, clip=100, loss_scale=128, train_wall=38, gb_free=9, wall=15265
2023-05-20 22:12:26 - progress_bar.py[line:272] - INFO: epoch 003:    503 / 1732 loss=2.593, loss_v1=0, loss_v2=0, nll_loss=1.42, ntokens=988.6, nsentences=32, sample_size=988.6, sample_size_v1=0, sample_size_v2=0, ppl=2.68, wps=260, ups=0.26, wpb=988.6, bsz=32, num_updates=3960, lr=9.82741e-06, gnorm=3.345, clip=100, loss_scale=128, train_wall=38, gb_free=9, wall=15303
2023-05-20 22:13:04 - progress_bar.py[line:272] - INFO: epoch 003:    513 / 1732 loss=2.618, loss_v1=0, loss_v2=0, nll_loss=1.453, ntokens=1035, nsentences=32, sample_size=1035, sample_size_v1=0, sample_size_v2=0, ppl=2.74, wps=269.8, ups=0.26, wpb=1035, bsz=32, num_updates=3970, lr=9.82536e-06, gnorm=2.902, clip=100, loss_scale=128, train_wall=38, gb_free=8.9, wall=15341
2023-05-20 22:13:42 - progress_bar.py[line:272] - INFO: epoch 003:    523 / 1732 loss=2.604, loss_v1=0, loss_v2=0, nll_loss=1.434, ntokens=997.6, nsentences=32, sample_size=997.6, sample_size_v1=0, sample_size_v2=0, ppl=2.7, wps=263.9, ups=0.26, wpb=997.6, bsz=32, num_updates=3980, lr=9.82331e-06, gnorm=3.149, clip=100, loss_scale=128, train_wall=38, gb_free=9, wall=15379
2023-05-20 22:14:20 - progress_bar.py[line:272] - INFO: epoch 003:    533 / 1732 loss=2.596, loss_v1=0, loss_v2=0, nll_loss=1.424, ntokens=935, nsentences=32, sample_size=935, sample_size_v1=0, sample_size_v2=0, ppl=2.68, wps=247.2, ups=0.26, wpb=935, bsz=32, num_updates=3990, lr=9.82126e-06, gnorm=3.35, clip=100, loss_scale=128, train_wall=38, gb_free=9, wall=15417
2023-05-20 22:14:58 - progress_bar.py[line:272] - INFO: epoch 003:    543 / 1732 loss=2.615, loss_v1=0, loss_v2=0, nll_loss=1.448, ntokens=1003.8, nsentences=32, sample_size=1003.8, sample_size_v1=0, sample_size_v2=0, ppl=2.73, wps=264.5, ups=0.26, wpb=1003.8, bsz=32, num_updates=4000, lr=9.81922e-06, gnorm=2.945, clip=100, loss_scale=128, train_wall=38, gb_free=8.6, wall=15455
2023-05-20 22:15:36 - progress_bar.py[line:272] - INFO: epoch 003:    553 / 1732 loss=2.648, loss_v1=0, loss_v2=0, nll_loss=1.483, ntokens=1017.4, nsentences=32, sample_size=1017.4, sample_size_v1=0, sample_size_v2=0, ppl=2.8, wps=267.4, ups=0.26, wpb=1017.4, bsz=32, num_updates=4010, lr=9.81717e-06, gnorm=3.292, clip=100, loss_scale=128, train_wall=38, gb_free=9, wall=15493
2023-05-20 22:16:14 - progress_bar.py[line:272] - INFO: epoch 003:    563 / 1732 loss=2.626, loss_v1=0, loss_v2=0, nll_loss=1.46, ntokens=1008.2, nsentences=32, sample_size=1008.2, sample_size_v1=0, sample_size_v2=0, ppl=2.75, wps=263.8, ups=0.26, wpb=1008.2, bsz=32, num_updates=4020, lr=9.81512e-06, gnorm=3.844, clip=100, loss_scale=128, train_wall=38, gb_free=9.3, wall=15531
2023-05-20 22:16:52 - progress_bar.py[line:272] - INFO: epoch 003:    573 / 1732 loss=2.636, loss_v1=0, loss_v2=0, nll_loss=1.468, ntokens=1041.3, nsentences=32, sample_size=1041.3, sample_size_v1=0, sample_size_v2=0, ppl=2.77, wps=271.8, ups=0.26, wpb=1041.3, bsz=32, num_updates=4030, lr=9.81307e-06, gnorm=3.765, clip=100, loss_scale=128, train_wall=38, gb_free=8.1, wall=15569
2023-05-20 22:17:31 - progress_bar.py[line:272] - INFO: epoch 003:    583 / 1732 loss=2.623, loss_v1=0, loss_v2=0, nll_loss=1.458, ntokens=981.7, nsentences=32, sample_size=981.7, sample_size_v1=0, sample_size_v2=0, ppl=2.75, wps=256.6, ups=0.26, wpb=981.7, bsz=32, num_updates=4040, lr=9.81103e-06, gnorm=3.254, clip=100, loss_scale=128, train_wall=38, gb_free=9, wall=15608
2023-05-20 22:18:09 - progress_bar.py[line:272] - INFO: epoch 003:    593 / 1732 loss=2.595, loss_v1=0, loss_v2=0, nll_loss=1.424, ntokens=957.4, nsentences=32, sample_size=957.4, sample_size_v1=0, sample_size_v2=0, ppl=2.68, wps=250.2, ups=0.26, wpb=957.4, bsz=32, num_updates=4050, lr=9.80898e-06, gnorm=3.432, clip=100, loss_scale=128, train_wall=38, gb_free=8.9, wall=15646
2023-05-20 22:18:47 - progress_bar.py[line:272] - INFO: epoch 003:    603 / 1732 loss=2.602, loss_v1=0, loss_v2=0, nll_loss=1.437, ntokens=911.2, nsentences=32, sample_size=911.2, sample_size_v1=0, sample_size_v2=0, ppl=2.71, wps=240.7, ups=0.26, wpb=911.2, bsz=32, num_updates=4060, lr=9.80693e-06, gnorm=3.424, clip=100, loss_scale=128, train_wall=38, gb_free=8.7, wall=15684
2023-05-20 22:19:25 - progress_bar.py[line:272] - INFO: epoch 003:    613 / 1732 loss=2.601, loss_v1=0, loss_v2=0, nll_loss=1.43, ntokens=893.3, nsentences=32, sample_size=893.3, sample_size_v1=0, sample_size_v2=0, ppl=2.7, wps=235.3, ups=0.26, wpb=893.3, bsz=32, num_updates=4070, lr=9.80489e-06, gnorm=3.621, clip=100, loss_scale=128, train_wall=38, gb_free=9.1, wall=15722
2023-05-20 22:20:02 - progress_bar.py[line:272] - INFO: epoch 003:    623 / 1732 loss=2.621, loss_v1=0, loss_v2=0, nll_loss=1.453, ntokens=887.2, nsentences=32, sample_size=887.2, sample_size_v1=0, sample_size_v2=0, ppl=2.74, wps=235.1, ups=0.26, wpb=887.2, bsz=32, num_updates=4080, lr=9.80284e-06, gnorm=3.753, clip=100, loss_scale=128, train_wall=38, gb_free=8.3, wall=15760
2023-05-20 22:20:40 - progress_bar.py[line:272] - INFO: epoch 003:    633 / 1732 loss=2.606, loss_v1=0, loss_v2=0, nll_loss=1.439, ntokens=925, nsentences=32, sample_size=925, sample_size_v1=0, sample_size_v2=0, ppl=2.71, wps=244, ups=0.26, wpb=925, bsz=32, num_updates=4090, lr=9.80079e-06, gnorm=3.399, clip=100, loss_scale=128, train_wall=38, gb_free=8.7, wall=15797
2023-05-20 22:21:18 - progress_bar.py[line:272] - INFO: epoch 003:    643 / 1732 loss=2.623, loss_v1=0, loss_v2=0, nll_loss=1.457, ntokens=963.8, nsentences=32, sample_size=963.8, sample_size_v1=0, sample_size_v2=0, ppl=2.75, wps=255.1, ups=0.26, wpb=963.8, bsz=32, num_updates=4100, lr=9.79874e-06, gnorm=3.606, clip=100, loss_scale=128, train_wall=38, gb_free=9, wall=15835
2023-05-20 22:21:56 - progress_bar.py[line:272] - INFO: epoch 003:    653 / 1732 loss=2.618, loss_v1=0, loss_v2=0, nll_loss=1.451, ntokens=928, nsentences=32, sample_size=928, sample_size_v1=0, sample_size_v2=0, ppl=2.73, wps=245.9, ups=0.26, wpb=928, bsz=32, num_updates=4110, lr=9.7967e-06, gnorm=3.526, clip=100, loss_scale=128, train_wall=38, gb_free=9.1, wall=15873
2023-05-20 22:22:34 - progress_bar.py[line:272] - INFO: epoch 003:    663 / 1732 loss=2.621, loss_v1=0, loss_v2=0, nll_loss=1.454, ntokens=882.9, nsentences=32, sample_size=882.9, sample_size_v1=0, sample_size_v2=0, ppl=2.74, wps=232.5, ups=0.26, wpb=882.9, bsz=32, num_updates=4120, lr=9.79465e-06, gnorm=3.795, clip=100, loss_scale=128, train_wall=38, gb_free=8.8, wall=15911
2023-05-20 22:23:12 - progress_bar.py[line:272] - INFO: epoch 003:    673 / 1732 loss=2.625, loss_v1=0, loss_v2=0, nll_loss=1.457, ntokens=954.3, nsentences=32, sample_size=954.3, sample_size_v1=0, sample_size_v2=0, ppl=2.75, wps=252.4, ups=0.26, wpb=954.3, bsz=32, num_updates=4130, lr=9.7926e-06, gnorm=3.503, clip=100, loss_scale=128, train_wall=38, gb_free=9, wall=15949
2023-05-20 22:23:50 - progress_bar.py[line:272] - INFO: epoch 003:    683 / 1732 loss=2.591, loss_v1=0, loss_v2=0, nll_loss=1.422, ntokens=960.5, nsentences=32, sample_size=960.5, sample_size_v1=0, sample_size_v2=0, ppl=2.68, wps=252.9, ups=0.26, wpb=960.5, bsz=32, num_updates=4140, lr=9.79055e-06, gnorm=3.59, clip=100, loss_scale=128, train_wall=38, gb_free=9.2, wall=15987
2023-05-20 22:24:28 - progress_bar.py[line:272] - INFO: epoch 003:    693 / 1732 loss=2.628, loss_v1=0, loss_v2=0, nll_loss=1.463, ntokens=962.9, nsentences=32, sample_size=962.9, sample_size_v1=0, sample_size_v2=0, ppl=2.76, wps=252.8, ups=0.26, wpb=962.9, bsz=32, num_updates=4150, lr=9.78851e-06, gnorm=3.586, clip=100, loss_scale=128, train_wall=38, gb_free=8.3, wall=16025
2023-05-20 22:25:06 - progress_bar.py[line:272] - INFO: epoch 003:    703 / 1732 loss=2.559, loss_v1=0, loss_v2=0, nll_loss=1.384, ntokens=972.9, nsentences=32, sample_size=972.9, sample_size_v1=0, sample_size_v2=0, ppl=2.61, wps=255.3, ups=0.26, wpb=972.9, bsz=32, num_updates=4160, lr=9.78646e-06, gnorm=3.308, clip=100, loss_scale=128, train_wall=38, gb_free=8.9, wall=16063
2023-05-20 22:25:44 - progress_bar.py[line:272] - INFO: epoch 003:    713 / 1732 loss=2.628, loss_v1=0, loss_v2=0, nll_loss=1.461, ntokens=898.6, nsentences=32, sample_size=898.6, sample_size_v1=0, sample_size_v2=0, ppl=2.75, wps=237.4, ups=0.26, wpb=898.6, bsz=32, num_updates=4170, lr=9.78441e-06, gnorm=3.454, clip=100, loss_scale=128, train_wall=38, gb_free=9.1, wall=16101
2023-05-20 22:26:21 - progress_bar.py[line:272] - INFO: epoch 003:    723 / 1732 loss=2.584, loss_v1=0, loss_v2=0, nll_loss=1.417, ntokens=877.5, nsentences=32, sample_size=877.5, sample_size_v1=0, sample_size_v2=0, ppl=2.67, wps=232.5, ups=0.26, wpb=877.5, bsz=32, num_updates=4180, lr=9.78236e-06, gnorm=3.42, clip=100, loss_scale=128, train_wall=38, gb_free=9.2, wall=16139
2023-05-20 22:26:59 - progress_bar.py[line:272] - INFO: epoch 003:    733 / 1732 loss=2.58, loss_v1=0, loss_v2=0, nll_loss=1.41, ntokens=959.6, nsentences=32, sample_size=959.6, sample_size_v1=0, sample_size_v2=0, ppl=2.66, wps=252.7, ups=0.26, wpb=959.6, bsz=32, num_updates=4190, lr=9.78032e-06, gnorm=3.177, clip=100, loss_scale=128, train_wall=38, gb_free=8.2, wall=16177
2023-05-20 22:27:37 - progress_bar.py[line:272] - INFO: epoch 003:    743 / 1732 loss=2.571, loss_v1=0, loss_v2=0, nll_loss=1.398, ntokens=991.8, nsentences=32, sample_size=991.8, sample_size_v1=0, sample_size_v2=0, ppl=2.64, wps=262.1, ups=0.26, wpb=991.8, bsz=32, num_updates=4200, lr=9.77827e-06, gnorm=3.392, clip=100, loss_scale=128, train_wall=38, gb_free=8.7, wall=16214
2023-05-20 22:28:15 - progress_bar.py[line:272] - INFO: epoch 003:    753 / 1732 loss=2.592, loss_v1=0, loss_v2=0, nll_loss=1.422, ntokens=968.6, nsentences=32, sample_size=968.6, sample_size_v1=0, sample_size_v2=0, ppl=2.68, wps=255, ups=0.26, wpb=968.6, bsz=32, num_updates=4210, lr=9.77622e-06, gnorm=3.604, clip=100, loss_scale=128, train_wall=38, gb_free=8.7, wall=16252
2023-05-20 22:28:53 - progress_bar.py[line:272] - INFO: epoch 003:    763 / 1732 loss=2.588, loss_v1=0, loss_v2=0, nll_loss=1.418, ntokens=964, nsentences=32, sample_size=964, sample_size_v1=0, sample_size_v2=0, ppl=2.67, wps=254.7, ups=0.26, wpb=964, bsz=32, num_updates=4220, lr=9.77417e-06, gnorm=3.208, clip=100, loss_scale=128, train_wall=38, gb_free=8.8, wall=16290
2023-05-20 22:29:31 - progress_bar.py[line:272] - INFO: epoch 003:    773 / 1732 loss=2.582, loss_v1=0, loss_v2=0, nll_loss=1.413, ntokens=971.7, nsentences=32, sample_size=971.7, sample_size_v1=0, sample_size_v2=0, ppl=2.66, wps=255.9, ups=0.26, wpb=971.7, bsz=32, num_updates=4230, lr=9.77213e-06, gnorm=3.345, clip=100, loss_scale=128, train_wall=38, gb_free=8.8, wall=16328
2023-05-20 22:30:09 - progress_bar.py[line:272] - INFO: epoch 003:    783 / 1732 loss=2.6, loss_v1=0, loss_v2=0, nll_loss=1.427, ntokens=1008.4, nsentences=32, sample_size=1008.4, sample_size_v1=0, sample_size_v2=0, ppl=2.69, wps=265.3, ups=0.26, wpb=1008.4, bsz=32, num_updates=4240, lr=9.77008e-06, gnorm=3.413, clip=100, loss_scale=128, train_wall=38, gb_free=8.4, wall=16366
2023-05-20 22:30:47 - progress_bar.py[line:272] - INFO: epoch 003:    793 / 1732 loss=2.575, loss_v1=0, loss_v2=0, nll_loss=1.401, ntokens=1034.6, nsentences=32, sample_size=1034.6, sample_size_v1=0, sample_size_v2=0, ppl=2.64, wps=270.4, ups=0.26, wpb=1034.6, bsz=32, num_updates=4250, lr=9.76803e-06, gnorm=3.38, clip=100, loss_scale=128, train_wall=38, gb_free=8.8, wall=16405
2023-05-20 22:31:25 - progress_bar.py[line:272] - INFO: epoch 003:    803 / 1732 loss=2.594, loss_v1=0, loss_v2=0, nll_loss=1.424, ntokens=964.4, nsentences=32, sample_size=964.4, sample_size_v1=0, sample_size_v2=0, ppl=2.68, wps=252.7, ups=0.26, wpb=964.4, bsz=32, num_updates=4260, lr=9.76598e-06, gnorm=3.682, clip=100, loss_scale=128, train_wall=38, gb_free=8.1, wall=16443
2023-05-20 22:32:03 - progress_bar.py[line:272] - INFO: epoch 003:    813 / 1732 loss=2.6, loss_v1=0, loss_v2=0, nll_loss=1.432, ntokens=940.9, nsentences=32, sample_size=940.9, sample_size_v1=0, sample_size_v2=0, ppl=2.7, wps=248.2, ups=0.26, wpb=940.9, bsz=32, num_updates=4270, lr=9.76394e-06, gnorm=3.66, clip=100, loss_scale=128, train_wall=38, gb_free=7.6, wall=16481
2023-05-20 22:32:42 - progress_bar.py[line:272] - INFO: epoch 003:    823 / 1732 loss=2.596, loss_v1=0, loss_v2=0, nll_loss=1.424, ntokens=915.1, nsentences=32, sample_size=915.1, sample_size_v1=0, sample_size_v2=0, ppl=2.68, wps=239.1, ups=0.26, wpb=915.1, bsz=32, num_updates=4280, lr=9.76189e-06, gnorm=3.716, clip=100, loss_scale=128, train_wall=38, gb_free=8.3, wall=16519
2023-05-20 22:33:19 - progress_bar.py[line:272] - INFO: epoch 003:    833 / 1732 loss=2.585, loss_v1=0, loss_v2=0, nll_loss=1.411, ntokens=907.5, nsentences=32, sample_size=907.5, sample_size_v1=0, sample_size_v2=0, ppl=2.66, wps=240.7, ups=0.27, wpb=907.5, bsz=32, num_updates=4290, lr=9.75984e-06, gnorm=3.391, clip=100, loss_scale=128, train_wall=38, gb_free=9.1, wall=16557
2023-05-20 22:33:57 - progress_bar.py[line:272] - INFO: epoch 003:    843 / 1732 loss=2.555, loss_v1=0, loss_v2=0, nll_loss=1.379, ntokens=950.7, nsentences=32, sample_size=950.7, sample_size_v1=0, sample_size_v2=0, ppl=2.6, wps=251.4, ups=0.26, wpb=950.7, bsz=32, num_updates=4300, lr=9.7578e-06, gnorm=3.56, clip=100, loss_scale=128, train_wall=38, gb_free=9, wall=16594
2023-05-20 22:34:35 - progress_bar.py[line:272] - INFO: epoch 003:    853 / 1732 loss=2.581, loss_v1=0, loss_v2=0, nll_loss=1.407, ntokens=1006.3, nsentences=32, sample_size=1006.3, sample_size_v1=0, sample_size_v2=0, ppl=2.65, wps=265, ups=0.26, wpb=1006.3, bsz=32, num_updates=4310, lr=9.75575e-06, gnorm=3.217, clip=100, loss_scale=128, train_wall=38, gb_free=8.3, wall=16632
2023-05-20 22:35:13 - progress_bar.py[line:272] - INFO: epoch 003:    863 / 1732 loss=2.574, loss_v1=0, loss_v2=0, nll_loss=1.407, ntokens=933.3, nsentences=32, sample_size=933.3, sample_size_v1=0, sample_size_v2=0, ppl=2.65, wps=246.6, ups=0.26, wpb=933.3, bsz=32, num_updates=4320, lr=9.7537e-06, gnorm=3.336, clip=100, loss_scale=128, train_wall=38, gb_free=8.6, wall=16670
2023-05-20 22:35:51 - progress_bar.py[line:272] - INFO: epoch 003:    873 / 1732 loss=2.562, loss_v1=0, loss_v2=0, nll_loss=1.386, ntokens=966.4, nsentences=32, sample_size=966.4, sample_size_v1=0, sample_size_v2=0, ppl=2.61, wps=255.2, ups=0.26, wpb=966.4, bsz=32, num_updates=4330, lr=9.75165e-06, gnorm=3.359, clip=100, loss_scale=128, train_wall=38, gb_free=8.6, wall=16708
2023-05-20 22:36:29 - progress_bar.py[line:272] - INFO: epoch 003:    883 / 1732 loss=2.523, loss_v1=0, loss_v2=0, nll_loss=1.343, ntokens=985.5, nsentences=32, sample_size=985.5, sample_size_v1=0, sample_size_v2=0, ppl=2.54, wps=257.7, ups=0.26, wpb=985.5, bsz=32, num_updates=4340, lr=9.74961e-06, gnorm=3.386, clip=100, loss_scale=128, train_wall=38, gb_free=8.5, wall=16746
2023-05-20 22:37:07 - progress_bar.py[line:272] - INFO: epoch 003:    893 / 1732 loss=2.544, loss_v1=0, loss_v2=0, nll_loss=1.368, ntokens=1009.8, nsentences=32, sample_size=1009.8, sample_size_v1=0, sample_size_v2=0, ppl=2.58, wps=264.2, ups=0.26, wpb=1009.8, bsz=32, num_updates=4350, lr=9.74756e-06, gnorm=3.276, clip=100, loss_scale=128, train_wall=38, gb_free=8.3, wall=16785
2023-05-20 22:37:46 - progress_bar.py[line:272] - INFO: epoch 003:    903 / 1732 loss=2.523, loss_v1=0, loss_v2=0, nll_loss=1.343, ntokens=1049.7, nsentences=32, sample_size=1049.7, sample_size_v1=0, sample_size_v2=0, ppl=2.54, wps=273.8, ups=0.26, wpb=1049.7, bsz=32, num_updates=4360, lr=9.74551e-06, gnorm=3.367, clip=100, loss_scale=128, train_wall=38, gb_free=8.7, wall=16823
2023-05-20 22:38:24 - progress_bar.py[line:272] - INFO: epoch 003:    913 / 1732 loss=2.617, loss_v1=0, loss_v2=0, nll_loss=1.449, ntokens=930.6, nsentences=32, sample_size=930.6, sample_size_v1=0, sample_size_v2=0, ppl=2.73, wps=244.4, ups=0.26, wpb=930.6, bsz=32, num_updates=4370, lr=9.74346e-06, gnorm=3.261, clip=100, loss_scale=256, train_wall=38, gb_free=8.2, wall=16861
2023-05-20 22:39:02 - progress_bar.py[line:272] - INFO: epoch 003:    923 / 1732 loss=2.557, loss_v1=0, loss_v2=0, nll_loss=1.382, ntokens=1023.3, nsentences=32, sample_size=1023.3, sample_size_v1=0, sample_size_v2=0, ppl=2.61, wps=266, ups=0.26, wpb=1023.3, bsz=32, num_updates=4380, lr=9.74142e-06, gnorm=3.17, clip=100, loss_scale=256, train_wall=38, gb_free=8.3, wall=16899
2023-05-20 22:39:17 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 128.0
2023-05-20 22:39:44 - progress_bar.py[line:272] - INFO: epoch 003:    934 / 1732 loss=2.548, loss_v1=0, loss_v2=0, nll_loss=1.374, ntokens=1015.5, nsentences=32, sample_size=1015.5, sample_size_v1=0, sample_size_v2=0, ppl=2.59, wps=240.9, ups=0.24, wpb=1015.5, bsz=32, num_updates=4390, lr=9.73937e-06, gnorm=3.002, clip=100, loss_scale=128, train_wall=42, gb_free=8.9, wall=16942
2023-05-20 22:40:23 - progress_bar.py[line:272] - INFO: epoch 003:    944 / 1732 loss=2.583, loss_v1=0, loss_v2=0, nll_loss=1.412, ntokens=1062, nsentences=32, sample_size=1062, sample_size_v1=0, sample_size_v2=0, ppl=2.66, wps=272.9, ups=0.26, wpb=1062, bsz=32, num_updates=4400, lr=9.73732e-06, gnorm=2.838, clip=100, loss_scale=128, train_wall=39, gb_free=8, wall=16981
2023-05-20 22:41:02 - progress_bar.py[line:272] - INFO: epoch 003:    954 / 1732 loss=2.554, loss_v1=0, loss_v2=0, nll_loss=1.378, ntokens=1041, nsentences=32, sample_size=1041, sample_size_v1=0, sample_size_v2=0, ppl=2.6, wps=268.7, ups=0.26, wpb=1041, bsz=32, num_updates=4410, lr=9.73527e-06, gnorm=3.056, clip=100, loss_scale=128, train_wall=39, gb_free=8.2, wall=17019
2023-05-20 22:41:41 - progress_bar.py[line:272] - INFO: epoch 003:    964 / 1732 loss=2.57, loss_v1=0, loss_v2=0, nll_loss=1.398, ntokens=1053, nsentences=32, sample_size=1053, sample_size_v1=0, sample_size_v2=0, ppl=2.63, wps=272.4, ups=0.26, wpb=1053, bsz=32, num_updates=4420, lr=9.73323e-06, gnorm=3.068, clip=100, loss_scale=128, train_wall=39, gb_free=8.6, wall=17058
2023-05-20 22:42:19 - progress_bar.py[line:272] - INFO: epoch 003:    974 / 1732 loss=2.579, loss_v1=0, loss_v2=0, nll_loss=1.406, ntokens=1051.9, nsentences=32, sample_size=1051.9, sample_size_v1=0, sample_size_v2=0, ppl=2.65, wps=273, ups=0.26, wpb=1051.9, bsz=32, num_updates=4430, lr=9.73118e-06, gnorm=3.065, clip=100, loss_scale=128, train_wall=38, gb_free=8.7, wall=17096
2023-05-20 22:42:58 - progress_bar.py[line:272] - INFO: epoch 003:    984 / 1732 loss=2.566, loss_v1=0, loss_v2=0, nll_loss=1.394, ntokens=1029.3, nsentences=32, sample_size=1029.3, sample_size_v1=0, sample_size_v2=0, ppl=2.63, wps=265.7, ups=0.26, wpb=1029.3, bsz=32, num_updates=4440, lr=9.72913e-06, gnorm=2.981, clip=100, loss_scale=128, train_wall=39, gb_free=7.9, wall=17135
2023-05-20 22:43:37 - progress_bar.py[line:272] - INFO: epoch 003:    994 / 1732 loss=2.552, loss_v1=0, loss_v2=0, nll_loss=1.375, ntokens=1030.4, nsentences=32, sample_size=1030.4, sample_size_v1=0, sample_size_v2=0, ppl=2.59, wps=266.5, ups=0.26, wpb=1030.4, bsz=32, num_updates=4450, lr=9.72708e-06, gnorm=3.264, clip=100, loss_scale=128, train_wall=39, gb_free=8.7, wall=17174
2023-05-20 22:44:15 - progress_bar.py[line:272] - INFO: epoch 003:   1004 / 1732 loss=2.551, loss_v1=0, loss_v2=0, nll_loss=1.373, ntokens=995.4, nsentences=32, sample_size=995.4, sample_size_v1=0, sample_size_v2=0, ppl=2.59, wps=258.4, ups=0.26, wpb=995.4, bsz=32, num_updates=4460, lr=9.72504e-06, gnorm=3.331, clip=100, loss_scale=128, train_wall=38, gb_free=9.1, wall=17212
2023-05-20 22:44:54 - progress_bar.py[line:272] - INFO: epoch 003:   1014 / 1732 loss=2.543, loss_v1=0, loss_v2=0, nll_loss=1.366, ntokens=997.1, nsentences=32, sample_size=997.1, sample_size_v1=0, sample_size_v2=0, ppl=2.58, wps=259.8, ups=0.26, wpb=997.1, bsz=32, num_updates=4470, lr=9.72299e-06, gnorm=3.195, clip=100, loss_scale=128, train_wall=38, gb_free=8.5, wall=17251
2023-05-20 22:45:32 - progress_bar.py[line:272] - INFO: epoch 003:   1024 / 1732 loss=2.552, loss_v1=0, loss_v2=0, nll_loss=1.378, ntokens=1086.7, nsentences=32, sample_size=1086.7, sample_size_v1=0, sample_size_v2=0, ppl=2.6, wps=280.3, ups=0.26, wpb=1086.7, bsz=32, num_updates=4480, lr=9.72094e-06, gnorm=3.175, clip=100, loss_scale=128, train_wall=39, gb_free=8.6, wall=17290
2023-05-20 22:46:11 - progress_bar.py[line:272] - INFO: epoch 003:   1034 / 1732 loss=2.557, loss_v1=0, loss_v2=0, nll_loss=1.38, ntokens=1103.2, nsentences=32, sample_size=1103.2, sample_size_v1=0, sample_size_v2=0, ppl=2.6, wps=282.9, ups=0.26, wpb=1103.2, bsz=32, num_updates=4490, lr=9.7189e-06, gnorm=3.39, clip=100, loss_scale=128, train_wall=39, gb_free=7.9, wall=17329
2023-05-20 22:46:50 - progress_bar.py[line:272] - INFO: epoch 003:   1044 / 1732 loss=2.554, loss_v1=0, loss_v2=0, nll_loss=1.376, ntokens=1052.8, nsentences=32, sample_size=1052.8, sample_size_v1=0, sample_size_v2=0, ppl=2.6, wps=272.1, ups=0.26, wpb=1052.8, bsz=32, num_updates=4500, lr=9.71685e-06, gnorm=3.129, clip=100, loss_scale=128, train_wall=39, gb_free=8.4, wall=17367
2023-05-20 22:47:28 - progress_bar.py[line:272] - INFO: epoch 003:   1054 / 1732 loss=2.562, loss_v1=0, loss_v2=0, nll_loss=1.387, ntokens=1068, nsentences=32, sample_size=1068, sample_size_v1=0, sample_size_v2=0, ppl=2.61, wps=278, ups=0.26, wpb=1068, bsz=32, num_updates=4510, lr=9.7148e-06, gnorm=3.31, clip=100, loss_scale=128, train_wall=38, gb_free=7, wall=17406
2023-05-20 22:48:07 - progress_bar.py[line:272] - INFO: epoch 003:   1064 / 1732 loss=2.548, loss_v1=0, loss_v2=0, nll_loss=1.37, ntokens=1024.1, nsentences=32, sample_size=1024.1, sample_size_v1=0, sample_size_v2=0, ppl=2.59, wps=265.3, ups=0.26, wpb=1024.1, bsz=32, num_updates=4520, lr=9.71275e-06, gnorm=3.244, clip=100, loss_scale=128, train_wall=39, gb_free=8.7, wall=17444
2023-05-20 22:48:46 - progress_bar.py[line:272] - INFO: epoch 003:   1074 / 1732 loss=2.551, loss_v1=0, loss_v2=0, nll_loss=1.371, ntokens=1002.8, nsentences=32, sample_size=1002.8, sample_size_v1=0, sample_size_v2=0, ppl=2.59, wps=259.8, ups=0.26, wpb=1002.8, bsz=32, num_updates=4530, lr=9.71071e-06, gnorm=3.275, clip=100, loss_scale=128, train_wall=39, gb_free=8.4, wall=17483
2023-05-20 22:49:24 - progress_bar.py[line:272] - INFO: epoch 003:   1084 / 1732 loss=2.584, loss_v1=0, loss_v2=0, nll_loss=1.415, ntokens=1060.4, nsentences=32, sample_size=1060.4, sample_size_v1=0, sample_size_v2=0, ppl=2.67, wps=273.3, ups=0.26, wpb=1060.4, bsz=32, num_updates=4540, lr=9.70866e-06, gnorm=3.174, clip=100, loss_scale=128, train_wall=39, gb_free=7.2, wall=17522
2023-05-20 22:50:03 - progress_bar.py[line:272] - INFO: epoch 003:   1094 / 1732 loss=2.543, loss_v1=0, loss_v2=0, nll_loss=1.363, ntokens=1050.5, nsentences=32, sample_size=1050.5, sample_size_v1=0, sample_size_v2=0, ppl=2.57, wps=271.2, ups=0.26, wpb=1050.5, bsz=32, num_updates=4550, lr=9.70661e-06, gnorm=2.895, clip=100, loss_scale=128, train_wall=39, gb_free=7.8, wall=17560
2023-05-20 22:50:42 - progress_bar.py[line:272] - INFO: epoch 003:   1104 / 1732 loss=2.558, loss_v1=0, loss_v2=0, nll_loss=1.385, ntokens=1042.3, nsentences=32, sample_size=1042.3, sample_size_v1=0, sample_size_v2=0, ppl=2.61, wps=269.8, ups=0.26, wpb=1042.3, bsz=32, num_updates=4560, lr=9.70456e-06, gnorm=2.965, clip=100, loss_scale=128, train_wall=39, gb_free=8.4, wall=17599
2023-05-20 22:51:21 - progress_bar.py[line:272] - INFO: epoch 003:   1114 / 1732 loss=2.551, loss_v1=0, loss_v2=0, nll_loss=1.376, ntokens=1000.7, nsentences=32, sample_size=1000.7, sample_size_v1=0, sample_size_v2=0, ppl=2.6, wps=258.6, ups=0.26, wpb=1000.7, bsz=32, num_updates=4570, lr=9.70252e-06, gnorm=3.342, clip=100, loss_scale=128, train_wall=39, gb_free=8.5, wall=17638
2023-05-20 22:51:59 - progress_bar.py[line:272] - INFO: epoch 003:   1124 / 1732 loss=2.557, loss_v1=0, loss_v2=0, nll_loss=1.379, ntokens=989.1, nsentences=32, sample_size=989.1, sample_size_v1=0, sample_size_v2=0, ppl=2.6, wps=256.8, ups=0.26, wpb=989.1, bsz=32, num_updates=4580, lr=9.70047e-06, gnorm=3.467, clip=100, loss_scale=128, train_wall=38, gb_free=8.4, wall=17676
2023-05-20 22:52:38 - progress_bar.py[line:272] - INFO: epoch 003:   1134 / 1732 loss=2.563, loss_v1=0, loss_v2=0, nll_loss=1.388, ntokens=968.8, nsentences=32, sample_size=968.8, sample_size_v1=0, sample_size_v2=0, ppl=2.62, wps=252, ups=0.26, wpb=968.8, bsz=32, num_updates=4590, lr=9.69842e-06, gnorm=3.118, clip=100, loss_scale=128, train_wall=38, gb_free=8.6, wall=17715
2023-05-20 22:53:16 - progress_bar.py[line:272] - INFO: epoch 003:   1144 / 1732 loss=2.561, loss_v1=0, loss_v2=0, nll_loss=1.386, ntokens=1034.3, nsentences=32, sample_size=1034.3, sample_size_v1=0, sample_size_v2=0, ppl=2.61, wps=268.5, ups=0.26, wpb=1034.3, bsz=32, num_updates=4600, lr=9.69637e-06, gnorm=2.953, clip=100, loss_scale=128, train_wall=38, gb_free=8.7, wall=17753
2023-05-20 22:53:54 - progress_bar.py[line:272] - INFO: epoch 003:   1154 / 1732 loss=2.558, loss_v1=0, loss_v2=0, nll_loss=1.382, ntokens=1025.8, nsentences=32, sample_size=1025.8, sample_size_v1=0, sample_size_v2=0, ppl=2.61, wps=266.8, ups=0.26, wpb=1025.8, bsz=32, num_updates=4610, lr=9.69433e-06, gnorm=3.076, clip=100, loss_scale=128, train_wall=38, gb_free=7.4, wall=17792
2023-05-20 22:54:33 - progress_bar.py[line:272] - INFO: epoch 003:   1164 / 1732 loss=2.516, loss_v1=0, loss_v2=0, nll_loss=1.335, ntokens=1008, nsentences=32, sample_size=1008, sample_size_v1=0, sample_size_v2=0, ppl=2.52, wps=260.3, ups=0.26, wpb=1008, bsz=32, num_updates=4620, lr=9.69228e-06, gnorm=3.337, clip=100, loss_scale=128, train_wall=39, gb_free=8.7, wall=17830
2023-05-20 22:55:12 - progress_bar.py[line:272] - INFO: epoch 003:   1174 / 1732 loss=2.553, loss_v1=0, loss_v2=0, nll_loss=1.373, ntokens=1081.1, nsentences=32, sample_size=1081.1, sample_size_v1=0, sample_size_v2=0, ppl=2.59, wps=279.7, ups=0.26, wpb=1081.1, bsz=32, num_updates=4630, lr=9.69023e-06, gnorm=2.874, clip=100, loss_scale=128, train_wall=39, gb_free=8.1, wall=17869
2023-05-20 22:55:50 - progress_bar.py[line:272] - INFO: epoch 003:   1184 / 1732 loss=2.564, loss_v1=0, loss_v2=0, nll_loss=1.392, ntokens=962, nsentences=32, sample_size=962, sample_size_v1=0, sample_size_v2=0, ppl=2.62, wps=251.4, ups=0.26, wpb=962, bsz=32, num_updates=4640, lr=9.68818e-06, gnorm=3.371, clip=100, loss_scale=128, train_wall=38, gb_free=8.8, wall=17907
2023-05-20 22:56:29 - progress_bar.py[line:272] - INFO: epoch 003:   1194 / 1732 loss=2.561, loss_v1=0, loss_v2=0, nll_loss=1.383, ntokens=1042.6, nsentences=32, sample_size=1042.6, sample_size_v1=0, sample_size_v2=0, ppl=2.61, wps=270.1, ups=0.26, wpb=1042.6, bsz=32, num_updates=4650, lr=9.68614e-06, gnorm=3.021, clip=100, loss_scale=128, train_wall=39, gb_free=8.7, wall=17946
2023-05-20 22:57:08 - progress_bar.py[line:272] - INFO: epoch 003:   1204 / 1732 loss=2.513, loss_v1=0, loss_v2=0, nll_loss=1.329, ntokens=1150.2, nsentences=32, sample_size=1150.2, sample_size_v1=0, sample_size_v2=0, ppl=2.51, wps=293.9, ups=0.26, wpb=1150.2, bsz=32, num_updates=4660, lr=9.68409e-06, gnorm=2.648, clip=100, loss_scale=128, train_wall=39, gb_free=8.4, wall=17985
2023-05-20 22:57:46 - progress_bar.py[line:272] - INFO: epoch 003:   1214 / 1732 loss=2.538, loss_v1=0, loss_v2=0, nll_loss=1.359, ntokens=996.3, nsentences=32, sample_size=996.3, sample_size_v1=0, sample_size_v2=0, ppl=2.56, wps=259.3, ups=0.26, wpb=996.3, bsz=32, num_updates=4670, lr=9.68204e-06, gnorm=3.159, clip=100, loss_scale=128, train_wall=38, gb_free=8.9, wall=18024
2023-05-20 22:58:25 - progress_bar.py[line:272] - INFO: epoch 003:   1224 / 1732 loss=2.57, loss_v1=0, loss_v2=0, nll_loss=1.395, ntokens=1056.3, nsentences=32, sample_size=1056.3, sample_size_v1=0, sample_size_v2=0, ppl=2.63, wps=273.3, ups=0.26, wpb=1056.3, bsz=32, num_updates=4680, lr=9.68e-06, gnorm=3.178, clip=100, loss_scale=128, train_wall=39, gb_free=8.7, wall=18062
2023-05-20 22:59:04 - progress_bar.py[line:272] - INFO: epoch 003:   1234 / 1732 loss=2.532, loss_v1=0, loss_v2=0, nll_loss=1.352, ntokens=1012.2, nsentences=32, sample_size=1012.2, sample_size_v1=0, sample_size_v2=0, ppl=2.55, wps=260.6, ups=0.26, wpb=1012.2, bsz=32, num_updates=4690, lr=9.67795e-06, gnorm=3.023, clip=100, loss_scale=128, train_wall=39, gb_free=8.7, wall=18101
2023-05-20 22:59:42 - progress_bar.py[line:272] - INFO: epoch 003:   1244 / 1732 loss=2.484, loss_v1=0, loss_v2=0, nll_loss=1.298, ntokens=1090.2, nsentences=32, sample_size=1090.2, sample_size_v1=0, sample_size_v2=0, ppl=2.46, wps=282.3, ups=0.26, wpb=1090.2, bsz=32, num_updates=4700, lr=9.6759e-06, gnorm=3.078, clip=100, loss_scale=128, train_wall=39, gb_free=8.6, wall=18140
2023-05-20 23:00:21 - progress_bar.py[line:272] - INFO: epoch 003:   1254 / 1732 loss=2.518, loss_v1=0, loss_v2=0, nll_loss=1.336, ntokens=1076, nsentences=32, sample_size=1076, sample_size_v1=0, sample_size_v2=0, ppl=2.53, wps=278.2, ups=0.26, wpb=1076, bsz=32, num_updates=4710, lr=9.67385e-06, gnorm=3.103, clip=100, loss_scale=128, train_wall=39, gb_free=8.8, wall=18178
2023-05-20 23:01:00 - progress_bar.py[line:272] - INFO: epoch 003:   1264 / 1732 loss=2.555, loss_v1=0, loss_v2=0, nll_loss=1.381, ntokens=1095.2, nsentences=32, sample_size=1095.2, sample_size_v1=0, sample_size_v2=0, ppl=2.61, wps=282.1, ups=0.26, wpb=1095.2, bsz=32, num_updates=4720, lr=9.67181e-06, gnorm=2.867, clip=100, loss_scale=128, train_wall=39, gb_free=7.8, wall=18217
2023-05-20 23:01:38 - progress_bar.py[line:272] - INFO: epoch 003:   1274 / 1732 loss=2.54, loss_v1=0, loss_v2=0, nll_loss=1.359, ntokens=1014.1, nsentences=32, sample_size=1014.1, sample_size_v1=0, sample_size_v2=0, ppl=2.56, wps=263.7, ups=0.26, wpb=1014.1, bsz=32, num_updates=4730, lr=9.66976e-06, gnorm=3.121, clip=100, loss_scale=128, train_wall=38, gb_free=8.1, wall=18256
2023-05-20 23:02:17 - progress_bar.py[line:272] - INFO: epoch 003:   1284 / 1732 loss=2.548, loss_v1=0, loss_v2=0, nll_loss=1.371, ntokens=1057.3, nsentences=32, sample_size=1057.3, sample_size_v1=0, sample_size_v2=0, ppl=2.59, wps=272.3, ups=0.26, wpb=1057.3, bsz=32, num_updates=4740, lr=9.66771e-06, gnorm=3.001, clip=100, loss_scale=128, train_wall=39, gb_free=8.8, wall=18294
2023-05-20 23:02:56 - progress_bar.py[line:272] - INFO: epoch 003:   1294 / 1732 loss=2.52, loss_v1=0, loss_v2=0, nll_loss=1.339, ntokens=1109.4, nsentences=32, sample_size=1109.4, sample_size_v1=0, sample_size_v2=0, ppl=2.53, wps=285.9, ups=0.26, wpb=1109.4, bsz=32, num_updates=4750, lr=9.66566e-06, gnorm=2.913, clip=100, loss_scale=128, train_wall=39, gb_free=8.3, wall=18333
2023-05-20 23:03:35 - progress_bar.py[line:272] - INFO: epoch 003:   1304 / 1732 loss=2.55, loss_v1=0, loss_v2=0, nll_loss=1.374, ntokens=1090.1, nsentences=32, sample_size=1090.1, sample_size_v1=0, sample_size_v2=0, ppl=2.59, wps=279.2, ups=0.26, wpb=1090.1, bsz=32, num_updates=4760, lr=9.66362e-06, gnorm=2.976, clip=100, loss_scale=128, train_wall=39, gb_free=8.3, wall=18372
2023-05-20 23:04:14 - progress_bar.py[line:272] - INFO: epoch 003:   1314 / 1732 loss=2.56, loss_v1=0, loss_v2=0, nll_loss=1.381, ntokens=1051.4, nsentences=32, sample_size=1051.4, sample_size_v1=0, sample_size_v2=0, ppl=2.6, wps=269.3, ups=0.26, wpb=1051.4, bsz=32, num_updates=4770, lr=9.66157e-06, gnorm=3.035, clip=100, loss_scale=128, train_wall=39, gb_free=8, wall=18411
2023-05-20 23:04:53 - progress_bar.py[line:272] - INFO: epoch 003:   1324 / 1732 loss=2.508, loss_v1=0, loss_v2=0, nll_loss=1.325, ntokens=1117, nsentences=32, sample_size=1117, sample_size_v1=0, sample_size_v2=0, ppl=2.5, wps=286.2, ups=0.26, wpb=1117, bsz=32, num_updates=4780, lr=9.65952e-06, gnorm=2.881, clip=100, loss_scale=128, train_wall=39, gb_free=8.5, wall=18450
2023-05-20 23:05:32 - progress_bar.py[line:272] - INFO: epoch 003:   1334 / 1732 loss=2.508, loss_v1=0, loss_v2=0, nll_loss=1.328, ntokens=1097.8, nsentences=32, sample_size=1097.8, sample_size_v1=0, sample_size_v2=0, ppl=2.51, wps=283.8, ups=0.26, wpb=1097.8, bsz=32, num_updates=4790, lr=9.65747e-06, gnorm=3.068, clip=100, loss_scale=128, train_wall=39, gb_free=8.8, wall=18489
2023-05-20 23:06:11 - progress_bar.py[line:272] - INFO: epoch 003:   1344 / 1732 loss=2.535, loss_v1=0, loss_v2=0, nll_loss=1.356, ntokens=1201.2, nsentences=32, sample_size=1201.2, sample_size_v1=0, sample_size_v2=0, ppl=2.56, wps=308, ups=0.26, wpb=1201.2, bsz=32, num_updates=4800, lr=9.65543e-06, gnorm=3.007, clip=100, loss_scale=128, train_wall=39, gb_free=8, wall=18528
2023-05-20 23:06:50 - progress_bar.py[line:272] - INFO: epoch 003:   1354 / 1732 loss=2.524, loss_v1=0, loss_v2=0, nll_loss=1.343, ntokens=1101.2, nsentences=32, sample_size=1101.2, sample_size_v1=0, sample_size_v2=0, ppl=2.54, wps=284.1, ups=0.26, wpb=1101.2, bsz=32, num_updates=4810, lr=9.65338e-06, gnorm=3.017, clip=100, loss_scale=128, train_wall=39, gb_free=8.6, wall=18567
2023-05-20 23:07:29 - progress_bar.py[line:272] - INFO: epoch 003:   1364 / 1732 loss=2.506, loss_v1=0, loss_v2=0, nll_loss=1.324, ntokens=1115.3, nsentences=32, sample_size=1115.3, sample_size_v1=0, sample_size_v2=0, ppl=2.5, wps=285.7, ups=0.26, wpb=1115.3, bsz=32, num_updates=4820, lr=9.65133e-06, gnorm=2.955, clip=100, loss_scale=128, train_wall=39, gb_free=8.2, wall=18606
2023-05-20 23:08:07 - progress_bar.py[line:272] - INFO: epoch 003:   1374 / 1732 loss=2.564, loss_v1=0, loss_v2=0, nll_loss=1.39, ntokens=1075.1, nsentences=32, sample_size=1075.1, sample_size_v1=0, sample_size_v2=0, ppl=2.62, wps=278, ups=0.26, wpb=1075.1, bsz=32, num_updates=4830, lr=9.64928e-06, gnorm=2.872, clip=100, loss_scale=128, train_wall=39, gb_free=8.9, wall=18645
2023-05-20 23:08:46 - progress_bar.py[line:272] - INFO: epoch 003:   1384 / 1732 loss=2.541, loss_v1=0, loss_v2=0, nll_loss=1.36, ntokens=1167.1, nsentences=32, sample_size=1167.1, sample_size_v1=0, sample_size_v2=0, ppl=2.57, wps=299.3, ups=0.26, wpb=1167.1, bsz=32, num_updates=4840, lr=9.64724e-06, gnorm=2.836, clip=100, loss_scale=128, train_wall=39, gb_free=7.9, wall=18684
2023-05-20 23:09:25 - progress_bar.py[line:272] - INFO: epoch 003:   1394 / 1732 loss=2.53, loss_v1=0, loss_v2=0, nll_loss=1.354, ntokens=1039.3, nsentences=32, sample_size=1039.3, sample_size_v1=0, sample_size_v2=0, ppl=2.56, wps=269.5, ups=0.26, wpb=1039.3, bsz=32, num_updates=4850, lr=9.64519e-06, gnorm=2.902, clip=100, loss_scale=128, train_wall=39, gb_free=7.7, wall=18722
2023-05-20 23:10:04 - progress_bar.py[line:272] - INFO: epoch 003:   1404 / 1732 loss=2.512, loss_v1=0, loss_v2=0, nll_loss=1.327, ntokens=1161.9, nsentences=32, sample_size=1161.9, sample_size_v1=0, sample_size_v2=0, ppl=2.51, wps=299.1, ups=0.26, wpb=1161.9, bsz=32, num_updates=4860, lr=9.64314e-06, gnorm=2.966, clip=100, loss_scale=128, train_wall=39, gb_free=7.1, wall=18761
2023-05-20 23:10:43 - progress_bar.py[line:272] - INFO: epoch 003:   1414 / 1732 loss=2.537, loss_v1=0, loss_v2=0, nll_loss=1.359, ntokens=1276, nsentences=32, sample_size=1276, sample_size_v1=0, sample_size_v2=0, ppl=2.56, wps=327.2, ups=0.26, wpb=1276, bsz=32, num_updates=4870, lr=9.64109e-06, gnorm=2.783, clip=100, loss_scale=128, train_wall=39, gb_free=7.7, wall=18800
2023-05-20 23:11:22 - progress_bar.py[line:272] - INFO: epoch 003:   1424 / 1732 loss=2.532, loss_v1=0, loss_v2=0, nll_loss=1.351, ntokens=1261.9, nsentences=32, sample_size=1261.9, sample_size_v1=0, sample_size_v2=0, ppl=2.55, wps=321.4, ups=0.25, wpb=1261.9, bsz=32, num_updates=4880, lr=9.63905e-06, gnorm=3.119, clip=100, loss_scale=128, train_wall=39, gb_free=7.7, wall=18839
2023-05-20 23:12:01 - progress_bar.py[line:272] - INFO: epoch 003:   1434 / 1732 loss=2.51, loss_v1=0, loss_v2=0, nll_loss=1.333, ntokens=1196.2, nsentences=32, sample_size=1196.2, sample_size_v1=0, sample_size_v2=0, ppl=2.52, wps=307.6, ups=0.26, wpb=1196.2, bsz=32, num_updates=4890, lr=9.637e-06, gnorm=2.722, clip=100, loss_scale=128, train_wall=39, gb_free=8.2, wall=18878
2023-05-20 23:12:40 - progress_bar.py[line:272] - INFO: epoch 003:   1444 / 1732 loss=2.542, loss_v1=0, loss_v2=0, nll_loss=1.359, ntokens=1129.1, nsentences=32, sample_size=1129.1, sample_size_v1=0, sample_size_v2=0, ppl=2.57, wps=289.8, ups=0.26, wpb=1129.1, bsz=32, num_updates=4900, lr=9.63495e-06, gnorm=3.027, clip=100, loss_scale=256, train_wall=39, gb_free=7.7, wall=18917
2023-05-20 23:13:19 - progress_bar.py[line:272] - INFO: epoch 003:   1454 / 1732 loss=2.54, loss_v1=0, loss_v2=0, nll_loss=1.36, ntokens=1122, nsentences=32, sample_size=1122, sample_size_v1=0, sample_size_v2=0, ppl=2.57, wps=289.1, ups=0.26, wpb=1122, bsz=32, num_updates=4910, lr=9.63291e-06, gnorm=3.089, clip=100, loss_scale=256, train_wall=39, gb_free=8, wall=18956
2023-05-20 23:13:58 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 128.0
2023-05-20 23:14:02 - progress_bar.py[line:272] - INFO: epoch 003:   1465 / 1732 loss=2.483, loss_v1=0, loss_v2=0, nll_loss=1.298, ntokens=1190.6, nsentences=32, sample_size=1190.6, sample_size_v1=0, sample_size_v2=0, ppl=2.46, wps=277.1, ups=0.23, wpb=1190.6, bsz=32, num_updates=4920, lr=9.63086e-06, gnorm=2.991, clip=100, loss_scale=128, train_wall=43, gb_free=8.5, wall=18999
2023-05-20 23:14:40 - progress_bar.py[line:272] - INFO: epoch 003:   1475 / 1732 loss=2.541, loss_v1=0, loss_v2=0, nll_loss=1.363, ntokens=1082.9, nsentences=32, sample_size=1082.9, sample_size_v1=0, sample_size_v2=0, ppl=2.57, wps=280.3, ups=0.26, wpb=1082.9, bsz=32, num_updates=4930, lr=9.62881e-06, gnorm=3.743, clip=100, loss_scale=128, train_wall=39, gb_free=8.1, wall=19038
2023-05-20 23:15:19 - progress_bar.py[line:272] - INFO: epoch 003:   1485 / 1732 loss=2.537, loss_v1=0, loss_v2=0, nll_loss=1.353, ntokens=1103.4, nsentences=32, sample_size=1103.4, sample_size_v1=0, sample_size_v2=0, ppl=2.55, wps=284.2, ups=0.26, wpb=1103.4, bsz=32, num_updates=4940, lr=9.62676e-06, gnorm=3.487, clip=100, loss_scale=128, train_wall=39, gb_free=7.7, wall=19076
2023-05-20 23:15:58 - progress_bar.py[line:272] - INFO: epoch 003:   1495 / 1732 loss=2.513, loss_v1=0, loss_v2=0, nll_loss=1.33, ntokens=1111.1, nsentences=32, sample_size=1111.1, sample_size_v1=0, sample_size_v2=0, ppl=2.51, wps=285.1, ups=0.26, wpb=1111.1, bsz=32, num_updates=4950, lr=9.62472e-06, gnorm=2.818, clip=100, loss_scale=128, train_wall=39, gb_free=7.5, wall=19115
2023-05-20 23:16:37 - progress_bar.py[line:272] - INFO: epoch 003:   1505 / 1732 loss=2.483, loss_v1=0, loss_v2=0, nll_loss=1.3, ntokens=1137.1, nsentences=32, sample_size=1137.1, sample_size_v1=0, sample_size_v2=0, ppl=2.46, wps=294.1, ups=0.26, wpb=1137.1, bsz=32, num_updates=4960, lr=9.62267e-06, gnorm=2.741, clip=100, loss_scale=128, train_wall=39, gb_free=8.5, wall=19154
2023-05-20 23:17:15 - progress_bar.py[line:272] - INFO: epoch 003:   1515 / 1732 loss=2.536, loss_v1=0, loss_v2=0, nll_loss=1.356, ntokens=1046.4, nsentences=32, sample_size=1046.4, sample_size_v1=0, sample_size_v2=0, ppl=2.56, wps=270.9, ups=0.26, wpb=1046.4, bsz=32, num_updates=4970, lr=9.62062e-06, gnorm=3.211, clip=100, loss_scale=128, train_wall=39, gb_free=8.3, wall=19193
2023-05-20 23:17:54 - progress_bar.py[line:272] - INFO: epoch 003:   1525 / 1732 loss=2.565, loss_v1=0, loss_v2=0, nll_loss=1.389, ntokens=1040.6, nsentences=32, sample_size=1040.6, sample_size_v1=0, sample_size_v2=0, ppl=2.62, wps=268.3, ups=0.26, wpb=1040.6, bsz=32, num_updates=4980, lr=9.61857e-06, gnorm=3.077, clip=100, loss_scale=128, train_wall=39, gb_free=8.1, wall=19231
2023-05-20 23:18:33 - progress_bar.py[line:272] - INFO: epoch 003:   1535 / 1732 loss=2.537, loss_v1=0, loss_v2=0, nll_loss=1.352, ntokens=1087.5, nsentences=32, sample_size=1087.5, sample_size_v1=0, sample_size_v2=0, ppl=2.55, wps=279.6, ups=0.26, wpb=1087.5, bsz=32, num_updates=4990, lr=9.61653e-06, gnorm=3.132, clip=100, loss_scale=128, train_wall=39, gb_free=7.8, wall=19270
2023-05-20 23:19:12 - progress_bar.py[line:272] - INFO: epoch 003:   1545 / 1732 loss=2.504, loss_v1=0, loss_v2=0, nll_loss=1.32, ntokens=1079.7, nsentences=32, sample_size=1079.7, sample_size_v1=0, sample_size_v2=0, ppl=2.5, wps=279.4, ups=0.26, wpb=1079.7, bsz=32, num_updates=5000, lr=9.61448e-06, gnorm=3.024, clip=100, loss_scale=128, train_wall=39, gb_free=8.8, wall=19309
2023-05-20 23:19:50 - progress_bar.py[line:272] - INFO: epoch 003:   1555 / 1732 loss=2.503, loss_v1=0, loss_v2=0, nll_loss=1.326, ntokens=1057.3, nsentences=32, sample_size=1057.3, sample_size_v1=0, sample_size_v2=0, ppl=2.51, wps=274.4, ups=0.26, wpb=1057.3, bsz=32, num_updates=5010, lr=9.61243e-06, gnorm=3.101, clip=100, loss_scale=128, train_wall=38, gb_free=8.5, wall=19348
2023-05-20 23:20:29 - progress_bar.py[line:272] - INFO: epoch 003:   1565 / 1732 loss=2.565, loss_v1=0, loss_v2=0, nll_loss=1.386, ntokens=1124.1, nsentences=32, sample_size=1124.1, sample_size_v1=0, sample_size_v2=0, ppl=2.61, wps=289.4, ups=0.26, wpb=1124.1, bsz=32, num_updates=5020, lr=9.61038e-06, gnorm=3.169, clip=100, loss_scale=128, train_wall=39, gb_free=7.7, wall=19386
2023-05-20 23:21:08 - progress_bar.py[line:272] - INFO: epoch 003:   1575 / 1732 loss=2.555, loss_v1=0, loss_v2=0, nll_loss=1.377, ntokens=1025.1, nsentences=32, sample_size=1025.1, sample_size_v1=0, sample_size_v2=0, ppl=2.6, wps=265.6, ups=0.26, wpb=1025.1, bsz=32, num_updates=5030, lr=9.60834e-06, gnorm=3.384, clip=100, loss_scale=128, train_wall=39, gb_free=8.9, wall=19425
2023-05-20 23:21:47 - progress_bar.py[line:272] - INFO: epoch 003:   1585 / 1732 loss=2.541, loss_v1=0, loss_v2=0, nll_loss=1.362, ntokens=1049.1, nsentences=32, sample_size=1049.1, sample_size_v1=0, sample_size_v2=0, ppl=2.57, wps=270.7, ups=0.26, wpb=1049.1, bsz=32, num_updates=5040, lr=9.60629e-06, gnorm=3.435, clip=100, loss_scale=128, train_wall=39, gb_free=7.7, wall=19464
2023-05-20 23:22:25 - progress_bar.py[line:272] - INFO: epoch 003:   1595 / 1732 loss=2.516, loss_v1=0, loss_v2=0, nll_loss=1.335, ntokens=1072.1, nsentences=32, sample_size=1072.1, sample_size_v1=0, sample_size_v2=0, ppl=2.52, wps=276.8, ups=0.26, wpb=1072.1, bsz=32, num_updates=5050, lr=9.60424e-06, gnorm=3.01, clip=100, loss_scale=128, train_wall=39, gb_free=8.2, wall=19502
2023-05-20 23:23:04 - progress_bar.py[line:272] - INFO: epoch 003:   1605 / 1732 loss=2.51, loss_v1=0, loss_v2=0, nll_loss=1.325, ntokens=1099, nsentences=32, sample_size=1099, sample_size_v1=0, sample_size_v2=0, ppl=2.5, wps=284, ups=0.26, wpb=1099, bsz=32, num_updates=5060, lr=9.60219e-06, gnorm=3.003, clip=100, loss_scale=128, train_wall=39, gb_free=8.3, wall=19541
2023-05-20 23:23:43 - progress_bar.py[line:272] - INFO: epoch 003:   1615 / 1732 loss=2.488, loss_v1=0, loss_v2=0, nll_loss=1.307, ntokens=1176.8, nsentences=32, sample_size=1176.8, sample_size_v1=0, sample_size_v2=0, ppl=2.47, wps=300.1, ups=0.25, wpb=1176.8, bsz=32, num_updates=5070, lr=9.60015e-06, gnorm=2.979, clip=100, loss_scale=128, train_wall=39, gb_free=8.5, wall=19580
2023-05-20 23:24:22 - progress_bar.py[line:272] - INFO: epoch 003:   1625 / 1732 loss=2.508, loss_v1=0, loss_v2=0, nll_loss=1.323, ntokens=1075.4, nsentences=32, sample_size=1075.4, sample_size_v1=0, sample_size_v2=0, ppl=2.5, wps=276.8, ups=0.26, wpb=1075.4, bsz=32, num_updates=5080, lr=9.5981e-06, gnorm=3.094, clip=100, loss_scale=128, train_wall=39, gb_free=7.6, wall=19619
2023-05-20 23:25:01 - progress_bar.py[line:272] - INFO: epoch 003:   1635 / 1732 loss=2.494, loss_v1=0, loss_v2=0, nll_loss=1.308, ntokens=1182.6, nsentences=32, sample_size=1182.6, sample_size_v1=0, sample_size_v2=0, ppl=2.48, wps=304.4, ups=0.26, wpb=1182.6, bsz=32, num_updates=5090, lr=9.59605e-06, gnorm=3.128, clip=100, loss_scale=128, train_wall=39, gb_free=7.7, wall=19658
2023-05-20 23:25:40 - progress_bar.py[line:272] - INFO: epoch 003:   1645 / 1732 loss=2.465, loss_v1=0, loss_v2=0, nll_loss=1.276, ntokens=1274.6, nsentences=32, sample_size=1274.6, sample_size_v1=0, sample_size_v2=0, ppl=2.42, wps=325, ups=0.25, wpb=1274.6, bsz=32, num_updates=5100, lr=9.59401e-06, gnorm=2.702, clip=100, loss_scale=128, train_wall=39, gb_free=8.2, wall=19697
2023-05-20 23:26:18 - progress_bar.py[line:272] - INFO: epoch 003:   1655 / 1732 loss=2.541, loss_v1=0, loss_v2=0, nll_loss=1.362, ntokens=951.7, nsentences=32, sample_size=951.7, sample_size_v1=0, sample_size_v2=0, ppl=2.57, wps=248.4, ups=0.26, wpb=951.7, bsz=32, num_updates=5110, lr=9.59196e-06, gnorm=3.556, clip=100, loss_scale=128, train_wall=38, gb_free=8.3, wall=19736
2023-05-20 23:26:57 - progress_bar.py[line:272] - INFO: epoch 003:   1665 / 1732 loss=2.536, loss_v1=0, loss_v2=0, nll_loss=1.354, ntokens=1028.1, nsentences=32, sample_size=1028.1, sample_size_v1=0, sample_size_v2=0, ppl=2.56, wps=266, ups=0.26, wpb=1028.1, bsz=32, num_updates=5120, lr=9.58991e-06, gnorm=2.805, clip=100, loss_scale=128, train_wall=39, gb_free=8.3, wall=19774
2023-05-20 23:27:36 - progress_bar.py[line:272] - INFO: epoch 003:   1675 / 1732 loss=2.484, loss_v1=0, loss_v2=0, nll_loss=1.297, ntokens=1102.6, nsentences=32, sample_size=1102.6, sample_size_v1=0, sample_size_v2=0, ppl=2.46, wps=282.8, ups=0.26, wpb=1102.6, bsz=32, num_updates=5130, lr=9.58786e-06, gnorm=2.849, clip=100, loss_scale=128, train_wall=39, gb_free=6.8, wall=19813
2023-05-20 23:28:15 - progress_bar.py[line:272] - INFO: epoch 003:   1685 / 1732 loss=2.485, loss_v1=0, loss_v2=0, nll_loss=1.302, ntokens=1141.1, nsentences=32, sample_size=1141.1, sample_size_v1=0, sample_size_v2=0, ppl=2.47, wps=293, ups=0.26, wpb=1141.1, bsz=32, num_updates=5140, lr=9.58582e-06, gnorm=2.693, clip=100, loss_scale=128, train_wall=39, gb_free=8.5, wall=19852
2023-05-20 23:28:55 - progress_bar.py[line:272] - INFO: epoch 003:   1695 / 1732 loss=2.516, loss_v1=0, loss_v2=0, nll_loss=1.334, ntokens=1274.5, nsentences=32, sample_size=1274.5, sample_size_v1=0, sample_size_v2=0, ppl=2.52, wps=322.7, ups=0.25, wpb=1274.5, bsz=32, num_updates=5150, lr=9.58377e-06, gnorm=2.787, clip=100, loss_scale=128, train_wall=39, gb_free=8.2, wall=19892
2023-05-20 23:29:34 - progress_bar.py[line:272] - INFO: epoch 003:   1705 / 1732 loss=2.498, loss_v1=0, loss_v2=0, nll_loss=1.312, ntokens=1217, nsentences=32, sample_size=1217, sample_size_v1=0, sample_size_v2=0, ppl=2.48, wps=310, ups=0.25, wpb=1217, bsz=32, num_updates=5160, lr=9.58172e-06, gnorm=2.702, clip=100, loss_scale=128, train_wall=39, gb_free=7.9, wall=19931
2023-05-20 23:30:13 - progress_bar.py[line:272] - INFO: epoch 003:   1715 / 1732 loss=2.487, loss_v1=0, loss_v2=0, nll_loss=1.302, ntokens=1196, nsentences=32, sample_size=1196, sample_size_v1=0, sample_size_v2=0, ppl=2.47, wps=306.8, ups=0.26, wpb=1196, bsz=32, num_updates=5170, lr=9.57967e-06, gnorm=2.9, clip=100, loss_scale=128, train_wall=39, gb_free=7.9, wall=19970
2023-05-20 23:30:52 - progress_bar.py[line:272] - INFO: epoch 003:   1725 / 1732 loss=2.533, loss_v1=0, loss_v2=0, nll_loss=1.351, ntokens=1108.9, nsentences=32, sample_size=1108.9, sample_size_v1=0, sample_size_v2=0, ppl=2.55, wps=285.3, ups=0.26, wpb=1108.9, bsz=32, num_updates=5180, lr=9.57763e-06, gnorm=2.87, clip=100, loss_scale=128, train_wall=39, gb_free=8.5, wall=20009
2023-05-20 23:31:16 - train.py[line:332] - INFO: end of epoch 3 (average epoch stats below)
2023-05-20 23:31:16 - progress_bar.py[line:282] - INFO: epoch 003 | loss 2.557 | loss_v1 0 | loss_v2 0 | nll_loss 1.381 | ntokens 1051.5 | nsentences 31.986 | sample_size 1051.5 | sample_size_v1 0 | sample_size_v2 0 | ppl 2.61 | wps 272.4 | ups 0.26 | wpb 1051.5 | bsz 32 | num_updates 5187 | lr 9.57619e-06 | gnorm 3.199 | clip 100 | loss_scale 128 | train_wall 6664 | gb_free 8.9 | wall 20033
2023-05-20 23:31:16 - trainer.py[line:639] - INFO: loading train data for epoch 4
local datafile ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 0 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 0 finished initializing row_count and line_idx-to-offset mapping
file ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 0 row count 55400 total row count 55400
slice_id 0 seek offset 0
2023-05-20 23:31:18 - trainer.py[line:703] - INFO: begin training epoch 4
2023-05-20 23:31:18 - train.py[line:305] - INFO: Start iterating over samples
2023-05-20 23:31:30 - progress_bar.py[line:272] - INFO: epoch 004:      3 / 1732 loss=2.515, loss_v1=0, loss_v2=0, nll_loss=1.33, ntokens=1127.6, nsentences=29.6, sample_size=1127.6, sample_size_v1=0, sample_size_v2=0, ppl=2.51, wps=295.1, ups=0.26, wpb=1127.6, bsz=29.6, num_updates=5190, lr=9.57558e-06, gnorm=3.109, clip=100, loss_scale=128, train_wall=36, gb_free=8.2, wall=20047
2023-05-20 23:32:09 - progress_bar.py[line:272] - INFO: epoch 004:     13 / 1732 loss=2.457, loss_v1=0, loss_v2=0, nll_loss=1.27, ntokens=1037.7, nsentences=32, sample_size=1037.7, sample_size_v1=0, sample_size_v2=0, ppl=2.41, wps=267.5, ups=0.26, wpb=1037.7, bsz=32, num_updates=5200, lr=9.57353e-06, gnorm=2.987, clip=100, loss_scale=128, train_wall=39, gb_free=8.2, wall=20086
2023-05-20 23:32:48 - progress_bar.py[line:272] - INFO: epoch 004:     23 / 1732 loss=2.378, loss_v1=0, loss_v2=0, nll_loss=1.174, ntokens=1082, nsentences=32, sample_size=1082, sample_size_v1=0, sample_size_v2=0, ppl=2.26, wps=278.2, ups=0.26, wpb=1082, bsz=32, num_updates=5210, lr=9.57148e-06, gnorm=3.089, clip=100, loss_scale=128, train_wall=39, gb_free=8.6, wall=20125
2023-05-20 23:33:27 - progress_bar.py[line:272] - INFO: epoch 004:     33 / 1732 loss=2.378, loss_v1=0, loss_v2=0, nll_loss=1.177, ntokens=1032.3, nsentences=32, sample_size=1032.3, sample_size_v1=0, sample_size_v2=0, ppl=2.26, wps=265, ups=0.26, wpb=1032.3, bsz=32, num_updates=5220, lr=9.56944e-06, gnorm=3.5, clip=100, loss_scale=128, train_wall=39, gb_free=7.2, wall=20164
2023-05-20 23:34:06 - progress_bar.py[line:272] - INFO: epoch 004:     43 / 1732 loss=2.304, loss_v1=0, loss_v2=0, nll_loss=1.099, ntokens=1156.8, nsentences=32, sample_size=1156.8, sample_size_v1=0, sample_size_v2=0, ppl=2.14, wps=296.4, ups=0.26, wpb=1156.8, bsz=32, num_updates=5230, lr=9.56739e-06, gnorm=2.649, clip=100, loss_scale=128, train_wall=39, gb_free=8.1, wall=20203
2023-05-20 23:34:44 - progress_bar.py[line:272] - INFO: epoch 004:     53 / 1732 loss=2.367, loss_v1=0, loss_v2=0, nll_loss=1.161, ntokens=1016.6, nsentences=32, sample_size=1016.6, sample_size_v1=0, sample_size_v2=0, ppl=2.24, wps=261.6, ups=0.26, wpb=1016.6, bsz=32, num_updates=5240, lr=9.56534e-06, gnorm=3.21, clip=100, loss_scale=128, train_wall=39, gb_free=8.6, wall=20242
2023-05-20 23:35:24 - progress_bar.py[line:272] - INFO: epoch 004:     63 / 1732 loss=2.12, loss_v1=0, loss_v2=0, nll_loss=0.895, ntokens=1239.4, nsentences=32, sample_size=1239.4, sample_size_v1=0, sample_size_v2=0, ppl=1.86, wps=315.5, ups=0.25, wpb=1239.4, bsz=32, num_updates=5250, lr=9.56329e-06, gnorm=2.589, clip=100, loss_scale=128, train_wall=39, gb_free=7.3, wall=20281
2023-05-20 23:36:04 - progress_bar.py[line:272] - INFO: epoch 004:     73 / 1732 loss=2.279, loss_v1=0, loss_v2=0, nll_loss=1.058, ntokens=1389.6, nsentences=32, sample_size=1389.6, sample_size_v1=0, sample_size_v2=0, ppl=2.08, wps=345.7, ups=0.25, wpb=1389.6, bsz=32, num_updates=5260, lr=9.56125e-06, gnorm=2.554, clip=100, loss_scale=128, train_wall=40, gb_free=7, wall=20321
2023-05-20 23:36:43 - progress_bar.py[line:272] - INFO: epoch 004:     83 / 1732 loss=2.324, loss_v1=0, loss_v2=0, nll_loss=1.121, ntokens=1166.3, nsentences=32, sample_size=1166.3, sample_size_v1=0, sample_size_v2=0, ppl=2.18, wps=295.2, ups=0.25, wpb=1166.3, bsz=32, num_updates=5270, lr=9.5592e-06, gnorm=2.715, clip=100, loss_scale=128, train_wall=39, gb_free=7.2, wall=20361
2023-05-20 23:37:22 - progress_bar.py[line:272] - INFO: epoch 004:     93 / 1732 loss=2.294, loss_v1=0, loss_v2=0, nll_loss=1.08, ntokens=1099.1, nsentences=32, sample_size=1099.1, sample_size_v1=0, sample_size_v2=0, ppl=2.11, wps=281.6, ups=0.26, wpb=1099.1, bsz=32, num_updates=5280, lr=9.55715e-06, gnorm=2.587, clip=100, loss_scale=128, train_wall=39, gb_free=8.2, wall=20400
2023-05-20 23:38:01 - progress_bar.py[line:272] - INFO: epoch 004:    103 / 1732 loss=2.486, loss_v1=0, loss_v2=0, nll_loss=1.306, ntokens=976, nsentences=32, sample_size=976, sample_size_v1=0, sample_size_v2=0, ppl=2.47, wps=253.9, ups=0.26, wpb=976, bsz=32, num_updates=5290, lr=9.55511e-06, gnorm=3.101, clip=100, loss_scale=128, train_wall=38, gb_free=8.6, wall=20438
2023-05-20 23:38:40 - progress_bar.py[line:272] - INFO: epoch 004:    113 / 1732 loss=2.514, loss_v1=0, loss_v2=0, nll_loss=1.333, ntokens=1030.9, nsentences=32, sample_size=1030.9, sample_size_v1=0, sample_size_v2=0, ppl=2.52, wps=266.5, ups=0.26, wpb=1030.9, bsz=32, num_updates=5300, lr=9.55306e-06, gnorm=2.749, clip=100, loss_scale=128, train_wall=39, gb_free=7.8, wall=20477
2023-05-20 23:39:19 - progress_bar.py[line:272] - INFO: epoch 004:    123 / 1732 loss=2.485, loss_v1=0, loss_v2=0, nll_loss=1.293, ntokens=1142.2, nsentences=32, sample_size=1142.2, sample_size_v1=0, sample_size_v2=0, ppl=2.45, wps=290.2, ups=0.25, wpb=1142.2, bsz=32, num_updates=5310, lr=9.55101e-06, gnorm=2.489, clip=100, loss_scale=128, train_wall=39, gb_free=7.6, wall=20516
2023-05-20 23:39:58 - progress_bar.py[line:272] - INFO: epoch 004:    133 / 1732 loss=2.419, loss_v1=0, loss_v2=0, nll_loss=1.225, ntokens=1207.4, nsentences=32, sample_size=1207.4, sample_size_v1=0, sample_size_v2=0, ppl=2.34, wps=307.5, ups=0.25, wpb=1207.4, bsz=32, num_updates=5320, lr=9.54896e-06, gnorm=2.394, clip=100, loss_scale=128, train_wall=39, gb_free=8, wall=20555
2023-05-20 23:40:38 - progress_bar.py[line:272] - INFO: epoch 004:    143 / 1732 loss=2.418, loss_v1=0, loss_v2=0, nll_loss=1.222, ntokens=1226.6, nsentences=32, sample_size=1226.6, sample_size_v1=0, sample_size_v2=0, ppl=2.33, wps=309.9, ups=0.25, wpb=1226.6, bsz=32, num_updates=5330, lr=9.54692e-06, gnorm=2.328, clip=100, loss_scale=128, train_wall=40, gb_free=7.2, wall=20595
2023-05-20 23:41:17 - progress_bar.py[line:272] - INFO: epoch 004:    153 / 1732 loss=2.421, loss_v1=0, loss_v2=0, nll_loss=1.224, ntokens=1152.6, nsentences=32, sample_size=1152.6, sample_size_v1=0, sample_size_v2=0, ppl=2.34, wps=291.7, ups=0.25, wpb=1152.6, bsz=32, num_updates=5340, lr=9.54487e-06, gnorm=2.545, clip=100, loss_scale=128, train_wall=39, gb_free=7.3, wall=20635
2023-05-20 23:41:56 - progress_bar.py[line:272] - INFO: epoch 004:    163 / 1732 loss=2.397, loss_v1=0, loss_v2=0, nll_loss=1.199, ntokens=1079.7, nsentences=32, sample_size=1079.7, sample_size_v1=0, sample_size_v2=0, ppl=2.3, wps=276.8, ups=0.26, wpb=1079.7, bsz=32, num_updates=5350, lr=9.54282e-06, gnorm=2.606, clip=100, loss_scale=128, train_wall=39, gb_free=8.7, wall=20674
2023-05-20 23:42:35 - progress_bar.py[line:272] - INFO: epoch 004:    173 / 1732 loss=2.417, loss_v1=0, loss_v2=0, nll_loss=1.221, ntokens=936.5, nsentences=32, sample_size=936.5, sample_size_v1=0, sample_size_v2=0, ppl=2.33, wps=241.5, ups=0.26, wpb=936.5, bsz=32, num_updates=5360, lr=9.54077e-06, gnorm=3.057, clip=100, loss_scale=128, train_wall=39, gb_free=7.8, wall=20712
2023-05-20 23:43:15 - progress_bar.py[line:272] - INFO: epoch 004:    183 / 1732 loss=2.373, loss_v1=0, loss_v2=0, nll_loss=1.172, ntokens=1184.7, nsentences=32, sample_size=1184.7, sample_size_v1=0, sample_size_v2=0, ppl=2.25, wps=299.9, ups=0.25, wpb=1184.7, bsz=32, num_updates=5370, lr=9.53873e-06, gnorm=2.704, clip=100, loss_scale=128, train_wall=39, gb_free=8.4, wall=20752
2023-05-20 23:43:54 - progress_bar.py[line:272] - INFO: epoch 004:    193 / 1732 loss=2.399, loss_v1=0, loss_v2=0, nll_loss=1.204, ntokens=1122.8, nsentences=32, sample_size=1122.8, sample_size_v1=0, sample_size_v2=0, ppl=2.3, wps=285, ups=0.25, wpb=1122.8, bsz=32, num_updates=5380, lr=9.53668e-06, gnorm=2.729, clip=100, loss_scale=128, train_wall=39, gb_free=8.2, wall=20791
2023-05-20 23:44:33 - progress_bar.py[line:272] - INFO: epoch 004:    203 / 1732 loss=2.491, loss_v1=0, loss_v2=0, nll_loss=1.305, ntokens=1086.7, nsentences=32, sample_size=1086.7, sample_size_v1=0, sample_size_v2=0, ppl=2.47, wps=280.2, ups=0.26, wpb=1086.7, bsz=32, num_updates=5390, lr=9.53463e-06, gnorm=3.143, clip=100, loss_scale=128, train_wall=39, gb_free=8.5, wall=20830
2023-05-20 23:45:11 - progress_bar.py[line:272] - INFO: epoch 004:    213 / 1732 loss=2.543, loss_v1=0, loss_v2=0, nll_loss=1.364, ntokens=1044.9, nsentences=32, sample_size=1044.9, sample_size_v1=0, sample_size_v2=0, ppl=2.57, wps=272.7, ups=0.26, wpb=1044.9, bsz=32, num_updates=5400, lr=9.53258e-06, gnorm=3.415, clip=100, loss_scale=128, train_wall=38, gb_free=8.5, wall=20868
2023-05-20 23:45:50 - progress_bar.py[line:272] - INFO: epoch 004:    223 / 1732 loss=2.541, loss_v1=0, loss_v2=0, nll_loss=1.359, ntokens=1134.6, nsentences=32, sample_size=1134.6, sample_size_v1=0, sample_size_v2=0, ppl=2.57, wps=294, ups=0.26, wpb=1134.6, bsz=32, num_updates=5410, lr=9.53054e-06, gnorm=3.064, clip=100, loss_scale=128, train_wall=39, gb_free=8.6, wall=20907
2023-05-20 23:46:28 - progress_bar.py[line:272] - INFO: epoch 004:    233 / 1732 loss=2.575, loss_v1=0, loss_v2=0, nll_loss=1.4, ntokens=1078.6, nsentences=32, sample_size=1078.6, sample_size_v1=0, sample_size_v2=0, ppl=2.64, wps=281.9, ups=0.26, wpb=1078.6, bsz=32, num_updates=5420, lr=9.52849e-06, gnorm=2.929, clip=100, loss_scale=128, train_wall=38, gb_free=9.1, wall=20945
2023-05-20 23:47:07 - progress_bar.py[line:272] - INFO: epoch 004:    243 / 1732 loss=2.577, loss_v1=0, loss_v2=0, nll_loss=1.398, ntokens=1123.3, nsentences=32, sample_size=1123.3, sample_size_v1=0, sample_size_v2=0, ppl=2.64, wps=290.8, ups=0.26, wpb=1123.3, bsz=32, num_updates=5430, lr=9.52644e-06, gnorm=3.18, clip=100, loss_scale=128, train_wall=39, gb_free=8.7, wall=20984
2023-05-20 23:47:45 - progress_bar.py[line:272] - INFO: epoch 004:    253 / 1732 loss=2.57, loss_v1=0, loss_v2=0, nll_loss=1.395, ntokens=1167.4, nsentences=32, sample_size=1167.4, sample_size_v1=0, sample_size_v2=0, ppl=2.63, wps=301.4, ups=0.26, wpb=1167.4, bsz=32, num_updates=5440, lr=9.52439e-06, gnorm=2.874, clip=100, loss_scale=256, train_wall=39, gb_free=8, wall=21023
2023-05-20 23:48:24 - progress_bar.py[line:272] - INFO: epoch 004:    263 / 1732 loss=2.564, loss_v1=0, loss_v2=0, nll_loss=1.387, ntokens=1123.9, nsentences=32, sample_size=1123.9, sample_size_v1=0, sample_size_v2=0, ppl=2.62, wps=292.6, ups=0.26, wpb=1123.9, bsz=32, num_updates=5450, lr=9.52235e-06, gnorm=3.005, clip=100, loss_scale=256, train_wall=38, gb_free=8, wall=21061
2023-05-20 23:49:02 - progress_bar.py[line:272] - INFO: epoch 004:    273 / 1732 loss=2.544, loss_v1=0, loss_v2=0, nll_loss=1.363, ntokens=1154.8, nsentences=32, sample_size=1154.8, sample_size_v1=0, sample_size_v2=0, ppl=2.57, wps=299.9, ups=0.26, wpb=1154.8, bsz=32, num_updates=5460, lr=9.5203e-06, gnorm=2.702, clip=100, loss_scale=256, train_wall=38, gb_free=8.3, wall=21099
2023-05-20 23:49:22 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 128.0
2023-05-20 23:49:45 - progress_bar.py[line:272] - INFO: epoch 004:    284 / 1732 loss=2.56, loss_v1=0, loss_v2=0, nll_loss=1.383, ntokens=1141.1, nsentences=32, sample_size=1141.1, sample_size_v1=0, sample_size_v2=0, ppl=2.61, wps=268.8, ups=0.24, wpb=1141.1, bsz=32, num_updates=5470, lr=9.51825e-06, gnorm=2.645, clip=100, loss_scale=128, train_wall=42, gb_free=8.4, wall=21142
2023-05-20 23:50:23 - progress_bar.py[line:272] - INFO: epoch 004:    294 / 1732 loss=2.541, loss_v1=0, loss_v2=0, nll_loss=1.36, ntokens=1144.7, nsentences=32, sample_size=1144.7, sample_size_v1=0, sample_size_v2=0, ppl=2.57, wps=298, ups=0.26, wpb=1144.7, bsz=32, num_updates=5480, lr=9.5162e-06, gnorm=2.516, clip=100, loss_scale=128, train_wall=38, gb_free=8.8, wall=21180
2023-05-20 23:51:01 - progress_bar.py[line:272] - INFO: epoch 004:    304 / 1732 loss=2.556, loss_v1=0, loss_v2=0, nll_loss=1.378, ntokens=1100.1, nsentences=32, sample_size=1100.1, sample_size_v1=0, sample_size_v2=0, ppl=2.6, wps=286.7, ups=0.26, wpb=1100.1, bsz=32, num_updates=5490, lr=9.51416e-06, gnorm=2.872, clip=100, loss_scale=128, train_wall=38, gb_free=8.6, wall=21219
2023-05-20 23:51:40 - progress_bar.py[line:272] - INFO: epoch 004:    314 / 1732 loss=2.543, loss_v1=0, loss_v2=0, nll_loss=1.363, ntokens=1016.6, nsentences=32, sample_size=1016.6, sample_size_v1=0, sample_size_v2=0, ppl=2.57, wps=266.2, ups=0.26, wpb=1016.6, bsz=32, num_updates=5500, lr=9.51211e-06, gnorm=3.043, clip=100, loss_scale=128, train_wall=38, gb_free=9.3, wall=21257
2023-05-20 23:52:18 - progress_bar.py[line:272] - INFO: epoch 004:    324 / 1732 loss=2.571, loss_v1=0, loss_v2=0, nll_loss=1.393, ntokens=1018.7, nsentences=32, sample_size=1018.7, sample_size_v1=0, sample_size_v2=0, ppl=2.63, wps=266.8, ups=0.26, wpb=1018.7, bsz=32, num_updates=5510, lr=9.51006e-06, gnorm=2.981, clip=100, loss_scale=128, train_wall=38, gb_free=8.5, wall=21295
2023-05-20 23:52:56 - progress_bar.py[line:272] - INFO: epoch 004:    334 / 1732 loss=2.555, loss_v1=0, loss_v2=0, nll_loss=1.378, ntokens=1018.9, nsentences=32, sample_size=1018.9, sample_size_v1=0, sample_size_v2=0, ppl=2.6, wps=266.6, ups=0.26, wpb=1018.9, bsz=32, num_updates=5520, lr=9.50802e-06, gnorm=3.123, clip=100, loss_scale=128, train_wall=38, gb_free=8.8, wall=21333
2023-05-20 23:53:34 - progress_bar.py[line:272] - INFO: epoch 004:    344 / 1732 loss=2.527, loss_v1=0, loss_v2=0, nll_loss=1.348, ntokens=921, nsentences=32, sample_size=921, sample_size_v1=0, sample_size_v2=0, ppl=2.55, wps=242.4, ups=0.26, wpb=921, bsz=32, num_updates=5530, lr=9.50597e-06, gnorm=3.247, clip=100, loss_scale=128, train_wall=38, gb_free=8.7, wall=21371
2023-05-20 23:54:12 - progress_bar.py[line:272] - INFO: epoch 004:    354 / 1732 loss=2.558, loss_v1=0, loss_v2=0, nll_loss=1.383, ntokens=961.9, nsentences=32, sample_size=961.9, sample_size_v1=0, sample_size_v2=0, ppl=2.61, wps=253, ups=0.26, wpb=961.9, bsz=32, num_updates=5540, lr=9.50392e-06, gnorm=3.312, clip=100, loss_scale=128, train_wall=38, gb_free=8.5, wall=21409
2023-05-20 23:54:50 - progress_bar.py[line:272] - INFO: epoch 004:    364 / 1732 loss=2.587, loss_v1=0, loss_v2=0, nll_loss=1.408, ntokens=927.9, nsentences=32, sample_size=927.9, sample_size_v1=0, sample_size_v2=0, ppl=2.65, wps=245, ups=0.26, wpb=927.9, bsz=32, num_updates=5550, lr=9.50187e-06, gnorm=3.384, clip=100, loss_scale=128, train_wall=38, gb_free=9, wall=21447
2023-05-20 23:55:28 - progress_bar.py[line:272] - INFO: epoch 004:    374 / 1732 loss=2.584, loss_v1=0, loss_v2=0, nll_loss=1.408, ntokens=1000.4, nsentences=32, sample_size=1000.4, sample_size_v1=0, sample_size_v2=0, ppl=2.65, wps=260.1, ups=0.26, wpb=1000.4, bsz=32, num_updates=5560, lr=9.49983e-06, gnorm=3.197, clip=100, loss_scale=128, train_wall=38, gb_free=8.7, wall=21486
2023-05-20 23:56:07 - progress_bar.py[line:272] - INFO: epoch 004:    384 / 1732 loss=2.56, loss_v1=0, loss_v2=0, nll_loss=1.383, ntokens=1084.8, nsentences=32, sample_size=1084.8, sample_size_v1=0, sample_size_v2=0, ppl=2.61, wps=283.9, ups=0.26, wpb=1084.8, bsz=32, num_updates=5570, lr=9.49778e-06, gnorm=2.813, clip=100, loss_scale=128, train_wall=38, gb_free=8.1, wall=21524
2023-05-20 23:56:45 - progress_bar.py[line:272] - INFO: epoch 004:    394 / 1732 loss=2.56, loss_v1=0, loss_v2=0, nll_loss=1.382, ntokens=950.6, nsentences=32, sample_size=950.6, sample_size_v1=0, sample_size_v2=0, ppl=2.61, wps=250.9, ups=0.26, wpb=950.6, bsz=32, num_updates=5580, lr=9.49573e-06, gnorm=3.248, clip=100, loss_scale=128, train_wall=38, gb_free=8.9, wall=21562
2023-05-20 23:57:23 - progress_bar.py[line:272] - INFO: epoch 004:    404 / 1732 loss=2.523, loss_v1=0, loss_v2=0, nll_loss=1.339, ntokens=1060.5, nsentences=32, sample_size=1060.5, sample_size_v1=0, sample_size_v2=0, ppl=2.53, wps=276.6, ups=0.26, wpb=1060.5, bsz=32, num_updates=5590, lr=9.49368e-06, gnorm=3.009, clip=100, loss_scale=128, train_wall=38, gb_free=8.1, wall=21600
2023-05-20 23:58:01 - progress_bar.py[line:272] - INFO: epoch 004:    414 / 1732 loss=2.528, loss_v1=0, loss_v2=0, nll_loss=1.347, ntokens=1066.1, nsentences=32, sample_size=1066.1, sample_size_v1=0, sample_size_v2=0, ppl=2.54, wps=278.4, ups=0.26, wpb=1066.1, bsz=32, num_updates=5600, lr=9.49164e-06, gnorm=3.034, clip=100, loss_scale=128, train_wall=38, gb_free=6.5, wall=21638
2023-05-20 23:58:39 - progress_bar.py[line:272] - INFO: epoch 004:    424 / 1732 loss=2.515, loss_v1=0, loss_v2=0, nll_loss=1.333, ntokens=992.6, nsentences=32, sample_size=992.6, sample_size_v1=0, sample_size_v2=0, ppl=2.52, wps=260.7, ups=0.26, wpb=992.6, bsz=32, num_updates=5610, lr=9.48959e-06, gnorm=3.078, clip=100, loss_scale=128, train_wall=38, gb_free=8.6, wall=21676
2023-05-20 23:59:17 - progress_bar.py[line:272] - INFO: epoch 004:    434 / 1732 loss=2.548, loss_v1=0, loss_v2=0, nll_loss=1.37, ntokens=1018.1, nsentences=32, sample_size=1018.1, sample_size_v1=0, sample_size_v2=0, ppl=2.58, wps=267, ups=0.26, wpb=1018.1, bsz=32, num_updates=5620, lr=9.48754e-06, gnorm=3.37, clip=100, loss_scale=128, train_wall=38, gb_free=9, wall=21715
2023-05-20 23:59:55 - progress_bar.py[line:272] - INFO: epoch 004:    444 / 1732 loss=2.571, loss_v1=0, loss_v2=0, nll_loss=1.393, ntokens=952.1, nsentences=32, sample_size=952.1, sample_size_v1=0, sample_size_v2=0, ppl=2.63, wps=250.1, ups=0.26, wpb=952.1, bsz=32, num_updates=5630, lr=9.48549e-06, gnorm=3.284, clip=100, loss_scale=128, train_wall=38, gb_free=9.1, wall=21753
2023-05-21 00:00:33 - progress_bar.py[line:272] - INFO: epoch 004:    454 / 1732 loss=2.55, loss_v1=0, loss_v2=0, nll_loss=1.369, ntokens=919.5, nsentences=32, sample_size=919.5, sample_size_v1=0, sample_size_v2=0, ppl=2.58, wps=242, ups=0.26, wpb=919.5, bsz=32, num_updates=5640, lr=9.48345e-06, gnorm=3.358, clip=100, loss_scale=128, train_wall=38, gb_free=8.6, wall=21791
2023-05-21 00:01:12 - progress_bar.py[line:272] - INFO: epoch 004:    464 / 1732 loss=2.562, loss_v1=0, loss_v2=0, nll_loss=1.385, ntokens=1076.9, nsentences=32, sample_size=1076.9, sample_size_v1=0, sample_size_v2=0, ppl=2.61, wps=281.5, ups=0.26, wpb=1076.9, bsz=32, num_updates=5650, lr=9.4814e-06, gnorm=2.918, clip=100, loss_scale=128, train_wall=38, gb_free=8.9, wall=21829
2023-05-21 00:01:50 - progress_bar.py[line:272] - INFO: epoch 004:    474 / 1732 loss=2.553, loss_v1=0, loss_v2=0, nll_loss=1.37, ntokens=1067.6, nsentences=32, sample_size=1067.6, sample_size_v1=0, sample_size_v2=0, ppl=2.58, wps=277.8, ups=0.26, wpb=1067.6, bsz=32, num_updates=5660, lr=9.47935e-06, gnorm=2.75, clip=100, loss_scale=128, train_wall=38, gb_free=9.1, wall=21867
2023-05-21 00:02:28 - progress_bar.py[line:272] - INFO: epoch 004:    484 / 1732 loss=2.538, loss_v1=0, loss_v2=0, nll_loss=1.36, ntokens=966.8, nsentences=32, sample_size=966.8, sample_size_v1=0, sample_size_v2=0, ppl=2.57, wps=254, ups=0.26, wpb=966.8, bsz=32, num_updates=5670, lr=9.4773e-06, gnorm=3.052, clip=100, loss_scale=128, train_wall=38, gb_free=8.7, wall=21905
2023-05-21 00:03:06 - progress_bar.py[line:272] - INFO: epoch 004:    494 / 1732 loss=2.54, loss_v1=0, loss_v2=0, nll_loss=1.361, ntokens=937.9, nsentences=32, sample_size=937.9, sample_size_v1=0, sample_size_v2=0, ppl=2.57, wps=246.2, ups=0.26, wpb=937.9, bsz=32, num_updates=5680, lr=9.47526e-06, gnorm=3.263, clip=100, loss_scale=128, train_wall=38, gb_free=8.5, wall=21944
2023-05-21 00:03:44 - progress_bar.py[line:272] - INFO: epoch 004:    504 / 1732 loss=2.532, loss_v1=0, loss_v2=0, nll_loss=1.349, ntokens=981, nsentences=32, sample_size=981, sample_size_v1=0, sample_size_v2=0, ppl=2.55, wps=259.1, ups=0.26, wpb=981, bsz=32, num_updates=5690, lr=9.47321e-06, gnorm=3.378, clip=100, loss_scale=128, train_wall=38, gb_free=8.6, wall=21981
2023-05-21 00:04:22 - progress_bar.py[line:272] - INFO: epoch 004:    514 / 1732 loss=2.554, loss_v1=0, loss_v2=0, nll_loss=1.377, ntokens=1052.2, nsentences=32, sample_size=1052.2, sample_size_v1=0, sample_size_v2=0, ppl=2.6, wps=275.2, ups=0.26, wpb=1052.2, bsz=32, num_updates=5700, lr=9.47116e-06, gnorm=2.889, clip=100, loss_scale=128, train_wall=38, gb_free=9, wall=22020
2023-05-21 00:05:00 - progress_bar.py[line:272] - INFO: epoch 004:    524 / 1732 loss=2.524, loss_v1=0, loss_v2=0, nll_loss=1.342, ntokens=980.8, nsentences=32, sample_size=980.8, sample_size_v1=0, sample_size_v2=0, ppl=2.53, wps=258.4, ups=0.26, wpb=980.8, bsz=32, num_updates=5710, lr=9.46912e-06, gnorm=3.158, clip=100, loss_scale=128, train_wall=38, gb_free=8.8, wall=22058
2023-05-21 00:05:38 - progress_bar.py[line:272] - INFO: epoch 004:    534 / 1732 loss=2.538, loss_v1=0, loss_v2=0, nll_loss=1.356, ntokens=944.9, nsentences=32, sample_size=944.9, sample_size_v1=0, sample_size_v2=0, ppl=2.56, wps=249, ups=0.26, wpb=944.9, bsz=32, num_updates=5720, lr=9.46707e-06, gnorm=3.295, clip=100, loss_scale=128, train_wall=38, gb_free=8.3, wall=22096
2023-05-21 00:06:16 - progress_bar.py[line:272] - INFO: epoch 004:    544 / 1732 loss=2.551, loss_v1=0, loss_v2=0, nll_loss=1.372, ntokens=998.9, nsentences=32, sample_size=998.9, sample_size_v1=0, sample_size_v2=0, ppl=2.59, wps=262.4, ups=0.26, wpb=998.9, bsz=32, num_updates=5730, lr=9.46502e-06, gnorm=3.155, clip=100, loss_scale=128, train_wall=38, gb_free=8.6, wall=22134
2023-05-21 00:06:54 - progress_bar.py[line:272] - INFO: epoch 004:    554 / 1732 loss=2.584, loss_v1=0, loss_v2=0, nll_loss=1.411, ntokens=1026.7, nsentences=32, sample_size=1026.7, sample_size_v1=0, sample_size_v2=0, ppl=2.66, wps=270.8, ups=0.26, wpb=1026.7, bsz=32, num_updates=5740, lr=9.46297e-06, gnorm=3.396, clip=100, loss_scale=128, train_wall=38, gb_free=8.5, wall=22172
2023-05-21 00:07:32 - progress_bar.py[line:272] - INFO: epoch 004:    564 / 1732 loss=2.566, loss_v1=0, loss_v2=0, nll_loss=1.386, ntokens=1028.3, nsentences=32, sample_size=1028.3, sample_size_v1=0, sample_size_v2=0, ppl=2.61, wps=269.8, ups=0.26, wpb=1028.3, bsz=32, num_updates=5750, lr=9.46093e-06, gnorm=3.519, clip=100, loss_scale=128, train_wall=38, gb_free=8.2, wall=22210
2023-05-21 00:08:11 - progress_bar.py[line:272] - INFO: epoch 004:    574 / 1732 loss=2.554, loss_v1=0, loss_v2=0, nll_loss=1.376, ntokens=1015.5, nsentences=32, sample_size=1015.5, sample_size_v1=0, sample_size_v2=0, ppl=2.6, wps=264.1, ups=0.26, wpb=1015.5, bsz=32, num_updates=5760, lr=9.45888e-06, gnorm=3.128, clip=100, loss_scale=128, train_wall=38, gb_free=8.1, wall=22248
2023-05-21 00:08:49 - progress_bar.py[line:272] - INFO: epoch 004:    584 / 1732 loss=2.556, loss_v1=0, loss_v2=0, nll_loss=1.379, ntokens=991.8, nsentences=32, sample_size=991.8, sample_size_v1=0, sample_size_v2=0, ppl=2.6, wps=259.3, ups=0.26, wpb=991.8, bsz=32, num_updates=5770, lr=9.45683e-06, gnorm=3.343, clip=100, loss_scale=128, train_wall=38, gb_free=7.9, wall=22286
2023-05-21 00:09:27 - progress_bar.py[line:272] - INFO: epoch 004:    594 / 1732 loss=2.522, loss_v1=0, loss_v2=0, nll_loss=1.339, ntokens=957.2, nsentences=32, sample_size=957.2, sample_size_v1=0, sample_size_v2=0, ppl=2.53, wps=250.1, ups=0.26, wpb=957.2, bsz=32, num_updates=5780, lr=9.45478e-06, gnorm=3.49, clip=100, loss_scale=128, train_wall=38, gb_free=8.5, wall=22325
2023-05-21 00:10:05 - progress_bar.py[line:272] - INFO: epoch 004:    604 / 1732 loss=2.536, loss_v1=0, loss_v2=0, nll_loss=1.358, ntokens=888.6, nsentences=32, sample_size=888.6, sample_size_v1=0, sample_size_v2=0, ppl=2.56, wps=234.8, ups=0.26, wpb=888.6, bsz=32, num_updates=5790, lr=9.45274e-06, gnorm=3.278, clip=100, loss_scale=128, train_wall=38, gb_free=8.4, wall=22363
2023-05-21 00:10:43 - progress_bar.py[line:272] - INFO: epoch 004:    614 / 1732 loss=2.551, loss_v1=0, loss_v2=0, nll_loss=1.373, ntokens=891, nsentences=32, sample_size=891, sample_size_v1=0, sample_size_v2=0, ppl=2.59, wps=235.1, ups=0.26, wpb=891, bsz=32, num_updates=5800, lr=9.45069e-06, gnorm=3.594, clip=100, loss_scale=128, train_wall=38, gb_free=8.8, wall=22400
2023-05-21 00:11:21 - progress_bar.py[line:272] - INFO: epoch 004:    624 / 1732 loss=2.55, loss_v1=0, loss_v2=0, nll_loss=1.371, ntokens=899.1, nsentences=32, sample_size=899.1, sample_size_v1=0, sample_size_v2=0, ppl=2.59, wps=238.6, ups=0.27, wpb=899.1, bsz=32, num_updates=5810, lr=9.44864e-06, gnorm=3.471, clip=100, loss_scale=128, train_wall=38, gb_free=9, wall=22438
2023-05-21 00:11:59 - progress_bar.py[line:272] - INFO: epoch 004:    634 / 1732 loss=2.547, loss_v1=0, loss_v2=0, nll_loss=1.37, ntokens=904.7, nsentences=32, sample_size=904.7, sample_size_v1=0, sample_size_v2=0, ppl=2.58, wps=240.3, ups=0.27, wpb=904.7, bsz=32, num_updates=5820, lr=9.44659e-06, gnorm=3.532, clip=100, loss_scale=128, train_wall=38, gb_free=9.2, wall=22476
2023-05-21 00:12:36 - progress_bar.py[line:272] - INFO: epoch 004:    644 / 1732 loss=2.555, loss_v1=0, loss_v2=0, nll_loss=1.376, ntokens=979.3, nsentences=32, sample_size=979.3, sample_size_v1=0, sample_size_v2=0, ppl=2.6, wps=258.7, ups=0.26, wpb=979.3, bsz=32, num_updates=5830, lr=9.44455e-06, gnorm=3.256, clip=100, loss_scale=128, train_wall=38, gb_free=8.7, wall=22514
2023-05-21 00:13:14 - progress_bar.py[line:272] - INFO: epoch 004:    654 / 1732 loss=2.569, loss_v1=0, loss_v2=0, nll_loss=1.391, ntokens=909.5, nsentences=32, sample_size=909.5, sample_size_v1=0, sample_size_v2=0, ppl=2.62, wps=241.3, ups=0.27, wpb=909.5, bsz=32, num_updates=5840, lr=9.4425e-06, gnorm=3.458, clip=100, loss_scale=128, train_wall=38, gb_free=8.6, wall=22551
2023-05-21 00:13:52 - progress_bar.py[line:272] - INFO: epoch 004:    664 / 1732 loss=2.555, loss_v1=0, loss_v2=0, nll_loss=1.378, ntokens=889.3, nsentences=32, sample_size=889.3, sample_size_v1=0, sample_size_v2=0, ppl=2.6, wps=234.7, ups=0.26, wpb=889.3, bsz=32, num_updates=5850, lr=9.44045e-06, gnorm=3.467, clip=100, loss_scale=128, train_wall=38, gb_free=9.1, wall=22589
2023-05-21 00:14:30 - progress_bar.py[line:272] - INFO: epoch 004:    674 / 1732 loss=2.562, loss_v1=0, loss_v2=0, nll_loss=1.384, ntokens=964.6, nsentences=32, sample_size=964.6, sample_size_v1=0, sample_size_v2=0, ppl=2.61, wps=253.8, ups=0.26, wpb=964.6, bsz=32, num_updates=5860, lr=9.4384e-06, gnorm=3.322, clip=100, loss_scale=128, train_wall=38, gb_free=8.7, wall=22627
2023-05-21 00:15:08 - progress_bar.py[line:272] - INFO: epoch 004:    684 / 1732 loss=2.539, loss_v1=0, loss_v2=0, nll_loss=1.358, ntokens=968.6, nsentences=32, sample_size=968.6, sample_size_v1=0, sample_size_v2=0, ppl=2.56, wps=254.4, ups=0.26, wpb=968.6, bsz=32, num_updates=5870, lr=9.43636e-06, gnorm=3.286, clip=100, loss_scale=128, train_wall=38, gb_free=9.1, wall=22665
2023-05-21 00:15:46 - progress_bar.py[line:272] - INFO: epoch 004:    694 / 1732 loss=2.558, loss_v1=0, loss_v2=0, nll_loss=1.381, ntokens=975.2, nsentences=32, sample_size=975.2, sample_size_v1=0, sample_size_v2=0, ppl=2.6, wps=255.6, ups=0.26, wpb=975.2, bsz=32, num_updates=5880, lr=9.43431e-06, gnorm=3.354, clip=100, loss_scale=128, train_wall=38, gb_free=8.2, wall=22703
2023-05-21 00:16:24 - progress_bar.py[line:272] - INFO: epoch 004:    704 / 1732 loss=2.507, loss_v1=0, loss_v2=0, nll_loss=1.322, ntokens=954.2, nsentences=32, sample_size=954.2, sample_size_v1=0, sample_size_v2=0, ppl=2.5, wps=250.7, ups=0.26, wpb=954.2, bsz=32, num_updates=5890, lr=9.43226e-06, gnorm=3.187, clip=100, loss_scale=128, train_wall=38, gb_free=9.1, wall=22742
2023-05-21 00:17:02 - progress_bar.py[line:272] - INFO: epoch 004:    714 / 1732 loss=2.566, loss_v1=0, loss_v2=0, nll_loss=1.388, ntokens=885.5, nsentences=32, sample_size=885.5, sample_size_v1=0, sample_size_v2=0, ppl=2.62, wps=233.7, ups=0.26, wpb=885.5, bsz=32, num_updates=5900, lr=9.43022e-06, gnorm=3.474, clip=100, loss_scale=128, train_wall=38, gb_free=8.4, wall=22779
2023-05-21 00:17:40 - progress_bar.py[line:272] - INFO: epoch 004:    724 / 1732 loss=2.512, loss_v1=0, loss_v2=0, nll_loss=1.331, ntokens=897.8, nsentences=32, sample_size=897.8, sample_size_v1=0, sample_size_v2=0, ppl=2.52, wps=237.3, ups=0.26, wpb=897.8, bsz=32, num_updates=5910, lr=9.42817e-06, gnorm=3.269, clip=100, loss_scale=128, train_wall=38, gb_free=8.9, wall=22817
2023-05-21 00:18:18 - progress_bar.py[line:272] - INFO: epoch 004:    734 / 1732 loss=2.518, loss_v1=0, loss_v2=0, nll_loss=1.337, ntokens=952.3, nsentences=32, sample_size=952.3, sample_size_v1=0, sample_size_v2=0, ppl=2.53, wps=250.8, ups=0.26, wpb=952.3, bsz=32, num_updates=5920, lr=9.42612e-06, gnorm=3.271, clip=100, loss_scale=128, train_wall=38, gb_free=8.8, wall=22855
2023-05-21 00:18:56 - progress_bar.py[line:272] - INFO: epoch 004:    744 / 1732 loss=2.513, loss_v1=0, loss_v2=0, nll_loss=1.331, ntokens=999.9, nsentences=32, sample_size=999.9, sample_size_v1=0, sample_size_v2=0, ppl=2.52, wps=261.6, ups=0.26, wpb=999.9, bsz=32, num_updates=5930, lr=9.42407e-06, gnorm=3.487, clip=100, loss_scale=128, train_wall=38, gb_free=8.1, wall=22893
2023-05-21 00:19:34 - progress_bar.py[line:272] - INFO: epoch 004:    754 / 1732 loss=2.531, loss_v1=0, loss_v2=0, nll_loss=1.346, ntokens=976.3, nsentences=32, sample_size=976.3, sample_size_v1=0, sample_size_v2=0, ppl=2.54, wps=255.8, ups=0.26, wpb=976.3, bsz=32, num_updates=5940, lr=9.42203e-06, gnorm=3.566, clip=100, loss_scale=128, train_wall=38, gb_free=8.7, wall=22932
2023-05-21 00:20:12 - progress_bar.py[line:272] - INFO: epoch 004:    764 / 1732 loss=2.535, loss_v1=0, loss_v2=0, nll_loss=1.355, ntokens=943.8, nsentences=32, sample_size=943.8, sample_size_v1=0, sample_size_v2=0, ppl=2.56, wps=249.6, ups=0.26, wpb=943.8, bsz=32, num_updates=5950, lr=9.41998e-06, gnorm=3.15, clip=100, loss_scale=128, train_wall=38, gb_free=9.1, wall=22969
2023-05-21 00:20:50 - progress_bar.py[line:272] - INFO: epoch 004:    774 / 1732 loss=2.522, loss_v1=0, loss_v2=0, nll_loss=1.343, ntokens=1000.5, nsentences=32, sample_size=1000.5, sample_size_v1=0, sample_size_v2=0, ppl=2.54, wps=262.9, ups=0.26, wpb=1000.5, bsz=32, num_updates=5960, lr=9.41793e-06, gnorm=3.279, clip=100, loss_scale=128, train_wall=38, gb_free=8.6, wall=23007
2023-05-21 00:21:28 - progress_bar.py[line:272] - INFO: epoch 004:    784 / 1732 loss=2.542, loss_v1=0, loss_v2=0, nll_loss=1.36, ntokens=1008.3, nsentences=32, sample_size=1008.3, sample_size_v1=0, sample_size_v2=0, ppl=2.57, wps=265.5, ups=0.26, wpb=1008.3, bsz=32, num_updates=5970, lr=9.41588e-06, gnorm=3.513, clip=100, loss_scale=128, train_wall=38, gb_free=8.8, wall=23045
2023-05-21 00:22:06 - progress_bar.py[line:272] - INFO: epoch 004:    794 / 1732 loss=2.525, loss_v1=0, loss_v2=0, nll_loss=1.341, ntokens=1024.7, nsentences=32, sample_size=1024.7, sample_size_v1=0, sample_size_v2=0, ppl=2.53, wps=268.5, ups=0.26, wpb=1024.7, bsz=32, num_updates=5980, lr=9.41384e-06, gnorm=3.375, clip=100, loss_scale=256, train_wall=38, gb_free=8.9, wall=23084
2023-05-21 00:22:45 - progress_bar.py[line:272] - INFO: epoch 004:    804 / 1732 loss=2.534, loss_v1=0, loss_v2=0, nll_loss=1.354, ntokens=947.8, nsentences=32, sample_size=947.8, sample_size_v1=0, sample_size_v2=0, ppl=2.56, wps=248.1, ups=0.26, wpb=947.8, bsz=32, num_updates=5990, lr=9.41179e-06, gnorm=3.548, clip=100, loss_scale=256, train_wall=38, gb_free=8.8, wall=23122
2023-05-21 00:23:23 - progress_bar.py[line:272] - INFO: epoch 004:    814 / 1732 loss=2.55, loss_v1=0, loss_v2=0, nll_loss=1.372, ntokens=938.1, nsentences=32, sample_size=938.1, sample_size_v1=0, sample_size_v2=0, ppl=2.59, wps=246.8, ups=0.26, wpb=938.1, bsz=32, num_updates=6000, lr=9.40974e-06, gnorm=3.509, clip=100, loss_scale=256, train_wall=38, gb_free=9.1, wall=23160
2023-05-21 00:24:01 - progress_bar.py[line:272] - INFO: epoch 004:    824 / 1732 loss=2.539, loss_v1=0, loss_v2=0, nll_loss=1.359, ntokens=923.7, nsentences=32, sample_size=923.7, sample_size_v1=0, sample_size_v2=0, ppl=2.57, wps=243, ups=0.26, wpb=923.7, bsz=32, num_updates=6010, lr=9.40769e-06, gnorm=3.549, clip=100, loss_scale=256, train_wall=38, gb_free=8.3, wall=23198
2023-05-21 00:24:27 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 128.0
2023-05-21 00:24:42 - progress_bar.py[line:272] - INFO: epoch 004:    835 / 1732 loss=2.522, loss_v1=0, loss_v2=0, nll_loss=1.338, ntokens=888.1, nsentences=32, sample_size=888.1, sample_size_v1=0, sample_size_v2=0, ppl=2.53, wps=214.8, ups=0.24, wpb=888.1, bsz=32, num_updates=6020, lr=9.40565e-06, gnorm=3.572, clip=100, loss_scale=128, train_wall=41, gb_free=9, wall=23239
2023-05-21 00:25:20 - progress_bar.py[line:272] - INFO: epoch 004:    845 / 1732 loss=2.51, loss_v1=0, loss_v2=0, nll_loss=1.325, ntokens=987.4, nsentences=32, sample_size=987.4, sample_size_v1=0, sample_size_v2=0, ppl=2.5, wps=260.4, ups=0.26, wpb=987.4, bsz=32, num_updates=6030, lr=9.4036e-06, gnorm=3.222, clip=100, loss_scale=128, train_wall=38, gb_free=8.4, wall=23277
2023-05-21 00:25:58 - progress_bar.py[line:272] - INFO: epoch 004:    855 / 1732 loss=2.524, loss_v1=0, loss_v2=0, nll_loss=1.341, ntokens=952, nsentences=32, sample_size=952, sample_size_v1=0, sample_size_v2=0, ppl=2.53, wps=250.8, ups=0.26, wpb=952, bsz=32, num_updates=6040, lr=9.40155e-06, gnorm=3.328, clip=100, loss_scale=128, train_wall=38, gb_free=9.2, wall=23315
2023-05-21 00:26:36 - progress_bar.py[line:272] - INFO: epoch 004:    865 / 1732 loss=2.533, loss_v1=0, loss_v2=0, nll_loss=1.355, ntokens=968.1, nsentences=32, sample_size=968.1, sample_size_v1=0, sample_size_v2=0, ppl=2.56, wps=254.7, ups=0.26, wpb=968.1, bsz=32, num_updates=6050, lr=9.3995e-06, gnorm=3.426, clip=100, loss_scale=128, train_wall=38, gb_free=8.7, wall=23353
2023-05-21 00:27:14 - progress_bar.py[line:272] - INFO: epoch 004:    875 / 1732 loss=2.496, loss_v1=0, loss_v2=0, nll_loss=1.309, ntokens=985.7, nsentences=32, sample_size=985.7, sample_size_v1=0, sample_size_v2=0, ppl=2.48, wps=259.5, ups=0.26, wpb=985.7, bsz=32, num_updates=6060, lr=9.39746e-06, gnorm=3.161, clip=100, loss_scale=128, train_wall=38, gb_free=8.6, wall=23391
2023-05-21 00:27:52 - progress_bar.py[line:272] - INFO: epoch 004:    885 / 1732 loss=2.477, loss_v1=0, loss_v2=0, nll_loss=1.29, ntokens=961.4, nsentences=32, sample_size=961.4, sample_size_v1=0, sample_size_v2=0, ppl=2.45, wps=252.3, ups=0.26, wpb=961.4, bsz=32, num_updates=6070, lr=9.39541e-06, gnorm=3.308, clip=100, loss_scale=128, train_wall=38, gb_free=8.7, wall=23429
2023-05-21 00:28:30 - progress_bar.py[line:272] - INFO: epoch 004:    895 / 1732 loss=2.481, loss_v1=0, loss_v2=0, nll_loss=1.293, ntokens=1031.3, nsentences=32, sample_size=1031.3, sample_size_v1=0, sample_size_v2=0, ppl=2.45, wps=269.8, ups=0.26, wpb=1031.3, bsz=32, num_updates=6080, lr=9.39336e-06, gnorm=3.19, clip=100, loss_scale=128, train_wall=38, gb_free=9, wall=23467
2023-05-21 00:29:08 - progress_bar.py[line:272] - INFO: epoch 004:    905 / 1732 loss=2.479, loss_v1=0, loss_v2=0, nll_loss=1.292, ntokens=1040.4, nsentences=32, sample_size=1040.4, sample_size_v1=0, sample_size_v2=0, ppl=2.45, wps=273.1, ups=0.26, wpb=1040.4, bsz=32, num_updates=6090, lr=9.39132e-06, gnorm=3.226, clip=100, loss_scale=128, train_wall=38, gb_free=8.2, wall=23506
2023-05-21 00:29:46 - progress_bar.py[line:272] - INFO: epoch 004:    915 / 1732 loss=2.548, loss_v1=0, loss_v2=0, nll_loss=1.37, ntokens=937.6, nsentences=32, sample_size=937.6, sample_size_v1=0, sample_size_v2=0, ppl=2.59, wps=247.6, ups=0.26, wpb=937.6, bsz=32, num_updates=6100, lr=9.38927e-06, gnorm=3.602, clip=100, loss_scale=128, train_wall=38, gb_free=8.9, wall=23543
2023-05-21 00:30:25 - progress_bar.py[line:272] - INFO: epoch 004:    925 / 1732 loss=2.495, loss_v1=0, loss_v2=0, nll_loss=1.309, ntokens=1005.1, nsentences=32, sample_size=1005.1, sample_size_v1=0, sample_size_v2=0, ppl=2.48, wps=261.1, ups=0.26, wpb=1005.1, bsz=32, num_updates=6110, lr=9.38722e-06, gnorm=3.175, clip=100, loss_scale=128, train_wall=38, gb_free=8.7, wall=23582
2023-05-21 00:31:03 - progress_bar.py[line:272] - INFO: epoch 004:    935 / 1732 loss=2.504, loss_v1=0, loss_v2=0, nll_loss=1.32, ntokens=1058.5, nsentences=32, sample_size=1058.5, sample_size_v1=0, sample_size_v2=0, ppl=2.5, wps=274.1, ups=0.26, wpb=1058.5, bsz=32, num_updates=6120, lr=9.38517e-06, gnorm=3.29, clip=100, loss_scale=128, train_wall=39, gb_free=8.4, wall=23621
2023-05-21 00:31:42 - progress_bar.py[line:272] - INFO: epoch 004:    945 / 1732 loss=2.525, loss_v1=0, loss_v2=0, nll_loss=1.346, ntokens=1055.4, nsentences=32, sample_size=1055.4, sample_size_v1=0, sample_size_v2=0, ppl=2.54, wps=271.5, ups=0.26, wpb=1055.4, bsz=32, num_updates=6130, lr=9.38313e-06, gnorm=2.89, clip=100, loss_scale=128, train_wall=39, gb_free=8.4, wall=23659
2023-05-21 00:32:21 - progress_bar.py[line:272] - INFO: epoch 004:    955 / 1732 loss=2.506, loss_v1=0, loss_v2=0, nll_loss=1.32, ntokens=1040.2, nsentences=32, sample_size=1040.2, sample_size_v1=0, sample_size_v2=0, ppl=2.5, wps=267.7, ups=0.26, wpb=1040.2, bsz=32, num_updates=6140, lr=9.38108e-06, gnorm=3.161, clip=100, loss_scale=128, train_wall=39, gb_free=8.7, wall=23698
2023-05-21 00:33:00 - progress_bar.py[line:272] - INFO: epoch 004:    965 / 1732 loss=2.513, loss_v1=0, loss_v2=0, nll_loss=1.33, ntokens=1047.7, nsentences=32, sample_size=1047.7, sample_size_v1=0, sample_size_v2=0, ppl=2.51, wps=271, ups=0.26, wpb=1047.7, bsz=32, num_updates=6150, lr=9.37903e-06, gnorm=3.371, clip=100, loss_scale=128, train_wall=39, gb_free=8.9, wall=23737
2023-05-21 00:33:38 - progress_bar.py[line:272] - INFO: epoch 004:    975 / 1732 loss=2.52, loss_v1=0, loss_v2=0, nll_loss=1.337, ntokens=1038, nsentences=32, sample_size=1038, sample_size_v1=0, sample_size_v2=0, ppl=2.53, wps=269.3, ups=0.26, wpb=1038, bsz=32, num_updates=6160, lr=9.37698e-06, gnorm=3.152, clip=100, loss_scale=128, train_wall=38, gb_free=8.8, wall=23775
2023-05-21 00:34:17 - progress_bar.py[line:272] - INFO: epoch 004:    985 / 1732 loss=2.512, loss_v1=0, loss_v2=0, nll_loss=1.33, ntokens=1034.6, nsentences=32, sample_size=1034.6, sample_size_v1=0, sample_size_v2=0, ppl=2.51, wps=267.8, ups=0.26, wpb=1034.6, bsz=32, num_updates=6170, lr=9.37494e-06, gnorm=3.155, clip=100, loss_scale=128, train_wall=39, gb_free=8.7, wall=23814
2023-05-21 00:34:55 - progress_bar.py[line:272] - INFO: epoch 004:    995 / 1732 loss=2.5, loss_v1=0, loss_v2=0, nll_loss=1.314, ntokens=1048.7, nsentences=32, sample_size=1048.7, sample_size_v1=0, sample_size_v2=0, ppl=2.49, wps=272.9, ups=0.26, wpb=1048.7, bsz=32, num_updates=6180, lr=9.37289e-06, gnorm=3.367, clip=100, loss_scale=128, train_wall=38, gb_free=7.7, wall=23853
2023-05-21 00:35:34 - progress_bar.py[line:272] - INFO: epoch 004:   1005 / 1732 loss=2.495, loss_v1=0, loss_v2=0, nll_loss=1.308, ntokens=981.9, nsentences=32, sample_size=981.9, sample_size_v1=0, sample_size_v2=0, ppl=2.48, wps=255.6, ups=0.26, wpb=981.9, bsz=32, num_updates=6190, lr=9.37084e-06, gnorm=3.109, clip=100, loss_scale=128, train_wall=38, gb_free=8.3, wall=23891
2023-05-21 00:36:12 - progress_bar.py[line:272] - INFO: epoch 004:   1015 / 1732 loss=2.508, loss_v1=0, loss_v2=0, nll_loss=1.324, ntokens=996.6, nsentences=32, sample_size=996.6, sample_size_v1=0, sample_size_v2=0, ppl=2.5, wps=260.2, ups=0.26, wpb=996.6, bsz=32, num_updates=6200, lr=9.36879e-06, gnorm=3.098, clip=100, loss_scale=128, train_wall=38, gb_free=8.8, wall=23929
2023-05-21 00:36:51 - progress_bar.py[line:272] - INFO: epoch 004:   1025 / 1732 loss=2.494, loss_v1=0, loss_v2=0, nll_loss=1.312, ntokens=1087.5, nsentences=32, sample_size=1087.5, sample_size_v1=0, sample_size_v2=0, ppl=2.48, wps=279.2, ups=0.26, wpb=1087.5, bsz=32, num_updates=6210, lr=9.36675e-06, gnorm=3.155, clip=100, loss_scale=128, train_wall=39, gb_free=7.8, wall=23968
2023-05-21 00:37:30 - progress_bar.py[line:272] - INFO: epoch 004:   1035 / 1732 loss=2.499, loss_v1=0, loss_v2=0, nll_loss=1.313, ntokens=1118.6, nsentences=32, sample_size=1118.6, sample_size_v1=0, sample_size_v2=0, ppl=2.48, wps=289.1, ups=0.26, wpb=1118.6, bsz=32, num_updates=6220, lr=9.3647e-06, gnorm=3.346, clip=100, loss_scale=128, train_wall=39, gb_free=8.6, wall=24007
2023-05-21 00:38:08 - progress_bar.py[line:272] - INFO: epoch 004:   1045 / 1732 loss=2.5, loss_v1=0, loss_v2=0, nll_loss=1.312, ntokens=1030.7, nsentences=32, sample_size=1030.7, sample_size_v1=0, sample_size_v2=0, ppl=2.48, wps=266.9, ups=0.26, wpb=1030.7, bsz=32, num_updates=6230, lr=9.36265e-06, gnorm=3.362, clip=100, loss_scale=128, train_wall=39, gb_free=8.8, wall=24046
2023-05-21 00:38:47 - progress_bar.py[line:272] - INFO: epoch 004:   1055 / 1732 loss=2.501, loss_v1=0, loss_v2=0, nll_loss=1.316, ntokens=1077.2, nsentences=32, sample_size=1077.2, sample_size_v1=0, sample_size_v2=0, ppl=2.49, wps=280.2, ups=0.26, wpb=1077.2, bsz=32, num_updates=6240, lr=9.3606e-06, gnorm=3.361, clip=100, loss_scale=128, train_wall=38, gb_free=8.3, wall=24084
2023-05-21 00:39:25 - progress_bar.py[line:272] - INFO: epoch 004:   1065 / 1732 loss=2.51, loss_v1=0, loss_v2=0, nll_loss=1.325, ntokens=1021, nsentences=32, sample_size=1021, sample_size_v1=0, sample_size_v2=0, ppl=2.51, wps=265.7, ups=0.26, wpb=1021, bsz=32, num_updates=6250, lr=9.35856e-06, gnorm=3.655, clip=100, loss_scale=128, train_wall=38, gb_free=8.6, wall=24122
2023-05-21 00:40:04 - progress_bar.py[line:272] - INFO: epoch 004:   1075 / 1732 loss=2.502, loss_v1=0, loss_v2=0, nll_loss=1.316, ntokens=1007.9, nsentences=32, sample_size=1007.9, sample_size_v1=0, sample_size_v2=0, ppl=2.49, wps=259.6, ups=0.26, wpb=1007.9, bsz=32, num_updates=6260, lr=9.35651e-06, gnorm=3.457, clip=100, loss_scale=128, train_wall=39, gb_free=8.1, wall=24161
2023-05-21 00:40:43 - progress_bar.py[line:272] - INFO: epoch 004:   1085 / 1732 loss=2.527, loss_v1=0, loss_v2=0, nll_loss=1.345, ntokens=1052.2, nsentences=32, sample_size=1052.2, sample_size_v1=0, sample_size_v2=0, ppl=2.54, wps=271.6, ups=0.26, wpb=1052.2, bsz=32, num_updates=6270, lr=9.35446e-06, gnorm=3.256, clip=100, loss_scale=128, train_wall=39, gb_free=9, wall=24200
2023-05-21 00:41:22 - progress_bar.py[line:272] - INFO: epoch 004:   1095 / 1732 loss=2.506, loss_v1=0, loss_v2=0, nll_loss=1.319, ntokens=1070, nsentences=32, sample_size=1070, sample_size_v1=0, sample_size_v2=0, ppl=2.5, wps=275.2, ups=0.26, wpb=1070, bsz=32, num_updates=6280, lr=9.35241e-06, gnorm=3.068, clip=100, loss_scale=128, train_wall=39, gb_free=8.6, wall=24239
2023-05-21 00:42:00 - progress_bar.py[line:272] - INFO: epoch 004:   1105 / 1732 loss=2.492, loss_v1=0, loss_v2=0, nll_loss=1.308, ntokens=1032.4, nsentences=32, sample_size=1032.4, sample_size_v1=0, sample_size_v2=0, ppl=2.48, wps=267.7, ups=0.26, wpb=1032.4, bsz=32, num_updates=6290, lr=9.35037e-06, gnorm=3.193, clip=100, loss_scale=128, train_wall=39, gb_free=8.5, wall=24277
2023-05-21 00:42:39 - progress_bar.py[line:272] - INFO: epoch 004:   1115 / 1732 loss=2.512, loss_v1=0, loss_v2=0, nll_loss=1.329, ntokens=979.5, nsentences=32, sample_size=979.5, sample_size_v1=0, sample_size_v2=0, ppl=2.51, wps=253.9, ups=0.26, wpb=979.5, bsz=32, num_updates=6300, lr=9.34832e-06, gnorm=3.302, clip=100, loss_scale=128, train_wall=39, gb_free=7.9, wall=24316
2023-05-21 00:43:17 - progress_bar.py[line:272] - INFO: epoch 004:   1125 / 1732 loss=2.511, loss_v1=0, loss_v2=0, nll_loss=1.326, ntokens=994.1, nsentences=32, sample_size=994.1, sample_size_v1=0, sample_size_v2=0, ppl=2.51, wps=258.1, ups=0.26, wpb=994.1, bsz=32, num_updates=6310, lr=9.34627e-06, gnorm=3.802, clip=100, loss_scale=128, train_wall=38, gb_free=8.1, wall=24355
2023-05-21 00:43:56 - progress_bar.py[line:272] - INFO: epoch 004:   1135 / 1732 loss=2.519, loss_v1=0, loss_v2=0, nll_loss=1.336, ntokens=998.2, nsentences=32, sample_size=998.2, sample_size_v1=0, sample_size_v2=0, ppl=2.52, wps=259.4, ups=0.26, wpb=998.2, bsz=32, num_updates=6320, lr=9.34423e-06, gnorm=3.486, clip=100, loss_scale=128, train_wall=38, gb_free=8.5, wall=24393
2023-05-21 00:44:34 - progress_bar.py[line:272] - INFO: epoch 004:   1145 / 1732 loss=2.517, loss_v1=0, loss_v2=0, nll_loss=1.333, ntokens=1012.1, nsentences=32, sample_size=1012.1, sample_size_v1=0, sample_size_v2=0, ppl=2.52, wps=262.5, ups=0.26, wpb=1012.1, bsz=32, num_updates=6330, lr=9.34218e-06, gnorm=3.388, clip=100, loss_scale=128, train_wall=39, gb_free=7.9, wall=24432
2023-05-21 00:45:13 - progress_bar.py[line:272] - INFO: epoch 004:   1155 / 1732 loss=2.49, loss_v1=0, loss_v2=0, nll_loss=1.302, ntokens=1037.8, nsentences=32, sample_size=1037.8, sample_size_v1=0, sample_size_v2=0, ppl=2.47, wps=268.6, ups=0.26, wpb=1037.8, bsz=32, num_updates=6340, lr=9.34013e-06, gnorm=3.328, clip=100, loss_scale=128, train_wall=39, gb_free=8.7, wall=24470
2023-05-21 00:45:52 - progress_bar.py[line:272] - INFO: epoch 004:   1165 / 1732 loss=2.485, loss_v1=0, loss_v2=0, nll_loss=1.297, ntokens=1000.9, nsentences=32, sample_size=1000.9, sample_size_v1=0, sample_size_v2=0, ppl=2.46, wps=258.5, ups=0.26, wpb=1000.9, bsz=32, num_updates=6350, lr=9.33808e-06, gnorm=3.44, clip=100, loss_scale=128, train_wall=39, gb_free=8.4, wall=24509
2023-05-21 00:46:30 - progress_bar.py[line:272] - INFO: epoch 004:   1175 / 1732 loss=2.487, loss_v1=0, loss_v2=0, nll_loss=1.298, ntokens=1076.2, nsentences=32, sample_size=1076.2, sample_size_v1=0, sample_size_v2=0, ppl=2.46, wps=279.3, ups=0.26, wpb=1076.2, bsz=32, num_updates=6360, lr=9.33604e-06, gnorm=2.934, clip=100, loss_scale=128, train_wall=38, gb_free=8.2, wall=24547
2023-05-21 00:47:09 - progress_bar.py[line:272] - INFO: epoch 004:   1185 / 1732 loss=2.52, loss_v1=0, loss_v2=0, nll_loss=1.34, ntokens=957.5, nsentences=32, sample_size=957.5, sample_size_v1=0, sample_size_v2=0, ppl=2.53, wps=248.9, ups=0.26, wpb=957.5, bsz=32, num_updates=6370, lr=9.33399e-06, gnorm=3.661, clip=100, loss_scale=128, train_wall=38, gb_free=8.9, wall=24586
2023-05-21 00:47:47 - progress_bar.py[line:272] - INFO: epoch 004:   1195 / 1732 loss=2.515, loss_v1=0, loss_v2=0, nll_loss=1.329, ntokens=1058.2, nsentences=32, sample_size=1058.2, sample_size_v1=0, sample_size_v2=0, ppl=2.51, wps=274, ups=0.26, wpb=1058.2, bsz=32, num_updates=6380, lr=9.33194e-06, gnorm=3.398, clip=100, loss_scale=128, train_wall=39, gb_free=8.3, wall=24625
2023-05-21 00:48:26 - progress_bar.py[line:272] - INFO: epoch 004:   1205 / 1732 loss=2.463, loss_v1=0, loss_v2=0, nll_loss=1.271, ntokens=1142.5, nsentences=32, sample_size=1142.5, sample_size_v1=0, sample_size_v2=0, ppl=2.41, wps=292.4, ups=0.26, wpb=1142.5, bsz=32, num_updates=6390, lr=9.32989e-06, gnorm=2.955, clip=100, loss_scale=128, train_wall=39, gb_free=8.4, wall=24664
2023-05-21 00:49:05 - progress_bar.py[line:272] - INFO: epoch 004:   1215 / 1732 loss=2.502, loss_v1=0, loss_v2=0, nll_loss=1.315, ntokens=998.9, nsentences=32, sample_size=998.9, sample_size_v1=0, sample_size_v2=0, ppl=2.49, wps=259.7, ups=0.26, wpb=998.9, bsz=32, num_updates=6400, lr=9.32785e-06, gnorm=3.604, clip=100, loss_scale=128, train_wall=38, gb_free=8.9, wall=24702
2023-05-21 00:49:44 - progress_bar.py[line:272] - INFO: epoch 004:   1225 / 1732 loss=2.512, loss_v1=0, loss_v2=0, nll_loss=1.328, ntokens=1043.3, nsentences=32, sample_size=1043.3, sample_size_v1=0, sample_size_v2=0, ppl=2.51, wps=270, ups=0.26, wpb=1043.3, bsz=32, num_updates=6410, lr=9.3258e-06, gnorm=3.325, clip=100, loss_scale=128, train_wall=39, gb_free=8.9, wall=24741
2023-05-21 00:50:22 - progress_bar.py[line:272] - INFO: epoch 004:   1235 / 1732 loss=2.485, loss_v1=0, loss_v2=0, nll_loss=1.297, ntokens=1038.1, nsentences=32, sample_size=1038.1, sample_size_v1=0, sample_size_v2=0, ppl=2.46, wps=268.5, ups=0.26, wpb=1038.1, bsz=32, num_updates=6420, lr=9.32375e-06, gnorm=3.409, clip=100, loss_scale=128, train_wall=39, gb_free=7.5, wall=24779
2023-05-21 00:51:01 - progress_bar.py[line:272] - INFO: epoch 004:   1245 / 1732 loss=2.437, loss_v1=0, loss_v2=0, nll_loss=1.243, ntokens=1088.5, nsentences=32, sample_size=1088.5, sample_size_v1=0, sample_size_v2=0, ppl=2.37, wps=279.8, ups=0.26, wpb=1088.5, bsz=32, num_updates=6430, lr=9.3217e-06, gnorm=3.421, clip=100, loss_scale=128, train_wall=39, gb_free=8.3, wall=24818
2023-05-21 00:51:40 - progress_bar.py[line:272] - INFO: epoch 004:   1255 / 1732 loss=2.469, loss_v1=0, loss_v2=0, nll_loss=1.28, ntokens=1068.9, nsentences=32, sample_size=1068.9, sample_size_v1=0, sample_size_v2=0, ppl=2.43, wps=276.8, ups=0.26, wpb=1068.9, bsz=32, num_updates=6440, lr=9.31966e-06, gnorm=3.348, clip=100, loss_scale=128, train_wall=39, gb_free=8.2, wall=24857
2023-05-21 00:52:18 - progress_bar.py[line:272] - INFO: epoch 004:   1265 / 1732 loss=2.51, loss_v1=0, loss_v2=0, nll_loss=1.328, ntokens=1072.6, nsentences=32, sample_size=1072.6, sample_size_v1=0, sample_size_v2=0, ppl=2.51, wps=277.2, ups=0.26, wpb=1072.6, bsz=32, num_updates=6450, lr=9.31761e-06, gnorm=3.61, clip=100, loss_scale=128, train_wall=39, gb_free=9.2, wall=24896
2023-05-21 00:52:57 - progress_bar.py[line:272] - INFO: epoch 004:   1275 / 1732 loss=2.494, loss_v1=0, loss_v2=0, nll_loss=1.306, ntokens=1036.2, nsentences=32, sample_size=1036.2, sample_size_v1=0, sample_size_v2=0, ppl=2.47, wps=268.5, ups=0.26, wpb=1036.2, bsz=32, num_updates=6460, lr=9.31556e-06, gnorm=3.636, clip=100, loss_scale=128, train_wall=39, gb_free=8.5, wall=24934
2023-05-21 00:53:36 - progress_bar.py[line:272] - INFO: epoch 004:   1285 / 1732 loss=2.494, loss_v1=0, loss_v2=0, nll_loss=1.308, ntokens=1069.5, nsentences=32, sample_size=1069.5, sample_size_v1=0, sample_size_v2=0, ppl=2.48, wps=275.5, ups=0.26, wpb=1069.5, bsz=32, num_updates=6470, lr=9.31351e-06, gnorm=3.414, clip=100, loss_scale=128, train_wall=39, gb_free=8.5, wall=24973
2023-05-21 00:54:15 - progress_bar.py[line:272] - INFO: epoch 004:   1295 / 1732 loss=2.481, loss_v1=0, loss_v2=0, nll_loss=1.294, ntokens=1106.6, nsentences=32, sample_size=1106.6, sample_size_v1=0, sample_size_v2=0, ppl=2.45, wps=285.8, ups=0.26, wpb=1106.6, bsz=32, num_updates=6480, lr=9.31147e-06, gnorm=3.384, clip=100, loss_scale=128, train_wall=39, gb_free=7.7, wall=25012
2023-05-21 00:54:54 - progress_bar.py[line:272] - INFO: epoch 004:   1305 / 1732 loss=2.507, loss_v1=0, loss_v2=0, nll_loss=1.323, ntokens=1087.8, nsentences=32, sample_size=1087.8, sample_size_v1=0, sample_size_v2=0, ppl=2.5, wps=278.4, ups=0.26, wpb=1087.8, bsz=32, num_updates=6490, lr=9.30942e-06, gnorm=2.872, clip=100, loss_scale=128, train_wall=39, gb_free=8, wall=25051
2023-05-21 00:55:32 - progress_bar.py[line:272] - INFO: epoch 004:   1315 / 1732 loss=2.504, loss_v1=0, loss_v2=0, nll_loss=1.317, ntokens=1038.9, nsentences=32, sample_size=1038.9, sample_size_v1=0, sample_size_v2=0, ppl=2.49, wps=267.8, ups=0.26, wpb=1038.9, bsz=32, num_updates=6500, lr=9.30737e-06, gnorm=3.371, clip=100, loss_scale=128, train_wall=39, gb_free=8.4, wall=25090
2023-05-21 00:56:12 - progress_bar.py[line:272] - INFO: epoch 004:   1325 / 1732 loss=2.474, loss_v1=0, loss_v2=0, nll_loss=1.283, ntokens=1136.1, nsentences=32, sample_size=1136.1, sample_size_v1=0, sample_size_v2=0, ppl=2.43, wps=290, ups=0.26, wpb=1136.1, bsz=32, num_updates=6510, lr=9.30533e-06, gnorm=3.236, clip=100, loss_scale=128, train_wall=39, gb_free=7.6, wall=25129
2023-05-21 00:56:50 - progress_bar.py[line:272] - INFO: epoch 004:   1335 / 1732 loss=2.462, loss_v1=0, loss_v2=0, nll_loss=1.274, ntokens=1103.3, nsentences=32, sample_size=1103.3, sample_size_v1=0, sample_size_v2=0, ppl=2.42, wps=284.9, ups=0.26, wpb=1103.3, bsz=32, num_updates=6520, lr=9.30328e-06, gnorm=3.58, clip=100, loss_scale=128, train_wall=39, gb_free=7.3, wall=25168
2023-05-21 00:57:29 - progress_bar.py[line:272] - INFO: epoch 004:   1345 / 1732 loss=2.493, loss_v1=0, loss_v2=0, nll_loss=1.309, ntokens=1182.5, nsentences=32, sample_size=1182.5, sample_size_v1=0, sample_size_v2=0, ppl=2.48, wps=302.7, ups=0.26, wpb=1182.5, bsz=32, num_updates=6530, lr=9.30123e-06, gnorm=3.375, clip=100, loss_scale=256, train_wall=39, gb_free=8.2, wall=25207
2023-05-21 00:58:08 - progress_bar.py[line:272] - INFO: epoch 004:   1355 / 1732 loss=2.464, loss_v1=0, loss_v2=0, nll_loss=1.272, ntokens=1122.3, nsentences=32, sample_size=1122.3, sample_size_v1=0, sample_size_v2=0, ppl=2.42, wps=287.9, ups=0.26, wpb=1122.3, bsz=32, num_updates=6540, lr=9.29918e-06, gnorm=3.34, clip=100, loss_scale=256, train_wall=39, gb_free=8.1, wall=25246
2023-05-21 00:58:24 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 128.0
2023-05-21 00:58:51 - progress_bar.py[line:272] - INFO: epoch 004:   1366 / 1732 loss=2.487, loss_v1=0, loss_v2=0, nll_loss=1.3, ntokens=1087.4, nsentences=32, sample_size=1087.4, sample_size_v1=0, sample_size_v2=0, ppl=2.46, wps=254.7, ups=0.23, wpb=1087.4, bsz=32, num_updates=6550, lr=9.29714e-06, gnorm=3.257, clip=100, loss_scale=128, train_wall=43, gb_free=8.8, wall=25288
2023-05-21 00:59:30 - progress_bar.py[line:272] - INFO: epoch 004:   1376 / 1732 loss=2.522, loss_v1=0, loss_v2=0, nll_loss=1.339, ntokens=1111.5, nsentences=32, sample_size=1111.5, sample_size_v1=0, sample_size_v2=0, ppl=2.53, wps=286.8, ups=0.26, wpb=1111.5, bsz=32, num_updates=6560, lr=9.29509e-06, gnorm=3.574, clip=100, loss_scale=128, train_wall=39, gb_free=8, wall=25327
2023-05-21 01:00:09 - progress_bar.py[line:272] - INFO: epoch 004:   1386 / 1732 loss=2.483, loss_v1=0, loss_v2=0, nll_loss=1.298, ntokens=1153.3, nsentences=32, sample_size=1153.3, sample_size_v1=0, sample_size_v2=0, ppl=2.46, wps=297.7, ups=0.26, wpb=1153.3, bsz=32, num_updates=6570, lr=9.29304e-06, gnorm=3.506, clip=100, loss_scale=128, train_wall=39, gb_free=8.9, wall=25366
2023-05-21 01:00:47 - progress_bar.py[line:272] - INFO: epoch 004:   1396 / 1732 loss=2.474, loss_v1=0, loss_v2=0, nll_loss=1.286, ntokens=1044.6, nsentences=32, sample_size=1044.6, sample_size_v1=0, sample_size_v2=0, ppl=2.44, wps=269.7, ups=0.26, wpb=1044.6, bsz=32, num_updates=6580, lr=9.29099e-06, gnorm=3.485, clip=100, loss_scale=128, train_wall=39, gb_free=8.6, wall=25405
2023-05-21 01:01:26 - progress_bar.py[line:272] - INFO: epoch 004:   1406 / 1732 loss=2.492, loss_v1=0, loss_v2=0, nll_loss=1.304, ntokens=1163.8, nsentences=32, sample_size=1163.8, sample_size_v1=0, sample_size_v2=0, ppl=2.47, wps=298.3, ups=0.26, wpb=1163.8, bsz=32, num_updates=6590, lr=9.28895e-06, gnorm=3.359, clip=100, loss_scale=128, train_wall=39, gb_free=8.7, wall=25444
2023-05-21 01:02:06 - progress_bar.py[line:272] - INFO: epoch 004:   1416 / 1732 loss=2.499, loss_v1=0, loss_v2=0, nll_loss=1.313, ntokens=1281, nsentences=32, sample_size=1281, sample_size_v1=0, sample_size_v2=0, ppl=2.49, wps=325.1, ups=0.25, wpb=1281, bsz=32, num_updates=6600, lr=9.2869e-06, gnorm=3.079, clip=100, loss_scale=128, train_wall=39, gb_free=7.6, wall=25483
2023-05-21 01:02:45 - progress_bar.py[line:272] - INFO: epoch 004:   1426 / 1732 loss=2.473, loss_v1=0, loss_v2=0, nll_loss=1.284, ntokens=1225.6, nsentences=32, sample_size=1225.6, sample_size_v1=0, sample_size_v2=0, ppl=2.43, wps=312.8, ups=0.26, wpb=1225.6, bsz=32, num_updates=6610, lr=9.28485e-06, gnorm=3.691, clip=100, loss_scale=128, train_wall=39, gb_free=7.7, wall=25522
2023-05-21 01:03:24 - progress_bar.py[line:272] - INFO: epoch 004:   1436 / 1732 loss=2.462, loss_v1=0, loss_v2=0, nll_loss=1.273, ntokens=1219.4, nsentences=32, sample_size=1219.4, sample_size_v1=0, sample_size_v2=0, ppl=2.42, wps=313.3, ups=0.26, wpb=1219.4, bsz=32, num_updates=6620, lr=9.2828e-06, gnorm=2.87, clip=100, loss_scale=128, train_wall=39, gb_free=8.1, wall=25561
2023-05-21 01:04:03 - progress_bar.py[line:272] - INFO: epoch 004:   1446 / 1732 loss=2.517, loss_v1=0, loss_v2=0, nll_loss=1.333, ntokens=1113.8, nsentences=32, sample_size=1113.8, sample_size_v1=0, sample_size_v2=0, ppl=2.52, wps=287.5, ups=0.26, wpb=1113.8, bsz=32, num_updates=6630, lr=9.28076e-06, gnorm=3.555, clip=100, loss_scale=128, train_wall=39, gb_free=8.5, wall=25600
2023-05-21 01:04:41 - progress_bar.py[line:272] - INFO: epoch 004:   1456 / 1732 loss=2.497, loss_v1=0, loss_v2=0, nll_loss=1.309, ntokens=1106.5, nsentences=32, sample_size=1106.5, sample_size_v1=0, sample_size_v2=0, ppl=2.48, wps=285.4, ups=0.26, wpb=1106.5, bsz=32, num_updates=6640, lr=9.27871e-06, gnorm=3.579, clip=100, loss_scale=128, train_wall=39, gb_free=8.2, wall=25639
2023-05-21 01:05:20 - progress_bar.py[line:272] - INFO: epoch 004:   1466 / 1732 loss=2.435, loss_v1=0, loss_v2=0, nll_loss=1.244, ntokens=1200.2, nsentences=32, sample_size=1200.2, sample_size_v1=0, sample_size_v2=0, ppl=2.37, wps=307.3, ups=0.26, wpb=1200.2, bsz=32, num_updates=6650, lr=9.27666e-06, gnorm=3.435, clip=100, loss_scale=128, train_wall=39, gb_free=8.4, wall=25678
2023-05-21 01:05:59 - progress_bar.py[line:272] - INFO: epoch 004:   1476 / 1732 loss=2.508, loss_v1=0, loss_v2=0, nll_loss=1.323, ntokens=1071.6, nsentences=32, sample_size=1071.6, sample_size_v1=0, sample_size_v2=0, ppl=2.5, wps=277.5, ups=0.26, wpb=1071.6, bsz=32, num_updates=6660, lr=9.27461e-06, gnorm=4.188, clip=100, loss_scale=128, train_wall=39, gb_free=8.4, wall=25716
2023-05-21 01:06:38 - progress_bar.py[line:272] - INFO: epoch 004:   1486 / 1732 loss=2.492, loss_v1=0, loss_v2=0, nll_loss=1.304, ntokens=1132, nsentences=32, sample_size=1132, sample_size_v1=0, sample_size_v2=0, ppl=2.47, wps=290, ups=0.26, wpb=1132, bsz=32, num_updates=6670, lr=9.27257e-06, gnorm=3.545, clip=100, loss_scale=128, train_wall=39, gb_free=7.6, wall=25755
2023-05-21 01:07:17 - progress_bar.py[line:272] - INFO: epoch 004:   1496 / 1732 loss=2.472, loss_v1=0, loss_v2=0, nll_loss=1.282, ntokens=1113.1, nsentences=32, sample_size=1113.1, sample_size_v1=0, sample_size_v2=0, ppl=2.43, wps=286.4, ups=0.26, wpb=1113.1, bsz=32, num_updates=6680, lr=9.27052e-06, gnorm=3.254, clip=100, loss_scale=128, train_wall=39, gb_free=8.1, wall=25794
2023-05-21 01:07:56 - progress_bar.py[line:272] - INFO: epoch 004:   1506 / 1732 loss=2.43, loss_v1=0, loss_v2=0, nll_loss=1.24, ntokens=1117, nsentences=32, sample_size=1117, sample_size_v1=0, sample_size_v2=0, ppl=2.36, wps=288.7, ups=0.26, wpb=1117, bsz=32, num_updates=6690, lr=9.26847e-06, gnorm=3.383, clip=100, loss_scale=128, train_wall=39, gb_free=8.6, wall=25833
2023-05-21 01:08:34 - progress_bar.py[line:272] - INFO: epoch 004:   1516 / 1732 loss=2.499, loss_v1=0, loss_v2=0, nll_loss=1.315, ntokens=1043.6, nsentences=32, sample_size=1043.6, sample_size_v1=0, sample_size_v2=0, ppl=2.49, wps=269.5, ups=0.26, wpb=1043.6, bsz=32, num_updates=6700, lr=9.26643e-06, gnorm=3.628, clip=100, loss_scale=128, train_wall=39, gb_free=8.5, wall=25872
2023-05-21 01:09:13 - progress_bar.py[line:272] - INFO: epoch 004:   1526 / 1732 loss=2.53, loss_v1=0, loss_v2=0, nll_loss=1.346, ntokens=1063.1, nsentences=32, sample_size=1063.1, sample_size_v1=0, sample_size_v2=0, ppl=2.54, wps=274.5, ups=0.26, wpb=1063.1, bsz=32, num_updates=6710, lr=9.26438e-06, gnorm=3.806, clip=100, loss_scale=128, train_wall=39, gb_free=8.4, wall=25910
2023-05-21 01:09:52 - progress_bar.py[line:272] - INFO: epoch 004:   1536 / 1732 loss=2.486, loss_v1=0, loss_v2=0, nll_loss=1.294, ntokens=1073.8, nsentences=32, sample_size=1073.8, sample_size_v1=0, sample_size_v2=0, ppl=2.45, wps=275.1, ups=0.26, wpb=1073.8, bsz=32, num_updates=6720, lr=9.26233e-06, gnorm=3.73, clip=100, loss_scale=128, train_wall=39, gb_free=8.4, wall=25949
2023-05-21 01:10:31 - progress_bar.py[line:272] - INFO: epoch 004:   1546 / 1732 loss=2.461, loss_v1=0, loss_v2=0, nll_loss=1.27, ntokens=1068.6, nsentences=32, sample_size=1068.6, sample_size_v1=0, sample_size_v2=0, ppl=2.41, wps=276.8, ups=0.26, wpb=1068.6, bsz=32, num_updates=6730, lr=9.26028e-06, gnorm=3.656, clip=100, loss_scale=128, train_wall=39, gb_free=8.3, wall=25988
2023-05-21 01:11:09 - progress_bar.py[line:272] - INFO: epoch 004:   1556 / 1732 loss=2.472, loss_v1=0, loss_v2=0, nll_loss=1.287, ntokens=1070.8, nsentences=32, sample_size=1070.8, sample_size_v1=0, sample_size_v2=0, ppl=2.44, wps=277.1, ups=0.26, wpb=1070.8, bsz=32, num_updates=6740, lr=9.25824e-06, gnorm=3.362, clip=100, loss_scale=128, train_wall=39, gb_free=8.4, wall=26027
2023-05-21 01:11:48 - progress_bar.py[line:272] - INFO: epoch 004:   1566 / 1732 loss=2.523, loss_v1=0, loss_v2=0, nll_loss=1.34, ntokens=1097.4, nsentences=32, sample_size=1097.4, sample_size_v1=0, sample_size_v2=0, ppl=2.53, wps=283.3, ups=0.26, wpb=1097.4, bsz=32, num_updates=6750, lr=9.25619e-06, gnorm=3.606, clip=100, loss_scale=128, train_wall=39, gb_free=8.8, wall=26065
2023-05-21 01:12:27 - progress_bar.py[line:272] - INFO: epoch 004:   1576 / 1732 loss=2.526, loss_v1=0, loss_v2=0, nll_loss=1.341, ntokens=1019.9, nsentences=32, sample_size=1019.9, sample_size_v1=0, sample_size_v2=0, ppl=2.53, wps=263.8, ups=0.26, wpb=1019.9, bsz=32, num_updates=6760, lr=9.25414e-06, gnorm=4.249, clip=100, loss_scale=128, train_wall=39, gb_free=8.7, wall=26104
2023-05-21 01:13:06 - progress_bar.py[line:272] - INFO: epoch 004:   1586 / 1732 loss=2.498, loss_v1=0, loss_v2=0, nll_loss=1.31, ntokens=1060.6, nsentences=32, sample_size=1060.6, sample_size_v1=0, sample_size_v2=0, ppl=2.48, wps=273.1, ups=0.26, wpb=1060.6, bsz=32, num_updates=6770, lr=9.25209e-06, gnorm=3.639, clip=100, loss_scale=128, train_wall=39, gb_free=8.2, wall=26143
2023-05-21 01:13:44 - progress_bar.py[line:272] - INFO: epoch 004:   1596 / 1732 loss=2.463, loss_v1=0, loss_v2=0, nll_loss=1.275, ntokens=1073.8, nsentences=32, sample_size=1073.8, sample_size_v1=0, sample_size_v2=0, ppl=2.42, wps=277.6, ups=0.26, wpb=1073.8, bsz=32, num_updates=6780, lr=9.25005e-06, gnorm=3.407, clip=100, loss_scale=128, train_wall=39, gb_free=8.4, wall=26182
2023-05-21 01:14:23 - progress_bar.py[line:272] - INFO: epoch 004:   1606 / 1732 loss=2.485, loss_v1=0, loss_v2=0, nll_loss=1.297, ntokens=1124, nsentences=32, sample_size=1124, sample_size_v1=0, sample_size_v2=0, ppl=2.46, wps=288.9, ups=0.26, wpb=1124, bsz=32, num_updates=6790, lr=9.248e-06, gnorm=3.311, clip=100, loss_scale=128, train_wall=39, gb_free=8.2, wall=26220
2023-05-21 01:15:02 - progress_bar.py[line:272] - INFO: epoch 004:   1616 / 1732 loss=2.441, loss_v1=0, loss_v2=0, nll_loss=1.247, ntokens=1154.1, nsentences=32, sample_size=1154.1, sample_size_v1=0, sample_size_v2=0, ppl=2.37, wps=295.3, ups=0.26, wpb=1154.1, bsz=32, num_updates=6800, lr=9.24595e-06, gnorm=3.759, clip=100, loss_scale=128, train_wall=39, gb_free=8.7, wall=26260
2023-05-21 01:15:41 - progress_bar.py[line:272] - INFO: epoch 004:   1626 / 1732 loss=2.473, loss_v1=0, loss_v2=0, nll_loss=1.287, ntokens=1109.2, nsentences=32, sample_size=1109.2, sample_size_v1=0, sample_size_v2=0, ppl=2.44, wps=284.7, ups=0.26, wpb=1109.2, bsz=32, num_updates=6810, lr=9.2439e-06, gnorm=3.492, clip=100, loss_scale=128, train_wall=39, gb_free=8.5, wall=26299
2023-05-21 01:16:20 - progress_bar.py[line:272] - INFO: epoch 004:   1636 / 1732 loss=2.451, loss_v1=0, loss_v2=0, nll_loss=1.256, ntokens=1146, nsentences=32, sample_size=1146, sample_size_v1=0, sample_size_v2=0, ppl=2.39, wps=295.4, ups=0.26, wpb=1146, bsz=32, num_updates=6820, lr=9.24186e-06, gnorm=3.667, clip=100, loss_scale=128, train_wall=39, gb_free=9.1, wall=26337
2023-05-21 01:16:59 - progress_bar.py[line:272] - INFO: epoch 004:   1646 / 1732 loss=2.432, loss_v1=0, loss_v2=0, nll_loss=1.236, ntokens=1290.2, nsentences=32, sample_size=1290.2, sample_size_v1=0, sample_size_v2=0, ppl=2.36, wps=328.5, ups=0.25, wpb=1290.2, bsz=32, num_updates=6830, lr=9.23981e-06, gnorm=3.231, clip=100, loss_scale=128, train_wall=39, gb_free=8.2, wall=26377
2023-05-21 01:17:38 - progress_bar.py[line:272] - INFO: epoch 004:   1656 / 1732 loss=2.508, loss_v1=0, loss_v2=0, nll_loss=1.324, ntokens=952.5, nsentences=32, sample_size=952.5, sample_size_v1=0, sample_size_v2=0, ppl=2.5, wps=249.1, ups=0.26, wpb=952.5, bsz=32, num_updates=6840, lr=9.23776e-06, gnorm=4.229, clip=100, loss_scale=128, train_wall=38, gb_free=8.5, wall=26415
2023-05-21 01:18:16 - progress_bar.py[line:272] - INFO: epoch 004:   1666 / 1732 loss=2.491, loss_v1=0, loss_v2=0, nll_loss=1.303, ntokens=1015, nsentences=32, sample_size=1015, sample_size_v1=0, sample_size_v2=0, ppl=2.47, wps=262.9, ups=0.26, wpb=1015, bsz=32, num_updates=6850, lr=9.23571e-06, gnorm=3.364, clip=100, loss_scale=128, train_wall=39, gb_free=8.5, wall=26453
2023-05-21 01:18:55 - progress_bar.py[line:272] - INFO: epoch 004:   1676 / 1732 loss=2.447, loss_v1=0, loss_v2=0, nll_loss=1.253, ntokens=1119.1, nsentences=32, sample_size=1119.1, sample_size_v1=0, sample_size_v2=0, ppl=2.38, wps=287.9, ups=0.26, wpb=1119.1, bsz=32, num_updates=6860, lr=9.23367e-06, gnorm=3.334, clip=100, loss_scale=128, train_wall=39, gb_free=8.3, wall=26492
2023-05-21 01:19:34 - progress_bar.py[line:272] - INFO: epoch 004:   1686 / 1732 loss=2.442, loss_v1=0, loss_v2=0, nll_loss=1.251, ntokens=1151.6, nsentences=32, sample_size=1151.6, sample_size_v1=0, sample_size_v2=0, ppl=2.38, wps=295.8, ups=0.26, wpb=1151.6, bsz=32, num_updates=6870, lr=9.23162e-06, gnorm=3.268, clip=100, loss_scale=128, train_wall=39, gb_free=7.7, wall=26531
2023-05-21 01:20:14 - progress_bar.py[line:272] - INFO: epoch 004:   1696 / 1732 loss=2.48, loss_v1=0, loss_v2=0, nll_loss=1.294, ntokens=1284.6, nsentences=32, sample_size=1284.6, sample_size_v1=0, sample_size_v2=0, ppl=2.45, wps=323.6, ups=0.25, wpb=1284.6, bsz=32, num_updates=6880, lr=9.22957e-06, gnorm=3.449, clip=100, loss_scale=128, train_wall=40, gb_free=7.9, wall=26571
2023-05-21 01:20:53 - progress_bar.py[line:272] - INFO: epoch 004:   1706 / 1732 loss=2.455, loss_v1=0, loss_v2=0, nll_loss=1.262, ntokens=1193.5, nsentences=32, sample_size=1193.5, sample_size_v1=0, sample_size_v2=0, ppl=2.4, wps=305.1, ups=0.26, wpb=1193.5, bsz=32, num_updates=6890, lr=9.22752e-06, gnorm=3.477, clip=100, loss_scale=128, train_wall=39, gb_free=7.9, wall=26610
2023-05-21 01:21:32 - progress_bar.py[line:272] - INFO: epoch 004:   1716 / 1732 loss=2.45, loss_v1=0, loss_v2=0, nll_loss=1.259, ntokens=1213.9, nsentences=32, sample_size=1213.9, sample_size_v1=0, sample_size_v2=0, ppl=2.39, wps=310.6, ups=0.26, wpb=1213.9, bsz=32, num_updates=6900, lr=9.22548e-06, gnorm=3.483, clip=100, loss_scale=128, train_wall=39, gb_free=7.4, wall=26649
2023-05-21 01:22:11 - progress_bar.py[line:272] - INFO: epoch 004:   1726 / 1732 loss=2.503, loss_v1=0, loss_v2=0, nll_loss=1.317, ntokens=1112.1, nsentences=32, sample_size=1112.1, sample_size_v1=0, sample_size_v2=0, ppl=2.49, wps=286.6, ups=0.26, wpb=1112.1, bsz=32, num_updates=6910, lr=9.22343e-06, gnorm=3.442, clip=100, loss_scale=128, train_wall=39, gb_free=8.3, wall=26688
2023-05-21 01:22:31 - train.py[line:332] - INFO: end of epoch 4 (average epoch stats below)
2023-05-21 01:22:31 - progress_bar.py[line:282] - INFO: epoch 004 | loss 2.497 | loss_v1 0 | loss_v2 0 | nll_loss 1.311 | ntokens 1051.57 | nsentences 31.986 | sample_size 1051.57 | sample_size_v1 0 | sample_size_v2 0 | ppl 2.48 | wps 272.4 | ups 0.26 | wpb 1051.6 | bsz 32 | num_updates 6916 | lr 9.2222e-06 | gnorm 3.267 | clip 100 | loss_scale 128 | train_wall 6664 | gb_free 8.9 | wall 26709
2023-05-21 01:22:31 - trainer.py[line:639] - INFO: loading train data for epoch 5
local datafile ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 0 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 0 finished initializing row_count and line_idx-to-offset mapping
file ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 0 row count 55400 total row count 55400
slice_id 0 seek offset 0
2023-05-21 01:22:33 - trainer.py[line:703] - INFO: begin training epoch 5
2023-05-21 01:22:33 - train.py[line:305] - INFO: Start iterating over samples
2023-05-21 01:22:49 - progress_bar.py[line:272] - INFO: epoch 005:      4 / 1732 loss=2.461, loss_v1=0, loss_v2=0, nll_loss=1.265, ntokens=1098.7, nsentences=29.6, sample_size=1098.7, sample_size_v1=0, sample_size_v2=0, ppl=2.4, wps=287.6, ups=0.26, wpb=1098.7, bsz=29.6, num_updates=6920, lr=9.22138e-06, gnorm=3.555, clip=100, loss_scale=128, train_wall=36, gb_free=8, wall=26726
2023-05-21 01:23:28 - progress_bar.py[line:272] - INFO: epoch 005:     14 / 1732 loss=2.417, loss_v1=0, loss_v2=0, nll_loss=1.222, ntokens=1064.2, nsentences=32, sample_size=1064.2, sample_size_v1=0, sample_size_v2=0, ppl=2.33, wps=275.5, ups=0.26, wpb=1064.2, bsz=32, num_updates=6930, lr=9.21934e-06, gnorm=3.39, clip=100, loss_scale=128, train_wall=39, gb_free=8.3, wall=26765
2023-05-21 01:24:06 - progress_bar.py[line:272] - INFO: epoch 005:     24 / 1732 loss=2.368, loss_v1=0, loss_v2=0, nll_loss=1.165, ntokens=1038.3, nsentences=32, sample_size=1038.3, sample_size_v1=0, sample_size_v2=0, ppl=2.24, wps=268, ups=0.26, wpb=1038.3, bsz=32, num_updates=6940, lr=9.21729e-06, gnorm=3.964, clip=100, loss_scale=128, train_wall=39, gb_free=8.5, wall=26804
2023-05-21 01:24:45 - progress_bar.py[line:272] - INFO: epoch 005:     34 / 1732 loss=2.311, loss_v1=0, loss_v2=0, nll_loss=1.099, ntokens=1072.7, nsentences=32, sample_size=1072.7, sample_size_v1=0, sample_size_v2=0, ppl=2.14, wps=275.7, ups=0.26, wpb=1072.7, bsz=32, num_updates=6950, lr=9.21524e-06, gnorm=3.699, clip=100, loss_scale=128, train_wall=39, gb_free=8.2, wall=26842
2023-05-21 01:25:24 - progress_bar.py[line:272] - INFO: epoch 005:     44 / 1732 loss=2.288, loss_v1=0, loss_v2=0, nll_loss=1.082, ntokens=1134, nsentences=32, sample_size=1134, sample_size_v1=0, sample_size_v2=0, ppl=2.12, wps=291.3, ups=0.26, wpb=1134, bsz=32, num_updates=6960, lr=9.21319e-06, gnorm=3.034, clip=100, loss_scale=128, train_wall=39, gb_free=8.1, wall=26881
2023-05-21 01:26:03 - progress_bar.py[line:272] - INFO: epoch 005:     54 / 1732 loss=2.288, loss_v1=0, loss_v2=0, nll_loss=1.07, ntokens=1025.8, nsentences=32, sample_size=1025.8, sample_size_v1=0, sample_size_v2=0, ppl=2.1, wps=264.4, ups=0.26, wpb=1025.8, bsz=32, num_updates=6970, lr=9.21115e-06, gnorm=3.473, clip=100, loss_scale=128, train_wall=39, gb_free=8.4, wall=26920
2023-05-21 01:26:42 - progress_bar.py[line:272] - INFO: epoch 005:     64 / 1732 loss=2.1, loss_v1=0, loss_v2=0, nll_loss=0.87, ntokens=1253.8, nsentences=32, sample_size=1253.8, sample_size_v1=0, sample_size_v2=0, ppl=1.83, wps=319.2, ups=0.25, wpb=1253.8, bsz=32, num_updates=6980, lr=9.2091e-06, gnorm=2.759, clip=100, loss_scale=128, train_wall=39, gb_free=7.8, wall=26960
2023-05-21 01:27:22 - progress_bar.py[line:272] - INFO: epoch 005:     74 / 1732 loss=2.244, loss_v1=0, loss_v2=0, nll_loss=1.026, ntokens=1358.9, nsentences=32, sample_size=1358.9, sample_size_v1=0, sample_size_v2=0, ppl=2.04, wps=340, ups=0.25, wpb=1358.9, bsz=32, num_updates=6990, lr=9.20705e-06, gnorm=2.898, clip=100, loss_scale=128, train_wall=40, gb_free=7.3, wall=26999
2023-05-21 01:28:02 - progress_bar.py[line:272] - INFO: epoch 005:     84 / 1732 loss=2.283, loss_v1=0, loss_v2=0, nll_loss=1.07, ntokens=1166.6, nsentences=32, sample_size=1166.6, sample_size_v1=0, sample_size_v2=0, ppl=2.1, wps=294.7, ups=0.25, wpb=1166.6, bsz=32, num_updates=7000, lr=9.205e-06, gnorm=2.739, clip=100, loss_scale=128, train_wall=40, gb_free=7.6, wall=27039
2023-05-21 01:28:41 - progress_bar.py[line:272] - INFO: epoch 005:     94 / 1732 loss=2.26, loss_v1=0, loss_v2=0, nll_loss=1.043, ntokens=1099.4, nsentences=32, sample_size=1099.4, sample_size_v1=0, sample_size_v2=0, ppl=2.06, wps=283.2, ups=0.26, wpb=1099.4, bsz=32, num_updates=7010, lr=9.20296e-06, gnorm=2.898, clip=100, loss_scale=128, train_wall=39, gb_free=8.8, wall=27078
2023-05-21 01:29:19 - progress_bar.py[line:272] - INFO: epoch 005:    104 / 1732 loss=2.452, loss_v1=0, loss_v2=0, nll_loss=1.263, ntokens=968, nsentences=32, sample_size=968, sample_size_v1=0, sample_size_v2=0, ppl=2.4, wps=252, ups=0.26, wpb=968, bsz=32, num_updates=7020, lr=9.20091e-06, gnorm=3.246, clip=100, loss_scale=128, train_wall=38, gb_free=8.7, wall=27116
2023-05-21 01:29:58 - progress_bar.py[line:272] - INFO: epoch 005:    114 / 1732 loss=2.492, loss_v1=0, loss_v2=0, nll_loss=1.306, ntokens=1043.8, nsentences=32, sample_size=1043.8, sample_size_v1=0, sample_size_v2=0, ppl=2.47, wps=269.4, ups=0.26, wpb=1043.8, bsz=32, num_updates=7030, lr=9.19886e-06, gnorm=2.788, clip=100, loss_scale=128, train_wall=39, gb_free=8.4, wall=27155
2023-05-21 01:30:37 - progress_bar.py[line:272] - INFO: epoch 005:    124 / 1732 loss=2.435, loss_v1=0, loss_v2=0, nll_loss=1.237, ntokens=1156.9, nsentences=32, sample_size=1156.9, sample_size_v1=0, sample_size_v2=0, ppl=2.36, wps=292.9, ups=0.25, wpb=1156.9, bsz=32, num_updates=7040, lr=9.19681e-06, gnorm=2.967, clip=100, loss_scale=128, train_wall=39, gb_free=8, wall=27195
2023-05-21 01:31:17 - progress_bar.py[line:272] - INFO: epoch 005:    134 / 1732 loss=2.38, loss_v1=0, loss_v2=0, nll_loss=1.178, ntokens=1187.1, nsentences=32, sample_size=1187.1, sample_size_v1=0, sample_size_v2=0, ppl=2.26, wps=302.7, ups=0.25, wpb=1187.1, bsz=32, num_updates=7050, lr=9.19477e-06, gnorm=2.843, clip=100, loss_scale=128, train_wall=39, gb_free=8.7, wall=27234
2023-05-21 01:31:56 - progress_bar.py[line:272] - INFO: epoch 005:    144 / 1732 loss=2.387, loss_v1=0, loss_v2=0, nll_loss=1.187, ntokens=1239.8, nsentences=32, sample_size=1239.8, sample_size_v1=0, sample_size_v2=0, ppl=2.28, wps=313.3, ups=0.25, wpb=1239.8, bsz=32, num_updates=7060, lr=9.19272e-06, gnorm=2.643, clip=100, loss_scale=256, train_wall=40, gb_free=7.6, wall=27273
2023-05-21 01:32:36 - progress_bar.py[line:272] - INFO: epoch 005:    154 / 1732 loss=2.385, loss_v1=0, loss_v2=0, nll_loss=1.186, ntokens=1177.9, nsentences=32, sample_size=1177.9, sample_size_v1=0, sample_size_v2=0, ppl=2.28, wps=297.3, ups=0.25, wpb=1177.9, bsz=32, num_updates=7070, lr=9.19067e-06, gnorm=2.786, clip=100, loss_scale=256, train_wall=40, gb_free=7.6, wall=27313
2023-05-21 01:33:15 - progress_bar.py[line:272] - INFO: epoch 005:    164 / 1732 loss=2.364, loss_v1=0, loss_v2=0, nll_loss=1.159, ntokens=1064.5, nsentences=32, sample_size=1064.5, sample_size_v1=0, sample_size_v2=0, ppl=2.23, wps=273.6, ups=0.26, wpb=1064.5, bsz=32, num_updates=7080, lr=9.18862e-06, gnorm=3.107, clip=100, loss_scale=256, train_wall=39, gb_free=7.2, wall=27352
2023-05-21 01:33:53 - progress_bar.py[line:272] - INFO: epoch 005:    174 / 1732 loss=2.385, loss_v1=0, loss_v2=0, nll_loss=1.185, ntokens=918.2, nsentences=32, sample_size=918.2, sample_size_v1=0, sample_size_v2=0, ppl=2.27, wps=238.9, ups=0.26, wpb=918.2, bsz=32, num_updates=7090, lr=9.18658e-06, gnorm=3.672, clip=100, loss_scale=256, train_wall=38, gb_free=8.5, wall=27390
2023-05-21 01:34:33 - progress_bar.py[line:272] - INFO: epoch 005:    184 / 1732 loss=2.342, loss_v1=0, loss_v2=0, nll_loss=1.137, ntokens=1196.7, nsentences=32, sample_size=1196.7, sample_size_v1=0, sample_size_v2=0, ppl=2.2, wps=303.1, ups=0.25, wpb=1196.7, bsz=32, num_updates=7100, lr=9.18453e-06, gnorm=3.095, clip=100, loss_scale=256, train_wall=39, gb_free=8.3, wall=27430
2023-05-21 01:35:12 - progress_bar.py[line:272] - INFO: epoch 005:    194 / 1732 loss=2.369, loss_v1=0, loss_v2=0, nll_loss=1.171, ntokens=1132.8, nsentences=32, sample_size=1132.8, sample_size_v1=0, sample_size_v2=0, ppl=2.25, wps=288.3, ups=0.25, wpb=1132.8, bsz=32, num_updates=7110, lr=9.18248e-06, gnorm=3.071, clip=100, loss_scale=256, train_wall=39, gb_free=7.5, wall=27469
2023-05-21 01:35:50 - progress_bar.py[line:272] - INFO: epoch 005:    204 / 1732 loss=2.474, loss_v1=0, loss_v2=0, nll_loss=1.283, ntokens=1052.4, nsentences=32, sample_size=1052.4, sample_size_v1=0, sample_size_v2=0, ppl=2.43, wps=272.7, ups=0.26, wpb=1052.4, bsz=32, num_updates=7120, lr=9.18044e-06, gnorm=3.82, clip=100, loss_scale=256, train_wall=39, gb_free=8.2, wall=27508
2023-05-21 01:36:13 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 128.0
2023-05-21 01:36:33 - progress_bar.py[line:272] - INFO: epoch 005:    215 / 1732 loss=2.517, loss_v1=0, loss_v2=0, nll_loss=1.334, ntokens=1067.8, nsentences=32, sample_size=1067.8, sample_size_v1=0, sample_size_v2=0, ppl=2.52, wps=253.3, ups=0.24, wpb=1067.8, bsz=32, num_updates=7130, lr=9.17839e-06, gnorm=3.719, clip=100, loss_scale=128, train_wall=42, gb_free=8.9, wall=27550
2023-05-21 01:37:11 - progress_bar.py[line:272] - INFO: epoch 005:    225 / 1732 loss=2.498, loss_v1=0, loss_v2=0, nll_loss=1.311, ntokens=1095.2, nsentences=32, sample_size=1095.2, sample_size_v1=0, sample_size_v2=0, ppl=2.48, wps=284.7, ups=0.26, wpb=1095.2, bsz=32, num_updates=7140, lr=9.17634e-06, gnorm=3.342, clip=100, loss_scale=128, train_wall=38, gb_free=8, wall=27588
2023-05-21 01:37:50 - progress_bar.py[line:272] - INFO: epoch 005:    235 / 1732 loss=2.555, loss_v1=0, loss_v2=0, nll_loss=1.374, ntokens=1090, nsentences=32, sample_size=1090, sample_size_v1=0, sample_size_v2=0, ppl=2.59, wps=283, ups=0.26, wpb=1090, bsz=32, num_updates=7150, lr=9.17429e-06, gnorm=3.902, clip=100, loss_scale=128, train_wall=38, gb_free=8.5, wall=27627
2023-05-21 01:38:28 - progress_bar.py[line:272] - INFO: epoch 005:    245 / 1732 loss=2.54, loss_v1=0, loss_v2=0, nll_loss=1.357, ntokens=1178.2, nsentences=32, sample_size=1178.2, sample_size_v1=0, sample_size_v2=0, ppl=2.56, wps=304.4, ups=0.26, wpb=1178.2, bsz=32, num_updates=7160, lr=9.17225e-06, gnorm=3.231, clip=100, loss_scale=128, train_wall=39, gb_free=8.4, wall=27666
2023-05-21 01:39:07 - progress_bar.py[line:272] - INFO: epoch 005:    255 / 1732 loss=2.526, loss_v1=0, loss_v2=0, nll_loss=1.344, ntokens=1128.2, nsentences=32, sample_size=1128.2, sample_size_v1=0, sample_size_v2=0, ppl=2.54, wps=292.4, ups=0.26, wpb=1128.2, bsz=32, num_updates=7170, lr=9.1702e-06, gnorm=3.38, clip=100, loss_scale=128, train_wall=39, gb_free=9, wall=27704
2023-05-21 01:39:46 - progress_bar.py[line:272] - INFO: epoch 005:    265 / 1732 loss=2.532, loss_v1=0, loss_v2=0, nll_loss=1.349, ntokens=1148, nsentences=32, sample_size=1148, sample_size_v1=0, sample_size_v2=0, ppl=2.55, wps=297.5, ups=0.26, wpb=1148, bsz=32, num_updates=7180, lr=9.16815e-06, gnorm=3.271, clip=100, loss_scale=128, train_wall=39, gb_free=8.5, wall=27743
2023-05-21 01:40:24 - progress_bar.py[line:272] - INFO: epoch 005:    275 / 1732 loss=2.513, loss_v1=0, loss_v2=0, nll_loss=1.326, ntokens=1140.3, nsentences=32, sample_size=1140.3, sample_size_v1=0, sample_size_v2=0, ppl=2.51, wps=296.5, ups=0.26, wpb=1140.3, bsz=32, num_updates=7190, lr=9.1661e-06, gnorm=3.554, clip=100, loss_scale=128, train_wall=38, gb_free=8.6, wall=27781
2023-05-21 01:41:03 - progress_bar.py[line:272] - INFO: epoch 005:    285 / 1732 loss=2.53, loss_v1=0, loss_v2=0, nll_loss=1.349, ntokens=1154.4, nsentences=32, sample_size=1154.4, sample_size_v1=0, sample_size_v2=0, ppl=2.55, wps=299.6, ups=0.26, wpb=1154.4, bsz=32, num_updates=7200, lr=9.16406e-06, gnorm=3.161, clip=100, loss_scale=128, train_wall=38, gb_free=7.3, wall=27820
2023-05-21 01:41:41 - progress_bar.py[line:272] - INFO: epoch 005:    295 / 1732 loss=2.511, loss_v1=0, loss_v2=0, nll_loss=1.327, ntokens=1115.8, nsentences=32, sample_size=1115.8, sample_size_v1=0, sample_size_v2=0, ppl=2.51, wps=290, ups=0.26, wpb=1115.8, bsz=32, num_updates=7210, lr=9.16201e-06, gnorm=3.214, clip=100, loss_scale=128, train_wall=38, gb_free=8.6, wall=27858
2023-05-21 01:42:20 - progress_bar.py[line:272] - INFO: epoch 005:    305 / 1732 loss=2.508, loss_v1=0, loss_v2=0, nll_loss=1.323, ntokens=1102.2, nsentences=32, sample_size=1102.2, sample_size_v1=0, sample_size_v2=0, ppl=2.5, wps=285.8, ups=0.26, wpb=1102.2, bsz=32, num_updates=7220, lr=9.15996e-06, gnorm=3.503, clip=100, loss_scale=128, train_wall=39, gb_free=8.2, wall=27897
2023-05-21 01:42:58 - progress_bar.py[line:272] - INFO: epoch 005:    315 / 1732 loss=2.518, loss_v1=0, loss_v2=0, nll_loss=1.334, ntokens=1020.3, nsentences=32, sample_size=1020.3, sample_size_v1=0, sample_size_v2=0, ppl=2.52, wps=266.3, ups=0.26, wpb=1020.3, bsz=32, num_updates=7230, lr=9.15791e-06, gnorm=3.496, clip=100, loss_scale=128, train_wall=38, gb_free=8.7, wall=27935
2023-05-21 01:43:36 - progress_bar.py[line:272] - INFO: epoch 005:    325 / 1732 loss=2.537, loss_v1=0, loss_v2=0, nll_loss=1.354, ntokens=1011.9, nsentences=32, sample_size=1011.9, sample_size_v1=0, sample_size_v2=0, ppl=2.56, wps=263.9, ups=0.26, wpb=1011.9, bsz=32, num_updates=7240, lr=9.15587e-06, gnorm=3.779, clip=100, loss_scale=128, train_wall=38, gb_free=9, wall=27973
2023-05-21 01:44:15 - progress_bar.py[line:272] - INFO: epoch 005:    335 / 1732 loss=2.527, loss_v1=0, loss_v2=0, nll_loss=1.343, ntokens=1020.9, nsentences=32, sample_size=1020.9, sample_size_v1=0, sample_size_v2=0, ppl=2.54, wps=266.9, ups=0.26, wpb=1020.9, bsz=32, num_updates=7250, lr=9.15382e-06, gnorm=3.827, clip=100, loss_scale=128, train_wall=38, gb_free=8.7, wall=28012
2023-05-21 01:44:53 - progress_bar.py[line:272] - INFO: epoch 005:    345 / 1732 loss=2.488, loss_v1=0, loss_v2=0, nll_loss=1.303, ntokens=903.9, nsentences=32, sample_size=903.9, sample_size_v1=0, sample_size_v2=0, ppl=2.47, wps=237.8, ups=0.26, wpb=903.9, bsz=32, num_updates=7260, lr=9.15177e-06, gnorm=4.09, clip=100, loss_scale=128, train_wall=38, gb_free=8.3, wall=28050
2023-05-21 01:45:31 - progress_bar.py[line:272] - INFO: epoch 005:    355 / 1732 loss=2.527, loss_v1=0, loss_v2=0, nll_loss=1.347, ntokens=961.9, nsentences=32, sample_size=961.9, sample_size_v1=0, sample_size_v2=0, ppl=2.54, wps=252, ups=0.26, wpb=961.9, bsz=32, num_updates=7270, lr=9.14972e-06, gnorm=3.989, clip=100, loss_scale=128, train_wall=38, gb_free=9, wall=28088
2023-05-21 01:46:09 - progress_bar.py[line:272] - INFO: epoch 005:    365 / 1732 loss=2.552, loss_v1=0, loss_v2=0, nll_loss=1.37, ntokens=955.9, nsentences=32, sample_size=955.9, sample_size_v1=0, sample_size_v2=0, ppl=2.59, wps=252.4, ups=0.26, wpb=955.9, bsz=32, num_updates=7280, lr=9.14768e-06, gnorm=4.031, clip=100, loss_scale=128, train_wall=38, gb_free=8.2, wall=28126
2023-05-21 01:46:47 - progress_bar.py[line:272] - INFO: epoch 005:    375 / 1732 loss=2.562, loss_v1=0, loss_v2=0, nll_loss=1.38, ntokens=987.5, nsentences=32, sample_size=987.5, sample_size_v1=0, sample_size_v2=0, ppl=2.6, wps=258.2, ups=0.26, wpb=987.5, bsz=32, num_updates=7290, lr=9.14563e-06, gnorm=3.842, clip=100, loss_scale=128, train_wall=38, gb_free=9.1, wall=28164
2023-05-21 01:47:25 - progress_bar.py[line:272] - INFO: epoch 005:    385 / 1732 loss=2.529, loss_v1=0, loss_v2=0, nll_loss=1.346, ntokens=1084.2, nsentences=32, sample_size=1084.2, sample_size_v1=0, sample_size_v2=0, ppl=2.54, wps=283.7, ups=0.26, wpb=1084.2, bsz=32, num_updates=7300, lr=9.14358e-06, gnorm=3.554, clip=100, loss_scale=128, train_wall=38, gb_free=8.8, wall=28202
2023-05-21 01:48:03 - progress_bar.py[line:272] - INFO: epoch 005:    395 / 1732 loss=2.526, loss_v1=0, loss_v2=0, nll_loss=1.342, ntokens=924.7, nsentences=32, sample_size=924.7, sample_size_v1=0, sample_size_v2=0, ppl=2.54, wps=243.7, ups=0.26, wpb=924.7, bsz=32, num_updates=7310, lr=9.14154e-06, gnorm=4.891, clip=100, loss_scale=128, train_wall=38, gb_free=8.8, wall=28240
2023-05-21 01:48:41 - progress_bar.py[line:272] - INFO: epoch 005:    405 / 1732 loss=2.487, loss_v1=0, loss_v2=0, nll_loss=1.301, ntokens=1086.5, nsentences=32, sample_size=1086.5, sample_size_v1=0, sample_size_v2=0, ppl=2.46, wps=283.8, ups=0.26, wpb=1086.5, bsz=32, num_updates=7320, lr=9.13949e-06, gnorm=3.635, clip=100, loss_scale=128, train_wall=38, gb_free=9, wall=28278
2023-05-21 01:49:20 - progress_bar.py[line:272] - INFO: epoch 005:    415 / 1732 loss=2.5, loss_v1=0, loss_v2=0, nll_loss=1.313, ntokens=1059.1, nsentences=32, sample_size=1059.1, sample_size_v1=0, sample_size_v2=0, ppl=2.48, wps=275.5, ups=0.26, wpb=1059.1, bsz=32, num_updates=7330, lr=9.13744e-06, gnorm=4.16, clip=100, loss_scale=128, train_wall=38, gb_free=8.9, wall=28317
2023-05-21 01:49:58 - progress_bar.py[line:272] - INFO: epoch 005:    425 / 1732 loss=2.475, loss_v1=0, loss_v2=0, nll_loss=1.287, ntokens=994.5, nsentences=32, sample_size=994.5, sample_size_v1=0, sample_size_v2=0, ppl=2.44, wps=259.7, ups=0.26, wpb=994.5, bsz=32, num_updates=7340, lr=9.13539e-06, gnorm=4.192, clip=100, loss_scale=128, train_wall=38, gb_free=8.5, wall=28355
2023-05-21 01:50:36 - progress_bar.py[line:272] - INFO: epoch 005:    435 / 1732 loss=2.523, loss_v1=0, loss_v2=0, nll_loss=1.342, ntokens=1024.5, nsentences=32, sample_size=1024.5, sample_size_v1=0, sample_size_v2=0, ppl=2.54, wps=269.3, ups=0.26, wpb=1024.5, bsz=32, num_updates=7350, lr=9.13335e-06, gnorm=4.146, clip=100, loss_scale=128, train_wall=38, gb_free=9.2, wall=28393
2023-05-21 01:51:14 - progress_bar.py[line:272] - INFO: epoch 005:    445 / 1732 loss=2.541, loss_v1=0, loss_v2=0, nll_loss=1.358, ntokens=956.5, nsentences=32, sample_size=956.5, sample_size_v1=0, sample_size_v2=0, ppl=2.56, wps=251, ups=0.26, wpb=956.5, bsz=32, num_updates=7360, lr=9.1313e-06, gnorm=4.102, clip=100, loss_scale=128, train_wall=38, gb_free=8.6, wall=28431
2023-05-21 01:51:52 - progress_bar.py[line:272] - INFO: epoch 005:    455 / 1732 loss=2.513, loss_v1=0, loss_v2=0, nll_loss=1.328, ntokens=932.1, nsentences=32, sample_size=932.1, sample_size_v1=0, sample_size_v2=0, ppl=2.51, wps=245.9, ups=0.26, wpb=932.1, bsz=32, num_updates=7370, lr=9.12925e-06, gnorm=4.301, clip=100, loss_scale=128, train_wall=38, gb_free=8.8, wall=28469
2023-05-21 01:52:30 - progress_bar.py[line:272] - INFO: epoch 005:    465 / 1732 loss=2.539, loss_v1=0, loss_v2=0, nll_loss=1.357, ntokens=1058.7, nsentences=32, sample_size=1058.7, sample_size_v1=0, sample_size_v2=0, ppl=2.56, wps=276.4, ups=0.26, wpb=1058.7, bsz=32, num_updates=7380, lr=9.1272e-06, gnorm=3.932, clip=100, loss_scale=128, train_wall=38, gb_free=8.6, wall=28508
2023-05-21 01:53:09 - progress_bar.py[line:272] - INFO: epoch 005:    475 / 1732 loss=2.527, loss_v1=0, loss_v2=0, nll_loss=1.344, ntokens=1061.8, nsentences=32, sample_size=1061.8, sample_size_v1=0, sample_size_v2=0, ppl=2.54, wps=276.4, ups=0.26, wpb=1061.8, bsz=32, num_updates=7390, lr=9.12516e-06, gnorm=3.97, clip=100, loss_scale=128, train_wall=38, gb_free=8.5, wall=28546
2023-05-21 01:53:47 - progress_bar.py[line:272] - INFO: epoch 005:    485 / 1732 loss=2.495, loss_v1=0, loss_v2=0, nll_loss=1.307, ntokens=980.2, nsentences=32, sample_size=980.2, sample_size_v1=0, sample_size_v2=0, ppl=2.47, wps=256.7, ups=0.26, wpb=980.2, bsz=32, num_updates=7400, lr=9.12311e-06, gnorm=4.08, clip=100, loss_scale=128, train_wall=38, gb_free=8.4, wall=28584
2023-05-21 01:54:25 - progress_bar.py[line:272] - INFO: epoch 005:    495 / 1732 loss=2.512, loss_v1=0, loss_v2=0, nll_loss=1.33, ntokens=928.7, nsentences=32, sample_size=928.7, sample_size_v1=0, sample_size_v2=0, ppl=2.51, wps=244.2, ups=0.26, wpb=928.7, bsz=32, num_updates=7410, lr=9.12106e-06, gnorm=4.083, clip=100, loss_scale=128, train_wall=38, gb_free=9.3, wall=28622
2023-05-21 01:55:03 - progress_bar.py[line:272] - INFO: epoch 005:    505 / 1732 loss=2.512, loss_v1=0, loss_v2=0, nll_loss=1.324, ntokens=974.8, nsentences=32, sample_size=974.8, sample_size_v1=0, sample_size_v2=0, ppl=2.5, wps=257.4, ups=0.26, wpb=974.8, bsz=32, num_updates=7420, lr=9.11901e-06, gnorm=4.479, clip=100, loss_scale=128, train_wall=38, gb_free=8.7, wall=28660
2023-05-21 01:55:41 - progress_bar.py[line:272] - INFO: epoch 005:    515 / 1732 loss=2.522, loss_v1=0, loss_v2=0, nll_loss=1.34, ntokens=1073.1, nsentences=32, sample_size=1073.1, sample_size_v1=0, sample_size_v2=0, ppl=2.53, wps=281.4, ups=0.26, wpb=1073.1, bsz=32, num_updates=7430, lr=9.11697e-06, gnorm=3.684, clip=100, loss_scale=128, train_wall=38, gb_free=8.4, wall=28698
2023-05-21 01:56:19 - progress_bar.py[line:272] - INFO: epoch 005:    525 / 1732 loss=2.507, loss_v1=0, loss_v2=0, nll_loss=1.324, ntokens=955.6, nsentences=32, sample_size=955.6, sample_size_v1=0, sample_size_v2=0, ppl=2.5, wps=251.4, ups=0.26, wpb=955.6, bsz=32, num_updates=7440, lr=9.11492e-06, gnorm=4.419, clip=100, loss_scale=128, train_wall=38, gb_free=8.9, wall=28736
2023-05-21 01:56:57 - progress_bar.py[line:272] - INFO: epoch 005:    535 / 1732 loss=2.509, loss_v1=0, loss_v2=0, nll_loss=1.323, ntokens=948.7, nsentences=32, sample_size=948.7, sample_size_v1=0, sample_size_v2=0, ppl=2.5, wps=250.2, ups=0.26, wpb=948.7, bsz=32, num_updates=7450, lr=9.11287e-06, gnorm=3.889, clip=100, loss_scale=128, train_wall=38, gb_free=8.5, wall=28774
2023-05-21 01:57:35 - progress_bar.py[line:272] - INFO: epoch 005:    545 / 1732 loss=2.524, loss_v1=0, loss_v2=0, nll_loss=1.34, ntokens=1010, nsentences=32, sample_size=1010, sample_size_v1=0, sample_size_v2=0, ppl=2.53, wps=266.4, ups=0.26, wpb=1010, bsz=32, num_updates=7460, lr=9.11082e-06, gnorm=3.804, clip=100, loss_scale=128, train_wall=38, gb_free=8.3, wall=28812
2023-05-21 01:58:13 - progress_bar.py[line:272] - INFO: epoch 005:    555 / 1732 loss=2.552, loss_v1=0, loss_v2=0, nll_loss=1.372, ntokens=1039.8, nsentences=32, sample_size=1039.8, sample_size_v1=0, sample_size_v2=0, ppl=2.59, wps=273.7, ups=0.26, wpb=1039.8, bsz=32, num_updates=7470, lr=9.10878e-06, gnorm=4.308, clip=100, loss_scale=128, train_wall=38, gb_free=8.6, wall=28850
2023-05-21 01:58:51 - progress_bar.py[line:272] - INFO: epoch 005:    565 / 1732 loss=2.539, loss_v1=0, loss_v2=0, nll_loss=1.358, ntokens=1014, nsentences=32, sample_size=1014, sample_size_v1=0, sample_size_v2=0, ppl=2.56, wps=265.4, ups=0.26, wpb=1014, bsz=32, num_updates=7480, lr=9.10673e-06, gnorm=4.659, clip=100, loss_scale=128, train_wall=38, gb_free=8.5, wall=28888
2023-05-21 01:59:29 - progress_bar.py[line:272] - INFO: epoch 005:    575 / 1732 loss=2.521, loss_v1=0, loss_v2=0, nll_loss=1.337, ntokens=1007.3, nsentences=32, sample_size=1007.3, sample_size_v1=0, sample_size_v2=0, ppl=2.53, wps=262.7, ups=0.26, wpb=1007.3, bsz=32, num_updates=7490, lr=9.10468e-06, gnorm=4.35, clip=100, loss_scale=128, train_wall=38, gb_free=8.8, wall=28927
2023-05-21 02:00:08 - progress_bar.py[line:272] - INFO: epoch 005:    585 / 1732 loss=2.532, loss_v1=0, loss_v2=0, nll_loss=1.35, ntokens=980.6, nsentences=32, sample_size=980.6, sample_size_v1=0, sample_size_v2=0, ppl=2.55, wps=255.2, ups=0.26, wpb=980.6, bsz=32, num_updates=7500, lr=9.10263e-06, gnorm=4.505, clip=100, loss_scale=128, train_wall=38, gb_free=8.8, wall=28965
2023-05-21 02:00:46 - progress_bar.py[line:272] - INFO: epoch 005:    595 / 1732 loss=2.497, loss_v1=0, loss_v2=0, nll_loss=1.312, ntokens=961.9, nsentences=32, sample_size=961.9, sample_size_v1=0, sample_size_v2=0, ppl=2.48, wps=251.2, ups=0.26, wpb=961.9, bsz=32, num_updates=7510, lr=9.10059e-06, gnorm=4.741, clip=100, loss_scale=128, train_wall=38, gb_free=8.8, wall=29003
2023-05-21 02:01:24 - progress_bar.py[line:272] - INFO: epoch 005:    605 / 1732 loss=2.499, loss_v1=0, loss_v2=0, nll_loss=1.315, ntokens=879.8, nsentences=32, sample_size=879.8, sample_size_v1=0, sample_size_v2=0, ppl=2.49, wps=232.6, ups=0.26, wpb=879.8, bsz=32, num_updates=7520, lr=9.09854e-06, gnorm=4.815, clip=100, loss_scale=128, train_wall=38, gb_free=9.3, wall=29041
2023-05-21 02:02:02 - progress_bar.py[line:272] - INFO: epoch 005:    615 / 1732 loss=2.525, loss_v1=0, loss_v2=0, nll_loss=1.343, ntokens=903.1, nsentences=32, sample_size=903.1, sample_size_v1=0, sample_size_v2=0, ppl=2.54, wps=236.7, ups=0.26, wpb=903.1, bsz=32, num_updates=7530, lr=9.09649e-06, gnorm=4.489, clip=100, loss_scale=128, train_wall=38, gb_free=8.4, wall=29079
2023-05-21 02:02:40 - progress_bar.py[line:272] - INFO: epoch 005:    625 / 1732 loss=2.525, loss_v1=0, loss_v2=0, nll_loss=1.341, ntokens=898.6, nsentences=32, sample_size=898.6, sample_size_v1=0, sample_size_v2=0, ppl=2.53, wps=238, ups=0.26, wpb=898.6, bsz=32, num_updates=7540, lr=9.09445e-06, gnorm=4.762, clip=100, loss_scale=128, train_wall=38, gb_free=8.9, wall=29117
2023-05-21 02:03:18 - progress_bar.py[line:272] - INFO: epoch 005:    635 / 1732 loss=2.528, loss_v1=0, loss_v2=0, nll_loss=1.346, ntokens=897.1, nsentences=32, sample_size=897.1, sample_size_v1=0, sample_size_v2=0, ppl=2.54, wps=236.9, ups=0.26, wpb=897.1, bsz=32, num_updates=7550, lr=9.0924e-06, gnorm=4.832, clip=100, loss_scale=128, train_wall=38, gb_free=9, wall=29155
2023-05-21 02:03:56 - progress_bar.py[line:272] - INFO: epoch 005:    645 / 1732 loss=2.522, loss_v1=0, loss_v2=0, nll_loss=1.34, ntokens=1010.4, nsentences=32, sample_size=1010.4, sample_size_v1=0, sample_size_v2=0, ppl=2.53, wps=265.9, ups=0.26, wpb=1010.4, bsz=32, num_updates=7560, lr=9.09035e-06, gnorm=4.263, clip=100, loss_scale=128, train_wall=38, gb_free=8.9, wall=29193
2023-05-21 02:04:33 - progress_bar.py[line:272] - INFO: epoch 005:    655 / 1732 loss=2.533, loss_v1=0, loss_v2=0, nll_loss=1.348, ntokens=879.8, nsentences=32, sample_size=879.8, sample_size_v1=0, sample_size_v2=0, ppl=2.55, wps=233.4, ups=0.27, wpb=879.8, bsz=32, num_updates=7570, lr=9.0883e-06, gnorm=4.8, clip=100, loss_scale=128, train_wall=38, gb_free=8.7, wall=29231
2023-05-21 02:05:11 - progress_bar.py[line:272] - INFO: epoch 005:    665 / 1732 loss=2.537, loss_v1=0, loss_v2=0, nll_loss=1.355, ntokens=893.8, nsentences=32, sample_size=893.8, sample_size_v1=0, sample_size_v2=0, ppl=2.56, wps=236.1, ups=0.26, wpb=893.8, bsz=32, num_updates=7580, lr=9.08626e-06, gnorm=5.544, clip=100, loss_scale=128, train_wall=38, gb_free=9.3, wall=29269
2023-05-21 02:05:49 - progress_bar.py[line:272] - INFO: epoch 005:    675 / 1732 loss=2.529, loss_v1=0, loss_v2=0, nll_loss=1.347, ntokens=961.9, nsentences=32, sample_size=961.9, sample_size_v1=0, sample_size_v2=0, ppl=2.54, wps=253.5, ups=0.26, wpb=961.9, bsz=32, num_updates=7590, lr=9.08421e-06, gnorm=4.199, clip=100, loss_scale=128, train_wall=38, gb_free=8, wall=29306
2023-05-21 02:06:27 - progress_bar.py[line:272] - INFO: epoch 005:    685 / 1732 loss=2.51, loss_v1=0, loss_v2=0, nll_loss=1.325, ntokens=961.5, nsentences=32, sample_size=961.5, sample_size_v1=0, sample_size_v2=0, ppl=2.5, wps=253.1, ups=0.26, wpb=961.5, bsz=32, num_updates=7600, lr=9.08216e-06, gnorm=4.326, clip=100, loss_scale=128, train_wall=38, gb_free=8.7, wall=29344
2023-05-21 02:07:05 - progress_bar.py[line:272] - INFO: epoch 005:    695 / 1732 loss=2.531, loss_v1=0, loss_v2=0, nll_loss=1.35, ntokens=1007.2, nsentences=32, sample_size=1007.2, sample_size_v1=0, sample_size_v2=0, ppl=2.55, wps=263.5, ups=0.26, wpb=1007.2, bsz=32, num_updates=7610, lr=9.08011e-06, gnorm=4.306, clip=100, loss_scale=128, train_wall=38, gb_free=7.5, wall=29383
2023-05-21 02:07:43 - progress_bar.py[line:272] - INFO: epoch 005:    705 / 1732 loss=2.488, loss_v1=0, loss_v2=0, nll_loss=1.3, ntokens=925.6, nsentences=32, sample_size=925.6, sample_size_v1=0, sample_size_v2=0, ppl=2.46, wps=243.8, ups=0.26, wpb=925.6, bsz=32, num_updates=7620, lr=9.07807e-06, gnorm=4.955, clip=100, loss_scale=128, train_wall=38, gb_free=9, wall=29421
2023-05-21 02:08:21 - progress_bar.py[line:272] - INFO: epoch 005:    715 / 1732 loss=2.537, loss_v1=0, loss_v2=0, nll_loss=1.353, ntokens=890.5, nsentences=32, sample_size=890.5, sample_size_v1=0, sample_size_v2=0, ppl=2.56, wps=235.7, ups=0.26, wpb=890.5, bsz=32, num_updates=7630, lr=9.07602e-06, gnorm=5.284, clip=100, loss_scale=128, train_wall=38, gb_free=8.9, wall=29458
2023-05-21 02:08:59 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 128.0
2023-05-21 02:09:03 - progress_bar.py[line:272] - INFO: epoch 005:    726 / 1732 loss=2.485, loss_v1=0, loss_v2=0, nll_loss=1.299, ntokens=897.2, nsentences=32, sample_size=897.2, sample_size_v1=0, sample_size_v2=0, ppl=2.46, wps=216.8, ups=0.24, wpb=897.2, bsz=32, num_updates=7640, lr=9.07397e-06, gnorm=4.307, clip=100, loss_scale=128, train_wall=41, gb_free=8.2, wall=29500
2023-05-21 02:09:40 - progress_bar.py[line:272] - INFO: epoch 005:    736 / 1732 loss=2.491, loss_v1=0, loss_v2=0, nll_loss=1.307, ntokens=979.7, nsentences=32, sample_size=979.7, sample_size_v1=0, sample_size_v2=0, ppl=2.47, wps=259, ups=0.26, wpb=979.7, bsz=32, num_updates=7650, lr=9.07192e-06, gnorm=4.546, clip=100, loss_scale=128, train_wall=38, gb_free=9, wall=29538
2023-05-21 02:10:19 - progress_bar.py[line:272] - INFO: epoch 005:    746 / 1732 loss=2.493, loss_v1=0, loss_v2=0, nll_loss=1.308, ntokens=974.7, nsentences=32, sample_size=974.7, sample_size_v1=0, sample_size_v2=0, ppl=2.48, wps=256, ups=0.26, wpb=974.7, bsz=32, num_updates=7660, lr=9.06988e-06, gnorm=4.748, clip=100, loss_scale=128, train_wall=38, gb_free=8.7, wall=29576
2023-05-21 02:10:57 - progress_bar.py[line:272] - INFO: epoch 005:    756 / 1732 loss=2.499, loss_v1=0, loss_v2=0, nll_loss=1.312, ntokens=977.2, nsentences=32, sample_size=977.2, sample_size_v1=0, sample_size_v2=0, ppl=2.48, wps=257.2, ups=0.26, wpb=977.2, bsz=32, num_updates=7670, lr=9.06783e-06, gnorm=5.051, clip=100, loss_scale=128, train_wall=38, gb_free=8.4, wall=29614
2023-05-21 02:11:34 - progress_bar.py[line:272] - INFO: epoch 005:    766 / 1732 loss=2.5, loss_v1=0, loss_v2=0, nll_loss=1.313, ntokens=933.3, nsentences=32, sample_size=933.3, sample_size_v1=0, sample_size_v2=0, ppl=2.48, wps=246, ups=0.26, wpb=933.3, bsz=32, num_updates=7680, lr=9.06578e-06, gnorm=4.72, clip=100, loss_scale=128, train_wall=38, gb_free=8.8, wall=29652
2023-05-21 02:12:13 - progress_bar.py[line:272] - INFO: epoch 005:    776 / 1732 loss=2.509, loss_v1=0, loss_v2=0, nll_loss=1.328, ntokens=1027.3, nsentences=32, sample_size=1027.3, sample_size_v1=0, sample_size_v2=0, ppl=2.51, wps=269.7, ups=0.26, wpb=1027.3, bsz=32, num_updates=7690, lr=9.06373e-06, gnorm=4.536, clip=100, loss_scale=128, train_wall=38, gb_free=8.6, wall=29690
2023-05-21 02:12:24 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2023-05-21 02:12:54 - progress_bar.py[line:272] - INFO: epoch 005:    787 / 1732 loss=2.508, loss_v1=0, loss_v2=0, nll_loss=1.324, ntokens=1001.7, nsentences=32, sample_size=1001.7, sample_size_v1=0, sample_size_v2=0, ppl=2.5, wps=239.3, ups=0.24, wpb=1001.7, bsz=32, num_updates=7700, lr=9.06169e-06, gnorm=4.5, clip=100, loss_scale=64, train_wall=42, gb_free=8.5, wall=29732
2023-05-21 02:13:33 - progress_bar.py[line:272] - INFO: epoch 005:    797 / 1732 loss=2.496, loss_v1=0, loss_v2=0, nll_loss=1.307, ntokens=1038, nsentences=32, sample_size=1038, sample_size_v1=0, sample_size_v2=0, ppl=2.47, wps=272.2, ups=0.26, wpb=1038, bsz=32, num_updates=7710, lr=9.05964e-06, gnorm=4.861, clip=100, loss_scale=64, train_wall=38, gb_free=8.8, wall=29770
2023-05-21 02:14:11 - progress_bar.py[line:272] - INFO: epoch 005:    807 / 1732 loss=2.506, loss_v1=0, loss_v2=0, nll_loss=1.321, ntokens=915, nsentences=32, sample_size=915, sample_size_v1=0, sample_size_v2=0, ppl=2.5, wps=240.6, ups=0.26, wpb=915, bsz=32, num_updates=7720, lr=9.05759e-06, gnorm=5.282, clip=100, loss_scale=64, train_wall=38, gb_free=8.7, wall=29808
2023-05-21 02:14:49 - progress_bar.py[line:272] - INFO: epoch 005:    817 / 1732 loss=2.522, loss_v1=0, loss_v2=0, nll_loss=1.339, ntokens=917.4, nsentences=32, sample_size=917.4, sample_size_v1=0, sample_size_v2=0, ppl=2.53, wps=240.1, ups=0.26, wpb=917.4, bsz=32, num_updates=7730, lr=9.05555e-06, gnorm=4.417, clip=100, loss_scale=64, train_wall=38, gb_free=8.9, wall=29846
2023-05-21 02:15:27 - progress_bar.py[line:272] - INFO: epoch 005:    827 / 1732 loss=2.51, loss_v1=0, loss_v2=0, nll_loss=1.325, ntokens=930.6, nsentences=32, sample_size=930.6, sample_size_v1=0, sample_size_v2=0, ppl=2.51, wps=245, ups=0.26, wpb=930.6, bsz=32, num_updates=7740, lr=9.0535e-06, gnorm=4.521, clip=100, loss_scale=64, train_wall=38, gb_free=8.9, wall=29884
2023-05-21 02:16:04 - progress_bar.py[line:272] - INFO: epoch 005:    837 / 1732 loss=2.504, loss_v1=0, loss_v2=0, nll_loss=1.318, ntokens=894.5, nsentences=32, sample_size=894.5, sample_size_v1=0, sample_size_v2=0, ppl=2.49, wps=237.5, ups=0.27, wpb=894.5, bsz=32, num_updates=7750, lr=9.05145e-06, gnorm=5.133, clip=100, loss_scale=64, train_wall=38, gb_free=9.1, wall=29922
2023-05-21 02:16:42 - progress_bar.py[line:272] - INFO: epoch 005:    847 / 1732 loss=2.483, loss_v1=0, loss_v2=0, nll_loss=1.291, ntokens=1012.6, nsentences=32, sample_size=1012.6, sample_size_v1=0, sample_size_v2=0, ppl=2.45, wps=266.4, ups=0.26, wpb=1012.6, bsz=32, num_updates=7760, lr=9.0494e-06, gnorm=4.384, clip=100, loss_scale=64, train_wall=38, gb_free=7.7, wall=29960
2023-05-21 02:17:20 - progress_bar.py[line:272] - INFO: epoch 005:    857 / 1732 loss=2.507, loss_v1=0, loss_v2=0, nll_loss=1.323, ntokens=920, nsentences=32, sample_size=920, sample_size_v1=0, sample_size_v2=0, ppl=2.5, wps=243.5, ups=0.26, wpb=920, bsz=32, num_updates=7770, lr=9.04736e-06, gnorm=4.992, clip=100, loss_scale=64, train_wall=38, gb_free=8.6, wall=29997
2023-05-21 02:17:58 - progress_bar.py[line:272] - INFO: epoch 005:    867 / 1732 loss=2.504, loss_v1=0, loss_v2=0, nll_loss=1.32, ntokens=979.9, nsentences=32, sample_size=979.9, sample_size_v1=0, sample_size_v2=0, ppl=2.5, wps=257.7, ups=0.26, wpb=979.9, bsz=32, num_updates=7780, lr=9.04531e-06, gnorm=4.746, clip=100, loss_scale=64, train_wall=38, gb_free=8.6, wall=30036
2023-05-21 02:18:36 - progress_bar.py[line:272] - INFO: epoch 005:    877 / 1732 loss=2.443, loss_v1=0, loss_v2=0, nll_loss=1.252, ntokens=994.5, nsentences=32, sample_size=994.5, sample_size_v1=0, sample_size_v2=0, ppl=2.38, wps=260.4, ups=0.26, wpb=994.5, bsz=32, num_updates=7790, lr=9.04326e-06, gnorm=4.197, clip=100, loss_scale=64, train_wall=38, gb_free=8.9, wall=30074
2023-05-21 02:19:15 - progress_bar.py[line:272] - INFO: epoch 005:    887 / 1732 loss=2.471, loss_v1=0, loss_v2=0, nll_loss=1.281, ntokens=982, nsentences=32, sample_size=982, sample_size_v1=0, sample_size_v2=0, ppl=2.43, wps=256.9, ups=0.26, wpb=982, bsz=32, num_updates=7800, lr=9.04121e-06, gnorm=4.767, clip=100, loss_scale=64, train_wall=38, gb_free=8.3, wall=30112
2023-05-21 02:19:53 - progress_bar.py[line:272] - INFO: epoch 005:    897 / 1732 loss=2.447, loss_v1=0, loss_v2=0, nll_loss=1.252, ntokens=1034.6, nsentences=32, sample_size=1034.6, sample_size_v1=0, sample_size_v2=0, ppl=2.38, wps=271, ups=0.26, wpb=1034.6, bsz=32, num_updates=7810, lr=9.03917e-06, gnorm=4.661, clip=100, loss_scale=64, train_wall=38, gb_free=8.6, wall=30150
2023-05-21 02:20:31 - progress_bar.py[line:272] - INFO: epoch 005:    907 / 1732 loss=2.459, loss_v1=0, loss_v2=0, nll_loss=1.271, ntokens=1016.8, nsentences=32, sample_size=1016.8, sample_size_v1=0, sample_size_v2=0, ppl=2.41, wps=266.1, ups=0.26, wpb=1016.8, bsz=32, num_updates=7820, lr=9.03712e-06, gnorm=4.917, clip=100, loss_scale=64, train_wall=38, gb_free=8.9, wall=30188
2023-05-21 02:21:09 - progress_bar.py[line:272] - INFO: epoch 005:    917 / 1732 loss=2.538, loss_v1=0, loss_v2=0, nll_loss=1.358, ntokens=936.4, nsentences=32, sample_size=936.4, sample_size_v1=0, sample_size_v2=0, ppl=2.56, wps=245.4, ups=0.26, wpb=936.4, bsz=32, num_updates=7830, lr=9.03507e-06, gnorm=5.32, clip=100, loss_scale=64, train_wall=38, gb_free=9.2, wall=30226
2023-05-21 02:21:48 - progress_bar.py[line:272] - INFO: epoch 005:    927 / 1732 loss=2.47, loss_v1=0, loss_v2=0, nll_loss=1.28, ntokens=1039.7, nsentences=32, sample_size=1039.7, sample_size_v1=0, sample_size_v2=0, ppl=2.43, wps=270.4, ups=0.26, wpb=1039.7, bsz=32, num_updates=7840, lr=9.03302e-06, gnorm=4.702, clip=100, loss_scale=64, train_wall=38, gb_free=8.7, wall=30265
2023-05-21 02:22:26 - progress_bar.py[line:272] - INFO: epoch 005:    937 / 1732 loss=2.471, loss_v1=0, loss_v2=0, nll_loss=1.283, ntokens=1061.1, nsentences=32, sample_size=1061.1, sample_size_v1=0, sample_size_v2=0, ppl=2.43, wps=275, ups=0.26, wpb=1061.1, bsz=32, num_updates=7850, lr=9.03098e-06, gnorm=4.416, clip=100, loss_scale=64, train_wall=39, gb_free=8.3, wall=30304
2023-05-21 02:23:05 - progress_bar.py[line:272] - INFO: epoch 005:    947 / 1732 loss=2.486, loss_v1=0, loss_v2=0, nll_loss=1.299, ntokens=1042.4, nsentences=32, sample_size=1042.4, sample_size_v1=0, sample_size_v2=0, ppl=2.46, wps=270, ups=0.26, wpb=1042.4, bsz=32, num_updates=7860, lr=9.02893e-06, gnorm=4.11, clip=100, loss_scale=64, train_wall=39, gb_free=8.6, wall=30342
2023-05-21 02:23:44 - progress_bar.py[line:272] - INFO: epoch 005:    957 / 1732 loss=2.488, loss_v1=0, loss_v2=0, nll_loss=1.301, ntokens=1046.8, nsentences=32, sample_size=1046.8, sample_size_v1=0, sample_size_v2=0, ppl=2.46, wps=269.2, ups=0.26, wpb=1046.8, bsz=32, num_updates=7870, lr=9.02688e-06, gnorm=4.756, clip=100, loss_scale=64, train_wall=39, gb_free=8.2, wall=30381
2023-05-21 02:24:22 - progress_bar.py[line:272] - INFO: epoch 005:    967 / 1732 loss=2.484, loss_v1=0, loss_v2=0, nll_loss=1.298, ntokens=1036.4, nsentences=32, sample_size=1036.4, sample_size_v1=0, sample_size_v2=0, ppl=2.46, wps=268.9, ups=0.26, wpb=1036.4, bsz=32, num_updates=7880, lr=9.02483e-06, gnorm=4.663, clip=100, loss_scale=64, train_wall=38, gb_free=8.6, wall=30420
2023-05-21 02:25:01 - progress_bar.py[line:272] - INFO: epoch 005:    977 / 1732 loss=2.497, loss_v1=0, loss_v2=0, nll_loss=1.311, ntokens=1035.2, nsentences=32, sample_size=1035.2, sample_size_v1=0, sample_size_v2=0, ppl=2.48, wps=267.2, ups=0.26, wpb=1035.2, bsz=32, num_updates=7890, lr=9.02279e-06, gnorm=4.39, clip=100, loss_scale=64, train_wall=39, gb_free=8.1, wall=30458
2023-05-21 02:25:40 - progress_bar.py[line:272] - INFO: epoch 005:    987 / 1732 loss=2.482, loss_v1=0, loss_v2=0, nll_loss=1.297, ntokens=1020.1, nsentences=32, sample_size=1020.1, sample_size_v1=0, sample_size_v2=0, ppl=2.46, wps=263.5, ups=0.26, wpb=1020.1, bsz=32, num_updates=7900, lr=9.02074e-06, gnorm=4.605, clip=100, loss_scale=64, train_wall=39, gb_free=8.5, wall=30497
2023-05-21 02:26:18 - progress_bar.py[line:272] - INFO: epoch 005:    997 / 1732 loss=2.474, loss_v1=0, loss_v2=0, nll_loss=1.282, ntokens=1032.4, nsentences=32, sample_size=1032.4, sample_size_v1=0, sample_size_v2=0, ppl=2.43, wps=268.5, ups=0.26, wpb=1032.4, bsz=32, num_updates=7910, lr=9.01869e-06, gnorm=4.536, clip=100, loss_scale=64, train_wall=38, gb_free=8.9, wall=30536
2023-05-21 02:26:57 - progress_bar.py[line:272] - INFO: epoch 005:   1007 / 1732 loss=2.466, loss_v1=0, loss_v2=0, nll_loss=1.276, ntokens=1018.9, nsentences=32, sample_size=1018.9, sample_size_v1=0, sample_size_v2=0, ppl=2.42, wps=265.2, ups=0.26, wpb=1018.9, bsz=32, num_updates=7920, lr=9.01665e-06, gnorm=4.288, clip=100, loss_scale=64, train_wall=38, gb_free=8.6, wall=30574
2023-05-21 02:27:35 - progress_bar.py[line:272] - INFO: epoch 005:   1017 / 1732 loss=2.473, loss_v1=0, loss_v2=0, nll_loss=1.285, ntokens=1024.8, nsentences=32, sample_size=1024.8, sample_size_v1=0, sample_size_v2=0, ppl=2.44, wps=266.4, ups=0.26, wpb=1024.8, bsz=32, num_updates=7930, lr=9.0146e-06, gnorm=4.513, clip=100, loss_scale=64, train_wall=38, gb_free=7.6, wall=30612
2023-05-21 02:28:14 - progress_bar.py[line:272] - INFO: epoch 005:   1027 / 1732 loss=2.495, loss_v1=0, loss_v2=0, nll_loss=1.311, ntokens=1051.5, nsentences=32, sample_size=1051.5, sample_size_v1=0, sample_size_v2=0, ppl=2.48, wps=270.5, ups=0.26, wpb=1051.5, bsz=32, num_updates=7940, lr=9.01255e-06, gnorm=4.649, clip=100, loss_scale=64, train_wall=39, gb_free=8.6, wall=30651
2023-05-21 02:28:53 - progress_bar.py[line:272] - INFO: epoch 005:   1037 / 1732 loss=2.469, loss_v1=0, loss_v2=0, nll_loss=1.279, ntokens=1129.2, nsentences=32, sample_size=1129.2, sample_size_v1=0, sample_size_v2=0, ppl=2.43, wps=290.7, ups=0.26, wpb=1129.2, bsz=32, num_updates=7950, lr=9.0105e-06, gnorm=4.549, clip=100, loss_scale=64, train_wall=39, gb_free=8.7, wall=30690
2023-05-21 02:29:31 - progress_bar.py[line:272] - INFO: epoch 005:   1047 / 1732 loss=2.47, loss_v1=0, loss_v2=0, nll_loss=1.278, ntokens=1024.6, nsentences=32, sample_size=1024.6, sample_size_v1=0, sample_size_v2=0, ppl=2.42, wps=266.4, ups=0.26, wpb=1024.6, bsz=32, num_updates=7960, lr=9.00846e-06, gnorm=4.707, clip=100, loss_scale=64, train_wall=38, gb_free=8.6, wall=30729
2023-05-21 02:30:10 - progress_bar.py[line:272] - INFO: epoch 005:   1057 / 1732 loss=2.475, loss_v1=0, loss_v2=0, nll_loss=1.285, ntokens=1089.7, nsentences=32, sample_size=1089.7, sample_size_v1=0, sample_size_v2=0, ppl=2.44, wps=282, ups=0.26, wpb=1089.7, bsz=32, num_updates=7970, lr=9.00641e-06, gnorm=4.343, clip=100, loss_scale=64, train_wall=39, gb_free=7.5, wall=30767
2023-05-21 02:30:48 - progress_bar.py[line:272] - INFO: epoch 005:   1067 / 1732 loss=2.478, loss_v1=0, loss_v2=0, nll_loss=1.29, ntokens=1006.5, nsentences=32, sample_size=1006.5, sample_size_v1=0, sample_size_v2=0, ppl=2.45, wps=261.6, ups=0.26, wpb=1006.5, bsz=32, num_updates=7980, lr=9.00436e-06, gnorm=4.871, clip=100, loss_scale=64, train_wall=38, gb_free=8.5, wall=30806
2023-05-21 02:31:27 - progress_bar.py[line:272] - INFO: epoch 005:   1077 / 1732 loss=2.502, loss_v1=0, loss_v2=0, nll_loss=1.315, ntokens=990.3, nsentences=32, sample_size=990.3, sample_size_v1=0, sample_size_v2=0, ppl=2.49, wps=255.6, ups=0.26, wpb=990.3, bsz=32, num_updates=7990, lr=9.00231e-06, gnorm=4.803, clip=100, loss_scale=64, train_wall=39, gb_free=9, wall=30844
2023-05-21 02:32:06 - progress_bar.py[line:272] - INFO: epoch 005:   1087 / 1732 loss=2.485, loss_v1=0, loss_v2=0, nll_loss=1.297, ntokens=1071.1, nsentences=32, sample_size=1071.1, sample_size_v1=0, sample_size_v2=0, ppl=2.46, wps=275.8, ups=0.26, wpb=1071.1, bsz=32, num_updates=8000, lr=9.00027e-06, gnorm=4.897, clip=100, loss_scale=64, train_wall=39, gb_free=8.8, wall=30883
2023-05-21 02:32:45 - progress_bar.py[line:272] - INFO: epoch 005:   1097 / 1732 loss=2.479, loss_v1=0, loss_v2=0, nll_loss=1.289, ntokens=1042.6, nsentences=32, sample_size=1042.6, sample_size_v1=0, sample_size_v2=0, ppl=2.44, wps=269.9, ups=0.26, wpb=1042.6, bsz=32, num_updates=8010, lr=8.99822e-06, gnorm=4.539, clip=100, loss_scale=64, train_wall=39, gb_free=8.9, wall=30922
2023-05-21 02:33:24 - progress_bar.py[line:272] - INFO: epoch 005:   1107 / 1732 loss=2.472, loss_v1=0, loss_v2=0, nll_loss=1.283, ntokens=1075.5, nsentences=32, sample_size=1075.5, sample_size_v1=0, sample_size_v2=0, ppl=2.43, wps=276.3, ups=0.26, wpb=1075.5, bsz=32, num_updates=8020, lr=8.99617e-06, gnorm=4.46, clip=100, loss_scale=64, train_wall=39, gb_free=8.1, wall=30961
2023-05-21 02:34:02 - progress_bar.py[line:272] - INFO: epoch 005:   1117 / 1732 loss=2.485, loss_v1=0, loss_v2=0, nll_loss=1.298, ntokens=943.9, nsentences=32, sample_size=943.9, sample_size_v1=0, sample_size_v2=0, ppl=2.46, wps=245.7, ups=0.26, wpb=943.9, bsz=32, num_updates=8030, lr=8.99412e-06, gnorm=5.529, clip=100, loss_scale=64, train_wall=38, gb_free=8.7, wall=30999
2023-05-21 02:34:41 - progress_bar.py[line:272] - INFO: epoch 005:   1127 / 1732 loss=2.489, loss_v1=0, loss_v2=0, nll_loss=1.302, ntokens=1022.2, nsentences=32, sample_size=1022.2, sample_size_v1=0, sample_size_v2=0, ppl=2.47, wps=265.1, ups=0.26, wpb=1022.2, bsz=32, num_updates=8040, lr=8.99208e-06, gnorm=4.896, clip=100, loss_scale=64, train_wall=39, gb_free=7.9, wall=31038
2023-05-21 02:35:19 - progress_bar.py[line:272] - INFO: epoch 005:   1137 / 1732 loss=2.491, loss_v1=0, loss_v2=0, nll_loss=1.303, ntokens=987.1, nsentences=32, sample_size=987.1, sample_size_v1=0, sample_size_v2=0, ppl=2.47, wps=255.5, ups=0.26, wpb=987.1, bsz=32, num_updates=8050, lr=8.99003e-06, gnorm=5.149, clip=100, loss_scale=64, train_wall=39, gb_free=8, wall=31076
2023-05-21 02:35:58 - progress_bar.py[line:272] - INFO: epoch 005:   1147 / 1732 loss=2.488, loss_v1=0, loss_v2=0, nll_loss=1.302, ntokens=1007.7, nsentences=32, sample_size=1007.7, sample_size_v1=0, sample_size_v2=0, ppl=2.47, wps=261.4, ups=0.26, wpb=1007.7, bsz=32, num_updates=8060, lr=8.98798e-06, gnorm=5.034, clip=100, loss_scale=64, train_wall=39, gb_free=8.4, wall=31115
2023-05-21 02:36:36 - progress_bar.py[line:272] - INFO: epoch 005:   1157 / 1732 loss=2.461, loss_v1=0, loss_v2=0, nll_loss=1.272, ntokens=1000.6, nsentences=32, sample_size=1000.6, sample_size_v1=0, sample_size_v2=0, ppl=2.41, wps=260.3, ups=0.26, wpb=1000.6, bsz=32, num_updates=8070, lr=8.98593e-06, gnorm=5.27, clip=100, loss_scale=64, train_wall=38, gb_free=8.9, wall=31153
2023-05-21 02:37:15 - progress_bar.py[line:272] - INFO: epoch 005:   1167 / 1732 loss=2.478, loss_v1=0, loss_v2=0, nll_loss=1.289, ntokens=1036.7, nsentences=32, sample_size=1036.7, sample_size_v1=0, sample_size_v2=0, ppl=2.44, wps=268, ups=0.26, wpb=1036.7, bsz=32, num_updates=8080, lr=8.98389e-06, gnorm=5.392, clip=100, loss_scale=64, train_wall=39, gb_free=8.6, wall=31192
2023-05-21 02:37:53 - progress_bar.py[line:272] - INFO: epoch 005:   1177 / 1732 loss=2.458, loss_v1=0, loss_v2=0, nll_loss=1.267, ntokens=1069.6, nsentences=32, sample_size=1069.6, sample_size_v1=0, sample_size_v2=0, ppl=2.41, wps=278.1, ups=0.26, wpb=1069.6, bsz=32, num_updates=8090, lr=8.98184e-06, gnorm=4.711, clip=100, loss_scale=64, train_wall=38, gb_free=9, wall=31231
2023-05-21 02:38:32 - progress_bar.py[line:272] - INFO: epoch 005:   1187 / 1732 loss=2.496, loss_v1=0, loss_v2=0, nll_loss=1.309, ntokens=953.6, nsentences=32, sample_size=953.6, sample_size_v1=0, sample_size_v2=0, ppl=2.48, wps=248.9, ups=0.26, wpb=953.6, bsz=32, num_updates=8100, lr=8.97979e-06, gnorm=4.92, clip=100, loss_scale=64, train_wall=38, gb_free=9.2, wall=31269
2023-05-21 02:39:11 - progress_bar.py[line:272] - INFO: epoch 005:   1197 / 1732 loss=2.47, loss_v1=0, loss_v2=0, nll_loss=1.278, ntokens=1116.1, nsentences=32, sample_size=1116.1, sample_size_v1=0, sample_size_v2=0, ppl=2.42, wps=287.7, ups=0.26, wpb=1116.1, bsz=32, num_updates=8110, lr=8.97775e-06, gnorm=5.123, clip=100, loss_scale=64, train_wall=39, gb_free=7.4, wall=31308
2023-05-21 02:39:50 - progress_bar.py[line:272] - INFO: epoch 005:   1207 / 1732 loss=2.445, loss_v1=0, loss_v2=0, nll_loss=1.252, ntokens=1096.1, nsentences=32, sample_size=1096.1, sample_size_v1=0, sample_size_v2=0, ppl=2.38, wps=281.1, ups=0.26, wpb=1096.1, bsz=32, num_updates=8120, lr=8.9757e-06, gnorm=4.392, clip=100, loss_scale=64, train_wall=39, gb_free=8.3, wall=31347
2023-05-21 02:40:28 - progress_bar.py[line:272] - INFO: epoch 005:   1217 / 1732 loss=2.49, loss_v1=0, loss_v2=0, nll_loss=1.301, ntokens=1014.3, nsentences=32, sample_size=1014.3, sample_size_v1=0, sample_size_v2=0, ppl=2.46, wps=262.7, ups=0.26, wpb=1014.3, bsz=32, num_updates=8130, lr=8.97365e-06, gnorm=5.282, clip=100, loss_scale=64, train_wall=39, gb_free=8.7, wall=31385
2023-05-21 02:41:07 - progress_bar.py[line:272] - INFO: epoch 005:   1227 / 1732 loss=2.489, loss_v1=0, loss_v2=0, nll_loss=1.302, ntokens=1027.4, nsentences=32, sample_size=1027.4, sample_size_v1=0, sample_size_v2=0, ppl=2.47, wps=265.7, ups=0.26, wpb=1027.4, bsz=32, num_updates=8140, lr=8.9716e-06, gnorm=5.204, clip=100, loss_scale=64, train_wall=39, gb_free=9.1, wall=31424
2023-05-21 02:41:46 - progress_bar.py[line:272] - INFO: epoch 005:   1237 / 1732 loss=2.447, loss_v1=0, loss_v2=0, nll_loss=1.254, ntokens=1040.4, nsentences=32, sample_size=1040.4, sample_size_v1=0, sample_size_v2=0, ppl=2.38, wps=268.8, ups=0.26, wpb=1040.4, bsz=32, num_updates=8150, lr=8.96956e-06, gnorm=4.881, clip=100, loss_scale=64, train_wall=39, gb_free=8.6, wall=31463
2023-05-21 02:42:25 - progress_bar.py[line:272] - INFO: epoch 005:   1247 / 1732 loss=2.423, loss_v1=0, loss_v2=0, nll_loss=1.228, ntokens=1124.4, nsentences=32, sample_size=1124.4, sample_size_v1=0, sample_size_v2=0, ppl=2.34, wps=288.3, ups=0.26, wpb=1124.4, bsz=32, num_updates=8160, lr=8.96751e-06, gnorm=4.963, clip=100, loss_scale=64, train_wall=39, gb_free=8.7, wall=31502
2023-05-21 02:43:03 - progress_bar.py[line:272] - INFO: epoch 005:   1257 / 1732 loss=2.446, loss_v1=0, loss_v2=0, nll_loss=1.255, ntokens=1053.7, nsentences=32, sample_size=1053.7, sample_size_v1=0, sample_size_v2=0, ppl=2.39, wps=274.4, ups=0.26, wpb=1053.7, bsz=32, num_updates=8170, lr=8.96546e-06, gnorm=4.858, clip=100, loss_scale=64, train_wall=38, gb_free=8.7, wall=31540
2023-05-21 02:43:42 - progress_bar.py[line:272] - INFO: epoch 005:   1267 / 1732 loss=2.482, loss_v1=0, loss_v2=0, nll_loss=1.295, ntokens=1037.3, nsentences=32, sample_size=1037.3, sample_size_v1=0, sample_size_v2=0, ppl=2.45, wps=268, ups=0.26, wpb=1037.3, bsz=32, num_updates=8180, lr=8.96341e-06, gnorm=5.048, clip=100, loss_scale=64, train_wall=39, gb_free=8.6, wall=31579
2023-05-21 02:44:20 - progress_bar.py[line:272] - INFO: epoch 005:   1277 / 1732 loss=2.485, loss_v1=0, loss_v2=0, nll_loss=1.295, ntokens=1060.8, nsentences=32, sample_size=1060.8, sample_size_v1=0, sample_size_v2=0, ppl=2.45, wps=274.6, ups=0.26, wpb=1060.8, bsz=32, num_updates=8190, lr=8.96137e-06, gnorm=5.584, clip=100, loss_scale=64, train_wall=39, gb_free=7.9, wall=31617
2023-05-21 02:44:59 - progress_bar.py[line:272] - INFO: epoch 005:   1287 / 1732 loss=2.464, loss_v1=0, loss_v2=0, nll_loss=1.274, ntokens=1057.7, nsentences=32, sample_size=1057.7, sample_size_v1=0, sample_size_v2=0, ppl=2.42, wps=273.9, ups=0.26, wpb=1057.7, bsz=32, num_updates=8200, lr=8.95932e-06, gnorm=4.514, clip=100, loss_scale=64, train_wall=39, gb_free=8.2, wall=31656
2023-05-21 02:45:38 - progress_bar.py[line:272] - INFO: epoch 005:   1297 / 1732 loss=2.451, loss_v1=0, loss_v2=0, nll_loss=1.258, ntokens=1105.1, nsentences=32, sample_size=1105.1, sample_size_v1=0, sample_size_v2=0, ppl=2.39, wps=285.4, ups=0.26, wpb=1105.1, bsz=32, num_updates=8210, lr=8.95727e-06, gnorm=4.884, clip=100, loss_scale=128, train_wall=39, gb_free=8.7, wall=31695
2023-05-21 02:46:17 - progress_bar.py[line:272] - INFO: epoch 005:   1307 / 1732 loss=2.488, loss_v1=0, loss_v2=0, nll_loss=1.3, ntokens=1096.7, nsentences=32, sample_size=1096.7, sample_size_v1=0, sample_size_v2=0, ppl=2.46, wps=280.1, ups=0.26, wpb=1096.7, bsz=32, num_updates=8220, lr=8.95522e-06, gnorm=4.238, clip=100, loss_scale=128, train_wall=39, gb_free=8.4, wall=31734
2023-05-21 02:46:56 - progress_bar.py[line:272] - INFO: epoch 005:   1317 / 1732 loss=2.476, loss_v1=0, loss_v2=0, nll_loss=1.286, ntokens=1048.7, nsentences=32, sample_size=1048.7, sample_size_v1=0, sample_size_v2=0, ppl=2.44, wps=270.2, ups=0.26, wpb=1048.7, bsz=32, num_updates=8230, lr=8.95318e-06, gnorm=4.9, clip=100, loss_scale=128, train_wall=39, gb_free=8.7, wall=31773
2023-05-21 02:47:35 - progress_bar.py[line:272] - INFO: epoch 005:   1327 / 1732 loss=2.451, loss_v1=0, loss_v2=0, nll_loss=1.259, ntokens=1124.5, nsentences=32, sample_size=1124.5, sample_size_v1=0, sample_size_v2=0, ppl=2.39, wps=287.2, ups=0.26, wpb=1124.5, bsz=32, num_updates=8240, lr=8.95113e-06, gnorm=4.915, clip=100, loss_scale=128, train_wall=39, gb_free=8.4, wall=31812
2023-05-21 02:48:14 - progress_bar.py[line:272] - INFO: epoch 005:   1337 / 1732 loss=2.44, loss_v1=0, loss_v2=0, nll_loss=1.249, ntokens=1126.2, nsentences=32, sample_size=1126.2, sample_size_v1=0, sample_size_v2=0, ppl=2.38, wps=289.2, ups=0.26, wpb=1126.2, bsz=32, num_updates=8250, lr=8.94908e-06, gnorm=4.777, clip=100, loss_scale=128, train_wall=39, gb_free=8.6, wall=31851
2023-05-21 02:48:53 - progress_bar.py[line:272] - INFO: epoch 005:   1347 / 1732 loss=2.464, loss_v1=0, loss_v2=0, nll_loss=1.273, ntokens=1159.1, nsentences=32, sample_size=1159.1, sample_size_v1=0, sample_size_v2=0, ppl=2.42, wps=296.8, ups=0.26, wpb=1159.1, bsz=32, num_updates=8260, lr=8.94703e-06, gnorm=5.033, clip=100, loss_scale=128, train_wall=39, gb_free=8.9, wall=31890
2023-05-21 02:49:32 - progress_bar.py[line:272] - INFO: epoch 005:   1357 / 1732 loss=2.439, loss_v1=0, loss_v2=0, nll_loss=1.246, ntokens=1146.3, nsentences=32, sample_size=1146.3, sample_size_v1=0, sample_size_v2=0, ppl=2.37, wps=293.5, ups=0.26, wpb=1146.3, bsz=32, num_updates=8270, lr=8.94499e-06, gnorm=4.409, clip=100, loss_scale=128, train_wall=39, gb_free=8, wall=31929
2023-05-21 02:50:11 - progress_bar.py[line:272] - INFO: epoch 005:   1367 / 1732 loss=2.467, loss_v1=0, loss_v2=0, nll_loss=1.277, ntokens=1081.6, nsentences=32, sample_size=1081.6, sample_size_v1=0, sample_size_v2=0, ppl=2.42, wps=278.6, ups=0.26, wpb=1081.6, bsz=32, num_updates=8280, lr=8.94294e-06, gnorm=4.926, clip=100, loss_scale=128, train_wall=39, gb_free=8.5, wall=31968
2023-05-21 02:50:49 - progress_bar.py[line:272] - INFO: epoch 005:   1377 / 1732 loss=2.491, loss_v1=0, loss_v2=0, nll_loss=1.305, ntokens=1107.3, nsentences=32, sample_size=1107.3, sample_size_v1=0, sample_size_v2=0, ppl=2.47, wps=286.9, ups=0.26, wpb=1107.3, bsz=32, num_updates=8290, lr=8.94089e-06, gnorm=5.063, clip=100, loss_scale=128, train_wall=39, gb_free=8.7, wall=32006
2023-05-21 02:51:12 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2023-05-21 02:51:32 - progress_bar.py[line:272] - INFO: epoch 005:   1388 / 1732 loss=2.472, loss_v1=0, loss_v2=0, nll_loss=1.283, ntokens=1126.9, nsentences=32, sample_size=1126.9, sample_size_v1=0, sample_size_v2=0, ppl=2.43, wps=264.9, ups=0.24, wpb=1126.9, bsz=32, num_updates=8300, lr=8.93884e-06, gnorm=4.985, clip=100, loss_scale=64, train_wall=42, gb_free=8.7, wall=32049
2023-05-21 02:52:11 - progress_bar.py[line:272] - INFO: epoch 005:   1398 / 1732 loss=2.441, loss_v1=0, loss_v2=0, nll_loss=1.249, ntokens=1097.3, nsentences=32, sample_size=1097.3, sample_size_v1=0, sample_size_v2=0, ppl=2.38, wps=281.7, ups=0.26, wpb=1097.3, bsz=32, num_updates=8310, lr=8.9368e-06, gnorm=4.798, clip=100, loss_scale=64, train_wall=39, gb_free=8.6, wall=32088
2023-05-21 02:52:50 - progress_bar.py[line:272] - INFO: epoch 005:   1408 / 1732 loss=2.475, loss_v1=0, loss_v2=0, nll_loss=1.284, ntokens=1161.5, nsentences=32, sample_size=1161.5, sample_size_v1=0, sample_size_v2=0, ppl=2.44, wps=299.2, ups=0.26, wpb=1161.5, bsz=32, num_updates=8320, lr=8.93475e-06, gnorm=5.026, clip=100, loss_scale=64, train_wall=39, gb_free=8.4, wall=32127
2023-05-21 02:53:29 - progress_bar.py[line:272] - INFO: epoch 005:   1418 / 1732 loss=2.478, loss_v1=0, loss_v2=0, nll_loss=1.29, ntokens=1285.2, nsentences=32, sample_size=1285.2, sample_size_v1=0, sample_size_v2=0, ppl=2.44, wps=326.7, ups=0.25, wpb=1285.2, bsz=32, num_updates=8330, lr=8.9327e-06, gnorm=4.591, clip=100, loss_scale=64, train_wall=39, gb_free=7.8, wall=32166
2023-05-21 02:54:08 - progress_bar.py[line:272] - INFO: epoch 005:   1428 / 1732 loss=2.446, loss_v1=0, loss_v2=0, nll_loss=1.255, ntokens=1229.6, nsentences=32, sample_size=1229.6, sample_size_v1=0, sample_size_v2=0, ppl=2.39, wps=313.7, ups=0.26, wpb=1229.6, bsz=32, num_updates=8340, lr=8.93066e-06, gnorm=4.45, clip=100, loss_scale=64, train_wall=39, gb_free=8.5, wall=32205
2023-05-21 02:54:47 - progress_bar.py[line:272] - INFO: epoch 005:   1438 / 1732 loss=2.445, loss_v1=0, loss_v2=0, nll_loss=1.253, ntokens=1179.5, nsentences=32, sample_size=1179.5, sample_size_v1=0, sample_size_v2=0, ppl=2.38, wps=303, ups=0.26, wpb=1179.5, bsz=32, num_updates=8350, lr=8.92861e-06, gnorm=4.385, clip=100, loss_scale=64, train_wall=39, gb_free=8.8, wall=32244
2023-05-21 02:55:26 - progress_bar.py[line:272] - INFO: epoch 005:   1448 / 1732 loss=2.486, loss_v1=0, loss_v2=0, nll_loss=1.298, ntokens=1120.7, nsentences=32, sample_size=1120.7, sample_size_v1=0, sample_size_v2=0, ppl=2.46, wps=290.1, ups=0.26, wpb=1120.7, bsz=32, num_updates=8360, lr=8.92656e-06, gnorm=5.261, clip=100, loss_scale=64, train_wall=39, gb_free=8.8, wall=32283
2023-05-21 02:56:05 - progress_bar.py[line:272] - INFO: epoch 005:   1458 / 1732 loss=2.449, loss_v1=0, loss_v2=0, nll_loss=1.254, ntokens=1151.7, nsentences=32, sample_size=1151.7, sample_size_v1=0, sample_size_v2=0, ppl=2.39, wps=295.6, ups=0.26, wpb=1151.7, bsz=32, num_updates=8370, lr=8.92451e-06, gnorm=4.606, clip=100, loss_scale=64, train_wall=39, gb_free=7.9, wall=32322
2023-05-21 02:56:44 - progress_bar.py[line:272] - INFO: epoch 005:   1468 / 1732 loss=2.437, loss_v1=0, loss_v2=0, nll_loss=1.244, ntokens=1195.8, nsentences=32, sample_size=1195.8, sample_size_v1=0, sample_size_v2=0, ppl=2.37, wps=307.5, ups=0.26, wpb=1195.8, bsz=32, num_updates=8380, lr=8.92247e-06, gnorm=4.813, clip=100, loss_scale=64, train_wall=39, gb_free=7.7, wall=32361
2023-05-21 02:57:22 - progress_bar.py[line:272] - INFO: epoch 005:   1478 / 1732 loss=2.492, loss_v1=0, loss_v2=0, nll_loss=1.307, ntokens=1019.5, nsentences=32, sample_size=1019.5, sample_size_v1=0, sample_size_v2=0, ppl=2.47, wps=264.4, ups=0.26, wpb=1019.5, bsz=32, num_updates=8390, lr=8.92042e-06, gnorm=5.592, clip=100, loss_scale=64, train_wall=39, gb_free=8.5, wall=32399
2023-05-21 02:58:01 - progress_bar.py[line:272] - INFO: epoch 005:   1488 / 1732 loss=2.468, loss_v1=0, loss_v2=0, nll_loss=1.276, ntokens=1151.5, nsentences=32, sample_size=1151.5, sample_size_v1=0, sample_size_v2=0, ppl=2.42, wps=295.5, ups=0.26, wpb=1151.5, bsz=32, num_updates=8400, lr=8.91837e-06, gnorm=4.322, clip=100, loss_scale=64, train_wall=39, gb_free=7.8, wall=32438
2023-05-21 02:58:40 - progress_bar.py[line:272] - INFO: epoch 005:   1498 / 1732 loss=2.448, loss_v1=0, loss_v2=0, nll_loss=1.255, ntokens=1078, nsentences=32, sample_size=1078, sample_size_v1=0, sample_size_v2=0, ppl=2.39, wps=277.9, ups=0.26, wpb=1078, bsz=32, num_updates=8410, lr=8.91632e-06, gnorm=4.488, clip=100, loss_scale=64, train_wall=39, gb_free=8.6, wall=32477
2023-05-21 02:59:19 - progress_bar.py[line:272] - INFO: epoch 005:   1508 / 1732 loss=2.414, loss_v1=0, loss_v2=0, nll_loss=1.22, ntokens=1107.9, nsentences=32, sample_size=1107.9, sample_size_v1=0, sample_size_v2=0, ppl=2.33, wps=285.1, ups=0.26, wpb=1107.9, bsz=32, num_updates=8420, lr=8.91428e-06, gnorm=4.899, clip=100, loss_scale=64, train_wall=39, gb_free=8.5, wall=32516
2023-05-21 02:59:57 - progress_bar.py[line:272] - INFO: epoch 005:   1518 / 1732 loss=2.476, loss_v1=0, loss_v2=0, nll_loss=1.29, ntokens=1079, nsentences=32, sample_size=1079, sample_size_v1=0, sample_size_v2=0, ppl=2.44, wps=279.1, ups=0.26, wpb=1079, bsz=32, num_updates=8430, lr=8.91223e-06, gnorm=4.441, clip=100, loss_scale=64, train_wall=39, gb_free=8.6, wall=32555
2023-05-21 03:00:36 - progress_bar.py[line:272] - INFO: epoch 005:   1528 / 1732 loss=2.51, loss_v1=0, loss_v2=0, nll_loss=1.322, ntokens=1041.5, nsentences=32, sample_size=1041.5, sample_size_v1=0, sample_size_v2=0, ppl=2.5, wps=270.8, ups=0.26, wpb=1041.5, bsz=32, num_updates=8440, lr=8.91018e-06, gnorm=5.182, clip=100, loss_scale=64, train_wall=38, gb_free=8.8, wall=32593
2023-05-21 03:01:15 - progress_bar.py[line:272] - INFO: epoch 005:   1538 / 1732 loss=2.457, loss_v1=0, loss_v2=0, nll_loss=1.264, ntokens=1094, nsentences=32, sample_size=1094, sample_size_v1=0, sample_size_v2=0, ppl=2.4, wps=281.5, ups=0.26, wpb=1094, bsz=32, num_updates=8450, lr=8.90813e-06, gnorm=5.122, clip=100, loss_scale=64, train_wall=39, gb_free=8.1, wall=32632
2023-05-21 03:01:53 - progress_bar.py[line:272] - INFO: epoch 005:   1548 / 1732 loss=2.445, loss_v1=0, loss_v2=0, nll_loss=1.254, ntokens=1084.2, nsentences=32, sample_size=1084.2, sample_size_v1=0, sample_size_v2=0, ppl=2.38, wps=280, ups=0.26, wpb=1084.2, bsz=32, num_updates=8460, lr=8.90609e-06, gnorm=5.034, clip=100, loss_scale=64, train_wall=39, gb_free=8.2, wall=32671
2023-05-21 03:02:32 - progress_bar.py[line:272] - INFO: epoch 005:   1558 / 1732 loss=2.449, loss_v1=0, loss_v2=0, nll_loss=1.257, ntokens=1077.4, nsentences=32, sample_size=1077.4, sample_size_v1=0, sample_size_v2=0, ppl=2.39, wps=277.8, ups=0.26, wpb=1077.4, bsz=32, num_updates=8470, lr=8.90404e-06, gnorm=4.641, clip=100, loss_scale=64, train_wall=39, gb_free=8, wall=32709
2023-05-21 03:03:11 - progress_bar.py[line:272] - INFO: epoch 005:   1568 / 1732 loss=2.514, loss_v1=0, loss_v2=0, nll_loss=1.33, ntokens=1072.3, nsentences=32, sample_size=1072.3, sample_size_v1=0, sample_size_v2=0, ppl=2.51, wps=275.3, ups=0.26, wpb=1072.3, bsz=32, num_updates=8480, lr=8.90199e-06, gnorm=5.118, clip=100, loss_scale=64, train_wall=39, gb_free=7.6, wall=32748
2023-05-21 03:03:50 - progress_bar.py[line:272] - INFO: epoch 005:   1578 / 1732 loss=2.497, loss_v1=0, loss_v2=0, nll_loss=1.31, ntokens=1004.7, nsentences=32, sample_size=1004.7, sample_size_v1=0, sample_size_v2=0, ppl=2.48, wps=260.3, ups=0.26, wpb=1004.7, bsz=32, num_updates=8490, lr=8.89994e-06, gnorm=5.791, clip=100, loss_scale=64, train_wall=39, gb_free=8.3, wall=32787
2023-05-21 03:04:29 - progress_bar.py[line:272] - INFO: epoch 005:   1588 / 1732 loss=2.467, loss_v1=0, loss_v2=0, nll_loss=1.275, ntokens=1078.3, nsentences=32, sample_size=1078.3, sample_size_v1=0, sample_size_v2=0, ppl=2.42, wps=277.9, ups=0.26, wpb=1078.3, bsz=32, num_updates=8500, lr=8.8979e-06, gnorm=5.411, clip=100, loss_scale=64, train_wall=39, gb_free=8.3, wall=32826
2023-05-21 03:05:07 - progress_bar.py[line:272] - INFO: epoch 005:   1598 / 1732 loss=2.452, loss_v1=0, loss_v2=0, nll_loss=1.26, ntokens=1079.8, nsentences=32, sample_size=1079.8, sample_size_v1=0, sample_size_v2=0, ppl=2.4, wps=279.9, ups=0.26, wpb=1079.8, bsz=32, num_updates=8510, lr=8.89585e-06, gnorm=5.068, clip=100, loss_scale=64, train_wall=39, gb_free=8.8, wall=32864
2023-05-21 03:05:46 - progress_bar.py[line:272] - INFO: epoch 005:   1608 / 1732 loss=2.445, loss_v1=0, loss_v2=0, nll_loss=1.255, ntokens=1140.6, nsentences=32, sample_size=1140.6, sample_size_v1=0, sample_size_v2=0, ppl=2.39, wps=293.4, ups=0.26, wpb=1140.6, bsz=32, num_updates=8520, lr=8.8938e-06, gnorm=4.98, clip=100, loss_scale=64, train_wall=39, gb_free=8.2, wall=32903
2023-05-21 03:06:25 - progress_bar.py[line:272] - INFO: epoch 005:   1618 / 1732 loss=2.417, loss_v1=0, loss_v2=0, nll_loss=1.221, ntokens=1124.7, nsentences=32, sample_size=1124.7, sample_size_v1=0, sample_size_v2=0, ppl=2.33, wps=289, ups=0.26, wpb=1124.7, bsz=32, num_updates=8530, lr=8.89176e-06, gnorm=5.345, clip=100, loss_scale=64, train_wall=39, gb_free=8.2, wall=32942
2023-05-21 03:07:04 - progress_bar.py[line:272] - INFO: epoch 005:   1628 / 1732 loss=2.454, loss_v1=0, loss_v2=0, nll_loss=1.263, ntokens=1158.7, nsentences=32, sample_size=1158.7, sample_size_v1=0, sample_size_v2=0, ppl=2.4, wps=296.2, ups=0.26, wpb=1158.7, bsz=32, num_updates=8540, lr=8.88971e-06, gnorm=4.565, clip=100, loss_scale=64, train_wall=39, gb_free=7.7, wall=32981
2023-05-21 03:07:43 - progress_bar.py[line:272] - INFO: epoch 005:   1638 / 1732 loss=2.43, loss_v1=0, loss_v2=0, nll_loss=1.233, ntokens=1131.3, nsentences=32, sample_size=1131.3, sample_size_v1=0, sample_size_v2=0, ppl=2.35, wps=293, ups=0.26, wpb=1131.3, bsz=32, num_updates=8550, lr=8.88766e-06, gnorm=4.667, clip=100, loss_scale=64, train_wall=39, gb_free=8.1, wall=33020
2023-05-21 03:08:22 - progress_bar.py[line:272] - INFO: epoch 005:   1648 / 1732 loss=2.419, loss_v1=0, loss_v2=0, nll_loss=1.223, ntokens=1231.9, nsentences=32, sample_size=1231.9, sample_size_v1=0, sample_size_v2=0, ppl=2.33, wps=314.2, ups=0.26, wpb=1231.9, bsz=32, num_updates=8560, lr=8.88561e-06, gnorm=4.537, clip=100, loss_scale=64, train_wall=39, gb_free=9, wall=33059
2023-05-21 03:09:00 - progress_bar.py[line:272] - INFO: epoch 005:   1658 / 1732 loss=2.486, loss_v1=0, loss_v2=0, nll_loss=1.3, ntokens=971, nsentences=32, sample_size=971, sample_size_v1=0, sample_size_v2=0, ppl=2.46, wps=253.4, ups=0.26, wpb=971, bsz=32, num_updates=8570, lr=8.88357e-06, gnorm=5.408, clip=100, loss_scale=64, train_wall=38, gb_free=8.5, wall=33097
2023-05-21 03:09:39 - progress_bar.py[line:272] - INFO: epoch 005:   1668 / 1732 loss=2.458, loss_v1=0, loss_v2=0, nll_loss=1.267, ntokens=1011.3, nsentences=32, sample_size=1011.3, sample_size_v1=0, sample_size_v2=0, ppl=2.41, wps=261.4, ups=0.26, wpb=1011.3, bsz=32, num_updates=8580, lr=8.88152e-06, gnorm=5.038, clip=100, loss_scale=64, train_wall=39, gb_free=8.8, wall=33136
2023-05-21 03:10:18 - progress_bar.py[line:272] - INFO: epoch 005:   1678 / 1732 loss=2.414, loss_v1=0, loss_v2=0, nll_loss=1.216, ntokens=1161.5, nsentences=32, sample_size=1161.5, sample_size_v1=0, sample_size_v2=0, ppl=2.32, wps=298.3, ups=0.26, wpb=1161.5, bsz=32, num_updates=8590, lr=8.87947e-06, gnorm=4.152, clip=100, loss_scale=64, train_wall=39, gb_free=7.9, wall=33175
2023-05-21 03:10:57 - progress_bar.py[line:272] - INFO: epoch 005:   1688 / 1732 loss=2.447, loss_v1=0, loss_v2=0, nll_loss=1.256, ntokens=1174.7, nsentences=32, sample_size=1174.7, sample_size_v1=0, sample_size_v2=0, ppl=2.39, wps=301.1, ups=0.26, wpb=1174.7, bsz=32, num_updates=8600, lr=8.87742e-06, gnorm=4.482, clip=100, loss_scale=64, train_wall=39, gb_free=7, wall=33214
2023-05-21 03:11:37 - progress_bar.py[line:272] - INFO: epoch 005:   1698 / 1732 loss=2.433, loss_v1=0, loss_v2=0, nll_loss=1.24, ntokens=1304.9, nsentences=32, sample_size=1304.9, sample_size_v1=0, sample_size_v2=0, ppl=2.36, wps=326.7, ups=0.25, wpb=1304.9, bsz=32, num_updates=8610, lr=8.87538e-06, gnorm=4.689, clip=100, loss_scale=64, train_wall=40, gb_free=8.3, wall=33254
2023-05-21 03:12:16 - progress_bar.py[line:272] - INFO: epoch 005:   1708 / 1732 loss=2.452, loss_v1=0, loss_v2=0, nll_loss=1.259, ntokens=1174.9, nsentences=32, sample_size=1174.9, sample_size_v1=0, sample_size_v2=0, ppl=2.39, wps=300.3, ups=0.26, wpb=1174.9, bsz=32, num_updates=8620, lr=8.87333e-06, gnorm=4.809, clip=100, loss_scale=64, train_wall=39, gb_free=8.1, wall=33293
2023-05-21 03:12:55 - progress_bar.py[line:272] - INFO: epoch 005:   1718 / 1732 loss=2.43, loss_v1=0, loss_v2=0, nll_loss=1.235, ntokens=1181.2, nsentences=32, sample_size=1181.2, sample_size_v1=0, sample_size_v2=0, ppl=2.35, wps=302.1, ups=0.26, wpb=1181.2, bsz=32, num_updates=8630, lr=8.87128e-06, gnorm=4.503, clip=100, loss_scale=64, train_wall=39, gb_free=8.2, wall=33332
2023-05-21 03:13:34 - progress_bar.py[line:272] - INFO: epoch 005:   1728 / 1732 loss=2.495, loss_v1=0, loss_v2=0, nll_loss=1.308, ntokens=1093.2, nsentences=32, sample_size=1093.2, sample_size_v1=0, sample_size_v2=0, ppl=2.48, wps=281, ups=0.26, wpb=1093.2, bsz=32, num_updates=8640, lr=8.86923e-06, gnorm=4.585, clip=100, loss_scale=64, train_wall=39, gb_free=8.1, wall=33371
2023-05-21 03:13:47 - train.py[line:332] - INFO: end of epoch 5 (average epoch stats below)
2023-05-21 03:13:47 - progress_bar.py[line:282] - INFO: epoch 005 | loss 2.47 | loss_v1 0 | loss_v2 0 | nll_loss 1.28 | ntokens 1051.55 | nsentences 31.986 | sample_size 1051.55 | sample_size_v1 0 | sample_size_v2 0 | ppl 2.43 | wps 272.2 | ups 0.26 | wpb 1051.5 | bsz 32 | num_updates 8644 | lr 8.86842e-06 | gnorm 4.406 | clip 100 | loss_scale 64 | train_wall 6664 | gb_free 8.9 | wall 33384
2023-05-21 03:13:47 - trainer.py[line:639] - INFO: loading train data for epoch 6
local datafile ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 0 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 0 finished initializing row_count and line_idx-to-offset mapping
file ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 0 row count 55400 total row count 55400
slice_id 0 seek offset 0
2023-05-21 03:13:48 - trainer.py[line:703] - INFO: begin training epoch 6
2023-05-21 03:13:48 - train.py[line:305] - INFO: Start iterating over samples
2023-05-21 03:14:12 - progress_bar.py[line:272] - INFO: epoch 006:      6 / 1732 loss=2.422, loss_v1=0, loss_v2=0, nll_loss=1.223, ntokens=1082.4, nsentences=29.6, sample_size=1082.4, sample_size_v1=0, sample_size_v2=0, ppl=2.33, wps=283.9, ups=0.26, wpb=1082.4, bsz=29.6, num_updates=8650, lr=8.86719e-06, gnorm=5.046, clip=100, loss_scale=64, train_wall=36, gb_free=8.4, wall=33409
2023-05-21 03:14:51 - progress_bar.py[line:272] - INFO: epoch 006:     16 / 1732 loss=2.383, loss_v1=0, loss_v2=0, nll_loss=1.183, ntokens=1099.3, nsentences=32, sample_size=1099.3, sample_size_v1=0, sample_size_v2=0, ppl=2.27, wps=284.8, ups=0.26, wpb=1099.3, bsz=32, num_updates=8660, lr=8.86514e-06, gnorm=4.478, clip=100, loss_scale=64, train_wall=39, gb_free=8.3, wall=33448
2023-05-21 03:15:29 - progress_bar.py[line:272] - INFO: epoch 006:     26 / 1732 loss=2.39, loss_v1=0, loss_v2=0, nll_loss=1.19, ntokens=973, nsentences=32, sample_size=973, sample_size_v1=0, sample_size_v2=0, ppl=2.28, wps=251.6, ups=0.26, wpb=973, bsz=32, num_updates=8670, lr=8.86309e-06, gnorm=5.47, clip=100, loss_scale=64, train_wall=39, gb_free=8.6, wall=33487
2023-05-21 03:16:08 - progress_bar.py[line:272] - INFO: epoch 006:     36 / 1732 loss=2.264, loss_v1=0, loss_v2=0, nll_loss=1.047, ntokens=1153.4, nsentences=32, sample_size=1153.4, sample_size_v1=0, sample_size_v2=0, ppl=2.07, wps=294.5, ups=0.26, wpb=1153.4, bsz=32, num_updates=8680, lr=8.86104e-06, gnorm=4.594, clip=100, loss_scale=64, train_wall=39, gb_free=7.4, wall=33526
2023-05-21 03:16:47 - progress_bar.py[line:272] - INFO: epoch 006:     46 / 1732 loss=2.278, loss_v1=0, loss_v2=0, nll_loss=1.071, ntokens=1066.8, nsentences=32, sample_size=1066.8, sample_size_v1=0, sample_size_v2=0, ppl=2.1, wps=276.5, ups=0.26, wpb=1066.8, bsz=32, num_updates=8690, lr=8.859e-06, gnorm=4.623, clip=100, loss_scale=64, train_wall=39, gb_free=8.8, wall=33564
2023-05-21 03:17:26 - progress_bar.py[line:272] - INFO: epoch 006:     56 / 1732 loss=2.205, loss_v1=0, loss_v2=0, nll_loss=0.978, ntokens=1077, nsentences=32, sample_size=1077, sample_size_v1=0, sample_size_v2=0, ppl=1.97, wps=277.5, ups=0.26, wpb=1077, bsz=32, num_updates=8700, lr=8.85695e-06, gnorm=4.038, clip=100, loss_scale=64, train_wall=39, gb_free=8.7, wall=33603
2023-05-21 03:18:06 - progress_bar.py[line:272] - INFO: epoch 006:     66 / 1732 loss=2.084, loss_v1=0, loss_v2=0, nll_loss=0.851, ntokens=1294.5, nsentences=32, sample_size=1294.5, sample_size_v1=0, sample_size_v2=0, ppl=1.8, wps=326.5, ups=0.25, wpb=1294.5, bsz=32, num_updates=8710, lr=8.8549e-06, gnorm=3.409, clip=100, loss_scale=64, train_wall=40, gb_free=7.5, wall=33643
2023-05-21 03:18:45 - progress_bar.py[line:272] - INFO: epoch 006:     76 / 1732 loss=2.223, loss_v1=0, loss_v2=0, nll_loss=0.999, ntokens=1343.5, nsentences=32, sample_size=1343.5, sample_size_v1=0, sample_size_v2=0, ppl=2, wps=336.5, ups=0.25, wpb=1343.5, bsz=32, num_updates=8720, lr=8.85286e-06, gnorm=4.07, clip=100, loss_scale=64, train_wall=40, gb_free=7.1, wall=33683
2023-05-21 03:19:25 - progress_bar.py[line:272] - INFO: epoch 006:     86 / 1732 loss=2.307, loss_v1=0, loss_v2=0, nll_loss=1.102, ntokens=1107.4, nsentences=32, sample_size=1107.4, sample_size_v1=0, sample_size_v2=0, ppl=2.15, wps=282.8, ups=0.26, wpb=1107.4, bsz=32, num_updates=8730, lr=8.85081e-06, gnorm=3.825, clip=100, loss_scale=64, train_wall=39, gb_free=7.9, wall=33722
2023-05-21 03:20:04 - progress_bar.py[line:272] - INFO: epoch 006:     96 / 1732 loss=2.25, loss_v1=0, loss_v2=0, nll_loss=1.031, ntokens=1069.5, nsentences=32, sample_size=1069.5, sample_size_v1=0, sample_size_v2=0, ppl=2.04, wps=273.7, ups=0.26, wpb=1069.5, bsz=32, num_updates=8740, lr=8.84876e-06, gnorm=3.467, clip=100, loss_scale=64, train_wall=39, gb_free=7.5, wall=33761
2023-05-21 03:20:42 - progress_bar.py[line:272] - INFO: epoch 006:    106 / 1732 loss=2.429, loss_v1=0, loss_v2=0, nll_loss=1.241, ntokens=998.2, nsentences=32, sample_size=998.2, sample_size_v1=0, sample_size_v2=0, ppl=2.36, wps=260, ups=0.26, wpb=998.2, bsz=32, num_updates=8750, lr=8.84671e-06, gnorm=4.038, clip=100, loss_scale=64, train_wall=38, gb_free=7.3, wall=33799
2023-05-21 03:21:21 - progress_bar.py[line:272] - INFO: epoch 006:    116 / 1732 loss=2.47, loss_v1=0, loss_v2=0, nll_loss=1.28, ntokens=1049.3, nsentences=32, sample_size=1049.3, sample_size_v1=0, sample_size_v2=0, ppl=2.43, wps=270.1, ups=0.26, wpb=1049.3, bsz=32, num_updates=8760, lr=8.84467e-06, gnorm=3.903, clip=100, loss_scale=64, train_wall=39, gb_free=7.6, wall=33838
2023-05-21 03:22:01 - progress_bar.py[line:272] - INFO: epoch 006:    126 / 1732 loss=2.396, loss_v1=0, loss_v2=0, nll_loss=1.193, ntokens=1187.5, nsentences=32, sample_size=1187.5, sample_size_v1=0, sample_size_v2=0, ppl=2.29, wps=300.1, ups=0.25, wpb=1187.5, bsz=32, num_updates=8770, lr=8.84262e-06, gnorm=3.698, clip=100, loss_scale=64, train_wall=40, gb_free=8.4, wall=33878
2023-05-21 03:22:40 - progress_bar.py[line:272] - INFO: epoch 006:    136 / 1732 loss=2.384, loss_v1=0, loss_v2=0, nll_loss=1.184, ntokens=1228, nsentences=32, sample_size=1228, sample_size_v1=0, sample_size_v2=0, ppl=2.27, wps=312.3, ups=0.25, wpb=1228, bsz=32, num_updates=8780, lr=8.84057e-06, gnorm=3.626, clip=100, loss_scale=64, train_wall=39, gb_free=7.4, wall=33917
2023-05-21 03:23:19 - progress_bar.py[line:272] - INFO: epoch 006:    146 / 1732 loss=2.338, loss_v1=0, loss_v2=0, nll_loss=1.132, ntokens=1192.9, nsentences=32, sample_size=1192.9, sample_size_v1=0, sample_size_v2=0, ppl=2.19, wps=301.5, ups=0.25, wpb=1192.9, bsz=32, num_updates=8790, lr=8.83852e-06, gnorm=3.333, clip=100, loss_scale=64, train_wall=40, gb_free=7.7, wall=33957
2023-05-21 03:23:59 - progress_bar.py[line:272] - INFO: epoch 006:    156 / 1732 loss=2.389, loss_v1=0, loss_v2=0, nll_loss=1.189, ntokens=1174.3, nsentences=32, sample_size=1174.3, sample_size_v1=0, sample_size_v2=0, ppl=2.28, wps=296.5, ups=0.25, wpb=1174.3, bsz=32, num_updates=8800, lr=8.83648e-06, gnorm=3.652, clip=100, loss_scale=64, train_wall=40, gb_free=8, wall=33996
2023-05-21 03:24:38 - progress_bar.py[line:272] - INFO: epoch 006:    166 / 1732 loss=2.338, loss_v1=0, loss_v2=0, nll_loss=1.131, ntokens=1039.2, nsentences=32, sample_size=1039.2, sample_size_v1=0, sample_size_v2=0, ppl=2.19, wps=268, ups=0.26, wpb=1039.2, bsz=32, num_updates=8810, lr=8.83443e-06, gnorm=3.838, clip=100, loss_scale=128, train_wall=39, gb_free=7.4, wall=34035
2023-05-21 03:25:17 - progress_bar.py[line:272] - INFO: epoch 006:    176 / 1732 loss=2.364, loss_v1=0, loss_v2=0, nll_loss=1.161, ntokens=982.6, nsentences=32, sample_size=982.6, sample_size_v1=0, sample_size_v2=0, ppl=2.24, wps=253.8, ups=0.26, wpb=982.6, bsz=32, num_updates=8820, lr=8.83238e-06, gnorm=4.546, clip=100, loss_scale=128, train_wall=39, gb_free=7.9, wall=34074
2023-05-21 03:25:56 - progress_bar.py[line:272] - INFO: epoch 006:    186 / 1732 loss=2.309, loss_v1=0, loss_v2=0, nll_loss=1.1, ntokens=1142, nsentences=32, sample_size=1142, sample_size_v1=0, sample_size_v2=0, ppl=2.14, wps=290.6, ups=0.25, wpb=1142, bsz=32, num_updates=8830, lr=8.83033e-06, gnorm=4.156, clip=100, loss_scale=128, train_wall=39, gb_free=8.2, wall=34113
2023-05-21 03:26:35 - progress_bar.py[line:272] - INFO: epoch 006:    196 / 1732 loss=2.372, loss_v1=0, loss_v2=0, nll_loss=1.173, ntokens=1152.2, nsentences=32, sample_size=1152.2, sample_size_v1=0, sample_size_v2=0, ppl=2.26, wps=293, ups=0.25, wpb=1152.2, bsz=32, num_updates=8840, lr=8.82829e-06, gnorm=4.101, clip=100, loss_scale=128, train_wall=39, gb_free=8.2, wall=34152
2023-05-21 03:27:13 - progress_bar.py[line:272] - INFO: epoch 006:    206 / 1732 loss=2.471, loss_v1=0, loss_v2=0, nll_loss=1.281, ntokens=995.3, nsentences=32, sample_size=995.3, sample_size_v1=0, sample_size_v2=0, ppl=2.43, wps=259.6, ups=0.26, wpb=995.3, bsz=32, num_updates=8850, lr=8.82624e-06, gnorm=4.874, clip=100, loss_scale=128, train_wall=38, gb_free=8.5, wall=34191
2023-05-21 03:27:52 - progress_bar.py[line:272] - INFO: epoch 006:    216 / 1732 loss=2.499, loss_v1=0, loss_v2=0, nll_loss=1.313, ntokens=1119.9, nsentences=32, sample_size=1119.9, sample_size_v1=0, sample_size_v2=0, ppl=2.49, wps=290.9, ups=0.26, wpb=1119.9, bsz=32, num_updates=8860, lr=8.82419e-06, gnorm=4.542, clip=100, loss_scale=128, train_wall=38, gb_free=8.9, wall=34229
2023-05-21 03:28:30 - progress_bar.py[line:272] - INFO: epoch 006:    226 / 1732 loss=2.481, loss_v1=0, loss_v2=0, nll_loss=1.291, ntokens=1111.6, nsentences=32, sample_size=1111.6, sample_size_v1=0, sample_size_v2=0, ppl=2.45, wps=289.1, ups=0.26, wpb=1111.6, bsz=32, num_updates=8870, lr=8.82214e-06, gnorm=4.57, clip=100, loss_scale=128, train_wall=38, gb_free=8.7, wall=34268
2023-05-21 03:28:53 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2023-05-21 03:29:12 - progress_bar.py[line:272] - INFO: epoch 006:    237 / 1732 loss=2.54, loss_v1=0, loss_v2=0, nll_loss=1.356, ntokens=1058, nsentences=32, sample_size=1058, sample_size_v1=0, sample_size_v2=0, ppl=2.56, wps=251.8, ups=0.24, wpb=1058, bsz=32, num_updates=8880, lr=8.8201e-06, gnorm=4.9, clip=100, loss_scale=64, train_wall=42, gb_free=7.8, wall=34310
2023-05-21 03:29:51 - progress_bar.py[line:272] - INFO: epoch 006:    247 / 1732 loss=2.507, loss_v1=0, loss_v2=0, nll_loss=1.319, ntokens=1188.4, nsentences=32, sample_size=1188.4, sample_size_v1=0, sample_size_v2=0, ppl=2.49, wps=305.9, ups=0.26, wpb=1188.4, bsz=32, num_updates=8890, lr=8.81805e-06, gnorm=4.162, clip=100, loss_scale=64, train_wall=39, gb_free=8.1, wall=34349
2023-05-21 03:30:30 - progress_bar.py[line:272] - INFO: epoch 006:    257 / 1732 loss=2.508, loss_v1=0, loss_v2=0, nll_loss=1.325, ntokens=1118.5, nsentences=32, sample_size=1118.5, sample_size_v1=0, sample_size_v2=0, ppl=2.5, wps=291.2, ups=0.26, wpb=1118.5, bsz=32, num_updates=8900, lr=8.816e-06, gnorm=5.04, clip=100, loss_scale=64, train_wall=38, gb_free=8.4, wall=34387
2023-05-21 03:31:08 - progress_bar.py[line:272] - INFO: epoch 006:    267 / 1732 loss=2.498, loss_v1=0, loss_v2=0, nll_loss=1.309, ntokens=1162.2, nsentences=32, sample_size=1162.2, sample_size_v1=0, sample_size_v2=0, ppl=2.48, wps=302.5, ups=0.26, wpb=1162.2, bsz=32, num_updates=8910, lr=8.81395e-06, gnorm=4.578, clip=100, loss_scale=64, train_wall=38, gb_free=8.4, wall=34425
2023-05-21 03:31:47 - progress_bar.py[line:272] - INFO: epoch 006:    277 / 1732 loss=2.502, loss_v1=0, loss_v2=0, nll_loss=1.314, ntokens=1137.3, nsentences=32, sample_size=1137.3, sample_size_v1=0, sample_size_v2=0, ppl=2.49, wps=295.1, ups=0.26, wpb=1137.3, bsz=32, num_updates=8920, lr=8.81191e-06, gnorm=4.641, clip=100, loss_scale=64, train_wall=38, gb_free=8.4, wall=34464
2023-05-21 03:32:25 - progress_bar.py[line:272] - INFO: epoch 006:    287 / 1732 loss=2.491, loss_v1=0, loss_v2=0, nll_loss=1.305, ntokens=1149.1, nsentences=32, sample_size=1149.1, sample_size_v1=0, sample_size_v2=0, ppl=2.47, wps=298, ups=0.26, wpb=1149.1, bsz=32, num_updates=8930, lr=8.80986e-06, gnorm=4.199, clip=100, loss_scale=64, train_wall=39, gb_free=8.2, wall=34502
2023-05-21 03:33:04 - progress_bar.py[line:272] - INFO: epoch 006:    297 / 1732 loss=2.509, loss_v1=0, loss_v2=0, nll_loss=1.324, ntokens=1120.1, nsentences=32, sample_size=1120.1, sample_size_v1=0, sample_size_v2=0, ppl=2.5, wps=292.5, ups=0.26, wpb=1120.1, bsz=32, num_updates=8940, lr=8.80781e-06, gnorm=4.507, clip=100, loss_scale=64, train_wall=38, gb_free=8, wall=34541
2023-05-21 03:33:42 - progress_bar.py[line:272] - INFO: epoch 006:    307 / 1732 loss=2.485, loss_v1=0, loss_v2=0, nll_loss=1.296, ntokens=1063.6, nsentences=32, sample_size=1063.6, sample_size_v1=0, sample_size_v2=0, ppl=2.46, wps=276.9, ups=0.26, wpb=1063.6, bsz=32, num_updates=8950, lr=8.80577e-06, gnorm=4.62, clip=100, loss_scale=64, train_wall=38, gb_free=9.2, wall=34579
2023-05-21 03:34:20 - progress_bar.py[line:272] - INFO: epoch 006:    317 / 1732 loss=2.503, loss_v1=0, loss_v2=0, nll_loss=1.316, ntokens=1045.4, nsentences=32, sample_size=1045.4, sample_size_v1=0, sample_size_v2=0, ppl=2.49, wps=273.4, ups=0.26, wpb=1045.4, bsz=32, num_updates=8960, lr=8.80372e-06, gnorm=5.012, clip=100, loss_scale=64, train_wall=38, gb_free=8.7, wall=34617
2023-05-21 03:34:58 - progress_bar.py[line:272] - INFO: epoch 006:    327 / 1732 loss=2.52, loss_v1=0, loss_v2=0, nll_loss=1.336, ntokens=1029.3, nsentences=32, sample_size=1029.3, sample_size_v1=0, sample_size_v2=0, ppl=2.52, wps=269.7, ups=0.26, wpb=1029.3, bsz=32, num_updates=8970, lr=8.80167e-06, gnorm=5.003, clip=100, loss_scale=64, train_wall=38, gb_free=8.5, wall=34656
2023-05-21 03:35:36 - progress_bar.py[line:272] - INFO: epoch 006:    337 / 1732 loss=2.489, loss_v1=0, loss_v2=0, nll_loss=1.3, ntokens=970.5, nsentences=32, sample_size=970.5, sample_size_v1=0, sample_size_v2=0, ppl=2.46, wps=254.9, ups=0.26, wpb=970.5, bsz=32, num_updates=8980, lr=8.79962e-06, gnorm=5.001, clip=100, loss_scale=64, train_wall=38, gb_free=8, wall=34694
2023-05-21 03:36:14 - progress_bar.py[line:272] - INFO: epoch 006:    347 / 1732 loss=2.487, loss_v1=0, loss_v2=0, nll_loss=1.302, ntokens=913.7, nsentences=32, sample_size=913.7, sample_size_v1=0, sample_size_v2=0, ppl=2.47, wps=241.6, ups=0.26, wpb=913.7, bsz=32, num_updates=8990, lr=8.79758e-06, gnorm=5.714, clip=100, loss_scale=64, train_wall=38, gb_free=8.7, wall=34731
2023-05-21 03:36:52 - progress_bar.py[line:272] - INFO: epoch 006:    357 / 1732 loss=2.523, loss_v1=0, loss_v2=0, nll_loss=1.341, ntokens=948.3, nsentences=32, sample_size=948.3, sample_size_v1=0, sample_size_v2=0, ppl=2.53, wps=249.5, ups=0.26, wpb=948.3, bsz=32, num_updates=9000, lr=8.79553e-06, gnorm=5.011, clip=100, loss_scale=64, train_wall=38, gb_free=9.1, wall=34769
2023-05-21 03:37:30 - progress_bar.py[line:272] - INFO: epoch 006:    367 / 1732 loss=2.536, loss_v1=0, loss_v2=0, nll_loss=1.351, ntokens=952.5, nsentences=32, sample_size=952.5, sample_size_v1=0, sample_size_v2=0, ppl=2.55, wps=250.6, ups=0.26, wpb=952.5, bsz=32, num_updates=9010, lr=8.79348e-06, gnorm=5.478, clip=100, loss_scale=64, train_wall=38, gb_free=8.9, wall=34808
2023-05-21 03:38:08 - progress_bar.py[line:272] - INFO: epoch 006:    377 / 1732 loss=2.535, loss_v1=0, loss_v2=0, nll_loss=1.349, ntokens=1056.5, nsentences=32, sample_size=1056.5, sample_size_v1=0, sample_size_v2=0, ppl=2.55, wps=277.6, ups=0.26, wpb=1056.5, bsz=32, num_updates=9020, lr=8.79143e-06, gnorm=4.963, clip=100, loss_scale=64, train_wall=38, gb_free=8.3, wall=34846
2023-05-21 03:38:46 - progress_bar.py[line:272] - INFO: epoch 006:    387 / 1732 loss=2.507, loss_v1=0, loss_v2=0, nll_loss=1.323, ntokens=1047.4, nsentences=32, sample_size=1047.4, sample_size_v1=0, sample_size_v2=0, ppl=2.5, wps=275.6, ups=0.26, wpb=1047.4, bsz=32, num_updates=9030, lr=8.78939e-06, gnorm=5.371, clip=100, loss_scale=64, train_wall=38, gb_free=8.8, wall=34884
2023-05-21 03:39:24 - progress_bar.py[line:272] - INFO: epoch 006:    397 / 1732 loss=2.493, loss_v1=0, loss_v2=0, nll_loss=1.306, ntokens=958, nsentences=32, sample_size=958, sample_size_v1=0, sample_size_v2=0, ppl=2.47, wps=251.8, ups=0.26, wpb=958, bsz=32, num_updates=9040, lr=8.78734e-06, gnorm=5.986, clip=100, loss_scale=64, train_wall=38, gb_free=8.3, wall=34922
2023-05-21 03:40:03 - progress_bar.py[line:272] - INFO: epoch 006:    407 / 1732 loss=2.488, loss_v1=0, loss_v2=0, nll_loss=1.299, ntokens=1072.2, nsentences=32, sample_size=1072.2, sample_size_v1=0, sample_size_v2=0, ppl=2.46, wps=279.8, ups=0.26, wpb=1072.2, bsz=32, num_updates=9050, lr=8.78529e-06, gnorm=4.873, clip=100, loss_scale=64, train_wall=38, gb_free=8.3, wall=34960
2023-05-21 03:40:41 - progress_bar.py[line:272] - INFO: epoch 006:    417 / 1732 loss=2.475, loss_v1=0, loss_v2=0, nll_loss=1.286, ntokens=1027.3, nsentences=32, sample_size=1027.3, sample_size_v1=0, sample_size_v2=0, ppl=2.44, wps=269, ups=0.26, wpb=1027.3, bsz=32, num_updates=9060, lr=8.78324e-06, gnorm=5.666, clip=100, loss_scale=64, train_wall=38, gb_free=8.9, wall=34998
2023-05-21 03:41:19 - progress_bar.py[line:272] - INFO: epoch 006:    427 / 1732 loss=2.472, loss_v1=0, loss_v2=0, nll_loss=1.284, ntokens=993.5, nsentences=32, sample_size=993.5, sample_size_v1=0, sample_size_v2=0, ppl=2.44, wps=260.8, ups=0.26, wpb=993.5, bsz=32, num_updates=9070, lr=8.7812e-06, gnorm=5.613, clip=100, loss_scale=64, train_wall=38, gb_free=8.5, wall=35036
2023-05-21 03:41:57 - progress_bar.py[line:272] - INFO: epoch 006:    437 / 1732 loss=2.505, loss_v1=0, loss_v2=0, nll_loss=1.319, ntokens=1035.6, nsentences=32, sample_size=1035.6, sample_size_v1=0, sample_size_v2=0, ppl=2.5, wps=272.3, ups=0.26, wpb=1035.6, bsz=32, num_updates=9080, lr=8.77915e-06, gnorm=5.13, clip=100, loss_scale=64, train_wall=38, gb_free=8.8, wall=35074
2023-05-21 03:42:35 - progress_bar.py[line:272] - INFO: epoch 006:    447 / 1732 loss=2.514, loss_v1=0, loss_v2=0, nll_loss=1.327, ntokens=949, nsentences=32, sample_size=949, sample_size_v1=0, sample_size_v2=0, ppl=2.51, wps=249.9, ups=0.26, wpb=949, bsz=32, num_updates=9090, lr=8.7771e-06, gnorm=6.076, clip=100, loss_scale=64, train_wall=38, gb_free=8.1, wall=35112
2023-05-21 03:43:13 - progress_bar.py[line:272] - INFO: epoch 006:    457 / 1732 loss=2.501, loss_v1=0, loss_v2=0, nll_loss=1.317, ntokens=959.4, nsentences=32, sample_size=959.4, sample_size_v1=0, sample_size_v2=0, ppl=2.49, wps=252.9, ups=0.26, wpb=959.4, bsz=32, num_updates=9100, lr=8.77505e-06, gnorm=5.709, clip=100, loss_scale=64, train_wall=38, gb_free=7.7, wall=35150
2023-05-21 03:43:51 - progress_bar.py[line:272] - INFO: epoch 006:    467 / 1732 loss=2.518, loss_v1=0, loss_v2=0, nll_loss=1.334, ntokens=1054.7, nsentences=32, sample_size=1054.7, sample_size_v1=0, sample_size_v2=0, ppl=2.52, wps=276.1, ups=0.26, wpb=1054.7, bsz=32, num_updates=9110, lr=8.77301e-06, gnorm=5.311, clip=100, loss_scale=64, train_wall=38, gb_free=8.3, wall=35188
2023-05-21 03:44:29 - progress_bar.py[line:272] - INFO: epoch 006:    477 / 1732 loss=2.515, loss_v1=0, loss_v2=0, nll_loss=1.329, ntokens=1051.9, nsentences=32, sample_size=1051.9, sample_size_v1=0, sample_size_v2=0, ppl=2.51, wps=275.5, ups=0.26, wpb=1051.9, bsz=32, num_updates=9120, lr=8.77096e-06, gnorm=5.354, clip=100, loss_scale=64, train_wall=38, gb_free=9.1, wall=35227
2023-05-21 03:45:07 - progress_bar.py[line:272] - INFO: epoch 006:    487 / 1732 loss=2.484, loss_v1=0, loss_v2=0, nll_loss=1.294, ntokens=936.6, nsentences=32, sample_size=936.6, sample_size_v1=0, sample_size_v2=0, ppl=2.45, wps=246.8, ups=0.26, wpb=936.6, bsz=32, num_updates=9130, lr=8.76891e-06, gnorm=5.839, clip=100, loss_scale=64, train_wall=38, gb_free=9.3, wall=35265
2023-05-21 03:45:45 - progress_bar.py[line:272] - INFO: epoch 006:    497 / 1732 loss=2.493, loss_v1=0, loss_v2=0, nll_loss=1.307, ntokens=954.7, nsentences=32, sample_size=954.7, sample_size_v1=0, sample_size_v2=0, ppl=2.47, wps=251.8, ups=0.26, wpb=954.7, bsz=32, num_updates=9140, lr=8.76687e-06, gnorm=5.803, clip=100, loss_scale=64, train_wall=38, gb_free=8.1, wall=35302
2023-05-21 03:46:23 - progress_bar.py[line:272] - INFO: epoch 006:    507 / 1732 loss=2.498, loss_v1=0, loss_v2=0, nll_loss=1.31, ntokens=1006.3, nsentences=32, sample_size=1006.3, sample_size_v1=0, sample_size_v2=0, ppl=2.48, wps=266, ups=0.26, wpb=1006.3, bsz=32, num_updates=9150, lr=8.76482e-06, gnorm=5.899, clip=100, loss_scale=64, train_wall=38, gb_free=8.4, wall=35340
2023-05-21 03:47:01 - progress_bar.py[line:272] - INFO: epoch 006:    517 / 1732 loss=2.503, loss_v1=0, loss_v2=0, nll_loss=1.316, ntokens=1047.1, nsentences=32, sample_size=1047.1, sample_size_v1=0, sample_size_v2=0, ppl=2.49, wps=276.3, ups=0.26, wpb=1047.1, bsz=32, num_updates=9160, lr=8.76277e-06, gnorm=5.301, clip=100, loss_scale=64, train_wall=38, gb_free=9, wall=35378
2023-05-21 03:47:39 - progress_bar.py[line:272] - INFO: epoch 006:    527 / 1732 loss=2.505, loss_v1=0, loss_v2=0, nll_loss=1.319, ntokens=940.9, nsentences=32, sample_size=940.9, sample_size_v1=0, sample_size_v2=0, ppl=2.49, wps=248.9, ups=0.26, wpb=940.9, bsz=32, num_updates=9170, lr=8.76072e-06, gnorm=6.181, clip=100, loss_scale=64, train_wall=38, gb_free=9.1, wall=35416
2023-05-21 03:48:17 - progress_bar.py[line:272] - INFO: epoch 006:    537 / 1732 loss=2.482, loss_v1=0, loss_v2=0, nll_loss=1.292, ntokens=964.7, nsentences=32, sample_size=964.7, sample_size_v1=0, sample_size_v2=0, ppl=2.45, wps=253.4, ups=0.26, wpb=964.7, bsz=32, num_updates=9180, lr=8.75868e-06, gnorm=5.452, clip=100, loss_scale=64, train_wall=38, gb_free=9, wall=35454
2023-05-21 03:48:55 - progress_bar.py[line:272] - INFO: epoch 006:    547 / 1732 loss=2.509, loss_v1=0, loss_v2=0, nll_loss=1.324, ntokens=1033.6, nsentences=32, sample_size=1033.6, sample_size_v1=0, sample_size_v2=0, ppl=2.5, wps=271.9, ups=0.26, wpb=1033.6, bsz=32, num_updates=9190, lr=8.75663e-06, gnorm=5.083, clip=100, loss_scale=64, train_wall=38, gb_free=8.4, wall=35492
2023-05-21 03:49:33 - progress_bar.py[line:272] - INFO: epoch 006:    557 / 1732 loss=2.53, loss_v1=0, loss_v2=0, nll_loss=1.349, ntokens=1010.2, nsentences=32, sample_size=1010.2, sample_size_v1=0, sample_size_v2=0, ppl=2.55, wps=266.4, ups=0.26, wpb=1010.2, bsz=32, num_updates=9200, lr=8.75458e-06, gnorm=5.778, clip=100, loss_scale=64, train_wall=38, gb_free=8.9, wall=35530
2023-05-21 03:50:11 - progress_bar.py[line:272] - INFO: epoch 006:    567 / 1732 loss=2.542, loss_v1=0, loss_v2=0, nll_loss=1.359, ntokens=1004.9, nsentences=32, sample_size=1004.9, sample_size_v1=0, sample_size_v2=0, ppl=2.56, wps=263.2, ups=0.26, wpb=1004.9, bsz=32, num_updates=9210, lr=8.75253e-06, gnorm=6.273, clip=100, loss_scale=64, train_wall=38, gb_free=8.9, wall=35568
2023-05-21 03:50:49 - progress_bar.py[line:272] - INFO: epoch 006:    577 / 1732 loss=2.499, loss_v1=0, loss_v2=0, nll_loss=1.311, ntokens=1011.7, nsentences=32, sample_size=1011.7, sample_size_v1=0, sample_size_v2=0, ppl=2.48, wps=263, ups=0.26, wpb=1011.7, bsz=32, num_updates=9220, lr=8.75049e-06, gnorm=6.117, clip=100, loss_scale=64, train_wall=38, gb_free=8.9, wall=35607
2023-05-21 03:51:28 - progress_bar.py[line:272] - INFO: epoch 006:    587 / 1732 loss=2.513, loss_v1=0, loss_v2=0, nll_loss=1.329, ntokens=962.2, nsentences=32, sample_size=962.2, sample_size_v1=0, sample_size_v2=0, ppl=2.51, wps=250.7, ups=0.26, wpb=962.2, bsz=32, num_updates=9230, lr=8.74844e-06, gnorm=6.007, clip=100, loss_scale=64, train_wall=38, gb_free=9.3, wall=35645
2023-05-21 03:52:06 - progress_bar.py[line:272] - INFO: epoch 006:    597 / 1732 loss=2.464, loss_v1=0, loss_v2=0, nll_loss=1.275, ntokens=975.4, nsentences=32, sample_size=975.4, sample_size_v1=0, sample_size_v2=0, ppl=2.42, wps=255.8, ups=0.26, wpb=975.4, bsz=32, num_updates=9240, lr=8.74639e-06, gnorm=5.717, clip=100, loss_scale=64, train_wall=38, gb_free=8.6, wall=35683
2023-05-21 03:52:44 - progress_bar.py[line:272] - INFO: epoch 006:    607 / 1732 loss=2.506, loss_v1=0, loss_v2=0, nll_loss=1.322, ntokens=882.8, nsentences=32, sample_size=882.8, sample_size_v1=0, sample_size_v2=0, ppl=2.5, wps=233.2, ups=0.26, wpb=882.8, bsz=32, num_updates=9250, lr=8.74434e-06, gnorm=5.716, clip=100, loss_scale=64, train_wall=38, gb_free=8.1, wall=35721
2023-05-21 03:53:22 - progress_bar.py[line:272] - INFO: epoch 006:    617 / 1732 loss=2.505, loss_v1=0, loss_v2=0, nll_loss=1.319, ntokens=866.1, nsentences=32, sample_size=866.1, sample_size_v1=0, sample_size_v2=0, ppl=2.5, wps=228.1, ups=0.26, wpb=866.1, bsz=32, num_updates=9260, lr=8.7423e-06, gnorm=6.549, clip=100, loss_scale=64, train_wall=38, gb_free=8.7, wall=35759
2023-05-21 03:53:59 - progress_bar.py[line:272] - INFO: epoch 006:    627 / 1732 loss=2.501, loss_v1=0, loss_v2=0, nll_loss=1.315, ntokens=930.6, nsentences=32, sample_size=930.6, sample_size_v1=0, sample_size_v2=0, ppl=2.49, wps=246.9, ups=0.27, wpb=930.6, bsz=32, num_updates=9270, lr=8.74025e-06, gnorm=6.008, clip=100, loss_scale=64, train_wall=38, gb_free=9.1, wall=35797
2023-05-21 03:54:37 - progress_bar.py[line:272] - INFO: epoch 006:    637 / 1732 loss=2.514, loss_v1=0, loss_v2=0, nll_loss=1.331, ntokens=914.3, nsentences=32, sample_size=914.3, sample_size_v1=0, sample_size_v2=0, ppl=2.52, wps=242.7, ups=0.27, wpb=914.3, bsz=32, num_updates=9280, lr=8.7382e-06, gnorm=6.167, clip=100, loss_scale=64, train_wall=38, gb_free=8.8, wall=35834
2023-05-21 03:55:15 - progress_bar.py[line:272] - INFO: epoch 006:    647 / 1732 loss=2.515, loss_v1=0, loss_v2=0, nll_loss=1.33, ntokens=980.8, nsentences=32, sample_size=980.8, sample_size_v1=0, sample_size_v2=0, ppl=2.51, wps=258.8, ups=0.26, wpb=980.8, bsz=32, num_updates=9290, lr=8.73615e-06, gnorm=5.777, clip=100, loss_scale=64, train_wall=38, gb_free=9, wall=35872
2023-05-21 03:55:53 - progress_bar.py[line:272] - INFO: epoch 006:    657 / 1732 loss=2.525, loss_v1=0, loss_v2=0, nll_loss=1.341, ntokens=894.4, nsentences=32, sample_size=894.4, sample_size_v1=0, sample_size_v2=0, ppl=2.53, wps=237.6, ups=0.27, wpb=894.4, bsz=32, num_updates=9300, lr=8.73411e-06, gnorm=6.417, clip=100, loss_scale=64, train_wall=38, gb_free=8.8, wall=35910
2023-05-21 03:56:30 - progress_bar.py[line:272] - INFO: epoch 006:    667 / 1732 loss=2.511, loss_v1=0, loss_v2=0, nll_loss=1.327, ntokens=903.9, nsentences=32, sample_size=903.9, sample_size_v1=0, sample_size_v2=0, ppl=2.51, wps=239.3, ups=0.26, wpb=903.9, bsz=32, num_updates=9310, lr=8.73206e-06, gnorm=6.839, clip=100, loss_scale=64, train_wall=38, gb_free=8.7, wall=35948
2023-05-21 03:57:09 - progress_bar.py[line:272] - INFO: epoch 006:    677 / 1732 loss=2.5, loss_v1=0, loss_v2=0, nll_loss=1.314, ntokens=985.3, nsentences=32, sample_size=985.3, sample_size_v1=0, sample_size_v2=0, ppl=2.49, wps=257.7, ups=0.26, wpb=985.3, bsz=32, num_updates=9320, lr=8.73001e-06, gnorm=5.751, clip=100, loss_scale=64, train_wall=38, gb_free=9, wall=35986
2023-05-21 03:57:47 - progress_bar.py[line:272] - INFO: epoch 006:    687 / 1732 loss=2.515, loss_v1=0, loss_v2=0, nll_loss=1.331, ntokens=943.2, nsentences=32, sample_size=943.2, sample_size_v1=0, sample_size_v2=0, ppl=2.51, wps=246.2, ups=0.26, wpb=943.2, bsz=32, num_updates=9330, lr=8.72797e-06, gnorm=5.844, clip=100, loss_scale=64, train_wall=38, gb_free=9.2, wall=36024
2023-05-21 03:58:25 - progress_bar.py[line:272] - INFO: epoch 006:    697 / 1732 loss=2.501, loss_v1=0, loss_v2=0, nll_loss=1.316, ntokens=1005.6, nsentences=32, sample_size=1005.6, sample_size_v1=0, sample_size_v2=0, ppl=2.49, wps=263.7, ups=0.26, wpb=1005.6, bsz=32, num_updates=9340, lr=8.72592e-06, gnorm=6.011, clip=100, loss_scale=64, train_wall=38, gb_free=8, wall=36062
2023-05-21 03:59:03 - progress_bar.py[line:272] - INFO: epoch 006:    707 / 1732 loss=2.498, loss_v1=0, loss_v2=0, nll_loss=1.311, ntokens=903.4, nsentences=32, sample_size=903.4, sample_size_v1=0, sample_size_v2=0, ppl=2.48, wps=239.3, ups=0.26, wpb=903.4, bsz=32, num_updates=9350, lr=8.72387e-06, gnorm=6.247, clip=100, loss_scale=64, train_wall=38, gb_free=9.1, wall=36100
2023-05-21 03:59:41 - progress_bar.py[line:272] - INFO: epoch 006:    717 / 1732 loss=2.496, loss_v1=0, loss_v2=0, nll_loss=1.309, ntokens=882.7, nsentences=32, sample_size=882.7, sample_size_v1=0, sample_size_v2=0, ppl=2.48, wps=234.7, ups=0.27, wpb=882.7, bsz=32, num_updates=9360, lr=8.72182e-06, gnorm=5.978, clip=100, loss_scale=64, train_wall=38, gb_free=8.8, wall=36138
2023-05-21 04:00:18 - progress_bar.py[line:272] - INFO: epoch 006:    727 / 1732 loss=2.48, loss_v1=0, loss_v2=0, nll_loss=1.293, ntokens=909.8, nsentences=32, sample_size=909.8, sample_size_v1=0, sample_size_v2=0, ppl=2.45, wps=241.2, ups=0.27, wpb=909.8, bsz=32, num_updates=9370, lr=8.71978e-06, gnorm=6.493, clip=100, loss_scale=64, train_wall=38, gb_free=9.2, wall=36175
2023-05-21 04:00:56 - progress_bar.py[line:272] - INFO: epoch 006:    737 / 1732 loss=2.474, loss_v1=0, loss_v2=0, nll_loss=1.286, ntokens=998.8, nsentences=32, sample_size=998.8, sample_size_v1=0, sample_size_v2=0, ppl=2.44, wps=263.9, ups=0.26, wpb=998.8, bsz=32, num_updates=9380, lr=8.71773e-06, gnorm=5.804, clip=100, loss_scale=64, train_wall=38, gb_free=8.6, wall=36213
2023-05-21 04:01:34 - progress_bar.py[line:272] - INFO: epoch 006:    747 / 1732 loss=2.475, loss_v1=0, loss_v2=0, nll_loss=1.286, ntokens=980.5, nsentences=32, sample_size=980.5, sample_size_v1=0, sample_size_v2=0, ppl=2.44, wps=256.3, ups=0.26, wpb=980.5, bsz=32, num_updates=9390, lr=8.71568e-06, gnorm=5.89, clip=100, loss_scale=128, train_wall=38, gb_free=8.3, wall=36252
2023-05-21 04:02:12 - progress_bar.py[line:272] - INFO: epoch 006:    757 / 1732 loss=2.492, loss_v1=0, loss_v2=0, nll_loss=1.303, ntokens=949.2, nsentences=32, sample_size=949.2, sample_size_v1=0, sample_size_v2=0, ppl=2.47, wps=249.4, ups=0.26, wpb=949.2, bsz=32, num_updates=9400, lr=8.71363e-06, gnorm=6.24, clip=100, loss_scale=128, train_wall=38, gb_free=8.8, wall=36290
2023-05-21 04:02:50 - progress_bar.py[line:272] - INFO: epoch 006:    767 / 1732 loss=2.485, loss_v1=0, loss_v2=0, nll_loss=1.298, ntokens=941.7, nsentences=32, sample_size=941.7, sample_size_v1=0, sample_size_v2=0, ppl=2.46, wps=248, ups=0.26, wpb=941.7, bsz=32, num_updates=9410, lr=8.71159e-06, gnorm=6.355, clip=100, loss_scale=128, train_wall=38, gb_free=9.2, wall=36328
2023-05-21 04:03:28 - progress_bar.py[line:272] - INFO: epoch 006:    777 / 1732 loss=2.499, loss_v1=0, loss_v2=0, nll_loss=1.314, ntokens=1028.6, nsentences=32, sample_size=1028.6, sample_size_v1=0, sample_size_v2=0, ppl=2.49, wps=270.7, ups=0.26, wpb=1028.6, bsz=32, num_updates=9420, lr=8.70954e-06, gnorm=5.701, clip=100, loss_scale=128, train_wall=38, gb_free=8.8, wall=36366
2023-05-21 04:04:06 - progress_bar.py[line:272] - INFO: epoch 006:    787 / 1732 loss=2.49, loss_v1=0, loss_v2=0, nll_loss=1.303, ntokens=1016.6, nsentences=32, sample_size=1016.6, sample_size_v1=0, sample_size_v2=0, ppl=2.47, wps=267.8, ups=0.26, wpb=1016.6, bsz=32, num_updates=9430, lr=8.70749e-06, gnorm=5.785, clip=100, loss_scale=128, train_wall=38, gb_free=8.5, wall=36404
2023-05-21 04:04:44 - progress_bar.py[line:272] - INFO: epoch 006:    797 / 1732 loss=2.484, loss_v1=0, loss_v2=0, nll_loss=1.294, ntokens=1038, nsentences=32, sample_size=1038, sample_size_v1=0, sample_size_v2=0, ppl=2.45, wps=272.6, ups=0.26, wpb=1038, bsz=32, num_updates=9440, lr=8.70544e-06, gnorm=6.198, clip=100, loss_scale=128, train_wall=38, gb_free=8.8, wall=36442
2023-05-21 04:05:22 - progress_bar.py[line:272] - INFO: epoch 006:    807 / 1732 loss=2.489, loss_v1=0, loss_v2=0, nll_loss=1.301, ntokens=915, nsentences=32, sample_size=915, sample_size_v1=0, sample_size_v2=0, ppl=2.46, wps=240.8, ups=0.26, wpb=915, bsz=32, num_updates=9450, lr=8.7034e-06, gnorm=6.246, clip=100, loss_scale=128, train_wall=38, gb_free=8.7, wall=36480
2023-05-21 04:05:26 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2023-05-21 04:06:04 - progress_bar.py[line:272] - INFO: epoch 006:    818 / 1732 loss=2.505, loss_v1=0, loss_v2=0, nll_loss=1.319, ntokens=917.4, nsentences=32, sample_size=917.4, sample_size_v1=0, sample_size_v2=0, ppl=2.5, wps=219.3, ups=0.24, wpb=917.4, bsz=32, num_updates=9460, lr=8.70135e-06, gnorm=6.99, clip=100, loss_scale=64, train_wall=42, gb_free=8.7, wall=36521
2023-05-21 04:06:42 - progress_bar.py[line:272] - INFO: epoch 006:    828 / 1732 loss=2.488, loss_v1=0, loss_v2=0, nll_loss=1.299, ntokens=929.3, nsentences=32, sample_size=929.3, sample_size_v1=0, sample_size_v2=0, ppl=2.46, wps=244.1, ups=0.26, wpb=929.3, bsz=32, num_updates=9470, lr=8.6993e-06, gnorm=5.901, clip=100, loss_scale=64, train_wall=38, gb_free=9, wall=36560
2023-05-21 04:07:20 - progress_bar.py[line:272] - INFO: epoch 006:    838 / 1732 loss=2.492, loss_v1=0, loss_v2=0, nll_loss=1.303, ntokens=901, nsentences=32, sample_size=901, sample_size_v1=0, sample_size_v2=0, ppl=2.47, wps=239, ups=0.27, wpb=901, bsz=32, num_updates=9480, lr=8.69725e-06, gnorm=6.782, clip=100, loss_scale=64, train_wall=38, gb_free=8.9, wall=36597
2023-05-21 04:07:58 - progress_bar.py[line:272] - INFO: epoch 006:    848 / 1732 loss=2.474, loss_v1=0, loss_v2=0, nll_loss=1.283, ntokens=1016.3, nsentences=32, sample_size=1016.3, sample_size_v1=0, sample_size_v2=0, ppl=2.43, wps=268, ups=0.26, wpb=1016.3, bsz=32, num_updates=9490, lr=8.69521e-06, gnorm=5.602, clip=100, loss_scale=64, train_wall=38, gb_free=7.9, wall=36635
2023-05-21 04:08:36 - progress_bar.py[line:272] - INFO: epoch 006:    858 / 1732 loss=2.484, loss_v1=0, loss_v2=0, nll_loss=1.296, ntokens=923.8, nsentences=32, sample_size=923.8, sample_size_v1=0, sample_size_v2=0, ppl=2.45, wps=244.4, ups=0.26, wpb=923.8, bsz=32, num_updates=9500, lr=8.69316e-06, gnorm=6.738, clip=100, loss_scale=64, train_wall=38, gb_free=8.8, wall=36673
2023-05-21 04:09:14 - progress_bar.py[line:272] - INFO: epoch 006:    868 / 1732 loss=2.496, loss_v1=0, loss_v2=0, nll_loss=1.31, ntokens=966.1, nsentences=32, sample_size=966.1, sample_size_v1=0, sample_size_v2=0, ppl=2.48, wps=254.3, ups=0.26, wpb=966.1, bsz=32, num_updates=9510, lr=8.69111e-06, gnorm=6.05, clip=100, loss_scale=64, train_wall=38, gb_free=8.9, wall=36711
2023-05-21 04:09:52 - progress_bar.py[line:272] - INFO: epoch 006:    878 / 1732 loss=2.429, loss_v1=0, loss_v2=0, nll_loss=1.236, ntokens=1016.8, nsentences=32, sample_size=1016.8, sample_size_v1=0, sample_size_v2=0, ppl=2.35, wps=266.9, ups=0.26, wpb=1016.8, bsz=32, num_updates=9520, lr=8.68906e-06, gnorm=5.554, clip=100, loss_scale=64, train_wall=38, gb_free=8.7, wall=36749
2023-05-21 04:10:30 - progress_bar.py[line:272] - INFO: epoch 006:    888 / 1732 loss=2.453, loss_v1=0, loss_v2=0, nll_loss=1.262, ntokens=961.8, nsentences=32, sample_size=961.8, sample_size_v1=0, sample_size_v2=0, ppl=2.4, wps=252.5, ups=0.26, wpb=961.8, bsz=32, num_updates=9530, lr=8.68702e-06, gnorm=6.732, clip=100, loss_scale=64, train_wall=38, gb_free=8.7, wall=36787
2023-05-21 04:11:08 - progress_bar.py[line:272] - INFO: epoch 006:    898 / 1732 loss=2.425, loss_v1=0, loss_v2=0, nll_loss=1.228, ntokens=1063.3, nsentences=32, sample_size=1063.3, sample_size_v1=0, sample_size_v2=0, ppl=2.34, wps=279, ups=0.26, wpb=1063.3, bsz=32, num_updates=9540, lr=8.68497e-06, gnorm=5.55, clip=100, loss_scale=64, train_wall=38, gb_free=8.2, wall=36825
2023-05-21 04:11:46 - progress_bar.py[line:272] - INFO: epoch 006:    908 / 1732 loss=2.451, loss_v1=0, loss_v2=0, nll_loss=1.26, ntokens=987.4, nsentences=32, sample_size=987.4, sample_size_v1=0, sample_size_v2=0, ppl=2.39, wps=260.4, ups=0.26, wpb=987.4, bsz=32, num_updates=9550, lr=8.68292e-06, gnorm=6.177, clip=100, loss_scale=64, train_wall=38, gb_free=8.8, wall=36863
2023-05-21 04:12:24 - progress_bar.py[line:272] - INFO: epoch 006:    918 / 1732 loss=2.525, loss_v1=0, loss_v2=0, nll_loss=1.343, ntokens=968, nsentences=32, sample_size=968, sample_size_v1=0, sample_size_v2=0, ppl=2.54, wps=254.5, ups=0.26, wpb=968, bsz=32, num_updates=9560, lr=8.68088e-06, gnorm=5.952, clip=100, loss_scale=64, train_wall=38, gb_free=7.8, wall=36901
2023-05-21 04:13:03 - progress_bar.py[line:272] - INFO: epoch 006:    928 / 1732 loss=2.457, loss_v1=0, loss_v2=0, nll_loss=1.266, ntokens=1026.7, nsentences=32, sample_size=1026.7, sample_size_v1=0, sample_size_v2=0, ppl=2.41, wps=266.5, ups=0.26, wpb=1026.7, bsz=32, num_updates=9570, lr=8.67883e-06, gnorm=6, clip=100, loss_scale=64, train_wall=38, gb_free=8.5, wall=36940
2023-05-21 04:13:41 - progress_bar.py[line:272] - INFO: epoch 006:    938 / 1732 loss=2.456, loss_v1=0, loss_v2=0, nll_loss=1.265, ntokens=1050.3, nsentences=32, sample_size=1050.3, sample_size_v1=0, sample_size_v2=0, ppl=2.4, wps=272, ups=0.26, wpb=1050.3, bsz=32, num_updates=9580, lr=8.67678e-06, gnorm=5.168, clip=100, loss_scale=64, train_wall=39, gb_free=7.7, wall=36978
2023-05-21 04:14:20 - progress_bar.py[line:272] - INFO: epoch 006:    948 / 1732 loss=2.473, loss_v1=0, loss_v2=0, nll_loss=1.284, ntokens=1031, nsentences=32, sample_size=1031, sample_size_v1=0, sample_size_v2=0, ppl=2.43, wps=267.6, ups=0.26, wpb=1031, bsz=32, num_updates=9590, lr=8.67473e-06, gnorm=4.929, clip=100, loss_scale=64, train_wall=38, gb_free=8.7, wall=37017
2023-05-21 04:14:58 - progress_bar.py[line:272] - INFO: epoch 006:    958 / 1732 loss=2.459, loss_v1=0, loss_v2=0, nll_loss=1.269, ntokens=1072.9, nsentences=32, sample_size=1072.9, sample_size_v1=0, sample_size_v2=0, ppl=2.41, wps=278.2, ups=0.26, wpb=1072.9, bsz=32, num_updates=9600, lr=8.67269e-06, gnorm=5.391, clip=100, loss_scale=64, train_wall=39, gb_free=8.3, wall=37055
2023-05-21 04:15:37 - progress_bar.py[line:272] - INFO: epoch 006:    968 / 1732 loss=2.487, loss_v1=0, loss_v2=0, nll_loss=1.301, ntokens=1015.7, nsentences=32, sample_size=1015.7, sample_size_v1=0, sample_size_v2=0, ppl=2.46, wps=264.9, ups=0.26, wpb=1015.7, bsz=32, num_updates=9610, lr=8.67064e-06, gnorm=5.671, clip=100, loss_scale=64, train_wall=38, gb_free=8.9, wall=37094
2023-05-21 04:16:15 - progress_bar.py[line:272] - INFO: epoch 006:    978 / 1732 loss=2.47, loss_v1=0, loss_v2=0, nll_loss=1.281, ntokens=1036.8, nsentences=32, sample_size=1036.8, sample_size_v1=0, sample_size_v2=0, ppl=2.43, wps=267, ups=0.26, wpb=1036.8, bsz=32, num_updates=9620, lr=8.66859e-06, gnorm=5.591, clip=100, loss_scale=64, train_wall=39, gb_free=9, wall=37133
2023-05-21 04:16:54 - progress_bar.py[line:272] - INFO: epoch 006:    988 / 1732 loss=2.468, loss_v1=0, loss_v2=0, nll_loss=1.278, ntokens=1050.5, nsentences=32, sample_size=1050.5, sample_size_v1=0, sample_size_v2=0, ppl=2.43, wps=270, ups=0.26, wpb=1050.5, bsz=32, num_updates=9630, lr=8.66654e-06, gnorm=5.828, clip=100, loss_scale=64, train_wall=39, gb_free=7.9, wall=37172
2023-05-21 04:17:33 - progress_bar.py[line:272] - INFO: epoch 006:    998 / 1732 loss=2.463, loss_v1=0, loss_v2=0, nll_loss=1.271, ntokens=1000, nsentences=32, sample_size=1000, sample_size_v1=0, sample_size_v2=0, ppl=2.41, wps=259.5, ups=0.26, wpb=1000, bsz=32, num_updates=9640, lr=8.6645e-06, gnorm=5.44, clip=100, loss_scale=64, train_wall=38, gb_free=8.4, wall=37210
2023-05-21 04:18:11 - progress_bar.py[line:272] - INFO: epoch 006:   1008 / 1732 loss=2.46, loss_v1=0, loss_v2=0, nll_loss=1.268, ntokens=1026.8, nsentences=32, sample_size=1026.8, sample_size_v1=0, sample_size_v2=0, ppl=2.41, wps=268, ups=0.26, wpb=1026.8, bsz=32, num_updates=9650, lr=8.66245e-06, gnorm=5.236, clip=100, loss_scale=64, train_wall=38, gb_free=7.4, wall=37248
2023-05-21 04:18:50 - progress_bar.py[line:272] - INFO: epoch 006:   1018 / 1732 loss=2.452, loss_v1=0, loss_v2=0, nll_loss=1.262, ntokens=1036.8, nsentences=32, sample_size=1036.8, sample_size_v1=0, sample_size_v2=0, ppl=2.4, wps=269.3, ups=0.26, wpb=1036.8, bsz=32, num_updates=9660, lr=8.6604e-06, gnorm=5.48, clip=100, loss_scale=64, train_wall=38, gb_free=8.4, wall=37287
2023-05-21 04:19:29 - progress_bar.py[line:272] - INFO: epoch 006:   1028 / 1732 loss=2.476, loss_v1=0, loss_v2=0, nll_loss=1.288, ntokens=1060.8, nsentences=32, sample_size=1060.8, sample_size_v1=0, sample_size_v2=0, ppl=2.44, wps=273.5, ups=0.26, wpb=1060.8, bsz=32, num_updates=9670, lr=8.65835e-06, gnorm=5.746, clip=100, loss_scale=64, train_wall=39, gb_free=7.3, wall=37326
2023-05-21 04:20:07 - progress_bar.py[line:272] - INFO: epoch 006:   1038 / 1732 loss=2.469, loss_v1=0, loss_v2=0, nll_loss=1.278, ntokens=1110, nsentences=32, sample_size=1110, sample_size_v1=0, sample_size_v2=0, ppl=2.43, wps=287.7, ups=0.26, wpb=1110, bsz=32, num_updates=9680, lr=8.65631e-06, gnorm=5.714, clip=100, loss_scale=64, train_wall=39, gb_free=8.9, wall=37364
2023-05-21 04:20:46 - progress_bar.py[line:272] - INFO: epoch 006:   1048 / 1732 loss=2.451, loss_v1=0, loss_v2=0, nll_loss=1.256, ntokens=1025.8, nsentences=32, sample_size=1025.8, sample_size_v1=0, sample_size_v2=0, ppl=2.39, wps=265.2, ups=0.26, wpb=1025.8, bsz=32, num_updates=9690, lr=8.65426e-06, gnorm=6.28, clip=100, loss_scale=64, train_wall=39, gb_free=8.6, wall=37403
2023-05-21 04:21:24 - progress_bar.py[line:272] - INFO: epoch 006:   1058 / 1732 loss=2.467, loss_v1=0, loss_v2=0, nll_loss=1.276, ntokens=1082.8, nsentences=32, sample_size=1082.8, sample_size_v1=0, sample_size_v2=0, ppl=2.42, wps=280.8, ups=0.26, wpb=1082.8, bsz=32, num_updates=9700, lr=8.65221e-06, gnorm=5.543, clip=100, loss_scale=64, train_wall=39, gb_free=9, wall=37442
2023-05-21 04:22:03 - progress_bar.py[line:272] - INFO: epoch 006:   1068 / 1732 loss=2.464, loss_v1=0, loss_v2=0, nll_loss=1.274, ntokens=1002.9, nsentences=32, sample_size=1002.9, sample_size_v1=0, sample_size_v2=0, ppl=2.42, wps=261.1, ups=0.26, wpb=1002.9, bsz=32, num_updates=9710, lr=8.65016e-06, gnorm=5.882, clip=100, loss_scale=64, train_wall=38, gb_free=8.9, wall=37480
2023-05-21 04:22:42 - progress_bar.py[line:272] - INFO: epoch 006:   1078 / 1732 loss=2.487, loss_v1=0, loss_v2=0, nll_loss=1.299, ntokens=1000.2, nsentences=32, sample_size=1000.2, sample_size_v1=0, sample_size_v2=0, ppl=2.46, wps=257.4, ups=0.26, wpb=1000.2, bsz=32, num_updates=9720, lr=8.64812e-06, gnorm=6.209, clip=100, loss_scale=64, train_wall=39, gb_free=8.7, wall=37519
2023-05-21 04:23:20 - progress_bar.py[line:272] - INFO: epoch 006:   1088 / 1732 loss=2.463, loss_v1=0, loss_v2=0, nll_loss=1.271, ntokens=1078.6, nsentences=32, sample_size=1078.6, sample_size_v1=0, sample_size_v2=0, ppl=2.41, wps=278.1, ups=0.26, wpb=1078.6, bsz=32, num_updates=9730, lr=8.64607e-06, gnorm=6.045, clip=100, loss_scale=64, train_wall=39, gb_free=8.6, wall=37558
2023-05-21 04:23:59 - progress_bar.py[line:272] - INFO: epoch 006:   1098 / 1732 loss=2.472, loss_v1=0, loss_v2=0, nll_loss=1.284, ntokens=1045.6, nsentences=32, sample_size=1045.6, sample_size_v1=0, sample_size_v2=0, ppl=2.43, wps=270.1, ups=0.26, wpb=1045.6, bsz=32, num_updates=9740, lr=8.64402e-06, gnorm=5.981, clip=100, loss_scale=64, train_wall=39, gb_free=7.9, wall=37596
2023-05-21 04:24:38 - progress_bar.py[line:272] - INFO: epoch 006:   1108 / 1732 loss=2.454, loss_v1=0, loss_v2=0, nll_loss=1.262, ntokens=1058.8, nsentences=32, sample_size=1058.8, sample_size_v1=0, sample_size_v2=0, ppl=2.4, wps=272.4, ups=0.26, wpb=1058.8, bsz=32, num_updates=9750, lr=8.64198e-06, gnorm=5.815, clip=100, loss_scale=64, train_wall=39, gb_free=8.9, wall=37635
2023-05-21 04:25:17 - progress_bar.py[line:272] - INFO: epoch 006:   1118 / 1732 loss=2.475, loss_v1=0, loss_v2=0, nll_loss=1.285, ntokens=944.7, nsentences=32, sample_size=944.7, sample_size_v1=0, sample_size_v2=0, ppl=2.44, wps=243.7, ups=0.26, wpb=944.7, bsz=32, num_updates=9760, lr=8.63993e-06, gnorm=6.962, clip=100, loss_scale=64, train_wall=39, gb_free=8.4, wall=37674
2023-05-21 04:25:56 - progress_bar.py[line:272] - INFO: epoch 006:   1128 / 1732 loss=2.484, loss_v1=0, loss_v2=0, nll_loss=1.296, ntokens=1025.9, nsentences=32, sample_size=1025.9, sample_size_v1=0, sample_size_v2=0, ppl=2.45, wps=264.6, ups=0.26, wpb=1025.9, bsz=32, num_updates=9770, lr=8.63788e-06, gnorm=6.612, clip=100, loss_scale=64, train_wall=39, gb_free=7.7, wall=37713
2023-05-21 04:26:34 - progress_bar.py[line:272] - INFO: epoch 006:   1138 / 1732 loss=2.475, loss_v1=0, loss_v2=0, nll_loss=1.285, ntokens=989.2, nsentences=32, sample_size=989.2, sample_size_v1=0, sample_size_v2=0, ppl=2.44, wps=256.5, ups=0.26, wpb=989.2, bsz=32, num_updates=9780, lr=8.63583e-06, gnorm=6.217, clip=100, loss_scale=64, train_wall=39, gb_free=8.7, wall=37751
2023-05-21 04:27:12 - progress_bar.py[line:272] - INFO: epoch 006:   1148 / 1732 loss=2.477, loss_v1=0, loss_v2=0, nll_loss=1.287, ntokens=1007.7, nsentences=32, sample_size=1007.7, sample_size_v1=0, sample_size_v2=0, ppl=2.44, wps=262.7, ups=0.26, wpb=1007.7, bsz=32, num_updates=9790, lr=8.63379e-06, gnorm=6.161, clip=100, loss_scale=64, train_wall=38, gb_free=8.6, wall=37790
2023-05-21 04:27:51 - progress_bar.py[line:272] - INFO: epoch 006:   1158 / 1732 loss=2.444, loss_v1=0, loss_v2=0, nll_loss=1.251, ntokens=1016, nsentences=32, sample_size=1016, sample_size_v1=0, sample_size_v2=0, ppl=2.38, wps=262.9, ups=0.26, wpb=1016, bsz=32, num_updates=9800, lr=8.63174e-06, gnorm=6.048, clip=100, loss_scale=64, train_wall=39, gb_free=7.9, wall=37828
2023-05-21 04:28:30 - progress_bar.py[line:272] - INFO: epoch 006:   1168 / 1732 loss=2.47, loss_v1=0, loss_v2=0, nll_loss=1.279, ntokens=1020.6, nsentences=32, sample_size=1020.6, sample_size_v1=0, sample_size_v2=0, ppl=2.43, wps=265.4, ups=0.26, wpb=1020.6, bsz=32, num_updates=9810, lr=8.62969e-06, gnorm=6.032, clip=100, loss_scale=64, train_wall=38, gb_free=8.1, wall=37867
2023-05-21 04:29:08 - progress_bar.py[line:272] - INFO: epoch 006:   1178 / 1732 loss=2.436, loss_v1=0, loss_v2=0, nll_loss=1.242, ntokens=1067, nsentences=32, sample_size=1067, sample_size_v1=0, sample_size_v2=0, ppl=2.37, wps=277.2, ups=0.26, wpb=1067, bsz=32, num_updates=9820, lr=8.62764e-06, gnorm=5.087, clip=100, loss_scale=64, train_wall=38, gb_free=8.7, wall=37905
2023-05-21 04:29:47 - progress_bar.py[line:272] - INFO: epoch 006:   1188 / 1732 loss=2.487, loss_v1=0, loss_v2=0, nll_loss=1.301, ntokens=963.5, nsentences=32, sample_size=963.5, sample_size_v1=0, sample_size_v2=0, ppl=2.46, wps=250.8, ups=0.26, wpb=963.5, bsz=32, num_updates=9830, lr=8.6256e-06, gnorm=6.646, clip=100, loss_scale=64, train_wall=38, gb_free=8.2, wall=37944
2023-05-21 04:30:25 - progress_bar.py[line:272] - INFO: epoch 006:   1198 / 1732 loss=2.444, loss_v1=0, loss_v2=0, nll_loss=1.249, ntokens=1123.7, nsentences=32, sample_size=1123.7, sample_size_v1=0, sample_size_v2=0, ppl=2.38, wps=290.8, ups=0.26, wpb=1123.7, bsz=32, num_updates=9840, lr=8.62355e-06, gnorm=5.958, clip=100, loss_scale=64, train_wall=39, gb_free=8.4, wall=37982
2023-05-21 04:31:04 - progress_bar.py[line:272] - INFO: epoch 006:   1208 / 1732 loss=2.437, loss_v1=0, loss_v2=0, nll_loss=1.24, ntokens=1088.9, nsentences=32, sample_size=1088.9, sample_size_v1=0, sample_size_v2=0, ppl=2.36, wps=280.2, ups=0.26, wpb=1088.9, bsz=32, num_updates=9850, lr=8.6215e-06, gnorm=5.462, clip=100, loss_scale=64, train_wall=39, gb_free=7.7, wall=38021
2023-05-21 04:31:43 - progress_bar.py[line:272] - INFO: epoch 006:   1218 / 1732 loss=2.49, loss_v1=0, loss_v2=0, nll_loss=1.303, ntokens=1016, nsentences=32, sample_size=1016, sample_size_v1=0, sample_size_v2=0, ppl=2.47, wps=263.9, ups=0.26, wpb=1016, bsz=32, num_updates=9860, lr=8.61945e-06, gnorm=7.29, clip=100, loss_scale=64, train_wall=38, gb_free=8.8, wall=38060
2023-05-21 04:32:21 - progress_bar.py[line:272] - INFO: epoch 006:   1228 / 1732 loss=2.467, loss_v1=0, loss_v2=0, nll_loss=1.277, ntokens=1018.6, nsentences=32, sample_size=1018.6, sample_size_v1=0, sample_size_v2=0, ppl=2.42, wps=264.3, ups=0.26, wpb=1018.6, bsz=32, num_updates=9870, lr=8.61741e-06, gnorm=5.84, clip=100, loss_scale=64, train_wall=38, gb_free=8.6, wall=38098
2023-05-21 04:33:00 - progress_bar.py[line:272] - INFO: epoch 006:   1238 / 1732 loss=2.427, loss_v1=0, loss_v2=0, nll_loss=1.23, ntokens=1070.1, nsentences=32, sample_size=1070.1, sample_size_v1=0, sample_size_v2=0, ppl=2.35, wps=276.4, ups=0.26, wpb=1070.1, bsz=32, num_updates=9880, lr=8.61536e-06, gnorm=6.296, clip=100, loss_scale=64, train_wall=39, gb_free=8.3, wall=38137
2023-05-21 04:33:39 - progress_bar.py[line:272] - INFO: epoch 006:   1248 / 1732 loss=2.421, loss_v1=0, loss_v2=0, nll_loss=1.225, ntokens=1083.3, nsentences=32, sample_size=1083.3, sample_size_v1=0, sample_size_v2=0, ppl=2.34, wps=279.1, ups=0.26, wpb=1083.3, bsz=32, num_updates=9890, lr=8.61331e-06, gnorm=6.151, clip=100, loss_scale=64, train_wall=39, gb_free=8, wall=38176
2023-05-21 04:34:17 - progress_bar.py[line:272] - INFO: epoch 006:   1258 / 1732 loss=2.428, loss_v1=0, loss_v2=0, nll_loss=1.233, ntokens=1058.8, nsentences=32, sample_size=1058.8, sample_size_v1=0, sample_size_v2=0, ppl=2.35, wps=274.1, ups=0.26, wpb=1058.8, bsz=32, num_updates=9900, lr=8.61126e-06, gnorm=6.149, clip=100, loss_scale=64, train_wall=39, gb_free=8.2, wall=38214
2023-05-21 04:34:56 - progress_bar.py[line:272] - INFO: epoch 006:   1268 / 1732 loss=2.467, loss_v1=0, loss_v2=0, nll_loss=1.278, ntokens=1040.1, nsentences=32, sample_size=1040.1, sample_size_v1=0, sample_size_v2=0, ppl=2.42, wps=267.3, ups=0.26, wpb=1040.1, bsz=32, num_updates=9910, lr=8.60922e-06, gnorm=5.966, clip=100, loss_scale=64, train_wall=39, gb_free=8.5, wall=38253
2023-05-21 04:35:35 - progress_bar.py[line:272] - INFO: epoch 006:   1278 / 1732 loss=2.48, loss_v1=0, loss_v2=0, nll_loss=1.292, ntokens=1064.5, nsentences=32, sample_size=1064.5, sample_size_v1=0, sample_size_v2=0, ppl=2.45, wps=274.5, ups=0.26, wpb=1064.5, bsz=32, num_updates=9920, lr=8.60717e-06, gnorm=6.882, clip=100, loss_scale=64, train_wall=39, gb_free=8.6, wall=38292
2023-05-21 04:36:14 - progress_bar.py[line:272] - INFO: epoch 006:   1288 / 1732 loss=2.443, loss_v1=0, loss_v2=0, nll_loss=1.249, ntokens=1074.2, nsentences=32, sample_size=1074.2, sample_size_v1=0, sample_size_v2=0, ppl=2.38, wps=276.4, ups=0.26, wpb=1074.2, bsz=32, num_updates=9930, lr=8.60512e-06, gnorm=5.478, clip=100, loss_scale=64, train_wall=39, gb_free=6.9, wall=38331
2023-05-21 04:36:53 - progress_bar.py[line:272] - INFO: epoch 006:   1298 / 1732 loss=2.444, loss_v1=0, loss_v2=0, nll_loss=1.25, ntokens=1104.5, nsentences=32, sample_size=1104.5, sample_size_v1=0, sample_size_v2=0, ppl=2.38, wps=285.4, ups=0.26, wpb=1104.5, bsz=32, num_updates=9940, lr=8.60308e-06, gnorm=5.783, clip=100, loss_scale=64, train_wall=39, gb_free=7.9, wall=38370
2023-05-21 04:37:31 - progress_bar.py[line:272] - INFO: epoch 006:   1308 / 1732 loss=2.481, loss_v1=0, loss_v2=0, nll_loss=1.293, ntokens=1079.8, nsentences=32, sample_size=1079.8, sample_size_v1=0, sample_size_v2=0, ppl=2.45, wps=277.1, ups=0.26, wpb=1079.8, bsz=32, num_updates=9950, lr=8.60103e-06, gnorm=5.466, clip=100, loss_scale=64, train_wall=39, gb_free=7.5, wall=38409
2023-05-21 04:38:10 - progress_bar.py[line:272] - INFO: epoch 006:   1318 / 1732 loss=2.451, loss_v1=0, loss_v2=0, nll_loss=1.258, ntokens=1085.2, nsentences=32, sample_size=1085.2, sample_size_v1=0, sample_size_v2=0, ppl=2.39, wps=280.3, ups=0.26, wpb=1085.2, bsz=32, num_updates=9960, lr=8.59898e-06, gnorm=6.495, clip=100, loss_scale=64, train_wall=39, gb_free=8.1, wall=38447
2023-05-21 04:38:49 - progress_bar.py[line:272] - INFO: epoch 006:   1328 / 1732 loss=2.421, loss_v1=0, loss_v2=0, nll_loss=1.224, ntokens=1103.2, nsentences=32, sample_size=1103.2, sample_size_v1=0, sample_size_v2=0, ppl=2.34, wps=282.9, ups=0.26, wpb=1103.2, bsz=32, num_updates=9970, lr=8.59693e-06, gnorm=6.248, clip=100, loss_scale=128, train_wall=39, gb_free=8.2, wall=38486
2023-05-21 04:39:05 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2023-05-21 04:39:32 - progress_bar.py[line:272] - INFO: epoch 006:   1339 / 1732 loss=2.448, loss_v1=0, loss_v2=0, nll_loss=1.258, ntokens=1120.9, nsentences=32, sample_size=1120.9, sample_size_v1=0, sample_size_v2=0, ppl=2.39, wps=262.3, ups=0.23, wpb=1120.9, bsz=32, num_updates=9980, lr=8.59489e-06, gnorm=5.87, clip=100, loss_scale=64, train_wall=43, gb_free=8.2, wall=38529
2023-05-21 04:40:11 - progress_bar.py[line:272] - INFO: epoch 006:   1349 / 1732 loss=2.438, loss_v1=0, loss_v2=0, nll_loss=1.243, ntokens=1187.2, nsentences=32, sample_size=1187.2, sample_size_v1=0, sample_size_v2=0, ppl=2.37, wps=304.1, ups=0.26, wpb=1187.2, bsz=32, num_updates=9990, lr=8.59284e-06, gnorm=6.049, clip=100, loss_scale=64, train_wall=39, gb_free=8.5, wall=38568
2023-05-21 04:40:50 - progress_bar.py[line:272] - INFO: epoch 006:   1359 / 1732 loss=2.419, loss_v1=0, loss_v2=0, nll_loss=1.224, ntokens=1104.5, nsentences=32, sample_size=1104.5, sample_size_v1=0, sample_size_v2=0, ppl=2.34, wps=283.7, ups=0.26, wpb=1104.5, bsz=32, num_updates=10000, lr=8.59079e-06, gnorm=5.515, clip=100, loss_scale=64, train_wall=39, gb_free=8.3, wall=38607
2023-05-21 04:41:29 - progress_bar.py[line:272] - INFO: epoch 006:   1369 / 1732 loss=2.474, loss_v1=0, loss_v2=0, nll_loss=1.285, ntokens=1096, nsentences=32, sample_size=1096, sample_size_v1=0, sample_size_v2=0, ppl=2.44, wps=279.6, ups=0.26, wpb=1096, bsz=32, num_updates=10010, lr=8.58874e-06, gnorm=5.725, clip=100, loss_scale=64, train_wall=39, gb_free=8, wall=38646
2023-05-21 04:42:08 - progress_bar.py[line:272] - INFO: epoch 006:   1379 / 1732 loss=2.464, loss_v1=0, loss_v2=0, nll_loss=1.272, ntokens=1115.7, nsentences=32, sample_size=1115.7, sample_size_v1=0, sample_size_v2=0, ppl=2.42, wps=288.1, ups=0.26, wpb=1115.7, bsz=32, num_updates=10020, lr=8.5867e-06, gnorm=6.702, clip=100, loss_scale=64, train_wall=39, gb_free=8.6, wall=38685
2023-05-21 04:42:46 - progress_bar.py[line:272] - INFO: epoch 006:   1389 / 1732 loss=2.456, loss_v1=0, loss_v2=0, nll_loss=1.264, ntokens=1122.1, nsentences=32, sample_size=1122.1, sample_size_v1=0, sample_size_v2=0, ppl=2.4, wps=291.5, ups=0.26, wpb=1122.1, bsz=32, num_updates=10030, lr=8.58465e-06, gnorm=6.049, clip=100, loss_scale=64, train_wall=38, gb_free=8.6, wall=38724
2023-05-21 04:43:25 - progress_bar.py[line:272] - INFO: epoch 006:   1399 / 1732 loss=2.425, loss_v1=0, loss_v2=0, nll_loss=1.231, ntokens=1113, nsentences=32, sample_size=1113, sample_size_v1=0, sample_size_v2=0, ppl=2.35, wps=287.1, ups=0.26, wpb=1113, bsz=32, num_updates=10040, lr=8.5826e-06, gnorm=5.958, clip=100, loss_scale=64, train_wall=39, gb_free=8.2, wall=38762
2023-05-21 04:44:04 - progress_bar.py[line:272] - INFO: epoch 006:   1409 / 1732 loss=2.472, loss_v1=0, loss_v2=0, nll_loss=1.282, ntokens=1156.6, nsentences=32, sample_size=1156.6, sample_size_v1=0, sample_size_v2=0, ppl=2.43, wps=298, ups=0.26, wpb=1156.6, bsz=32, num_updates=10050, lr=8.58055e-06, gnorm=5.332, clip=100, loss_scale=64, train_wall=39, gb_free=8.3, wall=38801
2023-05-21 04:44:43 - progress_bar.py[line:272] - INFO: epoch 006:   1419 / 1732 loss=2.466, loss_v1=0, loss_v2=0, nll_loss=1.276, ntokens=1290.6, nsentences=32, sample_size=1290.6, sample_size_v1=0, sample_size_v2=0, ppl=2.42, wps=327.2, ups=0.25, wpb=1290.6, bsz=32, num_updates=10060, lr=8.57851e-06, gnorm=5.402, clip=100, loss_scale=64, train_wall=39, gb_free=7.6, wall=38841
2023-05-21 04:45:23 - progress_bar.py[line:272] - INFO: epoch 006:   1429 / 1732 loss=2.43, loss_v1=0, loss_v2=0, nll_loss=1.235, ntokens=1226.2, nsentences=32, sample_size=1226.2, sample_size_v1=0, sample_size_v2=0, ppl=2.35, wps=313.1, ups=0.26, wpb=1226.2, bsz=32, num_updates=10070, lr=8.57646e-06, gnorm=5.377, clip=100, loss_scale=64, train_wall=39, gb_free=8.4, wall=38880
2023-05-21 04:46:02 - progress_bar.py[line:272] - INFO: epoch 006:   1439 / 1732 loss=2.432, loss_v1=0, loss_v2=0, nll_loss=1.237, ntokens=1192.7, nsentences=32, sample_size=1192.7, sample_size_v1=0, sample_size_v2=0, ppl=2.36, wps=306.1, ups=0.26, wpb=1192.7, bsz=32, num_updates=10080, lr=8.57441e-06, gnorm=5.111, clip=100, loss_scale=64, train_wall=39, gb_free=8.2, wall=38919
2023-05-21 04:46:40 - progress_bar.py[line:272] - INFO: epoch 006:   1449 / 1732 loss=2.467, loss_v1=0, loss_v2=0, nll_loss=1.275, ntokens=1089.5, nsentences=32, sample_size=1089.5, sample_size_v1=0, sample_size_v2=0, ppl=2.42, wps=280.9, ups=0.26, wpb=1089.5, bsz=32, num_updates=10090, lr=8.57236e-06, gnorm=5.999, clip=100, loss_scale=64, train_wall=39, gb_free=8.6, wall=38958
2023-05-21 04:47:19 - progress_bar.py[line:272] - INFO: epoch 006:   1459 / 1732 loss=2.435, loss_v1=0, loss_v2=0, nll_loss=1.24, ntokens=1160, nsentences=32, sample_size=1160, sample_size_v1=0, sample_size_v2=0, ppl=2.36, wps=297.1, ups=0.26, wpb=1160, bsz=32, num_updates=10100, lr=8.57032e-06, gnorm=6.179, clip=100, loss_scale=64, train_wall=39, gb_free=8.3, wall=38997
2023-05-21 04:47:58 - progress_bar.py[line:272] - INFO: epoch 006:   1469 / 1732 loss=2.438, loss_v1=0, loss_v2=0, nll_loss=1.246, ntokens=1187.1, nsentences=32, sample_size=1187.1, sample_size_v1=0, sample_size_v2=0, ppl=2.37, wps=304.9, ups=0.26, wpb=1187.1, bsz=32, num_updates=10110, lr=8.56827e-06, gnorm=5.794, clip=100, loss_scale=64, train_wall=39, gb_free=8.5, wall=39035
2023-05-21 04:48:37 - progress_bar.py[line:272] - INFO: epoch 006:   1479 / 1732 loss=2.467, loss_v1=0, loss_v2=0, nll_loss=1.277, ntokens=1029.5, nsentences=32, sample_size=1029.5, sample_size_v1=0, sample_size_v2=0, ppl=2.42, wps=266.3, ups=0.26, wpb=1029.5, bsz=32, num_updates=10120, lr=8.56622e-06, gnorm=6.334, clip=100, loss_scale=64, train_wall=39, gb_free=8.1, wall=39074
2023-05-21 04:49:16 - progress_bar.py[line:272] - INFO: epoch 006:   1489 / 1732 loss=2.451, loss_v1=0, loss_v2=0, nll_loss=1.257, ntokens=1147, nsentences=32, sample_size=1147, sample_size_v1=0, sample_size_v2=0, ppl=2.39, wps=294.5, ups=0.26, wpb=1147, bsz=32, num_updates=10130, lr=8.56418e-06, gnorm=5.042, clip=100, loss_scale=64, train_wall=39, gb_free=8.4, wall=39113
2023-05-21 04:49:55 - progress_bar.py[line:272] - INFO: epoch 006:   1499 / 1732 loss=2.427, loss_v1=0, loss_v2=0, nll_loss=1.231, ntokens=1095.4, nsentences=32, sample_size=1095.4, sample_size_v1=0, sample_size_v2=0, ppl=2.35, wps=283.7, ups=0.26, wpb=1095.4, bsz=32, num_updates=10140, lr=8.56213e-06, gnorm=5.488, clip=100, loss_scale=64, train_wall=39, gb_free=7.9, wall=39152
2023-05-21 04:50:33 - progress_bar.py[line:272] - INFO: epoch 006:   1509 / 1732 loss=2.4, loss_v1=0, loss_v2=0, nll_loss=1.205, ntokens=1114.3, nsentences=32, sample_size=1114.3, sample_size_v1=0, sample_size_v2=0, ppl=2.31, wps=289.2, ups=0.26, wpb=1114.3, bsz=32, num_updates=10150, lr=8.56008e-06, gnorm=5.652, clip=100, loss_scale=64, train_wall=38, gb_free=8.4, wall=39190
2023-05-21 04:51:12 - progress_bar.py[line:272] - INFO: epoch 006:   1519 / 1732 loss=2.477, loss_v1=0, loss_v2=0, nll_loss=1.289, ntokens=1050.9, nsentences=32, sample_size=1050.9, sample_size_v1=0, sample_size_v2=0, ppl=2.44, wps=272.4, ups=0.26, wpb=1050.9, bsz=32, num_updates=10160, lr=8.55803e-06, gnorm=5.532, clip=100, loss_scale=64, train_wall=39, gb_free=8.6, wall=39229
2023-05-21 04:51:50 - progress_bar.py[line:272] - INFO: epoch 006:   1529 / 1732 loss=2.486, loss_v1=0, loss_v2=0, nll_loss=1.294, ntokens=1056.3, nsentences=32, sample_size=1056.3, sample_size_v1=0, sample_size_v2=0, ppl=2.45, wps=274.3, ups=0.26, wpb=1056.3, bsz=32, num_updates=10170, lr=8.55599e-06, gnorm=5.934, clip=100, loss_scale=64, train_wall=38, gb_free=8.2, wall=39267
2023-05-21 04:52:29 - progress_bar.py[line:272] - INFO: epoch 006:   1539 / 1732 loss=2.455, loss_v1=0, loss_v2=0, nll_loss=1.261, ntokens=1083.3, nsentences=32, sample_size=1083.3, sample_size_v1=0, sample_size_v2=0, ppl=2.4, wps=278.3, ups=0.26, wpb=1083.3, bsz=32, num_updates=10180, lr=8.55394e-06, gnorm=6.035, clip=100, loss_scale=64, train_wall=39, gb_free=8.1, wall=39306
2023-05-21 04:53:08 - progress_bar.py[line:272] - INFO: epoch 006:   1549 / 1732 loss=2.424, loss_v1=0, loss_v2=0, nll_loss=1.23, ntokens=1075, nsentences=32, sample_size=1075, sample_size_v1=0, sample_size_v2=0, ppl=2.35, wps=279, ups=0.26, wpb=1075, bsz=32, num_updates=10190, lr=8.55189e-06, gnorm=6.359, clip=100, loss_scale=64, train_wall=38, gb_free=8.7, wall=39345
2023-05-21 04:53:46 - progress_bar.py[line:272] - INFO: epoch 006:   1559 / 1732 loss=2.443, loss_v1=0, loss_v2=0, nll_loss=1.251, ntokens=1092, nsentences=32, sample_size=1092, sample_size_v1=0, sample_size_v2=0, ppl=2.38, wps=281.2, ups=0.26, wpb=1092, bsz=32, num_updates=10200, lr=8.54984e-06, gnorm=6.074, clip=100, loss_scale=64, train_wall=39, gb_free=8.5, wall=39384
2023-05-21 04:54:25 - progress_bar.py[line:272] - INFO: epoch 006:   1569 / 1732 loss=2.491, loss_v1=0, loss_v2=0, nll_loss=1.305, ntokens=1059.1, nsentences=32, sample_size=1059.1, sample_size_v1=0, sample_size_v2=0, ppl=2.47, wps=273.7, ups=0.26, wpb=1059.1, bsz=32, num_updates=10210, lr=8.5478e-06, gnorm=6.545, clip=100, loss_scale=64, train_wall=39, gb_free=8, wall=39422
2023-05-21 04:55:04 - progress_bar.py[line:272] - INFO: epoch 006:   1579 / 1732 loss=2.479, loss_v1=0, loss_v2=0, nll_loss=1.287, ntokens=1008.7, nsentences=32, sample_size=1008.7, sample_size_v1=0, sample_size_v2=0, ppl=2.44, wps=262.5, ups=0.26, wpb=1008.7, bsz=32, num_updates=10220, lr=8.54575e-06, gnorm=7.234, clip=100, loss_scale=64, train_wall=38, gb_free=8.3, wall=39461
2023-05-21 04:55:42 - progress_bar.py[line:272] - INFO: epoch 006:   1589 / 1732 loss=2.459, loss_v1=0, loss_v2=0, nll_loss=1.266, ntokens=1092.2, nsentences=32, sample_size=1092.2, sample_size_v1=0, sample_size_v2=0, ppl=2.41, wps=282.3, ups=0.26, wpb=1092.2, bsz=32, num_updates=10230, lr=8.5437e-06, gnorm=6.181, clip=100, loss_scale=64, train_wall=39, gb_free=8.6, wall=39499
2023-05-21 04:56:21 - progress_bar.py[line:272] - INFO: epoch 006:   1599 / 1732 loss=2.432, loss_v1=0, loss_v2=0, nll_loss=1.239, ntokens=1061.1, nsentences=32, sample_size=1061.1, sample_size_v1=0, sample_size_v2=0, ppl=2.36, wps=274.2, ups=0.26, wpb=1061.1, bsz=32, num_updates=10240, lr=8.54165e-06, gnorm=5.413, clip=100, loss_scale=64, train_wall=39, gb_free=8.4, wall=39538
2023-05-21 04:57:00 - progress_bar.py[line:272] - INFO: epoch 006:   1609 / 1732 loss=2.425, loss_v1=0, loss_v2=0, nll_loss=1.23, ntokens=1155.5, nsentences=32, sample_size=1155.5, sample_size_v1=0, sample_size_v2=0, ppl=2.34, wps=295.5, ups=0.26, wpb=1155.5, bsz=32, num_updates=10250, lr=8.53961e-06, gnorm=5.339, clip=100, loss_scale=64, train_wall=39, gb_free=7.8, wall=39577
2023-05-21 04:57:39 - progress_bar.py[line:272] - INFO: epoch 006:   1619 / 1732 loss=2.398, loss_v1=0, loss_v2=0, nll_loss=1.198, ntokens=1123.8, nsentences=32, sample_size=1123.8, sample_size_v1=0, sample_size_v2=0, ppl=2.29, wps=289.2, ups=0.26, wpb=1123.8, bsz=32, num_updates=10260, lr=8.53756e-06, gnorm=6.33, clip=100, loss_scale=64, train_wall=39, gb_free=8, wall=39616
2023-05-21 04:58:18 - progress_bar.py[line:272] - INFO: epoch 006:   1629 / 1732 loss=2.442, loss_v1=0, loss_v2=0, nll_loss=1.251, ntokens=1172.3, nsentences=32, sample_size=1172.3, sample_size_v1=0, sample_size_v2=0, ppl=2.38, wps=300.4, ups=0.26, wpb=1172.3, bsz=32, num_updates=10270, lr=8.53551e-06, gnorm=5.983, clip=100, loss_scale=64, train_wall=39, gb_free=8.3, wall=39655
2023-05-21 04:58:57 - progress_bar.py[line:272] - INFO: epoch 006:   1639 / 1732 loss=2.414, loss_v1=0, loss_v2=0, nll_loss=1.215, ntokens=1139.8, nsentences=32, sample_size=1139.8, sample_size_v1=0, sample_size_v2=0, ppl=2.32, wps=295.7, ups=0.26, wpb=1139.8, bsz=32, num_updates=10280, lr=8.53346e-06, gnorm=5.334, clip=100, loss_scale=64, train_wall=39, gb_free=7.8, wall=39694
2023-05-21 04:59:36 - progress_bar.py[line:272] - INFO: epoch 006:   1649 / 1732 loss=2.416, loss_v1=0, loss_v2=0, nll_loss=1.218, ntokens=1200.9, nsentences=32, sample_size=1200.9, sample_size_v1=0, sample_size_v2=0, ppl=2.33, wps=307.7, ups=0.26, wpb=1200.9, bsz=32, num_updates=10290, lr=8.53142e-06, gnorm=5.618, clip=100, loss_scale=64, train_wall=39, gb_free=8.5, wall=39733
2023-05-21 05:00:14 - progress_bar.py[line:272] - INFO: epoch 006:   1659 / 1732 loss=2.473, loss_v1=0, loss_v2=0, nll_loss=1.286, ntokens=965.2, nsentences=32, sample_size=965.2, sample_size_v1=0, sample_size_v2=0, ppl=2.44, wps=251.7, ups=0.26, wpb=965.2, bsz=32, num_updates=10300, lr=8.52937e-06, gnorm=6.711, clip=100, loss_scale=64, train_wall=38, gb_free=8.6, wall=39771
2023-05-21 05:00:53 - progress_bar.py[line:272] - INFO: epoch 006:   1669 / 1732 loss=2.442, loss_v1=0, loss_v2=0, nll_loss=1.249, ntokens=1018.2, nsentences=32, sample_size=1018.2, sample_size_v1=0, sample_size_v2=0, ppl=2.38, wps=263.6, ups=0.26, wpb=1018.2, bsz=32, num_updates=10310, lr=8.52732e-06, gnorm=5.823, clip=100, loss_scale=64, train_wall=39, gb_free=9, wall=39810
2023-05-21 05:01:32 - progress_bar.py[line:272] - INFO: epoch 006:   1679 / 1732 loss=2.398, loss_v1=0, loss_v2=0, nll_loss=1.197, ntokens=1155.9, nsentences=32, sample_size=1155.9, sample_size_v1=0, sample_size_v2=0, ppl=2.29, wps=295.3, ups=0.26, wpb=1155.9, bsz=32, num_updates=10320, lr=8.52527e-06, gnorm=5.056, clip=100, loss_scale=64, train_wall=39, gb_free=8, wall=39849
2023-05-21 05:02:11 - progress_bar.py[line:272] - INFO: epoch 006:   1689 / 1732 loss=2.435, loss_v1=0, loss_v2=0, nll_loss=1.245, ntokens=1198.6, nsentences=32, sample_size=1198.6, sample_size_v1=0, sample_size_v2=0, ppl=2.37, wps=305.8, ups=0.26, wpb=1198.6, bsz=32, num_updates=10330, lr=8.52323e-06, gnorm=4.998, clip=100, loss_scale=64, train_wall=39, gb_free=7.4, wall=39888
2023-05-21 05:02:50 - progress_bar.py[line:272] - INFO: epoch 006:   1699 / 1732 loss=2.418, loss_v1=0, loss_v2=0, nll_loss=1.22, ntokens=1300, nsentences=32, sample_size=1300, sample_size_v1=0, sample_size_v2=0, ppl=2.33, wps=328.4, ups=0.25, wpb=1300, bsz=32, num_updates=10340, lr=8.52118e-06, gnorm=5.102, clip=100, loss_scale=64, train_wall=40, gb_free=7.8, wall=39928
2023-05-21 05:03:30 - progress_bar.py[line:272] - INFO: epoch 006:   1709 / 1732 loss=2.45, loss_v1=0, loss_v2=0, nll_loss=1.255, ntokens=1178.3, nsentences=32, sample_size=1178.3, sample_size_v1=0, sample_size_v2=0, ppl=2.39, wps=301.7, ups=0.26, wpb=1178.3, bsz=32, num_updates=10350, lr=8.51913e-06, gnorm=5.538, clip=100, loss_scale=64, train_wall=39, gb_free=8.5, wall=39967
2023-05-21 05:04:09 - progress_bar.py[line:272] - INFO: epoch 006:   1719 / 1732 loss=2.417, loss_v1=0, loss_v2=0, nll_loss=1.222, ntokens=1171.3, nsentences=32, sample_size=1171.3, sample_size_v1=0, sample_size_v2=0, ppl=2.33, wps=300, ups=0.26, wpb=1171.3, bsz=32, num_updates=10360, lr=8.51709e-06, gnorm=5.388, clip=100, loss_scale=64, train_wall=39, gb_free=8.1, wall=40006
2023-05-21 05:04:47 - progress_bar.py[line:272] - INFO: epoch 006:   1729 / 1732 loss=2.474, loss_v1=0, loss_v2=0, nll_loss=1.283, ntokens=1095.7, nsentences=32, sample_size=1095.7, sample_size_v1=0, sample_size_v2=0, ppl=2.43, wps=282.6, ups=0.26, wpb=1095.7, bsz=32, num_updates=10370, lr=8.51504e-06, gnorm=5.55, clip=100, loss_scale=64, train_wall=39, gb_free=8.4, wall=40045
2023-05-21 05:04:56 - train.py[line:332] - INFO: end of epoch 6 (average epoch stats below)
2023-05-21 05:04:56 - progress_bar.py[line:282] - INFO: epoch 006 | loss 2.454 | loss_v1 0 | loss_v2 0 | nll_loss 1.262 | ntokens 1051.59 | nsentences 31.986 | sample_size 1051.59 | sample_size_v1 0 | sample_size_v2 0 | ppl 2.4 | wps 272.6 | ups 0.26 | wpb 1051.6 | bsz 32 | num_updates 10373 | lr 8.51442e-06 | gnorm 5.576 | clip 100 | loss_scale 64 | train_wall 6659 | gb_free 8.9 | wall 40053
2023-05-21 05:04:56 - trainer.py[line:639] - INFO: loading train data for epoch 7
local datafile ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 0 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 0 finished initializing row_count and line_idx-to-offset mapping
file ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 0 row count 55400 total row count 55400
slice_id 0 seek offset 0
2023-05-21 05:04:58 - trainer.py[line:703] - INFO: begin training epoch 7
2023-05-21 05:04:58 - train.py[line:305] - INFO: Start iterating over samples
2023-05-21 05:05:25 - progress_bar.py[line:272] - INFO: epoch 007:      7 / 1732 loss=2.387, loss_v1=0, loss_v2=0, nll_loss=1.183, ntokens=1093.3, nsentences=29.6, sample_size=1093.3, sample_size_v1=0, sample_size_v2=0, ppl=2.27, wps=286.6, ups=0.26, wpb=1093.3, bsz=29.6, num_updates=10380, lr=8.51299e-06, gnorm=5.907, clip=100, loss_scale=64, train_wall=36, gb_free=8.4, wall=40083
2023-05-21 05:06:04 - progress_bar.py[line:272] - INFO: epoch 007:     17 / 1732 loss=2.36, loss_v1=0, loss_v2=0, nll_loss=1.159, ntokens=1095.7, nsentences=32, sample_size=1095.7, sample_size_v1=0, sample_size_v2=0, ppl=2.23, wps=282, ups=0.26, wpb=1095.7, bsz=32, num_updates=10390, lr=8.51094e-06, gnorm=6.268, clip=100, loss_scale=64, train_wall=39, gb_free=8.2, wall=40122
2023-05-21 05:06:43 - progress_bar.py[line:272] - INFO: epoch 007:     27 / 1732 loss=2.408, loss_v1=0, loss_v2=0, nll_loss=1.208, ntokens=954.5, nsentences=32, sample_size=954.5, sample_size_v1=0, sample_size_v2=0, ppl=2.31, wps=247.4, ups=0.26, wpb=954.5, bsz=32, num_updates=10400, lr=8.5089e-06, gnorm=6.087, clip=100, loss_scale=64, train_wall=39, gb_free=7.9, wall=40160
2023-05-21 05:07:22 - progress_bar.py[line:272] - INFO: epoch 007:     37 / 1732 loss=2.232, loss_v1=0, loss_v2=0, nll_loss=1.012, ntokens=1179.3, nsentences=32, sample_size=1179.3, sample_size_v1=0, sample_size_v2=0, ppl=2.02, wps=301.7, ups=0.26, wpb=1179.3, bsz=32, num_updates=10410, lr=8.50685e-06, gnorm=5.16, clip=100, loss_scale=64, train_wall=39, gb_free=8.5, wall=40199
2023-05-21 05:08:01 - progress_bar.py[line:272] - INFO: epoch 007:     47 / 1732 loss=2.278, loss_v1=0, loss_v2=0, nll_loss=1.07, ntokens=1055.1, nsentences=32, sample_size=1055.1, sample_size_v1=0, sample_size_v2=0, ppl=2.1, wps=272.7, ups=0.26, wpb=1055.1, bsz=32, num_updates=10420, lr=8.5048e-06, gnorm=4.996, clip=100, loss_scale=64, train_wall=39, gb_free=7.9, wall=40238
2023-05-21 05:08:39 - progress_bar.py[line:272] - INFO: epoch 007:     57 / 1732 loss=2.176, loss_v1=0, loss_v2=0, nll_loss=0.946, ntokens=1048.7, nsentences=32, sample_size=1048.7, sample_size_v1=0, sample_size_v2=0, ppl=1.93, wps=271, ups=0.26, wpb=1048.7, bsz=32, num_updates=10430, lr=8.50275e-06, gnorm=4.783, clip=100, loss_scale=64, train_wall=39, gb_free=8.4, wall=40277
2023-05-21 05:09:19 - progress_bar.py[line:272] - INFO: epoch 007:     67 / 1732 loss=2.078, loss_v1=0, loss_v2=0, nll_loss=0.846, ntokens=1356.1, nsentences=32, sample_size=1356.1, sample_size_v1=0, sample_size_v2=0, ppl=1.8, wps=340.9, ups=0.25, wpb=1356.1, bsz=32, num_updates=10440, lr=8.50071e-06, gnorm=3.681, clip=100, loss_scale=64, train_wall=40, gb_free=7.3, wall=40316
2023-05-21 05:09:59 - progress_bar.py[line:272] - INFO: epoch 007:     77 / 1732 loss=2.223, loss_v1=0, loss_v2=0, nll_loss=0.998, ntokens=1273.9, nsentences=32, sample_size=1273.9, sample_size_v1=0, sample_size_v2=0, ppl=2, wps=320.5, ups=0.25, wpb=1273.9, bsz=32, num_updates=10450, lr=8.49866e-06, gnorm=4.877, clip=100, loss_scale=64, train_wall=40, gb_free=8.2, wall=40356
2023-05-21 05:10:38 - progress_bar.py[line:272] - INFO: epoch 007:     87 / 1732 loss=2.294, loss_v1=0, loss_v2=0, nll_loss=1.088, ntokens=1141.2, nsentences=32, sample_size=1141.2, sample_size_v1=0, sample_size_v2=0, ppl=2.13, wps=290.4, ups=0.25, wpb=1141.2, bsz=32, num_updates=10460, lr=8.49661e-06, gnorm=4, clip=100, loss_scale=64, train_wall=39, gb_free=7.7, wall=40395
2023-05-21 05:11:17 - progress_bar.py[line:272] - INFO: epoch 007:     97 / 1732 loss=2.246, loss_v1=0, loss_v2=0, nll_loss=1.023, ntokens=1080.1, nsentences=32, sample_size=1080.1, sample_size_v1=0, sample_size_v2=0, ppl=2.03, wps=277.3, ups=0.26, wpb=1080.1, bsz=32, num_updates=10470, lr=8.49456e-06, gnorm=4.375, clip=100, loss_scale=64, train_wall=39, gb_free=7, wall=40434
2023-05-21 05:11:56 - progress_bar.py[line:272] - INFO: epoch 007:    107 / 1732 loss=2.424, loss_v1=0, loss_v2=0, nll_loss=1.236, ntokens=981.4, nsentences=32, sample_size=981.4, sample_size_v1=0, sample_size_v2=0, ppl=2.35, wps=253.9, ups=0.26, wpb=981.4, bsz=32, num_updates=10480, lr=8.49252e-06, gnorm=4.771, clip=100, loss_scale=64, train_wall=39, gb_free=7.7, wall=40473
2023-05-21 05:12:35 - progress_bar.py[line:272] - INFO: epoch 007:    117 / 1732 loss=2.453, loss_v1=0, loss_v2=0, nll_loss=1.26, ntokens=1060.7, nsentences=32, sample_size=1060.7, sample_size_v1=0, sample_size_v2=0, ppl=2.39, wps=272.5, ups=0.26, wpb=1060.7, bsz=32, num_updates=10490, lr=8.49047e-06, gnorm=4.495, clip=100, loss_scale=128, train_wall=39, gb_free=7.7, wall=40512
2023-05-21 05:13:14 - progress_bar.py[line:272] - INFO: epoch 007:    127 / 1732 loss=2.392, loss_v1=0, loss_v2=0, nll_loss=1.188, ntokens=1185.5, nsentences=32, sample_size=1185.5, sample_size_v1=0, sample_size_v2=0, ppl=2.28, wps=300.9, ups=0.25, wpb=1185.5, bsz=32, num_updates=10500, lr=8.48842e-06, gnorm=4.476, clip=100, loss_scale=128, train_wall=39, gb_free=8.2, wall=40551
2023-05-21 05:13:53 - progress_bar.py[line:272] - INFO: epoch 007:    137 / 1732 loss=2.363, loss_v1=0, loss_v2=0, nll_loss=1.16, ntokens=1222.2, nsentences=32, sample_size=1222.2, sample_size_v1=0, sample_size_v2=0, ppl=2.23, wps=312.2, ups=0.26, wpb=1222.2, bsz=32, num_updates=10510, lr=8.48637e-06, gnorm=4.197, clip=100, loss_scale=128, train_wall=39, gb_free=8.2, wall=40591
2023-05-21 05:14:33 - progress_bar.py[line:272] - INFO: epoch 007:    147 / 1732 loss=2.326, loss_v1=0, loss_v2=0, nll_loss=1.119, ntokens=1207.1, nsentences=32, sample_size=1207.1, sample_size_v1=0, sample_size_v2=0, ppl=2.17, wps=305.6, ups=0.25, wpb=1207.1, bsz=32, num_updates=10520, lr=8.48433e-06, gnorm=4.024, clip=100, loss_scale=128, train_wall=39, gb_free=8, wall=40630
2023-05-21 05:15:12 - progress_bar.py[line:272] - INFO: epoch 007:    157 / 1732 loss=2.372, loss_v1=0, loss_v2=0, nll_loss=1.169, ntokens=1172.8, nsentences=32, sample_size=1172.8, sample_size_v1=0, sample_size_v2=0, ppl=2.25, wps=296.4, ups=0.25, wpb=1172.8, bsz=32, num_updates=10530, lr=8.48228e-06, gnorm=4.538, clip=100, loss_scale=128, train_wall=40, gb_free=8, wall=40670
2023-05-21 05:15:51 - progress_bar.py[line:272] - INFO: epoch 007:    167 / 1732 loss=2.337, loss_v1=0, loss_v2=0, nll_loss=1.132, ntokens=1009.5, nsentences=32, sample_size=1009.5, sample_size_v1=0, sample_size_v2=0, ppl=2.19, wps=260.9, ups=0.26, wpb=1009.5, bsz=32, num_updates=10540, lr=8.48023e-06, gnorm=4.91, clip=100, loss_scale=128, train_wall=39, gb_free=7.3, wall=40708
2023-05-21 05:16:30 - progress_bar.py[line:272] - INFO: epoch 007:    177 / 1732 loss=2.342, loss_v1=0, loss_v2=0, nll_loss=1.137, ntokens=994.5, nsentences=32, sample_size=994.5, sample_size_v1=0, sample_size_v2=0, ppl=2.2, wps=257.3, ups=0.26, wpb=994.5, bsz=32, num_updates=10550, lr=8.47819e-06, gnorm=5.137, clip=100, loss_scale=128, train_wall=39, gb_free=8, wall=40747
2023-05-21 05:17:09 - progress_bar.py[line:272] - INFO: epoch 007:    187 / 1732 loss=2.302, loss_v1=0, loss_v2=0, nll_loss=1.091, ntokens=1141.8, nsentences=32, sample_size=1141.8, sample_size_v1=0, sample_size_v2=0, ppl=2.13, wps=291.5, ups=0.26, wpb=1141.8, bsz=32, num_updates=10560, lr=8.47614e-06, gnorm=4.494, clip=100, loss_scale=128, train_wall=39, gb_free=7.6, wall=40786
2023-05-21 05:17:48 - progress_bar.py[line:272] - INFO: epoch 007:    197 / 1732 loss=2.361, loss_v1=0, loss_v2=0, nll_loss=1.159, ntokens=1173.2, nsentences=32, sample_size=1173.2, sample_size_v1=0, sample_size_v2=0, ppl=2.23, wps=299.4, ups=0.26, wpb=1173.2, bsz=32, num_updates=10570, lr=8.47409e-06, gnorm=4.499, clip=100, loss_scale=128, train_wall=39, gb_free=8.5, wall=40825
2023-05-21 05:18:26 - progress_bar.py[line:272] - INFO: epoch 007:    207 / 1732 loss=2.475, loss_v1=0, loss_v2=0, nll_loss=1.286, ntokens=957.1, nsentences=32, sample_size=957.1, sample_size_v1=0, sample_size_v2=0, ppl=2.44, wps=251.6, ups=0.26, wpb=957.1, bsz=32, num_updates=10580, lr=8.47204e-06, gnorm=6.178, clip=100, loss_scale=128, train_wall=38, gb_free=7.8, wall=40863
2023-05-21 05:19:05 - progress_bar.py[line:272] - INFO: epoch 007:    217 / 1732 loss=2.488, loss_v1=0, loss_v2=0, nll_loss=1.299, ntokens=1157.1, nsentences=32, sample_size=1157.1, sample_size_v1=0, sample_size_v2=0, ppl=2.46, wps=301.2, ups=0.26, wpb=1157.1, bsz=32, num_updates=10590, lr=8.47e-06, gnorm=5.122, clip=100, loss_scale=128, train_wall=38, gb_free=8.4, wall=40902
2023-05-21 05:19:43 - progress_bar.py[line:272] - INFO: epoch 007:    227 / 1732 loss=2.473, loss_v1=0, loss_v2=0, nll_loss=1.283, ntokens=1106.8, nsentences=32, sample_size=1106.8, sample_size_v1=0, sample_size_v2=0, ppl=2.43, wps=288.9, ups=0.26, wpb=1106.8, bsz=32, num_updates=10600, lr=8.46795e-06, gnorm=5.693, clip=100, loss_scale=128, train_wall=38, gb_free=8, wall=40940
2023-05-21 05:20:21 - progress_bar.py[line:272] - INFO: epoch 007:    237 / 1732 loss=2.528, loss_v1=0, loss_v2=0, nll_loss=1.343, ntokens=1060.1, nsentences=32, sample_size=1060.1, sample_size_v1=0, sample_size_v2=0, ppl=2.54, wps=278.3, ups=0.26, wpb=1060.1, bsz=32, num_updates=10610, lr=8.4659e-06, gnorm=6.266, clip=100, loss_scale=128, train_wall=38, gb_free=7.8, wall=40978
2023-05-21 05:20:59 - progress_bar.py[line:272] - INFO: epoch 007:    247 / 1732 loss=2.495, loss_v1=0, loss_v2=0, nll_loss=1.305, ntokens=1188.4, nsentences=32, sample_size=1188.4, sample_size_v1=0, sample_size_v2=0, ppl=2.47, wps=308.9, ups=0.26, wpb=1188.4, bsz=32, num_updates=10620, lr=8.46385e-06, gnorm=5.37, clip=100, loss_scale=128, train_wall=38, gb_free=8.1, wall=41017
2023-05-21 05:21:38 - progress_bar.py[line:272] - INFO: epoch 007:    257 / 1732 loss=2.495, loss_v1=0, loss_v2=0, nll_loss=1.308, ntokens=1118.5, nsentences=32, sample_size=1118.5, sample_size_v1=0, sample_size_v2=0, ppl=2.48, wps=290.6, ups=0.26, wpb=1118.5, bsz=32, num_updates=10630, lr=8.46181e-06, gnorm=5.51, clip=100, loss_scale=128, train_wall=38, gb_free=8.4, wall=41055
2023-05-21 05:22:16 - progress_bar.py[line:272] - INFO: epoch 007:    267 / 1732 loss=2.484, loss_v1=0, loss_v2=0, nll_loss=1.296, ntokens=1162.2, nsentences=32, sample_size=1162.2, sample_size_v1=0, sample_size_v2=0, ppl=2.45, wps=303.1, ups=0.26, wpb=1162.2, bsz=32, num_updates=10640, lr=8.45976e-06, gnorm=5.097, clip=100, loss_scale=128, train_wall=38, gb_free=8.4, wall=41094
2023-05-21 05:22:55 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2023-05-21 05:22:59 - progress_bar.py[line:272] - INFO: epoch 007:    278 / 1732 loss=2.496, loss_v1=0, loss_v2=0, nll_loss=1.309, ntokens=1124.2, nsentences=32, sample_size=1124.2, sample_size_v1=0, sample_size_v2=0, ppl=2.48, wps=266.4, ups=0.24, wpb=1124.2, bsz=32, num_updates=10650, lr=8.45771e-06, gnorm=5.861, clip=100, loss_scale=64, train_wall=42, gb_free=8.4, wall=41136
2023-05-21 05:23:37 - progress_bar.py[line:272] - INFO: epoch 007:    288 / 1732 loss=2.469, loss_v1=0, loss_v2=0, nll_loss=1.28, ntokens=1173.3, nsentences=32, sample_size=1173.3, sample_size_v1=0, sample_size_v2=0, ppl=2.43, wps=302.9, ups=0.26, wpb=1173.3, bsz=32, num_updates=10660, lr=8.45566e-06, gnorm=4.988, clip=100, loss_scale=64, train_wall=39, gb_free=8.6, wall=41174
2023-05-21 05:24:16 - progress_bar.py[line:272] - INFO: epoch 007:    298 / 1732 loss=2.493, loss_v1=0, loss_v2=0, nll_loss=1.305, ntokens=1074.2, nsentences=32, sample_size=1074.2, sample_size_v1=0, sample_size_v2=0, ppl=2.47, wps=280.6, ups=0.26, wpb=1074.2, bsz=32, num_updates=10670, lr=8.45362e-06, gnorm=5.311, clip=100, loss_scale=64, train_wall=38, gb_free=9.1, wall=41213
2023-05-21 05:24:54 - progress_bar.py[line:272] - INFO: epoch 007:    308 / 1732 loss=2.47, loss_v1=0, loss_v2=0, nll_loss=1.28, ntokens=1090.6, nsentences=32, sample_size=1090.6, sample_size_v1=0, sample_size_v2=0, ppl=2.43, wps=284.7, ups=0.26, wpb=1090.6, bsz=32, num_updates=10680, lr=8.45157e-06, gnorm=5.532, clip=100, loss_scale=64, train_wall=38, gb_free=8.9, wall=41251
2023-05-21 05:25:32 - progress_bar.py[line:272] - INFO: epoch 007:    318 / 1732 loss=2.486, loss_v1=0, loss_v2=0, nll_loss=1.297, ntokens=1026, nsentences=32, sample_size=1026, sample_size_v1=0, sample_size_v2=0, ppl=2.46, wps=268.1, ups=0.26, wpb=1026, bsz=32, num_updates=10690, lr=8.44952e-06, gnorm=6.314, clip=100, loss_scale=64, train_wall=38, gb_free=9, wall=41289
2023-05-21 05:26:10 - progress_bar.py[line:272] - INFO: epoch 007:    328 / 1732 loss=2.519, loss_v1=0, loss_v2=0, nll_loss=1.334, ntokens=1009.5, nsentences=32, sample_size=1009.5, sample_size_v1=0, sample_size_v2=0, ppl=2.52, wps=263.6, ups=0.26, wpb=1009.5, bsz=32, num_updates=10700, lr=8.44747e-06, gnorm=6.338, clip=100, loss_scale=64, train_wall=38, gb_free=8.9, wall=41328
2023-05-21 05:26:48 - progress_bar.py[line:272] - INFO: epoch 007:    338 / 1732 loss=2.465, loss_v1=0, loss_v2=0, nll_loss=1.274, ntokens=991.1, nsentences=32, sample_size=991.1, sample_size_v1=0, sample_size_v2=0, ppl=2.42, wps=260.6, ups=0.26, wpb=991.1, bsz=32, num_updates=10710, lr=8.44543e-06, gnorm=5.768, clip=100, loss_scale=64, train_wall=38, gb_free=8.9, wall=41366
2023-05-21 05:27:27 - progress_bar.py[line:272] - INFO: epoch 007:    348 / 1732 loss=2.481, loss_v1=0, loss_v2=0, nll_loss=1.294, ntokens=913.6, nsentences=32, sample_size=913.6, sample_size_v1=0, sample_size_v2=0, ppl=2.45, wps=240.2, ups=0.26, wpb=913.6, bsz=32, num_updates=10720, lr=8.44338e-06, gnorm=6.314, clip=100, loss_scale=64, train_wall=38, gb_free=8.8, wall=41404
2023-05-21 05:28:04 - progress_bar.py[line:272] - INFO: epoch 007:    358 / 1732 loss=2.512, loss_v1=0, loss_v2=0, nll_loss=1.327, ntokens=943, nsentences=32, sample_size=943, sample_size_v1=0, sample_size_v2=0, ppl=2.51, wps=248.6, ups=0.26, wpb=943, bsz=32, num_updates=10730, lr=8.44133e-06, gnorm=6.02, clip=100, loss_scale=64, train_wall=38, gb_free=9.1, wall=41442
2023-05-21 05:28:43 - progress_bar.py[line:272] - INFO: epoch 007:    368 / 1732 loss=2.517, loss_v1=0, loss_v2=0, nll_loss=1.329, ntokens=960.6, nsentences=32, sample_size=960.6, sample_size_v1=0, sample_size_v2=0, ppl=2.51, wps=252.2, ups=0.26, wpb=960.6, bsz=32, num_updates=10740, lr=8.43929e-06, gnorm=6.678, clip=100, loss_scale=64, train_wall=38, gb_free=8.6, wall=41480
2023-05-21 05:29:21 - progress_bar.py[line:272] - INFO: epoch 007:    378 / 1732 loss=2.529, loss_v1=0, loss_v2=0, nll_loss=1.343, ntokens=1043.2, nsentences=32, sample_size=1043.2, sample_size_v1=0, sample_size_v2=0, ppl=2.54, wps=273.4, ups=0.26, wpb=1043.2, bsz=32, num_updates=10750, lr=8.43724e-06, gnorm=5.556, clip=100, loss_scale=64, train_wall=38, gb_free=9.1, wall=41518
2023-05-21 05:29:59 - progress_bar.py[line:272] - INFO: epoch 007:    388 / 1732 loss=2.478, loss_v1=0, loss_v2=0, nll_loss=1.289, ntokens=1053.2, nsentences=32, sample_size=1053.2, sample_size_v1=0, sample_size_v2=0, ppl=2.44, wps=275.9, ups=0.26, wpb=1053.2, bsz=32, num_updates=10760, lr=8.43519e-06, gnorm=6.615, clip=100, loss_scale=64, train_wall=38, gb_free=8.3, wall=41556
2023-05-21 05:30:37 - progress_bar.py[line:272] - INFO: epoch 007:    398 / 1732 loss=2.497, loss_v1=0, loss_v2=0, nll_loss=1.31, ntokens=977.4, nsentences=32, sample_size=977.4, sample_size_v1=0, sample_size_v2=0, ppl=2.48, wps=254.7, ups=0.26, wpb=977.4, bsz=32, num_updates=10770, lr=8.43314e-06, gnorm=7.019, clip=100, loss_scale=64, train_wall=38, gb_free=8, wall=41594
2023-05-21 05:31:15 - progress_bar.py[line:272] - INFO: epoch 007:    408 / 1732 loss=2.477, loss_v1=0, loss_v2=0, nll_loss=1.288, ntokens=1058.6, nsentences=32, sample_size=1058.6, sample_size_v1=0, sample_size_v2=0, ppl=2.44, wps=277.1, ups=0.26, wpb=1058.6, bsz=32, num_updates=10780, lr=8.4311e-06, gnorm=5.759, clip=100, loss_scale=64, train_wall=38, gb_free=8.6, wall=41633
2023-05-21 05:31:54 - progress_bar.py[line:272] - INFO: epoch 007:    418 / 1732 loss=2.45, loss_v1=0, loss_v2=0, nll_loss=1.257, ntokens=1021.6, nsentences=32, sample_size=1021.6, sample_size_v1=0, sample_size_v2=0, ppl=2.39, wps=266.9, ups=0.26, wpb=1021.6, bsz=32, num_updates=10790, lr=8.42905e-06, gnorm=6.383, clip=100, loss_scale=64, train_wall=38, gb_free=8, wall=41671
2023-05-21 05:32:32 - progress_bar.py[line:272] - INFO: epoch 007:    428 / 1732 loss=2.457, loss_v1=0, loss_v2=0, nll_loss=1.267, ntokens=1016.5, nsentences=32, sample_size=1016.5, sample_size_v1=0, sample_size_v2=0, ppl=2.41, wps=265.9, ups=0.26, wpb=1016.5, bsz=32, num_updates=10800, lr=8.427e-06, gnorm=6.583, clip=100, loss_scale=64, train_wall=38, gb_free=8.5, wall=41709
2023-05-21 05:33:10 - progress_bar.py[line:272] - INFO: epoch 007:    438 / 1732 loss=2.492, loss_v1=0, loss_v2=0, nll_loss=1.305, ntokens=1018.5, nsentences=32, sample_size=1018.5, sample_size_v1=0, sample_size_v2=0, ppl=2.47, wps=268.1, ups=0.26, wpb=1018.5, bsz=32, num_updates=10810, lr=8.42495e-06, gnorm=5.866, clip=100, loss_scale=64, train_wall=38, gb_free=8.9, wall=41747
2023-05-21 05:33:48 - progress_bar.py[line:272] - INFO: epoch 007:    448 / 1732 loss=2.51, loss_v1=0, loss_v2=0, nll_loss=1.323, ntokens=946.6, nsentences=32, sample_size=946.6, sample_size_v1=0, sample_size_v2=0, ppl=2.5, wps=247.7, ups=0.26, wpb=946.6, bsz=32, num_updates=10820, lr=8.42291e-06, gnorm=7.398, clip=100, loss_scale=64, train_wall=38, gb_free=8.6, wall=41785
2023-05-21 05:34:26 - progress_bar.py[line:272] - INFO: epoch 007:    458 / 1732 loss=2.496, loss_v1=0, loss_v2=0, nll_loss=1.309, ntokens=971.2, nsentences=32, sample_size=971.2, sample_size_v1=0, sample_size_v2=0, ppl=2.48, wps=254.7, ups=0.26, wpb=971.2, bsz=32, num_updates=10830, lr=8.42086e-06, gnorm=6.329, clip=100, loss_scale=64, train_wall=38, gb_free=8.9, wall=41824
2023-05-21 05:35:05 - progress_bar.py[line:272] - INFO: epoch 007:    468 / 1732 loss=2.49, loss_v1=0, loss_v2=0, nll_loss=1.302, ntokens=1064.3, nsentences=32, sample_size=1064.3, sample_size_v1=0, sample_size_v2=0, ppl=2.47, wps=278, ups=0.26, wpb=1064.3, bsz=32, num_updates=10840, lr=8.41881e-06, gnorm=5.924, clip=100, loss_scale=64, train_wall=38, gb_free=8.3, wall=41862
2023-05-21 05:35:43 - progress_bar.py[line:272] - INFO: epoch 007:    478 / 1732 loss=2.519, loss_v1=0, loss_v2=0, nll_loss=1.333, ntokens=1027.7, nsentences=32, sample_size=1027.7, sample_size_v1=0, sample_size_v2=0, ppl=2.52, wps=268.7, ups=0.26, wpb=1027.7, bsz=32, num_updates=10850, lr=8.41676e-06, gnorm=6.19, clip=100, loss_scale=64, train_wall=38, gb_free=8.9, wall=41900
2023-05-21 05:36:21 - progress_bar.py[line:272] - INFO: epoch 007:    488 / 1732 loss=2.459, loss_v1=0, loss_v2=0, nll_loss=1.268, ntokens=925.6, nsentences=32, sample_size=925.6, sample_size_v1=0, sample_size_v2=0, ppl=2.41, wps=243, ups=0.26, wpb=925.6, bsz=32, num_updates=10860, lr=8.41472e-06, gnorm=7.202, clip=100, loss_scale=64, train_wall=38, gb_free=9.2, wall=41938
2023-05-21 05:36:59 - progress_bar.py[line:272] - INFO: epoch 007:    498 / 1732 loss=2.482, loss_v1=0, loss_v2=0, nll_loss=1.295, ntokens=952.7, nsentences=32, sample_size=952.7, sample_size_v1=0, sample_size_v2=0, ppl=2.45, wps=249.6, ups=0.26, wpb=952.7, bsz=32, num_updates=10870, lr=8.41267e-06, gnorm=6.256, clip=100, loss_scale=64, train_wall=38, gb_free=9.3, wall=41976
2023-05-21 05:37:37 - progress_bar.py[line:272] - INFO: epoch 007:    508 / 1732 loss=2.493, loss_v1=0, loss_v2=0, nll_loss=1.303, ntokens=1034.3, nsentences=32, sample_size=1034.3, sample_size_v1=0, sample_size_v2=0, ppl=2.47, wps=271.7, ups=0.26, wpb=1034.3, bsz=32, num_updates=10880, lr=8.41062e-06, gnorm=6.485, clip=100, loss_scale=64, train_wall=38, gb_free=8.7, wall=42014
2023-05-21 05:38:15 - progress_bar.py[line:272] - INFO: epoch 007:    518 / 1732 loss=2.488, loss_v1=0, loss_v2=0, nll_loss=1.301, ntokens=1032.2, nsentences=32, sample_size=1032.2, sample_size_v1=0, sample_size_v2=0, ppl=2.46, wps=272.3, ups=0.26, wpb=1032.2, bsz=32, num_updates=10890, lr=8.40857e-06, gnorm=5.969, clip=100, loss_scale=64, train_wall=38, gb_free=8.9, wall=42052
2023-05-21 05:38:53 - progress_bar.py[line:272] - INFO: epoch 007:    528 / 1732 loss=2.493, loss_v1=0, loss_v2=0, nll_loss=1.306, ntokens=941.1, nsentences=32, sample_size=941.1, sample_size_v1=0, sample_size_v2=0, ppl=2.47, wps=249.6, ups=0.27, wpb=941.1, bsz=32, num_updates=10900, lr=8.40653e-06, gnorm=7.046, clip=100, loss_scale=64, train_wall=38, gb_free=9.1, wall=42090
2023-05-21 05:39:31 - progress_bar.py[line:272] - INFO: epoch 007:    538 / 1732 loss=2.472, loss_v1=0, loss_v2=0, nll_loss=1.283, ntokens=972.3, nsentences=32, sample_size=972.3, sample_size_v1=0, sample_size_v2=0, ppl=2.43, wps=257.7, ups=0.27, wpb=972.3, bsz=32, num_updates=10910, lr=8.40448e-06, gnorm=6.146, clip=100, loss_scale=64, train_wall=38, gb_free=8.4, wall=42128
2023-05-21 05:40:09 - progress_bar.py[line:272] - INFO: epoch 007:    548 / 1732 loss=2.507, loss_v1=0, loss_v2=0, nll_loss=1.32, ntokens=1027.8, nsentences=32, sample_size=1027.8, sample_size_v1=0, sample_size_v2=0, ppl=2.5, wps=269.1, ups=0.26, wpb=1027.8, bsz=32, num_updates=10920, lr=8.40243e-06, gnorm=5.798, clip=100, loss_scale=64, train_wall=38, gb_free=8.9, wall=42166
2023-05-21 05:40:47 - progress_bar.py[line:272] - INFO: epoch 007:    558 / 1732 loss=2.51, loss_v1=0, loss_v2=0, nll_loss=1.326, ntokens=1021.9, nsentences=32, sample_size=1021.9, sample_size_v1=0, sample_size_v2=0, ppl=2.51, wps=269.3, ups=0.26, wpb=1021.9, bsz=32, num_updates=10930, lr=8.40038e-06, gnorm=6.472, clip=100, loss_scale=64, train_wall=38, gb_free=8, wall=42204
2023-05-21 05:41:25 - progress_bar.py[line:272] - INFO: epoch 007:    568 / 1732 loss=2.531, loss_v1=0, loss_v2=0, nll_loss=1.346, ntokens=1014.9, nsentences=32, sample_size=1014.9, sample_size_v1=0, sample_size_v2=0, ppl=2.54, wps=264.1, ups=0.26, wpb=1014.9, bsz=32, num_updates=10940, lr=8.39834e-06, gnorm=7.069, clip=100, loss_scale=64, train_wall=38, gb_free=8.3, wall=42242
2023-05-21 05:42:03 - progress_bar.py[line:272] - INFO: epoch 007:    578 / 1732 loss=2.489, loss_v1=0, loss_v2=0, nll_loss=1.3, ntokens=991.4, nsentences=32, sample_size=991.4, sample_size_v1=0, sample_size_v2=0, ppl=2.46, wps=258.9, ups=0.26, wpb=991.4, bsz=32, num_updates=10950, lr=8.39629e-06, gnorm=7.35, clip=100, loss_scale=64, train_wall=38, gb_free=8.3, wall=42281
2023-05-21 05:42:42 - progress_bar.py[line:272] - INFO: epoch 007:    588 / 1732 loss=2.49, loss_v1=0, loss_v2=0, nll_loss=1.301, ntokens=965.9, nsentences=32, sample_size=965.9, sample_size_v1=0, sample_size_v2=0, ppl=2.46, wps=253, ups=0.26, wpb=965.9, bsz=32, num_updates=10960, lr=8.39424e-06, gnorm=6.381, clip=100, loss_scale=64, train_wall=38, gb_free=8.7, wall=42319
2023-05-21 05:43:20 - progress_bar.py[line:272] - INFO: epoch 007:    598 / 1732 loss=2.461, loss_v1=0, loss_v2=0, nll_loss=1.271, ntokens=957.4, nsentences=32, sample_size=957.4, sample_size_v1=0, sample_size_v2=0, ppl=2.41, wps=251.3, ups=0.26, wpb=957.4, bsz=32, num_updates=10970, lr=8.3922e-06, gnorm=7.045, clip=100, loss_scale=64, train_wall=38, gb_free=9.2, wall=42357
2023-05-21 05:43:58 - progress_bar.py[line:272] - INFO: epoch 007:    608 / 1732 loss=2.485, loss_v1=0, loss_v2=0, nll_loss=1.3, ntokens=893.5, nsentences=32, sample_size=893.5, sample_size_v1=0, sample_size_v2=0, ppl=2.46, wps=235.7, ups=0.26, wpb=893.5, bsz=32, num_updates=10980, lr=8.39015e-06, gnorm=6.532, clip=100, loss_scale=64, train_wall=38, gb_free=8.3, wall=42395
2023-05-21 05:44:36 - progress_bar.py[line:272] - INFO: epoch 007:    618 / 1732 loss=2.504, loss_v1=0, loss_v2=0, nll_loss=1.32, ntokens=860.2, nsentences=32, sample_size=860.2, sample_size_v1=0, sample_size_v2=0, ppl=2.5, wps=227.1, ups=0.26, wpb=860.2, bsz=32, num_updates=10990, lr=8.3881e-06, gnorm=7.635, clip=100, loss_scale=64, train_wall=38, gb_free=9, wall=42433
2023-05-21 05:45:13 - progress_bar.py[line:272] - INFO: epoch 007:    628 / 1732 loss=2.486, loss_v1=0, loss_v2=0, nll_loss=1.297, ntokens=929, nsentences=32, sample_size=929, sample_size_v1=0, sample_size_v2=0, ppl=2.46, wps=247, ups=0.27, wpb=929, bsz=32, num_updates=11000, lr=8.38605e-06, gnorm=7.301, clip=100, loss_scale=64, train_wall=38, gb_free=9, wall=42470
2023-05-21 05:45:51 - progress_bar.py[line:272] - INFO: epoch 007:    638 / 1732 loss=2.492, loss_v1=0, loss_v2=0, nll_loss=1.304, ntokens=921.3, nsentences=32, sample_size=921.3, sample_size_v1=0, sample_size_v2=0, ppl=2.47, wps=243.7, ups=0.26, wpb=921.3, bsz=32, num_updates=11010, lr=8.38401e-06, gnorm=7.366, clip=100, loss_scale=64, train_wall=38, gb_free=9, wall=42508
2023-05-21 05:46:29 - progress_bar.py[line:272] - INFO: epoch 007:    648 / 1732 loss=2.513, loss_v1=0, loss_v2=0, nll_loss=1.327, ntokens=983.5, nsentences=32, sample_size=983.5, sample_size_v1=0, sample_size_v2=0, ppl=2.51, wps=260.4, ups=0.26, wpb=983.5, bsz=32, num_updates=11020, lr=8.38196e-06, gnorm=7.106, clip=100, loss_scale=64, train_wall=38, gb_free=8.8, wall=42546
2023-05-21 05:47:06 - progress_bar.py[line:272] - INFO: epoch 007:    658 / 1732 loss=2.504, loss_v1=0, loss_v2=0, nll_loss=1.318, ntokens=892.2, nsentences=32, sample_size=892.2, sample_size_v1=0, sample_size_v2=0, ppl=2.49, wps=237.7, ups=0.27, wpb=892.2, bsz=32, num_updates=11030, lr=8.37991e-06, gnorm=7.32, clip=100, loss_scale=64, train_wall=37, gb_free=8.6, wall=42583
2023-05-21 05:47:44 - progress_bar.py[line:272] - INFO: epoch 007:    668 / 1732 loss=2.496, loss_v1=0, loss_v2=0, nll_loss=1.309, ntokens=910, nsentences=32, sample_size=910, sample_size_v1=0, sample_size_v2=0, ppl=2.48, wps=241, ups=0.26, wpb=910, bsz=32, num_updates=11040, lr=8.37786e-06, gnorm=7.381, clip=100, loss_scale=64, train_wall=38, gb_free=8.2, wall=42621
2023-05-21 05:48:22 - progress_bar.py[line:272] - INFO: epoch 007:    678 / 1732 loss=2.502, loss_v1=0, loss_v2=0, nll_loss=1.315, ntokens=980.2, nsentences=32, sample_size=980.2, sample_size_v1=0, sample_size_v2=0, ppl=2.49, wps=258.8, ups=0.26, wpb=980.2, bsz=32, num_updates=11050, lr=8.37582e-06, gnorm=6.588, clip=100, loss_scale=64, train_wall=38, gb_free=8.8, wall=42659
2023-05-21 05:49:00 - progress_bar.py[line:272] - INFO: epoch 007:    688 / 1732 loss=2.501, loss_v1=0, loss_v2=0, nll_loss=1.315, ntokens=942, nsentences=32, sample_size=942, sample_size_v1=0, sample_size_v2=0, ppl=2.49, wps=247.6, ups=0.26, wpb=942, bsz=32, num_updates=11060, lr=8.37377e-06, gnorm=7.118, clip=100, loss_scale=64, train_wall=38, gb_free=9, wall=42697
2023-05-21 05:49:38 - progress_bar.py[line:272] - INFO: epoch 007:    698 / 1732 loss=2.483, loss_v1=0, loss_v2=0, nll_loss=1.296, ntokens=1001.9, nsentences=32, sample_size=1001.9, sample_size_v1=0, sample_size_v2=0, ppl=2.45, wps=263.2, ups=0.26, wpb=1001.9, bsz=32, num_updates=11070, lr=8.37172e-06, gnorm=6.356, clip=100, loss_scale=64, train_wall=38, gb_free=8.9, wall=42735
2023-05-21 05:50:16 - progress_bar.py[line:272] - INFO: epoch 007:    708 / 1732 loss=2.489, loss_v1=0, loss_v2=0, nll_loss=1.301, ntokens=907.1, nsentences=32, sample_size=907.1, sample_size_v1=0, sample_size_v2=0, ppl=2.46, wps=240.1, ups=0.26, wpb=907.1, bsz=32, num_updates=11080, lr=8.36967e-06, gnorm=7.1, clip=100, loss_scale=64, train_wall=38, gb_free=8.9, wall=42773
2023-05-21 05:50:53 - progress_bar.py[line:272] - INFO: epoch 007:    718 / 1732 loss=2.486, loss_v1=0, loss_v2=0, nll_loss=1.296, ntokens=882, nsentences=32, sample_size=882, sample_size_v1=0, sample_size_v2=0, ppl=2.46, wps=234.1, ups=0.27, wpb=882, bsz=32, num_updates=11090, lr=8.36763e-06, gnorm=7.059, clip=100, loss_scale=64, train_wall=38, gb_free=9.3, wall=42811
2023-05-21 05:51:31 - progress_bar.py[line:272] - INFO: epoch 007:    728 / 1732 loss=2.461, loss_v1=0, loss_v2=0, nll_loss=1.272, ntokens=917.5, nsentences=32, sample_size=917.5, sample_size_v1=0, sample_size_v2=0, ppl=2.41, wps=242.6, ups=0.26, wpb=917.5, bsz=32, num_updates=11100, lr=8.36558e-06, gnorm=7.181, clip=100, loss_scale=64, train_wall=38, gb_free=8.7, wall=42849
2023-05-21 05:52:09 - progress_bar.py[line:272] - INFO: epoch 007:    738 / 1732 loss=2.466, loss_v1=0, loss_v2=0, nll_loss=1.278, ntokens=991.8, nsentences=32, sample_size=991.8, sample_size_v1=0, sample_size_v2=0, ppl=2.42, wps=262.5, ups=0.26, wpb=991.8, bsz=32, num_updates=11110, lr=8.36353e-06, gnorm=6.561, clip=100, loss_scale=64, train_wall=38, gb_free=8.9, wall=42886
2023-05-21 05:52:47 - progress_bar.py[line:272] - INFO: epoch 007:    748 / 1732 loss=2.477, loss_v1=0, loss_v2=0, nll_loss=1.288, ntokens=986.3, nsentences=32, sample_size=986.3, sample_size_v1=0, sample_size_v2=0, ppl=2.44, wps=259.4, ups=0.26, wpb=986.3, bsz=32, num_updates=11120, lr=8.36148e-06, gnorm=6.677, clip=100, loss_scale=64, train_wall=38, gb_free=8.8, wall=42924
2023-05-21 05:53:25 - progress_bar.py[line:272] - INFO: epoch 007:    758 / 1732 loss=2.465, loss_v1=0, loss_v2=0, nll_loss=1.273, ntokens=946.6, nsentences=32, sample_size=946.6, sample_size_v1=0, sample_size_v2=0, ppl=2.42, wps=250.1, ups=0.26, wpb=946.6, bsz=32, num_updates=11130, lr=8.35944e-06, gnorm=6.973, clip=100, loss_scale=64, train_wall=38, gb_free=8.6, wall=42962
2023-05-21 05:54:03 - progress_bar.py[line:272] - INFO: epoch 007:    768 / 1732 loss=2.481, loss_v1=0, loss_v2=0, nll_loss=1.293, ntokens=947.6, nsentences=32, sample_size=947.6, sample_size_v1=0, sample_size_v2=0, ppl=2.45, wps=250.8, ups=0.26, wpb=947.6, bsz=32, num_updates=11140, lr=8.35739e-06, gnorm=6.537, clip=100, loss_scale=64, train_wall=38, gb_free=8.5, wall=43000
2023-05-21 05:54:41 - progress_bar.py[line:272] - INFO: epoch 007:    778 / 1732 loss=2.486, loss_v1=0, loss_v2=0, nll_loss=1.299, ntokens=1017.6, nsentences=32, sample_size=1017.6, sample_size_v1=0, sample_size_v2=0, ppl=2.46, wps=267.5, ups=0.26, wpb=1017.6, bsz=32, num_updates=11150, lr=8.35534e-06, gnorm=6.449, clip=100, loss_scale=64, train_wall=38, gb_free=9.2, wall=43038
2023-05-21 05:55:19 - progress_bar.py[line:272] - INFO: epoch 007:    788 / 1732 loss=2.482, loss_v1=0, loss_v2=0, nll_loss=1.293, ntokens=1010.8, nsentences=32, sample_size=1010.8, sample_size_v1=0, sample_size_v2=0, ppl=2.45, wps=266.5, ups=0.26, wpb=1010.8, bsz=32, num_updates=11160, lr=8.3533e-06, gnorm=6.322, clip=100, loss_scale=64, train_wall=38, gb_free=8.4, wall=43076
2023-05-21 05:55:57 - progress_bar.py[line:272] - INFO: epoch 007:    798 / 1732 loss=2.468, loss_v1=0, loss_v2=0, nll_loss=1.277, ntokens=1050, nsentences=32, sample_size=1050, sample_size_v1=0, sample_size_v2=0, ppl=2.42, wps=276.1, ups=0.26, wpb=1050, bsz=32, num_updates=11170, lr=8.35125e-06, gnorm=6.861, clip=100, loss_scale=128, train_wall=38, gb_free=8.8, wall=43114
2023-05-21 05:56:35 - progress_bar.py[line:272] - INFO: epoch 007:    808 / 1732 loss=2.486, loss_v1=0, loss_v2=0, nll_loss=1.299, ntokens=907.2, nsentences=32, sample_size=907.2, sample_size_v1=0, sample_size_v2=0, ppl=2.46, wps=238.5, ups=0.26, wpb=907.2, bsz=32, num_updates=11180, lr=8.3492e-06, gnorm=7.208, clip=100, loss_scale=128, train_wall=38, gb_free=8.8, wall=43152
2023-05-21 05:56:50 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2023-05-21 05:57:16 - progress_bar.py[line:272] - INFO: epoch 007:    819 / 1732 loss=2.488, loss_v1=0, loss_v2=0, nll_loss=1.298, ntokens=919.3, nsentences=32, sample_size=919.3, sample_size_v1=0, sample_size_v2=0, ppl=2.46, wps=221.1, ups=0.24, wpb=919.3, bsz=32, num_updates=11190, lr=8.34715e-06, gnorm=7.199, clip=100, loss_scale=64, train_wall=42, gb_free=9.1, wall=43194
2023-05-21 05:57:54 - progress_bar.py[line:272] - INFO: epoch 007:    829 / 1732 loss=2.467, loss_v1=0, loss_v2=0, nll_loss=1.277, ntokens=917.4, nsentences=32, sample_size=917.4, sample_size_v1=0, sample_size_v2=0, ppl=2.42, wps=241.5, ups=0.26, wpb=917.4, bsz=32, num_updates=11200, lr=8.34511e-06, gnorm=7.238, clip=100, loss_scale=64, train_wall=38, gb_free=9.3, wall=43232
2023-05-21 05:58:32 - progress_bar.py[line:272] - INFO: epoch 007:    839 / 1732 loss=2.483, loss_v1=0, loss_v2=0, nll_loss=1.292, ntokens=902.5, nsentences=32, sample_size=902.5, sample_size_v1=0, sample_size_v2=0, ppl=2.45, wps=237.7, ups=0.26, wpb=902.5, bsz=32, num_updates=11210, lr=8.34306e-06, gnorm=8.271, clip=100, loss_scale=64, train_wall=38, gb_free=9.1, wall=43270
2023-05-21 05:59:10 - progress_bar.py[line:272] - INFO: epoch 007:    849 / 1732 loss=2.474, loss_v1=0, loss_v2=0, nll_loss=1.283, ntokens=1036.8, nsentences=32, sample_size=1036.8, sample_size_v1=0, sample_size_v2=0, ppl=2.43, wps=272, ups=0.26, wpb=1036.8, bsz=32, num_updates=11220, lr=8.34101e-06, gnorm=6.626, clip=100, loss_scale=64, train_wall=38, gb_free=8.6, wall=43308
2023-05-21 05:59:48 - progress_bar.py[line:272] - INFO: epoch 007:    859 / 1732 loss=2.467, loss_v1=0, loss_v2=0, nll_loss=1.277, ntokens=930.3, nsentences=32, sample_size=930.3, sample_size_v1=0, sample_size_v2=0, ppl=2.42, wps=246.1, ups=0.26, wpb=930.3, bsz=32, num_updates=11230, lr=8.33896e-06, gnorm=6.856, clip=100, loss_scale=64, train_wall=38, gb_free=8.6, wall=43345
2023-05-21 06:00:26 - progress_bar.py[line:272] - INFO: epoch 007:    869 / 1732 loss=2.489, loss_v1=0, loss_v2=0, nll_loss=1.302, ntokens=962.2, nsentences=32, sample_size=962.2, sample_size_v1=0, sample_size_v2=0, ppl=2.47, wps=253.9, ups=0.26, wpb=962.2, bsz=32, num_updates=11240, lr=8.33692e-06, gnorm=6.46, clip=100, loss_scale=64, train_wall=38, gb_free=8.8, wall=43383
2023-05-21 06:01:04 - progress_bar.py[line:272] - INFO: epoch 007:    879 / 1732 loss=2.413, loss_v1=0, loss_v2=0, nll_loss=1.217, ntokens=1001.9, nsentences=32, sample_size=1001.9, sample_size_v1=0, sample_size_v2=0, ppl=2.32, wps=262.8, ups=0.26, wpb=1001.9, bsz=32, num_updates=11250, lr=8.33487e-06, gnorm=5.597, clip=100, loss_scale=64, train_wall=38, gb_free=8.7, wall=43421
2023-05-21 06:01:42 - progress_bar.py[line:272] - INFO: epoch 007:    889 / 1732 loss=2.425, loss_v1=0, loss_v2=0, nll_loss=1.23, ntokens=975.7, nsentences=32, sample_size=975.7, sample_size_v1=0, sample_size_v2=0, ppl=2.35, wps=256.3, ups=0.26, wpb=975.7, bsz=32, num_updates=11260, lr=8.33282e-06, gnorm=7.026, clip=100, loss_scale=64, train_wall=38, gb_free=8.4, wall=43460
2023-05-21 06:02:20 - progress_bar.py[line:272] - INFO: epoch 007:    899 / 1732 loss=2.416, loss_v1=0, loss_v2=0, nll_loss=1.219, ntokens=1055.9, nsentences=32, sample_size=1055.9, sample_size_v1=0, sample_size_v2=0, ppl=2.33, wps=276.8, ups=0.26, wpb=1055.9, bsz=32, num_updates=11270, lr=8.33077e-06, gnorm=6.992, clip=100, loss_scale=64, train_wall=38, gb_free=8.2, wall=43498
2023-05-21 06:02:58 - progress_bar.py[line:272] - INFO: epoch 007:    909 / 1732 loss=2.461, loss_v1=0, loss_v2=0, nll_loss=1.271, ntokens=975.2, nsentences=32, sample_size=975.2, sample_size_v1=0, sample_size_v2=0, ppl=2.41, wps=256.9, ups=0.26, wpb=975.2, bsz=32, num_updates=11280, lr=8.32873e-06, gnorm=6.947, clip=100, loss_scale=64, train_wall=38, gb_free=9, wall=43536
2023-05-21 06:03:37 - progress_bar.py[line:272] - INFO: epoch 007:    919 / 1732 loss=2.497, loss_v1=0, loss_v2=0, nll_loss=1.312, ntokens=988.7, nsentences=32, sample_size=988.7, sample_size_v1=0, sample_size_v2=0, ppl=2.48, wps=258.5, ups=0.26, wpb=988.7, bsz=32, num_updates=11290, lr=8.32668e-06, gnorm=7.023, clip=100, loss_scale=64, train_wall=38, gb_free=8.2, wall=43574
2023-05-21 06:04:15 - progress_bar.py[line:272] - INFO: epoch 007:    929 / 1732 loss=2.447, loss_v1=0, loss_v2=0, nll_loss=1.255, ntokens=1019.8, nsentences=32, sample_size=1019.8, sample_size_v1=0, sample_size_v2=0, ppl=2.39, wps=265, ups=0.26, wpb=1019.8, bsz=32, num_updates=11300, lr=8.32463e-06, gnorm=6.12, clip=100, loss_scale=64, train_wall=38, gb_free=8.2, wall=43612
2023-05-21 06:04:54 - progress_bar.py[line:272] - INFO: epoch 007:    939 / 1732 loss=2.453, loss_v1=0, loss_v2=0, nll_loss=1.262, ntokens=1047.7, nsentences=32, sample_size=1047.7, sample_size_v1=0, sample_size_v2=0, ppl=2.4, wps=271.2, ups=0.26, wpb=1047.7, bsz=32, num_updates=11310, lr=8.32258e-06, gnorm=6.268, clip=100, loss_scale=64, train_wall=39, gb_free=8.4, wall=43651
2023-05-21 06:05:32 - progress_bar.py[line:272] - INFO: epoch 007:    949 / 1732 loss=2.461, loss_v1=0, loss_v2=0, nll_loss=1.27, ntokens=1037.9, nsentences=32, sample_size=1037.9, sample_size_v1=0, sample_size_v2=0, ppl=2.41, wps=269.4, ups=0.26, wpb=1037.9, bsz=32, num_updates=11320, lr=8.32054e-06, gnorm=5.832, clip=100, loss_scale=64, train_wall=38, gb_free=8.6, wall=43690
2023-05-21 06:06:11 - progress_bar.py[line:272] - INFO: epoch 007:    959 / 1732 loss=2.449, loss_v1=0, loss_v2=0, nll_loss=1.257, ntokens=1070.6, nsentences=32, sample_size=1070.6, sample_size_v1=0, sample_size_v2=0, ppl=2.39, wps=277.2, ups=0.26, wpb=1070.6, bsz=32, num_updates=11330, lr=8.31849e-06, gnorm=5.869, clip=100, loss_scale=64, train_wall=39, gb_free=8.3, wall=43728
2023-05-21 06:06:50 - progress_bar.py[line:272] - INFO: epoch 007:    969 / 1732 loss=2.483, loss_v1=0, loss_v2=0, nll_loss=1.297, ntokens=1025.9, nsentences=32, sample_size=1025.9, sample_size_v1=0, sample_size_v2=0, ppl=2.46, wps=266.3, ups=0.26, wpb=1025.9, bsz=32, num_updates=11340, lr=8.31644e-06, gnorm=6.441, clip=100, loss_scale=64, train_wall=38, gb_free=8.4, wall=43767
2023-05-21 06:07:28 - progress_bar.py[line:272] - INFO: epoch 007:    979 / 1732 loss=2.461, loss_v1=0, loss_v2=0, nll_loss=1.27, ntokens=1025.3, nsentences=32, sample_size=1025.3, sample_size_v1=0, sample_size_v2=0, ppl=2.41, wps=265.3, ups=0.26, wpb=1025.3, bsz=32, num_updates=11350, lr=8.3144e-06, gnorm=6.468, clip=100, loss_scale=64, train_wall=39, gb_free=8.1, wall=43805
2023-05-21 06:08:07 - progress_bar.py[line:272] - INFO: epoch 007:    989 / 1732 loss=2.455, loss_v1=0, loss_v2=0, nll_loss=1.263, ntokens=1057.2, nsentences=32, sample_size=1057.2, sample_size_v1=0, sample_size_v2=0, ppl=2.4, wps=270.9, ups=0.26, wpb=1057.2, bsz=32, num_updates=11360, lr=8.31235e-06, gnorm=6.468, clip=100, loss_scale=64, train_wall=39, gb_free=8.3, wall=43844
2023-05-21 06:08:45 - progress_bar.py[line:272] - INFO: epoch 007:    999 / 1732 loss=2.449, loss_v1=0, loss_v2=0, nll_loss=1.257, ntokens=989.7, nsentences=32, sample_size=989.7, sample_size_v1=0, sample_size_v2=0, ppl=2.39, wps=258.4, ups=0.26, wpb=989.7, bsz=32, num_updates=11370, lr=8.3103e-06, gnorm=6.33, clip=100, loss_scale=64, train_wall=38, gb_free=9, wall=43883
2023-05-21 06:09:24 - progress_bar.py[line:272] - INFO: epoch 007:   1009 / 1732 loss=2.449, loss_v1=0, loss_v2=0, nll_loss=1.255, ntokens=1040.9, nsentences=32, sample_size=1040.9, sample_size_v1=0, sample_size_v2=0, ppl=2.39, wps=270.3, ups=0.26, wpb=1040.9, bsz=32, num_updates=11380, lr=8.30825e-06, gnorm=6.017, clip=100, loss_scale=64, train_wall=38, gb_free=7.9, wall=43921
2023-05-21 06:10:03 - progress_bar.py[line:272] - INFO: epoch 007:   1019 / 1732 loss=2.434, loss_v1=0, loss_v2=0, nll_loss=1.241, ntokens=1021.6, nsentences=32, sample_size=1021.6, sample_size_v1=0, sample_size_v2=0, ppl=2.36, wps=265.1, ups=0.26, wpb=1021.6, bsz=32, num_updates=11390, lr=8.30621e-06, gnorm=6.957, clip=100, loss_scale=64, train_wall=38, gb_free=8.4, wall=43960
2023-05-21 06:10:41 - progress_bar.py[line:272] - INFO: epoch 007:   1029 / 1732 loss=2.457, loss_v1=0, loss_v2=0, nll_loss=1.268, ntokens=1092, nsentences=32, sample_size=1092, sample_size_v1=0, sample_size_v2=0, ppl=2.41, wps=280.4, ups=0.26, wpb=1092, bsz=32, num_updates=11400, lr=8.30416e-06, gnorm=5.942, clip=100, loss_scale=64, train_wall=39, gb_free=7.6, wall=43999
2023-05-21 06:11:20 - progress_bar.py[line:272] - INFO: epoch 007:   1039 / 1732 loss=2.468, loss_v1=0, loss_v2=0, nll_loss=1.277, ntokens=1077.1, nsentences=32, sample_size=1077.1, sample_size_v1=0, sample_size_v2=0, ppl=2.42, wps=279.7, ups=0.26, wpb=1077.1, bsz=32, num_updates=11410, lr=8.30211e-06, gnorm=6.085, clip=100, loss_scale=64, train_wall=38, gb_free=8, wall=44037
2023-05-21 06:11:58 - progress_bar.py[line:272] - INFO: epoch 007:   1049 / 1732 loss=2.451, loss_v1=0, loss_v2=0, nll_loss=1.255, ntokens=1018.7, nsentences=32, sample_size=1018.7, sample_size_v1=0, sample_size_v2=0, ppl=2.39, wps=265.4, ups=0.26, wpb=1018.7, bsz=32, num_updates=11420, lr=8.30006e-06, gnorm=7.029, clip=100, loss_scale=64, train_wall=38, gb_free=8.7, wall=44076
2023-05-21 06:12:37 - progress_bar.py[line:272] - INFO: epoch 007:   1059 / 1732 loss=2.456, loss_v1=0, loss_v2=0, nll_loss=1.263, ntokens=1090.9, nsentences=32, sample_size=1090.9, sample_size_v1=0, sample_size_v2=0, ppl=2.4, wps=282.2, ups=0.26, wpb=1090.9, bsz=32, num_updates=11430, lr=8.29802e-06, gnorm=6.315, clip=100, loss_scale=64, train_wall=39, gb_free=8.6, wall=44114
2023-05-21 06:13:16 - progress_bar.py[line:272] - INFO: epoch 007:   1069 / 1732 loss=2.455, loss_v1=0, loss_v2=0, nll_loss=1.263, ntokens=979.2, nsentences=32, sample_size=979.2, sample_size_v1=0, sample_size_v2=0, ppl=2.4, wps=254.7, ups=0.26, wpb=979.2, bsz=32, num_updates=11440, lr=8.29597e-06, gnorm=6.811, clip=100, loss_scale=64, train_wall=38, gb_free=8.4, wall=44153
2023-05-21 06:13:54 - progress_bar.py[line:272] - INFO: epoch 007:   1079 / 1732 loss=2.475, loss_v1=0, loss_v2=0, nll_loss=1.286, ntokens=1044.7, nsentences=32, sample_size=1044.7, sample_size_v1=0, sample_size_v2=0, ppl=2.44, wps=269.9, ups=0.26, wpb=1044.7, bsz=32, num_updates=11450, lr=8.29392e-06, gnorm=7.096, clip=100, loss_scale=64, train_wall=39, gb_free=8.1, wall=44191
2023-05-21 06:14:33 - progress_bar.py[line:272] - INFO: epoch 007:   1089 / 1732 loss=2.451, loss_v1=0, loss_v2=0, nll_loss=1.259, ntokens=1065.4, nsentences=32, sample_size=1065.4, sample_size_v1=0, sample_size_v2=0, ppl=2.39, wps=274.8, ups=0.26, wpb=1065.4, bsz=32, num_updates=11460, lr=8.29187e-06, gnorm=6.686, clip=100, loss_scale=64, train_wall=39, gb_free=8.6, wall=44230
2023-05-21 06:15:12 - progress_bar.py[line:272] - INFO: epoch 007:   1099 / 1732 loss=2.46, loss_v1=0, loss_v2=0, nll_loss=1.268, ntokens=1034.8, nsentences=32, sample_size=1034.8, sample_size_v1=0, sample_size_v2=0, ppl=2.41, wps=268.6, ups=0.26, wpb=1034.8, bsz=32, num_updates=11470, lr=8.28983e-06, gnorm=7.291, clip=100, loss_scale=64, train_wall=38, gb_free=7.6, wall=44269
2023-05-21 06:15:50 - progress_bar.py[line:272] - INFO: epoch 007:   1109 / 1732 loss=2.454, loss_v1=0, loss_v2=0, nll_loss=1.261, ntokens=1058.4, nsentences=32, sample_size=1058.4, sample_size_v1=0, sample_size_v2=0, ppl=2.4, wps=274, ups=0.26, wpb=1058.4, bsz=32, num_updates=11480, lr=8.28778e-06, gnorm=6.975, clip=100, loss_scale=64, train_wall=39, gb_free=7.5, wall=44307
2023-05-21 06:16:29 - progress_bar.py[line:272] - INFO: epoch 007:   1119 / 1732 loss=2.466, loss_v1=0, loss_v2=0, nll_loss=1.275, ntokens=966, nsentences=32, sample_size=966, sample_size_v1=0, sample_size_v2=0, ppl=2.42, wps=250.4, ups=0.26, wpb=966, bsz=32, num_updates=11490, lr=8.28573e-06, gnorm=7.905, clip=100, loss_scale=64, train_wall=39, gb_free=8, wall=44346
2023-05-21 06:17:07 - progress_bar.py[line:272] - INFO: epoch 007:   1129 / 1732 loss=2.467, loss_v1=0, loss_v2=0, nll_loss=1.277, ntokens=1007.5, nsentences=32, sample_size=1007.5, sample_size_v1=0, sample_size_v2=0, ppl=2.42, wps=261.7, ups=0.26, wpb=1007.5, bsz=32, num_updates=11500, lr=8.28368e-06, gnorm=7.419, clip=100, loss_scale=64, train_wall=38, gb_free=8.7, wall=44384
2023-05-21 06:17:46 - progress_bar.py[line:272] - INFO: epoch 007:   1139 / 1732 loss=2.475, loss_v1=0, loss_v2=0, nll_loss=1.286, ntokens=999.7, nsentences=32, sample_size=999.7, sample_size_v1=0, sample_size_v2=0, ppl=2.44, wps=258.8, ups=0.26, wpb=999.7, bsz=32, num_updates=11510, lr=8.28164e-06, gnorm=6.822, clip=100, loss_scale=64, train_wall=39, gb_free=8.2, wall=44423
2023-05-21 06:18:24 - progress_bar.py[line:272] - INFO: epoch 007:   1149 / 1732 loss=2.46, loss_v1=0, loss_v2=0, nll_loss=1.268, ntokens=999, nsentences=32, sample_size=999, sample_size_v1=0, sample_size_v2=0, ppl=2.41, wps=258.9, ups=0.26, wpb=999, bsz=32, num_updates=11520, lr=8.27959e-06, gnorm=7.077, clip=100, loss_scale=64, train_wall=39, gb_free=8.7, wall=44462
2023-05-21 06:19:03 - progress_bar.py[line:272] - INFO: epoch 007:   1159 / 1732 loss=2.436, loss_v1=0, loss_v2=0, nll_loss=1.242, ntokens=1014.2, nsentences=32, sample_size=1014.2, sample_size_v1=0, sample_size_v2=0, ppl=2.37, wps=262.9, ups=0.26, wpb=1014.2, bsz=32, num_updates=11530, lr=8.27754e-06, gnorm=7.287, clip=100, loss_scale=64, train_wall=39, gb_free=8.6, wall=44500
2023-05-21 06:19:41 - progress_bar.py[line:272] - INFO: epoch 007:   1169 / 1732 loss=2.445, loss_v1=0, loss_v2=0, nll_loss=1.253, ntokens=1031, nsentences=32, sample_size=1031, sample_size_v1=0, sample_size_v2=0, ppl=2.38, wps=268.3, ups=0.26, wpb=1031, bsz=32, num_updates=11540, lr=8.27549e-06, gnorm=6.915, clip=100, loss_scale=64, train_wall=38, gb_free=8.2, wall=44539
2023-05-21 06:20:20 - progress_bar.py[line:272] - INFO: epoch 007:   1179 / 1732 loss=2.421, loss_v1=0, loss_v2=0, nll_loss=1.224, ntokens=1057.9, nsentences=32, sample_size=1057.9, sample_size_v1=0, sample_size_v2=0, ppl=2.34, wps=276.5, ups=0.26, wpb=1057.9, bsz=32, num_updates=11550, lr=8.27345e-06, gnorm=6.116, clip=100, loss_scale=64, train_wall=38, gb_free=8.9, wall=44577
2023-05-21 06:20:58 - progress_bar.py[line:272] - INFO: epoch 007:   1189 / 1732 loss=2.467, loss_v1=0, loss_v2=0, nll_loss=1.279, ntokens=993.6, nsentences=32, sample_size=993.6, sample_size_v1=0, sample_size_v2=0, ppl=2.43, wps=259, ups=0.26, wpb=993.6, bsz=32, num_updates=11560, lr=8.2714e-06, gnorm=7.093, clip=100, loss_scale=64, train_wall=38, gb_free=8.3, wall=44615
2023-05-21 06:21:37 - progress_bar.py[line:272] - INFO: epoch 007:   1199 / 1732 loss=2.431, loss_v1=0, loss_v2=0, nll_loss=1.234, ntokens=1103.9, nsentences=32, sample_size=1103.9, sample_size_v1=0, sample_size_v2=0, ppl=2.35, wps=285.9, ups=0.26, wpb=1103.9, bsz=32, num_updates=11570, lr=8.26935e-06, gnorm=5.945, clip=100, loss_scale=64, train_wall=39, gb_free=7.7, wall=44654
2023-05-21 06:22:16 - progress_bar.py[line:272] - INFO: epoch 007:   1209 / 1732 loss=2.434, loss_v1=0, loss_v2=0, nll_loss=1.237, ntokens=1079.5, nsentences=32, sample_size=1079.5, sample_size_v1=0, sample_size_v2=0, ppl=2.36, wps=278.1, ups=0.26, wpb=1079.5, bsz=32, num_updates=11580, lr=8.26731e-06, gnorm=6.12, clip=100, loss_scale=64, train_wall=39, gb_free=8.5, wall=44693
2023-05-21 06:22:54 - progress_bar.py[line:272] - INFO: epoch 007:   1219 / 1732 loss=2.489, loss_v1=0, loss_v2=0, nll_loss=1.301, ntokens=1009.3, nsentences=32, sample_size=1009.3, sample_size_v1=0, sample_size_v2=0, ppl=2.46, wps=263.3, ups=0.26, wpb=1009.3, bsz=32, num_updates=11590, lr=8.26526e-06, gnorm=7.459, clip=100, loss_scale=64, train_wall=38, gb_free=8.5, wall=44731
2023-05-21 06:23:32 - progress_bar.py[line:272] - INFO: epoch 007:   1229 / 1732 loss=2.452, loss_v1=0, loss_v2=0, nll_loss=1.26, ntokens=1052.5, nsentences=32, sample_size=1052.5, sample_size_v1=0, sample_size_v2=0, ppl=2.39, wps=273, ups=0.26, wpb=1052.5, bsz=32, num_updates=11600, lr=8.26321e-06, gnorm=6.635, clip=100, loss_scale=64, train_wall=38, gb_free=8.3, wall=44770
2023-05-21 06:24:11 - progress_bar.py[line:272] - INFO: epoch 007:   1239 / 1732 loss=2.406, loss_v1=0, loss_v2=0, nll_loss=1.209, ntokens=1065.1, nsentences=32, sample_size=1065.1, sample_size_v1=0, sample_size_v2=0, ppl=2.31, wps=275, ups=0.26, wpb=1065.1, bsz=32, num_updates=11610, lr=8.26116e-06, gnorm=8.083, clip=100, loss_scale=64, train_wall=39, gb_free=7.9, wall=44808
2023-05-21 06:24:50 - progress_bar.py[line:272] - INFO: epoch 007:   1249 / 1732 loss=2.412, loss_v1=0, loss_v2=0, nll_loss=1.215, ntokens=1065.4, nsentences=32, sample_size=1065.4, sample_size_v1=0, sample_size_v2=0, ppl=2.32, wps=275.4, ups=0.26, wpb=1065.4, bsz=32, num_updates=11620, lr=8.25912e-06, gnorm=6.474, clip=100, loss_scale=64, train_wall=39, gb_free=8.6, wall=44847
2023-05-21 06:25:28 - progress_bar.py[line:272] - INFO: epoch 007:   1259 / 1732 loss=2.433, loss_v1=0, loss_v2=0, nll_loss=1.238, ntokens=1045.9, nsentences=32, sample_size=1045.9, sample_size_v1=0, sample_size_v2=0, ppl=2.36, wps=271, ups=0.26, wpb=1045.9, bsz=32, num_updates=11630, lr=8.25707e-06, gnorm=6.422, clip=100, loss_scale=64, train_wall=39, gb_free=8.8, wall=44886
2023-05-21 06:26:07 - progress_bar.py[line:272] - INFO: epoch 007:   1269 / 1732 loss=2.454, loss_v1=0, loss_v2=0, nll_loss=1.262, ntokens=1069.2, nsentences=32, sample_size=1069.2, sample_size_v1=0, sample_size_v2=0, ppl=2.4, wps=276.7, ups=0.26, wpb=1069.2, bsz=32, num_updates=11640, lr=8.25502e-06, gnorm=7.925, clip=100, loss_scale=64, train_wall=39, gb_free=8.3, wall=44924
2023-05-21 06:26:46 - progress_bar.py[line:272] - INFO: epoch 007:   1279 / 1732 loss=2.455, loss_v1=0, loss_v2=0, nll_loss=1.262, ntokens=1067, nsentences=32, sample_size=1067, sample_size_v1=0, sample_size_v2=0, ppl=2.4, wps=273.6, ups=0.26, wpb=1067, bsz=32, num_updates=11650, lr=8.25297e-06, gnorm=7.264, clip=100, loss_scale=64, train_wall=39, gb_free=8, wall=44963
2023-05-21 06:27:25 - progress_bar.py[line:272] - INFO: epoch 007:   1289 / 1732 loss=2.439, loss_v1=0, loss_v2=0, nll_loss=1.245, ntokens=1071, nsentences=32, sample_size=1071, sample_size_v1=0, sample_size_v2=0, ppl=2.37, wps=275.6, ups=0.26, wpb=1071, bsz=32, num_updates=11660, lr=8.25093e-06, gnorm=5.932, clip=100, loss_scale=64, train_wall=39, gb_free=7, wall=45002
2023-05-21 06:28:03 - progress_bar.py[line:272] - INFO: epoch 007:   1299 / 1732 loss=2.433, loss_v1=0, loss_v2=0, nll_loss=1.239, ntokens=1078.1, nsentences=32, sample_size=1078.1, sample_size_v1=0, sample_size_v2=0, ppl=2.36, wps=280.3, ups=0.26, wpb=1078.1, bsz=32, num_updates=11670, lr=8.24888e-06, gnorm=6.579, clip=100, loss_scale=64, train_wall=38, gb_free=8.6, wall=45041
2023-05-21 06:28:42 - progress_bar.py[line:272] - INFO: epoch 007:   1309 / 1732 loss=2.477, loss_v1=0, loss_v2=0, nll_loss=1.287, ntokens=1085.2, nsentences=32, sample_size=1085.2, sample_size_v1=0, sample_size_v2=0, ppl=2.44, wps=278.6, ups=0.26, wpb=1085.2, bsz=32, num_updates=11680, lr=8.24683e-06, gnorm=6.341, clip=100, loss_scale=64, train_wall=39, gb_free=7.9, wall=45080
2023-05-21 06:29:21 - progress_bar.py[line:272] - INFO: epoch 007:   1319 / 1732 loss=2.43, loss_v1=0, loss_v2=0, nll_loss=1.234, ntokens=1092.6, nsentences=32, sample_size=1092.6, sample_size_v1=0, sample_size_v2=0, ppl=2.35, wps=281.6, ups=0.26, wpb=1092.6, bsz=32, num_updates=11690, lr=8.24478e-06, gnorm=6.865, clip=100, loss_scale=64, train_wall=39, gb_free=7.9, wall=45118
2023-05-21 06:30:00 - progress_bar.py[line:272] - INFO: epoch 007:   1329 / 1732 loss=2.417, loss_v1=0, loss_v2=0, nll_loss=1.22, ntokens=1106.3, nsentences=32, sample_size=1106.3, sample_size_v1=0, sample_size_v2=0, ppl=2.33, wps=283.4, ups=0.26, wpb=1106.3, bsz=32, num_updates=11700, lr=8.24274e-06, gnorm=6.635, clip=100, loss_scale=128, train_wall=39, gb_free=8.5, wall=45157
2023-05-21 06:30:27 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2023-05-21 06:30:43 - progress_bar.py[line:272] - INFO: epoch 007:   1340 / 1732 loss=2.423, loss_v1=0, loss_v2=0, nll_loss=1.228, ntokens=1129.9, nsentences=32, sample_size=1129.9, sample_size_v1=0, sample_size_v2=0, ppl=2.34, wps=265.5, ups=0.23, wpb=1129.9, bsz=32, num_updates=11710, lr=8.24069e-06, gnorm=6.787, clip=100, loss_scale=64, train_wall=43, gb_free=8, wall=45200
2023-05-21 06:31:22 - progress_bar.py[line:272] - INFO: epoch 007:   1350 / 1732 loss=2.436, loss_v1=0, loss_v2=0, nll_loss=1.242, ntokens=1168.9, nsentences=32, sample_size=1168.9, sample_size_v1=0, sample_size_v2=0, ppl=2.37, wps=300.3, ups=0.26, wpb=1168.9, bsz=32, num_updates=11720, lr=8.23864e-06, gnorm=6.784, clip=100, loss_scale=64, train_wall=39, gb_free=8.5, wall=45239
2023-05-21 06:32:01 - progress_bar.py[line:272] - INFO: epoch 007:   1360 / 1732 loss=2.414, loss_v1=0, loss_v2=0, nll_loss=1.217, ntokens=1107.8, nsentences=32, sample_size=1107.8, sample_size_v1=0, sample_size_v2=0, ppl=2.32, wps=283.3, ups=0.26, wpb=1107.8, bsz=32, num_updates=11730, lr=8.23659e-06, gnorm=7.496, clip=100, loss_scale=64, train_wall=39, gb_free=8.3, wall=45278
2023-05-21 06:32:40 - progress_bar.py[line:272] - INFO: epoch 007:   1370 / 1732 loss=2.441, loss_v1=0, loss_v2=0, nll_loss=1.248, ntokens=1111.1, nsentences=32, sample_size=1111.1, sample_size_v1=0, sample_size_v2=0, ppl=2.37, wps=284.5, ups=0.26, wpb=1111.1, bsz=32, num_updates=11740, lr=8.23455e-06, gnorm=6.53, clip=100, loss_scale=64, train_wall=39, gb_free=8.3, wall=45317
2023-05-21 06:33:19 - progress_bar.py[line:272] - INFO: epoch 007:   1380 / 1732 loss=2.467, loss_v1=0, loss_v2=0, nll_loss=1.277, ntokens=1113.4, nsentences=32, sample_size=1113.4, sample_size_v1=0, sample_size_v2=0, ppl=2.42, wps=287.5, ups=0.26, wpb=1113.4, bsz=32, num_updates=11750, lr=8.2325e-06, gnorm=7.162, clip=100, loss_scale=64, train_wall=39, gb_free=7.6, wall=45356
2023-05-21 06:33:57 - progress_bar.py[line:272] - INFO: epoch 007:   1390 / 1732 loss=2.445, loss_v1=0, loss_v2=0, nll_loss=1.251, ntokens=1104, nsentences=32, sample_size=1104, sample_size_v1=0, sample_size_v2=0, ppl=2.38, wps=286.4, ups=0.26, wpb=1104, bsz=32, num_updates=11760, lr=8.23045e-06, gnorm=7.037, clip=100, loss_scale=64, train_wall=38, gb_free=8.3, wall=45394
2023-05-21 06:34:36 - progress_bar.py[line:272] - INFO: epoch 007:   1400 / 1732 loss=2.411, loss_v1=0, loss_v2=0, nll_loss=1.213, ntokens=1114.6, nsentences=32, sample_size=1114.6, sample_size_v1=0, sample_size_v2=0, ppl=2.32, wps=287.6, ups=0.26, wpb=1114.6, bsz=32, num_updates=11770, lr=8.22841e-06, gnorm=6.5, clip=100, loss_scale=64, train_wall=39, gb_free=8.2, wall=45433
2023-05-21 06:35:15 - progress_bar.py[line:272] - INFO: epoch 007:   1410 / 1732 loss=2.463, loss_v1=0, loss_v2=0, nll_loss=1.271, ntokens=1192.3, nsentences=32, sample_size=1192.3, sample_size_v1=0, sample_size_v2=0, ppl=2.41, wps=306.7, ups=0.26, wpb=1192.3, bsz=32, num_updates=11780, lr=8.22636e-06, gnorm=6.483, clip=100, loss_scale=64, train_wall=39, gb_free=8.1, wall=45472
2023-05-21 06:35:54 - progress_bar.py[line:272] - INFO: epoch 007:   1420 / 1732 loss=2.443, loss_v1=0, loss_v2=0, nll_loss=1.251, ntokens=1265.6, nsentences=32, sample_size=1265.6, sample_size_v1=0, sample_size_v2=0, ppl=2.38, wps=320.4, ups=0.25, wpb=1265.6, bsz=32, num_updates=11790, lr=8.22431e-06, gnorm=5.942, clip=100, loss_scale=64, train_wall=39, gb_free=8.3, wall=45511
2023-05-21 06:36:34 - progress_bar.py[line:272] - INFO: epoch 007:   1430 / 1732 loss=2.414, loss_v1=0, loss_v2=0, nll_loss=1.218, ntokens=1231, nsentences=32, sample_size=1231, sample_size_v1=0, sample_size_v2=0, ppl=2.33, wps=312.7, ups=0.25, wpb=1231, bsz=32, num_updates=11800, lr=8.22226e-06, gnorm=5.921, clip=100, loss_scale=64, train_wall=39, gb_free=6.8, wall=45551
2023-05-21 06:37:13 - progress_bar.py[line:272] - INFO: epoch 007:   1440 / 1732 loss=2.443, loss_v1=0, loss_v2=0, nll_loss=1.251, ntokens=1169.2, nsentences=32, sample_size=1169.2, sample_size_v1=0, sample_size_v2=0, ppl=2.38, wps=300.6, ups=0.26, wpb=1169.2, bsz=32, num_updates=11810, lr=8.22022e-06, gnorm=6.085, clip=100, loss_scale=64, train_wall=39, gb_free=8.8, wall=45590
2023-05-21 06:37:51 - progress_bar.py[line:272] - INFO: epoch 007:   1450 / 1732 loss=2.448, loss_v1=0, loss_v2=0, nll_loss=1.253, ntokens=1100.3, nsentences=32, sample_size=1100.3, sample_size_v1=0, sample_size_v2=0, ppl=2.38, wps=284.5, ups=0.26, wpb=1100.3, bsz=32, num_updates=11820, lr=8.21817e-06, gnorm=6.444, clip=100, loss_scale=64, train_wall=39, gb_free=8.2, wall=45628
2023-05-21 06:38:30 - progress_bar.py[line:272] - INFO: epoch 007:   1460 / 1732 loss=2.425, loss_v1=0, loss_v2=0, nll_loss=1.229, ntokens=1171.4, nsentences=32, sample_size=1171.4, sample_size_v1=0, sample_size_v2=0, ppl=2.34, wps=301.6, ups=0.26, wpb=1171.4, bsz=32, num_updates=11830, lr=8.21612e-06, gnorm=6.421, clip=100, loss_scale=64, train_wall=39, gb_free=8.3, wall=45667
2023-05-21 06:39:09 - progress_bar.py[line:272] - INFO: epoch 007:   1470 / 1732 loss=2.424, loss_v1=0, loss_v2=0, nll_loss=1.232, ntokens=1176.9, nsentences=32, sample_size=1176.9, sample_size_v1=0, sample_size_v2=0, ppl=2.35, wps=303.2, ups=0.26, wpb=1176.9, bsz=32, num_updates=11840, lr=8.21407e-06, gnorm=6.726, clip=100, loss_scale=64, train_wall=39, gb_free=6.7, wall=45706
2023-05-21 06:39:47 - progress_bar.py[line:272] - INFO: epoch 007:   1480 / 1732 loss=2.462, loss_v1=0, loss_v2=0, nll_loss=1.27, ntokens=1035.6, nsentences=32, sample_size=1035.6, sample_size_v1=0, sample_size_v2=0, ppl=2.41, wps=269.4, ups=0.26, wpb=1035.6, bsz=32, num_updates=11850, lr=8.21203e-06, gnorm=7.334, clip=100, loss_scale=64, train_wall=38, gb_free=8.6, wall=45745
2023-05-21 06:40:26 - progress_bar.py[line:272] - INFO: epoch 007:   1490 / 1732 loss=2.429, loss_v1=0, loss_v2=0, nll_loss=1.231, ntokens=1129.4, nsentences=32, sample_size=1129.4, sample_size_v1=0, sample_size_v2=0, ppl=2.35, wps=291.1, ups=0.26, wpb=1129.4, bsz=32, num_updates=11860, lr=8.20998e-06, gnorm=6.115, clip=100, loss_scale=64, train_wall=39, gb_free=8.6, wall=45783
2023-05-21 06:41:05 - progress_bar.py[line:272] - INFO: epoch 007:   1500 / 1732 loss=2.407, loss_v1=0, loss_v2=0, nll_loss=1.209, ntokens=1104.6, nsentences=32, sample_size=1104.6, sample_size_v1=0, sample_size_v2=0, ppl=2.31, wps=286.4, ups=0.26, wpb=1104.6, bsz=32, num_updates=11870, lr=8.20793e-06, gnorm=6.224, clip=100, loss_scale=64, train_wall=39, gb_free=8.6, wall=45822
2023-05-21 06:41:43 - progress_bar.py[line:272] - INFO: epoch 007:   1510 / 1732 loss=2.412, loss_v1=0, loss_v2=0, nll_loss=1.219, ntokens=1117.2, nsentences=32, sample_size=1117.2, sample_size_v1=0, sample_size_v2=0, ppl=2.33, wps=290.2, ups=0.26, wpb=1117.2, bsz=32, num_updates=11880, lr=8.20588e-06, gnorm=6.462, clip=100, loss_scale=64, train_wall=38, gb_free=7.9, wall=45860
2023-05-21 06:42:22 - progress_bar.py[line:272] - INFO: epoch 007:   1520 / 1732 loss=2.457, loss_v1=0, loss_v2=0, nll_loss=1.266, ntokens=1039.7, nsentences=32, sample_size=1039.7, sample_size_v1=0, sample_size_v2=0, ppl=2.41, wps=268.9, ups=0.26, wpb=1039.7, bsz=32, num_updates=11890, lr=8.20384e-06, gnorm=6.146, clip=100, loss_scale=64, train_wall=39, gb_free=8.7, wall=45899
2023-05-21 06:43:01 - progress_bar.py[line:272] - INFO: epoch 007:   1530 / 1732 loss=2.475, loss_v1=0, loss_v2=0, nll_loss=1.281, ntokens=1056.8, nsentences=32, sample_size=1056.8, sample_size_v1=0, sample_size_v2=0, ppl=2.43, wps=273, ups=0.26, wpb=1056.8, bsz=32, num_updates=11900, lr=8.20179e-06, gnorm=6.684, clip=100, loss_scale=64, train_wall=39, gb_free=7.7, wall=45938
2023-05-21 06:43:39 - progress_bar.py[line:272] - INFO: epoch 007:   1540 / 1732 loss=2.425, loss_v1=0, loss_v2=0, nll_loss=1.229, ntokens=1106.8, nsentences=32, sample_size=1106.8, sample_size_v1=0, sample_size_v2=0, ppl=2.34, wps=285.1, ups=0.26, wpb=1106.8, bsz=32, num_updates=11910, lr=8.19974e-06, gnorm=6.48, clip=100, loss_scale=64, train_wall=39, gb_free=8, wall=45977
2023-05-21 06:44:18 - progress_bar.py[line:272] - INFO: epoch 007:   1550 / 1732 loss=2.424, loss_v1=0, loss_v2=0, nll_loss=1.229, ntokens=1063.7, nsentences=32, sample_size=1063.7, sample_size_v1=0, sample_size_v2=0, ppl=2.34, wps=276.7, ups=0.26, wpb=1063.7, bsz=32, num_updates=11920, lr=8.19769e-06, gnorm=6.763, clip=100, loss_scale=64, train_wall=38, gb_free=7.9, wall=46015
2023-05-21 06:44:57 - progress_bar.py[line:272] - INFO: epoch 007:   1560 / 1732 loss=2.445, loss_v1=0, loss_v2=0, nll_loss=1.253, ntokens=1090.1, nsentences=32, sample_size=1090.1, sample_size_v1=0, sample_size_v2=0, ppl=2.38, wps=282.2, ups=0.26, wpb=1090.1, bsz=32, num_updates=11930, lr=8.19565e-06, gnorm=6.74, clip=100, loss_scale=64, train_wall=39, gb_free=7.5, wall=46054
2023-05-21 06:45:35 - progress_bar.py[line:272] - INFO: epoch 007:   1570 / 1732 loss=2.479, loss_v1=0, loss_v2=0, nll_loss=1.289, ntokens=1073.5, nsentences=32, sample_size=1073.5, sample_size_v1=0, sample_size_v2=0, ppl=2.44, wps=276.9, ups=0.26, wpb=1073.5, bsz=32, num_updates=11940, lr=8.1936e-06, gnorm=7.535, clip=100, loss_scale=64, train_wall=39, gb_free=8.5, wall=46092
2023-05-21 06:46:14 - progress_bar.py[line:272] - INFO: epoch 007:   1580 / 1732 loss=2.474, loss_v1=0, loss_v2=0, nll_loss=1.282, ntokens=980.3, nsentences=32, sample_size=980.3, sample_size_v1=0, sample_size_v2=0, ppl=2.43, wps=255.6, ups=0.26, wpb=980.3, bsz=32, num_updates=11950, lr=8.19155e-06, gnorm=8.67, clip=100, loss_scale=64, train_wall=38, gb_free=8.9, wall=46131
2023-05-21 06:46:52 - progress_bar.py[line:272] - INFO: epoch 007:   1590 / 1732 loss=2.433, loss_v1=0, loss_v2=0, nll_loss=1.237, ntokens=1103, nsentences=32, sample_size=1103, sample_size_v1=0, sample_size_v2=0, ppl=2.36, wps=285.2, ups=0.26, wpb=1103, bsz=32, num_updates=11960, lr=8.18951e-06, gnorm=7.15, clip=100, loss_scale=64, train_wall=39, gb_free=7.7, wall=46170
2023-05-21 06:47:31 - progress_bar.py[line:272] - INFO: epoch 007:   1600 / 1732 loss=2.42, loss_v1=0, loss_v2=0, nll_loss=1.226, ntokens=1067.6, nsentences=32, sample_size=1067.6, sample_size_v1=0, sample_size_v2=0, ppl=2.34, wps=277.6, ups=0.26, wpb=1067.6, bsz=32, num_updates=11970, lr=8.18746e-06, gnorm=6.879, clip=100, loss_scale=64, train_wall=38, gb_free=8.1, wall=46208
2023-05-21 06:48:10 - progress_bar.py[line:272] - INFO: epoch 007:   1610 / 1732 loss=2.409, loss_v1=0, loss_v2=0, nll_loss=1.211, ntokens=1149.4, nsentences=32, sample_size=1149.4, sample_size_v1=0, sample_size_v2=0, ppl=2.32, wps=295.6, ups=0.26, wpb=1149.4, bsz=32, num_updates=11980, lr=8.18541e-06, gnorm=6.075, clip=100, loss_scale=64, train_wall=39, gb_free=8.4, wall=46247
2023-05-21 06:48:49 - progress_bar.py[line:272] - INFO: epoch 007:   1620 / 1732 loss=2.384, loss_v1=0, loss_v2=0, nll_loss=1.185, ntokens=1143.9, nsentences=32, sample_size=1143.9, sample_size_v1=0, sample_size_v2=0, ppl=2.27, wps=294.5, ups=0.26, wpb=1143.9, bsz=32, num_updates=11990, lr=8.18336e-06, gnorm=7.304, clip=100, loss_scale=64, train_wall=39, gb_free=7.8, wall=46286
2023-05-21 06:49:27 - progress_bar.py[line:272] - INFO: epoch 007:   1630 / 1732 loss=2.426, loss_v1=0, loss_v2=0, nll_loss=1.232, ntokens=1148.8, nsentences=32, sample_size=1148.8, sample_size_v1=0, sample_size_v2=0, ppl=2.35, wps=295.7, ups=0.26, wpb=1148.8, bsz=32, num_updates=12000, lr=8.18132e-06, gnorm=6.098, clip=100, loss_scale=64, train_wall=39, gb_free=8.7, wall=46325
2023-05-21 06:50:06 - progress_bar.py[line:272] - INFO: epoch 007:   1640 / 1732 loss=2.398, loss_v1=0, loss_v2=0, nll_loss=1.196, ntokens=1148.2, nsentences=32, sample_size=1148.2, sample_size_v1=0, sample_size_v2=0, ppl=2.29, wps=298, ups=0.26, wpb=1148.2, bsz=32, num_updates=12010, lr=8.17927e-06, gnorm=6.25, clip=100, loss_scale=64, train_wall=38, gb_free=8, wall=46363
2023-05-21 06:50:45 - progress_bar.py[line:272] - INFO: epoch 007:   1650 / 1732 loss=2.41, loss_v1=0, loss_v2=0, nll_loss=1.212, ntokens=1158.7, nsentences=32, sample_size=1158.7, sample_size_v1=0, sample_size_v2=0, ppl=2.32, wps=296.6, ups=0.26, wpb=1158.7, bsz=32, num_updates=12020, lr=8.17722e-06, gnorm=6.65, clip=100, loss_scale=64, train_wall=39, gb_free=9, wall=46402
2023-05-21 06:51:23 - progress_bar.py[line:272] - INFO: epoch 007:   1660 / 1732 loss=2.455, loss_v1=0, loss_v2=0, nll_loss=1.265, ntokens=997.6, nsentences=32, sample_size=997.6, sample_size_v1=0, sample_size_v2=0, ppl=2.4, wps=259.1, ups=0.26, wpb=997.6, bsz=32, num_updates=12030, lr=8.17517e-06, gnorm=7.292, clip=100, loss_scale=64, train_wall=38, gb_free=8.5, wall=46441
2023-05-21 06:52:02 - progress_bar.py[line:272] - INFO: epoch 007:   1670 / 1732 loss=2.439, loss_v1=0, loss_v2=0, nll_loss=1.243, ntokens=1015.8, nsentences=32, sample_size=1015.8, sample_size_v1=0, sample_size_v2=0, ppl=2.37, wps=263.7, ups=0.26, wpb=1015.8, bsz=32, num_updates=12040, lr=8.17313e-06, gnorm=6.506, clip=100, loss_scale=64, train_wall=38, gb_free=8.6, wall=46479
2023-05-21 06:52:41 - progress_bar.py[line:272] - INFO: epoch 007:   1680 / 1732 loss=2.381, loss_v1=0, loss_v2=0, nll_loss=1.178, ntokens=1181.3, nsentences=32, sample_size=1181.3, sample_size_v1=0, sample_size_v2=0, ppl=2.26, wps=302.8, ups=0.26, wpb=1181.3, bsz=32, num_updates=12050, lr=8.17108e-06, gnorm=6.083, clip=100, loss_scale=64, train_wall=39, gb_free=8.2, wall=46518
2023-05-21 06:53:20 - progress_bar.py[line:272] - INFO: epoch 007:   1690 / 1732 loss=2.422, loss_v1=0, loss_v2=0, nll_loss=1.231, ntokens=1198.5, nsentences=32, sample_size=1198.5, sample_size_v1=0, sample_size_v2=0, ppl=2.35, wps=307.2, ups=0.26, wpb=1198.5, bsz=32, num_updates=12060, lr=8.16903e-06, gnorm=6.181, clip=100, loss_scale=64, train_wall=39, gb_free=8, wall=46557
2023-05-21 06:53:59 - progress_bar.py[line:272] - INFO: epoch 007:   1700 / 1732 loss=2.412, loss_v1=0, loss_v2=0, nll_loss=1.214, ntokens=1281, nsentences=32, sample_size=1281, sample_size_v1=0, sample_size_v2=0, ppl=2.32, wps=325.1, ups=0.25, wpb=1281, bsz=32, num_updates=12070, lr=8.16698e-06, gnorm=5.881, clip=100, loss_scale=64, train_wall=39, gb_free=8.4, wall=46597
2023-05-21 06:54:38 - progress_bar.py[line:272] - INFO: epoch 007:   1710 / 1732 loss=2.432, loss_v1=0, loss_v2=0, nll_loss=1.235, ntokens=1170.9, nsentences=32, sample_size=1170.9, sample_size_v1=0, sample_size_v2=0, ppl=2.35, wps=301.1, ups=0.26, wpb=1170.9, bsz=32, num_updates=12080, lr=8.16494e-06, gnorm=6.551, clip=100, loss_scale=64, train_wall=39, gb_free=7.2, wall=46636
2023-05-21 06:55:17 - progress_bar.py[line:272] - INFO: epoch 007:   1720 / 1732 loss=2.411, loss_v1=0, loss_v2=0, nll_loss=1.215, ntokens=1171, nsentences=32, sample_size=1171, sample_size_v1=0, sample_size_v2=0, ppl=2.32, wps=299.2, ups=0.26, wpb=1171, bsz=32, num_updates=12090, lr=8.16289e-06, gnorm=5.556, clip=100, loss_scale=64, train_wall=39, gb_free=8.4, wall=46675
2023-05-21 06:55:56 - progress_bar.py[line:272] - INFO: epoch 007:   1730 / 1732 loss=2.466, loss_v1=0, loss_v2=0, nll_loss=1.274, ntokens=1126.4, nsentences=32, sample_size=1126.4, sample_size_v1=0, sample_size_v2=0, ppl=2.42, wps=290.3, ups=0.26, wpb=1126.4, bsz=32, num_updates=12100, lr=8.16084e-06, gnorm=5.566, clip=100, loss_scale=64, train_wall=39, gb_free=8.1, wall=46713
2023-05-21 06:56:01 - train.py[line:332] - INFO: end of epoch 7 (average epoch stats below)
2023-05-21 06:56:01 - progress_bar.py[line:282] - INFO: epoch 007 | loss 2.442 | loss_v1 0 | loss_v2 0 | nll_loss 1.249 | ntokens 1051.5 | nsentences 31.986 | sample_size 1051.5 | sample_size_v1 0 | sample_size_v2 0 | ppl 2.38 | wps 272.8 | ups 0.26 | wpb 1051.5 | bsz 32 | num_updates 12102 | lr 8.16043e-06 | gnorm 6.373 | clip 100 | loss_scale 64 | train_wall 6654 | gb_free 8.9 | wall 46718
2023-05-21 06:56:01 - trainer.py[line:639] - INFO: loading train data for epoch 8
local datafile ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 0 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 0 finished initializing row_count and line_idx-to-offset mapping
file ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 0 row count 55400 total row count 55400
slice_id 0 seek offset 0
2023-05-21 06:56:03 - trainer.py[line:703] - INFO: begin training epoch 8
2023-05-21 06:56:03 - train.py[line:305] - INFO: Start iterating over samples
2023-05-21 06:56:34 - progress_bar.py[line:272] - INFO: epoch 008:      8 / 1732 loss=2.361, loss_v1=0, loss_v2=0, nll_loss=1.154, ntokens=1080.1, nsentences=29.6, sample_size=1080.1, sample_size_v1=0, sample_size_v2=0, ppl=2.23, wps=283.8, ups=0.26, wpb=1080.1, bsz=29.6, num_updates=12110, lr=8.15879e-06, gnorm=6.071, clip=100, loss_scale=64, train_wall=36, gb_free=7.4, wall=46752
2023-05-21 06:57:13 - progress_bar.py[line:272] - INFO: epoch 008:     18 / 1732 loss=2.331, loss_v1=0, loss_v2=0, nll_loss=1.126, ntokens=1071.6, nsentences=32, sample_size=1071.6, sample_size_v1=0, sample_size_v2=0, ppl=2.18, wps=277.1, ups=0.26, wpb=1071.6, bsz=32, num_updates=12120, lr=8.15675e-06, gnorm=7.255, clip=100, loss_scale=64, train_wall=39, gb_free=8.3, wall=46790
2023-05-21 06:57:52 - progress_bar.py[line:272] - INFO: epoch 008:     28 / 1732 loss=2.404, loss_v1=0, loss_v2=0, nll_loss=1.204, ntokens=959.8, nsentences=32, sample_size=959.8, sample_size_v1=0, sample_size_v2=0, ppl=2.3, wps=248.9, ups=0.26, wpb=959.8, bsz=32, num_updates=12130, lr=8.1547e-06, gnorm=8.007, clip=100, loss_scale=64, train_wall=39, gb_free=8.5, wall=46829
2023-05-21 06:58:31 - progress_bar.py[line:272] - INFO: epoch 008:     38 / 1732 loss=2.204, loss_v1=0, loss_v2=0, nll_loss=0.98, ntokens=1177.1, nsentences=32, sample_size=1177.1, sample_size_v1=0, sample_size_v2=0, ppl=1.97, wps=300.5, ups=0.26, wpb=1177.1, bsz=32, num_updates=12140, lr=8.15265e-06, gnorm=5.741, clip=100, loss_scale=64, train_wall=39, gb_free=8.5, wall=46868
2023-05-21 06:59:10 - progress_bar.py[line:272] - INFO: epoch 008:     48 / 1732 loss=2.272, loss_v1=0, loss_v2=0, nll_loss=1.065, ntokens=1064.2, nsentences=32, sample_size=1064.2, sample_size_v1=0, sample_size_v2=0, ppl=2.09, wps=273.8, ups=0.26, wpb=1064.2, bsz=32, num_updates=12150, lr=8.1506e-06, gnorm=7.777, clip=100, loss_scale=64, train_wall=39, gb_free=7.9, wall=46907
2023-05-21 06:59:48 - progress_bar.py[line:272] - INFO: epoch 008:     58 / 1732 loss=2.135, loss_v1=0, loss_v2=0, nll_loss=0.899, ntokens=1039.9, nsentences=32, sample_size=1039.9, sample_size_v1=0, sample_size_v2=0, ppl=1.86, wps=269.5, ups=0.26, wpb=1039.9, bsz=32, num_updates=12160, lr=8.14856e-06, gnorm=5.951, clip=100, loss_scale=64, train_wall=39, gb_free=8.8, wall=46945
2023-05-21 07:00:29 - progress_bar.py[line:272] - INFO: epoch 008:     68 / 1732 loss=2.08, loss_v1=0, loss_v2=0, nll_loss=0.849, ntokens=1401.1, nsentences=32, sample_size=1401.1, sample_size_v1=0, sample_size_v2=0, ppl=1.8, wps=347.7, ups=0.25, wpb=1401.1, bsz=32, num_updates=12170, lr=8.14651e-06, gnorm=4.457, clip=100, loss_scale=64, train_wall=40, gb_free=7.2, wall=46986
2023-05-21 07:01:08 - progress_bar.py[line:272] - INFO: epoch 008:     78 / 1732 loss=2.209, loss_v1=0, loss_v2=0, nll_loss=0.981, ntokens=1268.8, nsentences=32, sample_size=1268.8, sample_size_v1=0, sample_size_v2=0, ppl=1.97, wps=318.7, ups=0.25, wpb=1268.8, bsz=32, num_updates=12180, lr=8.14446e-06, gnorm=5.565, clip=100, loss_scale=64, train_wall=40, gb_free=6.8, wall=47026
2023-05-21 07:01:48 - progress_bar.py[line:272] - INFO: epoch 008:     88 / 1732 loss=2.279, loss_v1=0, loss_v2=0, nll_loss=1.069, ntokens=1100.2, nsentences=32, sample_size=1100.2, sample_size_v1=0, sample_size_v2=0, ppl=2.1, wps=279.3, ups=0.25, wpb=1100.2, bsz=32, num_updates=12190, lr=8.14242e-06, gnorm=5.794, clip=100, loss_scale=64, train_wall=39, gb_free=8.1, wall=47065
2023-05-21 07:02:27 - progress_bar.py[line:272] - INFO: epoch 008:     98 / 1732 loss=2.239, loss_v1=0, loss_v2=0, nll_loss=1.021, ntokens=1080.6, nsentences=32, sample_size=1080.6, sample_size_v1=0, sample_size_v2=0, ppl=2.03, wps=277.5, ups=0.26, wpb=1080.6, bsz=32, num_updates=12200, lr=8.14037e-06, gnorm=6.223, clip=100, loss_scale=64, train_wall=39, gb_free=8.4, wall=47104
2023-05-21 07:03:05 - progress_bar.py[line:272] - INFO: epoch 008:    108 / 1732 loss=2.448, loss_v1=0, loss_v2=0, nll_loss=1.259, ntokens=978.3, nsentences=32, sample_size=978.3, sample_size_v1=0, sample_size_v2=0, ppl=2.39, wps=255.7, ups=0.26, wpb=978.3, bsz=32, num_updates=12210, lr=8.13832e-06, gnorm=6.306, clip=100, loss_scale=64, train_wall=38, gb_free=8.9, wall=47142
2023-05-21 07:03:44 - progress_bar.py[line:272] - INFO: epoch 008:    118 / 1732 loss=2.42, loss_v1=0, loss_v2=0, nll_loss=1.225, ntokens=1087, nsentences=32, sample_size=1087, sample_size_v1=0, sample_size_v2=0, ppl=2.34, wps=277.7, ups=0.26, wpb=1087, bsz=32, num_updates=12220, lr=8.13627e-06, gnorm=5.954, clip=100, loss_scale=128, train_wall=39, gb_free=8.1, wall=47181
2023-05-21 07:04:23 - progress_bar.py[line:272] - INFO: epoch 008:    128 / 1732 loss=2.38, loss_v1=0, loss_v2=0, nll_loss=1.176, ntokens=1177.5, nsentences=32, sample_size=1177.5, sample_size_v1=0, sample_size_v2=0, ppl=2.26, wps=298.9, ups=0.25, wpb=1177.5, bsz=32, num_updates=12230, lr=8.13423e-06, gnorm=6.133, clip=100, loss_scale=128, train_wall=39, gb_free=8.6, wall=47221
2023-05-21 07:04:43 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2023-05-21 07:05:07 - progress_bar.py[line:272] - INFO: epoch 008:    139 / 1732 loss=2.346, loss_v1=0, loss_v2=0, nll_loss=1.138, ntokens=1243.7, nsentences=32, sample_size=1243.7, sample_size_v1=0, sample_size_v2=0, ppl=2.2, wps=288.1, ups=0.23, wpb=1243.7, bsz=32, num_updates=12240, lr=8.13218e-06, gnorm=5.404, clip=100, loss_scale=64, train_wall=43, gb_free=7.4, wall=47264
2023-05-21 07:05:46 - progress_bar.py[line:272] - INFO: epoch 008:    149 / 1732 loss=2.314, loss_v1=0, loss_v2=0, nll_loss=1.106, ntokens=1177.5, nsentences=32, sample_size=1177.5, sample_size_v1=0, sample_size_v2=0, ppl=2.15, wps=297.6, ups=0.25, wpb=1177.5, bsz=32, num_updates=12250, lr=8.13013e-06, gnorm=5.068, clip=100, loss_scale=64, train_wall=40, gb_free=7.4, wall=47303
2023-05-21 07:06:26 - progress_bar.py[line:272] - INFO: epoch 008:    159 / 1732 loss=2.355, loss_v1=0, loss_v2=0, nll_loss=1.154, ntokens=1139.9, nsentences=32, sample_size=1139.9, sample_size_v1=0, sample_size_v2=0, ppl=2.23, wps=288.1, ups=0.25, wpb=1139.9, bsz=32, num_updates=12260, lr=8.12808e-06, gnorm=5.659, clip=100, loss_scale=64, train_wall=40, gb_free=8.5, wall=47343
2023-05-21 07:07:05 - progress_bar.py[line:272] - INFO: epoch 008:    169 / 1732 loss=2.333, loss_v1=0, loss_v2=0, nll_loss=1.123, ntokens=986.6, nsentences=32, sample_size=986.6, sample_size_v1=0, sample_size_v2=0, ppl=2.18, wps=254.7, ups=0.26, wpb=986.6, bsz=32, num_updates=12270, lr=8.12604e-06, gnorm=5.481, clip=100, loss_scale=64, train_wall=39, gb_free=8.5, wall=47382
2023-05-21 07:07:43 - progress_bar.py[line:272] - INFO: epoch 008:    179 / 1732 loss=2.317, loss_v1=0, loss_v2=0, nll_loss=1.109, ntokens=1076.1, nsentences=32, sample_size=1076.1, sample_size_v1=0, sample_size_v2=0, ppl=2.16, wps=276.2, ups=0.26, wpb=1076.1, bsz=32, num_updates=12280, lr=8.12399e-06, gnorm=5.91, clip=100, loss_scale=64, train_wall=39, gb_free=7.7, wall=47421
2023-05-21 07:08:23 - progress_bar.py[line:272] - INFO: epoch 008:    189 / 1732 loss=2.31, loss_v1=0, loss_v2=0, nll_loss=1.101, ntokens=1120.4, nsentences=32, sample_size=1120.4, sample_size_v1=0, sample_size_v2=0, ppl=2.14, wps=284.7, ups=0.25, wpb=1120.4, bsz=32, num_updates=12290, lr=8.12194e-06, gnorm=5.744, clip=100, loss_scale=64, train_wall=39, gb_free=8.7, wall=47460
2023-05-21 07:09:02 - progress_bar.py[line:272] - INFO: epoch 008:    199 / 1732 loss=2.367, loss_v1=0, loss_v2=0, nll_loss=1.165, ntokens=1141, nsentences=32, sample_size=1141, sample_size_v1=0, sample_size_v2=0, ppl=2.24, wps=291, ups=0.26, wpb=1141, bsz=32, num_updates=12300, lr=8.11989e-06, gnorm=6.253, clip=100, loss_scale=64, train_wall=39, gb_free=8.8, wall=47499
2023-05-21 07:09:40 - progress_bar.py[line:272] - INFO: epoch 008:    209 / 1732 loss=2.478, loss_v1=0, loss_v2=0, nll_loss=1.29, ntokens=970.7, nsentences=32, sample_size=970.7, sample_size_v1=0, sample_size_v2=0, ppl=2.44, wps=253.2, ups=0.26, wpb=970.7, bsz=32, num_updates=12310, lr=8.11785e-06, gnorm=6.763, clip=100, loss_scale=64, train_wall=38, gb_free=7.4, wall=47538
2023-05-21 07:10:19 - progress_bar.py[line:272] - INFO: epoch 008:    219 / 1732 loss=2.466, loss_v1=0, loss_v2=0, nll_loss=1.274, ntokens=1152.7, nsentences=32, sample_size=1152.7, sample_size_v1=0, sample_size_v2=0, ppl=2.42, wps=299.3, ups=0.26, wpb=1152.7, bsz=32, num_updates=12320, lr=8.1158e-06, gnorm=6.322, clip=100, loss_scale=64, train_wall=38, gb_free=8.5, wall=47576
2023-05-21 07:10:57 - progress_bar.py[line:272] - INFO: epoch 008:    229 / 1732 loss=2.466, loss_v1=0, loss_v2=0, nll_loss=1.274, ntokens=1096.1, nsentences=32, sample_size=1096.1, sample_size_v1=0, sample_size_v2=0, ppl=2.42, wps=284.7, ups=0.26, wpb=1096.1, bsz=32, num_updates=12330, lr=8.11375e-06, gnorm=7.469, clip=100, loss_scale=64, train_wall=38, gb_free=8.9, wall=47615
2023-05-21 07:11:36 - progress_bar.py[line:272] - INFO: epoch 008:    239 / 1732 loss=2.51, loss_v1=0, loss_v2=0, nll_loss=1.322, ntokens=1117, nsentences=32, sample_size=1117, sample_size_v1=0, sample_size_v2=0, ppl=2.5, wps=289.9, ups=0.26, wpb=1117, bsz=32, num_updates=12340, lr=8.1117e-06, gnorm=7.157, clip=100, loss_scale=64, train_wall=38, gb_free=8, wall=47653
2023-05-21 07:12:14 - progress_bar.py[line:272] - INFO: epoch 008:    249 / 1732 loss=2.472, loss_v1=0, loss_v2=0, nll_loss=1.279, ntokens=1165.4, nsentences=32, sample_size=1165.4, sample_size_v1=0, sample_size_v2=0, ppl=2.43, wps=302.4, ups=0.26, wpb=1165.4, bsz=32, num_updates=12350, lr=8.10966e-06, gnorm=5.817, clip=100, loss_scale=64, train_wall=38, gb_free=8.4, wall=47692
2023-05-21 07:12:53 - progress_bar.py[line:272] - INFO: epoch 008:    259 / 1732 loss=2.487, loss_v1=0, loss_v2=0, nll_loss=1.299, ntokens=1119.2, nsentences=32, sample_size=1119.2, sample_size_v1=0, sample_size_v2=0, ppl=2.46, wps=289, ups=0.26, wpb=1119.2, bsz=32, num_updates=12360, lr=8.10761e-06, gnorm=6.36, clip=100, loss_scale=64, train_wall=39, gb_free=8.2, wall=47730
2023-05-21 07:13:32 - progress_bar.py[line:272] - INFO: epoch 008:    269 / 1732 loss=2.475, loss_v1=0, loss_v2=0, nll_loss=1.284, ntokens=1154.8, nsentences=32, sample_size=1154.8, sample_size_v1=0, sample_size_v2=0, ppl=2.43, wps=300.4, ups=0.26, wpb=1154.8, bsz=32, num_updates=12370, lr=8.10556e-06, gnorm=5.913, clip=100, loss_scale=64, train_wall=38, gb_free=8.1, wall=47769
2023-05-21 07:14:10 - progress_bar.py[line:272] - INFO: epoch 008:    279 / 1732 loss=2.476, loss_v1=0, loss_v2=0, nll_loss=1.286, ntokens=1151.7, nsentences=32, sample_size=1151.7, sample_size_v1=0, sample_size_v2=0, ppl=2.44, wps=297.2, ups=0.26, wpb=1151.7, bsz=32, num_updates=12380, lr=8.10352e-06, gnorm=6.52, clip=100, loss_scale=64, train_wall=39, gb_free=7.9, wall=47808
2023-05-21 07:14:49 - progress_bar.py[line:272] - INFO: epoch 008:    289 / 1732 loss=2.461, loss_v1=0, loss_v2=0, nll_loss=1.271, ntokens=1147.9, nsentences=32, sample_size=1147.9, sample_size_v1=0, sample_size_v2=0, ppl=2.41, wps=299.8, ups=0.26, wpb=1147.9, bsz=32, num_updates=12390, lr=8.10147e-06, gnorm=6.532, clip=100, loss_scale=64, train_wall=38, gb_free=9.1, wall=47846
2023-05-21 07:15:27 - progress_bar.py[line:272] - INFO: epoch 008:    299 / 1732 loss=2.472, loss_v1=0, loss_v2=0, nll_loss=1.281, ntokens=1105.2, nsentences=32, sample_size=1105.2, sample_size_v1=0, sample_size_v2=0, ppl=2.43, wps=289.4, ups=0.26, wpb=1105.2, bsz=32, num_updates=12400, lr=8.09942e-06, gnorm=6.608, clip=100, loss_scale=64, train_wall=38, gb_free=8.3, wall=47884
2023-05-21 07:16:05 - progress_bar.py[line:272] - INFO: epoch 008:    309 / 1732 loss=2.454, loss_v1=0, loss_v2=0, nll_loss=1.261, ntokens=1071, nsentences=32, sample_size=1071, sample_size_v1=0, sample_size_v2=0, ppl=2.4, wps=280.4, ups=0.26, wpb=1071, bsz=32, num_updates=12410, lr=8.09737e-06, gnorm=6.75, clip=100, loss_scale=64, train_wall=38, gb_free=8.5, wall=47922
2023-05-21 07:16:43 - progress_bar.py[line:272] - INFO: epoch 008:    319 / 1732 loss=2.481, loss_v1=0, loss_v2=0, nll_loss=1.292, ntokens=1020.8, nsentences=32, sample_size=1020.8, sample_size_v1=0, sample_size_v2=0, ppl=2.45, wps=268.2, ups=0.26, wpb=1020.8, bsz=32, num_updates=12420, lr=8.09533e-06, gnorm=7.301, clip=100, loss_scale=64, train_wall=38, gb_free=9, wall=47960
2023-05-21 07:17:21 - progress_bar.py[line:272] - INFO: epoch 008:    329 / 1732 loss=2.5, loss_v1=0, loss_v2=0, nll_loss=1.313, ntokens=1025.4, nsentences=32, sample_size=1025.4, sample_size_v1=0, sample_size_v2=0, ppl=2.48, wps=269, ups=0.26, wpb=1025.4, bsz=32, num_updates=12430, lr=8.09328e-06, gnorm=7.08, clip=100, loss_scale=64, train_wall=38, gb_free=8.5, wall=47998
2023-05-21 07:17:59 - progress_bar.py[line:272] - INFO: epoch 008:    339 / 1732 loss=2.459, loss_v1=0, loss_v2=0, nll_loss=1.267, ntokens=950.6, nsentences=32, sample_size=950.6, sample_size_v1=0, sample_size_v2=0, ppl=2.41, wps=251.4, ups=0.26, wpb=950.6, bsz=32, num_updates=12440, lr=8.09123e-06, gnorm=6.834, clip=100, loss_scale=64, train_wall=38, gb_free=8.9, wall=48036
2023-05-21 07:18:37 - progress_bar.py[line:272] - INFO: epoch 008:    349 / 1732 loss=2.475, loss_v1=0, loss_v2=0, nll_loss=1.287, ntokens=919.8, nsentences=32, sample_size=919.8, sample_size_v1=0, sample_size_v2=0, ppl=2.44, wps=243.7, ups=0.26, wpb=919.8, bsz=32, num_updates=12450, lr=8.08918e-06, gnorm=7.431, clip=100, loss_scale=64, train_wall=38, gb_free=8.7, wall=48074
2023-05-21 07:19:15 - progress_bar.py[line:272] - INFO: epoch 008:    359 / 1732 loss=2.499, loss_v1=0, loss_v2=0, nll_loss=1.313, ntokens=933.3, nsentences=32, sample_size=933.3, sample_size_v1=0, sample_size_v2=0, ppl=2.48, wps=247.4, ups=0.27, wpb=933.3, bsz=32, num_updates=12460, lr=8.08714e-06, gnorm=7.127, clip=100, loss_scale=64, train_wall=38, gb_free=8.6, wall=48112
2023-05-21 07:19:52 - progress_bar.py[line:272] - INFO: epoch 008:    369 / 1732 loss=2.51, loss_v1=0, loss_v2=0, nll_loss=1.321, ntokens=971.1, nsentences=32, sample_size=971.1, sample_size_v1=0, sample_size_v2=0, ppl=2.5, wps=257.1, ups=0.26, wpb=971.1, bsz=32, num_updates=12470, lr=8.08509e-06, gnorm=7.324, clip=100, loss_scale=64, train_wall=38, gb_free=8.9, wall=48150
2023-05-21 07:20:31 - progress_bar.py[line:272] - INFO: epoch 008:    379 / 1732 loss=2.506, loss_v1=0, loss_v2=0, nll_loss=1.319, ntokens=1075.7, nsentences=32, sample_size=1075.7, sample_size_v1=0, sample_size_v2=0, ppl=2.5, wps=281.9, ups=0.26, wpb=1075.7, bsz=32, num_updates=12480, lr=8.08304e-06, gnorm=6.728, clip=100, loss_scale=64, train_wall=38, gb_free=8.2, wall=48188
2023-05-21 07:21:09 - progress_bar.py[line:272] - INFO: epoch 008:    389 / 1732 loss=2.475, loss_v1=0, loss_v2=0, nll_loss=1.285, ntokens=1027.5, nsentences=32, sample_size=1027.5, sample_size_v1=0, sample_size_v2=0, ppl=2.44, wps=270, ups=0.26, wpb=1027.5, bsz=32, num_updates=12490, lr=8.08099e-06, gnorm=7.004, clip=100, loss_scale=64, train_wall=38, gb_free=8.9, wall=48226
2023-05-21 07:21:47 - progress_bar.py[line:272] - INFO: epoch 008:    399 / 1732 loss=2.471, loss_v1=0, loss_v2=0, nll_loss=1.28, ntokens=981.4, nsentences=32, sample_size=981.4, sample_size_v1=0, sample_size_v2=0, ppl=2.43, wps=257.3, ups=0.26, wpb=981.4, bsz=32, num_updates=12500, lr=8.07895e-06, gnorm=7.865, clip=100, loss_scale=64, train_wall=38, gb_free=8.8, wall=48264
2023-05-21 07:22:25 - progress_bar.py[line:272] - INFO: epoch 008:    409 / 1732 loss=2.469, loss_v1=0, loss_v2=0, nll_loss=1.279, ntokens=1066.6, nsentences=32, sample_size=1066.6, sample_size_v1=0, sample_size_v2=0, ppl=2.43, wps=278.5, ups=0.26, wpb=1066.6, bsz=32, num_updates=12510, lr=8.0769e-06, gnorm=6.954, clip=100, loss_scale=64, train_wall=38, gb_free=8.7, wall=48302
2023-05-21 07:23:03 - progress_bar.py[line:272] - INFO: epoch 008:    419 / 1732 loss=2.449, loss_v1=0, loss_v2=0, nll_loss=1.255, ntokens=1023.6, nsentences=32, sample_size=1023.6, sample_size_v1=0, sample_size_v2=0, ppl=2.39, wps=269, ups=0.26, wpb=1023.6, bsz=32, num_updates=12520, lr=8.07485e-06, gnorm=7.481, clip=100, loss_scale=64, train_wall=38, gb_free=8.3, wall=48340
2023-05-21 07:23:41 - progress_bar.py[line:272] - INFO: epoch 008:    429 / 1732 loss=2.443, loss_v1=0, loss_v2=0, nll_loss=1.251, ntokens=1011.5, nsentences=32, sample_size=1011.5, sample_size_v1=0, sample_size_v2=0, ppl=2.38, wps=265.8, ups=0.26, wpb=1011.5, bsz=32, num_updates=12530, lr=8.0728e-06, gnorm=6.894, clip=100, loss_scale=64, train_wall=38, gb_free=8.8, wall=48378
2023-05-21 07:24:19 - progress_bar.py[line:272] - INFO: epoch 008:    439 / 1732 loss=2.483, loss_v1=0, loss_v2=0, nll_loss=1.294, ntokens=1024.1, nsentences=32, sample_size=1024.1, sample_size_v1=0, sample_size_v2=0, ppl=2.45, wps=269.6, ups=0.26, wpb=1024.1, bsz=32, num_updates=12540, lr=8.07076e-06, gnorm=6.343, clip=100, loss_scale=64, train_wall=38, gb_free=7.6, wall=48416
2023-05-21 07:24:57 - progress_bar.py[line:272] - INFO: epoch 008:    449 / 1732 loss=2.499, loss_v1=0, loss_v2=0, nll_loss=1.311, ntokens=917.8, nsentences=32, sample_size=917.8, sample_size_v1=0, sample_size_v2=0, ppl=2.48, wps=241.6, ups=0.26, wpb=917.8, bsz=32, num_updates=12550, lr=8.06871e-06, gnorm=8.263, clip=100, loss_scale=64, train_wall=38, gb_free=8.4, wall=48454
2023-05-21 07:25:35 - progress_bar.py[line:272] - INFO: epoch 008:    459 / 1732 loss=2.481, loss_v1=0, loss_v2=0, nll_loss=1.292, ntokens=1003.6, nsentences=32, sample_size=1003.6, sample_size_v1=0, sample_size_v2=0, ppl=2.45, wps=264, ups=0.26, wpb=1003.6, bsz=32, num_updates=12560, lr=8.06666e-06, gnorm=7.057, clip=100, loss_scale=64, train_wall=38, gb_free=8.8, wall=48492
2023-05-21 07:26:14 - progress_bar.py[line:272] - INFO: epoch 008:    469 / 1732 loss=2.482, loss_v1=0, loss_v2=0, nll_loss=1.293, ntokens=1054.5, nsentences=32, sample_size=1054.5, sample_size_v1=0, sample_size_v2=0, ppl=2.45, wps=274.1, ups=0.26, wpb=1054.5, bsz=32, num_updates=12570, lr=8.06462e-06, gnorm=7.18, clip=100, loss_scale=64, train_wall=38, gb_free=7.7, wall=48531
2023-05-21 07:26:52 - progress_bar.py[line:272] - INFO: epoch 008:    479 / 1732 loss=2.504, loss_v1=0, loss_v2=0, nll_loss=1.317, ntokens=1034.5, nsentences=32, sample_size=1034.5, sample_size_v1=0, sample_size_v2=0, ppl=2.49, wps=270.3, ups=0.26, wpb=1034.5, bsz=32, num_updates=12580, lr=8.06257e-06, gnorm=7.03, clip=100, loss_scale=64, train_wall=38, gb_free=8.8, wall=48569
2023-05-21 07:27:30 - progress_bar.py[line:272] - INFO: epoch 008:    489 / 1732 loss=2.463, loss_v1=0, loss_v2=0, nll_loss=1.272, ntokens=912, nsentences=32, sample_size=912, sample_size_v1=0, sample_size_v2=0, ppl=2.42, wps=240.9, ups=0.26, wpb=912, bsz=32, num_updates=12590, lr=8.06052e-06, gnorm=8.363, clip=100, loss_scale=64, train_wall=38, gb_free=8.9, wall=48607
2023-05-21 07:28:08 - progress_bar.py[line:272] - INFO: epoch 008:    499 / 1732 loss=2.469, loss_v1=0, loss_v2=0, nll_loss=1.279, ntokens=957.3, nsentences=32, sample_size=957.3, sample_size_v1=0, sample_size_v2=0, ppl=2.43, wps=253.1, ups=0.26, wpb=957.3, bsz=32, num_updates=12600, lr=8.05847e-06, gnorm=7.345, clip=100, loss_scale=64, train_wall=38, gb_free=8.5, wall=48645
2023-05-21 07:28:46 - progress_bar.py[line:272] - INFO: epoch 008:    509 / 1732 loss=2.486, loss_v1=0, loss_v2=0, nll_loss=1.297, ntokens=1025.1, nsentences=32, sample_size=1025.1, sample_size_v1=0, sample_size_v2=0, ppl=2.46, wps=270.3, ups=0.26, wpb=1025.1, bsz=32, num_updates=12610, lr=8.05643e-06, gnorm=7.151, clip=100, loss_scale=64, train_wall=38, gb_free=8.8, wall=48683
2023-05-21 07:29:24 - progress_bar.py[line:272] - INFO: epoch 008:    519 / 1732 loss=2.47, loss_v1=0, loss_v2=0, nll_loss=1.278, ntokens=1029.2, nsentences=32, sample_size=1029.2, sample_size_v1=0, sample_size_v2=0, ppl=2.43, wps=270.5, ups=0.26, wpb=1029.2, bsz=32, num_updates=12620, lr=8.05438e-06, gnorm=6.716, clip=100, loss_scale=64, train_wall=38, gb_free=9.1, wall=48721
2023-05-21 07:30:01 - progress_bar.py[line:272] - INFO: epoch 008:    529 / 1732 loss=2.485, loss_v1=0, loss_v2=0, nll_loss=1.297, ntokens=945, nsentences=32, sample_size=945, sample_size_v1=0, sample_size_v2=0, ppl=2.46, wps=249.7, ups=0.26, wpb=945, bsz=32, num_updates=12630, lr=8.05233e-06, gnorm=9.009, clip=100, loss_scale=64, train_wall=38, gb_free=8.8, wall=48759
2023-05-21 07:30:39 - progress_bar.py[line:272] - INFO: epoch 008:    539 / 1732 loss=2.47, loss_v1=0, loss_v2=0, nll_loss=1.28, ntokens=990.9, nsentences=32, sample_size=990.9, sample_size_v1=0, sample_size_v2=0, ppl=2.43, wps=262, ups=0.26, wpb=990.9, bsz=32, num_updates=12640, lr=8.05028e-06, gnorm=7.02, clip=100, loss_scale=64, train_wall=38, gb_free=8.6, wall=48796
2023-05-21 07:31:17 - progress_bar.py[line:272] - INFO: epoch 008:    549 / 1732 loss=2.503, loss_v1=0, loss_v2=0, nll_loss=1.316, ntokens=1038.3, nsentences=32, sample_size=1038.3, sample_size_v1=0, sample_size_v2=0, ppl=2.49, wps=272.4, ups=0.26, wpb=1038.3, bsz=32, num_updates=12650, lr=8.04824e-06, gnorm=6.788, clip=100, loss_scale=64, train_wall=38, gb_free=8.8, wall=48835
2023-05-21 07:31:56 - progress_bar.py[line:272] - INFO: epoch 008:    559 / 1732 loss=2.485, loss_v1=0, loss_v2=0, nll_loss=1.298, ntokens=1016.1, nsentences=32, sample_size=1016.1, sample_size_v1=0, sample_size_v2=0, ppl=2.46, wps=265.6, ups=0.26, wpb=1016.1, bsz=32, num_updates=12660, lr=8.04619e-06, gnorm=7.031, clip=100, loss_scale=64, train_wall=38, gb_free=8.2, wall=48873
2023-05-21 07:32:34 - progress_bar.py[line:272] - INFO: epoch 008:    569 / 1732 loss=2.529, loss_v1=0, loss_v2=0, nll_loss=1.346, ntokens=1004.9, nsentences=32, sample_size=1004.9, sample_size_v1=0, sample_size_v2=0, ppl=2.54, wps=262, ups=0.26, wpb=1004.9, bsz=32, num_updates=12670, lr=8.04414e-06, gnorm=8.229, clip=100, loss_scale=64, train_wall=38, gb_free=8.4, wall=48911
2023-05-21 07:33:12 - progress_bar.py[line:272] - INFO: epoch 008:    579 / 1732 loss=2.474, loss_v1=0, loss_v2=0, nll_loss=1.284, ntokens=1003.1, nsentences=32, sample_size=1003.1, sample_size_v1=0, sample_size_v2=0, ppl=2.43, wps=262, ups=0.26, wpb=1003.1, bsz=32, num_updates=12680, lr=8.04209e-06, gnorm=7.541, clip=100, loss_scale=64, train_wall=38, gb_free=8.2, wall=48949
2023-05-21 07:33:51 - progress_bar.py[line:272] - INFO: epoch 008:    589 / 1732 loss=2.486, loss_v1=0, loss_v2=0, nll_loss=1.298, ntokens=951.2, nsentences=32, sample_size=951.2, sample_size_v1=0, sample_size_v2=0, ppl=2.46, wps=248, ups=0.26, wpb=951.2, bsz=32, num_updates=12690, lr=8.04005e-06, gnorm=7.695, clip=100, loss_scale=64, train_wall=38, gb_free=7.8, wall=48988
2023-05-21 07:34:28 - progress_bar.py[line:272] - INFO: epoch 008:    599 / 1732 loss=2.453, loss_v1=0, loss_v2=0, nll_loss=1.261, ntokens=935, nsentences=32, sample_size=935, sample_size_v1=0, sample_size_v2=0, ppl=2.4, wps=247.2, ups=0.26, wpb=935, bsz=32, num_updates=12700, lr=8.038e-06, gnorm=8.027, clip=100, loss_scale=64, train_wall=38, gb_free=9.4, wall=49026
2023-05-21 07:35:06 - progress_bar.py[line:272] - INFO: epoch 008:    609 / 1732 loss=2.474, loss_v1=0, loss_v2=0, nll_loss=1.286, ntokens=917.6, nsentences=32, sample_size=917.6, sample_size_v1=0, sample_size_v2=0, ppl=2.44, wps=242.2, ups=0.26, wpb=917.6, bsz=32, num_updates=12710, lr=8.03595e-06, gnorm=7.88, clip=100, loss_scale=64, train_wall=38, gb_free=7.6, wall=49064
2023-05-21 07:35:44 - progress_bar.py[line:272] - INFO: epoch 008:    619 / 1732 loss=2.502, loss_v1=0, loss_v2=0, nll_loss=1.315, ntokens=845.1, nsentences=32, sample_size=845.1, sample_size_v1=0, sample_size_v2=0, ppl=2.49, wps=224.8, ups=0.27, wpb=845.1, bsz=32, num_updates=12720, lr=8.0339e-06, gnorm=9.322, clip=100, loss_scale=64, train_wall=38, gb_free=9, wall=49101
2023-05-21 07:36:22 - progress_bar.py[line:272] - INFO: epoch 008:    629 / 1732 loss=2.468, loss_v1=0, loss_v2=0, nll_loss=1.277, ntokens=934.9, nsentences=32, sample_size=934.9, sample_size_v1=0, sample_size_v2=0, ppl=2.42, wps=247.8, ups=0.27, wpb=934.9, bsz=32, num_updates=12730, lr=8.03186e-06, gnorm=8.455, clip=100, loss_scale=64, train_wall=38, gb_free=9.1, wall=49139
2023-05-21 07:37:00 - progress_bar.py[line:272] - INFO: epoch 008:    639 / 1732 loss=2.491, loss_v1=0, loss_v2=0, nll_loss=1.303, ntokens=925.6, nsentences=32, sample_size=925.6, sample_size_v1=0, sample_size_v2=0, ppl=2.47, wps=244.2, ups=0.26, wpb=925.6, bsz=32, num_updates=12740, lr=8.02981e-06, gnorm=8.78, clip=100, loss_scale=64, train_wall=38, gb_free=8.2, wall=49177
2023-05-21 07:37:37 - progress_bar.py[line:272] - INFO: epoch 008:    649 / 1732 loss=2.493, loss_v1=0, loss_v2=0, nll_loss=1.306, ntokens=987, nsentences=32, sample_size=987, sample_size_v1=0, sample_size_v2=0, ppl=2.47, wps=261.9, ups=0.27, wpb=987, bsz=32, num_updates=12750, lr=8.02776e-06, gnorm=8.033, clip=100, loss_scale=128, train_wall=38, gb_free=8.6, wall=49214
2023-05-21 07:38:03 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2023-05-21 07:38:18 - progress_bar.py[line:272] - INFO: epoch 008:    660 / 1732 loss=2.506, loss_v1=0, loss_v2=0, nll_loss=1.319, ntokens=872, nsentences=32, sample_size=872, sample_size_v1=0, sample_size_v2=0, ppl=2.5, wps=212.2, ups=0.24, wpb=872, bsz=32, num_updates=12760, lr=8.02572e-06, gnorm=9.211, clip=100, loss_scale=64, train_wall=41, gb_free=9.2, wall=49256
2023-05-21 07:38:56 - progress_bar.py[line:272] - INFO: epoch 008:    670 / 1732 loss=2.494, loss_v1=0, loss_v2=0, nll_loss=1.308, ntokens=914.5, nsentences=32, sample_size=914.5, sample_size_v1=0, sample_size_v2=0, ppl=2.48, wps=241.2, ups=0.26, wpb=914.5, bsz=32, num_updates=12770, lr=8.02367e-06, gnorm=8.726, clip=100, loss_scale=64, train_wall=38, gb_free=8.7, wall=49293
2023-05-21 07:39:34 - progress_bar.py[line:272] - INFO: epoch 008:    680 / 1732 loss=2.483, loss_v1=0, loss_v2=0, nll_loss=1.295, ntokens=998, nsentences=32, sample_size=998, sample_size_v1=0, sample_size_v2=0, ppl=2.45, wps=262.1, ups=0.26, wpb=998, bsz=32, num_updates=12780, lr=8.02162e-06, gnorm=7.305, clip=100, loss_scale=64, train_wall=38, gb_free=8.3, wall=49332
2023-05-21 07:40:13 - progress_bar.py[line:272] - INFO: epoch 008:    690 / 1732 loss=2.489, loss_v1=0, loss_v2=0, nll_loss=1.299, ntokens=956.7, nsentences=32, sample_size=956.7, sample_size_v1=0, sample_size_v2=0, ppl=2.46, wps=250.3, ups=0.26, wpb=956.7, bsz=32, num_updates=12790, lr=8.01957e-06, gnorm=8.174, clip=100, loss_scale=64, train_wall=38, gb_free=7.7, wall=49370
2023-05-21 07:40:51 - progress_bar.py[line:272] - INFO: epoch 008:    700 / 1732 loss=2.461, loss_v1=0, loss_v2=0, nll_loss=1.27, ntokens=979.4, nsentences=32, sample_size=979.4, sample_size_v1=0, sample_size_v2=0, ppl=2.41, wps=257.3, ups=0.26, wpb=979.4, bsz=32, num_updates=12800, lr=8.01753e-06, gnorm=7.672, clip=100, loss_scale=64, train_wall=38, gb_free=8.9, wall=49408
2023-05-21 07:41:29 - progress_bar.py[line:272] - INFO: epoch 008:    710 / 1732 loss=2.483, loss_v1=0, loss_v2=0, nll_loss=1.295, ntokens=915.1, nsentences=32, sample_size=915.1, sample_size_v1=0, sample_size_v2=0, ppl=2.45, wps=239.7, ups=0.26, wpb=915.1, bsz=32, num_updates=12810, lr=8.01548e-06, gnorm=8.743, clip=100, loss_scale=64, train_wall=38, gb_free=8.5, wall=49446
2023-05-21 07:42:07 - progress_bar.py[line:272] - INFO: epoch 008:    720 / 1732 loss=2.475, loss_v1=0, loss_v2=0, nll_loss=1.285, ntokens=848.7, nsentences=32, sample_size=848.7, sample_size_v1=0, sample_size_v2=0, ppl=2.44, wps=225, ups=0.27, wpb=848.7, bsz=32, num_updates=12820, lr=8.01343e-06, gnorm=8.773, clip=100, loss_scale=64, train_wall=38, gb_free=8.1, wall=49484
2023-05-21 07:42:44 - progress_bar.py[line:272] - INFO: epoch 008:    730 / 1732 loss=2.451, loss_v1=0, loss_v2=0, nll_loss=1.26, ntokens=943.7, nsentences=32, sample_size=943.7, sample_size_v1=0, sample_size_v2=0, ppl=2.4, wps=248.8, ups=0.26, wpb=943.7, bsz=32, num_updates=12830, lr=8.01138e-06, gnorm=7.208, clip=100, loss_scale=64, train_wall=38, gb_free=9.1, wall=49522
2023-05-21 07:43:22 - progress_bar.py[line:272] - INFO: epoch 008:    740 / 1732 loss=2.457, loss_v1=0, loss_v2=0, nll_loss=1.268, ntokens=1007.2, nsentences=32, sample_size=1007.2, sample_size_v1=0, sample_size_v2=0, ppl=2.41, wps=265.5, ups=0.26, wpb=1007.2, bsz=32, num_updates=12840, lr=8.00934e-06, gnorm=7.739, clip=100, loss_scale=64, train_wall=38, gb_free=8.5, wall=49560
2023-05-21 07:44:00 - progress_bar.py[line:272] - INFO: epoch 008:    750 / 1732 loss=2.464, loss_v1=0, loss_v2=0, nll_loss=1.273, ntokens=970.2, nsentences=32, sample_size=970.2, sample_size_v1=0, sample_size_v2=0, ppl=2.42, wps=254.9, ups=0.26, wpb=970.2, bsz=32, num_updates=12850, lr=8.00729e-06, gnorm=7.805, clip=100, loss_scale=64, train_wall=38, gb_free=8.8, wall=49598
2023-05-21 07:44:39 - progress_bar.py[line:272] - INFO: epoch 008:    760 / 1732 loss=2.461, loss_v1=0, loss_v2=0, nll_loss=1.268, ntokens=974, nsentences=32, sample_size=974, sample_size_v1=0, sample_size_v2=0, ppl=2.41, wps=255.1, ups=0.26, wpb=974, bsz=32, num_updates=12860, lr=8.00524e-06, gnorm=7.938, clip=100, loss_scale=64, train_wall=38, gb_free=8.5, wall=49636
2023-05-21 07:45:17 - progress_bar.py[line:272] - INFO: epoch 008:    770 / 1732 loss=2.468, loss_v1=0, loss_v2=0, nll_loss=1.279, ntokens=922.1, nsentences=32, sample_size=922.1, sample_size_v1=0, sample_size_v2=0, ppl=2.43, wps=243.4, ups=0.26, wpb=922.1, bsz=32, num_updates=12870, lr=8.00319e-06, gnorm=8.667, clip=100, loss_scale=64, train_wall=38, gb_free=9.1, wall=49674
2023-05-21 07:45:55 - progress_bar.py[line:272] - INFO: epoch 008:    780 / 1732 loss=2.472, loss_v1=0, loss_v2=0, nll_loss=1.283, ntokens=1056.6, nsentences=32, sample_size=1056.6, sample_size_v1=0, sample_size_v2=0, ppl=2.43, wps=277.5, ups=0.26, wpb=1056.6, bsz=32, num_updates=12880, lr=8.00115e-06, gnorm=7.519, clip=100, loss_scale=64, train_wall=38, gb_free=8.6, wall=49712
2023-05-21 07:46:33 - progress_bar.py[line:272] - INFO: epoch 008:    790 / 1732 loss=2.466, loss_v1=0, loss_v2=0, nll_loss=1.275, ntokens=1011.9, nsentences=32, sample_size=1011.9, sample_size_v1=0, sample_size_v2=0, ppl=2.42, wps=266, ups=0.26, wpb=1011.9, bsz=32, num_updates=12890, lr=7.9991e-06, gnorm=7.999, clip=100, loss_scale=64, train_wall=38, gb_free=8.1, wall=49750
2023-05-21 07:47:10 - progress_bar.py[line:272] - INFO: epoch 008:    800 / 1732 loss=2.474, loss_v1=0, loss_v2=0, nll_loss=1.282, ntokens=1000.1, nsentences=32, sample_size=1000.1, sample_size_v1=0, sample_size_v2=0, ppl=2.43, wps=264.7, ups=0.26, wpb=1000.1, bsz=32, num_updates=12900, lr=7.99705e-06, gnorm=7.71, clip=100, loss_scale=64, train_wall=38, gb_free=8.9, wall=49788
2023-05-21 07:47:48 - progress_bar.py[line:272] - INFO: epoch 008:    810 / 1732 loss=2.471, loss_v1=0, loss_v2=0, nll_loss=1.282, ntokens=918.3, nsentences=32, sample_size=918.3, sample_size_v1=0, sample_size_v2=0, ppl=2.43, wps=243.2, ups=0.26, wpb=918.3, bsz=32, num_updates=12910, lr=7.995e-06, gnorm=8.636, clip=100, loss_scale=64, train_wall=38, gb_free=8.6, wall=49825
2023-05-21 07:48:26 - progress_bar.py[line:272] - INFO: epoch 008:    820 / 1732 loss=2.48, loss_v1=0, loss_v2=0, nll_loss=1.29, ntokens=912.3, nsentences=32, sample_size=912.3, sample_size_v1=0, sample_size_v2=0, ppl=2.45, wps=241.1, ups=0.26, wpb=912.3, bsz=32, num_updates=12920, lr=7.99296e-06, gnorm=8.743, clip=100, loss_scale=64, train_wall=38, gb_free=8.6, wall=49863
2023-05-21 07:49:04 - progress_bar.py[line:272] - INFO: epoch 008:    830 / 1732 loss=2.458, loss_v1=0, loss_v2=0, nll_loss=1.266, ntokens=919.5, nsentences=32, sample_size=919.5, sample_size_v1=0, sample_size_v2=0, ppl=2.41, wps=242.7, ups=0.26, wpb=919.5, bsz=32, num_updates=12930, lr=7.99091e-06, gnorm=8.254, clip=100, loss_scale=64, train_wall=38, gb_free=8.9, wall=49901
2023-05-21 07:49:42 - progress_bar.py[line:272] - INFO: epoch 008:    840 / 1732 loss=2.473, loss_v1=0, loss_v2=0, nll_loss=1.282, ntokens=917.9, nsentences=32, sample_size=917.9, sample_size_v1=0, sample_size_v2=0, ppl=2.43, wps=242.7, ups=0.26, wpb=917.9, bsz=32, num_updates=12940, lr=7.98886e-06, gnorm=8.525, clip=100, loss_scale=64, train_wall=38, gb_free=8.4, wall=49939
2023-05-21 07:50:20 - progress_bar.py[line:272] - INFO: epoch 008:    850 / 1732 loss=2.473, loss_v1=0, loss_v2=0, nll_loss=1.282, ntokens=1015.3, nsentences=32, sample_size=1015.3, sample_size_v1=0, sample_size_v2=0, ppl=2.43, wps=265.4, ups=0.26, wpb=1015.3, bsz=32, num_updates=12950, lr=7.98681e-06, gnorm=7.353, clip=100, loss_scale=64, train_wall=38, gb_free=8.9, wall=49977
2023-05-21 07:50:58 - progress_bar.py[line:272] - INFO: epoch 008:    860 / 1732 loss=2.45, loss_v1=0, loss_v2=0, nll_loss=1.259, ntokens=930.1, nsentences=32, sample_size=930.1, sample_size_v1=0, sample_size_v2=0, ppl=2.39, wps=246.4, ups=0.26, wpb=930.1, bsz=32, num_updates=12960, lr=7.98477e-06, gnorm=7.576, clip=100, loss_scale=64, train_wall=38, gb_free=9, wall=50015
2023-05-21 07:51:36 - progress_bar.py[line:272] - INFO: epoch 008:    870 / 1732 loss=2.465, loss_v1=0, loss_v2=0, nll_loss=1.275, ntokens=970.4, nsentences=32, sample_size=970.4, sample_size_v1=0, sample_size_v2=0, ppl=2.42, wps=256, ups=0.26, wpb=970.4, bsz=32, num_updates=12970, lr=7.98272e-06, gnorm=7.23, clip=100, loss_scale=64, train_wall=38, gb_free=8.8, wall=50053
2023-05-21 07:52:14 - progress_bar.py[line:272] - INFO: epoch 008:    880 / 1732 loss=2.413, loss_v1=0, loss_v2=0, nll_loss=1.217, ntokens=1004.9, nsentences=32, sample_size=1004.9, sample_size_v1=0, sample_size_v2=0, ppl=2.32, wps=263.2, ups=0.26, wpb=1004.9, bsz=32, num_updates=12980, lr=7.98067e-06, gnorm=7.482, clip=100, loss_scale=64, train_wall=38, gb_free=8.4, wall=50091
2023-05-21 07:52:52 - progress_bar.py[line:272] - INFO: epoch 008:    890 / 1732 loss=2.417, loss_v1=0, loss_v2=0, nll_loss=1.22, ntokens=986.6, nsentences=32, sample_size=986.6, sample_size_v1=0, sample_size_v2=0, ppl=2.33, wps=259.7, ups=0.26, wpb=986.6, bsz=32, num_updates=12990, lr=7.97863e-06, gnorm=7.55, clip=100, loss_scale=64, train_wall=38, gb_free=8.4, wall=50129
2023-05-21 07:53:30 - progress_bar.py[line:272] - INFO: epoch 008:    900 / 1732 loss=2.406, loss_v1=0, loss_v2=0, nll_loss=1.208, ntokens=1043.1, nsentences=32, sample_size=1043.1, sample_size_v1=0, sample_size_v2=0, ppl=2.31, wps=273.9, ups=0.26, wpb=1043.1, bsz=32, num_updates=13000, lr=7.97658e-06, gnorm=7.752, clip=100, loss_scale=64, train_wall=38, gb_free=9, wall=50167
2023-05-21 07:54:08 - progress_bar.py[line:272] - INFO: epoch 008:    910 / 1732 loss=2.453, loss_v1=0, loss_v2=0, nll_loss=1.262, ntokens=976.1, nsentences=32, sample_size=976.1, sample_size_v1=0, sample_size_v2=0, ppl=2.4, wps=257.5, ups=0.26, wpb=976.1, bsz=32, num_updates=13010, lr=7.97453e-06, gnorm=7.54, clip=100, loss_scale=64, train_wall=38, gb_free=8.6, wall=50205
2023-05-21 07:54:46 - progress_bar.py[line:272] - INFO: epoch 008:    920 / 1732 loss=2.483, loss_v1=0, loss_v2=0, nll_loss=1.295, ntokens=983.5, nsentences=32, sample_size=983.5, sample_size_v1=0, sample_size_v2=0, ppl=2.45, wps=257.2, ups=0.26, wpb=983.5, bsz=32, num_updates=13020, lr=7.97248e-06, gnorm=8.254, clip=100, loss_scale=64, train_wall=38, gb_free=8.9, wall=50243
2023-05-21 07:55:25 - progress_bar.py[line:272] - INFO: epoch 008:    930 / 1732 loss=2.443, loss_v1=0, loss_v2=0, nll_loss=1.249, ntokens=1038.6, nsentences=32, sample_size=1038.6, sample_size_v1=0, sample_size_v2=0, ppl=2.38, wps=268.9, ups=0.26, wpb=1038.6, bsz=32, num_updates=13030, lr=7.97044e-06, gnorm=7.645, clip=100, loss_scale=64, train_wall=39, gb_free=8.8, wall=50282
2023-05-21 07:56:03 - progress_bar.py[line:272] - INFO: epoch 008:    940 / 1732 loss=2.431, loss_v1=0, loss_v2=0, nll_loss=1.238, ntokens=1043.2, nsentences=32, sample_size=1043.2, sample_size_v1=0, sample_size_v2=0, ppl=2.36, wps=269.6, ups=0.26, wpb=1043.2, bsz=32, num_updates=13040, lr=7.96839e-06, gnorm=6.757, clip=100, loss_scale=64, train_wall=39, gb_free=8.1, wall=50321
2023-05-21 07:56:42 - progress_bar.py[line:272] - INFO: epoch 008:    950 / 1732 loss=2.452, loss_v1=0, loss_v2=0, nll_loss=1.259, ntokens=1038.6, nsentences=32, sample_size=1038.6, sample_size_v1=0, sample_size_v2=0, ppl=2.39, wps=269.8, ups=0.26, wpb=1038.6, bsz=32, num_updates=13050, lr=7.96634e-06, gnorm=7.193, clip=100, loss_scale=64, train_wall=38, gb_free=8.8, wall=50359
2023-05-21 07:57:21 - progress_bar.py[line:272] - INFO: epoch 008:    960 / 1732 loss=2.448, loss_v1=0, loss_v2=0, nll_loss=1.256, ntokens=1044.3, nsentences=32, sample_size=1044.3, sample_size_v1=0, sample_size_v2=0, ppl=2.39, wps=270.7, ups=0.26, wpb=1044.3, bsz=32, num_updates=13060, lr=7.96429e-06, gnorm=7.213, clip=100, loss_scale=64, train_wall=39, gb_free=8.5, wall=50398
2023-05-21 07:57:59 - progress_bar.py[line:272] - INFO: epoch 008:    970 / 1732 loss=2.472, loss_v1=0, loss_v2=0, nll_loss=1.284, ntokens=1054.8, nsentences=32, sample_size=1054.8, sample_size_v1=0, sample_size_v2=0, ppl=2.44, wps=274.7, ups=0.26, wpb=1054.8, bsz=32, num_updates=13070, lr=7.96225e-06, gnorm=7.483, clip=100, loss_scale=64, train_wall=38, gb_free=8.7, wall=50436
2023-05-21 07:58:38 - progress_bar.py[line:272] - INFO: epoch 008:    980 / 1732 loss=2.451, loss_v1=0, loss_v2=0, nll_loss=1.26, ntokens=1012, nsentences=32, sample_size=1012, sample_size_v1=0, sample_size_v2=0, ppl=2.4, wps=261.3, ups=0.26, wpb=1012, bsz=32, num_updates=13080, lr=7.9602e-06, gnorm=7.283, clip=100, loss_scale=64, train_wall=39, gb_free=8.6, wall=50475
2023-05-21 07:59:16 - progress_bar.py[line:272] - INFO: epoch 008:    990 / 1732 loss=2.447, loss_v1=0, loss_v2=0, nll_loss=1.254, ntokens=1049.1, nsentences=32, sample_size=1049.1, sample_size_v1=0, sample_size_v2=0, ppl=2.38, wps=271.7, ups=0.26, wpb=1049.1, bsz=32, num_updates=13090, lr=7.95815e-06, gnorm=7.825, clip=100, loss_scale=64, train_wall=39, gb_free=9.1, wall=50513
2023-05-21 07:59:55 - progress_bar.py[line:272] - INFO: epoch 008:   1000 / 1732 loss=2.434, loss_v1=0, loss_v2=0, nll_loss=1.238, ntokens=1015.5, nsentences=32, sample_size=1015.5, sample_size_v1=0, sample_size_v2=0, ppl=2.36, wps=264.3, ups=0.26, wpb=1015.5, bsz=32, num_updates=13100, lr=7.9561e-06, gnorm=7.339, clip=100, loss_scale=64, train_wall=38, gb_free=9, wall=50552
2023-05-21 08:00:33 - progress_bar.py[line:272] - INFO: epoch 008:   1010 / 1732 loss=2.448, loss_v1=0, loss_v2=0, nll_loss=1.254, ntokens=1013.4, nsentences=32, sample_size=1013.4, sample_size_v1=0, sample_size_v2=0, ppl=2.38, wps=263.4, ups=0.26, wpb=1013.4, bsz=32, num_updates=13110, lr=7.95406e-06, gnorm=7.363, clip=100, loss_scale=64, train_wall=38, gb_free=8.8, wall=50590
2023-05-21 08:01:12 - progress_bar.py[line:272] - INFO: epoch 008:   1020 / 1732 loss=2.418, loss_v1=0, loss_v2=0, nll_loss=1.224, ntokens=1035.8, nsentences=32, sample_size=1035.8, sample_size_v1=0, sample_size_v2=0, ppl=2.34, wps=268.8, ups=0.26, wpb=1035.8, bsz=32, num_updates=13120, lr=7.95201e-06, gnorm=7.185, clip=100, loss_scale=64, train_wall=38, gb_free=8.4, wall=50629
2023-05-21 08:01:51 - progress_bar.py[line:272] - INFO: epoch 008:   1030 / 1732 loss=2.455, loss_v1=0, loss_v2=0, nll_loss=1.264, ntokens=1101.6, nsentences=32, sample_size=1101.6, sample_size_v1=0, sample_size_v2=0, ppl=2.4, wps=282.5, ups=0.26, wpb=1101.6, bsz=32, num_updates=13130, lr=7.94996e-06, gnorm=7.845, clip=100, loss_scale=64, train_wall=39, gb_free=8.3, wall=50668
2023-05-21 08:02:29 - progress_bar.py[line:272] - INFO: epoch 008:   1040 / 1732 loss=2.447, loss_v1=0, loss_v2=0, nll_loss=1.254, ntokens=1070.8, nsentences=32, sample_size=1070.8, sample_size_v1=0, sample_size_v2=0, ppl=2.38, wps=277, ups=0.26, wpb=1070.8, bsz=32, num_updates=13140, lr=7.94791e-06, gnorm=6.973, clip=100, loss_scale=64, train_wall=39, gb_free=8, wall=50707
2023-05-21 08:03:08 - progress_bar.py[line:272] - INFO: epoch 008:   1050 / 1732 loss=2.446, loss_v1=0, loss_v2=0, nll_loss=1.248, ntokens=1039.3, nsentences=32, sample_size=1039.3, sample_size_v1=0, sample_size_v2=0, ppl=2.38, wps=270.3, ups=0.26, wpb=1039.3, bsz=32, num_updates=13150, lr=7.94587e-06, gnorm=8.251, clip=100, loss_scale=64, train_wall=38, gb_free=8.6, wall=50745
2023-05-21 08:03:46 - progress_bar.py[line:272] - INFO: epoch 008:   1060 / 1732 loss=2.438, loss_v1=0, loss_v2=0, nll_loss=1.244, ntokens=1066.3, nsentences=32, sample_size=1066.3, sample_size_v1=0, sample_size_v2=0, ppl=2.37, wps=277.6, ups=0.26, wpb=1066.3, bsz=32, num_updates=13160, lr=7.94382e-06, gnorm=7.902, clip=100, loss_scale=64, train_wall=38, gb_free=7.9, wall=50783
2023-05-21 08:04:25 - progress_bar.py[line:272] - INFO: epoch 008:   1070 / 1732 loss=2.449, loss_v1=0, loss_v2=0, nll_loss=1.255, ntokens=985.6, nsentences=32, sample_size=985.6, sample_size_v1=0, sample_size_v2=0, ppl=2.39, wps=256.8, ups=0.26, wpb=985.6, bsz=32, num_updates=13170, lr=7.94177e-06, gnorm=7.616, clip=100, loss_scale=64, train_wall=38, gb_free=8, wall=50822
2023-05-21 08:05:03 - progress_bar.py[line:272] - INFO: epoch 008:   1080 / 1732 loss=2.457, loss_v1=0, loss_v2=0, nll_loss=1.266, ntokens=1039.6, nsentences=32, sample_size=1039.6, sample_size_v1=0, sample_size_v2=0, ppl=2.4, wps=269.4, ups=0.26, wpb=1039.6, bsz=32, num_updates=13180, lr=7.93973e-06, gnorm=7.817, clip=100, loss_scale=64, train_wall=39, gb_free=8.3, wall=50860
2023-05-21 08:05:42 - progress_bar.py[line:272] - INFO: epoch 008:   1090 / 1732 loss=2.445, loss_v1=0, loss_v2=0, nll_loss=1.252, ntokens=1074, nsentences=32, sample_size=1074, sample_size_v1=0, sample_size_v2=0, ppl=2.38, wps=277.4, ups=0.26, wpb=1074, bsz=32, num_updates=13190, lr=7.93768e-06, gnorm=8.531, clip=100, loss_scale=64, train_wall=39, gb_free=8.3, wall=50899
2023-05-21 08:06:20 - progress_bar.py[line:272] - INFO: epoch 008:   1100 / 1732 loss=2.455, loss_v1=0, loss_v2=0, nll_loss=1.261, ntokens=1032, nsentences=32, sample_size=1032, sample_size_v1=0, sample_size_v2=0, ppl=2.4, wps=268.7, ups=0.26, wpb=1032, bsz=32, num_updates=13200, lr=7.93563e-06, gnorm=8.029, clip=100, loss_scale=64, train_wall=38, gb_free=8.8, wall=50938
2023-05-21 08:06:59 - progress_bar.py[line:272] - INFO: epoch 008:   1110 / 1732 loss=2.445, loss_v1=0, loss_v2=0, nll_loss=1.252, ntokens=1053.3, nsentences=32, sample_size=1053.3, sample_size_v1=0, sample_size_v2=0, ppl=2.38, wps=272.2, ups=0.26, wpb=1053.3, bsz=32, num_updates=13210, lr=7.93358e-06, gnorm=7.44, clip=100, loss_scale=64, train_wall=39, gb_free=8.6, wall=50976
2023-05-21 08:07:38 - progress_bar.py[line:272] - INFO: epoch 008:   1120 / 1732 loss=2.458, loss_v1=0, loss_v2=0, nll_loss=1.268, ntokens=958.1, nsentences=32, sample_size=958.1, sample_size_v1=0, sample_size_v2=0, ppl=2.41, wps=248.4, ups=0.26, wpb=958.1, bsz=32, num_updates=13220, lr=7.93154e-06, gnorm=8.145, clip=100, loss_scale=64, train_wall=39, gb_free=8.8, wall=51015
2023-05-21 08:08:16 - progress_bar.py[line:272] - INFO: epoch 008:   1130 / 1732 loss=2.445, loss_v1=0, loss_v2=0, nll_loss=1.253, ntokens=1008.8, nsentences=32, sample_size=1008.8, sample_size_v1=0, sample_size_v2=0, ppl=2.38, wps=261.9, ups=0.26, wpb=1008.8, bsz=32, num_updates=13230, lr=7.92949e-06, gnorm=8.152, clip=100, loss_scale=64, train_wall=38, gb_free=8.8, wall=51053
2023-05-21 08:08:55 - progress_bar.py[line:272] - INFO: epoch 008:   1140 / 1732 loss=2.463, loss_v1=0, loss_v2=0, nll_loss=1.27, ntokens=1003.3, nsentences=32, sample_size=1003.3, sample_size_v1=0, sample_size_v2=0, ppl=2.41, wps=259.3, ups=0.26, wpb=1003.3, bsz=32, num_updates=13240, lr=7.92744e-06, gnorm=7.812, clip=100, loss_scale=64, train_wall=39, gb_free=8.9, wall=51092
2023-05-21 08:09:33 - progress_bar.py[line:272] - INFO: epoch 008:   1150 / 1732 loss=2.451, loss_v1=0, loss_v2=0, nll_loss=1.258, ntokens=1020.4, nsentences=32, sample_size=1020.4, sample_size_v1=0, sample_size_v2=0, ppl=2.39, wps=264.4, ups=0.26, wpb=1020.4, bsz=32, num_updates=13250, lr=7.92539e-06, gnorm=7.83, clip=100, loss_scale=64, train_wall=39, gb_free=8.4, wall=51131
2023-05-21 08:10:12 - progress_bar.py[line:272] - INFO: epoch 008:   1160 / 1732 loss=2.428, loss_v1=0, loss_v2=0, nll_loss=1.232, ntokens=995, nsentences=32, sample_size=995, sample_size_v1=0, sample_size_v2=0, ppl=2.35, wps=258.8, ups=0.26, wpb=995, bsz=32, num_updates=13260, lr=7.92335e-06, gnorm=8.869, clip=100, loss_scale=64, train_wall=38, gb_free=8.6, wall=51169
2023-05-21 08:10:50 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2023-05-21 08:10:54 - progress_bar.py[line:272] - INFO: epoch 008:   1171 / 1732 loss=2.428, loss_v1=0, loss_v2=0, nll_loss=1.233, ntokens=1036.6, nsentences=32, sample_size=1036.6, sample_size_v1=0, sample_size_v2=0, ppl=2.35, wps=244.1, ups=0.24, wpb=1036.6, bsz=32, num_updates=13270, lr=7.9213e-06, gnorm=8.335, clip=100, loss_scale=64, train_wall=42, gb_free=8.1, wall=51212
2023-05-21 08:11:33 - progress_bar.py[line:272] - INFO: epoch 008:   1181 / 1732 loss=2.417, loss_v1=0, loss_v2=0, nll_loss=1.221, ntokens=1019.2, nsentences=32, sample_size=1019.2, sample_size_v1=0, sample_size_v2=0, ppl=2.33, wps=264.4, ups=0.26, wpb=1019.2, bsz=32, num_updates=13280, lr=7.91925e-06, gnorm=7.112, clip=100, loss_scale=64, train_wall=38, gb_free=7.4, wall=51250
2023-05-21 08:12:11 - progress_bar.py[line:272] - INFO: epoch 008:   1191 / 1732 loss=2.48, loss_v1=0, loss_v2=0, nll_loss=1.291, ntokens=1005.4, nsentences=32, sample_size=1005.4, sample_size_v1=0, sample_size_v2=0, ppl=2.45, wps=260.5, ups=0.26, wpb=1005.4, bsz=32, num_updates=13290, lr=7.9172e-06, gnorm=8.117, clip=100, loss_scale=64, train_wall=39, gb_free=8.8, wall=51289
2023-05-21 08:12:50 - progress_bar.py[line:272] - INFO: epoch 008:   1201 / 1732 loss=2.411, loss_v1=0, loss_v2=0, nll_loss=1.211, ntokens=1106.6, nsentences=32, sample_size=1106.6, sample_size_v1=0, sample_size_v2=0, ppl=2.31, wps=285.4, ups=0.26, wpb=1106.6, bsz=32, num_updates=13300, lr=7.91516e-06, gnorm=7.1, clip=100, loss_scale=64, train_wall=39, gb_free=8.4, wall=51327
2023-05-21 08:13:29 - progress_bar.py[line:272] - INFO: epoch 008:   1211 / 1732 loss=2.432, loss_v1=0, loss_v2=0, nll_loss=1.236, ntokens=1064.4, nsentences=32, sample_size=1064.4, sample_size_v1=0, sample_size_v2=0, ppl=2.36, wps=274.3, ups=0.26, wpb=1064.4, bsz=32, num_updates=13310, lr=7.91311e-06, gnorm=7.255, clip=100, loss_scale=64, train_wall=39, gb_free=8.6, wall=51366
2023-05-21 08:14:07 - progress_bar.py[line:272] - INFO: epoch 008:   1221 / 1732 loss=2.47, loss_v1=0, loss_v2=0, nll_loss=1.281, ntokens=1029, nsentences=32, sample_size=1029, sample_size_v1=0, sample_size_v2=0, ppl=2.43, wps=268.1, ups=0.26, wpb=1029, bsz=32, num_updates=13320, lr=7.91106e-06, gnorm=8, clip=100, loss_scale=64, train_wall=38, gb_free=8.9, wall=51405
2023-05-21 08:14:46 - progress_bar.py[line:272] - INFO: epoch 008:   1231 / 1732 loss=2.431, loss_v1=0, loss_v2=0, nll_loss=1.237, ntokens=1027, nsentences=32, sample_size=1027, sample_size_v1=0, sample_size_v2=0, ppl=2.36, wps=267.2, ups=0.26, wpb=1027, bsz=32, num_updates=13330, lr=7.90901e-06, gnorm=7.889, clip=100, loss_scale=64, train_wall=38, gb_free=8.6, wall=51443
2023-05-21 08:15:25 - progress_bar.py[line:272] - INFO: epoch 008:   1241 / 1732 loss=2.389, loss_v1=0, loss_v2=0, nll_loss=1.188, ntokens=1099, nsentences=32, sample_size=1099, sample_size_v1=0, sample_size_v2=0, ppl=2.28, wps=284, ups=0.26, wpb=1099, bsz=32, num_updates=13340, lr=7.90697e-06, gnorm=8.008, clip=100, loss_scale=64, train_wall=39, gb_free=8.5, wall=51482
2023-05-21 08:16:03 - progress_bar.py[line:272] - INFO: epoch 008:   1251 / 1732 loss=2.419, loss_v1=0, loss_v2=0, nll_loss=1.223, ntokens=1063.8, nsentences=32, sample_size=1063.8, sample_size_v1=0, sample_size_v2=0, ppl=2.33, wps=275.2, ups=0.26, wpb=1063.8, bsz=32, num_updates=13350, lr=7.90492e-06, gnorm=7.479, clip=100, loss_scale=64, train_wall=39, gb_free=8.4, wall=51520
2023-05-21 08:16:42 - progress_bar.py[line:272] - INFO: epoch 008:   1261 / 1732 loss=2.421, loss_v1=0, loss_v2=0, nll_loss=1.225, ntokens=1068.4, nsentences=32, sample_size=1068.4, sample_size_v1=0, sample_size_v2=0, ppl=2.34, wps=276.2, ups=0.26, wpb=1068.4, bsz=32, num_updates=13360, lr=7.90287e-06, gnorm=7.53, clip=100, loss_scale=64, train_wall=39, gb_free=8.2, wall=51559
2023-05-21 08:17:20 - progress_bar.py[line:272] - INFO: epoch 008:   1271 / 1732 loss=2.45, loss_v1=0, loss_v2=0, nll_loss=1.258, ntokens=1028.5, nsentences=32, sample_size=1028.5, sample_size_v1=0, sample_size_v2=0, ppl=2.39, wps=267.5, ups=0.26, wpb=1028.5, bsz=32, num_updates=13370, lr=7.90083e-06, gnorm=8.535, clip=100, loss_scale=64, train_wall=38, gb_free=9, wall=51598
2023-05-21 08:17:59 - progress_bar.py[line:272] - INFO: epoch 008:   1281 / 1732 loss=2.425, loss_v1=0, loss_v2=0, nll_loss=1.228, ntokens=1068.6, nsentences=32, sample_size=1068.6, sample_size_v1=0, sample_size_v2=0, ppl=2.34, wps=275.6, ups=0.26, wpb=1068.6, bsz=32, num_updates=13380, lr=7.89878e-06, gnorm=8.386, clip=100, loss_scale=64, train_wall=39, gb_free=8.4, wall=51636
2023-05-21 08:18:38 - progress_bar.py[line:272] - INFO: epoch 008:   1291 / 1732 loss=2.439, loss_v1=0, loss_v2=0, nll_loss=1.243, ntokens=1084.2, nsentences=32, sample_size=1084.2, sample_size_v1=0, sample_size_v2=0, ppl=2.37, wps=277.7, ups=0.26, wpb=1084.2, bsz=32, num_updates=13390, lr=7.89673e-06, gnorm=7.443, clip=100, loss_scale=64, train_wall=39, gb_free=8.7, wall=51675
2023-05-21 08:19:17 - progress_bar.py[line:272] - INFO: epoch 008:   1301 / 1732 loss=2.427, loss_v1=0, loss_v2=0, nll_loss=1.232, ntokens=1090.9, nsentences=32, sample_size=1090.9, sample_size_v1=0, sample_size_v2=0, ppl=2.35, wps=283.1, ups=0.26, wpb=1090.9, bsz=32, num_updates=13400, lr=7.89468e-06, gnorm=7.378, clip=100, loss_scale=64, train_wall=38, gb_free=8.6, wall=51714
2023-05-21 08:19:56 - progress_bar.py[line:272] - INFO: epoch 008:   1311 / 1732 loss=2.461, loss_v1=0, loss_v2=0, nll_loss=1.268, ntokens=1079.3, nsentences=32, sample_size=1079.3, sample_size_v1=0, sample_size_v2=0, ppl=2.41, wps=275.2, ups=0.25, wpb=1079.3, bsz=32, num_updates=13410, lr=7.89264e-06, gnorm=7.039, clip=100, loss_scale=64, train_wall=39, gb_free=7.9, wall=51753
2023-05-21 08:20:35 - progress_bar.py[line:272] - INFO: epoch 008:   1321 / 1732 loss=2.431, loss_v1=0, loss_v2=0, nll_loss=1.235, ntokens=1098.3, nsentences=32, sample_size=1098.3, sample_size_v1=0, sample_size_v2=0, ppl=2.35, wps=282.1, ups=0.26, wpb=1098.3, bsz=32, num_updates=13420, lr=7.89059e-06, gnorm=8.083, clip=100, loss_scale=64, train_wall=39, gb_free=6, wall=51792
2023-05-21 08:21:14 - progress_bar.py[line:272] - INFO: epoch 008:   1331 / 1732 loss=2.402, loss_v1=0, loss_v2=0, nll_loss=1.204, ntokens=1102.8, nsentences=32, sample_size=1102.8, sample_size_v1=0, sample_size_v2=0, ppl=2.3, wps=283.2, ups=0.26, wpb=1102.8, bsz=32, num_updates=13430, lr=7.88854e-06, gnorm=8.187, clip=100, loss_scale=64, train_wall=39, gb_free=8.5, wall=51831
2023-05-21 08:21:53 - progress_bar.py[line:272] - INFO: epoch 008:   1341 / 1732 loss=2.417, loss_v1=0, loss_v2=0, nll_loss=1.222, ntokens=1167.8, nsentences=32, sample_size=1167.8, sample_size_v1=0, sample_size_v2=0, ppl=2.33, wps=300, ups=0.26, wpb=1167.8, bsz=32, num_updates=13440, lr=7.88649e-06, gnorm=8.222, clip=100, loss_scale=64, train_wall=39, gb_free=8, wall=51870
2023-05-21 08:22:32 - progress_bar.py[line:272] - INFO: epoch 008:   1351 / 1732 loss=2.437, loss_v1=0, loss_v2=0, nll_loss=1.245, ntokens=1137.2, nsentences=32, sample_size=1137.2, sample_size_v1=0, sample_size_v2=0, ppl=2.37, wps=293.3, ups=0.26, wpb=1137.2, bsz=32, num_updates=13450, lr=7.88445e-06, gnorm=8.248, clip=100, loss_scale=64, train_wall=39, gb_free=8.1, wall=51909
2023-05-21 08:23:10 - progress_bar.py[line:272] - INFO: epoch 008:   1361 / 1732 loss=2.395, loss_v1=0, loss_v2=0, nll_loss=1.194, ntokens=1107.4, nsentences=32, sample_size=1107.4, sample_size_v1=0, sample_size_v2=0, ppl=2.29, wps=284.2, ups=0.26, wpb=1107.4, bsz=32, num_updates=13460, lr=7.8824e-06, gnorm=7.189, clip=100, loss_scale=64, train_wall=39, gb_free=8.6, wall=51948
2023-05-21 08:23:49 - progress_bar.py[line:272] - INFO: epoch 008:   1371 / 1732 loss=2.444, loss_v1=0, loss_v2=0, nll_loss=1.251, ntokens=1105.1, nsentences=32, sample_size=1105.1, sample_size_v1=0, sample_size_v2=0, ppl=2.38, wps=285.4, ups=0.26, wpb=1105.1, bsz=32, num_updates=13470, lr=7.88035e-06, gnorm=7.492, clip=100, loss_scale=64, train_wall=39, gb_free=8.7, wall=51986
2023-05-21 08:24:28 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2023-05-21 08:24:32 - progress_bar.py[line:272] - INFO: epoch 008:   1382 / 1732 loss=2.459, loss_v1=0, loss_v2=0, nll_loss=1.266, ntokens=1126.2, nsentences=32, sample_size=1126.2, sample_size_v1=0, sample_size_v2=0, ppl=2.4, wps=266.1, ups=0.24, wpb=1126.2, bsz=32, num_updates=13480, lr=7.8783e-06, gnorm=8.333, clip=100, loss_scale=32, train_wall=42, gb_free=8, wall=52029
2023-05-21 08:25:10 - progress_bar.py[line:272] - INFO: epoch 008:   1392 / 1732 loss=2.432, loss_v1=0, loss_v2=0, nll_loss=1.237, ntokens=1049.4, nsentences=32, sample_size=1049.4, sample_size_v1=0, sample_size_v2=0, ppl=2.36, wps=273.5, ups=0.26, wpb=1049.4, bsz=32, num_updates=13490, lr=7.87626e-06, gnorm=8.492, clip=100, loss_scale=32, train_wall=38, gb_free=8.3, wall=52067
2023-05-21 08:25:49 - progress_bar.py[line:272] - INFO: epoch 008:   1402 / 1732 loss=2.411, loss_v1=0, loss_v2=0, nll_loss=1.214, ntokens=1133.7, nsentences=32, sample_size=1133.7, sample_size_v1=0, sample_size_v2=0, ppl=2.32, wps=291.6, ups=0.26, wpb=1133.7, bsz=32, num_updates=13500, lr=7.87421e-06, gnorm=7.699, clip=100, loss_scale=32, train_wall=39, gb_free=7.2, wall=52106
2023-05-21 08:26:28 - progress_bar.py[line:272] - INFO: epoch 008:   1412 / 1732 loss=2.444, loss_v1=0, loss_v2=0, nll_loss=1.251, ntokens=1246.7, nsentences=32, sample_size=1246.7, sample_size_v1=0, sample_size_v2=0, ppl=2.38, wps=318.7, ups=0.26, wpb=1246.7, bsz=32, num_updates=13510, lr=7.87216e-06, gnorm=6.491, clip=100, loss_scale=32, train_wall=39, gb_free=7.9, wall=52145
2023-05-21 08:27:07 - progress_bar.py[line:272] - INFO: epoch 008:   1422 / 1732 loss=2.434, loss_v1=0, loss_v2=0, nll_loss=1.238, ntokens=1259.2, nsentences=32, sample_size=1259.2, sample_size_v1=0, sample_size_v2=0, ppl=2.36, wps=319, ups=0.25, wpb=1259.2, bsz=32, num_updates=13520, lr=7.87011e-06, gnorm=7.288, clip=100, loss_scale=32, train_wall=39, gb_free=8, wall=52185
2023-05-21 08:27:46 - progress_bar.py[line:272] - INFO: epoch 008:   1432 / 1732 loss=2.402, loss_v1=0, loss_v2=0, nll_loss=1.204, ntokens=1215.6, nsentences=32, sample_size=1215.6, sample_size_v1=0, sample_size_v2=0, ppl=2.3, wps=313.9, ups=0.26, wpb=1215.6, bsz=32, num_updates=13530, lr=7.86807e-06, gnorm=6.375, clip=100, loss_scale=32, train_wall=39, gb_free=8.3, wall=52223
2023-05-21 08:28:25 - progress_bar.py[line:272] - INFO: epoch 008:   1442 / 1732 loss=2.435, loss_v1=0, loss_v2=0, nll_loss=1.241, ntokens=1136.6, nsentences=32, sample_size=1136.6, sample_size_v1=0, sample_size_v2=0, ppl=2.36, wps=293.6, ups=0.26, wpb=1136.6, bsz=32, num_updates=13540, lr=7.86602e-06, gnorm=7.331, clip=100, loss_scale=32, train_wall=39, gb_free=8.5, wall=52262
2023-05-21 08:29:04 - progress_bar.py[line:272] - INFO: epoch 008:   1452 / 1732 loss=2.444, loss_v1=0, loss_v2=0, nll_loss=1.25, ntokens=1140.1, nsentences=32, sample_size=1140.1, sample_size_v1=0, sample_size_v2=0, ppl=2.38, wps=294.1, ups=0.26, wpb=1140.1, bsz=32, num_updates=13550, lr=7.86397e-06, gnorm=7.535, clip=100, loss_scale=32, train_wall=39, gb_free=9, wall=52301
2023-05-21 08:29:43 - progress_bar.py[line:272] - INFO: epoch 008:   1462 / 1732 loss=2.407, loss_v1=0, loss_v2=0, nll_loss=1.209, ntokens=1170.3, nsentences=32, sample_size=1170.3, sample_size_v1=0, sample_size_v2=0, ppl=2.31, wps=299.3, ups=0.26, wpb=1170.3, bsz=32, num_updates=13560, lr=7.86192e-06, gnorm=7.027, clip=100, loss_scale=32, train_wall=39, gb_free=7.7, wall=52340
2023-05-21 08:30:22 - progress_bar.py[line:272] - INFO: epoch 008:   1472 / 1732 loss=2.416, loss_v1=0, loss_v2=0, nll_loss=1.221, ntokens=1139, nsentences=32, sample_size=1139, sample_size_v1=0, sample_size_v2=0, ppl=2.33, wps=292.8, ups=0.26, wpb=1139, bsz=32, num_updates=13570, lr=7.85988e-06, gnorm=7.496, clip=100, loss_scale=32, train_wall=39, gb_free=8.9, wall=52379
2023-05-21 08:31:00 - progress_bar.py[line:272] - INFO: epoch 008:   1482 / 1732 loss=2.46, loss_v1=0, loss_v2=0, nll_loss=1.267, ntokens=1051.3, nsentences=32, sample_size=1051.3, sample_size_v1=0, sample_size_v2=0, ppl=2.41, wps=272.3, ups=0.26, wpb=1051.3, bsz=32, num_updates=13580, lr=7.85783e-06, gnorm=7.757, clip=100, loss_scale=32, train_wall=39, gb_free=7.7, wall=52417
2023-05-21 08:31:39 - progress_bar.py[line:272] - INFO: epoch 008:   1492 / 1732 loss=2.423, loss_v1=0, loss_v2=0, nll_loss=1.225, ntokens=1143, nsentences=32, sample_size=1143, sample_size_v1=0, sample_size_v2=0, ppl=2.34, wps=293.9, ups=0.26, wpb=1143, bsz=32, num_updates=13590, lr=7.85578e-06, gnorm=6.884, clip=100, loss_scale=32, train_wall=39, gb_free=8.8, wall=52456
2023-05-21 08:32:18 - progress_bar.py[line:272] - INFO: epoch 008:   1502 / 1732 loss=2.383, loss_v1=0, loss_v2=0, nll_loss=1.183, ntokens=1131.9, nsentences=32, sample_size=1131.9, sample_size_v1=0, sample_size_v2=0, ppl=2.27, wps=291.6, ups=0.26, wpb=1131.9, bsz=32, num_updates=13600, lr=7.85374e-06, gnorm=7.317, clip=100, loss_scale=32, train_wall=39, gb_free=7.4, wall=52495
2023-05-21 08:32:56 - progress_bar.py[line:272] - INFO: epoch 008:   1512 / 1732 loss=2.421, loss_v1=0, loss_v2=0, nll_loss=1.228, ntokens=1058.6, nsentences=32, sample_size=1058.6, sample_size_v1=0, sample_size_v2=0, ppl=2.34, wps=275.7, ups=0.26, wpb=1058.6, bsz=32, num_updates=13610, lr=7.85169e-06, gnorm=7.717, clip=100, loss_scale=32, train_wall=38, gb_free=7.8, wall=52534
2023-05-21 08:33:35 - progress_bar.py[line:272] - INFO: epoch 008:   1522 / 1732 loss=2.455, loss_v1=0, loss_v2=0, nll_loss=1.262, ntokens=1011, nsentences=32, sample_size=1011, sample_size_v1=0, sample_size_v2=0, ppl=2.4, wps=263.9, ups=0.26, wpb=1011, bsz=32, num_updates=13620, lr=7.84964e-06, gnorm=7.513, clip=100, loss_scale=32, train_wall=38, gb_free=9, wall=52572
2023-05-21 08:34:13 - progress_bar.py[line:272] - INFO: epoch 008:   1532 / 1732 loss=2.45, loss_v1=0, loss_v2=0, nll_loss=1.255, ntokens=1075.4, nsentences=32, sample_size=1075.4, sample_size_v1=0, sample_size_v2=0, ppl=2.39, wps=277.7, ups=0.26, wpb=1075.4, bsz=32, num_updates=13630, lr=7.84759e-06, gnorm=8.37, clip=100, loss_scale=32, train_wall=39, gb_free=7.9, wall=52611
2023-05-21 08:34:52 - progress_bar.py[line:272] - INFO: epoch 008:   1542 / 1732 loss=2.411, loss_v1=0, loss_v2=0, nll_loss=1.212, ntokens=1113.4, nsentences=32, sample_size=1113.4, sample_size_v1=0, sample_size_v2=0, ppl=2.32, wps=287.5, ups=0.26, wpb=1113.4, bsz=32, num_updates=13640, lr=7.84555e-06, gnorm=7.771, clip=100, loss_scale=32, train_wall=39, gb_free=8.2, wall=52649
2023-05-21 08:35:31 - progress_bar.py[line:272] - INFO: epoch 008:   1552 / 1732 loss=2.412, loss_v1=0, loss_v2=0, nll_loss=1.217, ntokens=1059, nsentences=32, sample_size=1059, sample_size_v1=0, sample_size_v2=0, ppl=2.32, wps=275, ups=0.26, wpb=1059, bsz=32, num_updates=13650, lr=7.8435e-06, gnorm=8.008, clip=100, loss_scale=32, train_wall=38, gb_free=8.5, wall=52688
2023-05-21 08:36:10 - progress_bar.py[line:272] - INFO: epoch 008:   1562 / 1732 loss=2.439, loss_v1=0, loss_v2=0, nll_loss=1.244, ntokens=1107.4, nsentences=32, sample_size=1107.4, sample_size_v1=0, sample_size_v2=0, ppl=2.37, wps=284.3, ups=0.26, wpb=1107.4, bsz=32, num_updates=13660, lr=7.84145e-06, gnorm=7.632, clip=100, loss_scale=32, train_wall=39, gb_free=8.3, wall=52727
2023-05-21 08:36:48 - progress_bar.py[line:272] - INFO: epoch 008:   1572 / 1732 loss=2.457, loss_v1=0, loss_v2=0, nll_loss=1.264, ntokens=1068.7, nsentences=32, sample_size=1068.7, sample_size_v1=0, sample_size_v2=0, ppl=2.4, wps=275.9, ups=0.26, wpb=1068.7, bsz=32, num_updates=13670, lr=7.8394e-06, gnorm=9.167, clip=100, loss_scale=32, train_wall=39, gb_free=8.7, wall=52766
2023-05-21 08:37:27 - progress_bar.py[line:272] - INFO: epoch 008:   1582 / 1732 loss=2.471, loss_v1=0, loss_v2=0, nll_loss=1.281, ntokens=1012.7, nsentences=32, sample_size=1012.7, sample_size_v1=0, sample_size_v2=0, ppl=2.43, wps=260.7, ups=0.26, wpb=1012.7, bsz=32, num_updates=13680, lr=7.83736e-06, gnorm=8.364, clip=100, loss_scale=32, train_wall=39, gb_free=7.7, wall=52804
2023-05-21 08:38:06 - progress_bar.py[line:272] - INFO: epoch 008:   1592 / 1732 loss=2.416, loss_v1=0, loss_v2=0, nll_loss=1.218, ntokens=1072.6, nsentences=32, sample_size=1072.6, sample_size_v1=0, sample_size_v2=0, ppl=2.33, wps=275.3, ups=0.26, wpb=1072.6, bsz=32, num_updates=13690, lr=7.83531e-06, gnorm=7.647, clip=100, loss_scale=32, train_wall=39, gb_free=8.8, wall=52843
2023-05-21 08:38:45 - progress_bar.py[line:272] - INFO: epoch 008:   1602 / 1732 loss=2.404, loss_v1=0, loss_v2=0, nll_loss=1.207, ntokens=1101.7, nsentences=32, sample_size=1101.7, sample_size_v1=0, sample_size_v2=0, ppl=2.31, wps=284.7, ups=0.26, wpb=1101.7, bsz=32, num_updates=13700, lr=7.83326e-06, gnorm=7.754, clip=100, loss_scale=32, train_wall=39, gb_free=7.5, wall=52882
2023-05-21 08:39:24 - progress_bar.py[line:272] - INFO: epoch 008:   1612 / 1732 loss=2.403, loss_v1=0, loss_v2=0, nll_loss=1.204, ntokens=1156, nsentences=32, sample_size=1156, sample_size_v1=0, sample_size_v2=0, ppl=2.3, wps=296.8, ups=0.26, wpb=1156, bsz=32, num_updates=13710, lr=7.83121e-06, gnorm=7.831, clip=100, loss_scale=32, train_wall=39, gb_free=8.7, wall=52921
2023-05-21 08:40:03 - progress_bar.py[line:272] - INFO: epoch 008:   1622 / 1732 loss=2.397, loss_v1=0, loss_v2=0, nll_loss=1.2, ntokens=1098.4, nsentences=32, sample_size=1098.4, sample_size_v1=0, sample_size_v2=0, ppl=2.3, wps=281.7, ups=0.26, wpb=1098.4, bsz=32, num_updates=13720, lr=7.82917e-06, gnorm=7.536, clip=100, loss_scale=32, train_wall=39, gb_free=8.6, wall=52960
2023-05-21 08:40:42 - progress_bar.py[line:272] - INFO: epoch 008:   1632 / 1732 loss=2.415, loss_v1=0, loss_v2=0, nll_loss=1.219, ntokens=1161.4, nsentences=32, sample_size=1161.4, sample_size_v1=0, sample_size_v2=0, ppl=2.33, wps=298.9, ups=0.26, wpb=1161.4, bsz=32, num_updates=13730, lr=7.82712e-06, gnorm=7.253, clip=100, loss_scale=32, train_wall=39, gb_free=8.8, wall=52999
2023-05-21 08:41:21 - progress_bar.py[line:272] - INFO: epoch 008:   1642 / 1732 loss=2.383, loss_v1=0, loss_v2=0, nll_loss=1.179, ntokens=1223.1, nsentences=32, sample_size=1223.1, sample_size_v1=0, sample_size_v2=0, ppl=2.26, wps=314.8, ups=0.26, wpb=1223.1, bsz=32, num_updates=13740, lr=7.82507e-06, gnorm=7.14, clip=100, loss_scale=32, train_wall=39, gb_free=7.9, wall=53038
2023-05-21 08:41:59 - progress_bar.py[line:272] - INFO: epoch 008:   1652 / 1732 loss=2.416, loss_v1=0, loss_v2=0, nll_loss=1.219, ntokens=1045.5, nsentences=32, sample_size=1045.5, sample_size_v1=0, sample_size_v2=0, ppl=2.33, wps=271.9, ups=0.26, wpb=1045.5, bsz=32, num_updates=13750, lr=7.82302e-06, gnorm=8.41, clip=100, loss_scale=32, train_wall=38, gb_free=8.3, wall=53076
2023-05-21 08:42:37 - progress_bar.py[line:272] - INFO: epoch 008:   1662 / 1732 loss=2.439, loss_v1=0, loss_v2=0, nll_loss=1.245, ntokens=1037.9, nsentences=32, sample_size=1037.9, sample_size_v1=0, sample_size_v2=0, ppl=2.37, wps=269.7, ups=0.26, wpb=1037.9, bsz=32, num_updates=13760, lr=7.82098e-06, gnorm=8.006, clip=100, loss_scale=32, train_wall=38, gb_free=8.5, wall=53115
2023-05-21 08:43:16 - progress_bar.py[line:272] - INFO: epoch 008:   1672 / 1732 loss=2.421, loss_v1=0, loss_v2=0, nll_loss=1.223, ntokens=1009.9, nsentences=32, sample_size=1009.9, sample_size_v1=0, sample_size_v2=0, ppl=2.33, wps=262.9, ups=0.26, wpb=1009.9, bsz=32, num_updates=13770, lr=7.81893e-06, gnorm=7.463, clip=100, loss_scale=32, train_wall=38, gb_free=8.1, wall=53153
2023-05-21 08:43:55 - progress_bar.py[line:272] - INFO: epoch 008:   1682 / 1732 loss=2.378, loss_v1=0, loss_v2=0, nll_loss=1.176, ntokens=1181.4, nsentences=32, sample_size=1181.4, sample_size_v1=0, sample_size_v2=0, ppl=2.26, wps=302.8, ups=0.26, wpb=1181.4, bsz=32, num_updates=13780, lr=7.81688e-06, gnorm=6.515, clip=100, loss_scale=32, train_wall=39, gb_free=8.4, wall=53192
2023-05-21 08:44:34 - progress_bar.py[line:272] - INFO: epoch 008:   1692 / 1732 loss=2.391, loss_v1=0, loss_v2=0, nll_loss=1.195, ntokens=1233.5, nsentences=32, sample_size=1233.5, sample_size_v1=0, sample_size_v2=0, ppl=2.29, wps=314.4, ups=0.25, wpb=1233.5, bsz=32, num_updates=13790, lr=7.81484e-06, gnorm=6.928, clip=100, loss_scale=32, train_wall=39, gb_free=7.9, wall=53231
2023-05-21 08:45:13 - progress_bar.py[line:272] - INFO: epoch 008:   1702 / 1732 loss=2.408, loss_v1=0, loss_v2=0, nll_loss=1.21, ntokens=1273, nsentences=32, sample_size=1273, sample_size_v1=0, sample_size_v2=0, ppl=2.31, wps=324.2, ups=0.25, wpb=1273, bsz=32, num_updates=13800, lr=7.81279e-06, gnorm=6.783, clip=100, loss_scale=32, train_wall=39, gb_free=7.7, wall=53271
2023-05-21 08:45:52 - progress_bar.py[line:272] - INFO: epoch 008:   1712 / 1732 loss=2.421, loss_v1=0, loss_v2=0, nll_loss=1.224, ntokens=1144.5, nsentences=32, sample_size=1144.5, sample_size_v1=0, sample_size_v2=0, ppl=2.34, wps=295.4, ups=0.26, wpb=1144.5, bsz=32, num_updates=13810, lr=7.81074e-06, gnorm=7.579, clip=100, loss_scale=32, train_wall=39, gb_free=8.4, wall=53309
2023-05-21 08:46:31 - progress_bar.py[line:272] - INFO: epoch 008:   1722 / 1732 loss=2.408, loss_v1=0, loss_v2=0, nll_loss=1.21, ntokens=1176.1, nsentences=32, sample_size=1176.1, sample_size_v1=0, sample_size_v2=0, ppl=2.31, wps=301.2, ups=0.26, wpb=1176.1, bsz=32, num_updates=13820, lr=7.80869e-06, gnorm=6.815, clip=100, loss_scale=32, train_wall=39, gb_free=8.4, wall=53348
2023-05-21 08:47:07 - progress_bar.py[line:272] - INFO: epoch 008:   1732 / 1732 loss=2.452, loss_v1=0, loss_v2=0, nll_loss=1.258, ntokens=1056.7, nsentences=29.6, sample_size=1056.7, sample_size_v1=0, sample_size_v2=0, ppl=2.39, wps=292, ups=0.28, wpb=1056.7, bsz=29.6, num_updates=13830, lr=7.80665e-06, gnorm=7.612, clip=100, loss_scale=32, train_wall=36, gb_free=8.9, wall=53385
2023-05-21 08:47:07 - train.py[line:332] - INFO: end of epoch 8 (average epoch stats below)
2023-05-21 08:47:07 - progress_bar.py[line:282] - INFO: epoch 008 | loss 2.432 | loss_v1 0 | loss_v2 0 | nll_loss 1.237 | ntokens 1051.42 | nsentences 31.986 | sample_size 1051.42 | sample_size_v1 0 | sample_size_v2 0 | ppl 2.36 | wps 272.5 | ups 0.26 | wpb 1051.4 | bsz 32 | num_updates 13830 | lr 7.80665e-06 | gnorm 7.42 | clip 100 | loss_scale 32 | train_wall 6655 | gb_free 8.9 | wall 53385
2023-05-21 08:47:07 - trainer.py[line:639] - INFO: loading train data for epoch 9
local datafile ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 0 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 0 finished initializing row_count and line_idx-to-offset mapping
file ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 0 row count 55400 total row count 55400
slice_id 0 seek offset 0
2023-05-21 08:47:09 - trainer.py[line:703] - INFO: begin training epoch 9
2023-05-21 08:47:09 - train.py[line:305] - INFO: Start iterating over samples
2023-05-21 08:47:48 - progress_bar.py[line:272] - INFO: epoch 009:     10 / 1732 loss=2.365, loss_v1=0, loss_v2=0, nll_loss=1.159, ntokens=1132.5, nsentences=32, sample_size=1132.5, sample_size_v1=0, sample_size_v2=0, ppl=2.23, wps=276.8, ups=0.24, wpb=1132.5, bsz=32, num_updates=13840, lr=7.8046e-06, gnorm=7.54, clip=100, loss_scale=32, train_wall=39, gb_free=7.2, wall=53426
2023-05-21 08:48:27 - progress_bar.py[line:272] - INFO: epoch 009:     20 / 1732 loss=2.299, loss_v1=0, loss_v2=0, nll_loss=1.088, ntokens=1079.2, nsentences=32, sample_size=1079.2, sample_size_v1=0, sample_size_v2=0, ppl=2.13, wps=279.6, ups=0.26, wpb=1079.2, bsz=32, num_updates=13850, lr=7.80255e-06, gnorm=8.42, clip=100, loss_scale=32, train_wall=39, gb_free=8.6, wall=53464
2023-05-21 08:49:06 - progress_bar.py[line:272] - INFO: epoch 009:     30 / 1732 loss=2.356, loss_v1=0, loss_v2=0, nll_loss=1.151, ntokens=962.6, nsentences=32, sample_size=962.6, sample_size_v1=0, sample_size_v2=0, ppl=2.22, wps=249, ups=0.26, wpb=962.6, bsz=32, num_updates=13860, lr=7.8005e-06, gnorm=9.388, clip=100, loss_scale=32, train_wall=39, gb_free=8.3, wall=53503
2023-05-21 08:49:45 - progress_bar.py[line:272] - INFO: epoch 009:     40 / 1732 loss=2.181, loss_v1=0, loss_v2=0, nll_loss=0.957, ntokens=1211.6, nsentences=32, sample_size=1211.6, sample_size_v1=0, sample_size_v2=0, ppl=1.94, wps=307.5, ups=0.25, wpb=1211.6, bsz=32, num_updates=13870, lr=7.79846e-06, gnorm=6.487, clip=100, loss_scale=32, train_wall=39, gb_free=8.5, wall=53542
2023-05-21 08:50:24 - progress_bar.py[line:272] - INFO: epoch 009:     50 / 1732 loss=2.279, loss_v1=0, loss_v2=0, nll_loss=1.07, ntokens=1054.8, nsentences=32, sample_size=1054.8, sample_size_v1=0, sample_size_v2=0, ppl=2.1, wps=271.6, ups=0.26, wpb=1054.8, bsz=32, num_updates=13880, lr=7.79641e-06, gnorm=10.11, clip=100, loss_scale=32, train_wall=39, gb_free=8.2, wall=53581
2023-05-21 08:51:02 - progress_bar.py[line:272] - INFO: epoch 009:     60 / 1732 loss=2.086, loss_v1=0, loss_v2=0, nll_loss=0.846, ntokens=1049.9, nsentences=32, sample_size=1049.9, sample_size_v1=0, sample_size_v2=0, ppl=1.8, wps=273.4, ups=0.26, wpb=1049.9, bsz=32, num_updates=13890, lr=7.79436e-06, gnorm=7.78, clip=100, loss_scale=32, train_wall=38, gb_free=7.3, wall=53619
2023-05-21 08:51:42 - progress_bar.py[line:272] - INFO: epoch 009:     70 / 1732 loss=2.126, loss_v1=0, loss_v2=0, nll_loss=0.899, ntokens=1412, nsentences=32, sample_size=1412, sample_size_v1=0, sample_size_v2=0, ppl=1.86, wps=351.2, ups=0.25, wpb=1412, bsz=32, num_updates=13900, lr=7.79231e-06, gnorm=5.382, clip=100, loss_scale=32, train_wall=40, gb_free=7.9, wall=53660
2023-05-21 08:52:22 - progress_bar.py[line:272] - INFO: epoch 009:     80 / 1732 loss=2.178, loss_v1=0, loss_v2=0, nll_loss=0.947, ntokens=1259.9, nsentences=32, sample_size=1259.9, sample_size_v1=0, sample_size_v2=0, ppl=1.93, wps=316.4, ups=0.25, wpb=1259.9, bsz=32, num_updates=13910, lr=7.79027e-06, gnorm=5.93, clip=100, loss_scale=32, train_wall=40, gb_free=7.7, wall=53699
2023-05-21 08:53:01 - progress_bar.py[line:272] - INFO: epoch 009:     90 / 1732 loss=2.283, loss_v1=0, loss_v2=0, nll_loss=1.073, ntokens=1086.9, nsentences=32, sample_size=1086.9, sample_size_v1=0, sample_size_v2=0, ppl=2.1, wps=278.1, ups=0.26, wpb=1086.9, bsz=32, num_updates=13920, lr=7.78822e-06, gnorm=7.562, clip=100, loss_scale=32, train_wall=39, gb_free=8.2, wall=53739
2023-05-21 08:53:40 - progress_bar.py[line:272] - INFO: epoch 009:    100 / 1732 loss=2.264, loss_v1=0, loss_v2=0, nll_loss=1.05, ntokens=1024.5, nsentences=32, sample_size=1024.5, sample_size_v1=0, sample_size_v2=0, ppl=2.07, wps=265.3, ups=0.26, wpb=1024.5, bsz=32, num_updates=13930, lr=7.78617e-06, gnorm=8.081, clip=100, loss_scale=32, train_wall=39, gb_free=8.1, wall=53777
2023-05-21 08:54:19 - progress_bar.py[line:272] - INFO: epoch 009:    110 / 1732 loss=2.432, loss_v1=0, loss_v2=0, nll_loss=1.238, ntokens=1011.2, nsentences=32, sample_size=1011.2, sample_size_v1=0, sample_size_v2=0, ppl=2.36, wps=261.9, ups=0.26, wpb=1011.2, bsz=32, num_updates=13940, lr=7.78412e-06, gnorm=8.115, clip=100, loss_scale=32, train_wall=39, gb_free=8.1, wall=53816
2023-05-21 08:54:58 - progress_bar.py[line:272] - INFO: epoch 009:    120 / 1732 loss=2.391, loss_v1=0, loss_v2=0, nll_loss=1.194, ntokens=1124.3, nsentences=32, sample_size=1124.3, sample_size_v1=0, sample_size_v2=0, ppl=2.29, wps=286.5, ups=0.25, wpb=1124.3, bsz=32, num_updates=13950, lr=7.78208e-06, gnorm=7.622, clip=100, loss_scale=32, train_wall=39, gb_free=7.9, wall=53855
2023-05-21 08:55:37 - progress_bar.py[line:272] - INFO: epoch 009:    130 / 1732 loss=2.367, loss_v1=0, loss_v2=0, nll_loss=1.162, ntokens=1171.7, nsentences=32, sample_size=1171.7, sample_size_v1=0, sample_size_v2=0, ppl=2.24, wps=297.2, ups=0.25, wpb=1171.7, bsz=32, num_updates=13960, lr=7.78003e-06, gnorm=7.046, clip=100, loss_scale=32, train_wall=39, gb_free=7.7, wall=53894
2023-05-21 08:56:17 - progress_bar.py[line:272] - INFO: epoch 009:    140 / 1732 loss=2.334, loss_v1=0, loss_v2=0, nll_loss=1.123, ntokens=1245, nsentences=32, sample_size=1245, sample_size_v1=0, sample_size_v2=0, ppl=2.18, wps=314.5, ups=0.25, wpb=1245, bsz=32, num_updates=13970, lr=7.77798e-06, gnorm=6.324, clip=100, loss_scale=32, train_wall=40, gb_free=7.2, wall=53934
2023-05-21 08:56:57 - progress_bar.py[line:272] - INFO: epoch 009:    150 / 1732 loss=2.306, loss_v1=0, loss_v2=0, nll_loss=1.099, ntokens=1172.1, nsentences=32, sample_size=1172.1, sample_size_v1=0, sample_size_v2=0, ppl=2.14, wps=295.7, ups=0.25, wpb=1172.1, bsz=32, num_updates=13980, lr=7.77594e-06, gnorm=6.106, clip=100, loss_scale=32, train_wall=40, gb_free=8.1, wall=53974
2023-05-21 08:57:36 - progress_bar.py[line:272] - INFO: epoch 009:    160 / 1732 loss=2.342, loss_v1=0, loss_v2=0, nll_loss=1.138, ntokens=1127.8, nsentences=32, sample_size=1127.8, sample_size_v1=0, sample_size_v2=0, ppl=2.2, wps=286.1, ups=0.25, wpb=1127.8, bsz=32, num_updates=13990, lr=7.77389e-06, gnorm=6.837, clip=100, loss_scale=32, train_wall=39, gb_free=8.3, wall=54013
2023-05-21 08:58:15 - progress_bar.py[line:272] - INFO: epoch 009:    170 / 1732 loss=2.331, loss_v1=0, loss_v2=0, nll_loss=1.124, ntokens=965.3, nsentences=32, sample_size=965.3, sample_size_v1=0, sample_size_v2=0, ppl=2.18, wps=249.6, ups=0.26, wpb=965.3, bsz=32, num_updates=14000, lr=7.77184e-06, gnorm=7.085, clip=100, loss_scale=64, train_wall=39, gb_free=8.5, wall=54052
2023-05-21 08:58:54 - progress_bar.py[line:272] - INFO: epoch 009:    180 / 1732 loss=2.296, loss_v1=0, loss_v2=0, nll_loss=1.083, ntokens=1102.7, nsentences=32, sample_size=1102.7, sample_size_v1=0, sample_size_v2=0, ppl=2.12, wps=281.8, ups=0.26, wpb=1102.7, bsz=32, num_updates=14010, lr=7.76979e-06, gnorm=6.982, clip=100, loss_scale=64, train_wall=39, gb_free=8.1, wall=54091
2023-05-21 08:59:33 - progress_bar.py[line:272] - INFO: epoch 009:    190 / 1732 loss=2.314, loss_v1=0, loss_v2=0, nll_loss=1.106, ntokens=1120.1, nsentences=32, sample_size=1120.1, sample_size_v1=0, sample_size_v2=0, ppl=2.15, wps=286, ups=0.26, wpb=1120.1, bsz=32, num_updates=14020, lr=7.76775e-06, gnorm=6.816, clip=100, loss_scale=64, train_wall=39, gb_free=7.8, wall=54130
2023-05-21 09:00:12 - progress_bar.py[line:272] - INFO: epoch 009:    200 / 1732 loss=2.37, loss_v1=0, loss_v2=0, nll_loss=1.169, ntokens=1100.1, nsentences=32, sample_size=1100.1, sample_size_v1=0, sample_size_v2=0, ppl=2.25, wps=282.9, ups=0.26, wpb=1100.1, bsz=32, num_updates=14030, lr=7.7657e-06, gnorm=7.149, clip=100, loss_scale=64, train_wall=39, gb_free=8.9, wall=54169
2023-05-21 09:00:50 - progress_bar.py[line:272] - INFO: epoch 009:    210 / 1732 loss=2.458, loss_v1=0, loss_v2=0, nll_loss=1.268, ntokens=1012.9, nsentences=32, sample_size=1012.9, sample_size_v1=0, sample_size_v2=0, ppl=2.41, wps=264.2, ups=0.26, wpb=1012.9, bsz=32, num_updates=14040, lr=7.76365e-06, gnorm=7.321, clip=100, loss_scale=64, train_wall=38, gb_free=8.4, wall=54207
2023-05-21 09:01:29 - progress_bar.py[line:272] - INFO: epoch 009:    220 / 1732 loss=2.451, loss_v1=0, loss_v2=0, nll_loss=1.259, ntokens=1142.1, nsentences=32, sample_size=1142.1, sample_size_v1=0, sample_size_v2=0, ppl=2.39, wps=297.3, ups=0.26, wpb=1142.1, bsz=32, num_updates=14050, lr=7.7616e-06, gnorm=7.682, clip=100, loss_scale=64, train_wall=38, gb_free=8.4, wall=54246
2023-05-21 09:02:07 - progress_bar.py[line:272] - INFO: epoch 009:    230 / 1732 loss=2.474, loss_v1=0, loss_v2=0, nll_loss=1.282, ntokens=1099.8, nsentences=32, sample_size=1099.8, sample_size_v1=0, sample_size_v2=0, ppl=2.43, wps=287, ups=0.26, wpb=1099.8, bsz=32, num_updates=14060, lr=7.75956e-06, gnorm=8.303, clip=100, loss_scale=64, train_wall=38, gb_free=8.1, wall=54284
2023-05-21 09:02:45 - progress_bar.py[line:272] - INFO: epoch 009:    240 / 1732 loss=2.485, loss_v1=0, loss_v2=0, nll_loss=1.295, ntokens=1111.4, nsentences=32, sample_size=1111.4, sample_size_v1=0, sample_size_v2=0, ppl=2.45, wps=290.1, ups=0.26, wpb=1111.4, bsz=32, num_updates=14070, lr=7.75751e-06, gnorm=7.971, clip=100, loss_scale=64, train_wall=38, gb_free=8, wall=54322
2023-05-21 09:03:24 - progress_bar.py[line:272] - INFO: epoch 009:    250 / 1732 loss=2.461, loss_v1=0, loss_v2=0, nll_loss=1.268, ntokens=1170.4, nsentences=32, sample_size=1170.4, sample_size_v1=0, sample_size_v2=0, ppl=2.41, wps=302.6, ups=0.26, wpb=1170.4, bsz=32, num_updates=14080, lr=7.75546e-06, gnorm=6.878, clip=100, loss_scale=64, train_wall=39, gb_free=7.9, wall=54361
2023-05-21 09:04:02 - progress_bar.py[line:272] - INFO: epoch 009:    260 / 1732 loss=2.491, loss_v1=0, loss_v2=0, nll_loss=1.304, ntokens=1120.1, nsentences=32, sample_size=1120.1, sample_size_v1=0, sample_size_v2=0, ppl=2.47, wps=291.5, ups=0.26, wpb=1120.1, bsz=32, num_updates=14090, lr=7.75341e-06, gnorm=7.352, clip=100, loss_scale=64, train_wall=38, gb_free=8.3, wall=54400
2023-05-21 09:04:41 - progress_bar.py[line:272] - INFO: epoch 009:    270 / 1732 loss=2.456, loss_v1=0, loss_v2=0, nll_loss=1.262, ntokens=1146.7, nsentences=32, sample_size=1146.7, sample_size_v1=0, sample_size_v2=0, ppl=2.4, wps=298.1, ups=0.26, wpb=1146.7, bsz=32, num_updates=14100, lr=7.75137e-06, gnorm=7.177, clip=100, loss_scale=64, train_wall=38, gb_free=7.9, wall=54438
2023-05-21 09:05:19 - progress_bar.py[line:272] - INFO: epoch 009:    280 / 1732 loss=2.472, loss_v1=0, loss_v2=0, nll_loss=1.281, ntokens=1171.6, nsentences=32, sample_size=1171.6, sample_size_v1=0, sample_size_v2=0, ppl=2.43, wps=303.6, ups=0.26, wpb=1171.6, bsz=32, num_updates=14110, lr=7.74932e-06, gnorm=7.736, clip=100, loss_scale=64, train_wall=39, gb_free=8.2, wall=54477
2023-05-21 09:05:58 - progress_bar.py[line:272] - INFO: epoch 009:    290 / 1732 loss=2.442, loss_v1=0, loss_v2=0, nll_loss=1.249, ntokens=1121.4, nsentences=32, sample_size=1121.4, sample_size_v1=0, sample_size_v2=0, ppl=2.38, wps=291.3, ups=0.26, wpb=1121.4, bsz=32, num_updates=14120, lr=7.74727e-06, gnorm=7.108, clip=100, loss_scale=64, train_wall=38, gb_free=9, wall=54515
2023-05-21 09:06:36 - progress_bar.py[line:272] - INFO: epoch 009:    300 / 1732 loss=2.466, loss_v1=0, loss_v2=0, nll_loss=1.274, ntokens=1116.4, nsentences=32, sample_size=1116.4, sample_size_v1=0, sample_size_v2=0, ppl=2.42, wps=291.6, ups=0.26, wpb=1116.4, bsz=32, num_updates=14130, lr=7.74522e-06, gnorm=6.861, clip=100, loss_scale=64, train_wall=38, gb_free=7.7, wall=54553
2023-05-21 09:07:14 - progress_bar.py[line:272] - INFO: epoch 009:    310 / 1732 loss=2.441, loss_v1=0, loss_v2=0, nll_loss=1.246, ntokens=1069.4, nsentences=32, sample_size=1069.4, sample_size_v1=0, sample_size_v2=0, ppl=2.37, wps=279.3, ups=0.26, wpb=1069.4, bsz=32, num_updates=14140, lr=7.74318e-06, gnorm=7.937, clip=100, loss_scale=64, train_wall=38, gb_free=7.9, wall=54592
2023-05-21 09:07:53 - progress_bar.py[line:272] - INFO: epoch 009:    320 / 1732 loss=2.48, loss_v1=0, loss_v2=0, nll_loss=1.291, ntokens=1013.1, nsentences=32, sample_size=1013.1, sample_size_v1=0, sample_size_v2=0, ppl=2.45, wps=265.6, ups=0.26, wpb=1013.1, bsz=32, num_updates=14150, lr=7.74113e-06, gnorm=9.194, clip=100, loss_scale=64, train_wall=38, gb_free=8.6, wall=54630
2023-05-21 09:08:31 - progress_bar.py[line:272] - INFO: epoch 009:    330 / 1732 loss=2.494, loss_v1=0, loss_v2=0, nll_loss=1.306, ntokens=1024.4, nsentences=32, sample_size=1024.4, sample_size_v1=0, sample_size_v2=0, ppl=2.47, wps=268.3, ups=0.26, wpb=1024.4, bsz=32, num_updates=14160, lr=7.73908e-06, gnorm=7.855, clip=100, loss_scale=64, train_wall=38, gb_free=8.7, wall=54668
2023-05-21 09:09:09 - progress_bar.py[line:272] - INFO: epoch 009:    340 / 1732 loss=2.447, loss_v1=0, loss_v2=0, nll_loss=1.254, ntokens=959.9, nsentences=32, sample_size=959.9, sample_size_v1=0, sample_size_v2=0, ppl=2.39, wps=251.8, ups=0.26, wpb=959.9, bsz=32, num_updates=14170, lr=7.73703e-06, gnorm=7.91, clip=100, loss_scale=64, train_wall=38, gb_free=8.7, wall=54706
2023-05-21 09:09:47 - progress_bar.py[line:272] - INFO: epoch 009:    350 / 1732 loss=2.465, loss_v1=0, loss_v2=0, nll_loss=1.276, ntokens=909.7, nsentences=32, sample_size=909.7, sample_size_v1=0, sample_size_v2=0, ppl=2.42, wps=238.9, ups=0.26, wpb=909.7, bsz=32, num_updates=14180, lr=7.73499e-06, gnorm=8.583, clip=100, loss_scale=64, train_wall=38, gb_free=8.8, wall=54744
2023-05-21 09:10:25 - progress_bar.py[line:272] - INFO: epoch 009:    360 / 1732 loss=2.491, loss_v1=0, loss_v2=0, nll_loss=1.303, ntokens=938.9, nsentences=32, sample_size=938.9, sample_size_v1=0, sample_size_v2=0, ppl=2.47, wps=247.1, ups=0.26, wpb=938.9, bsz=32, num_updates=14190, lr=7.73294e-06, gnorm=8.202, clip=100, loss_scale=64, train_wall=38, gb_free=8.8, wall=54782
2023-05-21 09:11:03 - progress_bar.py[line:272] - INFO: epoch 009:    370 / 1732 loss=2.508, loss_v1=0, loss_v2=0, nll_loss=1.318, ntokens=953.9, nsentences=32, sample_size=953.9, sample_size_v1=0, sample_size_v2=0, ppl=2.49, wps=252.3, ups=0.26, wpb=953.9, bsz=32, num_updates=14200, lr=7.73089e-06, gnorm=8.623, clip=100, loss_scale=64, train_wall=38, gb_free=9.2, wall=54820
2023-05-21 09:11:41 - progress_bar.py[line:272] - INFO: epoch 009:    380 / 1732 loss=2.49, loss_v1=0, loss_v2=0, nll_loss=1.3, ntokens=1091.6, nsentences=32, sample_size=1091.6, sample_size_v1=0, sample_size_v2=0, ppl=2.46, wps=284.8, ups=0.26, wpb=1091.6, bsz=32, num_updates=14210, lr=7.72885e-06, gnorm=7.563, clip=100, loss_scale=64, train_wall=38, gb_free=8.9, wall=54858
2023-05-21 09:12:19 - progress_bar.py[line:272] - INFO: epoch 009:    390 / 1732 loss=2.469, loss_v1=0, loss_v2=0, nll_loss=1.279, ntokens=1027.2, nsentences=32, sample_size=1027.2, sample_size_v1=0, sample_size_v2=0, ppl=2.43, wps=269, ups=0.26, wpb=1027.2, bsz=32, num_updates=14220, lr=7.7268e-06, gnorm=8.203, clip=100, loss_scale=64, train_wall=38, gb_free=8.3, wall=54897
2023-05-21 09:12:57 - progress_bar.py[line:272] - INFO: epoch 009:    400 / 1732 loss=2.464, loss_v1=0, loss_v2=0, nll_loss=1.275, ntokens=977.7, nsentences=32, sample_size=977.7, sample_size_v1=0, sample_size_v2=0, ppl=2.42, wps=257.2, ups=0.26, wpb=977.7, bsz=32, num_updates=14230, lr=7.72475e-06, gnorm=8.649, clip=100, loss_scale=64, train_wall=38, gb_free=8.5, wall=54935
2023-05-21 09:13:36 - progress_bar.py[line:272] - INFO: epoch 009:    410 / 1732 loss=2.456, loss_v1=0, loss_v2=0, nll_loss=1.263, ntokens=1069.8, nsentences=32, sample_size=1069.8, sample_size_v1=0, sample_size_v2=0, ppl=2.4, wps=279.5, ups=0.26, wpb=1069.8, bsz=32, num_updates=14240, lr=7.7227e-06, gnorm=7.948, clip=100, loss_scale=64, train_wall=38, gb_free=8.4, wall=54973
2023-05-21 09:14:14 - progress_bar.py[line:272] - INFO: epoch 009:    420 / 1732 loss=2.438, loss_v1=0, loss_v2=0, nll_loss=1.244, ntokens=1036.4, nsentences=32, sample_size=1036.4, sample_size_v1=0, sample_size_v2=0, ppl=2.37, wps=270.7, ups=0.26, wpb=1036.4, bsz=32, num_updates=14250, lr=7.72066e-06, gnorm=8.936, clip=100, loss_scale=64, train_wall=38, gb_free=7.9, wall=55011
2023-05-21 09:14:52 - progress_bar.py[line:272] - INFO: epoch 009:    430 / 1732 loss=2.444, loss_v1=0, loss_v2=0, nll_loss=1.25, ntokens=1013.2, nsentences=32, sample_size=1013.2, sample_size_v1=0, sample_size_v2=0, ppl=2.38, wps=263.9, ups=0.26, wpb=1013.2, bsz=32, num_updates=14260, lr=7.71861e-06, gnorm=8.707, clip=100, loss_scale=64, train_wall=38, gb_free=8.5, wall=55049
2023-05-21 09:15:30 - progress_bar.py[line:272] - INFO: epoch 009:    440 / 1732 loss=2.476, loss_v1=0, loss_v2=0, nll_loss=1.287, ntokens=989.2, nsentences=32, sample_size=989.2, sample_size_v1=0, sample_size_v2=0, ppl=2.44, wps=259, ups=0.26, wpb=989.2, bsz=32, num_updates=14270, lr=7.71656e-06, gnorm=8.095, clip=100, loss_scale=64, train_wall=38, gb_free=9, wall=55088
2023-05-21 09:16:09 - progress_bar.py[line:272] - INFO: epoch 009:    450 / 1732 loss=2.483, loss_v1=0, loss_v2=0, nll_loss=1.294, ntokens=915.3, nsentences=32, sample_size=915.3, sample_size_v1=0, sample_size_v2=0, ppl=2.45, wps=240, ups=0.26, wpb=915.3, bsz=32, num_updates=14280, lr=7.71451e-06, gnorm=9.981, clip=100, loss_scale=64, train_wall=38, gb_free=9, wall=55126
2023-05-21 09:16:47 - progress_bar.py[line:272] - INFO: epoch 009:    460 / 1732 loss=2.472, loss_v1=0, loss_v2=0, nll_loss=1.282, ntokens=1040.5, nsentences=32, sample_size=1040.5, sample_size_v1=0, sample_size_v2=0, ppl=2.43, wps=273.5, ups=0.26, wpb=1040.5, bsz=32, num_updates=14290, lr=7.71247e-06, gnorm=8.049, clip=100, loss_scale=64, train_wall=38, gb_free=8.8, wall=55164
2023-05-21 09:17:25 - progress_bar.py[line:272] - INFO: epoch 009:    470 / 1732 loss=2.479, loss_v1=0, loss_v2=0, nll_loss=1.289, ntokens=1036.3, nsentences=32, sample_size=1036.3, sample_size_v1=0, sample_size_v2=0, ppl=2.44, wps=269.8, ups=0.26, wpb=1036.3, bsz=32, num_updates=14300, lr=7.71042e-06, gnorm=7.617, clip=100, loss_scale=64, train_wall=38, gb_free=8.7, wall=55202
2023-05-21 09:18:03 - progress_bar.py[line:272] - INFO: epoch 009:    480 / 1732 loss=2.482, loss_v1=0, loss_v2=0, nll_loss=1.291, ntokens=1040.5, nsentences=32, sample_size=1040.5, sample_size_v1=0, sample_size_v2=0, ppl=2.45, wps=271.4, ups=0.26, wpb=1040.5, bsz=32, num_updates=14310, lr=7.70837e-06, gnorm=8.774, clip=100, loss_scale=64, train_wall=38, gb_free=6.9, wall=55241
2023-05-21 09:18:41 - progress_bar.py[line:272] - INFO: epoch 009:    490 / 1732 loss=2.461, loss_v1=0, loss_v2=0, nll_loss=1.27, ntokens=919.9, nsentences=32, sample_size=919.9, sample_size_v1=0, sample_size_v2=0, ppl=2.41, wps=242.1, ups=0.26, wpb=919.9, bsz=32, num_updates=14320, lr=7.70632e-06, gnorm=9.186, clip=100, loss_scale=64, train_wall=38, gb_free=7.5, wall=55279
2023-05-21 09:19:19 - progress_bar.py[line:272] - INFO: epoch 009:    500 / 1732 loss=2.455, loss_v1=0, loss_v2=0, nll_loss=1.263, ntokens=950.8, nsentences=32, sample_size=950.8, sample_size_v1=0, sample_size_v2=0, ppl=2.4, wps=251.1, ups=0.26, wpb=950.8, bsz=32, num_updates=14330, lr=7.70428e-06, gnorm=8.377, clip=100, loss_scale=64, train_wall=38, gb_free=8.7, wall=55316
2023-05-21 09:19:57 - progress_bar.py[line:272] - INFO: epoch 009:    510 / 1732 loss=2.491, loss_v1=0, loss_v2=0, nll_loss=1.302, ntokens=1039.6, nsentences=32, sample_size=1039.6, sample_size_v1=0, sample_size_v2=0, ppl=2.47, wps=273.6, ups=0.26, wpb=1039.6, bsz=32, num_updates=14340, lr=7.70223e-06, gnorm=7.709, clip=100, loss_scale=64, train_wall=38, gb_free=8.1, wall=55354
2023-05-21 09:20:35 - progress_bar.py[line:272] - INFO: epoch 009:    520 / 1732 loss=2.449, loss_v1=0, loss_v2=0, nll_loss=1.257, ntokens=1010.1, nsentences=32, sample_size=1010.1, sample_size_v1=0, sample_size_v2=0, ppl=2.39, wps=267, ups=0.26, wpb=1010.1, bsz=32, num_updates=14350, lr=7.70018e-06, gnorm=8.707, clip=100, loss_scale=64, train_wall=38, gb_free=8.9, wall=55392
2023-05-21 09:21:13 - progress_bar.py[line:272] - INFO: epoch 009:    530 / 1732 loss=2.482, loss_v1=0, loss_v2=0, nll_loss=1.294, ntokens=937.1, nsentences=32, sample_size=937.1, sample_size_v1=0, sample_size_v2=0, ppl=2.45, wps=248.2, ups=0.26, wpb=937.1, bsz=32, num_updates=14360, lr=7.69813e-06, gnorm=9.851, clip=100, loss_scale=64, train_wall=38, gb_free=8.7, wall=55430
2023-05-21 09:21:51 - progress_bar.py[line:272] - INFO: epoch 009:    540 / 1732 loss=2.463, loss_v1=0, loss_v2=0, nll_loss=1.271, ntokens=998.6, nsentences=32, sample_size=998.6, sample_size_v1=0, sample_size_v2=0, ppl=2.41, wps=264.1, ups=0.26, wpb=998.6, bsz=32, num_updates=14370, lr=7.69609e-06, gnorm=8.381, clip=100, loss_scale=64, train_wall=38, gb_free=9.2, wall=55468
2023-05-21 09:22:29 - progress_bar.py[line:272] - INFO: epoch 009:    550 / 1732 loss=2.495, loss_v1=0, loss_v2=0, nll_loss=1.307, ntokens=1026.6, nsentences=32, sample_size=1026.6, sample_size_v1=0, sample_size_v2=0, ppl=2.47, wps=269.9, ups=0.26, wpb=1026.6, bsz=32, num_updates=14380, lr=7.69404e-06, gnorm=7.545, clip=100, loss_scale=64, train_wall=38, gb_free=8, wall=55506
2023-05-21 09:23:07 - progress_bar.py[line:272] - INFO: epoch 009:    560 / 1732 loss=2.481, loss_v1=0, loss_v2=0, nll_loss=1.293, ntokens=1014, nsentences=32, sample_size=1014, sample_size_v1=0, sample_size_v2=0, ppl=2.45, wps=266.6, ups=0.26, wpb=1014, bsz=32, num_updates=14390, lr=7.69199e-06, gnorm=8.247, clip=100, loss_scale=64, train_wall=38, gb_free=9, wall=55544
2023-05-21 09:23:45 - progress_bar.py[line:272] - INFO: epoch 009:    570 / 1732 loss=2.519, loss_v1=0, loss_v2=0, nll_loss=1.333, ntokens=1025.9, nsentences=32, sample_size=1025.9, sample_size_v1=0, sample_size_v2=0, ppl=2.52, wps=267.6, ups=0.26, wpb=1025.9, bsz=32, num_updates=14400, lr=7.68995e-06, gnorm=9.68, clip=100, loss_scale=64, train_wall=38, gb_free=8.5, wall=55582
2023-05-21 09:24:24 - progress_bar.py[line:272] - INFO: epoch 009:    580 / 1732 loss=2.473, loss_v1=0, loss_v2=0, nll_loss=1.282, ntokens=999.5, nsentences=32, sample_size=999.5, sample_size_v1=0, sample_size_v2=0, ppl=2.43, wps=259.9, ups=0.26, wpb=999.5, bsz=32, num_updates=14410, lr=7.6879e-06, gnorm=9.416, clip=100, loss_scale=64, train_wall=38, gb_free=8.3, wall=55621
2023-05-21 09:25:02 - progress_bar.py[line:272] - INFO: epoch 009:    590 / 1732 loss=2.472, loss_v1=0, loss_v2=0, nll_loss=1.282, ntokens=927.2, nsentences=32, sample_size=927.2, sample_size_v1=0, sample_size_v2=0, ppl=2.43, wps=242.3, ups=0.26, wpb=927.2, bsz=32, num_updates=14420, lr=7.68585e-06, gnorm=8.896, clip=100, loss_scale=64, train_wall=38, gb_free=9.4, wall=55659
2023-05-21 09:25:40 - progress_bar.py[line:272] - INFO: epoch 009:    600 / 1732 loss=2.439, loss_v1=0, loss_v2=0, nll_loss=1.246, ntokens=957.2, nsentences=32, sample_size=957.2, sample_size_v1=0, sample_size_v2=0, ppl=2.37, wps=251.8, ups=0.26, wpb=957.2, bsz=32, num_updates=14430, lr=7.6838e-06, gnorm=9.186, clip=100, loss_scale=64, train_wall=38, gb_free=8.5, wall=55697
2023-05-21 09:26:18 - progress_bar.py[line:272] - INFO: epoch 009:    610 / 1732 loss=2.455, loss_v1=0, loss_v2=0, nll_loss=1.266, ntokens=913.5, nsentences=32, sample_size=913.5, sample_size_v1=0, sample_size_v2=0, ppl=2.4, wps=240.4, ups=0.26, wpb=913.5, bsz=32, num_updates=14440, lr=7.68176e-06, gnorm=8.856, clip=100, loss_scale=64, train_wall=38, gb_free=9.1, wall=55735
2023-05-21 09:26:56 - progress_bar.py[line:272] - INFO: epoch 009:    620 / 1732 loss=2.498, loss_v1=0, loss_v2=0, nll_loss=1.31, ntokens=845.3, nsentences=32, sample_size=845.3, sample_size_v1=0, sample_size_v2=0, ppl=2.48, wps=224.4, ups=0.27, wpb=845.3, bsz=32, num_updates=14450, lr=7.67971e-06, gnorm=9.898, clip=100, loss_scale=64, train_wall=38, gb_free=9.1, wall=55773
2023-05-21 09:27:33 - progress_bar.py[line:272] - INFO: epoch 009:    630 / 1732 loss=2.46, loss_v1=0, loss_v2=0, nll_loss=1.269, ntokens=937, nsentences=32, sample_size=937, sample_size_v1=0, sample_size_v2=0, ppl=2.41, wps=248.2, ups=0.26, wpb=937, bsz=32, num_updates=14460, lr=7.67766e-06, gnorm=10.249, clip=100, loss_scale=64, train_wall=38, gb_free=8.6, wall=55811
2023-05-21 09:28:11 - progress_bar.py[line:272] - INFO: epoch 009:    640 / 1732 loss=2.488, loss_v1=0, loss_v2=0, nll_loss=1.3, ntokens=921.7, nsentences=32, sample_size=921.7, sample_size_v1=0, sample_size_v2=0, ppl=2.46, wps=242.8, ups=0.26, wpb=921.7, bsz=32, num_updates=14470, lr=7.67561e-06, gnorm=9.761, clip=100, loss_scale=64, train_wall=38, gb_free=8.2, wall=55848
2023-05-21 09:28:49 - progress_bar.py[line:272] - INFO: epoch 009:    650 / 1732 loss=2.482, loss_v1=0, loss_v2=0, nll_loss=1.293, ntokens=995.3, nsentences=32, sample_size=995.3, sample_size_v1=0, sample_size_v2=0, ppl=2.45, wps=263.2, ups=0.26, wpb=995.3, bsz=32, num_updates=14480, lr=7.67357e-06, gnorm=8.994, clip=100, loss_scale=64, train_wall=38, gb_free=8.3, wall=55886
2023-05-21 09:29:26 - progress_bar.py[line:272] - INFO: epoch 009:    660 / 1732 loss=2.495, loss_v1=0, loss_v2=0, nll_loss=1.307, ntokens=859.4, nsentences=32, sample_size=859.4, sample_size_v1=0, sample_size_v2=0, ppl=2.47, wps=230.3, ups=0.27, wpb=859.4, bsz=32, num_updates=14490, lr=7.67152e-06, gnorm=10.766, clip=100, loss_scale=64, train_wall=37, gb_free=9.2, wall=55924
2023-05-21 09:30:04 - progress_bar.py[line:272] - INFO: epoch 009:    670 / 1732 loss=2.484, loss_v1=0, loss_v2=0, nll_loss=1.294, ntokens=914.5, nsentences=32, sample_size=914.5, sample_size_v1=0, sample_size_v2=0, ppl=2.45, wps=242.1, ups=0.26, wpb=914.5, bsz=32, num_updates=14500, lr=7.66947e-06, gnorm=9.803, clip=100, loss_scale=64, train_wall=38, gb_free=8.7, wall=55961
2023-05-21 09:30:23 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2023-05-21 09:30:46 - progress_bar.py[line:272] - INFO: epoch 009:    681 / 1732 loss=2.469, loss_v1=0, loss_v2=0, nll_loss=1.278, ntokens=1004.5, nsentences=32, sample_size=1004.5, sample_size_v1=0, sample_size_v2=0, ppl=2.43, wps=241.3, ups=0.24, wpb=1004.5, bsz=32, num_updates=14510, lr=7.66742e-06, gnorm=8.175, clip=100, loss_scale=64, train_wall=42, gb_free=8.2, wall=56003
2023-05-21 09:31:24 - progress_bar.py[line:272] - INFO: epoch 009:    691 / 1732 loss=2.489, loss_v1=0, loss_v2=0, nll_loss=1.302, ntokens=949, nsentences=32, sample_size=949, sample_size_v1=0, sample_size_v2=0, ppl=2.47, wps=249.6, ups=0.26, wpb=949, bsz=32, num_updates=14520, lr=7.66538e-06, gnorm=9.63, clip=100, loss_scale=64, train_wall=38, gb_free=8.9, wall=56041
2023-05-21 09:32:02 - progress_bar.py[line:272] - INFO: epoch 009:    701 / 1732 loss=2.448, loss_v1=0, loss_v2=0, nll_loss=1.255, ntokens=988.7, nsentences=32, sample_size=988.7, sample_size_v1=0, sample_size_v2=0, ppl=2.39, wps=260.4, ups=0.26, wpb=988.7, bsz=32, num_updates=14530, lr=7.66333e-06, gnorm=7.825, clip=100, loss_scale=64, train_wall=38, gb_free=9, wall=56079
2023-05-21 09:32:40 - progress_bar.py[line:272] - INFO: epoch 009:    711 / 1732 loss=2.488, loss_v1=0, loss_v2=0, nll_loss=1.298, ntokens=913.9, nsentences=32, sample_size=913.9, sample_size_v1=0, sample_size_v2=0, ppl=2.46, wps=242, ups=0.26, wpb=913.9, bsz=32, num_updates=14540, lr=7.66128e-06, gnorm=10.131, clip=100, loss_scale=64, train_wall=38, gb_free=9, wall=56117
2023-05-21 09:33:17 - progress_bar.py[line:272] - INFO: epoch 009:    721 / 1732 loss=2.446, loss_v1=0, loss_v2=0, nll_loss=1.252, ntokens=854.5, nsentences=32, sample_size=854.5, sample_size_v1=0, sample_size_v2=0, ppl=2.38, wps=226, ups=0.26, wpb=854.5, bsz=32, num_updates=14550, lr=7.65923e-06, gnorm=8.808, clip=100, loss_scale=64, train_wall=38, gb_free=8.6, wall=56155
2023-05-21 09:33:55 - progress_bar.py[line:272] - INFO: epoch 009:    731 / 1732 loss=2.45, loss_v1=0, loss_v2=0, nll_loss=1.259, ntokens=932.8, nsentences=32, sample_size=932.8, sample_size_v1=0, sample_size_v2=0, ppl=2.39, wps=247.7, ups=0.27, wpb=932.8, bsz=32, num_updates=14560, lr=7.65719e-06, gnorm=8.847, clip=100, loss_scale=64, train_wall=38, gb_free=8.7, wall=56192
2023-05-21 09:34:33 - progress_bar.py[line:272] - INFO: epoch 009:    741 / 1732 loss=2.448, loss_v1=0, loss_v2=0, nll_loss=1.259, ntokens=1003.7, nsentences=32, sample_size=1003.7, sample_size_v1=0, sample_size_v2=0, ppl=2.39, wps=264.9, ups=0.26, wpb=1003.7, bsz=32, num_updates=14570, lr=7.65514e-06, gnorm=9.906, clip=100, loss_scale=64, train_wall=38, gb_free=8.6, wall=56230
2023-05-21 09:35:11 - progress_bar.py[line:272] - INFO: epoch 009:    751 / 1732 loss=2.464, loss_v1=0, loss_v2=0, nll_loss=1.272, ntokens=975.7, nsentences=32, sample_size=975.7, sample_size_v1=0, sample_size_v2=0, ppl=2.42, wps=256.8, ups=0.26, wpb=975.7, bsz=32, num_updates=14580, lr=7.65309e-06, gnorm=8.676, clip=100, loss_scale=64, train_wall=38, gb_free=8.2, wall=56268
2023-05-21 09:35:49 - progress_bar.py[line:272] - INFO: epoch 009:    761 / 1732 loss=2.447, loss_v1=0, loss_v2=0, nll_loss=1.252, ntokens=974.2, nsentences=32, sample_size=974.2, sample_size_v1=0, sample_size_v2=0, ppl=2.38, wps=255.9, ups=0.26, wpb=974.2, bsz=32, num_updates=14590, lr=7.65105e-06, gnorm=8.532, clip=100, loss_scale=64, train_wall=38, gb_free=8.7, wall=56306
2023-05-21 09:36:27 - progress_bar.py[line:272] - INFO: epoch 009:    771 / 1732 loss=2.455, loss_v1=0, loss_v2=0, nll_loss=1.266, ntokens=924.9, nsentences=32, sample_size=924.9, sample_size_v1=0, sample_size_v2=0, ppl=2.41, wps=244, ups=0.26, wpb=924.9, bsz=32, num_updates=14600, lr=7.649e-06, gnorm=9.496, clip=100, loss_scale=64, train_wall=38, gb_free=8.9, wall=56344
2023-05-21 09:37:05 - progress_bar.py[line:272] - INFO: epoch 009:    781 / 1732 loss=2.468, loss_v1=0, loss_v2=0, nll_loss=1.278, ntokens=1053.4, nsentences=32, sample_size=1053.4, sample_size_v1=0, sample_size_v2=0, ppl=2.42, wps=275.8, ups=0.26, wpb=1053.4, bsz=32, num_updates=14610, lr=7.64695e-06, gnorm=8.473, clip=100, loss_scale=64, train_wall=38, gb_free=8.9, wall=56382
2023-05-21 09:37:43 - progress_bar.py[line:272] - INFO: epoch 009:    791 / 1732 loss=2.461, loss_v1=0, loss_v2=0, nll_loss=1.27, ntokens=1022, nsentences=32, sample_size=1022, sample_size_v1=0, sample_size_v2=0, ppl=2.41, wps=267.9, ups=0.26, wpb=1022, bsz=32, num_updates=14620, lr=7.6449e-06, gnorm=9.061, clip=100, loss_scale=64, train_wall=38, gb_free=8.6, wall=56420
2023-05-21 09:38:21 - progress_bar.py[line:272] - INFO: epoch 009:    801 / 1732 loss=2.454, loss_v1=0, loss_v2=0, nll_loss=1.261, ntokens=984.3, nsentences=32, sample_size=984.3, sample_size_v1=0, sample_size_v2=0, ppl=2.4, wps=258.8, ups=0.26, wpb=984.3, bsz=32, num_updates=14630, lr=7.64286e-06, gnorm=8.816, clip=100, loss_scale=64, train_wall=38, gb_free=8.3, wall=56459
2023-05-21 09:38:59 - progress_bar.py[line:272] - INFO: epoch 009:    811 / 1732 loss=2.459, loss_v1=0, loss_v2=0, nll_loss=1.268, ntokens=931.4, nsentences=32, sample_size=931.4, sample_size_v1=0, sample_size_v2=0, ppl=2.41, wps=245.1, ups=0.26, wpb=931.4, bsz=32, num_updates=14640, lr=7.64081e-06, gnorm=9.855, clip=100, loss_scale=64, train_wall=38, gb_free=8.7, wall=56497
2023-05-21 09:39:37 - progress_bar.py[line:272] - INFO: epoch 009:    821 / 1732 loss=2.474, loss_v1=0, loss_v2=0, nll_loss=1.283, ntokens=915.1, nsentences=32, sample_size=915.1, sample_size_v1=0, sample_size_v2=0, ppl=2.43, wps=240.6, ups=0.26, wpb=915.1, bsz=32, num_updates=14650, lr=7.63876e-06, gnorm=9.698, clip=100, loss_scale=64, train_wall=38, gb_free=7.2, wall=56535
2023-05-21 09:40:15 - progress_bar.py[line:272] - INFO: epoch 009:    831 / 1732 loss=2.457, loss_v1=0, loss_v2=0, nll_loss=1.264, ntokens=914.9, nsentences=32, sample_size=914.9, sample_size_v1=0, sample_size_v2=0, ppl=2.4, wps=241.6, ups=0.26, wpb=914.9, bsz=32, num_updates=14660, lr=7.63671e-06, gnorm=9.061, clip=100, loss_scale=64, train_wall=38, gb_free=8.8, wall=56572
2023-05-21 09:40:53 - progress_bar.py[line:272] - INFO: epoch 009:    841 / 1732 loss=2.457, loss_v1=0, loss_v2=0, nll_loss=1.264, ntokens=933, nsentences=32, sample_size=933, sample_size_v1=0, sample_size_v2=0, ppl=2.4, wps=246.3, ups=0.26, wpb=933, bsz=32, num_updates=14670, lr=7.63467e-06, gnorm=9.675, clip=100, loss_scale=64, train_wall=38, gb_free=9, wall=56610
2023-05-21 09:41:31 - progress_bar.py[line:272] - INFO: epoch 009:    851 / 1732 loss=2.463, loss_v1=0, loss_v2=0, nll_loss=1.271, ntokens=1005.2, nsentences=32, sample_size=1005.2, sample_size_v1=0, sample_size_v2=0, ppl=2.41, wps=264.6, ups=0.26, wpb=1005.2, bsz=32, num_updates=14680, lr=7.63262e-06, gnorm=9.118, clip=100, loss_scale=64, train_wall=38, gb_free=8.6, wall=56648
2023-05-21 09:42:09 - progress_bar.py[line:272] - INFO: epoch 009:    861 / 1732 loss=2.441, loss_v1=0, loss_v2=0, nll_loss=1.246, ntokens=942.6, nsentences=32, sample_size=942.6, sample_size_v1=0, sample_size_v2=0, ppl=2.37, wps=249.8, ups=0.27, wpb=942.6, bsz=32, num_updates=14690, lr=7.63057e-06, gnorm=10.033, clip=100, loss_scale=64, train_wall=38, gb_free=8.5, wall=56686
2023-05-21 09:42:47 - progress_bar.py[line:272] - INFO: epoch 009:    871 / 1732 loss=2.464, loss_v1=0, loss_v2=0, nll_loss=1.273, ntokens=962.7, nsentences=32, sample_size=962.7, sample_size_v1=0, sample_size_v2=0, ppl=2.42, wps=253.7, ups=0.26, wpb=962.7, bsz=32, num_updates=14700, lr=7.62852e-06, gnorm=8.603, clip=100, loss_scale=64, train_wall=38, gb_free=9, wall=56724
2023-05-21 09:43:25 - progress_bar.py[line:272] - INFO: epoch 009:    881 / 1732 loss=2.408, loss_v1=0, loss_v2=0, nll_loss=1.213, ntokens=988.4, nsentences=32, sample_size=988.4, sample_size_v1=0, sample_size_v2=0, ppl=2.32, wps=258, ups=0.26, wpb=988.4, bsz=32, num_updates=14710, lr=7.62648e-06, gnorm=8.426, clip=100, loss_scale=64, train_wall=38, gb_free=9.2, wall=56762
2023-05-21 09:44:03 - progress_bar.py[line:272] - INFO: epoch 009:    891 / 1732 loss=2.397, loss_v1=0, loss_v2=0, nll_loss=1.199, ntokens=1001.4, nsentences=32, sample_size=1001.4, sample_size_v1=0, sample_size_v2=0, ppl=2.3, wps=262.1, ups=0.26, wpb=1001.4, bsz=32, num_updates=14720, lr=7.62443e-06, gnorm=8.361, clip=100, loss_scale=64, train_wall=38, gb_free=8.6, wall=56801
2023-05-21 09:44:42 - progress_bar.py[line:272] - INFO: epoch 009:    901 / 1732 loss=2.397, loss_v1=0, loss_v2=0, nll_loss=1.197, ntokens=1032.4, nsentences=32, sample_size=1032.4, sample_size_v1=0, sample_size_v2=0, ppl=2.29, wps=269.9, ups=0.26, wpb=1032.4, bsz=32, num_updates=14730, lr=7.62238e-06, gnorm=8.906, clip=100, loss_scale=64, train_wall=38, gb_free=9.2, wall=56839
2023-05-21 09:45:20 - progress_bar.py[line:272] - INFO: epoch 009:    911 / 1732 loss=2.452, loss_v1=0, loss_v2=0, nll_loss=1.258, ntokens=960.1, nsentences=32, sample_size=960.1, sample_size_v1=0, sample_size_v2=0, ppl=2.39, wps=252.9, ups=0.26, wpb=960.1, bsz=32, num_updates=14740, lr=7.62033e-06, gnorm=8.835, clip=100, loss_scale=64, train_wall=38, gb_free=9.2, wall=56877
2023-05-21 09:45:58 - progress_bar.py[line:272] - INFO: epoch 009:    921 / 1732 loss=2.465, loss_v1=0, loss_v2=0, nll_loss=1.276, ntokens=986.3, nsentences=32, sample_size=986.3, sample_size_v1=0, sample_size_v2=0, ppl=2.42, wps=258.1, ups=0.26, wpb=986.3, bsz=32, num_updates=14750, lr=7.61829e-06, gnorm=9.211, clip=100, loss_scale=64, train_wall=38, gb_free=8.5, wall=56915
2023-05-21 09:46:36 - progress_bar.py[line:272] - INFO: epoch 009:    931 / 1732 loss=2.428, loss_v1=0, loss_v2=0, nll_loss=1.233, ntokens=1050.4, nsentences=32, sample_size=1050.4, sample_size_v1=0, sample_size_v2=0, ppl=2.35, wps=272.4, ups=0.26, wpb=1050.4, bsz=32, num_updates=14760, lr=7.61624e-06, gnorm=8.469, clip=100, loss_scale=64, train_wall=39, gb_free=8.8, wall=56954
2023-05-21 09:47:15 - progress_bar.py[line:272] - INFO: epoch 009:    941 / 1732 loss=2.423, loss_v1=0, loss_v2=0, nll_loss=1.225, ntokens=1052.3, nsentences=32, sample_size=1052.3, sample_size_v1=0, sample_size_v2=0, ppl=2.34, wps=272.3, ups=0.26, wpb=1052.3, bsz=32, num_updates=14770, lr=7.61419e-06, gnorm=7.44, clip=100, loss_scale=64, train_wall=39, gb_free=7.1, wall=56992
2023-05-21 09:47:53 - progress_bar.py[line:272] - INFO: epoch 009:    951 / 1732 loss=2.439, loss_v1=0, loss_v2=0, nll_loss=1.244, ntokens=1037.8, nsentences=32, sample_size=1037.8, sample_size_v1=0, sample_size_v2=0, ppl=2.37, wps=270, ups=0.26, wpb=1037.8, bsz=32, num_updates=14780, lr=7.61215e-06, gnorm=7.824, clip=100, loss_scale=64, train_wall=38, gb_free=8.3, wall=57031
2023-05-21 09:48:32 - progress_bar.py[line:272] - INFO: epoch 009:    961 / 1732 loss=2.438, loss_v1=0, loss_v2=0, nll_loss=1.247, ntokens=1067.9, nsentences=32, sample_size=1067.9, sample_size_v1=0, sample_size_v2=0, ppl=2.37, wps=275.3, ups=0.26, wpb=1067.9, bsz=32, num_updates=14790, lr=7.6101e-06, gnorm=7.154, clip=100, loss_scale=64, train_wall=39, gb_free=8.6, wall=57069
2023-05-21 09:49:11 - progress_bar.py[line:272] - INFO: epoch 009:    971 / 1732 loss=2.471, loss_v1=0, loss_v2=0, nll_loss=1.282, ntokens=1026.9, nsentences=32, sample_size=1026.9, sample_size_v1=0, sample_size_v2=0, ppl=2.43, wps=267.3, ups=0.26, wpb=1026.9, bsz=32, num_updates=14800, lr=7.60805e-06, gnorm=8.738, clip=100, loss_scale=64, train_wall=38, gb_free=7.4, wall=57108
2023-05-21 09:49:49 - progress_bar.py[line:272] - INFO: epoch 009:    981 / 1732 loss=2.431, loss_v1=0, loss_v2=0, nll_loss=1.236, ntokens=1016.8, nsentences=32, sample_size=1016.8, sample_size_v1=0, sample_size_v2=0, ppl=2.36, wps=264.2, ups=0.26, wpb=1016.8, bsz=32, num_updates=14810, lr=7.606e-06, gnorm=7.943, clip=100, loss_scale=64, train_wall=38, gb_free=8.2, wall=57146
2023-05-21 09:50:28 - progress_bar.py[line:272] - INFO: epoch 009:    991 / 1732 loss=2.446, loss_v1=0, loss_v2=0, nll_loss=1.253, ntokens=1042.2, nsentences=32, sample_size=1042.2, sample_size_v1=0, sample_size_v2=0, ppl=2.38, wps=269.8, ups=0.26, wpb=1042.2, bsz=32, num_updates=14820, lr=7.60396e-06, gnorm=8.234, clip=100, loss_scale=64, train_wall=39, gb_free=8.8, wall=57185
2023-05-21 09:51:06 - progress_bar.py[line:272] - INFO: epoch 009:   1001 / 1732 loss=2.423, loss_v1=0, loss_v2=0, nll_loss=1.226, ntokens=1019, nsentences=32, sample_size=1019, sample_size_v1=0, sample_size_v2=0, ppl=2.34, wps=265.6, ups=0.26, wpb=1019, bsz=32, num_updates=14830, lr=7.60191e-06, gnorm=8.349, clip=100, loss_scale=64, train_wall=38, gb_free=8.7, wall=57223
2023-05-21 09:51:45 - progress_bar.py[line:272] - INFO: epoch 009:   1011 / 1732 loss=2.443, loss_v1=0, loss_v2=0, nll_loss=1.249, ntokens=995.8, nsentences=32, sample_size=995.8, sample_size_v1=0, sample_size_v2=0, ppl=2.38, wps=258.4, ups=0.26, wpb=995.8, bsz=32, num_updates=14840, lr=7.59986e-06, gnorm=9.204, clip=100, loss_scale=64, train_wall=38, gb_free=8.7, wall=57262
2023-05-21 09:52:24 - progress_bar.py[line:272] - INFO: epoch 009:   1021 / 1732 loss=2.417, loss_v1=0, loss_v2=0, nll_loss=1.221, ntokens=1050, nsentences=32, sample_size=1050, sample_size_v1=0, sample_size_v2=0, ppl=2.33, wps=269.3, ups=0.26, wpb=1050, bsz=32, num_updates=14850, lr=7.59781e-06, gnorm=7.855, clip=100, loss_scale=64, train_wall=39, gb_free=7.5, wall=57301
2023-05-21 09:53:03 - progress_bar.py[line:272] - INFO: epoch 009:   1031 / 1732 loss=2.441, loss_v1=0, loss_v2=0, nll_loss=1.249, ntokens=1125.6, nsentences=32, sample_size=1125.6, sample_size_v1=0, sample_size_v2=0, ppl=2.38, wps=287.8, ups=0.26, wpb=1125.6, bsz=32, num_updates=14860, lr=7.59577e-06, gnorm=7.579, clip=100, loss_scale=64, train_wall=39, gb_free=8.3, wall=57340
2023-05-21 09:53:42 - progress_bar.py[line:272] - INFO: epoch 009:   1041 / 1732 loss=2.438, loss_v1=0, loss_v2=0, nll_loss=1.241, ntokens=1038.5, nsentences=32, sample_size=1038.5, sample_size_v1=0, sample_size_v2=0, ppl=2.36, wps=267.7, ups=0.26, wpb=1038.5, bsz=32, num_updates=14870, lr=7.59372e-06, gnorm=8.275, clip=100, loss_scale=64, train_wall=39, gb_free=9, wall=57379
2023-05-21 09:54:20 - progress_bar.py[line:272] - INFO: epoch 009:   1051 / 1732 loss=2.441, loss_v1=0, loss_v2=0, nll_loss=1.245, ntokens=1067.2, nsentences=32, sample_size=1067.2, sample_size_v1=0, sample_size_v2=0, ppl=2.37, wps=277, ups=0.26, wpb=1067.2, bsz=32, num_updates=14880, lr=7.59167e-06, gnorm=8.834, clip=100, loss_scale=64, train_wall=38, gb_free=8.6, wall=57417
2023-05-21 09:54:59 - progress_bar.py[line:272] - INFO: epoch 009:   1061 / 1732 loss=2.432, loss_v1=0, loss_v2=0, nll_loss=1.236, ntokens=1037.8, nsentences=32, sample_size=1037.8, sample_size_v1=0, sample_size_v2=0, ppl=2.36, wps=268.6, ups=0.26, wpb=1037.8, bsz=32, num_updates=14890, lr=7.58962e-06, gnorm=9.894, clip=100, loss_scale=64, train_wall=39, gb_free=8.7, wall=57456
2023-05-21 09:55:37 - progress_bar.py[line:272] - INFO: epoch 009:   1071 / 1732 loss=2.435, loss_v1=0, loss_v2=0, nll_loss=1.241, ntokens=999.8, nsentences=32, sample_size=999.8, sample_size_v1=0, sample_size_v2=0, ppl=2.36, wps=259.4, ups=0.26, wpb=999.8, bsz=32, num_updates=14900, lr=7.58758e-06, gnorm=9.032, clip=100, loss_scale=64, train_wall=38, gb_free=7.8, wall=57494
2023-05-21 09:56:16 - progress_bar.py[line:272] - INFO: epoch 009:   1081 / 1732 loss=2.448, loss_v1=0, loss_v2=0, nll_loss=1.255, ntokens=1039.7, nsentences=32, sample_size=1039.7, sample_size_v1=0, sample_size_v2=0, ppl=2.39, wps=268.6, ups=0.26, wpb=1039.7, bsz=32, num_updates=14910, lr=7.58553e-06, gnorm=9.008, clip=100, loss_scale=64, train_wall=39, gb_free=8.2, wall=57533
2023-05-21 09:56:55 - progress_bar.py[line:272] - INFO: epoch 009:   1091 / 1732 loss=2.437, loss_v1=0, loss_v2=0, nll_loss=1.242, ntokens=1090, nsentences=32, sample_size=1090, sample_size_v1=0, sample_size_v2=0, ppl=2.36, wps=281.4, ups=0.26, wpb=1090, bsz=32, num_updates=14920, lr=7.58348e-06, gnorm=8.77, clip=100, loss_scale=64, train_wall=39, gb_free=8.5, wall=57572
2023-05-21 09:57:33 - progress_bar.py[line:272] - INFO: epoch 009:   1101 / 1732 loss=2.451, loss_v1=0, loss_v2=0, nll_loss=1.258, ntokens=1006.7, nsentences=32, sample_size=1006.7, sample_size_v1=0, sample_size_v2=0, ppl=2.39, wps=262.2, ups=0.26, wpb=1006.7, bsz=32, num_updates=14930, lr=7.58143e-06, gnorm=9.466, clip=100, loss_scale=64, train_wall=38, gb_free=8.2, wall=57610
2023-05-21 09:58:12 - progress_bar.py[line:272] - INFO: epoch 009:   1111 / 1732 loss=2.427, loss_v1=0, loss_v2=0, nll_loss=1.232, ntokens=1054.1, nsentences=32, sample_size=1054.1, sample_size_v1=0, sample_size_v2=0, ppl=2.35, wps=272.4, ups=0.26, wpb=1054.1, bsz=32, num_updates=14940, lr=7.57939e-06, gnorm=8.597, clip=100, loss_scale=64, train_wall=39, gb_free=8.6, wall=57649
2023-05-21 09:58:50 - progress_bar.py[line:272] - INFO: epoch 009:   1121 / 1732 loss=2.446, loss_v1=0, loss_v2=0, nll_loss=1.254, ntokens=962.9, nsentences=32, sample_size=962.9, sample_size_v1=0, sample_size_v2=0, ppl=2.39, wps=249.6, ups=0.26, wpb=962.9, bsz=32, num_updates=14950, lr=7.57734e-06, gnorm=8.938, clip=100, loss_scale=64, train_wall=39, gb_free=8.7, wall=57688
2023-05-21 09:59:29 - progress_bar.py[line:272] - INFO: epoch 009:   1131 / 1732 loss=2.449, loss_v1=0, loss_v2=0, nll_loss=1.257, ntokens=991.2, nsentences=32, sample_size=991.2, sample_size_v1=0, sample_size_v2=0, ppl=2.39, wps=257.8, ups=0.26, wpb=991.2, bsz=32, num_updates=14960, lr=7.57529e-06, gnorm=8.964, clip=100, loss_scale=64, train_wall=38, gb_free=8.8, wall=57726
2023-05-21 10:00:07 - progress_bar.py[line:272] - INFO: epoch 009:   1141 / 1732 loss=2.449, loss_v1=0, loss_v2=0, nll_loss=1.256, ntokens=1017.8, nsentences=32, sample_size=1017.8, sample_size_v1=0, sample_size_v2=0, ppl=2.39, wps=264.8, ups=0.26, wpb=1017.8, bsz=32, num_updates=14970, lr=7.57324e-06, gnorm=8.77, clip=100, loss_scale=64, train_wall=38, gb_free=8.6, wall=57764
2023-05-21 10:00:46 - progress_bar.py[line:272] - INFO: epoch 009:   1151 / 1732 loss=2.436, loss_v1=0, loss_v2=0, nll_loss=1.24, ntokens=1034.7, nsentences=32, sample_size=1034.7, sample_size_v1=0, sample_size_v2=0, ppl=2.36, wps=270, ups=0.26, wpb=1034.7, bsz=32, num_updates=14980, lr=7.5712e-06, gnorm=8.82, clip=100, loss_scale=64, train_wall=38, gb_free=8, wall=57803
2023-05-21 10:01:24 - progress_bar.py[line:272] - INFO: epoch 009:   1161 / 1732 loss=2.404, loss_v1=0, loss_v2=0, nll_loss=1.207, ntokens=995.8, nsentences=32, sample_size=995.8, sample_size_v1=0, sample_size_v2=0, ppl=2.31, wps=259.2, ups=0.26, wpb=995.8, bsz=32, num_updates=14990, lr=7.56915e-06, gnorm=9.809, clip=100, loss_scale=64, train_wall=38, gb_free=8.6, wall=57841
2023-05-21 10:02:03 - progress_bar.py[line:272] - INFO: epoch 009:   1171 / 1732 loss=2.432, loss_v1=0, loss_v2=0, nll_loss=1.237, ntokens=1049.1, nsentences=32, sample_size=1049.1, sample_size_v1=0, sample_size_v2=0, ppl=2.36, wps=270.5, ups=0.26, wpb=1049.1, bsz=32, num_updates=15000, lr=7.5671e-06, gnorm=8.471, clip=100, loss_scale=64, train_wall=39, gb_free=8.4, wall=57880
2023-05-21 10:02:41 - progress_bar.py[line:272] - INFO: epoch 009:   1181 / 1732 loss=2.411, loss_v1=0, loss_v2=0, nll_loss=1.213, ntokens=1019.2, nsentences=32, sample_size=1019.2, sample_size_v1=0, sample_size_v2=0, ppl=2.32, wps=265.8, ups=0.26, wpb=1019.2, bsz=32, num_updates=15010, lr=7.56506e-06, gnorm=8.156, clip=100, loss_scale=64, train_wall=38, gb_free=7.4, wall=57918
2023-05-21 10:03:08 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2023-05-21 10:03:23 - progress_bar.py[line:272] - INFO: epoch 009:   1192 / 1732 loss=2.459, loss_v1=0, loss_v2=0, nll_loss=1.267, ntokens=1010.2, nsentences=32, sample_size=1010.2, sample_size_v1=0, sample_size_v2=0, ppl=2.41, wps=238.7, ups=0.24, wpb=1010.2, bsz=32, num_updates=15020, lr=7.56301e-06, gnorm=8.79, clip=100, loss_scale=64, train_wall=42, gb_free=8.5, wall=57961
2023-05-21 10:04:02 - progress_bar.py[line:272] - INFO: epoch 009:   1202 / 1732 loss=2.397, loss_v1=0, loss_v2=0, nll_loss=1.196, ntokens=1128.3, nsentences=32, sample_size=1128.3, sample_size_v1=0, sample_size_v2=0, ppl=2.29, wps=289.7, ups=0.26, wpb=1128.3, bsz=32, num_updates=15030, lr=7.56096e-06, gnorm=7.869, clip=100, loss_scale=64, train_wall=39, gb_free=8.5, wall=58000
2023-05-21 10:04:41 - progress_bar.py[line:272] - INFO: epoch 009:   1212 / 1732 loss=2.431, loss_v1=0, loss_v2=0, nll_loss=1.237, ntokens=1031.6, nsentences=32, sample_size=1031.6, sample_size_v1=0, sample_size_v2=0, ppl=2.36, wps=267, ups=0.26, wpb=1031.6, bsz=32, num_updates=15040, lr=7.55891e-06, gnorm=7.715, clip=100, loss_scale=64, train_wall=39, gb_free=8, wall=58038
2023-05-21 10:05:20 - progress_bar.py[line:272] - INFO: epoch 009:   1222 / 1732 loss=2.464, loss_v1=0, loss_v2=0, nll_loss=1.27, ntokens=1024, nsentences=32, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=2.41, wps=266.1, ups=0.26, wpb=1024, bsz=32, num_updates=15050, lr=7.55687e-06, gnorm=8.985, clip=100, loss_scale=64, train_wall=38, gb_free=7.9, wall=58077
2023-05-21 10:05:58 - progress_bar.py[line:272] - INFO: epoch 009:   1232 / 1732 loss=2.42, loss_v1=0, loss_v2=0, nll_loss=1.224, ntokens=1035.1, nsentences=32, sample_size=1035.1, sample_size_v1=0, sample_size_v2=0, ppl=2.34, wps=269.3, ups=0.26, wpb=1035.1, bsz=32, num_updates=15060, lr=7.55482e-06, gnorm=7.794, clip=100, loss_scale=64, train_wall=38, gb_free=8.6, wall=58115
2023-05-21 10:06:37 - progress_bar.py[line:272] - INFO: epoch 009:   1242 / 1732 loss=2.375, loss_v1=0, loss_v2=0, nll_loss=1.174, ntokens=1078.3, nsentences=32, sample_size=1078.3, sample_size_v1=0, sample_size_v2=0, ppl=2.26, wps=279.5, ups=0.26, wpb=1078.3, bsz=32, num_updates=15070, lr=7.55277e-06, gnorm=8.523, clip=100, loss_scale=64, train_wall=39, gb_free=8.8, wall=58154
2023-05-21 10:07:15 - progress_bar.py[line:272] - INFO: epoch 009:   1252 / 1732 loss=2.401, loss_v1=0, loss_v2=0, nll_loss=1.203, ntokens=1106.3, nsentences=32, sample_size=1106.3, sample_size_v1=0, sample_size_v2=0, ppl=2.3, wps=284.9, ups=0.26, wpb=1106.3, bsz=32, num_updates=15080, lr=7.55072e-06, gnorm=8.431, clip=100, loss_scale=64, train_wall=39, gb_free=8, wall=58193
2023-05-21 10:07:54 - progress_bar.py[line:272] - INFO: epoch 009:   1262 / 1732 loss=2.433, loss_v1=0, loss_v2=0, nll_loss=1.238, ntokens=1064, nsentences=32, sample_size=1064, sample_size_v1=0, sample_size_v2=0, ppl=2.36, wps=274.8, ups=0.26, wpb=1064, bsz=32, num_updates=15090, lr=7.54868e-06, gnorm=7.902, clip=100, loss_scale=64, train_wall=39, gb_free=8, wall=58231
2023-05-21 10:08:33 - progress_bar.py[line:272] - INFO: epoch 009:   1272 / 1732 loss=2.441, loss_v1=0, loss_v2=0, nll_loss=1.247, ntokens=1010.3, nsentences=32, sample_size=1010.3, sample_size_v1=0, sample_size_v2=0, ppl=2.37, wps=262.3, ups=0.26, wpb=1010.3, bsz=32, num_updates=15100, lr=7.54663e-06, gnorm=8.955, clip=100, loss_scale=64, train_wall=38, gb_free=8, wall=58270
2023-05-21 10:09:12 - progress_bar.py[line:272] - INFO: epoch 009:   1282 / 1732 loss=2.421, loss_v1=0, loss_v2=0, nll_loss=1.222, ntokens=1073.6, nsentences=32, sample_size=1073.6, sample_size_v1=0, sample_size_v2=0, ppl=2.33, wps=275.2, ups=0.26, wpb=1073.6, bsz=32, num_updates=15110, lr=7.54458e-06, gnorm=8.828, clip=100, loss_scale=64, train_wall=39, gb_free=7.4, wall=58309
2023-05-21 10:09:50 - progress_bar.py[line:272] - INFO: epoch 009:   1292 / 1732 loss=2.421, loss_v1=0, loss_v2=0, nll_loss=1.224, ntokens=1095.2, nsentences=32, sample_size=1095.2, sample_size_v1=0, sample_size_v2=0, ppl=2.34, wps=283.1, ups=0.26, wpb=1095.2, bsz=32, num_updates=15120, lr=7.54253e-06, gnorm=8.132, clip=100, loss_scale=64, train_wall=39, gb_free=7.7, wall=58348
2023-05-21 10:10:29 - progress_bar.py[line:272] - INFO: epoch 009:   1302 / 1732 loss=2.425, loss_v1=0, loss_v2=0, nll_loss=1.229, ntokens=1099.5, nsentences=32, sample_size=1099.5, sample_size_v1=0, sample_size_v2=0, ppl=2.34, wps=283.5, ups=0.26, wpb=1099.5, bsz=32, num_updates=15130, lr=7.54049e-06, gnorm=8.233, clip=100, loss_scale=64, train_wall=39, gb_free=7.4, wall=58386
2023-05-21 10:11:08 - progress_bar.py[line:272] - INFO: epoch 009:   1312 / 1732 loss=2.458, loss_v1=0, loss_v2=0, nll_loss=1.266, ntokens=1055.4, nsentences=32, sample_size=1055.4, sample_size_v1=0, sample_size_v2=0, ppl=2.4, wps=268.7, ups=0.25, wpb=1055.4, bsz=32, num_updates=15140, lr=7.53844e-06, gnorm=7.957, clip=100, loss_scale=64, train_wall=39, gb_free=8.6, wall=58426
2023-05-21 10:11:47 - progress_bar.py[line:272] - INFO: epoch 009:   1322 / 1732 loss=2.416, loss_v1=0, loss_v2=0, nll_loss=1.22, ntokens=1120.6, nsentences=32, sample_size=1120.6, sample_size_v1=0, sample_size_v2=0, ppl=2.33, wps=288.6, ups=0.26, wpb=1120.6, bsz=32, num_updates=15150, lr=7.53639e-06, gnorm=9.062, clip=100, loss_scale=64, train_wall=39, gb_free=7.7, wall=58465
2023-05-21 10:12:26 - progress_bar.py[line:272] - INFO: epoch 009:   1332 / 1732 loss=2.391, loss_v1=0, loss_v2=0, nll_loss=1.19, ntokens=1081, nsentences=32, sample_size=1081, sample_size_v1=0, sample_size_v2=0, ppl=2.28, wps=279.5, ups=0.26, wpb=1081, bsz=32, num_updates=15160, lr=7.53434e-06, gnorm=9.629, clip=100, loss_scale=64, train_wall=39, gb_free=8.5, wall=58503
2023-05-21 10:13:05 - progress_bar.py[line:272] - INFO: epoch 009:   1342 / 1732 loss=2.405, loss_v1=0, loss_v2=0, nll_loss=1.207, ntokens=1183.5, nsentences=32, sample_size=1183.5, sample_size_v1=0, sample_size_v2=0, ppl=2.31, wps=304.3, ups=0.26, wpb=1183.5, bsz=32, num_updates=15170, lr=7.5323e-06, gnorm=9.178, clip=100, loss_scale=64, train_wall=39, gb_free=7.4, wall=58542
2023-05-21 10:13:44 - progress_bar.py[line:272] - INFO: epoch 009:   1352 / 1732 loss=2.429, loss_v1=0, loss_v2=0, nll_loss=1.235, ntokens=1129.4, nsentences=32, sample_size=1129.4, sample_size_v1=0, sample_size_v2=0, ppl=2.35, wps=291.7, ups=0.26, wpb=1129.4, bsz=32, num_updates=15180, lr=7.53025e-06, gnorm=8.758, clip=100, loss_scale=64, train_wall=39, gb_free=8.2, wall=58581
2023-05-21 10:14:23 - progress_bar.py[line:272] - INFO: epoch 009:   1362 / 1732 loss=2.391, loss_v1=0, loss_v2=0, nll_loss=1.189, ntokens=1092.5, nsentences=32, sample_size=1092.5, sample_size_v1=0, sample_size_v2=0, ppl=2.28, wps=279.2, ups=0.26, wpb=1092.5, bsz=32, num_updates=15190, lr=7.5282e-06, gnorm=8.033, clip=100, loss_scale=64, train_wall=39, gb_free=7.5, wall=58620
2023-05-21 10:15:01 - progress_bar.py[line:272] - INFO: epoch 009:   1372 / 1732 loss=2.435, loss_v1=0, loss_v2=0, nll_loss=1.24, ntokens=1098.3, nsentences=32, sample_size=1098.3, sample_size_v1=0, sample_size_v2=0, ppl=2.36, wps=284.5, ups=0.26, wpb=1098.3, bsz=32, num_updates=15200, lr=7.52616e-06, gnorm=8.236, clip=100, loss_scale=64, train_wall=39, gb_free=8.8, wall=58659
2023-05-21 10:15:40 - progress_bar.py[line:272] - INFO: epoch 009:   1382 / 1732 loss=2.442, loss_v1=0, loss_v2=0, nll_loss=1.247, ntokens=1160, nsentences=32, sample_size=1160, sample_size_v1=0, sample_size_v2=0, ppl=2.37, wps=300.4, ups=0.26, wpb=1160, bsz=32, num_updates=15210, lr=7.52411e-06, gnorm=9.178, clip=100, loss_scale=64, train_wall=39, gb_free=8, wall=58697
2023-05-21 10:16:18 - progress_bar.py[line:272] - INFO: epoch 009:   1392 / 1732 loss=2.42, loss_v1=0, loss_v2=0, nll_loss=1.224, ntokens=1049.4, nsentences=32, sample_size=1049.4, sample_size_v1=0, sample_size_v2=0, ppl=2.34, wps=273.8, ups=0.26, wpb=1049.4, bsz=32, num_updates=15220, lr=7.52206e-06, gnorm=9.994, clip=100, loss_scale=64, train_wall=38, gb_free=8.3, wall=58735
2023-05-21 10:16:57 - progress_bar.py[line:272] - INFO: epoch 009:   1402 / 1732 loss=2.4, loss_v1=0, loss_v2=0, nll_loss=1.202, ntokens=1133.7, nsentences=32, sample_size=1133.7, sample_size_v1=0, sample_size_v2=0, ppl=2.3, wps=291, ups=0.26, wpb=1133.7, bsz=32, num_updates=15230, lr=7.52001e-06, gnorm=8.66, clip=100, loss_scale=64, train_wall=39, gb_free=7.2, wall=58774
2023-05-21 10:17:36 - progress_bar.py[line:272] - INFO: epoch 009:   1412 / 1732 loss=2.434, loss_v1=0, loss_v2=0, nll_loss=1.239, ntokens=1246.7, nsentences=32, sample_size=1246.7, sample_size_v1=0, sample_size_v2=0, ppl=2.36, wps=319.7, ups=0.26, wpb=1246.7, bsz=32, num_updates=15240, lr=7.51797e-06, gnorm=7.941, clip=100, loss_scale=64, train_wall=39, gb_free=7.9, wall=58813
2023-05-21 10:18:16 - progress_bar.py[line:272] - INFO: epoch 009:   1422 / 1732 loss=2.424, loss_v1=0, loss_v2=0, nll_loss=1.228, ntokens=1259.2, nsentences=32, sample_size=1259.2, sample_size_v1=0, sample_size_v2=0, ppl=2.34, wps=319.1, ups=0.25, wpb=1259.2, bsz=32, num_updates=15250, lr=7.51592e-06, gnorm=7.86, clip=100, loss_scale=64, train_wall=39, gb_free=8, wall=58853
2023-05-21 10:18:55 - progress_bar.py[line:272] - INFO: epoch 009:   1432 / 1732 loss=2.394, loss_v1=0, loss_v2=0, nll_loss=1.194, ntokens=1215.6, nsentences=32, sample_size=1215.6, sample_size_v1=0, sample_size_v2=0, ppl=2.29, wps=311.8, ups=0.26, wpb=1215.6, bsz=32, num_updates=15260, lr=7.51387e-06, gnorm=7.439, clip=100, loss_scale=64, train_wall=39, gb_free=8.3, wall=58892
2023-05-21 10:19:33 - progress_bar.py[line:272] - INFO: epoch 009:   1442 / 1732 loss=2.424, loss_v1=0, loss_v2=0, nll_loss=1.229, ntokens=1136.6, nsentences=32, sample_size=1136.6, sample_size_v1=0, sample_size_v2=0, ppl=2.34, wps=294.1, ups=0.26, wpb=1136.6, bsz=32, num_updates=15270, lr=7.51182e-06, gnorm=8.477, clip=100, loss_scale=64, train_wall=39, gb_free=8.5, wall=58931
2023-05-21 10:20:12 - progress_bar.py[line:272] - INFO: epoch 009:   1452 / 1732 loss=2.433, loss_v1=0, loss_v2=0, nll_loss=1.236, ntokens=1140.1, nsentences=32, sample_size=1140.1, sample_size_v1=0, sample_size_v2=0, ppl=2.36, wps=294.6, ups=0.26, wpb=1140.1, bsz=32, num_updates=15280, lr=7.50978e-06, gnorm=7.598, clip=100, loss_scale=64, train_wall=39, gb_free=9, wall=58969
2023-05-21 10:20:51 - progress_bar.py[line:272] - INFO: epoch 009:   1462 / 1732 loss=2.397, loss_v1=0, loss_v2=0, nll_loss=1.198, ntokens=1170.3, nsentences=32, sample_size=1170.3, sample_size_v1=0, sample_size_v2=0, ppl=2.29, wps=300, ups=0.26, wpb=1170.3, bsz=32, num_updates=15290, lr=7.50773e-06, gnorm=7.129, clip=100, loss_scale=64, train_wall=39, gb_free=7.7, wall=59008
2023-05-21 10:21:30 - progress_bar.py[line:272] - INFO: epoch 009:   1472 / 1732 loss=2.404, loss_v1=0, loss_v2=0, nll_loss=1.206, ntokens=1139, nsentences=32, sample_size=1139, sample_size_v1=0, sample_size_v2=0, ppl=2.31, wps=293.7, ups=0.26, wpb=1139, bsz=32, num_updates=15300, lr=7.50568e-06, gnorm=8.349, clip=100, loss_scale=64, train_wall=39, gb_free=8.9, wall=59047
2023-05-21 10:22:09 - progress_bar.py[line:272] - INFO: epoch 009:   1482 / 1732 loss=2.451, loss_v1=0, loss_v2=0, nll_loss=1.259, ntokens=1051.3, nsentences=32, sample_size=1051.3, sample_size_v1=0, sample_size_v2=0, ppl=2.39, wps=271.9, ups=0.26, wpb=1051.3, bsz=32, num_updates=15310, lr=7.50363e-06, gnorm=8.381, clip=100, loss_scale=64, train_wall=39, gb_free=7.7, wall=59086
2023-05-21 10:22:47 - progress_bar.py[line:272] - INFO: epoch 009:   1492 / 1732 loss=2.411, loss_v1=0, loss_v2=0, nll_loss=1.21, ntokens=1143, nsentences=32, sample_size=1143, sample_size_v1=0, sample_size_v2=0, ppl=2.31, wps=294.3, ups=0.26, wpb=1143, bsz=32, num_updates=15320, lr=7.50159e-06, gnorm=7.603, clip=100, loss_scale=64, train_wall=39, gb_free=8.8, wall=59125
2023-05-21 10:23:26 - progress_bar.py[line:272] - INFO: epoch 009:   1502 / 1732 loss=2.374, loss_v1=0, loss_v2=0, nll_loss=1.171, ntokens=1131.9, nsentences=32, sample_size=1131.9, sample_size_v1=0, sample_size_v2=0, ppl=2.25, wps=292.3, ups=0.26, wpb=1131.9, bsz=32, num_updates=15330, lr=7.49954e-06, gnorm=7.731, clip=100, loss_scale=64, train_wall=39, gb_free=7.4, wall=59163
2023-05-21 10:24:05 - progress_bar.py[line:272] - INFO: epoch 009:   1512 / 1732 loss=2.412, loss_v1=0, loss_v2=0, nll_loss=1.219, ntokens=1058.6, nsentences=32, sample_size=1058.6, sample_size_v1=0, sample_size_v2=0, ppl=2.33, wps=275.5, ups=0.26, wpb=1058.6, bsz=32, num_updates=15340, lr=7.49749e-06, gnorm=8.863, clip=100, loss_scale=64, train_wall=38, gb_free=7.8, wall=59202
2023-05-21 10:24:43 - progress_bar.py[line:272] - INFO: epoch 009:   1522 / 1732 loss=2.448, loss_v1=0, loss_v2=0, nll_loss=1.257, ntokens=1011, nsentences=32, sample_size=1011, sample_size_v1=0, sample_size_v2=0, ppl=2.39, wps=262.3, ups=0.26, wpb=1011, bsz=32, num_updates=15350, lr=7.49544e-06, gnorm=9.015, clip=100, loss_scale=64, train_wall=38, gb_free=9, wall=59240
2023-05-21 10:25:22 - progress_bar.py[line:272] - INFO: epoch 009:   1532 / 1732 loss=2.441, loss_v1=0, loss_v2=0, nll_loss=1.243, ntokens=1075.4, nsentences=32, sample_size=1075.4, sample_size_v1=0, sample_size_v2=0, ppl=2.37, wps=276.7, ups=0.26, wpb=1075.4, bsz=32, num_updates=15360, lr=7.4934e-06, gnorm=8.676, clip=100, loss_scale=64, train_wall=39, gb_free=7.9, wall=59279
2023-05-21 10:26:01 - progress_bar.py[line:272] - INFO: epoch 009:   1542 / 1732 loss=2.403, loss_v1=0, loss_v2=0, nll_loss=1.203, ntokens=1113.4, nsentences=32, sample_size=1113.4, sample_size_v1=0, sample_size_v2=0, ppl=2.3, wps=287.1, ups=0.26, wpb=1113.4, bsz=32, num_updates=15370, lr=7.49135e-06, gnorm=8.053, clip=100, loss_scale=64, train_wall=39, gb_free=8.2, wall=59318
2023-05-21 10:26:39 - progress_bar.py[line:272] - INFO: epoch 009:   1552 / 1732 loss=2.403, loss_v1=0, loss_v2=0, nll_loss=1.206, ntokens=1059, nsentences=32, sample_size=1059, sample_size_v1=0, sample_size_v2=0, ppl=2.31, wps=275.4, ups=0.26, wpb=1059, bsz=32, num_updates=15380, lr=7.4893e-06, gnorm=8.901, clip=100, loss_scale=64, train_wall=38, gb_free=8.5, wall=59356
2023-05-21 10:27:18 - progress_bar.py[line:272] - INFO: epoch 009:   1562 / 1732 loss=2.427, loss_v1=0, loss_v2=0, nll_loss=1.233, ntokens=1107.4, nsentences=32, sample_size=1107.4, sample_size_v1=0, sample_size_v2=0, ppl=2.35, wps=285.3, ups=0.26, wpb=1107.4, bsz=32, num_updates=15390, lr=7.48726e-06, gnorm=8.62, clip=100, loss_scale=64, train_wall=39, gb_free=8.3, wall=59395
2023-05-21 10:27:57 - progress_bar.py[line:272] - INFO: epoch 009:   1572 / 1732 loss=2.444, loss_v1=0, loss_v2=0, nll_loss=1.249, ntokens=1068.7, nsentences=32, sample_size=1068.7, sample_size_v1=0, sample_size_v2=0, ppl=2.38, wps=275.3, ups=0.26, wpb=1068.7, bsz=32, num_updates=15400, lr=7.48521e-06, gnorm=9.706, clip=100, loss_scale=64, train_wall=39, gb_free=8.7, wall=59434
2023-05-21 10:28:36 - progress_bar.py[line:272] - INFO: epoch 009:   1582 / 1732 loss=2.464, loss_v1=0, loss_v2=0, nll_loss=1.272, ntokens=1012.7, nsentences=32, sample_size=1012.7, sample_size_v1=0, sample_size_v2=0, ppl=2.41, wps=260.7, ups=0.26, wpb=1012.7, bsz=32, num_updates=15410, lr=7.48316e-06, gnorm=9.702, clip=100, loss_scale=64, train_wall=39, gb_free=7.7, wall=59473
2023-05-21 10:29:14 - progress_bar.py[line:272] - INFO: epoch 009:   1592 / 1732 loss=2.406, loss_v1=0, loss_v2=0, nll_loss=1.207, ntokens=1072.6, nsentences=32, sample_size=1072.6, sample_size_v1=0, sample_size_v2=0, ppl=2.31, wps=276.8, ups=0.26, wpb=1072.6, bsz=32, num_updates=15420, lr=7.48111e-06, gnorm=8.663, clip=100, loss_scale=64, train_wall=39, gb_free=8.8, wall=59512
2023-05-21 10:29:53 - progress_bar.py[line:272] - INFO: epoch 009:   1602 / 1732 loss=2.39, loss_v1=0, loss_v2=0, nll_loss=1.192, ntokens=1101.7, nsentences=32, sample_size=1101.7, sample_size_v1=0, sample_size_v2=0, ppl=2.29, wps=284.4, ups=0.26, wpb=1101.7, bsz=32, num_updates=15430, lr=7.47907e-06, gnorm=8.266, clip=100, loss_scale=64, train_wall=39, gb_free=7.5, wall=59550
2023-05-21 10:30:32 - progress_bar.py[line:272] - INFO: epoch 009:   1612 / 1732 loss=2.392, loss_v1=0, loss_v2=0, nll_loss=1.192, ntokens=1156, nsentences=32, sample_size=1156, sample_size_v1=0, sample_size_v2=0, ppl=2.28, wps=299.2, ups=0.26, wpb=1156, bsz=32, num_updates=15440, lr=7.47702e-06, gnorm=8.08, clip=100, loss_scale=64, train_wall=39, gb_free=8.7, wall=59589
2023-05-21 10:30:43 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2023-05-21 10:31:14 - progress_bar.py[line:272] - INFO: epoch 009:   1623 / 1732 loss=2.394, loss_v1=0, loss_v2=0, nll_loss=1.195, ntokens=1092.4, nsentences=32, sample_size=1092.4, sample_size_v1=0, sample_size_v2=0, ppl=2.29, wps=256.6, ups=0.23, wpb=1092.4, bsz=32, num_updates=15450, lr=7.47497e-06, gnorm=8.012, clip=100, loss_scale=32, train_wall=43, gb_free=8.1, wall=59632
2023-05-21 10:31:53 - progress_bar.py[line:272] - INFO: epoch 009:   1633 / 1732 loss=2.397, loss_v1=0, loss_v2=0, nll_loss=1.199, ntokens=1178.3, nsentences=32, sample_size=1178.3, sample_size_v1=0, sample_size_v2=0, ppl=2.3, wps=304.1, ups=0.26, wpb=1178.3, bsz=32, num_updates=15460, lr=7.47292e-06, gnorm=8.347, clip=100, loss_scale=32, train_wall=39, gb_free=8.8, wall=59670
2023-05-21 10:32:32 - progress_bar.py[line:272] - INFO: epoch 009:   1643 / 1732 loss=2.374, loss_v1=0, loss_v2=0, nll_loss=1.169, ntokens=1238.2, nsentences=32, sample_size=1238.2, sample_size_v1=0, sample_size_v2=0, ppl=2.25, wps=318.6, ups=0.26, wpb=1238.2, bsz=32, num_updates=15470, lr=7.47088e-06, gnorm=8.181, clip=100, loss_scale=32, train_wall=39, gb_free=8.4, wall=59709
2023-05-21 10:33:10 - progress_bar.py[line:272] - INFO: epoch 009:   1653 / 1732 loss=2.426, loss_v1=0, loss_v2=0, nll_loss=1.229, ntokens=993.8, nsentences=32, sample_size=993.8, sample_size_v1=0, sample_size_v2=0, ppl=2.34, wps=259.1, ups=0.26, wpb=993.8, bsz=32, num_updates=15480, lr=7.46883e-06, gnorm=9.505, clip=100, loss_scale=32, train_wall=38, gb_free=8.6, wall=59748
2023-05-21 10:33:49 - progress_bar.py[line:272] - INFO: epoch 009:   1663 / 1732 loss=2.426, loss_v1=0, loss_v2=0, nll_loss=1.231, ntokens=1051.4, nsentences=32, sample_size=1051.4, sample_size_v1=0, sample_size_v2=0, ppl=2.35, wps=272.9, ups=0.26, wpb=1051.4, bsz=32, num_updates=15490, lr=7.46678e-06, gnorm=8.177, clip=100, loss_scale=32, train_wall=38, gb_free=8.2, wall=59786
2023-05-21 10:34:27 - progress_bar.py[line:272] - INFO: epoch 009:   1673 / 1732 loss=2.395, loss_v1=0, loss_v2=0, nll_loss=1.194, ntokens=1033, nsentences=32, sample_size=1033, sample_size_v1=0, sample_size_v2=0, ppl=2.29, wps=269.2, ups=0.26, wpb=1033, bsz=32, num_updates=15500, lr=7.46473e-06, gnorm=8.25, clip=100, loss_scale=32, train_wall=38, gb_free=7.9, wall=59824
2023-05-21 10:35:06 - progress_bar.py[line:272] - INFO: epoch 009:   1683 / 1732 loss=2.37, loss_v1=0, loss_v2=0, nll_loss=1.167, ntokens=1168.8, nsentences=32, sample_size=1168.8, sample_size_v1=0, sample_size_v2=0, ppl=2.25, wps=298.1, ups=0.26, wpb=1168.8, bsz=32, num_updates=15510, lr=7.46269e-06, gnorm=7.796, clip=100, loss_scale=32, train_wall=39, gb_free=8.5, wall=59864
2023-05-21 10:35:46 - progress_bar.py[line:272] - INFO: epoch 009:   1693 / 1732 loss=2.39, loss_v1=0, loss_v2=0, nll_loss=1.193, ntokens=1251.1, nsentences=32, sample_size=1251.1, sample_size_v1=0, sample_size_v2=0, ppl=2.29, wps=316.9, ups=0.25, wpb=1251.1, bsz=32, num_updates=15520, lr=7.46064e-06, gnorm=7.011, clip=100, loss_scale=32, train_wall=39, gb_free=8, wall=59903
2023-05-21 10:36:25 - progress_bar.py[line:272] - INFO: epoch 009:   1703 / 1732 loss=2.405, loss_v1=0, loss_v2=0, nll_loss=1.206, ntokens=1247.1, nsentences=32, sample_size=1247.1, sample_size_v1=0, sample_size_v2=0, ppl=2.31, wps=317, ups=0.25, wpb=1247.1, bsz=32, num_updates=15530, lr=7.45859e-06, gnorm=7.821, clip=100, loss_scale=32, train_wall=39, gb_free=8.4, wall=59943
2023-05-21 10:37:04 - progress_bar.py[line:272] - INFO: epoch 009:   1713 / 1732 loss=2.402, loss_v1=0, loss_v2=0, nll_loss=1.203, ntokens=1176.1, nsentences=32, sample_size=1176.1, sample_size_v1=0, sample_size_v2=0, ppl=2.3, wps=301.5, ups=0.26, wpb=1176.1, bsz=32, num_updates=15540, lr=7.45654e-06, gnorm=7.632, clip=100, loss_scale=32, train_wall=39, gb_free=6.2, wall=59982
2023-05-21 10:37:43 - progress_bar.py[line:272] - INFO: epoch 009:   1723 / 1732 loss=2.41, loss_v1=0, loss_v2=0, nll_loss=1.212, ntokens=1147.2, nsentences=32, sample_size=1147.2, sample_size_v1=0, sample_size_v2=0, ppl=2.32, wps=294.3, ups=0.26, wpb=1147.2, bsz=32, num_updates=15550, lr=7.4545e-06, gnorm=7.411, clip=100, loss_scale=32, train_wall=39, gb_free=7.4, wall=60020
2023-05-21 10:38:15 - train.py[line:332] - INFO: end of epoch 9 (average epoch stats below)
2023-05-21 10:38:15 - progress_bar.py[line:282] - INFO: epoch 009 | loss 2.423 | loss_v1 0 | loss_v2 0 | nll_loss 1.227 | ntokens 1051.66 | nsentences 31.986 | sample_size 1051.66 | sample_size_v1 0 | sample_size_v2 0 | ppl 2.34 | wps 272.7 | ups 0.26 | wpb 1051.7 | bsz 32 | num_updates 15559 | lr 7.45265e-06 | gnorm 8.415 | clip 100 | loss_scale 32 | train_wall 6657 | gb_free 8.9 | wall 60053
2023-05-21 10:38:15 - trainer.py[line:639] - INFO: loading train data for epoch 10
local datafile ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 0 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 0 finished initializing row_count and line_idx-to-offset mapping
file ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 0 row count 55400 total row count 55400
slice_id 0 seek offset 0
2023-05-21 10:38:17 - trainer.py[line:703] - INFO: begin training epoch 10
2023-05-21 10:38:17 - train.py[line:305] - INFO: Start iterating over samples
2023-05-21 10:38:21 - progress_bar.py[line:272] - INFO: epoch 010:      1 / 1732 loss=2.46, loss_v1=0, loss_v2=0, nll_loss=1.267, ntokens=1067.2, nsentences=29.6, sample_size=1067.2, sample_size_v1=0, sample_size_v2=0, ppl=2.41, wps=280.8, ups=0.26, wpb=1067.2, bsz=29.6, num_updates=15560, lr=7.45245e-06, gnorm=9.429, clip=100, loss_scale=32, train_wall=36, gb_free=8.5, wall=60059
2023-05-21 10:39:00 - progress_bar.py[line:272] - INFO: epoch 010:     11 / 1732 loss=2.335, loss_v1=0, loss_v2=0, nll_loss=1.126, ntokens=1109.8, nsentences=32, sample_size=1109.8, sample_size_v1=0, sample_size_v2=0, ppl=2.18, wps=284.1, ups=0.26, wpb=1109.8, bsz=32, num_updates=15570, lr=7.4504e-06, gnorm=8.477, clip=100, loss_scale=32, train_wall=39, gb_free=8.6, wall=60098
2023-05-21 10:39:39 - progress_bar.py[line:272] - INFO: epoch 010:     21 / 1732 loss=2.288, loss_v1=0, loss_v2=0, nll_loss=1.076, ntokens=1106.8, nsentences=32, sample_size=1106.8, sample_size_v1=0, sample_size_v2=0, ppl=2.11, wps=286.1, ups=0.26, wpb=1106.8, bsz=32, num_updates=15580, lr=7.44835e-06, gnorm=8.668, clip=100, loss_scale=32, train_wall=39, gb_free=8.4, wall=60136
2023-05-21 10:40:18 - progress_bar.py[line:272] - INFO: epoch 010:     31 / 1732 loss=2.328, loss_v1=0, loss_v2=0, nll_loss=1.118, ntokens=958.4, nsentences=32, sample_size=958.4, sample_size_v1=0, sample_size_v2=0, ppl=2.17, wps=247.7, ups=0.26, wpb=958.4, bsz=32, num_updates=15590, lr=7.44631e-06, gnorm=10.094, clip=100, loss_scale=32, train_wall=39, gb_free=8.3, wall=60175
2023-05-21 10:40:57 - progress_bar.py[line:272] - INFO: epoch 010:     41 / 1732 loss=2.189, loss_v1=0, loss_v2=0, nll_loss=0.968, ntokens=1207.2, nsentences=32, sample_size=1207.2, sample_size_v1=0, sample_size_v2=0, ppl=1.96, wps=307.4, ups=0.25, wpb=1207.2, bsz=32, num_updates=15600, lr=7.44426e-06, gnorm=6.449, clip=100, loss_scale=32, train_wall=39, gb_free=8, wall=60214
2023-05-21 10:41:36 - progress_bar.py[line:272] - INFO: epoch 010:     51 / 1732 loss=2.274, loss_v1=0, loss_v2=0, nll_loss=1.062, ntokens=1028.6, nsentences=32, sample_size=1028.6, sample_size_v1=0, sample_size_v2=0, ppl=2.09, wps=266.5, ups=0.26, wpb=1028.6, bsz=32, num_updates=15610, lr=7.44221e-06, gnorm=11.276, clip=100, loss_scale=32, train_wall=39, gb_free=8.3, wall=60253
2023-05-21 10:42:14 - progress_bar.py[line:272] - INFO: epoch 010:     61 / 1732 loss=2.059, loss_v1=0, loss_v2=0, nll_loss=0.817, ntokens=1123.9, nsentences=32, sample_size=1123.9, sample_size_v1=0, sample_size_v2=0, ppl=1.76, wps=289.9, ups=0.26, wpb=1123.9, bsz=32, num_updates=15620, lr=7.44017e-06, gnorm=7.171, clip=100, loss_scale=32, train_wall=39, gb_free=7.1, wall=60292
2023-05-21 10:42:54 - progress_bar.py[line:272] - INFO: epoch 010:     71 / 1732 loss=2.146, loss_v1=0, loss_v2=0, nll_loss=0.922, ntokens=1363.4, nsentences=32, sample_size=1363.4, sample_size_v1=0, sample_size_v2=0, ppl=1.89, wps=340.8, ups=0.25, wpb=1363.4, bsz=32, num_updates=15630, lr=7.43812e-06, gnorm=6.301, clip=100, loss_scale=32, train_wall=40, gb_free=7, wall=60332
2023-05-21 10:43:34 - progress_bar.py[line:272] - INFO: epoch 010:     81 / 1732 loss=2.181, loss_v1=0, loss_v2=0, nll_loss=0.951, ntokens=1263, nsentences=32, sample_size=1263, sample_size_v1=0, sample_size_v2=0, ppl=1.93, wps=317.2, ups=0.25, wpb=1263, bsz=32, num_updates=15640, lr=7.43607e-06, gnorm=6.004, clip=100, loss_scale=32, train_wall=40, gb_free=8.5, wall=60371
2023-05-21 10:44:13 - progress_bar.py[line:272] - INFO: epoch 010:     91 / 1732 loss=2.26, loss_v1=0, loss_v2=0, nll_loss=1.049, ntokens=1062.5, nsentences=32, sample_size=1062.5, sample_size_v1=0, sample_size_v2=0, ppl=2.07, wps=270.8, ups=0.25, wpb=1062.5, bsz=32, num_updates=15650, lr=7.43402e-06, gnorm=7.447, clip=100, loss_scale=32, train_wall=39, gb_free=8.6, wall=60411
2023-05-21 10:44:52 - progress_bar.py[line:272] - INFO: epoch 010:    101 / 1732 loss=2.27, loss_v1=0, loss_v2=0, nll_loss=1.055, ntokens=1023.5, nsentences=32, sample_size=1023.5, sample_size_v1=0, sample_size_v2=0, ppl=2.08, wps=265, ups=0.26, wpb=1023.5, bsz=32, num_updates=15660, lr=7.43198e-06, gnorm=8.624, clip=100, loss_scale=32, train_wall=39, gb_free=8.1, wall=60449
2023-05-21 10:45:31 - progress_bar.py[line:272] - INFO: epoch 010:    111 / 1732 loss=2.42, loss_v1=0, loss_v2=0, nll_loss=1.226, ntokens=1034.7, nsentences=32, sample_size=1034.7, sample_size_v1=0, sample_size_v2=0, ppl=2.34, wps=268.5, ups=0.26, wpb=1034.7, bsz=32, num_updates=15670, lr=7.42993e-06, gnorm=7.681, clip=100, loss_scale=32, train_wall=38, gb_free=8.4, wall=60488
2023-05-21 10:46:10 - progress_bar.py[line:272] - INFO: epoch 010:    121 / 1732 loss=2.382, loss_v1=0, loss_v2=0, nll_loss=1.182, ntokens=1114.4, nsentences=32, sample_size=1114.4, sample_size_v1=0, sample_size_v2=0, ppl=2.27, wps=284.7, ups=0.26, wpb=1114.4, bsz=32, num_updates=15680, lr=7.42788e-06, gnorm=7.577, clip=100, loss_scale=32, train_wall=39, gb_free=8.1, wall=60527
2023-05-21 10:46:49 - progress_bar.py[line:272] - INFO: epoch 010:    131 / 1732 loss=2.36, loss_v1=0, loss_v2=0, nll_loss=1.154, ntokens=1176.2, nsentences=32, sample_size=1176.2, sample_size_v1=0, sample_size_v2=0, ppl=2.23, wps=298.1, ups=0.25, wpb=1176.2, bsz=32, num_updates=15690, lr=7.42583e-06, gnorm=6.914, clip=100, loss_scale=32, train_wall=39, gb_free=8.3, wall=60566
2023-05-21 10:47:29 - progress_bar.py[line:272] - INFO: epoch 010:    141 / 1732 loss=2.313, loss_v1=0, loss_v2=0, nll_loss=1.099, ntokens=1252.9, nsentences=32, sample_size=1252.9, sample_size_v1=0, sample_size_v2=0, ppl=2.14, wps=317.5, ups=0.25, wpb=1252.9, bsz=32, num_updates=15700, lr=7.42379e-06, gnorm=6.238, clip=100, loss_scale=32, train_wall=39, gb_free=8.3, wall=60606
2023-05-21 10:48:08 - progress_bar.py[line:272] - INFO: epoch 010:    151 / 1732 loss=2.306, loss_v1=0, loss_v2=0, nll_loss=1.1, ntokens=1168.3, nsentences=32, sample_size=1168.3, sample_size_v1=0, sample_size_v2=0, ppl=2.14, wps=294.7, ups=0.25, wpb=1168.3, bsz=32, num_updates=15710, lr=7.42174e-06, gnorm=6.469, clip=100, loss_scale=32, train_wall=40, gb_free=6.8, wall=60646
2023-05-21 10:48:48 - progress_bar.py[line:272] - INFO: epoch 010:    161 / 1732 loss=2.332, loss_v1=0, loss_v2=0, nll_loss=1.125, ntokens=1106.1, nsentences=32, sample_size=1106.1, sample_size_v1=0, sample_size_v2=0, ppl=2.18, wps=281.2, ups=0.25, wpb=1106.1, bsz=32, num_updates=15720, lr=7.41969e-06, gnorm=8.025, clip=100, loss_scale=32, train_wall=39, gb_free=8.4, wall=60685
2023-05-21 10:49:26 - progress_bar.py[line:272] - INFO: epoch 010:    171 / 1732 loss=2.332, loss_v1=0, loss_v2=0, nll_loss=1.122, ntokens=969.4, nsentences=32, sample_size=969.4, sample_size_v1=0, sample_size_v2=0, ppl=2.18, wps=251.5, ups=0.26, wpb=969.4, bsz=32, num_updates=15730, lr=7.41764e-06, gnorm=7.72, clip=100, loss_scale=32, train_wall=38, gb_free=8.5, wall=60723
2023-05-21 10:50:05 - progress_bar.py[line:272] - INFO: epoch 010:    181 / 1732 loss=2.291, loss_v1=0, loss_v2=0, nll_loss=1.078, ntokens=1122.2, nsentences=32, sample_size=1122.2, sample_size_v1=0, sample_size_v2=0, ppl=2.11, wps=286.6, ups=0.26, wpb=1122.2, bsz=32, num_updates=15740, lr=7.4156e-06, gnorm=7.845, clip=100, loss_scale=32, train_wall=39, gb_free=8.2, wall=60763
2023-05-21 10:50:45 - progress_bar.py[line:272] - INFO: epoch 010:    191 / 1732 loss=2.3, loss_v1=0, loss_v2=0, nll_loss=1.09, ntokens=1130.1, nsentences=32, sample_size=1130.1, sample_size_v1=0, sample_size_v2=0, ppl=2.13, wps=288.4, ups=0.26, wpb=1130.1, bsz=32, num_updates=15750, lr=7.41355e-06, gnorm=6.785, clip=100, loss_scale=32, train_wall=39, gb_free=8, wall=60802
2023-05-21 10:51:23 - progress_bar.py[line:272] - INFO: epoch 010:    201 / 1732 loss=2.379, loss_v1=0, loss_v2=0, nll_loss=1.179, ntokens=1092.1, nsentences=32, sample_size=1092.1, sample_size_v1=0, sample_size_v2=0, ppl=2.26, wps=281.6, ups=0.26, wpb=1092.1, bsz=32, num_updates=15760, lr=7.4115e-06, gnorm=7.405, clip=100, loss_scale=32, train_wall=39, gb_free=8.5, wall=60841
2023-05-21 10:52:02 - progress_bar.py[line:272] - INFO: epoch 010:    211 / 1732 loss=2.452, loss_v1=0, loss_v2=0, nll_loss=1.26, ntokens=1010.6, nsentences=32, sample_size=1010.6, sample_size_v1=0, sample_size_v2=0, ppl=2.4, wps=263.7, ups=0.26, wpb=1010.6, bsz=32, num_updates=15770, lr=7.40945e-06, gnorm=8.197, clip=100, loss_scale=32, train_wall=38, gb_free=8.1, wall=60879
2023-05-21 10:52:40 - progress_bar.py[line:272] - INFO: epoch 010:    221 / 1732 loss=2.439, loss_v1=0, loss_v2=0, nll_loss=1.244, ntokens=1140.8, nsentences=32, sample_size=1140.8, sample_size_v1=0, sample_size_v2=0, ppl=2.37, wps=297.9, ups=0.26, wpb=1140.8, bsz=32, num_updates=15780, lr=7.40741e-06, gnorm=8.043, clip=100, loss_scale=32, train_wall=38, gb_free=7.7, wall=60917
2023-05-21 10:53:18 - progress_bar.py[line:272] - INFO: epoch 010:    231 / 1732 loss=2.465, loss_v1=0, loss_v2=0, nll_loss=1.274, ntokens=1093.8, nsentences=32, sample_size=1093.8, sample_size_v1=0, sample_size_v2=0, ppl=2.42, wps=284.9, ups=0.26, wpb=1093.8, bsz=32, num_updates=15790, lr=7.40536e-06, gnorm=8.273, clip=100, loss_scale=32, train_wall=38, gb_free=8.8, wall=60956
2023-05-21 10:53:57 - progress_bar.py[line:272] - INFO: epoch 010:    241 / 1732 loss=2.481, loss_v1=0, loss_v2=0, nll_loss=1.289, ntokens=1114.7, nsentences=32, sample_size=1114.7, sample_size_v1=0, sample_size_v2=0, ppl=2.44, wps=288.4, ups=0.26, wpb=1114.7, bsz=32, num_updates=15800, lr=7.40331e-06, gnorm=8.169, clip=100, loss_scale=32, train_wall=39, gb_free=8.7, wall=60994
2023-05-21 10:54:36 - progress_bar.py[line:272] - INFO: epoch 010:    251 / 1732 loss=2.453, loss_v1=0, loss_v2=0, nll_loss=1.258, ntokens=1172.1, nsentences=32, sample_size=1172.1, sample_size_v1=0, sample_size_v2=0, ppl=2.39, wps=301.2, ups=0.26, wpb=1172.1, bsz=32, num_updates=15810, lr=7.40127e-06, gnorm=7.569, clip=100, loss_scale=32, train_wall=39, gb_free=8.8, wall=61033
2023-05-21 10:55:14 - progress_bar.py[line:272] - INFO: epoch 010:    261 / 1732 loss=2.481, loss_v1=0, loss_v2=0, nll_loss=1.293, ntokens=1139.9, nsentences=32, sample_size=1139.9, sample_size_v1=0, sample_size_v2=0, ppl=2.45, wps=297.4, ups=0.26, wpb=1139.9, bsz=32, num_updates=15820, lr=7.39922e-06, gnorm=8.181, clip=100, loss_scale=32, train_wall=38, gb_free=8.3, wall=61072
2023-05-21 10:55:53 - progress_bar.py[line:272] - INFO: epoch 010:    271 / 1732 loss=2.44, loss_v1=0, loss_v2=0, nll_loss=1.244, ntokens=1145.3, nsentences=32, sample_size=1145.3, sample_size_v1=0, sample_size_v2=0, ppl=2.37, wps=298, ups=0.26, wpb=1145.3, bsz=32, num_updates=15830, lr=7.39717e-06, gnorm=7.503, clip=100, loss_scale=32, train_wall=38, gb_free=8.3, wall=61110
2023-05-21 10:56:31 - progress_bar.py[line:272] - INFO: epoch 010:    281 / 1732 loss=2.469, loss_v1=0, loss_v2=0, nll_loss=1.279, ntokens=1149.7, nsentences=32, sample_size=1149.7, sample_size_v1=0, sample_size_v2=0, ppl=2.43, wps=299.4, ups=0.26, wpb=1149.7, bsz=32, num_updates=15840, lr=7.39512e-06, gnorm=7.639, clip=100, loss_scale=32, train_wall=38, gb_free=9.1, wall=61148
2023-05-21 10:57:10 - progress_bar.py[line:272] - INFO: epoch 010:    291 / 1732 loss=2.433, loss_v1=0, loss_v2=0, nll_loss=1.239, ntokens=1130.5, nsentences=32, sample_size=1130.5, sample_size_v1=0, sample_size_v2=0, ppl=2.36, wps=294.1, ups=0.26, wpb=1130.5, bsz=32, num_updates=15850, lr=7.39308e-06, gnorm=7.513, clip=100, loss_scale=32, train_wall=38, gb_free=8.5, wall=61187
2023-05-21 10:57:48 - progress_bar.py[line:272] - INFO: epoch 010:    301 / 1732 loss=2.457, loss_v1=0, loss_v2=0, nll_loss=1.265, ntokens=1109.1, nsentences=32, sample_size=1109.1, sample_size_v1=0, sample_size_v2=0, ppl=2.4, wps=288, ups=0.26, wpb=1109.1, bsz=32, num_updates=15860, lr=7.39103e-06, gnorm=7.652, clip=100, loss_scale=32, train_wall=38, gb_free=8.8, wall=61225
2023-05-21 10:58:27 - progress_bar.py[line:272] - INFO: epoch 010:    311 / 1732 loss=2.436, loss_v1=0, loss_v2=0, nll_loss=1.24, ntokens=1067.3, nsentences=32, sample_size=1067.3, sample_size_v1=0, sample_size_v2=0, ppl=2.36, wps=277.4, ups=0.26, wpb=1067.3, bsz=32, num_updates=15870, lr=7.38898e-06, gnorm=8.762, clip=100, loss_scale=32, train_wall=38, gb_free=8.7, wall=61264
2023-05-21 10:59:05 - progress_bar.py[line:272] - INFO: epoch 010:    321 / 1732 loss=2.478, loss_v1=0, loss_v2=0, nll_loss=1.289, ntokens=1001.7, nsentences=32, sample_size=1001.7, sample_size_v1=0, sample_size_v2=0, ppl=2.44, wps=263.5, ups=0.26, wpb=1001.7, bsz=32, num_updates=15880, lr=7.38693e-06, gnorm=9.438, clip=100, loss_scale=32, train_wall=38, gb_free=9.1, wall=61302
2023-05-21 10:59:43 - progress_bar.py[line:272] - INFO: epoch 010:    331 / 1732 loss=2.48, loss_v1=0, loss_v2=0, nll_loss=1.29, ntokens=1019.4, nsentences=32, sample_size=1019.4, sample_size_v1=0, sample_size_v2=0, ppl=2.44, wps=267.4, ups=0.26, wpb=1019.4, bsz=32, num_updates=15890, lr=7.38489e-06, gnorm=8.481, clip=100, loss_scale=32, train_wall=38, gb_free=8.7, wall=61340
2023-05-21 11:00:21 - progress_bar.py[line:272] - INFO: epoch 010:    341 / 1732 loss=2.436, loss_v1=0, loss_v2=0, nll_loss=1.241, ntokens=952.2, nsentences=32, sample_size=952.2, sample_size_v1=0, sample_size_v2=0, ppl=2.36, wps=250, ups=0.26, wpb=952.2, bsz=32, num_updates=15900, lr=7.38284e-06, gnorm=8.842, clip=100, loss_scale=32, train_wall=38, gb_free=9, wall=61378
2023-05-21 11:00:59 - progress_bar.py[line:272] - INFO: epoch 010:    351 / 1732 loss=2.465, loss_v1=0, loss_v2=0, nll_loss=1.276, ntokens=941.5, nsentences=32, sample_size=941.5, sample_size_v1=0, sample_size_v2=0, ppl=2.42, wps=247.8, ups=0.26, wpb=941.5, bsz=32, num_updates=15910, lr=7.38079e-06, gnorm=9.615, clip=100, loss_scale=32, train_wall=38, gb_free=8.7, wall=61416
2023-05-21 11:01:37 - progress_bar.py[line:272] - INFO: epoch 010:    361 / 1732 loss=2.485, loss_v1=0, loss_v2=0, nll_loss=1.299, ntokens=925.7, nsentences=32, sample_size=925.7, sample_size_v1=0, sample_size_v2=0, ppl=2.46, wps=243.8, ups=0.26, wpb=925.7, bsz=32, num_updates=15920, lr=7.37874e-06, gnorm=8.973, clip=100, loss_scale=32, train_wall=38, gb_free=8.6, wall=61454
2023-05-21 11:02:15 - progress_bar.py[line:272] - INFO: epoch 010:    371 / 1732 loss=2.495, loss_v1=0, loss_v2=0, nll_loss=1.304, ntokens=989.1, nsentences=32, sample_size=989.1, sample_size_v1=0, sample_size_v2=0, ppl=2.47, wps=258.9, ups=0.26, wpb=989.1, bsz=32, num_updates=15930, lr=7.3767e-06, gnorm=9.122, clip=100, loss_scale=32, train_wall=38, gb_free=8.2, wall=61492
2023-05-21 11:02:53 - progress_bar.py[line:272] - INFO: epoch 010:    381 / 1732 loss=2.482, loss_v1=0, loss_v2=0, nll_loss=1.29, ntokens=1071.8, nsentences=32, sample_size=1071.8, sample_size_v1=0, sample_size_v2=0, ppl=2.45, wps=282, ups=0.26, wpb=1071.8, bsz=32, num_updates=15940, lr=7.37465e-06, gnorm=8.257, clip=100, loss_scale=32, train_wall=38, gb_free=8.6, wall=61530
2023-05-21 11:03:31 - progress_bar.py[line:272] - INFO: epoch 010:    391 / 1732 loss=2.457, loss_v1=0, loss_v2=0, nll_loss=1.266, ntokens=986, nsentences=32, sample_size=986, sample_size_v1=0, sample_size_v2=0, ppl=2.4, wps=259.1, ups=0.26, wpb=986, bsz=32, num_updates=15950, lr=7.3726e-06, gnorm=9.007, clip=100, loss_scale=32, train_wall=38, gb_free=8.8, wall=61568
2023-05-21 11:04:09 - progress_bar.py[line:272] - INFO: epoch 010:    401 / 1732 loss=2.457, loss_v1=0, loss_v2=0, nll_loss=1.265, ntokens=999.1, nsentences=32, sample_size=999.1, sample_size_v1=0, sample_size_v2=0, ppl=2.4, wps=262.3, ups=0.26, wpb=999.1, bsz=32, num_updates=15960, lr=7.37055e-06, gnorm=9.135, clip=100, loss_scale=64, train_wall=38, gb_free=8.5, wall=61606
2023-05-21 11:04:47 - progress_bar.py[line:272] - INFO: epoch 010:    411 / 1732 loss=2.444, loss_v1=0, loss_v2=0, nll_loss=1.251, ntokens=1079.4, nsentences=32, sample_size=1079.4, sample_size_v1=0, sample_size_v2=0, ppl=2.38, wps=282.3, ups=0.26, wpb=1079.4, bsz=32, num_updates=15970, lr=7.36851e-06, gnorm=8.138, clip=100, loss_scale=64, train_wall=38, gb_free=8.7, wall=61645
2023-05-21 11:05:26 - progress_bar.py[line:272] - INFO: epoch 010:    421 / 1732 loss=2.428, loss_v1=0, loss_v2=0, nll_loss=1.234, ntokens=1019, nsentences=32, sample_size=1019, sample_size_v1=0, sample_size_v2=0, ppl=2.35, wps=267.4, ups=0.26, wpb=1019, bsz=32, num_updates=15980, lr=7.36646e-06, gnorm=9.666, clip=100, loss_scale=64, train_wall=38, gb_free=8.5, wall=61683
2023-05-21 11:06:04 - progress_bar.py[line:272] - INFO: epoch 010:    431 / 1732 loss=2.443, loss_v1=0, loss_v2=0, nll_loss=1.249, ntokens=1019.7, nsentences=32, sample_size=1019.7, sample_size_v1=0, sample_size_v2=0, ppl=2.38, wps=268.1, ups=0.26, wpb=1019.7, bsz=32, num_updates=15990, lr=7.36441e-06, gnorm=8.89, clip=100, loss_scale=64, train_wall=38, gb_free=8.4, wall=61721
2023-05-21 11:06:41 - progress_bar.py[line:272] - INFO: epoch 010:    441 / 1732 loss=2.464, loss_v1=0, loss_v2=0, nll_loss=1.273, ntokens=990.4, nsentences=32, sample_size=990.4, sample_size_v1=0, sample_size_v2=0, ppl=2.42, wps=261.9, ups=0.26, wpb=990.4, bsz=32, num_updates=16000, lr=7.36237e-06, gnorm=8.247, clip=100, loss_scale=64, train_wall=38, gb_free=8.7, wall=61759
2023-05-21 11:07:20 - progress_bar.py[line:272] - INFO: epoch 010:    451 / 1732 loss=2.469, loss_v1=0, loss_v2=0, nll_loss=1.277, ntokens=920.2, nsentences=32, sample_size=920.2, sample_size_v1=0, sample_size_v2=0, ppl=2.42, wps=240.9, ups=0.26, wpb=920.2, bsz=32, num_updates=16010, lr=7.36032e-06, gnorm=10.211, clip=100, loss_scale=64, train_wall=38, gb_free=8, wall=61797
2023-05-21 11:07:58 - progress_bar.py[line:272] - INFO: epoch 010:    461 / 1732 loss=2.475, loss_v1=0, loss_v2=0, nll_loss=1.285, ntokens=1038.5, nsentences=32, sample_size=1038.5, sample_size_v1=0, sample_size_v2=0, ppl=2.44, wps=273.7, ups=0.26, wpb=1038.5, bsz=32, num_updates=16020, lr=7.35827e-06, gnorm=8.918, clip=100, loss_scale=64, train_wall=38, gb_free=8.3, wall=61835
2023-05-21 11:08:36 - progress_bar.py[line:272] - INFO: epoch 010:    471 / 1732 loss=2.47, loss_v1=0, loss_v2=0, nll_loss=1.279, ntokens=1039.4, nsentences=32, sample_size=1039.4, sample_size_v1=0, sample_size_v2=0, ppl=2.43, wps=272.3, ups=0.26, wpb=1039.4, bsz=32, num_updates=16030, lr=7.35622e-06, gnorm=8.1, clip=100, loss_scale=64, train_wall=38, gb_free=8.9, wall=61873
2023-05-21 11:09:14 - progress_bar.py[line:272] - INFO: epoch 010:    481 / 1732 loss=2.469, loss_v1=0, loss_v2=0, nll_loss=1.278, ntokens=1025, nsentences=32, sample_size=1025, sample_size_v1=0, sample_size_v2=0, ppl=2.43, wps=269, ups=0.26, wpb=1025, bsz=32, num_updates=16040, lr=7.35418e-06, gnorm=8.353, clip=100, loss_scale=64, train_wall=38, gb_free=9.2, wall=61911
2023-05-21 11:09:52 - progress_bar.py[line:272] - INFO: epoch 010:    491 / 1732 loss=2.455, loss_v1=0, loss_v2=0, nll_loss=1.262, ntokens=939.5, nsentences=32, sample_size=939.5, sample_size_v1=0, sample_size_v2=0, ppl=2.4, wps=248.1, ups=0.26, wpb=939.5, bsz=32, num_updates=16050, lr=7.35213e-06, gnorm=10.393, clip=100, loss_scale=64, train_wall=38, gb_free=7.9, wall=61949
2023-05-21 11:10:30 - progress_bar.py[line:272] - INFO: epoch 010:    501 / 1732 loss=2.447, loss_v1=0, loss_v2=0, nll_loss=1.254, ntokens=938, nsentences=32, sample_size=938, sample_size_v1=0, sample_size_v2=0, ppl=2.38, wps=247.9, ups=0.26, wpb=938, bsz=32, num_updates=16060, lr=7.35008e-06, gnorm=8.899, clip=100, loss_scale=64, train_wall=38, gb_free=8.9, wall=61987
2023-05-21 11:11:08 - progress_bar.py[line:272] - INFO: epoch 010:    511 / 1732 loss=2.487, loss_v1=0, loss_v2=0, nll_loss=1.299, ntokens=1040.7, nsentences=32, sample_size=1040.7, sample_size_v1=0, sample_size_v2=0, ppl=2.46, wps=273.6, ups=0.26, wpb=1040.7, bsz=32, num_updates=16070, lr=7.34803e-06, gnorm=8.226, clip=100, loss_scale=64, train_wall=38, gb_free=9.3, wall=62025
2023-05-21 11:11:46 - progress_bar.py[line:272] - INFO: epoch 010:    521 / 1732 loss=2.433, loss_v1=0, loss_v2=0, nll_loss=1.239, ntokens=1020.1, nsentences=32, sample_size=1020.1, sample_size_v1=0, sample_size_v2=0, ppl=2.36, wps=268.6, ups=0.26, wpb=1020.1, bsz=32, num_updates=16080, lr=7.34599e-06, gnorm=9.446, clip=100, loss_scale=64, train_wall=38, gb_free=8.6, wall=62063
2023-05-21 11:12:23 - progress_bar.py[line:272] - INFO: epoch 010:    531 / 1732 loss=2.472, loss_v1=0, loss_v2=0, nll_loss=1.281, ntokens=931.7, nsentences=32, sample_size=931.7, sample_size_v1=0, sample_size_v2=0, ppl=2.43, wps=246.2, ups=0.26, wpb=931.7, bsz=32, num_updates=16090, lr=7.34394e-06, gnorm=10.604, clip=100, loss_scale=64, train_wall=38, gb_free=8.7, wall=62101
2023-05-21 11:13:01 - progress_bar.py[line:272] - INFO: epoch 010:    541 / 1732 loss=2.458, loss_v1=0, loss_v2=0, nll_loss=1.267, ntokens=994.8, nsentences=32, sample_size=994.8, sample_size_v1=0, sample_size_v2=0, ppl=2.41, wps=263.2, ups=0.26, wpb=994.8, bsz=32, num_updates=16100, lr=7.34189e-06, gnorm=9.414, clip=100, loss_scale=64, train_wall=38, gb_free=9.1, wall=62138
2023-05-21 11:13:39 - progress_bar.py[line:272] - INFO: epoch 010:    551 / 1732 loss=2.482, loss_v1=0, loss_v2=0, nll_loss=1.294, ntokens=1021.9, nsentences=32, sample_size=1021.9, sample_size_v1=0, sample_size_v2=0, ppl=2.45, wps=268, ups=0.26, wpb=1021.9, bsz=32, num_updates=16110, lr=7.33984e-06, gnorm=8.571, clip=100, loss_scale=64, train_wall=38, gb_free=8.5, wall=62177
2023-05-21 11:14:17 - progress_bar.py[line:272] - INFO: epoch 010:    561 / 1732 loss=2.478, loss_v1=0, loss_v2=0, nll_loss=1.289, ntokens=1030.9, nsentences=32, sample_size=1030.9, sample_size_v1=0, sample_size_v2=0, ppl=2.44, wps=270.9, ups=0.26, wpb=1030.9, bsz=32, num_updates=16120, lr=7.3378e-06, gnorm=9.43, clip=100, loss_scale=64, train_wall=38, gb_free=8.5, wall=62215
2023-05-21 11:14:55 - progress_bar.py[line:272] - INFO: epoch 010:    571 / 1732 loss=2.502, loss_v1=0, loss_v2=0, nll_loss=1.314, ntokens=990.9, nsentences=32, sample_size=990.9, sample_size_v1=0, sample_size_v2=0, ppl=2.49, wps=260.7, ups=0.26, wpb=990.9, bsz=32, num_updates=16130, lr=7.33575e-06, gnorm=10.46, clip=100, loss_scale=64, train_wall=38, gb_free=9.2, wall=62253
2023-05-21 11:15:34 - progress_bar.py[line:272] - INFO: epoch 010:    581 / 1732 loss=2.463, loss_v1=0, loss_v2=0, nll_loss=1.272, ntokens=1021.6, nsentences=32, sample_size=1021.6, sample_size_v1=0, sample_size_v2=0, ppl=2.41, wps=267.4, ups=0.26, wpb=1021.6, bsz=32, num_updates=16140, lr=7.3337e-06, gnorm=9.661, clip=100, loss_scale=64, train_wall=38, gb_free=7.8, wall=62291
2023-05-21 11:16:12 - progress_bar.py[line:272] - INFO: epoch 010:    591 / 1732 loss=2.455, loss_v1=0, loss_v2=0, nll_loss=1.263, ntokens=934.4, nsentences=32, sample_size=934.4, sample_size_v1=0, sample_size_v2=0, ppl=2.4, wps=245.6, ups=0.26, wpb=934.4, bsz=32, num_updates=16150, lr=7.33165e-06, gnorm=9.96, clip=100, loss_scale=64, train_wall=38, gb_free=7.8, wall=62329
2023-05-21 11:16:50 - progress_bar.py[line:272] - INFO: epoch 010:    601 / 1732 loss=2.436, loss_v1=0, loss_v2=0, nll_loss=1.244, ntokens=941.2, nsentences=32, sample_size=941.2, sample_size_v1=0, sample_size_v2=0, ppl=2.37, wps=247.3, ups=0.26, wpb=941.2, bsz=32, num_updates=16160, lr=7.32961e-06, gnorm=9.958, clip=100, loss_scale=64, train_wall=38, gb_free=8.8, wall=62367
2023-05-21 11:17:28 - progress_bar.py[line:272] - INFO: epoch 010:    611 / 1732 loss=2.455, loss_v1=0, loss_v2=0, nll_loss=1.264, ntokens=911.9, nsentences=32, sample_size=911.9, sample_size_v1=0, sample_size_v2=0, ppl=2.4, wps=241.3, ups=0.26, wpb=911.9, bsz=32, num_updates=16170, lr=7.32756e-06, gnorm=10.051, clip=100, loss_scale=64, train_wall=38, gb_free=9.1, wall=62405
2023-05-21 11:18:05 - progress_bar.py[line:272] - INFO: epoch 010:    621 / 1732 loss=2.485, loss_v1=0, loss_v2=0, nll_loss=1.296, ntokens=845.9, nsentences=32, sample_size=845.9, sample_size_v1=0, sample_size_v2=0, ppl=2.46, wps=224.6, ups=0.27, wpb=845.9, bsz=32, num_updates=16180, lr=7.32551e-06, gnorm=10.831, clip=100, loss_scale=64, train_wall=38, gb_free=9, wall=62442
2023-05-21 11:18:43 - progress_bar.py[line:272] - INFO: epoch 010:    631 / 1732 loss=2.451, loss_v1=0, loss_v2=0, nll_loss=1.258, ntokens=949.2, nsentences=32, sample_size=949.2, sample_size_v1=0, sample_size_v2=0, ppl=2.39, wps=249.6, ups=0.26, wpb=949.2, bsz=32, num_updates=16190, lr=7.32346e-06, gnorm=11.054, clip=100, loss_scale=64, train_wall=38, gb_free=8.4, wall=62480
2023-05-21 11:19:21 - progress_bar.py[line:272] - INFO: epoch 010:    641 / 1732 loss=2.488, loss_v1=0, loss_v2=0, nll_loss=1.301, ntokens=915.8, nsentences=32, sample_size=915.8, sample_size_v1=0, sample_size_v2=0, ppl=2.46, wps=242, ups=0.26, wpb=915.8, bsz=32, num_updates=16200, lr=7.32142e-06, gnorm=10.331, clip=100, loss_scale=64, train_wall=38, gb_free=9.2, wall=62518
2023-05-21 11:19:59 - progress_bar.py[line:272] - INFO: epoch 010:    651 / 1732 loss=2.472, loss_v1=0, loss_v2=0, nll_loss=1.282, ntokens=990.2, nsentences=32, sample_size=990.2, sample_size_v1=0, sample_size_v2=0, ppl=2.43, wps=261.8, ups=0.26, wpb=990.2, bsz=32, num_updates=16210, lr=7.31937e-06, gnorm=10.107, clip=100, loss_scale=64, train_wall=38, gb_free=8.9, wall=62556
2023-05-21 11:20:36 - progress_bar.py[line:272] - INFO: epoch 010:    661 / 1732 loss=2.486, loss_v1=0, loss_v2=0, nll_loss=1.298, ntokens=863.9, nsentences=32, sample_size=863.9, sample_size_v1=0, sample_size_v2=0, ppl=2.46, wps=231.4, ups=0.27, wpb=863.9, bsz=32, num_updates=16220, lr=7.31732e-06, gnorm=11.65, clip=100, loss_scale=64, train_wall=37, gb_free=8.7, wall=62593
2023-05-21 11:21:14 - progress_bar.py[line:272] - INFO: epoch 010:    671 / 1732 loss=2.478, loss_v1=0, loss_v2=0, nll_loss=1.29, ntokens=943.7, nsentences=32, sample_size=943.7, sample_size_v1=0, sample_size_v2=0, ppl=2.45, wps=249, ups=0.26, wpb=943.7, bsz=32, num_updates=16230, lr=7.31528e-06, gnorm=11.579, clip=100, loss_scale=64, train_wall=38, gb_free=8.7, wall=62631
2023-05-21 11:21:52 - progress_bar.py[line:272] - INFO: epoch 010:    681 / 1732 loss=2.462, loss_v1=0, loss_v2=0, nll_loss=1.27, ntokens=972.8, nsentences=32, sample_size=972.8, sample_size_v1=0, sample_size_v2=0, ppl=2.41, wps=255.3, ups=0.26, wpb=972.8, bsz=32, num_updates=16240, lr=7.31323e-06, gnorm=9.535, clip=100, loss_scale=64, train_wall=38, gb_free=8.2, wall=62669
2023-05-21 11:22:30 - progress_bar.py[line:272] - INFO: epoch 010:    691 / 1732 loss=2.485, loss_v1=0, loss_v2=0, nll_loss=1.295, ntokens=949, nsentences=32, sample_size=949, sample_size_v1=0, sample_size_v2=0, ppl=2.45, wps=249, ups=0.26, wpb=949, bsz=32, num_updates=16250, lr=7.31118e-06, gnorm=10.974, clip=100, loss_scale=64, train_wall=38, gb_free=8.9, wall=62708
2023-05-21 11:23:09 - progress_bar.py[line:272] - INFO: epoch 010:    701 / 1732 loss=2.44, loss_v1=0, loss_v2=0, nll_loss=1.246, ntokens=988.7, nsentences=32, sample_size=988.7, sample_size_v1=0, sample_size_v2=0, ppl=2.37, wps=258.8, ups=0.26, wpb=988.7, bsz=32, num_updates=16260, lr=7.30913e-06, gnorm=9.856, clip=100, loss_scale=64, train_wall=38, gb_free=9, wall=62746
2023-05-21 11:23:47 - progress_bar.py[line:272] - INFO: epoch 010:    711 / 1732 loss=2.481, loss_v1=0, loss_v2=0, nll_loss=1.29, ntokens=913.9, nsentences=32, sample_size=913.9, sample_size_v1=0, sample_size_v2=0, ppl=2.45, wps=240.1, ups=0.26, wpb=913.9, bsz=32, num_updates=16270, lr=7.30709e-06, gnorm=10.182, clip=100, loss_scale=64, train_wall=38, gb_free=9, wall=62784
2023-05-21 11:24:24 - progress_bar.py[line:272] - INFO: epoch 010:    721 / 1732 loss=2.439, loss_v1=0, loss_v2=0, nll_loss=1.244, ntokens=854.5, nsentences=32, sample_size=854.5, sample_size_v1=0, sample_size_v2=0, ppl=2.37, wps=226.8, ups=0.27, wpb=854.5, bsz=32, num_updates=16280, lr=7.30504e-06, gnorm=9.818, clip=100, loss_scale=64, train_wall=38, gb_free=8.6, wall=62822
2023-05-21 11:25:02 - progress_bar.py[line:272] - INFO: epoch 010:    731 / 1732 loss=2.445, loss_v1=0, loss_v2=0, nll_loss=1.255, ntokens=932.8, nsentences=32, sample_size=932.8, sample_size_v1=0, sample_size_v2=0, ppl=2.39, wps=246.7, ups=0.26, wpb=932.8, bsz=32, num_updates=16290, lr=7.30299e-06, gnorm=9.099, clip=100, loss_scale=64, train_wall=38, gb_free=8.7, wall=62859
2023-05-21 11:25:40 - progress_bar.py[line:272] - INFO: epoch 010:    741 / 1732 loss=2.437, loss_v1=0, loss_v2=0, nll_loss=1.244, ntokens=1003.7, nsentences=32, sample_size=1003.7, sample_size_v1=0, sample_size_v2=0, ppl=2.37, wps=262.4, ups=0.26, wpb=1003.7, bsz=32, num_updates=16300, lr=7.30094e-06, gnorm=9.749, clip=100, loss_scale=64, train_wall=38, gb_free=8.6, wall=62898
2023-05-21 11:26:18 - progress_bar.py[line:272] - INFO: epoch 010:    751 / 1732 loss=2.454, loss_v1=0, loss_v2=0, nll_loss=1.261, ntokens=975.7, nsentences=32, sample_size=975.7, sample_size_v1=0, sample_size_v2=0, ppl=2.4, wps=257, ups=0.26, wpb=975.7, bsz=32, num_updates=16310, lr=7.2989e-06, gnorm=9.481, clip=100, loss_scale=64, train_wall=38, gb_free=8.2, wall=62936
2023-05-21 11:26:56 - progress_bar.py[line:272] - INFO: epoch 010:    761 / 1732 loss=2.436, loss_v1=0, loss_v2=0, nll_loss=1.242, ntokens=974.2, nsentences=32, sample_size=974.2, sample_size_v1=0, sample_size_v2=0, ppl=2.37, wps=258, ups=0.26, wpb=974.2, bsz=32, num_updates=16320, lr=7.29685e-06, gnorm=9.65, clip=100, loss_scale=64, train_wall=38, gb_free=8.7, wall=62973
2023-05-21 11:27:34 - progress_bar.py[line:272] - INFO: epoch 010:    771 / 1732 loss=2.448, loss_v1=0, loss_v2=0, nll_loss=1.257, ntokens=924.9, nsentences=32, sample_size=924.9, sample_size_v1=0, sample_size_v2=0, ppl=2.39, wps=245.4, ups=0.27, wpb=924.9, bsz=32, num_updates=16330, lr=7.2948e-06, gnorm=10.304, clip=100, loss_scale=64, train_wall=38, gb_free=8.9, wall=63011
2023-05-21 11:28:12 - progress_bar.py[line:272] - INFO: epoch 010:    781 / 1732 loss=2.46, loss_v1=0, loss_v2=0, nll_loss=1.27, ntokens=1053.4, nsentences=32, sample_size=1053.4, sample_size_v1=0, sample_size_v2=0, ppl=2.41, wps=275.6, ups=0.26, wpb=1053.4, bsz=32, num_updates=16340, lr=7.29275e-06, gnorm=9.577, clip=100, loss_scale=64, train_wall=38, gb_free=8.9, wall=63049
2023-05-21 11:28:50 - progress_bar.py[line:272] - INFO: epoch 010:    791 / 1732 loss=2.456, loss_v1=0, loss_v2=0, nll_loss=1.264, ntokens=1022, nsentences=32, sample_size=1022, sample_size_v1=0, sample_size_v2=0, ppl=2.4, wps=268.4, ups=0.26, wpb=1022, bsz=32, num_updates=16350, lr=7.29071e-06, gnorm=10.152, clip=100, loss_scale=64, train_wall=38, gb_free=8.6, wall=63087
2023-05-21 11:29:28 - progress_bar.py[line:272] - INFO: epoch 010:    801 / 1732 loss=2.45, loss_v1=0, loss_v2=0, nll_loss=1.257, ntokens=984.3, nsentences=32, sample_size=984.3, sample_size_v1=0, sample_size_v2=0, ppl=2.39, wps=260.5, ups=0.26, wpb=984.3, bsz=32, num_updates=16360, lr=7.28866e-06, gnorm=10.088, clip=100, loss_scale=64, train_wall=38, gb_free=8.3, wall=63125
2023-05-21 11:30:06 - progress_bar.py[line:272] - INFO: epoch 010:    811 / 1732 loss=2.451, loss_v1=0, loss_v2=0, nll_loss=1.257, ntokens=931.4, nsentences=32, sample_size=931.4, sample_size_v1=0, sample_size_v2=0, ppl=2.39, wps=245.8, ups=0.26, wpb=931.4, bsz=32, num_updates=16370, lr=7.28661e-06, gnorm=11.582, clip=100, loss_scale=64, train_wall=38, gb_free=8.7, wall=63163
2023-05-21 11:30:44 - progress_bar.py[line:272] - INFO: epoch 010:    821 / 1732 loss=2.463, loss_v1=0, loss_v2=0, nll_loss=1.271, ntokens=915.1, nsentences=32, sample_size=915.1, sample_size_v1=0, sample_size_v2=0, ppl=2.41, wps=241.4, ups=0.26, wpb=915.1, bsz=32, num_updates=16380, lr=7.28456e-06, gnorm=10.391, clip=100, loss_scale=64, train_wall=38, gb_free=7.2, wall=63201
2023-05-21 11:31:21 - progress_bar.py[line:272] - INFO: epoch 010:    831 / 1732 loss=2.449, loss_v1=0, loss_v2=0, nll_loss=1.255, ntokens=914.9, nsentences=32, sample_size=914.9, sample_size_v1=0, sample_size_v2=0, ppl=2.39, wps=242.2, ups=0.26, wpb=914.9, bsz=32, num_updates=16390, lr=7.28252e-06, gnorm=10.6, clip=100, loss_scale=64, train_wall=38, gb_free=8.8, wall=63239
2023-05-21 11:31:59 - progress_bar.py[line:272] - INFO: epoch 010:    841 / 1732 loss=2.448, loss_v1=0, loss_v2=0, nll_loss=1.256, ntokens=933, nsentences=32, sample_size=933, sample_size_v1=0, sample_size_v2=0, ppl=2.39, wps=246.5, ups=0.26, wpb=933, bsz=32, num_updates=16400, lr=7.28047e-06, gnorm=10.049, clip=100, loss_scale=64, train_wall=38, gb_free=9, wall=63277
2023-05-21 11:32:37 - progress_bar.py[line:272] - INFO: epoch 010:    851 / 1732 loss=2.456, loss_v1=0, loss_v2=0, nll_loss=1.263, ntokens=1005.2, nsentences=32, sample_size=1005.2, sample_size_v1=0, sample_size_v2=0, ppl=2.4, wps=264.5, ups=0.26, wpb=1005.2, bsz=32, num_updates=16410, lr=7.27842e-06, gnorm=9.476, clip=100, loss_scale=64, train_wall=38, gb_free=8.6, wall=63315
2023-05-21 11:33:15 - progress_bar.py[line:272] - INFO: epoch 010:    861 / 1732 loss=2.433, loss_v1=0, loss_v2=0, nll_loss=1.237, ntokens=942.6, nsentences=32, sample_size=942.6, sample_size_v1=0, sample_size_v2=0, ppl=2.36, wps=249.7, ups=0.26, wpb=942.6, bsz=32, num_updates=16420, lr=7.27638e-06, gnorm=9.379, clip=100, loss_scale=64, train_wall=38, gb_free=8.5, wall=63352
2023-05-21 11:33:53 - progress_bar.py[line:272] - INFO: epoch 010:    871 / 1732 loss=2.455, loss_v1=0, loss_v2=0, nll_loss=1.265, ntokens=962.7, nsentences=32, sample_size=962.7, sample_size_v1=0, sample_size_v2=0, ppl=2.4, wps=253.3, ups=0.26, wpb=962.7, bsz=32, num_updates=16430, lr=7.27433e-06, gnorm=9.901, clip=100, loss_scale=64, train_wall=38, gb_free=9, wall=63390
2023-05-21 11:34:31 - progress_bar.py[line:272] - INFO: epoch 010:    881 / 1732 loss=2.406, loss_v1=0, loss_v2=0, nll_loss=1.208, ntokens=988.4, nsentences=32, sample_size=988.4, sample_size_v1=0, sample_size_v2=0, ppl=2.31, wps=258.6, ups=0.26, wpb=988.4, bsz=32, num_updates=16440, lr=7.27228e-06, gnorm=8.997, clip=100, loss_scale=64, train_wall=38, gb_free=9.2, wall=63429
2023-05-21 11:35:10 - progress_bar.py[line:272] - INFO: epoch 010:    891 / 1732 loss=2.392, loss_v1=0, loss_v2=0, nll_loss=1.193, ntokens=1001.4, nsentences=32, sample_size=1001.4, sample_size_v1=0, sample_size_v2=0, ppl=2.29, wps=261.5, ups=0.26, wpb=1001.4, bsz=32, num_updates=16450, lr=7.27023e-06, gnorm=9.068, clip=100, loss_scale=64, train_wall=38, gb_free=8.6, wall=63467
2023-05-21 11:35:48 - progress_bar.py[line:272] - INFO: epoch 010:    901 / 1732 loss=2.393, loss_v1=0, loss_v2=0, nll_loss=1.192, ntokens=1032.4, nsentences=32, sample_size=1032.4, sample_size_v1=0, sample_size_v2=0, ppl=2.29, wps=270.3, ups=0.26, wpb=1032.4, bsz=32, num_updates=16460, lr=7.26819e-06, gnorm=9.668, clip=100, loss_scale=64, train_wall=38, gb_free=9.2, wall=63505
2023-05-21 11:36:26 - progress_bar.py[line:272] - INFO: epoch 010:    911 / 1732 loss=2.448, loss_v1=0, loss_v2=0, nll_loss=1.255, ntokens=960.1, nsentences=32, sample_size=960.1, sample_size_v1=0, sample_size_v2=0, ppl=2.39, wps=253.2, ups=0.26, wpb=960.1, bsz=32, num_updates=16470, lr=7.26614e-06, gnorm=9.276, clip=100, loss_scale=128, train_wall=38, gb_free=9.2, wall=63543
2023-05-21 11:36:33 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2023-05-21 11:37:08 - progress_bar.py[line:272] - INFO: epoch 010:    922 / 1732 loss=2.43, loss_v1=0, loss_v2=0, nll_loss=1.236, ntokens=1011.8, nsentences=32, sample_size=1011.8, sample_size_v1=0, sample_size_v2=0, ppl=2.36, wps=241, ups=0.24, wpb=1011.8, bsz=32, num_updates=16480, lr=7.26409e-06, gnorm=9.556, clip=100, loss_scale=64, train_wall=42, gb_free=8.5, wall=63585
2023-05-21 11:37:46 - progress_bar.py[line:272] - INFO: epoch 010:    932 / 1732 loss=2.421, loss_v1=0, loss_v2=0, nll_loss=1.223, ntokens=1036.8, nsentences=32, sample_size=1036.8, sample_size_v1=0, sample_size_v2=0, ppl=2.33, wps=269.2, ups=0.26, wpb=1036.8, bsz=32, num_updates=16490, lr=7.26204e-06, gnorm=9.7, clip=100, loss_scale=64, train_wall=38, gb_free=8.1, wall=63623
2023-05-21 11:38:25 - progress_bar.py[line:272] - INFO: epoch 010:    942 / 1732 loss=2.425, loss_v1=0, loss_v2=0, nll_loss=1.23, ntokens=1063.3, nsentences=32, sample_size=1063.3, sample_size_v1=0, sample_size_v2=0, ppl=2.35, wps=275.5, ups=0.26, wpb=1063.3, bsz=32, num_updates=16500, lr=7.26e-06, gnorm=8.275, clip=100, loss_scale=64, train_wall=39, gb_free=8.8, wall=63662
2023-05-21 11:39:03 - progress_bar.py[line:272] - INFO: epoch 010:    952 / 1732 loss=2.429, loss_v1=0, loss_v2=0, nll_loss=1.235, ntokens=1011.4, nsentences=32, sample_size=1011.4, sample_size_v1=0, sample_size_v2=0, ppl=2.35, wps=262.1, ups=0.26, wpb=1011.4, bsz=32, num_updates=16510, lr=7.25795e-06, gnorm=9.457, clip=100, loss_scale=64, train_wall=39, gb_free=8.8, wall=63701
2023-05-21 11:39:42 - progress_bar.py[line:272] - INFO: epoch 010:    962 / 1732 loss=2.429, loss_v1=0, loss_v2=0, nll_loss=1.235, ntokens=1071.4, nsentences=32, sample_size=1071.4, sample_size_v1=0, sample_size_v2=0, ppl=2.35, wps=277.5, ups=0.26, wpb=1071.4, bsz=32, num_updates=16520, lr=7.2559e-06, gnorm=8.924, clip=100, loss_scale=64, train_wall=39, gb_free=8.7, wall=63739
2023-05-21 11:40:21 - progress_bar.py[line:272] - INFO: epoch 010:    972 / 1732 loss=2.457, loss_v1=0, loss_v2=0, nll_loss=1.266, ntokens=1038.3, nsentences=32, sample_size=1038.3, sample_size_v1=0, sample_size_v2=0, ppl=2.4, wps=269.3, ups=0.26, wpb=1038.3, bsz=32, num_updates=16530, lr=7.25385e-06, gnorm=9.589, clip=100, loss_scale=64, train_wall=39, gb_free=8.2, wall=63778
2023-05-21 11:40:59 - progress_bar.py[line:272] - INFO: epoch 010:    982 / 1732 loss=2.429, loss_v1=0, loss_v2=0, nll_loss=1.234, ntokens=1035.4, nsentences=32, sample_size=1035.4, sample_size_v1=0, sample_size_v2=0, ppl=2.35, wps=269, ups=0.26, wpb=1035.4, bsz=32, num_updates=16540, lr=7.25181e-06, gnorm=8.541, clip=100, loss_scale=64, train_wall=38, gb_free=8.4, wall=63816
2023-05-21 11:41:38 - progress_bar.py[line:272] - INFO: epoch 010:    992 / 1732 loss=2.439, loss_v1=0, loss_v2=0, nll_loss=1.245, ntokens=1026.6, nsentences=32, sample_size=1026.6, sample_size_v1=0, sample_size_v2=0, ppl=2.37, wps=266, ups=0.26, wpb=1026.6, bsz=32, num_updates=16550, lr=7.24976e-06, gnorm=9.88, clip=100, loss_scale=64, train_wall=39, gb_free=8.6, wall=63855
2023-05-21 11:42:16 - progress_bar.py[line:272] - INFO: epoch 010:   1002 / 1732 loss=2.41, loss_v1=0, loss_v2=0, nll_loss=1.212, ntokens=1023.8, nsentences=32, sample_size=1023.8, sample_size_v1=0, sample_size_v2=0, ppl=2.32, wps=266.2, ups=0.26, wpb=1023.8, bsz=32, num_updates=16560, lr=7.24771e-06, gnorm=8.898, clip=100, loss_scale=64, train_wall=38, gb_free=8.2, wall=63893
2023-05-21 11:42:54 - progress_bar.py[line:272] - INFO: epoch 010:   1012 / 1732 loss=2.438, loss_v1=0, loss_v2=0, nll_loss=1.243, ntokens=987.2, nsentences=32, sample_size=987.2, sample_size_v1=0, sample_size_v2=0, ppl=2.37, wps=257.3, ups=0.26, wpb=987.2, bsz=32, num_updates=16570, lr=7.24566e-06, gnorm=9.035, clip=100, loss_scale=64, train_wall=38, gb_free=8.5, wall=63932
2023-05-21 11:43:33 - progress_bar.py[line:272] - INFO: epoch 010:   1022 / 1732 loss=2.422, loss_v1=0, loss_v2=0, nll_loss=1.228, ntokens=1063.7, nsentences=32, sample_size=1063.7, sample_size_v1=0, sample_size_v2=0, ppl=2.34, wps=274.6, ups=0.26, wpb=1063.7, bsz=32, num_updates=16580, lr=7.24362e-06, gnorm=8.892, clip=100, loss_scale=64, train_wall=39, gb_free=7.8, wall=63970
2023-05-21 11:44:12 - progress_bar.py[line:272] - INFO: epoch 010:   1032 / 1732 loss=2.423, loss_v1=0, loss_v2=0, nll_loss=1.228, ntokens=1117.6, nsentences=32, sample_size=1117.6, sample_size_v1=0, sample_size_v2=0, ppl=2.34, wps=285.9, ups=0.26, wpb=1117.6, bsz=32, num_updates=16590, lr=7.24157e-06, gnorm=8.214, clip=100, loss_scale=64, train_wall=39, gb_free=8.7, wall=64010
2023-05-21 11:44:51 - progress_bar.py[line:272] - INFO: epoch 010:   1042 / 1732 loss=2.43, loss_v1=0, loss_v2=0, nll_loss=1.233, ntokens=1067.2, nsentences=32, sample_size=1067.2, sample_size_v1=0, sample_size_v2=0, ppl=2.35, wps=273.4, ups=0.26, wpb=1067.2, bsz=32, num_updates=16600, lr=7.23952e-06, gnorm=8.8, clip=100, loss_scale=64, train_wall=39, gb_free=8, wall=64049
2023-05-21 11:45:30 - progress_bar.py[line:272] - INFO: epoch 010:   1052 / 1732 loss=2.44, loss_v1=0, loss_v2=0, nll_loss=1.244, ntokens=1041, nsentences=32, sample_size=1041, sample_size_v1=0, sample_size_v2=0, ppl=2.37, wps=271.7, ups=0.26, wpb=1041, bsz=32, num_updates=16610, lr=7.23748e-06, gnorm=10.151, clip=100, loss_scale=64, train_wall=38, gb_free=8.4, wall=64087
2023-05-21 11:46:08 - progress_bar.py[line:272] - INFO: epoch 010:   1062 / 1732 loss=2.425, loss_v1=0, loss_v2=0, nll_loss=1.23, ntokens=1046.1, nsentences=32, sample_size=1046.1, sample_size_v1=0, sample_size_v2=0, ppl=2.35, wps=270.4, ups=0.26, wpb=1046.1, bsz=32, num_updates=16620, lr=7.23543e-06, gnorm=9.797, clip=100, loss_scale=64, train_wall=39, gb_free=8.4, wall=64126
2023-05-21 11:46:47 - progress_bar.py[line:272] - INFO: epoch 010:   1072 / 1732 loss=2.429, loss_v1=0, loss_v2=0, nll_loss=1.233, ntokens=994.4, nsentences=32, sample_size=994.4, sample_size_v1=0, sample_size_v2=0, ppl=2.35, wps=257, ups=0.26, wpb=994.4, bsz=32, num_updates=16630, lr=7.23338e-06, gnorm=9.376, clip=100, loss_scale=64, train_wall=39, gb_free=8.7, wall=64164
2023-05-21 11:47:26 - progress_bar.py[line:272] - INFO: epoch 010:   1082 / 1732 loss=2.45, loss_v1=0, loss_v2=0, nll_loss=1.257, ntokens=1041.7, nsentences=32, sample_size=1041.7, sample_size_v1=0, sample_size_v2=0, ppl=2.39, wps=268.5, ups=0.26, wpb=1041.7, bsz=32, num_updates=16640, lr=7.23133e-06, gnorm=9.596, clip=100, loss_scale=64, train_wall=39, gb_free=8.2, wall=64203
2023-05-21 11:48:05 - progress_bar.py[line:272] - INFO: epoch 010:   1092 / 1732 loss=2.427, loss_v1=0, loss_v2=0, nll_loss=1.232, ntokens=1060.8, nsentences=32, sample_size=1060.8, sample_size_v1=0, sample_size_v2=0, ppl=2.35, wps=274.4, ups=0.26, wpb=1060.8, bsz=32, num_updates=16650, lr=7.22929e-06, gnorm=9.564, clip=100, loss_scale=64, train_wall=39, gb_free=8.7, wall=64242
2023-05-21 11:48:43 - progress_bar.py[line:272] - INFO: epoch 010:   1102 / 1732 loss=2.434, loss_v1=0, loss_v2=0, nll_loss=1.239, ntokens=1049.1, nsentences=32, sample_size=1049.1, sample_size_v1=0, sample_size_v2=0, ppl=2.36, wps=272, ups=0.26, wpb=1049.1, bsz=32, num_updates=16660, lr=7.22724e-06, gnorm=9.15, clip=100, loss_scale=64, train_wall=39, gb_free=7.5, wall=64280
2023-05-21 11:49:22 - progress_bar.py[line:272] - INFO: epoch 010:   1112 / 1732 loss=2.421, loss_v1=0, loss_v2=0, nll_loss=1.225, ntokens=1025.7, nsentences=32, sample_size=1025.7, sample_size_v1=0, sample_size_v2=0, ppl=2.34, wps=265.6, ups=0.26, wpb=1025.7, bsz=32, num_updates=16670, lr=7.22519e-06, gnorm=9.119, clip=100, loss_scale=64, train_wall=39, gb_free=8.4, wall=64319
2023-05-21 11:50:00 - progress_bar.py[line:272] - INFO: epoch 010:   1122 / 1732 loss=2.438, loss_v1=0, loss_v2=0, nll_loss=1.245, ntokens=976.1, nsentences=32, sample_size=976.1, sample_size_v1=0, sample_size_v2=0, ppl=2.37, wps=254, ups=0.26, wpb=976.1, bsz=32, num_updates=16680, lr=7.22314e-06, gnorm=10.18, clip=100, loss_scale=64, train_wall=38, gb_free=8.5, wall=64357
2023-05-21 11:50:39 - progress_bar.py[line:272] - INFO: epoch 010:   1132 / 1732 loss=2.449, loss_v1=0, loss_v2=0, nll_loss=1.257, ntokens=969.4, nsentences=32, sample_size=969.4, sample_size_v1=0, sample_size_v2=0, ppl=2.39, wps=252, ups=0.26, wpb=969.4, bsz=32, num_updates=16690, lr=7.2211e-06, gnorm=9.492, clip=100, loss_scale=64, train_wall=38, gb_free=8.8, wall=64396
2023-05-21 11:51:17 - progress_bar.py[line:272] - INFO: epoch 010:   1142 / 1732 loss=2.436, loss_v1=0, loss_v2=0, nll_loss=1.242, ntokens=1032.5, nsentences=32, sample_size=1032.5, sample_size_v1=0, sample_size_v2=0, ppl=2.36, wps=268.2, ups=0.26, wpb=1032.5, bsz=32, num_updates=16700, lr=7.21905e-06, gnorm=9.016, clip=100, loss_scale=64, train_wall=38, gb_free=8.2, wall=64434
2023-05-21 11:51:55 - progress_bar.py[line:272] - INFO: epoch 010:   1152 / 1732 loss=2.42, loss_v1=0, loss_v2=0, nll_loss=1.221, ntokens=1026.9, nsentences=32, sample_size=1026.9, sample_size_v1=0, sample_size_v2=0, ppl=2.33, wps=268.1, ups=0.26, wpb=1026.9, bsz=32, num_updates=16710, lr=7.217e-06, gnorm=9.152, clip=100, loss_scale=64, train_wall=38, gb_free=8.6, wall=64473
2023-05-21 11:52:34 - progress_bar.py[line:272] - INFO: epoch 010:   1162 / 1732 loss=2.403, loss_v1=0, loss_v2=0, nll_loss=1.206, ntokens=1008.4, nsentences=32, sample_size=1008.4, sample_size_v1=0, sample_size_v2=0, ppl=2.31, wps=261.7, ups=0.26, wpb=1008.4, bsz=32, num_updates=16720, lr=7.21495e-06, gnorm=9.794, clip=100, loss_scale=64, train_wall=38, gb_free=8.6, wall=64511
2023-05-21 11:53:13 - progress_bar.py[line:272] - INFO: epoch 010:   1172 / 1732 loss=2.424, loss_v1=0, loss_v2=0, nll_loss=1.228, ntokens=1048.6, nsentences=32, sample_size=1048.6, sample_size_v1=0, sample_size_v2=0, ppl=2.34, wps=271.7, ups=0.26, wpb=1048.6, bsz=32, num_updates=16730, lr=7.21291e-06, gnorm=9.482, clip=100, loss_scale=64, train_wall=39, gb_free=7.9, wall=64550
2023-05-21 11:53:51 - progress_bar.py[line:272] - INFO: epoch 010:   1182 / 1732 loss=2.408, loss_v1=0, loss_v2=0, nll_loss=1.208, ntokens=1018.1, nsentences=32, sample_size=1018.1, sample_size_v1=0, sample_size_v2=0, ppl=2.31, wps=265.8, ups=0.26, wpb=1018.1, bsz=32, num_updates=16740, lr=7.21086e-06, gnorm=9.521, clip=100, loss_scale=64, train_wall=38, gb_free=8.3, wall=64588
2023-05-21 11:54:18 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2023-05-21 11:54:33 - progress_bar.py[line:272] - INFO: epoch 010:   1193 / 1732 loss=2.457, loss_v1=0, loss_v2=0, nll_loss=1.265, ntokens=992.4, nsentences=32, sample_size=992.4, sample_size_v1=0, sample_size_v2=0, ppl=2.4, wps=234.3, ups=0.24, wpb=992.4, bsz=32, num_updates=16750, lr=7.20881e-06, gnorm=10.588, clip=100, loss_scale=32, train_wall=42, gb_free=8.5, wall=64630
2023-05-21 11:55:12 - progress_bar.py[line:272] - INFO: epoch 010:   1203 / 1732 loss=2.402, loss_v1=0, loss_v2=0, nll_loss=1.201, ntokens=1142.6, nsentences=32, sample_size=1142.6, sample_size_v1=0, sample_size_v2=0, ppl=2.3, wps=293.6, ups=0.26, wpb=1142.6, bsz=32, num_updates=16760, lr=7.20676e-06, gnorm=8.534, clip=100, loss_scale=32, train_wall=39, gb_free=7.4, wall=64669
2023-05-21 11:55:51 - progress_bar.py[line:272] - INFO: epoch 010:   1213 / 1732 loss=2.42, loss_v1=0, loss_v2=0, nll_loss=1.223, ntokens=1010.9, nsentences=32, sample_size=1010.9, sample_size_v1=0, sample_size_v2=0, ppl=2.33, wps=263, ups=0.26, wpb=1010.9, bsz=32, num_updates=16770, lr=7.20472e-06, gnorm=9.055, clip=100, loss_scale=32, train_wall=38, gb_free=8.9, wall=64708
2023-05-21 11:56:29 - progress_bar.py[line:272] - INFO: epoch 010:   1223 / 1732 loss=2.453, loss_v1=0, loss_v2=0, nll_loss=1.26, ntokens=1033.2, nsentences=32, sample_size=1033.2, sample_size_v1=0, sample_size_v2=0, ppl=2.4, wps=268.8, ups=0.26, wpb=1033.2, bsz=32, num_updates=16780, lr=7.20267e-06, gnorm=10.18, clip=100, loss_scale=32, train_wall=38, gb_free=8.4, wall=64746
2023-05-21 11:57:07 - progress_bar.py[line:272] - INFO: epoch 010:   1233 / 1732 loss=2.414, loss_v1=0, loss_v2=0, nll_loss=1.216, ntokens=1038.6, nsentences=32, sample_size=1038.6, sample_size_v1=0, sample_size_v2=0, ppl=2.32, wps=270.5, ups=0.26, wpb=1038.6, bsz=32, num_updates=16790, lr=7.20062e-06, gnorm=9.451, clip=100, loss_scale=32, train_wall=38, gb_free=8.2, wall=64785
2023-05-21 11:57:46 - progress_bar.py[line:272] - INFO: epoch 010:   1243 / 1732 loss=2.364, loss_v1=0, loss_v2=0, nll_loss=1.161, ntokens=1063.3, nsentences=32, sample_size=1063.3, sample_size_v1=0, sample_size_v2=0, ppl=2.24, wps=275.3, ups=0.26, wpb=1063.3, bsz=32, num_updates=16800, lr=7.19858e-06, gnorm=9.9, clip=100, loss_scale=32, train_wall=39, gb_free=8.8, wall=64823
2023-05-21 11:58:25 - progress_bar.py[line:272] - INFO: epoch 010:   1253 / 1732 loss=2.389, loss_v1=0, loss_v2=0, nll_loss=1.188, ntokens=1098.7, nsentences=32, sample_size=1098.7, sample_size_v1=0, sample_size_v2=0, ppl=2.28, wps=284.1, ups=0.26, wpb=1098.7, bsz=32, num_updates=16810, lr=7.19653e-06, gnorm=8.756, clip=100, loss_scale=32, train_wall=39, gb_free=8.5, wall=64862
2023-05-21 11:59:03 - progress_bar.py[line:272] - INFO: epoch 010:   1263 / 1732 loss=2.427, loss_v1=0, loss_v2=0, nll_loss=1.233, ntokens=1070.8, nsentences=32, sample_size=1070.8, sample_size_v1=0, sample_size_v2=0, ppl=2.35, wps=277.6, ups=0.26, wpb=1070.8, bsz=32, num_updates=16820, lr=7.19448e-06, gnorm=9.254, clip=100, loss_scale=32, train_wall=39, gb_free=8.3, wall=64901
2023-05-21 11:59:42 - progress_bar.py[line:272] - INFO: epoch 010:   1273 / 1732 loss=2.436, loss_v1=0, loss_v2=0, nll_loss=1.242, ntokens=1005.1, nsentences=32, sample_size=1005.1, sample_size_v1=0, sample_size_v2=0, ppl=2.36, wps=260.8, ups=0.26, wpb=1005.1, bsz=32, num_updates=16830, lr=7.19243e-06, gnorm=10.016, clip=100, loss_scale=32, train_wall=38, gb_free=7.9, wall=64939
2023-05-21 12:00:21 - progress_bar.py[line:272] - INFO: epoch 010:   1283 / 1732 loss=2.411, loss_v1=0, loss_v2=0, nll_loss=1.213, ntokens=1101.8, nsentences=32, sample_size=1101.8, sample_size_v1=0, sample_size_v2=0, ppl=2.32, wps=283, ups=0.26, wpb=1101.8, bsz=32, num_updates=16840, lr=7.19039e-06, gnorm=9.656, clip=100, loss_scale=32, train_wall=39, gb_free=8.6, wall=64978
2023-05-21 12:01:00 - progress_bar.py[line:272] - INFO: epoch 010:   1293 / 1732 loss=2.408, loss_v1=0, loss_v2=0, nll_loss=1.208, ntokens=1084.4, nsentences=32, sample_size=1084.4, sample_size_v1=0, sample_size_v2=0, ppl=2.31, wps=280.1, ups=0.26, wpb=1084.4, bsz=32, num_updates=16850, lr=7.18834e-06, gnorm=10.036, clip=100, loss_scale=32, train_wall=39, gb_free=8.5, wall=65017
2023-05-21 12:01:38 - progress_bar.py[line:272] - INFO: epoch 010:   1303 / 1732 loss=2.419, loss_v1=0, loss_v2=0, nll_loss=1.223, ntokens=1102.4, nsentences=32, sample_size=1102.4, sample_size_v1=0, sample_size_v2=0, ppl=2.33, wps=284.1, ups=0.26, wpb=1102.4, bsz=32, num_updates=16860, lr=7.18629e-06, gnorm=8.434, clip=100, loss_scale=32, train_wall=39, gb_free=8, wall=65056
2023-05-21 12:02:17 - progress_bar.py[line:272] - INFO: epoch 010:   1313 / 1732 loss=2.443, loss_v1=0, loss_v2=0, nll_loss=1.25, ntokens=1055.3, nsentences=32, sample_size=1055.3, sample_size_v1=0, sample_size_v2=0, ppl=2.38, wps=271.2, ups=0.26, wpb=1055.3, bsz=32, num_updates=16870, lr=7.18424e-06, gnorm=9.594, clip=100, loss_scale=32, train_wall=39, gb_free=7.8, wall=65094
2023-05-21 12:02:56 - progress_bar.py[line:272] - INFO: epoch 010:   1323 / 1732 loss=2.396, loss_v1=0, loss_v2=0, nll_loss=1.198, ntokens=1103.3, nsentences=32, sample_size=1103.3, sample_size_v1=0, sample_size_v2=0, ppl=2.29, wps=282.1, ups=0.26, wpb=1103.3, bsz=32, num_updates=16880, lr=7.1822e-06, gnorm=10.843, clip=100, loss_scale=32, train_wall=39, gb_free=8.4, wall=65134
2023-05-21 12:03:36 - progress_bar.py[line:272] - INFO: epoch 010:   1333 / 1732 loss=2.391, loss_v1=0, loss_v2=0, nll_loss=1.191, ntokens=1100.8, nsentences=32, sample_size=1100.8, sample_size_v1=0, sample_size_v2=0, ppl=2.28, wps=280.8, ups=0.26, wpb=1100.8, bsz=32, num_updates=16890, lr=7.18015e-06, gnorm=10.53, clip=100, loss_scale=32, train_wall=39, gb_free=8.5, wall=65173
2023-05-21 12:04:15 - progress_bar.py[line:272] - INFO: epoch 010:   1343 / 1732 loss=2.403, loss_v1=0, loss_v2=0, nll_loss=1.204, ntokens=1190.4, nsentences=32, sample_size=1190.4, sample_size_v1=0, sample_size_v2=0, ppl=2.3, wps=304.4, ups=0.26, wpb=1190.4, bsz=32, num_updates=16900, lr=7.1781e-06, gnorm=9.22, clip=100, loss_scale=32, train_wall=39, gb_free=8.4, wall=65212
2023-05-21 12:04:54 - progress_bar.py[line:272] - INFO: epoch 010:   1353 / 1732 loss=2.416, loss_v1=0, loss_v2=0, nll_loss=1.219, ntokens=1120.7, nsentences=32, sample_size=1120.7, sample_size_v1=0, sample_size_v2=0, ppl=2.33, wps=288, ups=0.26, wpb=1120.7, bsz=32, num_updates=16910, lr=7.17605e-06, gnorm=9.96, clip=100, loss_scale=32, train_wall=39, gb_free=8.6, wall=65251
2023-05-21 12:05:33 - progress_bar.py[line:272] - INFO: epoch 010:   1363 / 1732 loss=2.385, loss_v1=0, loss_v2=0, nll_loss=1.182, ntokens=1088.2, nsentences=32, sample_size=1088.2, sample_size_v1=0, sample_size_v2=0, ppl=2.27, wps=279.5, ups=0.26, wpb=1088.2, bsz=32, num_updates=16920, lr=7.17401e-06, gnorm=8.796, clip=100, loss_scale=32, train_wall=39, gb_free=8.9, wall=65290
2023-05-21 12:06:11 - progress_bar.py[line:272] - INFO: epoch 010:   1373 / 1732 loss=2.433, loss_v1=0, loss_v2=0, nll_loss=1.24, ntokens=1114.2, nsentences=32, sample_size=1114.2, sample_size_v1=0, sample_size_v2=0, ppl=2.36, wps=287.3, ups=0.26, wpb=1114.2, bsz=32, num_updates=16930, lr=7.17196e-06, gnorm=9.324, clip=100, loss_scale=32, train_wall=39, gb_free=8.6, wall=65329
2023-05-21 12:06:50 - progress_bar.py[line:272] - INFO: epoch 010:   1383 / 1732 loss=2.428, loss_v1=0, loss_v2=0, nll_loss=1.232, ntokens=1148.9, nsentences=32, sample_size=1148.9, sample_size_v1=0, sample_size_v2=0, ppl=2.35, wps=297.5, ups=0.26, wpb=1148.9, bsz=32, num_updates=16940, lr=7.16991e-06, gnorm=10.454, clip=100, loss_scale=32, train_wall=39, gb_free=8.7, wall=65367
2023-05-21 12:07:28 - progress_bar.py[line:272] - INFO: epoch 010:   1393 / 1732 loss=2.418, loss_v1=0, loss_v2=0, nll_loss=1.223, ntokens=1033.6, nsentences=32, sample_size=1033.6, sample_size_v1=0, sample_size_v2=0, ppl=2.33, wps=269.3, ups=0.26, wpb=1033.6, bsz=32, num_updates=16950, lr=7.16786e-06, gnorm=10.469, clip=100, loss_scale=32, train_wall=38, gb_free=8.1, wall=65406
2023-05-21 12:08:07 - progress_bar.py[line:272] - INFO: epoch 010:   1403 / 1732 loss=2.398, loss_v1=0, loss_v2=0, nll_loss=1.197, ntokens=1148.6, nsentences=32, sample_size=1148.6, sample_size_v1=0, sample_size_v2=0, ppl=2.29, wps=296.6, ups=0.26, wpb=1148.6, bsz=32, num_updates=16960, lr=7.16582e-06, gnorm=9.623, clip=100, loss_scale=32, train_wall=39, gb_free=8.7, wall=65444
2023-05-21 12:08:46 - progress_bar.py[line:272] - INFO: epoch 010:   1413 / 1732 loss=2.428, loss_v1=0, loss_v2=0, nll_loss=1.231, ntokens=1251.8, nsentences=32, sample_size=1251.8, sample_size_v1=0, sample_size_v2=0, ppl=2.35, wps=320.5, ups=0.26, wpb=1251.8, bsz=32, num_updates=16970, lr=7.16377e-06, gnorm=8.535, clip=100, loss_scale=32, train_wall=39, gb_free=8.3, wall=65483
2023-05-21 12:09:26 - progress_bar.py[line:272] - INFO: epoch 010:   1423 / 1732 loss=2.408, loss_v1=0, loss_v2=0, nll_loss=1.211, ntokens=1276.2, nsentences=32, sample_size=1276.2, sample_size_v1=0, sample_size_v2=0, ppl=2.32, wps=324.1, ups=0.25, wpb=1276.2, bsz=32, num_updates=16980, lr=7.16172e-06, gnorm=8.251, clip=100, loss_scale=32, train_wall=39, gb_free=8.5, wall=65523
2023-05-21 12:10:04 - progress_bar.py[line:272] - INFO: epoch 010:   1433 / 1732 loss=2.39, loss_v1=0, loss_v2=0, nll_loss=1.191, ntokens=1210.9, nsentences=32, sample_size=1210.9, sample_size_v1=0, sample_size_v2=0, ppl=2.28, wps=312.7, ups=0.26, wpb=1210.9, bsz=32, num_updates=16990, lr=7.15967e-06, gnorm=7.859, clip=100, loss_scale=32, train_wall=39, gb_free=8.4, wall=65561
2023-05-21 12:10:43 - progress_bar.py[line:272] - INFO: epoch 010:   1443 / 1732 loss=2.421, loss_v1=0, loss_v2=0, nll_loss=1.225, ntokens=1130.8, nsentences=32, sample_size=1130.8, sample_size_v1=0, sample_size_v2=0, ppl=2.34, wps=292.8, ups=0.26, wpb=1130.8, bsz=32, num_updates=17000, lr=7.15763e-06, gnorm=9.506, clip=100, loss_scale=32, train_wall=39, gb_free=7.8, wall=65600
2023-05-21 12:11:22 - progress_bar.py[line:272] - INFO: epoch 010:   1453 / 1732 loss=2.433, loss_v1=0, loss_v2=0, nll_loss=1.236, ntokens=1116.6, nsentences=32, sample_size=1116.6, sample_size_v1=0, sample_size_v2=0, ppl=2.36, wps=287.4, ups=0.26, wpb=1116.6, bsz=32, num_updates=17010, lr=7.15558e-06, gnorm=9.096, clip=100, loss_scale=32, train_wall=39, gb_free=7.9, wall=65639
2023-05-21 12:12:01 - progress_bar.py[line:272] - INFO: epoch 010:   1463 / 1732 loss=2.374, loss_v1=0, loss_v2=0, nll_loss=1.171, ntokens=1191.9, nsentences=32, sample_size=1191.9, sample_size_v1=0, sample_size_v2=0, ppl=2.25, wps=303.8, ups=0.25, wpb=1191.9, bsz=32, num_updates=17020, lr=7.15353e-06, gnorm=8.323, clip=100, loss_scale=32, train_wall=39, gb_free=7.4, wall=65678
2023-05-21 12:12:40 - progress_bar.py[line:272] - INFO: epoch 010:   1473 / 1732 loss=2.408, loss_v1=0, loss_v2=0, nll_loss=1.211, ntokens=1103.1, nsentences=32, sample_size=1103.1, sample_size_v1=0, sample_size_v2=0, ppl=2.31, wps=284.1, ups=0.26, wpb=1103.1, bsz=32, num_updates=17030, lr=7.15149e-06, gnorm=9.56, clip=100, loss_scale=32, train_wall=39, gb_free=8.5, wall=65717
2023-05-21 12:13:19 - progress_bar.py[line:272] - INFO: epoch 010:   1483 / 1732 loss=2.44, loss_v1=0, loss_v2=0, nll_loss=1.247, ntokens=1083.9, nsentences=32, sample_size=1083.9, sample_size_v1=0, sample_size_v2=0, ppl=2.37, wps=277.8, ups=0.26, wpb=1083.9, bsz=32, num_updates=17040, lr=7.14944e-06, gnorm=10.088, clip=100, loss_scale=32, train_wall=39, gb_free=8.9, wall=65756
2023-05-21 12:13:58 - progress_bar.py[line:272] - INFO: epoch 010:   1493 / 1732 loss=2.405, loss_v1=0, loss_v2=0, nll_loss=1.205, ntokens=1119.2, nsentences=32, sample_size=1119.2, sample_size_v1=0, sample_size_v2=0, ppl=2.31, wps=286.4, ups=0.26, wpb=1119.2, bsz=32, num_updates=17050, lr=7.14739e-06, gnorm=8.114, clip=100, loss_scale=32, train_wall=39, gb_free=8.7, wall=65795
2023-05-21 12:14:37 - progress_bar.py[line:272] - INFO: epoch 010:   1503 / 1732 loss=2.362, loss_v1=0, loss_v2=0, nll_loss=1.158, ntokens=1138.8, nsentences=32, sample_size=1138.8, sample_size_v1=0, sample_size_v2=0, ppl=2.23, wps=293.8, ups=0.26, wpb=1138.8, bsz=32, num_updates=17060, lr=7.14534e-06, gnorm=8.926, clip=100, loss_scale=32, train_wall=39, gb_free=8.8, wall=65834
2023-05-21 12:15:15 - progress_bar.py[line:272] - INFO: epoch 010:   1513 / 1732 loss=2.404, loss_v1=0, loss_v2=0, nll_loss=1.208, ntokens=1063.2, nsentences=32, sample_size=1063.2, sample_size_v1=0, sample_size_v2=0, ppl=2.31, wps=276.1, ups=0.26, wpb=1063.2, bsz=32, num_updates=17070, lr=7.1433e-06, gnorm=9.419, clip=100, loss_scale=32, train_wall=38, gb_free=8.4, wall=65872
2023-05-21 12:15:54 - progress_bar.py[line:272] - INFO: epoch 010:   1523 / 1732 loss=2.459, loss_v1=0, loss_v2=0, nll_loss=1.269, ntokens=1020.5, nsentences=32, sample_size=1020.5, sample_size_v1=0, sample_size_v2=0, ppl=2.41, wps=264.5, ups=0.26, wpb=1020.5, bsz=32, num_updates=17080, lr=7.14125e-06, gnorm=9.622, clip=100, loss_scale=32, train_wall=39, gb_free=8.4, wall=65911
2023-05-21 12:16:33 - progress_bar.py[line:272] - INFO: epoch 010:   1533 / 1732 loss=2.42, loss_v1=0, loss_v2=0, nll_loss=1.221, ntokens=1081, nsentences=32, sample_size=1081, sample_size_v1=0, sample_size_v2=0, ppl=2.33, wps=278.7, ups=0.26, wpb=1081, bsz=32, num_updates=17090, lr=7.1392e-06, gnorm=9.146, clip=100, loss_scale=32, train_wall=39, gb_free=8.1, wall=65950
2023-05-21 12:17:11 - progress_bar.py[line:272] - INFO: epoch 010:   1543 / 1732 loss=2.401, loss_v1=0, loss_v2=0, nll_loss=1.2, ntokens=1109.5, nsentences=32, sample_size=1109.5, sample_size_v1=0, sample_size_v2=0, ppl=2.3, wps=285.8, ups=0.26, wpb=1109.5, bsz=32, num_updates=17100, lr=7.13715e-06, gnorm=9.23, clip=100, loss_scale=32, train_wall=39, gb_free=8.5, wall=65989
2023-05-21 12:17:50 - progress_bar.py[line:272] - INFO: epoch 010:   1553 / 1732 loss=2.397, loss_v1=0, loss_v2=0, nll_loss=1.198, ntokens=1034.9, nsentences=32, sample_size=1034.9, sample_size_v1=0, sample_size_v2=0, ppl=2.29, wps=268.3, ups=0.26, wpb=1034.9, bsz=32, num_updates=17110, lr=7.13511e-06, gnorm=9.43, clip=100, loss_scale=32, train_wall=39, gb_free=8.4, wall=66027
2023-05-21 12:18:29 - progress_bar.py[line:272] - INFO: epoch 010:   1563 / 1732 loss=2.424, loss_v1=0, loss_v2=0, nll_loss=1.228, ntokens=1130.9, nsentences=32, sample_size=1130.9, sample_size_v1=0, sample_size_v2=0, ppl=2.34, wps=291.3, ups=0.26, wpb=1130.9, bsz=32, num_updates=17120, lr=7.13306e-06, gnorm=9.061, clip=100, loss_scale=32, train_wall=39, gb_free=8.9, wall=66066
2023-05-21 12:19:08 - progress_bar.py[line:272] - INFO: epoch 010:   1573 / 1732 loss=2.449, loss_v1=0, loss_v2=0, nll_loss=1.256, ntokens=1064.8, nsentences=32, sample_size=1064.8, sample_size_v1=0, sample_size_v2=0, ppl=2.39, wps=274.6, ups=0.26, wpb=1064.8, bsz=32, num_updates=17130, lr=7.13101e-06, gnorm=10.699, clip=100, loss_scale=32, train_wall=39, gb_free=8, wall=66105
2023-05-21 12:19:46 - progress_bar.py[line:272] - INFO: epoch 010:   1583 / 1732 loss=2.446, loss_v1=0, loss_v2=0, nll_loss=1.251, ntokens=1007.5, nsentences=32, sample_size=1007.5, sample_size_v1=0, sample_size_v2=0, ppl=2.38, wps=260.5, ups=0.26, wpb=1007.5, bsz=32, num_updates=17140, lr=7.12896e-06, gnorm=10.181, clip=100, loss_scale=32, train_wall=39, gb_free=8.4, wall=66143
2023-05-21 12:20:25 - progress_bar.py[line:272] - INFO: epoch 010:   1593 / 1732 loss=2.39, loss_v1=0, loss_v2=0, nll_loss=1.19, ntokens=1081.3, nsentences=32, sample_size=1081.3, sample_size_v1=0, sample_size_v2=0, ppl=2.28, wps=278.9, ups=0.26, wpb=1081.3, bsz=32, num_updates=17150, lr=7.12692e-06, gnorm=9.178, clip=100, loss_scale=32, train_wall=39, gb_free=8.8, wall=66182
2023-05-21 12:21:04 - progress_bar.py[line:272] - INFO: epoch 010:   1603 / 1732 loss=2.392, loss_v1=0, loss_v2=0, nll_loss=1.196, ntokens=1092.4, nsentences=32, sample_size=1092.4, sample_size_v1=0, sample_size_v2=0, ppl=2.29, wps=282.5, ups=0.26, wpb=1092.4, bsz=32, num_updates=17160, lr=7.12487e-06, gnorm=9.31, clip=100, loss_scale=32, train_wall=39, gb_free=8.7, wall=66221
2023-05-21 12:21:43 - progress_bar.py[line:272] - INFO: epoch 010:   1613 / 1732 loss=2.382, loss_v1=0, loss_v2=0, nll_loss=1.18, ntokens=1153.1, nsentences=32, sample_size=1153.1, sample_size_v1=0, sample_size_v2=0, ppl=2.27, wps=295.1, ups=0.26, wpb=1153.1, bsz=32, num_updates=17170, lr=7.12282e-06, gnorm=8.533, clip=100, loss_scale=32, train_wall=39, gb_free=7.8, wall=66260
2023-05-21 12:22:22 - progress_bar.py[line:272] - INFO: epoch 010:   1623 / 1732 loss=2.386, loss_v1=0, loss_v2=0, nll_loss=1.185, ntokens=1098.4, nsentences=32, sample_size=1098.4, sample_size_v1=0, sample_size_v2=0, ppl=2.27, wps=281.3, ups=0.26, wpb=1098.4, bsz=32, num_updates=17180, lr=7.12077e-06, gnorm=9.358, clip=100, loss_scale=32, train_wall=39, gb_free=8.1, wall=66299
2023-05-21 12:23:01 - progress_bar.py[line:272] - INFO: epoch 010:   1633 / 1732 loss=2.39, loss_v1=0, loss_v2=0, nll_loss=1.19, ntokens=1178.3, nsentences=32, sample_size=1178.3, sample_size_v1=0, sample_size_v2=0, ppl=2.28, wps=303.4, ups=0.26, wpb=1178.3, bsz=32, num_updates=17190, lr=7.11873e-06, gnorm=8.64, clip=100, loss_scale=32, train_wall=39, gb_free=8.8, wall=66338
2023-05-21 12:23:40 - progress_bar.py[line:272] - INFO: epoch 010:   1643 / 1732 loss=2.366, loss_v1=0, loss_v2=0, nll_loss=1.162, ntokens=1238.2, nsentences=32, sample_size=1238.2, sample_size_v1=0, sample_size_v2=0, ppl=2.24, wps=318.1, ups=0.26, wpb=1238.2, bsz=32, num_updates=17200, lr=7.11668e-06, gnorm=8.237, clip=100, loss_scale=32, train_wall=39, gb_free=8.4, wall=66377
2023-05-21 12:24:18 - progress_bar.py[line:272] - INFO: epoch 010:   1653 / 1732 loss=2.423, loss_v1=0, loss_v2=0, nll_loss=1.226, ntokens=993.8, nsentences=32, sample_size=993.8, sample_size_v1=0, sample_size_v2=0, ppl=2.34, wps=259.1, ups=0.26, wpb=993.8, bsz=32, num_updates=17210, lr=7.11463e-06, gnorm=10.926, clip=100, loss_scale=32, train_wall=38, gb_free=8.6, wall=66415
2023-05-21 12:24:56 - progress_bar.py[line:272] - INFO: epoch 010:   1663 / 1732 loss=2.419, loss_v1=0, loss_v2=0, nll_loss=1.224, ntokens=1051.4, nsentences=32, sample_size=1051.4, sample_size_v1=0, sample_size_v2=0, ppl=2.34, wps=272.8, ups=0.26, wpb=1051.4, bsz=32, num_updates=17220, lr=7.11259e-06, gnorm=9.225, clip=100, loss_scale=32, train_wall=39, gb_free=8.2, wall=66454
2023-05-21 12:25:35 - progress_bar.py[line:272] - INFO: epoch 010:   1673 / 1732 loss=2.387, loss_v1=0, loss_v2=0, nll_loss=1.185, ntokens=1033, nsentences=32, sample_size=1033, sample_size_v1=0, sample_size_v2=0, ppl=2.27, wps=268.1, ups=0.26, wpb=1033, bsz=32, num_updates=17230, lr=7.11054e-06, gnorm=9.341, clip=100, loss_scale=32, train_wall=38, gb_free=7.9, wall=66492
2023-05-21 12:26:14 - progress_bar.py[line:272] - INFO: epoch 010:   1683 / 1732 loss=2.362, loss_v1=0, loss_v2=0, nll_loss=1.158, ntokens=1168.8, nsentences=32, sample_size=1168.8, sample_size_v1=0, sample_size_v2=0, ppl=2.23, wps=299.3, ups=0.26, wpb=1168.8, bsz=32, num_updates=17240, lr=7.10849e-06, gnorm=9.391, clip=100, loss_scale=32, train_wall=39, gb_free=8.5, wall=66531
2023-05-21 12:26:53 - progress_bar.py[line:272] - INFO: epoch 010:   1693 / 1732 loss=2.382, loss_v1=0, loss_v2=0, nll_loss=1.182, ntokens=1251.1, nsentences=32, sample_size=1251.1, sample_size_v1=0, sample_size_v2=0, ppl=2.27, wps=318.8, ups=0.25, wpb=1251.1, bsz=32, num_updates=17250, lr=7.10644e-06, gnorm=7.729, clip=100, loss_scale=32, train_wall=39, gb_free=8, wall=66571
2023-05-21 12:27:33 - progress_bar.py[line:272] - INFO: epoch 010:   1703 / 1732 loss=2.397, loss_v1=0, loss_v2=0, nll_loss=1.198, ntokens=1247.1, nsentences=32, sample_size=1247.1, sample_size_v1=0, sample_size_v2=0, ppl=2.29, wps=315.8, ups=0.25, wpb=1247.1, bsz=32, num_updates=17260, lr=7.1044e-06, gnorm=8.736, clip=100, loss_scale=64, train_wall=39, gb_free=8.4, wall=66610
2023-05-21 12:28:12 - progress_bar.py[line:272] - INFO: epoch 010:   1713 / 1732 loss=2.395, loss_v1=0, loss_v2=0, nll_loss=1.196, ntokens=1176.1, nsentences=32, sample_size=1176.1, sample_size_v1=0, sample_size_v2=0, ppl=2.29, wps=300.6, ups=0.26, wpb=1176.1, bsz=32, num_updates=17270, lr=7.10235e-06, gnorm=9.19, clip=100, loss_scale=64, train_wall=39, gb_free=6.2, wall=66649
2023-05-21 12:28:51 - progress_bar.py[line:272] - INFO: epoch 010:   1723 / 1732 loss=2.403, loss_v1=0, loss_v2=0, nll_loss=1.203, ntokens=1147.2, nsentences=32, sample_size=1147.2, sample_size_v1=0, sample_size_v2=0, ppl=2.3, wps=294.9, ups=0.26, wpb=1147.2, bsz=32, num_updates=17280, lr=7.1003e-06, gnorm=8.2, clip=100, loss_scale=64, train_wall=39, gb_free=7.4, wall=66688
2023-05-21 12:29:23 - checkpoint_utils.py[line:64] - INFO: Preparing to save checkpoint for epoch 10 @ 17289 updates
2023-05-21 12:29:23 - trainer.py[line:431] - INFO: Saving checkpoint to ../../checkpoints/OFA/sgcls_checkpoints/_30_1e-5_480/checkpoint10.pt
2023-05-21 12:29:30 - trainer.py[line:441] - INFO: Finished saving checkpoint to ../../checkpoints/OFA/sgcls_checkpoints/_30_1e-5_480/checkpoint10.pt
2023-05-21 12:29:33 - checkpoint_utils.py[line:133] - INFO: Saved checkpoint ../../checkpoints/OFA/sgcls_checkpoints/_30_1e-5_480/checkpoint10.pt (epoch 10 @ 17289 updates, score None) (writing took 9.883750488050282 seconds)
2023-05-21 12:29:33 - train.py[line:332] - INFO: end of epoch 10 (average epoch stats below)
2023-05-21 12:29:33 - progress_bar.py[line:282] - INFO: epoch 010 | loss 2.415 | loss_v1 0 | loss_v2 0 | nll_loss 1.218 | ntokens 1051.58 | nsentences 31.986 | sample_size 1051.58 | sample_size_v1 0 | sample_size_v2 0 | ppl 2.33 | wps 272.4 | ups 0.26 | wpb 1051.6 | bsz 32 | num_updates 17289 | lr 7.09846e-06 | gnorm 9.157 | clip 100 | loss_scale 64 | train_wall 6657 | gb_free 8.9 | wall 66730
2023-05-21 12:29:33 - trainer.py[line:639] - INFO: loading train data for epoch 11
local datafile ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 0 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 0 finished initializing row_count and line_idx-to-offset mapping
file ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 0 row count 55400 total row count 55400
slice_id 0 seek offset 0
2023-05-21 12:29:35 - trainer.py[line:703] - INFO: begin training epoch 11
2023-05-21 12:29:35 - train.py[line:305] - INFO: Start iterating over samples
2023-05-21 12:29:39 - progress_bar.py[line:272] - INFO: epoch 011:      1 / 1732 loss=2.453, loss_v1=0, loss_v2=0, nll_loss=1.26, ntokens=1067.2, nsentences=29.6, sample_size=1067.2, sample_size_v1=0, sample_size_v2=0, ppl=2.39, wps=223, ups=0.21, wpb=1067.2, bsz=29.6, num_updates=17290, lr=7.09825e-06, gnorm=9.962, clip=100, loss_scale=64, train_wall=36, gb_free=8.5, wall=66736
2023-05-21 12:30:18 - progress_bar.py[line:272] - INFO: epoch 011:     11 / 1732 loss=2.33, loss_v1=0, loss_v2=0, nll_loss=1.12, ntokens=1109.8, nsentences=32, sample_size=1109.8, sample_size_v1=0, sample_size_v2=0, ppl=2.17, wps=284.5, ups=0.26, wpb=1109.8, bsz=32, num_updates=17300, lr=7.09621e-06, gnorm=9.64, clip=100, loss_scale=64, train_wall=39, gb_free=8.6, wall=66775
2023-05-21 12:30:57 - progress_bar.py[line:272] - INFO: epoch 011:     21 / 1732 loss=2.278, loss_v1=0, loss_v2=0, nll_loss=1.065, ntokens=1106.8, nsentences=32, sample_size=1106.8, sample_size_v1=0, sample_size_v2=0, ppl=2.09, wps=285.5, ups=0.26, wpb=1106.8, bsz=32, num_updates=17310, lr=7.09416e-06, gnorm=9.35, clip=100, loss_scale=64, train_wall=39, gb_free=8.4, wall=66814
2023-05-21 12:31:35 - progress_bar.py[line:272] - INFO: epoch 011:     31 / 1732 loss=2.317, loss_v1=0, loss_v2=0, nll_loss=1.107, ntokens=958.4, nsentences=32, sample_size=958.4, sample_size_v1=0, sample_size_v2=0, ppl=2.15, wps=246.8, ups=0.26, wpb=958.4, bsz=32, num_updates=17320, lr=7.09211e-06, gnorm=9.915, clip=100, loss_scale=64, train_wall=39, gb_free=8.3, wall=66853
2023-05-21 12:32:15 - progress_bar.py[line:272] - INFO: epoch 011:     41 / 1732 loss=2.179, loss_v1=0, loss_v2=0, nll_loss=0.958, ntokens=1207.2, nsentences=32, sample_size=1207.2, sample_size_v1=0, sample_size_v2=0, ppl=1.94, wps=307.3, ups=0.25, wpb=1207.2, bsz=32, num_updates=17330, lr=7.09006e-06, gnorm=7.463, clip=100, loss_scale=64, train_wall=39, gb_free=8, wall=66892
2023-05-21 12:32:30 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2023-05-21 12:32:57 - progress_bar.py[line:272] - INFO: epoch 011:     52 / 1732 loss=2.233, loss_v1=0, loss_v2=0, nll_loss=1.015, ntokens=1016, nsentences=32, sample_size=1016, sample_size_v1=0, sample_size_v2=0, ppl=2.02, wps=239, ups=0.24, wpb=1016, bsz=32, num_updates=17340, lr=7.08802e-06, gnorm=9.526, clip=100, loss_scale=32, train_wall=42, gb_free=8.8, wall=66934
2023-05-21 12:33:36 - progress_bar.py[line:272] - INFO: epoch 011:     62 / 1732 loss=2.042, loss_v1=0, loss_v2=0, nll_loss=0.798, ntokens=1192.6, nsentences=32, sample_size=1192.6, sample_size_v1=0, sample_size_v2=0, ppl=1.74, wps=307.2, ups=0.26, wpb=1192.6, bsz=32, num_updates=17350, lr=7.08597e-06, gnorm=6.738, clip=100, loss_scale=32, train_wall=39, gb_free=7.4, wall=66973
2023-05-21 12:34:16 - progress_bar.py[line:272] - INFO: epoch 011:     72 / 1732 loss=2.15, loss_v1=0, loss_v2=0, nll_loss=0.926, ntokens=1389.6, nsentences=32, sample_size=1389.6, sample_size_v1=0, sample_size_v2=0, ppl=1.9, wps=347.5, ups=0.25, wpb=1389.6, bsz=32, num_updates=17360, lr=7.08392e-06, gnorm=7.104, clip=100, loss_scale=32, train_wall=40, gb_free=7.4, wall=67013
2023-05-21 12:34:55 - progress_bar.py[line:272] - INFO: epoch 011:     82 / 1732 loss=2.183, loss_v1=0, loss_v2=0, nll_loss=0.953, ntokens=1199, nsentences=32, sample_size=1199, sample_size_v1=0, sample_size_v2=0, ppl=1.94, wps=304.5, ups=0.25, wpb=1199, bsz=32, num_updates=17370, lr=7.08187e-06, gnorm=8.348, clip=100, loss_scale=32, train_wall=39, gb_free=8, wall=67053
2023-05-21 12:35:34 - progress_bar.py[line:272] - INFO: epoch 011:     92 / 1732 loss=2.216, loss_v1=0, loss_v2=0, nll_loss=0.997, ntokens=1081.9, nsentences=32, sample_size=1081.9, sample_size_v1=0, sample_size_v2=0, ppl=2, wps=277.6, ups=0.26, wpb=1081.9, bsz=32, num_updates=17380, lr=7.07983e-06, gnorm=9.081, clip=100, loss_scale=32, train_wall=39, gb_free=8.3, wall=67092
2023-05-21 12:36:13 - progress_bar.py[line:272] - INFO: epoch 011:    102 / 1732 loss=2.307, loss_v1=0, loss_v2=0, nll_loss=1.099, ntokens=1017.7, nsentences=32, sample_size=1017.7, sample_size_v1=0, sample_size_v2=0, ppl=2.14, wps=265.8, ups=0.26, wpb=1017.7, bsz=32, num_updates=17390, lr=7.07778e-06, gnorm=10.325, clip=100, loss_scale=32, train_wall=38, gb_free=8.3, wall=67130
2023-05-21 12:36:51 - progress_bar.py[line:272] - INFO: epoch 011:    112 / 1732 loss=2.419, loss_v1=0, loss_v2=0, nll_loss=1.224, ntokens=1026.3, nsentences=32, sample_size=1026.3, sample_size_v1=0, sample_size_v2=0, ppl=2.34, wps=266.7, ups=0.26, wpb=1026.3, bsz=32, num_updates=17400, lr=7.07573e-06, gnorm=10.109, clip=100, loss_scale=32, train_wall=38, gb_free=7.2, wall=67168
2023-05-21 12:37:30 - progress_bar.py[line:272] - INFO: epoch 011:    122 / 1732 loss=2.382, loss_v1=0, loss_v2=0, nll_loss=1.183, ntokens=1103.7, nsentences=32, sample_size=1103.7, sample_size_v1=0, sample_size_v2=0, ppl=2.27, wps=280.7, ups=0.25, wpb=1103.7, bsz=32, num_updates=17410, lr=7.07369e-06, gnorm=9.949, clip=100, loss_scale=32, train_wall=39, gb_free=7.8, wall=67208
2023-05-21 12:38:10 - progress_bar.py[line:272] - INFO: epoch 011:    132 / 1732 loss=2.326, loss_v1=0, loss_v2=0, nll_loss=1.115, ntokens=1224.5, nsentences=32, sample_size=1224.5, sample_size_v1=0, sample_size_v2=0, ppl=2.17, wps=310.1, ups=0.25, wpb=1224.5, bsz=32, num_updates=17420, lr=7.07164e-06, gnorm=7.541, clip=100, loss_scale=32, train_wall=39, gb_free=7.8, wall=67247
2023-05-21 12:38:49 - progress_bar.py[line:272] - INFO: epoch 011:    142 / 1732 loss=2.306, loss_v1=0, loss_v2=0, nll_loss=1.094, ntokens=1223.2, nsentences=32, sample_size=1223.2, sample_size_v1=0, sample_size_v2=0, ppl=2.13, wps=309.4, ups=0.25, wpb=1223.2, bsz=32, num_updates=17430, lr=7.06959e-06, gnorm=7.142, clip=100, loss_scale=32, train_wall=39, gb_free=7.8, wall=67287
2023-05-21 12:39:29 - progress_bar.py[line:272] - INFO: epoch 011:    152 / 1732 loss=2.314, loss_v1=0, loss_v2=0, nll_loss=1.108, ntokens=1158.5, nsentences=32, sample_size=1158.5, sample_size_v1=0, sample_size_v2=0, ppl=2.16, wps=293.3, ups=0.25, wpb=1158.5, bsz=32, num_updates=17440, lr=7.06754e-06, gnorm=7.263, clip=100, loss_scale=32, train_wall=39, gb_free=7.8, wall=67326
2023-05-21 12:40:08 - progress_bar.py[line:272] - INFO: epoch 011:    162 / 1732 loss=2.314, loss_v1=0, loss_v2=0, nll_loss=1.105, ntokens=1101.3, nsentences=32, sample_size=1101.3, sample_size_v1=0, sample_size_v2=0, ppl=2.15, wps=279.7, ups=0.25, wpb=1101.3, bsz=32, num_updates=17450, lr=7.0655e-06, gnorm=7.746, clip=100, loss_scale=32, train_wall=39, gb_free=8.2, wall=67366
2023-05-21 12:40:47 - progress_bar.py[line:272] - INFO: epoch 011:    172 / 1732 loss=2.344, loss_v1=0, loss_v2=0, nll_loss=1.138, ntokens=937.9, nsentences=32, sample_size=937.9, sample_size_v1=0, sample_size_v2=0, ppl=2.2, wps=243.4, ups=0.26, wpb=937.9, bsz=32, num_updates=17460, lr=7.06345e-06, gnorm=9.317, clip=100, loss_scale=32, train_wall=38, gb_free=8.3, wall=67404
2023-05-21 12:41:26 - progress_bar.py[line:272] - INFO: epoch 011:    182 / 1732 loss=2.277, loss_v1=0, loss_v2=0, nll_loss=1.063, ntokens=1177.8, nsentences=32, sample_size=1177.8, sample_size_v1=0, sample_size_v2=0, ppl=2.09, wps=299.8, ups=0.25, wpb=1177.8, bsz=32, num_updates=17470, lr=7.0614e-06, gnorm=7.204, clip=100, loss_scale=32, train_wall=39, gb_free=8.1, wall=67443
2023-05-21 12:42:05 - progress_bar.py[line:272] - INFO: epoch 011:    192 / 1732 loss=2.295, loss_v1=0, loss_v2=0, nll_loss=1.083, ntokens=1116, nsentences=32, sample_size=1116, sample_size_v1=0, sample_size_v2=0, ppl=2.12, wps=285.2, ups=0.26, wpb=1116, bsz=32, num_updates=17480, lr=7.05935e-06, gnorm=7.45, clip=100, loss_scale=32, train_wall=39, gb_free=7.7, wall=67482
2023-05-21 12:42:44 - progress_bar.py[line:272] - INFO: epoch 011:    202 / 1732 loss=2.383, loss_v1=0, loss_v2=0, nll_loss=1.185, ntokens=1088.7, nsentences=32, sample_size=1088.7, sample_size_v1=0, sample_size_v2=0, ppl=2.27, wps=280.6, ups=0.26, wpb=1088.7, bsz=32, num_updates=17490, lr=7.05731e-06, gnorm=8.857, clip=100, loss_scale=32, train_wall=39, gb_free=7.8, wall=67521
2023-05-21 12:43:22 - progress_bar.py[line:272] - INFO: epoch 011:    212 / 1732 loss=2.435, loss_v1=0, loss_v2=0, nll_loss=1.241, ntokens=1014.1, nsentences=32, sample_size=1014.1, sample_size_v1=0, sample_size_v2=0, ppl=2.36, wps=264.8, ups=0.26, wpb=1014.1, bsz=32, num_updates=17500, lr=7.05526e-06, gnorm=8.496, clip=100, loss_scale=32, train_wall=38, gb_free=8.1, wall=67560
2023-05-21 12:44:01 - progress_bar.py[line:272] - INFO: epoch 011:    222 / 1732 loss=2.438, loss_v1=0, loss_v2=0, nll_loss=1.245, ntokens=1144.1, nsentences=32, sample_size=1144.1, sample_size_v1=0, sample_size_v2=0, ppl=2.37, wps=298.7, ups=0.26, wpb=1144.1, bsz=32, num_updates=17510, lr=7.05321e-06, gnorm=8.819, clip=100, loss_scale=32, train_wall=38, gb_free=7.9, wall=67598
2023-05-21 12:44:39 - progress_bar.py[line:272] - INFO: epoch 011:    232 / 1732 loss=2.461, loss_v1=0, loss_v2=0, nll_loss=1.268, ntokens=1097.8, nsentences=32, sample_size=1097.8, sample_size_v1=0, sample_size_v2=0, ppl=2.41, wps=287.8, ups=0.26, wpb=1097.8, bsz=32, num_updates=17520, lr=7.05116e-06, gnorm=10.045, clip=100, loss_scale=32, train_wall=38, gb_free=8.5, wall=67636
2023-05-21 12:45:17 - progress_bar.py[line:272] - INFO: epoch 011:    242 / 1732 loss=2.448, loss_v1=0, loss_v2=0, nll_loss=1.253, ntokens=1115.1, nsentences=32, sample_size=1115.1, sample_size_v1=0, sample_size_v2=0, ppl=2.38, wps=290, ups=0.26, wpb=1115.1, bsz=32, num_updates=17530, lr=7.04912e-06, gnorm=9.188, clip=100, loss_scale=32, train_wall=38, gb_free=7.9, wall=67675
2023-05-21 12:45:56 - progress_bar.py[line:272] - INFO: epoch 011:    252 / 1732 loss=2.466, loss_v1=0, loss_v2=0, nll_loss=1.274, ntokens=1167.7, nsentences=32, sample_size=1167.7, sample_size_v1=0, sample_size_v2=0, ppl=2.42, wps=304.1, ups=0.26, wpb=1167.7, bsz=32, num_updates=17540, lr=7.04707e-06, gnorm=8.498, clip=100, loss_scale=32, train_wall=38, gb_free=8.4, wall=67713
2023-05-21 12:46:34 - progress_bar.py[line:272] - INFO: epoch 011:    262 / 1732 loss=2.473, loss_v1=0, loss_v2=0, nll_loss=1.283, ntokens=1134.1, nsentences=32, sample_size=1134.1, sample_size_v1=0, sample_size_v2=0, ppl=2.43, wps=296.9, ups=0.26, wpb=1134.1, bsz=32, num_updates=17550, lr=7.04502e-06, gnorm=9.289, clip=100, loss_scale=32, train_wall=38, gb_free=8.5, wall=67751
2023-05-21 12:47:12 - progress_bar.py[line:272] - INFO: epoch 011:    272 / 1732 loss=2.428, loss_v1=0, loss_v2=0, nll_loss=1.232, ntokens=1139, nsentences=32, sample_size=1139, sample_size_v1=0, sample_size_v2=0, ppl=2.35, wps=297.5, ups=0.26, wpb=1139, bsz=32, num_updates=17560, lr=7.04297e-06, gnorm=8.259, clip=100, loss_scale=32, train_wall=38, gb_free=8.9, wall=67789
2023-05-21 12:47:51 - progress_bar.py[line:272] - INFO: epoch 011:    282 / 1732 loss=2.463, loss_v1=0, loss_v2=0, nll_loss=1.272, ntokens=1161.5, nsentences=32, sample_size=1161.5, sample_size_v1=0, sample_size_v2=0, ppl=2.41, wps=300.2, ups=0.26, wpb=1161.5, bsz=32, num_updates=17570, lr=7.04093e-06, gnorm=8.626, clip=100, loss_scale=32, train_wall=39, gb_free=7.8, wall=67828
2023-05-21 12:48:29 - progress_bar.py[line:272] - INFO: epoch 011:    292 / 1732 loss=2.425, loss_v1=0, loss_v2=0, nll_loss=1.229, ntokens=1114.9, nsentences=32, sample_size=1114.9, sample_size_v1=0, sample_size_v2=0, ppl=2.34, wps=290.3, ups=0.26, wpb=1114.9, bsz=32, num_updates=17580, lr=7.03888e-06, gnorm=9.018, clip=100, loss_scale=32, train_wall=38, gb_free=8.6, wall=67866
2023-05-21 12:49:08 - progress_bar.py[line:272] - INFO: epoch 011:    302 / 1732 loss=2.44, loss_v1=0, loss_v2=0, nll_loss=1.246, ntokens=1109.4, nsentences=32, sample_size=1109.4, sample_size_v1=0, sample_size_v2=0, ppl=2.37, wps=288.5, ups=0.26, wpb=1109.4, bsz=32, num_updates=17590, lr=7.03683e-06, gnorm=9.408, clip=100, loss_scale=32, train_wall=38, gb_free=8.8, wall=67905
2023-05-21 12:49:46 - progress_bar.py[line:272] - INFO: epoch 011:    312 / 1732 loss=2.425, loss_v1=0, loss_v2=0, nll_loss=1.228, ntokens=1061.9, nsentences=32, sample_size=1061.9, sample_size_v1=0, sample_size_v2=0, ppl=2.34, wps=275.9, ups=0.26, wpb=1061.9, bsz=32, num_updates=17600, lr=7.03478e-06, gnorm=9.164, clip=100, loss_scale=32, train_wall=38, gb_free=8.6, wall=67943
2023-05-21 12:50:24 - progress_bar.py[line:272] - INFO: epoch 011:    322 / 1732 loss=2.483, loss_v1=0, loss_v2=0, nll_loss=1.294, ntokens=1000.1, nsentences=32, sample_size=1000.1, sample_size_v1=0, sample_size_v2=0, ppl=2.45, wps=262.9, ups=0.26, wpb=1000.1, bsz=32, num_updates=17610, lr=7.03274e-06, gnorm=10.004, clip=100, loss_scale=32, train_wall=38, gb_free=8.5, wall=67981
2023-05-21 12:51:03 - progress_bar.py[line:272] - INFO: epoch 011:    332 / 1732 loss=2.462, loss_v1=0, loss_v2=0, nll_loss=1.27, ntokens=1031.9, nsentences=32, sample_size=1031.9, sample_size_v1=0, sample_size_v2=0, ppl=2.41, wps=270, ups=0.26, wpb=1031.9, bsz=32, num_updates=17620, lr=7.03069e-06, gnorm=9.567, clip=100, loss_scale=32, train_wall=38, gb_free=8.5, wall=68020
2023-05-21 12:51:41 - progress_bar.py[line:272] - INFO: epoch 011:    342 / 1732 loss=2.429, loss_v1=0, loss_v2=0, nll_loss=1.233, ntokens=926.6, nsentences=32, sample_size=926.6, sample_size_v1=0, sample_size_v2=0, ppl=2.35, wps=243.8, ups=0.26, wpb=926.6, bsz=32, num_updates=17630, lr=7.02864e-06, gnorm=10.288, clip=100, loss_scale=32, train_wall=38, gb_free=9.1, wall=68058
2023-05-21 12:52:19 - progress_bar.py[line:272] - INFO: epoch 011:    352 / 1732 loss=2.45, loss_v1=0, loss_v2=0, nll_loss=1.259, ntokens=952.9, nsentences=32, sample_size=952.9, sample_size_v1=0, sample_size_v2=0, ppl=2.39, wps=250.1, ups=0.26, wpb=952.9, bsz=32, num_updates=17640, lr=7.0266e-06, gnorm=9.918, clip=100, loss_scale=32, train_wall=38, gb_free=9, wall=68096
2023-05-21 12:52:57 - progress_bar.py[line:272] - INFO: epoch 011:    362 / 1732 loss=2.483, loss_v1=0, loss_v2=0, nll_loss=1.295, ntokens=940.7, nsentences=32, sample_size=940.7, sample_size_v1=0, sample_size_v2=0, ppl=2.45, wps=247.5, ups=0.26, wpb=940.7, bsz=32, num_updates=17650, lr=7.02455e-06, gnorm=10.839, clip=100, loss_scale=32, train_wall=38, gb_free=8.5, wall=68134
2023-05-21 12:53:35 - progress_bar.py[line:272] - INFO: epoch 011:    372 / 1732 loss=2.484, loss_v1=0, loss_v2=0, nll_loss=1.293, ntokens=975.5, nsentences=32, sample_size=975.5, sample_size_v1=0, sample_size_v2=0, ppl=2.45, wps=257.2, ups=0.26, wpb=975.5, bsz=32, num_updates=17660, lr=7.0225e-06, gnorm=10.098, clip=100, loss_scale=32, train_wall=38, gb_free=8.9, wall=68172
2023-05-21 12:54:13 - progress_bar.py[line:272] - INFO: epoch 011:    382 / 1732 loss=2.464, loss_v1=0, loss_v2=0, nll_loss=1.271, ntokens=1062, nsentences=32, sample_size=1062, sample_size_v1=0, sample_size_v2=0, ppl=2.41, wps=279.4, ups=0.26, wpb=1062, bsz=32, num_updates=17670, lr=7.02045e-06, gnorm=9.358, clip=100, loss_scale=32, train_wall=38, gb_free=8.4, wall=68210
2023-05-21 12:54:51 - progress_bar.py[line:272] - INFO: epoch 011:    392 / 1732 loss=2.457, loss_v1=0, loss_v2=0, nll_loss=1.264, ntokens=1004.1, nsentences=32, sample_size=1004.1, sample_size_v1=0, sample_size_v2=0, ppl=2.4, wps=264.7, ups=0.26, wpb=1004.1, bsz=32, num_updates=17680, lr=7.01841e-06, gnorm=8.962, clip=100, loss_scale=32, train_wall=38, gb_free=9.1, wall=68248
2023-05-21 12:55:29 - progress_bar.py[line:272] - INFO: epoch 011:    402 / 1732 loss=2.44, loss_v1=0, loss_v2=0, nll_loss=1.247, ntokens=1005.2, nsentences=32, sample_size=1005.2, sample_size_v1=0, sample_size_v2=0, ppl=2.37, wps=264.1, ups=0.26, wpb=1005.2, bsz=32, num_updates=17690, lr=7.01636e-06, gnorm=11.037, clip=100, loss_scale=32, train_wall=38, gb_free=8.5, wall=68286
2023-05-21 12:56:07 - progress_bar.py[line:272] - INFO: epoch 011:    412 / 1732 loss=2.433, loss_v1=0, loss_v2=0, nll_loss=1.237, ntokens=1091.2, nsentences=32, sample_size=1091.2, sample_size_v1=0, sample_size_v2=0, ppl=2.36, wps=286.6, ups=0.26, wpb=1091.2, bsz=32, num_updates=17700, lr=7.01431e-06, gnorm=9.906, clip=100, loss_scale=32, train_wall=38, gb_free=8.4, wall=68324
2023-05-21 12:56:45 - progress_bar.py[line:272] - INFO: epoch 011:    422 / 1732 loss=2.427, loss_v1=0, loss_v2=0, nll_loss=1.233, ntokens=1011.2, nsentences=32, sample_size=1011.2, sample_size_v1=0, sample_size_v2=0, ppl=2.35, wps=264.8, ups=0.26, wpb=1011.2, bsz=32, num_updates=17710, lr=7.01226e-06, gnorm=10.719, clip=100, loss_scale=32, train_wall=38, gb_free=8.1, wall=68362
2023-05-21 12:57:23 - progress_bar.py[line:272] - INFO: epoch 011:    432 / 1732 loss=2.439, loss_v1=0, loss_v2=0, nll_loss=1.244, ntokens=1006.8, nsentences=32, sample_size=1006.8, sample_size_v1=0, sample_size_v2=0, ppl=2.37, wps=264.6, ups=0.26, wpb=1006.8, bsz=32, num_updates=17720, lr=7.01022e-06, gnorm=9.8, clip=100, loss_scale=32, train_wall=38, gb_free=9, wall=68400
2023-05-21 12:58:01 - progress_bar.py[line:272] - INFO: epoch 011:    442 / 1732 loss=2.466, loss_v1=0, loss_v2=0, nll_loss=1.275, ntokens=979.7, nsentences=32, sample_size=979.7, sample_size_v1=0, sample_size_v2=0, ppl=2.42, wps=258.4, ups=0.26, wpb=979.7, bsz=32, num_updates=17730, lr=7.00817e-06, gnorm=9.194, clip=100, loss_scale=32, train_wall=38, gb_free=8.2, wall=68438
2023-05-21 12:58:39 - progress_bar.py[line:272] - INFO: epoch 011:    452 / 1732 loss=2.455, loss_v1=0, loss_v2=0, nll_loss=1.263, ntokens=913.2, nsentences=32, sample_size=913.2, sample_size_v1=0, sample_size_v2=0, ppl=2.4, wps=239.6, ups=0.26, wpb=913.2, bsz=32, num_updates=17740, lr=7.00612e-06, gnorm=11.413, clip=100, loss_scale=32, train_wall=38, gb_free=9.2, wall=68476
2023-05-21 12:59:17 - progress_bar.py[line:272] - INFO: epoch 011:    462 / 1732 loss=2.473, loss_v1=0, loss_v2=0, nll_loss=1.283, ntokens=1070.3, nsentences=32, sample_size=1070.3, sample_size_v1=0, sample_size_v2=0, ppl=2.43, wps=281, ups=0.26, wpb=1070.3, bsz=32, num_updates=17750, lr=7.00407e-06, gnorm=9.189, clip=100, loss_scale=32, train_wall=38, gb_free=8.2, wall=68514
2023-05-21 12:59:55 - progress_bar.py[line:272] - INFO: epoch 011:    472 / 1732 loss=2.46, loss_v1=0, loss_v2=0, nll_loss=1.267, ntokens=1036.2, nsentences=32, sample_size=1036.2, sample_size_v1=0, sample_size_v2=0, ppl=2.41, wps=270, ups=0.26, wpb=1036.2, bsz=32, num_updates=17760, lr=7.00203e-06, gnorm=9.766, clip=100, loss_scale=32, train_wall=38, gb_free=8.2, wall=68553
2023-05-21 13:00:33 - progress_bar.py[line:272] - INFO: epoch 011:    482 / 1732 loss=2.453, loss_v1=0, loss_v2=0, nll_loss=1.259, ntokens=990.8, nsentences=32, sample_size=990.8, sample_size_v1=0, sample_size_v2=0, ppl=2.39, wps=260.2, ups=0.26, wpb=990.8, bsz=32, num_updates=17770, lr=6.99998e-06, gnorm=10.75, clip=100, loss_scale=32, train_wall=38, gb_free=9.1, wall=68591
2023-05-21 13:01:12 - progress_bar.py[line:272] - INFO: epoch 011:    492 / 1732 loss=2.454, loss_v1=0, loss_v2=0, nll_loss=1.262, ntokens=948.5, nsentences=32, sample_size=948.5, sample_size_v1=0, sample_size_v2=0, ppl=2.4, wps=248, ups=0.26, wpb=948.5, bsz=32, num_updates=17780, lr=6.99793e-06, gnorm=10.703, clip=100, loss_scale=32, train_wall=38, gb_free=8.3, wall=68629
2023-05-21 13:01:50 - progress_bar.py[line:272] - INFO: epoch 011:    502 / 1732 loss=2.438, loss_v1=0, loss_v2=0, nll_loss=1.244, ntokens=961.7, nsentences=32, sample_size=961.7, sample_size_v1=0, sample_size_v2=0, ppl=2.37, wps=253.6, ups=0.26, wpb=961.7, bsz=32, num_updates=17790, lr=6.99588e-06, gnorm=11.872, clip=100, loss_scale=32, train_wall=38, gb_free=8.8, wall=68667
2023-05-21 13:02:28 - progress_bar.py[line:272] - INFO: epoch 011:    512 / 1732 loss=2.481, loss_v1=0, loss_v2=0, nll_loss=1.291, ntokens=1041.1, nsentences=32, sample_size=1041.1, sample_size_v1=0, sample_size_v2=0, ppl=2.45, wps=273.1, ups=0.26, wpb=1041.1, bsz=32, num_updates=17800, lr=6.99384e-06, gnorm=8.896, clip=100, loss_scale=32, train_wall=38, gb_free=7.9, wall=68705
2023-05-21 13:03:06 - progress_bar.py[line:272] - INFO: epoch 011:    522 / 1732 loss=2.433, loss_v1=0, loss_v2=0, nll_loss=1.239, ntokens=995.3, nsentences=32, sample_size=995.3, sample_size_v1=0, sample_size_v2=0, ppl=2.36, wps=263.2, ups=0.26, wpb=995.3, bsz=32, num_updates=17810, lr=6.99179e-06, gnorm=10.719, clip=100, loss_scale=32, train_wall=38, gb_free=8.9, wall=68743
2023-05-21 13:03:44 - progress_bar.py[line:272] - INFO: epoch 011:    532 / 1732 loss=2.455, loss_v1=0, loss_v2=0, nll_loss=1.263, ntokens=942.5, nsentences=32, sample_size=942.5, sample_size_v1=0, sample_size_v2=0, ppl=2.4, wps=248.3, ups=0.26, wpb=942.5, bsz=32, num_updates=17820, lr=6.98974e-06, gnorm=10.878, clip=100, loss_scale=32, train_wall=38, gb_free=9.2, wall=68781
2023-05-21 13:04:22 - progress_bar.py[line:272] - INFO: epoch 011:    542 / 1732 loss=2.459, loss_v1=0, loss_v2=0, nll_loss=1.267, ntokens=994, nsentences=32, sample_size=994, sample_size_v1=0, sample_size_v2=0, ppl=2.41, wps=260.9, ups=0.26, wpb=994, bsz=32, num_updates=17830, lr=6.9877e-06, gnorm=9.729, clip=100, loss_scale=32, train_wall=38, gb_free=8.2, wall=68819
2023-05-21 13:05:00 - progress_bar.py[line:272] - INFO: epoch 011:    552 / 1732 loss=2.483, loss_v1=0, loss_v2=0, nll_loss=1.294, ntokens=1035.9, nsentences=32, sample_size=1035.9, sample_size_v1=0, sample_size_v2=0, ppl=2.45, wps=272.5, ups=0.26, wpb=1035.9, bsz=32, num_updates=17840, lr=6.98565e-06, gnorm=9.766, clip=100, loss_scale=32, train_wall=38, gb_free=8.3, wall=68857
2023-05-21 13:05:38 - progress_bar.py[line:272] - INFO: epoch 011:    562 / 1732 loss=2.467, loss_v1=0, loss_v2=0, nll_loss=1.278, ntokens=1016.1, nsentences=32, sample_size=1016.1, sample_size_v1=0, sample_size_v2=0, ppl=2.42, wps=266, ups=0.26, wpb=1016.1, bsz=32, num_updates=17850, lr=6.9836e-06, gnorm=9.941, clip=100, loss_scale=64, train_wall=38, gb_free=9.2, wall=68895
2023-05-21 13:06:16 - progress_bar.py[line:272] - INFO: epoch 011:    572 / 1732 loss=2.49, loss_v1=0, loss_v2=0, nll_loss=1.3, ntokens=1005.3, nsentences=32, sample_size=1005.3, sample_size_v1=0, sample_size_v2=0, ppl=2.46, wps=262.1, ups=0.26, wpb=1005.3, bsz=32, num_updates=17860, lr=6.98155e-06, gnorm=11.366, clip=100, loss_scale=64, train_wall=38, gb_free=8.3, wall=68933
2023-05-21 13:06:54 - progress_bar.py[line:272] - INFO: epoch 011:    582 / 1732 loss=2.461, loss_v1=0, loss_v2=0, nll_loss=1.268, ntokens=1004.5, nsentences=32, sample_size=1004.5, sample_size_v1=0, sample_size_v2=0, ppl=2.41, wps=262.6, ups=0.26, wpb=1004.5, bsz=32, num_updates=17870, lr=6.97951e-06, gnorm=10.709, clip=100, loss_scale=64, train_wall=38, gb_free=8.3, wall=68972
2023-05-21 13:07:33 - progress_bar.py[line:272] - INFO: epoch 011:    592 / 1732 loss=2.444, loss_v1=0, loss_v2=0, nll_loss=1.249, ntokens=950.1, nsentences=32, sample_size=950.1, sample_size_v1=0, sample_size_v2=0, ppl=2.38, wps=248.7, ups=0.26, wpb=950.1, bsz=32, num_updates=17880, lr=6.97746e-06, gnorm=11.013, clip=100, loss_scale=64, train_wall=38, gb_free=8.2, wall=69010
2023-05-21 13:08:11 - progress_bar.py[line:272] - INFO: epoch 011:    602 / 1732 loss=2.425, loss_v1=0, loss_v2=0, nll_loss=1.231, ntokens=920.7, nsentences=32, sample_size=920.7, sample_size_v1=0, sample_size_v2=0, ppl=2.35, wps=242.6, ups=0.26, wpb=920.7, bsz=32, num_updates=17890, lr=6.97541e-06, gnorm=11.012, clip=100, loss_scale=64, train_wall=38, gb_free=9.1, wall=69048
2023-05-21 13:08:49 - progress_bar.py[line:272] - INFO: epoch 011:    612 / 1732 loss=2.456, loss_v1=0, loss_v2=0, nll_loss=1.267, ntokens=908, nsentences=32, sample_size=908, sample_size_v1=0, sample_size_v2=0, ppl=2.41, wps=239.7, ups=0.26, wpb=908, bsz=32, num_updates=17900, lr=6.97336e-06, gnorm=11.821, clip=100, loss_scale=64, train_wall=38, gb_free=8.9, wall=69086
2023-05-21 13:09:26 - progress_bar.py[line:272] - INFO: epoch 011:    622 / 1732 loss=2.483, loss_v1=0, loss_v2=0, nll_loss=1.293, ntokens=856.3, nsentences=32, sample_size=856.3, sample_size_v1=0, sample_size_v2=0, ppl=2.45, wps=226.8, ups=0.26, wpb=856.3, bsz=32, num_updates=17910, lr=6.97132e-06, gnorm=12.477, clip=100, loss_scale=64, train_wall=38, gb_free=8.6, wall=69123
2023-05-21 13:10:04 - progress_bar.py[line:272] - INFO: epoch 011:    632 / 1732 loss=2.455, loss_v1=0, loss_v2=0, nll_loss=1.262, ntokens=935.9, nsentences=32, sample_size=935.9, sample_size_v1=0, sample_size_v2=0, ppl=2.4, wps=246.5, ups=0.26, wpb=935.9, bsz=32, num_updates=17920, lr=6.96927e-06, gnorm=12.603, clip=100, loss_scale=64, train_wall=38, gb_free=8.9, wall=69161
2023-05-21 13:10:42 - progress_bar.py[line:272] - INFO: epoch 011:    642 / 1732 loss=2.466, loss_v1=0, loss_v2=0, nll_loss=1.275, ntokens=946.6, nsentences=32, sample_size=946.6, sample_size_v1=0, sample_size_v2=0, ppl=2.42, wps=249.3, ups=0.26, wpb=946.6, bsz=32, num_updates=17930, lr=6.96722e-06, gnorm=11.002, clip=100, loss_scale=64, train_wall=38, gb_free=8.4, wall=69199
2023-05-21 13:11:20 - progress_bar.py[line:272] - INFO: epoch 011:    652 / 1732 loss=2.467, loss_v1=0, loss_v2=0, nll_loss=1.277, ntokens=952.7, nsentences=32, sample_size=952.7, sample_size_v1=0, sample_size_v2=0, ppl=2.42, wps=252.8, ups=0.27, wpb=952.7, bsz=32, num_updates=17940, lr=6.96517e-06, gnorm=10.891, clip=100, loss_scale=64, train_wall=38, gb_free=9.5, wall=69237
2023-05-21 13:11:57 - progress_bar.py[line:272] - INFO: epoch 011:    662 / 1732 loss=2.47, loss_v1=0, loss_v2=0, nll_loss=1.279, ntokens=882.3, nsentences=32, sample_size=882.3, sample_size_v1=0, sample_size_v2=0, ppl=2.43, wps=235.2, ups=0.27, wpb=882.3, bsz=32, num_updates=17950, lr=6.96313e-06, gnorm=13.088, clip=100, loss_scale=64, train_wall=37, gb_free=7.8, wall=69275
2023-05-21 13:12:20 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2023-05-21 13:12:39 - progress_bar.py[line:272] - INFO: epoch 011:    673 / 1732 loss=2.49, loss_v1=0, loss_v2=0, nll_loss=1.301, ntokens=942.7, nsentences=32, sample_size=942.7, sample_size_v1=0, sample_size_v2=0, ppl=2.46, wps=227.2, ups=0.24, wpb=942.7, bsz=32, num_updates=17960, lr=6.96108e-06, gnorm=12.184, clip=100, loss_scale=32, train_wall=41, gb_free=9, wall=69316
2023-05-21 13:13:17 - progress_bar.py[line:272] - INFO: epoch 011:    683 / 1732 loss=2.448, loss_v1=0, loss_v2=0, nll_loss=1.255, ntokens=960.5, nsentences=32, sample_size=960.5, sample_size_v1=0, sample_size_v2=0, ppl=2.39, wps=253.1, ups=0.26, wpb=960.5, bsz=32, num_updates=17970, lr=6.95903e-06, gnorm=11.581, clip=100, loss_scale=32, train_wall=38, gb_free=9.2, wall=69354
2023-05-21 13:13:55 - progress_bar.py[line:272] - INFO: epoch 011:    693 / 1732 loss=2.473, loss_v1=0, loss_v2=0, nll_loss=1.282, ntokens=962.9, nsentences=32, sample_size=962.9, sample_size_v1=0, sample_size_v2=0, ppl=2.43, wps=253.1, ups=0.26, wpb=962.9, bsz=32, num_updates=17980, lr=6.95698e-06, gnorm=11.705, clip=100, loss_scale=32, train_wall=38, gb_free=8.3, wall=69392
2023-05-21 13:14:33 - progress_bar.py[line:272] - INFO: epoch 011:    703 / 1732 loss=2.424, loss_v1=0, loss_v2=0, nll_loss=1.228, ntokens=972.9, nsentences=32, sample_size=972.9, sample_size_v1=0, sample_size_v2=0, ppl=2.34, wps=256, ups=0.26, wpb=972.9, bsz=32, num_updates=17990, lr=6.95494e-06, gnorm=11.019, clip=100, loss_scale=32, train_wall=38, gb_free=8.9, wall=69430
2023-05-21 13:15:11 - progress_bar.py[line:272] - INFO: epoch 011:    713 / 1732 loss=2.48, loss_v1=0, loss_v2=0, nll_loss=1.289, ntokens=898.6, nsentences=32, sample_size=898.6, sample_size_v1=0, sample_size_v2=0, ppl=2.44, wps=238.1, ups=0.26, wpb=898.6, bsz=32, num_updates=18000, lr=6.95289e-06, gnorm=12.046, clip=100, loss_scale=32, train_wall=38, gb_free=9.1, wall=69468
2023-05-21 13:15:48 - progress_bar.py[line:272] - INFO: epoch 011:    723 / 1732 loss=2.432, loss_v1=0, loss_v2=0, nll_loss=1.238, ntokens=877.5, nsentences=32, sample_size=877.5, sample_size_v1=0, sample_size_v2=0, ppl=2.36, wps=233, ups=0.27, wpb=877.5, bsz=32, num_updates=18010, lr=6.95084e-06, gnorm=10.641, clip=100, loss_scale=32, train_wall=38, gb_free=9.2, wall=69506
2023-05-21 13:16:26 - progress_bar.py[line:272] - INFO: epoch 011:    733 / 1732 loss=2.431, loss_v1=0, loss_v2=0, nll_loss=1.237, ntokens=959.6, nsentences=32, sample_size=959.6, sample_size_v1=0, sample_size_v2=0, ppl=2.36, wps=253.1, ups=0.26, wpb=959.6, bsz=32, num_updates=18020, lr=6.9488e-06, gnorm=10.262, clip=100, loss_scale=32, train_wall=38, gb_free=8.2, wall=69543
2023-05-21 13:17:04 - progress_bar.py[line:272] - INFO: epoch 011:    743 / 1732 loss=2.434, loss_v1=0, loss_v2=0, nll_loss=1.239, ntokens=991.8, nsentences=32, sample_size=991.8, sample_size_v1=0, sample_size_v2=0, ppl=2.36, wps=260.5, ups=0.26, wpb=991.8, bsz=32, num_updates=18030, lr=6.94675e-06, gnorm=11.645, clip=100, loss_scale=32, train_wall=38, gb_free=8.7, wall=69582
2023-05-21 13:17:42 - progress_bar.py[line:272] - INFO: epoch 011:    753 / 1732 loss=2.448, loss_v1=0, loss_v2=0, nll_loss=1.254, ntokens=968.6, nsentences=32, sample_size=968.6, sample_size_v1=0, sample_size_v2=0, ppl=2.38, wps=254.2, ups=0.26, wpb=968.6, bsz=32, num_updates=18040, lr=6.9447e-06, gnorm=11.036, clip=100, loss_scale=32, train_wall=38, gb_free=8.7, wall=69620
2023-05-21 13:18:20 - progress_bar.py[line:272] - INFO: epoch 011:    763 / 1732 loss=2.437, loss_v1=0, loss_v2=0, nll_loss=1.243, ntokens=964, nsentences=32, sample_size=964, sample_size_v1=0, sample_size_v2=0, ppl=2.37, wps=255.4, ups=0.26, wpb=964, bsz=32, num_updates=18050, lr=6.94265e-06, gnorm=11.07, clip=100, loss_scale=32, train_wall=38, gb_free=8.8, wall=69657
2023-05-21 13:18:58 - progress_bar.py[line:272] - INFO: epoch 011:    773 / 1732 loss=2.441, loss_v1=0, loss_v2=0, nll_loss=1.248, ntokens=971.7, nsentences=32, sample_size=971.7, sample_size_v1=0, sample_size_v2=0, ppl=2.38, wps=255.4, ups=0.26, wpb=971.7, bsz=32, num_updates=18060, lr=6.94061e-06, gnorm=12.433, clip=100, loss_scale=32, train_wall=38, gb_free=8.8, wall=69695
2023-05-21 13:19:36 - progress_bar.py[line:272] - INFO: epoch 011:    783 / 1732 loss=2.454, loss_v1=0, loss_v2=0, nll_loss=1.262, ntokens=1008.4, nsentences=32, sample_size=1008.4, sample_size_v1=0, sample_size_v2=0, ppl=2.4, wps=265.4, ups=0.26, wpb=1008.4, bsz=32, num_updates=18070, lr=6.93856e-06, gnorm=10.364, clip=100, loss_scale=32, train_wall=38, gb_free=8.4, wall=69733
2023-05-21 13:20:14 - progress_bar.py[line:272] - INFO: epoch 011:    793 / 1732 loss=2.439, loss_v1=0, loss_v2=0, nll_loss=1.244, ntokens=1034.6, nsentences=32, sample_size=1034.6, sample_size_v1=0, sample_size_v2=0, ppl=2.37, wps=272, ups=0.26, wpb=1034.6, bsz=32, num_updates=18080, lr=6.93651e-06, gnorm=10.7, clip=100, loss_scale=32, train_wall=38, gb_free=8.8, wall=69772
2023-05-21 13:20:52 - progress_bar.py[line:272] - INFO: epoch 011:    803 / 1732 loss=2.441, loss_v1=0, loss_v2=0, nll_loss=1.248, ntokens=964.4, nsentences=32, sample_size=964.4, sample_size_v1=0, sample_size_v2=0, ppl=2.37, wps=255, ups=0.26, wpb=964.4, bsz=32, num_updates=18090, lr=6.93446e-06, gnorm=10.785, clip=100, loss_scale=32, train_wall=38, gb_free=8.1, wall=69809
2023-05-21 13:21:30 - progress_bar.py[line:272] - INFO: epoch 011:    813 / 1732 loss=2.463, loss_v1=0, loss_v2=0, nll_loss=1.271, ntokens=940.9, nsentences=32, sample_size=940.9, sample_size_v1=0, sample_size_v2=0, ppl=2.41, wps=248.7, ups=0.26, wpb=940.9, bsz=32, num_updates=18100, lr=6.93242e-06, gnorm=12.042, clip=100, loss_scale=32, train_wall=38, gb_free=7.6, wall=69847
2023-05-21 13:22:08 - progress_bar.py[line:272] - INFO: epoch 011:    823 / 1732 loss=2.447, loss_v1=0, loss_v2=0, nll_loss=1.252, ntokens=915.1, nsentences=32, sample_size=915.1, sample_size_v1=0, sample_size_v2=0, ppl=2.38, wps=241.3, ups=0.26, wpb=915.1, bsz=32, num_updates=18110, lr=6.93037e-06, gnorm=12.15, clip=100, loss_scale=32, train_wall=38, gb_free=8.3, wall=69885
2023-05-21 13:22:46 - progress_bar.py[line:272] - INFO: epoch 011:    833 / 1732 loss=2.457, loss_v1=0, loss_v2=0, nll_loss=1.264, ntokens=907.5, nsentences=32, sample_size=907.5, sample_size_v1=0, sample_size_v2=0, ppl=2.4, wps=241.3, ups=0.27, wpb=907.5, bsz=32, num_updates=18120, lr=6.92832e-06, gnorm=11.848, clip=100, loss_scale=32, train_wall=38, gb_free=9.1, wall=69923
2023-05-21 13:23:23 - progress_bar.py[line:272] - INFO: epoch 011:    843 / 1732 loss=2.427, loss_v1=0, loss_v2=0, nll_loss=1.229, ntokens=950.7, nsentences=32, sample_size=950.7, sample_size_v1=0, sample_size_v2=0, ppl=2.34, wps=251.5, ups=0.26, wpb=950.7, bsz=32, num_updates=18130, lr=6.92627e-06, gnorm=10.429, clip=100, loss_scale=32, train_wall=38, gb_free=9, wall=69961
2023-05-21 13:24:01 - progress_bar.py[line:272] - INFO: epoch 011:    853 / 1732 loss=2.442, loss_v1=0, loss_v2=0, nll_loss=1.248, ntokens=1006.3, nsentences=32, sample_size=1006.3, sample_size_v1=0, sample_size_v2=0, ppl=2.38, wps=263.9, ups=0.26, wpb=1006.3, bsz=32, num_updates=18140, lr=6.92423e-06, gnorm=10.731, clip=100, loss_scale=32, train_wall=38, gb_free=8.3, wall=69999
2023-05-21 13:24:39 - progress_bar.py[line:272] - INFO: epoch 011:    863 / 1732 loss=2.449, loss_v1=0, loss_v2=0, nll_loss=1.257, ntokens=933.3, nsentences=32, sample_size=933.3, sample_size_v1=0, sample_size_v2=0, ppl=2.39, wps=247.2, ups=0.26, wpb=933.3, bsz=32, num_updates=18150, lr=6.92218e-06, gnorm=13.413, clip=100, loss_scale=32, train_wall=38, gb_free=8.6, wall=70036
2023-05-21 13:25:17 - progress_bar.py[line:272] - INFO: epoch 011:    873 / 1732 loss=2.428, loss_v1=0, loss_v2=0, nll_loss=1.232, ntokens=966.4, nsentences=32, sample_size=966.4, sample_size_v1=0, sample_size_v2=0, ppl=2.35, wps=255.1, ups=0.26, wpb=966.4, bsz=32, num_updates=18160, lr=6.92013e-06, gnorm=10.769, clip=100, loss_scale=32, train_wall=38, gb_free=8.6, wall=70074
2023-05-21 13:25:55 - progress_bar.py[line:272] - INFO: epoch 011:    883 / 1732 loss=2.378, loss_v1=0, loss_v2=0, nll_loss=1.178, ntokens=985.5, nsentences=32, sample_size=985.5, sample_size_v1=0, sample_size_v2=0, ppl=2.26, wps=257.4, ups=0.26, wpb=985.5, bsz=32, num_updates=18170, lr=6.91808e-06, gnorm=10.81, clip=100, loss_scale=32, train_wall=38, gb_free=8.5, wall=70113
2023-05-21 13:26:34 - progress_bar.py[line:272] - INFO: epoch 011:    893 / 1732 loss=2.399, loss_v1=0, loss_v2=0, nll_loss=1.202, ntokens=1009.8, nsentences=32, sample_size=1009.8, sample_size_v1=0, sample_size_v2=0, ppl=2.3, wps=262.5, ups=0.26, wpb=1009.8, bsz=32, num_updates=18180, lr=6.91604e-06, gnorm=9.791, clip=100, loss_scale=32, train_wall=38, gb_free=8.3, wall=70151
2023-05-21 13:27:12 - progress_bar.py[line:272] - INFO: epoch 011:    903 / 1732 loss=2.384, loss_v1=0, loss_v2=0, nll_loss=1.183, ntokens=1049.7, nsentences=32, sample_size=1049.7, sample_size_v1=0, sample_size_v2=0, ppl=2.27, wps=276.3, ups=0.26, wpb=1049.7, bsz=32, num_updates=18190, lr=6.91399e-06, gnorm=10.285, clip=100, loss_scale=32, train_wall=38, gb_free=8.7, wall=70189
2023-05-21 13:27:50 - progress_bar.py[line:272] - INFO: epoch 011:    913 / 1732 loss=2.477, loss_v1=0, loss_v2=0, nll_loss=1.288, ntokens=930.6, nsentences=32, sample_size=930.6, sample_size_v1=0, sample_size_v2=0, ppl=2.44, wps=245.7, ups=0.26, wpb=930.6, bsz=32, num_updates=18200, lr=6.91194e-06, gnorm=11.414, clip=100, loss_scale=32, train_wall=38, gb_free=8.2, wall=70227
2023-05-21 13:28:28 - progress_bar.py[line:272] - INFO: epoch 011:    923 / 1732 loss=2.41, loss_v1=0, loss_v2=0, nll_loss=1.212, ntokens=1023.3, nsentences=32, sample_size=1023.3, sample_size_v1=0, sample_size_v2=0, ppl=2.32, wps=266.3, ups=0.26, wpb=1023.3, bsz=32, num_updates=18210, lr=6.90989e-06, gnorm=10.359, clip=100, loss_scale=32, train_wall=38, gb_free=8.3, wall=70265
2023-05-21 13:29:07 - progress_bar.py[line:272] - INFO: epoch 011:    933 / 1732 loss=2.412, loss_v1=0, loss_v2=0, nll_loss=1.215, ntokens=1034.6, nsentences=32, sample_size=1034.6, sample_size_v1=0, sample_size_v2=0, ppl=2.32, wps=268, ups=0.26, wpb=1034.6, bsz=32, num_updates=18220, lr=6.90785e-06, gnorm=10.777, clip=100, loss_scale=32, train_wall=39, gb_free=8.2, wall=70304
2023-05-21 13:29:45 - progress_bar.py[line:272] - INFO: epoch 011:    943 / 1732 loss=2.434, loss_v1=0, loss_v2=0, nll_loss=1.239, ntokens=1054.1, nsentences=32, sample_size=1054.1, sample_size_v1=0, sample_size_v2=0, ppl=2.36, wps=274.2, ups=0.26, wpb=1054.1, bsz=32, num_updates=18230, lr=6.9058e-06, gnorm=9.522, clip=100, loss_scale=32, train_wall=38, gb_free=8.4, wall=70342
2023-05-21 13:30:24 - progress_bar.py[line:272] - INFO: epoch 011:    953 / 1732 loss=2.419, loss_v1=0, loss_v2=0, nll_loss=1.221, ntokens=1032.2, nsentences=32, sample_size=1032.2, sample_size_v1=0, sample_size_v2=0, ppl=2.33, wps=267.2, ups=0.26, wpb=1032.2, bsz=32, num_updates=18240, lr=6.90375e-06, gnorm=9.417, clip=100, loss_scale=32, train_wall=39, gb_free=8.1, wall=70381
2023-05-21 13:31:02 - progress_bar.py[line:272] - INFO: epoch 011:    963 / 1732 loss=2.428, loss_v1=0, loss_v2=0, nll_loss=1.235, ntokens=1069.2, nsentences=32, sample_size=1069.2, sample_size_v1=0, sample_size_v2=0, ppl=2.35, wps=277.4, ups=0.26, wpb=1069.2, bsz=32, num_updates=18250, lr=6.90171e-06, gnorm=9.884, clip=100, loss_scale=32, train_wall=38, gb_free=8.4, wall=70420
2023-05-21 13:31:41 - progress_bar.py[line:272] - INFO: epoch 011:    973 / 1732 loss=2.443, loss_v1=0, loss_v2=0, nll_loss=1.25, ntokens=1034.1, nsentences=32, sample_size=1034.1, sample_size_v1=0, sample_size_v2=0, ppl=2.38, wps=268.4, ups=0.26, wpb=1034.1, bsz=32, num_updates=18260, lr=6.89966e-06, gnorm=10.892, clip=100, loss_scale=32, train_wall=38, gb_free=8.3, wall=70458
2023-05-21 13:32:19 - progress_bar.py[line:272] - INFO: epoch 011:    983 / 1732 loss=2.425, loss_v1=0, loss_v2=0, nll_loss=1.23, ntokens=1026.6, nsentences=32, sample_size=1026.6, sample_size_v1=0, sample_size_v2=0, ppl=2.35, wps=266.4, ups=0.26, wpb=1026.6, bsz=32, num_updates=18270, lr=6.89761e-06, gnorm=10.492, clip=100, loss_scale=32, train_wall=38, gb_free=8.3, wall=70497
2023-05-21 13:32:58 - progress_bar.py[line:272] - INFO: epoch 011:    993 / 1732 loss=2.426, loss_v1=0, loss_v2=0, nll_loss=1.228, ntokens=1041.8, nsentences=32, sample_size=1041.8, sample_size_v1=0, sample_size_v2=0, ppl=2.34, wps=271.6, ups=0.26, wpb=1041.8, bsz=32, num_updates=18280, lr=6.89556e-06, gnorm=11.076, clip=100, loss_scale=32, train_wall=38, gb_free=8.4, wall=70535
2023-05-21 13:33:36 - progress_bar.py[line:272] - INFO: epoch 011:   1003 / 1732 loss=2.41, loss_v1=0, loss_v2=0, nll_loss=1.213, ntokens=1018, nsentences=32, sample_size=1018, sample_size_v1=0, sample_size_v2=0, ppl=2.32, wps=266, ups=0.26, wpb=1018, bsz=32, num_updates=18290, lr=6.89352e-06, gnorm=9.818, clip=100, loss_scale=32, train_wall=38, gb_free=8.4, wall=70573
2023-05-21 13:34:14 - progress_bar.py[line:272] - INFO: epoch 011:   1013 / 1732 loss=2.427, loss_v1=0, loss_v2=0, nll_loss=1.231, ntokens=965, nsentences=32, sample_size=965, sample_size_v1=0, sample_size_v2=0, ppl=2.35, wps=253.4, ups=0.26, wpb=965, bsz=32, num_updates=18300, lr=6.89147e-06, gnorm=10.079, clip=100, loss_scale=32, train_wall=38, gb_free=9.1, wall=70611
2023-05-21 13:34:53 - progress_bar.py[line:272] - INFO: epoch 011:   1023 / 1732 loss=2.413, loss_v1=0, loss_v2=0, nll_loss=1.216, ntokens=1087.1, nsentences=32, sample_size=1087.1, sample_size_v1=0, sample_size_v2=0, ppl=2.32, wps=280.9, ups=0.26, wpb=1087.1, bsz=32, num_updates=18310, lr=6.88942e-06, gnorm=10.34, clip=100, loss_scale=32, train_wall=39, gb_free=8.1, wall=70650
2023-05-21 13:35:32 - progress_bar.py[line:272] - INFO: epoch 011:   1033 / 1732 loss=2.418, loss_v1=0, loss_v2=0, nll_loss=1.222, ntokens=1100.3, nsentences=32, sample_size=1100.3, sample_size_v1=0, sample_size_v2=0, ppl=2.33, wps=282.5, ups=0.26, wpb=1100.3, bsz=32, num_updates=18320, lr=6.88737e-06, gnorm=9.293, clip=100, loss_scale=32, train_wall=39, gb_free=8.8, wall=70689
2023-05-21 13:36:11 - progress_bar.py[line:272] - INFO: epoch 011:   1043 / 1732 loss=2.42, loss_v1=0, loss_v2=0, nll_loss=1.222, ntokens=1068.2, nsentences=32, sample_size=1068.2, sample_size_v1=0, sample_size_v2=0, ppl=2.33, wps=275.9, ups=0.26, wpb=1068.2, bsz=32, num_updates=18330, lr=6.88533e-06, gnorm=10.211, clip=100, loss_scale=32, train_wall=39, gb_free=8.3, wall=70728
2023-05-21 13:36:49 - progress_bar.py[line:272] - INFO: epoch 011:   1053 / 1732 loss=2.421, loss_v1=0, loss_v2=0, nll_loss=1.223, ntokens=1062.8, nsentences=32, sample_size=1062.8, sample_size_v1=0, sample_size_v2=0, ppl=2.33, wps=277.8, ups=0.26, wpb=1062.8, bsz=32, num_updates=18340, lr=6.88328e-06, gnorm=11.049, clip=100, loss_scale=32, train_wall=38, gb_free=8.6, wall=70766
2023-05-21 13:37:27 - progress_bar.py[line:272] - INFO: epoch 011:   1063 / 1732 loss=2.416, loss_v1=0, loss_v2=0, nll_loss=1.218, ntokens=1030.9, nsentences=32, sample_size=1030.9, sample_size_v1=0, sample_size_v2=0, ppl=2.33, wps=268.1, ups=0.26, wpb=1030.9, bsz=32, num_updates=18350, lr=6.88123e-06, gnorm=11.342, clip=100, loss_scale=32, train_wall=38, gb_free=8.3, wall=70804
2023-05-21 13:38:06 - progress_bar.py[line:272] - INFO: epoch 011:   1073 / 1732 loss=2.438, loss_v1=0, loss_v2=0, nll_loss=1.244, ntokens=999.3, nsentences=32, sample_size=999.3, sample_size_v1=0, sample_size_v2=0, ppl=2.37, wps=258.8, ups=0.26, wpb=999.3, bsz=32, num_updates=18360, lr=6.87918e-06, gnorm=11.187, clip=100, loss_scale=32, train_wall=39, gb_free=8.5, wall=70843
2023-05-21 13:38:45 - progress_bar.py[line:272] - INFO: epoch 011:   1083 / 1732 loss=2.434, loss_v1=0, loss_v2=0, nll_loss=1.239, ntokens=1054.9, nsentences=32, sample_size=1054.9, sample_size_v1=0, sample_size_v2=0, ppl=2.36, wps=272.6, ups=0.26, wpb=1054.9, bsz=32, num_updates=18370, lr=6.87714e-06, gnorm=10.758, clip=100, loss_scale=32, train_wall=39, gb_free=7.6, wall=70882
2023-05-21 13:39:23 - progress_bar.py[line:272] - INFO: epoch 011:   1093 / 1732 loss=2.421, loss_v1=0, loss_v2=0, nll_loss=1.225, ntokens=1060.6, nsentences=32, sample_size=1060.6, sample_size_v1=0, sample_size_v2=0, ppl=2.34, wps=275.5, ups=0.26, wpb=1060.6, bsz=32, num_updates=18380, lr=6.87509e-06, gnorm=10.465, clip=100, loss_scale=32, train_wall=38, gb_free=8.3, wall=70920
2023-05-21 13:40:02 - progress_bar.py[line:272] - INFO: epoch 011:   1103 / 1732 loss=2.43, loss_v1=0, loss_v2=0, nll_loss=1.235, ntokens=1039.1, nsentences=32, sample_size=1039.1, sample_size_v1=0, sample_size_v2=0, ppl=2.35, wps=270.5, ups=0.26, wpb=1039.1, bsz=32, num_updates=18390, lr=6.87304e-06, gnorm=11.196, clip=100, loss_scale=32, train_wall=38, gb_free=8.9, wall=70959
2023-05-21 13:40:40 - progress_bar.py[line:272] - INFO: epoch 011:   1113 / 1732 loss=2.421, loss_v1=0, loss_v2=0, nll_loss=1.224, ntokens=1008.5, nsentences=32, sample_size=1008.5, sample_size_v1=0, sample_size_v2=0, ppl=2.34, wps=261.7, ups=0.26, wpb=1008.5, bsz=32, num_updates=18400, lr=6.87099e-06, gnorm=10.915, clip=100, loss_scale=32, train_wall=38, gb_free=8.5, wall=70997
2023-05-21 13:41:19 - progress_bar.py[line:272] - INFO: epoch 011:   1123 / 1732 loss=2.426, loss_v1=0, loss_v2=0, nll_loss=1.229, ntokens=976.6, nsentences=32, sample_size=976.6, sample_size_v1=0, sample_size_v2=0, ppl=2.34, wps=253.8, ups=0.26, wpb=976.6, bsz=32, num_updates=18410, lr=6.86895e-06, gnorm=10.851, clip=100, loss_scale=32, train_wall=38, gb_free=8.2, wall=71036
2023-05-21 13:41:57 - progress_bar.py[line:272] - INFO: epoch 011:   1133 / 1732 loss=2.438, loss_v1=0, loss_v2=0, nll_loss=1.245, ntokens=965.2, nsentences=32, sample_size=965.2, sample_size_v1=0, sample_size_v2=0, ppl=2.37, wps=251.4, ups=0.26, wpb=965.2, bsz=32, num_updates=18420, lr=6.8669e-06, gnorm=11.463, clip=100, loss_scale=32, train_wall=38, gb_free=7.7, wall=71074
2023-05-21 13:42:35 - progress_bar.py[line:272] - INFO: epoch 011:   1143 / 1732 loss=2.424, loss_v1=0, loss_v2=0, nll_loss=1.227, ntokens=1060.3, nsentences=32, sample_size=1060.3, sample_size_v1=0, sample_size_v2=0, ppl=2.34, wps=275.2, ups=0.26, wpb=1060.3, bsz=32, num_updates=18430, lr=6.86485e-06, gnorm=9.987, clip=100, loss_scale=32, train_wall=38, gb_free=7.9, wall=71113
2023-05-21 13:43:14 - progress_bar.py[line:272] - INFO: epoch 011:   1153 / 1732 loss=2.416, loss_v1=0, loss_v2=0, nll_loss=1.219, ntokens=1009.1, nsentences=32, sample_size=1009.1, sample_size_v1=0, sample_size_v2=0, ppl=2.33, wps=263.5, ups=0.26, wpb=1009.1, bsz=32, num_updates=18440, lr=6.86281e-06, gnorm=10.459, clip=100, loss_scale=32, train_wall=38, gb_free=8.9, wall=71151
2023-05-21 13:43:52 - progress_bar.py[line:272] - INFO: epoch 011:   1163 / 1732 loss=2.404, loss_v1=0, loss_v2=0, nll_loss=1.206, ntokens=999.2, nsentences=32, sample_size=999.2, sample_size_v1=0, sample_size_v2=0, ppl=2.31, wps=259, ups=0.26, wpb=999.2, bsz=32, num_updates=18450, lr=6.86076e-06, gnorm=12.023, clip=100, loss_scale=32, train_wall=39, gb_free=8.4, wall=71190
2023-05-21 13:44:31 - progress_bar.py[line:272] - INFO: epoch 011:   1173 / 1732 loss=2.417, loss_v1=0, loss_v2=0, nll_loss=1.22, ntokens=1077.2, nsentences=32, sample_size=1077.2, sample_size_v1=0, sample_size_v2=0, ppl=2.33, wps=278.9, ups=0.26, wpb=1077.2, bsz=32, num_updates=18460, lr=6.85871e-06, gnorm=10.349, clip=100, loss_scale=32, train_wall=39, gb_free=8.5, wall=71228
2023-05-21 13:45:09 - progress_bar.py[line:272] - INFO: epoch 011:   1183 / 1732 loss=2.41, loss_v1=0, loss_v2=0, nll_loss=1.212, ntokens=988.2, nsentences=32, sample_size=988.2, sample_size_v1=0, sample_size_v2=0, ppl=2.32, wps=257.3, ups=0.26, wpb=988.2, bsz=32, num_updates=18470, lr=6.85666e-06, gnorm=11.136, clip=100, loss_scale=64, train_wall=38, gb_free=8.3, wall=71267
2023-05-21 13:45:48 - progress_bar.py[line:272] - INFO: epoch 011:   1193 / 1732 loss=2.429, loss_v1=0, loss_v2=0, nll_loss=1.233, ntokens=1028.6, nsentences=32, sample_size=1028.6, sample_size_v1=0, sample_size_v2=0, ppl=2.35, wps=267.8, ups=0.26, wpb=1028.6, bsz=32, num_updates=18480, lr=6.85462e-06, gnorm=11.193, clip=100, loss_scale=64, train_wall=38, gb_free=8.5, wall=71305
2023-05-21 13:46:27 - progress_bar.py[line:272] - INFO: epoch 011:   1203 / 1732 loss=2.391, loss_v1=0, loss_v2=0, nll_loss=1.188, ntokens=1142.6, nsentences=32, sample_size=1142.6, sample_size_v1=0, sample_size_v2=0, ppl=2.28, wps=293.3, ups=0.26, wpb=1142.6, bsz=32, num_updates=18490, lr=6.85257e-06, gnorm=9.973, clip=100, loss_scale=64, train_wall=39, gb_free=7.4, wall=71344
2023-05-21 13:47:05 - progress_bar.py[line:272] - INFO: epoch 011:   1213 / 1732 loss=2.417, loss_v1=0, loss_v2=0, nll_loss=1.219, ntokens=1010.9, nsentences=32, sample_size=1010.9, sample_size_v1=0, sample_size_v2=0, ppl=2.33, wps=262.8, ups=0.26, wpb=1010.9, bsz=32, num_updates=18500, lr=6.85052e-06, gnorm=10.568, clip=100, loss_scale=64, train_wall=38, gb_free=8.9, wall=71382
2023-05-21 13:47:44 - progress_bar.py[line:272] - INFO: epoch 011:   1223 / 1732 loss=2.445, loss_v1=0, loss_v2=0, nll_loss=1.252, ntokens=1033.2, nsentences=32, sample_size=1033.2, sample_size_v1=0, sample_size_v2=0, ppl=2.38, wps=268, ups=0.26, wpb=1033.2, bsz=32, num_updates=18510, lr=6.84847e-06, gnorm=11.548, clip=100, loss_scale=64, train_wall=38, gb_free=8.4, wall=71421
2023-05-21 13:47:59 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2023-05-21 13:48:26 - progress_bar.py[line:272] - INFO: epoch 011:   1234 / 1732 loss=2.407, loss_v1=0, loss_v2=0, nll_loss=1.209, ntokens=1032.5, nsentences=32, sample_size=1032.5, sample_size_v1=0, sample_size_v2=0, ppl=2.31, wps=243.9, ups=0.24, wpb=1032.5, bsz=32, num_updates=18520, lr=6.84643e-06, gnorm=10.383, clip=100, loss_scale=32, train_wall=42, gb_free=8.7, wall=71463
2023-05-21 13:49:05 - progress_bar.py[line:272] - INFO: epoch 011:   1244 / 1732 loss=2.351, loss_v1=0, loss_v2=0, nll_loss=1.148, ntokens=1090.2, nsentences=32, sample_size=1090.2, sample_size_v1=0, sample_size_v2=0, ppl=2.22, wps=281.7, ups=0.26, wpb=1090.2, bsz=32, num_updates=18530, lr=6.84438e-06, gnorm=10.792, clip=100, loss_scale=32, train_wall=39, gb_free=8.6, wall=71502
2023-05-21 13:49:43 - progress_bar.py[line:272] - INFO: epoch 011:   1254 / 1732 loss=2.385, loss_v1=0, loss_v2=0, nll_loss=1.183, ntokens=1076, nsentences=32, sample_size=1076, sample_size_v1=0, sample_size_v2=0, ppl=2.27, wps=279.1, ups=0.26, wpb=1076, bsz=32, num_updates=18540, lr=6.84233e-06, gnorm=9.813, clip=100, loss_scale=32, train_wall=39, gb_free=8.8, wall=71541
2023-05-21 13:50:22 - progress_bar.py[line:272] - INFO: epoch 011:   1264 / 1732 loss=2.427, loss_v1=0, loss_v2=0, nll_loss=1.233, ntokens=1095.2, nsentences=32, sample_size=1095.2, sample_size_v1=0, sample_size_v2=0, ppl=2.35, wps=282.9, ups=0.26, wpb=1095.2, bsz=32, num_updates=18550, lr=6.84028e-06, gnorm=10.176, clip=100, loss_scale=32, train_wall=39, gb_free=7.8, wall=71579
2023-05-21 13:51:00 - progress_bar.py[line:272] - INFO: epoch 011:   1274 / 1732 loss=2.419, loss_v1=0, loss_v2=0, nll_loss=1.222, ntokens=1014.1, nsentences=32, sample_size=1014.1, sample_size_v1=0, sample_size_v2=0, ppl=2.33, wps=264.4, ups=0.26, wpb=1014.1, bsz=32, num_updates=18560, lr=6.83824e-06, gnorm=10.567, clip=100, loss_scale=32, train_wall=38, gb_free=8.1, wall=71618
2023-05-21 13:51:39 - progress_bar.py[line:272] - INFO: epoch 011:   1284 / 1732 loss=2.413, loss_v1=0, loss_v2=0, nll_loss=1.214, ntokens=1057.3, nsentences=32, sample_size=1057.3, sample_size_v1=0, sample_size_v2=0, ppl=2.32, wps=272.6, ups=0.26, wpb=1057.3, bsz=32, num_updates=18570, lr=6.83619e-06, gnorm=10.727, clip=100, loss_scale=32, train_wall=39, gb_free=8.8, wall=71656
2023-05-21 13:52:18 - progress_bar.py[line:272] - INFO: epoch 011:   1294 / 1732 loss=2.399, loss_v1=0, loss_v2=0, nll_loss=1.2, ntokens=1109.4, nsentences=32, sample_size=1109.4, sample_size_v1=0, sample_size_v2=0, ppl=2.3, wps=286, ups=0.26, wpb=1109.4, bsz=32, num_updates=18580, lr=6.83414e-06, gnorm=9.708, clip=100, loss_scale=32, train_wall=39, gb_free=8.3, wall=71695
2023-05-21 13:52:57 - progress_bar.py[line:272] - INFO: epoch 011:   1304 / 1732 loss=2.426, loss_v1=0, loss_v2=0, nll_loss=1.229, ntokens=1090.1, nsentences=32, sample_size=1090.1, sample_size_v1=0, sample_size_v2=0, ppl=2.34, wps=279.1, ups=0.26, wpb=1090.1, bsz=32, num_updates=18590, lr=6.83209e-06, gnorm=9.338, clip=100, loss_scale=32, train_wall=39, gb_free=8.3, wall=71734
2023-05-21 13:53:36 - progress_bar.py[line:272] - INFO: epoch 011:   1314 / 1732 loss=2.431, loss_v1=0, loss_v2=0, nll_loss=1.234, ntokens=1051.4, nsentences=32, sample_size=1051.4, sample_size_v1=0, sample_size_v2=0, ppl=2.35, wps=270.8, ups=0.26, wpb=1051.4, bsz=32, num_updates=18600, lr=6.83005e-06, gnorm=10.4, clip=100, loss_scale=32, train_wall=39, gb_free=8, wall=71773
2023-05-21 13:54:15 - progress_bar.py[line:272] - INFO: epoch 011:   1324 / 1732 loss=2.388, loss_v1=0, loss_v2=0, nll_loss=1.189, ntokens=1117, nsentences=32, sample_size=1117, sample_size_v1=0, sample_size_v2=0, ppl=2.28, wps=284.8, ups=0.25, wpb=1117, bsz=32, num_updates=18610, lr=6.828e-06, gnorm=11.693, clip=100, loss_scale=32, train_wall=39, gb_free=8.5, wall=71812
2023-05-21 13:54:54 - progress_bar.py[line:272] - INFO: epoch 011:   1334 / 1732 loss=2.389, loss_v1=0, loss_v2=0, nll_loss=1.188, ntokens=1097.8, nsentences=32, sample_size=1097.8, sample_size_v1=0, sample_size_v2=0, ppl=2.28, wps=284.9, ups=0.26, wpb=1097.8, bsz=32, num_updates=18620, lr=6.82595e-06, gnorm=10.791, clip=100, loss_scale=32, train_wall=38, gb_free=8.8, wall=71851
2023-05-21 13:55:33 - progress_bar.py[line:272] - INFO: epoch 011:   1344 / 1732 loss=2.392, loss_v1=0, loss_v2=0, nll_loss=1.193, ntokens=1201.2, nsentences=32, sample_size=1201.2, sample_size_v1=0, sample_size_v2=0, ppl=2.29, wps=307, ups=0.26, wpb=1201.2, bsz=32, num_updates=18630, lr=6.82391e-06, gnorm=10.766, clip=100, loss_scale=32, train_wall=39, gb_free=8, wall=71890
2023-05-21 13:56:12 - progress_bar.py[line:272] - INFO: epoch 011:   1354 / 1732 loss=2.408, loss_v1=0, loss_v2=0, nll_loss=1.209, ntokens=1101.2, nsentences=32, sample_size=1101.2, sample_size_v1=0, sample_size_v2=0, ppl=2.31, wps=283.5, ups=0.26, wpb=1101.2, bsz=32, num_updates=18640, lr=6.82186e-06, gnorm=10.777, clip=100, loss_scale=32, train_wall=39, gb_free=8.6, wall=71929
2023-05-21 13:56:51 - progress_bar.py[line:272] - INFO: epoch 011:   1364 / 1732 loss=2.378, loss_v1=0, loss_v2=0, nll_loss=1.175, ntokens=1115.3, nsentences=32, sample_size=1115.3, sample_size_v1=0, sample_size_v2=0, ppl=2.26, wps=286.3, ups=0.26, wpb=1115.3, bsz=32, num_updates=18650, lr=6.81981e-06, gnorm=10.019, clip=100, loss_scale=32, train_wall=39, gb_free=8.2, wall=71968
2023-05-21 13:57:29 - progress_bar.py[line:272] - INFO: epoch 011:   1374 / 1732 loss=2.436, loss_v1=0, loss_v2=0, nll_loss=1.241, ntokens=1075.1, nsentences=32, sample_size=1075.1, sample_size_v1=0, sample_size_v2=0, ppl=2.36, wps=279, ups=0.26, wpb=1075.1, bsz=32, num_updates=18660, lr=6.81776e-06, gnorm=10.228, clip=100, loss_scale=32, train_wall=38, gb_free=8.9, wall=72006
2023-05-21 13:58:08 - progress_bar.py[line:272] - INFO: epoch 011:   1384 / 1732 loss=2.418, loss_v1=0, loss_v2=0, nll_loss=1.222, ntokens=1167.1, nsentences=32, sample_size=1167.1, sample_size_v1=0, sample_size_v2=0, ppl=2.33, wps=301.5, ups=0.26, wpb=1167.1, bsz=32, num_updates=18670, lr=6.81572e-06, gnorm=10.805, clip=100, loss_scale=32, train_wall=39, gb_free=7.9, wall=72045
2023-05-21 13:58:46 - progress_bar.py[line:272] - INFO: epoch 011:   1394 / 1732 loss=2.413, loss_v1=0, loss_v2=0, nll_loss=1.216, ntokens=1039.3, nsentences=32, sample_size=1039.3, sample_size_v1=0, sample_size_v2=0, ppl=2.32, wps=269.9, ups=0.26, wpb=1039.3, bsz=32, num_updates=18680, lr=6.81367e-06, gnorm=12.193, clip=100, loss_scale=32, train_wall=38, gb_free=7.7, wall=72084
2023-05-21 13:59:25 - progress_bar.py[line:272] - INFO: epoch 011:   1404 / 1732 loss=2.388, loss_v1=0, loss_v2=0, nll_loss=1.187, ntokens=1161.9, nsentences=32, sample_size=1161.9, sample_size_v1=0, sample_size_v2=0, ppl=2.28, wps=299.6, ups=0.26, wpb=1161.9, bsz=32, num_updates=18690, lr=6.81162e-06, gnorm=10.233, clip=100, loss_scale=32, train_wall=39, gb_free=7.1, wall=72122
2023-05-21 14:00:04 - progress_bar.py[line:272] - INFO: epoch 011:   1414 / 1732 loss=2.421, loss_v1=0, loss_v2=0, nll_loss=1.223, ntokens=1276, nsentences=32, sample_size=1276, sample_size_v1=0, sample_size_v2=0, ppl=2.33, wps=325.3, ups=0.25, wpb=1276, bsz=32, num_updates=18700, lr=6.80957e-06, gnorm=10.073, clip=100, loss_scale=32, train_wall=39, gb_free=7.7, wall=72162
2023-05-21 14:00:44 - progress_bar.py[line:272] - INFO: epoch 011:   1424 / 1732 loss=2.396, loss_v1=0, loss_v2=0, nll_loss=1.197, ntokens=1261.9, nsentences=32, sample_size=1261.9, sample_size_v1=0, sample_size_v2=0, ppl=2.29, wps=322, ups=0.26, wpb=1261.9, bsz=32, num_updates=18710, lr=6.80753e-06, gnorm=8.861, clip=100, loss_scale=32, train_wall=39, gb_free=7.7, wall=72201
2023-05-21 14:01:22 - progress_bar.py[line:272] - INFO: epoch 011:   1434 / 1732 loss=2.394, loss_v1=0, loss_v2=0, nll_loss=1.195, ntokens=1196.2, nsentences=32, sample_size=1196.2, sample_size_v1=0, sample_size_v2=0, ppl=2.29, wps=308.7, ups=0.26, wpb=1196.2, bsz=32, num_updates=18720, lr=6.80548e-06, gnorm=8.955, clip=100, loss_scale=32, train_wall=39, gb_free=8.2, wall=72240
2023-05-21 14:02:01 - progress_bar.py[line:272] - INFO: epoch 011:   1444 / 1732 loss=2.414, loss_v1=0, loss_v2=0, nll_loss=1.218, ntokens=1129.1, nsentences=32, sample_size=1129.1, sample_size_v1=0, sample_size_v2=0, ppl=2.33, wps=292.3, ups=0.26, wpb=1129.1, bsz=32, num_updates=18730, lr=6.80343e-06, gnorm=9.571, clip=100, loss_scale=32, train_wall=39, gb_free=7.7, wall=72278
2023-05-21 14:02:40 - progress_bar.py[line:272] - INFO: epoch 011:   1454 / 1732 loss=2.415, loss_v1=0, loss_v2=0, nll_loss=1.216, ntokens=1122, nsentences=32, sample_size=1122, sample_size_v1=0, sample_size_v2=0, ppl=2.32, wps=290.7, ups=0.26, wpb=1122, bsz=32, num_updates=18740, lr=6.80138e-06, gnorm=9.909, clip=100, loss_scale=32, train_wall=39, gb_free=8, wall=72317
2023-05-21 14:03:19 - progress_bar.py[line:272] - INFO: epoch 011:   1464 / 1732 loss=2.371, loss_v1=0, loss_v2=0, nll_loss=1.168, ntokens=1182.3, nsentences=32, sample_size=1182.3, sample_size_v1=0, sample_size_v2=0, ppl=2.25, wps=303.1, ups=0.26, wpb=1182.3, bsz=32, num_updates=18750, lr=6.79934e-06, gnorm=9.433, clip=100, loss_scale=32, train_wall=39, gb_free=8.5, wall=72356
2023-05-21 14:03:57 - progress_bar.py[line:272] - INFO: epoch 011:   1474 / 1732 loss=2.404, loss_v1=0, loss_v2=0, nll_loss=1.207, ntokens=1095.3, nsentences=32, sample_size=1095.3, sample_size_v1=0, sample_size_v2=0, ppl=2.31, wps=282, ups=0.26, wpb=1095.3, bsz=32, num_updates=18760, lr=6.79729e-06, gnorm=10.454, clip=100, loss_scale=32, train_wall=39, gb_free=8.6, wall=72395
2023-05-21 14:04:36 - progress_bar.py[line:272] - INFO: epoch 011:   1484 / 1732 loss=2.43, loss_v1=0, loss_v2=0, nll_loss=1.236, ntokens=1096.5, nsentences=32, sample_size=1096.5, sample_size_v1=0, sample_size_v2=0, ppl=2.35, wps=283.9, ups=0.26, wpb=1096.5, bsz=32, num_updates=18770, lr=6.79524e-06, gnorm=9.639, clip=100, loss_scale=32, train_wall=39, gb_free=7.9, wall=72433
2023-05-21 14:05:15 - progress_bar.py[line:272] - INFO: epoch 011:   1494 / 1732 loss=2.397, loss_v1=0, loss_v2=0, nll_loss=1.196, ntokens=1106.4, nsentences=32, sample_size=1106.4, sample_size_v1=0, sample_size_v2=0, ppl=2.29, wps=285, ups=0.26, wpb=1106.4, bsz=32, num_updates=18780, lr=6.79319e-06, gnorm=9.328, clip=100, loss_scale=32, train_wall=39, gb_free=8.2, wall=72472
2023-05-21 14:05:54 - progress_bar.py[line:272] - INFO: epoch 011:   1504 / 1732 loss=2.354, loss_v1=0, loss_v2=0, nll_loss=1.149, ntokens=1153.1, nsentences=32, sample_size=1153.1, sample_size_v1=0, sample_size_v2=0, ppl=2.22, wps=298.4, ups=0.26, wpb=1153.1, bsz=32, num_updates=18790, lr=6.79115e-06, gnorm=9.915, clip=100, loss_scale=32, train_wall=39, gb_free=8.1, wall=72511
2023-05-21 14:06:32 - progress_bar.py[line:272] - INFO: epoch 011:   1514 / 1732 loss=2.41, loss_v1=0, loss_v2=0, nll_loss=1.215, ntokens=1041.2, nsentences=32, sample_size=1041.2, sample_size_v1=0, sample_size_v2=0, ppl=2.32, wps=271.2, ups=0.26, wpb=1041.2, bsz=32, num_updates=18800, lr=6.7891e-06, gnorm=10.173, clip=100, loss_scale=32, train_wall=38, gb_free=8.9, wall=72549
2023-05-21 14:07:10 - progress_bar.py[line:272] - INFO: epoch 011:   1524 / 1732 loss=2.443, loss_v1=0, loss_v2=0, nll_loss=1.251, ntokens=1034.8, nsentences=32, sample_size=1034.8, sample_size_v1=0, sample_size_v2=0, ppl=2.38, wps=269.5, ups=0.26, wpb=1034.8, bsz=32, num_updates=18810, lr=6.78705e-06, gnorm=10.382, clip=100, loss_scale=32, train_wall=38, gb_free=7.5, wall=72588
2023-05-21 14:07:49 - progress_bar.py[line:272] - INFO: epoch 011:   1534 / 1732 loss=2.407, loss_v1=0, loss_v2=0, nll_loss=1.206, ntokens=1092.4, nsentences=32, sample_size=1092.4, sample_size_v1=0, sample_size_v2=0, ppl=2.31, wps=282.1, ups=0.26, wpb=1092.4, bsz=32, num_updates=18820, lr=6.78501e-06, gnorm=10.853, clip=100, loss_scale=32, train_wall=39, gb_free=8.3, wall=72626
2023-05-21 14:08:28 - progress_bar.py[line:272] - INFO: epoch 011:   1544 / 1732 loss=2.394, loss_v1=0, loss_v2=0, nll_loss=1.193, ntokens=1091.8, nsentences=32, sample_size=1091.8, sample_size_v1=0, sample_size_v2=0, ppl=2.29, wps=282.6, ups=0.26, wpb=1091.8, bsz=32, num_updates=18830, lr=6.78296e-06, gnorm=10.278, clip=100, loss_scale=32, train_wall=39, gb_free=8.7, wall=72665
2023-05-21 14:09:06 - progress_bar.py[line:272] - INFO: epoch 011:   1554 / 1732 loss=2.39, loss_v1=0, loss_v2=0, nll_loss=1.192, ntokens=1040, nsentences=32, sample_size=1040, sample_size_v1=0, sample_size_v2=0, ppl=2.28, wps=269.7, ups=0.26, wpb=1040, bsz=32, num_updates=18840, lr=6.78091e-06, gnorm=10.956, clip=100, loss_scale=32, train_wall=39, gb_free=8.7, wall=72703
2023-05-21 14:09:45 - progress_bar.py[line:272] - INFO: epoch 011:   1564 / 1732 loss=2.423, loss_v1=0, loss_v2=0, nll_loss=1.226, ntokens=1120.2, nsentences=32, sample_size=1120.2, sample_size_v1=0, sample_size_v2=0, ppl=2.34, wps=289.4, ups=0.26, wpb=1120.2, bsz=32, num_updates=18850, lr=6.77886e-06, gnorm=10.532, clip=100, loss_scale=32, train_wall=39, gb_free=8.8, wall=72742
2023-05-21 14:10:24 - progress_bar.py[line:272] - INFO: epoch 011:   1574 / 1732 loss=2.439, loss_v1=0, loss_v2=0, nll_loss=1.245, ntokens=1055.9, nsentences=32, sample_size=1055.9, sample_size_v1=0, sample_size_v2=0, ppl=2.37, wps=273.2, ups=0.26, wpb=1055.9, bsz=32, num_updates=18860, lr=6.77682e-06, gnorm=11.553, clip=100, loss_scale=32, train_wall=39, gb_free=8.3, wall=72781
2023-05-21 14:11:02 - progress_bar.py[line:272] - INFO: epoch 011:   1584 / 1732 loss=2.432, loss_v1=0, loss_v2=0, nll_loss=1.238, ntokens=1026.8, nsentences=32, sample_size=1026.8, sample_size_v1=0, sample_size_v2=0, ppl=2.36, wps=265.5, ups=0.26, wpb=1026.8, bsz=32, num_updates=18870, lr=6.77477e-06, gnorm=11.486, clip=100, loss_scale=32, train_wall=39, gb_free=7.9, wall=72820
2023-05-21 14:11:41 - progress_bar.py[line:272] - INFO: epoch 011:   1594 / 1732 loss=2.389, loss_v1=0, loss_v2=0, nll_loss=1.187, ntokens=1068.7, nsentences=32, sample_size=1068.7, sample_size_v1=0, sample_size_v2=0, ppl=2.28, wps=275.8, ups=0.26, wpb=1068.7, bsz=32, num_updates=18880, lr=6.77272e-06, gnorm=11.045, clip=100, loss_scale=32, train_wall=39, gb_free=8.4, wall=72858
2023-05-21 14:12:20 - progress_bar.py[line:272] - INFO: epoch 011:   1604 / 1732 loss=2.388, loss_v1=0, loss_v2=0, nll_loss=1.188, ntokens=1089, nsentences=32, sample_size=1089, sample_size_v1=0, sample_size_v2=0, ppl=2.28, wps=281.4, ups=0.26, wpb=1089, bsz=32, num_updates=18890, lr=6.77067e-06, gnorm=10.435, clip=100, loss_scale=32, train_wall=39, gb_free=7.9, wall=72897
2023-05-21 14:12:59 - progress_bar.py[line:272] - INFO: epoch 011:   1614 / 1732 loss=2.363, loss_v1=0, loss_v2=0, nll_loss=1.16, ntokens=1186.1, nsentences=32, sample_size=1186.1, sample_size_v1=0, sample_size_v2=0, ppl=2.23, wps=302.5, ups=0.26, wpb=1186.1, bsz=32, num_updates=18900, lr=6.76863e-06, gnorm=9.633, clip=100, loss_scale=32, train_wall=39, gb_free=8, wall=72936
2023-05-21 14:13:38 - progress_bar.py[line:272] - INFO: epoch 011:   1624 / 1732 loss=2.397, loss_v1=0, loss_v2=0, nll_loss=1.198, ntokens=1074.1, nsentences=32, sample_size=1074.1, sample_size_v1=0, sample_size_v2=0, ppl=2.29, wps=277.9, ups=0.26, wpb=1074.1, bsz=32, num_updates=18910, lr=6.76658e-06, gnorm=10.72, clip=100, loss_scale=32, train_wall=39, gb_free=8.7, wall=72975
2023-05-21 14:14:17 - progress_bar.py[line:272] - INFO: epoch 011:   1634 / 1732 loss=2.375, loss_v1=0, loss_v2=0, nll_loss=1.173, ntokens=1178.9, nsentences=32, sample_size=1178.9, sample_size_v1=0, sample_size_v2=0, ppl=2.26, wps=303.1, ups=0.26, wpb=1178.9, bsz=32, num_updates=18920, lr=6.76453e-06, gnorm=9.748, clip=100, loss_scale=32, train_wall=39, gb_free=8.7, wall=73014
2023-05-21 14:14:55 - progress_bar.py[line:272] - INFO: epoch 011:   1644 / 1732 loss=2.35, loss_v1=0, loss_v2=0, nll_loss=1.144, ntokens=1265.1, nsentences=32, sample_size=1265.1, sample_size_v1=0, sample_size_v2=0, ppl=2.21, wps=324.9, ups=0.26, wpb=1265.1, bsz=32, num_updates=18930, lr=6.76248e-06, gnorm=9.43, clip=100, loss_scale=32, train_wall=39, gb_free=8, wall=73053
2023-05-21 14:15:34 - progress_bar.py[line:272] - INFO: epoch 011:   1654 / 1732 loss=2.419, loss_v1=0, loss_v2=0, nll_loss=1.222, ntokens=974.9, nsentences=32, sample_size=974.9, sample_size_v1=0, sample_size_v2=0, ppl=2.33, wps=254.7, ups=0.26, wpb=974.9, bsz=32, num_updates=18940, lr=6.76044e-06, gnorm=12.39, clip=100, loss_scale=32, train_wall=38, gb_free=8.6, wall=73091
2023-05-21 14:16:12 - progress_bar.py[line:272] - INFO: epoch 011:   1664 / 1732 loss=2.414, loss_v1=0, loss_v2=0, nll_loss=1.218, ntokens=1041.8, nsentences=32, sample_size=1041.8, sample_size_v1=0, sample_size_v2=0, ppl=2.33, wps=269.1, ups=0.26, wpb=1041.8, bsz=32, num_updates=18950, lr=6.75839e-06, gnorm=10.428, clip=100, loss_scale=32, train_wall=39, gb_free=8.3, wall=73130
2023-05-21 14:16:51 - progress_bar.py[line:272] - INFO: epoch 011:   1674 / 1732 loss=2.373, loss_v1=0, loss_v2=0, nll_loss=1.169, ntokens=1052.3, nsentences=32, sample_size=1052.3, sample_size_v1=0, sample_size_v2=0, ppl=2.25, wps=273.4, ups=0.26, wpb=1052.3, bsz=32, num_updates=18960, lr=6.75634e-06, gnorm=10.431, clip=100, loss_scale=32, train_wall=38, gb_free=8.1, wall=73168
2023-05-21 14:17:30 - progress_bar.py[line:272] - INFO: epoch 011:   1684 / 1732 loss=2.351, loss_v1=0, loss_v2=0, nll_loss=1.147, ntokens=1169.1, nsentences=32, sample_size=1169.1, sample_size_v1=0, sample_size_v2=0, ppl=2.21, wps=298.1, ups=0.25, wpb=1169.1, bsz=32, num_updates=18970, lr=6.75429e-06, gnorm=9.849, clip=100, loss_scale=32, train_wall=39, gb_free=8.8, wall=73207
2023-05-21 14:18:10 - progress_bar.py[line:272] - INFO: epoch 011:   1694 / 1732 loss=2.385, loss_v1=0, loss_v2=0, nll_loss=1.186, ntokens=1257.3, nsentences=32, sample_size=1257.3, sample_size_v1=0, sample_size_v2=0, ppl=2.28, wps=316.9, ups=0.25, wpb=1257.3, bsz=32, num_updates=18980, lr=6.75225e-06, gnorm=9.479, clip=100, loss_scale=32, train_wall=40, gb_free=7, wall=73247
2023-05-21 14:18:49 - progress_bar.py[line:272] - INFO: epoch 011:   1704 / 1732 loss=2.385, loss_v1=0, loss_v2=0, nll_loss=1.185, ntokens=1232.6, nsentences=32, sample_size=1232.6, sample_size_v1=0, sample_size_v2=0, ppl=2.27, wps=313.4, ups=0.25, wpb=1232.6, bsz=32, num_updates=18990, lr=6.7502e-06, gnorm=9.721, clip=100, loss_scale=32, train_wall=39, gb_free=8.4, wall=73286
2023-05-21 14:19:28 - progress_bar.py[line:272] - INFO: epoch 011:   1714 / 1732 loss=2.39, loss_v1=0, loss_v2=0, nll_loss=1.191, ntokens=1181.2, nsentences=32, sample_size=1181.2, sample_size_v1=0, sample_size_v2=0, ppl=2.28, wps=302, ups=0.26, wpb=1181.2, bsz=32, num_updates=19000, lr=6.74815e-06, gnorm=9.383, clip=100, loss_scale=32, train_wall=39, gb_free=8.3, wall=73325
2023-05-21 14:20:07 - progress_bar.py[line:272] - INFO: epoch 011:   1724 / 1732 loss=2.397, loss_v1=0, loss_v2=0, nll_loss=1.197, ntokens=1135.1, nsentences=32, sample_size=1135.1, sample_size_v1=0, sample_size_v2=0, ppl=2.29, wps=290.2, ups=0.26, wpb=1135.1, bsz=32, num_updates=19010, lr=6.7461e-06, gnorm=9.547, clip=100, loss_scale=32, train_wall=39, gb_free=8.6, wall=73365
2023-05-21 14:20:36 - train.py[line:332] - INFO: end of epoch 11 (average epoch stats below)
2023-05-21 14:20:36 - progress_bar.py[line:282] - INFO: epoch 011 | loss 2.408 | loss_v1 0 | loss_v2 0 | nll_loss 1.21 | ntokens 1051.78 | nsentences 31.986 | sample_size 1051.78 | sample_size_v1 0 | sample_size_v2 0 | ppl 2.31 | wps 272.9 | ups 0.26 | wpb 1051.8 | bsz 32 | num_updates 19018 | lr 6.74447e-06 | gnorm 10.247 | clip 100 | loss_scale 32 | train_wall 6652 | gb_free 8.9 | wall 73393
2023-05-21 14:20:36 - trainer.py[line:639] - INFO: loading train data for epoch 12
local datafile ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 0 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 0 finished initializing row_count and line_idx-to-offset mapping
file ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 0 row count 55400 total row count 55400
slice_id 0 seek offset 0
2023-05-21 14:20:37 - trainer.py[line:703] - INFO: begin training epoch 12
2023-05-21 14:20:37 - train.py[line:305] - INFO: Start iterating over samples
2023-05-21 14:20:45 - progress_bar.py[line:272] - INFO: epoch 012:      2 / 1732 loss=2.436, loss_v1=0, loss_v2=0, nll_loss=1.24, ntokens=1104.4, nsentences=29.6, sample_size=1104.4, sample_size_v1=0, sample_size_v2=0, ppl=2.36, wps=290.1, ups=0.26, wpb=1104.4, bsz=29.6, num_updates=19020, lr=6.74406e-06, gnorm=11.224, clip=100, loss_scale=32, train_wall=36, gb_free=8, wall=73403
2023-05-21 14:21:24 - progress_bar.py[line:272] - INFO: epoch 012:     12 / 1732 loss=2.328, loss_v1=0, loss_v2=0, nll_loss=1.118, ntokens=1057.9, nsentences=32, sample_size=1057.9, sample_size_v1=0, sample_size_v2=0, ppl=2.17, wps=272.9, ups=0.26, wpb=1057.9, bsz=32, num_updates=19030, lr=6.74201e-06, gnorm=12.125, clip=100, loss_scale=64, train_wall=39, gb_free=8.8, wall=73441
2023-05-21 14:21:59 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2023-05-21 14:22:07 - progress_bar.py[line:272] - INFO: epoch 012:     23 / 1732 loss=2.286, loss_v1=0, loss_v2=0, nll_loss=1.073, ntokens=1067, nsentences=32, sample_size=1067, sample_size_v1=0, sample_size_v2=0, ppl=2.1, wps=249.5, ups=0.23, wpb=1067, bsz=32, num_updates=19040, lr=6.73996e-06, gnorm=11.079, clip=100, loss_scale=32, train_wall=43, gb_free=8.6, wall=73484
2023-05-21 14:22:46 - progress_bar.py[line:272] - INFO: epoch 012:     33 / 1732 loss=2.268, loss_v1=0, loss_v2=0, nll_loss=1.052, ntokens=1032.3, nsentences=32, sample_size=1032.3, sample_size_v1=0, sample_size_v2=0, ppl=2.07, wps=264.1, ups=0.26, wpb=1032.3, bsz=32, num_updates=19050, lr=6.73792e-06, gnorm=10.679, clip=100, loss_scale=32, train_wall=39, gb_free=7.2, wall=73523
2023-05-21 14:23:25 - progress_bar.py[line:272] - INFO: epoch 012:     43 / 1732 loss=2.183, loss_v1=0, loss_v2=0, nll_loss=0.962, ntokens=1156.8, nsentences=32, sample_size=1156.8, sample_size_v1=0, sample_size_v2=0, ppl=1.95, wps=296, ups=0.26, wpb=1156.8, bsz=32, num_updates=19060, lr=6.73587e-06, gnorm=9.579, clip=100, loss_scale=32, train_wall=39, gb_free=8.1, wall=73562
2023-05-21 14:24:04 - progress_bar.py[line:272] - INFO: epoch 012:     53 / 1732 loss=2.243, loss_v1=0, loss_v2=0, nll_loss=1.024, ntokens=1016.6, nsentences=32, sample_size=1016.6, sample_size_v1=0, sample_size_v2=0, ppl=2.03, wps=262.9, ups=0.26, wpb=1016.6, bsz=32, num_updates=19070, lr=6.73382e-06, gnorm=11.972, clip=100, loss_scale=32, train_wall=39, gb_free=8.6, wall=73601
2023-05-21 14:24:43 - progress_bar.py[line:272] - INFO: epoch 012:     63 / 1732 loss=2.025, loss_v1=0, loss_v2=0, nll_loss=0.78, ntokens=1239.4, nsentences=32, sample_size=1239.4, sample_size_v1=0, sample_size_v2=0, ppl=1.72, wps=317.6, ups=0.26, wpb=1239.4, bsz=32, num_updates=19080, lr=6.73177e-06, gnorm=7.036, clip=100, loss_scale=32, train_wall=39, gb_free=7.3, wall=73640
2023-05-21 14:25:23 - progress_bar.py[line:272] - INFO: epoch 012:     73 / 1732 loss=2.156, loss_v1=0, loss_v2=0, nll_loss=0.932, ntokens=1389.6, nsentences=32, sample_size=1389.6, sample_size_v1=0, sample_size_v2=0, ppl=1.91, wps=348.6, ups=0.25, wpb=1389.6, bsz=32, num_updates=19090, lr=6.72973e-06, gnorm=8.747, clip=100, loss_scale=32, train_wall=40, gb_free=7, wall=73680
2023-05-21 14:26:02 - progress_bar.py[line:272] - INFO: epoch 012:     83 / 1732 loss=2.19, loss_v1=0, loss_v2=0, nll_loss=0.962, ntokens=1166.3, nsentences=32, sample_size=1166.3, sample_size_v1=0, sample_size_v2=0, ppl=1.95, wps=296.5, ups=0.25, wpb=1166.3, bsz=32, num_updates=19100, lr=6.72768e-06, gnorm=8.947, clip=100, loss_scale=32, train_wall=39, gb_free=7.2, wall=73719
2023-05-21 14:26:41 - progress_bar.py[line:272] - INFO: epoch 012:     93 / 1732 loss=2.181, loss_v1=0, loss_v2=0, nll_loss=0.956, ntokens=1099.1, nsentences=32, sample_size=1099.1, sample_size_v1=0, sample_size_v2=0, ppl=1.94, wps=282, ups=0.26, wpb=1099.1, bsz=32, num_updates=19110, lr=6.72563e-06, gnorm=9.243, clip=100, loss_scale=32, train_wall=39, gb_free=8.2, wall=73758
2023-05-21 14:27:20 - progress_bar.py[line:272] - INFO: epoch 012:    103 / 1732 loss=2.356, loss_v1=0, loss_v2=0, nll_loss=1.155, ntokens=976, nsentences=32, sample_size=976, sample_size_v1=0, sample_size_v2=0, ppl=2.23, wps=253.2, ups=0.26, wpb=976, bsz=32, num_updates=19120, lr=6.72358e-06, gnorm=11.304, clip=100, loss_scale=32, train_wall=38, gb_free=8.6, wall=73797
2023-05-21 14:27:58 - progress_bar.py[line:272] - INFO: epoch 012:    113 / 1732 loss=2.405, loss_v1=0, loss_v2=0, nll_loss=1.208, ntokens=1030.9, nsentences=32, sample_size=1030.9, sample_size_v1=0, sample_size_v2=0, ppl=2.31, wps=265.7, ups=0.26, wpb=1030.9, bsz=32, num_updates=19130, lr=6.72154e-06, gnorm=10.517, clip=100, loss_scale=32, train_wall=39, gb_free=7.8, wall=73836
2023-05-21 14:28:38 - progress_bar.py[line:272] - INFO: epoch 012:    123 / 1732 loss=2.375, loss_v1=0, loss_v2=0, nll_loss=1.173, ntokens=1142.2, nsentences=32, sample_size=1142.2, sample_size_v1=0, sample_size_v2=0, ppl=2.25, wps=289.6, ups=0.25, wpb=1142.2, bsz=32, num_updates=19140, lr=6.71949e-06, gnorm=9.73, clip=100, loss_scale=32, train_wall=39, gb_free=7.6, wall=73875
2023-05-21 14:29:17 - progress_bar.py[line:272] - INFO: epoch 012:    133 / 1732 loss=2.318, loss_v1=0, loss_v2=0, nll_loss=1.107, ntokens=1207.4, nsentences=32, sample_size=1207.4, sample_size_v1=0, sample_size_v2=0, ppl=2.15, wps=306, ups=0.25, wpb=1207.4, bsz=32, num_updates=19150, lr=6.71744e-06, gnorm=8.789, clip=100, loss_scale=32, train_wall=39, gb_free=8, wall=73915
2023-05-21 14:29:57 - progress_bar.py[line:272] - INFO: epoch 012:    143 / 1732 loss=2.306, loss_v1=0, loss_v2=0, nll_loss=1.093, ntokens=1226.6, nsentences=32, sample_size=1226.6, sample_size_v1=0, sample_size_v2=0, ppl=2.13, wps=309, ups=0.25, wpb=1226.6, bsz=32, num_updates=19160, lr=6.71539e-06, gnorm=8.348, clip=100, loss_scale=32, train_wall=40, gb_free=7.2, wall=73954
2023-05-21 14:30:37 - progress_bar.py[line:272] - INFO: epoch 012:    153 / 1732 loss=2.317, loss_v1=0, loss_v2=0, nll_loss=1.11, ntokens=1152.6, nsentences=32, sample_size=1152.6, sample_size_v1=0, sample_size_v2=0, ppl=2.16, wps=290.6, ups=0.25, wpb=1152.6, bsz=32, num_updates=19170, lr=6.71335e-06, gnorm=8.583, clip=100, loss_scale=32, train_wall=40, gb_free=7.3, wall=73994
2023-05-21 14:31:16 - progress_bar.py[line:272] - INFO: epoch 012:    163 / 1732 loss=2.308, loss_v1=0, loss_v2=0, nll_loss=1.101, ntokens=1079.7, nsentences=32, sample_size=1079.7, sample_size_v1=0, sample_size_v2=0, ppl=2.15, wps=275.8, ups=0.26, wpb=1079.7, bsz=32, num_updates=19180, lr=6.7113e-06, gnorm=9.283, clip=100, loss_scale=32, train_wall=39, gb_free=8.7, wall=74033
2023-05-21 14:31:55 - progress_bar.py[line:272] - INFO: epoch 012:    173 / 1732 loss=2.325, loss_v1=0, loss_v2=0, nll_loss=1.115, ntokens=936.5, nsentences=32, sample_size=936.5, sample_size_v1=0, sample_size_v2=0, ppl=2.17, wps=241.7, ups=0.26, wpb=936.5, bsz=32, num_updates=19190, lr=6.70925e-06, gnorm=9.565, clip=100, loss_scale=32, train_wall=39, gb_free=7.8, wall=74072
2023-05-21 14:32:34 - progress_bar.py[line:272] - INFO: epoch 012:    183 / 1732 loss=2.277, loss_v1=0, loss_v2=0, nll_loss=1.061, ntokens=1184.7, nsentences=32, sample_size=1184.7, sample_size_v1=0, sample_size_v2=0, ppl=2.09, wps=300.3, ups=0.25, wpb=1184.7, bsz=32, num_updates=19200, lr=6.7072e-06, gnorm=8.33, clip=100, loss_scale=32, train_wall=39, gb_free=8.4, wall=74111
2023-05-21 14:33:13 - progress_bar.py[line:272] - INFO: epoch 012:    193 / 1732 loss=2.294, loss_v1=0, loss_v2=0, nll_loss=1.085, ntokens=1122.8, nsentences=32, sample_size=1122.8, sample_size_v1=0, sample_size_v2=0, ppl=2.12, wps=285.1, ups=0.25, wpb=1122.8, bsz=32, num_updates=19210, lr=6.70516e-06, gnorm=8.696, clip=100, loss_scale=32, train_wall=39, gb_free=8.2, wall=74151
2023-05-21 14:33:52 - progress_bar.py[line:272] - INFO: epoch 012:    203 / 1732 loss=2.39, loss_v1=0, loss_v2=0, nll_loss=1.192, ntokens=1086.7, nsentences=32, sample_size=1086.7, sample_size_v1=0, sample_size_v2=0, ppl=2.29, wps=280.2, ups=0.26, wpb=1086.7, bsz=32, num_updates=19220, lr=6.70311e-06, gnorm=10.262, clip=100, loss_scale=32, train_wall=39, gb_free=8.5, wall=74189
2023-05-21 14:34:31 - progress_bar.py[line:272] - INFO: epoch 012:    213 / 1732 loss=2.419, loss_v1=0, loss_v2=0, nll_loss=1.222, ntokens=1044.9, nsentences=32, sample_size=1044.9, sample_size_v1=0, sample_size_v2=0, ppl=2.33, wps=271.4, ups=0.26, wpb=1044.9, bsz=32, num_updates=19230, lr=6.70106e-06, gnorm=9.466, clip=100, loss_scale=32, train_wall=38, gb_free=8.5, wall=74228
2023-05-21 14:35:09 - progress_bar.py[line:272] - INFO: epoch 012:    223 / 1732 loss=2.42, loss_v1=0, loss_v2=0, nll_loss=1.224, ntokens=1134.6, nsentences=32, sample_size=1134.6, sample_size_v1=0, sample_size_v2=0, ppl=2.34, wps=294.8, ups=0.26, wpb=1134.6, bsz=32, num_updates=19240, lr=6.69902e-06, gnorm=9.267, clip=100, loss_scale=32, train_wall=38, gb_free=8.6, wall=74266
2023-05-21 14:35:48 - progress_bar.py[line:272] - INFO: epoch 012:    233 / 1732 loss=2.469, loss_v1=0, loss_v2=0, nll_loss=1.28, ntokens=1078.6, nsentences=32, sample_size=1078.6, sample_size_v1=0, sample_size_v2=0, ppl=2.43, wps=281, ups=0.26, wpb=1078.6, bsz=32, num_updates=19250, lr=6.69697e-06, gnorm=10.661, clip=100, loss_scale=32, train_wall=38, gb_free=9.1, wall=74305
2023-05-21 14:36:26 - progress_bar.py[line:272] - INFO: epoch 012:    243 / 1732 loss=2.457, loss_v1=0, loss_v2=0, nll_loss=1.26, ntokens=1123.3, nsentences=32, sample_size=1123.3, sample_size_v1=0, sample_size_v2=0, ppl=2.4, wps=291.2, ups=0.26, wpb=1123.3, bsz=32, num_updates=19260, lr=6.69492e-06, gnorm=9.712, clip=100, loss_scale=32, train_wall=39, gb_free=8.7, wall=74343
2023-05-21 14:37:05 - progress_bar.py[line:272] - INFO: epoch 012:    253 / 1732 loss=2.458, loss_v1=0, loss_v2=0, nll_loss=1.265, ntokens=1167.4, nsentences=32, sample_size=1167.4, sample_size_v1=0, sample_size_v2=0, ppl=2.4, wps=302.5, ups=0.26, wpb=1167.4, bsz=32, num_updates=19270, lr=6.69287e-06, gnorm=9.776, clip=100, loss_scale=32, train_wall=39, gb_free=8, wall=74382
2023-05-21 14:37:43 - progress_bar.py[line:272] - INFO: epoch 012:    263 / 1732 loss=2.447, loss_v1=0, loss_v2=0, nll_loss=1.253, ntokens=1123.9, nsentences=32, sample_size=1123.9, sample_size_v1=0, sample_size_v2=0, ppl=2.38, wps=293.2, ups=0.26, wpb=1123.9, bsz=32, num_updates=19280, lr=6.69083e-06, gnorm=10.069, clip=100, loss_scale=32, train_wall=38, gb_free=8, wall=74420
2023-05-21 14:38:21 - progress_bar.py[line:272] - INFO: epoch 012:    273 / 1732 loss=2.434, loss_v1=0, loss_v2=0, nll_loss=1.238, ntokens=1154.8, nsentences=32, sample_size=1154.8, sample_size_v1=0, sample_size_v2=0, ppl=2.36, wps=301.4, ups=0.26, wpb=1154.8, bsz=32, num_updates=19290, lr=6.68878e-06, gnorm=9.925, clip=100, loss_scale=32, train_wall=38, gb_free=8.3, wall=74459
2023-05-21 14:39:00 - progress_bar.py[line:272] - INFO: epoch 012:    283 / 1732 loss=2.451, loss_v1=0, loss_v2=0, nll_loss=1.26, ntokens=1146.7, nsentences=32, sample_size=1146.7, sample_size_v1=0, sample_size_v2=0, ppl=2.39, wps=297.5, ups=0.26, wpb=1146.7, bsz=32, num_updates=19300, lr=6.68673e-06, gnorm=9.716, clip=100, loss_scale=32, train_wall=38, gb_free=8.2, wall=74497
2023-05-21 14:39:38 - progress_bar.py[line:272] - INFO: epoch 012:    293 / 1732 loss=2.419, loss_v1=0, loss_v2=0, nll_loss=1.223, ntokens=1122.6, nsentences=32, sample_size=1122.6, sample_size_v1=0, sample_size_v2=0, ppl=2.33, wps=293.6, ups=0.26, wpb=1122.6, bsz=32, num_updates=19310, lr=6.68468e-06, gnorm=8.948, clip=100, loss_scale=32, train_wall=38, gb_free=7.4, wall=74535
2023-05-21 14:40:16 - progress_bar.py[line:272] - INFO: epoch 012:    303 / 1732 loss=2.424, loss_v1=0, loss_v2=0, nll_loss=1.227, ntokens=1117.4, nsentences=32, sample_size=1117.4, sample_size_v1=0, sample_size_v2=0, ppl=2.34, wps=292.4, ups=0.26, wpb=1117.4, bsz=32, num_updates=19320, lr=6.68264e-06, gnorm=10.265, clip=100, loss_scale=32, train_wall=38, gb_free=8.2, wall=74574
2023-05-21 14:40:55 - progress_bar.py[line:272] - INFO: epoch 012:    313 / 1732 loss=2.436, loss_v1=0, loss_v2=0, nll_loss=1.241, ntokens=1045.5, nsentences=32, sample_size=1045.5, sample_size_v1=0, sample_size_v2=0, ppl=2.36, wps=273.9, ups=0.26, wpb=1045.5, bsz=32, num_updates=19330, lr=6.68059e-06, gnorm=10.561, clip=100, loss_scale=32, train_wall=38, gb_free=8.6, wall=74612
2023-05-21 14:41:33 - progress_bar.py[line:272] - INFO: epoch 012:    323 / 1732 loss=2.47, loss_v1=0, loss_v2=0, nll_loss=1.28, ntokens=1005.7, nsentences=32, sample_size=1005.7, sample_size_v1=0, sample_size_v2=0, ppl=2.43, wps=263.4, ups=0.26, wpb=1005.7, bsz=32, num_updates=19340, lr=6.67854e-06, gnorm=10.988, clip=100, loss_scale=32, train_wall=38, gb_free=8.6, wall=74650
2023-05-21 14:42:11 - progress_bar.py[line:272] - INFO: epoch 012:    333 / 1732 loss=2.451, loss_v1=0, loss_v2=0, nll_loss=1.256, ntokens=1019.2, nsentences=32, sample_size=1019.2, sample_size_v1=0, sample_size_v2=0, ppl=2.39, wps=267.4, ups=0.26, wpb=1019.2, bsz=32, num_updates=19350, lr=6.67649e-06, gnorm=10.655, clip=100, loss_scale=32, train_wall=38, gb_free=8.6, wall=74688
2023-05-21 14:42:49 - progress_bar.py[line:272] - INFO: epoch 012:    343 / 1732 loss=2.42, loss_v1=0, loss_v2=0, nll_loss=1.223, ntokens=919.2, nsentences=32, sample_size=919.2, sample_size_v1=0, sample_size_v2=0, ppl=2.33, wps=242, ups=0.26, wpb=919.2, bsz=32, num_updates=19360, lr=6.67445e-06, gnorm=11.03, clip=100, loss_scale=32, train_wall=38, gb_free=9.1, wall=74726
2023-05-21 14:43:27 - progress_bar.py[line:272] - INFO: epoch 012:    353 / 1732 loss=2.447, loss_v1=0, loss_v2=0, nll_loss=1.257, ntokens=968.9, nsentences=32, sample_size=968.9, sample_size_v1=0, sample_size_v2=0, ppl=2.39, wps=253.3, ups=0.26, wpb=968.9, bsz=32, num_updates=19370, lr=6.6724e-06, gnorm=10.655, clip=100, loss_scale=32, train_wall=38, gb_free=7.7, wall=74764
2023-05-21 14:44:05 - progress_bar.py[line:272] - INFO: epoch 012:    363 / 1732 loss=2.486, loss_v1=0, loss_v2=0, nll_loss=1.297, ntokens=932.1, nsentences=32, sample_size=932.1, sample_size_v1=0, sample_size_v2=0, ppl=2.46, wps=245.3, ups=0.26, wpb=932.1, bsz=32, num_updates=19380, lr=6.67035e-06, gnorm=11.002, clip=100, loss_scale=32, train_wall=38, gb_free=8.7, wall=74802
2023-05-21 14:44:43 - progress_bar.py[line:272] - INFO: epoch 012:    373 / 1732 loss=2.478, loss_v1=0, loss_v2=0, nll_loss=1.284, ntokens=967.4, nsentences=32, sample_size=967.4, sample_size_v1=0, sample_size_v2=0, ppl=2.43, wps=253.4, ups=0.26, wpb=967.4, bsz=32, num_updates=19390, lr=6.6683e-06, gnorm=10.823, clip=100, loss_scale=32, train_wall=38, gb_free=8.9, wall=74841
2023-05-21 14:45:21 - progress_bar.py[line:272] - INFO: epoch 012:    383 / 1732 loss=2.456, loss_v1=0, loss_v2=0, nll_loss=1.262, ntokens=1070.5, nsentences=32, sample_size=1070.5, sample_size_v1=0, sample_size_v2=0, ppl=2.4, wps=281, ups=0.26, wpb=1070.5, bsz=32, num_updates=19400, lr=6.66626e-06, gnorm=10.673, clip=100, loss_scale=32, train_wall=38, gb_free=8.7, wall=74879
2023-05-21 14:45:59 - progress_bar.py[line:272] - INFO: epoch 012:    393 / 1732 loss=2.451, loss_v1=0, loss_v2=0, nll_loss=1.258, ntokens=990.3, nsentences=32, sample_size=990.3, sample_size_v1=0, sample_size_v2=0, ppl=2.39, wps=260.3, ups=0.26, wpb=990.3, bsz=32, num_updates=19410, lr=6.66421e-06, gnorm=10.62, clip=100, loss_scale=32, train_wall=38, gb_free=8.9, wall=74917
2023-05-21 14:46:38 - progress_bar.py[line:272] - INFO: epoch 012:    403 / 1732 loss=2.43, loss_v1=0, loss_v2=0, nll_loss=1.235, ntokens=1045, nsentences=32, sample_size=1045, sample_size_v1=0, sample_size_v2=0, ppl=2.35, wps=274.2, ups=0.26, wpb=1045, bsz=32, num_updates=19420, lr=6.66216e-06, gnorm=10.426, clip=100, loss_scale=32, train_wall=38, gb_free=8.4, wall=74955
2023-05-21 14:47:16 - progress_bar.py[line:272] - INFO: epoch 012:    413 / 1732 loss=2.429, loss_v1=0, loss_v2=0, nll_loss=1.233, ntokens=1078.5, nsentences=32, sample_size=1078.5, sample_size_v1=0, sample_size_v2=0, ppl=2.35, wps=282.5, ups=0.26, wpb=1078.5, bsz=32, num_updates=19430, lr=6.66012e-06, gnorm=11.188, clip=100, loss_scale=32, train_wall=38, gb_free=8.6, wall=74993
2023-05-21 14:47:54 - progress_bar.py[line:272] - INFO: epoch 012:    423 / 1732 loss=2.414, loss_v1=0, loss_v2=0, nll_loss=1.216, ntokens=985.4, nsentences=32, sample_size=985.4, sample_size_v1=0, sample_size_v2=0, ppl=2.32, wps=258.3, ups=0.26, wpb=985.4, bsz=32, num_updates=19440, lr=6.65807e-06, gnorm=12.099, clip=100, loss_scale=32, train_wall=38, gb_free=8.3, wall=75031
2023-05-21 14:48:32 - progress_bar.py[line:272] - INFO: epoch 012:    433 / 1732 loss=2.424, loss_v1=0, loss_v2=0, nll_loss=1.228, ntokens=1024.2, nsentences=32, sample_size=1024.2, sample_size_v1=0, sample_size_v2=0, ppl=2.34, wps=269.5, ups=0.26, wpb=1024.2, bsz=32, num_updates=19450, lr=6.65602e-06, gnorm=10.904, clip=100, loss_scale=32, train_wall=38, gb_free=9, wall=75069
2023-05-21 14:49:10 - progress_bar.py[line:272] - INFO: epoch 012:    443 / 1732 loss=2.467, loss_v1=0, loss_v2=0, nll_loss=1.277, ntokens=966.7, nsentences=32, sample_size=966.7, sample_size_v1=0, sample_size_v2=0, ppl=2.42, wps=254.3, ups=0.26, wpb=966.7, bsz=32, num_updates=19460, lr=6.65397e-06, gnorm=10.553, clip=100, loss_scale=32, train_wall=38, gb_free=8.9, wall=75107
2023-05-21 14:49:48 - progress_bar.py[line:272] - INFO: epoch 012:    453 / 1732 loss=2.446, loss_v1=0, loss_v2=0, nll_loss=1.254, ntokens=911.8, nsentences=32, sample_size=911.8, sample_size_v1=0, sample_size_v2=0, ppl=2.38, wps=241, ups=0.26, wpb=911.8, bsz=32, num_updates=19470, lr=6.65193e-06, gnorm=12.514, clip=100, loss_scale=32, train_wall=38, gb_free=9.1, wall=75145
2023-05-21 14:50:26 - progress_bar.py[line:272] - INFO: epoch 012:    463 / 1732 loss=2.472, loss_v1=0, loss_v2=0, nll_loss=1.281, ntokens=1072.4, nsentences=32, sample_size=1072.4, sample_size_v1=0, sample_size_v2=0, ppl=2.43, wps=280.9, ups=0.26, wpb=1072.4, bsz=32, num_updates=19480, lr=6.64988e-06, gnorm=10.628, clip=100, loss_scale=32, train_wall=38, gb_free=8.8, wall=75183
2023-05-21 14:51:04 - progress_bar.py[line:272] - INFO: epoch 012:    473 / 1732 loss=2.455, loss_v1=0, loss_v2=0, nll_loss=1.261, ntokens=1059.2, nsentences=32, sample_size=1059.2, sample_size_v1=0, sample_size_v2=0, ppl=2.4, wps=276.6, ups=0.26, wpb=1059.2, bsz=32, num_updates=19490, lr=6.64783e-06, gnorm=9.725, clip=100, loss_scale=32, train_wall=38, gb_free=7.5, wall=75221
2023-05-21 14:51:42 - progress_bar.py[line:272] - INFO: epoch 012:    483 / 1732 loss=2.447, loss_v1=0, loss_v2=0, nll_loss=1.253, ntokens=966.6, nsentences=32, sample_size=966.6, sample_size_v1=0, sample_size_v2=0, ppl=2.38, wps=254.7, ups=0.26, wpb=966.6, bsz=32, num_updates=19500, lr=6.64578e-06, gnorm=11.106, clip=100, loss_scale=32, train_wall=38, gb_free=8.8, wall=75259
2023-05-21 14:52:20 - progress_bar.py[line:272] - INFO: epoch 012:    493 / 1732 loss=2.449, loss_v1=0, loss_v2=0, nll_loss=1.256, ntokens=940.2, nsentences=32, sample_size=940.2, sample_size_v1=0, sample_size_v2=0, ppl=2.39, wps=247.4, ups=0.26, wpb=940.2, bsz=32, num_updates=19510, lr=6.64374e-06, gnorm=13.169, clip=100, loss_scale=32, train_wall=38, gb_free=9, wall=75297
2023-05-21 14:52:58 - progress_bar.py[line:272] - INFO: epoch 012:    503 / 1732 loss=2.444, loss_v1=0, loss_v2=0, nll_loss=1.25, ntokens=988.6, nsentences=32, sample_size=988.6, sample_size_v1=0, sample_size_v2=0, ppl=2.38, wps=261.3, ups=0.26, wpb=988.6, bsz=32, num_updates=19520, lr=6.64169e-06, gnorm=11.265, clip=100, loss_scale=32, train_wall=38, gb_free=9, wall=75335
2023-05-21 14:53:36 - progress_bar.py[line:272] - INFO: epoch 012:    513 / 1732 loss=2.461, loss_v1=0, loss_v2=0, nll_loss=1.268, ntokens=1035, nsentences=32, sample_size=1035, sample_size_v1=0, sample_size_v2=0, ppl=2.41, wps=272.4, ups=0.26, wpb=1035, bsz=32, num_updates=19530, lr=6.63964e-06, gnorm=10.378, clip=100, loss_scale=32, train_wall=38, gb_free=8.9, wall=75373
2023-05-21 14:54:14 - progress_bar.py[line:272] - INFO: epoch 012:    523 / 1732 loss=2.434, loss_v1=0, loss_v2=0, nll_loss=1.239, ntokens=997.6, nsentences=32, sample_size=997.6, sample_size_v1=0, sample_size_v2=0, ppl=2.36, wps=263.6, ups=0.26, wpb=997.6, bsz=32, num_updates=19540, lr=6.63759e-06, gnorm=11.887, clip=100, loss_scale=32, train_wall=38, gb_free=9, wall=75411
2023-05-21 14:54:52 - progress_bar.py[line:272] - INFO: epoch 012:    533 / 1732 loss=2.442, loss_v1=0, loss_v2=0, nll_loss=1.249, ntokens=935, nsentences=32, sample_size=935, sample_size_v1=0, sample_size_v2=0, ppl=2.38, wps=246.9, ups=0.26, wpb=935, bsz=32, num_updates=19550, lr=6.63555e-06, gnorm=12.721, clip=100, loss_scale=64, train_wall=38, gb_free=9, wall=75449
2023-05-21 14:55:30 - progress_bar.py[line:272] - INFO: epoch 012:    543 / 1732 loss=2.456, loss_v1=0, loss_v2=0, nll_loss=1.263, ntokens=1003.8, nsentences=32, sample_size=1003.8, sample_size_v1=0, sample_size_v2=0, ppl=2.4, wps=263.5, ups=0.26, wpb=1003.8, bsz=32, num_updates=19560, lr=6.6335e-06, gnorm=10.591, clip=100, loss_scale=64, train_wall=38, gb_free=8.6, wall=75487
2023-05-21 14:56:08 - progress_bar.py[line:272] - INFO: epoch 012:    553 / 1732 loss=2.478, loss_v1=0, loss_v2=0, nll_loss=1.288, ntokens=1017.4, nsentences=32, sample_size=1017.4, sample_size_v1=0, sample_size_v2=0, ppl=2.44, wps=267.7, ups=0.26, wpb=1017.4, bsz=32, num_updates=19570, lr=6.63145e-06, gnorm=10.552, clip=100, loss_scale=64, train_wall=38, gb_free=9, wall=75525
2023-05-21 14:56:46 - progress_bar.py[line:272] - INFO: epoch 012:    563 / 1732 loss=2.469, loss_v1=0, loss_v2=0, nll_loss=1.278, ntokens=1008.2, nsentences=32, sample_size=1008.2, sample_size_v1=0, sample_size_v2=0, ppl=2.43, wps=265.1, ups=0.26, wpb=1008.2, bsz=32, num_updates=19580, lr=6.6294e-06, gnorm=11.213, clip=100, loss_scale=64, train_wall=38, gb_free=9.3, wall=75563
2023-05-21 14:57:24 - progress_bar.py[line:272] - INFO: epoch 012:    573 / 1732 loss=2.471, loss_v1=0, loss_v2=0, nll_loss=1.28, ntokens=1041.3, nsentences=32, sample_size=1041.3, sample_size_v1=0, sample_size_v2=0, ppl=2.43, wps=271.3, ups=0.26, wpb=1041.3, bsz=32, num_updates=19590, lr=6.62736e-06, gnorm=12.284, clip=100, loss_scale=64, train_wall=38, gb_free=8.1, wall=75602
2023-05-21 14:58:03 - progress_bar.py[line:272] - INFO: epoch 012:    583 / 1732 loss=2.461, loss_v1=0, loss_v2=0, nll_loss=1.269, ntokens=981.7, nsentences=32, sample_size=981.7, sample_size_v1=0, sample_size_v2=0, ppl=2.41, wps=256.4, ups=0.26, wpb=981.7, bsz=32, num_updates=19600, lr=6.62531e-06, gnorm=11.879, clip=100, loss_scale=64, train_wall=38, gb_free=9, wall=75640
2023-05-21 14:58:41 - progress_bar.py[line:272] - INFO: epoch 012:    593 / 1732 loss=2.424, loss_v1=0, loss_v2=0, nll_loss=1.227, ntokens=957.4, nsentences=32, sample_size=957.4, sample_size_v1=0, sample_size_v2=0, ppl=2.34, wps=250.7, ups=0.26, wpb=957.4, bsz=32, num_updates=19610, lr=6.62326e-06, gnorm=11.815, clip=100, loss_scale=64, train_wall=38, gb_free=8.9, wall=75678
2023-05-21 14:59:19 - progress_bar.py[line:272] - INFO: epoch 012:    603 / 1732 loss=2.431, loss_v1=0, loss_v2=0, nll_loss=1.239, ntokens=911.2, nsentences=32, sample_size=911.2, sample_size_v1=0, sample_size_v2=0, ppl=2.36, wps=240.9, ups=0.26, wpb=911.2, bsz=32, num_updates=19620, lr=6.62121e-06, gnorm=12.405, clip=100, loss_scale=64, train_wall=38, gb_free=8.7, wall=75716
2023-05-21 14:59:57 - progress_bar.py[line:272] - INFO: epoch 012:    613 / 1732 loss=2.451, loss_v1=0, loss_v2=0, nll_loss=1.26, ntokens=893.3, nsentences=32, sample_size=893.3, sample_size_v1=0, sample_size_v2=0, ppl=2.39, wps=234.4, ups=0.26, wpb=893.3, bsz=32, num_updates=19630, lr=6.61917e-06, gnorm=12.368, clip=100, loss_scale=64, train_wall=38, gb_free=9.1, wall=75754
2023-05-21 15:00:34 - progress_bar.py[line:272] - INFO: epoch 012:    623 / 1732 loss=2.465, loss_v1=0, loss_v2=0, nll_loss=1.273, ntokens=887.2, nsentences=32, sample_size=887.2, sample_size_v1=0, sample_size_v2=0, ppl=2.42, wps=235.2, ups=0.27, wpb=887.2, bsz=32, num_updates=19640, lr=6.61712e-06, gnorm=13.936, clip=100, loss_scale=64, train_wall=38, gb_free=8.3, wall=75792
2023-05-21 15:01:12 - progress_bar.py[line:272] - INFO: epoch 012:    633 / 1732 loss=2.45, loss_v1=0, loss_v2=0, nll_loss=1.256, ntokens=925, nsentences=32, sample_size=925, sample_size_v1=0, sample_size_v2=0, ppl=2.39, wps=245.3, ups=0.27, wpb=925, bsz=32, num_updates=19650, lr=6.61507e-06, gnorm=13.915, clip=100, loss_scale=64, train_wall=38, gb_free=8.7, wall=75829
2023-05-21 15:01:50 - progress_bar.py[line:272] - INFO: epoch 012:    643 / 1732 loss=2.464, loss_v1=0, loss_v2=0, nll_loss=1.272, ntokens=963.8, nsentences=32, sample_size=963.8, sample_size_v1=0, sample_size_v2=0, ppl=2.42, wps=255.2, ups=0.26, wpb=963.8, bsz=32, num_updates=19660, lr=6.61303e-06, gnorm=12.756, clip=100, loss_scale=64, train_wall=38, gb_free=9, wall=75867
2023-05-21 15:02:28 - progress_bar.py[line:272] - INFO: epoch 012:    653 / 1732 loss=2.461, loss_v1=0, loss_v2=0, nll_loss=1.269, ntokens=928, nsentences=32, sample_size=928, sample_size_v1=0, sample_size_v2=0, ppl=2.41, wps=247, ups=0.27, wpb=928, bsz=32, num_updates=19670, lr=6.61098e-06, gnorm=12.085, clip=100, loss_scale=64, train_wall=38, gb_free=9.1, wall=75905
2023-05-21 15:03:05 - progress_bar.py[line:272] - INFO: epoch 012:    663 / 1732 loss=2.465, loss_v1=0, loss_v2=0, nll_loss=1.275, ntokens=882.9, nsentences=32, sample_size=882.9, sample_size_v1=0, sample_size_v2=0, ppl=2.42, wps=235, ups=0.27, wpb=882.9, bsz=32, num_updates=19680, lr=6.60893e-06, gnorm=14.104, clip=100, loss_scale=64, train_wall=38, gb_free=8.8, wall=75942
2023-05-21 15:03:43 - progress_bar.py[line:272] - INFO: epoch 012:    673 / 1732 loss=2.471, loss_v1=0, loss_v2=0, nll_loss=1.281, ntokens=954.3, nsentences=32, sample_size=954.3, sample_size_v1=0, sample_size_v2=0, ppl=2.43, wps=252.6, ups=0.26, wpb=954.3, bsz=32, num_updates=19690, lr=6.60688e-06, gnorm=14.052, clip=100, loss_scale=64, train_wall=38, gb_free=9, wall=75980
2023-05-21 15:04:21 - progress_bar.py[line:272] - INFO: epoch 012:    683 / 1732 loss=2.442, loss_v1=0, loss_v2=0, nll_loss=1.248, ntokens=960.5, nsentences=32, sample_size=960.5, sample_size_v1=0, sample_size_v2=0, ppl=2.38, wps=253.3, ups=0.26, wpb=960.5, bsz=32, num_updates=19700, lr=6.60484e-06, gnorm=12.709, clip=100, loss_scale=64, train_wall=38, gb_free=9.2, wall=76018
2023-05-21 15:04:59 - progress_bar.py[line:272] - INFO: epoch 012:    693 / 1732 loss=2.466, loss_v1=0, loss_v2=0, nll_loss=1.275, ntokens=962.9, nsentences=32, sample_size=962.9, sample_size_v1=0, sample_size_v2=0, ppl=2.42, wps=252, ups=0.26, wpb=962.9, bsz=32, num_updates=19710, lr=6.60279e-06, gnorm=12.039, clip=100, loss_scale=64, train_wall=38, gb_free=8.3, wall=76056
2023-05-21 15:05:37 - progress_bar.py[line:272] - INFO: epoch 012:    703 / 1732 loss=2.418, loss_v1=0, loss_v2=0, nll_loss=1.221, ntokens=972.9, nsentences=32, sample_size=972.9, sample_size_v1=0, sample_size_v2=0, ppl=2.33, wps=255.3, ups=0.26, wpb=972.9, bsz=32, num_updates=19720, lr=6.60074e-06, gnorm=13.048, clip=100, loss_scale=64, train_wall=38, gb_free=8.9, wall=76094
2023-05-21 15:06:15 - progress_bar.py[line:272] - INFO: epoch 012:    713 / 1732 loss=2.476, loss_v1=0, loss_v2=0, nll_loss=1.285, ntokens=898.6, nsentences=32, sample_size=898.6, sample_size_v1=0, sample_size_v2=0, ppl=2.44, wps=237.2, ups=0.26, wpb=898.6, bsz=32, num_updates=19730, lr=6.59869e-06, gnorm=12.923, clip=100, loss_scale=64, train_wall=38, gb_free=9.1, wall=76132
2023-05-21 15:06:53 - progress_bar.py[line:272] - INFO: epoch 012:    723 / 1732 loss=2.426, loss_v1=0, loss_v2=0, nll_loss=1.229, ntokens=877.5, nsentences=32, sample_size=877.5, sample_size_v1=0, sample_size_v2=0, ppl=2.34, wps=232.9, ups=0.27, wpb=877.5, bsz=32, num_updates=19740, lr=6.59665e-06, gnorm=12.144, clip=100, loss_scale=64, train_wall=38, gb_free=9.2, wall=76170
2023-05-21 15:07:31 - progress_bar.py[line:272] - INFO: epoch 012:    733 / 1732 loss=2.427, loss_v1=0, loss_v2=0, nll_loss=1.234, ntokens=959.6, nsentences=32, sample_size=959.6, sample_size_v1=0, sample_size_v2=0, ppl=2.35, wps=252.6, ups=0.26, wpb=959.6, bsz=32, num_updates=19750, lr=6.5946e-06, gnorm=10.674, clip=100, loss_scale=64, train_wall=38, gb_free=8.2, wall=76208
2023-05-21 15:08:09 - progress_bar.py[line:272] - INFO: epoch 012:    743 / 1732 loss=2.427, loss_v1=0, loss_v2=0, nll_loss=1.232, ntokens=991.8, nsentences=32, sample_size=991.8, sample_size_v1=0, sample_size_v2=0, ppl=2.35, wps=261.9, ups=0.26, wpb=991.8, bsz=32, num_updates=19760, lr=6.59255e-06, gnorm=11.777, clip=100, loss_scale=64, train_wall=38, gb_free=8.7, wall=76246
2023-05-21 15:08:47 - progress_bar.py[line:272] - INFO: epoch 012:    753 / 1732 loss=2.442, loss_v1=0, loss_v2=0, nll_loss=1.248, ntokens=968.6, nsentences=32, sample_size=968.6, sample_size_v1=0, sample_size_v2=0, ppl=2.37, wps=253.6, ups=0.26, wpb=968.6, bsz=32, num_updates=19770, lr=6.5905e-06, gnorm=12.632, clip=100, loss_scale=64, train_wall=38, gb_free=8.7, wall=76284
2023-05-21 15:09:25 - progress_bar.py[line:272] - INFO: epoch 012:    763 / 1732 loss=2.428, loss_v1=0, loss_v2=0, nll_loss=1.233, ntokens=964, nsentences=32, sample_size=964, sample_size_v1=0, sample_size_v2=0, ppl=2.35, wps=252.1, ups=0.26, wpb=964, bsz=32, num_updates=19780, lr=6.58846e-06, gnorm=10.911, clip=100, loss_scale=64, train_wall=38, gb_free=8.8, wall=76322
2023-05-21 15:10:03 - progress_bar.py[line:272] - INFO: epoch 012:    773 / 1732 loss=2.437, loss_v1=0, loss_v2=0, nll_loss=1.243, ntokens=971.7, nsentences=32, sample_size=971.7, sample_size_v1=0, sample_size_v2=0, ppl=2.37, wps=255.9, ups=0.26, wpb=971.7, bsz=32, num_updates=19790, lr=6.58641e-06, gnorm=12.892, clip=100, loss_scale=64, train_wall=38, gb_free=8.8, wall=76360
2023-05-21 15:10:41 - progress_bar.py[line:272] - INFO: epoch 012:    783 / 1732 loss=2.443, loss_v1=0, loss_v2=0, nll_loss=1.25, ntokens=1008.4, nsentences=32, sample_size=1008.4, sample_size_v1=0, sample_size_v2=0, ppl=2.38, wps=265.2, ups=0.26, wpb=1008.4, bsz=32, num_updates=19800, lr=6.58436e-06, gnorm=10.956, clip=100, loss_scale=64, train_wall=38, gb_free=8.4, wall=76398
2023-05-21 15:10:56 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2023-05-21 15:11:23 - progress_bar.py[line:272] - INFO: epoch 012:    794 / 1732 loss=2.438, loss_v1=0, loss_v2=0, nll_loss=1.244, ntokens=1049.2, nsentences=32, sample_size=1049.2, sample_size_v1=0, sample_size_v2=0, ppl=2.37, wps=250.9, ups=0.24, wpb=1049.2, bsz=32, num_updates=19810, lr=6.58231e-06, gnorm=11.248, clip=100, loss_scale=32, train_wall=42, gb_free=8.9, wall=76440
2023-05-21 15:12:01 - progress_bar.py[line:272] - INFO: epoch 012:    804 / 1732 loss=2.44, loss_v1=0, loss_v2=0, nll_loss=1.245, ntokens=947.8, nsentences=32, sample_size=947.8, sample_size_v1=0, sample_size_v2=0, ppl=2.37, wps=250.8, ups=0.26, wpb=947.8, bsz=32, num_updates=19820, lr=6.58027e-06, gnorm=13.328, clip=100, loss_scale=32, train_wall=38, gb_free=8.8, wall=76478
2023-05-21 15:12:39 - progress_bar.py[line:272] - INFO: epoch 012:    814 / 1732 loss=2.454, loss_v1=0, loss_v2=0, nll_loss=1.26, ntokens=938.1, nsentences=32, sample_size=938.1, sample_size_v1=0, sample_size_v2=0, ppl=2.4, wps=247.6, ups=0.26, wpb=938.1, bsz=32, num_updates=19830, lr=6.57822e-06, gnorm=13.079, clip=100, loss_scale=32, train_wall=38, gb_free=9.1, wall=76516
2023-05-21 15:13:16 - progress_bar.py[line:272] - INFO: epoch 012:    824 / 1732 loss=2.44, loss_v1=0, loss_v2=0, nll_loss=1.245, ntokens=923.7, nsentences=32, sample_size=923.7, sample_size_v1=0, sample_size_v2=0, ppl=2.37, wps=243.5, ups=0.26, wpb=923.7, bsz=32, num_updates=19840, lr=6.57617e-06, gnorm=12.333, clip=100, loss_scale=32, train_wall=38, gb_free=8.3, wall=76554
2023-05-21 15:13:54 - progress_bar.py[line:272] - INFO: epoch 012:    834 / 1732 loss=2.455, loss_v1=0, loss_v2=0, nll_loss=1.261, ntokens=890.1, nsentences=32, sample_size=890.1, sample_size_v1=0, sample_size_v2=0, ppl=2.4, wps=237, ups=0.27, wpb=890.1, bsz=32, num_updates=19850, lr=6.57413e-06, gnorm=12.516, clip=100, loss_scale=32, train_wall=38, gb_free=9.1, wall=76591
2023-05-21 15:14:32 - progress_bar.py[line:272] - INFO: epoch 012:    844 / 1732 loss=2.424, loss_v1=0, loss_v2=0, nll_loss=1.226, ntokens=972.2, nsentences=32, sample_size=972.2, sample_size_v1=0, sample_size_v2=0, ppl=2.34, wps=256.6, ups=0.26, wpb=972.2, bsz=32, num_updates=19860, lr=6.57208e-06, gnorm=11.308, clip=100, loss_scale=32, train_wall=38, gb_free=9, wall=76629
2023-05-21 15:15:10 - progress_bar.py[line:272] - INFO: epoch 012:    854 / 1732 loss=2.431, loss_v1=0, loss_v2=0, nll_loss=1.235, ntokens=976.8, nsentences=32, sample_size=976.8, sample_size_v1=0, sample_size_v2=0, ppl=2.35, wps=256.6, ups=0.26, wpb=976.8, bsz=32, num_updates=19870, lr=6.57003e-06, gnorm=11.586, clip=100, loss_scale=32, train_wall=38, gb_free=8.6, wall=76667
2023-05-21 15:15:48 - progress_bar.py[line:272] - INFO: epoch 012:    864 / 1732 loss=2.455, loss_v1=0, loss_v2=0, nll_loss=1.264, ntokens=958.7, nsentences=32, sample_size=958.7, sample_size_v1=0, sample_size_v2=0, ppl=2.4, wps=252.4, ups=0.26, wpb=958.7, bsz=32, num_updates=19880, lr=6.56798e-06, gnorm=12.23, clip=100, loss_scale=32, train_wall=38, gb_free=8.6, wall=76705
2023-05-21 15:16:26 - progress_bar.py[line:272] - INFO: epoch 012:    874 / 1732 loss=2.408, loss_v1=0, loss_v2=0, nll_loss=1.211, ntokens=975.5, nsentences=32, sample_size=975.5, sample_size_v1=0, sample_size_v2=0, ppl=2.31, wps=256.7, ups=0.26, wpb=975.5, bsz=32, num_updates=19890, lr=6.56594e-06, gnorm=11.56, clip=100, loss_scale=32, train_wall=38, gb_free=8.2, wall=76743
2023-05-21 15:17:04 - progress_bar.py[line:272] - INFO: epoch 012:    884 / 1732 loss=2.378, loss_v1=0, loss_v2=0, nll_loss=1.176, ntokens=977.6, nsentences=32, sample_size=977.6, sample_size_v1=0, sample_size_v2=0, ppl=2.26, wps=255.6, ups=0.26, wpb=977.6, bsz=32, num_updates=19900, lr=6.56389e-06, gnorm=11.209, clip=100, loss_scale=32, train_wall=38, gb_free=8.6, wall=76781
2023-05-21 15:17:43 - progress_bar.py[line:272] - INFO: epoch 012:    894 / 1732 loss=2.393, loss_v1=0, loss_v2=0, nll_loss=1.193, ntokens=1010, nsentences=32, sample_size=1010, sample_size_v1=0, sample_size_v2=0, ppl=2.29, wps=263.5, ups=0.26, wpb=1010, bsz=32, num_updates=19910, lr=6.56184e-06, gnorm=11.56, clip=100, loss_scale=32, train_wall=38, gb_free=8.1, wall=76820
2023-05-21 15:18:21 - progress_bar.py[line:272] - INFO: epoch 012:    904 / 1732 loss=2.385, loss_v1=0, loss_v2=0, nll_loss=1.183, ntokens=1055.2, nsentences=32, sample_size=1055.2, sample_size_v1=0, sample_size_v2=0, ppl=2.27, wps=275.1, ups=0.26, wpb=1055.2, bsz=32, num_updates=19920, lr=6.55979e-06, gnorm=11.328, clip=100, loss_scale=32, train_wall=38, gb_free=8.7, wall=76858
2023-05-21 15:18:59 - progress_bar.py[line:272] - INFO: epoch 012:    914 / 1732 loss=2.474, loss_v1=0, loss_v2=0, nll_loss=1.284, ntokens=927.8, nsentences=32, sample_size=927.8, sample_size_v1=0, sample_size_v2=0, ppl=2.43, wps=244.4, ups=0.26, wpb=927.8, bsz=32, num_updates=19930, lr=6.55775e-06, gnorm=12.879, clip=100, loss_scale=32, train_wall=38, gb_free=9, wall=76896
2023-05-21 15:19:37 - progress_bar.py[line:272] - INFO: epoch 012:    924 / 1732 loss=2.391, loss_v1=0, loss_v2=0, nll_loss=1.191, ntokens=1031.4, nsentences=32, sample_size=1031.4, sample_size_v1=0, sample_size_v2=0, ppl=2.28, wps=267.4, ups=0.26, wpb=1031.4, bsz=32, num_updates=19940, lr=6.5557e-06, gnorm=10.776, clip=100, loss_scale=32, train_wall=39, gb_free=8.7, wall=76935
2023-05-21 15:20:16 - progress_bar.py[line:272] - INFO: epoch 012:    934 / 1732 loss=2.415, loss_v1=0, loss_v2=0, nll_loss=1.218, ntokens=1020.2, nsentences=32, sample_size=1020.2, sample_size_v1=0, sample_size_v2=0, ppl=2.33, wps=264.7, ups=0.26, wpb=1020.2, bsz=32, num_updates=19950, lr=6.55365e-06, gnorm=11.78, clip=100, loss_scale=32, train_wall=38, gb_free=8.9, wall=76973
2023-05-21 15:20:55 - progress_bar.py[line:272] - INFO: epoch 012:    944 / 1732 loss=2.43, loss_v1=0, loss_v2=0, nll_loss=1.234, ntokens=1062, nsentences=32, sample_size=1062, sample_size_v1=0, sample_size_v2=0, ppl=2.35, wps=273.5, ups=0.26, wpb=1062, bsz=32, num_updates=19960, lr=6.5516e-06, gnorm=10.601, clip=100, loss_scale=32, train_wall=39, gb_free=8, wall=77012
2023-05-21 15:21:33 - progress_bar.py[line:272] - INFO: epoch 012:    954 / 1732 loss=2.414, loss_v1=0, loss_v2=0, nll_loss=1.217, ntokens=1041, nsentences=32, sample_size=1041, sample_size_v1=0, sample_size_v2=0, ppl=2.32, wps=270.7, ups=0.26, wpb=1041, bsz=32, num_updates=19970, lr=6.54956e-06, gnorm=10.168, clip=100, loss_scale=32, train_wall=38, gb_free=8.2, wall=77050
2023-05-21 15:22:12 - progress_bar.py[line:272] - INFO: epoch 012:    964 / 1732 loss=2.421, loss_v1=0, loss_v2=0, nll_loss=1.226, ntokens=1053, nsentences=32, sample_size=1053, sample_size_v1=0, sample_size_v2=0, ppl=2.34, wps=272.8, ups=0.26, wpb=1053, bsz=32, num_updates=19980, lr=6.54751e-06, gnorm=11.695, clip=100, loss_scale=32, train_wall=39, gb_free=8.6, wall=77089
2023-05-21 15:22:51 - progress_bar.py[line:272] - INFO: epoch 012:    974 / 1732 loss=2.428, loss_v1=0, loss_v2=0, nll_loss=1.236, ntokens=1051.9, nsentences=32, sample_size=1051.9, sample_size_v1=0, sample_size_v2=0, ppl=2.36, wps=271.4, ups=0.26, wpb=1051.9, bsz=32, num_updates=19990, lr=6.54546e-06, gnorm=11.297, clip=100, loss_scale=32, train_wall=39, gb_free=8.7, wall=77128
2023-05-21 15:23:29 - progress_bar.py[line:272] - INFO: epoch 012:    984 / 1732 loss=2.42, loss_v1=0, loss_v2=0, nll_loss=1.224, ntokens=1029.3, nsentences=32, sample_size=1029.3, sample_size_v1=0, sample_size_v2=0, ppl=2.34, wps=266.1, ups=0.26, wpb=1029.3, bsz=32, num_updates=20000, lr=6.54341e-06, gnorm=11.156, clip=100, loss_scale=32, train_wall=39, gb_free=7.9, wall=77167
2023-05-21 15:24:08 - progress_bar.py[line:272] - INFO: epoch 012:    994 / 1732 loss=2.416, loss_v1=0, loss_v2=0, nll_loss=1.217, ntokens=1030.4, nsentences=32, sample_size=1030.4, sample_size_v1=0, sample_size_v2=0, ppl=2.32, wps=268.5, ups=0.26, wpb=1030.4, bsz=32, num_updates=20010, lr=6.54137e-06, gnorm=11.71, clip=100, loss_scale=32, train_wall=38, gb_free=8.7, wall=77205
2023-05-21 15:24:46 - progress_bar.py[line:272] - INFO: epoch 012:   1004 / 1732 loss=2.411, loss_v1=0, loss_v2=0, nll_loss=1.213, ntokens=995.4, nsentences=32, sample_size=995.4, sample_size_v1=0, sample_size_v2=0, ppl=2.32, wps=259.2, ups=0.26, wpb=995.4, bsz=32, num_updates=20020, lr=6.53932e-06, gnorm=10.312, clip=100, loss_scale=32, train_wall=38, gb_free=9.1, wall=77243
2023-05-21 15:25:25 - progress_bar.py[line:272] - INFO: epoch 012:   1014 / 1732 loss=2.403, loss_v1=0, loss_v2=0, nll_loss=1.205, ntokens=997.1, nsentences=32, sample_size=997.1, sample_size_v1=0, sample_size_v2=0, ppl=2.3, wps=258.9, ups=0.26, wpb=997.1, bsz=32, num_updates=20030, lr=6.53727e-06, gnorm=11.129, clip=100, loss_scale=32, train_wall=38, gb_free=8.5, wall=77282
2023-05-21 15:26:04 - progress_bar.py[line:272] - INFO: epoch 012:   1024 / 1732 loss=2.412, loss_v1=0, loss_v2=0, nll_loss=1.216, ntokens=1086.7, nsentences=32, sample_size=1086.7, sample_size_v1=0, sample_size_v2=0, ppl=2.32, wps=279.2, ups=0.26, wpb=1086.7, bsz=32, num_updates=20040, lr=6.53523e-06, gnorm=10.801, clip=100, loss_scale=32, train_wall=39, gb_free=8.6, wall=77321
2023-05-21 15:26:42 - progress_bar.py[line:272] - INFO: epoch 012:   1034 / 1732 loss=2.411, loss_v1=0, loss_v2=0, nll_loss=1.215, ntokens=1103.2, nsentences=32, sample_size=1103.2, sample_size_v1=0, sample_size_v2=0, ppl=2.32, wps=284.3, ups=0.26, wpb=1103.2, bsz=32, num_updates=20050, lr=6.53318e-06, gnorm=10.417, clip=100, loss_scale=32, train_wall=39, gb_free=7.9, wall=77360
2023-05-21 15:27:21 - progress_bar.py[line:272] - INFO: epoch 012:   1044 / 1732 loss=2.409, loss_v1=0, loss_v2=0, nll_loss=1.21, ntokens=1052.8, nsentences=32, sample_size=1052.8, sample_size_v1=0, sample_size_v2=0, ppl=2.31, wps=272.6, ups=0.26, wpb=1052.8, bsz=32, num_updates=20060, lr=6.53113e-06, gnorm=11.1, clip=100, loss_scale=32, train_wall=39, gb_free=8.4, wall=77398
2023-05-21 15:28:00 - progress_bar.py[line:272] - INFO: epoch 012:   1054 / 1732 loss=2.431, loss_v1=0, loss_v2=0, nll_loss=1.234, ntokens=1068, nsentences=32, sample_size=1068, sample_size_v1=0, sample_size_v2=0, ppl=2.35, wps=276.8, ups=0.26, wpb=1068, bsz=32, num_updates=20070, lr=6.52908e-06, gnorm=11.546, clip=100, loss_scale=32, train_wall=39, gb_free=7, wall=77437
2023-05-21 15:28:38 - progress_bar.py[line:272] - INFO: epoch 012:   1064 / 1732 loss=2.414, loss_v1=0, loss_v2=0, nll_loss=1.217, ntokens=1024.1, nsentences=32, sample_size=1024.1, sample_size_v1=0, sample_size_v2=0, ppl=2.33, wps=265.4, ups=0.26, wpb=1024.1, bsz=32, num_updates=20080, lr=6.52704e-06, gnorm=12.345, clip=100, loss_scale=32, train_wall=39, gb_free=8.7, wall=77475
2023-05-21 15:29:17 - progress_bar.py[line:272] - INFO: epoch 012:   1074 / 1732 loss=2.42, loss_v1=0, loss_v2=0, nll_loss=1.222, ntokens=1002.8, nsentences=32, sample_size=1002.8, sample_size_v1=0, sample_size_v2=0, ppl=2.33, wps=260.7, ups=0.26, wpb=1002.8, bsz=32, num_updates=20090, lr=6.52499e-06, gnorm=11.507, clip=100, loss_scale=32, train_wall=38, gb_free=8.4, wall=77514
2023-05-21 15:29:55 - progress_bar.py[line:272] - INFO: epoch 012:   1084 / 1732 loss=2.434, loss_v1=0, loss_v2=0, nll_loss=1.238, ntokens=1060.4, nsentences=32, sample_size=1060.4, sample_size_v1=0, sample_size_v2=0, ppl=2.36, wps=274, ups=0.26, wpb=1060.4, bsz=32, num_updates=20100, lr=6.52294e-06, gnorm=11.753, clip=100, loss_scale=32, train_wall=39, gb_free=7.2, wall=77553
2023-05-21 15:30:34 - progress_bar.py[line:272] - INFO: epoch 012:   1094 / 1732 loss=2.413, loss_v1=0, loss_v2=0, nll_loss=1.215, ntokens=1050.5, nsentences=32, sample_size=1050.5, sample_size_v1=0, sample_size_v2=0, ppl=2.32, wps=273.2, ups=0.26, wpb=1050.5, bsz=32, num_updates=20110, lr=6.52089e-06, gnorm=12.791, clip=100, loss_scale=32, train_wall=38, gb_free=7.8, wall=77591
2023-05-21 15:31:12 - progress_bar.py[line:272] - INFO: epoch 012:   1104 / 1732 loss=2.418, loss_v1=0, loss_v2=0, nll_loss=1.221, ntokens=1042.3, nsentences=32, sample_size=1042.3, sample_size_v1=0, sample_size_v2=0, ppl=2.33, wps=270.5, ups=0.26, wpb=1042.3, bsz=32, num_updates=20120, lr=6.51885e-06, gnorm=11.775, clip=100, loss_scale=32, train_wall=38, gb_free=8.4, wall=77630
2023-05-21 15:31:51 - progress_bar.py[line:272] - INFO: epoch 012:   1114 / 1732 loss=2.42, loss_v1=0, loss_v2=0, nll_loss=1.224, ntokens=1000.7, nsentences=32, sample_size=1000.7, sample_size_v1=0, sample_size_v2=0, ppl=2.34, wps=259.6, ups=0.26, wpb=1000.7, bsz=32, num_updates=20130, lr=6.5168e-06, gnorm=11.393, clip=100, loss_scale=32, train_wall=38, gb_free=8.5, wall=77668
2023-05-21 15:32:29 - progress_bar.py[line:272] - INFO: epoch 012:   1124 / 1732 loss=2.416, loss_v1=0, loss_v2=0, nll_loss=1.218, ntokens=989.1, nsentences=32, sample_size=989.1, sample_size_v1=0, sample_size_v2=0, ppl=2.33, wps=256.8, ups=0.26, wpb=989.1, bsz=32, num_updates=20140, lr=6.51475e-06, gnorm=11.478, clip=100, loss_scale=32, train_wall=38, gb_free=8.4, wall=77707
2023-05-21 15:33:08 - progress_bar.py[line:272] - INFO: epoch 012:   1134 / 1732 loss=2.431, loss_v1=0, loss_v2=0, nll_loss=1.238, ntokens=968.8, nsentences=32, sample_size=968.8, sample_size_v1=0, sample_size_v2=0, ppl=2.36, wps=252.6, ups=0.26, wpb=968.8, bsz=32, num_updates=20150, lr=6.5127e-06, gnorm=12.605, clip=100, loss_scale=32, train_wall=38, gb_free=8.6, wall=77745
2023-05-21 15:33:46 - progress_bar.py[line:272] - INFO: epoch 012:   1144 / 1732 loss=2.422, loss_v1=0, loss_v2=0, nll_loss=1.226, ntokens=1034.3, nsentences=32, sample_size=1034.3, sample_size_v1=0, sample_size_v2=0, ppl=2.34, wps=269.4, ups=0.26, wpb=1034.3, bsz=32, num_updates=20160, lr=6.51066e-06, gnorm=12.401, clip=100, loss_scale=32, train_wall=38, gb_free=8.7, wall=77783
2023-05-21 15:34:25 - progress_bar.py[line:272] - INFO: epoch 012:   1154 / 1732 loss=2.412, loss_v1=0, loss_v2=0, nll_loss=1.214, ntokens=1025.8, nsentences=32, sample_size=1025.8, sample_size_v1=0, sample_size_v2=0, ppl=2.32, wps=265.8, ups=0.26, wpb=1025.8, bsz=32, num_updates=20170, lr=6.50861e-06, gnorm=11.21, clip=100, loss_scale=32, train_wall=39, gb_free=7.4, wall=77822
2023-05-21 15:35:03 - progress_bar.py[line:272] - INFO: epoch 012:   1164 / 1732 loss=2.388, loss_v1=0, loss_v2=0, nll_loss=1.187, ntokens=1008, nsentences=32, sample_size=1008, sample_size_v1=0, sample_size_v2=0, ppl=2.28, wps=260.1, ups=0.26, wpb=1008, bsz=32, num_updates=20180, lr=6.50656e-06, gnorm=12.447, clip=100, loss_scale=32, train_wall=39, gb_free=8.7, wall=77861
2023-05-21 15:35:42 - progress_bar.py[line:272] - INFO: epoch 012:   1174 / 1732 loss=2.413, loss_v1=0, loss_v2=0, nll_loss=1.217, ntokens=1081.1, nsentences=32, sample_size=1081.1, sample_size_v1=0, sample_size_v2=0, ppl=2.32, wps=279.7, ups=0.26, wpb=1081.1, bsz=32, num_updates=20190, lr=6.50451e-06, gnorm=11.568, clip=100, loss_scale=32, train_wall=39, gb_free=8.1, wall=77899
2023-05-21 15:36:20 - progress_bar.py[line:272] - INFO: epoch 012:   1184 / 1732 loss=2.405, loss_v1=0, loss_v2=0, nll_loss=1.207, ntokens=962, nsentences=32, sample_size=962, sample_size_v1=0, sample_size_v2=0, ppl=2.31, wps=251.1, ups=0.26, wpb=962, bsz=32, num_updates=20200, lr=6.50247e-06, gnorm=11.383, clip=100, loss_scale=32, train_wall=38, gb_free=8.8, wall=77938
2023-05-21 15:36:59 - progress_bar.py[line:272] - INFO: epoch 012:   1194 / 1732 loss=2.431, loss_v1=0, loss_v2=0, nll_loss=1.236, ntokens=1042.6, nsentences=32, sample_size=1042.6, sample_size_v1=0, sample_size_v2=0, ppl=2.35, wps=269.6, ups=0.26, wpb=1042.6, bsz=32, num_updates=20210, lr=6.50042e-06, gnorm=11.888, clip=100, loss_scale=32, train_wall=39, gb_free=8.7, wall=77976
2023-05-21 15:37:38 - progress_bar.py[line:272] - INFO: epoch 012:   1204 / 1732 loss=2.379, loss_v1=0, loss_v2=0, nll_loss=1.174, ntokens=1150.2, nsentences=32, sample_size=1150.2, sample_size_v1=0, sample_size_v2=0, ppl=2.26, wps=293.4, ups=0.26, wpb=1150.2, bsz=32, num_updates=20220, lr=6.49837e-06, gnorm=10.534, clip=100, loss_scale=32, train_wall=39, gb_free=8.4, wall=78016
2023-05-21 15:38:17 - progress_bar.py[line:272] - INFO: epoch 012:   1214 / 1732 loss=2.415, loss_v1=0, loss_v2=0, nll_loss=1.217, ntokens=996.3, nsentences=32, sample_size=996.3, sample_size_v1=0, sample_size_v2=0, ppl=2.32, wps=259.5, ups=0.26, wpb=996.3, bsz=32, num_updates=20230, lr=6.49632e-06, gnorm=11.248, clip=100, loss_scale=32, train_wall=38, gb_free=8.9, wall=78054
2023-05-21 15:38:55 - progress_bar.py[line:272] - INFO: epoch 012:   1224 / 1732 loss=2.438, loss_v1=0, loss_v2=0, nll_loss=1.243, ntokens=1056.3, nsentences=32, sample_size=1056.3, sample_size_v1=0, sample_size_v2=0, ppl=2.37, wps=275, ups=0.26, wpb=1056.3, bsz=32, num_updates=20240, lr=6.49428e-06, gnorm=12.367, clip=100, loss_scale=32, train_wall=38, gb_free=8.7, wall=78092
2023-05-21 15:39:33 - progress_bar.py[line:272] - INFO: epoch 012:   1234 / 1732 loss=2.405, loss_v1=0, loss_v2=0, nll_loss=1.207, ntokens=1012.2, nsentences=32, sample_size=1012.2, sample_size_v1=0, sample_size_v2=0, ppl=2.31, wps=264.4, ups=0.26, wpb=1012.2, bsz=32, num_updates=20250, lr=6.49223e-06, gnorm=11.805, clip=100, loss_scale=32, train_wall=38, gb_free=8.7, wall=78131
2023-05-21 15:40:12 - progress_bar.py[line:272] - INFO: epoch 012:   1244 / 1732 loss=2.349, loss_v1=0, loss_v2=0, nll_loss=1.145, ntokens=1090.2, nsentences=32, sample_size=1090.2, sample_size_v1=0, sample_size_v2=0, ppl=2.21, wps=283.6, ups=0.26, wpb=1090.2, bsz=32, num_updates=20260, lr=6.49018e-06, gnorm=11.627, clip=100, loss_scale=32, train_wall=38, gb_free=8.6, wall=78169
2023-05-21 15:40:50 - progress_bar.py[line:272] - INFO: epoch 012:   1254 / 1732 loss=2.381, loss_v1=0, loss_v2=0, nll_loss=1.18, ntokens=1076, nsentences=32, sample_size=1076, sample_size_v1=0, sample_size_v2=0, ppl=2.27, wps=279.9, ups=0.26, wpb=1076, bsz=32, num_updates=20270, lr=6.48814e-06, gnorm=10.86, clip=100, loss_scale=32, train_wall=38, gb_free=8.8, wall=78208
2023-05-21 15:41:29 - progress_bar.py[line:272] - INFO: epoch 012:   1264 / 1732 loss=2.419, loss_v1=0, loss_v2=0, nll_loss=1.221, ntokens=1095.2, nsentences=32, sample_size=1095.2, sample_size_v1=0, sample_size_v2=0, ppl=2.33, wps=283.4, ups=0.26, wpb=1095.2, bsz=32, num_updates=20280, lr=6.48609e-06, gnorm=11.37, clip=100, loss_scale=32, train_wall=39, gb_free=7.8, wall=78246
2023-05-21 15:42:07 - progress_bar.py[line:272] - INFO: epoch 012:   1274 / 1732 loss=2.411, loss_v1=0, loss_v2=0, nll_loss=1.214, ntokens=1014.1, nsentences=32, sample_size=1014.1, sample_size_v1=0, sample_size_v2=0, ppl=2.32, wps=265, ups=0.26, wpb=1014.1, bsz=32, num_updates=20290, lr=6.48404e-06, gnorm=13.282, clip=100, loss_scale=32, train_wall=38, gb_free=8.1, wall=78284
2023-05-21 15:42:46 - progress_bar.py[line:272] - INFO: epoch 012:   1284 / 1732 loss=2.409, loss_v1=0, loss_v2=0, nll_loss=1.212, ntokens=1057.3, nsentences=32, sample_size=1057.3, sample_size_v1=0, sample_size_v2=0, ppl=2.32, wps=273.1, ups=0.26, wpb=1057.3, bsz=32, num_updates=20300, lr=6.48199e-06, gnorm=12.593, clip=100, loss_scale=32, train_wall=39, gb_free=8.8, wall=78323
2023-05-21 15:43:24 - progress_bar.py[line:272] - INFO: epoch 012:   1294 / 1732 loss=2.391, loss_v1=0, loss_v2=0, nll_loss=1.191, ntokens=1109.4, nsentences=32, sample_size=1109.4, sample_size_v1=0, sample_size_v2=0, ppl=2.28, wps=288.3, ups=0.26, wpb=1109.4, bsz=32, num_updates=20310, lr=6.47995e-06, gnorm=11.053, clip=100, loss_scale=32, train_wall=38, gb_free=8.3, wall=78362
2023-05-21 15:44:03 - progress_bar.py[line:272] - INFO: epoch 012:   1304 / 1732 loss=2.418, loss_v1=0, loss_v2=0, nll_loss=1.221, ntokens=1090.1, nsentences=32, sample_size=1090.1, sample_size_v1=0, sample_size_v2=0, ppl=2.33, wps=281.5, ups=0.26, wpb=1090.1, bsz=32, num_updates=20320, lr=6.4779e-06, gnorm=10.752, clip=100, loss_scale=64, train_wall=39, gb_free=8.3, wall=78400
2023-05-21 15:44:42 - progress_bar.py[line:272] - INFO: epoch 012:   1314 / 1732 loss=2.425, loss_v1=0, loss_v2=0, nll_loss=1.227, ntokens=1051.4, nsentences=32, sample_size=1051.4, sample_size_v1=0, sample_size_v2=0, ppl=2.34, wps=271.5, ups=0.26, wpb=1051.4, bsz=32, num_updates=20330, lr=6.47585e-06, gnorm=11.368, clip=100, loss_scale=64, train_wall=39, gb_free=8, wall=78439
2023-05-21 15:45:21 - progress_bar.py[line:272] - INFO: epoch 012:   1324 / 1732 loss=2.38, loss_v1=0, loss_v2=0, nll_loss=1.179, ntokens=1117, nsentences=32, sample_size=1117, sample_size_v1=0, sample_size_v2=0, ppl=2.26, wps=287.7, ups=0.26, wpb=1117, bsz=32, num_updates=20340, lr=6.4738e-06, gnorm=12.556, clip=100, loss_scale=64, train_wall=39, gb_free=8.5, wall=78478
2023-05-21 15:45:59 - progress_bar.py[line:272] - INFO: epoch 012:   1334 / 1732 loss=2.382, loss_v1=0, loss_v2=0, nll_loss=1.181, ntokens=1097.8, nsentences=32, sample_size=1097.8, sample_size_v1=0, sample_size_v2=0, ppl=2.27, wps=284, ups=0.26, wpb=1097.8, bsz=32, num_updates=20350, lr=6.47176e-06, gnorm=12.807, clip=100, loss_scale=64, train_wall=39, gb_free=8.8, wall=78517
2023-05-21 15:46:38 - progress_bar.py[line:272] - INFO: epoch 012:   1344 / 1732 loss=2.386, loss_v1=0, loss_v2=0, nll_loss=1.186, ntokens=1201.2, nsentences=32, sample_size=1201.2, sample_size_v1=0, sample_size_v2=0, ppl=2.27, wps=308.6, ups=0.26, wpb=1201.2, bsz=32, num_updates=20360, lr=6.46971e-06, gnorm=11.412, clip=100, loss_scale=64, train_wall=39, gb_free=8, wall=78556
2023-05-21 15:47:17 - progress_bar.py[line:272] - INFO: epoch 012:   1354 / 1732 loss=2.4, loss_v1=0, loss_v2=0, nll_loss=1.202, ntokens=1101.2, nsentences=32, sample_size=1101.2, sample_size_v1=0, sample_size_v2=0, ppl=2.3, wps=282.2, ups=0.26, wpb=1101.2, bsz=32, num_updates=20370, lr=6.46766e-06, gnorm=11.409, clip=100, loss_scale=64, train_wall=39, gb_free=8.6, wall=78595
2023-05-21 15:47:56 - progress_bar.py[line:272] - INFO: epoch 012:   1364 / 1732 loss=2.376, loss_v1=0, loss_v2=0, nll_loss=1.172, ntokens=1115.3, nsentences=32, sample_size=1115.3, sample_size_v1=0, sample_size_v2=0, ppl=2.25, wps=288, ups=0.26, wpb=1115.3, bsz=32, num_updates=20380, lr=6.46561e-06, gnorm=10.814, clip=100, loss_scale=64, train_wall=39, gb_free=8.2, wall=78633
2023-05-21 15:48:35 - progress_bar.py[line:272] - INFO: epoch 012:   1374 / 1732 loss=2.433, loss_v1=0, loss_v2=0, nll_loss=1.238, ntokens=1075.1, nsentences=32, sample_size=1075.1, sample_size_v1=0, sample_size_v2=0, ppl=2.36, wps=279.8, ups=0.26, wpb=1075.1, bsz=32, num_updates=20390, lr=6.46357e-06, gnorm=10.672, clip=100, loss_scale=64, train_wall=38, gb_free=8.9, wall=78672
2023-05-21 15:49:13 - progress_bar.py[line:272] - INFO: epoch 012:   1384 / 1732 loss=2.411, loss_v1=0, loss_v2=0, nll_loss=1.213, ntokens=1167.1, nsentences=32, sample_size=1167.1, sample_size_v1=0, sample_size_v2=0, ppl=2.32, wps=301.9, ups=0.26, wpb=1167.1, bsz=32, num_updates=20400, lr=6.46152e-06, gnorm=12.464, clip=100, loss_scale=64, train_wall=39, gb_free=7.9, wall=78710
2023-05-21 15:49:44 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2023-05-21 15:49:55 - progress_bar.py[line:272] - INFO: epoch 012:   1395 / 1732 loss=2.403, loss_v1=0, loss_v2=0, nll_loss=1.203, ntokens=1085.4, nsentences=32, sample_size=1085.4, sample_size_v1=0, sample_size_v2=0, ppl=2.3, wps=257, ups=0.24, wpb=1085.4, bsz=32, num_updates=20410, lr=6.45947e-06, gnorm=12.701, clip=100, loss_scale=32, train_wall=42, gb_free=8.3, wall=78753
2023-05-21 15:50:34 - progress_bar.py[line:272] - INFO: epoch 012:   1405 / 1732 loss=2.388, loss_v1=0, loss_v2=0, nll_loss=1.186, ntokens=1161.5, nsentences=32, sample_size=1161.5, sample_size_v1=0, sample_size_v2=0, ppl=2.28, wps=298.2, ups=0.26, wpb=1161.5, bsz=32, num_updates=20420, lr=6.45742e-06, gnorm=12.229, clip=100, loss_scale=32, train_wall=39, gb_free=8.1, wall=78792
2023-05-21 15:51:14 - progress_bar.py[line:272] - INFO: epoch 012:   1415 / 1732 loss=2.423, loss_v1=0, loss_v2=0, nll_loss=1.228, ntokens=1285.3, nsentences=32, sample_size=1285.3, sample_size_v1=0, sample_size_v2=0, ppl=2.34, wps=327.1, ups=0.25, wpb=1285.3, bsz=32, num_updates=20430, lr=6.45538e-06, gnorm=9.451, clip=100, loss_scale=32, train_wall=39, gb_free=7.8, wall=78831
2023-05-21 15:51:53 - progress_bar.py[line:272] - INFO: epoch 012:   1425 / 1732 loss=2.383, loss_v1=0, loss_v2=0, nll_loss=1.181, ntokens=1231.8, nsentences=32, sample_size=1231.8, sample_size_v1=0, sample_size_v2=0, ppl=2.27, wps=315, ups=0.26, wpb=1231.8, bsz=32, num_updates=20440, lr=6.45333e-06, gnorm=9.894, clip=100, loss_scale=32, train_wall=39, gb_free=6.9, wall=78870
2023-05-21 15:52:32 - progress_bar.py[line:272] - INFO: epoch 012:   1435 / 1732 loss=2.379, loss_v1=0, loss_v2=0, nll_loss=1.178, ntokens=1210.6, nsentences=32, sample_size=1210.6, sample_size_v1=0, sample_size_v2=0, ppl=2.26, wps=312.3, ups=0.26, wpb=1210.6, bsz=32, num_updates=20450, lr=6.45128e-06, gnorm=9.506, clip=100, loss_scale=32, train_wall=39, gb_free=8.5, wall=78909
2023-05-21 15:53:10 - progress_bar.py[line:272] - INFO: epoch 012:   1445 / 1732 loss=2.418, loss_v1=0, loss_v2=0, nll_loss=1.222, ntokens=1117.4, nsentences=32, sample_size=1117.4, sample_size_v1=0, sample_size_v2=0, ppl=2.33, wps=288.4, ups=0.26, wpb=1117.4, bsz=32, num_updates=20460, lr=6.44924e-06, gnorm=11.018, clip=100, loss_scale=32, train_wall=39, gb_free=8.6, wall=78948
2023-05-21 15:53:49 - progress_bar.py[line:272] - INFO: epoch 012:   1455 / 1732 loss=2.413, loss_v1=0, loss_v2=0, nll_loss=1.217, ntokens=1125.4, nsentences=32, sample_size=1125.4, sample_size_v1=0, sample_size_v2=0, ppl=2.32, wps=291.1, ups=0.26, wpb=1125.4, bsz=32, num_updates=20470, lr=6.44719e-06, gnorm=11.199, clip=100, loss_scale=32, train_wall=39, gb_free=8.3, wall=78986
2023-05-21 15:54:28 - progress_bar.py[line:272] - INFO: epoch 012:   1465 / 1732 loss=2.354, loss_v1=0, loss_v2=0, nll_loss=1.148, ntokens=1185.4, nsentences=32, sample_size=1185.4, sample_size_v1=0, sample_size_v2=0, ppl=2.22, wps=303.7, ups=0.26, wpb=1185.4, bsz=32, num_updates=20480, lr=6.44514e-06, gnorm=10.535, clip=100, loss_scale=32, train_wall=39, gb_free=8.5, wall=79025
2023-05-21 15:55:06 - progress_bar.py[line:272] - INFO: epoch 012:   1475 / 1732 loss=2.414, loss_v1=0, loss_v2=0, nll_loss=1.216, ntokens=1082.9, nsentences=32, sample_size=1082.9, sample_size_v1=0, sample_size_v2=0, ppl=2.32, wps=281.7, ups=0.26, wpb=1082.9, bsz=32, num_updates=20490, lr=6.44309e-06, gnorm=11.779, clip=100, loss_scale=32, train_wall=38, gb_free=8.1, wall=79064
2023-05-21 15:55:45 - progress_bar.py[line:272] - INFO: epoch 012:   1485 / 1732 loss=2.414, loss_v1=0, loss_v2=0, nll_loss=1.218, ntokens=1103.4, nsentences=32, sample_size=1103.4, sample_size_v1=0, sample_size_v2=0, ppl=2.33, wps=286.4, ups=0.26, wpb=1103.4, bsz=32, num_updates=20500, lr=6.44105e-06, gnorm=10.798, clip=100, loss_scale=32, train_wall=38, gb_free=7.7, wall=79102
2023-05-21 15:56:24 - progress_bar.py[line:272] - INFO: epoch 012:   1495 / 1732 loss=2.383, loss_v1=0, loss_v2=0, nll_loss=1.181, ntokens=1111.1, nsentences=32, sample_size=1111.1, sample_size_v1=0, sample_size_v2=0, ppl=2.27, wps=286.1, ups=0.26, wpb=1111.1, bsz=32, num_updates=20510, lr=6.439e-06, gnorm=9.751, clip=100, loss_scale=32, train_wall=39, gb_free=7.5, wall=79141
2023-05-21 15:57:02 - progress_bar.py[line:272] - INFO: epoch 012:   1505 / 1732 loss=2.351, loss_v1=0, loss_v2=0, nll_loss=1.147, ntokens=1137.1, nsentences=32, sample_size=1137.1, sample_size_v1=0, sample_size_v2=0, ppl=2.21, wps=295.2, ups=0.26, wpb=1137.1, bsz=32, num_updates=20520, lr=6.43695e-06, gnorm=10.84, clip=100, loss_scale=32, train_wall=38, gb_free=8.5, wall=79180
2023-05-21 15:57:41 - progress_bar.py[line:272] - INFO: epoch 012:   1515 / 1732 loss=2.41, loss_v1=0, loss_v2=0, nll_loss=1.214, ntokens=1046.4, nsentences=32, sample_size=1046.4, sample_size_v1=0, sample_size_v2=0, ppl=2.32, wps=273.6, ups=0.26, wpb=1046.4, bsz=32, num_updates=20530, lr=6.4349e-06, gnorm=11.824, clip=100, loss_scale=32, train_wall=38, gb_free=8.3, wall=79218
2023-05-21 15:58:19 - progress_bar.py[line:272] - INFO: epoch 012:   1525 / 1732 loss=2.441, loss_v1=0, loss_v2=0, nll_loss=1.247, ntokens=1040.6, nsentences=32, sample_size=1040.6, sample_size_v1=0, sample_size_v2=0, ppl=2.37, wps=271.8, ups=0.26, wpb=1040.6, bsz=32, num_updates=20540, lr=6.43286e-06, gnorm=11.503, clip=100, loss_scale=32, train_wall=38, gb_free=8.1, wall=79256
2023-05-21 15:58:58 - progress_bar.py[line:272] - INFO: epoch 012:   1535 / 1732 loss=2.405, loss_v1=0, loss_v2=0, nll_loss=1.205, ntokens=1087.5, nsentences=32, sample_size=1087.5, sample_size_v1=0, sample_size_v2=0, ppl=2.31, wps=280.7, ups=0.26, wpb=1087.5, bsz=32, num_updates=20550, lr=6.43081e-06, gnorm=11.93, clip=100, loss_scale=32, train_wall=39, gb_free=7.8, wall=79295
2023-05-21 15:59:36 - progress_bar.py[line:272] - INFO: epoch 012:   1545 / 1732 loss=2.376, loss_v1=0, loss_v2=0, nll_loss=1.172, ntokens=1079.7, nsentences=32, sample_size=1079.7, sample_size_v1=0, sample_size_v2=0, ppl=2.25, wps=281.2, ups=0.26, wpb=1079.7, bsz=32, num_updates=20560, lr=6.42876e-06, gnorm=10.718, clip=100, loss_scale=32, train_wall=38, gb_free=8.8, wall=79333
2023-05-21 16:00:15 - progress_bar.py[line:272] - INFO: epoch 012:   1555 / 1732 loss=2.382, loss_v1=0, loss_v2=0, nll_loss=1.182, ntokens=1057.3, nsentences=32, sample_size=1057.3, sample_size_v1=0, sample_size_v2=0, ppl=2.27, wps=274.7, ups=0.26, wpb=1057.3, bsz=32, num_updates=20570, lr=6.42671e-06, gnorm=11.201, clip=100, loss_scale=32, train_wall=38, gb_free=8.5, wall=79372
2023-05-21 16:00:53 - progress_bar.py[line:272] - INFO: epoch 012:   1565 / 1732 loss=2.434, loss_v1=0, loss_v2=0, nll_loss=1.238, ntokens=1124.1, nsentences=32, sample_size=1124.1, sample_size_v1=0, sample_size_v2=0, ppl=2.36, wps=289.7, ups=0.26, wpb=1124.1, bsz=32, num_updates=20580, lr=6.42467e-06, gnorm=11.231, clip=100, loss_scale=32, train_wall=39, gb_free=7.7, wall=79411
2023-05-21 16:01:32 - progress_bar.py[line:272] - INFO: epoch 012:   1575 / 1732 loss=2.422, loss_v1=0, loss_v2=0, nll_loss=1.226, ntokens=1025.1, nsentences=32, sample_size=1025.1, sample_size_v1=0, sample_size_v2=0, ppl=2.34, wps=266.6, ups=0.26, wpb=1025.1, bsz=32, num_updates=20590, lr=6.42262e-06, gnorm=12.712, clip=100, loss_scale=32, train_wall=38, gb_free=8.9, wall=79449
2023-05-21 16:02:10 - progress_bar.py[line:272] - INFO: epoch 012:   1585 / 1732 loss=2.414, loss_v1=0, loss_v2=0, nll_loss=1.217, ntokens=1049.1, nsentences=32, sample_size=1049.1, sample_size_v1=0, sample_size_v2=0, ppl=2.33, wps=272.7, ups=0.26, wpb=1049.1, bsz=32, num_updates=20600, lr=6.42057e-06, gnorm=11.166, clip=100, loss_scale=32, train_wall=38, gb_free=7.7, wall=79487
2023-05-21 16:02:49 - progress_bar.py[line:272] - INFO: epoch 012:   1595 / 1732 loss=2.384, loss_v1=0, loss_v2=0, nll_loss=1.182, ntokens=1072.1, nsentences=32, sample_size=1072.1, sample_size_v1=0, sample_size_v2=0, ppl=2.27, wps=280, ups=0.26, wpb=1072.1, bsz=32, num_updates=20610, lr=6.41852e-06, gnorm=11.228, clip=100, loss_scale=32, train_wall=38, gb_free=8.2, wall=79526
2023-05-21 16:03:27 - progress_bar.py[line:272] - INFO: epoch 012:   1605 / 1732 loss=2.393, loss_v1=0, loss_v2=0, nll_loss=1.194, ntokens=1099, nsentences=32, sample_size=1099, sample_size_v1=0, sample_size_v2=0, ppl=2.29, wps=286.6, ups=0.26, wpb=1099, bsz=32, num_updates=20620, lr=6.41648e-06, gnorm=11.362, clip=100, loss_scale=32, train_wall=38, gb_free=8.3, wall=79564
2023-05-21 16:04:06 - progress_bar.py[line:272] - INFO: epoch 012:   1615 / 1732 loss=2.354, loss_v1=0, loss_v2=0, nll_loss=1.149, ntokens=1176.8, nsentences=32, sample_size=1176.8, sample_size_v1=0, sample_size_v2=0, ppl=2.22, wps=303.3, ups=0.26, wpb=1176.8, bsz=32, num_updates=20630, lr=6.41443e-06, gnorm=10.473, clip=100, loss_scale=32, train_wall=39, gb_free=8.5, wall=79603
2023-05-21 16:04:44 - progress_bar.py[line:272] - INFO: epoch 012:   1625 / 1732 loss=2.398, loss_v1=0, loss_v2=0, nll_loss=1.199, ntokens=1075.4, nsentences=32, sample_size=1075.4, sample_size_v1=0, sample_size_v2=0, ppl=2.3, wps=278.5, ups=0.26, wpb=1075.4, bsz=32, num_updates=20640, lr=6.41238e-06, gnorm=11.189, clip=100, loss_scale=32, train_wall=39, gb_free=7.6, wall=79642
2023-05-21 16:05:23 - progress_bar.py[line:272] - INFO: epoch 012:   1635 / 1732 loss=2.369, loss_v1=0, loss_v2=0, nll_loss=1.168, ntokens=1182.6, nsentences=32, sample_size=1182.6, sample_size_v1=0, sample_size_v2=0, ppl=2.25, wps=306.9, ups=0.26, wpb=1182.6, bsz=32, num_updates=20650, lr=6.41034e-06, gnorm=10.481, clip=100, loss_scale=32, train_wall=38, gb_free=7.7, wall=79680
2023-05-21 16:06:02 - progress_bar.py[line:272] - INFO: epoch 012:   1645 / 1732 loss=2.346, loss_v1=0, loss_v2=0, nll_loss=1.139, ntokens=1274.6, nsentences=32, sample_size=1274.6, sample_size_v1=0, sample_size_v2=0, ppl=2.2, wps=326.6, ups=0.26, wpb=1274.6, bsz=32, num_updates=20660, lr=6.40829e-06, gnorm=9.847, clip=100, loss_scale=32, train_wall=39, gb_free=8.2, wall=79719
2023-05-21 16:06:40 - progress_bar.py[line:272] - INFO: epoch 012:   1655 / 1732 loss=2.42, loss_v1=0, loss_v2=0, nll_loss=1.222, ntokens=951.7, nsentences=32, sample_size=951.7, sample_size_v1=0, sample_size_v2=0, ppl=2.33, wps=250.2, ups=0.26, wpb=951.7, bsz=32, num_updates=20670, lr=6.40624e-06, gnorm=12.864, clip=100, loss_scale=32, train_wall=38, gb_free=8.3, wall=79757
2023-05-21 16:07:18 - progress_bar.py[line:272] - INFO: epoch 012:   1665 / 1732 loss=2.415, loss_v1=0, loss_v2=0, nll_loss=1.218, ntokens=1028.1, nsentences=32, sample_size=1028.1, sample_size_v1=0, sample_size_v2=0, ppl=2.33, wps=268, ups=0.26, wpb=1028.1, bsz=32, num_updates=20680, lr=6.40419e-06, gnorm=11.283, clip=100, loss_scale=32, train_wall=38, gb_free=8.3, wall=79796
2023-05-21 16:07:57 - progress_bar.py[line:272] - INFO: epoch 012:   1675 / 1732 loss=2.35, loss_v1=0, loss_v2=0, nll_loss=1.143, ntokens=1102.6, nsentences=32, sample_size=1102.6, sample_size_v1=0, sample_size_v2=0, ppl=2.21, wps=286.3, ups=0.26, wpb=1102.6, bsz=32, num_updates=20690, lr=6.40215e-06, gnorm=10.744, clip=100, loss_scale=32, train_wall=38, gb_free=6.8, wall=79834
2023-05-21 16:08:36 - progress_bar.py[line:272] - INFO: epoch 012:   1685 / 1732 loss=2.355, loss_v1=0, loss_v2=0, nll_loss=1.149, ntokens=1141.1, nsentences=32, sample_size=1141.1, sample_size_v1=0, sample_size_v2=0, ppl=2.22, wps=294, ups=0.26, wpb=1141.1, bsz=32, num_updates=20700, lr=6.4001e-06, gnorm=10.194, clip=100, loss_scale=32, train_wall=39, gb_free=8.5, wall=79873
2023-05-21 16:09:15 - progress_bar.py[line:272] - INFO: epoch 012:   1695 / 1732 loss=2.386, loss_v1=0, loss_v2=0, nll_loss=1.187, ntokens=1274.5, nsentences=32, sample_size=1274.5, sample_size_v1=0, sample_size_v2=0, ppl=2.28, wps=323.6, ups=0.25, wpb=1274.5, bsz=32, num_updates=20710, lr=6.39805e-06, gnorm=9.807, clip=100, loss_scale=32, train_wall=39, gb_free=8.2, wall=79912
2023-05-21 16:09:54 - progress_bar.py[line:272] - INFO: epoch 012:   1705 / 1732 loss=2.381, loss_v1=0, loss_v2=0, nll_loss=1.181, ntokens=1217, nsentences=32, sample_size=1217, sample_size_v1=0, sample_size_v2=0, ppl=2.27, wps=310.5, ups=0.26, wpb=1217, bsz=32, num_updates=20720, lr=6.396e-06, gnorm=10.157, clip=100, loss_scale=32, train_wall=39, gb_free=7.9, wall=79951
2023-05-21 16:10:33 - progress_bar.py[line:272] - INFO: epoch 012:   1715 / 1732 loss=2.367, loss_v1=0, loss_v2=0, nll_loss=1.164, ntokens=1196, nsentences=32, sample_size=1196, sample_size_v1=0, sample_size_v2=0, ppl=2.24, wps=307.1, ups=0.26, wpb=1196, bsz=32, num_updates=20730, lr=6.39396e-06, gnorm=10.109, clip=100, loss_scale=32, train_wall=39, gb_free=7.9, wall=79990
2023-05-21 16:11:12 - progress_bar.py[line:272] - INFO: epoch 012:   1725 / 1732 loss=2.396, loss_v1=0, loss_v2=0, nll_loss=1.196, ntokens=1108.9, nsentences=32, sample_size=1108.9, sample_size_v1=0, sample_size_v2=0, ppl=2.29, wps=285.6, ups=0.26, wpb=1108.9, bsz=32, num_updates=20740, lr=6.39191e-06, gnorm=9.7, clip=100, loss_scale=32, train_wall=39, gb_free=8.5, wall=80029
2023-05-21 16:11:36 - train.py[line:332] - INFO: end of epoch 12 (average epoch stats below)
2023-05-21 16:11:36 - progress_bar.py[line:282] - INFO: epoch 012 | loss 2.402 | loss_v1 0 | loss_v2 0 | nll_loss 1.203 | ntokens 1051.73 | nsentences 31.986 | sample_size 1051.73 | sample_size_v1 0 | sample_size_v2 0 | ppl 2.3 | wps 273 | ups 0.26 | wpb 1051.7 | bsz 32 | num_updates 20747 | lr 6.39048e-06 | gnorm 11.183 | clip 100 | loss_scale 32 | train_wall 6650 | gb_free 8.9 | wall 80054
2023-05-21 16:11:36 - trainer.py[line:639] - INFO: loading train data for epoch 13
local datafile ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 0 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 0 finished initializing row_count and line_idx-to-offset mapping
file ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 0 row count 55400 total row count 55400
slice_id 0 seek offset 0
2023-05-21 16:11:38 - trainer.py[line:703] - INFO: begin training epoch 13
2023-05-21 16:11:38 - train.py[line:305] - INFO: Start iterating over samples
2023-05-21 16:11:50 - progress_bar.py[line:272] - INFO: epoch 013:      3 / 1732 loss=2.403, loss_v1=0, loss_v2=0, nll_loss=1.202, ntokens=1127.6, nsentences=29.6, sample_size=1127.6, sample_size_v1=0, sample_size_v2=0, ppl=2.3, wps=295.7, ups=0.26, wpb=1127.6, bsz=29.6, num_updates=20750, lr=6.38986e-06, gnorm=11.78, clip=100, loss_scale=32, train_wall=36, gb_free=8.2, wall=80067
2023-05-21 16:12:29 - progress_bar.py[line:272] - INFO: epoch 013:     13 / 1732 loss=2.34, loss_v1=0, loss_v2=0, nll_loss=1.133, ntokens=1037.7, nsentences=32, sample_size=1037.7, sample_size_v1=0, sample_size_v2=0, ppl=2.19, wps=268.9, ups=0.26, wpb=1037.7, bsz=32, num_updates=20760, lr=6.38781e-06, gnorm=12.443, clip=100, loss_scale=32, train_wall=39, gb_free=8.2, wall=80106
2023-05-21 16:13:07 - progress_bar.py[line:272] - INFO: epoch 013:     23 / 1732 loss=2.276, loss_v1=0, loss_v2=0, nll_loss=1.062, ntokens=1082, nsentences=32, sample_size=1082, sample_size_v1=0, sample_size_v2=0, ppl=2.09, wps=280.5, ups=0.26, wpb=1082, bsz=32, num_updates=20770, lr=6.38577e-06, gnorm=11.003, clip=100, loss_scale=32, train_wall=39, gb_free=8.6, wall=80145
2023-05-21 16:13:46 - progress_bar.py[line:272] - INFO: epoch 013:     33 / 1732 loss=2.263, loss_v1=0, loss_v2=0, nll_loss=1.046, ntokens=1032.3, nsentences=32, sample_size=1032.3, sample_size_v1=0, sample_size_v2=0, ppl=2.06, wps=267, ups=0.26, wpb=1032.3, bsz=32, num_updates=20780, lr=6.38372e-06, gnorm=11.223, clip=100, loss_scale=32, train_wall=39, gb_free=7.2, wall=80183
2023-05-21 16:14:25 - progress_bar.py[line:272] - INFO: epoch 013:     43 / 1732 loss=2.173, loss_v1=0, loss_v2=0, nll_loss=0.954, ntokens=1156.8, nsentences=32, sample_size=1156.8, sample_size_v1=0, sample_size_v2=0, ppl=1.94, wps=296.7, ups=0.26, wpb=1156.8, bsz=32, num_updates=20790, lr=6.38167e-06, gnorm=9.427, clip=100, loss_scale=32, train_wall=39, gb_free=8.1, wall=80222
2023-05-21 16:15:04 - progress_bar.py[line:272] - INFO: epoch 013:     53 / 1732 loss=2.235, loss_v1=0, loss_v2=0, nll_loss=1.017, ntokens=1016.6, nsentences=32, sample_size=1016.6, sample_size_v1=0, sample_size_v2=0, ppl=2.02, wps=263.6, ups=0.26, wpb=1016.6, bsz=32, num_updates=20800, lr=6.37962e-06, gnorm=11.553, clip=100, loss_scale=32, train_wall=39, gb_free=8.6, wall=80261
2023-05-21 16:15:43 - progress_bar.py[line:272] - INFO: epoch 013:     63 / 1732 loss=2.02, loss_v1=0, loss_v2=0, nll_loss=0.775, ntokens=1239.4, nsentences=32, sample_size=1239.4, sample_size_v1=0, sample_size_v2=0, ppl=1.71, wps=318.2, ups=0.26, wpb=1239.4, bsz=32, num_updates=20810, lr=6.37758e-06, gnorm=7.548, clip=100, loss_scale=32, train_wall=39, gb_free=7.3, wall=80300
2023-05-21 16:16:22 - progress_bar.py[line:272] - INFO: epoch 013:     73 / 1732 loss=2.153, loss_v1=0, loss_v2=0, nll_loss=0.927, ntokens=1389.6, nsentences=32, sample_size=1389.6, sample_size_v1=0, sample_size_v2=0, ppl=1.9, wps=349.6, ups=0.25, wpb=1389.6, bsz=32, num_updates=20820, lr=6.37553e-06, gnorm=9.072, clip=100, loss_scale=32, train_wall=40, gb_free=7, wall=80339
2023-05-21 16:17:02 - progress_bar.py[line:272] - INFO: epoch 013:     83 / 1732 loss=2.186, loss_v1=0, loss_v2=0, nll_loss=0.957, ntokens=1166.3, nsentences=32, sample_size=1166.3, sample_size_v1=0, sample_size_v2=0, ppl=1.94, wps=296.2, ups=0.25, wpb=1166.3, bsz=32, num_updates=20830, lr=6.37348e-06, gnorm=9.838, clip=100, loss_scale=32, train_wall=39, gb_free=7.2, wall=80379
2023-05-21 16:17:40 - progress_bar.py[line:272] - INFO: epoch 013:     93 / 1732 loss=2.175, loss_v1=0, loss_v2=0, nll_loss=0.951, ntokens=1099.1, nsentences=32, sample_size=1099.1, sample_size_v1=0, sample_size_v2=0, ppl=1.93, wps=283, ups=0.26, wpb=1099.1, bsz=32, num_updates=20840, lr=6.37144e-06, gnorm=9.844, clip=100, loss_scale=32, train_wall=39, gb_free=8.2, wall=80418
2023-05-21 16:18:19 - progress_bar.py[line:272] - INFO: epoch 013:    103 / 1732 loss=2.346, loss_v1=0, loss_v2=0, nll_loss=1.142, ntokens=976, nsentences=32, sample_size=976, sample_size_v1=0, sample_size_v2=0, ppl=2.21, wps=255.6, ups=0.26, wpb=976, bsz=32, num_updates=20850, lr=6.36939e-06, gnorm=12.204, clip=100, loss_scale=32, train_wall=38, gb_free=8.6, wall=80456
2023-05-21 16:18:57 - progress_bar.py[line:272] - INFO: epoch 013:    113 / 1732 loss=2.4, loss_v1=0, loss_v2=0, nll_loss=1.204, ntokens=1030.9, nsentences=32, sample_size=1030.9, sample_size_v1=0, sample_size_v2=0, ppl=2.3, wps=267.8, ups=0.26, wpb=1030.9, bsz=32, num_updates=20860, lr=6.36734e-06, gnorm=11.189, clip=100, loss_scale=32, train_wall=38, gb_free=7.8, wall=80494
2023-05-21 16:19:36 - progress_bar.py[line:272] - INFO: epoch 013:    123 / 1732 loss=2.369, loss_v1=0, loss_v2=0, nll_loss=1.168, ntokens=1142.2, nsentences=32, sample_size=1142.2, sample_size_v1=0, sample_size_v2=0, ppl=2.25, wps=292, ups=0.26, wpb=1142.2, bsz=32, num_updates=20870, lr=6.36529e-06, gnorm=10.682, clip=100, loss_scale=32, train_wall=39, gb_free=7.6, wall=80533
2023-05-21 16:20:16 - progress_bar.py[line:272] - INFO: epoch 013:    133 / 1732 loss=2.309, loss_v1=0, loss_v2=0, nll_loss=1.097, ntokens=1207.4, nsentences=32, sample_size=1207.4, sample_size_v1=0, sample_size_v2=0, ppl=2.14, wps=306.3, ups=0.25, wpb=1207.4, bsz=32, num_updates=20880, lr=6.36325e-06, gnorm=8.727, clip=100, loss_scale=32, train_wall=39, gb_free=8, wall=80573
2023-05-21 16:20:55 - progress_bar.py[line:272] - INFO: epoch 013:    143 / 1732 loss=2.297, loss_v1=0, loss_v2=0, nll_loss=1.084, ntokens=1226.6, nsentences=32, sample_size=1226.6, sample_size_v1=0, sample_size_v2=0, ppl=2.12, wps=311.2, ups=0.25, wpb=1226.6, bsz=32, num_updates=20890, lr=6.3612e-06, gnorm=7.905, clip=100, loss_scale=32, train_wall=39, gb_free=7.2, wall=80612
2023-05-21 16:21:34 - progress_bar.py[line:272] - INFO: epoch 013:    153 / 1732 loss=2.31, loss_v1=0, loss_v2=0, nll_loss=1.101, ntokens=1152.6, nsentences=32, sample_size=1152.6, sample_size_v1=0, sample_size_v2=0, ppl=2.14, wps=293.1, ups=0.25, wpb=1152.6, bsz=32, num_updates=20900, lr=6.35915e-06, gnorm=8.434, clip=100, loss_scale=32, train_wall=39, gb_free=7.3, wall=80652
2023-05-21 16:22:13 - progress_bar.py[line:272] - INFO: epoch 013:    163 / 1732 loss=2.304, loss_v1=0, loss_v2=0, nll_loss=1.096, ntokens=1079.7, nsentences=32, sample_size=1079.7, sample_size_v1=0, sample_size_v2=0, ppl=2.14, wps=278, ups=0.26, wpb=1079.7, bsz=32, num_updates=20910, lr=6.3571e-06, gnorm=10.357, clip=100, loss_scale=32, train_wall=39, gb_free=8.7, wall=80691
2023-05-21 16:22:52 - progress_bar.py[line:272] - INFO: epoch 013:    173 / 1732 loss=2.319, loss_v1=0, loss_v2=0, nll_loss=1.109, ntokens=936.5, nsentences=32, sample_size=936.5, sample_size_v1=0, sample_size_v2=0, ppl=2.16, wps=244, ups=0.26, wpb=936.5, bsz=32, num_updates=20920, lr=6.35506e-06, gnorm=10.739, clip=100, loss_scale=64, train_wall=38, gb_free=7.8, wall=80729
2023-05-21 16:23:31 - progress_bar.py[line:272] - INFO: epoch 013:    183 / 1732 loss=2.271, loss_v1=0, loss_v2=0, nll_loss=1.055, ntokens=1184.7, nsentences=32, sample_size=1184.7, sample_size_v1=0, sample_size_v2=0, ppl=2.08, wps=302.4, ups=0.26, wpb=1184.7, bsz=32, num_updates=20930, lr=6.35301e-06, gnorm=9.256, clip=100, loss_scale=64, train_wall=39, gb_free=8.4, wall=80768
2023-05-21 16:24:10 - progress_bar.py[line:272] - INFO: epoch 013:    193 / 1732 loss=2.289, loss_v1=0, loss_v2=0, nll_loss=1.077, ntokens=1122.8, nsentences=32, sample_size=1122.8, sample_size_v1=0, sample_size_v2=0, ppl=2.11, wps=285.7, ups=0.25, wpb=1122.8, bsz=32, num_updates=20940, lr=6.35096e-06, gnorm=9.112, clip=100, loss_scale=64, train_wall=39, gb_free=8.2, wall=80807
2023-05-21 16:24:49 - progress_bar.py[line:272] - INFO: epoch 013:    203 / 1732 loss=2.384, loss_v1=0, loss_v2=0, nll_loss=1.185, ntokens=1086.7, nsentences=32, sample_size=1086.7, sample_size_v1=0, sample_size_v2=0, ppl=2.27, wps=281.7, ups=0.26, wpb=1086.7, bsz=32, num_updates=20950, lr=6.34891e-06, gnorm=11.166, clip=100, loss_scale=64, train_wall=39, gb_free=8.5, wall=80846
2023-05-21 16:25:27 - progress_bar.py[line:272] - INFO: epoch 013:    213 / 1732 loss=2.41, loss_v1=0, loss_v2=0, nll_loss=1.213, ntokens=1044.9, nsentences=32, sample_size=1044.9, sample_size_v1=0, sample_size_v2=0, ppl=2.32, wps=274, ups=0.26, wpb=1044.9, bsz=32, num_updates=20960, lr=6.34687e-06, gnorm=10.116, clip=100, loss_scale=64, train_wall=38, gb_free=8.5, wall=80884
2023-05-21 16:25:42 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2023-05-21 16:26:09 - progress_bar.py[line:272] - INFO: epoch 013:    224 / 1732 loss=2.417, loss_v1=0, loss_v2=0, nll_loss=1.22, ntokens=1095, nsentences=32, sample_size=1095, sample_size_v1=0, sample_size_v2=0, ppl=2.33, wps=261.5, ups=0.24, wpb=1095, bsz=32, num_updates=20970, lr=6.34482e-06, gnorm=10.869, clip=100, loss_scale=32, train_wall=42, gb_free=8.4, wall=80926
2023-05-21 16:26:47 - progress_bar.py[line:272] - INFO: epoch 013:    234 / 1732 loss=2.465, loss_v1=0, loss_v2=0, nll_loss=1.273, ntokens=1090.7, nsentences=32, sample_size=1090.7, sample_size_v1=0, sample_size_v2=0, ppl=2.42, wps=287.1, ups=0.26, wpb=1090.7, bsz=32, num_updates=20980, lr=6.34277e-06, gnorm=11.177, clip=100, loss_scale=32, train_wall=38, gb_free=8.4, wall=80964
2023-05-21 16:27:25 - progress_bar.py[line:272] - INFO: epoch 013:    244 / 1732 loss=2.446, loss_v1=0, loss_v2=0, nll_loss=1.25, ntokens=1157.9, nsentences=32, sample_size=1157.9, sample_size_v1=0, sample_size_v2=0, ppl=2.38, wps=300.6, ups=0.26, wpb=1157.9, bsz=32, num_updates=20990, lr=6.34072e-06, gnorm=10.082, clip=100, loss_scale=32, train_wall=38, gb_free=7.8, wall=81002
2023-05-21 16:28:04 - progress_bar.py[line:272] - INFO: epoch 013:    254 / 1732 loss=2.443, loss_v1=0, loss_v2=0, nll_loss=1.249, ntokens=1151.4, nsentences=32, sample_size=1151.4, sample_size_v1=0, sample_size_v2=0, ppl=2.38, wps=299.1, ups=0.26, wpb=1151.4, bsz=32, num_updates=21000, lr=6.33868e-06, gnorm=10.902, clip=100, loss_scale=32, train_wall=38, gb_free=8.4, wall=81041
2023-05-21 16:28:42 - progress_bar.py[line:272] - INFO: epoch 013:    264 / 1732 loss=2.443, loss_v1=0, loss_v2=0, nll_loss=1.248, ntokens=1137.5, nsentences=32, sample_size=1137.5, sample_size_v1=0, sample_size_v2=0, ppl=2.38, wps=297.1, ups=0.26, wpb=1137.5, bsz=32, num_updates=21010, lr=6.33663e-06, gnorm=11.76, clip=100, loss_scale=32, train_wall=38, gb_free=7.8, wall=81079
2023-05-21 16:29:21 - progress_bar.py[line:272] - INFO: epoch 013:    274 / 1732 loss=2.431, loss_v1=0, loss_v2=0, nll_loss=1.235, ntokens=1136.4, nsentences=32, sample_size=1136.4, sample_size_v1=0, sample_size_v2=0, ppl=2.35, wps=294.8, ups=0.26, wpb=1136.4, bsz=32, num_updates=21020, lr=6.33458e-06, gnorm=10.777, clip=100, loss_scale=32, train_wall=38, gb_free=6.3, wall=81118
2023-05-21 16:29:59 - progress_bar.py[line:272] - INFO: epoch 013:    284 / 1732 loss=2.45, loss_v1=0, loss_v2=0, nll_loss=1.255, ntokens=1138.6, nsentences=32, sample_size=1138.6, sample_size_v1=0, sample_size_v2=0, ppl=2.39, wps=295.3, ups=0.26, wpb=1138.6, bsz=32, num_updates=21030, lr=6.33253e-06, gnorm=10.593, clip=100, loss_scale=32, train_wall=39, gb_free=8.4, wall=81156
2023-05-21 16:30:37 - progress_bar.py[line:272] - INFO: epoch 013:    294 / 1732 loss=2.414, loss_v1=0, loss_v2=0, nll_loss=1.217, ntokens=1144.7, nsentences=32, sample_size=1144.7, sample_size_v1=0, sample_size_v2=0, ppl=2.32, wps=298.9, ups=0.26, wpb=1144.7, bsz=32, num_updates=21040, lr=6.33049e-06, gnorm=10.086, clip=100, loss_scale=32, train_wall=38, gb_free=8.8, wall=81195
2023-05-21 16:31:16 - progress_bar.py[line:272] - INFO: epoch 013:    304 / 1732 loss=2.424, loss_v1=0, loss_v2=0, nll_loss=1.228, ntokens=1100.1, nsentences=32, sample_size=1100.1, sample_size_v1=0, sample_size_v2=0, ppl=2.34, wps=288.4, ups=0.26, wpb=1100.1, bsz=32, num_updates=21050, lr=6.32844e-06, gnorm=10.782, clip=100, loss_scale=32, train_wall=38, gb_free=8.6, wall=81233
2023-05-21 16:31:54 - progress_bar.py[line:272] - INFO: epoch 013:    314 / 1732 loss=2.43, loss_v1=0, loss_v2=0, nll_loss=1.234, ntokens=1016.6, nsentences=32, sample_size=1016.6, sample_size_v1=0, sample_size_v2=0, ppl=2.35, wps=267, ups=0.26, wpb=1016.6, bsz=32, num_updates=21060, lr=6.32639e-06, gnorm=12.257, clip=100, loss_scale=32, train_wall=38, gb_free=9.3, wall=81271
2023-05-21 16:32:32 - progress_bar.py[line:272] - INFO: epoch 013:    324 / 1732 loss=2.453, loss_v1=0, loss_v2=0, nll_loss=1.259, ntokens=1018.7, nsentences=32, sample_size=1018.7, sample_size_v1=0, sample_size_v2=0, ppl=2.39, wps=266.5, ups=0.26, wpb=1018.7, bsz=32, num_updates=21070, lr=6.32435e-06, gnorm=11.758, clip=100, loss_scale=32, train_wall=38, gb_free=8.5, wall=81309
2023-05-21 16:33:10 - progress_bar.py[line:272] - INFO: epoch 013:    334 / 1732 loss=2.45, loss_v1=0, loss_v2=0, nll_loss=1.257, ntokens=1018.9, nsentences=32, sample_size=1018.9, sample_size_v1=0, sample_size_v2=0, ppl=2.39, wps=268.3, ups=0.26, wpb=1018.9, bsz=32, num_updates=21080, lr=6.3223e-06, gnorm=10.601, clip=100, loss_scale=32, train_wall=38, gb_free=8.8, wall=81347
2023-05-21 16:33:48 - progress_bar.py[line:272] - INFO: epoch 013:    344 / 1732 loss=2.405, loss_v1=0, loss_v2=0, nll_loss=1.207, ntokens=921, nsentences=32, sample_size=921, sample_size_v1=0, sample_size_v2=0, ppl=2.31, wps=241.9, ups=0.26, wpb=921, bsz=32, num_updates=21090, lr=6.32025e-06, gnorm=11.711, clip=100, loss_scale=32, train_wall=38, gb_free=8.7, wall=81385
2023-05-21 16:34:26 - progress_bar.py[line:272] - INFO: epoch 013:    354 / 1732 loss=2.441, loss_v1=0, loss_v2=0, nll_loss=1.249, ntokens=961.9, nsentences=32, sample_size=961.9, sample_size_v1=0, sample_size_v2=0, ppl=2.38, wps=253.6, ups=0.26, wpb=961.9, bsz=32, num_updates=21100, lr=6.3182e-06, gnorm=12.15, clip=100, loss_scale=32, train_wall=38, gb_free=8.5, wall=81423
2023-05-21 16:35:04 - progress_bar.py[line:272] - INFO: epoch 013:    364 / 1732 loss=2.483, loss_v1=0, loss_v2=0, nll_loss=1.295, ntokens=927.9, nsentences=32, sample_size=927.9, sample_size_v1=0, sample_size_v2=0, ppl=2.45, wps=245, ups=0.26, wpb=927.9, bsz=32, num_updates=21110, lr=6.31616e-06, gnorm=13.678, clip=100, loss_scale=32, train_wall=38, gb_free=9, wall=81461
2023-05-21 16:35:42 - progress_bar.py[line:272] - INFO: epoch 013:    374 / 1732 loss=2.476, loss_v1=0, loss_v2=0, nll_loss=1.283, ntokens=1000.4, nsentences=32, sample_size=1000.4, sample_size_v1=0, sample_size_v2=0, ppl=2.43, wps=262.7, ups=0.26, wpb=1000.4, bsz=32, num_updates=21120, lr=6.31411e-06, gnorm=12.453, clip=100, loss_scale=32, train_wall=38, gb_free=8.7, wall=81499
2023-05-21 16:36:20 - progress_bar.py[line:272] - INFO: epoch 013:    384 / 1732 loss=2.448, loss_v1=0, loss_v2=0, nll_loss=1.253, ntokens=1084.8, nsentences=32, sample_size=1084.8, sample_size_v1=0, sample_size_v2=0, ppl=2.38, wps=286.3, ups=0.26, wpb=1084.8, bsz=32, num_updates=21130, lr=6.31206e-06, gnorm=11.89, clip=100, loss_scale=32, train_wall=38, gb_free=8.1, wall=81537
2023-05-21 16:36:58 - progress_bar.py[line:272] - INFO: epoch 013:    394 / 1732 loss=2.453, loss_v1=0, loss_v2=0, nll_loss=1.258, ntokens=950.6, nsentences=32, sample_size=950.6, sample_size_v1=0, sample_size_v2=0, ppl=2.39, wps=251.6, ups=0.26, wpb=950.6, bsz=32, num_updates=21140, lr=6.31001e-06, gnorm=12.552, clip=100, loss_scale=32, train_wall=38, gb_free=8.9, wall=81575
2023-05-21 16:37:36 - progress_bar.py[line:272] - INFO: epoch 013:    404 / 1732 loss=2.409, loss_v1=0, loss_v2=0, nll_loss=1.213, ntokens=1060.5, nsentences=32, sample_size=1060.5, sample_size_v1=0, sample_size_v2=0, ppl=2.32, wps=276.4, ups=0.26, wpb=1060.5, bsz=32, num_updates=21150, lr=6.30797e-06, gnorm=11.589, clip=100, loss_scale=32, train_wall=38, gb_free=8.1, wall=81613
2023-05-21 16:38:14 - progress_bar.py[line:272] - INFO: epoch 013:    414 / 1732 loss=2.417, loss_v1=0, loss_v2=0, nll_loss=1.221, ntokens=1066.1, nsentences=32, sample_size=1066.1, sample_size_v1=0, sample_size_v2=0, ppl=2.33, wps=279, ups=0.26, wpb=1066.1, bsz=32, num_updates=21160, lr=6.30592e-06, gnorm=11.491, clip=100, loss_scale=32, train_wall=38, gb_free=6.5, wall=81651
2023-05-21 16:38:52 - progress_bar.py[line:272] - INFO: epoch 013:    424 / 1732 loss=2.403, loss_v1=0, loss_v2=0, nll_loss=1.203, ntokens=992.6, nsentences=32, sample_size=992.6, sample_size_v1=0, sample_size_v2=0, ppl=2.3, wps=259.6, ups=0.26, wpb=992.6, bsz=32, num_updates=21170, lr=6.30387e-06, gnorm=11.219, clip=100, loss_scale=32, train_wall=38, gb_free=8.6, wall=81690
2023-05-21 16:39:31 - progress_bar.py[line:272] - INFO: epoch 013:    434 / 1732 loss=2.43, loss_v1=0, loss_v2=0, nll_loss=1.234, ntokens=1018.1, nsentences=32, sample_size=1018.1, sample_size_v1=0, sample_size_v2=0, ppl=2.35, wps=265, ups=0.26, wpb=1018.1, bsz=32, num_updates=21180, lr=6.30182e-06, gnorm=12.145, clip=100, loss_scale=32, train_wall=38, gb_free=9, wall=81728
2023-05-21 16:40:09 - progress_bar.py[line:272] - INFO: epoch 013:    444 / 1732 loss=2.461, loss_v1=0, loss_v2=0, nll_loss=1.27, ntokens=952.1, nsentences=32, sample_size=952.1, sample_size_v1=0, sample_size_v2=0, ppl=2.41, wps=249.8, ups=0.26, wpb=952.1, bsz=32, num_updates=21190, lr=6.29978e-06, gnorm=11.723, clip=100, loss_scale=32, train_wall=38, gb_free=9.1, wall=81766
2023-05-21 16:40:47 - progress_bar.py[line:272] - INFO: epoch 013:    454 / 1732 loss=2.451, loss_v1=0, loss_v2=0, nll_loss=1.258, ntokens=919.5, nsentences=32, sample_size=919.5, sample_size_v1=0, sample_size_v2=0, ppl=2.39, wps=241.7, ups=0.26, wpb=919.5, bsz=32, num_updates=21200, lr=6.29773e-06, gnorm=12.803, clip=100, loss_scale=32, train_wall=38, gb_free=8.6, wall=81804
2023-05-21 16:41:25 - progress_bar.py[line:272] - INFO: epoch 013:    464 / 1732 loss=2.463, loss_v1=0, loss_v2=0, nll_loss=1.271, ntokens=1076.9, nsentences=32, sample_size=1076.9, sample_size_v1=0, sample_size_v2=0, ppl=2.41, wps=280.9, ups=0.26, wpb=1076.9, bsz=32, num_updates=21210, lr=6.29568e-06, gnorm=10.944, clip=100, loss_scale=32, train_wall=38, gb_free=8.9, wall=81843
2023-05-21 16:42:04 - progress_bar.py[line:272] - INFO: epoch 013:    474 / 1732 loss=2.453, loss_v1=0, loss_v2=0, nll_loss=1.26, ntokens=1067.6, nsentences=32, sample_size=1067.6, sample_size_v1=0, sample_size_v2=0, ppl=2.4, wps=278.4, ups=0.26, wpb=1067.6, bsz=32, num_updates=21220, lr=6.29363e-06, gnorm=10.798, clip=100, loss_scale=32, train_wall=38, gb_free=9.1, wall=81881
2023-05-21 16:42:42 - progress_bar.py[line:272] - INFO: epoch 013:    484 / 1732 loss=2.438, loss_v1=0, loss_v2=0, nll_loss=1.242, ntokens=966.8, nsentences=32, sample_size=966.8, sample_size_v1=0, sample_size_v2=0, ppl=2.37, wps=253.8, ups=0.26, wpb=966.8, bsz=32, num_updates=21230, lr=6.29159e-06, gnorm=12.788, clip=100, loss_scale=32, train_wall=38, gb_free=8.7, wall=81919
2023-05-21 16:43:20 - progress_bar.py[line:272] - INFO: epoch 013:    494 / 1732 loss=2.435, loss_v1=0, loss_v2=0, nll_loss=1.24, ntokens=937.9, nsentences=32, sample_size=937.9, sample_size_v1=0, sample_size_v2=0, ppl=2.36, wps=247.1, ups=0.26, wpb=937.9, bsz=32, num_updates=21240, lr=6.28954e-06, gnorm=12.779, clip=100, loss_scale=32, train_wall=38, gb_free=8.5, wall=81957
2023-05-21 16:43:58 - progress_bar.py[line:272] - INFO: epoch 013:    504 / 1732 loss=2.443, loss_v1=0, loss_v2=0, nll_loss=1.25, ntokens=981, nsentences=32, sample_size=981, sample_size_v1=0, sample_size_v2=0, ppl=2.38, wps=259.4, ups=0.26, wpb=981, bsz=32, num_updates=21250, lr=6.28749e-06, gnorm=12.974, clip=100, loss_scale=32, train_wall=38, gb_free=8.6, wall=81995
2023-05-21 16:44:36 - progress_bar.py[line:272] - INFO: epoch 013:    514 / 1732 loss=2.454, loss_v1=0, loss_v2=0, nll_loss=1.261, ntokens=1052.2, nsentences=32, sample_size=1052.2, sample_size_v1=0, sample_size_v2=0, ppl=2.4, wps=276.1, ups=0.26, wpb=1052.2, bsz=32, num_updates=21260, lr=6.28545e-06, gnorm=10.935, clip=100, loss_scale=32, train_wall=38, gb_free=9, wall=82033
2023-05-21 16:45:14 - progress_bar.py[line:272] - INFO: epoch 013:    524 / 1732 loss=2.425, loss_v1=0, loss_v2=0, nll_loss=1.23, ntokens=980.8, nsentences=32, sample_size=980.8, sample_size_v1=0, sample_size_v2=0, ppl=2.35, wps=258.8, ups=0.26, wpb=980.8, bsz=32, num_updates=21270, lr=6.2834e-06, gnorm=12.484, clip=100, loss_scale=32, train_wall=38, gb_free=8.8, wall=82071
2023-05-21 16:45:51 - progress_bar.py[line:272] - INFO: epoch 013:    534 / 1732 loss=2.438, loss_v1=0, loss_v2=0, nll_loss=1.244, ntokens=944.9, nsentences=32, sample_size=944.9, sample_size_v1=0, sample_size_v2=0, ppl=2.37, wps=249.9, ups=0.26, wpb=944.9, bsz=32, num_updates=21280, lr=6.28135e-06, gnorm=12.249, clip=100, loss_scale=32, train_wall=38, gb_free=8.3, wall=82109
2023-05-21 16:46:29 - progress_bar.py[line:272] - INFO: epoch 013:    544 / 1732 loss=2.448, loss_v1=0, loss_v2=0, nll_loss=1.254, ntokens=998.9, nsentences=32, sample_size=998.9, sample_size_v1=0, sample_size_v2=0, ppl=2.39, wps=263.8, ups=0.26, wpb=998.9, bsz=32, num_updates=21290, lr=6.2793e-06, gnorm=12.312, clip=100, loss_scale=32, train_wall=38, gb_free=8.6, wall=82146
2023-05-21 16:47:07 - progress_bar.py[line:272] - INFO: epoch 013:    554 / 1732 loss=2.479, loss_v1=0, loss_v2=0, nll_loss=1.289, ntokens=1026.7, nsentences=32, sample_size=1026.7, sample_size_v1=0, sample_size_v2=0, ppl=2.44, wps=269.9, ups=0.26, wpb=1026.7, bsz=32, num_updates=21300, lr=6.27726e-06, gnorm=11.644, clip=100, loss_scale=32, train_wall=38, gb_free=8.5, wall=82185
2023-05-21 16:47:45 - progress_bar.py[line:272] - INFO: epoch 013:    564 / 1732 loss=2.465, loss_v1=0, loss_v2=0, nll_loss=1.275, ntokens=1028.3, nsentences=32, sample_size=1028.3, sample_size_v1=0, sample_size_v2=0, ppl=2.42, wps=269.8, ups=0.26, wpb=1028.3, bsz=32, num_updates=21310, lr=6.27521e-06, gnorm=11.603, clip=100, loss_scale=32, train_wall=38, gb_free=8.2, wall=82223
2023-05-21 16:48:24 - progress_bar.py[line:272] - INFO: epoch 013:    574 / 1732 loss=2.458, loss_v1=0, loss_v2=0, nll_loss=1.265, ntokens=1015.5, nsentences=32, sample_size=1015.5, sample_size_v1=0, sample_size_v2=0, ppl=2.4, wps=265.3, ups=0.26, wpb=1015.5, bsz=32, num_updates=21320, lr=6.27316e-06, gnorm=13.32, clip=100, loss_scale=32, train_wall=38, gb_free=8.1, wall=82261
2023-05-21 16:49:02 - progress_bar.py[line:272] - INFO: epoch 013:    584 / 1732 loss=2.46, loss_v1=0, loss_v2=0, nll_loss=1.268, ntokens=991.8, nsentences=32, sample_size=991.8, sample_size_v1=0, sample_size_v2=0, ppl=2.41, wps=259.4, ups=0.26, wpb=991.8, bsz=32, num_updates=21330, lr=6.27111e-06, gnorm=12.529, clip=100, loss_scale=32, train_wall=38, gb_free=7.9, wall=82299
2023-05-21 16:49:40 - progress_bar.py[line:272] - INFO: epoch 013:    594 / 1732 loss=2.415, loss_v1=0, loss_v2=0, nll_loss=1.217, ntokens=957.2, nsentences=32, sample_size=957.2, sample_size_v1=0, sample_size_v2=0, ppl=2.32, wps=251.4, ups=0.26, wpb=957.2, bsz=32, num_updates=21340, lr=6.26907e-06, gnorm=12.028, clip=100, loss_scale=32, train_wall=38, gb_free=8.5, wall=82337
2023-05-21 16:50:18 - progress_bar.py[line:272] - INFO: epoch 013:    604 / 1732 loss=2.424, loss_v1=0, loss_v2=0, nll_loss=1.229, ntokens=888.6, nsentences=32, sample_size=888.6, sample_size_v1=0, sample_size_v2=0, ppl=2.34, wps=234.9, ups=0.26, wpb=888.6, bsz=32, num_updates=21350, lr=6.26702e-06, gnorm=12.497, clip=100, loss_scale=32, train_wall=38, gb_free=8.4, wall=82375
2023-05-21 16:50:56 - progress_bar.py[line:272] - INFO: epoch 013:    614 / 1732 loss=2.457, loss_v1=0, loss_v2=0, nll_loss=1.267, ntokens=891, nsentences=32, sample_size=891, sample_size_v1=0, sample_size_v2=0, ppl=2.41, wps=234.4, ups=0.26, wpb=891, bsz=32, num_updates=21360, lr=6.26497e-06, gnorm=13.476, clip=100, loss_scale=32, train_wall=38, gb_free=8.8, wall=82413
2023-05-21 16:51:34 - progress_bar.py[line:272] - INFO: epoch 013:    624 / 1732 loss=2.458, loss_v1=0, loss_v2=0, nll_loss=1.264, ntokens=899.1, nsentences=32, sample_size=899.1, sample_size_v1=0, sample_size_v2=0, ppl=2.4, wps=238.3, ups=0.27, wpb=899.1, bsz=32, num_updates=21370, lr=6.26292e-06, gnorm=14.508, clip=100, loss_scale=32, train_wall=38, gb_free=9, wall=82451
2023-05-21 16:52:12 - progress_bar.py[line:272] - INFO: epoch 013:    634 / 1732 loss=2.449, loss_v1=0, loss_v2=0, nll_loss=1.255, ntokens=904.7, nsentences=32, sample_size=904.7, sample_size_v1=0, sample_size_v2=0, ppl=2.39, wps=237.3, ups=0.26, wpb=904.7, bsz=32, num_updates=21380, lr=6.26088e-06, gnorm=14.713, clip=100, loss_scale=32, train_wall=38, gb_free=9.2, wall=82489
2023-05-21 16:52:50 - progress_bar.py[line:272] - INFO: epoch 013:    644 / 1732 loss=2.456, loss_v1=0, loss_v2=0, nll_loss=1.263, ntokens=979.3, nsentences=32, sample_size=979.3, sample_size_v1=0, sample_size_v2=0, ppl=2.4, wps=257.8, ups=0.26, wpb=979.3, bsz=32, num_updates=21390, lr=6.25883e-06, gnorm=13.122, clip=100, loss_scale=32, train_wall=38, gb_free=8.7, wall=82527
2023-05-21 16:53:28 - progress_bar.py[line:272] - INFO: epoch 013:    654 / 1732 loss=2.463, loss_v1=0, loss_v2=0, nll_loss=1.272, ntokens=909.5, nsentences=32, sample_size=909.5, sample_size_v1=0, sample_size_v2=0, ppl=2.41, wps=240.4, ups=0.26, wpb=909.5, bsz=32, num_updates=21400, lr=6.25678e-06, gnorm=13.877, clip=100, loss_scale=32, train_wall=38, gb_free=8.6, wall=82565
2023-05-21 16:54:05 - progress_bar.py[line:272] - INFO: epoch 013:    664 / 1732 loss=2.455, loss_v1=0, loss_v2=0, nll_loss=1.263, ntokens=889.3, nsentences=32, sample_size=889.3, sample_size_v1=0, sample_size_v2=0, ppl=2.4, wps=235.4, ups=0.26, wpb=889.3, bsz=32, num_updates=21410, lr=6.25473e-06, gnorm=14.043, clip=100, loss_scale=32, train_wall=38, gb_free=9.1, wall=82603
2023-05-21 16:54:43 - progress_bar.py[line:272] - INFO: epoch 013:    674 / 1732 loss=2.464, loss_v1=0, loss_v2=0, nll_loss=1.274, ntokens=964.6, nsentences=32, sample_size=964.6, sample_size_v1=0, sample_size_v2=0, ppl=2.42, wps=254.6, ups=0.26, wpb=964.6, bsz=32, num_updates=21420, lr=6.25269e-06, gnorm=13.616, clip=100, loss_scale=32, train_wall=38, gb_free=8.7, wall=82640
2023-05-21 16:55:21 - progress_bar.py[line:272] - INFO: epoch 013:    684 / 1732 loss=2.446, loss_v1=0, loss_v2=0, nll_loss=1.252, ntokens=968.6, nsentences=32, sample_size=968.6, sample_size_v1=0, sample_size_v2=0, ppl=2.38, wps=254.7, ups=0.26, wpb=968.6, bsz=32, num_updates=21430, lr=6.25064e-06, gnorm=14.078, clip=100, loss_scale=32, train_wall=38, gb_free=9.1, wall=82678
2023-05-21 16:55:59 - progress_bar.py[line:272] - INFO: epoch 013:    694 / 1732 loss=2.454, loss_v1=0, loss_v2=0, nll_loss=1.26, ntokens=975.2, nsentences=32, sample_size=975.2, sample_size_v1=0, sample_size_v2=0, ppl=2.4, wps=255.9, ups=0.26, wpb=975.2, bsz=32, num_updates=21440, lr=6.24859e-06, gnorm=12.487, clip=100, loss_scale=32, train_wall=38, gb_free=8.2, wall=82717
2023-05-21 16:56:38 - progress_bar.py[line:272] - INFO: epoch 013:    704 / 1732 loss=2.421, loss_v1=0, loss_v2=0, nll_loss=1.223, ntokens=954.2, nsentences=32, sample_size=954.2, sample_size_v1=0, sample_size_v2=0, ppl=2.33, wps=250.1, ups=0.26, wpb=954.2, bsz=32, num_updates=21450, lr=6.24655e-06, gnorm=12.643, clip=100, loss_scale=32, train_wall=38, gb_free=9.1, wall=82755
2023-05-21 16:57:15 - progress_bar.py[line:272] - INFO: epoch 013:    714 / 1732 loss=2.469, loss_v1=0, loss_v2=0, nll_loss=1.278, ntokens=885.5, nsentences=32, sample_size=885.5, sample_size_v1=0, sample_size_v2=0, ppl=2.42, wps=234, ups=0.26, wpb=885.5, bsz=32, num_updates=21460, lr=6.2445e-06, gnorm=13.368, clip=100, loss_scale=32, train_wall=38, gb_free=8.4, wall=82793
2023-05-21 16:57:53 - progress_bar.py[line:272] - INFO: epoch 013:    724 / 1732 loss=2.411, loss_v1=0, loss_v2=0, nll_loss=1.215, ntokens=897.8, nsentences=32, sample_size=897.8, sample_size_v1=0, sample_size_v2=0, ppl=2.32, wps=237.3, ups=0.26, wpb=897.8, bsz=32, num_updates=21470, lr=6.24245e-06, gnorm=13.621, clip=100, loss_scale=32, train_wall=38, gb_free=8.9, wall=82830
2023-05-21 16:58:31 - progress_bar.py[line:272] - INFO: epoch 013:    734 / 1732 loss=2.428, loss_v1=0, loss_v2=0, nll_loss=1.233, ntokens=952.3, nsentences=32, sample_size=952.3, sample_size_v1=0, sample_size_v2=0, ppl=2.35, wps=250.4, ups=0.26, wpb=952.3, bsz=32, num_updates=21480, lr=6.2404e-06, gnorm=12.516, clip=100, loss_scale=64, train_wall=38, gb_free=8.8, wall=82868
2023-05-21 16:58:35 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2023-05-21 16:59:13 - progress_bar.py[line:272] - INFO: epoch 013:    745 / 1732 loss=2.418, loss_v1=0, loss_v2=0, nll_loss=1.222, ntokens=978.3, nsentences=32, sample_size=978.3, sample_size_v1=0, sample_size_v2=0, ppl=2.33, wps=234.8, ups=0.24, wpb=978.3, bsz=32, num_updates=21490, lr=6.23836e-06, gnorm=12.689, clip=100, loss_scale=32, train_wall=42, gb_free=8.3, wall=82910
2023-05-21 16:59:51 - progress_bar.py[line:272] - INFO: epoch 013:    755 / 1732 loss=2.435, loss_v1=0, loss_v2=0, nll_loss=1.242, ntokens=975.4, nsentences=32, sample_size=975.4, sample_size_v1=0, sample_size_v2=0, ppl=2.36, wps=256.3, ups=0.26, wpb=975.4, bsz=32, num_updates=21500, lr=6.23631e-06, gnorm=12.792, clip=100, loss_scale=32, train_wall=38, gb_free=9, wall=82948
2023-05-21 17:00:29 - progress_bar.py[line:272] - INFO: epoch 013:    765 / 1732 loss=2.427, loss_v1=0, loss_v2=0, nll_loss=1.232, ntokens=948.8, nsentences=32, sample_size=948.8, sample_size_v1=0, sample_size_v2=0, ppl=2.35, wps=250.3, ups=0.26, wpb=948.8, bsz=32, num_updates=21510, lr=6.23426e-06, gnorm=12.892, clip=100, loss_scale=32, train_wall=38, gb_free=7.6, wall=82986
2023-05-21 17:01:07 - progress_bar.py[line:272] - INFO: epoch 013:    775 / 1732 loss=2.436, loss_v1=0, loss_v2=0, nll_loss=1.241, ntokens=1002.4, nsentences=32, sample_size=1002.4, sample_size_v1=0, sample_size_v2=0, ppl=2.36, wps=262.1, ups=0.26, wpb=1002.4, bsz=32, num_updates=21520, lr=6.23221e-06, gnorm=13.205, clip=100, loss_scale=32, train_wall=38, gb_free=8.7, wall=83024
2023-05-21 17:01:45 - progress_bar.py[line:272] - INFO: epoch 013:    785 / 1732 loss=2.435, loss_v1=0, loss_v2=0, nll_loss=1.241, ntokens=1003.9, nsentences=32, sample_size=1003.9, sample_size_v1=0, sample_size_v2=0, ppl=2.36, wps=263.7, ups=0.26, wpb=1003.9, bsz=32, num_updates=21530, lr=6.23017e-06, gnorm=11.693, clip=100, loss_scale=32, train_wall=38, gb_free=8.4, wall=83062
2023-05-21 17:02:23 - progress_bar.py[line:272] - INFO: epoch 013:    795 / 1732 loss=2.435, loss_v1=0, loss_v2=0, nll_loss=1.24, ntokens=1051.8, nsentences=32, sample_size=1051.8, sample_size_v1=0, sample_size_v2=0, ppl=2.36, wps=275.7, ups=0.26, wpb=1051.8, bsz=32, num_updates=21540, lr=6.22812e-06, gnorm=12.352, clip=100, loss_scale=32, train_wall=38, gb_free=8.3, wall=83101
2023-05-21 17:03:01 - progress_bar.py[line:272] - INFO: epoch 013:    805 / 1732 loss=2.441, loss_v1=0, loss_v2=0, nll_loss=1.245, ntokens=913, nsentences=32, sample_size=913, sample_size_v1=0, sample_size_v2=0, ppl=2.37, wps=241, ups=0.26, wpb=913, bsz=32, num_updates=21550, lr=6.22607e-06, gnorm=13.966, clip=100, loss_scale=32, train_wall=38, gb_free=8.3, wall=83138
2023-05-21 17:03:39 - progress_bar.py[line:272] - INFO: epoch 013:    815 / 1732 loss=2.437, loss_v1=0, loss_v2=0, nll_loss=1.243, ntokens=936.3, nsentences=32, sample_size=936.3, sample_size_v1=0, sample_size_v2=0, ppl=2.37, wps=246.6, ups=0.26, wpb=936.3, bsz=32, num_updates=21560, lr=6.22402e-06, gnorm=12.664, clip=100, loss_scale=32, train_wall=38, gb_free=8.8, wall=83176
2023-05-21 17:04:17 - progress_bar.py[line:272] - INFO: epoch 013:    825 / 1732 loss=2.44, loss_v1=0, loss_v2=0, nll_loss=1.245, ntokens=931.3, nsentences=32, sample_size=931.3, sample_size_v1=0, sample_size_v2=0, ppl=2.37, wps=244.9, ups=0.26, wpb=931.3, bsz=32, num_updates=21570, lr=6.22198e-06, gnorm=13.613, clip=100, loss_scale=32, train_wall=38, gb_free=9.2, wall=83214
2023-05-21 17:04:55 - progress_bar.py[line:272] - INFO: epoch 013:    835 / 1732 loss=2.44, loss_v1=0, loss_v2=0, nll_loss=1.244, ntokens=897.4, nsentences=32, sample_size=897.4, sample_size_v1=0, sample_size_v2=0, ppl=2.37, wps=238.3, ups=0.27, wpb=897.4, bsz=32, num_updates=21580, lr=6.21993e-06, gnorm=12.985, clip=100, loss_scale=32, train_wall=38, gb_free=9, wall=83252
2023-05-21 17:05:33 - progress_bar.py[line:272] - INFO: epoch 013:    845 / 1732 loss=2.411, loss_v1=0, loss_v2=0, nll_loss=1.212, ntokens=987.4, nsentences=32, sample_size=987.4, sample_size_v1=0, sample_size_v2=0, ppl=2.32, wps=260.5, ups=0.26, wpb=987.4, bsz=32, num_updates=21590, lr=6.21788e-06, gnorm=11.732, clip=100, loss_scale=32, train_wall=38, gb_free=8.4, wall=83290
2023-05-21 17:06:11 - progress_bar.py[line:272] - INFO: epoch 013:    855 / 1732 loss=2.431, loss_v1=0, loss_v2=0, nll_loss=1.234, ntokens=952, nsentences=32, sample_size=952, sample_size_v1=0, sample_size_v2=0, ppl=2.35, wps=250.3, ups=0.26, wpb=952, bsz=32, num_updates=21600, lr=6.21583e-06, gnorm=12.288, clip=100, loss_scale=32, train_wall=38, gb_free=9.2, wall=83328
2023-05-21 17:06:49 - progress_bar.py[line:272] - INFO: epoch 013:    865 / 1732 loss=2.448, loss_v1=0, loss_v2=0, nll_loss=1.254, ntokens=968.1, nsentences=32, sample_size=968.1, sample_size_v1=0, sample_size_v2=0, ppl=2.38, wps=254.6, ups=0.26, wpb=968.1, bsz=32, num_updates=21610, lr=6.21379e-06, gnorm=13.682, clip=100, loss_scale=32, train_wall=38, gb_free=8.7, wall=83366
2023-05-21 17:07:27 - progress_bar.py[line:272] - INFO: epoch 013:    875 / 1732 loss=2.4, loss_v1=0, loss_v2=0, nll_loss=1.202, ntokens=985.7, nsentences=32, sample_size=985.7, sample_size_v1=0, sample_size_v2=0, ppl=2.3, wps=259, ups=0.26, wpb=985.7, bsz=32, num_updates=21620, lr=6.21174e-06, gnorm=11.368, clip=100, loss_scale=32, train_wall=38, gb_free=8.6, wall=83404
2023-05-21 17:08:05 - progress_bar.py[line:272] - INFO: epoch 013:    885 / 1732 loss=2.379, loss_v1=0, loss_v2=0, nll_loss=1.178, ntokens=961.4, nsentences=32, sample_size=961.4, sample_size_v1=0, sample_size_v2=0, ppl=2.26, wps=252.6, ups=0.26, wpb=961.4, bsz=32, num_updates=21630, lr=6.20969e-06, gnorm=12.433, clip=100, loss_scale=32, train_wall=38, gb_free=8.7, wall=83442
2023-05-21 17:08:43 - progress_bar.py[line:272] - INFO: epoch 013:    895 / 1732 loss=2.384, loss_v1=0, loss_v2=0, nll_loss=1.183, ntokens=1031.3, nsentences=32, sample_size=1031.3, sample_size_v1=0, sample_size_v2=0, ppl=2.27, wps=270.4, ups=0.26, wpb=1031.3, bsz=32, num_updates=21640, lr=6.20764e-06, gnorm=11.628, clip=100, loss_scale=32, train_wall=38, gb_free=9, wall=83480
2023-05-21 17:09:21 - progress_bar.py[line:272] - INFO: epoch 013:    905 / 1732 loss=2.382, loss_v1=0, loss_v2=0, nll_loss=1.181, ntokens=1040.4, nsentences=32, sample_size=1040.4, sample_size_v1=0, sample_size_v2=0, ppl=2.27, wps=273.8, ups=0.26, wpb=1040.4, bsz=32, num_updates=21650, lr=6.2056e-06, gnorm=11.793, clip=100, loss_scale=32, train_wall=38, gb_free=8.2, wall=83518
2023-05-21 17:09:59 - progress_bar.py[line:272] - INFO: epoch 013:    915 / 1732 loss=2.455, loss_v1=0, loss_v2=0, nll_loss=1.263, ntokens=937.6, nsentences=32, sample_size=937.6, sample_size_v1=0, sample_size_v2=0, ppl=2.4, wps=248.1, ups=0.26, wpb=937.6, bsz=32, num_updates=21660, lr=6.20355e-06, gnorm=13.167, clip=100, loss_scale=32, train_wall=38, gb_free=8.9, wall=83556
2023-05-21 17:10:38 - progress_bar.py[line:272] - INFO: epoch 013:    925 / 1732 loss=2.391, loss_v1=0, loss_v2=0, nll_loss=1.192, ntokens=1005.1, nsentences=32, sample_size=1005.1, sample_size_v1=0, sample_size_v2=0, ppl=2.28, wps=259.7, ups=0.26, wpb=1005.1, bsz=32, num_updates=21670, lr=6.2015e-06, gnorm=11.583, clip=100, loss_scale=32, train_wall=39, gb_free=8.7, wall=83595
2023-05-21 17:11:16 - progress_bar.py[line:272] - INFO: epoch 013:    935 / 1732 loss=2.404, loss_v1=0, loss_v2=0, nll_loss=1.205, ntokens=1058.5, nsentences=32, sample_size=1058.5, sample_size_v1=0, sample_size_v2=0, ppl=2.31, wps=276.1, ups=0.26, wpb=1058.5, bsz=32, num_updates=21680, lr=6.19946e-06, gnorm=12.875, clip=100, loss_scale=32, train_wall=38, gb_free=8.4, wall=83633
2023-05-21 17:11:55 - progress_bar.py[line:272] - INFO: epoch 013:    945 / 1732 loss=2.427, loss_v1=0, loss_v2=0, nll_loss=1.231, ntokens=1055.4, nsentences=32, sample_size=1055.4, sample_size_v1=0, sample_size_v2=0, ppl=2.35, wps=272.9, ups=0.26, wpb=1055.4, bsz=32, num_updates=21690, lr=6.19741e-06, gnorm=11.428, clip=100, loss_scale=32, train_wall=39, gb_free=8.4, wall=83672
2023-05-21 17:12:33 - progress_bar.py[line:272] - INFO: epoch 013:    955 / 1732 loss=2.409, loss_v1=0, loss_v2=0, nll_loss=1.211, ntokens=1040.2, nsentences=32, sample_size=1040.2, sample_size_v1=0, sample_size_v2=0, ppl=2.31, wps=268.6, ups=0.26, wpb=1040.2, bsz=32, num_updates=21700, lr=6.19536e-06, gnorm=11.306, clip=100, loss_scale=32, train_wall=39, gb_free=8.7, wall=83711
2023-05-21 17:13:12 - progress_bar.py[line:272] - INFO: epoch 013:    965 / 1732 loss=2.415, loss_v1=0, loss_v2=0, nll_loss=1.22, ntokens=1047.7, nsentences=32, sample_size=1047.7, sample_size_v1=0, sample_size_v2=0, ppl=2.33, wps=271.8, ups=0.26, wpb=1047.7, bsz=32, num_updates=21710, lr=6.19331e-06, gnorm=11.963, clip=100, loss_scale=32, train_wall=39, gb_free=8.9, wall=83749
2023-05-21 17:13:51 - progress_bar.py[line:272] - INFO: epoch 013:    975 / 1732 loss=2.419, loss_v1=0, loss_v2=0, nll_loss=1.224, ntokens=1038, nsentences=32, sample_size=1038, sample_size_v1=0, sample_size_v2=0, ppl=2.34, wps=267.7, ups=0.26, wpb=1038, bsz=32, num_updates=21720, lr=6.19127e-06, gnorm=12.067, clip=100, loss_scale=32, train_wall=39, gb_free=8.8, wall=83788
2023-05-21 17:14:29 - progress_bar.py[line:272] - INFO: epoch 013:    985 / 1732 loss=2.419, loss_v1=0, loss_v2=0, nll_loss=1.223, ntokens=1034.6, nsentences=32, sample_size=1034.6, sample_size_v1=0, sample_size_v2=0, ppl=2.33, wps=266.9, ups=0.26, wpb=1034.6, bsz=32, num_updates=21730, lr=6.18922e-06, gnorm=12.043, clip=100, loss_scale=32, train_wall=39, gb_free=8.7, wall=83827
2023-05-21 17:15:08 - progress_bar.py[line:272] - INFO: epoch 013:    995 / 1732 loss=2.404, loss_v1=0, loss_v2=0, nll_loss=1.204, ntokens=1048.7, nsentences=32, sample_size=1048.7, sample_size_v1=0, sample_size_v2=0, ppl=2.3, wps=272.2, ups=0.26, wpb=1048.7, bsz=32, num_updates=21740, lr=6.18717e-06, gnorm=11.162, clip=100, loss_scale=32, train_wall=38, gb_free=7.7, wall=83865
2023-05-21 17:15:46 - progress_bar.py[line:272] - INFO: epoch 013:   1005 / 1732 loss=2.405, loss_v1=0, loss_v2=0, nll_loss=1.205, ntokens=981.9, nsentences=32, sample_size=981.9, sample_size_v1=0, sample_size_v2=0, ppl=2.31, wps=256.5, ups=0.26, wpb=981.9, bsz=32, num_updates=21750, lr=6.18512e-06, gnorm=11.693, clip=100, loss_scale=32, train_wall=38, gb_free=8.3, wall=83904
2023-05-21 17:16:25 - progress_bar.py[line:272] - INFO: epoch 013:   1015 / 1732 loss=2.412, loss_v1=0, loss_v2=0, nll_loss=1.214, ntokens=996.6, nsentences=32, sample_size=996.6, sample_size_v1=0, sample_size_v2=0, ppl=2.32, wps=260, ups=0.26, wpb=996.6, bsz=32, num_updates=21760, lr=6.18308e-06, gnorm=11.621, clip=100, loss_scale=32, train_wall=38, gb_free=8.8, wall=83942
2023-05-21 17:17:04 - progress_bar.py[line:272] - INFO: epoch 013:   1025 / 1732 loss=2.401, loss_v1=0, loss_v2=0, nll_loss=1.204, ntokens=1087.5, nsentences=32, sample_size=1087.5, sample_size_v1=0, sample_size_v2=0, ppl=2.3, wps=278.7, ups=0.26, wpb=1087.5, bsz=32, num_updates=21770, lr=6.18103e-06, gnorm=11.961, clip=100, loss_scale=32, train_wall=39, gb_free=7.8, wall=83981
2023-05-21 17:17:42 - progress_bar.py[line:272] - INFO: epoch 013:   1035 / 1732 loss=2.403, loss_v1=0, loss_v2=0, nll_loss=1.207, ntokens=1118.6, nsentences=32, sample_size=1118.6, sample_size_v1=0, sample_size_v2=0, ppl=2.31, wps=289.4, ups=0.26, wpb=1118.6, bsz=32, num_updates=21780, lr=6.17898e-06, gnorm=11.017, clip=100, loss_scale=32, train_wall=39, gb_free=8.6, wall=84020
2023-05-21 17:18:21 - progress_bar.py[line:272] - INFO: epoch 013:   1045 / 1732 loss=2.405, loss_v1=0, loss_v2=0, nll_loss=1.206, ntokens=1030.7, nsentences=32, sample_size=1030.7, sample_size_v1=0, sample_size_v2=0, ppl=2.31, wps=267.2, ups=0.26, wpb=1030.7, bsz=32, num_updates=21790, lr=6.17693e-06, gnorm=11.841, clip=100, loss_scale=32, train_wall=39, gb_free=8.8, wall=84058
2023-05-21 17:18:59 - progress_bar.py[line:272] - INFO: epoch 013:   1055 / 1732 loss=2.409, loss_v1=0, loss_v2=0, nll_loss=1.21, ntokens=1077.2, nsentences=32, sample_size=1077.2, sample_size_v1=0, sample_size_v2=0, ppl=2.31, wps=279.2, ups=0.26, wpb=1077.2, bsz=32, num_updates=21800, lr=6.17489e-06, gnorm=12.229, clip=100, loss_scale=32, train_wall=39, gb_free=8.3, wall=84097
2023-05-21 17:19:38 - progress_bar.py[line:272] - INFO: epoch 013:   1065 / 1732 loss=2.416, loss_v1=0, loss_v2=0, nll_loss=1.219, ntokens=1021, nsentences=32, sample_size=1021, sample_size_v1=0, sample_size_v2=0, ppl=2.33, wps=264.1, ups=0.26, wpb=1021, bsz=32, num_updates=21810, lr=6.17284e-06, gnorm=13.527, clip=100, loss_scale=32, train_wall=39, gb_free=8.6, wall=84135
2023-05-21 17:20:17 - progress_bar.py[line:272] - INFO: epoch 013:   1075 / 1732 loss=2.413, loss_v1=0, loss_v2=0, nll_loss=1.215, ntokens=1007.9, nsentences=32, sample_size=1007.9, sample_size_v1=0, sample_size_v2=0, ppl=2.32, wps=259.1, ups=0.26, wpb=1007.9, bsz=32, num_updates=21820, lr=6.17079e-06, gnorm=11.668, clip=100, loss_scale=32, train_wall=39, gb_free=8.1, wall=84174
2023-05-21 17:20:56 - progress_bar.py[line:272] - INFO: epoch 013:   1085 / 1732 loss=2.431, loss_v1=0, loss_v2=0, nll_loss=1.237, ntokens=1052.2, nsentences=32, sample_size=1052.2, sample_size_v1=0, sample_size_v2=0, ppl=2.36, wps=271.9, ups=0.26, wpb=1052.2, bsz=32, num_updates=21830, lr=6.16874e-06, gnorm=12.647, clip=100, loss_scale=32, train_wall=39, gb_free=9, wall=84213
2023-05-21 17:21:34 - progress_bar.py[line:272] - INFO: epoch 013:   1095 / 1732 loss=2.42, loss_v1=0, loss_v2=0, nll_loss=1.224, ntokens=1070, nsentences=32, sample_size=1070, sample_size_v1=0, sample_size_v2=0, ppl=2.34, wps=276.9, ups=0.26, wpb=1070, bsz=32, num_updates=21840, lr=6.1667e-06, gnorm=13.22, clip=100, loss_scale=32, train_wall=39, gb_free=8.6, wall=84252
2023-05-21 17:22:13 - progress_bar.py[line:272] - INFO: epoch 013:   1105 / 1732 loss=2.399, loss_v1=0, loss_v2=0, nll_loss=1.199, ntokens=1032.4, nsentences=32, sample_size=1032.4, sample_size_v1=0, sample_size_v2=0, ppl=2.3, wps=266.4, ups=0.26, wpb=1032.4, bsz=32, num_updates=21850, lr=6.16465e-06, gnorm=12.516, clip=100, loss_scale=32, train_wall=39, gb_free=8.5, wall=84290
2023-05-21 17:22:52 - progress_bar.py[line:272] - INFO: epoch 013:   1115 / 1732 loss=2.415, loss_v1=0, loss_v2=0, nll_loss=1.217, ntokens=979.5, nsentences=32, sample_size=979.5, sample_size_v1=0, sample_size_v2=0, ppl=2.32, wps=252.5, ups=0.26, wpb=979.5, bsz=32, num_updates=21860, lr=6.1626e-06, gnorm=11.813, clip=100, loss_scale=32, train_wall=39, gb_free=7.9, wall=84329
2023-05-21 17:23:31 - progress_bar.py[line:272] - INFO: epoch 013:   1125 / 1732 loss=2.412, loss_v1=0, loss_v2=0, nll_loss=1.215, ntokens=994.1, nsentences=32, sample_size=994.1, sample_size_v1=0, sample_size_v2=0, ppl=2.32, wps=256.6, ups=0.26, wpb=994.1, bsz=32, num_updates=21870, lr=6.16056e-06, gnorm=12.468, clip=100, loss_scale=32, train_wall=39, gb_free=8.1, wall=84368
2023-05-21 17:24:09 - progress_bar.py[line:272] - INFO: epoch 013:   1135 / 1732 loss=2.422, loss_v1=0, loss_v2=0, nll_loss=1.229, ntokens=998.2, nsentences=32, sample_size=998.2, sample_size_v1=0, sample_size_v2=0, ppl=2.34, wps=258.6, ups=0.26, wpb=998.2, bsz=32, num_updates=21880, lr=6.15851e-06, gnorm=12.826, clip=100, loss_scale=32, train_wall=39, gb_free=8.5, wall=84407
2023-05-21 17:24:48 - progress_bar.py[line:272] - INFO: epoch 013:   1145 / 1732 loss=2.419, loss_v1=0, loss_v2=0, nll_loss=1.221, ntokens=1012.1, nsentences=32, sample_size=1012.1, sample_size_v1=0, sample_size_v2=0, ppl=2.33, wps=262.5, ups=0.26, wpb=1012.1, bsz=32, num_updates=21890, lr=6.15646e-06, gnorm=13.275, clip=100, loss_scale=32, train_wall=39, gb_free=7.9, wall=84445
2023-05-21 17:25:26 - progress_bar.py[line:272] - INFO: epoch 013:   1155 / 1732 loss=2.396, loss_v1=0, loss_v2=0, nll_loss=1.196, ntokens=1037.8, nsentences=32, sample_size=1037.8, sample_size_v1=0, sample_size_v2=0, ppl=2.29, wps=269.2, ups=0.26, wpb=1037.8, bsz=32, num_updates=21900, lr=6.15441e-06, gnorm=11.749, clip=100, loss_scale=32, train_wall=39, gb_free=8.7, wall=84484
2023-05-21 17:26:05 - progress_bar.py[line:272] - INFO: epoch 013:   1165 / 1732 loss=2.395, loss_v1=0, loss_v2=0, nll_loss=1.196, ntokens=1000.9, nsentences=32, sample_size=1000.9, sample_size_v1=0, sample_size_v2=0, ppl=2.29, wps=259.4, ups=0.26, wpb=1000.9, bsz=32, num_updates=21910, lr=6.15237e-06, gnorm=13.05, clip=100, loss_scale=32, train_wall=39, gb_free=8.4, wall=84522
2023-05-21 17:26:44 - progress_bar.py[line:272] - INFO: epoch 013:   1175 / 1732 loss=2.399, loss_v1=0, loss_v2=0, nll_loss=1.199, ntokens=1076.2, nsentences=32, sample_size=1076.2, sample_size_v1=0, sample_size_v2=0, ppl=2.3, wps=277.9, ups=0.26, wpb=1076.2, bsz=32, num_updates=21920, lr=6.15032e-06, gnorm=11.497, clip=100, loss_scale=32, train_wall=39, gb_free=8.2, wall=84561
2023-05-21 17:27:22 - progress_bar.py[line:272] - INFO: epoch 013:   1185 / 1732 loss=2.41, loss_v1=0, loss_v2=0, nll_loss=1.213, ntokens=957.5, nsentences=32, sample_size=957.5, sample_size_v1=0, sample_size_v2=0, ppl=2.32, wps=249.1, ups=0.26, wpb=957.5, bsz=32, num_updates=21930, lr=6.14827e-06, gnorm=13.092, clip=100, loss_scale=32, train_wall=38, gb_free=8.9, wall=84599
2023-05-21 17:28:01 - progress_bar.py[line:272] - INFO: epoch 013:   1195 / 1732 loss=2.424, loss_v1=0, loss_v2=0, nll_loss=1.228, ntokens=1058.2, nsentences=32, sample_size=1058.2, sample_size_v1=0, sample_size_v2=0, ppl=2.34, wps=273.9, ups=0.26, wpb=1058.2, bsz=32, num_updates=21940, lr=6.14622e-06, gnorm=13.523, clip=100, loss_scale=32, train_wall=39, gb_free=8.3, wall=84638
2023-05-21 17:28:40 - progress_bar.py[line:272] - INFO: epoch 013:   1205 / 1732 loss=2.375, loss_v1=0, loss_v2=0, nll_loss=1.171, ntokens=1142.5, nsentences=32, sample_size=1142.5, sample_size_v1=0, sample_size_v2=0, ppl=2.25, wps=292.8, ups=0.26, wpb=1142.5, bsz=32, num_updates=21950, lr=6.14418e-06, gnorm=12.119, clip=100, loss_scale=32, train_wall=39, gb_free=8.4, wall=84677
2023-05-21 17:29:18 - progress_bar.py[line:272] - INFO: epoch 013:   1215 / 1732 loss=2.414, loss_v1=0, loss_v2=0, nll_loss=1.215, ntokens=998.9, nsentences=32, sample_size=998.9, sample_size_v1=0, sample_size_v2=0, ppl=2.32, wps=259.8, ups=0.26, wpb=998.9, bsz=32, num_updates=21960, lr=6.14213e-06, gnorm=11.733, clip=100, loss_scale=32, train_wall=38, gb_free=8.9, wall=84716
2023-05-21 17:29:57 - progress_bar.py[line:272] - INFO: epoch 013:   1225 / 1732 loss=2.427, loss_v1=0, loss_v2=0, nll_loss=1.23, ntokens=1043.3, nsentences=32, sample_size=1043.3, sample_size_v1=0, sample_size_v2=0, ppl=2.35, wps=269.2, ups=0.26, wpb=1043.3, bsz=32, num_updates=21970, lr=6.14008e-06, gnorm=13.716, clip=100, loss_scale=32, train_wall=39, gb_free=8.9, wall=84754
2023-05-21 17:30:36 - progress_bar.py[line:272] - INFO: epoch 013:   1235 / 1732 loss=2.4, loss_v1=0, loss_v2=0, nll_loss=1.201, ntokens=1038.1, nsentences=32, sample_size=1038.1, sample_size_v1=0, sample_size_v2=0, ppl=2.3, wps=269.1, ups=0.26, wpb=1038.1, bsz=32, num_updates=21980, lr=6.13803e-06, gnorm=12.642, clip=100, loss_scale=32, train_wall=39, gb_free=7.5, wall=84793
2023-05-21 17:31:14 - progress_bar.py[line:272] - INFO: epoch 013:   1245 / 1732 loss=2.348, loss_v1=0, loss_v2=0, nll_loss=1.143, ntokens=1088.5, nsentences=32, sample_size=1088.5, sample_size_v1=0, sample_size_v2=0, ppl=2.21, wps=281.4, ups=0.26, wpb=1088.5, bsz=32, num_updates=21990, lr=6.13599e-06, gnorm=12.988, clip=100, loss_scale=32, train_wall=39, gb_free=8.3, wall=84832
2023-05-21 17:31:53 - progress_bar.py[line:272] - INFO: epoch 013:   1255 / 1732 loss=2.374, loss_v1=0, loss_v2=0, nll_loss=1.172, ntokens=1068.9, nsentences=32, sample_size=1068.9, sample_size_v1=0, sample_size_v2=0, ppl=2.25, wps=277.1, ups=0.26, wpb=1068.9, bsz=32, num_updates=22000, lr=6.13394e-06, gnorm=11.021, clip=100, loss_scale=64, train_wall=39, gb_free=8.2, wall=84870
2023-05-21 17:32:32 - progress_bar.py[line:272] - INFO: epoch 013:   1265 / 1732 loss=2.416, loss_v1=0, loss_v2=0, nll_loss=1.218, ntokens=1072.6, nsentences=32, sample_size=1072.6, sample_size_v1=0, sample_size_v2=0, ppl=2.33, wps=276.3, ups=0.26, wpb=1072.6, bsz=32, num_updates=22010, lr=6.13189e-06, gnorm=12.169, clip=100, loss_scale=64, train_wall=39, gb_free=9.2, wall=84909
2023-05-21 17:32:51 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2023-05-21 17:33:14 - progress_bar.py[line:272] - INFO: epoch 013:   1276 / 1732 loss=2.411, loss_v1=0, loss_v2=0, nll_loss=1.213, ntokens=1061.1, nsentences=32, sample_size=1061.1, sample_size_v1=0, sample_size_v2=0, ppl=2.32, wps=248.5, ups=0.23, wpb=1061.1, bsz=32, num_updates=22020, lr=6.12984e-06, gnorm=12.53, clip=100, loss_scale=32, train_wall=43, gb_free=8.1, wall=84952
2023-05-21 17:33:53 - progress_bar.py[line:272] - INFO: epoch 013:   1286 / 1732 loss=2.404, loss_v1=0, loss_v2=0, nll_loss=1.205, ntokens=1038.1, nsentences=32, sample_size=1038.1, sample_size_v1=0, sample_size_v2=0, ppl=2.31, wps=268.3, ups=0.26, wpb=1038.1, bsz=32, num_updates=22030, lr=6.1278e-06, gnorm=12.479, clip=100, loss_scale=32, train_wall=39, gb_free=8.8, wall=84990
2023-05-21 17:34:32 - progress_bar.py[line:272] - INFO: epoch 013:   1296 / 1732 loss=2.378, loss_v1=0, loss_v2=0, nll_loss=1.178, ntokens=1121.3, nsentences=32, sample_size=1121.3, sample_size_v1=0, sample_size_v2=0, ppl=2.26, wps=289.5, ups=0.26, wpb=1121.3, bsz=32, num_updates=22040, lr=6.12575e-06, gnorm=11.542, clip=100, loss_scale=32, train_wall=39, gb_free=8.4, wall=85029
2023-05-21 17:35:11 - progress_bar.py[line:272] - INFO: epoch 013:   1306 / 1732 loss=2.42, loss_v1=0, loss_v2=0, nll_loss=1.223, ntokens=1091, nsentences=32, sample_size=1091, sample_size_v1=0, sample_size_v2=0, ppl=2.33, wps=280, ups=0.26, wpb=1091, bsz=32, num_updates=22050, lr=6.1237e-06, gnorm=11.001, clip=100, loss_scale=32, train_wall=39, gb_free=7.8, wall=85068
2023-05-21 17:35:50 - progress_bar.py[line:272] - INFO: epoch 013:   1316 / 1732 loss=2.407, loss_v1=0, loss_v2=0, nll_loss=1.207, ntokens=1049.3, nsentences=32, sample_size=1049.3, sample_size_v1=0, sample_size_v2=0, ppl=2.31, wps=270, ups=0.26, wpb=1049.3, bsz=32, num_updates=22060, lr=6.12166e-06, gnorm=12.462, clip=100, loss_scale=32, train_wall=39, gb_free=8.6, wall=85107
2023-05-21 17:36:29 - progress_bar.py[line:272] - INFO: epoch 013:   1326 / 1732 loss=2.39, loss_v1=0, loss_v2=0, nll_loss=1.189, ntokens=1110.6, nsentences=32, sample_size=1110.6, sample_size_v1=0, sample_size_v2=0, ppl=2.28, wps=284.2, ups=0.26, wpb=1110.6, bsz=32, num_updates=22070, lr=6.11961e-06, gnorm=13.071, clip=100, loss_scale=32, train_wall=39, gb_free=8.7, wall=85146
2023-05-21 17:37:08 - progress_bar.py[line:272] - INFO: epoch 013:   1336 / 1732 loss=2.378, loss_v1=0, loss_v2=0, nll_loss=1.176, ntokens=1122.3, nsentences=32, sample_size=1122.3, sample_size_v1=0, sample_size_v2=0, ppl=2.26, wps=289.5, ups=0.26, wpb=1122.3, bsz=32, num_updates=22080, lr=6.11756e-06, gnorm=13.485, clip=100, loss_scale=32, train_wall=39, gb_free=8.2, wall=85185
2023-05-21 17:37:47 - progress_bar.py[line:272] - INFO: epoch 013:   1346 / 1732 loss=2.385, loss_v1=0, loss_v2=0, nll_loss=1.184, ntokens=1171.7, nsentences=32, sample_size=1171.7, sample_size_v1=0, sample_size_v2=0, ppl=2.27, wps=300.4, ups=0.26, wpb=1171.7, bsz=32, num_updates=22090, lr=6.11551e-06, gnorm=12.272, clip=100, loss_scale=32, train_wall=39, gb_free=8.1, wall=85224
2023-05-21 17:38:25 - progress_bar.py[line:272] - INFO: epoch 013:   1356 / 1732 loss=2.379, loss_v1=0, loss_v2=0, nll_loss=1.177, ntokens=1137.3, nsentences=32, sample_size=1137.3, sample_size_v1=0, sample_size_v2=0, ppl=2.26, wps=292.8, ups=0.26, wpb=1137.3, bsz=32, num_updates=22100, lr=6.11347e-06, gnorm=11.731, clip=100, loss_scale=32, train_wall=39, gb_free=8.4, wall=85263
2023-05-21 17:39:05 - progress_bar.py[line:272] - INFO: epoch 013:   1366 / 1732 loss=2.379, loss_v1=0, loss_v2=0, nll_loss=1.177, ntokens=1081.4, nsentences=32, sample_size=1081.4, sample_size_v1=0, sample_size_v2=0, ppl=2.26, wps=276, ups=0.26, wpb=1081.4, bsz=32, num_updates=22110, lr=6.11142e-06, gnorm=11.502, clip=100, loss_scale=32, train_wall=39, gb_free=8.8, wall=85302
2023-05-21 17:39:43 - progress_bar.py[line:272] - INFO: epoch 013:   1376 / 1732 loss=2.432, loss_v1=0, loss_v2=0, nll_loss=1.237, ntokens=1111.5, nsentences=32, sample_size=1111.5, sample_size_v1=0, sample_size_v2=0, ppl=2.36, wps=286.9, ups=0.26, wpb=1111.5, bsz=32, num_updates=22120, lr=6.10937e-06, gnorm=12.078, clip=100, loss_scale=32, train_wall=39, gb_free=8, wall=85341
2023-05-21 17:40:22 - progress_bar.py[line:272] - INFO: epoch 013:   1386 / 1732 loss=2.389, loss_v1=0, loss_v2=0, nll_loss=1.19, ntokens=1153.3, nsentences=32, sample_size=1153.3, sample_size_v1=0, sample_size_v2=0, ppl=2.28, wps=297.2, ups=0.26, wpb=1153.3, bsz=32, num_updates=22130, lr=6.10732e-06, gnorm=11.997, clip=100, loss_scale=32, train_wall=39, gb_free=8.9, wall=85379
2023-05-21 17:41:01 - progress_bar.py[line:272] - INFO: epoch 013:   1396 / 1732 loss=2.391, loss_v1=0, loss_v2=0, nll_loss=1.19, ntokens=1044.6, nsentences=32, sample_size=1044.6, sample_size_v1=0, sample_size_v2=0, ppl=2.28, wps=270, ups=0.26, wpb=1044.6, bsz=32, num_updates=22140, lr=6.10528e-06, gnorm=13.017, clip=100, loss_scale=32, train_wall=39, gb_free=8.6, wall=85418
2023-05-21 17:41:40 - progress_bar.py[line:272] - INFO: epoch 013:   1406 / 1732 loss=2.397, loss_v1=0, loss_v2=0, nll_loss=1.197, ntokens=1163.8, nsentences=32, sample_size=1163.8, sample_size_v1=0, sample_size_v2=0, ppl=2.29, wps=299.4, ups=0.26, wpb=1163.8, bsz=32, num_updates=22150, lr=6.10323e-06, gnorm=12.482, clip=100, loss_scale=32, train_wall=39, gb_free=8.7, wall=85457
2023-05-21 17:42:19 - progress_bar.py[line:272] - INFO: epoch 013:   1416 / 1732 loss=2.417, loss_v1=0, loss_v2=0, nll_loss=1.219, ntokens=1281, nsentences=32, sample_size=1281, sample_size_v1=0, sample_size_v2=0, ppl=2.33, wps=326.6, ups=0.25, wpb=1281, bsz=32, num_updates=22160, lr=6.10118e-06, gnorm=10.695, clip=100, loss_scale=32, train_wall=39, gb_free=7.6, wall=85496
2023-05-21 17:42:58 - progress_bar.py[line:272] - INFO: epoch 013:   1426 / 1732 loss=2.369, loss_v1=0, loss_v2=0, nll_loss=1.166, ntokens=1225.6, nsentences=32, sample_size=1225.6, sample_size_v1=0, sample_size_v2=0, ppl=2.24, wps=311.6, ups=0.25, wpb=1225.6, bsz=32, num_updates=22170, lr=6.09913e-06, gnorm=10.793, clip=100, loss_scale=32, train_wall=39, gb_free=7.7, wall=85535
2023-05-21 17:43:37 - progress_bar.py[line:272] - INFO: epoch 013:   1436 / 1732 loss=2.376, loss_v1=0, loss_v2=0, nll_loss=1.174, ntokens=1219.4, nsentences=32, sample_size=1219.4, sample_size_v1=0, sample_size_v2=0, ppl=2.26, wps=315.2, ups=0.26, wpb=1219.4, bsz=32, num_updates=22180, lr=6.09709e-06, gnorm=10.249, clip=100, loss_scale=32, train_wall=39, gb_free=8.1, wall=85574
2023-05-21 17:44:16 - progress_bar.py[line:272] - INFO: epoch 013:   1446 / 1732 loss=2.416, loss_v1=0, loss_v2=0, nll_loss=1.22, ntokens=1113.8, nsentences=32, sample_size=1113.8, sample_size_v1=0, sample_size_v2=0, ppl=2.33, wps=286.8, ups=0.26, wpb=1113.8, bsz=32, num_updates=22190, lr=6.09504e-06, gnorm=11.7, clip=100, loss_scale=32, train_wall=39, gb_free=8.5, wall=85613
2023-05-21 17:44:55 - progress_bar.py[line:272] - INFO: epoch 013:   1456 / 1732 loss=2.406, loss_v1=0, loss_v2=0, nll_loss=1.208, ntokens=1106.5, nsentences=32, sample_size=1106.5, sample_size_v1=0, sample_size_v2=0, ppl=2.31, wps=285.2, ups=0.26, wpb=1106.5, bsz=32, num_updates=22200, lr=6.09299e-06, gnorm=11.951, clip=100, loss_scale=32, train_wall=39, gb_free=8.2, wall=85652
2023-05-21 17:45:34 - progress_bar.py[line:272] - INFO: epoch 013:   1466 / 1732 loss=2.341, loss_v1=0, loss_v2=0, nll_loss=1.135, ntokens=1200.2, nsentences=32, sample_size=1200.2, sample_size_v1=0, sample_size_v2=0, ppl=2.2, wps=307.9, ups=0.26, wpb=1200.2, bsz=32, num_updates=22210, lr=6.09094e-06, gnorm=11.175, clip=100, loss_scale=32, train_wall=39, gb_free=8.4, wall=85691
2023-05-21 17:46:12 - progress_bar.py[line:272] - INFO: epoch 013:   1476 / 1732 loss=2.417, loss_v1=0, loss_v2=0, nll_loss=1.222, ntokens=1071.6, nsentences=32, sample_size=1071.6, sample_size_v1=0, sample_size_v2=0, ppl=2.33, wps=277.1, ups=0.26, wpb=1071.6, bsz=32, num_updates=22220, lr=6.0889e-06, gnorm=12.953, clip=100, loss_scale=32, train_wall=39, gb_free=8.4, wall=85729
2023-05-21 17:46:51 - progress_bar.py[line:272] - INFO: epoch 013:   1486 / 1732 loss=2.406, loss_v1=0, loss_v2=0, nll_loss=1.208, ntokens=1132, nsentences=32, sample_size=1132, sample_size_v1=0, sample_size_v2=0, ppl=2.31, wps=291.3, ups=0.26, wpb=1132, bsz=32, num_updates=22230, lr=6.08685e-06, gnorm=11.948, clip=100, loss_scale=32, train_wall=39, gb_free=7.6, wall=85768
2023-05-21 17:47:30 - progress_bar.py[line:272] - INFO: epoch 013:   1496 / 1732 loss=2.381, loss_v1=0, loss_v2=0, nll_loss=1.179, ntokens=1113.1, nsentences=32, sample_size=1113.1, sample_size_v1=0, sample_size_v2=0, ppl=2.26, wps=285.3, ups=0.26, wpb=1113.1, bsz=32, num_updates=22240, lr=6.0848e-06, gnorm=10.269, clip=100, loss_scale=32, train_wall=39, gb_free=8.1, wall=85807
2023-05-21 17:48:09 - progress_bar.py[line:272] - INFO: epoch 013:   1506 / 1732 loss=2.34, loss_v1=0, loss_v2=0, nll_loss=1.135, ntokens=1117, nsentences=32, sample_size=1117, sample_size_v1=0, sample_size_v2=0, ppl=2.2, wps=288.6, ups=0.26, wpb=1117, bsz=32, num_updates=22250, lr=6.08275e-06, gnorm=12.052, clip=100, loss_scale=32, train_wall=39, gb_free=8.6, wall=85846
2023-05-21 17:48:48 - progress_bar.py[line:272] - INFO: epoch 013:   1516 / 1732 loss=2.412, loss_v1=0, loss_v2=0, nll_loss=1.215, ntokens=1043.6, nsentences=32, sample_size=1043.6, sample_size_v1=0, sample_size_v2=0, ppl=2.32, wps=269.1, ups=0.26, wpb=1043.6, bsz=32, num_updates=22260, lr=6.08071e-06, gnorm=11.546, clip=100, loss_scale=32, train_wall=39, gb_free=8.5, wall=85885
2023-05-21 17:49:26 - progress_bar.py[line:272] - INFO: epoch 013:   1526 / 1732 loss=2.441, loss_v1=0, loss_v2=0, nll_loss=1.246, ntokens=1063.1, nsentences=32, sample_size=1063.1, sample_size_v1=0, sample_size_v2=0, ppl=2.37, wps=274.7, ups=0.26, wpb=1063.1, bsz=32, num_updates=22270, lr=6.07866e-06, gnorm=12.615, clip=100, loss_scale=32, train_wall=39, gb_free=8.4, wall=85924
2023-05-21 17:50:05 - progress_bar.py[line:272] - INFO: epoch 013:   1536 / 1732 loss=2.391, loss_v1=0, loss_v2=0, nll_loss=1.188, ntokens=1073.8, nsentences=32, sample_size=1073.8, sample_size_v1=0, sample_size_v2=0, ppl=2.28, wps=276.2, ups=0.26, wpb=1073.8, bsz=32, num_updates=22280, lr=6.07661e-06, gnorm=12.487, clip=100, loss_scale=32, train_wall=39, gb_free=8.4, wall=85962
2023-05-21 17:50:44 - progress_bar.py[line:272] - INFO: epoch 013:   1546 / 1732 loss=2.366, loss_v1=0, loss_v2=0, nll_loss=1.163, ntokens=1068.6, nsentences=32, sample_size=1068.6, sample_size_v1=0, sample_size_v2=0, ppl=2.24, wps=275.4, ups=0.26, wpb=1068.6, bsz=32, num_updates=22290, lr=6.07457e-06, gnorm=11.515, clip=100, loss_scale=32, train_wall=39, gb_free=8.3, wall=86001
2023-05-21 17:51:23 - progress_bar.py[line:272] - INFO: epoch 013:   1556 / 1732 loss=2.387, loss_v1=0, loss_v2=0, nll_loss=1.187, ntokens=1070.8, nsentences=32, sample_size=1070.8, sample_size_v1=0, sample_size_v2=0, ppl=2.28, wps=276.6, ups=0.26, wpb=1070.8, bsz=32, num_updates=22300, lr=6.07252e-06, gnorm=11.507, clip=100, loss_scale=32, train_wall=39, gb_free=8.4, wall=86040
2023-05-21 17:52:01 - progress_bar.py[line:272] - INFO: epoch 013:   1566 / 1732 loss=2.429, loss_v1=0, loss_v2=0, nll_loss=1.232, ntokens=1097.4, nsentences=32, sample_size=1097.4, sample_size_v1=0, sample_size_v2=0, ppl=2.35, wps=283.9, ups=0.26, wpb=1097.4, bsz=32, num_updates=22310, lr=6.07047e-06, gnorm=12.435, clip=100, loss_scale=32, train_wall=39, gb_free=8.8, wall=86079
2023-05-21 17:52:40 - progress_bar.py[line:272] - INFO: epoch 013:   1576 / 1732 loss=2.432, loss_v1=0, loss_v2=0, nll_loss=1.237, ntokens=1019.9, nsentences=32, sample_size=1019.9, sample_size_v1=0, sample_size_v2=0, ppl=2.36, wps=263.3, ups=0.26, wpb=1019.9, bsz=32, num_updates=22320, lr=6.06842e-06, gnorm=14.227, clip=100, loss_scale=32, train_wall=39, gb_free=8.7, wall=86117
2023-05-21 17:53:19 - progress_bar.py[line:272] - INFO: epoch 013:   1586 / 1732 loss=2.406, loss_v1=0, loss_v2=0, nll_loss=1.208, ntokens=1060.6, nsentences=32, sample_size=1060.6, sample_size_v1=0, sample_size_v2=0, ppl=2.31, wps=273.4, ups=0.26, wpb=1060.6, bsz=32, num_updates=22330, lr=6.06638e-06, gnorm=12.728, clip=100, loss_scale=32, train_wall=39, gb_free=8.2, wall=86156
2023-05-21 17:53:57 - progress_bar.py[line:272] - INFO: epoch 013:   1596 / 1732 loss=2.366, loss_v1=0, loss_v2=0, nll_loss=1.162, ntokens=1073.8, nsentences=32, sample_size=1073.8, sample_size_v1=0, sample_size_v2=0, ppl=2.24, wps=278.4, ups=0.26, wpb=1073.8, bsz=32, num_updates=22340, lr=6.06433e-06, gnorm=11.233, clip=100, loss_scale=32, train_wall=39, gb_free=8.4, wall=86195
2023-05-21 17:54:36 - progress_bar.py[line:272] - INFO: epoch 013:   1606 / 1732 loss=2.392, loss_v1=0, loss_v2=0, nll_loss=1.194, ntokens=1124, nsentences=32, sample_size=1124, sample_size_v1=0, sample_size_v2=0, ppl=2.29, wps=289.4, ups=0.26, wpb=1124, bsz=32, num_updates=22350, lr=6.06228e-06, gnorm=11.539, clip=100, loss_scale=32, train_wall=39, gb_free=8.2, wall=86234
2023-05-21 17:55:15 - progress_bar.py[line:272] - INFO: epoch 013:   1616 / 1732 loss=2.346, loss_v1=0, loss_v2=0, nll_loss=1.141, ntokens=1154.1, nsentences=32, sample_size=1154.1, sample_size_v1=0, sample_size_v2=0, ppl=2.21, wps=294.9, ups=0.26, wpb=1154.1, bsz=32, num_updates=22360, lr=6.06023e-06, gnorm=10.816, clip=100, loss_scale=32, train_wall=39, gb_free=8.7, wall=86273
2023-05-21 17:55:54 - progress_bar.py[line:272] - INFO: epoch 013:   1626 / 1732 loss=2.385, loss_v1=0, loss_v2=0, nll_loss=1.185, ntokens=1109.2, nsentences=32, sample_size=1109.2, sample_size_v1=0, sample_size_v2=0, ppl=2.27, wps=284.5, ups=0.26, wpb=1109.2, bsz=32, num_updates=22370, lr=6.05819e-06, gnorm=10.828, clip=100, loss_scale=32, train_wall=39, gb_free=8.5, wall=86312
2023-05-21 17:56:33 - progress_bar.py[line:272] - INFO: epoch 013:   1636 / 1732 loss=2.363, loss_v1=0, loss_v2=0, nll_loss=1.159, ntokens=1146, nsentences=32, sample_size=1146, sample_size_v1=0, sample_size_v2=0, ppl=2.23, wps=296.2, ups=0.26, wpb=1146, bsz=32, num_updates=22380, lr=6.05614e-06, gnorm=10.623, clip=100, loss_scale=32, train_wall=39, gb_free=9.1, wall=86350
2023-05-21 17:57:12 - progress_bar.py[line:272] - INFO: epoch 013:   1646 / 1732 loss=2.34, loss_v1=0, loss_v2=0, nll_loss=1.133, ntokens=1290.2, nsentences=32, sample_size=1290.2, sample_size_v1=0, sample_size_v2=0, ppl=2.19, wps=328.1, ups=0.25, wpb=1290.2, bsz=32, num_updates=22390, lr=6.05409e-06, gnorm=10.014, clip=100, loss_scale=32, train_wall=39, gb_free=8.2, wall=86390
2023-05-21 17:57:51 - progress_bar.py[line:272] - INFO: epoch 013:   1656 / 1732 loss=2.416, loss_v1=0, loss_v2=0, nll_loss=1.219, ntokens=952.5, nsentences=32, sample_size=952.5, sample_size_v1=0, sample_size_v2=0, ppl=2.33, wps=248.6, ups=0.26, wpb=952.5, bsz=32, num_updates=22400, lr=6.05204e-06, gnorm=13.011, clip=100, loss_scale=32, train_wall=38, gb_free=8.5, wall=86428
2023-05-21 17:58:30 - progress_bar.py[line:272] - INFO: epoch 013:   1666 / 1732 loss=2.404, loss_v1=0, loss_v2=0, nll_loss=1.207, ntokens=1015, nsentences=32, sample_size=1015, sample_size_v1=0, sample_size_v2=0, ppl=2.31, wps=261.6, ups=0.26, wpb=1015, bsz=32, num_updates=22410, lr=6.05e-06, gnorm=12.392, clip=100, loss_scale=32, train_wall=39, gb_free=8.5, wall=86467
2023-05-21 17:59:08 - progress_bar.py[line:272] - INFO: epoch 013:   1676 / 1732 loss=2.345, loss_v1=0, loss_v2=0, nll_loss=1.138, ntokens=1119.1, nsentences=32, sample_size=1119.1, sample_size_v1=0, sample_size_v2=0, ppl=2.2, wps=289.4, ups=0.26, wpb=1119.1, bsz=32, num_updates=22420, lr=6.04795e-06, gnorm=10.888, clip=100, loss_scale=32, train_wall=39, gb_free=8.3, wall=86505
2023-05-21 17:59:47 - progress_bar.py[line:272] - INFO: epoch 013:   1686 / 1732 loss=2.344, loss_v1=0, loss_v2=0, nll_loss=1.138, ntokens=1151.6, nsentences=32, sample_size=1151.6, sample_size_v1=0, sample_size_v2=0, ppl=2.2, wps=295, ups=0.26, wpb=1151.6, bsz=32, num_updates=22430, lr=6.0459e-06, gnorm=11.077, clip=100, loss_scale=32, train_wall=39, gb_free=7.7, wall=86545
2023-05-21 18:00:27 - progress_bar.py[line:272] - INFO: epoch 013:   1696 / 1732 loss=2.382, loss_v1=0, loss_v2=0, nll_loss=1.182, ntokens=1284.6, nsentences=32, sample_size=1284.6, sample_size_v1=0, sample_size_v2=0, ppl=2.27, wps=323.4, ups=0.25, wpb=1284.6, bsz=32, num_updates=22440, lr=6.04385e-06, gnorm=10.528, clip=100, loss_scale=32, train_wall=40, gb_free=7.9, wall=86584
2023-05-21 18:01:06 - progress_bar.py[line:272] - INFO: epoch 013:   1706 / 1732 loss=2.375, loss_v1=0, loss_v2=0, nll_loss=1.172, ntokens=1193.5, nsentences=32, sample_size=1193.5, sample_size_v1=0, sample_size_v2=0, ppl=2.25, wps=303.8, ups=0.25, wpb=1193.5, bsz=32, num_updates=22450, lr=6.04181e-06, gnorm=11.01, clip=100, loss_scale=32, train_wall=39, gb_free=7.9, wall=86624
2023-05-21 18:01:46 - progress_bar.py[line:272] - INFO: epoch 013:   1716 / 1732 loss=2.364, loss_v1=0, loss_v2=0, nll_loss=1.161, ntokens=1213.9, nsentences=32, sample_size=1213.9, sample_size_v1=0, sample_size_v2=0, ppl=2.24, wps=309.9, ups=0.26, wpb=1213.9, bsz=32, num_updates=22460, lr=6.03976e-06, gnorm=11.419, clip=100, loss_scale=32, train_wall=39, gb_free=7.4, wall=86663
2023-05-21 18:02:24 - progress_bar.py[line:272] - INFO: epoch 013:   1726 / 1732 loss=2.406, loss_v1=0, loss_v2=0, nll_loss=1.208, ntokens=1112.1, nsentences=32, sample_size=1112.1, sample_size_v1=0, sample_size_v2=0, ppl=2.31, wps=285.3, ups=0.26, wpb=1112.1, bsz=32, num_updates=22470, lr=6.03771e-06, gnorm=11.927, clip=100, loss_scale=32, train_wall=39, gb_free=8.3, wall=86702
2023-05-21 18:02:45 - train.py[line:332] - INFO: end of epoch 13 (average epoch stats below)
2023-05-21 18:02:45 - progress_bar.py[line:282] - INFO: epoch 013 | loss 2.396 | loss_v1 0 | loss_v2 0 | nll_loss 1.197 | ntokens 1051.48 | nsentences 31.986 | sample_size 1051.48 | sample_size_v1 0 | sample_size_v2 0 | ppl 2.29 | wps 272.6 | ups 0.26 | wpb 1051.5 | bsz 32 | num_updates 22476 | lr 6.03648e-06 | gnorm 11.888 | clip 100 | loss_scale 32 | train_wall 6658 | gb_free 8.9 | wall 86722
2023-05-21 18:02:45 - trainer.py[line:639] - INFO: loading train data for epoch 14
local datafile ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 0 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 0 finished initializing row_count and line_idx-to-offset mapping
file ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 0 row count 55400 total row count 55400
slice_id 0 seek offset 0
2023-05-21 18:02:47 - trainer.py[line:703] - INFO: begin training epoch 14
2023-05-21 18:02:47 - train.py[line:305] - INFO: Start iterating over samples
2023-05-21 18:03:03 - progress_bar.py[line:272] - INFO: epoch 014:      4 / 1732 loss=2.378, loss_v1=0, loss_v2=0, nll_loss=1.175, ntokens=1098.7, nsentences=29.6, sample_size=1098.7, sample_size_v1=0, sample_size_v2=0, ppl=2.26, wps=287.8, ups=0.26, wpb=1098.7, bsz=29.6, num_updates=22480, lr=6.03567e-06, gnorm=13.446, clip=100, loss_scale=32, train_wall=36, gb_free=8, wall=86740
2023-05-21 18:03:41 - progress_bar.py[line:272] - INFO: epoch 014:     14 / 1732 loss=2.332, loss_v1=0, loss_v2=0, nll_loss=1.124, ntokens=1064.2, nsentences=32, sample_size=1064.2, sample_size_v1=0, sample_size_v2=0, ppl=2.18, wps=275.3, ups=0.26, wpb=1064.2, bsz=32, num_updates=22490, lr=6.03362e-06, gnorm=11.462, clip=100, loss_scale=32, train_wall=39, gb_free=8.3, wall=86779
2023-05-21 18:04:20 - progress_bar.py[line:272] - INFO: epoch 014:     24 / 1732 loss=2.287, loss_v1=0, loss_v2=0, nll_loss=1.073, ntokens=1038.3, nsentences=32, sample_size=1038.3, sample_size_v1=0, sample_size_v2=0, ppl=2.1, wps=267.3, ups=0.26, wpb=1038.3, bsz=32, num_updates=22500, lr=6.03157e-06, gnorm=12.874, clip=100, loss_scale=32, train_wall=39, gb_free=8.5, wall=86817
2023-05-21 18:04:59 - progress_bar.py[line:272] - INFO: epoch 014:     34 / 1732 loss=2.229, loss_v1=0, loss_v2=0, nll_loss=1.007, ntokens=1072.7, nsentences=32, sample_size=1072.7, sample_size_v1=0, sample_size_v2=0, ppl=2.01, wps=274.8, ups=0.26, wpb=1072.7, bsz=32, num_updates=22510, lr=6.02952e-06, gnorm=10.956, clip=100, loss_scale=32, train_wall=39, gb_free=8.2, wall=86856
2023-05-21 18:05:38 - progress_bar.py[line:272] - INFO: epoch 014:     44 / 1732 loss=2.185, loss_v1=0, loss_v2=0, nll_loss=0.966, ntokens=1134, nsentences=32, sample_size=1134, sample_size_v1=0, sample_size_v2=0, ppl=1.95, wps=291.1, ups=0.26, wpb=1134, bsz=32, num_updates=22520, lr=6.02748e-06, gnorm=9.551, clip=100, loss_scale=32, train_wall=39, gb_free=8.1, wall=86895
2023-05-21 18:06:17 - progress_bar.py[line:272] - INFO: epoch 014:     54 / 1732 loss=2.2, loss_v1=0, loss_v2=0, nll_loss=0.977, ntokens=1025.8, nsentences=32, sample_size=1025.8, sample_size_v1=0, sample_size_v2=0, ppl=1.97, wps=264.2, ups=0.26, wpb=1025.8, bsz=32, num_updates=22530, lr=6.02543e-06, gnorm=10.989, clip=100, loss_scale=64, train_wall=39, gb_free=8.4, wall=86934
2023-05-21 18:06:57 - progress_bar.py[line:272] - INFO: epoch 014:     64 / 1732 loss=2.025, loss_v1=0, loss_v2=0, nll_loss=0.781, ntokens=1253.8, nsentences=32, sample_size=1253.8, sample_size_v1=0, sample_size_v2=0, ppl=1.72, wps=317.7, ups=0.25, wpb=1253.8, bsz=32, num_updates=22540, lr=6.02338e-06, gnorm=7.426, clip=100, loss_scale=64, train_wall=39, gb_free=7.8, wall=86974
2023-05-21 18:07:17 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2023-05-21 18:07:40 - progress_bar.py[line:272] - INFO: epoch 014:     75 / 1732 loss=2.125, loss_v1=0, loss_v2=0, nll_loss=0.895, ntokens=1363.4, nsentences=32, sample_size=1363.4, sample_size_v1=0, sample_size_v2=0, ppl=1.86, wps=310.3, ups=0.23, wpb=1363.4, bsz=32, num_updates=22550, lr=6.02133e-06, gnorm=8.767, clip=100, loss_scale=32, train_wall=44, gb_free=7.6, wall=87018
2023-05-21 18:08:20 - progress_bar.py[line:272] - INFO: epoch 014:     85 / 1732 loss=2.213, loss_v1=0, loss_v2=0, nll_loss=0.99, ntokens=1112.6, nsentences=32, sample_size=1112.6, sample_size_v1=0, sample_size_v2=0, ppl=1.99, wps=282.7, ups=0.25, wpb=1112.6, bsz=32, num_updates=22560, lr=6.01929e-06, gnorm=10.632, clip=100, loss_scale=32, train_wall=39, gb_free=8.5, wall=87057
2023-05-21 18:08:59 - progress_bar.py[line:272] - INFO: epoch 014:     95 / 1732 loss=2.175, loss_v1=0, loss_v2=0, nll_loss=0.948, ntokens=1092.3, nsentences=32, sample_size=1092.3, sample_size_v1=0, sample_size_v2=0, ppl=1.93, wps=281.6, ups=0.26, wpb=1092.3, bsz=32, num_updates=22570, lr=6.01724e-06, gnorm=10.226, clip=100, loss_scale=32, train_wall=39, gb_free=8.8, wall=87096
2023-05-21 18:09:37 - progress_bar.py[line:272] - INFO: epoch 014:    105 / 1732 loss=2.352, loss_v1=0, loss_v2=0, nll_loss=1.152, ntokens=995.3, nsentences=32, sample_size=995.3, sample_size_v1=0, sample_size_v2=0, ppl=2.22, wps=257.8, ups=0.26, wpb=995.3, bsz=32, num_updates=22580, lr=6.01519e-06, gnorm=12.693, clip=100, loss_scale=32, train_wall=39, gb_free=8.3, wall=87134
2023-05-21 18:10:16 - progress_bar.py[line:272] - INFO: epoch 014:    115 / 1732 loss=2.413, loss_v1=0, loss_v2=0, nll_loss=1.218, ntokens=1032.5, nsentences=32, sample_size=1032.5, sample_size_v1=0, sample_size_v2=0, ppl=2.33, wps=266.2, ups=0.26, wpb=1032.5, bsz=32, num_updates=22590, lr=6.01314e-06, gnorm=11.847, clip=100, loss_scale=32, train_wall=39, gb_free=8.2, wall=87173
2023-05-21 18:10:55 - progress_bar.py[line:272] - INFO: epoch 014:    125 / 1732 loss=2.344, loss_v1=0, loss_v2=0, nll_loss=1.135, ntokens=1181.7, nsentences=32, sample_size=1181.7, sample_size_v1=0, sample_size_v2=0, ppl=2.2, wps=299.4, ups=0.25, wpb=1181.7, bsz=32, num_updates=22600, lr=6.0111e-06, gnorm=11.354, clip=100, loss_scale=32, train_wall=39, gb_free=7.4, wall=87213
2023-05-21 18:11:35 - progress_bar.py[line:272] - INFO: epoch 014:    135 / 1732 loss=2.315, loss_v1=0, loss_v2=0, nll_loss=1.104, ntokens=1179.6, nsentences=32, sample_size=1179.6, sample_size_v1=0, sample_size_v2=0, ppl=2.15, wps=301.7, ups=0.26, wpb=1179.6, bsz=32, num_updates=22610, lr=6.00905e-06, gnorm=9.88, clip=100, loss_scale=32, train_wall=39, gb_free=8.6, wall=87252
2023-05-21 18:12:14 - progress_bar.py[line:272] - INFO: epoch 014:    145 / 1732 loss=2.282, loss_v1=0, loss_v2=0, nll_loss=1.068, ntokens=1246.8, nsentences=32, sample_size=1246.8, sample_size_v1=0, sample_size_v2=0, ppl=2.1, wps=313.1, ups=0.25, wpb=1246.8, bsz=32, num_updates=22620, lr=6.007e-06, gnorm=9.172, clip=100, loss_scale=32, train_wall=40, gb_free=7.7, wall=87292
2023-05-21 18:12:54 - progress_bar.py[line:272] - INFO: epoch 014:    155 / 1732 loss=2.315, loss_v1=0, loss_v2=0, nll_loss=1.109, ntokens=1151.6, nsentences=32, sample_size=1151.6, sample_size_v1=0, sample_size_v2=0, ppl=2.16, wps=290.1, ups=0.25, wpb=1151.6, bsz=32, num_updates=22630, lr=6.00495e-06, gnorm=9.142, clip=100, loss_scale=32, train_wall=40, gb_free=7.9, wall=87331
2023-05-21 18:13:33 - progress_bar.py[line:272] - INFO: epoch 014:    165 / 1732 loss=2.283, loss_v1=0, loss_v2=0, nll_loss=1.071, ntokens=1062.3, nsentences=32, sample_size=1062.3, sample_size_v1=0, sample_size_v2=0, ppl=2.1, wps=272.7, ups=0.26, wpb=1062.3, bsz=32, num_updates=22640, lr=6.00291e-06, gnorm=10.138, clip=100, loss_scale=32, train_wall=39, gb_free=8.8, wall=87370
2023-05-21 18:14:12 - progress_bar.py[line:272] - INFO: epoch 014:    175 / 1732 loss=2.318, loss_v1=0, loss_v2=0, nll_loss=1.107, ntokens=958.4, nsentences=32, sample_size=958.4, sample_size_v1=0, sample_size_v2=0, ppl=2.15, wps=247.1, ups=0.26, wpb=958.4, bsz=32, num_updates=22650, lr=6.00086e-06, gnorm=10.982, clip=100, loss_scale=32, train_wall=39, gb_free=7.7, wall=87409
2023-05-21 18:14:51 - progress_bar.py[line:272] - INFO: epoch 014:    185 / 1732 loss=2.264, loss_v1=0, loss_v2=0, nll_loss=1.047, ntokens=1173.4, nsentences=32, sample_size=1173.4, sample_size_v1=0, sample_size_v2=0, ppl=2.07, wps=297.4, ups=0.25, wpb=1173.4, bsz=32, num_updates=22660, lr=5.99881e-06, gnorm=9.67, clip=100, loss_scale=32, train_wall=39, gb_free=6.7, wall=87449
2023-05-21 18:15:31 - progress_bar.py[line:272] - INFO: epoch 014:    195 / 1732 loss=2.306, loss_v1=0, loss_v2=0, nll_loss=1.096, ntokens=1144.6, nsentences=32, sample_size=1144.6, sample_size_v1=0, sample_size_v2=0, ppl=2.14, wps=290.1, ups=0.25, wpb=1144.6, bsz=32, num_updates=22670, lr=5.99677e-06, gnorm=9.826, clip=100, loss_scale=32, train_wall=39, gb_free=7.7, wall=87488
2023-05-21 18:16:09 - progress_bar.py[line:272] - INFO: epoch 014:    205 / 1732 loss=2.392, loss_v1=0, loss_v2=0, nll_loss=1.193, ntokens=1021.8, nsentences=32, sample_size=1021.8, sample_size_v1=0, sample_size_v2=0, ppl=2.29, wps=265.1, ups=0.26, wpb=1021.8, bsz=32, num_updates=22680, lr=5.99472e-06, gnorm=11.267, clip=100, loss_scale=32, train_wall=39, gb_free=9, wall=87527
2023-05-21 18:16:48 - progress_bar.py[line:272] - INFO: epoch 014:    215 / 1732 loss=2.416, loss_v1=0, loss_v2=0, nll_loss=1.222, ntokens=1094.3, nsentences=32, sample_size=1094.3, sample_size_v1=0, sample_size_v2=0, ppl=2.33, wps=284.8, ups=0.26, wpb=1094.3, bsz=32, num_updates=22690, lr=5.99267e-06, gnorm=10.069, clip=100, loss_scale=32, train_wall=38, gb_free=8.9, wall=87565
2023-05-21 18:17:26 - progress_bar.py[line:272] - INFO: epoch 014:    225 / 1732 loss=2.405, loss_v1=0, loss_v2=0, nll_loss=1.205, ntokens=1095.2, nsentences=32, sample_size=1095.2, sample_size_v1=0, sample_size_v2=0, ppl=2.31, wps=284.9, ups=0.26, wpb=1095.2, bsz=32, num_updates=22700, lr=5.99062e-06, gnorm=11.545, clip=100, loss_scale=32, train_wall=38, gb_free=8, wall=87603
2023-05-21 18:18:05 - progress_bar.py[line:272] - INFO: epoch 014:    235 / 1732 loss=2.464, loss_v1=0, loss_v2=0, nll_loss=1.271, ntokens=1090, nsentences=32, sample_size=1090, sample_size_v1=0, sample_size_v2=0, ppl=2.41, wps=284.4, ups=0.26, wpb=1090, bsz=32, num_updates=22710, lr=5.98858e-06, gnorm=11.679, clip=100, loss_scale=32, train_wall=38, gb_free=8.5, wall=87642
2023-05-21 18:18:43 - progress_bar.py[line:272] - INFO: epoch 014:    245 / 1732 loss=2.442, loss_v1=0, loss_v2=0, nll_loss=1.247, ntokens=1178.2, nsentences=32, sample_size=1178.2, sample_size_v1=0, sample_size_v2=0, ppl=2.37, wps=305.1, ups=0.26, wpb=1178.2, bsz=32, num_updates=22720, lr=5.98653e-06, gnorm=10.924, clip=100, loss_scale=32, train_wall=39, gb_free=8.4, wall=87680
2023-05-21 18:19:22 - progress_bar.py[line:272] - INFO: epoch 014:    255 / 1732 loss=2.438, loss_v1=0, loss_v2=0, nll_loss=1.242, ntokens=1128.2, nsentences=32, sample_size=1128.2, sample_size_v1=0, sample_size_v2=0, ppl=2.36, wps=291.6, ups=0.26, wpb=1128.2, bsz=32, num_updates=22730, lr=5.98448e-06, gnorm=11.413, clip=100, loss_scale=32, train_wall=39, gb_free=9, wall=87719
2023-05-21 18:20:00 - progress_bar.py[line:272] - INFO: epoch 014:    265 / 1732 loss=2.433, loss_v1=0, loss_v2=0, nll_loss=1.238, ntokens=1148, nsentences=32, sample_size=1148, sample_size_v1=0, sample_size_v2=0, ppl=2.36, wps=297.2, ups=0.26, wpb=1148, bsz=32, num_updates=22740, lr=5.98243e-06, gnorm=11.103, clip=100, loss_scale=32, train_wall=39, gb_free=8.5, wall=87758
2023-05-21 18:20:39 - progress_bar.py[line:272] - INFO: epoch 014:    275 / 1732 loss=2.421, loss_v1=0, loss_v2=0, nll_loss=1.224, ntokens=1140.3, nsentences=32, sample_size=1140.3, sample_size_v1=0, sample_size_v2=0, ppl=2.34, wps=295, ups=0.26, wpb=1140.3, bsz=32, num_updates=22750, lr=5.98039e-06, gnorm=11.418, clip=100, loss_scale=32, train_wall=39, gb_free=8.6, wall=87796
2023-05-21 18:21:18 - progress_bar.py[line:272] - INFO: epoch 014:    285 / 1732 loss=2.44, loss_v1=0, loss_v2=0, nll_loss=1.245, ntokens=1154.4, nsentences=32, sample_size=1154.4, sample_size_v1=0, sample_size_v2=0, ppl=2.37, wps=298.6, ups=0.26, wpb=1154.4, bsz=32, num_updates=22760, lr=5.97834e-06, gnorm=11.326, clip=100, loss_scale=32, train_wall=39, gb_free=7.3, wall=87835
2023-05-21 18:21:56 - progress_bar.py[line:272] - INFO: epoch 014:    295 / 1732 loss=2.415, loss_v1=0, loss_v2=0, nll_loss=1.218, ntokens=1115.8, nsentences=32, sample_size=1115.8, sample_size_v1=0, sample_size_v2=0, ppl=2.33, wps=290.8, ups=0.26, wpb=1115.8, bsz=32, num_updates=22770, lr=5.97629e-06, gnorm=10.523, clip=100, loss_scale=32, train_wall=38, gb_free=8.6, wall=87873
2023-05-21 18:22:35 - progress_bar.py[line:272] - INFO: epoch 014:    305 / 1732 loss=2.411, loss_v1=0, loss_v2=0, nll_loss=1.213, ntokens=1102.2, nsentences=32, sample_size=1102.2, sample_size_v1=0, sample_size_v2=0, ppl=2.32, wps=285.8, ups=0.26, wpb=1102.2, bsz=32, num_updates=22780, lr=5.97424e-06, gnorm=11.471, clip=100, loss_scale=32, train_wall=39, gb_free=8.2, wall=87912
2023-05-21 18:23:13 - progress_bar.py[line:272] - INFO: epoch 014:    315 / 1732 loss=2.434, loss_v1=0, loss_v2=0, nll_loss=1.239, ntokens=1020.3, nsentences=32, sample_size=1020.3, sample_size_v1=0, sample_size_v2=0, ppl=2.36, wps=266.6, ups=0.26, wpb=1020.3, bsz=32, num_updates=22790, lr=5.9722e-06, gnorm=12.947, clip=100, loss_scale=32, train_wall=38, gb_free=8.7, wall=87950
2023-05-21 18:23:51 - progress_bar.py[line:272] - INFO: epoch 014:    325 / 1732 loss=2.446, loss_v1=0, loss_v2=0, nll_loss=1.253, ntokens=1011.9, nsentences=32, sample_size=1011.9, sample_size_v1=0, sample_size_v2=0, ppl=2.38, wps=265.4, ups=0.26, wpb=1011.9, bsz=32, num_updates=22800, lr=5.97015e-06, gnorm=12.16, clip=100, loss_scale=32, train_wall=38, gb_free=9, wall=87988
2023-05-21 18:24:29 - progress_bar.py[line:272] - INFO: epoch 014:    335 / 1732 loss=2.446, loss_v1=0, loss_v2=0, nll_loss=1.252, ntokens=1020.9, nsentences=32, sample_size=1020.9, sample_size_v1=0, sample_size_v2=0, ppl=2.38, wps=268.1, ups=0.26, wpb=1020.9, bsz=32, num_updates=22810, lr=5.9681e-06, gnorm=12.399, clip=100, loss_scale=32, train_wall=38, gb_free=8.7, wall=88026
2023-05-21 18:25:07 - progress_bar.py[line:272] - INFO: epoch 014:    345 / 1732 loss=2.405, loss_v1=0, loss_v2=0, nll_loss=1.205, ntokens=903.9, nsentences=32, sample_size=903.9, sample_size_v1=0, sample_size_v2=0, ppl=2.31, wps=238.7, ups=0.26, wpb=903.9, bsz=32, num_updates=22820, lr=5.96605e-06, gnorm=12.296, clip=100, loss_scale=32, train_wall=38, gb_free=8.3, wall=88064
2023-05-21 18:25:45 - progress_bar.py[line:272] - INFO: epoch 014:    355 / 1732 loss=2.438, loss_v1=0, loss_v2=0, nll_loss=1.246, ntokens=961.9, nsentences=32, sample_size=961.9, sample_size_v1=0, sample_size_v2=0, ppl=2.37, wps=252, ups=0.26, wpb=961.9, bsz=32, num_updates=22830, lr=5.96401e-06, gnorm=12.934, clip=100, loss_scale=32, train_wall=38, gb_free=9, wall=88102
2023-05-21 18:26:23 - progress_bar.py[line:272] - INFO: epoch 014:    365 / 1732 loss=2.47, loss_v1=0, loss_v2=0, nll_loss=1.28, ntokens=955.9, nsentences=32, sample_size=955.9, sample_size_v1=0, sample_size_v2=0, ppl=2.43, wps=252.5, ups=0.26, wpb=955.9, bsz=32, num_updates=22840, lr=5.96196e-06, gnorm=12.622, clip=100, loss_scale=32, train_wall=38, gb_free=8.2, wall=88140
2023-05-21 18:27:01 - progress_bar.py[line:272] - INFO: epoch 014:    375 / 1732 loss=2.47, loss_v1=0, loss_v2=0, nll_loss=1.277, ntokens=987.5, nsentences=32, sample_size=987.5, sample_size_v1=0, sample_size_v2=0, ppl=2.42, wps=259.2, ups=0.26, wpb=987.5, bsz=32, num_updates=22850, lr=5.95991e-06, gnorm=14.207, clip=100, loss_scale=32, train_wall=38, gb_free=9.1, wall=88178
2023-05-21 18:27:39 - progress_bar.py[line:272] - INFO: epoch 014:    385 / 1732 loss=2.444, loss_v1=0, loss_v2=0, nll_loss=1.249, ntokens=1084.2, nsentences=32, sample_size=1084.2, sample_size_v1=0, sample_size_v2=0, ppl=2.38, wps=283.6, ups=0.26, wpb=1084.2, bsz=32, num_updates=22860, lr=5.95786e-06, gnorm=12.178, clip=100, loss_scale=32, train_wall=38, gb_free=8.8, wall=88217
2023-05-21 18:28:17 - progress_bar.py[line:272] - INFO: epoch 014:    395 / 1732 loss=2.449, loss_v1=0, loss_v2=0, nll_loss=1.255, ntokens=924.7, nsentences=32, sample_size=924.7, sample_size_v1=0, sample_size_v2=0, ppl=2.39, wps=243.4, ups=0.26, wpb=924.7, bsz=32, num_updates=22870, lr=5.95582e-06, gnorm=12.128, clip=100, loss_scale=32, train_wall=38, gb_free=8.8, wall=88255
2023-05-21 18:28:56 - progress_bar.py[line:272] - INFO: epoch 014:    405 / 1732 loss=2.402, loss_v1=0, loss_v2=0, nll_loss=1.204, ntokens=1086.5, nsentences=32, sample_size=1086.5, sample_size_v1=0, sample_size_v2=0, ppl=2.3, wps=282.8, ups=0.26, wpb=1086.5, bsz=32, num_updates=22880, lr=5.95377e-06, gnorm=11.305, clip=100, loss_scale=32, train_wall=38, gb_free=9, wall=88293
2023-05-21 18:29:34 - progress_bar.py[line:272] - INFO: epoch 014:    415 / 1732 loss=2.419, loss_v1=0, loss_v2=0, nll_loss=1.223, ntokens=1059.1, nsentences=32, sample_size=1059.1, sample_size_v1=0, sample_size_v2=0, ppl=2.33, wps=276.3, ups=0.26, wpb=1059.1, bsz=32, num_updates=22890, lr=5.95172e-06, gnorm=11.999, clip=100, loss_scale=32, train_wall=38, gb_free=8.9, wall=88331
2023-05-21 18:30:12 - progress_bar.py[line:272] - INFO: epoch 014:    425 / 1732 loss=2.393, loss_v1=0, loss_v2=0, nll_loss=1.193, ntokens=994.5, nsentences=32, sample_size=994.5, sample_size_v1=0, sample_size_v2=0, ppl=2.29, wps=260.1, ups=0.26, wpb=994.5, bsz=32, num_updates=22900, lr=5.94968e-06, gnorm=12.461, clip=100, loss_scale=32, train_wall=38, gb_free=8.5, wall=88370
2023-05-21 18:30:51 - progress_bar.py[line:272] - INFO: epoch 014:    435 / 1732 loss=2.433, loss_v1=0, loss_v2=0, nll_loss=1.237, ntokens=1024.5, nsentences=32, sample_size=1024.5, sample_size_v1=0, sample_size_v2=0, ppl=2.36, wps=268.3, ups=0.26, wpb=1024.5, bsz=32, num_updates=22910, lr=5.94763e-06, gnorm=13.4, clip=100, loss_scale=32, train_wall=38, gb_free=9.2, wall=88408
2023-05-21 18:31:29 - progress_bar.py[line:272] - INFO: epoch 014:    445 / 1732 loss=2.453, loss_v1=0, loss_v2=0, nll_loss=1.26, ntokens=956.5, nsentences=32, sample_size=956.5, sample_size_v1=0, sample_size_v2=0, ppl=2.39, wps=250.3, ups=0.26, wpb=956.5, bsz=32, num_updates=22920, lr=5.94558e-06, gnorm=12.339, clip=100, loss_scale=32, train_wall=38, gb_free=8.6, wall=88446
2023-05-21 18:32:07 - progress_bar.py[line:272] - INFO: epoch 014:    455 / 1732 loss=2.439, loss_v1=0, loss_v2=0, nll_loss=1.247, ntokens=932.1, nsentences=32, sample_size=932.1, sample_size_v1=0, sample_size_v2=0, ppl=2.37, wps=244.8, ups=0.26, wpb=932.1, bsz=32, num_updates=22930, lr=5.94353e-06, gnorm=13.79, clip=100, loss_scale=32, train_wall=38, gb_free=8.8, wall=88484
2023-05-21 18:32:45 - progress_bar.py[line:272] - INFO: epoch 014:    465 / 1732 loss=2.464, loss_v1=0, loss_v2=0, nll_loss=1.271, ntokens=1058.7, nsentences=32, sample_size=1058.7, sample_size_v1=0, sample_size_v2=0, ppl=2.41, wps=277.6, ups=0.26, wpb=1058.7, bsz=32, num_updates=22940, lr=5.94149e-06, gnorm=12.359, clip=100, loss_scale=32, train_wall=38, gb_free=8.6, wall=88522
2023-05-21 18:33:23 - progress_bar.py[line:272] - INFO: epoch 014:    475 / 1732 loss=2.452, loss_v1=0, loss_v2=0, nll_loss=1.257, ntokens=1061.8, nsentences=32, sample_size=1061.8, sample_size_v1=0, sample_size_v2=0, ppl=2.39, wps=277.1, ups=0.26, wpb=1061.8, bsz=32, num_updates=22950, lr=5.93944e-06, gnorm=11.784, clip=100, loss_scale=32, train_wall=38, gb_free=8.5, wall=88561
2023-05-21 18:34:01 - progress_bar.py[line:272] - INFO: epoch 014:    485 / 1732 loss=2.426, loss_v1=0, loss_v2=0, nll_loss=1.229, ntokens=980.2, nsentences=32, sample_size=980.2, sample_size_v1=0, sample_size_v2=0, ppl=2.34, wps=257.5, ups=0.26, wpb=980.2, bsz=32, num_updates=22960, lr=5.93739e-06, gnorm=13.395, clip=100, loss_scale=32, train_wall=38, gb_free=8.4, wall=88599
2023-05-21 18:34:39 - progress_bar.py[line:272] - INFO: epoch 014:    495 / 1732 loss=2.429, loss_v1=0, loss_v2=0, nll_loss=1.235, ntokens=928.7, nsentences=32, sample_size=928.7, sample_size_v1=0, sample_size_v2=0, ppl=2.35, wps=244.9, ups=0.26, wpb=928.7, bsz=32, num_updates=22970, lr=5.93534e-06, gnorm=13.059, clip=100, loss_scale=32, train_wall=38, gb_free=9.3, wall=88637
2023-05-21 18:35:18 - progress_bar.py[line:272] - INFO: epoch 014:    505 / 1732 loss=2.443, loss_v1=0, loss_v2=0, nll_loss=1.249, ntokens=974.8, nsentences=32, sample_size=974.8, sample_size_v1=0, sample_size_v2=0, ppl=2.38, wps=255.3, ups=0.26, wpb=974.8, bsz=32, num_updates=22980, lr=5.9333e-06, gnorm=14.09, clip=100, loss_scale=32, train_wall=38, gb_free=8.7, wall=88675
2023-05-21 18:35:56 - progress_bar.py[line:272] - INFO: epoch 014:    515 / 1732 loss=2.442, loss_v1=0, loss_v2=0, nll_loss=1.247, ntokens=1073.1, nsentences=32, sample_size=1073.1, sample_size_v1=0, sample_size_v2=0, ppl=2.37, wps=279.9, ups=0.26, wpb=1073.1, bsz=32, num_updates=22990, lr=5.93125e-06, gnorm=11.403, clip=100, loss_scale=32, train_wall=38, gb_free=8.4, wall=88713
2023-05-21 18:36:34 - progress_bar.py[line:272] - INFO: epoch 014:    525 / 1732 loss=2.436, loss_v1=0, loss_v2=0, nll_loss=1.242, ntokens=955.6, nsentences=32, sample_size=955.6, sample_size_v1=0, sample_size_v2=0, ppl=2.37, wps=251.4, ups=0.26, wpb=955.6, bsz=32, num_updates=23000, lr=5.9292e-06, gnorm=13.712, clip=100, loss_scale=32, train_wall=38, gb_free=8.9, wall=88751
2023-05-21 18:37:12 - progress_bar.py[line:272] - INFO: epoch 014:    535 / 1732 loss=2.433, loss_v1=0, loss_v2=0, nll_loss=1.236, ntokens=948.7, nsentences=32, sample_size=948.7, sample_size_v1=0, sample_size_v2=0, ppl=2.36, wps=249.4, ups=0.26, wpb=948.7, bsz=32, num_updates=23010, lr=5.92715e-06, gnorm=13.298, clip=100, loss_scale=32, train_wall=38, gb_free=8.5, wall=88789
2023-05-21 18:37:50 - progress_bar.py[line:272] - INFO: epoch 014:    545 / 1732 loss=2.444, loss_v1=0, loss_v2=0, nll_loss=1.25, ntokens=1010, nsentences=32, sample_size=1010, sample_size_v1=0, sample_size_v2=0, ppl=2.38, wps=264.4, ups=0.26, wpb=1010, bsz=32, num_updates=23020, lr=5.92511e-06, gnorm=12.608, clip=100, loss_scale=32, train_wall=38, gb_free=8.3, wall=88827
2023-05-21 18:38:28 - progress_bar.py[line:272] - INFO: epoch 014:    555 / 1732 loss=2.474, loss_v1=0, loss_v2=0, nll_loss=1.283, ntokens=1039.8, nsentences=32, sample_size=1039.8, sample_size_v1=0, sample_size_v2=0, ppl=2.43, wps=272.5, ups=0.26, wpb=1039.8, bsz=32, num_updates=23030, lr=5.92306e-06, gnorm=12.048, clip=100, loss_scale=32, train_wall=38, gb_free=8.6, wall=88866
2023-05-21 18:39:07 - progress_bar.py[line:272] - INFO: epoch 014:    565 / 1732 loss=2.46, loss_v1=0, loss_v2=0, nll_loss=1.268, ntokens=1014, nsentences=32, sample_size=1014, sample_size_v1=0, sample_size_v2=0, ppl=2.41, wps=263.8, ups=0.26, wpb=1014, bsz=32, num_updates=23040, lr=5.92101e-06, gnorm=12.84, clip=100, loss_scale=32, train_wall=38, gb_free=8.5, wall=88904
2023-05-21 18:39:45 - progress_bar.py[line:272] - INFO: epoch 014:    575 / 1732 loss=2.448, loss_v1=0, loss_v2=0, nll_loss=1.255, ntokens=1007.3, nsentences=32, sample_size=1007.3, sample_size_v1=0, sample_size_v2=0, ppl=2.39, wps=262, ups=0.26, wpb=1007.3, bsz=32, num_updates=23050, lr=5.91896e-06, gnorm=13.413, clip=100, loss_scale=32, train_wall=38, gb_free=8.8, wall=88942
2023-05-21 18:40:24 - progress_bar.py[line:272] - INFO: epoch 014:    585 / 1732 loss=2.461, loss_v1=0, loss_v2=0, nll_loss=1.268, ntokens=980.6, nsentences=32, sample_size=980.6, sample_size_v1=0, sample_size_v2=0, ppl=2.41, wps=254.7, ups=0.26, wpb=980.6, bsz=32, num_updates=23060, lr=5.91692e-06, gnorm=12.992, clip=100, loss_scale=64, train_wall=38, gb_free=8.8, wall=88981
2023-05-21 18:41:02 - progress_bar.py[line:272] - INFO: epoch 014:    595 / 1732 loss=2.414, loss_v1=0, loss_v2=0, nll_loss=1.216, ntokens=961.9, nsentences=32, sample_size=961.9, sample_size_v1=0, sample_size_v2=0, ppl=2.32, wps=251.6, ups=0.26, wpb=961.9, bsz=32, num_updates=23070, lr=5.91487e-06, gnorm=13.493, clip=100, loss_scale=64, train_wall=38, gb_free=8.8, wall=89019
2023-05-21 18:41:40 - progress_bar.py[line:272] - INFO: epoch 014:    605 / 1732 loss=2.419, loss_v1=0, loss_v2=0, nll_loss=1.225, ntokens=879.8, nsentences=32, sample_size=879.8, sample_size_v1=0, sample_size_v2=0, ppl=2.34, wps=233.5, ups=0.27, wpb=879.8, bsz=32, num_updates=23080, lr=5.91282e-06, gnorm=13.987, clip=100, loss_scale=64, train_wall=38, gb_free=9.3, wall=89057
2023-05-21 18:42:06 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2023-05-21 18:42:21 - progress_bar.py[line:272] - INFO: epoch 014:    616 / 1732 loss=2.458, loss_v1=0, loss_v2=0, nll_loss=1.267, ntokens=884.9, nsentences=32, sample_size=884.9, sample_size_v1=0, sample_size_v2=0, ppl=2.41, wps=212.3, ups=0.24, wpb=884.9, bsz=32, num_updates=23090, lr=5.91078e-06, gnorm=13.792, clip=100, loss_scale=32, train_wall=42, gb_free=9.4, wall=89099
2023-05-21 18:42:59 - progress_bar.py[line:272] - INFO: epoch 014:    626 / 1732 loss=2.446, loss_v1=0, loss_v2=0, nll_loss=1.251, ntokens=922.9, nsentences=32, sample_size=922.9, sample_size_v1=0, sample_size_v2=0, ppl=2.38, wps=244.2, ups=0.26, wpb=922.9, bsz=32, num_updates=23100, lr=5.90873e-06, gnorm=14.821, clip=100, loss_scale=32, train_wall=38, gb_free=8.9, wall=89136
2023-05-21 18:43:37 - progress_bar.py[line:272] - INFO: epoch 014:    636 / 1732 loss=2.454, loss_v1=0, loss_v2=0, nll_loss=1.261, ntokens=899.7, nsentences=32, sample_size=899.7, sample_size_v1=0, sample_size_v2=0, ppl=2.4, wps=237.2, ups=0.26, wpb=899.7, bsz=32, num_updates=23110, lr=5.90668e-06, gnorm=14.176, clip=100, loss_scale=32, train_wall=38, gb_free=8.6, wall=89174
2023-05-21 18:44:15 - progress_bar.py[line:272] - INFO: epoch 014:    646 / 1732 loss=2.447, loss_v1=0, loss_v2=0, nll_loss=1.254, ntokens=1003.9, nsentences=32, sample_size=1003.9, sample_size_v1=0, sample_size_v2=0, ppl=2.38, wps=264, ups=0.26, wpb=1003.9, bsz=32, num_updates=23120, lr=5.90463e-06, gnorm=12.454, clip=100, loss_scale=32, train_wall=38, gb_free=9.3, wall=89212
2023-05-21 18:44:53 - progress_bar.py[line:272] - INFO: epoch 014:    656 / 1732 loss=2.456, loss_v1=0, loss_v2=0, nll_loss=1.263, ntokens=882.2, nsentences=32, sample_size=882.2, sample_size_v1=0, sample_size_v2=0, ppl=2.4, wps=232.4, ups=0.26, wpb=882.2, bsz=32, num_updates=23130, lr=5.90259e-06, gnorm=15.351, clip=100, loss_scale=32, train_wall=38, gb_free=9.2, wall=89250
2023-05-21 18:45:31 - progress_bar.py[line:272] - INFO: epoch 014:    666 / 1732 loss=2.452, loss_v1=0, loss_v2=0, nll_loss=1.26, ntokens=902.8, nsentences=32, sample_size=902.8, sample_size_v1=0, sample_size_v2=0, ppl=2.39, wps=239.4, ups=0.27, wpb=902.8, bsz=32, num_updates=23140, lr=5.90054e-06, gnorm=14.879, clip=100, loss_scale=32, train_wall=38, gb_free=8.4, wall=89288
2023-05-21 18:46:09 - progress_bar.py[line:272] - INFO: epoch 014:    676 / 1732 loss=2.452, loss_v1=0, loss_v2=0, nll_loss=1.259, ntokens=976.1, nsentences=32, sample_size=976.1, sample_size_v1=0, sample_size_v2=0, ppl=2.39, wps=257.1, ups=0.26, wpb=976.1, bsz=32, num_updates=23150, lr=5.89849e-06, gnorm=14.808, clip=100, loss_scale=32, train_wall=38, gb_free=8.6, wall=89326
2023-05-21 18:46:47 - progress_bar.py[line:272] - INFO: epoch 014:    686 / 1732 loss=2.442, loss_v1=0, loss_v2=0, nll_loss=1.248, ntokens=963.6, nsentences=32, sample_size=963.6, sample_size_v1=0, sample_size_v2=0, ppl=2.37, wps=253.7, ups=0.26, wpb=963.6, bsz=32, num_updates=23160, lr=5.89644e-06, gnorm=14.983, clip=100, loss_scale=32, train_wall=38, gb_free=8.4, wall=89364
2023-05-21 18:47:25 - progress_bar.py[line:272] - INFO: epoch 014:    696 / 1732 loss=2.456, loss_v1=0, loss_v2=0, nll_loss=1.264, ntokens=982.5, nsentences=32, sample_size=982.5, sample_size_v1=0, sample_size_v2=0, ppl=2.4, wps=257.2, ups=0.26, wpb=982.5, bsz=32, num_updates=23170, lr=5.8944e-06, gnorm=12.919, clip=100, loss_scale=32, train_wall=38, gb_free=8.9, wall=89402
2023-05-21 18:48:03 - progress_bar.py[line:272] - INFO: epoch 014:    706 / 1732 loss=2.43, loss_v1=0, loss_v2=0, nll_loss=1.232, ntokens=918.4, nsentences=32, sample_size=918.4, sample_size_v1=0, sample_size_v2=0, ppl=2.35, wps=242.2, ups=0.26, wpb=918.4, bsz=32, num_updates=23180, lr=5.89235e-06, gnorm=14.537, clip=100, loss_scale=32, train_wall=38, gb_free=9.1, wall=89440
2023-05-21 18:48:41 - progress_bar.py[line:272] - INFO: epoch 014:    716 / 1732 loss=2.437, loss_v1=0, loss_v2=0, nll_loss=1.241, ntokens=886.1, nsentences=32, sample_size=886.1, sample_size_v1=0, sample_size_v2=0, ppl=2.36, wps=234.5, ups=0.26, wpb=886.1, bsz=32, num_updates=23190, lr=5.8903e-06, gnorm=12.992, clip=100, loss_scale=32, train_wall=38, gb_free=8.9, wall=89478
2023-05-21 18:49:18 - progress_bar.py[line:272] - INFO: epoch 014:    726 / 1732 loss=2.413, loss_v1=0, loss_v2=0, nll_loss=1.216, ntokens=913.6, nsentences=32, sample_size=913.6, sample_size_v1=0, sample_size_v2=0, ppl=2.32, wps=242, ups=0.26, wpb=913.6, bsz=32, num_updates=23200, lr=5.88825e-06, gnorm=14.057, clip=100, loss_scale=32, train_wall=38, gb_free=8.2, wall=89516
2023-05-21 18:49:56 - progress_bar.py[line:272] - INFO: epoch 014:    736 / 1732 loss=2.422, loss_v1=0, loss_v2=0, nll_loss=1.228, ntokens=979.7, nsentences=32, sample_size=979.7, sample_size_v1=0, sample_size_v2=0, ppl=2.34, wps=257.7, ups=0.26, wpb=979.7, bsz=32, num_updates=23210, lr=5.88621e-06, gnorm=12.493, clip=100, loss_scale=32, train_wall=38, gb_free=9, wall=89554
2023-05-21 18:50:35 - progress_bar.py[line:272] - INFO: epoch 014:    746 / 1732 loss=2.421, loss_v1=0, loss_v2=0, nll_loss=1.225, ntokens=974.7, nsentences=32, sample_size=974.7, sample_size_v1=0, sample_size_v2=0, ppl=2.34, wps=254.9, ups=0.26, wpb=974.7, bsz=32, num_updates=23220, lr=5.88416e-06, gnorm=12.552, clip=100, loss_scale=32, train_wall=38, gb_free=8.7, wall=89592
2023-05-21 18:51:13 - progress_bar.py[line:272] - INFO: epoch 014:    756 / 1732 loss=2.424, loss_v1=0, loss_v2=0, nll_loss=1.228, ntokens=977.2, nsentences=32, sample_size=977.2, sample_size_v1=0, sample_size_v2=0, ppl=2.34, wps=256.4, ups=0.26, wpb=977.2, bsz=32, num_updates=23230, lr=5.88211e-06, gnorm=12.785, clip=100, loss_scale=32, train_wall=38, gb_free=8.4, wall=89630
2023-05-21 18:51:51 - progress_bar.py[line:272] - INFO: epoch 014:    766 / 1732 loss=2.424, loss_v1=0, loss_v2=0, nll_loss=1.227, ntokens=933.3, nsentences=32, sample_size=933.3, sample_size_v1=0, sample_size_v2=0, ppl=2.34, wps=246, ups=0.26, wpb=933.3, bsz=32, num_updates=23240, lr=5.88006e-06, gnorm=12.257, clip=100, loss_scale=32, train_wall=38, gb_free=8.8, wall=89668
2023-05-21 18:52:29 - progress_bar.py[line:272] - INFO: epoch 014:    776 / 1732 loss=2.43, loss_v1=0, loss_v2=0, nll_loss=1.235, ntokens=1027.3, nsentences=32, sample_size=1027.3, sample_size_v1=0, sample_size_v2=0, ppl=2.35, wps=270.2, ups=0.26, wpb=1027.3, bsz=32, num_updates=23250, lr=5.87802e-06, gnorm=13.09, clip=100, loss_scale=32, train_wall=38, gb_free=8.6, wall=89706
2023-05-21 18:53:07 - progress_bar.py[line:272] - INFO: epoch 014:    786 / 1732 loss=2.44, loss_v1=0, loss_v2=0, nll_loss=1.246, ntokens=1013.1, nsentences=32, sample_size=1013.1, sample_size_v1=0, sample_size_v2=0, ppl=2.37, wps=265.3, ups=0.26, wpb=1013.1, bsz=32, num_updates=23260, lr=5.87597e-06, gnorm=12.546, clip=100, loss_scale=32, train_wall=38, gb_free=9, wall=89744
2023-05-21 18:53:45 - progress_bar.py[line:272] - INFO: epoch 014:    796 / 1732 loss=2.426, loss_v1=0, loss_v2=0, nll_loss=1.231, ntokens=1030.3, nsentences=32, sample_size=1030.3, sample_size_v1=0, sample_size_v2=0, ppl=2.35, wps=269.4, ups=0.26, wpb=1030.3, bsz=32, num_updates=23270, lr=5.87392e-06, gnorm=12.043, clip=100, loss_scale=32, train_wall=38, gb_free=8.4, wall=89782
2023-05-21 18:54:23 - progress_bar.py[line:272] - INFO: epoch 014:    806 / 1732 loss=2.432, loss_v1=0, loss_v2=0, nll_loss=1.237, ntokens=912.3, nsentences=32, sample_size=912.3, sample_size_v1=0, sample_size_v2=0, ppl=2.36, wps=241, ups=0.26, wpb=912.3, bsz=32, num_updates=23280, lr=5.87188e-06, gnorm=14.497, clip=100, loss_scale=32, train_wall=38, gb_free=9, wall=89820
2023-05-21 18:55:01 - progress_bar.py[line:272] - INFO: epoch 014:    816 / 1732 loss=2.436, loss_v1=0, loss_v2=0, nll_loss=1.241, ntokens=920, nsentences=32, sample_size=920, sample_size_v1=0, sample_size_v2=0, ppl=2.36, wps=241.8, ups=0.26, wpb=920, bsz=32, num_updates=23290, lr=5.86983e-06, gnorm=14.523, clip=100, loss_scale=32, train_wall=38, gb_free=8.2, wall=89858
2023-05-21 18:55:39 - progress_bar.py[line:272] - INFO: epoch 014:    826 / 1732 loss=2.435, loss_v1=0, loss_v2=0, nll_loss=1.239, ntokens=944.4, nsentences=32, sample_size=944.4, sample_size_v1=0, sample_size_v2=0, ppl=2.36, wps=247.6, ups=0.26, wpb=944.4, bsz=32, num_updates=23300, lr=5.86778e-06, gnorm=13.684, clip=100, loss_scale=32, train_wall=38, gb_free=8.8, wall=89896
2023-05-21 18:56:17 - progress_bar.py[line:272] - INFO: epoch 014:    836 / 1732 loss=2.435, loss_v1=0, loss_v2=0, nll_loss=1.239, ntokens=894, nsentences=32, sample_size=894, sample_size_v1=0, sample_size_v2=0, ppl=2.36, wps=236.5, ups=0.26, wpb=894, bsz=32, num_updates=23310, lr=5.86573e-06, gnorm=13.521, clip=100, loss_scale=32, train_wall=38, gb_free=9.1, wall=89934
2023-05-21 18:56:55 - progress_bar.py[line:272] - INFO: epoch 014:    846 / 1732 loss=2.404, loss_v1=0, loss_v2=0, nll_loss=1.204, ntokens=995.1, nsentences=32, sample_size=995.1, sample_size_v1=0, sample_size_v2=0, ppl=2.3, wps=261.4, ups=0.26, wpb=995.1, bsz=32, num_updates=23320, lr=5.86369e-06, gnorm=12.576, clip=100, loss_scale=32, train_wall=38, gb_free=8.8, wall=89972
2023-05-21 18:57:33 - progress_bar.py[line:272] - INFO: epoch 014:    856 / 1732 loss=2.426, loss_v1=0, loss_v2=0, nll_loss=1.231, ntokens=944.9, nsentences=32, sample_size=944.9, sample_size_v1=0, sample_size_v2=0, ppl=2.35, wps=249.1, ups=0.26, wpb=944.9, bsz=32, num_updates=23330, lr=5.86164e-06, gnorm=14.018, clip=100, loss_scale=32, train_wall=38, gb_free=8.8, wall=90010
2023-05-21 18:58:11 - progress_bar.py[line:272] - INFO: epoch 014:    866 / 1732 loss=2.449, loss_v1=0, loss_v2=0, nll_loss=1.255, ntokens=954.3, nsentences=32, sample_size=954.3, sample_size_v1=0, sample_size_v2=0, ppl=2.39, wps=251.4, ups=0.26, wpb=954.3, bsz=32, num_updates=23340, lr=5.85959e-06, gnorm=14.206, clip=100, loss_scale=32, train_wall=38, gb_free=8.6, wall=90048
2023-05-21 18:58:49 - progress_bar.py[line:272] - INFO: epoch 014:    876 / 1732 loss=2.379, loss_v1=0, loss_v2=0, nll_loss=1.176, ntokens=1023, nsentences=32, sample_size=1023, sample_size_v1=0, sample_size_v2=0, ppl=2.26, wps=266.7, ups=0.26, wpb=1023, bsz=32, num_updates=23350, lr=5.85754e-06, gnorm=11.91, clip=100, loss_scale=32, train_wall=38, gb_free=8.5, wall=90087
2023-05-21 18:59:28 - progress_bar.py[line:272] - INFO: epoch 014:    886 / 1732 loss=2.384, loss_v1=0, loss_v2=0, nll_loss=1.184, ntokens=963.8, nsentences=32, sample_size=963.8, sample_size_v1=0, sample_size_v2=0, ppl=2.27, wps=252.3, ups=0.26, wpb=963.8, bsz=32, num_updates=23360, lr=5.8555e-06, gnorm=12.766, clip=100, loss_scale=32, train_wall=38, gb_free=8.2, wall=90125
2023-05-21 19:00:06 - progress_bar.py[line:272] - INFO: epoch 014:    896 / 1732 loss=2.377, loss_v1=0, loss_v2=0, nll_loss=1.177, ntokens=1021.4, nsentences=32, sample_size=1021.4, sample_size_v1=0, sample_size_v2=0, ppl=2.26, wps=268.3, ups=0.26, wpb=1021.4, bsz=32, num_updates=23370, lr=5.85345e-06, gnorm=12.776, clip=100, loss_scale=32, train_wall=38, gb_free=8.7, wall=90163
2023-05-21 19:00:44 - progress_bar.py[line:272] - INFO: epoch 014:    906 / 1732 loss=2.38, loss_v1=0, loss_v2=0, nll_loss=1.179, ntokens=1030.5, nsentences=32, sample_size=1030.5, sample_size_v1=0, sample_size_v2=0, ppl=2.26, wps=270.5, ups=0.26, wpb=1030.5, bsz=32, num_updates=23380, lr=5.8514e-06, gnorm=12.388, clip=100, loss_scale=32, train_wall=38, gb_free=7.7, wall=90201
2023-05-21 19:01:22 - progress_bar.py[line:272] - INFO: epoch 014:    916 / 1732 loss=2.451, loss_v1=0, loss_v2=0, nll_loss=1.258, ntokens=932.7, nsentences=32, sample_size=932.7, sample_size_v1=0, sample_size_v2=0, ppl=2.39, wps=245, ups=0.26, wpb=932.7, bsz=32, num_updates=23390, lr=5.84935e-06, gnorm=14.139, clip=100, loss_scale=32, train_wall=38, gb_free=8.4, wall=90239
2023-05-21 19:02:00 - progress_bar.py[line:272] - INFO: epoch 014:    926 / 1732 loss=2.397, loss_v1=0, loss_v2=0, nll_loss=1.197, ntokens=1024.6, nsentences=32, sample_size=1024.6, sample_size_v1=0, sample_size_v2=0, ppl=2.29, wps=266.1, ups=0.26, wpb=1024.6, bsz=32, num_updates=23400, lr=5.84731e-06, gnorm=12.503, clip=100, loss_scale=32, train_wall=38, gb_free=8.5, wall=90278
2023-05-21 19:02:39 - progress_bar.py[line:272] - INFO: epoch 014:    936 / 1732 loss=2.395, loss_v1=0, loss_v2=0, nll_loss=1.194, ntokens=1056.9, nsentences=32, sample_size=1056.9, sample_size_v1=0, sample_size_v2=0, ppl=2.29, wps=273.2, ups=0.26, wpb=1056.9, bsz=32, num_updates=23410, lr=5.84526e-06, gnorm=12.996, clip=100, loss_scale=32, train_wall=39, gb_free=8.7, wall=90316
2023-05-21 19:03:18 - progress_bar.py[line:272] - INFO: epoch 014:    946 / 1732 loss=2.423, loss_v1=0, loss_v2=0, nll_loss=1.226, ntokens=1053.9, nsentences=32, sample_size=1053.9, sample_size_v1=0, sample_size_v2=0, ppl=2.34, wps=269.8, ups=0.26, wpb=1053.9, bsz=32, num_updates=23420, lr=5.84321e-06, gnorm=11.168, clip=100, loss_scale=32, train_wall=39, gb_free=8.4, wall=90355
2023-05-21 19:03:57 - progress_bar.py[line:272] - INFO: epoch 014:    956 / 1732 loss=2.406, loss_v1=0, loss_v2=0, nll_loss=1.208, ntokens=1038.8, nsentences=32, sample_size=1038.8, sample_size_v1=0, sample_size_v2=0, ppl=2.31, wps=269.1, ups=0.26, wpb=1038.8, bsz=32, num_updates=23430, lr=5.84116e-06, gnorm=12.639, clip=100, loss_scale=32, train_wall=39, gb_free=8.3, wall=90394
2023-05-21 19:04:35 - progress_bar.py[line:272] - INFO: epoch 014:    966 / 1732 loss=2.416, loss_v1=0, loss_v2=0, nll_loss=1.22, ntokens=1045.2, nsentences=32, sample_size=1045.2, sample_size_v1=0, sample_size_v2=0, ppl=2.33, wps=271.5, ups=0.26, wpb=1045.2, bsz=32, num_updates=23440, lr=5.83912e-06, gnorm=13.568, clip=100, loss_scale=32, train_wall=38, gb_free=8.7, wall=90432
2023-05-21 19:05:14 - progress_bar.py[line:272] - INFO: epoch 014:    976 / 1732 loss=2.415, loss_v1=0, loss_v2=0, nll_loss=1.22, ntokens=1030.4, nsentences=32, sample_size=1030.4, sample_size_v1=0, sample_size_v2=0, ppl=2.33, wps=266.9, ups=0.26, wpb=1030.4, bsz=32, num_updates=23450, lr=5.83707e-06, gnorm=12.287, clip=100, loss_scale=32, train_wall=39, gb_free=8.9, wall=90471
2023-05-21 19:05:53 - progress_bar.py[line:272] - INFO: epoch 014:    986 / 1732 loss=2.416, loss_v1=0, loss_v2=0, nll_loss=1.221, ntokens=1042.1, nsentences=32, sample_size=1042.1, sample_size_v1=0, sample_size_v2=0, ppl=2.33, wps=267.7, ups=0.26, wpb=1042.1, bsz=32, num_updates=23460, lr=5.83502e-06, gnorm=12.091, clip=100, loss_scale=32, train_wall=39, gb_free=7.8, wall=90510
2023-05-21 19:06:31 - progress_bar.py[line:272] - INFO: epoch 014:    996 / 1732 loss=2.404, loss_v1=0, loss_v2=0, nll_loss=1.204, ntokens=1036.4, nsentences=32, sample_size=1036.4, sample_size_v1=0, sample_size_v2=0, ppl=2.3, wps=269.6, ups=0.26, wpb=1036.4, bsz=32, num_updates=23470, lr=5.83298e-06, gnorm=12.541, clip=100, loss_scale=32, train_wall=38, gb_free=8.8, wall=90548
2023-05-21 19:07:10 - progress_bar.py[line:272] - INFO: epoch 014:   1006 / 1732 loss=2.393, loss_v1=0, loss_v2=0, nll_loss=1.191, ntokens=1007.9, nsentences=32, sample_size=1007.9, sample_size_v1=0, sample_size_v2=0, ppl=2.28, wps=262.5, ups=0.26, wpb=1007.9, bsz=32, num_updates=23480, lr=5.83093e-06, gnorm=12.368, clip=100, loss_scale=32, train_wall=38, gb_free=8.7, wall=90587
2023-05-21 19:07:48 - progress_bar.py[line:272] - INFO: epoch 014:   1016 / 1732 loss=2.408, loss_v1=0, loss_v2=0, nll_loss=1.21, ntokens=979.4, nsentences=32, sample_size=979.4, sample_size_v1=0, sample_size_v2=0, ppl=2.31, wps=255.1, ups=0.26, wpb=979.4, bsz=32, num_updates=23490, lr=5.82888e-06, gnorm=12.774, clip=100, loss_scale=32, train_wall=38, gb_free=8.5, wall=90625
2023-05-21 19:08:27 - progress_bar.py[line:272] - INFO: epoch 014:   1026 / 1732 loss=2.408, loss_v1=0, loss_v2=0, nll_loss=1.211, ntokens=1095, nsentences=32, sample_size=1095, sample_size_v1=0, sample_size_v2=0, ppl=2.31, wps=279.9, ups=0.26, wpb=1095, bsz=32, num_updates=23500, lr=5.82683e-06, gnorm=13.027, clip=100, loss_scale=32, train_wall=39, gb_free=8.5, wall=90664
2023-05-21 19:09:06 - progress_bar.py[line:272] - INFO: epoch 014:   1036 / 1732 loss=2.389, loss_v1=0, loss_v2=0, nll_loss=1.19, ntokens=1118.5, nsentences=32, sample_size=1118.5, sample_size_v1=0, sample_size_v2=0, ppl=2.28, wps=287.6, ups=0.26, wpb=1118.5, bsz=32, num_updates=23510, lr=5.82479e-06, gnorm=11.775, clip=100, loss_scale=32, train_wall=39, gb_free=8.5, wall=90703
2023-05-21 19:09:45 - progress_bar.py[line:272] - INFO: epoch 014:   1046 / 1732 loss=2.401, loss_v1=0, loss_v2=0, nll_loss=1.202, ntokens=1013.5, nsentences=32, sample_size=1013.5, sample_size_v1=0, sample_size_v2=0, ppl=2.3, wps=261.8, ups=0.26, wpb=1013.5, bsz=32, num_updates=23520, lr=5.82274e-06, gnorm=14.243, clip=100, loss_scale=32, train_wall=39, gb_free=8.9, wall=90742
2023-05-21 19:10:23 - progress_bar.py[line:272] - INFO: epoch 014:   1056 / 1732 loss=2.404, loss_v1=0, loss_v2=0, nll_loss=1.204, ntokens=1086.8, nsentences=32, sample_size=1086.8, sample_size_v1=0, sample_size_v2=0, ppl=2.3, wps=282, ups=0.26, wpb=1086.8, bsz=32, num_updates=23530, lr=5.82069e-06, gnorm=13.517, clip=100, loss_scale=32, train_wall=38, gb_free=8.3, wall=90780
2023-05-21 19:11:02 - progress_bar.py[line:272] - INFO: epoch 014:   1066 / 1732 loss=2.401, loss_v1=0, loss_v2=0, nll_loss=1.201, ntokens=1024.1, nsentences=32, sample_size=1024.1, sample_size_v1=0, sample_size_v2=0, ppl=2.3, wps=264.6, ups=0.26, wpb=1024.1, bsz=32, num_updates=23540, lr=5.81864e-06, gnorm=13.216, clip=100, loss_scale=32, train_wall=39, gb_free=8.4, wall=90819
2023-05-21 19:11:41 - progress_bar.py[line:272] - INFO: epoch 014:   1076 / 1732 loss=2.429, loss_v1=0, loss_v2=0, nll_loss=1.234, ntokens=1000.2, nsentences=32, sample_size=1000.2, sample_size_v1=0, sample_size_v2=0, ppl=2.35, wps=258.2, ups=0.26, wpb=1000.2, bsz=32, num_updates=23550, lr=5.8166e-06, gnorm=13.068, clip=100, loss_scale=32, train_wall=39, gb_free=8.6, wall=90858
2023-05-21 19:12:20 - progress_bar.py[line:272] - INFO: epoch 014:   1086 / 1732 loss=2.411, loss_v1=0, loss_v2=0, nll_loss=1.215, ntokens=1073.8, nsentences=32, sample_size=1073.8, sample_size_v1=0, sample_size_v2=0, ppl=2.32, wps=276.6, ups=0.26, wpb=1073.8, bsz=32, num_updates=23560, lr=5.81455e-06, gnorm=13.248, clip=100, loss_scale=32, train_wall=39, gb_free=8.3, wall=90897
2023-05-21 19:12:58 - progress_bar.py[line:272] - INFO: epoch 014:   1096 / 1732 loss=2.411, loss_v1=0, loss_v2=0, nll_loss=1.213, ntokens=1044.2, nsentences=32, sample_size=1044.2, sample_size_v1=0, sample_size_v2=0, ppl=2.32, wps=268.3, ups=0.26, wpb=1044.2, bsz=32, num_updates=23570, lr=5.8125e-06, gnorm=14.826, clip=100, loss_scale=32, train_wall=39, gb_free=8.2, wall=90936
2023-05-21 19:13:37 - progress_bar.py[line:272] - INFO: epoch 014:   1106 / 1732 loss=2.401, loss_v1=0, loss_v2=0, nll_loss=1.202, ntokens=1073, nsentences=32, sample_size=1073, sample_size_v1=0, sample_size_v2=0, ppl=2.3, wps=276.8, ups=0.26, wpb=1073, bsz=32, num_updates=23580, lr=5.81045e-06, gnorm=13.401, clip=100, loss_scale=32, train_wall=39, gb_free=8.3, wall=90974
2023-05-21 19:14:16 - progress_bar.py[line:272] - INFO: epoch 014:   1116 / 1732 loss=2.417, loss_v1=0, loss_v2=0, nll_loss=1.219, ntokens=936.7, nsentences=32, sample_size=936.7, sample_size_v1=0, sample_size_v2=0, ppl=2.33, wps=243.4, ups=0.26, wpb=936.7, bsz=32, num_updates=23590, lr=5.80841e-06, gnorm=13.163, clip=100, loss_scale=32, train_wall=38, gb_free=8.2, wall=91013
2023-05-21 19:14:54 - progress_bar.py[line:272] - INFO: epoch 014:   1126 / 1732 loss=2.408, loss_v1=0, loss_v2=0, nll_loss=1.21, ntokens=1021, nsentences=32, sample_size=1021, sample_size_v1=0, sample_size_v2=0, ppl=2.31, wps=264.9, ups=0.26, wpb=1021, bsz=32, num_updates=23600, lr=5.80636e-06, gnorm=14.51, clip=100, loss_scale=64, train_wall=38, gb_free=8, wall=91051
2023-05-21 19:15:10 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2023-05-21 19:15:36 - progress_bar.py[line:272] - INFO: epoch 014:   1137 / 1732 loss=2.413, loss_v1=0, loss_v2=0, nll_loss=1.216, ntokens=994.1, nsentences=32, sample_size=994.1, sample_size_v1=0, sample_size_v2=0, ppl=2.32, wps=235.5, ups=0.24, wpb=994.1, bsz=32, num_updates=23610, lr=5.80431e-06, gnorm=13.545, clip=100, loss_scale=32, train_wall=42, gb_free=8, wall=91094
2023-05-21 19:16:15 - progress_bar.py[line:272] - INFO: epoch 014:   1147 / 1732 loss=2.421, loss_v1=0, loss_v2=0, nll_loss=1.225, ntokens=1007.7, nsentences=32, sample_size=1007.7, sample_size_v1=0, sample_size_v2=0, ppl=2.34, wps=261.7, ups=0.26, wpb=1007.7, bsz=32, num_updates=23620, lr=5.80226e-06, gnorm=13.617, clip=100, loss_scale=32, train_wall=38, gb_free=8.4, wall=91132
2023-05-21 19:16:54 - progress_bar.py[line:272] - INFO: epoch 014:   1157 / 1732 loss=2.387, loss_v1=0, loss_v2=0, nll_loss=1.185, ntokens=1000.6, nsentences=32, sample_size=1000.6, sample_size_v1=0, sample_size_v2=0, ppl=2.27, wps=259.2, ups=0.26, wpb=1000.6, bsz=32, num_updates=23630, lr=5.80022e-06, gnorm=12.45, clip=100, loss_scale=32, train_wall=39, gb_free=8.9, wall=91171
2023-05-21 19:17:32 - progress_bar.py[line:272] - INFO: epoch 014:   1167 / 1732 loss=2.408, loss_v1=0, loss_v2=0, nll_loss=1.21, ntokens=1036.7, nsentences=32, sample_size=1036.7, sample_size_v1=0, sample_size_v2=0, ppl=2.31, wps=267.9, ups=0.26, wpb=1036.7, bsz=32, num_updates=23640, lr=5.79817e-06, gnorm=13.533, clip=100, loss_scale=32, train_wall=39, gb_free=8.6, wall=91209
2023-05-21 19:18:11 - progress_bar.py[line:272] - INFO: epoch 014:   1177 / 1732 loss=2.383, loss_v1=0, loss_v2=0, nll_loss=1.181, ntokens=1069.6, nsentences=32, sample_size=1069.6, sample_size_v1=0, sample_size_v2=0, ppl=2.27, wps=278, ups=0.26, wpb=1069.6, bsz=32, num_updates=23650, lr=5.79612e-06, gnorm=13.085, clip=100, loss_scale=32, train_wall=38, gb_free=9, wall=91248
2023-05-21 19:18:49 - progress_bar.py[line:272] - INFO: epoch 014:   1187 / 1732 loss=2.411, loss_v1=0, loss_v2=0, nll_loss=1.214, ntokens=953.6, nsentences=32, sample_size=953.6, sample_size_v1=0, sample_size_v2=0, ppl=2.32, wps=248.8, ups=0.26, wpb=953.6, bsz=32, num_updates=23660, lr=5.79407e-06, gnorm=14.187, clip=100, loss_scale=32, train_wall=38, gb_free=9.2, wall=91286
2023-05-21 19:19:28 - progress_bar.py[line:272] - INFO: epoch 014:   1197 / 1732 loss=2.402, loss_v1=0, loss_v2=0, nll_loss=1.203, ntokens=1116.1, nsentences=32, sample_size=1116.1, sample_size_v1=0, sample_size_v2=0, ppl=2.3, wps=288.9, ups=0.26, wpb=1116.1, bsz=32, num_updates=23670, lr=5.79203e-06, gnorm=13.706, clip=100, loss_scale=32, train_wall=39, gb_free=7.4, wall=91325
2023-05-21 19:20:07 - progress_bar.py[line:272] - INFO: epoch 014:   1207 / 1732 loss=2.374, loss_v1=0, loss_v2=0, nll_loss=1.171, ntokens=1096.1, nsentences=32, sample_size=1096.1, sample_size_v1=0, sample_size_v2=0, ppl=2.25, wps=282, ups=0.26, wpb=1096.1, bsz=32, num_updates=23680, lr=5.78998e-06, gnorm=12.041, clip=100, loss_scale=32, train_wall=39, gb_free=8.3, wall=91364
2023-05-21 19:20:45 - progress_bar.py[line:272] - INFO: epoch 014:   1217 / 1732 loss=2.421, loss_v1=0, loss_v2=0, nll_loss=1.223, ntokens=1014.3, nsentences=32, sample_size=1014.3, sample_size_v1=0, sample_size_v2=0, ppl=2.33, wps=263.1, ups=0.26, wpb=1014.3, bsz=32, num_updates=23690, lr=5.78793e-06, gnorm=13.819, clip=100, loss_scale=32, train_wall=38, gb_free=8.7, wall=91402
2023-05-21 19:21:24 - progress_bar.py[line:272] - INFO: epoch 014:   1227 / 1732 loss=2.422, loss_v1=0, loss_v2=0, nll_loss=1.224, ntokens=1027.4, nsentences=32, sample_size=1027.4, sample_size_v1=0, sample_size_v2=0, ppl=2.34, wps=266.3, ups=0.26, wpb=1027.4, bsz=32, num_updates=23700, lr=5.78589e-06, gnorm=13.057, clip=100, loss_scale=32, train_wall=39, gb_free=9.1, wall=91441
2023-05-21 19:22:02 - progress_bar.py[line:272] - INFO: epoch 014:   1237 / 1732 loss=2.375, loss_v1=0, loss_v2=0, nll_loss=1.173, ntokens=1040.4, nsentences=32, sample_size=1040.4, sample_size_v1=0, sample_size_v2=0, ppl=2.25, wps=269.4, ups=0.26, wpb=1040.4, bsz=32, num_updates=23710, lr=5.78384e-06, gnorm=12.813, clip=100, loss_scale=32, train_wall=39, gb_free=8.6, wall=91480
2023-05-21 19:22:41 - progress_bar.py[line:272] - INFO: epoch 014:   1247 / 1732 loss=2.352, loss_v1=0, loss_v2=0, nll_loss=1.148, ntokens=1124.4, nsentences=32, sample_size=1124.4, sample_size_v1=0, sample_size_v2=0, ppl=2.22, wps=289.3, ups=0.26, wpb=1124.4, bsz=32, num_updates=23720, lr=5.78179e-06, gnorm=12.485, clip=100, loss_scale=32, train_wall=39, gb_free=8.7, wall=91518
2023-05-21 19:23:20 - progress_bar.py[line:272] - INFO: epoch 014:   1257 / 1732 loss=2.377, loss_v1=0, loss_v2=0, nll_loss=1.175, ntokens=1053.7, nsentences=32, sample_size=1053.7, sample_size_v1=0, sample_size_v2=0, ppl=2.26, wps=274.1, ups=0.26, wpb=1053.7, bsz=32, num_updates=23730, lr=5.77974e-06, gnorm=12.549, clip=100, loss_scale=32, train_wall=38, gb_free=8.7, wall=91557
2023-05-21 19:23:59 - progress_bar.py[line:272] - INFO: epoch 014:   1267 / 1732 loss=2.411, loss_v1=0, loss_v2=0, nll_loss=1.213, ntokens=1037.3, nsentences=32, sample_size=1037.3, sample_size_v1=0, sample_size_v2=0, ppl=2.32, wps=267.2, ups=0.26, wpb=1037.3, bsz=32, num_updates=23740, lr=5.7777e-06, gnorm=13.223, clip=100, loss_scale=32, train_wall=39, gb_free=8.6, wall=91596
2023-05-21 19:24:37 - progress_bar.py[line:272] - INFO: epoch 014:   1277 / 1732 loss=2.412, loss_v1=0, loss_v2=0, nll_loss=1.216, ntokens=1060.8, nsentences=32, sample_size=1060.8, sample_size_v1=0, sample_size_v2=0, ppl=2.32, wps=273.1, ups=0.26, wpb=1060.8, bsz=32, num_updates=23750, lr=5.77565e-06, gnorm=13.223, clip=100, loss_scale=32, train_wall=39, gb_free=7.9, wall=91635
2023-05-21 19:25:16 - progress_bar.py[line:272] - INFO: epoch 014:   1287 / 1732 loss=2.386, loss_v1=0, loss_v2=0, nll_loss=1.184, ntokens=1057.7, nsentences=32, sample_size=1057.7, sample_size_v1=0, sample_size_v2=0, ppl=2.27, wps=272.2, ups=0.26, wpb=1057.7, bsz=32, num_updates=23760, lr=5.7736e-06, gnorm=12.737, clip=100, loss_scale=32, train_wall=39, gb_free=8.2, wall=91673
2023-05-21 19:25:55 - progress_bar.py[line:272] - INFO: epoch 014:   1297 / 1732 loss=2.38, loss_v1=0, loss_v2=0, nll_loss=1.179, ntokens=1105.1, nsentences=32, sample_size=1105.1, sample_size_v1=0, sample_size_v2=0, ppl=2.26, wps=284.4, ups=0.26, wpb=1105.1, bsz=32, num_updates=23770, lr=5.77155e-06, gnorm=12.641, clip=100, loss_scale=32, train_wall=39, gb_free=8.7, wall=91712
2023-05-21 19:26:34 - progress_bar.py[line:272] - INFO: epoch 014:   1307 / 1732 loss=2.419, loss_v1=0, loss_v2=0, nll_loss=1.222, ntokens=1096.7, nsentences=32, sample_size=1096.7, sample_size_v1=0, sample_size_v2=0, ppl=2.33, wps=280.2, ups=0.26, wpb=1096.7, bsz=32, num_updates=23780, lr=5.76951e-06, gnorm=13.413, clip=100, loss_scale=32, train_wall=39, gb_free=8.4, wall=91751
2023-05-21 19:27:13 - progress_bar.py[line:272] - INFO: epoch 014:   1317 / 1732 loss=2.404, loss_v1=0, loss_v2=0, nll_loss=1.205, ntokens=1048.7, nsentences=32, sample_size=1048.7, sample_size_v1=0, sample_size_v2=0, ppl=2.3, wps=270.2, ups=0.26, wpb=1048.7, bsz=32, num_updates=23790, lr=5.76746e-06, gnorm=13.684, clip=100, loss_scale=32, train_wall=39, gb_free=8.7, wall=91790
2023-05-21 19:27:52 - progress_bar.py[line:272] - INFO: epoch 014:   1327 / 1732 loss=2.38, loss_v1=0, loss_v2=0, nll_loss=1.179, ntokens=1124.5, nsentences=32, sample_size=1124.5, sample_size_v1=0, sample_size_v2=0, ppl=2.26, wps=286.8, ups=0.26, wpb=1124.5, bsz=32, num_updates=23800, lr=5.76541e-06, gnorm=12.978, clip=100, loss_scale=32, train_wall=39, gb_free=8.4, wall=91829
2023-05-21 19:28:31 - progress_bar.py[line:272] - INFO: epoch 014:   1337 / 1732 loss=2.369, loss_v1=0, loss_v2=0, nll_loss=1.166, ntokens=1126.2, nsentences=32, sample_size=1126.2, sample_size_v1=0, sample_size_v2=0, ppl=2.24, wps=289.3, ups=0.26, wpb=1126.2, bsz=32, num_updates=23810, lr=5.76336e-06, gnorm=13.907, clip=100, loss_scale=32, train_wall=39, gb_free=8.6, wall=91868
2023-05-21 19:29:10 - progress_bar.py[line:272] - INFO: epoch 014:   1347 / 1732 loss=2.386, loss_v1=0, loss_v2=0, nll_loss=1.186, ntokens=1159.1, nsentences=32, sample_size=1159.1, sample_size_v1=0, sample_size_v2=0, ppl=2.28, wps=297, ups=0.26, wpb=1159.1, bsz=32, num_updates=23820, lr=5.76132e-06, gnorm=12.154, clip=100, loss_scale=32, train_wall=39, gb_free=8.9, wall=91907
2023-05-21 19:29:49 - progress_bar.py[line:272] - INFO: epoch 014:   1357 / 1732 loss=2.363, loss_v1=0, loss_v2=0, nll_loss=1.158, ntokens=1146.3, nsentences=32, sample_size=1146.3, sample_size_v1=0, sample_size_v2=0, ppl=2.23, wps=294.3, ups=0.26, wpb=1146.3, bsz=32, num_updates=23830, lr=5.75927e-06, gnorm=12.488, clip=100, loss_scale=32, train_wall=39, gb_free=8, wall=91946
2023-05-21 19:30:28 - progress_bar.py[line:272] - INFO: epoch 014:   1367 / 1732 loss=2.388, loss_v1=0, loss_v2=0, nll_loss=1.186, ntokens=1081.6, nsentences=32, sample_size=1081.6, sample_size_v1=0, sample_size_v2=0, ppl=2.28, wps=279, ups=0.26, wpb=1081.6, bsz=32, num_updates=23840, lr=5.75722e-06, gnorm=12.514, clip=100, loss_scale=32, train_wall=39, gb_free=8.5, wall=91985
2023-05-21 19:31:07 - progress_bar.py[line:272] - INFO: epoch 014:   1377 / 1732 loss=2.42, loss_v1=0, loss_v2=0, nll_loss=1.223, ntokens=1107.3, nsentences=32, sample_size=1107.3, sample_size_v1=0, sample_size_v2=0, ppl=2.33, wps=286.7, ups=0.26, wpb=1107.3, bsz=32, num_updates=23850, lr=5.75517e-06, gnorm=13.127, clip=100, loss_scale=32, train_wall=39, gb_free=8.7, wall=92024
2023-05-21 19:31:45 - progress_bar.py[line:272] - INFO: epoch 014:   1387 / 1732 loss=2.383, loss_v1=0, loss_v2=0, nll_loss=1.183, ntokens=1152.6, nsentences=32, sample_size=1152.6, sample_size_v1=0, sample_size_v2=0, ppl=2.27, wps=296.6, ups=0.26, wpb=1152.6, bsz=32, num_updates=23860, lr=5.75313e-06, gnorm=12.73, clip=100, loss_scale=32, train_wall=39, gb_free=8.6, wall=92063
2023-05-21 19:32:24 - progress_bar.py[line:272] - INFO: epoch 014:   1397 / 1732 loss=2.391, loss_v1=0, loss_v2=0, nll_loss=1.191, ntokens=1066.5, nsentences=32, sample_size=1066.5, sample_size_v1=0, sample_size_v2=0, ppl=2.28, wps=274.2, ups=0.26, wpb=1066.5, bsz=32, num_updates=23870, lr=5.75108e-06, gnorm=13.923, clip=100, loss_scale=32, train_wall=39, gb_free=8.2, wall=92102
2023-05-21 19:33:03 - progress_bar.py[line:272] - INFO: epoch 014:   1407 / 1732 loss=2.394, loss_v1=0, loss_v2=0, nll_loss=1.193, ntokens=1152.8, nsentences=32, sample_size=1152.8, sample_size_v1=0, sample_size_v2=0, ppl=2.29, wps=296.1, ups=0.26, wpb=1152.8, bsz=32, num_updates=23880, lr=5.74903e-06, gnorm=12.044, clip=100, loss_scale=32, train_wall=39, gb_free=8.4, wall=92140
2023-05-21 19:33:43 - progress_bar.py[line:272] - INFO: epoch 014:   1417 / 1732 loss=2.408, loss_v1=0, loss_v2=0, nll_loss=1.21, ntokens=1290.7, nsentences=32, sample_size=1290.7, sample_size_v1=0, sample_size_v2=0, ppl=2.31, wps=328.7, ups=0.25, wpb=1290.7, bsz=32, num_updates=23890, lr=5.74699e-06, gnorm=11.198, clip=100, loss_scale=32, train_wall=39, gb_free=8, wall=92180
2023-05-21 19:34:22 - progress_bar.py[line:272] - INFO: epoch 014:   1427 / 1732 loss=2.364, loss_v1=0, loss_v2=0, nll_loss=1.16, ntokens=1220.7, nsentences=32, sample_size=1220.7, sample_size_v1=0, sample_size_v2=0, ppl=2.23, wps=312.7, ups=0.26, wpb=1220.7, bsz=32, num_updates=23900, lr=5.74494e-06, gnorm=11.833, clip=100, loss_scale=32, train_wall=39, gb_free=8.8, wall=92219
2023-05-21 19:35:00 - progress_bar.py[line:272] - INFO: epoch 014:   1437 / 1732 loss=2.376, loss_v1=0, loss_v2=0, nll_loss=1.175, ntokens=1217.2, nsentences=32, sample_size=1217.2, sample_size_v1=0, sample_size_v2=0, ppl=2.26, wps=313.6, ups=0.26, wpb=1217.2, bsz=32, num_updates=23910, lr=5.74289e-06, gnorm=11.164, clip=100, loss_scale=32, train_wall=39, gb_free=6.5, wall=92258
2023-05-21 19:35:39 - progress_bar.py[line:272] - INFO: epoch 014:   1447 / 1732 loss=2.406, loss_v1=0, loss_v2=0, nll_loss=1.208, ntokens=1115.7, nsentences=32, sample_size=1115.7, sample_size_v1=0, sample_size_v2=0, ppl=2.31, wps=289.1, ups=0.26, wpb=1115.7, bsz=32, num_updates=23920, lr=5.74084e-06, gnorm=11.992, clip=100, loss_scale=32, train_wall=39, gb_free=8.8, wall=92296
2023-05-21 19:36:18 - progress_bar.py[line:272] - INFO: epoch 014:   1457 / 1732 loss=2.398, loss_v1=0, loss_v2=0, nll_loss=1.2, ntokens=1111.8, nsentences=32, sample_size=1111.8, sample_size_v1=0, sample_size_v2=0, ppl=2.3, wps=285.7, ups=0.26, wpb=1111.8, bsz=32, num_updates=23930, lr=5.7388e-06, gnorm=12.312, clip=100, loss_scale=32, train_wall=39, gb_free=7.7, wall=92335
2023-05-21 19:36:57 - progress_bar.py[line:272] - INFO: epoch 014:   1467 / 1732 loss=2.348, loss_v1=0, loss_v2=0, nll_loss=1.142, ntokens=1202.5, nsentences=32, sample_size=1202.5, sample_size_v1=0, sample_size_v2=0, ppl=2.21, wps=308.8, ups=0.26, wpb=1202.5, bsz=32, num_updates=23940, lr=5.73675e-06, gnorm=12.636, clip=100, loss_scale=32, train_wall=39, gb_free=8.5, wall=92374
2023-05-21 19:37:35 - progress_bar.py[line:272] - INFO: epoch 014:   1477 / 1732 loss=2.413, loss_v1=0, loss_v2=0, nll_loss=1.215, ntokens=1052.1, nsentences=32, sample_size=1052.1, sample_size_v1=0, sample_size_v2=0, ppl=2.32, wps=272.5, ups=0.26, wpb=1052.1, bsz=32, num_updates=23950, lr=5.7347e-06, gnorm=13.549, clip=100, loss_scale=32, train_wall=39, gb_free=7.8, wall=92413
2023-05-21 19:38:14 - progress_bar.py[line:272] - INFO: epoch 014:   1487 / 1732 loss=2.403, loss_v1=0, loss_v2=0, nll_loss=1.203, ntokens=1147.5, nsentences=32, sample_size=1147.5, sample_size_v1=0, sample_size_v2=0, ppl=2.3, wps=295, ups=0.26, wpb=1147.5, bsz=32, num_updates=23960, lr=5.73265e-06, gnorm=11.196, clip=100, loss_scale=32, train_wall=39, gb_free=8, wall=92452
2023-05-21 19:38:53 - progress_bar.py[line:272] - INFO: epoch 014:   1497 / 1732 loss=2.375, loss_v1=0, loss_v2=0, nll_loss=1.173, ntokens=1083.9, nsentences=32, sample_size=1083.9, sample_size_v1=0, sample_size_v2=0, ppl=2.25, wps=279.4, ups=0.26, wpb=1083.9, bsz=32, num_updates=23970, lr=5.73061e-06, gnorm=11.763, clip=100, loss_scale=32, train_wall=39, gb_free=8.4, wall=92490
2023-05-21 19:39:32 - progress_bar.py[line:272] - INFO: epoch 014:   1507 / 1732 loss=2.333, loss_v1=0, loss_v2=0, nll_loss=1.126, ntokens=1112.5, nsentences=32, sample_size=1112.5, sample_size_v1=0, sample_size_v2=0, ppl=2.18, wps=288.4, ups=0.26, wpb=1112.5, bsz=32, num_updates=23980, lr=5.72856e-06, gnorm=13.093, clip=100, loss_scale=32, train_wall=39, gb_free=8.3, wall=92529
2023-05-21 19:40:10 - progress_bar.py[line:272] - INFO: epoch 014:   1517 / 1732 loss=2.411, loss_v1=0, loss_v2=0, nll_loss=1.215, ntokens=1063, nsentences=32, sample_size=1063, sample_size_v1=0, sample_size_v2=0, ppl=2.32, wps=275.8, ups=0.26, wpb=1063, bsz=32, num_updates=23990, lr=5.72651e-06, gnorm=12.452, clip=100, loss_scale=32, train_wall=39, gb_free=7.8, wall=92568
2023-05-21 19:40:49 - progress_bar.py[line:272] - INFO: epoch 014:   1527 / 1732 loss=2.434, loss_v1=0, loss_v2=0, nll_loss=1.24, ntokens=1062.3, nsentences=32, sample_size=1062.3, sample_size_v1=0, sample_size_v2=0, ppl=2.36, wps=275.5, ups=0.26, wpb=1062.3, bsz=32, num_updates=24000, lr=5.72446e-06, gnorm=13.72, clip=100, loss_scale=32, train_wall=39, gb_free=8.3, wall=92606
2023-05-21 19:41:28 - progress_bar.py[line:272] - INFO: epoch 014:   1537 / 1732 loss=2.384, loss_v1=0, loss_v2=0, nll_loss=1.181, ntokens=1067, nsentences=32, sample_size=1067, sample_size_v1=0, sample_size_v2=0, ppl=2.27, wps=271.6, ups=0.25, wpb=1067, bsz=32, num_updates=24010, lr=5.72242e-06, gnorm=14.807, clip=100, loss_scale=32, train_wall=39, gb_free=7.7, wall=92645
2023-05-21 19:42:07 - progress_bar.py[line:272] - INFO: epoch 014:   1547 / 1732 loss=2.368, loss_v1=0, loss_v2=0, nll_loss=1.163, ntokens=1093.5, nsentences=32, sample_size=1093.5, sample_size_v1=0, sample_size_v2=0, ppl=2.24, wps=283.1, ups=0.26, wpb=1093.5, bsz=32, num_updates=24020, lr=5.72037e-06, gnorm=11.814, clip=100, loss_scale=32, train_wall=39, gb_free=8.4, wall=92684
2023-05-21 19:42:45 - progress_bar.py[line:272] - INFO: epoch 014:   1557 / 1732 loss=2.381, loss_v1=0, loss_v2=0, nll_loss=1.181, ntokens=1051.1, nsentences=32, sample_size=1051.1, sample_size_v1=0, sample_size_v2=0, ppl=2.27, wps=272, ups=0.26, wpb=1051.1, bsz=32, num_updates=24030, lr=5.71832e-06, gnorm=12.442, clip=100, loss_scale=32, train_wall=39, gb_free=8.3, wall=92723
2023-05-21 19:43:24 - progress_bar.py[line:272] - INFO: epoch 014:   1567 / 1732 loss=2.427, loss_v1=0, loss_v2=0, nll_loss=1.231, ntokens=1097.1, nsentences=32, sample_size=1097.1, sample_size_v1=0, sample_size_v2=0, ppl=2.35, wps=282.8, ups=0.26, wpb=1097.1, bsz=32, num_updates=24040, lr=5.71627e-06, gnorm=13.606, clip=100, loss_scale=32, train_wall=39, gb_free=7.5, wall=92761
2023-05-21 19:44:03 - progress_bar.py[line:272] - INFO: epoch 014:   1577 / 1732 loss=2.432, loss_v1=0, loss_v2=0, nll_loss=1.236, ntokens=1002.1, nsentences=32, sample_size=1002.1, sample_size_v1=0, sample_size_v2=0, ppl=2.36, wps=258.1, ups=0.26, wpb=1002.1, bsz=32, num_updates=24050, lr=5.71423e-06, gnorm=14.492, clip=100, loss_scale=32, train_wall=39, gb_free=8.7, wall=92800
2023-05-21 19:44:42 - progress_bar.py[line:272] - INFO: epoch 014:   1587 / 1732 loss=2.397, loss_v1=0, loss_v2=0, nll_loss=1.197, ntokens=1081.3, nsentences=32, sample_size=1081.3, sample_size_v1=0, sample_size_v2=0, ppl=2.29, wps=276.9, ups=0.26, wpb=1081.3, bsz=32, num_updates=24060, lr=5.71218e-06, gnorm=12.69, clip=100, loss_scale=32, train_wall=39, gb_free=7.9, wall=92839
2023-05-21 19:45:21 - progress_bar.py[line:272] - INFO: epoch 014:   1597 / 1732 loss=2.37, loss_v1=0, loss_v2=0, nll_loss=1.169, ntokens=1084.4, nsentences=32, sample_size=1084.4, sample_size_v1=0, sample_size_v2=0, ppl=2.25, wps=279, ups=0.26, wpb=1084.4, bsz=32, num_updates=24070, lr=5.71013e-06, gnorm=12.382, clip=100, loss_scale=32, train_wall=39, gb_free=8, wall=92878
2023-05-21 19:46:00 - progress_bar.py[line:272] - INFO: epoch 014:   1607 / 1732 loss=2.377, loss_v1=0, loss_v2=0, nll_loss=1.176, ntokens=1122.8, nsentences=32, sample_size=1122.8, sample_size_v1=0, sample_size_v2=0, ppl=2.26, wps=288.6, ups=0.26, wpb=1122.8, bsz=32, num_updates=24080, lr=5.70809e-06, gnorm=12.809, clip=100, loss_scale=32, train_wall=39, gb_free=8, wall=92917
2023-05-21 19:46:39 - progress_bar.py[line:272] - INFO: epoch 014:   1617 / 1732 loss=2.347, loss_v1=0, loss_v2=0, nll_loss=1.141, ntokens=1114.5, nsentences=32, sample_size=1114.5, sample_size_v1=0, sample_size_v2=0, ppl=2.21, wps=286.2, ups=0.26, wpb=1114.5, bsz=32, num_updates=24090, lr=5.70604e-06, gnorm=11.699, clip=100, loss_scale=32, train_wall=39, gb_free=8.4, wall=92956
2023-05-21 19:47:18 - progress_bar.py[line:272] - INFO: epoch 014:   1627 / 1732 loss=2.377, loss_v1=0, loss_v2=0, nll_loss=1.177, ntokens=1162.3, nsentences=32, sample_size=1162.3, sample_size_v1=0, sample_size_v2=0, ppl=2.26, wps=298.8, ups=0.26, wpb=1162.3, bsz=32, num_updates=24100, lr=5.70399e-06, gnorm=12.423, clip=100, loss_scale=32, train_wall=39, gb_free=8.3, wall=92995
2023-05-21 19:47:56 - progress_bar.py[line:272] - INFO: epoch 014:   1637 / 1732 loss=2.36, loss_v1=0, loss_v2=0, nll_loss=1.157, ntokens=1115.7, nsentences=32, sample_size=1115.7, sample_size_v1=0, sample_size_v2=0, ppl=2.23, wps=288.2, ups=0.26, wpb=1115.7, bsz=32, num_updates=24110, lr=5.70194e-06, gnorm=12.951, clip=100, loss_scale=32, train_wall=39, gb_free=8.6, wall=93034
2023-05-21 19:48:36 - progress_bar.py[line:272] - INFO: epoch 014:   1647 / 1732 loss=2.339, loss_v1=0, loss_v2=0, nll_loss=1.132, ntokens=1285, nsentences=32, sample_size=1285, sample_size_v1=0, sample_size_v2=0, ppl=2.19, wps=327.3, ups=0.25, wpb=1285, bsz=32, num_updates=24120, lr=5.6999e-06, gnorm=10.161, clip=100, loss_scale=64, train_wall=39, gb_free=8.2, wall=93073
2023-05-21 19:49:14 - progress_bar.py[line:272] - INFO: epoch 014:   1657 / 1732 loss=2.42, loss_v1=0, loss_v2=0, nll_loss=1.222, ntokens=952, nsentences=32, sample_size=952, sample_size_v1=0, sample_size_v2=0, ppl=2.33, wps=248.3, ups=0.26, wpb=952, bsz=32, num_updates=24130, lr=5.69785e-06, gnorm=14.01, clip=100, loss_scale=64, train_wall=38, gb_free=8.4, wall=93111
2023-05-21 19:49:53 - progress_bar.py[line:272] - INFO: epoch 014:   1667 / 1732 loss=2.39, loss_v1=0, loss_v2=0, nll_loss=1.189, ntokens=1028.1, nsentences=32, sample_size=1028.1, sample_size_v1=0, sample_size_v2=0, ppl=2.28, wps=265.3, ups=0.26, wpb=1028.1, bsz=32, num_updates=24140, lr=5.6958e-06, gnorm=12.576, clip=100, loss_scale=64, train_wall=39, gb_free=8.5, wall=93150
2023-05-21 19:50:32 - progress_bar.py[line:272] - INFO: epoch 014:   1677 / 1732 loss=2.341, loss_v1=0, loss_v2=0, nll_loss=1.134, ntokens=1135.4, nsentences=32, sample_size=1135.4, sample_size_v1=0, sample_size_v2=0, ppl=2.19, wps=290.1, ups=0.26, wpb=1135.4, bsz=32, num_updates=24150, lr=5.69375e-06, gnorm=12.512, clip=100, loss_scale=64, train_wall=39, gb_free=7.4, wall=93189
2023-05-21 19:51:11 - progress_bar.py[line:272] - INFO: epoch 014:   1687 / 1732 loss=2.359, loss_v1=0, loss_v2=0, nll_loss=1.154, ntokens=1154.5, nsentences=32, sample_size=1154.5, sample_size_v1=0, sample_size_v2=0, ppl=2.22, wps=295.6, ups=0.26, wpb=1154.5, bsz=32, num_updates=24160, lr=5.69171e-06, gnorm=12.08, clip=100, loss_scale=64, train_wall=39, gb_free=7, wall=93228
2023-05-21 19:51:51 - progress_bar.py[line:272] - INFO: epoch 014:   1697 / 1732 loss=2.366, loss_v1=0, loss_v2=0, nll_loss=1.164, ntokens=1302.5, nsentences=32, sample_size=1302.5, sample_size_v1=0, sample_size_v2=0, ppl=2.24, wps=328.3, ups=0.25, wpb=1302.5, bsz=32, num_updates=24170, lr=5.68966e-06, gnorm=11.128, clip=100, loss_scale=64, train_wall=40, gb_free=8, wall=93268
2023-05-21 19:52:30 - progress_bar.py[line:272] - INFO: epoch 014:   1707 / 1732 loss=2.37, loss_v1=0, loss_v2=0, nll_loss=1.17, ntokens=1171.1, nsentences=32, sample_size=1171.1, sample_size_v1=0, sample_size_v2=0, ppl=2.25, wps=298.6, ups=0.26, wpb=1171.1, bsz=32, num_updates=24180, lr=5.68761e-06, gnorm=11.811, clip=100, loss_scale=64, train_wall=39, gb_free=8.5, wall=93307
2023-05-21 19:53:09 - progress_bar.py[line:272] - INFO: epoch 014:   1717 / 1732 loss=2.36, loss_v1=0, loss_v2=0, nll_loss=1.157, ntokens=1206.1, nsentences=32, sample_size=1206.1, sample_size_v1=0, sample_size_v2=0, ppl=2.23, wps=306.8, ups=0.25, wpb=1206.1, bsz=32, num_updates=24190, lr=5.68556e-06, gnorm=11.425, clip=100, loss_scale=64, train_wall=39, gb_free=8.3, wall=93346
2023-05-21 19:53:48 - progress_bar.py[line:272] - INFO: epoch 014:   1727 / 1732 loss=2.409, loss_v1=0, loss_v2=0, nll_loss=1.21, ntokens=1102.3, nsentences=32, sample_size=1102.3, sample_size_v1=0, sample_size_v2=0, ppl=2.31, wps=282.4, ups=0.26, wpb=1102.3, bsz=32, num_updates=24200, lr=5.68352e-06, gnorm=12.08, clip=100, loss_scale=64, train_wall=39, gb_free=8.8, wall=93385
2023-05-21 19:54:00 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2023-05-21 19:54:05 - train.py[line:332] - INFO: end of epoch 14 (average epoch stats below)
2023-05-21 19:54:05 - progress_bar.py[line:282] - INFO: epoch 014 | loss 2.392 | loss_v1 0 | loss_v2 0 | nll_loss 1.192 | ntokens 1051.44 | nsentences 31.986 | sample_size 1051.44 | sample_size_v1 0 | sample_size_v2 0 | ppl 2.28 | wps 272 | ups 0.26 | wpb 1051.4 | bsz 32 | num_updates 24204 | lr 5.6827e-06 | gnorm 12.549 | clip 100 | loss_scale 32 | train_wall 6669 | gb_free 8.9 | wall 93402
2023-05-21 19:54:05 - trainer.py[line:639] - INFO: loading train data for epoch 15
local datafile ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 0 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 0 finished initializing row_count and line_idx-to-offset mapping
file ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 0 row count 55400 total row count 55400
slice_id 0 seek offset 0
2023-05-21 19:54:07 - trainer.py[line:703] - INFO: begin training epoch 15
2023-05-21 19:54:07 - train.py[line:305] - INFO: Start iterating over samples
2023-05-21 19:54:30 - progress_bar.py[line:272] - INFO: epoch 015:      6 / 1732 loss=2.342, loss_v1=0, loss_v2=0, nll_loss=1.135, ntokens=1059.8, nsentences=29.6, sample_size=1059.8, sample_size_v1=0, sample_size_v2=0, ppl=2.2, wps=252.4, ups=0.24, wpb=1059.8, bsz=29.6, num_updates=24210, lr=5.68147e-06, gnorm=13.995, clip=100, loss_scale=32, train_wall=40, gb_free=8.4, wall=93427
2023-05-21 19:55:09 - progress_bar.py[line:272] - INFO: epoch 015:     16 / 1732 loss=2.316, loss_v1=0, loss_v2=0, nll_loss=1.105, ntokens=1099.3, nsentences=32, sample_size=1099.3, sample_size_v1=0, sample_size_v2=0, ppl=2.15, wps=283.7, ups=0.26, wpb=1099.3, bsz=32, num_updates=24220, lr=5.67942e-06, gnorm=13.493, clip=100, loss_scale=32, train_wall=39, gb_free=8.3, wall=93466
2023-05-21 19:55:48 - progress_bar.py[line:272] - INFO: epoch 015:     26 / 1732 loss=2.321, loss_v1=0, loss_v2=0, nll_loss=1.112, ntokens=973, nsentences=32, sample_size=973, sample_size_v1=0, sample_size_v2=0, ppl=2.16, wps=250.6, ups=0.26, wpb=973, bsz=32, num_updates=24230, lr=5.67737e-06, gnorm=12.98, clip=100, loss_scale=32, train_wall=39, gb_free=8.6, wall=93505
2023-05-21 19:56:27 - progress_bar.py[line:272] - INFO: epoch 015:     36 / 1732 loss=2.188, loss_v1=0, loss_v2=0, nll_loss=0.962, ntokens=1153.4, nsentences=32, sample_size=1153.4, sample_size_v1=0, sample_size_v2=0, ppl=1.95, wps=294.2, ups=0.26, wpb=1153.4, bsz=32, num_updates=24240, lr=5.67533e-06, gnorm=10.432, clip=100, loss_scale=32, train_wall=39, gb_free=7.4, wall=93544
2023-05-21 19:57:06 - progress_bar.py[line:272] - INFO: epoch 015:     46 / 1732 loss=2.198, loss_v1=0, loss_v2=0, nll_loss=0.982, ntokens=1066.8, nsentences=32, sample_size=1066.8, sample_size_v1=0, sample_size_v2=0, ppl=1.98, wps=275.4, ups=0.26, wpb=1066.8, bsz=32, num_updates=24250, lr=5.67328e-06, gnorm=12.475, clip=100, loss_scale=32, train_wall=39, gb_free=8.8, wall=93583
2023-05-21 19:57:45 - progress_bar.py[line:272] - INFO: epoch 015:     56 / 1732 loss=2.141, loss_v1=0, loss_v2=0, nll_loss=0.91, ntokens=1077, nsentences=32, sample_size=1077, sample_size_v1=0, sample_size_v2=0, ppl=1.88, wps=276.6, ups=0.26, wpb=1077, bsz=32, num_updates=24260, lr=5.67123e-06, gnorm=10.764, clip=100, loss_scale=32, train_wall=39, gb_free=8.7, wall=93622
2023-05-21 19:58:24 - progress_bar.py[line:272] - INFO: epoch 015:     66 / 1732 loss=2.018, loss_v1=0, loss_v2=0, nll_loss=0.775, ntokens=1294.5, nsentences=32, sample_size=1294.5, sample_size_v1=0, sample_size_v2=0, ppl=1.71, wps=326.4, ups=0.25, wpb=1294.5, bsz=32, num_updates=24270, lr=5.66918e-06, gnorm=7.379, clip=100, loss_scale=32, train_wall=40, gb_free=7.5, wall=93662
2023-05-21 19:59:04 - progress_bar.py[line:272] - INFO: epoch 015:     76 / 1732 loss=2.147, loss_v1=0, loss_v2=0, nll_loss=0.921, ntokens=1343.5, nsentences=32, sample_size=1343.5, sample_size_v1=0, sample_size_v2=0, ppl=1.89, wps=335.8, ups=0.25, wpb=1343.5, bsz=32, num_updates=24280, lr=5.66714e-06, gnorm=10.845, clip=100, loss_scale=32, train_wall=40, gb_free=7.1, wall=93702
2023-05-21 19:59:44 - progress_bar.py[line:272] - INFO: epoch 015:     86 / 1732 loss=2.225, loss_v1=0, loss_v2=0, nll_loss=1.002, ntokens=1107.4, nsentences=32, sample_size=1107.4, sample_size_v1=0, sample_size_v2=0, ppl=2, wps=280.2, ups=0.25, wpb=1107.4, bsz=32, num_updates=24290, lr=5.66509e-06, gnorm=11.919, clip=100, loss_scale=32, train_wall=39, gb_free=7.9, wall=93741
2023-05-21 20:00:23 - progress_bar.py[line:272] - INFO: epoch 015:     96 / 1732 loss=2.184, loss_v1=0, loss_v2=0, nll_loss=0.959, ntokens=1069.5, nsentences=32, sample_size=1069.5, sample_size_v1=0, sample_size_v2=0, ppl=1.94, wps=275.3, ups=0.26, wpb=1069.5, bsz=32, num_updates=24300, lr=5.66304e-06, gnorm=11.974, clip=100, loss_scale=32, train_wall=39, gb_free=7.5, wall=93780
2023-05-21 20:01:01 - progress_bar.py[line:272] - INFO: epoch 015:    106 / 1732 loss=2.355, loss_v1=0, loss_v2=0, nll_loss=1.152, ntokens=998.2, nsentences=32, sample_size=998.2, sample_size_v1=0, sample_size_v2=0, ppl=2.22, wps=258.4, ups=0.26, wpb=998.2, bsz=32, num_updates=24310, lr=5.661e-06, gnorm=14.436, clip=100, loss_scale=32, train_wall=39, gb_free=7.3, wall=93819
2023-05-21 20:01:40 - progress_bar.py[line:272] - INFO: epoch 015:    116 / 1732 loss=2.405, loss_v1=0, loss_v2=0, nll_loss=1.208, ntokens=1049.3, nsentences=32, sample_size=1049.3, sample_size_v1=0, sample_size_v2=0, ppl=2.31, wps=270.4, ups=0.26, wpb=1049.3, bsz=32, num_updates=24320, lr=5.65895e-06, gnorm=12.858, clip=100, loss_scale=32, train_wall=39, gb_free=7.6, wall=93857
2023-05-21 20:02:20 - progress_bar.py[line:272] - INFO: epoch 015:    126 / 1732 loss=2.328, loss_v1=0, loss_v2=0, nll_loss=1.12, ntokens=1187.5, nsentences=32, sample_size=1187.5, sample_size_v1=0, sample_size_v2=0, ppl=2.17, wps=299.7, ups=0.25, wpb=1187.5, bsz=32, num_updates=24330, lr=5.6569e-06, gnorm=12.563, clip=100, loss_scale=32, train_wall=40, gb_free=8.4, wall=93897
2023-05-21 20:02:59 - progress_bar.py[line:272] - INFO: epoch 015:    136 / 1732 loss=2.315, loss_v1=0, loss_v2=0, nll_loss=1.106, ntokens=1228, nsentences=32, sample_size=1228, sample_size_v1=0, sample_size_v2=0, ppl=2.15, wps=312.4, ups=0.25, wpb=1228, bsz=32, num_updates=24340, lr=5.65485e-06, gnorm=10.018, clip=100, loss_scale=32, train_wall=39, gb_free=7.4, wall=93936
2023-05-21 20:03:39 - progress_bar.py[line:272] - INFO: epoch 015:    146 / 1732 loss=2.272, loss_v1=0, loss_v2=0, nll_loss=1.057, ntokens=1192.9, nsentences=32, sample_size=1192.9, sample_size_v1=0, sample_size_v2=0, ppl=2.08, wps=301.8, ups=0.25, wpb=1192.9, bsz=32, num_updates=24350, lr=5.65281e-06, gnorm=9.469, clip=100, loss_scale=32, train_wall=39, gb_free=7.7, wall=93976
2023-05-21 20:04:18 - progress_bar.py[line:272] - INFO: epoch 015:    156 / 1732 loss=2.317, loss_v1=0, loss_v2=0, nll_loss=1.11, ntokens=1174.3, nsentences=32, sample_size=1174.3, sample_size_v1=0, sample_size_v2=0, ppl=2.16, wps=295.4, ups=0.25, wpb=1174.3, bsz=32, num_updates=24360, lr=5.65076e-06, gnorm=10.031, clip=100, loss_scale=32, train_wall=40, gb_free=8, wall=94016
2023-05-21 20:04:57 - progress_bar.py[line:272] - INFO: epoch 015:    166 / 1732 loss=2.28, loss_v1=0, loss_v2=0, nll_loss=1.068, ntokens=1039.2, nsentences=32, sample_size=1039.2, sample_size_v1=0, sample_size_v2=0, ppl=2.1, wps=266.7, ups=0.26, wpb=1039.2, bsz=32, num_updates=24370, lr=5.64871e-06, gnorm=11.602, clip=100, loss_scale=32, train_wall=39, gb_free=7.4, wall=94055
2023-05-21 20:05:36 - progress_bar.py[line:272] - INFO: epoch 015:    176 / 1732 loss=2.304, loss_v1=0, loss_v2=0, nll_loss=1.092, ntokens=982.6, nsentences=32, sample_size=982.6, sample_size_v1=0, sample_size_v2=0, ppl=2.13, wps=253.1, ups=0.26, wpb=982.6, bsz=32, num_updates=24380, lr=5.64666e-06, gnorm=13.083, clip=100, loss_scale=32, train_wall=39, gb_free=7.9, wall=94093
2023-05-21 20:06:16 - progress_bar.py[line:272] - INFO: epoch 015:    186 / 1732 loss=2.246, loss_v1=0, loss_v2=0, nll_loss=1.027, ntokens=1142, nsentences=32, sample_size=1142, sample_size_v1=0, sample_size_v2=0, ppl=2.04, wps=289.9, ups=0.25, wpb=1142, bsz=32, num_updates=24390, lr=5.64462e-06, gnorm=10.71, clip=100, loss_scale=32, train_wall=39, gb_free=8.2, wall=94133
2023-05-21 20:06:55 - progress_bar.py[line:272] - INFO: epoch 015:    196 / 1732 loss=2.309, loss_v1=0, loss_v2=0, nll_loss=1.099, ntokens=1152.2, nsentences=32, sample_size=1152.2, sample_size_v1=0, sample_size_v2=0, ppl=2.14, wps=292.7, ups=0.25, wpb=1152.2, bsz=32, num_updates=24400, lr=5.64257e-06, gnorm=10.828, clip=100, loss_scale=32, train_wall=39, gb_free=8.2, wall=94172
2023-05-21 20:07:33 - progress_bar.py[line:272] - INFO: epoch 015:    206 / 1732 loss=2.397, loss_v1=0, loss_v2=0, nll_loss=1.2, ntokens=995.3, nsentences=32, sample_size=995.3, sample_size_v1=0, sample_size_v2=0, ppl=2.3, wps=260, ups=0.26, wpb=995.3, bsz=32, num_updates=24410, lr=5.64052e-06, gnorm=13.47, clip=100, loss_scale=32, train_wall=38, gb_free=8.5, wall=94211
2023-05-21 20:08:12 - progress_bar.py[line:272] - INFO: epoch 015:    216 / 1732 loss=2.413, loss_v1=0, loss_v2=0, nll_loss=1.217, ntokens=1119.9, nsentences=32, sample_size=1119.9, sample_size_v1=0, sample_size_v2=0, ppl=2.32, wps=290.5, ups=0.26, wpb=1119.9, bsz=32, num_updates=24420, lr=5.63847e-06, gnorm=10.765, clip=100, loss_scale=32, train_wall=39, gb_free=8.9, wall=94249
2023-05-21 20:08:51 - progress_bar.py[line:272] - INFO: epoch 015:    226 / 1732 loss=2.401, loss_v1=0, loss_v2=0, nll_loss=1.202, ntokens=1111.6, nsentences=32, sample_size=1111.6, sample_size_v1=0, sample_size_v2=0, ppl=2.3, wps=287.4, ups=0.26, wpb=1111.6, bsz=32, num_updates=24430, lr=5.63643e-06, gnorm=11.63, clip=100, loss_scale=32, train_wall=39, gb_free=8.7, wall=94288
2023-05-21 20:09:29 - progress_bar.py[line:272] - INFO: epoch 015:    236 / 1732 loss=2.458, loss_v1=0, loss_v2=0, nll_loss=1.266, ntokens=1076.5, nsentences=32, sample_size=1076.5, sample_size_v1=0, sample_size_v2=0, ppl=2.4, wps=279.8, ups=0.26, wpb=1076.5, bsz=32, num_updates=24440, lr=5.63438e-06, gnorm=11.8, clip=100, loss_scale=32, train_wall=38, gb_free=8.6, wall=94326
2023-05-21 20:10:08 - progress_bar.py[line:272] - INFO: epoch 015:    246 / 1732 loss=2.434, loss_v1=0, loss_v2=0, nll_loss=1.236, ntokens=1166.2, nsentences=32, sample_size=1166.2, sample_size_v1=0, sample_size_v2=0, ppl=2.36, wps=302, ups=0.26, wpb=1166.2, bsz=32, num_updates=24450, lr=5.63233e-06, gnorm=11.935, clip=100, loss_scale=32, train_wall=39, gb_free=8.9, wall=94365
2023-05-21 20:10:46 - progress_bar.py[line:272] - INFO: epoch 015:    256 / 1732 loss=2.425, loss_v1=0, loss_v2=0, nll_loss=1.228, ntokens=1137.6, nsentences=32, sample_size=1137.6, sample_size_v1=0, sample_size_v2=0, ppl=2.34, wps=295.8, ups=0.26, wpb=1137.6, bsz=32, num_updates=24460, lr=5.63028e-06, gnorm=11.965, clip=100, loss_scale=32, train_wall=38, gb_free=8.5, wall=94403
2023-05-21 20:11:25 - progress_bar.py[line:272] - INFO: epoch 015:    266 / 1732 loss=2.432, loss_v1=0, loss_v2=0, nll_loss=1.235, ntokens=1142, nsentences=32, sample_size=1142, sample_size_v1=0, sample_size_v2=0, ppl=2.35, wps=297, ups=0.26, wpb=1142, bsz=32, num_updates=24470, lr=5.62824e-06, gnorm=11.459, clip=100, loss_scale=32, train_wall=38, gb_free=7.6, wall=94442
2023-05-21 20:12:03 - progress_bar.py[line:272] - INFO: epoch 015:    276 / 1732 loss=2.421, loss_v1=0, loss_v2=0, nll_loss=1.224, ntokens=1142.5, nsentences=32, sample_size=1142.5, sample_size_v1=0, sample_size_v2=0, ppl=2.34, wps=297.2, ups=0.26, wpb=1142.5, bsz=32, num_updates=24480, lr=5.62619e-06, gnorm=11.101, clip=100, loss_scale=32, train_wall=38, gb_free=8, wall=94480
2023-05-21 20:12:41 - progress_bar.py[line:272] - INFO: epoch 015:    286 / 1732 loss=2.426, loss_v1=0, loss_v2=0, nll_loss=1.231, ntokens=1155.8, nsentences=32, sample_size=1155.8, sample_size_v1=0, sample_size_v2=0, ppl=2.35, wps=300.5, ups=0.26, wpb=1155.8, bsz=32, num_updates=24490, lr=5.62414e-06, gnorm=12.832, clip=100, loss_scale=32, train_wall=38, gb_free=8.4, wall=94519
2023-05-21 20:13:20 - progress_bar.py[line:272] - INFO: epoch 015:    296 / 1732 loss=2.412, loss_v1=0, loss_v2=0, nll_loss=1.214, ntokens=1134.4, nsentences=32, sample_size=1134.4, sample_size_v1=0, sample_size_v2=0, ppl=2.32, wps=294.8, ups=0.26, wpb=1134.4, bsz=32, num_updates=24500, lr=5.6221e-06, gnorm=11.755, clip=100, loss_scale=32, train_wall=38, gb_free=8.2, wall=94557
2023-05-21 20:13:58 - progress_bar.py[line:272] - INFO: epoch 015:    306 / 1732 loss=2.398, loss_v1=0, loss_v2=0, nll_loss=1.198, ntokens=1078.8, nsentences=32, sample_size=1078.8, sample_size_v1=0, sample_size_v2=0, ppl=2.29, wps=280.2, ups=0.26, wpb=1078.8, bsz=32, num_updates=24510, lr=5.62005e-06, gnorm=12.709, clip=100, loss_scale=32, train_wall=38, gb_free=8.1, wall=94596
2023-05-21 20:14:37 - progress_bar.py[line:272] - INFO: epoch 015:    316 / 1732 loss=2.433, loss_v1=0, loss_v2=0, nll_loss=1.238, ntokens=1033.6, nsentences=32, sample_size=1033.6, sample_size_v1=0, sample_size_v2=0, ppl=2.36, wps=269.3, ups=0.26, wpb=1033.6, bsz=32, num_updates=24520, lr=5.618e-06, gnorm=12.467, clip=100, loss_scale=32, train_wall=38, gb_free=7.9, wall=94634
2023-05-21 20:15:15 - progress_bar.py[line:272] - INFO: epoch 015:    326 / 1732 loss=2.447, loss_v1=0, loss_v2=0, nll_loss=1.253, ntokens=1006.1, nsentences=32, sample_size=1006.1, sample_size_v1=0, sample_size_v2=0, ppl=2.38, wps=263.5, ups=0.26, wpb=1006.1, bsz=32, num_updates=24530, lr=5.61595e-06, gnorm=12.745, clip=100, loss_scale=32, train_wall=38, gb_free=8.8, wall=94672
2023-05-21 20:15:53 - progress_bar.py[line:272] - INFO: epoch 015:    336 / 1732 loss=2.423, loss_v1=0, loss_v2=0, nll_loss=1.227, ntokens=1005.9, nsentences=32, sample_size=1005.9, sample_size_v1=0, sample_size_v2=0, ppl=2.34, wps=262.6, ups=0.26, wpb=1005.9, bsz=32, num_updates=24540, lr=5.61391e-06, gnorm=13.023, clip=100, loss_scale=32, train_wall=38, gb_free=8.6, wall=94711
2023-05-21 20:16:31 - progress_bar.py[line:272] - INFO: epoch 015:    346 / 1732 loss=2.412, loss_v1=0, loss_v2=0, nll_loss=1.215, ntokens=909.3, nsentences=32, sample_size=909.3, sample_size_v1=0, sample_size_v2=0, ppl=2.32, wps=239.3, ups=0.26, wpb=909.3, bsz=32, num_updates=24550, lr=5.61186e-06, gnorm=13.492, clip=100, loss_scale=32, train_wall=38, gb_free=8.6, wall=94749
2023-05-21 20:17:09 - progress_bar.py[line:272] - INFO: epoch 015:    356 / 1732 loss=2.447, loss_v1=0, loss_v2=0, nll_loss=1.253, ntokens=955.2, nsentences=32, sample_size=955.2, sample_size_v1=0, sample_size_v2=0, ppl=2.38, wps=252.3, ups=0.26, wpb=955.2, bsz=32, num_updates=24560, lr=5.60981e-06, gnorm=13.699, clip=100, loss_scale=32, train_wall=38, gb_free=9.1, wall=94786
2023-05-21 20:17:47 - progress_bar.py[line:272] - INFO: epoch 015:    366 / 1732 loss=2.464, loss_v1=0, loss_v2=0, nll_loss=1.273, ntokens=951.9, nsentences=32, sample_size=951.9, sample_size_v1=0, sample_size_v2=0, ppl=2.42, wps=251.6, ups=0.26, wpb=951.9, bsz=32, num_updates=24570, lr=5.60776e-06, gnorm=13.943, clip=100, loss_scale=32, train_wall=38, gb_free=8.9, wall=94824
2023-05-21 20:18:25 - progress_bar.py[line:272] - INFO: epoch 015:    376 / 1732 loss=2.465, loss_v1=0, loss_v2=0, nll_loss=1.272, ntokens=1015.4, nsentences=32, sample_size=1015.4, sample_size_v1=0, sample_size_v2=0, ppl=2.42, wps=264.8, ups=0.26, wpb=1015.4, bsz=32, num_updates=24580, lr=5.60572e-06, gnorm=13.147, clip=100, loss_scale=32, train_wall=38, gb_free=8.7, wall=94863
2023-05-21 20:19:04 - progress_bar.py[line:272] - INFO: epoch 015:    386 / 1732 loss=2.44, loss_v1=0, loss_v2=0, nll_loss=1.244, ntokens=1063.1, nsentences=32, sample_size=1063.1, sample_size_v1=0, sample_size_v2=0, ppl=2.37, wps=278.4, ups=0.26, wpb=1063.1, bsz=32, num_updates=24590, lr=5.60367e-06, gnorm=12.93, clip=100, loss_scale=32, train_wall=38, gb_free=8.6, wall=94901
2023-05-21 20:19:41 - progress_bar.py[line:272] - INFO: epoch 015:    396 / 1732 loss=2.427, loss_v1=0, loss_v2=0, nll_loss=1.23, ntokens=950.2, nsentences=32, sample_size=950.2, sample_size_v1=0, sample_size_v2=0, ppl=2.35, wps=250.7, ups=0.26, wpb=950.2, bsz=32, num_updates=24600, lr=5.60162e-06, gnorm=14.284, clip=100, loss_scale=32, train_wall=38, gb_free=8.1, wall=94939
2023-05-21 20:20:20 - progress_bar.py[line:272] - INFO: epoch 015:    406 / 1732 loss=2.413, loss_v1=0, loss_v2=0, nll_loss=1.214, ntokens=1066.6, nsentences=32, sample_size=1066.6, sample_size_v1=0, sample_size_v2=0, ppl=2.32, wps=279.2, ups=0.26, wpb=1066.6, bsz=32, num_updates=24610, lr=5.59957e-06, gnorm=12.663, clip=100, loss_scale=32, train_wall=38, gb_free=8.4, wall=94977
2023-05-21 20:20:58 - progress_bar.py[line:272] - INFO: epoch 015:    416 / 1732 loss=2.411, loss_v1=0, loss_v2=0, nll_loss=1.213, ntokens=1055.1, nsentences=32, sample_size=1055.1, sample_size_v1=0, sample_size_v2=0, ppl=2.32, wps=276.1, ups=0.26, wpb=1055.1, bsz=32, num_updates=24620, lr=5.59753e-06, gnorm=12.822, clip=100, loss_scale=32, train_wall=38, gb_free=8.7, wall=95015
2023-05-21 20:21:36 - progress_bar.py[line:272] - INFO: epoch 015:    426 / 1732 loss=2.393, loss_v1=0, loss_v2=0, nll_loss=1.194, ntokens=988.1, nsentences=32, sample_size=988.1, sample_size_v1=0, sample_size_v2=0, ppl=2.29, wps=259.1, ups=0.26, wpb=988.1, bsz=32, num_updates=24630, lr=5.59548e-06, gnorm=13.271, clip=100, loss_scale=32, train_wall=38, gb_free=8.1, wall=95053
2023-05-21 20:22:14 - progress_bar.py[line:272] - INFO: epoch 015:    436 / 1732 loss=2.432, loss_v1=0, loss_v2=0, nll_loss=1.237, ntokens=1044.5, nsentences=32, sample_size=1044.5, sample_size_v1=0, sample_size_v2=0, ppl=2.36, wps=274.5, ups=0.26, wpb=1044.5, bsz=32, num_updates=24640, lr=5.59343e-06, gnorm=13.677, clip=100, loss_scale=32, train_wall=38, gb_free=8.2, wall=95091
2023-05-21 20:22:52 - progress_bar.py[line:272] - INFO: epoch 015:    446 / 1732 loss=2.446, loss_v1=0, loss_v2=0, nll_loss=1.252, ntokens=952.9, nsentences=32, sample_size=952.9, sample_size_v1=0, sample_size_v2=0, ppl=2.38, wps=250.2, ups=0.26, wpb=952.9, bsz=32, num_updates=24650, lr=5.59138e-06, gnorm=13.518, clip=100, loss_scale=32, train_wall=38, gb_free=8, wall=95129
2023-05-21 20:23:30 - progress_bar.py[line:272] - INFO: epoch 015:    456 / 1732 loss=2.438, loss_v1=0, loss_v2=0, nll_loss=1.244, ntokens=925.5, nsentences=32, sample_size=925.5, sample_size_v1=0, sample_size_v2=0, ppl=2.37, wps=244.3, ups=0.26, wpb=925.5, bsz=32, num_updates=24660, lr=5.58934e-06, gnorm=15.637, clip=100, loss_scale=32, train_wall=38, gb_free=8.8, wall=95167
2023-05-21 20:24:08 - progress_bar.py[line:272] - INFO: epoch 015:    466 / 1732 loss=2.454, loss_v1=0, loss_v2=0, nll_loss=1.259, ntokens=1063.6, nsentences=32, sample_size=1063.6, sample_size_v1=0, sample_size_v2=0, ppl=2.39, wps=277, ups=0.26, wpb=1063.6, bsz=32, num_updates=24670, lr=5.58729e-06, gnorm=12.624, clip=100, loss_scale=32, train_wall=38, gb_free=8.7, wall=95206
2023-05-21 20:24:47 - progress_bar.py[line:272] - INFO: epoch 015:    476 / 1732 loss=2.459, loss_v1=0, loss_v2=0, nll_loss=1.264, ntokens=1057.9, nsentences=32, sample_size=1057.9, sample_size_v1=0, sample_size_v2=0, ppl=2.4, wps=274.4, ups=0.26, wpb=1057.9, bsz=32, num_updates=24680, lr=5.58524e-06, gnorm=12.163, clip=100, loss_scale=32, train_wall=39, gb_free=8.6, wall=95244
2023-05-21 20:25:25 - progress_bar.py[line:272] - INFO: epoch 015:    486 / 1732 loss=2.416, loss_v1=0, loss_v2=0, nll_loss=1.219, ntokens=966.1, nsentences=32, sample_size=966.1, sample_size_v1=0, sample_size_v2=0, ppl=2.33, wps=254.3, ups=0.26, wpb=966.1, bsz=32, num_updates=24690, lr=5.5832e-06, gnorm=13.168, clip=100, loss_scale=32, train_wall=38, gb_free=8.4, wall=95282
2023-05-21 20:26:03 - progress_bar.py[line:272] - INFO: epoch 015:    496 / 1732 loss=2.424, loss_v1=0, loss_v2=0, nll_loss=1.229, ntokens=932.2, nsentences=32, sample_size=932.2, sample_size_v1=0, sample_size_v2=0, ppl=2.34, wps=245.7, ups=0.26, wpb=932.2, bsz=32, num_updates=24700, lr=5.58115e-06, gnorm=14.427, clip=100, loss_scale=32, train_wall=38, gb_free=8.9, wall=95320
2023-05-21 20:26:41 - progress_bar.py[line:272] - INFO: epoch 015:    506 / 1732 loss=2.443, loss_v1=0, loss_v2=0, nll_loss=1.249, ntokens=994.9, nsentences=32, sample_size=994.9, sample_size_v1=0, sample_size_v2=0, ppl=2.38, wps=262.7, ups=0.26, wpb=994.9, bsz=32, num_updates=24710, lr=5.5791e-06, gnorm=13.33, clip=100, loss_scale=32, train_wall=38, gb_free=8.3, wall=95358
2023-05-21 20:27:19 - progress_bar.py[line:272] - INFO: epoch 015:    516 / 1732 loss=2.436, loss_v1=0, loss_v2=0, nll_loss=1.24, ntokens=1062.8, nsentences=32, sample_size=1062.8, sample_size_v1=0, sample_size_v2=0, ppl=2.36, wps=278.8, ups=0.26, wpb=1062.8, bsz=32, num_updates=24720, lr=5.57705e-06, gnorm=12.086, clip=100, loss_scale=64, train_wall=38, gb_free=8.8, wall=95396
2023-05-21 20:27:46 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2023-05-21 20:28:01 - progress_bar.py[line:272] - INFO: epoch 015:    527 / 1732 loss=2.426, loss_v1=0, loss_v2=0, nll_loss=1.231, ntokens=935, nsentences=32, sample_size=935, sample_size_v1=0, sample_size_v2=0, ppl=2.35, wps=223.5, ups=0.24, wpb=935, bsz=32, num_updates=24730, lr=5.57501e-06, gnorm=15.105, clip=100, loss_scale=32, train_wall=42, gb_free=9.1, wall=95438
2023-05-21 20:28:39 - progress_bar.py[line:272] - INFO: epoch 015:    537 / 1732 loss=2.417, loss_v1=0, loss_v2=0, nll_loss=1.22, ntokens=964.7, nsentences=32, sample_size=964.7, sample_size_v1=0, sample_size_v2=0, ppl=2.33, wps=255.8, ups=0.27, wpb=964.7, bsz=32, num_updates=24740, lr=5.57296e-06, gnorm=14.787, clip=100, loss_scale=32, train_wall=38, gb_free=9, wall=95476
2023-05-21 20:29:16 - progress_bar.py[line:272] - INFO: epoch 015:    547 / 1732 loss=2.446, loss_v1=0, loss_v2=0, nll_loss=1.252, ntokens=1033.6, nsentences=32, sample_size=1033.6, sample_size_v1=0, sample_size_v2=0, ppl=2.38, wps=272.2, ups=0.26, wpb=1033.6, bsz=32, num_updates=24750, lr=5.57091e-06, gnorm=13.771, clip=100, loss_scale=32, train_wall=38, gb_free=8.4, wall=95514
2023-05-21 20:29:54 - progress_bar.py[line:272] - INFO: epoch 015:    557 / 1732 loss=2.462, loss_v1=0, loss_v2=0, nll_loss=1.27, ntokens=1010.2, nsentences=32, sample_size=1010.2, sample_size_v1=0, sample_size_v2=0, ppl=2.41, wps=266.7, ups=0.26, wpb=1010.2, bsz=32, num_updates=24760, lr=5.56886e-06, gnorm=13.041, clip=100, loss_scale=32, train_wall=38, gb_free=8.9, wall=95552
2023-05-21 20:30:33 - progress_bar.py[line:272] - INFO: epoch 015:    567 / 1732 loss=2.475, loss_v1=0, loss_v2=0, nll_loss=1.285, ntokens=1004.9, nsentences=32, sample_size=1004.9, sample_size_v1=0, sample_size_v2=0, ppl=2.44, wps=263.3, ups=0.26, wpb=1004.9, bsz=32, num_updates=24770, lr=5.56682e-06, gnorm=14.185, clip=100, loss_scale=32, train_wall=38, gb_free=8.9, wall=95590
2023-05-21 20:31:11 - progress_bar.py[line:272] - INFO: epoch 015:    577 / 1732 loss=2.437, loss_v1=0, loss_v2=0, nll_loss=1.242, ntokens=1011.7, nsentences=32, sample_size=1011.7, sample_size_v1=0, sample_size_v2=0, ppl=2.37, wps=264, ups=0.26, wpb=1011.7, bsz=32, num_updates=24780, lr=5.56477e-06, gnorm=13.749, clip=100, loss_scale=32, train_wall=38, gb_free=8.9, wall=95628
2023-05-21 20:31:49 - progress_bar.py[line:272] - INFO: epoch 015:    587 / 1732 loss=2.45, loss_v1=0, loss_v2=0, nll_loss=1.256, ntokens=962.2, nsentences=32, sample_size=962.2, sample_size_v1=0, sample_size_v2=0, ppl=2.39, wps=251.6, ups=0.26, wpb=962.2, bsz=32, num_updates=24790, lr=5.56272e-06, gnorm=14.679, clip=100, loss_scale=32, train_wall=38, gb_free=9.3, wall=95666
2023-05-21 20:32:27 - progress_bar.py[line:272] - INFO: epoch 015:    597 / 1732 loss=2.392, loss_v1=0, loss_v2=0, nll_loss=1.191, ntokens=975.4, nsentences=32, sample_size=975.4, sample_size_v1=0, sample_size_v2=0, ppl=2.28, wps=254.4, ups=0.26, wpb=975.4, bsz=32, num_updates=24800, lr=5.56067e-06, gnorm=14.372, clip=100, loss_scale=32, train_wall=38, gb_free=8.6, wall=95705
2023-05-21 20:33:05 - progress_bar.py[line:272] - INFO: epoch 015:    607 / 1732 loss=2.441, loss_v1=0, loss_v2=0, nll_loss=1.249, ntokens=882.8, nsentences=32, sample_size=882.8, sample_size_v1=0, sample_size_v2=0, ppl=2.38, wps=232.5, ups=0.26, wpb=882.8, bsz=32, num_updates=24810, lr=5.55863e-06, gnorm=14.462, clip=100, loss_scale=32, train_wall=38, gb_free=8.1, wall=95743
2023-05-21 20:33:43 - progress_bar.py[line:272] - INFO: epoch 015:    617 / 1732 loss=2.446, loss_v1=0, loss_v2=0, nll_loss=1.253, ntokens=866.1, nsentences=32, sample_size=866.1, sample_size_v1=0, sample_size_v2=0, ppl=2.38, wps=229, ups=0.26, wpb=866.1, bsz=32, num_updates=24820, lr=5.55658e-06, gnorm=15.782, clip=100, loss_scale=32, train_wall=38, gb_free=8.7, wall=95780
2023-05-21 20:34:21 - progress_bar.py[line:272] - INFO: epoch 015:    627 / 1732 loss=2.435, loss_v1=0, loss_v2=0, nll_loss=1.239, ntokens=930.6, nsentences=32, sample_size=930.6, sample_size_v1=0, sample_size_v2=0, ppl=2.36, wps=245.8, ups=0.26, wpb=930.6, bsz=32, num_updates=24830, lr=5.55453e-06, gnorm=15.392, clip=100, loss_scale=32, train_wall=38, gb_free=9.1, wall=95818
2023-05-21 20:34:59 - progress_bar.py[line:272] - INFO: epoch 015:    637 / 1732 loss=2.449, loss_v1=0, loss_v2=0, nll_loss=1.256, ntokens=914.3, nsentences=32, sample_size=914.3, sample_size_v1=0, sample_size_v2=0, ppl=2.39, wps=241.1, ups=0.26, wpb=914.3, bsz=32, num_updates=24840, lr=5.55248e-06, gnorm=16.519, clip=100, loss_scale=32, train_wall=38, gb_free=8.8, wall=95856
2023-05-21 20:35:37 - progress_bar.py[line:272] - INFO: epoch 015:    647 / 1732 loss=2.447, loss_v1=0, loss_v2=0, nll_loss=1.253, ntokens=980.8, nsentences=32, sample_size=980.8, sample_size_v1=0, sample_size_v2=0, ppl=2.38, wps=258.5, ups=0.26, wpb=980.8, bsz=32, num_updates=24850, lr=5.55044e-06, gnorm=14.803, clip=100, loss_scale=32, train_wall=38, gb_free=9, wall=95894
2023-05-21 20:36:15 - progress_bar.py[line:272] - INFO: epoch 015:    657 / 1732 loss=2.456, loss_v1=0, loss_v2=0, nll_loss=1.263, ntokens=894.4, nsentences=32, sample_size=894.4, sample_size_v1=0, sample_size_v2=0, ppl=2.4, wps=238.1, ups=0.27, wpb=894.4, bsz=32, num_updates=24860, lr=5.54839e-06, gnorm=15.018, clip=100, loss_scale=32, train_wall=38, gb_free=8.8, wall=95932
2023-05-21 20:36:53 - progress_bar.py[line:272] - INFO: epoch 015:    667 / 1732 loss=2.438, loss_v1=0, loss_v2=0, nll_loss=1.244, ntokens=903.9, nsentences=32, sample_size=903.9, sample_size_v1=0, sample_size_v2=0, ppl=2.37, wps=238, ups=0.26, wpb=903.9, bsz=32, num_updates=24870, lr=5.54634e-06, gnorm=15.485, clip=100, loss_scale=32, train_wall=38, gb_free=8.7, wall=95970
2023-05-21 20:37:31 - progress_bar.py[line:272] - INFO: epoch 015:    677 / 1732 loss=2.435, loss_v1=0, loss_v2=0, nll_loss=1.241, ntokens=985.3, nsentences=32, sample_size=985.3, sample_size_v1=0, sample_size_v2=0, ppl=2.36, wps=258.6, ups=0.26, wpb=985.3, bsz=32, num_updates=24880, lr=5.54429e-06, gnorm=14.677, clip=100, loss_scale=32, train_wall=38, gb_free=9, wall=96008
2023-05-21 20:38:09 - progress_bar.py[line:272] - INFO: epoch 015:    687 / 1732 loss=2.455, loss_v1=0, loss_v2=0, nll_loss=1.262, ntokens=943.2, nsentences=32, sample_size=943.2, sample_size_v1=0, sample_size_v2=0, ppl=2.4, wps=248, ups=0.26, wpb=943.2, bsz=32, num_updates=24890, lr=5.54225e-06, gnorm=14.738, clip=100, loss_scale=32, train_wall=38, gb_free=9.2, wall=96046
2023-05-21 20:38:47 - progress_bar.py[line:272] - INFO: epoch 015:    697 / 1732 loss=2.438, loss_v1=0, loss_v2=0, nll_loss=1.243, ntokens=1005.6, nsentences=32, sample_size=1005.6, sample_size_v1=0, sample_size_v2=0, ppl=2.37, wps=262.6, ups=0.26, wpb=1005.6, bsz=32, num_updates=24900, lr=5.5402e-06, gnorm=12.922, clip=100, loss_scale=32, train_wall=38, gb_free=8, wall=96084
2023-05-21 20:39:25 - progress_bar.py[line:272] - INFO: epoch 015:    707 / 1732 loss=2.436, loss_v1=0, loss_v2=0, nll_loss=1.239, ntokens=903.4, nsentences=32, sample_size=903.4, sample_size_v1=0, sample_size_v2=0, ppl=2.36, wps=238.3, ups=0.26, wpb=903.4, bsz=32, num_updates=24910, lr=5.53815e-06, gnorm=14.631, clip=100, loss_scale=32, train_wall=38, gb_free=9.1, wall=96122
2023-05-21 20:40:03 - progress_bar.py[line:272] - INFO: epoch 015:    717 / 1732 loss=2.431, loss_v1=0, loss_v2=0, nll_loss=1.233, ntokens=882.7, nsentences=32, sample_size=882.7, sample_size_v1=0, sample_size_v2=0, ppl=2.35, wps=233, ups=0.26, wpb=882.7, bsz=32, num_updates=24920, lr=5.53611e-06, gnorm=14.828, clip=100, loss_scale=32, train_wall=38, gb_free=8.8, wall=96160
2023-05-21 20:40:41 - progress_bar.py[line:272] - INFO: epoch 015:    727 / 1732 loss=2.417, loss_v1=0, loss_v2=0, nll_loss=1.22, ntokens=909.8, nsentences=32, sample_size=909.8, sample_size_v1=0, sample_size_v2=0, ppl=2.33, wps=240, ups=0.26, wpb=909.8, bsz=32, num_updates=24930, lr=5.53406e-06, gnorm=15.53, clip=100, loss_scale=32, train_wall=38, gb_free=9.2, wall=96198
2023-05-21 20:41:19 - progress_bar.py[line:272] - INFO: epoch 015:    737 / 1732 loss=2.418, loss_v1=0, loss_v2=0, nll_loss=1.223, ntokens=998.8, nsentences=32, sample_size=998.8, sample_size_v1=0, sample_size_v2=0, ppl=2.33, wps=262.4, ups=0.26, wpb=998.8, bsz=32, num_updates=24940, lr=5.53201e-06, gnorm=13.88, clip=100, loss_scale=32, train_wall=38, gb_free=8.6, wall=96236
2023-05-21 20:41:57 - progress_bar.py[line:272] - INFO: epoch 015:    747 / 1732 loss=2.414, loss_v1=0, loss_v2=0, nll_loss=1.219, ntokens=980.5, nsentences=32, sample_size=980.5, sample_size_v1=0, sample_size_v2=0, ppl=2.33, wps=256.7, ups=0.26, wpb=980.5, bsz=32, num_updates=24950, lr=5.52996e-06, gnorm=13.853, clip=100, loss_scale=32, train_wall=38, gb_free=8.3, wall=96274
2023-05-21 20:42:35 - progress_bar.py[line:272] - INFO: epoch 015:    757 / 1732 loss=2.425, loss_v1=0, loss_v2=0, nll_loss=1.229, ntokens=949.2, nsentences=32, sample_size=949.2, sample_size_v1=0, sample_size_v2=0, ppl=2.34, wps=249.1, ups=0.26, wpb=949.2, bsz=32, num_updates=24960, lr=5.52792e-06, gnorm=14.058, clip=100, loss_scale=32, train_wall=38, gb_free=8.8, wall=96312
2023-05-21 20:43:13 - progress_bar.py[line:272] - INFO: epoch 015:    767 / 1732 loss=2.422, loss_v1=0, loss_v2=0, nll_loss=1.226, ntokens=941.7, nsentences=32, sample_size=941.7, sample_size_v1=0, sample_size_v2=0, ppl=2.34, wps=247.7, ups=0.26, wpb=941.7, bsz=32, num_updates=24970, lr=5.52587e-06, gnorm=14.224, clip=100, loss_scale=32, train_wall=38, gb_free=9.2, wall=96350
2023-05-21 20:43:51 - progress_bar.py[line:272] - INFO: epoch 015:    777 / 1732 loss=2.432, loss_v1=0, loss_v2=0, nll_loss=1.237, ntokens=1028.6, nsentences=32, sample_size=1028.6, sample_size_v1=0, sample_size_v2=0, ppl=2.36, wps=268.9, ups=0.26, wpb=1028.6, bsz=32, num_updates=24980, lr=5.52382e-06, gnorm=14.592, clip=100, loss_scale=32, train_wall=38, gb_free=8.8, wall=96389
2023-05-21 20:44:29 - progress_bar.py[line:272] - INFO: epoch 015:    787 / 1732 loss=2.429, loss_v1=0, loss_v2=0, nll_loss=1.234, ntokens=1016.6, nsentences=32, sample_size=1016.6, sample_size_v1=0, sample_size_v2=0, ppl=2.35, wps=267.5, ups=0.26, wpb=1016.6, bsz=32, num_updates=24990, lr=5.52177e-06, gnorm=14.218, clip=100, loss_scale=32, train_wall=38, gb_free=8.5, wall=96427
2023-05-21 20:45:07 - progress_bar.py[line:272] - INFO: epoch 015:    797 / 1732 loss=2.418, loss_v1=0, loss_v2=0, nll_loss=1.222, ntokens=1038, nsentences=32, sample_size=1038, sample_size_v1=0, sample_size_v2=0, ppl=2.33, wps=272, ups=0.26, wpb=1038, bsz=32, num_updates=25000, lr=5.51973e-06, gnorm=13.408, clip=100, loss_scale=32, train_wall=38, gb_free=8.8, wall=96465
2023-05-21 20:45:45 - progress_bar.py[line:272] - INFO: epoch 015:    807 / 1732 loss=2.424, loss_v1=0, loss_v2=0, nll_loss=1.227, ntokens=915, nsentences=32, sample_size=915, sample_size_v1=0, sample_size_v2=0, ppl=2.34, wps=241.4, ups=0.26, wpb=915, bsz=32, num_updates=25010, lr=5.51768e-06, gnorm=15.487, clip=100, loss_scale=32, train_wall=38, gb_free=8.7, wall=96503
2023-05-21 20:46:24 - progress_bar.py[line:272] - INFO: epoch 015:    817 / 1732 loss=2.443, loss_v1=0, loss_v2=0, nll_loss=1.247, ntokens=917.4, nsentences=32, sample_size=917.4, sample_size_v1=0, sample_size_v2=0, ppl=2.37, wps=239.6, ups=0.26, wpb=917.4, bsz=32, num_updates=25020, lr=5.51563e-06, gnorm=14.769, clip=100, loss_scale=32, train_wall=38, gb_free=8.9, wall=96541
2023-05-21 20:47:02 - progress_bar.py[line:272] - INFO: epoch 015:    827 / 1732 loss=2.43, loss_v1=0, loss_v2=0, nll_loss=1.233, ntokens=930.6, nsentences=32, sample_size=930.6, sample_size_v1=0, sample_size_v2=0, ppl=2.35, wps=244.6, ups=0.26, wpb=930.6, bsz=32, num_updates=25030, lr=5.51358e-06, gnorm=13.729, clip=100, loss_scale=32, train_wall=38, gb_free=8.9, wall=96579
2023-05-21 20:47:40 - progress_bar.py[line:272] - INFO: epoch 015:    837 / 1732 loss=2.433, loss_v1=0, loss_v2=0, nll_loss=1.237, ntokens=894.5, nsentences=32, sample_size=894.5, sample_size_v1=0, sample_size_v2=0, ppl=2.36, wps=235.8, ups=0.26, wpb=894.5, bsz=32, num_updates=25040, lr=5.51154e-06, gnorm=15.61, clip=100, loss_scale=32, train_wall=38, gb_free=9.1, wall=96617
2023-05-21 20:48:18 - progress_bar.py[line:272] - INFO: epoch 015:    847 / 1732 loss=2.405, loss_v1=0, loss_v2=0, nll_loss=1.206, ntokens=1012.6, nsentences=32, sample_size=1012.6, sample_size_v1=0, sample_size_v2=0, ppl=2.31, wps=266.1, ups=0.26, wpb=1012.6, bsz=32, num_updates=25050, lr=5.50949e-06, gnorm=13.598, clip=100, loss_scale=32, train_wall=38, gb_free=7.7, wall=96655
2023-05-21 20:48:56 - progress_bar.py[line:272] - INFO: epoch 015:    857 / 1732 loss=2.43, loss_v1=0, loss_v2=0, nll_loss=1.235, ntokens=920, nsentences=32, sample_size=920, sample_size_v1=0, sample_size_v2=0, ppl=2.35, wps=243, ups=0.26, wpb=920, bsz=32, num_updates=25060, lr=5.50744e-06, gnorm=15.284, clip=100, loss_scale=32, train_wall=38, gb_free=8.6, wall=96693
2023-05-21 20:49:34 - progress_bar.py[line:272] - INFO: epoch 015:    867 / 1732 loss=2.438, loss_v1=0, loss_v2=0, nll_loss=1.242, ntokens=979.9, nsentences=32, sample_size=979.9, sample_size_v1=0, sample_size_v2=0, ppl=2.37, wps=258, ups=0.26, wpb=979.9, bsz=32, num_updates=25070, lr=5.50539e-06, gnorm=15.466, clip=100, loss_scale=32, train_wall=38, gb_free=8.6, wall=96731
2023-05-21 20:50:12 - progress_bar.py[line:272] - INFO: epoch 015:    877 / 1732 loss=2.364, loss_v1=0, loss_v2=0, nll_loss=1.161, ntokens=994.5, nsentences=32, sample_size=994.5, sample_size_v1=0, sample_size_v2=0, ppl=2.24, wps=260.7, ups=0.26, wpb=994.5, bsz=32, num_updates=25080, lr=5.50335e-06, gnorm=12.038, clip=100, loss_scale=32, train_wall=38, gb_free=8.9, wall=96769
2023-05-21 20:50:50 - progress_bar.py[line:272] - INFO: epoch 015:    887 / 1732 loss=2.388, loss_v1=0, loss_v2=0, nll_loss=1.187, ntokens=982, nsentences=32, sample_size=982, sample_size_v1=0, sample_size_v2=0, ppl=2.28, wps=257.1, ups=0.26, wpb=982, bsz=32, num_updates=25090, lr=5.5013e-06, gnorm=13.678, clip=100, loss_scale=32, train_wall=38, gb_free=8.3, wall=96807
2023-05-21 20:51:28 - progress_bar.py[line:272] - INFO: epoch 015:    897 / 1732 loss=2.367, loss_v1=0, loss_v2=0, nll_loss=1.163, ntokens=1034.6, nsentences=32, sample_size=1034.6, sample_size_v1=0, sample_size_v2=0, ppl=2.24, wps=270.2, ups=0.26, wpb=1034.6, bsz=32, num_updates=25100, lr=5.49925e-06, gnorm=12.47, clip=100, loss_scale=32, train_wall=38, gb_free=8.6, wall=96845
2023-05-21 20:52:07 - progress_bar.py[line:272] - INFO: epoch 015:    907 / 1732 loss=2.377, loss_v1=0, loss_v2=0, nll_loss=1.177, ntokens=1016.8, nsentences=32, sample_size=1016.8, sample_size_v1=0, sample_size_v2=0, ppl=2.26, wps=265, ups=0.26, wpb=1016.8, bsz=32, num_updates=25110, lr=5.49721e-06, gnorm=13.245, clip=100, loss_scale=32, train_wall=38, gb_free=8.9, wall=96884
2023-05-21 20:52:45 - progress_bar.py[line:272] - INFO: epoch 015:    917 / 1732 loss=2.459, loss_v1=0, loss_v2=0, nll_loss=1.266, ntokens=936.4, nsentences=32, sample_size=936.4, sample_size_v1=0, sample_size_v2=0, ppl=2.4, wps=245.3, ups=0.26, wpb=936.4, bsz=32, num_updates=25120, lr=5.49516e-06, gnorm=14.951, clip=100, loss_scale=32, train_wall=38, gb_free=9.2, wall=96922
2023-05-21 20:53:23 - progress_bar.py[line:272] - INFO: epoch 015:    927 / 1732 loss=2.385, loss_v1=0, loss_v2=0, nll_loss=1.184, ntokens=1039.7, nsentences=32, sample_size=1039.7, sample_size_v1=0, sample_size_v2=0, ppl=2.27, wps=269.9, ups=0.26, wpb=1039.7, bsz=32, num_updates=25130, lr=5.49311e-06, gnorm=14.564, clip=100, loss_scale=32, train_wall=38, gb_free=8.7, wall=96961
2023-05-21 20:54:02 - progress_bar.py[line:272] - INFO: epoch 015:    937 / 1732 loss=2.394, loss_v1=0, loss_v2=0, nll_loss=1.194, ntokens=1061.1, nsentences=32, sample_size=1061.1, sample_size_v1=0, sample_size_v2=0, ppl=2.29, wps=273, ups=0.26, wpb=1061.1, bsz=32, num_updates=25140, lr=5.49106e-06, gnorm=13.271, clip=100, loss_scale=32, train_wall=39, gb_free=8.3, wall=96999
2023-05-21 20:54:41 - progress_bar.py[line:272] - INFO: epoch 015:    947 / 1732 loss=2.409, loss_v1=0, loss_v2=0, nll_loss=1.211, ntokens=1042.4, nsentences=32, sample_size=1042.4, sample_size_v1=0, sample_size_v2=0, ppl=2.32, wps=267.7, ups=0.26, wpb=1042.4, bsz=32, num_updates=25150, lr=5.48902e-06, gnorm=13.199, clip=100, loss_scale=32, train_wall=39, gb_free=8.6, wall=97038
2023-05-21 20:55:20 - progress_bar.py[line:272] - INFO: epoch 015:    957 / 1732 loss=2.407, loss_v1=0, loss_v2=0, nll_loss=1.209, ntokens=1046.8, nsentences=32, sample_size=1046.8, sample_size_v1=0, sample_size_v2=0, ppl=2.31, wps=270.2, ups=0.26, wpb=1046.8, bsz=32, num_updates=25160, lr=5.48697e-06, gnorm=13.1, clip=100, loss_scale=32, train_wall=39, gb_free=8.2, wall=97077
2023-05-21 20:55:58 - progress_bar.py[line:272] - INFO: epoch 015:    967 / 1732 loss=2.405, loss_v1=0, loss_v2=0, nll_loss=1.208, ntokens=1036.4, nsentences=32, sample_size=1036.4, sample_size_v1=0, sample_size_v2=0, ppl=2.31, wps=268.4, ups=0.26, wpb=1036.4, bsz=32, num_updates=25170, lr=5.48492e-06, gnorm=13.666, clip=100, loss_scale=32, train_wall=39, gb_free=8.6, wall=97116
2023-05-21 20:56:37 - progress_bar.py[line:272] - INFO: epoch 015:    977 / 1732 loss=2.414, loss_v1=0, loss_v2=0, nll_loss=1.219, ntokens=1035.2, nsentences=32, sample_size=1035.2, sample_size_v1=0, sample_size_v2=0, ppl=2.33, wps=266.6, ups=0.26, wpb=1035.2, bsz=32, num_updates=25180, lr=5.48287e-06, gnorm=12.93, clip=100, loss_scale=32, train_wall=39, gb_free=8.1, wall=97155
2023-05-21 20:57:16 - progress_bar.py[line:272] - INFO: epoch 015:    987 / 1732 loss=2.409, loss_v1=0, loss_v2=0, nll_loss=1.212, ntokens=1020.1, nsentences=32, sample_size=1020.1, sample_size_v1=0, sample_size_v2=0, ppl=2.32, wps=263.4, ups=0.26, wpb=1020.1, bsz=32, num_updates=25190, lr=5.48083e-06, gnorm=13.141, clip=100, loss_scale=32, train_wall=39, gb_free=8.5, wall=97193
2023-05-21 20:57:55 - progress_bar.py[line:272] - INFO: epoch 015:    997 / 1732 loss=2.395, loss_v1=0, loss_v2=0, nll_loss=1.194, ntokens=1032.4, nsentences=32, sample_size=1032.4, sample_size_v1=0, sample_size_v2=0, ppl=2.29, wps=268.3, ups=0.26, wpb=1032.4, bsz=32, num_updates=25200, lr=5.47878e-06, gnorm=13.306, clip=100, loss_scale=32, train_wall=38, gb_free=8.9, wall=97232
2023-05-21 20:58:33 - progress_bar.py[line:272] - INFO: epoch 015:   1007 / 1732 loss=2.392, loss_v1=0, loss_v2=0, nll_loss=1.191, ntokens=1018.9, nsentences=32, sample_size=1018.9, sample_size_v1=0, sample_size_v2=0, ppl=2.28, wps=266.1, ups=0.26, wpb=1018.9, bsz=32, num_updates=25210, lr=5.47673e-06, gnorm=13.82, clip=100, loss_scale=32, train_wall=38, gb_free=8.6, wall=97270
2023-05-21 20:59:12 - progress_bar.py[line:272] - INFO: epoch 015:   1017 / 1732 loss=2.389, loss_v1=0, loss_v2=0, nll_loss=1.188, ntokens=1024.8, nsentences=32, sample_size=1024.8, sample_size_v1=0, sample_size_v2=0, ppl=2.28, wps=264.9, ups=0.26, wpb=1024.8, bsz=32, num_updates=25220, lr=5.47468e-06, gnorm=12.672, clip=100, loss_scale=32, train_wall=39, gb_free=7.6, wall=97309
2023-05-21 20:59:50 - progress_bar.py[line:272] - INFO: epoch 015:   1027 / 1732 loss=2.421, loss_v1=0, loss_v2=0, nll_loss=1.226, ntokens=1051.5, nsentences=32, sample_size=1051.5, sample_size_v1=0, sample_size_v2=0, ppl=2.34, wps=270.5, ups=0.26, wpb=1051.5, bsz=32, num_updates=25230, lr=5.47264e-06, gnorm=13.113, clip=100, loss_scale=32, train_wall=39, gb_free=8.6, wall=97348
2023-05-21 21:00:29 - progress_bar.py[line:272] - INFO: epoch 015:   1037 / 1732 loss=2.389, loss_v1=0, loss_v2=0, nll_loss=1.189, ntokens=1129.2, nsentences=32, sample_size=1129.2, sample_size_v1=0, sample_size_v2=0, ppl=2.28, wps=291.4, ups=0.26, wpb=1129.2, bsz=32, num_updates=25240, lr=5.47059e-06, gnorm=12.153, clip=100, loss_scale=64, train_wall=39, gb_free=8.7, wall=97386
2023-05-21 21:01:08 - progress_bar.py[line:272] - INFO: epoch 015:   1047 / 1732 loss=2.394, loss_v1=0, loss_v2=0, nll_loss=1.193, ntokens=1024.6, nsentences=32, sample_size=1024.6, sample_size_v1=0, sample_size_v2=0, ppl=2.29, wps=266.4, ups=0.26, wpb=1024.6, bsz=32, num_updates=25250, lr=5.46854e-06, gnorm=13.626, clip=100, loss_scale=64, train_wall=38, gb_free=8.6, wall=97425
2023-05-21 21:01:11 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2023-05-21 21:01:50 - progress_bar.py[line:272] - INFO: epoch 015:   1058 / 1732 loss=2.403, loss_v1=0, loss_v2=0, nll_loss=1.204, ntokens=1082.8, nsentences=32, sample_size=1082.8, sample_size_v1=0, sample_size_v2=0, ppl=2.3, wps=256.2, ups=0.24, wpb=1082.8, bsz=32, num_updates=25260, lr=5.46649e-06, gnorm=13.923, clip=100, loss_scale=32, train_wall=42, gb_free=9, wall=97467
2023-05-21 21:02:28 - progress_bar.py[line:272] - INFO: epoch 015:   1068 / 1732 loss=2.4, loss_v1=0, loss_v2=0, nll_loss=1.201, ntokens=1002.9, nsentences=32, sample_size=1002.9, sample_size_v1=0, sample_size_v2=0, ppl=2.3, wps=260.5, ups=0.26, wpb=1002.9, bsz=32, num_updates=25270, lr=5.46445e-06, gnorm=14.152, clip=100, loss_scale=32, train_wall=38, gb_free=8.9, wall=97506
2023-05-21 21:03:07 - progress_bar.py[line:272] - INFO: epoch 015:   1078 / 1732 loss=2.426, loss_v1=0, loss_v2=0, nll_loss=1.23, ntokens=1000.2, nsentences=32, sample_size=1000.2, sample_size_v1=0, sample_size_v2=0, ppl=2.35, wps=256.8, ups=0.26, wpb=1000.2, bsz=32, num_updates=25280, lr=5.4624e-06, gnorm=13.586, clip=100, loss_scale=32, train_wall=39, gb_free=8.7, wall=97545
2023-05-21 21:03:46 - progress_bar.py[line:272] - INFO: epoch 015:   1088 / 1732 loss=2.39, loss_v1=0, loss_v2=0, nll_loss=1.19, ntokens=1078.6, nsentences=32, sample_size=1078.6, sample_size_v1=0, sample_size_v2=0, ppl=2.28, wps=277.6, ups=0.26, wpb=1078.6, bsz=32, num_updates=25290, lr=5.46035e-06, gnorm=12.889, clip=100, loss_scale=32, train_wall=39, gb_free=8.6, wall=97583
2023-05-21 21:04:25 - progress_bar.py[line:272] - INFO: epoch 015:   1098 / 1732 loss=2.41, loss_v1=0, loss_v2=0, nll_loss=1.212, ntokens=1045.6, nsentences=32, sample_size=1045.6, sample_size_v1=0, sample_size_v2=0, ppl=2.32, wps=270.1, ups=0.26, wpb=1045.6, bsz=32, num_updates=25300, lr=5.45831e-06, gnorm=14.645, clip=100, loss_scale=32, train_wall=39, gb_free=7.9, wall=97622
2023-05-21 21:05:04 - progress_bar.py[line:272] - INFO: epoch 015:   1108 / 1732 loss=2.394, loss_v1=0, loss_v2=0, nll_loss=1.193, ntokens=1058.8, nsentences=32, sample_size=1058.8, sample_size_v1=0, sample_size_v2=0, ppl=2.29, wps=272.1, ups=0.26, wpb=1058.8, bsz=32, num_updates=25310, lr=5.45626e-06, gnorm=14.308, clip=100, loss_scale=32, train_wall=39, gb_free=8.9, wall=97661
2023-05-21 21:05:42 - progress_bar.py[line:272] - INFO: epoch 015:   1118 / 1732 loss=2.412, loss_v1=0, loss_v2=0, nll_loss=1.214, ntokens=944.7, nsentences=32, sample_size=944.7, sample_size_v1=0, sample_size_v2=0, ppl=2.32, wps=245.4, ups=0.26, wpb=944.7, bsz=32, num_updates=25320, lr=5.45421e-06, gnorm=14.857, clip=100, loss_scale=32, train_wall=38, gb_free=8.4, wall=97700
2023-05-21 21:06:21 - progress_bar.py[line:272] - INFO: epoch 015:   1128 / 1732 loss=2.415, loss_v1=0, loss_v2=0, nll_loss=1.218, ntokens=1025.9, nsentences=32, sample_size=1025.9, sample_size_v1=0, sample_size_v2=0, ppl=2.33, wps=265.8, ups=0.26, wpb=1025.9, bsz=32, num_updates=25330, lr=5.45216e-06, gnorm=13.434, clip=100, loss_scale=32, train_wall=39, gb_free=7.7, wall=97738
2023-05-21 21:06:59 - progress_bar.py[line:272] - INFO: epoch 015:   1138 / 1732 loss=2.408, loss_v1=0, loss_v2=0, nll_loss=1.21, ntokens=989.2, nsentences=32, sample_size=989.2, sample_size_v1=0, sample_size_v2=0, ppl=2.31, wps=256.9, ups=0.26, wpb=989.2, bsz=32, num_updates=25340, lr=5.45012e-06, gnorm=14.871, clip=100, loss_scale=32, train_wall=38, gb_free=8.7, wall=97777
2023-05-21 21:07:38 - progress_bar.py[line:272] - INFO: epoch 015:   1148 / 1732 loss=2.413, loss_v1=0, loss_v2=0, nll_loss=1.216, ntokens=1007.7, nsentences=32, sample_size=1007.7, sample_size_v1=0, sample_size_v2=0, ppl=2.32, wps=260.6, ups=0.26, wpb=1007.7, bsz=32, num_updates=25350, lr=5.44807e-06, gnorm=13.638, clip=100, loss_scale=32, train_wall=39, gb_free=8.6, wall=97815
2023-05-21 21:08:17 - progress_bar.py[line:272] - INFO: epoch 015:   1158 / 1732 loss=2.379, loss_v1=0, loss_v2=0, nll_loss=1.177, ntokens=1016, nsentences=32, sample_size=1016, sample_size_v1=0, sample_size_v2=0, ppl=2.26, wps=262.9, ups=0.26, wpb=1016, bsz=32, num_updates=25360, lr=5.44602e-06, gnorm=13.186, clip=100, loss_scale=32, train_wall=39, gb_free=7.9, wall=97854
2023-05-21 21:08:55 - progress_bar.py[line:272] - INFO: epoch 015:   1168 / 1732 loss=2.412, loss_v1=0, loss_v2=0, nll_loss=1.215, ntokens=1020.6, nsentences=32, sample_size=1020.6, sample_size_v1=0, sample_size_v2=0, ppl=2.32, wps=264.2, ups=0.26, wpb=1020.6, bsz=32, num_updates=25370, lr=5.44397e-06, gnorm=14.317, clip=100, loss_scale=32, train_wall=39, gb_free=8.1, wall=97893
2023-05-21 21:09:34 - progress_bar.py[line:272] - INFO: epoch 015:   1178 / 1732 loss=2.371, loss_v1=0, loss_v2=0, nll_loss=1.167, ntokens=1067, nsentences=32, sample_size=1067, sample_size_v1=0, sample_size_v2=0, ppl=2.25, wps=276.3, ups=0.26, wpb=1067, bsz=32, num_updates=25380, lr=5.44193e-06, gnorm=14.44, clip=100, loss_scale=32, train_wall=39, gb_free=8.7, wall=97931
2023-05-21 21:10:12 - progress_bar.py[line:272] - INFO: epoch 015:   1188 / 1732 loss=2.416, loss_v1=0, loss_v2=0, nll_loss=1.219, ntokens=963.5, nsentences=32, sample_size=963.5, sample_size_v1=0, sample_size_v2=0, ppl=2.33, wps=250.4, ups=0.26, wpb=963.5, bsz=32, num_updates=25390, lr=5.43988e-06, gnorm=14.59, clip=100, loss_scale=32, train_wall=38, gb_free=8.2, wall=97970
2023-05-21 21:10:51 - progress_bar.py[line:272] - INFO: epoch 015:   1198 / 1732 loss=2.381, loss_v1=0, loss_v2=0, nll_loss=1.179, ntokens=1123.7, nsentences=32, sample_size=1123.7, sample_size_v1=0, sample_size_v2=0, ppl=2.26, wps=290.9, ups=0.26, wpb=1123.7, bsz=32, num_updates=25400, lr=5.43783e-06, gnorm=13.666, clip=100, loss_scale=32, train_wall=39, gb_free=8.4, wall=98008
2023-05-21 21:11:30 - progress_bar.py[line:272] - INFO: epoch 015:   1208 / 1732 loss=2.374, loss_v1=0, loss_v2=0, nll_loss=1.17, ntokens=1088.9, nsentences=32, sample_size=1088.9, sample_size_v1=0, sample_size_v2=0, ppl=2.25, wps=280.3, ups=0.26, wpb=1088.9, bsz=32, num_updates=25410, lr=5.43578e-06, gnorm=12.798, clip=100, loss_scale=32, train_wall=39, gb_free=7.7, wall=98047
2023-05-21 21:12:08 - progress_bar.py[line:272] - INFO: epoch 015:   1218 / 1732 loss=2.428, loss_v1=0, loss_v2=0, nll_loss=1.231, ntokens=1016, nsentences=32, sample_size=1016, sample_size_v1=0, sample_size_v2=0, ppl=2.35, wps=265.1, ups=0.26, wpb=1016, bsz=32, num_updates=25420, lr=5.43374e-06, gnorm=14.071, clip=100, loss_scale=32, train_wall=38, gb_free=8.8, wall=98086
2023-05-21 21:12:47 - progress_bar.py[line:272] - INFO: epoch 015:   1228 / 1732 loss=2.409, loss_v1=0, loss_v2=0, nll_loss=1.21, ntokens=1018.6, nsentences=32, sample_size=1018.6, sample_size_v1=0, sample_size_v2=0, ppl=2.31, wps=265.4, ups=0.26, wpb=1018.6, bsz=32, num_updates=25430, lr=5.43169e-06, gnorm=14.489, clip=100, loss_scale=32, train_wall=38, gb_free=8.6, wall=98124
2023-05-21 21:13:25 - progress_bar.py[line:272] - INFO: epoch 015:   1238 / 1732 loss=2.364, loss_v1=0, loss_v2=0, nll_loss=1.161, ntokens=1070.1, nsentences=32, sample_size=1070.1, sample_size_v1=0, sample_size_v2=0, ppl=2.24, wps=275.8, ups=0.26, wpb=1070.1, bsz=32, num_updates=25440, lr=5.42964e-06, gnorm=14.019, clip=100, loss_scale=32, train_wall=39, gb_free=8.3, wall=98163
2023-05-21 21:14:04 - progress_bar.py[line:272] - INFO: epoch 015:   1248 / 1732 loss=2.358, loss_v1=0, loss_v2=0, nll_loss=1.155, ntokens=1083.3, nsentences=32, sample_size=1083.3, sample_size_v1=0, sample_size_v2=0, ppl=2.23, wps=280.3, ups=0.26, wpb=1083.3, bsz=32, num_updates=25450, lr=5.42759e-06, gnorm=13.178, clip=100, loss_scale=32, train_wall=39, gb_free=8, wall=98201
2023-05-21 21:14:43 - progress_bar.py[line:272] - INFO: epoch 015:   1258 / 1732 loss=2.366, loss_v1=0, loss_v2=0, nll_loss=1.162, ntokens=1058.8, nsentences=32, sample_size=1058.8, sample_size_v1=0, sample_size_v2=0, ppl=2.24, wps=272.7, ups=0.26, wpb=1058.8, bsz=32, num_updates=25460, lr=5.42555e-06, gnorm=14.37, clip=100, loss_scale=32, train_wall=39, gb_free=8.2, wall=98240
2023-05-21 21:15:22 - progress_bar.py[line:272] - INFO: epoch 015:   1268 / 1732 loss=2.402, loss_v1=0, loss_v2=0, nll_loss=1.203, ntokens=1040.1, nsentences=32, sample_size=1040.1, sample_size_v1=0, sample_size_v2=0, ppl=2.3, wps=268.9, ups=0.26, wpb=1040.1, bsz=32, num_updates=25470, lr=5.4235e-06, gnorm=13.031, clip=100, loss_scale=32, train_wall=39, gb_free=8.5, wall=98279
2023-05-21 21:16:00 - progress_bar.py[line:272] - INFO: epoch 015:   1278 / 1732 loss=2.421, loss_v1=0, loss_v2=0, nll_loss=1.225, ntokens=1064.5, nsentences=32, sample_size=1064.5, sample_size_v1=0, sample_size_v2=0, ppl=2.34, wps=275.1, ups=0.26, wpb=1064.5, bsz=32, num_updates=25480, lr=5.42145e-06, gnorm=14.704, clip=100, loss_scale=32, train_wall=39, gb_free=8.6, wall=98318
2023-05-21 21:16:39 - progress_bar.py[line:272] - INFO: epoch 015:   1288 / 1732 loss=2.38, loss_v1=0, loss_v2=0, nll_loss=1.177, ntokens=1074.2, nsentences=32, sample_size=1074.2, sample_size_v1=0, sample_size_v2=0, ppl=2.26, wps=277.7, ups=0.26, wpb=1074.2, bsz=32, num_updates=25490, lr=5.41941e-06, gnorm=13.828, clip=100, loss_scale=32, train_wall=39, gb_free=6.9, wall=98356
2023-05-21 21:17:18 - progress_bar.py[line:272] - INFO: epoch 015:   1298 / 1732 loss=2.384, loss_v1=0, loss_v2=0, nll_loss=1.182, ntokens=1104.5, nsentences=32, sample_size=1104.5, sample_size_v1=0, sample_size_v2=0, ppl=2.27, wps=285.8, ups=0.26, wpb=1104.5, bsz=32, num_updates=25500, lr=5.41736e-06, gnorm=12.956, clip=100, loss_scale=32, train_wall=39, gb_free=7.9, wall=98395
2023-05-21 21:17:57 - progress_bar.py[line:272] - INFO: epoch 015:   1308 / 1732 loss=2.42, loss_v1=0, loss_v2=0, nll_loss=1.222, ntokens=1079.8, nsentences=32, sample_size=1079.8, sample_size_v1=0, sample_size_v2=0, ppl=2.33, wps=276.8, ups=0.26, wpb=1079.8, bsz=32, num_updates=25510, lr=5.41531e-06, gnorm=12.911, clip=100, loss_scale=32, train_wall=39, gb_free=7.5, wall=98434
2023-05-21 21:18:36 - progress_bar.py[line:272] - INFO: epoch 015:   1318 / 1732 loss=2.389, loss_v1=0, loss_v2=0, nll_loss=1.187, ntokens=1085.2, nsentences=32, sample_size=1085.2, sample_size_v1=0, sample_size_v2=0, ppl=2.28, wps=279.2, ups=0.26, wpb=1085.2, bsz=32, num_updates=25520, lr=5.41326e-06, gnorm=13.117, clip=100, loss_scale=32, train_wall=39, gb_free=8.1, wall=98473
2023-05-21 21:19:15 - progress_bar.py[line:272] - INFO: epoch 015:   1328 / 1732 loss=2.364, loss_v1=0, loss_v2=0, nll_loss=1.162, ntokens=1103.2, nsentences=32, sample_size=1103.2, sample_size_v1=0, sample_size_v2=0, ppl=2.24, wps=280.7, ups=0.25, wpb=1103.2, bsz=32, num_updates=25530, lr=5.41122e-06, gnorm=16.035, clip=100, loss_scale=32, train_wall=39, gb_free=8.2, wall=98512
2023-05-21 21:19:54 - progress_bar.py[line:272] - INFO: epoch 015:   1338 / 1732 loss=2.38, loss_v1=0, loss_v2=0, nll_loss=1.179, ntokens=1116.2, nsentences=32, sample_size=1116.2, sample_size_v1=0, sample_size_v2=0, ppl=2.26, wps=288, ups=0.26, wpb=1116.2, bsz=32, num_updates=25540, lr=5.40917e-06, gnorm=14.388, clip=100, loss_scale=32, train_wall=39, gb_free=7.7, wall=98551
2023-05-21 21:20:33 - progress_bar.py[line:272] - INFO: epoch 015:   1348 / 1732 loss=2.379, loss_v1=0, loss_v2=0, nll_loss=1.178, ntokens=1187.2, nsentences=32, sample_size=1187.2, sample_size_v1=0, sample_size_v2=0, ppl=2.26, wps=302.9, ups=0.26, wpb=1187.2, bsz=32, num_updates=25550, lr=5.40712e-06, gnorm=12.702, clip=100, loss_scale=32, train_wall=39, gb_free=8.3, wall=98590
2023-05-21 21:21:12 - progress_bar.py[line:272] - INFO: epoch 015:   1358 / 1732 loss=2.367, loss_v1=0, loss_v2=0, nll_loss=1.163, ntokens=1099, nsentences=32, sample_size=1099, sample_size_v1=0, sample_size_v2=0, ppl=2.24, wps=281.2, ups=0.26, wpb=1099, bsz=32, num_updates=25560, lr=5.40507e-06, gnorm=12.453, clip=100, loss_scale=32, train_wall=39, gb_free=8.5, wall=98629
2023-05-21 21:21:51 - progress_bar.py[line:272] - INFO: epoch 015:   1368 / 1732 loss=2.393, loss_v1=0, loss_v2=0, nll_loss=1.193, ntokens=1106.4, nsentences=32, sample_size=1106.4, sample_size_v1=0, sample_size_v2=0, ppl=2.29, wps=284.1, ups=0.26, wpb=1106.4, bsz=32, num_updates=25570, lr=5.40303e-06, gnorm=13.124, clip=100, loss_scale=32, train_wall=39, gb_free=8.5, wall=98668
2023-05-21 21:22:30 - progress_bar.py[line:272] - INFO: epoch 015:   1378 / 1732 loss=2.406, loss_v1=0, loss_v2=0, nll_loss=1.207, ntokens=1104.2, nsentences=32, sample_size=1104.2, sample_size_v1=0, sample_size_v2=0, ppl=2.31, wps=285.7, ups=0.26, wpb=1104.2, bsz=32, num_updates=25580, lr=5.40098e-06, gnorm=14.457, clip=100, loss_scale=32, train_wall=39, gb_free=8.5, wall=98707
2023-05-21 21:23:08 - progress_bar.py[line:272] - INFO: epoch 015:   1388 / 1732 loss=2.396, loss_v1=0, loss_v2=0, nll_loss=1.195, ntokens=1131.9, nsentences=32, sample_size=1131.9, sample_size_v1=0, sample_size_v2=0, ppl=2.29, wps=291.6, ups=0.26, wpb=1131.9, bsz=32, num_updates=25590, lr=5.39893e-06, gnorm=13.888, clip=100, loss_scale=32, train_wall=39, gb_free=8.7, wall=98746
2023-05-21 21:23:47 - progress_bar.py[line:272] - INFO: epoch 015:   1398 / 1732 loss=2.367, loss_v1=0, loss_v2=0, nll_loss=1.164, ntokens=1097.3, nsentences=32, sample_size=1097.3, sample_size_v1=0, sample_size_v2=0, ppl=2.24, wps=281.7, ups=0.26, wpb=1097.3, bsz=32, num_updates=25600, lr=5.39688e-06, gnorm=13.289, clip=100, loss_scale=32, train_wall=39, gb_free=8.6, wall=98784
2023-05-21 21:24:26 - progress_bar.py[line:272] - INFO: epoch 015:   1408 / 1732 loss=2.396, loss_v1=0, loss_v2=0, nll_loss=1.196, ntokens=1161.5, nsentences=32, sample_size=1161.5, sample_size_v1=0, sample_size_v2=0, ppl=2.29, wps=297, ups=0.26, wpb=1161.5, bsz=32, num_updates=25610, lr=5.39484e-06, gnorm=13.878, clip=100, loss_scale=32, train_wall=39, gb_free=8.4, wall=98824
2023-05-21 21:25:06 - progress_bar.py[line:272] - INFO: epoch 015:   1418 / 1732 loss=2.403, loss_v1=0, loss_v2=0, nll_loss=1.205, ntokens=1285.2, nsentences=32, sample_size=1285.2, sample_size_v1=0, sample_size_v2=0, ppl=2.31, wps=326, ups=0.25, wpb=1285.2, bsz=32, num_updates=25620, lr=5.39279e-06, gnorm=11.687, clip=100, loss_scale=32, train_wall=39, gb_free=7.8, wall=98863
2023-05-21 21:25:45 - progress_bar.py[line:272] - INFO: epoch 015:   1428 / 1732 loss=2.362, loss_v1=0, loss_v2=0, nll_loss=1.156, ntokens=1229.6, nsentences=32, sample_size=1229.6, sample_size_v1=0, sample_size_v2=0, ppl=2.23, wps=314, ups=0.26, wpb=1229.6, bsz=32, num_updates=25630, lr=5.39074e-06, gnorm=11.593, clip=100, loss_scale=32, train_wall=39, gb_free=8.5, wall=98902
2023-05-21 21:26:24 - progress_bar.py[line:272] - INFO: epoch 015:   1438 / 1732 loss=2.371, loss_v1=0, loss_v2=0, nll_loss=1.169, ntokens=1179.5, nsentences=32, sample_size=1179.5, sample_size_v1=0, sample_size_v2=0, ppl=2.25, wps=302.7, ups=0.26, wpb=1179.5, bsz=32, num_updates=25640, lr=5.38869e-06, gnorm=11.712, clip=100, loss_scale=32, train_wall=39, gb_free=8.8, wall=98941
2023-05-21 21:27:03 - progress_bar.py[line:272] - INFO: epoch 015:   1448 / 1732 loss=2.403, loss_v1=0, loss_v2=0, nll_loss=1.204, ntokens=1120.7, nsentences=32, sample_size=1120.7, sample_size_v1=0, sample_size_v2=0, ppl=2.3, wps=289.8, ups=0.26, wpb=1120.7, bsz=32, num_updates=25650, lr=5.38665e-06, gnorm=13.774, clip=100, loss_scale=32, train_wall=39, gb_free=8.8, wall=98980
2023-05-21 21:27:42 - progress_bar.py[line:272] - INFO: epoch 015:   1458 / 1732 loss=2.379, loss_v1=0, loss_v2=0, nll_loss=1.177, ntokens=1151.7, nsentences=32, sample_size=1151.7, sample_size_v1=0, sample_size_v2=0, ppl=2.26, wps=295, ups=0.26, wpb=1151.7, bsz=32, num_updates=25660, lr=5.3846e-06, gnorm=12.828, clip=100, loss_scale=32, train_wall=39, gb_free=7.9, wall=99019
2023-05-21 21:28:21 - progress_bar.py[line:272] - INFO: epoch 015:   1468 / 1732 loss=2.357, loss_v1=0, loss_v2=0, nll_loss=1.152, ntokens=1195.8, nsentences=32, sample_size=1195.8, sample_size_v1=0, sample_size_v2=0, ppl=2.22, wps=306.4, ups=0.26, wpb=1195.8, bsz=32, num_updates=25670, lr=5.38255e-06, gnorm=12.926, clip=100, loss_scale=32, train_wall=39, gb_free=7.7, wall=99058
2023-05-21 21:28:59 - progress_bar.py[line:272] - INFO: epoch 015:   1478 / 1732 loss=2.414, loss_v1=0, loss_v2=0, nll_loss=1.216, ntokens=1019.5, nsentences=32, sample_size=1019.5, sample_size_v1=0, sample_size_v2=0, ppl=2.32, wps=263.1, ups=0.26, wpb=1019.5, bsz=32, num_updates=25680, lr=5.3805e-06, gnorm=15.043, clip=100, loss_scale=32, train_wall=39, gb_free=8.5, wall=99097
2023-05-21 21:29:39 - progress_bar.py[line:272] - INFO: epoch 015:   1488 / 1732 loss=2.387, loss_v1=0, loss_v2=0, nll_loss=1.186, ntokens=1151.5, nsentences=32, sample_size=1151.5, sample_size_v1=0, sample_size_v2=0, ppl=2.27, wps=293.6, ups=0.26, wpb=1151.5, bsz=32, num_updates=25690, lr=5.37846e-06, gnorm=13.571, clip=100, loss_scale=32, train_wall=39, gb_free=7.8, wall=99136
2023-05-21 21:30:17 - progress_bar.py[line:272] - INFO: epoch 015:   1498 / 1732 loss=2.371, loss_v1=0, loss_v2=0, nll_loss=1.168, ntokens=1078, nsentences=32, sample_size=1078, sample_size_v1=0, sample_size_v2=0, ppl=2.25, wps=278.4, ups=0.26, wpb=1078, bsz=32, num_updates=25700, lr=5.37641e-06, gnorm=12.849, clip=100, loss_scale=32, train_wall=39, gb_free=8.6, wall=99175
2023-05-21 21:30:56 - progress_bar.py[line:272] - INFO: epoch 015:   1508 / 1732 loss=2.333, loss_v1=0, loss_v2=0, nll_loss=1.126, ntokens=1107.9, nsentences=32, sample_size=1107.9, sample_size_v1=0, sample_size_v2=0, ppl=2.18, wps=287.3, ups=0.26, wpb=1107.9, bsz=32, num_updates=25710, lr=5.37436e-06, gnorm=13.197, clip=100, loss_scale=32, train_wall=39, gb_free=8.5, wall=99213
2023-05-21 21:31:35 - progress_bar.py[line:272] - INFO: epoch 015:   1518 / 1732 loss=2.398, loss_v1=0, loss_v2=0, nll_loss=1.201, ntokens=1079, nsentences=32, sample_size=1079, sample_size_v1=0, sample_size_v2=0, ppl=2.3, wps=279.4, ups=0.26, wpb=1079, bsz=32, num_updates=25720, lr=5.37232e-06, gnorm=13.032, clip=100, loss_scale=32, train_wall=39, gb_free=8.6, wall=99252
2023-05-21 21:32:13 - progress_bar.py[line:272] - INFO: epoch 015:   1528 / 1732 loss=2.437, loss_v1=0, loss_v2=0, nll_loss=1.243, ntokens=1041.5, nsentences=32, sample_size=1041.5, sample_size_v1=0, sample_size_v2=0, ppl=2.37, wps=268.9, ups=0.26, wpb=1041.5, bsz=32, num_updates=25730, lr=5.37027e-06, gnorm=14.901, clip=100, loss_scale=32, train_wall=39, gb_free=8.8, wall=99291
2023-05-21 21:32:52 - progress_bar.py[line:272] - INFO: epoch 015:   1538 / 1732 loss=2.376, loss_v1=0, loss_v2=0, nll_loss=1.172, ntokens=1094, nsentences=32, sample_size=1094, sample_size_v1=0, sample_size_v2=0, ppl=2.25, wps=279.5, ups=0.26, wpb=1094, bsz=32, num_updates=25740, lr=5.36822e-06, gnorm=12.73, clip=100, loss_scale=32, train_wall=39, gb_free=8.1, wall=99330
2023-05-21 21:33:31 - progress_bar.py[line:272] - INFO: epoch 015:   1548 / 1732 loss=2.363, loss_v1=0, loss_v2=0, nll_loss=1.157, ntokens=1084.2, nsentences=32, sample_size=1084.2, sample_size_v1=0, sample_size_v2=0, ppl=2.23, wps=278.8, ups=0.26, wpb=1084.2, bsz=32, num_updates=25750, lr=5.36617e-06, gnorm=13.053, clip=100, loss_scale=32, train_wall=39, gb_free=8.2, wall=99369
2023-05-21 21:34:10 - progress_bar.py[line:272] - INFO: epoch 015:   1558 / 1732 loss=2.371, loss_v1=0, loss_v2=0, nll_loss=1.169, ntokens=1077.4, nsentences=32, sample_size=1077.4, sample_size_v1=0, sample_size_v2=0, ppl=2.25, wps=277.6, ups=0.26, wpb=1077.4, bsz=32, num_updates=25760, lr=5.36413e-06, gnorm=12.988, clip=100, loss_scale=32, train_wall=39, gb_free=8, wall=99407
2023-05-21 21:34:26 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2023-05-21 21:34:53 - progress_bar.py[line:272] - INFO: epoch 015:   1569 / 1732 loss=2.431, loss_v1=0, loss_v2=0, nll_loss=1.236, ntokens=1062.9, nsentences=32, sample_size=1062.9, sample_size_v1=0, sample_size_v2=0, ppl=2.36, wps=248.6, ups=0.23, wpb=1062.9, bsz=32, num_updates=25770, lr=5.36208e-06, gnorm=14.948, clip=100, loss_scale=32, train_wall=43, gb_free=8, wall=99450
2023-05-21 21:35:32 - progress_bar.py[line:272] - INFO: epoch 015:   1579 / 1732 loss=2.414, loss_v1=0, loss_v2=0, nll_loss=1.215, ntokens=1008.7, nsentences=32, sample_size=1008.7, sample_size_v1=0, sample_size_v2=0, ppl=2.32, wps=261.2, ups=0.26, wpb=1008.7, bsz=32, num_updates=25780, lr=5.36003e-06, gnorm=14.384, clip=100, loss_scale=32, train_wall=39, gb_free=8.3, wall=99489
2023-05-21 21:36:11 - progress_bar.py[line:272] - INFO: epoch 015:   1589 / 1732 loss=2.394, loss_v1=0, loss_v2=0, nll_loss=1.192, ntokens=1092.2, nsentences=32, sample_size=1092.2, sample_size_v1=0, sample_size_v2=0, ppl=2.28, wps=280.1, ups=0.26, wpb=1092.2, bsz=32, num_updates=25790, lr=5.35798e-06, gnorm=14.53, clip=100, loss_scale=32, train_wall=39, gb_free=8.6, wall=99528
2023-05-21 21:36:49 - progress_bar.py[line:272] - INFO: epoch 015:   1599 / 1732 loss=2.365, loss_v1=0, loss_v2=0, nll_loss=1.162, ntokens=1061.1, nsentences=32, sample_size=1061.1, sample_size_v1=0, sample_size_v2=0, ppl=2.24, wps=274.4, ups=0.26, wpb=1061.1, bsz=32, num_updates=25800, lr=5.35594e-06, gnorm=13.487, clip=100, loss_scale=32, train_wall=39, gb_free=8.4, wall=99566
2023-05-21 21:37:28 - progress_bar.py[line:272] - INFO: epoch 015:   1609 / 1732 loss=2.357, loss_v1=0, loss_v2=0, nll_loss=1.155, ntokens=1155.5, nsentences=32, sample_size=1155.5, sample_size_v1=0, sample_size_v2=0, ppl=2.23, wps=296.6, ups=0.26, wpb=1155.5, bsz=32, num_updates=25810, lr=5.35389e-06, gnorm=13.211, clip=100, loss_scale=32, train_wall=39, gb_free=7.8, wall=99605
2023-05-21 21:38:07 - progress_bar.py[line:272] - INFO: epoch 015:   1619 / 1732 loss=2.337, loss_v1=0, loss_v2=0, nll_loss=1.131, ntokens=1123.8, nsentences=32, sample_size=1123.8, sample_size_v1=0, sample_size_v2=0, ppl=2.19, wps=289.8, ups=0.26, wpb=1123.8, bsz=32, num_updates=25820, lr=5.35184e-06, gnorm=12.166, clip=100, loss_scale=32, train_wall=39, gb_free=8, wall=99644
2023-05-21 21:38:46 - progress_bar.py[line:272] - INFO: epoch 015:   1629 / 1732 loss=2.378, loss_v1=0, loss_v2=0, nll_loss=1.176, ntokens=1172.3, nsentences=32, sample_size=1172.3, sample_size_v1=0, sample_size_v2=0, ppl=2.26, wps=300.3, ups=0.26, wpb=1172.3, bsz=32, num_updates=25830, lr=5.34979e-06, gnorm=13.039, clip=100, loss_scale=32, train_wall=39, gb_free=8.3, wall=99683
2023-05-21 21:39:25 - progress_bar.py[line:272] - INFO: epoch 015:   1639 / 1732 loss=2.352, loss_v1=0, loss_v2=0, nll_loss=1.146, ntokens=1139.8, nsentences=32, sample_size=1139.8, sample_size_v1=0, sample_size_v2=0, ppl=2.21, wps=295.6, ups=0.26, wpb=1139.8, bsz=32, num_updates=25840, lr=5.34775e-06, gnorm=13.055, clip=100, loss_scale=32, train_wall=39, gb_free=7.8, wall=99722
2023-05-21 21:40:04 - progress_bar.py[line:272] - INFO: epoch 015:   1649 / 1732 loss=2.353, loss_v1=0, loss_v2=0, nll_loss=1.148, ntokens=1200.9, nsentences=32, sample_size=1200.9, sample_size_v1=0, sample_size_v2=0, ppl=2.22, wps=306.4, ups=0.26, wpb=1200.9, bsz=32, num_updates=25850, lr=5.3457e-06, gnorm=11.426, clip=100, loss_scale=32, train_wall=39, gb_free=8.5, wall=99761
2023-05-21 21:40:42 - progress_bar.py[line:272] - INFO: epoch 015:   1659 / 1732 loss=2.41, loss_v1=0, loss_v2=0, nll_loss=1.211, ntokens=965.2, nsentences=32, sample_size=965.2, sample_size_v1=0, sample_size_v2=0, ppl=2.32, wps=250.8, ups=0.26, wpb=965.2, bsz=32, num_updates=25860, lr=5.34365e-06, gnorm=14.507, clip=100, loss_scale=32, train_wall=38, gb_free=8.6, wall=99799
2023-05-21 21:41:21 - progress_bar.py[line:272] - INFO: epoch 015:   1669 / 1732 loss=2.375, loss_v1=0, loss_v2=0, nll_loss=1.172, ntokens=1018.2, nsentences=32, sample_size=1018.2, sample_size_v1=0, sample_size_v2=0, ppl=2.25, wps=263.5, ups=0.26, wpb=1018.2, bsz=32, num_updates=25870, lr=5.3416e-06, gnorm=14.136, clip=100, loss_scale=32, train_wall=39, gb_free=9, wall=99838
2023-05-21 21:42:00 - progress_bar.py[line:272] - INFO: epoch 015:   1679 / 1732 loss=2.331, loss_v1=0, loss_v2=0, nll_loss=1.125, ntokens=1155.9, nsentences=32, sample_size=1155.9, sample_size_v1=0, sample_size_v2=0, ppl=2.18, wps=295.7, ups=0.26, wpb=1155.9, bsz=32, num_updates=25880, lr=5.33956e-06, gnorm=12.639, clip=100, loss_scale=32, train_wall=39, gb_free=8, wall=99877
2023-05-21 21:42:39 - progress_bar.py[line:272] - INFO: epoch 015:   1689 / 1732 loss=2.368, loss_v1=0, loss_v2=0, nll_loss=1.164, ntokens=1198.6, nsentences=32, sample_size=1198.6, sample_size_v1=0, sample_size_v2=0, ppl=2.24, wps=306.6, ups=0.26, wpb=1198.6, bsz=32, num_updates=25890, lr=5.33751e-06, gnorm=12.076, clip=100, loss_scale=32, train_wall=39, gb_free=7.4, wall=99916
2023-05-21 21:43:19 - progress_bar.py[line:272] - INFO: epoch 015:   1699 / 1732 loss=2.351, loss_v1=0, loss_v2=0, nll_loss=1.146, ntokens=1300, nsentences=32, sample_size=1300, sample_size_v1=0, sample_size_v2=0, ppl=2.21, wps=326.9, ups=0.25, wpb=1300, bsz=32, num_updates=25900, lr=5.33546e-06, gnorm=11.752, clip=100, loss_scale=32, train_wall=40, gb_free=7.8, wall=99956
2023-05-21 21:43:58 - progress_bar.py[line:272] - INFO: epoch 015:   1709 / 1732 loss=2.388, loss_v1=0, loss_v2=0, nll_loss=1.188, ntokens=1178.3, nsentences=32, sample_size=1178.3, sample_size_v1=0, sample_size_v2=0, ppl=2.28, wps=302.1, ups=0.26, wpb=1178.3, bsz=32, num_updates=25910, lr=5.33342e-06, gnorm=11.935, clip=100, loss_scale=32, train_wall=39, gb_free=8.5, wall=99995
2023-05-21 21:44:37 - progress_bar.py[line:272] - INFO: epoch 015:   1719 / 1732 loss=2.346, loss_v1=0, loss_v2=0, nll_loss=1.142, ntokens=1171.3, nsentences=32, sample_size=1171.3, sample_size_v1=0, sample_size_v2=0, ppl=2.21, wps=298, ups=0.25, wpb=1171.3, bsz=32, num_updates=25920, lr=5.33137e-06, gnorm=12.405, clip=100, loss_scale=32, train_wall=39, gb_free=8.1, wall=100034
2023-05-21 21:45:16 - progress_bar.py[line:272] - INFO: epoch 015:   1729 / 1732 loss=2.407, loss_v1=0, loss_v2=0, nll_loss=1.209, ntokens=1095.7, nsentences=32, sample_size=1095.7, sample_size_v1=0, sample_size_v2=0, ppl=2.31, wps=281.6, ups=0.26, wpb=1095.7, bsz=32, num_updates=25930, lr=5.32932e-06, gnorm=13.416, clip=100, loss_scale=32, train_wall=39, gb_free=8.4, wall=100073
2023-05-21 21:45:20 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2023-05-21 21:45:25 - train.py[line:332] - INFO: end of epoch 15 (average epoch stats below)
2023-05-21 21:45:25 - progress_bar.py[line:282] - INFO: epoch 015 | loss 2.388 | loss_v1 0 | loss_v2 0 | nll_loss 1.187 | ntokens 1051.46 | nsentences 31.986 | sample_size 1051.46 | sample_size_v1 0 | sample_size_v2 0 | ppl 2.28 | wps 272 | ups 0.26 | wpb 1051.5 | bsz 32 | num_updates 25932 | lr 5.32891e-06 | gnorm 13.354 | clip 100 | loss_scale 16 | train_wall 6669 | gb_free 8.9 | wall 100082
2023-05-21 21:45:25 - trainer.py[line:639] - INFO: loading train data for epoch 16
local datafile ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 0 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 0 finished initializing row_count and line_idx-to-offset mapping
file ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 0 row count 55400 total row count 55400
slice_id 0 seek offset 0
2023-05-21 21:45:27 - trainer.py[line:703] - INFO: begin training epoch 16
2023-05-21 21:45:27 - train.py[line:305] - INFO: Start iterating over samples
2023-05-21 21:45:58 - progress_bar.py[line:272] - INFO: epoch 016:      8 / 1732 loss=2.312, loss_v1=0, loss_v2=0, nll_loss=1.102, ntokens=1080.1, nsentences=29.6, sample_size=1080.1, sample_size_v1=0, sample_size_v2=0, ppl=2.15, wps=256.6, ups=0.24, wpb=1080.1, bsz=29.6, num_updates=25940, lr=5.32727e-06, gnorm=15.229, clip=100, loss_scale=16, train_wall=40, gb_free=7.4, wall=100115
2023-05-21 21:46:37 - progress_bar.py[line:272] - INFO: epoch 016:     18 / 1732 loss=2.283, loss_v1=0, loss_v2=0, nll_loss=1.068, ntokens=1071.6, nsentences=32, sample_size=1071.6, sample_size_v1=0, sample_size_v2=0, ppl=2.1, wps=276, ups=0.26, wpb=1071.6, bsz=32, num_updates=25950, lr=5.32523e-06, gnorm=13.744, clip=100, loss_scale=16, train_wall=39, gb_free=8.3, wall=100154
2023-05-21 21:47:16 - progress_bar.py[line:272] - INFO: epoch 016:     28 / 1732 loss=2.351, loss_v1=0, loss_v2=0, nll_loss=1.146, ntokens=959.8, nsentences=32, sample_size=959.8, sample_size_v1=0, sample_size_v2=0, ppl=2.21, wps=249, ups=0.26, wpb=959.8, bsz=32, num_updates=25960, lr=5.32318e-06, gnorm=13.491, clip=100, loss_scale=16, train_wall=39, gb_free=8.5, wall=100193
2023-05-21 21:47:55 - progress_bar.py[line:272] - INFO: epoch 016:     38 / 1732 loss=2.155, loss_v1=0, loss_v2=0, nll_loss=0.926, ntokens=1177.1, nsentences=32, sample_size=1177.1, sample_size_v1=0, sample_size_v2=0, ppl=1.9, wps=300.6, ups=0.26, wpb=1177.1, bsz=32, num_updates=25970, lr=5.32113e-06, gnorm=9.334, clip=100, loss_scale=16, train_wall=39, gb_free=8.5, wall=100232
2023-05-21 21:48:34 - progress_bar.py[line:272] - INFO: epoch 016:     48 / 1732 loss=2.21, loss_v1=0, loss_v2=0, nll_loss=0.997, ntokens=1064.2, nsentences=32, sample_size=1064.2, sample_size_v1=0, sample_size_v2=0, ppl=2, wps=272.5, ups=0.26, wpb=1064.2, bsz=32, num_updates=25980, lr=5.31908e-06, gnorm=11.442, clip=100, loss_scale=16, train_wall=39, gb_free=7.9, wall=100271
2023-05-21 21:49:12 - progress_bar.py[line:272] - INFO: epoch 016:     58 / 1732 loss=2.098, loss_v1=0, loss_v2=0, nll_loss=0.86, ntokens=1039.9, nsentences=32, sample_size=1039.9, sample_size_v1=0, sample_size_v2=0, ppl=1.82, wps=269.5, ups=0.26, wpb=1039.9, bsz=32, num_updates=25990, lr=5.31704e-06, gnorm=11.103, clip=100, loss_scale=16, train_wall=39, gb_free=8.8, wall=100310
2023-05-21 21:49:53 - progress_bar.py[line:272] - INFO: epoch 016:     68 / 1732 loss=2.027, loss_v1=0, loss_v2=0, nll_loss=0.787, ntokens=1401.1, nsentences=32, sample_size=1401.1, sample_size_v1=0, sample_size_v2=0, ppl=1.73, wps=348.7, ups=0.25, wpb=1401.1, bsz=32, num_updates=26000, lr=5.31499e-06, gnorm=7.66, clip=100, loss_scale=16, train_wall=40, gb_free=7.2, wall=100350
2023-05-21 21:50:32 - progress_bar.py[line:272] - INFO: epoch 016:     78 / 1732 loss=2.16, loss_v1=0, loss_v2=0, nll_loss=0.933, ntokens=1268.8, nsentences=32, sample_size=1268.8, sample_size_v1=0, sample_size_v2=0, ppl=1.91, wps=318.8, ups=0.25, wpb=1268.8, bsz=32, num_updates=26010, lr=5.31294e-06, gnorm=11.929, clip=100, loss_scale=16, train_wall=40, gb_free=6.8, wall=100390
2023-05-21 21:51:12 - progress_bar.py[line:272] - INFO: epoch 016:     88 / 1732 loss=2.228, loss_v1=0, loss_v2=0, nll_loss=1.006, ntokens=1100.2, nsentences=32, sample_size=1100.2, sample_size_v1=0, sample_size_v2=0, ppl=2.01, wps=279.6, ups=0.25, wpb=1100.2, bsz=32, num_updates=26020, lr=5.31089e-06, gnorm=13.728, clip=100, loss_scale=16, train_wall=39, gb_free=8.1, wall=100429
2023-05-21 21:51:51 - progress_bar.py[line:272] - INFO: epoch 016:     98 / 1732 loss=2.185, loss_v1=0, loss_v2=0, nll_loss=0.96, ntokens=1080.6, nsentences=32, sample_size=1080.6, sample_size_v1=0, sample_size_v2=0, ppl=1.95, wps=276.2, ups=0.26, wpb=1080.6, bsz=32, num_updates=26030, lr=5.30885e-06, gnorm=11.946, clip=100, loss_scale=16, train_wall=39, gb_free=8.4, wall=100468
2023-05-21 21:52:29 - progress_bar.py[line:272] - INFO: epoch 016:    108 / 1732 loss=2.399, loss_v1=0, loss_v2=0, nll_loss=1.204, ntokens=978.3, nsentences=32, sample_size=978.3, sample_size_v1=0, sample_size_v2=0, ppl=2.3, wps=254.2, ups=0.26, wpb=978.3, bsz=32, num_updates=26040, lr=5.3068e-06, gnorm=15.505, clip=100, loss_scale=16, train_wall=38, gb_free=8.9, wall=100507
2023-05-21 21:53:08 - progress_bar.py[line:272] - INFO: epoch 016:    118 / 1732 loss=2.374, loss_v1=0, loss_v2=0, nll_loss=1.172, ntokens=1087, nsentences=32, sample_size=1087, sample_size_v1=0, sample_size_v2=0, ppl=2.25, wps=277.9, ups=0.26, wpb=1087, bsz=32, num_updates=26050, lr=5.30475e-06, gnorm=12.91, clip=100, loss_scale=16, train_wall=39, gb_free=8.1, wall=100546
2023-05-21 21:53:48 - progress_bar.py[line:272] - INFO: epoch 016:    128 / 1732 loss=2.331, loss_v1=0, loss_v2=0, nll_loss=1.123, ntokens=1177.5, nsentences=32, sample_size=1177.5, sample_size_v1=0, sample_size_v2=0, ppl=2.18, wps=297.4, ups=0.25, wpb=1177.5, bsz=32, num_updates=26060, lr=5.3027e-06, gnorm=11.984, clip=100, loss_scale=16, train_wall=40, gb_free=8.6, wall=100585
2023-05-21 21:54:27 - progress_bar.py[line:272] - INFO: epoch 016:    138 / 1732 loss=2.298, loss_v1=0, loss_v2=0, nll_loss=1.086, ntokens=1228, nsentences=32, sample_size=1228, sample_size_v1=0, sample_size_v2=0, ppl=2.12, wps=312.7, ups=0.25, wpb=1228, bsz=32, num_updates=26070, lr=5.30066e-06, gnorm=10.082, clip=100, loss_scale=16, train_wall=39, gb_free=8.2, wall=100625
2023-05-21 21:55:07 - progress_bar.py[line:272] - INFO: epoch 016:    148 / 1732 loss=2.256, loss_v1=0, loss_v2=0, nll_loss=1.04, ntokens=1210.4, nsentences=32, sample_size=1210.4, sample_size_v1=0, sample_size_v2=0, ppl=2.06, wps=305.8, ups=0.25, wpb=1210.4, bsz=32, num_updates=26080, lr=5.29861e-06, gnorm=9.74, clip=100, loss_scale=16, train_wall=40, gb_free=7.7, wall=100664
2023-05-21 21:55:46 - progress_bar.py[line:272] - INFO: epoch 016:    158 / 1732 loss=2.311, loss_v1=0, loss_v2=0, nll_loss=1.103, ntokens=1139, nsentences=32, sample_size=1139, sample_size_v1=0, sample_size_v2=0, ppl=2.15, wps=288.5, ups=0.25, wpb=1139, bsz=32, num_updates=26090, lr=5.29656e-06, gnorm=11.319, clip=100, loss_scale=16, train_wall=39, gb_free=8.4, wall=100704
2023-05-21 21:56:25 - progress_bar.py[line:272] - INFO: epoch 016:    168 / 1732 loss=2.288, loss_v1=0, loss_v2=0, nll_loss=1.076, ntokens=1015.2, nsentences=32, sample_size=1015.2, sample_size_v1=0, sample_size_v2=0, ppl=2.11, wps=261.4, ups=0.26, wpb=1015.2, bsz=32, num_updates=26100, lr=5.29452e-06, gnorm=12.614, clip=100, loss_scale=16, train_wall=39, gb_free=8.6, wall=100742
2023-05-21 21:57:04 - progress_bar.py[line:272] - INFO: epoch 016:    178 / 1732 loss=2.285, loss_v1=0, loss_v2=0, nll_loss=1.072, ntokens=1025.5, nsentences=32, sample_size=1025.5, sample_size_v1=0, sample_size_v2=0, ppl=2.1, wps=263.2, ups=0.26, wpb=1025.5, bsz=32, num_updates=26110, lr=5.29247e-06, gnorm=12.127, clip=100, loss_scale=16, train_wall=39, gb_free=8.2, wall=100781
2023-05-21 21:57:44 - progress_bar.py[line:272] - INFO: epoch 016:    188 / 1732 loss=2.25, loss_v1=0, loss_v2=0, nll_loss=1.032, ntokens=1150.5, nsentences=32, sample_size=1150.5, sample_size_v1=0, sample_size_v2=0, ppl=2.04, wps=292.1, ups=0.25, wpb=1150.5, bsz=32, num_updates=26120, lr=5.29042e-06, gnorm=10.402, clip=100, loss_scale=16, train_wall=39, gb_free=8.3, wall=100821
2023-05-21 21:58:23 - progress_bar.py[line:272] - INFO: epoch 016:    198 / 1732 loss=2.315, loss_v1=0, loss_v2=0, nll_loss=1.108, ntokens=1142.2, nsentences=32, sample_size=1142.2, sample_size_v1=0, sample_size_v2=0, ppl=2.16, wps=290.7, ups=0.25, wpb=1142.2, bsz=32, num_updates=26130, lr=5.28837e-06, gnorm=12.44, clip=100, loss_scale=16, train_wall=39, gb_free=8.1, wall=100860
2023-05-21 21:59:01 - progress_bar.py[line:272] - INFO: epoch 016:    208 / 1732 loss=2.417, loss_v1=0, loss_v2=0, nll_loss=1.221, ntokens=961.8, nsentences=32, sample_size=961.8, sample_size_v1=0, sample_size_v2=0, ppl=2.33, wps=252, ups=0.26, wpb=961.8, bsz=32, num_updates=26140, lr=5.28633e-06, gnorm=14.201, clip=100, loss_scale=16, train_wall=38, gb_free=8.2, wall=100898
2023-05-21 21:59:40 - progress_bar.py[line:272] - INFO: epoch 016:    218 / 1732 loss=2.41, loss_v1=0, loss_v2=0, nll_loss=1.213, ntokens=1149.2, nsentences=32, sample_size=1149.2, sample_size_v1=0, sample_size_v2=0, ppl=2.32, wps=298.1, ups=0.26, wpb=1149.2, bsz=32, num_updates=26150, lr=5.28428e-06, gnorm=11.73, clip=100, loss_scale=16, train_wall=39, gb_free=8.8, wall=100937
2023-05-21 22:00:18 - progress_bar.py[line:272] - INFO: epoch 016:    228 / 1732 loss=2.409, loss_v1=0, loss_v2=0, nll_loss=1.212, ntokens=1111.8, nsentences=32, sample_size=1111.8, sample_size_v1=0, sample_size_v2=0, ppl=2.32, wps=289.1, ups=0.26, wpb=1111.8, bsz=32, num_updates=26160, lr=5.28223e-06, gnorm=12.5, clip=100, loss_scale=16, train_wall=38, gb_free=8.8, wall=100975
2023-05-21 22:00:57 - progress_bar.py[line:272] - INFO: epoch 016:    238 / 1732 loss=2.457, loss_v1=0, loss_v2=0, nll_loss=1.265, ntokens=1085.4, nsentences=32, sample_size=1085.4, sample_size_v1=0, sample_size_v2=0, ppl=2.4, wps=282.6, ups=0.26, wpb=1085.4, bsz=32, num_updates=26170, lr=5.28018e-06, gnorm=13.416, clip=100, loss_scale=16, train_wall=38, gb_free=8.7, wall=101014
2023-05-21 22:01:35 - progress_bar.py[line:272] - INFO: epoch 016:    248 / 1732 loss=2.41, loss_v1=0, loss_v2=0, nll_loss=1.211, ntokens=1171.6, nsentences=32, sample_size=1171.6, sample_size_v1=0, sample_size_v2=0, ppl=2.32, wps=302.2, ups=0.26, wpb=1171.6, bsz=32, num_updates=26180, lr=5.27814e-06, gnorm=12.527, clip=100, loss_scale=16, train_wall=39, gb_free=8.5, wall=101053
2023-05-21 22:02:14 - progress_bar.py[line:272] - INFO: epoch 016:    258 / 1732 loss=2.435, loss_v1=0, loss_v2=0, nll_loss=1.24, ntokens=1118, nsentences=32, sample_size=1118, sample_size_v1=0, sample_size_v2=0, ppl=2.36, wps=291.1, ups=0.26, wpb=1118, bsz=32, num_updates=26190, lr=5.27609e-06, gnorm=13.705, clip=100, loss_scale=16, train_wall=38, gb_free=8.6, wall=101091
2023-05-21 22:02:52 - progress_bar.py[line:272] - INFO: epoch 016:    268 / 1732 loss=2.417, loss_v1=0, loss_v2=0, nll_loss=1.219, ntokens=1160.8, nsentences=32, sample_size=1160.8, sample_size_v1=0, sample_size_v2=0, ppl=2.33, wps=300.8, ups=0.26, wpb=1160.8, bsz=32, num_updates=26200, lr=5.27404e-06, gnorm=12.055, clip=100, loss_scale=16, train_wall=39, gb_free=8.8, wall=101130
2023-05-21 22:03:31 - progress_bar.py[line:272] - INFO: epoch 016:    278 / 1732 loss=2.425, loss_v1=0, loss_v2=0, nll_loss=1.227, ntokens=1136.9, nsentences=32, sample_size=1136.9, sample_size_v1=0, sample_size_v2=0, ppl=2.34, wps=294.3, ups=0.26, wpb=1136.9, bsz=32, num_updates=26210, lr=5.27199e-06, gnorm=12.558, clip=100, loss_scale=16, train_wall=39, gb_free=8.6, wall=101168
2023-05-21 22:04:10 - progress_bar.py[line:272] - INFO: epoch 016:    288 / 1732 loss=2.403, loss_v1=0, loss_v2=0, nll_loss=1.204, ntokens=1173.3, nsentences=32, sample_size=1173.3, sample_size_v1=0, sample_size_v2=0, ppl=2.3, wps=302.6, ups=0.26, wpb=1173.3, bsz=32, num_updates=26220, lr=5.26995e-06, gnorm=12.579, clip=100, loss_scale=16, train_wall=39, gb_free=8.6, wall=101207
2023-05-21 22:04:48 - progress_bar.py[line:272] - INFO: epoch 016:    298 / 1732 loss=2.42, loss_v1=0, loss_v2=0, nll_loss=1.223, ntokens=1074.2, nsentences=32, sample_size=1074.2, sample_size_v1=0, sample_size_v2=0, ppl=2.33, wps=281.2, ups=0.26, wpb=1074.2, bsz=32, num_updates=26230, lr=5.2679e-06, gnorm=12.666, clip=100, loss_scale=16, train_wall=38, gb_free=9.1, wall=101245
2023-05-21 22:05:26 - progress_bar.py[line:272] - INFO: epoch 016:    308 / 1732 loss=2.403, loss_v1=0, loss_v2=0, nll_loss=1.205, ntokens=1090.6, nsentences=32, sample_size=1090.6, sample_size_v1=0, sample_size_v2=0, ppl=2.31, wps=284.1, ups=0.26, wpb=1090.6, bsz=32, num_updates=26240, lr=5.26585e-06, gnorm=12.685, clip=100, loss_scale=16, train_wall=38, gb_free=8.9, wall=101284
2023-05-21 22:06:04 - progress_bar.py[line:272] - INFO: epoch 016:    318 / 1732 loss=2.427, loss_v1=0, loss_v2=0, nll_loss=1.231, ntokens=1026, nsentences=32, sample_size=1026, sample_size_v1=0, sample_size_v2=0, ppl=2.35, wps=268.6, ups=0.26, wpb=1026, bsz=32, num_updates=26250, lr=5.2638e-06, gnorm=13.221, clip=100, loss_scale=16, train_wall=38, gb_free=9, wall=101322
2023-05-21 22:06:43 - progress_bar.py[line:272] - INFO: epoch 016:    328 / 1732 loss=2.452, loss_v1=0, loss_v2=0, nll_loss=1.26, ntokens=1009.5, nsentences=32, sample_size=1009.5, sample_size_v1=0, sample_size_v2=0, ppl=2.39, wps=264.8, ups=0.26, wpb=1009.5, bsz=32, num_updates=26260, lr=5.26176e-06, gnorm=13.984, clip=100, loss_scale=16, train_wall=38, gb_free=8.9, wall=101360
2023-05-21 22:07:21 - progress_bar.py[line:272] - INFO: epoch 016:    338 / 1732 loss=2.402, loss_v1=0, loss_v2=0, nll_loss=1.202, ntokens=991.1, nsentences=32, sample_size=991.1, sample_size_v1=0, sample_size_v2=0, ppl=2.3, wps=259.1, ups=0.26, wpb=991.1, bsz=32, num_updates=26270, lr=5.25971e-06, gnorm=13.422, clip=100, loss_scale=16, train_wall=38, gb_free=8.9, wall=101398
2023-05-21 22:07:59 - progress_bar.py[line:272] - INFO: epoch 016:    348 / 1732 loss=2.416, loss_v1=0, loss_v2=0, nll_loss=1.218, ntokens=913.6, nsentences=32, sample_size=913.6, sample_size_v1=0, sample_size_v2=0, ppl=2.33, wps=239.6, ups=0.26, wpb=913.6, bsz=32, num_updates=26280, lr=5.25766e-06, gnorm=13.927, clip=100, loss_scale=16, train_wall=38, gb_free=8.8, wall=101436
2023-05-21 22:08:37 - progress_bar.py[line:272] - INFO: epoch 016:    358 / 1732 loss=2.446, loss_v1=0, loss_v2=0, nll_loss=1.252, ntokens=943, nsentences=32, sample_size=943, sample_size_v1=0, sample_size_v2=0, ppl=2.38, wps=247.6, ups=0.26, wpb=943, bsz=32, num_updates=26290, lr=5.25561e-06, gnorm=14.725, clip=100, loss_scale=16, train_wall=38, gb_free=9.1, wall=101474
2023-05-21 22:09:15 - progress_bar.py[line:272] - INFO: epoch 016:    368 / 1732 loss=2.454, loss_v1=0, loss_v2=0, nll_loss=1.262, ntokens=960.6, nsentences=32, sample_size=960.6, sample_size_v1=0, sample_size_v2=0, ppl=2.4, wps=252.6, ups=0.26, wpb=960.6, bsz=32, num_updates=26300, lr=5.25357e-06, gnorm=15.04, clip=100, loss_scale=16, train_wall=38, gb_free=8.6, wall=101512
2023-05-21 22:09:53 - progress_bar.py[line:272] - INFO: epoch 016:    378 / 1732 loss=2.463, loss_v1=0, loss_v2=0, nll_loss=1.272, ntokens=1043.2, nsentences=32, sample_size=1043.2, sample_size_v1=0, sample_size_v2=0, ppl=2.41, wps=273.3, ups=0.26, wpb=1043.2, bsz=32, num_updates=26310, lr=5.25152e-06, gnorm=13.345, clip=100, loss_scale=16, train_wall=38, gb_free=9.1, wall=101550
2023-05-21 22:10:31 - progress_bar.py[line:272] - INFO: epoch 016:    388 / 1732 loss=2.418, loss_v1=0, loss_v2=0, nll_loss=1.219, ntokens=1053.2, nsentences=32, sample_size=1053.2, sample_size_v1=0, sample_size_v2=0, ppl=2.33, wps=276.5, ups=0.26, wpb=1053.2, bsz=32, num_updates=26320, lr=5.24947e-06, gnorm=14.813, clip=100, loss_scale=16, train_wall=38, gb_free=8.3, wall=101589
2023-05-21 22:11:10 - progress_bar.py[line:272] - INFO: epoch 016:    398 / 1732 loss=2.435, loss_v1=0, loss_v2=0, nll_loss=1.238, ntokens=977.4, nsentences=32, sample_size=977.4, sample_size_v1=0, sample_size_v2=0, ppl=2.36, wps=256, ups=0.26, wpb=977.4, bsz=32, num_updates=26330, lr=5.24743e-06, gnorm=14.709, clip=100, loss_scale=16, train_wall=38, gb_free=8, wall=101627
2023-05-21 22:11:48 - progress_bar.py[line:272] - INFO: epoch 016:    408 / 1732 loss=2.416, loss_v1=0, loss_v2=0, nll_loss=1.218, ntokens=1058.6, nsentences=32, sample_size=1058.6, sample_size_v1=0, sample_size_v2=0, ppl=2.33, wps=277.2, ups=0.26, wpb=1058.6, bsz=32, num_updates=26340, lr=5.24538e-06, gnorm=12.754, clip=100, loss_scale=16, train_wall=38, gb_free=8.6, wall=101665
2023-05-21 22:12:26 - progress_bar.py[line:272] - INFO: epoch 016:    418 / 1732 loss=2.386, loss_v1=0, loss_v2=0, nll_loss=1.186, ntokens=1021.6, nsentences=32, sample_size=1021.6, sample_size_v1=0, sample_size_v2=0, ppl=2.28, wps=266.9, ups=0.26, wpb=1021.6, bsz=32, num_updates=26350, lr=5.24333e-06, gnorm=14.25, clip=100, loss_scale=16, train_wall=38, gb_free=8, wall=101703
2023-05-21 22:13:04 - progress_bar.py[line:272] - INFO: epoch 016:    428 / 1732 loss=2.399, loss_v1=0, loss_v2=0, nll_loss=1.202, ntokens=1016.5, nsentences=32, sample_size=1016.5, sample_size_v1=0, sample_size_v2=0, ppl=2.3, wps=266.6, ups=0.26, wpb=1016.5, bsz=32, num_updates=26360, lr=5.24128e-06, gnorm=15.535, clip=100, loss_scale=16, train_wall=38, gb_free=8.5, wall=101741
2023-05-21 22:13:42 - progress_bar.py[line:272] - INFO: epoch 016:    438 / 1732 loss=2.425, loss_v1=0, loss_v2=0, nll_loss=1.229, ntokens=1018.5, nsentences=32, sample_size=1018.5, sample_size_v1=0, sample_size_v2=0, ppl=2.34, wps=267.8, ups=0.26, wpb=1018.5, bsz=32, num_updates=26370, lr=5.23924e-06, gnorm=13.449, clip=100, loss_scale=16, train_wall=38, gb_free=8.9, wall=101779
2023-05-21 22:14:20 - progress_bar.py[line:272] - INFO: epoch 016:    448 / 1732 loss=2.449, loss_v1=0, loss_v2=0, nll_loss=1.255, ntokens=946.6, nsentences=32, sample_size=946.6, sample_size_v1=0, sample_size_v2=0, ppl=2.39, wps=248.5, ups=0.26, wpb=946.6, bsz=32, num_updates=26380, lr=5.23719e-06, gnorm=15.828, clip=100, loss_scale=16, train_wall=38, gb_free=8.6, wall=101818
2023-05-21 22:14:58 - progress_bar.py[line:272] - INFO: epoch 016:    458 / 1732 loss=2.441, loss_v1=0, loss_v2=0, nll_loss=1.246, ntokens=971.2, nsentences=32, sample_size=971.2, sample_size_v1=0, sample_size_v2=0, ppl=2.37, wps=255.9, ups=0.26, wpb=971.2, bsz=32, num_updates=26390, lr=5.23514e-06, gnorm=14.84, clip=100, loss_scale=16, train_wall=38, gb_free=8.9, wall=101855
2023-05-21 22:15:37 - progress_bar.py[line:272] - INFO: epoch 016:    468 / 1732 loss=2.436, loss_v1=0, loss_v2=0, nll_loss=1.24, ntokens=1064.3, nsentences=32, sample_size=1064.3, sample_size_v1=0, sample_size_v2=0, ppl=2.36, wps=276.3, ups=0.26, wpb=1064.3, bsz=32, num_updates=26400, lr=5.23309e-06, gnorm=12.564, clip=100, loss_scale=16, train_wall=38, gb_free=8.3, wall=101894
2023-05-21 22:16:15 - progress_bar.py[line:272] - INFO: epoch 016:    478 / 1732 loss=2.462, loss_v1=0, loss_v2=0, nll_loss=1.268, ntokens=1027.7, nsentences=32, sample_size=1027.7, sample_size_v1=0, sample_size_v2=0, ppl=2.41, wps=269, ups=0.26, wpb=1027.7, bsz=32, num_updates=26410, lr=5.23105e-06, gnorm=14.056, clip=100, loss_scale=16, train_wall=38, gb_free=8.9, wall=101932
2023-05-21 22:16:53 - progress_bar.py[line:272] - INFO: epoch 016:    488 / 1732 loss=2.398, loss_v1=0, loss_v2=0, nll_loss=1.198, ntokens=925.6, nsentences=32, sample_size=925.6, sample_size_v1=0, sample_size_v2=0, ppl=2.29, wps=245, ups=0.26, wpb=925.6, bsz=32, num_updates=26420, lr=5.229e-06, gnorm=14.825, clip=100, loss_scale=16, train_wall=38, gb_free=9.2, wall=101970
2023-05-21 22:17:31 - progress_bar.py[line:272] - INFO: epoch 016:    498 / 1732 loss=2.423, loss_v1=0, loss_v2=0, nll_loss=1.228, ntokens=952.7, nsentences=32, sample_size=952.7, sample_size_v1=0, sample_size_v2=0, ppl=2.34, wps=250.7, ups=0.26, wpb=952.7, bsz=32, num_updates=26430, lr=5.22695e-06, gnorm=14.169, clip=100, loss_scale=16, train_wall=38, gb_free=9.3, wall=102008
2023-05-21 22:18:09 - progress_bar.py[line:272] - INFO: epoch 016:    508 / 1732 loss=2.434, loss_v1=0, loss_v2=0, nll_loss=1.239, ntokens=1034.3, nsentences=32, sample_size=1034.3, sample_size_v1=0, sample_size_v2=0, ppl=2.36, wps=272.3, ups=0.26, wpb=1034.3, bsz=32, num_updates=26440, lr=5.2249e-06, gnorm=13.04, clip=100, loss_scale=16, train_wall=38, gb_free=8.7, wall=102046
2023-05-21 22:18:47 - progress_bar.py[line:272] - INFO: epoch 016:    518 / 1732 loss=2.426, loss_v1=0, loss_v2=0, nll_loss=1.231, ntokens=1032.2, nsentences=32, sample_size=1032.2, sample_size_v1=0, sample_size_v2=0, ppl=2.35, wps=271.8, ups=0.26, wpb=1032.2, bsz=32, num_updates=26450, lr=5.22286e-06, gnorm=13.497, clip=100, loss_scale=32, train_wall=38, gb_free=8.9, wall=102084
2023-05-21 22:19:25 - progress_bar.py[line:272] - INFO: epoch 016:    528 / 1732 loss=2.432, loss_v1=0, loss_v2=0, nll_loss=1.237, ntokens=941.1, nsentences=32, sample_size=941.1, sample_size_v1=0, sample_size_v2=0, ppl=2.36, wps=249, ups=0.26, wpb=941.1, bsz=32, num_updates=26460, lr=5.22081e-06, gnorm=15.19, clip=100, loss_scale=32, train_wall=38, gb_free=9.1, wall=102122
2023-05-21 22:20:03 - progress_bar.py[line:272] - INFO: epoch 016:    538 / 1732 loss=2.418, loss_v1=0, loss_v2=0, nll_loss=1.22, ntokens=972.3, nsentences=32, sample_size=972.3, sample_size_v1=0, sample_size_v2=0, ppl=2.33, wps=255.8, ups=0.26, wpb=972.3, bsz=32, num_updates=26470, lr=5.21876e-06, gnorm=15.661, clip=100, loss_scale=32, train_wall=38, gb_free=8.4, wall=102160
2023-05-21 22:20:41 - progress_bar.py[line:272] - INFO: epoch 016:    548 / 1732 loss=2.452, loss_v1=0, loss_v2=0, nll_loss=1.258, ntokens=1027.8, nsentences=32, sample_size=1027.8, sample_size_v1=0, sample_size_v2=0, ppl=2.39, wps=270, ups=0.26, wpb=1027.8, bsz=32, num_updates=26480, lr=5.21671e-06, gnorm=13.964, clip=100, loss_scale=32, train_wall=38, gb_free=8.9, wall=102198
2023-05-21 22:21:19 - progress_bar.py[line:272] - INFO: epoch 016:    558 / 1732 loss=2.454, loss_v1=0, loss_v2=0, nll_loss=1.261, ntokens=1021.9, nsentences=32, sample_size=1021.9, sample_size_v1=0, sample_size_v2=0, ppl=2.4, wps=268.9, ups=0.26, wpb=1021.9, bsz=32, num_updates=26490, lr=5.21467e-06, gnorm=14.432, clip=100, loss_scale=32, train_wall=38, gb_free=8, wall=102236
2023-05-21 22:21:57 - progress_bar.py[line:272] - INFO: epoch 016:    568 / 1732 loss=2.473, loss_v1=0, loss_v2=0, nll_loss=1.283, ntokens=1014.9, nsentences=32, sample_size=1014.9, sample_size_v1=0, sample_size_v2=0, ppl=2.43, wps=266, ups=0.26, wpb=1014.9, bsz=32, num_updates=26500, lr=5.21262e-06, gnorm=14.4, clip=100, loss_scale=32, train_wall=38, gb_free=8.3, wall=102274
2023-05-21 22:22:35 - progress_bar.py[line:272] - INFO: epoch 016:    578 / 1732 loss=2.43, loss_v1=0, loss_v2=0, nll_loss=1.234, ntokens=991.4, nsentences=32, sample_size=991.4, sample_size_v1=0, sample_size_v2=0, ppl=2.35, wps=259.7, ups=0.26, wpb=991.4, bsz=32, num_updates=26510, lr=5.21057e-06, gnorm=15.206, clip=100, loss_scale=32, train_wall=38, gb_free=8.3, wall=102312
2023-05-21 22:23:13 - progress_bar.py[line:272] - INFO: epoch 016:    588 / 1732 loss=2.431, loss_v1=0, loss_v2=0, nll_loss=1.234, ntokens=965.9, nsentences=32, sample_size=965.9, sample_size_v1=0, sample_size_v2=0, ppl=2.35, wps=251.6, ups=0.26, wpb=965.9, bsz=32, num_updates=26520, lr=5.20853e-06, gnorm=15.542, clip=100, loss_scale=32, train_wall=38, gb_free=8.7, wall=102351
2023-05-21 22:23:51 - progress_bar.py[line:272] - INFO: epoch 016:    598 / 1732 loss=2.399, loss_v1=0, loss_v2=0, nll_loss=1.2, ntokens=957.4, nsentences=32, sample_size=957.4, sample_size_v1=0, sample_size_v2=0, ppl=2.3, wps=251.4, ups=0.26, wpb=957.4, bsz=32, num_updates=26530, lr=5.20648e-06, gnorm=15.589, clip=100, loss_scale=32, train_wall=38, gb_free=9.2, wall=102389
2023-05-21 22:24:30 - progress_bar.py[line:272] - INFO: epoch 016:    608 / 1732 loss=2.423, loss_v1=0, loss_v2=0, nll_loss=1.227, ntokens=893.5, nsentences=32, sample_size=893.5, sample_size_v1=0, sample_size_v2=0, ppl=2.34, wps=234.9, ups=0.26, wpb=893.5, bsz=32, num_updates=26540, lr=5.20443e-06, gnorm=16.57, clip=100, loss_scale=32, train_wall=38, gb_free=8.3, wall=102427
2023-05-21 22:25:07 - progress_bar.py[line:272] - INFO: epoch 016:    618 / 1732 loss=2.451, loss_v1=0, loss_v2=0, nll_loss=1.26, ntokens=860.2, nsentences=32, sample_size=860.2, sample_size_v1=0, sample_size_v2=0, ppl=2.39, wps=227.1, ups=0.26, wpb=860.2, bsz=32, num_updates=26550, lr=5.20238e-06, gnorm=17.339, clip=100, loss_scale=32, train_wall=38, gb_free=9, wall=102465
2023-05-21 22:25:45 - progress_bar.py[line:272] - INFO: epoch 016:    628 / 1732 loss=2.427, loss_v1=0, loss_v2=0, nll_loss=1.231, ntokens=929, nsentences=32, sample_size=929, sample_size_v1=0, sample_size_v2=0, ppl=2.35, wps=246.6, ups=0.27, wpb=929, bsz=32, num_updates=26560, lr=5.20034e-06, gnorm=16.094, clip=100, loss_scale=32, train_wall=38, gb_free=9, wall=102502
2023-05-21 22:26:23 - progress_bar.py[line:272] - INFO: epoch 016:    638 / 1732 loss=2.444, loss_v1=0, loss_v2=0, nll_loss=1.25, ntokens=921.3, nsentences=32, sample_size=921.3, sample_size_v1=0, sample_size_v2=0, ppl=2.38, wps=243.4, ups=0.26, wpb=921.3, bsz=32, num_updates=26570, lr=5.19829e-06, gnorm=17.327, clip=100, loss_scale=32, train_wall=38, gb_free=9, wall=102540
2023-05-21 22:27:01 - progress_bar.py[line:272] - INFO: epoch 016:    648 / 1732 loss=2.453, loss_v1=0, loss_v2=0, nll_loss=1.26, ntokens=983.5, nsentences=32, sample_size=983.5, sample_size_v1=0, sample_size_v2=0, ppl=2.4, wps=259.1, ups=0.26, wpb=983.5, bsz=32, num_updates=26580, lr=5.19624e-06, gnorm=16.127, clip=100, loss_scale=32, train_wall=38, gb_free=8.8, wall=102578
2023-05-21 22:27:39 - progress_bar.py[line:272] - INFO: epoch 016:    658 / 1732 loss=2.446, loss_v1=0, loss_v2=0, nll_loss=1.252, ntokens=892.2, nsentences=32, sample_size=892.2, sample_size_v1=0, sample_size_v2=0, ppl=2.38, wps=236.8, ups=0.27, wpb=892.2, bsz=32, num_updates=26590, lr=5.19419e-06, gnorm=16.492, clip=100, loss_scale=32, train_wall=38, gb_free=8.6, wall=102616
2023-05-21 22:28:16 - progress_bar.py[line:272] - INFO: epoch 016:    668 / 1732 loss=2.439, loss_v1=0, loss_v2=0, nll_loss=1.244, ntokens=910, nsentences=32, sample_size=910, sample_size_v1=0, sample_size_v2=0, ppl=2.37, wps=241.3, ups=0.27, wpb=910, bsz=32, num_updates=26600, lr=5.19215e-06, gnorm=16.353, clip=100, loss_scale=32, train_wall=38, gb_free=8.2, wall=102653
2023-05-21 22:28:54 - progress_bar.py[line:272] - INFO: epoch 016:    678 / 1732 loss=2.442, loss_v1=0, loss_v2=0, nll_loss=1.248, ntokens=980.2, nsentences=32, sample_size=980.2, sample_size_v1=0, sample_size_v2=0, ppl=2.38, wps=258.2, ups=0.26, wpb=980.2, bsz=32, num_updates=26610, lr=5.1901e-06, gnorm=15.628, clip=100, loss_scale=32, train_wall=38, gb_free=8.8, wall=102691
2023-05-21 22:29:32 - progress_bar.py[line:272] - INFO: epoch 016:    688 / 1732 loss=2.441, loss_v1=0, loss_v2=0, nll_loss=1.246, ntokens=942, nsentences=32, sample_size=942, sample_size_v1=0, sample_size_v2=0, ppl=2.37, wps=247.5, ups=0.26, wpb=942, bsz=32, num_updates=26620, lr=5.18805e-06, gnorm=16.617, clip=100, loss_scale=32, train_wall=38, gb_free=9, wall=102730
2023-05-21 22:30:10 - progress_bar.py[line:272] - INFO: epoch 016:    698 / 1732 loss=2.43, loss_v1=0, loss_v2=0, nll_loss=1.232, ntokens=1001.9, nsentences=32, sample_size=1001.9, sample_size_v1=0, sample_size_v2=0, ppl=2.35, wps=262.9, ups=0.26, wpb=1001.9, bsz=32, num_updates=26630, lr=5.186e-06, gnorm=15.004, clip=100, loss_scale=32, train_wall=38, gb_free=8.9, wall=102768
2023-05-21 22:30:48 - progress_bar.py[line:272] - INFO: epoch 016:    708 / 1732 loss=2.434, loss_v1=0, loss_v2=0, nll_loss=1.237, ntokens=907.1, nsentences=32, sample_size=907.1, sample_size_v1=0, sample_size_v2=0, ppl=2.36, wps=239.8, ups=0.26, wpb=907.1, bsz=32, num_updates=26640, lr=5.18396e-06, gnorm=15.868, clip=100, loss_scale=32, train_wall=38, gb_free=8.9, wall=102805
2023-05-21 22:31:26 - progress_bar.py[line:272] - INFO: epoch 016:    718 / 1732 loss=2.429, loss_v1=0, loss_v2=0, nll_loss=1.231, ntokens=882, nsentences=32, sample_size=882, sample_size_v1=0, sample_size_v2=0, ppl=2.35, wps=232.8, ups=0.26, wpb=882, bsz=32, num_updates=26650, lr=5.18191e-06, gnorm=15.139, clip=100, loss_scale=32, train_wall=38, gb_free=9.3, wall=102843
2023-05-21 22:32:04 - progress_bar.py[line:272] - INFO: epoch 016:    728 / 1732 loss=2.4, loss_v1=0, loss_v2=0, nll_loss=1.201, ntokens=917.5, nsentences=32, sample_size=917.5, sample_size_v1=0, sample_size_v2=0, ppl=2.3, wps=241.9, ups=0.26, wpb=917.5, bsz=32, num_updates=26660, lr=5.17986e-06, gnorm=15.679, clip=100, loss_scale=32, train_wall=38, gb_free=8.7, wall=102881
2023-05-21 22:32:42 - progress_bar.py[line:272] - INFO: epoch 016:    738 / 1732 loss=2.415, loss_v1=0, loss_v2=0, nll_loss=1.219, ntokens=991.8, nsentences=32, sample_size=991.8, sample_size_v1=0, sample_size_v2=0, ppl=2.33, wps=261.5, ups=0.26, wpb=991.8, bsz=32, num_updates=26670, lr=5.17781e-06, gnorm=14.871, clip=100, loss_scale=32, train_wall=38, gb_free=8.9, wall=102919
2023-05-21 22:33:20 - progress_bar.py[line:272] - INFO: epoch 016:    748 / 1732 loss=2.421, loss_v1=0, loss_v2=0, nll_loss=1.226, ntokens=986.3, nsentences=32, sample_size=986.3, sample_size_v1=0, sample_size_v2=0, ppl=2.34, wps=257.8, ups=0.26, wpb=986.3, bsz=32, num_updates=26680, lr=5.17577e-06, gnorm=15.184, clip=100, loss_scale=32, train_wall=38, gb_free=8.8, wall=102957
2023-05-21 22:33:58 - progress_bar.py[line:272] - INFO: epoch 016:    758 / 1732 loss=2.409, loss_v1=0, loss_v2=0, nll_loss=1.211, ntokens=946.6, nsentences=32, sample_size=946.6, sample_size_v1=0, sample_size_v2=0, ppl=2.32, wps=249.1, ups=0.26, wpb=946.6, bsz=32, num_updates=26690, lr=5.17372e-06, gnorm=15.085, clip=100, loss_scale=32, train_wall=38, gb_free=8.6, wall=102995
2023-05-21 22:34:36 - progress_bar.py[line:272] - INFO: epoch 016:    768 / 1732 loss=2.421, loss_v1=0, loss_v2=0, nll_loss=1.225, ntokens=947.6, nsentences=32, sample_size=947.6, sample_size_v1=0, sample_size_v2=0, ppl=2.34, wps=249.7, ups=0.26, wpb=947.6, bsz=32, num_updates=26700, lr=5.17167e-06, gnorm=15.591, clip=100, loss_scale=32, train_wall=38, gb_free=8.5, wall=103033
2023-05-21 22:35:14 - progress_bar.py[line:272] - INFO: epoch 016:    778 / 1732 loss=2.428, loss_v1=0, loss_v2=0, nll_loss=1.233, ntokens=1017.6, nsentences=32, sample_size=1017.6, sample_size_v1=0, sample_size_v2=0, ppl=2.35, wps=266.4, ups=0.26, wpb=1017.6, bsz=32, num_updates=26710, lr=5.16963e-06, gnorm=15.997, clip=100, loss_scale=32, train_wall=38, gb_free=9.2, wall=103072
2023-05-21 22:35:52 - progress_bar.py[line:272] - INFO: epoch 016:    788 / 1732 loss=2.421, loss_v1=0, loss_v2=0, nll_loss=1.225, ntokens=1010.8, nsentences=32, sample_size=1010.8, sample_size_v1=0, sample_size_v2=0, ppl=2.34, wps=265.9, ups=0.26, wpb=1010.8, bsz=32, num_updates=26720, lr=5.16758e-06, gnorm=14.947, clip=100, loss_scale=32, train_wall=38, gb_free=8.4, wall=103110
2023-05-21 22:36:30 - progress_bar.py[line:272] - INFO: epoch 016:    798 / 1732 loss=2.413, loss_v1=0, loss_v2=0, nll_loss=1.216, ntokens=1050, nsentences=32, sample_size=1050, sample_size_v1=0, sample_size_v2=0, ppl=2.32, wps=276.2, ups=0.26, wpb=1050, bsz=32, num_updates=26730, lr=5.16553e-06, gnorm=14.718, clip=100, loss_scale=32, train_wall=38, gb_free=8.8, wall=103148
2023-05-21 22:37:08 - progress_bar.py[line:272] - INFO: epoch 016:    808 / 1732 loss=2.427, loss_v1=0, loss_v2=0, nll_loss=1.231, ntokens=907.2, nsentences=32, sample_size=907.2, sample_size_v1=0, sample_size_v2=0, ppl=2.35, wps=239.2, ups=0.26, wpb=907.2, bsz=32, num_updates=26740, lr=5.16348e-06, gnorm=17.52, clip=100, loss_scale=32, train_wall=38, gb_free=8.8, wall=103186
2023-05-21 22:37:46 - progress_bar.py[line:272] - INFO: epoch 016:    818 / 1732 loss=2.44, loss_v1=0, loss_v2=0, nll_loss=1.247, ntokens=917.4, nsentences=32, sample_size=917.4, sample_size_v1=0, sample_size_v2=0, ppl=2.37, wps=240.8, ups=0.26, wpb=917.4, bsz=32, num_updates=26750, lr=5.16144e-06, gnorm=16.296, clip=100, loss_scale=32, train_wall=38, gb_free=8.7, wall=103224
2023-05-21 22:38:25 - progress_bar.py[line:272] - INFO: epoch 016:    828 / 1732 loss=2.425, loss_v1=0, loss_v2=0, nll_loss=1.227, ntokens=929.3, nsentences=32, sample_size=929.3, sample_size_v1=0, sample_size_v2=0, ppl=2.34, wps=243.9, ups=0.26, wpb=929.3, bsz=32, num_updates=26760, lr=5.15939e-06, gnorm=15.312, clip=100, loss_scale=32, train_wall=38, gb_free=9, wall=103262
2023-05-21 22:39:02 - progress_bar.py[line:272] - INFO: epoch 016:    838 / 1732 loss=2.425, loss_v1=0, loss_v2=0, nll_loss=1.227, ntokens=901, nsentences=32, sample_size=901, sample_size_v1=0, sample_size_v2=0, ppl=2.34, wps=239, ups=0.27, wpb=901, bsz=32, num_updates=26770, lr=5.15734e-06, gnorm=16.22, clip=100, loss_scale=32, train_wall=38, gb_free=8.9, wall=103299
2023-05-21 22:39:40 - progress_bar.py[line:272] - INFO: epoch 016:    848 / 1732 loss=2.41, loss_v1=0, loss_v2=0, nll_loss=1.211, ntokens=1016.3, nsentences=32, sample_size=1016.3, sample_size_v1=0, sample_size_v2=0, ppl=2.32, wps=266.6, ups=0.26, wpb=1016.3, bsz=32, num_updates=26780, lr=5.15529e-06, gnorm=14.373, clip=100, loss_scale=32, train_wall=38, gb_free=7.9, wall=103338
2023-05-21 22:40:18 - progress_bar.py[line:272] - INFO: epoch 016:    858 / 1732 loss=2.423, loss_v1=0, loss_v2=0, nll_loss=1.227, ntokens=923.8, nsentences=32, sample_size=923.8, sample_size_v1=0, sample_size_v2=0, ppl=2.34, wps=245.2, ups=0.27, wpb=923.8, bsz=32, num_updates=26790, lr=5.15325e-06, gnorm=15.2, clip=100, loss_scale=32, train_wall=38, gb_free=8.8, wall=103375
2023-05-21 22:40:56 - progress_bar.py[line:272] - INFO: epoch 016:    868 / 1732 loss=2.435, loss_v1=0, loss_v2=0, nll_loss=1.24, ntokens=966.1, nsentences=32, sample_size=966.1, sample_size_v1=0, sample_size_v2=0, ppl=2.36, wps=254.5, ups=0.26, wpb=966.1, bsz=32, num_updates=26800, lr=5.1512e-06, gnorm=15.089, clip=100, loss_scale=32, train_wall=38, gb_free=8.9, wall=103413
2023-05-21 22:41:34 - progress_bar.py[line:272] - INFO: epoch 016:    878 / 1732 loss=2.356, loss_v1=0, loss_v2=0, nll_loss=1.153, ntokens=1016.8, nsentences=32, sample_size=1016.8, sample_size_v1=0, sample_size_v2=0, ppl=2.22, wps=266.9, ups=0.26, wpb=1016.8, bsz=32, num_updates=26810, lr=5.14915e-06, gnorm=13.155, clip=100, loss_scale=32, train_wall=38, gb_free=8.7, wall=103451
2023-05-21 22:42:12 - progress_bar.py[line:272] - INFO: epoch 016:    888 / 1732 loss=2.38, loss_v1=0, loss_v2=0, nll_loss=1.179, ntokens=961.8, nsentences=32, sample_size=961.8, sample_size_v1=0, sample_size_v2=0, ppl=2.26, wps=253, ups=0.26, wpb=961.8, bsz=32, num_updates=26820, lr=5.1471e-06, gnorm=14.343, clip=100, loss_scale=32, train_wall=38, gb_free=8.7, wall=103489
2023-05-21 22:42:50 - progress_bar.py[line:272] - INFO: epoch 016:    898 / 1732 loss=2.355, loss_v1=0, loss_v2=0, nll_loss=1.15, ntokens=1063.3, nsentences=32, sample_size=1063.3, sample_size_v1=0, sample_size_v2=0, ppl=2.22, wps=277.9, ups=0.26, wpb=1063.3, bsz=32, num_updates=26830, lr=5.14506e-06, gnorm=14.03, clip=100, loss_scale=32, train_wall=38, gb_free=8.2, wall=103528
2023-05-21 22:43:29 - progress_bar.py[line:272] - INFO: epoch 016:    908 / 1732 loss=2.384, loss_v1=0, loss_v2=0, nll_loss=1.183, ntokens=987.4, nsentences=32, sample_size=987.4, sample_size_v1=0, sample_size_v2=0, ppl=2.27, wps=259.3, ups=0.26, wpb=987.4, bsz=32, num_updates=26840, lr=5.14301e-06, gnorm=14.009, clip=100, loss_scale=32, train_wall=38, gb_free=8.8, wall=103566
2023-05-21 22:44:07 - progress_bar.py[line:272] - INFO: epoch 016:    918 / 1732 loss=2.45, loss_v1=0, loss_v2=0, nll_loss=1.257, ntokens=968, nsentences=32, sample_size=968, sample_size_v1=0, sample_size_v2=0, ppl=2.39, wps=254.1, ups=0.26, wpb=968, bsz=32, num_updates=26850, lr=5.14096e-06, gnorm=15.541, clip=100, loss_scale=32, train_wall=38, gb_free=7.8, wall=103604
2023-05-21 22:44:45 - progress_bar.py[line:272] - INFO: epoch 016:    928 / 1732 loss=2.386, loss_v1=0, loss_v2=0, nll_loss=1.185, ntokens=1026.7, nsentences=32, sample_size=1026.7, sample_size_v1=0, sample_size_v2=0, ppl=2.27, wps=266.3, ups=0.26, wpb=1026.7, bsz=32, num_updates=26860, lr=5.13891e-06, gnorm=14.055, clip=100, loss_scale=32, train_wall=39, gb_free=8.5, wall=103642
2023-05-21 22:45:24 - progress_bar.py[line:272] - INFO: epoch 016:    938 / 1732 loss=2.398, loss_v1=0, loss_v2=0, nll_loss=1.197, ntokens=1050.3, nsentences=32, sample_size=1050.3, sample_size_v1=0, sample_size_v2=0, ppl=2.29, wps=271.1, ups=0.26, wpb=1050.3, bsz=32, num_updates=26870, lr=5.13687e-06, gnorm=13.692, clip=100, loss_scale=32, train_wall=39, gb_free=7.7, wall=103681
2023-05-21 22:46:03 - progress_bar.py[line:272] - INFO: epoch 016:    948 / 1732 loss=2.406, loss_v1=0, loss_v2=0, nll_loss=1.206, ntokens=1031, nsentences=32, sample_size=1031, sample_size_v1=0, sample_size_v2=0, ppl=2.31, wps=266.2, ups=0.26, wpb=1031, bsz=32, num_updates=26880, lr=5.13482e-06, gnorm=13.434, clip=100, loss_scale=32, train_wall=39, gb_free=8.7, wall=103720
2023-05-21 22:46:41 - progress_bar.py[line:272] - INFO: epoch 016:    958 / 1732 loss=2.39, loss_v1=0, loss_v2=0, nll_loss=1.19, ntokens=1072.9, nsentences=32, sample_size=1072.9, sample_size_v1=0, sample_size_v2=0, ppl=2.28, wps=277.5, ups=0.26, wpb=1072.9, bsz=32, num_updates=26890, lr=5.13277e-06, gnorm=13.634, clip=100, loss_scale=32, train_wall=39, gb_free=8.3, wall=103759
2023-05-21 22:47:20 - progress_bar.py[line:272] - INFO: epoch 016:    968 / 1732 loss=2.425, loss_v1=0, loss_v2=0, nll_loss=1.23, ntokens=1015.7, nsentences=32, sample_size=1015.7, sample_size_v1=0, sample_size_v2=0, ppl=2.35, wps=264.1, ups=0.26, wpb=1015.7, bsz=32, num_updates=26900, lr=5.13072e-06, gnorm=15.462, clip=100, loss_scale=32, train_wall=38, gb_free=8.9, wall=103797
2023-05-21 22:47:59 - progress_bar.py[line:272] - INFO: epoch 016:    978 / 1732 loss=2.401, loss_v1=0, loss_v2=0, nll_loss=1.204, ntokens=1036.8, nsentences=32, sample_size=1036.8, sample_size_v1=0, sample_size_v2=0, ppl=2.3, wps=266.9, ups=0.26, wpb=1036.8, bsz=32, num_updates=26910, lr=5.12868e-06, gnorm=13.454, clip=100, loss_scale=32, train_wall=39, gb_free=9, wall=103836
2023-05-21 22:48:37 - progress_bar.py[line:272] - INFO: epoch 016:    988 / 1732 loss=2.398, loss_v1=0, loss_v2=0, nll_loss=1.2, ntokens=1050.5, nsentences=32, sample_size=1050.5, sample_size_v1=0, sample_size_v2=0, ppl=2.3, wps=271.9, ups=0.26, wpb=1050.5, bsz=32, num_updates=26920, lr=5.12663e-06, gnorm=15.072, clip=100, loss_scale=32, train_wall=39, gb_free=7.9, wall=103874
2023-05-21 22:49:16 - progress_bar.py[line:272] - INFO: epoch 016:    998 / 1732 loss=2.397, loss_v1=0, loss_v2=0, nll_loss=1.197, ntokens=1000, nsentences=32, sample_size=1000, sample_size_v1=0, sample_size_v2=0, ppl=2.29, wps=260, ups=0.26, wpb=1000, bsz=32, num_updates=26930, lr=5.12458e-06, gnorm=14.115, clip=100, loss_scale=32, train_wall=38, gb_free=8.4, wall=103913
2023-05-21 22:49:54 - progress_bar.py[line:272] - INFO: epoch 016:   1008 / 1732 loss=2.393, loss_v1=0, loss_v2=0, nll_loss=1.192, ntokens=1026.8, nsentences=32, sample_size=1026.8, sample_size_v1=0, sample_size_v2=0, ppl=2.28, wps=266.3, ups=0.26, wpb=1026.8, bsz=32, num_updates=26940, lr=5.12254e-06, gnorm=13.942, clip=100, loss_scale=32, train_wall=39, gb_free=7.4, wall=103952
2023-05-21 22:50:33 - progress_bar.py[line:272] - INFO: epoch 016:   1018 / 1732 loss=2.376, loss_v1=0, loss_v2=0, nll_loss=1.173, ntokens=1036.8, nsentences=32, sample_size=1036.8, sample_size_v1=0, sample_size_v2=0, ppl=2.26, wps=269.7, ups=0.26, wpb=1036.8, bsz=32, num_updates=26950, lr=5.12049e-06, gnorm=14.803, clip=100, loss_scale=32, train_wall=38, gb_free=8.4, wall=103990
2023-05-21 22:51:12 - progress_bar.py[line:272] - INFO: epoch 016:   1028 / 1732 loss=2.408, loss_v1=0, loss_v2=0, nll_loss=1.21, ntokens=1060.8, nsentences=32, sample_size=1060.8, sample_size_v1=0, sample_size_v2=0, ppl=2.31, wps=271.6, ups=0.26, wpb=1060.8, bsz=32, num_updates=26960, lr=5.11844e-06, gnorm=13.945, clip=100, loss_scale=64, train_wall=39, gb_free=7.3, wall=104029
2023-05-21 22:51:50 - progress_bar.py[line:272] - INFO: epoch 016:   1038 / 1732 loss=2.397, loss_v1=0, loss_v2=0, nll_loss=1.2, ntokens=1110, nsentences=32, sample_size=1110, sample_size_v1=0, sample_size_v2=0, ppl=2.3, wps=286.9, ups=0.26, wpb=1110, bsz=32, num_updates=26970, lr=5.11639e-06, gnorm=12.775, clip=100, loss_scale=64, train_wall=39, gb_free=8.9, wall=104068
2023-05-21 22:52:14 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2023-05-21 22:52:33 - progress_bar.py[line:272] - INFO: epoch 016:   1049 / 1732 loss=2.398, loss_v1=0, loss_v2=0, nll_loss=1.199, ntokens=1012.5, nsentences=32, sample_size=1012.5, sample_size_v1=0, sample_size_v2=0, ppl=2.3, wps=239.7, ups=0.24, wpb=1012.5, bsz=32, num_updates=26980, lr=5.11435e-06, gnorm=14.809, clip=100, loss_scale=32, train_wall=42, gb_free=8.7, wall=104110
2023-05-21 22:53:11 - progress_bar.py[line:272] - INFO: epoch 016:   1059 / 1732 loss=2.4, loss_v1=0, loss_v2=0, nll_loss=1.201, ntokens=1090.9, nsentences=32, sample_size=1090.9, sample_size_v1=0, sample_size_v2=0, ppl=2.3, wps=281.7, ups=0.26, wpb=1090.9, bsz=32, num_updates=26990, lr=5.1123e-06, gnorm=14.713, clip=100, loss_scale=32, train_wall=39, gb_free=8.6, wall=104149
2023-05-21 22:53:50 - progress_bar.py[line:272] - INFO: epoch 016:   1069 / 1732 loss=2.398, loss_v1=0, loss_v2=0, nll_loss=1.198, ntokens=979.2, nsentences=32, sample_size=979.2, sample_size_v1=0, sample_size_v2=0, ppl=2.29, wps=255.3, ups=0.26, wpb=979.2, bsz=32, num_updates=27000, lr=5.11025e-06, gnorm=14.256, clip=100, loss_scale=32, train_wall=38, gb_free=8.4, wall=104187
2023-05-21 22:54:29 - progress_bar.py[line:272] - INFO: epoch 016:   1079 / 1732 loss=2.417, loss_v1=0, loss_v2=0, nll_loss=1.22, ntokens=1044.7, nsentences=32, sample_size=1044.7, sample_size_v1=0, sample_size_v2=0, ppl=2.33, wps=268.5, ups=0.26, wpb=1044.7, bsz=32, num_updates=27010, lr=5.1082e-06, gnorm=14.121, clip=100, loss_scale=32, train_wall=39, gb_free=8.1, wall=104226
2023-05-21 22:55:08 - progress_bar.py[line:272] - INFO: epoch 016:   1089 / 1732 loss=2.387, loss_v1=0, loss_v2=0, nll_loss=1.186, ntokens=1065.4, nsentences=32, sample_size=1065.4, sample_size_v1=0, sample_size_v2=0, ppl=2.28, wps=273.7, ups=0.26, wpb=1065.4, bsz=32, num_updates=27020, lr=5.10616e-06, gnorm=14.679, clip=100, loss_scale=32, train_wall=39, gb_free=8.6, wall=104265
2023-05-21 22:55:46 - progress_bar.py[line:272] - INFO: epoch 016:   1099 / 1732 loss=2.403, loss_v1=0, loss_v2=0, nll_loss=1.204, ntokens=1034.8, nsentences=32, sample_size=1034.8, sample_size_v1=0, sample_size_v2=0, ppl=2.3, wps=267.5, ups=0.26, wpb=1034.8, bsz=32, num_updates=27030, lr=5.10411e-06, gnorm=15.957, clip=100, loss_scale=32, train_wall=39, gb_free=7.6, wall=104304
2023-05-21 22:56:25 - progress_bar.py[line:272] - INFO: epoch 016:   1109 / 1732 loss=2.398, loss_v1=0, loss_v2=0, nll_loss=1.199, ntokens=1058.4, nsentences=32, sample_size=1058.4, sample_size_v1=0, sample_size_v2=0, ppl=2.3, wps=272.7, ups=0.26, wpb=1058.4, bsz=32, num_updates=27040, lr=5.10206e-06, gnorm=13.499, clip=100, loss_scale=32, train_wall=39, gb_free=7.5, wall=104342
2023-05-21 22:57:04 - progress_bar.py[line:272] - INFO: epoch 016:   1119 / 1732 loss=2.409, loss_v1=0, loss_v2=0, nll_loss=1.209, ntokens=966, nsentences=32, sample_size=966, sample_size_v1=0, sample_size_v2=0, ppl=2.31, wps=250.5, ups=0.26, wpb=966, bsz=32, num_updates=27050, lr=5.10001e-06, gnorm=14.99, clip=100, loss_scale=32, train_wall=39, gb_free=8, wall=104381
2023-05-21 22:57:42 - progress_bar.py[line:272] - INFO: epoch 016:   1129 / 1732 loss=2.406, loss_v1=0, loss_v2=0, nll_loss=1.208, ntokens=1007.5, nsentences=32, sample_size=1007.5, sample_size_v1=0, sample_size_v2=0, ppl=2.31, wps=261.1, ups=0.26, wpb=1007.5, bsz=32, num_updates=27060, lr=5.09797e-06, gnorm=15.253, clip=100, loss_scale=32, train_wall=39, gb_free=8.7, wall=104420
2023-05-21 22:58:21 - progress_bar.py[line:272] - INFO: epoch 016:   1139 / 1732 loss=2.416, loss_v1=0, loss_v2=0, nll_loss=1.219, ntokens=999.7, nsentences=32, sample_size=999.7, sample_size_v1=0, sample_size_v2=0, ppl=2.33, wps=259.8, ups=0.26, wpb=999.7, bsz=32, num_updates=27070, lr=5.09592e-06, gnorm=15.955, clip=100, loss_scale=32, train_wall=38, gb_free=8.2, wall=104458
2023-05-21 22:58:59 - progress_bar.py[line:272] - INFO: epoch 016:   1149 / 1732 loss=2.403, loss_v1=0, loss_v2=0, nll_loss=1.205, ntokens=999, nsentences=32, sample_size=999, sample_size_v1=0, sample_size_v2=0, ppl=2.31, wps=259.9, ups=0.26, wpb=999, bsz=32, num_updates=27080, lr=5.09387e-06, gnorm=14.598, clip=100, loss_scale=32, train_wall=38, gb_free=8.7, wall=104496
2023-05-21 22:59:38 - progress_bar.py[line:272] - INFO: epoch 016:   1159 / 1732 loss=2.378, loss_v1=0, loss_v2=0, nll_loss=1.176, ntokens=1014.2, nsentences=32, sample_size=1014.2, sample_size_v1=0, sample_size_v2=0, ppl=2.26, wps=262.7, ups=0.26, wpb=1014.2, bsz=32, num_updates=27090, lr=5.09182e-06, gnorm=15.051, clip=100, loss_scale=32, train_wall=39, gb_free=8.6, wall=104535
2023-05-21 23:00:17 - progress_bar.py[line:272] - INFO: epoch 016:   1169 / 1732 loss=2.391, loss_v1=0, loss_v2=0, nll_loss=1.191, ntokens=1031, nsentences=32, sample_size=1031, sample_size_v1=0, sample_size_v2=0, ppl=2.28, wps=266.6, ups=0.26, wpb=1031, bsz=32, num_updates=27100, lr=5.08978e-06, gnorm=14.836, clip=100, loss_scale=32, train_wall=39, gb_free=8.2, wall=104574
2023-05-21 23:00:55 - progress_bar.py[line:272] - INFO: epoch 016:   1179 / 1732 loss=2.371, loss_v1=0, loss_v2=0, nll_loss=1.168, ntokens=1057.9, nsentences=32, sample_size=1057.9, sample_size_v1=0, sample_size_v2=0, ppl=2.25, wps=275, ups=0.26, wpb=1057.9, bsz=32, num_updates=27110, lr=5.08773e-06, gnorm=14.728, clip=100, loss_scale=32, train_wall=38, gb_free=8.9, wall=104612
2023-05-21 23:01:34 - progress_bar.py[line:272] - INFO: epoch 016:   1189 / 1732 loss=2.409, loss_v1=0, loss_v2=0, nll_loss=1.211, ntokens=993.6, nsentences=32, sample_size=993.6, sample_size_v1=0, sample_size_v2=0, ppl=2.31, wps=257.6, ups=0.26, wpb=993.6, bsz=32, num_updates=27120, lr=5.08568e-06, gnorm=14.953, clip=100, loss_scale=32, train_wall=39, gb_free=8.3, wall=104651
2023-05-21 23:02:13 - progress_bar.py[line:272] - INFO: epoch 016:   1199 / 1732 loss=2.378, loss_v1=0, loss_v2=0, nll_loss=1.175, ntokens=1103.9, nsentences=32, sample_size=1103.9, sample_size_v1=0, sample_size_v2=0, ppl=2.26, wps=283.5, ups=0.26, wpb=1103.9, bsz=32, num_updates=27130, lr=5.08364e-06, gnorm=15.389, clip=100, loss_scale=32, train_wall=39, gb_free=7.7, wall=104690
2023-05-21 23:02:52 - progress_bar.py[line:272] - INFO: epoch 016:   1209 / 1732 loss=2.377, loss_v1=0, loss_v2=0, nll_loss=1.173, ntokens=1079.5, nsentences=32, sample_size=1079.5, sample_size_v1=0, sample_size_v2=0, ppl=2.25, wps=276, ups=0.26, wpb=1079.5, bsz=32, num_updates=27140, lr=5.08159e-06, gnorm=13.971, clip=100, loss_scale=32, train_wall=39, gb_free=8.5, wall=104729
2023-05-21 23:03:30 - progress_bar.py[line:272] - INFO: epoch 016:   1219 / 1732 loss=2.436, loss_v1=0, loss_v2=0, nll_loss=1.24, ntokens=1009.3, nsentences=32, sample_size=1009.3, sample_size_v1=0, sample_size_v2=0, ppl=2.36, wps=261.8, ups=0.26, wpb=1009.3, bsz=32, num_updates=27150, lr=5.07954e-06, gnorm=15.683, clip=100, loss_scale=32, train_wall=38, gb_free=8.5, wall=104767
2023-05-21 23:04:09 - progress_bar.py[line:272] - INFO: epoch 016:   1229 / 1732 loss=2.394, loss_v1=0, loss_v2=0, nll_loss=1.192, ntokens=1052.5, nsentences=32, sample_size=1052.5, sample_size_v1=0, sample_size_v2=0, ppl=2.29, wps=274, ups=0.26, wpb=1052.5, bsz=32, num_updates=27160, lr=5.07749e-06, gnorm=15.025, clip=100, loss_scale=32, train_wall=38, gb_free=8.3, wall=104806
2023-05-21 23:04:47 - progress_bar.py[line:272] - INFO: epoch 016:   1239 / 1732 loss=2.347, loss_v1=0, loss_v2=0, nll_loss=1.143, ntokens=1065.1, nsentences=32, sample_size=1065.1, sample_size_v1=0, sample_size_v2=0, ppl=2.21, wps=274.1, ups=0.26, wpb=1065.1, bsz=32, num_updates=27170, lr=5.07545e-06, gnorm=13.544, clip=100, loss_scale=32, train_wall=39, gb_free=7.9, wall=104845
2023-05-21 23:05:26 - progress_bar.py[line:272] - INFO: epoch 016:   1249 / 1732 loss=2.355, loss_v1=0, loss_v2=0, nll_loss=1.152, ntokens=1065.4, nsentences=32, sample_size=1065.4, sample_size_v1=0, sample_size_v2=0, ppl=2.22, wps=275.8, ups=0.26, wpb=1065.4, bsz=32, num_updates=27180, lr=5.0734e-06, gnorm=15.16, clip=100, loss_scale=32, train_wall=39, gb_free=8.6, wall=104883
2023-05-21 23:06:05 - progress_bar.py[line:272] - INFO: epoch 016:   1259 / 1732 loss=2.383, loss_v1=0, loss_v2=0, nll_loss=1.182, ntokens=1045.9, nsentences=32, sample_size=1045.9, sample_size_v1=0, sample_size_v2=0, ppl=2.27, wps=271, ups=0.26, wpb=1045.9, bsz=32, num_updates=27190, lr=5.07135e-06, gnorm=14.672, clip=100, loss_scale=32, train_wall=39, gb_free=8.8, wall=104922
2023-05-21 23:06:44 - progress_bar.py[line:272] - INFO: epoch 016:   1269 / 1732 loss=2.398, loss_v1=0, loss_v2=0, nll_loss=1.199, ntokens=1069.2, nsentences=32, sample_size=1069.2, sample_size_v1=0, sample_size_v2=0, ppl=2.3, wps=275.3, ups=0.26, wpb=1069.2, bsz=32, num_updates=27200, lr=5.0693e-06, gnorm=13.696, clip=100, loss_scale=32, train_wall=39, gb_free=8.3, wall=104961
2023-05-21 23:07:22 - progress_bar.py[line:272] - INFO: epoch 016:   1279 / 1732 loss=2.396, loss_v1=0, loss_v2=0, nll_loss=1.195, ntokens=1067, nsentences=32, sample_size=1067, sample_size_v1=0, sample_size_v2=0, ppl=2.29, wps=276.1, ups=0.26, wpb=1067, bsz=32, num_updates=27210, lr=5.06726e-06, gnorm=15.247, clip=100, loss_scale=32, train_wall=39, gb_free=8, wall=104999
2023-05-21 23:08:01 - progress_bar.py[line:272] - INFO: epoch 016:   1289 / 1732 loss=2.379, loss_v1=0, loss_v2=0, nll_loss=1.177, ntokens=1071, nsentences=32, sample_size=1071, sample_size_v1=0, sample_size_v2=0, ppl=2.26, wps=276, ups=0.26, wpb=1071, bsz=32, num_updates=27220, lr=5.06521e-06, gnorm=13.542, clip=100, loss_scale=32, train_wall=39, gb_free=7, wall=105038
2023-05-21 23:08:40 - progress_bar.py[line:272] - INFO: epoch 016:   1299 / 1732 loss=2.377, loss_v1=0, loss_v2=0, nll_loss=1.176, ntokens=1078.1, nsentences=32, sample_size=1078.1, sample_size_v1=0, sample_size_v2=0, ppl=2.26, wps=279.9, ups=0.26, wpb=1078.1, bsz=32, num_updates=27230, lr=5.06316e-06, gnorm=14.387, clip=100, loss_scale=32, train_wall=38, gb_free=8.6, wall=105077
2023-05-21 23:09:19 - progress_bar.py[line:272] - INFO: epoch 016:   1309 / 1732 loss=2.426, loss_v1=0, loss_v2=0, nll_loss=1.23, ntokens=1085.2, nsentences=32, sample_size=1085.2, sample_size_v1=0, sample_size_v2=0, ppl=2.35, wps=278.1, ups=0.26, wpb=1085.2, bsz=32, num_updates=27240, lr=5.06111e-06, gnorm=14.55, clip=100, loss_scale=32, train_wall=39, gb_free=7.9, wall=105116
2023-05-21 23:09:57 - progress_bar.py[line:272] - INFO: epoch 016:   1319 / 1732 loss=2.38, loss_v1=0, loss_v2=0, nll_loss=1.178, ntokens=1092.6, nsentences=32, sample_size=1092.6, sample_size_v1=0, sample_size_v2=0, ppl=2.26, wps=281.1, ups=0.26, wpb=1092.6, bsz=32, num_updates=27250, lr=5.05907e-06, gnorm=14.626, clip=100, loss_scale=32, train_wall=39, gb_free=7.9, wall=105155
2023-05-21 23:10:37 - progress_bar.py[line:272] - INFO: epoch 016:   1329 / 1732 loss=2.36, loss_v1=0, loss_v2=0, nll_loss=1.156, ntokens=1106.3, nsentences=32, sample_size=1106.3, sample_size_v1=0, sample_size_v2=0, ppl=2.23, wps=281.6, ups=0.25, wpb=1106.3, bsz=32, num_updates=27260, lr=5.05702e-06, gnorm=14.939, clip=100, loss_scale=32, train_wall=39, gb_free=8.5, wall=105194
2023-05-21 23:11:16 - progress_bar.py[line:272] - INFO: epoch 016:   1339 / 1732 loss=2.378, loss_v1=0, loss_v2=0, nll_loss=1.176, ntokens=1120.5, nsentences=32, sample_size=1120.5, sample_size_v1=0, sample_size_v2=0, ppl=2.26, wps=287.8, ups=0.26, wpb=1120.5, bsz=32, num_updates=27270, lr=5.05497e-06, gnorm=16.075, clip=100, loss_scale=32, train_wall=39, gb_free=8.2, wall=105233
2023-05-21 23:11:55 - progress_bar.py[line:272] - INFO: epoch 016:   1349 / 1732 loss=2.37, loss_v1=0, loss_v2=0, nll_loss=1.167, ntokens=1187.2, nsentences=32, sample_size=1187.2, sample_size_v1=0, sample_size_v2=0, ppl=2.25, wps=303, ups=0.26, wpb=1187.2, bsz=32, num_updates=27280, lr=5.05292e-06, gnorm=13.869, clip=100, loss_scale=32, train_wall=39, gb_free=8.5, wall=105272
2023-05-21 23:12:34 - progress_bar.py[line:272] - INFO: epoch 016:   1359 / 1732 loss=2.351, loss_v1=0, loss_v2=0, nll_loss=1.145, ntokens=1104.5, nsentences=32, sample_size=1104.5, sample_size_v1=0, sample_size_v2=0, ppl=2.21, wps=282.3, ups=0.26, wpb=1104.5, bsz=32, num_updates=27290, lr=5.05088e-06, gnorm=13.689, clip=100, loss_scale=32, train_wall=39, gb_free=8.3, wall=105311
2023-05-21 23:13:13 - progress_bar.py[line:272] - INFO: epoch 016:   1369 / 1732 loss=2.4, loss_v1=0, loss_v2=0, nll_loss=1.201, ntokens=1096, nsentences=32, sample_size=1096, sample_size_v1=0, sample_size_v2=0, ppl=2.3, wps=280.8, ups=0.26, wpb=1096, bsz=32, num_updates=27300, lr=5.04883e-06, gnorm=14.369, clip=100, loss_scale=32, train_wall=39, gb_free=8, wall=105350
2023-05-21 23:13:51 - progress_bar.py[line:272] - INFO: epoch 016:   1379 / 1732 loss=2.407, loss_v1=0, loss_v2=0, nll_loss=1.21, ntokens=1115.7, nsentences=32, sample_size=1115.7, sample_size_v1=0, sample_size_v2=0, ppl=2.31, wps=290.1, ups=0.26, wpb=1115.7, bsz=32, num_updates=27310, lr=5.04678e-06, gnorm=14.718, clip=100, loss_scale=32, train_wall=38, gb_free=8.6, wall=105389
2023-05-21 23:14:30 - progress_bar.py[line:272] - INFO: epoch 016:   1389 / 1732 loss=2.392, loss_v1=0, loss_v2=0, nll_loss=1.192, ntokens=1122.1, nsentences=32, sample_size=1122.1, sample_size_v1=0, sample_size_v2=0, ppl=2.28, wps=291.2, ups=0.26, wpb=1122.1, bsz=32, num_updates=27320, lr=5.04474e-06, gnorm=14.603, clip=100, loss_scale=32, train_wall=38, gb_free=8.6, wall=105427
2023-05-21 23:15:09 - progress_bar.py[line:272] - INFO: epoch 016:   1399 / 1732 loss=2.359, loss_v1=0, loss_v2=0, nll_loss=1.155, ntokens=1113, nsentences=32, sample_size=1113, sample_size_v1=0, sample_size_v2=0, ppl=2.23, wps=286.3, ups=0.26, wpb=1113, bsz=32, num_updates=27330, lr=5.04269e-06, gnorm=13.886, clip=100, loss_scale=32, train_wall=39, gb_free=8.2, wall=105466
2023-05-21 23:15:48 - progress_bar.py[line:272] - INFO: epoch 016:   1409 / 1732 loss=2.403, loss_v1=0, loss_v2=0, nll_loss=1.203, ntokens=1156.6, nsentences=32, sample_size=1156.6, sample_size_v1=0, sample_size_v2=0, ppl=2.3, wps=296.7, ups=0.26, wpb=1156.6, bsz=32, num_updates=27340, lr=5.04064e-06, gnorm=13.85, clip=100, loss_scale=32, train_wall=39, gb_free=8.3, wall=105505
2023-05-21 23:16:27 - progress_bar.py[line:272] - INFO: epoch 016:   1419 / 1732 loss=2.396, loss_v1=0, loss_v2=0, nll_loss=1.197, ntokens=1290.6, nsentences=32, sample_size=1290.6, sample_size_v1=0, sample_size_v2=0, ppl=2.29, wps=327.2, ups=0.25, wpb=1290.6, bsz=32, num_updates=27350, lr=5.03859e-06, gnorm=12.936, clip=100, loss_scale=32, train_wall=39, gb_free=7.6, wall=105544
2023-05-21 23:17:07 - progress_bar.py[line:272] - INFO: epoch 016:   1429 / 1732 loss=2.362, loss_v1=0, loss_v2=0, nll_loss=1.158, ntokens=1226.2, nsentences=32, sample_size=1226.2, sample_size_v1=0, sample_size_v2=0, ppl=2.23, wps=312.7, ups=0.26, wpb=1226.2, bsz=32, num_updates=27360, lr=5.03655e-06, gnorm=12.561, clip=100, loss_scale=32, train_wall=39, gb_free=8.4, wall=105584
2023-05-21 23:17:45 - progress_bar.py[line:272] - INFO: epoch 016:   1439 / 1732 loss=2.366, loss_v1=0, loss_v2=0, nll_loss=1.162, ntokens=1192.7, nsentences=32, sample_size=1192.7, sample_size_v1=0, sample_size_v2=0, ppl=2.24, wps=307.5, ups=0.26, wpb=1192.7, bsz=32, num_updates=27370, lr=5.0345e-06, gnorm=11.897, clip=100, loss_scale=32, train_wall=39, gb_free=8.2, wall=105623
2023-05-21 23:18:24 - progress_bar.py[line:272] - INFO: epoch 016:   1449 / 1732 loss=2.396, loss_v1=0, loss_v2=0, nll_loss=1.197, ntokens=1089.5, nsentences=32, sample_size=1089.5, sample_size_v1=0, sample_size_v2=0, ppl=2.29, wps=281.4, ups=0.26, wpb=1089.5, bsz=32, num_updates=27380, lr=5.03245e-06, gnorm=14.157, clip=100, loss_scale=32, train_wall=39, gb_free=8.6, wall=105661
2023-05-21 23:19:03 - progress_bar.py[line:272] - INFO: epoch 016:   1459 / 1732 loss=2.368, loss_v1=0, loss_v2=0, nll_loss=1.165, ntokens=1160, nsentences=32, sample_size=1160, sample_size_v1=0, sample_size_v2=0, ppl=2.24, wps=296.6, ups=0.26, wpb=1160, bsz=32, num_updates=27390, lr=5.0304e-06, gnorm=13.616, clip=100, loss_scale=32, train_wall=39, gb_free=8.3, wall=105700
2023-05-21 23:19:42 - progress_bar.py[line:272] - INFO: epoch 016:   1469 / 1732 loss=2.369, loss_v1=0, loss_v2=0, nll_loss=1.166, ntokens=1187.1, nsentences=32, sample_size=1187.1, sample_size_v1=0, sample_size_v2=0, ppl=2.24, wps=304.7, ups=0.26, wpb=1187.1, bsz=32, num_updates=27400, lr=5.02836e-06, gnorm=12.605, clip=100, loss_scale=32, train_wall=39, gb_free=8.5, wall=105739
2023-05-21 23:20:21 - progress_bar.py[line:272] - INFO: epoch 016:   1479 / 1732 loss=2.405, loss_v1=0, loss_v2=0, nll_loss=1.207, ntokens=1029.5, nsentences=32, sample_size=1029.5, sample_size_v1=0, sample_size_v2=0, ppl=2.31, wps=265.6, ups=0.26, wpb=1029.5, bsz=32, num_updates=27410, lr=5.02631e-06, gnorm=16.192, clip=100, loss_scale=32, train_wall=39, gb_free=8.1, wall=105778
2023-05-21 23:21:00 - progress_bar.py[line:272] - INFO: epoch 016:   1489 / 1732 loss=2.385, loss_v1=0, loss_v2=0, nll_loss=1.183, ntokens=1147, nsentences=32, sample_size=1147, sample_size_v1=0, sample_size_v2=0, ppl=2.27, wps=293.3, ups=0.26, wpb=1147, bsz=32, num_updates=27420, lr=5.02426e-06, gnorm=13.456, clip=100, loss_scale=32, train_wall=39, gb_free=8.4, wall=105817
2023-05-21 23:21:39 - progress_bar.py[line:272] - INFO: epoch 016:   1499 / 1732 loss=2.363, loss_v1=0, loss_v2=0, nll_loss=1.159, ntokens=1095.4, nsentences=32, sample_size=1095.4, sample_size_v1=0, sample_size_v2=0, ppl=2.23, wps=282.8, ups=0.26, wpb=1095.4, bsz=32, num_updates=27430, lr=5.02221e-06, gnorm=13.151, clip=100, loss_scale=32, train_wall=39, gb_free=7.9, wall=105856
2023-05-21 23:22:17 - progress_bar.py[line:272] - INFO: epoch 016:   1509 / 1732 loss=2.335, loss_v1=0, loss_v2=0, nll_loss=1.13, ntokens=1114.3, nsentences=32, sample_size=1114.3, sample_size_v1=0, sample_size_v2=0, ppl=2.19, wps=288.6, ups=0.26, wpb=1114.3, bsz=32, num_updates=27440, lr=5.02017e-06, gnorm=15.174, clip=100, loss_scale=32, train_wall=39, gb_free=8.4, wall=105895
2023-05-21 23:22:56 - progress_bar.py[line:272] - INFO: epoch 016:   1519 / 1732 loss=2.41, loss_v1=0, loss_v2=0, nll_loss=1.214, ntokens=1050.9, nsentences=32, sample_size=1050.9, sample_size_v1=0, sample_size_v2=0, ppl=2.32, wps=272.4, ups=0.26, wpb=1050.9, bsz=32, num_updates=27450, lr=5.01812e-06, gnorm=15.112, clip=100, loss_scale=32, train_wall=39, gb_free=8.6, wall=105933
2023-05-21 23:23:35 - progress_bar.py[line:272] - INFO: epoch 016:   1529 / 1732 loss=2.412, loss_v1=0, loss_v2=0, nll_loss=1.215, ntokens=1056.3, nsentences=32, sample_size=1056.3, sample_size_v1=0, sample_size_v2=0, ppl=2.32, wps=273.7, ups=0.26, wpb=1056.3, bsz=32, num_updates=27460, lr=5.01607e-06, gnorm=16.432, clip=100, loss_scale=32, train_wall=39, gb_free=8.2, wall=105972
2023-05-21 23:24:13 - progress_bar.py[line:272] - INFO: epoch 016:   1539 / 1732 loss=2.384, loss_v1=0, loss_v2=0, nll_loss=1.183, ntokens=1083.3, nsentences=32, sample_size=1083.3, sample_size_v1=0, sample_size_v2=0, ppl=2.27, wps=278.4, ups=0.26, wpb=1083.3, bsz=32, num_updates=27470, lr=5.01402e-06, gnorm=14.416, clip=100, loss_scale=32, train_wall=39, gb_free=8.1, wall=106011
2023-05-21 23:24:52 - progress_bar.py[line:272] - INFO: epoch 016:   1549 / 1732 loss=2.355, loss_v1=0, loss_v2=0, nll_loss=1.148, ntokens=1075, nsentences=32, sample_size=1075, sample_size_v1=0, sample_size_v2=0, ppl=2.22, wps=279.1, ups=0.26, wpb=1075, bsz=32, num_updates=27480, lr=5.01198e-06, gnorm=14.59, clip=100, loss_scale=32, train_wall=38, gb_free=8.7, wall=106049
2023-05-21 23:25:31 - progress_bar.py[line:272] - INFO: epoch 016:   1559 / 1732 loss=2.385, loss_v1=0, loss_v2=0, nll_loss=1.186, ntokens=1092, nsentences=32, sample_size=1092, sample_size_v1=0, sample_size_v2=0, ppl=2.27, wps=280, ups=0.26, wpb=1092, bsz=32, num_updates=27490, lr=5.00993e-06, gnorm=14.247, clip=100, loss_scale=64, train_wall=39, gb_free=8.5, wall=106088
2023-05-21 23:25:46 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2023-05-21 23:26:13 - progress_bar.py[line:272] - INFO: epoch 016:   1570 / 1732 loss=2.427, loss_v1=0, loss_v2=0, nll_loss=1.23, ntokens=1068.6, nsentences=32, sample_size=1068.6, sample_size_v1=0, sample_size_v2=0, ppl=2.35, wps=251.4, ups=0.24, wpb=1068.6, bsz=32, num_updates=27500, lr=5.00788e-06, gnorm=15.449, clip=100, loss_scale=32, train_wall=42, gb_free=8.5, wall=106131
2023-05-21 23:26:52 - progress_bar.py[line:272] - INFO: epoch 016:   1580 / 1732 loss=2.415, loss_v1=0, loss_v2=0, nll_loss=1.218, ntokens=980.3, nsentences=32, sample_size=980.3, sample_size_v1=0, sample_size_v2=0, ppl=2.33, wps=254.7, ups=0.26, wpb=980.3, bsz=32, num_updates=27510, lr=5.00584e-06, gnorm=16.844, clip=100, loss_scale=32, train_wall=38, gb_free=8.9, wall=106169
2023-05-21 23:27:31 - progress_bar.py[line:272] - INFO: epoch 016:   1590 / 1732 loss=2.378, loss_v1=0, loss_v2=0, nll_loss=1.175, ntokens=1103, nsentences=32, sample_size=1103, sample_size_v1=0, sample_size_v2=0, ppl=2.26, wps=283.3, ups=0.26, wpb=1103, bsz=32, num_updates=27520, lr=5.00379e-06, gnorm=14.326, clip=100, loss_scale=32, train_wall=39, gb_free=7.7, wall=106208
2023-05-21 23:28:10 - progress_bar.py[line:272] - INFO: epoch 016:   1600 / 1732 loss=2.365, loss_v1=0, loss_v2=0, nll_loss=1.162, ntokens=1067.6, nsentences=32, sample_size=1067.6, sample_size_v1=0, sample_size_v2=0, ppl=2.24, wps=276.3, ups=0.26, wpb=1067.6, bsz=32, num_updates=27530, lr=5.00174e-06, gnorm=14.326, clip=100, loss_scale=32, train_wall=39, gb_free=8.1, wall=106247
2023-05-21 23:28:49 - progress_bar.py[line:272] - INFO: epoch 016:   1610 / 1732 loss=2.359, loss_v1=0, loss_v2=0, nll_loss=1.156, ntokens=1149.4, nsentences=32, sample_size=1149.4, sample_size_v1=0, sample_size_v2=0, ppl=2.23, wps=294.2, ups=0.26, wpb=1149.4, bsz=32, num_updates=27540, lr=4.99969e-06, gnorm=13.071, clip=100, loss_scale=32, train_wall=39, gb_free=8.4, wall=106286
2023-05-21 23:29:28 - progress_bar.py[line:272] - INFO: epoch 016:   1620 / 1732 loss=2.328, loss_v1=0, loss_v2=0, nll_loss=1.121, ntokens=1143.9, nsentences=32, sample_size=1143.9, sample_size_v1=0, sample_size_v2=0, ppl=2.18, wps=293.8, ups=0.26, wpb=1143.9, bsz=32, num_updates=27550, lr=4.99765e-06, gnorm=13.04, clip=100, loss_scale=32, train_wall=39, gb_free=7.8, wall=106325
2023-05-21 23:30:06 - progress_bar.py[line:272] - INFO: epoch 016:   1630 / 1732 loss=2.376, loss_v1=0, loss_v2=0, nll_loss=1.175, ntokens=1148.8, nsentences=32, sample_size=1148.8, sample_size_v1=0, sample_size_v2=0, ppl=2.26, wps=295, ups=0.26, wpb=1148.8, bsz=32, num_updates=27560, lr=4.9956e-06, gnorm=13.277, clip=100, loss_scale=32, train_wall=39, gb_free=8.7, wall=106364
2023-05-21 23:30:45 - progress_bar.py[line:272] - INFO: epoch 016:   1640 / 1732 loss=2.347, loss_v1=0, loss_v2=0, nll_loss=1.141, ntokens=1148.2, nsentences=32, sample_size=1148.2, sample_size_v1=0, sample_size_v2=0, ppl=2.21, wps=297.1, ups=0.26, wpb=1148.2, bsz=32, num_updates=27570, lr=4.99355e-06, gnorm=14.119, clip=100, loss_scale=32, train_wall=39, gb_free=8, wall=106402
2023-05-21 23:31:24 - progress_bar.py[line:272] - INFO: epoch 016:   1650 / 1732 loss=2.356, loss_v1=0, loss_v2=0, nll_loss=1.15, ntokens=1158.7, nsentences=32, sample_size=1158.7, sample_size_v1=0, sample_size_v2=0, ppl=2.22, wps=296.6, ups=0.26, wpb=1158.7, bsz=32, num_updates=27580, lr=4.9915e-06, gnorm=12.709, clip=100, loss_scale=32, train_wall=39, gb_free=9, wall=106441
2023-05-21 23:32:03 - progress_bar.py[line:272] - INFO: epoch 016:   1660 / 1732 loss=2.398, loss_v1=0, loss_v2=0, nll_loss=1.199, ntokens=997.6, nsentences=32, sample_size=997.6, sample_size_v1=0, sample_size_v2=0, ppl=2.3, wps=259.3, ups=0.26, wpb=997.6, bsz=32, num_updates=27590, lr=4.98946e-06, gnorm=13.427, clip=100, loss_scale=32, train_wall=38, gb_free=8.5, wall=106480
2023-05-21 23:32:41 - progress_bar.py[line:272] - INFO: epoch 016:   1670 / 1732 loss=2.376, loss_v1=0, loss_v2=0, nll_loss=1.174, ntokens=1015.8, nsentences=32, sample_size=1015.8, sample_size_v1=0, sample_size_v2=0, ppl=2.26, wps=264.6, ups=0.26, wpb=1015.8, bsz=32, num_updates=27600, lr=4.98741e-06, gnorm=15.009, clip=100, loss_scale=32, train_wall=38, gb_free=8.6, wall=106518
2023-05-21 23:33:20 - progress_bar.py[line:272] - INFO: epoch 016:   1680 / 1732 loss=2.325, loss_v1=0, loss_v2=0, nll_loss=1.118, ntokens=1181.3, nsentences=32, sample_size=1181.3, sample_size_v1=0, sample_size_v2=0, ppl=2.17, wps=303, ups=0.26, wpb=1181.3, bsz=32, num_updates=27610, lr=4.98536e-06, gnorm=12.566, clip=100, loss_scale=32, train_wall=39, gb_free=8.2, wall=106557
2023-05-21 23:33:59 - progress_bar.py[line:272] - INFO: epoch 016:   1690 / 1732 loss=2.36, loss_v1=0, loss_v2=0, nll_loss=1.155, ntokens=1198.5, nsentences=32, sample_size=1198.5, sample_size_v1=0, sample_size_v2=0, ppl=2.23, wps=306.4, ups=0.26, wpb=1198.5, bsz=32, num_updates=27620, lr=4.98331e-06, gnorm=13.161, clip=100, loss_scale=32, train_wall=39, gb_free=8, wall=106596
2023-05-21 23:34:39 - progress_bar.py[line:272] - INFO: epoch 016:   1700 / 1732 loss=2.354, loss_v1=0, loss_v2=0, nll_loss=1.15, ntokens=1281, nsentences=32, sample_size=1281, sample_size_v1=0, sample_size_v2=0, ppl=2.22, wps=324.6, ups=0.25, wpb=1281, bsz=32, num_updates=27630, lr=4.98127e-06, gnorm=12.925, clip=100, loss_scale=32, train_wall=39, gb_free=8.4, wall=106636
2023-05-21 23:35:18 - progress_bar.py[line:272] - INFO: epoch 016:   1710 / 1732 loss=2.375, loss_v1=0, loss_v2=0, nll_loss=1.173, ntokens=1170.9, nsentences=32, sample_size=1170.9, sample_size_v1=0, sample_size_v2=0, ppl=2.25, wps=298.6, ups=0.25, wpb=1170.9, bsz=32, num_updates=27640, lr=4.97922e-06, gnorm=13.915, clip=100, loss_scale=32, train_wall=39, gb_free=7.2, wall=106675
2023-05-21 23:35:57 - progress_bar.py[line:272] - INFO: epoch 016:   1720 / 1732 loss=2.349, loss_v1=0, loss_v2=0, nll_loss=1.145, ntokens=1171, nsentences=32, sample_size=1171, sample_size_v1=0, sample_size_v2=0, ppl=2.21, wps=300.5, ups=0.26, wpb=1171, bsz=32, num_updates=27650, lr=4.97717e-06, gnorm=13.386, clip=100, loss_scale=32, train_wall=39, gb_free=8.4, wall=106714
2023-05-21 23:36:36 - progress_bar.py[line:272] - INFO: epoch 016:   1730 / 1732 loss=2.407, loss_v1=0, loss_v2=0, nll_loss=1.209, ntokens=1126.4, nsentences=32, sample_size=1126.4, sample_size_v1=0, sample_size_v2=0, ppl=2.31, wps=289.3, ups=0.26, wpb=1126.4, bsz=32, num_updates=27660, lr=4.97512e-06, gnorm=14.045, clip=100, loss_scale=32, train_wall=39, gb_free=8.1, wall=106753
2023-05-21 23:36:41 - train.py[line:332] - INFO: end of epoch 16 (average epoch stats below)
2023-05-21 23:36:41 - progress_bar.py[line:282] - INFO: epoch 016 | loss 2.384 | loss_v1 0 | loss_v2 0 | nll_loss 1.183 | ntokens 1051.57 | nsentences 31.986 | sample_size 1051.57 | sample_size_v1 0 | sample_size_v2 0 | ppl 2.27 | wps 272.5 | ups 0.26 | wpb 1051.6 | bsz 32 | num_updates 27662 | lr 4.97471e-06 | gnorm 14.161 | clip 100 | loss_scale 32 | train_wall 6665 | gb_free 8.9 | wall 106758
2023-05-21 23:36:41 - trainer.py[line:639] - INFO: loading train data for epoch 17
local datafile ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 0 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 0 finished initializing row_count and line_idx-to-offset mapping
file ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 0 row count 55400 total row count 55400
slice_id 0 seek offset 0
2023-05-21 23:36:42 - trainer.py[line:703] - INFO: begin training epoch 17
2023-05-21 23:36:42 - train.py[line:305] - INFO: Start iterating over samples
2023-05-21 23:37:14 - progress_bar.py[line:272] - INFO: epoch 017:      8 / 1732 loss=2.309, loss_v1=0, loss_v2=0, nll_loss=1.097, ntokens=1080.1, nsentences=29.6, sample_size=1080.1, sample_size_v1=0, sample_size_v2=0, ppl=2.14, wps=284.2, ups=0.26, wpb=1080.1, bsz=29.6, num_updates=27670, lr=4.97308e-06, gnorm=16.255, clip=100, loss_scale=32, train_wall=36, gb_free=7.4, wall=106791
2023-05-21 23:37:53 - progress_bar.py[line:272] - INFO: epoch 017:     18 / 1732 loss=2.282, loss_v1=0, loss_v2=0, nll_loss=1.068, ntokens=1071.6, nsentences=32, sample_size=1071.6, sample_size_v1=0, sample_size_v2=0, ppl=2.1, wps=276.1, ups=0.26, wpb=1071.6, bsz=32, num_updates=27680, lr=4.97103e-06, gnorm=13.391, clip=100, loss_scale=32, train_wall=39, gb_free=8.3, wall=106830
2023-05-21 23:38:31 - progress_bar.py[line:272] - INFO: epoch 017:     28 / 1732 loss=2.347, loss_v1=0, loss_v2=0, nll_loss=1.141, ntokens=959.8, nsentences=32, sample_size=959.8, sample_size_v1=0, sample_size_v2=0, ppl=2.21, wps=247, ups=0.26, wpb=959.8, bsz=32, num_updates=27690, lr=4.96898e-06, gnorm=15.386, clip=100, loss_scale=32, train_wall=39, gb_free=8.5, wall=106869
2023-05-21 23:39:11 - progress_bar.py[line:272] - INFO: epoch 017:     38 / 1732 loss=2.156, loss_v1=0, loss_v2=0, nll_loss=0.926, ntokens=1177.1, nsentences=32, sample_size=1177.1, sample_size_v1=0, sample_size_v2=0, ppl=1.9, wps=298.6, ups=0.25, wpb=1177.1, bsz=32, num_updates=27700, lr=4.96693e-06, gnorm=9.912, clip=100, loss_scale=32, train_wall=39, gb_free=8.5, wall=106908
2023-05-21 23:39:50 - progress_bar.py[line:272] - INFO: epoch 017:     48 / 1732 loss=2.203, loss_v1=0, loss_v2=0, nll_loss=0.988, ntokens=1064.2, nsentences=32, sample_size=1064.2, sample_size_v1=0, sample_size_v2=0, ppl=1.98, wps=273.7, ups=0.26, wpb=1064.2, bsz=32, num_updates=27710, lr=4.96489e-06, gnorm=12.102, clip=100, loss_scale=32, train_wall=39, gb_free=7.9, wall=106947
2023-05-21 23:40:28 - progress_bar.py[line:272] - INFO: epoch 017:     58 / 1732 loss=2.093, loss_v1=0, loss_v2=0, nll_loss=0.854, ntokens=1039.9, nsentences=32, sample_size=1039.9, sample_size_v1=0, sample_size_v2=0, ppl=1.81, wps=270.3, ups=0.26, wpb=1039.9, bsz=32, num_updates=27720, lr=4.96284e-06, gnorm=11.667, clip=100, loss_scale=32, train_wall=38, gb_free=8.8, wall=106985
2023-05-21 23:41:08 - progress_bar.py[line:272] - INFO: epoch 017:     68 / 1732 loss=2.027, loss_v1=0, loss_v2=0, nll_loss=0.787, ntokens=1401.1, nsentences=32, sample_size=1401.1, sample_size_v1=0, sample_size_v2=0, ppl=1.72, wps=348.3, ups=0.25, wpb=1401.1, bsz=32, num_updates=27730, lr=4.96079e-06, gnorm=7.982, clip=100, loss_scale=32, train_wall=40, gb_free=7.2, wall=107026
2023-05-21 23:41:48 - progress_bar.py[line:272] - INFO: epoch 017:     78 / 1732 loss=2.153, loss_v1=0, loss_v2=0, nll_loss=0.925, ntokens=1268.8, nsentences=32, sample_size=1268.8, sample_size_v1=0, sample_size_v2=0, ppl=1.9, wps=319.4, ups=0.25, wpb=1268.8, bsz=32, num_updates=27740, lr=4.95875e-06, gnorm=12.915, clip=100, loss_scale=32, train_wall=40, gb_free=6.8, wall=107065
2023-05-21 23:42:28 - progress_bar.py[line:272] - INFO: epoch 017:     88 / 1732 loss=2.228, loss_v1=0, loss_v2=0, nll_loss=1.006, ntokens=1100.2, nsentences=32, sample_size=1100.2, sample_size_v1=0, sample_size_v2=0, ppl=2.01, wps=279.6, ups=0.25, wpb=1100.2, bsz=32, num_updates=27750, lr=4.9567e-06, gnorm=13.544, clip=100, loss_scale=32, train_wall=39, gb_free=8.1, wall=107105
2023-05-21 23:43:07 - progress_bar.py[line:272] - INFO: epoch 017:     98 / 1732 loss=2.183, loss_v1=0, loss_v2=0, nll_loss=0.956, ntokens=1080.6, nsentences=32, sample_size=1080.6, sample_size_v1=0, sample_size_v2=0, ppl=1.94, wps=276.8, ups=0.26, wpb=1080.6, bsz=32, num_updates=27760, lr=4.95465e-06, gnorm=12.601, clip=100, loss_scale=32, train_wall=39, gb_free=8.4, wall=107144
2023-05-21 23:43:45 - progress_bar.py[line:272] - INFO: epoch 017:    108 / 1732 loss=2.393, loss_v1=0, loss_v2=0, nll_loss=1.197, ntokens=978.3, nsentences=32, sample_size=978.3, sample_size_v1=0, sample_size_v2=0, ppl=2.29, wps=254.6, ups=0.26, wpb=978.3, bsz=32, num_updates=27770, lr=4.9526e-06, gnorm=17.596, clip=100, loss_scale=32, train_wall=38, gb_free=8.9, wall=107182
2023-05-21 23:44:24 - progress_bar.py[line:272] - INFO: epoch 017:    118 / 1732 loss=2.371, loss_v1=0, loss_v2=0, nll_loss=1.169, ntokens=1087, nsentences=32, sample_size=1087, sample_size_v1=0, sample_size_v2=0, ppl=2.25, wps=277.3, ups=0.26, wpb=1087, bsz=32, num_updates=27780, lr=4.95056e-06, gnorm=14.131, clip=100, loss_scale=32, train_wall=39, gb_free=8.1, wall=107221
2023-05-21 23:45:04 - progress_bar.py[line:272] - INFO: epoch 017:    128 / 1732 loss=2.329, loss_v1=0, loss_v2=0, nll_loss=1.12, ntokens=1177.5, nsentences=32, sample_size=1177.5, sample_size_v1=0, sample_size_v2=0, ppl=2.17, wps=298.6, ups=0.25, wpb=1177.5, bsz=32, num_updates=27790, lr=4.94851e-06, gnorm=12.338, clip=100, loss_scale=32, train_wall=39, gb_free=8.6, wall=107261
2023-05-21 23:45:43 - progress_bar.py[line:272] - INFO: epoch 017:    138 / 1732 loss=2.296, loss_v1=0, loss_v2=0, nll_loss=1.084, ntokens=1228, nsentences=32, sample_size=1228, sample_size_v1=0, sample_size_v2=0, ppl=2.12, wps=312.9, ups=0.25, wpb=1228, bsz=32, num_updates=27800, lr=4.94646e-06, gnorm=10.821, clip=100, loss_scale=32, train_wall=39, gb_free=8.2, wall=107300
2023-05-21 23:46:23 - progress_bar.py[line:272] - INFO: epoch 017:    148 / 1732 loss=2.253, loss_v1=0, loss_v2=0, nll_loss=1.037, ntokens=1210.4, nsentences=32, sample_size=1210.4, sample_size_v1=0, sample_size_v2=0, ppl=2.05, wps=305.6, ups=0.25, wpb=1210.4, bsz=32, num_updates=27810, lr=4.94441e-06, gnorm=10.278, clip=100, loss_scale=32, train_wall=40, gb_free=7.7, wall=107340
2023-05-21 23:47:02 - progress_bar.py[line:272] - INFO: epoch 017:    158 / 1732 loss=2.309, loss_v1=0, loss_v2=0, nll_loss=1.101, ntokens=1139, nsentences=32, sample_size=1139, sample_size_v1=0, sample_size_v2=0, ppl=2.14, wps=288.6, ups=0.25, wpb=1139, bsz=32, num_updates=27820, lr=4.94237e-06, gnorm=12.015, clip=100, loss_scale=32, train_wall=39, gb_free=8.4, wall=107379
2023-05-21 23:47:41 - progress_bar.py[line:272] - INFO: epoch 017:    168 / 1732 loss=2.286, loss_v1=0, loss_v2=0, nll_loss=1.076, ntokens=1015.2, nsentences=32, sample_size=1015.2, sample_size_v1=0, sample_size_v2=0, ppl=2.11, wps=262, ups=0.26, wpb=1015.2, bsz=32, num_updates=27830, lr=4.94032e-06, gnorm=12.67, clip=100, loss_scale=32, train_wall=39, gb_free=8.6, wall=107418
2023-05-21 23:48:20 - progress_bar.py[line:272] - INFO: epoch 017:    178 / 1732 loss=2.284, loss_v1=0, loss_v2=0, nll_loss=1.071, ntokens=1025.5, nsentences=32, sample_size=1025.5, sample_size_v1=0, sample_size_v2=0, ppl=2.1, wps=263.5, ups=0.26, wpb=1025.5, bsz=32, num_updates=27840, lr=4.93827e-06, gnorm=13.689, clip=100, loss_scale=32, train_wall=39, gb_free=8.2, wall=107457
2023-05-21 23:48:59 - progress_bar.py[line:272] - INFO: epoch 017:    188 / 1732 loss=2.249, loss_v1=0, loss_v2=0, nll_loss=1.031, ntokens=1150.5, nsentences=32, sample_size=1150.5, sample_size_v1=0, sample_size_v2=0, ppl=2.04, wps=292.7, ups=0.25, wpb=1150.5, bsz=32, num_updates=27850, lr=4.93622e-06, gnorm=10.812, clip=100, loss_scale=32, train_wall=39, gb_free=8.3, wall=107496
2023-05-21 23:49:38 - progress_bar.py[line:272] - INFO: epoch 017:    198 / 1732 loss=2.313, loss_v1=0, loss_v2=0, nll_loss=1.103, ntokens=1142.2, nsentences=32, sample_size=1142.2, sample_size_v1=0, sample_size_v2=0, ppl=2.15, wps=289.9, ups=0.25, wpb=1142.2, bsz=32, num_updates=27860, lr=4.93418e-06, gnorm=12.458, clip=100, loss_scale=32, train_wall=39, gb_free=8.1, wall=107536
2023-05-21 23:50:17 - progress_bar.py[line:272] - INFO: epoch 017:    208 / 1732 loss=2.409, loss_v1=0, loss_v2=0, nll_loss=1.212, ntokens=961.8, nsentences=32, sample_size=961.8, sample_size_v1=0, sample_size_v2=0, ppl=2.32, wps=251.9, ups=0.26, wpb=961.8, bsz=32, num_updates=27870, lr=4.93213e-06, gnorm=14.117, clip=100, loss_scale=32, train_wall=38, gb_free=8.2, wall=107574
2023-05-21 23:50:55 - progress_bar.py[line:272] - INFO: epoch 017:    218 / 1732 loss=2.408, loss_v1=0, loss_v2=0, nll_loss=1.211, ntokens=1149.2, nsentences=32, sample_size=1149.2, sample_size_v1=0, sample_size_v2=0, ppl=2.32, wps=299.2, ups=0.26, wpb=1149.2, bsz=32, num_updates=27880, lr=4.93008e-06, gnorm=12.424, clip=100, loss_scale=32, train_wall=38, gb_free=8.8, wall=107612
2023-05-21 23:51:34 - progress_bar.py[line:272] - INFO: epoch 017:    228 / 1732 loss=2.405, loss_v1=0, loss_v2=0, nll_loss=1.208, ntokens=1111.8, nsentences=32, sample_size=1111.8, sample_size_v1=0, sample_size_v2=0, ppl=2.31, wps=287.3, ups=0.26, wpb=1111.8, bsz=32, num_updates=27890, lr=4.92803e-06, gnorm=13.275, clip=100, loss_scale=32, train_wall=39, gb_free=8.8, wall=107651
2023-05-21 23:52:12 - progress_bar.py[line:272] - INFO: epoch 017:    238 / 1732 loss=2.451, loss_v1=0, loss_v2=0, nll_loss=1.258, ntokens=1085.4, nsentences=32, sample_size=1085.4, sample_size_v1=0, sample_size_v2=0, ppl=2.39, wps=282.8, ups=0.26, wpb=1085.4, bsz=32, num_updates=27900, lr=4.92599e-06, gnorm=13.918, clip=100, loss_scale=32, train_wall=38, gb_free=8.7, wall=107689
2023-05-21 23:52:51 - progress_bar.py[line:272] - INFO: epoch 017:    248 / 1732 loss=2.41, loss_v1=0, loss_v2=0, nll_loss=1.21, ntokens=1171.6, nsentences=32, sample_size=1171.6, sample_size_v1=0, sample_size_v2=0, ppl=2.31, wps=302.3, ups=0.26, wpb=1171.6, bsz=32, num_updates=27910, lr=4.92394e-06, gnorm=12.491, clip=100, loss_scale=32, train_wall=39, gb_free=8.5, wall=107728
2023-05-21 23:53:29 - progress_bar.py[line:272] - INFO: epoch 017:    258 / 1732 loss=2.433, loss_v1=0, loss_v2=0, nll_loss=1.237, ntokens=1118, nsentences=32, sample_size=1118, sample_size_v1=0, sample_size_v2=0, ppl=2.36, wps=291.3, ups=0.26, wpb=1118, bsz=32, num_updates=27920, lr=4.92189e-06, gnorm=14.064, clip=100, loss_scale=32, train_wall=38, gb_free=8.6, wall=107766
2023-05-21 23:54:08 - progress_bar.py[line:272] - INFO: epoch 017:    268 / 1732 loss=2.413, loss_v1=0, loss_v2=0, nll_loss=1.215, ntokens=1160.8, nsentences=32, sample_size=1160.8, sample_size_v1=0, sample_size_v2=0, ppl=2.32, wps=301.3, ups=0.26, wpb=1160.8, bsz=32, num_updates=27930, lr=4.91985e-06, gnorm=12.78, clip=100, loss_scale=32, train_wall=38, gb_free=8.8, wall=107805
2023-05-21 23:54:47 - progress_bar.py[line:272] - INFO: epoch 017:    278 / 1732 loss=2.419, loss_v1=0, loss_v2=0, nll_loss=1.221, ntokens=1136.9, nsentences=32, sample_size=1136.9, sample_size_v1=0, sample_size_v2=0, ppl=2.33, wps=292.6, ups=0.26, wpb=1136.9, bsz=32, num_updates=27940, lr=4.9178e-06, gnorm=12.853, clip=100, loss_scale=32, train_wall=39, gb_free=8.6, wall=107844
2023-05-21 23:55:25 - progress_bar.py[line:272] - INFO: epoch 017:    288 / 1732 loss=2.398, loss_v1=0, loss_v2=0, nll_loss=1.199, ntokens=1173.3, nsentences=32, sample_size=1173.3, sample_size_v1=0, sample_size_v2=0, ppl=2.3, wps=303.9, ups=0.26, wpb=1173.3, bsz=32, num_updates=27950, lr=4.91575e-06, gnorm=12.961, clip=100, loss_scale=32, train_wall=39, gb_free=8.6, wall=107882
2023-05-21 23:56:03 - progress_bar.py[line:272] - INFO: epoch 017:    298 / 1732 loss=2.418, loss_v1=0, loss_v2=0, nll_loss=1.221, ntokens=1074.2, nsentences=32, sample_size=1074.2, sample_size_v1=0, sample_size_v2=0, ppl=2.33, wps=281.4, ups=0.26, wpb=1074.2, bsz=32, num_updates=27960, lr=4.9137e-06, gnorm=14.162, clip=100, loss_scale=32, train_wall=38, gb_free=9.1, wall=107921
2023-05-21 23:56:42 - progress_bar.py[line:272] - INFO: epoch 017:    308 / 1732 loss=2.402, loss_v1=0, loss_v2=0, nll_loss=1.201, ntokens=1090.6, nsentences=32, sample_size=1090.6, sample_size_v1=0, sample_size_v2=0, ppl=2.3, wps=283.3, ups=0.26, wpb=1090.6, bsz=32, num_updates=27970, lr=4.91166e-06, gnorm=13.522, clip=100, loss_scale=32, train_wall=38, gb_free=8.9, wall=107959
2023-05-21 23:57:20 - progress_bar.py[line:272] - INFO: epoch 017:    318 / 1732 loss=2.423, loss_v1=0, loss_v2=0, nll_loss=1.224, ntokens=1026, nsentences=32, sample_size=1026, sample_size_v1=0, sample_size_v2=0, ppl=2.34, wps=267.8, ups=0.26, wpb=1026, bsz=32, num_updates=27980, lr=4.90961e-06, gnorm=13.875, clip=100, loss_scale=32, train_wall=38, gb_free=9, wall=107997
2023-05-21 23:57:58 - progress_bar.py[line:272] - INFO: epoch 017:    328 / 1732 loss=2.453, loss_v1=0, loss_v2=0, nll_loss=1.261, ntokens=1009.5, nsentences=32, sample_size=1009.5, sample_size_v1=0, sample_size_v2=0, ppl=2.4, wps=263.5, ups=0.26, wpb=1009.5, bsz=32, num_updates=27990, lr=4.90756e-06, gnorm=14.093, clip=100, loss_scale=32, train_wall=38, gb_free=8.9, wall=108036
2023-05-21 23:58:37 - progress_bar.py[line:272] - INFO: epoch 017:    338 / 1732 loss=2.4, loss_v1=0, loss_v2=0, nll_loss=1.201, ntokens=991.1, nsentences=32, sample_size=991.1, sample_size_v1=0, sample_size_v2=0, ppl=2.3, wps=260.1, ups=0.26, wpb=991.1, bsz=32, num_updates=28000, lr=4.90551e-06, gnorm=14.385, clip=100, loss_scale=32, train_wall=38, gb_free=8.9, wall=108074
2023-05-21 23:59:11 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2023-05-21 23:59:18 - progress_bar.py[line:272] - INFO: epoch 017:    349 / 1732 loss=2.414, loss_v1=0, loss_v2=0, nll_loss=1.217, ntokens=907.6, nsentences=32, sample_size=907.6, sample_size_v1=0, sample_size_v2=0, ppl=2.32, wps=218.4, ups=0.24, wpb=907.6, bsz=32, num_updates=28010, lr=4.90347e-06, gnorm=16.155, clip=100, loss_scale=32, train_wall=42, gb_free=8.7, wall=108115
2023-05-21 23:59:56 - progress_bar.py[line:272] - INFO: epoch 017:    359 / 1732 loss=2.45, loss_v1=0, loss_v2=0, nll_loss=1.258, ntokens=933.3, nsentences=32, sample_size=933.3, sample_size_v1=0, sample_size_v2=0, ppl=2.39, wps=246.1, ups=0.26, wpb=933.3, bsz=32, num_updates=28020, lr=4.90142e-06, gnorm=16.369, clip=100, loss_scale=32, train_wall=38, gb_free=8.6, wall=108153
2023-05-22 00:00:34 - progress_bar.py[line:272] - INFO: epoch 017:    369 / 1732 loss=2.459, loss_v1=0, loss_v2=0, nll_loss=1.265, ntokens=971.1, nsentences=32, sample_size=971.1, sample_size_v1=0, sample_size_v2=0, ppl=2.4, wps=256.1, ups=0.26, wpb=971.1, bsz=32, num_updates=28030, lr=4.89937e-06, gnorm=15.208, clip=100, loss_scale=32, train_wall=38, gb_free=8.9, wall=108191
2023-05-22 00:01:12 - progress_bar.py[line:272] - INFO: epoch 017:    379 / 1732 loss=2.446, loss_v1=0, loss_v2=0, nll_loss=1.25, ntokens=1075.7, nsentences=32, sample_size=1075.7, sample_size_v1=0, sample_size_v2=0, ppl=2.38, wps=281.8, ups=0.26, wpb=1075.7, bsz=32, num_updates=28040, lr=4.89732e-06, gnorm=14.393, clip=100, loss_scale=32, train_wall=38, gb_free=8.2, wall=108229
2023-05-22 00:01:50 - progress_bar.py[line:272] - INFO: epoch 017:    389 / 1732 loss=2.416, loss_v1=0, loss_v2=0, nll_loss=1.218, ntokens=1027.5, nsentences=32, sample_size=1027.5, sample_size_v1=0, sample_size_v2=0, ppl=2.33, wps=270.1, ups=0.26, wpb=1027.5, bsz=32, num_updates=28050, lr=4.89528e-06, gnorm=15.045, clip=100, loss_scale=32, train_wall=38, gb_free=8.9, wall=108267
2023-05-22 00:02:28 - progress_bar.py[line:272] - INFO: epoch 017:    399 / 1732 loss=2.417, loss_v1=0, loss_v2=0, nll_loss=1.219, ntokens=981.4, nsentences=32, sample_size=981.4, sample_size_v1=0, sample_size_v2=0, ppl=2.33, wps=257.9, ups=0.26, wpb=981.4, bsz=32, num_updates=28060, lr=4.89323e-06, gnorm=13.511, clip=100, loss_scale=32, train_wall=38, gb_free=8.8, wall=108305
2023-05-22 00:03:07 - progress_bar.py[line:272] - INFO: epoch 017:    409 / 1732 loss=2.411, loss_v1=0, loss_v2=0, nll_loss=1.214, ntokens=1066.6, nsentences=32, sample_size=1066.6, sample_size_v1=0, sample_size_v2=0, ppl=2.32, wps=277, ups=0.26, wpb=1066.6, bsz=32, num_updates=28070, lr=4.89118e-06, gnorm=13.44, clip=100, loss_scale=32, train_wall=38, gb_free=8.7, wall=108344
2023-05-22 00:03:45 - progress_bar.py[line:272] - INFO: epoch 017:    419 / 1732 loss=2.394, loss_v1=0, loss_v2=0, nll_loss=1.195, ntokens=1023.6, nsentences=32, sample_size=1023.6, sample_size_v1=0, sample_size_v2=0, ppl=2.29, wps=268.5, ups=0.26, wpb=1023.6, bsz=32, num_updates=28080, lr=4.88913e-06, gnorm=15.472, clip=100, loss_scale=32, train_wall=38, gb_free=8.3, wall=108382
2023-05-22 00:04:23 - progress_bar.py[line:272] - INFO: epoch 017:    429 / 1732 loss=2.388, loss_v1=0, loss_v2=0, nll_loss=1.187, ntokens=1011.5, nsentences=32, sample_size=1011.5, sample_size_v1=0, sample_size_v2=0, ppl=2.28, wps=265.3, ups=0.26, wpb=1011.5, bsz=32, num_updates=28090, lr=4.88709e-06, gnorm=15.686, clip=100, loss_scale=32, train_wall=38, gb_free=8.8, wall=108420
2023-05-22 00:05:01 - progress_bar.py[line:272] - INFO: epoch 017:    439 / 1732 loss=2.423, loss_v1=0, loss_v2=0, nll_loss=1.227, ntokens=1024.1, nsentences=32, sample_size=1024.1, sample_size_v1=0, sample_size_v2=0, ppl=2.34, wps=268.7, ups=0.26, wpb=1024.1, bsz=32, num_updates=28100, lr=4.88504e-06, gnorm=13.268, clip=100, loss_scale=32, train_wall=38, gb_free=7.6, wall=108458
2023-05-22 00:05:39 - progress_bar.py[line:272] - INFO: epoch 017:    449 / 1732 loss=2.447, loss_v1=0, loss_v2=0, nll_loss=1.252, ntokens=917.8, nsentences=32, sample_size=917.8, sample_size_v1=0, sample_size_v2=0, ppl=2.38, wps=240, ups=0.26, wpb=917.8, bsz=32, num_updates=28110, lr=4.88299e-06, gnorm=16.026, clip=100, loss_scale=32, train_wall=38, gb_free=8.4, wall=108497
2023-05-22 00:06:17 - progress_bar.py[line:272] - INFO: epoch 017:    459 / 1732 loss=2.436, loss_v1=0, loss_v2=0, nll_loss=1.24, ntokens=1003.6, nsentences=32, sample_size=1003.6, sample_size_v1=0, sample_size_v2=0, ppl=2.36, wps=264.3, ups=0.26, wpb=1003.6, bsz=32, num_updates=28120, lr=4.88095e-06, gnorm=16.182, clip=100, loss_scale=32, train_wall=38, gb_free=8.8, wall=108535
2023-05-22 00:06:56 - progress_bar.py[line:272] - INFO: epoch 017:    469 / 1732 loss=2.432, loss_v1=0, loss_v2=0, nll_loss=1.236, ntokens=1054.5, nsentences=32, sample_size=1054.5, sample_size_v1=0, sample_size_v2=0, ppl=2.36, wps=274.6, ups=0.26, wpb=1054.5, bsz=32, num_updates=28130, lr=4.8789e-06, gnorm=13.593, clip=100, loss_scale=32, train_wall=38, gb_free=7.7, wall=108573
2023-05-22 00:07:34 - progress_bar.py[line:272] - INFO: epoch 017:    479 / 1732 loss=2.453, loss_v1=0, loss_v2=0, nll_loss=1.257, ntokens=1034.5, nsentences=32, sample_size=1034.5, sample_size_v1=0, sample_size_v2=0, ppl=2.39, wps=270.4, ups=0.26, wpb=1034.5, bsz=32, num_updates=28140, lr=4.87685e-06, gnorm=13.799, clip=100, loss_scale=32, train_wall=38, gb_free=8.8, wall=108611
2023-05-22 00:08:12 - progress_bar.py[line:272] - INFO: epoch 017:    489 / 1732 loss=2.411, loss_v1=0, loss_v2=0, nll_loss=1.212, ntokens=912, nsentences=32, sample_size=912, sample_size_v1=0, sample_size_v2=0, ppl=2.32, wps=240.9, ups=0.26, wpb=912, bsz=32, num_updates=28150, lr=4.8748e-06, gnorm=15.578, clip=100, loss_scale=32, train_wall=38, gb_free=8.9, wall=108649
2023-05-22 00:08:50 - progress_bar.py[line:272] - INFO: epoch 017:    499 / 1732 loss=2.414, loss_v1=0, loss_v2=0, nll_loss=1.218, ntokens=957.3, nsentences=32, sample_size=957.3, sample_size_v1=0, sample_size_v2=0, ppl=2.33, wps=252.3, ups=0.26, wpb=957.3, bsz=32, num_updates=28160, lr=4.87276e-06, gnorm=15.535, clip=100, loss_scale=32, train_wall=38, gb_free=8.5, wall=108687
2023-05-22 00:09:28 - progress_bar.py[line:272] - INFO: epoch 017:    509 / 1732 loss=2.437, loss_v1=0, loss_v2=0, nll_loss=1.242, ntokens=1025.1, nsentences=32, sample_size=1025.1, sample_size_v1=0, sample_size_v2=0, ppl=2.37, wps=270.1, ups=0.26, wpb=1025.1, bsz=32, num_updates=28170, lr=4.87071e-06, gnorm=13.973, clip=100, loss_scale=32, train_wall=38, gb_free=8.8, wall=108725
2023-05-22 00:10:06 - progress_bar.py[line:272] - INFO: epoch 017:    519 / 1732 loss=2.418, loss_v1=0, loss_v2=0, nll_loss=1.22, ntokens=1029.2, nsentences=32, sample_size=1029.2, sample_size_v1=0, sample_size_v2=0, ppl=2.33, wps=271.7, ups=0.26, wpb=1029.2, bsz=32, num_updates=28180, lr=4.86866e-06, gnorm=13.233, clip=100, loss_scale=32, train_wall=38, gb_free=9.1, wall=108763
2023-05-22 00:10:44 - progress_bar.py[line:272] - INFO: epoch 017:    529 / 1732 loss=2.438, loss_v1=0, loss_v2=0, nll_loss=1.243, ntokens=945, nsentences=32, sample_size=945, sample_size_v1=0, sample_size_v2=0, ppl=2.37, wps=248.1, ups=0.26, wpb=945, bsz=32, num_updates=28190, lr=4.86661e-06, gnorm=15.369, clip=100, loss_scale=32, train_wall=38, gb_free=8.8, wall=108801
2023-05-22 00:11:22 - progress_bar.py[line:272] - INFO: epoch 017:    539 / 1732 loss=2.425, loss_v1=0, loss_v2=0, nll_loss=1.229, ntokens=990.9, nsentences=32, sample_size=990.9, sample_size_v1=0, sample_size_v2=0, ppl=2.34, wps=260, ups=0.26, wpb=990.9, bsz=32, num_updates=28200, lr=4.86457e-06, gnorm=15.848, clip=100, loss_scale=32, train_wall=38, gb_free=8.6, wall=108839
2023-05-22 00:12:00 - progress_bar.py[line:272] - INFO: epoch 017:    549 / 1732 loss=2.451, loss_v1=0, loss_v2=0, nll_loss=1.256, ntokens=1038.3, nsentences=32, sample_size=1038.3, sample_size_v1=0, sample_size_v2=0, ppl=2.39, wps=272.2, ups=0.26, wpb=1038.3, bsz=32, num_updates=28210, lr=4.86252e-06, gnorm=14.173, clip=100, loss_scale=32, train_wall=38, gb_free=8.8, wall=108877
2023-05-22 00:12:38 - progress_bar.py[line:272] - INFO: epoch 017:    559 / 1732 loss=2.434, loss_v1=0, loss_v2=0, nll_loss=1.237, ntokens=1016.1, nsentences=32, sample_size=1016.1, sample_size_v1=0, sample_size_v2=0, ppl=2.36, wps=266, ups=0.26, wpb=1016.1, bsz=32, num_updates=28220, lr=4.86047e-06, gnorm=13.964, clip=100, loss_scale=32, train_wall=38, gb_free=8.2, wall=108915
2023-05-22 00:13:17 - progress_bar.py[line:272] - INFO: epoch 017:    569 / 1732 loss=2.478, loss_v1=0, loss_v2=0, nll_loss=1.288, ntokens=1004.9, nsentences=32, sample_size=1004.9, sample_size_v1=0, sample_size_v2=0, ppl=2.44, wps=262.3, ups=0.26, wpb=1004.9, bsz=32, num_updates=28230, lr=4.85842e-06, gnorm=16.135, clip=100, loss_scale=32, train_wall=38, gb_free=8.4, wall=108954
2023-05-22 00:13:55 - progress_bar.py[line:272] - INFO: epoch 017:    579 / 1732 loss=2.424, loss_v1=0, loss_v2=0, nll_loss=1.228, ntokens=1003.1, nsentences=32, sample_size=1003.1, sample_size_v1=0, sample_size_v2=0, ppl=2.34, wps=263.3, ups=0.26, wpb=1003.1, bsz=32, num_updates=28240, lr=4.85638e-06, gnorm=15.472, clip=100, loss_scale=32, train_wall=38, gb_free=8.2, wall=108992
2023-05-22 00:14:33 - progress_bar.py[line:272] - INFO: epoch 017:    589 / 1732 loss=2.434, loss_v1=0, loss_v2=0, nll_loss=1.239, ntokens=951.2, nsentences=32, sample_size=951.2, sample_size_v1=0, sample_size_v2=0, ppl=2.36, wps=248.2, ups=0.26, wpb=951.2, bsz=32, num_updates=28250, lr=4.85433e-06, gnorm=15.867, clip=100, loss_scale=32, train_wall=38, gb_free=7.8, wall=109030
2023-05-22 00:15:11 - progress_bar.py[line:272] - INFO: epoch 017:    599 / 1732 loss=2.394, loss_v1=0, loss_v2=0, nll_loss=1.194, ntokens=935, nsentences=32, sample_size=935, sample_size_v1=0, sample_size_v2=0, ppl=2.29, wps=245.7, ups=0.26, wpb=935, bsz=32, num_updates=28260, lr=4.85228e-06, gnorm=16.327, clip=100, loss_scale=32, train_wall=38, gb_free=9.4, wall=109068
2023-05-22 00:15:49 - progress_bar.py[line:272] - INFO: epoch 017:    609 / 1732 loss=2.422, loss_v1=0, loss_v2=0, nll_loss=1.226, ntokens=917.6, nsentences=32, sample_size=917.6, sample_size_v1=0, sample_size_v2=0, ppl=2.34, wps=240.5, ups=0.26, wpb=917.6, bsz=32, num_updates=28270, lr=4.85023e-06, gnorm=16.679, clip=100, loss_scale=32, train_wall=38, gb_free=7.6, wall=109106
2023-05-22 00:16:27 - progress_bar.py[line:272] - INFO: epoch 017:    619 / 1732 loss=2.456, loss_v1=0, loss_v2=0, nll_loss=1.266, ntokens=845.1, nsentences=32, sample_size=845.1, sample_size_v1=0, sample_size_v2=0, ppl=2.4, wps=223.8, ups=0.26, wpb=845.1, bsz=32, num_updates=28280, lr=4.84819e-06, gnorm=17.84, clip=100, loss_scale=32, train_wall=38, gb_free=9, wall=109144
2023-05-22 00:17:05 - progress_bar.py[line:272] - INFO: epoch 017:    629 / 1732 loss=2.418, loss_v1=0, loss_v2=0, nll_loss=1.222, ntokens=934.9, nsentences=32, sample_size=934.9, sample_size_v1=0, sample_size_v2=0, ppl=2.33, wps=247.7, ups=0.27, wpb=934.9, bsz=32, num_updates=28290, lr=4.84614e-06, gnorm=18.055, clip=100, loss_scale=32, train_wall=38, gb_free=9.1, wall=109182
2023-05-22 00:17:43 - progress_bar.py[line:272] - INFO: epoch 017:    639 / 1732 loss=2.441, loss_v1=0, loss_v2=0, nll_loss=1.247, ntokens=925.6, nsentences=32, sample_size=925.6, sample_size_v1=0, sample_size_v2=0, ppl=2.37, wps=243.2, ups=0.26, wpb=925.6, bsz=32, num_updates=28300, lr=4.84409e-06, gnorm=17.059, clip=100, loss_scale=32, train_wall=38, gb_free=8.2, wall=109220
2023-05-22 00:18:21 - progress_bar.py[line:272] - INFO: epoch 017:    649 / 1732 loss=2.444, loss_v1=0, loss_v2=0, nll_loss=1.251, ntokens=987, nsentences=32, sample_size=987, sample_size_v1=0, sample_size_v2=0, ppl=2.38, wps=259.9, ups=0.26, wpb=987, bsz=32, num_updates=28310, lr=4.84204e-06, gnorm=16.3, clip=100, loss_scale=32, train_wall=38, gb_free=8.6, wall=109258
2023-05-22 00:18:59 - progress_bar.py[line:272] - INFO: epoch 017:    659 / 1732 loss=2.449, loss_v1=0, loss_v2=0, nll_loss=1.255, ntokens=871.8, nsentences=32, sample_size=871.8, sample_size_v1=0, sample_size_v2=0, ppl=2.39, wps=231.2, ups=0.27, wpb=871.8, bsz=32, num_updates=28320, lr=4.84e-06, gnorm=18.664, clip=100, loss_scale=32, train_wall=38, gb_free=9.3, wall=109296
2023-05-22 00:19:36 - progress_bar.py[line:272] - INFO: epoch 017:    669 / 1732 loss=2.441, loss_v1=0, loss_v2=0, nll_loss=1.247, ntokens=918, nsentences=32, sample_size=918, sample_size_v1=0, sample_size_v2=0, ppl=2.37, wps=242, ups=0.26, wpb=918, bsz=32, num_updates=28330, lr=4.83795e-06, gnorm=16.602, clip=100, loss_scale=32, train_wall=38, gb_free=8.6, wall=109334
2023-05-22 00:20:15 - progress_bar.py[line:272] - INFO: epoch 017:    679 / 1732 loss=2.439, loss_v1=0, loss_v2=0, nll_loss=1.244, ntokens=982.1, nsentences=32, sample_size=982.1, sample_size_v1=0, sample_size_v2=0, ppl=2.37, wps=257, ups=0.26, wpb=982.1, bsz=32, num_updates=28340, lr=4.8359e-06, gnorm=16.089, clip=100, loss_scale=32, train_wall=38, gb_free=8.7, wall=109372
2023-05-22 00:20:53 - progress_bar.py[line:272] - INFO: epoch 017:    689 / 1732 loss=2.444, loss_v1=0, loss_v2=0, nll_loss=1.249, ntokens=949.7, nsentences=32, sample_size=949.7, sample_size_v1=0, sample_size_v2=0, ppl=2.38, wps=248.5, ups=0.26, wpb=949.7, bsz=32, num_updates=28350, lr=4.83386e-06, gnorm=16.746, clip=100, loss_scale=32, train_wall=38, gb_free=7.8, wall=109410
2023-05-22 00:21:31 - progress_bar.py[line:272] - INFO: epoch 017:    699 / 1732 loss=2.419, loss_v1=0, loss_v2=0, nll_loss=1.221, ntokens=981.3, nsentences=32, sample_size=981.3, sample_size_v1=0, sample_size_v2=0, ppl=2.33, wps=257.6, ups=0.26, wpb=981.3, bsz=32, num_updates=28360, lr=4.83181e-06, gnorm=15.389, clip=100, loss_scale=32, train_wall=38, gb_free=8.8, wall=109448
2023-05-22 00:22:09 - progress_bar.py[line:272] - INFO: epoch 017:    709 / 1732 loss=2.423, loss_v1=0, loss_v2=0, nll_loss=1.226, ntokens=928.2, nsentences=32, sample_size=928.2, sample_size_v1=0, sample_size_v2=0, ppl=2.34, wps=244.6, ups=0.26, wpb=928.2, bsz=32, num_updates=28370, lr=4.82976e-06, gnorm=15.069, clip=100, loss_scale=32, train_wall=38, gb_free=8.2, wall=109486
2023-05-22 00:22:47 - progress_bar.py[line:272] - INFO: epoch 017:    719 / 1732 loss=2.431, loss_v1=0, loss_v2=0, nll_loss=1.235, ntokens=863.5, nsentences=32, sample_size=863.5, sample_size_v1=0, sample_size_v2=0, ppl=2.35, wps=228.1, ups=0.26, wpb=863.5, bsz=32, num_updates=28380, lr=4.82771e-06, gnorm=17.171, clip=100, loss_scale=32, train_wall=38, gb_free=9.1, wall=109524
2023-05-22 00:23:25 - progress_bar.py[line:272] - INFO: epoch 017:    729 / 1732 loss=2.408, loss_v1=0, loss_v2=0, nll_loss=1.21, ntokens=920.7, nsentences=32, sample_size=920.7, sample_size_v1=0, sample_size_v2=0, ppl=2.31, wps=241.5, ups=0.26, wpb=920.7, bsz=32, num_updates=28390, lr=4.82567e-06, gnorm=15.6, clip=100, loss_scale=32, train_wall=38, gb_free=9, wall=109562
2023-05-22 00:24:03 - progress_bar.py[line:272] - INFO: epoch 017:    739 / 1732 loss=2.409, loss_v1=0, loss_v2=0, nll_loss=1.213, ntokens=1016.5, nsentences=32, sample_size=1016.5, sample_size_v1=0, sample_size_v2=0, ppl=2.32, wps=267.7, ups=0.26, wpb=1016.5, bsz=32, num_updates=28400, lr=4.82362e-06, gnorm=16.393, clip=100, loss_scale=32, train_wall=38, gb_free=8.7, wall=109600
2023-05-22 00:24:41 - progress_bar.py[line:272] - INFO: epoch 017:    749 / 1732 loss=2.414, loss_v1=0, loss_v2=0, nll_loss=1.217, ntokens=964.9, nsentences=32, sample_size=964.9, sample_size_v1=0, sample_size_v2=0, ppl=2.32, wps=253.9, ups=0.26, wpb=964.9, bsz=32, num_updates=28410, lr=4.82157e-06, gnorm=15.132, clip=100, loss_scale=32, train_wall=38, gb_free=8.8, wall=109638
2023-05-22 00:25:19 - progress_bar.py[line:272] - INFO: epoch 017:    759 / 1732 loss=2.403, loss_v1=0, loss_v2=0, nll_loss=1.205, ntokens=966.4, nsentences=32, sample_size=966.4, sample_size_v1=0, sample_size_v2=0, ppl=2.3, wps=255, ups=0.26, wpb=966.4, bsz=32, num_updates=28420, lr=4.81952e-06, gnorm=16.899, clip=100, loss_scale=32, train_wall=38, gb_free=8.8, wall=109676
2023-05-22 00:25:57 - progress_bar.py[line:272] - INFO: epoch 017:    769 / 1732 loss=2.423, loss_v1=0, loss_v2=0, nll_loss=1.228, ntokens=931.4, nsentences=32, sample_size=931.4, sample_size_v1=0, sample_size_v2=0, ppl=2.34, wps=246.3, ups=0.26, wpb=931.4, bsz=32, num_updates=28430, lr=4.81748e-06, gnorm=15.828, clip=100, loss_scale=32, train_wall=38, gb_free=9, wall=109714
2023-05-22 00:26:35 - progress_bar.py[line:272] - INFO: epoch 017:    779 / 1732 loss=2.43, loss_v1=0, loss_v2=0, nll_loss=1.236, ntokens=1031.1, nsentences=32, sample_size=1031.1, sample_size_v1=0, sample_size_v2=0, ppl=2.36, wps=271.5, ups=0.26, wpb=1031.1, bsz=32, num_updates=28440, lr=4.81543e-06, gnorm=16.051, clip=100, loss_scale=32, train_wall=38, gb_free=8.7, wall=109752
2023-05-22 00:27:13 - progress_bar.py[line:272] - INFO: epoch 017:    789 / 1732 loss=2.413, loss_v1=0, loss_v2=0, nll_loss=1.216, ntokens=1004.1, nsentences=32, sample_size=1004.1, sample_size_v1=0, sample_size_v2=0, ppl=2.32, wps=263.1, ups=0.26, wpb=1004.1, bsz=32, num_updates=28450, lr=4.81338e-06, gnorm=14.718, clip=100, loss_scale=32, train_wall=38, gb_free=9.1, wall=109790
2023-05-22 00:27:51 - progress_bar.py[line:272] - INFO: epoch 017:    799 / 1732 loss=2.418, loss_v1=0, loss_v2=0, nll_loss=1.22, ntokens=1038.9, nsentences=32, sample_size=1038.9, sample_size_v1=0, sample_size_v2=0, ppl=2.33, wps=273.7, ups=0.26, wpb=1038.9, bsz=32, num_updates=28460, lr=4.81133e-06, gnorm=15.556, clip=100, loss_scale=32, train_wall=38, gb_free=8.8, wall=109828
2023-05-22 00:28:29 - progress_bar.py[line:272] - INFO: epoch 017:    809 / 1732 loss=2.426, loss_v1=0, loss_v2=0, nll_loss=1.229, ntokens=922.8, nsentences=32, sample_size=922.8, sample_size_v1=0, sample_size_v2=0, ppl=2.34, wps=244.1, ups=0.26, wpb=922.8, bsz=32, num_updates=28470, lr=4.80929e-06, gnorm=17.197, clip=100, loss_scale=32, train_wall=38, gb_free=9, wall=109866
2023-05-22 00:29:06 - progress_bar.py[line:272] - INFO: epoch 017:    819 / 1732 loss=2.435, loss_v1=0, loss_v2=0, nll_loss=1.238, ntokens=909.6, nsentences=32, sample_size=909.6, sample_size_v1=0, sample_size_v2=0, ppl=2.36, wps=240.6, ups=0.26, wpb=909.6, bsz=32, num_updates=28480, lr=4.80724e-06, gnorm=16.554, clip=100, loss_scale=32, train_wall=38, gb_free=9.1, wall=109904
2023-05-22 00:29:44 - progress_bar.py[line:272] - INFO: epoch 017:    829 / 1732 loss=2.407, loss_v1=0, loss_v2=0, nll_loss=1.207, ntokens=917.4, nsentences=32, sample_size=917.4, sample_size_v1=0, sample_size_v2=0, ppl=2.31, wps=241.7, ups=0.26, wpb=917.4, bsz=32, num_updates=28490, lr=4.80519e-06, gnorm=15.679, clip=100, loss_scale=32, train_wall=38, gb_free=9.3, wall=109941
2023-05-22 00:30:22 - progress_bar.py[line:272] - INFO: epoch 017:    839 / 1732 loss=2.43, loss_v1=0, loss_v2=0, nll_loss=1.234, ntokens=902.5, nsentences=32, sample_size=902.5, sample_size_v1=0, sample_size_v2=0, ppl=2.35, wps=239.1, ups=0.26, wpb=902.5, bsz=32, num_updates=28500, lr=4.80314e-06, gnorm=17.721, clip=100, loss_scale=32, train_wall=38, gb_free=9.1, wall=109979
2023-05-22 00:31:00 - progress_bar.py[line:272] - INFO: epoch 017:    849 / 1732 loss=2.414, loss_v1=0, loss_v2=0, nll_loss=1.215, ntokens=1036.8, nsentences=32, sample_size=1036.8, sample_size_v1=0, sample_size_v2=0, ppl=2.32, wps=272, ups=0.26, wpb=1036.8, bsz=32, num_updates=28510, lr=4.8011e-06, gnorm=16.736, clip=100, loss_scale=32, train_wall=38, gb_free=8.6, wall=110017
2023-05-22 00:31:38 - progress_bar.py[line:272] - INFO: epoch 017:    859 / 1732 loss=2.409, loss_v1=0, loss_v2=0, nll_loss=1.21, ntokens=930.3, nsentences=32, sample_size=930.3, sample_size_v1=0, sample_size_v2=0, ppl=2.31, wps=244.2, ups=0.26, wpb=930.3, bsz=32, num_updates=28520, lr=4.79905e-06, gnorm=16.154, clip=100, loss_scale=64, train_wall=38, gb_free=8.6, wall=110055
2023-05-22 00:31:46 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2023-05-22 00:32:20 - progress_bar.py[line:272] - INFO: epoch 017:    870 / 1732 loss=2.434, loss_v1=0, loss_v2=0, nll_loss=1.237, ntokens=942.2, nsentences=32, sample_size=942.2, sample_size_v1=0, sample_size_v2=0, ppl=2.36, wps=225.7, ups=0.24, wpb=942.2, bsz=32, num_updates=28530, lr=4.797e-06, gnorm=16.015, clip=100, loss_scale=32, train_wall=42, gb_free=8.8, wall=110097
2023-05-22 00:32:58 - progress_bar.py[line:272] - INFO: epoch 017:    880 / 1732 loss=2.364, loss_v1=0, loss_v2=0, nll_loss=1.161, ntokens=1004.9, nsentences=32, sample_size=1004.9, sample_size_v1=0, sample_size_v2=0, ppl=2.24, wps=263.5, ups=0.26, wpb=1004.9, bsz=32, num_updates=28540, lr=4.79496e-06, gnorm=13.852, clip=100, loss_scale=32, train_wall=38, gb_free=8.4, wall=110135
2023-05-22 00:33:36 - progress_bar.py[line:272] - INFO: epoch 017:    890 / 1732 loss=2.361, loss_v1=0, loss_v2=0, nll_loss=1.157, ntokens=986.6, nsentences=32, sample_size=986.6, sample_size_v1=0, sample_size_v2=0, ppl=2.23, wps=259.8, ups=0.26, wpb=986.6, bsz=32, num_updates=28550, lr=4.79291e-06, gnorm=14.93, clip=100, loss_scale=32, train_wall=38, gb_free=8.4, wall=110173
2023-05-22 00:34:14 - progress_bar.py[line:272] - INFO: epoch 017:    900 / 1732 loss=2.356, loss_v1=0, loss_v2=0, nll_loss=1.151, ntokens=1043.1, nsentences=32, sample_size=1043.1, sample_size_v1=0, sample_size_v2=0, ppl=2.22, wps=273.5, ups=0.26, wpb=1043.1, bsz=32, num_updates=28560, lr=4.79086e-06, gnorm=13.712, clip=100, loss_scale=32, train_wall=38, gb_free=9, wall=110211
2023-05-22 00:34:52 - progress_bar.py[line:272] - INFO: epoch 017:    910 / 1732 loss=2.402, loss_v1=0, loss_v2=0, nll_loss=1.204, ntokens=976.1, nsentences=32, sample_size=976.1, sample_size_v1=0, sample_size_v2=0, ppl=2.3, wps=257.6, ups=0.26, wpb=976.1, bsz=32, num_updates=28570, lr=4.78881e-06, gnorm=15.423, clip=100, loss_scale=32, train_wall=38, gb_free=8.6, wall=110249
2023-05-22 00:35:30 - progress_bar.py[line:272] - INFO: epoch 017:    920 / 1732 loss=2.428, loss_v1=0, loss_v2=0, nll_loss=1.232, ntokens=983.5, nsentences=32, sample_size=983.5, sample_size_v1=0, sample_size_v2=0, ppl=2.35, wps=256.8, ups=0.26, wpb=983.5, bsz=32, num_updates=28580, lr=4.78677e-06, gnorm=16.095, clip=100, loss_scale=32, train_wall=38, gb_free=8.9, wall=110288
2023-05-22 00:36:09 - progress_bar.py[line:272] - INFO: epoch 017:    930 / 1732 loss=2.39, loss_v1=0, loss_v2=0, nll_loss=1.19, ntokens=1038.6, nsentences=32, sample_size=1038.6, sample_size_v1=0, sample_size_v2=0, ppl=2.28, wps=269.3, ups=0.26, wpb=1038.6, bsz=32, num_updates=28590, lr=4.78472e-06, gnorm=15.639, clip=100, loss_scale=32, train_wall=39, gb_free=8.8, wall=110326
2023-05-22 00:36:48 - progress_bar.py[line:272] - INFO: epoch 017:    940 / 1732 loss=2.381, loss_v1=0, loss_v2=0, nll_loss=1.18, ntokens=1043.2, nsentences=32, sample_size=1043.2, sample_size_v1=0, sample_size_v2=0, ppl=2.27, wps=268.4, ups=0.26, wpb=1043.2, bsz=32, num_updates=28600, lr=4.78267e-06, gnorm=15.255, clip=100, loss_scale=32, train_wall=39, gb_free=8.1, wall=110365
2023-05-22 00:37:26 - progress_bar.py[line:272] - INFO: epoch 017:    950 / 1732 loss=2.408, loss_v1=0, loss_v2=0, nll_loss=1.209, ntokens=1038.6, nsentences=32, sample_size=1038.6, sample_size_v1=0, sample_size_v2=0, ppl=2.31, wps=269.2, ups=0.26, wpb=1038.6, bsz=32, num_updates=28610, lr=4.78062e-06, gnorm=14.55, clip=100, loss_scale=32, train_wall=39, gb_free=8.8, wall=110404
2023-05-22 00:38:05 - progress_bar.py[line:272] - INFO: epoch 017:    960 / 1732 loss=2.394, loss_v1=0, loss_v2=0, nll_loss=1.194, ntokens=1044.3, nsentences=32, sample_size=1044.3, sample_size_v1=0, sample_size_v2=0, ppl=2.29, wps=269.9, ups=0.26, wpb=1044.3, bsz=32, num_updates=28620, lr=4.77858e-06, gnorm=14.395, clip=100, loss_scale=32, train_wall=39, gb_free=8.5, wall=110442
2023-05-22 00:38:44 - progress_bar.py[line:272] - INFO: epoch 017:    970 / 1732 loss=2.419, loss_v1=0, loss_v2=0, nll_loss=1.224, ntokens=1054.8, nsentences=32, sample_size=1054.8, sample_size_v1=0, sample_size_v2=0, ppl=2.34, wps=274.1, ups=0.26, wpb=1054.8, bsz=32, num_updates=28630, lr=4.77653e-06, gnorm=15.917, clip=100, loss_scale=32, train_wall=38, gb_free=8.7, wall=110481
2023-05-22 00:39:22 - progress_bar.py[line:272] - INFO: epoch 017:    980 / 1732 loss=2.401, loss_v1=0, loss_v2=0, nll_loss=1.205, ntokens=1012, nsentences=32, sample_size=1012, sample_size_v1=0, sample_size_v2=0, ppl=2.31, wps=263.2, ups=0.26, wpb=1012, bsz=32, num_updates=28640, lr=4.77448e-06, gnorm=15.57, clip=100, loss_scale=32, train_wall=38, gb_free=8.6, wall=110519
2023-05-22 00:40:01 - progress_bar.py[line:272] - INFO: epoch 017:    990 / 1732 loss=2.399, loss_v1=0, loss_v2=0, nll_loss=1.2, ntokens=1049.1, nsentences=32, sample_size=1049.1, sample_size_v1=0, sample_size_v2=0, ppl=2.3, wps=271.8, ups=0.26, wpb=1049.1, bsz=32, num_updates=28650, lr=4.77243e-06, gnorm=13.52, clip=100, loss_scale=32, train_wall=39, gb_free=9.1, wall=110558
2023-05-22 00:40:39 - progress_bar.py[line:272] - INFO: epoch 017:   1000 / 1732 loss=2.382, loss_v1=0, loss_v2=0, nll_loss=1.18, ntokens=1015.5, nsentences=32, sample_size=1015.5, sample_size_v1=0, sample_size_v2=0, ppl=2.27, wps=263.8, ups=0.26, wpb=1015.5, bsz=32, num_updates=28660, lr=4.77039e-06, gnorm=14.778, clip=100, loss_scale=32, train_wall=38, gb_free=9, wall=110596
2023-05-22 00:41:18 - progress_bar.py[line:272] - INFO: epoch 017:   1010 / 1732 loss=2.393, loss_v1=0, loss_v2=0, nll_loss=1.192, ntokens=1013.4, nsentences=32, sample_size=1013.4, sample_size_v1=0, sample_size_v2=0, ppl=2.29, wps=263.2, ups=0.26, wpb=1013.4, bsz=32, num_updates=28670, lr=4.76834e-06, gnorm=14.458, clip=100, loss_scale=32, train_wall=38, gb_free=8.8, wall=110635
2023-05-22 00:41:56 - progress_bar.py[line:272] - INFO: epoch 017:   1020 / 1732 loss=2.367, loss_v1=0, loss_v2=0, nll_loss=1.164, ntokens=1035.8, nsentences=32, sample_size=1035.8, sample_size_v1=0, sample_size_v2=0, ppl=2.24, wps=267.4, ups=0.26, wpb=1035.8, bsz=32, num_updates=28680, lr=4.76629e-06, gnorm=15.045, clip=100, loss_scale=32, train_wall=39, gb_free=8.4, wall=110674
2023-05-22 00:42:36 - progress_bar.py[line:272] - INFO: epoch 017:   1030 / 1732 loss=2.404, loss_v1=0, loss_v2=0, nll_loss=1.207, ntokens=1101.6, nsentences=32, sample_size=1101.6, sample_size_v1=0, sample_size_v2=0, ppl=2.31, wps=281.6, ups=0.26, wpb=1101.6, bsz=32, num_updates=28690, lr=4.76424e-06, gnorm=13.332, clip=100, loss_scale=32, train_wall=39, gb_free=8.3, wall=110713
2023-05-22 00:43:14 - progress_bar.py[line:272] - INFO: epoch 017:   1040 / 1732 loss=2.394, loss_v1=0, loss_v2=0, nll_loss=1.196, ntokens=1070.8, nsentences=32, sample_size=1070.8, sample_size_v1=0, sample_size_v2=0, ppl=2.29, wps=275.5, ups=0.26, wpb=1070.8, bsz=32, num_updates=28700, lr=4.7622e-06, gnorm=14.94, clip=100, loss_scale=32, train_wall=39, gb_free=8, wall=110752
2023-05-22 00:43:53 - progress_bar.py[line:272] - INFO: epoch 017:   1050 / 1732 loss=2.398, loss_v1=0, loss_v2=0, nll_loss=1.198, ntokens=1039.3, nsentences=32, sample_size=1039.3, sample_size_v1=0, sample_size_v2=0, ppl=2.29, wps=269, ups=0.26, wpb=1039.3, bsz=32, num_updates=28710, lr=4.76015e-06, gnorm=15.189, clip=100, loss_scale=32, train_wall=39, gb_free=8.6, wall=110790
2023-05-22 00:44:32 - progress_bar.py[line:272] - INFO: epoch 017:   1060 / 1732 loss=2.387, loss_v1=0, loss_v2=0, nll_loss=1.185, ntokens=1066.3, nsentences=32, sample_size=1066.3, sample_size_v1=0, sample_size_v2=0, ppl=2.27, wps=276.6, ups=0.26, wpb=1066.3, bsz=32, num_updates=28720, lr=4.7581e-06, gnorm=15.949, clip=100, loss_scale=32, train_wall=38, gb_free=7.9, wall=110829
2023-05-22 00:45:10 - progress_bar.py[line:272] - INFO: epoch 017:   1070 / 1732 loss=2.401, loss_v1=0, loss_v2=0, nll_loss=1.201, ntokens=985.6, nsentences=32, sample_size=985.6, sample_size_v1=0, sample_size_v2=0, ppl=2.3, wps=256.4, ups=0.26, wpb=985.6, bsz=32, num_updates=28730, lr=4.75606e-06, gnorm=15.226, clip=100, loss_scale=32, train_wall=38, gb_free=8, wall=110867
2023-05-22 00:45:49 - progress_bar.py[line:272] - INFO: epoch 017:   1080 / 1732 loss=2.408, loss_v1=0, loss_v2=0, nll_loss=1.21, ntokens=1039.6, nsentences=32, sample_size=1039.6, sample_size_v1=0, sample_size_v2=0, ppl=2.31, wps=268.1, ups=0.26, wpb=1039.6, bsz=32, num_updates=28740, lr=4.75401e-06, gnorm=15.784, clip=100, loss_scale=32, train_wall=39, gb_free=8.3, wall=110906
2023-05-22 00:46:28 - progress_bar.py[line:272] - INFO: epoch 017:   1090 / 1732 loss=2.391, loss_v1=0, loss_v2=0, nll_loss=1.192, ntokens=1074, nsentences=32, sample_size=1074, sample_size_v1=0, sample_size_v2=0, ppl=2.28, wps=277.9, ups=0.26, wpb=1074, bsz=32, num_updates=28750, lr=4.75196e-06, gnorm=15.498, clip=100, loss_scale=32, train_wall=39, gb_free=8.3, wall=110945
2023-05-22 00:47:06 - progress_bar.py[line:272] - INFO: epoch 017:   1100 / 1732 loss=2.403, loss_v1=0, loss_v2=0, nll_loss=1.205, ntokens=1032, nsentences=32, sample_size=1032, sample_size_v1=0, sample_size_v2=0, ppl=2.31, wps=267.9, ups=0.26, wpb=1032, bsz=32, num_updates=28760, lr=4.74991e-06, gnorm=16.648, clip=100, loss_scale=32, train_wall=38, gb_free=8.8, wall=110983
2023-05-22 00:47:45 - progress_bar.py[line:272] - INFO: epoch 017:   1110 / 1732 loss=2.399, loss_v1=0, loss_v2=0, nll_loss=1.198, ntokens=1053.3, nsentences=32, sample_size=1053.3, sample_size_v1=0, sample_size_v2=0, ppl=2.29, wps=270.3, ups=0.26, wpb=1053.3, bsz=32, num_updates=28770, lr=4.74787e-06, gnorm=15.026, clip=100, loss_scale=32, train_wall=39, gb_free=8.6, wall=111022
2023-05-22 00:48:24 - progress_bar.py[line:272] - INFO: epoch 017:   1120 / 1732 loss=2.405, loss_v1=0, loss_v2=0, nll_loss=1.204, ntokens=958.1, nsentences=32, sample_size=958.1, sample_size_v1=0, sample_size_v2=0, ppl=2.3, wps=247, ups=0.26, wpb=958.1, bsz=32, num_updates=28780, lr=4.74582e-06, gnorm=15.377, clip=100, loss_scale=32, train_wall=39, gb_free=8.8, wall=111061
2023-05-22 00:49:03 - progress_bar.py[line:272] - INFO: epoch 017:   1130 / 1732 loss=2.394, loss_v1=0, loss_v2=0, nll_loss=1.194, ntokens=1008.8, nsentences=32, sample_size=1008.8, sample_size_v1=0, sample_size_v2=0, ppl=2.29, wps=260.7, ups=0.26, wpb=1008.8, bsz=32, num_updates=28790, lr=4.74377e-06, gnorm=16.156, clip=100, loss_scale=32, train_wall=39, gb_free=8.8, wall=111100
2023-05-22 00:49:41 - progress_bar.py[line:272] - INFO: epoch 017:   1140 / 1732 loss=2.41, loss_v1=0, loss_v2=0, nll_loss=1.214, ntokens=1003.3, nsentences=32, sample_size=1003.3, sample_size_v1=0, sample_size_v2=0, ppl=2.32, wps=260.7, ups=0.26, wpb=1003.3, bsz=32, num_updates=28800, lr=4.74172e-06, gnorm=15.994, clip=100, loss_scale=32, train_wall=38, gb_free=8.9, wall=111138
2023-05-22 00:50:20 - progress_bar.py[line:272] - INFO: epoch 017:   1150 / 1732 loss=2.397, loss_v1=0, loss_v2=0, nll_loss=1.198, ntokens=1020.4, nsentences=32, sample_size=1020.4, sample_size_v1=0, sample_size_v2=0, ppl=2.29, wps=264.6, ups=0.26, wpb=1020.4, bsz=32, num_updates=28810, lr=4.73968e-06, gnorm=16.746, clip=100, loss_scale=32, train_wall=39, gb_free=8.4, wall=111177
2023-05-22 00:50:58 - progress_bar.py[line:272] - INFO: epoch 017:   1160 / 1732 loss=2.378, loss_v1=0, loss_v2=0, nll_loss=1.177, ntokens=995, nsentences=32, sample_size=995, sample_size_v1=0, sample_size_v2=0, ppl=2.26, wps=258, ups=0.26, wpb=995, bsz=32, num_updates=28820, lr=4.73763e-06, gnorm=16.785, clip=100, loss_scale=32, train_wall=39, gb_free=8.6, wall=111215
2023-05-22 00:51:37 - progress_bar.py[line:272] - INFO: epoch 017:   1170 / 1732 loss=2.388, loss_v1=0, loss_v2=0, nll_loss=1.189, ntokens=1051.7, nsentences=32, sample_size=1051.7, sample_size_v1=0, sample_size_v2=0, ppl=2.28, wps=271.5, ups=0.26, wpb=1051.7, bsz=32, num_updates=28830, lr=4.73558e-06, gnorm=15.195, clip=100, loss_scale=32, train_wall=39, gb_free=8.1, wall=111254
2023-05-22 00:52:15 - progress_bar.py[line:272] - INFO: epoch 017:   1180 / 1732 loss=2.37, loss_v1=0, loss_v2=0, nll_loss=1.166, ntokens=1021, nsentences=32, sample_size=1021, sample_size_v1=0, sample_size_v2=0, ppl=2.24, wps=267, ups=0.26, wpb=1021, bsz=32, num_updates=28840, lr=4.73353e-06, gnorm=15.817, clip=100, loss_scale=32, train_wall=38, gb_free=8.8, wall=111292
2023-05-22 00:52:54 - progress_bar.py[line:272] - INFO: epoch 017:   1190 / 1732 loss=2.407, loss_v1=0, loss_v2=0, nll_loss=1.21, ntokens=996.9, nsentences=32, sample_size=996.9, sample_size_v1=0, sample_size_v2=0, ppl=2.31, wps=259.4, ups=0.26, wpb=996.9, bsz=32, num_updates=28850, lr=4.73149e-06, gnorm=16.186, clip=100, loss_scale=32, train_wall=38, gb_free=8.4, wall=111331
2023-05-22 00:53:33 - progress_bar.py[line:272] - INFO: epoch 017:   1200 / 1732 loss=2.376, loss_v1=0, loss_v2=0, nll_loss=1.174, ntokens=1118, nsentences=32, sample_size=1118, sample_size_v1=0, sample_size_v2=0, ppl=2.26, wps=286.6, ups=0.26, wpb=1118, bsz=32, num_updates=28860, lr=4.72944e-06, gnorm=14.687, clip=100, loss_scale=32, train_wall=39, gb_free=8.5, wall=111370
2023-05-22 00:54:12 - progress_bar.py[line:272] - INFO: epoch 017:   1210 / 1732 loss=2.37, loss_v1=0, loss_v2=0, nll_loss=1.166, ntokens=1074.7, nsentences=32, sample_size=1074.7, sample_size_v1=0, sample_size_v2=0, ppl=2.24, wps=276.1, ups=0.26, wpb=1074.7, bsz=32, num_updates=28870, lr=4.72739e-06, gnorm=14.574, clip=100, loss_scale=32, train_wall=39, gb_free=8.5, wall=111409
2023-05-22 00:54:50 - progress_bar.py[line:272] - INFO: epoch 017:   1220 / 1732 loss=2.428, loss_v1=0, loss_v2=0, nll_loss=1.231, ntokens=1018.6, nsentences=32, sample_size=1018.6, sample_size_v1=0, sample_size_v2=0, ppl=2.35, wps=265, ups=0.26, wpb=1018.6, bsz=32, num_updates=28880, lr=4.72534e-06, gnorm=16.916, clip=100, loss_scale=32, train_wall=38, gb_free=8.5, wall=111447
2023-05-22 00:55:29 - progress_bar.py[line:272] - INFO: epoch 017:   1230 / 1732 loss=2.382, loss_v1=0, loss_v2=0, nll_loss=1.18, ntokens=1037.6, nsentences=32, sample_size=1037.6, sample_size_v1=0, sample_size_v2=0, ppl=2.27, wps=269, ups=0.26, wpb=1037.6, bsz=32, num_updates=28890, lr=4.7233e-06, gnorm=14.827, clip=100, loss_scale=32, train_wall=39, gb_free=8.5, wall=111486
2023-05-22 00:56:07 - progress_bar.py[line:272] - INFO: epoch 017:   1240 / 1732 loss=2.348, loss_v1=0, loss_v2=0, nll_loss=1.144, ntokens=1099.9, nsentences=32, sample_size=1099.9, sample_size_v1=0, sample_size_v2=0, ppl=2.21, wps=284.3, ups=0.26, wpb=1099.9, bsz=32, num_updates=28900, lr=4.72125e-06, gnorm=15.722, clip=100, loss_scale=32, train_wall=39, gb_free=8.2, wall=111524
2023-05-22 00:56:46 - progress_bar.py[line:272] - INFO: epoch 017:   1250 / 1732 loss=2.362, loss_v1=0, loss_v2=0, nll_loss=1.157, ntokens=1054.2, nsentences=32, sample_size=1054.2, sample_size_v1=0, sample_size_v2=0, ppl=2.23, wps=272.5, ups=0.26, wpb=1054.2, bsz=32, num_updates=28910, lr=4.7192e-06, gnorm=14.855, clip=100, loss_scale=32, train_wall=39, gb_free=8.1, wall=111563
2023-05-22 00:57:25 - progress_bar.py[line:272] - INFO: epoch 017:   1260 / 1732 loss=2.369, loss_v1=0, loss_v2=0, nll_loss=1.166, ntokens=1034.2, nsentences=32, sample_size=1034.2, sample_size_v1=0, sample_size_v2=0, ppl=2.24, wps=266.8, ups=0.26, wpb=1034.2, bsz=32, num_updates=28920, lr=4.71715e-06, gnorm=15.861, clip=100, loss_scale=32, train_wall=39, gb_free=8.8, wall=111602
2023-05-22 00:58:03 - progress_bar.py[line:272] - INFO: epoch 017:   1270 / 1732 loss=2.405, loss_v1=0, loss_v2=0, nll_loss=1.207, ntokens=1069.3, nsentences=32, sample_size=1069.3, sample_size_v1=0, sample_size_v2=0, ppl=2.31, wps=277.2, ups=0.26, wpb=1069.3, bsz=32, num_updates=28930, lr=4.71511e-06, gnorm=15.133, clip=100, loss_scale=32, train_wall=39, gb_free=8.6, wall=111640
2023-05-22 00:58:42 - progress_bar.py[line:272] - INFO: epoch 017:   1280 / 1732 loss=2.388, loss_v1=0, loss_v2=0, nll_loss=1.187, ntokens=1062.1, nsentences=32, sample_size=1062.1, sample_size_v1=0, sample_size_v2=0, ppl=2.28, wps=274, ups=0.26, wpb=1062.1, bsz=32, num_updates=28940, lr=4.71306e-06, gnorm=16.63, clip=100, loss_scale=32, train_wall=39, gb_free=8.4, wall=111679
2023-05-22 00:59:21 - progress_bar.py[line:272] - INFO: epoch 017:   1290 / 1732 loss=2.38, loss_v1=0, loss_v2=0, nll_loss=1.178, ntokens=1082.8, nsentences=32, sample_size=1082.8, sample_size_v1=0, sample_size_v2=0, ppl=2.26, wps=278, ups=0.26, wpb=1082.8, bsz=32, num_updates=28950, lr=4.71101e-06, gnorm=14.812, clip=100, loss_scale=32, train_wall=39, gb_free=8.4, wall=111718
2023-05-22 00:59:59 - progress_bar.py[line:272] - INFO: epoch 017:   1300 / 1732 loss=2.377, loss_v1=0, loss_v2=0, nll_loss=1.176, ntokens=1083.5, nsentences=32, sample_size=1083.5, sample_size_v1=0, sample_size_v2=0, ppl=2.26, wps=281.7, ups=0.26, wpb=1083.5, bsz=32, num_updates=28960, lr=4.70897e-06, gnorm=16.135, clip=100, loss_scale=32, train_wall=38, gb_free=8.5, wall=111757
2023-05-22 01:00:38 - progress_bar.py[line:272] - INFO: epoch 017:   1310 / 1732 loss=2.418, loss_v1=0, loss_v2=0, nll_loss=1.221, ntokens=1072.8, nsentences=32, sample_size=1072.8, sample_size_v1=0, sample_size_v2=0, ppl=2.33, wps=275.6, ups=0.26, wpb=1072.8, bsz=32, num_updates=28970, lr=4.70692e-06, gnorm=15.281, clip=100, loss_scale=32, train_wall=39, gb_free=8.4, wall=111796
2023-05-22 01:01:17 - progress_bar.py[line:272] - INFO: epoch 017:   1320 / 1732 loss=2.374, loss_v1=0, loss_v2=0, nll_loss=1.171, ntokens=1105.6, nsentences=32, sample_size=1105.6, sample_size_v1=0, sample_size_v2=0, ppl=2.25, wps=284, ups=0.26, wpb=1105.6, bsz=32, num_updates=28980, lr=4.70487e-06, gnorm=16.487, clip=100, loss_scale=32, train_wall=39, gb_free=7.1, wall=111834
2023-05-22 01:01:56 - progress_bar.py[line:272] - INFO: epoch 017:   1330 / 1732 loss=2.354, loss_v1=0, loss_v2=0, nll_loss=1.149, ntokens=1099.6, nsentences=32, sample_size=1099.6, sample_size_v1=0, sample_size_v2=0, ppl=2.22, wps=281, ups=0.26, wpb=1099.6, bsz=32, num_updates=28990, lr=4.70282e-06, gnorm=14.219, clip=100, loss_scale=32, train_wall=39, gb_free=8.2, wall=111874
2023-05-22 01:02:35 - progress_bar.py[line:272] - INFO: epoch 017:   1340 / 1732 loss=2.378, loss_v1=0, loss_v2=0, nll_loss=1.176, ntokens=1139, nsentences=32, sample_size=1139, sample_size_v1=0, sample_size_v2=0, ppl=2.26, wps=293, ups=0.26, wpb=1139, bsz=32, num_updates=29000, lr=4.70078e-06, gnorm=16.268, clip=100, loss_scale=32, train_wall=39, gb_free=8, wall=111913
2023-05-22 01:03:14 - progress_bar.py[line:272] - INFO: epoch 017:   1350 / 1732 loss=2.377, loss_v1=0, loss_v2=0, nll_loss=1.176, ntokens=1168.9, nsentences=32, sample_size=1168.9, sample_size_v1=0, sample_size_v2=0, ppl=2.26, wps=298.7, ups=0.26, wpb=1168.9, bsz=32, num_updates=29010, lr=4.69873e-06, gnorm=15.545, clip=100, loss_scale=32, train_wall=39, gb_free=8.5, wall=111952
2023-05-22 01:03:54 - progress_bar.py[line:272] - INFO: epoch 017:   1360 / 1732 loss=2.356, loss_v1=0, loss_v2=0, nll_loss=1.151, ntokens=1107.8, nsentences=32, sample_size=1107.8, sample_size_v1=0, sample_size_v2=0, ppl=2.22, wps=283.4, ups=0.26, wpb=1107.8, bsz=32, num_updates=29020, lr=4.69668e-06, gnorm=15.618, clip=100, loss_scale=32, train_wall=39, gb_free=8.3, wall=111991
2023-05-22 01:04:32 - progress_bar.py[line:272] - INFO: epoch 017:   1370 / 1732 loss=2.38, loss_v1=0, loss_v2=0, nll_loss=1.178, ntokens=1111.1, nsentences=32, sample_size=1111.1, sample_size_v1=0, sample_size_v2=0, ppl=2.26, wps=285.3, ups=0.26, wpb=1111.1, bsz=32, num_updates=29030, lr=4.69463e-06, gnorm=14.907, clip=100, loss_scale=32, train_wall=39, gb_free=8.3, wall=112030
2023-05-22 01:04:52 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2023-05-22 01:05:15 - progress_bar.py[line:272] - INFO: epoch 017:   1381 / 1732 loss=2.406, loss_v1=0, loss_v2=0, nll_loss=1.206, ntokens=1122.8, nsentences=32, sample_size=1122.8, sample_size_v1=0, sample_size_v2=0, ppl=2.31, wps=265, ups=0.24, wpb=1122.8, bsz=32, num_updates=29040, lr=4.69259e-06, gnorm=14.483, clip=100, loss_scale=32, train_wall=42, gb_free=8.5, wall=112072
2023-05-22 01:05:53 - progress_bar.py[line:272] - INFO: epoch 017:   1391 / 1732 loss=2.39, loss_v1=0, loss_v2=0, nll_loss=1.189, ntokens=1079.9, nsentences=32, sample_size=1079.9, sample_size_v1=0, sample_size_v2=0, ppl=2.28, wps=280.7, ups=0.26, wpb=1079.9, bsz=32, num_updates=29050, lr=4.69054e-06, gnorm=15.349, clip=100, loss_scale=32, train_wall=38, gb_free=8, wall=112111
2023-05-22 01:06:32 - progress_bar.py[line:272] - INFO: epoch 017:   1401 / 1732 loss=2.353, loss_v1=0, loss_v2=0, nll_loss=1.148, ntokens=1107.2, nsentences=32, sample_size=1107.2, sample_size_v1=0, sample_size_v2=0, ppl=2.22, wps=285.1, ups=0.26, wpb=1107.2, bsz=32, num_updates=29060, lr=4.68849e-06, gnorm=16.321, clip=100, loss_scale=32, train_wall=39, gb_free=9.1, wall=112149
2023-05-22 01:07:11 - progress_bar.py[line:272] - INFO: epoch 017:   1411 / 1732 loss=2.392, loss_v1=0, loss_v2=0, nll_loss=1.191, ntokens=1229.2, nsentences=32, sample_size=1229.2, sample_size_v1=0, sample_size_v2=0, ppl=2.28, wps=314.7, ups=0.26, wpb=1229.2, bsz=32, num_updates=29070, lr=4.68644e-06, gnorm=14.067, clip=100, loss_scale=32, train_wall=39, gb_free=8, wall=112188
2023-05-22 01:07:51 - progress_bar.py[line:272] - INFO: epoch 017:   1421 / 1732 loss=2.385, loss_v1=0, loss_v2=0, nll_loss=1.183, ntokens=1255.1, nsentences=32, sample_size=1255.1, sample_size_v1=0, sample_size_v2=0, ppl=2.27, wps=317.9, ups=0.25, wpb=1255.1, bsz=32, num_updates=29080, lr=4.6844e-06, gnorm=13.944, clip=100, loss_scale=32, train_wall=39, gb_free=6.8, wall=112228
2023-05-22 01:08:30 - progress_bar.py[line:272] - INFO: epoch 017:   1431 / 1732 loss=2.355, loss_v1=0, loss_v2=0, nll_loss=1.151, ntokens=1244.5, nsentences=32, sample_size=1244.5, sample_size_v1=0, sample_size_v2=0, ppl=2.22, wps=319.3, ups=0.26, wpb=1244.5, bsz=32, num_updates=29090, lr=4.68235e-06, gnorm=12.55, clip=100, loss_scale=32, train_wall=39, gb_free=7.8, wall=112267
2023-05-22 01:09:08 - progress_bar.py[line:272] - INFO: epoch 017:   1441 / 1732 loss=2.382, loss_v1=0, loss_v2=0, nll_loss=1.181, ntokens=1138.5, nsentences=32, sample_size=1138.5, sample_size_v1=0, sample_size_v2=0, ppl=2.27, wps=293.6, ups=0.26, wpb=1138.5, bsz=32, num_updates=29100, lr=4.6803e-06, gnorm=12.844, clip=100, loss_scale=32, train_wall=39, gb_free=8.3, wall=112306
2023-05-22 01:09:47 - progress_bar.py[line:272] - INFO: epoch 017:   1451 / 1732 loss=2.383, loss_v1=0, loss_v2=0, nll_loss=1.182, ntokens=1144.4, nsentences=32, sample_size=1144.4, sample_size_v1=0, sample_size_v2=0, ppl=2.27, wps=294.9, ups=0.26, wpb=1144.4, bsz=32, num_updates=29110, lr=4.67825e-06, gnorm=14.988, clip=100, loss_scale=32, train_wall=39, gb_free=8.1, wall=112345
2023-05-22 01:10:26 - progress_bar.py[line:272] - INFO: epoch 017:   1461 / 1732 loss=2.369, loss_v1=0, loss_v2=0, nll_loss=1.166, ntokens=1149.6, nsentences=32, sample_size=1149.6, sample_size_v1=0, sample_size_v2=0, ppl=2.24, wps=296.5, ups=0.26, wpb=1149.6, bsz=32, num_updates=29120, lr=4.67621e-06, gnorm=13.787, clip=100, loss_scale=32, train_wall=39, gb_free=8.1, wall=112383
2023-05-22 01:11:05 - progress_bar.py[line:272] - INFO: epoch 017:   1471 / 1732 loss=2.355, loss_v1=0, loss_v2=0, nll_loss=1.15, ntokens=1162.5, nsentences=32, sample_size=1162.5, sample_size_v1=0, sample_size_v2=0, ppl=2.22, wps=298, ups=0.26, wpb=1162.5, bsz=32, num_updates=29130, lr=4.67416e-06, gnorm=13.726, clip=100, loss_scale=32, train_wall=39, gb_free=8.8, wall=112422
2023-05-22 01:11:44 - progress_bar.py[line:272] - INFO: epoch 017:   1481 / 1732 loss=2.405, loss_v1=0, loss_v2=0, nll_loss=1.207, ntokens=1033.9, nsentences=32, sample_size=1033.9, sample_size_v1=0, sample_size_v2=0, ppl=2.31, wps=268.1, ups=0.26, wpb=1033.9, bsz=32, num_updates=29140, lr=4.67211e-06, gnorm=16.617, clip=100, loss_scale=32, train_wall=39, gb_free=8, wall=112461
2023-05-22 01:12:23 - progress_bar.py[line:272] - INFO: epoch 017:   1491 / 1732 loss=2.381, loss_v1=0, loss_v2=0, nll_loss=1.18, ntokens=1139.7, nsentences=32, sample_size=1139.7, sample_size_v1=0, sample_size_v2=0, ppl=2.27, wps=291.6, ups=0.26, wpb=1139.7, bsz=32, num_updates=29150, lr=4.67007e-06, gnorm=14.687, clip=100, loss_scale=32, train_wall=39, gb_free=8.5, wall=112500
2023-05-22 01:13:01 - progress_bar.py[line:272] - INFO: epoch 017:   1501 / 1732 loss=2.339, loss_v1=0, loss_v2=0, nll_loss=1.132, ntokens=1132.8, nsentences=32, sample_size=1132.8, sample_size_v1=0, sample_size_v2=0, ppl=2.19, wps=292.9, ups=0.26, wpb=1132.8, bsz=32, num_updates=29160, lr=4.66802e-06, gnorm=13.859, clip=100, loss_scale=32, train_wall=39, gb_free=7.9, wall=112539
2023-05-22 01:13:40 - progress_bar.py[line:272] - INFO: epoch 017:   1511 / 1732 loss=2.368, loss_v1=0, loss_v2=0, nll_loss=1.166, ntokens=1056, nsentences=32, sample_size=1056, sample_size_v1=0, sample_size_v2=0, ppl=2.24, wps=275.8, ups=0.26, wpb=1056, bsz=32, num_updates=29170, lr=4.66597e-06, gnorm=14.918, clip=100, loss_scale=32, train_wall=38, gb_free=7.9, wall=112577
2023-05-22 01:14:18 - progress_bar.py[line:272] - INFO: epoch 017:   1521 / 1732 loss=2.4, loss_v1=0, loss_v2=0, nll_loss=1.202, ntokens=1046.7, nsentences=32, sample_size=1046.7, sample_size_v1=0, sample_size_v2=0, ppl=2.3, wps=271.1, ups=0.26, wpb=1046.7, bsz=32, num_updates=29180, lr=4.66392e-06, gnorm=15.239, clip=100, loss_scale=32, train_wall=39, gb_free=8.7, wall=112616
2023-05-22 01:14:57 - progress_bar.py[line:272] - INFO: epoch 017:   1531 / 1732 loss=2.409, loss_v1=0, loss_v2=0, nll_loss=1.21, ntokens=1056, nsentences=32, sample_size=1056, sample_size_v1=0, sample_size_v2=0, ppl=2.31, wps=273.3, ups=0.26, wpb=1056, bsz=32, num_updates=29190, lr=4.66188e-06, gnorm=15.791, clip=100, loss_scale=32, train_wall=39, gb_free=7.8, wall=112654
2023-05-22 01:15:36 - progress_bar.py[line:272] - INFO: epoch 017:   1541 / 1732 loss=2.361, loss_v1=0, loss_v2=0, nll_loss=1.155, ntokens=1105.6, nsentences=32, sample_size=1105.6, sample_size_v1=0, sample_size_v2=0, ppl=2.23, wps=284.1, ups=0.26, wpb=1105.6, bsz=32, num_updates=29200, lr=4.65983e-06, gnorm=14.447, clip=100, loss_scale=32, train_wall=39, gb_free=8.7, wall=112693
2023-05-22 01:16:14 - progress_bar.py[line:272] - INFO: epoch 017:   1551 / 1732 loss=2.36, loss_v1=0, loss_v2=0, nll_loss=1.155, ntokens=1073.3, nsentences=32, sample_size=1073.3, sample_size_v1=0, sample_size_v2=0, ppl=2.23, wps=278.7, ups=0.26, wpb=1073.3, bsz=32, num_updates=29210, lr=4.65778e-06, gnorm=14.619, clip=100, loss_scale=32, train_wall=38, gb_free=8.5, wall=112732
2023-05-22 01:16:53 - progress_bar.py[line:272] - INFO: epoch 017:   1561 / 1732 loss=2.383, loss_v1=0, loss_v2=0, nll_loss=1.182, ntokens=1091.5, nsentences=32, sample_size=1091.5, sample_size_v1=0, sample_size_v2=0, ppl=2.27, wps=282.1, ups=0.26, wpb=1091.5, bsz=32, num_updates=29220, lr=4.65573e-06, gnorm=15.532, clip=100, loss_scale=32, train_wall=39, gb_free=8.5, wall=112770
2023-05-22 01:17:32 - progress_bar.py[line:272] - INFO: epoch 017:   1571 / 1732 loss=2.409, loss_v1=0, loss_v2=0, nll_loss=1.211, ntokens=1079.7, nsentences=32, sample_size=1079.7, sample_size_v1=0, sample_size_v2=0, ppl=2.32, wps=278, ups=0.26, wpb=1079.7, bsz=32, num_updates=29230, lr=4.65369e-06, gnorm=16.283, clip=100, loss_scale=32, train_wall=39, gb_free=7.7, wall=112809
2023-05-22 01:18:11 - progress_bar.py[line:272] - INFO: epoch 017:   1581 / 1732 loss=2.415, loss_v1=0, loss_v2=0, nll_loss=1.218, ntokens=984.8, nsentences=32, sample_size=984.8, sample_size_v1=0, sample_size_v2=0, ppl=2.33, wps=254.8, ups=0.26, wpb=984.8, bsz=32, num_updates=29240, lr=4.65164e-06, gnorm=16.708, clip=100, loss_scale=32, train_wall=39, gb_free=8, wall=112848
2023-05-22 01:18:49 - progress_bar.py[line:272] - INFO: epoch 017:   1591 / 1732 loss=2.366, loss_v1=0, loss_v2=0, nll_loss=1.164, ntokens=1097.4, nsentences=32, sample_size=1097.4, sample_size_v1=0, sample_size_v2=0, ppl=2.24, wps=282.9, ups=0.26, wpb=1097.4, bsz=32, num_updates=29250, lr=4.64959e-06, gnorm=14.676, clip=100, loss_scale=32, train_wall=39, gb_free=8.3, wall=112887
2023-05-22 01:19:28 - progress_bar.py[line:272] - INFO: epoch 017:   1601 / 1732 loss=2.356, loss_v1=0, loss_v2=0, nll_loss=1.153, ntokens=1085.9, nsentences=32, sample_size=1085.9, sample_size_v1=0, sample_size_v2=0, ppl=2.22, wps=282.6, ups=0.26, wpb=1085.9, bsz=32, num_updates=29260, lr=4.64754e-06, gnorm=15.579, clip=100, loss_scale=32, train_wall=38, gb_free=8.4, wall=112925
2023-05-22 01:20:07 - progress_bar.py[line:272] - INFO: epoch 017:   1611 / 1732 loss=2.351, loss_v1=0, loss_v2=0, nll_loss=1.146, ntokens=1158.1, nsentences=32, sample_size=1158.1, sample_size_v1=0, sample_size_v2=0, ppl=2.21, wps=296.9, ups=0.26, wpb=1158.1, bsz=32, num_updates=29270, lr=4.6455e-06, gnorm=14.392, clip=100, loss_scale=32, train_wall=39, gb_free=8.2, wall=112964
2023-05-22 01:20:46 - progress_bar.py[line:272] - INFO: epoch 017:   1621 / 1732 loss=2.341, loss_v1=0, loss_v2=0, nll_loss=1.134, ntokens=1113.1, nsentences=32, sample_size=1113.1, sample_size_v1=0, sample_size_v2=0, ppl=2.2, wps=285.4, ups=0.26, wpb=1113.1, bsz=32, num_updates=29280, lr=4.64345e-06, gnorm=14.849, clip=100, loss_scale=32, train_wall=39, gb_free=8.6, wall=113003
2023-05-22 01:21:25 - progress_bar.py[line:272] - INFO: epoch 017:   1631 / 1732 loss=2.365, loss_v1=0, loss_v2=0, nll_loss=1.163, ntokens=1151.4, nsentences=32, sample_size=1151.4, sample_size_v1=0, sample_size_v2=0, ppl=2.24, wps=294.9, ups=0.26, wpb=1151.4, bsz=32, num_updates=29290, lr=4.6414e-06, gnorm=15.399, clip=100, loss_scale=32, train_wall=39, gb_free=8.3, wall=113042
2023-05-22 01:22:04 - progress_bar.py[line:272] - INFO: epoch 017:   1641 / 1732 loss=2.344, loss_v1=0, loss_v2=0, nll_loss=1.139, ntokens=1178.1, nsentences=32, sample_size=1178.1, sample_size_v1=0, sample_size_v2=0, ppl=2.2, wps=302, ups=0.26, wpb=1178.1, bsz=32, num_updates=29300, lr=4.63935e-06, gnorm=14.886, clip=100, loss_scale=32, train_wall=39, gb_free=7, wall=113081
2023-05-22 01:22:43 - progress_bar.py[line:272] - INFO: epoch 017:   1651 / 1732 loss=2.357, loss_v1=0, loss_v2=0, nll_loss=1.152, ntokens=1103.6, nsentences=32, sample_size=1103.6, sample_size_v1=0, sample_size_v2=0, ppl=2.22, wps=285.7, ups=0.26, wpb=1103.6, bsz=32, num_updates=29310, lr=4.63731e-06, gnorm=15.385, clip=100, loss_scale=32, train_wall=39, gb_free=9.2, wall=113120
2023-05-22 01:23:21 - progress_bar.py[line:272] - INFO: epoch 017:   1661 / 1732 loss=2.388, loss_v1=0, loss_v2=0, nll_loss=1.186, ntokens=1033.5, nsentences=32, sample_size=1033.5, sample_size_v1=0, sample_size_v2=0, ppl=2.28, wps=268.4, ups=0.26, wpb=1033.5, bsz=32, num_updates=29320, lr=4.63526e-06, gnorm=15.205, clip=100, loss_scale=32, train_wall=38, gb_free=8, wall=113158
2023-05-22 01:23:59 - progress_bar.py[line:272] - INFO: epoch 017:   1671 / 1732 loss=2.368, loss_v1=0, loss_v2=0, nll_loss=1.164, ntokens=998, nsentences=32, sample_size=998, sample_size_v1=0, sample_size_v2=0, ppl=2.24, wps=259.9, ups=0.26, wpb=998, bsz=32, num_updates=29330, lr=4.63321e-06, gnorm=17.146, clip=100, loss_scale=32, train_wall=38, gb_free=8.5, wall=113197
2023-05-22 01:24:38 - progress_bar.py[line:272] - INFO: epoch 017:   1681 / 1732 loss=2.325, loss_v1=0, loss_v2=0, nll_loss=1.118, ntokens=1185.3, nsentences=32, sample_size=1185.3, sample_size_v1=0, sample_size_v2=0, ppl=2.17, wps=304.2, ups=0.26, wpb=1185.3, bsz=32, num_updates=29340, lr=4.63117e-06, gnorm=13.141, clip=100, loss_scale=32, train_wall=39, gb_free=8.4, wall=113236
2023-05-22 01:25:18 - progress_bar.py[line:272] - INFO: epoch 017:   1691 / 1732 loss=2.349, loss_v1=0, loss_v2=0, nll_loss=1.144, ntokens=1205.4, nsentences=32, sample_size=1205.4, sample_size_v1=0, sample_size_v2=0, ppl=2.21, wps=308.2, ups=0.26, wpb=1205.4, bsz=32, num_updates=29350, lr=4.62912e-06, gnorm=13.094, clip=100, loss_scale=32, train_wall=39, gb_free=7.7, wall=113275
2023-05-22 01:25:57 - progress_bar.py[line:272] - INFO: epoch 017:   1701 / 1732 loss=2.362, loss_v1=0, loss_v2=0, nll_loss=1.159, ntokens=1274, nsentences=32, sample_size=1274, sample_size_v1=0, sample_size_v2=0, ppl=2.23, wps=324, ups=0.25, wpb=1274, bsz=32, num_updates=29360, lr=4.62707e-06, gnorm=13.418, clip=100, loss_scale=32, train_wall=39, gb_free=8.4, wall=113314
2023-05-22 01:26:36 - progress_bar.py[line:272] - INFO: epoch 017:   1711 / 1732 loss=2.374, loss_v1=0, loss_v2=0, nll_loss=1.173, ntokens=1171.2, nsentences=32, sample_size=1171.2, sample_size_v1=0, sample_size_v2=0, ppl=2.25, wps=301.2, ups=0.26, wpb=1171.2, bsz=32, num_updates=29370, lr=4.62502e-06, gnorm=14.695, clip=100, loss_scale=32, train_wall=39, gb_free=8.7, wall=113353
2023-05-22 01:27:15 - progress_bar.py[line:272] - INFO: epoch 017:   1721 / 1732 loss=2.346, loss_v1=0, loss_v2=0, nll_loss=1.141, ntokens=1173.7, nsentences=32, sample_size=1173.7, sample_size_v1=0, sample_size_v2=0, ppl=2.2, wps=300.8, ups=0.26, wpb=1173.7, bsz=32, num_updates=29380, lr=4.62298e-06, gnorm=13.168, clip=100, loss_scale=32, train_wall=39, gb_free=8, wall=113392
2023-05-22 01:27:54 - progress_bar.py[line:272] - INFO: epoch 017:   1731 / 1732 loss=2.415, loss_v1=0, loss_v2=0, nll_loss=1.218, ntokens=1135.4, nsentences=32, sample_size=1135.4, sample_size_v1=0, sample_size_v2=0, ppl=2.33, wps=291.9, ups=0.26, wpb=1135.4, bsz=32, num_updates=29390, lr=4.62093e-06, gnorm=14.399, clip=100, loss_scale=32, train_wall=39, gb_free=8.4, wall=113431
2023-05-22 01:27:55 - train.py[line:332] - INFO: end of epoch 17 (average epoch stats below)
2023-05-22 01:27:55 - progress_bar.py[line:282] - INFO: epoch 017 | loss 2.381 | loss_v1 0 | loss_v2 0 | nll_loss 1.179 | ntokens 1051.57 | nsentences 31.986 | sample_size 1051.57 | sample_size_v1 0 | sample_size_v2 0 | ppl 2.26 | wps 272.4 | ups 0.26 | wpb 1051.6 | bsz 32 | num_updates 29391 | lr 4.62072e-06 | gnorm 14.864 | clip 100 | loss_scale 32 | train_wall 6663 | gb_free 8.9 | wall 113432
2023-05-22 01:27:55 - trainer.py[line:639] - INFO: loading train data for epoch 18
local datafile ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 0 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 0 finished initializing row_count and line_idx-to-offset mapping
file ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 0 row count 55400 total row count 55400
slice_id 0 seek offset 0
2023-05-22 01:27:56 - trainer.py[line:703] - INFO: begin training epoch 18
2023-05-22 01:27:56 - train.py[line:305] - INFO: Start iterating over samples
2023-05-22 01:28:32 - progress_bar.py[line:272] - INFO: epoch 018:      9 / 1732 loss=2.308, loss_v1=0, loss_v2=0, nll_loss=1.096, ntokens=1061, nsentences=29.6, sample_size=1061, sample_size_v1=0, sample_size_v2=0, ppl=2.14, wps=279.4, ups=0.26, wpb=1061, bsz=29.6, num_updates=29400, lr=4.61888e-06, gnorm=15.879, clip=100, loss_scale=32, train_wall=36, gb_free=8.1, wall=113469
2023-05-22 01:29:10 - progress_bar.py[line:272] - INFO: epoch 018:     19 / 1732 loss=2.252, loss_v1=0, loss_v2=0, nll_loss=1.035, ntokens=1084.7, nsentences=32, sample_size=1084.7, sample_size_v1=0, sample_size_v2=0, ppl=2.05, wps=280.6, ups=0.26, wpb=1084.7, bsz=32, num_updates=29410, lr=4.61683e-06, gnorm=14.171, clip=100, loss_scale=32, train_wall=39, gb_free=8.6, wall=113507
2023-05-22 01:29:49 - progress_bar.py[line:272] - INFO: epoch 018:     29 / 1732 loss=2.352, loss_v1=0, loss_v2=0, nll_loss=1.147, ntokens=941, nsentences=32, sample_size=941, sample_size_v1=0, sample_size_v2=0, ppl=2.21, wps=244.5, ups=0.26, wpb=941, bsz=32, num_updates=29420, lr=4.61479e-06, gnorm=16.077, clip=100, loss_scale=32, train_wall=38, gb_free=8.5, wall=113546
2023-05-22 01:30:28 - progress_bar.py[line:272] - INFO: epoch 018:     39 / 1732 loss=2.116, loss_v1=0, loss_v2=0, nll_loss=0.883, ntokens=1243.8, nsentences=32, sample_size=1243.8, sample_size_v1=0, sample_size_v2=0, ppl=1.84, wps=315.1, ups=0.25, wpb=1243.8, bsz=32, num_updates=29430, lr=4.61274e-06, gnorm=9.801, clip=100, loss_scale=32, train_wall=39, gb_free=7.4, wall=113585
2023-05-22 01:31:07 - progress_bar.py[line:272] - INFO: epoch 018:     49 / 1732 loss=2.223, loss_v1=0, loss_v2=0, nll_loss=1.01, ntokens=1045.9, nsentences=32, sample_size=1045.9, sample_size_v1=0, sample_size_v2=0, ppl=2.01, wps=269.6, ups=0.26, wpb=1045.9, bsz=32, num_updates=29440, lr=4.61069e-06, gnorm=12.984, clip=100, loss_scale=32, train_wall=39, gb_free=7.8, wall=113624
2023-05-22 01:31:45 - progress_bar.py[line:272] - INFO: epoch 018:     59 / 1732 loss=2.08, loss_v1=0, loss_v2=0, nll_loss=0.844, ntokens=1005.7, nsentences=32, sample_size=1005.7, sample_size_v1=0, sample_size_v2=0, ppl=1.8, wps=262.2, ups=0.26, wpb=1005.7, bsz=32, num_updates=29450, lr=4.60864e-06, gnorm=12.691, clip=100, loss_scale=32, train_wall=38, gb_free=8.5, wall=113663
2023-05-22 01:32:26 - progress_bar.py[line:272] - INFO: epoch 018:     69 / 1732 loss=2.051, loss_v1=0, loss_v2=0, nll_loss=0.812, ntokens=1433.6, nsentences=32, sample_size=1433.6, sample_size_v1=0, sample_size_v2=0, ppl=1.76, wps=355.5, ups=0.25, wpb=1433.6, bsz=32, num_updates=29460, lr=4.6066e-06, gnorm=10.139, clip=100, loss_scale=32, train_wall=40, gb_free=8, wall=113703
2023-05-22 01:33:05 - progress_bar.py[line:272] - INFO: epoch 018:     79 / 1732 loss=2.13, loss_v1=0, loss_v2=0, nll_loss=0.898, ntokens=1268.1, nsentences=32, sample_size=1268.1, sample_size_v1=0, sample_size_v2=0, ppl=1.86, wps=319, ups=0.25, wpb=1268.1, bsz=32, num_updates=29470, lr=4.60455e-06, gnorm=11.959, clip=100, loss_scale=32, train_wall=40, gb_free=7.4, wall=113743
2023-05-22 01:33:45 - progress_bar.py[line:272] - INFO: epoch 018:     89 / 1732 loss=2.237, loss_v1=0, loss_v2=0, nll_loss=1.017, ntokens=1075.5, nsentences=32, sample_size=1075.5, sample_size_v1=0, sample_size_v2=0, ppl=2.02, wps=275.2, ups=0.26, wpb=1075.5, bsz=32, num_updates=29480, lr=4.6025e-06, gnorm=14.939, clip=100, loss_scale=32, train_wall=39, gb_free=7, wall=113782
2023-05-22 01:34:23 - progress_bar.py[line:272] - INFO: epoch 018:     99 / 1732 loss=2.191, loss_v1=0, loss_v2=0, nll_loss=0.968, ntokens=1059.8, nsentences=32, sample_size=1059.8, sample_size_v1=0, sample_size_v2=0, ppl=1.96, wps=275, ups=0.26, wpb=1059.8, bsz=32, num_updates=29490, lr=4.60045e-06, gnorm=13.576, clip=100, loss_scale=32, train_wall=38, gb_free=9.1, wall=113820
2023-05-22 01:35:01 - progress_bar.py[line:272] - INFO: epoch 018:    109 / 1732 loss=2.383, loss_v1=0, loss_v2=0, nll_loss=1.184, ntokens=996.8, nsentences=32, sample_size=996.8, sample_size_v1=0, sample_size_v2=0, ppl=2.27, wps=260.6, ups=0.26, wpb=996.8, bsz=32, num_updates=29500, lr=4.59841e-06, gnorm=16.946, clip=100, loss_scale=32, train_wall=38, gb_free=8.8, wall=113859
2023-05-22 01:35:41 - progress_bar.py[line:272] - INFO: epoch 018:    119 / 1732 loss=2.354, loss_v1=0, loss_v2=0, nll_loss=1.148, ntokens=1100.1, nsentences=32, sample_size=1100.1, sample_size_v1=0, sample_size_v2=0, ppl=2.22, wps=280.9, ups=0.26, wpb=1100.1, bsz=32, num_updates=29510, lr=4.59636e-06, gnorm=14.274, clip=100, loss_scale=32, train_wall=39, gb_free=7.3, wall=113898
2023-05-22 01:36:20 - progress_bar.py[line:272] - INFO: epoch 018:    129 / 1732 loss=2.339, loss_v1=0, loss_v2=0, nll_loss=1.131, ntokens=1171.3, nsentences=32, sample_size=1171.3, sample_size_v1=0, sample_size_v2=0, ppl=2.19, wps=297.1, ups=0.25, wpb=1171.3, bsz=32, num_updates=29520, lr=4.59431e-06, gnorm=13.312, clip=100, loss_scale=32, train_wall=39, gb_free=7.7, wall=113937
2023-05-22 01:37:00 - progress_bar.py[line:272] - INFO: epoch 018:    139 / 1732 loss=2.283, loss_v1=0, loss_v2=0, nll_loss=1.073, ntokens=1243.3, nsentences=32, sample_size=1243.3, sample_size_v1=0, sample_size_v2=0, ppl=2.1, wps=313.7, ups=0.25, wpb=1243.3, bsz=32, num_updates=29530, lr=4.59227e-06, gnorm=12.886, clip=100, loss_scale=32, train_wall=40, gb_free=7.4, wall=113977
2023-05-22 01:37:39 - progress_bar.py[line:272] - INFO: epoch 018:    149 / 1732 loss=2.255, loss_v1=0, loss_v2=0, nll_loss=1.039, ntokens=1177.5, nsentences=32, sample_size=1177.5, sample_size_v1=0, sample_size_v2=0, ppl=2.05, wps=297.2, ups=0.25, wpb=1177.5, bsz=32, num_updates=29540, lr=4.59022e-06, gnorm=10.748, clip=100, loss_scale=32, train_wall=40, gb_free=7.4, wall=114016
2023-05-22 01:38:19 - progress_bar.py[line:272] - INFO: epoch 018:    159 / 1732 loss=2.307, loss_v1=0, loss_v2=0, nll_loss=1.096, ntokens=1139.9, nsentences=32, sample_size=1139.9, sample_size_v1=0, sample_size_v2=0, ppl=2.14, wps=287.3, ups=0.25, wpb=1139.9, bsz=32, num_updates=29550, lr=4.58817e-06, gnorm=12.564, clip=100, loss_scale=64, train_wall=40, gb_free=8.5, wall=114056
2023-05-22 01:38:54 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2023-05-22 01:39:01 - progress_bar.py[line:272] - INFO: epoch 018:    170 / 1732 loss=2.281, loss_v1=0, loss_v2=0, nll_loss=1.07, ntokens=982.7, nsentences=32, sample_size=982.7, sample_size_v1=0, sample_size_v2=0, ppl=2.1, wps=231.2, ups=0.24, wpb=982.7, bsz=32, num_updates=29560, lr=4.58612e-06, gnorm=13.423, clip=100, loss_scale=32, train_wall=42, gb_free=8.5, wall=114099
2023-05-22 01:39:41 - progress_bar.py[line:272] - INFO: epoch 018:    180 / 1732 loss=2.258, loss_v1=0, loss_v2=0, nll_loss=1.043, ntokens=1102.7, nsentences=32, sample_size=1102.7, sample_size_v1=0, sample_size_v2=0, ppl=2.06, wps=281, ups=0.25, wpb=1102.7, bsz=32, num_updates=29570, lr=4.58408e-06, gnorm=14.408, clip=100, loss_scale=32, train_wall=39, gb_free=8.1, wall=114138
2023-05-22 01:40:20 - progress_bar.py[line:272] - INFO: epoch 018:    190 / 1732 loss=2.269, loss_v1=0, loss_v2=0, nll_loss=1.053, ntokens=1120.1, nsentences=32, sample_size=1120.1, sample_size_v1=0, sample_size_v2=0, ppl=2.07, wps=284.8, ups=0.25, wpb=1120.1, bsz=32, num_updates=29580, lr=4.58203e-06, gnorm=12.662, clip=100, loss_scale=32, train_wall=39, gb_free=7.8, wall=114177
2023-05-22 01:40:59 - progress_bar.py[line:272] - INFO: epoch 018:    200 / 1732 loss=2.328, loss_v1=0, loss_v2=0, nll_loss=1.12, ntokens=1100.1, nsentences=32, sample_size=1100.1, sample_size_v1=0, sample_size_v2=0, ppl=2.17, wps=282.6, ups=0.26, wpb=1100.1, bsz=32, num_updates=29590, lr=4.57998e-06, gnorm=13.747, clip=100, loss_scale=32, train_wall=39, gb_free=8.9, wall=114216
2023-05-22 01:41:37 - progress_bar.py[line:272] - INFO: epoch 018:    210 / 1732 loss=2.403, loss_v1=0, loss_v2=0, nll_loss=1.205, ntokens=1012.9, nsentences=32, sample_size=1012.9, sample_size_v1=0, sample_size_v2=0, ppl=2.31, wps=263.5, ups=0.26, wpb=1012.9, bsz=32, num_updates=29600, lr=4.57793e-06, gnorm=14.892, clip=100, loss_scale=32, train_wall=38, gb_free=8.4, wall=114255
2023-05-22 01:42:16 - progress_bar.py[line:272] - INFO: epoch 018:    220 / 1732 loss=2.396, loss_v1=0, loss_v2=0, nll_loss=1.197, ntokens=1142.1, nsentences=32, sample_size=1142.1, sample_size_v1=0, sample_size_v2=0, ppl=2.29, wps=297.6, ups=0.26, wpb=1142.1, bsz=32, num_updates=29610, lr=4.57589e-06, gnorm=13.549, clip=100, loss_scale=32, train_wall=38, gb_free=8.4, wall=114293
2023-05-22 01:42:54 - progress_bar.py[line:272] - INFO: epoch 018:    230 / 1732 loss=2.419, loss_v1=0, loss_v2=0, nll_loss=1.223, ntokens=1099.8, nsentences=32, sample_size=1099.8, sample_size_v1=0, sample_size_v2=0, ppl=2.33, wps=287, ups=0.26, wpb=1099.8, bsz=32, num_updates=29620, lr=4.57384e-06, gnorm=13.817, clip=100, loss_scale=32, train_wall=38, gb_free=8.1, wall=114331
2023-05-22 01:43:32 - progress_bar.py[line:272] - INFO: epoch 018:    240 / 1732 loss=2.433, loss_v1=0, loss_v2=0, nll_loss=1.236, ntokens=1111.4, nsentences=32, sample_size=1111.4, sample_size_v1=0, sample_size_v2=0, ppl=2.35, wps=289.5, ups=0.26, wpb=1111.4, bsz=32, num_updates=29630, lr=4.57179e-06, gnorm=14.164, clip=100, loss_scale=32, train_wall=38, gb_free=8, wall=114370
2023-05-22 01:44:11 - progress_bar.py[line:272] - INFO: epoch 018:    250 / 1732 loss=2.413, loss_v1=0, loss_v2=0, nll_loss=1.214, ntokens=1170.4, nsentences=32, sample_size=1170.4, sample_size_v1=0, sample_size_v2=0, ppl=2.32, wps=302.5, ups=0.26, wpb=1170.4, bsz=32, num_updates=29640, lr=4.56974e-06, gnorm=14.025, clip=100, loss_scale=32, train_wall=39, gb_free=7.9, wall=114408
2023-05-22 01:44:50 - progress_bar.py[line:272] - INFO: epoch 018:    260 / 1732 loss=2.441, loss_v1=0, loss_v2=0, nll_loss=1.246, ntokens=1120.1, nsentences=32, sample_size=1120.1, sample_size_v1=0, sample_size_v2=0, ppl=2.37, wps=291.5, ups=0.26, wpb=1120.1, bsz=32, num_updates=29650, lr=4.5677e-06, gnorm=15.068, clip=100, loss_scale=32, train_wall=38, gb_free=8.3, wall=114447
2023-05-22 01:45:28 - progress_bar.py[line:272] - INFO: epoch 018:    270 / 1732 loss=2.403, loss_v1=0, loss_v2=0, nll_loss=1.203, ntokens=1146.7, nsentences=32, sample_size=1146.7, sample_size_v1=0, sample_size_v2=0, ppl=2.3, wps=296.4, ups=0.26, wpb=1146.7, bsz=32, num_updates=29660, lr=4.56565e-06, gnorm=13.338, clip=100, loss_scale=32, train_wall=39, gb_free=7.9, wall=114485
2023-05-22 01:46:07 - progress_bar.py[line:272] - INFO: epoch 018:    280 / 1732 loss=2.42, loss_v1=0, loss_v2=0, nll_loss=1.223, ntokens=1171.6, nsentences=32, sample_size=1171.6, sample_size_v1=0, sample_size_v2=0, ppl=2.33, wps=302, ups=0.26, wpb=1171.6, bsz=32, num_updates=29670, lr=4.5636e-06, gnorm=14.067, clip=100, loss_scale=32, train_wall=39, gb_free=8.2, wall=114524
2023-05-22 01:46:45 - progress_bar.py[line:272] - INFO: epoch 018:    290 / 1732 loss=2.392, loss_v1=0, loss_v2=0, nll_loss=1.192, ntokens=1121.4, nsentences=32, sample_size=1121.4, sample_size_v1=0, sample_size_v2=0, ppl=2.28, wps=292.4, ups=0.26, wpb=1121.4, bsz=32, num_updates=29680, lr=4.56155e-06, gnorm=14.787, clip=100, loss_scale=32, train_wall=38, gb_free=9, wall=114563
2023-05-22 01:47:24 - progress_bar.py[line:272] - INFO: epoch 018:    300 / 1732 loss=2.413, loss_v1=0, loss_v2=0, nll_loss=1.215, ntokens=1116.4, nsentences=32, sample_size=1116.4, sample_size_v1=0, sample_size_v2=0, ppl=2.32, wps=290.1, ups=0.26, wpb=1116.4, bsz=32, num_updates=29690, lr=4.55951e-06, gnorm=14.037, clip=100, loss_scale=32, train_wall=38, gb_free=7.7, wall=114601
2023-05-22 01:48:02 - progress_bar.py[line:272] - INFO: epoch 018:    310 / 1732 loss=2.387, loss_v1=0, loss_v2=0, nll_loss=1.186, ntokens=1069.4, nsentences=32, sample_size=1069.4, sample_size_v1=0, sample_size_v2=0, ppl=2.27, wps=279.6, ups=0.26, wpb=1069.4, bsz=32, num_updates=29700, lr=4.55746e-06, gnorm=15.025, clip=100, loss_scale=32, train_wall=38, gb_free=7.9, wall=114639
2023-05-22 01:48:40 - progress_bar.py[line:272] - INFO: epoch 018:    320 / 1732 loss=2.433, loss_v1=0, loss_v2=0, nll_loss=1.237, ntokens=1013.1, nsentences=32, sample_size=1013.1, sample_size_v1=0, sample_size_v2=0, ppl=2.36, wps=266.6, ups=0.26, wpb=1013.1, bsz=32, num_updates=29710, lr=4.55541e-06, gnorm=15.706, clip=100, loss_scale=32, train_wall=38, gb_free=8.6, wall=114677
2023-05-22 01:49:18 - progress_bar.py[line:272] - INFO: epoch 018:    330 / 1732 loss=2.449, loss_v1=0, loss_v2=0, nll_loss=1.256, ntokens=1024.4, nsentences=32, sample_size=1024.4, sample_size_v1=0, sample_size_v2=0, ppl=2.39, wps=268.9, ups=0.26, wpb=1024.4, bsz=32, num_updates=29720, lr=4.55336e-06, gnorm=15.076, clip=100, loss_scale=32, train_wall=38, gb_free=8.7, wall=114715
2023-05-22 01:49:56 - progress_bar.py[line:272] - INFO: epoch 018:    340 / 1732 loss=2.394, loss_v1=0, loss_v2=0, nll_loss=1.193, ntokens=959.9, nsentences=32, sample_size=959.9, sample_size_v1=0, sample_size_v2=0, ppl=2.29, wps=252.7, ups=0.26, wpb=959.9, bsz=32, num_updates=29730, lr=4.55132e-06, gnorm=15.333, clip=100, loss_scale=32, train_wall=38, gb_free=8.7, wall=114753
2023-05-22 01:50:34 - progress_bar.py[line:272] - INFO: epoch 018:    350 / 1732 loss=2.411, loss_v1=0, loss_v2=0, nll_loss=1.213, ntokens=909.7, nsentences=32, sample_size=909.7, sample_size_v1=0, sample_size_v2=0, ppl=2.32, wps=240.2, ups=0.26, wpb=909.7, bsz=32, num_updates=29740, lr=4.54927e-06, gnorm=16.968, clip=100, loss_scale=32, train_wall=38, gb_free=8.8, wall=114791
2023-05-22 01:51:12 - progress_bar.py[line:272] - INFO: epoch 018:    360 / 1732 loss=2.445, loss_v1=0, loss_v2=0, nll_loss=1.251, ntokens=938.9, nsentences=32, sample_size=938.9, sample_size_v1=0, sample_size_v2=0, ppl=2.38, wps=247.6, ups=0.26, wpb=938.9, bsz=32, num_updates=29750, lr=4.54722e-06, gnorm=16.025, clip=100, loss_scale=32, train_wall=38, gb_free=8.8, wall=114829
2023-05-22 01:51:50 - progress_bar.py[line:272] - INFO: epoch 018:    370 / 1732 loss=2.458, loss_v1=0, loss_v2=0, nll_loss=1.266, ntokens=953.9, nsentences=32, sample_size=953.9, sample_size_v1=0, sample_size_v2=0, ppl=2.41, wps=252.3, ups=0.26, wpb=953.9, bsz=32, num_updates=29760, lr=4.54518e-06, gnorm=16.091, clip=100, loss_scale=32, train_wall=38, gb_free=9.2, wall=114867
2023-05-22 01:52:28 - progress_bar.py[line:272] - INFO: epoch 018:    380 / 1732 loss=2.441, loss_v1=0, loss_v2=0, nll_loss=1.246, ntokens=1091.6, nsentences=32, sample_size=1091.6, sample_size_v1=0, sample_size_v2=0, ppl=2.37, wps=286.7, ups=0.26, wpb=1091.6, bsz=32, num_updates=29770, lr=4.54313e-06, gnorm=15.664, clip=100, loss_scale=32, train_wall=38, gb_free=8.9, wall=114905
2023-05-22 01:53:06 - progress_bar.py[line:272] - INFO: epoch 018:    390 / 1732 loss=2.42, loss_v1=0, loss_v2=0, nll_loss=1.223, ntokens=1027.2, nsentences=32, sample_size=1027.2, sample_size_v1=0, sample_size_v2=0, ppl=2.33, wps=270.8, ups=0.26, wpb=1027.2, bsz=32, num_updates=29780, lr=4.54108e-06, gnorm=15.407, clip=100, loss_scale=32, train_wall=38, gb_free=8.3, wall=114943
2023-05-22 01:53:44 - progress_bar.py[line:272] - INFO: epoch 018:    400 / 1732 loss=2.413, loss_v1=0, loss_v2=0, nll_loss=1.214, ntokens=977.7, nsentences=32, sample_size=977.7, sample_size_v1=0, sample_size_v2=0, ppl=2.32, wps=256.6, ups=0.26, wpb=977.7, bsz=32, num_updates=29790, lr=4.53903e-06, gnorm=16.137, clip=100, loss_scale=32, train_wall=38, gb_free=8.5, wall=114981
2023-05-22 01:54:22 - progress_bar.py[line:272] - INFO: epoch 018:    410 / 1732 loss=2.404, loss_v1=0, loss_v2=0, nll_loss=1.205, ntokens=1069.8, nsentences=32, sample_size=1069.8, sample_size_v1=0, sample_size_v2=0, ppl=2.31, wps=279.4, ups=0.26, wpb=1069.8, bsz=32, num_updates=29800, lr=4.53699e-06, gnorm=14.893, clip=100, loss_scale=32, train_wall=38, gb_free=8.4, wall=115019
2023-05-22 01:55:01 - progress_bar.py[line:272] - INFO: epoch 018:    420 / 1732 loss=2.384, loss_v1=0, loss_v2=0, nll_loss=1.183, ntokens=1036.4, nsentences=32, sample_size=1036.4, sample_size_v1=0, sample_size_v2=0, ppl=2.27, wps=270.7, ups=0.26, wpb=1036.4, bsz=32, num_updates=29810, lr=4.53494e-06, gnorm=16.42, clip=100, loss_scale=32, train_wall=38, gb_free=7.9, wall=115058
2023-05-22 01:55:39 - progress_bar.py[line:272] - INFO: epoch 018:    430 / 1732 loss=2.395, loss_v1=0, loss_v2=0, nll_loss=1.196, ntokens=1013.2, nsentences=32, sample_size=1013.2, sample_size_v1=0, sample_size_v2=0, ppl=2.29, wps=264.9, ups=0.26, wpb=1013.2, bsz=32, num_updates=29820, lr=4.53289e-06, gnorm=16.568, clip=100, loss_scale=32, train_wall=38, gb_free=8.5, wall=115096
2023-05-22 01:56:17 - progress_bar.py[line:272] - INFO: epoch 018:    440 / 1732 loss=2.427, loss_v1=0, loss_v2=0, nll_loss=1.231, ntokens=989.2, nsentences=32, sample_size=989.2, sample_size_v1=0, sample_size_v2=0, ppl=2.35, wps=260.5, ups=0.26, wpb=989.2, bsz=32, num_updates=29830, lr=4.53084e-06, gnorm=16.15, clip=100, loss_scale=32, train_wall=38, gb_free=9, wall=115134
2023-05-22 01:56:55 - progress_bar.py[line:272] - INFO: epoch 018:    450 / 1732 loss=2.433, loss_v1=0, loss_v2=0, nll_loss=1.237, ntokens=915.3, nsentences=32, sample_size=915.3, sample_size_v1=0, sample_size_v2=0, ppl=2.36, wps=239.9, ups=0.26, wpb=915.3, bsz=32, num_updates=29840, lr=4.5288e-06, gnorm=16.809, clip=100, loss_scale=32, train_wall=38, gb_free=9, wall=115172
2023-05-22 01:57:33 - progress_bar.py[line:272] - INFO: epoch 018:    460 / 1732 loss=2.436, loss_v1=0, loss_v2=0, nll_loss=1.24, ntokens=1040.5, nsentences=32, sample_size=1040.5, sample_size_v1=0, sample_size_v2=0, ppl=2.36, wps=274.6, ups=0.26, wpb=1040.5, bsz=32, num_updates=29850, lr=4.52675e-06, gnorm=14.907, clip=100, loss_scale=32, train_wall=38, gb_free=8.8, wall=115210
2023-05-22 01:58:11 - progress_bar.py[line:272] - INFO: epoch 018:    470 / 1732 loss=2.431, loss_v1=0, loss_v2=0, nll_loss=1.235, ntokens=1036.3, nsentences=32, sample_size=1036.3, sample_size_v1=0, sample_size_v2=0, ppl=2.35, wps=270.7, ups=0.26, wpb=1036.3, bsz=32, num_updates=29860, lr=4.5247e-06, gnorm=15.223, clip=100, loss_scale=32, train_wall=38, gb_free=8.7, wall=115248
2023-05-22 01:58:49 - progress_bar.py[line:272] - INFO: epoch 018:    480 / 1732 loss=2.435, loss_v1=0, loss_v2=0, nll_loss=1.239, ntokens=1040.5, nsentences=32, sample_size=1040.5, sample_size_v1=0, sample_size_v2=0, ppl=2.36, wps=273.2, ups=0.26, wpb=1040.5, bsz=32, num_updates=29870, lr=4.52265e-06, gnorm=14.157, clip=100, loss_scale=32, train_wall=38, gb_free=6.9, wall=115286
2023-05-22 01:59:27 - progress_bar.py[line:272] - INFO: epoch 018:    490 / 1732 loss=2.415, loss_v1=0, loss_v2=0, nll_loss=1.217, ntokens=919.9, nsentences=32, sample_size=919.9, sample_size_v1=0, sample_size_v2=0, ppl=2.33, wps=242.8, ups=0.26, wpb=919.9, bsz=32, num_updates=29880, lr=4.52061e-06, gnorm=17.548, clip=100, loss_scale=32, train_wall=38, gb_free=7.5, wall=115324
2023-05-22 02:00:05 - progress_bar.py[line:272] - INFO: epoch 018:    500 / 1732 loss=2.406, loss_v1=0, loss_v2=0, nll_loss=1.208, ntokens=950.8, nsentences=32, sample_size=950.8, sample_size_v1=0, sample_size_v2=0, ppl=2.31, wps=250, ups=0.26, wpb=950.8, bsz=32, num_updates=29890, lr=4.51856e-06, gnorm=16.785, clip=100, loss_scale=32, train_wall=38, gb_free=8.7, wall=115362
2023-05-22 02:00:43 - progress_bar.py[line:272] - INFO: epoch 018:    510 / 1732 loss=2.447, loss_v1=0, loss_v2=0, nll_loss=1.253, ntokens=1039.6, nsentences=32, sample_size=1039.6, sample_size_v1=0, sample_size_v2=0, ppl=2.38, wps=273.6, ups=0.26, wpb=1039.6, bsz=32, num_updates=29900, lr=4.51651e-06, gnorm=14.683, clip=100, loss_scale=32, train_wall=38, gb_free=8.1, wall=115400
2023-05-22 02:01:21 - progress_bar.py[line:272] - INFO: epoch 018:    520 / 1732 loss=2.404, loss_v1=0, loss_v2=0, nll_loss=1.205, ntokens=1010.1, nsentences=32, sample_size=1010.1, sample_size_v1=0, sample_size_v2=0, ppl=2.3, wps=266.8, ups=0.26, wpb=1010.1, bsz=32, num_updates=29910, lr=4.51446e-06, gnorm=14.088, clip=100, loss_scale=32, train_wall=38, gb_free=8.9, wall=115438
2023-05-22 02:01:59 - progress_bar.py[line:272] - INFO: epoch 018:    530 / 1732 loss=2.429, loss_v1=0, loss_v2=0, nll_loss=1.233, ntokens=937.1, nsentences=32, sample_size=937.1, sample_size_v1=0, sample_size_v2=0, ppl=2.35, wps=247.5, ups=0.26, wpb=937.1, bsz=32, num_updates=29920, lr=4.51242e-06, gnorm=16.173, clip=100, loss_scale=32, train_wall=38, gb_free=8.7, wall=115476
2023-05-22 02:02:37 - progress_bar.py[line:272] - INFO: epoch 018:    540 / 1732 loss=2.421, loss_v1=0, loss_v2=0, nll_loss=1.225, ntokens=998.6, nsentences=32, sample_size=998.6, sample_size_v1=0, sample_size_v2=0, ppl=2.34, wps=263.2, ups=0.26, wpb=998.6, bsz=32, num_updates=29930, lr=4.51037e-06, gnorm=16.291, clip=100, loss_scale=32, train_wall=38, gb_free=9.2, wall=115514
2023-05-22 02:03:15 - progress_bar.py[line:272] - INFO: epoch 018:    550 / 1732 loss=2.45, loss_v1=0, loss_v2=0, nll_loss=1.256, ntokens=1026.6, nsentences=32, sample_size=1026.6, sample_size_v1=0, sample_size_v2=0, ppl=2.39, wps=269.3, ups=0.26, wpb=1026.6, bsz=32, num_updates=29940, lr=4.50832e-06, gnorm=15.739, clip=100, loss_scale=32, train_wall=38, gb_free=8, wall=115552
2023-05-22 02:03:53 - progress_bar.py[line:272] - INFO: epoch 018:    560 / 1732 loss=2.431, loss_v1=0, loss_v2=0, nll_loss=1.235, ntokens=1014, nsentences=32, sample_size=1014, sample_size_v1=0, sample_size_v2=0, ppl=2.35, wps=267.2, ups=0.26, wpb=1014, bsz=32, num_updates=29950, lr=4.50628e-06, gnorm=14.826, clip=100, loss_scale=32, train_wall=38, gb_free=9, wall=115590
2023-05-22 02:04:31 - progress_bar.py[line:272] - INFO: epoch 018:    570 / 1732 loss=2.473, loss_v1=0, loss_v2=0, nll_loss=1.281, ntokens=1025.9, nsentences=32, sample_size=1025.9, sample_size_v1=0, sample_size_v2=0, ppl=2.43, wps=267, ups=0.26, wpb=1025.9, bsz=32, num_updates=29960, lr=4.50423e-06, gnorm=15.897, clip=100, loss_scale=32, train_wall=38, gb_free=8.5, wall=115629
2023-05-22 02:05:10 - progress_bar.py[line:272] - INFO: epoch 018:    580 / 1732 loss=2.431, loss_v1=0, loss_v2=0, nll_loss=1.236, ntokens=999.5, nsentences=32, sample_size=999.5, sample_size_v1=0, sample_size_v2=0, ppl=2.36, wps=261.6, ups=0.26, wpb=999.5, bsz=32, num_updates=29970, lr=4.50218e-06, gnorm=17.409, clip=100, loss_scale=32, train_wall=38, gb_free=8.3, wall=115667
2023-05-22 02:05:48 - progress_bar.py[line:272] - INFO: epoch 018:    590 / 1732 loss=2.423, loss_v1=0, loss_v2=0, nll_loss=1.226, ntokens=927.2, nsentences=32, sample_size=927.2, sample_size_v1=0, sample_size_v2=0, ppl=2.34, wps=243.4, ups=0.26, wpb=927.2, bsz=32, num_updates=29980, lr=4.50013e-06, gnorm=16.927, clip=100, loss_scale=32, train_wall=38, gb_free=9.4, wall=115705
2023-05-22 02:06:26 - progress_bar.py[line:272] - INFO: epoch 018:    600 / 1732 loss=2.39, loss_v1=0, loss_v2=0, nll_loss=1.19, ntokens=957.2, nsentences=32, sample_size=957.2, sample_size_v1=0, sample_size_v2=0, ppl=2.28, wps=251, ups=0.26, wpb=957.2, bsz=32, num_updates=29990, lr=4.49809e-06, gnorm=16.979, clip=100, loss_scale=32, train_wall=38, gb_free=8.5, wall=115743
2023-05-22 02:07:04 - progress_bar.py[line:272] - INFO: epoch 018:    610 / 1732 loss=2.411, loss_v1=0, loss_v2=0, nll_loss=1.215, ntokens=913.5, nsentences=32, sample_size=913.5, sample_size_v1=0, sample_size_v2=0, ppl=2.32, wps=239.1, ups=0.26, wpb=913.5, bsz=32, num_updates=30000, lr=4.49604e-06, gnorm=16.572, clip=100, loss_scale=32, train_wall=38, gb_free=9.1, wall=115781
2023-05-22 02:07:42 - progress_bar.py[line:272] - INFO: epoch 018:    620 / 1732 loss=2.456, loss_v1=0, loss_v2=0, nll_loss=1.265, ntokens=845.3, nsentences=32, sample_size=845.3, sample_size_v1=0, sample_size_v2=0, ppl=2.4, wps=224.6, ups=0.27, wpb=845.3, bsz=32, num_updates=30010, lr=4.49399e-06, gnorm=19.116, clip=100, loss_scale=32, train_wall=38, gb_free=9.1, wall=115819
2023-05-22 02:08:20 - progress_bar.py[line:272] - INFO: epoch 018:    630 / 1732 loss=2.417, loss_v1=0, loss_v2=0, nll_loss=1.221, ntokens=937, nsentences=32, sample_size=937, sample_size_v1=0, sample_size_v2=0, ppl=2.33, wps=247.1, ups=0.26, wpb=937, bsz=32, num_updates=30020, lr=4.49194e-06, gnorm=18.28, clip=100, loss_scale=32, train_wall=38, gb_free=8.6, wall=115857
2023-05-22 02:08:57 - progress_bar.py[line:272] - INFO: epoch 018:    640 / 1732 loss=2.448, loss_v1=0, loss_v2=0, nll_loss=1.255, ntokens=921.7, nsentences=32, sample_size=921.7, sample_size_v1=0, sample_size_v2=0, ppl=2.39, wps=243.3, ups=0.26, wpb=921.7, bsz=32, num_updates=30030, lr=4.4899e-06, gnorm=17.674, clip=100, loss_scale=32, train_wall=38, gb_free=8.2, wall=115895
2023-05-22 02:09:35 - progress_bar.py[line:272] - INFO: epoch 018:    650 / 1732 loss=2.434, loss_v1=0, loss_v2=0, nll_loss=1.238, ntokens=995.3, nsentences=32, sample_size=995.3, sample_size_v1=0, sample_size_v2=0, ppl=2.36, wps=261.7, ups=0.26, wpb=995.3, bsz=32, num_updates=30040, lr=4.48785e-06, gnorm=16.909, clip=100, loss_scale=32, train_wall=38, gb_free=8.3, wall=115933
2023-05-22 02:10:13 - progress_bar.py[line:272] - INFO: epoch 018:    660 / 1732 loss=2.452, loss_v1=0, loss_v2=0, nll_loss=1.258, ntokens=859.4, nsentences=32, sample_size=859.4, sample_size_v1=0, sample_size_v2=0, ppl=2.39, wps=229.4, ups=0.27, wpb=859.4, bsz=32, num_updates=30050, lr=4.4858e-06, gnorm=18.886, clip=100, loss_scale=32, train_wall=37, gb_free=9.2, wall=115970
2023-05-22 02:10:51 - progress_bar.py[line:272] - INFO: epoch 018:    670 / 1732 loss=2.44, loss_v1=0, loss_v2=0, nll_loss=1.245, ntokens=914.5, nsentences=32, sample_size=914.5, sample_size_v1=0, sample_size_v2=0, ppl=2.37, wps=241.1, ups=0.26, wpb=914.5, bsz=32, num_updates=30060, lr=4.48375e-06, gnorm=18.124, clip=100, loss_scale=32, train_wall=38, gb_free=8.7, wall=116008
2023-05-22 02:11:29 - progress_bar.py[line:272] - INFO: epoch 018:    680 / 1732 loss=2.433, loss_v1=0, loss_v2=0, nll_loss=1.237, ntokens=998, nsentences=32, sample_size=998, sample_size_v1=0, sample_size_v2=0, ppl=2.36, wps=262.8, ups=0.26, wpb=998, bsz=32, num_updates=30070, lr=4.48171e-06, gnorm=17.231, clip=100, loss_scale=64, train_wall=38, gb_free=8.3, wall=116046
2023-05-22 02:11:40 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2023-05-22 02:12:11 - progress_bar.py[line:272] - INFO: epoch 018:    691 / 1732 loss=2.438, loss_v1=0, loss_v2=0, nll_loss=1.243, ntokens=965.8, nsentences=32, sample_size=965.8, sample_size_v1=0, sample_size_v2=0, ppl=2.37, wps=230.8, ups=0.24, wpb=965.8, bsz=32, num_updates=30080, lr=4.47966e-06, gnorm=17.629, clip=100, loss_scale=32, train_wall=42, gb_free=8.9, wall=116088
2023-05-22 02:12:49 - progress_bar.py[line:272] - INFO: epoch 018:    701 / 1732 loss=2.404, loss_v1=0, loss_v2=0, nll_loss=1.203, ntokens=988.7, nsentences=32, sample_size=988.7, sample_size_v1=0, sample_size_v2=0, ppl=2.3, wps=259.8, ups=0.26, wpb=988.7, bsz=32, num_updates=30090, lr=4.47761e-06, gnorm=15.448, clip=100, loss_scale=32, train_wall=38, gb_free=9, wall=116126
2023-05-22 02:13:27 - progress_bar.py[line:272] - INFO: epoch 018:    711 / 1732 loss=2.447, loss_v1=0, loss_v2=0, nll_loss=1.253, ntokens=913.9, nsentences=32, sample_size=913.9, sample_size_v1=0, sample_size_v2=0, ppl=2.38, wps=241.8, ups=0.26, wpb=913.9, bsz=32, num_updates=30100, lr=4.47556e-06, gnorm=16.622, clip=100, loss_scale=32, train_wall=38, gb_free=9, wall=116164
2023-05-22 02:14:04 - progress_bar.py[line:272] - INFO: epoch 018:    721 / 1732 loss=2.406, loss_v1=0, loss_v2=0, nll_loss=1.206, ntokens=854.5, nsentences=32, sample_size=854.5, sample_size_v1=0, sample_size_v2=0, ppl=2.31, wps=226.1, ups=0.26, wpb=854.5, bsz=32, num_updates=30110, lr=4.47352e-06, gnorm=19.03, clip=100, loss_scale=32, train_wall=38, gb_free=8.6, wall=116202
2023-05-22 02:14:42 - progress_bar.py[line:272] - INFO: epoch 018:    731 / 1732 loss=2.406, loss_v1=0, loss_v2=0, nll_loss=1.208, ntokens=932.8, nsentences=32, sample_size=932.8, sample_size_v1=0, sample_size_v2=0, ppl=2.31, wps=247.3, ups=0.27, wpb=932.8, bsz=32, num_updates=30120, lr=4.47147e-06, gnorm=18.015, clip=100, loss_scale=32, train_wall=38, gb_free=8.7, wall=116239
2023-05-22 02:15:20 - progress_bar.py[line:272] - INFO: epoch 018:    741 / 1732 loss=2.409, loss_v1=0, loss_v2=0, nll_loss=1.212, ntokens=1003.7, nsentences=32, sample_size=1003.7, sample_size_v1=0, sample_size_v2=0, ppl=2.32, wps=263.9, ups=0.26, wpb=1003.7, bsz=32, num_updates=30130, lr=4.46942e-06, gnorm=17.125, clip=100, loss_scale=32, train_wall=38, gb_free=8.6, wall=116277
2023-05-22 02:15:58 - progress_bar.py[line:272] - INFO: epoch 018:    751 / 1732 loss=2.415, loss_v1=0, loss_v2=0, nll_loss=1.219, ntokens=975.7, nsentences=32, sample_size=975.7, sample_size_v1=0, sample_size_v2=0, ppl=2.33, wps=255.7, ups=0.26, wpb=975.7, bsz=32, num_updates=30140, lr=4.46738e-06, gnorm=15.28, clip=100, loss_scale=32, train_wall=38, gb_free=8.2, wall=116315
2023-05-22 02:16:36 - progress_bar.py[line:272] - INFO: epoch 018:    761 / 1732 loss=2.399, loss_v1=0, loss_v2=0, nll_loss=1.2, ntokens=974.2, nsentences=32, sample_size=974.2, sample_size_v1=0, sample_size_v2=0, ppl=2.3, wps=256.6, ups=0.26, wpb=974.2, bsz=32, num_updates=30150, lr=4.46533e-06, gnorm=16.048, clip=100, loss_scale=32, train_wall=38, gb_free=8.7, wall=116353
2023-05-22 02:17:14 - progress_bar.py[line:272] - INFO: epoch 018:    771 / 1732 loss=2.416, loss_v1=0, loss_v2=0, nll_loss=1.22, ntokens=924.9, nsentences=32, sample_size=924.9, sample_size_v1=0, sample_size_v2=0, ppl=2.33, wps=243.9, ups=0.26, wpb=924.9, bsz=32, num_updates=30160, lr=4.46328e-06, gnorm=16.916, clip=100, loss_scale=32, train_wall=38, gb_free=8.9, wall=116391
2023-05-22 02:17:52 - progress_bar.py[line:272] - INFO: epoch 018:    781 / 1732 loss=2.415, loss_v1=0, loss_v2=0, nll_loss=1.218, ntokens=1053.4, nsentences=32, sample_size=1053.4, sample_size_v1=0, sample_size_v2=0, ppl=2.33, wps=275.5, ups=0.26, wpb=1053.4, bsz=32, num_updates=30170, lr=4.46123e-06, gnorm=16.506, clip=100, loss_scale=32, train_wall=38, gb_free=8.9, wall=116430
2023-05-22 02:18:30 - progress_bar.py[line:272] - INFO: epoch 018:    791 / 1732 loss=2.418, loss_v1=0, loss_v2=0, nll_loss=1.22, ntokens=1022, nsentences=32, sample_size=1022, sample_size_v1=0, sample_size_v2=0, ppl=2.33, wps=269.3, ups=0.26, wpb=1022, bsz=32, num_updates=30180, lr=4.45919e-06, gnorm=14.745, clip=100, loss_scale=32, train_wall=38, gb_free=8.6, wall=116468
2023-05-22 02:19:08 - progress_bar.py[line:272] - INFO: epoch 018:    801 / 1732 loss=2.413, loss_v1=0, loss_v2=0, nll_loss=1.215, ntokens=984.3, nsentences=32, sample_size=984.3, sample_size_v1=0, sample_size_v2=0, ppl=2.32, wps=259, ups=0.26, wpb=984.3, bsz=32, num_updates=30190, lr=4.45714e-06, gnorm=16.159, clip=100, loss_scale=32, train_wall=38, gb_free=8.3, wall=116506
2023-05-22 02:19:46 - progress_bar.py[line:272] - INFO: epoch 018:    811 / 1732 loss=2.416, loss_v1=0, loss_v2=0, nll_loss=1.22, ntokens=931.4, nsentences=32, sample_size=931.4, sample_size_v1=0, sample_size_v2=0, ppl=2.33, wps=244.3, ups=0.26, wpb=931.4, bsz=32, num_updates=30200, lr=4.45509e-06, gnorm=18.791, clip=100, loss_scale=32, train_wall=38, gb_free=8.7, wall=116544
2023-05-22 02:20:25 - progress_bar.py[line:272] - INFO: epoch 018:    821 / 1732 loss=2.426, loss_v1=0, loss_v2=0, nll_loss=1.229, ntokens=915.1, nsentences=32, sample_size=915.1, sample_size_v1=0, sample_size_v2=0, ppl=2.34, wps=240.1, ups=0.26, wpb=915.1, bsz=32, num_updates=30210, lr=4.45304e-06, gnorm=17.709, clip=100, loss_scale=32, train_wall=38, gb_free=7.2, wall=116582
2023-05-22 02:21:02 - progress_bar.py[line:272] - INFO: epoch 018:    831 / 1732 loss=2.413, loss_v1=0, loss_v2=0, nll_loss=1.214, ntokens=914.9, nsentences=32, sample_size=914.9, sample_size_v1=0, sample_size_v2=0, ppl=2.32, wps=242.3, ups=0.26, wpb=914.9, bsz=32, num_updates=30220, lr=4.451e-06, gnorm=16.538, clip=100, loss_scale=32, train_wall=38, gb_free=8.8, wall=116620
2023-05-22 02:21:40 - progress_bar.py[line:272] - INFO: epoch 018:    841 / 1732 loss=2.413, loss_v1=0, loss_v2=0, nll_loss=1.215, ntokens=933, nsentences=32, sample_size=933, sample_size_v1=0, sample_size_v2=0, ppl=2.32, wps=247.3, ups=0.27, wpb=933, bsz=32, num_updates=30230, lr=4.44895e-06, gnorm=16.308, clip=100, loss_scale=32, train_wall=38, gb_free=9, wall=116657
2023-05-22 02:22:18 - progress_bar.py[line:272] - INFO: epoch 018:    851 / 1732 loss=2.415, loss_v1=0, loss_v2=0, nll_loss=1.217, ntokens=1005.2, nsentences=32, sample_size=1005.2, sample_size_v1=0, sample_size_v2=0, ppl=2.32, wps=265.4, ups=0.26, wpb=1005.2, bsz=32, num_updates=30240, lr=4.4469e-06, gnorm=16.326, clip=100, loss_scale=32, train_wall=38, gb_free=8.6, wall=116695
2023-05-22 02:22:56 - progress_bar.py[line:272] - INFO: epoch 018:    861 / 1732 loss=2.4, loss_v1=0, loss_v2=0, nll_loss=1.2, ntokens=942.6, nsentences=32, sample_size=942.6, sample_size_v1=0, sample_size_v2=0, ppl=2.3, wps=249.8, ups=0.27, wpb=942.6, bsz=32, num_updates=30250, lr=4.44485e-06, gnorm=16.745, clip=100, loss_scale=32, train_wall=38, gb_free=8.5, wall=116733
2023-05-22 02:23:34 - progress_bar.py[line:272] - INFO: epoch 018:    871 / 1732 loss=2.421, loss_v1=0, loss_v2=0, nll_loss=1.225, ntokens=962.7, nsentences=32, sample_size=962.7, sample_size_v1=0, sample_size_v2=0, ppl=2.34, wps=252.5, ups=0.26, wpb=962.7, bsz=32, num_updates=30260, lr=4.44281e-06, gnorm=17.158, clip=100, loss_scale=32, train_wall=38, gb_free=9, wall=116771
2023-05-22 02:24:12 - progress_bar.py[line:272] - INFO: epoch 018:    881 / 1732 loss=2.364, loss_v1=0, loss_v2=0, nll_loss=1.161, ntokens=988.4, nsentences=32, sample_size=988.4, sample_size_v1=0, sample_size_v2=0, ppl=2.24, wps=258.7, ups=0.26, wpb=988.4, bsz=32, num_updates=30270, lr=4.44076e-06, gnorm=17.146, clip=100, loss_scale=32, train_wall=38, gb_free=9.2, wall=116809
2023-05-22 02:24:50 - progress_bar.py[line:272] - INFO: epoch 018:    891 / 1732 loss=2.353, loss_v1=0, loss_v2=0, nll_loss=1.149, ntokens=1001.4, nsentences=32, sample_size=1001.4, sample_size_v1=0, sample_size_v2=0, ppl=2.22, wps=262.1, ups=0.26, wpb=1001.4, bsz=32, num_updates=30280, lr=4.43871e-06, gnorm=16.287, clip=100, loss_scale=32, train_wall=38, gb_free=8.6, wall=116847
2023-05-22 02:25:28 - progress_bar.py[line:272] - INFO: epoch 018:    901 / 1732 loss=2.357, loss_v1=0, loss_v2=0, nll_loss=1.152, ntokens=1032.4, nsentences=32, sample_size=1032.4, sample_size_v1=0, sample_size_v2=0, ppl=2.22, wps=270.4, ups=0.26, wpb=1032.4, bsz=32, num_updates=30290, lr=4.43666e-06, gnorm=15.462, clip=100, loss_scale=32, train_wall=38, gb_free=9.2, wall=116886
2023-05-22 02:26:07 - progress_bar.py[line:272] - INFO: epoch 018:    911 / 1732 loss=2.41, loss_v1=0, loss_v2=0, nll_loss=1.213, ntokens=960.1, nsentences=32, sample_size=960.1, sample_size_v1=0, sample_size_v2=0, ppl=2.32, wps=251.7, ups=0.26, wpb=960.1, bsz=32, num_updates=30300, lr=4.43462e-06, gnorm=16.338, clip=100, loss_scale=32, train_wall=38, gb_free=9.2, wall=116924
2023-05-22 02:26:45 - progress_bar.py[line:272] - INFO: epoch 018:    921 / 1732 loss=2.414, loss_v1=0, loss_v2=0, nll_loss=1.216, ntokens=986.3, nsentences=32, sample_size=986.3, sample_size_v1=0, sample_size_v2=0, ppl=2.32, wps=257.2, ups=0.26, wpb=986.3, bsz=32, num_updates=30310, lr=4.43257e-06, gnorm=16.719, clip=100, loss_scale=32, train_wall=38, gb_free=8.5, wall=116962
2023-05-22 02:27:24 - progress_bar.py[line:272] - INFO: epoch 018:    931 / 1732 loss=2.384, loss_v1=0, loss_v2=0, nll_loss=1.183, ntokens=1050.4, nsentences=32, sample_size=1050.4, sample_size_v1=0, sample_size_v2=0, ppl=2.27, wps=271.9, ups=0.26, wpb=1050.4, bsz=32, num_updates=30320, lr=4.43052e-06, gnorm=15.492, clip=100, loss_scale=32, train_wall=39, gb_free=8.8, wall=117001
2023-05-22 02:28:02 - progress_bar.py[line:272] - INFO: epoch 018:    941 / 1732 loss=2.386, loss_v1=0, loss_v2=0, nll_loss=1.183, ntokens=1052.3, nsentences=32, sample_size=1052.3, sample_size_v1=0, sample_size_v2=0, ppl=2.27, wps=271.4, ups=0.26, wpb=1052.3, bsz=32, num_updates=30330, lr=4.42847e-06, gnorm=14.552, clip=100, loss_scale=32, train_wall=39, gb_free=7.1, wall=117040
2023-05-22 02:28:41 - progress_bar.py[line:272] - INFO: epoch 018:    951 / 1732 loss=2.398, loss_v1=0, loss_v2=0, nll_loss=1.197, ntokens=1037.8, nsentences=32, sample_size=1037.8, sample_size_v1=0, sample_size_v2=0, ppl=2.29, wps=268.9, ups=0.26, wpb=1037.8, bsz=32, num_updates=30340, lr=4.42643e-06, gnorm=14.882, clip=100, loss_scale=32, train_wall=39, gb_free=8.3, wall=117078
2023-05-22 02:29:20 - progress_bar.py[line:272] - INFO: epoch 018:    961 / 1732 loss=2.388, loss_v1=0, loss_v2=0, nll_loss=1.188, ntokens=1067.9, nsentences=32, sample_size=1067.9, sample_size_v1=0, sample_size_v2=0, ppl=2.28, wps=275.3, ups=0.26, wpb=1067.9, bsz=32, num_updates=30350, lr=4.42438e-06, gnorm=15.684, clip=100, loss_scale=32, train_wall=39, gb_free=8.6, wall=117117
2023-05-22 02:29:58 - progress_bar.py[line:272] - INFO: epoch 018:    971 / 1732 loss=2.427, loss_v1=0, loss_v2=0, nll_loss=1.233, ntokens=1026.9, nsentences=32, sample_size=1026.9, sample_size_v1=0, sample_size_v2=0, ppl=2.35, wps=266.6, ups=0.26, wpb=1026.9, bsz=32, num_updates=30360, lr=4.42233e-06, gnorm=17.254, clip=100, loss_scale=32, train_wall=38, gb_free=7.4, wall=117155
2023-05-22 02:30:37 - progress_bar.py[line:272] - INFO: epoch 018:    981 / 1732 loss=2.394, loss_v1=0, loss_v2=0, nll_loss=1.196, ntokens=1016.8, nsentences=32, sample_size=1016.8, sample_size_v1=0, sample_size_v2=0, ppl=2.29, wps=262.4, ups=0.26, wpb=1016.8, bsz=32, num_updates=30370, lr=4.42029e-06, gnorm=15.986, clip=100, loss_scale=32, train_wall=39, gb_free=8.2, wall=117194
2023-05-22 02:31:16 - progress_bar.py[line:272] - INFO: epoch 018:    991 / 1732 loss=2.406, loss_v1=0, loss_v2=0, nll_loss=1.207, ntokens=1042.2, nsentences=32, sample_size=1042.2, sample_size_v1=0, sample_size_v2=0, ppl=2.31, wps=269.2, ups=0.26, wpb=1042.2, bsz=32, num_updates=30380, lr=4.41824e-06, gnorm=15.989, clip=100, loss_scale=32, train_wall=39, gb_free=8.8, wall=117233
2023-05-22 02:31:54 - progress_bar.py[line:272] - INFO: epoch 018:   1001 / 1732 loss=2.381, loss_v1=0, loss_v2=0, nll_loss=1.178, ntokens=1019, nsentences=32, sample_size=1019, sample_size_v1=0, sample_size_v2=0, ppl=2.26, wps=265.9, ups=0.26, wpb=1019, bsz=32, num_updates=30390, lr=4.41619e-06, gnorm=14.685, clip=100, loss_scale=32, train_wall=38, gb_free=8.7, wall=117271
2023-05-22 02:32:32 - progress_bar.py[line:272] - INFO: epoch 018:   1011 / 1732 loss=2.397, loss_v1=0, loss_v2=0, nll_loss=1.198, ntokens=995.8, nsentences=32, sample_size=995.8, sample_size_v1=0, sample_size_v2=0, ppl=2.29, wps=259.3, ups=0.26, wpb=995.8, bsz=32, num_updates=30400, lr=4.41414e-06, gnorm=16.025, clip=100, loss_scale=32, train_wall=38, gb_free=8.7, wall=117310
2023-05-22 02:33:11 - progress_bar.py[line:272] - INFO: epoch 018:   1021 / 1732 loss=2.37, loss_v1=0, loss_v2=0, nll_loss=1.166, ntokens=1050, nsentences=32, sample_size=1050, sample_size_v1=0, sample_size_v2=0, ppl=2.24, wps=270.7, ups=0.26, wpb=1050, bsz=32, num_updates=30410, lr=4.4121e-06, gnorm=14.403, clip=100, loss_scale=32, train_wall=39, gb_free=7.5, wall=117348
2023-05-22 02:33:50 - progress_bar.py[line:272] - INFO: epoch 018:   1031 / 1732 loss=2.393, loss_v1=0, loss_v2=0, nll_loss=1.194, ntokens=1125.6, nsentences=32, sample_size=1125.6, sample_size_v1=0, sample_size_v2=0, ppl=2.29, wps=288.9, ups=0.26, wpb=1125.6, bsz=32, num_updates=30420, lr=4.41005e-06, gnorm=13.748, clip=100, loss_scale=32, train_wall=39, gb_free=8.3, wall=117387
2023-05-22 02:34:29 - progress_bar.py[line:272] - INFO: epoch 018:   1041 / 1732 loss=2.388, loss_v1=0, loss_v2=0, nll_loss=1.188, ntokens=1038.5, nsentences=32, sample_size=1038.5, sample_size_v1=0, sample_size_v2=0, ppl=2.28, wps=269, ups=0.26, wpb=1038.5, bsz=32, num_updates=30430, lr=4.408e-06, gnorm=15.811, clip=100, loss_scale=32, train_wall=39, gb_free=9, wall=117426
2023-05-22 02:35:07 - progress_bar.py[line:272] - INFO: epoch 018:   1051 / 1732 loss=2.4, loss_v1=0, loss_v2=0, nll_loss=1.202, ntokens=1067.2, nsentences=32, sample_size=1067.2, sample_size_v1=0, sample_size_v2=0, ppl=2.3, wps=277.2, ups=0.26, wpb=1067.2, bsz=32, num_updates=30440, lr=4.40595e-06, gnorm=16.906, clip=100, loss_scale=32, train_wall=38, gb_free=8.6, wall=117464
2023-05-22 02:35:46 - progress_bar.py[line:272] - INFO: epoch 018:   1061 / 1732 loss=2.389, loss_v1=0, loss_v2=0, nll_loss=1.188, ntokens=1037.8, nsentences=32, sample_size=1037.8, sample_size_v1=0, sample_size_v2=0, ppl=2.28, wps=269.7, ups=0.26, wpb=1037.8, bsz=32, num_updates=30450, lr=4.40391e-06, gnorm=18.129, clip=100, loss_scale=32, train_wall=38, gb_free=8.7, wall=117503
2023-05-22 02:36:24 - progress_bar.py[line:272] - INFO: epoch 018:   1071 / 1732 loss=2.391, loss_v1=0, loss_v2=0, nll_loss=1.191, ntokens=999.8, nsentences=32, sample_size=999.8, sample_size_v1=0, sample_size_v2=0, ppl=2.28, wps=259.5, ups=0.26, wpb=999.8, bsz=32, num_updates=30460, lr=4.40186e-06, gnorm=16.963, clip=100, loss_scale=32, train_wall=38, gb_free=7.8, wall=117541
2023-05-22 02:37:03 - progress_bar.py[line:272] - INFO: epoch 018:   1081 / 1732 loss=2.405, loss_v1=0, loss_v2=0, nll_loss=1.205, ntokens=1039.7, nsentences=32, sample_size=1039.7, sample_size_v1=0, sample_size_v2=0, ppl=2.31, wps=269.1, ups=0.26, wpb=1039.7, bsz=32, num_updates=30470, lr=4.39981e-06, gnorm=15.422, clip=100, loss_scale=32, train_wall=39, gb_free=8.2, wall=117580
2023-05-22 02:37:42 - progress_bar.py[line:272] - INFO: epoch 018:   1091 / 1732 loss=2.391, loss_v1=0, loss_v2=0, nll_loss=1.191, ntokens=1090, nsentences=32, sample_size=1090, sample_size_v1=0, sample_size_v2=0, ppl=2.28, wps=281.9, ups=0.26, wpb=1090, bsz=32, num_updates=30480, lr=4.39776e-06, gnorm=17.137, clip=100, loss_scale=32, train_wall=39, gb_free=8.5, wall=117619
2023-05-22 02:38:20 - progress_bar.py[line:272] - INFO: epoch 018:   1101 / 1732 loss=2.406, loss_v1=0, loss_v2=0, nll_loss=1.209, ntokens=1006.7, nsentences=32, sample_size=1006.7, sample_size_v1=0, sample_size_v2=0, ppl=2.31, wps=261.3, ups=0.26, wpb=1006.7, bsz=32, num_updates=30490, lr=4.39572e-06, gnorm=18.572, clip=100, loss_scale=32, train_wall=38, gb_free=8.2, wall=117657
2023-05-22 02:38:59 - progress_bar.py[line:272] - INFO: epoch 018:   1111 / 1732 loss=2.386, loss_v1=0, loss_v2=0, nll_loss=1.184, ntokens=1054.1, nsentences=32, sample_size=1054.1, sample_size_v1=0, sample_size_v2=0, ppl=2.27, wps=272.5, ups=0.26, wpb=1054.1, bsz=32, num_updates=30500, lr=4.39367e-06, gnorm=15.132, clip=100, loss_scale=32, train_wall=39, gb_free=8.6, wall=117696
2023-05-22 02:39:37 - progress_bar.py[line:272] - INFO: epoch 018:   1121 / 1732 loss=2.397, loss_v1=0, loss_v2=0, nll_loss=1.197, ntokens=962.9, nsentences=32, sample_size=962.9, sample_size_v1=0, sample_size_v2=0, ppl=2.29, wps=250, ups=0.26, wpb=962.9, bsz=32, num_updates=30510, lr=4.39162e-06, gnorm=17.158, clip=100, loss_scale=32, train_wall=38, gb_free=8.7, wall=117735
2023-05-22 02:40:16 - progress_bar.py[line:272] - INFO: epoch 018:   1131 / 1732 loss=2.404, loss_v1=0, loss_v2=0, nll_loss=1.205, ntokens=991.2, nsentences=32, sample_size=991.2, sample_size_v1=0, sample_size_v2=0, ppl=2.31, wps=257.4, ups=0.26, wpb=991.2, bsz=32, num_updates=30520, lr=4.38957e-06, gnorm=17.206, clip=100, loss_scale=32, train_wall=38, gb_free=8.8, wall=117773
2023-05-22 02:40:54 - progress_bar.py[line:272] - INFO: epoch 018:   1141 / 1732 loss=2.406, loss_v1=0, loss_v2=0, nll_loss=1.207, ntokens=1017.8, nsentences=32, sample_size=1017.8, sample_size_v1=0, sample_size_v2=0, ppl=2.31, wps=263.9, ups=0.26, wpb=1017.8, bsz=32, num_updates=30530, lr=4.38753e-06, gnorm=16.295, clip=100, loss_scale=32, train_wall=39, gb_free=8.6, wall=117812
2023-05-22 02:41:33 - progress_bar.py[line:272] - INFO: epoch 018:   1151 / 1732 loss=2.394, loss_v1=0, loss_v2=0, nll_loss=1.195, ntokens=1034.7, nsentences=32, sample_size=1034.7, sample_size_v1=0, sample_size_v2=0, ppl=2.29, wps=268.3, ups=0.26, wpb=1034.7, bsz=32, num_updates=30540, lr=4.38548e-06, gnorm=16.01, clip=100, loss_scale=32, train_wall=39, gb_free=8, wall=117850
2023-05-22 02:42:12 - progress_bar.py[line:272] - INFO: epoch 018:   1161 / 1732 loss=2.36, loss_v1=0, loss_v2=0, nll_loss=1.157, ntokens=995.8, nsentences=32, sample_size=995.8, sample_size_v1=0, sample_size_v2=0, ppl=2.23, wps=256.5, ups=0.26, wpb=995.8, bsz=32, num_updates=30550, lr=4.38343e-06, gnorm=16.621, clip=100, loss_scale=32, train_wall=39, gb_free=8.6, wall=117889
2023-05-22 02:42:51 - progress_bar.py[line:272] - INFO: epoch 018:   1171 / 1732 loss=2.388, loss_v1=0, loss_v2=0, nll_loss=1.189, ntokens=1049.1, nsentences=32, sample_size=1049.1, sample_size_v1=0, sample_size_v2=0, ppl=2.28, wps=270, ups=0.26, wpb=1049.1, bsz=32, num_updates=30560, lr=4.38139e-06, gnorm=15.722, clip=100, loss_scale=32, train_wall=39, gb_free=8.4, wall=117928
2023-05-22 02:43:29 - progress_bar.py[line:272] - INFO: epoch 018:   1181 / 1732 loss=2.37, loss_v1=0, loss_v2=0, nll_loss=1.165, ntokens=1019.2, nsentences=32, sample_size=1019.2, sample_size_v1=0, sample_size_v2=0, ppl=2.24, wps=265.1, ups=0.26, wpb=1019.2, bsz=32, num_updates=30570, lr=4.37934e-06, gnorm=17.153, clip=100, loss_scale=32, train_wall=38, gb_free=7.4, wall=117966
2023-05-22 02:44:08 - progress_bar.py[line:272] - INFO: epoch 018:   1191 / 1732 loss=2.427, loss_v1=0, loss_v2=0, nll_loss=1.232, ntokens=1005.4, nsentences=32, sample_size=1005.4, sample_size_v1=0, sample_size_v2=0, ppl=2.35, wps=261.3, ups=0.26, wpb=1005.4, bsz=32, num_updates=30580, lr=4.37729e-06, gnorm=16.958, clip=100, loss_scale=32, train_wall=38, gb_free=8.8, wall=118005
2023-05-22 02:44:46 - progress_bar.py[line:272] - INFO: epoch 018:   1201 / 1732 loss=2.363, loss_v1=0, loss_v2=0, nll_loss=1.158, ntokens=1106.6, nsentences=32, sample_size=1106.6, sample_size_v1=0, sample_size_v2=0, ppl=2.23, wps=285.3, ups=0.26, wpb=1106.6, bsz=32, num_updates=30590, lr=4.37524e-06, gnorm=16.015, clip=100, loss_scale=64, train_wall=39, gb_free=8.4, wall=118044
2023-05-22 02:44:50 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2023-05-22 02:45:29 - progress_bar.py[line:272] - INFO: epoch 018:   1212 / 1732 loss=2.388, loss_v1=0, loss_v2=0, nll_loss=1.186, ntokens=1031.6, nsentences=32, sample_size=1031.6, sample_size_v1=0, sample_size_v2=0, ppl=2.27, wps=241.7, ups=0.23, wpb=1031.6, bsz=32, num_updates=30600, lr=4.3732e-06, gnorm=15.927, clip=100, loss_scale=32, train_wall=43, gb_free=8, wall=118086
2023-05-22 02:46:08 - progress_bar.py[line:272] - INFO: epoch 018:   1222 / 1732 loss=2.418, loss_v1=0, loss_v2=0, nll_loss=1.221, ntokens=1024, nsentences=32, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=2.33, wps=264.3, ups=0.26, wpb=1024, bsz=32, num_updates=30610, lr=4.37115e-06, gnorm=16.743, clip=100, loss_scale=32, train_wall=39, gb_free=7.9, wall=118125
2023-05-22 02:46:46 - progress_bar.py[line:272] - INFO: epoch 018:   1232 / 1732 loss=2.375, loss_v1=0, loss_v2=0, nll_loss=1.172, ntokens=1035.1, nsentences=32, sample_size=1035.1, sample_size_v1=0, sample_size_v2=0, ppl=2.25, wps=268.9, ups=0.26, wpb=1035.1, bsz=32, num_updates=30620, lr=4.3691e-06, gnorm=15.238, clip=100, loss_scale=32, train_wall=38, gb_free=8.6, wall=118164
2023-05-22 02:47:25 - progress_bar.py[line:272] - INFO: epoch 018:   1242 / 1732 loss=2.336, loss_v1=0, loss_v2=0, nll_loss=1.129, ntokens=1078.3, nsentences=32, sample_size=1078.3, sample_size_v1=0, sample_size_v2=0, ppl=2.19, wps=279.2, ups=0.26, wpb=1078.3, bsz=32, num_updates=30630, lr=4.36705e-06, gnorm=14.648, clip=100, loss_scale=32, train_wall=39, gb_free=8.8, wall=118202
2023-05-22 02:48:04 - progress_bar.py[line:272] - INFO: epoch 018:   1252 / 1732 loss=2.36, loss_v1=0, loss_v2=0, nll_loss=1.157, ntokens=1106.3, nsentences=32, sample_size=1106.3, sample_size_v1=0, sample_size_v2=0, ppl=2.23, wps=285.8, ups=0.26, wpb=1106.3, bsz=32, num_updates=30640, lr=4.36501e-06, gnorm=14.772, clip=100, loss_scale=32, train_wall=39, gb_free=8, wall=118241
2023-05-22 02:48:42 - progress_bar.py[line:272] - INFO: epoch 018:   1262 / 1732 loss=2.388, loss_v1=0, loss_v2=0, nll_loss=1.186, ntokens=1064, nsentences=32, sample_size=1064, sample_size_v1=0, sample_size_v2=0, ppl=2.27, wps=275.2, ups=0.26, wpb=1064, bsz=32, num_updates=30650, lr=4.36296e-06, gnorm=15.742, clip=100, loss_scale=32, train_wall=39, gb_free=8, wall=118280
2023-05-22 02:49:21 - progress_bar.py[line:272] - INFO: epoch 018:   1272 / 1732 loss=2.395, loss_v1=0, loss_v2=0, nll_loss=1.195, ntokens=1010.3, nsentences=32, sample_size=1010.3, sample_size_v1=0, sample_size_v2=0, ppl=2.29, wps=262.6, ups=0.26, wpb=1010.3, bsz=32, num_updates=30660, lr=4.36091e-06, gnorm=17.03, clip=100, loss_scale=32, train_wall=38, gb_free=8, wall=118318
2023-05-22 02:50:00 - progress_bar.py[line:272] - INFO: epoch 018:   1282 / 1732 loss=2.381, loss_v1=0, loss_v2=0, nll_loss=1.179, ntokens=1073.6, nsentences=32, sample_size=1073.6, sample_size_v1=0, sample_size_v2=0, ppl=2.26, wps=276.8, ups=0.26, wpb=1073.6, bsz=32, num_updates=30670, lr=4.35886e-06, gnorm=17.431, clip=100, loss_scale=32, train_wall=39, gb_free=7.4, wall=118357
2023-05-22 02:50:38 - progress_bar.py[line:272] - INFO: epoch 018:   1292 / 1732 loss=2.374, loss_v1=0, loss_v2=0, nll_loss=1.172, ntokens=1095.2, nsentences=32, sample_size=1095.2, sample_size_v1=0, sample_size_v2=0, ppl=2.25, wps=281.8, ups=0.26, wpb=1095.2, bsz=32, num_updates=30680, lr=4.35682e-06, gnorm=15.144, clip=100, loss_scale=32, train_wall=39, gb_free=7.7, wall=118396
2023-05-22 02:51:17 - progress_bar.py[line:272] - INFO: epoch 018:   1302 / 1732 loss=2.383, loss_v1=0, loss_v2=0, nll_loss=1.182, ntokens=1099.5, nsentences=32, sample_size=1099.5, sample_size_v1=0, sample_size_v2=0, ppl=2.27, wps=283.1, ups=0.26, wpb=1099.5, bsz=32, num_updates=30690, lr=4.35477e-06, gnorm=15.037, clip=100, loss_scale=32, train_wall=39, gb_free=7.4, wall=118435
2023-05-22 02:51:57 - progress_bar.py[line:272] - INFO: epoch 018:   1312 / 1732 loss=2.414, loss_v1=0, loss_v2=0, nll_loss=1.216, ntokens=1055.4, nsentences=32, sample_size=1055.4, sample_size_v1=0, sample_size_v2=0, ppl=2.32, wps=268.1, ups=0.25, wpb=1055.4, bsz=32, num_updates=30700, lr=4.35272e-06, gnorm=16.373, clip=100, loss_scale=32, train_wall=39, gb_free=8.6, wall=118474
2023-05-22 02:52:36 - progress_bar.py[line:272] - INFO: epoch 018:   1322 / 1732 loss=2.37, loss_v1=0, loss_v2=0, nll_loss=1.166, ntokens=1120.6, nsentences=32, sample_size=1120.6, sample_size_v1=0, sample_size_v2=0, ppl=2.24, wps=287.6, ups=0.26, wpb=1120.6, bsz=32, num_updates=30710, lr=4.35067e-06, gnorm=15.334, clip=100, loss_scale=32, train_wall=39, gb_free=7.7, wall=118513
2023-05-22 02:53:15 - progress_bar.py[line:272] - INFO: epoch 018:   1332 / 1732 loss=2.354, loss_v1=0, loss_v2=0, nll_loss=1.149, ntokens=1081, nsentences=32, sample_size=1081, sample_size_v1=0, sample_size_v2=0, ppl=2.22, wps=277.7, ups=0.26, wpb=1081, bsz=32, num_updates=30720, lr=4.34863e-06, gnorm=16.507, clip=100, loss_scale=32, train_wall=39, gb_free=8.5, wall=118552
2023-05-22 02:53:54 - progress_bar.py[line:272] - INFO: epoch 018:   1342 / 1732 loss=2.365, loss_v1=0, loss_v2=0, nll_loss=1.162, ntokens=1183.5, nsentences=32, sample_size=1183.5, sample_size_v1=0, sample_size_v2=0, ppl=2.24, wps=301.4, ups=0.25, wpb=1183.5, bsz=32, num_updates=30730, lr=4.34658e-06, gnorm=16.974, clip=100, loss_scale=32, train_wall=39, gb_free=7.4, wall=118591
2023-05-22 02:54:33 - progress_bar.py[line:272] - INFO: epoch 018:   1352 / 1732 loss=2.385, loss_v1=0, loss_v2=0, nll_loss=1.186, ntokens=1129.4, nsentences=32, sample_size=1129.4, sample_size_v1=0, sample_size_v2=0, ppl=2.27, wps=289.7, ups=0.26, wpb=1129.4, bsz=32, num_updates=30740, lr=4.34453e-06, gnorm=16.095, clip=100, loss_scale=32, train_wall=39, gb_free=8.2, wall=118630
2023-05-22 02:55:12 - progress_bar.py[line:272] - INFO: epoch 018:   1362 / 1732 loss=2.343, loss_v1=0, loss_v2=0, nll_loss=1.136, ntokens=1092.5, nsentences=32, sample_size=1092.5, sample_size_v1=0, sample_size_v2=0, ppl=2.2, wps=279.3, ups=0.26, wpb=1092.5, bsz=32, num_updates=30750, lr=4.34249e-06, gnorm=15.558, clip=100, loss_scale=32, train_wall=39, gb_free=7.5, wall=118669
2023-05-22 02:55:51 - progress_bar.py[line:272] - INFO: epoch 018:   1372 / 1732 loss=2.391, loss_v1=0, loss_v2=0, nll_loss=1.191, ntokens=1098.3, nsentences=32, sample_size=1098.3, sample_size_v1=0, sample_size_v2=0, ppl=2.28, wps=283.6, ups=0.26, wpb=1098.3, bsz=32, num_updates=30760, lr=4.34044e-06, gnorm=16.468, clip=100, loss_scale=32, train_wall=39, gb_free=8.8, wall=118708
2023-05-22 02:56:29 - progress_bar.py[line:272] - INFO: epoch 018:   1382 / 1732 loss=2.396, loss_v1=0, loss_v2=0, nll_loss=1.195, ntokens=1160, nsentences=32, sample_size=1160, sample_size_v1=0, sample_size_v2=0, ppl=2.29, wps=299.4, ups=0.26, wpb=1160, bsz=32, num_updates=30770, lr=4.33839e-06, gnorm=15.59, clip=100, loss_scale=32, train_wall=39, gb_free=8, wall=118747
2023-05-22 02:57:08 - progress_bar.py[line:272] - INFO: epoch 018:   1392 / 1732 loss=2.387, loss_v1=0, loss_v2=0, nll_loss=1.187, ntokens=1049.4, nsentences=32, sample_size=1049.4, sample_size_v1=0, sample_size_v2=0, ppl=2.28, wps=272.7, ups=0.26, wpb=1049.4, bsz=32, num_updates=30780, lr=4.33634e-06, gnorm=17.179, clip=100, loss_scale=32, train_wall=38, gb_free=8.3, wall=118785
2023-05-22 02:57:47 - progress_bar.py[line:272] - INFO: epoch 018:   1402 / 1732 loss=2.355, loss_v1=0, loss_v2=0, nll_loss=1.15, ntokens=1133.7, nsentences=32, sample_size=1133.7, sample_size_v1=0, sample_size_v2=0, ppl=2.22, wps=291.3, ups=0.26, wpb=1133.7, bsz=32, num_updates=30790, lr=4.3343e-06, gnorm=15.309, clip=100, loss_scale=32, train_wall=39, gb_free=7.2, wall=118824
2023-05-22 02:58:26 - progress_bar.py[line:272] - INFO: epoch 018:   1412 / 1732 loss=2.394, loss_v1=0, loss_v2=0, nll_loss=1.193, ntokens=1246.7, nsentences=32, sample_size=1246.7, sample_size_v1=0, sample_size_v2=0, ppl=2.29, wps=317.9, ups=0.26, wpb=1246.7, bsz=32, num_updates=30800, lr=4.33225e-06, gnorm=14.452, clip=100, loss_scale=32, train_wall=39, gb_free=7.9, wall=118863
2023-05-22 02:59:06 - progress_bar.py[line:272] - INFO: epoch 018:   1422 / 1732 loss=2.377, loss_v1=0, loss_v2=0, nll_loss=1.175, ntokens=1259.2, nsentences=32, sample_size=1259.2, sample_size_v1=0, sample_size_v2=0, ppl=2.26, wps=318.4, ups=0.25, wpb=1259.2, bsz=32, num_updates=30810, lr=4.3302e-06, gnorm=14.124, clip=100, loss_scale=32, train_wall=40, gb_free=8, wall=118903
2023-05-22 02:59:45 - progress_bar.py[line:272] - INFO: epoch 018:   1432 / 1732 loss=2.35, loss_v1=0, loss_v2=0, nll_loss=1.144, ntokens=1215.6, nsentences=32, sample_size=1215.6, sample_size_v1=0, sample_size_v2=0, ppl=2.21, wps=312.1, ups=0.26, wpb=1215.6, bsz=32, num_updates=30820, lr=4.32815e-06, gnorm=12.351, clip=100, loss_scale=32, train_wall=39, gb_free=8.3, wall=118942
2023-05-22 03:00:23 - progress_bar.py[line:272] - INFO: epoch 018:   1442 / 1732 loss=2.378, loss_v1=0, loss_v2=0, nll_loss=1.177, ntokens=1136.6, nsentences=32, sample_size=1136.6, sample_size_v1=0, sample_size_v2=0, ppl=2.26, wps=293.1, ups=0.26, wpb=1136.6, bsz=32, num_updates=30830, lr=4.32611e-06, gnorm=14.924, clip=100, loss_scale=32, train_wall=39, gb_free=8.5, wall=118981
2023-05-22 03:01:02 - progress_bar.py[line:272] - INFO: epoch 018:   1452 / 1732 loss=2.387, loss_v1=0, loss_v2=0, nll_loss=1.187, ntokens=1140.1, nsentences=32, sample_size=1140.1, sample_size_v1=0, sample_size_v2=0, ppl=2.28, wps=291.2, ups=0.26, wpb=1140.1, bsz=32, num_updates=30840, lr=4.32406e-06, gnorm=14.731, clip=100, loss_scale=32, train_wall=39, gb_free=9, wall=119020
2023-05-22 03:01:42 - progress_bar.py[line:272] - INFO: epoch 018:   1462 / 1732 loss=2.354, loss_v1=0, loss_v2=0, nll_loss=1.149, ntokens=1170.3, nsentences=32, sample_size=1170.3, sample_size_v1=0, sample_size_v2=0, ppl=2.22, wps=298.7, ups=0.26, wpb=1170.3, bsz=32, num_updates=30850, lr=4.32201e-06, gnorm=15.149, clip=100, loss_scale=32, train_wall=39, gb_free=7.7, wall=119059
2023-05-22 03:02:21 - progress_bar.py[line:272] - INFO: epoch 018:   1472 / 1732 loss=2.358, loss_v1=0, loss_v2=0, nll_loss=1.154, ntokens=1139, nsentences=32, sample_size=1139, sample_size_v1=0, sample_size_v2=0, ppl=2.22, wps=292.3, ups=0.26, wpb=1139, bsz=32, num_updates=30860, lr=4.31996e-06, gnorm=14.714, clip=100, loss_scale=32, train_wall=39, gb_free=8.9, wall=119098
2023-05-22 03:02:59 - progress_bar.py[line:272] - INFO: epoch 018:   1482 / 1732 loss=2.41, loss_v1=0, loss_v2=0, nll_loss=1.212, ntokens=1051.3, nsentences=32, sample_size=1051.3, sample_size_v1=0, sample_size_v2=0, ppl=2.32, wps=271.8, ups=0.26, wpb=1051.3, bsz=32, num_updates=30870, lr=4.31792e-06, gnorm=16.697, clip=100, loss_scale=32, train_wall=39, gb_free=7.7, wall=119137
2023-05-22 03:03:38 - progress_bar.py[line:272] - INFO: epoch 018:   1492 / 1732 loss=2.368, loss_v1=0, loss_v2=0, nll_loss=1.166, ntokens=1143, nsentences=32, sample_size=1143, sample_size_v1=0, sample_size_v2=0, ppl=2.24, wps=293.5, ups=0.26, wpb=1143, bsz=32, num_updates=30880, lr=4.31587e-06, gnorm=13.904, clip=100, loss_scale=32, train_wall=39, gb_free=8.8, wall=119175
2023-05-22 03:04:17 - progress_bar.py[line:272] - INFO: epoch 018:   1502 / 1732 loss=2.334, loss_v1=0, loss_v2=0, nll_loss=1.127, ntokens=1131.9, nsentences=32, sample_size=1131.9, sample_size_v1=0, sample_size_v2=0, ppl=2.18, wps=290.6, ups=0.26, wpb=1131.9, bsz=32, num_updates=30890, lr=4.31382e-06, gnorm=14.534, clip=100, loss_scale=32, train_wall=39, gb_free=7.4, wall=119214
2023-05-22 03:04:56 - progress_bar.py[line:272] - INFO: epoch 018:   1512 / 1732 loss=2.371, loss_v1=0, loss_v2=0, nll_loss=1.169, ntokens=1058.6, nsentences=32, sample_size=1058.6, sample_size_v1=0, sample_size_v2=0, ppl=2.25, wps=274.7, ups=0.26, wpb=1058.6, bsz=32, num_updates=30900, lr=4.31177e-06, gnorm=16.045, clip=100, loss_scale=32, train_wall=38, gb_free=7.8, wall=119253
2023-05-22 03:05:34 - progress_bar.py[line:272] - INFO: epoch 018:   1522 / 1732 loss=2.405, loss_v1=0, loss_v2=0, nll_loss=1.208, ntokens=1011, nsentences=32, sample_size=1011, sample_size_v1=0, sample_size_v2=0, ppl=2.31, wps=262.7, ups=0.26, wpb=1011, bsz=32, num_updates=30910, lr=4.30973e-06, gnorm=17.044, clip=100, loss_scale=32, train_wall=38, gb_free=9, wall=119291
2023-05-22 03:06:13 - progress_bar.py[line:272] - INFO: epoch 018:   1532 / 1732 loss=2.398, loss_v1=0, loss_v2=0, nll_loss=1.199, ntokens=1075.4, nsentences=32, sample_size=1075.4, sample_size_v1=0, sample_size_v2=0, ppl=2.3, wps=276.2, ups=0.26, wpb=1075.4, bsz=32, num_updates=30920, lr=4.30768e-06, gnorm=17.241, clip=100, loss_scale=32, train_wall=39, gb_free=7.9, wall=119330
2023-05-22 03:06:52 - progress_bar.py[line:272] - INFO: epoch 018:   1542 / 1732 loss=2.361, loss_v1=0, loss_v2=0, nll_loss=1.155, ntokens=1113.4, nsentences=32, sample_size=1113.4, sample_size_v1=0, sample_size_v2=0, ppl=2.23, wps=286.5, ups=0.26, wpb=1113.4, bsz=32, num_updates=30930, lr=4.30563e-06, gnorm=16.833, clip=100, loss_scale=32, train_wall=39, gb_free=8.2, wall=119369
2023-05-22 03:07:31 - progress_bar.py[line:272] - INFO: epoch 018:   1552 / 1732 loss=2.362, loss_v1=0, loss_v2=0, nll_loss=1.157, ntokens=1059, nsentences=32, sample_size=1059, sample_size_v1=0, sample_size_v2=0, ppl=2.23, wps=274, ups=0.26, wpb=1059, bsz=32, num_updates=30940, lr=4.30358e-06, gnorm=15.339, clip=100, loss_scale=32, train_wall=39, gb_free=8.5, wall=119408
2023-05-22 03:08:10 - progress_bar.py[line:272] - INFO: epoch 018:   1562 / 1732 loss=2.386, loss_v1=0, loss_v2=0, nll_loss=1.185, ntokens=1107.4, nsentences=32, sample_size=1107.4, sample_size_v1=0, sample_size_v2=0, ppl=2.27, wps=284.7, ups=0.26, wpb=1107.4, bsz=32, num_updates=30950, lr=4.30154e-06, gnorm=16.011, clip=100, loss_scale=32, train_wall=39, gb_free=8.3, wall=119447
2023-05-22 03:08:48 - progress_bar.py[line:272] - INFO: epoch 018:   1572 / 1732 loss=2.402, loss_v1=0, loss_v2=0, nll_loss=1.203, ntokens=1068.7, nsentences=32, sample_size=1068.7, sample_size_v1=0, sample_size_v2=0, ppl=2.3, wps=275.1, ups=0.26, wpb=1068.7, bsz=32, num_updates=30960, lr=4.29949e-06, gnorm=16.745, clip=100, loss_scale=32, train_wall=39, gb_free=8.7, wall=119486
2023-05-22 03:09:28 - progress_bar.py[line:272] - INFO: epoch 018:   1582 / 1732 loss=2.422, loss_v1=0, loss_v2=0, nll_loss=1.224, ntokens=1012.7, nsentences=32, sample_size=1012.7, sample_size_v1=0, sample_size_v2=0, ppl=2.34, wps=258.9, ups=0.26, wpb=1012.7, bsz=32, num_updates=30970, lr=4.29744e-06, gnorm=17.9, clip=100, loss_scale=32, train_wall=39, gb_free=7.7, wall=119525
2023-05-22 03:10:06 - progress_bar.py[line:272] - INFO: epoch 018:   1592 / 1732 loss=2.362, loss_v1=0, loss_v2=0, nll_loss=1.158, ntokens=1072.6, nsentences=32, sample_size=1072.6, sample_size_v1=0, sample_size_v2=0, ppl=2.23, wps=275.8, ups=0.26, wpb=1072.6, bsz=32, num_updates=30980, lr=4.2954e-06, gnorm=16.48, clip=100, loss_scale=32, train_wall=39, gb_free=8.8, wall=119564
2023-05-22 03:10:46 - progress_bar.py[line:272] - INFO: epoch 018:   1602 / 1732 loss=2.349, loss_v1=0, loss_v2=0, nll_loss=1.145, ntokens=1101.7, nsentences=32, sample_size=1101.7, sample_size_v1=0, sample_size_v2=0, ppl=2.21, wps=281.9, ups=0.26, wpb=1101.7, bsz=32, num_updates=30990, lr=4.29335e-06, gnorm=16.128, clip=100, loss_scale=32, train_wall=39, gb_free=7.5, wall=119603
2023-05-22 03:11:25 - progress_bar.py[line:272] - INFO: epoch 018:   1612 / 1732 loss=2.349, loss_v1=0, loss_v2=0, nll_loss=1.145, ntokens=1156, nsentences=32, sample_size=1156, sample_size_v1=0, sample_size_v2=0, ppl=2.21, wps=296.6, ups=0.26, wpb=1156, bsz=32, num_updates=31000, lr=4.2913e-06, gnorm=15.593, clip=100, loss_scale=32, train_wall=39, gb_free=8.7, wall=119642
2023-05-22 03:12:04 - progress_bar.py[line:272] - INFO: epoch 018:   1622 / 1732 loss=2.352, loss_v1=0, loss_v2=0, nll_loss=1.147, ntokens=1098.4, nsentences=32, sample_size=1098.4, sample_size_v1=0, sample_size_v2=0, ppl=2.21, wps=281.2, ups=0.26, wpb=1098.4, bsz=32, num_updates=31010, lr=4.28925e-06, gnorm=14.836, clip=100, loss_scale=32, train_wall=39, gb_free=8.6, wall=119681
2023-05-22 03:12:43 - progress_bar.py[line:272] - INFO: epoch 018:   1632 / 1732 loss=2.359, loss_v1=0, loss_v2=0, nll_loss=1.156, ntokens=1161.4, nsentences=32, sample_size=1161.4, sample_size_v1=0, sample_size_v2=0, ppl=2.23, wps=296.8, ups=0.26, wpb=1161.4, bsz=32, num_updates=31020, lr=4.28721e-06, gnorm=15.329, clip=100, loss_scale=32, train_wall=39, gb_free=8.8, wall=119720
2023-05-22 03:13:22 - progress_bar.py[line:272] - INFO: epoch 018:   1642 / 1732 loss=2.338, loss_v1=0, loss_v2=0, nll_loss=1.131, ntokens=1223.1, nsentences=32, sample_size=1223.1, sample_size_v1=0, sample_size_v2=0, ppl=2.19, wps=313.9, ups=0.26, wpb=1223.1, bsz=32, num_updates=31030, lr=4.28516e-06, gnorm=13.995, clip=100, loss_scale=32, train_wall=39, gb_free=7.9, wall=119759
2023-05-22 03:14:00 - progress_bar.py[line:272] - INFO: epoch 018:   1652 / 1732 loss=2.358, loss_v1=0, loss_v2=0, nll_loss=1.155, ntokens=1045.5, nsentences=32, sample_size=1045.5, sample_size_v1=0, sample_size_v2=0, ppl=2.23, wps=271.6, ups=0.26, wpb=1045.5, bsz=32, num_updates=31040, lr=4.28311e-06, gnorm=15.519, clip=100, loss_scale=32, train_wall=38, gb_free=8.3, wall=119797
2023-05-22 03:14:39 - progress_bar.py[line:272] - INFO: epoch 018:   1662 / 1732 loss=2.388, loss_v1=0, loss_v2=0, nll_loss=1.188, ntokens=1037.9, nsentences=32, sample_size=1037.9, sample_size_v1=0, sample_size_v2=0, ppl=2.28, wps=268.7, ups=0.26, wpb=1037.9, bsz=32, num_updates=31050, lr=4.28106e-06, gnorm=15.643, clip=100, loss_scale=32, train_wall=39, gb_free=8.5, wall=119836
2023-05-22 03:15:17 - progress_bar.py[line:272] - INFO: epoch 018:   1672 / 1732 loss=2.366, loss_v1=0, loss_v2=0, nll_loss=1.161, ntokens=1009.9, nsentences=32, sample_size=1009.9, sample_size_v1=0, sample_size_v2=0, ppl=2.24, wps=262.7, ups=0.26, wpb=1009.9, bsz=32, num_updates=31060, lr=4.27902e-06, gnorm=16.622, clip=100, loss_scale=32, train_wall=38, gb_free=8.1, wall=119874
2023-05-22 03:15:56 - progress_bar.py[line:272] - INFO: epoch 018:   1682 / 1732 loss=2.325, loss_v1=0, loss_v2=0, nll_loss=1.116, ntokens=1181.4, nsentences=32, sample_size=1181.4, sample_size_v1=0, sample_size_v2=0, ppl=2.17, wps=302.9, ups=0.26, wpb=1181.4, bsz=32, num_updates=31070, lr=4.27697e-06, gnorm=14.385, clip=100, loss_scale=32, train_wall=39, gb_free=8.4, wall=119913
2023-05-22 03:16:36 - progress_bar.py[line:272] - INFO: epoch 018:   1692 / 1732 loss=2.335, loss_v1=0, loss_v2=0, nll_loss=1.127, ntokens=1233.5, nsentences=32, sample_size=1233.5, sample_size_v1=0, sample_size_v2=0, ppl=2.18, wps=312.6, ups=0.25, wpb=1233.5, bsz=32, num_updates=31080, lr=4.27492e-06, gnorm=13.732, clip=100, loss_scale=32, train_wall=39, gb_free=7.9, wall=119953
2023-05-22 03:17:15 - progress_bar.py[line:272] - INFO: epoch 018:   1702 / 1732 loss=2.358, loss_v1=0, loss_v2=0, nll_loss=1.154, ntokens=1273, nsentences=32, sample_size=1273, sample_size_v1=0, sample_size_v2=0, ppl=2.23, wps=322.3, ups=0.25, wpb=1273, bsz=32, num_updates=31090, lr=4.27287e-06, gnorm=14.564, clip=100, loss_scale=32, train_wall=39, gb_free=7.7, wall=119992
2023-05-22 03:17:54 - progress_bar.py[line:272] - INFO: epoch 018:   1712 / 1732 loss=2.374, loss_v1=0, loss_v2=0, nll_loss=1.172, ntokens=1144.5, nsentences=32, sample_size=1144.5, sample_size_v1=0, sample_size_v2=0, ppl=2.25, wps=294.1, ups=0.26, wpb=1144.5, bsz=32, num_updates=31100, lr=4.27083e-06, gnorm=14.722, clip=100, loss_scale=32, train_wall=39, gb_free=8.4, wall=120031
2023-05-22 03:18:26 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2023-05-22 03:18:37 - progress_bar.py[line:272] - INFO: epoch 018:   1723 / 1732 loss=2.358, loss_v1=0, loss_v2=0, nll_loss=1.155, ntokens=1178.5, nsentences=32, sample_size=1178.5, sample_size_v1=0, sample_size_v2=0, ppl=2.23, wps=273.4, ups=0.23, wpb=1178.5, bsz=32, num_updates=31110, lr=4.26878e-06, gnorm=14.462, clip=100, loss_scale=32, train_wall=43, gb_free=7.4, wall=120074
2023-05-22 03:19:09 - train.py[line:332] - INFO: end of epoch 18 (average epoch stats below)
2023-05-22 03:19:09 - progress_bar.py[line:282] - INFO: epoch 018 | loss 2.378 | loss_v1 0 | loss_v2 0 | nll_loss 1.176 | ntokens 1051.68 | nsentences 31.986 | sample_size 1051.68 | sample_size_v1 0 | sample_size_v2 0 | ppl 2.26 | wps 272.3 | ups 0.26 | wpb 1051.7 | bsz 32 | num_updates 31119 | lr 4.26694e-06 | gnorm 15.643 | clip 100 | loss_scale 32 | train_wall 6664 | gb_free 8.9 | wall 120107
2023-05-22 03:19:09 - trainer.py[line:639] - INFO: loading train data for epoch 19
local datafile ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 0 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 0 finished initializing row_count and line_idx-to-offset mapping
file ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 0 row count 55400 total row count 55400
slice_id 0 seek offset 0
2023-05-22 03:19:11 - trainer.py[line:703] - INFO: begin training epoch 19
2023-05-22 03:19:11 - train.py[line:305] - INFO: Start iterating over samples
2023-05-22 03:19:15 - progress_bar.py[line:272] - INFO: epoch 019:      1 / 1732 loss=2.417, loss_v1=0, loss_v2=0, nll_loss=1.22, ntokens=1067.2, nsentences=29.6, sample_size=1067.2, sample_size_v1=0, sample_size_v2=0, ppl=2.33, wps=279.7, ups=0.26, wpb=1067.2, bsz=29.6, num_updates=31120, lr=4.26673e-06, gnorm=16.659, clip=100, loss_scale=32, train_wall=36, gb_free=8.5, wall=120113
2023-05-22 03:19:54 - progress_bar.py[line:272] - INFO: epoch 019:     11 / 1732 loss=2.297, loss_v1=0, loss_v2=0, nll_loss=1.084, ntokens=1109.8, nsentences=32, sample_size=1109.8, sample_size_v1=0, sample_size_v2=0, ppl=2.12, wps=284.9, ups=0.26, wpb=1109.8, bsz=32, num_updates=31130, lr=4.26468e-06, gnorm=16.486, clip=100, loss_scale=32, train_wall=39, gb_free=8.6, wall=120152
2023-05-22 03:20:33 - progress_bar.py[line:272] - INFO: epoch 019:     21 / 1732 loss=2.245, loss_v1=0, loss_v2=0, nll_loss=1.025, ntokens=1106.8, nsentences=32, sample_size=1106.8, sample_size_v1=0, sample_size_v2=0, ppl=2.04, wps=286, ups=0.26, wpb=1106.8, bsz=32, num_updates=31140, lr=4.26264e-06, gnorm=14.687, clip=100, loss_scale=32, train_wall=39, gb_free=8.4, wall=120190
2023-05-22 03:21:12 - progress_bar.py[line:272] - INFO: epoch 019:     31 / 1732 loss=2.277, loss_v1=0, loss_v2=0, nll_loss=1.062, ntokens=958.4, nsentences=32, sample_size=958.4, sample_size_v1=0, sample_size_v2=0, ppl=2.09, wps=247.8, ups=0.26, wpb=958.4, bsz=32, num_updates=31150, lr=4.26059e-06, gnorm=15.491, clip=100, loss_scale=32, train_wall=39, gb_free=8.3, wall=120229
2023-05-22 03:21:51 - progress_bar.py[line:272] - INFO: epoch 019:     41 / 1732 loss=2.147, loss_v1=0, loss_v2=0, nll_loss=0.92, ntokens=1207.2, nsentences=32, sample_size=1207.2, sample_size_v1=0, sample_size_v2=0, ppl=1.89, wps=306.7, ups=0.25, wpb=1207.2, bsz=32, num_updates=31160, lr=4.25854e-06, gnorm=10.349, clip=100, loss_scale=32, train_wall=39, gb_free=8, wall=120268
2023-05-22 03:22:30 - progress_bar.py[line:272] - INFO: epoch 019:     51 / 1732 loss=2.221, loss_v1=0, loss_v2=0, nll_loss=1.007, ntokens=1028.6, nsentences=32, sample_size=1028.6, sample_size_v1=0, sample_size_v2=0, ppl=2.01, wps=265.8, ups=0.26, wpb=1028.6, bsz=32, num_updates=31170, lr=4.2565e-06, gnorm=13.495, clip=100, loss_scale=32, train_wall=39, gb_free=8.3, wall=120307
2023-05-22 03:23:09 - progress_bar.py[line:272] - INFO: epoch 019:     61 / 1732 loss=2.024, loss_v1=0, loss_v2=0, nll_loss=0.782, ntokens=1123.9, nsentences=32, sample_size=1123.9, sample_size_v1=0, sample_size_v2=0, ppl=1.72, wps=290.3, ups=0.26, wpb=1123.9, bsz=32, num_updates=31180, lr=4.25445e-06, gnorm=11.613, clip=100, loss_scale=32, train_wall=39, gb_free=7.1, wall=120346
2023-05-22 03:23:49 - progress_bar.py[line:272] - INFO: epoch 019:     71 / 1732 loss=2.099, loss_v1=0, loss_v2=0, nll_loss=0.868, ntokens=1363.4, nsentences=32, sample_size=1363.4, sample_size_v1=0, sample_size_v2=0, ppl=1.82, wps=340.4, ups=0.25, wpb=1363.4, bsz=32, num_updates=31190, lr=4.2524e-06, gnorm=11.12, clip=100, loss_scale=32, train_wall=40, gb_free=7, wall=120386
2023-05-22 03:24:28 - progress_bar.py[line:272] - INFO: epoch 019:     81 / 1732 loss=2.14, loss_v1=0, loss_v2=0, nll_loss=0.908, ntokens=1263, nsentences=32, sample_size=1263, sample_size_v1=0, sample_size_v2=0, ppl=1.88, wps=316.9, ups=0.25, wpb=1263, bsz=32, num_updates=31200, lr=4.25035e-06, gnorm=14.265, clip=100, loss_scale=32, train_wall=40, gb_free=8.5, wall=120426
2023-05-22 03:25:08 - progress_bar.py[line:272] - INFO: epoch 019:     91 / 1732 loss=2.22, loss_v1=0, loss_v2=0, nll_loss=0.998, ntokens=1062.5, nsentences=32, sample_size=1062.5, sample_size_v1=0, sample_size_v2=0, ppl=2, wps=271, ups=0.26, wpb=1062.5, bsz=32, num_updates=31210, lr=4.24831e-06, gnorm=15.08, clip=100, loss_scale=32, train_wall=39, gb_free=8.6, wall=120465
2023-05-22 03:25:46 - progress_bar.py[line:272] - INFO: epoch 019:    101 / 1732 loss=2.225, loss_v1=0, loss_v2=0, nll_loss=1.006, ntokens=1023.5, nsentences=32, sample_size=1023.5, sample_size_v1=0, sample_size_v2=0, ppl=2.01, wps=266.2, ups=0.26, wpb=1023.5, bsz=32, num_updates=31220, lr=4.24626e-06, gnorm=16.14, clip=100, loss_scale=32, train_wall=38, gb_free=8.1, wall=120503
2023-05-22 03:26:25 - progress_bar.py[line:272] - INFO: epoch 019:    111 / 1732 loss=2.38, loss_v1=0, loss_v2=0, nll_loss=1.179, ntokens=1034.7, nsentences=32, sample_size=1034.7, sample_size_v1=0, sample_size_v2=0, ppl=2.26, wps=268.5, ups=0.26, wpb=1034.7, bsz=32, num_updates=31230, lr=4.24421e-06, gnorm=18.227, clip=100, loss_scale=32, train_wall=38, gb_free=8.4, wall=120542
2023-05-22 03:27:04 - progress_bar.py[line:272] - INFO: epoch 019:    121 / 1732 loss=2.341, loss_v1=0, loss_v2=0, nll_loss=1.133, ntokens=1114.4, nsentences=32, sample_size=1114.4, sample_size_v1=0, sample_size_v2=0, ppl=2.19, wps=283.8, ups=0.25, wpb=1114.4, bsz=32, num_updates=31240, lr=4.24216e-06, gnorm=14.499, clip=100, loss_scale=32, train_wall=39, gb_free=8.1, wall=120581
2023-05-22 03:27:44 - progress_bar.py[line:272] - INFO: epoch 019:    131 / 1732 loss=2.318, loss_v1=0, loss_v2=0, nll_loss=1.109, ntokens=1176.2, nsentences=32, sample_size=1176.2, sample_size_v1=0, sample_size_v2=0, ppl=2.16, wps=297.3, ups=0.25, wpb=1176.2, bsz=32, num_updates=31250, lr=4.24012e-06, gnorm=14.316, clip=100, loss_scale=32, train_wall=40, gb_free=8.3, wall=120621
2023-05-22 03:28:23 - progress_bar.py[line:272] - INFO: epoch 019:    141 / 1732 loss=2.27, loss_v1=0, loss_v2=0, nll_loss=1.056, ntokens=1252.9, nsentences=32, sample_size=1252.9, sample_size_v1=0, sample_size_v2=0, ppl=2.08, wps=317.8, ups=0.25, wpb=1252.9, bsz=32, num_updates=31260, lr=4.23807e-06, gnorm=12.43, clip=100, loss_scale=32, train_wall=39, gb_free=8.3, wall=120660
2023-05-22 03:29:03 - progress_bar.py[line:272] - INFO: epoch 019:    151 / 1732 loss=2.263, loss_v1=0, loss_v2=0, nll_loss=1.049, ntokens=1168.3, nsentences=32, sample_size=1168.3, sample_size_v1=0, sample_size_v2=0, ppl=2.07, wps=292.5, ups=0.25, wpb=1168.3, bsz=32, num_updates=31270, lr=4.23602e-06, gnorm=12.706, clip=100, loss_scale=32, train_wall=40, gb_free=6.8, wall=120700
2023-05-22 03:29:42 - progress_bar.py[line:272] - INFO: epoch 019:    161 / 1732 loss=2.294, loss_v1=0, loss_v2=0, nll_loss=1.082, ntokens=1106.1, nsentences=32, sample_size=1106.1, sample_size_v1=0, sample_size_v2=0, ppl=2.12, wps=281.3, ups=0.25, wpb=1106.1, bsz=32, num_updates=31280, lr=4.23397e-06, gnorm=13.39, clip=100, loss_scale=32, train_wall=39, gb_free=8.4, wall=120739
2023-05-22 03:30:21 - progress_bar.py[line:272] - INFO: epoch 019:    171 / 1732 loss=2.298, loss_v1=0, loss_v2=0, nll_loss=1.089, ntokens=969.4, nsentences=32, sample_size=969.4, sample_size_v1=0, sample_size_v2=0, ppl=2.13, wps=250.2, ups=0.26, wpb=969.4, bsz=32, num_updates=31290, lr=4.23193e-06, gnorm=15.71, clip=100, loss_scale=32, train_wall=39, gb_free=8.5, wall=120778
2023-05-22 03:31:00 - progress_bar.py[line:272] - INFO: epoch 019:    181 / 1732 loss=2.255, loss_v1=0, loss_v2=0, nll_loss=1.039, ntokens=1122.2, nsentences=32, sample_size=1122.2, sample_size_v1=0, sample_size_v2=0, ppl=2.05, wps=284.6, ups=0.25, wpb=1122.2, bsz=32, num_updates=31300, lr=4.22988e-06, gnorm=14.312, clip=100, loss_scale=32, train_wall=39, gb_free=8.2, wall=120818
2023-05-22 03:31:40 - progress_bar.py[line:272] - INFO: epoch 019:    191 / 1732 loss=2.262, loss_v1=0, loss_v2=0, nll_loss=1.044, ntokens=1130.1, nsentences=32, sample_size=1130.1, sample_size_v1=0, sample_size_v2=0, ppl=2.06, wps=286.2, ups=0.25, wpb=1130.1, bsz=32, num_updates=31310, lr=4.22783e-06, gnorm=13.215, clip=100, loss_scale=32, train_wall=39, gb_free=8, wall=120857
2023-05-22 03:32:19 - progress_bar.py[line:272] - INFO: epoch 019:    201 / 1732 loss=2.338, loss_v1=0, loss_v2=0, nll_loss=1.131, ntokens=1092.1, nsentences=32, sample_size=1092.1, sample_size_v1=0, sample_size_v2=0, ppl=2.19, wps=279.9, ups=0.26, wpb=1092.1, bsz=32, num_updates=31320, lr=4.22578e-06, gnorm=15.473, clip=100, loss_scale=32, train_wall=39, gb_free=8.5, wall=120896
2023-05-22 03:32:57 - progress_bar.py[line:272] - INFO: epoch 019:    211 / 1732 loss=2.406, loss_v1=0, loss_v2=0, nll_loss=1.207, ntokens=1010.6, nsentences=32, sample_size=1010.6, sample_size_v1=0, sample_size_v2=0, ppl=2.31, wps=263.7, ups=0.26, wpb=1010.6, bsz=32, num_updates=31330, lr=4.22374e-06, gnorm=15.532, clip=100, loss_scale=32, train_wall=38, gb_free=8.1, wall=120934
2023-05-22 03:33:36 - progress_bar.py[line:272] - INFO: epoch 019:    221 / 1732 loss=2.392, loss_v1=0, loss_v2=0, nll_loss=1.194, ntokens=1140.8, nsentences=32, sample_size=1140.8, sample_size_v1=0, sample_size_v2=0, ppl=2.29, wps=297.6, ups=0.26, wpb=1140.8, bsz=32, num_updates=31340, lr=4.22169e-06, gnorm=16.055, clip=100, loss_scale=32, train_wall=38, gb_free=7.7, wall=120973
2023-05-22 03:34:14 - progress_bar.py[line:272] - INFO: epoch 019:    231 / 1732 loss=2.416, loss_v1=0, loss_v2=0, nll_loss=1.22, ntokens=1093.8, nsentences=32, sample_size=1093.8, sample_size_v1=0, sample_size_v2=0, ppl=2.33, wps=285.3, ups=0.26, wpb=1093.8, bsz=32, num_updates=31350, lr=4.21964e-06, gnorm=15.109, clip=100, loss_scale=32, train_wall=38, gb_free=8.8, wall=121011
2023-05-22 03:34:52 - progress_bar.py[line:272] - INFO: epoch 019:    241 / 1732 loss=2.431, loss_v1=0, loss_v2=0, nll_loss=1.235, ntokens=1114.7, nsentences=32, sample_size=1114.7, sample_size_v1=0, sample_size_v2=0, ppl=2.35, wps=289.4, ups=0.26, wpb=1114.7, bsz=32, num_updates=31360, lr=4.2176e-06, gnorm=15.252, clip=100, loss_scale=32, train_wall=38, gb_free=8.7, wall=121050
2023-05-22 03:35:31 - progress_bar.py[line:272] - INFO: epoch 019:    251 / 1732 loss=2.408, loss_v1=0, loss_v2=0, nll_loss=1.208, ntokens=1172.1, nsentences=32, sample_size=1172.1, sample_size_v1=0, sample_size_v2=0, ppl=2.31, wps=302.1, ups=0.26, wpb=1172.1, bsz=32, num_updates=31370, lr=4.21555e-06, gnorm=14.777, clip=100, loss_scale=32, train_wall=39, gb_free=8.8, wall=121088
2023-05-22 03:36:10 - progress_bar.py[line:272] - INFO: epoch 019:    261 / 1732 loss=2.433, loss_v1=0, loss_v2=0, nll_loss=1.237, ntokens=1139.9, nsentences=32, sample_size=1139.9, sample_size_v1=0, sample_size_v2=0, ppl=2.36, wps=296.3, ups=0.26, wpb=1139.9, bsz=32, num_updates=31380, lr=4.2135e-06, gnorm=14.689, clip=100, loss_scale=32, train_wall=38, gb_free=8.3, wall=121127
2023-05-22 03:36:48 - progress_bar.py[line:272] - INFO: epoch 019:    271 / 1732 loss=2.396, loss_v1=0, loss_v2=0, nll_loss=1.195, ntokens=1145.3, nsentences=32, sample_size=1145.3, sample_size_v1=0, sample_size_v2=0, ppl=2.29, wps=296.2, ups=0.26, wpb=1145.3, bsz=32, num_updates=31390, lr=4.21145e-06, gnorm=15.349, clip=100, loss_scale=32, train_wall=39, gb_free=8.3, wall=121166
2023-05-22 03:37:27 - progress_bar.py[line:272] - INFO: epoch 019:    281 / 1732 loss=2.425, loss_v1=0, loss_v2=0, nll_loss=1.228, ntokens=1149.7, nsentences=32, sample_size=1149.7, sample_size_v1=0, sample_size_v2=0, ppl=2.34, wps=297.3, ups=0.26, wpb=1149.7, bsz=32, num_updates=31400, lr=4.20941e-06, gnorm=14.519, clip=100, loss_scale=32, train_wall=39, gb_free=9.1, wall=121204
2023-05-22 03:38:06 - progress_bar.py[line:272] - INFO: epoch 019:    291 / 1732 loss=2.386, loss_v1=0, loss_v2=0, nll_loss=1.185, ntokens=1130.5, nsentences=32, sample_size=1130.5, sample_size_v1=0, sample_size_v2=0, ppl=2.27, wps=293.4, ups=0.26, wpb=1130.5, bsz=32, num_updates=31410, lr=4.20736e-06, gnorm=14.733, clip=100, loss_scale=32, train_wall=38, gb_free=8.5, wall=121243
2023-05-22 03:38:44 - progress_bar.py[line:272] - INFO: epoch 019:    301 / 1732 loss=2.407, loss_v1=0, loss_v2=0, nll_loss=1.208, ntokens=1109.1, nsentences=32, sample_size=1109.1, sample_size_v1=0, sample_size_v2=0, ppl=2.31, wps=286.4, ups=0.26, wpb=1109.1, bsz=32, num_updates=31420, lr=4.20531e-06, gnorm=15.764, clip=100, loss_scale=32, train_wall=39, gb_free=8.8, wall=121282
2023-05-22 03:39:23 - progress_bar.py[line:272] - INFO: epoch 019:    311 / 1732 loss=2.388, loss_v1=0, loss_v2=0, nll_loss=1.188, ntokens=1067.3, nsentences=32, sample_size=1067.3, sample_size_v1=0, sample_size_v2=0, ppl=2.28, wps=278.6, ups=0.26, wpb=1067.3, bsz=32, num_updates=31430, lr=4.20326e-06, gnorm=16.164, clip=100, loss_scale=32, train_wall=38, gb_free=8.7, wall=121320
2023-05-22 03:40:01 - progress_bar.py[line:272] - INFO: epoch 019:    321 / 1732 loss=2.435, loss_v1=0, loss_v2=0, nll_loss=1.24, ntokens=1001.7, nsentences=32, sample_size=1001.7, sample_size_v1=0, sample_size_v2=0, ppl=2.36, wps=262.9, ups=0.26, wpb=1001.7, bsz=32, num_updates=31440, lr=4.20122e-06, gnorm=16.772, clip=100, loss_scale=32, train_wall=38, gb_free=9.1, wall=121358
2023-05-22 03:40:39 - progress_bar.py[line:272] - INFO: epoch 019:    331 / 1732 loss=2.433, loss_v1=0, loss_v2=0, nll_loss=1.239, ntokens=1019.4, nsentences=32, sample_size=1019.4, sample_size_v1=0, sample_size_v2=0, ppl=2.36, wps=266.8, ups=0.26, wpb=1019.4, bsz=32, num_updates=31450, lr=4.19917e-06, gnorm=15.391, clip=100, loss_scale=32, train_wall=38, gb_free=8.7, wall=121396
2023-05-22 03:41:17 - progress_bar.py[line:272] - INFO: epoch 019:    341 / 1732 loss=2.387, loss_v1=0, loss_v2=0, nll_loss=1.186, ntokens=952.2, nsentences=32, sample_size=952.2, sample_size_v1=0, sample_size_v2=0, ppl=2.28, wps=251.1, ups=0.26, wpb=952.2, bsz=32, num_updates=31460, lr=4.19712e-06, gnorm=16.315, clip=100, loss_scale=32, train_wall=38, gb_free=9, wall=121434
2023-05-22 03:41:55 - progress_bar.py[line:272] - INFO: epoch 019:    351 / 1732 loss=2.416, loss_v1=0, loss_v2=0, nll_loss=1.22, ntokens=941.5, nsentences=32, sample_size=941.5, sample_size_v1=0, sample_size_v2=0, ppl=2.33, wps=247.4, ups=0.26, wpb=941.5, bsz=32, num_updates=31470, lr=4.19507e-06, gnorm=18.393, clip=100, loss_scale=32, train_wall=38, gb_free=8.7, wall=121472
2023-05-22 03:42:33 - progress_bar.py[line:272] - INFO: epoch 019:    361 / 1732 loss=2.446, loss_v1=0, loss_v2=0, nll_loss=1.253, ntokens=925.7, nsentences=32, sample_size=925.7, sample_size_v1=0, sample_size_v2=0, ppl=2.38, wps=243, ups=0.26, wpb=925.7, bsz=32, num_updates=31480, lr=4.19303e-06, gnorm=17.958, clip=100, loss_scale=32, train_wall=38, gb_free=8.6, wall=121510
2023-05-22 03:43:11 - progress_bar.py[line:272] - INFO: epoch 019:    371 / 1732 loss=2.449, loss_v1=0, loss_v2=0, nll_loss=1.255, ntokens=989.1, nsentences=32, sample_size=989.1, sample_size_v1=0, sample_size_v2=0, ppl=2.39, wps=259.5, ups=0.26, wpb=989.1, bsz=32, num_updates=31490, lr=4.19098e-06, gnorm=16.143, clip=100, loss_scale=32, train_wall=38, gb_free=8.2, wall=121548
2023-05-22 03:43:49 - progress_bar.py[line:272] - INFO: epoch 019:    381 / 1732 loss=2.44, loss_v1=0, loss_v2=0, nll_loss=1.244, ntokens=1071.8, nsentences=32, sample_size=1071.8, sample_size_v1=0, sample_size_v2=0, ppl=2.37, wps=280.3, ups=0.26, wpb=1071.8, bsz=32, num_updates=31500, lr=4.18893e-06, gnorm=16.713, clip=100, loss_scale=32, train_wall=38, gb_free=8.6, wall=121587
2023-05-22 03:44:28 - progress_bar.py[line:272] - INFO: epoch 019:    391 / 1732 loss=2.416, loss_v1=0, loss_v2=0, nll_loss=1.218, ntokens=986, nsentences=32, sample_size=986, sample_size_v1=0, sample_size_v2=0, ppl=2.33, wps=258.3, ups=0.26, wpb=986, bsz=32, num_updates=31510, lr=4.18688e-06, gnorm=16.71, clip=100, loss_scale=32, train_wall=38, gb_free=8.8, wall=121625
2023-05-22 03:45:06 - progress_bar.py[line:272] - INFO: epoch 019:    401 / 1732 loss=2.413, loss_v1=0, loss_v2=0, nll_loss=1.215, ntokens=999.1, nsentences=32, sample_size=999.1, sample_size_v1=0, sample_size_v2=0, ppl=2.32, wps=262.6, ups=0.26, wpb=999.1, bsz=32, num_updates=31520, lr=4.18484e-06, gnorm=16.915, clip=100, loss_scale=32, train_wall=38, gb_free=8.5, wall=121663
2023-05-22 03:45:44 - progress_bar.py[line:272] - INFO: epoch 019:    411 / 1732 loss=2.397, loss_v1=0, loss_v2=0, nll_loss=1.197, ntokens=1079.4, nsentences=32, sample_size=1079.4, sample_size_v1=0, sample_size_v2=0, ppl=2.29, wps=283, ups=0.26, wpb=1079.4, bsz=32, num_updates=31530, lr=4.18279e-06, gnorm=15.143, clip=100, loss_scale=32, train_wall=38, gb_free=8.7, wall=121701
2023-05-22 03:46:22 - progress_bar.py[line:272] - INFO: epoch 019:    421 / 1732 loss=2.387, loss_v1=0, loss_v2=0, nll_loss=1.188, ntokens=1019, nsentences=32, sample_size=1019, sample_size_v1=0, sample_size_v2=0, ppl=2.28, wps=265.9, ups=0.26, wpb=1019, bsz=32, num_updates=31540, lr=4.18074e-06, gnorm=17.264, clip=100, loss_scale=32, train_wall=38, gb_free=8.5, wall=121739
2023-05-22 03:47:00 - progress_bar.py[line:272] - INFO: epoch 019:    431 / 1732 loss=2.394, loss_v1=0, loss_v2=0, nll_loss=1.194, ntokens=1019.7, nsentences=32, sample_size=1019.7, sample_size_v1=0, sample_size_v2=0, ppl=2.29, wps=266.6, ups=0.26, wpb=1019.7, bsz=32, num_updates=31550, lr=4.1787e-06, gnorm=16.6, clip=100, loss_scale=32, train_wall=38, gb_free=8.4, wall=121778
2023-05-22 03:47:38 - progress_bar.py[line:272] - INFO: epoch 019:    441 / 1732 loss=2.421, loss_v1=0, loss_v2=0, nll_loss=1.224, ntokens=990.4, nsentences=32, sample_size=990.4, sample_size_v1=0, sample_size_v2=0, ppl=2.34, wps=261.5, ups=0.26, wpb=990.4, bsz=32, num_updates=31560, lr=4.17665e-06, gnorm=16.385, clip=100, loss_scale=32, train_wall=38, gb_free=8.7, wall=121815
2023-05-22 03:48:16 - progress_bar.py[line:272] - INFO: epoch 019:    451 / 1732 loss=2.425, loss_v1=0, loss_v2=0, nll_loss=1.229, ntokens=920.2, nsentences=32, sample_size=920.2, sample_size_v1=0, sample_size_v2=0, ppl=2.34, wps=241.4, ups=0.26, wpb=920.2, bsz=32, num_updates=31570, lr=4.1746e-06, gnorm=17.948, clip=100, loss_scale=32, train_wall=38, gb_free=8, wall=121854
2023-05-22 03:48:54 - progress_bar.py[line:272] - INFO: epoch 019:    461 / 1732 loss=2.439, loss_v1=0, loss_v2=0, nll_loss=1.244, ntokens=1038.5, nsentences=32, sample_size=1038.5, sample_size_v1=0, sample_size_v2=0, ppl=2.37, wps=273, ups=0.26, wpb=1038.5, bsz=32, num_updates=31580, lr=4.17255e-06, gnorm=16.608, clip=100, loss_scale=32, train_wall=38, gb_free=8.3, wall=121892
2023-05-22 03:49:32 - progress_bar.py[line:272] - INFO: epoch 019:    471 / 1732 loss=2.429, loss_v1=0, loss_v2=0, nll_loss=1.234, ntokens=1039.4, nsentences=32, sample_size=1039.4, sample_size_v1=0, sample_size_v2=0, ppl=2.35, wps=272.8, ups=0.26, wpb=1039.4, bsz=32, num_updates=31590, lr=4.17051e-06, gnorm=15.978, clip=100, loss_scale=32, train_wall=38, gb_free=8.9, wall=121930
2023-05-22 03:50:11 - progress_bar.py[line:272] - INFO: epoch 019:    481 / 1732 loss=2.431, loss_v1=0, loss_v2=0, nll_loss=1.234, ntokens=1025, nsentences=32, sample_size=1025, sample_size_v1=0, sample_size_v2=0, ppl=2.35, wps=269.4, ups=0.26, wpb=1025, bsz=32, num_updates=31600, lr=4.16846e-06, gnorm=14.909, clip=100, loss_scale=32, train_wall=38, gb_free=9.2, wall=121968
2023-05-22 03:50:49 - progress_bar.py[line:272] - INFO: epoch 019:    491 / 1732 loss=2.417, loss_v1=0, loss_v2=0, nll_loss=1.22, ntokens=939.5, nsentences=32, sample_size=939.5, sample_size_v1=0, sample_size_v2=0, ppl=2.33, wps=247.1, ups=0.26, wpb=939.5, bsz=32, num_updates=31610, lr=4.16641e-06, gnorm=17.317, clip=100, loss_scale=32, train_wall=38, gb_free=7.9, wall=122006
2023-05-22 03:51:26 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2023-05-22 03:51:30 - progress_bar.py[line:272] - INFO: epoch 019:    502 / 1732 loss=2.403, loss_v1=0, loss_v2=0, nll_loss=1.204, ntokens=957.5, nsentences=32, sample_size=957.5, sample_size_v1=0, sample_size_v2=0, ppl=2.3, wps=230, ups=0.24, wpb=957.5, bsz=32, num_updates=31620, lr=4.16436e-06, gnorm=16.67, clip=100, loss_scale=32, train_wall=42, gb_free=8.8, wall=122047
2023-05-22 03:52:08 - progress_bar.py[line:272] - INFO: epoch 019:    512 / 1732 loss=2.447, loss_v1=0, loss_v2=0, nll_loss=1.252, ntokens=1041.1, nsentences=32, sample_size=1041.1, sample_size_v1=0, sample_size_v2=0, ppl=2.38, wps=274, ups=0.26, wpb=1041.1, bsz=32, num_updates=31630, lr=4.16232e-06, gnorm=15.053, clip=100, loss_scale=32, train_wall=38, gb_free=7.9, wall=122085
2023-05-22 03:52:46 - progress_bar.py[line:272] - INFO: epoch 019:    522 / 1732 loss=2.397, loss_v1=0, loss_v2=0, nll_loss=1.197, ntokens=995.3, nsentences=32, sample_size=995.3, sample_size_v1=0, sample_size_v2=0, ppl=2.29, wps=261.7, ups=0.26, wpb=995.3, bsz=32, num_updates=31640, lr=4.16027e-06, gnorm=17.172, clip=100, loss_scale=32, train_wall=38, gb_free=8.9, wall=122123
2023-05-22 03:53:24 - progress_bar.py[line:272] - INFO: epoch 019:    532 / 1732 loss=2.421, loss_v1=0, loss_v2=0, nll_loss=1.226, ntokens=942.5, nsentences=32, sample_size=942.5, sample_size_v1=0, sample_size_v2=0, ppl=2.34, wps=248.6, ups=0.26, wpb=942.5, bsz=32, num_updates=31650, lr=4.15822e-06, gnorm=18.629, clip=100, loss_scale=32, train_wall=38, gb_free=9.2, wall=122161
2023-05-22 03:54:02 - progress_bar.py[line:272] - INFO: epoch 019:    542 / 1732 loss=2.43, loss_v1=0, loss_v2=0, nll_loss=1.235, ntokens=994, nsentences=32, sample_size=994, sample_size_v1=0, sample_size_v2=0, ppl=2.35, wps=261.6, ups=0.26, wpb=994, bsz=32, num_updates=31660, lr=4.15617e-06, gnorm=17.006, clip=100, loss_scale=32, train_wall=38, gb_free=8.2, wall=122199
2023-05-22 03:54:40 - progress_bar.py[line:272] - INFO: epoch 019:    552 / 1732 loss=2.448, loss_v1=0, loss_v2=0, nll_loss=1.253, ntokens=1035.9, nsentences=32, sample_size=1035.9, sample_size_v1=0, sample_size_v2=0, ppl=2.38, wps=271.3, ups=0.26, wpb=1035.9, bsz=32, num_updates=31670, lr=4.15413e-06, gnorm=15.159, clip=100, loss_scale=32, train_wall=38, gb_free=8.3, wall=122238
2023-05-22 03:55:18 - progress_bar.py[line:272] - INFO: epoch 019:    562 / 1732 loss=2.431, loss_v1=0, loss_v2=0, nll_loss=1.235, ntokens=1016.1, nsentences=32, sample_size=1016.1, sample_size_v1=0, sample_size_v2=0, ppl=2.35, wps=266.2, ups=0.26, wpb=1016.1, bsz=32, num_updates=31680, lr=4.15208e-06, gnorm=16.371, clip=100, loss_scale=32, train_wall=38, gb_free=9.2, wall=122276
2023-05-22 03:55:57 - progress_bar.py[line:272] - INFO: epoch 019:    572 / 1732 loss=2.453, loss_v1=0, loss_v2=0, nll_loss=1.26, ntokens=1005.3, nsentences=32, sample_size=1005.3, sample_size_v1=0, sample_size_v2=0, ppl=2.4, wps=264.2, ups=0.26, wpb=1005.3, bsz=32, num_updates=31690, lr=4.15003e-06, gnorm=18.93, clip=100, loss_scale=32, train_wall=38, gb_free=8.3, wall=122314
2023-05-22 03:56:35 - progress_bar.py[line:272] - INFO: epoch 019:    582 / 1732 loss=2.434, loss_v1=0, loss_v2=0, nll_loss=1.239, ntokens=1004.5, nsentences=32, sample_size=1004.5, sample_size_v1=0, sample_size_v2=0, ppl=2.36, wps=262.9, ups=0.26, wpb=1004.5, bsz=32, num_updates=31700, lr=4.14798e-06, gnorm=18.247, clip=100, loss_scale=32, train_wall=38, gb_free=8.3, wall=122352
2023-05-22 03:57:13 - progress_bar.py[line:272] - INFO: epoch 019:    592 / 1732 loss=2.406, loss_v1=0, loss_v2=0, nll_loss=1.207, ntokens=950.1, nsentences=32, sample_size=950.1, sample_size_v1=0, sample_size_v2=0, ppl=2.31, wps=247.8, ups=0.26, wpb=950.1, bsz=32, num_updates=31710, lr=4.14594e-06, gnorm=17.731, clip=100, loss_scale=32, train_wall=38, gb_free=8.2, wall=122390
2023-05-22 03:57:51 - progress_bar.py[line:272] - INFO: epoch 019:    602 / 1732 loss=2.392, loss_v1=0, loss_v2=0, nll_loss=1.192, ntokens=920.7, nsentences=32, sample_size=920.7, sample_size_v1=0, sample_size_v2=0, ppl=2.29, wps=244.3, ups=0.27, wpb=920.7, bsz=32, num_updates=31720, lr=4.14389e-06, gnorm=18.198, clip=100, loss_scale=32, train_wall=38, gb_free=9.1, wall=122428
2023-05-22 03:58:29 - progress_bar.py[line:272] - INFO: epoch 019:    612 / 1732 loss=2.419, loss_v1=0, loss_v2=0, nll_loss=1.223, ntokens=908, nsentences=32, sample_size=908, sample_size_v1=0, sample_size_v2=0, ppl=2.34, wps=240, ups=0.26, wpb=908, bsz=32, num_updates=31730, lr=4.14184e-06, gnorm=19.677, clip=100, loss_scale=32, train_wall=38, gb_free=8.9, wall=122466
2023-05-22 03:59:06 - progress_bar.py[line:272] - INFO: epoch 019:    622 / 1732 loss=2.45, loss_v1=0, loss_v2=0, nll_loss=1.257, ntokens=856.3, nsentences=32, sample_size=856.3, sample_size_v1=0, sample_size_v2=0, ppl=2.39, wps=228.2, ups=0.27, wpb=856.3, bsz=32, num_updates=31740, lr=4.13979e-06, gnorm=20.474, clip=100, loss_scale=32, train_wall=37, gb_free=8.6, wall=122503
2023-05-22 03:59:44 - progress_bar.py[line:272] - INFO: epoch 019:    632 / 1732 loss=2.424, loss_v1=0, loss_v2=0, nll_loss=1.228, ntokens=935.9, nsentences=32, sample_size=935.9, sample_size_v1=0, sample_size_v2=0, ppl=2.34, wps=248.3, ups=0.27, wpb=935.9, bsz=32, num_updates=31750, lr=4.13775e-06, gnorm=19.557, clip=100, loss_scale=32, train_wall=38, gb_free=8.9, wall=122541
2023-05-22 04:00:22 - progress_bar.py[line:272] - INFO: epoch 019:    642 / 1732 loss=2.434, loss_v1=0, loss_v2=0, nll_loss=1.239, ntokens=946.6, nsentences=32, sample_size=946.6, sample_size_v1=0, sample_size_v2=0, ppl=2.36, wps=251.1, ups=0.27, wpb=946.6, bsz=32, num_updates=31760, lr=4.1357e-06, gnorm=18.144, clip=100, loss_scale=32, train_wall=38, gb_free=8.4, wall=122579
2023-05-22 04:00:59 - progress_bar.py[line:272] - INFO: epoch 019:    652 / 1732 loss=2.435, loss_v1=0, loss_v2=0, nll_loss=1.24, ntokens=952.7, nsentences=32, sample_size=952.7, sample_size_v1=0, sample_size_v2=0, ppl=2.36, wps=253.8, ups=0.27, wpb=952.7, bsz=32, num_updates=31770, lr=4.13365e-06, gnorm=17.768, clip=100, loss_scale=32, train_wall=37, gb_free=9.5, wall=122616
2023-05-22 04:01:37 - progress_bar.py[line:272] - INFO: epoch 019:    662 / 1732 loss=2.433, loss_v1=0, loss_v2=0, nll_loss=1.238, ntokens=882.3, nsentences=32, sample_size=882.3, sample_size_v1=0, sample_size_v2=0, ppl=2.36, wps=235.5, ups=0.27, wpb=882.3, bsz=32, num_updates=31780, lr=4.13161e-06, gnorm=18.322, clip=100, loss_scale=32, train_wall=37, gb_free=7.8, wall=122654
2023-05-22 04:02:14 - progress_bar.py[line:272] - INFO: epoch 019:    672 / 1732 loss=2.452, loss_v1=0, loss_v2=0, nll_loss=1.26, ntokens=943.8, nsentences=32, sample_size=943.8, sample_size_v1=0, sample_size_v2=0, ppl=2.39, wps=249.6, ups=0.26, wpb=943.8, bsz=32, num_updates=31790, lr=4.12956e-06, gnorm=19.108, clip=100, loss_scale=32, train_wall=38, gb_free=8.9, wall=122692
2023-05-22 04:02:52 - progress_bar.py[line:272] - INFO: epoch 019:    682 / 1732 loss=2.42, loss_v1=0, loss_v2=0, nll_loss=1.223, ntokens=981.8, nsentences=32, sample_size=981.8, sample_size_v1=0, sample_size_v2=0, ppl=2.33, wps=258.3, ups=0.26, wpb=981.8, bsz=32, num_updates=31800, lr=4.12751e-06, gnorm=16.895, clip=100, loss_scale=32, train_wall=38, gb_free=8.9, wall=122730
2023-05-22 04:03:31 - progress_bar.py[line:272] - INFO: epoch 019:    692 / 1732 loss=2.444, loss_v1=0, loss_v2=0, nll_loss=1.248, ntokens=939.1, nsentences=32, sample_size=939.1, sample_size_v1=0, sample_size_v2=0, ppl=2.38, wps=246.4, ups=0.26, wpb=939.1, bsz=32, num_updates=31810, lr=4.12546e-06, gnorm=18.803, clip=100, loss_scale=32, train_wall=38, gb_free=9.2, wall=122768
2023-05-22 04:04:09 - progress_bar.py[line:272] - INFO: epoch 019:    702 / 1732 loss=2.403, loss_v1=0, loss_v2=0, nll_loss=1.203, ntokens=974.5, nsentences=32, sample_size=974.5, sample_size_v1=0, sample_size_v2=0, ppl=2.3, wps=255.3, ups=0.26, wpb=974.5, bsz=32, num_updates=31820, lr=4.12342e-06, gnorm=16.28, clip=100, loss_scale=32, train_wall=38, gb_free=8.8, wall=122806
2023-05-22 04:04:47 - progress_bar.py[line:272] - INFO: epoch 019:    712 / 1732 loss=2.442, loss_v1=0, loss_v2=0, nll_loss=1.247, ntokens=913.9, nsentences=32, sample_size=913.9, sample_size_v1=0, sample_size_v2=0, ppl=2.37, wps=241.1, ups=0.26, wpb=913.9, bsz=32, num_updates=31830, lr=4.12137e-06, gnorm=18.863, clip=100, loss_scale=32, train_wall=38, gb_free=9.2, wall=122844
2023-05-22 04:05:24 - progress_bar.py[line:272] - INFO: epoch 019:    722 / 1732 loss=2.407, loss_v1=0, loss_v2=0, nll_loss=1.208, ntokens=864.8, nsentences=32, sample_size=864.8, sample_size_v1=0, sample_size_v2=0, ppl=2.31, wps=229, ups=0.26, wpb=864.8, bsz=32, num_updates=31840, lr=4.11932e-06, gnorm=18.288, clip=100, loss_scale=32, train_wall=38, gb_free=8.8, wall=122882
2023-05-22 04:06:02 - progress_bar.py[line:272] - INFO: epoch 019:    732 / 1732 loss=2.4, loss_v1=0, loss_v2=0, nll_loss=1.201, ntokens=937.9, nsentences=32, sample_size=937.9, sample_size_v1=0, sample_size_v2=0, ppl=2.3, wps=247.3, ups=0.26, wpb=937.9, bsz=32, num_updates=31850, lr=4.11727e-06, gnorm=17.356, clip=100, loss_scale=32, train_wall=38, gb_free=8.3, wall=122919
2023-05-22 04:06:40 - progress_bar.py[line:272] - INFO: epoch 019:    742 / 1732 loss=2.403, loss_v1=0, loss_v2=0, nll_loss=1.204, ntokens=1015.7, nsentences=32, sample_size=1015.7, sample_size_v1=0, sample_size_v2=0, ppl=2.3, wps=265.8, ups=0.26, wpb=1015.7, bsz=32, num_updates=31860, lr=4.11523e-06, gnorm=17.04, clip=100, loss_scale=32, train_wall=38, gb_free=8.7, wall=122958
2023-05-22 04:07:19 - progress_bar.py[line:272] - INFO: epoch 019:    752 / 1732 loss=2.416, loss_v1=0, loss_v2=0, nll_loss=1.219, ntokens=960.1, nsentences=32, sample_size=960.1, sample_size_v1=0, sample_size_v2=0, ppl=2.33, wps=252.6, ups=0.26, wpb=960.1, bsz=32, num_updates=31870, lr=4.11318e-06, gnorm=17.362, clip=100, loss_scale=32, train_wall=38, gb_free=9, wall=122996
2023-05-22 04:07:56 - progress_bar.py[line:272] - INFO: epoch 019:    762 / 1732 loss=2.403, loss_v1=0, loss_v2=0, nll_loss=1.205, ntokens=973.7, nsentences=32, sample_size=973.7, sample_size_v1=0, sample_size_v2=0, ppl=2.31, wps=257.3, ups=0.26, wpb=973.7, bsz=32, num_updates=31880, lr=4.11113e-06, gnorm=16.051, clip=100, loss_scale=32, train_wall=38, gb_free=9.1, wall=123034
2023-05-22 04:08:34 - progress_bar.py[line:272] - INFO: epoch 019:    772 / 1732 loss=2.408, loss_v1=0, loss_v2=0, nll_loss=1.213, ntokens=955.8, nsentences=32, sample_size=955.8, sample_size_v1=0, sample_size_v2=0, ppl=2.32, wps=251.7, ups=0.26, wpb=955.8, bsz=32, num_updates=31890, lr=4.10908e-06, gnorm=19.477, clip=100, loss_scale=32, train_wall=38, gb_free=7.4, wall=123072
2023-05-22 04:09:12 - progress_bar.py[line:272] - INFO: epoch 019:    782 / 1732 loss=2.42, loss_v1=0, loss_v2=0, nll_loss=1.224, ntokens=1024.5, nsentences=32, sample_size=1024.5, sample_size_v1=0, sample_size_v2=0, ppl=2.34, wps=268.7, ups=0.26, wpb=1024.5, bsz=32, num_updates=31900, lr=4.10704e-06, gnorm=16.568, clip=100, loss_scale=32, train_wall=38, gb_free=8.9, wall=123110
2023-05-22 04:09:51 - progress_bar.py[line:272] - INFO: epoch 019:    792 / 1732 loss=2.419, loss_v1=0, loss_v2=0, nll_loss=1.222, ntokens=1023.9, nsentences=32, sample_size=1023.9, sample_size_v1=0, sample_size_v2=0, ppl=2.33, wps=269.2, ups=0.26, wpb=1023.9, bsz=32, num_updates=31910, lr=4.10499e-06, gnorm=16.425, clip=100, loss_scale=32, train_wall=38, gb_free=9.3, wall=123148
2023-05-22 04:10:28 - progress_bar.py[line:272] - INFO: epoch 019:    802 / 1732 loss=2.407, loss_v1=0, loss_v2=0, nll_loss=1.208, ntokens=971.6, nsentences=32, sample_size=971.6, sample_size_v1=0, sample_size_v2=0, ppl=2.31, wps=256.9, ups=0.26, wpb=971.6, bsz=32, num_updates=31920, lr=4.10294e-06, gnorm=17.995, clip=100, loss_scale=32, train_wall=38, gb_free=9, wall=123186
2023-05-22 04:11:06 - progress_bar.py[line:272] - INFO: epoch 019:    812 / 1732 loss=2.429, loss_v1=0, loss_v2=0, nll_loss=1.233, ntokens=942.1, nsentences=32, sample_size=942.1, sample_size_v1=0, sample_size_v2=0, ppl=2.35, wps=247.7, ups=0.26, wpb=942.1, bsz=32, num_updates=31930, lr=4.10089e-06, gnorm=19.512, clip=100, loss_scale=32, train_wall=38, gb_free=8.8, wall=123224
2023-05-22 04:11:44 - progress_bar.py[line:272] - INFO: epoch 019:    822 / 1732 loss=2.409, loss_v1=0, loss_v2=0, nll_loss=1.211, ntokens=921.5, nsentences=32, sample_size=921.5, sample_size_v1=0, sample_size_v2=0, ppl=2.31, wps=243.4, ups=0.26, wpb=921.5, bsz=32, num_updates=31940, lr=4.09885e-06, gnorm=18.583, clip=100, loss_scale=32, train_wall=38, gb_free=8.5, wall=123261
2023-05-22 04:12:22 - progress_bar.py[line:272] - INFO: epoch 019:    832 / 1732 loss=2.421, loss_v1=0, loss_v2=0, nll_loss=1.224, ntokens=907.9, nsentences=32, sample_size=907.9, sample_size_v1=0, sample_size_v2=0, ppl=2.34, wps=241.6, ups=0.27, wpb=907.9, bsz=32, num_updates=31950, lr=4.0968e-06, gnorm=17.152, clip=100, loss_scale=32, train_wall=38, gb_free=9.1, wall=123299
2023-05-22 04:12:59 - progress_bar.py[line:272] - INFO: epoch 019:    842 / 1732 loss=2.397, loss_v1=0, loss_v2=0, nll_loss=1.196, ntokens=950.4, nsentences=32, sample_size=950.4, sample_size_v1=0, sample_size_v2=0, ppl=2.29, wps=252.6, ups=0.27, wpb=950.4, bsz=32, num_updates=31960, lr=4.09475e-06, gnorm=17.55, clip=100, loss_scale=32, train_wall=38, gb_free=8.6, wall=123337
2023-05-22 04:13:37 - progress_bar.py[line:272] - INFO: epoch 019:    852 / 1732 loss=2.42, loss_v1=0, loss_v2=0, nll_loss=1.223, ntokens=997.8, nsentences=32, sample_size=997.8, sample_size_v1=0, sample_size_v2=0, ppl=2.33, wps=264, ups=0.26, wpb=997.8, bsz=32, num_updates=31970, lr=4.09271e-06, gnorm=17.407, clip=100, loss_scale=32, train_wall=38, gb_free=9, wall=123374
2023-05-22 04:14:15 - progress_bar.py[line:272] - INFO: epoch 019:    862 / 1732 loss=2.402, loss_v1=0, loss_v2=0, nll_loss=1.202, ntokens=931.8, nsentences=32, sample_size=931.8, sample_size_v1=0, sample_size_v2=0, ppl=2.3, wps=247.3, ups=0.27, wpb=931.8, bsz=32, num_updates=31980, lr=4.09066e-06, gnorm=17.846, clip=100, loss_scale=32, train_wall=38, gb_free=8, wall=123412
2023-05-22 04:14:53 - progress_bar.py[line:272] - INFO: epoch 019:    872 / 1732 loss=2.407, loss_v1=0, loss_v2=0, nll_loss=1.208, ntokens=965, nsentences=32, sample_size=965, sample_size_v1=0, sample_size_v2=0, ppl=2.31, wps=255.4, ups=0.26, wpb=965, bsz=32, num_updates=31990, lr=4.08861e-06, gnorm=16.251, clip=100, loss_scale=32, train_wall=38, gb_free=8.8, wall=123450
2023-05-22 04:15:31 - progress_bar.py[line:272] - INFO: epoch 019:    882 / 1732 loss=2.355, loss_v1=0, loss_v2=0, nll_loss=1.151, ntokens=987.7, nsentences=32, sample_size=987.7, sample_size_v1=0, sample_size_v2=0, ppl=2.22, wps=257.9, ups=0.26, wpb=987.7, bsz=32, num_updates=32000, lr=4.08656e-06, gnorm=17.608, clip=100, loss_scale=32, train_wall=38, gb_free=8.6, wall=123488
2023-05-22 04:16:09 - progress_bar.py[line:272] - INFO: epoch 019:    892 / 1732 loss=2.356, loss_v1=0, loss_v2=0, nll_loss=1.153, ntokens=1003.5, nsentences=32, sample_size=1003.5, sample_size_v1=0, sample_size_v2=0, ppl=2.22, wps=262.3, ups=0.26, wpb=1003.5, bsz=32, num_updates=32010, lr=4.08452e-06, gnorm=15.759, clip=100, loss_scale=32, train_wall=38, gb_free=8.3, wall=123526
2023-05-22 04:16:47 - progress_bar.py[line:272] - INFO: epoch 019:    902 / 1732 loss=2.356, loss_v1=0, loss_v2=0, nll_loss=1.151, ntokens=1046.1, nsentences=32, sample_size=1046.1, sample_size_v1=0, sample_size_v2=0, ppl=2.22, wps=275.7, ups=0.26, wpb=1046.1, bsz=32, num_updates=32020, lr=4.08247e-06, gnorm=16.456, clip=100, loss_scale=32, train_wall=38, gb_free=8.5, wall=123564
2023-05-22 04:17:25 - progress_bar.py[line:272] - INFO: epoch 019:    912 / 1732 loss=2.421, loss_v1=0, loss_v2=0, nll_loss=1.225, ntokens=948.6, nsentences=32, sample_size=948.6, sample_size_v1=0, sample_size_v2=0, ppl=2.34, wps=249.8, ups=0.26, wpb=948.6, bsz=32, num_updates=32030, lr=4.08042e-06, gnorm=18.028, clip=100, loss_scale=32, train_wall=38, gb_free=8.2, wall=123602
2023-05-22 04:18:03 - progress_bar.py[line:272] - INFO: epoch 019:    922 / 1732 loss=2.393, loss_v1=0, loss_v2=0, nll_loss=1.193, ntokens=1004.6, nsentences=32, sample_size=1004.6, sample_size_v1=0, sample_size_v2=0, ppl=2.29, wps=263.4, ups=0.26, wpb=1004.6, bsz=32, num_updates=32040, lr=4.07837e-06, gnorm=16.985, clip=100, loss_scale=32, train_wall=38, gb_free=8.5, wall=123641
2023-05-22 04:18:42 - progress_bar.py[line:272] - INFO: epoch 019:    932 / 1732 loss=2.385, loss_v1=0, loss_v2=0, nll_loss=1.183, ntokens=1036.8, nsentences=32, sample_size=1036.8, sample_size_v1=0, sample_size_v2=0, ppl=2.27, wps=270.1, ups=0.26, wpb=1036.8, bsz=32, num_updates=32050, lr=4.07633e-06, gnorm=16.715, clip=100, loss_scale=32, train_wall=38, gb_free=8.1, wall=123679
2023-05-22 04:19:20 - progress_bar.py[line:272] - INFO: epoch 019:    942 / 1732 loss=2.388, loss_v1=0, loss_v2=0, nll_loss=1.186, ntokens=1063.3, nsentences=32, sample_size=1063.3, sample_size_v1=0, sample_size_v2=0, ppl=2.27, wps=276.7, ups=0.26, wpb=1063.3, bsz=32, num_updates=32060, lr=4.07428e-06, gnorm=15.643, clip=100, loss_scale=32, train_wall=38, gb_free=8.8, wall=123717
2023-05-22 04:19:59 - progress_bar.py[line:272] - INFO: epoch 019:    952 / 1732 loss=2.395, loss_v1=0, loss_v2=0, nll_loss=1.194, ntokens=1011.4, nsentences=32, sample_size=1011.4, sample_size_v1=0, sample_size_v2=0, ppl=2.29, wps=263.6, ups=0.26, wpb=1011.4, bsz=32, num_updates=32070, lr=4.07223e-06, gnorm=16.708, clip=100, loss_scale=32, train_wall=38, gb_free=8.8, wall=123756
2023-05-22 04:20:37 - progress_bar.py[line:272] - INFO: epoch 019:    962 / 1732 loss=2.385, loss_v1=0, loss_v2=0, nll_loss=1.184, ntokens=1071.4, nsentences=32, sample_size=1071.4, sample_size_v1=0, sample_size_v2=0, ppl=2.27, wps=277.7, ups=0.26, wpb=1071.4, bsz=32, num_updates=32080, lr=4.07018e-06, gnorm=16.954, clip=100, loss_scale=32, train_wall=39, gb_free=8.7, wall=123794
2023-05-22 04:21:16 - progress_bar.py[line:272] - INFO: epoch 019:    972 / 1732 loss=2.423, loss_v1=0, loss_v2=0, nll_loss=1.229, ntokens=1038.3, nsentences=32, sample_size=1038.3, sample_size_v1=0, sample_size_v2=0, ppl=2.34, wps=269.2, ups=0.26, wpb=1038.3, bsz=32, num_updates=32090, lr=4.06814e-06, gnorm=17.161, clip=100, loss_scale=32, train_wall=39, gb_free=8.2, wall=123833
2023-05-22 04:21:54 - progress_bar.py[line:272] - INFO: epoch 019:    982 / 1732 loss=2.389, loss_v1=0, loss_v2=0, nll_loss=1.191, ntokens=1035.4, nsentences=32, sample_size=1035.4, sample_size_v1=0, sample_size_v2=0, ppl=2.28, wps=268.8, ups=0.26, wpb=1035.4, bsz=32, num_updates=32100, lr=4.06609e-06, gnorm=16.654, clip=100, loss_scale=32, train_wall=38, gb_free=8.4, wall=123871
2023-05-22 04:22:33 - progress_bar.py[line:272] - INFO: epoch 019:    992 / 1732 loss=2.398, loss_v1=0, loss_v2=0, nll_loss=1.2, ntokens=1026.6, nsentences=32, sample_size=1026.6, sample_size_v1=0, sample_size_v2=0, ppl=2.3, wps=267, ups=0.26, wpb=1026.6, bsz=32, num_updates=32110, lr=4.06404e-06, gnorm=16.394, clip=100, loss_scale=32, train_wall=38, gb_free=8.6, wall=123910
2023-05-22 04:23:11 - progress_bar.py[line:272] - INFO: epoch 019:   1002 / 1732 loss=2.372, loss_v1=0, loss_v2=0, nll_loss=1.168, ntokens=1023.8, nsentences=32, sample_size=1023.8, sample_size_v1=0, sample_size_v2=0, ppl=2.25, wps=267.6, ups=0.26, wpb=1023.8, bsz=32, num_updates=32120, lr=4.06199e-06, gnorm=14.425, clip=100, loss_scale=32, train_wall=38, gb_free=8.2, wall=123948
2023-05-22 04:23:49 - progress_bar.py[line:272] - INFO: epoch 019:   1012 / 1732 loss=2.395, loss_v1=0, loss_v2=0, nll_loss=1.195, ntokens=987.2, nsentences=32, sample_size=987.2, sample_size_v1=0, sample_size_v2=0, ppl=2.29, wps=258.6, ups=0.26, wpb=987.2, bsz=32, num_updates=32130, lr=4.05995e-06, gnorm=16.593, clip=100, loss_scale=32, train_wall=38, gb_free=8.5, wall=123986
2023-05-22 04:24:12 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2023-05-22 04:24:31 - progress_bar.py[line:272] - INFO: epoch 019:   1023 / 1732 loss=2.376, loss_v1=0, loss_v2=0, nll_loss=1.174, ntokens=1065.9, nsentences=32, sample_size=1065.9, sample_size_v1=0, sample_size_v2=0, ppl=2.26, wps=251.8, ups=0.24, wpb=1065.9, bsz=32, num_updates=32140, lr=4.0579e-06, gnorm=15.357, clip=100, loss_scale=32, train_wall=42, gb_free=8.1, wall=124029
2023-05-22 04:25:10 - progress_bar.py[line:272] - INFO: epoch 019:   1033 / 1732 loss=2.382, loss_v1=0, loss_v2=0, nll_loss=1.182, ntokens=1100.3, nsentences=32, sample_size=1100.3, sample_size_v1=0, sample_size_v2=0, ppl=2.27, wps=283, ups=0.26, wpb=1100.3, bsz=32, num_updates=32150, lr=4.05585e-06, gnorm=15.265, clip=100, loss_scale=32, train_wall=39, gb_free=8.8, wall=124068
2023-05-22 04:25:49 - progress_bar.py[line:272] - INFO: epoch 019:   1043 / 1732 loss=2.39, loss_v1=0, loss_v2=0, nll_loss=1.192, ntokens=1068.2, nsentences=32, sample_size=1068.2, sample_size_v1=0, sample_size_v2=0, ppl=2.28, wps=276.6, ups=0.26, wpb=1068.2, bsz=32, num_updates=32160, lr=4.05381e-06, gnorm=16.751, clip=100, loss_scale=32, train_wall=39, gb_free=8.3, wall=124106
2023-05-22 04:26:27 - progress_bar.py[line:272] - INFO: epoch 019:   1053 / 1732 loss=2.392, loss_v1=0, loss_v2=0, nll_loss=1.192, ntokens=1062.8, nsentences=32, sample_size=1062.8, sample_size_v1=0, sample_size_v2=0, ppl=2.28, wps=276.3, ups=0.26, wpb=1062.8, bsz=32, num_updates=32170, lr=4.05176e-06, gnorm=16.203, clip=100, loss_scale=32, train_wall=38, gb_free=8.6, wall=124145
2023-05-22 04:27:06 - progress_bar.py[line:272] - INFO: epoch 019:   1063 / 1732 loss=2.384, loss_v1=0, loss_v2=0, nll_loss=1.182, ntokens=1030.9, nsentences=32, sample_size=1030.9, sample_size_v1=0, sample_size_v2=0, ppl=2.27, wps=266.8, ups=0.26, wpb=1030.9, bsz=32, num_updates=32180, lr=4.04971e-06, gnorm=18.011, clip=100, loss_scale=32, train_wall=39, gb_free=8.3, wall=124183
2023-05-22 04:27:45 - progress_bar.py[line:272] - INFO: epoch 019:   1073 / 1732 loss=2.407, loss_v1=0, loss_v2=0, nll_loss=1.208, ntokens=999.3, nsentences=32, sample_size=999.3, sample_size_v1=0, sample_size_v2=0, ppl=2.31, wps=258.3, ups=0.26, wpb=999.3, bsz=32, num_updates=32190, lr=4.04766e-06, gnorm=17.566, clip=100, loss_scale=32, train_wall=39, gb_free=8.5, wall=124222
2023-05-22 04:28:24 - progress_bar.py[line:272] - INFO: epoch 019:   1083 / 1732 loss=2.401, loss_v1=0, loss_v2=0, nll_loss=1.203, ntokens=1054.9, nsentences=32, sample_size=1054.9, sample_size_v1=0, sample_size_v2=0, ppl=2.3, wps=271.3, ups=0.26, wpb=1054.9, bsz=32, num_updates=32200, lr=4.04562e-06, gnorm=16.238, clip=100, loss_scale=32, train_wall=39, gb_free=7.6, wall=124261
2023-05-22 04:29:02 - progress_bar.py[line:272] - INFO: epoch 019:   1093 / 1732 loss=2.389, loss_v1=0, loss_v2=0, nll_loss=1.188, ntokens=1060.6, nsentences=32, sample_size=1060.6, sample_size_v1=0, sample_size_v2=0, ppl=2.28, wps=274.9, ups=0.26, wpb=1060.6, bsz=32, num_updates=32210, lr=4.04357e-06, gnorm=17.722, clip=100, loss_scale=32, train_wall=39, gb_free=8.3, wall=124299
2023-05-22 04:29:41 - progress_bar.py[line:272] - INFO: epoch 019:   1103 / 1732 loss=2.397, loss_v1=0, loss_v2=0, nll_loss=1.197, ntokens=1039.1, nsentences=32, sample_size=1039.1, sample_size_v1=0, sample_size_v2=0, ppl=2.29, wps=269.5, ups=0.26, wpb=1039.1, bsz=32, num_updates=32220, lr=4.04152e-06, gnorm=17.388, clip=100, loss_scale=32, train_wall=39, gb_free=8.9, wall=124338
2023-05-22 04:30:19 - progress_bar.py[line:272] - INFO: epoch 019:   1113 / 1732 loss=2.386, loss_v1=0, loss_v2=0, nll_loss=1.184, ntokens=1008.5, nsentences=32, sample_size=1008.5, sample_size_v1=0, sample_size_v2=0, ppl=2.27, wps=260.8, ups=0.26, wpb=1008.5, bsz=32, num_updates=32230, lr=4.03947e-06, gnorm=17.052, clip=100, loss_scale=32, train_wall=39, gb_free=8.5, wall=124377
2023-05-22 04:30:58 - progress_bar.py[line:272] - INFO: epoch 019:   1123 / 1732 loss=2.39, loss_v1=0, loss_v2=0, nll_loss=1.188, ntokens=976.6, nsentences=32, sample_size=976.6, sample_size_v1=0, sample_size_v2=0, ppl=2.28, wps=253.1, ups=0.26, wpb=976.6, bsz=32, num_updates=32240, lr=4.03743e-06, gnorm=17.73, clip=100, loss_scale=32, train_wall=39, gb_free=8.2, wall=124415
2023-05-22 04:31:37 - progress_bar.py[line:272] - INFO: epoch 019:   1133 / 1732 loss=2.401, loss_v1=0, loss_v2=0, nll_loss=1.201, ntokens=965.2, nsentences=32, sample_size=965.2, sample_size_v1=0, sample_size_v2=0, ppl=2.3, wps=250.3, ups=0.26, wpb=965.2, bsz=32, num_updates=32250, lr=4.03538e-06, gnorm=18.071, clip=100, loss_scale=32, train_wall=39, gb_free=7.7, wall=124454
2023-05-22 04:32:15 - progress_bar.py[line:272] - INFO: epoch 019:   1143 / 1732 loss=2.395, loss_v1=0, loss_v2=0, nll_loss=1.196, ntokens=1060.3, nsentences=32, sample_size=1060.3, sample_size_v1=0, sample_size_v2=0, ppl=2.29, wps=274.2, ups=0.26, wpb=1060.3, bsz=32, num_updates=32260, lr=4.03333e-06, gnorm=16.73, clip=100, loss_scale=32, train_wall=39, gb_free=7.9, wall=124492
2023-05-22 04:32:54 - progress_bar.py[line:272] - INFO: epoch 019:   1153 / 1732 loss=2.384, loss_v1=0, loss_v2=0, nll_loss=1.183, ntokens=1009.1, nsentences=32, sample_size=1009.1, sample_size_v1=0, sample_size_v2=0, ppl=2.27, wps=262.8, ups=0.26, wpb=1009.1, bsz=32, num_updates=32270, lr=4.03128e-06, gnorm=16.58, clip=100, loss_scale=32, train_wall=38, gb_free=8.9, wall=124531
2023-05-22 04:33:32 - progress_bar.py[line:272] - INFO: epoch 019:   1163 / 1732 loss=2.374, loss_v1=0, loss_v2=0, nll_loss=1.172, ntokens=999.2, nsentences=32, sample_size=999.2, sample_size_v1=0, sample_size_v2=0, ppl=2.25, wps=258.7, ups=0.26, wpb=999.2, bsz=32, num_updates=32280, lr=4.02924e-06, gnorm=18.577, clip=100, loss_scale=32, train_wall=39, gb_free=8.4, wall=124569
2023-05-22 04:34:11 - progress_bar.py[line:272] - INFO: epoch 019:   1173 / 1732 loss=2.38, loss_v1=0, loss_v2=0, nll_loss=1.179, ntokens=1077.2, nsentences=32, sample_size=1077.2, sample_size_v1=0, sample_size_v2=0, ppl=2.26, wps=279.4, ups=0.26, wpb=1077.2, bsz=32, num_updates=32290, lr=4.02719e-06, gnorm=16.452, clip=100, loss_scale=32, train_wall=39, gb_free=8.5, wall=124608
2023-05-22 04:34:49 - progress_bar.py[line:272] - INFO: epoch 019:   1183 / 1732 loss=2.372, loss_v1=0, loss_v2=0, nll_loss=1.169, ntokens=988.2, nsentences=32, sample_size=988.2, sample_size_v1=0, sample_size_v2=0, ppl=2.25, wps=257, ups=0.26, wpb=988.2, bsz=32, num_updates=32300, lr=4.02514e-06, gnorm=18.063, clip=100, loss_scale=32, train_wall=38, gb_free=8.3, wall=124646
2023-05-22 04:35:28 - progress_bar.py[line:272] - INFO: epoch 019:   1193 / 1732 loss=2.395, loss_v1=0, loss_v2=0, nll_loss=1.195, ntokens=1028.6, nsentences=32, sample_size=1028.6, sample_size_v1=0, sample_size_v2=0, ppl=2.29, wps=267.5, ups=0.26, wpb=1028.6, bsz=32, num_updates=32310, lr=4.02309e-06, gnorm=16.257, clip=100, loss_scale=32, train_wall=38, gb_free=8.5, wall=124685
2023-05-22 04:36:07 - progress_bar.py[line:272] - INFO: epoch 019:   1203 / 1732 loss=2.361, loss_v1=0, loss_v2=0, nll_loss=1.157, ntokens=1142.6, nsentences=32, sample_size=1142.6, sample_size_v1=0, sample_size_v2=0, ppl=2.23, wps=293.6, ups=0.26, wpb=1142.6, bsz=32, num_updates=32320, lr=4.02105e-06, gnorm=15.716, clip=100, loss_scale=32, train_wall=39, gb_free=7.4, wall=124724
2023-05-22 04:36:45 - progress_bar.py[line:272] - INFO: epoch 019:   1213 / 1732 loss=2.389, loss_v1=0, loss_v2=0, nll_loss=1.188, ntokens=1010.9, nsentences=32, sample_size=1010.9, sample_size_v1=0, sample_size_v2=0, ppl=2.28, wps=262.5, ups=0.26, wpb=1010.9, bsz=32, num_updates=32330, lr=4.019e-06, gnorm=17.093, clip=100, loss_scale=32, train_wall=38, gb_free=8.9, wall=124762
2023-05-22 04:37:24 - progress_bar.py[line:272] - INFO: epoch 019:   1223 / 1732 loss=2.415, loss_v1=0, loss_v2=0, nll_loss=1.217, ntokens=1033.2, nsentences=32, sample_size=1033.2, sample_size_v1=0, sample_size_v2=0, ppl=2.32, wps=269.2, ups=0.26, wpb=1033.2, bsz=32, num_updates=32340, lr=4.01695e-06, gnorm=18.363, clip=100, loss_scale=32, train_wall=38, gb_free=8.4, wall=124801
2023-05-22 04:38:02 - progress_bar.py[line:272] - INFO: epoch 019:   1233 / 1732 loss=2.375, loss_v1=0, loss_v2=0, nll_loss=1.171, ntokens=1038.6, nsentences=32, sample_size=1038.6, sample_size_v1=0, sample_size_v2=0, ppl=2.25, wps=270.9, ups=0.26, wpb=1038.6, bsz=32, num_updates=32350, lr=4.0149e-06, gnorm=15.535, clip=100, loss_scale=32, train_wall=38, gb_free=8.2, wall=124839
2023-05-22 04:38:40 - progress_bar.py[line:272] - INFO: epoch 019:   1243 / 1732 loss=2.336, loss_v1=0, loss_v2=0, nll_loss=1.129, ntokens=1063.3, nsentences=32, sample_size=1063.3, sample_size_v1=0, sample_size_v2=0, ppl=2.19, wps=276.3, ups=0.26, wpb=1063.3, bsz=32, num_updates=32360, lr=4.01286e-06, gnorm=15.899, clip=100, loss_scale=32, train_wall=38, gb_free=8.8, wall=124878
2023-05-22 04:39:19 - progress_bar.py[line:272] - INFO: epoch 019:   1253 / 1732 loss=2.349, loss_v1=0, loss_v2=0, nll_loss=1.143, ntokens=1098.7, nsentences=32, sample_size=1098.7, sample_size_v1=0, sample_size_v2=0, ppl=2.21, wps=284.7, ups=0.26, wpb=1098.7, bsz=32, num_updates=32370, lr=4.01081e-06, gnorm=15.25, clip=100, loss_scale=32, train_wall=39, gb_free=8.5, wall=124916
2023-05-22 04:39:58 - progress_bar.py[line:272] - INFO: epoch 019:   1263 / 1732 loss=2.387, loss_v1=0, loss_v2=0, nll_loss=1.185, ntokens=1070.8, nsentences=32, sample_size=1070.8, sample_size_v1=0, sample_size_v2=0, ppl=2.27, wps=277.6, ups=0.26, wpb=1070.8, bsz=32, num_updates=32380, lr=4.00876e-06, gnorm=17.078, clip=100, loss_scale=32, train_wall=39, gb_free=8.3, wall=124955
2023-05-22 04:40:36 - progress_bar.py[line:272] - INFO: epoch 019:   1273 / 1732 loss=2.402, loss_v1=0, loss_v2=0, nll_loss=1.203, ntokens=1005.1, nsentences=32, sample_size=1005.1, sample_size_v1=0, sample_size_v2=0, ppl=2.3, wps=260.9, ups=0.26, wpb=1005.1, bsz=32, num_updates=32390, lr=4.00672e-06, gnorm=19.35, clip=100, loss_scale=32, train_wall=38, gb_free=7.9, wall=124993
2023-05-22 04:41:15 - progress_bar.py[line:272] - INFO: epoch 019:   1283 / 1732 loss=2.374, loss_v1=0, loss_v2=0, nll_loss=1.173, ntokens=1101.8, nsentences=32, sample_size=1101.8, sample_size_v1=0, sample_size_v2=0, ppl=2.25, wps=282.9, ups=0.26, wpb=1101.8, bsz=32, num_updates=32400, lr=4.00467e-06, gnorm=15.841, clip=100, loss_scale=32, train_wall=39, gb_free=8.6, wall=125032
2023-05-22 04:41:54 - progress_bar.py[line:272] - INFO: epoch 019:   1293 / 1732 loss=2.368, loss_v1=0, loss_v2=0, nll_loss=1.165, ntokens=1084.4, nsentences=32, sample_size=1084.4, sample_size_v1=0, sample_size_v2=0, ppl=2.24, wps=281.2, ups=0.26, wpb=1084.4, bsz=32, num_updates=32410, lr=4.00262e-06, gnorm=15.447, clip=100, loss_scale=32, train_wall=39, gb_free=8.5, wall=125071
2023-05-22 04:42:32 - progress_bar.py[line:272] - INFO: epoch 019:   1303 / 1732 loss=2.385, loss_v1=0, loss_v2=0, nll_loss=1.184, ntokens=1102.4, nsentences=32, sample_size=1102.4, sample_size_v1=0, sample_size_v2=0, ppl=2.27, wps=284.9, ups=0.26, wpb=1102.4, bsz=32, num_updates=32420, lr=4.00057e-06, gnorm=15.815, clip=100, loss_scale=32, train_wall=39, gb_free=8, wall=125110
2023-05-22 04:43:11 - progress_bar.py[line:272] - INFO: epoch 019:   1313 / 1732 loss=2.409, loss_v1=0, loss_v2=0, nll_loss=1.21, ntokens=1055.3, nsentences=32, sample_size=1055.3, sample_size_v1=0, sample_size_v2=0, ppl=2.31, wps=271.3, ups=0.26, wpb=1055.3, bsz=32, num_updates=32430, lr=3.99853e-06, gnorm=15.647, clip=100, loss_scale=32, train_wall=39, gb_free=7.8, wall=125148
2023-05-22 04:43:50 - progress_bar.py[line:272] - INFO: epoch 019:   1323 / 1732 loss=2.363, loss_v1=0, loss_v2=0, nll_loss=1.158, ntokens=1103.3, nsentences=32, sample_size=1103.3, sample_size_v1=0, sample_size_v2=0, ppl=2.23, wps=282.5, ups=0.26, wpb=1103.3, bsz=32, num_updates=32440, lr=3.99648e-06, gnorm=15.57, clip=100, loss_scale=32, train_wall=39, gb_free=8.4, wall=125187
2023-05-22 04:44:29 - progress_bar.py[line:272] - INFO: epoch 019:   1333 / 1732 loss=2.359, loss_v1=0, loss_v2=0, nll_loss=1.155, ntokens=1100.8, nsentences=32, sample_size=1100.8, sample_size_v1=0, sample_size_v2=0, ppl=2.23, wps=280.7, ups=0.26, wpb=1100.8, bsz=32, num_updates=32450, lr=3.99443e-06, gnorm=18.362, clip=100, loss_scale=32, train_wall=39, gb_free=8.5, wall=125227
2023-05-22 04:45:09 - progress_bar.py[line:272] - INFO: epoch 019:   1343 / 1732 loss=2.366, loss_v1=0, loss_v2=0, nll_loss=1.164, ntokens=1190.4, nsentences=32, sample_size=1190.4, sample_size_v1=0, sample_size_v2=0, ppl=2.24, wps=304, ups=0.26, wpb=1190.4, bsz=32, num_updates=32460, lr=3.99238e-06, gnorm=17.402, clip=100, loss_scale=32, train_wall=39, gb_free=8.4, wall=125266
2023-05-22 04:45:48 - progress_bar.py[line:272] - INFO: epoch 019:   1353 / 1732 loss=2.377, loss_v1=0, loss_v2=0, nll_loss=1.177, ntokens=1120.7, nsentences=32, sample_size=1120.7, sample_size_v1=0, sample_size_v2=0, ppl=2.26, wps=287.7, ups=0.26, wpb=1120.7, bsz=32, num_updates=32470, lr=3.99034e-06, gnorm=17.527, clip=100, loss_scale=32, train_wall=39, gb_free=8.6, wall=125305
2023-05-22 04:46:27 - progress_bar.py[line:272] - INFO: epoch 019:   1363 / 1732 loss=2.343, loss_v1=0, loss_v2=0, nll_loss=1.136, ntokens=1088.2, nsentences=32, sample_size=1088.2, sample_size_v1=0, sample_size_v2=0, ppl=2.2, wps=278.4, ups=0.26, wpb=1088.2, bsz=32, num_updates=32480, lr=3.98829e-06, gnorm=16.969, clip=100, loss_scale=32, train_wall=39, gb_free=8.9, wall=125344
2023-05-22 04:47:05 - progress_bar.py[line:272] - INFO: epoch 019:   1373 / 1732 loss=2.391, loss_v1=0, loss_v2=0, nll_loss=1.19, ntokens=1114.2, nsentences=32, sample_size=1114.2, sample_size_v1=0, sample_size_v2=0, ppl=2.28, wps=288.1, ups=0.26, wpb=1114.2, bsz=32, num_updates=32490, lr=3.98624e-06, gnorm=15.673, clip=100, loss_scale=32, train_wall=39, gb_free=8.6, wall=125383
2023-05-22 04:47:44 - progress_bar.py[line:272] - INFO: epoch 019:   1383 / 1732 loss=2.388, loss_v1=0, loss_v2=0, nll_loss=1.188, ntokens=1148.9, nsentences=32, sample_size=1148.9, sample_size_v1=0, sample_size_v2=0, ppl=2.28, wps=297.9, ups=0.26, wpb=1148.9, bsz=32, num_updates=32500, lr=3.98419e-06, gnorm=16.826, clip=100, loss_scale=32, train_wall=39, gb_free=8.7, wall=125421
2023-05-22 04:48:22 - progress_bar.py[line:272] - INFO: epoch 019:   1393 / 1732 loss=2.381, loss_v1=0, loss_v2=0, nll_loss=1.181, ntokens=1033.6, nsentences=32, sample_size=1033.6, sample_size_v1=0, sample_size_v2=0, ppl=2.27, wps=269.7, ups=0.26, wpb=1033.6, bsz=32, num_updates=32510, lr=3.98215e-06, gnorm=16.696, clip=100, loss_scale=32, train_wall=38, gb_free=8.1, wall=125459
2023-05-22 04:49:01 - progress_bar.py[line:272] - INFO: epoch 019:   1403 / 1732 loss=2.361, loss_v1=0, loss_v2=0, nll_loss=1.156, ntokens=1148.6, nsentences=32, sample_size=1148.6, sample_size_v1=0, sample_size_v2=0, ppl=2.23, wps=296.1, ups=0.26, wpb=1148.6, bsz=32, num_updates=32520, lr=3.9801e-06, gnorm=16.984, clip=100, loss_scale=32, train_wall=39, gb_free=8.7, wall=125498
2023-05-22 04:49:40 - progress_bar.py[line:272] - INFO: epoch 019:   1413 / 1732 loss=2.39, loss_v1=0, loss_v2=0, nll_loss=1.188, ntokens=1251.8, nsentences=32, sample_size=1251.8, sample_size_v1=0, sample_size_v2=0, ppl=2.28, wps=320.4, ups=0.26, wpb=1251.8, bsz=32, num_updates=32530, lr=3.97805e-06, gnorm=15.451, clip=100, loss_scale=32, train_wall=39, gb_free=8.3, wall=125537
2023-05-22 04:50:19 - progress_bar.py[line:272] - INFO: epoch 019:   1423 / 1732 loss=2.368, loss_v1=0, loss_v2=0, nll_loss=1.165, ntokens=1276.2, nsentences=32, sample_size=1276.2, sample_size_v1=0, sample_size_v2=0, ppl=2.24, wps=325, ups=0.25, wpb=1276.2, bsz=32, num_updates=32540, lr=3.976e-06, gnorm=14.78, clip=100, loss_scale=32, train_wall=39, gb_free=8.5, wall=125577
2023-05-22 04:50:58 - progress_bar.py[line:272] - INFO: epoch 019:   1433 / 1732 loss=2.355, loss_v1=0, loss_v2=0, nll_loss=1.149, ntokens=1210.9, nsentences=32, sample_size=1210.9, sample_size_v1=0, sample_size_v2=0, ppl=2.22, wps=311.4, ups=0.26, wpb=1210.9, bsz=32, num_updates=32550, lr=3.97396e-06, gnorm=15.297, clip=100, loss_scale=32, train_wall=39, gb_free=8.4, wall=125615
2023-05-22 04:51:37 - progress_bar.py[line:272] - INFO: epoch 019:   1443 / 1732 loss=2.377, loss_v1=0, loss_v2=0, nll_loss=1.176, ntokens=1130.8, nsentences=32, sample_size=1130.8, sample_size_v1=0, sample_size_v2=0, ppl=2.26, wps=291, ups=0.26, wpb=1130.8, bsz=32, num_updates=32560, lr=3.97191e-06, gnorm=15.621, clip=100, loss_scale=32, train_wall=39, gb_free=7.8, wall=125654
2023-05-22 04:52:16 - progress_bar.py[line:272] - INFO: epoch 019:   1453 / 1732 loss=2.396, loss_v1=0, loss_v2=0, nll_loss=1.196, ntokens=1116.6, nsentences=32, sample_size=1116.6, sample_size_v1=0, sample_size_v2=0, ppl=2.29, wps=288, ups=0.26, wpb=1116.6, bsz=32, num_updates=32570, lr=3.96986e-06, gnorm=15.958, clip=100, loss_scale=32, train_wall=39, gb_free=7.9, wall=125693
2023-05-22 04:52:55 - progress_bar.py[line:272] - INFO: epoch 019:   1463 / 1732 loss=2.34, loss_v1=0, loss_v2=0, nll_loss=1.134, ntokens=1191.9, nsentences=32, sample_size=1191.9, sample_size_v1=0, sample_size_v2=0, ppl=2.19, wps=305, ups=0.26, wpb=1191.9, bsz=32, num_updates=32580, lr=3.96782e-06, gnorm=15.009, clip=100, loss_scale=32, train_wall=39, gb_free=7.4, wall=125732
2023-05-22 04:53:34 - progress_bar.py[line:272] - INFO: epoch 019:   1473 / 1732 loss=2.363, loss_v1=0, loss_v2=0, nll_loss=1.159, ntokens=1103.1, nsentences=32, sample_size=1103.1, sample_size_v1=0, sample_size_v2=0, ppl=2.23, wps=284.2, ups=0.26, wpb=1103.1, bsz=32, num_updates=32590, lr=3.96577e-06, gnorm=17.098, clip=100, loss_scale=32, train_wall=39, gb_free=8.5, wall=125771
2023-05-22 04:54:12 - progress_bar.py[line:272] - INFO: epoch 019:   1483 / 1732 loss=2.401, loss_v1=0, loss_v2=0, nll_loss=1.202, ntokens=1083.9, nsentences=32, sample_size=1083.9, sample_size_v1=0, sample_size_v2=0, ppl=2.3, wps=280.8, ups=0.26, wpb=1083.9, bsz=32, num_updates=32600, lr=3.96372e-06, gnorm=18.283, clip=100, loss_scale=32, train_wall=39, gb_free=8.9, wall=125810
2023-05-22 04:54:51 - progress_bar.py[line:272] - INFO: epoch 019:   1493 / 1732 loss=2.366, loss_v1=0, loss_v2=0, nll_loss=1.162, ntokens=1119.2, nsentences=32, sample_size=1119.2, sample_size_v1=0, sample_size_v2=0, ppl=2.24, wps=287.7, ups=0.26, wpb=1119.2, bsz=32, num_updates=32610, lr=3.96167e-06, gnorm=15.904, clip=100, loss_scale=32, train_wall=39, gb_free=8.7, wall=125849
2023-05-22 04:55:30 - progress_bar.py[line:272] - INFO: epoch 019:   1503 / 1732 loss=2.325, loss_v1=0, loss_v2=0, nll_loss=1.118, ntokens=1138.8, nsentences=32, sample_size=1138.8, sample_size_v1=0, sample_size_v2=0, ppl=2.17, wps=294, ups=0.26, wpb=1138.8, bsz=32, num_updates=32620, lr=3.95963e-06, gnorm=14.537, clip=100, loss_scale=32, train_wall=39, gb_free=8.8, wall=125887
2023-05-22 04:56:08 - progress_bar.py[line:272] - INFO: epoch 019:   1513 / 1732 loss=2.365, loss_v1=0, loss_v2=0, nll_loss=1.163, ntokens=1063.2, nsentences=32, sample_size=1063.2, sample_size_v1=0, sample_size_v2=0, ppl=2.24, wps=277, ups=0.26, wpb=1063.2, bsz=32, num_updates=32630, lr=3.95758e-06, gnorm=17.509, clip=100, loss_scale=32, train_wall=38, gb_free=8.4, wall=125926
2023-05-22 04:56:47 - progress_bar.py[line:272] - INFO: epoch 019:   1523 / 1732 loss=2.422, loss_v1=0, loss_v2=0, nll_loss=1.226, ntokens=1020.5, nsentences=32, sample_size=1020.5, sample_size_v1=0, sample_size_v2=0, ppl=2.34, wps=266, ups=0.26, wpb=1020.5, bsz=32, num_updates=32640, lr=3.95553e-06, gnorm=17.03, clip=100, loss_scale=32, train_wall=38, gb_free=8.4, wall=125964
2023-05-22 04:57:26 - progress_bar.py[line:272] - INFO: epoch 019:   1533 / 1732 loss=2.38, loss_v1=0, loss_v2=0, nll_loss=1.178, ntokens=1081, nsentences=32, sample_size=1081, sample_size_v1=0, sample_size_v2=0, ppl=2.26, wps=278.6, ups=0.26, wpb=1081, bsz=32, num_updates=32650, lr=3.95348e-06, gnorm=15.601, clip=100, loss_scale=64, train_wall=39, gb_free=8.1, wall=126003
2023-05-22 04:57:45 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2023-05-22 04:58:08 - progress_bar.py[line:272] - INFO: epoch 019:   1544 / 1732 loss=2.36, loss_v1=0, loss_v2=0, nll_loss=1.155, ntokens=1095.9, nsentences=32, sample_size=1095.9, sample_size_v1=0, sample_size_v2=0, ppl=2.23, wps=258.2, ups=0.24, wpb=1095.9, bsz=32, num_updates=32660, lr=3.95144e-06, gnorm=16.351, clip=100, loss_scale=32, train_wall=42, gb_free=8.7, wall=126045
2023-05-22 04:58:46 - progress_bar.py[line:272] - INFO: epoch 019:   1554 / 1732 loss=2.359, loss_v1=0, loss_v2=0, nll_loss=1.154, ntokens=1040, nsentences=32, sample_size=1040, sample_size_v1=0, sample_size_v2=0, ppl=2.23, wps=270.8, ups=0.26, wpb=1040, bsz=32, num_updates=32670, lr=3.94939e-06, gnorm=15.4, clip=100, loss_scale=32, train_wall=38, gb_free=8.7, wall=126084
2023-05-22 04:59:25 - progress_bar.py[line:272] - INFO: epoch 019:   1564 / 1732 loss=2.395, loss_v1=0, loss_v2=0, nll_loss=1.195, ntokens=1120.2, nsentences=32, sample_size=1120.2, sample_size_v1=0, sample_size_v2=0, ppl=2.29, wps=289.4, ups=0.26, wpb=1120.2, bsz=32, num_updates=32680, lr=3.94734e-06, gnorm=15.247, clip=100, loss_scale=32, train_wall=39, gb_free=8.8, wall=126122
2023-05-22 05:00:04 - progress_bar.py[line:272] - INFO: epoch 019:   1574 / 1732 loss=2.406, loss_v1=0, loss_v2=0, nll_loss=1.207, ntokens=1055.9, nsentences=32, sample_size=1055.9, sample_size_v1=0, sample_size_v2=0, ppl=2.31, wps=273.1, ups=0.26, wpb=1055.9, bsz=32, num_updates=32690, lr=3.94529e-06, gnorm=17.436, clip=100, loss_scale=32, train_wall=39, gb_free=8.3, wall=126161
2023-05-22 05:00:42 - progress_bar.py[line:272] - INFO: epoch 019:   1584 / 1732 loss=2.401, loss_v1=0, loss_v2=0, nll_loss=1.2, ntokens=1026.8, nsentences=32, sample_size=1026.8, sample_size_v1=0, sample_size_v2=0, ppl=2.3, wps=266.3, ups=0.26, wpb=1026.8, bsz=32, num_updates=32700, lr=3.94325e-06, gnorm=17.336, clip=100, loss_scale=32, train_wall=39, gb_free=7.9, wall=126200
2023-05-22 05:01:21 - progress_bar.py[line:272] - INFO: epoch 019:   1594 / 1732 loss=2.357, loss_v1=0, loss_v2=0, nll_loss=1.152, ntokens=1068.7, nsentences=32, sample_size=1068.7, sample_size_v1=0, sample_size_v2=0, ppl=2.22, wps=276.7, ups=0.26, wpb=1068.7, bsz=32, num_updates=32710, lr=3.9412e-06, gnorm=15.79, clip=100, loss_scale=32, train_wall=39, gb_free=8.4, wall=126238
2023-05-22 05:02:00 - progress_bar.py[line:272] - INFO: epoch 019:   1604 / 1732 loss=2.354, loss_v1=0, loss_v2=0, nll_loss=1.15, ntokens=1089, nsentences=32, sample_size=1089, sample_size_v1=0, sample_size_v2=0, ppl=2.22, wps=281.5, ups=0.26, wpb=1089, bsz=32, num_updates=32720, lr=3.93915e-06, gnorm=16.605, clip=100, loss_scale=32, train_wall=39, gb_free=7.9, wall=126277
2023-05-22 05:02:39 - progress_bar.py[line:272] - INFO: epoch 019:   1614 / 1732 loss=2.333, loss_v1=0, loss_v2=0, nll_loss=1.128, ntokens=1186.1, nsentences=32, sample_size=1186.1, sample_size_v1=0, sample_size_v2=0, ppl=2.19, wps=302.6, ups=0.26, wpb=1186.1, bsz=32, num_updates=32730, lr=3.9371e-06, gnorm=15.095, clip=100, loss_scale=32, train_wall=39, gb_free=8, wall=126316
2023-05-22 05:03:18 - progress_bar.py[line:272] - INFO: epoch 019:   1624 / 1732 loss=2.368, loss_v1=0, loss_v2=0, nll_loss=1.166, ntokens=1074.1, nsentences=32, sample_size=1074.1, sample_size_v1=0, sample_size_v2=0, ppl=2.24, wps=275.8, ups=0.26, wpb=1074.1, bsz=32, num_updates=32740, lr=3.93506e-06, gnorm=17.244, clip=100, loss_scale=32, train_wall=39, gb_free=8.7, wall=126355
2023-05-22 05:03:57 - progress_bar.py[line:272] - INFO: epoch 019:   1634 / 1732 loss=2.348, loss_v1=0, loss_v2=0, nll_loss=1.142, ntokens=1178.9, nsentences=32, sample_size=1178.9, sample_size_v1=0, sample_size_v2=0, ppl=2.21, wps=304.2, ups=0.26, wpb=1178.9, bsz=32, num_updates=32750, lr=3.93301e-06, gnorm=16.092, clip=100, loss_scale=32, train_wall=39, gb_free=8.7, wall=126394
2023-05-22 05:04:36 - progress_bar.py[line:272] - INFO: epoch 019:   1644 / 1732 loss=2.327, loss_v1=0, loss_v2=0, nll_loss=1.118, ntokens=1265.1, nsentences=32, sample_size=1265.1, sample_size_v1=0, sample_size_v2=0, ppl=2.17, wps=323.9, ups=0.26, wpb=1265.1, bsz=32, num_updates=32760, lr=3.93096e-06, gnorm=14.395, clip=100, loss_scale=32, train_wall=39, gb_free=8, wall=126433
2023-05-22 05:05:14 - progress_bar.py[line:272] - INFO: epoch 019:   1654 / 1732 loss=2.387, loss_v1=0, loss_v2=0, nll_loss=1.186, ntokens=974.9, nsentences=32, sample_size=974.9, sample_size_v1=0, sample_size_v2=0, ppl=2.28, wps=254, ups=0.26, wpb=974.9, bsz=32, num_updates=32770, lr=3.92892e-06, gnorm=17.064, clip=100, loss_scale=32, train_wall=38, gb_free=8.6, wall=126471
2023-05-22 05:05:53 - progress_bar.py[line:272] - INFO: epoch 019:   1664 / 1732 loss=2.382, loss_v1=0, loss_v2=0, nll_loss=1.181, ntokens=1041.8, nsentences=32, sample_size=1041.8, sample_size_v1=0, sample_size_v2=0, ppl=2.27, wps=270, ups=0.26, wpb=1041.8, bsz=32, num_updates=32780, lr=3.92687e-06, gnorm=15.819, clip=100, loss_scale=32, train_wall=39, gb_free=8.3, wall=126510
2023-05-22 05:06:31 - progress_bar.py[line:272] - INFO: epoch 019:   1674 / 1732 loss=2.337, loss_v1=0, loss_v2=0, nll_loss=1.13, ntokens=1052.3, nsentences=32, sample_size=1052.3, sample_size_v1=0, sample_size_v2=0, ppl=2.19, wps=274.2, ups=0.26, wpb=1052.3, bsz=32, num_updates=32790, lr=3.92482e-06, gnorm=16.012, clip=100, loss_scale=32, train_wall=38, gb_free=8.1, wall=126548
2023-05-22 05:07:10 - progress_bar.py[line:272] - INFO: epoch 019:   1684 / 1732 loss=2.317, loss_v1=0, loss_v2=0, nll_loss=1.108, ntokens=1169.1, nsentences=32, sample_size=1169.1, sample_size_v1=0, sample_size_v2=0, ppl=2.16, wps=300.4, ups=0.26, wpb=1169.1, bsz=32, num_updates=32800, lr=3.92277e-06, gnorm=15.161, clip=100, loss_scale=32, train_wall=39, gb_free=8.8, wall=126587
2023-05-22 05:07:49 - progress_bar.py[line:272] - INFO: epoch 019:   1694 / 1732 loss=2.35, loss_v1=0, loss_v2=0, nll_loss=1.144, ntokens=1257.3, nsentences=32, sample_size=1257.3, sample_size_v1=0, sample_size_v2=0, ppl=2.21, wps=319.3, ups=0.25, wpb=1257.3, bsz=32, num_updates=32810, lr=3.92073e-06, gnorm=15.086, clip=100, loss_scale=32, train_wall=39, gb_free=7, wall=126627
2023-05-22 05:08:28 - progress_bar.py[line:272] - INFO: epoch 019:   1704 / 1732 loss=2.357, loss_v1=0, loss_v2=0, nll_loss=1.154, ntokens=1232.6, nsentences=32, sample_size=1232.6, sample_size_v1=0, sample_size_v2=0, ppl=2.23, wps=315.3, ups=0.26, wpb=1232.6, bsz=32, num_updates=32820, lr=3.91868e-06, gnorm=14.999, clip=100, loss_scale=32, train_wall=39, gb_free=8.4, wall=126666
2023-05-22 05:09:07 - progress_bar.py[line:272] - INFO: epoch 019:   1714 / 1732 loss=2.362, loss_v1=0, loss_v2=0, nll_loss=1.158, ntokens=1181.2, nsentences=32, sample_size=1181.2, sample_size_v1=0, sample_size_v2=0, ppl=2.23, wps=303, ups=0.26, wpb=1181.2, bsz=32, num_updates=32830, lr=3.91663e-06, gnorm=14.721, clip=100, loss_scale=32, train_wall=39, gb_free=8.3, wall=126705
2023-05-22 05:09:47 - progress_bar.py[line:272] - INFO: epoch 019:   1724 / 1732 loss=2.365, loss_v1=0, loss_v2=0, nll_loss=1.163, ntokens=1135.1, nsentences=32, sample_size=1135.1, sample_size_v1=0, sample_size_v2=0, ppl=2.24, wps=290.4, ups=0.26, wpb=1135.1, bsz=32, num_updates=32840, lr=3.91458e-06, gnorm=15.456, clip=100, loss_scale=32, train_wall=39, gb_free=8.6, wall=126744
2023-05-22 05:10:15 - train.py[line:332] - INFO: end of epoch 19 (average epoch stats below)
2023-05-22 05:10:15 - progress_bar.py[line:282] - INFO: epoch 019 | loss 2.375 | loss_v1 0 | loss_v2 0 | nll_loss 1.173 | ntokens 1051.59 | nsentences 31.986 | sample_size 1051.59 | sample_size_v1 0 | sample_size_v2 0 | ppl 2.25 | wps 272.8 | ups 0.26 | wpb 1051.6 | bsz 32 | num_updates 32848 | lr 3.91295e-06 | gnorm 16.406 | clip 100 | loss_scale 32 | train_wall 6655 | gb_free 8.9 | wall 126772
2023-05-22 05:10:15 - trainer.py[line:639] - INFO: loading train data for epoch 20
local datafile ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 0 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 0 finished initializing row_count and line_idx-to-offset mapping
file ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 0 row count 55400 total row count 55400
slice_id 0 seek offset 0
2023-05-22 05:10:16 - trainer.py[line:703] - INFO: begin training epoch 20
2023-05-22 05:10:16 - train.py[line:305] - INFO: Start iterating over samples
2023-05-22 05:10:25 - progress_bar.py[line:272] - INFO: epoch 020:      2 / 1732 loss=2.409, loss_v1=0, loss_v2=0, nll_loss=1.212, ntokens=1104.4, nsentences=29.6, sample_size=1104.4, sample_size_v1=0, sample_size_v2=0, ppl=2.32, wps=290.7, ups=0.26, wpb=1104.4, bsz=29.6, num_updates=32850, lr=3.91254e-06, gnorm=17.341, clip=100, loss_scale=32, train_wall=36, gb_free=8, wall=126782
2023-05-22 05:11:03 - progress_bar.py[line:272] - INFO: epoch 020:     12 / 1732 loss=2.3, loss_v1=0, loss_v2=0, nll_loss=1.088, ntokens=1057.9, nsentences=32, sample_size=1057.9, sample_size_v1=0, sample_size_v2=0, ppl=2.13, wps=274.2, ups=0.26, wpb=1057.9, bsz=32, num_updates=32860, lr=3.91049e-06, gnorm=17.806, clip=100, loss_scale=32, train_wall=39, gb_free=8.8, wall=126820
2023-05-22 05:11:42 - progress_bar.py[line:272] - INFO: epoch 020:     22 / 1732 loss=2.244, loss_v1=0, loss_v2=0, nll_loss=1.026, ntokens=1106.7, nsentences=32, sample_size=1106.7, sample_size_v1=0, sample_size_v2=0, ppl=2.04, wps=286.5, ups=0.26, wpb=1106.7, bsz=32, num_updates=32870, lr=3.90844e-06, gnorm=14.881, clip=100, loss_scale=32, train_wall=39, gb_free=8.5, wall=126859
2023-05-22 05:12:21 - progress_bar.py[line:272] - INFO: epoch 020:     32 / 1732 loss=2.269, loss_v1=0, loss_v2=0, nll_loss=1.053, ntokens=985.4, nsentences=32, sample_size=985.4, sample_size_v1=0, sample_size_v2=0, ppl=2.07, wps=253.6, ups=0.26, wpb=985.4, bsz=32, num_updates=32880, lr=3.90639e-06, gnorm=15.756, clip=100, loss_scale=32, train_wall=39, gb_free=7.6, wall=126898
2023-05-22 05:13:00 - progress_bar.py[line:272] - INFO: epoch 020:     42 / 1732 loss=2.137, loss_v1=0, loss_v2=0, nll_loss=0.909, ntokens=1168.8, nsentences=32, sample_size=1168.8, sample_size_v1=0, sample_size_v2=0, ppl=1.88, wps=299.1, ups=0.26, wpb=1168.8, bsz=32, num_updates=32890, lr=3.90435e-06, gnorm=11.341, clip=100, loss_scale=32, train_wall=39, gb_free=8.7, wall=126937
2023-05-22 05:13:38 - progress_bar.py[line:272] - INFO: epoch 020:     52 / 1732 loss=2.203, loss_v1=0, loss_v2=0, nll_loss=0.987, ntokens=1030.1, nsentences=32, sample_size=1030.1, sample_size_v1=0, sample_size_v2=0, ppl=1.98, wps=265.4, ups=0.26, wpb=1030.1, bsz=32, num_updates=32900, lr=3.9023e-06, gnorm=14.546, clip=100, loss_scale=32, train_wall=39, gb_free=8.8, wall=126976
2023-05-22 05:14:17 - progress_bar.py[line:272] - INFO: epoch 020:     62 / 1732 loss=2.006, loss_v1=0, loss_v2=0, nll_loss=0.762, ntokens=1192.6, nsentences=32, sample_size=1192.6, sample_size_v1=0, sample_size_v2=0, ppl=1.7, wps=306.2, ups=0.26, wpb=1192.6, bsz=32, num_updates=32910, lr=3.90025e-06, gnorm=11.738, clip=100, loss_scale=32, train_wall=39, gb_free=7.4, wall=127015
2023-05-22 05:14:46 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2023-05-22 05:15:02 - progress_bar.py[line:272] - INFO: epoch 020:     73 / 1732 loss=2.092, loss_v1=0, loss_v2=0, nll_loss=0.86, ntokens=1399.6, nsentences=32, sample_size=1399.6, sample_size_v1=0, sample_size_v2=0, ppl=1.81, wps=317.5, ups=0.23, wpb=1399.6, bsz=32, num_updates=32920, lr=3.8982e-06, gnorm=11.538, clip=100, loss_scale=16, train_wall=44, gb_free=7, wall=127059
2023-05-22 05:15:41 - progress_bar.py[line:272] - INFO: epoch 020:     83 / 1732 loss=2.164, loss_v1=0, loss_v2=0, nll_loss=0.936, ntokens=1166.3, nsentences=32, sample_size=1166.3, sample_size_v1=0, sample_size_v2=0, ppl=1.91, wps=296.6, ups=0.25, wpb=1166.3, bsz=32, num_updates=32930, lr=3.89616e-06, gnorm=16.367, clip=100, loss_scale=16, train_wall=39, gb_free=7.2, wall=127098
2023-05-22 05:16:20 - progress_bar.py[line:272] - INFO: epoch 020:     93 / 1732 loss=2.154, loss_v1=0, loss_v2=0, nll_loss=0.921, ntokens=1099.1, nsentences=32, sample_size=1099.1, sample_size_v1=0, sample_size_v2=0, ppl=1.89, wps=282.6, ups=0.26, wpb=1099.1, bsz=32, num_updates=32940, lr=3.89411e-06, gnorm=15.178, clip=100, loss_scale=16, train_wall=39, gb_free=8.2, wall=127137
2023-05-22 05:16:58 - progress_bar.py[line:272] - INFO: epoch 020:    103 / 1732 loss=2.314, loss_v1=0, loss_v2=0, nll_loss=1.105, ntokens=976, nsentences=32, sample_size=976, sample_size_v1=0, sample_size_v2=0, ppl=2.15, wps=255.1, ups=0.26, wpb=976, bsz=32, num_updates=32950, lr=3.89206e-06, gnorm=18.684, clip=100, loss_scale=16, train_wall=38, gb_free=8.6, wall=127175
2023-05-22 05:17:37 - progress_bar.py[line:272] - INFO: epoch 020:    113 / 1732 loss=2.378, loss_v1=0, loss_v2=0, nll_loss=1.177, ntokens=1030.9, nsentences=32, sample_size=1030.9, sample_size_v1=0, sample_size_v2=0, ppl=2.26, wps=267.2, ups=0.26, wpb=1030.9, bsz=32, num_updates=32960, lr=3.89001e-06, gnorm=17.891, clip=100, loss_scale=16, train_wall=39, gb_free=7.8, wall=127214
2023-05-22 05:18:16 - progress_bar.py[line:272] - INFO: epoch 020:    123 / 1732 loss=2.345, loss_v1=0, loss_v2=0, nll_loss=1.139, ntokens=1142.2, nsentences=32, sample_size=1142.2, sample_size_v1=0, sample_size_v2=0, ppl=2.2, wps=291.1, ups=0.25, wpb=1142.2, bsz=32, num_updates=32970, lr=3.88797e-06, gnorm=15.784, clip=100, loss_scale=16, train_wall=39, gb_free=7.6, wall=127253
2023-05-22 05:18:55 - progress_bar.py[line:272] - INFO: epoch 020:    133 / 1732 loss=2.289, loss_v1=0, loss_v2=0, nll_loss=1.077, ntokens=1207.4, nsentences=32, sample_size=1207.4, sample_size_v1=0, sample_size_v2=0, ppl=2.11, wps=308.3, ups=0.26, wpb=1207.4, bsz=32, num_updates=32980, lr=3.88592e-06, gnorm=13.94, clip=100, loss_scale=16, train_wall=39, gb_free=8, wall=127292
2023-05-22 05:19:34 - progress_bar.py[line:272] - INFO: epoch 020:    143 / 1732 loss=2.273, loss_v1=0, loss_v2=0, nll_loss=1.058, ntokens=1226.6, nsentences=32, sample_size=1226.6, sample_size_v1=0, sample_size_v2=0, ppl=2.08, wps=311.1, ups=0.25, wpb=1226.6, bsz=32, num_updates=32990, lr=3.88387e-06, gnorm=13.305, clip=100, loss_scale=16, train_wall=39, gb_free=7.2, wall=127332
2023-05-22 05:20:14 - progress_bar.py[line:272] - INFO: epoch 020:    153 / 1732 loss=2.286, loss_v1=0, loss_v2=0, nll_loss=1.075, ntokens=1152.6, nsentences=32, sample_size=1152.6, sample_size_v1=0, sample_size_v2=0, ppl=2.11, wps=292.8, ups=0.25, wpb=1152.6, bsz=32, num_updates=33000, lr=3.88183e-06, gnorm=12.997, clip=100, loss_scale=16, train_wall=39, gb_free=7.3, wall=127371
2023-05-22 05:20:53 - progress_bar.py[line:272] - INFO: epoch 020:    163 / 1732 loss=2.276, loss_v1=0, loss_v2=0, nll_loss=1.062, ntokens=1079.7, nsentences=32, sample_size=1079.7, sample_size_v1=0, sample_size_v2=0, ppl=2.09, wps=277.4, ups=0.26, wpb=1079.7, bsz=32, num_updates=33010, lr=3.87978e-06, gnorm=14.058, clip=100, loss_scale=16, train_wall=39, gb_free=8.7, wall=127410
2023-05-22 05:21:32 - progress_bar.py[line:272] - INFO: epoch 020:    173 / 1732 loss=2.299, loss_v1=0, loss_v2=0, nll_loss=1.089, ntokens=936.5, nsentences=32, sample_size=936.5, sample_size_v1=0, sample_size_v2=0, ppl=2.13, wps=241.5, ups=0.26, wpb=936.5, bsz=32, num_updates=33020, lr=3.87773e-06, gnorm=14.987, clip=100, loss_scale=16, train_wall=39, gb_free=7.8, wall=127449
2023-05-22 05:22:11 - progress_bar.py[line:272] - INFO: epoch 020:    183 / 1732 loss=2.249, loss_v1=0, loss_v2=0, nll_loss=1.031, ntokens=1184.7, nsentences=32, sample_size=1184.7, sample_size_v1=0, sample_size_v2=0, ppl=2.04, wps=301.8, ups=0.25, wpb=1184.7, bsz=32, num_updates=33030, lr=3.87568e-06, gnorm=13.7, clip=100, loss_scale=16, train_wall=39, gb_free=8.4, wall=127488
2023-05-22 05:22:50 - progress_bar.py[line:272] - INFO: epoch 020:    193 / 1732 loss=2.265, loss_v1=0, loss_v2=0, nll_loss=1.048, ntokens=1122.8, nsentences=32, sample_size=1122.8, sample_size_v1=0, sample_size_v2=0, ppl=2.07, wps=285.6, ups=0.25, wpb=1122.8, bsz=32, num_updates=33040, lr=3.87364e-06, gnorm=13.959, clip=100, loss_scale=16, train_wall=39, gb_free=8.2, wall=127527
2023-05-22 05:23:29 - progress_bar.py[line:272] - INFO: epoch 020:    203 / 1732 loss=2.36, loss_v1=0, loss_v2=0, nll_loss=1.156, ntokens=1086.7, nsentences=32, sample_size=1086.7, sample_size_v1=0, sample_size_v2=0, ppl=2.23, wps=279.2, ups=0.26, wpb=1086.7, bsz=32, num_updates=33050, lr=3.87159e-06, gnorm=15.707, clip=100, loss_scale=16, train_wall=39, gb_free=8.5, wall=127566
2023-05-22 05:24:07 - progress_bar.py[line:272] - INFO: epoch 020:    213 / 1732 loss=2.384, loss_v1=0, loss_v2=0, nll_loss=1.184, ntokens=1044.9, nsentences=32, sample_size=1044.9, sample_size_v1=0, sample_size_v2=0, ppl=2.27, wps=272.3, ups=0.26, wpb=1044.9, bsz=32, num_updates=33060, lr=3.86954e-06, gnorm=16.715, clip=100, loss_scale=16, train_wall=38, gb_free=8.5, wall=127605
2023-05-22 05:24:46 - progress_bar.py[line:272] - INFO: epoch 020:    223 / 1732 loss=2.39, loss_v1=0, loss_v2=0, nll_loss=1.191, ntokens=1134.6, nsentences=32, sample_size=1134.6, sample_size_v1=0, sample_size_v2=0, ppl=2.28, wps=295.8, ups=0.26, wpb=1134.6, bsz=32, num_updates=33070, lr=3.86749e-06, gnorm=14.749, clip=100, loss_scale=16, train_wall=38, gb_free=8.6, wall=127643
2023-05-22 05:25:24 - progress_bar.py[line:272] - INFO: epoch 020:    233 / 1732 loss=2.432, loss_v1=0, loss_v2=0, nll_loss=1.237, ntokens=1078.6, nsentences=32, sample_size=1078.6, sample_size_v1=0, sample_size_v2=0, ppl=2.36, wps=280.7, ups=0.26, wpb=1078.6, bsz=32, num_updates=33080, lr=3.86545e-06, gnorm=15.562, clip=100, loss_scale=16, train_wall=38, gb_free=9.1, wall=127681
2023-05-22 05:26:03 - progress_bar.py[line:272] - INFO: epoch 020:    243 / 1732 loss=2.421, loss_v1=0, loss_v2=0, nll_loss=1.225, ntokens=1123.3, nsentences=32, sample_size=1123.3, sample_size_v1=0, sample_size_v2=0, ppl=2.34, wps=289.4, ups=0.26, wpb=1123.3, bsz=32, num_updates=33090, lr=3.8634e-06, gnorm=14.911, clip=100, loss_scale=16, train_wall=39, gb_free=8.7, wall=127720
2023-05-22 05:26:42 - progress_bar.py[line:272] - INFO: epoch 020:    253 / 1732 loss=2.419, loss_v1=0, loss_v2=0, nll_loss=1.222, ntokens=1167.4, nsentences=32, sample_size=1167.4, sample_size_v1=0, sample_size_v2=0, ppl=2.33, wps=303, ups=0.26, wpb=1167.4, bsz=32, num_updates=33100, lr=3.86135e-06, gnorm=14.399, clip=100, loss_scale=16, train_wall=38, gb_free=8, wall=127759
2023-05-22 05:27:20 - progress_bar.py[line:272] - INFO: epoch 020:    263 / 1732 loss=2.412, loss_v1=0, loss_v2=0, nll_loss=1.214, ntokens=1123.9, nsentences=32, sample_size=1123.9, sample_size_v1=0, sample_size_v2=0, ppl=2.32, wps=293.1, ups=0.26, wpb=1123.9, bsz=32, num_updates=33110, lr=3.8593e-06, gnorm=15.847, clip=100, loss_scale=16, train_wall=38, gb_free=8, wall=127797
2023-05-22 05:27:58 - progress_bar.py[line:272] - INFO: epoch 020:    273 / 1732 loss=2.401, loss_v1=0, loss_v2=0, nll_loss=1.199, ntokens=1154.8, nsentences=32, sample_size=1154.8, sample_size_v1=0, sample_size_v2=0, ppl=2.3, wps=300.1, ups=0.26, wpb=1154.8, bsz=32, num_updates=33120, lr=3.85726e-06, gnorm=15.482, clip=100, loss_scale=16, train_wall=38, gb_free=8.3, wall=127836
2023-05-22 05:28:37 - progress_bar.py[line:272] - INFO: epoch 020:    283 / 1732 loss=2.423, loss_v1=0, loss_v2=0, nll_loss=1.226, ntokens=1146.7, nsentences=32, sample_size=1146.7, sample_size_v1=0, sample_size_v2=0, ppl=2.34, wps=296.4, ups=0.26, wpb=1146.7, bsz=32, num_updates=33130, lr=3.85521e-06, gnorm=15.43, clip=100, loss_scale=16, train_wall=39, gb_free=8.2, wall=127874
2023-05-22 05:29:16 - progress_bar.py[line:272] - INFO: epoch 020:    293 / 1732 loss=2.388, loss_v1=0, loss_v2=0, nll_loss=1.187, ntokens=1122.6, nsentences=32, sample_size=1122.6, sample_size_v1=0, sample_size_v2=0, ppl=2.28, wps=292, ups=0.26, wpb=1122.6, bsz=32, num_updates=33140, lr=3.85316e-06, gnorm=16.127, clip=100, loss_scale=16, train_wall=38, gb_free=7.4, wall=127913
2023-05-22 05:29:54 - progress_bar.py[line:272] - INFO: epoch 020:    303 / 1732 loss=2.388, loss_v1=0, loss_v2=0, nll_loss=1.186, ntokens=1117.4, nsentences=32, sample_size=1117.4, sample_size_v1=0, sample_size_v2=0, ppl=2.28, wps=291.6, ups=0.26, wpb=1117.4, bsz=32, num_updates=33150, lr=3.85111e-06, gnorm=16.069, clip=100, loss_scale=16, train_wall=38, gb_free=8.2, wall=127951
2023-05-22 05:30:32 - progress_bar.py[line:272] - INFO: epoch 020:    313 / 1732 loss=2.404, loss_v1=0, loss_v2=0, nll_loss=1.204, ntokens=1045.5, nsentences=32, sample_size=1045.5, sample_size_v1=0, sample_size_v2=0, ppl=2.3, wps=272, ups=0.26, wpb=1045.5, bsz=32, num_updates=33160, lr=3.84907e-06, gnorm=16.363, clip=100, loss_scale=16, train_wall=38, gb_free=8.6, wall=127989
2023-05-22 05:31:10 - progress_bar.py[line:272] - INFO: epoch 020:    323 / 1732 loss=2.436, loss_v1=0, loss_v2=0, nll_loss=1.241, ntokens=1005.7, nsentences=32, sample_size=1005.7, sample_size_v1=0, sample_size_v2=0, ppl=2.36, wps=263.4, ups=0.26, wpb=1005.7, bsz=32, num_updates=33170, lr=3.84702e-06, gnorm=17.069, clip=100, loss_scale=16, train_wall=38, gb_free=8.6, wall=128028
2023-05-22 05:31:48 - progress_bar.py[line:272] - INFO: epoch 020:    333 / 1732 loss=2.42, loss_v1=0, loss_v2=0, nll_loss=1.224, ntokens=1019.2, nsentences=32, sample_size=1019.2, sample_size_v1=0, sample_size_v2=0, ppl=2.34, wps=268, ups=0.26, wpb=1019.2, bsz=32, num_updates=33180, lr=3.84497e-06, gnorm=15.87, clip=100, loss_scale=16, train_wall=38, gb_free=8.6, wall=128066
2023-05-22 05:32:26 - progress_bar.py[line:272] - INFO: epoch 020:    343 / 1732 loss=2.387, loss_v1=0, loss_v2=0, nll_loss=1.187, ntokens=919.2, nsentences=32, sample_size=919.2, sample_size_v1=0, sample_size_v2=0, ppl=2.28, wps=243, ups=0.26, wpb=919.2, bsz=32, num_updates=33190, lr=3.84293e-06, gnorm=17.748, clip=100, loss_scale=16, train_wall=38, gb_free=9.1, wall=128104
2023-05-22 05:33:04 - progress_bar.py[line:272] - INFO: epoch 020:    353 / 1732 loss=2.413, loss_v1=0, loss_v2=0, nll_loss=1.215, ntokens=968.9, nsentences=32, sample_size=968.9, sample_size_v1=0, sample_size_v2=0, ppl=2.32, wps=255.6, ups=0.26, wpb=968.9, bsz=32, num_updates=33200, lr=3.84088e-06, gnorm=17.91, clip=100, loss_scale=16, train_wall=38, gb_free=7.7, wall=128141
2023-05-22 05:33:42 - progress_bar.py[line:272] - INFO: epoch 020:    363 / 1732 loss=2.454, loss_v1=0, loss_v2=0, nll_loss=1.262, ntokens=932.1, nsentences=32, sample_size=932.1, sample_size_v1=0, sample_size_v2=0, ppl=2.4, wps=247.3, ups=0.27, wpb=932.1, bsz=32, num_updates=33210, lr=3.83883e-06, gnorm=19.277, clip=100, loss_scale=16, train_wall=38, gb_free=8.7, wall=128179
2023-05-22 05:34:20 - progress_bar.py[line:272] - INFO: epoch 020:    373 / 1732 loss=2.445, loss_v1=0, loss_v2=0, nll_loss=1.25, ntokens=967.4, nsentences=32, sample_size=967.4, sample_size_v1=0, sample_size_v2=0, ppl=2.38, wps=254.6, ups=0.26, wpb=967.4, bsz=32, num_updates=33220, lr=3.83678e-06, gnorm=17.647, clip=100, loss_scale=16, train_wall=38, gb_free=8.9, wall=128217
2023-05-22 05:34:58 - progress_bar.py[line:272] - INFO: epoch 020:    383 / 1732 loss=2.424, loss_v1=0, loss_v2=0, nll_loss=1.228, ntokens=1070.5, nsentences=32, sample_size=1070.5, sample_size_v1=0, sample_size_v2=0, ppl=2.34, wps=281.9, ups=0.26, wpb=1070.5, bsz=32, num_updates=33230, lr=3.83474e-06, gnorm=17.721, clip=100, loss_scale=16, train_wall=38, gb_free=8.7, wall=128255
2023-05-22 05:35:36 - progress_bar.py[line:272] - INFO: epoch 020:    393 / 1732 loss=2.424, loss_v1=0, loss_v2=0, nll_loss=1.227, ntokens=990.3, nsentences=32, sample_size=990.3, sample_size_v1=0, sample_size_v2=0, ppl=2.34, wps=260.2, ups=0.26, wpb=990.3, bsz=32, num_updates=33240, lr=3.83269e-06, gnorm=17.387, clip=100, loss_scale=16, train_wall=38, gb_free=8.9, wall=128293
2023-05-22 05:36:14 - progress_bar.py[line:272] - INFO: epoch 020:    403 / 1732 loss=2.398, loss_v1=0, loss_v2=0, nll_loss=1.197, ntokens=1045, nsentences=32, sample_size=1045, sample_size_v1=0, sample_size_v2=0, ppl=2.29, wps=273.3, ups=0.26, wpb=1045, bsz=32, num_updates=33250, lr=3.83064e-06, gnorm=16.678, clip=100, loss_scale=16, train_wall=38, gb_free=8.4, wall=128331
2023-05-22 05:36:52 - progress_bar.py[line:272] - INFO: epoch 020:    413 / 1732 loss=2.393, loss_v1=0, loss_v2=0, nll_loss=1.193, ntokens=1078.5, nsentences=32, sample_size=1078.5, sample_size_v1=0, sample_size_v2=0, ppl=2.29, wps=282.5, ups=0.26, wpb=1078.5, bsz=32, num_updates=33260, lr=3.82859e-06, gnorm=15.569, clip=100, loss_scale=16, train_wall=38, gb_free=8.6, wall=128370
2023-05-22 05:37:30 - progress_bar.py[line:272] - INFO: epoch 020:    423 / 1732 loss=2.378, loss_v1=0, loss_v2=0, nll_loss=1.176, ntokens=985.4, nsentences=32, sample_size=985.4, sample_size_v1=0, sample_size_v2=0, ppl=2.26, wps=259.1, ups=0.26, wpb=985.4, bsz=32, num_updates=33270, lr=3.82655e-06, gnorm=18.372, clip=100, loss_scale=16, train_wall=38, gb_free=8.3, wall=128408
2023-05-22 05:38:08 - progress_bar.py[line:272] - INFO: epoch 020:    433 / 1732 loss=2.393, loss_v1=0, loss_v2=0, nll_loss=1.193, ntokens=1024.2, nsentences=32, sample_size=1024.2, sample_size_v1=0, sample_size_v2=0, ppl=2.29, wps=269.6, ups=0.26, wpb=1024.2, bsz=32, num_updates=33280, lr=3.8245e-06, gnorm=19.055, clip=100, loss_scale=16, train_wall=38, gb_free=9, wall=128446
2023-05-22 05:38:46 - progress_bar.py[line:272] - INFO: epoch 020:    443 / 1732 loss=2.439, loss_v1=0, loss_v2=0, nll_loss=1.245, ntokens=966.7, nsentences=32, sample_size=966.7, sample_size_v1=0, sample_size_v2=0, ppl=2.37, wps=253.9, ups=0.26, wpb=966.7, bsz=32, num_updates=33290, lr=3.82245e-06, gnorm=18.592, clip=100, loss_scale=16, train_wall=38, gb_free=8.9, wall=128484
2023-05-22 05:39:24 - progress_bar.py[line:272] - INFO: epoch 020:    453 / 1732 loss=2.416, loss_v1=0, loss_v2=0, nll_loss=1.218, ntokens=911.8, nsentences=32, sample_size=911.8, sample_size_v1=0, sample_size_v2=0, ppl=2.33, wps=240, ups=0.26, wpb=911.8, bsz=32, num_updates=33300, lr=3.8204e-06, gnorm=20.623, clip=100, loss_scale=16, train_wall=38, gb_free=9.1, wall=128522
2023-05-22 05:40:03 - progress_bar.py[line:272] - INFO: epoch 020:    463 / 1732 loss=2.445, loss_v1=0, loss_v2=0, nll_loss=1.251, ntokens=1072.4, nsentences=32, sample_size=1072.4, sample_size_v1=0, sample_size_v2=0, ppl=2.38, wps=282, ups=0.26, wpb=1072.4, bsz=32, num_updates=33310, lr=3.81836e-06, gnorm=16.639, clip=100, loss_scale=16, train_wall=38, gb_free=8.8, wall=128560
2023-05-22 05:40:41 - progress_bar.py[line:272] - INFO: epoch 020:    473 / 1732 loss=2.424, loss_v1=0, loss_v2=0, nll_loss=1.227, ntokens=1059.2, nsentences=32, sample_size=1059.2, sample_size_v1=0, sample_size_v2=0, ppl=2.34, wps=274.9, ups=0.26, wpb=1059.2, bsz=32, num_updates=33320, lr=3.81631e-06, gnorm=16.622, clip=100, loss_scale=16, train_wall=38, gb_free=7.5, wall=128598
2023-05-22 05:41:19 - progress_bar.py[line:272] - INFO: epoch 020:    483 / 1732 loss=2.416, loss_v1=0, loss_v2=0, nll_loss=1.217, ntokens=966.6, nsentences=32, sample_size=966.6, sample_size_v1=0, sample_size_v2=0, ppl=2.32, wps=255.8, ups=0.26, wpb=966.6, bsz=32, num_updates=33330, lr=3.81426e-06, gnorm=17.877, clip=100, loss_scale=16, train_wall=38, gb_free=8.8, wall=128636
2023-05-22 05:41:57 - progress_bar.py[line:272] - INFO: epoch 020:    493 / 1732 loss=2.42, loss_v1=0, loss_v2=0, nll_loss=1.223, ntokens=940.2, nsentences=32, sample_size=940.2, sample_size_v1=0, sample_size_v2=0, ppl=2.33, wps=247.6, ups=0.26, wpb=940.2, bsz=32, num_updates=33340, lr=3.81221e-06, gnorm=18.569, clip=100, loss_scale=16, train_wall=38, gb_free=9, wall=128674
2023-05-22 05:42:35 - progress_bar.py[line:272] - INFO: epoch 020:    503 / 1732 loss=2.415, loss_v1=0, loss_v2=0, nll_loss=1.216, ntokens=988.6, nsentences=32, sample_size=988.6, sample_size_v1=0, sample_size_v2=0, ppl=2.32, wps=261.9, ups=0.26, wpb=988.6, bsz=32, num_updates=33350, lr=3.81017e-06, gnorm=17.71, clip=100, loss_scale=16, train_wall=38, gb_free=9, wall=128712
2023-05-22 05:43:13 - progress_bar.py[line:272] - INFO: epoch 020:    513 / 1732 loss=2.435, loss_v1=0, loss_v2=0, nll_loss=1.238, ntokens=1035, nsentences=32, sample_size=1035, sample_size_v1=0, sample_size_v2=0, ppl=2.36, wps=272, ups=0.26, wpb=1035, bsz=32, num_updates=33360, lr=3.80812e-06, gnorm=16.328, clip=100, loss_scale=16, train_wall=38, gb_free=8.9, wall=128750
2023-05-22 05:43:50 - progress_bar.py[line:272] - INFO: epoch 020:    523 / 1732 loss=2.407, loss_v1=0, loss_v2=0, nll_loss=1.208, ntokens=997.6, nsentences=32, sample_size=997.6, sample_size_v1=0, sample_size_v2=0, ppl=2.31, wps=263.9, ups=0.26, wpb=997.6, bsz=32, num_updates=33370, lr=3.80607e-06, gnorm=17.552, clip=100, loss_scale=16, train_wall=38, gb_free=9, wall=128788
2023-05-22 05:44:28 - progress_bar.py[line:272] - INFO: epoch 020:    533 / 1732 loss=2.407, loss_v1=0, loss_v2=0, nll_loss=1.209, ntokens=935, nsentences=32, sample_size=935, sample_size_v1=0, sample_size_v2=0, ppl=2.31, wps=248.3, ups=0.27, wpb=935, bsz=32, num_updates=33380, lr=3.80403e-06, gnorm=17.186, clip=100, loss_scale=16, train_wall=38, gb_free=9, wall=128825
2023-05-22 05:45:06 - progress_bar.py[line:272] - INFO: epoch 020:    543 / 1732 loss=2.426, loss_v1=0, loss_v2=0, nll_loss=1.229, ntokens=1003.8, nsentences=32, sample_size=1003.8, sample_size_v1=0, sample_size_v2=0, ppl=2.34, wps=265, ups=0.26, wpb=1003.8, bsz=32, num_updates=33390, lr=3.80198e-06, gnorm=17.243, clip=100, loss_scale=16, train_wall=38, gb_free=8.6, wall=128863
2023-05-22 05:45:44 - progress_bar.py[line:272] - INFO: epoch 020:    553 / 1732 loss=2.449, loss_v1=0, loss_v2=0, nll_loss=1.255, ntokens=1017.4, nsentences=32, sample_size=1017.4, sample_size_v1=0, sample_size_v2=0, ppl=2.39, wps=267.4, ups=0.26, wpb=1017.4, bsz=32, num_updates=33400, lr=3.79993e-06, gnorm=17.682, clip=100, loss_scale=16, train_wall=38, gb_free=9, wall=128901
2023-05-22 05:46:22 - progress_bar.py[line:272] - INFO: epoch 020:    563 / 1732 loss=2.442, loss_v1=0, loss_v2=0, nll_loss=1.247, ntokens=1008.2, nsentences=32, sample_size=1008.2, sample_size_v1=0, sample_size_v2=0, ppl=2.37, wps=264.1, ups=0.26, wpb=1008.2, bsz=32, num_updates=33410, lr=3.79788e-06, gnorm=17.112, clip=100, loss_scale=16, train_wall=38, gb_free=9.3, wall=128939
2023-05-22 05:47:00 - progress_bar.py[line:272] - INFO: epoch 020:    573 / 1732 loss=2.444, loss_v1=0, loss_v2=0, nll_loss=1.25, ntokens=1041.3, nsentences=32, sample_size=1041.3, sample_size_v1=0, sample_size_v2=0, ppl=2.38, wps=272.1, ups=0.26, wpb=1041.3, bsz=32, num_updates=33420, lr=3.79584e-06, gnorm=18.093, clip=100, loss_scale=16, train_wall=38, gb_free=8.1, wall=128978
2023-05-22 05:47:39 - progress_bar.py[line:272] - INFO: epoch 020:    583 / 1732 loss=2.434, loss_v1=0, loss_v2=0, nll_loss=1.239, ntokens=981.7, nsentences=32, sample_size=981.7, sample_size_v1=0, sample_size_v2=0, ppl=2.36, wps=256.9, ups=0.26, wpb=981.7, bsz=32, num_updates=33430, lr=3.79379e-06, gnorm=18.093, clip=100, loss_scale=32, train_wall=38, gb_free=9, wall=129016
2023-05-22 05:48:17 - progress_bar.py[line:272] - INFO: epoch 020:    593 / 1732 loss=2.394, loss_v1=0, loss_v2=0, nll_loss=1.193, ntokens=957.4, nsentences=32, sample_size=957.4, sample_size_v1=0, sample_size_v2=0, ppl=2.29, wps=251.5, ups=0.26, wpb=957.4, bsz=32, num_updates=33440, lr=3.79174e-06, gnorm=17.647, clip=100, loss_scale=32, train_wall=38, gb_free=8.9, wall=129054
2023-05-22 05:48:54 - progress_bar.py[line:272] - INFO: epoch 020:    603 / 1732 loss=2.401, loss_v1=0, loss_v2=0, nll_loss=1.203, ntokens=911.2, nsentences=32, sample_size=911.2, sample_size_v1=0, sample_size_v2=0, ppl=2.3, wps=241.5, ups=0.27, wpb=911.2, bsz=32, num_updates=33450, lr=3.78969e-06, gnorm=20.334, clip=100, loss_scale=32, train_wall=38, gb_free=8.7, wall=129092
2023-05-22 05:49:32 - progress_bar.py[line:272] - INFO: epoch 020:    613 / 1732 loss=2.418, loss_v1=0, loss_v2=0, nll_loss=1.223, ntokens=893.3, nsentences=32, sample_size=893.3, sample_size_v1=0, sample_size_v2=0, ppl=2.33, wps=235.4, ups=0.26, wpb=893.3, bsz=32, num_updates=33460, lr=3.78765e-06, gnorm=18.875, clip=100, loss_scale=32, train_wall=38, gb_free=9.1, wall=129130
2023-05-22 05:50:10 - progress_bar.py[line:272] - INFO: epoch 020:    623 / 1732 loss=2.433, loss_v1=0, loss_v2=0, nll_loss=1.238, ntokens=887.2, nsentences=32, sample_size=887.2, sample_size_v1=0, sample_size_v2=0, ppl=2.36, wps=234.6, ups=0.26, wpb=887.2, bsz=32, num_updates=33470, lr=3.7856e-06, gnorm=19.895, clip=100, loss_scale=32, train_wall=38, gb_free=8.3, wall=129167
2023-05-22 05:50:48 - progress_bar.py[line:272] - INFO: epoch 020:    633 / 1732 loss=2.423, loss_v1=0, loss_v2=0, nll_loss=1.226, ntokens=925, nsentences=32, sample_size=925, sample_size_v1=0, sample_size_v2=0, ppl=2.34, wps=245.4, ups=0.27, wpb=925, bsz=32, num_updates=33480, lr=3.78355e-06, gnorm=22.44, clip=100, loss_scale=32, train_wall=38, gb_free=8.7, wall=129205
2023-05-22 05:51:26 - progress_bar.py[line:272] - INFO: epoch 020:    643 / 1732 loss=2.438, loss_v1=0, loss_v2=0, nll_loss=1.243, ntokens=963.8, nsentences=32, sample_size=963.8, sample_size_v1=0, sample_size_v2=0, ppl=2.37, wps=255.5, ups=0.27, wpb=963.8, bsz=32, num_updates=33490, lr=3.7815e-06, gnorm=18.322, clip=100, loss_scale=32, train_wall=38, gb_free=9, wall=129243
2023-05-22 05:52:03 - progress_bar.py[line:272] - INFO: epoch 020:    653 / 1732 loss=2.433, loss_v1=0, loss_v2=0, nll_loss=1.238, ntokens=928, nsentences=32, sample_size=928, sample_size_v1=0, sample_size_v2=0, ppl=2.36, wps=246.6, ups=0.27, wpb=928, bsz=32, num_updates=33500, lr=3.77946e-06, gnorm=19.144, clip=100, loss_scale=32, train_wall=38, gb_free=9.1, wall=129280
2023-05-22 05:52:41 - progress_bar.py[line:272] - INFO: epoch 020:    663 / 1732 loss=2.432, loss_v1=0, loss_v2=0, nll_loss=1.236, ntokens=882.9, nsentences=32, sample_size=882.9, sample_size_v1=0, sample_size_v2=0, ppl=2.36, wps=234.2, ups=0.27, wpb=882.9, bsz=32, num_updates=33510, lr=3.77741e-06, gnorm=19.48, clip=100, loss_scale=32, train_wall=38, gb_free=8.8, wall=129318
2023-05-22 05:53:19 - progress_bar.py[line:272] - INFO: epoch 020:    673 / 1732 loss=2.444, loss_v1=0, loss_v2=0, nll_loss=1.251, ntokens=954.3, nsentences=32, sample_size=954.3, sample_size_v1=0, sample_size_v2=0, ppl=2.38, wps=251.6, ups=0.26, wpb=954.3, bsz=32, num_updates=33520, lr=3.77536e-06, gnorm=19.585, clip=100, loss_scale=32, train_wall=38, gb_free=9, wall=129356
2023-05-22 05:53:57 - progress_bar.py[line:272] - INFO: epoch 020:    683 / 1732 loss=2.414, loss_v1=0, loss_v2=0, nll_loss=1.216, ntokens=960.5, nsentences=32, sample_size=960.5, sample_size_v1=0, sample_size_v2=0, ppl=2.32, wps=252.5, ups=0.26, wpb=960.5, bsz=32, num_updates=33530, lr=3.77331e-06, gnorm=18.974, clip=100, loss_scale=32, train_wall=38, gb_free=9.2, wall=129394
2023-05-22 05:54:35 - progress_bar.py[line:272] - INFO: epoch 020:    693 / 1732 loss=2.445, loss_v1=0, loss_v2=0, nll_loss=1.251, ntokens=962.9, nsentences=32, sample_size=962.9, sample_size_v1=0, sample_size_v2=0, ppl=2.38, wps=253.9, ups=0.26, wpb=962.9, bsz=32, num_updates=33540, lr=3.77127e-06, gnorm=18.031, clip=100, loss_scale=32, train_wall=38, gb_free=8.3, wall=129432
2023-05-22 05:55:13 - progress_bar.py[line:272] - INFO: epoch 020:    703 / 1732 loss=2.389, loss_v1=0, loss_v2=0, nll_loss=1.187, ntokens=972.9, nsentences=32, sample_size=972.9, sample_size_v1=0, sample_size_v2=0, ppl=2.28, wps=256.9, ups=0.26, wpb=972.9, bsz=32, num_updates=33550, lr=3.76922e-06, gnorm=18.259, clip=100, loss_scale=32, train_wall=38, gb_free=8.9, wall=129470
2023-05-22 05:55:50 - progress_bar.py[line:272] - INFO: epoch 020:    713 / 1732 loss=2.445, loss_v1=0, loss_v2=0, nll_loss=1.25, ntokens=898.6, nsentences=32, sample_size=898.6, sample_size_v1=0, sample_size_v2=0, ppl=2.38, wps=238.3, ups=0.27, wpb=898.6, bsz=32, num_updates=33560, lr=3.76717e-06, gnorm=18.85, clip=100, loss_scale=32, train_wall=38, gb_free=9.1, wall=129508
2023-05-22 05:56:28 - progress_bar.py[line:272] - INFO: epoch 020:    723 / 1732 loss=2.396, loss_v1=0, loss_v2=0, nll_loss=1.196, ntokens=877.5, nsentences=32, sample_size=877.5, sample_size_v1=0, sample_size_v2=0, ppl=2.29, wps=233.9, ups=0.27, wpb=877.5, bsz=32, num_updates=33570, lr=3.76512e-06, gnorm=18.554, clip=100, loss_scale=32, train_wall=37, gb_free=9.2, wall=129545
2023-05-22 05:57:06 - progress_bar.py[line:272] - INFO: epoch 020:    733 / 1732 loss=2.404, loss_v1=0, loss_v2=0, nll_loss=1.205, ntokens=959.6, nsentences=32, sample_size=959.6, sample_size_v1=0, sample_size_v2=0, ppl=2.31, wps=253.2, ups=0.26, wpb=959.6, bsz=32, num_updates=33580, lr=3.76308e-06, gnorm=16.176, clip=100, loss_scale=32, train_wall=38, gb_free=8.2, wall=129583
2023-05-22 05:57:44 - progress_bar.py[line:272] - INFO: epoch 020:    743 / 1732 loss=2.402, loss_v1=0, loss_v2=0, nll_loss=1.203, ntokens=991.8, nsentences=32, sample_size=991.8, sample_size_v1=0, sample_size_v2=0, ppl=2.3, wps=261.7, ups=0.26, wpb=991.8, bsz=32, num_updates=33590, lr=3.76103e-06, gnorm=18.111, clip=100, loss_scale=32, train_wall=38, gb_free=8.7, wall=129621
2023-05-22 05:58:22 - progress_bar.py[line:272] - INFO: epoch 020:    753 / 1732 loss=2.416, loss_v1=0, loss_v2=0, nll_loss=1.219, ntokens=968.6, nsentences=32, sample_size=968.6, sample_size_v1=0, sample_size_v2=0, ppl=2.33, wps=254.9, ups=0.26, wpb=968.6, bsz=32, num_updates=33600, lr=3.75898e-06, gnorm=17.035, clip=100, loss_scale=32, train_wall=38, gb_free=8.7, wall=129659
2023-05-22 05:59:00 - progress_bar.py[line:272] - INFO: epoch 020:    763 / 1732 loss=2.402, loss_v1=0, loss_v2=0, nll_loss=1.203, ntokens=964, nsentences=32, sample_size=964, sample_size_v1=0, sample_size_v2=0, ppl=2.3, wps=253.6, ups=0.26, wpb=964, bsz=32, num_updates=33610, lr=3.75694e-06, gnorm=17.588, clip=100, loss_scale=32, train_wall=38, gb_free=8.8, wall=129697
2023-05-22 05:59:38 - progress_bar.py[line:272] - INFO: epoch 020:    773 / 1732 loss=2.41, loss_v1=0, loss_v2=0, nll_loss=1.213, ntokens=971.7, nsentences=32, sample_size=971.7, sample_size_v1=0, sample_size_v2=0, ppl=2.32, wps=255.7, ups=0.26, wpb=971.7, bsz=32, num_updates=33620, lr=3.75489e-06, gnorm=19.29, clip=100, loss_scale=32, train_wall=38, gb_free=8.8, wall=129735
2023-05-22 06:00:16 - progress_bar.py[line:272] - INFO: epoch 020:    783 / 1732 loss=2.416, loss_v1=0, loss_v2=0, nll_loss=1.219, ntokens=1008.4, nsentences=32, sample_size=1008.4, sample_size_v1=0, sample_size_v2=0, ppl=2.33, wps=265.3, ups=0.26, wpb=1008.4, bsz=32, num_updates=33630, lr=3.75284e-06, gnorm=17.873, clip=100, loss_scale=32, train_wall=38, gb_free=8.4, wall=129773
2023-05-22 06:00:54 - progress_bar.py[line:272] - INFO: epoch 020:    793 / 1732 loss=2.409, loss_v1=0, loss_v2=0, nll_loss=1.212, ntokens=1034.6, nsentences=32, sample_size=1034.6, sample_size_v1=0, sample_size_v2=0, ppl=2.32, wps=272.1, ups=0.26, wpb=1034.6, bsz=32, num_updates=33640, lr=3.75079e-06, gnorm=16.435, clip=100, loss_scale=32, train_wall=38, gb_free=8.8, wall=129811
2023-05-22 06:01:32 - progress_bar.py[line:272] - INFO: epoch 020:    803 / 1732 loss=2.413, loss_v1=0, loss_v2=0, nll_loss=1.215, ntokens=964.4, nsentences=32, sample_size=964.4, sample_size_v1=0, sample_size_v2=0, ppl=2.32, wps=253.9, ups=0.26, wpb=964.4, bsz=32, num_updates=33650, lr=3.74875e-06, gnorm=17.631, clip=100, loss_scale=32, train_wall=38, gb_free=8.1, wall=129849
2023-05-22 06:02:10 - progress_bar.py[line:272] - INFO: epoch 020:    813 / 1732 loss=2.424, loss_v1=0, loss_v2=0, nll_loss=1.228, ntokens=940.9, nsentences=32, sample_size=940.9, sample_size_v1=0, sample_size_v2=0, ppl=2.34, wps=247, ups=0.26, wpb=940.9, bsz=32, num_updates=33660, lr=3.7467e-06, gnorm=18.665, clip=100, loss_scale=32, train_wall=38, gb_free=7.6, wall=129887
2023-05-22 06:02:48 - progress_bar.py[line:272] - INFO: epoch 020:    823 / 1732 loss=2.411, loss_v1=0, loss_v2=0, nll_loss=1.212, ntokens=915.1, nsentences=32, sample_size=915.1, sample_size_v1=0, sample_size_v2=0, ppl=2.32, wps=240.2, ups=0.26, wpb=915.1, bsz=32, num_updates=33670, lr=3.74465e-06, gnorm=18.511, clip=100, loss_scale=32, train_wall=38, gb_free=8.3, wall=129925
2023-05-22 06:03:26 - progress_bar.py[line:272] - INFO: epoch 020:    833 / 1732 loss=2.42, loss_v1=0, loss_v2=0, nll_loss=1.222, ntokens=907.5, nsentences=32, sample_size=907.5, sample_size_v1=0, sample_size_v2=0, ppl=2.33, wps=240.8, ups=0.27, wpb=907.5, bsz=32, num_updates=33680, lr=3.7426e-06, gnorm=18.176, clip=100, loss_scale=32, train_wall=38, gb_free=9.1, wall=129963
2023-05-22 06:04:04 - progress_bar.py[line:272] - INFO: epoch 020:    843 / 1732 loss=2.392, loss_v1=0, loss_v2=0, nll_loss=1.19, ntokens=950.7, nsentences=32, sample_size=950.7, sample_size_v1=0, sample_size_v2=0, ppl=2.28, wps=251.1, ups=0.26, wpb=950.7, bsz=32, num_updates=33690, lr=3.74056e-06, gnorm=19.133, clip=100, loss_scale=32, train_wall=38, gb_free=9, wall=130001
2023-05-22 06:04:42 - progress_bar.py[line:272] - INFO: epoch 020:    853 / 1732 loss=2.406, loss_v1=0, loss_v2=0, nll_loss=1.208, ntokens=1006.3, nsentences=32, sample_size=1006.3, sample_size_v1=0, sample_size_v2=0, ppl=2.31, wps=264.5, ups=0.26, wpb=1006.3, bsz=32, num_updates=33700, lr=3.73851e-06, gnorm=16.769, clip=100, loss_scale=32, train_wall=38, gb_free=8.3, wall=130039
2023-05-22 06:05:20 - progress_bar.py[line:272] - INFO: epoch 020:    863 / 1732 loss=2.411, loss_v1=0, loss_v2=0, nll_loss=1.212, ntokens=933.3, nsentences=32, sample_size=933.3, sample_size_v1=0, sample_size_v2=0, ppl=2.32, wps=246.6, ups=0.26, wpb=933.3, bsz=32, num_updates=33710, lr=3.73646e-06, gnorm=19.493, clip=100, loss_scale=32, train_wall=38, gb_free=8.6, wall=130077
2023-05-22 06:05:57 - progress_bar.py[line:272] - INFO: epoch 020:    873 / 1732 loss=2.394, loss_v1=0, loss_v2=0, nll_loss=1.192, ntokens=966.4, nsentences=32, sample_size=966.4, sample_size_v1=0, sample_size_v2=0, ppl=2.28, wps=255.8, ups=0.26, wpb=966.4, bsz=32, num_updates=33720, lr=3.73441e-06, gnorm=16.535, clip=100, loss_scale=32, train_wall=38, gb_free=8.6, wall=130114
2023-05-22 06:06:35 - progress_bar.py[line:272] - INFO: epoch 020:    883 / 1732 loss=2.347, loss_v1=0, loss_v2=0, nll_loss=1.141, ntokens=985.5, nsentences=32, sample_size=985.5, sample_size_v1=0, sample_size_v2=0, ppl=2.21, wps=258, ups=0.26, wpb=985.5, bsz=32, num_updates=33730, lr=3.73237e-06, gnorm=17.482, clip=100, loss_scale=32, train_wall=38, gb_free=8.5, wall=130153
2023-05-22 06:07:13 - progress_bar.py[line:272] - INFO: epoch 020:    893 / 1732 loss=2.363, loss_v1=0, loss_v2=0, nll_loss=1.16, ntokens=1009.8, nsentences=32, sample_size=1009.8, sample_size_v1=0, sample_size_v2=0, ppl=2.23, wps=265.7, ups=0.26, wpb=1009.8, bsz=32, num_updates=33740, lr=3.73032e-06, gnorm=15.376, clip=100, loss_scale=32, train_wall=38, gb_free=8.3, wall=130191
2023-05-22 06:07:51 - progress_bar.py[line:272] - INFO: epoch 020:    903 / 1732 loss=2.352, loss_v1=0, loss_v2=0, nll_loss=1.147, ntokens=1049.7, nsentences=32, sample_size=1049.7, sample_size_v1=0, sample_size_v2=0, ppl=2.22, wps=276.5, ups=0.26, wpb=1049.7, bsz=32, num_updates=33750, lr=3.72827e-06, gnorm=15.518, clip=100, loss_scale=32, train_wall=38, gb_free=8.7, wall=130229
2023-05-22 06:08:29 - progress_bar.py[line:272] - INFO: epoch 020:    913 / 1732 loss=2.444, loss_v1=0, loss_v2=0, nll_loss=1.251, ntokens=930.6, nsentences=32, sample_size=930.6, sample_size_v1=0, sample_size_v2=0, ppl=2.38, wps=244.8, ups=0.26, wpb=930.6, bsz=32, num_updates=33760, lr=3.72622e-06, gnorm=18.355, clip=100, loss_scale=32, train_wall=38, gb_free=8.2, wall=130267
2023-05-22 06:09:08 - progress_bar.py[line:272] - INFO: epoch 020:    923 / 1732 loss=2.372, loss_v1=0, loss_v2=0, nll_loss=1.17, ntokens=1023.3, nsentences=32, sample_size=1023.3, sample_size_v1=0, sample_size_v2=0, ppl=2.25, wps=266.4, ups=0.26, wpb=1023.3, bsz=32, num_updates=33770, lr=3.72418e-06, gnorm=16.279, clip=100, loss_scale=32, train_wall=38, gb_free=8.3, wall=130305
2023-05-22 06:09:47 - progress_bar.py[line:272] - INFO: epoch 020:    933 / 1732 loss=2.378, loss_v1=0, loss_v2=0, nll_loss=1.176, ntokens=1034.6, nsentences=32, sample_size=1034.6, sample_size_v1=0, sample_size_v2=0, ppl=2.26, wps=267.6, ups=0.26, wpb=1034.6, bsz=32, num_updates=33780, lr=3.72213e-06, gnorm=17.66, clip=100, loss_scale=32, train_wall=39, gb_free=8.2, wall=130344
2023-05-22 06:10:25 - progress_bar.py[line:272] - INFO: epoch 020:    943 / 1732 loss=2.399, loss_v1=0, loss_v2=0, nll_loss=1.198, ntokens=1054.1, nsentences=32, sample_size=1054.1, sample_size_v1=0, sample_size_v2=0, ppl=2.29, wps=273.7, ups=0.26, wpb=1054.1, bsz=32, num_updates=33790, lr=3.72008e-06, gnorm=17.008, clip=100, loss_scale=32, train_wall=38, gb_free=8.4, wall=130382
2023-05-22 06:11:04 - progress_bar.py[line:272] - INFO: epoch 020:    953 / 1732 loss=2.387, loss_v1=0, loss_v2=0, nll_loss=1.185, ntokens=1032.2, nsentences=32, sample_size=1032.2, sample_size_v1=0, sample_size_v2=0, ppl=2.27, wps=267.2, ups=0.26, wpb=1032.2, bsz=32, num_updates=33800, lr=3.71804e-06, gnorm=16.525, clip=100, loss_scale=32, train_wall=39, gb_free=8.1, wall=130421
2023-05-22 06:11:42 - progress_bar.py[line:272] - INFO: epoch 020:    963 / 1732 loss=2.394, loss_v1=0, loss_v2=0, nll_loss=1.193, ntokens=1069.2, nsentences=32, sample_size=1069.2, sample_size_v1=0, sample_size_v2=0, ppl=2.29, wps=277.7, ups=0.26, wpb=1069.2, bsz=32, num_updates=33810, lr=3.71599e-06, gnorm=18.245, clip=100, loss_scale=32, train_wall=38, gb_free=8.4, wall=130459
2023-05-22 06:12:21 - progress_bar.py[line:272] - INFO: epoch 020:    973 / 1732 loss=2.402, loss_v1=0, loss_v2=0, nll_loss=1.204, ntokens=1034.1, nsentences=32, sample_size=1034.1, sample_size_v1=0, sample_size_v2=0, ppl=2.3, wps=268, ups=0.26, wpb=1034.1, bsz=32, num_updates=33820, lr=3.71394e-06, gnorm=17.163, clip=100, loss_scale=32, train_wall=39, gb_free=8.3, wall=130498
2023-05-22 06:13:00 - progress_bar.py[line:272] - INFO: epoch 020:    983 / 1732 loss=2.396, loss_v1=0, loss_v2=0, nll_loss=1.197, ntokens=1026.6, nsentences=32, sample_size=1026.6, sample_size_v1=0, sample_size_v2=0, ppl=2.29, wps=265.1, ups=0.26, wpb=1026.6, bsz=32, num_updates=33830, lr=3.71189e-06, gnorm=17.401, clip=100, loss_scale=32, train_wall=39, gb_free=8.3, wall=130537
2023-05-22 06:13:38 - progress_bar.py[line:272] - INFO: epoch 020:    993 / 1732 loss=2.394, loss_v1=0, loss_v2=0, nll_loss=1.195, ntokens=1041.8, nsentences=32, sample_size=1041.8, sample_size_v1=0, sample_size_v2=0, ppl=2.29, wps=270.2, ups=0.26, wpb=1041.8, bsz=32, num_updates=33840, lr=3.70985e-06, gnorm=17.039, clip=100, loss_scale=32, train_wall=39, gb_free=8.4, wall=130575
2023-05-22 06:14:17 - progress_bar.py[line:272] - INFO: epoch 020:   1003 / 1732 loss=2.372, loss_v1=0, loss_v2=0, nll_loss=1.169, ntokens=1018, nsentences=32, sample_size=1018, sample_size_v1=0, sample_size_v2=0, ppl=2.25, wps=264.6, ups=0.26, wpb=1018, bsz=32, num_updates=33850, lr=3.7078e-06, gnorm=17.318, clip=100, loss_scale=32, train_wall=38, gb_free=8.4, wall=130614
2023-05-22 06:14:55 - progress_bar.py[line:272] - INFO: epoch 020:   1013 / 1732 loss=2.385, loss_v1=0, loss_v2=0, nll_loss=1.184, ntokens=965, nsentences=32, sample_size=965, sample_size_v1=0, sample_size_v2=0, ppl=2.27, wps=251.9, ups=0.26, wpb=965, bsz=32, num_updates=33860, lr=3.70575e-06, gnorm=18.233, clip=100, loss_scale=32, train_wall=38, gb_free=9.1, wall=130652
2023-05-22 06:15:34 - progress_bar.py[line:272] - INFO: epoch 020:   1023 / 1732 loss=2.377, loss_v1=0, loss_v2=0, nll_loss=1.175, ntokens=1087.1, nsentences=32, sample_size=1087.1, sample_size_v1=0, sample_size_v2=0, ppl=2.26, wps=281.2, ups=0.26, wpb=1087.1, bsz=32, num_updates=33870, lr=3.7037e-06, gnorm=15.405, clip=100, loss_scale=32, train_wall=39, gb_free=8.1, wall=130691
2023-05-22 06:16:12 - progress_bar.py[line:272] - INFO: epoch 020:   1033 / 1732 loss=2.384, loss_v1=0, loss_v2=0, nll_loss=1.185, ntokens=1100.3, nsentences=32, sample_size=1100.3, sample_size_v1=0, sample_size_v2=0, ppl=2.27, wps=284.6, ups=0.26, wpb=1100.3, bsz=32, num_updates=33880, lr=3.70166e-06, gnorm=14.932, clip=100, loss_scale=32, train_wall=39, gb_free=8.8, wall=130729
2023-05-22 06:16:51 - progress_bar.py[line:272] - INFO: epoch 020:   1043 / 1732 loss=2.386, loss_v1=0, loss_v2=0, nll_loss=1.186, ntokens=1068.2, nsentences=32, sample_size=1068.2, sample_size_v1=0, sample_size_v2=0, ppl=2.27, wps=276.7, ups=0.26, wpb=1068.2, bsz=32, num_updates=33890, lr=3.69961e-06, gnorm=17.227, clip=100, loss_scale=32, train_wall=39, gb_free=8.3, wall=130768
2023-05-22 06:17:29 - progress_bar.py[line:272] - INFO: epoch 020:   1053 / 1732 loss=2.389, loss_v1=0, loss_v2=0, nll_loss=1.189, ntokens=1062.8, nsentences=32, sample_size=1062.8, sample_size_v1=0, sample_size_v2=0, ppl=2.28, wps=276.8, ups=0.26, wpb=1062.8, bsz=32, num_updates=33900, lr=3.69756e-06, gnorm=17.075, clip=100, loss_scale=32, train_wall=38, gb_free=8.6, wall=130806
2023-05-22 06:18:08 - progress_bar.py[line:272] - INFO: epoch 020:   1063 / 1732 loss=2.379, loss_v1=0, loss_v2=0, nll_loss=1.178, ntokens=1030.9, nsentences=32, sample_size=1030.9, sample_size_v1=0, sample_size_v2=0, ppl=2.26, wps=267.5, ups=0.26, wpb=1030.9, bsz=32, num_updates=33910, lr=3.69551e-06, gnorm=18.122, clip=100, loss_scale=32, train_wall=38, gb_free=8.3, wall=130845
2023-05-22 06:18:46 - progress_bar.py[line:272] - INFO: epoch 020:   1073 / 1732 loss=2.402, loss_v1=0, loss_v2=0, nll_loss=1.201, ntokens=999.3, nsentences=32, sample_size=999.3, sample_size_v1=0, sample_size_v2=0, ppl=2.3, wps=259, ups=0.26, wpb=999.3, bsz=32, num_updates=33920, lr=3.69347e-06, gnorm=17.082, clip=100, loss_scale=32, train_wall=39, gb_free=8.5, wall=130884
2023-05-22 06:19:25 - progress_bar.py[line:272] - INFO: epoch 020:   1083 / 1732 loss=2.4, loss_v1=0, loss_v2=0, nll_loss=1.201, ntokens=1054.9, nsentences=32, sample_size=1054.9, sample_size_v1=0, sample_size_v2=0, ppl=2.3, wps=272.1, ups=0.26, wpb=1054.9, bsz=32, num_updates=33930, lr=3.69142e-06, gnorm=16.944, clip=100, loss_scale=32, train_wall=39, gb_free=7.6, wall=130922
2023-05-22 06:20:04 - progress_bar.py[line:272] - INFO: epoch 020:   1093 / 1732 loss=2.383, loss_v1=0, loss_v2=0, nll_loss=1.182, ntokens=1060.6, nsentences=32, sample_size=1060.6, sample_size_v1=0, sample_size_v2=0, ppl=2.27, wps=274.8, ups=0.26, wpb=1060.6, bsz=32, num_updates=33940, lr=3.68937e-06, gnorm=19.085, clip=100, loss_scale=64, train_wall=39, gb_free=8.3, wall=130961
2023-05-22 06:20:07 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2023-05-22 06:20:46 - progress_bar.py[line:272] - INFO: epoch 020:   1104 / 1732 loss=2.393, loss_v1=0, loss_v2=0, nll_loss=1.194, ntokens=1042.3, nsentences=32, sample_size=1042.3, sample_size_v1=0, sample_size_v2=0, ppl=2.29, wps=246.9, ups=0.24, wpb=1042.3, bsz=32, num_updates=33950, lr=3.68732e-06, gnorm=17.35, clip=100, loss_scale=32, train_wall=42, gb_free=8.4, wall=131003
2023-05-22 06:21:24 - progress_bar.py[line:272] - INFO: epoch 020:   1114 / 1732 loss=2.392, loss_v1=0, loss_v2=0, nll_loss=1.19, ntokens=1000.7, nsentences=32, sample_size=1000.7, sample_size_v1=0, sample_size_v2=0, ppl=2.28, wps=260.1, ups=0.26, wpb=1000.7, bsz=32, num_updates=33960, lr=3.68528e-06, gnorm=17.491, clip=100, loss_scale=32, train_wall=38, gb_free=8.5, wall=131042
2023-05-22 06:22:03 - progress_bar.py[line:272] - INFO: epoch 020:   1124 / 1732 loss=2.387, loss_v1=0, loss_v2=0, nll_loss=1.185, ntokens=989.1, nsentences=32, sample_size=989.1, sample_size_v1=0, sample_size_v2=0, ppl=2.27, wps=257.2, ups=0.26, wpb=989.1, bsz=32, num_updates=33970, lr=3.68323e-06, gnorm=16.596, clip=100, loss_scale=32, train_wall=38, gb_free=8.4, wall=131080
2023-05-22 06:22:41 - progress_bar.py[line:272] - INFO: epoch 020:   1134 / 1732 loss=2.398, loss_v1=0, loss_v2=0, nll_loss=1.198, ntokens=968.8, nsentences=32, sample_size=968.8, sample_size_v1=0, sample_size_v2=0, ppl=2.29, wps=252.2, ups=0.26, wpb=968.8, bsz=32, num_updates=33980, lr=3.68118e-06, gnorm=18.387, clip=100, loss_scale=32, train_wall=38, gb_free=8.6, wall=131118
2023-05-22 06:23:20 - progress_bar.py[line:272] - INFO: epoch 020:   1144 / 1732 loss=2.394, loss_v1=0, loss_v2=0, nll_loss=1.194, ntokens=1034.3, nsentences=32, sample_size=1034.3, sample_size_v1=0, sample_size_v2=0, ppl=2.29, wps=268.1, ups=0.26, wpb=1034.3, bsz=32, num_updates=33990, lr=3.67914e-06, gnorm=19.033, clip=100, loss_scale=32, train_wall=39, gb_free=8.7, wall=131157
2023-05-22 06:23:58 - progress_bar.py[line:272] - INFO: epoch 020:   1154 / 1732 loss=2.389, loss_v1=0, loss_v2=0, nll_loss=1.188, ntokens=1025.8, nsentences=32, sample_size=1025.8, sample_size_v1=0, sample_size_v2=0, ppl=2.28, wps=265.8, ups=0.26, wpb=1025.8, bsz=32, num_updates=34000, lr=3.67709e-06, gnorm=17.957, clip=100, loss_scale=32, train_wall=39, gb_free=7.4, wall=131196
2023-05-22 06:24:37 - progress_bar.py[line:272] - INFO: epoch 020:   1164 / 1732 loss=2.365, loss_v1=0, loss_v2=0, nll_loss=1.163, ntokens=1008, nsentences=32, sample_size=1008, sample_size_v1=0, sample_size_v2=0, ppl=2.24, wps=261.4, ups=0.26, wpb=1008, bsz=32, num_updates=34010, lr=3.67504e-06, gnorm=17.552, clip=100, loss_scale=32, train_wall=39, gb_free=8.7, wall=131234
2023-05-22 06:25:16 - progress_bar.py[line:272] - INFO: epoch 020:   1174 / 1732 loss=2.385, loss_v1=0, loss_v2=0, nll_loss=1.184, ntokens=1081.1, nsentences=32, sample_size=1081.1, sample_size_v1=0, sample_size_v2=0, ppl=2.27, wps=279.4, ups=0.26, wpb=1081.1, bsz=32, num_updates=34020, lr=3.67299e-06, gnorm=18.087, clip=100, loss_scale=32, train_wall=39, gb_free=8.1, wall=131273
2023-05-22 06:25:54 - progress_bar.py[line:272] - INFO: epoch 020:   1184 / 1732 loss=2.375, loss_v1=0, loss_v2=0, nll_loss=1.172, ntokens=962, nsentences=32, sample_size=962, sample_size_v1=0, sample_size_v2=0, ppl=2.25, wps=252.1, ups=0.26, wpb=962, bsz=32, num_updates=34030, lr=3.67095e-06, gnorm=17.415, clip=100, loss_scale=32, train_wall=38, gb_free=8.8, wall=131311
2023-05-22 06:26:32 - progress_bar.py[line:272] - INFO: epoch 020:   1194 / 1732 loss=2.399, loss_v1=0, loss_v2=0, nll_loss=1.201, ntokens=1042.6, nsentences=32, sample_size=1042.6, sample_size_v1=0, sample_size_v2=0, ppl=2.3, wps=271.8, ups=0.26, wpb=1042.6, bsz=32, num_updates=34040, lr=3.6689e-06, gnorm=18.163, clip=100, loss_scale=32, train_wall=38, gb_free=8.7, wall=131349
2023-05-22 06:27:12 - progress_bar.py[line:272] - INFO: epoch 020:   1204 / 1732 loss=2.347, loss_v1=0, loss_v2=0, nll_loss=1.141, ntokens=1150.2, nsentences=32, sample_size=1150.2, sample_size_v1=0, sample_size_v2=0, ppl=2.2, wps=292.5, ups=0.25, wpb=1150.2, bsz=32, num_updates=34050, lr=3.66685e-06, gnorm=15.928, clip=100, loss_scale=32, train_wall=39, gb_free=8.4, wall=131389
2023-05-22 06:27:50 - progress_bar.py[line:272] - INFO: epoch 020:   1214 / 1732 loss=2.39, loss_v1=0, loss_v2=0, nll_loss=1.19, ntokens=996.3, nsentences=32, sample_size=996.3, sample_size_v1=0, sample_size_v2=0, ppl=2.28, wps=259.9, ups=0.26, wpb=996.3, bsz=32, num_updates=34060, lr=3.6648e-06, gnorm=18.009, clip=100, loss_scale=32, train_wall=38, gb_free=8.9, wall=131427
2023-05-22 06:28:28 - progress_bar.py[line:272] - INFO: epoch 020:   1224 / 1732 loss=2.408, loss_v1=0, loss_v2=0, nll_loss=1.209, ntokens=1056.3, nsentences=32, sample_size=1056.3, sample_size_v1=0, sample_size_v2=0, ppl=2.31, wps=273.8, ups=0.26, wpb=1056.3, bsz=32, num_updates=34070, lr=3.66276e-06, gnorm=18.377, clip=100, loss_scale=32, train_wall=39, gb_free=8.7, wall=131466
2023-05-22 06:29:07 - progress_bar.py[line:272] - INFO: epoch 020:   1234 / 1732 loss=2.376, loss_v1=0, loss_v2=0, nll_loss=1.173, ntokens=1012.2, nsentences=32, sample_size=1012.2, sample_size_v1=0, sample_size_v2=0, ppl=2.25, wps=264.2, ups=0.26, wpb=1012.2, bsz=32, num_updates=34080, lr=3.66071e-06, gnorm=16.643, clip=100, loss_scale=32, train_wall=38, gb_free=8.7, wall=131504
2023-05-22 06:29:45 - progress_bar.py[line:272] - INFO: epoch 020:   1244 / 1732 loss=2.32, loss_v1=0, loss_v2=0, nll_loss=1.112, ntokens=1090.2, nsentences=32, sample_size=1090.2, sample_size_v1=0, sample_size_v2=0, ppl=2.16, wps=282.6, ups=0.26, wpb=1090.2, bsz=32, num_updates=34090, lr=3.65866e-06, gnorm=16.395, clip=100, loss_scale=32, train_wall=39, gb_free=8.6, wall=131543
2023-05-22 06:30:24 - progress_bar.py[line:272] - INFO: epoch 020:   1254 / 1732 loss=2.351, loss_v1=0, loss_v2=0, nll_loss=1.147, ntokens=1076, nsentences=32, sample_size=1076, sample_size_v1=0, sample_size_v2=0, ppl=2.21, wps=279.6, ups=0.26, wpb=1076, bsz=32, num_updates=34100, lr=3.65661e-06, gnorm=16.771, clip=100, loss_scale=32, train_wall=38, gb_free=8.8, wall=131581
2023-05-22 06:31:03 - progress_bar.py[line:272] - INFO: epoch 020:   1264 / 1732 loss=2.393, loss_v1=0, loss_v2=0, nll_loss=1.194, ntokens=1095.2, nsentences=32, sample_size=1095.2, sample_size_v1=0, sample_size_v2=0, ppl=2.29, wps=283, ups=0.26, wpb=1095.2, bsz=32, num_updates=34110, lr=3.65457e-06, gnorm=17.161, clip=100, loss_scale=32, train_wall=39, gb_free=7.8, wall=131620
2023-05-22 06:31:41 - progress_bar.py[line:272] - INFO: epoch 020:   1274 / 1732 loss=2.388, loss_v1=0, loss_v2=0, nll_loss=1.188, ntokens=1014.1, nsentences=32, sample_size=1014.1, sample_size_v1=0, sample_size_v2=0, ppl=2.28, wps=264.2, ups=0.26, wpb=1014.1, bsz=32, num_updates=34120, lr=3.65252e-06, gnorm=18.533, clip=100, loss_scale=32, train_wall=38, gb_free=8.1, wall=131658
2023-05-22 06:32:20 - progress_bar.py[line:272] - INFO: epoch 020:   1284 / 1732 loss=2.379, loss_v1=0, loss_v2=0, nll_loss=1.177, ntokens=1057.3, nsentences=32, sample_size=1057.3, sample_size_v1=0, sample_size_v2=0, ppl=2.26, wps=271.8, ups=0.26, wpb=1057.3, bsz=32, num_updates=34130, lr=3.65047e-06, gnorm=16.666, clip=100, loss_scale=32, train_wall=39, gb_free=8.8, wall=131697
2023-05-22 06:32:59 - progress_bar.py[line:272] - INFO: epoch 020:   1294 / 1732 loss=2.362, loss_v1=0, loss_v2=0, nll_loss=1.158, ntokens=1109.4, nsentences=32, sample_size=1109.4, sample_size_v1=0, sample_size_v2=0, ppl=2.23, wps=286, ups=0.26, wpb=1109.4, bsz=32, num_updates=34140, lr=3.64842e-06, gnorm=14.456, clip=100, loss_scale=32, train_wall=39, gb_free=8.3, wall=131736
2023-05-22 06:33:38 - progress_bar.py[line:272] - INFO: epoch 020:   1304 / 1732 loss=2.39, loss_v1=0, loss_v2=0, nll_loss=1.19, ntokens=1090.1, nsentences=32, sample_size=1090.1, sample_size_v1=0, sample_size_v2=0, ppl=2.28, wps=279.5, ups=0.26, wpb=1090.1, bsz=32, num_updates=34150, lr=3.64638e-06, gnorm=16.839, clip=100, loss_scale=32, train_wall=39, gb_free=8.3, wall=131775
2023-05-22 06:34:17 - progress_bar.py[line:272] - INFO: epoch 020:   1314 / 1732 loss=2.395, loss_v1=0, loss_v2=0, nll_loss=1.194, ntokens=1051.4, nsentences=32, sample_size=1051.4, sample_size_v1=0, sample_size_v2=0, ppl=2.29, wps=269.8, ups=0.26, wpb=1051.4, bsz=32, num_updates=34160, lr=3.64433e-06, gnorm=16.634, clip=100, loss_scale=32, train_wall=39, gb_free=8, wall=131814
2023-05-22 06:34:56 - progress_bar.py[line:272] - INFO: epoch 020:   1324 / 1732 loss=2.356, loss_v1=0, loss_v2=0, nll_loss=1.152, ntokens=1117, nsentences=32, sample_size=1117, sample_size_v1=0, sample_size_v2=0, ppl=2.22, wps=286, ups=0.26, wpb=1117, bsz=32, num_updates=34170, lr=3.64228e-06, gnorm=15.996, clip=100, loss_scale=32, train_wall=39, gb_free=8.5, wall=131853
2023-05-22 06:35:34 - progress_bar.py[line:272] - INFO: epoch 020:   1334 / 1732 loss=2.354, loss_v1=0, loss_v2=0, nll_loss=1.148, ntokens=1097.8, nsentences=32, sample_size=1097.8, sample_size_v1=0, sample_size_v2=0, ppl=2.22, wps=283.6, ups=0.26, wpb=1097.8, bsz=32, num_updates=34180, lr=3.64024e-06, gnorm=19.069, clip=100, loss_scale=32, train_wall=39, gb_free=8.8, wall=131892
2023-05-22 06:36:14 - progress_bar.py[line:272] - INFO: epoch 020:   1344 / 1732 loss=2.359, loss_v1=0, loss_v2=0, nll_loss=1.155, ntokens=1201.2, nsentences=32, sample_size=1201.2, sample_size_v1=0, sample_size_v2=0, ppl=2.23, wps=307, ups=0.26, wpb=1201.2, bsz=32, num_updates=34190, lr=3.63819e-06, gnorm=19.408, clip=100, loss_scale=32, train_wall=39, gb_free=8, wall=131931
2023-05-22 06:36:53 - progress_bar.py[line:272] - INFO: epoch 020:   1354 / 1732 loss=2.372, loss_v1=0, loss_v2=0, nll_loss=1.17, ntokens=1101.2, nsentences=32, sample_size=1101.2, sample_size_v1=0, sample_size_v2=0, ppl=2.25, wps=281.7, ups=0.26, wpb=1101.2, bsz=32, num_updates=34200, lr=3.63614e-06, gnorm=17.865, clip=100, loss_scale=32, train_wall=39, gb_free=8.6, wall=131970
2023-05-22 06:37:32 - progress_bar.py[line:272] - INFO: epoch 020:   1364 / 1732 loss=2.344, loss_v1=0, loss_v2=0, nll_loss=1.138, ntokens=1115.3, nsentences=32, sample_size=1115.3, sample_size_v1=0, sample_size_v2=0, ppl=2.2, wps=286, ups=0.26, wpb=1115.3, bsz=32, num_updates=34210, lr=3.63409e-06, gnorm=16.316, clip=100, loss_scale=32, train_wall=39, gb_free=8.2, wall=132009
2023-05-22 06:38:10 - progress_bar.py[line:272] - INFO: epoch 020:   1374 / 1732 loss=2.403, loss_v1=0, loss_v2=0, nll_loss=1.205, ntokens=1075.1, nsentences=32, sample_size=1075.1, sample_size_v1=0, sample_size_v2=0, ppl=2.3, wps=278.6, ups=0.26, wpb=1075.1, bsz=32, num_updates=34220, lr=3.63205e-06, gnorm=17.708, clip=100, loss_scale=32, train_wall=39, gb_free=8.9, wall=132047
2023-05-22 06:38:49 - progress_bar.py[line:272] - INFO: epoch 020:   1384 / 1732 loss=2.387, loss_v1=0, loss_v2=0, nll_loss=1.186, ntokens=1167.1, nsentences=32, sample_size=1167.1, sample_size_v1=0, sample_size_v2=0, ppl=2.27, wps=300.5, ups=0.26, wpb=1167.1, bsz=32, num_updates=34230, lr=3.63e-06, gnorm=16.441, clip=100, loss_scale=32, train_wall=39, gb_free=7.9, wall=132086
2023-05-22 06:39:28 - progress_bar.py[line:272] - INFO: epoch 020:   1394 / 1732 loss=2.379, loss_v1=0, loss_v2=0, nll_loss=1.177, ntokens=1039.3, nsentences=32, sample_size=1039.3, sample_size_v1=0, sample_size_v2=0, ppl=2.26, wps=268.9, ups=0.26, wpb=1039.3, bsz=32, num_updates=34240, lr=3.62795e-06, gnorm=18.84, clip=100, loss_scale=32, train_wall=39, gb_free=7.7, wall=132125
2023-05-22 06:40:07 - progress_bar.py[line:272] - INFO: epoch 020:   1404 / 1732 loss=2.354, loss_v1=0, loss_v2=0, nll_loss=1.149, ntokens=1161.9, nsentences=32, sample_size=1161.9, sample_size_v1=0, sample_size_v2=0, ppl=2.22, wps=298.3, ups=0.26, wpb=1161.9, bsz=32, num_updates=34250, lr=3.6259e-06, gnorm=17.68, clip=100, loss_scale=32, train_wall=39, gb_free=7.1, wall=132164
2023-05-22 06:40:46 - progress_bar.py[line:272] - INFO: epoch 020:   1414 / 1732 loss=2.39, loss_v1=0, loss_v2=0, nll_loss=1.189, ntokens=1276, nsentences=32, sample_size=1276, sample_size_v1=0, sample_size_v2=0, ppl=2.28, wps=325.4, ups=0.25, wpb=1276, bsz=32, num_updates=34260, lr=3.62386e-06, gnorm=16.071, clip=100, loss_scale=32, train_wall=39, gb_free=7.7, wall=132203
2023-05-22 06:41:25 - progress_bar.py[line:272] - INFO: epoch 020:   1424 / 1732 loss=2.358, loss_v1=0, loss_v2=0, nll_loss=1.153, ntokens=1261.9, nsentences=32, sample_size=1261.9, sample_size_v1=0, sample_size_v2=0, ppl=2.22, wps=321.3, ups=0.25, wpb=1261.9, bsz=32, num_updates=34270, lr=3.62181e-06, gnorm=15.255, clip=100, loss_scale=32, train_wall=39, gb_free=7.7, wall=132242
2023-05-22 06:42:04 - progress_bar.py[line:272] - INFO: epoch 020:   1434 / 1732 loss=2.359, loss_v1=0, loss_v2=0, nll_loss=1.154, ntokens=1196.2, nsentences=32, sample_size=1196.2, sample_size_v1=0, sample_size_v2=0, ppl=2.22, wps=308.4, ups=0.26, wpb=1196.2, bsz=32, num_updates=34280, lr=3.61976e-06, gnorm=15.775, clip=100, loss_scale=32, train_wall=39, gb_free=8.2, wall=132281
2023-05-22 06:42:43 - progress_bar.py[line:272] - INFO: epoch 020:   1444 / 1732 loss=2.378, loss_v1=0, loss_v2=0, nll_loss=1.177, ntokens=1129.1, nsentences=32, sample_size=1129.1, sample_size_v1=0, sample_size_v2=0, ppl=2.26, wps=292.2, ups=0.26, wpb=1129.1, bsz=32, num_updates=34290, lr=3.61771e-06, gnorm=16.584, clip=100, loss_scale=32, train_wall=39, gb_free=7.7, wall=132320
2023-05-22 06:43:21 - progress_bar.py[line:272] - INFO: epoch 020:   1454 / 1732 loss=2.381, loss_v1=0, loss_v2=0, nll_loss=1.179, ntokens=1122, nsentences=32, sample_size=1122, sample_size_v1=0, sample_size_v2=0, ppl=2.26, wps=290.1, ups=0.26, wpb=1122, bsz=32, num_updates=34300, lr=3.61567e-06, gnorm=16.157, clip=100, loss_scale=32, train_wall=39, gb_free=8, wall=132358
2023-05-22 06:44:00 - progress_bar.py[line:272] - INFO: epoch 020:   1464 / 1732 loss=2.337, loss_v1=0, loss_v2=0, nll_loss=1.131, ntokens=1182.3, nsentences=32, sample_size=1182.3, sample_size_v1=0, sample_size_v2=0, ppl=2.19, wps=303, ups=0.26, wpb=1182.3, bsz=32, num_updates=34310, lr=3.61362e-06, gnorm=15.44, clip=100, loss_scale=32, train_wall=39, gb_free=8.5, wall=132398
2023-05-22 06:44:39 - progress_bar.py[line:272] - INFO: epoch 020:   1474 / 1732 loss=2.369, loss_v1=0, loss_v2=0, nll_loss=1.167, ntokens=1095.3, nsentences=32, sample_size=1095.3, sample_size_v1=0, sample_size_v2=0, ppl=2.24, wps=284, ups=0.26, wpb=1095.3, bsz=32, num_updates=34320, lr=3.61157e-06, gnorm=17.782, clip=100, loss_scale=32, train_wall=39, gb_free=8.6, wall=132436
2023-05-22 06:45:18 - progress_bar.py[line:272] - INFO: epoch 020:   1484 / 1732 loss=2.396, loss_v1=0, loss_v2=0, nll_loss=1.195, ntokens=1096.5, nsentences=32, sample_size=1096.5, sample_size_v1=0, sample_size_v2=0, ppl=2.29, wps=283.6, ups=0.26, wpb=1096.5, bsz=32, num_updates=34330, lr=3.60952e-06, gnorm=19.116, clip=100, loss_scale=32, train_wall=39, gb_free=7.9, wall=132475
2023-05-22 06:45:56 - progress_bar.py[line:272] - INFO: epoch 020:   1494 / 1732 loss=2.364, loss_v1=0, loss_v2=0, nll_loss=1.161, ntokens=1106.4, nsentences=32, sample_size=1106.4, sample_size_v1=0, sample_size_v2=0, ppl=2.24, wps=284.4, ups=0.26, wpb=1106.4, bsz=32, num_updates=34340, lr=3.60748e-06, gnorm=16.83, clip=100, loss_scale=32, train_wall=39, gb_free=8.2, wall=132514
2023-05-22 06:46:35 - progress_bar.py[line:272] - INFO: epoch 020:   1504 / 1732 loss=2.322, loss_v1=0, loss_v2=0, nll_loss=1.113, ntokens=1153.1, nsentences=32, sample_size=1153.1, sample_size_v1=0, sample_size_v2=0, ppl=2.16, wps=295.4, ups=0.26, wpb=1153.1, bsz=32, num_updates=34350, lr=3.60543e-06, gnorm=15.781, clip=100, loss_scale=32, train_wall=39, gb_free=8.1, wall=132553
2023-05-22 06:47:14 - progress_bar.py[line:272] - INFO: epoch 020:   1514 / 1732 loss=2.379, loss_v1=0, loss_v2=0, nll_loss=1.178, ntokens=1041.2, nsentences=32, sample_size=1041.2, sample_size_v1=0, sample_size_v2=0, ppl=2.26, wps=270.6, ups=0.26, wpb=1041.2, bsz=32, num_updates=34360, lr=3.60338e-06, gnorm=16.319, clip=100, loss_scale=32, train_wall=38, gb_free=8.9, wall=132591
2023-05-22 06:47:52 - progress_bar.py[line:272] - INFO: epoch 020:   1524 / 1732 loss=2.409, loss_v1=0, loss_v2=0, nll_loss=1.212, ntokens=1034.8, nsentences=32, sample_size=1034.8, sample_size_v1=0, sample_size_v2=0, ppl=2.32, wps=268.8, ups=0.26, wpb=1034.8, bsz=32, num_updates=34370, lr=3.60133e-06, gnorm=17.084, clip=100, loss_scale=32, train_wall=38, gb_free=7.5, wall=132630
2023-05-22 06:48:31 - progress_bar.py[line:272] - INFO: epoch 020:   1534 / 1732 loss=2.38, loss_v1=0, loss_v2=0, nll_loss=1.178, ntokens=1092.4, nsentences=32, sample_size=1092.4, sample_size_v1=0, sample_size_v2=0, ppl=2.26, wps=280.9, ups=0.26, wpb=1092.4, bsz=32, num_updates=34380, lr=3.59929e-06, gnorm=16.907, clip=100, loss_scale=32, train_wall=39, gb_free=8.3, wall=132669
2023-05-22 06:49:10 - progress_bar.py[line:272] - INFO: epoch 020:   1544 / 1732 loss=2.359, loss_v1=0, loss_v2=0, nll_loss=1.154, ntokens=1091.8, nsentences=32, sample_size=1091.8, sample_size_v1=0, sample_size_v2=0, ppl=2.23, wps=281.8, ups=0.26, wpb=1091.8, bsz=32, num_updates=34390, lr=3.59724e-06, gnorm=17.432, clip=100, loss_scale=32, train_wall=39, gb_free=8.7, wall=132707
2023-05-22 06:49:49 - progress_bar.py[line:272] - INFO: epoch 020:   1554 / 1732 loss=2.357, loss_v1=0, loss_v2=0, nll_loss=1.153, ntokens=1040, nsentences=32, sample_size=1040, sample_size_v1=0, sample_size_v2=0, ppl=2.22, wps=269, ups=0.26, wpb=1040, bsz=32, num_updates=34400, lr=3.59519e-06, gnorm=16.67, clip=100, loss_scale=32, train_wall=39, gb_free=8.7, wall=132746
2023-05-22 06:50:28 - progress_bar.py[line:272] - INFO: epoch 020:   1564 / 1732 loss=2.388, loss_v1=0, loss_v2=0, nll_loss=1.187, ntokens=1120.2, nsentences=32, sample_size=1120.2, sample_size_v1=0, sample_size_v2=0, ppl=2.28, wps=288.1, ups=0.26, wpb=1120.2, bsz=32, num_updates=34410, lr=3.59315e-06, gnorm=16.93, clip=100, loss_scale=32, train_wall=39, gb_free=8.8, wall=132785
2023-05-22 06:51:06 - progress_bar.py[line:272] - INFO: epoch 020:   1574 / 1732 loss=2.403, loss_v1=0, loss_v2=0, nll_loss=1.204, ntokens=1055.9, nsentences=32, sample_size=1055.9, sample_size_v1=0, sample_size_v2=0, ppl=2.3, wps=272.8, ups=0.26, wpb=1055.9, bsz=32, num_updates=34420, lr=3.5911e-06, gnorm=18.309, clip=100, loss_scale=32, train_wall=39, gb_free=8.3, wall=132824
2023-05-22 06:51:45 - progress_bar.py[line:272] - INFO: epoch 020:   1584 / 1732 loss=2.4, loss_v1=0, loss_v2=0, nll_loss=1.2, ntokens=1026.8, nsentences=32, sample_size=1026.8, sample_size_v1=0, sample_size_v2=0, ppl=2.3, wps=266.1, ups=0.26, wpb=1026.8, bsz=32, num_updates=34430, lr=3.58905e-06, gnorm=17.505, clip=100, loss_scale=32, train_wall=39, gb_free=7.9, wall=132862
2023-05-22 06:52:24 - progress_bar.py[line:272] - INFO: epoch 020:   1594 / 1732 loss=2.353, loss_v1=0, loss_v2=0, nll_loss=1.149, ntokens=1068.7, nsentences=32, sample_size=1068.7, sample_size_v1=0, sample_size_v2=0, ppl=2.22, wps=276.8, ups=0.26, wpb=1068.7, bsz=32, num_updates=34440, lr=3.587e-06, gnorm=16.887, clip=100, loss_scale=32, train_wall=39, gb_free=8.4, wall=132901
2023-05-22 06:53:02 - progress_bar.py[line:272] - INFO: epoch 020:   1604 / 1732 loss=2.354, loss_v1=0, loss_v2=0, nll_loss=1.151, ntokens=1089, nsentences=32, sample_size=1089, sample_size_v1=0, sample_size_v2=0, ppl=2.22, wps=282.4, ups=0.26, wpb=1089, bsz=32, num_updates=34450, lr=3.58496e-06, gnorm=16.713, clip=100, loss_scale=32, train_wall=39, gb_free=7.9, wall=132939
2023-05-22 06:53:18 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2023-05-22 06:53:45 - progress_bar.py[line:272] - INFO: epoch 020:   1615 / 1732 loss=2.329, loss_v1=0, loss_v2=0, nll_loss=1.122, ntokens=1177.5, nsentences=32, sample_size=1177.5, sample_size_v1=0, sample_size_v2=0, ppl=2.18, wps=275.6, ups=0.23, wpb=1177.5, bsz=32, num_updates=34460, lr=3.58291e-06, gnorm=16.14, clip=100, loss_scale=32, train_wall=43, gb_free=8.5, wall=132982
2023-05-22 06:54:24 - progress_bar.py[line:272] - INFO: epoch 020:   1625 / 1732 loss=2.367, loss_v1=0, loss_v2=0, nll_loss=1.165, ntokens=1075.4, nsentences=32, sample_size=1075.4, sample_size_v1=0, sample_size_v2=0, ppl=2.24, wps=277.6, ups=0.26, wpb=1075.4, bsz=32, num_updates=34470, lr=3.58086e-06, gnorm=17.786, clip=100, loss_scale=32, train_wall=39, gb_free=7.6, wall=133021
2023-05-22 06:55:02 - progress_bar.py[line:272] - INFO: epoch 020:   1635 / 1732 loss=2.344, loss_v1=0, loss_v2=0, nll_loss=1.14, ntokens=1182.6, nsentences=32, sample_size=1182.6, sample_size_v1=0, sample_size_v2=0, ppl=2.2, wps=304.7, ups=0.26, wpb=1182.6, bsz=32, num_updates=34480, lr=3.57881e-06, gnorm=15.96, clip=100, loss_scale=32, train_wall=39, gb_free=7.7, wall=133060
2023-05-22 06:55:42 - progress_bar.py[line:272] - INFO: epoch 020:   1645 / 1732 loss=2.323, loss_v1=0, loss_v2=0, nll_loss=1.114, ntokens=1274.6, nsentences=32, sample_size=1274.6, sample_size_v1=0, sample_size_v2=0, ppl=2.17, wps=324.1, ups=0.25, wpb=1274.6, bsz=32, num_updates=34490, lr=3.57677e-06, gnorm=14.52, clip=100, loss_scale=32, train_wall=39, gb_free=8.2, wall=133099
2023-05-22 06:56:20 - progress_bar.py[line:272] - INFO: epoch 020:   1655 / 1732 loss=2.384, loss_v1=0, loss_v2=0, nll_loss=1.183, ntokens=951.7, nsentences=32, sample_size=951.7, sample_size_v1=0, sample_size_v2=0, ppl=2.27, wps=248.6, ups=0.26, wpb=951.7, bsz=32, num_updates=34500, lr=3.57472e-06, gnorm=17.195, clip=100, loss_scale=32, train_wall=38, gb_free=8.3, wall=133137
2023-05-22 06:56:59 - progress_bar.py[line:272] - INFO: epoch 020:   1665 / 1732 loss=2.385, loss_v1=0, loss_v2=0, nll_loss=1.183, ntokens=1028.1, nsentences=32, sample_size=1028.1, sample_size_v1=0, sample_size_v2=0, ppl=2.27, wps=265.6, ups=0.26, wpb=1028.1, bsz=32, num_updates=34510, lr=3.57267e-06, gnorm=17.529, clip=100, loss_scale=32, train_wall=39, gb_free=8.3, wall=133176
2023-05-22 06:57:38 - progress_bar.py[line:272] - INFO: epoch 020:   1675 / 1732 loss=2.322, loss_v1=0, loss_v2=0, nll_loss=1.114, ntokens=1102.6, nsentences=32, sample_size=1102.6, sample_size_v1=0, sample_size_v2=0, ppl=2.17, wps=284.2, ups=0.26, wpb=1102.6, bsz=32, num_updates=34520, lr=3.57062e-06, gnorm=16.923, clip=100, loss_scale=32, train_wall=39, gb_free=6.8, wall=133215
2023-05-22 06:58:17 - progress_bar.py[line:272] - INFO: epoch 020:   1685 / 1732 loss=2.325, loss_v1=0, loss_v2=0, nll_loss=1.116, ntokens=1141.1, nsentences=32, sample_size=1141.1, sample_size_v1=0, sample_size_v2=0, ppl=2.17, wps=292.2, ups=0.26, wpb=1141.1, bsz=32, num_updates=34530, lr=3.56858e-06, gnorm=15.673, clip=100, loss_scale=32, train_wall=39, gb_free=8.5, wall=133254
2023-05-22 06:58:56 - progress_bar.py[line:272] - INFO: epoch 020:   1695 / 1732 loss=2.357, loss_v1=0, loss_v2=0, nll_loss=1.152, ntokens=1274.5, nsentences=32, sample_size=1274.5, sample_size_v1=0, sample_size_v2=0, ppl=2.22, wps=322.3, ups=0.25, wpb=1274.5, bsz=32, num_updates=34540, lr=3.56653e-06, gnorm=15.678, clip=100, loss_scale=32, train_wall=39, gb_free=8.2, wall=133293
2023-05-22 06:59:35 - progress_bar.py[line:272] - INFO: epoch 020:   1705 / 1732 loss=2.352, loss_v1=0, loss_v2=0, nll_loss=1.148, ntokens=1217, nsentences=32, sample_size=1217, sample_size_v1=0, sample_size_v2=0, ppl=2.22, wps=309.8, ups=0.25, wpb=1217, bsz=32, num_updates=34550, lr=3.56448e-06, gnorm=14.255, clip=100, loss_scale=32, train_wall=39, gb_free=7.9, wall=133333
2023-05-22 07:00:14 - progress_bar.py[line:272] - INFO: epoch 020:   1715 / 1732 loss=2.341, loss_v1=0, loss_v2=0, nll_loss=1.135, ntokens=1196, nsentences=32, sample_size=1196, sample_size_v1=0, sample_size_v2=0, ppl=2.2, wps=307.4, ups=0.26, wpb=1196, bsz=32, num_updates=34560, lr=3.56243e-06, gnorm=15.705, clip=100, loss_scale=32, train_wall=39, gb_free=7.9, wall=133372
2023-05-22 07:00:53 - progress_bar.py[line:272] - INFO: epoch 020:   1725 / 1732 loss=2.369, loss_v1=0, loss_v2=0, nll_loss=1.168, ntokens=1108.9, nsentences=32, sample_size=1108.9, sample_size_v1=0, sample_size_v2=0, ppl=2.25, wps=285.8, ups=0.26, wpb=1108.9, bsz=32, num_updates=34570, lr=3.56039e-06, gnorm=15.065, clip=100, loss_scale=32, train_wall=39, gb_free=8.5, wall=133410
2023-05-22 07:01:18 - checkpoint_utils.py[line:64] - INFO: Preparing to save checkpoint for epoch 20 @ 34577 updates
2023-05-22 07:01:18 - trainer.py[line:431] - INFO: Saving checkpoint to ../../checkpoints/OFA/sgcls_checkpoints/_30_1e-5_480/checkpoint20.pt
2023-05-22 07:01:24 - trainer.py[line:441] - INFO: Finished saving checkpoint to ../../checkpoints/OFA/sgcls_checkpoints/_30_1e-5_480/checkpoint20.pt
2023-05-22 07:01:43 - checkpoint_utils.py[line:133] - INFO: Saved checkpoint ../../checkpoints/OFA/sgcls_checkpoints/_30_1e-5_480/checkpoint20.pt (epoch 20 @ 34577 updates, score None) (writing took 25.06686279689893 seconds)
2023-05-22 07:01:43 - train.py[line:332] - INFO: end of epoch 20 (average epoch stats below)
2023-05-22 07:01:43 - progress_bar.py[line:282] - INFO: epoch 020 | loss 2.373 | loss_v1 0 | loss_v2 0 | nll_loss 1.17 | ntokens 1051.38 | nsentences 31.986 | sample_size 1051.38 | sample_size_v1 0 | sample_size_v2 0 | ppl 2.25 | wps 271.8 | ups 0.26 | wpb 1051.4 | bsz 32 | num_updates 34577 | lr 3.55895e-06 | gnorm 16.985 | clip 100 | loss_scale 32 | train_wall 6652 | gb_free 8.9 | wall 133460
2023-05-22 07:01:43 - trainer.py[line:639] - INFO: loading train data for epoch 21
local datafile ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 0 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 0 finished initializing row_count and line_idx-to-offset mapping
file ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 0 row count 55400 total row count 55400
slice_id 0 seek offset 0
2023-05-22 07:01:44 - trainer.py[line:703] - INFO: begin training epoch 21
2023-05-22 07:01:44 - train.py[line:305] - INFO: Start iterating over samples
2023-05-22 07:01:56 - progress_bar.py[line:272] - INFO: epoch 021:      3 / 1732 loss=2.377, loss_v1=0, loss_v2=0, nll_loss=1.175, ntokens=1127.6, nsentences=29.6, sample_size=1127.6, sample_size_v1=0, sample_size_v2=0, ppl=2.26, wps=178.6, ups=0.16, wpb=1127.6, bsz=29.6, num_updates=34580, lr=3.55834e-06, gnorm=17.899, clip=100, loss_scale=32, train_wall=36, gb_free=8.2, wall=133474
2023-05-22 07:02:35 - progress_bar.py[line:272] - INFO: epoch 021:     13 / 1732 loss=2.308, loss_v1=0, loss_v2=0, nll_loss=1.097, ntokens=1037.7, nsentences=32, sample_size=1037.7, sample_size_v1=0, sample_size_v2=0, ppl=2.14, wps=268.8, ups=0.26, wpb=1037.7, bsz=32, num_updates=34590, lr=3.55629e-06, gnorm=16.867, clip=100, loss_scale=32, train_wall=39, gb_free=8.2, wall=133512
2023-05-22 07:03:14 - progress_bar.py[line:272] - INFO: epoch 021:     23 / 1732 loss=2.249, loss_v1=0, loss_v2=0, nll_loss=1.031, ntokens=1082, nsentences=32, sample_size=1082, sample_size_v1=0, sample_size_v2=0, ppl=2.04, wps=278.1, ups=0.26, wpb=1082, bsz=32, num_updates=34600, lr=3.55425e-06, gnorm=15.987, clip=100, loss_scale=32, train_wall=39, gb_free=8.6, wall=133551
2023-05-22 07:03:53 - progress_bar.py[line:272] - INFO: epoch 021:     33 / 1732 loss=2.23, loss_v1=0, loss_v2=0, nll_loss=1.009, ntokens=1032.3, nsentences=32, sample_size=1032.3, sample_size_v1=0, sample_size_v2=0, ppl=2.01, wps=264.5, ups=0.26, wpb=1032.3, bsz=32, num_updates=34610, lr=3.5522e-06, gnorm=14.822, clip=100, loss_scale=32, train_wall=39, gb_free=7.2, wall=133590
2023-05-22 07:04:32 - progress_bar.py[line:272] - INFO: epoch 021:     43 / 1732 loss=2.144, loss_v1=0, loss_v2=0, nll_loss=0.917, ntokens=1156.8, nsentences=32, sample_size=1156.8, sample_size_v1=0, sample_size_v2=0, ppl=1.89, wps=297.1, ups=0.26, wpb=1156.8, bsz=32, num_updates=34620, lr=3.55015e-06, gnorm=12.343, clip=100, loss_scale=32, train_wall=39, gb_free=8.1, wall=133629
2023-05-22 07:05:10 - progress_bar.py[line:272] - INFO: epoch 021:     53 / 1732 loss=2.201, loss_v1=0, loss_v2=0, nll_loss=0.984, ntokens=1016.6, nsentences=32, sample_size=1016.6, sample_size_v1=0, sample_size_v2=0, ppl=1.98, wps=263.2, ups=0.26, wpb=1016.6, bsz=32, num_updates=34630, lr=3.5481e-06, gnorm=13.945, clip=100, loss_scale=32, train_wall=39, gb_free=8.6, wall=133668
2023-05-22 07:05:49 - progress_bar.py[line:272] - INFO: epoch 021:     63 / 1732 loss=1.996, loss_v1=0, loss_v2=0, nll_loss=0.753, ntokens=1239.4, nsentences=32, sample_size=1239.4, sample_size_v1=0, sample_size_v2=0, ppl=1.68, wps=317.9, ups=0.26, wpb=1239.4, bsz=32, num_updates=34640, lr=3.54606e-06, gnorm=11.384, clip=100, loss_scale=32, train_wall=39, gb_free=7.3, wall=133707
2023-05-22 07:06:29 - progress_bar.py[line:272] - INFO: epoch 021:     73 / 1732 loss=2.119, loss_v1=0, loss_v2=0, nll_loss=0.888, ntokens=1389.6, nsentences=32, sample_size=1389.6, sample_size_v1=0, sample_size_v2=0, ppl=1.85, wps=348.5, ups=0.25, wpb=1389.6, bsz=32, num_updates=34650, lr=3.54401e-06, gnorm=12.391, clip=100, loss_scale=32, train_wall=40, gb_free=7, wall=133747
2023-05-22 07:07:09 - progress_bar.py[line:272] - INFO: epoch 021:     83 / 1732 loss=2.161, loss_v1=0, loss_v2=0, nll_loss=0.934, ntokens=1166.3, nsentences=32, sample_size=1166.3, sample_size_v1=0, sample_size_v2=0, ppl=1.91, wps=297.2, ups=0.25, wpb=1166.3, bsz=32, num_updates=34660, lr=3.54196e-06, gnorm=16.533, clip=100, loss_scale=32, train_wall=39, gb_free=7.2, wall=133786
2023-05-22 07:07:47 - progress_bar.py[line:272] - INFO: epoch 021:     93 / 1732 loss=2.151, loss_v1=0, loss_v2=0, nll_loss=0.92, ntokens=1099.1, nsentences=32, sample_size=1099.1, sample_size_v1=0, sample_size_v2=0, ppl=1.89, wps=282.8, ups=0.26, wpb=1099.1, bsz=32, num_updates=34670, lr=3.53991e-06, gnorm=15.552, clip=100, loss_scale=32, train_wall=39, gb_free=8.2, wall=133825
2023-05-22 07:08:26 - progress_bar.py[line:272] - INFO: epoch 021:    103 / 1732 loss=2.308, loss_v1=0, loss_v2=0, nll_loss=1.1, ntokens=976, nsentences=32, sample_size=976, sample_size_v1=0, sample_size_v2=0, ppl=2.14, wps=255.7, ups=0.26, wpb=976, bsz=32, num_updates=34680, lr=3.53787e-06, gnorm=18.967, clip=100, loss_scale=32, train_wall=38, gb_free=8.6, wall=133863
2023-05-22 07:09:04 - progress_bar.py[line:272] - INFO: epoch 021:    113 / 1732 loss=2.378, loss_v1=0, loss_v2=0, nll_loss=1.177, ntokens=1030.9, nsentences=32, sample_size=1030.9, sample_size_v1=0, sample_size_v2=0, ppl=2.26, wps=267.6, ups=0.26, wpb=1030.9, bsz=32, num_updates=34690, lr=3.53582e-06, gnorm=18.008, clip=100, loss_scale=32, train_wall=38, gb_free=7.8, wall=133901
2023-05-22 07:09:43 - progress_bar.py[line:272] - INFO: epoch 021:    123 / 1732 loss=2.344, loss_v1=0, loss_v2=0, nll_loss=1.135, ntokens=1142.2, nsentences=32, sample_size=1142.2, sample_size_v1=0, sample_size_v2=0, ppl=2.2, wps=291.7, ups=0.26, wpb=1142.2, bsz=32, num_updates=34700, lr=3.53377e-06, gnorm=16.32, clip=100, loss_scale=32, train_wall=39, gb_free=7.6, wall=133940
2023-05-22 07:10:22 - progress_bar.py[line:272] - INFO: epoch 021:    133 / 1732 loss=2.286, loss_v1=0, loss_v2=0, nll_loss=1.072, ntokens=1207.4, nsentences=32, sample_size=1207.4, sample_size_v1=0, sample_size_v2=0, ppl=2.1, wps=308.6, ups=0.26, wpb=1207.4, bsz=32, num_updates=34710, lr=3.53172e-06, gnorm=14.988, clip=100, loss_scale=32, train_wall=39, gb_free=8, wall=133980
2023-05-22 07:11:02 - progress_bar.py[line:272] - INFO: epoch 021:    143 / 1732 loss=2.272, loss_v1=0, loss_v2=0, nll_loss=1.059, ntokens=1226.6, nsentences=32, sample_size=1226.6, sample_size_v1=0, sample_size_v2=0, ppl=2.08, wps=311.9, ups=0.25, wpb=1226.6, bsz=32, num_updates=34720, lr=3.52968e-06, gnorm=14.112, clip=100, loss_scale=32, train_wall=39, gb_free=7.2, wall=134019
2023-05-22 07:11:41 - progress_bar.py[line:272] - INFO: epoch 021:    153 / 1732 loss=2.281, loss_v1=0, loss_v2=0, nll_loss=1.07, ntokens=1152.6, nsentences=32, sample_size=1152.6, sample_size_v1=0, sample_size_v2=0, ppl=2.1, wps=292.4, ups=0.25, wpb=1152.6, bsz=32, num_updates=34730, lr=3.52763e-06, gnorm=14.558, clip=100, loss_scale=32, train_wall=39, gb_free=7.3, wall=134058
2023-05-22 07:12:20 - progress_bar.py[line:272] - INFO: epoch 021:    163 / 1732 loss=2.273, loss_v1=0, loss_v2=0, nll_loss=1.059, ntokens=1079.7, nsentences=32, sample_size=1079.7, sample_size_v1=0, sample_size_v2=0, ppl=2.08, wps=277.4, ups=0.26, wpb=1079.7, bsz=32, num_updates=34740, lr=3.52558e-06, gnorm=15.373, clip=100, loss_scale=32, train_wall=39, gb_free=8.7, wall=134097
2023-05-22 07:12:59 - progress_bar.py[line:272] - INFO: epoch 021:    173 / 1732 loss=2.296, loss_v1=0, loss_v2=0, nll_loss=1.085, ntokens=936.5, nsentences=32, sample_size=936.5, sample_size_v1=0, sample_size_v2=0, ppl=2.12, wps=242.3, ups=0.26, wpb=936.5, bsz=32, num_updates=34750, lr=3.52353e-06, gnorm=17.272, clip=100, loss_scale=32, train_wall=39, gb_free=7.8, wall=134136
2023-05-22 07:13:38 - progress_bar.py[line:272] - INFO: epoch 021:    183 / 1732 loss=2.247, loss_v1=0, loss_v2=0, nll_loss=1.03, ntokens=1184.7, nsentences=32, sample_size=1184.7, sample_size_v1=0, sample_size_v2=0, ppl=2.04, wps=301.4, ups=0.25, wpb=1184.7, bsz=32, num_updates=34760, lr=3.52149e-06, gnorm=15.406, clip=100, loss_scale=32, train_wall=39, gb_free=8.4, wall=134175
2023-05-22 07:14:17 - progress_bar.py[line:272] - INFO: epoch 021:    193 / 1732 loss=2.264, loss_v1=0, loss_v2=0, nll_loss=1.048, ntokens=1122.8, nsentences=32, sample_size=1122.8, sample_size_v1=0, sample_size_v2=0, ppl=2.07, wps=287, ups=0.26, wpb=1122.8, bsz=32, num_updates=34770, lr=3.51944e-06, gnorm=14.825, clip=100, loss_scale=32, train_wall=39, gb_free=8.2, wall=134214
2023-05-22 07:14:56 - progress_bar.py[line:272] - INFO: epoch 021:    203 / 1732 loss=2.355, loss_v1=0, loss_v2=0, nll_loss=1.151, ntokens=1086.7, nsentences=32, sample_size=1086.7, sample_size_v1=0, sample_size_v2=0, ppl=2.22, wps=281.2, ups=0.26, wpb=1086.7, bsz=32, num_updates=34780, lr=3.51739e-06, gnorm=16.687, clip=100, loss_scale=32, train_wall=39, gb_free=8.5, wall=134253
2023-05-22 07:15:34 - progress_bar.py[line:272] - INFO: epoch 021:    213 / 1732 loss=2.383, loss_v1=0, loss_v2=0, nll_loss=1.181, ntokens=1044.9, nsentences=32, sample_size=1044.9, sample_size_v1=0, sample_size_v2=0, ppl=2.27, wps=273.8, ups=0.26, wpb=1044.9, bsz=32, num_updates=34790, lr=3.51535e-06, gnorm=17.343, clip=100, loss_scale=32, train_wall=38, gb_free=8.5, wall=134291
2023-05-22 07:16:12 - progress_bar.py[line:272] - INFO: epoch 021:    223 / 1732 loss=2.387, loss_v1=0, loss_v2=0, nll_loss=1.187, ntokens=1134.6, nsentences=32, sample_size=1134.6, sample_size_v1=0, sample_size_v2=0, ppl=2.28, wps=297.1, ups=0.26, wpb=1134.6, bsz=32, num_updates=34800, lr=3.5133e-06, gnorm=16.181, clip=100, loss_scale=32, train_wall=38, gb_free=8.6, wall=134329
2023-05-22 07:16:50 - progress_bar.py[line:272] - INFO: epoch 021:    233 / 1732 loss=2.43, loss_v1=0, loss_v2=0, nll_loss=1.235, ntokens=1078.6, nsentences=32, sample_size=1078.6, sample_size_v1=0, sample_size_v2=0, ppl=2.35, wps=283.8, ups=0.26, wpb=1078.6, bsz=32, num_updates=34810, lr=3.51125e-06, gnorm=16.938, clip=100, loss_scale=32, train_wall=38, gb_free=9.1, wall=134367
2023-05-22 07:17:29 - progress_bar.py[line:272] - INFO: epoch 021:    243 / 1732 loss=2.418, loss_v1=0, loss_v2=0, nll_loss=1.221, ntokens=1123.3, nsentences=32, sample_size=1123.3, sample_size_v1=0, sample_size_v2=0, ppl=2.33, wps=292.2, ups=0.26, wpb=1123.3, bsz=32, num_updates=34820, lr=3.5092e-06, gnorm=16.937, clip=100, loss_scale=32, train_wall=38, gb_free=8.7, wall=134406
2023-05-22 07:18:07 - progress_bar.py[line:272] - INFO: epoch 021:    253 / 1732 loss=2.42, loss_v1=0, loss_v2=0, nll_loss=1.223, ntokens=1167.4, nsentences=32, sample_size=1167.4, sample_size_v1=0, sample_size_v2=0, ppl=2.33, wps=304.5, ups=0.26, wpb=1167.4, bsz=32, num_updates=34830, lr=3.50716e-06, gnorm=15.556, clip=100, loss_scale=32, train_wall=38, gb_free=8, wall=134444
2023-05-22 07:18:45 - progress_bar.py[line:272] - INFO: epoch 021:    263 / 1732 loss=2.411, loss_v1=0, loss_v2=0, nll_loss=1.212, ntokens=1123.9, nsentences=32, sample_size=1123.9, sample_size_v1=0, sample_size_v2=0, ppl=2.32, wps=294.2, ups=0.26, wpb=1123.9, bsz=32, num_updates=34840, lr=3.50511e-06, gnorm=16.461, clip=100, loss_scale=32, train_wall=38, gb_free=8, wall=134482
2023-05-22 07:19:23 - progress_bar.py[line:272] - INFO: epoch 021:    273 / 1732 loss=2.4, loss_v1=0, loss_v2=0, nll_loss=1.2, ntokens=1154.8, nsentences=32, sample_size=1154.8, sample_size_v1=0, sample_size_v2=0, ppl=2.3, wps=301.8, ups=0.26, wpb=1154.8, bsz=32, num_updates=34850, lr=3.50306e-06, gnorm=15.694, clip=100, loss_scale=32, train_wall=38, gb_free=8.3, wall=134521
2023-05-22 07:20:02 - progress_bar.py[line:272] - INFO: epoch 021:    283 / 1732 loss=2.418, loss_v1=0, loss_v2=0, nll_loss=1.22, ntokens=1146.7, nsentences=32, sample_size=1146.7, sample_size_v1=0, sample_size_v2=0, ppl=2.33, wps=297.6, ups=0.26, wpb=1146.7, bsz=32, num_updates=34860, lr=3.50101e-06, gnorm=16.499, clip=100, loss_scale=32, train_wall=38, gb_free=8.2, wall=134559
2023-05-22 07:20:40 - progress_bar.py[line:272] - INFO: epoch 021:    293 / 1732 loss=2.387, loss_v1=0, loss_v2=0, nll_loss=1.186, ntokens=1122.6, nsentences=32, sample_size=1122.6, sample_size_v1=0, sample_size_v2=0, ppl=2.27, wps=293.2, ups=0.26, wpb=1122.6, bsz=32, num_updates=34870, lr=3.49897e-06, gnorm=16.162, clip=100, loss_scale=32, train_wall=38, gb_free=7.4, wall=134598
2023-05-22 07:21:18 - progress_bar.py[line:272] - INFO: epoch 021:    303 / 1732 loss=2.388, loss_v1=0, loss_v2=0, nll_loss=1.187, ntokens=1117.4, nsentences=32, sample_size=1117.4, sample_size_v1=0, sample_size_v2=0, ppl=2.28, wps=292.9, ups=0.26, wpb=1117.4, bsz=32, num_updates=34880, lr=3.49692e-06, gnorm=17.744, clip=100, loss_scale=32, train_wall=38, gb_free=8.2, wall=134636
2023-05-22 07:21:57 - progress_bar.py[line:272] - INFO: epoch 021:    313 / 1732 loss=2.402, loss_v1=0, loss_v2=0, nll_loss=1.203, ntokens=1045.5, nsentences=32, sample_size=1045.5, sample_size_v1=0, sample_size_v2=0, ppl=2.3, wps=274, ups=0.26, wpb=1045.5, bsz=32, num_updates=34890, lr=3.49487e-06, gnorm=17.108, clip=100, loss_scale=32, train_wall=38, gb_free=8.6, wall=134674
2023-05-22 07:22:35 - progress_bar.py[line:272] - INFO: epoch 021:    323 / 1732 loss=2.433, loss_v1=0, loss_v2=0, nll_loss=1.237, ntokens=1005.7, nsentences=32, sample_size=1005.7, sample_size_v1=0, sample_size_v2=0, ppl=2.36, wps=263.8, ups=0.26, wpb=1005.7, bsz=32, num_updates=34900, lr=3.49282e-06, gnorm=16.763, clip=100, loss_scale=32, train_wall=38, gb_free=8.6, wall=134712
2023-05-22 07:23:13 - progress_bar.py[line:272] - INFO: epoch 021:    333 / 1732 loss=2.418, loss_v1=0, loss_v2=0, nll_loss=1.22, ntokens=1019.2, nsentences=32, sample_size=1019.2, sample_size_v1=0, sample_size_v2=0, ppl=2.33, wps=268, ups=0.26, wpb=1019.2, bsz=32, num_updates=34910, lr=3.49078e-06, gnorm=17.572, clip=100, loss_scale=32, train_wall=38, gb_free=8.6, wall=134750
2023-05-22 07:23:51 - progress_bar.py[line:272] - INFO: epoch 021:    343 / 1732 loss=2.384, loss_v1=0, loss_v2=0, nll_loss=1.183, ntokens=919.2, nsentences=32, sample_size=919.2, sample_size_v1=0, sample_size_v2=0, ppl=2.27, wps=242.8, ups=0.26, wpb=919.2, bsz=32, num_updates=34920, lr=3.48873e-06, gnorm=18.058, clip=100, loss_scale=32, train_wall=38, gb_free=9.1, wall=134788
2023-05-22 07:24:29 - progress_bar.py[line:272] - INFO: epoch 021:    353 / 1732 loss=2.411, loss_v1=0, loss_v2=0, nll_loss=1.214, ntokens=968.9, nsentences=32, sample_size=968.9, sample_size_v1=0, sample_size_v2=0, ppl=2.32, wps=255.9, ups=0.26, wpb=968.9, bsz=32, num_updates=34930, lr=3.48668e-06, gnorm=17.997, clip=100, loss_scale=32, train_wall=38, gb_free=7.7, wall=134826
2023-05-22 07:25:06 - progress_bar.py[line:272] - INFO: epoch 021:    363 / 1732 loss=2.451, loss_v1=0, loss_v2=0, nll_loss=1.259, ntokens=932.1, nsentences=32, sample_size=932.1, sample_size_v1=0, sample_size_v2=0, ppl=2.39, wps=247.4, ups=0.27, wpb=932.1, bsz=32, num_updates=34940, lr=3.48463e-06, gnorm=20.235, clip=100, loss_scale=32, train_wall=38, gb_free=8.7, wall=134863
2023-05-22 07:25:44 - progress_bar.py[line:272] - INFO: epoch 021:    373 / 1732 loss=2.437, loss_v1=0, loss_v2=0, nll_loss=1.243, ntokens=967.4, nsentences=32, sample_size=967.4, sample_size_v1=0, sample_size_v2=0, ppl=2.37, wps=255.2, ups=0.26, wpb=967.4, bsz=32, num_updates=34950, lr=3.48259e-06, gnorm=17.557, clip=100, loss_scale=32, train_wall=38, gb_free=8.9, wall=134901
2023-05-22 07:26:22 - progress_bar.py[line:272] - INFO: epoch 021:    383 / 1732 loss=2.419, loss_v1=0, loss_v2=0, nll_loss=1.222, ntokens=1070.5, nsentences=32, sample_size=1070.5, sample_size_v1=0, sample_size_v2=0, ppl=2.33, wps=282.6, ups=0.26, wpb=1070.5, bsz=32, num_updates=34960, lr=3.48054e-06, gnorm=16.804, clip=100, loss_scale=32, train_wall=38, gb_free=8.7, wall=134939
2023-05-22 07:27:00 - progress_bar.py[line:272] - INFO: epoch 021:    393 / 1732 loss=2.422, loss_v1=0, loss_v2=0, nll_loss=1.225, ntokens=990.3, nsentences=32, sample_size=990.3, sample_size_v1=0, sample_size_v2=0, ppl=2.34, wps=261.6, ups=0.26, wpb=990.3, bsz=32, num_updates=34970, lr=3.47849e-06, gnorm=16.447, clip=100, loss_scale=64, train_wall=38, gb_free=8.9, wall=134977
2023-05-22 07:27:11 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2023-05-22 07:27:42 - progress_bar.py[line:272] - INFO: epoch 021:    404 / 1732 loss=2.398, loss_v1=0, loss_v2=0, nll_loss=1.197, ntokens=1032.2, nsentences=32, sample_size=1032.2, sample_size_v1=0, sample_size_v2=0, ppl=2.29, wps=247.3, ups=0.24, wpb=1032.2, bsz=32, num_updates=34980, lr=3.47644e-06, gnorm=16.756, clip=100, loss_scale=32, train_wall=42, gb_free=8.1, wall=135019
2023-05-22 07:28:20 - progress_bar.py[line:272] - INFO: epoch 021:    414 / 1732 loss=2.386, loss_v1=0, loss_v2=0, nll_loss=1.185, ntokens=1066.1, nsentences=32, sample_size=1066.1, sample_size_v1=0, sample_size_v2=0, ppl=2.27, wps=280, ups=0.26, wpb=1066.1, bsz=32, num_updates=34990, lr=3.4744e-06, gnorm=17.696, clip=100, loss_scale=32, train_wall=38, gb_free=6.5, wall=135057
2023-05-22 07:28:58 - progress_bar.py[line:272] - INFO: epoch 021:    424 / 1732 loss=2.381, loss_v1=0, loss_v2=0, nll_loss=1.179, ntokens=992.6, nsentences=32, sample_size=992.6, sample_size_v1=0, sample_size_v2=0, ppl=2.26, wps=261.3, ups=0.26, wpb=992.6, bsz=32, num_updates=35000, lr=3.47235e-06, gnorm=16.928, clip=100, loss_scale=32, train_wall=38, gb_free=8.6, wall=135095
2023-05-22 07:29:36 - progress_bar.py[line:272] - INFO: epoch 021:    434 / 1732 loss=2.404, loss_v1=0, loss_v2=0, nll_loss=1.206, ntokens=1018.1, nsentences=32, sample_size=1018.1, sample_size_v1=0, sample_size_v2=0, ppl=2.31, wps=268.7, ups=0.26, wpb=1018.1, bsz=32, num_updates=35010, lr=3.4703e-06, gnorm=19.049, clip=100, loss_scale=32, train_wall=38, gb_free=9, wall=135133
2023-05-22 07:30:13 - progress_bar.py[line:272] - INFO: epoch 021:    444 / 1732 loss=2.433, loss_v1=0, loss_v2=0, nll_loss=1.238, ntokens=952.1, nsentences=32, sample_size=952.1, sample_size_v1=0, sample_size_v2=0, ppl=2.36, wps=251.8, ups=0.26, wpb=952.1, bsz=32, num_updates=35020, lr=3.46826e-06, gnorm=16.729, clip=100, loss_scale=32, train_wall=38, gb_free=9.1, wall=135171
2023-05-22 07:30:51 - progress_bar.py[line:272] - INFO: epoch 021:    454 / 1732 loss=2.426, loss_v1=0, loss_v2=0, nll_loss=1.229, ntokens=919.5, nsentences=32, sample_size=919.5, sample_size_v1=0, sample_size_v2=0, ppl=2.34, wps=243.2, ups=0.26, wpb=919.5, bsz=32, num_updates=35030, lr=3.46621e-06, gnorm=19.388, clip=100, loss_scale=32, train_wall=38, gb_free=8.6, wall=135208
2023-05-22 07:31:29 - progress_bar.py[line:272] - INFO: epoch 021:    464 / 1732 loss=2.437, loss_v1=0, loss_v2=0, nll_loss=1.241, ntokens=1076.9, nsentences=32, sample_size=1076.9, sample_size_v1=0, sample_size_v2=0, ppl=2.36, wps=282.2, ups=0.26, wpb=1076.9, bsz=32, num_updates=35040, lr=3.46416e-06, gnorm=16.618, clip=100, loss_scale=32, train_wall=38, gb_free=8.9, wall=135247
2023-05-22 07:31:37 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2023-05-22 07:32:11 - progress_bar.py[line:272] - INFO: epoch 021:    475 / 1732 loss=2.435, loss_v1=0, loss_v2=0, nll_loss=1.239, ntokens=1059.2, nsentences=32, sample_size=1059.2, sample_size_v1=0, sample_size_v2=0, ppl=2.36, wps=252.8, ups=0.24, wpb=1059.2, bsz=32, num_updates=35050, lr=3.46211e-06, gnorm=17.016, clip=100, loss_scale=16, train_wall=42, gb_free=8.5, wall=135288
2023-05-22 07:32:49 - progress_bar.py[line:272] - INFO: epoch 021:    485 / 1732 loss=2.408, loss_v1=0, loss_v2=0, nll_loss=1.208, ntokens=980.2, nsentences=32, sample_size=980.2, sample_size_v1=0, sample_size_v2=0, ppl=2.31, wps=259.4, ups=0.26, wpb=980.2, bsz=32, num_updates=35060, lr=3.46007e-06, gnorm=18.101, clip=100, loss_scale=16, train_wall=38, gb_free=8.4, wall=135326
2023-05-22 07:33:27 - progress_bar.py[line:272] - INFO: epoch 021:    495 / 1732 loss=2.413, loss_v1=0, loss_v2=0, nll_loss=1.214, ntokens=928.7, nsentences=32, sample_size=928.7, sample_size_v1=0, sample_size_v2=0, ppl=2.32, wps=245.7, ups=0.26, wpb=928.7, bsz=32, num_updates=35070, lr=3.45802e-06, gnorm=18.778, clip=100, loss_scale=16, train_wall=38, gb_free=9.3, wall=135364
2023-05-22 07:34:05 - progress_bar.py[line:272] - INFO: epoch 021:    505 / 1732 loss=2.418, loss_v1=0, loss_v2=0, nll_loss=1.22, ntokens=974.8, nsentences=32, sample_size=974.8, sample_size_v1=0, sample_size_v2=0, ppl=2.33, wps=258.8, ups=0.27, wpb=974.8, bsz=32, num_updates=35080, lr=3.45597e-06, gnorm=18.289, clip=100, loss_scale=16, train_wall=38, gb_free=8.7, wall=135402
2023-05-22 07:34:43 - progress_bar.py[line:272] - INFO: epoch 021:    515 / 1732 loss=2.422, loss_v1=0, loss_v2=0, nll_loss=1.225, ntokens=1073.1, nsentences=32, sample_size=1073.1, sample_size_v1=0, sample_size_v2=0, ppl=2.34, wps=282.3, ups=0.26, wpb=1073.1, bsz=32, num_updates=35090, lr=3.45392e-06, gnorm=15.858, clip=100, loss_scale=16, train_wall=38, gb_free=8.4, wall=135440
2023-05-22 07:35:20 - progress_bar.py[line:272] - INFO: epoch 021:    525 / 1732 loss=2.409, loss_v1=0, loss_v2=0, nll_loss=1.211, ntokens=955.6, nsentences=32, sample_size=955.6, sample_size_v1=0, sample_size_v2=0, ppl=2.31, wps=253.5, ups=0.27, wpb=955.6, bsz=32, num_updates=35100, lr=3.45188e-06, gnorm=19.417, clip=100, loss_scale=16, train_wall=38, gb_free=8.9, wall=135477
2023-05-22 07:35:58 - progress_bar.py[line:272] - INFO: epoch 021:    535 / 1732 loss=2.41, loss_v1=0, loss_v2=0, nll_loss=1.211, ntokens=948.7, nsentences=32, sample_size=948.7, sample_size_v1=0, sample_size_v2=0, ppl=2.31, wps=251.9, ups=0.27, wpb=948.7, bsz=32, num_updates=35110, lr=3.44983e-06, gnorm=18.525, clip=100, loss_scale=16, train_wall=38, gb_free=8.5, wall=135515
2023-05-22 07:36:36 - progress_bar.py[line:272] - INFO: epoch 021:    545 / 1732 loss=2.421, loss_v1=0, loss_v2=0, nll_loss=1.226, ntokens=1010, nsentences=32, sample_size=1010, sample_size_v1=0, sample_size_v2=0, ppl=2.34, wps=266.8, ups=0.26, wpb=1010, bsz=32, num_updates=35120, lr=3.44778e-06, gnorm=18.214, clip=100, loss_scale=16, train_wall=38, gb_free=8.3, wall=135553
2023-05-22 07:37:14 - progress_bar.py[line:272] - INFO: epoch 021:    555 / 1732 loss=2.454, loss_v1=0, loss_v2=0, nll_loss=1.261, ntokens=1039.8, nsentences=32, sample_size=1039.8, sample_size_v1=0, sample_size_v2=0, ppl=2.4, wps=274.3, ups=0.26, wpb=1039.8, bsz=32, num_updates=35130, lr=3.44573e-06, gnorm=17.576, clip=100, loss_scale=16, train_wall=38, gb_free=8.6, wall=135591
2023-05-22 07:37:52 - progress_bar.py[line:272] - INFO: epoch 021:    565 / 1732 loss=2.437, loss_v1=0, loss_v2=0, nll_loss=1.242, ntokens=1014, nsentences=32, sample_size=1014, sample_size_v1=0, sample_size_v2=0, ppl=2.37, wps=266.7, ups=0.26, wpb=1014, bsz=32, num_updates=35140, lr=3.44369e-06, gnorm=17.094, clip=100, loss_scale=16, train_wall=38, gb_free=8.5, wall=135629
2023-05-22 07:38:30 - progress_bar.py[line:272] - INFO: epoch 021:    575 / 1732 loss=2.427, loss_v1=0, loss_v2=0, nll_loss=1.231, ntokens=1007.3, nsentences=32, sample_size=1007.3, sample_size_v1=0, sample_size_v2=0, ppl=2.35, wps=264.3, ups=0.26, wpb=1007.3, bsz=32, num_updates=35150, lr=3.44164e-06, gnorm=18.393, clip=100, loss_scale=16, train_wall=38, gb_free=8.8, wall=135667
2023-05-22 07:39:08 - progress_bar.py[line:272] - INFO: epoch 021:    585 / 1732 loss=2.436, loss_v1=0, loss_v2=0, nll_loss=1.241, ntokens=980.6, nsentences=32, sample_size=980.6, sample_size_v1=0, sample_size_v2=0, ppl=2.36, wps=256.9, ups=0.26, wpb=980.6, bsz=32, num_updates=35160, lr=3.43959e-06, gnorm=18.488, clip=100, loss_scale=16, train_wall=38, gb_free=8.8, wall=135705
2023-05-22 07:39:46 - progress_bar.py[line:272] - INFO: epoch 021:    595 / 1732 loss=2.387, loss_v1=0, loss_v2=0, nll_loss=1.186, ntokens=961.9, nsentences=32, sample_size=961.9, sample_size_v1=0, sample_size_v2=0, ppl=2.27, wps=253, ups=0.26, wpb=961.9, bsz=32, num_updates=35170, lr=3.43754e-06, gnorm=18.007, clip=100, loss_scale=16, train_wall=38, gb_free=8.8, wall=135743
2023-05-22 07:40:24 - progress_bar.py[line:272] - INFO: epoch 021:    605 / 1732 loss=2.397, loss_v1=0, loss_v2=0, nll_loss=1.198, ntokens=879.8, nsentences=32, sample_size=879.8, sample_size_v1=0, sample_size_v2=0, ppl=2.29, wps=234.3, ups=0.27, wpb=879.8, bsz=32, num_updates=35180, lr=3.4355e-06, gnorm=18.374, clip=100, loss_scale=16, train_wall=37, gb_free=9.3, wall=135781
2023-05-22 07:41:02 - progress_bar.py[line:272] - INFO: epoch 021:    615 / 1732 loss=2.431, loss_v1=0, loss_v2=0, nll_loss=1.237, ntokens=903.1, nsentences=32, sample_size=903.1, sample_size_v1=0, sample_size_v2=0, ppl=2.36, wps=237.8, ups=0.26, wpb=903.1, bsz=32, num_updates=35190, lr=3.43345e-06, gnorm=19.985, clip=100, loss_scale=16, train_wall=38, gb_free=8.4, wall=135819
2023-05-22 07:41:39 - progress_bar.py[line:272] - INFO: epoch 021:    625 / 1732 loss=2.426, loss_v1=0, loss_v2=0, nll_loss=1.231, ntokens=898.6, nsentences=32, sample_size=898.6, sample_size_v1=0, sample_size_v2=0, ppl=2.35, wps=239.9, ups=0.27, wpb=898.6, bsz=32, num_updates=35200, lr=3.4314e-06, gnorm=20.8, clip=100, loss_scale=16, train_wall=37, gb_free=8.9, wall=135856
2023-05-22 07:42:16 - progress_bar.py[line:272] - INFO: epoch 021:    635 / 1732 loss=2.433, loss_v1=0, loss_v2=0, nll_loss=1.238, ntokens=897.1, nsentences=32, sample_size=897.1, sample_size_v1=0, sample_size_v2=0, ppl=2.36, wps=239.3, ups=0.27, wpb=897.1, bsz=32, num_updates=35210, lr=3.42936e-06, gnorm=21.431, clip=100, loss_scale=16, train_wall=37, gb_free=9, wall=135894
2023-05-22 07:42:54 - progress_bar.py[line:272] - INFO: epoch 021:    645 / 1732 loss=2.43, loss_v1=0, loss_v2=0, nll_loss=1.234, ntokens=1010.4, nsentences=32, sample_size=1010.4, sample_size_v1=0, sample_size_v2=0, ppl=2.35, wps=267.6, ups=0.26, wpb=1010.4, bsz=32, num_updates=35220, lr=3.42731e-06, gnorm=17.664, clip=100, loss_scale=16, train_wall=38, gb_free=8.9, wall=135931
2023-05-22 07:43:32 - progress_bar.py[line:272] - INFO: epoch 021:    655 / 1732 loss=2.43, loss_v1=0, loss_v2=0, nll_loss=1.234, ntokens=879.8, nsentences=32, sample_size=879.8, sample_size_v1=0, sample_size_v2=0, ppl=2.35, wps=235.6, ups=0.27, wpb=879.8, bsz=32, num_updates=35230, lr=3.42526e-06, gnorm=20.385, clip=100, loss_scale=16, train_wall=37, gb_free=8.7, wall=135969
2023-05-22 07:44:09 - progress_bar.py[line:272] - INFO: epoch 021:    665 / 1732 loss=2.431, loss_v1=0, loss_v2=0, nll_loss=1.236, ntokens=893.8, nsentences=32, sample_size=893.8, sample_size_v1=0, sample_size_v2=0, ppl=2.36, wps=239.1, ups=0.27, wpb=893.8, bsz=32, num_updates=35240, lr=3.42321e-06, gnorm=20.429, clip=100, loss_scale=16, train_wall=37, gb_free=9.3, wall=136006
2023-05-22 07:44:47 - progress_bar.py[line:272] - INFO: epoch 021:    675 / 1732 loss=2.436, loss_v1=0, loss_v2=0, nll_loss=1.242, ntokens=961.9, nsentences=32, sample_size=961.9, sample_size_v1=0, sample_size_v2=0, ppl=2.36, wps=254.3, ups=0.26, wpb=961.9, bsz=32, num_updates=35250, lr=3.42117e-06, gnorm=18.825, clip=100, loss_scale=16, train_wall=38, gb_free=8, wall=136044
2023-05-22 07:45:25 - progress_bar.py[line:272] - INFO: epoch 021:    685 / 1732 loss=2.421, loss_v1=0, loss_v2=0, nll_loss=1.224, ntokens=961.5, nsentences=32, sample_size=961.5, sample_size_v1=0, sample_size_v2=0, ppl=2.34, wps=254.6, ups=0.26, wpb=961.5, bsz=32, num_updates=35260, lr=3.41912e-06, gnorm=19.911, clip=100, loss_scale=16, train_wall=38, gb_free=8.7, wall=136082
2023-05-22 07:46:03 - progress_bar.py[line:272] - INFO: epoch 021:    695 / 1732 loss=2.432, loss_v1=0, loss_v2=0, nll_loss=1.235, ntokens=1007.2, nsentences=32, sample_size=1007.2, sample_size_v1=0, sample_size_v2=0, ppl=2.35, wps=264.7, ups=0.26, wpb=1007.2, bsz=32, num_updates=35270, lr=3.41707e-06, gnorm=19.052, clip=100, loss_scale=16, train_wall=38, gb_free=7.5, wall=136120
2023-05-22 07:46:40 - progress_bar.py[line:272] - INFO: epoch 021:    705 / 1732 loss=2.394, loss_v1=0, loss_v2=0, nll_loss=1.191, ntokens=925.6, nsentences=32, sample_size=925.6, sample_size_v1=0, sample_size_v2=0, ppl=2.28, wps=245.6, ups=0.27, wpb=925.6, bsz=32, num_updates=35280, lr=3.41502e-06, gnorm=19.978, clip=100, loss_scale=16, train_wall=38, gb_free=9, wall=136158
2023-05-22 07:47:18 - progress_bar.py[line:272] - INFO: epoch 021:    715 / 1732 loss=2.44, loss_v1=0, loss_v2=0, nll_loss=1.243, ntokens=890.5, nsentences=32, sample_size=890.5, sample_size_v1=0, sample_size_v2=0, ppl=2.37, wps=237.1, ups=0.27, wpb=890.5, bsz=32, num_updates=35290, lr=3.41298e-06, gnorm=19.417, clip=100, loss_scale=16, train_wall=38, gb_free=8.9, wall=136195
2023-05-22 07:47:55 - progress_bar.py[line:272] - INFO: epoch 021:    725 / 1732 loss=2.381, loss_v1=0, loss_v2=0, nll_loss=1.178, ntokens=904.8, nsentences=32, sample_size=904.8, sample_size_v1=0, sample_size_v2=0, ppl=2.26, wps=241.1, ups=0.27, wpb=904.8, bsz=32, num_updates=35300, lr=3.41093e-06, gnorm=19.813, clip=100, loss_scale=16, train_wall=37, gb_free=8.7, wall=136233
2023-05-22 07:48:33 - progress_bar.py[line:272] - INFO: epoch 021:    735 / 1732 loss=2.412, loss_v1=0, loss_v2=0, nll_loss=1.213, ntokens=965.8, nsentences=32, sample_size=965.8, sample_size_v1=0, sample_size_v2=0, ppl=2.32, wps=255.9, ups=0.26, wpb=965.8, bsz=32, num_updates=35310, lr=3.40888e-06, gnorm=17.406, clip=100, loss_scale=16, train_wall=38, gb_free=8.9, wall=136270
2023-05-22 07:49:11 - progress_bar.py[line:272] - INFO: epoch 021:    745 / 1732 loss=2.391, loss_v1=0, loss_v2=0, nll_loss=1.191, ntokens=978.3, nsentences=32, sample_size=978.3, sample_size_v1=0, sample_size_v2=0, ppl=2.28, wps=259, ups=0.26, wpb=978.3, bsz=32, num_updates=35320, lr=3.40683e-06, gnorm=19.003, clip=100, loss_scale=16, train_wall=38, gb_free=8.3, wall=136308
2023-05-22 07:49:49 - progress_bar.py[line:272] - INFO: epoch 021:    755 / 1732 loss=2.406, loss_v1=0, loss_v2=0, nll_loss=1.208, ntokens=975.4, nsentences=32, sample_size=975.4, sample_size_v1=0, sample_size_v2=0, ppl=2.31, wps=258, ups=0.26, wpb=975.4, bsz=32, num_updates=35330, lr=3.40479e-06, gnorm=18.973, clip=100, loss_scale=16, train_wall=38, gb_free=9, wall=136346
2023-05-22 07:50:27 - progress_bar.py[line:272] - INFO: epoch 021:    765 / 1732 loss=2.402, loss_v1=0, loss_v2=0, nll_loss=1.204, ntokens=948.8, nsentences=32, sample_size=948.8, sample_size_v1=0, sample_size_v2=0, ppl=2.3, wps=250.9, ups=0.26, wpb=948.8, bsz=32, num_updates=35340, lr=3.40274e-06, gnorm=18.417, clip=100, loss_scale=16, train_wall=38, gb_free=7.6, wall=136384
2023-05-22 07:51:04 - progress_bar.py[line:272] - INFO: epoch 021:    775 / 1732 loss=2.408, loss_v1=0, loss_v2=0, nll_loss=1.21, ntokens=1002.4, nsentences=32, sample_size=1002.4, sample_size_v1=0, sample_size_v2=0, ppl=2.31, wps=265.7, ups=0.27, wpb=1002.4, bsz=32, num_updates=35350, lr=3.40069e-06, gnorm=19.557, clip=100, loss_scale=16, train_wall=38, gb_free=8.7, wall=136421
2023-05-22 07:51:42 - progress_bar.py[line:272] - INFO: epoch 021:    785 / 1732 loss=2.407, loss_v1=0, loss_v2=0, nll_loss=1.208, ntokens=1003.9, nsentences=32, sample_size=1003.9, sample_size_v1=0, sample_size_v2=0, ppl=2.31, wps=265.2, ups=0.26, wpb=1003.9, bsz=32, num_updates=35360, lr=3.39864e-06, gnorm=18.478, clip=100, loss_scale=16, train_wall=38, gb_free=8.4, wall=136459
2023-05-22 07:52:20 - progress_bar.py[line:272] - INFO: epoch 021:    795 / 1732 loss=2.414, loss_v1=0, loss_v2=0, nll_loss=1.217, ntokens=1051.8, nsentences=32, sample_size=1051.8, sample_size_v1=0, sample_size_v2=0, ppl=2.32, wps=278.1, ups=0.26, wpb=1051.8, bsz=32, num_updates=35370, lr=3.3966e-06, gnorm=17.535, clip=100, loss_scale=16, train_wall=38, gb_free=8.3, wall=136497
2023-05-22 07:52:58 - progress_bar.py[line:272] - INFO: epoch 021:    805 / 1732 loss=2.417, loss_v1=0, loss_v2=0, nll_loss=1.219, ntokens=913, nsentences=32, sample_size=913, sample_size_v1=0, sample_size_v2=0, ppl=2.33, wps=242.8, ups=0.27, wpb=913, bsz=32, num_updates=35380, lr=3.39455e-06, gnorm=20.128, clip=100, loss_scale=16, train_wall=38, gb_free=8.3, wall=136535
2023-05-22 07:53:35 - progress_bar.py[line:272] - INFO: epoch 021:    815 / 1732 loss=2.415, loss_v1=0, loss_v2=0, nll_loss=1.217, ntokens=936.3, nsentences=32, sample_size=936.3, sample_size_v1=0, sample_size_v2=0, ppl=2.32, wps=248.4, ups=0.27, wpb=936.3, bsz=32, num_updates=35390, lr=3.3925e-06, gnorm=19.579, clip=100, loss_scale=16, train_wall=38, gb_free=8.8, wall=136572
2023-05-22 07:54:13 - progress_bar.py[line:272] - INFO: epoch 021:    825 / 1732 loss=2.413, loss_v1=0, loss_v2=0, nll_loss=1.215, ntokens=931.3, nsentences=32, sample_size=931.3, sample_size_v1=0, sample_size_v2=0, ppl=2.32, wps=246.4, ups=0.26, wpb=931.3, bsz=32, num_updates=35400, lr=3.39046e-06, gnorm=18.931, clip=100, loss_scale=16, train_wall=38, gb_free=9.2, wall=136610
2023-05-22 07:54:51 - progress_bar.py[line:272] - INFO: epoch 021:    835 / 1732 loss=2.411, loss_v1=0, loss_v2=0, nll_loss=1.213, ntokens=897.4, nsentences=32, sample_size=897.4, sample_size_v1=0, sample_size_v2=0, ppl=2.32, wps=238.5, ups=0.27, wpb=897.4, bsz=32, num_updates=35410, lr=3.38841e-06, gnorm=19.511, clip=100, loss_scale=16, train_wall=38, gb_free=9, wall=136648
2023-05-22 07:55:28 - progress_bar.py[line:272] - INFO: epoch 021:    845 / 1732 loss=2.387, loss_v1=0, loss_v2=0, nll_loss=1.186, ntokens=987.4, nsentences=32, sample_size=987.4, sample_size_v1=0, sample_size_v2=0, ppl=2.28, wps=262.3, ups=0.27, wpb=987.4, bsz=32, num_updates=35420, lr=3.38636e-06, gnorm=20.114, clip=100, loss_scale=16, train_wall=38, gb_free=8.4, wall=136686
2023-05-22 07:56:06 - progress_bar.py[line:272] - INFO: epoch 021:    855 / 1732 loss=2.4, loss_v1=0, loss_v2=0, nll_loss=1.199, ntokens=952, nsentences=32, sample_size=952, sample_size_v1=0, sample_size_v2=0, ppl=2.3, wps=252.2, ups=0.26, wpb=952, bsz=32, num_updates=35430, lr=3.38431e-06, gnorm=18.52, clip=100, loss_scale=16, train_wall=38, gb_free=9.2, wall=136723
2023-05-22 07:56:44 - progress_bar.py[line:272] - INFO: epoch 021:    865 / 1732 loss=2.422, loss_v1=0, loss_v2=0, nll_loss=1.224, ntokens=968.1, nsentences=32, sample_size=968.1, sample_size_v1=0, sample_size_v2=0, ppl=2.34, wps=256.2, ups=0.26, wpb=968.1, bsz=32, num_updates=35440, lr=3.38227e-06, gnorm=19.908, clip=100, loss_scale=16, train_wall=38, gb_free=8.7, wall=136761
2023-05-22 07:57:22 - progress_bar.py[line:272] - INFO: epoch 021:    875 / 1732 loss=2.375, loss_v1=0, loss_v2=0, nll_loss=1.173, ntokens=985.7, nsentences=32, sample_size=985.7, sample_size_v1=0, sample_size_v2=0, ppl=2.26, wps=260.1, ups=0.26, wpb=985.7, bsz=32, num_updates=35450, lr=3.38022e-06, gnorm=16.853, clip=100, loss_scale=16, train_wall=38, gb_free=8.6, wall=136799
2023-05-22 07:58:00 - progress_bar.py[line:272] - INFO: epoch 021:    885 / 1732 loss=2.356, loss_v1=0, loss_v2=0, nll_loss=1.152, ntokens=961.4, nsentences=32, sample_size=961.4, sample_size_v1=0, sample_size_v2=0, ppl=2.22, wps=253.8, ups=0.26, wpb=961.4, bsz=32, num_updates=35460, lr=3.37817e-06, gnorm=18.986, clip=100, loss_scale=16, train_wall=38, gb_free=8.7, wall=136837
2023-05-22 07:58:38 - progress_bar.py[line:272] - INFO: epoch 021:    895 / 1732 loss=2.356, loss_v1=0, loss_v2=0, nll_loss=1.151, ntokens=1031.3, nsentences=32, sample_size=1031.3, sample_size_v1=0, sample_size_v2=0, ppl=2.22, wps=270.6, ups=0.26, wpb=1031.3, bsz=32, num_updates=35470, lr=3.37612e-06, gnorm=15.982, clip=100, loss_scale=16, train_wall=38, gb_free=9, wall=136875
2023-05-22 07:59:16 - progress_bar.py[line:272] - INFO: epoch 021:    905 / 1732 loss=2.357, loss_v1=0, loss_v2=0, nll_loss=1.152, ntokens=1040.4, nsentences=32, sample_size=1040.4, sample_size_v1=0, sample_size_v2=0, ppl=2.22, wps=272.9, ups=0.26, wpb=1040.4, bsz=32, num_updates=35480, lr=3.37408e-06, gnorm=18.368, clip=100, loss_scale=16, train_wall=38, gb_free=8.2, wall=136913
2023-05-22 07:59:54 - progress_bar.py[line:272] - INFO: epoch 021:    915 / 1732 loss=2.429, loss_v1=0, loss_v2=0, nll_loss=1.233, ntokens=937.6, nsentences=32, sample_size=937.6, sample_size_v1=0, sample_size_v2=0, ppl=2.35, wps=248.7, ups=0.27, wpb=937.6, bsz=32, num_updates=35490, lr=3.37203e-06, gnorm=20.911, clip=100, loss_scale=16, train_wall=38, gb_free=8.9, wall=136951
2023-05-22 08:00:32 - progress_bar.py[line:272] - INFO: epoch 021:    925 / 1732 loss=2.364, loss_v1=0, loss_v2=0, nll_loss=1.159, ntokens=1005.1, nsentences=32, sample_size=1005.1, sample_size_v1=0, sample_size_v2=0, ppl=2.23, wps=262.1, ups=0.26, wpb=1005.1, bsz=32, num_updates=35500, lr=3.36998e-06, gnorm=18.965, clip=100, loss_scale=16, train_wall=38, gb_free=8.7, wall=136989
2023-05-22 08:01:10 - progress_bar.py[line:272] - INFO: epoch 021:    935 / 1732 loss=2.381, loss_v1=0, loss_v2=0, nll_loss=1.179, ntokens=1058.5, nsentences=32, sample_size=1058.5, sample_size_v1=0, sample_size_v2=0, ppl=2.26, wps=276.5, ups=0.26, wpb=1058.5, bsz=32, num_updates=35510, lr=3.36793e-06, gnorm=17.588, clip=100, loss_scale=16, train_wall=38, gb_free=8.4, wall=137027
2023-05-22 08:01:49 - progress_bar.py[line:272] - INFO: epoch 021:    945 / 1732 loss=2.401, loss_v1=0, loss_v2=0, nll_loss=1.201, ntokens=1055.4, nsentences=32, sample_size=1055.4, sample_size_v1=0, sample_size_v2=0, ppl=2.3, wps=274.1, ups=0.26, wpb=1055.4, bsz=32, num_updates=35520, lr=3.36589e-06, gnorm=16.859, clip=100, loss_scale=16, train_wall=38, gb_free=8.4, wall=137066
2023-05-22 08:02:27 - progress_bar.py[line:272] - INFO: epoch 021:    955 / 1732 loss=2.385, loss_v1=0, loss_v2=0, nll_loss=1.183, ntokens=1040.2, nsentences=32, sample_size=1040.2, sample_size_v1=0, sample_size_v2=0, ppl=2.27, wps=270.8, ups=0.26, wpb=1040.2, bsz=32, num_updates=35530, lr=3.36384e-06, gnorm=17.217, clip=100, loss_scale=16, train_wall=38, gb_free=8.7, wall=137104
2023-05-22 08:03:06 - progress_bar.py[line:272] - INFO: epoch 021:    965 / 1732 loss=2.396, loss_v1=0, loss_v2=0, nll_loss=1.197, ntokens=1047.7, nsentences=32, sample_size=1047.7, sample_size_v1=0, sample_size_v2=0, ppl=2.29, wps=273.2, ups=0.26, wpb=1047.7, bsz=32, num_updates=35540, lr=3.36179e-06, gnorm=18.387, clip=100, loss_scale=16, train_wall=38, gb_free=8.9, wall=137143
2023-05-22 08:03:44 - progress_bar.py[line:272] - INFO: epoch 021:    975 / 1732 loss=2.392, loss_v1=0, loss_v2=0, nll_loss=1.193, ntokens=1038, nsentences=32, sample_size=1038, sample_size_v1=0, sample_size_v2=0, ppl=2.29, wps=270.1, ups=0.26, wpb=1038, bsz=32, num_updates=35550, lr=3.35974e-06, gnorm=18.076, clip=100, loss_scale=16, train_wall=38, gb_free=8.8, wall=137181
2023-05-22 08:04:22 - progress_bar.py[line:272] - INFO: epoch 021:    985 / 1732 loss=2.395, loss_v1=0, loss_v2=0, nll_loss=1.198, ntokens=1034.6, nsentences=32, sample_size=1034.6, sample_size_v1=0, sample_size_v2=0, ppl=2.29, wps=269, ups=0.26, wpb=1034.6, bsz=32, num_updates=35560, lr=3.3577e-06, gnorm=18.309, clip=100, loss_scale=32, train_wall=38, gb_free=8.7, wall=137220
2023-05-22 08:05:01 - progress_bar.py[line:272] - INFO: epoch 021:    995 / 1732 loss=2.38, loss_v1=0, loss_v2=0, nll_loss=1.179, ntokens=1048.7, nsentences=32, sample_size=1048.7, sample_size_v1=0, sample_size_v2=0, ppl=2.26, wps=273.7, ups=0.26, wpb=1048.7, bsz=32, num_updates=35570, lr=3.35565e-06, gnorm=16.76, clip=100, loss_scale=32, train_wall=38, gb_free=7.7, wall=137258
2023-05-22 08:05:39 - progress_bar.py[line:272] - INFO: epoch 021:   1005 / 1732 loss=2.379, loss_v1=0, loss_v2=0, nll_loss=1.177, ntokens=981.9, nsentences=32, sample_size=981.9, sample_size_v1=0, sample_size_v2=0, ppl=2.26, wps=257.6, ups=0.26, wpb=981.9, bsz=32, num_updates=35580, lr=3.3536e-06, gnorm=17.202, clip=100, loss_scale=32, train_wall=38, gb_free=8.3, wall=137296
2023-05-22 08:06:17 - progress_bar.py[line:272] - INFO: epoch 021:   1015 / 1732 loss=2.383, loss_v1=0, loss_v2=0, nll_loss=1.182, ntokens=996.6, nsentences=32, sample_size=996.6, sample_size_v1=0, sample_size_v2=0, ppl=2.27, wps=261.9, ups=0.26, wpb=996.6, bsz=32, num_updates=35590, lr=3.35155e-06, gnorm=16.009, clip=100, loss_scale=32, train_wall=38, gb_free=8.8, wall=137334
2023-05-22 08:06:56 - progress_bar.py[line:272] - INFO: epoch 021:   1025 / 1732 loss=2.372, loss_v1=0, loss_v2=0, nll_loss=1.17, ntokens=1087.5, nsentences=32, sample_size=1087.5, sample_size_v1=0, sample_size_v2=0, ppl=2.25, wps=280.8, ups=0.26, wpb=1087.5, bsz=32, num_updates=35600, lr=3.34951e-06, gnorm=16.433, clip=100, loss_scale=32, train_wall=39, gb_free=7.8, wall=137373
2023-05-22 08:07:34 - progress_bar.py[line:272] - INFO: epoch 021:   1035 / 1732 loss=2.379, loss_v1=0, loss_v2=0, nll_loss=1.177, ntokens=1118.6, nsentences=32, sample_size=1118.6, sample_size_v1=0, sample_size_v2=0, ppl=2.26, wps=290.4, ups=0.26, wpb=1118.6, bsz=32, num_updates=35610, lr=3.34746e-06, gnorm=15.712, clip=100, loss_scale=32, train_wall=38, gb_free=8.6, wall=137411
2023-05-22 08:08:13 - progress_bar.py[line:272] - INFO: epoch 021:   1045 / 1732 loss=2.382, loss_v1=0, loss_v2=0, nll_loss=1.182, ntokens=1030.7, nsentences=32, sample_size=1030.7, sample_size_v1=0, sample_size_v2=0, ppl=2.27, wps=268.5, ups=0.26, wpb=1030.7, bsz=32, num_updates=35620, lr=3.34541e-06, gnorm=17.921, clip=100, loss_scale=32, train_wall=38, gb_free=8.8, wall=137450
2023-05-22 08:08:51 - progress_bar.py[line:272] - INFO: epoch 021:   1055 / 1732 loss=2.385, loss_v1=0, loss_v2=0, nll_loss=1.184, ntokens=1077.2, nsentences=32, sample_size=1077.2, sample_size_v1=0, sample_size_v2=0, ppl=2.27, wps=280.3, ups=0.26, wpb=1077.2, bsz=32, num_updates=35630, lr=3.34337e-06, gnorm=18.568, clip=100, loss_scale=32, train_wall=38, gb_free=8.3, wall=137488
2023-05-22 08:09:29 - progress_bar.py[line:272] - INFO: epoch 021:   1065 / 1732 loss=2.391, loss_v1=0, loss_v2=0, nll_loss=1.192, ntokens=1021, nsentences=32, sample_size=1021, sample_size_v1=0, sample_size_v2=0, ppl=2.28, wps=267.3, ups=0.26, wpb=1021, bsz=32, num_updates=35640, lr=3.34132e-06, gnorm=19.058, clip=100, loss_scale=32, train_wall=38, gb_free=8.6, wall=137526
2023-05-22 08:10:08 - progress_bar.py[line:272] - INFO: epoch 021:   1075 / 1732 loss=2.387, loss_v1=0, loss_v2=0, nll_loss=1.185, ntokens=1007.9, nsentences=32, sample_size=1007.9, sample_size_v1=0, sample_size_v2=0, ppl=2.27, wps=261.7, ups=0.26, wpb=1007.9, bsz=32, num_updates=35650, lr=3.33927e-06, gnorm=17.869, clip=100, loss_scale=32, train_wall=38, gb_free=8.1, wall=137565
2023-05-22 08:10:46 - progress_bar.py[line:272] - INFO: epoch 021:   1085 / 1732 loss=2.397, loss_v1=0, loss_v2=0, nll_loss=1.197, ntokens=1052.2, nsentences=32, sample_size=1052.2, sample_size_v1=0, sample_size_v2=0, ppl=2.29, wps=274.3, ups=0.26, wpb=1052.2, bsz=32, num_updates=35660, lr=3.33722e-06, gnorm=18.948, clip=100, loss_scale=32, train_wall=38, gb_free=9, wall=137603
2023-05-22 08:11:25 - progress_bar.py[line:272] - INFO: epoch 021:   1095 / 1732 loss=2.395, loss_v1=0, loss_v2=0, nll_loss=1.196, ntokens=1070, nsentences=32, sample_size=1070, sample_size_v1=0, sample_size_v2=0, ppl=2.29, wps=278, ups=0.26, wpb=1070, bsz=32, num_updates=35670, lr=3.33518e-06, gnorm=18.968, clip=100, loss_scale=32, train_wall=38, gb_free=8.6, wall=137642
2023-05-22 08:12:03 - progress_bar.py[line:272] - INFO: epoch 021:   1105 / 1732 loss=2.378, loss_v1=0, loss_v2=0, nll_loss=1.176, ntokens=1032.4, nsentences=32, sample_size=1032.4, sample_size_v1=0, sample_size_v2=0, ppl=2.26, wps=269.2, ups=0.26, wpb=1032.4, bsz=32, num_updates=35680, lr=3.33313e-06, gnorm=17.956, clip=100, loss_scale=32, train_wall=38, gb_free=8.5, wall=137680
2023-05-22 08:12:41 - progress_bar.py[line:272] - INFO: epoch 021:   1115 / 1732 loss=2.393, loss_v1=0, loss_v2=0, nll_loss=1.194, ntokens=979.5, nsentences=32, sample_size=979.5, sample_size_v1=0, sample_size_v2=0, ppl=2.29, wps=255.7, ups=0.26, wpb=979.5, bsz=32, num_updates=35690, lr=3.33108e-06, gnorm=17.908, clip=100, loss_scale=32, train_wall=38, gb_free=7.9, wall=137718
2023-05-22 08:13:20 - progress_bar.py[line:272] - INFO: epoch 021:   1125 / 1732 loss=2.386, loss_v1=0, loss_v2=0, nll_loss=1.184, ntokens=994.1, nsentences=32, sample_size=994.1, sample_size_v1=0, sample_size_v2=0, ppl=2.27, wps=259.3, ups=0.26, wpb=994.1, bsz=32, num_updates=35700, lr=3.32903e-06, gnorm=18.087, clip=100, loss_scale=32, train_wall=38, gb_free=8.1, wall=137757
2023-05-22 08:13:58 - progress_bar.py[line:272] - INFO: epoch 021:   1135 / 1732 loss=2.401, loss_v1=0, loss_v2=0, nll_loss=1.203, ntokens=998.2, nsentences=32, sample_size=998.2, sample_size_v1=0, sample_size_v2=0, ppl=2.3, wps=260.8, ups=0.26, wpb=998.2, bsz=32, num_updates=35710, lr=3.32699e-06, gnorm=19.062, clip=100, loss_scale=32, train_wall=38, gb_free=8.5, wall=137795
2023-05-22 08:14:36 - progress_bar.py[line:272] - INFO: epoch 021:   1145 / 1732 loss=2.392, loss_v1=0, loss_v2=0, nll_loss=1.193, ntokens=1012.1, nsentences=32, sample_size=1012.1, sample_size_v1=0, sample_size_v2=0, ppl=2.29, wps=264.4, ups=0.26, wpb=1012.1, bsz=32, num_updates=35720, lr=3.32494e-06, gnorm=18.61, clip=100, loss_scale=32, train_wall=38, gb_free=7.9, wall=137833
2023-05-22 08:15:14 - progress_bar.py[line:272] - INFO: epoch 021:   1155 / 1732 loss=2.371, loss_v1=0, loss_v2=0, nll_loss=1.168, ntokens=1037.8, nsentences=32, sample_size=1037.8, sample_size_v1=0, sample_size_v2=0, ppl=2.25, wps=270.9, ups=0.26, wpb=1037.8, bsz=32, num_updates=35730, lr=3.32289e-06, gnorm=18.779, clip=100, loss_scale=32, train_wall=38, gb_free=8.7, wall=137872
2023-05-22 08:15:53 - progress_bar.py[line:272] - INFO: epoch 021:   1165 / 1732 loss=2.372, loss_v1=0, loss_v2=0, nll_loss=1.17, ntokens=1000.9, nsentences=32, sample_size=1000.9, sample_size_v1=0, sample_size_v2=0, ppl=2.25, wps=261.3, ups=0.26, wpb=1000.9, bsz=32, num_updates=35740, lr=3.32084e-06, gnorm=19.33, clip=100, loss_scale=32, train_wall=38, gb_free=8.4, wall=137910
2023-05-22 08:16:31 - progress_bar.py[line:272] - INFO: epoch 021:   1175 / 1732 loss=2.372, loss_v1=0, loss_v2=0, nll_loss=1.169, ntokens=1076.2, nsentences=32, sample_size=1076.2, sample_size_v1=0, sample_size_v2=0, ppl=2.25, wps=281.4, ups=0.26, wpb=1076.2, bsz=32, num_updates=35750, lr=3.3188e-06, gnorm=19.49, clip=100, loss_scale=32, train_wall=38, gb_free=8.2, wall=137948
2023-05-22 08:17:09 - progress_bar.py[line:272] - INFO: epoch 021:   1185 / 1732 loss=2.382, loss_v1=0, loss_v2=0, nll_loss=1.181, ntokens=957.5, nsentences=32, sample_size=957.5, sample_size_v1=0, sample_size_v2=0, ppl=2.27, wps=251.6, ups=0.26, wpb=957.5, bsz=32, num_updates=35760, lr=3.31675e-06, gnorm=19.928, clip=100, loss_scale=32, train_wall=38, gb_free=8.9, wall=137986
2023-05-22 08:17:48 - progress_bar.py[line:272] - INFO: epoch 021:   1195 / 1732 loss=2.398, loss_v1=0, loss_v2=0, nll_loss=1.2, ntokens=1058.2, nsentences=32, sample_size=1058.2, sample_size_v1=0, sample_size_v2=0, ppl=2.3, wps=275.4, ups=0.26, wpb=1058.2, bsz=32, num_updates=35770, lr=3.3147e-06, gnorm=17.723, clip=100, loss_scale=32, train_wall=38, gb_free=8.3, wall=138025
2023-05-22 08:18:27 - progress_bar.py[line:272] - INFO: epoch 021:   1205 / 1732 loss=2.354, loss_v1=0, loss_v2=0, nll_loss=1.148, ntokens=1142.5, nsentences=32, sample_size=1142.5, sample_size_v1=0, sample_size_v2=0, ppl=2.22, wps=292.3, ups=0.26, wpb=1142.5, bsz=32, num_updates=35780, lr=3.31265e-06, gnorm=17.001, clip=100, loss_scale=32, train_wall=39, gb_free=8.4, wall=138064
2023-05-22 08:19:05 - progress_bar.py[line:272] - INFO: epoch 021:   1215 / 1732 loss=2.394, loss_v1=0, loss_v2=0, nll_loss=1.193, ntokens=998.9, nsentences=32, sample_size=998.9, sample_size_v1=0, sample_size_v2=0, ppl=2.29, wps=261.7, ups=0.26, wpb=998.9, bsz=32, num_updates=35790, lr=3.31061e-06, gnorm=18.45, clip=100, loss_scale=32, train_wall=38, gb_free=8.9, wall=138102
2023-05-22 08:19:43 - progress_bar.py[line:272] - INFO: epoch 021:   1225 / 1732 loss=2.397, loss_v1=0, loss_v2=0, nll_loss=1.197, ntokens=1043.3, nsentences=32, sample_size=1043.3, sample_size_v1=0, sample_size_v2=0, ppl=2.29, wps=271.2, ups=0.26, wpb=1043.3, bsz=32, num_updates=35800, lr=3.30856e-06, gnorm=19.535, clip=100, loss_scale=32, train_wall=38, gb_free=8.9, wall=138140
2023-05-22 08:20:22 - progress_bar.py[line:272] - INFO: epoch 021:   1235 / 1732 loss=2.368, loss_v1=0, loss_v2=0, nll_loss=1.163, ntokens=1038.1, nsentences=32, sample_size=1038.1, sample_size_v1=0, sample_size_v2=0, ppl=2.24, wps=270, ups=0.26, wpb=1038.1, bsz=32, num_updates=35810, lr=3.30651e-06, gnorm=17.2, clip=100, loss_scale=32, train_wall=38, gb_free=7.5, wall=138179
2023-05-22 08:21:00 - progress_bar.py[line:272] - INFO: epoch 021:   1245 / 1732 loss=2.322, loss_v1=0, loss_v2=0, nll_loss=1.113, ntokens=1088.5, nsentences=32, sample_size=1088.5, sample_size_v1=0, sample_size_v2=0, ppl=2.16, wps=282.3, ups=0.26, wpb=1088.5, bsz=32, num_updates=35820, lr=3.30447e-06, gnorm=17.86, clip=100, loss_scale=32, train_wall=39, gb_free=8.3, wall=138218
2023-05-22 08:21:39 - progress_bar.py[line:272] - INFO: epoch 021:   1255 / 1732 loss=2.35, loss_v1=0, loss_v2=0, nll_loss=1.146, ntokens=1068.9, nsentences=32, sample_size=1068.9, sample_size_v1=0, sample_size_v2=0, ppl=2.21, wps=278.6, ups=0.26, wpb=1068.9, bsz=32, num_updates=35830, lr=3.30242e-06, gnorm=17.519, clip=100, loss_scale=32, train_wall=38, gb_free=8.2, wall=138256
2023-05-22 08:22:17 - progress_bar.py[line:272] - INFO: epoch 021:   1265 / 1732 loss=2.394, loss_v1=0, loss_v2=0, nll_loss=1.194, ntokens=1072.6, nsentences=32, sample_size=1072.6, sample_size_v1=0, sample_size_v2=0, ppl=2.29, wps=278.2, ups=0.26, wpb=1072.6, bsz=32, num_updates=35840, lr=3.30037e-06, gnorm=16.978, clip=100, loss_scale=32, train_wall=39, gb_free=9.2, wall=138294
2023-05-22 08:22:48 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2023-05-22 08:22:59 - progress_bar.py[line:272] - INFO: epoch 021:   1276 / 1732 loss=2.383, loss_v1=0, loss_v2=0, nll_loss=1.182, ntokens=1071.2, nsentences=32, sample_size=1071.2, sample_size_v1=0, sample_size_v2=0, ppl=2.27, wps=253.4, ups=0.24, wpb=1071.2, bsz=32, num_updates=35850, lr=3.29832e-06, gnorm=17.665, clip=100, loss_scale=16, train_wall=42, gb_free=8.1, wall=138337
2023-05-22 08:23:38 - progress_bar.py[line:272] - INFO: epoch 021:   1286 / 1732 loss=2.38, loss_v1=0, loss_v2=0, nll_loss=1.179, ntokens=1038.1, nsentences=32, sample_size=1038.1, sample_size_v1=0, sample_size_v2=0, ppl=2.26, wps=269.7, ups=0.26, wpb=1038.1, bsz=32, num_updates=35860, lr=3.29628e-06, gnorm=18.571, clip=100, loss_scale=16, train_wall=38, gb_free=8.8, wall=138375
2023-05-22 08:24:17 - progress_bar.py[line:272] - INFO: epoch 021:   1296 / 1732 loss=2.352, loss_v1=0, loss_v2=0, nll_loss=1.147, ntokens=1121.3, nsentences=32, sample_size=1121.3, sample_size_v1=0, sample_size_v2=0, ppl=2.21, wps=290.5, ups=0.26, wpb=1121.3, bsz=32, num_updates=35870, lr=3.29423e-06, gnorm=16.02, clip=100, loss_scale=16, train_wall=39, gb_free=8.4, wall=138414
2023-05-22 08:24:55 - progress_bar.py[line:272] - INFO: epoch 021:   1306 / 1732 loss=2.393, loss_v1=0, loss_v2=0, nll_loss=1.193, ntokens=1091, nsentences=32, sample_size=1091, sample_size_v1=0, sample_size_v2=0, ppl=2.29, wps=281.2, ups=0.26, wpb=1091, bsz=32, num_updates=35880, lr=3.29218e-06, gnorm=15.702, clip=100, loss_scale=16, train_wall=39, gb_free=7.8, wall=138453
2023-05-22 08:25:34 - progress_bar.py[line:272] - INFO: epoch 021:   1316 / 1732 loss=2.381, loss_v1=0, loss_v2=0, nll_loss=1.18, ntokens=1049.3, nsentences=32, sample_size=1049.3, sample_size_v1=0, sample_size_v2=0, ppl=2.27, wps=271.9, ups=0.26, wpb=1049.3, bsz=32, num_updates=35890, lr=3.29013e-06, gnorm=18.578, clip=100, loss_scale=16, train_wall=39, gb_free=8.6, wall=138491
2023-05-22 08:26:13 - progress_bar.py[line:272] - INFO: epoch 021:   1326 / 1732 loss=2.363, loss_v1=0, loss_v2=0, nll_loss=1.159, ntokens=1110.6, nsentences=32, sample_size=1110.6, sample_size_v1=0, sample_size_v2=0, ppl=2.23, wps=285.5, ups=0.26, wpb=1110.6, bsz=32, num_updates=35900, lr=3.28809e-06, gnorm=18.023, clip=100, loss_scale=16, train_wall=39, gb_free=8.7, wall=138530
2023-05-22 08:26:52 - progress_bar.py[line:272] - INFO: epoch 021:   1336 / 1732 loss=2.356, loss_v1=0, loss_v2=0, nll_loss=1.151, ntokens=1122.3, nsentences=32, sample_size=1122.3, sample_size_v1=0, sample_size_v2=0, ppl=2.22, wps=290.1, ups=0.26, wpb=1122.3, bsz=32, num_updates=35910, lr=3.28604e-06, gnorm=20, clip=100, loss_scale=16, train_wall=39, gb_free=8.2, wall=138569
2023-05-22 08:27:31 - progress_bar.py[line:272] - INFO: epoch 021:   1346 / 1732 loss=2.361, loss_v1=0, loss_v2=0, nll_loss=1.158, ntokens=1171.7, nsentences=32, sample_size=1171.7, sample_size_v1=0, sample_size_v2=0, ppl=2.23, wps=300.2, ups=0.26, wpb=1171.7, bsz=32, num_updates=35920, lr=3.28399e-06, gnorm=17.313, clip=100, loss_scale=16, train_wall=39, gb_free=8.1, wall=138608
2023-05-22 08:28:09 - progress_bar.py[line:272] - INFO: epoch 021:   1356 / 1732 loss=2.349, loss_v1=0, loss_v2=0, nll_loss=1.144, ntokens=1137.3, nsentences=32, sample_size=1137.3, sample_size_v1=0, sample_size_v2=0, ppl=2.21, wps=294, ups=0.26, wpb=1137.3, bsz=32, num_updates=35930, lr=3.28194e-06, gnorm=17.551, clip=100, loss_scale=16, train_wall=39, gb_free=8.4, wall=138647
2023-05-22 08:28:48 - progress_bar.py[line:272] - INFO: epoch 021:   1366 / 1732 loss=2.354, loss_v1=0, loss_v2=0, nll_loss=1.15, ntokens=1081.4, nsentences=32, sample_size=1081.4, sample_size_v1=0, sample_size_v2=0, ppl=2.22, wps=279.8, ups=0.26, wpb=1081.4, bsz=32, num_updates=35940, lr=3.2799e-06, gnorm=17.702, clip=100, loss_scale=16, train_wall=39, gb_free=8.8, wall=138685
2023-05-22 08:29:26 - progress_bar.py[line:272] - INFO: epoch 021:   1376 / 1732 loss=2.409, loss_v1=0, loss_v2=0, nll_loss=1.212, ntokens=1111.5, nsentences=32, sample_size=1111.5, sample_size_v1=0, sample_size_v2=0, ppl=2.32, wps=288.4, ups=0.26, wpb=1111.5, bsz=32, num_updates=35950, lr=3.27785e-06, gnorm=17.956, clip=100, loss_scale=16, train_wall=38, gb_free=8, wall=138724
2023-05-22 08:30:05 - progress_bar.py[line:272] - INFO: epoch 021:   1386 / 1732 loss=2.365, loss_v1=0, loss_v2=0, nll_loss=1.161, ntokens=1153.3, nsentences=32, sample_size=1153.3, sample_size_v1=0, sample_size_v2=0, ppl=2.24, wps=300.4, ups=0.26, wpb=1153.3, bsz=32, num_updates=35960, lr=3.2758e-06, gnorm=16.793, clip=100, loss_scale=16, train_wall=38, gb_free=8.9, wall=138762
2023-05-22 08:30:43 - progress_bar.py[line:272] - INFO: epoch 021:   1396 / 1732 loss=2.368, loss_v1=0, loss_v2=0, nll_loss=1.165, ntokens=1044.6, nsentences=32, sample_size=1044.6, sample_size_v1=0, sample_size_v2=0, ppl=2.24, wps=271.6, ups=0.26, wpb=1044.6, bsz=32, num_updates=35970, lr=3.27375e-06, gnorm=19.65, clip=100, loss_scale=16, train_wall=38, gb_free=8.6, wall=138801
2023-05-22 08:31:22 - progress_bar.py[line:272] - INFO: epoch 021:   1406 / 1732 loss=2.37, loss_v1=0, loss_v2=0, nll_loss=1.168, ntokens=1163.8, nsentences=32, sample_size=1163.8, sample_size_v1=0, sample_size_v2=0, ppl=2.25, wps=301.5, ups=0.26, wpb=1163.8, bsz=32, num_updates=35980, lr=3.27171e-06, gnorm=17.834, clip=100, loss_scale=16, train_wall=39, gb_free=8.7, wall=138839
2023-05-22 08:32:01 - progress_bar.py[line:272] - INFO: epoch 021:   1416 / 1732 loss=2.393, loss_v1=0, loss_v2=0, nll_loss=1.193, ntokens=1281, nsentences=32, sample_size=1281, sample_size_v1=0, sample_size_v2=0, ppl=2.29, wps=328.2, ups=0.26, wpb=1281, bsz=32, num_updates=35990, lr=3.26966e-06, gnorm=16.492, clip=100, loss_scale=16, train_wall=39, gb_free=7.6, wall=138878
2023-05-22 08:32:40 - progress_bar.py[line:272] - INFO: epoch 021:   1426 / 1732 loss=2.344, loss_v1=0, loss_v2=0, nll_loss=1.137, ntokens=1225.6, nsentences=32, sample_size=1225.6, sample_size_v1=0, sample_size_v2=0, ppl=2.2, wps=314.7, ups=0.26, wpb=1225.6, bsz=32, num_updates=36000, lr=3.26761e-06, gnorm=16.952, clip=100, loss_scale=16, train_wall=39, gb_free=7.7, wall=138917
2023-05-22 08:33:19 - progress_bar.py[line:272] - INFO: epoch 021:   1436 / 1732 loss=2.356, loss_v1=0, loss_v2=0, nll_loss=1.15, ntokens=1219.4, nsentences=32, sample_size=1219.4, sample_size_v1=0, sample_size_v2=0, ppl=2.22, wps=315.9, ups=0.26, wpb=1219.4, bsz=32, num_updates=36010, lr=3.26557e-06, gnorm=15.672, clip=100, loss_scale=16, train_wall=39, gb_free=8.1, wall=138956
2023-05-22 08:33:57 - progress_bar.py[line:272] - INFO: epoch 021:   1446 / 1732 loss=2.391, loss_v1=0, loss_v2=0, nll_loss=1.19, ntokens=1113.8, nsentences=32, sample_size=1113.8, sample_size_v1=0, sample_size_v2=0, ppl=2.28, wps=288.9, ups=0.26, wpb=1113.8, bsz=32, num_updates=36020, lr=3.26352e-06, gnorm=17.304, clip=100, loss_scale=16, train_wall=39, gb_free=8.5, wall=138994
2023-05-22 08:34:36 - progress_bar.py[line:272] - INFO: epoch 021:   1456 / 1732 loss=2.384, loss_v1=0, loss_v2=0, nll_loss=1.183, ntokens=1106.5, nsentences=32, sample_size=1106.5, sample_size_v1=0, sample_size_v2=0, ppl=2.27, wps=286.8, ups=0.26, wpb=1106.5, bsz=32, num_updates=36030, lr=3.26147e-06, gnorm=17.112, clip=100, loss_scale=16, train_wall=39, gb_free=8.2, wall=139033
2023-05-22 08:35:14 - progress_bar.py[line:272] - INFO: epoch 021:   1466 / 1732 loss=2.319, loss_v1=0, loss_v2=0, nll_loss=1.11, ntokens=1200.2, nsentences=32, sample_size=1200.2, sample_size_v1=0, sample_size_v2=0, ppl=2.16, wps=309.4, ups=0.26, wpb=1200.2, bsz=32, num_updates=36040, lr=3.25942e-06, gnorm=16.432, clip=100, loss_scale=16, train_wall=39, gb_free=8.4, wall=139072
2023-05-22 08:35:53 - progress_bar.py[line:272] - INFO: epoch 021:   1476 / 1732 loss=2.389, loss_v1=0, loss_v2=0, nll_loss=1.189, ntokens=1071.6, nsentences=32, sample_size=1071.6, sample_size_v1=0, sample_size_v2=0, ppl=2.28, wps=278.9, ups=0.26, wpb=1071.6, bsz=32, num_updates=36050, lr=3.25738e-06, gnorm=18.145, clip=100, loss_scale=16, train_wall=38, gb_free=8.4, wall=139110
2023-05-22 08:36:32 - progress_bar.py[line:272] - INFO: epoch 021:   1486 / 1732 loss=2.384, loss_v1=0, loss_v2=0, nll_loss=1.184, ntokens=1132, nsentences=32, sample_size=1132, sample_size_v1=0, sample_size_v2=0, ppl=2.27, wps=292.7, ups=0.26, wpb=1132, bsz=32, num_updates=36060, lr=3.25533e-06, gnorm=17.382, clip=100, loss_scale=16, train_wall=39, gb_free=7.6, wall=139149
2023-05-22 08:37:10 - progress_bar.py[line:272] - INFO: epoch 021:   1496 / 1732 loss=2.353, loss_v1=0, loss_v2=0, nll_loss=1.148, ntokens=1113.1, nsentences=32, sample_size=1113.1, sample_size_v1=0, sample_size_v2=0, ppl=2.22, wps=286.6, ups=0.26, wpb=1113.1, bsz=32, num_updates=36070, lr=3.25328e-06, gnorm=17.32, clip=100, loss_scale=16, train_wall=39, gb_free=8.1, wall=139188
2023-05-22 08:37:49 - progress_bar.py[line:272] - INFO: epoch 021:   1506 / 1732 loss=2.315, loss_v1=0, loss_v2=0, nll_loss=1.105, ntokens=1117, nsentences=32, sample_size=1117, sample_size_v1=0, sample_size_v2=0, ppl=2.15, wps=290.9, ups=0.26, wpb=1117, bsz=32, num_updates=36080, lr=3.25123e-06, gnorm=17.055, clip=100, loss_scale=16, train_wall=38, gb_free=8.6, wall=139226
2023-05-22 08:38:27 - progress_bar.py[line:272] - INFO: epoch 021:   1516 / 1732 loss=2.383, loss_v1=0, loss_v2=0, nll_loss=1.181, ntokens=1043.6, nsentences=32, sample_size=1043.6, sample_size_v1=0, sample_size_v2=0, ppl=2.27, wps=272.6, ups=0.26, wpb=1043.6, bsz=32, num_updates=36090, lr=3.24919e-06, gnorm=18.016, clip=100, loss_scale=16, train_wall=38, gb_free=8.5, wall=139264
2023-05-22 08:39:05 - progress_bar.py[line:272] - INFO: epoch 021:   1526 / 1732 loss=2.417, loss_v1=0, loss_v2=0, nll_loss=1.221, ntokens=1063.1, nsentences=32, sample_size=1063.1, sample_size_v1=0, sample_size_v2=0, ppl=2.33, wps=277.1, ups=0.26, wpb=1063.1, bsz=32, num_updates=36100, lr=3.24714e-06, gnorm=17.93, clip=100, loss_scale=16, train_wall=38, gb_free=8.4, wall=139303
2023-05-22 08:39:44 - progress_bar.py[line:272] - INFO: epoch 021:   1536 / 1732 loss=2.368, loss_v1=0, loss_v2=0, nll_loss=1.165, ntokens=1073.8, nsentences=32, sample_size=1073.8, sample_size_v1=0, sample_size_v2=0, ppl=2.24, wps=278.4, ups=0.26, wpb=1073.8, bsz=32, num_updates=36110, lr=3.24509e-06, gnorm=18.487, clip=100, loss_scale=16, train_wall=39, gb_free=8.4, wall=139341
2023-05-22 08:40:22 - progress_bar.py[line:272] - INFO: epoch 021:   1546 / 1732 loss=2.342, loss_v1=0, loss_v2=0, nll_loss=1.136, ntokens=1068.6, nsentences=32, sample_size=1068.6, sample_size_v1=0, sample_size_v2=0, ppl=2.2, wps=278.5, ups=0.26, wpb=1068.6, bsz=32, num_updates=36120, lr=3.24304e-06, gnorm=17.865, clip=100, loss_scale=16, train_wall=38, gb_free=8.3, wall=139380
2023-05-22 08:41:01 - progress_bar.py[line:272] - INFO: epoch 021:   1556 / 1732 loss=2.361, loss_v1=0, loss_v2=0, nll_loss=1.157, ntokens=1070.8, nsentences=32, sample_size=1070.8, sample_size_v1=0, sample_size_v2=0, ppl=2.23, wps=278.9, ups=0.26, wpb=1070.8, bsz=32, num_updates=36130, lr=3.241e-06, gnorm=18.091, clip=100, loss_scale=16, train_wall=38, gb_free=8.4, wall=139418
2023-05-22 08:41:39 - progress_bar.py[line:272] - INFO: epoch 021:   1566 / 1732 loss=2.402, loss_v1=0, loss_v2=0, nll_loss=1.203, ntokens=1097.4, nsentences=32, sample_size=1097.4, sample_size_v1=0, sample_size_v2=0, ppl=2.3, wps=285.4, ups=0.26, wpb=1097.4, bsz=32, num_updates=36140, lr=3.23895e-06, gnorm=17.243, clip=100, loss_scale=16, train_wall=38, gb_free=8.8, wall=139456
2023-05-22 08:42:18 - progress_bar.py[line:272] - INFO: epoch 021:   1576 / 1732 loss=2.407, loss_v1=0, loss_v2=0, nll_loss=1.209, ntokens=1019.9, nsentences=32, sample_size=1019.9, sample_size_v1=0, sample_size_v2=0, ppl=2.31, wps=265.1, ups=0.26, wpb=1019.9, bsz=32, num_updates=36150, lr=3.2369e-06, gnorm=21.367, clip=100, loss_scale=16, train_wall=38, gb_free=8.7, wall=139495
2023-05-22 08:42:56 - progress_bar.py[line:272] - INFO: epoch 021:   1586 / 1732 loss=2.383, loss_v1=0, loss_v2=0, nll_loss=1.181, ntokens=1060.6, nsentences=32, sample_size=1060.6, sample_size_v1=0, sample_size_v2=0, ppl=2.27, wps=274.1, ups=0.26, wpb=1060.6, bsz=32, num_updates=36160, lr=3.23485e-06, gnorm=17.985, clip=100, loss_scale=16, train_wall=39, gb_free=8.2, wall=139534
2023-05-22 08:43:35 - progress_bar.py[line:272] - INFO: epoch 021:   1596 / 1732 loss=2.341, loss_v1=0, loss_v2=0, nll_loss=1.136, ntokens=1073.8, nsentences=32, sample_size=1073.8, sample_size_v1=0, sample_size_v2=0, ppl=2.2, wps=279.2, ups=0.26, wpb=1073.8, bsz=32, num_updates=36170, lr=3.23281e-06, gnorm=16.93, clip=100, loss_scale=16, train_wall=38, gb_free=8.4, wall=139572
2023-05-22 08:44:13 - progress_bar.py[line:272] - INFO: epoch 021:   1606 / 1732 loss=2.367, loss_v1=0, loss_v2=0, nll_loss=1.166, ntokens=1124, nsentences=32, sample_size=1124, sample_size_v1=0, sample_size_v2=0, ppl=2.24, wps=291.7, ups=0.26, wpb=1124, bsz=32, num_updates=36180, lr=3.23076e-06, gnorm=18.863, clip=100, loss_scale=16, train_wall=38, gb_free=8.2, wall=139611
2023-05-22 08:44:52 - progress_bar.py[line:272] - INFO: epoch 021:   1616 / 1732 loss=2.322, loss_v1=0, loss_v2=0, nll_loss=1.115, ntokens=1154.1, nsentences=32, sample_size=1154.1, sample_size_v1=0, sample_size_v2=0, ppl=2.17, wps=297.6, ups=0.26, wpb=1154.1, bsz=32, num_updates=36190, lr=3.22871e-06, gnorm=17.476, clip=100, loss_scale=16, train_wall=39, gb_free=8.7, wall=139649
2023-05-22 08:45:31 - progress_bar.py[line:272] - INFO: epoch 021:   1626 / 1732 loss=2.357, loss_v1=0, loss_v2=0, nll_loss=1.154, ntokens=1109.2, nsentences=32, sample_size=1109.2, sample_size_v1=0, sample_size_v2=0, ppl=2.22, wps=286.5, ups=0.26, wpb=1109.2, bsz=32, num_updates=36200, lr=3.22667e-06, gnorm=16.085, clip=100, loss_scale=16, train_wall=39, gb_free=8.5, wall=139688
2023-05-22 08:46:09 - progress_bar.py[line:272] - INFO: epoch 021:   1636 / 1732 loss=2.343, loss_v1=0, loss_v2=0, nll_loss=1.136, ntokens=1146, nsentences=32, sample_size=1146, sample_size_v1=0, sample_size_v2=0, ppl=2.2, wps=297.4, ups=0.26, wpb=1146, bsz=32, num_updates=36210, lr=3.22462e-06, gnorm=16.337, clip=100, loss_scale=16, train_wall=38, gb_free=9.1, wall=139727
2023-05-22 08:46:49 - progress_bar.py[line:272] - INFO: epoch 021:   1646 / 1732 loss=2.321, loss_v1=0, loss_v2=0, nll_loss=1.113, ntokens=1290.2, nsentences=32, sample_size=1290.2, sample_size_v1=0, sample_size_v2=0, ppl=2.16, wps=328.6, ups=0.25, wpb=1290.2, bsz=32, num_updates=36220, lr=3.22257e-06, gnorm=15.246, clip=100, loss_scale=16, train_wall=39, gb_free=8.2, wall=139766
2023-05-22 08:47:27 - progress_bar.py[line:272] - INFO: epoch 021:   1656 / 1732 loss=2.386, loss_v1=0, loss_v2=0, nll_loss=1.185, ntokens=952.5, nsentences=32, sample_size=952.5, sample_size_v1=0, sample_size_v2=0, ppl=2.27, wps=250.1, ups=0.26, wpb=952.5, bsz=32, num_updates=36230, lr=3.22052e-06, gnorm=19.156, clip=100, loss_scale=16, train_wall=38, gb_free=8.5, wall=139804
2023-05-22 08:48:05 - progress_bar.py[line:272] - INFO: epoch 021:   1666 / 1732 loss=2.378, loss_v1=0, loss_v2=0, nll_loss=1.177, ntokens=1015, nsentences=32, sample_size=1015, sample_size_v1=0, sample_size_v2=0, ppl=2.26, wps=264.1, ups=0.26, wpb=1015, bsz=32, num_updates=36240, lr=3.21848e-06, gnorm=17.427, clip=100, loss_scale=16, train_wall=38, gb_free=8.5, wall=139842
2023-05-22 08:48:44 - progress_bar.py[line:272] - INFO: epoch 021:   1676 / 1732 loss=2.322, loss_v1=0, loss_v2=0, nll_loss=1.113, ntokens=1119.1, nsentences=32, sample_size=1119.1, sample_size_v1=0, sample_size_v2=0, ppl=2.16, wps=290.5, ups=0.26, wpb=1119.1, bsz=32, num_updates=36250, lr=3.21643e-06, gnorm=16.868, clip=100, loss_scale=16, train_wall=38, gb_free=8.3, wall=139881
2023-05-22 08:49:23 - progress_bar.py[line:272] - INFO: epoch 021:   1686 / 1732 loss=2.319, loss_v1=0, loss_v2=0, nll_loss=1.11, ntokens=1151.6, nsentences=32, sample_size=1151.6, sample_size_v1=0, sample_size_v2=0, ppl=2.16, wps=297, ups=0.26, wpb=1151.6, bsz=32, num_updates=36260, lr=3.21438e-06, gnorm=16.171, clip=100, loss_scale=16, train_wall=39, gb_free=7.7, wall=139920
2023-05-22 08:50:02 - progress_bar.py[line:272] - INFO: epoch 021:   1696 / 1732 loss=2.359, loss_v1=0, loss_v2=0, nll_loss=1.157, ntokens=1284.6, nsentences=32, sample_size=1284.6, sample_size_v1=0, sample_size_v2=0, ppl=2.23, wps=325.6, ups=0.25, wpb=1284.6, bsz=32, num_updates=36270, lr=3.21233e-06, gnorm=16.865, clip=100, loss_scale=16, train_wall=39, gb_free=7.9, wall=139959
2023-05-22 08:50:41 - progress_bar.py[line:272] - INFO: epoch 021:   1706 / 1732 loss=2.351, loss_v1=0, loss_v2=0, nll_loss=1.146, ntokens=1193.5, nsentences=32, sample_size=1193.5, sample_size_v1=0, sample_size_v2=0, ppl=2.21, wps=306, ups=0.26, wpb=1193.5, bsz=32, num_updates=36280, lr=3.21029e-06, gnorm=16.424, clip=100, loss_scale=16, train_wall=39, gb_free=7.9, wall=139998
2023-05-22 08:51:20 - progress_bar.py[line:272] - INFO: epoch 021:   1716 / 1732 loss=2.342, loss_v1=0, loss_v2=0, nll_loss=1.135, ntokens=1213.9, nsentences=32, sample_size=1213.9, sample_size_v1=0, sample_size_v2=0, ppl=2.2, wps=311.6, ups=0.26, wpb=1213.9, bsz=32, num_updates=36290, lr=3.20824e-06, gnorm=16.384, clip=100, loss_scale=16, train_wall=39, gb_free=7.4, wall=140037
2023-05-22 08:51:59 - progress_bar.py[line:272] - INFO: epoch 021:   1726 / 1732 loss=2.377, loss_v1=0, loss_v2=0, nll_loss=1.176, ntokens=1112.1, nsentences=32, sample_size=1112.1, sample_size_v1=0, sample_size_v2=0, ppl=2.26, wps=287.6, ups=0.26, wpb=1112.1, bsz=32, num_updates=36300, lr=3.20619e-06, gnorm=16.078, clip=100, loss_scale=16, train_wall=39, gb_free=8.3, wall=140076
2023-05-22 08:52:19 - train.py[line:332] - INFO: end of epoch 21 (average epoch stats below)
2023-05-22 08:52:19 - progress_bar.py[line:282] - INFO: epoch 021 | loss 2.37 | loss_v1 0 | loss_v2 0 | nll_loss 1.168 | ntokens 1051.6 | nsentences 31.986 | sample_size 1051.6 | sample_size_v1 0 | sample_size_v2 0 | ppl 2.25 | wps 274 | ups 0.26 | wpb 1051.6 | bsz 32 | num_updates 36306 | lr 3.20496e-06 | gnorm 17.639 | clip 100 | loss_scale 16 | train_wall 6626 | gb_free 8.9 | wall 140096
2023-05-22 08:52:19 - trainer.py[line:639] - INFO: loading train data for epoch 22
local datafile ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 0 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 0 finished initializing row_count and line_idx-to-offset mapping
file ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 0 row count 55400 total row count 55400
slice_id 0 seek offset 0
2023-05-22 08:52:21 - trainer.py[line:703] - INFO: begin training epoch 22
2023-05-22 08:52:21 - train.py[line:305] - INFO: Start iterating over samples
2023-05-22 08:52:37 - progress_bar.py[line:272] - INFO: epoch 022:      4 / 1732 loss=2.355, loss_v1=0, loss_v2=0, nll_loss=1.151, ntokens=1098.7, nsentences=29.6, sample_size=1098.7, sample_size_v1=0, sample_size_v2=0, ppl=2.22, wps=288.5, ups=0.26, wpb=1098.7, bsz=29.6, num_updates=36310, lr=3.20414e-06, gnorm=18.255, clip=100, loss_scale=16, train_wall=36, gb_free=8, wall=140114
2023-05-22 08:53:15 - progress_bar.py[line:272] - INFO: epoch 022:     14 / 1732 loss=2.308, loss_v1=0, loss_v2=0, nll_loss=1.097, ntokens=1064.2, nsentences=32, sample_size=1064.2, sample_size_v1=0, sample_size_v2=0, ppl=2.14, wps=277, ups=0.26, wpb=1064.2, bsz=32, num_updates=36320, lr=3.2021e-06, gnorm=18.623, clip=100, loss_scale=16, train_wall=38, gb_free=8.3, wall=140152
2023-05-22 08:53:54 - progress_bar.py[line:272] - INFO: epoch 022:     24 / 1732 loss=2.265, loss_v1=0, loss_v2=0, nll_loss=1.049, ntokens=1038.3, nsentences=32, sample_size=1038.3, sample_size_v1=0, sample_size_v2=0, ppl=2.07, wps=268.5, ups=0.26, wpb=1038.3, bsz=32, num_updates=36330, lr=3.20005e-06, gnorm=17.059, clip=100, loss_scale=16, train_wall=39, gb_free=8.5, wall=140191
2023-05-22 08:54:33 - progress_bar.py[line:272] - INFO: epoch 022:     34 / 1732 loss=2.203, loss_v1=0, loss_v2=0, nll_loss=0.979, ntokens=1072.7, nsentences=32, sample_size=1072.7, sample_size_v1=0, sample_size_v2=0, ppl=1.97, wps=276, ups=0.26, wpb=1072.7, bsz=32, num_updates=36340, lr=3.198e-06, gnorm=14.224, clip=100, loss_scale=16, train_wall=39, gb_free=8.2, wall=140230
2023-05-22 08:55:12 - progress_bar.py[line:272] - INFO: epoch 022:     44 / 1732 loss=2.158, loss_v1=0, loss_v2=0, nll_loss=0.932, ntokens=1134, nsentences=32, sample_size=1134, sample_size_v1=0, sample_size_v2=0, ppl=1.91, wps=292.4, ups=0.26, wpb=1134, bsz=32, num_updates=36350, lr=3.19595e-06, gnorm=13.066, clip=100, loss_scale=16, train_wall=39, gb_free=8.1, wall=140269
2023-05-22 08:55:50 - progress_bar.py[line:272] - INFO: epoch 022:     54 / 1732 loss=2.172, loss_v1=0, loss_v2=0, nll_loss=0.95, ntokens=1025.8, nsentences=32, sample_size=1025.8, sample_size_v1=0, sample_size_v2=0, ppl=1.93, wps=264.2, ups=0.26, wpb=1025.8, bsz=32, num_updates=36360, lr=3.19391e-06, gnorm=15.181, clip=100, loss_scale=32, train_wall=39, gb_free=8.4, wall=140308
2023-05-22 08:56:29 - progress_bar.py[line:272] - INFO: epoch 022:     64 / 1732 loss=1.999, loss_v1=0, loss_v2=0, nll_loss=0.758, ntokens=1253.8, nsentences=32, sample_size=1253.8, sample_size_v1=0, sample_size_v2=0, ppl=1.69, wps=320.8, ups=0.26, wpb=1253.8, bsz=32, num_updates=36370, lr=3.19186e-06, gnorm=12.242, clip=100, loss_scale=32, train_wall=39, gb_free=7.8, wall=140347
2023-05-22 08:57:09 - progress_bar.py[line:272] - INFO: epoch 022:     74 / 1732 loss=2.125, loss_v1=0, loss_v2=0, nll_loss=0.895, ntokens=1358.9, nsentences=32, sample_size=1358.9, sample_size_v1=0, sample_size_v2=0, ppl=1.86, wps=342, ups=0.25, wpb=1358.9, bsz=32, num_updates=36380, lr=3.18981e-06, gnorm=12.956, clip=100, loss_scale=32, train_wall=40, gb_free=7.3, wall=140386
2023-05-22 08:57:48 - progress_bar.py[line:272] - INFO: epoch 022:     84 / 1732 loss=2.161, loss_v1=0, loss_v2=0, nll_loss=0.933, ntokens=1166.6, nsentences=32, sample_size=1166.6, sample_size_v1=0, sample_size_v2=0, ppl=1.91, wps=297.2, ups=0.25, wpb=1166.6, bsz=32, num_updates=36390, lr=3.18776e-06, gnorm=16.498, clip=100, loss_scale=32, train_wall=39, gb_free=7.6, wall=140426
2023-05-22 08:58:27 - progress_bar.py[line:272] - INFO: epoch 022:     94 / 1732 loss=2.148, loss_v1=0, loss_v2=0, nll_loss=0.916, ntokens=1099.4, nsentences=32, sample_size=1099.4, sample_size_v1=0, sample_size_v2=0, ppl=1.89, wps=284.4, ups=0.26, wpb=1099.4, bsz=32, num_updates=36400, lr=3.18572e-06, gnorm=15.555, clip=100, loss_scale=32, train_wall=39, gb_free=8.8, wall=140464
2023-05-22 08:59:05 - progress_bar.py[line:272] - INFO: epoch 022:    104 / 1732 loss=2.318, loss_v1=0, loss_v2=0, nll_loss=1.11, ntokens=968, nsentences=32, sample_size=968, sample_size_v1=0, sample_size_v2=0, ppl=2.16, wps=253.9, ups=0.26, wpb=968, bsz=32, num_updates=36410, lr=3.18367e-06, gnorm=20.048, clip=100, loss_scale=32, train_wall=38, gb_free=8.7, wall=140502
2023-05-22 08:59:44 - progress_bar.py[line:272] - INFO: epoch 022:    114 / 1732 loss=2.391, loss_v1=0, loss_v2=0, nll_loss=1.19, ntokens=1043.8, nsentences=32, sample_size=1043.8, sample_size_v1=0, sample_size_v2=0, ppl=2.28, wps=270.9, ups=0.26, wpb=1043.8, bsz=32, num_updates=36420, lr=3.18162e-06, gnorm=19.068, clip=100, loss_scale=32, train_wall=38, gb_free=8.4, wall=140541
2023-05-22 09:00:23 - progress_bar.py[line:272] - INFO: epoch 022:    124 / 1732 loss=2.328, loss_v1=0, loss_v2=0, nll_loss=1.118, ntokens=1156.9, nsentences=32, sample_size=1156.9, sample_size_v1=0, sample_size_v2=0, ppl=2.17, wps=295, ups=0.25, wpb=1156.9, bsz=32, num_updates=36430, lr=3.17958e-06, gnorm=16.581, clip=100, loss_scale=32, train_wall=39, gb_free=8, wall=140580
2023-05-22 09:01:02 - progress_bar.py[line:272] - INFO: epoch 022:    134 / 1732 loss=2.285, loss_v1=0, loss_v2=0, nll_loss=1.071, ntokens=1187.1, nsentences=32, sample_size=1187.1, sample_size_v1=0, sample_size_v2=0, ppl=2.1, wps=303.9, ups=0.26, wpb=1187.1, bsz=32, num_updates=36440, lr=3.17753e-06, gnorm=15.845, clip=100, loss_scale=32, train_wall=39, gb_free=8.7, wall=140619
2023-05-22 09:01:41 - progress_bar.py[line:272] - INFO: epoch 022:    144 / 1732 loss=2.274, loss_v1=0, loss_v2=0, nll_loss=1.061, ntokens=1239.8, nsentences=32, sample_size=1239.8, sample_size_v1=0, sample_size_v2=0, ppl=2.09, wps=314.9, ups=0.25, wpb=1239.8, bsz=32, num_updates=36450, lr=3.17548e-06, gnorm=13.581, clip=100, loss_scale=32, train_wall=39, gb_free=7.6, wall=140659
2023-05-22 09:02:21 - progress_bar.py[line:272] - INFO: epoch 022:    154 / 1732 loss=2.278, loss_v1=0, loss_v2=0, nll_loss=1.066, ntokens=1177.9, nsentences=32, sample_size=1177.9, sample_size_v1=0, sample_size_v2=0, ppl=2.09, wps=299, ups=0.25, wpb=1177.9, bsz=32, num_updates=36460, lr=3.17343e-06, gnorm=14.628, clip=100, loss_scale=32, train_wall=39, gb_free=7.6, wall=140698
2023-05-22 09:03:00 - progress_bar.py[line:272] - INFO: epoch 022:    164 / 1732 loss=2.263, loss_v1=0, loss_v2=0, nll_loss=1.048, ntokens=1064.5, nsentences=32, sample_size=1064.5, sample_size_v1=0, sample_size_v2=0, ppl=2.07, wps=274.4, ups=0.26, wpb=1064.5, bsz=32, num_updates=36470, lr=3.17139e-06, gnorm=15.884, clip=100, loss_scale=32, train_wall=39, gb_free=7.2, wall=140737
2023-05-22 09:03:38 - progress_bar.py[line:272] - INFO: epoch 022:    174 / 1732 loss=2.298, loss_v1=0, loss_v2=0, nll_loss=1.088, ntokens=918.2, nsentences=32, sample_size=918.2, sample_size_v1=0, sample_size_v2=0, ppl=2.13, wps=239.4, ups=0.26, wpb=918.2, bsz=32, num_updates=36480, lr=3.16934e-06, gnorm=17.684, clip=100, loss_scale=32, train_wall=38, gb_free=8.5, wall=140775
2023-05-22 09:04:17 - progress_bar.py[line:272] - INFO: epoch 022:    184 / 1732 loss=2.244, loss_v1=0, loss_v2=0, nll_loss=1.026, ntokens=1196.7, nsentences=32, sample_size=1196.7, sample_size_v1=0, sample_size_v2=0, ppl=2.04, wps=305.2, ups=0.26, wpb=1196.7, bsz=32, num_updates=36490, lr=3.16729e-06, gnorm=14.418, clip=100, loss_scale=32, train_wall=39, gb_free=8.3, wall=140814
2023-05-22 09:04:56 - progress_bar.py[line:272] - INFO: epoch 022:    194 / 1732 loss=2.27, loss_v1=0, loss_v2=0, nll_loss=1.055, ntokens=1132.8, nsentences=32, sample_size=1132.8, sample_size_v1=0, sample_size_v2=0, ppl=2.08, wps=288.1, ups=0.25, wpb=1132.8, bsz=32, num_updates=36500, lr=3.16524e-06, gnorm=15.792, clip=100, loss_scale=32, train_wall=39, gb_free=7.5, wall=140854
2023-05-22 09:05:35 - progress_bar.py[line:272] - INFO: epoch 022:    204 / 1732 loss=2.363, loss_v1=0, loss_v2=0, nll_loss=1.159, ntokens=1052.4, nsentences=32, sample_size=1052.4, sample_size_v1=0, sample_size_v2=0, ppl=2.23, wps=274.5, ups=0.26, wpb=1052.4, bsz=32, num_updates=36510, lr=3.1632e-06, gnorm=18.043, clip=100, loss_scale=32, train_wall=38, gb_free=8.2, wall=140892
2023-05-22 09:06:13 - progress_bar.py[line:272] - INFO: epoch 022:    214 / 1732 loss=2.384, loss_v1=0, loss_v2=0, nll_loss=1.184, ntokens=1074.9, nsentences=32, sample_size=1074.9, sample_size_v1=0, sample_size_v2=0, ppl=2.27, wps=281.3, ups=0.26, wpb=1074.9, bsz=32, num_updates=36520, lr=3.16115e-06, gnorm=16.781, clip=100, loss_scale=32, train_wall=38, gb_free=8.5, wall=140930
2023-05-22 09:06:51 - progress_bar.py[line:272] - INFO: epoch 022:    224 / 1732 loss=2.386, loss_v1=0, loss_v2=0, nll_loss=1.187, ntokens=1100.1, nsentences=32, sample_size=1100.1, sample_size_v1=0, sample_size_v2=0, ppl=2.28, wps=288.3, ups=0.26, wpb=1100.1, bsz=32, num_updates=36530, lr=3.1591e-06, gnorm=17.671, clip=100, loss_scale=32, train_wall=38, gb_free=8.4, wall=140968
2023-05-22 09:07:29 - progress_bar.py[line:272] - INFO: epoch 022:    234 / 1732 loss=2.426, loss_v1=0, loss_v2=0, nll_loss=1.229, ntokens=1090.7, nsentences=32, sample_size=1090.7, sample_size_v1=0, sample_size_v2=0, ppl=2.34, wps=287.2, ups=0.26, wpb=1090.7, bsz=32, num_updates=36540, lr=3.15705e-06, gnorm=17.472, clip=100, loss_scale=32, train_wall=38, gb_free=8.4, wall=141006
2023-05-22 09:08:08 - progress_bar.py[line:272] - INFO: epoch 022:    244 / 1732 loss=2.414, loss_v1=0, loss_v2=0, nll_loss=1.216, ntokens=1157.9, nsentences=32, sample_size=1157.9, sample_size_v1=0, sample_size_v2=0, ppl=2.32, wps=301.5, ups=0.26, wpb=1157.9, bsz=32, num_updates=36550, lr=3.15501e-06, gnorm=16.029, clip=100, loss_scale=32, train_wall=38, gb_free=7.8, wall=141045
2023-05-22 09:08:46 - progress_bar.py[line:272] - INFO: epoch 022:    254 / 1732 loss=2.406, loss_v1=0, loss_v2=0, nll_loss=1.207, ntokens=1151.4, nsentences=32, sample_size=1151.4, sample_size_v1=0, sample_size_v2=0, ppl=2.31, wps=300.7, ups=0.26, wpb=1151.4, bsz=32, num_updates=36560, lr=3.15296e-06, gnorm=17.298, clip=100, loss_scale=32, train_wall=38, gb_free=8.4, wall=141083
2023-05-22 09:09:24 - progress_bar.py[line:272] - INFO: epoch 022:    264 / 1732 loss=2.411, loss_v1=0, loss_v2=0, nll_loss=1.213, ntokens=1137.5, nsentences=32, sample_size=1137.5, sample_size_v1=0, sample_size_v2=0, ppl=2.32, wps=298.2, ups=0.26, wpb=1137.5, bsz=32, num_updates=36570, lr=3.15091e-06, gnorm=17.434, clip=100, loss_scale=32, train_wall=38, gb_free=7.8, wall=141121
2023-05-22 09:10:02 - progress_bar.py[line:272] - INFO: epoch 022:    274 / 1732 loss=2.396, loss_v1=0, loss_v2=0, nll_loss=1.196, ntokens=1136.4, nsentences=32, sample_size=1136.4, sample_size_v1=0, sample_size_v2=0, ppl=2.29, wps=297.2, ups=0.26, wpb=1136.4, bsz=32, num_updates=36580, lr=3.14886e-06, gnorm=17.163, clip=100, loss_scale=32, train_wall=38, gb_free=6.3, wall=141159
2023-05-22 09:10:41 - progress_bar.py[line:272] - INFO: epoch 022:    284 / 1732 loss=2.419, loss_v1=0, loss_v2=0, nll_loss=1.222, ntokens=1138.6, nsentences=32, sample_size=1138.6, sample_size_v1=0, sample_size_v2=0, ppl=2.33, wps=297.1, ups=0.26, wpb=1138.6, bsz=32, num_updates=36590, lr=3.14682e-06, gnorm=18.215, clip=100, loss_scale=32, train_wall=38, gb_free=8.4, wall=141198
2023-05-22 09:11:19 - progress_bar.py[line:272] - INFO: epoch 022:    294 / 1732 loss=2.385, loss_v1=0, loss_v2=0, nll_loss=1.183, ntokens=1144.7, nsentences=32, sample_size=1144.7, sample_size_v1=0, sample_size_v2=0, ppl=2.27, wps=299.6, ups=0.26, wpb=1144.7, bsz=32, num_updates=36600, lr=3.14477e-06, gnorm=16.96, clip=100, loss_scale=32, train_wall=38, gb_free=8.8, wall=141236
2023-05-22 09:11:57 - progress_bar.py[line:272] - INFO: epoch 022:    304 / 1732 loss=2.389, loss_v1=0, loss_v2=0, nll_loss=1.188, ntokens=1100.1, nsentences=32, sample_size=1100.1, sample_size_v1=0, sample_size_v2=0, ppl=2.28, wps=288.4, ups=0.26, wpb=1100.1, bsz=32, num_updates=36610, lr=3.14272e-06, gnorm=18.125, clip=100, loss_scale=32, train_wall=38, gb_free=8.6, wall=141274
2023-05-22 09:12:35 - progress_bar.py[line:272] - INFO: epoch 022:    314 / 1732 loss=2.4, loss_v1=0, loss_v2=0, nll_loss=1.201, ntokens=1016.6, nsentences=32, sample_size=1016.6, sample_size_v1=0, sample_size_v2=0, ppl=2.3, wps=267.6, ups=0.26, wpb=1016.6, bsz=32, num_updates=36620, lr=3.14068e-06, gnorm=18.911, clip=100, loss_scale=32, train_wall=38, gb_free=9.3, wall=141312
2023-05-22 09:13:13 - progress_bar.py[line:272] - INFO: epoch 022:    324 / 1732 loss=2.425, loss_v1=0, loss_v2=0, nll_loss=1.228, ntokens=1018.7, nsentences=32, sample_size=1018.7, sample_size_v1=0, sample_size_v2=0, ppl=2.34, wps=268.7, ups=0.26, wpb=1018.7, bsz=32, num_updates=36630, lr=3.13863e-06, gnorm=18.248, clip=100, loss_scale=32, train_wall=38, gb_free=8.5, wall=141350
2023-05-22 09:13:51 - progress_bar.py[line:272] - INFO: epoch 022:    334 / 1732 loss=2.421, loss_v1=0, loss_v2=0, nll_loss=1.224, ntokens=1018.9, nsentences=32, sample_size=1018.9, sample_size_v1=0, sample_size_v2=0, ppl=2.34, wps=269.1, ups=0.26, wpb=1018.9, bsz=32, num_updates=36640, lr=3.13658e-06, gnorm=17.635, clip=100, loss_scale=32, train_wall=38, gb_free=8.8, wall=141388
2023-05-22 09:14:29 - progress_bar.py[line:272] - INFO: epoch 022:    344 / 1732 loss=2.383, loss_v1=0, loss_v2=0, nll_loss=1.182, ntokens=921, nsentences=32, sample_size=921, sample_size_v1=0, sample_size_v2=0, ppl=2.27, wps=243.2, ups=0.26, wpb=921, bsz=32, num_updates=36650, lr=3.13453e-06, gnorm=18.157, clip=100, loss_scale=32, train_wall=38, gb_free=8.7, wall=141426
2023-05-22 09:15:06 - progress_bar.py[line:272] - INFO: epoch 022:    354 / 1732 loss=2.41, loss_v1=0, loss_v2=0, nll_loss=1.211, ntokens=961.9, nsentences=32, sample_size=961.9, sample_size_v1=0, sample_size_v2=0, ppl=2.32, wps=254.7, ups=0.26, wpb=961.9, bsz=32, num_updates=36660, lr=3.13249e-06, gnorm=20.591, clip=100, loss_scale=32, train_wall=38, gb_free=8.5, wall=141464
2023-05-22 09:15:44 - progress_bar.py[line:272] - INFO: epoch 022:    364 / 1732 loss=2.45, loss_v1=0, loss_v2=0, nll_loss=1.257, ntokens=927.9, nsentences=32, sample_size=927.9, sample_size_v1=0, sample_size_v2=0, ppl=2.39, wps=246.7, ups=0.27, wpb=927.9, bsz=32, num_updates=36670, lr=3.13044e-06, gnorm=20.065, clip=100, loss_scale=32, train_wall=38, gb_free=9, wall=141501
2023-05-22 09:16:22 - progress_bar.py[line:272] - INFO: epoch 022:    374 / 1732 loss=2.441, loss_v1=0, loss_v2=0, nll_loss=1.246, ntokens=1000.4, nsentences=32, sample_size=1000.4, sample_size_v1=0, sample_size_v2=0, ppl=2.37, wps=263.3, ups=0.26, wpb=1000.4, bsz=32, num_updates=36680, lr=3.12839e-06, gnorm=20.312, clip=100, loss_scale=32, train_wall=38, gb_free=8.7, wall=141539
2023-05-22 09:17:00 - progress_bar.py[line:272] - INFO: epoch 022:    384 / 1732 loss=2.417, loss_v1=0, loss_v2=0, nll_loss=1.22, ntokens=1084.8, nsentences=32, sample_size=1084.8, sample_size_v1=0, sample_size_v2=0, ppl=2.33, wps=286.4, ups=0.26, wpb=1084.8, bsz=32, num_updates=36690, lr=3.12634e-06, gnorm=17.883, clip=100, loss_scale=32, train_wall=38, gb_free=8.1, wall=141577
2023-05-22 09:17:38 - progress_bar.py[line:272] - INFO: epoch 022:    394 / 1732 loss=2.422, loss_v1=0, loss_v2=0, nll_loss=1.225, ntokens=950.6, nsentences=32, sample_size=950.6, sample_size_v1=0, sample_size_v2=0, ppl=2.34, wps=252.2, ups=0.27, wpb=950.6, bsz=32, num_updates=36700, lr=3.1243e-06, gnorm=19.309, clip=100, loss_scale=32, train_wall=38, gb_free=8.9, wall=141615
2023-05-22 09:18:16 - progress_bar.py[line:272] - INFO: epoch 022:    404 / 1732 loss=2.376, loss_v1=0, loss_v2=0, nll_loss=1.173, ntokens=1060.5, nsentences=32, sample_size=1060.5, sample_size_v1=0, sample_size_v2=0, ppl=2.25, wps=278.1, ups=0.26, wpb=1060.5, bsz=32, num_updates=36710, lr=3.12225e-06, gnorm=18.159, clip=100, loss_scale=32, train_wall=38, gb_free=8.1, wall=141653
2023-05-22 09:18:54 - progress_bar.py[line:272] - INFO: epoch 022:    414 / 1732 loss=2.387, loss_v1=0, loss_v2=0, nll_loss=1.185, ntokens=1066.1, nsentences=32, sample_size=1066.1, sample_size_v1=0, sample_size_v2=0, ppl=2.27, wps=280.4, ups=0.26, wpb=1066.1, bsz=32, num_updates=36720, lr=3.1202e-06, gnorm=17.204, clip=100, loss_scale=32, train_wall=38, gb_free=6.5, wall=141691
2023-05-22 09:19:32 - progress_bar.py[line:272] - INFO: epoch 022:    424 / 1732 loss=2.378, loss_v1=0, loss_v2=0, nll_loss=1.176, ntokens=992.6, nsentences=32, sample_size=992.6, sample_size_v1=0, sample_size_v2=0, ppl=2.26, wps=262, ups=0.26, wpb=992.6, bsz=32, num_updates=36730, lr=3.11815e-06, gnorm=19.12, clip=100, loss_scale=32, train_wall=38, gb_free=8.6, wall=141729
2023-05-22 09:20:09 - progress_bar.py[line:272] - INFO: epoch 022:    434 / 1732 loss=2.401, loss_v1=0, loss_v2=0, nll_loss=1.202, ntokens=1018.1, nsentences=32, sample_size=1018.1, sample_size_v1=0, sample_size_v2=0, ppl=2.3, wps=269.2, ups=0.26, wpb=1018.1, bsz=32, num_updates=36740, lr=3.11611e-06, gnorm=19.141, clip=100, loss_scale=32, train_wall=38, gb_free=9, wall=141767
2023-05-22 09:20:47 - progress_bar.py[line:272] - INFO: epoch 022:    444 / 1732 loss=2.429, loss_v1=0, loss_v2=0, nll_loss=1.234, ntokens=952.1, nsentences=32, sample_size=952.1, sample_size_v1=0, sample_size_v2=0, ppl=2.35, wps=252.2, ups=0.26, wpb=952.1, bsz=32, num_updates=36750, lr=3.11406e-06, gnorm=18.699, clip=100, loss_scale=32, train_wall=38, gb_free=9.1, wall=141804
2023-05-22 09:21:25 - progress_bar.py[line:272] - INFO: epoch 022:    454 / 1732 loss=2.424, loss_v1=0, loss_v2=0, nll_loss=1.227, ntokens=919.5, nsentences=32, sample_size=919.5, sample_size_v1=0, sample_size_v2=0, ppl=2.34, wps=243.3, ups=0.26, wpb=919.5, bsz=32, num_updates=36760, lr=3.11201e-06, gnorm=19.872, clip=100, loss_scale=32, train_wall=38, gb_free=8.6, wall=141842
2023-05-22 09:22:03 - progress_bar.py[line:272] - INFO: epoch 022:    464 / 1732 loss=2.434, loss_v1=0, loss_v2=0, nll_loss=1.238, ntokens=1076.9, nsentences=32, sample_size=1076.9, sample_size_v1=0, sample_size_v2=0, ppl=2.36, wps=283.4, ups=0.26, wpb=1076.9, bsz=32, num_updates=36770, lr=3.10996e-06, gnorm=18.125, clip=100, loss_scale=32, train_wall=38, gb_free=8.9, wall=141880
2023-05-22 09:22:41 - progress_bar.py[line:272] - INFO: epoch 022:    474 / 1732 loss=2.427, loss_v1=0, loss_v2=0, nll_loss=1.23, ntokens=1067.6, nsentences=32, sample_size=1067.6, sample_size_v1=0, sample_size_v2=0, ppl=2.35, wps=279.6, ups=0.26, wpb=1067.6, bsz=32, num_updates=36780, lr=3.10792e-06, gnorm=18.405, clip=100, loss_scale=32, train_wall=38, gb_free=9.1, wall=141918
2023-05-22 09:23:19 - progress_bar.py[line:272] - INFO: epoch 022:    484 / 1732 loss=2.411, loss_v1=0, loss_v2=0, nll_loss=1.211, ntokens=966.8, nsentences=32, sample_size=966.8, sample_size_v1=0, sample_size_v2=0, ppl=2.31, wps=256, ups=0.26, wpb=966.8, bsz=32, num_updates=36790, lr=3.10587e-06, gnorm=18.496, clip=100, loss_scale=32, train_wall=38, gb_free=8.7, wall=141956
2023-05-22 09:23:57 - progress_bar.py[line:272] - INFO: epoch 022:    494 / 1732 loss=2.408, loss_v1=0, loss_v2=0, nll_loss=1.209, ntokens=937.9, nsentences=32, sample_size=937.9, sample_size_v1=0, sample_size_v2=0, ppl=2.31, wps=246.7, ups=0.26, wpb=937.9, bsz=32, num_updates=36800, lr=3.10382e-06, gnorm=20.311, clip=100, loss_scale=32, train_wall=38, gb_free=8.5, wall=141994
2023-05-22 09:24:35 - progress_bar.py[line:272] - INFO: epoch 022:    504 / 1732 loss=2.419, loss_v1=0, loss_v2=0, nll_loss=1.221, ntokens=981, nsentences=32, sample_size=981, sample_size_v1=0, sample_size_v2=0, ppl=2.33, wps=261, ups=0.27, wpb=981, bsz=32, num_updates=36810, lr=3.10178e-06, gnorm=19.364, clip=100, loss_scale=32, train_wall=38, gb_free=8.6, wall=142032
2023-05-22 09:25:13 - progress_bar.py[line:272] - INFO: epoch 022:    514 / 1732 loss=2.428, loss_v1=0, loss_v2=0, nll_loss=1.231, ntokens=1052.2, nsentences=32, sample_size=1052.2, sample_size_v1=0, sample_size_v2=0, ppl=2.35, wps=277.7, ups=0.26, wpb=1052.2, bsz=32, num_updates=36820, lr=3.09973e-06, gnorm=16.816, clip=100, loss_scale=32, train_wall=38, gb_free=9, wall=142070
2023-05-22 09:25:50 - progress_bar.py[line:272] - INFO: epoch 022:    524 / 1732 loss=2.398, loss_v1=0, loss_v2=0, nll_loss=1.197, ntokens=980.8, nsentences=32, sample_size=980.8, sample_size_v1=0, sample_size_v2=0, ppl=2.29, wps=260, ups=0.27, wpb=980.8, bsz=32, num_updates=36830, lr=3.09768e-06, gnorm=19.453, clip=100, loss_scale=32, train_wall=38, gb_free=8.8, wall=142107
2023-05-22 09:26:28 - progress_bar.py[line:272] - INFO: epoch 022:    534 / 1732 loss=2.408, loss_v1=0, loss_v2=0, nll_loss=1.21, ntokens=944.9, nsentences=32, sample_size=944.9, sample_size_v1=0, sample_size_v2=0, ppl=2.31, wps=251, ups=0.27, wpb=944.9, bsz=32, num_updates=36840, lr=3.09563e-06, gnorm=19.577, clip=100, loss_scale=32, train_wall=38, gb_free=8.3, wall=142145
2023-05-22 09:27:06 - progress_bar.py[line:272] - INFO: epoch 022:    544 / 1732 loss=2.423, loss_v1=0, loss_v2=0, nll_loss=1.226, ntokens=998.9, nsentences=32, sample_size=998.9, sample_size_v1=0, sample_size_v2=0, ppl=2.34, wps=264.4, ups=0.26, wpb=998.9, bsz=32, num_updates=36850, lr=3.09359e-06, gnorm=20.329, clip=100, loss_scale=32, train_wall=38, gb_free=8.6, wall=142183
2023-05-22 09:27:43 - progress_bar.py[line:272] - INFO: epoch 022:    554 / 1732 loss=2.452, loss_v1=0, loss_v2=0, nll_loss=1.259, ntokens=1026.7, nsentences=32, sample_size=1026.7, sample_size_v1=0, sample_size_v2=0, ppl=2.39, wps=271.7, ups=0.26, wpb=1026.7, bsz=32, num_updates=36860, lr=3.09154e-06, gnorm=17.739, clip=100, loss_scale=32, train_wall=38, gb_free=8.5, wall=142221
2023-05-22 09:28:21 - progress_bar.py[line:272] - INFO: epoch 022:    564 / 1732 loss=2.438, loss_v1=0, loss_v2=0, nll_loss=1.243, ntokens=1028.3, nsentences=32, sample_size=1028.3, sample_size_v1=0, sample_size_v2=0, ppl=2.37, wps=270.6, ups=0.26, wpb=1028.3, bsz=32, num_updates=36870, lr=3.08949e-06, gnorm=18.112, clip=100, loss_scale=32, train_wall=38, gb_free=8.2, wall=142259
2023-05-22 09:28:29 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2023-05-22 09:29:03 - progress_bar.py[line:272] - INFO: epoch 022:    575 / 1732 loss=2.426, loss_v1=0, loss_v2=0, nll_loss=1.23, ntokens=1008, nsentences=32, sample_size=1008, sample_size_v1=0, sample_size_v2=0, ppl=2.35, wps=241.5, ups=0.24, wpb=1008, bsz=32, num_updates=36880, lr=3.08744e-06, gnorm=18.604, clip=100, loss_scale=32, train_wall=42, gb_free=8.8, wall=142300
2023-05-22 09:29:41 - progress_bar.py[line:272] - INFO: epoch 022:    585 / 1732 loss=2.435, loss_v1=0, loss_v2=0, nll_loss=1.239, ntokens=980.6, nsentences=32, sample_size=980.6, sample_size_v1=0, sample_size_v2=0, ppl=2.36, wps=257.6, ups=0.26, wpb=980.6, bsz=32, num_updates=36890, lr=3.0854e-06, gnorm=20.571, clip=100, loss_scale=32, train_wall=38, gb_free=8.8, wall=142338
2023-05-22 09:30:19 - progress_bar.py[line:272] - INFO: epoch 022:    595 / 1732 loss=2.388, loss_v1=0, loss_v2=0, nll_loss=1.186, ntokens=961.9, nsentences=32, sample_size=961.9, sample_size_v1=0, sample_size_v2=0, ppl=2.28, wps=253.1, ups=0.26, wpb=961.9, bsz=32, num_updates=36900, lr=3.08335e-06, gnorm=19.683, clip=100, loss_scale=32, train_wall=38, gb_free=8.8, wall=142376
2023-05-22 09:30:57 - progress_bar.py[line:272] - INFO: epoch 022:    605 / 1732 loss=2.394, loss_v1=0, loss_v2=0, nll_loss=1.194, ntokens=879.8, nsentences=32, sample_size=879.8, sample_size_v1=0, sample_size_v2=0, ppl=2.29, wps=234.7, ups=0.27, wpb=879.8, bsz=32, num_updates=36910, lr=3.0813e-06, gnorm=19.243, clip=100, loss_scale=32, train_wall=37, gb_free=9.3, wall=142414
2023-05-22 09:31:35 - progress_bar.py[line:272] - INFO: epoch 022:    615 / 1732 loss=2.431, loss_v1=0, loss_v2=0, nll_loss=1.235, ntokens=903.1, nsentences=32, sample_size=903.1, sample_size_v1=0, sample_size_v2=0, ppl=2.35, wps=239, ups=0.26, wpb=903.1, bsz=32, num_updates=36920, lr=3.07925e-06, gnorm=19.815, clip=100, loss_scale=32, train_wall=38, gb_free=8.4, wall=142452
2023-05-22 09:32:12 - progress_bar.py[line:272] - INFO: epoch 022:    625 / 1732 loss=2.426, loss_v1=0, loss_v2=0, nll_loss=1.23, ntokens=898.6, nsentences=32, sample_size=898.6, sample_size_v1=0, sample_size_v2=0, ppl=2.35, wps=239.6, ups=0.27, wpb=898.6, bsz=32, num_updates=36930, lr=3.07721e-06, gnorm=22.228, clip=100, loss_scale=32, train_wall=37, gb_free=8.9, wall=142489
2023-05-22 09:32:50 - progress_bar.py[line:272] - INFO: epoch 022:    635 / 1732 loss=2.428, loss_v1=0, loss_v2=0, nll_loss=1.234, ntokens=897.1, nsentences=32, sample_size=897.1, sample_size_v1=0, sample_size_v2=0, ppl=2.35, wps=239.4, ups=0.27, wpb=897.1, bsz=32, num_updates=36940, lr=3.07516e-06, gnorm=22.233, clip=100, loss_scale=32, train_wall=37, gb_free=9, wall=142527
2023-05-22 09:33:27 - progress_bar.py[line:272] - INFO: epoch 022:    645 / 1732 loss=2.424, loss_v1=0, loss_v2=0, nll_loss=1.228, ntokens=1010.4, nsentences=32, sample_size=1010.4, sample_size_v1=0, sample_size_v2=0, ppl=2.34, wps=266.4, ups=0.26, wpb=1010.4, bsz=32, num_updates=36950, lr=3.07311e-06, gnorm=20.06, clip=100, loss_scale=32, train_wall=38, gb_free=8.9, wall=142565
2023-05-22 09:34:05 - progress_bar.py[line:272] - INFO: epoch 022:    655 / 1732 loss=2.43, loss_v1=0, loss_v2=0, nll_loss=1.235, ntokens=879.8, nsentences=32, sample_size=879.8, sample_size_v1=0, sample_size_v2=0, ppl=2.35, wps=235.6, ups=0.27, wpb=879.8, bsz=32, num_updates=36960, lr=3.07106e-06, gnorm=19.957, clip=100, loss_scale=32, train_wall=37, gb_free=8.7, wall=142602
2023-05-22 09:34:42 - progress_bar.py[line:272] - INFO: epoch 022:    665 / 1732 loss=2.429, loss_v1=0, loss_v2=0, nll_loss=1.234, ntokens=893.8, nsentences=32, sample_size=893.8, sample_size_v1=0, sample_size_v2=0, ppl=2.35, wps=239.1, ups=0.27, wpb=893.8, bsz=32, num_updates=36970, lr=3.06902e-06, gnorm=21.31, clip=100, loss_scale=32, train_wall=37, gb_free=9.3, wall=142639
2023-05-22 09:35:20 - progress_bar.py[line:272] - INFO: epoch 022:    675 / 1732 loss=2.43, loss_v1=0, loss_v2=0, nll_loss=1.235, ntokens=961.9, nsentences=32, sample_size=961.9, sample_size_v1=0, sample_size_v2=0, ppl=2.35, wps=254.6, ups=0.26, wpb=961.9, bsz=32, num_updates=36980, lr=3.06697e-06, gnorm=19.866, clip=100, loss_scale=32, train_wall=38, gb_free=8, wall=142677
2023-05-22 09:35:58 - progress_bar.py[line:272] - INFO: epoch 022:    685 / 1732 loss=2.423, loss_v1=0, loss_v2=0, nll_loss=1.226, ntokens=961.5, nsentences=32, sample_size=961.5, sample_size_v1=0, sample_size_v2=0, ppl=2.34, wps=255, ups=0.27, wpb=961.5, bsz=32, num_updates=36990, lr=3.06492e-06, gnorm=19.908, clip=100, loss_scale=32, train_wall=38, gb_free=8.7, wall=142715
2023-05-22 09:36:36 - progress_bar.py[line:272] - INFO: epoch 022:    695 / 1732 loss=2.43, loss_v1=0, loss_v2=0, nll_loss=1.234, ntokens=1007.2, nsentences=32, sample_size=1007.2, sample_size_v1=0, sample_size_v2=0, ppl=2.35, wps=264.8, ups=0.26, wpb=1007.2, bsz=32, num_updates=37000, lr=3.06287e-06, gnorm=18.234, clip=100, loss_scale=32, train_wall=38, gb_free=7.5, wall=142753
2023-05-22 09:37:13 - progress_bar.py[line:272] - INFO: epoch 022:    705 / 1732 loss=2.393, loss_v1=0, loss_v2=0, nll_loss=1.191, ntokens=925.6, nsentences=32, sample_size=925.6, sample_size_v1=0, sample_size_v2=0, ppl=2.28, wps=245.7, ups=0.27, wpb=925.6, bsz=32, num_updates=37010, lr=3.06083e-06, gnorm=20.616, clip=100, loss_scale=32, train_wall=38, gb_free=9, wall=142791
2023-05-22 09:37:51 - progress_bar.py[line:272] - INFO: epoch 022:    715 / 1732 loss=2.437, loss_v1=0, loss_v2=0, nll_loss=1.241, ntokens=890.5, nsentences=32, sample_size=890.5, sample_size_v1=0, sample_size_v2=0, ppl=2.36, wps=236.6, ups=0.27, wpb=890.5, bsz=32, num_updates=37020, lr=3.05878e-06, gnorm=20.33, clip=100, loss_scale=32, train_wall=38, gb_free=8.9, wall=142828
2023-05-22 09:38:29 - progress_bar.py[line:272] - INFO: epoch 022:    725 / 1732 loss=2.378, loss_v1=0, loss_v2=0, nll_loss=1.175, ntokens=904.8, nsentences=32, sample_size=904.8, sample_size_v1=0, sample_size_v2=0, ppl=2.26, wps=241.3, ups=0.27, wpb=904.8, bsz=32, num_updates=37030, lr=3.05673e-06, gnorm=20.141, clip=100, loss_scale=32, train_wall=37, gb_free=8.7, wall=142866
2023-05-22 09:39:06 - progress_bar.py[line:272] - INFO: epoch 022:    735 / 1732 loss=2.408, loss_v1=0, loss_v2=0, nll_loss=1.209, ntokens=965.8, nsentences=32, sample_size=965.8, sample_size_v1=0, sample_size_v2=0, ppl=2.31, wps=256.3, ups=0.27, wpb=965.8, bsz=32, num_updates=37040, lr=3.05469e-06, gnorm=17.995, clip=100, loss_scale=32, train_wall=38, gb_free=8.9, wall=142903
2023-05-22 09:39:44 - progress_bar.py[line:272] - INFO: epoch 022:    745 / 1732 loss=2.389, loss_v1=0, loss_v2=0, nll_loss=1.188, ntokens=978.3, nsentences=32, sample_size=978.3, sample_size_v1=0, sample_size_v2=0, ppl=2.28, wps=259.5, ups=0.27, wpb=978.3, bsz=32, num_updates=37050, lr=3.05264e-06, gnorm=19.07, clip=100, loss_scale=32, train_wall=38, gb_free=8.3, wall=142941
2023-05-22 09:40:22 - progress_bar.py[line:272] - INFO: epoch 022:    755 / 1732 loss=2.409, loss_v1=0, loss_v2=0, nll_loss=1.211, ntokens=975.4, nsentences=32, sample_size=975.4, sample_size_v1=0, sample_size_v2=0, ppl=2.31, wps=258.1, ups=0.26, wpb=975.4, bsz=32, num_updates=37060, lr=3.05059e-06, gnorm=18.998, clip=100, loss_scale=32, train_wall=38, gb_free=9, wall=142979
2023-05-22 09:40:59 - progress_bar.py[line:272] - INFO: epoch 022:    765 / 1732 loss=2.398, loss_v1=0, loss_v2=0, nll_loss=1.198, ntokens=948.8, nsentences=32, sample_size=948.8, sample_size_v1=0, sample_size_v2=0, ppl=2.3, wps=252.5, ups=0.27, wpb=948.8, bsz=32, num_updates=37070, lr=3.04854e-06, gnorm=19.185, clip=100, loss_scale=32, train_wall=38, gb_free=7.6, wall=143017
2023-05-22 09:41:37 - progress_bar.py[line:272] - INFO: epoch 022:    775 / 1732 loss=2.408, loss_v1=0, loss_v2=0, nll_loss=1.21, ntokens=1002.4, nsentences=32, sample_size=1002.4, sample_size_v1=0, sample_size_v2=0, ppl=2.31, wps=266.1, ups=0.27, wpb=1002.4, bsz=32, num_updates=37080, lr=3.0465e-06, gnorm=20.259, clip=100, loss_scale=32, train_wall=38, gb_free=8.7, wall=143054
2023-05-22 09:42:15 - progress_bar.py[line:272] - INFO: epoch 022:    785 / 1732 loss=2.41, loss_v1=0, loss_v2=0, nll_loss=1.212, ntokens=1003.9, nsentences=32, sample_size=1003.9, sample_size_v1=0, sample_size_v2=0, ppl=2.32, wps=264, ups=0.26, wpb=1003.9, bsz=32, num_updates=37090, lr=3.04445e-06, gnorm=18.283, clip=100, loss_scale=32, train_wall=38, gb_free=8.4, wall=143092
2023-05-22 09:42:53 - progress_bar.py[line:272] - INFO: epoch 022:    795 / 1732 loss=2.41, loss_v1=0, loss_v2=0, nll_loss=1.213, ntokens=1051.8, nsentences=32, sample_size=1051.8, sample_size_v1=0, sample_size_v2=0, ppl=2.32, wps=278.2, ups=0.26, wpb=1051.8, bsz=32, num_updates=37100, lr=3.0424e-06, gnorm=17.705, clip=100, loss_scale=32, train_wall=38, gb_free=8.3, wall=143130
2023-05-22 09:43:31 - progress_bar.py[line:272] - INFO: epoch 022:    805 / 1732 loss=2.414, loss_v1=0, loss_v2=0, nll_loss=1.216, ntokens=913, nsentences=32, sample_size=913, sample_size_v1=0, sample_size_v2=0, ppl=2.32, wps=242.4, ups=0.27, wpb=913, bsz=32, num_updates=37110, lr=3.04035e-06, gnorm=19.505, clip=100, loss_scale=32, train_wall=38, gb_free=8.3, wall=143168
2023-05-22 09:44:08 - progress_bar.py[line:272] - INFO: epoch 022:    815 / 1732 loss=2.416, loss_v1=0, loss_v2=0, nll_loss=1.218, ntokens=936.3, nsentences=32, sample_size=936.3, sample_size_v1=0, sample_size_v2=0, ppl=2.33, wps=247.8, ups=0.26, wpb=936.3, bsz=32, num_updates=37120, lr=3.03831e-06, gnorm=20.271, clip=100, loss_scale=32, train_wall=38, gb_free=8.8, wall=143206
2023-05-22 09:44:46 - progress_bar.py[line:272] - INFO: epoch 022:    825 / 1732 loss=2.413, loss_v1=0, loss_v2=0, nll_loss=1.216, ntokens=931.3, nsentences=32, sample_size=931.3, sample_size_v1=0, sample_size_v2=0, ppl=2.32, wps=246.6, ups=0.26, wpb=931.3, bsz=32, num_updates=37130, lr=3.03626e-06, gnorm=18.436, clip=100, loss_scale=32, train_wall=38, gb_free=9.2, wall=143243
2023-05-22 09:45:24 - progress_bar.py[line:272] - INFO: epoch 022:    835 / 1732 loss=2.411, loss_v1=0, loss_v2=0, nll_loss=1.214, ntokens=897.4, nsentences=32, sample_size=897.4, sample_size_v1=0, sample_size_v2=0, ppl=2.32, wps=239.5, ups=0.27, wpb=897.4, bsz=32, num_updates=37140, lr=3.03421e-06, gnorm=20.048, clip=100, loss_scale=32, train_wall=37, gb_free=9, wall=143281
2023-05-22 09:46:01 - progress_bar.py[line:272] - INFO: epoch 022:    845 / 1732 loss=2.386, loss_v1=0, loss_v2=0, nll_loss=1.185, ntokens=987.4, nsentences=32, sample_size=987.4, sample_size_v1=0, sample_size_v2=0, ppl=2.27, wps=262.4, ups=0.27, wpb=987.4, bsz=32, num_updates=37150, lr=3.03216e-06, gnorm=18.637, clip=100, loss_scale=32, train_wall=38, gb_free=8.4, wall=143318
2023-05-22 09:46:39 - progress_bar.py[line:272] - INFO: epoch 022:    855 / 1732 loss=2.401, loss_v1=0, loss_v2=0, nll_loss=1.201, ntokens=952, nsentences=32, sample_size=952, sample_size_v1=0, sample_size_v2=0, ppl=2.3, wps=252.4, ups=0.27, wpb=952, bsz=32, num_updates=37160, lr=3.03012e-06, gnorm=19.788, clip=100, loss_scale=32, train_wall=38, gb_free=9.2, wall=143356
2023-05-22 09:47:17 - progress_bar.py[line:272] - INFO: epoch 022:    865 / 1732 loss=2.418, loss_v1=0, loss_v2=0, nll_loss=1.22, ntokens=968.1, nsentences=32, sample_size=968.1, sample_size_v1=0, sample_size_v2=0, ppl=2.33, wps=256.1, ups=0.26, wpb=968.1, bsz=32, num_updates=37170, lr=3.02807e-06, gnorm=20.513, clip=100, loss_scale=32, train_wall=38, gb_free=8.7, wall=143394
2023-05-22 09:47:55 - progress_bar.py[line:272] - INFO: epoch 022:    875 / 1732 loss=2.374, loss_v1=0, loss_v2=0, nll_loss=1.171, ntokens=985.7, nsentences=32, sample_size=985.7, sample_size_v1=0, sample_size_v2=0, ppl=2.25, wps=260.8, ups=0.26, wpb=985.7, bsz=32, num_updates=37180, lr=3.02602e-06, gnorm=16.538, clip=100, loss_scale=32, train_wall=38, gb_free=8.6, wall=143432
2023-05-22 09:48:32 - progress_bar.py[line:272] - INFO: epoch 022:    885 / 1732 loss=2.352, loss_v1=0, loss_v2=0, nll_loss=1.147, ntokens=961.4, nsentences=32, sample_size=961.4, sample_size_v1=0, sample_size_v2=0, ppl=2.21, wps=253.6, ups=0.26, wpb=961.4, bsz=32, num_updates=37190, lr=3.02397e-06, gnorm=19.734, clip=100, loss_scale=32, train_wall=38, gb_free=8.7, wall=143470
2023-05-22 09:49:10 - progress_bar.py[line:272] - INFO: epoch 022:    895 / 1732 loss=2.357, loss_v1=0, loss_v2=0, nll_loss=1.153, ntokens=1031.3, nsentences=32, sample_size=1031.3, sample_size_v1=0, sample_size_v2=0, ppl=2.22, wps=271.4, ups=0.26, wpb=1031.3, bsz=32, num_updates=37200, lr=3.02193e-06, gnorm=17.593, clip=100, loss_scale=32, train_wall=38, gb_free=9, wall=143508
2023-05-22 09:49:48 - progress_bar.py[line:272] - INFO: epoch 022:    905 / 1732 loss=2.357, loss_v1=0, loss_v2=0, nll_loss=1.153, ntokens=1040.4, nsentences=32, sample_size=1040.4, sample_size_v1=0, sample_size_v2=0, ppl=2.22, wps=274.8, ups=0.26, wpb=1040.4, bsz=32, num_updates=37210, lr=3.01988e-06, gnorm=17.683, clip=100, loss_scale=32, train_wall=38, gb_free=8.2, wall=143545
2023-05-22 09:50:26 - progress_bar.py[line:272] - INFO: epoch 022:    915 / 1732 loss=2.429, loss_v1=0, loss_v2=0, nll_loss=1.234, ntokens=937.6, nsentences=32, sample_size=937.6, sample_size_v1=0, sample_size_v2=0, ppl=2.35, wps=248.7, ups=0.27, wpb=937.6, bsz=32, num_updates=37220, lr=3.01783e-06, gnorm=20.489, clip=100, loss_scale=32, train_wall=38, gb_free=8.9, wall=143583
2023-05-22 09:51:04 - progress_bar.py[line:272] - INFO: epoch 022:    925 / 1732 loss=2.365, loss_v1=0, loss_v2=0, nll_loss=1.162, ntokens=1005.1, nsentences=32, sample_size=1005.1, sample_size_v1=0, sample_size_v2=0, ppl=2.24, wps=262.6, ups=0.26, wpb=1005.1, bsz=32, num_updates=37230, lr=3.01579e-06, gnorm=17.67, clip=100, loss_scale=32, train_wall=38, gb_free=8.7, wall=143621
2023-05-22 09:51:43 - progress_bar.py[line:272] - INFO: epoch 022:    935 / 1732 loss=2.375, loss_v1=0, loss_v2=0, nll_loss=1.171, ntokens=1058.5, nsentences=32, sample_size=1058.5, sample_size_v1=0, sample_size_v2=0, ppl=2.25, wps=275.1, ups=0.26, wpb=1058.5, bsz=32, num_updates=37240, lr=3.01374e-06, gnorm=18.392, clip=100, loss_scale=32, train_wall=38, gb_free=8.4, wall=143660
2023-05-22 09:52:21 - progress_bar.py[line:272] - INFO: epoch 022:    945 / 1732 loss=2.402, loss_v1=0, loss_v2=0, nll_loss=1.202, ntokens=1055.4, nsentences=32, sample_size=1055.4, sample_size_v1=0, sample_size_v2=0, ppl=2.3, wps=274.4, ups=0.26, wpb=1055.4, bsz=32, num_updates=37250, lr=3.01169e-06, gnorm=16.804, clip=100, loss_scale=32, train_wall=38, gb_free=8.4, wall=143698
2023-05-22 09:53:00 - progress_bar.py[line:272] - INFO: epoch 022:    955 / 1732 loss=2.385, loss_v1=0, loss_v2=0, nll_loss=1.183, ntokens=1040.2, nsentences=32, sample_size=1040.2, sample_size_v1=0, sample_size_v2=0, ppl=2.27, wps=271.5, ups=0.26, wpb=1040.2, bsz=32, num_updates=37260, lr=3.00964e-06, gnorm=19.6, clip=100, loss_scale=32, train_wall=38, gb_free=8.7, wall=143737
2023-05-22 09:53:38 - progress_bar.py[line:272] - INFO: epoch 022:    965 / 1732 loss=2.393, loss_v1=0, loss_v2=0, nll_loss=1.193, ntokens=1047.7, nsentences=32, sample_size=1047.7, sample_size_v1=0, sample_size_v2=0, ppl=2.29, wps=273.4, ups=0.26, wpb=1047.7, bsz=32, num_updates=37270, lr=3.0076e-06, gnorm=20.045, clip=100, loss_scale=32, train_wall=38, gb_free=8.9, wall=143775
2023-05-22 09:54:16 - progress_bar.py[line:272] - INFO: epoch 022:    975 / 1732 loss=2.392, loss_v1=0, loss_v2=0, nll_loss=1.192, ntokens=1038, nsentences=32, sample_size=1038, sample_size_v1=0, sample_size_v2=0, ppl=2.28, wps=270.7, ups=0.26, wpb=1038, bsz=32, num_updates=37280, lr=3.00555e-06, gnorm=18.473, clip=100, loss_scale=32, train_wall=38, gb_free=8.8, wall=143813
2023-05-22 09:54:55 - progress_bar.py[line:272] - INFO: epoch 022:    985 / 1732 loss=2.398, loss_v1=0, loss_v2=0, nll_loss=1.199, ntokens=1034.6, nsentences=32, sample_size=1034.6, sample_size_v1=0, sample_size_v2=0, ppl=2.3, wps=269.3, ups=0.26, wpb=1034.6, bsz=32, num_updates=37290, lr=3.0035e-06, gnorm=19.32, clip=100, loss_scale=32, train_wall=38, gb_free=8.7, wall=143852
2023-05-22 09:55:33 - progress_bar.py[line:272] - INFO: epoch 022:    995 / 1732 loss=2.381, loss_v1=0, loss_v2=0, nll_loss=1.179, ntokens=1048.7, nsentences=32, sample_size=1048.7, sample_size_v1=0, sample_size_v2=0, ppl=2.26, wps=273.9, ups=0.26, wpb=1048.7, bsz=32, num_updates=37300, lr=3.00145e-06, gnorm=17.742, clip=100, loss_scale=32, train_wall=38, gb_free=7.7, wall=143890
2023-05-22 09:56:11 - progress_bar.py[line:272] - INFO: epoch 022:   1005 / 1732 loss=2.376, loss_v1=0, loss_v2=0, nll_loss=1.174, ntokens=981.9, nsentences=32, sample_size=981.9, sample_size_v1=0, sample_size_v2=0, ppl=2.26, wps=257.7, ups=0.26, wpb=981.9, bsz=32, num_updates=37310, lr=2.99941e-06, gnorm=17.92, clip=100, loss_scale=32, train_wall=38, gb_free=8.3, wall=143928
2023-05-22 09:56:49 - progress_bar.py[line:272] - INFO: epoch 022:   1015 / 1732 loss=2.382, loss_v1=0, loss_v2=0, nll_loss=1.18, ntokens=996.6, nsentences=32, sample_size=996.6, sample_size_v1=0, sample_size_v2=0, ppl=2.27, wps=262, ups=0.26, wpb=996.6, bsz=32, num_updates=37320, lr=2.99736e-06, gnorm=19.714, clip=100, loss_scale=32, train_wall=38, gb_free=8.8, wall=143966
2023-05-22 09:57:28 - progress_bar.py[line:272] - INFO: epoch 022:   1025 / 1732 loss=2.371, loss_v1=0, loss_v2=0, nll_loss=1.169, ntokens=1087.5, nsentences=32, sample_size=1087.5, sample_size_v1=0, sample_size_v2=0, ppl=2.25, wps=280.7, ups=0.26, wpb=1087.5, bsz=32, num_updates=37330, lr=2.99531e-06, gnorm=17.219, clip=100, loss_scale=32, train_wall=39, gb_free=7.8, wall=144005
2023-05-22 09:58:06 - progress_bar.py[line:272] - INFO: epoch 022:   1035 / 1732 loss=2.374, loss_v1=0, loss_v2=0, nll_loss=1.173, ntokens=1118.6, nsentences=32, sample_size=1118.6, sample_size_v1=0, sample_size_v2=0, ppl=2.25, wps=290.4, ups=0.26, wpb=1118.6, bsz=32, num_updates=37340, lr=2.99326e-06, gnorm=16.675, clip=100, loss_scale=32, train_wall=38, gb_free=8.6, wall=144044
2023-05-22 09:58:45 - progress_bar.py[line:272] - INFO: epoch 022:   1045 / 1732 loss=2.381, loss_v1=0, loss_v2=0, nll_loss=1.181, ntokens=1030.7, nsentences=32, sample_size=1030.7, sample_size_v1=0, sample_size_v2=0, ppl=2.27, wps=268.4, ups=0.26, wpb=1030.7, bsz=32, num_updates=37350, lr=2.99122e-06, gnorm=18.094, clip=100, loss_scale=32, train_wall=38, gb_free=8.8, wall=144082
2023-05-22 09:59:23 - progress_bar.py[line:272] - INFO: epoch 022:   1055 / 1732 loss=2.386, loss_v1=0, loss_v2=0, nll_loss=1.186, ntokens=1077.2, nsentences=32, sample_size=1077.2, sample_size_v1=0, sample_size_v2=0, ppl=2.27, wps=281.4, ups=0.26, wpb=1077.2, bsz=32, num_updates=37360, lr=2.98917e-06, gnorm=19.053, clip=100, loss_scale=32, train_wall=38, gb_free=8.3, wall=144120
2023-05-22 10:00:01 - progress_bar.py[line:272] - INFO: epoch 022:   1065 / 1732 loss=2.388, loss_v1=0, loss_v2=0, nll_loss=1.187, ntokens=1021, nsentences=32, sample_size=1021, sample_size_v1=0, sample_size_v2=0, ppl=2.28, wps=266.8, ups=0.26, wpb=1021, bsz=32, num_updates=37370, lr=2.98712e-06, gnorm=20.51, clip=100, loss_scale=32, train_wall=38, gb_free=8.6, wall=144158
2023-05-22 10:00:40 - progress_bar.py[line:272] - INFO: epoch 022:   1075 / 1732 loss=2.385, loss_v1=0, loss_v2=0, nll_loss=1.184, ntokens=1007.9, nsentences=32, sample_size=1007.9, sample_size_v1=0, sample_size_v2=0, ppl=2.27, wps=259.6, ups=0.26, wpb=1007.9, bsz=32, num_updates=37380, lr=2.98507e-06, gnorm=19.821, clip=100, loss_scale=32, train_wall=39, gb_free=8.1, wall=144197
2023-05-22 10:01:03 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2023-05-22 10:01:22 - progress_bar.py[line:272] - INFO: epoch 022:   1086 / 1732 loss=2.395, loss_v1=0, loss_v2=0, nll_loss=1.196, ntokens=1069.7, nsentences=32, sample_size=1069.7, sample_size_v1=0, sample_size_v2=0, ppl=2.29, wps=254, ups=0.24, wpb=1069.7, bsz=32, num_updates=37390, lr=2.98303e-06, gnorm=18.741, clip=100, loss_scale=32, train_wall=42, gb_free=8.3, wall=144239
2023-05-22 10:02:00 - progress_bar.py[line:272] - INFO: epoch 022:   1096 / 1732 loss=2.391, loss_v1=0, loss_v2=0, nll_loss=1.191, ntokens=1044.2, nsentences=32, sample_size=1044.2, sample_size_v1=0, sample_size_v2=0, ppl=2.28, wps=273.2, ups=0.26, wpb=1044.2, bsz=32, num_updates=37400, lr=2.98098e-06, gnorm=19.416, clip=100, loss_scale=32, train_wall=38, gb_free=8.2, wall=144278
2023-05-22 10:02:39 - progress_bar.py[line:272] - INFO: epoch 022:   1106 / 1732 loss=2.374, loss_v1=0, loss_v2=0, nll_loss=1.171, ntokens=1073, nsentences=32, sample_size=1073, sample_size_v1=0, sample_size_v2=0, ppl=2.25, wps=279.8, ups=0.26, wpb=1073, bsz=32, num_updates=37410, lr=2.97893e-06, gnorm=18.769, clip=100, loss_scale=32, train_wall=38, gb_free=8.3, wall=144316
2023-05-22 10:03:17 - progress_bar.py[line:272] - INFO: epoch 022:   1116 / 1732 loss=2.397, loss_v1=0, loss_v2=0, nll_loss=1.196, ntokens=936.7, nsentences=32, sample_size=936.7, sample_size_v1=0, sample_size_v2=0, ppl=2.29, wps=245.2, ups=0.26, wpb=936.7, bsz=32, num_updates=37420, lr=2.97689e-06, gnorm=19.641, clip=100, loss_scale=32, train_wall=38, gb_free=8.2, wall=144354
2023-05-22 10:03:55 - progress_bar.py[line:272] - INFO: epoch 022:   1126 / 1732 loss=2.383, loss_v1=0, loss_v2=0, nll_loss=1.181, ntokens=1021, nsentences=32, sample_size=1021, sample_size_v1=0, sample_size_v2=0, ppl=2.27, wps=266.5, ups=0.26, wpb=1021, bsz=32, num_updates=37430, lr=2.97484e-06, gnorm=19.999, clip=100, loss_scale=32, train_wall=38, gb_free=8, wall=144393
2023-05-22 10:04:34 - progress_bar.py[line:272] - INFO: epoch 022:   1136 / 1732 loss=2.394, loss_v1=0, loss_v2=0, nll_loss=1.195, ntokens=969.6, nsentences=32, sample_size=969.6, sample_size_v1=0, sample_size_v2=0, ppl=2.29, wps=253.7, ups=0.26, wpb=969.6, bsz=32, num_updates=37440, lr=2.97279e-06, gnorm=18.464, clip=100, loss_scale=32, train_wall=38, gb_free=8.9, wall=144431
2023-05-22 10:05:12 - progress_bar.py[line:272] - INFO: epoch 022:   1146 / 1732 loss=2.383, loss_v1=0, loss_v2=0, nll_loss=1.182, ntokens=1029.8, nsentences=32, sample_size=1029.8, sample_size_v1=0, sample_size_v2=0, ppl=2.27, wps=269.2, ups=0.26, wpb=1029.8, bsz=32, num_updates=37450, lr=2.97074e-06, gnorm=18.306, clip=100, loss_scale=32, train_wall=38, gb_free=8.6, wall=144469
2023-05-22 10:05:50 - progress_bar.py[line:272] - INFO: epoch 022:   1156 / 1732 loss=2.379, loss_v1=0, loss_v2=0, nll_loss=1.178, ntokens=1017, nsentences=32, sample_size=1017, sample_size_v1=0, sample_size_v2=0, ppl=2.26, wps=265.7, ups=0.26, wpb=1017, bsz=32, num_updates=37460, lr=2.9687e-06, gnorm=19.549, clip=100, loss_scale=32, train_wall=38, gb_free=7.7, wall=144507
2023-05-22 10:06:28 - progress_bar.py[line:272] - INFO: epoch 022:   1166 / 1732 loss=2.38, loss_v1=0, loss_v2=0, nll_loss=1.178, ntokens=1020.6, nsentences=32, sample_size=1020.6, sample_size_v1=0, sample_size_v2=0, ppl=2.26, wps=266, ups=0.26, wpb=1020.6, bsz=32, num_updates=37470, lr=2.96665e-06, gnorm=19.191, clip=100, loss_scale=32, train_wall=38, gb_free=8.7, wall=144546
2023-05-22 10:07:07 - progress_bar.py[line:272] - INFO: epoch 022:   1176 / 1732 loss=2.361, loss_v1=0, loss_v2=0, nll_loss=1.158, ntokens=1064.1, nsentences=32, sample_size=1064.1, sample_size_v1=0, sample_size_v2=0, ppl=2.23, wps=277.6, ups=0.26, wpb=1064.1, bsz=32, num_updates=37480, lr=2.9646e-06, gnorm=18.349, clip=100, loss_scale=32, train_wall=38, gb_free=7.9, wall=144584
2023-05-22 10:07:45 - progress_bar.py[line:272] - INFO: epoch 022:   1186 / 1732 loss=2.391, loss_v1=0, loss_v2=0, nll_loss=1.192, ntokens=966.7, nsentences=32, sample_size=966.7, sample_size_v1=0, sample_size_v2=0, ppl=2.28, wps=253.9, ups=0.26, wpb=966.7, bsz=32, num_updates=37490, lr=2.96255e-06, gnorm=21.292, clip=100, loss_scale=32, train_wall=38, gb_free=8.9, wall=144622
2023-05-22 10:08:23 - progress_bar.py[line:272] - INFO: epoch 022:   1196 / 1732 loss=2.382, loss_v1=0, loss_v2=0, nll_loss=1.182, ntokens=1072.1, nsentences=32, sample_size=1072.1, sample_size_v1=0, sample_size_v2=0, ppl=2.27, wps=279.4, ups=0.26, wpb=1072.1, bsz=32, num_updates=37500, lr=2.96051e-06, gnorm=19.515, clip=100, loss_scale=32, train_wall=38, gb_free=8.4, wall=144660
2023-05-22 10:09:02 - progress_bar.py[line:272] - INFO: epoch 022:   1206 / 1732 loss=2.352, loss_v1=0, loss_v2=0, nll_loss=1.148, ntokens=1115.4, nsentences=32, sample_size=1115.4, sample_size_v1=0, sample_size_v2=0, ppl=2.22, wps=287.2, ups=0.26, wpb=1115.4, bsz=32, num_updates=37510, lr=2.95846e-06, gnorm=17.256, clip=100, loss_scale=32, train_wall=39, gb_free=9, wall=144699
2023-05-22 10:09:40 - progress_bar.py[line:272] - INFO: epoch 022:   1216 / 1732 loss=2.393, loss_v1=0, loss_v2=0, nll_loss=1.191, ntokens=1038.1, nsentences=32, sample_size=1038.1, sample_size_v1=0, sample_size_v2=0, ppl=2.28, wps=270.5, ups=0.26, wpb=1038.1, bsz=32, num_updates=37520, lr=2.95641e-06, gnorm=19.993, clip=100, loss_scale=32, train_wall=38, gb_free=8.1, wall=144738
2023-05-22 10:10:19 - progress_bar.py[line:272] - INFO: epoch 022:   1226 / 1732 loss=2.399, loss_v1=0, loss_v2=0, nll_loss=1.198, ntokens=1020.3, nsentences=32, sample_size=1020.3, sample_size_v1=0, sample_size_v2=0, ppl=2.29, wps=264.7, ups=0.26, wpb=1020.3, bsz=32, num_updates=37530, lr=2.95436e-06, gnorm=19.804, clip=100, loss_scale=32, train_wall=38, gb_free=8.2, wall=144776
2023-05-22 10:10:57 - progress_bar.py[line:272] - INFO: epoch 022:   1236 / 1732 loss=2.361, loss_v1=0, loss_v2=0, nll_loss=1.156, ntokens=1034, nsentences=32, sample_size=1034, sample_size_v1=0, sample_size_v2=0, ppl=2.23, wps=271.1, ups=0.26, wpb=1034, bsz=32, num_updates=37540, lr=2.95232e-06, gnorm=19.397, clip=100, loss_scale=32, train_wall=38, gb_free=7.8, wall=144814
2023-05-22 10:11:36 - progress_bar.py[line:272] - INFO: epoch 022:   1246 / 1732 loss=2.324, loss_v1=0, loss_v2=0, nll_loss=1.116, ntokens=1109.3, nsentences=32, sample_size=1109.3, sample_size_v1=0, sample_size_v2=0, ppl=2.17, wps=287.9, ups=0.26, wpb=1109.3, bsz=32, num_updates=37550, lr=2.95027e-06, gnorm=18.013, clip=100, loss_scale=32, train_wall=38, gb_free=7.8, wall=144853
2023-05-22 10:12:14 - progress_bar.py[line:272] - INFO: epoch 022:   1256 / 1732 loss=2.358, loss_v1=0, loss_v2=0, nll_loss=1.155, ntokens=1060.4, nsentences=32, sample_size=1060.4, sample_size_v1=0, sample_size_v2=0, ppl=2.23, wps=277.5, ups=0.26, wpb=1060.4, bsz=32, num_updates=37560, lr=2.94822e-06, gnorm=17.612, clip=100, loss_scale=32, train_wall=38, gb_free=8.5, wall=144891
2023-05-22 10:12:52 - progress_bar.py[line:272] - INFO: epoch 022:   1266 / 1732 loss=2.39, loss_v1=0, loss_v2=0, nll_loss=1.189, ntokens=1048.7, nsentences=32, sample_size=1048.7, sample_size_v1=0, sample_size_v2=0, ppl=2.28, wps=272.6, ups=0.26, wpb=1048.7, bsz=32, num_updates=37570, lr=2.94617e-06, gnorm=18.455, clip=100, loss_scale=32, train_wall=38, gb_free=8.6, wall=144930
2023-05-22 10:13:31 - progress_bar.py[line:272] - INFO: epoch 022:   1276 / 1732 loss=2.383, loss_v1=0, loss_v2=0, nll_loss=1.182, ntokens=1075.2, nsentences=32, sample_size=1075.2, sample_size_v1=0, sample_size_v2=0, ppl=2.27, wps=279.4, ups=0.26, wpb=1075.2, bsz=32, num_updates=37580, lr=2.94413e-06, gnorm=19.194, clip=100, loss_scale=32, train_wall=38, gb_free=8.1, wall=144968
2023-05-22 10:14:09 - progress_bar.py[line:272] - INFO: epoch 022:   1286 / 1732 loss=2.376, loss_v1=0, loss_v2=0, nll_loss=1.173, ntokens=1038.1, nsentences=32, sample_size=1038.1, sample_size_v1=0, sample_size_v2=0, ppl=2.26, wps=269.8, ups=0.26, wpb=1038.1, bsz=32, num_updates=37590, lr=2.94208e-06, gnorm=18.942, clip=100, loss_scale=32, train_wall=38, gb_free=8.8, wall=145007
2023-05-22 10:14:48 - progress_bar.py[line:272] - INFO: epoch 022:   1296 / 1732 loss=2.349, loss_v1=0, loss_v2=0, nll_loss=1.144, ntokens=1121.3, nsentences=32, sample_size=1121.3, sample_size_v1=0, sample_size_v2=0, ppl=2.21, wps=290.8, ups=0.26, wpb=1121.3, bsz=32, num_updates=37600, lr=2.94003e-06, gnorm=16.639, clip=100, loss_scale=32, train_wall=39, gb_free=8.4, wall=145045
2023-05-22 10:15:27 - progress_bar.py[line:272] - INFO: epoch 022:   1306 / 1732 loss=2.393, loss_v1=0, loss_v2=0, nll_loss=1.193, ntokens=1091, nsentences=32, sample_size=1091, sample_size_v1=0, sample_size_v2=0, ppl=2.29, wps=280.9, ups=0.26, wpb=1091, bsz=32, num_updates=37610, lr=2.93798e-06, gnorm=16.753, clip=100, loss_scale=32, train_wall=39, gb_free=7.8, wall=145084
2023-05-22 10:16:05 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2023-05-22 10:16:09 - progress_bar.py[line:272] - INFO: epoch 022:   1317 / 1732 loss=2.393, loss_v1=0, loss_v2=0, nll_loss=1.192, ntokens=1018.9, nsentences=32, sample_size=1018.9, sample_size_v1=0, sample_size_v2=0, ppl=2.29, wps=241.3, ups=0.24, wpb=1018.9, bsz=32, num_updates=37620, lr=2.93594e-06, gnorm=18.42, clip=100, loss_scale=16, train_wall=42, gb_free=8.6, wall=145126
2023-05-22 10:16:48 - progress_bar.py[line:272] - INFO: epoch 022:   1327 / 1732 loss=2.36, loss_v1=0, loss_v2=0, nll_loss=1.154, ntokens=1124.5, nsentences=32, sample_size=1124.5, sample_size_v1=0, sample_size_v2=0, ppl=2.23, wps=288.7, ups=0.26, wpb=1124.5, bsz=32, num_updates=37630, lr=2.93389e-06, gnorm=17.329, clip=100, loss_scale=16, train_wall=39, gb_free=8.4, wall=145165
2023-05-22 10:17:26 - progress_bar.py[line:272] - INFO: epoch 022:   1337 / 1732 loss=2.352, loss_v1=0, loss_v2=0, nll_loss=1.147, ntokens=1126.2, nsentences=32, sample_size=1126.2, sample_size_v1=0, sample_size_v2=0, ppl=2.21, wps=292.1, ups=0.26, wpb=1126.2, bsz=32, num_updates=37640, lr=2.93184e-06, gnorm=20.242, clip=100, loss_scale=16, train_wall=39, gb_free=8.6, wall=145204
2023-05-22 10:18:05 - progress_bar.py[line:272] - INFO: epoch 022:   1347 / 1732 loss=2.368, loss_v1=0, loss_v2=0, nll_loss=1.165, ntokens=1159.1, nsentences=32, sample_size=1159.1, sample_size_v1=0, sample_size_v2=0, ppl=2.24, wps=299.1, ups=0.26, wpb=1159.1, bsz=32, num_updates=37650, lr=2.9298e-06, gnorm=19.222, clip=100, loss_scale=16, train_wall=39, gb_free=8.9, wall=145242
2023-05-22 10:18:44 - progress_bar.py[line:272] - INFO: epoch 022:   1357 / 1732 loss=2.343, loss_v1=0, loss_v2=0, nll_loss=1.137, ntokens=1146.3, nsentences=32, sample_size=1146.3, sample_size_v1=0, sample_size_v2=0, ppl=2.2, wps=296.4, ups=0.26, wpb=1146.3, bsz=32, num_updates=37660, lr=2.92775e-06, gnorm=17.235, clip=100, loss_scale=16, train_wall=39, gb_free=8, wall=145281
2023-05-22 10:19:23 - progress_bar.py[line:272] - INFO: epoch 022:   1367 / 1732 loss=2.368, loss_v1=0, loss_v2=0, nll_loss=1.165, ntokens=1081.6, nsentences=32, sample_size=1081.6, sample_size_v1=0, sample_size_v2=0, ppl=2.24, wps=280, ups=0.26, wpb=1081.6, bsz=32, num_updates=37670, lr=2.9257e-06, gnorm=17.693, clip=100, loss_scale=16, train_wall=39, gb_free=8.5, wall=145320
2023-05-22 10:20:01 - progress_bar.py[line:272] - INFO: epoch 022:   1377 / 1732 loss=2.399, loss_v1=0, loss_v2=0, nll_loss=1.2, ntokens=1107.3, nsentences=32, sample_size=1107.3, sample_size_v1=0, sample_size_v2=0, ppl=2.3, wps=287, ups=0.26, wpb=1107.3, bsz=32, num_updates=37680, lr=2.92365e-06, gnorm=18.435, clip=100, loss_scale=16, train_wall=39, gb_free=8.7, wall=145358
2023-05-22 10:20:39 - progress_bar.py[line:272] - INFO: epoch 022:   1387 / 1732 loss=2.359, loss_v1=0, loss_v2=0, nll_loss=1.155, ntokens=1152.6, nsentences=32, sample_size=1152.6, sample_size_v1=0, sample_size_v2=0, ppl=2.23, wps=300.6, ups=0.26, wpb=1152.6, bsz=32, num_updates=37690, lr=2.92161e-06, gnorm=17.073, clip=100, loss_scale=16, train_wall=38, gb_free=8.6, wall=145397
2023-05-22 10:21:18 - progress_bar.py[line:272] - INFO: epoch 022:   1397 / 1732 loss=2.369, loss_v1=0, loss_v2=0, nll_loss=1.167, ntokens=1066.5, nsentences=32, sample_size=1066.5, sample_size_v1=0, sample_size_v2=0, ppl=2.24, wps=277.4, ups=0.26, wpb=1066.5, bsz=32, num_updates=37700, lr=2.91956e-06, gnorm=19.001, clip=100, loss_scale=16, train_wall=38, gb_free=8.2, wall=145435
2023-05-22 10:21:56 - progress_bar.py[line:272] - INFO: epoch 022:   1407 / 1732 loss=2.366, loss_v1=0, loss_v2=0, nll_loss=1.162, ntokens=1152.8, nsentences=32, sample_size=1152.8, sample_size_v1=0, sample_size_v2=0, ppl=2.24, wps=299.2, ups=0.26, wpb=1152.8, bsz=32, num_updates=37710, lr=2.91751e-06, gnorm=18.468, clip=100, loss_scale=16, train_wall=38, gb_free=8.4, wall=145474
2023-05-22 10:22:35 - progress_bar.py[line:272] - INFO: epoch 022:   1417 / 1732 loss=2.384, loss_v1=0, loss_v2=0, nll_loss=1.184, ntokens=1290.7, nsentences=32, sample_size=1290.7, sample_size_v1=0, sample_size_v2=0, ppl=2.27, wps=330.7, ups=0.26, wpb=1290.7, bsz=32, num_updates=37720, lr=2.91546e-06, gnorm=16.261, clip=100, loss_scale=16, train_wall=39, gb_free=8, wall=145513
2023-05-22 10:23:14 - progress_bar.py[line:272] - INFO: epoch 022:   1427 / 1732 loss=2.342, loss_v1=0, loss_v2=0, nll_loss=1.135, ntokens=1220.7, nsentences=32, sample_size=1220.7, sample_size_v1=0, sample_size_v2=0, ppl=2.2, wps=314.1, ups=0.26, wpb=1220.7, bsz=32, num_updates=37730, lr=2.91342e-06, gnorm=16.874, clip=100, loss_scale=16, train_wall=39, gb_free=8.8, wall=145552
2023-05-22 10:23:53 - progress_bar.py[line:272] - INFO: epoch 022:   1437 / 1732 loss=2.354, loss_v1=0, loss_v2=0, nll_loss=1.149, ntokens=1217.2, nsentences=32, sample_size=1217.2, sample_size_v1=0, sample_size_v2=0, ppl=2.22, wps=314.8, ups=0.26, wpb=1217.2, bsz=32, num_updates=37740, lr=2.91137e-06, gnorm=14.845, clip=100, loss_scale=16, train_wall=39, gb_free=6.5, wall=145590
2023-05-22 10:24:31 - progress_bar.py[line:272] - INFO: epoch 022:   1447 / 1732 loss=2.381, loss_v1=0, loss_v2=0, nll_loss=1.181, ntokens=1115.7, nsentences=32, sample_size=1115.7, sample_size_v1=0, sample_size_v2=0, ppl=2.27, wps=291.1, ups=0.26, wpb=1115.7, bsz=32, num_updates=37750, lr=2.90932e-06, gnorm=18.516, clip=100, loss_scale=16, train_wall=38, gb_free=8.8, wall=145629
2023-05-22 10:25:10 - progress_bar.py[line:272] - INFO: epoch 022:   1457 / 1732 loss=2.383, loss_v1=0, loss_v2=0, nll_loss=1.182, ntokens=1111.8, nsentences=32, sample_size=1111.8, sample_size_v1=0, sample_size_v2=0, ppl=2.27, wps=287, ups=0.26, wpb=1111.8, bsz=32, num_updates=37760, lr=2.90727e-06, gnorm=17.913, clip=100, loss_scale=16, train_wall=39, gb_free=7.7, wall=145667
2023-05-22 10:25:49 - progress_bar.py[line:272] - INFO: epoch 022:   1467 / 1732 loss=2.322, loss_v1=0, loss_v2=0, nll_loss=1.113, ntokens=1202.5, nsentences=32, sample_size=1202.5, sample_size_v1=0, sample_size_v2=0, ppl=2.16, wps=309.9, ups=0.26, wpb=1202.5, bsz=32, num_updates=37770, lr=2.90523e-06, gnorm=15.834, clip=100, loss_scale=16, train_wall=39, gb_free=8.5, wall=145706
2023-05-22 10:26:27 - progress_bar.py[line:272] - INFO: epoch 022:   1477 / 1732 loss=2.387, loss_v1=0, loss_v2=0, nll_loss=1.185, ntokens=1052.1, nsentences=32, sample_size=1052.1, sample_size_v1=0, sample_size_v2=0, ppl=2.27, wps=274.2, ups=0.26, wpb=1052.1, bsz=32, num_updates=37780, lr=2.90318e-06, gnorm=18.692, clip=100, loss_scale=16, train_wall=38, gb_free=7.8, wall=145744
2023-05-22 10:27:06 - progress_bar.py[line:272] - INFO: epoch 022:   1487 / 1732 loss=2.383, loss_v1=0, loss_v2=0, nll_loss=1.182, ntokens=1147.5, nsentences=32, sample_size=1147.5, sample_size_v1=0, sample_size_v2=0, ppl=2.27, wps=297, ups=0.26, wpb=1147.5, bsz=32, num_updates=37790, lr=2.90113e-06, gnorm=17.564, clip=100, loss_scale=16, train_wall=39, gb_free=8, wall=145783
2023-05-22 10:27:44 - progress_bar.py[line:272] - INFO: epoch 022:   1497 / 1732 loss=2.351, loss_v1=0, loss_v2=0, nll_loss=1.147, ntokens=1083.9, nsentences=32, sample_size=1083.9, sample_size_v1=0, sample_size_v2=0, ppl=2.21, wps=281.4, ups=0.26, wpb=1083.9, bsz=32, num_updates=37800, lr=2.89908e-06, gnorm=17.606, clip=100, loss_scale=16, train_wall=38, gb_free=8.4, wall=145822
2023-05-22 10:28:23 - progress_bar.py[line:272] - INFO: epoch 022:   1507 / 1732 loss=2.309, loss_v1=0, loss_v2=0, nll_loss=1.099, ntokens=1112.5, nsentences=32, sample_size=1112.5, sample_size_v1=0, sample_size_v2=0, ppl=2.14, wps=289.5, ups=0.26, wpb=1112.5, bsz=32, num_updates=37810, lr=2.89704e-06, gnorm=18.288, clip=100, loss_scale=16, train_wall=38, gb_free=8.3, wall=145860
2023-05-22 10:29:01 - progress_bar.py[line:272] - INFO: epoch 022:   1517 / 1732 loss=2.385, loss_v1=0, loss_v2=0, nll_loss=1.184, ntokens=1063, nsentences=32, sample_size=1063, sample_size_v1=0, sample_size_v2=0, ppl=2.27, wps=276.3, ups=0.26, wpb=1063, bsz=32, num_updates=37820, lr=2.89499e-06, gnorm=18.133, clip=100, loss_scale=16, train_wall=38, gb_free=7.8, wall=145899
2023-05-22 10:29:40 - progress_bar.py[line:272] - INFO: epoch 022:   1527 / 1732 loss=2.413, loss_v1=0, loss_v2=0, nll_loss=1.215, ntokens=1062.3, nsentences=32, sample_size=1062.3, sample_size_v1=0, sample_size_v2=0, ppl=2.32, wps=275.7, ups=0.26, wpb=1062.3, bsz=32, num_updates=37830, lr=2.89294e-06, gnorm=18.787, clip=100, loss_scale=16, train_wall=38, gb_free=8.3, wall=145937
2023-05-22 10:30:18 - progress_bar.py[line:272] - INFO: epoch 022:   1537 / 1732 loss=2.368, loss_v1=0, loss_v2=0, nll_loss=1.164, ntokens=1067, nsentences=32, sample_size=1067, sample_size_v1=0, sample_size_v2=0, ppl=2.24, wps=276.6, ups=0.26, wpb=1067, bsz=32, num_updates=37840, lr=2.8909e-06, gnorm=18.343, clip=100, loss_scale=16, train_wall=39, gb_free=7.7, wall=145976
2023-05-22 10:30:57 - progress_bar.py[line:272] - INFO: epoch 022:   1547 / 1732 loss=2.346, loss_v1=0, loss_v2=0, nll_loss=1.14, ntokens=1093.5, nsentences=32, sample_size=1093.5, sample_size_v1=0, sample_size_v2=0, ppl=2.2, wps=285.1, ups=0.26, wpb=1093.5, bsz=32, num_updates=37850, lr=2.88885e-06, gnorm=18.554, clip=100, loss_scale=16, train_wall=38, gb_free=8.4, wall=146014
2023-05-22 10:31:35 - progress_bar.py[line:272] - INFO: epoch 022:   1557 / 1732 loss=2.355, loss_v1=0, loss_v2=0, nll_loss=1.15, ntokens=1051.1, nsentences=32, sample_size=1051.1, sample_size_v1=0, sample_size_v2=0, ppl=2.22, wps=274.1, ups=0.26, wpb=1051.1, bsz=32, num_updates=37860, lr=2.8868e-06, gnorm=18.656, clip=100, loss_scale=16, train_wall=38, gb_free=8.3, wall=146052
2023-05-22 10:32:14 - progress_bar.py[line:272] - INFO: epoch 022:   1567 / 1732 loss=2.401, loss_v1=0, loss_v2=0, nll_loss=1.202, ntokens=1097.1, nsentences=32, sample_size=1097.1, sample_size_v1=0, sample_size_v2=0, ppl=2.3, wps=284.8, ups=0.26, wpb=1097.1, bsz=32, num_updates=37870, lr=2.88475e-06, gnorm=19.631, clip=100, loss_scale=16, train_wall=38, gb_free=7.5, wall=146091
2023-05-22 10:32:52 - progress_bar.py[line:272] - INFO: epoch 022:   1577 / 1732 loss=2.407, loss_v1=0, loss_v2=0, nll_loss=1.209, ntokens=1002.1, nsentences=32, sample_size=1002.1, sample_size_v1=0, sample_size_v2=0, ppl=2.31, wps=261.5, ups=0.26, wpb=1002.1, bsz=32, num_updates=37880, lr=2.88271e-06, gnorm=21.518, clip=100, loss_scale=16, train_wall=38, gb_free=8.7, wall=146129
2023-05-22 10:33:31 - progress_bar.py[line:272] - INFO: epoch 022:   1587 / 1732 loss=2.379, loss_v1=0, loss_v2=0, nll_loss=1.177, ntokens=1081.3, nsentences=32, sample_size=1081.3, sample_size_v1=0, sample_size_v2=0, ppl=2.26, wps=279.1, ups=0.26, wpb=1081.3, bsz=32, num_updates=37890, lr=2.88066e-06, gnorm=18.231, clip=100, loss_scale=16, train_wall=39, gb_free=7.9, wall=146168
2023-05-22 10:34:09 - progress_bar.py[line:272] - INFO: epoch 022:   1597 / 1732 loss=2.346, loss_v1=0, loss_v2=0, nll_loss=1.141, ntokens=1084.4, nsentences=32, sample_size=1084.4, sample_size_v1=0, sample_size_v2=0, ppl=2.21, wps=281.7, ups=0.26, wpb=1084.4, bsz=32, num_updates=37900, lr=2.87861e-06, gnorm=17.449, clip=100, loss_scale=16, train_wall=38, gb_free=8, wall=146206
2023-05-22 10:34:48 - progress_bar.py[line:272] - INFO: epoch 022:   1607 / 1732 loss=2.353, loss_v1=0, loss_v2=0, nll_loss=1.15, ntokens=1122.8, nsentences=32, sample_size=1122.8, sample_size_v1=0, sample_size_v2=0, ppl=2.22, wps=290.3, ups=0.26, wpb=1122.8, bsz=32, num_updates=37910, lr=2.87656e-06, gnorm=18.519, clip=100, loss_scale=16, train_wall=39, gb_free=8, wall=146245
2023-05-22 10:35:27 - progress_bar.py[line:272] - INFO: epoch 022:   1617 / 1732 loss=2.326, loss_v1=0, loss_v2=0, nll_loss=1.12, ntokens=1114.5, nsentences=32, sample_size=1114.5, sample_size_v1=0, sample_size_v2=0, ppl=2.17, wps=288.1, ups=0.26, wpb=1114.5, bsz=32, num_updates=37920, lr=2.87452e-06, gnorm=17.476, clip=100, loss_scale=16, train_wall=39, gb_free=8.4, wall=146284
2023-05-22 10:36:05 - progress_bar.py[line:272] - INFO: epoch 022:   1627 / 1732 loss=2.357, loss_v1=0, loss_v2=0, nll_loss=1.153, ntokens=1162.3, nsentences=32, sample_size=1162.3, sample_size_v1=0, sample_size_v2=0, ppl=2.22, wps=299.8, ups=0.26, wpb=1162.3, bsz=32, num_updates=37930, lr=2.87247e-06, gnorm=16.554, clip=100, loss_scale=16, train_wall=39, gb_free=8.3, wall=146323
2023-05-22 10:36:44 - progress_bar.py[line:272] - INFO: epoch 022:   1637 / 1732 loss=2.341, loss_v1=0, loss_v2=0, nll_loss=1.134, ntokens=1115.7, nsentences=32, sample_size=1115.7, sample_size_v1=0, sample_size_v2=0, ppl=2.2, wps=290.9, ups=0.26, wpb=1115.7, bsz=32, num_updates=37940, lr=2.87042e-06, gnorm=19.12, clip=100, loss_scale=16, train_wall=38, gb_free=8.6, wall=146361
2023-05-22 10:37:23 - progress_bar.py[line:272] - INFO: epoch 022:   1647 / 1732 loss=2.319, loss_v1=0, loss_v2=0, nll_loss=1.11, ntokens=1285, nsentences=32, sample_size=1285, sample_size_v1=0, sample_size_v2=0, ppl=2.16, wps=329.8, ups=0.26, wpb=1285, bsz=32, num_updates=37950, lr=2.86837e-06, gnorm=14.918, clip=100, loss_scale=16, train_wall=39, gb_free=8.2, wall=146400
2023-05-22 10:38:01 - progress_bar.py[line:272] - INFO: epoch 022:   1657 / 1732 loss=2.39, loss_v1=0, loss_v2=0, nll_loss=1.19, ntokens=952, nsentences=32, sample_size=952, sample_size_v1=0, sample_size_v2=0, ppl=2.28, wps=249.7, ups=0.26, wpb=952, bsz=32, num_updates=37960, lr=2.86633e-06, gnorm=19.111, clip=100, loss_scale=16, train_wall=38, gb_free=8.4, wall=146438
2023-05-22 10:38:39 - progress_bar.py[line:272] - INFO: epoch 022:   1667 / 1732 loss=2.364, loss_v1=0, loss_v2=0, nll_loss=1.161, ntokens=1028.1, nsentences=32, sample_size=1028.1, sample_size_v1=0, sample_size_v2=0, ppl=2.24, wps=266.7, ups=0.26, wpb=1028.1, bsz=32, num_updates=37970, lr=2.86428e-06, gnorm=18.851, clip=100, loss_scale=16, train_wall=38, gb_free=8.5, wall=146477
2023-05-22 10:39:18 - progress_bar.py[line:272] - INFO: epoch 022:   1677 / 1732 loss=2.316, loss_v1=0, loss_v2=0, nll_loss=1.107, ntokens=1135.4, nsentences=32, sample_size=1135.4, sample_size_v1=0, sample_size_v2=0, ppl=2.15, wps=294.4, ups=0.26, wpb=1135.4, bsz=32, num_updates=37980, lr=2.86223e-06, gnorm=16.454, clip=100, loss_scale=16, train_wall=39, gb_free=7.4, wall=146515
2023-05-22 10:39:57 - progress_bar.py[line:272] - INFO: epoch 022:   1687 / 1732 loss=2.34, loss_v1=0, loss_v2=0, nll_loss=1.134, ntokens=1154.5, nsentences=32, sample_size=1154.5, sample_size_v1=0, sample_size_v2=0, ppl=2.19, wps=298.3, ups=0.26, wpb=1154.5, bsz=32, num_updates=37990, lr=2.86018e-06, gnorm=17.067, clip=100, loss_scale=16, train_wall=39, gb_free=7, wall=146554
2023-05-22 10:40:36 - progress_bar.py[line:272] - INFO: epoch 022:   1697 / 1732 loss=2.344, loss_v1=0, loss_v2=0, nll_loss=1.14, ntokens=1302.5, nsentences=32, sample_size=1302.5, sample_size_v1=0, sample_size_v2=0, ppl=2.2, wps=330.1, ups=0.25, wpb=1302.5, bsz=32, num_updates=38000, lr=2.85814e-06, gnorm=16.479, clip=100, loss_scale=16, train_wall=39, gb_free=8, wall=146593
2023-05-22 10:41:15 - progress_bar.py[line:272] - INFO: epoch 022:   1707 / 1732 loss=2.353, loss_v1=0, loss_v2=0, nll_loss=1.148, ntokens=1171.1, nsentences=32, sample_size=1171.1, sample_size_v1=0, sample_size_v2=0, ppl=2.22, wps=302.1, ups=0.26, wpb=1171.1, bsz=32, num_updates=38010, lr=2.85609e-06, gnorm=16.428, clip=100, loss_scale=16, train_wall=39, gb_free=8.5, wall=146632
2023-05-22 10:41:54 - progress_bar.py[line:272] - INFO: epoch 022:   1717 / 1732 loss=2.342, loss_v1=0, loss_v2=0, nll_loss=1.136, ntokens=1206.1, nsentences=32, sample_size=1206.1, sample_size_v1=0, sample_size_v2=0, ppl=2.2, wps=310.4, ups=0.26, wpb=1206.1, bsz=32, num_updates=38020, lr=2.85404e-06, gnorm=15.715, clip=100, loss_scale=16, train_wall=39, gb_free=8.3, wall=146671
2023-05-22 10:42:32 - progress_bar.py[line:272] - INFO: epoch 022:   1727 / 1732 loss=2.384, loss_v1=0, loss_v2=0, nll_loss=1.183, ntokens=1102.3, nsentences=32, sample_size=1102.3, sample_size_v1=0, sample_size_v2=0, ppl=2.27, wps=285.9, ups=0.26, wpb=1102.3, bsz=32, num_updates=38030, lr=2.852e-06, gnorm=17.509, clip=100, loss_scale=16, train_wall=39, gb_free=8.8, wall=146710
2023-05-22 10:42:49 - train.py[line:332] - INFO: end of epoch 22 (average epoch stats below)
2023-05-22 10:42:49 - progress_bar.py[line:282] - INFO: epoch 022 | loss 2.369 | loss_v1 0 | loss_v2 0 | nll_loss 1.166 | ntokens 1051.54 | nsentences 31.986 | sample_size 1051.54 | sample_size_v1 0 | sample_size_v2 0 | ppl 2.24 | wps 274.2 | ups 0.26 | wpb 1051.5 | bsz 32 | num_updates 38035 | lr 2.85097e-06 | gnorm 18.276 | clip 100 | loss_scale 16 | train_wall 6619 | gb_free 8.9 | wall 146726
2023-05-22 10:42:49 - trainer.py[line:639] - INFO: loading train data for epoch 23
local datafile ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 0 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 0 finished initializing row_count and line_idx-to-offset mapping
file ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 0 row count 55400 total row count 55400
slice_id 0 seek offset 0
2023-05-22 10:42:51 - trainer.py[line:703] - INFO: begin training epoch 23
2023-05-22 10:42:51 - train.py[line:305] - INFO: Start iterating over samples
2023-05-22 10:43:10 - progress_bar.py[line:272] - INFO: epoch 023:      5 / 1732 loss=2.334, loss_v1=0, loss_v2=0, nll_loss=1.127, ntokens=1084.5, nsentences=29.6, sample_size=1084.5, sample_size_v1=0, sample_size_v2=0, ppl=2.18, wps=285.7, ups=0.26, wpb=1084.5, bsz=29.6, num_updates=38040, lr=2.84995e-06, gnorm=18.274, clip=100, loss_scale=16, train_wall=36, gb_free=8.4, wall=146748
2023-05-22 10:43:49 - progress_bar.py[line:272] - INFO: epoch 023:     15 / 1732 loss=2.314, loss_v1=0, loss_v2=0, nll_loss=1.104, ntokens=1089.9, nsentences=32, sample_size=1089.9, sample_size_v1=0, sample_size_v2=0, ppl=2.15, wps=282.9, ups=0.26, wpb=1089.9, bsz=32, num_updates=38050, lr=2.8479e-06, gnorm=18.864, clip=100, loss_scale=16, train_wall=38, gb_free=8.2, wall=146786
2023-05-22 10:44:27 - progress_bar.py[line:272] - INFO: epoch 023:     25 / 1732 loss=2.273, loss_v1=0, loss_v2=0, nll_loss=1.058, ntokens=998.7, nsentences=32, sample_size=998.7, sample_size_v1=0, sample_size_v2=0, ppl=2.08, wps=260.1, ups=0.26, wpb=998.7, bsz=32, num_updates=38060, lr=2.84585e-06, gnorm=17.897, clip=100, loss_scale=16, train_wall=38, gb_free=9.1, wall=146824
2023-05-22 10:45:06 - progress_bar.py[line:272] - INFO: epoch 023:     35 / 1732 loss=2.185, loss_v1=0, loss_v2=0, nll_loss=0.958, ntokens=1115.2, nsentences=32, sample_size=1115.2, sample_size_v1=0, sample_size_v2=0, ppl=1.94, wps=287.5, ups=0.26, wpb=1115.2, bsz=32, num_updates=38070, lr=2.84381e-06, gnorm=14.733, clip=100, loss_scale=16, train_wall=39, gb_free=8.1, wall=146863
2023-05-22 10:45:45 - progress_bar.py[line:272] - INFO: epoch 023:     45 / 1732 loss=2.168, loss_v1=0, loss_v2=0, nll_loss=0.944, ntokens=1103.9, nsentences=32, sample_size=1103.9, sample_size_v1=0, sample_size_v2=0, ppl=1.92, wps=285.4, ups=0.26, wpb=1103.9, bsz=32, num_updates=38080, lr=2.84176e-06, gnorm=14.162, clip=100, loss_scale=16, train_wall=39, gb_free=7.8, wall=146902
2023-05-22 10:46:23 - progress_bar.py[line:272] - INFO: epoch 023:     55 / 1732 loss=2.126, loss_v1=0, loss_v2=0, nll_loss=0.897, ntokens=1058.4, nsentences=32, sample_size=1058.4, sample_size_v1=0, sample_size_v2=0, ppl=1.86, wps=274.6, ups=0.26, wpb=1058.4, bsz=32, num_updates=38090, lr=2.83971e-06, gnorm=15.525, clip=100, loss_scale=16, train_wall=39, gb_free=8.2, wall=146940
2023-05-22 10:47:03 - progress_bar.py[line:272] - INFO: epoch 023:     65 / 1732 loss=2.002, loss_v1=0, loss_v2=0, nll_loss=0.761, ntokens=1260.1, nsentences=32, sample_size=1260.1, sample_size_v1=0, sample_size_v2=0, ppl=1.7, wps=320.9, ups=0.25, wpb=1260.1, bsz=32, num_updates=38100, lr=2.83766e-06, gnorm=11.667, clip=100, loss_scale=16, train_wall=39, gb_free=7.5, wall=146980
2023-05-22 10:47:42 - progress_bar.py[line:272] - INFO: epoch 023:     75 / 1732 loss=2.124, loss_v1=0, loss_v2=0, nll_loss=0.895, ntokens=1372.4, nsentences=32, sample_size=1372.4, sample_size_v1=0, sample_size_v2=0, ppl=1.86, wps=344.5, ups=0.25, wpb=1372.4, bsz=32, num_updates=38110, lr=2.83562e-06, gnorm=13.675, clip=100, loss_scale=16, train_wall=40, gb_free=7.6, wall=147020
2023-05-22 10:48:21 - progress_bar.py[line:272] - INFO: epoch 023:     85 / 1732 loss=2.186, loss_v1=0, loss_v2=0, nll_loss=0.963, ntokens=1112.6, nsentences=32, sample_size=1112.6, sample_size_v1=0, sample_size_v2=0, ppl=1.95, wps=284.9, ups=0.26, wpb=1112.6, bsz=32, num_updates=38120, lr=2.83357e-06, gnorm=18.498, clip=100, loss_scale=16, train_wall=39, gb_free=8.5, wall=147059
2023-05-22 10:49:00 - progress_bar.py[line:272] - INFO: epoch 023:     95 / 1732 loss=2.144, loss_v1=0, loss_v2=0, nll_loss=0.911, ntokens=1092.3, nsentences=32, sample_size=1092.3, sample_size_v1=0, sample_size_v2=0, ppl=1.88, wps=283.5, ups=0.26, wpb=1092.3, bsz=32, num_updates=38130, lr=2.83152e-06, gnorm=17.416, clip=100, loss_scale=16, train_wall=38, gb_free=8.8, wall=147097
2023-05-22 10:49:38 - progress_bar.py[line:272] - INFO: epoch 023:    105 / 1732 loss=2.318, loss_v1=0, loss_v2=0, nll_loss=1.111, ntokens=995.3, nsentences=32, sample_size=995.3, sample_size_v1=0, sample_size_v2=0, ppl=2.16, wps=260.3, ups=0.26, wpb=995.3, bsz=32, num_updates=38140, lr=2.82947e-06, gnorm=20.887, clip=100, loss_scale=32, train_wall=38, gb_free=8.3, wall=147135
2023-05-22 10:50:17 - progress_bar.py[line:272] - INFO: epoch 023:    115 / 1732 loss=2.388, loss_v1=0, loss_v2=0, nll_loss=1.186, ntokens=1032.5, nsentences=32, sample_size=1032.5, sample_size_v1=0, sample_size_v2=0, ppl=2.28, wps=267.5, ups=0.26, wpb=1032.5, bsz=32, num_updates=38150, lr=2.82743e-06, gnorm=20.983, clip=100, loss_scale=32, train_wall=39, gb_free=8.2, wall=147174
2023-05-22 10:50:56 - progress_bar.py[line:272] - INFO: epoch 023:    125 / 1732 loss=2.317, loss_v1=0, loss_v2=0, nll_loss=1.105, ntokens=1181.7, nsentences=32, sample_size=1181.7, sample_size_v1=0, sample_size_v2=0, ppl=2.15, wps=301.2, ups=0.25, wpb=1181.7, bsz=32, num_updates=38160, lr=2.82538e-06, gnorm=17.718, clip=100, loss_scale=32, train_wall=39, gb_free=7.4, wall=147213
2023-05-22 10:51:35 - progress_bar.py[line:272] - INFO: epoch 023:    135 / 1732 loss=2.293, loss_v1=0, loss_v2=0, nll_loss=1.079, ntokens=1179.6, nsentences=32, sample_size=1179.6, sample_size_v1=0, sample_size_v2=0, ppl=2.11, wps=302.7, ups=0.26, wpb=1179.6, bsz=32, num_updates=38170, lr=2.82333e-06, gnorm=16.474, clip=100, loss_scale=32, train_wall=39, gb_free=8.6, wall=147252
2023-05-22 10:52:14 - progress_bar.py[line:272] - INFO: epoch 023:    145 / 1732 loss=2.259, loss_v1=0, loss_v2=0, nll_loss=1.043, ntokens=1246.8, nsentences=32, sample_size=1246.8, sample_size_v1=0, sample_size_v2=0, ppl=2.06, wps=315.8, ups=0.25, wpb=1246.8, bsz=32, num_updates=38180, lr=2.82128e-06, gnorm=14.945, clip=100, loss_scale=32, train_wall=39, gb_free=7.7, wall=147292
2023-05-22 10:52:54 - progress_bar.py[line:272] - INFO: epoch 023:    155 / 1732 loss=2.291, loss_v1=0, loss_v2=0, nll_loss=1.08, ntokens=1151.6, nsentences=32, sample_size=1151.6, sample_size_v1=0, sample_size_v2=0, ppl=2.11, wps=292.5, ups=0.25, wpb=1151.6, bsz=32, num_updates=38190, lr=2.81924e-06, gnorm=15.695, clip=100, loss_scale=32, train_wall=39, gb_free=7.9, wall=147331
2023-05-22 10:53:33 - progress_bar.py[line:272] - INFO: epoch 023:    165 / 1732 loss=2.257, loss_v1=0, loss_v2=0, nll_loss=1.042, ntokens=1062.3, nsentences=32, sample_size=1062.3, sample_size_v1=0, sample_size_v2=0, ppl=2.06, wps=274.7, ups=0.26, wpb=1062.3, bsz=32, num_updates=38200, lr=2.81719e-06, gnorm=15.798, clip=100, loss_scale=32, train_wall=39, gb_free=8.8, wall=147370
2023-05-22 10:54:11 - progress_bar.py[line:272] - INFO: epoch 023:    175 / 1732 loss=2.296, loss_v1=0, loss_v2=0, nll_loss=1.086, ntokens=958.4, nsentences=32, sample_size=958.4, sample_size_v1=0, sample_size_v2=0, ppl=2.12, wps=248.6, ups=0.26, wpb=958.4, bsz=32, num_updates=38210, lr=2.81514e-06, gnorm=18.753, clip=100, loss_scale=32, train_wall=39, gb_free=7.7, wall=147408
2023-05-22 10:54:50 - progress_bar.py[line:272] - INFO: epoch 023:    185 / 1732 loss=2.234, loss_v1=0, loss_v2=0, nll_loss=1.016, ntokens=1173.4, nsentences=32, sample_size=1173.4, sample_size_v1=0, sample_size_v2=0, ppl=2.02, wps=299.4, ups=0.26, wpb=1173.4, bsz=32, num_updates=38220, lr=2.8131e-06, gnorm=15.139, clip=100, loss_scale=32, train_wall=39, gb_free=6.7, wall=147447
2023-05-22 10:55:29 - progress_bar.py[line:272] - INFO: epoch 023:    195 / 1732 loss=2.287, loss_v1=0, loss_v2=0, nll_loss=1.074, ntokens=1144.6, nsentences=32, sample_size=1144.6, sample_size_v1=0, sample_size_v2=0, ppl=2.11, wps=292.6, ups=0.26, wpb=1144.6, bsz=32, num_updates=38230, lr=2.81105e-06, gnorm=16.158, clip=100, loss_scale=32, train_wall=39, gb_free=7.7, wall=147487
2023-05-22 10:56:08 - progress_bar.py[line:272] - INFO: epoch 023:    205 / 1732 loss=2.363, loss_v1=0, loss_v2=0, nll_loss=1.16, ntokens=1021.8, nsentences=32, sample_size=1021.8, sample_size_v1=0, sample_size_v2=0, ppl=2.23, wps=267.5, ups=0.26, wpb=1021.8, bsz=32, num_updates=38240, lr=2.809e-06, gnorm=19.934, clip=100, loss_scale=32, train_wall=38, gb_free=9, wall=147525
2023-05-22 10:56:46 - progress_bar.py[line:272] - INFO: epoch 023:    215 / 1732 loss=2.388, loss_v1=0, loss_v2=0, nll_loss=1.188, ntokens=1094.3, nsentences=32, sample_size=1094.3, sample_size_v1=0, sample_size_v2=0, ppl=2.28, wps=285.3, ups=0.26, wpb=1094.3, bsz=32, num_updates=38250, lr=2.80695e-06, gnorm=17.383, clip=100, loss_scale=32, train_wall=38, gb_free=8.9, wall=147563
2023-05-22 10:57:24 - progress_bar.py[line:272] - INFO: epoch 023:    225 / 1732 loss=2.377, loss_v1=0, loss_v2=0, nll_loss=1.175, ntokens=1095.2, nsentences=32, sample_size=1095.2, sample_size_v1=0, sample_size_v2=0, ppl=2.26, wps=287.2, ups=0.26, wpb=1095.2, bsz=32, num_updates=38260, lr=2.80491e-06, gnorm=17.742, clip=100, loss_scale=32, train_wall=38, gb_free=8, wall=147601
2023-05-22 10:58:02 - progress_bar.py[line:272] - INFO: epoch 023:    235 / 1732 loss=2.433, loss_v1=0, loss_v2=0, nll_loss=1.238, ntokens=1090, nsentences=32, sample_size=1090, sample_size_v1=0, sample_size_v2=0, ppl=2.36, wps=287.3, ups=0.26, wpb=1090, bsz=32, num_updates=38270, lr=2.80286e-06, gnorm=16.812, clip=100, loss_scale=32, train_wall=38, gb_free=8.5, wall=147639
2023-05-22 10:58:40 - progress_bar.py[line:272] - INFO: epoch 023:    245 / 1732 loss=2.411, loss_v1=0, loss_v2=0, nll_loss=1.212, ntokens=1178.2, nsentences=32, sample_size=1178.2, sample_size_v1=0, sample_size_v2=0, ppl=2.32, wps=307.5, ups=0.26, wpb=1178.2, bsz=32, num_updates=38280, lr=2.80081e-06, gnorm=16.695, clip=100, loss_scale=32, train_wall=38, gb_free=8.4, wall=147678
2023-05-22 10:59:19 - progress_bar.py[line:272] - INFO: epoch 023:    255 / 1732 loss=2.412, loss_v1=0, loss_v2=0, nll_loss=1.215, ntokens=1128.2, nsentences=32, sample_size=1128.2, sample_size_v1=0, sample_size_v2=0, ppl=2.32, wps=295.2, ups=0.26, wpb=1128.2, bsz=32, num_updates=38290, lr=2.79876e-06, gnorm=17.862, clip=100, loss_scale=32, train_wall=38, gb_free=9, wall=147716
2023-05-22 10:59:57 - progress_bar.py[line:272] - INFO: epoch 023:    265 / 1732 loss=2.407, loss_v1=0, loss_v2=0, nll_loss=1.209, ntokens=1148, nsentences=32, sample_size=1148, sample_size_v1=0, sample_size_v2=0, ppl=2.31, wps=300.8, ups=0.26, wpb=1148, bsz=32, num_updates=38300, lr=2.79672e-06, gnorm=17.026, clip=100, loss_scale=32, train_wall=38, gb_free=8.5, wall=147754
2023-05-22 11:00:35 - progress_bar.py[line:272] - INFO: epoch 023:    275 / 1732 loss=2.4, loss_v1=0, loss_v2=0, nll_loss=1.2, ntokens=1140.3, nsentences=32, sample_size=1140.3, sample_size_v1=0, sample_size_v2=0, ppl=2.3, wps=298.1, ups=0.26, wpb=1140.3, bsz=32, num_updates=38310, lr=2.79467e-06, gnorm=18.513, clip=100, loss_scale=32, train_wall=38, gb_free=8.6, wall=147792
2023-05-22 11:01:13 - progress_bar.py[line:272] - INFO: epoch 023:    285 / 1732 loss=2.412, loss_v1=0, loss_v2=0, nll_loss=1.215, ntokens=1154.4, nsentences=32, sample_size=1154.4, sample_size_v1=0, sample_size_v2=0, ppl=2.32, wps=300.7, ups=0.26, wpb=1154.4, bsz=32, num_updates=38320, lr=2.79262e-06, gnorm=18.058, clip=100, loss_scale=32, train_wall=38, gb_free=7.3, wall=147831
2023-05-22 11:01:51 - progress_bar.py[line:272] - INFO: epoch 023:    295 / 1732 loss=2.392, loss_v1=0, loss_v2=0, nll_loss=1.191, ntokens=1115.8, nsentences=32, sample_size=1115.8, sample_size_v1=0, sample_size_v2=0, ppl=2.28, wps=293.1, ups=0.26, wpb=1115.8, bsz=32, num_updates=38330, lr=2.79057e-06, gnorm=17.612, clip=100, loss_scale=32, train_wall=38, gb_free=8.6, wall=147869
2023-05-22 11:02:30 - progress_bar.py[line:272] - INFO: epoch 023:    305 / 1732 loss=2.385, loss_v1=0, loss_v2=0, nll_loss=1.183, ntokens=1102.2, nsentences=32, sample_size=1102.2, sample_size_v1=0, sample_size_v2=0, ppl=2.27, wps=289.3, ups=0.26, wpb=1102.2, bsz=32, num_updates=38340, lr=2.78853e-06, gnorm=18.749, clip=100, loss_scale=32, train_wall=38, gb_free=8.2, wall=147907
2023-05-22 11:03:07 - progress_bar.py[line:272] - INFO: epoch 023:    315 / 1732 loss=2.407, loss_v1=0, loss_v2=0, nll_loss=1.208, ntokens=1020.3, nsentences=32, sample_size=1020.3, sample_size_v1=0, sample_size_v2=0, ppl=2.31, wps=269.5, ups=0.26, wpb=1020.3, bsz=32, num_updates=38350, lr=2.78648e-06, gnorm=18.846, clip=100, loss_scale=32, train_wall=38, gb_free=8.7, wall=147945
2023-05-22 11:03:45 - progress_bar.py[line:272] - INFO: epoch 023:    325 / 1732 loss=2.418, loss_v1=0, loss_v2=0, nll_loss=1.219, ntokens=1011.9, nsentences=32, sample_size=1011.9, sample_size_v1=0, sample_size_v2=0, ppl=2.33, wps=267.1, ups=0.26, wpb=1011.9, bsz=32, num_updates=38360, lr=2.78443e-06, gnorm=18.644, clip=100, loss_scale=32, train_wall=38, gb_free=9, wall=147983
2023-05-22 11:04:23 - progress_bar.py[line:272] - INFO: epoch 023:    335 / 1732 loss=2.417, loss_v1=0, loss_v2=0, nll_loss=1.218, ntokens=1020.9, nsentences=32, sample_size=1020.9, sample_size_v1=0, sample_size_v2=0, ppl=2.33, wps=269, ups=0.26, wpb=1020.9, bsz=32, num_updates=38370, lr=2.78238e-06, gnorm=18.371, clip=100, loss_scale=32, train_wall=38, gb_free=8.7, wall=148020
2023-05-22 11:05:01 - progress_bar.py[line:272] - INFO: epoch 023:    345 / 1732 loss=2.377, loss_v1=0, loss_v2=0, nll_loss=1.174, ntokens=903.9, nsentences=32, sample_size=903.9, sample_size_v1=0, sample_size_v2=0, ppl=2.26, wps=238.8, ups=0.26, wpb=903.9, bsz=32, num_updates=38380, lr=2.78034e-06, gnorm=19.313, clip=100, loss_scale=32, train_wall=38, gb_free=8.3, wall=148058
2023-05-22 11:05:39 - progress_bar.py[line:272] - INFO: epoch 023:    355 / 1732 loss=2.412, loss_v1=0, loss_v2=0, nll_loss=1.213, ntokens=961.9, nsentences=32, sample_size=961.9, sample_size_v1=0, sample_size_v2=0, ppl=2.32, wps=254.6, ups=0.26, wpb=961.9, bsz=32, num_updates=38390, lr=2.77829e-06, gnorm=20.964, clip=100, loss_scale=32, train_wall=38, gb_free=9, wall=148096
2023-05-22 11:06:17 - progress_bar.py[line:272] - INFO: epoch 023:    365 / 1732 loss=2.446, loss_v1=0, loss_v2=0, nll_loss=1.252, ntokens=955.9, nsentences=32, sample_size=955.9, sample_size_v1=0, sample_size_v2=0, ppl=2.38, wps=252.6, ups=0.26, wpb=955.9, bsz=32, num_updates=38400, lr=2.77624e-06, gnorm=21.061, clip=100, loss_scale=32, train_wall=38, gb_free=8.2, wall=148134
2023-05-22 11:06:55 - progress_bar.py[line:272] - INFO: epoch 023:    375 / 1732 loss=2.443, loss_v1=0, loss_v2=0, nll_loss=1.25, ntokens=987.5, nsentences=32, sample_size=987.5, sample_size_v1=0, sample_size_v2=0, ppl=2.38, wps=261.3, ups=0.26, wpb=987.5, bsz=32, num_updates=38410, lr=2.77419e-06, gnorm=19.998, clip=100, loss_scale=32, train_wall=38, gb_free=9.1, wall=148172
2023-05-22 11:07:32 - progress_bar.py[line:272] - INFO: epoch 023:    385 / 1732 loss=2.416, loss_v1=0, loss_v2=0, nll_loss=1.22, ntokens=1084.2, nsentences=32, sample_size=1084.2, sample_size_v1=0, sample_size_v2=0, ppl=2.33, wps=286.7, ups=0.26, wpb=1084.2, bsz=32, num_updates=38420, lr=2.77215e-06, gnorm=18.672, clip=100, loss_scale=32, train_wall=38, gb_free=8.8, wall=148210
2023-05-22 11:08:10 - progress_bar.py[line:272] - INFO: epoch 023:    395 / 1732 loss=2.422, loss_v1=0, loss_v2=0, nll_loss=1.225, ntokens=924.7, nsentences=32, sample_size=924.7, sample_size_v1=0, sample_size_v2=0, ppl=2.34, wps=246, ups=0.27, wpb=924.7, bsz=32, num_updates=38430, lr=2.7701e-06, gnorm=19.853, clip=100, loss_scale=32, train_wall=38, gb_free=8.8, wall=148247
2023-05-22 11:08:48 - progress_bar.py[line:272] - INFO: epoch 023:    405 / 1732 loss=2.374, loss_v1=0, loss_v2=0, nll_loss=1.171, ntokens=1086.5, nsentences=32, sample_size=1086.5, sample_size_v1=0, sample_size_v2=0, ppl=2.25, wps=285.6, ups=0.26, wpb=1086.5, bsz=32, num_updates=38440, lr=2.76805e-06, gnorm=17.058, clip=100, loss_scale=32, train_wall=38, gb_free=9, wall=148285
2023-05-22 11:09:26 - progress_bar.py[line:272] - INFO: epoch 023:    415 / 1732 loss=2.39, loss_v1=0, loss_v2=0, nll_loss=1.189, ntokens=1059.1, nsentences=32, sample_size=1059.1, sample_size_v1=0, sample_size_v2=0, ppl=2.28, wps=278.7, ups=0.26, wpb=1059.1, bsz=32, num_updates=38450, lr=2.76601e-06, gnorm=18.461, clip=100, loss_scale=32, train_wall=38, gb_free=8.9, wall=148323
2023-05-22 11:10:04 - progress_bar.py[line:272] - INFO: epoch 023:    425 / 1732 loss=2.364, loss_v1=0, loss_v2=0, nll_loss=1.161, ntokens=994.5, nsentences=32, sample_size=994.5, sample_size_v1=0, sample_size_v2=0, ppl=2.24, wps=262.7, ups=0.26, wpb=994.5, bsz=32, num_updates=38460, lr=2.76396e-06, gnorm=19.799, clip=100, loss_scale=32, train_wall=38, gb_free=8.5, wall=148361
2023-05-22 11:10:42 - progress_bar.py[line:272] - INFO: epoch 023:    435 / 1732 loss=2.408, loss_v1=0, loss_v2=0, nll_loss=1.21, ntokens=1024.5, nsentences=32, sample_size=1024.5, sample_size_v1=0, sample_size_v2=0, ppl=2.31, wps=271.5, ups=0.26, wpb=1024.5, bsz=32, num_updates=38470, lr=2.76191e-06, gnorm=19.183, clip=100, loss_scale=32, train_wall=38, gb_free=9.2, wall=148399
2023-05-22 11:11:19 - progress_bar.py[line:272] - INFO: epoch 023:    445 / 1732 loss=2.422, loss_v1=0, loss_v2=0, nll_loss=1.225, ntokens=956.5, nsentences=32, sample_size=956.5, sample_size_v1=0, sample_size_v2=0, ppl=2.34, wps=253.1, ups=0.26, wpb=956.5, bsz=32, num_updates=38480, lr=2.75986e-06, gnorm=19.791, clip=100, loss_scale=32, train_wall=38, gb_free=8.6, wall=148437
2023-05-22 11:11:57 - progress_bar.py[line:272] - INFO: epoch 023:    455 / 1732 loss=2.415, loss_v1=0, loss_v2=0, nll_loss=1.217, ntokens=932.1, nsentences=32, sample_size=932.1, sample_size_v1=0, sample_size_v2=0, ppl=2.33, wps=247, ups=0.27, wpb=932.1, bsz=32, num_updates=38490, lr=2.75782e-06, gnorm=20.138, clip=100, loss_scale=32, train_wall=38, gb_free=8.8, wall=148474
2023-05-22 11:12:35 - progress_bar.py[line:272] - INFO: epoch 023:    465 / 1732 loss=2.438, loss_v1=0, loss_v2=0, nll_loss=1.243, ntokens=1058.7, nsentences=32, sample_size=1058.7, sample_size_v1=0, sample_size_v2=0, ppl=2.37, wps=279, ups=0.26, wpb=1058.7, bsz=32, num_updates=38500, lr=2.75577e-06, gnorm=18.054, clip=100, loss_scale=32, train_wall=38, gb_free=8.6, wall=148512
2023-05-22 11:13:13 - progress_bar.py[line:272] - INFO: epoch 023:    475 / 1732 loss=2.429, loss_v1=0, loss_v2=0, nll_loss=1.232, ntokens=1061.8, nsentences=32, sample_size=1061.8, sample_size_v1=0, sample_size_v2=0, ppl=2.35, wps=278.7, ups=0.26, wpb=1061.8, bsz=32, num_updates=38510, lr=2.75372e-06, gnorm=19.579, clip=100, loss_scale=32, train_wall=38, gb_free=8.5, wall=148550
2023-05-22 11:13:51 - progress_bar.py[line:272] - INFO: epoch 023:    485 / 1732 loss=2.402, loss_v1=0, loss_v2=0, nll_loss=1.203, ntokens=980.2, nsentences=32, sample_size=980.2, sample_size_v1=0, sample_size_v2=0, ppl=2.3, wps=259.5, ups=0.26, wpb=980.2, bsz=32, num_updates=38520, lr=2.75167e-06, gnorm=19.613, clip=100, loss_scale=32, train_wall=38, gb_free=8.4, wall=148588
2023-05-22 11:14:29 - progress_bar.py[line:272] - INFO: epoch 023:    495 / 1732 loss=2.404, loss_v1=0, loss_v2=0, nll_loss=1.205, ntokens=928.7, nsentences=32, sample_size=928.7, sample_size_v1=0, sample_size_v2=0, ppl=2.31, wps=246.6, ups=0.27, wpb=928.7, bsz=32, num_updates=38530, lr=2.74963e-06, gnorm=20.54, clip=100, loss_scale=32, train_wall=38, gb_free=9.3, wall=148626
2023-05-22 11:15:06 - progress_bar.py[line:272] - INFO: epoch 023:    505 / 1732 loss=2.422, loss_v1=0, loss_v2=0, nll_loss=1.224, ntokens=974.8, nsentences=32, sample_size=974.8, sample_size_v1=0, sample_size_v2=0, ppl=2.34, wps=259.9, ups=0.27, wpb=974.8, bsz=32, num_updates=38540, lr=2.74758e-06, gnorm=20.446, clip=100, loss_scale=32, train_wall=37, gb_free=8.7, wall=148663
2023-05-22 11:15:44 - progress_bar.py[line:272] - INFO: epoch 023:    515 / 1732 loss=2.421, loss_v1=0, loss_v2=0, nll_loss=1.224, ntokens=1073.1, nsentences=32, sample_size=1073.1, sample_size_v1=0, sample_size_v2=0, ppl=2.34, wps=281.9, ups=0.26, wpb=1073.1, bsz=32, num_updates=38550, lr=2.74553e-06, gnorm=16.707, clip=100, loss_scale=32, train_wall=38, gb_free=8.4, wall=148701
2023-05-22 11:16:22 - progress_bar.py[line:272] - INFO: epoch 023:    525 / 1732 loss=2.41, loss_v1=0, loss_v2=0, nll_loss=1.211, ntokens=955.6, nsentences=32, sample_size=955.6, sample_size_v1=0, sample_size_v2=0, ppl=2.32, wps=253.3, ups=0.27, wpb=955.6, bsz=32, num_updates=38560, lr=2.74348e-06, gnorm=21.871, clip=100, loss_scale=32, train_wall=38, gb_free=8.9, wall=148739
2023-05-22 11:17:00 - progress_bar.py[line:272] - INFO: epoch 023:    535 / 1732 loss=2.405, loss_v1=0, loss_v2=0, nll_loss=1.206, ntokens=948.7, nsentences=32, sample_size=948.7, sample_size_v1=0, sample_size_v2=0, ppl=2.31, wps=252.2, ups=0.27, wpb=948.7, bsz=32, num_updates=38570, lr=2.74144e-06, gnorm=20.975, clip=100, loss_scale=32, train_wall=38, gb_free=8.5, wall=148777
2023-05-22 11:17:37 - progress_bar.py[line:272] - INFO: epoch 023:    545 / 1732 loss=2.418, loss_v1=0, loss_v2=0, nll_loss=1.221, ntokens=1010, nsentences=32, sample_size=1010, sample_size_v1=0, sample_size_v2=0, ppl=2.33, wps=267.7, ups=0.27, wpb=1010, bsz=32, num_updates=38580, lr=2.73939e-06, gnorm=19.111, clip=100, loss_scale=32, train_wall=38, gb_free=8.3, wall=148814
2023-05-22 11:18:15 - progress_bar.py[line:272] - INFO: epoch 023:    555 / 1732 loss=2.45, loss_v1=0, loss_v2=0, nll_loss=1.254, ntokens=1039.8, nsentences=32, sample_size=1039.8, sample_size_v1=0, sample_size_v2=0, ppl=2.39, wps=275.1, ups=0.26, wpb=1039.8, bsz=32, num_updates=38590, lr=2.73734e-06, gnorm=19.044, clip=100, loss_scale=32, train_wall=38, gb_free=8.6, wall=148852
2023-05-22 11:18:53 - progress_bar.py[line:272] - INFO: epoch 023:    565 / 1732 loss=2.431, loss_v1=0, loss_v2=0, nll_loss=1.235, ntokens=1014, nsentences=32, sample_size=1014, sample_size_v1=0, sample_size_v2=0, ppl=2.35, wps=266.4, ups=0.26, wpb=1014, bsz=32, num_updates=38600, lr=2.73529e-06, gnorm=20.345, clip=100, loss_scale=32, train_wall=38, gb_free=8.5, wall=148890
2023-05-22 11:19:31 - progress_bar.py[line:272] - INFO: epoch 023:    575 / 1732 loss=2.424, loss_v1=0, loss_v2=0, nll_loss=1.227, ntokens=1007.3, nsentences=32, sample_size=1007.3, sample_size_v1=0, sample_size_v2=0, ppl=2.34, wps=265, ups=0.26, wpb=1007.3, bsz=32, num_updates=38610, lr=2.73325e-06, gnorm=20.819, clip=100, loss_scale=32, train_wall=38, gb_free=8.8, wall=148928
2023-05-22 11:20:09 - progress_bar.py[line:272] - INFO: epoch 023:    585 / 1732 loss=2.436, loss_v1=0, loss_v2=0, nll_loss=1.241, ntokens=980.6, nsentences=32, sample_size=980.6, sample_size_v1=0, sample_size_v2=0, ppl=2.36, wps=257.7, ups=0.26, wpb=980.6, bsz=32, num_updates=38620, lr=2.7312e-06, gnorm=20.937, clip=100, loss_scale=32, train_wall=38, gb_free=8.8, wall=148966
2023-05-22 11:20:47 - progress_bar.py[line:272] - INFO: epoch 023:    595 / 1732 loss=2.385, loss_v1=0, loss_v2=0, nll_loss=1.183, ntokens=961.9, nsentences=32, sample_size=961.9, sample_size_v1=0, sample_size_v2=0, ppl=2.27, wps=253.1, ups=0.26, wpb=961.9, bsz=32, num_updates=38630, lr=2.72915e-06, gnorm=20.056, clip=100, loss_scale=32, train_wall=38, gb_free=8.8, wall=149004
2023-05-22 11:21:25 - progress_bar.py[line:272] - INFO: epoch 023:    605 / 1732 loss=2.393, loss_v1=0, loss_v2=0, nll_loss=1.194, ntokens=879.8, nsentences=32, sample_size=879.8, sample_size_v1=0, sample_size_v2=0, ppl=2.29, wps=234.4, ups=0.27, wpb=879.8, bsz=32, num_updates=38640, lr=2.72711e-06, gnorm=20.447, clip=100, loss_scale=32, train_wall=37, gb_free=9.3, wall=149042
2023-05-22 11:21:47 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2023-05-22 11:22:06 - progress_bar.py[line:272] - INFO: epoch 023:    616 / 1732 loss=2.421, loss_v1=0, loss_v2=0, nll_loss=1.226, ntokens=887, nsentences=32, sample_size=887, sample_size_v1=0, sample_size_v2=0, ppl=2.34, wps=214.1, ups=0.24, wpb=887, bsz=32, num_updates=38650, lr=2.72506e-06, gnorm=22.068, clip=100, loss_scale=32, train_wall=41, gb_free=9.4, wall=149083
2023-05-22 11:22:44 - progress_bar.py[line:272] - INFO: epoch 023:    626 / 1732 loss=2.42, loss_v1=0, loss_v2=0, nll_loss=1.225, ntokens=922.9, nsentences=32, sample_size=922.9, sample_size_v1=0, sample_size_v2=0, ppl=2.34, wps=245.5, ups=0.27, wpb=922.9, bsz=32, num_updates=38660, lr=2.72301e-06, gnorm=22.937, clip=100, loss_scale=32, train_wall=38, gb_free=8.9, wall=149121
2023-05-22 11:23:21 - progress_bar.py[line:272] - INFO: epoch 023:    636 / 1732 loss=2.43, loss_v1=0, loss_v2=0, nll_loss=1.235, ntokens=899.7, nsentences=32, sample_size=899.7, sample_size_v1=0, sample_size_v2=0, ppl=2.35, wps=238.8, ups=0.27, wpb=899.7, bsz=32, num_updates=38670, lr=2.72096e-06, gnorm=22.833, clip=100, loss_scale=32, train_wall=38, gb_free=8.6, wall=149159
2023-05-22 11:23:59 - progress_bar.py[line:272] - INFO: epoch 023:    646 / 1732 loss=2.423, loss_v1=0, loss_v2=0, nll_loss=1.227, ntokens=1003.9, nsentences=32, sample_size=1003.9, sample_size_v1=0, sample_size_v2=0, ppl=2.34, wps=265.8, ups=0.26, wpb=1003.9, bsz=32, num_updates=38680, lr=2.71892e-06, gnorm=21.189, clip=100, loss_scale=32, train_wall=38, gb_free=9.3, wall=149196
2023-05-22 11:24:37 - progress_bar.py[line:272] - INFO: epoch 023:    656 / 1732 loss=2.428, loss_v1=0, loss_v2=0, nll_loss=1.232, ntokens=882.2, nsentences=32, sample_size=882.2, sample_size_v1=0, sample_size_v2=0, ppl=2.35, wps=234.3, ups=0.27, wpb=882.2, bsz=32, num_updates=38690, lr=2.71687e-06, gnorm=22.206, clip=100, loss_scale=32, train_wall=38, gb_free=9.2, wall=149234
2023-05-22 11:25:14 - progress_bar.py[line:272] - INFO: epoch 023:    666 / 1732 loss=2.423, loss_v1=0, loss_v2=0, nll_loss=1.226, ntokens=902.8, nsentences=32, sample_size=902.8, sample_size_v1=0, sample_size_v2=0, ppl=2.34, wps=240.9, ups=0.27, wpb=902.8, bsz=32, num_updates=38700, lr=2.71482e-06, gnorm=21.332, clip=100, loss_scale=32, train_wall=37, gb_free=8.4, wall=149272
2023-05-22 11:25:52 - progress_bar.py[line:272] - INFO: epoch 023:    676 / 1732 loss=2.428, loss_v1=0, loss_v2=0, nll_loss=1.231, ntokens=976.1, nsentences=32, sample_size=976.1, sample_size_v1=0, sample_size_v2=0, ppl=2.35, wps=258.4, ups=0.26, wpb=976.1, bsz=32, num_updates=38710, lr=2.71277e-06, gnorm=20.476, clip=100, loss_scale=32, train_wall=38, gb_free=8.6, wall=149309
2023-05-22 11:26:30 - progress_bar.py[line:272] - INFO: epoch 023:    686 / 1732 loss=2.418, loss_v1=0, loss_v2=0, nll_loss=1.221, ntokens=963.6, nsentences=32, sample_size=963.6, sample_size_v1=0, sample_size_v2=0, ppl=2.33, wps=254.9, ups=0.26, wpb=963.6, bsz=32, num_updates=38720, lr=2.71073e-06, gnorm=21.253, clip=100, loss_scale=32, train_wall=38, gb_free=8.4, wall=149347
2023-05-22 11:27:08 - progress_bar.py[line:272] - INFO: epoch 023:    696 / 1732 loss=2.431, loss_v1=0, loss_v2=0, nll_loss=1.234, ntokens=982.5, nsentences=32, sample_size=982.5, sample_size_v1=0, sample_size_v2=0, ppl=2.35, wps=259.3, ups=0.26, wpb=982.5, bsz=32, num_updates=38730, lr=2.70868e-06, gnorm=20.286, clip=100, loss_scale=32, train_wall=38, gb_free=8.9, wall=149385
2023-05-22 11:27:46 - progress_bar.py[line:272] - INFO: epoch 023:    706 / 1732 loss=2.404, loss_v1=0, loss_v2=0, nll_loss=1.204, ntokens=918.4, nsentences=32, sample_size=918.4, sample_size_v1=0, sample_size_v2=0, ppl=2.3, wps=243.8, ups=0.27, wpb=918.4, bsz=32, num_updates=38740, lr=2.70663e-06, gnorm=21.852, clip=100, loss_scale=32, train_wall=38, gb_free=9.1, wall=149423
2023-05-22 11:28:23 - progress_bar.py[line:272] - INFO: epoch 023:    716 / 1732 loss=2.422, loss_v1=0, loss_v2=0, nll_loss=1.225, ntokens=886.1, nsentences=32, sample_size=886.1, sample_size_v1=0, sample_size_v2=0, ppl=2.34, wps=236.1, ups=0.27, wpb=886.1, bsz=32, num_updates=38750, lr=2.70458e-06, gnorm=20.875, clip=100, loss_scale=32, train_wall=37, gb_free=8.9, wall=149460
2023-05-22 11:29:01 - progress_bar.py[line:272] - INFO: epoch 023:    726 / 1732 loss=2.388, loss_v1=0, loss_v2=0, nll_loss=1.187, ntokens=913.6, nsentences=32, sample_size=913.6, sample_size_v1=0, sample_size_v2=0, ppl=2.28, wps=243.6, ups=0.27, wpb=913.6, bsz=32, num_updates=38760, lr=2.70254e-06, gnorm=21.044, clip=100, loss_scale=32, train_wall=37, gb_free=8.2, wall=149498
2023-05-22 11:29:38 - progress_bar.py[line:272] - INFO: epoch 023:    736 / 1732 loss=2.404, loss_v1=0, loss_v2=0, nll_loss=1.204, ntokens=979.7, nsentences=32, sample_size=979.7, sample_size_v1=0, sample_size_v2=0, ppl=2.3, wps=259.9, ups=0.27, wpb=979.7, bsz=32, num_updates=38770, lr=2.70049e-06, gnorm=18.897, clip=100, loss_scale=32, train_wall=38, gb_free=9, wall=149535
2023-05-22 11:30:16 - progress_bar.py[line:272] - INFO: epoch 023:    746 / 1732 loss=2.394, loss_v1=0, loss_v2=0, nll_loss=1.194, ntokens=974.7, nsentences=32, sample_size=974.7, sample_size_v1=0, sample_size_v2=0, ppl=2.29, wps=257.8, ups=0.26, wpb=974.7, bsz=32, num_updates=38780, lr=2.69844e-06, gnorm=20.44, clip=100, loss_scale=32, train_wall=38, gb_free=8.7, wall=149573
2023-05-22 11:30:54 - progress_bar.py[line:272] - INFO: epoch 023:    756 / 1732 loss=2.403, loss_v1=0, loss_v2=0, nll_loss=1.203, ntokens=977.2, nsentences=32, sample_size=977.2, sample_size_v1=0, sample_size_v2=0, ppl=2.3, wps=258.6, ups=0.26, wpb=977.2, bsz=32, num_updates=38790, lr=2.69639e-06, gnorm=19.454, clip=100, loss_scale=32, train_wall=38, gb_free=8.4, wall=149611
2023-05-22 11:31:31 - progress_bar.py[line:272] - INFO: epoch 023:    766 / 1732 loss=2.399, loss_v1=0, loss_v2=0, nll_loss=1.2, ntokens=933.3, nsentences=32, sample_size=933.3, sample_size_v1=0, sample_size_v2=0, ppl=2.3, wps=248.2, ups=0.27, wpb=933.3, bsz=32, num_updates=38800, lr=2.69435e-06, gnorm=19.56, clip=100, loss_scale=32, train_wall=38, gb_free=8.8, wall=149649
2023-05-22 11:31:54 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2023-05-22 11:32:13 - progress_bar.py[line:272] - INFO: epoch 023:    777 / 1732 loss=2.419, loss_v1=0, loss_v2=0, nll_loss=1.222, ntokens=995.3, nsentences=32, sample_size=995.3, sample_size_v1=0, sample_size_v2=0, ppl=2.33, wps=240.4, ups=0.24, wpb=995.3, bsz=32, num_updates=38810, lr=2.6923e-06, gnorm=21.016, clip=100, loss_scale=16, train_wall=41, gb_free=8.8, wall=149690
2023-05-22 11:32:51 - progress_bar.py[line:272] - INFO: epoch 023:    787 / 1732 loss=2.407, loss_v1=0, loss_v2=0, nll_loss=1.208, ntokens=1016.6, nsentences=32, sample_size=1016.6, sample_size_v1=0, sample_size_v2=0, ppl=2.31, wps=269.3, ups=0.26, wpb=1016.6, bsz=32, num_updates=38820, lr=2.69025e-06, gnorm=18.809, clip=100, loss_scale=16, train_wall=38, gb_free=8.5, wall=149728
2023-05-22 11:33:28 - progress_bar.py[line:272] - INFO: epoch 023:    797 / 1732 loss=2.403, loss_v1=0, loss_v2=0, nll_loss=1.204, ntokens=1038, nsentences=32, sample_size=1038, sample_size_v1=0, sample_size_v2=0, ppl=2.3, wps=274.2, ups=0.26, wpb=1038, bsz=32, num_updates=38830, lr=2.68821e-06, gnorm=18.267, clip=100, loss_scale=16, train_wall=38, gb_free=8.8, wall=149766
2023-05-22 11:34:06 - progress_bar.py[line:272] - INFO: epoch 023:    807 / 1732 loss=2.408, loss_v1=0, loss_v2=0, nll_loss=1.21, ntokens=915, nsentences=32, sample_size=915, sample_size_v1=0, sample_size_v2=0, ppl=2.31, wps=241.9, ups=0.26, wpb=915, bsz=32, num_updates=38840, lr=2.68616e-06, gnorm=21.842, clip=100, loss_scale=16, train_wall=38, gb_free=8.7, wall=149803
2023-05-22 11:34:44 - progress_bar.py[line:272] - INFO: epoch 023:    817 / 1732 loss=2.424, loss_v1=0, loss_v2=0, nll_loss=1.228, ntokens=917.4, nsentences=32, sample_size=917.4, sample_size_v1=0, sample_size_v2=0, ppl=2.34, wps=243.7, ups=0.27, wpb=917.4, bsz=32, num_updates=38850, lr=2.68411e-06, gnorm=20.79, clip=100, loss_scale=16, train_wall=38, gb_free=8.9, wall=149841
2023-05-22 11:35:22 - progress_bar.py[line:272] - INFO: epoch 023:    827 / 1732 loss=2.408, loss_v1=0, loss_v2=0, nll_loss=1.209, ntokens=930.6, nsentences=32, sample_size=930.6, sample_size_v1=0, sample_size_v2=0, ppl=2.31, wps=246.7, ups=0.27, wpb=930.6, bsz=32, num_updates=38860, lr=2.68206e-06, gnorm=19.703, clip=100, loss_scale=16, train_wall=38, gb_free=8.9, wall=149879
2023-05-22 11:35:59 - progress_bar.py[line:272] - INFO: epoch 023:    837 / 1732 loss=2.415, loss_v1=0, loss_v2=0, nll_loss=1.219, ntokens=894.5, nsentences=32, sample_size=894.5, sample_size_v1=0, sample_size_v2=0, ppl=2.33, wps=239, ups=0.27, wpb=894.5, bsz=32, num_updates=38870, lr=2.68002e-06, gnorm=20.826, clip=100, loss_scale=16, train_wall=37, gb_free=9.1, wall=149916
2023-05-22 11:36:37 - progress_bar.py[line:272] - INFO: epoch 023:    847 / 1732 loss=2.387, loss_v1=0, loss_v2=0, nll_loss=1.186, ntokens=1012.6, nsentences=32, sample_size=1012.6, sample_size_v1=0, sample_size_v2=0, ppl=2.28, wps=268.2, ups=0.26, wpb=1012.6, bsz=32, num_updates=38880, lr=2.67797e-06, gnorm=20.605, clip=100, loss_scale=16, train_wall=38, gb_free=7.7, wall=149954
2023-05-22 11:37:14 - progress_bar.py[line:272] - INFO: epoch 023:    857 / 1732 loss=2.41, loss_v1=0, loss_v2=0, nll_loss=1.212, ntokens=920, nsentences=32, sample_size=920, sample_size_v1=0, sample_size_v2=0, ppl=2.32, wps=245, ups=0.27, wpb=920, bsz=32, num_updates=38890, lr=2.67592e-06, gnorm=22.211, clip=100, loss_scale=16, train_wall=38, gb_free=8.6, wall=149992
2023-05-22 11:37:52 - progress_bar.py[line:272] - INFO: epoch 023:    867 / 1732 loss=2.416, loss_v1=0, loss_v2=0, nll_loss=1.218, ntokens=979.9, nsentences=32, sample_size=979.9, sample_size_v1=0, sample_size_v2=0, ppl=2.33, wps=259.2, ups=0.26, wpb=979.9, bsz=32, num_updates=38900, lr=2.67387e-06, gnorm=20.403, clip=100, loss_scale=16, train_wall=38, gb_free=8.6, wall=150029
2023-05-22 11:38:30 - progress_bar.py[line:272] - INFO: epoch 023:    877 / 1732 loss=2.344, loss_v1=0, loss_v2=0, nll_loss=1.138, ntokens=994.5, nsentences=32, sample_size=994.5, sample_size_v1=0, sample_size_v2=0, ppl=2.2, wps=261.5, ups=0.26, wpb=994.5, bsz=32, num_updates=38910, lr=2.67183e-06, gnorm=17.607, clip=100, loss_scale=16, train_wall=38, gb_free=8.9, wall=150067
2023-05-22 11:39:08 - progress_bar.py[line:272] - INFO: epoch 023:    887 / 1732 loss=2.367, loss_v1=0, loss_v2=0, nll_loss=1.164, ntokens=982, nsentences=32, sample_size=982, sample_size_v1=0, sample_size_v2=0, ppl=2.24, wps=258.6, ups=0.26, wpb=982, bsz=32, num_updates=38920, lr=2.66978e-06, gnorm=19.229, clip=100, loss_scale=16, train_wall=38, gb_free=8.3, wall=150105
2023-05-22 11:39:46 - progress_bar.py[line:272] - INFO: epoch 023:    897 / 1732 loss=2.348, loss_v1=0, loss_v2=0, nll_loss=1.143, ntokens=1034.6, nsentences=32, sample_size=1034.6, sample_size_v1=0, sample_size_v2=0, ppl=2.21, wps=272.6, ups=0.26, wpb=1034.6, bsz=32, num_updates=38930, lr=2.66773e-06, gnorm=18.478, clip=100, loss_scale=16, train_wall=38, gb_free=8.6, wall=150143
2023-05-22 11:40:24 - progress_bar.py[line:272] - INFO: epoch 023:    907 / 1732 loss=2.361, loss_v1=0, loss_v2=0, nll_loss=1.157, ntokens=1016.8, nsentences=32, sample_size=1016.8, sample_size_v1=0, sample_size_v2=0, ppl=2.23, wps=267.7, ups=0.26, wpb=1016.8, bsz=32, num_updates=38940, lr=2.66568e-06, gnorm=19.519, clip=100, loss_scale=16, train_wall=38, gb_free=8.9, wall=150181
2023-05-22 11:41:02 - progress_bar.py[line:272] - INFO: epoch 023:    917 / 1732 loss=2.438, loss_v1=0, loss_v2=0, nll_loss=1.244, ntokens=936.4, nsentences=32, sample_size=936.4, sample_size_v1=0, sample_size_v2=0, ppl=2.37, wps=247.9, ups=0.26, wpb=936.4, bsz=32, num_updates=38950, lr=2.66364e-06, gnorm=21.425, clip=100, loss_scale=16, train_wall=38, gb_free=9.2, wall=150219
2023-05-22 11:41:40 - progress_bar.py[line:272] - INFO: epoch 023:    927 / 1732 loss=2.366, loss_v1=0, loss_v2=0, nll_loss=1.164, ntokens=1039.7, nsentences=32, sample_size=1039.7, sample_size_v1=0, sample_size_v2=0, ppl=2.24, wps=271.7, ups=0.26, wpb=1039.7, bsz=32, num_updates=38960, lr=2.66159e-06, gnorm=19.869, clip=100, loss_scale=16, train_wall=38, gb_free=8.7, wall=150257
2023-05-22 11:42:19 - progress_bar.py[line:272] - INFO: epoch 023:    937 / 1732 loss=2.377, loss_v1=0, loss_v2=0, nll_loss=1.174, ntokens=1061.1, nsentences=32, sample_size=1061.1, sample_size_v1=0, sample_size_v2=0, ppl=2.26, wps=276.1, ups=0.26, wpb=1061.1, bsz=32, num_updates=38970, lr=2.65954e-06, gnorm=18.289, clip=100, loss_scale=16, train_wall=38, gb_free=8.3, wall=150296
2023-05-22 11:42:57 - progress_bar.py[line:272] - INFO: epoch 023:    947 / 1732 loss=2.391, loss_v1=0, loss_v2=0, nll_loss=1.188, ntokens=1042.4, nsentences=32, sample_size=1042.4, sample_size_v1=0, sample_size_v2=0, ppl=2.28, wps=270, ups=0.26, wpb=1042.4, bsz=32, num_updates=38980, lr=2.65749e-06, gnorm=18.522, clip=100, loss_scale=16, train_wall=39, gb_free=8.6, wall=150334
2023-05-22 11:43:36 - progress_bar.py[line:272] - INFO: epoch 023:    957 / 1732 loss=2.385, loss_v1=0, loss_v2=0, nll_loss=1.184, ntokens=1046.8, nsentences=32, sample_size=1046.8, sample_size_v1=0, sample_size_v2=0, ppl=2.27, wps=272.9, ups=0.26, wpb=1046.8, bsz=32, num_updates=38990, lr=2.65545e-06, gnorm=18.217, clip=100, loss_scale=16, train_wall=38, gb_free=8.2, wall=150373
2023-05-22 11:44:14 - progress_bar.py[line:272] - INFO: epoch 023:    967 / 1732 loss=2.39, loss_v1=0, loss_v2=0, nll_loss=1.189, ntokens=1036.4, nsentences=32, sample_size=1036.4, sample_size_v1=0, sample_size_v2=0, ppl=2.28, wps=270.5, ups=0.26, wpb=1036.4, bsz=32, num_updates=39000, lr=2.6534e-06, gnorm=19.711, clip=100, loss_scale=16, train_wall=38, gb_free=8.6, wall=150411
2023-05-22 11:44:52 - progress_bar.py[line:272] - INFO: epoch 023:    977 / 1732 loss=2.395, loss_v1=0, loss_v2=0, nll_loss=1.196, ntokens=1035.2, nsentences=32, sample_size=1035.2, sample_size_v1=0, sample_size_v2=0, ppl=2.29, wps=269.6, ups=0.26, wpb=1035.2, bsz=32, num_updates=39010, lr=2.65135e-06, gnorm=17.069, clip=100, loss_scale=16, train_wall=38, gb_free=8.1, wall=150450
2023-05-22 11:45:31 - progress_bar.py[line:272] - INFO: epoch 023:    987 / 1732 loss=2.388, loss_v1=0, loss_v2=0, nll_loss=1.186, ntokens=1020.1, nsentences=32, sample_size=1020.1, sample_size_v1=0, sample_size_v2=0, ppl=2.28, wps=265.8, ups=0.26, wpb=1020.1, bsz=32, num_updates=39020, lr=2.6493e-06, gnorm=19.923, clip=100, loss_scale=16, train_wall=38, gb_free=8.5, wall=150488
2023-05-22 11:46:09 - progress_bar.py[line:272] - INFO: epoch 023:    997 / 1732 loss=2.377, loss_v1=0, loss_v2=0, nll_loss=1.175, ntokens=1032.4, nsentences=32, sample_size=1032.4, sample_size_v1=0, sample_size_v2=0, ppl=2.26, wps=270.2, ups=0.26, wpb=1032.4, bsz=32, num_updates=39030, lr=2.64726e-06, gnorm=18.527, clip=100, loss_scale=16, train_wall=38, gb_free=8.9, wall=150526
2023-05-22 11:46:47 - progress_bar.py[line:272] - INFO: epoch 023:   1007 / 1732 loss=2.37, loss_v1=0, loss_v2=0, nll_loss=1.168, ntokens=1018.9, nsentences=32, sample_size=1018.9, sample_size_v1=0, sample_size_v2=0, ppl=2.25, wps=267.7, ups=0.26, wpb=1018.9, bsz=32, num_updates=39040, lr=2.64521e-06, gnorm=17.789, clip=100, loss_scale=16, train_wall=38, gb_free=8.6, wall=150564
2023-05-22 11:47:25 - progress_bar.py[line:272] - INFO: epoch 023:   1017 / 1732 loss=2.366, loss_v1=0, loss_v2=0, nll_loss=1.163, ntokens=1024.8, nsentences=32, sample_size=1024.8, sample_size_v1=0, sample_size_v2=0, ppl=2.24, wps=268.5, ups=0.26, wpb=1024.8, bsz=32, num_updates=39050, lr=2.64316e-06, gnorm=18.581, clip=100, loss_scale=16, train_wall=38, gb_free=7.6, wall=150602
2023-05-22 11:48:04 - progress_bar.py[line:272] - INFO: epoch 023:   1027 / 1732 loss=2.401, loss_v1=0, loss_v2=0, nll_loss=1.203, ntokens=1051.5, nsentences=32, sample_size=1051.5, sample_size_v1=0, sample_size_v2=0, ppl=2.3, wps=272.4, ups=0.26, wpb=1051.5, bsz=32, num_updates=39060, lr=2.64112e-06, gnorm=18.287, clip=100, loss_scale=16, train_wall=39, gb_free=8.6, wall=150641
2023-05-22 11:48:42 - progress_bar.py[line:272] - INFO: epoch 023:   1037 / 1732 loss=2.368, loss_v1=0, loss_v2=0, nll_loss=1.166, ntokens=1129.2, nsentences=32, sample_size=1129.2, sample_size_v1=0, sample_size_v2=0, ppl=2.24, wps=292.8, ups=0.26, wpb=1129.2, bsz=32, num_updates=39070, lr=2.63907e-06, gnorm=17.451, clip=100, loss_scale=16, train_wall=39, gb_free=8.7, wall=150680
2023-05-22 11:49:21 - progress_bar.py[line:272] - INFO: epoch 023:   1047 / 1732 loss=2.371, loss_v1=0, loss_v2=0, nll_loss=1.169, ntokens=1024.6, nsentences=32, sample_size=1024.6, sample_size_v1=0, sample_size_v2=0, ppl=2.25, wps=267.7, ups=0.26, wpb=1024.6, bsz=32, num_updates=39080, lr=2.63702e-06, gnorm=18.512, clip=100, loss_scale=16, train_wall=38, gb_free=8.6, wall=150718
2023-05-22 11:49:59 - progress_bar.py[line:272] - INFO: epoch 023:   1057 / 1732 loss=2.38, loss_v1=0, loss_v2=0, nll_loss=1.179, ntokens=1089.7, nsentences=32, sample_size=1089.7, sample_size_v1=0, sample_size_v2=0, ppl=2.26, wps=283.3, ups=0.26, wpb=1089.7, bsz=32, num_updates=39090, lr=2.63497e-06, gnorm=19.012, clip=100, loss_scale=16, train_wall=38, gb_free=7.5, wall=150756
2023-05-22 11:50:37 - progress_bar.py[line:272] - INFO: epoch 023:   1067 / 1732 loss=2.383, loss_v1=0, loss_v2=0, nll_loss=1.182, ntokens=1006.5, nsentences=32, sample_size=1006.5, sample_size_v1=0, sample_size_v2=0, ppl=2.27, wps=263.7, ups=0.26, wpb=1006.5, bsz=32, num_updates=39100, lr=2.63293e-06, gnorm=19.128, clip=100, loss_scale=16, train_wall=38, gb_free=8.5, wall=150794
2023-05-22 11:51:16 - progress_bar.py[line:272] - INFO: epoch 023:   1077 / 1732 loss=2.41, loss_v1=0, loss_v2=0, nll_loss=1.211, ntokens=990.3, nsentences=32, sample_size=990.3, sample_size_v1=0, sample_size_v2=0, ppl=2.31, wps=257, ups=0.26, wpb=990.3, bsz=32, num_updates=39110, lr=2.63088e-06, gnorm=20.033, clip=100, loss_scale=16, train_wall=38, gb_free=9, wall=150833
2023-05-22 11:51:54 - progress_bar.py[line:272] - INFO: epoch 023:   1087 / 1732 loss=2.381, loss_v1=0, loss_v2=0, nll_loss=1.181, ntokens=1071.1, nsentences=32, sample_size=1071.1, sample_size_v1=0, sample_size_v2=0, ppl=2.27, wps=278.8, ups=0.26, wpb=1071.1, bsz=32, num_updates=39120, lr=2.62883e-06, gnorm=18.661, clip=100, loss_scale=16, train_wall=38, gb_free=8.8, wall=150871
2023-05-22 11:52:33 - progress_bar.py[line:272] - INFO: epoch 023:   1097 / 1732 loss=2.386, loss_v1=0, loss_v2=0, nll_loss=1.186, ntokens=1042.6, nsentences=32, sample_size=1042.6, sample_size_v1=0, sample_size_v2=0, ppl=2.27, wps=270.8, ups=0.26, wpb=1042.6, bsz=32, num_updates=39130, lr=2.62678e-06, gnorm=20.226, clip=100, loss_scale=16, train_wall=38, gb_free=8.9, wall=150910
2023-05-22 11:53:11 - progress_bar.py[line:272] - INFO: epoch 023:   1107 / 1732 loss=2.377, loss_v1=0, loss_v2=0, nll_loss=1.175, ntokens=1075.5, nsentences=32, sample_size=1075.5, sample_size_v1=0, sample_size_v2=0, ppl=2.26, wps=279.4, ups=0.26, wpb=1075.5, bsz=32, num_updates=39140, lr=2.62474e-06, gnorm=18.683, clip=100, loss_scale=16, train_wall=38, gb_free=8.1, wall=150948
2023-05-22 11:53:49 - progress_bar.py[line:272] - INFO: epoch 023:   1117 / 1732 loss=2.392, loss_v1=0, loss_v2=0, nll_loss=1.191, ntokens=943.9, nsentences=32, sample_size=943.9, sample_size_v1=0, sample_size_v2=0, ppl=2.28, wps=246.8, ups=0.26, wpb=943.9, bsz=32, num_updates=39150, lr=2.62269e-06, gnorm=20.451, clip=100, loss_scale=16, train_wall=38, gb_free=8.7, wall=150987
2023-05-22 11:54:28 - progress_bar.py[line:272] - INFO: epoch 023:   1127 / 1732 loss=2.382, loss_v1=0, loss_v2=0, nll_loss=1.18, ntokens=1022.2, nsentences=32, sample_size=1022.2, sample_size_v1=0, sample_size_v2=0, ppl=2.27, wps=265.7, ups=0.26, wpb=1022.2, bsz=32, num_updates=39160, lr=2.62064e-06, gnorm=19.122, clip=100, loss_scale=16, train_wall=38, gb_free=7.9, wall=151025
2023-05-22 11:55:06 - progress_bar.py[line:272] - INFO: epoch 023:   1137 / 1732 loss=2.391, loss_v1=0, loss_v2=0, nll_loss=1.189, ntokens=987.1, nsentences=32, sample_size=987.1, sample_size_v1=0, sample_size_v2=0, ppl=2.28, wps=257.9, ups=0.26, wpb=987.1, bsz=32, num_updates=39170, lr=2.61859e-06, gnorm=18.587, clip=100, loss_scale=16, train_wall=38, gb_free=8, wall=151063
2023-05-22 11:55:44 - progress_bar.py[line:272] - INFO: epoch 023:   1147 / 1732 loss=2.395, loss_v1=0, loss_v2=0, nll_loss=1.196, ntokens=1007.7, nsentences=32, sample_size=1007.7, sample_size_v1=0, sample_size_v2=0, ppl=2.29, wps=263.2, ups=0.26, wpb=1007.7, bsz=32, num_updates=39180, lr=2.61655e-06, gnorm=19.232, clip=100, loss_scale=16, train_wall=38, gb_free=8.4, wall=151102
2023-05-22 11:56:23 - progress_bar.py[line:272] - INFO: epoch 023:   1157 / 1732 loss=2.364, loss_v1=0, loss_v2=0, nll_loss=1.162, ntokens=1000.6, nsentences=32, sample_size=1000.6, sample_size_v1=0, sample_size_v2=0, ppl=2.24, wps=261.5, ups=0.26, wpb=1000.6, bsz=32, num_updates=39190, lr=2.6145e-06, gnorm=18.773, clip=100, loss_scale=16, train_wall=38, gb_free=8.9, wall=151140
2023-05-22 11:57:01 - progress_bar.py[line:272] - INFO: epoch 023:   1167 / 1732 loss=2.387, loss_v1=0, loss_v2=0, nll_loss=1.186, ntokens=1036.7, nsentences=32, sample_size=1036.7, sample_size_v1=0, sample_size_v2=0, ppl=2.28, wps=269.6, ups=0.26, wpb=1036.7, bsz=32, num_updates=39200, lr=2.61245e-06, gnorm=19.063, clip=100, loss_scale=16, train_wall=38, gb_free=8.6, wall=151178
2023-05-22 11:57:40 - progress_bar.py[line:272] - INFO: epoch 023:   1177 / 1732 loss=2.358, loss_v1=0, loss_v2=0, nll_loss=1.155, ntokens=1069.6, nsentences=32, sample_size=1069.6, sample_size_v1=0, sample_size_v2=0, ppl=2.23, wps=278.9, ups=0.26, wpb=1069.6, bsz=32, num_updates=39210, lr=2.6104e-06, gnorm=17.827, clip=100, loss_scale=16, train_wall=38, gb_free=9, wall=151217
2023-05-22 11:58:18 - progress_bar.py[line:272] - INFO: epoch 023:   1187 / 1732 loss=2.385, loss_v1=0, loss_v2=0, nll_loss=1.184, ntokens=953.6, nsentences=32, sample_size=953.6, sample_size_v1=0, sample_size_v2=0, ppl=2.27, wps=249.5, ups=0.26, wpb=953.6, bsz=32, num_updates=39220, lr=2.60836e-06, gnorm=21.068, clip=100, loss_scale=16, train_wall=38, gb_free=9.2, wall=151255
2023-05-22 11:58:56 - progress_bar.py[line:272] - INFO: epoch 023:   1197 / 1732 loss=2.379, loss_v1=0, loss_v2=0, nll_loss=1.177, ntokens=1116.1, nsentences=32, sample_size=1116.1, sample_size_v1=0, sample_size_v2=0, ppl=2.26, wps=288.7, ups=0.26, wpb=1116.1, bsz=32, num_updates=39230, lr=2.60631e-06, gnorm=19.13, clip=100, loss_scale=16, train_wall=39, gb_free=7.4, wall=151294
2023-05-22 11:59:35 - progress_bar.py[line:272] - INFO: epoch 023:   1207 / 1732 loss=2.356, loss_v1=0, loss_v2=0, nll_loss=1.151, ntokens=1096.1, nsentences=32, sample_size=1096.1, sample_size_v1=0, sample_size_v2=0, ppl=2.22, wps=282.9, ups=0.26, wpb=1096.1, bsz=32, num_updates=39240, lr=2.60426e-06, gnorm=19.555, clip=100, loss_scale=16, train_wall=39, gb_free=8.3, wall=151332
2023-05-22 12:00:14 - progress_bar.py[line:272] - INFO: epoch 023:   1217 / 1732 loss=2.395, loss_v1=0, loss_v2=0, nll_loss=1.195, ntokens=1014.3, nsentences=32, sample_size=1014.3, sample_size_v1=0, sample_size_v2=0, ppl=2.29, wps=264.7, ups=0.26, wpb=1014.3, bsz=32, num_updates=39250, lr=2.60222e-06, gnorm=21.185, clip=100, loss_scale=16, train_wall=38, gb_free=8.7, wall=151371
2023-05-22 12:00:52 - progress_bar.py[line:272] - INFO: epoch 023:   1227 / 1732 loss=2.399, loss_v1=0, loss_v2=0, nll_loss=1.199, ntokens=1027.4, nsentences=32, sample_size=1027.4, sample_size_v1=0, sample_size_v2=0, ppl=2.3, wps=268.7, ups=0.26, wpb=1027.4, bsz=32, num_updates=39260, lr=2.60017e-06, gnorm=21.957, clip=100, loss_scale=16, train_wall=38, gb_free=9.1, wall=151409
2023-05-22 12:01:30 - progress_bar.py[line:272] - INFO: epoch 023:   1237 / 1732 loss=2.353, loss_v1=0, loss_v2=0, nll_loss=1.147, ntokens=1040.4, nsentences=32, sample_size=1040.4, sample_size_v1=0, sample_size_v2=0, ppl=2.21, wps=271, ups=0.26, wpb=1040.4, bsz=32, num_updates=39270, lr=2.59812e-06, gnorm=20.672, clip=100, loss_scale=16, train_wall=38, gb_free=8.6, wall=151447
2023-05-22 12:02:09 - progress_bar.py[line:272] - INFO: epoch 023:   1247 / 1732 loss=2.329, loss_v1=0, loss_v2=0, nll_loss=1.121, ntokens=1124.4, nsentences=32, sample_size=1124.4, sample_size_v1=0, sample_size_v2=0, ppl=2.17, wps=290.6, ups=0.26, wpb=1124.4, bsz=32, num_updates=39280, lr=2.59607e-06, gnorm=17.965, clip=100, loss_scale=16, train_wall=39, gb_free=8.7, wall=151486
2023-05-22 12:02:47 - progress_bar.py[line:272] - INFO: epoch 023:   1257 / 1732 loss=2.349, loss_v1=0, loss_v2=0, nll_loss=1.145, ntokens=1053.7, nsentences=32, sample_size=1053.7, sample_size_v1=0, sample_size_v2=0, ppl=2.21, wps=275.4, ups=0.26, wpb=1053.7, bsz=32, num_updates=39290, lr=2.59403e-06, gnorm=18.368, clip=100, loss_scale=16, train_wall=38, gb_free=8.7, wall=151524
2023-05-22 12:03:26 - progress_bar.py[line:272] - INFO: epoch 023:   1267 / 1732 loss=2.388, loss_v1=0, loss_v2=0, nll_loss=1.187, ntokens=1037.3, nsentences=32, sample_size=1037.3, sample_size_v1=0, sample_size_v2=0, ppl=2.28, wps=269.4, ups=0.26, wpb=1037.3, bsz=32, num_updates=39300, lr=2.59198e-06, gnorm=18.249, clip=100, loss_scale=16, train_wall=38, gb_free=8.6, wall=151563
2023-05-22 12:04:04 - progress_bar.py[line:272] - INFO: epoch 023:   1277 / 1732 loss=2.389, loss_v1=0, loss_v2=0, nll_loss=1.188, ntokens=1060.8, nsentences=32, sample_size=1060.8, sample_size_v1=0, sample_size_v2=0, ppl=2.28, wps=275.8, ups=0.26, wpb=1060.8, bsz=32, num_updates=39310, lr=2.58993e-06, gnorm=18.955, clip=100, loss_scale=16, train_wall=38, gb_free=7.9, wall=151601
2023-05-22 12:04:43 - progress_bar.py[line:272] - INFO: epoch 023:   1287 / 1732 loss=2.363, loss_v1=0, loss_v2=0, nll_loss=1.16, ntokens=1057.7, nsentences=32, sample_size=1057.7, sample_size_v1=0, sample_size_v2=0, ppl=2.23, wps=274.9, ups=0.26, wpb=1057.7, bsz=32, num_updates=39320, lr=2.58788e-06, gnorm=18.445, clip=100, loss_scale=32, train_wall=38, gb_free=8.2, wall=151640
2023-05-22 12:05:21 - progress_bar.py[line:272] - INFO: epoch 023:   1297 / 1732 loss=2.356, loss_v1=0, loss_v2=0, nll_loss=1.153, ntokens=1105.1, nsentences=32, sample_size=1105.1, sample_size_v1=0, sample_size_v2=0, ppl=2.22, wps=286.7, ups=0.26, wpb=1105.1, bsz=32, num_updates=39330, lr=2.58584e-06, gnorm=17.52, clip=100, loss_scale=32, train_wall=38, gb_free=8.7, wall=151678
2023-05-22 12:06:00 - progress_bar.py[line:272] - INFO: epoch 023:   1307 / 1732 loss=2.395, loss_v1=0, loss_v2=0, nll_loss=1.196, ntokens=1096.7, nsentences=32, sample_size=1096.7, sample_size_v1=0, sample_size_v2=0, ppl=2.29, wps=282.1, ups=0.26, wpb=1096.7, bsz=32, num_updates=39340, lr=2.58379e-06, gnorm=16.639, clip=100, loss_scale=32, train_wall=39, gb_free=8.4, wall=151717
2023-05-22 12:06:39 - progress_bar.py[line:272] - INFO: epoch 023:   1317 / 1732 loss=2.378, loss_v1=0, loss_v2=0, nll_loss=1.176, ntokens=1048.7, nsentences=32, sample_size=1048.7, sample_size_v1=0, sample_size_v2=0, ppl=2.26, wps=271.8, ups=0.26, wpb=1048.7, bsz=32, num_updates=39350, lr=2.58174e-06, gnorm=18.725, clip=100, loss_scale=32, train_wall=39, gb_free=8.7, wall=151756
2023-05-22 12:07:17 - progress_bar.py[line:272] - INFO: epoch 023:   1327 / 1732 loss=2.359, loss_v1=0, loss_v2=0, nll_loss=1.153, ntokens=1124.5, nsentences=32, sample_size=1124.5, sample_size_v1=0, sample_size_v2=0, ppl=2.22, wps=289.4, ups=0.26, wpb=1124.5, bsz=32, num_updates=39360, lr=2.57969e-06, gnorm=19.58, clip=100, loss_scale=32, train_wall=39, gb_free=8.4, wall=151795
2023-05-22 12:07:56 - progress_bar.py[line:272] - INFO: epoch 023:   1337 / 1732 loss=2.349, loss_v1=0, loss_v2=0, nll_loss=1.143, ntokens=1126.2, nsentences=32, sample_size=1126.2, sample_size_v1=0, sample_size_v2=0, ppl=2.21, wps=292.4, ups=0.26, wpb=1126.2, bsz=32, num_updates=39370, lr=2.57765e-06, gnorm=18.323, clip=100, loss_scale=32, train_wall=38, gb_free=8.6, wall=151833
2023-05-22 12:08:35 - progress_bar.py[line:272] - INFO: epoch 023:   1347 / 1732 loss=2.363, loss_v1=0, loss_v2=0, nll_loss=1.159, ntokens=1159.1, nsentences=32, sample_size=1159.1, sample_size_v1=0, sample_size_v2=0, ppl=2.23, wps=298.7, ups=0.26, wpb=1159.1, bsz=32, num_updates=39380, lr=2.5756e-06, gnorm=20.051, clip=100, loss_scale=32, train_wall=39, gb_free=8.9, wall=151872
2023-05-22 12:09:14 - progress_bar.py[line:272] - INFO: epoch 023:   1357 / 1732 loss=2.34, loss_v1=0, loss_v2=0, nll_loss=1.134, ntokens=1146.3, nsentences=32, sample_size=1146.3, sample_size_v1=0, sample_size_v2=0, ppl=2.2, wps=296, ups=0.26, wpb=1146.3, bsz=32, num_updates=39390, lr=2.57355e-06, gnorm=19.59, clip=100, loss_scale=32, train_wall=39, gb_free=8, wall=151911
2023-05-22 12:09:52 - progress_bar.py[line:272] - INFO: epoch 023:   1367 / 1732 loss=2.363, loss_v1=0, loss_v2=0, nll_loss=1.159, ntokens=1081.6, nsentences=32, sample_size=1081.6, sample_size_v1=0, sample_size_v2=0, ppl=2.23, wps=280.6, ups=0.26, wpb=1081.6, bsz=32, num_updates=39400, lr=2.5715e-06, gnorm=19, clip=100, loss_scale=32, train_wall=38, gb_free=8.5, wall=151949
2023-05-22 12:10:30 - progress_bar.py[line:272] - INFO: epoch 023:   1377 / 1732 loss=2.398, loss_v1=0, loss_v2=0, nll_loss=1.2, ntokens=1107.3, nsentences=32, sample_size=1107.3, sample_size_v1=0, sample_size_v2=0, ppl=2.3, wps=288.5, ups=0.26, wpb=1107.3, bsz=32, num_updates=39410, lr=2.56946e-06, gnorm=20.775, clip=100, loss_scale=32, train_wall=38, gb_free=8.7, wall=151988
2023-05-22 12:11:09 - progress_bar.py[line:272] - INFO: epoch 023:   1387 / 1732 loss=2.36, loss_v1=0, loss_v2=0, nll_loss=1.156, ntokens=1152.6, nsentences=32, sample_size=1152.6, sample_size_v1=0, sample_size_v2=0, ppl=2.23, wps=300.5, ups=0.26, wpb=1152.6, bsz=32, num_updates=39420, lr=2.56741e-06, gnorm=18.307, clip=100, loss_scale=32, train_wall=38, gb_free=8.6, wall=152026
2023-05-22 12:11:47 - progress_bar.py[line:272] - INFO: epoch 023:   1397 / 1732 loss=2.364, loss_v1=0, loss_v2=0, nll_loss=1.16, ntokens=1066.5, nsentences=32, sample_size=1066.5, sample_size_v1=0, sample_size_v2=0, ppl=2.23, wps=276.5, ups=0.26, wpb=1066.5, bsz=32, num_updates=39430, lr=2.56536e-06, gnorm=21.044, clip=100, loss_scale=32, train_wall=39, gb_free=8.2, wall=152065
2023-05-22 12:12:26 - progress_bar.py[line:272] - INFO: epoch 023:   1407 / 1732 loss=2.368, loss_v1=0, loss_v2=0, nll_loss=1.164, ntokens=1152.8, nsentences=32, sample_size=1152.8, sample_size_v1=0, sample_size_v2=0, ppl=2.24, wps=298.4, ups=0.26, wpb=1152.8, bsz=32, num_updates=39440, lr=2.56332e-06, gnorm=19.204, clip=100, loss_scale=32, train_wall=39, gb_free=8.4, wall=152103
2023-05-22 12:13:05 - progress_bar.py[line:272] - INFO: epoch 023:   1417 / 1732 loss=2.386, loss_v1=0, loss_v2=0, nll_loss=1.185, ntokens=1290.7, nsentences=32, sample_size=1290.7, sample_size_v1=0, sample_size_v2=0, ppl=2.27, wps=330.6, ups=0.26, wpb=1290.7, bsz=32, num_updates=39450, lr=2.56127e-06, gnorm=18.441, clip=100, loss_scale=32, train_wall=39, gb_free=8, wall=152142
2023-05-22 12:13:44 - progress_bar.py[line:272] - INFO: epoch 023:   1427 / 1732 loss=2.347, loss_v1=0, loss_v2=0, nll_loss=1.14, ntokens=1220.7, nsentences=32, sample_size=1220.7, sample_size_v1=0, sample_size_v2=0, ppl=2.2, wps=313.5, ups=0.26, wpb=1220.7, bsz=32, num_updates=39460, lr=2.55922e-06, gnorm=17.703, clip=100, loss_scale=32, train_wall=39, gb_free=8.8, wall=152181
2023-05-22 12:14:23 - progress_bar.py[line:272] - INFO: epoch 023:   1437 / 1732 loss=2.351, loss_v1=0, loss_v2=0, nll_loss=1.146, ntokens=1217.2, nsentences=32, sample_size=1217.2, sample_size_v1=0, sample_size_v2=0, ppl=2.21, wps=313.9, ups=0.26, wpb=1217.2, bsz=32, num_updates=39470, lr=2.55717e-06, gnorm=17.04, clip=100, loss_scale=32, train_wall=39, gb_free=6.5, wall=152220
2023-05-22 12:15:05 - progress_bar.py[line:272] - INFO: epoch 023:   1447 / 1732 loss=2.382, loss_v1=0, loss_v2=0, nll_loss=1.182, ntokens=1115.7, nsentences=32, sample_size=1115.7, sample_size_v1=0, sample_size_v2=0, ppl=2.27, wps=262.6, ups=0.24, wpb=1115.7, bsz=32, num_updates=39480, lr=2.55513e-06, gnorm=18.291, clip=100, loss_scale=32, train_wall=42, gb_free=8.8, wall=152262
2023-05-22 12:15:51 - progress_bar.py[line:272] - INFO: epoch 023:   1457 / 1732 loss=2.381, loss_v1=0, loss_v2=0, nll_loss=1.18, ntokens=1111.8, nsentences=32, sample_size=1111.8, sample_size_v1=0, sample_size_v2=0, ppl=2.27, wps=241.1, ups=0.22, wpb=1111.8, bsz=32, num_updates=39490, lr=2.55308e-06, gnorm=19.777, clip=100, loss_scale=32, train_wall=46, gb_free=7.7, wall=152309
2023-05-22 12:16:37 - progress_bar.py[line:272] - INFO: epoch 023:   1467 / 1732 loss=2.323, loss_v1=0, loss_v2=0, nll_loss=1.115, ntokens=1202.5, nsentences=32, sample_size=1202.5, sample_size_v1=0, sample_size_v2=0, ppl=2.17, wps=261.6, ups=0.22, wpb=1202.5, bsz=32, num_updates=39500, lr=2.55103e-06, gnorm=16.545, clip=100, loss_scale=32, train_wall=46, gb_free=8.5, wall=152355
2023-05-22 12:17:16 - progress_bar.py[line:272] - INFO: epoch 023:   1477 / 1732 loss=2.388, loss_v1=0, loss_v2=0, nll_loss=1.187, ntokens=1052.1, nsentences=32, sample_size=1052.1, sample_size_v1=0, sample_size_v2=0, ppl=2.28, wps=270, ups=0.26, wpb=1052.1, bsz=32, num_updates=39510, lr=2.54898e-06, gnorm=19.35, clip=100, loss_scale=32, train_wall=39, gb_free=7.8, wall=152394
2023-05-22 12:17:55 - progress_bar.py[line:272] - INFO: epoch 023:   1487 / 1732 loss=2.378, loss_v1=0, loss_v2=0, nll_loss=1.178, ntokens=1147.5, nsentences=32, sample_size=1147.5, sample_size_v1=0, sample_size_v2=0, ppl=2.26, wps=297.1, ups=0.26, wpb=1147.5, bsz=32, num_updates=39520, lr=2.54694e-06, gnorm=19.439, clip=100, loss_scale=32, train_wall=39, gb_free=8, wall=152432
2023-05-22 12:18:33 - progress_bar.py[line:272] - INFO: epoch 023:   1497 / 1732 loss=2.351, loss_v1=0, loss_v2=0, nll_loss=1.146, ntokens=1083.9, nsentences=32, sample_size=1083.9, sample_size_v1=0, sample_size_v2=0, ppl=2.21, wps=281.6, ups=0.26, wpb=1083.9, bsz=32, num_updates=39530, lr=2.54489e-06, gnorm=19.15, clip=100, loss_scale=32, train_wall=38, gb_free=8.4, wall=152471
2023-05-22 12:19:12 - progress_bar.py[line:272] - INFO: epoch 023:   1507 / 1732 loss=2.31, loss_v1=0, loss_v2=0, nll_loss=1.099, ntokens=1112.5, nsentences=32, sample_size=1112.5, sample_size_v1=0, sample_size_v2=0, ppl=2.14, wps=289.8, ups=0.26, wpb=1112.5, bsz=32, num_updates=39540, lr=2.54284e-06, gnorm=18.537, clip=100, loss_scale=32, train_wall=38, gb_free=8.3, wall=152509
2023-05-22 12:19:50 - progress_bar.py[line:272] - INFO: epoch 023:   1517 / 1732 loss=2.386, loss_v1=0, loss_v2=0, nll_loss=1.184, ntokens=1063, nsentences=32, sample_size=1063, sample_size_v1=0, sample_size_v2=0, ppl=2.27, wps=277.1, ups=0.26, wpb=1063, bsz=32, num_updates=39550, lr=2.54079e-06, gnorm=17.939, clip=100, loss_scale=32, train_wall=38, gb_free=7.8, wall=152547
2023-05-22 12:20:29 - progress_bar.py[line:272] - INFO: epoch 023:   1527 / 1732 loss=2.413, loss_v1=0, loss_v2=0, nll_loss=1.216, ntokens=1062.3, nsentences=32, sample_size=1062.3, sample_size_v1=0, sample_size_v2=0, ppl=2.32, wps=275.4, ups=0.26, wpb=1062.3, bsz=32, num_updates=39560, lr=2.53875e-06, gnorm=19.123, clip=100, loss_scale=32, train_wall=39, gb_free=8.3, wall=152586
2023-05-22 12:21:08 - progress_bar.py[line:272] - INFO: epoch 023:   1537 / 1732 loss=2.362, loss_v1=0, loss_v2=0, nll_loss=1.158, ntokens=1067, nsentences=32, sample_size=1067, sample_size_v1=0, sample_size_v2=0, ppl=2.23, wps=275.1, ups=0.26, wpb=1067, bsz=32, num_updates=39570, lr=2.5367e-06, gnorm=19.806, clip=100, loss_scale=32, train_wall=39, gb_free=7.7, wall=152625
2023-05-22 12:21:46 - progress_bar.py[line:272] - INFO: epoch 023:   1547 / 1732 loss=2.343, loss_v1=0, loss_v2=0, nll_loss=1.137, ntokens=1093.5, nsentences=32, sample_size=1093.5, sample_size_v1=0, sample_size_v2=0, ppl=2.2, wps=284.8, ups=0.26, wpb=1093.5, bsz=32, num_updates=39580, lr=2.53465e-06, gnorm=18.218, clip=100, loss_scale=32, train_wall=38, gb_free=8.4, wall=152663
2023-05-22 12:22:24 - progress_bar.py[line:272] - INFO: epoch 023:   1557 / 1732 loss=2.354, loss_v1=0, loss_v2=0, nll_loss=1.15, ntokens=1051.1, nsentences=32, sample_size=1051.1, sample_size_v1=0, sample_size_v2=0, ppl=2.22, wps=273.7, ups=0.26, wpb=1051.1, bsz=32, num_updates=39590, lr=2.5326e-06, gnorm=18.922, clip=100, loss_scale=32, train_wall=38, gb_free=8.3, wall=152702
2023-05-22 12:23:03 - progress_bar.py[line:272] - INFO: epoch 023:   1567 / 1732 loss=2.401, loss_v1=0, loss_v2=0, nll_loss=1.204, ntokens=1097.1, nsentences=32, sample_size=1097.1, sample_size_v1=0, sample_size_v2=0, ppl=2.3, wps=284.2, ups=0.26, wpb=1097.1, bsz=32, num_updates=39600, lr=2.53056e-06, gnorm=19.055, clip=100, loss_scale=32, train_wall=39, gb_free=7.5, wall=152740
2023-05-22 12:23:41 - progress_bar.py[line:272] - INFO: epoch 023:   1577 / 1732 loss=2.404, loss_v1=0, loss_v2=0, nll_loss=1.206, ntokens=1002.1, nsentences=32, sample_size=1002.1, sample_size_v1=0, sample_size_v2=0, ppl=2.31, wps=261.4, ups=0.26, wpb=1002.1, bsz=32, num_updates=39610, lr=2.52851e-06, gnorm=23.065, clip=100, loss_scale=32, train_wall=38, gb_free=8.7, wall=152779
2023-05-22 12:24:20 - progress_bar.py[line:272] - INFO: epoch 023:   1587 / 1732 loss=2.372, loss_v1=0, loss_v2=0, nll_loss=1.169, ntokens=1081.3, nsentences=32, sample_size=1081.3, sample_size_v1=0, sample_size_v2=0, ppl=2.25, wps=279, ups=0.26, wpb=1081.3, bsz=32, num_updates=39620, lr=2.52646e-06, gnorm=18.727, clip=100, loss_scale=32, train_wall=39, gb_free=7.9, wall=152817
2023-05-22 12:24:59 - progress_bar.py[line:272] - INFO: epoch 023:   1597 / 1732 loss=2.344, loss_v1=0, loss_v2=0, nll_loss=1.138, ntokens=1084.4, nsentences=32, sample_size=1084.4, sample_size_v1=0, sample_size_v2=0, ppl=2.2, wps=282, ups=0.26, wpb=1084.4, bsz=32, num_updates=39630, lr=2.52441e-06, gnorm=19.714, clip=100, loss_scale=32, train_wall=38, gb_free=8, wall=152856
2023-05-22 12:25:37 - progress_bar.py[line:272] - INFO: epoch 023:   1607 / 1732 loss=2.351, loss_v1=0, loss_v2=0, nll_loss=1.147, ntokens=1122.8, nsentences=32, sample_size=1122.8, sample_size_v1=0, sample_size_v2=0, ppl=2.21, wps=291.6, ups=0.26, wpb=1122.8, bsz=32, num_updates=39640, lr=2.52237e-06, gnorm=18.835, clip=100, loss_scale=32, train_wall=38, gb_free=8, wall=152894
2023-05-22 12:26:16 - progress_bar.py[line:272] - INFO: epoch 023:   1617 / 1732 loss=2.324, loss_v1=0, loss_v2=0, nll_loss=1.117, ntokens=1114.5, nsentences=32, sample_size=1114.5, sample_size_v1=0, sample_size_v2=0, ppl=2.17, wps=288.3, ups=0.26, wpb=1114.5, bsz=32, num_updates=39650, lr=2.52032e-06, gnorm=18.229, clip=100, loss_scale=32, train_wall=39, gb_free=8.4, wall=152933
2023-05-22 12:26:55 - progress_bar.py[line:272] - INFO: epoch 023:   1627 / 1732 loss=2.354, loss_v1=0, loss_v2=0, nll_loss=1.15, ntokens=1162.3, nsentences=32, sample_size=1162.3, sample_size_v1=0, sample_size_v2=0, ppl=2.22, wps=299.7, ups=0.26, wpb=1162.3, bsz=32, num_updates=39660, lr=2.51827e-06, gnorm=17.149, clip=100, loss_scale=32, train_wall=39, gb_free=8.3, wall=152972
2023-05-22 12:27:33 - progress_bar.py[line:272] - INFO: epoch 023:   1637 / 1732 loss=2.339, loss_v1=0, loss_v2=0, nll_loss=1.132, ntokens=1115.7, nsentences=32, sample_size=1115.7, sample_size_v1=0, sample_size_v2=0, ppl=2.19, wps=289.7, ups=0.26, wpb=1115.7, bsz=32, num_updates=39670, lr=2.51623e-06, gnorm=19.2, clip=100, loss_scale=32, train_wall=38, gb_free=8.6, wall=153010
2023-05-22 12:28:12 - progress_bar.py[line:272] - INFO: epoch 023:   1647 / 1732 loss=2.317, loss_v1=0, loss_v2=0, nll_loss=1.107, ntokens=1285, nsentences=32, sample_size=1285, sample_size_v1=0, sample_size_v2=0, ppl=2.15, wps=329.2, ups=0.26, wpb=1285, bsz=32, num_updates=39680, lr=2.51418e-06, gnorm=14.657, clip=100, loss_scale=32, train_wall=39, gb_free=8.2, wall=153049
2023-05-22 12:28:50 - progress_bar.py[line:272] - INFO: epoch 023:   1657 / 1732 loss=2.391, loss_v1=0, loss_v2=0, nll_loss=1.191, ntokens=952, nsentences=32, sample_size=952, sample_size_v1=0, sample_size_v2=0, ppl=2.28, wps=249.5, ups=0.26, wpb=952, bsz=32, num_updates=39690, lr=2.51213e-06, gnorm=20.397, clip=100, loss_scale=32, train_wall=38, gb_free=8.4, wall=153087
2023-05-22 12:29:29 - progress_bar.py[line:272] - INFO: epoch 023:   1667 / 1732 loss=2.363, loss_v1=0, loss_v2=0, nll_loss=1.161, ntokens=1028.1, nsentences=32, sample_size=1028.1, sample_size_v1=0, sample_size_v2=0, ppl=2.24, wps=267.6, ups=0.26, wpb=1028.1, bsz=32, num_updates=39700, lr=2.51008e-06, gnorm=19.393, clip=100, loss_scale=32, train_wall=38, gb_free=8.5, wall=153126
2023-05-22 12:30:07 - progress_bar.py[line:272] - INFO: epoch 023:   1677 / 1732 loss=2.314, loss_v1=0, loss_v2=0, nll_loss=1.105, ntokens=1135.4, nsentences=32, sample_size=1135.4, sample_size_v1=0, sample_size_v2=0, ppl=2.15, wps=293.9, ups=0.26, wpb=1135.4, bsz=32, num_updates=39710, lr=2.50804e-06, gnorm=18.624, clip=100, loss_scale=32, train_wall=39, gb_free=7.4, wall=153165
2023-05-22 12:30:46 - progress_bar.py[line:272] - INFO: epoch 023:   1687 / 1732 loss=2.335, loss_v1=0, loss_v2=0, nll_loss=1.128, ntokens=1154.5, nsentences=32, sample_size=1154.5, sample_size_v1=0, sample_size_v2=0, ppl=2.19, wps=296.6, ups=0.26, wpb=1154.5, bsz=32, num_updates=39720, lr=2.50599e-06, gnorm=16.769, clip=100, loss_scale=32, train_wall=39, gb_free=7, wall=153203
2023-05-22 12:31:26 - progress_bar.py[line:272] - INFO: epoch 023:   1697 / 1732 loss=2.34, loss_v1=0, loss_v2=0, nll_loss=1.133, ntokens=1302.5, nsentences=32, sample_size=1302.5, sample_size_v1=0, sample_size_v2=0, ppl=2.19, wps=329.4, ups=0.25, wpb=1302.5, bsz=32, num_updates=39730, lr=2.50394e-06, gnorm=16.022, clip=100, loss_scale=32, train_wall=39, gb_free=8, wall=153243
2023-05-22 12:32:05 - progress_bar.py[line:272] - INFO: epoch 023:   1707 / 1732 loss=2.351, loss_v1=0, loss_v2=0, nll_loss=1.148, ntokens=1171.1, nsentences=32, sample_size=1171.1, sample_size_v1=0, sample_size_v2=0, ppl=2.22, wps=301.9, ups=0.26, wpb=1171.1, bsz=32, num_updates=39740, lr=2.50189e-06, gnorm=17.189, clip=100, loss_scale=32, train_wall=39, gb_free=8.5, wall=153282
2023-05-22 12:32:43 - progress_bar.py[line:272] - INFO: epoch 023:   1717 / 1732 loss=2.342, loss_v1=0, loss_v2=0, nll_loss=1.136, ntokens=1206.1, nsentences=32, sample_size=1206.1, sample_size_v1=0, sample_size_v2=0, ppl=2.2, wps=310.3, ups=0.26, wpb=1206.1, bsz=32, num_updates=39750, lr=2.49985e-06, gnorm=17.434, clip=100, loss_scale=32, train_wall=39, gb_free=8.3, wall=153321
2023-05-22 12:33:22 - progress_bar.py[line:272] - INFO: epoch 023:   1727 / 1732 loss=2.384, loss_v1=0, loss_v2=0, nll_loss=1.183, ntokens=1102.3, nsentences=32, sample_size=1102.3, sample_size_v1=0, sample_size_v2=0, ppl=2.27, wps=285.2, ups=0.26, wpb=1102.3, bsz=32, num_updates=39760, lr=2.4978e-06, gnorm=17.735, clip=100, loss_scale=32, train_wall=39, gb_free=8.8, wall=153359
2023-05-22 12:33:39 - train.py[line:332] - INFO: end of epoch 23 (average epoch stats below)
2023-05-22 12:33:39 - progress_bar.py[line:282] - INFO: epoch 023 | loss 2.367 | loss_v1 0 | loss_v2 0 | nll_loss 1.164 | ntokens 1051.64 | nsentences 31.986 | sample_size 1051.64 | sample_size_v1 0 | sample_size_v2 0 | ppl 2.24 | wps 273.6 | ups 0.26 | wpb 1051.6 | bsz 32 | num_updates 39765 | lr 2.49678e-06 | gnorm 18.959 | clip 100 | loss_scale 32 | train_wall 6639 | gb_free 8.9 | wall 153376
2023-05-22 12:33:39 - trainer.py[line:639] - INFO: loading train data for epoch 24
local datafile ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 0 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 0 finished initializing row_count and line_idx-to-offset mapping
file ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 0 row count 55400 total row count 55400
slice_id 0 seek offset 0
2023-05-22 12:33:40 - trainer.py[line:703] - INFO: begin training epoch 24
2023-05-22 12:33:40 - train.py[line:305] - INFO: Start iterating over samples
2023-05-22 12:34:00 - progress_bar.py[line:272] - INFO: epoch 024:      5 / 1732 loss=2.327, loss_v1=0, loss_v2=0, nll_loss=1.121, ntokens=1084.5, nsentences=29.6, sample_size=1084.5, sample_size_v1=0, sample_size_v2=0, ppl=2.17, wps=285.1, ups=0.26, wpb=1084.5, bsz=29.6, num_updates=39770, lr=2.49575e-06, gnorm=18.853, clip=100, loss_scale=32, train_wall=36, gb_free=8.4, wall=153397
2023-05-22 12:34:39 - progress_bar.py[line:272] - INFO: epoch 024:     15 / 1732 loss=2.309, loss_v1=0, loss_v2=0, nll_loss=1.099, ntokens=1089.9, nsentences=32, sample_size=1089.9, sample_size_v1=0, sample_size_v2=0, ppl=2.14, wps=282.4, ups=0.26, wpb=1089.9, bsz=32, num_updates=39780, lr=2.4937e-06, gnorm=19.724, clip=100, loss_scale=32, train_wall=39, gb_free=8.2, wall=153436
2023-05-22 12:35:17 - progress_bar.py[line:272] - INFO: epoch 024:     25 / 1732 loss=2.271, loss_v1=0, loss_v2=0, nll_loss=1.056, ntokens=998.7, nsentences=32, sample_size=998.7, sample_size_v1=0, sample_size_v2=0, ppl=2.08, wps=259.6, ups=0.26, wpb=998.7, bsz=32, num_updates=39790, lr=2.49166e-06, gnorm=18.134, clip=100, loss_scale=32, train_wall=38, gb_free=9.1, wall=153474
2023-05-22 12:35:56 - progress_bar.py[line:272] - INFO: epoch 024:     35 / 1732 loss=2.183, loss_v1=0, loss_v2=0, nll_loss=0.957, ntokens=1115.2, nsentences=32, sample_size=1115.2, sample_size_v1=0, sample_size_v2=0, ppl=1.94, wps=287, ups=0.26, wpb=1115.2, bsz=32, num_updates=39800, lr=2.48961e-06, gnorm=14.547, clip=100, loss_scale=32, train_wall=39, gb_free=8.1, wall=153513
2023-05-22 12:36:35 - progress_bar.py[line:272] - INFO: epoch 024:     45 / 1732 loss=2.166, loss_v1=0, loss_v2=0, nll_loss=0.94, ntokens=1103.9, nsentences=32, sample_size=1103.9, sample_size_v1=0, sample_size_v2=0, ppl=1.92, wps=284.9, ups=0.26, wpb=1103.9, bsz=32, num_updates=39810, lr=2.48756e-06, gnorm=16.228, clip=100, loss_scale=32, train_wall=39, gb_free=7.8, wall=153552
2023-05-22 12:37:13 - progress_bar.py[line:272] - INFO: epoch 024:     55 / 1732 loss=2.123, loss_v1=0, loss_v2=0, nll_loss=0.893, ntokens=1058.4, nsentences=32, sample_size=1058.4, sample_size_v1=0, sample_size_v2=0, ppl=1.86, wps=274.5, ups=0.26, wpb=1058.4, bsz=32, num_updates=39820, lr=2.48551e-06, gnorm=15.232, clip=100, loss_scale=32, train_wall=39, gb_free=8.2, wall=153591
2023-05-22 12:37:52 - progress_bar.py[line:272] - INFO: epoch 024:     65 / 1732 loss=2.002, loss_v1=0, loss_v2=0, nll_loss=0.761, ntokens=1260.1, nsentences=32, sample_size=1260.1, sample_size_v1=0, sample_size_v2=0, ppl=1.7, wps=322.2, ups=0.26, wpb=1260.1, bsz=32, num_updates=39830, lr=2.48347e-06, gnorm=11.958, clip=100, loss_scale=64, train_wall=39, gb_free=7.5, wall=153630
2023-05-22 12:38:09 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2023-05-22 12:38:36 - progress_bar.py[line:272] - INFO: epoch 024:     76 / 1732 loss=2.089, loss_v1=0, loss_v2=0, nll_loss=0.856, ntokens=1351, nsentences=32, sample_size=1351, sample_size_v1=0, sample_size_v2=0, ppl=1.81, wps=308.8, ups=0.23, wpb=1351, bsz=32, num_updates=39840, lr=2.48142e-06, gnorm=13.927, clip=100, loss_scale=32, train_wall=44, gb_free=7.1, wall=153673
2023-05-22 12:39:15 - progress_bar.py[line:272] - INFO: epoch 024:     86 / 1732 loss=2.206, loss_v1=0, loss_v2=0, nll_loss=0.985, ntokens=1107.4, nsentences=32, sample_size=1107.4, sample_size_v1=0, sample_size_v2=0, ppl=1.98, wps=282.9, ups=0.26, wpb=1107.4, bsz=32, num_updates=39850, lr=2.47937e-06, gnorm=20.113, clip=100, loss_scale=32, train_wall=39, gb_free=7.9, wall=153713
2023-05-22 12:39:54 - progress_bar.py[line:272] - INFO: epoch 024:     96 / 1732 loss=2.16, loss_v1=0, loss_v2=0, nll_loss=0.931, ntokens=1069.5, nsentences=32, sample_size=1069.5, sample_size_v1=0, sample_size_v2=0, ppl=1.91, wps=277.2, ups=0.26, wpb=1069.5, bsz=32, num_updates=39860, lr=2.47733e-06, gnorm=18.058, clip=100, loss_scale=32, train_wall=39, gb_free=7.5, wall=153751
2023-05-22 12:40:32 - progress_bar.py[line:272] - INFO: epoch 024:    106 / 1732 loss=2.32, loss_v1=0, loss_v2=0, nll_loss=1.112, ntokens=998.2, nsentences=32, sample_size=998.2, sample_size_v1=0, sample_size_v2=0, ppl=2.16, wps=260.5, ups=0.26, wpb=998.2, bsz=32, num_updates=39870, lr=2.47528e-06, gnorm=21.678, clip=100, loss_scale=32, train_wall=38, gb_free=7.3, wall=153790
2023-05-22 12:41:11 - progress_bar.py[line:272] - INFO: epoch 024:    116 / 1732 loss=2.389, loss_v1=0, loss_v2=0, nll_loss=1.188, ntokens=1049.3, nsentences=32, sample_size=1049.3, sample_size_v1=0, sample_size_v2=0, ppl=2.28, wps=271.8, ups=0.26, wpb=1049.3, bsz=32, num_updates=39880, lr=2.47323e-06, gnorm=19.563, clip=100, loss_scale=32, train_wall=39, gb_free=7.6, wall=153828
2023-05-22 12:41:50 - progress_bar.py[line:272] - INFO: epoch 024:    126 / 1732 loss=2.306, loss_v1=0, loss_v2=0, nll_loss=1.092, ntokens=1187.5, nsentences=32, sample_size=1187.5, sample_size_v1=0, sample_size_v2=0, ppl=2.13, wps=302.6, ups=0.25, wpb=1187.5, bsz=32, num_updates=39890, lr=2.47118e-06, gnorm=17.992, clip=100, loss_scale=32, train_wall=39, gb_free=8.4, wall=153867
2023-05-22 12:42:29 - progress_bar.py[line:272] - INFO: epoch 024:    136 / 1732 loss=2.298, loss_v1=0, loss_v2=0, nll_loss=1.084, ntokens=1228, nsentences=32, sample_size=1228, sample_size_v1=0, sample_size_v2=0, ppl=2.12, wps=314.3, ups=0.26, wpb=1228, bsz=32, num_updates=39900, lr=2.46914e-06, gnorm=18.3, clip=100, loss_scale=32, train_wall=39, gb_free=7.4, wall=153906
2023-05-22 12:43:09 - progress_bar.py[line:272] - INFO: epoch 024:    146 / 1732 loss=2.249, loss_v1=0, loss_v2=0, nll_loss=1.031, ntokens=1192.9, nsentences=32, sample_size=1192.9, sample_size_v1=0, sample_size_v2=0, ppl=2.04, wps=303, ups=0.25, wpb=1192.9, bsz=32, num_updates=39910, lr=2.46709e-06, gnorm=15.244, clip=100, loss_scale=32, train_wall=39, gb_free=7.7, wall=153946
2023-05-22 12:43:48 - progress_bar.py[line:272] - INFO: epoch 024:    156 / 1732 loss=2.295, loss_v1=0, loss_v2=0, nll_loss=1.084, ntokens=1174.3, nsentences=32, sample_size=1174.3, sample_size_v1=0, sample_size_v2=0, ppl=2.12, wps=297.7, ups=0.25, wpb=1174.3, bsz=32, num_updates=39920, lr=2.46504e-06, gnorm=15.973, clip=100, loss_scale=32, train_wall=39, gb_free=8, wall=153985
2023-05-22 12:44:27 - progress_bar.py[line:272] - INFO: epoch 024:    166 / 1732 loss=2.263, loss_v1=0, loss_v2=0, nll_loss=1.049, ntokens=1039.2, nsentences=32, sample_size=1039.2, sample_size_v1=0, sample_size_v2=0, ppl=2.07, wps=269, ups=0.26, wpb=1039.2, bsz=32, num_updates=39930, lr=2.46299e-06, gnorm=18.334, clip=100, loss_scale=32, train_wall=39, gb_free=7.4, wall=154024
2023-05-22 12:45:05 - progress_bar.py[line:272] - INFO: epoch 024:    176 / 1732 loss=2.283, loss_v1=0, loss_v2=0, nll_loss=1.072, ntokens=982.6, nsentences=32, sample_size=982.6, sample_size_v1=0, sample_size_v2=0, ppl=2.1, wps=254.5, ups=0.26, wpb=982.6, bsz=32, num_updates=39940, lr=2.46095e-06, gnorm=20.171, clip=100, loss_scale=32, train_wall=39, gb_free=7.9, wall=154063
2023-05-22 12:45:44 - progress_bar.py[line:272] - INFO: epoch 024:    186 / 1732 loss=2.225, loss_v1=0, loss_v2=0, nll_loss=1.006, ntokens=1142, nsentences=32, sample_size=1142, sample_size_v1=0, sample_size_v2=0, ppl=2.01, wps=292.6, ups=0.26, wpb=1142, bsz=32, num_updates=39950, lr=2.4589e-06, gnorm=16.571, clip=100, loss_scale=32, train_wall=39, gb_free=8.2, wall=154102
2023-05-22 12:46:24 - progress_bar.py[line:272] - INFO: epoch 024:    196 / 1732 loss=2.288, loss_v1=0, loss_v2=0, nll_loss=1.076, ntokens=1152.2, nsentences=32, sample_size=1152.2, sample_size_v1=0, sample_size_v2=0, ppl=2.11, wps=294.4, ups=0.26, wpb=1152.2, bsz=32, num_updates=39960, lr=2.45685e-06, gnorm=16.808, clip=100, loss_scale=32, train_wall=39, gb_free=8.2, wall=154141
2023-05-22 12:47:02 - progress_bar.py[line:272] - INFO: epoch 024:    206 / 1732 loss=2.373, loss_v1=0, loss_v2=0, nll_loss=1.171, ntokens=995.3, nsentences=32, sample_size=995.3, sample_size_v1=0, sample_size_v2=0, ppl=2.25, wps=261.3, ups=0.26, wpb=995.3, bsz=32, num_updates=39970, lr=2.4548e-06, gnorm=19.659, clip=100, loss_scale=32, train_wall=38, gb_free=8.5, wall=154179
2023-05-22 12:47:40 - progress_bar.py[line:272] - INFO: epoch 024:    216 / 1732 loss=2.391, loss_v1=0, loss_v2=0, nll_loss=1.192, ntokens=1119.9, nsentences=32, sample_size=1119.9, sample_size_v1=0, sample_size_v2=0, ppl=2.29, wps=292.7, ups=0.26, wpb=1119.9, bsz=32, num_updates=39980, lr=2.45276e-06, gnorm=16.566, clip=100, loss_scale=32, train_wall=38, gb_free=8.9, wall=154217
2023-05-22 12:48:18 - progress_bar.py[line:272] - INFO: epoch 024:    226 / 1732 loss=2.381, loss_v1=0, loss_v2=0, nll_loss=1.18, ntokens=1111.6, nsentences=32, sample_size=1111.6, sample_size_v1=0, sample_size_v2=0, ppl=2.26, wps=290.8, ups=0.26, wpb=1111.6, bsz=32, num_updates=39990, lr=2.45071e-06, gnorm=19.304, clip=100, loss_scale=32, train_wall=38, gb_free=8.7, wall=154255
2023-05-22 12:48:56 - progress_bar.py[line:272] - INFO: epoch 024:    236 / 1732 loss=2.433, loss_v1=0, loss_v2=0, nll_loss=1.238, ntokens=1076.5, nsentences=32, sample_size=1076.5, sample_size_v1=0, sample_size_v2=0, ppl=2.36, wps=280.7, ups=0.26, wpb=1076.5, bsz=32, num_updates=40000, lr=2.44866e-06, gnorm=19.336, clip=100, loss_scale=32, train_wall=38, gb_free=8.6, wall=154294
2023-05-22 12:49:35 - progress_bar.py[line:272] - INFO: epoch 024:    246 / 1732 loss=2.41, loss_v1=0, loss_v2=0, nll_loss=1.213, ntokens=1166.2, nsentences=32, sample_size=1166.2, sample_size_v1=0, sample_size_v2=0, ppl=2.32, wps=303.9, ups=0.26, wpb=1166.2, bsz=32, num_updates=40010, lr=2.44661e-06, gnorm=18.015, clip=100, loss_scale=32, train_wall=38, gb_free=8.9, wall=154332
2023-05-22 12:50:13 - progress_bar.py[line:272] - INFO: epoch 024:    256 / 1732 loss=2.399, loss_v1=0, loss_v2=0, nll_loss=1.2, ntokens=1137.6, nsentences=32, sample_size=1137.6, sample_size_v1=0, sample_size_v2=0, ppl=2.3, wps=296.6, ups=0.26, wpb=1137.6, bsz=32, num_updates=40020, lr=2.44457e-06, gnorm=17.798, clip=100, loss_scale=32, train_wall=38, gb_free=8.5, wall=154370
2023-05-22 12:50:51 - progress_bar.py[line:272] - INFO: epoch 024:    266 / 1732 loss=2.41, loss_v1=0, loss_v2=0, nll_loss=1.211, ntokens=1142, nsentences=32, sample_size=1142, sample_size_v1=0, sample_size_v2=0, ppl=2.32, wps=298.3, ups=0.26, wpb=1142, bsz=32, num_updates=40030, lr=2.44252e-06, gnorm=17.641, clip=100, loss_scale=32, train_wall=38, gb_free=7.6, wall=154409
2023-05-22 12:51:30 - progress_bar.py[line:272] - INFO: epoch 024:    276 / 1732 loss=2.4, loss_v1=0, loss_v2=0, nll_loss=1.201, ntokens=1142.5, nsentences=32, sample_size=1142.5, sample_size_v1=0, sample_size_v2=0, ppl=2.3, wps=297.8, ups=0.26, wpb=1142.5, bsz=32, num_updates=40040, lr=2.44047e-06, gnorm=18.096, clip=100, loss_scale=32, train_wall=38, gb_free=8, wall=154447
2023-05-22 12:52:08 - progress_bar.py[line:272] - INFO: epoch 024:    286 / 1732 loss=2.405, loss_v1=0, loss_v2=0, nll_loss=1.206, ntokens=1155.8, nsentences=32, sample_size=1155.8, sample_size_v1=0, sample_size_v2=0, ppl=2.31, wps=300.6, ups=0.26, wpb=1155.8, bsz=32, num_updates=40050, lr=2.43843e-06, gnorm=18.57, clip=100, loss_scale=32, train_wall=38, gb_free=8.4, wall=154486
2023-05-22 12:52:46 - progress_bar.py[line:272] - INFO: epoch 024:    296 / 1732 loss=2.393, loss_v1=0, loss_v2=0, nll_loss=1.193, ntokens=1134.4, nsentences=32, sample_size=1134.4, sample_size_v1=0, sample_size_v2=0, ppl=2.29, wps=297.1, ups=0.26, wpb=1134.4, bsz=32, num_updates=40060, lr=2.43638e-06, gnorm=18.333, clip=100, loss_scale=32, train_wall=38, gb_free=8.2, wall=154524
2023-05-22 12:53:25 - progress_bar.py[line:272] - INFO: epoch 024:    306 / 1732 loss=2.38, loss_v1=0, loss_v2=0, nll_loss=1.177, ntokens=1078.8, nsentences=32, sample_size=1078.8, sample_size_v1=0, sample_size_v2=0, ppl=2.26, wps=282.5, ups=0.26, wpb=1078.8, bsz=32, num_updates=40070, lr=2.43433e-06, gnorm=19.129, clip=100, loss_scale=32, train_wall=38, gb_free=8.1, wall=154562
2023-05-22 12:54:03 - progress_bar.py[line:272] - INFO: epoch 024:    316 / 1732 loss=2.41, loss_v1=0, loss_v2=0, nll_loss=1.211, ntokens=1033.6, nsentences=32, sample_size=1033.6, sample_size_v1=0, sample_size_v2=0, ppl=2.32, wps=271.9, ups=0.26, wpb=1033.6, bsz=32, num_updates=40080, lr=2.43228e-06, gnorm=20.194, clip=100, loss_scale=32, train_wall=38, gb_free=7.9, wall=154600
2023-05-22 12:54:41 - progress_bar.py[line:272] - INFO: epoch 024:    326 / 1732 loss=2.421, loss_v1=0, loss_v2=0, nll_loss=1.224, ntokens=1006.1, nsentences=32, sample_size=1006.1, sample_size_v1=0, sample_size_v2=0, ppl=2.34, wps=265.5, ups=0.26, wpb=1006.1, bsz=32, num_updates=40090, lr=2.43024e-06, gnorm=19.496, clip=100, loss_scale=32, train_wall=38, gb_free=8.8, wall=154638
2023-05-22 12:55:18 - progress_bar.py[line:272] - INFO: epoch 024:    336 / 1732 loss=2.404, loss_v1=0, loss_v2=0, nll_loss=1.204, ntokens=1005.9, nsentences=32, sample_size=1005.9, sample_size_v1=0, sample_size_v2=0, ppl=2.3, wps=265.5, ups=0.26, wpb=1005.9, bsz=32, num_updates=40100, lr=2.42819e-06, gnorm=18.284, clip=100, loss_scale=32, train_wall=38, gb_free=8.6, wall=154676
2023-05-22 12:55:56 - progress_bar.py[line:272] - INFO: epoch 024:    346 / 1732 loss=2.383, loss_v1=0, loss_v2=0, nll_loss=1.181, ntokens=909.3, nsentences=32, sample_size=909.3, sample_size_v1=0, sample_size_v2=0, ppl=2.27, wps=240.6, ups=0.26, wpb=909.3, bsz=32, num_updates=40110, lr=2.42614e-06, gnorm=20.346, clip=100, loss_scale=32, train_wall=38, gb_free=8.6, wall=154713
2023-05-22 12:56:34 - progress_bar.py[line:272] - INFO: epoch 024:    356 / 1732 loss=2.42, loss_v1=0, loss_v2=0, nll_loss=1.222, ntokens=955.2, nsentences=32, sample_size=955.2, sample_size_v1=0, sample_size_v2=0, ppl=2.33, wps=253.6, ups=0.27, wpb=955.2, bsz=32, num_updates=40120, lr=2.42409e-06, gnorm=21.035, clip=100, loss_scale=32, train_wall=38, gb_free=9.1, wall=154751
2023-05-22 12:57:12 - progress_bar.py[line:272] - INFO: epoch 024:    366 / 1732 loss=2.438, loss_v1=0, loss_v2=0, nll_loss=1.243, ntokens=951.9, nsentences=32, sample_size=951.9, sample_size_v1=0, sample_size_v2=0, ppl=2.37, wps=252.7, ups=0.27, wpb=951.9, bsz=32, num_updates=40130, lr=2.42205e-06, gnorm=22.262, clip=100, loss_scale=32, train_wall=38, gb_free=8.9, wall=154789
2023-05-22 12:57:50 - progress_bar.py[line:272] - INFO: epoch 024:    376 / 1732 loss=2.443, loss_v1=0, loss_v2=0, nll_loss=1.249, ntokens=1015.4, nsentences=32, sample_size=1015.4, sample_size_v1=0, sample_size_v2=0, ppl=2.38, wps=267.7, ups=0.26, wpb=1015.4, bsz=32, num_updates=40140, lr=2.42e-06, gnorm=19.639, clip=100, loss_scale=32, train_wall=38, gb_free=8.7, wall=154827
2023-05-22 12:58:28 - progress_bar.py[line:272] - INFO: epoch 024:    386 / 1732 loss=2.419, loss_v1=0, loss_v2=0, nll_loss=1.221, ntokens=1063.1, nsentences=32, sample_size=1063.1, sample_size_v1=0, sample_size_v2=0, ppl=2.33, wps=279, ups=0.26, wpb=1063.1, bsz=32, num_updates=40150, lr=2.41795e-06, gnorm=19.498, clip=100, loss_scale=32, train_wall=38, gb_free=8.6, wall=154865
2023-05-22 12:59:05 - progress_bar.py[line:272] - INFO: epoch 024:    396 / 1732 loss=2.408, loss_v1=0, loss_v2=0, nll_loss=1.207, ntokens=950.2, nsentences=32, sample_size=950.2, sample_size_v1=0, sample_size_v2=0, ppl=2.31, wps=252, ups=0.27, wpb=950.2, bsz=32, num_updates=40160, lr=2.4159e-06, gnorm=20.383, clip=100, loss_scale=32, train_wall=38, gb_free=8.1, wall=154903
2023-05-22 12:59:43 - progress_bar.py[line:272] - INFO: epoch 024:    406 / 1732 loss=2.385, loss_v1=0, loss_v2=0, nll_loss=1.184, ntokens=1066.6, nsentences=32, sample_size=1066.6, sample_size_v1=0, sample_size_v2=0, ppl=2.27, wps=280, ups=0.26, wpb=1066.6, bsz=32, num_updates=40170, lr=2.41386e-06, gnorm=17.48, clip=100, loss_scale=32, train_wall=38, gb_free=8.4, wall=154941
2023-05-22 13:00:22 - progress_bar.py[line:272] - INFO: epoch 024:    416 / 1732 loss=2.386, loss_v1=0, loss_v2=0, nll_loss=1.185, ntokens=1055.1, nsentences=32, sample_size=1055.1, sample_size_v1=0, sample_size_v2=0, ppl=2.27, wps=276.7, ups=0.26, wpb=1055.1, bsz=32, num_updates=40180, lr=2.41181e-06, gnorm=19.689, clip=100, loss_scale=32, train_wall=38, gb_free=8.7, wall=154979
2023-05-22 13:01:00 - progress_bar.py[line:272] - INFO: epoch 024:    426 / 1732 loss=2.369, loss_v1=0, loss_v2=0, nll_loss=1.166, ntokens=988.1, nsentences=32, sample_size=988.1, sample_size_v1=0, sample_size_v2=0, ppl=2.24, wps=260.2, ups=0.26, wpb=988.1, bsz=32, num_updates=40190, lr=2.40976e-06, gnorm=19.96, clip=100, loss_scale=32, train_wall=38, gb_free=8.1, wall=155017
2023-05-22 13:01:37 - progress_bar.py[line:272] - INFO: epoch 024:    436 / 1732 loss=2.407, loss_v1=0, loss_v2=0, nll_loss=1.208, ntokens=1044.5, nsentences=32, sample_size=1044.5, sample_size_v1=0, sample_size_v2=0, ppl=2.31, wps=276, ups=0.26, wpb=1044.5, bsz=32, num_updates=40200, lr=2.40771e-06, gnorm=18.647, clip=100, loss_scale=32, train_wall=38, gb_free=8.2, wall=155055
2023-05-22 13:02:15 - progress_bar.py[line:272] - INFO: epoch 024:    446 / 1732 loss=2.418, loss_v1=0, loss_v2=0, nll_loss=1.22, ntokens=952.9, nsentences=32, sample_size=952.9, sample_size_v1=0, sample_size_v2=0, ppl=2.33, wps=251.7, ups=0.26, wpb=952.9, bsz=32, num_updates=40210, lr=2.40567e-06, gnorm=21.364, clip=100, loss_scale=32, train_wall=38, gb_free=8, wall=155092
2023-05-22 13:02:53 - progress_bar.py[line:272] - INFO: epoch 024:    456 / 1732 loss=2.418, loss_v1=0, loss_v2=0, nll_loss=1.221, ntokens=925.5, nsentences=32, sample_size=925.5, sample_size_v1=0, sample_size_v2=0, ppl=2.33, wps=245.5, ups=0.27, wpb=925.5, bsz=32, num_updates=40220, lr=2.40362e-06, gnorm=21.624, clip=100, loss_scale=32, train_wall=38, gb_free=8.8, wall=155130
2023-05-22 13:03:31 - progress_bar.py[line:272] - INFO: epoch 024:    466 / 1732 loss=2.432, loss_v1=0, loss_v2=0, nll_loss=1.235, ntokens=1063.6, nsentences=32, sample_size=1063.6, sample_size_v1=0, sample_size_v2=0, ppl=2.35, wps=278.5, ups=0.26, wpb=1063.6, bsz=32, num_updates=40230, lr=2.40157e-06, gnorm=19.879, clip=100, loss_scale=32, train_wall=38, gb_free=8.7, wall=155168
2023-05-22 13:04:09 - progress_bar.py[line:272] - INFO: epoch 024:    476 / 1732 loss=2.434, loss_v1=0, loss_v2=0, nll_loss=1.237, ntokens=1057.9, nsentences=32, sample_size=1057.9, sample_size_v1=0, sample_size_v2=0, ppl=2.36, wps=276.5, ups=0.26, wpb=1057.9, bsz=32, num_updates=40240, lr=2.39953e-06, gnorm=19.724, clip=100, loss_scale=32, train_wall=38, gb_free=8.6, wall=155207
2023-05-22 13:04:47 - progress_bar.py[line:272] - INFO: epoch 024:    486 / 1732 loss=2.397, loss_v1=0, loss_v2=0, nll_loss=1.197, ntokens=966.1, nsentences=32, sample_size=966.1, sample_size_v1=0, sample_size_v2=0, ppl=2.29, wps=255.7, ups=0.26, wpb=966.1, bsz=32, num_updates=40250, lr=2.39748e-06, gnorm=20.211, clip=100, loss_scale=32, train_wall=38, gb_free=8.4, wall=155244
2023-05-22 13:05:25 - progress_bar.py[line:272] - INFO: epoch 024:    496 / 1732 loss=2.405, loss_v1=0, loss_v2=0, nll_loss=1.205, ntokens=932.2, nsentences=32, sample_size=932.2, sample_size_v1=0, sample_size_v2=0, ppl=2.31, wps=247.9, ups=0.27, wpb=932.2, bsz=32, num_updates=40260, lr=2.39543e-06, gnorm=21.964, clip=100, loss_scale=32, train_wall=38, gb_free=8.9, wall=155282
2023-05-22 13:06:02 - progress_bar.py[line:272] - INFO: epoch 024:    506 / 1732 loss=2.42, loss_v1=0, loss_v2=0, nll_loss=1.222, ntokens=994.9, nsentences=32, sample_size=994.9, sample_size_v1=0, sample_size_v2=0, ppl=2.33, wps=264.6, ups=0.27, wpb=994.9, bsz=32, num_updates=40270, lr=2.39338e-06, gnorm=22.1, clip=100, loss_scale=32, train_wall=38, gb_free=8.3, wall=155320
2023-05-22 13:06:40 - progress_bar.py[line:272] - INFO: epoch 024:    516 / 1732 loss=2.413, loss_v1=0, loss_v2=0, nll_loss=1.215, ntokens=1062.8, nsentences=32, sample_size=1062.8, sample_size_v1=0, sample_size_v2=0, ppl=2.32, wps=281.2, ups=0.26, wpb=1062.8, bsz=32, num_updates=40280, lr=2.39134e-06, gnorm=18.502, clip=100, loss_scale=32, train_wall=38, gb_free=8.8, wall=155357
2023-05-22 13:07:18 - progress_bar.py[line:272] - INFO: epoch 024:    526 / 1732 loss=2.414, loss_v1=0, loss_v2=0, nll_loss=1.216, ntokens=946.7, nsentences=32, sample_size=946.7, sample_size_v1=0, sample_size_v2=0, ppl=2.32, wps=250.7, ups=0.26, wpb=946.7, bsz=32, num_updates=40290, lr=2.38929e-06, gnorm=22.564, clip=100, loss_scale=32, train_wall=38, gb_free=9, wall=155395
2023-05-22 13:07:56 - progress_bar.py[line:272] - INFO: epoch 024:    536 / 1732 loss=2.401, loss_v1=0, loss_v2=0, nll_loss=1.202, ntokens=955.9, nsentences=32, sample_size=955.9, sample_size_v1=0, sample_size_v2=0, ppl=2.3, wps=254.5, ups=0.27, wpb=955.9, bsz=32, num_updates=40300, lr=2.38724e-06, gnorm=19.191, clip=100, loss_scale=32, train_wall=38, gb_free=8.7, wall=155433
2023-05-22 13:08:33 - progress_bar.py[line:272] - INFO: epoch 024:    546 / 1732 loss=2.42, loss_v1=0, loss_v2=0, nll_loss=1.223, ntokens=1026.2, nsentences=32, sample_size=1026.2, sample_size_v1=0, sample_size_v2=0, ppl=2.33, wps=271.4, ups=0.26, wpb=1026.2, bsz=32, num_updates=40310, lr=2.38519e-06, gnorm=19.398, clip=100, loss_scale=32, train_wall=38, gb_free=8.5, wall=155471
2023-05-22 13:09:11 - progress_bar.py[line:272] - INFO: epoch 024:    556 / 1732 loss=2.444, loss_v1=0, loss_v2=0, nll_loss=1.249, ntokens=1007.9, nsentences=32, sample_size=1007.9, sample_size_v1=0, sample_size_v2=0, ppl=2.38, wps=266.4, ups=0.26, wpb=1007.9, bsz=32, num_updates=40320, lr=2.38315e-06, gnorm=20.095, clip=100, loss_scale=32, train_wall=38, gb_free=8.2, wall=155508
2023-05-22 13:09:49 - progress_bar.py[line:272] - INFO: epoch 024:    566 / 1732 loss=2.443, loss_v1=0, loss_v2=0, nll_loss=1.25, ntokens=1034.4, nsentences=32, sample_size=1034.4, sample_size_v1=0, sample_size_v2=0, ppl=2.38, wps=272.8, ups=0.26, wpb=1034.4, bsz=32, num_updates=40330, lr=2.3811e-06, gnorm=19.353, clip=100, loss_scale=32, train_wall=38, gb_free=7.7, wall=155546
2023-05-22 13:10:27 - progress_bar.py[line:272] - INFO: epoch 024:    576 / 1732 loss=2.413, loss_v1=0, loss_v2=0, nll_loss=1.214, ntokens=1004.8, nsentences=32, sample_size=1004.8, sample_size_v1=0, sample_size_v2=0, ppl=2.32, wps=264.2, ups=0.26, wpb=1004.8, bsz=32, num_updates=40340, lr=2.37905e-06, gnorm=20.456, clip=100, loss_scale=32, train_wall=38, gb_free=8.3, wall=155584
2023-05-22 13:10:50 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2023-05-22 13:11:09 - progress_bar.py[line:272] - INFO: epoch 024:    587 / 1732 loss=2.429, loss_v1=0, loss_v2=0, nll_loss=1.233, ntokens=954.6, nsentences=32, sample_size=954.6, sample_size_v1=0, sample_size_v2=0, ppl=2.35, wps=229, ups=0.24, wpb=954.6, bsz=32, num_updates=40350, lr=2.377e-06, gnorm=22.336, clip=100, loss_scale=32, train_wall=42, gb_free=9.3, wall=155626
2023-05-22 13:11:47 - progress_bar.py[line:272] - INFO: epoch 024:    597 / 1732 loss=2.377, loss_v1=0, loss_v2=0, nll_loss=1.175, ntokens=975.4, nsentences=32, sample_size=975.4, sample_size_v1=0, sample_size_v2=0, ppl=2.26, wps=257.5, ups=0.26, wpb=975.4, bsz=32, num_updates=40360, lr=2.37496e-06, gnorm=21.042, clip=100, loss_scale=32, train_wall=38, gb_free=8.6, wall=155664
2023-05-22 13:12:24 - progress_bar.py[line:272] - INFO: epoch 024:    607 / 1732 loss=2.415, loss_v1=0, loss_v2=0, nll_loss=1.218, ntokens=882.8, nsentences=32, sample_size=882.8, sample_size_v1=0, sample_size_v2=0, ppl=2.33, wps=235, ups=0.27, wpb=882.8, bsz=32, num_updates=40370, lr=2.37291e-06, gnorm=22.24, clip=100, loss_scale=32, train_wall=38, gb_free=8.1, wall=155701
2023-05-22 13:13:02 - progress_bar.py[line:272] - INFO: epoch 024:    617 / 1732 loss=2.426, loss_v1=0, loss_v2=0, nll_loss=1.231, ntokens=866.1, nsentences=32, sample_size=866.1, sample_size_v1=0, sample_size_v2=0, ppl=2.35, wps=230.6, ups=0.27, wpb=866.1, bsz=32, num_updates=40380, lr=2.37086e-06, gnorm=25.079, clip=100, loss_scale=32, train_wall=38, gb_free=8.7, wall=155739
2023-05-22 13:13:39 - progress_bar.py[line:272] - INFO: epoch 024:    627 / 1732 loss=2.414, loss_v1=0, loss_v2=0, nll_loss=1.217, ntokens=930.6, nsentences=32, sample_size=930.6, sample_size_v1=0, sample_size_v2=0, ppl=2.32, wps=247.8, ups=0.27, wpb=930.6, bsz=32, num_updates=40390, lr=2.36881e-06, gnorm=23.469, clip=100, loss_scale=32, train_wall=38, gb_free=9.1, wall=155777
2023-05-22 13:14:17 - progress_bar.py[line:272] - INFO: epoch 024:    637 / 1732 loss=2.43, loss_v1=0, loss_v2=0, nll_loss=1.234, ntokens=914.3, nsentences=32, sample_size=914.3, sample_size_v1=0, sample_size_v2=0, ppl=2.35, wps=242.7, ups=0.27, wpb=914.3, bsz=32, num_updates=40400, lr=2.36677e-06, gnorm=23.408, clip=100, loss_scale=32, train_wall=38, gb_free=8.8, wall=155814
2023-05-22 13:14:55 - progress_bar.py[line:272] - INFO: epoch 024:    647 / 1732 loss=2.43, loss_v1=0, loss_v2=0, nll_loss=1.235, ntokens=980.8, nsentences=32, sample_size=980.8, sample_size_v1=0, sample_size_v2=0, ppl=2.35, wps=260.4, ups=0.27, wpb=980.8, bsz=32, num_updates=40410, lr=2.36472e-06, gnorm=23.263, clip=100, loss_scale=32, train_wall=38, gb_free=9, wall=155852
2023-05-22 13:15:32 - progress_bar.py[line:272] - INFO: epoch 024:    657 / 1732 loss=2.435, loss_v1=0, loss_v2=0, nll_loss=1.242, ntokens=894.4, nsentences=32, sample_size=894.4, sample_size_v1=0, sample_size_v2=0, ppl=2.36, wps=239.2, ups=0.27, wpb=894.4, bsz=32, num_updates=40420, lr=2.36267e-06, gnorm=24.003, clip=100, loss_scale=32, train_wall=37, gb_free=8.8, wall=155889
2023-05-22 13:16:10 - progress_bar.py[line:272] - INFO: epoch 024:    667 / 1732 loss=2.42, loss_v1=0, loss_v2=0, nll_loss=1.222, ntokens=903.9, nsentences=32, sample_size=903.9, sample_size_v1=0, sample_size_v2=0, ppl=2.33, wps=240.8, ups=0.27, wpb=903.9, bsz=32, num_updates=40430, lr=2.36062e-06, gnorm=22.425, clip=100, loss_scale=32, train_wall=37, gb_free=8.7, wall=155927
2023-05-22 13:16:48 - progress_bar.py[line:272] - INFO: epoch 024:    677 / 1732 loss=2.416, loss_v1=0, loss_v2=0, nll_loss=1.219, ntokens=985.3, nsentences=32, sample_size=985.3, sample_size_v1=0, sample_size_v2=0, ppl=2.33, wps=259, ups=0.26, wpb=985.3, bsz=32, num_updates=40440, lr=2.35858e-06, gnorm=20.93, clip=100, loss_scale=32, train_wall=38, gb_free=9, wall=155965
2023-05-22 13:17:26 - progress_bar.py[line:272] - INFO: epoch 024:    687 / 1732 loss=2.432, loss_v1=0, loss_v2=0, nll_loss=1.236, ntokens=943.2, nsentences=32, sample_size=943.2, sample_size_v1=0, sample_size_v2=0, ppl=2.36, wps=249.5, ups=0.26, wpb=943.2, bsz=32, num_updates=40450, lr=2.35653e-06, gnorm=22.94, clip=100, loss_scale=32, train_wall=38, gb_free=9.2, wall=156003
2023-05-22 13:18:04 - progress_bar.py[line:272] - INFO: epoch 024:    697 / 1732 loss=2.414, loss_v1=0, loss_v2=0, nll_loss=1.216, ntokens=1005.6, nsentences=32, sample_size=1005.6, sample_size_v1=0, sample_size_v2=0, ppl=2.32, wps=264.6, ups=0.26, wpb=1005.6, bsz=32, num_updates=40460, lr=2.35448e-06, gnorm=20.974, clip=100, loss_scale=32, train_wall=38, gb_free=8, wall=156041
2023-05-22 13:18:41 - progress_bar.py[line:272] - INFO: epoch 024:    707 / 1732 loss=2.42, loss_v1=0, loss_v2=0, nll_loss=1.224, ntokens=903.4, nsentences=32, sample_size=903.4, sample_size_v1=0, sample_size_v2=0, ppl=2.34, wps=239.8, ups=0.27, wpb=903.4, bsz=32, num_updates=40470, lr=2.35244e-06, gnorm=22.989, clip=100, loss_scale=32, train_wall=38, gb_free=9.1, wall=156078
2023-05-22 13:19:19 - progress_bar.py[line:272] - INFO: epoch 024:    717 / 1732 loss=2.41, loss_v1=0, loss_v2=0, nll_loss=1.211, ntokens=882.7, nsentences=32, sample_size=882.7, sample_size_v1=0, sample_size_v2=0, ppl=2.31, wps=235.2, ups=0.27, wpb=882.7, bsz=32, num_updates=40480, lr=2.35039e-06, gnorm=22.383, clip=100, loss_scale=32, train_wall=37, gb_free=8.8, wall=156116
2023-05-22 13:19:56 - progress_bar.py[line:272] - INFO: epoch 024:    727 / 1732 loss=2.396, loss_v1=0, loss_v2=0, nll_loss=1.196, ntokens=909.8, nsentences=32, sample_size=909.8, sample_size_v1=0, sample_size_v2=0, ppl=2.29, wps=242.2, ups=0.27, wpb=909.8, bsz=32, num_updates=40490, lr=2.34834e-06, gnorm=23.116, clip=100, loss_scale=32, train_wall=38, gb_free=9.2, wall=156154
2023-05-22 13:20:34 - progress_bar.py[line:272] - INFO: epoch 024:    737 / 1732 loss=2.395, loss_v1=0, loss_v2=0, nll_loss=1.195, ntokens=998.8, nsentences=32, sample_size=998.8, sample_size_v1=0, sample_size_v2=0, ppl=2.29, wps=264.7, ups=0.26, wpb=998.8, bsz=32, num_updates=40500, lr=2.34629e-06, gnorm=19.351, clip=100, loss_scale=32, train_wall=38, gb_free=8.6, wall=156191
2023-05-22 13:20:41 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2023-05-22 13:21:16 - progress_bar.py[line:272] - INFO: epoch 024:    748 / 1732 loss=2.407, loss_v1=0, loss_v2=0, nll_loss=1.207, ntokens=970.6, nsentences=32, sample_size=970.6, sample_size_v1=0, sample_size_v2=0, ppl=2.31, wps=233.8, ups=0.24, wpb=970.6, bsz=32, num_updates=40510, lr=2.34425e-06, gnorm=19.244, clip=100, loss_scale=16, train_wall=41, gb_free=8.8, wall=156233
2023-05-22 13:21:53 - progress_bar.py[line:272] - INFO: epoch 024:    758 / 1732 loss=2.389, loss_v1=0, loss_v2=0, nll_loss=1.188, ntokens=946.6, nsentences=32, sample_size=946.6, sample_size_v1=0, sample_size_v2=0, ppl=2.28, wps=251.1, ups=0.27, wpb=946.6, bsz=32, num_updates=40520, lr=2.3422e-06, gnorm=21.276, clip=100, loss_scale=16, train_wall=38, gb_free=8.6, wall=156271
2023-05-22 13:22:31 - progress_bar.py[line:272] - INFO: epoch 024:    768 / 1732 loss=2.405, loss_v1=0, loss_v2=0, nll_loss=1.206, ntokens=947.6, nsentences=32, sample_size=947.6, sample_size_v1=0, sample_size_v2=0, ppl=2.31, wps=252, ups=0.27, wpb=947.6, bsz=32, num_updates=40530, lr=2.34015e-06, gnorm=20.465, clip=100, loss_scale=16, train_wall=38, gb_free=8.5, wall=156308
2023-05-22 13:23:09 - progress_bar.py[line:272] - INFO: epoch 024:    778 / 1732 loss=2.408, loss_v1=0, loss_v2=0, nll_loss=1.209, ntokens=1017.6, nsentences=32, sample_size=1017.6, sample_size_v1=0, sample_size_v2=0, ppl=2.31, wps=269.3, ups=0.26, wpb=1017.6, bsz=32, num_updates=40540, lr=2.3381e-06, gnorm=20.387, clip=100, loss_scale=16, train_wall=38, gb_free=9.2, wall=156346
2023-05-22 13:23:47 - progress_bar.py[line:272] - INFO: epoch 024:    788 / 1732 loss=2.404, loss_v1=0, loss_v2=0, nll_loss=1.205, ntokens=1010.8, nsentences=32, sample_size=1010.8, sample_size_v1=0, sample_size_v2=0, ppl=2.3, wps=267.3, ups=0.26, wpb=1010.8, bsz=32, num_updates=40550, lr=2.33606e-06, gnorm=19.818, clip=100, loss_scale=16, train_wall=38, gb_free=8.4, wall=156384
2023-05-22 13:24:24 - progress_bar.py[line:272] - INFO: epoch 024:    798 / 1732 loss=2.401, loss_v1=0, loss_v2=0, nll_loss=1.203, ntokens=1050, nsentences=32, sample_size=1050, sample_size_v1=0, sample_size_v2=0, ppl=2.3, wps=277.3, ups=0.26, wpb=1050, bsz=32, num_updates=40560, lr=2.33401e-06, gnorm=21.196, clip=100, loss_scale=16, train_wall=38, gb_free=8.8, wall=156422
2023-05-22 13:25:02 - progress_bar.py[line:272] - INFO: epoch 024:    808 / 1732 loss=2.412, loss_v1=0, loss_v2=0, nll_loss=1.214, ntokens=907.2, nsentences=32, sample_size=907.2, sample_size_v1=0, sample_size_v2=0, ppl=2.32, wps=240.5, ups=0.27, wpb=907.2, bsz=32, num_updates=40570, lr=2.33196e-06, gnorm=21.238, clip=100, loss_scale=16, train_wall=38, gb_free=8.8, wall=156459
2023-05-22 13:25:40 - progress_bar.py[line:272] - INFO: epoch 024:    818 / 1732 loss=2.42, loss_v1=0, loss_v2=0, nll_loss=1.223, ntokens=917.4, nsentences=32, sample_size=917.4, sample_size_v1=0, sample_size_v2=0, ppl=2.33, wps=242.8, ups=0.26, wpb=917.4, bsz=32, num_updates=40580, lr=2.32991e-06, gnorm=20.386, clip=100, loss_scale=16, train_wall=38, gb_free=8.7, wall=156497
2023-05-22 13:26:18 - progress_bar.py[line:272] - INFO: epoch 024:    828 / 1732 loss=2.404, loss_v1=0, loss_v2=0, nll_loss=1.205, ntokens=929.3, nsentences=32, sample_size=929.3, sample_size_v1=0, sample_size_v2=0, ppl=2.3, wps=244, ups=0.26, wpb=929.3, bsz=32, num_updates=40590, lr=2.32787e-06, gnorm=21.314, clip=100, loss_scale=16, train_wall=38, gb_free=9, wall=156535
2023-05-22 13:26:56 - progress_bar.py[line:272] - INFO: epoch 024:    838 / 1732 loss=2.409, loss_v1=0, loss_v2=0, nll_loss=1.212, ntokens=901, nsentences=32, sample_size=901, sample_size_v1=0, sample_size_v2=0, ppl=2.32, wps=240.1, ups=0.27, wpb=901, bsz=32, num_updates=40600, lr=2.32582e-06, gnorm=23.587, clip=100, loss_scale=16, train_wall=37, gb_free=8.9, wall=156573
2023-05-22 13:27:33 - progress_bar.py[line:272] - INFO: epoch 024:    848 / 1732 loss=2.391, loss_v1=0, loss_v2=0, nll_loss=1.189, ntokens=1016.3, nsentences=32, sample_size=1016.3, sample_size_v1=0, sample_size_v2=0, ppl=2.28, wps=268.9, ups=0.26, wpb=1016.3, bsz=32, num_updates=40610, lr=2.32377e-06, gnorm=21.197, clip=100, loss_scale=16, train_wall=38, gb_free=7.9, wall=156611
2023-05-22 13:28:11 - progress_bar.py[line:272] - INFO: epoch 024:    858 / 1732 loss=2.401, loss_v1=0, loss_v2=0, nll_loss=1.201, ntokens=923.8, nsentences=32, sample_size=923.8, sample_size_v1=0, sample_size_v2=0, ppl=2.3, wps=246.2, ups=0.27, wpb=923.8, bsz=32, num_updates=40620, lr=2.32172e-06, gnorm=23.437, clip=100, loss_scale=16, train_wall=37, gb_free=8.8, wall=156648
2023-05-22 13:28:49 - progress_bar.py[line:272] - INFO: epoch 024:    868 / 1732 loss=2.413, loss_v1=0, loss_v2=0, nll_loss=1.215, ntokens=966.1, nsentences=32, sample_size=966.1, sample_size_v1=0, sample_size_v2=0, ppl=2.32, wps=256, ups=0.27, wpb=966.1, bsz=32, num_updates=40630, lr=2.31968e-06, gnorm=22.096, clip=100, loss_scale=16, train_wall=38, gb_free=8.9, wall=156686
2023-05-22 13:29:26 - progress_bar.py[line:272] - INFO: epoch 024:    878 / 1732 loss=2.341, loss_v1=0, loss_v2=0, nll_loss=1.134, ntokens=1016.8, nsentences=32, sample_size=1016.8, sample_size_v1=0, sample_size_v2=0, ppl=2.19, wps=268.3, ups=0.26, wpb=1016.8, bsz=32, num_updates=40640, lr=2.31763e-06, gnorm=18.392, clip=100, loss_scale=16, train_wall=38, gb_free=8.7, wall=156724
2023-05-22 13:30:04 - progress_bar.py[line:272] - INFO: epoch 024:    888 / 1732 loss=2.369, loss_v1=0, loss_v2=0, nll_loss=1.167, ntokens=961.8, nsentences=32, sample_size=961.8, sample_size_v1=0, sample_size_v2=0, ppl=2.25, wps=254.1, ups=0.26, wpb=961.8, bsz=32, num_updates=40650, lr=2.31558e-06, gnorm=19.616, clip=100, loss_scale=16, train_wall=38, gb_free=8.7, wall=156762
2023-05-22 13:30:42 - progress_bar.py[line:272] - INFO: epoch 024:    898 / 1732 loss=2.335, loss_v1=0, loss_v2=0, nll_loss=1.128, ntokens=1063.3, nsentences=32, sample_size=1063.3, sample_size_v1=0, sample_size_v2=0, ppl=2.19, wps=280.4, ups=0.26, wpb=1063.3, bsz=32, num_updates=40660, lr=2.31354e-06, gnorm=17.416, clip=100, loss_scale=16, train_wall=38, gb_free=8.2, wall=156799
2023-05-22 13:31:20 - progress_bar.py[line:272] - INFO: epoch 024:    908 / 1732 loss=2.364, loss_v1=0, loss_v2=0, nll_loss=1.161, ntokens=987.4, nsentences=32, sample_size=987.4, sample_size_v1=0, sample_size_v2=0, ppl=2.24, wps=261.4, ups=0.26, wpb=987.4, bsz=32, num_updates=40670, lr=2.31149e-06, gnorm=20.699, clip=100, loss_scale=16, train_wall=38, gb_free=8.8, wall=156837
2023-05-22 13:31:58 - progress_bar.py[line:272] - INFO: epoch 024:    918 / 1732 loss=2.435, loss_v1=0, loss_v2=0, nll_loss=1.239, ntokens=968, nsentences=32, sample_size=968, sample_size_v1=0, sample_size_v2=0, ppl=2.36, wps=255, ups=0.26, wpb=968, bsz=32, num_updates=40680, lr=2.30944e-06, gnorm=22.253, clip=100, loss_scale=16, train_wall=38, gb_free=7.8, wall=156875
2023-05-22 13:32:36 - progress_bar.py[line:272] - INFO: epoch 024:    928 / 1732 loss=2.367, loss_v1=0, loss_v2=0, nll_loss=1.164, ntokens=1026.7, nsentences=32, sample_size=1026.7, sample_size_v1=0, sample_size_v2=0, ppl=2.24, wps=267.3, ups=0.26, wpb=1026.7, bsz=32, num_updates=40690, lr=2.30739e-06, gnorm=20.311, clip=100, loss_scale=16, train_wall=38, gb_free=8.5, wall=156914
2023-05-22 13:33:15 - progress_bar.py[line:272] - INFO: epoch 024:    938 / 1732 loss=2.379, loss_v1=0, loss_v2=0, nll_loss=1.177, ntokens=1050.3, nsentences=32, sample_size=1050.3, sample_size_v1=0, sample_size_v2=0, ppl=2.26, wps=271.8, ups=0.26, wpb=1050.3, bsz=32, num_updates=40700, lr=2.30535e-06, gnorm=19.647, clip=100, loss_scale=16, train_wall=39, gb_free=7.7, wall=156952
2023-05-22 13:33:54 - progress_bar.py[line:272] - INFO: epoch 024:    948 / 1732 loss=2.392, loss_v1=0, loss_v2=0, nll_loss=1.19, ntokens=1031, nsentences=32, sample_size=1031, sample_size_v1=0, sample_size_v2=0, ppl=2.28, wps=267.9, ups=0.26, wpb=1031, bsz=32, num_updates=40710, lr=2.3033e-06, gnorm=19.633, clip=100, loss_scale=16, train_wall=38, gb_free=8.7, wall=156991
2023-05-22 13:34:32 - progress_bar.py[line:272] - INFO: epoch 024:    958 / 1732 loss=2.372, loss_v1=0, loss_v2=0, nll_loss=1.169, ntokens=1072.9, nsentences=32, sample_size=1072.9, sample_size_v1=0, sample_size_v2=0, ppl=2.25, wps=278.5, ups=0.26, wpb=1072.9, bsz=32, num_updates=40720, lr=2.30125e-06, gnorm=18.576, clip=100, loss_scale=16, train_wall=38, gb_free=8.3, wall=157029
2023-05-22 13:35:11 - progress_bar.py[line:272] - INFO: epoch 024:    968 / 1732 loss=2.404, loss_v1=0, loss_v2=0, nll_loss=1.206, ntokens=1015.7, nsentences=32, sample_size=1015.7, sample_size_v1=0, sample_size_v2=0, ppl=2.31, wps=264.1, ups=0.26, wpb=1015.7, bsz=32, num_updates=40730, lr=2.2992e-06, gnorm=21.02, clip=100, loss_scale=16, train_wall=38, gb_free=8.9, wall=157068
2023-05-22 13:35:49 - progress_bar.py[line:272] - INFO: epoch 024:    978 / 1732 loss=2.388, loss_v1=0, loss_v2=0, nll_loss=1.188, ntokens=1036.8, nsentences=32, sample_size=1036.8, sample_size_v1=0, sample_size_v2=0, ppl=2.28, wps=269, ups=0.26, wpb=1036.8, bsz=32, num_updates=40740, lr=2.29716e-06, gnorm=18.581, clip=100, loss_scale=16, train_wall=38, gb_free=9, wall=157106
2023-05-22 13:36:28 - progress_bar.py[line:272] - INFO: epoch 024:    988 / 1732 loss=2.381, loss_v1=0, loss_v2=0, nll_loss=1.18, ntokens=1050.5, nsentences=32, sample_size=1050.5, sample_size_v1=0, sample_size_v2=0, ppl=2.27, wps=272.6, ups=0.26, wpb=1050.5, bsz=32, num_updates=40750, lr=2.29511e-06, gnorm=19.232, clip=100, loss_scale=16, train_wall=38, gb_free=7.9, wall=157145
2023-05-22 13:37:06 - progress_bar.py[line:272] - INFO: epoch 024:    998 / 1732 loss=2.38, loss_v1=0, loss_v2=0, nll_loss=1.178, ntokens=1000, nsentences=32, sample_size=1000, sample_size_v1=0, sample_size_v2=0, ppl=2.26, wps=261.8, ups=0.26, wpb=1000, bsz=32, num_updates=40760, lr=2.29306e-06, gnorm=18.212, clip=100, loss_scale=16, train_wall=38, gb_free=8.4, wall=157183
2023-05-22 13:37:44 - progress_bar.py[line:272] - INFO: epoch 024:   1008 / 1732 loss=2.375, loss_v1=0, loss_v2=0, nll_loss=1.173, ntokens=1026.8, nsentences=32, sample_size=1026.8, sample_size_v1=0, sample_size_v2=0, ppl=2.25, wps=268.4, ups=0.26, wpb=1026.8, bsz=32, num_updates=40770, lr=2.29101e-06, gnorm=18.25, clip=100, loss_scale=16, train_wall=38, gb_free=7.4, wall=157221
2023-05-22 13:38:22 - progress_bar.py[line:272] - INFO: epoch 024:   1018 / 1732 loss=2.357, loss_v1=0, loss_v2=0, nll_loss=1.154, ntokens=1036.8, nsentences=32, sample_size=1036.8, sample_size_v1=0, sample_size_v2=0, ppl=2.22, wps=270.8, ups=0.26, wpb=1036.8, bsz=32, num_updates=40780, lr=2.28897e-06, gnorm=18.777, clip=100, loss_scale=16, train_wall=38, gb_free=8.4, wall=157260
2023-05-22 13:39:01 - progress_bar.py[line:272] - INFO: epoch 024:   1028 / 1732 loss=2.391, loss_v1=0, loss_v2=0, nll_loss=1.19, ntokens=1060.8, nsentences=32, sample_size=1060.8, sample_size_v1=0, sample_size_v2=0, ppl=2.28, wps=274.2, ups=0.26, wpb=1060.8, bsz=32, num_updates=40790, lr=2.28692e-06, gnorm=19.841, clip=100, loss_scale=16, train_wall=39, gb_free=7.3, wall=157298
2023-05-22 13:39:40 - progress_bar.py[line:272] - INFO: epoch 024:   1038 / 1732 loss=2.38, loss_v1=0, loss_v2=0, nll_loss=1.179, ntokens=1110, nsentences=32, sample_size=1110, sample_size_v1=0, sample_size_v2=0, ppl=2.26, wps=288.6, ups=0.26, wpb=1110, bsz=32, num_updates=40800, lr=2.28487e-06, gnorm=18.069, clip=100, loss_scale=16, train_wall=38, gb_free=8.9, wall=157337
2023-05-22 13:40:18 - progress_bar.py[line:272] - INFO: epoch 024:   1048 / 1732 loss=2.368, loss_v1=0, loss_v2=0, nll_loss=1.165, ntokens=1025.8, nsentences=32, sample_size=1025.8, sample_size_v1=0, sample_size_v2=0, ppl=2.24, wps=267.1, ups=0.26, wpb=1025.8, bsz=32, num_updates=40810, lr=2.28282e-06, gnorm=19.419, clip=100, loss_scale=16, train_wall=38, gb_free=8.6, wall=157375
2023-05-22 13:40:56 - progress_bar.py[line:272] - INFO: epoch 024:   1058 / 1732 loss=2.383, loss_v1=0, loss_v2=0, nll_loss=1.183, ntokens=1082.8, nsentences=32, sample_size=1082.8, sample_size_v1=0, sample_size_v2=0, ppl=2.27, wps=282.3, ups=0.26, wpb=1082.8, bsz=32, num_updates=40820, lr=2.28078e-06, gnorm=19.951, clip=100, loss_scale=16, train_wall=38, gb_free=9, wall=157414
2023-05-22 13:41:34 - progress_bar.py[line:272] - INFO: epoch 024:   1068 / 1732 loss=2.38, loss_v1=0, loss_v2=0, nll_loss=1.179, ntokens=1002.9, nsentences=32, sample_size=1002.9, sample_size_v1=0, sample_size_v2=0, ppl=2.26, wps=262.9, ups=0.26, wpb=1002.9, bsz=32, num_updates=40830, lr=2.27873e-06, gnorm=20.138, clip=100, loss_scale=16, train_wall=38, gb_free=8.9, wall=157452
2023-05-22 13:42:13 - progress_bar.py[line:272] - INFO: epoch 024:   1078 / 1732 loss=2.407, loss_v1=0, loss_v2=0, nll_loss=1.208, ntokens=1000.2, nsentences=32, sample_size=1000.2, sample_size_v1=0, sample_size_v2=0, ppl=2.31, wps=259.6, ups=0.26, wpb=1000.2, bsz=32, num_updates=40840, lr=2.27668e-06, gnorm=21.385, clip=100, loss_scale=16, train_wall=38, gb_free=8.7, wall=157490
2023-05-22 13:42:52 - progress_bar.py[line:272] - INFO: epoch 024:   1088 / 1732 loss=2.372, loss_v1=0, loss_v2=0, nll_loss=1.171, ntokens=1078.6, nsentences=32, sample_size=1078.6, sample_size_v1=0, sample_size_v2=0, ppl=2.25, wps=279.8, ups=0.26, wpb=1078.6, bsz=32, num_updates=40850, lr=2.27464e-06, gnorm=19.613, clip=100, loss_scale=16, train_wall=39, gb_free=8.6, wall=157529
2023-05-22 13:43:30 - progress_bar.py[line:272] - INFO: epoch 024:   1098 / 1732 loss=2.392, loss_v1=0, loss_v2=0, nll_loss=1.193, ntokens=1045.6, nsentences=32, sample_size=1045.6, sample_size_v1=0, sample_size_v2=0, ppl=2.29, wps=272.1, ups=0.26, wpb=1045.6, bsz=32, num_updates=40860, lr=2.27259e-06, gnorm=20.958, clip=100, loss_scale=16, train_wall=38, gb_free=7.9, wall=157567
2023-05-22 13:44:09 - progress_bar.py[line:272] - INFO: epoch 024:   1108 / 1732 loss=2.375, loss_v1=0, loss_v2=0, nll_loss=1.173, ntokens=1058.8, nsentences=32, sample_size=1058.8, sample_size_v1=0, sample_size_v2=0, ppl=2.25, wps=274.7, ups=0.26, wpb=1058.8, bsz=32, num_updates=40870, lr=2.27054e-06, gnorm=19.85, clip=100, loss_scale=16, train_wall=38, gb_free=8.9, wall=157606
2023-05-22 13:44:47 - progress_bar.py[line:272] - INFO: epoch 024:   1118 / 1732 loss=2.386, loss_v1=0, loss_v2=0, nll_loss=1.186, ntokens=944.7, nsentences=32, sample_size=944.7, sample_size_v1=0, sample_size_v2=0, ppl=2.27, wps=244.4, ups=0.26, wpb=944.7, bsz=32, num_updates=40880, lr=2.26849e-06, gnorm=20.406, clip=100, loss_scale=16, train_wall=39, gb_free=8.4, wall=157644
2023-05-22 13:45:26 - progress_bar.py[line:272] - INFO: epoch 024:   1128 / 1732 loss=2.397, loss_v1=0, loss_v2=0, nll_loss=1.196, ntokens=1025.9, nsentences=32, sample_size=1025.9, sample_size_v1=0, sample_size_v2=0, ppl=2.29, wps=266.1, ups=0.26, wpb=1025.9, bsz=32, num_updates=40890, lr=2.26645e-06, gnorm=21.047, clip=100, loss_scale=16, train_wall=39, gb_free=7.7, wall=157683
2023-05-22 13:46:04 - progress_bar.py[line:272] - INFO: epoch 024:   1138 / 1732 loss=2.386, loss_v1=0, loss_v2=0, nll_loss=1.186, ntokens=989.2, nsentences=32, sample_size=989.2, sample_size_v1=0, sample_size_v2=0, ppl=2.28, wps=257.1, ups=0.26, wpb=989.2, bsz=32, num_updates=40900, lr=2.2644e-06, gnorm=20.48, clip=100, loss_scale=16, train_wall=38, gb_free=8.7, wall=157721
2023-05-22 13:46:43 - progress_bar.py[line:272] - INFO: epoch 024:   1148 / 1732 loss=2.391, loss_v1=0, loss_v2=0, nll_loss=1.19, ntokens=1007.7, nsentences=32, sample_size=1007.7, sample_size_v1=0, sample_size_v2=0, ppl=2.28, wps=262.3, ups=0.26, wpb=1007.7, bsz=32, num_updates=40910, lr=2.26235e-06, gnorm=21.209, clip=100, loss_scale=16, train_wall=38, gb_free=8.6, wall=157760
2023-05-22 13:47:21 - progress_bar.py[line:272] - INFO: epoch 024:   1158 / 1732 loss=2.36, loss_v1=0, loss_v2=0, nll_loss=1.156, ntokens=1016, nsentences=32, sample_size=1016, sample_size_v1=0, sample_size_v2=0, ppl=2.23, wps=261.8, ups=0.26, wpb=1016, bsz=32, num_updates=40920, lr=2.2603e-06, gnorm=21.665, clip=100, loss_scale=16, train_wall=39, gb_free=7.9, wall=157799
2023-05-22 13:48:00 - progress_bar.py[line:272] - INFO: epoch 024:   1168 / 1732 loss=2.392, loss_v1=0, loss_v2=0, nll_loss=1.191, ntokens=1020.6, nsentences=32, sample_size=1020.6, sample_size_v1=0, sample_size_v2=0, ppl=2.28, wps=264.2, ups=0.26, wpb=1020.6, bsz=32, num_updates=40930, lr=2.25826e-06, gnorm=21.229, clip=100, loss_scale=16, train_wall=39, gb_free=8.1, wall=157837
2023-05-22 13:48:39 - progress_bar.py[line:272] - INFO: epoch 024:   1178 / 1732 loss=2.35, loss_v1=0, loss_v2=0, nll_loss=1.145, ntokens=1067, nsentences=32, sample_size=1067, sample_size_v1=0, sample_size_v2=0, ppl=2.21, wps=277.4, ups=0.26, wpb=1067, bsz=32, num_updates=40940, lr=2.25621e-06, gnorm=19.68, clip=100, loss_scale=16, train_wall=38, gb_free=8.7, wall=157876
2023-05-22 13:49:17 - progress_bar.py[line:272] - INFO: epoch 024:   1188 / 1732 loss=2.394, loss_v1=0, loss_v2=0, nll_loss=1.193, ntokens=963.5, nsentences=32, sample_size=963.5, sample_size_v1=0, sample_size_v2=0, ppl=2.29, wps=251, ups=0.26, wpb=963.5, bsz=32, num_updates=40950, lr=2.25416e-06, gnorm=21.048, clip=100, loss_scale=16, train_wall=38, gb_free=8.2, wall=157914
2023-05-22 13:49:56 - progress_bar.py[line:272] - INFO: epoch 024:   1198 / 1732 loss=2.363, loss_v1=0, loss_v2=0, nll_loss=1.158, ntokens=1123.7, nsentences=32, sample_size=1123.7, sample_size_v1=0, sample_size_v2=0, ppl=2.23, wps=290, ups=0.26, wpb=1123.7, bsz=32, num_updates=40960, lr=2.25211e-06, gnorm=20.186, clip=100, loss_scale=16, train_wall=39, gb_free=8.4, wall=157953
2023-05-22 13:50:35 - progress_bar.py[line:272] - INFO: epoch 024:   1208 / 1732 loss=2.354, loss_v1=0, loss_v2=0, nll_loss=1.149, ntokens=1088.9, nsentences=32, sample_size=1088.9, sample_size_v1=0, sample_size_v2=0, ppl=2.22, wps=280, ups=0.26, wpb=1088.9, bsz=32, num_updates=40970, lr=2.25007e-06, gnorm=18.576, clip=100, loss_scale=16, train_wall=39, gb_free=7.7, wall=157992
2023-05-22 13:51:13 - progress_bar.py[line:272] - INFO: epoch 024:   1218 / 1732 loss=2.406, loss_v1=0, loss_v2=0, nll_loss=1.207, ntokens=1016, nsentences=32, sample_size=1016, sample_size_v1=0, sample_size_v2=0, ppl=2.31, wps=263.4, ups=0.26, wpb=1016, bsz=32, num_updates=40980, lr=2.24802e-06, gnorm=19.773, clip=100, loss_scale=16, train_wall=39, gb_free=8.8, wall=158030
2023-05-22 13:51:52 - progress_bar.py[line:272] - INFO: epoch 024:   1228 / 1732 loss=2.388, loss_v1=0, loss_v2=0, nll_loss=1.188, ntokens=1018.6, nsentences=32, sample_size=1018.6, sample_size_v1=0, sample_size_v2=0, ppl=2.28, wps=265, ups=0.26, wpb=1018.6, bsz=32, num_updates=40990, lr=2.24597e-06, gnorm=20.168, clip=100, loss_scale=16, train_wall=38, gb_free=8.6, wall=158069
2023-05-22 13:52:30 - progress_bar.py[line:272] - INFO: epoch 024:   1238 / 1732 loss=2.339, loss_v1=0, loss_v2=0, nll_loss=1.132, ntokens=1070.1, nsentences=32, sample_size=1070.1, sample_size_v1=0, sample_size_v2=0, ppl=2.19, wps=276.6, ups=0.26, wpb=1070.1, bsz=32, num_updates=41000, lr=2.24392e-06, gnorm=19.277, clip=100, loss_scale=16, train_wall=39, gb_free=8.3, wall=158107
2023-05-22 13:53:09 - progress_bar.py[line:272] - INFO: epoch 024:   1248 / 1732 loss=2.335, loss_v1=0, loss_v2=0, nll_loss=1.127, ntokens=1083.3, nsentences=32, sample_size=1083.3, sample_size_v1=0, sample_size_v2=0, ppl=2.18, wps=280.4, ups=0.26, wpb=1083.3, bsz=32, num_updates=41010, lr=2.24188e-06, gnorm=19.562, clip=100, loss_scale=16, train_wall=39, gb_free=8, wall=158146
2023-05-22 13:53:47 - progress_bar.py[line:272] - INFO: epoch 024:   1258 / 1732 loss=2.345, loss_v1=0, loss_v2=0, nll_loss=1.138, ntokens=1058.8, nsentences=32, sample_size=1058.8, sample_size_v1=0, sample_size_v2=0, ppl=2.2, wps=274.8, ups=0.26, wpb=1058.8, bsz=32, num_updates=41020, lr=2.23983e-06, gnorm=20.53, clip=100, loss_scale=32, train_wall=38, gb_free=8.2, wall=158185
2023-05-22 13:54:26 - progress_bar.py[line:272] - INFO: epoch 024:   1268 / 1732 loss=2.382, loss_v1=0, loss_v2=0, nll_loss=1.181, ntokens=1040.1, nsentences=32, sample_size=1040.1, sample_size_v1=0, sample_size_v2=0, ppl=2.27, wps=267, ups=0.26, wpb=1040.1, bsz=32, num_updates=41030, lr=2.23778e-06, gnorm=20.202, clip=100, loss_scale=32, train_wall=39, gb_free=8.5, wall=158224
2023-05-22 13:55:05 - progress_bar.py[line:272] - INFO: epoch 024:   1278 / 1732 loss=2.397, loss_v1=0, loss_v2=0, nll_loss=1.198, ntokens=1064.5, nsentences=32, sample_size=1064.5, sample_size_v1=0, sample_size_v2=0, ppl=2.29, wps=275.2, ups=0.26, wpb=1064.5, bsz=32, num_updates=41040, lr=2.23573e-06, gnorm=20.04, clip=100, loss_scale=32, train_wall=39, gb_free=8.6, wall=158262
2023-05-22 13:55:44 - progress_bar.py[line:272] - INFO: epoch 024:   1288 / 1732 loss=2.36, loss_v1=0, loss_v2=0, nll_loss=1.157, ntokens=1074.2, nsentences=32, sample_size=1074.2, sample_size_v1=0, sample_size_v2=0, ppl=2.23, wps=277.2, ups=0.26, wpb=1074.2, bsz=32, num_updates=41050, lr=2.23369e-06, gnorm=18.599, clip=100, loss_scale=32, train_wall=39, gb_free=6.9, wall=158301
2023-05-22 13:56:23 - progress_bar.py[line:272] - INFO: epoch 024:   1298 / 1732 loss=2.362, loss_v1=0, loss_v2=0, nll_loss=1.159, ntokens=1104.5, nsentences=32, sample_size=1104.5, sample_size_v1=0, sample_size_v2=0, ppl=2.23, wps=285.3, ups=0.26, wpb=1104.5, bsz=32, num_updates=41060, lr=2.23164e-06, gnorm=18.801, clip=100, loss_scale=32, train_wall=39, gb_free=7.9, wall=158340
2023-05-22 13:57:02 - progress_bar.py[line:272] - INFO: epoch 024:   1308 / 1732 loss=2.396, loss_v1=0, loss_v2=0, nll_loss=1.196, ntokens=1079.8, nsentences=32, sample_size=1079.8, sample_size_v1=0, sample_size_v2=0, ppl=2.29, wps=277.2, ups=0.26, wpb=1079.8, bsz=32, num_updates=41070, lr=2.22959e-06, gnorm=19.422, clip=100, loss_scale=32, train_wall=39, gb_free=7.5, wall=158379
2023-05-22 13:57:40 - progress_bar.py[line:272] - INFO: epoch 024:   1318 / 1732 loss=2.367, loss_v1=0, loss_v2=0, nll_loss=1.163, ntokens=1085.2, nsentences=32, sample_size=1085.2, sample_size_v1=0, sample_size_v2=0, ppl=2.24, wps=279.5, ups=0.26, wpb=1085.2, bsz=32, num_updates=41080, lr=2.22755e-06, gnorm=19.593, clip=100, loss_scale=32, train_wall=39, gb_free=8.1, wall=158418
2023-05-22 13:57:48 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2023-05-22 13:58:23 - progress_bar.py[line:272] - INFO: epoch 024:   1329 / 1732 loss=2.345, loss_v1=0, loss_v2=0, nll_loss=1.139, ntokens=1094, nsentences=32, sample_size=1094, sample_size_v1=0, sample_size_v2=0, ppl=2.2, wps=254.9, ups=0.23, wpb=1094, bsz=32, num_updates=41090, lr=2.2255e-06, gnorm=19.19, clip=100, loss_scale=16, train_wall=43, gb_free=8.5, wall=158460
2023-05-22 13:59:02 - progress_bar.py[line:272] - INFO: epoch 024:   1339 / 1732 loss=2.363, loss_v1=0, loss_v2=0, nll_loss=1.159, ntokens=1120.5, nsentences=32, sample_size=1120.5, sample_size_v1=0, sample_size_v2=0, ppl=2.23, wps=288.9, ups=0.26, wpb=1120.5, bsz=32, num_updates=41100, lr=2.22345e-06, gnorm=21.859, clip=100, loss_scale=16, train_wall=39, gb_free=8.2, wall=158499
2023-05-22 13:59:41 - progress_bar.py[line:272] - INFO: epoch 024:   1349 / 1732 loss=2.356, loss_v1=0, loss_v2=0, nll_loss=1.152, ntokens=1187.2, nsentences=32, sample_size=1187.2, sample_size_v1=0, sample_size_v2=0, ppl=2.22, wps=304.2, ups=0.26, wpb=1187.2, bsz=32, num_updates=41110, lr=2.2214e-06, gnorm=20.042, clip=100, loss_scale=16, train_wall=39, gb_free=8.5, wall=158538
2023-05-22 14:00:20 - progress_bar.py[line:272] - INFO: epoch 024:   1359 / 1732 loss=2.334, loss_v1=0, loss_v2=0, nll_loss=1.126, ntokens=1104.5, nsentences=32, sample_size=1104.5, sample_size_v1=0, sample_size_v2=0, ppl=2.18, wps=282.7, ups=0.26, wpb=1104.5, bsz=32, num_updates=41120, lr=2.21936e-06, gnorm=21.39, clip=100, loss_scale=16, train_wall=39, gb_free=8.3, wall=158577
2023-05-22 14:00:59 - progress_bar.py[line:272] - INFO: epoch 024:   1369 / 1732 loss=2.38, loss_v1=0, loss_v2=0, nll_loss=1.179, ntokens=1096, nsentences=32, sample_size=1096, sample_size_v1=0, sample_size_v2=0, ppl=2.26, wps=281.2, ups=0.26, wpb=1096, bsz=32, num_updates=41130, lr=2.21731e-06, gnorm=19.14, clip=100, loss_scale=16, train_wall=39, gb_free=8, wall=158616
2023-05-22 14:01:38 - progress_bar.py[line:272] - INFO: epoch 024:   1379 / 1732 loss=2.388, loss_v1=0, loss_v2=0, nll_loss=1.187, ntokens=1115.7, nsentences=32, sample_size=1115.7, sample_size_v1=0, sample_size_v2=0, ppl=2.28, wps=289.1, ups=0.26, wpb=1115.7, bsz=32, num_updates=41140, lr=2.21526e-06, gnorm=21.175, clip=100, loss_scale=16, train_wall=39, gb_free=8.6, wall=158655
2023-05-22 14:02:17 - progress_bar.py[line:272] - INFO: epoch 024:   1389 / 1732 loss=2.373, loss_v1=0, loss_v2=0, nll_loss=1.17, ntokens=1122.1, nsentences=32, sample_size=1122.1, sample_size_v1=0, sample_size_v2=0, ppl=2.25, wps=289.6, ups=0.26, wpb=1122.1, bsz=32, num_updates=41150, lr=2.21321e-06, gnorm=19.454, clip=100, loss_scale=16, train_wall=39, gb_free=8.6, wall=158694
2023-05-22 14:02:55 - progress_bar.py[line:272] - INFO: epoch 024:   1399 / 1732 loss=2.346, loss_v1=0, loss_v2=0, nll_loss=1.141, ntokens=1113, nsentences=32, sample_size=1113, sample_size_v1=0, sample_size_v2=0, ppl=2.21, wps=286.5, ups=0.26, wpb=1113, bsz=32, num_updates=41160, lr=2.21117e-06, gnorm=19.155, clip=100, loss_scale=16, train_wall=39, gb_free=8.2, wall=158733
2023-05-22 14:03:34 - progress_bar.py[line:272] - INFO: epoch 024:   1409 / 1732 loss=2.383, loss_v1=0, loss_v2=0, nll_loss=1.182, ntokens=1156.6, nsentences=32, sample_size=1156.6, sample_size_v1=0, sample_size_v2=0, ppl=2.27, wps=296.8, ups=0.26, wpb=1156.6, bsz=32, num_updates=41170, lr=2.20912e-06, gnorm=18.978, clip=100, loss_scale=16, train_wall=39, gb_free=8.3, wall=158772
2023-05-22 14:04:14 - progress_bar.py[line:272] - INFO: epoch 024:   1419 / 1732 loss=2.383, loss_v1=0, loss_v2=0, nll_loss=1.182, ntokens=1290.6, nsentences=32, sample_size=1290.6, sample_size_v1=0, sample_size_v2=0, ppl=2.27, wps=326.1, ups=0.25, wpb=1290.6, bsz=32, num_updates=41180, lr=2.20707e-06, gnorm=19.193, clip=100, loss_scale=16, train_wall=40, gb_free=7.6, wall=158811
2023-05-22 14:04:53 - progress_bar.py[line:272] - INFO: epoch 024:   1429 / 1732 loss=2.346, loss_v1=0, loss_v2=0, nll_loss=1.139, ntokens=1226.2, nsentences=32, sample_size=1226.2, sample_size_v1=0, sample_size_v2=0, ppl=2.2, wps=314.4, ups=0.26, wpb=1226.2, bsz=32, num_updates=41190, lr=2.20502e-06, gnorm=18.13, clip=100, loss_scale=16, train_wall=39, gb_free=8.4, wall=158850
2023-05-22 14:05:32 - progress_bar.py[line:272] - INFO: epoch 024:   1439 / 1732 loss=2.347, loss_v1=0, loss_v2=0, nll_loss=1.142, ntokens=1192.7, nsentences=32, sample_size=1192.7, sample_size_v1=0, sample_size_v2=0, ppl=2.21, wps=305.5, ups=0.26, wpb=1192.7, bsz=32, num_updates=41200, lr=2.20298e-06, gnorm=17.367, clip=100, loss_scale=16, train_wall=39, gb_free=8.2, wall=158889
2023-05-22 14:06:11 - progress_bar.py[line:272] - INFO: epoch 024:   1449 / 1732 loss=2.381, loss_v1=0, loss_v2=0, nll_loss=1.178, ntokens=1089.5, nsentences=32, sample_size=1089.5, sample_size_v1=0, sample_size_v2=0, ppl=2.26, wps=280.9, ups=0.26, wpb=1089.5, bsz=32, num_updates=41210, lr=2.20093e-06, gnorm=19.806, clip=100, loss_scale=16, train_wall=39, gb_free=8.6, wall=158928
2023-05-22 14:06:50 - progress_bar.py[line:272] - INFO: epoch 024:   1459 / 1732 loss=2.349, loss_v1=0, loss_v2=0, nll_loss=1.143, ntokens=1160, nsentences=32, sample_size=1160, sample_size_v1=0, sample_size_v2=0, ppl=2.21, wps=296.2, ups=0.26, wpb=1160, bsz=32, num_updates=41220, lr=2.19888e-06, gnorm=18.84, clip=100, loss_scale=16, train_wall=39, gb_free=8.3, wall=158967
2023-05-22 14:07:29 - progress_bar.py[line:272] - INFO: epoch 024:   1469 / 1732 loss=2.356, loss_v1=0, loss_v2=0, nll_loss=1.151, ntokens=1187.1, nsentences=32, sample_size=1187.1, sample_size_v1=0, sample_size_v2=0, ppl=2.22, wps=303.7, ups=0.26, wpb=1187.1, bsz=32, num_updates=41230, lr=2.19683e-06, gnorm=17.705, clip=100, loss_scale=16, train_wall=39, gb_free=8.5, wall=159006
2023-05-22 14:08:08 - progress_bar.py[line:272] - INFO: epoch 024:   1479 / 1732 loss=2.385, loss_v1=0, loss_v2=0, nll_loss=1.183, ntokens=1029.5, nsentences=32, sample_size=1029.5, sample_size_v1=0, sample_size_v2=0, ppl=2.27, wps=265.6, ups=0.26, wpb=1029.5, bsz=32, num_updates=41240, lr=2.19479e-06, gnorm=20.563, clip=100, loss_scale=16, train_wall=39, gb_free=8.1, wall=159045
2023-05-22 14:08:47 - progress_bar.py[line:272] - INFO: epoch 024:   1489 / 1732 loss=2.368, loss_v1=0, loss_v2=0, nll_loss=1.165, ntokens=1147, nsentences=32, sample_size=1147, sample_size_v1=0, sample_size_v2=0, ppl=2.24, wps=294.4, ups=0.26, wpb=1147, bsz=32, num_updates=41250, lr=2.19274e-06, gnorm=19.696, clip=100, loss_scale=16, train_wall=39, gb_free=8.4, wall=159084
2023-05-22 14:09:25 - progress_bar.py[line:272] - INFO: epoch 024:   1499 / 1732 loss=2.345, loss_v1=0, loss_v2=0, nll_loss=1.14, ntokens=1095.4, nsentences=32, sample_size=1095.4, sample_size_v1=0, sample_size_v2=0, ppl=2.2, wps=283.7, ups=0.26, wpb=1095.4, bsz=32, num_updates=41260, lr=2.19069e-06, gnorm=18.927, clip=100, loss_scale=16, train_wall=39, gb_free=7.9, wall=159123
2023-05-22 14:10:04 - progress_bar.py[line:272] - INFO: epoch 024:   1509 / 1732 loss=2.321, loss_v1=0, loss_v2=0, nll_loss=1.114, ntokens=1114.3, nsentences=32, sample_size=1114.3, sample_size_v1=0, sample_size_v2=0, ppl=2.16, wps=289, ups=0.26, wpb=1114.3, bsz=32, num_updates=41270, lr=2.18865e-06, gnorm=19.643, clip=100, loss_scale=16, train_wall=39, gb_free=8.4, wall=159161
2023-05-22 14:10:43 - progress_bar.py[line:272] - INFO: epoch 024:   1519 / 1732 loss=2.391, loss_v1=0, loss_v2=0, nll_loss=1.19, ntokens=1050.9, nsentences=32, sample_size=1050.9, sample_size_v1=0, sample_size_v2=0, ppl=2.28, wps=272.1, ups=0.26, wpb=1050.9, bsz=32, num_updates=41280, lr=2.1866e-06, gnorm=18.888, clip=100, loss_scale=16, train_wall=39, gb_free=8.6, wall=159200
2023-05-22 14:11:21 - progress_bar.py[line:272] - INFO: epoch 024:   1529 / 1732 loss=2.399, loss_v1=0, loss_v2=0, nll_loss=1.199, ntokens=1056.3, nsentences=32, sample_size=1056.3, sample_size_v1=0, sample_size_v2=0, ppl=2.3, wps=272.9, ups=0.26, wpb=1056.3, bsz=32, num_updates=41290, lr=2.18455e-06, gnorm=18.834, clip=100, loss_scale=16, train_wall=39, gb_free=8.2, wall=159238
2023-05-22 14:12:00 - progress_bar.py[line:272] - INFO: epoch 024:   1539 / 1732 loss=2.368, loss_v1=0, loss_v2=0, nll_loss=1.166, ntokens=1083.3, nsentences=32, sample_size=1083.3, sample_size_v1=0, sample_size_v2=0, ppl=2.24, wps=279.2, ups=0.26, wpb=1083.3, bsz=32, num_updates=41300, lr=2.1825e-06, gnorm=19.372, clip=100, loss_scale=16, train_wall=39, gb_free=8.1, wall=159277
2023-05-22 14:12:38 - progress_bar.py[line:272] - INFO: epoch 024:   1549 / 1732 loss=2.338, loss_v1=0, loss_v2=0, nll_loss=1.131, ntokens=1075, nsentences=32, sample_size=1075, sample_size_v1=0, sample_size_v2=0, ppl=2.19, wps=279.8, ups=0.26, wpb=1075, bsz=32, num_updates=41310, lr=2.18046e-06, gnorm=17.899, clip=100, loss_scale=16, train_wall=38, gb_free=8.7, wall=159316
2023-05-22 14:13:18 - progress_bar.py[line:272] - INFO: epoch 024:   1559 / 1732 loss=2.363, loss_v1=0, loss_v2=0, nll_loss=1.16, ntokens=1092, nsentences=32, sample_size=1092, sample_size_v1=0, sample_size_v2=0, ppl=2.23, wps=279.5, ups=0.26, wpb=1092, bsz=32, num_updates=41320, lr=2.17841e-06, gnorm=19.65, clip=100, loss_scale=16, train_wall=39, gb_free=8.5, wall=159355
2023-05-22 14:13:56 - progress_bar.py[line:272] - INFO: epoch 024:   1569 / 1732 loss=2.4, loss_v1=0, loss_v2=0, nll_loss=1.201, ntokens=1059.1, nsentences=32, sample_size=1059.1, sample_size_v1=0, sample_size_v2=0, ppl=2.3, wps=271.9, ups=0.26, wpb=1059.1, bsz=32, num_updates=41330, lr=2.17636e-06, gnorm=20.274, clip=100, loss_scale=16, train_wall=39, gb_free=8, wall=159394
2023-05-22 14:14:35 - progress_bar.py[line:272] - INFO: epoch 024:   1579 / 1732 loss=2.392, loss_v1=0, loss_v2=0, nll_loss=1.193, ntokens=1008.7, nsentences=32, sample_size=1008.7, sample_size_v1=0, sample_size_v2=0, ppl=2.29, wps=260.4, ups=0.26, wpb=1008.7, bsz=32, num_updates=41340, lr=2.17431e-06, gnorm=21.523, clip=100, loss_scale=16, train_wall=39, gb_free=8.3, wall=159432
2023-05-22 14:15:14 - progress_bar.py[line:272] - INFO: epoch 024:   1589 / 1732 loss=2.37, loss_v1=0, loss_v2=0, nll_loss=1.168, ntokens=1092.2, nsentences=32, sample_size=1092.2, sample_size_v1=0, sample_size_v2=0, ppl=2.25, wps=280.8, ups=0.26, wpb=1092.2, bsz=32, num_updates=41350, lr=2.17227e-06, gnorm=19.852, clip=100, loss_scale=16, train_wall=39, gb_free=8.6, wall=159471
2023-05-22 14:15:53 - progress_bar.py[line:272] - INFO: epoch 024:   1599 / 1732 loss=2.35, loss_v1=0, loss_v2=0, nll_loss=1.145, ntokens=1061.1, nsentences=32, sample_size=1061.1, sample_size_v1=0, sample_size_v2=0, ppl=2.21, wps=275.1, ups=0.26, wpb=1061.1, bsz=32, num_updates=41360, lr=2.17022e-06, gnorm=19.878, clip=100, loss_scale=16, train_wall=39, gb_free=8.4, wall=159510
2023-05-22 14:16:32 - progress_bar.py[line:272] - INFO: epoch 024:   1609 / 1732 loss=2.34, loss_v1=0, loss_v2=0, nll_loss=1.135, ntokens=1155.5, nsentences=32, sample_size=1155.5, sample_size_v1=0, sample_size_v2=0, ppl=2.2, wps=296, ups=0.26, wpb=1155.5, bsz=32, num_updates=41370, lr=2.16817e-06, gnorm=19.834, clip=100, loss_scale=16, train_wall=39, gb_free=7.8, wall=159549
2023-05-22 14:17:11 - progress_bar.py[line:272] - INFO: epoch 024:   1619 / 1732 loss=2.314, loss_v1=0, loss_v2=0, nll_loss=1.105, ntokens=1123.8, nsentences=32, sample_size=1123.8, sample_size_v1=0, sample_size_v2=0, ppl=2.15, wps=288.1, ups=0.26, wpb=1123.8, bsz=32, num_updates=41380, lr=2.16612e-06, gnorm=17.841, clip=100, loss_scale=16, train_wall=39, gb_free=8, wall=159588
2023-05-22 14:17:50 - progress_bar.py[line:272] - INFO: epoch 024:   1629 / 1732 loss=2.358, loss_v1=0, loss_v2=0, nll_loss=1.155, ntokens=1172.3, nsentences=32, sample_size=1172.3, sample_size_v1=0, sample_size_v2=0, ppl=2.23, wps=299.8, ups=0.26, wpb=1172.3, bsz=32, num_updates=41390, lr=2.16408e-06, gnorm=18.369, clip=100, loss_scale=16, train_wall=39, gb_free=8.3, wall=159627
2023-05-22 14:18:28 - progress_bar.py[line:272] - INFO: epoch 024:   1639 / 1732 loss=2.334, loss_v1=0, loss_v2=0, nll_loss=1.127, ntokens=1139.8, nsentences=32, sample_size=1139.8, sample_size_v1=0, sample_size_v2=0, ppl=2.18, wps=296.1, ups=0.26, wpb=1139.8, bsz=32, num_updates=41400, lr=2.16203e-06, gnorm=18.823, clip=100, loss_scale=16, train_wall=38, gb_free=7.8, wall=159666
2023-05-22 14:19:07 - progress_bar.py[line:272] - INFO: epoch 024:   1649 / 1732 loss=2.33, loss_v1=0, loss_v2=0, nll_loss=1.123, ntokens=1200.9, nsentences=32, sample_size=1200.9, sample_size_v1=0, sample_size_v2=0, ppl=2.18, wps=307.5, ups=0.26, wpb=1200.9, bsz=32, num_updates=41410, lr=2.15998e-06, gnorm=17.913, clip=100, loss_scale=16, train_wall=39, gb_free=8.5, wall=159705
2023-05-22 14:19:46 - progress_bar.py[line:272] - INFO: epoch 024:   1659 / 1732 loss=2.384, loss_v1=0, loss_v2=0, nll_loss=1.183, ntokens=965.2, nsentences=32, sample_size=965.2, sample_size_v1=0, sample_size_v2=0, ppl=2.27, wps=252, ups=0.26, wpb=965.2, bsz=32, num_updates=41420, lr=2.15793e-06, gnorm=20.967, clip=100, loss_scale=16, train_wall=38, gb_free=8.6, wall=159743
2023-05-22 14:20:24 - progress_bar.py[line:272] - INFO: epoch 024:   1669 / 1732 loss=2.35, loss_v1=0, loss_v2=0, nll_loss=1.145, ntokens=1018.2, nsentences=32, sample_size=1018.2, sample_size_v1=0, sample_size_v2=0, ppl=2.21, wps=263.9, ups=0.26, wpb=1018.2, bsz=32, num_updates=41430, lr=2.15589e-06, gnorm=20.535, clip=100, loss_scale=16, train_wall=39, gb_free=9, wall=159782
2023-05-22 14:21:03 - progress_bar.py[line:272] - INFO: epoch 024:   1679 / 1732 loss=2.311, loss_v1=0, loss_v2=0, nll_loss=1.101, ntokens=1155.9, nsentences=32, sample_size=1155.9, sample_size_v1=0, sample_size_v2=0, ppl=2.14, wps=296, ups=0.26, wpb=1155.9, bsz=32, num_updates=41440, lr=2.15384e-06, gnorm=18.14, clip=100, loss_scale=16, train_wall=39, gb_free=8, wall=159821
2023-05-22 14:21:43 - progress_bar.py[line:272] - INFO: epoch 024:   1689 / 1732 loss=2.348, loss_v1=0, loss_v2=0, nll_loss=1.142, ntokens=1198.6, nsentences=32, sample_size=1198.6, sample_size_v1=0, sample_size_v2=0, ppl=2.21, wps=305.8, ups=0.26, wpb=1198.6, bsz=32, num_updates=41450, lr=2.15179e-06, gnorm=17.151, clip=100, loss_scale=16, train_wall=39, gb_free=7.4, wall=159860
2023-05-22 14:22:22 - progress_bar.py[line:272] - INFO: epoch 024:   1699 / 1732 loss=2.331, loss_v1=0, loss_v2=0, nll_loss=1.125, ntokens=1300, nsentences=32, sample_size=1300, sample_size_v1=0, sample_size_v2=0, ppl=2.18, wps=329.3, ups=0.25, wpb=1300, bsz=32, num_updates=41460, lr=2.14975e-06, gnorm=18.335, clip=100, loss_scale=16, train_wall=39, gb_free=7.8, wall=159899
2023-05-22 14:23:01 - progress_bar.py[line:272] - INFO: epoch 024:   1709 / 1732 loss=2.369, loss_v1=0, loss_v2=0, nll_loss=1.167, ntokens=1178.3, nsentences=32, sample_size=1178.3, sample_size_v1=0, sample_size_v2=0, ppl=2.24, wps=300.7, ups=0.26, wpb=1178.3, bsz=32, num_updates=41470, lr=2.1477e-06, gnorm=17.96, clip=100, loss_scale=16, train_wall=39, gb_free=8.5, wall=159938
2023-05-22 14:23:40 - progress_bar.py[line:272] - INFO: epoch 024:   1719 / 1732 loss=2.328, loss_v1=0, loss_v2=0, nll_loss=1.121, ntokens=1171.3, nsentences=32, sample_size=1171.3, sample_size_v1=0, sample_size_v2=0, ppl=2.17, wps=299.4, ups=0.26, wpb=1171.3, bsz=32, num_updates=41480, lr=2.14565e-06, gnorm=17.162, clip=100, loss_scale=16, train_wall=39, gb_free=8.1, wall=159978
2023-05-22 14:24:19 - progress_bar.py[line:272] - INFO: epoch 024:   1729 / 1732 loss=2.384, loss_v1=0, loss_v2=0, nll_loss=1.183, ntokens=1095.7, nsentences=32, sample_size=1095.7, sample_size_v1=0, sample_size_v2=0, ppl=2.27, wps=282.3, ups=0.26, wpb=1095.7, bsz=32, num_updates=41490, lr=2.1436e-06, gnorm=18.773, clip=100, loss_scale=16, train_wall=39, gb_free=8.4, wall=160016
2023-05-22 14:24:28 - train.py[line:332] - INFO: end of epoch 24 (average epoch stats below)
2023-05-22 14:24:28 - progress_bar.py[line:282] - INFO: epoch 024 | loss 2.366 | loss_v1 0 | loss_v2 0 | nll_loss 1.163 | ntokens 1051.4 | nsentences 31.986 | sample_size 1051.4 | sample_size_v1 0 | sample_size_v2 0 | ppl 2.24 | wps 273.2 | ups 0.26 | wpb 1051.4 | bsz 32 | num_updates 41493 | lr 2.14299e-06 | gnorm 19.709 | clip 100 | loss_scale 16 | train_wall 6639 | gb_free 8.9 | wall 160025
2023-05-22 14:24:28 - trainer.py[line:639] - INFO: loading train data for epoch 25
local datafile ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 0 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 0 finished initializing row_count and line_idx-to-offset mapping
file ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 0 row count 55400 total row count 55400
slice_id 0 seek offset 0
2023-05-22 14:24:30 - trainer.py[line:703] - INFO: begin training epoch 25
2023-05-22 14:24:30 - train.py[line:305] - INFO: Start iterating over samples
2023-05-22 14:24:57 - progress_bar.py[line:272] - INFO: epoch 025:      7 / 1732 loss=2.301, loss_v1=0, loss_v2=0, nll_loss=1.092, ntokens=1093.3, nsentences=29.6, sample_size=1093.3, sample_size_v1=0, sample_size_v2=0, ppl=2.13, wps=287.3, ups=0.26, wpb=1093.3, bsz=29.6, num_updates=41500, lr=2.14156e-06, gnorm=19.226, clip=100, loss_scale=16, train_wall=36, gb_free=8.4, wall=160054
2023-05-22 14:25:36 - progress_bar.py[line:272] - INFO: epoch 025:     17 / 1732 loss=2.284, loss_v1=0, loss_v2=0, nll_loss=1.069, ntokens=1095.7, nsentences=32, sample_size=1095.7, sample_size_v1=0, sample_size_v2=0, ppl=2.1, wps=281.7, ups=0.26, wpb=1095.7, bsz=32, num_updates=41510, lr=2.13951e-06, gnorm=20.384, clip=100, loss_scale=16, train_wall=39, gb_free=8.2, wall=160093
2023-05-22 14:26:15 - progress_bar.py[line:272] - INFO: epoch 025:     27 / 1732 loss=2.316, loss_v1=0, loss_v2=0, nll_loss=1.107, ntokens=954.5, nsentences=32, sample_size=954.5, sample_size_v1=0, sample_size_v2=0, ppl=2.15, wps=246, ups=0.26, wpb=954.5, bsz=32, num_updates=41520, lr=2.13746e-06, gnorm=19.264, clip=100, loss_scale=16, train_wall=39, gb_free=7.9, wall=160132
2023-05-22 14:26:54 - progress_bar.py[line:272] - INFO: epoch 025:     37 / 1732 loss=2.148, loss_v1=0, loss_v2=0, nll_loss=0.918, ntokens=1179.3, nsentences=32, sample_size=1179.3, sample_size_v1=0, sample_size_v2=0, ppl=1.89, wps=299.5, ups=0.25, wpb=1179.3, bsz=32, num_updates=41530, lr=2.13541e-06, gnorm=14.428, clip=100, loss_scale=16, train_wall=39, gb_free=8.5, wall=160172
2023-05-22 14:27:33 - progress_bar.py[line:272] - INFO: epoch 025:     47 / 1732 loss=2.179, loss_v1=0, loss_v2=0, nll_loss=0.954, ntokens=1055.1, nsentences=32, sample_size=1055.1, sample_size_v1=0, sample_size_v2=0, ppl=1.94, wps=272.5, ups=0.26, wpb=1055.1, bsz=32, num_updates=41540, lr=2.13337e-06, gnorm=15.214, clip=100, loss_scale=16, train_wall=39, gb_free=7.9, wall=160210
2023-05-22 14:28:12 - progress_bar.py[line:272] - INFO: epoch 025:     57 / 1732 loss=2.096, loss_v1=0, loss_v2=0, nll_loss=0.862, ntokens=1048.7, nsentences=32, sample_size=1048.7, sample_size_v1=0, sample_size_v2=0, ppl=1.82, wps=270.1, ups=0.26, wpb=1048.7, bsz=32, num_updates=41550, lr=2.13132e-06, gnorm=16.201, clip=100, loss_scale=16, train_wall=39, gb_free=8.4, wall=160249
2023-05-22 14:28:52 - progress_bar.py[line:272] - INFO: epoch 025:     67 / 1732 loss=1.999, loss_v1=0, loss_v2=0, nll_loss=0.757, ntokens=1356.1, nsentences=32, sample_size=1356.1, sample_size_v1=0, sample_size_v2=0, ppl=1.69, wps=339.6, ups=0.25, wpb=1356.1, bsz=32, num_updates=41560, lr=2.12927e-06, gnorm=12.195, clip=100, loss_scale=16, train_wall=40, gb_free=7.3, wall=160289
2023-05-22 14:29:32 - progress_bar.py[line:272] - INFO: epoch 025:     77 / 1732 loss=2.126, loss_v1=0, loss_v2=0, nll_loss=0.897, ntokens=1273.9, nsentences=32, sample_size=1273.9, sample_size_v1=0, sample_size_v2=0, ppl=1.86, wps=318.3, ups=0.25, wpb=1273.9, bsz=32, num_updates=41570, lr=2.12722e-06, gnorm=15.853, clip=100, loss_scale=16, train_wall=40, gb_free=8.2, wall=160329
2023-05-22 14:30:11 - progress_bar.py[line:272] - INFO: epoch 025:     87 / 1732 loss=2.213, loss_v1=0, loss_v2=0, nll_loss=0.994, ntokens=1141.2, nsentences=32, sample_size=1141.2, sample_size_v1=0, sample_size_v2=0, ppl=1.99, wps=289.7, ups=0.25, wpb=1141.2, bsz=32, num_updates=41580, lr=2.12518e-06, gnorm=19.931, clip=100, loss_scale=16, train_wall=39, gb_free=7.7, wall=160368
2023-05-22 14:30:50 - progress_bar.py[line:272] - INFO: epoch 025:     97 / 1732 loss=2.163, loss_v1=0, loss_v2=0, nll_loss=0.936, ntokens=1080.1, nsentences=32, sample_size=1080.1, sample_size_v1=0, sample_size_v2=0, ppl=1.91, wps=278.1, ups=0.26, wpb=1080.1, bsz=32, num_updates=41590, lr=2.12313e-06, gnorm=20.046, clip=100, loss_scale=16, train_wall=39, gb_free=7, wall=160407
2023-05-22 14:31:29 - progress_bar.py[line:272] - INFO: epoch 025:    107 / 1732 loss=2.328, loss_v1=0, loss_v2=0, nll_loss=1.124, ntokens=981.4, nsentences=32, sample_size=981.4, sample_size_v1=0, sample_size_v2=0, ppl=2.18, wps=255.3, ups=0.26, wpb=981.4, bsz=32, num_updates=41600, lr=2.12108e-06, gnorm=23.426, clip=100, loss_scale=32, train_wall=38, gb_free=7.7, wall=160446
2023-05-22 14:32:08 - progress_bar.py[line:272] - INFO: epoch 025:    117 / 1732 loss=2.384, loss_v1=0, loss_v2=0, nll_loss=1.182, ntokens=1060.7, nsentences=32, sample_size=1060.7, sample_size_v1=0, sample_size_v2=0, ppl=2.27, wps=271.3, ups=0.26, wpb=1060.7, bsz=32, num_updates=41610, lr=2.11903e-06, gnorm=19.716, clip=100, loss_scale=32, train_wall=39, gb_free=7.7, wall=160485
2023-05-22 14:32:47 - progress_bar.py[line:272] - INFO: epoch 025:    127 / 1732 loss=2.317, loss_v1=0, loss_v2=0, nll_loss=1.104, ntokens=1185.5, nsentences=32, sample_size=1185.5, sample_size_v1=0, sample_size_v2=0, ppl=2.15, wps=300.9, ups=0.25, wpb=1185.5, bsz=32, num_updates=41620, lr=2.11699e-06, gnorm=18.311, clip=100, loss_scale=32, train_wall=39, gb_free=8.2, wall=160524
2023-05-22 14:33:26 - progress_bar.py[line:272] - INFO: epoch 025:    137 / 1732 loss=2.288, loss_v1=0, loss_v2=0, nll_loss=1.075, ntokens=1222.2, nsentences=32, sample_size=1222.2, sample_size_v1=0, sample_size_v2=0, ppl=2.11, wps=311.8, ups=0.26, wpb=1222.2, bsz=32, num_updates=41630, lr=2.11494e-06, gnorm=17.106, clip=100, loss_scale=32, train_wall=39, gb_free=8.2, wall=160563
2023-05-22 14:34:06 - progress_bar.py[line:272] - INFO: epoch 025:    147 / 1732 loss=2.242, loss_v1=0, loss_v2=0, nll_loss=1.023, ntokens=1207.1, nsentences=32, sample_size=1207.1, sample_size_v1=0, sample_size_v2=0, ppl=2.03, wps=305.1, ups=0.25, wpb=1207.1, bsz=32, num_updates=41640, lr=2.11289e-06, gnorm=16.51, clip=100, loss_scale=32, train_wall=40, gb_free=8, wall=160603
2023-05-22 14:34:46 - progress_bar.py[line:272] - INFO: epoch 025:    157 / 1732 loss=2.295, loss_v1=0, loss_v2=0, nll_loss=1.083, ntokens=1172.8, nsentences=32, sample_size=1172.8, sample_size_v1=0, sample_size_v2=0, ppl=2.12, wps=295.2, ups=0.25, wpb=1172.8, bsz=32, num_updates=41650, lr=2.11084e-06, gnorm=17.536, clip=100, loss_scale=32, train_wall=40, gb_free=8, wall=160643
2023-05-22 14:35:25 - progress_bar.py[line:272] - INFO: epoch 025:    167 / 1732 loss=2.27, loss_v1=0, loss_v2=0, nll_loss=1.056, ntokens=1009.5, nsentences=32, sample_size=1009.5, sample_size_v1=0, sample_size_v2=0, ppl=2.08, wps=259, ups=0.26, wpb=1009.5, bsz=32, num_updates=41660, lr=2.1088e-06, gnorm=19.286, clip=100, loss_scale=32, train_wall=39, gb_free=7.3, wall=160682
2023-05-22 14:36:03 - progress_bar.py[line:272] - INFO: epoch 025:    177 / 1732 loss=2.278, loss_v1=0, loss_v2=0, nll_loss=1.065, ntokens=994.5, nsentences=32, sample_size=994.5, sample_size_v1=0, sample_size_v2=0, ppl=2.09, wps=256.2, ups=0.26, wpb=994.5, bsz=32, num_updates=41670, lr=2.10675e-06, gnorm=20.508, clip=100, loss_scale=32, train_wall=39, gb_free=8, wall=160721
2023-05-22 14:36:43 - progress_bar.py[line:272] - INFO: epoch 025:    187 / 1732 loss=2.224, loss_v1=0, loss_v2=0, nll_loss=1.005, ntokens=1141.8, nsentences=32, sample_size=1141.8, sample_size_v1=0, sample_size_v2=0, ppl=2.01, wps=289.4, ups=0.25, wpb=1141.8, bsz=32, num_updates=41680, lr=2.1047e-06, gnorm=16.769, clip=100, loss_scale=32, train_wall=39, gb_free=7.6, wall=160760
2023-05-22 14:37:22 - progress_bar.py[line:272] - INFO: epoch 025:    197 / 1732 loss=2.292, loss_v1=0, loss_v2=0, nll_loss=1.082, ntokens=1173.2, nsentences=32, sample_size=1173.2, sample_size_v1=0, sample_size_v2=0, ppl=2.12, wps=296.1, ups=0.25, wpb=1173.2, bsz=32, num_updates=41690, lr=2.10266e-06, gnorm=16.448, clip=100, loss_scale=32, train_wall=40, gb_free=8.5, wall=160800
2023-05-22 14:38:01 - progress_bar.py[line:272] - INFO: epoch 025:    207 / 1732 loss=2.383, loss_v1=0, loss_v2=0, nll_loss=1.183, ntokens=957.1, nsentences=32, sample_size=957.1, sample_size_v1=0, sample_size_v2=0, ppl=2.27, wps=250.1, ups=0.26, wpb=957.1, bsz=32, num_updates=41700, lr=2.10061e-06, gnorm=20.585, clip=100, loss_scale=32, train_wall=38, gb_free=7.8, wall=160838
2023-05-22 14:38:39 - progress_bar.py[line:272] - INFO: epoch 025:    217 / 1732 loss=2.392, loss_v1=0, loss_v2=0, nll_loss=1.194, ntokens=1157.1, nsentences=32, sample_size=1157.1, sample_size_v1=0, sample_size_v2=0, ppl=2.29, wps=299.1, ups=0.26, wpb=1157.1, bsz=32, num_updates=41710, lr=2.09856e-06, gnorm=17.787, clip=100, loss_scale=32, train_wall=39, gb_free=8.4, wall=160877
2023-05-22 14:39:18 - progress_bar.py[line:272] - INFO: epoch 025:    227 / 1732 loss=2.384, loss_v1=0, loss_v2=0, nll_loss=1.184, ntokens=1106.8, nsentences=32, sample_size=1106.8, sample_size_v1=0, sample_size_v2=0, ppl=2.27, wps=287, ups=0.26, wpb=1106.8, bsz=32, num_updates=41720, lr=2.09651e-06, gnorm=18.79, clip=100, loss_scale=32, train_wall=39, gb_free=8, wall=160915
2023-05-22 14:39:56 - progress_bar.py[line:272] - INFO: epoch 025:    237 / 1732 loss=2.442, loss_v1=0, loss_v2=0, nll_loss=1.248, ntokens=1060.1, nsentences=32, sample_size=1060.1, sample_size_v1=0, sample_size_v2=0, ppl=2.37, wps=277.9, ups=0.26, wpb=1060.1, bsz=32, num_updates=41730, lr=2.09447e-06, gnorm=20.922, clip=100, loss_scale=32, train_wall=38, gb_free=7.8, wall=160953
2023-05-22 14:40:35 - progress_bar.py[line:272] - INFO: epoch 025:    247 / 1732 loss=2.403, loss_v1=0, loss_v2=0, nll_loss=1.205, ntokens=1188.4, nsentences=32, sample_size=1188.4, sample_size_v1=0, sample_size_v2=0, ppl=2.3, wps=307.9, ups=0.26, wpb=1188.4, bsz=32, num_updates=41740, lr=2.09242e-06, gnorm=18.448, clip=100, loss_scale=32, train_wall=39, gb_free=8.1, wall=160992
2023-05-22 14:41:13 - progress_bar.py[line:272] - INFO: epoch 025:    257 / 1732 loss=2.406, loss_v1=0, loss_v2=0, nll_loss=1.208, ntokens=1118.5, nsentences=32, sample_size=1118.5, sample_size_v1=0, sample_size_v2=0, ppl=2.31, wps=288.6, ups=0.26, wpb=1118.5, bsz=32, num_updates=41750, lr=2.09037e-06, gnorm=20.808, clip=100, loss_scale=32, train_wall=39, gb_free=8.4, wall=161031
2023-05-22 14:41:52 - progress_bar.py[line:272] - INFO: epoch 025:    267 / 1732 loss=2.394, loss_v1=0, loss_v2=0, nll_loss=1.193, ntokens=1162.2, nsentences=32, sample_size=1162.2, sample_size_v1=0, sample_size_v2=0, ppl=2.29, wps=301.5, ups=0.26, wpb=1162.2, bsz=32, num_updates=41760, lr=2.08832e-06, gnorm=18.68, clip=100, loss_scale=32, train_wall=39, gb_free=8.4, wall=161069
2023-05-22 14:42:31 - progress_bar.py[line:272] - INFO: epoch 025:    277 / 1732 loss=2.407, loss_v1=0, loss_v2=0, nll_loss=1.208, ntokens=1137.3, nsentences=32, sample_size=1137.3, sample_size_v1=0, sample_size_v2=0, ppl=2.31, wps=293.8, ups=0.26, wpb=1137.3, bsz=32, num_updates=41770, lr=2.08628e-06, gnorm=18.422, clip=100, loss_scale=32, train_wall=39, gb_free=8.4, wall=161108
2023-05-22 14:43:09 - progress_bar.py[line:272] - INFO: epoch 025:    287 / 1732 loss=2.393, loss_v1=0, loss_v2=0, nll_loss=1.193, ntokens=1149.1, nsentences=32, sample_size=1149.1, sample_size_v1=0, sample_size_v2=0, ppl=2.29, wps=298.4, ups=0.26, wpb=1149.1, bsz=32, num_updates=41780, lr=2.08423e-06, gnorm=19.242, clip=100, loss_scale=32, train_wall=38, gb_free=8.2, wall=161146
2023-05-22 14:43:47 - progress_bar.py[line:272] - INFO: epoch 025:    297 / 1732 loss=2.402, loss_v1=0, loss_v2=0, nll_loss=1.204, ntokens=1120.1, nsentences=32, sample_size=1120.1, sample_size_v1=0, sample_size_v2=0, ppl=2.3, wps=292.9, ups=0.26, wpb=1120.1, bsz=32, num_updates=41790, lr=2.08218e-06, gnorm=19.523, clip=100, loss_scale=32, train_wall=38, gb_free=8, wall=161185
2023-05-22 14:44:26 - progress_bar.py[line:272] - INFO: epoch 025:    307 / 1732 loss=2.382, loss_v1=0, loss_v2=0, nll_loss=1.181, ntokens=1063.6, nsentences=32, sample_size=1063.6, sample_size_v1=0, sample_size_v2=0, ppl=2.27, wps=277.8, ups=0.26, wpb=1063.6, bsz=32, num_updates=41800, lr=2.08013e-06, gnorm=20.648, clip=100, loss_scale=32, train_wall=38, gb_free=9.2, wall=161223
2023-05-22 14:45:04 - progress_bar.py[line:272] - INFO: epoch 025:    317 / 1732 loss=2.408, loss_v1=0, loss_v2=0, nll_loss=1.209, ntokens=1045.4, nsentences=32, sample_size=1045.4, sample_size_v1=0, sample_size_v2=0, ppl=2.31, wps=272.9, ups=0.26, wpb=1045.4, bsz=32, num_updates=41810, lr=2.07809e-06, gnorm=20.3, clip=100, loss_scale=32, train_wall=38, gb_free=8.7, wall=161261
2023-05-22 14:45:42 - progress_bar.py[line:272] - INFO: epoch 025:    327 / 1732 loss=2.426, loss_v1=0, loss_v2=0, nll_loss=1.229, ntokens=1029.3, nsentences=32, sample_size=1029.3, sample_size_v1=0, sample_size_v2=0, ppl=2.34, wps=270.7, ups=0.26, wpb=1029.3, bsz=32, num_updates=41820, lr=2.07604e-06, gnorm=20.195, clip=100, loss_scale=32, train_wall=38, gb_free=8.5, wall=161299
2023-05-22 14:46:20 - progress_bar.py[line:272] - INFO: epoch 025:    337 / 1732 loss=2.394, loss_v1=0, loss_v2=0, nll_loss=1.194, ntokens=970.5, nsentences=32, sample_size=970.5, sample_size_v1=0, sample_size_v2=0, ppl=2.29, wps=255.8, ups=0.26, wpb=970.5, bsz=32, num_updates=41830, lr=2.07399e-06, gnorm=19.544, clip=100, loss_scale=32, train_wall=38, gb_free=8, wall=161337
2023-05-22 14:46:50 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2023-05-22 14:47:02 - progress_bar.py[line:272] - INFO: epoch 025:    348 / 1732 loss=2.397, loss_v1=0, loss_v2=0, nll_loss=1.197, ntokens=923.7, nsentences=32, sample_size=923.7, sample_size_v1=0, sample_size_v2=0, ppl=2.29, wps=222.8, ups=0.24, wpb=923.7, bsz=32, num_updates=41840, lr=2.07194e-06, gnorm=21.787, clip=100, loss_scale=16, train_wall=41, gb_free=8.8, wall=161379
2023-05-22 14:47:39 - progress_bar.py[line:272] - INFO: epoch 025:    358 / 1732 loss=2.428, loss_v1=0, loss_v2=0, nll_loss=1.231, ntokens=943, nsentences=32, sample_size=943, sample_size_v1=0, sample_size_v2=0, ppl=2.35, wps=249.6, ups=0.26, wpb=943, bsz=32, num_updates=41850, lr=2.0699e-06, gnorm=22.625, clip=100, loss_scale=16, train_wall=38, gb_free=9.1, wall=161416
2023-05-22 14:48:17 - progress_bar.py[line:272] - INFO: epoch 025:    368 / 1732 loss=2.44, loss_v1=0, loss_v2=0, nll_loss=1.246, ntokens=960.6, nsentences=32, sample_size=960.6, sample_size_v1=0, sample_size_v2=0, ppl=2.37, wps=253.1, ups=0.26, wpb=960.6, bsz=32, num_updates=41860, lr=2.06785e-06, gnorm=23.131, clip=100, loss_scale=16, train_wall=38, gb_free=8.6, wall=161454
2023-05-22 14:48:55 - progress_bar.py[line:272] - INFO: epoch 025:    378 / 1732 loss=2.437, loss_v1=0, loss_v2=0, nll_loss=1.242, ntokens=1043.2, nsentences=32, sample_size=1043.2, sample_size_v1=0, sample_size_v2=0, ppl=2.37, wps=273.8, ups=0.26, wpb=1043.2, bsz=32, num_updates=41870, lr=2.0658e-06, gnorm=19.445, clip=100, loss_scale=16, train_wall=38, gb_free=9.1, wall=161493
2023-05-22 14:49:34 - progress_bar.py[line:272] - INFO: epoch 025:    388 / 1732 loss=2.401, loss_v1=0, loss_v2=0, nll_loss=1.202, ntokens=1053.2, nsentences=32, sample_size=1053.2, sample_size_v1=0, sample_size_v2=0, ppl=2.3, wps=274.8, ups=0.26, wpb=1053.2, bsz=32, num_updates=41880, lr=2.06376e-06, gnorm=20.032, clip=100, loss_scale=16, train_wall=38, gb_free=8.3, wall=161531
2023-05-22 14:50:12 - progress_bar.py[line:272] - INFO: epoch 025:    398 / 1732 loss=2.415, loss_v1=0, loss_v2=0, nll_loss=1.215, ntokens=977.4, nsentences=32, sample_size=977.4, sample_size_v1=0, sample_size_v2=0, ppl=2.32, wps=256.3, ups=0.26, wpb=977.4, bsz=32, num_updates=41890, lr=2.06171e-06, gnorm=21.093, clip=100, loss_scale=16, train_wall=38, gb_free=8, wall=161569
2023-05-22 14:50:50 - progress_bar.py[line:272] - INFO: epoch 025:    408 / 1732 loss=2.388, loss_v1=0, loss_v2=0, nll_loss=1.186, ntokens=1058.6, nsentences=32, sample_size=1058.6, sample_size_v1=0, sample_size_v2=0, ppl=2.28, wps=275, ups=0.26, wpb=1058.6, bsz=32, num_updates=41900, lr=2.05966e-06, gnorm=18.42, clip=100, loss_scale=16, train_wall=38, gb_free=8.6, wall=161608
2023-05-22 14:51:28 - progress_bar.py[line:272] - INFO: epoch 025:    418 / 1732 loss=2.368, loss_v1=0, loss_v2=0, nll_loss=1.166, ntokens=1021.6, nsentences=32, sample_size=1021.6, sample_size_v1=0, sample_size_v2=0, ppl=2.24, wps=268, ups=0.26, wpb=1021.6, bsz=32, num_updates=41910, lr=2.05761e-06, gnorm=20.238, clip=100, loss_scale=16, train_wall=38, gb_free=8, wall=161646
2023-05-22 14:52:07 - progress_bar.py[line:272] - INFO: epoch 025:    428 / 1732 loss=2.378, loss_v1=0, loss_v2=0, nll_loss=1.177, ntokens=1016.5, nsentences=32, sample_size=1016.5, sample_size_v1=0, sample_size_v2=0, ppl=2.26, wps=265.5, ups=0.26, wpb=1016.5, bsz=32, num_updates=41920, lr=2.05557e-06, gnorm=21.884, clip=100, loss_scale=16, train_wall=38, gb_free=8.5, wall=161684
2023-05-22 14:52:45 - progress_bar.py[line:272] - INFO: epoch 025:    438 / 1732 loss=2.403, loss_v1=0, loss_v2=0, nll_loss=1.204, ntokens=1018.5, nsentences=32, sample_size=1018.5, sample_size_v1=0, sample_size_v2=0, ppl=2.3, wps=268.4, ups=0.26, wpb=1018.5, bsz=32, num_updates=41930, lr=2.05352e-06, gnorm=19.421, clip=100, loss_scale=16, train_wall=38, gb_free=8.9, wall=161722
2023-05-22 14:53:23 - progress_bar.py[line:272] - INFO: epoch 025:    448 / 1732 loss=2.427, loss_v1=0, loss_v2=0, nll_loss=1.231, ntokens=946.6, nsentences=32, sample_size=946.6, sample_size_v1=0, sample_size_v2=0, ppl=2.35, wps=248.8, ups=0.26, wpb=946.6, bsz=32, num_updates=41940, lr=2.05147e-06, gnorm=23.174, clip=100, loss_scale=16, train_wall=38, gb_free=8.6, wall=161760
2023-05-22 14:54:01 - progress_bar.py[line:272] - INFO: epoch 025:    458 / 1732 loss=2.419, loss_v1=0, loss_v2=0, nll_loss=1.222, ntokens=971.2, nsentences=32, sample_size=971.2, sample_size_v1=0, sample_size_v2=0, ppl=2.33, wps=256.2, ups=0.26, wpb=971.2, bsz=32, num_updates=41950, lr=2.04942e-06, gnorm=20.417, clip=100, loss_scale=16, train_wall=38, gb_free=8.9, wall=161798
2023-05-22 14:54:39 - progress_bar.py[line:272] - INFO: epoch 025:    468 / 1732 loss=2.416, loss_v1=0, loss_v2=0, nll_loss=1.217, ntokens=1064.3, nsentences=32, sample_size=1064.3, sample_size_v1=0, sample_size_v2=0, ppl=2.32, wps=278.7, ups=0.26, wpb=1064.3, bsz=32, num_updates=41960, lr=2.04738e-06, gnorm=20.643, clip=100, loss_scale=16, train_wall=38, gb_free=8.3, wall=161836
2023-05-22 14:55:17 - progress_bar.py[line:272] - INFO: epoch 025:    478 / 1732 loss=2.446, loss_v1=0, loss_v2=0, nll_loss=1.251, ntokens=1027.7, nsentences=32, sample_size=1027.7, sample_size_v1=0, sample_size_v2=0, ppl=2.38, wps=269.9, ups=0.26, wpb=1027.7, bsz=32, num_updates=41970, lr=2.04533e-06, gnorm=20.717, clip=100, loss_scale=16, train_wall=38, gb_free=8.9, wall=161874
2023-05-22 14:55:55 - progress_bar.py[line:272] - INFO: epoch 025:    488 / 1732 loss=2.381, loss_v1=0, loss_v2=0, nll_loss=1.177, ntokens=925.6, nsentences=32, sample_size=925.6, sample_size_v1=0, sample_size_v2=0, ppl=2.26, wps=245, ups=0.26, wpb=925.6, bsz=32, num_updates=41980, lr=2.04328e-06, gnorm=21.195, clip=100, loss_scale=16, train_wall=38, gb_free=9.2, wall=161912
2023-05-22 14:56:33 - progress_bar.py[line:272] - INFO: epoch 025:    498 / 1732 loss=2.398, loss_v1=0, loss_v2=0, nll_loss=1.199, ntokens=952.7, nsentences=32, sample_size=952.7, sample_size_v1=0, sample_size_v2=0, ppl=2.3, wps=251.6, ups=0.26, wpb=952.7, bsz=32, num_updates=41990, lr=2.04123e-06, gnorm=20.812, clip=100, loss_scale=16, train_wall=38, gb_free=9.3, wall=161950
2023-05-22 14:57:10 - progress_bar.py[line:272] - INFO: epoch 025:    508 / 1732 loss=2.416, loss_v1=0, loss_v2=0, nll_loss=1.217, ntokens=1034.3, nsentences=32, sample_size=1034.3, sample_size_v1=0, sample_size_v2=0, ppl=2.32, wps=273.2, ups=0.26, wpb=1034.3, bsz=32, num_updates=42000, lr=2.03919e-06, gnorm=20.502, clip=100, loss_scale=16, train_wall=38, gb_free=8.7, wall=161988
2023-05-22 14:57:48 - progress_bar.py[line:272] - INFO: epoch 025:    518 / 1732 loss=2.408, loss_v1=0, loss_v2=0, nll_loss=1.208, ntokens=1032.2, nsentences=32, sample_size=1032.2, sample_size_v1=0, sample_size_v2=0, ppl=2.31, wps=272.7, ups=0.26, wpb=1032.2, bsz=32, num_updates=42010, lr=2.03714e-06, gnorm=19.459, clip=100, loss_scale=16, train_wall=38, gb_free=8.9, wall=162025
2023-05-22 14:58:26 - progress_bar.py[line:272] - INFO: epoch 025:    528 / 1732 loss=2.414, loss_v1=0, loss_v2=0, nll_loss=1.215, ntokens=941.1, nsentences=32, sample_size=941.1, sample_size_v1=0, sample_size_v2=0, ppl=2.32, wps=249.9, ups=0.27, wpb=941.1, bsz=32, num_updates=42020, lr=2.03509e-06, gnorm=22.083, clip=100, loss_scale=16, train_wall=38, gb_free=9.1, wall=162063
2023-05-22 14:59:04 - progress_bar.py[line:272] - INFO: epoch 025:    538 / 1732 loss=2.397, loss_v1=0, loss_v2=0, nll_loss=1.197, ntokens=972.3, nsentences=32, sample_size=972.3, sample_size_v1=0, sample_size_v2=0, ppl=2.29, wps=257.9, ups=0.27, wpb=972.3, bsz=32, num_updates=42030, lr=2.03304e-06, gnorm=19.926, clip=100, loss_scale=16, train_wall=38, gb_free=8.4, wall=162101
2023-05-22 14:59:42 - progress_bar.py[line:272] - INFO: epoch 025:    548 / 1732 loss=2.432, loss_v1=0, loss_v2=0, nll_loss=1.236, ntokens=1027.8, nsentences=32, sample_size=1027.8, sample_size_v1=0, sample_size_v2=0, ppl=2.36, wps=270, ups=0.26, wpb=1027.8, bsz=32, num_updates=42040, lr=2.031e-06, gnorm=20.191, clip=100, loss_scale=16, train_wall=38, gb_free=8.9, wall=162139
2023-05-22 15:00:20 - progress_bar.py[line:272] - INFO: epoch 025:    558 / 1732 loss=2.438, loss_v1=0, loss_v2=0, nll_loss=1.243, ntokens=1021.9, nsentences=32, sample_size=1021.9, sample_size_v1=0, sample_size_v2=0, ppl=2.37, wps=268.1, ups=0.26, wpb=1021.9, bsz=32, num_updates=42050, lr=2.02895e-06, gnorm=20.793, clip=100, loss_scale=16, train_wall=38, gb_free=8, wall=162177
2023-05-22 15:00:58 - progress_bar.py[line:272] - INFO: epoch 025:    568 / 1732 loss=2.449, loss_v1=0, loss_v2=0, nll_loss=1.254, ntokens=1014.9, nsentences=32, sample_size=1014.9, sample_size_v1=0, sample_size_v2=0, ppl=2.39, wps=265.4, ups=0.26, wpb=1014.9, bsz=32, num_updates=42060, lr=2.0269e-06, gnorm=20.133, clip=100, loss_scale=16, train_wall=38, gb_free=8.3, wall=162215
2023-05-22 15:01:36 - progress_bar.py[line:272] - INFO: epoch 025:    578 / 1732 loss=2.418, loss_v1=0, loss_v2=0, nll_loss=1.22, ntokens=991.4, nsentences=32, sample_size=991.4, sample_size_v1=0, sample_size_v2=0, ppl=2.33, wps=261.3, ups=0.26, wpb=991.4, bsz=32, num_updates=42070, lr=2.02486e-06, gnorm=21.707, clip=100, loss_scale=16, train_wall=38, gb_free=8.3, wall=162253
2023-05-22 15:02:14 - progress_bar.py[line:272] - INFO: epoch 025:    588 / 1732 loss=2.412, loss_v1=0, loss_v2=0, nll_loss=1.215, ntokens=965.9, nsentences=32, sample_size=965.9, sample_size_v1=0, sample_size_v2=0, ppl=2.32, wps=254.1, ups=0.26, wpb=965.9, bsz=32, num_updates=42080, lr=2.02281e-06, gnorm=20.886, clip=100, loss_scale=16, train_wall=38, gb_free=8.7, wall=162291
2023-05-22 15:02:52 - progress_bar.py[line:272] - INFO: epoch 025:    598 / 1732 loss=2.378, loss_v1=0, loss_v2=0, nll_loss=1.176, ntokens=957.4, nsentences=32, sample_size=957.4, sample_size_v1=0, sample_size_v2=0, ppl=2.26, wps=253.6, ups=0.26, wpb=957.4, bsz=32, num_updates=42090, lr=2.02076e-06, gnorm=21.172, clip=100, loss_scale=16, train_wall=38, gb_free=9.2, wall=162329
2023-05-22 15:03:30 - progress_bar.py[line:272] - INFO: epoch 025:    608 / 1732 loss=2.409, loss_v1=0, loss_v2=0, nll_loss=1.211, ntokens=893.5, nsentences=32, sample_size=893.5, sample_size_v1=0, sample_size_v2=0, ppl=2.31, wps=236.3, ups=0.26, wpb=893.5, bsz=32, num_updates=42100, lr=2.01871e-06, gnorm=23.415, clip=100, loss_scale=16, train_wall=38, gb_free=8.3, wall=162367
2023-05-22 15:04:07 - progress_bar.py[line:272] - INFO: epoch 025:    618 / 1732 loss=2.432, loss_v1=0, loss_v2=0, nll_loss=1.237, ntokens=860.2, nsentences=32, sample_size=860.2, sample_size_v1=0, sample_size_v2=0, ppl=2.36, wps=228.8, ups=0.27, wpb=860.2, bsz=32, num_updates=42110, lr=2.01667e-06, gnorm=25.272, clip=100, loss_scale=16, train_wall=38, gb_free=9, wall=162404
2023-05-22 15:04:45 - progress_bar.py[line:272] - INFO: epoch 025:    628 / 1732 loss=2.409, loss_v1=0, loss_v2=0, nll_loss=1.212, ntokens=929, nsentences=32, sample_size=929, sample_size_v1=0, sample_size_v2=0, ppl=2.32, wps=247.8, ups=0.27, wpb=929, bsz=32, num_updates=42120, lr=2.01462e-06, gnorm=24.346, clip=100, loss_scale=16, train_wall=37, gb_free=9, wall=162442
2023-05-22 15:05:22 - progress_bar.py[line:272] - INFO: epoch 025:    638 / 1732 loss=2.421, loss_v1=0, loss_v2=0, nll_loss=1.225, ntokens=921.3, nsentences=32, sample_size=921.3, sample_size_v1=0, sample_size_v2=0, ppl=2.34, wps=244, ups=0.26, wpb=921.3, bsz=32, num_updates=42130, lr=2.01257e-06, gnorm=21.67, clip=100, loss_scale=16, train_wall=38, gb_free=9, wall=162480
2023-05-22 15:06:00 - progress_bar.py[line:272] - INFO: epoch 025:    648 / 1732 loss=2.435, loss_v1=0, loss_v2=0, nll_loss=1.241, ntokens=983.5, nsentences=32, sample_size=983.5, sample_size_v1=0, sample_size_v2=0, ppl=2.36, wps=260.1, ups=0.26, wpb=983.5, bsz=32, num_updates=42140, lr=2.01052e-06, gnorm=22.067, clip=100, loss_scale=16, train_wall=38, gb_free=8.8, wall=162518
2023-05-22 15:06:38 - progress_bar.py[line:272] - INFO: epoch 025:    658 / 1732 loss=2.431, loss_v1=0, loss_v2=0, nll_loss=1.235, ntokens=892.2, nsentences=32, sample_size=892.2, sample_size_v1=0, sample_size_v2=0, ppl=2.35, wps=238.5, ups=0.27, wpb=892.2, bsz=32, num_updates=42150, lr=2.00848e-06, gnorm=22.129, clip=100, loss_scale=16, train_wall=37, gb_free=8.6, wall=162555
2023-05-22 15:07:15 - progress_bar.py[line:272] - INFO: epoch 025:    668 / 1732 loss=2.416, loss_v1=0, loss_v2=0, nll_loss=1.218, ntokens=910, nsentences=32, sample_size=910, sample_size_v1=0, sample_size_v2=0, ppl=2.33, wps=243.5, ups=0.27, wpb=910, bsz=32, num_updates=42160, lr=2.00643e-06, gnorm=21.712, clip=100, loss_scale=16, train_wall=37, gb_free=8.2, wall=162592
2023-05-22 15:07:53 - progress_bar.py[line:272] - INFO: epoch 025:    678 / 1732 loss=2.426, loss_v1=0, loss_v2=0, nll_loss=1.231, ntokens=980.2, nsentences=32, sample_size=980.2, sample_size_v1=0, sample_size_v2=0, ppl=2.35, wps=259.9, ups=0.27, wpb=980.2, bsz=32, num_updates=42170, lr=2.00438e-06, gnorm=21.094, clip=100, loss_scale=16, train_wall=38, gb_free=8.8, wall=162630
2023-05-22 15:08:31 - progress_bar.py[line:272] - INFO: epoch 025:    688 / 1732 loss=2.425, loss_v1=0, loss_v2=0, nll_loss=1.228, ntokens=942, nsentences=32, sample_size=942, sample_size_v1=0, sample_size_v2=0, ppl=2.34, wps=248.3, ups=0.26, wpb=942, bsz=32, num_updates=42180, lr=2.00233e-06, gnorm=22.936, clip=100, loss_scale=16, train_wall=38, gb_free=9, wall=162668
2023-05-22 15:09:09 - progress_bar.py[line:272] - INFO: epoch 025:    698 / 1732 loss=2.407, loss_v1=0, loss_v2=0, nll_loss=1.208, ntokens=1001.9, nsentences=32, sample_size=1001.9, sample_size_v1=0, sample_size_v2=0, ppl=2.31, wps=263.1, ups=0.26, wpb=1001.9, bsz=32, num_updates=42190, lr=2.00029e-06, gnorm=20.252, clip=100, loss_scale=16, train_wall=38, gb_free=8.9, wall=162706
2023-05-22 15:09:47 - progress_bar.py[line:272] - INFO: epoch 025:    708 / 1732 loss=2.416, loss_v1=0, loss_v2=0, nll_loss=1.217, ntokens=907.1, nsentences=32, sample_size=907.1, sample_size_v1=0, sample_size_v2=0, ppl=2.32, wps=239.3, ups=0.26, wpb=907.1, bsz=32, num_updates=42200, lr=1.99824e-06, gnorm=23.35, clip=100, loss_scale=16, train_wall=38, gb_free=8.9, wall=162744
2023-05-22 15:10:24 - progress_bar.py[line:272] - INFO: epoch 025:    718 / 1732 loss=2.409, loss_v1=0, loss_v2=0, nll_loss=1.209, ntokens=882, nsentences=32, sample_size=882, sample_size_v1=0, sample_size_v2=0, ppl=2.31, wps=233.7, ups=0.26, wpb=882, bsz=32, num_updates=42210, lr=1.99619e-06, gnorm=22.487, clip=100, loss_scale=16, train_wall=38, gb_free=9.3, wall=162782
2023-05-22 15:11:03 - progress_bar.py[line:272] - INFO: epoch 025:    728 / 1732 loss=2.388, loss_v1=0, loss_v2=0, nll_loss=1.186, ntokens=917.5, nsentences=32, sample_size=917.5, sample_size_v1=0, sample_size_v2=0, ppl=2.28, wps=241, ups=0.26, wpb=917.5, bsz=32, num_updates=42220, lr=1.99414e-06, gnorm=21.181, clip=100, loss_scale=16, train_wall=38, gb_free=8.7, wall=162820
2023-05-22 15:11:40 - progress_bar.py[line:272] - INFO: epoch 025:    738 / 1732 loss=2.396, loss_v1=0, loss_v2=0, nll_loss=1.195, ntokens=991.8, nsentences=32, sample_size=991.8, sample_size_v1=0, sample_size_v2=0, ppl=2.29, wps=262.2, ups=0.26, wpb=991.8, bsz=32, num_updates=42230, lr=1.9921e-06, gnorm=18.807, clip=100, loss_scale=16, train_wall=38, gb_free=8.9, wall=162858
2023-05-22 15:12:19 - progress_bar.py[line:272] - INFO: epoch 025:    748 / 1732 loss=2.401, loss_v1=0, loss_v2=0, nll_loss=1.203, ntokens=986.3, nsentences=32, sample_size=986.3, sample_size_v1=0, sample_size_v2=0, ppl=2.3, wps=258.1, ups=0.26, wpb=986.3, bsz=32, num_updates=42240, lr=1.99005e-06, gnorm=20.793, clip=100, loss_scale=16, train_wall=38, gb_free=8.8, wall=162896
2023-05-22 15:12:57 - progress_bar.py[line:272] - INFO: epoch 025:    758 / 1732 loss=2.388, loss_v1=0, loss_v2=0, nll_loss=1.187, ntokens=946.6, nsentences=32, sample_size=946.6, sample_size_v1=0, sample_size_v2=0, ppl=2.28, wps=249.6, ups=0.26, wpb=946.6, bsz=32, num_updates=42250, lr=1.988e-06, gnorm=22.115, clip=100, loss_scale=16, train_wall=38, gb_free=8.6, wall=162934
2023-05-22 15:13:34 - progress_bar.py[line:272] - INFO: epoch 025:    768 / 1732 loss=2.407, loss_v1=0, loss_v2=0, nll_loss=1.209, ntokens=947.6, nsentences=32, sample_size=947.6, sample_size_v1=0, sample_size_v2=0, ppl=2.31, wps=249.8, ups=0.26, wpb=947.6, bsz=32, num_updates=42260, lr=1.98595e-06, gnorm=21.187, clip=100, loss_scale=16, train_wall=38, gb_free=8.5, wall=162972
2023-05-22 15:14:12 - progress_bar.py[line:272] - INFO: epoch 025:    778 / 1732 loss=2.407, loss_v1=0, loss_v2=0, nll_loss=1.208, ntokens=1017.6, nsentences=32, sample_size=1017.6, sample_size_v1=0, sample_size_v2=0, ppl=2.31, wps=267.8, ups=0.26, wpb=1017.6, bsz=32, num_updates=42270, lr=1.98391e-06, gnorm=21.231, clip=100, loss_scale=16, train_wall=38, gb_free=9.2, wall=163010
2023-05-22 15:14:51 - progress_bar.py[line:272] - INFO: epoch 025:    788 / 1732 loss=2.407, loss_v1=0, loss_v2=0, nll_loss=1.208, ntokens=1010.8, nsentences=32, sample_size=1010.8, sample_size_v1=0, sample_size_v2=0, ppl=2.31, wps=265.8, ups=0.26, wpb=1010.8, bsz=32, num_updates=42280, lr=1.98186e-06, gnorm=20.281, clip=100, loss_scale=16, train_wall=38, gb_free=8.4, wall=163048
2023-05-22 15:15:29 - progress_bar.py[line:272] - INFO: epoch 025:    798 / 1732 loss=2.399, loss_v1=0, loss_v2=0, nll_loss=1.2, ntokens=1050, nsentences=32, sample_size=1050, sample_size_v1=0, sample_size_v2=0, ppl=2.3, wps=276.2, ups=0.26, wpb=1050, bsz=32, num_updates=42290, lr=1.97981e-06, gnorm=21.082, clip=100, loss_scale=16, train_wall=38, gb_free=8.8, wall=163086
2023-05-22 15:16:07 - progress_bar.py[line:272] - INFO: epoch 025:    808 / 1732 loss=2.413, loss_v1=0, loss_v2=0, nll_loss=1.216, ntokens=907.2, nsentences=32, sample_size=907.2, sample_size_v1=0, sample_size_v2=0, ppl=2.32, wps=238, ups=0.26, wpb=907.2, bsz=32, num_updates=42300, lr=1.97777e-06, gnorm=22.078, clip=100, loss_scale=16, train_wall=38, gb_free=8.8, wall=163124
2023-05-22 15:16:45 - progress_bar.py[line:272] - INFO: epoch 025:    818 / 1732 loss=2.419, loss_v1=0, loss_v2=0, nll_loss=1.222, ntokens=917.4, nsentences=32, sample_size=917.4, sample_size_v1=0, sample_size_v2=0, ppl=2.33, wps=240.8, ups=0.26, wpb=917.4, bsz=32, num_updates=42310, lr=1.97572e-06, gnorm=21.87, clip=100, loss_scale=16, train_wall=38, gb_free=8.7, wall=163162
2023-05-22 15:17:23 - progress_bar.py[line:272] - INFO: epoch 025:    828 / 1732 loss=2.398, loss_v1=0, loss_v2=0, nll_loss=1.197, ntokens=929.3, nsentences=32, sample_size=929.3, sample_size_v1=0, sample_size_v2=0, ppl=2.29, wps=244.1, ups=0.26, wpb=929.3, bsz=32, num_updates=42320, lr=1.97367e-06, gnorm=21.9, clip=100, loss_scale=16, train_wall=38, gb_free=9, wall=163200
2023-05-22 15:18:01 - progress_bar.py[line:272] - INFO: epoch 025:    838 / 1732 loss=2.41, loss_v1=0, loss_v2=0, nll_loss=1.212, ntokens=901, nsentences=32, sample_size=901, sample_size_v1=0, sample_size_v2=0, ppl=2.32, wps=237.3, ups=0.26, wpb=901, bsz=32, num_updates=42330, lr=1.97162e-06, gnorm=24.039, clip=100, loss_scale=16, train_wall=38, gb_free=8.9, wall=163238
2023-05-22 15:18:39 - progress_bar.py[line:272] - INFO: epoch 025:    848 / 1732 loss=2.392, loss_v1=0, loss_v2=0, nll_loss=1.192, ntokens=1016.3, nsentences=32, sample_size=1016.3, sample_size_v1=0, sample_size_v2=0, ppl=2.29, wps=265.5, ups=0.26, wpb=1016.3, bsz=32, num_updates=42340, lr=1.96958e-06, gnorm=22.013, clip=100, loss_scale=16, train_wall=38, gb_free=7.9, wall=163276
2023-05-22 15:19:17 - progress_bar.py[line:272] - INFO: epoch 025:    858 / 1732 loss=2.398, loss_v1=0, loss_v2=0, nll_loss=1.199, ntokens=923.8, nsentences=32, sample_size=923.8, sample_size_v1=0, sample_size_v2=0, ppl=2.3, wps=244.3, ups=0.26, wpb=923.8, bsz=32, num_updates=42350, lr=1.96753e-06, gnorm=23.028, clip=100, loss_scale=32, train_wall=38, gb_free=8.8, wall=163314
2023-05-22 15:19:55 - progress_bar.py[line:272] - INFO: epoch 025:    868 / 1732 loss=2.414, loss_v1=0, loss_v2=0, nll_loss=1.216, ntokens=966.1, nsentences=32, sample_size=966.1, sample_size_v1=0, sample_size_v2=0, ppl=2.32, wps=253.5, ups=0.26, wpb=966.1, bsz=32, num_updates=42360, lr=1.96548e-06, gnorm=22.15, clip=100, loss_scale=32, train_wall=38, gb_free=8.9, wall=163352
2023-05-22 15:20:33 - progress_bar.py[line:272] - INFO: epoch 025:    878 / 1732 loss=2.339, loss_v1=0, loss_v2=0, nll_loss=1.132, ntokens=1016.8, nsentences=32, sample_size=1016.8, sample_size_v1=0, sample_size_v2=0, ppl=2.19, wps=264.6, ups=0.26, wpb=1016.8, bsz=32, num_updates=42370, lr=1.96343e-06, gnorm=20.073, clip=100, loss_scale=32, train_wall=38, gb_free=8.7, wall=163391
2023-05-22 15:21:12 - progress_bar.py[line:272] - INFO: epoch 025:    888 / 1732 loss=2.37, loss_v1=0, loss_v2=0, nll_loss=1.168, ntokens=961.8, nsentences=32, sample_size=961.8, sample_size_v1=0, sample_size_v2=0, ppl=2.25, wps=251.2, ups=0.26, wpb=961.8, bsz=32, num_updates=42380, lr=1.96139e-06, gnorm=20.921, clip=100, loss_scale=32, train_wall=38, gb_free=8.7, wall=163429
2023-05-22 15:21:50 - progress_bar.py[line:272] - INFO: epoch 025:    898 / 1732 loss=2.332, loss_v1=0, loss_v2=0, nll_loss=1.122, ntokens=1063.3, nsentences=32, sample_size=1063.3, sample_size_v1=0, sample_size_v2=0, ppl=2.18, wps=277.3, ups=0.26, wpb=1063.3, bsz=32, num_updates=42390, lr=1.95934e-06, gnorm=18.234, clip=100, loss_scale=32, train_wall=38, gb_free=8.2, wall=163467
2023-05-22 15:22:21 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2023-05-22 15:22:32 - progress_bar.py[line:272] - INFO: epoch 025:    909 / 1732 loss=2.371, loss_v1=0, loss_v2=0, nll_loss=1.169, ntokens=977.4, nsentences=32, sample_size=977.4, sample_size_v1=0, sample_size_v2=0, ppl=2.25, wps=233.4, ups=0.24, wpb=977.4, bsz=32, num_updates=42400, lr=1.95729e-06, gnorm=19.831, clip=100, loss_scale=16, train_wall=42, gb_free=9, wall=163509
2023-05-22 15:23:10 - progress_bar.py[line:272] - INFO: epoch 025:    919 / 1732 loss=2.418, loss_v1=0, loss_v2=0, nll_loss=1.221, ntokens=988.7, nsentences=32, sample_size=988.7, sample_size_v1=0, sample_size_v2=0, ppl=2.33, wps=258, ups=0.26, wpb=988.7, bsz=32, num_updates=42410, lr=1.95524e-06, gnorm=21.262, clip=100, loss_scale=16, train_wall=38, gb_free=8.2, wall=163547
2023-05-22 15:23:49 - progress_bar.py[line:272] - INFO: epoch 025:    929 / 1732 loss=2.367, loss_v1=0, loss_v2=0, nll_loss=1.164, ntokens=1019.8, nsentences=32, sample_size=1019.8, sample_size_v1=0, sample_size_v2=0, ppl=2.24, wps=265.3, ups=0.26, wpb=1019.8, bsz=32, num_updates=42420, lr=1.9532e-06, gnorm=20.453, clip=100, loss_scale=16, train_wall=38, gb_free=8.2, wall=163586
2023-05-22 15:24:28 - progress_bar.py[line:272] - INFO: epoch 025:    939 / 1732 loss=2.379, loss_v1=0, loss_v2=0, nll_loss=1.177, ntokens=1047.7, nsentences=32, sample_size=1047.7, sample_size_v1=0, sample_size_v2=0, ppl=2.26, wps=269.8, ups=0.26, wpb=1047.7, bsz=32, num_updates=42430, lr=1.95115e-06, gnorm=20.17, clip=100, loss_scale=16, train_wall=39, gb_free=8.4, wall=163625
2023-05-22 15:25:09 - progress_bar.py[line:272] - INFO: epoch 025:    949 / 1732 loss=2.381, loss_v1=0, loss_v2=0, nll_loss=1.178, ntokens=1037.9, nsentences=32, sample_size=1037.9, sample_size_v1=0, sample_size_v2=0, ppl=2.26, wps=252, ups=0.24, wpb=1037.9, bsz=32, num_updates=42440, lr=1.9491e-06, gnorm=19.556, clip=100, loss_scale=16, train_wall=41, gb_free=8.6, wall=163666
2023-05-22 15:25:49 - progress_bar.py[line:272] - INFO: epoch 025:    959 / 1732 loss=2.372, loss_v1=0, loss_v2=0, nll_loss=1.167, ntokens=1070.6, nsentences=32, sample_size=1070.6, sample_size_v1=0, sample_size_v2=0, ppl=2.25, wps=266.4, ups=0.25, wpb=1070.6, bsz=32, num_updates=42450, lr=1.94705e-06, gnorm=20.39, clip=100, loss_scale=16, train_wall=40, gb_free=8.3, wall=163706
2023-05-22 15:26:28 - progress_bar.py[line:272] - INFO: epoch 025:    969 / 1732 loss=2.411, loss_v1=0, loss_v2=0, nll_loss=1.213, ntokens=1025.9, nsentences=32, sample_size=1025.9, sample_size_v1=0, sample_size_v2=0, ppl=2.32, wps=265.4, ups=0.26, wpb=1025.9, bsz=32, num_updates=42460, lr=1.94501e-06, gnorm=22.217, clip=100, loss_scale=16, train_wall=39, gb_free=8.4, wall=163745
2023-05-22 15:27:08 - progress_bar.py[line:272] - INFO: epoch 025:    979 / 1732 loss=2.388, loss_v1=0, loss_v2=0, nll_loss=1.188, ntokens=1025.3, nsentences=32, sample_size=1025.3, sample_size_v1=0, sample_size_v2=0, ppl=2.28, wps=254.4, ups=0.25, wpb=1025.3, bsz=32, num_updates=42470, lr=1.94296e-06, gnorm=20.446, clip=100, loss_scale=16, train_wall=40, gb_free=8.1, wall=163785
2023-05-22 15:27:50 - progress_bar.py[line:272] - INFO: epoch 025:    989 / 1732 loss=2.385, loss_v1=0, loss_v2=0, nll_loss=1.184, ntokens=1057.2, nsentences=32, sample_size=1057.2, sample_size_v1=0, sample_size_v2=0, ppl=2.27, wps=252.4, ups=0.24, wpb=1057.2, bsz=32, num_updates=42480, lr=1.94091e-06, gnorm=19.553, clip=100, loss_scale=16, train_wall=42, gb_free=8.3, wall=163827
2023-05-22 15:28:29 - progress_bar.py[line:272] - INFO: epoch 025:    999 / 1732 loss=2.373, loss_v1=0, loss_v2=0, nll_loss=1.171, ntokens=989.7, nsentences=32, sample_size=989.7, sample_size_v1=0, sample_size_v2=0, ppl=2.25, wps=255.5, ups=0.26, wpb=989.7, bsz=32, num_updates=42490, lr=1.93887e-06, gnorm=20.427, clip=100, loss_scale=16, train_wall=39, gb_free=9, wall=163866
2023-05-22 15:29:08 - progress_bar.py[line:272] - INFO: epoch 025:   1009 / 1732 loss=2.373, loss_v1=0, loss_v2=0, nll_loss=1.171, ntokens=1040.9, nsentences=32, sample_size=1040.9, sample_size_v1=0, sample_size_v2=0, ppl=2.25, wps=265.5, ups=0.26, wpb=1040.9, bsz=32, num_updates=42500, lr=1.93682e-06, gnorm=20.062, clip=100, loss_scale=16, train_wall=39, gb_free=7.9, wall=163905
2023-05-22 15:29:48 - progress_bar.py[line:272] - INFO: epoch 025:   1019 / 1732 loss=2.358, loss_v1=0, loss_v2=0, nll_loss=1.153, ntokens=1021.6, nsentences=32, sample_size=1021.6, sample_size_v1=0, sample_size_v2=0, ppl=2.22, wps=251.2, ups=0.25, wpb=1021.6, bsz=32, num_updates=42510, lr=1.93477e-06, gnorm=19.592, clip=100, loss_scale=16, train_wall=41, gb_free=8.4, wall=163946
2023-05-22 15:30:28 - progress_bar.py[line:272] - INFO: epoch 025:   1029 / 1732 loss=2.38, loss_v1=0, loss_v2=0, nll_loss=1.178, ntokens=1092, nsentences=32, sample_size=1092, sample_size_v1=0, sample_size_v2=0, ppl=2.26, wps=276.7, ups=0.25, wpb=1092, bsz=32, num_updates=42520, lr=1.93272e-06, gnorm=17.813, clip=100, loss_scale=16, train_wall=39, gb_free=7.6, wall=163985
2023-05-22 15:31:06 - progress_bar.py[line:272] - INFO: epoch 025:   1039 / 1732 loss=2.387, loss_v1=0, loss_v2=0, nll_loss=1.187, ntokens=1077.1, nsentences=32, sample_size=1077.1, sample_size_v1=0, sample_size_v2=0, ppl=2.28, wps=279.7, ups=0.26, wpb=1077.1, bsz=32, num_updates=42530, lr=1.93068e-06, gnorm=17.902, clip=100, loss_scale=16, train_wall=38, gb_free=8, wall=164024
2023-05-22 15:31:45 - progress_bar.py[line:272] - INFO: epoch 025:   1049 / 1732 loss=2.373, loss_v1=0, loss_v2=0, nll_loss=1.171, ntokens=1018.7, nsentences=32, sample_size=1018.7, sample_size_v1=0, sample_size_v2=0, ppl=2.25, wps=264.2, ups=0.26, wpb=1018.7, bsz=32, num_updates=42540, lr=1.92863e-06, gnorm=20.064, clip=100, loss_scale=16, train_wall=39, gb_free=8.7, wall=164062
2023-05-22 15:32:26 - progress_bar.py[line:272] - INFO: epoch 025:   1059 / 1732 loss=2.383, loss_v1=0, loss_v2=0, nll_loss=1.182, ntokens=1090.9, nsentences=32, sample_size=1090.9, sample_size_v1=0, sample_size_v2=0, ppl=2.27, wps=265.1, ups=0.24, wpb=1090.9, bsz=32, num_updates=42550, lr=1.92658e-06, gnorm=19.441, clip=100, loss_scale=16, train_wall=41, gb_free=8.6, wall=164103
2023-05-22 15:33:06 - progress_bar.py[line:272] - INFO: epoch 025:   1069 / 1732 loss=2.379, loss_v1=0, loss_v2=0, nll_loss=1.177, ntokens=979.2, nsentences=32, sample_size=979.2, sample_size_v1=0, sample_size_v2=0, ppl=2.26, wps=247.1, ups=0.25, wpb=979.2, bsz=32, num_updates=42560, lr=1.92453e-06, gnorm=20.9, clip=100, loss_scale=16, train_wall=40, gb_free=8.4, wall=164143
2023-05-22 15:33:45 - progress_bar.py[line:272] - INFO: epoch 025:   1079 / 1732 loss=2.402, loss_v1=0, loss_v2=0, nll_loss=1.204, ntokens=1044.7, nsentences=32, sample_size=1044.7, sample_size_v1=0, sample_size_v2=0, ppl=2.3, wps=269.2, ups=0.26, wpb=1044.7, bsz=32, num_updates=42570, lr=1.92249e-06, gnorm=21.058, clip=100, loss_scale=16, train_wall=39, gb_free=8.1, wall=164182
2023-05-22 15:34:26 - progress_bar.py[line:272] - INFO: epoch 025:   1089 / 1732 loss=2.368, loss_v1=0, loss_v2=0, nll_loss=1.167, ntokens=1065.4, nsentences=32, sample_size=1065.4, sample_size_v1=0, sample_size_v2=0, ppl=2.25, wps=258.9, ups=0.24, wpb=1065.4, bsz=32, num_updates=42580, lr=1.92044e-06, gnorm=19.584, clip=100, loss_scale=16, train_wall=41, gb_free=8.6, wall=164223
2023-05-22 15:35:06 - progress_bar.py[line:272] - INFO: epoch 025:   1099 / 1732 loss=2.386, loss_v1=0, loss_v2=0, nll_loss=1.185, ntokens=1034.8, nsentences=32, sample_size=1034.8, sample_size_v1=0, sample_size_v2=0, ppl=2.27, wps=257.1, ups=0.25, wpb=1034.8, bsz=32, num_updates=42590, lr=1.91839e-06, gnorm=22.093, clip=100, loss_scale=16, train_wall=40, gb_free=7.6, wall=164263
2023-05-22 15:35:45 - progress_bar.py[line:272] - INFO: epoch 025:   1109 / 1732 loss=2.379, loss_v1=0, loss_v2=0, nll_loss=1.177, ntokens=1058.4, nsentences=32, sample_size=1058.4, sample_size_v1=0, sample_size_v2=0, ppl=2.26, wps=272.1, ups=0.26, wpb=1058.4, bsz=32, num_updates=42600, lr=1.91634e-06, gnorm=18.455, clip=100, loss_scale=16, train_wall=39, gb_free=7.5, wall=164302
2023-05-22 15:36:23 - progress_bar.py[line:272] - INFO: epoch 025:   1119 / 1732 loss=2.389, loss_v1=0, loss_v2=0, nll_loss=1.188, ntokens=966, nsentences=32, sample_size=966, sample_size_v1=0, sample_size_v2=0, ppl=2.28, wps=251.5, ups=0.26, wpb=966, bsz=32, num_updates=42610, lr=1.9143e-06, gnorm=21.73, clip=100, loss_scale=16, train_wall=38, gb_free=8, wall=164340
2023-05-22 15:37:02 - progress_bar.py[line:272] - INFO: epoch 025:   1129 / 1732 loss=2.384, loss_v1=0, loss_v2=0, nll_loss=1.182, ntokens=1007.5, nsentences=32, sample_size=1007.5, sample_size_v1=0, sample_size_v2=0, ppl=2.27, wps=262, ups=0.26, wpb=1007.5, bsz=32, num_updates=42620, lr=1.91225e-06, gnorm=21.163, clip=100, loss_scale=16, train_wall=38, gb_free=8.7, wall=164379
2023-05-22 15:37:40 - progress_bar.py[line:272] - INFO: epoch 025:   1139 / 1732 loss=2.399, loss_v1=0, loss_v2=0, nll_loss=1.198, ntokens=999.7, nsentences=32, sample_size=999.7, sample_size_v1=0, sample_size_v2=0, ppl=2.29, wps=259.8, ups=0.26, wpb=999.7, bsz=32, num_updates=42630, lr=1.9102e-06, gnorm=21.021, clip=100, loss_scale=16, train_wall=38, gb_free=8.2, wall=164417
2023-05-22 15:38:19 - progress_bar.py[line:272] - INFO: epoch 025:   1149 / 1732 loss=2.383, loss_v1=0, loss_v2=0, nll_loss=1.181, ntokens=999, nsentences=32, sample_size=999, sample_size_v1=0, sample_size_v2=0, ppl=2.27, wps=260.2, ups=0.26, wpb=999, bsz=32, num_updates=42640, lr=1.90815e-06, gnorm=23.443, clip=100, loss_scale=16, train_wall=38, gb_free=8.7, wall=164456
2023-05-22 15:39:00 - progress_bar.py[line:272] - INFO: epoch 025:   1159 / 1732 loss=2.362, loss_v1=0, loss_v2=0, nll_loss=1.158, ntokens=1014.2, nsentences=32, sample_size=1014.2, sample_size_v1=0, sample_size_v2=0, ppl=2.23, wps=247.1, ups=0.24, wpb=1014.2, bsz=32, num_updates=42650, lr=1.90611e-06, gnorm=19.112, clip=100, loss_scale=16, train_wall=41, gb_free=8.6, wall=164497
2023-05-22 15:39:40 - progress_bar.py[line:272] - INFO: epoch 025:   1169 / 1732 loss=2.377, loss_v1=0, loss_v2=0, nll_loss=1.178, ntokens=1031, nsentences=32, sample_size=1031, sample_size_v1=0, sample_size_v2=0, ppl=2.26, wps=257.1, ups=0.25, wpb=1031, bsz=32, num_updates=42660, lr=1.90406e-06, gnorm=21.591, clip=100, loss_scale=16, train_wall=40, gb_free=8.2, wall=164537
2023-05-22 15:40:18 - progress_bar.py[line:272] - INFO: epoch 025:   1179 / 1732 loss=2.352, loss_v1=0, loss_v2=0, nll_loss=1.147, ntokens=1057.9, nsentences=32, sample_size=1057.9, sample_size_v1=0, sample_size_v2=0, ppl=2.21, wps=275.5, ups=0.26, wpb=1057.9, bsz=32, num_updates=42670, lr=1.90201e-06, gnorm=19.585, clip=100, loss_scale=16, train_wall=38, gb_free=8.9, wall=164575
2023-05-22 15:40:57 - progress_bar.py[line:272] - INFO: epoch 025:   1189 / 1732 loss=2.385, loss_v1=0, loss_v2=0, nll_loss=1.185, ntokens=993.6, nsentences=32, sample_size=993.6, sample_size_v1=0, sample_size_v2=0, ppl=2.27, wps=255.9, ups=0.26, wpb=993.6, bsz=32, num_updates=42680, lr=1.89997e-06, gnorm=21.899, clip=100, loss_scale=16, train_wall=39, gb_free=8.3, wall=164614
2023-05-22 15:41:38 - progress_bar.py[line:272] - INFO: epoch 025:   1199 / 1732 loss=2.361, loss_v1=0, loss_v2=0, nll_loss=1.157, ntokens=1103.9, nsentences=32, sample_size=1103.9, sample_size_v1=0, sample_size_v2=0, ppl=2.23, wps=267.7, ups=0.24, wpb=1103.9, bsz=32, num_updates=42690, lr=1.89792e-06, gnorm=20.094, clip=100, loss_scale=16, train_wall=41, gb_free=7.7, wall=164655
2023-05-22 15:42:18 - progress_bar.py[line:272] - INFO: epoch 025:   1209 / 1732 loss=2.359, loss_v1=0, loss_v2=0, nll_loss=1.156, ntokens=1079.5, nsentences=32, sample_size=1079.5, sample_size_v1=0, sample_size_v2=0, ppl=2.23, wps=271, ups=0.25, wpb=1079.5, bsz=32, num_updates=42700, lr=1.89587e-06, gnorm=19.621, clip=100, loss_scale=16, train_wall=40, gb_free=8.5, wall=164695
2023-05-22 15:42:58 - progress_bar.py[line:272] - INFO: epoch 025:   1219 / 1732 loss=2.419, loss_v1=0, loss_v2=0, nll_loss=1.222, ntokens=1009.3, nsentences=32, sample_size=1009.3, sample_size_v1=0, sample_size_v2=0, ppl=2.33, wps=251.3, ups=0.25, wpb=1009.3, bsz=32, num_updates=42710, lr=1.89382e-06, gnorm=22.418, clip=100, loss_scale=16, train_wall=40, gb_free=8.5, wall=164735
2023-05-22 15:43:39 - progress_bar.py[line:272] - INFO: epoch 025:   1229 / 1732 loss=2.373, loss_v1=0, loss_v2=0, nll_loss=1.17, ntokens=1052.5, nsentences=32, sample_size=1052.5, sample_size_v1=0, sample_size_v2=0, ppl=2.25, wps=257.2, ups=0.24, wpb=1052.5, bsz=32, num_updates=42720, lr=1.89178e-06, gnorm=20.712, clip=100, loss_scale=16, train_wall=41, gb_free=8.3, wall=164776
2023-05-22 15:44:18 - progress_bar.py[line:272] - INFO: epoch 025:   1239 / 1732 loss=2.335, loss_v1=0, loss_v2=0, nll_loss=1.128, ntokens=1065.1, nsentences=32, sample_size=1065.1, sample_size_v1=0, sample_size_v2=0, ppl=2.19, wps=274.7, ups=0.26, wpb=1065.1, bsz=32, num_updates=42730, lr=1.88973e-06, gnorm=19.997, clip=100, loss_scale=16, train_wall=39, gb_free=7.9, wall=164815
2023-05-22 15:44:56 - progress_bar.py[line:272] - INFO: epoch 025:   1249 / 1732 loss=2.342, loss_v1=0, loss_v2=0, nll_loss=1.135, ntokens=1065.4, nsentences=32, sample_size=1065.4, sample_size_v1=0, sample_size_v2=0, ppl=2.2, wps=276.5, ups=0.26, wpb=1065.4, bsz=32, num_updates=42740, lr=1.88768e-06, gnorm=19.681, clip=100, loss_scale=16, train_wall=38, gb_free=8.6, wall=164854
2023-05-22 15:45:35 - progress_bar.py[line:272] - INFO: epoch 025:   1259 / 1732 loss=2.359, loss_v1=0, loss_v2=0, nll_loss=1.156, ntokens=1045.9, nsentences=32, sample_size=1045.9, sample_size_v1=0, sample_size_v2=0, ppl=2.23, wps=270.3, ups=0.26, wpb=1045.9, bsz=32, num_updates=42750, lr=1.88563e-06, gnorm=21.948, clip=100, loss_scale=16, train_wall=39, gb_free=8.8, wall=164892
2023-05-22 15:46:14 - progress_bar.py[line:272] - INFO: epoch 025:   1269 / 1732 loss=2.387, loss_v1=0, loss_v2=0, nll_loss=1.187, ntokens=1069.2, nsentences=32, sample_size=1069.2, sample_size_v1=0, sample_size_v2=0, ppl=2.28, wps=277.5, ups=0.26, wpb=1069.2, bsz=32, num_updates=42760, lr=1.88359e-06, gnorm=19.541, clip=100, loss_scale=16, train_wall=38, gb_free=8.3, wall=164931
2023-05-22 15:46:52 - progress_bar.py[line:272] - INFO: epoch 025:   1279 / 1732 loss=2.379, loss_v1=0, loss_v2=0, nll_loss=1.177, ntokens=1067, nsentences=32, sample_size=1067, sample_size_v1=0, sample_size_v2=0, ppl=2.26, wps=276.6, ups=0.26, wpb=1067, bsz=32, num_updates=42770, lr=1.88154e-06, gnorm=22.03, clip=100, loss_scale=16, train_wall=39, gb_free=8, wall=164969
2023-05-22 15:47:31 - progress_bar.py[line:272] - INFO: epoch 025:   1289 / 1732 loss=2.362, loss_v1=0, loss_v2=0, nll_loss=1.158, ntokens=1071, nsentences=32, sample_size=1071, sample_size_v1=0, sample_size_v2=0, ppl=2.23, wps=275.2, ups=0.26, wpb=1071, bsz=32, num_updates=42780, lr=1.87949e-06, gnorm=19.084, clip=100, loss_scale=16, train_wall=39, gb_free=7, wall=165008
2023-05-22 15:48:10 - progress_bar.py[line:272] - INFO: epoch 025:   1299 / 1732 loss=2.362, loss_v1=0, loss_v2=0, nll_loss=1.157, ntokens=1078.1, nsentences=32, sample_size=1078.1, sample_size_v1=0, sample_size_v2=0, ppl=2.23, wps=280.4, ups=0.26, wpb=1078.1, bsz=32, num_updates=42790, lr=1.87744e-06, gnorm=18.321, clip=100, loss_scale=16, train_wall=38, gb_free=8.6, wall=165047
2023-05-22 15:48:49 - progress_bar.py[line:272] - INFO: epoch 025:   1309 / 1732 loss=2.406, loss_v1=0, loss_v2=0, nll_loss=1.208, ntokens=1085.2, nsentences=32, sample_size=1085.2, sample_size_v1=0, sample_size_v2=0, ppl=2.31, wps=279.1, ups=0.26, wpb=1085.2, bsz=32, num_updates=42800, lr=1.8754e-06, gnorm=18.479, clip=100, loss_scale=16, train_wall=39, gb_free=7.9, wall=165086
2023-05-22 15:49:27 - progress_bar.py[line:272] - INFO: epoch 025:   1319 / 1732 loss=2.36, loss_v1=0, loss_v2=0, nll_loss=1.155, ntokens=1092.6, nsentences=32, sample_size=1092.6, sample_size_v1=0, sample_size_v2=0, ppl=2.23, wps=283.1, ups=0.26, wpb=1092.6, bsz=32, num_updates=42810, lr=1.87335e-06, gnorm=19.668, clip=100, loss_scale=16, train_wall=39, gb_free=7.9, wall=165124
2023-05-22 15:50:06 - progress_bar.py[line:272] - INFO: epoch 025:   1329 / 1732 loss=2.344, loss_v1=0, loss_v2=0, nll_loss=1.138, ntokens=1106.3, nsentences=32, sample_size=1106.3, sample_size_v1=0, sample_size_v2=0, ppl=2.2, wps=283.8, ups=0.26, wpb=1106.3, bsz=32, num_updates=42820, lr=1.8713e-06, gnorm=20.426, clip=100, loss_scale=16, train_wall=39, gb_free=8.5, wall=165163
2023-05-22 15:50:45 - progress_bar.py[line:272] - INFO: epoch 025:   1339 / 1732 loss=2.36, loss_v1=0, loss_v2=0, nll_loss=1.156, ntokens=1120.5, nsentences=32, sample_size=1120.5, sample_size_v1=0, sample_size_v2=0, ppl=2.23, wps=290.4, ups=0.26, wpb=1120.5, bsz=32, num_updates=42830, lr=1.86925e-06, gnorm=21.96, clip=100, loss_scale=16, train_wall=39, gb_free=8.2, wall=165202
2023-05-22 15:51:24 - progress_bar.py[line:272] - INFO: epoch 025:   1349 / 1732 loss=2.354, loss_v1=0, loss_v2=0, nll_loss=1.149, ntokens=1187.2, nsentences=32, sample_size=1187.2, sample_size_v1=0, sample_size_v2=0, ppl=2.22, wps=304.6, ups=0.26, wpb=1187.2, bsz=32, num_updates=42840, lr=1.86721e-06, gnorm=20.77, clip=100, loss_scale=16, train_wall=39, gb_free=8.5, wall=165241
2023-05-22 15:52:03 - progress_bar.py[line:272] - INFO: epoch 025:   1359 / 1732 loss=2.34, loss_v1=0, loss_v2=0, nll_loss=1.134, ntokens=1104.5, nsentences=32, sample_size=1104.5, sample_size_v1=0, sample_size_v2=0, ppl=2.19, wps=282.8, ups=0.26, wpb=1104.5, bsz=32, num_updates=42850, lr=1.86516e-06, gnorm=19.844, clip=100, loss_scale=16, train_wall=39, gb_free=8.3, wall=165280
2023-05-22 15:52:42 - progress_bar.py[line:272] - INFO: epoch 025:   1369 / 1732 loss=2.377, loss_v1=0, loss_v2=0, nll_loss=1.176, ntokens=1096, nsentences=32, sample_size=1096, sample_size_v1=0, sample_size_v2=0, ppl=2.26, wps=281.9, ups=0.26, wpb=1096, bsz=32, num_updates=42860, lr=1.86311e-06, gnorm=19.096, clip=100, loss_scale=16, train_wall=39, gb_free=8, wall=165319
2023-05-22 15:53:20 - progress_bar.py[line:272] - INFO: epoch 025:   1379 / 1732 loss=2.389, loss_v1=0, loss_v2=0, nll_loss=1.188, ntokens=1115.7, nsentences=32, sample_size=1115.7, sample_size_v1=0, sample_size_v2=0, ppl=2.28, wps=290.7, ups=0.26, wpb=1115.7, bsz=32, num_updates=42870, lr=1.86107e-06, gnorm=21.669, clip=100, loss_scale=16, train_wall=38, gb_free=8.6, wall=165357
2023-05-22 15:53:59 - progress_bar.py[line:272] - INFO: epoch 025:   1389 / 1732 loss=2.371, loss_v1=0, loss_v2=0, nll_loss=1.168, ntokens=1122.1, nsentences=32, sample_size=1122.1, sample_size_v1=0, sample_size_v2=0, ppl=2.25, wps=291.6, ups=0.26, wpb=1122.1, bsz=32, num_updates=42880, lr=1.85902e-06, gnorm=20.635, clip=100, loss_scale=16, train_wall=38, gb_free=8.6, wall=165396
2023-05-22 15:54:39 - progress_bar.py[line:272] - INFO: epoch 025:   1399 / 1732 loss=2.342, loss_v1=0, loss_v2=0, nll_loss=1.137, ntokens=1113, nsentences=32, sample_size=1113, sample_size_v1=0, sample_size_v2=0, ppl=2.2, wps=272.6, ups=0.24, wpb=1113, bsz=32, num_updates=42890, lr=1.85697e-06, gnorm=20.43, clip=100, loss_scale=16, train_wall=41, gb_free=8.2, wall=165437
2023-05-22 15:55:20 - progress_bar.py[line:272] - INFO: epoch 025:   1409 / 1732 loss=2.386, loss_v1=0, loss_v2=0, nll_loss=1.186, ntokens=1156.6, nsentences=32, sample_size=1156.6, sample_size_v1=0, sample_size_v2=0, ppl=2.28, wps=283.9, ups=0.25, wpb=1156.6, bsz=32, num_updates=42900, lr=1.85492e-06, gnorm=20.526, clip=100, loss_scale=16, train_wall=41, gb_free=8.3, wall=165477
2023-05-22 15:56:00 - progress_bar.py[line:272] - INFO: epoch 025:   1419 / 1732 loss=2.379, loss_v1=0, loss_v2=0, nll_loss=1.178, ntokens=1290.6, nsentences=32, sample_size=1290.6, sample_size_v1=0, sample_size_v2=0, ppl=2.26, wps=327, ups=0.25, wpb=1290.6, bsz=32, num_updates=42910, lr=1.85288e-06, gnorm=20.73, clip=100, loss_scale=32, train_wall=39, gb_free=7.6, wall=165517
2023-05-22 15:56:39 - progress_bar.py[line:272] - INFO: epoch 025:   1429 / 1732 loss=2.343, loss_v1=0, loss_v2=0, nll_loss=1.135, ntokens=1226.2, nsentences=32, sample_size=1226.2, sample_size_v1=0, sample_size_v2=0, ppl=2.2, wps=312.3, ups=0.25, wpb=1226.2, bsz=32, num_updates=42920, lr=1.85083e-06, gnorm=17.643, clip=100, loss_scale=32, train_wall=39, gb_free=8.4, wall=165556
2023-05-22 15:57:18 - progress_bar.py[line:272] - INFO: epoch 025:   1439 / 1732 loss=2.344, loss_v1=0, loss_v2=0, nll_loss=1.138, ntokens=1192.7, nsentences=32, sample_size=1192.7, sample_size_v1=0, sample_size_v2=0, ppl=2.2, wps=306.2, ups=0.26, wpb=1192.7, bsz=32, num_updates=42930, lr=1.84878e-06, gnorm=17.562, clip=100, loss_scale=32, train_wall=39, gb_free=8.2, wall=165595
2023-05-22 15:57:56 - progress_bar.py[line:272] - INFO: epoch 025:   1449 / 1732 loss=2.376, loss_v1=0, loss_v2=0, nll_loss=1.174, ntokens=1089.5, nsentences=32, sample_size=1089.5, sample_size_v1=0, sample_size_v2=0, ppl=2.26, wps=282.2, ups=0.26, wpb=1089.5, bsz=32, num_updates=42940, lr=1.84673e-06, gnorm=20.575, clip=100, loss_scale=32, train_wall=39, gb_free=8.6, wall=165634
2023-05-22 15:58:35 - progress_bar.py[line:272] - INFO: epoch 025:   1459 / 1732 loss=2.35, loss_v1=0, loss_v2=0, nll_loss=1.145, ntokens=1160, nsentences=32, sample_size=1160, sample_size_v1=0, sample_size_v2=0, ppl=2.21, wps=298, ups=0.26, wpb=1160, bsz=32, num_updates=42950, lr=1.84469e-06, gnorm=19.574, clip=100, loss_scale=32, train_wall=39, gb_free=8.3, wall=165673
2023-05-22 15:59:14 - progress_bar.py[line:272] - INFO: epoch 025:   1469 / 1732 loss=2.352, loss_v1=0, loss_v2=0, nll_loss=1.148, ntokens=1187.1, nsentences=32, sample_size=1187.1, sample_size_v1=0, sample_size_v2=0, ppl=2.22, wps=304.1, ups=0.26, wpb=1187.1, bsz=32, num_updates=42960, lr=1.84264e-06, gnorm=18.69, clip=100, loss_scale=32, train_wall=39, gb_free=8.5, wall=165712
2023-05-22 15:59:53 - progress_bar.py[line:272] - INFO: epoch 025:   1479 / 1732 loss=2.382, loss_v1=0, loss_v2=0, nll_loss=1.181, ntokens=1029.5, nsentences=32, sample_size=1029.5, sample_size_v1=0, sample_size_v2=0, ppl=2.27, wps=265.4, ups=0.26, wpb=1029.5, bsz=32, num_updates=42970, lr=1.84059e-06, gnorm=20.737, clip=100, loss_scale=32, train_wall=39, gb_free=8.1, wall=165750
2023-05-22 16:00:32 - progress_bar.py[line:272] - INFO: epoch 025:   1489 / 1732 loss=2.366, loss_v1=0, loss_v2=0, nll_loss=1.164, ntokens=1147, nsentences=32, sample_size=1147, sample_size_v1=0, sample_size_v2=0, ppl=2.24, wps=293.7, ups=0.26, wpb=1147, bsz=32, num_updates=42980, lr=1.83854e-06, gnorm=19.056, clip=100, loss_scale=32, train_wall=39, gb_free=8.4, wall=165789
2023-05-22 16:01:11 - progress_bar.py[line:272] - INFO: epoch 025:   1499 / 1732 loss=2.346, loss_v1=0, loss_v2=0, nll_loss=1.141, ntokens=1095.4, nsentences=32, sample_size=1095.4, sample_size_v1=0, sample_size_v2=0, ppl=2.2, wps=282.9, ups=0.26, wpb=1095.4, bsz=32, num_updates=42990, lr=1.8365e-06, gnorm=19.385, clip=100, loss_scale=32, train_wall=39, gb_free=7.9, wall=165828
2023-05-22 16:01:49 - progress_bar.py[line:272] - INFO: epoch 025:   1509 / 1732 loss=2.32, loss_v1=0, loss_v2=0, nll_loss=1.111, ntokens=1114.3, nsentences=32, sample_size=1114.3, sample_size_v1=0, sample_size_v2=0, ppl=2.16, wps=289.4, ups=0.26, wpb=1114.3, bsz=32, num_updates=43000, lr=1.83445e-06, gnorm=20.871, clip=100, loss_scale=32, train_wall=38, gb_free=8.4, wall=165867
2023-05-22 16:02:28 - progress_bar.py[line:272] - INFO: epoch 025:   1519 / 1732 loss=2.392, loss_v1=0, loss_v2=0, nll_loss=1.192, ntokens=1050.9, nsentences=32, sample_size=1050.9, sample_size_v1=0, sample_size_v2=0, ppl=2.28, wps=272.8, ups=0.26, wpb=1050.9, bsz=32, num_updates=43010, lr=1.8324e-06, gnorm=20.282, clip=100, loss_scale=32, train_wall=38, gb_free=8.6, wall=165905
2023-05-22 16:03:06 - progress_bar.py[line:272] - INFO: epoch 025:   1529 / 1732 loss=2.395, loss_v1=0, loss_v2=0, nll_loss=1.194, ntokens=1056.3, nsentences=32, sample_size=1056.3, sample_size_v1=0, sample_size_v2=0, ppl=2.29, wps=274.5, ups=0.26, wpb=1056.3, bsz=32, num_updates=43020, lr=1.83035e-06, gnorm=20.235, clip=100, loss_scale=32, train_wall=38, gb_free=8.2, wall=165944
2023-05-22 16:03:45 - progress_bar.py[line:272] - INFO: epoch 025:   1539 / 1732 loss=2.368, loss_v1=0, loss_v2=0, nll_loss=1.165, ntokens=1083.3, nsentences=32, sample_size=1083.3, sample_size_v1=0, sample_size_v2=0, ppl=2.24, wps=279.1, ups=0.26, wpb=1083.3, bsz=32, num_updates=43030, lr=1.82831e-06, gnorm=21.278, clip=100, loss_scale=32, train_wall=39, gb_free=8.1, wall=165982
2023-05-22 16:04:24 - progress_bar.py[line:272] - INFO: epoch 025:   1549 / 1732 loss=2.338, loss_v1=0, loss_v2=0, nll_loss=1.13, ntokens=1075, nsentences=32, sample_size=1075, sample_size_v1=0, sample_size_v2=0, ppl=2.19, wps=277.9, ups=0.26, wpb=1075, bsz=32, num_updates=43040, lr=1.82626e-06, gnorm=19.745, clip=100, loss_scale=32, train_wall=39, gb_free=8.7, wall=166021
2023-05-22 16:05:03 - progress_bar.py[line:272] - INFO: epoch 025:   1559 / 1732 loss=2.361, loss_v1=0, loss_v2=0, nll_loss=1.158, ntokens=1092, nsentences=32, sample_size=1092, sample_size_v1=0, sample_size_v2=0, ppl=2.23, wps=281, ups=0.26, wpb=1092, bsz=32, num_updates=43050, lr=1.82421e-06, gnorm=19.93, clip=100, loss_scale=32, train_wall=39, gb_free=8.5, wall=166060
2023-05-22 16:05:42 - progress_bar.py[line:272] - INFO: epoch 025:   1569 / 1732 loss=2.4, loss_v1=0, loss_v2=0, nll_loss=1.2, ntokens=1059.1, nsentences=32, sample_size=1059.1, sample_size_v1=0, sample_size_v2=0, ppl=2.3, wps=272.3, ups=0.26, wpb=1059.1, bsz=32, num_updates=43060, lr=1.82216e-06, gnorm=21.597, clip=100, loss_scale=32, train_wall=39, gb_free=8, wall=166099
2023-05-22 16:06:21 - progress_bar.py[line:272] - INFO: epoch 025:   1579 / 1732 loss=2.395, loss_v1=0, loss_v2=0, nll_loss=1.195, ntokens=1008.7, nsentences=32, sample_size=1008.7, sample_size_v1=0, sample_size_v2=0, ppl=2.29, wps=259.3, ups=0.26, wpb=1008.7, bsz=32, num_updates=43070, lr=1.82012e-06, gnorm=22.98, clip=100, loss_scale=32, train_wall=39, gb_free=8.3, wall=166138
2023-05-22 16:06:59 - progress_bar.py[line:272] - INFO: epoch 025:   1589 / 1732 loss=2.373, loss_v1=0, loss_v2=0, nll_loss=1.17, ntokens=1092.2, nsentences=32, sample_size=1092.2, sample_size_v1=0, sample_size_v2=0, ppl=2.25, wps=281.4, ups=0.26, wpb=1092.2, bsz=32, num_updates=43080, lr=1.81807e-06, gnorm=19.25, clip=100, loss_scale=32, train_wall=39, gb_free=8.6, wall=166177
2023-05-22 16:07:38 - progress_bar.py[line:272] - INFO: epoch 025:   1599 / 1732 loss=2.349, loss_v1=0, loss_v2=0, nll_loss=1.144, ntokens=1061.1, nsentences=32, sample_size=1061.1, sample_size_v1=0, sample_size_v2=0, ppl=2.21, wps=275, ups=0.26, wpb=1061.1, bsz=32, num_updates=43090, lr=1.81602e-06, gnorm=21.231, clip=100, loss_scale=32, train_wall=39, gb_free=8.4, wall=166215
2023-05-22 16:08:13 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2023-05-22 16:08:21 - progress_bar.py[line:272] - INFO: epoch 025:   1610 / 1732 loss=2.339, loss_v1=0, loss_v2=0, nll_loss=1.134, ntokens=1145.8, nsentences=32, sample_size=1145.8, sample_size_v1=0, sample_size_v2=0, ppl=2.19, wps=267.1, ups=0.23, wpb=1145.8, bsz=32, num_updates=43100, lr=1.81398e-06, gnorm=20.367, clip=100, loss_scale=16, train_wall=43, gb_free=8.4, wall=166258
2023-05-22 16:09:00 - progress_bar.py[line:272] - INFO: epoch 025:   1620 / 1732 loss=2.314, loss_v1=0, loss_v2=0, nll_loss=1.106, ntokens=1143.9, nsentences=32, sample_size=1143.9, sample_size_v1=0, sample_size_v2=0, ppl=2.15, wps=294, ups=0.26, wpb=1143.9, bsz=32, num_updates=43110, lr=1.81193e-06, gnorm=19.33, clip=100, loss_scale=16, train_wall=39, gb_free=7.8, wall=166297
2023-05-22 16:09:39 - progress_bar.py[line:272] - INFO: epoch 025:   1630 / 1732 loss=2.355, loss_v1=0, loss_v2=0, nll_loss=1.151, ntokens=1148.8, nsentences=32, sample_size=1148.8, sample_size_v1=0, sample_size_v2=0, ppl=2.22, wps=294.3, ups=0.26, wpb=1148.8, bsz=32, num_updates=43120, lr=1.80988e-06, gnorm=18.681, clip=100, loss_scale=16, train_wall=39, gb_free=8.7, wall=166336
2023-05-22 16:10:18 - progress_bar.py[line:272] - INFO: epoch 025:   1640 / 1732 loss=2.333, loss_v1=0, loss_v2=0, nll_loss=1.126, ntokens=1148.2, nsentences=32, sample_size=1148.2, sample_size_v1=0, sample_size_v2=0, ppl=2.18, wps=297.2, ups=0.26, wpb=1148.2, bsz=32, num_updates=43130, lr=1.80783e-06, gnorm=20.754, clip=100, loss_scale=16, train_wall=39, gb_free=8, wall=166375
2023-05-22 16:10:56 - progress_bar.py[line:272] - INFO: epoch 025:   1650 / 1732 loss=2.335, loss_v1=0, loss_v2=0, nll_loss=1.129, ntokens=1158.7, nsentences=32, sample_size=1158.7, sample_size_v1=0, sample_size_v2=0, ppl=2.19, wps=297.7, ups=0.26, wpb=1158.7, bsz=32, num_updates=43140, lr=1.80579e-06, gnorm=19.486, clip=100, loss_scale=16, train_wall=39, gb_free=9, wall=166414
2023-05-22 16:11:35 - progress_bar.py[line:272] - INFO: epoch 025:   1660 / 1732 loss=2.379, loss_v1=0, loss_v2=0, nll_loss=1.178, ntokens=997.6, nsentences=32, sample_size=997.6, sample_size_v1=0, sample_size_v2=0, ppl=2.26, wps=259.1, ups=0.26, wpb=997.6, bsz=32, num_updates=43150, lr=1.80374e-06, gnorm=19.938, clip=100, loss_scale=16, train_wall=38, gb_free=8.5, wall=166452
2023-05-22 16:12:14 - progress_bar.py[line:272] - INFO: epoch 025:   1670 / 1732 loss=2.358, loss_v1=0, loss_v2=0, nll_loss=1.155, ntokens=1015.8, nsentences=32, sample_size=1015.8, sample_size_v1=0, sample_size_v2=0, ppl=2.23, wps=263.4, ups=0.26, wpb=1015.8, bsz=32, num_updates=43160, lr=1.80169e-06, gnorm=20.83, clip=100, loss_scale=16, train_wall=39, gb_free=8.6, wall=166491
2023-05-22 16:12:53 - progress_bar.py[line:272] - INFO: epoch 025:   1680 / 1732 loss=2.305, loss_v1=0, loss_v2=0, nll_loss=1.094, ntokens=1181.3, nsentences=32, sample_size=1181.3, sample_size_v1=0, sample_size_v2=0, ppl=2.13, wps=302.8, ups=0.26, wpb=1181.3, bsz=32, num_updates=43170, lr=1.79964e-06, gnorm=17.573, clip=100, loss_scale=16, train_wall=39, gb_free=8.2, wall=166530
2023-05-22 16:13:32 - progress_bar.py[line:272] - INFO: epoch 025:   1690 / 1732 loss=2.343, loss_v1=0, loss_v2=0, nll_loss=1.136, ntokens=1198.5, nsentences=32, sample_size=1198.5, sample_size_v1=0, sample_size_v2=0, ppl=2.2, wps=306.4, ups=0.26, wpb=1198.5, bsz=32, num_updates=43180, lr=1.7976e-06, gnorm=18.486, clip=100, loss_scale=16, train_wall=39, gb_free=8, wall=166569
2023-05-22 16:14:11 - progress_bar.py[line:272] - INFO: epoch 025:   1700 / 1732 loss=2.336, loss_v1=0, loss_v2=0, nll_loss=1.129, ntokens=1281, nsentences=32, sample_size=1281, sample_size_v1=0, sample_size_v2=0, ppl=2.19, wps=324.6, ups=0.25, wpb=1281, bsz=32, num_updates=43190, lr=1.79555e-06, gnorm=17.42, clip=100, loss_scale=16, train_wall=39, gb_free=8.4, wall=166608
2023-05-22 16:14:50 - progress_bar.py[line:272] - INFO: epoch 025:   1710 / 1732 loss=2.363, loss_v1=0, loss_v2=0, nll_loss=1.158, ntokens=1170.9, nsentences=32, sample_size=1170.9, sample_size_v1=0, sample_size_v2=0, ppl=2.23, wps=300, ups=0.26, wpb=1170.9, bsz=32, num_updates=43200, lr=1.7935e-06, gnorm=20.66, clip=100, loss_scale=16, train_wall=39, gb_free=7.2, wall=166647
2023-05-22 16:15:29 - progress_bar.py[line:272] - INFO: epoch 025:   1720 / 1732 loss=2.333, loss_v1=0, loss_v2=0, nll_loss=1.126, ntokens=1171, nsentences=32, sample_size=1171, sample_size_v1=0, sample_size_v2=0, ppl=2.18, wps=298, ups=0.25, wpb=1171, bsz=32, num_updates=43210, lr=1.79145e-06, gnorm=18.055, clip=100, loss_scale=16, train_wall=39, gb_free=8.4, wall=166687
2023-05-22 16:16:08 - progress_bar.py[line:272] - INFO: epoch 025:   1730 / 1732 loss=2.391, loss_v1=0, loss_v2=0, nll_loss=1.191, ntokens=1126.4, nsentences=32, sample_size=1126.4, sample_size_v1=0, sample_size_v2=0, ppl=2.28, wps=290.1, ups=0.26, wpb=1126.4, bsz=32, num_updates=43220, lr=1.78941e-06, gnorm=18.414, clip=100, loss_scale=16, train_wall=39, gb_free=8.1, wall=166726
2023-05-22 16:16:13 - train.py[line:332] - INFO: end of epoch 25 (average epoch stats below)
2023-05-22 16:16:13 - progress_bar.py[line:282] - INFO: epoch 025 | loss 2.365 | loss_v1 0 | loss_v2 0 | nll_loss 1.162 | ntokens 1051.68 | nsentences 31.986 | sample_size 1051.68 | sample_size_v1 0 | sample_size_v2 0 | ppl 2.24 | wps 271.2 | ups 0.26 | wpb 1051.7 | bsz 32 | num_updates 43222 | lr 1.789e-06 | gnorm 20.218 | clip 100 | loss_scale 16 | train_wall 6694 | gb_free 8.9 | wall 166730
2023-05-22 16:16:13 - trainer.py[line:639] - INFO: loading train data for epoch 26
local datafile ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 0 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 0 finished initializing row_count and line_idx-to-offset mapping
file ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 0 row count 55400 total row count 55400
slice_id 0 seek offset 0
2023-05-22 16:16:15 - trainer.py[line:703] - INFO: begin training epoch 26
2023-05-22 16:16:15 - train.py[line:305] - INFO: Start iterating over samples
2023-05-22 16:16:46 - progress_bar.py[line:272] - INFO: epoch 026:      8 / 1732 loss=2.29, loss_v1=0, loss_v2=0, nll_loss=1.079, ntokens=1080.1, nsentences=29.6, sample_size=1080.1, sample_size_v1=0, sample_size_v2=0, ppl=2.11, wps=283.1, ups=0.26, wpb=1080.1, bsz=29.6, num_updates=43230, lr=1.78736e-06, gnorm=21.213, clip=100, loss_scale=16, train_wall=36, gb_free=7.4, wall=166764
2023-05-22 16:17:25 - progress_bar.py[line:272] - INFO: epoch 026:     18 / 1732 loss=2.265, loss_v1=0, loss_v2=0, nll_loss=1.049, ntokens=1071.6, nsentences=32, sample_size=1071.6, sample_size_v1=0, sample_size_v2=0, ppl=2.07, wps=275.6, ups=0.26, wpb=1071.6, bsz=32, num_updates=43240, lr=1.78531e-06, gnorm=19.897, clip=100, loss_scale=16, train_wall=39, gb_free=8.3, wall=166803
2023-05-22 16:18:04 - progress_bar.py[line:272] - INFO: epoch 026:     28 / 1732 loss=2.329, loss_v1=0, loss_v2=0, nll_loss=1.121, ntokens=959.8, nsentences=32, sample_size=959.8, sample_size_v1=0, sample_size_v2=0, ppl=2.18, wps=248.6, ups=0.26, wpb=959.8, bsz=32, num_updates=43250, lr=1.78326e-06, gnorm=20.515, clip=100, loss_scale=16, train_wall=39, gb_free=8.5, wall=166841
2023-05-22 16:18:43 - progress_bar.py[line:272] - INFO: epoch 026:     38 / 1732 loss=2.136, loss_v1=0, loss_v2=0, nll_loss=0.904, ntokens=1177.1, nsentences=32, sample_size=1177.1, sample_size_v1=0, sample_size_v2=0, ppl=1.87, wps=299.1, ups=0.25, wpb=1177.1, bsz=32, num_updates=43260, lr=1.78122e-06, gnorm=14.758, clip=100, loss_scale=16, train_wall=39, gb_free=8.5, wall=166881
2023-05-22 16:19:22 - progress_bar.py[line:272] - INFO: epoch 026:     48 / 1732 loss=2.183, loss_v1=0, loss_v2=0, nll_loss=0.959, ntokens=1064.2, nsentences=32, sample_size=1064.2, sample_size_v1=0, sample_size_v2=0, ppl=1.94, wps=273.2, ups=0.26, wpb=1064.2, bsz=32, num_updates=43270, lr=1.77917e-06, gnorm=16.271, clip=100, loss_scale=16, train_wall=39, gb_free=7.9, wall=166920
2023-05-22 16:20:01 - progress_bar.py[line:272] - INFO: epoch 026:     58 / 1732 loss=2.079, loss_v1=0, loss_v2=0, nll_loss=0.844, ntokens=1039.9, nsentences=32, sample_size=1039.9, sample_size_v1=0, sample_size_v2=0, ppl=1.79, wps=270.5, ups=0.26, wpb=1039.9, bsz=32, num_updates=43280, lr=1.77712e-06, gnorm=16.354, clip=100, loss_scale=16, train_wall=38, gb_free=8.8, wall=166958
2023-05-22 16:20:41 - progress_bar.py[line:272] - INFO: epoch 026:     68 / 1732 loss=2.009, loss_v1=0, loss_v2=0, nll_loss=0.767, ntokens=1401.1, nsentences=32, sample_size=1401.1, sample_size_v1=0, sample_size_v2=0, ppl=1.7, wps=349.9, ups=0.25, wpb=1401.1, bsz=32, num_updates=43290, lr=1.77508e-06, gnorm=12.23, clip=100, loss_scale=16, train_wall=40, gb_free=7.2, wall=166998
2023-05-22 16:21:21 - progress_bar.py[line:272] - INFO: epoch 026:     78 / 1732 loss=2.132, loss_v1=0, loss_v2=0, nll_loss=0.904, ntokens=1268.8, nsentences=32, sample_size=1268.8, sample_size_v1=0, sample_size_v2=0, ppl=1.87, wps=319.2, ups=0.25, wpb=1268.8, bsz=32, num_updates=43300, lr=1.77303e-06, gnorm=17.139, clip=100, loss_scale=16, train_wall=40, gb_free=6.8, wall=167038
2023-05-22 16:22:00 - progress_bar.py[line:272] - INFO: epoch 026:     88 / 1732 loss=2.213, loss_v1=0, loss_v2=0, nll_loss=0.996, ntokens=1100.2, nsentences=32, sample_size=1100.2, sample_size_v1=0, sample_size_v2=0, ppl=1.99, wps=281, ups=0.26, wpb=1100.2, bsz=32, num_updates=43310, lr=1.77098e-06, gnorm=20.845, clip=100, loss_scale=16, train_wall=39, gb_free=8.1, wall=167077
2023-05-22 16:22:39 - progress_bar.py[line:272] - INFO: epoch 026:     98 / 1732 loss=2.168, loss_v1=0, loss_v2=0, nll_loss=0.943, ntokens=1080.6, nsentences=32, sample_size=1080.6, sample_size_v1=0, sample_size_v2=0, ppl=1.92, wps=277.8, ups=0.26, wpb=1080.6, bsz=32, num_updates=43320, lr=1.76893e-06, gnorm=20.747, clip=100, loss_scale=16, train_wall=39, gb_free=8.4, wall=167116
2023-05-22 16:23:17 - progress_bar.py[line:272] - INFO: epoch 026:    108 / 1732 loss=2.367, loss_v1=0, loss_v2=0, nll_loss=1.166, ntokens=978.3, nsentences=32, sample_size=978.3, sample_size_v1=0, sample_size_v2=0, ppl=2.24, wps=255.3, ups=0.26, wpb=978.3, bsz=32, num_updates=43330, lr=1.76689e-06, gnorm=24.649, clip=100, loss_scale=16, train_wall=38, gb_free=8.9, wall=167154
2023-05-22 16:23:56 - progress_bar.py[line:272] - INFO: epoch 026:    118 / 1732 loss=2.36, loss_v1=0, loss_v2=0, nll_loss=1.156, ntokens=1087, nsentences=32, sample_size=1087, sample_size_v1=0, sample_size_v2=0, ppl=2.23, wps=278, ups=0.26, wpb=1087, bsz=32, num_updates=43340, lr=1.76484e-06, gnorm=19.192, clip=100, loss_scale=16, train_wall=39, gb_free=8.1, wall=167193
2023-05-22 16:24:36 - progress_bar.py[line:272] - INFO: epoch 026:    128 / 1732 loss=2.316, loss_v1=0, loss_v2=0, nll_loss=1.105, ntokens=1177.5, nsentences=32, sample_size=1177.5, sample_size_v1=0, sample_size_v2=0, ppl=2.15, wps=296.9, ups=0.25, wpb=1177.5, bsz=32, num_updates=43350, lr=1.76279e-06, gnorm=18.226, clip=100, loss_scale=16, train_wall=40, gb_free=8.6, wall=167233
2023-05-22 16:25:15 - progress_bar.py[line:272] - INFO: epoch 026:    138 / 1732 loss=2.282, loss_v1=0, loss_v2=0, nll_loss=1.068, ntokens=1228, nsentences=32, sample_size=1228, sample_size_v1=0, sample_size_v2=0, ppl=2.1, wps=312.5, ups=0.25, wpb=1228, bsz=32, num_updates=43360, lr=1.76074e-06, gnorm=16.587, clip=100, loss_scale=16, train_wall=39, gb_free=8.2, wall=167272
/data/hulab/zcai75/anaconda3/envs/vilt/lib/python3.8/site-packages/torch/distributed/launch.py:178: FutureWarning: The module torch.distributed.launch is deprecated
and will be removed in future. Use torchrun.
Note that --use_env is set by default in torchrun.
If your script expects `--local_rank` argument to be set, please
change it to read from `os.environ['LOCAL_RANK']` instead. See 
https://pytorch.org/docs/stable/distributed.html#launch-utility for 
further instructions

  warnings.warn(
WARNING:torch.distributed.elastic.agent.server.api:Received 2 death signal, shutting down workers
WARNING:torch.distributed.elastic.multiprocessing.api:Sending process 4191355 closing signal SIGINT
Traceback (most recent call last):
  File "../../train.py", line 539, in <module>
    cli_main()
  File "../../train.py", line 532, in cli_main
    distributed_utils.call_main(cfg, main)
  File "/home/zcai75/Github/OFA/fairseq/fairseq/distributed/utils.py", line 374, in call_main
    distributed_main(cfg.distributed_training.device_id, main, cfg, kwargs)
  File "/home/zcai75/Github/OFA/fairseq/fairseq/distributed/utils.py", line 348, in distributed_main
    main(cfg, **kwargs)
  File "../../train.py", line 199, in main
    valid_losses, should_stop = train(cfg, trainer, task, epoch_itr)
  File "/data/hulab/zcai75/anaconda3/envs/vilt/lib/python3.8/contextlib.py", line 75, in inner
    return func(*args, **kwds)
  File "../../train.py", line 310, in train
    log_output = trainer.train_step(samples)
  File "/data/hulab/zcai75/anaconda3/envs/vilt/lib/python3.8/contextlib.py", line 75, in inner
    return func(*args, **kwds)
  File "/home/zcai75/Github/OFA_forked/trainer.py", line 773, in train_step
    loss, sample_size_i, logging_output = self.task.train_step(
  File "/home/zcai75/Github/OFA_forked/tasks/ofa_task.py", line 338, in train_step
    optimizer.backward(loss)
  File "/home/zcai75/Github/OFA/fairseq/fairseq/optim/fp16_optimizer.py", line 393, in backward
    loss.backward()
  File "/data/hulab/zcai75/anaconda3/envs/vilt/lib/python3.8/site-packages/torch/_tensor.py", line 396, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph, inputs=inputs)
  File "/data/hulab/zcai75/anaconda3/envs/vilt/lib/python3.8/site-packages/torch/autograd/__init__.py", line 173, in backward
    Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
KeyboardInterrupt
wandb: Waiting for W&B process to finish... (failed 255). Press Control-C to abort syncing.
wandb: 
wandb: Run history:
wandb:                  train/bsz ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:                 train/clip ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:              train/gb_free ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:                train/gnorm ▇▂▁▁▁▂▂▃▃▃▄▄▅▅▅▆▆▆▆▇▇▇▇██
wandb:                 train/loss █▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:           train/loss_scale ▄███▄▄▄▂▂▄▂▂▂▂▁▂▂▂▂▂▁▁▂▁▁
wandb:              train/loss_v1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:              train/loss_v2 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:                   train/lr ▄██▇▇▇▆▆▆▆▅▅▅▄▄▄▃▃▃▃▂▂▂▁▁
wandb:             train/nll_loss █▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:           train/nsentences ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:              train/ntokens ▁▆▅▆▆▆▅▅▇▆█▇▅▅▅▆▆▇▆▄▆▆▇▄▇
wandb:                  train/ppl █▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:          train/sample_size ▁▆▅▆▆▆▅▅▇▆█▇▅▅▅▆▆▇▆▄▆▆▇▄▇
wandb:       train/sample_size_v1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/sample_size_v2 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:           train/train_wall ▅▅▅▅▅▅▄▄▅▅▄▄▅▆▆▅▅▅▄▄▂▁▃▃█
wandb:                  train/ups ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:                 train/wall ▁▁▂▂▂▂▃▃▃▄▄▄▅▅▅▅▆▆▆▇▇▇▇██
wandb:                  train/wpb ▁▆▅▆▅▆▅▅▇▆█▇▅▅▅▆▆▇▆▅▆▅▆▅▇
wandb:                  train/wps ▅▄▄▄▃▄▅▄▅▄▅▅▄▃▃▄▄▄▅▂██▇▆▁
wandb:            train_inner/bsz ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:           train_inner/clip ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:        train_inner/gb_free ▆▆█▄▅▃▃▆▆▄▆▆▃▅▂▄▇▃▄▆▆▅▁▆▇▁▇▂▅▅▄▅▇█▆▄▅▄▁▅
wandb:          train_inner/gnorm ▅▃▂▁▁▁▁▂▂▂▂▂▃▃▃▃▄▄▄▄▄▄▄▅▄▅▅▄▆▆▆▆▇▆▇▇▆▇█▇
wandb:           train_inner/loss █▄▂▂▂▂▂▂▂▂▂▁▁▁▂▂▂▁▂▂▁▂▁▂▁▁▁▁▁▁▂▁▂▁▁▂▁▂▁▁
wandb:     train_inner/loss_scale ▁▁▂█▄▄▄▄▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:        train_inner/loss_v1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:        train_inner/loss_v2 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:             train_inner/lr ▁▃▇███▇▇▇▇▇▇▆▆▆▆▅▅▅▅▅▅▄▄▄▄▄▃▃▃▃▃▂▂▂▂▂▁▁▁
wandb:       train_inner/nll_loss █▄▂▂▂▂▂▂▂▂▂▁▁▁▂▂▂▁▂▂▁▂▁▁▁▁▁▁▁▁▁▁▂▁▁▂▁▂▁▁
wandb:     train_inner/nsentences ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:        train_inner/ntokens ▃▅▁▅▆▄█▂▅▅▅▅█▄▆▅▂▄▂▄▄▄▅▂▆▆▄▅▆▃▄▄▁▆▂▂▄▄▃▇
wandb:            train_inner/ppl █▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:    train_inner/sample_size ▃▅▁▅▆▄█▂▅▅▅▅█▄▆▅▂▄▂▄▄▄▅▂▆▆▄▅▆▃▄▄▁▆▂▂▄▄▃▇
wandb: train_inner/sample_size_v1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: train_inner/sample_size_v2 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     train_inner/train_wall ▅█▅▅█▅█▅▅█▅██▅██▅▅▅▅▅▅█▅▅█▅██▅▅█▁█▅▅▅▅▅▅
wandb:            train_inner/ups ▄▄▄▄▄▄▁▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄█▄▄▄▄▄▄▄
wandb:           train_inner/wall ▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███
wandb:            train_inner/wpb ▃▅▁▅▆▄█▂▅▅▅▅█▄▆▅▂▄▂▄▄▄▅▂▆▆▄▅▆▃▄▄▁▆▂▂▄▄▃▇
wandb:            train_inner/wps ▃▅▁▆▆▄▇▂▅▅▅▄█▄▅▄▂▄▁▄▃▄▅▂▆▆▃▄▅▃▄▃▁▅▂▂▄▄▃▇
wandb: 
wandb: Run summary:
wandb:                  train/bsz 32.0
wandb:                 train/clip 100.0
wandb:              train/gb_free 8.9
wandb:                train/gnorm 20.218
wandb:                 train/loss 2.365
wandb:           train/loss_scale 16.0
wandb:              train/loss_v1 0.0
wandb:              train/loss_v2 0.0
wandb:                   train/lr 0.0
wandb:             train/nll_loss 1.162
wandb:           train/nsentences 31.986
wandb:              train/ntokens 1051.68
wandb:                  train/ppl 2.24
wandb:          train/sample_size 1051.68
wandb:       train/sample_size_v1 0.0
wandb:       train/sample_size_v2 0.0
wandb:           train/train_wall 6694.0
wandb:                  train/ups 0.26
wandb:                 train/wall 166730.0
wandb:                  train/wpb 1051.7
wandb:                  train/wps 271.2
wandb:            train_inner/bsz 32.0
wandb:           train_inner/clip 100.0
wandb:        train_inner/gb_free 8.2
wandb:          train_inner/gnorm 16.587
wandb:           train_inner/loss 2.282
wandb:     train_inner/loss_scale 16.0
wandb:        train_inner/loss_v1 0.0
wandb:        train_inner/loss_v2 0.0
wandb:             train_inner/lr 0.0
wandb:       train_inner/nll_loss 1.068
wandb:     train_inner/nsentences 32.0
wandb:        train_inner/ntokens 1228.0
wandb:            train_inner/ppl 2.1
wandb:    train_inner/sample_size 1228.0
wandb: train_inner/sample_size_v1 0.0
wandb: train_inner/sample_size_v2 0.0
wandb:     train_inner/train_wall 39.0
wandb:            train_inner/ups 0.25
wandb:           train_inner/wall 167272.0
wandb:            train_inner/wpb 1228.0
wandb:            train_inner/wps 312.5
wandb: 
wandb: 🚀 View run _30_1e-5_480 at: https://wandb.ai/jackcai1206/OFA-VG/runs/w7yh51h4
wandb: Synced 6 W&B file(s), 0 media file(s), 2 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230520_175725-w7yh51h4/logs
Traceback (most recent call last):
  File "/data/hulab/zcai75/anaconda3/envs/vilt/lib/python3.8/runpy.py", line 194, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File "/data/hulab/zcai75/anaconda3/envs/vilt/lib/python3.8/runpy.py", line 87, in _run_code
    exec(code, run_globals)
  File "/data/hulab/zcai75/anaconda3/envs/vilt/lib/python3.8/site-packages/torch/distributed/launch.py", line 193, in <module>
    main()
  File "/data/hulab/zcai75/anaconda3/envs/vilt/lib/python3.8/site-packages/torch/distributed/launch.py", line 189, in main
    launch(args)
  File "/data/hulab/zcai75/anaconda3/envs/vilt/lib/python3.8/site-packages/torch/distributed/launch.py", line 174, in launch
    run(args)
  File "/data/hulab/zcai75/anaconda3/envs/vilt/lib/python3.8/site-packages/torch/distributed/run.py", line 752, in run
    elastic_launch(
  File "/data/hulab/zcai75/anaconda3/envs/vilt/lib/python3.8/site-packages/torch/distributed/launcher/api.py", line 131, in __call__
    return launch_agent(self._config, self._entrypoint, list(args))
  File "/data/hulab/zcai75/anaconda3/envs/vilt/lib/python3.8/site-packages/torch/distributed/launcher/api.py", line 236, in launch_agent
    result = agent.run()
  File "/data/hulab/zcai75/anaconda3/envs/vilt/lib/python3.8/site-packages/torch/distributed/elastic/metrics/api.py", line 125, in wrapper
    result = f(*args, **kwargs)
  File "/data/hulab/zcai75/anaconda3/envs/vilt/lib/python3.8/site-packages/torch/distributed/elastic/agent/server/api.py", line 709, in run
    result = self._invoke_run(role)
  File "/data/hulab/zcai75/anaconda3/envs/vilt/lib/python3.8/site-packages/torch/distributed/elastic/agent/server/api.py", line 850, in _invoke_run
    time.sleep(monitor_interval)
  File "/data/hulab/zcai75/anaconda3/envs/vilt/lib/python3.8/site-packages/torch/distributed/elastic/multiprocessing/api.py", line 60, in _terminate_process_handler
    raise SignalException(f"Process {os.getpid()} got signal: {sigval}", sigval=sigval)
torch.distributed.elastic.multiprocessing.api.SignalException: Process 4191315 got signal: 2

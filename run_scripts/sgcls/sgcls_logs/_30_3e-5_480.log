/data/hulab/zcai75/anaconda3/envs/vilt/lib/python3.8/site-packages/torch/distributed/launch.py:178: FutureWarning: The module torch.distributed.launch is deprecated
and will be removed in future. Use torchrun.
Note that --use_env is set by default in torchrun.
If your script expects `--local_rank` argument to be set, please
change it to read from `os.environ['LOCAL_RANK']` instead. See 
https://pytorch.org/docs/stable/distributed.html#launch-utility for 
further instructions

  warnings.warn(
WARNING:torch.distributed.run:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
2023-05-07 23:55:51 - utils.py[line:255] - INFO: distributed init (rank 0): env://
2023-05-07 23:55:51 - utils.py[line:261] - INFO: Start init
2023-05-07 23:55:51 - distributed_c10d.py[line:228] - INFO: Added key: store_based_barrier_key:1 to store for rank: 0
2023-05-07 23:55:51 - utils.py[line:255] - INFO: distributed init (rank 1): env://
2023-05-07 23:55:51 - utils.py[line:261] - INFO: Start init
2023-05-07 23:55:51 - distributed_c10d.py[line:228] - INFO: Added key: store_based_barrier_key:1 to store for rank: 1
2023-05-07 23:55:51 - distributed_c10d.py[line:262] - INFO: Rank 1: Completed store-based barrier for key:store_based_barrier_key:1 with 2 nodes.
2023-05-07 23:55:51 - utils.py[line:271] - INFO: initialized host AMD4RTX3090GPU14 as rank 1
single-machine distributed training is initialized.
2023-05-07 23:55:51 - distributed_c10d.py[line:262] - INFO: Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 2 nodes.
2023-05-07 23:55:51 - utils.py[line:271] - INFO: initialized host AMD4RTX3090GPU14 as rank 0
single-machine distributed training is initialized.
2023-05-07 23:55:52 - train.py[line:77] - INFO: {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 10, 'log_format': 'simple', 'log_file': None, 'tensorboard_logdir': './tensorboard/_30_3e-5_480', 'wandb_project': 'OFA-VG', 'azureml_logging': False, 'seed': 1, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': True, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': 512, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': '../../ofa_module', 'empty_cache_freq': 0, 'all_gather_list_size': 2097152, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 2, 'distributed_num_procs': 2, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': 'env://', 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': True, 'ddp_backend': 'pytorch_ddp', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': True, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_algorithm': 'LocalSGD', 'localsgd_frequency': 3, 'nprocs_per_node': 2, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': True, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False}, 'dataset': {'_name': None, 'num_workers': 0, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': None, 'batch_size': 4, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 30, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': 7, 'disable_validation': False, 'max_tokens_valid': None, 'batch_size_valid': 4, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0}, 'optimization': {'_name': None, 'max_epoch': 30, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 1.0, 'sentence_avg': False, 'update_freq': [8], 'lr': [3e-05], 'stop_min_lr': -1.0, 'use_bmuf': False}, 'checkpoint': {'_name': None, 'save_dir': '../../checkpoints/OFA/sgcls_checkpoints/_30_3e-5_480/tmp', 'restore_file': '../../checkpoints/ofa_large.pt', 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 10, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': 1, 'no_save': False, 'no_epoch_checkpoints': False, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': True, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1, 'use_ema_weights_to_init_param': False, 'use_latest_weights_to_init_ema': False}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 2}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': Namespace(_name='ofa_large', activation_fn='gelu', adam_betas='(0.9,0.999)', adam_eps=1e-08, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, add_type_embedding=True, all_gather_list_size=2097152, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, arch='ofa_large', attention_dropout=0.0, attn_scale_factor=2, azureml_logging=False, batch_size=4, batch_size_valid=4, best_checkpoint_metric='loss', bf16=False, bitfit=False, bpe=None, bpe_dir='../../utils/BPE', broadcast_buffers=False, bucket_cap_mb=25, checkpoint_shard_count=1, checkpoint_suffix='', clip_norm=1.0, code_dict_size=8192, code_image_size=128, code_layernorm_embedding=True, combine_valid_subsets=None, constraint_range=None, cpu=False, cpu_offload=False, criterion='adjust_label_smoothed_cross_entropy', cross_self_attention=False, curriculum=0, data='../../dataset/OFA_data/sgcls/vg_train_full.tsv,../../dataset/OFA_data/sgcls/vg_val_full.tsv', data_buffer_size=10, dataset_impl=None, ddp_backend='pytorch_ddp', ddp_comm_hook='none', decoder_attention_heads=16, decoder_drop_path_rate=0.1, decoder_embed_dim=1024, decoder_embed_path=None, decoder_ffn_embed_dim=4096, decoder_input_dim=1024, decoder_layerdrop=0, decoder_layers=12, decoder_layers_to_keep=None, decoder_learned_pos=True, decoder_normalize_before=True, decoder_output_dim=1024, device_id=0, disable_entangle=True, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_num_procs=2, distributed_port=-1, distributed_rank=0, distributed_world_size=2, drop_worst_after=0, drop_worst_ratio=0.0, dropout=0.1, ema_decay=0.9999, ema_fp32=False, ema_seed_model=None, ema_start_update=0, ema_update_freq=1, empty_cache_freq=0, encoder_attention_heads=16, encoder_drop_path_rate=0.1, encoder_embed_dim=1024, encoder_embed_path=None, encoder_ffn_embed_dim=4096, encoder_layerdrop=0, encoder_layers=12, encoder_layers_to_keep=None, encoder_learned_pos=True, encoder_normalize_before=True, end_learning_rate=0.0, entangle_position_embedding=False, eos=2, eval_args='{"beam":5,"max_len_a":0,"max_len_b":200}', eval_print_samples=False, fast_stat_sync=False, find_unused_parameters=True, finetune_from_model=None, fix_batches_to_gpus=False, fixed_validation_seed=7, force_anneal=None, fp16=True, fp16_adam_stats=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=512, fp32_reduce_scatter=False, freeze_decoder_embedding=False, freeze_encoder_embedding=False, gen_subset='test', gradient_as_bucket_view=False, heartbeat_timeout=-1, ignore_eos=False, ignore_prefix_size=0, ignore_unused_valid_subsets=False, image_bucket_size=42, imagenet_default_mean_and_std=False, keep_best_checkpoints=1, keep_interval_updates=-1, keep_interval_updates_pattern=-1, keep_last_epochs=-1, label_smoothing=0.1, layernorm_embedding=True, load_checkpoint_on_all_dp_ranks=False, localsgd_frequency=3, log_file=None, log_format='simple', log_interval=10, lr=[3e-05], lr_scheduler='polynomial_decay', max_epoch=30, max_source_positions=1024, max_src_length=100, max_target_positions=1024, max_tgt_length=100, max_tokens=None, max_tokens_valid=None, max_update=0, max_valid_steps=None, maximize_best_checkpoint_metric=True, memory_efficient_bf16=False, memory_efficient_fp16=True, min_loss_scale=0.0001, min_params_to_wrap=100000000, model_parallel_size=1, no_cross_attention=False, no_epoch_checkpoints=False, no_last_checkpoints=False, no_progress_bar=False, no_reshard_after_forward=False, no_save=False, no_save_optimizer_state=False, no_scale_embedding=True, no_seed_provided=False, no_token_positional_embeddings=False, nprocs_per_node=2, num_bins=1000, num_shards=1, num_workers=0, on_cpu_convert_precision=False, optimizer='adam', optimizer_overrides='{}', orig_patch_image_size=256, pad=1, patch_image_size=480, patch_layernorm_embedding=True, patience=-1, pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, plasma_path='/tmp/plasma', pooler_activation_fn='tanh', pooler_classifier='mlp', pooler_dropout=0.0, power=1.0, profile=False, quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, quantization_config_path=None, reg_alpha=1.0, relu_dropout=0.0, report_accuracy=False, required_batch_size_multiple=8, required_seq_len_multiple=1, reset_dataloader=False, reset_logging=False, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, resnet_drop_path_rate=0.0, resnet_type='resnet152', restore_file='../../checkpoints/ofa_large.pt', sample_patch_num=196, save_dir='../../checkpoints/OFA/sgcls_checkpoints/_30_3e-5_480/tmp', save_interval=10, save_interval_updates=0, scale_attn=True, scale_fc=True, scale_heads=True, scale_resids=False, scoring='bleu', seed=1, selected_cols=None, sentence_avg=False, shard_id=0, share_all_embeddings=True, share_decoder_input_output_embed=True, simul_type=None, skip_invalid_size_inputs_valid_test=False, slowmo_algorithm='LocalSGD', slowmo_momentum=None, stop_min_lr=-1.0, stop_time_hours=0, store_ema=False, suppress_crashes=False, sync_bn=False, task='sgcls', tensorboard_logdir='./tensorboard/_30_3e-5_480', threshold_loss_scale=None, token_bucket_size=256, tokenizer=None, total_num_update=1000000, tpu=False, train_subset='train', unk=3, update_freq=[8], use_bmuf=False, use_ema_weights_to_init_param=False, use_latest_weights_to_init_ema=False, use_old_adam=False, use_plasma_view=False, use_rdrop=False, use_sharded_state=False, user_dir='../../ofa_module', valid_subset='valid', validate_after_updates=0, validate_interval=30, validate_interval_updates=0, vg_json_dir=None, wandb_project='OFA-VG', warmup_ratio=0.06, warmup_updates=0, weight_decay=0.01, write_checkpoints_asynchronously=False, zero_sharding='none'), 'task': {'_name': 'sgcls', 'data': '../../dataset/OFA_data/sgcls/vg_train_full.tsv,../../dataset/OFA_data/sgcls/vg_val_full.tsv', 'selected_cols': None, 'bpe': None, 'bpe_dir': '../../utils/BPE', 'max_source_positions': 1024, 'max_target_positions': 1024, 'max_src_length': 100, 'max_tgt_length': 100, 'code_dict_size': 8192, 'patch_image_size': 480, 'orig_patch_image_size': 256, 'num_bins': 1000, 'imagenet_default_mean_and_std': False, 'constraint_range': None, 'eval_args': '{"beam":5,"max_len_a":0,"max_len_b":200}', 'eval_print_samples': False, 'vg_json_dir': None}, 'criterion': {'_name': 'adjust_label_smoothed_cross_entropy', 'label_smoothing': 0.1, 'report_accuracy': False, 'ignore_prefix_size': 0, 'ignore_eos': False, 'sentence_avg': False, 'drop_worst_ratio': 0.0, 'drop_worst_after': 0, 'use_rdrop': False, 'reg_alpha': 1.0, 'sample_patch_num': 196, 'constraint_range': None}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9,0.999)', 'adam_eps': 1e-08, 'weight_decay': 0.01, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': False, 'lr': [3e-05]}, 'lr_scheduler': {'_name': 'polynomial_decay', 'warmup_updates': 0, 'warmup_ratio': 0.06, 'force_anneal': None, 'end_learning_rate': 0.0, 'power': 1.0, 'total_num_update': 1000000.0, 'lr': [3e-05]}, 'scoring': {'_name': 'bleu', 'pad': 1, 'eos': 2, 'unk': 3}, 'bpe': None, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}, 'simul_type': None}
2023-05-07 23:55:52 - sg_cls.py[line:82] - INFO: sgcls setup: source dictionary: 51267 types
2023-05-07 23:55:52 - sg_cls.py[line:83] - INFO: sgcls setup: target dictionary: 51267 types
/data/hulab/zcai75/anaconda3/envs/vilt/lib/python3.8/site-packages/torch/functional.py:478: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at  ../aten/src/ATen/native/TensorShape.cpp:2894.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/data/hulab/zcai75/anaconda3/envs/vilt/lib/python3.8/site-packages/torch/functional.py:478: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at  ../aten/src/ATen/native/TensorShape.cpp:2894.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
local datafile ../../dataset/OFA_data/sgcls/vg_val_full.tsv slice_id 1 begin to initialize row_count and line_idx-to-offset mapping
2023-05-07 23:55:58 - train.py[line:110] - INFO: OFAModel(
  (encoder): TransformerEncoder(
    (encoder_dropout): Dropout(p=0.2, inplace=False)
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(51267, 1024, padding_idx=1)
    (layernorm_embedding): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (type_embedding): Embedding(2, 1024)
    (embed_images): ResNet(
      (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)
      (layer1): Sequential(
        (0): Bottleneck(
          (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (downsample): Sequential(
            (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (drop_path): Identity()
        )
        (1): Bottleneck(
          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (2): Bottleneck(
          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
      )
      (layer2): Sequential(
        (0): Bottleneck(
          (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (downsample): Sequential(
            (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
            (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (drop_path): Identity()
        )
        (1): Bottleneck(
          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (2): Bottleneck(
          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (3): Bottleneck(
          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (4): Bottleneck(
          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (5): Bottleneck(
          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (6): Bottleneck(
          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (7): Bottleneck(
          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
      )
      (layer3): Sequential(
        (0): Bottleneck(
          (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (downsample): Sequential(
            (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)
            (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (drop_path): Identity()
        )
        (1): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (2): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (3): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (4): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (5): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (6): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (7): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (8): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (9): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (10): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (11): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (12): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (13): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (14): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (15): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (16): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (17): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (18): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (19): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (20): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (21): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (22): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (23): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (24): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (25): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (26): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (27): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (28): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (29): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (30): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (31): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (32): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (33): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (34): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (35): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
      )
    )
    (image_proj): Linear(in_features=1024, out_features=1024, bias=True)
    (patch_layernorm_embedding): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (embed_positions): Embedding(1026, 1024)
    (embed_image_positions): Embedding(1765, 1024)
    (pos_ln): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (image_pos_ln): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (pos_q_linear): Linear(in_features=1024, out_features=1024, bias=True)
    (pos_k_linear): Linear(in_features=1024, out_features=1024, bias=True)
    (layers): ModuleList(
      (0): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=1024, out_features=4096, bias=True)
        (fc2): Linear(in_features=4096, out_features=1024, bias=True)
        (attn_ln): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)
        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (drop_path): Identity()
      )
      (1): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=1024, out_features=4096, bias=True)
        (fc2): Linear(in_features=4096, out_features=1024, bias=True)
        (attn_ln): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)
        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(p=0.00909090880304575)
      )
      (2): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=1024, out_features=4096, bias=True)
        (fc2): Linear(in_features=4096, out_features=1024, bias=True)
        (attn_ln): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)
        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(p=0.0181818176060915)
      )
      (3): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=1024, out_features=4096, bias=True)
        (fc2): Linear(in_features=4096, out_features=1024, bias=True)
        (attn_ln): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)
        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(p=0.027272727340459824)
      )
      (4): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=1024, out_features=4096, bias=True)
        (fc2): Linear(in_features=4096, out_features=1024, bias=True)
        (attn_ln): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)
        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(p=0.036363635212183)
      )
      (5): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=1024, out_features=4096, bias=True)
        (fc2): Linear(in_features=4096, out_features=1024, bias=True)
        (attn_ln): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)
        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(p=0.045454543083906174)
      )
      (6): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=1024, out_features=4096, bias=True)
        (fc2): Linear(in_features=4096, out_features=1024, bias=True)
        (attn_ln): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)
        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(p=0.054545458406209946)
      )
      (7): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=1024, out_features=4096, bias=True)
        (fc2): Linear(in_features=4096, out_features=1024, bias=True)
        (attn_ln): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)
        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(p=0.06363636255264282)
      )
      (8): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=1024, out_features=4096, bias=True)
        (fc2): Linear(in_features=4096, out_features=1024, bias=True)
        (attn_ln): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)
        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(p=0.0727272778749466)
      )
      (9): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=1024, out_features=4096, bias=True)
        (fc2): Linear(in_features=4096, out_features=1024, bias=True)
        (attn_ln): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)
        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(p=0.08181818574666977)
      )
      (10): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=1024, out_features=4096, bias=True)
        (fc2): Linear(in_features=4096, out_features=1024, bias=True)
        (attn_ln): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)
        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(p=0.09090909361839294)
      )
      (11): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=1024, out_features=4096, bias=True)
        (fc2): Linear(in_features=4096, out_features=1024, bias=True)
        (attn_ln): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)
        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(p=0.10000000149011612)
      )
    )
    (layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (token_rel_pos_table_list): ModuleList(
      (0): Embedding(511, 16)
      (1): Embedding(511, 16)
      (2): Embedding(511, 16)
      (3): Embedding(511, 16)
      (4): Embedding(511, 16)
      (5): Embedding(511, 16)
      (6): Embedding(511, 16)
      (7): Embedding(511, 16)
      (8): Embedding(511, 16)
      (9): Embedding(511, 16)
      (10): Embedding(511, 16)
      (11): Embedding(511, 16)
    )
    (image_rel_pos_table_list): ModuleList(
      (0): Embedding(6892, 16)
      (1): Embedding(6892, 16)
      (2): Embedding(6892, 16)
      (3): Embedding(6892, 16)
      (4): Embedding(6892, 16)
      (5): Embedding(6892, 16)
      (6): Embedding(6892, 16)
      (7): Embedding(6892, 16)
      (8): Embedding(6892, 16)
      (9): Embedding(6892, 16)
      (10): Embedding(6892, 16)
      (11): Embedding(6892, 16)
    )
  )
  (decoder): TransformerDecoder(
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(51267, 1024, padding_idx=1)
    (layernorm_embedding): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (embed_positions): Embedding(1026, 1024)
    (embed_image_positions): Embedding(1765, 1024)
    (pos_ln): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (image_pos_ln): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (self_pos_q_linear): Linear(in_features=1024, out_features=1024, bias=True)
    (self_pos_k_linear): Linear(in_features=1024, out_features=1024, bias=True)
    (cross_pos_q_linear): Linear(in_features=1024, out_features=1024, bias=True)
    (cross_pos_k_linear): Linear(in_features=1024, out_features=1024, bias=True)
    (code_layernorm_embedding): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (layers): ModuleList(
      (0): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)
        )
        (self_attn_ln): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (cross_attn_ln): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=1024, out_features=4096, bias=True)
        (fc2): Linear(in_features=4096, out_features=1024, bias=True)
        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (drop_path): Identity()
      )
      (1): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)
        )
        (self_attn_ln): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (cross_attn_ln): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=1024, out_features=4096, bias=True)
        (fc2): Linear(in_features=4096, out_features=1024, bias=True)
        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(p=0.00909090880304575)
      )
      (2): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)
        )
        (self_attn_ln): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (cross_attn_ln): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=1024, out_features=4096, bias=True)
        (fc2): Linear(in_features=4096, out_features=1024, bias=True)
        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(p=0.0181818176060915)
      )
      (3): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)
        )
        (self_attn_ln): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (cross_attn_ln): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=1024, out_features=4096, bias=True)
        (fc2): Linear(in_features=4096, out_features=1024, bias=True)
        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(p=0.027272727340459824)
      )
      (4): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)
        )
        (self_attn_ln): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (cross_attn_ln): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=1024, out_features=4096, bias=True)
        (fc2): Linear(in_features=4096, out_features=1024, bias=True)
        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(p=0.036363635212183)
      )
      (5): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)
        )
        (self_attn_ln): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (cross_attn_ln): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=1024, out_features=4096, bias=True)
        (fc2): Linear(in_features=4096, out_features=1024, bias=True)
        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(p=0.045454543083906174)
      )
      (6): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)
        )
        (self_attn_ln): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (cross_attn_ln): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=1024, out_features=4096, bias=True)
        (fc2): Linear(in_features=4096, out_features=1024, bias=True)
        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(p=0.054545458406209946)
      )
      (7): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)
        )
        (self_attn_ln): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (cross_attn_ln): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=1024, out_features=4096, bias=True)
        (fc2): Linear(in_features=4096, out_features=1024, bias=True)
        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(p=0.06363636255264282)
      )
      (8): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)
        )
        (self_attn_ln): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (cross_attn_ln): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=1024, out_features=4096, bias=True)
        (fc2): Linear(in_features=4096, out_features=1024, bias=True)
        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(p=0.0727272778749466)
      )
      (9): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)
        )
        (self_attn_ln): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (cross_attn_ln): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=1024, out_features=4096, bias=True)
        (fc2): Linear(in_features=4096, out_features=1024, bias=True)
        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(p=0.08181818574666977)
      )
      (10): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)
        )
        (self_attn_ln): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (cross_attn_ln): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=1024, out_features=4096, bias=True)
        (fc2): Linear(in_features=4096, out_features=1024, bias=True)
        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(p=0.09090909361839294)
      )
      (11): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)
        )
        (self_attn_ln): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (cross_attn_ln): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=1024, out_features=4096, bias=True)
        (fc2): Linear(in_features=4096, out_features=1024, bias=True)
        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(p=0.10000000149011612)
      )
    )
    (layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (output_projection): Linear(in_features=1024, out_features=51267, bias=False)
    (token_rel_pos_table_list): ModuleList(
      (0): Embedding(511, 16)
      (1): Embedding(511, 16)
      (2): Embedding(511, 16)
      (3): Embedding(511, 16)
      (4): Embedding(511, 16)
      (5): Embedding(511, 16)
      (6): Embedding(511, 16)
      (7): Embedding(511, 16)
      (8): Embedding(511, 16)
      (9): Embedding(511, 16)
      (10): Embedding(511, 16)
      (11): Embedding(511, 16)
    )
    (image_rel_pos_table_list): ModuleList(
      (0): Embedding(6892, 16)
      (1): Embedding(6892, 16)
      (2): Embedding(6892, 16)
      (3): Embedding(6892, 16)
      (4): Embedding(6892, 16)
      (5): Embedding(6892, 16)
      (6): Embedding(6892, 16)
      (7): Embedding(6892, 16)
      (8): Embedding(6892, 16)
      (9): Embedding(6892, 16)
      (10): Embedding(6892, 16)
      (11): Embedding(6892, 16)
    )
  )
  (classification_heads): ModuleDict()
)
2023-05-07 23:55:58 - train.py[line:111] - INFO: task: SGClsTask
2023-05-07 23:55:58 - train.py[line:112] - INFO: model: OFAModel
2023-05-07 23:55:58 - train.py[line:113] - INFO: criterion: AdjustLabelSmoothedCrossEntropyCriterion
2023-05-07 23:55:58 - train.py[line:114] - INFO: num. shared model params: 464,590,592 (num. trained: 464,590,592)
2023-05-07 23:55:58 - train.py[line:121] - INFO: num. expert model params: 0 (num. trained: 0)
local datafile ../../dataset/OFA_data/sgcls/vg_val_full.tsv slice_id 0 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../dataset/OFA_data/sgcls/vg_val_full.tsv slice_id 1 finished initializing row_count and line_idx-to-offset mapping
file ../../dataset/OFA_data/sgcls/vg_val_full.tsv slice_id 1 row count 11440 total row count 22880
/data/hulab/zcai75/anaconda3/envs/vilt/lib/python3.8/site-packages/torchvision/transforms/transforms.py:332: UserWarning: Argument 'interpolation' of type int is deprecated since 0.13 and will be removed in 0.15. Please use InterpolationMode enum.
  warnings.warn(
local datafile ../../dataset/OFA_data/sgcls/vg_val_full.tsv slice_id 0 finished initializing row_count and line_idx-to-offset mapping
file ../../dataset/OFA_data/sgcls/vg_val_full.tsv slice_id 0 row count 11440 total row count 22880
/data/hulab/zcai75/anaconda3/envs/vilt/lib/python3.8/site-packages/torchvision/transforms/transforms.py:332: UserWarning: Argument 'interpolation' of type int is deprecated since 0.13 and will be removed in 0.15. Please use InterpolationMode enum.
  warnings.warn(
2023-05-07 23:55:59 - distributed_c10d.py[line:228] - INFO: Added key: store_based_barrier_key:2 to store for rank: 0
2023-05-07 23:55:59 - distributed_c10d.py[line:262] - INFO: Rank 0: Completed store-based barrier for key:store_based_barrier_key:2 with 2 nodes.
2023-05-07 23:55:59 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_tokens.weight <- decoder.embed_tokens.weight
2023-05-07 23:55:59 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_tokens.weight <- decoder.output_projection.weight
2023-05-07 23:55:59 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer1.0.conv1.bias
2023-05-07 23:55:59 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer1.0.conv2.bias
2023-05-07 23:55:59 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer1.0.conv3.bias
2023-05-07 23:55:59 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer1.0.downsample.0.bias
2023-05-07 23:55:59 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer1.1.conv1.bias
2023-05-07 23:55:59 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer1.1.conv2.bias
2023-05-07 23:55:59 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer1.1.conv3.bias
2023-05-07 23:55:59 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer1.2.conv1.bias
2023-05-07 23:55:59 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer1.2.conv2.bias
2023-05-07 23:55:59 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer1.2.conv3.bias
2023-05-07 23:55:59 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.0.conv1.bias
2023-05-07 23:55:59 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.0.conv2.bias
2023-05-07 23:55:59 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.0.conv3.bias
2023-05-07 23:55:59 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.0.downsample.0.bias
2023-05-07 23:55:59 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.1.conv1.bias
2023-05-07 23:55:59 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.1.conv2.bias
2023-05-07 23:55:59 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.1.conv3.bias
2023-05-07 23:55:59 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.2.conv1.bias
2023-05-07 23:55:59 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.2.conv2.bias
2023-05-07 23:55:59 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.2.conv3.bias
2023-05-07 23:55:59 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.3.conv1.bias
2023-05-07 23:55:59 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.3.conv2.bias
2023-05-07 23:55:59 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.3.conv3.bias
2023-05-07 23:55:59 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.4.conv1.bias
2023-05-07 23:55:59 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.4.conv2.bias
2023-05-07 23:55:59 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.4.conv3.bias
2023-05-07 23:55:59 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.5.conv1.bias
2023-05-07 23:55:59 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.5.conv2.bias
2023-05-07 23:55:59 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.5.conv3.bias
2023-05-07 23:55:59 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.6.conv1.bias
2023-05-07 23:55:59 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.6.conv2.bias
2023-05-07 23:55:59 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.6.conv3.bias
2023-05-07 23:55:59 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.7.conv1.bias
2023-05-07 23:55:59 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.7.conv2.bias
2023-05-07 23:55:59 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.7.conv3.bias
2023-05-07 23:55:59 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.0.conv1.bias
2023-05-07 23:55:59 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.0.conv2.bias
2023-05-07 23:55:59 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.0.conv3.bias
2023-05-07 23:55:59 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.0.downsample.0.bias
2023-05-07 23:55:59 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.1.conv1.bias
2023-05-07 23:55:59 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.1.conv2.bias
2023-05-07 23:55:59 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.1.conv3.bias
2023-05-07 23:55:59 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.2.conv1.bias
2023-05-07 23:55:59 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.2.conv2.bias
2023-05-07 23:55:59 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.2.conv3.bias
2023-05-07 23:55:59 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.3.conv1.bias
2023-05-07 23:55:59 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.3.conv2.bias
2023-05-07 23:55:59 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.3.conv3.bias
2023-05-07 23:55:59 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.4.conv1.bias
2023-05-07 23:55:59 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.4.conv2.bias
2023-05-07 23:55:59 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.4.conv3.bias
2023-05-07 23:55:59 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.5.conv1.bias
2023-05-07 23:55:59 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.5.conv2.bias
2023-05-07 23:55:59 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.5.conv3.bias
2023-05-07 23:55:59 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.6.conv1.bias
2023-05-07 23:55:59 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.6.conv2.bias
2023-05-07 23:55:59 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.6.conv3.bias
2023-05-07 23:55:59 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.7.conv1.bias
2023-05-07 23:55:59 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.7.conv2.bias
2023-05-07 23:55:59 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.7.conv3.bias
2023-05-07 23:55:59 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.8.conv1.bias
2023-05-07 23:55:59 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.8.conv2.bias
2023-05-07 23:55:59 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.8.conv3.bias
2023-05-07 23:55:59 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.9.conv1.bias
2023-05-07 23:55:59 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.9.conv2.bias
2023-05-07 23:55:59 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.9.conv3.bias
2023-05-07 23:55:59 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.10.conv1.bias
2023-05-07 23:55:59 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.10.conv2.bias
2023-05-07 23:55:59 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.10.conv3.bias
2023-05-07 23:55:59 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.11.conv1.bias
2023-05-07 23:55:59 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.11.conv2.bias
2023-05-07 23:55:59 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.11.conv3.bias
2023-05-07 23:55:59 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.12.conv1.bias
2023-05-07 23:55:59 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.12.conv2.bias
2023-05-07 23:55:59 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.12.conv3.bias
2023-05-07 23:55:59 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.13.conv1.bias
2023-05-07 23:55:59 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.13.conv2.bias
2023-05-07 23:55:59 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.13.conv3.bias
2023-05-07 23:55:59 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.14.conv1.bias
2023-05-07 23:55:59 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.14.conv2.bias
2023-05-07 23:55:59 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.14.conv3.bias
2023-05-07 23:55:59 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.15.conv1.bias
2023-05-07 23:55:59 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.15.conv2.bias
2023-05-07 23:55:59 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.15.conv3.bias
2023-05-07 23:55:59 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.16.conv1.bias
2023-05-07 23:55:59 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.16.conv2.bias
2023-05-07 23:55:59 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.16.conv3.bias
2023-05-07 23:55:59 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.17.conv1.bias
2023-05-07 23:55:59 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.17.conv2.bias
2023-05-07 23:55:59 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.17.conv3.bias
2023-05-07 23:55:59 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.18.conv1.bias
2023-05-07 23:55:59 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.18.conv2.bias
2023-05-07 23:55:59 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.18.conv3.bias
2023-05-07 23:55:59 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.19.conv1.bias
2023-05-07 23:55:59 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.19.conv2.bias
2023-05-07 23:55:59 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.19.conv3.bias
2023-05-07 23:55:59 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.20.conv1.bias
2023-05-07 23:55:59 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.20.conv2.bias
2023-05-07 23:55:59 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.20.conv3.bias
2023-05-07 23:55:59 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.21.conv1.bias
2023-05-07 23:55:59 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.21.conv2.bias
2023-05-07 23:55:59 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.21.conv3.bias
2023-05-07 23:55:59 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.22.conv1.bias
2023-05-07 23:55:59 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.22.conv2.bias
2023-05-07 23:55:59 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.22.conv3.bias
2023-05-07 23:55:59 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.23.conv1.bias
2023-05-07 23:55:59 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.23.conv2.bias
2023-05-07 23:55:59 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.23.conv3.bias
2023-05-07 23:55:59 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.24.conv1.bias
2023-05-07 23:55:59 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.24.conv2.bias
2023-05-07 23:55:59 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.24.conv3.bias
2023-05-07 23:55:59 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.25.conv1.bias
2023-05-07 23:55:59 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.25.conv2.bias
2023-05-07 23:55:59 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.25.conv3.bias
2023-05-07 23:55:59 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.26.conv1.bias
2023-05-07 23:55:59 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.26.conv2.bias
2023-05-07 23:55:59 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.26.conv3.bias
2023-05-07 23:55:59 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.27.conv1.bias
2023-05-07 23:55:59 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.27.conv2.bias
2023-05-07 23:55:59 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.27.conv3.bias
2023-05-07 23:55:59 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.28.conv1.bias
2023-05-07 23:55:59 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.28.conv2.bias
2023-05-07 23:55:59 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.28.conv3.bias
2023-05-07 23:55:59 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.29.conv1.bias
2023-05-07 23:55:59 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.29.conv2.bias
2023-05-07 23:55:59 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.29.conv3.bias
2023-05-07 23:55:59 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.30.conv1.bias
2023-05-07 23:55:59 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.30.conv2.bias
2023-05-07 23:55:59 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.30.conv3.bias
2023-05-07 23:55:59 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.31.conv1.bias
2023-05-07 23:55:59 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.31.conv2.bias
2023-05-07 23:55:59 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.31.conv3.bias
2023-05-07 23:55:59 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.32.conv1.bias
2023-05-07 23:55:59 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.32.conv2.bias
2023-05-07 23:55:59 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.32.conv3.bias
2023-05-07 23:55:59 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.33.conv1.bias
2023-05-07 23:55:59 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.33.conv2.bias
2023-05-07 23:55:59 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.33.conv3.bias
2023-05-07 23:55:59 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.34.conv1.bias
2023-05-07 23:55:59 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.34.conv2.bias
2023-05-07 23:55:59 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.34.conv3.bias
2023-05-07 23:55:59 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.35.conv1.bias
2023-05-07 23:55:59 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.35.conv2.bias
2023-05-07 23:55:59 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.35.conv3.bias
2023-05-07 23:55:59 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- decoder.output_projection.bias
2023-05-07 23:55:59 - utils.py[line:759] - INFO: ***********************CUDA enviroments for all 2 workers***********************
2023-05-07 23:55:59 - utils.py[line:761] - INFO: rank   0: capabilities =  8.6  ; total memory = 23.688 GB ; name = NVIDIA GeForce RTX 3090 Ti              
2023-05-07 23:55:59 - utils.py[line:761] - INFO: rank   1: capabilities =  8.6  ; total memory = 23.688 GB ; name = NVIDIA GeForce RTX 3090 Ti              
2023-05-07 23:55:59 - utils.py[line:767] - INFO: ***********************CUDA enviroments for all 2 workers***********************
2023-05-07 23:55:59 - train.py[line:152] - INFO: training on 2 devices (GPUs/TPUs)
2023-05-07 23:55:59 - train.py[line:157] - INFO: max tokens per device = None and max sentences per device = 4
2023-05-07 23:55:59 - trainer.py[line:458] - INFO: Preparing to load checkpoint ../../checkpoints/ofa_large.pt
2023-05-07 23:55:59 - trainer.py[line:624] - INFO: No existing checkpoint found ../../checkpoints/ofa_large.pt
2023-05-07 23:55:59 - trainer.py[line:639] - INFO: loading train data for epoch 1
local datafile ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 1 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 0 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 0 finished initializing row_count and line_idx-to-offset mapping
file ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 0 row count 27700 total row count 55400
local datafile ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 1 finished initializing row_count and line_idx-to-offset mapping
file ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 1 row count 27700 total row count 55400
slice_id 1 seek offset 27700
Total steps 25980, warmup steps 1558, warmup_factor 0.0006418485237483953
slice_id 0 seek offset 0
Total steps 25980, warmup steps 1558, warmup_factor 0.0006418485237483953
wandb: Currently logged in as: jackcai1206. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.15.2 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /home/zcai75/Github/OFA_forked/run_scripts/sgcls/wandb/run-20230507_235602-8x2h18ua
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run tmp
wandb: ⭐️ View project at https://wandb.ai/jackcai1206/OFA-VG
wandb: 🚀 View run at https://wandb.ai/jackcai1206/OFA-VG/runs/8x2h18ua
2023-05-07 23:56:08 - trainer.py[line:703] - INFO: begin training epoch 1
2023-05-07 23:56:08 - train.py[line:305] - INFO: Start iterating over samples
/home/zcai75/Github/OFA/fairseq/fairseq/utils.py:372: UserWarning: amp_C fused kernels unavailable, disabling multi_tensor_l2norm; you may get better performance by installing NVIDIA's apex library
  warnings.warn(
/home/zcai75/Github/OFA/fairseq/fairseq/utils.py:372: UserWarning: amp_C fused kernels unavailable, disabling multi_tensor_l2norm; you may get better performance by installing NVIDIA's apex library
  warnings.warn(
2023-05-07 23:56:15 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2023-05-07 23:56:20 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2023-05-07 23:56:25 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2023-05-07 23:57:07 - progress_bar.py[line:272] - INFO: epoch 001:     13 / 866 loss=11.053, loss_v1=0, loss_v2=0, nll_loss=11.054, ntokens=2047.5, nsentences=64, sample_size=2047.5, sample_size_v1=0, sample_size_v2=0, ppl=2125.73, wps=502.3, ups=0.25, wpb=2047.5, bsz=64, num_updates=10, lr=1.92555e-07, gnorm=36.155, clip=100, loss_scale=16, train_wall=59, gb_free=7.3, wall=68
2023-05-07 23:57:48 - progress_bar.py[line:272] - INFO: epoch 001:     23 / 866 loss=11.035, loss_v1=0, loss_v2=0, nll_loss=11.033, ntokens=2054.4, nsentences=64, sample_size=2054.4, sample_size_v1=0, sample_size_v2=0, ppl=2095.52, wps=508.2, ups=0.25, wpb=2054.4, bsz=64, num_updates=20, lr=3.85109e-07, gnorm=36.713, clip=100, loss_scale=16, train_wall=40, gb_free=7.7, wall=109
2023-05-07 23:58:28 - progress_bar.py[line:272] - INFO: epoch 001:     33 / 866 loss=10.996, loss_v1=0, loss_v2=0, nll_loss=10.99, ntokens=2091.8, nsentences=64, sample_size=2091.8, sample_size_v1=0, sample_size_v2=0, ppl=2033.53, wps=515.9, ups=0.25, wpb=2091.8, bsz=64, num_updates=30, lr=5.77664e-07, gnorm=35.98, clip=100, loss_scale=16, train_wall=40, gb_free=6.4, wall=149
2023-05-07 23:58:53 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2023-05-07 23:59:13 - progress_bar.py[line:272] - INFO: epoch 001:     44 / 866 loss=10.92, loss_v1=0, loss_v2=0, nll_loss=10.905, ntokens=2055.3, nsentences=64, sample_size=2055.3, sample_size_v1=0, sample_size_v2=0, ppl=1917.65, wps=460.7, ups=0.22, wpb=2055.3, bsz=64, num_updates=40, lr=7.70218e-07, gnorm=35.421, clip=100, loss_scale=8, train_wall=45, gb_free=7.2, wall=194
2023-05-07 23:59:54 - progress_bar.py[line:272] - INFO: epoch 001:     54 / 866 loss=10.783, loss_v1=0, loss_v2=0, nll_loss=10.753, ntokens=2019.6, nsentences=64, sample_size=2019.6, sample_size_v1=0, sample_size_v2=0, ppl=1726, wps=495.4, ups=0.25, wpb=2019.6, bsz=64, num_updates=50, lr=9.62773e-07, gnorm=34.683, clip=100, loss_scale=8, train_wall=41, gb_free=7.5, wall=235
2023-05-08 00:00:35 - progress_bar.py[line:272] - INFO: epoch 001:     64 / 866 loss=10.481, loss_v1=0, loss_v2=0, nll_loss=10.417, ntokens=2283.9, nsentences=64, sample_size=2283.9, sample_size_v1=0, sample_size_v2=0, ppl=1367.59, wps=553.5, ups=0.24, wpb=2283.9, bsz=64, num_updates=60, lr=1.15533e-06, gnorm=38.437, clip=100, loss_scale=8, train_wall=41, gb_free=6.9, wall=276
2023-05-08 00:01:17 - progress_bar.py[line:272] - INFO: epoch 001:     74 / 866 loss=10.14, loss_v1=0, loss_v2=0, nll_loss=10.038, ntokens=2393.5, nsentences=64, sample_size=2393.5, sample_size_v1=0, sample_size_v2=0, ppl=1051.61, wps=570.1, ups=0.24, wpb=2393.5, bsz=64, num_updates=70, lr=1.34788e-06, gnorm=34.315, clip=100, loss_scale=8, train_wall=42, gb_free=6.4, wall=318
2023-05-08 00:01:58 - progress_bar.py[line:272] - INFO: epoch 001:     84 / 866 loss=9.701, loss_v1=0, loss_v2=0, nll_loss=9.551, ntokens=2213.9, nsentences=64, sample_size=2213.9, sample_size_v1=0, sample_size_v2=0, ppl=749.96, wps=537.7, ups=0.24, wpb=2213.9, bsz=64, num_updates=80, lr=1.54044e-06, gnorm=34.826, clip=100, loss_scale=8, train_wall=41, gb_free=6.7, wall=359
2023-05-08 00:02:39 - progress_bar.py[line:272] - INFO: epoch 001:     94 / 866 loss=9.116, loss_v1=0, loss_v2=0, nll_loss=8.9, ntokens=2148.5, nsentences=64, sample_size=2148.5, sample_size_v1=0, sample_size_v2=0, ppl=477.78, wps=530.3, ups=0.25, wpb=2148.5, bsz=64, num_updates=90, lr=1.73299e-06, gnorm=30.545, clip=100, loss_scale=8, train_wall=40, gb_free=8, wall=400
2023-05-08 00:03:19 - progress_bar.py[line:272] - INFO: epoch 001:    104 / 866 loss=8.544, loss_v1=0, loss_v2=0, nll_loss=8.263, ntokens=2017.3, nsentences=64, sample_size=2017.3, sample_size_v1=0, sample_size_v2=0, ppl=307.17, wps=501.3, ups=0.25, wpb=2017.3, bsz=64, num_updates=100, lr=1.92555e-06, gnorm=24.8, clip=100, loss_scale=8, train_wall=40, gb_free=7.9, wall=440
2023-05-08 00:04:00 - progress_bar.py[line:272] - INFO: epoch 001:    114 / 866 loss=7.996, loss_v1=0, loss_v2=0, nll_loss=7.648, ntokens=2055.6, nsentences=64, sample_size=2055.6, sample_size_v1=0, sample_size_v2=0, ppl=200.52, wps=504.8, ups=0.25, wpb=2055.6, bsz=64, num_updates=110, lr=2.1181e-06, gnorm=20.622, clip=100, loss_scale=8, train_wall=41, gb_free=7.6, wall=481
2023-05-08 00:04:41 - progress_bar.py[line:272] - INFO: epoch 001:    124 / 866 loss=7.513, loss_v1=0, loss_v2=0, nll_loss=7.103, ntokens=2215.8, nsentences=64, sample_size=2215.8, sample_size_v1=0, sample_size_v2=0, ppl=137.44, wps=539.6, ups=0.24, wpb=2215.8, bsz=64, num_updates=120, lr=2.31065e-06, gnorm=16.424, clip=100, loss_scale=8, train_wall=41, gb_free=7.1, wall=522
2023-05-08 00:05:22 - progress_bar.py[line:272] - INFO: epoch 001:    134 / 866 loss=7.18, loss_v1=0, loss_v2=0, nll_loss=6.726, ntokens=2192.9, nsentences=64, sample_size=2192.9, sample_size_v1=0, sample_size_v2=0, ppl=105.82, wps=535.8, ups=0.24, wpb=2192.9, bsz=64, num_updates=130, lr=2.50321e-06, gnorm=14.798, clip=100, loss_scale=8, train_wall=41, gb_free=7.8, wall=563
2023-05-08 00:06:03 - progress_bar.py[line:272] - INFO: epoch 001:    144 / 866 loss=6.921, loss_v1=0, loss_v2=0, nll_loss=6.434, ntokens=2257.1, nsentences=64, sample_size=2257.1, sample_size_v1=0, sample_size_v2=0, ppl=86.48, wps=547, ups=0.24, wpb=2257.1, bsz=64, num_updates=140, lr=2.69576e-06, gnorm=13.004, clip=100, loss_scale=8, train_wall=41, gb_free=6.7, wall=604
2023-05-08 00:06:44 - progress_bar.py[line:272] - INFO: epoch 001:    154 / 866 loss=6.747, loss_v1=0, loss_v2=0, nll_loss=6.239, ntokens=2212.4, nsentences=64, sample_size=2212.4, sample_size_v1=0, sample_size_v2=0, ppl=75.54, wps=535.9, ups=0.24, wpb=2212.4, bsz=64, num_updates=150, lr=2.88832e-06, gnorm=12.195, clip=100, loss_scale=8, train_wall=41, gb_free=6.7, wall=645
2023-05-08 00:07:25 - progress_bar.py[line:272] - INFO: epoch 001:    164 / 866 loss=6.592, loss_v1=0, loss_v2=0, nll_loss=6.063, ntokens=2162.6, nsentences=64, sample_size=2162.6, sample_size_v1=0, sample_size_v2=0, ppl=66.86, wps=531.4, ups=0.25, wpb=2162.6, bsz=64, num_updates=160, lr=3.08087e-06, gnorm=10.996, clip=100, loss_scale=8, train_wall=41, gb_free=6.4, wall=686
2023-05-08 00:08:05 - progress_bar.py[line:272] - INFO: epoch 001:    174 / 866 loss=6.412, loss_v1=0, loss_v2=0, nll_loss=5.864, ntokens=2000.4, nsentences=64, sample_size=2000.4, sample_size_v1=0, sample_size_v2=0, ppl=58.22, wps=497.1, ups=0.25, wpb=2000.4, bsz=64, num_updates=170, lr=3.27343e-06, gnorm=10.983, clip=100, loss_scale=8, train_wall=40, gb_free=7.6, wall=726
2023-05-08 00:08:46 - progress_bar.py[line:272] - INFO: epoch 001:    184 / 866 loss=6.216, loss_v1=0, loss_v2=0, nll_loss=5.644, ntokens=2214.2, nsentences=64, sample_size=2214.2, sample_size_v1=0, sample_size_v2=0, ppl=50.01, wps=537.9, ups=0.24, wpb=2214.2, bsz=64, num_updates=180, lr=3.46598e-06, gnorm=10.299, clip=100, loss_scale=8, train_wall=41, gb_free=7.4, wall=767
2023-05-08 00:09:27 - progress_bar.py[line:272] - INFO: epoch 001:    194 / 866 loss=6.141, loss_v1=0, loss_v2=0, nll_loss=5.558, ntokens=2214.5, nsentences=64, sample_size=2214.5, sample_size_v1=0, sample_size_v2=0, ppl=47.13, wps=536.7, ups=0.24, wpb=2214.5, bsz=64, num_updates=190, lr=3.65854e-06, gnorm=9.98, clip=100, loss_scale=8, train_wall=41, gb_free=6.6, wall=809
2023-05-08 00:10:08 - progress_bar.py[line:272] - INFO: epoch 001:    204 / 866 loss=6.002, loss_v1=0, loss_v2=0, nll_loss=5.401, ntokens=2031.5, nsentences=64, sample_size=2031.5, sample_size_v1=0, sample_size_v2=0, ppl=42.25, wps=503.2, ups=0.25, wpb=2031.5, bsz=64, num_updates=200, lr=3.85109e-06, gnorm=10.483, clip=100, loss_scale=8, train_wall=40, gb_free=7.3, wall=849
2023-05-08 00:10:48 - progress_bar.py[line:272] - INFO: epoch 001:    214 / 866 loss=5.847, loss_v1=0, loss_v2=0, nll_loss=5.223, ntokens=2119.7, nsentences=64, sample_size=2119.7, sample_size_v1=0, sample_size_v2=0, ppl=37.35, wps=525.4, ups=0.25, wpb=2119.7, bsz=64, num_updates=210, lr=4.04365e-06, gnorm=9.976, clip=100, loss_scale=8, train_wall=40, gb_free=7.6, wall=889
2023-05-08 00:11:28 - progress_bar.py[line:272] - INFO: epoch 001:    224 / 866 loss=5.678, loss_v1=0, loss_v2=0, nll_loss=5.028, ntokens=2165.1, nsentences=64, sample_size=2165.1, sample_size_v1=0, sample_size_v2=0, ppl=32.62, wps=539.1, ups=0.25, wpb=2165.1, bsz=64, num_updates=220, lr=4.2362e-06, gnorm=9.461, clip=100, loss_scale=8, train_wall=40, gb_free=7.6, wall=929
2023-05-08 00:12:08 - progress_bar.py[line:272] - INFO: epoch 001:    234 / 866 loss=5.465, loss_v1=0, loss_v2=0, nll_loss=4.782, ntokens=2130, nsentences=64, sample_size=2130, sample_size_v1=0, sample_size_v2=0, ppl=27.52, wps=532.6, ups=0.25, wpb=2130, bsz=64, num_updates=230, lr=4.42875e-06, gnorm=9.059, clip=100, loss_scale=8, train_wall=40, gb_free=7.6, wall=969
2023-05-08 00:12:49 - progress_bar.py[line:272] - INFO: epoch 001:    244 / 866 loss=5.237, loss_v1=0, loss_v2=0, nll_loss=4.517, ntokens=2215.8, nsentences=64, sample_size=2215.8, sample_size_v1=0, sample_size_v2=0, ppl=22.9, wps=546.5, ups=0.25, wpb=2215.8, bsz=64, num_updates=240, lr=4.62131e-06, gnorm=8.53, clip=100, loss_scale=8, train_wall=40, gb_free=6.9, wall=1010
2023-05-08 00:13:29 - progress_bar.py[line:272] - INFO: epoch 001:    254 / 866 loss=5.083, loss_v1=0, loss_v2=0, nll_loss=4.337, ntokens=2094.8, nsentences=64, sample_size=2094.8, sample_size_v1=0, sample_size_v2=0, ppl=20.2, wps=519.5, ups=0.25, wpb=2094.8, bsz=64, num_updates=250, lr=4.81386e-06, gnorm=8.751, clip=100, loss_scale=8, train_wall=40, gb_free=7.5, wall=1050
2023-05-08 00:14:09 - progress_bar.py[line:272] - INFO: epoch 001:    264 / 866 loss=4.979, loss_v1=0, loss_v2=0, nll_loss=4.215, ntokens=2161.1, nsentences=64, sample_size=2161.1, sample_size_v1=0, sample_size_v2=0, ppl=18.58, wps=538.7, ups=0.25, wpb=2161.1, bsz=64, num_updates=260, lr=5.00642e-06, gnorm=8.829, clip=100, loss_scale=8, train_wall=40, gb_free=7, wall=1090
2023-05-08 00:14:50 - progress_bar.py[line:272] - INFO: epoch 001:    274 / 866 loss=4.88, loss_v1=0, loss_v2=0, nll_loss=4.104, ntokens=2135.8, nsentences=64, sample_size=2135.8, sample_size_v1=0, sample_size_v2=0, ppl=17.2, wps=528.9, ups=0.25, wpb=2135.8, bsz=64, num_updates=270, lr=5.19897e-06, gnorm=7.832, clip=100, loss_scale=8, train_wall=40, gb_free=5.5, wall=1131
2023-05-08 00:15:30 - progress_bar.py[line:272] - INFO: epoch 001:    284 / 866 loss=4.754, loss_v1=0, loss_v2=0, nll_loss=3.959, ntokens=2152.8, nsentences=64, sample_size=2152.8, sample_size_v1=0, sample_size_v2=0, ppl=15.55, wps=534.3, ups=0.25, wpb=2152.8, bsz=64, num_updates=280, lr=5.39153e-06, gnorm=7.374, clip=100, loss_scale=8, train_wall=40, gb_free=7.5, wall=1171
2023-05-08 00:16:10 - progress_bar.py[line:272] - INFO: epoch 001:    294 / 866 loss=4.668, loss_v1=0, loss_v2=0, nll_loss=3.861, ntokens=2143.4, nsentences=64, sample_size=2143.4, sample_size_v1=0, sample_size_v2=0, ppl=14.53, wps=532.4, ups=0.25, wpb=2143.4, bsz=64, num_updates=290, lr=5.58408e-06, gnorm=7.171, clip=100, loss_scale=8, train_wall=40, gb_free=8, wall=1211
2023-05-08 00:16:50 - progress_bar.py[line:272] - INFO: epoch 001:    304 / 866 loss=4.577, loss_v1=0, loss_v2=0, nll_loss=3.755, ntokens=2147.4, nsentences=64, sample_size=2147.4, sample_size_v1=0, sample_size_v2=0, ppl=13.5, wps=535, ups=0.25, wpb=2147.4, bsz=64, num_updates=300, lr=5.77664e-06, gnorm=7.148, clip=100, loss_scale=8, train_wall=40, gb_free=7.7, wall=1252
2023-05-08 00:17:30 - progress_bar.py[line:272] - INFO: epoch 001:    314 / 866 loss=4.521, loss_v1=0, loss_v2=0, nll_loss=3.691, ntokens=2051.3, nsentences=64, sample_size=2051.3, sample_size_v1=0, sample_size_v2=0, ppl=12.91, wps=512.1, ups=0.25, wpb=2051.3, bsz=64, num_updates=310, lr=5.96919e-06, gnorm=6.932, clip=100, loss_scale=8, train_wall=40, gb_free=8.4, wall=1292
2023-05-08 00:18:11 - progress_bar.py[line:272] - INFO: epoch 001:    324 / 866 loss=4.453, loss_v1=0, loss_v2=0, nll_loss=3.611, ntokens=2017.8, nsentences=64, sample_size=2017.8, sample_size_v1=0, sample_size_v2=0, ppl=12.21, wps=502.9, ups=0.25, wpb=2017.8, bsz=64, num_updates=320, lr=6.16175e-06, gnorm=6.103, clip=100, loss_scale=8, train_wall=40, gb_free=7.6, wall=1332
2023-05-08 00:18:51 - progress_bar.py[line:272] - INFO: epoch 001:    334 / 866 loss=4.342, loss_v1=0, loss_v2=0, nll_loss=3.484, ntokens=2125.2, nsentences=64, sample_size=2125.2, sample_size_v1=0, sample_size_v2=0, ppl=11.19, wps=532.2, ups=0.25, wpb=2125.2, bsz=64, num_updates=330, lr=6.3543e-06, gnorm=6.172, clip=100, loss_scale=8, train_wall=40, gb_free=7.9, wall=1372
2023-05-08 00:19:31 - progress_bar.py[line:272] - INFO: epoch 001:    344 / 866 loss=4.283, loss_v1=0, loss_v2=0, nll_loss=3.416, ntokens=1996.4, nsentences=64, sample_size=1996.4, sample_size_v1=0, sample_size_v2=0, ppl=10.67, wps=493.5, ups=0.25, wpb=1996.4, bsz=64, num_updates=340, lr=6.54685e-06, gnorm=5.978, clip=100, loss_scale=8, train_wall=40, gb_free=7.9, wall=1412
2023-05-08 00:20:11 - progress_bar.py[line:272] - INFO: epoch 001:    354 / 866 loss=4.299, loss_v1=0, loss_v2=0, nll_loss=3.433, ntokens=1992.2, nsentences=64, sample_size=1992.2, sample_size_v1=0, sample_size_v2=0, ppl=10.8, wps=501.1, ups=0.25, wpb=1992.2, bsz=64, num_updates=350, lr=6.73941e-06, gnorm=5.715, clip=100, loss_scale=8, train_wall=40, gb_free=7.7, wall=1452
2023-05-08 00:20:51 - progress_bar.py[line:272] - INFO: epoch 001:    364 / 866 loss=4.194, loss_v1=0, loss_v2=0, nll_loss=3.312, ntokens=1966.7, nsentences=64, sample_size=1966.7, sample_size_v1=0, sample_size_v2=0, ppl=9.93, wps=494.5, ups=0.25, wpb=1966.7, bsz=64, num_updates=360, lr=6.93196e-06, gnorm=5.575, clip=100, loss_scale=8, train_wall=40, gb_free=8.1, wall=1492
2023-05-08 00:21:31 - progress_bar.py[line:272] - INFO: epoch 001:    374 / 866 loss=4.145, loss_v1=0, loss_v2=0, nll_loss=3.258, ntokens=2086.7, nsentences=64, sample_size=2086.7, sample_size_v1=0, sample_size_v2=0, ppl=9.56, wps=519.9, ups=0.25, wpb=2086.7, bsz=64, num_updates=370, lr=7.12452e-06, gnorm=5.638, clip=100, loss_scale=8, train_wall=40, gb_free=7.9, wall=1532
2023-05-08 00:22:11 - progress_bar.py[line:272] - INFO: epoch 001:    384 / 866 loss=4.084, loss_v1=0, loss_v2=0, nll_loss=3.185, ntokens=2129.5, nsentences=64, sample_size=2129.5, sample_size_v1=0, sample_size_v2=0, ppl=9.1, wps=532.4, ups=0.25, wpb=2129.5, bsz=64, num_updates=380, lr=7.31707e-06, gnorm=5.098, clip=100, loss_scale=8, train_wall=40, gb_free=7.2, wall=1572
2023-05-08 00:22:51 - progress_bar.py[line:272] - INFO: epoch 001:    394 / 866 loss=3.956, loss_v1=0, loss_v2=0, nll_loss=3.037, ntokens=1995.2, nsentences=64, sample_size=1995.2, sample_size_v1=0, sample_size_v2=0, ppl=8.21, wps=500.1, ups=0.25, wpb=1995.2, bsz=64, num_updates=390, lr=7.50963e-06, gnorm=5.101, clip=100, loss_scale=8, train_wall=40, gb_free=8.1, wall=1612
2023-05-08 00:23:31 - progress_bar.py[line:272] - INFO: epoch 001:    404 / 866 loss=3.931, loss_v1=0, loss_v2=0, nll_loss=3.011, ntokens=2131.8, nsentences=64, sample_size=2131.8, sample_size_v1=0, sample_size_v2=0, ppl=8.06, wps=531.7, ups=0.25, wpb=2131.8, bsz=64, num_updates=400, lr=7.70218e-06, gnorm=4.749, clip=100, loss_scale=8, train_wall=40, gb_free=7.3, wall=1652
2023-05-08 00:24:11 - progress_bar.py[line:272] - INFO: epoch 001:    414 / 866 loss=3.855, loss_v1=0, loss_v2=0, nll_loss=2.925, ntokens=2133.5, nsentences=64, sample_size=2133.5, sample_size_v1=0, sample_size_v2=0, ppl=7.6, wps=532.4, ups=0.25, wpb=2133.5, bsz=64, num_updates=410, lr=7.89474e-06, gnorm=4.716, clip=100, loss_scale=8, train_wall=40, gb_free=5.5, wall=1692
2023-05-08 00:24:51 - progress_bar.py[line:272] - INFO: epoch 001:    424 / 866 loss=3.842, loss_v1=0, loss_v2=0, nll_loss=2.906, ntokens=2063.4, nsentences=64, sample_size=2063.4, sample_size_v1=0, sample_size_v2=0, ppl=7.49, wps=514.7, ups=0.25, wpb=2063.4, bsz=64, num_updates=420, lr=8.08729e-06, gnorm=4.725, clip=100, loss_scale=8, train_wall=40, gb_free=7.7, wall=1732
2023-05-08 00:25:31 - progress_bar.py[line:272] - INFO: epoch 001:    434 / 866 loss=3.778, loss_v1=0, loss_v2=0, nll_loss=2.834, ntokens=2107.9, nsentences=64, sample_size=2107.9, sample_size_v1=0, sample_size_v2=0, ppl=7.13, wps=528.1, ups=0.25, wpb=2107.9, bsz=64, num_updates=430, lr=8.27985e-06, gnorm=4.335, clip=100, loss_scale=8, train_wall=40, gb_free=8.1, wall=1772
2023-05-08 00:26:11 - progress_bar.py[line:272] - INFO: epoch 001:    444 / 866 loss=3.741, loss_v1=0, loss_v2=0, nll_loss=2.79, ntokens=2030.8, nsentences=64, sample_size=2030.8, sample_size_v1=0, sample_size_v2=0, ppl=6.92, wps=504.9, ups=0.25, wpb=2030.8, bsz=64, num_updates=440, lr=8.4724e-06, gnorm=4.318, clip=100, loss_scale=8, train_wall=40, gb_free=8.2, wall=1812
2023-05-08 00:26:51 - progress_bar.py[line:272] - INFO: epoch 001:    454 / 866 loss=3.704, loss_v1=0, loss_v2=0, nll_loss=2.747, ntokens=2015.3, nsentences=64, sample_size=2015.3, sample_size_v1=0, sample_size_v2=0, ppl=6.71, wps=503.7, ups=0.25, wpb=2015.3, bsz=64, num_updates=450, lr=8.66496e-06, gnorm=4.541, clip=100, loss_scale=8, train_wall=40, gb_free=7.8, wall=1852
2023-05-08 00:27:32 - progress_bar.py[line:272] - INFO: epoch 001:    464 / 866 loss=3.604, loss_v1=0, loss_v2=0, nll_loss=2.631, ntokens=2171.2, nsentences=64, sample_size=2171.2, sample_size_v1=0, sample_size_v2=0, ppl=6.2, wps=536.4, ups=0.25, wpb=2171.2, bsz=64, num_updates=460, lr=8.85751e-06, gnorm=4.454, clip=100, loss_scale=8, train_wall=40, gb_free=8, wall=1893
2023-05-08 00:28:12 - progress_bar.py[line:272] - INFO: epoch 001:    474 / 866 loss=3.591, loss_v1=0, loss_v2=0, nll_loss=2.615, ntokens=2208.2, nsentences=64, sample_size=2208.2, sample_size_v1=0, sample_size_v2=0, ppl=6.13, wps=546.4, ups=0.25, wpb=2208.2, bsz=64, num_updates=470, lr=9.05006e-06, gnorm=4.438, clip=100, loss_scale=8, train_wall=40, gb_free=8.2, wall=1933
2023-05-08 00:28:52 - progress_bar.py[line:272] - INFO: epoch 001:    484 / 866 loss=3.54, loss_v1=0, loss_v2=0, nll_loss=2.556, ntokens=2144.3, nsentences=64, sample_size=2144.3, sample_size_v1=0, sample_size_v2=0, ppl=5.88, wps=529, ups=0.25, wpb=2144.3, bsz=64, num_updates=480, lr=9.24262e-06, gnorm=4.463, clip=100, loss_scale=8, train_wall=40, gb_free=7.8, wall=1974
2023-05-08 00:29:33 - progress_bar.py[line:272] - INFO: epoch 001:    494 / 866 loss=3.485, loss_v1=0, loss_v2=0, nll_loss=2.492, ntokens=2045, nsentences=64, sample_size=2045, sample_size_v1=0, sample_size_v2=0, ppl=5.63, wps=508.9, ups=0.25, wpb=2045, bsz=64, num_updates=490, lr=9.43517e-06, gnorm=4.475, clip=100, loss_scale=8, train_wall=40, gb_free=7.6, wall=2014
2023-05-08 00:30:13 - progress_bar.py[line:272] - INFO: epoch 001:    504 / 866 loss=3.46, loss_v1=0, loss_v2=0, nll_loss=2.462, ntokens=2073.9, nsentences=64, sample_size=2073.9, sample_size_v1=0, sample_size_v2=0, ppl=5.51, wps=518.5, ups=0.25, wpb=2073.9, bsz=64, num_updates=500, lr=9.62773e-06, gnorm=4.107, clip=100, loss_scale=8, train_wall=40, gb_free=7.8, wall=2054
2023-05-08 00:30:53 - progress_bar.py[line:272] - INFO: epoch 001:    514 / 866 loss=3.441, loss_v1=0, loss_v2=0, nll_loss=2.439, ntokens=2170.7, nsentences=64, sample_size=2170.7, sample_size_v1=0, sample_size_v2=0, ppl=5.42, wps=544.1, ups=0.25, wpb=2170.7, bsz=64, num_updates=510, lr=9.82028e-06, gnorm=4.353, clip=100, loss_scale=8, train_wall=40, gb_free=8.1, wall=2094
2023-05-08 00:31:32 - progress_bar.py[line:272] - INFO: epoch 001:    524 / 866 loss=3.395, loss_v1=0, loss_v2=0, nll_loss=2.386, ntokens=2105.4, nsentences=64, sample_size=2105.4, sample_size_v1=0, sample_size_v2=0, ppl=5.23, wps=528.2, ups=0.25, wpb=2105.4, bsz=64, num_updates=520, lr=1.00128e-05, gnorm=4.209, clip=100, loss_scale=8, train_wall=40, gb_free=8, wall=2134
2023-05-08 00:32:12 - progress_bar.py[line:272] - INFO: epoch 001:    534 / 866 loss=3.317, loss_v1=0, loss_v2=0, nll_loss=2.295, ntokens=2042.8, nsentences=64, sample_size=2042.8, sample_size_v1=0, sample_size_v2=0, ppl=4.91, wps=510.8, ups=0.25, wpb=2042.8, bsz=64, num_updates=530, lr=1.02054e-05, gnorm=4.335, clip=100, loss_scale=8, train_wall=40, gb_free=7.5, wall=2174
2023-05-08 00:32:53 - progress_bar.py[line:272] - INFO: epoch 001:    544 / 866 loss=3.315, loss_v1=0, loss_v2=0, nll_loss=2.293, ntokens=2184.6, nsentences=64, sample_size=2184.6, sample_size_v1=0, sample_size_v2=0, ppl=4.9, wps=545, ups=0.25, wpb=2184.6, bsz=64, num_updates=540, lr=1.03979e-05, gnorm=4.38, clip=100, loss_scale=8, train_wall=40, gb_free=7.8, wall=2214
2023-05-08 00:33:33 - progress_bar.py[line:272] - INFO: epoch 001:    554 / 866 loss=3.296, loss_v1=0, loss_v2=0, nll_loss=2.268, ntokens=2311.7, nsentences=64, sample_size=2311.7, sample_size_v1=0, sample_size_v2=0, ppl=4.82, wps=570, ups=0.25, wpb=2311.7, bsz=64, num_updates=550, lr=1.05905e-05, gnorm=4.073, clip=100, loss_scale=16, train_wall=41, gb_free=7.6, wall=2254
2023-05-08 00:34:13 - progress_bar.py[line:272] - INFO: epoch 001:    564 / 866 loss=3.257, loss_v1=0, loss_v2=0, nll_loss=2.222, ntokens=2250.1, nsentences=64, sample_size=2250.1, sample_size_v1=0, sample_size_v2=0, ppl=4.67, wps=558.3, ups=0.25, wpb=2250.1, bsz=64, num_updates=560, lr=1.07831e-05, gnorm=4.096, clip=100, loss_scale=16, train_wall=40, gb_free=7.3, wall=2294
2023-05-08 00:34:53 - progress_bar.py[line:272] - INFO: epoch 001:    574 / 866 loss=3.231, loss_v1=0, loss_v2=0, nll_loss=2.193, ntokens=2186.6, nsentences=64, sample_size=2186.6, sample_size_v1=0, sample_size_v2=0, ppl=4.57, wps=545.1, ups=0.25, wpb=2186.6, bsz=64, num_updates=570, lr=1.09756e-05, gnorm=3.818, clip=100, loss_scale=16, train_wall=40, gb_free=7.3, wall=2335
2023-05-08 00:35:34 - progress_bar.py[line:272] - INFO: epoch 001:    584 / 866 loss=3.196, loss_v1=0, loss_v2=0, nll_loss=2.15, ntokens=2097.5, nsentences=64, sample_size=2097.5, sample_size_v1=0, sample_size_v2=0, ppl=4.44, wps=523, ups=0.25, wpb=2097.5, bsz=64, num_updates=580, lr=1.11682e-05, gnorm=4.132, clip=100, loss_scale=16, train_wall=40, gb_free=7, wall=2375
2023-05-08 00:36:14 - progress_bar.py[line:272] - INFO: epoch 001:    594 / 866 loss=3.158, loss_v1=0, loss_v2=0, nll_loss=2.107, ntokens=2123.3, nsentences=64, sample_size=2123.3, sample_size_v1=0, sample_size_v2=0, ppl=4.31, wps=526.1, ups=0.25, wpb=2123.3, bsz=64, num_updates=590, lr=1.13607e-05, gnorm=3.972, clip=100, loss_scale=16, train_wall=40, gb_free=7.7, wall=2415
2023-05-08 00:36:54 - progress_bar.py[line:272] - INFO: epoch 001:    604 / 866 loss=3.12, loss_v1=0, loss_v2=0, nll_loss=2.062, ntokens=2066.5, nsentences=64, sample_size=2066.5, sample_size_v1=0, sample_size_v2=0, ppl=4.18, wps=514.7, ups=0.25, wpb=2066.5, bsz=64, num_updates=600, lr=1.15533e-05, gnorm=4.155, clip=100, loss_scale=16, train_wall=40, gb_free=7.6, wall=2455
2023-05-08 00:37:34 - progress_bar.py[line:272] - INFO: epoch 001:    614 / 866 loss=3.1, loss_v1=0, loss_v2=0, nll_loss=2.038, ntokens=1920.8, nsentences=64, sample_size=1920.8, sample_size_v1=0, sample_size_v2=0, ppl=4.11, wps=480.5, ups=0.25, wpb=1920.8, bsz=64, num_updates=610, lr=1.17458e-05, gnorm=4.204, clip=100, loss_scale=16, train_wall=40, gb_free=8, wall=2495
2023-05-08 00:38:14 - progress_bar.py[line:272] - INFO: epoch 001:    624 / 866 loss=3.094, loss_v1=0, loss_v2=0, nll_loss=2.028, ntokens=2039.6, nsentences=64, sample_size=2039.6, sample_size_v1=0, sample_size_v2=0, ppl=4.08, wps=507.2, ups=0.25, wpb=2039.6, bsz=64, num_updates=620, lr=1.19384e-05, gnorm=3.95, clip=100, loss_scale=16, train_wall=40, gb_free=8.1, wall=2535
2023-05-08 00:38:54 - progress_bar.py[line:272] - INFO: epoch 001:    634 / 866 loss=3.062, loss_v1=0, loss_v2=0, nll_loss=1.992, ntokens=2012.5, nsentences=64, sample_size=2012.5, sample_size_v1=0, sample_size_v2=0, ppl=3.98, wps=503.2, ups=0.25, wpb=2012.5, bsz=64, num_updates=630, lr=1.21309e-05, gnorm=4.091, clip=100, loss_scale=16, train_wall=40, gb_free=8.3, wall=2575
2023-05-08 00:39:34 - progress_bar.py[line:272] - INFO: epoch 001:    644 / 866 loss=3.034, loss_v1=0, loss_v2=0, nll_loss=1.96, ntokens=2085, nsentences=64, sample_size=2085, sample_size_v1=0, sample_size_v2=0, ppl=3.89, wps=522.3, ups=0.25, wpb=2085, bsz=64, num_updates=640, lr=1.23235e-05, gnorm=3.686, clip=100, loss_scale=16, train_wall=40, gb_free=7.8, wall=2615
2023-05-08 00:40:14 - progress_bar.py[line:272] - INFO: epoch 001:    654 / 866 loss=3.035, loss_v1=0, loss_v2=0, nll_loss=1.959, ntokens=1951, nsentences=64, sample_size=1951, sample_size_v1=0, sample_size_v2=0, ppl=3.89, wps=490.4, ups=0.25, wpb=1951, bsz=64, num_updates=650, lr=1.2516e-05, gnorm=3.804, clip=100, loss_scale=16, train_wall=40, gb_free=7.8, wall=2655
2023-05-08 00:40:54 - progress_bar.py[line:272] - INFO: epoch 001:    664 / 866 loss=3.021, loss_v1=0, loss_v2=0, nll_loss=1.942, ntokens=1940, nsentences=64, sample_size=1940, sample_size_v1=0, sample_size_v2=0, ppl=3.84, wps=488.2, ups=0.25, wpb=1940, bsz=64, num_updates=660, lr=1.27086e-05, gnorm=3.963, clip=100, loss_scale=16, train_wall=40, gb_free=8.2, wall=2695
2023-05-08 00:41:34 - progress_bar.py[line:272] - INFO: epoch 001:    674 / 866 loss=2.989, loss_v1=0, loss_v2=0, nll_loss=1.902, ntokens=2070.8, nsentences=64, sample_size=2070.8, sample_size_v1=0, sample_size_v2=0, ppl=3.74, wps=516.8, ups=0.25, wpb=2070.8, bsz=64, num_updates=670, lr=1.29012e-05, gnorm=3.622, clip=100, loss_scale=16, train_wall=40, gb_free=7.8, wall=2735
2023-05-08 00:42:14 - progress_bar.py[line:272] - INFO: epoch 001:    684 / 866 loss=2.941, loss_v1=0, loss_v2=0, nll_loss=1.85, ntokens=2040.2, nsentences=64, sample_size=2040.2, sample_size_v1=0, sample_size_v2=0, ppl=3.6, wps=511.6, ups=0.25, wpb=2040.2, bsz=64, num_updates=680, lr=1.30937e-05, gnorm=3.243, clip=100, loss_scale=16, train_wall=40, gb_free=8.2, wall=2775
2023-05-08 00:42:54 - progress_bar.py[line:272] - INFO: epoch 001:    694 / 866 loss=2.951, loss_v1=0, loss_v2=0, nll_loss=1.858, ntokens=2072.2, nsentences=64, sample_size=2072.2, sample_size_v1=0, sample_size_v2=0, ppl=3.63, wps=515.8, ups=0.25, wpb=2072.2, bsz=64, num_updates=690, lr=1.32863e-05, gnorm=3.471, clip=100, loss_scale=16, train_wall=40, gb_free=7.3, wall=2815
2023-05-08 00:43:34 - progress_bar.py[line:272] - INFO: epoch 001:    704 / 866 loss=2.909, loss_v1=0, loss_v2=0, nll_loss=1.811, ntokens=2017.9, nsentences=64, sample_size=2017.9, sample_size_v1=0, sample_size_v2=0, ppl=3.51, wps=503.8, ups=0.25, wpb=2017.9, bsz=64, num_updates=700, lr=1.34788e-05, gnorm=3.611, clip=100, loss_scale=16, train_wall=40, gb_free=8.2, wall=2855
2023-05-08 00:44:14 - progress_bar.py[line:272] - INFO: epoch 001:    714 / 866 loss=2.946, loss_v1=0, loss_v2=0, nll_loss=1.847, ntokens=1871.5, nsentences=64, sample_size=1871.5, sample_size_v1=0, sample_size_v2=0, ppl=3.6, wps=470.7, ups=0.25, wpb=1871.5, bsz=64, num_updates=710, lr=1.36714e-05, gnorm=3.353, clip=100, loss_scale=16, train_wall=40, gb_free=7.6, wall=2895
2023-05-08 00:44:54 - progress_bar.py[line:272] - INFO: epoch 001:    724 / 866 loss=2.892, loss_v1=0, loss_v2=0, nll_loss=1.789, ntokens=1998.5, nsentences=64, sample_size=1998.5, sample_size_v1=0, sample_size_v2=0, ppl=3.45, wps=501.3, ups=0.25, wpb=1998.5, bsz=64, num_updates=720, lr=1.38639e-05, gnorm=3.381, clip=100, loss_scale=16, train_wall=40, gb_free=8.1, wall=2935
2023-05-08 00:45:34 - progress_bar.py[line:272] - INFO: epoch 001:    734 / 866 loss=2.857, loss_v1=0, loss_v2=0, nll_loss=1.747, ntokens=2017.8, nsentences=64, sample_size=2017.8, sample_size_v1=0, sample_size_v2=0, ppl=3.36, wps=504.3, ups=0.25, wpb=2017.8, bsz=64, num_updates=730, lr=1.40565e-05, gnorm=3.382, clip=100, loss_scale=16, train_wall=40, gb_free=8, wall=2975
2023-05-08 00:46:14 - progress_bar.py[line:272] - INFO: epoch 001:    744 / 866 loss=2.836, loss_v1=0, loss_v2=0, nll_loss=1.721, ntokens=2152.2, nsentences=64, sample_size=2152.2, sample_size_v1=0, sample_size_v2=0, ppl=3.3, wps=536.3, ups=0.25, wpb=2152.2, bsz=64, num_updates=740, lr=1.4249e-05, gnorm=3.175, clip=100, loss_scale=16, train_wall=40, gb_free=7.2, wall=3015
2023-05-08 00:46:54 - progress_bar.py[line:272] - INFO: epoch 001:    754 / 866 loss=2.811, loss_v1=0, loss_v2=0, nll_loss=1.691, ntokens=2102.9, nsentences=64, sample_size=2102.9, sample_size_v1=0, sample_size_v2=0, ppl=3.23, wps=524.8, ups=0.25, wpb=2102.9, bsz=64, num_updates=750, lr=1.44416e-05, gnorm=3.17, clip=100, loss_scale=16, train_wall=40, gb_free=7.8, wall=3055
2023-05-08 00:47:34 - progress_bar.py[line:272] - INFO: epoch 001:    764 / 866 loss=2.815, loss_v1=0, loss_v2=0, nll_loss=1.694, ntokens=2112.8, nsentences=64, sample_size=2112.8, sample_size_v1=0, sample_size_v2=0, ppl=3.24, wps=525.2, ups=0.25, wpb=2112.8, bsz=64, num_updates=760, lr=1.46341e-05, gnorm=3.207, clip=100, loss_scale=16, train_wall=40, gb_free=8.2, wall=3095
2023-05-08 00:48:14 - progress_bar.py[line:272] - INFO: epoch 001:    774 / 866 loss=2.778, loss_v1=0, loss_v2=0, nll_loss=1.651, ntokens=2150, nsentences=64, sample_size=2150, sample_size_v1=0, sample_size_v2=0, ppl=3.14, wps=534, ups=0.25, wpb=2150, bsz=64, num_updates=770, lr=1.48267e-05, gnorm=3.068, clip=100, loss_scale=16, train_wall=40, gb_free=7.7, wall=3135
2023-05-08 00:48:55 - progress_bar.py[line:272] - INFO: epoch 001:    784 / 866 loss=2.789, loss_v1=0, loss_v2=0, nll_loss=1.662, ntokens=2176.4, nsentences=64, sample_size=2176.4, sample_size_v1=0, sample_size_v2=0, ppl=3.16, wps=540.7, ups=0.25, wpb=2176.4, bsz=64, num_updates=780, lr=1.50193e-05, gnorm=3.076, clip=100, loss_scale=16, train_wall=40, gb_free=7.9, wall=3176
2023-05-08 00:49:34 - progress_bar.py[line:272] - INFO: epoch 001:    794 / 866 loss=2.791, loss_v1=0, loss_v2=0, nll_loss=1.662, ntokens=2016.9, nsentences=64, sample_size=2016.9, sample_size_v1=0, sample_size_v2=0, ppl=3.16, wps=506.5, ups=0.25, wpb=2016.9, bsz=64, num_updates=790, lr=1.52118e-05, gnorm=2.942, clip=100, loss_scale=16, train_wall=40, gb_free=8, wall=3215
2023-05-08 00:50:14 - progress_bar.py[line:272] - INFO: epoch 001:    804 / 866 loss=2.781, loss_v1=0, loss_v2=0, nll_loss=1.653, ntokens=1963, nsentences=64, sample_size=1963, sample_size_v1=0, sample_size_v2=0, ppl=3.14, wps=492.8, ups=0.25, wpb=1963, bsz=64, num_updates=800, lr=1.54044e-05, gnorm=3.198, clip=100, loss_scale=16, train_wall=40, gb_free=8, wall=3255
2023-05-08 00:50:54 - progress_bar.py[line:272] - INFO: epoch 001:    814 / 866 loss=2.764, loss_v1=0, loss_v2=0, nll_loss=1.634, ntokens=2102.1, nsentences=64, sample_size=2102.1, sample_size_v1=0, sample_size_v2=0, ppl=3.1, wps=523.8, ups=0.25, wpb=2102.1, bsz=64, num_updates=810, lr=1.55969e-05, gnorm=2.936, clip=100, loss_scale=16, train_wall=40, gb_free=8.2, wall=3295
2023-05-08 00:51:35 - progress_bar.py[line:272] - INFO: epoch 001:    824 / 866 loss=2.765, loss_v1=0, loss_v2=0, nll_loss=1.632, ntokens=2124.1, nsentences=64, sample_size=2124.1, sample_size_v1=0, sample_size_v2=0, ppl=3.1, wps=527, ups=0.25, wpb=2124.1, bsz=64, num_updates=820, lr=1.57895e-05, gnorm=2.909, clip=100, loss_scale=16, train_wall=40, gb_free=7.4, wall=3336
2023-05-08 00:52:15 - progress_bar.py[line:272] - INFO: epoch 001:    834 / 866 loss=2.726, loss_v1=0, loss_v2=0, nll_loss=1.586, ntokens=2173.1, nsentences=64, sample_size=2173.1, sample_size_v1=0, sample_size_v2=0, ppl=3, wps=535.1, ups=0.25, wpb=2173.1, bsz=64, num_updates=830, lr=1.5982e-05, gnorm=2.9, clip=100, loss_scale=16, train_wall=41, gb_free=8.3, wall=3376
2023-05-08 00:52:55 - progress_bar.py[line:272] - INFO: epoch 001:    844 / 866 loss=2.726, loss_v1=0, loss_v2=0, nll_loss=1.583, ntokens=2148.3, nsentences=64, sample_size=2148.3, sample_size_v1=0, sample_size_v2=0, ppl=3, wps=535.3, ups=0.25, wpb=2148.3, bsz=64, num_updates=840, lr=1.61746e-05, gnorm=2.787, clip=100, loss_scale=16, train_wall=40, gb_free=8.1, wall=3417
2023-05-08 00:53:36 - progress_bar.py[line:272] - INFO: epoch 001:    854 / 866 loss=2.712, loss_v1=0, loss_v2=0, nll_loss=1.573, ntokens=2153.4, nsentences=64, sample_size=2153.4, sample_size_v1=0, sample_size_v2=0, ppl=2.97, wps=535.1, ups=0.25, wpb=2153.4, bsz=64, num_updates=850, lr=1.63671e-05, gnorm=2.804, clip=100, loss_scale=16, train_wall=40, gb_free=7.8, wall=3457
2023-05-08 00:54:16 - progress_bar.py[line:272] - INFO: epoch 001:    864 / 866 loss=2.746, loss_v1=0, loss_v2=0, nll_loss=1.607, ntokens=2070.8, nsentences=64, sample_size=2070.8, sample_size_v1=0, sample_size_v2=0, ppl=3.05, wps=517.5, ups=0.25, wpb=2070.8, bsz=64, num_updates=860, lr=1.65597e-05, gnorm=2.771, clip=100, loss_scale=16, train_wall=40, gb_free=7.8, wall=3497
2023-05-08 00:54:22 - train.py[line:332] - INFO: end of epoch 1 (average epoch stats below)
local datafile ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 1 begin to initialize row_count and line_idx-to-offset mapping
2023-05-08 00:54:22 - progress_bar.py[line:282] - INFO: epoch 001 | loss 4.765 | loss_v1 0 | loss_v2 0 | nll_loss 3.945 | ntokens 2102.05 | nsentences 63.972 | sample_size 2102.05 | sample_size_v1 0 | sample_size_v2 0 | ppl 15.4 | wps 521.3 | ups 0.25 | wpb 2102 | bsz 64 | num_updates 862 | lr 1.65982e-05 | gnorm 9.121 | clip 100 | loss_scale 16 | train_wall 3490 | gb_free 8.7 | wall 3503
2023-05-08 00:54:22 - trainer.py[line:639] - INFO: loading train data for epoch 2
local datafile ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 0 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 0 finished initializing row_count and line_idx-to-offset mapping
file ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 0 row count 27700 total row count 55400
/data/hulab/zcai75/anaconda3/envs/vilt/lib/python3.8/site-packages/torchvision/transforms/transforms.py:332: UserWarning: Argument 'interpolation' of type int is deprecated since 0.13 and will be removed in 0.15. Please use InterpolationMode enum.
  warnings.warn(
slice_id 0 seek offset 0
2023-05-08 00:54:24 - trainer.py[line:703] - INFO: begin training epoch 2
2023-05-08 00:54:24 - train.py[line:305] - INFO: Start iterating over samples
local datafile ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 1 finished initializing row_count and line_idx-to-offset mapping
file ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 1 row count 27700 total row count 55400
slice_id 1 seek offset 27700
2023-05-08 00:54:57 - progress_bar.py[line:272] - INFO: epoch 002:      8 / 866 loss=2.664, loss_v1=0, loss_v2=0, nll_loss=1.512, ntokens=2070.9, nsentences=61.6, sample_size=2070.9, sample_size_v1=0, sample_size_v2=0, ppl=2.85, wps=503.4, ups=0.24, wpb=2070.9, bsz=61.6, num_updates=870, lr=1.67522e-05, gnorm=2.704, clip=100, loss_scale=16, train_wall=39, gb_free=6.5, wall=3538
2023-05-08 00:55:37 - progress_bar.py[line:272] - INFO: epoch 002:     18 / 866 loss=2.626, loss_v1=0, loss_v2=0, nll_loss=1.471, ntokens=2050.4, nsentences=64, sample_size=2050.4, sample_size_v1=0, sample_size_v2=0, ppl=2.77, wps=507.1, ups=0.25, wpb=2050.4, bsz=64, num_updates=880, lr=1.69448e-05, gnorm=3.062, clip=100, loss_scale=16, train_wall=40, gb_free=7.4, wall=3578
2023-05-08 00:56:17 - progress_bar.py[line:272] - INFO: epoch 002:     28 / 866 loss=2.667, loss_v1=0, loss_v2=0, nll_loss=1.513, ntokens=1965.3, nsentences=64, sample_size=1965.3, sample_size_v1=0, sample_size_v2=0, ppl=2.85, wps=488.7, ups=0.25, wpb=1965.3, bsz=64, num_updates=890, lr=1.71374e-05, gnorm=2.963, clip=100, loss_scale=16, train_wall=40, gb_free=7.7, wall=3619
2023-05-08 00:56:58 - progress_bar.py[line:272] - INFO: epoch 002:     38 / 866 loss=2.544, loss_v1=0, loss_v2=0, nll_loss=1.374, ntokens=2219.2, nsentences=64, sample_size=2219.2, sample_size_v1=0, sample_size_v2=0, ppl=2.59, wps=543.5, ups=0.24, wpb=2219.2, bsz=64, num_updates=900, lr=1.73299e-05, gnorm=2.496, clip=100, loss_scale=16, train_wall=41, gb_free=7.7, wall=3659
2023-05-08 00:57:39 - progress_bar.py[line:272] - INFO: epoch 002:     48 / 866 loss=2.633, loss_v1=0, loss_v2=0, nll_loss=1.476, ntokens=2006.4, nsentences=64, sample_size=2006.4, sample_size_v1=0, sample_size_v2=0, ppl=2.78, wps=491.9, ups=0.25, wpb=2006.4, bsz=64, num_updates=910, lr=1.75225e-05, gnorm=2.837, clip=100, loss_scale=16, train_wall=41, gb_free=7, wall=3700
2023-05-08 00:58:19 - progress_bar.py[line:272] - INFO: epoch 002:     58 / 866 loss=2.511, loss_v1=0, loss_v2=0, nll_loss=1.34, ntokens=2051.7, nsentences=64, sample_size=2051.7, sample_size_v1=0, sample_size_v2=0, ppl=2.53, wps=511.3, ups=0.25, wpb=2051.7, bsz=64, num_updates=920, lr=1.7715e-05, gnorm=2.754, clip=100, loss_scale=16, train_wall=40, gb_free=7.9, wall=3740
2023-05-08 00:59:01 - progress_bar.py[line:272] - INFO: epoch 002:     68 / 866 loss=2.456, loss_v1=0, loss_v2=0, nll_loss=1.269, ntokens=2441.3, nsentences=64, sample_size=2441.3, sample_size_v1=0, sample_size_v2=0, ppl=2.41, wps=582.3, ups=0.24, wpb=2441.3, bsz=64, num_updates=930, lr=1.79076e-05, gnorm=2.482, clip=100, loss_scale=16, train_wall=42, gb_free=6.3, wall=3782
2023-05-08 00:59:42 - progress_bar.py[line:272] - INFO: epoch 002:     78 / 866 loss=2.564, loss_v1=0, loss_v2=0, nll_loss=1.396, ntokens=2331.2, nsentences=64, sample_size=2331.2, sample_size_v1=0, sample_size_v2=0, ppl=2.63, wps=564.1, ups=0.24, wpb=2331.2, bsz=64, num_updates=940, lr=1.81001e-05, gnorm=2.562, clip=100, loss_scale=16, train_wall=41, gb_free=5.9, wall=3824
2023-05-08 01:00:23 - progress_bar.py[line:272] - INFO: epoch 002:     88 / 866 loss=2.593, loss_v1=0, loss_v2=0, nll_loss=1.43, ntokens=2130.8, nsentences=64, sample_size=2130.8, sample_size_v1=0, sample_size_v2=0, ppl=2.69, wps=520.1, ups=0.24, wpb=2130.8, bsz=64, num_updates=950, lr=1.82927e-05, gnorm=2.519, clip=100, loss_scale=16, train_wall=41, gb_free=7.3, wall=3865
2023-05-08 01:01:04 - progress_bar.py[line:272] - INFO: epoch 002:     98 / 866 loss=2.569, loss_v1=0, loss_v2=0, nll_loss=1.406, ntokens=2150, nsentences=64, sample_size=2150, sample_size_v1=0, sample_size_v2=0, ppl=2.65, wps=529.1, ups=0.25, wpb=2150, bsz=64, num_updates=960, lr=1.84852e-05, gnorm=2.397, clip=100, loss_scale=16, train_wall=41, gb_free=7.6, wall=3905
2023-05-08 01:01:44 - progress_bar.py[line:272] - INFO: epoch 002:    108 / 866 loss=2.679, loss_v1=0, loss_v2=0, nll_loss=1.523, ntokens=2012.3, nsentences=64, sample_size=2012.3, sample_size_v1=0, sample_size_v2=0, ppl=2.87, wps=501.8, ups=0.25, wpb=2012.3, bsz=64, num_updates=970, lr=1.86778e-05, gnorm=2.35, clip=100, loss_scale=16, train_wall=40, gb_free=8.1, wall=3945
2023-05-08 01:02:25 - progress_bar.py[line:272] - INFO: epoch 002:    118 / 866 loss=2.643, loss_v1=0, loss_v2=0, nll_loss=1.484, ntokens=2123.2, nsentences=64, sample_size=2123.2, sample_size_v1=0, sample_size_v2=0, ppl=2.8, wps=521.5, ups=0.25, wpb=2123.2, bsz=64, num_updates=980, lr=1.88703e-05, gnorm=2.173, clip=100, loss_scale=16, train_wall=41, gb_free=7.2, wall=3986
2023-05-08 01:03:06 - progress_bar.py[line:272] - INFO: epoch 002:    128 / 866 loss=2.612, loss_v1=0, loss_v2=0, nll_loss=1.446, ntokens=2216.2, nsentences=64, sample_size=2216.2, sample_size_v1=0, sample_size_v2=0, ppl=2.72, wps=538.7, ups=0.24, wpb=2216.2, bsz=64, num_updates=990, lr=1.90629e-05, gnorm=2.173, clip=100, loss_scale=16, train_wall=41, gb_free=7.7, wall=4027
2023-05-08 01:03:47 - progress_bar.py[line:272] - INFO: epoch 002:    138 / 866 loss=2.581, loss_v1=0, loss_v2=0, nll_loss=1.412, ntokens=2223.9, nsentences=64, sample_size=2223.9, sample_size_v1=0, sample_size_v2=0, ppl=2.66, wps=542.2, ups=0.24, wpb=2223.9, bsz=64, num_updates=1000, lr=1.92555e-05, gnorm=2.154, clip=100, loss_scale=16, train_wall=41, gb_free=7.3, wall=4068
2023-05-08 01:04:28 - progress_bar.py[line:272] - INFO: epoch 002:    148 / 866 loss=2.566, loss_v1=0, loss_v2=0, nll_loss=1.397, ntokens=2202.7, nsentences=64, sample_size=2202.7, sample_size_v1=0, sample_size_v2=0, ppl=2.63, wps=533.6, ups=0.24, wpb=2202.7, bsz=64, num_updates=1010, lr=1.9448e-05, gnorm=2.256, clip=100, loss_scale=16, train_wall=41, gb_free=6.8, wall=4109
2023-05-08 01:05:10 - progress_bar.py[line:272] - INFO: epoch 002:    158 / 866 loss=2.579, loss_v1=0, loss_v2=0, nll_loss=1.409, ntokens=2218.6, nsentences=64, sample_size=2218.6, sample_size_v1=0, sample_size_v2=0, ppl=2.66, wps=537.1, ups=0.24, wpb=2218.6, bsz=64, num_updates=1020, lr=1.96406e-05, gnorm=2.235, clip=100, loss_scale=16, train_wall=41, gb_free=7.5, wall=4151
2023-05-08 01:05:50 - progress_bar.py[line:272] - INFO: epoch 002:    168 / 866 loss=2.564, loss_v1=0, loss_v2=0, nll_loss=1.39, ntokens=2127.3, nsentences=64, sample_size=2127.3, sample_size_v1=0, sample_size_v2=0, ppl=2.62, wps=524.2, ups=0.25, wpb=2127.3, bsz=64, num_updates=1030, lr=1.98331e-05, gnorm=2.113, clip=100, loss_scale=16, train_wall=41, gb_free=7.8, wall=4191
2023-05-08 01:06:31 - progress_bar.py[line:272] - INFO: epoch 002:    178 / 866 loss=2.552, loss_v1=0, loss_v2=0, nll_loss=1.377, ntokens=2069.7, nsentences=64, sample_size=2069.7, sample_size_v1=0, sample_size_v2=0, ppl=2.6, wps=509.2, ups=0.25, wpb=2069.7, bsz=64, num_updates=1040, lr=2.00257e-05, gnorm=2.183, clip=100, loss_scale=16, train_wall=41, gb_free=7.4, wall=4232
2023-05-08 01:07:12 - progress_bar.py[line:272] - INFO: epoch 002:    188 / 866 loss=2.546, loss_v1=0, loss_v2=0, nll_loss=1.372, ntokens=2227.8, nsentences=64, sample_size=2227.8, sample_size_v1=0, sample_size_v2=0, ppl=2.59, wps=541.6, ups=0.24, wpb=2227.8, bsz=64, num_updates=1050, lr=2.02182e-05, gnorm=2.308, clip=100, loss_scale=16, train_wall=41, gb_free=7.4, wall=4273
2023-05-08 01:07:53 - progress_bar.py[line:272] - INFO: epoch 002:    198 / 866 loss=2.564, loss_v1=0, loss_v2=0, nll_loss=1.393, ntokens=2162.5, nsentences=64, sample_size=2162.5, sample_size_v1=0, sample_size_v2=0, ppl=2.63, wps=528.9, ups=0.24, wpb=2162.5, bsz=64, num_updates=1060, lr=2.04108e-05, gnorm=2.356, clip=100, loss_scale=32, train_wall=41, gb_free=7.2, wall=4314
2023-05-08 01:08:33 - progress_bar.py[line:272] - INFO: epoch 002:    208 / 866 loss=2.617, loss_v1=0, loss_v2=0, nll_loss=1.451, ntokens=1967.7, nsentences=64, sample_size=1967.7, sample_size_v1=0, sample_size_v2=0, ppl=2.73, wps=490.2, ups=0.25, wpb=1967.7, bsz=64, num_updates=1070, lr=2.06033e-05, gnorm=2.275, clip=100, loss_scale=32, train_wall=40, gb_free=7.4, wall=4354
2023-05-08 01:09:13 - progress_bar.py[line:272] - INFO: epoch 002:    218 / 866 loss=2.638, loss_v1=0, loss_v2=0, nll_loss=1.474, ntokens=2200.8, nsentences=64, sample_size=2200.8, sample_size_v1=0, sample_size_v2=0, ppl=2.78, wps=546.7, ups=0.25, wpb=2200.8, bsz=64, num_updates=1080, lr=2.07959e-05, gnorm=2.178, clip=100, loss_scale=32, train_wall=40, gb_free=7.9, wall=4394
2023-05-08 01:09:53 - progress_bar.py[line:272] - INFO: epoch 002:    228 / 866 loss=2.615, loss_v1=0, loss_v2=0, nll_loss=1.45, ntokens=2165.7, nsentences=64, sample_size=2165.7, sample_size_v1=0, sample_size_v2=0, ppl=2.73, wps=539.8, ups=0.25, wpb=2165.7, bsz=64, num_updates=1090, lr=2.09884e-05, gnorm=2.014, clip=100, loss_scale=32, train_wall=40, gb_free=8, wall=4435
2023-05-08 01:10:34 - progress_bar.py[line:272] - INFO: epoch 002:    238 / 866 loss=2.642, loss_v1=0, loss_v2=0, nll_loss=1.479, ntokens=2129.1, nsentences=64, sample_size=2129.1, sample_size_v1=0, sample_size_v2=0, ppl=2.79, wps=531, ups=0.25, wpb=2129.1, bsz=64, num_updates=1100, lr=2.1181e-05, gnorm=2.052, clip=100, loss_scale=32, train_wall=40, gb_free=7.8, wall=4475
2023-05-08 01:11:14 - progress_bar.py[line:272] - INFO: epoch 002:    248 / 866 loss=2.612, loss_v1=0, loss_v2=0, nll_loss=1.446, ntokens=2173.3, nsentences=64, sample_size=2173.3, sample_size_v1=0, sample_size_v2=0, ppl=2.73, wps=538.5, ups=0.25, wpb=2173.3, bsz=64, num_updates=1110, lr=2.13736e-05, gnorm=2.043, clip=100, loss_scale=32, train_wall=40, gb_free=7.7, wall=4515
2023-05-08 01:11:54 - progress_bar.py[line:272] - INFO: epoch 002:    258 / 866 loss=2.624, loss_v1=0, loss_v2=0, nll_loss=1.455, ntokens=2109.7, nsentences=64, sample_size=2109.7, sample_size_v1=0, sample_size_v2=0, ppl=2.74, wps=526.5, ups=0.25, wpb=2109.7, bsz=64, num_updates=1120, lr=2.15661e-05, gnorm=2.131, clip=100, loss_scale=32, train_wall=40, gb_free=7.8, wall=4555
2023-05-08 01:12:34 - progress_bar.py[line:272] - INFO: epoch 002:    268 / 866 loss=2.615, loss_v1=0, loss_v2=0, nll_loss=1.448, ntokens=2130.6, nsentences=64, sample_size=2130.6, sample_size_v1=0, sample_size_v2=0, ppl=2.73, wps=530.4, ups=0.25, wpb=2130.6, bsz=64, num_updates=1130, lr=2.17587e-05, gnorm=2.004, clip=100, loss_scale=32, train_wall=40, gb_free=8, wall=4595
2023-05-08 01:13:14 - progress_bar.py[line:272] - INFO: epoch 002:    278 / 866 loss=2.609, loss_v1=0, loss_v2=0, nll_loss=1.44, ntokens=2172.4, nsentences=64, sample_size=2172.4, sample_size_v1=0, sample_size_v2=0, ppl=2.71, wps=539.6, ups=0.25, wpb=2172.4, bsz=64, num_updates=1140, lr=2.19512e-05, gnorm=2.101, clip=100, loss_scale=32, train_wall=40, gb_free=7.7, wall=4636
2023-05-08 01:13:55 - progress_bar.py[line:272] - INFO: epoch 002:    288 / 866 loss=2.592, loss_v1=0, loss_v2=0, nll_loss=1.421, ntokens=2196.8, nsentences=64, sample_size=2196.8, sample_size_v1=0, sample_size_v2=0, ppl=2.68, wps=545.3, ups=0.25, wpb=2196.8, bsz=64, num_updates=1150, lr=2.21438e-05, gnorm=1.88, clip=100, loss_scale=32, train_wall=40, gb_free=7.8, wall=4676
2023-05-08 01:14:35 - progress_bar.py[line:272] - INFO: epoch 002:    298 / 866 loss=2.596, loss_v1=0, loss_v2=0, nll_loss=1.424, ntokens=2080.1, nsentences=64, sample_size=2080.1, sample_size_v1=0, sample_size_v2=0, ppl=2.68, wps=520.6, ups=0.25, wpb=2080.1, bsz=64, num_updates=1160, lr=2.23363e-05, gnorm=2.226, clip=100, loss_scale=32, train_wall=40, gb_free=8.2, wall=4716
2023-05-08 01:15:15 - progress_bar.py[line:272] - INFO: epoch 002:    308 / 866 loss=2.59, loss_v1=0, loss_v2=0, nll_loss=1.42, ntokens=2155.7, nsentences=64, sample_size=2155.7, sample_size_v1=0, sample_size_v2=0, ppl=2.68, wps=537.8, ups=0.25, wpb=2155.7, bsz=64, num_updates=1170, lr=2.25289e-05, gnorm=2.075, clip=100, loss_scale=32, train_wall=40, gb_free=8.1, wall=4756
2023-05-08 01:15:55 - progress_bar.py[line:272] - INFO: epoch 002:    318 / 866 loss=2.603, loss_v1=0, loss_v2=0, nll_loss=1.433, ntokens=2007.1, nsentences=64, sample_size=2007.1, sample_size_v1=0, sample_size_v2=0, ppl=2.7, wps=502.2, ups=0.25, wpb=2007.1, bsz=64, num_updates=1180, lr=2.27214e-05, gnorm=2.267, clip=100, loss_scale=32, train_wall=40, gb_free=8.1, wall=4796
2023-05-08 01:16:35 - progress_bar.py[line:272] - INFO: epoch 002:    328 / 866 loss=2.61, loss_v1=0, loss_v2=0, nll_loss=1.439, ntokens=2043.2, nsentences=64, sample_size=2043.2, sample_size_v1=0, sample_size_v2=0, ppl=2.71, wps=507.5, ups=0.25, wpb=2043.2, bsz=64, num_updates=1190, lr=2.2914e-05, gnorm=1.944, clip=100, loss_scale=32, train_wall=40, gb_free=8, wall=4836
2023-05-08 01:17:15 - progress_bar.py[line:272] - INFO: epoch 002:    338 / 866 loss=2.551, loss_v1=0, loss_v2=0, nll_loss=1.372, ntokens=2147.1, nsentences=64, sample_size=2147.1, sample_size_v1=0, sample_size_v2=0, ppl=2.59, wps=533.2, ups=0.25, wpb=2147.1, bsz=64, num_updates=1200, lr=2.31065e-05, gnorm=1.873, clip=100, loss_scale=32, train_wall=40, gb_free=8, wall=4876
2023-05-08 01:17:55 - progress_bar.py[line:272] - INFO: epoch 002:    348 / 866 loss=2.578, loss_v1=0, loss_v2=0, nll_loss=1.403, ntokens=1910.8, nsentences=64, sample_size=1910.8, sample_size_v1=0, sample_size_v2=0, ppl=2.65, wps=480.5, ups=0.25, wpb=1910.8, bsz=64, num_updates=1210, lr=2.32991e-05, gnorm=2.091, clip=100, loss_scale=32, train_wall=40, gb_free=7.9, wall=4916
2023-05-08 01:18:35 - progress_bar.py[line:272] - INFO: epoch 002:    358 / 866 loss=2.601, loss_v1=0, loss_v2=0, nll_loss=1.431, ntokens=1995.2, nsentences=64, sample_size=1995.2, sample_size_v1=0, sample_size_v2=0, ppl=2.7, wps=501.1, ups=0.25, wpb=1995.2, bsz=64, num_updates=1220, lr=2.34917e-05, gnorm=2.069, clip=100, loss_scale=32, train_wall=40, gb_free=8.2, wall=4956
2023-05-08 01:19:15 - progress_bar.py[line:272] - INFO: epoch 002:    368 / 866 loss=2.583, loss_v1=0, loss_v2=0, nll_loss=1.407, ntokens=1984.4, nsentences=64, sample_size=1984.4, sample_size_v1=0, sample_size_v2=0, ppl=2.65, wps=498.2, ups=0.25, wpb=1984.4, bsz=64, num_updates=1230, lr=2.36842e-05, gnorm=2.146, clip=100, loss_scale=32, train_wall=40, gb_free=7.8, wall=4996
2023-05-08 01:19:55 - progress_bar.py[line:272] - INFO: epoch 002:    378 / 866 loss=2.566, loss_v1=0, loss_v2=0, nll_loss=1.39, ntokens=2113.8, nsentences=64, sample_size=2113.8, sample_size_v1=0, sample_size_v2=0, ppl=2.62, wps=527.8, ups=0.25, wpb=2113.8, bsz=64, num_updates=1240, lr=2.38768e-05, gnorm=2.03, clip=100, loss_scale=32, train_wall=40, gb_free=8.2, wall=5036
2023-05-08 01:20:35 - progress_bar.py[line:272] - INFO: epoch 002:    388 / 866 loss=2.554, loss_v1=0, loss_v2=0, nll_loss=1.377, ntokens=2138.6, nsentences=64, sample_size=2138.6, sample_size_v1=0, sample_size_v2=0, ppl=2.6, wps=535, ups=0.25, wpb=2138.6, bsz=64, num_updates=1250, lr=2.40693e-05, gnorm=1.832, clip=100, loss_scale=32, train_wall=40, gb_free=7.5, wall=5076
2023-05-08 01:21:15 - progress_bar.py[line:272] - INFO: epoch 002:    398 / 866 loss=2.574, loss_v1=0, loss_v2=0, nll_loss=1.399, ntokens=2064.6, nsentences=64, sample_size=2064.6, sample_size_v1=0, sample_size_v2=0, ppl=2.64, wps=516.6, ups=0.25, wpb=2064.6, bsz=64, num_updates=1260, lr=2.42619e-05, gnorm=2.089, clip=100, loss_scale=32, train_wall=40, gb_free=7.2, wall=5116
2023-05-08 01:21:55 - progress_bar.py[line:272] - INFO: epoch 002:    408 / 866 loss=2.564, loss_v1=0, loss_v2=0, nll_loss=1.386, ntokens=2069, nsentences=64, sample_size=2069, sample_size_v1=0, sample_size_v2=0, ppl=2.61, wps=518, ups=0.25, wpb=2069, bsz=64, num_updates=1270, lr=2.44544e-05, gnorm=2.002, clip=100, loss_scale=32, train_wall=40, gb_free=7.7, wall=5156
2023-05-08 01:22:35 - progress_bar.py[line:272] - INFO: epoch 002:    418 / 866 loss=2.549, loss_v1=0, loss_v2=0, nll_loss=1.371, ntokens=2098.3, nsentences=64, sample_size=2098.3, sample_size_v1=0, sample_size_v2=0, ppl=2.59, wps=522.9, ups=0.25, wpb=2098.3, bsz=64, num_updates=1280, lr=2.4647e-05, gnorm=2.021, clip=100, loss_scale=32, train_wall=40, gb_free=7.2, wall=5196
2023-05-08 01:23:15 - progress_bar.py[line:272] - INFO: epoch 002:    428 / 866 loss=2.544, loss_v1=0, loss_v2=0, nll_loss=1.366, ntokens=2110.8, nsentences=64, sample_size=2110.8, sample_size_v1=0, sample_size_v2=0, ppl=2.58, wps=526, ups=0.25, wpb=2110.8, bsz=64, num_updates=1290, lr=2.48395e-05, gnorm=1.948, clip=100, loss_scale=32, train_wall=40, gb_free=7.7, wall=5236
2023-05-08 01:23:55 - progress_bar.py[line:272] - INFO: epoch 002:    438 / 866 loss=2.567, loss_v1=0, loss_v2=0, nll_loss=1.391, ntokens=2124.1, nsentences=64, sample_size=2124.1, sample_size_v1=0, sample_size_v2=0, ppl=2.62, wps=531.1, ups=0.25, wpb=2124.1, bsz=64, num_updates=1300, lr=2.50321e-05, gnorm=1.821, clip=100, loss_scale=32, train_wall=40, gb_free=8, wall=5276
2023-05-08 01:24:35 - progress_bar.py[line:272] - INFO: epoch 002:    448 / 866 loss=2.581, loss_v1=0, loss_v2=0, nll_loss=1.403, ntokens=1996.8, nsentences=64, sample_size=1996.8, sample_size_v1=0, sample_size_v2=0, ppl=2.64, wps=498, ups=0.25, wpb=1996.8, bsz=64, num_updates=1310, lr=2.52246e-05, gnorm=2.136, clip=100, loss_scale=32, train_wall=40, gb_free=7.7, wall=5316
2023-05-08 01:25:15 - progress_bar.py[line:272] - INFO: epoch 002:    458 / 866 loss=2.546, loss_v1=0, loss_v2=0, nll_loss=1.37, ntokens=2079.8, nsentences=64, sample_size=2079.8, sample_size_v1=0, sample_size_v2=0, ppl=2.58, wps=517.4, ups=0.25, wpb=2079.8, bsz=64, num_updates=1320, lr=2.54172e-05, gnorm=2.007, clip=100, loss_scale=32, train_wall=40, gb_free=8, wall=5356
2023-05-08 01:25:56 - progress_bar.py[line:272] - INFO: epoch 002:    468 / 866 loss=2.545, loss_v1=0, loss_v2=0, nll_loss=1.363, ntokens=2164.7, nsentences=64, sample_size=2164.7, sample_size_v1=0, sample_size_v2=0, ppl=2.57, wps=534.3, ups=0.25, wpb=2164.7, bsz=64, num_updates=1330, lr=2.56098e-05, gnorm=1.845, clip=100, loss_scale=32, train_wall=40, gb_free=7.4, wall=5397
2023-05-08 01:26:36 - progress_bar.py[line:272] - INFO: epoch 002:    478 / 866 loss=2.569, loss_v1=0, loss_v2=0, nll_loss=1.392, ntokens=2220, nsentences=64, sample_size=2220, sample_size_v1=0, sample_size_v2=0, ppl=2.63, wps=549.2, ups=0.25, wpb=2220, bsz=64, num_updates=1340, lr=2.58023e-05, gnorm=1.974, clip=100, loss_scale=32, train_wall=40, gb_free=8, wall=5437
2023-05-08 01:27:16 - progress_bar.py[line:272] - INFO: epoch 002:    488 / 866 loss=2.531, loss_v1=0, loss_v2=0, nll_loss=1.348, ntokens=2033.8, nsentences=64, sample_size=2033.8, sample_size_v1=0, sample_size_v2=0, ppl=2.55, wps=508.5, ups=0.25, wpb=2033.8, bsz=64, num_updates=1350, lr=2.59949e-05, gnorm=1.953, clip=100, loss_scale=32, train_wall=40, gb_free=8.3, wall=5477
2023-05-08 01:27:56 - progress_bar.py[line:272] - INFO: epoch 002:    498 / 866 loss=2.535, loss_v1=0, loss_v2=0, nll_loss=1.354, ntokens=2069, nsentences=64, sample_size=2069, sample_size_v1=0, sample_size_v2=0, ppl=2.56, wps=516.3, ups=0.25, wpb=2069, bsz=64, num_updates=1360, lr=2.61874e-05, gnorm=1.956, clip=100, loss_scale=32, train_wall=40, gb_free=8.5, wall=5517
2023-05-08 01:28:36 - progress_bar.py[line:272] - INFO: epoch 002:    508 / 866 loss=2.56, loss_v1=0, loss_v2=0, nll_loss=1.382, ntokens=2115.2, nsentences=64, sample_size=2115.2, sample_size_v1=0, sample_size_v2=0, ppl=2.61, wps=529.1, ups=0.25, wpb=2115.2, bsz=64, num_updates=1370, lr=2.638e-05, gnorm=1.938, clip=100, loss_scale=32, train_wall=40, gb_free=7.9, wall=5557
2023-05-08 01:29:16 - progress_bar.py[line:272] - INFO: epoch 002:    518 / 866 loss=2.551, loss_v1=0, loss_v2=0, nll_loss=1.372, ntokens=2197.1, nsentences=64, sample_size=2197.1, sample_size_v1=0, sample_size_v2=0, ppl=2.59, wps=550.4, ups=0.25, wpb=2197.1, bsz=64, num_updates=1380, lr=2.65725e-05, gnorm=1.745, clip=100, loss_scale=32, train_wall=40, gb_free=8.1, wall=5597
2023-05-08 01:29:56 - progress_bar.py[line:272] - INFO: epoch 002:    528 / 866 loss=2.543, loss_v1=0, loss_v2=0, nll_loss=1.364, ntokens=1974.3, nsentences=64, sample_size=1974.3, sample_size_v1=0, sample_size_v2=0, ppl=2.57, wps=498, ups=0.25, wpb=1974.3, bsz=64, num_updates=1390, lr=2.67651e-05, gnorm=2.036, clip=100, loss_scale=32, train_wall=40, gb_free=8.3, wall=5637
2023-05-08 01:30:36 - progress_bar.py[line:272] - INFO: epoch 002:    538 / 866 loss=2.524, loss_v1=0, loss_v2=0, nll_loss=1.339, ntokens=2123.8, nsentences=64, sample_size=2123.8, sample_size_v1=0, sample_size_v2=0, ppl=2.53, wps=530.2, ups=0.25, wpb=2123.8, bsz=64, num_updates=1400, lr=2.69576e-05, gnorm=1.962, clip=100, loss_scale=32, train_wall=40, gb_free=7.5, wall=5677
2023-05-08 01:31:16 - progress_bar.py[line:272] - INFO: epoch 002:    548 / 866 loss=2.555, loss_v1=0, loss_v2=0, nll_loss=1.375, ntokens=2308.9, nsentences=64, sample_size=2308.9, sample_size_v1=0, sample_size_v2=0, ppl=2.59, wps=571.8, ups=0.25, wpb=2308.9, bsz=64, num_updates=1410, lr=2.71502e-05, gnorm=1.876, clip=100, loss_scale=32, train_wall=40, gb_free=8.1, wall=5717
2023-05-08 01:31:57 - progress_bar.py[line:272] - INFO: epoch 002:    558 / 866 loss=2.549, loss_v1=0, loss_v2=0, nll_loss=1.37, ntokens=2284.3, nsentences=64, sample_size=2284.3, sample_size_v1=0, sample_size_v2=0, ppl=2.58, wps=565.5, ups=0.25, wpb=2284.3, bsz=64, num_updates=1420, lr=2.73427e-05, gnorm=1.912, clip=100, loss_scale=32, train_wall=40, gb_free=7.2, wall=5758
2023-05-08 01:32:37 - progress_bar.py[line:272] - INFO: epoch 002:    568 / 866 loss=2.544, loss_v1=0, loss_v2=0, nll_loss=1.362, ntokens=2217.8, nsentences=64, sample_size=2217.8, sample_size_v1=0, sample_size_v2=0, ppl=2.57, wps=553.3, ups=0.25, wpb=2217.8, bsz=64, num_updates=1430, lr=2.75353e-05, gnorm=1.832, clip=100, loss_scale=32, train_wall=40, gb_free=7.4, wall=5798
2023-05-08 01:33:17 - progress_bar.py[line:272] - INFO: epoch 002:    578 / 866 loss=2.548, loss_v1=0, loss_v2=0, nll_loss=1.367, ntokens=2124.1, nsentences=64, sample_size=2124.1, sample_size_v1=0, sample_size_v2=0, ppl=2.58, wps=529.5, ups=0.25, wpb=2124.1, bsz=64, num_updates=1440, lr=2.77279e-05, gnorm=1.958, clip=100, loss_scale=32, train_wall=40, gb_free=7.5, wall=5838
2023-05-08 01:33:57 - progress_bar.py[line:272] - INFO: epoch 002:    588 / 866 loss=2.548, loss_v1=0, loss_v2=0, nll_loss=1.368, ntokens=2074.5, nsentences=64, sample_size=2074.5, sample_size_v1=0, sample_size_v2=0, ppl=2.58, wps=517.1, ups=0.25, wpb=2074.5, bsz=64, num_updates=1450, lr=2.79204e-05, gnorm=1.825, clip=100, loss_scale=32, train_wall=40, gb_free=7.8, wall=5878
2023-05-08 01:34:37 - progress_bar.py[line:272] - INFO: epoch 002:    598 / 866 loss=2.503, loss_v1=0, loss_v2=0, nll_loss=1.317, ntokens=2145.5, nsentences=64, sample_size=2145.5, sample_size_v1=0, sample_size_v2=0, ppl=2.49, wps=532, ups=0.25, wpb=2145.5, bsz=64, num_updates=1460, lr=2.8113e-05, gnorm=1.844, clip=100, loss_scale=32, train_wall=40, gb_free=8.4, wall=5918
2023-05-08 01:35:17 - progress_bar.py[line:272] - INFO: epoch 002:    608 / 866 loss=2.529, loss_v1=0, loss_v2=0, nll_loss=1.345, ntokens=1989.2, nsentences=64, sample_size=1989.2, sample_size_v1=0, sample_size_v2=0, ppl=2.54, wps=496.7, ups=0.25, wpb=1989.2, bsz=64, num_updates=1470, lr=2.83055e-05, gnorm=2.075, clip=100, loss_scale=32, train_wall=40, gb_free=7.4, wall=5958
2023-05-08 01:35:58 - progress_bar.py[line:272] - INFO: epoch 002:    618 / 866 loss=2.549, loss_v1=0, loss_v2=0, nll_loss=1.367, ntokens=1954.5, nsentences=64, sample_size=1954.5, sample_size_v1=0, sample_size_v2=0, ppl=2.58, wps=485.7, ups=0.25, wpb=1954.5, bsz=64, num_updates=1480, lr=2.84981e-05, gnorm=1.965, clip=100, loss_scale=32, train_wall=40, gb_free=8.1, wall=5999
2023-05-08 01:36:38 - progress_bar.py[line:272] - INFO: epoch 002:    628 / 866 loss=2.531, loss_v1=0, loss_v2=0, nll_loss=1.35, ntokens=2038.9, nsentences=64, sample_size=2038.9, sample_size_v1=0, sample_size_v2=0, ppl=2.55, wps=508.4, ups=0.25, wpb=2038.9, bsz=64, num_updates=1490, lr=2.86906e-05, gnorm=1.887, clip=100, loss_scale=32, train_wall=40, gb_free=8.1, wall=6039
2023-05-08 01:37:18 - progress_bar.py[line:272] - INFO: epoch 002:    638 / 866 loss=2.5, loss_v1=0, loss_v2=0, nll_loss=1.313, ntokens=2076.7, nsentences=64, sample_size=2076.7, sample_size_v1=0, sample_size_v2=0, ppl=2.48, wps=518.7, ups=0.25, wpb=2076.7, bsz=64, num_updates=1500, lr=2.88832e-05, gnorm=1.7, clip=100, loss_scale=32, train_wall=40, gb_free=8.1, wall=6079
2023-05-08 01:37:57 - progress_bar.py[line:272] - INFO: epoch 002:    648 / 866 loss=2.542, loss_v1=0, loss_v2=0, nll_loss=1.359, ntokens=2031.8, nsentences=64, sample_size=2031.8, sample_size_v1=0, sample_size_v2=0, ppl=2.56, wps=511.9, ups=0.25, wpb=2031.8, bsz=64, num_updates=1510, lr=2.90757e-05, gnorm=1.961, clip=100, loss_scale=32, train_wall=40, gb_free=7.9, wall=6118
2023-05-08 01:38:37 - progress_bar.py[line:272] - INFO: epoch 002:    658 / 866 loss=2.554, loss_v1=0, loss_v2=0, nll_loss=1.374, ntokens=1925.9, nsentences=64, sample_size=1925.9, sample_size_v1=0, sample_size_v2=0, ppl=2.59, wps=485.9, ups=0.25, wpb=1925.9, bsz=64, num_updates=1520, lr=2.92683e-05, gnorm=1.974, clip=100, loss_scale=32, train_wall=40, gb_free=7.7, wall=6158
2023-05-08 01:39:17 - progress_bar.py[line:272] - INFO: epoch 002:    668 / 866 loss=2.534, loss_v1=0, loss_v2=0, nll_loss=1.351, ntokens=1987.1, nsentences=64, sample_size=1987.1, sample_size_v1=0, sample_size_v2=0, ppl=2.55, wps=496.5, ups=0.25, wpb=1987.1, bsz=64, num_updates=1530, lr=2.94608e-05, gnorm=1.928, clip=100, loss_scale=32, train_wall=40, gb_free=7.3, wall=6198
2023-05-08 01:39:57 - progress_bar.py[line:272] - INFO: epoch 002:    678 / 866 loss=2.53, loss_v1=0, loss_v2=0, nll_loss=1.349, ntokens=2078.2, nsentences=64, sample_size=2078.2, sample_size_v1=0, sample_size_v2=0, ppl=2.55, wps=520.7, ups=0.25, wpb=2078.2, bsz=64, num_updates=1540, lr=2.96534e-05, gnorm=1.825, clip=100, loss_scale=32, train_wall=40, gb_free=7.9, wall=6238
2023-05-08 01:40:37 - progress_bar.py[line:272] - INFO: epoch 002:    688 / 866 loss=2.517, loss_v1=0, loss_v2=0, nll_loss=1.332, ntokens=1984.8, nsentences=64, sample_size=1984.8, sample_size_v1=0, sample_size_v2=0, ppl=2.52, wps=497.9, ups=0.25, wpb=1984.8, bsz=64, num_updates=1550, lr=2.9846e-05, gnorm=1.959, clip=100, loss_scale=32, train_wall=40, gb_free=8.1, wall=6278
2023-05-08 01:41:17 - progress_bar.py[line:272] - INFO: epoch 002:    698 / 866 loss=2.529, loss_v1=0, loss_v2=0, nll_loss=1.344, ntokens=2119.6, nsentences=64, sample_size=2119.6, sample_size_v1=0, sample_size_v2=0, ppl=2.54, wps=527.8, ups=0.25, wpb=2119.6, bsz=64, num_updates=1560, lr=2.99975e-05, gnorm=1.757, clip=100, loss_scale=32, train_wall=40, gb_free=8.1, wall=6318
2023-05-08 01:41:57 - progress_bar.py[line:272] - INFO: epoch 002:    708 / 866 loss=2.542, loss_v1=0, loss_v2=0, nll_loss=1.36, ntokens=1968.4, nsentences=64, sample_size=1968.4, sample_size_v1=0, sample_size_v2=0, ppl=2.57, wps=493.6, ups=0.25, wpb=1968.4, bsz=64, num_updates=1570, lr=2.99853e-05, gnorm=1.935, clip=100, loss_scale=32, train_wall=40, gb_free=8.1, wall=6358
2023-05-08 01:42:37 - progress_bar.py[line:272] - INFO: epoch 002:    718 / 866 loss=2.538, loss_v1=0, loss_v2=0, nll_loss=1.354, ntokens=1904, nsentences=64, sample_size=1904, sample_size_v1=0, sample_size_v2=0, ppl=2.56, wps=477.5, ups=0.25, wpb=1904, bsz=64, num_updates=1580, lr=2.9973e-05, gnorm=1.879, clip=100, loss_scale=64, train_wall=40, gb_free=8.4, wall=6398
2023-05-08 01:43:17 - progress_bar.py[line:272] - INFO: epoch 002:    728 / 866 loss=2.5, loss_v1=0, loss_v2=0, nll_loss=1.314, ntokens=2000.2, nsentences=64, sample_size=2000.2, sample_size_v1=0, sample_size_v2=0, ppl=2.49, wps=501.1, ups=0.25, wpb=2000.2, bsz=64, num_updates=1590, lr=2.99607e-05, gnorm=1.786, clip=100, loss_scale=64, train_wall=40, gb_free=7.7, wall=6438
2023-05-08 01:43:57 - progress_bar.py[line:272] - INFO: epoch 002:    738 / 866 loss=2.496, loss_v1=0, loss_v2=0, nll_loss=1.309, ntokens=2072.1, nsentences=64, sample_size=2072.1, sample_size_v1=0, sample_size_v2=0, ppl=2.48, wps=518.7, ups=0.25, wpb=2072.1, bsz=64, num_updates=1600, lr=2.99484e-05, gnorm=1.749, clip=100, loss_scale=64, train_wall=40, gb_free=8, wall=6478
2023-05-08 01:44:37 - progress_bar.py[line:272] - INFO: epoch 002:    748 / 866 loss=2.491, loss_v1=0, loss_v2=0, nll_loss=1.304, ntokens=2155.4, nsentences=64, sample_size=2155.4, sample_size_v1=0, sample_size_v2=0, ppl=2.47, wps=536.3, ups=0.25, wpb=2155.4, bsz=64, num_updates=1610, lr=2.99361e-05, gnorm=1.913, clip=100, loss_scale=64, train_wall=40, gb_free=8, wall=6518
2023-05-08 01:45:17 - progress_bar.py[line:272] - INFO: epoch 002:    758 / 866 loss=2.49, loss_v1=0, loss_v2=0, nll_loss=1.303, ntokens=2038.7, nsentences=64, sample_size=2038.7, sample_size_v1=0, sample_size_v2=0, ppl=2.47, wps=505.2, ups=0.25, wpb=2038.7, bsz=64, num_updates=1620, lr=2.99238e-05, gnorm=1.93, clip=100, loss_scale=64, train_wall=40, gb_free=7.8, wall=6558
2023-05-08 01:45:57 - progress_bar.py[line:272] - INFO: epoch 002:    768 / 866 loss=2.488, loss_v1=0, loss_v2=0, nll_loss=1.298, ntokens=2125.8, nsentences=64, sample_size=2125.8, sample_size_v1=0, sample_size_v2=0, ppl=2.46, wps=531, ups=0.25, wpb=2125.8, bsz=64, num_updates=1630, lr=2.99116e-05, gnorm=1.845, clip=100, loss_scale=64, train_wall=40, gb_free=7.7, wall=6598
2023-05-08 01:46:37 - progress_bar.py[line:272] - INFO: epoch 002:    778 / 866 loss=2.483, loss_v1=0, loss_v2=0, nll_loss=1.293, ntokens=2262.1, nsentences=64, sample_size=2262.1, sample_size_v1=0, sample_size_v2=0, ppl=2.45, wps=563.6, ups=0.25, wpb=2262.1, bsz=64, num_updates=1640, lr=2.98993e-05, gnorm=1.684, clip=100, loss_scale=64, train_wall=40, gb_free=8.3, wall=6638
2023-05-08 01:47:17 - progress_bar.py[line:272] - INFO: epoch 002:    788 / 866 loss=2.512, loss_v1=0, loss_v2=0, nll_loss=1.328, ntokens=2004.5, nsentences=64, sample_size=2004.5, sample_size_v1=0, sample_size_v2=0, ppl=2.51, wps=503.1, ups=0.25, wpb=2004.5, bsz=64, num_updates=1650, lr=2.9887e-05, gnorm=2.183, clip=100, loss_scale=64, train_wall=40, gb_free=7.4, wall=6678
2023-05-08 01:47:57 - progress_bar.py[line:272] - INFO: epoch 002:    798 / 866 loss=2.502, loss_v1=0, loss_v2=0, nll_loss=1.312, ntokens=2086.3, nsentences=64, sample_size=2086.3, sample_size_v1=0, sample_size_v2=0, ppl=2.48, wps=523.1, ups=0.25, wpb=2086.3, bsz=64, num_updates=1660, lr=2.98747e-05, gnorm=1.932, clip=100, loss_scale=64, train_wall=40, gb_free=7.9, wall=6718
2023-05-08 01:48:37 - progress_bar.py[line:272] - INFO: epoch 002:    808 / 866 loss=2.487, loss_v1=0, loss_v2=0, nll_loss=1.298, ntokens=1960.4, nsentences=64, sample_size=1960.4, sample_size_v1=0, sample_size_v2=0, ppl=2.46, wps=493.8, ups=0.25, wpb=1960.4, bsz=64, num_updates=1670, lr=2.98624e-05, gnorm=2.018, clip=100, loss_scale=64, train_wall=40, gb_free=7.9, wall=6758
2023-05-08 01:49:17 - progress_bar.py[line:272] - INFO: epoch 002:    818 / 866 loss=2.486, loss_v1=0, loss_v2=0, nll_loss=1.302, ntokens=2086.6, nsentences=64, sample_size=2086.6, sample_size_v1=0, sample_size_v2=0, ppl=2.47, wps=520.4, ups=0.25, wpb=2086.6, bsz=64, num_updates=1680, lr=2.98501e-05, gnorm=2.208, clip=100, loss_scale=64, train_wall=40, gb_free=7.8, wall=6798
2023-05-08 01:49:57 - progress_bar.py[line:272] - INFO: epoch 002:    828 / 866 loss=2.487, loss_v1=0, loss_v2=0, nll_loss=1.295, ntokens=2166.7, nsentences=64, sample_size=2166.7, sample_size_v1=0, sample_size_v2=0, ppl=2.45, wps=534.9, ups=0.25, wpb=2166.7, bsz=64, num_updates=1690, lr=2.98379e-05, gnorm=2.076, clip=100, loss_scale=64, train_wall=40, gb_free=8.1, wall=6838
2023-05-08 01:50:38 - progress_bar.py[line:272] - INFO: epoch 002:    838 / 866 loss=2.482, loss_v1=0, loss_v2=0, nll_loss=1.293, ntokens=2156.5, nsentences=64, sample_size=2156.5, sample_size_v1=0, sample_size_v2=0, ppl=2.45, wps=533.8, ups=0.25, wpb=2156.5, bsz=64, num_updates=1700, lr=2.98256e-05, gnorm=2.345, clip=100, loss_scale=64, train_wall=40, gb_free=8, wall=6879
2023-05-08 01:51:18 - progress_bar.py[line:272] - INFO: epoch 002:    848 / 866 loss=2.477, loss_v1=0, loss_v2=0, nll_loss=1.286, ntokens=2196.7, nsentences=64, sample_size=2196.7, sample_size_v1=0, sample_size_v2=0, ppl=2.44, wps=544.8, ups=0.25, wpb=2196.7, bsz=64, num_updates=1710, lr=2.98133e-05, gnorm=2.093, clip=100, loss_scale=64, train_wall=40, gb_free=7, wall=6919
2023-05-08 01:51:58 - progress_bar.py[line:272] - INFO: epoch 002:    858 / 866 loss=2.487, loss_v1=0, loss_v2=0, nll_loss=1.299, ntokens=2061.2, nsentences=64, sample_size=2061.2, sample_size_v1=0, sample_size_v2=0, ppl=2.46, wps=514.5, ups=0.25, wpb=2061.2, bsz=64, num_updates=1720, lr=2.9801e-05, gnorm=1.906, clip=100, loss_scale=64, train_wall=40, gb_free=8, wall=6959
2023-05-08 01:52:29 - train.py[line:332] - INFO: end of epoch 2 (average epoch stats below)
local datafile ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 1 begin to initialize row_count and line_idx-to-offset mapping
2023-05-08 01:52:29 - progress_bar.py[line:282] - INFO: epoch 002 | loss 2.556 | loss_v1 0 | loss_v2 0 | nll_loss 1.38 | ntokens 2103.23 | nsentences 63.972 | sample_size 2103.23 | sample_size_v1 0 | sample_size_v2 0 | ppl 2.6 | wps 522.4 | ups 0.25 | wpb 2103.2 | bsz 64 | num_updates 1728 | lr 2.97912e-05 | gnorm 2.084 | clip 100 | loss_scale 64 | train_wall 3480 | gb_free 8.7 | wall 6990
2023-05-08 01:52:29 - trainer.py[line:639] - INFO: loading train data for epoch 3
local datafile ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 0 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 1 finished initializing row_count and line_idx-to-offset mapping
file ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 1 row count 27700 total row count 55400
slice_id 1 seek offset 27700
local datafile ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 0 finished initializing row_count and line_idx-to-offset mapping
file ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 0 row count 27700 total row count 55400
slice_id 0 seek offset 0
2023-05-08 01:52:31 - trainer.py[line:703] - INFO: begin training epoch 3
2023-05-08 01:52:31 - train.py[line:305] - INFO: Start iterating over samples
2023-05-08 01:52:39 - progress_bar.py[line:272] - INFO: epoch 003:      2 / 866 loss=2.518, loss_v1=0, loss_v2=0, nll_loss=1.331, ntokens=2068.6, nsentences=61.6, sample_size=2068.6, sample_size_v1=0, sample_size_v2=0, ppl=2.52, wps=505.6, ups=0.24, wpb=2068.6, bsz=61.6, num_updates=1730, lr=2.97887e-05, gnorm=1.941, clip=100, loss_scale=64, train_wall=39, gb_free=7.2, wall=7000
2023-05-08 01:53:19 - progress_bar.py[line:272] - INFO: epoch 003:     12 / 866 loss=2.427, loss_v1=0, loss_v2=0, nll_loss=1.234, ntokens=2074.7, nsentences=64, sample_size=2074.7, sample_size_v1=0, sample_size_v2=0, ppl=2.35, wps=514, ups=0.25, wpb=2074.7, bsz=64, num_updates=1740, lr=2.97764e-05, gnorm=2.267, clip=100, loss_scale=64, train_wall=40, gb_free=8, wall=7041
2023-05-08 01:54:00 - progress_bar.py[line:272] - INFO: epoch 003:     22 / 866 loss=2.407, loss_v1=0, loss_v2=0, nll_loss=1.206, ntokens=2062.9, nsentences=64, sample_size=2062.9, sample_size_v1=0, sample_size_v2=0, ppl=2.31, wps=511, ups=0.25, wpb=2062.9, bsz=64, num_updates=1750, lr=2.97641e-05, gnorm=2.386, clip=100, loss_scale=64, train_wall=40, gb_free=7.7, wall=7081
2023-05-08 01:54:41 - progress_bar.py[line:272] - INFO: epoch 003:     32 / 866 loss=2.415, loss_v1=0, loss_v2=0, nll_loss=1.215, ntokens=2052.7, nsentences=64, sample_size=2052.7, sample_size_v1=0, sample_size_v2=0, ppl=2.32, wps=503.8, ups=0.25, wpb=2052.7, bsz=64, num_updates=1760, lr=2.97519e-05, gnorm=2.58, clip=100, loss_scale=64, train_wall=41, gb_free=6.7, wall=7122
2023-05-08 01:55:21 - progress_bar.py[line:272] - INFO: epoch 003:     42 / 866 loss=2.354, loss_v1=0, loss_v2=0, nll_loss=1.15, ntokens=2166.2, nsentences=64, sample_size=2166.2, sample_size_v1=0, sample_size_v2=0, ppl=2.22, wps=530.8, ups=0.25, wpb=2166.2, bsz=64, num_updates=1770, lr=2.97396e-05, gnorm=2.621, clip=100, loss_scale=64, train_wall=41, gb_free=7.8, wall=7163
2023-05-08 01:56:02 - progress_bar.py[line:272] - INFO: epoch 003:     52 / 866 loss=2.431, loss_v1=0, loss_v2=0, nll_loss=1.235, ntokens=1980.2, nsentences=64, sample_size=1980.2, sample_size_v1=0, sample_size_v2=0, ppl=2.35, wps=490.1, ups=0.25, wpb=1980.2, bsz=64, num_updates=1780, lr=2.97273e-05, gnorm=3.856, clip=100, loss_scale=64, train_wall=40, gb_free=8, wall=7203
2023-05-08 01:56:42 - progress_bar.py[line:272] - INFO: epoch 003:     62 / 866 loss=2.27, loss_v1=0, loss_v2=0, nll_loss=1.056, ntokens=2226.9, nsentences=64, sample_size=2226.9, sample_size_v1=0, sample_size_v2=0, ppl=2.08, wps=547.2, ups=0.25, wpb=2226.9, bsz=64, num_updates=1790, lr=2.9715e-05, gnorm=2.626, clip=100, loss_scale=64, train_wall=41, gb_free=6.5, wall=7244
2023-05-08 01:57:24 - progress_bar.py[line:272] - INFO: epoch 003:     72 / 866 loss=2.323, loss_v1=0, loss_v2=0, nll_loss=1.112, ntokens=2446.2, nsentences=64, sample_size=2446.2, sample_size_v1=0, sample_size_v2=0, ppl=2.16, wps=586.2, ups=0.24, wpb=2446.2, bsz=64, num_updates=1800, lr=2.97027e-05, gnorm=2.217, clip=100, loss_scale=64, train_wall=42, gb_free=6.5, wall=7285
2023-05-08 01:58:05 - progress_bar.py[line:272] - INFO: epoch 003:     82 / 866 loss=2.365, loss_v1=0, loss_v2=0, nll_loss=1.162, ntokens=2236.1, nsentences=64, sample_size=2236.1, sample_size_v1=0, sample_size_v2=0, ppl=2.24, wps=543.1, ups=0.24, wpb=2236.1, bsz=64, num_updates=1810, lr=2.96904e-05, gnorm=2.429, clip=100, loss_scale=64, train_wall=41, gb_free=7.1, wall=7327
2023-05-08 01:58:46 - progress_bar.py[line:272] - INFO: epoch 003:     92 / 866 loss=2.382, loss_v1=0, loss_v2=0, nll_loss=1.179, ntokens=2133.1, nsentences=64, sample_size=2133.1, sample_size_v1=0, sample_size_v2=0, ppl=2.26, wps=523.1, ups=0.25, wpb=2133.1, bsz=64, num_updates=1820, lr=2.96782e-05, gnorm=2.356, clip=100, loss_scale=64, train_wall=41, gb_free=7.4, wall=7367
2023-05-08 01:59:26 - progress_bar.py[line:272] - INFO: epoch 003:    102 / 866 loss=2.437, loss_v1=0, loss_v2=0, nll_loss=1.245, ntokens=2053.1, nsentences=64, sample_size=2053.1, sample_size_v1=0, sample_size_v2=0, ppl=2.37, wps=509.5, ups=0.25, wpb=2053.1, bsz=64, num_updates=1830, lr=2.96659e-05, gnorm=2.26, clip=100, loss_scale=64, train_wall=40, gb_free=7.4, wall=7408
2023-05-08 02:00:07 - progress_bar.py[line:272] - INFO: epoch 003:    112 / 866 loss=2.482, loss_v1=0, loss_v2=0, nll_loss=1.291, ntokens=2059.9, nsentences=64, sample_size=2059.9, sample_size_v1=0, sample_size_v2=0, ppl=2.45, wps=510.4, ups=0.25, wpb=2059.9, bsz=64, num_updates=1840, lr=2.96536e-05, gnorm=1.948, clip=100, loss_scale=64, train_wall=40, gb_free=6.3, wall=7448
2023-05-08 02:00:48 - progress_bar.py[line:272] - INFO: epoch 003:    122 / 866 loss=2.456, loss_v1=0, loss_v2=0, nll_loss=1.264, ntokens=2153.6, nsentences=64, sample_size=2153.6, sample_size_v1=0, sample_size_v2=0, ppl=2.4, wps=526.3, ups=0.24, wpb=2153.6, bsz=64, num_updates=1850, lr=2.96413e-05, gnorm=1.991, clip=100, loss_scale=64, train_wall=41, gb_free=6.9, wall=7489
2023-05-08 02:01:29 - progress_bar.py[line:272] - INFO: epoch 003:    132 / 866 loss=2.422, loss_v1=0, loss_v2=0, nll_loss=1.223, ntokens=2226.4, nsentences=64, sample_size=2226.4, sample_size_v1=0, sample_size_v2=0, ppl=2.33, wps=539.8, ups=0.24, wpb=2226.4, bsz=64, num_updates=1860, lr=2.9629e-05, gnorm=1.951, clip=100, loss_scale=64, train_wall=41, gb_free=6.9, wall=7530
2023-05-08 02:02:10 - progress_bar.py[line:272] - INFO: epoch 003:    142 / 866 loss=2.403, loss_v1=0, loss_v2=0, nll_loss=1.207, ntokens=2247.7, nsentences=64, sample_size=2247.7, sample_size_v1=0, sample_size_v2=0, ppl=2.31, wps=545.6, ups=0.24, wpb=2247.7, bsz=64, num_updates=1870, lr=2.96167e-05, gnorm=2.18, clip=100, loss_scale=64, train_wall=41, gb_free=7, wall=7571
2023-05-08 02:02:52 - progress_bar.py[line:272] - INFO: epoch 003:    152 / 866 loss=2.417, loss_v1=0, loss_v2=0, nll_loss=1.221, ntokens=2190.1, nsentences=64, sample_size=2190.1, sample_size_v1=0, sample_size_v2=0, ppl=2.33, wps=530.3, ups=0.24, wpb=2190.1, bsz=64, num_updates=1880, lr=2.96045e-05, gnorm=2.279, clip=100, loss_scale=64, train_wall=41, gb_free=6.9, wall=7613
2023-05-08 02:03:33 - progress_bar.py[line:272] - INFO: epoch 003:    162 / 866 loss=2.42, loss_v1=0, loss_v2=0, nll_loss=1.223, ntokens=2159.5, nsentences=64, sample_size=2159.5, sample_size_v1=0, sample_size_v2=0, ppl=2.33, wps=526.5, ups=0.24, wpb=2159.5, bsz=64, num_updates=1890, lr=2.95922e-05, gnorm=2.28, clip=100, loss_scale=64, train_wall=41, gb_free=7.2, wall=7654
2023-05-08 02:04:13 - progress_bar.py[line:272] - INFO: epoch 003:    172 / 866 loss=2.436, loss_v1=0, loss_v2=0, nll_loss=1.24, ntokens=2057.6, nsentences=64, sample_size=2057.6, sample_size_v1=0, sample_size_v2=0, ppl=2.36, wps=507.7, ups=0.25, wpb=2057.6, bsz=64, num_updates=1900, lr=2.95799e-05, gnorm=2.359, clip=100, loss_scale=64, train_wall=40, gb_free=7.5, wall=7694
2023-05-08 02:04:54 - progress_bar.py[line:272] - INFO: epoch 003:    182 / 866 loss=2.384, loss_v1=0, loss_v2=0, nll_loss=1.182, ntokens=2189.4, nsentences=64, sample_size=2189.4, sample_size_v1=0, sample_size_v2=0, ppl=2.27, wps=532.4, ups=0.24, wpb=2189.4, bsz=64, num_updates=1910, lr=2.95676e-05, gnorm=2.116, clip=100, loss_scale=64, train_wall=41, gb_free=7.3, wall=7735
2023-05-08 02:05:35 - progress_bar.py[line:272] - INFO: epoch 003:    192 / 866 loss=2.413, loss_v1=0, loss_v2=0, nll_loss=1.216, ntokens=2214.7, nsentences=64, sample_size=2214.7, sample_size_v1=0, sample_size_v2=0, ppl=2.32, wps=541.4, ups=0.24, wpb=2214.7, bsz=64, num_updates=1920, lr=2.95553e-05, gnorm=2.114, clip=100, loss_scale=64, train_wall=41, gb_free=6.8, wall=7776
2023-05-08 02:06:16 - progress_bar.py[line:272] - INFO: epoch 003:    202 / 866 loss=2.444, loss_v1=0, loss_v2=0, nll_loss=1.248, ntokens=2086.6, nsentences=64, sample_size=2086.6, sample_size_v1=0, sample_size_v2=0, ppl=2.38, wps=512.8, ups=0.25, wpb=2086.6, bsz=64, num_updates=1930, lr=2.9543e-05, gnorm=2.215, clip=100, loss_scale=64, train_wall=41, gb_free=6.9, wall=7817
2023-05-08 02:06:56 - progress_bar.py[line:272] - INFO: epoch 003:    212 / 866 loss=2.489, loss_v1=0, loss_v2=0, nll_loss=1.301, ntokens=2014.6, nsentences=64, sample_size=2014.6, sample_size_v1=0, sample_size_v2=0, ppl=2.46, wps=501.2, ups=0.25, wpb=2014.6, bsz=64, num_updates=1940, lr=2.95308e-05, gnorm=2.261, clip=100, loss_scale=64, train_wall=40, gb_free=7.3, wall=7857
2023-05-08 02:07:36 - progress_bar.py[line:272] - INFO: epoch 003:    222 / 866 loss=2.473, loss_v1=0, loss_v2=0, nll_loss=1.284, ntokens=2222.5, nsentences=64, sample_size=2222.5, sample_size_v1=0, sample_size_v2=0, ppl=2.44, wps=552.4, ups=0.25, wpb=2222.5, bsz=64, num_updates=1950, lr=2.95185e-05, gnorm=2.223, clip=100, loss_scale=64, train_wall=40, gb_free=7.1, wall=7897
2023-05-08 02:08:16 - progress_bar.py[line:272] - INFO: epoch 003:    232 / 866 loss=2.496, loss_v1=0, loss_v2=0, nll_loss=1.308, ntokens=2130.9, nsentences=64, sample_size=2130.9, sample_size_v1=0, sample_size_v2=0, ppl=2.48, wps=532.6, ups=0.25, wpb=2130.9, bsz=64, num_updates=1960, lr=2.95062e-05, gnorm=2.191, clip=100, loss_scale=64, train_wall=40, gb_free=7.6, wall=7937
2023-05-08 02:08:56 - progress_bar.py[line:272] - INFO: epoch 003:    242 / 866 loss=2.48, loss_v1=0, loss_v2=0, nll_loss=1.292, ntokens=2192.7, nsentences=64, sample_size=2192.7, sample_size_v1=0, sample_size_v2=0, ppl=2.45, wps=545.1, ups=0.25, wpb=2192.7, bsz=64, num_updates=1970, lr=2.94939e-05, gnorm=2.118, clip=100, loss_scale=64, train_wall=40, gb_free=7.1, wall=7978
2023-05-08 02:09:37 - progress_bar.py[line:272] - INFO: epoch 003:    252 / 866 loss=2.497, loss_v1=0, loss_v2=0, nll_loss=1.309, ntokens=2103.6, nsentences=64, sample_size=2103.6, sample_size_v1=0, sample_size_v2=0, ppl=2.48, wps=522.2, ups=0.25, wpb=2103.6, bsz=64, num_updates=1980, lr=2.94816e-05, gnorm=2.276, clip=100, loss_scale=64, train_wall=40, gb_free=7.5, wall=8018
2023-05-08 02:10:17 - progress_bar.py[line:272] - INFO: epoch 003:    262 / 866 loss=2.498, loss_v1=0, loss_v2=0, nll_loss=1.31, ntokens=2158.9, nsentences=64, sample_size=2158.9, sample_size_v1=0, sample_size_v2=0, ppl=2.48, wps=538.3, ups=0.25, wpb=2158.9, bsz=64, num_updates=1990, lr=2.94693e-05, gnorm=2.106, clip=100, loss_scale=64, train_wall=40, gb_free=7.7, wall=8058
2023-05-08 02:10:57 - progress_bar.py[line:272] - INFO: epoch 003:    272 / 866 loss=2.475, loss_v1=0, loss_v2=0, nll_loss=1.287, ntokens=2133.5, nsentences=64, sample_size=2133.5, sample_size_v1=0, sample_size_v2=0, ppl=2.44, wps=531.5, ups=0.25, wpb=2133.5, bsz=64, num_updates=2000, lr=2.9457e-05, gnorm=2.235, clip=100, loss_scale=64, train_wall=40, gb_free=8, wall=8098
2023-05-08 02:11:37 - progress_bar.py[line:272] - INFO: epoch 003:    282 / 866 loss=2.495, loss_v1=0, loss_v2=0, nll_loss=1.306, ntokens=2167.2, nsentences=64, sample_size=2167.2, sample_size_v1=0, sample_size_v2=0, ppl=2.47, wps=537, ups=0.25, wpb=2167.2, bsz=64, num_updates=2010, lr=2.94448e-05, gnorm=2.316, clip=100, loss_scale=64, train_wall=40, gb_free=6.9, wall=8138
2023-05-08 02:12:17 - progress_bar.py[line:272] - INFO: epoch 003:    292 / 866 loss=2.451, loss_v1=0, loss_v2=0, nll_loss=1.259, ntokens=2121.1, nsentences=64, sample_size=2121.1, sample_size_v1=0, sample_size_v2=0, ppl=2.39, wps=529.5, ups=0.25, wpb=2121.1, bsz=64, num_updates=2020, lr=2.94325e-05, gnorm=2.534, clip=100, loss_scale=64, train_wall=40, gb_free=7.8, wall=8179
2023-05-08 02:12:57 - progress_bar.py[line:272] - INFO: epoch 003:    302 / 866 loss=2.476, loss_v1=0, loss_v2=0, nll_loss=1.285, ntokens=2135.1, nsentences=64, sample_size=2135.1, sample_size_v1=0, sample_size_v2=0, ppl=2.44, wps=533.8, ups=0.25, wpb=2135.1, bsz=64, num_updates=2030, lr=2.94202e-05, gnorm=2.467, clip=100, loss_scale=64, train_wall=40, gb_free=7.9, wall=8219
2023-05-08 02:13:38 - progress_bar.py[line:272] - INFO: epoch 003:    312 / 866 loss=2.453, loss_v1=0, loss_v2=0, nll_loss=1.26, ntokens=2131.6, nsentences=64, sample_size=2131.6, sample_size_v1=0, sample_size_v2=0, ppl=2.39, wps=527, ups=0.25, wpb=2131.6, bsz=64, num_updates=2040, lr=2.94079e-05, gnorm=2.43, clip=100, loss_scale=64, train_wall=40, gb_free=7.8, wall=8259
2023-05-08 02:14:18 - progress_bar.py[line:272] - INFO: epoch 003:    322 / 866 loss=2.501, loss_v1=0, loss_v2=0, nll_loss=1.315, ntokens=1957, nsentences=64, sample_size=1957, sample_size_v1=0, sample_size_v2=0, ppl=2.49, wps=491.9, ups=0.25, wpb=1957, bsz=64, num_updates=2050, lr=2.93956e-05, gnorm=2.792, clip=100, loss_scale=64, train_wall=40, gb_free=7.7, wall=8299
2023-05-08 02:14:58 - progress_bar.py[line:272] - INFO: epoch 003:    332 / 866 loss=2.464, loss_v1=0, loss_v2=0, nll_loss=1.273, ntokens=2161.6, nsentences=64, sample_size=2161.6, sample_size_v1=0, sample_size_v2=0, ppl=2.42, wps=540.9, ups=0.25, wpb=2161.6, bsz=64, num_updates=2060, lr=2.93833e-05, gnorm=2.545, clip=100, loss_scale=64, train_wall=40, gb_free=7.6, wall=8339
2023-05-08 02:15:38 - progress_bar.py[line:272] - INFO: epoch 003:    342 / 866 loss=2.446, loss_v1=0, loss_v2=0, nll_loss=1.253, ntokens=2014.9, nsentences=64, sample_size=2014.9, sample_size_v1=0, sample_size_v2=0, ppl=2.38, wps=503.9, ups=0.25, wpb=2014.9, bsz=64, num_updates=2070, lr=2.93711e-05, gnorm=2.677, clip=100, loss_scale=64, train_wall=40, gb_free=8.2, wall=8379
2023-05-08 02:16:17 - progress_bar.py[line:272] - INFO: epoch 003:    352 / 866 loss=2.48, loss_v1=0, loss_v2=0, nll_loss=1.291, ntokens=1958, nsentences=64, sample_size=1958, sample_size_v1=0, sample_size_v2=0, ppl=2.45, wps=492.6, ups=0.25, wpb=1958, bsz=64, num_updates=2080, lr=2.93588e-05, gnorm=3.081, clip=100, loss_scale=64, train_wall=40, gb_free=8.2, wall=8418
2023-05-08 02:16:57 - progress_bar.py[line:272] - INFO: epoch 003:    362 / 866 loss=2.484, loss_v1=0, loss_v2=0, nll_loss=1.295, ntokens=1964.4, nsentences=64, sample_size=1964.4, sample_size_v1=0, sample_size_v2=0, ppl=2.45, wps=493.8, ups=0.25, wpb=1964.4, bsz=64, num_updates=2090, lr=2.93465e-05, gnorm=2.708, clip=100, loss_scale=128, train_wall=40, gb_free=7.7, wall=8458
2023-05-08 02:17:37 - progress_bar.py[line:272] - INFO: epoch 003:    372 / 866 loss=2.474, loss_v1=0, loss_v2=0, nll_loss=1.285, ntokens=2038.1, nsentences=64, sample_size=2038.1, sample_size_v1=0, sample_size_v2=0, ppl=2.44, wps=508.9, ups=0.25, wpb=2038.1, bsz=64, num_updates=2100, lr=2.93342e-05, gnorm=2.448, clip=100, loss_scale=128, train_wall=40, gb_free=8, wall=8498
2023-05-08 02:18:17 - progress_bar.py[line:272] - INFO: epoch 003:    382 / 866 loss=2.445, loss_v1=0, loss_v2=0, nll_loss=1.251, ntokens=2164.2, nsentences=64, sample_size=2164.2, sample_size_v1=0, sample_size_v2=0, ppl=2.38, wps=541, ups=0.25, wpb=2164.2, bsz=64, num_updates=2110, lr=2.93219e-05, gnorm=2.175, clip=100, loss_scale=128, train_wall=40, gb_free=7.5, wall=8538
2023-05-08 02:18:57 - progress_bar.py[line:272] - INFO: epoch 003:    392 / 866 loss=2.454, loss_v1=0, loss_v2=0, nll_loss=1.263, ntokens=2067.8, nsentences=64, sample_size=2067.8, sample_size_v1=0, sample_size_v2=0, ppl=2.4, wps=518.8, ups=0.25, wpb=2067.8, bsz=64, num_updates=2120, lr=2.93096e-05, gnorm=2.674, clip=100, loss_scale=128, train_wall=40, gb_free=8.2, wall=8578
2023-05-08 02:19:37 - progress_bar.py[line:272] - INFO: epoch 003:    402 / 866 loss=2.466, loss_v1=0, loss_v2=0, nll_loss=1.274, ntokens=2036, nsentences=64, sample_size=2036, sample_size_v1=0, sample_size_v2=0, ppl=2.42, wps=508.7, ups=0.25, wpb=2036, bsz=64, num_updates=2130, lr=2.92974e-05, gnorm=2.575, clip=100, loss_scale=128, train_wall=40, gb_free=7.6, wall=8618
2023-05-08 02:20:17 - progress_bar.py[line:272] - INFO: epoch 003:    412 / 866 loss=2.463, loss_v1=0, loss_v2=0, nll_loss=1.272, ntokens=2161.9, nsentences=64, sample_size=2161.9, sample_size_v1=0, sample_size_v2=0, ppl=2.42, wps=539.4, ups=0.25, wpb=2161.9, bsz=64, num_updates=2140, lr=2.92851e-05, gnorm=2.518, clip=100, loss_scale=128, train_wall=40, gb_free=7.5, wall=8658
2023-05-08 02:20:57 - progress_bar.py[line:272] - INFO: epoch 003:    422 / 866 loss=2.45, loss_v1=0, loss_v2=0, nll_loss=1.258, ntokens=2082.2, nsentences=64, sample_size=2082.2, sample_size_v1=0, sample_size_v2=0, ppl=2.39, wps=519.7, ups=0.25, wpb=2082.2, bsz=64, num_updates=2150, lr=2.92728e-05, gnorm=2.345, clip=100, loss_scale=128, train_wall=40, gb_free=7.2, wall=8698
2023-05-08 02:21:37 - progress_bar.py[line:272] - INFO: epoch 003:    432 / 866 loss=2.45, loss_v1=0, loss_v2=0, nll_loss=1.256, ntokens=2104.8, nsentences=64, sample_size=2104.8, sample_size_v1=0, sample_size_v2=0, ppl=2.39, wps=526.6, ups=0.25, wpb=2104.8, bsz=64, num_updates=2160, lr=2.92605e-05, gnorm=2.394, clip=100, loss_scale=128, train_wall=40, gb_free=8.1, wall=8738
2023-05-08 02:22:17 - progress_bar.py[line:272] - INFO: epoch 003:    442 / 866 loss=2.48, loss_v1=0, loss_v2=0, nll_loss=1.289, ntokens=2064.2, nsentences=64, sample_size=2064.2, sample_size_v1=0, sample_size_v2=0, ppl=2.44, wps=514.1, ups=0.25, wpb=2064.2, bsz=64, num_updates=2170, lr=2.92482e-05, gnorm=2.744, clip=100, loss_scale=128, train_wall=40, gb_free=7.3, wall=8779
2023-05-08 02:22:57 - progress_bar.py[line:272] - INFO: epoch 003:    452 / 866 loss=2.457, loss_v1=0, loss_v2=0, nll_loss=1.265, ntokens=1981.6, nsentences=64, sample_size=1981.6, sample_size_v1=0, sample_size_v2=0, ppl=2.4, wps=496.4, ups=0.25, wpb=1981.6, bsz=64, num_updates=2180, lr=2.92359e-05, gnorm=2.913, clip=100, loss_scale=128, train_wall=40, gb_free=8.3, wall=8818
2023-05-08 02:23:38 - progress_bar.py[line:272] - INFO: epoch 003:    462 / 866 loss=2.457, loss_v1=0, loss_v2=0, nll_loss=1.268, ntokens=2192.3, nsentences=64, sample_size=2192.3, sample_size_v1=0, sample_size_v2=0, ppl=2.41, wps=539.9, ups=0.25, wpb=2192.3, bsz=64, num_updates=2190, lr=2.92237e-05, gnorm=2.897, clip=100, loss_scale=128, train_wall=41, gb_free=7.3, wall=8859
2023-05-08 02:24:18 - progress_bar.py[line:272] - INFO: epoch 003:    472 / 866 loss=2.458, loss_v1=0, loss_v2=0, nll_loss=1.265, ntokens=2142.5, nsentences=64, sample_size=2142.5, sample_size_v1=0, sample_size_v2=0, ppl=2.4, wps=532.5, ups=0.25, wpb=2142.5, bsz=64, num_updates=2200, lr=2.92114e-05, gnorm=2.785, clip=100, loss_scale=128, train_wall=40, gb_free=7.3, wall=8899
2023-05-08 02:24:59 - progress_bar.py[line:272] - INFO: epoch 003:    482 / 866 loss=2.456, loss_v1=0, loss_v2=0, nll_loss=1.264, ntokens=2178.2, nsentences=64, sample_size=2178.2, sample_size_v1=0, sample_size_v2=0, ppl=2.4, wps=538.2, ups=0.25, wpb=2178.2, bsz=64, num_updates=2210, lr=2.91991e-05, gnorm=2.738, clip=100, loss_scale=128, train_wall=40, gb_free=8.2, wall=8940
2023-05-08 02:25:39 - progress_bar.py[line:272] - INFO: epoch 003:    492 / 866 loss=2.441, loss_v1=0, loss_v2=0, nll_loss=1.245, ntokens=2054.4, nsentences=64, sample_size=2054.4, sample_size_v1=0, sample_size_v2=0, ppl=2.37, wps=513.2, ups=0.25, wpb=2054.4, bsz=64, num_updates=2220, lr=2.91868e-05, gnorm=2.54, clip=100, loss_scale=128, train_wall=40, gb_free=7.5, wall=8980
2023-05-08 02:26:19 - progress_bar.py[line:272] - INFO: epoch 003:    502 / 866 loss=2.454, loss_v1=0, loss_v2=0, nll_loss=1.262, ntokens=2074.9, nsentences=64, sample_size=2074.9, sample_size_v1=0, sample_size_v2=0, ppl=2.4, wps=519.1, ups=0.25, wpb=2074.9, bsz=64, num_updates=2230, lr=2.91745e-05, gnorm=2.528, clip=100, loss_scale=128, train_wall=40, gb_free=7.9, wall=9020
2023-05-08 02:26:59 - progress_bar.py[line:272] - INFO: epoch 003:    512 / 866 loss=2.474, loss_v1=0, loss_v2=0, nll_loss=1.285, ntokens=2141.6, nsentences=64, sample_size=2141.6, sample_size_v1=0, sample_size_v2=0, ppl=2.44, wps=535.5, ups=0.25, wpb=2141.6, bsz=64, num_updates=2240, lr=2.91622e-05, gnorm=2.542, clip=100, loss_scale=128, train_wall=40, gb_free=7, wall=9060
2023-05-08 02:27:38 - progress_bar.py[line:272] - INFO: epoch 003:    522 / 866 loss=2.445, loss_v1=0, loss_v2=0, nll_loss=1.252, ntokens=2127.1, nsentences=64, sample_size=2127.1, sample_size_v1=0, sample_size_v2=0, ppl=2.38, wps=534.2, ups=0.25, wpb=2127.1, bsz=64, num_updates=2250, lr=2.91499e-05, gnorm=2.759, clip=100, loss_scale=128, train_wall=40, gb_free=8.1, wall=9100
2023-05-08 02:28:18 - progress_bar.py[line:272] - INFO: epoch 003:    532 / 866 loss=2.449, loss_v1=0, loss_v2=0, nll_loss=1.256, ntokens=2031, nsentences=64, sample_size=2031, sample_size_v1=0, sample_size_v2=0, ppl=2.39, wps=509.6, ups=0.25, wpb=2031, bsz=64, num_updates=2260, lr=2.91377e-05, gnorm=2.306, clip=100, loss_scale=128, train_wall=40, gb_free=8.3, wall=9139
2023-05-08 02:28:58 - progress_bar.py[line:272] - INFO: epoch 003:    542 / 866 loss=2.462, loss_v1=0, loss_v2=0, nll_loss=1.271, ntokens=2149.8, nsentences=64, sample_size=2149.8, sample_size_v1=0, sample_size_v2=0, ppl=2.41, wps=536.4, ups=0.25, wpb=2149.8, bsz=64, num_updates=2270, lr=2.91254e-05, gnorm=2.31, clip=100, loss_scale=128, train_wall=40, gb_free=7.3, wall=9180
2023-05-08 02:29:39 - progress_bar.py[line:272] - INFO: epoch 003:    552 / 866 loss=2.477, loss_v1=0, loss_v2=0, nll_loss=1.287, ntokens=2323, nsentences=64, sample_size=2323, sample_size_v1=0, sample_size_v2=0, ppl=2.44, wps=575.3, ups=0.25, wpb=2323, bsz=64, num_updates=2280, lr=2.91131e-05, gnorm=2.313, clip=100, loss_scale=128, train_wall=40, gb_free=7.4, wall=9220
2023-05-08 02:30:19 - progress_bar.py[line:272] - INFO: epoch 003:    562 / 866 loss=2.455, loss_v1=0, loss_v2=0, nll_loss=1.262, ntokens=2243.9, nsentences=64, sample_size=2243.9, sample_size_v1=0, sample_size_v2=0, ppl=2.4, wps=556.4, ups=0.25, wpb=2243.9, bsz=64, num_updates=2290, lr=2.91008e-05, gnorm=2.507, clip=100, loss_scale=128, train_wall=40, gb_free=8.3, wall=9260
2023-05-08 02:30:59 - progress_bar.py[line:272] - INFO: epoch 003:    572 / 866 loss=2.456, loss_v1=0, loss_v2=0, nll_loss=1.263, ntokens=2202.4, nsentences=64, sample_size=2202.4, sample_size_v1=0, sample_size_v2=0, ppl=2.4, wps=549, ups=0.25, wpb=2202.4, bsz=64, num_updates=2300, lr=2.90885e-05, gnorm=2.426, clip=100, loss_scale=128, train_wall=40, gb_free=7.4, wall=9300
2023-05-08 02:31:39 - progress_bar.py[line:272] - INFO: epoch 003:    582 / 866 loss=2.469, loss_v1=0, loss_v2=0, nll_loss=1.278, ntokens=2123.1, nsentences=64, sample_size=2123.1, sample_size_v1=0, sample_size_v2=0, ppl=2.42, wps=529.5, ups=0.25, wpb=2123.1, bsz=64, num_updates=2310, lr=2.90762e-05, gnorm=2.535, clip=100, loss_scale=128, train_wall=40, gb_free=7.4, wall=9340
2023-05-08 02:32:20 - progress_bar.py[line:272] - INFO: epoch 003:    592 / 866 loss=2.446, loss_v1=0, loss_v2=0, nll_loss=1.253, ntokens=2089, nsentences=64, sample_size=2089, sample_size_v1=0, sample_size_v2=0, ppl=2.38, wps=518.8, ups=0.25, wpb=2089, bsz=64, num_updates=2320, lr=2.9064e-05, gnorm=2.89, clip=100, loss_scale=128, train_wall=40, gb_free=7.3, wall=9381
2023-05-08 02:33:00 - progress_bar.py[line:272] - INFO: epoch 003:    602 / 866 loss=2.418, loss_v1=0, loss_v2=0, nll_loss=1.223, ntokens=2122.3, nsentences=64, sample_size=2122.3, sample_size_v1=0, sample_size_v2=0, ppl=2.33, wps=522.8, ups=0.25, wpb=2122.3, bsz=64, num_updates=2330, lr=2.90517e-05, gnorm=2.886, clip=100, loss_scale=128, train_wall=41, gb_free=8.3, wall=9421
2023-05-08 02:33:40 - progress_bar.py[line:272] - INFO: epoch 003:    612 / 866 loss=2.464, loss_v1=0, loss_v2=0, nll_loss=1.272, ntokens=1933.1, nsentences=64, sample_size=1933.1, sample_size_v1=0, sample_size_v2=0, ppl=2.42, wps=484.2, ups=0.25, wpb=1933.1, bsz=64, num_updates=2340, lr=2.90394e-05, gnorm=3.195, clip=100, loss_scale=128, train_wall=40, gb_free=8.1, wall=9461
2023-05-08 02:34:20 - progress_bar.py[line:272] - INFO: epoch 003:    622 / 866 loss=2.456, loss_v1=0, loss_v2=0, nll_loss=1.262, ntokens=2007.3, nsentences=64, sample_size=2007.3, sample_size_v1=0, sample_size_v2=0, ppl=2.4, wps=499.1, ups=0.25, wpb=2007.3, bsz=64, num_updates=2350, lr=2.90271e-05, gnorm=3.12, clip=100, loss_scale=128, train_wall=40, gb_free=7.7, wall=9501
2023-05-08 02:35:00 - progress_bar.py[line:272] - INFO: epoch 003:    632 / 866 loss=2.443, loss_v1=0, loss_v2=0, nll_loss=1.252, ntokens=2011.8, nsentences=64, sample_size=2011.8, sample_size_v1=0, sample_size_v2=0, ppl=2.38, wps=504.7, ups=0.25, wpb=2011.8, bsz=64, num_updates=2360, lr=2.90148e-05, gnorm=3.304, clip=100, loss_scale=128, train_wall=40, gb_free=8.1, wall=9541
2023-05-08 02:35:40 - progress_bar.py[line:272] - INFO: epoch 003:    642 / 866 loss=2.418, loss_v1=0, loss_v2=0, nll_loss=1.221, ntokens=2063.3, nsentences=64, sample_size=2063.3, sample_size_v1=0, sample_size_v2=0, ppl=2.33, wps=516.4, ups=0.25, wpb=2063.3, bsz=64, num_updates=2370, lr=2.90025e-05, gnorm=3.302, clip=100, loss_scale=128, train_wall=40, gb_free=7.5, wall=9581
2023-05-08 02:36:20 - progress_bar.py[line:272] - INFO: epoch 003:    652 / 866 loss=2.463, loss_v1=0, loss_v2=0, nll_loss=1.272, ntokens=2019.1, nsentences=64, sample_size=2019.1, sample_size_v1=0, sample_size_v2=0, ppl=2.42, wps=506.8, ups=0.25, wpb=2019.1, bsz=64, num_updates=2380, lr=2.89903e-05, gnorm=3.315, clip=100, loss_scale=128, train_wall=40, gb_free=8.7, wall=9621
2023-05-08 02:37:00 - progress_bar.py[line:272] - INFO: epoch 003:    662 / 866 loss=2.475, loss_v1=0, loss_v2=0, nll_loss=1.284, ntokens=1927, nsentences=64, sample_size=1927, sample_size_v1=0, sample_size_v2=0, ppl=2.44, wps=485.5, ups=0.25, wpb=1927, bsz=64, num_updates=2390, lr=2.8978e-05, gnorm=3.391, clip=100, loss_scale=128, train_wall=40, gb_free=6.9, wall=9661
2023-05-08 02:37:40 - progress_bar.py[line:272] - INFO: epoch 003:    672 / 866 loss=2.455, loss_v1=0, loss_v2=0, nll_loss=1.264, ntokens=2033.9, nsentences=64, sample_size=2033.9, sample_size_v1=0, sample_size_v2=0, ppl=2.4, wps=507.4, ups=0.25, wpb=2033.9, bsz=64, num_updates=2400, lr=2.89657e-05, gnorm=3.525, clip=100, loss_scale=128, train_wall=40, gb_free=8.1, wall=9701
2023-05-08 02:38:20 - progress_bar.py[line:272] - INFO: epoch 003:    682 / 866 loss=2.43, loss_v1=0, loss_v2=0, nll_loss=1.233, ntokens=2076.8, nsentences=64, sample_size=2076.8, sample_size_v1=0, sample_size_v2=0, ppl=2.35, wps=520, ups=0.25, wpb=2076.8, bsz=64, num_updates=2410, lr=2.89534e-05, gnorm=3.268, clip=100, loss_scale=128, train_wall=40, gb_free=7.9, wall=9741
2023-05-08 02:39:00 - progress_bar.py[line:272] - INFO: epoch 003:    692 / 866 loss=2.444, loss_v1=0, loss_v2=0, nll_loss=1.252, ntokens=1991.3, nsentences=64, sample_size=1991.3, sample_size_v1=0, sample_size_v2=0, ppl=2.38, wps=498.1, ups=0.25, wpb=1991.3, bsz=64, num_updates=2420, lr=2.89411e-05, gnorm=3.727, clip=100, loss_scale=128, train_wall=40, gb_free=8.3, wall=9781
2023-05-08 02:39:40 - progress_bar.py[line:272] - INFO: epoch 003:    702 / 866 loss=2.458, loss_v1=0, loss_v2=0, nll_loss=1.266, ntokens=2062.5, nsentences=64, sample_size=2062.5, sample_size_v1=0, sample_size_v2=0, ppl=2.41, wps=516.4, ups=0.25, wpb=2062.5, bsz=64, num_updates=2430, lr=2.89288e-05, gnorm=3.315, clip=100, loss_scale=128, train_wall=40, gb_free=8, wall=9821
2023-05-08 02:40:20 - progress_bar.py[line:272] - INFO: epoch 003:    712 / 866 loss=2.466, loss_v1=0, loss_v2=0, nll_loss=1.275, ntokens=1917.3, nsentences=64, sample_size=1917.3, sample_size_v1=0, sample_size_v2=0, ppl=2.42, wps=478.2, ups=0.25, wpb=1917.3, bsz=64, num_updates=2440, lr=2.89166e-05, gnorm=3.918, clip=100, loss_scale=128, train_wall=40, gb_free=8.3, wall=9861
2023-05-08 02:41:00 - progress_bar.py[line:272] - INFO: epoch 003:    722 / 866 loss=2.437, loss_v1=0, loss_v2=0, nll_loss=1.244, ntokens=1946.1, nsentences=64, sample_size=1946.1, sample_size_v1=0, sample_size_v2=0, ppl=2.37, wps=486.8, ups=0.25, wpb=1946.1, bsz=64, num_updates=2450, lr=2.89043e-05, gnorm=3.771, clip=100, loss_scale=128, train_wall=40, gb_free=7.9, wall=9901
2023-05-08 02:41:40 - progress_bar.py[line:272] - INFO: epoch 003:    732 / 866 loss=2.42, loss_v1=0, loss_v2=0, nll_loss=1.225, ntokens=2021.9, nsentences=64, sample_size=2021.9, sample_size_v1=0, sample_size_v2=0, ppl=2.34, wps=506.1, ups=0.25, wpb=2021.9, bsz=64, num_updates=2460, lr=2.8892e-05, gnorm=3.227, clip=100, loss_scale=128, train_wall=40, gb_free=7.4, wall=9941
2023-05-08 02:42:20 - progress_bar.py[line:272] - INFO: epoch 003:    742 / 866 loss=2.417, loss_v1=0, loss_v2=0, nll_loss=1.217, ntokens=2148.8, nsentences=64, sample_size=2148.8, sample_size_v1=0, sample_size_v2=0, ppl=2.32, wps=529.4, ups=0.25, wpb=2148.8, bsz=64, num_updates=2470, lr=2.88797e-05, gnorm=3.381, clip=100, loss_scale=128, train_wall=41, gb_free=7.9, wall=9981
2023-05-08 02:43:00 - progress_bar.py[line:272] - INFO: epoch 003:    752 / 866 loss=2.412, loss_v1=0, loss_v2=0, nll_loss=1.216, ntokens=2084.2, nsentences=64, sample_size=2084.2, sample_size_v1=0, sample_size_v2=0, ppl=2.32, wps=520.6, ups=0.25, wpb=2084.2, bsz=64, num_updates=2480, lr=2.88674e-05, gnorm=3.321, clip=100, loss_scale=128, train_wall=40, gb_free=8.1, wall=10021
2023-05-08 02:43:41 - progress_bar.py[line:272] - INFO: epoch 003:    762 / 866 loss=2.432, loss_v1=0, loss_v2=0, nll_loss=1.238, ntokens=2125.4, nsentences=64, sample_size=2125.4, sample_size_v1=0, sample_size_v2=0, ppl=2.36, wps=529.4, ups=0.25, wpb=2125.4, bsz=64, num_updates=2490, lr=2.88551e-05, gnorm=3.232, clip=100, loss_scale=128, train_wall=40, gb_free=8.3, wall=10062
2023-05-08 02:44:20 - progress_bar.py[line:272] - INFO: epoch 003:    772 / 866 loss=2.412, loss_v1=0, loss_v2=0, nll_loss=1.212, ntokens=2085.7, nsentences=64, sample_size=2085.7, sample_size_v1=0, sample_size_v2=0, ppl=2.32, wps=522.6, ups=0.25, wpb=2085.7, bsz=64, num_updates=2500, lr=2.88428e-05, gnorm=3.619, clip=100, loss_scale=128, train_wall=40, gb_free=6.6, wall=10102
2023-05-08 02:45:01 - progress_bar.py[line:272] - INFO: epoch 003:    782 / 866 loss=2.414, loss_v1=0, loss_v2=0, nll_loss=1.217, ntokens=2278.8, nsentences=64, sample_size=2278.8, sample_size_v1=0, sample_size_v2=0, ppl=2.33, wps=564.9, ups=0.25, wpb=2278.8, bsz=64, num_updates=2510, lr=2.88306e-05, gnorm=2.92, clip=100, loss_scale=128, train_wall=40, gb_free=8, wall=10142
2023-05-08 02:45:41 - progress_bar.py[line:272] - INFO: epoch 003:    792 / 866 loss=2.458, loss_v1=0, loss_v2=0, nll_loss=1.266, ntokens=1976.5, nsentences=64, sample_size=1976.5, sample_size_v1=0, sample_size_v2=0, ppl=2.41, wps=496, ups=0.25, wpb=1976.5, bsz=64, num_updates=2520, lr=2.88183e-05, gnorm=3.831, clip=100, loss_scale=128, train_wall=40, gb_free=8.4, wall=10182
2023-05-08 02:46:20 - progress_bar.py[line:272] - INFO: epoch 003:    802 / 866 loss=2.431, loss_v1=0, loss_v2=0, nll_loss=1.236, ntokens=1992.1, nsentences=64, sample_size=1992.1, sample_size_v1=0, sample_size_v2=0, ppl=2.36, wps=500.4, ups=0.25, wpb=1992.1, bsz=64, num_updates=2530, lr=2.8806e-05, gnorm=3.615, clip=100, loss_scale=128, train_wall=40, gb_free=8.1, wall=10222
2023-05-08 02:47:00 - progress_bar.py[line:272] - INFO: epoch 003:    812 / 866 loss=2.41, loss_v1=0, loss_v2=0, nll_loss=1.212, ntokens=2094, nsentences=64, sample_size=2094, sample_size_v1=0, sample_size_v2=0, ppl=2.32, wps=523.9, ups=0.25, wpb=2094, bsz=64, num_updates=2540, lr=2.87937e-05, gnorm=3.152, clip=100, loss_scale=128, train_wall=40, gb_free=7.9, wall=10262
2023-05-08 02:47:41 - progress_bar.py[line:272] - INFO: epoch 003:    822 / 866 loss=2.425, loss_v1=0, loss_v2=0, nll_loss=1.23, ntokens=2092, nsentences=64, sample_size=2092, sample_size_v1=0, sample_size_v2=0, ppl=2.34, wps=521.7, ups=0.25, wpb=2092, bsz=64, num_updates=2550, lr=2.87814e-05, gnorm=3.491, clip=100, loss_scale=128, train_wall=40, gb_free=7.6, wall=10302
2023-05-08 02:48:21 - progress_bar.py[line:272] - INFO: epoch 003:    832 / 866 loss=2.42, loss_v1=0, loss_v2=0, nll_loss=1.223, ntokens=2219.9, nsentences=64, sample_size=2219.9, sample_size_v1=0, sample_size_v2=0, ppl=2.33, wps=544.7, ups=0.25, wpb=2219.9, bsz=64, num_updates=2560, lr=2.87691e-05, gnorm=3.354, clip=100, loss_scale=128, train_wall=41, gb_free=8.2, wall=10342
2023-05-08 02:49:01 - progress_bar.py[line:272] - INFO: epoch 003:    842 / 866 loss=2.423, loss_v1=0, loss_v2=0, nll_loss=1.226, ntokens=2113, nsentences=64, sample_size=2113, sample_size_v1=0, sample_size_v2=0, ppl=2.34, wps=526.9, ups=0.25, wpb=2113, bsz=64, num_updates=2570, lr=2.87569e-05, gnorm=3.358, clip=100, loss_scale=128, train_wall=40, gb_free=7.7, wall=10382
2023-05-08 02:49:42 - progress_bar.py[line:272] - INFO: epoch 003:    852 / 866 loss=2.415, loss_v1=0, loss_v2=0, nll_loss=1.22, ntokens=2190.2, nsentences=64, sample_size=2190.2, sample_size_v1=0, sample_size_v2=0, ppl=2.33, wps=543.1, ups=0.25, wpb=2190.2, bsz=64, num_updates=2580, lr=2.87446e-05, gnorm=3.424, clip=100, loss_scale=128, train_wall=40, gb_free=8.2, wall=10423
2023-05-08 02:50:22 - progress_bar.py[line:272] - INFO: epoch 003:    862 / 866 loss=2.44, loss_v1=0, loss_v2=0, nll_loss=1.245, ntokens=2026.6, nsentences=64, sample_size=2026.6, sample_size_v1=0, sample_size_v2=0, ppl=2.37, wps=506.4, ups=0.25, wpb=2026.6, bsz=64, num_updates=2590, lr=2.87323e-05, gnorm=3.573, clip=100, loss_scale=128, train_wall=40, gb_free=7.2, wall=10463
2023-05-08 02:50:36 - train.py[line:332] - INFO: end of epoch 3 (average epoch stats below)
local datafile ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 1 begin to initialize row_count and line_idx-to-offset mapping
2023-05-08 02:50:36 - progress_bar.py[line:282] - INFO: epoch 003 | loss 2.442 | loss_v1 0 | loss_v2 0 | nll_loss 1.248 | ntokens 2103.23 | nsentences 63.972 | sample_size 2103.23 | sample_size_v1 0 | sample_size_v2 0 | ppl 2.38 | wps 522.3 | ups 0.25 | wpb 2103.2 | bsz 64 | num_updates 2594 | lr 2.87274e-05 | gnorm 2.752 | clip 100 | loss_scale 128 | train_wall 3481 | gb_free 8.7 | wall 10477
2023-05-08 02:50:36 - trainer.py[line:639] - INFO: loading train data for epoch 4
local datafile ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 0 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 0 finished initializing row_count and line_idx-to-offset mapping
file ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 0 row count 27700 total row count 55400
slice_id 0 seek offset 0
2023-05-08 02:50:38 - trainer.py[line:703] - INFO: begin training epoch 4
2023-05-08 02:50:38 - train.py[line:305] - INFO: Start iterating over samples
local datafile ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 1 finished initializing row_count and line_idx-to-offset mapping
file ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 1 row count 27700 total row count 55400
slice_id 1 seek offset 27700
2023-05-08 02:50:46 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 128.0
2023-05-08 02:51:07 - progress_bar.py[line:272] - INFO: epoch 004:      7 / 866 loss=2.406, loss_v1=0, loss_v2=0, nll_loss=1.207, ntokens=2050.4, nsentences=61.6, sample_size=2050.4, sample_size_v1=0, sample_size_v2=0, ppl=2.31, wps=453.9, ups=0.22, wpb=2050.4, bsz=61.6, num_updates=2600, lr=2.872e-05, gnorm=3.851, clip=100, loss_scale=128, train_wall=43, gb_free=7.5, wall=10508
2023-05-08 02:51:48 - progress_bar.py[line:272] - INFO: epoch 004:     17 / 866 loss=2.364, loss_v1=0, loss_v2=0, nll_loss=1.16, ntokens=2075.1, nsentences=64, sample_size=2075.1, sample_size_v1=0, sample_size_v2=0, ppl=2.24, wps=509.3, ups=0.25, wpb=2075.1, bsz=64, num_updates=2610, lr=2.87077e-05, gnorm=4.103, clip=100, loss_scale=128, train_wall=41, gb_free=7.3, wall=10549
2023-05-08 02:52:28 - progress_bar.py[line:272] - INFO: epoch 004:     27 / 866 loss=2.399, loss_v1=0, loss_v2=0, nll_loss=1.199, ntokens=1975.4, nsentences=64, sample_size=1975.4, sample_size_v1=0, sample_size_v2=0, ppl=2.3, wps=489.2, ups=0.25, wpb=1975.4, bsz=64, num_updates=2620, lr=2.86954e-05, gnorm=3.765, clip=100, loss_scale=128, train_wall=40, gb_free=7.1, wall=10589
2023-05-08 02:53:09 - progress_bar.py[line:272] - INFO: epoch 004:     37 / 866 loss=2.303, loss_v1=0, loss_v2=0, nll_loss=1.094, ntokens=2214.8, nsentences=64, sample_size=2214.8, sample_size_v1=0, sample_size_v2=0, ppl=2.13, wps=542.9, ups=0.25, wpb=2214.8, bsz=64, num_updates=2630, lr=2.86832e-05, gnorm=3.023, clip=100, loss_scale=128, train_wall=41, gb_free=7.6, wall=10630
2023-05-08 02:53:49 - progress_bar.py[line:272] - INFO: epoch 004:     47 / 866 loss=2.366, loss_v1=0, loss_v2=0, nll_loss=1.163, ntokens=2012, nsentences=64, sample_size=2012, sample_size_v1=0, sample_size_v2=0, ppl=2.24, wps=498.7, ups=0.25, wpb=2012, bsz=64, num_updates=2640, lr=2.86709e-05, gnorm=4.148, clip=100, loss_scale=128, train_wall=40, gb_free=7, wall=10670
2023-05-08 02:54:30 - progress_bar.py[line:272] - INFO: epoch 004:     57 / 866 loss=2.293, loss_v1=0, loss_v2=0, nll_loss=1.082, ntokens=2065.2, nsentences=64, sample_size=2065.2, sample_size_v1=0, sample_size_v2=0, ppl=2.12, wps=511.3, ups=0.25, wpb=2065.2, bsz=64, num_updates=2650, lr=2.86586e-05, gnorm=3.414, clip=100, loss_scale=128, train_wall=40, gb_free=7.6, wall=10711
2023-05-08 02:55:11 - progress_bar.py[line:272] - INFO: epoch 004:     67 / 866 loss=2.219, loss_v1=0, loss_v2=0, nll_loss=0.998, ntokens=2385, nsentences=64, sample_size=2385, sample_size_v1=0, sample_size_v2=0, ppl=2, wps=573.9, ups=0.24, wpb=2385, bsz=64, num_updates=2660, lr=2.86463e-05, gnorm=2.532, clip=100, loss_scale=128, train_wall=42, gb_free=6.4, wall=10752
2023-05-08 02:55:53 - progress_bar.py[line:272] - INFO: epoch 004:     77 / 866 loss=2.305, loss_v1=0, loss_v2=0, nll_loss=1.093, ntokens=2320.6, nsentences=64, sample_size=2320.6, sample_size_v1=0, sample_size_v2=0, ppl=2.13, wps=560, ups=0.24, wpb=2320.6, bsz=64, num_updates=2670, lr=2.8634e-05, gnorm=3.369, clip=100, loss_scale=128, train_wall=41, gb_free=7.3, wall=10794
2023-05-08 02:56:01 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2023-05-08 02:56:38 - progress_bar.py[line:272] - INFO: epoch 004:     88 / 866 loss=2.364, loss_v1=0, loss_v2=0, nll_loss=1.162, ntokens=2150.3, nsentences=64, sample_size=2150.3, sample_size_v1=0, sample_size_v2=0, ppl=2.24, wps=478.2, ups=0.22, wpb=2150.3, bsz=64, num_updates=2680, lr=2.86217e-05, gnorm=3.703, clip=100, loss_scale=64, train_wall=45, gb_free=7.3, wall=10839
2023-05-08 02:57:18 - progress_bar.py[line:272] - INFO: epoch 004:     98 / 866 loss=2.339, loss_v1=0, loss_v2=0, nll_loss=1.134, ntokens=2150, nsentences=64, sample_size=2150, sample_size_v1=0, sample_size_v2=0, ppl=2.19, wps=529.4, ups=0.25, wpb=2150, bsz=64, num_updates=2690, lr=2.86095e-05, gnorm=3.784, clip=100, loss_scale=64, train_wall=41, gb_free=7.6, wall=10879
2023-05-08 02:57:58 - progress_bar.py[line:272] - INFO: epoch 004:    108 / 866 loss=2.432, loss_v1=0, loss_v2=0, nll_loss=1.238, ntokens=2012.3, nsentences=64, sample_size=2012.3, sample_size_v1=0, sample_size_v2=0, ppl=2.36, wps=502.2, ups=0.25, wpb=2012.3, bsz=64, num_updates=2700, lr=2.85972e-05, gnorm=3.946, clip=100, loss_scale=64, train_wall=40, gb_free=8.1, wall=10919
2023-05-08 02:58:39 - progress_bar.py[line:272] - INFO: epoch 004:    118 / 866 loss=2.419, loss_v1=0, loss_v2=0, nll_loss=1.221, ntokens=2123.2, nsentences=64, sample_size=2123.2, sample_size_v1=0, sample_size_v2=0, ppl=2.33, wps=521.2, ups=0.25, wpb=2123.2, bsz=64, num_updates=2710, lr=2.85849e-05, gnorm=3.201, clip=100, loss_scale=64, train_wall=41, gb_free=7.2, wall=10960
2023-05-08 02:59:20 - progress_bar.py[line:272] - INFO: epoch 004:    128 / 866 loss=2.392, loss_v1=0, loss_v2=0, nll_loss=1.192, ntokens=2216.2, nsentences=64, sample_size=2216.2, sample_size_v1=0, sample_size_v2=0, ppl=2.28, wps=538.3, ups=0.24, wpb=2216.2, bsz=64, num_updates=2720, lr=2.85726e-05, gnorm=3.198, clip=100, loss_scale=64, train_wall=41, gb_free=7.7, wall=11001
2023-05-08 03:00:01 - progress_bar.py[line:272] - INFO: epoch 004:    138 / 866 loss=2.373, loss_v1=0, loss_v2=0, nll_loss=1.172, ntokens=2223.9, nsentences=64, sample_size=2223.9, sample_size_v1=0, sample_size_v2=0, ppl=2.25, wps=542.6, ups=0.24, wpb=2223.9, bsz=64, num_updates=2730, lr=2.85603e-05, gnorm=2.991, clip=100, loss_scale=64, train_wall=41, gb_free=7.3, wall=11042
2023-05-08 03:00:42 - progress_bar.py[line:272] - INFO: epoch 004:    148 / 866 loss=2.352, loss_v1=0, loss_v2=0, nll_loss=1.148, ntokens=2202.7, nsentences=64, sample_size=2202.7, sample_size_v1=0, sample_size_v2=0, ppl=2.22, wps=532.8, ups=0.24, wpb=2202.7, bsz=64, num_updates=2740, lr=2.8548e-05, gnorm=2.956, clip=100, loss_scale=64, train_wall=41, gb_free=6.8, wall=11084
2023-05-08 03:01:24 - progress_bar.py[line:272] - INFO: epoch 004:    158 / 866 loss=2.382, loss_v1=0, loss_v2=0, nll_loss=1.18, ntokens=2218.6, nsentences=64, sample_size=2218.6, sample_size_v1=0, sample_size_v2=0, ppl=2.27, wps=533.3, ups=0.24, wpb=2218.6, bsz=64, num_updates=2750, lr=2.85357e-05, gnorm=3.346, clip=100, loss_scale=64, train_wall=42, gb_free=7.5, wall=11125
2023-05-08 03:02:05 - progress_bar.py[line:272] - INFO: epoch 004:    168 / 866 loss=2.375, loss_v1=0, loss_v2=0, nll_loss=1.173, ntokens=2127.3, nsentences=64, sample_size=2127.3, sample_size_v1=0, sample_size_v2=0, ppl=2.25, wps=524.3, ups=0.25, wpb=2127.3, bsz=64, num_updates=2760, lr=2.85235e-05, gnorm=3.112, clip=100, loss_scale=64, train_wall=41, gb_free=7.8, wall=11166
2023-05-08 03:02:45 - progress_bar.py[line:272] - INFO: epoch 004:    178 / 866 loss=2.368, loss_v1=0, loss_v2=0, nll_loss=1.163, ntokens=2069.7, nsentences=64, sample_size=2069.7, sample_size_v1=0, sample_size_v2=0, ppl=2.24, wps=510.2, ups=0.25, wpb=2069.7, bsz=64, num_updates=2770, lr=2.85112e-05, gnorm=3.606, clip=100, loss_scale=64, train_wall=41, gb_free=7.4, wall=11206
2023-05-08 03:03:26 - progress_bar.py[line:272] - INFO: epoch 004:    188 / 866 loss=2.355, loss_v1=0, loss_v2=0, nll_loss=1.153, ntokens=2227.8, nsentences=64, sample_size=2227.8, sample_size_v1=0, sample_size_v2=0, ppl=2.22, wps=542.9, ups=0.24, wpb=2227.8, bsz=64, num_updates=2780, lr=2.84989e-05, gnorm=3.458, clip=100, loss_scale=64, train_wall=41, gb_free=7.4, wall=11247
2023-05-08 03:04:07 - progress_bar.py[line:272] - INFO: epoch 004:    198 / 866 loss=2.379, loss_v1=0, loss_v2=0, nll_loss=1.176, ntokens=2162.5, nsentences=64, sample_size=2162.5, sample_size_v1=0, sample_size_v2=0, ppl=2.26, wps=528.6, ups=0.24, wpb=2162.5, bsz=64, num_updates=2790, lr=2.84866e-05, gnorm=3.561, clip=100, loss_scale=64, train_wall=41, gb_free=7.2, wall=11288
2023-05-08 03:04:47 - progress_bar.py[line:272] - INFO: epoch 004:    208 / 866 loss=2.434, loss_v1=0, loss_v2=0, nll_loss=1.237, ntokens=1967.7, nsentences=64, sample_size=1967.7, sample_size_v1=0, sample_size_v2=0, ppl=2.36, wps=490.6, ups=0.25, wpb=1967.7, bsz=64, num_updates=2800, lr=2.84743e-05, gnorm=3.915, clip=100, loss_scale=64, train_wall=40, gb_free=7.4, wall=11328
2023-05-08 03:05:28 - progress_bar.py[line:272] - INFO: epoch 004:    218 / 866 loss=2.438, loss_v1=0, loss_v2=0, nll_loss=1.245, ntokens=2200.8, nsentences=64, sample_size=2200.8, sample_size_v1=0, sample_size_v2=0, ppl=2.37, wps=546.8, ups=0.25, wpb=2200.8, bsz=64, num_updates=2810, lr=2.8462e-05, gnorm=3.635, clip=100, loss_scale=64, train_wall=40, gb_free=7.9, wall=11369
2023-05-08 03:06:08 - progress_bar.py[line:272] - INFO: epoch 004:    228 / 866 loss=2.429, loss_v1=0, loss_v2=0, nll_loss=1.232, ntokens=2165.7, nsentences=64, sample_size=2165.7, sample_size_v1=0, sample_size_v2=0, ppl=2.35, wps=539.8, ups=0.25, wpb=2165.7, bsz=64, num_updates=2820, lr=2.84498e-05, gnorm=3.708, clip=100, loss_scale=64, train_wall=40, gb_free=8, wall=11409
2023-05-08 03:06:48 - progress_bar.py[line:272] - INFO: epoch 004:    238 / 866 loss=2.455, loss_v1=0, loss_v2=0, nll_loss=1.264, ntokens=2129.1, nsentences=64, sample_size=2129.1, sample_size_v1=0, sample_size_v2=0, ppl=2.4, wps=531.2, ups=0.25, wpb=2129.1, bsz=64, num_updates=2830, lr=2.84375e-05, gnorm=3.894, clip=100, loss_scale=64, train_wall=40, gb_free=7.8, wall=11449
2023-05-08 03:07:28 - progress_bar.py[line:272] - INFO: epoch 004:    248 / 866 loss=2.432, loss_v1=0, loss_v2=0, nll_loss=1.238, ntokens=2173.3, nsentences=64, sample_size=2173.3, sample_size_v1=0, sample_size_v2=0, ppl=2.36, wps=537.9, ups=0.25, wpb=2173.3, bsz=64, num_updates=2840, lr=2.84252e-05, gnorm=3.863, clip=100, loss_scale=64, train_wall=40, gb_free=7.7, wall=11489
2023-05-08 03:08:08 - progress_bar.py[line:272] - INFO: epoch 004:    258 / 866 loss=2.441, loss_v1=0, loss_v2=0, nll_loss=1.247, ntokens=2109.7, nsentences=64, sample_size=2109.7, sample_size_v1=0, sample_size_v2=0, ppl=2.37, wps=526.4, ups=0.25, wpb=2109.7, bsz=64, num_updates=2850, lr=2.84129e-05, gnorm=3.589, clip=100, loss_scale=64, train_wall=40, gb_free=7.8, wall=11529
2023-05-08 03:08:48 - progress_bar.py[line:272] - INFO: epoch 004:    268 / 866 loss=2.443, loss_v1=0, loss_v2=0, nll_loss=1.248, ntokens=2130.6, nsentences=64, sample_size=2130.6, sample_size_v1=0, sample_size_v2=0, ppl=2.38, wps=530.8, ups=0.25, wpb=2130.6, bsz=64, num_updates=2860, lr=2.84006e-05, gnorm=4.112, clip=100, loss_scale=64, train_wall=40, gb_free=8, wall=11570
2023-05-08 03:09:29 - progress_bar.py[line:272] - INFO: epoch 004:    278 / 866 loss=2.434, loss_v1=0, loss_v2=0, nll_loss=1.241, ntokens=2172.4, nsentences=64, sample_size=2172.4, sample_size_v1=0, sample_size_v2=0, ppl=2.36, wps=539.4, ups=0.25, wpb=2172.4, bsz=64, num_updates=2870, lr=2.83883e-05, gnorm=4.079, clip=100, loss_scale=64, train_wall=40, gb_free=7.7, wall=11610
2023-05-08 03:10:09 - progress_bar.py[line:272] - INFO: epoch 004:    288 / 866 loss=2.42, loss_v1=0, loss_v2=0, nll_loss=1.223, ntokens=2196.8, nsentences=64, sample_size=2196.8, sample_size_v1=0, sample_size_v2=0, ppl=2.33, wps=545.5, ups=0.25, wpb=2196.8, bsz=64, num_updates=2880, lr=2.83761e-05, gnorm=3.863, clip=100, loss_scale=64, train_wall=40, gb_free=7.8, wall=11650
2023-05-08 03:10:49 - progress_bar.py[line:272] - INFO: epoch 004:    298 / 866 loss=2.423, loss_v1=0, loss_v2=0, nll_loss=1.227, ntokens=2080.1, nsentences=64, sample_size=2080.1, sample_size_v1=0, sample_size_v2=0, ppl=2.34, wps=515.2, ups=0.25, wpb=2080.1, bsz=64, num_updates=2890, lr=2.83638e-05, gnorm=4.274, clip=100, loss_scale=64, train_wall=40, gb_free=8.2, wall=11690
2023-05-08 03:11:29 - progress_bar.py[line:272] - INFO: epoch 004:    308 / 866 loss=2.426, loss_v1=0, loss_v2=0, nll_loss=1.232, ntokens=2155.7, nsentences=64, sample_size=2155.7, sample_size_v1=0, sample_size_v2=0, ppl=2.35, wps=537.1, ups=0.25, wpb=2155.7, bsz=64, num_updates=2900, lr=2.83515e-05, gnorm=4.328, clip=100, loss_scale=64, train_wall=40, gb_free=8.1, wall=11731
2023-05-08 03:12:09 - progress_bar.py[line:272] - INFO: epoch 004:    318 / 866 loss=2.429, loss_v1=0, loss_v2=0, nll_loss=1.232, ntokens=2007.1, nsentences=64, sample_size=2007.1, sample_size_v1=0, sample_size_v2=0, ppl=2.35, wps=501.6, ups=0.25, wpb=2007.1, bsz=64, num_updates=2910, lr=2.83392e-05, gnorm=4.469, clip=100, loss_scale=64, train_wall=40, gb_free=8.1, wall=11771
2023-05-08 03:12:49 - progress_bar.py[line:272] - INFO: epoch 004:    328 / 866 loss=2.455, loss_v1=0, loss_v2=0, nll_loss=1.264, ntokens=2043.2, nsentences=64, sample_size=2043.2, sample_size_v1=0, sample_size_v2=0, ppl=2.4, wps=512.7, ups=0.25, wpb=2043.2, bsz=64, num_updates=2920, lr=2.83269e-05, gnorm=4.859, clip=100, loss_scale=64, train_wall=40, gb_free=8, wall=11810
2023-05-08 03:13:30 - progress_bar.py[line:272] - INFO: epoch 004:    338 / 866 loss=2.4, loss_v1=0, loss_v2=0, nll_loss=1.199, ntokens=2147.1, nsentences=64, sample_size=2147.1, sample_size_v1=0, sample_size_v2=0, ppl=2.3, wps=533.4, ups=0.25, wpb=2147.1, bsz=64, num_updates=2930, lr=2.83146e-05, gnorm=4.454, clip=100, loss_scale=64, train_wall=40, gb_free=8, wall=11851
2023-05-08 03:14:09 - progress_bar.py[line:272] - INFO: epoch 004:    348 / 866 loss=2.427, loss_v1=0, loss_v2=0, nll_loss=1.234, ntokens=1910.8, nsentences=64, sample_size=1910.8, sample_size_v1=0, sample_size_v2=0, ppl=2.35, wps=481, ups=0.25, wpb=1910.8, bsz=64, num_updates=2940, lr=2.83024e-05, gnorm=4.77, clip=100, loss_scale=64, train_wall=40, gb_free=7.9, wall=11890
2023-05-08 03:14:49 - progress_bar.py[line:272] - INFO: epoch 004:    358 / 866 loss=2.452, loss_v1=0, loss_v2=0, nll_loss=1.258, ntokens=1995.2, nsentences=64, sample_size=1995.2, sample_size_v1=0, sample_size_v2=0, ppl=2.39, wps=501.4, ups=0.25, wpb=1995.2, bsz=64, num_updates=2950, lr=2.82901e-05, gnorm=4.883, clip=100, loss_scale=64, train_wall=40, gb_free=8.2, wall=11930
2023-05-08 03:15:29 - progress_bar.py[line:272] - INFO: epoch 004:    368 / 866 loss=2.435, loss_v1=0, loss_v2=0, nll_loss=1.24, ntokens=1984.4, nsentences=64, sample_size=1984.4, sample_size_v1=0, sample_size_v2=0, ppl=2.36, wps=498.3, ups=0.25, wpb=1984.4, bsz=64, num_updates=2960, lr=2.82778e-05, gnorm=4.766, clip=100, loss_scale=64, train_wall=40, gb_free=7.8, wall=11970
2023-05-08 03:16:09 - progress_bar.py[line:272] - INFO: epoch 004:    378 / 866 loss=2.416, loss_v1=0, loss_v2=0, nll_loss=1.221, ntokens=2113.8, nsentences=64, sample_size=2113.8, sample_size_v1=0, sample_size_v2=0, ppl=2.33, wps=527.1, ups=0.25, wpb=2113.8, bsz=64, num_updates=2970, lr=2.82655e-05, gnorm=4.413, clip=100, loss_scale=64, train_wall=40, gb_free=8.2, wall=12010
2023-05-08 03:16:49 - progress_bar.py[line:272] - INFO: epoch 004:    388 / 866 loss=2.404, loss_v1=0, loss_v2=0, nll_loss=1.204, ntokens=2138.6, nsentences=64, sample_size=2138.6, sample_size_v1=0, sample_size_v2=0, ppl=2.3, wps=534.6, ups=0.25, wpb=2138.6, bsz=64, num_updates=2980, lr=2.82532e-05, gnorm=4.142, clip=100, loss_scale=64, train_wall=40, gb_free=7.5, wall=12050
2023-05-08 03:17:29 - progress_bar.py[line:272] - INFO: epoch 004:    398 / 866 loss=2.439, loss_v1=0, loss_v2=0, nll_loss=1.246, ntokens=2064.6, nsentences=64, sample_size=2064.6, sample_size_v1=0, sample_size_v2=0, ppl=2.37, wps=515.6, ups=0.25, wpb=2064.6, bsz=64, num_updates=2990, lr=2.82409e-05, gnorm=4.729, clip=100, loss_scale=64, train_wall=40, gb_free=7.2, wall=12090
2023-05-08 03:18:09 - progress_bar.py[line:272] - INFO: epoch 004:    408 / 866 loss=2.424, loss_v1=0, loss_v2=0, nll_loss=1.228, ntokens=2069, nsentences=64, sample_size=2069, sample_size_v1=0, sample_size_v2=0, ppl=2.34, wps=518.3, ups=0.25, wpb=2069, bsz=64, num_updates=3000, lr=2.82286e-05, gnorm=4.502, clip=100, loss_scale=64, train_wall=40, gb_free=7.7, wall=12130
2023-05-08 03:18:49 - progress_bar.py[line:272] - INFO: epoch 004:    418 / 866 loss=2.408, loss_v1=0, loss_v2=0, nll_loss=1.21, ntokens=2098.3, nsentences=64, sample_size=2098.3, sample_size_v1=0, sample_size_v2=0, ppl=2.31, wps=523.5, ups=0.25, wpb=2098.3, bsz=64, num_updates=3010, lr=2.82164e-05, gnorm=4.167, clip=100, loss_scale=64, train_wall=40, gb_free=7.2, wall=12170
2023-05-08 03:19:29 - progress_bar.py[line:272] - INFO: epoch 004:    428 / 866 loss=2.4, loss_v1=0, loss_v2=0, nll_loss=1.203, ntokens=2110.8, nsentences=64, sample_size=2110.8, sample_size_v1=0, sample_size_v2=0, ppl=2.3, wps=525.6, ups=0.25, wpb=2110.8, bsz=64, num_updates=3020, lr=2.82041e-05, gnorm=4.311, clip=100, loss_scale=64, train_wall=40, gb_free=7.7, wall=12210
2023-05-08 03:20:09 - progress_bar.py[line:272] - INFO: epoch 004:    438 / 866 loss=2.431, loss_v1=0, loss_v2=0, nll_loss=1.234, ntokens=2124.1, nsentences=64, sample_size=2124.1, sample_size_v1=0, sample_size_v2=0, ppl=2.35, wps=528.9, ups=0.25, wpb=2124.1, bsz=64, num_updates=3030, lr=2.81918e-05, gnorm=4.45, clip=100, loss_scale=64, train_wall=40, gb_free=8, wall=12251
2023-05-08 03:20:50 - progress_bar.py[line:272] - INFO: epoch 004:    448 / 866 loss=2.446, loss_v1=0, loss_v2=0, nll_loss=1.253, ntokens=1996.8, nsentences=64, sample_size=1996.8, sample_size_v1=0, sample_size_v2=0, ppl=2.38, wps=496, ups=0.25, wpb=1996.8, bsz=64, num_updates=3040, lr=2.81795e-05, gnorm=5.527, clip=100, loss_scale=64, train_wall=40, gb_free=7.7, wall=12291
2023-05-08 03:21:30 - progress_bar.py[line:272] - INFO: epoch 004:    458 / 866 loss=2.415, loss_v1=0, loss_v2=0, nll_loss=1.217, ntokens=2079.8, nsentences=64, sample_size=2079.8, sample_size_v1=0, sample_size_v2=0, ppl=2.33, wps=515.1, ups=0.25, wpb=2079.8, bsz=64, num_updates=3050, lr=2.81672e-05, gnorm=4.754, clip=100, loss_scale=64, train_wall=40, gb_free=8, wall=12331
2023-05-08 03:22:10 - progress_bar.py[line:272] - INFO: epoch 004:    468 / 866 loss=2.413, loss_v1=0, loss_v2=0, nll_loss=1.217, ntokens=2164.7, nsentences=64, sample_size=2164.7, sample_size_v1=0, sample_size_v2=0, ppl=2.33, wps=536.4, ups=0.25, wpb=2164.7, bsz=64, num_updates=3060, lr=2.81549e-05, gnorm=4.469, clip=100, loss_scale=64, train_wall=40, gb_free=7.4, wall=12372
2023-05-08 03:22:51 - progress_bar.py[line:272] - INFO: epoch 004:    478 / 866 loss=2.428, loss_v1=0, loss_v2=0, nll_loss=1.232, ntokens=2220, nsentences=64, sample_size=2220, sample_size_v1=0, sample_size_v2=0, ppl=2.35, wps=547.1, ups=0.25, wpb=2220, bsz=64, num_updates=3070, lr=2.81427e-05, gnorm=4.838, clip=100, loss_scale=64, train_wall=41, gb_free=8, wall=12412
2023-05-08 03:23:31 - progress_bar.py[line:272] - INFO: epoch 004:    488 / 866 loss=2.406, loss_v1=0, loss_v2=0, nll_loss=1.207, ntokens=2033.8, nsentences=64, sample_size=2033.8, sample_size_v1=0, sample_size_v2=0, ppl=2.31, wps=507.2, ups=0.25, wpb=2033.8, bsz=64, num_updates=3080, lr=2.81304e-05, gnorm=4.965, clip=100, loss_scale=64, train_wall=40, gb_free=8.3, wall=12452
2023-05-08 03:24:11 - progress_bar.py[line:272] - INFO: epoch 004:    498 / 866 loss=2.402, loss_v1=0, loss_v2=0, nll_loss=1.204, ntokens=2069, nsentences=64, sample_size=2069, sample_size_v1=0, sample_size_v2=0, ppl=2.3, wps=515.8, ups=0.25, wpb=2069, bsz=64, num_updates=3090, lr=2.81181e-05, gnorm=4.765, clip=100, loss_scale=64, train_wall=40, gb_free=8.5, wall=12492
2023-05-08 03:24:51 - progress_bar.py[line:272] - INFO: epoch 004:    508 / 866 loss=2.435, loss_v1=0, loss_v2=0, nll_loss=1.241, ntokens=2115.2, nsentences=64, sample_size=2115.2, sample_size_v1=0, sample_size_v2=0, ppl=2.36, wps=528.6, ups=0.25, wpb=2115.2, bsz=64, num_updates=3100, lr=2.81058e-05, gnorm=4.647, clip=100, loss_scale=64, train_wall=40, gb_free=7.9, wall=12532
2023-05-08 03:25:31 - progress_bar.py[line:272] - INFO: epoch 004:    518 / 866 loss=2.423, loss_v1=0, loss_v2=0, nll_loss=1.226, ntokens=2197.1, nsentences=64, sample_size=2197.1, sample_size_v1=0, sample_size_v2=0, ppl=2.34, wps=548.1, ups=0.25, wpb=2197.1, bsz=64, num_updates=3110, lr=2.80935e-05, gnorm=4.731, clip=100, loss_scale=64, train_wall=40, gb_free=8.1, wall=12572
2023-05-08 03:26:11 - progress_bar.py[line:272] - INFO: epoch 004:    528 / 866 loss=2.42, loss_v1=0, loss_v2=0, nll_loss=1.225, ntokens=1974.3, nsentences=64, sample_size=1974.3, sample_size_v1=0, sample_size_v2=0, ppl=2.34, wps=497.4, ups=0.25, wpb=1974.3, bsz=64, num_updates=3120, lr=2.80812e-05, gnorm=5.597, clip=100, loss_scale=64, train_wall=40, gb_free=8.3, wall=12612
2023-05-08 03:26:51 - progress_bar.py[line:272] - INFO: epoch 004:    538 / 866 loss=2.402, loss_v1=0, loss_v2=0, nll_loss=1.205, ntokens=2123.8, nsentences=64, sample_size=2123.8, sample_size_v1=0, sample_size_v2=0, ppl=2.31, wps=530.5, ups=0.25, wpb=2123.8, bsz=64, num_updates=3130, lr=2.8069e-05, gnorm=4.216, clip=100, loss_scale=64, train_wall=40, gb_free=7.5, wall=12652
2023-05-08 03:27:32 - progress_bar.py[line:272] - INFO: epoch 004:    548 / 866 loss=2.432, loss_v1=0, loss_v2=0, nll_loss=1.237, ntokens=2308.9, nsentences=64, sample_size=2308.9, sample_size_v1=0, sample_size_v2=0, ppl=2.36, wps=571, ups=0.25, wpb=2308.9, bsz=64, num_updates=3140, lr=2.80567e-05, gnorm=4.007, clip=100, loss_scale=64, train_wall=40, gb_free=8.1, wall=12693
2023-05-08 03:28:12 - progress_bar.py[line:272] - INFO: epoch 004:    558 / 866 loss=2.422, loss_v1=0, loss_v2=0, nll_loss=1.226, ntokens=2284.3, nsentences=64, sample_size=2284.3, sample_size_v1=0, sample_size_v2=0, ppl=2.34, wps=564.5, ups=0.25, wpb=2284.3, bsz=64, num_updates=3150, lr=2.80444e-05, gnorm=4.618, clip=100, loss_scale=64, train_wall=40, gb_free=7.2, wall=12733
2023-05-08 03:28:52 - progress_bar.py[line:272] - INFO: epoch 004:    568 / 866 loss=2.425, loss_v1=0, loss_v2=0, nll_loss=1.229, ntokens=2217.8, nsentences=64, sample_size=2217.8, sample_size_v1=0, sample_size_v2=0, ppl=2.34, wps=552.7, ups=0.25, wpb=2217.8, bsz=64, num_updates=3160, lr=2.80321e-05, gnorm=4.3, clip=100, loss_scale=64, train_wall=40, gb_free=7.4, wall=12773
2023-05-08 03:29:32 - progress_bar.py[line:272] - INFO: epoch 004:    578 / 866 loss=2.424, loss_v1=0, loss_v2=0, nll_loss=1.228, ntokens=2124.1, nsentences=64, sample_size=2124.1, sample_size_v1=0, sample_size_v2=0, ppl=2.34, wps=529.1, ups=0.25, wpb=2124.1, bsz=64, num_updates=3170, lr=2.80198e-05, gnorm=4.595, clip=100, loss_scale=64, train_wall=40, gb_free=7.5, wall=12813
2023-05-08 03:30:13 - progress_bar.py[line:272] - INFO: epoch 004:    588 / 866 loss=2.432, loss_v1=0, loss_v2=0, nll_loss=1.236, ntokens=2074.5, nsentences=64, sample_size=2074.5, sample_size_v1=0, sample_size_v2=0, ppl=2.36, wps=513.2, ups=0.25, wpb=2074.5, bsz=64, num_updates=3180, lr=2.80075e-05, gnorm=4.3, clip=100, loss_scale=64, train_wall=40, gb_free=7.8, wall=12854
2023-05-08 03:30:41 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2023-05-08 03:30:57 - progress_bar.py[line:272] - INFO: epoch 004:    599 / 866 loss=2.381, loss_v1=0, loss_v2=0, nll_loss=1.183, ntokens=2126.5, nsentences=64, sample_size=2126.5, sample_size_v1=0, sample_size_v2=0, ppl=2.27, wps=481, ups=0.23, wpb=2126.5, bsz=64, num_updates=3190, lr=2.79953e-05, gnorm=5.054, clip=100, loss_scale=64, train_wall=44, gb_free=8.6, wall=12898
2023-05-08 03:31:37 - progress_bar.py[line:272] - INFO: epoch 004:    609 / 866 loss=2.416, loss_v1=0, loss_v2=0, nll_loss=1.219, ntokens=2007.2, nsentences=64, sample_size=2007.2, sample_size_v1=0, sample_size_v2=0, ppl=2.33, wps=500.4, ups=0.25, wpb=2007.2, bsz=64, num_updates=3200, lr=2.7983e-05, gnorm=4.424, clip=100, loss_scale=64, train_wall=40, gb_free=6.7, wall=12938
2023-05-08 03:32:17 - progress_bar.py[line:272] - INFO: epoch 004:    619 / 866 loss=2.441, loss_v1=0, loss_v2=0, nll_loss=1.246, ntokens=1950, nsentences=64, sample_size=1950, sample_size_v1=0, sample_size_v2=0, ppl=2.37, wps=488.8, ups=0.25, wpb=1950, bsz=64, num_updates=3210, lr=2.79707e-05, gnorm=5.227, clip=100, loss_scale=64, train_wall=40, gb_free=8.1, wall=12978
2023-05-08 03:32:57 - progress_bar.py[line:272] - INFO: epoch 004:    629 / 866 loss=2.404, loss_v1=0, loss_v2=0, nll_loss=1.207, ntokens=2034.9, nsentences=64, sample_size=2034.9, sample_size_v1=0, sample_size_v2=0, ppl=2.31, wps=509.1, ups=0.25, wpb=2034.9, bsz=64, num_updates=3220, lr=2.79584e-05, gnorm=5.347, clip=100, loss_scale=64, train_wall=40, gb_free=8.3, wall=13018
2023-05-08 03:33:37 - progress_bar.py[line:272] - INFO: epoch 004:    639 / 866 loss=2.393, loss_v1=0, loss_v2=0, nll_loss=1.195, ntokens=2084.2, nsentences=64, sample_size=2084.2, sample_size_v1=0, sample_size_v2=0, ppl=2.29, wps=520.2, ups=0.25, wpb=2084.2, bsz=64, num_updates=3230, lr=2.79461e-05, gnorm=5.027, clip=100, loss_scale=64, train_wall=40, gb_free=7.3, wall=13058
2023-05-08 03:34:17 - progress_bar.py[line:272] - INFO: epoch 004:    649 / 866 loss=2.432, loss_v1=0, loss_v2=0, nll_loss=1.236, ntokens=2024.1, nsentences=64, sample_size=2024.1, sample_size_v1=0, sample_size_v2=0, ppl=2.36, wps=509.9, ups=0.25, wpb=2024.1, bsz=64, num_updates=3240, lr=2.79338e-05, gnorm=4.996, clip=100, loss_scale=64, train_wall=40, gb_free=7.8, wall=13098
2023-05-08 03:34:56 - progress_bar.py[line:272] - INFO: epoch 004:    659 / 866 loss=2.447, loss_v1=0, loss_v2=0, nll_loss=1.254, ntokens=1897.3, nsentences=64, sample_size=1897.3, sample_size_v1=0, sample_size_v2=0, ppl=2.39, wps=477.5, ups=0.25, wpb=1897.3, bsz=64, num_updates=3250, lr=2.79215e-05, gnorm=5.349, clip=100, loss_scale=64, train_wall=40, gb_free=8.4, wall=13137
2023-05-08 03:35:36 - progress_bar.py[line:272] - INFO: epoch 004:    669 / 866 loss=2.429, loss_v1=0, loss_v2=0, nll_loss=1.233, ntokens=2007.8, nsentences=64, sample_size=2007.8, sample_size_v1=0, sample_size_v2=0, ppl=2.35, wps=500.9, ups=0.25, wpb=2007.8, bsz=64, num_updates=3260, lr=2.79093e-05, gnorm=5.14, clip=100, loss_scale=64, train_wall=40, gb_free=7.7, wall=13178
2023-05-08 03:36:16 - progress_bar.py[line:272] - INFO: epoch 004:    679 / 866 loss=2.408, loss_v1=0, loss_v2=0, nll_loss=1.208, ntokens=2082.9, nsentences=64, sample_size=2082.9, sample_size_v1=0, sample_size_v2=0, ppl=2.31, wps=521.5, ups=0.25, wpb=2082.9, bsz=64, num_updates=3270, lr=2.7897e-05, gnorm=4.674, clip=100, loss_scale=64, train_wall=40, gb_free=7.8, wall=13218
2023-05-08 03:36:56 - progress_bar.py[line:272] - INFO: epoch 004:    689 / 866 loss=2.41, loss_v1=0, loss_v2=0, nll_loss=1.215, ntokens=1992.1, nsentences=64, sample_size=1992.1, sample_size_v1=0, sample_size_v2=0, ppl=2.32, wps=499.6, ups=0.25, wpb=1992.1, bsz=64, num_updates=3280, lr=2.78847e-05, gnorm=5.418, clip=100, loss_scale=64, train_wall=40, gb_free=6.9, wall=13257
2023-05-08 03:37:36 - progress_bar.py[line:272] - INFO: epoch 004:    699 / 866 loss=2.427, loss_v1=0, loss_v2=0, nll_loss=1.23, ntokens=2100.7, nsentences=64, sample_size=2100.7, sample_size_v1=0, sample_size_v2=0, ppl=2.35, wps=524.1, ups=0.25, wpb=2100.7, bsz=64, num_updates=3290, lr=2.78724e-05, gnorm=5.071, clip=100, loss_scale=64, train_wall=40, gb_free=7.9, wall=13297
2023-05-08 03:38:16 - progress_bar.py[line:272] - INFO: epoch 004:    709 / 866 loss=2.424, loss_v1=0, loss_v2=0, nll_loss=1.228, ntokens=1973.5, nsentences=64, sample_size=1973.5, sample_size_v1=0, sample_size_v2=0, ppl=2.34, wps=494.1, ups=0.25, wpb=1973.5, bsz=64, num_updates=3300, lr=2.78601e-05, gnorm=5.353, clip=100, loss_scale=64, train_wall=40, gb_free=7.4, wall=13337
2023-05-08 03:38:56 - progress_bar.py[line:272] - INFO: epoch 004:    719 / 866 loss=2.428, loss_v1=0, loss_v2=0, nll_loss=1.233, ntokens=1906.9, nsentences=64, sample_size=1906.9, sample_size_v1=0, sample_size_v2=0, ppl=2.35, wps=477.6, ups=0.25, wpb=1906.9, bsz=64, num_updates=3310, lr=2.78478e-05, gnorm=5.627, clip=100, loss_scale=64, train_wall=40, gb_free=8.2, wall=13377
2023-05-08 03:39:37 - progress_bar.py[line:272] - INFO: epoch 004:    729 / 866 loss=2.392, loss_v1=0, loss_v2=0, nll_loss=1.193, ntokens=1992.3, nsentences=64, sample_size=1992.3, sample_size_v1=0, sample_size_v2=0, ppl=2.29, wps=493.7, ups=0.25, wpb=1992.3, bsz=64, num_updates=3320, lr=2.78356e-05, gnorm=5.208, clip=100, loss_scale=64, train_wall=40, gb_free=8.1, wall=13418
2023-05-08 03:40:17 - progress_bar.py[line:272] - INFO: epoch 004:    739 / 866 loss=2.396, loss_v1=0, loss_v2=0, nll_loss=1.197, ntokens=2108.6, nsentences=64, sample_size=2108.6, sample_size_v1=0, sample_size_v2=0, ppl=2.29, wps=527.1, ups=0.25, wpb=2108.6, bsz=64, num_updates=3330, lr=2.78233e-05, gnorm=5.081, clip=100, loss_scale=64, train_wall=40, gb_free=7.9, wall=13458
2023-05-08 03:40:57 - progress_bar.py[line:272] - INFO: epoch 004:    749 / 866 loss=2.378, loss_v1=0, loss_v2=0, nll_loss=1.177, ntokens=2148.5, nsentences=64, sample_size=2148.5, sample_size_v1=0, sample_size_v2=0, ppl=2.26, wps=534, ups=0.25, wpb=2148.5, bsz=64, num_updates=3340, lr=2.7811e-05, gnorm=5.09, clip=100, loss_scale=64, train_wall=40, gb_free=7.9, wall=13498
2023-05-08 03:41:37 - progress_bar.py[line:272] - INFO: epoch 004:    759 / 866 loss=2.404, loss_v1=0, loss_v2=0, nll_loss=1.207, ntokens=2034.8, nsentences=64, sample_size=2034.8, sample_size_v1=0, sample_size_v2=0, ppl=2.31, wps=509.5, ups=0.25, wpb=2034.8, bsz=64, num_updates=3350, lr=2.77987e-05, gnorm=5.101, clip=100, loss_scale=64, train_wall=40, gb_free=7.9, wall=13538
2023-05-08 03:42:17 - progress_bar.py[line:272] - INFO: epoch 004:    769 / 866 loss=2.398, loss_v1=0, loss_v2=0, nll_loss=1.199, ntokens=2112.7, nsentences=64, sample_size=2112.7, sample_size_v1=0, sample_size_v2=0, ppl=2.3, wps=528.4, ups=0.25, wpb=2112.7, bsz=64, num_updates=3360, lr=2.77864e-05, gnorm=5.031, clip=100, loss_scale=64, train_wall=40, gb_free=8.2, wall=13578
2023-05-08 03:42:57 - progress_bar.py[line:272] - INFO: epoch 004:    779 / 866 loss=2.382, loss_v1=0, loss_v2=0, nll_loss=1.178, ntokens=2311.6, nsentences=64, sample_size=2311.6, sample_size_v1=0, sample_size_v2=0, ppl=2.26, wps=572.7, ups=0.25, wpb=2311.6, bsz=64, num_updates=3370, lr=2.77741e-05, gnorm=4.381, clip=100, loss_scale=64, train_wall=40, gb_free=7.9, wall=13618
2023-05-08 03:43:37 - progress_bar.py[line:272] - INFO: epoch 004:    789 / 866 loss=2.418, loss_v1=0, loss_v2=0, nll_loss=1.223, ntokens=1956.5, nsentences=64, sample_size=1956.5, sample_size_v1=0, sample_size_v2=0, ppl=2.33, wps=491.9, ups=0.25, wpb=1956.5, bsz=64, num_updates=3380, lr=2.77619e-05, gnorm=5.101, clip=100, loss_scale=64, train_wall=40, gb_free=8.2, wall=13658
2023-05-08 03:44:17 - progress_bar.py[line:272] - INFO: epoch 004:    799 / 866 loss=2.415, loss_v1=0, loss_v2=0, nll_loss=1.216, ntokens=2067.5, nsentences=64, sample_size=2067.5, sample_size_v1=0, sample_size_v2=0, ppl=2.32, wps=518.8, ups=0.25, wpb=2067.5, bsz=64, num_updates=3390, lr=2.77496e-05, gnorm=4.536, clip=100, loss_scale=64, train_wall=40, gb_free=7.9, wall=13698
2023-05-08 03:44:57 - progress_bar.py[line:272] - INFO: epoch 004:    809 / 866 loss=2.39, loss_v1=0, loss_v2=0, nll_loss=1.192, ntokens=2011.6, nsentences=64, sample_size=2011.6, sample_size_v1=0, sample_size_v2=0, ppl=2.28, wps=504.3, ups=0.25, wpb=2011.6, bsz=64, num_updates=3400, lr=2.77373e-05, gnorm=5.113, clip=100, loss_scale=64, train_wall=40, gb_free=8.1, wall=13738
2023-05-08 03:45:37 - progress_bar.py[line:272] - INFO: epoch 004:    819 / 866 loss=2.391, loss_v1=0, loss_v2=0, nll_loss=1.191, ntokens=2062, nsentences=64, sample_size=2062, sample_size_v1=0, sample_size_v2=0, ppl=2.28, wps=514.2, ups=0.25, wpb=2062, bsz=64, num_updates=3410, lr=2.7725e-05, gnorm=4.665, clip=100, loss_scale=64, train_wall=40, gb_free=8.2, wall=13778
2023-05-08 03:46:18 - progress_bar.py[line:272] - INFO: epoch 004:    829 / 866 loss=2.394, loss_v1=0, loss_v2=0, nll_loss=1.194, ntokens=2180.5, nsentences=64, sample_size=2180.5, sample_size_v1=0, sample_size_v2=0, ppl=2.29, wps=535.3, ups=0.25, wpb=2180.5, bsz=64, num_updates=3420, lr=2.77127e-05, gnorm=4.627, clip=100, loss_scale=64, train_wall=41, gb_free=8.4, wall=13819
2023-05-08 03:46:58 - progress_bar.py[line:272] - INFO: epoch 004:    839 / 866 loss=2.402, loss_v1=0, loss_v2=0, nll_loss=1.205, ntokens=2134.9, nsentences=64, sample_size=2134.9, sample_size_v1=0, sample_size_v2=0, ppl=2.3, wps=528.1, ups=0.25, wpb=2134.9, bsz=64, num_updates=3430, lr=2.77004e-05, gnorm=4.758, clip=100, loss_scale=64, train_wall=40, gb_free=8.3, wall=13859
2023-05-08 03:47:38 - progress_bar.py[line:272] - INFO: epoch 004:    849 / 866 loss=2.39, loss_v1=0, loss_v2=0, nll_loss=1.19, ntokens=2218.6, nsentences=64, sample_size=2218.6, sample_size_v1=0, sample_size_v2=0, ppl=2.28, wps=550.8, ups=0.25, wpb=2218.6, bsz=64, num_updates=3440, lr=2.76882e-05, gnorm=4.37, clip=100, loss_scale=64, train_wall=40, gb_free=7.7, wall=13899
2023-05-08 03:48:18 - progress_bar.py[line:272] - INFO: epoch 004:    859 / 866 loss=2.403, loss_v1=0, loss_v2=0, nll_loss=1.205, ntokens=2042.9, nsentences=64, sample_size=2042.9, sample_size_v1=0, sample_size_v2=0, ppl=2.3, wps=509.2, ups=0.25, wpb=2042.9, bsz=64, num_updates=3450, lr=2.76759e-05, gnorm=4.864, clip=100, loss_scale=64, train_wall=40, gb_free=7.8, wall=13939
2023-05-08 03:48:45 - train.py[line:332] - INFO: end of epoch 4 (average epoch stats below)
local datafile ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 1 begin to initialize row_count and line_idx-to-offset mapping
2023-05-08 03:48:45 - progress_bar.py[line:282] - INFO: epoch 004 | loss 2.404 | loss_v1 0 | loss_v2 0 | nll_loss 1.206 | ntokens 2102.8 | nsentences 63.972 | sample_size 2102.8 | sample_size_v1 0 | sample_size_v2 0 | ppl 2.31 | wps 520.1 | ups 0.25 | wpb 2102.8 | bsz 64 | num_updates 3457 | lr 2.76673e-05 | gnorm 4.384 | clip 100 | loss_scale 64 | train_wall 3483 | gb_free 8.7 | wall 13966
2023-05-08 03:48:45 - trainer.py[line:639] - INFO: loading train data for epoch 5
local datafile ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 0 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 1 finished initializing row_count and line_idx-to-offset mapping
file ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 1 row count 27700 total row count 55400
slice_id 1 seek offset 27700
local datafile ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 0 finished initializing row_count and line_idx-to-offset mapping
file ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 0 row count 27700 total row count 55400
slice_id 0 seek offset 0
2023-05-08 03:48:47 - trainer.py[line:703] - INFO: begin training epoch 5
2023-05-08 03:48:47 - train.py[line:305] - INFO: Start iterating over samples
2023-05-08 03:49:00 - progress_bar.py[line:272] - INFO: epoch 005:      3 / 866 loss=2.417, loss_v1=0, loss_v2=0, nll_loss=1.218, ntokens=2095.2, nsentences=61.6, sample_size=2095.2, sample_size_v1=0, sample_size_v2=0, ppl=2.33, wps=505.9, ups=0.24, wpb=2095.2, bsz=61.6, num_updates=3460, lr=2.76636e-05, gnorm=5.398, clip=100, loss_scale=64, train_wall=39, gb_free=7.3, wall=13981
2023-05-08 03:49:40 - progress_bar.py[line:272] - INFO: epoch 005:     13 / 866 loss=2.353, loss_v1=0, loss_v2=0, nll_loss=1.15, ntokens=2047.5, nsentences=64, sample_size=2047.5, sample_size_v1=0, sample_size_v2=0, ppl=2.22, wps=507.5, ups=0.25, wpb=2047.5, bsz=64, num_updates=3470, lr=2.76513e-05, gnorm=4.845, clip=100, loss_scale=64, train_wall=40, gb_free=7.4, wall=14021
2023-05-08 03:50:21 - progress_bar.py[line:272] - INFO: epoch 005:     23 / 866 loss=2.331, loss_v1=0, loss_v2=0, nll_loss=1.122, ntokens=2054.4, nsentences=64, sample_size=2054.4, sample_size_v1=0, sample_size_v2=0, ppl=2.18, wps=508, ups=0.25, wpb=2054.4, bsz=64, num_updates=3480, lr=2.7639e-05, gnorm=4.758, clip=100, loss_scale=64, train_wall=40, gb_free=7.7, wall=14062
2023-05-08 03:51:01 - progress_bar.py[line:272] - INFO: epoch 005:     33 / 866 loss=2.32, loss_v1=0, loss_v2=0, nll_loss=1.111, ntokens=2091.8, nsentences=64, sample_size=2091.8, sample_size_v1=0, sample_size_v2=0, ppl=2.16, wps=515.7, ups=0.25, wpb=2091.8, bsz=64, num_updates=3490, lr=2.76267e-05, gnorm=4.238, clip=100, loss_scale=64, train_wall=41, gb_free=6.4, wall=14102
2023-05-08 03:51:42 - progress_bar.py[line:272] - INFO: epoch 005:     43 / 866 loss=2.294, loss_v1=0, loss_v2=0, nll_loss=1.084, ntokens=2128, nsentences=64, sample_size=2128, sample_size_v1=0, sample_size_v2=0, ppl=2.12, wps=522.7, ups=0.25, wpb=2128, bsz=64, num_updates=3500, lr=2.76144e-05, gnorm=4.74, clip=100, loss_scale=64, train_wall=41, gb_free=7.3, wall=14143
2023-05-08 03:52:22 - progress_bar.py[line:272] - INFO: epoch 005:     53 / 866 loss=2.352, loss_v1=0, loss_v2=0, nll_loss=1.146, ntokens=1987.1, nsentences=64, sample_size=1987.1, sample_size_v1=0, sample_size_v2=0, ppl=2.21, wps=491.8, ups=0.25, wpb=1987.1, bsz=64, num_updates=3510, lr=2.76022e-05, gnorm=5.651, clip=100, loss_scale=64, train_wall=40, gb_free=7.8, wall=14183
2023-05-08 03:53:03 - progress_bar.py[line:272] - INFO: epoch 005:     63 / 866 loss=2.198, loss_v1=0, loss_v2=0, nll_loss=0.976, ntokens=2273.9, nsentences=64, sample_size=2273.9, sample_size_v1=0, sample_size_v2=0, ppl=1.97, wps=555.7, ups=0.24, wpb=2273.9, bsz=64, num_updates=3520, lr=2.75899e-05, gnorm=3.575, clip=100, loss_scale=64, train_wall=41, gb_free=6.5, wall=14224
2023-05-08 03:53:45 - progress_bar.py[line:272] - INFO: epoch 005:     73 / 866 loss=2.263, loss_v1=0, loss_v2=0, nll_loss=1.046, ntokens=2436.8, nsentences=64, sample_size=2436.8, sample_size_v1=0, sample_size_v2=0, ppl=2.06, wps=585, ups=0.24, wpb=2436.8, bsz=64, num_updates=3530, lr=2.75776e-05, gnorm=3.889, clip=100, loss_scale=64, train_wall=42, gb_free=6.2, wall=14266
2023-05-08 03:54:26 - progress_bar.py[line:272] - INFO: epoch 005:     83 / 866 loss=2.31, loss_v1=0, loss_v2=0, nll_loss=1.101, ntokens=2209.4, nsentences=64, sample_size=2209.4, sample_size_v1=0, sample_size_v2=0, ppl=2.14, wps=537.2, ups=0.24, wpb=2209.4, bsz=64, num_updates=3540, lr=2.75653e-05, gnorm=5.04, clip=100, loss_scale=64, train_wall=41, gb_free=6.3, wall=14307
2023-05-08 03:55:07 - progress_bar.py[line:272] - INFO: epoch 005:     93 / 866 loss=2.292, loss_v1=0, loss_v2=0, nll_loss=1.08, ntokens=2158.2, nsentences=64, sample_size=2158.2, sample_size_v1=0, sample_size_v2=0, ppl=2.11, wps=530.5, ups=0.25, wpb=2158.2, bsz=64, num_updates=3550, lr=2.7553e-05, gnorm=4.169, clip=100, loss_scale=64, train_wall=41, gb_free=7.3, wall=14348
2023-05-08 03:55:47 - progress_bar.py[line:272] - INFO: epoch 005:    103 / 866 loss=2.393, loss_v1=0, loss_v2=0, nll_loss=1.196, ntokens=1999.5, nsentences=64, sample_size=1999.5, sample_size_v1=0, sample_size_v2=0, ppl=2.29, wps=497.2, ups=0.25, wpb=1999.5, bsz=64, num_updates=3560, lr=2.75407e-05, gnorm=5.449, clip=100, loss_scale=64, train_wall=40, gb_free=7.7, wall=14388
2023-05-08 03:56:27 - progress_bar.py[line:272] - INFO: epoch 005:    113 / 866 loss=2.403, loss_v1=0, loss_v2=0, nll_loss=1.203, ntokens=2058.9, nsentences=64, sample_size=2058.9, sample_size_v1=0, sample_size_v2=0, ppl=2.3, wps=508.5, ups=0.25, wpb=2058.9, bsz=64, num_updates=3570, lr=2.75285e-05, gnorm=4.122, clip=100, loss_scale=64, train_wall=40, gb_free=7, wall=14428
2023-05-08 03:57:08 - progress_bar.py[line:272] - INFO: epoch 005:    123 / 866 loss=2.386, loss_v1=0, loss_v2=0, nll_loss=1.186, ntokens=2201.6, nsentences=64, sample_size=2201.6, sample_size_v1=0, sample_size_v2=0, ppl=2.28, wps=536.7, ups=0.24, wpb=2201.6, bsz=64, num_updates=3580, lr=2.75162e-05, gnorm=4.228, clip=100, loss_scale=64, train_wall=41, gb_free=6.8, wall=14470
2023-05-08 03:57:49 - progress_bar.py[line:272] - INFO: epoch 005:    133 / 866 loss=2.352, loss_v1=0, loss_v2=0, nll_loss=1.146, ntokens=2208, nsentences=64, sample_size=2208, sample_size_v1=0, sample_size_v2=0, ppl=2.21, wps=538.6, ups=0.24, wpb=2208, bsz=64, num_updates=3590, lr=2.75039e-05, gnorm=4.046, clip=100, loss_scale=64, train_wall=41, gb_free=7.1, wall=14511
2023-05-08 03:58:31 - progress_bar.py[line:272] - INFO: epoch 005:    143 / 866 loss=2.345, loss_v1=0, loss_v2=0, nll_loss=1.142, ntokens=2264.9, nsentences=64, sample_size=2264.9, sample_size_v1=0, sample_size_v2=0, ppl=2.21, wps=546.2, ups=0.24, wpb=2264.9, bsz=64, num_updates=3600, lr=2.74916e-05, gnorm=4.226, clip=100, loss_scale=64, train_wall=41, gb_free=6.4, wall=14552
2023-05-08 03:59:12 - progress_bar.py[line:272] - INFO: epoch 005:    153 / 866 loss=2.347, loss_v1=0, loss_v2=0, nll_loss=1.142, ntokens=2165, nsentences=64, sample_size=2165, sample_size_v1=0, sample_size_v2=0, ppl=2.21, wps=525.4, ups=0.24, wpb=2165, bsz=64, num_updates=3610, lr=2.74793e-05, gnorm=4.279, clip=100, loss_scale=64, train_wall=41, gb_free=6.4, wall=14593
2023-05-08 03:59:53 - progress_bar.py[line:272] - INFO: epoch 005:    163 / 866 loss=2.353, loss_v1=0, loss_v2=0, nll_loss=1.149, ntokens=2159.1, nsentences=64, sample_size=2159.1, sample_size_v1=0, sample_size_v2=0, ppl=2.22, wps=529.6, ups=0.25, wpb=2159.1, bsz=64, num_updates=3620, lr=2.7467e-05, gnorm=4.79, clip=100, loss_scale=64, train_wall=41, gb_free=7.8, wall=14634
2023-05-08 04:00:33 - progress_bar.py[line:272] - INFO: epoch 005:    173 / 866 loss=2.369, loss_v1=0, loss_v2=0, nll_loss=1.165, ntokens=2040.6, nsentences=64, sample_size=2040.6, sample_size_v1=0, sample_size_v2=0, ppl=2.24, wps=506.3, ups=0.25, wpb=2040.6, bsz=64, num_updates=3630, lr=2.74548e-05, gnorm=4.654, clip=100, loss_scale=64, train_wall=40, gb_free=6.9, wall=14674
2023-05-08 04:01:14 - progress_bar.py[line:272] - INFO: epoch 005:    183 / 866 loss=2.324, loss_v1=0, loss_v2=0, nll_loss=1.118, ntokens=2201.4, nsentences=64, sample_size=2201.4, sample_size_v1=0, sample_size_v2=0, ppl=2.17, wps=535.5, ups=0.24, wpb=2201.4, bsz=64, num_updates=3640, lr=2.74425e-05, gnorm=4.668, clip=100, loss_scale=64, train_wall=41, gb_free=7.6, wall=14715
2023-05-08 04:01:55 - progress_bar.py[line:272] - INFO: epoch 005:    193 / 866 loss=2.346, loss_v1=0, loss_v2=0, nll_loss=1.139, ntokens=2205.9, nsentences=64, sample_size=2205.9, sample_size_v1=0, sample_size_v2=0, ppl=2.2, wps=538.8, ups=0.24, wpb=2205.9, bsz=64, num_updates=3650, lr=2.74302e-05, gnorm=4.226, clip=100, loss_scale=64, train_wall=41, gb_free=7.3, wall=14756
2023-05-08 04:02:36 - progress_bar.py[line:272] - INFO: epoch 005:    203 / 866 loss=2.389, loss_v1=0, loss_v2=0, nll_loss=1.189, ntokens=2075.5, nsentences=64, sample_size=2075.5, sample_size_v1=0, sample_size_v2=0, ppl=2.28, wps=511.2, ups=0.25, wpb=2075.5, bsz=64, num_updates=3660, lr=2.74179e-05, gnorm=4.754, clip=100, loss_scale=64, train_wall=41, gb_free=7.6, wall=14797
2023-05-08 04:03:16 - progress_bar.py[line:272] - INFO: epoch 005:    213 / 866 loss=2.412, loss_v1=0, loss_v2=0, nll_loss=1.214, ntokens=2063.9, nsentences=64, sample_size=2063.9, sample_size_v1=0, sample_size_v2=0, ppl=2.32, wps=512.6, ups=0.25, wpb=2063.9, bsz=64, num_updates=3670, lr=2.74056e-05, gnorm=4.498, clip=100, loss_scale=64, train_wall=40, gb_free=7.6, wall=14837
2023-05-08 04:03:56 - progress_bar.py[line:272] - INFO: epoch 005:    223 / 866 loss=2.399, loss_v1=0, loss_v2=0, nll_loss=1.202, ntokens=2222.1, nsentences=64, sample_size=2222.1, sample_size_v1=0, sample_size_v2=0, ppl=2.3, wps=552.7, ups=0.25, wpb=2222.1, bsz=64, num_updates=3680, lr=2.73933e-05, gnorm=4.747, clip=100, loss_scale=64, train_wall=40, gb_free=7.7, wall=14877
2023-05-08 04:04:36 - progress_bar.py[line:272] - INFO: epoch 005:    233 / 866 loss=2.432, loss_v1=0, loss_v2=0, nll_loss=1.236, ntokens=2107.2, nsentences=64, sample_size=2107.2, sample_size_v1=0, sample_size_v2=0, ppl=2.35, wps=526.8, ups=0.25, wpb=2107.2, bsz=64, num_updates=3690, lr=2.7381e-05, gnorm=4.501, clip=100, loss_scale=64, train_wall=40, gb_free=8.2, wall=14917
2023-05-08 04:05:17 - progress_bar.py[line:272] - INFO: epoch 005:    243 / 866 loss=2.416, loss_v1=0, loss_v2=0, nll_loss=1.221, ntokens=2185.9, nsentences=64, sample_size=2185.9, sample_size_v1=0, sample_size_v2=0, ppl=2.33, wps=540.8, ups=0.25, wpb=2185.9, bsz=64, num_updates=3700, lr=2.73688e-05, gnorm=4.378, clip=100, loss_scale=128, train_wall=40, gb_free=7.9, wall=14958
2023-05-08 04:05:57 - progress_bar.py[line:272] - INFO: epoch 005:    253 / 866 loss=2.421, loss_v1=0, loss_v2=0, nll_loss=1.225, ntokens=2123.8, nsentences=64, sample_size=2123.8, sample_size_v1=0, sample_size_v2=0, ppl=2.34, wps=525.2, ups=0.25, wpb=2123.8, bsz=64, num_updates=3710, lr=2.73565e-05, gnorm=4.65, clip=100, loss_scale=128, train_wall=40, gb_free=7.1, wall=14998
2023-05-08 04:06:17 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2023-05-08 04:06:41 - progress_bar.py[line:272] - INFO: epoch 005:    264 / 866 loss=2.422, loss_v1=0, loss_v2=0, nll_loss=1.226, ntokens=2149.6, nsentences=64, sample_size=2149.6, sample_size_v1=0, sample_size_v2=0, ppl=2.34, wps=487.3, ups=0.23, wpb=2149.6, bsz=64, num_updates=3720, lr=2.73442e-05, gnorm=4.754, clip=100, loss_scale=64, train_wall=44, gb_free=7, wall=15042
2023-05-08 04:07:22 - progress_bar.py[line:272] - INFO: epoch 005:    274 / 866 loss=2.415, loss_v1=0, loss_v2=0, nll_loss=1.219, ntokens=2135.8, nsentences=64, sample_size=2135.8, sample_size_v1=0, sample_size_v2=0, ppl=2.33, wps=530.8, ups=0.25, wpb=2135.8, bsz=64, num_updates=3730, lr=2.73319e-05, gnorm=4.857, clip=100, loss_scale=64, train_wall=40, gb_free=5.5, wall=15083
2023-05-08 04:08:02 - progress_bar.py[line:272] - INFO: epoch 005:    284 / 866 loss=2.416, loss_v1=0, loss_v2=0, nll_loss=1.218, ntokens=2152.8, nsentences=64, sample_size=2152.8, sample_size_v1=0, sample_size_v2=0, ppl=2.33, wps=534.3, ups=0.25, wpb=2152.8, bsz=64, num_updates=3740, lr=2.73196e-05, gnorm=4.941, clip=100, loss_scale=64, train_wall=40, gb_free=7.5, wall=15123
2023-05-08 04:08:42 - progress_bar.py[line:272] - INFO: epoch 005:    294 / 866 loss=2.394, loss_v1=0, loss_v2=0, nll_loss=1.195, ntokens=2143.4, nsentences=64, sample_size=2143.4, sample_size_v1=0, sample_size_v2=0, ppl=2.29, wps=530.8, ups=0.25, wpb=2143.4, bsz=64, num_updates=3750, lr=2.73073e-05, gnorm=5.219, clip=100, loss_scale=64, train_wall=40, gb_free=8, wall=15163
2023-05-08 04:09:22 - progress_bar.py[line:272] - INFO: epoch 005:    304 / 866 loss=2.405, loss_v1=0, loss_v2=0, nll_loss=1.207, ntokens=2147.4, nsentences=64, sample_size=2147.4, sample_size_v1=0, sample_size_v2=0, ppl=2.31, wps=534.5, ups=0.25, wpb=2147.4, bsz=64, num_updates=3760, lr=2.72951e-05, gnorm=5.011, clip=100, loss_scale=64, train_wall=40, gb_free=7.7, wall=15203
2023-05-08 04:10:02 - progress_bar.py[line:272] - INFO: epoch 005:    314 / 866 loss=2.397, loss_v1=0, loss_v2=0, nll_loss=1.197, ntokens=2051.3, nsentences=64, sample_size=2051.3, sample_size_v1=0, sample_size_v2=0, ppl=2.29, wps=513.9, ups=0.25, wpb=2051.3, bsz=64, num_updates=3770, lr=2.72828e-05, gnorm=5.204, clip=100, loss_scale=64, train_wall=40, gb_free=8.4, wall=15243
2023-05-08 04:10:42 - progress_bar.py[line:272] - INFO: epoch 005:    324 / 866 loss=2.428, loss_v1=0, loss_v2=0, nll_loss=1.233, ntokens=2017.8, nsentences=64, sample_size=2017.8, sample_size_v1=0, sample_size_v2=0, ppl=2.35, wps=504.9, ups=0.25, wpb=2017.8, bsz=64, num_updates=3780, lr=2.72705e-05, gnorm=5.184, clip=100, loss_scale=64, train_wall=40, gb_free=7.6, wall=15283
2023-05-08 04:11:22 - progress_bar.py[line:272] - INFO: epoch 005:    334 / 866 loss=2.403, loss_v1=0, loss_v2=0, nll_loss=1.203, ntokens=2125.2, nsentences=64, sample_size=2125.2, sample_size_v1=0, sample_size_v2=0, ppl=2.3, wps=531.4, ups=0.25, wpb=2125.2, bsz=64, num_updates=3790, lr=2.72582e-05, gnorm=5.085, clip=100, loss_scale=64, train_wall=40, gb_free=7.9, wall=15323
2023-05-08 04:12:02 - progress_bar.py[line:272] - INFO: epoch 005:    344 / 866 loss=2.388, loss_v1=0, loss_v2=0, nll_loss=1.19, ntokens=1996.4, nsentences=64, sample_size=1996.4, sample_size_v1=0, sample_size_v2=0, ppl=2.28, wps=498.2, ups=0.25, wpb=1996.4, bsz=64, num_updates=3800, lr=2.72459e-05, gnorm=5.243, clip=100, loss_scale=64, train_wall=40, gb_free=7.9, wall=15363
2023-05-08 04:12:42 - progress_bar.py[line:272] - INFO: epoch 005:    354 / 866 loss=2.432, loss_v1=0, loss_v2=0, nll_loss=1.235, ntokens=1992.2, nsentences=64, sample_size=1992.2, sample_size_v1=0, sample_size_v2=0, ppl=2.35, wps=501, ups=0.25, wpb=1992.2, bsz=64, num_updates=3810, lr=2.72336e-05, gnorm=5.337, clip=100, loss_scale=64, train_wall=40, gb_free=7.7, wall=15403
2023-05-08 04:13:22 - progress_bar.py[line:272] - INFO: epoch 005:    364 / 866 loss=2.426, loss_v1=0, loss_v2=0, nll_loss=1.231, ntokens=1966.7, nsentences=64, sample_size=1966.7, sample_size_v1=0, sample_size_v2=0, ppl=2.35, wps=494.9, ups=0.25, wpb=1966.7, bsz=64, num_updates=3820, lr=2.72214e-05, gnorm=5.186, clip=100, loss_scale=64, train_wall=40, gb_free=8.1, wall=15443
2023-05-08 04:14:02 - progress_bar.py[line:272] - INFO: epoch 005:    374 / 866 loss=2.399, loss_v1=0, loss_v2=0, nll_loss=1.2, ntokens=2086.7, nsentences=64, sample_size=2086.7, sample_size_v1=0, sample_size_v2=0, ppl=2.3, wps=521.8, ups=0.25, wpb=2086.7, bsz=64, num_updates=3830, lr=2.72091e-05, gnorm=5.358, clip=100, loss_scale=64, train_wall=40, gb_free=7.9, wall=15483
2023-05-08 04:14:42 - progress_bar.py[line:272] - INFO: epoch 005:    384 / 866 loss=2.399, loss_v1=0, loss_v2=0, nll_loss=1.2, ntokens=2129.5, nsentences=64, sample_size=2129.5, sample_size_v1=0, sample_size_v2=0, ppl=2.3, wps=531.5, ups=0.25, wpb=2129.5, bsz=64, num_updates=3840, lr=2.71968e-05, gnorm=4.691, clip=100, loss_scale=64, train_wall=40, gb_free=7.2, wall=15523
2023-05-08 04:15:22 - progress_bar.py[line:272] - INFO: epoch 005:    394 / 866 loss=2.401, loss_v1=0, loss_v2=0, nll_loss=1.202, ntokens=1995.2, nsentences=64, sample_size=1995.2, sample_size_v1=0, sample_size_v2=0, ppl=2.3, wps=500.3, ups=0.25, wpb=1995.2, bsz=64, num_updates=3850, lr=2.71845e-05, gnorm=5.311, clip=100, loss_scale=64, train_wall=40, gb_free=8.1, wall=15563
2023-05-08 04:16:02 - progress_bar.py[line:272] - INFO: epoch 005:    404 / 866 loss=2.402, loss_v1=0, loss_v2=0, nll_loss=1.204, ntokens=2131.8, nsentences=64, sample_size=2131.8, sample_size_v1=0, sample_size_v2=0, ppl=2.3, wps=531.2, ups=0.25, wpb=2131.8, bsz=64, num_updates=3860, lr=2.71722e-05, gnorm=4.792, clip=100, loss_scale=64, train_wall=40, gb_free=7.3, wall=15603
2023-05-08 04:16:42 - progress_bar.py[line:272] - INFO: epoch 005:    414 / 866 loss=2.399, loss_v1=0, loss_v2=0, nll_loss=1.2, ntokens=2133.5, nsentences=64, sample_size=2133.5, sample_size_v1=0, sample_size_v2=0, ppl=2.3, wps=532.1, ups=0.25, wpb=2133.5, bsz=64, num_updates=3870, lr=2.71599e-05, gnorm=5.008, clip=100, loss_scale=64, train_wall=40, gb_free=5.5, wall=15643
2023-05-08 04:17:22 - progress_bar.py[line:272] - INFO: epoch 005:    424 / 866 loss=2.389, loss_v1=0, loss_v2=0, nll_loss=1.19, ntokens=2063.4, nsentences=64, sample_size=2063.4, sample_size_v1=0, sample_size_v2=0, ppl=2.28, wps=511.3, ups=0.25, wpb=2063.4, bsz=64, num_updates=3880, lr=2.71477e-05, gnorm=4.745, clip=100, loss_scale=64, train_wall=40, gb_free=7.7, wall=15683
2023-05-08 04:18:02 - progress_bar.py[line:272] - INFO: epoch 005:    434 / 866 loss=2.397, loss_v1=0, loss_v2=0, nll_loss=1.196, ntokens=2107.9, nsentences=64, sample_size=2107.9, sample_size_v1=0, sample_size_v2=0, ppl=2.29, wps=526, ups=0.25, wpb=2107.9, bsz=64, num_updates=3890, lr=2.71354e-05, gnorm=5.084, clip=100, loss_scale=64, train_wall=40, gb_free=8.1, wall=15724
2023-05-08 04:18:43 - progress_bar.py[line:272] - INFO: epoch 005:    444 / 866 loss=2.433, loss_v1=0, loss_v2=0, nll_loss=1.239, ntokens=2030.8, nsentences=64, sample_size=2030.8, sample_size_v1=0, sample_size_v2=0, ppl=2.36, wps=505.5, ups=0.25, wpb=2030.8, bsz=64, num_updates=3900, lr=2.71231e-05, gnorm=5.748, clip=100, loss_scale=64, train_wall=40, gb_free=8.2, wall=15764
2023-05-08 04:19:23 - progress_bar.py[line:272] - INFO: epoch 005:    454 / 866 loss=2.404, loss_v1=0, loss_v2=0, nll_loss=1.206, ntokens=2015.3, nsentences=64, sample_size=2015.3, sample_size_v1=0, sample_size_v2=0, ppl=2.31, wps=504.1, ups=0.25, wpb=2015.3, bsz=64, num_updates=3910, lr=2.71108e-05, gnorm=6.433, clip=100, loss_scale=64, train_wall=40, gb_free=7.8, wall=15804
2023-05-08 04:20:03 - progress_bar.py[line:272] - INFO: epoch 005:    464 / 866 loss=2.399, loss_v1=0, loss_v2=0, nll_loss=1.2, ntokens=2171.2, nsentences=64, sample_size=2171.2, sample_size_v1=0, sample_size_v2=0, ppl=2.3, wps=539, ups=0.25, wpb=2171.2, bsz=64, num_updates=3920, lr=2.70985e-05, gnorm=4.578, clip=100, loss_scale=64, train_wall=40, gb_free=8, wall=15844
2023-05-08 04:20:43 - progress_bar.py[line:272] - INFO: epoch 005:    474 / 866 loss=2.406, loss_v1=0, loss_v2=0, nll_loss=1.208, ntokens=2208.2, nsentences=64, sample_size=2208.2, sample_size_v1=0, sample_size_v2=0, ppl=2.31, wps=546.9, ups=0.25, wpb=2208.2, bsz=64, num_updates=3930, lr=2.70862e-05, gnorm=5.12, clip=100, loss_scale=64, train_wall=40, gb_free=8.2, wall=15884
2023-05-08 04:21:23 - progress_bar.py[line:272] - INFO: epoch 005:    484 / 866 loss=2.4, loss_v1=0, loss_v2=0, nll_loss=1.201, ntokens=2144.3, nsentences=64, sample_size=2144.3, sample_size_v1=0, sample_size_v2=0, ppl=2.3, wps=533.5, ups=0.25, wpb=2144.3, bsz=64, num_updates=3940, lr=2.70739e-05, gnorm=4.928, clip=100, loss_scale=64, train_wall=40, gb_free=7.8, wall=15925
2023-05-08 04:22:04 - progress_bar.py[line:272] - INFO: epoch 005:    494 / 866 loss=2.386, loss_v1=0, loss_v2=0, nll_loss=1.186, ntokens=2045, nsentences=64, sample_size=2045, sample_size_v1=0, sample_size_v2=0, ppl=2.28, wps=509.3, ups=0.25, wpb=2045, bsz=64, num_updates=3950, lr=2.70617e-05, gnorm=5.272, clip=100, loss_scale=64, train_wall=40, gb_free=7.6, wall=15965
2023-05-08 04:22:44 - progress_bar.py[line:272] - INFO: epoch 005:    504 / 866 loss=2.409, loss_v1=0, loss_v2=0, nll_loss=1.212, ntokens=2073.9, nsentences=64, sample_size=2073.9, sample_size_v1=0, sample_size_v2=0, ppl=2.32, wps=518.3, ups=0.25, wpb=2073.9, bsz=64, num_updates=3960, lr=2.70494e-05, gnorm=5.337, clip=100, loss_scale=64, train_wall=40, gb_free=7.8, wall=16005
2023-05-08 04:23:24 - progress_bar.py[line:272] - INFO: epoch 005:    514 / 866 loss=2.422, loss_v1=0, loss_v2=0, nll_loss=1.224, ntokens=2170.7, nsentences=64, sample_size=2170.7, sample_size_v1=0, sample_size_v2=0, ppl=2.34, wps=543.9, ups=0.25, wpb=2170.7, bsz=64, num_updates=3970, lr=2.70371e-05, gnorm=5.503, clip=100, loss_scale=64, train_wall=40, gb_free=8.1, wall=16045
2023-05-08 04:24:03 - progress_bar.py[line:272] - INFO: epoch 005:    524 / 866 loss=2.393, loss_v1=0, loss_v2=0, nll_loss=1.194, ntokens=2105.4, nsentences=64, sample_size=2105.4, sample_size_v1=0, sample_size_v2=0, ppl=2.29, wps=528.4, ups=0.25, wpb=2105.4, bsz=64, num_updates=3980, lr=2.70248e-05, gnorm=5.286, clip=100, loss_scale=64, train_wall=40, gb_free=8, wall=16085
2023-05-08 04:24:43 - progress_bar.py[line:272] - INFO: epoch 005:    534 / 866 loss=2.385, loss_v1=0, loss_v2=0, nll_loss=1.186, ntokens=2042.8, nsentences=64, sample_size=2042.8, sample_size_v1=0, sample_size_v2=0, ppl=2.27, wps=511, ups=0.25, wpb=2042.8, bsz=64, num_updates=3990, lr=2.70125e-05, gnorm=5.718, clip=100, loss_scale=64, train_wall=40, gb_free=7.5, wall=16125
2023-05-08 04:25:23 - progress_bar.py[line:272] - INFO: epoch 005:    544 / 866 loss=2.412, loss_v1=0, loss_v2=0, nll_loss=1.215, ntokens=2184.6, nsentences=64, sample_size=2184.6, sample_size_v1=0, sample_size_v2=0, ppl=2.32, wps=545.3, ups=0.25, wpb=2184.6, bsz=64, num_updates=4000, lr=2.70002e-05, gnorm=4.796, clip=100, loss_scale=64, train_wall=40, gb_free=7.8, wall=16165
2023-05-08 04:26:04 - progress_bar.py[line:272] - INFO: epoch 005:    554 / 866 loss=2.417, loss_v1=0, loss_v2=0, nll_loss=1.22, ntokens=2311.7, nsentences=64, sample_size=2311.7, sample_size_v1=0, sample_size_v2=0, ppl=2.33, wps=570.2, ups=0.25, wpb=2311.7, bsz=64, num_updates=4010, lr=2.6988e-05, gnorm=4.801, clip=100, loss_scale=64, train_wall=40, gb_free=7.6, wall=16205
2023-05-08 04:26:44 - progress_bar.py[line:272] - INFO: epoch 005:    564 / 866 loss=2.396, loss_v1=0, loss_v2=0, nll_loss=1.195, ntokens=2250.1, nsentences=64, sample_size=2250.1, sample_size_v1=0, sample_size_v2=0, ppl=2.29, wps=556.2, ups=0.25, wpb=2250.1, bsz=64, num_updates=4020, lr=2.69757e-05, gnorm=4.988, clip=100, loss_scale=64, train_wall=40, gb_free=7.3, wall=16246
2023-05-08 04:27:25 - progress_bar.py[line:272] - INFO: epoch 005:    574 / 866 loss=2.408, loss_v1=0, loss_v2=0, nll_loss=1.21, ntokens=2186.6, nsentences=64, sample_size=2186.6, sample_size_v1=0, sample_size_v2=0, ppl=2.31, wps=542.3, ups=0.25, wpb=2186.6, bsz=64, num_updates=4030, lr=2.69634e-05, gnorm=5.091, clip=100, loss_scale=64, train_wall=40, gb_free=7.3, wall=16286
2023-05-08 04:28:05 - progress_bar.py[line:272] - INFO: epoch 005:    584 / 866 loss=2.413, loss_v1=0, loss_v2=0, nll_loss=1.215, ntokens=2097.5, nsentences=64, sample_size=2097.5, sample_size_v1=0, sample_size_v2=0, ppl=2.32, wps=523.2, ups=0.25, wpb=2097.5, bsz=64, num_updates=4040, lr=2.69511e-05, gnorm=4.983, clip=100, loss_scale=64, train_wall=40, gb_free=7, wall=16326
2023-05-08 04:28:45 - progress_bar.py[line:272] - INFO: epoch 005:    594 / 866 loss=2.383, loss_v1=0, loss_v2=0, nll_loss=1.183, ntokens=2123.3, nsentences=64, sample_size=2123.3, sample_size_v1=0, sample_size_v2=0, ppl=2.27, wps=526.7, ups=0.25, wpb=2123.3, bsz=64, num_updates=4050, lr=2.69388e-05, gnorm=5.412, clip=100, loss_scale=64, train_wall=40, gb_free=7.7, wall=16366
2023-05-08 04:29:25 - progress_bar.py[line:272] - INFO: epoch 005:    604 / 866 loss=2.385, loss_v1=0, loss_v2=0, nll_loss=1.186, ntokens=2066.5, nsentences=64, sample_size=2066.5, sample_size_v1=0, sample_size_v2=0, ppl=2.28, wps=514.4, ups=0.25, wpb=2066.5, bsz=64, num_updates=4060, lr=2.69265e-05, gnorm=5.037, clip=100, loss_scale=64, train_wall=40, gb_free=7.6, wall=16406
2023-05-08 04:30:05 - progress_bar.py[line:272] - INFO: epoch 005:    614 / 866 loss=2.416, loss_v1=0, loss_v2=0, nll_loss=1.217, ntokens=1920.8, nsentences=64, sample_size=1920.8, sample_size_v1=0, sample_size_v2=0, ppl=2.32, wps=480.4, ups=0.25, wpb=1920.8, bsz=64, num_updates=4070, lr=2.69143e-05, gnorm=5.054, clip=100, loss_scale=64, train_wall=40, gb_free=8, wall=16446
2023-05-08 04:30:45 - progress_bar.py[line:272] - INFO: epoch 005:    624 / 866 loss=2.407, loss_v1=0, loss_v2=0, nll_loss=1.209, ntokens=2039.6, nsentences=64, sample_size=2039.6, sample_size_v1=0, sample_size_v2=0, ppl=2.31, wps=509.5, ups=0.25, wpb=2039.6, bsz=64, num_updates=4080, lr=2.6902e-05, gnorm=5.199, clip=100, loss_scale=64, train_wall=40, gb_free=8.1, wall=16487
2023-05-08 04:31:25 - progress_bar.py[line:272] - INFO: epoch 005:    634 / 866 loss=2.387, loss_v1=0, loss_v2=0, nll_loss=1.187, ntokens=2012.5, nsentences=64, sample_size=2012.5, sample_size_v1=0, sample_size_v2=0, ppl=2.28, wps=505.7, ups=0.25, wpb=2012.5, bsz=64, num_updates=4090, lr=2.68897e-05, gnorm=5.301, clip=100, loss_scale=64, train_wall=40, gb_free=8.3, wall=16526
2023-05-08 04:32:05 - progress_bar.py[line:272] - INFO: epoch 005:    644 / 866 loss=2.389, loss_v1=0, loss_v2=0, nll_loss=1.19, ntokens=2085, nsentences=64, sample_size=2085, sample_size_v1=0, sample_size_v2=0, ppl=2.28, wps=523.4, ups=0.25, wpb=2085, bsz=64, num_updates=4100, lr=2.68774e-05, gnorm=5.201, clip=100, loss_scale=64, train_wall=40, gb_free=7.8, wall=16566
2023-05-08 04:32:45 - progress_bar.py[line:272] - INFO: epoch 005:    654 / 866 loss=2.423, loss_v1=0, loss_v2=0, nll_loss=1.225, ntokens=1951, nsentences=64, sample_size=1951, sample_size_v1=0, sample_size_v2=0, ppl=2.34, wps=490.3, ups=0.25, wpb=1951, bsz=64, num_updates=4110, lr=2.68651e-05, gnorm=5.606, clip=100, loss_scale=64, train_wall=40, gb_free=7.8, wall=16606
2023-05-08 04:33:25 - progress_bar.py[line:272] - INFO: epoch 005:    664 / 866 loss=2.421, loss_v1=0, loss_v2=0, nll_loss=1.224, ntokens=1940, nsentences=64, sample_size=1940, sample_size_v1=0, sample_size_v2=0, ppl=2.34, wps=488.4, ups=0.25, wpb=1940, bsz=64, num_updates=4120, lr=2.68528e-05, gnorm=5.638, clip=100, loss_scale=64, train_wall=40, gb_free=8.2, wall=16646
2023-05-08 04:34:05 - progress_bar.py[line:272] - INFO: epoch 005:    674 / 866 loss=2.405, loss_v1=0, loss_v2=0, nll_loss=1.206, ntokens=2070.8, nsentences=64, sample_size=2070.8, sample_size_v1=0, sample_size_v2=0, ppl=2.31, wps=517.3, ups=0.25, wpb=2070.8, bsz=64, num_updates=4130, lr=2.68406e-05, gnorm=4.994, clip=100, loss_scale=64, train_wall=40, gb_free=7.8, wall=16686
2023-05-08 04:34:44 - progress_bar.py[line:272] - INFO: epoch 005:    684 / 866 loss=2.386, loss_v1=0, loss_v2=0, nll_loss=1.187, ntokens=2040.2, nsentences=64, sample_size=2040.2, sample_size_v1=0, sample_size_v2=0, ppl=2.28, wps=512.6, ups=0.25, wpb=2040.2, bsz=64, num_updates=4140, lr=2.68283e-05, gnorm=5.374, clip=100, loss_scale=64, train_wall=40, gb_free=8.2, wall=16726
2023-05-08 04:35:25 - progress_bar.py[line:272] - INFO: epoch 005:    694 / 866 loss=2.407, loss_v1=0, loss_v2=0, nll_loss=1.209, ntokens=2072.2, nsentences=64, sample_size=2072.2, sample_size_v1=0, sample_size_v2=0, ppl=2.31, wps=516.7, ups=0.25, wpb=2072.2, bsz=64, num_updates=4150, lr=2.6816e-05, gnorm=5.094, clip=100, loss_scale=64, train_wall=40, gb_free=7.3, wall=16766
2023-05-08 04:36:05 - progress_bar.py[line:272] - INFO: epoch 005:    704 / 866 loss=2.409, loss_v1=0, loss_v2=0, nll_loss=1.21, ntokens=2017.9, nsentences=64, sample_size=2017.9, sample_size_v1=0, sample_size_v2=0, ppl=2.31, wps=501.8, ups=0.25, wpb=2017.9, bsz=64, num_updates=4160, lr=2.68037e-05, gnorm=5.385, clip=100, loss_scale=64, train_wall=40, gb_free=8.2, wall=16806
2023-05-08 04:36:44 - progress_bar.py[line:272] - INFO: epoch 005:    714 / 866 loss=2.43, loss_v1=0, loss_v2=0, nll_loss=1.236, ntokens=1871.5, nsentences=64, sample_size=1871.5, sample_size_v1=0, sample_size_v2=0, ppl=2.36, wps=470.5, ups=0.25, wpb=1871.5, bsz=64, num_updates=4170, lr=2.67914e-05, gnorm=6.474, clip=100, loss_scale=64, train_wall=40, gb_free=7.6, wall=16846
2023-05-08 04:37:25 - progress_bar.py[line:272] - INFO: epoch 005:    724 / 866 loss=2.384, loss_v1=0, loss_v2=0, nll_loss=1.184, ntokens=1998.5, nsentences=64, sample_size=1998.5, sample_size_v1=0, sample_size_v2=0, ppl=2.27, wps=497.9, ups=0.25, wpb=1998.5, bsz=64, num_updates=4180, lr=2.67791e-05, gnorm=5.577, clip=100, loss_scale=64, train_wall=40, gb_free=8.1, wall=16886
2023-05-08 04:38:05 - progress_bar.py[line:272] - INFO: epoch 005:    734 / 866 loss=2.383, loss_v1=0, loss_v2=0, nll_loss=1.182, ntokens=2017.8, nsentences=64, sample_size=2017.8, sample_size_v1=0, sample_size_v2=0, ppl=2.27, wps=505, ups=0.25, wpb=2017.8, bsz=64, num_updates=4190, lr=2.67668e-05, gnorm=5.55, clip=100, loss_scale=64, train_wall=40, gb_free=8, wall=16926
2023-05-08 04:38:45 - progress_bar.py[line:272] - INFO: epoch 005:    744 / 866 loss=2.369, loss_v1=0, loss_v2=0, nll_loss=1.164, ntokens=2152.2, nsentences=64, sample_size=2152.2, sample_size_v1=0, sample_size_v2=0, ppl=2.24, wps=536.7, ups=0.25, wpb=2152.2, bsz=64, num_updates=4200, lr=2.67546e-05, gnorm=5.335, clip=100, loss_scale=64, train_wall=40, gb_free=7.2, wall=16966
2023-05-08 04:39:25 - progress_bar.py[line:272] - INFO: epoch 005:    754 / 866 loss=2.373, loss_v1=0, loss_v2=0, nll_loss=1.173, ntokens=2102.9, nsentences=64, sample_size=2102.9, sample_size_v1=0, sample_size_v2=0, ppl=2.25, wps=524.5, ups=0.25, wpb=2102.9, bsz=64, num_updates=4210, lr=2.67423e-05, gnorm=5.63, clip=100, loss_scale=64, train_wall=40, gb_free=7.8, wall=17006
2023-05-08 04:40:05 - progress_bar.py[line:272] - INFO: epoch 005:    764 / 866 loss=2.39, loss_v1=0, loss_v2=0, nll_loss=1.191, ntokens=2112.8, nsentences=64, sample_size=2112.8, sample_size_v1=0, sample_size_v2=0, ppl=2.28, wps=526, ups=0.25, wpb=2112.8, bsz=64, num_updates=4220, lr=2.673e-05, gnorm=5.568, clip=100, loss_scale=64, train_wall=40, gb_free=8.2, wall=17046
2023-05-08 04:40:33 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2023-05-08 04:40:49 - progress_bar.py[line:272] - INFO: epoch 005:    775 / 866 loss=2.367, loss_v1=0, loss_v2=0, nll_loss=1.161, ntokens=2159.6, nsentences=64, sample_size=2159.6, sample_size_v1=0, sample_size_v2=0, ppl=2.24, wps=491.4, ups=0.23, wpb=2159.6, bsz=64, num_updates=4230, lr=2.67177e-05, gnorm=5.266, clip=100, loss_scale=64, train_wall=44, gb_free=7.9, wall=17090
2023-05-08 04:41:29 - progress_bar.py[line:272] - INFO: epoch 005:    785 / 866 loss=2.379, loss_v1=0, loss_v2=0, nll_loss=1.179, ntokens=2138.6, nsentences=64, sample_size=2138.6, sample_size_v1=0, sample_size_v2=0, ppl=2.26, wps=531.9, ups=0.25, wpb=2138.6, bsz=64, num_updates=4240, lr=2.67054e-05, gnorm=5.572, clip=100, loss_scale=64, train_wall=40, gb_free=7.5, wall=17130
2023-05-08 04:42:09 - progress_bar.py[line:272] - INFO: epoch 005:    795 / 866 loss=2.406, loss_v1=0, loss_v2=0, nll_loss=1.207, ntokens=2075.8, nsentences=64, sample_size=2075.8, sample_size_v1=0, sample_size_v2=0, ppl=2.31, wps=519.3, ups=0.25, wpb=2075.8, bsz=64, num_updates=4250, lr=2.66931e-05, gnorm=5.234, clip=100, loss_scale=64, train_wall=40, gb_free=7.5, wall=17170
2023-05-08 04:42:49 - progress_bar.py[line:272] - INFO: epoch 005:    805 / 866 loss=2.395, loss_v1=0, loss_v2=0, nll_loss=1.196, ntokens=1921.7, nsentences=64, sample_size=1921.7, sample_size_v1=0, sample_size_v2=0, ppl=2.29, wps=482.3, ups=0.25, wpb=1921.7, bsz=64, num_updates=4260, lr=2.66809e-05, gnorm=6.052, clip=100, loss_scale=64, train_wall=40, gb_free=7.5, wall=17210
2023-05-08 04:43:29 - progress_bar.py[line:272] - INFO: epoch 005:    815 / 866 loss=2.364, loss_v1=0, loss_v2=0, nll_loss=1.16, ntokens=2107.8, nsentences=64, sample_size=2107.8, sample_size_v1=0, sample_size_v2=0, ppl=2.23, wps=523.1, ups=0.25, wpb=2107.8, bsz=64, num_updates=4270, lr=2.66686e-05, gnorm=5.623, clip=100, loss_scale=64, train_wall=40, gb_free=8, wall=17250
2023-05-08 04:44:10 - progress_bar.py[line:272] - INFO: epoch 005:    825 / 866 loss=2.383, loss_v1=0, loss_v2=0, nll_loss=1.182, ntokens=2129.9, nsentences=64, sample_size=2129.9, sample_size_v1=0, sample_size_v2=0, ppl=2.27, wps=528, ups=0.25, wpb=2129.9, bsz=64, num_updates=4280, lr=2.66563e-05, gnorm=5.408, clip=100, loss_scale=64, train_wall=40, gb_free=8.3, wall=17291
2023-05-08 04:44:50 - progress_bar.py[line:272] - INFO: epoch 005:    835 / 866 loss=2.377, loss_v1=0, loss_v2=0, nll_loss=1.175, ntokens=2180.9, nsentences=64, sample_size=2180.9, sample_size_v1=0, sample_size_v2=0, ppl=2.26, wps=537, ups=0.25, wpb=2180.9, bsz=64, num_updates=4290, lr=2.6644e-05, gnorm=5.608, clip=100, loss_scale=64, train_wall=41, gb_free=8.1, wall=17331
2023-05-08 04:45:30 - progress_bar.py[line:272] - INFO: epoch 005:    845 / 866 loss=2.378, loss_v1=0, loss_v2=0, nll_loss=1.178, ntokens=2162.5, nsentences=64, sample_size=2162.5, sample_size_v1=0, sample_size_v2=0, ppl=2.26, wps=537.8, ups=0.25, wpb=2162.5, bsz=64, num_updates=4300, lr=2.66317e-05, gnorm=5.011, clip=100, loss_scale=64, train_wall=40, gb_free=7.5, wall=17372
2023-05-08 04:46:11 - progress_bar.py[line:272] - INFO: epoch 005:    855 / 866 loss=2.371, loss_v1=0, loss_v2=0, nll_loss=1.168, ntokens=2115.5, nsentences=64, sample_size=2115.5, sample_size_v1=0, sample_size_v2=0, ppl=2.25, wps=523.2, ups=0.25, wpb=2115.5, bsz=64, num_updates=4310, lr=2.66194e-05, gnorm=5.199, clip=100, loss_scale=64, train_wall=40, gb_free=8.3, wall=17412
2023-05-08 04:46:51 - progress_bar.py[line:272] - INFO: epoch 005:    865 / 866 loss=2.413, loss_v1=0, loss_v2=0, nll_loss=1.215, ntokens=2106.8, nsentences=64, sample_size=2106.8, sample_size_v1=0, sample_size_v2=0, ppl=2.32, wps=524.4, ups=0.25, wpb=2106.8, bsz=64, num_updates=4320, lr=2.66072e-05, gnorm=5.305, clip=100, loss_scale=64, train_wall=40, gb_free=7.8, wall=17452
2023-05-08 04:46:54 - train.py[line:332] - INFO: end of epoch 5 (average epoch stats below)
local datafile ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 1 begin to initialize row_count and line_idx-to-offset mapping
2023-05-08 04:46:54 - progress_bar.py[line:282] - INFO: epoch 005 | loss 2.385 | loss_v1 0 | loss_v2 0 | nll_loss 1.184 | ntokens 2103.3 | nsentences 63.972 | sample_size 2103.3 | sample_size_v1 0 | sample_size_v2 0 | ppl 2.27 | wps 520.9 | ups 0.25 | wpb 2103.3 | bsz 64 | num_updates 4321 | lr 2.66059e-05 | gnorm 5.058 | clip 100 | loss_scale 64 | train_wall 3482 | gb_free 8.7 | wall 17455
2023-05-08 04:46:54 - trainer.py[line:639] - INFO: loading train data for epoch 6
local datafile ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 0 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 1 finished initializing row_count and line_idx-to-offset mapping
file ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 1 row count 27700 total row count 55400
slice_id 1 seek offset 27700
local datafile ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 0 finished initializing row_count and line_idx-to-offset mapping
file ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 0 row count 27700 total row count 55400
slice_id 0 seek offset 0
2023-05-08 04:46:55 - trainer.py[line:703] - INFO: begin training epoch 6
2023-05-08 04:46:55 - train.py[line:305] - INFO: Start iterating over samples
2023-05-08 04:47:32 - progress_bar.py[line:272] - INFO: epoch 006:      9 / 866 loss=2.351, loss_v1=0, loss_v2=0, nll_loss=1.148, ntokens=2044, nsentences=61.6, sample_size=2044, sample_size_v1=0, sample_size_v2=0, ppl=2.22, wps=495.5, ups=0.24, wpb=2044, bsz=61.6, num_updates=4330, lr=2.65949e-05, gnorm=5.885, clip=100, loss_scale=64, train_wall=39, gb_free=7.2, wall=17493
2023-05-08 04:48:13 - progress_bar.py[line:272] - INFO: epoch 006:     19 / 866 loss=2.307, loss_v1=0, loss_v2=0, nll_loss=1.096, ntokens=2060.4, nsentences=64, sample_size=2060.4, sample_size_v1=0, sample_size_v2=0, ppl=2.14, wps=509.6, ups=0.25, wpb=2060.4, bsz=64, num_updates=4340, lr=2.65826e-05, gnorm=5.13, clip=100, loss_scale=64, train_wall=40, gb_free=7.7, wall=17534
2023-05-08 04:48:53 - progress_bar.py[line:272] - INFO: epoch 006:     29 / 866 loss=2.367, loss_v1=0, loss_v2=0, nll_loss=1.164, ntokens=1969, nsentences=64, sample_size=1969, sample_size_v1=0, sample_size_v2=0, ppl=2.24, wps=489.6, ups=0.25, wpb=1969, bsz=64, num_updates=4350, lr=2.65703e-05, gnorm=5.317, clip=100, loss_scale=64, train_wall=40, gb_free=7.6, wall=17574
2023-05-08 04:49:34 - progress_bar.py[line:272] - INFO: epoch 006:     39 / 866 loss=2.241, loss_v1=0, loss_v2=0, nll_loss=1.024, ntokens=2286.2, nsentences=64, sample_size=2286.2, sample_size_v1=0, sample_size_v2=0, ppl=2.03, wps=556.8, ups=0.24, wpb=2286.2, bsz=64, num_updates=4360, lr=2.6558e-05, gnorm=4.859, clip=100, loss_scale=64, train_wall=41, gb_free=6.6, wall=17615
2023-05-08 04:50:14 - progress_bar.py[line:272] - INFO: epoch 006:     49 / 866 loss=2.343, loss_v1=0, loss_v2=0, nll_loss=1.138, ntokens=1977.4, nsentences=64, sample_size=1977.4, sample_size_v1=0, sample_size_v2=0, ppl=2.2, wps=489.7, ups=0.25, wpb=1977.4, bsz=64, num_updates=4370, lr=2.65457e-05, gnorm=6.188, clip=100, loss_scale=64, train_wall=40, gb_free=7, wall=17656
2023-05-08 04:50:54 - progress_bar.py[line:272] - INFO: epoch 006:     59 / 866 loss=2.235, loss_v1=0, loss_v2=0, nll_loss=1.016, ntokens=2024.1, nsentences=64, sample_size=2024.1, sample_size_v1=0, sample_size_v2=0, ppl=2.02, wps=505.4, ups=0.25, wpb=2024.1, bsz=64, num_updates=4380, lr=2.65335e-05, gnorm=5.259, clip=100, loss_scale=64, train_wall=40, gb_free=7.7, wall=17696
2023-05-08 04:51:36 - progress_bar.py[line:272] - INFO: epoch 006:     69 / 866 loss=2.201, loss_v1=0, loss_v2=0, nll_loss=0.978, ntokens=2467.6, nsentences=64, sample_size=2467.6, sample_size_v1=0, sample_size_v2=0, ppl=1.97, wps=587.5, ups=0.24, wpb=2467.6, bsz=64, num_updates=4390, lr=2.65212e-05, gnorm=3.836, clip=100, loss_scale=64, train_wall=42, gb_free=7.1, wall=17738
2023-05-08 04:52:18 - progress_bar.py[line:272] - INFO: epoch 006:     79 / 866 loss=2.269, loss_v1=0, loss_v2=0, nll_loss=1.055, ntokens=2322.4, nsentences=64, sample_size=2322.4, sample_size_v1=0, sample_size_v2=0, ppl=2.08, wps=560.5, ups=0.24, wpb=2322.4, bsz=64, num_updates=4400, lr=2.65089e-05, gnorm=4.92, clip=100, loss_scale=64, train_wall=41, gb_free=6.5, wall=17779
2023-05-08 04:52:59 - progress_bar.py[line:272] - INFO: epoch 006:     89 / 866 loss=2.327, loss_v1=0, loss_v2=0, nll_loss=1.12, ntokens=2129.6, nsentences=64, sample_size=2129.6, sample_size_v1=0, sample_size_v2=0, ppl=2.17, wps=522.1, ups=0.25, wpb=2129.6, bsz=64, num_updates=4410, lr=2.64966e-05, gnorm=4.838, clip=100, loss_scale=64, train_wall=41, gb_free=6.1, wall=17820
2023-05-08 04:53:39 - progress_bar.py[line:272] - INFO: epoch 006:     99 / 866 loss=2.31, loss_v1=0, loss_v2=0, nll_loss=1.101, ntokens=2114.8, nsentences=64, sample_size=2114.8, sample_size_v1=0, sample_size_v2=0, ppl=2.15, wps=523, ups=0.25, wpb=2114.8, bsz=64, num_updates=4420, lr=2.64843e-05, gnorm=4.83, clip=100, loss_scale=64, train_wall=40, gb_free=8.2, wall=17860
2023-05-08 04:54:19 - progress_bar.py[line:272] - INFO: epoch 006:    109 / 866 loss=2.386, loss_v1=0, loss_v2=0, nll_loss=1.185, ntokens=2026.2, nsentences=64, sample_size=2026.2, sample_size_v1=0, sample_size_v2=0, ppl=2.27, wps=504.3, ups=0.25, wpb=2026.2, bsz=64, num_updates=4430, lr=2.6472e-05, gnorm=4.69, clip=100, loss_scale=64, train_wall=40, gb_free=7.9, wall=17900
2023-05-08 04:55:00 - progress_bar.py[line:272] - INFO: epoch 006:    119 / 866 loss=2.377, loss_v1=0, loss_v2=0, nll_loss=1.174, ntokens=2135.1, nsentences=64, sample_size=2135.1, sample_size_v1=0, sample_size_v2=0, ppl=2.26, wps=522.2, ups=0.24, wpb=2135.1, bsz=64, num_updates=4440, lr=2.64597e-05, gnorm=4.09, clip=100, loss_scale=64, train_wall=41, gb_free=6.4, wall=17941
2023-05-08 04:55:41 - progress_bar.py[line:272] - INFO: epoch 006:    129 / 866 loss=2.368, loss_v1=0, loss_v2=0, nll_loss=1.164, ntokens=2211.4, nsentences=64, sample_size=2211.4, sample_size_v1=0, sample_size_v2=0, ppl=2.24, wps=536, ups=0.24, wpb=2211.4, bsz=64, num_updates=4450, lr=2.64475e-05, gnorm=4.196, clip=100, loss_scale=64, train_wall=41, gb_free=6.9, wall=17983
2023-05-08 04:56:23 - progress_bar.py[line:272] - INFO: epoch 006:    139 / 866 loss=2.329, loss_v1=0, loss_v2=0, nll_loss=1.124, ntokens=2236.8, nsentences=64, sample_size=2236.8, sample_size_v1=0, sample_size_v2=0, ppl=2.18, wps=541.7, ups=0.24, wpb=2236.8, bsz=64, num_updates=4460, lr=2.64352e-05, gnorm=4.083, clip=100, loss_scale=64, train_wall=41, gb_free=6.5, wall=18024
2023-05-08 04:57:04 - progress_bar.py[line:272] - INFO: epoch 006:    149 / 866 loss=2.325, loss_v1=0, loss_v2=0, nll_loss=1.117, ntokens=2172.4, nsentences=64, sample_size=2172.4, sample_size_v1=0, sample_size_v2=0, ppl=2.17, wps=527.3, ups=0.24, wpb=2172.4, bsz=64, num_updates=4470, lr=2.64229e-05, gnorm=4.129, clip=100, loss_scale=64, train_wall=41, gb_free=6.5, wall=18065
2023-05-08 04:57:45 - progress_bar.py[line:272] - INFO: epoch 006:    159 / 866 loss=2.346, loss_v1=0, loss_v2=0, nll_loss=1.14, ntokens=2229.6, nsentences=64, sample_size=2229.6, sample_size_v1=0, sample_size_v2=0, ppl=2.2, wps=540.9, ups=0.24, wpb=2229.6, bsz=64, num_updates=4480, lr=2.64106e-05, gnorm=4.683, clip=100, loss_scale=64, train_wall=41, gb_free=7.6, wall=18106
2023-05-08 04:58:26 - progress_bar.py[line:272] - INFO: epoch 006:    169 / 866 loss=2.341, loss_v1=0, loss_v2=0, nll_loss=1.134, ntokens=2095.1, nsentences=64, sample_size=2095.1, sample_size_v1=0, sample_size_v2=0, ppl=2.2, wps=517.8, ups=0.25, wpb=2095.1, bsz=64, num_updates=4490, lr=2.63983e-05, gnorm=4.977, clip=100, loss_scale=64, train_wall=40, gb_free=7.6, wall=18147
2023-05-08 04:59:06 - progress_bar.py[line:272] - INFO: epoch 006:    179 / 866 loss=2.323, loss_v1=0, loss_v2=0, nll_loss=1.115, ntokens=2124.2, nsentences=64, sample_size=2124.2, sample_size_v1=0, sample_size_v2=0, ppl=2.17, wps=520.6, ups=0.25, wpb=2124.2, bsz=64, num_updates=4500, lr=2.6386e-05, gnorm=4.787, clip=100, loss_scale=64, train_wall=41, gb_free=6.8, wall=18188
2023-05-08 04:59:47 - progress_bar.py[line:272] - INFO: epoch 006:    189 / 866 loss=2.33, loss_v1=0, loss_v2=0, nll_loss=1.123, ntokens=2185.3, nsentences=64, sample_size=2185.3, sample_size_v1=0, sample_size_v2=0, ppl=2.18, wps=533.9, ups=0.24, wpb=2185.3, bsz=64, num_updates=4510, lr=2.63738e-05, gnorm=4.722, clip=100, loss_scale=64, train_wall=41, gb_free=7.8, wall=18229
2023-05-08 05:00:28 - progress_bar.py[line:272] - INFO: epoch 006:    199 / 866 loss=2.347, loss_v1=0, loss_v2=0, nll_loss=1.143, ntokens=2178.1, nsentences=64, sample_size=2178.1, sample_size_v1=0, sample_size_v2=0, ppl=2.21, wps=533, ups=0.24, wpb=2178.1, bsz=64, num_updates=4520, lr=2.63615e-05, gnorm=4.731, clip=100, loss_scale=64, train_wall=41, gb_free=7.9, wall=18269
2023-05-08 05:01:08 - progress_bar.py[line:272] - INFO: epoch 006:    209 / 866 loss=2.398, loss_v1=0, loss_v2=0, nll_loss=1.197, ntokens=1953.8, nsentences=64, sample_size=1953.8, sample_size_v1=0, sample_size_v2=0, ppl=2.29, wps=486.4, ups=0.25, wpb=1953.8, bsz=64, num_updates=4530, lr=2.63492e-05, gnorm=4.833, clip=100, loss_scale=64, train_wall=40, gb_free=6.5, wall=18310
2023-05-08 05:01:49 - progress_bar.py[line:272] - INFO: epoch 006:    219 / 866 loss=2.393, loss_v1=0, loss_v2=0, nll_loss=1.194, ntokens=2210.3, nsentences=64, sample_size=2210.3, sample_size_v1=0, sample_size_v2=0, ppl=2.29, wps=548.3, ups=0.25, wpb=2210.3, bsz=64, num_updates=4540, lr=2.63369e-05, gnorm=4.693, clip=100, loss_scale=64, train_wall=40, gb_free=7.6, wall=18350
2023-05-08 05:02:29 - progress_bar.py[line:272] - INFO: epoch 006:    229 / 866 loss=2.397, loss_v1=0, loss_v2=0, nll_loss=1.197, ntokens=2168.5, nsentences=64, sample_size=2168.5, sample_size_v1=0, sample_size_v2=0, ppl=2.29, wps=540.6, ups=0.25, wpb=2168.5, bsz=64, num_updates=4550, lr=2.63246e-05, gnorm=5.042, clip=100, loss_scale=64, train_wall=40, gb_free=8, wall=18390
2023-05-08 05:03:09 - progress_bar.py[line:272] - INFO: epoch 006:    239 / 866 loss=2.408, loss_v1=0, loss_v2=0, nll_loss=1.211, ntokens=2160.5, nsentences=64, sample_size=2160.5, sample_size_v1=0, sample_size_v2=0, ppl=2.31, wps=538.3, ups=0.25, wpb=2160.5, bsz=64, num_updates=4560, lr=2.63123e-05, gnorm=4.38, clip=100, loss_scale=64, train_wall=40, gb_free=7.1, wall=18430
2023-05-08 05:03:50 - progress_bar.py[line:272] - INFO: epoch 006:    249 / 866 loss=2.396, loss_v1=0, loss_v2=0, nll_loss=1.198, ntokens=2135.9, nsentences=64, sample_size=2135.9, sample_size_v1=0, sample_size_v2=0, ppl=2.29, wps=526.4, ups=0.25, wpb=2135.9, bsz=64, num_updates=4570, lr=2.63001e-05, gnorm=4.767, clip=100, loss_scale=64, train_wall=41, gb_free=7.5, wall=18471
2023-05-08 05:04:30 - progress_bar.py[line:272] - INFO: epoch 006:    259 / 866 loss=2.403, loss_v1=0, loss_v2=0, nll_loss=1.205, ntokens=2120, nsentences=64, sample_size=2120, sample_size_v1=0, sample_size_v2=0, ppl=2.31, wps=525.6, ups=0.25, wpb=2120, bsz=64, num_updates=4580, lr=2.62878e-05, gnorm=4.868, clip=100, loss_scale=64, train_wall=40, gb_free=7.4, wall=18511
2023-05-08 05:05:10 - progress_bar.py[line:272] - INFO: epoch 006:    269 / 866 loss=2.408, loss_v1=0, loss_v2=0, nll_loss=1.21, ntokens=2134.9, nsentences=64, sample_size=2134.9, sample_size_v1=0, sample_size_v2=0, ppl=2.31, wps=531.4, ups=0.25, wpb=2134.9, bsz=64, num_updates=4590, lr=2.62755e-05, gnorm=4.83, clip=100, loss_scale=64, train_wall=40, gb_free=7.3, wall=18551
2023-05-08 05:05:51 - progress_bar.py[line:272] - INFO: epoch 006:    279 / 866 loss=2.398, loss_v1=0, loss_v2=0, nll_loss=1.199, ntokens=2176.7, nsentences=64, sample_size=2176.7, sample_size_v1=0, sample_size_v2=0, ppl=2.3, wps=537.1, ups=0.25, wpb=2176.7, bsz=64, num_updates=4600, lr=2.62632e-05, gnorm=5.398, clip=100, loss_scale=64, train_wall=40, gb_free=7, wall=18592
2023-05-08 05:06:31 - progress_bar.py[line:272] - INFO: epoch 006:    289 / 866 loss=2.381, loss_v1=0, loss_v2=0, nll_loss=1.179, ntokens=2182.2, nsentences=64, sample_size=2182.2, sample_size_v1=0, sample_size_v2=0, ppl=2.26, wps=543.3, ups=0.25, wpb=2182.2, bsz=64, num_updates=4610, lr=2.62509e-05, gnorm=5.094, clip=100, loss_scale=64, train_wall=40, gb_free=8.3, wall=18632
2023-05-08 05:07:11 - progress_bar.py[line:272] - INFO: epoch 006:    299 / 866 loss=2.382, loss_v1=0, loss_v2=0, nll_loss=1.183, ntokens=2111.5, nsentences=64, sample_size=2111.5, sample_size_v1=0, sample_size_v2=0, ppl=2.27, wps=527, ups=0.25, wpb=2111.5, bsz=64, num_updates=4620, lr=2.62386e-05, gnorm=5.487, clip=100, loss_scale=64, train_wall=40, gb_free=7.4, wall=18672
2023-05-08 05:07:51 - progress_bar.py[line:272] - INFO: epoch 006:    309 / 866 loss=2.384, loss_v1=0, loss_v2=0, nll_loss=1.182, ntokens=2156.3, nsentences=64, sample_size=2156.3, sample_size_v1=0, sample_size_v2=0, ppl=2.27, wps=537.5, ups=0.25, wpb=2156.3, bsz=64, num_updates=4630, lr=2.62264e-05, gnorm=5.161, clip=100, loss_scale=64, train_wall=40, gb_free=7.6, wall=18712
2023-05-08 05:08:31 - progress_bar.py[line:272] - INFO: epoch 006:    319 / 866 loss=2.397, loss_v1=0, loss_v2=0, nll_loss=1.198, ntokens=1965.2, nsentences=64, sample_size=1965.2, sample_size_v1=0, sample_size_v2=0, ppl=2.29, wps=489.1, ups=0.25, wpb=1965.2, bsz=64, num_updates=4640, lr=2.62141e-05, gnorm=5.474, clip=100, loss_scale=64, train_wall=40, gb_free=8.1, wall=18752
2023-05-08 05:09:11 - progress_bar.py[line:272] - INFO: epoch 006:    329 / 866 loss=2.409, loss_v1=0, loss_v2=0, nll_loss=1.21, ntokens=2086.5, nsentences=64, sample_size=2086.5, sample_size_v1=0, sample_size_v2=0, ppl=2.31, wps=520, ups=0.25, wpb=2086.5, bsz=64, num_updates=4650, lr=2.62018e-05, gnorm=5.314, clip=100, loss_scale=64, train_wall=40, gb_free=7.6, wall=18792
2023-05-08 05:09:52 - progress_bar.py[line:272] - INFO: epoch 006:    339 / 866 loss=2.367, loss_v1=0, loss_v2=0, nll_loss=1.166, ntokens=2091.7, nsentences=64, sample_size=2091.7, sample_size_v1=0, sample_size_v2=0, ppl=2.24, wps=520.5, ups=0.25, wpb=2091.7, bsz=64, num_updates=4660, lr=2.61895e-05, gnorm=4.942, clip=100, loss_scale=64, train_wall=40, gb_free=8, wall=18833
2023-05-08 05:10:31 - progress_bar.py[line:272] - INFO: epoch 006:    349 / 866 loss=2.393, loss_v1=0, loss_v2=0, nll_loss=1.193, ntokens=1919.4, nsentences=64, sample_size=1919.4, sample_size_v1=0, sample_size_v2=0, ppl=2.29, wps=482.3, ups=0.25, wpb=1919.4, bsz=64, num_updates=4670, lr=2.61772e-05, gnorm=6.027, clip=100, loss_scale=64, train_wall=40, gb_free=7.9, wall=18872
2023-05-08 05:11:11 - progress_bar.py[line:272] - INFO: epoch 006:    359 / 866 loss=2.413, loss_v1=0, loss_v2=0, nll_loss=1.215, ntokens=1989.5, nsentences=64, sample_size=1989.5, sample_size_v1=0, sample_size_v2=0, ppl=2.32, wps=499.8, ups=0.25, wpb=1989.5, bsz=64, num_updates=4680, lr=2.61649e-05, gnorm=5.89, clip=100, loss_scale=64, train_wall=40, gb_free=7.7, wall=18912
2023-05-08 05:11:51 - progress_bar.py[line:272] - INFO: epoch 006:    369 / 866 loss=2.404, loss_v1=0, loss_v2=0, nll_loss=1.204, ntokens=1991.8, nsentences=64, sample_size=1991.8, sample_size_v1=0, sample_size_v2=0, ppl=2.3, wps=499.5, ups=0.25, wpb=1991.8, bsz=64, num_updates=4690, lr=2.61526e-05, gnorm=5.796, clip=100, loss_scale=64, train_wall=40, gb_free=8, wall=18952
2023-05-08 05:12:31 - progress_bar.py[line:272] - INFO: epoch 006:    379 / 866 loss=2.371, loss_v1=0, loss_v2=0, nll_loss=1.168, ntokens=2163.2, nsentences=64, sample_size=2163.2, sample_size_v1=0, sample_size_v2=0, ppl=2.25, wps=539.3, ups=0.25, wpb=2163.2, bsz=64, num_updates=4700, lr=2.61404e-05, gnorm=5.085, clip=100, loss_scale=64, train_wall=40, gb_free=7.3, wall=18992
2023-05-08 05:13:11 - progress_bar.py[line:272] - INFO: epoch 006:    389 / 866 loss=2.372, loss_v1=0, loss_v2=0, nll_loss=1.17, ntokens=2094.7, nsentences=64, sample_size=2094.7, sample_size_v1=0, sample_size_v2=0, ppl=2.25, wps=524.2, ups=0.25, wpb=2094.7, bsz=64, num_updates=4710, lr=2.61281e-05, gnorm=5.468, clip=100, loss_scale=64, train_wall=40, gb_free=8, wall=19032
2023-05-08 05:13:51 - progress_bar.py[line:272] - INFO: epoch 006:    399 / 866 loss=2.394, loss_v1=0, loss_v2=0, nll_loss=1.196, ntokens=2065.6, nsentences=64, sample_size=2065.6, sample_size_v1=0, sample_size_v2=0, ppl=2.29, wps=516.1, ups=0.25, wpb=2065.6, bsz=64, num_updates=4720, lr=2.61158e-05, gnorm=5.578, clip=100, loss_scale=64, train_wall=40, gb_free=8, wall=19072
2023-05-08 05:14:31 - progress_bar.py[line:272] - INFO: epoch 006:    409 / 866 loss=2.385, loss_v1=0, loss_v2=0, nll_loss=1.185, ntokens=2097.8, nsentences=64, sample_size=2097.8, sample_size_v1=0, sample_size_v2=0, ppl=2.27, wps=522.6, ups=0.25, wpb=2097.8, bsz=64, num_updates=4730, lr=2.61035e-05, gnorm=5.166, clip=100, loss_scale=64, train_wall=40, gb_free=7.9, wall=19112
2023-05-08 05:15:11 - progress_bar.py[line:272] - INFO: epoch 006:    419 / 866 loss=2.376, loss_v1=0, loss_v2=0, nll_loss=1.175, ntokens=2079.6, nsentences=64, sample_size=2079.6, sample_size_v1=0, sample_size_v2=0, ppl=2.26, wps=517.6, ups=0.25, wpb=2079.6, bsz=64, num_updates=4740, lr=2.60912e-05, gnorm=5.208, clip=100, loss_scale=128, train_wall=40, gb_free=7.5, wall=19153
2023-05-08 05:15:19 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2023-05-08 05:15:55 - progress_bar.py[line:272] - INFO: epoch 006:    430 / 866 loss=2.363, loss_v1=0, loss_v2=0, nll_loss=1.16, ntokens=2174.6, nsentences=64, sample_size=2174.6, sample_size_v1=0, sample_size_v2=0, ppl=2.23, wps=494.9, ups=0.23, wpb=2174.6, bsz=64, num_updates=4750, lr=2.60789e-05, gnorm=4.978, clip=100, loss_scale=64, train_wall=44, gb_free=7.6, wall=19196
2023-05-08 05:16:35 - progress_bar.py[line:272] - INFO: epoch 006:    440 / 866 loss=2.402, loss_v1=0, loss_v2=0, nll_loss=1.202, ntokens=2073.6, nsentences=64, sample_size=2073.6, sample_size_v1=0, sample_size_v2=0, ppl=2.3, wps=516.8, ups=0.25, wpb=2073.6, bsz=64, num_updates=4760, lr=2.60667e-05, gnorm=5.416, clip=100, loss_scale=64, train_wall=40, gb_free=8.1, wall=19237
2023-05-08 05:17:15 - progress_bar.py[line:272] - INFO: epoch 006:    450 / 866 loss=2.403, loss_v1=0, loss_v2=0, nll_loss=1.205, ntokens=1959.4, nsentences=64, sample_size=1959.4, sample_size_v1=0, sample_size_v2=0, ppl=2.31, wps=490.5, ups=0.25, wpb=1959.4, bsz=64, num_updates=4770, lr=2.60544e-05, gnorm=6.312, clip=100, loss_scale=64, train_wall=40, gb_free=8.2, wall=19277
2023-05-08 05:17:56 - progress_bar.py[line:272] - INFO: epoch 006:    460 / 866 loss=2.389, loss_v1=0, loss_v2=0, nll_loss=1.189, ntokens=2156, nsentences=64, sample_size=2156, sample_size_v1=0, sample_size_v2=0, ppl=2.28, wps=535.2, ups=0.25, wpb=2156, bsz=64, num_updates=4780, lr=2.60421e-05, gnorm=5.563, clip=100, loss_scale=64, train_wall=40, gb_free=8, wall=19317
2023-05-08 05:18:36 - progress_bar.py[line:272] - INFO: epoch 006:    470 / 866 loss=2.385, loss_v1=0, loss_v2=0, nll_loss=1.185, ntokens=2146.1, nsentences=64, sample_size=2146.1, sample_size_v1=0, sample_size_v2=0, ppl=2.27, wps=533.4, ups=0.25, wpb=2146.1, bsz=64, num_updates=4790, lr=2.60298e-05, gnorm=5.992, clip=100, loss_scale=64, train_wall=40, gb_free=7.9, wall=19357
2023-05-08 05:19:16 - progress_bar.py[line:272] - INFO: epoch 006:    480 / 866 loss=2.385, loss_v1=0, loss_v2=0, nll_loss=1.183, ntokens=2219.3, nsentences=64, sample_size=2219.3, sample_size_v1=0, sample_size_v2=0, ppl=2.27, wps=549.6, ups=0.25, wpb=2219.3, bsz=64, num_updates=4800, lr=2.60175e-05, gnorm=4.867, clip=100, loss_scale=64, train_wall=40, gb_free=6, wall=19397
2023-05-08 05:19:56 - progress_bar.py[line:272] - INFO: epoch 006:    490 / 866 loss=2.368, loss_v1=0, loss_v2=0, nll_loss=1.166, ntokens=2055.4, nsentences=64, sample_size=2055.4, sample_size_v1=0, sample_size_v2=0, ppl=2.24, wps=512.3, ups=0.25, wpb=2055.4, bsz=64, num_updates=4810, lr=2.60052e-05, gnorm=5.793, clip=100, loss_scale=64, train_wall=40, gb_free=6.7, wall=19438
2023-05-08 05:20:36 - progress_bar.py[line:272] - INFO: epoch 006:    500 / 866 loss=2.374, loss_v1=0, loss_v2=0, nll_loss=1.171, ntokens=2029.7, nsentences=64, sample_size=2029.7, sample_size_v1=0, sample_size_v2=0, ppl=2.25, wps=507.4, ups=0.25, wpb=2029.7, bsz=64, num_updates=4820, lr=2.5993e-05, gnorm=5.547, clip=100, loss_scale=64, train_wall=40, gb_free=7.8, wall=19478
2023-05-08 05:21:17 - progress_bar.py[line:272] - INFO: epoch 006:    510 / 866 loss=2.41, loss_v1=0, loss_v2=0, nll_loss=1.213, ntokens=2148.4, nsentences=64, sample_size=2148.4, sample_size_v1=0, sample_size_v2=0, ppl=2.32, wps=536.2, ups=0.25, wpb=2148.4, bsz=64, num_updates=4830, lr=2.59807e-05, gnorm=5.424, clip=100, loss_scale=64, train_wall=40, gb_free=7.2, wall=19518
2023-05-08 05:21:56 - progress_bar.py[line:272] - INFO: epoch 006:    520 / 866 loss=2.371, loss_v1=0, loss_v2=0, nll_loss=1.167, ntokens=2163.3, nsentences=64, sample_size=2163.3, sample_size_v1=0, sample_size_v2=0, ppl=2.25, wps=542, ups=0.25, wpb=2163.3, bsz=64, num_updates=4840, lr=2.59684e-05, gnorm=4.919, clip=100, loss_scale=64, train_wall=40, gb_free=8, wall=19558
2023-05-08 05:22:36 - progress_bar.py[line:272] - INFO: epoch 006:    530 / 866 loss=2.379, loss_v1=0, loss_v2=0, nll_loss=1.179, ntokens=1997, nsentences=64, sample_size=1997, sample_size_v1=0, sample_size_v2=0, ppl=2.26, wps=501.4, ups=0.25, wpb=1997, bsz=64, num_updates=4850, lr=2.59561e-05, gnorm=5.999, clip=100, loss_scale=64, train_wall=40, gb_free=7.8, wall=19597
2023-05-08 05:23:16 - progress_bar.py[line:272] - INFO: epoch 006:    540 / 866 loss=2.377, loss_v1=0, loss_v2=0, nll_loss=1.175, ntokens=2157.8, nsentences=64, sample_size=2157.8, sample_size_v1=0, sample_size_v2=0, ppl=2.26, wps=539.1, ups=0.25, wpb=2157.8, bsz=64, num_updates=4860, lr=2.59438e-05, gnorm=5.033, clip=100, loss_scale=64, train_wall=40, gb_free=8.3, wall=19637
2023-05-08 05:23:57 - progress_bar.py[line:272] - INFO: epoch 006:    550 / 866 loss=2.404, loss_v1=0, loss_v2=0, nll_loss=1.208, ntokens=2308.6, nsentences=64, sample_size=2308.6, sample_size_v1=0, sample_size_v2=0, ppl=2.31, wps=567.3, ups=0.25, wpb=2308.6, bsz=64, num_updates=4870, lr=2.59315e-05, gnorm=4.761, clip=100, loss_scale=64, train_wall=41, gb_free=7.1, wall=19678
2023-05-08 05:24:38 - progress_bar.py[line:272] - INFO: epoch 006:    560 / 866 loss=2.377, loss_v1=0, loss_v2=0, nll_loss=1.174, ntokens=2245.5, nsentences=64, sample_size=2245.5, sample_size_v1=0, sample_size_v2=0, ppl=2.26, wps=554, ups=0.25, wpb=2245.5, bsz=64, num_updates=4880, lr=2.59193e-05, gnorm=4.985, clip=100, loss_scale=64, train_wall=40, gb_free=8.2, wall=19719
2023-05-08 05:25:18 - progress_bar.py[line:272] - INFO: epoch 006:    570 / 866 loss=2.392, loss_v1=0, loss_v2=0, nll_loss=1.192, ntokens=2250.3, nsentences=64, sample_size=2250.3, sample_size_v1=0, sample_size_v2=0, ppl=2.28, wps=560.5, ups=0.25, wpb=2250.3, bsz=64, num_updates=4890, lr=2.5907e-05, gnorm=5.141, clip=100, loss_scale=64, train_wall=40, gb_free=7.6, wall=19759
2023-05-08 05:25:58 - progress_bar.py[line:272] - INFO: epoch 006:    580 / 866 loss=2.399, loss_v1=0, loss_v2=0, nll_loss=1.199, ntokens=2106.6, nsentences=64, sample_size=2106.6, sample_size_v1=0, sample_size_v2=0, ppl=2.3, wps=524.9, ups=0.25, wpb=2106.6, bsz=64, num_updates=4900, lr=2.58947e-05, gnorm=5.197, clip=100, loss_scale=64, train_wall=40, gb_free=7.4, wall=19799
2023-05-08 05:26:38 - progress_bar.py[line:272] - INFO: epoch 006:    590 / 866 loss=2.395, loss_v1=0, loss_v2=0, nll_loss=1.195, ntokens=2037.9, nsentences=64, sample_size=2037.9, sample_size_v1=0, sample_size_v2=0, ppl=2.29, wps=506.5, ups=0.25, wpb=2037.9, bsz=64, num_updates=4910, lr=2.58824e-05, gnorm=5.777, clip=100, loss_scale=64, train_wall=40, gb_free=8.5, wall=19839
2023-05-08 05:27:18 - progress_bar.py[line:272] - INFO: epoch 006:    600 / 866 loss=2.342, loss_v1=0, loss_v2=0, nll_loss=1.139, ntokens=2132.3, nsentences=64, sample_size=2132.3, sample_size_v1=0, sample_size_v2=0, ppl=2.2, wps=530.8, ups=0.25, wpb=2132.3, bsz=64, num_updates=4920, lr=2.58701e-05, gnorm=5.058, clip=100, loss_scale=64, train_wall=40, gb_free=7.6, wall=19879
2023-05-08 05:27:58 - progress_bar.py[line:272] - INFO: epoch 006:    610 / 866 loss=2.387, loss_v1=0, loss_v2=0, nll_loss=1.184, ntokens=2005.6, nsentences=64, sample_size=2005.6, sample_size_v1=0, sample_size_v2=0, ppl=2.27, wps=500.6, ups=0.25, wpb=2005.6, bsz=64, num_updates=4930, lr=2.58578e-05, gnorm=5.44, clip=100, loss_scale=64, train_wall=40, gb_free=8.2, wall=19919
2023-05-08 05:28:38 - progress_bar.py[line:272] - INFO: epoch 006:    620 / 866 loss=2.4, loss_v1=0, loss_v2=0, nll_loss=1.2, ntokens=1964.6, nsentences=64, sample_size=1964.6, sample_size_v1=0, sample_size_v2=0, ppl=2.3, wps=491.6, ups=0.25, wpb=1964.6, bsz=64, num_updates=4940, lr=2.58455e-05, gnorm=5.147, clip=100, loss_scale=64, train_wall=40, gb_free=8.3, wall=19959
2023-05-08 05:29:18 - progress_bar.py[line:272] - INFO: epoch 006:    630 / 866 loss=2.373, loss_v1=0, loss_v2=0, nll_loss=1.171, ntokens=2054.6, nsentences=64, sample_size=2054.6, sample_size_v1=0, sample_size_v2=0, ppl=2.25, wps=511.5, ups=0.25, wpb=2054.6, bsz=64, num_updates=4950, lr=2.58333e-05, gnorm=5.424, clip=100, loss_scale=64, train_wall=40, gb_free=7.7, wall=20000
2023-05-08 05:29:58 - progress_bar.py[line:272] - INFO: epoch 006:    640 / 866 loss=2.363, loss_v1=0, loss_v2=0, nll_loss=1.16, ntokens=2049.7, nsentences=64, sample_size=2049.7, sample_size_v1=0, sample_size_v2=0, ppl=2.23, wps=512.7, ups=0.25, wpb=2049.7, bsz=64, num_updates=4960, lr=2.5821e-05, gnorm=5.275, clip=100, loss_scale=64, train_wall=40, gb_free=7.3, wall=20040
2023-05-08 05:30:38 - progress_bar.py[line:272] - INFO: epoch 006:    650 / 866 loss=2.398, loss_v1=0, loss_v2=0, nll_loss=1.197, ntokens=2026.3, nsentences=64, sample_size=2026.3, sample_size_v1=0, sample_size_v2=0, ppl=2.29, wps=510.9, ups=0.25, wpb=2026.3, bsz=64, num_updates=4970, lr=2.58087e-05, gnorm=5.398, clip=100, loss_scale=64, train_wall=40, gb_free=7.5, wall=20079
2023-05-08 05:31:18 - progress_bar.py[line:272] - INFO: epoch 006:    660 / 866 loss=2.416, loss_v1=0, loss_v2=0, nll_loss=1.221, ntokens=1918, nsentences=64, sample_size=1918, sample_size_v1=0, sample_size_v2=0, ppl=2.33, wps=482, ups=0.25, wpb=1918, bsz=64, num_updates=4980, lr=2.57964e-05, gnorm=5.907, clip=100, loss_scale=64, train_wall=40, gb_free=8.3, wall=20119
2023-05-08 05:31:58 - progress_bar.py[line:272] - INFO: epoch 006:    670 / 866 loss=2.388, loss_v1=0, loss_v2=0, nll_loss=1.186, ntokens=1996.5, nsentences=64, sample_size=1996.5, sample_size_v1=0, sample_size_v2=0, ppl=2.27, wps=498.3, ups=0.25, wpb=1996.5, bsz=64, num_updates=4990, lr=2.57841e-05, gnorm=5.541, clip=100, loss_scale=64, train_wall=40, gb_free=7.8, wall=20159
2023-05-08 05:32:38 - progress_bar.py[line:272] - INFO: epoch 006:    680 / 866 loss=2.367, loss_v1=0, loss_v2=0, nll_loss=1.165, ntokens=2076.1, nsentences=64, sample_size=2076.1, sample_size_v1=0, sample_size_v2=0, ppl=2.24, wps=521, ups=0.25, wpb=2076.1, bsz=64, num_updates=5000, lr=2.57718e-05, gnorm=5.473, clip=100, loss_scale=64, train_wall=40, gb_free=7.5, wall=20199
2023-05-08 05:33:18 - progress_bar.py[line:272] - INFO: epoch 006:    690 / 866 loss=2.376, loss_v1=0, loss_v2=0, nll_loss=1.175, ntokens=2026.9, nsentences=64, sample_size=2026.9, sample_size_v1=0, sample_size_v2=0, ppl=2.26, wps=505.2, ups=0.25, wpb=2026.9, bsz=64, num_updates=5010, lr=2.57596e-05, gnorm=5.568, clip=100, loss_scale=64, train_wall=40, gb_free=6.8, wall=20239
2023-05-08 05:33:58 - progress_bar.py[line:272] - INFO: epoch 006:    700 / 866 loss=2.394, loss_v1=0, loss_v2=0, nll_loss=1.192, ntokens=2087, nsentences=64, sample_size=2087, sample_size_v1=0, sample_size_v2=0, ppl=2.28, wps=520.9, ups=0.25, wpb=2087, bsz=64, num_updates=5020, lr=2.57473e-05, gnorm=5.151, clip=100, loss_scale=64, train_wall=40, gb_free=8, wall=20279
2023-05-08 05:34:38 - progress_bar.py[line:272] - INFO: epoch 006:    710 / 866 loss=2.4, loss_v1=0, loss_v2=0, nll_loss=1.202, ntokens=1923.4, nsentences=64, sample_size=1923.4, sample_size_v1=0, sample_size_v2=0, ppl=2.3, wps=479.5, ups=0.25, wpb=1923.4, bsz=64, num_updates=5030, lr=2.5735e-05, gnorm=5.899, clip=100, loss_scale=64, train_wall=40, gb_free=7.6, wall=20319
2023-05-08 05:35:18 - progress_bar.py[line:272] - INFO: epoch 006:    720 / 866 loss=2.391, loss_v1=0, loss_v2=0, nll_loss=1.19, ntokens=1913.9, nsentences=64, sample_size=1913.9, sample_size_v1=0, sample_size_v2=0, ppl=2.28, wps=479.4, ups=0.25, wpb=1913.9, bsz=64, num_updates=5040, lr=2.57227e-05, gnorm=5.663, clip=100, loss_scale=64, train_wall=40, gb_free=7.2, wall=20359
2023-05-08 05:35:58 - progress_bar.py[line:272] - INFO: epoch 006:    730 / 866 loss=2.354, loss_v1=0, loss_v2=0, nll_loss=1.149, ntokens=2011.1, nsentences=64, sample_size=2011.1, sample_size_v1=0, sample_size_v2=0, ppl=2.22, wps=505.3, ups=0.25, wpb=2011.1, bsz=64, num_updates=5050, lr=2.57104e-05, gnorm=5.602, clip=100, loss_scale=64, train_wall=40, gb_free=8.2, wall=20399
2023-05-08 05:36:38 - progress_bar.py[line:272] - INFO: epoch 006:    740 / 866 loss=2.373, loss_v1=0, loss_v2=0, nll_loss=1.17, ntokens=2124.3, nsentences=64, sample_size=2124.3, sample_size_v1=0, sample_size_v2=0, ppl=2.25, wps=529.2, ups=0.25, wpb=2124.3, bsz=64, num_updates=5060, lr=2.56981e-05, gnorm=5.373, clip=100, loss_scale=64, train_wall=40, gb_free=7.7, wall=20439
2023-05-08 05:37:18 - progress_bar.py[line:272] - INFO: epoch 006:    750 / 866 loss=2.345, loss_v1=0, loss_v2=0, nll_loss=1.14, ntokens=2131.9, nsentences=64, sample_size=2131.9, sample_size_v1=0, sample_size_v2=0, ppl=2.2, wps=530.6, ups=0.25, wpb=2131.9, bsz=64, num_updates=5070, lr=2.56859e-05, gnorm=5.458, clip=100, loss_scale=64, train_wall=40, gb_free=8, wall=20479
2023-05-08 05:37:58 - progress_bar.py[line:272] - INFO: epoch 006:    760 / 866 loss=2.367, loss_v1=0, loss_v2=0, nll_loss=1.165, ntokens=2080.6, nsentences=64, sample_size=2080.6, sample_size_v1=0, sample_size_v2=0, ppl=2.24, wps=518.5, ups=0.25, wpb=2080.6, bsz=64, num_updates=5080, lr=2.56736e-05, gnorm=5.375, clip=100, loss_scale=64, train_wall=40, gb_free=7.6, wall=20519
2023-05-08 05:38:38 - progress_bar.py[line:272] - INFO: epoch 006:    770 / 866 loss=2.357, loss_v1=0, loss_v2=0, nll_loss=1.153, ntokens=2072.8, nsentences=64, sample_size=2072.8, sample_size_v1=0, sample_size_v2=0, ppl=2.22, wps=518.6, ups=0.25, wpb=2072.8, bsz=64, num_updates=5090, lr=2.56613e-05, gnorm=5.348, clip=100, loss_scale=64, train_wall=40, gb_free=8.3, wall=20559
2023-05-08 05:39:19 - progress_bar.py[line:272] - INFO: epoch 006:    780 / 866 loss=2.35, loss_v1=0, loss_v2=0, nll_loss=1.144, ntokens=2340.3, nsentences=64, sample_size=2340.3, sample_size_v1=0, sample_size_v2=0, ppl=2.21, wps=578.3, ups=0.25, wpb=2340.3, bsz=64, num_updates=5100, lr=2.5649e-05, gnorm=5.059, clip=100, loss_scale=64, train_wall=40, gb_free=7.7, wall=20600
2023-05-08 05:39:59 - progress_bar.py[line:272] - INFO: epoch 006:    790 / 866 loss=2.384, loss_v1=0, loss_v2=0, nll_loss=1.184, ntokens=1961, nsentences=64, sample_size=1961, sample_size_v1=0, sample_size_v2=0, ppl=2.27, wps=492.9, ups=0.25, wpb=1961, bsz=64, num_updates=5110, lr=2.56367e-05, gnorm=5.715, clip=100, loss_scale=64, train_wall=40, gb_free=7.2, wall=20640
2023-05-08 05:40:39 - progress_bar.py[line:272] - INFO: epoch 006:    800 / 866 loss=2.388, loss_v1=0, loss_v2=0, nll_loss=1.186, ntokens=2027.5, nsentences=64, sample_size=2027.5, sample_size_v1=0, sample_size_v2=0, ppl=2.28, wps=507.9, ups=0.25, wpb=2027.5, bsz=64, num_updates=5120, lr=2.56244e-05, gnorm=5.451, clip=100, loss_scale=64, train_wall=40, gb_free=8.1, wall=20680
2023-05-08 05:41:18 - progress_bar.py[line:272] - INFO: epoch 006:    810 / 866 loss=2.347, loss_v1=0, loss_v2=0, nll_loss=1.142, ntokens=2021.4, nsentences=64, sample_size=2021.4, sample_size_v1=0, sample_size_v2=0, ppl=2.21, wps=507, ups=0.25, wpb=2021.4, bsz=64, num_updates=5130, lr=2.56122e-05, gnorm=5.658, clip=100, loss_scale=64, train_wall=40, gb_free=7.8, wall=20719
2023-05-08 05:41:58 - progress_bar.py[line:272] - INFO: epoch 006:    820 / 866 loss=2.353, loss_v1=0, loss_v2=0, nll_loss=1.149, ntokens=2070, nsentences=64, sample_size=2070, sample_size_v1=0, sample_size_v2=0, ppl=2.22, wps=516.8, ups=0.25, wpb=2070, bsz=64, num_updates=5140, lr=2.55999e-05, gnorm=5.141, clip=100, loss_scale=64, train_wall=40, gb_free=7.8, wall=20760
2023-05-08 05:42:39 - progress_bar.py[line:272] - INFO: epoch 006:    830 / 866 loss=2.361, loss_v1=0, loss_v2=0, nll_loss=1.156, ntokens=2200.4, nsentences=64, sample_size=2200.4, sample_size_v1=0, sample_size_v2=0, ppl=2.23, wps=540, ups=0.25, wpb=2200.4, bsz=64, num_updates=5150, lr=2.55876e-05, gnorm=5.059, clip=100, loss_scale=64, train_wall=41, gb_free=8, wall=20800
2023-05-08 05:43:20 - progress_bar.py[line:272] - INFO: epoch 006:    840 / 866 loss=2.374, loss_v1=0, loss_v2=0, nll_loss=1.173, ntokens=2111.9, nsentences=64, sample_size=2111.9, sample_size_v1=0, sample_size_v2=0, ppl=2.25, wps=521.8, ups=0.25, wpb=2111.9, bsz=64, num_updates=5160, lr=2.55753e-05, gnorm=5.615, clip=100, loss_scale=64, train_wall=40, gb_free=7.6, wall=20841
2023-05-08 05:44:00 - progress_bar.py[line:272] - INFO: epoch 006:    850 / 866 loss=2.359, loss_v1=0, loss_v2=0, nll_loss=1.155, ntokens=2216.5, nsentences=64, sample_size=2216.5, sample_size_v1=0, sample_size_v2=0, ppl=2.23, wps=547.7, ups=0.25, wpb=2216.5, bsz=64, num_updates=5170, lr=2.5563e-05, gnorm=5.103, clip=100, loss_scale=64, train_wall=40, gb_free=8.1, wall=20881
2023-05-08 05:44:40 - progress_bar.py[line:272] - INFO: epoch 006:    860 / 866 loss=2.367, loss_v1=0, loss_v2=0, nll_loss=1.163, ntokens=2044.3, nsentences=64, sample_size=2044.3, sample_size_v1=0, sample_size_v2=0, ppl=2.24, wps=511.2, ups=0.25, wpb=2044.3, bsz=64, num_updates=5180, lr=2.55507e-05, gnorm=5.471, clip=100, loss_scale=64, train_wall=40, gb_free=8.1, wall=20921
2023-05-08 05:45:03 - train.py[line:332] - INFO: end of epoch 6 (average epoch stats below)
local datafile ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 1 begin to initialize row_count and line_idx-to-offset mapping
2023-05-08 05:45:03 - progress_bar.py[line:282] - INFO: epoch 006 | loss 2.368 | loss_v1 0 | loss_v2 0 | nll_loss 1.165 | ntokens 2103.52 | nsentences 63.972 | sample_size 2103.52 | sample_size_v1 0 | sample_size_v2 0 | ppl 2.24 | wps 521.5 | ups 0.25 | wpb 2103.5 | bsz 64 | num_updates 5186 | lr 2.55434e-05 | gnorm 5.215 | clip 100 | loss_scale 64 | train_wall 3483 | gb_free 8.7 | wall 20944
2023-05-08 05:45:03 - trainer.py[line:639] - INFO: loading train data for epoch 7
local datafile ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 0 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 1 finished initializing row_count and line_idx-to-offset mapping
file ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 1 row count 27700 total row count 55400
slice_id 1 seek offset 27700
local datafile ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 0 finished initializing row_count and line_idx-to-offset mapping
file ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 0 row count 27700 total row count 55400
slice_id 0 seek offset 0
2023-05-08 05:45:04 - trainer.py[line:703] - INFO: begin training epoch 7
2023-05-08 05:45:04 - train.py[line:305] - INFO: Start iterating over samples
2023-05-08 05:45:21 - progress_bar.py[line:272] - INFO: epoch 007:      4 / 866 loss=2.372, loss_v1=0, loss_v2=0, nll_loss=1.17, ntokens=2092.9, nsentences=61.6, sample_size=2092.9, sample_size_v1=0, sample_size_v2=0, ppl=2.25, wps=509.2, ups=0.24, wpb=2092.9, bsz=61.6, num_updates=5190, lr=2.55384e-05, gnorm=5.361, clip=100, loss_scale=64, train_wall=39, gb_free=7.1, wall=20962
2023-05-08 05:46:02 - progress_bar.py[line:272] - INFO: epoch 007:     14 / 866 loss=2.326, loss_v1=0, loss_v2=0, nll_loss=1.118, ntokens=2059.7, nsentences=64, sample_size=2059.7, sample_size_v1=0, sample_size_v2=0, ppl=2.17, wps=511, ups=0.25, wpb=2059.7, bsz=64, num_updates=5200, lr=2.55262e-05, gnorm=5.005, clip=100, loss_scale=64, train_wall=40, gb_free=7.5, wall=21003
2023-05-08 05:46:42 - progress_bar.py[line:272] - INFO: epoch 007:     24 / 866 loss=2.295, loss_v1=0, loss_v2=0, nll_loss=1.083, ntokens=2025.5, nsentences=64, sample_size=2025.5, sample_size_v1=0, sample_size_v2=0, ppl=2.12, wps=501.5, ups=0.25, wpb=2025.5, bsz=64, num_updates=5210, lr=2.55139e-05, gnorm=5.402, clip=100, loss_scale=64, train_wall=40, gb_free=7.6, wall=21043
2023-05-08 05:47:23 - progress_bar.py[line:272] - INFO: epoch 007:     34 / 866 loss=2.273, loss_v1=0, loss_v2=0, nll_loss=1.06, ntokens=2115.7, nsentences=64, sample_size=2115.7, sample_size_v1=0, sample_size_v2=0, ppl=2.08, wps=521, ups=0.25, wpb=2115.7, bsz=64, num_updates=5220, lr=2.55016e-05, gnorm=5.26, clip=100, loss_scale=64, train_wall=41, gb_free=7.4, wall=21084
2023-05-08 05:48:03 - progress_bar.py[line:272] - INFO: epoch 007:     44 / 866 loss=2.275, loss_v1=0, loss_v2=0, nll_loss=1.062, ntokens=2111.3, nsentences=64, sample_size=2111.3, sample_size_v1=0, sample_size_v2=0, ppl=2.09, wps=519.8, ups=0.25, wpb=2111.3, bsz=64, num_updates=5230, lr=2.54893e-05, gnorm=5.594, clip=100, loss_scale=64, train_wall=41, gb_free=7.2, wall=21124
2023-05-08 05:48:44 - progress_bar.py[line:272] - INFO: epoch 007:     54 / 866 loss=2.296, loss_v1=0, loss_v2=0, nll_loss=1.086, ntokens=2019.6, nsentences=64, sample_size=2019.6, sample_size_v1=0, sample_size_v2=0, ppl=2.12, wps=500, ups=0.25, wpb=2019.6, bsz=64, num_updates=5240, lr=2.5477e-05, gnorm=6.24, clip=100, loss_scale=64, train_wall=40, gb_free=7.5, wall=21165
2023-05-08 05:49:25 - progress_bar.py[line:272] - INFO: epoch 007:     64 / 866 loss=2.171, loss_v1=0, loss_v2=0, nll_loss=0.947, ntokens=2283.9, nsentences=64, sample_size=2283.9, sample_size_v1=0, sample_size_v2=0, ppl=1.93, wps=557.2, ups=0.24, wpb=2283.9, bsz=64, num_updates=5250, lr=2.54647e-05, gnorm=4.186, clip=100, loss_scale=64, train_wall=41, gb_free=6.9, wall=21206
2023-05-08 05:49:50 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2023-05-08 05:50:10 - progress_bar.py[line:272] - INFO: epoch 007:     75 / 866 loss=2.218, loss_v1=0, loss_v2=0, nll_loss=0.995, ntokens=2397.6, nsentences=64, sample_size=2397.6, sample_size_v1=0, sample_size_v2=0, ppl=1.99, wps=523.5, ups=0.22, wpb=2397.6, bsz=64, num_updates=5260, lr=2.54525e-05, gnorm=4.346, clip=100, loss_scale=64, train_wall=46, gb_free=6.7, wall=21251
2023-05-08 05:50:51 - progress_bar.py[line:272] - INFO: epoch 007:     85 / 866 loss=2.294, loss_v1=0, loss_v2=0, nll_loss=1.085, ntokens=2169.1, nsentences=64, sample_size=2169.1, sample_size_v1=0, sample_size_v2=0, ppl=2.12, wps=528.9, ups=0.24, wpb=2169.1, bsz=64, num_updates=5270, lr=2.54402e-05, gnorm=5.453, clip=100, loss_scale=64, train_wall=41, gb_free=7.6, wall=21292
2023-05-08 05:51:32 - progress_bar.py[line:272] - INFO: epoch 007:     95 / 866 loss=2.261, loss_v1=0, loss_v2=0, nll_loss=1.045, ntokens=2152.5, nsentences=64, sample_size=2152.5, sample_size_v1=0, sample_size_v2=0, ppl=2.06, wps=530.4, ups=0.25, wpb=2152.5, bsz=64, num_updates=5280, lr=2.54279e-05, gnorm=4.994, clip=100, loss_scale=64, train_wall=41, gb_free=7.9, wall=21333
2023-05-08 05:52:12 - progress_bar.py[line:272] - INFO: epoch 007:    105 / 866 loss=2.363, loss_v1=0, loss_v2=0, nll_loss=1.16, ntokens=2018, nsentences=64, sample_size=2018, sample_size_v1=0, sample_size_v2=0, ppl=2.23, wps=501.8, ups=0.25, wpb=2018, bsz=64, num_updates=5290, lr=2.54156e-05, gnorm=5.689, clip=100, loss_scale=64, train_wall=40, gb_free=7.4, wall=21373
2023-05-08 05:52:53 - progress_bar.py[line:272] - INFO: epoch 007:    115 / 866 loss=2.371, loss_v1=0, loss_v2=0, nll_loss=1.169, ntokens=2044, nsentences=64, sample_size=2044, sample_size_v1=0, sample_size_v2=0, ppl=2.25, wps=501.7, ups=0.25, wpb=2044, bsz=64, num_updates=5300, lr=2.54033e-05, gnorm=4.483, clip=100, loss_scale=64, train_wall=41, gb_free=7.4, wall=21414
2023-05-08 05:53:34 - progress_bar.py[line:272] - INFO: epoch 007:    125 / 866 loss=2.34, loss_v1=0, loss_v2=0, nll_loss=1.132, ntokens=2237.3, nsentences=64, sample_size=2237.3, sample_size_v1=0, sample_size_v2=0, ppl=2.19, wps=541.8, ups=0.24, wpb=2237.3, bsz=64, num_updates=5310, lr=2.5391e-05, gnorm=4.616, clip=100, loss_scale=64, train_wall=41, gb_free=6.6, wall=21455
2023-05-08 05:54:15 - progress_bar.py[line:272] - INFO: epoch 007:    135 / 866 loss=2.322, loss_v1=0, loss_v2=0, nll_loss=1.114, ntokens=2191.3, nsentences=64, sample_size=2191.3, sample_size_v1=0, sample_size_v2=0, ppl=2.16, wps=536.1, ups=0.24, wpb=2191.3, bsz=64, num_updates=5320, lr=2.53788e-05, gnorm=4.638, clip=100, loss_scale=64, train_wall=41, gb_free=7.8, wall=21496
2023-05-08 05:54:57 - progress_bar.py[line:272] - INFO: epoch 007:    145 / 866 loss=2.308, loss_v1=0, loss_v2=0, nll_loss=1.098, ntokens=2255.5, nsentences=64, sample_size=2255.5, sample_size_v1=0, sample_size_v2=0, ppl=2.14, wps=544.8, ups=0.24, wpb=2255.5, bsz=64, num_updates=5330, lr=2.53665e-05, gnorm=4.392, clip=100, loss_scale=64, train_wall=41, gb_free=6.8, wall=21538
2023-05-08 05:55:38 - progress_bar.py[line:272] - INFO: epoch 007:    155 / 866 loss=2.32, loss_v1=0, loss_v2=0, nll_loss=1.112, ntokens=2187.3, nsentences=64, sample_size=2187.3, sample_size_v1=0, sample_size_v2=0, ppl=2.16, wps=530, ups=0.24, wpb=2187.3, bsz=64, num_updates=5340, lr=2.53542e-05, gnorm=4.629, clip=100, loss_scale=64, train_wall=41, gb_free=7, wall=21579
2023-05-08 05:56:18 - progress_bar.py[line:272] - INFO: epoch 007:    165 / 866 loss=2.319, loss_v1=0, loss_v2=0, nll_loss=1.11, ntokens=2176.2, nsentences=64, sample_size=2176.2, sample_size_v1=0, sample_size_v2=0, ppl=2.16, wps=535.7, ups=0.25, wpb=2176.2, bsz=64, num_updates=5350, lr=2.53419e-05, gnorm=5.024, clip=100, loss_scale=64, train_wall=41, gb_free=8, wall=21620
2023-05-08 05:56:59 - progress_bar.py[line:272] - INFO: epoch 007:    175 / 866 loss=2.331, loss_v1=0, loss_v2=0, nll_loss=1.124, ntokens=2019.3, nsentences=64, sample_size=2019.3, sample_size_v1=0, sample_size_v2=0, ppl=2.18, wps=499.7, ups=0.25, wpb=2019.3, bsz=64, num_updates=5360, lr=2.53296e-05, gnorm=5.06, clip=100, loss_scale=64, train_wall=40, gb_free=6.9, wall=21660
2023-05-08 05:57:40 - progress_bar.py[line:272] - INFO: epoch 007:    185 / 866 loss=2.302, loss_v1=0, loss_v2=0, nll_loss=1.093, ntokens=2236.2, nsentences=64, sample_size=2236.2, sample_size_v1=0, sample_size_v2=0, ppl=2.13, wps=544.3, ups=0.24, wpb=2236.2, bsz=64, num_updates=5370, lr=2.53173e-05, gnorm=4.765, clip=100, loss_scale=64, train_wall=41, gb_free=5.8, wall=21701
2023-05-08 05:58:21 - progress_bar.py[line:272] - INFO: epoch 007:    195 / 866 loss=2.32, loss_v1=0, loss_v2=0, nll_loss=1.111, ntokens=2181.1, nsentences=64, sample_size=2181.1, sample_size_v1=0, sample_size_v2=0, ppl=2.16, wps=532.3, ups=0.24, wpb=2181.1, bsz=64, num_updates=5380, lr=2.53051e-05, gnorm=4.421, clip=100, loss_scale=64, train_wall=41, gb_free=6.8, wall=21742
2023-05-08 05:59:01 - progress_bar.py[line:272] - INFO: epoch 007:    205 / 866 loss=2.364, loss_v1=0, loss_v2=0, nll_loss=1.161, ntokens=2014.6, nsentences=64, sample_size=2014.6, sample_size_v1=0, sample_size_v2=0, ppl=2.24, wps=499.5, ups=0.25, wpb=2014.6, bsz=64, num_updates=5390, lr=2.52928e-05, gnorm=5.466, clip=100, loss_scale=64, train_wall=40, gb_free=8.1, wall=21782
2023-05-08 05:59:41 - progress_bar.py[line:272] - INFO: epoch 007:    215 / 866 loss=2.37, loss_v1=0, loss_v2=0, nll_loss=1.166, ntokens=2131.6, nsentences=64, sample_size=2131.6, sample_size_v1=0, sample_size_v2=0, ppl=2.24, wps=529.5, ups=0.25, wpb=2131.6, bsz=64, num_updates=5400, lr=2.52805e-05, gnorm=4.564, clip=100, loss_scale=64, train_wall=40, gb_free=8, wall=21823
2023-05-08 06:00:22 - progress_bar.py[line:272] - INFO: epoch 007:    225 / 866 loss=2.366, loss_v1=0, loss_v2=0, nll_loss=1.163, ntokens=2190.1, nsentences=64, sample_size=2190.1, sample_size_v1=0, sample_size_v2=0, ppl=2.24, wps=544.6, ups=0.25, wpb=2190.1, bsz=64, num_updates=5410, lr=2.52682e-05, gnorm=4.84, clip=100, loss_scale=64, train_wall=40, gb_free=7.1, wall=21863
2023-05-08 06:01:02 - progress_bar.py[line:272] - INFO: epoch 007:    235 / 866 loss=2.4, loss_v1=0, loss_v2=0, nll_loss=1.202, ntokens=2099.1, nsentences=64, sample_size=2099.1, sample_size_v1=0, sample_size_v2=0, ppl=2.3, wps=525.7, ups=0.25, wpb=2099.1, bsz=64, num_updates=5420, lr=2.52559e-05, gnorm=5.154, clip=100, loss_scale=64, train_wall=40, gb_free=7.6, wall=21903
2023-05-08 06:01:42 - progress_bar.py[line:272] - INFO: epoch 007:    245 / 866 loss=2.384, loss_v1=0, loss_v2=0, nll_loss=1.183, ntokens=2235, nsentences=64, sample_size=2235, sample_size_v1=0, sample_size_v2=0, ppl=2.27, wps=554, ups=0.25, wpb=2235, bsz=64, num_updates=5430, lr=2.52436e-05, gnorm=4.162, clip=100, loss_scale=64, train_wall=40, gb_free=7.6, wall=21943
2023-05-08 06:02:22 - progress_bar.py[line:272] - INFO: epoch 007:    255 / 866 loss=2.382, loss_v1=0, loss_v2=0, nll_loss=1.183, ntokens=2084.7, nsentences=64, sample_size=2084.7, sample_size_v1=0, sample_size_v2=0, ppl=2.27, wps=516.3, ups=0.25, wpb=2084.7, bsz=64, num_updates=5440, lr=2.52313e-05, gnorm=5.011, clip=100, loss_scale=64, train_wall=40, gb_free=8.2, wall=21983
2023-05-08 06:03:03 - progress_bar.py[line:272] - INFO: epoch 007:    265 / 866 loss=2.383, loss_v1=0, loss_v2=0, nll_loss=1.181, ntokens=2160.1, nsentences=64, sample_size=2160.1, sample_size_v1=0, sample_size_v2=0, ppl=2.27, wps=535.9, ups=0.25, wpb=2160.1, bsz=64, num_updates=5450, lr=2.52191e-05, gnorm=4.709, clip=100, loss_scale=64, train_wall=40, gb_free=7.6, wall=22024
2023-05-08 06:03:43 - progress_bar.py[line:272] - INFO: epoch 007:    275 / 866 loss=2.381, loss_v1=0, loss_v2=0, nll_loss=1.182, ntokens=2134.5, nsentences=64, sample_size=2134.5, sample_size_v1=0, sample_size_v2=0, ppl=2.27, wps=531.3, ups=0.25, wpb=2134.5, bsz=64, num_updates=5460, lr=2.52068e-05, gnorm=4.745, clip=100, loss_scale=64, train_wall=40, gb_free=7.7, wall=22064
2023-05-08 06:04:23 - progress_bar.py[line:272] - INFO: epoch 007:    285 / 866 loss=2.383, loss_v1=0, loss_v2=0, nll_loss=1.18, ntokens=2188.7, nsentences=64, sample_size=2188.7, sample_size_v1=0, sample_size_v2=0, ppl=2.27, wps=544.2, ups=0.25, wpb=2188.7, bsz=64, num_updates=5470, lr=2.51945e-05, gnorm=5.072, clip=100, loss_scale=64, train_wall=40, gb_free=6.4, wall=22104
2023-05-08 06:04:47 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2023-05-08 06:05:07 - progress_bar.py[line:272] - INFO: epoch 007:    296 / 866 loss=2.352, loss_v1=0, loss_v2=0, nll_loss=1.149, ntokens=2146.1, nsentences=64, sample_size=2146.1, sample_size_v1=0, sample_size_v2=0, ppl=2.22, wps=487.1, ups=0.23, wpb=2146.1, bsz=64, num_updates=5480, lr=2.51822e-05, gnorm=4.913, clip=100, loss_scale=32, train_wall=44, gb_free=7.2, wall=22148
2023-05-08 06:05:47 - progress_bar.py[line:272] - INFO: epoch 007:    306 / 866 loss=2.362, loss_v1=0, loss_v2=0, nll_loss=1.157, ntokens=2129.4, nsentences=64, sample_size=2129.4, sample_size_v1=0, sample_size_v2=0, ppl=2.23, wps=530.4, ups=0.25, wpb=2129.4, bsz=64, num_updates=5490, lr=2.51699e-05, gnorm=4.994, clip=100, loss_scale=32, train_wall=40, gb_free=7.2, wall=22188
2023-05-08 06:06:27 - progress_bar.py[line:272] - INFO: epoch 007:    316 / 866 loss=2.371, loss_v1=0, loss_v2=0, nll_loss=1.167, ntokens=2049.6, nsentences=64, sample_size=2049.6, sample_size_v1=0, sample_size_v2=0, ppl=2.25, wps=512, ups=0.25, wpb=2049.6, bsz=64, num_updates=5500, lr=2.51576e-05, gnorm=5.269, clip=100, loss_scale=32, train_wall=40, gb_free=7, wall=22228
2023-05-08 06:07:07 - progress_bar.py[line:272] - INFO: epoch 007:    326 / 866 loss=2.4, loss_v1=0, loss_v2=0, nll_loss=1.201, ntokens=2016.2, nsentences=64, sample_size=2016.2, sample_size_v1=0, sample_size_v2=0, ppl=2.3, wps=506, ups=0.25, wpb=2016.2, bsz=64, num_updates=5510, lr=2.51454e-05, gnorm=5.504, clip=100, loss_scale=32, train_wall=40, gb_free=8, wall=22268
2023-05-08 06:07:47 - progress_bar.py[line:272] - INFO: epoch 007:    336 / 866 loss=2.353, loss_v1=0, loss_v2=0, nll_loss=1.148, ntokens=2129.6, nsentences=64, sample_size=2129.6, sample_size_v1=0, sample_size_v2=0, ppl=2.22, wps=530.1, ups=0.25, wpb=2129.6, bsz=64, num_updates=5520, lr=2.51331e-05, gnorm=4.966, clip=100, loss_scale=32, train_wall=40, gb_free=7.7, wall=22308
2023-05-08 06:08:27 - progress_bar.py[line:272] - INFO: epoch 007:    346 / 866 loss=2.367, loss_v1=0, loss_v2=0, nll_loss=1.166, ntokens=1943.9, nsentences=64, sample_size=1943.9, sample_size_v1=0, sample_size_v2=0, ppl=2.24, wps=484.8, ups=0.25, wpb=1943.9, bsz=64, num_updates=5530, lr=2.51208e-05, gnorm=5.841, clip=100, loss_scale=32, train_wall=40, gb_free=7.7, wall=22349
2023-05-08 06:09:07 - progress_bar.py[line:272] - INFO: epoch 007:    356 / 866 loss=2.398, loss_v1=0, loss_v2=0, nll_loss=1.197, ntokens=1991.6, nsentences=64, sample_size=1991.6, sample_size_v1=0, sample_size_v2=0, ppl=2.29, wps=500.8, ups=0.25, wpb=1991.6, bsz=64, num_updates=5540, lr=2.51085e-05, gnorm=5.48, clip=100, loss_scale=32, train_wall=40, gb_free=8.3, wall=22388
2023-05-08 06:09:47 - progress_bar.py[line:272] - INFO: epoch 007:    366 / 866 loss=2.381, loss_v1=0, loss_v2=0, nll_loss=1.179, ntokens=1975.6, nsentences=64, sample_size=1975.6, sample_size_v1=0, sample_size_v2=0, ppl=2.26, wps=496.4, ups=0.25, wpb=1975.6, bsz=64, num_updates=5550, lr=2.50962e-05, gnorm=5.618, clip=100, loss_scale=32, train_wall=40, gb_free=8.1, wall=22428
2023-05-08 06:10:27 - progress_bar.py[line:272] - INFO: epoch 007:    376 / 866 loss=2.365, loss_v1=0, loss_v2=0, nll_loss=1.162, ntokens=2108.1, nsentences=64, sample_size=2108.1, sample_size_v1=0, sample_size_v2=0, ppl=2.24, wps=527.1, ups=0.25, wpb=2108.1, bsz=64, num_updates=5560, lr=2.50839e-05, gnorm=5.194, clip=100, loss_scale=32, train_wall=40, gb_free=7.8, wall=22468
2023-05-08 06:11:07 - progress_bar.py[line:272] - INFO: epoch 007:    386 / 866 loss=2.361, loss_v1=0, loss_v2=0, nll_loss=1.158, ntokens=2138, nsentences=64, sample_size=2138, sample_size_v1=0, sample_size_v2=0, ppl=2.23, wps=533.6, ups=0.25, wpb=2138, bsz=64, num_updates=5570, lr=2.50717e-05, gnorm=5.048, clip=100, loss_scale=32, train_wall=40, gb_free=7.7, wall=22508
2023-05-08 06:11:47 - progress_bar.py[line:272] - INFO: epoch 007:    396 / 866 loss=2.372, loss_v1=0, loss_v2=0, nll_loss=1.17, ntokens=2024.2, nsentences=64, sample_size=2024.2, sample_size_v1=0, sample_size_v2=0, ppl=2.25, wps=505.9, ups=0.25, wpb=2024.2, bsz=64, num_updates=5580, lr=2.50594e-05, gnorm=5.88, clip=100, loss_scale=32, train_wall=40, gb_free=7.2, wall=22548
2023-05-08 06:12:27 - progress_bar.py[line:272] - INFO: epoch 007:    406 / 866 loss=2.368, loss_v1=0, loss_v2=0, nll_loss=1.165, ntokens=2079.1, nsentences=64, sample_size=2079.1, sample_size_v1=0, sample_size_v2=0, ppl=2.24, wps=517.1, ups=0.25, wpb=2079.1, bsz=64, num_updates=5590, lr=2.50471e-05, gnorm=5.153, clip=100, loss_scale=32, train_wall=40, gb_free=7.5, wall=22588
2023-05-08 06:13:07 - progress_bar.py[line:272] - INFO: epoch 007:    416 / 866 loss=2.357, loss_v1=0, loss_v2=0, nll_loss=1.155, ntokens=2132.3, nsentences=64, sample_size=2132.3, sample_size_v1=0, sample_size_v2=0, ppl=2.23, wps=532.1, ups=0.25, wpb=2132.3, bsz=64, num_updates=5600, lr=2.50348e-05, gnorm=5.691, clip=100, loss_scale=32, train_wall=40, gb_free=7.9, wall=22629
2023-05-08 06:13:47 - progress_bar.py[line:272] - INFO: epoch 007:    426 / 866 loss=2.346, loss_v1=0, loss_v2=0, nll_loss=1.14, ntokens=2080.3, nsentences=64, sample_size=2080.3, sample_size_v1=0, sample_size_v2=0, ppl=2.2, wps=519.4, ups=0.25, wpb=2080.3, bsz=64, num_updates=5610, lr=2.50225e-05, gnorm=5.069, clip=100, loss_scale=32, train_wall=40, gb_free=7.3, wall=22669
2023-05-08 06:14:27 - progress_bar.py[line:272] - INFO: epoch 007:    436 / 866 loss=2.375, loss_v1=0, loss_v2=0, nll_loss=1.172, ntokens=2138.3, nsentences=64, sample_size=2138.3, sample_size_v1=0, sample_size_v2=0, ppl=2.25, wps=535.7, ups=0.25, wpb=2138.3, bsz=64, num_updates=5620, lr=2.50102e-05, gnorm=5.439, clip=100, loss_scale=32, train_wall=40, gb_free=7.3, wall=22708
2023-05-08 06:15:08 - progress_bar.py[line:272] - INFO: epoch 007:    446 / 866 loss=2.39, loss_v1=0, loss_v2=0, nll_loss=1.189, ntokens=2024.4, nsentences=64, sample_size=2024.4, sample_size_v1=0, sample_size_v2=0, ppl=2.28, wps=503, ups=0.25, wpb=2024.4, bsz=64, num_updates=5630, lr=2.4998e-05, gnorm=5.853, clip=100, loss_scale=32, train_wall=40, gb_free=7.2, wall=22749
2023-05-08 06:15:48 - progress_bar.py[line:272] - INFO: epoch 007:    456 / 866 loss=2.371, loss_v1=0, loss_v2=0, nll_loss=1.169, ntokens=2040.8, nsentences=64, sample_size=2040.8, sample_size_v1=0, sample_size_v2=0, ppl=2.25, wps=508.7, ups=0.25, wpb=2040.8, bsz=64, num_updates=5640, lr=2.49857e-05, gnorm=6.024, clip=100, loss_scale=32, train_wall=40, gb_free=7.9, wall=22789
2023-05-08 06:16:28 - progress_bar.py[line:272] - INFO: epoch 007:    466 / 866 loss=2.362, loss_v1=0, loss_v2=0, nll_loss=1.158, ntokens=2147.8, nsentences=64, sample_size=2147.8, sample_size_v1=0, sample_size_v2=0, ppl=2.23, wps=535, ups=0.25, wpb=2147.8, bsz=64, num_updates=5650, lr=2.49734e-05, gnorm=5.131, clip=100, loss_scale=32, train_wall=40, gb_free=7.8, wall=22829
2023-05-08 06:17:09 - progress_bar.py[line:272] - INFO: epoch 007:    476 / 866 loss=2.378, loss_v1=0, loss_v2=0, nll_loss=1.174, ntokens=2236, nsentences=64, sample_size=2236, sample_size_v1=0, sample_size_v2=0, ppl=2.26, wps=550.4, ups=0.25, wpb=2236, bsz=64, num_updates=5660, lr=2.49611e-05, gnorm=5.636, clip=100, loss_scale=32, train_wall=41, gb_free=7.8, wall=22870
2023-05-08 06:17:49 - progress_bar.py[line:272] - INFO: epoch 007:    486 / 866 loss=2.366, loss_v1=0, loss_v2=0, nll_loss=1.163, ntokens=2102.6, nsentences=64, sample_size=2102.6, sample_size_v1=0, sample_size_v2=0, ppl=2.24, wps=523.7, ups=0.25, wpb=2102.6, bsz=64, num_updates=5670, lr=2.49488e-05, gnorm=5.065, clip=100, loss_scale=32, train_wall=40, gb_free=7.6, wall=22910
2023-05-08 06:18:29 - progress_bar.py[line:272] - INFO: epoch 007:    496 / 866 loss=2.345, loss_v1=0, loss_v2=0, nll_loss=1.139, ntokens=2024.7, nsentences=64, sample_size=2024.7, sample_size_v1=0, sample_size_v2=0, ppl=2.2, wps=505.6, ups=0.25, wpb=2024.7, bsz=64, num_updates=5680, lr=2.49365e-05, gnorm=5.684, clip=100, loss_scale=32, train_wall=40, gb_free=8.1, wall=22950
2023-05-08 06:19:09 - progress_bar.py[line:272] - INFO: epoch 007:    506 / 866 loss=2.379, loss_v1=0, loss_v2=0, nll_loss=1.178, ntokens=2098.8, nsentences=64, sample_size=2098.8, sample_size_v1=0, sample_size_v2=0, ppl=2.26, wps=524.9, ups=0.25, wpb=2098.8, bsz=64, num_updates=5690, lr=2.49242e-05, gnorm=5.576, clip=100, loss_scale=32, train_wall=40, gb_free=7.5, wall=22990
2023-05-08 06:19:49 - progress_bar.py[line:272] - INFO: epoch 007:    516 / 866 loss=2.378, loss_v1=0, loss_v2=0, nll_loss=1.174, ntokens=2219, nsentences=64, sample_size=2219, sample_size_v1=0, sample_size_v2=0, ppl=2.26, wps=554.7, ups=0.25, wpb=2219, bsz=64, num_updates=5700, lr=2.4912e-05, gnorm=4.915, clip=100, loss_scale=32, train_wall=40, gb_free=7.9, wall=23030
2023-05-08 06:20:28 - progress_bar.py[line:272] - INFO: epoch 007:    526 / 866 loss=2.371, loss_v1=0, loss_v2=0, nll_loss=1.17, ntokens=2002, nsentences=64, sample_size=2002, sample_size_v1=0, sample_size_v2=0, ppl=2.25, wps=504.8, ups=0.25, wpb=2002, bsz=64, num_updates=5710, lr=2.48997e-05, gnorm=6, clip=100, loss_scale=32, train_wall=40, gb_free=8.1, wall=23069
2023-05-08 06:21:08 - progress_bar.py[line:272] - INFO: epoch 007:    536 / 866 loss=2.344, loss_v1=0, loss_v2=0, nll_loss=1.138, ntokens=2077.6, nsentences=64, sample_size=2077.6, sample_size_v1=0, sample_size_v2=0, ppl=2.2, wps=520.1, ups=0.25, wpb=2077.6, bsz=64, num_updates=5720, lr=2.48874e-05, gnorm=5.449, clip=100, loss_scale=32, train_wall=40, gb_free=7.9, wall=23109
2023-05-08 06:21:49 - progress_bar.py[line:272] - INFO: epoch 007:    546 / 866 loss=2.377, loss_v1=0, loss_v2=0, nll_loss=1.176, ntokens=2278.3, nsentences=64, sample_size=2278.3, sample_size_v1=0, sample_size_v2=0, ppl=2.26, wps=563.4, ups=0.25, wpb=2278.3, bsz=64, num_updates=5730, lr=2.48751e-05, gnorm=5.293, clip=100, loss_scale=32, train_wall=40, gb_free=7.6, wall=23150
2023-05-08 06:22:30 - progress_bar.py[line:272] - INFO: epoch 007:    556 / 866 loss=2.385, loss_v1=0, loss_v2=0, nll_loss=1.184, ntokens=2260.8, nsentences=64, sample_size=2260.8, sample_size_v1=0, sample_size_v2=0, ppl=2.27, wps=554, ups=0.25, wpb=2260.8, bsz=64, num_updates=5740, lr=2.48628e-05, gnorm=4.786, clip=100, loss_scale=32, train_wall=41, gb_free=7.3, wall=23191
2023-05-08 06:23:10 - progress_bar.py[line:272] - INFO: epoch 007:    566 / 866 loss=2.366, loss_v1=0, loss_v2=0, nll_loss=1.163, ntokens=2249.8, nsentences=64, sample_size=2249.8, sample_size_v1=0, sample_size_v2=0, ppl=2.24, wps=561.1, ups=0.25, wpb=2249.8, bsz=64, num_updates=5750, lr=2.48505e-05, gnorm=5.532, clip=100, loss_scale=32, train_wall=40, gb_free=6.8, wall=23231
2023-05-08 06:23:50 - progress_bar.py[line:272] - INFO: epoch 007:    576 / 866 loss=2.37, loss_v1=0, loss_v2=0, nll_loss=1.167, ntokens=2151, nsentences=64, sample_size=2151, sample_size_v1=0, sample_size_v2=0, ppl=2.25, wps=536.6, ups=0.25, wpb=2151, bsz=64, num_updates=5760, lr=2.48383e-05, gnorm=5.152, clip=100, loss_scale=32, train_wall=40, gb_free=7.4, wall=23271
2023-05-08 06:24:30 - progress_bar.py[line:272] - INFO: epoch 007:    586 / 866 loss=2.381, loss_v1=0, loss_v2=0, nll_loss=1.179, ntokens=2121, nsentences=64, sample_size=2121, sample_size_v1=0, sample_size_v2=0, ppl=2.26, wps=526.1, ups=0.25, wpb=2121, bsz=64, num_updates=5770, lr=2.4826e-05, gnorm=5.571, clip=100, loss_scale=32, train_wall=40, gb_free=7.6, wall=23311
2023-05-08 06:25:10 - progress_bar.py[line:272] - INFO: epoch 007:    596 / 866 loss=2.342, loss_v1=0, loss_v2=0, nll_loss=1.138, ntokens=2106.7, nsentences=64, sample_size=2106.7, sample_size_v1=0, sample_size_v2=0, ppl=2.2, wps=524.7, ups=0.25, wpb=2106.7, bsz=64, num_updates=5780, lr=2.48137e-05, gnorm=5.59, clip=100, loss_scale=32, train_wall=40, gb_free=7.4, wall=23351
2023-05-08 06:25:50 - progress_bar.py[line:272] - INFO: epoch 007:    606 / 866 loss=2.351, loss_v1=0, loss_v2=0, nll_loss=1.147, ntokens=2021.9, nsentences=64, sample_size=2021.9, sample_size_v1=0, sample_size_v2=0, ppl=2.21, wps=504.1, ups=0.25, wpb=2021.9, bsz=64, num_updates=5790, lr=2.48014e-05, gnorm=5.632, clip=100, loss_scale=32, train_wall=40, gb_free=8.1, wall=23391
2023-05-08 06:26:30 - progress_bar.py[line:272] - INFO: epoch 007:    616 / 866 loss=2.384, loss_v1=0, loss_v2=0, nll_loss=1.181, ntokens=1934.7, nsentences=64, sample_size=1934.7, sample_size_v1=0, sample_size_v2=0, ppl=2.27, wps=483.9, ups=0.25, wpb=1934.7, bsz=64, num_updates=5800, lr=2.47891e-05, gnorm=5.602, clip=100, loss_scale=32, train_wall=40, gb_free=8.6, wall=23431
2023-05-08 06:27:11 - progress_bar.py[line:272] - INFO: epoch 007:    626 / 866 loss=2.368, loss_v1=0, loss_v2=0, nll_loss=1.166, ntokens=2062.4, nsentences=64, sample_size=2062.4, sample_size_v1=0, sample_size_v2=0, ppl=2.24, wps=513.4, ups=0.25, wpb=2062.4, bsz=64, num_updates=5810, lr=2.47768e-05, gnorm=5.244, clip=100, loss_scale=32, train_wall=40, gb_free=8, wall=23472
2023-05-08 06:27:51 - progress_bar.py[line:272] - INFO: epoch 007:    636 / 866 loss=2.35, loss_v1=0, loss_v2=0, nll_loss=1.144, ntokens=2032.4, nsentences=64, sample_size=2032.4, sample_size_v1=0, sample_size_v2=0, ppl=2.21, wps=507.6, ups=0.25, wpb=2032.4, bsz=64, num_updates=5820, lr=2.47646e-05, gnorm=5.595, clip=100, loss_scale=32, train_wall=40, gb_free=7.7, wall=23512
2023-05-08 06:28:30 - progress_bar.py[line:272] - INFO: epoch 007:    646 / 866 loss=2.362, loss_v1=0, loss_v2=0, nll_loss=1.158, ntokens=2066.6, nsentences=64, sample_size=2066.6, sample_size_v1=0, sample_size_v2=0, ppl=2.23, wps=519.1, ups=0.25, wpb=2066.6, bsz=64, num_updates=5830, lr=2.47523e-05, gnorm=5.082, clip=100, loss_scale=32, train_wall=40, gb_free=8.5, wall=23551
2023-05-08 06:29:10 - progress_bar.py[line:272] - INFO: epoch 007:    656 / 866 loss=2.387, loss_v1=0, loss_v2=0, nll_loss=1.187, ntokens=1902.3, nsentences=64, sample_size=1902.3, sample_size_v1=0, sample_size_v2=0, ppl=2.28, wps=480.2, ups=0.25, wpb=1902.3, bsz=64, num_updates=5840, lr=2.474e-05, gnorm=6.104, clip=100, loss_scale=32, train_wall=40, gb_free=8.3, wall=23591
2023-05-08 06:29:50 - progress_bar.py[line:272] - INFO: epoch 007:    666 / 866 loss=2.381, loss_v1=0, loss_v2=0, nll_loss=1.179, ntokens=1976.5, nsentences=64, sample_size=1976.5, sample_size_v1=0, sample_size_v2=0, ppl=2.26, wps=495.3, ups=0.25, wpb=1976.5, bsz=64, num_updates=5850, lr=2.47277e-05, gnorm=5.597, clip=100, loss_scale=32, train_wall=40, gb_free=7.5, wall=23631
2023-05-08 06:30:30 - progress_bar.py[line:272] - INFO: epoch 007:    676 / 866 loss=2.361, loss_v1=0, loss_v2=0, nll_loss=1.157, ntokens=2075, nsentences=64, sample_size=2075, sample_size_v1=0, sample_size_v2=0, ppl=2.23, wps=518, ups=0.25, wpb=2075, bsz=64, num_updates=5860, lr=2.47154e-05, gnorm=5.419, clip=100, loss_scale=32, train_wall=40, gb_free=7.7, wall=23671
2023-05-08 06:31:10 - progress_bar.py[line:272] - INFO: epoch 007:    686 / 866 loss=2.358, loss_v1=0, loss_v2=0, nll_loss=1.155, ntokens=2037.7, nsentences=64, sample_size=2037.7, sample_size_v1=0, sample_size_v2=0, ppl=2.23, wps=508.6, ups=0.25, wpb=2037.7, bsz=64, num_updates=5870, lr=2.47031e-05, gnorm=5.667, clip=100, loss_scale=32, train_wall=40, gb_free=7.5, wall=23711
2023-05-08 06:31:50 - progress_bar.py[line:272] - INFO: epoch 007:    696 / 866 loss=2.377, loss_v1=0, loss_v2=0, nll_loss=1.175, ntokens=2087.8, nsentences=64, sample_size=2087.8, sample_size_v1=0, sample_size_v2=0, ppl=2.26, wps=517.8, ups=0.25, wpb=2087.8, bsz=64, num_updates=5880, lr=2.46909e-05, gnorm=5.624, clip=100, loss_scale=32, train_wall=40, gb_free=8, wall=23751
2023-05-08 06:32:30 - progress_bar.py[line:272] - INFO: epoch 007:    706 / 866 loss=2.373, loss_v1=0, loss_v2=0, nll_loss=1.171, ntokens=1990.3, nsentences=64, sample_size=1990.3, sample_size_v1=0, sample_size_v2=0, ppl=2.25, wps=499.2, ups=0.25, wpb=1990.3, bsz=64, num_updates=5890, lr=2.46786e-05, gnorm=5.861, clip=100, loss_scale=32, train_wall=40, gb_free=8.3, wall=23791
2023-05-08 06:33:10 - progress_bar.py[line:272] - INFO: epoch 007:    716 / 866 loss=2.393, loss_v1=0, loss_v2=0, nll_loss=1.194, ntokens=1886.2, nsentences=64, sample_size=1886.2, sample_size_v1=0, sample_size_v2=0, ppl=2.29, wps=473.2, ups=0.25, wpb=1886.2, bsz=64, num_updates=5900, lr=2.46663e-05, gnorm=6.105, clip=100, loss_scale=32, train_wall=40, gb_free=8, wall=23831
2023-05-08 06:33:50 - progress_bar.py[line:272] - INFO: epoch 007:    726 / 866 loss=2.342, loss_v1=0, loss_v2=0, nll_loss=1.136, ntokens=1999, nsentences=64, sample_size=1999, sample_size_v1=0, sample_size_v2=0, ppl=2.2, wps=501, ups=0.25, wpb=1999, bsz=64, num_updates=5910, lr=2.4654e-05, gnorm=5.288, clip=100, loss_scale=32, train_wall=40, gb_free=7.3, wall=23871
2023-05-08 06:34:30 - progress_bar.py[line:272] - INFO: epoch 007:    736 / 866 loss=2.345, loss_v1=0, loss_v2=0, nll_loss=1.137, ntokens=2067.7, nsentences=64, sample_size=2067.7, sample_size_v1=0, sample_size_v2=0, ppl=2.2, wps=515.6, ups=0.25, wpb=2067.7, bsz=64, num_updates=5920, lr=2.46417e-05, gnorm=5.313, clip=100, loss_scale=32, train_wall=40, gb_free=8.1, wall=23911
2023-05-08 06:35:10 - progress_bar.py[line:272] - INFO: epoch 007:    746 / 866 loss=2.34, loss_v1=0, loss_v2=0, nll_loss=1.133, ntokens=2136.1, nsentences=64, sample_size=2136.1, sample_size_v1=0, sample_size_v2=0, ppl=2.19, wps=531.1, ups=0.25, wpb=2136.1, bsz=64, num_updates=5930, lr=2.46294e-05, gnorm=5.335, clip=100, loss_scale=32, train_wall=40, gb_free=7.9, wall=23951
2023-05-08 06:35:50 - progress_bar.py[line:272] - INFO: epoch 007:    756 / 866 loss=2.343, loss_v1=0, loss_v2=0, nll_loss=1.138, ntokens=2079.3, nsentences=64, sample_size=2079.3, sample_size_v1=0, sample_size_v2=0, ppl=2.2, wps=517.7, ups=0.25, wpb=2079.3, bsz=64, num_updates=5940, lr=2.46171e-05, gnorm=5.993, clip=100, loss_scale=32, train_wall=40, gb_free=7.5, wall=23992
2023-05-08 06:36:31 - progress_bar.py[line:272] - INFO: epoch 007:    766 / 866 loss=2.353, loss_v1=0, loss_v2=0, nll_loss=1.15, ntokens=2087.9, nsentences=64, sample_size=2087.9, sample_size_v1=0, sample_size_v2=0, ppl=2.22, wps=520.3, ups=0.25, wpb=2087.9, bsz=64, num_updates=5950, lr=2.46049e-05, gnorm=5.439, clip=100, loss_scale=32, train_wall=40, gb_free=7.9, wall=24032
2023-05-08 06:37:11 - progress_bar.py[line:272] - INFO: epoch 007:    776 / 866 loss=2.339, loss_v1=0, loss_v2=0, nll_loss=1.13, ntokens=2232.1, nsentences=64, sample_size=2232.1, sample_size_v1=0, sample_size_v2=0, ppl=2.19, wps=556.1, ups=0.25, wpb=2232.1, bsz=64, num_updates=5960, lr=2.45926e-05, gnorm=5.641, clip=100, loss_scale=32, train_wall=40, gb_free=7.8, wall=24072
2023-05-08 06:37:51 - progress_bar.py[line:272] - INFO: epoch 007:    786 / 866 loss=2.35, loss_v1=0, loss_v2=0, nll_loss=1.146, ntokens=2088.2, nsentences=64, sample_size=2088.2, sample_size_v1=0, sample_size_v2=0, ppl=2.21, wps=521.6, ups=0.25, wpb=2088.2, bsz=64, num_updates=5970, lr=2.45803e-05, gnorm=5.821, clip=100, loss_scale=32, train_wall=40, gb_free=8.1, wall=24112
2023-05-08 06:38:31 - progress_bar.py[line:272] - INFO: epoch 007:    796 / 866 loss=2.367, loss_v1=0, loss_v2=0, nll_loss=1.162, ntokens=2068.1, nsentences=64, sample_size=2068.1, sample_size_v1=0, sample_size_v2=0, ppl=2.24, wps=516.8, ups=0.25, wpb=2068.1, bsz=64, num_updates=5980, lr=2.4568e-05, gnorm=5.335, clip=100, loss_scale=32, train_wall=40, gb_free=7.5, wall=24152
2023-05-08 06:39:11 - progress_bar.py[line:272] - INFO: epoch 007:    806 / 866 loss=2.353, loss_v1=0, loss_v2=0, nll_loss=1.149, ntokens=1919.9, nsentences=64, sample_size=1919.9, sample_size_v1=0, sample_size_v2=0, ppl=2.22, wps=483.1, ups=0.25, wpb=1919.9, bsz=64, num_updates=5990, lr=2.45557e-05, gnorm=6.011, clip=100, loss_scale=64, train_wall=40, gb_free=8.1, wall=24192
2023-05-08 06:39:51 - progress_bar.py[line:272] - INFO: epoch 007:    816 / 866 loss=2.333, loss_v1=0, loss_v2=0, nll_loss=1.126, ntokens=2099.5, nsentences=64, sample_size=2099.5, sample_size_v1=0, sample_size_v2=0, ppl=2.18, wps=521.3, ups=0.25, wpb=2099.5, bsz=64, num_updates=6000, lr=2.45434e-05, gnorm=5.47, clip=100, loss_scale=64, train_wall=40, gb_free=7.4, wall=24232
2023-05-08 06:40:32 - progress_bar.py[line:272] - INFO: epoch 007:    826 / 866 loss=2.336, loss_v1=0, loss_v2=0, nll_loss=1.129, ntokens=2152.1, nsentences=64, sample_size=2152.1, sample_size_v1=0, sample_size_v2=0, ppl=2.19, wps=529, ups=0.25, wpb=2152.1, bsz=64, num_updates=6010, lr=2.45312e-05, gnorm=5.224, clip=100, loss_scale=64, train_wall=41, gb_free=7.9, wall=24273
2023-05-08 06:41:12 - progress_bar.py[line:272] - INFO: epoch 007:    836 / 866 loss=2.35, loss_v1=0, loss_v2=0, nll_loss=1.144, ntokens=2165.2, nsentences=64, sample_size=2165.2, sample_size_v1=0, sample_size_v2=0, ppl=2.21, wps=533.7, ups=0.25, wpb=2165.2, bsz=64, num_updates=6020, lr=2.45189e-05, gnorm=5.333, clip=100, loss_scale=64, train_wall=41, gb_free=8.2, wall=24313
2023-05-08 06:41:52 - progress_bar.py[line:272] - INFO: epoch 007:    846 / 866 loss=2.349, loss_v1=0, loss_v2=0, nll_loss=1.144, ntokens=2171.3, nsentences=64, sample_size=2171.3, sample_size_v1=0, sample_size_v2=0, ppl=2.21, wps=539.8, ups=0.25, wpb=2171.3, bsz=64, num_updates=6030, lr=2.45066e-05, gnorm=5.612, clip=100, loss_scale=64, train_wall=40, gb_free=8, wall=24353
2023-05-08 06:42:33 - progress_bar.py[line:272] - INFO: epoch 007:    856 / 866 loss=2.343, loss_v1=0, loss_v2=0, nll_loss=1.138, ntokens=2114.8, nsentences=64, sample_size=2114.8, sample_size_v1=0, sample_size_v2=0, ppl=2.2, wps=524.1, ups=0.25, wpb=2114.8, bsz=64, num_updates=6040, lr=2.44943e-05, gnorm=5.394, clip=100, loss_scale=64, train_wall=40, gb_free=7.9, wall=24394
local datafile ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 1 begin to initialize row_count and line_idx-to-offset mapping
2023-05-08 06:43:11 - progress_bar.py[line:272] - INFO: epoch 007:    866 / 866 loss=2.373, loss_v1=0, loss_v2=0, nll_loss=1.168, ntokens=2017.9, nsentences=61.6, sample_size=2017.9, sample_size_v1=0, sample_size_v2=0, ppl=2.25, wps=523.5, ups=0.26, wpb=2017.9, bsz=61.6, num_updates=6050, lr=2.4482e-05, gnorm=5.629, clip=100, loss_scale=64, train_wall=39, gb_free=8.7, wall=24432
2023-05-08 06:43:11 - train.py[line:332] - INFO: end of epoch 7 (average epoch stats below)
2023-05-08 06:43:11 - progress_bar.py[line:282] - INFO: epoch 007 | loss 2.351 | loss_v1 0 | loss_v2 0 | nll_loss 1.146 | ntokens 2102.97 | nsentences 63.972 | sample_size 2102.97 | sample_size_v1 0 | sample_size_v2 0 | ppl 2.21 | wps 520.8 | ups 0.25 | wpb 2103 | bsz 64 | num_updates 6050 | lr 2.4482e-05 | gnorm 5.299 | clip 100 | loss_scale 64 | train_wall 3482 | gb_free 8.7 | wall 24432
2023-05-08 06:43:11 - trainer.py[line:639] - INFO: loading train data for epoch 8
local datafile ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 0 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 1 finished initializing row_count and line_idx-to-offset mapping
file ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 1 row count 27700 total row count 55400
slice_id 1 seek offset 27700
local datafile ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 0 finished initializing row_count and line_idx-to-offset mapping
file ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 0 row count 27700 total row count 55400
slice_id 0 seek offset 0
2023-05-08 06:43:13 - trainer.py[line:703] - INFO: begin training epoch 8
2023-05-08 06:43:13 - train.py[line:305] - INFO: Start iterating over samples
2023-05-08 06:43:54 - progress_bar.py[line:272] - INFO: epoch 008:     10 / 866 loss=2.314, loss_v1=0, loss_v2=0, nll_loss=1.106, ntokens=2137.4, nsentences=64, sample_size=2137.4, sample_size_v1=0, sample_size_v2=0, ppl=2.15, wps=499.4, ups=0.23, wpb=2137.4, bsz=64, num_updates=6060, lr=2.44697e-05, gnorm=5.532, clip=100, loss_scale=64, train_wall=41, gb_free=6.3, wall=24475
2023-05-08 06:44:34 - progress_bar.py[line:272] - INFO: epoch 008:     20 / 866 loss=2.279, loss_v1=0, loss_v2=0, nll_loss=1.065, ntokens=2050.9, nsentences=64, sample_size=2050.9, sample_size_v1=0, sample_size_v2=0, ppl=2.09, wps=508.7, ups=0.25, wpb=2050.9, bsz=64, num_updates=6070, lr=2.44575e-05, gnorm=5.273, clip=100, loss_scale=64, train_wall=40, gb_free=7.8, wall=24515
2023-05-08 06:45:15 - progress_bar.py[line:272] - INFO: epoch 008:     30 / 866 loss=2.306, loss_v1=0, loss_v2=0, nll_loss=1.097, ntokens=1987.5, nsentences=64, sample_size=1987.5, sample_size_v1=0, sample_size_v2=0, ppl=2.14, wps=494, ups=0.25, wpb=1987.5, bsz=64, num_updates=6080, lr=2.44452e-05, gnorm=5.667, clip=100, loss_scale=64, train_wall=40, gb_free=7.4, wall=24556
2023-05-08 06:45:56 - progress_bar.py[line:272] - INFO: epoch 008:     40 / 866 loss=2.226, loss_v1=0, loss_v2=0, nll_loss=1.006, ntokens=2238.7, nsentences=64, sample_size=2238.7, sample_size_v1=0, sample_size_v2=0, ppl=2.01, wps=545.8, ups=0.24, wpb=2238.7, bsz=64, num_updates=6090, lr=2.44329e-05, gnorm=5.077, clip=100, loss_scale=64, train_wall=41, gb_free=7.6, wall=24597
2023-05-08 06:46:36 - progress_bar.py[line:272] - INFO: epoch 008:     50 / 866 loss=2.303, loss_v1=0, loss_v2=0, nll_loss=1.095, ntokens=1995.1, nsentences=64, sample_size=1995.1, sample_size_v1=0, sample_size_v2=0, ppl=2.14, wps=494, ups=0.25, wpb=1995.1, bsz=64, num_updates=6100, lr=2.44206e-05, gnorm=6.094, clip=100, loss_scale=64, train_wall=40, gb_free=7.4, wall=24637
2023-05-08 06:47:16 - progress_bar.py[line:272] - INFO: epoch 008:     60 / 866 loss=2.193, loss_v1=0, loss_v2=0, nll_loss=0.968, ntokens=2062.8, nsentences=64, sample_size=2062.8, sample_size_v1=0, sample_size_v2=0, ppl=1.96, wps=513.5, ups=0.25, wpb=2062.8, bsz=64, num_updates=6110, lr=2.44083e-05, gnorm=5.673, clip=100, loss_scale=64, train_wall=40, gb_free=6.4, wall=24677
2023-05-08 06:47:58 - progress_bar.py[line:272] - INFO: epoch 008:     70 / 866 loss=2.188, loss_v1=0, loss_v2=0, nll_loss=0.963, ntokens=2476.7, nsentences=64, sample_size=2476.7, sample_size_v1=0, sample_size_v2=0, ppl=1.95, wps=591.8, ups=0.24, wpb=2476.7, bsz=64, num_updates=6120, lr=2.4396e-05, gnorm=4.123, clip=100, loss_scale=64, train_wall=42, gb_free=7, wall=24719
2023-05-08 06:48:40 - progress_bar.py[line:272] - INFO: epoch 008:     80 / 866 loss=2.239, loss_v1=0, loss_v2=0, nll_loss=1.022, ntokens=2320.5, nsentences=64, sample_size=2320.5, sample_size_v1=0, sample_size_v2=0, ppl=2.03, wps=559.7, ups=0.24, wpb=2320.5, bsz=64, num_updates=6130, lr=2.43838e-05, gnorm=5.328, clip=100, loss_scale=64, train_wall=41, gb_free=6.8, wall=24761
2023-05-08 06:49:20 - progress_bar.py[line:272] - INFO: epoch 008:     90 / 866 loss=2.287, loss_v1=0, loss_v2=0, nll_loss=1.075, ntokens=2123.9, nsentences=64, sample_size=2123.9, sample_size_v1=0, sample_size_v2=0, ppl=2.11, wps=520.6, ups=0.25, wpb=2123.9, bsz=64, num_updates=6140, lr=2.43715e-05, gnorm=5.159, clip=100, loss_scale=64, train_wall=41, gb_free=7.4, wall=24801
2023-05-08 06:50:01 - progress_bar.py[line:272] - INFO: epoch 008:    100 / 866 loss=2.286, loss_v1=0, loss_v2=0, nll_loss=1.075, ntokens=2077.5, nsentences=64, sample_size=2077.5, sample_size_v1=0, sample_size_v2=0, ppl=2.11, wps=512.6, ups=0.25, wpb=2077.5, bsz=64, num_updates=6150, lr=2.43592e-05, gnorm=5.323, clip=100, loss_scale=64, train_wall=40, gb_free=7.2, wall=24842
2023-05-08 06:50:41 - progress_bar.py[line:272] - INFO: epoch 008:    110 / 866 loss=2.346, loss_v1=0, loss_v2=0, nll_loss=1.141, ntokens=2029.9, nsentences=64, sample_size=2029.9, sample_size_v1=0, sample_size_v2=0, ppl=2.21, wps=500.1, ups=0.25, wpb=2029.9, bsz=64, num_updates=6160, lr=2.43469e-05, gnorm=5.223, clip=100, loss_scale=64, train_wall=41, gb_free=7.2, wall=24883
2023-05-08 06:51:22 - progress_bar.py[line:272] - INFO: epoch 008:    120 / 866 loss=2.333, loss_v1=0, loss_v2=0, nll_loss=1.125, ntokens=2169.2, nsentences=64, sample_size=2169.2, sample_size_v1=0, sample_size_v2=0, ppl=2.18, wps=529.8, ups=0.24, wpb=2169.2, bsz=64, num_updates=6170, lr=2.43346e-05, gnorm=4.946, clip=100, loss_scale=64, train_wall=41, gb_free=7, wall=24923
2023-05-08 06:52:04 - progress_bar.py[line:272] - INFO: epoch 008:    130 / 866 loss=2.321, loss_v1=0, loss_v2=0, nll_loss=1.113, ntokens=2201.3, nsentences=64, sample_size=2201.3, sample_size_v1=0, sample_size_v2=0, ppl=2.16, wps=534.9, ups=0.24, wpb=2201.3, bsz=64, num_updates=6180, lr=2.43223e-05, gnorm=4.747, clip=100, loss_scale=64, train_wall=41, gb_free=6.8, wall=24965
2023-05-08 06:52:45 - progress_bar.py[line:272] - INFO: epoch 008:    140 / 866 loss=2.294, loss_v1=0, loss_v2=0, nll_loss=1.084, ntokens=2246.8, nsentences=64, sample_size=2246.8, sample_size_v1=0, sample_size_v2=0, ppl=2.12, wps=548.3, ups=0.24, wpb=2246.8, bsz=64, num_updates=6190, lr=2.431e-05, gnorm=5.056, clip=100, loss_scale=64, train_wall=41, gb_free=6.2, wall=25006
2023-05-08 06:53:26 - progress_bar.py[line:272] - INFO: epoch 008:    150 / 866 loss=2.292, loss_v1=0, loss_v2=0, nll_loss=1.08, ntokens=2170, nsentences=64, sample_size=2170, sample_size_v1=0, sample_size_v2=0, ppl=2.11, wps=527, ups=0.24, wpb=2170, bsz=64, num_updates=6200, lr=2.42978e-05, gnorm=4.653, clip=100, loss_scale=64, train_wall=41, gb_free=7.3, wall=25047
2023-05-08 06:54:07 - progress_bar.py[line:272] - INFO: epoch 008:    160 / 866 loss=2.314, loss_v1=0, loss_v2=0, nll_loss=1.106, ntokens=2205.1, nsentences=64, sample_size=2205.1, sample_size_v1=0, sample_size_v2=0, ppl=2.15, wps=537.5, ups=0.24, wpb=2205.1, bsz=64, num_updates=6210, lr=2.42855e-05, gnorm=4.873, clip=100, loss_scale=64, train_wall=41, gb_free=7.5, wall=25088
2023-05-08 06:54:47 - progress_bar.py[line:272] - INFO: epoch 008:    170 / 866 loss=2.313, loss_v1=0, loss_v2=0, nll_loss=1.102, ntokens=2090.1, nsentences=64, sample_size=2090.1, sample_size_v1=0, sample_size_v2=0, ppl=2.15, wps=517, ups=0.25, wpb=2090.1, bsz=64, num_updates=6220, lr=2.42732e-05, gnorm=5.425, clip=100, loss_scale=64, train_wall=40, gb_free=7.6, wall=25128
2023-05-08 06:55:28 - progress_bar.py[line:272] - INFO: epoch 008:    180 / 866 loss=2.285, loss_v1=0, loss_v2=0, nll_loss=1.073, ntokens=2119.6, nsentences=64, sample_size=2119.6, sample_size_v1=0, sample_size_v2=0, ppl=2.1, wps=519.2, ups=0.24, wpb=2119.6, bsz=64, num_updates=6230, lr=2.42609e-05, gnorm=5.289, clip=100, loss_scale=64, train_wall=41, gb_free=7.2, wall=25169
2023-05-08 06:56:09 - progress_bar.py[line:272] - INFO: epoch 008:    190 / 866 loss=2.3, loss_v1=0, loss_v2=0, nll_loss=1.088, ntokens=2205.1, nsentences=64, sample_size=2205.1, sample_size_v1=0, sample_size_v2=0, ppl=2.13, wps=539.8, ups=0.24, wpb=2205.1, bsz=64, num_updates=6240, lr=2.42486e-05, gnorm=5.196, clip=100, loss_scale=64, train_wall=41, gb_free=6.9, wall=25210
2023-05-08 06:56:50 - progress_bar.py[line:272] - INFO: epoch 008:    200 / 866 loss=2.319, loss_v1=0, loss_v2=0, nll_loss=1.112, ntokens=2135.3, nsentences=64, sample_size=2135.3, sample_size_v1=0, sample_size_v2=0, ppl=2.16, wps=524, ups=0.25, wpb=2135.3, bsz=64, num_updates=6250, lr=2.42363e-05, gnorm=5.303, clip=100, loss_scale=64, train_wall=41, gb_free=8, wall=25251
2023-05-08 06:57:30 - progress_bar.py[line:272] - INFO: epoch 008:    210 / 866 loss=2.362, loss_v1=0, loss_v2=0, nll_loss=1.158, ntokens=2011.1, nsentences=64, sample_size=2011.1, sample_size_v1=0, sample_size_v2=0, ppl=2.23, wps=499.9, ups=0.25, wpb=2011.1, bsz=64, num_updates=6260, lr=2.42241e-05, gnorm=5.697, clip=100, loss_scale=64, train_wall=40, gb_free=7.5, wall=25291
2023-05-08 06:58:10 - progress_bar.py[line:272] - INFO: epoch 008:    220 / 866 loss=2.35, loss_v1=0, loss_v2=0, nll_loss=1.145, ntokens=2199.5, nsentences=64, sample_size=2199.5, sample_size_v1=0, sample_size_v2=0, ppl=2.21, wps=547.7, ups=0.25, wpb=2199.5, bsz=64, num_updates=6270, lr=2.42118e-05, gnorm=4.933, clip=100, loss_scale=64, train_wall=40, gb_free=7.5, wall=25331
2023-05-08 06:58:50 - progress_bar.py[line:272] - INFO: epoch 008:    230 / 866 loss=2.37, loss_v1=0, loss_v2=0, nll_loss=1.167, ntokens=2148.4, nsentences=64, sample_size=2148.4, sample_size_v1=0, sample_size_v2=0, ppl=2.24, wps=534.7, ups=0.25, wpb=2148.4, bsz=64, num_updates=6280, lr=2.41995e-05, gnorm=4.958, clip=100, loss_scale=64, train_wall=40, gb_free=7.3, wall=25371
2023-05-08 06:59:30 - progress_bar.py[line:272] - INFO: epoch 008:    240 / 866 loss=2.362, loss_v1=0, loss_v2=0, nll_loss=1.16, ntokens=2187.6, nsentences=64, sample_size=2187.6, sample_size_v1=0, sample_size_v2=0, ppl=2.23, wps=543.3, ups=0.25, wpb=2187.6, bsz=64, num_updates=6290, lr=2.41872e-05, gnorm=4.884, clip=100, loss_scale=64, train_wall=40, gb_free=7.1, wall=25412
2023-05-08 07:00:11 - progress_bar.py[line:272] - INFO: epoch 008:    250 / 866 loss=2.364, loss_v1=0, loss_v2=0, nll_loss=1.161, ntokens=2106.9, nsentences=64, sample_size=2106.9, sample_size_v1=0, sample_size_v2=0, ppl=2.24, wps=519.2, ups=0.25, wpb=2106.9, bsz=64, num_updates=6300, lr=2.41749e-05, gnorm=4.963, clip=100, loss_scale=64, train_wall=41, gb_free=7.1, wall=25452
2023-05-08 07:00:51 - progress_bar.py[line:272] - INFO: epoch 008:    260 / 866 loss=2.372, loss_v1=0, loss_v2=0, nll_loss=1.17, ntokens=2131.9, nsentences=64, sample_size=2131.9, sample_size_v1=0, sample_size_v2=0, ppl=2.25, wps=531.1, ups=0.25, wpb=2131.9, bsz=64, num_updates=6310, lr=2.41626e-05, gnorm=5.257, clip=100, loss_scale=64, train_wall=40, gb_free=7.4, wall=25492
2023-05-08 07:01:31 - progress_bar.py[line:272] - INFO: epoch 008:    270 / 866 loss=2.356, loss_v1=0, loss_v2=0, nll_loss=1.152, ntokens=2130.1, nsentences=64, sample_size=2130.1, sample_size_v1=0, sample_size_v2=0, ppl=2.22, wps=531, ups=0.25, wpb=2130.1, bsz=64, num_updates=6320, lr=2.41504e-05, gnorm=4.725, clip=100, loss_scale=64, train_wall=40, gb_free=7.1, wall=25532
2023-05-08 07:02:12 - progress_bar.py[line:272] - INFO: epoch 008:    280 / 866 loss=2.365, loss_v1=0, loss_v2=0, nll_loss=1.163, ntokens=2196.7, nsentences=64, sample_size=2196.7, sample_size_v1=0, sample_size_v2=0, ppl=2.24, wps=544.9, ups=0.25, wpb=2196.7, bsz=64, num_updates=6330, lr=2.41381e-05, gnorm=5.359, clip=100, loss_scale=64, train_wall=40, gb_free=7.2, wall=25573
2023-05-08 07:02:52 - progress_bar.py[line:272] - INFO: epoch 008:    290 / 866 loss=2.343, loss_v1=0, loss_v2=0, nll_loss=1.137, ntokens=2140.2, nsentences=64, sample_size=2140.2, sample_size_v1=0, sample_size_v2=0, ppl=2.2, wps=533.3, ups=0.25, wpb=2140.2, bsz=64, num_updates=6340, lr=2.41258e-05, gnorm=5.539, clip=100, loss_scale=64, train_wall=40, gb_free=8.2, wall=25613
2023-05-08 07:03:32 - progress_bar.py[line:272] - INFO: epoch 008:    300 / 866 loss=2.353, loss_v1=0, loss_v2=0, nll_loss=1.15, ntokens=2142.2, nsentences=64, sample_size=2142.2, sample_size_v1=0, sample_size_v2=0, ppl=2.22, wps=534.6, ups=0.25, wpb=2142.2, bsz=64, num_updates=6350, lr=2.41135e-05, gnorm=5.148, clip=100, loss_scale=64, train_wall=40, gb_free=6.8, wall=25653
2023-05-08 07:04:12 - progress_bar.py[line:272] - INFO: epoch 008:    310 / 866 loss=2.34, loss_v1=0, loss_v2=0, nll_loss=1.132, ntokens=2129.3, nsentences=64, sample_size=2129.3, sample_size_v1=0, sample_size_v2=0, ppl=2.19, wps=530.8, ups=0.25, wpb=2129.3, bsz=64, num_updates=6360, lr=2.41012e-05, gnorm=5.651, clip=100, loss_scale=64, train_wall=40, gb_free=7.1, wall=25693
2023-05-08 07:04:52 - progress_bar.py[line:272] - INFO: epoch 008:    320 / 866 loss=2.367, loss_v1=0, loss_v2=0, nll_loss=1.164, ntokens=1976.4, nsentences=64, sample_size=1976.4, sample_size_v1=0, sample_size_v2=0, ppl=2.24, wps=495.5, ups=0.25, wpb=1976.4, bsz=64, num_updates=6370, lr=2.40889e-05, gnorm=5.239, clip=100, loss_scale=64, train_wall=40, gb_free=7.7, wall=25733
2023-05-08 07:05:32 - progress_bar.py[line:272] - INFO: epoch 008:    330 / 866 loss=2.377, loss_v1=0, loss_v2=0, nll_loss=1.173, ntokens=2097.8, nsentences=64, sample_size=2097.8, sample_size_v1=0, sample_size_v2=0, ppl=2.26, wps=524.9, ups=0.25, wpb=2097.8, bsz=64, num_updates=6380, lr=2.40767e-05, gnorm=5.348, clip=100, loss_scale=64, train_wall=40, gb_free=7.8, wall=25773
2023-05-08 07:06:12 - progress_bar.py[line:272] - INFO: epoch 008:    340 / 866 loss=2.332, loss_v1=0, loss_v2=0, nll_loss=1.127, ntokens=2080.8, nsentences=64, sample_size=2080.8, sample_size_v1=0, sample_size_v2=0, ppl=2.18, wps=516.7, ups=0.25, wpb=2080.8, bsz=64, num_updates=6390, lr=2.40644e-05, gnorm=5.13, clip=100, loss_scale=64, train_wall=40, gb_free=7.8, wall=25813
2023-05-08 07:06:52 - progress_bar.py[line:272] - INFO: epoch 008:    350 / 866 loss=2.365, loss_v1=0, loss_v2=0, nll_loss=1.161, ntokens=1936.9, nsentences=64, sample_size=1936.9, sample_size_v1=0, sample_size_v2=0, ppl=2.24, wps=487.4, ups=0.25, wpb=1936.9, bsz=64, num_updates=6400, lr=2.40521e-05, gnorm=6.284, clip=100, loss_scale=64, train_wall=40, gb_free=8, wall=25853
2023-05-08 07:07:32 - progress_bar.py[line:272] - INFO: epoch 008:    360 / 866 loss=2.377, loss_v1=0, loss_v2=0, nll_loss=1.176, ntokens=1968.7, nsentences=64, sample_size=1968.7, sample_size_v1=0, sample_size_v2=0, ppl=2.26, wps=495, ups=0.25, wpb=1968.7, bsz=64, num_updates=6410, lr=2.40398e-05, gnorm=5.77, clip=100, loss_scale=64, train_wall=40, gb_free=7.9, wall=25893
2023-05-08 07:08:11 - progress_bar.py[line:272] - INFO: epoch 008:    370 / 866 loss=2.371, loss_v1=0, loss_v2=0, nll_loss=1.167, ntokens=1983.4, nsentences=64, sample_size=1983.4, sample_size_v1=0, sample_size_v2=0, ppl=2.25, wps=497.6, ups=0.25, wpb=1983.4, bsz=64, num_updates=6420, lr=2.40275e-05, gnorm=5.445, clip=100, loss_scale=64, train_wall=40, gb_free=8.4, wall=25933
2023-05-08 07:08:52 - progress_bar.py[line:272] - INFO: epoch 008:    380 / 866 loss=2.338, loss_v1=0, loss_v2=0, nll_loss=1.132, ntokens=2204.3, nsentences=64, sample_size=2204.3, sample_size_v1=0, sample_size_v2=0, ppl=2.19, wps=548.8, ups=0.25, wpb=2204.3, bsz=64, num_updates=6430, lr=2.40152e-05, gnorm=5.234, clip=100, loss_scale=64, train_wall=40, gb_free=8, wall=25973
2023-05-08 07:09:32 - progress_bar.py[line:272] - INFO: epoch 008:    390 / 866 loss=2.345, loss_v1=0, loss_v2=0, nll_loss=1.14, ntokens=2074.9, nsentences=64, sample_size=2074.9, sample_size_v1=0, sample_size_v2=0, ppl=2.2, wps=515.4, ups=0.25, wpb=2074.9, bsz=64, num_updates=6440, lr=2.40029e-05, gnorm=5.53, clip=100, loss_scale=64, train_wall=40, gb_free=7.4, wall=26013
2023-05-08 07:10:12 - progress_bar.py[line:272] - INFO: epoch 008:    400 / 866 loss=2.366, loss_v1=0, loss_v2=0, nll_loss=1.164, ntokens=2042.3, nsentences=64, sample_size=2042.3, sample_size_v1=0, sample_size_v2=0, ppl=2.24, wps=509.3, ups=0.25, wpb=2042.3, bsz=64, num_updates=6450, lr=2.39907e-05, gnorm=5.349, clip=100, loss_scale=64, train_wall=40, gb_free=7.6, wall=26053
2023-05-08 07:10:52 - progress_bar.py[line:272] - INFO: epoch 008:    410 / 866 loss=2.346, loss_v1=0, loss_v2=0, nll_loss=1.143, ntokens=2135.2, nsentences=64, sample_size=2135.2, sample_size_v1=0, sample_size_v2=0, ppl=2.21, wps=533.2, ups=0.25, wpb=2135.2, bsz=64, num_updates=6460, lr=2.39784e-05, gnorm=5.246, clip=100, loss_scale=64, train_wall=40, gb_free=7.5, wall=26093
2023-05-08 07:11:32 - progress_bar.py[line:272] - INFO: epoch 008:    420 / 866 loss=2.339, loss_v1=0, loss_v2=0, nll_loss=1.133, ntokens=2077.1, nsentences=64, sample_size=2077.1, sample_size_v1=0, sample_size_v2=0, ppl=2.19, wps=519, ups=0.25, wpb=2077.1, bsz=64, num_updates=6470, lr=2.39661e-05, gnorm=5.664, clip=100, loss_scale=64, train_wall=40, gb_free=7, wall=26133
2023-05-08 07:12:12 - progress_bar.py[line:272] - INFO: epoch 008:    430 / 866 loss=2.328, loss_v1=0, loss_v2=0, nll_loss=1.12, ntokens=2138.6, nsentences=64, sample_size=2138.6, sample_size_v1=0, sample_size_v2=0, ppl=2.17, wps=533.7, ups=0.25, wpb=2138.6, bsz=64, num_updates=6480, lr=2.39538e-05, gnorm=4.565, clip=100, loss_scale=64, train_wall=40, gb_free=7.6, wall=26173
2023-05-08 07:12:52 - progress_bar.py[line:272] - INFO: epoch 008:    440 / 866 loss=2.372, loss_v1=0, loss_v2=0, nll_loss=1.168, ntokens=2073.6, nsentences=64, sample_size=2073.6, sample_size_v1=0, sample_size_v2=0, ppl=2.25, wps=516.2, ups=0.25, wpb=2073.6, bsz=64, num_updates=6490, lr=2.39415e-05, gnorm=5.641, clip=100, loss_scale=64, train_wall=40, gb_free=8.1, wall=26213
2023-05-08 07:13:32 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2023-05-08 07:13:36 - progress_bar.py[line:272] - INFO: epoch 008:    451 / 866 loss=2.374, loss_v1=0, loss_v2=0, nll_loss=1.173, ntokens=1967.6, nsentences=64, sample_size=1967.6, sample_size_v1=0, sample_size_v2=0, ppl=2.26, wps=448.7, ups=0.23, wpb=1967.6, bsz=64, num_updates=6500, lr=2.39292e-05, gnorm=6.176, clip=100, loss_scale=64, train_wall=44, gb_free=7.1, wall=26257
2023-05-08 07:14:16 - progress_bar.py[line:272] - INFO: epoch 008:    461 / 866 loss=2.36, loss_v1=0, loss_v2=0, nll_loss=1.156, ntokens=2166.2, nsentences=64, sample_size=2166.2, sample_size_v1=0, sample_size_v2=0, ppl=2.23, wps=537.9, ups=0.25, wpb=2166.2, bsz=64, num_updates=6510, lr=2.3917e-05, gnorm=5.932, clip=100, loss_scale=64, train_wall=40, gb_free=7.4, wall=26298
2023-05-08 07:14:57 - progress_bar.py[line:272] - INFO: epoch 008:    471 / 866 loss=2.349, loss_v1=0, loss_v2=0, nll_loss=1.145, ntokens=2148.8, nsentences=64, sample_size=2148.8, sample_size_v1=0, sample_size_v2=0, ppl=2.21, wps=535.2, ups=0.25, wpb=2148.8, bsz=64, num_updates=6520, lr=2.39047e-05, gnorm=5.393, clip=100, loss_scale=64, train_wall=40, gb_free=8, wall=26338
2023-05-08 07:15:37 - progress_bar.py[line:272] - INFO: epoch 008:    481 / 866 loss=2.356, loss_v1=0, loss_v2=0, nll_loss=1.15, ntokens=2201, nsentences=64, sample_size=2201, sample_size_v1=0, sample_size_v2=0, ppl=2.22, wps=545.2, ups=0.25, wpb=2201, bsz=64, num_updates=6530, lr=2.38924e-05, gnorm=5.352, clip=100, loss_scale=64, train_wall=40, gb_free=8.4, wall=26378
2023-05-08 07:16:17 - progress_bar.py[line:272] - INFO: epoch 008:    491 / 866 loss=2.336, loss_v1=0, loss_v2=0, nll_loss=1.13, ntokens=2074.4, nsentences=64, sample_size=2074.4, sample_size_v1=0, sample_size_v2=0, ppl=2.19, wps=516.6, ups=0.25, wpb=2074.4, bsz=64, num_updates=6540, lr=2.38801e-05, gnorm=5.553, clip=100, loss_scale=64, train_wall=40, gb_free=7, wall=26418
2023-05-08 07:16:57 - progress_bar.py[line:272] - INFO: epoch 008:    501 / 866 loss=2.341, loss_v1=0, loss_v2=0, nll_loss=1.136, ntokens=2027.2, nsentences=64, sample_size=2027.2, sample_size_v1=0, sample_size_v2=0, ppl=2.2, wps=506.4, ups=0.25, wpb=2027.2, bsz=64, num_updates=6550, lr=2.38678e-05, gnorm=5.867, clip=100, loss_scale=64, train_wall=40, gb_free=8.1, wall=26458
2023-05-08 07:17:37 - progress_bar.py[line:272] - INFO: epoch 008:    511 / 866 loss=2.383, loss_v1=0, loss_v2=0, nll_loss=1.18, ntokens=2140.6, nsentences=64, sample_size=2140.6, sample_size_v1=0, sample_size_v2=0, ppl=2.27, wps=535.2, ups=0.25, wpb=2140.6, bsz=64, num_updates=6560, lr=2.38555e-05, gnorm=5.642, clip=100, loss_scale=64, train_wall=40, gb_free=8.4, wall=26498
2023-05-08 07:18:17 - progress_bar.py[line:272] - INFO: epoch 008:    521 / 866 loss=2.329, loss_v1=0, loss_v2=0, nll_loss=1.123, ntokens=2179.5, nsentences=64, sample_size=2179.5, sample_size_v1=0, sample_size_v2=0, ppl=2.18, wps=546.9, ups=0.25, wpb=2179.5, bsz=64, num_updates=6570, lr=2.38433e-05, gnorm=5.84, clip=100, loss_scale=64, train_wall=40, gb_free=7.7, wall=26538
2023-05-08 07:18:57 - progress_bar.py[line:272] - INFO: epoch 008:    531 / 866 loss=2.351, loss_v1=0, loss_v2=0, nll_loss=1.147, ntokens=2003.1, nsentences=64, sample_size=2003.1, sample_size_v1=0, sample_size_v2=0, ppl=2.21, wps=499.1, ups=0.25, wpb=2003.1, bsz=64, num_updates=6580, lr=2.3831e-05, gnorm=6.125, clip=100, loss_scale=64, train_wall=40, gb_free=7.9, wall=26578
2023-05-08 07:19:37 - progress_bar.py[line:272] - INFO: epoch 008:    541 / 866 loss=2.348, loss_v1=0, loss_v2=0, nll_loss=1.142, ntokens=2145.8, nsentences=64, sample_size=2145.8, sample_size_v1=0, sample_size_v2=0, ppl=2.21, wps=533.9, ups=0.25, wpb=2145.8, bsz=64, num_updates=6590, lr=2.38187e-05, gnorm=5.384, clip=100, loss_scale=64, train_wall=40, gb_free=8.3, wall=26618
2023-05-08 07:20:18 - progress_bar.py[line:272] - INFO: epoch 008:    551 / 866 loss=2.371, loss_v1=0, loss_v2=0, nll_loss=1.17, ntokens=2299.8, nsentences=64, sample_size=2299.8, sample_size_v1=0, sample_size_v2=0, ppl=2.25, wps=568.7, ups=0.25, wpb=2299.8, bsz=64, num_updates=6600, lr=2.38064e-05, gnorm=5.214, clip=100, loss_scale=64, train_wall=40, gb_free=7.6, wall=26659
2023-05-08 07:20:58 - progress_bar.py[line:272] - INFO: epoch 008:    561 / 866 loss=2.348, loss_v1=0, loss_v2=0, nll_loss=1.142, ntokens=2246, nsentences=64, sample_size=2246, sample_size_v1=0, sample_size_v2=0, ppl=2.21, wps=556.8, ups=0.25, wpb=2246, bsz=64, num_updates=6610, lr=2.37941e-05, gnorm=5.563, clip=100, loss_scale=64, train_wall=40, gb_free=7.7, wall=26699
2023-05-08 07:21:38 - progress_bar.py[line:272] - INFO: epoch 008:    571 / 866 loss=2.362, loss_v1=0, loss_v2=0, nll_loss=1.158, ntokens=2220.8, nsentences=64, sample_size=2220.8, sample_size_v1=0, sample_size_v2=0, ppl=2.23, wps=554.4, ups=0.25, wpb=2220.8, bsz=64, num_updates=6620, lr=2.37818e-05, gnorm=5.262, clip=100, loss_scale=64, train_wall=40, gb_free=8.3, wall=26739
2023-05-08 07:22:19 - progress_bar.py[line:272] - INFO: epoch 008:    581 / 866 loss=2.361, loss_v1=0, loss_v2=0, nll_loss=1.158, ntokens=2124.7, nsentences=64, sample_size=2124.7, sample_size_v1=0, sample_size_v2=0, ppl=2.23, wps=525.7, ups=0.25, wpb=2124.7, bsz=64, num_updates=6630, lr=2.37696e-05, gnorm=5.463, clip=100, loss_scale=64, train_wall=40, gb_free=6.9, wall=26780
2023-05-08 07:22:59 - progress_bar.py[line:272] - INFO: epoch 008:    591 / 866 loss=2.361, loss_v1=0, loss_v2=0, nll_loss=1.156, ntokens=2033, nsentences=64, sample_size=2033, sample_size_v1=0, sample_size_v2=0, ppl=2.23, wps=505.1, ups=0.25, wpb=2033, bsz=64, num_updates=6640, lr=2.37573e-05, gnorm=5.663, clip=100, loss_scale=64, train_wall=40, gb_free=6.9, wall=26820
2023-05-08 07:23:39 - progress_bar.py[line:272] - INFO: epoch 008:    601 / 866 loss=2.309, loss_v1=0, loss_v2=0, nll_loss=1.102, ntokens=2167.4, nsentences=64, sample_size=2167.4, sample_size_v1=0, sample_size_v2=0, ppl=2.15, wps=538, ups=0.25, wpb=2167.4, bsz=64, num_updates=6650, lr=2.3745e-05, gnorm=5.244, clip=100, loss_scale=64, train_wall=40, gb_free=8, wall=26860
2023-05-08 07:24:19 - progress_bar.py[line:272] - INFO: epoch 008:    611 / 866 loss=2.359, loss_v1=0, loss_v2=0, nll_loss=1.154, ntokens=1954.2, nsentences=64, sample_size=1954.2, sample_size_v1=0, sample_size_v2=0, ppl=2.23, wps=488.7, ups=0.25, wpb=1954.2, bsz=64, num_updates=6660, lr=2.37327e-05, gnorm=6.028, clip=100, loss_scale=64, train_wall=40, gb_free=8.3, wall=26900
2023-05-08 07:24:59 - progress_bar.py[line:272] - INFO: epoch 008:    621 / 866 loss=2.365, loss_v1=0, loss_v2=0, nll_loss=1.16, ntokens=2011.9, nsentences=64, sample_size=2011.9, sample_size_v1=0, sample_size_v2=0, ppl=2.23, wps=502.6, ups=0.25, wpb=2011.9, bsz=64, num_updates=6670, lr=2.37204e-05, gnorm=5.516, clip=100, loss_scale=64, train_wall=40, gb_free=8.1, wall=26940
2023-05-08 07:25:39 - progress_bar.py[line:272] - INFO: epoch 008:    631 / 866 loss=2.338, loss_v1=0, loss_v2=0, nll_loss=1.132, ntokens=2024.1, nsentences=64, sample_size=2024.1, sample_size_v1=0, sample_size_v2=0, ppl=2.19, wps=506.9, ups=0.25, wpb=2024.1, bsz=64, num_updates=6680, lr=2.37081e-05, gnorm=5.731, clip=100, loss_scale=64, train_wall=40, gb_free=7.5, wall=26980
2023-05-08 07:26:19 - progress_bar.py[line:272] - INFO: epoch 008:    641 / 866 loss=2.329, loss_v1=0, loss_v2=0, nll_loss=1.121, ntokens=2038, nsentences=64, sample_size=2038, sample_size_v1=0, sample_size_v2=0, ppl=2.18, wps=510.6, ups=0.25, wpb=2038, bsz=64, num_updates=6690, lr=2.36958e-05, gnorm=5.997, clip=100, loss_scale=64, train_wall=40, gb_free=8.3, wall=27020
2023-05-08 07:26:59 - progress_bar.py[line:272] - INFO: epoch 008:    651 / 866 loss=2.357, loss_v1=0, loss_v2=0, nll_loss=1.152, ntokens=2054.8, nsentences=64, sample_size=2054.8, sample_size_v1=0, sample_size_v2=0, ppl=2.22, wps=516.7, ups=0.25, wpb=2054.8, bsz=64, num_updates=6700, lr=2.36836e-05, gnorm=5.227, clip=100, loss_scale=64, train_wall=40, gb_free=8, wall=27060
2023-05-08 07:27:39 - progress_bar.py[line:272] - INFO: epoch 008:    661 / 866 loss=2.384, loss_v1=0, loss_v2=0, nll_loss=1.185, ntokens=1912, nsentences=64, sample_size=1912, sample_size_v1=0, sample_size_v2=0, ppl=2.27, wps=481.3, ups=0.25, wpb=1912, bsz=64, num_updates=6710, lr=2.36713e-05, gnorm=5.957, clip=100, loss_scale=64, train_wall=40, gb_free=7.8, wall=27100
2023-05-08 07:28:19 - progress_bar.py[line:272] - INFO: epoch 008:    671 / 866 loss=2.352, loss_v1=0, loss_v2=0, nll_loss=1.145, ntokens=2020, nsentences=64, sample_size=2020, sample_size_v1=0, sample_size_v2=0, ppl=2.21, wps=502.3, ups=0.25, wpb=2020, bsz=64, num_updates=6720, lr=2.3659e-05, gnorm=5.291, clip=100, loss_scale=64, train_wall=40, gb_free=7.8, wall=27140
2023-05-08 07:28:59 - progress_bar.py[line:272] - INFO: epoch 008:    681 / 866 loss=2.335, loss_v1=0, loss_v2=0, nll_loss=1.13, ntokens=2053.7, nsentences=64, sample_size=2053.7, sample_size_v1=0, sample_size_v2=0, ppl=2.19, wps=513.9, ups=0.25, wpb=2053.7, bsz=64, num_updates=6730, lr=2.36467e-05, gnorm=5.538, clip=100, loss_scale=64, train_wall=40, gb_free=7.3, wall=27180
2023-05-08 07:29:39 - progress_bar.py[line:272] - INFO: epoch 008:    691 / 866 loss=2.353, loss_v1=0, loss_v2=0, nll_loss=1.149, ntokens=2002, nsentences=64, sample_size=2002, sample_size_v1=0, sample_size_v2=0, ppl=2.22, wps=500.3, ups=0.25, wpb=2002, bsz=64, num_updates=6740, lr=2.36344e-05, gnorm=5.626, clip=100, loss_scale=64, train_wall=40, gb_free=8, wall=27220
2023-05-08 07:30:19 - progress_bar.py[line:272] - INFO: epoch 008:    701 / 866 loss=2.355, loss_v1=0, loss_v2=0, nll_loss=1.15, ntokens=2092.2, nsentences=64, sample_size=2092.2, sample_size_v1=0, sample_size_v2=0, ppl=2.22, wps=522.4, ups=0.25, wpb=2092.2, bsz=64, num_updates=6750, lr=2.36221e-05, gnorm=5.654, clip=100, loss_scale=64, train_wall=40, gb_free=8.1, wall=27260
2023-05-08 07:30:59 - progress_bar.py[line:272] - INFO: epoch 008:    711 / 866 loss=2.373, loss_v1=0, loss_v2=0, nll_loss=1.172, ntokens=1922.9, nsentences=64, sample_size=1922.9, sample_size_v1=0, sample_size_v2=0, ppl=2.25, wps=481.9, ups=0.25, wpb=1922.9, bsz=64, num_updates=6760, lr=2.36099e-05, gnorm=6.618, clip=100, loss_scale=64, train_wall=40, gb_free=8.1, wall=27300
2023-05-08 07:31:39 - progress_bar.py[line:272] - INFO: epoch 008:    721 / 866 loss=2.346, loss_v1=0, loss_v2=0, nll_loss=1.141, ntokens=1920.7, nsentences=64, sample_size=1920.7, sample_size_v1=0, sample_size_v2=0, ppl=2.21, wps=480.4, ups=0.25, wpb=1920.7, bsz=64, num_updates=6770, lr=2.35976e-05, gnorm=6.028, clip=100, loss_scale=64, train_wall=40, gb_free=7.7, wall=27340
2023-05-08 07:32:19 - progress_bar.py[line:272] - INFO: epoch 008:    731 / 866 loss=2.326, loss_v1=0, loss_v2=0, nll_loss=1.117, ntokens=2019.1, nsentences=64, sample_size=2019.1, sample_size_v1=0, sample_size_v2=0, ppl=2.17, wps=505.4, ups=0.25, wpb=2019.1, bsz=64, num_updates=6780, lr=2.35853e-05, gnorm=5.553, clip=100, loss_scale=64, train_wall=40, gb_free=7.8, wall=27380
2023-05-08 07:32:59 - progress_bar.py[line:272] - INFO: epoch 008:    741 / 866 loss=2.332, loss_v1=0, loss_v2=0, nll_loss=1.124, ntokens=2131.3, nsentences=64, sample_size=2131.3, sample_size_v1=0, sample_size_v2=0, ppl=2.18, wps=531.4, ups=0.25, wpb=2131.3, bsz=64, num_updates=6790, lr=2.3573e-05, gnorm=5.218, clip=100, loss_scale=64, train_wall=40, gb_free=7.8, wall=27420
2023-05-08 07:33:39 - progress_bar.py[line:272] - INFO: epoch 008:    751 / 866 loss=2.323, loss_v1=0, loss_v2=0, nll_loss=1.114, ntokens=2103.9, nsentences=64, sample_size=2103.9, sample_size_v1=0, sample_size_v2=0, ppl=2.16, wps=523.2, ups=0.25, wpb=2103.9, bsz=64, num_updates=6800, lr=2.35607e-05, gnorm=5.583, clip=100, loss_scale=64, train_wall=40, gb_free=7.3, wall=27460
2023-05-08 07:34:19 - progress_bar.py[line:272] - INFO: epoch 008:    761 / 866 loss=2.333, loss_v1=0, loss_v2=0, nll_loss=1.129, ntokens=2112.8, nsentences=64, sample_size=2112.8, sample_size_v1=0, sample_size_v2=0, ppl=2.19, wps=525.3, ups=0.25, wpb=2112.8, bsz=64, num_updates=6810, lr=2.35484e-05, gnorm=5.668, clip=100, loss_scale=64, train_wall=40, gb_free=7.8, wall=27500
2023-05-08 07:34:59 - progress_bar.py[line:272] - INFO: epoch 008:    771 / 866 loss=2.327, loss_v1=0, loss_v2=0, nll_loss=1.118, ntokens=2055, nsentences=64, sample_size=2055, sample_size_v1=0, sample_size_v2=0, ppl=2.17, wps=514.5, ups=0.25, wpb=2055, bsz=64, num_updates=6820, lr=2.35362e-05, gnorm=6.071, clip=100, loss_scale=64, train_wall=40, gb_free=8, wall=27540
2023-05-08 07:35:40 - progress_bar.py[line:272] - INFO: epoch 008:    781 / 866 loss=2.316, loss_v1=0, loss_v2=0, nll_loss=1.106, ntokens=2337.4, nsentences=64, sample_size=2337.4, sample_size_v1=0, sample_size_v2=0, ppl=2.15, wps=578.1, ups=0.25, wpb=2337.4, bsz=64, num_updates=6830, lr=2.35239e-05, gnorm=5.272, clip=100, loss_scale=64, train_wall=40, gb_free=8, wall=27581
2023-05-08 07:36:19 - progress_bar.py[line:272] - INFO: epoch 008:    791 / 866 loss=2.357, loss_v1=0, loss_v2=0, nll_loss=1.153, ntokens=1979.7, nsentences=64, sample_size=1979.7, sample_size_v1=0, sample_size_v2=0, ppl=2.22, wps=496.9, ups=0.25, wpb=1979.7, bsz=64, num_updates=6840, lr=2.35116e-05, gnorm=6.276, clip=100, loss_scale=64, train_wall=40, gb_free=7.7, wall=27621
2023-05-08 07:36:59 - progress_bar.py[line:272] - INFO: epoch 008:    801 / 866 loss=2.343, loss_v1=0, loss_v2=0, nll_loss=1.137, ntokens=2007.4, nsentences=64, sample_size=2007.4, sample_size_v1=0, sample_size_v2=0, ppl=2.2, wps=504.3, ups=0.25, wpb=2007.4, bsz=64, num_updates=6850, lr=2.34993e-05, gnorm=5.396, clip=100, loss_scale=64, train_wall=40, gb_free=7.4, wall=27660
2023-05-08 07:37:39 - progress_bar.py[line:272] - INFO: epoch 008:    811 / 866 loss=2.316, loss_v1=0, loss_v2=0, nll_loss=1.108, ntokens=2059.7, nsentences=64, sample_size=2059.7, sample_size_v1=0, sample_size_v2=0, ppl=2.16, wps=512.1, ups=0.25, wpb=2059.7, bsz=64, num_updates=6860, lr=2.3487e-05, gnorm=6.049, clip=100, loss_scale=64, train_wall=40, gb_free=7.9, wall=27701
2023-05-08 07:38:20 - progress_bar.py[line:272] - INFO: epoch 008:    821 / 866 loss=2.324, loss_v1=0, loss_v2=0, nll_loss=1.116, ntokens=2072.2, nsentences=64, sample_size=2072.2, sample_size_v1=0, sample_size_v2=0, ppl=2.17, wps=516.3, ups=0.25, wpb=2072.2, bsz=64, num_updates=6870, lr=2.34747e-05, gnorm=5.355, clip=100, loss_scale=64, train_wall=40, gb_free=6.3, wall=27741
2023-05-08 07:39:00 - progress_bar.py[line:272] - INFO: epoch 008:    831 / 866 loss=2.325, loss_v1=0, loss_v2=0, nll_loss=1.117, ntokens=2201.4, nsentences=64, sample_size=2201.4, sample_size_v1=0, sample_size_v2=0, ppl=2.17, wps=539.7, ups=0.25, wpb=2201.4, bsz=64, num_updates=6880, lr=2.34625e-05, gnorm=4.834, clip=100, loss_scale=64, train_wall=41, gb_free=7.9, wall=27781
2023-05-08 07:39:41 - progress_bar.py[line:272] - INFO: epoch 008:    841 / 866 loss=2.34, loss_v1=0, loss_v2=0, nll_loss=1.135, ntokens=2111.2, nsentences=64, sample_size=2111.2, sample_size_v1=0, sample_size_v2=0, ppl=2.2, wps=524.9, ups=0.25, wpb=2111.2, bsz=64, num_updates=6890, lr=2.34502e-05, gnorm=5.316, clip=100, loss_scale=64, train_wall=40, gb_free=8.1, wall=27822
2023-05-08 07:40:21 - progress_bar.py[line:272] - INFO: epoch 008:    851 / 866 loss=2.329, loss_v1=0, loss_v2=0, nll_loss=1.122, ntokens=2219.1, nsentences=64, sample_size=2219.1, sample_size_v1=0, sample_size_v2=0, ppl=2.18, wps=548.9, ups=0.25, wpb=2219.1, bsz=64, num_updates=6900, lr=2.34379e-05, gnorm=5.045, clip=100, loss_scale=64, train_wall=40, gb_free=7.7, wall=27862
2023-05-08 07:41:01 - progress_bar.py[line:272] - INFO: epoch 008:    861 / 866 loss=2.344, loss_v1=0, loss_v2=0, nll_loss=1.137, ntokens=2050.8, nsentences=64, sample_size=2050.8, sample_size_v1=0, sample_size_v2=0, ppl=2.2, wps=511.8, ups=0.25, wpb=2050.8, bsz=64, num_updates=6910, lr=2.34256e-05, gnorm=5.89, clip=100, loss_scale=64, train_wall=40, gb_free=7.6, wall=27902
2023-05-08 07:41:20 - train.py[line:332] - INFO: end of epoch 8 (average epoch stats below)
local datafile ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 1 begin to initialize row_count and line_idx-to-offset mapping
2023-05-08 07:41:20 - progress_bar.py[line:282] - INFO: epoch 008 | loss 2.335 | loss_v1 0 | loss_v2 0 | nll_loss 1.128 | ntokens 2103.38 | nsentences 63.972 | sample_size 2103.38 | sample_size_v1 0 | sample_size_v2 0 | ppl 2.19 | wps 521.6 | ups 0.25 | wpb 2103.4 | bsz 64 | num_updates 6915 | lr 2.34195e-05 | gnorm 5.441 | clip 100 | loss_scale 64 | train_wall 3482 | gb_free 8.7 | wall 27921
2023-05-08 07:41:20 - trainer.py[line:639] - INFO: loading train data for epoch 9
local datafile ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 0 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 1 finished initializing row_count and line_idx-to-offset mapping
file ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 1 row count 27700 total row count 55400
slice_id 1 seek offset 27700
local datafile ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 0 finished initializing row_count and line_idx-to-offset mapping
file ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 0 row count 27700 total row count 55400
slice_id 0 seek offset 0
2023-05-08 07:41:21 - trainer.py[line:703] - INFO: begin training epoch 9
2023-05-08 07:41:21 - train.py[line:305] - INFO: Start iterating over samples
2023-05-08 07:41:42 - progress_bar.py[line:272] - INFO: epoch 009:      5 / 866 loss=2.327, loss_v1=0, loss_v2=0, nll_loss=1.12, ntokens=2048.9, nsentences=61.6, sample_size=2048.9, sample_size_v1=0, sample_size_v2=0, ppl=2.17, wps=499.2, ups=0.24, wpb=2048.9, bsz=61.6, num_updates=6920, lr=2.34133e-05, gnorm=5.47, clip=100, loss_scale=64, train_wall=39, gb_free=7.5, wall=27943
2023-05-08 07:42:23 - progress_bar.py[line:272] - INFO: epoch 009:     15 / 866 loss=2.3, loss_v1=0, loss_v2=0, nll_loss=1.089, ntokens=2078.3, nsentences=64, sample_size=2078.3, sample_size_v1=0, sample_size_v2=0, ppl=2.13, wps=514.1, ups=0.25, wpb=2078.3, bsz=64, num_updates=6930, lr=2.3401e-05, gnorm=5.691, clip=100, loss_scale=64, train_wall=40, gb_free=7.3, wall=27984
2023-05-08 07:43:03 - progress_bar.py[line:272] - INFO: epoch 009:     25 / 866 loss=2.275, loss_v1=0, loss_v2=0, nll_loss=1.061, ntokens=1994.7, nsentences=64, sample_size=1994.7, sample_size_v1=0, sample_size_v2=0, ppl=2.09, wps=495.1, ups=0.25, wpb=1994.7, bsz=64, num_updates=6940, lr=2.33887e-05, gnorm=5.467, clip=100, loss_scale=64, train_wall=40, gb_free=8.3, wall=28024
2023-05-08 07:43:44 - progress_bar.py[line:272] - INFO: epoch 009:     35 / 866 loss=2.239, loss_v1=0, loss_v2=0, nll_loss=1.023, ntokens=2148.6, nsentences=64, sample_size=2148.6, sample_size_v1=0, sample_size_v2=0, ppl=2.03, wps=527.1, ups=0.25, wpb=2148.6, bsz=64, num_updates=6950, lr=2.33765e-05, gnorm=5.408, clip=100, loss_scale=64, train_wall=41, gb_free=7.3, wall=28065
2023-05-08 07:44:24 - progress_bar.py[line:272] - INFO: epoch 009:     45 / 866 loss=2.248, loss_v1=0, loss_v2=0, nll_loss=1.031, ntokens=2074.7, nsentences=64, sample_size=2074.7, sample_size_v1=0, sample_size_v2=0, ppl=2.04, wps=510.7, ups=0.25, wpb=2074.7, bsz=64, num_updates=6960, lr=2.33642e-05, gnorm=5.048, clip=100, loss_scale=64, train_wall=41, gb_free=6.9, wall=28105
2023-05-08 07:45:05 - progress_bar.py[line:272] - INFO: epoch 009:     55 / 866 loss=2.245, loss_v1=0, loss_v2=0, nll_loss=1.028, ntokens=2045.2, nsentences=64, sample_size=2045.2, sample_size_v1=0, sample_size_v2=0, ppl=2.04, wps=506.1, ups=0.25, wpb=2045.2, bsz=64, num_updates=6970, lr=2.33519e-05, gnorm=5.601, clip=100, loss_scale=64, train_wall=40, gb_free=7.3, wall=28146
2023-05-08 07:45:46 - progress_bar.py[line:272] - INFO: epoch 009:     65 / 866 loss=2.153, loss_v1=0, loss_v2=0, nll_loss=0.926, ntokens=2303.2, nsentences=64, sample_size=2303.2, sample_size_v1=0, sample_size_v2=0, ppl=1.9, wps=559.8, ups=0.24, wpb=2303.2, bsz=64, num_updates=6980, lr=2.33396e-05, gnorm=4.446, clip=100, loss_scale=64, train_wall=41, gb_free=6.7, wall=28187
2023-05-08 07:46:07 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2023-05-08 07:46:32 - progress_bar.py[line:272] - INFO: epoch 009:     76 / 866 loss=2.195, loss_v1=0, loss_v2=0, nll_loss=0.971, ntokens=2407.2, nsentences=64, sample_size=2407.2, sample_size_v1=0, sample_size_v2=0, ppl=1.96, wps=524.5, ups=0.22, wpb=2407.2, bsz=64, num_updates=6990, lr=2.33273e-05, gnorm=4.237, clip=100, loss_scale=32, train_wall=46, gb_free=6.3, wall=28233
2023-05-08 07:47:13 - progress_bar.py[line:272] - INFO: epoch 009:     86 / 866 loss=2.267, loss_v1=0, loss_v2=0, nll_loss=1.052, ntokens=2127.2, nsentences=64, sample_size=2127.2, sample_size_v1=0, sample_size_v2=0, ppl=2.07, wps=518.4, ups=0.24, wpb=2127.2, bsz=64, num_updates=7000, lr=2.3315e-05, gnorm=5.338, clip=100, loss_scale=32, train_wall=41, gb_free=7.1, wall=28274
2023-05-08 07:47:54 - progress_bar.py[line:272] - INFO: epoch 009:     96 / 866 loss=2.243, loss_v1=0, loss_v2=0, nll_loss=1.028, ntokens=2135.5, nsentences=64, sample_size=2135.5, sample_size_v1=0, sample_size_v2=0, ppl=2.04, wps=522.3, ups=0.24, wpb=2135.5, bsz=64, num_updates=7010, lr=2.33028e-05, gnorm=5.065, clip=100, loss_scale=32, train_wall=41, gb_free=6.6, wall=28315
2023-05-08 07:48:34 - progress_bar.py[line:272] - INFO: epoch 009:    106 / 866 loss=2.327, loss_v1=0, loss_v2=0, nll_loss=1.12, ntokens=2037, nsentences=64, sample_size=2037, sample_size_v1=0, sample_size_v2=0, ppl=2.17, wps=506.3, ups=0.25, wpb=2037, bsz=64, num_updates=7020, lr=2.32905e-05, gnorm=5.313, clip=100, loss_scale=32, train_wall=40, gb_free=6.5, wall=28355
2023-05-08 07:49:15 - progress_bar.py[line:272] - INFO: epoch 009:    116 / 866 loss=2.335, loss_v1=0, loss_v2=0, nll_loss=1.128, ntokens=2065.5, nsentences=64, sample_size=2065.5, sample_size_v1=0, sample_size_v2=0, ppl=2.19, wps=508.5, ups=0.25, wpb=2065.5, bsz=64, num_updates=7030, lr=2.32782e-05, gnorm=4.898, clip=100, loss_scale=32, train_wall=41, gb_free=6.7, wall=28396
2023-05-08 07:49:56 - progress_bar.py[line:272] - INFO: epoch 009:    126 / 866 loss=2.31, loss_v1=0, loss_v2=0, nll_loss=1.099, ntokens=2234.5, nsentences=64, sample_size=2234.5, sample_size_v1=0, sample_size_v2=0, ppl=2.14, wps=542.3, ups=0.24, wpb=2234.5, bsz=64, num_updates=7040, lr=2.32659e-05, gnorm=4.693, clip=100, loss_scale=32, train_wall=41, gb_free=7.5, wall=28437
2023-05-08 07:50:37 - progress_bar.py[line:272] - INFO: epoch 009:    136 / 866 loss=2.288, loss_v1=0, loss_v2=0, nll_loss=1.077, ntokens=2248.4, nsentences=64, sample_size=2248.4, sample_size_v1=0, sample_size_v2=0, ppl=2.11, wps=549.4, ups=0.24, wpb=2248.4, bsz=64, num_updates=7050, lr=2.32536e-05, gnorm=4.379, clip=100, loss_scale=32, train_wall=41, gb_free=6.6, wall=28478
2023-05-08 07:51:18 - progress_bar.py[line:272] - INFO: epoch 009:    146 / 866 loss=2.276, loss_v1=0, loss_v2=0, nll_loss=1.062, ntokens=2176.4, nsentences=64, sample_size=2176.4, sample_size_v1=0, sample_size_v2=0, ppl=2.09, wps=526.9, ups=0.24, wpb=2176.4, bsz=64, num_updates=7060, lr=2.32413e-05, gnorm=4.654, clip=100, loss_scale=32, train_wall=41, gb_free=6.9, wall=28519
2023-05-08 07:51:59 - progress_bar.py[line:272] - INFO: epoch 009:    156 / 866 loss=2.298, loss_v1=0, loss_v2=0, nll_loss=1.087, ntokens=2231.2, nsentences=64, sample_size=2231.2, sample_size_v1=0, sample_size_v2=0, ppl=2.12, wps=539.1, ups=0.24, wpb=2231.2, bsz=64, num_updates=7070, lr=2.32291e-05, gnorm=4.995, clip=100, loss_scale=32, train_wall=41, gb_free=7.2, wall=28560
2023-05-08 07:52:40 - progress_bar.py[line:272] - INFO: epoch 009:    166 / 866 loss=2.287, loss_v1=0, loss_v2=0, nll_loss=1.075, ntokens=2161.1, nsentences=64, sample_size=2161.1, sample_size_v1=0, sample_size_v2=0, ppl=2.11, wps=532.3, ups=0.25, wpb=2161.1, bsz=64, num_updates=7080, lr=2.32168e-05, gnorm=5.593, clip=100, loss_scale=32, train_wall=41, gb_free=6.6, wall=28601
2023-05-08 07:53:21 - progress_bar.py[line:272] - INFO: epoch 009:    176 / 866 loss=2.303, loss_v1=0, loss_v2=0, nll_loss=1.091, ntokens=2050, nsentences=64, sample_size=2050, sample_size_v1=0, sample_size_v2=0, ppl=2.13, wps=505.5, ups=0.25, wpb=2050, bsz=64, num_updates=7090, lr=2.32045e-05, gnorm=5.358, clip=100, loss_scale=32, train_wall=41, gb_free=7.1, wall=28642
2023-05-08 07:54:02 - progress_bar.py[line:272] - INFO: epoch 009:    186 / 866 loss=2.274, loss_v1=0, loss_v2=0, nll_loss=1.062, ntokens=2187.5, nsentences=64, sample_size=2187.5, sample_size_v1=0, sample_size_v2=0, ppl=2.09, wps=533.9, ups=0.24, wpb=2187.5, bsz=64, num_updates=7100, lr=2.31922e-05, gnorm=4.685, clip=100, loss_scale=32, train_wall=41, gb_free=7.3, wall=28683
2023-05-08 07:54:42 - progress_bar.py[line:272] - INFO: epoch 009:    196 / 866 loss=2.293, loss_v1=0, loss_v2=0, nll_loss=1.081, ntokens=2200.1, nsentences=64, sample_size=2200.1, sample_size_v1=0, sample_size_v2=0, ppl=2.11, wps=537.3, ups=0.24, wpb=2200.1, bsz=64, num_updates=7110, lr=2.31799e-05, gnorm=5.03, clip=100, loss_scale=32, train_wall=41, gb_free=7.4, wall=28724
2023-05-08 07:55:23 - progress_bar.py[line:272] - INFO: epoch 009:    206 / 866 loss=2.334, loss_v1=0, loss_v2=0, nll_loss=1.128, ntokens=1976.2, nsentences=64, sample_size=1976.2, sample_size_v1=0, sample_size_v2=0, ppl=2.19, wps=491.3, ups=0.25, wpb=1976.2, bsz=64, num_updates=7120, lr=2.31676e-05, gnorm=5.496, clip=100, loss_scale=32, train_wall=40, gb_free=7.7, wall=28764
2023-05-08 07:56:03 - progress_bar.py[line:272] - INFO: epoch 009:    216 / 866 loss=2.338, loss_v1=0, loss_v2=0, nll_loss=1.13, ntokens=2173.5, nsentences=64, sample_size=2173.5, sample_size_v1=0, sample_size_v2=0, ppl=2.19, wps=539.2, ups=0.25, wpb=2173.5, bsz=64, num_updates=7130, lr=2.31554e-05, gnorm=5.061, clip=100, loss_scale=32, train_wall=40, gb_free=8.1, wall=28804
2023-05-08 07:56:43 - progress_bar.py[line:272] - INFO: epoch 009:    226 / 866 loss=2.334, loss_v1=0, loss_v2=0, nll_loss=1.128, ntokens=2179, nsentences=64, sample_size=2179, sample_size_v1=0, sample_size_v2=0, ppl=2.19, wps=539.7, ups=0.25, wpb=2179, bsz=64, num_updates=7140, lr=2.31431e-05, gnorm=5.118, clip=100, loss_scale=32, train_wall=40, gb_free=7.8, wall=28844
2023-05-08 07:57:24 - progress_bar.py[line:272] - INFO: epoch 009:    236 / 866 loss=2.368, loss_v1=0, loss_v2=0, nll_loss=1.164, ntokens=2107.4, nsentences=64, sample_size=2107.4, sample_size_v1=0, sample_size_v2=0, ppl=2.24, wps=524.2, ups=0.25, wpb=2107.4, bsz=64, num_updates=7150, lr=2.31308e-05, gnorm=5.563, clip=100, loss_scale=32, train_wall=40, gb_free=7.7, wall=28885
2023-05-08 07:58:04 - progress_bar.py[line:272] - INFO: epoch 009:    246 / 866 loss=2.344, loss_v1=0, loss_v2=0, nll_loss=1.14, ntokens=2213.1, nsentences=64, sample_size=2213.1, sample_size_v1=0, sample_size_v2=0, ppl=2.2, wps=549.3, ups=0.25, wpb=2213.1, bsz=64, num_updates=7160, lr=2.31185e-05, gnorm=4.542, clip=100, loss_scale=32, train_wall=40, gb_free=8, wall=28925
2023-05-08 07:58:44 - progress_bar.py[line:272] - INFO: epoch 009:    256 / 866 loss=2.34, loss_v1=0, loss_v2=0, nll_loss=1.135, ntokens=2108.5, nsentences=64, sample_size=2108.5, sample_size_v1=0, sample_size_v2=0, ppl=2.2, wps=524.4, ups=0.25, wpb=2108.5, bsz=64, num_updates=7170, lr=2.31062e-05, gnorm=5.52, clip=100, loss_scale=32, train_wall=40, gb_free=7.7, wall=28965
2023-05-08 07:59:24 - progress_bar.py[line:272] - INFO: epoch 009:    266 / 866 loss=2.353, loss_v1=0, loss_v2=0, nll_loss=1.147, ntokens=2109.6, nsentences=64, sample_size=2109.6, sample_size_v1=0, sample_size_v2=0, ppl=2.21, wps=524.9, ups=0.25, wpb=2109.6, bsz=64, num_updates=7180, lr=2.30939e-05, gnorm=4.888, clip=100, loss_scale=32, train_wall=40, gb_free=6.8, wall=29005
2023-05-08 08:00:04 - progress_bar.py[line:272] - INFO: epoch 009:    276 / 866 loss=2.343, loss_v1=0, loss_v2=0, nll_loss=1.139, ntokens=2168.3, nsentences=64, sample_size=2168.3, sample_size_v1=0, sample_size_v2=0, ppl=2.2, wps=539.4, ups=0.25, wpb=2168.3, bsz=64, num_updates=7190, lr=2.30816e-05, gnorm=5.12, clip=100, loss_scale=32, train_wall=40, gb_free=7.1, wall=29046
2023-05-08 08:00:45 - progress_bar.py[line:272] - INFO: epoch 009:    286 / 866 loss=2.342, loss_v1=0, loss_v2=0, nll_loss=1.135, ntokens=2179.9, nsentences=64, sample_size=2179.9, sample_size_v1=0, sample_size_v2=0, ppl=2.2, wps=542.4, ups=0.25, wpb=2179.9, bsz=64, num_updates=7200, lr=2.30694e-05, gnorm=5.097, clip=100, loss_scale=32, train_wall=40, gb_free=7.5, wall=29086
2023-05-08 08:01:25 - progress_bar.py[line:272] - INFO: epoch 009:    296 / 866 loss=2.322, loss_v1=0, loss_v2=0, nll_loss=1.116, ntokens=2147.9, nsentences=64, sample_size=2147.9, sample_size_v1=0, sample_size_v2=0, ppl=2.17, wps=535.1, ups=0.25, wpb=2147.9, bsz=64, num_updates=7210, lr=2.30571e-05, gnorm=5.194, clip=100, loss_scale=32, train_wall=40, gb_free=7.2, wall=29126
2023-05-08 08:02:05 - progress_bar.py[line:272] - INFO: epoch 009:    306 / 866 loss=2.327, loss_v1=0, loss_v2=0, nll_loss=1.118, ntokens=2129.4, nsentences=64, sample_size=2129.4, sample_size_v1=0, sample_size_v2=0, ppl=2.17, wps=530.5, ups=0.25, wpb=2129.4, bsz=64, num_updates=7220, lr=2.30448e-05, gnorm=4.932, clip=100, loss_scale=32, train_wall=40, gb_free=7.2, wall=29166
2023-05-08 08:02:45 - progress_bar.py[line:272] - INFO: epoch 009:    316 / 866 loss=2.335, loss_v1=0, loss_v2=0, nll_loss=1.128, ntokens=2049.6, nsentences=64, sample_size=2049.6, sample_size_v1=0, sample_size_v2=0, ppl=2.18, wps=512.9, ups=0.25, wpb=2049.6, bsz=64, num_updates=7230, lr=2.30325e-05, gnorm=5.87, clip=100, loss_scale=32, train_wall=40, gb_free=7, wall=29206
2023-05-08 08:03:25 - progress_bar.py[line:272] - INFO: epoch 009:    326 / 866 loss=2.366, loss_v1=0, loss_v2=0, nll_loss=1.162, ntokens=2016.2, nsentences=64, sample_size=2016.2, sample_size_v1=0, sample_size_v2=0, ppl=2.24, wps=506.5, ups=0.25, wpb=2016.2, bsz=64, num_updates=7240, lr=2.30202e-05, gnorm=5.418, clip=100, loss_scale=32, train_wall=40, gb_free=8, wall=29246
2023-05-08 08:04:05 - progress_bar.py[line:272] - INFO: epoch 009:    336 / 866 loss=2.322, loss_v1=0, loss_v2=0, nll_loss=1.113, ntokens=2129.6, nsentences=64, sample_size=2129.6, sample_size_v1=0, sample_size_v2=0, ppl=2.16, wps=531.7, ups=0.25, wpb=2129.6, bsz=64, num_updates=7250, lr=2.30079e-05, gnorm=5.046, clip=100, loss_scale=32, train_wall=40, gb_free=7.7, wall=29286
2023-05-08 08:04:45 - progress_bar.py[line:272] - INFO: epoch 009:    346 / 866 loss=2.333, loss_v1=0, loss_v2=0, nll_loss=1.129, ntokens=1943.9, nsentences=64, sample_size=1943.9, sample_size_v1=0, sample_size_v2=0, ppl=2.19, wps=486.1, ups=0.25, wpb=1943.9, bsz=64, num_updates=7260, lr=2.29957e-05, gnorm=5.817, clip=100, loss_scale=32, train_wall=40, gb_free=7.7, wall=29326
2023-05-08 08:05:24 - progress_bar.py[line:272] - INFO: epoch 009:    356 / 866 loss=2.364, loss_v1=0, loss_v2=0, nll_loss=1.16, ntokens=1991.6, nsentences=64, sample_size=1991.6, sample_size_v1=0, sample_size_v2=0, ppl=2.23, wps=501.6, ups=0.25, wpb=1991.6, bsz=64, num_updates=7270, lr=2.29834e-05, gnorm=5.956, clip=100, loss_scale=32, train_wall=40, gb_free=8.3, wall=29366
2023-05-08 08:06:04 - progress_bar.py[line:272] - INFO: epoch 009:    366 / 866 loss=2.348, loss_v1=0, loss_v2=0, nll_loss=1.143, ntokens=1975.6, nsentences=64, sample_size=1975.6, sample_size_v1=0, sample_size_v2=0, ppl=2.21, wps=496.2, ups=0.25, wpb=1975.6, bsz=64, num_updates=7280, lr=2.29711e-05, gnorm=5.336, clip=100, loss_scale=32, train_wall=40, gb_free=8.1, wall=29405
2023-05-08 08:06:45 - progress_bar.py[line:272] - INFO: epoch 009:    376 / 866 loss=2.335, loss_v1=0, loss_v2=0, nll_loss=1.128, ntokens=2108.1, nsentences=64, sample_size=2108.1, sample_size_v1=0, sample_size_v2=0, ppl=2.19, wps=524.1, ups=0.25, wpb=2108.1, bsz=64, num_updates=7290, lr=2.29588e-05, gnorm=5.156, clip=100, loss_scale=32, train_wall=40, gb_free=7.8, wall=29446
2023-05-08 08:07:25 - progress_bar.py[line:272] - INFO: epoch 009:    386 / 866 loss=2.328, loss_v1=0, loss_v2=0, nll_loss=1.12, ntokens=2138, nsentences=64, sample_size=2138, sample_size_v1=0, sample_size_v2=0, ppl=2.17, wps=532.1, ups=0.25, wpb=2138, bsz=64, num_updates=7300, lr=2.29465e-05, gnorm=5.17, clip=100, loss_scale=32, train_wall=40, gb_free=7.7, wall=29486
2023-05-08 08:08:05 - progress_bar.py[line:272] - INFO: epoch 009:    396 / 866 loss=2.339, loss_v1=0, loss_v2=0, nll_loss=1.133, ntokens=2024.2, nsentences=64, sample_size=2024.2, sample_size_v1=0, sample_size_v2=0, ppl=2.19, wps=508.1, ups=0.25, wpb=2024.2, bsz=64, num_updates=7310, lr=2.29342e-05, gnorm=5.951, clip=100, loss_scale=32, train_wall=40, gb_free=7.2, wall=29526
2023-05-08 08:08:45 - progress_bar.py[line:272] - INFO: epoch 009:    406 / 866 loss=2.334, loss_v1=0, loss_v2=0, nll_loss=1.128, ntokens=2079.1, nsentences=64, sample_size=2079.1, sample_size_v1=0, sample_size_v2=0, ppl=2.19, wps=519.4, ups=0.25, wpb=2079.1, bsz=64, num_updates=7320, lr=2.2922e-05, gnorm=4.782, clip=100, loss_scale=32, train_wall=40, gb_free=7.5, wall=29566
2023-05-08 08:09:25 - progress_bar.py[line:272] - INFO: epoch 009:    416 / 866 loss=2.327, loss_v1=0, loss_v2=0, nll_loss=1.121, ntokens=2132.3, nsentences=64, sample_size=2132.3, sample_size_v1=0, sample_size_v2=0, ppl=2.17, wps=532, ups=0.25, wpb=2132.3, bsz=64, num_updates=7330, lr=2.29097e-05, gnorm=5.627, clip=100, loss_scale=32, train_wall=40, gb_free=7.9, wall=29606
2023-05-08 08:10:05 - progress_bar.py[line:272] - INFO: epoch 009:    426 / 866 loss=2.313, loss_v1=0, loss_v2=0, nll_loss=1.103, ntokens=2080.3, nsentences=64, sample_size=2080.3, sample_size_v1=0, sample_size_v2=0, ppl=2.15, wps=519.8, ups=0.25, wpb=2080.3, bsz=64, num_updates=7340, lr=2.28974e-05, gnorm=4.894, clip=100, loss_scale=32, train_wall=40, gb_free=7.3, wall=29646
2023-05-08 08:10:45 - progress_bar.py[line:272] - INFO: epoch 009:    436 / 866 loss=2.344, loss_v1=0, loss_v2=0, nll_loss=1.137, ntokens=2138.3, nsentences=64, sample_size=2138.3, sample_size_v1=0, sample_size_v2=0, ppl=2.2, wps=535.4, ups=0.25, wpb=2138.3, bsz=64, num_updates=7350, lr=2.28851e-05, gnorm=5.245, clip=100, loss_scale=32, train_wall=40, gb_free=7.3, wall=29686
2023-05-08 08:11:25 - progress_bar.py[line:272] - INFO: epoch 009:    446 / 866 loss=2.359, loss_v1=0, loss_v2=0, nll_loss=1.156, ntokens=2024.4, nsentences=64, sample_size=2024.4, sample_size_v1=0, sample_size_v2=0, ppl=2.23, wps=503.4, ups=0.25, wpb=2024.4, bsz=64, num_updates=7360, lr=2.28728e-05, gnorm=5.692, clip=100, loss_scale=32, train_wall=40, gb_free=7.2, wall=29726
2023-05-08 08:12:05 - progress_bar.py[line:272] - INFO: epoch 009:    456 / 866 loss=2.345, loss_v1=0, loss_v2=0, nll_loss=1.141, ntokens=2040.8, nsentences=64, sample_size=2040.8, sample_size_v1=0, sample_size_v2=0, ppl=2.2, wps=508.9, ups=0.25, wpb=2040.8, bsz=64, num_updates=7370, lr=2.28605e-05, gnorm=6.11, clip=100, loss_scale=32, train_wall=40, gb_free=7.9, wall=29766
2023-05-08 08:12:45 - progress_bar.py[line:272] - INFO: epoch 009:    466 / 866 loss=2.332, loss_v1=0, loss_v2=0, nll_loss=1.125, ntokens=2147.8, nsentences=64, sample_size=2147.8, sample_size_v1=0, sample_size_v2=0, ppl=2.18, wps=535.6, ups=0.25, wpb=2147.8, bsz=64, num_updates=7380, lr=2.28483e-05, gnorm=5.262, clip=100, loss_scale=32, train_wall=40, gb_free=7.8, wall=29806
2023-05-08 08:13:26 - progress_bar.py[line:272] - INFO: epoch 009:    476 / 866 loss=2.346, loss_v1=0, loss_v2=0, nll_loss=1.14, ntokens=2236, nsentences=64, sample_size=2236, sample_size_v1=0, sample_size_v2=0, ppl=2.2, wps=551.5, ups=0.25, wpb=2236, bsz=64, num_updates=7390, lr=2.2836e-05, gnorm=4.964, clip=100, loss_scale=32, train_wall=40, gb_free=7.8, wall=29847
2023-05-08 08:14:06 - progress_bar.py[line:272] - INFO: epoch 009:    486 / 866 loss=2.332, loss_v1=0, loss_v2=0, nll_loss=1.124, ntokens=2102.6, nsentences=64, sample_size=2102.6, sample_size_v1=0, sample_size_v2=0, ppl=2.18, wps=524.1, ups=0.25, wpb=2102.6, bsz=64, num_updates=7400, lr=2.28237e-05, gnorm=5.258, clip=100, loss_scale=32, train_wall=40, gb_free=7.6, wall=29887
2023-05-08 08:14:46 - progress_bar.py[line:272] - INFO: epoch 009:    496 / 866 loss=2.31, loss_v1=0, loss_v2=0, nll_loss=1.101, ntokens=2024.7, nsentences=64, sample_size=2024.7, sample_size_v1=0, sample_size_v2=0, ppl=2.14, wps=506, ups=0.25, wpb=2024.7, bsz=64, num_updates=7410, lr=2.28114e-05, gnorm=5.304, clip=100, loss_scale=32, train_wall=40, gb_free=8.1, wall=29927
2023-05-08 08:15:26 - progress_bar.py[line:272] - INFO: epoch 009:    506 / 866 loss=2.345, loss_v1=0, loss_v2=0, nll_loss=1.138, ntokens=2098.8, nsentences=64, sample_size=2098.8, sample_size_v1=0, sample_size_v2=0, ppl=2.2, wps=525, ups=0.25, wpb=2098.8, bsz=64, num_updates=7420, lr=2.27991e-05, gnorm=5.181, clip=100, loss_scale=32, train_wall=40, gb_free=7.5, wall=29967
2023-05-08 08:16:06 - progress_bar.py[line:272] - INFO: epoch 009:    516 / 866 loss=2.345, loss_v1=0, loss_v2=0, nll_loss=1.139, ntokens=2219, nsentences=64, sample_size=2219, sample_size_v1=0, sample_size_v2=0, ppl=2.2, wps=552.7, ups=0.25, wpb=2219, bsz=64, num_updates=7430, lr=2.27868e-05, gnorm=5.167, clip=100, loss_scale=32, train_wall=40, gb_free=7.9, wall=30007
2023-05-08 08:16:46 - progress_bar.py[line:272] - INFO: epoch 009:    526 / 866 loss=2.344, loss_v1=0, loss_v2=0, nll_loss=1.139, ntokens=2002, nsentences=64, sample_size=2002, sample_size_v1=0, sample_size_v2=0, ppl=2.2, wps=503.6, ups=0.25, wpb=2002, bsz=64, num_updates=7440, lr=2.27745e-05, gnorm=5.401, clip=100, loss_scale=32, train_wall=40, gb_free=8.1, wall=30047
2023-05-08 08:17:26 - progress_bar.py[line:272] - INFO: epoch 009:    536 / 866 loss=2.314, loss_v1=0, loss_v2=0, nll_loss=1.104, ntokens=2077.6, nsentences=64, sample_size=2077.6, sample_size_v1=0, sample_size_v2=0, ppl=2.15, wps=520.2, ups=0.25, wpb=2077.6, bsz=64, num_updates=7450, lr=2.27623e-05, gnorm=5.315, clip=100, loss_scale=32, train_wall=40, gb_free=7.9, wall=30087
2023-05-08 08:18:06 - progress_bar.py[line:272] - INFO: epoch 009:    546 / 866 loss=2.347, loss_v1=0, loss_v2=0, nll_loss=1.143, ntokens=2278.3, nsentences=64, sample_size=2278.3, sample_size_v1=0, sample_size_v2=0, ppl=2.21, wps=566, ups=0.25, wpb=2278.3, bsz=64, num_updates=7460, lr=2.275e-05, gnorm=5.192, clip=100, loss_scale=32, train_wall=40, gb_free=7.6, wall=30127
2023-05-08 08:18:46 - progress_bar.py[line:272] - INFO: epoch 009:    556 / 866 loss=2.352, loss_v1=0, loss_v2=0, nll_loss=1.147, ntokens=2260.8, nsentences=64, sample_size=2260.8, sample_size_v1=0, sample_size_v2=0, ppl=2.21, wps=556.7, ups=0.25, wpb=2260.8, bsz=64, num_updates=7470, lr=2.27377e-05, gnorm=4.612, clip=100, loss_scale=32, train_wall=41, gb_free=7.3, wall=30168
2023-05-08 08:19:27 - progress_bar.py[line:272] - INFO: epoch 009:    566 / 866 loss=2.336, loss_v1=0, loss_v2=0, nll_loss=1.129, ntokens=2249.8, nsentences=64, sample_size=2249.8, sample_size_v1=0, sample_size_v2=0, ppl=2.19, wps=561.4, ups=0.25, wpb=2249.8, bsz=64, num_updates=7480, lr=2.27254e-05, gnorm=5.515, clip=100, loss_scale=32, train_wall=40, gb_free=6.8, wall=30208
2023-05-08 08:20:07 - progress_bar.py[line:272] - INFO: epoch 009:    576 / 866 loss=2.338, loss_v1=0, loss_v2=0, nll_loss=1.132, ntokens=2151, nsentences=64, sample_size=2151, sample_size_v1=0, sample_size_v2=0, ppl=2.19, wps=536.3, ups=0.25, wpb=2151, bsz=64, num_updates=7490, lr=2.27131e-05, gnorm=5.288, clip=100, loss_scale=32, train_wall=40, gb_free=7.4, wall=30248
2023-05-08 08:20:47 - progress_bar.py[line:272] - INFO: epoch 009:    586 / 866 loss=2.347, loss_v1=0, loss_v2=0, nll_loss=1.143, ntokens=2121, nsentences=64, sample_size=2121, sample_size_v1=0, sample_size_v2=0, ppl=2.21, wps=526.8, ups=0.25, wpb=2121, bsz=64, num_updates=7500, lr=2.27008e-05, gnorm=5.534, clip=100, loss_scale=64, train_wall=40, gb_free=7.6, wall=30288
2023-05-08 08:21:27 - progress_bar.py[line:272] - INFO: epoch 009:    596 / 866 loss=2.311, loss_v1=0, loss_v2=0, nll_loss=1.102, ntokens=2106.7, nsentences=64, sample_size=2106.7, sample_size_v1=0, sample_size_v2=0, ppl=2.15, wps=522.8, ups=0.25, wpb=2106.7, bsz=64, num_updates=7510, lr=2.26886e-05, gnorm=5.119, clip=100, loss_scale=64, train_wall=40, gb_free=7.4, wall=30328
2023-05-08 08:22:07 - progress_bar.py[line:272] - INFO: epoch 009:    606 / 866 loss=2.321, loss_v1=0, loss_v2=0, nll_loss=1.115, ntokens=2021.9, nsentences=64, sample_size=2021.9, sample_size_v1=0, sample_size_v2=0, ppl=2.17, wps=501.7, ups=0.25, wpb=2021.9, bsz=64, num_updates=7520, lr=2.26763e-05, gnorm=5.756, clip=100, loss_scale=64, train_wall=40, gb_free=8.1, wall=30369
2023-05-08 08:22:48 - progress_bar.py[line:272] - INFO: epoch 009:    616 / 866 loss=2.354, loss_v1=0, loss_v2=0, nll_loss=1.148, ntokens=1934.7, nsentences=64, sample_size=1934.7, sample_size_v1=0, sample_size_v2=0, ppl=2.22, wps=480.3, ups=0.25, wpb=1934.7, bsz=64, num_updates=7530, lr=2.2664e-05, gnorm=5.311, clip=100, loss_scale=64, train_wall=40, gb_free=8.6, wall=30409
2023-05-08 08:23:28 - progress_bar.py[line:272] - INFO: epoch 009:    626 / 866 loss=2.336, loss_v1=0, loss_v2=0, nll_loss=1.13, ntokens=2062.4, nsentences=64, sample_size=2062.4, sample_size_v1=0, sample_size_v2=0, ppl=2.19, wps=512.5, ups=0.25, wpb=2062.4, bsz=64, num_updates=7540, lr=2.26517e-05, gnorm=5.445, clip=100, loss_scale=64, train_wall=40, gb_free=8, wall=30449
2023-05-08 08:24:08 - progress_bar.py[line:272] - INFO: epoch 009:    636 / 866 loss=2.316, loss_v1=0, loss_v2=0, nll_loss=1.107, ntokens=2032.4, nsentences=64, sample_size=2032.4, sample_size_v1=0, sample_size_v2=0, ppl=2.15, wps=508.6, ups=0.25, wpb=2032.4, bsz=64, num_updates=7550, lr=2.26394e-05, gnorm=5.745, clip=100, loss_scale=64, train_wall=40, gb_free=7.7, wall=30489
2023-05-08 08:24:48 - progress_bar.py[line:272] - INFO: epoch 009:    646 / 866 loss=2.327, loss_v1=0, loss_v2=0, nll_loss=1.12, ntokens=2066.6, nsentences=64, sample_size=2066.6, sample_size_v1=0, sample_size_v2=0, ppl=2.17, wps=520.2, ups=0.25, wpb=2066.6, bsz=64, num_updates=7560, lr=2.26271e-05, gnorm=5.713, clip=100, loss_scale=64, train_wall=40, gb_free=8.5, wall=30529
2023-05-08 08:25:27 - progress_bar.py[line:272] - INFO: epoch 009:    656 / 866 loss=2.351, loss_v1=0, loss_v2=0, nll_loss=1.147, ntokens=1902.3, nsentences=64, sample_size=1902.3, sample_size_v1=0, sample_size_v2=0, ppl=2.21, wps=478.2, ups=0.25, wpb=1902.3, bsz=64, num_updates=7570, lr=2.26149e-05, gnorm=5.719, clip=100, loss_scale=64, train_wall=40, gb_free=8.3, wall=30569
2023-05-08 08:26:08 - progress_bar.py[line:272] - INFO: epoch 009:    666 / 866 loss=2.348, loss_v1=0, loss_v2=0, nll_loss=1.142, ntokens=1976.5, nsentences=64, sample_size=1976.5, sample_size_v1=0, sample_size_v2=0, ppl=2.21, wps=493.7, ups=0.25, wpb=1976.5, bsz=64, num_updates=7580, lr=2.26026e-05, gnorm=5.752, clip=100, loss_scale=64, train_wall=40, gb_free=7.5, wall=30609
2023-05-08 08:26:48 - progress_bar.py[line:272] - INFO: epoch 009:    676 / 866 loss=2.325, loss_v1=0, loss_v2=0, nll_loss=1.118, ntokens=2075, nsentences=64, sample_size=2075, sample_size_v1=0, sample_size_v2=0, ppl=2.17, wps=519, ups=0.25, wpb=2075, bsz=64, num_updates=7590, lr=2.25903e-05, gnorm=5.37, clip=100, loss_scale=64, train_wall=40, gb_free=7.7, wall=30649
2023-05-08 08:27:27 - progress_bar.py[line:272] - INFO: epoch 009:    686 / 866 loss=2.321, loss_v1=0, loss_v2=0, nll_loss=1.114, ntokens=2037.7, nsentences=64, sample_size=2037.7, sample_size_v1=0, sample_size_v2=0, ppl=2.16, wps=511.8, ups=0.25, wpb=2037.7, bsz=64, num_updates=7600, lr=2.2578e-05, gnorm=5.795, clip=100, loss_scale=64, train_wall=40, gb_free=7.5, wall=30688
2023-05-08 08:28:07 - progress_bar.py[line:272] - INFO: epoch 009:    696 / 866 loss=2.343, loss_v1=0, loss_v2=0, nll_loss=1.138, ntokens=2087.8, nsentences=64, sample_size=2087.8, sample_size_v1=0, sample_size_v2=0, ppl=2.2, wps=520.6, ups=0.25, wpb=2087.8, bsz=64, num_updates=7610, lr=2.25657e-05, gnorm=5.636, clip=100, loss_scale=64, train_wall=40, gb_free=8, wall=30729
2023-05-08 08:28:47 - progress_bar.py[line:272] - INFO: epoch 009:    706 / 866 loss=2.34, loss_v1=0, loss_v2=0, nll_loss=1.133, ntokens=1990.3, nsentences=64, sample_size=1990.3, sample_size_v1=0, sample_size_v2=0, ppl=2.19, wps=499, ups=0.25, wpb=1990.3, bsz=64, num_updates=7620, lr=2.25534e-05, gnorm=5.766, clip=100, loss_scale=64, train_wall=40, gb_free=8.3, wall=30768
2023-05-08 08:29:27 - progress_bar.py[line:272] - INFO: epoch 009:    716 / 866 loss=2.355, loss_v1=0, loss_v2=0, nll_loss=1.151, ntokens=1886.2, nsentences=64, sample_size=1886.2, sample_size_v1=0, sample_size_v2=0, ppl=2.22, wps=472.4, ups=0.25, wpb=1886.2, bsz=64, num_updates=7630, lr=2.25412e-05, gnorm=5.83, clip=100, loss_scale=64, train_wall=40, gb_free=8, wall=30808
2023-05-08 08:30:07 - progress_bar.py[line:272] - INFO: epoch 009:    726 / 866 loss=2.306, loss_v1=0, loss_v2=0, nll_loss=1.096, ntokens=1999, nsentences=64, sample_size=1999, sample_size_v1=0, sample_size_v2=0, ppl=2.14, wps=501.6, ups=0.25, wpb=1999, bsz=64, num_updates=7640, lr=2.25289e-05, gnorm=5.546, clip=100, loss_scale=64, train_wall=40, gb_free=7.3, wall=30848
2023-05-08 08:30:47 - progress_bar.py[line:272] - INFO: epoch 009:    736 / 866 loss=2.307, loss_v1=0, loss_v2=0, nll_loss=1.096, ntokens=2067.7, nsentences=64, sample_size=2067.7, sample_size_v1=0, sample_size_v2=0, ppl=2.14, wps=517.4, ups=0.25, wpb=2067.7, bsz=64, num_updates=7650, lr=2.25166e-05, gnorm=5.158, clip=100, loss_scale=64, train_wall=40, gb_free=8.1, wall=30888
2023-05-08 08:31:27 - progress_bar.py[line:272] - INFO: epoch 009:    746 / 866 loss=2.305, loss_v1=0, loss_v2=0, nll_loss=1.094, ntokens=2136.1, nsentences=64, sample_size=2136.1, sample_size_v1=0, sample_size_v2=0, ppl=2.13, wps=531.9, ups=0.25, wpb=2136.1, bsz=64, num_updates=7660, lr=2.25043e-05, gnorm=5.084, clip=100, loss_scale=64, train_wall=40, gb_free=7.9, wall=30928
2023-05-08 08:32:07 - progress_bar.py[line:272] - INFO: epoch 009:    756 / 866 loss=2.312, loss_v1=0, loss_v2=0, nll_loss=1.104, ntokens=2079.3, nsentences=64, sample_size=2079.3, sample_size_v1=0, sample_size_v2=0, ppl=2.15, wps=517, ups=0.25, wpb=2079.3, bsz=64, num_updates=7670, lr=2.2492e-05, gnorm=5.66, clip=100, loss_scale=64, train_wall=40, gb_free=7.5, wall=30969
2023-05-08 08:32:47 - progress_bar.py[line:272] - INFO: epoch 009:    766 / 866 loss=2.319, loss_v1=0, loss_v2=0, nll_loss=1.111, ntokens=2087.9, nsentences=64, sample_size=2087.9, sample_size_v1=0, sample_size_v2=0, ppl=2.16, wps=521.7, ups=0.25, wpb=2087.9, bsz=64, num_updates=7680, lr=2.24797e-05, gnorm=5.637, clip=100, loss_scale=64, train_wall=40, gb_free=7.9, wall=31009
2023-05-08 08:33:28 - progress_bar.py[line:272] - INFO: epoch 009:    776 / 866 loss=2.31, loss_v1=0, loss_v2=0, nll_loss=1.099, ntokens=2232.1, nsentences=64, sample_size=2232.1, sample_size_v1=0, sample_size_v2=0, ppl=2.14, wps=557.2, ups=0.25, wpb=2232.1, bsz=64, num_updates=7690, lr=2.24674e-05, gnorm=5.449, clip=100, loss_scale=64, train_wall=40, gb_free=7.8, wall=31049
2023-05-08 08:34:07 - progress_bar.py[line:272] - INFO: epoch 009:    786 / 866 loss=2.319, loss_v1=0, loss_v2=0, nll_loss=1.11, ntokens=2088.2, nsentences=64, sample_size=2088.2, sample_size_v1=0, sample_size_v2=0, ppl=2.16, wps=523.4, ups=0.25, wpb=2088.2, bsz=64, num_updates=7700, lr=2.24552e-05, gnorm=6.228, clip=100, loss_scale=64, train_wall=40, gb_free=8.1, wall=31089
2023-05-08 08:34:47 - progress_bar.py[line:272] - INFO: epoch 009:    796 / 866 loss=2.334, loss_v1=0, loss_v2=0, nll_loss=1.126, ntokens=2068.1, nsentences=64, sample_size=2068.1, sample_size_v1=0, sample_size_v2=0, ppl=2.18, wps=516.8, ups=0.25, wpb=2068.1, bsz=64, num_updates=7710, lr=2.24429e-05, gnorm=5.703, clip=100, loss_scale=64, train_wall=40, gb_free=7.5, wall=31129
2023-05-08 08:35:27 - progress_bar.py[line:272] - INFO: epoch 009:    806 / 866 loss=2.32, loss_v1=0, loss_v2=0, nll_loss=1.111, ntokens=1919.9, nsentences=64, sample_size=1919.9, sample_size_v1=0, sample_size_v2=0, ppl=2.16, wps=482.5, ups=0.25, wpb=1919.9, bsz=64, num_updates=7720, lr=2.24306e-05, gnorm=5.791, clip=100, loss_scale=64, train_wall=40, gb_free=8.1, wall=31168
2023-05-08 08:36:07 - progress_bar.py[line:272] - INFO: epoch 009:    816 / 866 loss=2.301, loss_v1=0, loss_v2=0, nll_loss=1.092, ntokens=2099.5, nsentences=64, sample_size=2099.5, sample_size_v1=0, sample_size_v2=0, ppl=2.13, wps=523.8, ups=0.25, wpb=2099.5, bsz=64, num_updates=7730, lr=2.24183e-05, gnorm=5.328, clip=100, loss_scale=64, train_wall=40, gb_free=7.4, wall=31208
2023-05-08 08:36:48 - progress_bar.py[line:272] - INFO: epoch 009:    826 / 866 loss=2.305, loss_v1=0, loss_v2=0, nll_loss=1.094, ntokens=2152.1, nsentences=64, sample_size=2152.1, sample_size_v1=0, sample_size_v2=0, ppl=2.13, wps=531.8, ups=0.25, wpb=2152.1, bsz=64, num_updates=7740, lr=2.2406e-05, gnorm=5.219, clip=100, loss_scale=64, train_wall=40, gb_free=7.9, wall=31249
2023-05-08 08:37:28 - progress_bar.py[line:272] - INFO: epoch 009:    836 / 866 loss=2.317, loss_v1=0, loss_v2=0, nll_loss=1.108, ntokens=2165.2, nsentences=64, sample_size=2165.2, sample_size_v1=0, sample_size_v2=0, ppl=2.16, wps=535.2, ups=0.25, wpb=2165.2, bsz=64, num_updates=7750, lr=2.23937e-05, gnorm=5.251, clip=100, loss_scale=64, train_wall=40, gb_free=8.2, wall=31289
2023-05-08 08:38:08 - progress_bar.py[line:272] - INFO: epoch 009:    846 / 866 loss=2.317, loss_v1=0, loss_v2=0, nll_loss=1.108, ntokens=2171.3, nsentences=64, sample_size=2171.3, sample_size_v1=0, sample_size_v2=0, ppl=2.16, wps=540.7, ups=0.25, wpb=2171.3, bsz=64, num_updates=7760, lr=2.23815e-05, gnorm=5.131, clip=100, loss_scale=64, train_wall=40, gb_free=8, wall=31330
2023-05-08 08:38:49 - progress_bar.py[line:272] - INFO: epoch 009:    856 / 866 loss=2.308, loss_v1=0, loss_v2=0, nll_loss=1.099, ntokens=2114.8, nsentences=64, sample_size=2114.8, sample_size_v1=0, sample_size_v2=0, ppl=2.14, wps=525, ups=0.25, wpb=2114.8, bsz=64, num_updates=7770, lr=2.23692e-05, gnorm=5.514, clip=100, loss_scale=64, train_wall=40, gb_free=7.9, wall=31370
2023-05-08 08:39:27 - progress_bar.py[line:272] - INFO: epoch 009:    866 / 866 loss=2.344, loss_v1=0, loss_v2=0, nll_loss=1.138, ntokens=2017.9, nsentences=61.6, sample_size=2017.9, sample_size_v1=0, sample_size_v2=0, ppl=2.2, wps=524.1, ups=0.26, wpb=2017.9, bsz=61.6, num_updates=7780, lr=2.23569e-05, gnorm=5.017, clip=100, loss_scale=64, train_wall=38, gb_free=8.7, wall=31408
local datafile ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 1 begin to initialize row_count and line_idx-to-offset mapping
2023-05-08 08:39:27 - train.py[line:332] - INFO: end of epoch 9 (average epoch stats below)
2023-05-08 08:39:27 - progress_bar.py[line:282] - INFO: epoch 009 | loss 2.318 | loss_v1 0 | loss_v2 0 | nll_loss 1.11 | ntokens 2102.86 | nsentences 63.972 | sample_size 2102.86 | sample_size_v1 0 | sample_size_v2 0 | ppl 2.16 | wps 521.6 | ups 0.25 | wpb 2102.9 | bsz 64 | num_updates 7780 | lr 2.23569e-05 | gnorm 5.317 | clip 100 | loss_scale 64 | train_wall 3481 | gb_free 8.7 | wall 31408
2023-05-08 08:39:27 - trainer.py[line:639] - INFO: loading train data for epoch 10
local datafile ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 0 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 1 finished initializing row_count and line_idx-to-offset mapping
file ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 1 row count 27700 total row count 55400
slice_id 1 seek offset 27700
local datafile ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 0 finished initializing row_count and line_idx-to-offset mapping
file ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 0 row count 27700 total row count 55400
slice_id 0 seek offset 0
2023-05-08 08:39:29 - trainer.py[line:703] - INFO: begin training epoch 10
2023-05-08 08:39:29 - train.py[line:305] - INFO: Start iterating over samples
2023-05-08 08:40:10 - progress_bar.py[line:272] - INFO: epoch 010:     10 / 866 loss=2.283, loss_v1=0, loss_v2=0, nll_loss=1.071, ntokens=2137.4, nsentences=64, sample_size=2137.4, sample_size_v1=0, sample_size_v2=0, ppl=2.1, wps=500.7, ups=0.23, wpb=2137.4, bsz=64, num_updates=7790, lr=2.23446e-05, gnorm=5.283, clip=100, loss_scale=64, train_wall=41, gb_free=6.3, wall=31451
2023-05-08 08:40:50 - progress_bar.py[line:272] - INFO: epoch 010:     20 / 866 loss=2.251, loss_v1=0, loss_v2=0, nll_loss=1.035, ntokens=2050.9, nsentences=64, sample_size=2050.9, sample_size_v1=0, sample_size_v2=0, ppl=2.05, wps=508, ups=0.25, wpb=2050.9, bsz=64, num_updates=7800, lr=2.23323e-05, gnorm=5.423, clip=100, loss_scale=64, train_wall=40, gb_free=7.8, wall=31491
2023-05-08 08:41:31 - progress_bar.py[line:272] - INFO: epoch 010:     30 / 866 loss=2.275, loss_v1=0, loss_v2=0, nll_loss=1.061, ntokens=1987.5, nsentences=64, sample_size=1987.5, sample_size_v1=0, sample_size_v2=0, ppl=2.09, wps=493.5, ups=0.25, wpb=1987.5, bsz=64, num_updates=7810, lr=2.232e-05, gnorm=5.924, clip=100, loss_scale=64, train_wall=40, gb_free=7.4, wall=31532
2023-05-08 08:42:12 - progress_bar.py[line:272] - INFO: epoch 010:     40 / 866 loss=2.197, loss_v1=0, loss_v2=0, nll_loss=0.976, ntokens=2238.7, nsentences=64, sample_size=2238.7, sample_size_v1=0, sample_size_v2=0, ppl=1.97, wps=545.4, ups=0.24, wpb=2238.7, bsz=64, num_updates=7820, lr=2.23078e-05, gnorm=4.954, clip=100, loss_scale=64, train_wall=41, gb_free=7.6, wall=31573
2023-05-08 08:42:52 - progress_bar.py[line:272] - INFO: epoch 010:     50 / 866 loss=2.266, loss_v1=0, loss_v2=0, nll_loss=1.051, ntokens=1995.1, nsentences=64, sample_size=1995.1, sample_size_v1=0, sample_size_v2=0, ppl=2.07, wps=493.5, ups=0.25, wpb=1995.1, bsz=64, num_updates=7830, lr=2.22955e-05, gnorm=4.969, clip=100, loss_scale=64, train_wall=40, gb_free=7.4, wall=31613
2023-05-08 08:43:32 - progress_bar.py[line:272] - INFO: epoch 010:     60 / 866 loss=2.168, loss_v1=0, loss_v2=0, nll_loss=0.942, ntokens=2062.8, nsentences=64, sample_size=2062.8, sample_size_v1=0, sample_size_v2=0, ppl=1.92, wps=512.9, ups=0.25, wpb=2062.8, bsz=64, num_updates=7840, lr=2.22832e-05, gnorm=5.229, clip=100, loss_scale=64, train_wall=40, gb_free=6.4, wall=31653
2023-05-08 08:44:14 - progress_bar.py[line:272] - INFO: epoch 010:     70 / 866 loss=2.162, loss_v1=0, loss_v2=0, nll_loss=0.934, ntokens=2476.7, nsentences=64, sample_size=2476.7, sample_size_v1=0, sample_size_v2=0, ppl=1.91, wps=588.8, ups=0.24, wpb=2476.7, bsz=64, num_updates=7850, lr=2.22709e-05, gnorm=4.111, clip=100, loss_scale=64, train_wall=42, gb_free=7, wall=31695
2023-05-08 08:44:56 - progress_bar.py[line:272] - INFO: epoch 010:     80 / 866 loss=2.21, loss_v1=0, loss_v2=0, nll_loss=0.989, ntokens=2320.5, nsentences=64, sample_size=2320.5, sample_size_v1=0, sample_size_v2=0, ppl=1.99, wps=556.6, ups=0.24, wpb=2320.5, bsz=64, num_updates=7860, lr=2.22586e-05, gnorm=4.505, clip=100, loss_scale=64, train_wall=42, gb_free=6.8, wall=31737
2023-05-08 08:45:37 - progress_bar.py[line:272] - INFO: epoch 010:     90 / 866 loss=2.259, loss_v1=0, loss_v2=0, nll_loss=1.042, ntokens=2123.9, nsentences=64, sample_size=2123.9, sample_size_v1=0, sample_size_v2=0, ppl=2.06, wps=520.6, ups=0.25, wpb=2123.9, bsz=64, num_updates=7870, lr=2.22463e-05, gnorm=5.169, clip=100, loss_scale=64, train_wall=41, gb_free=7.4, wall=31778
2023-05-08 08:46:17 - progress_bar.py[line:272] - INFO: epoch 010:    100 / 866 loss=2.254, loss_v1=0, loss_v2=0, nll_loss=1.04, ntokens=2077.5, nsentences=64, sample_size=2077.5, sample_size_v1=0, sample_size_v2=0, ppl=2.06, wps=515.2, ups=0.25, wpb=2077.5, bsz=64, num_updates=7880, lr=2.22341e-05, gnorm=5.246, clip=100, loss_scale=64, train_wall=40, gb_free=7.2, wall=31818
2023-05-08 08:46:57 - progress_bar.py[line:272] - INFO: epoch 010:    110 / 866 loss=2.313, loss_v1=0, loss_v2=0, nll_loss=1.102, ntokens=2029.9, nsentences=64, sample_size=2029.9, sample_size_v1=0, sample_size_v2=0, ppl=2.15, wps=504.4, ups=0.25, wpb=2029.9, bsz=64, num_updates=7890, lr=2.22218e-05, gnorm=5.632, clip=100, loss_scale=64, train_wall=40, gb_free=7.2, wall=31859
2023-05-08 08:47:38 - progress_bar.py[line:272] - INFO: epoch 010:    120 / 866 loss=2.302, loss_v1=0, loss_v2=0, nll_loss=1.091, ntokens=2169.2, nsentences=64, sample_size=2169.2, sample_size_v1=0, sample_size_v2=0, ppl=2.13, wps=529.8, ups=0.24, wpb=2169.2, bsz=64, num_updates=7900, lr=2.22095e-05, gnorm=4.6, clip=100, loss_scale=64, train_wall=41, gb_free=7, wall=31899
2023-05-08 08:48:20 - progress_bar.py[line:272] - INFO: epoch 010:    130 / 866 loss=2.289, loss_v1=0, loss_v2=0, nll_loss=1.076, ntokens=2201.3, nsentences=64, sample_size=2201.3, sample_size_v1=0, sample_size_v2=0, ppl=2.11, wps=535.1, ups=0.24, wpb=2201.3, bsz=64, num_updates=7910, lr=2.21972e-05, gnorm=4.976, clip=100, loss_scale=64, train_wall=41, gb_free=6.8, wall=31941
2023-05-08 08:49:01 - progress_bar.py[line:272] - INFO: epoch 010:    140 / 866 loss=2.263, loss_v1=0, loss_v2=0, nll_loss=1.049, ntokens=2246.8, nsentences=64, sample_size=2246.8, sample_size_v1=0, sample_size_v2=0, ppl=2.07, wps=547.6, ups=0.24, wpb=2246.8, bsz=64, num_updates=7920, lr=2.21849e-05, gnorm=4.895, clip=100, loss_scale=64, train_wall=41, gb_free=6.2, wall=31982
2023-05-08 08:49:42 - progress_bar.py[line:272] - INFO: epoch 010:    150 / 866 loss=2.261, loss_v1=0, loss_v2=0, nll_loss=1.046, ntokens=2170, nsentences=64, sample_size=2170, sample_size_v1=0, sample_size_v2=0, ppl=2.06, wps=526.2, ups=0.24, wpb=2170, bsz=64, num_updates=7930, lr=2.21726e-05, gnorm=4.874, clip=100, loss_scale=64, train_wall=41, gb_free=7.3, wall=32023
2023-05-08 08:50:23 - progress_bar.py[line:272] - INFO: epoch 010:    160 / 866 loss=2.282, loss_v1=0, loss_v2=0, nll_loss=1.069, ntokens=2205.1, nsentences=64, sample_size=2205.1, sample_size_v1=0, sample_size_v2=0, ppl=2.1, wps=536.6, ups=0.24, wpb=2205.1, bsz=64, num_updates=7940, lr=2.21603e-05, gnorm=5.043, clip=100, loss_scale=64, train_wall=41, gb_free=7.5, wall=32064
2023-05-08 08:51:03 - progress_bar.py[line:272] - INFO: epoch 010:    170 / 866 loss=2.287, loss_v1=0, loss_v2=0, nll_loss=1.073, ntokens=2090.1, nsentences=64, sample_size=2090.1, sample_size_v1=0, sample_size_v2=0, ppl=2.1, wps=517.1, ups=0.25, wpb=2090.1, bsz=64, num_updates=7950, lr=2.21481e-05, gnorm=5.119, clip=100, loss_scale=64, train_wall=40, gb_free=7.6, wall=32104
2023-05-08 08:51:44 - progress_bar.py[line:272] - INFO: epoch 010:    180 / 866 loss=2.258, loss_v1=0, loss_v2=0, nll_loss=1.042, ntokens=2119.6, nsentences=64, sample_size=2119.6, sample_size_v1=0, sample_size_v2=0, ppl=2.06, wps=518.2, ups=0.24, wpb=2119.6, bsz=64, num_updates=7960, lr=2.21358e-05, gnorm=5.144, clip=100, loss_scale=64, train_wall=41, gb_free=7.2, wall=32145
2023-05-08 08:52:25 - progress_bar.py[line:272] - INFO: epoch 010:    190 / 866 loss=2.271, loss_v1=0, loss_v2=0, nll_loss=1.057, ntokens=2205.1, nsentences=64, sample_size=2205.1, sample_size_v1=0, sample_size_v2=0, ppl=2.08, wps=538.6, ups=0.24, wpb=2205.1, bsz=64, num_updates=7970, lr=2.21235e-05, gnorm=5.181, clip=100, loss_scale=64, train_wall=41, gb_free=6.9, wall=32186
2023-05-08 08:53:06 - progress_bar.py[line:272] - INFO: epoch 010:    200 / 866 loss=2.29, loss_v1=0, loss_v2=0, nll_loss=1.079, ntokens=2135.3, nsentences=64, sample_size=2135.3, sample_size_v1=0, sample_size_v2=0, ppl=2.11, wps=524.1, ups=0.25, wpb=2135.3, bsz=64, num_updates=7980, lr=2.21112e-05, gnorm=5.642, clip=100, loss_scale=64, train_wall=41, gb_free=8, wall=32227
2023-05-08 08:53:46 - progress_bar.py[line:272] - INFO: epoch 010:    210 / 866 loss=2.326, loss_v1=0, loss_v2=0, nll_loss=1.119, ntokens=2011.1, nsentences=64, sample_size=2011.1, sample_size_v1=0, sample_size_v2=0, ppl=2.17, wps=497.9, ups=0.25, wpb=2011.1, bsz=64, num_updates=7990, lr=2.20989e-05, gnorm=5.736, clip=100, loss_scale=64, train_wall=40, gb_free=7.5, wall=32267
2023-05-08 08:54:27 - progress_bar.py[line:272] - INFO: epoch 010:    220 / 866 loss=2.317, loss_v1=0, loss_v2=0, nll_loss=1.107, ntokens=2199.5, nsentences=64, sample_size=2199.5, sample_size_v1=0, sample_size_v2=0, ppl=2.15, wps=544.7, ups=0.25, wpb=2199.5, bsz=64, num_updates=8000, lr=2.20866e-05, gnorm=5.509, clip=100, loss_scale=64, train_wall=40, gb_free=7.5, wall=32308
2023-05-08 08:55:03 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2023-05-08 08:55:11 - progress_bar.py[line:272] - INFO: epoch 010:    231 / 866 loss=2.327, loss_v1=0, loss_v2=0, nll_loss=1.119, ntokens=2148.7, nsentences=64, sample_size=2148.7, sample_size_v1=0, sample_size_v2=0, ppl=2.17, wps=488.6, ups=0.23, wpb=2148.7, bsz=64, num_updates=8010, lr=2.20744e-05, gnorm=4.923, clip=100, loss_scale=64, train_wall=44, gb_free=8, wall=32352
2023-05-08 08:55:51 - progress_bar.py[line:272] - INFO: epoch 010:    241 / 866 loss=2.331, loss_v1=0, loss_v2=0, nll_loss=1.125, ntokens=2186, nsentences=64, sample_size=2186, sample_size_v1=0, sample_size_v2=0, ppl=2.18, wps=544.2, ups=0.25, wpb=2186, bsz=64, num_updates=8020, lr=2.20621e-05, gnorm=4.952, clip=100, loss_scale=64, train_wall=40, gb_free=7.8, wall=32392
2023-05-08 08:56:31 - progress_bar.py[line:272] - INFO: epoch 010:    251 / 866 loss=2.326, loss_v1=0, loss_v2=0, nll_loss=1.12, ntokens=2114, nsentences=64, sample_size=2114, sample_size_v1=0, sample_size_v2=0, ppl=2.17, wps=523.1, ups=0.25, wpb=2114, bsz=64, num_updates=8030, lr=2.20498e-05, gnorm=5.088, clip=100, loss_scale=64, train_wall=40, gb_free=7.9, wall=32432
2023-05-08 08:57:11 - progress_bar.py[line:272] - INFO: epoch 010:    261 / 866 loss=2.337, loss_v1=0, loss_v2=0, nll_loss=1.13, ntokens=2157.6, nsentences=64, sample_size=2157.6, sample_size_v1=0, sample_size_v2=0, ppl=2.19, wps=538.7, ups=0.25, wpb=2157.6, bsz=64, num_updates=8040, lr=2.20375e-05, gnorm=5.054, clip=100, loss_scale=64, train_wall=40, gb_free=7.5, wall=32472
2023-05-08 08:57:51 - progress_bar.py[line:272] - INFO: epoch 010:    271 / 866 loss=2.313, loss_v1=0, loss_v2=0, nll_loss=1.104, ntokens=2130.4, nsentences=64, sample_size=2130.4, sample_size_v1=0, sample_size_v2=0, ppl=2.15, wps=530.4, ups=0.25, wpb=2130.4, bsz=64, num_updates=8050, lr=2.20252e-05, gnorm=4.726, clip=100, loss_scale=64, train_wall=40, gb_free=7.4, wall=32513
2023-05-08 08:58:32 - progress_bar.py[line:272] - INFO: epoch 010:    281 / 866 loss=2.337, loss_v1=0, loss_v2=0, nll_loss=1.132, ntokens=2166, nsentences=64, sample_size=2166, sample_size_v1=0, sample_size_v2=0, ppl=2.19, wps=539, ups=0.25, wpb=2166, bsz=64, num_updates=8060, lr=2.20129e-05, gnorm=5.058, clip=100, loss_scale=64, train_wall=40, gb_free=8.2, wall=32553
2023-05-08 08:59:12 - progress_bar.py[line:272] - INFO: epoch 010:    291 / 866 loss=2.308, loss_v1=0, loss_v2=0, nll_loss=1.097, ntokens=2137.1, nsentences=64, sample_size=2137.1, sample_size_v1=0, sample_size_v2=0, ppl=2.14, wps=532.7, ups=0.25, wpb=2137.1, bsz=64, num_updates=8070, lr=2.20007e-05, gnorm=5.201, clip=100, loss_scale=64, train_wall=40, gb_free=7.6, wall=32593
2023-05-08 08:59:52 - progress_bar.py[line:272] - INFO: epoch 010:    301 / 866 loss=2.317, loss_v1=0, loss_v2=0, nll_loss=1.111, ntokens=2149.5, nsentences=64, sample_size=2149.5, sample_size_v1=0, sample_size_v2=0, ppl=2.16, wps=536.2, ups=0.25, wpb=2149.5, bsz=64, num_updates=8080, lr=2.19884e-05, gnorm=5.085, clip=100, loss_scale=64, train_wall=40, gb_free=7.9, wall=32633
2023-05-08 09:00:32 - progress_bar.py[line:272] - INFO: epoch 010:    311 / 866 loss=2.306, loss_v1=0, loss_v2=0, nll_loss=1.094, ntokens=2134, nsentences=64, sample_size=2134, sample_size_v1=0, sample_size_v2=0, ppl=2.13, wps=532.7, ups=0.25, wpb=2134, bsz=64, num_updates=8090, lr=2.19761e-05, gnorm=5.049, clip=100, loss_scale=64, train_wall=40, gb_free=7.8, wall=32673
2023-05-08 09:01:12 - progress_bar.py[line:272] - INFO: epoch 010:    321 / 866 loss=2.338, loss_v1=0, loss_v2=0, nll_loss=1.132, ntokens=1954.2, nsentences=64, sample_size=1954.2, sample_size_v1=0, sample_size_v2=0, ppl=2.19, wps=490.3, ups=0.25, wpb=1954.2, bsz=64, num_updates=8100, lr=2.19638e-05, gnorm=6.035, clip=100, loss_scale=64, train_wall=40, gb_free=8.2, wall=32713
2023-05-08 09:01:52 - progress_bar.py[line:272] - INFO: epoch 010:    331 / 866 loss=2.327, loss_v1=0, loss_v2=0, nll_loss=1.119, ntokens=2123.6, nsentences=64, sample_size=2123.6, sample_size_v1=0, sample_size_v2=0, ppl=2.17, wps=530.8, ups=0.25, wpb=2123.6, bsz=64, num_updates=8110, lr=2.19515e-05, gnorm=4.946, clip=100, loss_scale=64, train_wall=40, gb_free=7.9, wall=32753
2023-05-08 09:02:32 - progress_bar.py[line:272] - INFO: epoch 010:    341 / 866 loss=2.298, loss_v1=0, loss_v2=0, nll_loss=1.088, ntokens=2058.4, nsentences=64, sample_size=2058.4, sample_size_v1=0, sample_size_v2=0, ppl=2.13, wps=513.9, ups=0.25, wpb=2058.4, bsz=64, num_updates=8120, lr=2.19392e-05, gnorm=4.91, clip=100, loss_scale=64, train_wall=40, gb_free=8.1, wall=32793
2023-05-08 09:03:12 - progress_bar.py[line:272] - INFO: epoch 010:    351 / 866 loss=2.334, loss_v1=0, loss_v2=0, nll_loss=1.127, ntokens=1946.1, nsentences=64, sample_size=1946.1, sample_size_v1=0, sample_size_v2=0, ppl=2.18, wps=487.3, ups=0.25, wpb=1946.1, bsz=64, num_updates=8130, lr=2.1927e-05, gnorm=5.693, clip=100, loss_scale=64, train_wall=40, gb_free=7.8, wall=32833
2023-05-08 09:03:52 - progress_bar.py[line:272] - INFO: epoch 010:    361 / 866 loss=2.347, loss_v1=0, loss_v2=0, nll_loss=1.142, ntokens=1961.9, nsentences=64, sample_size=1961.9, sample_size_v1=0, sample_size_v2=0, ppl=2.21, wps=493.9, ups=0.25, wpb=1961.9, bsz=64, num_updates=8140, lr=2.19147e-05, gnorm=6.279, clip=100, loss_scale=64, train_wall=40, gb_free=7.8, wall=32873
2023-05-08 09:04:32 - progress_bar.py[line:272] - INFO: epoch 010:    371 / 866 loss=2.324, loss_v1=0, loss_v2=0, nll_loss=1.115, ntokens=2017.2, nsentences=64, sample_size=2017.2, sample_size_v1=0, sample_size_v2=0, ppl=2.17, wps=500.4, ups=0.25, wpb=2017.2, bsz=64, num_updates=8150, lr=2.19024e-05, gnorm=5.043, clip=100, loss_scale=64, train_wall=40, gb_free=7.3, wall=32913
2023-05-08 09:05:12 - progress_bar.py[line:272] - INFO: epoch 010:    381 / 866 loss=2.301, loss_v1=0, loss_v2=0, nll_loss=1.091, ntokens=2202.5, nsentences=64, sample_size=2202.5, sample_size_v1=0, sample_size_v2=0, ppl=2.13, wps=548, ups=0.25, wpb=2202.5, bsz=64, num_updates=8160, lr=2.18901e-05, gnorm=5.251, clip=100, loss_scale=64, train_wall=40, gb_free=7.7, wall=32953
2023-05-08 09:05:52 - progress_bar.py[line:272] - INFO: epoch 010:    391 / 866 loss=2.313, loss_v1=0, loss_v2=0, nll_loss=1.104, ntokens=2040.6, nsentences=64, sample_size=2040.6, sample_size_v1=0, sample_size_v2=0, ppl=2.15, wps=509.9, ups=0.25, wpb=2040.6, bsz=64, num_updates=8170, lr=2.18778e-05, gnorm=5.439, clip=100, loss_scale=64, train_wall=40, gb_free=8, wall=32993
2023-05-08 09:06:32 - progress_bar.py[line:272] - INFO: epoch 010:    401 / 866 loss=2.332, loss_v1=0, loss_v2=0, nll_loss=1.125, ntokens=2039.7, nsentences=64, sample_size=2039.7, sample_size_v1=0, sample_size_v2=0, ppl=2.18, wps=506.3, ups=0.25, wpb=2039.7, bsz=64, num_updates=8180, lr=2.18655e-05, gnorm=5.634, clip=100, loss_scale=64, train_wall=40, gb_free=7.6, wall=33033
2023-05-08 09:07:13 - progress_bar.py[line:272] - INFO: epoch 010:    411 / 866 loss=2.313, loss_v1=0, loss_v2=0, nll_loss=1.106, ntokens=2145.8, nsentences=64, sample_size=2145.8, sample_size_v1=0, sample_size_v2=0, ppl=2.15, wps=533.5, ups=0.25, wpb=2145.8, bsz=64, num_updates=8190, lr=2.18532e-05, gnorm=5.1, clip=100, loss_scale=64, train_wall=40, gb_free=7.8, wall=33074
2023-05-08 09:07:53 - progress_bar.py[line:272] - INFO: epoch 010:    421 / 866 loss=2.305, loss_v1=0, loss_v2=0, nll_loss=1.094, ntokens=2060.2, nsentences=64, sample_size=2060.2, sample_size_v1=0, sample_size_v2=0, ppl=2.14, wps=512.3, ups=0.25, wpb=2060.2, bsz=64, num_updates=8200, lr=2.1841e-05, gnorm=5.19, clip=100, loss_scale=64, train_wall=40, gb_free=7.7, wall=33114
2023-05-08 09:08:33 - progress_bar.py[line:272] - INFO: epoch 010:    431 / 866 loss=2.297, loss_v1=0, loss_v2=0, nll_loss=1.086, ntokens=2139.4, nsentences=64, sample_size=2139.4, sample_size_v1=0, sample_size_v2=0, ppl=2.12, wps=533.8, ups=0.25, wpb=2139.4, bsz=64, num_updates=8210, lr=2.18287e-05, gnorm=4.826, clip=100, loss_scale=64, train_wall=40, gb_free=7.6, wall=33154
2023-05-08 09:09:13 - progress_bar.py[line:272] - INFO: epoch 010:    441 / 866 loss=2.346, loss_v1=0, loss_v2=0, nll_loss=1.138, ntokens=2084.1, nsentences=64, sample_size=2084.1, sample_size_v1=0, sample_size_v2=0, ppl=2.2, wps=519.7, ups=0.25, wpb=2084.1, bsz=64, num_updates=8220, lr=2.18164e-05, gnorm=5.67, clip=100, loss_scale=64, train_wall=40, gb_free=7.8, wall=33194
2023-05-08 09:09:53 - progress_bar.py[line:272] - INFO: epoch 010:    451 / 866 loss=2.329, loss_v1=0, loss_v2=0, nll_loss=1.124, ntokens=1968.6, nsentences=64, sample_size=1968.6, sample_size_v1=0, sample_size_v2=0, ppl=2.18, wps=492.4, ups=0.25, wpb=1968.6, bsz=64, num_updates=8230, lr=2.18041e-05, gnorm=5.91, clip=100, loss_scale=64, train_wall=40, gb_free=7.1, wall=33234
2023-05-08 09:10:33 - progress_bar.py[line:272] - INFO: epoch 010:    461 / 866 loss=2.328, loss_v1=0, loss_v2=0, nll_loss=1.121, ntokens=2166.2, nsentences=64, sample_size=2166.2, sample_size_v1=0, sample_size_v2=0, ppl=2.17, wps=538.2, ups=0.25, wpb=2166.2, bsz=64, num_updates=8240, lr=2.17918e-05, gnorm=5.633, clip=100, loss_scale=64, train_wall=40, gb_free=7.4, wall=33274
2023-05-08 09:11:13 - progress_bar.py[line:272] - INFO: epoch 010:    471 / 866 loss=2.315, loss_v1=0, loss_v2=0, nll_loss=1.107, ntokens=2148.8, nsentences=64, sample_size=2148.8, sample_size_v1=0, sample_size_v2=0, ppl=2.15, wps=535.1, ups=0.25, wpb=2148.8, bsz=64, num_updates=8250, lr=2.17795e-05, gnorm=5.643, clip=100, loss_scale=64, train_wall=40, gb_free=8, wall=33314
2023-05-08 09:11:54 - progress_bar.py[line:272] - INFO: epoch 010:    481 / 866 loss=2.321, loss_v1=0, loss_v2=0, nll_loss=1.112, ntokens=2201, nsentences=64, sample_size=2201, sample_size_v1=0, sample_size_v2=0, ppl=2.16, wps=545.9, ups=0.25, wpb=2201, bsz=64, num_updates=8260, lr=2.17673e-05, gnorm=5.361, clip=100, loss_scale=64, train_wall=40, gb_free=8.4, wall=33355
2023-05-08 09:12:34 - progress_bar.py[line:272] - INFO: epoch 010:    491 / 866 loss=2.3, loss_v1=0, loss_v2=0, nll_loss=1.089, ntokens=2074.4, nsentences=64, sample_size=2074.4, sample_size_v1=0, sample_size_v2=0, ppl=2.13, wps=518, ups=0.25, wpb=2074.4, bsz=64, num_updates=8270, lr=2.1755e-05, gnorm=5.215, clip=100, loss_scale=64, train_wall=40, gb_free=7, wall=33395
2023-05-08 09:13:14 - progress_bar.py[line:272] - INFO: epoch 010:    501 / 866 loss=2.305, loss_v1=0, loss_v2=0, nll_loss=1.096, ntokens=2027.2, nsentences=64, sample_size=2027.2, sample_size_v1=0, sample_size_v2=0, ppl=2.14, wps=505, ups=0.25, wpb=2027.2, bsz=64, num_updates=8280, lr=2.17427e-05, gnorm=5.349, clip=100, loss_scale=64, train_wall=40, gb_free=8.1, wall=33435
2023-05-08 09:13:54 - progress_bar.py[line:272] - INFO: epoch 010:    511 / 866 loss=2.352, loss_v1=0, loss_v2=0, nll_loss=1.146, ntokens=2140.6, nsentences=64, sample_size=2140.6, sample_size_v1=0, sample_size_v2=0, ppl=2.21, wps=532.2, ups=0.25, wpb=2140.6, bsz=64, num_updates=8290, lr=2.17304e-05, gnorm=5.525, clip=100, loss_scale=64, train_wall=40, gb_free=8.4, wall=33475
2023-05-08 09:14:34 - progress_bar.py[line:272] - INFO: epoch 010:    521 / 866 loss=2.297, loss_v1=0, loss_v2=0, nll_loss=1.087, ntokens=2179.5, nsentences=64, sample_size=2179.5, sample_size_v1=0, sample_size_v2=0, ppl=2.12, wps=547.2, ups=0.25, wpb=2179.5, bsz=64, num_updates=8300, lr=2.17181e-05, gnorm=5.053, clip=100, loss_scale=64, train_wall=40, gb_free=7.7, wall=33515
2023-05-08 09:15:14 - progress_bar.py[line:272] - INFO: epoch 010:    531 / 866 loss=2.319, loss_v1=0, loss_v2=0, nll_loss=1.111, ntokens=2003.1, nsentences=64, sample_size=2003.1, sample_size_v1=0, sample_size_v2=0, ppl=2.16, wps=502.2, ups=0.25, wpb=2003.1, bsz=64, num_updates=8310, lr=2.17058e-05, gnorm=5.726, clip=100, loss_scale=64, train_wall=40, gb_free=7.9, wall=33555
2023-05-08 09:15:54 - progress_bar.py[line:272] - INFO: epoch 010:    541 / 866 loss=2.315, loss_v1=0, loss_v2=0, nll_loss=1.105, ntokens=2145.8, nsentences=64, sample_size=2145.8, sample_size_v1=0, sample_size_v2=0, ppl=2.15, wps=536.7, ups=0.25, wpb=2145.8, bsz=64, num_updates=8320, lr=2.16936e-05, gnorm=5.293, clip=100, loss_scale=64, train_wall=40, gb_free=8.3, wall=33595
2023-05-08 09:16:34 - progress_bar.py[line:272] - INFO: epoch 010:    551 / 866 loss=2.337, loss_v1=0, loss_v2=0, nll_loss=1.132, ntokens=2299.8, nsentences=64, sample_size=2299.8, sample_size_v1=0, sample_size_v2=0, ppl=2.19, wps=569.7, ups=0.25, wpb=2299.8, bsz=64, num_updates=8330, lr=2.16813e-05, gnorm=4.873, clip=100, loss_scale=64, train_wall=40, gb_free=7.6, wall=33635
2023-05-08 09:17:15 - progress_bar.py[line:272] - INFO: epoch 010:    561 / 866 loss=2.317, loss_v1=0, loss_v2=0, nll_loss=1.107, ntokens=2246, nsentences=64, sample_size=2246, sample_size_v1=0, sample_size_v2=0, ppl=2.15, wps=557, ups=0.25, wpb=2246, bsz=64, num_updates=8340, lr=2.1669e-05, gnorm=5.23, clip=100, loss_scale=64, train_wall=40, gb_free=7.7, wall=33676
2023-05-08 09:17:55 - progress_bar.py[line:272] - INFO: epoch 010:    571 / 866 loss=2.326, loss_v1=0, loss_v2=0, nll_loss=1.119, ntokens=2220.8, nsentences=64, sample_size=2220.8, sample_size_v1=0, sample_size_v2=0, ppl=2.17, wps=554.6, ups=0.25, wpb=2220.8, bsz=64, num_updates=8350, lr=2.16567e-05, gnorm=5.144, clip=100, loss_scale=64, train_wall=40, gb_free=8.3, wall=33716
2023-05-08 09:18:35 - progress_bar.py[line:272] - INFO: epoch 010:    581 / 866 loss=2.325, loss_v1=0, loss_v2=0, nll_loss=1.117, ntokens=2124.7, nsentences=64, sample_size=2124.7, sample_size_v1=0, sample_size_v2=0, ppl=2.17, wps=528.5, ups=0.25, wpb=2124.7, bsz=64, num_updates=8360, lr=2.16444e-05, gnorm=5.022, clip=100, loss_scale=64, train_wall=40, gb_free=6.9, wall=33756
2023-05-08 09:19:15 - progress_bar.py[line:272] - INFO: epoch 010:    591 / 866 loss=2.33, loss_v1=0, loss_v2=0, nll_loss=1.123, ntokens=2033, nsentences=64, sample_size=2033, sample_size_v1=0, sample_size_v2=0, ppl=2.18, wps=505.8, ups=0.25, wpb=2033, bsz=64, num_updates=8370, lr=2.16321e-05, gnorm=5.886, clip=100, loss_scale=64, train_wall=40, gb_free=6.9, wall=33796
2023-05-08 09:19:55 - progress_bar.py[line:272] - INFO: epoch 010:    601 / 866 loss=2.279, loss_v1=0, loss_v2=0, nll_loss=1.068, ntokens=2167.4, nsentences=64, sample_size=2167.4, sample_size_v1=0, sample_size_v2=0, ppl=2.1, wps=538.1, ups=0.25, wpb=2167.4, bsz=64, num_updates=8380, lr=2.16199e-05, gnorm=5.272, clip=100, loss_scale=64, train_wall=40, gb_free=8, wall=33836
2023-05-08 09:20:35 - progress_bar.py[line:272] - INFO: epoch 010:    611 / 866 loss=2.326, loss_v1=0, loss_v2=0, nll_loss=1.119, ntokens=1954.2, nsentences=64, sample_size=1954.2, sample_size_v1=0, sample_size_v2=0, ppl=2.17, wps=489.6, ups=0.25, wpb=1954.2, bsz=64, num_updates=8390, lr=2.16076e-05, gnorm=6.046, clip=100, loss_scale=64, train_wall=40, gb_free=8.3, wall=33876
2023-05-08 09:21:15 - progress_bar.py[line:272] - INFO: epoch 010:    621 / 866 loss=2.33, loss_v1=0, loss_v2=0, nll_loss=1.12, ntokens=2011.9, nsentences=64, sample_size=2011.9, sample_size_v1=0, sample_size_v2=0, ppl=2.17, wps=502.6, ups=0.25, wpb=2011.9, bsz=64, num_updates=8400, lr=2.15953e-05, gnorm=5.134, clip=100, loss_scale=64, train_wall=40, gb_free=8.1, wall=33916
2023-05-08 09:21:55 - progress_bar.py[line:272] - INFO: epoch 010:    631 / 866 loss=2.306, loss_v1=0, loss_v2=0, nll_loss=1.097, ntokens=2024.1, nsentences=64, sample_size=2024.1, sample_size_v1=0, sample_size_v2=0, ppl=2.14, wps=507.1, ups=0.25, wpb=2024.1, bsz=64, num_updates=8410, lr=2.1583e-05, gnorm=5.5, clip=100, loss_scale=64, train_wall=40, gb_free=7.5, wall=33956
2023-05-08 09:22:35 - progress_bar.py[line:272] - INFO: epoch 010:    641 / 866 loss=2.3, loss_v1=0, loss_v2=0, nll_loss=1.088, ntokens=2038, nsentences=64, sample_size=2038, sample_size_v1=0, sample_size_v2=0, ppl=2.13, wps=508.7, ups=0.25, wpb=2038, bsz=64, num_updates=8420, lr=2.15707e-05, gnorm=5.768, clip=100, loss_scale=64, train_wall=40, gb_free=8.3, wall=33996
2023-05-08 09:23:15 - progress_bar.py[line:272] - INFO: epoch 010:    651 / 866 loss=2.322, loss_v1=0, loss_v2=0, nll_loss=1.115, ntokens=2054.8, nsentences=64, sample_size=2054.8, sample_size_v1=0, sample_size_v2=0, ppl=2.17, wps=514, ups=0.25, wpb=2054.8, bsz=64, num_updates=8430, lr=2.15584e-05, gnorm=5.358, clip=100, loss_scale=64, train_wall=40, gb_free=8, wall=34036
2023-05-08 09:23:55 - progress_bar.py[line:272] - INFO: epoch 010:    661 / 866 loss=2.351, loss_v1=0, loss_v2=0, nll_loss=1.146, ntokens=1912, nsentences=64, sample_size=1912, sample_size_v1=0, sample_size_v2=0, ppl=2.21, wps=481.6, ups=0.25, wpb=1912, bsz=64, num_updates=8440, lr=2.15461e-05, gnorm=5.946, clip=100, loss_scale=64, train_wall=40, gb_free=7.8, wall=34076
2023-05-08 09:24:35 - progress_bar.py[line:272] - INFO: epoch 010:    671 / 866 loss=2.315, loss_v1=0, loss_v2=0, nll_loss=1.105, ntokens=2020, nsentences=64, sample_size=2020, sample_size_v1=0, sample_size_v2=0, ppl=2.15, wps=504.4, ups=0.25, wpb=2020, bsz=64, num_updates=8450, lr=2.15339e-05, gnorm=5.509, clip=100, loss_scale=64, train_wall=40, gb_free=7.8, wall=34116
2023-05-08 09:25:15 - progress_bar.py[line:272] - INFO: epoch 010:    681 / 866 loss=2.302, loss_v1=0, loss_v2=0, nll_loss=1.093, ntokens=2053.7, nsentences=64, sample_size=2053.7, sample_size_v1=0, sample_size_v2=0, ppl=2.13, wps=516.1, ups=0.25, wpb=2053.7, bsz=64, num_updates=8460, lr=2.15216e-05, gnorm=5.793, clip=100, loss_scale=64, train_wall=40, gb_free=7.3, wall=34156
2023-05-08 09:25:55 - progress_bar.py[line:272] - INFO: epoch 010:    691 / 866 loss=2.318, loss_v1=0, loss_v2=0, nll_loss=1.109, ntokens=2002, nsentences=64, sample_size=2002, sample_size_v1=0, sample_size_v2=0, ppl=2.16, wps=500.7, ups=0.25, wpb=2002, bsz=64, num_updates=8470, lr=2.15093e-05, gnorm=5.914, clip=100, loss_scale=64, train_wall=40, gb_free=8, wall=34196
2023-05-08 09:26:35 - progress_bar.py[line:272] - INFO: epoch 010:    701 / 866 loss=2.323, loss_v1=0, loss_v2=0, nll_loss=1.115, ntokens=2092.2, nsentences=64, sample_size=2092.2, sample_size_v1=0, sample_size_v2=0, ppl=2.17, wps=522.9, ups=0.25, wpb=2092.2, bsz=64, num_updates=8480, lr=2.1497e-05, gnorm=5.589, clip=100, loss_scale=64, train_wall=40, gb_free=8.1, wall=34236
2023-05-08 09:27:15 - progress_bar.py[line:272] - INFO: epoch 010:    711 / 866 loss=2.338, loss_v1=0, loss_v2=0, nll_loss=1.132, ntokens=1922.9, nsentences=64, sample_size=1922.9, sample_size_v1=0, sample_size_v2=0, ppl=2.19, wps=482.1, ups=0.25, wpb=1922.9, bsz=64, num_updates=8490, lr=2.14847e-05, gnorm=6.152, clip=100, loss_scale=64, train_wall=40, gb_free=8.1, wall=34276
2023-05-08 09:27:55 - progress_bar.py[line:272] - INFO: epoch 010:    721 / 866 loss=2.313, loss_v1=0, loss_v2=0, nll_loss=1.105, ntokens=1920.7, nsentences=64, sample_size=1920.7, sample_size_v1=0, sample_size_v2=0, ppl=2.15, wps=480.5, ups=0.25, wpb=1920.7, bsz=64, num_updates=8500, lr=2.14724e-05, gnorm=5.638, clip=100, loss_scale=64, train_wall=40, gb_free=7.7, wall=34316
2023-05-08 09:28:34 - progress_bar.py[line:272] - INFO: epoch 010:    731 / 866 loss=2.293, loss_v1=0, loss_v2=0, nll_loss=1.08, ntokens=2019.1, nsentences=64, sample_size=2019.1, sample_size_v1=0, sample_size_v2=0, ppl=2.11, wps=506.7, ups=0.25, wpb=2019.1, bsz=64, num_updates=8510, lr=2.14602e-05, gnorm=5.668, clip=100, loss_scale=64, train_wall=40, gb_free=7.8, wall=34356
2023-05-08 09:29:14 - progress_bar.py[line:272] - INFO: epoch 010:    741 / 866 loss=2.294, loss_v1=0, loss_v2=0, nll_loss=1.081, ntokens=2131.3, nsentences=64, sample_size=2131.3, sample_size_v1=0, sample_size_v2=0, ppl=2.12, wps=532.7, ups=0.25, wpb=2131.3, bsz=64, num_updates=8520, lr=2.14479e-05, gnorm=5.647, clip=100, loss_scale=128, train_wall=40, gb_free=7.8, wall=34396
2023-05-08 09:29:22 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2023-05-08 09:29:58 - progress_bar.py[line:272] - INFO: epoch 010:    752 / 866 loss=2.288, loss_v1=0, loss_v2=0, nll_loss=1.076, ntokens=2096.3, nsentences=64, sample_size=2096.3, sample_size_v1=0, sample_size_v2=0, ppl=2.11, wps=476.9, ups=0.23, wpb=2096.3, bsz=64, num_updates=8530, lr=2.14356e-05, gnorm=5.445, clip=100, loss_scale=64, train_wall=44, gb_free=8.1, wall=34440
2023-05-08 09:30:39 - progress_bar.py[line:272] - INFO: epoch 010:    762 / 866 loss=2.304, loss_v1=0, loss_v2=0, nll_loss=1.095, ntokens=2125.4, nsentences=64, sample_size=2125.4, sample_size_v1=0, sample_size_v2=0, ppl=2.14, wps=529.5, ups=0.25, wpb=2125.4, bsz=64, num_updates=8540, lr=2.14233e-05, gnorm=5.454, clip=100, loss_scale=64, train_wall=40, gb_free=8.3, wall=34480
2023-05-08 09:31:18 - progress_bar.py[line:272] - INFO: epoch 010:    772 / 866 loss=2.289, loss_v1=0, loss_v2=0, nll_loss=1.078, ntokens=2085.7, nsentences=64, sample_size=2085.7, sample_size_v1=0, sample_size_v2=0, ppl=2.11, wps=523.8, ups=0.25, wpb=2085.7, bsz=64, num_updates=8550, lr=2.1411e-05, gnorm=5.684, clip=100, loss_scale=64, train_wall=40, gb_free=6.6, wall=34519
2023-05-08 09:31:59 - progress_bar.py[line:272] - INFO: epoch 010:    782 / 866 loss=2.288, loss_v1=0, loss_v2=0, nll_loss=1.073, ntokens=2278.8, nsentences=64, sample_size=2278.8, sample_size_v1=0, sample_size_v2=0, ppl=2.1, wps=562.7, ups=0.25, wpb=2278.8, bsz=64, num_updates=8560, lr=2.13987e-05, gnorm=5.29, clip=100, loss_scale=64, train_wall=40, gb_free=8, wall=34560
2023-05-08 09:32:39 - progress_bar.py[line:272] - INFO: epoch 010:    792 / 866 loss=2.334, loss_v1=0, loss_v2=0, nll_loss=1.13, ntokens=1976.5, nsentences=64, sample_size=1976.5, sample_size_v1=0, sample_size_v2=0, ppl=2.19, wps=494.4, ups=0.25, wpb=1976.5, bsz=64, num_updates=8570, lr=2.13865e-05, gnorm=6.178, clip=100, loss_scale=64, train_wall=40, gb_free=8.4, wall=34600
2023-05-08 09:33:19 - progress_bar.py[line:272] - INFO: epoch 010:    802 / 866 loss=2.309, loss_v1=0, loss_v2=0, nll_loss=1.096, ntokens=1992.1, nsentences=64, sample_size=1992.1, sample_size_v1=0, sample_size_v2=0, ppl=2.14, wps=501.2, ups=0.25, wpb=1992.1, bsz=64, num_updates=8580, lr=2.13742e-05, gnorm=5.417, clip=100, loss_scale=64, train_wall=40, gb_free=8.1, wall=34640
2023-05-08 09:33:59 - progress_bar.py[line:272] - INFO: epoch 010:    812 / 866 loss=2.285, loss_v1=0, loss_v2=0, nll_loss=1.074, ntokens=2094, nsentences=64, sample_size=2094, sample_size_v1=0, sample_size_v2=0, ppl=2.1, wps=523.9, ups=0.25, wpb=2094, bsz=64, num_updates=8590, lr=2.13619e-05, gnorm=5.09, clip=100, loss_scale=64, train_wall=40, gb_free=7.9, wall=34680
2023-05-08 09:34:39 - progress_bar.py[line:272] - INFO: epoch 010:    822 / 866 loss=2.292, loss_v1=0, loss_v2=0, nll_loss=1.08, ntokens=2092, nsentences=64, sample_size=2092, sample_size_v1=0, sample_size_v2=0, ppl=2.11, wps=522, ups=0.25, wpb=2092, bsz=64, num_updates=8600, lr=2.13496e-05, gnorm=5.425, clip=100, loss_scale=64, train_wall=40, gb_free=7.6, wall=34720
2023-05-08 09:35:19 - progress_bar.py[line:272] - INFO: epoch 010:    832 / 866 loss=2.292, loss_v1=0, loss_v2=0, nll_loss=1.081, ntokens=2219.9, nsentences=64, sample_size=2219.9, sample_size_v1=0, sample_size_v2=0, ppl=2.12, wps=544.6, ups=0.25, wpb=2219.9, bsz=64, num_updates=8610, lr=2.13373e-05, gnorm=5.244, clip=100, loss_scale=64, train_wall=41, gb_free=8.2, wall=34761
2023-05-08 09:36:00 - progress_bar.py[line:272] - INFO: epoch 010:    842 / 866 loss=2.305, loss_v1=0, loss_v2=0, nll_loss=1.095, ntokens=2113, nsentences=64, sample_size=2113, sample_size_v1=0, sample_size_v2=0, ppl=2.14, wps=527.2, ups=0.25, wpb=2113, bsz=64, num_updates=8620, lr=2.1325e-05, gnorm=5.31, clip=100, loss_scale=64, train_wall=40, gb_free=7.7, wall=34801
2023-05-08 09:36:40 - progress_bar.py[line:272] - INFO: epoch 010:    852 / 866 loss=2.294, loss_v1=0, loss_v2=0, nll_loss=1.085, ntokens=2190.2, nsentences=64, sample_size=2190.2, sample_size_v1=0, sample_size_v2=0, ppl=2.12, wps=543.1, ups=0.25, wpb=2190.2, bsz=64, num_updates=8630, lr=2.13128e-05, gnorm=4.98, clip=100, loss_scale=64, train_wall=40, gb_free=8.2, wall=34841
2023-05-08 09:37:20 - progress_bar.py[line:272] - INFO: epoch 010:    862 / 866 loss=2.311, loss_v1=0, loss_v2=0, nll_loss=1.099, ntokens=2026.6, nsentences=64, sample_size=2026.6, sample_size_v1=0, sample_size_v2=0, ppl=2.14, wps=507.7, ups=0.25, wpb=2026.6, bsz=64, num_updates=8640, lr=2.13005e-05, gnorm=5.575, clip=100, loss_scale=64, train_wall=40, gb_free=7.2, wall=34881
2023-05-08 09:37:34 - checkpoint_utils.py[line:64] - INFO: Preparing to save checkpoint for epoch 10 @ 8644 updates
2023-05-08 09:37:34 - trainer.py[line:431] - INFO: Saving checkpoint to ../../checkpoints/OFA/sgcls_checkpoints/_30_3e-5_480/tmp/checkpoint10.pt
local datafile ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 1 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 1 finished initializing row_count and line_idx-to-offset mapping
file ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 1 row count 27700 total row count 55400
slice_id 1 seek offset 27700
2023-05-08 09:37:41 - trainer.py[line:441] - INFO: Finished saving checkpoint to ../../checkpoints/OFA/sgcls_checkpoints/_30_3e-5_480/tmp/checkpoint10.pt
2023-05-08 09:37:44 - checkpoint_utils.py[line:133] - INFO: Saved checkpoint ../../checkpoints/OFA/sgcls_checkpoints/_30_3e-5_480/tmp/checkpoint10.pt (epoch 10 @ 8644 updates, score None) (writing took 9.766993409022689 seconds)
2023-05-08 09:37:44 - train.py[line:332] - INFO: end of epoch 10 (average epoch stats below)
2023-05-08 09:37:44 - progress_bar.py[line:282] - INFO: epoch 010 | loss 2.302 | loss_v1 0 | loss_v2 0 | nll_loss 1.091 | ntokens 2103.28 | nsentences 63.972 | sample_size 2103.28 | sample_size_v1 0 | sample_size_v2 0 | ppl 2.13 | wps 519.7 | ups 0.25 | wpb 2103.3 | bsz 64 | num_updates 8644 | lr 2.12956e-05 | gnorm 5.341 | clip 100 | loss_scale 64 | train_wall 3481 | gb_free 8.7 | wall 34905
2023-05-08 09:37:44 - trainer.py[line:639] - INFO: loading train data for epoch 11
local datafile ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 0 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 0 finished initializing row_count and line_idx-to-offset mapping
file ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 0 row count 27700 total row count 55400
slice_id 0 seek offset 0
2023-05-08 09:37:46 - trainer.py[line:703] - INFO: begin training epoch 11
2023-05-08 09:37:46 - train.py[line:305] - INFO: Start iterating over samples
2023-05-08 09:38:11 - progress_bar.py[line:272] - INFO: epoch 011:      6 / 866 loss=2.288, loss_v1=0, loss_v2=0, nll_loss=1.076, ntokens=2056, nsentences=61.6, sample_size=2056, sample_size_v1=0, sample_size_v2=0, ppl=2.11, wps=403, ups=0.2, wpb=2056, bsz=61.6, num_updates=8650, lr=2.12882e-05, gnorm=5.432, clip=100, loss_scale=64, train_wall=39, gb_free=7.5, wall=34932
2023-05-08 09:38:51 - progress_bar.py[line:272] - INFO: epoch 011:     16 / 866 loss=2.255, loss_v1=0, loss_v2=0, nll_loss=1.04, ntokens=2094.4, nsentences=64, sample_size=2094.4, sample_size_v1=0, sample_size_v2=0, ppl=2.06, wps=519.2, ups=0.25, wpb=2094.4, bsz=64, num_updates=8660, lr=2.12759e-05, gnorm=5.052, clip=100, loss_scale=64, train_wall=40, gb_free=7.5, wall=34972
2023-05-08 09:39:31 - progress_bar.py[line:272] - INFO: epoch 011:     26 / 866 loss=2.257, loss_v1=0, loss_v2=0, nll_loss=1.04, ntokens=1961.6, nsentences=64, sample_size=1961.6, sample_size_v1=0, sample_size_v2=0, ppl=2.06, wps=486.7, ups=0.25, wpb=1961.6, bsz=64, num_updates=8670, lr=2.12636e-05, gnorm=5.557, clip=100, loss_scale=64, train_wall=40, gb_free=7.8, wall=35013
2023-05-08 09:40:12 - progress_bar.py[line:272] - INFO: epoch 011:     36 / 866 loss=2.197, loss_v1=0, loss_v2=0, nll_loss=0.977, ntokens=2199.4, nsentences=64, sample_size=2199.4, sample_size_v1=0, sample_size_v2=0, ppl=1.97, wps=538, ups=0.24, wpb=2199.4, bsz=64, num_updates=8680, lr=2.12513e-05, gnorm=4.712, clip=100, loss_scale=64, train_wall=41, gb_free=6.6, wall=35053
2023-05-08 09:40:53 - progress_bar.py[line:272] - INFO: epoch 011:     46 / 866 loss=2.225, loss_v1=0, loss_v2=0, nll_loss=1.005, ntokens=2017.3, nsentences=64, sample_size=2017.3, sample_size_v1=0, sample_size_v2=0, ppl=2.01, wps=499.4, ups=0.25, wpb=2017.3, bsz=64, num_updates=8690, lr=2.1239e-05, gnorm=5.589, clip=100, loss_scale=64, train_wall=40, gb_free=8, wall=35094
2023-05-08 09:41:34 - progress_bar.py[line:272] - INFO: epoch 011:     56 / 866 loss=2.196, loss_v1=0, loss_v2=0, nll_loss=0.974, ntokens=2095.1, nsentences=64, sample_size=2095.1, sample_size_v1=0, sample_size_v2=0, ppl=1.96, wps=513.5, ups=0.25, wpb=2095.1, bsz=64, num_updates=8700, lr=2.12268e-05, gnorm=5.231, clip=100, loss_scale=64, train_wall=41, gb_free=7.8, wall=35135
2023-05-08 09:42:15 - progress_bar.py[line:272] - INFO: epoch 011:     66 / 866 loss=2.118, loss_v1=0, loss_v2=0, nll_loss=0.887, ntokens=2319.7, nsentences=64, sample_size=2319.7, sample_size_v1=0, sample_size_v2=0, ppl=1.85, wps=561.2, ups=0.24, wpb=2319.7, bsz=64, num_updates=8710, lr=2.12145e-05, gnorm=4.557, clip=100, loss_scale=64, train_wall=41, gb_free=6.7, wall=35176
2023-05-08 09:42:57 - progress_bar.py[line:272] - INFO: epoch 011:     76 / 866 loss=2.182, loss_v1=0, loss_v2=0, nll_loss=0.956, ntokens=2406.4, nsentences=64, sample_size=2406.4, sample_size_v1=0, sample_size_v2=0, ppl=1.94, wps=576.8, ups=0.24, wpb=2406.4, bsz=64, num_updates=8720, lr=2.12022e-05, gnorm=4.399, clip=100, loss_scale=64, train_wall=42, gb_free=6.3, wall=35218
2023-05-08 09:43:37 - progress_bar.py[line:272] - INFO: epoch 011:     86 / 866 loss=2.234, loss_v1=0, loss_v2=0, nll_loss=1.017, ntokens=2127.2, nsentences=64, sample_size=2127.2, sample_size_v1=0, sample_size_v2=0, ppl=2.02, wps=520.4, ups=0.24, wpb=2127.2, bsz=64, num_updates=8730, lr=2.11899e-05, gnorm=5.387, clip=100, loss_scale=64, train_wall=41, gb_free=7.1, wall=35259
2023-05-08 09:44:18 - progress_bar.py[line:272] - INFO: epoch 011:     96 / 866 loss=2.209, loss_v1=0, loss_v2=0, nll_loss=0.989, ntokens=2135.5, nsentences=64, sample_size=2135.5, sample_size_v1=0, sample_size_v2=0, ppl=1.98, wps=526.7, ups=0.25, wpb=2135.5, bsz=64, num_updates=8740, lr=2.11776e-05, gnorm=5.328, clip=100, loss_scale=64, train_wall=40, gb_free=6.6, wall=35299
2023-05-08 09:44:58 - progress_bar.py[line:272] - INFO: epoch 011:    106 / 866 loss=2.292, loss_v1=0, loss_v2=0, nll_loss=1.082, ntokens=2037, nsentences=64, sample_size=2037, sample_size_v1=0, sample_size_v2=0, ppl=2.12, wps=505.6, ups=0.25, wpb=2037, bsz=64, num_updates=8750, lr=2.11653e-05, gnorm=5.917, clip=100, loss_scale=64, train_wall=40, gb_free=6.5, wall=35339
2023-05-08 09:45:39 - progress_bar.py[line:272] - INFO: epoch 011:    116 / 866 loss=2.302, loss_v1=0, loss_v2=0, nll_loss=1.09, ntokens=2065.5, nsentences=64, sample_size=2065.5, sample_size_v1=0, sample_size_v2=0, ppl=2.13, wps=508.7, ups=0.25, wpb=2065.5, bsz=64, num_updates=8760, lr=2.11531e-05, gnorm=5.039, clip=100, loss_scale=64, train_wall=41, gb_free=6.7, wall=35380
2023-05-08 09:46:20 - progress_bar.py[line:272] - INFO: epoch 011:    126 / 866 loss=2.276, loss_v1=0, loss_v2=0, nll_loss=1.062, ntokens=2234.5, nsentences=64, sample_size=2234.5, sample_size_v1=0, sample_size_v2=0, ppl=2.09, wps=542.5, ups=0.24, wpb=2234.5, bsz=64, num_updates=8770, lr=2.11408e-05, gnorm=5.035, clip=100, loss_scale=64, train_wall=41, gb_free=7.5, wall=35421
2023-05-08 09:47:01 - progress_bar.py[line:272] - INFO: epoch 011:    136 / 866 loss=2.259, loss_v1=0, loss_v2=0, nll_loss=1.043, ntokens=2248.4, nsentences=64, sample_size=2248.4, sample_size_v1=0, sample_size_v2=0, ppl=2.06, wps=549.8, ups=0.24, wpb=2248.4, bsz=64, num_updates=8780, lr=2.11285e-05, gnorm=4.827, clip=100, loss_scale=64, train_wall=41, gb_free=6.6, wall=35462
2023-05-08 09:47:42 - progress_bar.py[line:272] - INFO: epoch 011:    146 / 866 loss=2.243, loss_v1=0, loss_v2=0, nll_loss=1.026, ntokens=2176.4, nsentences=64, sample_size=2176.4, sample_size_v1=0, sample_size_v2=0, ppl=2.04, wps=528, ups=0.24, wpb=2176.4, bsz=64, num_updates=8790, lr=2.11162e-05, gnorm=4.686, clip=100, loss_scale=64, train_wall=41, gb_free=6.9, wall=35503
2023-05-08 09:48:24 - progress_bar.py[line:272] - INFO: epoch 011:    156 / 866 loss=2.267, loss_v1=0, loss_v2=0, nll_loss=1.052, ntokens=2231.2, nsentences=64, sample_size=2231.2, sample_size_v1=0, sample_size_v2=0, ppl=2.07, wps=539.5, ups=0.24, wpb=2231.2, bsz=64, num_updates=8800, lr=2.11039e-05, gnorm=5.021, clip=100, loss_scale=64, train_wall=41, gb_free=7.2, wall=35545
2023-05-08 09:49:04 - progress_bar.py[line:272] - INFO: epoch 011:    166 / 866 loss=2.254, loss_v1=0, loss_v2=0, nll_loss=1.038, ntokens=2161.1, nsentences=64, sample_size=2161.1, sample_size_v1=0, sample_size_v2=0, ppl=2.05, wps=532.8, ups=0.25, wpb=2161.1, bsz=64, num_updates=8810, lr=2.10916e-05, gnorm=4.98, clip=100, loss_scale=64, train_wall=41, gb_free=6.6, wall=35585
2023-05-08 09:49:45 - progress_bar.py[line:272] - INFO: epoch 011:    176 / 866 loss=2.271, loss_v1=0, loss_v2=0, nll_loss=1.056, ntokens=2050, nsentences=64, sample_size=2050, sample_size_v1=0, sample_size_v2=0, ppl=2.08, wps=506.9, ups=0.25, wpb=2050, bsz=64, num_updates=8820, lr=2.10794e-05, gnorm=5.531, clip=100, loss_scale=64, train_wall=40, gb_free=7.1, wall=35626
2023-05-08 09:50:26 - progress_bar.py[line:272] - INFO: epoch 011:    186 / 866 loss=2.241, loss_v1=0, loss_v2=0, nll_loss=1.025, ntokens=2187.5, nsentences=64, sample_size=2187.5, sample_size_v1=0, sample_size_v2=0, ppl=2.04, wps=532.9, ups=0.24, wpb=2187.5, bsz=64, num_updates=8830, lr=2.10671e-05, gnorm=5.205, clip=100, loss_scale=64, train_wall=41, gb_free=7.3, wall=35667
2023-05-08 09:51:07 - progress_bar.py[line:272] - INFO: epoch 011:    196 / 866 loss=2.259, loss_v1=0, loss_v2=0, nll_loss=1.043, ntokens=2200.1, nsentences=64, sample_size=2200.1, sample_size_v1=0, sample_size_v2=0, ppl=2.06, wps=532.7, ups=0.24, wpb=2200.1, bsz=64, num_updates=8840, lr=2.10548e-05, gnorm=4.832, clip=100, loss_scale=64, train_wall=41, gb_free=7.4, wall=35708
2023-05-08 09:51:47 - progress_bar.py[line:272] - INFO: epoch 011:    206 / 866 loss=2.301, loss_v1=0, loss_v2=0, nll_loss=1.09, ntokens=1976.2, nsentences=64, sample_size=1976.2, sample_size_v1=0, sample_size_v2=0, ppl=2.13, wps=491.6, ups=0.25, wpb=1976.2, bsz=64, num_updates=8850, lr=2.10425e-05, gnorm=5.379, clip=100, loss_scale=64, train_wall=40, gb_free=7.7, wall=35748
2023-05-08 09:52:27 - progress_bar.py[line:272] - INFO: epoch 011:    216 / 866 loss=2.306, loss_v1=0, loss_v2=0, nll_loss=1.095, ntokens=2173.5, nsentences=64, sample_size=2173.5, sample_size_v1=0, sample_size_v2=0, ppl=2.14, wps=540.2, ups=0.25, wpb=2173.5, bsz=64, num_updates=8860, lr=2.10302e-05, gnorm=5.296, clip=100, loss_scale=64, train_wall=40, gb_free=8.1, wall=35788
2023-05-08 09:53:07 - progress_bar.py[line:272] - INFO: epoch 011:    226 / 866 loss=2.3, loss_v1=0, loss_v2=0, nll_loss=1.09, ntokens=2179, nsentences=64, sample_size=2179, sample_size_v1=0, sample_size_v2=0, ppl=2.13, wps=543.6, ups=0.25, wpb=2179, bsz=64, num_updates=8870, lr=2.10179e-05, gnorm=5.033, clip=100, loss_scale=64, train_wall=40, gb_free=7.8, wall=35829
2023-05-08 09:53:47 - progress_bar.py[line:272] - INFO: epoch 011:    236 / 866 loss=2.334, loss_v1=0, loss_v2=0, nll_loss=1.127, ntokens=2107.4, nsentences=64, sample_size=2107.4, sample_size_v1=0, sample_size_v2=0, ppl=2.18, wps=527.3, ups=0.25, wpb=2107.4, bsz=64, num_updates=8880, lr=2.10057e-05, gnorm=4.986, clip=100, loss_scale=64, train_wall=40, gb_free=7.7, wall=35869
2023-05-08 09:54:28 - progress_bar.py[line:272] - INFO: epoch 011:    246 / 866 loss=2.306, loss_v1=0, loss_v2=0, nll_loss=1.096, ntokens=2213.1, nsentences=64, sample_size=2213.1, sample_size_v1=0, sample_size_v2=0, ppl=2.14, wps=549.7, ups=0.25, wpb=2213.1, bsz=64, num_updates=8890, lr=2.09934e-05, gnorm=4.694, clip=100, loss_scale=64, train_wall=40, gb_free=8, wall=35909
2023-05-08 09:55:08 - progress_bar.py[line:272] - INFO: epoch 011:    256 / 866 loss=2.305, loss_v1=0, loss_v2=0, nll_loss=1.096, ntokens=2108.5, nsentences=64, sample_size=2108.5, sample_size_v1=0, sample_size_v2=0, ppl=2.14, wps=525.3, ups=0.25, wpb=2108.5, bsz=64, num_updates=8900, lr=2.09811e-05, gnorm=5.229, clip=100, loss_scale=64, train_wall=40, gb_free=7.7, wall=35949
2023-05-08 09:55:48 - progress_bar.py[line:272] - INFO: epoch 011:    266 / 866 loss=2.314, loss_v1=0, loss_v2=0, nll_loss=1.105, ntokens=2109.6, nsentences=64, sample_size=2109.6, sample_size_v1=0, sample_size_v2=0, ppl=2.15, wps=523.8, ups=0.25, wpb=2109.6, bsz=64, num_updates=8910, lr=2.09688e-05, gnorm=5.214, clip=100, loss_scale=64, train_wall=40, gb_free=6.8, wall=35989
2023-05-08 09:56:29 - progress_bar.py[line:272] - INFO: epoch 011:    276 / 866 loss=2.303, loss_v1=0, loss_v2=0, nll_loss=1.094, ntokens=2168.3, nsentences=64, sample_size=2168.3, sample_size_v1=0, sample_size_v2=0, ppl=2.13, wps=536.9, ups=0.25, wpb=2168.3, bsz=64, num_updates=8920, lr=2.09565e-05, gnorm=4.666, clip=100, loss_scale=64, train_wall=40, gb_free=7.1, wall=36030
2023-05-08 09:57:09 - progress_bar.py[line:272] - INFO: epoch 011:    286 / 866 loss=2.307, loss_v1=0, loss_v2=0, nll_loss=1.096, ntokens=2179.9, nsentences=64, sample_size=2179.9, sample_size_v1=0, sample_size_v2=0, ppl=2.14, wps=539.8, ups=0.25, wpb=2179.9, bsz=64, num_updates=8930, lr=2.09442e-05, gnorm=5.159, clip=100, loss_scale=64, train_wall=40, gb_free=7.5, wall=36070
2023-05-08 09:57:49 - progress_bar.py[line:272] - INFO: epoch 011:    296 / 866 loss=2.288, loss_v1=0, loss_v2=0, nll_loss=1.077, ntokens=2147.9, nsentences=64, sample_size=2147.9, sample_size_v1=0, sample_size_v2=0, ppl=2.11, wps=532, ups=0.25, wpb=2147.9, bsz=64, num_updates=8940, lr=2.09319e-05, gnorm=5.014, clip=100, loss_scale=64, train_wall=40, gb_free=7.2, wall=36110
2023-05-08 09:58:29 - progress_bar.py[line:272] - INFO: epoch 011:    306 / 866 loss=2.293, loss_v1=0, loss_v2=0, nll_loss=1.08, ntokens=2129.4, nsentences=64, sample_size=2129.4, sample_size_v1=0, sample_size_v2=0, ppl=2.11, wps=529.6, ups=0.25, wpb=2129.4, bsz=64, num_updates=8950, lr=2.09197e-05, gnorm=5.051, clip=100, loss_scale=64, train_wall=40, gb_free=7.2, wall=36151
2023-05-08 09:59:09 - progress_bar.py[line:272] - INFO: epoch 011:    316 / 866 loss=2.3, loss_v1=0, loss_v2=0, nll_loss=1.088, ntokens=2049.6, nsentences=64, sample_size=2049.6, sample_size_v1=0, sample_size_v2=0, ppl=2.13, wps=513.2, ups=0.25, wpb=2049.6, bsz=64, num_updates=8960, lr=2.09074e-05, gnorm=5.174, clip=100, loss_scale=64, train_wall=40, gb_free=7, wall=36191
2023-05-08 09:59:49 - progress_bar.py[line:272] - INFO: epoch 011:    326 / 866 loss=2.328, loss_v1=0, loss_v2=0, nll_loss=1.121, ntokens=2016.2, nsentences=64, sample_size=2016.2, sample_size_v1=0, sample_size_v2=0, ppl=2.18, wps=507, ups=0.25, wpb=2016.2, bsz=64, num_updates=8970, lr=2.08951e-05, gnorm=5.185, clip=100, loss_scale=64, train_wall=40, gb_free=8, wall=36230
2023-05-08 10:00:30 - progress_bar.py[line:272] - INFO: epoch 011:    336 / 866 loss=2.287, loss_v1=0, loss_v2=0, nll_loss=1.074, ntokens=2129.6, nsentences=64, sample_size=2129.6, sample_size_v1=0, sample_size_v2=0, ppl=2.1, wps=528.5, ups=0.25, wpb=2129.6, bsz=64, num_updates=8980, lr=2.08828e-05, gnorm=4.664, clip=100, loss_scale=64, train_wall=40, gb_free=7.7, wall=36271
2023-05-08 10:01:10 - progress_bar.py[line:272] - INFO: epoch 011:    346 / 866 loss=2.297, loss_v1=0, loss_v2=0, nll_loss=1.088, ntokens=1943.9, nsentences=64, sample_size=1943.9, sample_size_v1=0, sample_size_v2=0, ppl=2.13, wps=485.3, ups=0.25, wpb=1943.9, bsz=64, num_updates=8990, lr=2.08705e-05, gnorm=5.752, clip=100, loss_scale=64, train_wall=40, gb_free=7.7, wall=36311
2023-05-08 10:01:49 - progress_bar.py[line:272] - INFO: epoch 011:    356 / 866 loss=2.328, loss_v1=0, loss_v2=0, nll_loss=1.121, ntokens=1991.6, nsentences=64, sample_size=1991.6, sample_size_v1=0, sample_size_v2=0, ppl=2.18, wps=501.9, ups=0.25, wpb=1991.6, bsz=64, num_updates=9000, lr=2.08582e-05, gnorm=5.504, clip=100, loss_scale=64, train_wall=40, gb_free=8.3, wall=36350
2023-05-08 10:02:29 - progress_bar.py[line:272] - INFO: epoch 011:    366 / 866 loss=2.315, loss_v1=0, loss_v2=0, nll_loss=1.105, ntokens=1975.6, nsentences=64, sample_size=1975.6, sample_size_v1=0, sample_size_v2=0, ppl=2.15, wps=495.6, ups=0.25, wpb=1975.6, bsz=64, num_updates=9010, lr=2.0846e-05, gnorm=5.317, clip=100, loss_scale=64, train_wall=40, gb_free=8.1, wall=36390
2023-05-08 10:03:09 - progress_bar.py[line:272] - INFO: epoch 011:    376 / 866 loss=2.299, loss_v1=0, loss_v2=0, nll_loss=1.088, ntokens=2108.1, nsentences=64, sample_size=2108.1, sample_size_v1=0, sample_size_v2=0, ppl=2.13, wps=526.6, ups=0.25, wpb=2108.1, bsz=64, num_updates=9020, lr=2.08337e-05, gnorm=4.855, clip=100, loss_scale=64, train_wall=40, gb_free=7.8, wall=36430
2023-05-08 10:03:49 - progress_bar.py[line:272] - INFO: epoch 011:    386 / 866 loss=2.297, loss_v1=0, loss_v2=0, nll_loss=1.086, ntokens=2138, nsentences=64, sample_size=2138, sample_size_v1=0, sample_size_v2=0, ppl=2.12, wps=534.2, ups=0.25, wpb=2138, bsz=64, num_updates=9030, lr=2.08214e-05, gnorm=4.894, clip=100, loss_scale=64, train_wall=40, gb_free=7.7, wall=36470
2023-05-08 10:04:05 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2023-05-08 10:04:33 - progress_bar.py[line:272] - INFO: epoch 011:    397 / 866 loss=2.298, loss_v1=0, loss_v2=0, nll_loss=1.088, ntokens=2045.7, nsentences=64, sample_size=2045.7, sample_size_v1=0, sample_size_v2=0, ppl=2.13, wps=467.1, ups=0.23, wpb=2045.7, bsz=64, num_updates=9040, lr=2.08091e-05, gnorm=5.103, clip=100, loss_scale=64, train_wall=44, gb_free=7.4, wall=36514
2023-05-08 10:05:13 - progress_bar.py[line:272] - INFO: epoch 011:    407 / 866 loss=2.305, loss_v1=0, loss_v2=0, nll_loss=1.094, ntokens=2083.1, nsentences=64, sample_size=2083.1, sample_size_v1=0, sample_size_v2=0, ppl=2.14, wps=520.3, ups=0.25, wpb=2083.1, bsz=64, num_updates=9050, lr=2.07968e-05, gnorm=4.862, clip=100, loss_scale=64, train_wall=40, gb_free=7.4, wall=36554
2023-05-08 10:05:53 - progress_bar.py[line:272] - INFO: epoch 011:    417 / 866 loss=2.291, loss_v1=0, loss_v2=0, nll_loss=1.082, ntokens=2117.4, nsentences=64, sample_size=2117.4, sample_size_v1=0, sample_size_v2=0, ppl=2.12, wps=527.9, ups=0.25, wpb=2117.4, bsz=64, num_updates=9060, lr=2.07845e-05, gnorm=5.315, clip=100, loss_scale=64, train_wall=40, gb_free=8.1, wall=36594
2023-05-08 10:06:33 - progress_bar.py[line:272] - INFO: epoch 011:    427 / 866 loss=2.281, loss_v1=0, loss_v2=0, nll_loss=1.067, ntokens=2086.1, nsentences=64, sample_size=2086.1, sample_size_v1=0, sample_size_v2=0, ppl=2.1, wps=520.7, ups=0.25, wpb=2086.1, bsz=64, num_updates=9070, lr=2.07723e-05, gnorm=4.799, clip=100, loss_scale=64, train_wall=40, gb_free=7.6, wall=36634
2023-05-08 10:07:13 - progress_bar.py[line:272] - INFO: epoch 011:    437 / 866 loss=2.31, loss_v1=0, loss_v2=0, nll_loss=1.098, ntokens=2130.3, nsentences=64, sample_size=2130.3, sample_size_v1=0, sample_size_v2=0, ppl=2.14, wps=531.9, ups=0.25, wpb=2130.3, bsz=64, num_updates=9080, lr=2.076e-05, gnorm=4.704, clip=100, loss_scale=64, train_wall=40, gb_free=8, wall=36674
2023-05-08 10:07:53 - progress_bar.py[line:272] - INFO: epoch 011:    447 / 866 loss=2.328, loss_v1=0, loss_v2=0, nll_loss=1.122, ntokens=2002.9, nsentences=64, sample_size=2002.9, sample_size_v1=0, sample_size_v2=0, ppl=2.18, wps=500.6, ups=0.25, wpb=2002.9, bsz=64, num_updates=9090, lr=2.07477e-05, gnorm=5.793, clip=100, loss_scale=64, train_wall=40, gb_free=7.2, wall=36714
2023-05-08 10:08:33 - progress_bar.py[line:272] - INFO: epoch 011:    457 / 866 loss=2.31, loss_v1=0, loss_v2=0, nll_loss=1.102, ntokens=2062.3, nsentences=64, sample_size=2062.3, sample_size_v1=0, sample_size_v2=0, ppl=2.15, wps=513.2, ups=0.25, wpb=2062.3, bsz=64, num_updates=9100, lr=2.07354e-05, gnorm=5.314, clip=100, loss_scale=64, train_wall=40, gb_free=6.8, wall=36755
2023-05-08 10:09:14 - progress_bar.py[line:272] - INFO: epoch 011:    467 / 866 loss=2.302, loss_v1=0, loss_v2=0, nll_loss=1.09, ntokens=2158.4, nsentences=64, sample_size=2158.4, sample_size_v1=0, sample_size_v2=0, ppl=2.13, wps=538.4, ups=0.25, wpb=2158.4, bsz=64, num_updates=9110, lr=2.07231e-05, gnorm=4.905, clip=100, loss_scale=64, train_wall=40, gb_free=7.4, wall=36795
2023-05-08 10:09:54 - progress_bar.py[line:272] - INFO: epoch 011:    477 / 866 loss=2.307, loss_v1=0, loss_v2=0, nll_loss=1.099, ntokens=2238.4, nsentences=64, sample_size=2238.4, sample_size_v1=0, sample_size_v2=0, ppl=2.14, wps=548.3, ups=0.24, wpb=2238.4, bsz=64, num_updates=9120, lr=2.07108e-05, gnorm=5.049, clip=100, loss_scale=64, train_wall=41, gb_free=8.2, wall=36835
2023-05-08 10:10:34 - progress_bar.py[line:272] - INFO: epoch 011:    487 / 866 loss=2.298, loss_v1=0, loss_v2=0, nll_loss=1.086, ntokens=2060.3, nsentences=64, sample_size=2060.3, sample_size_v1=0, sample_size_v2=0, ppl=2.12, wps=514.5, ups=0.25, wpb=2060.3, bsz=64, num_updates=9130, lr=2.06986e-05, gnorm=4.751, clip=100, loss_scale=64, train_wall=40, gb_free=8.4, wall=36876
2023-05-08 10:11:14 - progress_bar.py[line:272] - INFO: epoch 011:    497 / 866 loss=2.275, loss_v1=0, loss_v2=0, nll_loss=1.065, ntokens=2048.4, nsentences=64, sample_size=2048.4, sample_size_v1=0, sample_size_v2=0, ppl=2.09, wps=512, ups=0.25, wpb=2048.4, bsz=64, num_updates=9140, lr=2.06863e-05, gnorm=5.218, clip=100, loss_scale=64, train_wall=40, gb_free=7.2, wall=36916
2023-05-08 10:11:54 - progress_bar.py[line:272] - INFO: epoch 011:    507 / 866 loss=2.311, loss_v1=0, loss_v2=0, nll_loss=1.099, ntokens=2101.5, nsentences=64, sample_size=2101.5, sample_size_v1=0, sample_size_v2=0, ppl=2.14, wps=525.7, ups=0.25, wpb=2101.5, bsz=64, num_updates=9150, lr=2.0674e-05, gnorm=5.115, clip=100, loss_scale=64, train_wall=40, gb_free=7.6, wall=36956
2023-05-08 10:12:34 - progress_bar.py[line:272] - INFO: epoch 011:    517 / 866 loss=2.308, loss_v1=0, loss_v2=0, nll_loss=1.098, ntokens=2207.3, nsentences=64, sample_size=2207.3, sample_size_v1=0, sample_size_v2=0, ppl=2.14, wps=551.7, ups=0.25, wpb=2207.3, bsz=64, num_updates=9160, lr=2.06617e-05, gnorm=4.977, clip=100, loss_scale=64, train_wall=40, gb_free=8.1, wall=36996
2023-05-08 10:13:14 - progress_bar.py[line:272] - INFO: epoch 011:    527 / 866 loss=2.305, loss_v1=0, loss_v2=0, nll_loss=1.096, ntokens=1979.5, nsentences=64, sample_size=1979.5, sample_size_v1=0, sample_size_v2=0, ppl=2.14, wps=498.7, ups=0.25, wpb=1979.5, bsz=64, num_updates=9170, lr=2.06494e-05, gnorm=5.471, clip=100, loss_scale=64, train_wall=40, gb_free=8.2, wall=37035
2023-05-08 10:13:54 - progress_bar.py[line:272] - INFO: epoch 011:    537 / 866 loss=2.284, loss_v1=0, loss_v2=0, nll_loss=1.071, ntokens=2105, nsentences=64, sample_size=2105, sample_size_v1=0, sample_size_v2=0, ppl=2.1, wps=526.4, ups=0.25, wpb=2105, bsz=64, num_updates=9180, lr=2.06371e-05, gnorm=5.432, clip=100, loss_scale=64, train_wall=40, gb_free=8.1, wall=37075
2023-05-08 10:14:34 - progress_bar.py[line:272] - INFO: epoch 011:    547 / 866 loss=2.317, loss_v1=0, loss_v2=0, nll_loss=1.109, ntokens=2281.5, nsentences=64, sample_size=2281.5, sample_size_v1=0, sample_size_v2=0, ppl=2.16, wps=567.2, ups=0.25, wpb=2281.5, bsz=64, num_updates=9190, lr=2.06248e-05, gnorm=5.085, clip=100, loss_scale=64, train_wall=40, gb_free=7.6, wall=37115
2023-05-08 10:15:15 - progress_bar.py[line:272] - INFO: epoch 011:    557 / 866 loss=2.311, loss_v1=0, loss_v2=0, nll_loss=1.102, ntokens=2288, nsentences=64, sample_size=2288, sample_size_v1=0, sample_size_v2=0, ppl=2.15, wps=564.9, ups=0.25, wpb=2288, bsz=64, num_updates=9200, lr=2.06126e-05, gnorm=4.911, clip=100, loss_scale=64, train_wall=40, gb_free=8.1, wall=37156
2023-05-08 10:15:55 - progress_bar.py[line:272] - INFO: epoch 011:    567 / 866 loss=2.307, loss_v1=0, loss_v2=0, nll_loss=1.097, ntokens=2212.7, nsentences=64, sample_size=2212.7, sample_size_v1=0, sample_size_v2=0, ppl=2.14, wps=553.4, ups=0.25, wpb=2212.7, bsz=64, num_updates=9210, lr=2.06003e-05, gnorm=4.841, clip=100, loss_scale=64, train_wall=40, gb_free=8.1, wall=37196
2023-05-08 10:16:35 - progress_bar.py[line:272] - INFO: epoch 011:    577 / 866 loss=2.302, loss_v1=0, loss_v2=0, nll_loss=1.09, ntokens=2143.4, nsentences=64, sample_size=2143.4, sample_size_v1=0, sample_size_v2=0, ppl=2.13, wps=534.3, ups=0.25, wpb=2143.4, bsz=64, num_updates=9220, lr=2.0588e-05, gnorm=4.65, clip=100, loss_scale=64, train_wall=40, gb_free=8.1, wall=37236
2023-05-08 10:17:15 - progress_bar.py[line:272] - INFO: epoch 011:    587 / 866 loss=2.318, loss_v1=0, loss_v2=0, nll_loss=1.11, ntokens=2086.5, nsentences=64, sample_size=2086.5, sample_size_v1=0, sample_size_v2=0, ppl=2.16, wps=518.9, ups=0.25, wpb=2086.5, bsz=64, num_updates=9230, lr=2.05757e-05, gnorm=5.191, clip=100, loss_scale=64, train_wall=40, gb_free=8.4, wall=37276
2023-05-08 10:17:56 - progress_bar.py[line:272] - INFO: epoch 011:    597 / 866 loss=2.27, loss_v1=0, loss_v2=0, nll_loss=1.056, ntokens=2154.7, nsentences=64, sample_size=2154.7, sample_size_v1=0, sample_size_v2=0, ppl=2.08, wps=533.7, ups=0.25, wpb=2154.7, bsz=64, num_updates=9240, lr=2.05634e-05, gnorm=5.162, clip=100, loss_scale=64, train_wall=40, gb_free=7.7, wall=37317
2023-05-08 10:18:36 - progress_bar.py[line:272] - INFO: epoch 011:    607 / 866 loss=2.294, loss_v1=0, loss_v2=0, nll_loss=1.085, ntokens=2011.2, nsentences=64, sample_size=2011.2, sample_size_v1=0, sample_size_v2=0, ppl=2.12, wps=501.4, ups=0.25, wpb=2011.2, bsz=64, num_updates=9250, lr=2.05511e-05, gnorm=5.085, clip=100, loss_scale=64, train_wall=40, gb_free=7.3, wall=37357
2023-05-08 10:19:16 - progress_bar.py[line:272] - INFO: epoch 011:    617 / 866 loss=2.319, loss_v1=0, loss_v2=0, nll_loss=1.107, ntokens=1941.8, nsentences=64, sample_size=1941.8, sample_size_v1=0, sample_size_v2=0, ppl=2.15, wps=484.4, ups=0.25, wpb=1941.8, bsz=64, num_updates=9260, lr=2.05389e-05, gnorm=5.375, clip=100, loss_scale=64, train_wall=40, gb_free=7.8, wall=37397
2023-05-08 10:19:56 - progress_bar.py[line:272] - INFO: epoch 011:    627 / 866 loss=2.303, loss_v1=0, loss_v2=0, nll_loss=1.094, ntokens=2052.9, nsentences=64, sample_size=2052.9, sample_size_v1=0, sample_size_v2=0, ppl=2.14, wps=510.7, ups=0.25, wpb=2052.9, bsz=64, num_updates=9270, lr=2.05266e-05, gnorm=4.978, clip=100, loss_scale=64, train_wall=40, gb_free=8.2, wall=37437
2023-05-08 10:20:36 - progress_bar.py[line:272] - INFO: epoch 011:    637 / 866 loss=2.284, loss_v1=0, loss_v2=0, nll_loss=1.07, ntokens=2035.5, nsentences=64, sample_size=2035.5, sample_size_v1=0, sample_size_v2=0, ppl=2.1, wps=509.1, ups=0.25, wpb=2035.5, bsz=64, num_updates=9280, lr=2.05143e-05, gnorm=5.331, clip=100, loss_scale=64, train_wall=40, gb_free=8, wall=37477
2023-05-08 10:21:16 - progress_bar.py[line:272] - INFO: epoch 011:    647 / 866 loss=2.298, loss_v1=0, loss_v2=0, nll_loss=1.088, ntokens=2063.3, nsentences=64, sample_size=2063.3, sample_size_v1=0, sample_size_v2=0, ppl=2.13, wps=519.3, ups=0.25, wpb=2063.3, bsz=64, num_updates=9290, lr=2.0502e-05, gnorm=5.209, clip=100, loss_scale=64, train_wall=40, gb_free=8.2, wall=37517
2023-05-08 10:21:55 - progress_bar.py[line:272] - INFO: epoch 011:    657 / 866 loss=2.325, loss_v1=0, loss_v2=0, nll_loss=1.119, ntokens=1895.4, nsentences=64, sample_size=1895.4, sample_size_v1=0, sample_size_v2=0, ppl=2.17, wps=478.3, ups=0.25, wpb=1895.4, bsz=64, num_updates=9300, lr=2.04897e-05, gnorm=5.837, clip=100, loss_scale=64, train_wall=40, gb_free=7.9, wall=37556
2023-05-08 10:22:35 - progress_bar.py[line:272] - INFO: epoch 011:    667 / 866 loss=2.307, loss_v1=0, loss_v2=0, nll_loss=1.094, ntokens=2004.3, nsentences=64, sample_size=2004.3, sample_size_v1=0, sample_size_v2=0, ppl=2.13, wps=501.4, ups=0.25, wpb=2004.3, bsz=64, num_updates=9310, lr=2.04774e-05, gnorm=5.459, clip=100, loss_scale=64, train_wall=40, gb_free=7.8, wall=37596
2023-05-08 10:23:15 - progress_bar.py[line:272] - INFO: epoch 011:    677 / 866 loss=2.295, loss_v1=0, loss_v2=0, nll_loss=1.085, ntokens=2088.4, nsentences=64, sample_size=2088.4, sample_size_v1=0, sample_size_v2=0, ppl=2.12, wps=522.9, ups=0.25, wpb=2088.4, bsz=64, num_updates=9320, lr=2.04652e-05, gnorm=5.195, clip=100, loss_scale=64, train_wall=40, gb_free=8.1, wall=37636
2023-05-08 10:23:55 - progress_bar.py[line:272] - INFO: epoch 011:    687 / 866 loss=2.296, loss_v1=0, loss_v2=0, nll_loss=1.087, ntokens=1980.4, nsentences=64, sample_size=1980.4, sample_size_v1=0, sample_size_v2=0, ppl=2.12, wps=497.5, ups=0.25, wpb=1980.4, bsz=64, num_updates=9330, lr=2.04529e-05, gnorm=5.797, clip=100, loss_scale=64, train_wall=40, gb_free=8.4, wall=37676
2023-05-08 10:24:35 - progress_bar.py[line:272] - INFO: epoch 011:    697 / 866 loss=2.306, loss_v1=0, loss_v2=0, nll_loss=1.095, ntokens=2133.2, nsentences=64, sample_size=2133.2, sample_size_v1=0, sample_size_v2=0, ppl=2.14, wps=530.7, ups=0.25, wpb=2133.2, bsz=64, num_updates=9340, lr=2.04406e-05, gnorm=5.171, clip=100, loss_scale=64, train_wall=40, gb_free=7.1, wall=37716
2023-05-08 10:25:15 - progress_bar.py[line:272] - INFO: epoch 011:    707 / 866 loss=2.31, loss_v1=0, loss_v2=0, nll_loss=1.101, ntokens=1972.1, nsentences=64, sample_size=1972.1, sample_size_v1=0, sample_size_v2=0, ppl=2.15, wps=493.9, ups=0.25, wpb=1972.1, bsz=64, num_updates=9350, lr=2.04283e-05, gnorm=5.091, clip=100, loss_scale=64, train_wall=40, gb_free=8.2, wall=37756
2023-05-08 10:25:55 - progress_bar.py[line:272] - INFO: epoch 011:    717 / 866 loss=2.315, loss_v1=0, loss_v2=0, nll_loss=1.107, ntokens=1886.4, nsentences=64, sample_size=1886.4, sample_size_v1=0, sample_size_v2=0, ppl=2.15, wps=473.6, ups=0.25, wpb=1886.4, bsz=64, num_updates=9360, lr=2.0416e-05, gnorm=5.523, clip=100, loss_scale=64, train_wall=40, gb_free=8, wall=37796
2023-05-08 10:26:35 - progress_bar.py[line:272] - INFO: epoch 011:    727 / 866 loss=2.275, loss_v1=0, loss_v2=0, nll_loss=1.061, ntokens=1984.1, nsentences=64, sample_size=1984.1, sample_size_v1=0, sample_size_v2=0, ppl=2.09, wps=498.4, ups=0.25, wpb=1984.1, bsz=64, num_updates=9370, lr=2.04037e-05, gnorm=5.029, clip=100, loss_scale=64, train_wall=40, gb_free=8.3, wall=37836
2023-05-08 10:27:15 - progress_bar.py[line:272] - INFO: epoch 011:    737 / 866 loss=2.274, loss_v1=0, loss_v2=0, nll_loss=1.059, ntokens=2105.3, nsentences=64, sample_size=2105.3, sample_size_v1=0, sample_size_v2=0, ppl=2.08, wps=525.5, ups=0.25, wpb=2105.3, bsz=64, num_updates=9380, lr=2.03915e-05, gnorm=4.931, clip=100, loss_scale=64, train_wall=40, gb_free=7.8, wall=37876
2023-05-08 10:27:55 - progress_bar.py[line:272] - INFO: epoch 011:    747 / 866 loss=2.268, loss_v1=0, loss_v2=0, nll_loss=1.052, ntokens=2126.6, nsentences=64, sample_size=2126.6, sample_size_v1=0, sample_size_v2=0, ppl=2.07, wps=529.8, ups=0.25, wpb=2126.6, bsz=64, num_updates=9390, lr=2.03792e-05, gnorm=4.856, clip=100, loss_scale=64, train_wall=40, gb_free=7.5, wall=37916
2023-05-08 10:28:35 - progress_bar.py[line:272] - INFO: epoch 011:    757 / 866 loss=2.283, loss_v1=0, loss_v2=0, nll_loss=1.073, ntokens=2055.9, nsentences=64, sample_size=2055.9, sample_size_v1=0, sample_size_v2=0, ppl=2.1, wps=513.3, ups=0.25, wpb=2055.9, bsz=64, num_updates=9400, lr=2.03669e-05, gnorm=5.433, clip=100, loss_scale=64, train_wall=40, gb_free=7.9, wall=37956
2023-05-08 10:29:15 - progress_bar.py[line:272] - INFO: epoch 011:    767 / 866 loss=2.283, loss_v1=0, loss_v2=0, nll_loss=1.071, ntokens=2104.6, nsentences=64, sample_size=2104.6, sample_size_v1=0, sample_size_v2=0, ppl=2.1, wps=521.7, ups=0.25, wpb=2104.6, bsz=64, num_updates=9410, lr=2.03546e-05, gnorm=5.526, clip=100, loss_scale=64, train_wall=40, gb_free=8.3, wall=37997
2023-05-08 10:29:56 - progress_bar.py[line:272] - INFO: epoch 011:    777 / 866 loss=2.277, loss_v1=0, loss_v2=0, nll_loss=1.064, ntokens=2258.8, nsentences=64, sample_size=2258.8, sample_size_v1=0, sample_size_v2=0, ppl=2.09, wps=562.2, ups=0.25, wpb=2258.8, bsz=64, num_updates=9420, lr=2.03423e-05, gnorm=5.468, clip=100, loss_scale=64, train_wall=40, gb_free=7.9, wall=38037
2023-05-08 10:30:36 - progress_bar.py[line:272] - INFO: epoch 011:    787 / 866 loss=2.296, loss_v1=0, loss_v2=0, nll_loss=1.083, ntokens=2038.1, nsentences=64, sample_size=2038.1, sample_size_v1=0, sample_size_v2=0, ppl=2.12, wps=510.7, ups=0.25, wpb=2038.1, bsz=64, num_updates=9430, lr=2.033e-05, gnorm=5.712, clip=100, loss_scale=64, train_wall=40, gb_free=7.7, wall=38077
2023-05-08 10:31:15 - progress_bar.py[line:272] - INFO: epoch 011:    797 / 866 loss=2.302, loss_v1=0, loss_v2=0, nll_loss=1.091, ntokens=2084.7, nsentences=64, sample_size=2084.7, sample_size_v1=0, sample_size_v2=0, ppl=2.13, wps=522.3, ups=0.25, wpb=2084.7, bsz=64, num_updates=9440, lr=2.03177e-05, gnorm=5.293, clip=100, loss_scale=64, train_wall=40, gb_free=7.9, wall=38117
2023-05-08 10:31:55 - progress_bar.py[line:272] - INFO: epoch 011:    807 / 866 loss=2.276, loss_v1=0, loss_v2=0, nll_loss=1.062, ntokens=1945.9, nsentences=64, sample_size=1945.9, sample_size_v1=0, sample_size_v2=0, ppl=2.09, wps=490.8, ups=0.25, wpb=1945.9, bsz=64, num_updates=9450, lr=2.03055e-05, gnorm=5.34, clip=100, loss_scale=64, train_wall=40, gb_free=7.8, wall=38156
2023-05-08 10:32:35 - progress_bar.py[line:272] - INFO: epoch 011:    817 / 866 loss=2.273, loss_v1=0, loss_v2=0, nll_loss=1.059, ntokens=2085.3, nsentences=64, sample_size=2085.3, sample_size_v1=0, sample_size_v2=0, ppl=2.08, wps=519.6, ups=0.25, wpb=2085.3, bsz=64, num_updates=9460, lr=2.02932e-05, gnorm=5.404, clip=100, loss_scale=64, train_wall=40, gb_free=8, wall=38196
2023-05-08 10:33:16 - progress_bar.py[line:272] - INFO: epoch 011:    827 / 866 loss=2.272, loss_v1=0, loss_v2=0, nll_loss=1.059, ntokens=2163, nsentences=64, sample_size=2163, sample_size_v1=0, sample_size_v2=0, ppl=2.08, wps=534.7, ups=0.25, wpb=2163, bsz=64, num_updates=9470, lr=2.02809e-05, gnorm=4.894, clip=100, loss_scale=64, train_wall=40, gb_free=8.1, wall=38237
2023-05-08 10:33:56 - progress_bar.py[line:272] - INFO: epoch 011:    837 / 866 loss=2.288, loss_v1=0, loss_v2=0, nll_loss=1.075, ntokens=2161.7, nsentences=64, sample_size=2161.7, sample_size_v1=0, sample_size_v2=0, ppl=2.11, wps=534.4, ups=0.25, wpb=2161.7, bsz=64, num_updates=9480, lr=2.02686e-05, gnorm=4.923, clip=100, loss_scale=64, train_wall=40, gb_free=8.2, wall=38277
2023-05-08 10:34:36 - progress_bar.py[line:272] - INFO: epoch 011:    847 / 866 loss=2.28, loss_v1=0, loss_v2=0, nll_loss=1.067, ntokens=2168.3, nsentences=64, sample_size=2168.3, sample_size_v1=0, sample_size_v2=0, ppl=2.1, wps=540.1, ups=0.25, wpb=2168.3, bsz=64, num_updates=9490, lr=2.02563e-05, gnorm=4.753, clip=100, loss_scale=64, train_wall=40, gb_free=6.9, wall=38317
2023-05-08 10:35:16 - progress_bar.py[line:272] - INFO: epoch 011:    857 / 866 loss=2.282, loss_v1=0, loss_v2=0, nll_loss=1.07, ntokens=2080.9, nsentences=64, sample_size=2080.9, sample_size_v1=0, sample_size_v2=0, ppl=2.1, wps=517.9, ups=0.25, wpb=2080.9, bsz=64, num_updates=9500, lr=2.0244e-05, gnorm=5.168, clip=100, loss_scale=64, train_wall=40, gb_free=7.8, wall=38358
local datafile ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 1 begin to initialize row_count and line_idx-to-offset mapping
2023-05-08 10:35:51 - train.py[line:332] - INFO: end of epoch 11 (average epoch stats below)
2023-05-08 10:35:51 - progress_bar.py[line:282] - INFO: epoch 011 | loss 2.285 | loss_v1 0 | loss_v2 0 | nll_loss 1.073 | ntokens 2103.24 | nsentences 63.972 | sample_size 2103.24 | sample_size_v1 0 | sample_size_v2 0 | ppl 2.1 | wps 521.8 | ups 0.25 | wpb 2103.2 | bsz 64 | num_updates 9509 | lr 2.0233e-05 | gnorm 5.147 | clip 100 | loss_scale 64 | train_wall 3480 | gb_free 8.7 | wall 38392
2023-05-08 10:35:51 - trainer.py[line:639] - INFO: loading train data for epoch 12
local datafile ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 0 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 1 finished initializing row_count and line_idx-to-offset mapping
file ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 1 row count 27700 total row count 55400
slice_id 1 seek offset 27700
local datafile ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 0 finished initializing row_count and line_idx-to-offset mapping
file ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 0 row count 27700 total row count 55400
slice_id 0 seek offset 0
2023-05-08 10:35:53 - trainer.py[line:703] - INFO: begin training epoch 12
2023-05-08 10:35:53 - train.py[line:305] - INFO: Start iterating over samples
2023-05-08 10:35:57 - progress_bar.py[line:272] - INFO: epoch 012:      1 / 866 loss=2.317, loss_v1=0, loss_v2=0, nll_loss=1.105, ntokens=2052.4, nsentences=61.6, sample_size=2052.4, sample_size_v1=0, sample_size_v2=0, ppl=2.15, wps=504.3, ups=0.25, wpb=2052.4, bsz=61.6, num_updates=9510, lr=2.02318e-05, gnorm=5.265, clip=100, loss_scale=64, train_wall=39, gb_free=7.6, wall=38398
2023-05-08 10:36:38 - progress_bar.py[line:272] - INFO: epoch 012:     11 / 866 loss=2.229, loss_v1=0, loss_v2=0, nll_loss=1.013, ntokens=2113.9, nsentences=64, sample_size=2113.9, sample_size_v1=0, sample_size_v2=0, ppl=2.02, wps=520.7, ups=0.25, wpb=2113.9, bsz=64, num_updates=9520, lr=2.02195e-05, gnorm=4.794, clip=100, loss_scale=64, train_wall=41, gb_free=7.8, wall=38439
2023-05-08 10:37:18 - progress_bar.py[line:272] - INFO: epoch 012:     21 / 866 loss=2.218, loss_v1=0, loss_v2=0, nll_loss=0.997, ntokens=2073.7, nsentences=64, sample_size=2073.7, sample_size_v1=0, sample_size_v2=0, ppl=2, wps=513.5, ups=0.25, wpb=2073.7, bsz=64, num_updates=9530, lr=2.02072e-05, gnorm=5.173, clip=100, loss_scale=64, train_wall=40, gb_free=7.5, wall=38479
2023-05-08 10:37:58 - progress_bar.py[line:272] - INFO: epoch 012:     31 / 866 loss=2.23, loss_v1=0, loss_v2=0, nll_loss=1.01, ntokens=1996.7, nsentences=64, sample_size=1996.7, sample_size_v1=0, sample_size_v2=0, ppl=2.01, wps=495.3, ups=0.25, wpb=1996.7, bsz=64, num_updates=9540, lr=2.01949e-05, gnorm=5.584, clip=100, loss_scale=64, train_wall=40, gb_free=7.4, wall=38520
2023-05-08 10:38:36 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2023-05-08 10:38:44 - progress_bar.py[line:272] - INFO: epoch 012:     42 / 866 loss=2.165, loss_v1=0, loss_v2=0, nll_loss=0.942, ntokens=2221.6, nsentences=64, sample_size=2221.6, sample_size_v1=0, sample_size_v2=0, ppl=1.92, wps=491.3, ups=0.22, wpb=2221.6, bsz=64, num_updates=9550, lr=2.01826e-05, gnorm=4.593, clip=100, loss_scale=64, train_wall=45, gb_free=7.8, wall=38565
2023-05-08 10:39:24 - progress_bar.py[line:272] - INFO: epoch 012:     52 / 866 loss=2.238, loss_v1=0, loss_v2=0, nll_loss=1.02, ntokens=1980.2, nsentences=64, sample_size=1980.2, sample_size_v1=0, sample_size_v2=0, ppl=2.03, wps=490.2, ups=0.25, wpb=1980.2, bsz=64, num_updates=9560, lr=2.01703e-05, gnorm=5.418, clip=100, loss_scale=64, train_wall=40, gb_free=8, wall=38605
2023-05-08 10:40:05 - progress_bar.py[line:272] - INFO: epoch 012:     62 / 866 loss=2.112, loss_v1=0, loss_v2=0, nll_loss=0.88, ntokens=2226.9, nsentences=64, sample_size=2226.9, sample_size_v1=0, sample_size_v2=0, ppl=1.84, wps=547.8, ups=0.25, wpb=2226.9, bsz=64, num_updates=9570, lr=2.01581e-05, gnorm=4.82, clip=100, loss_scale=64, train_wall=41, gb_free=6.5, wall=38646
2023-05-08 10:40:46 - progress_bar.py[line:272] - INFO: epoch 012:     72 / 866 loss=2.154, loss_v1=0, loss_v2=0, nll_loss=0.926, ntokens=2446.2, nsentences=64, sample_size=2446.2, sample_size_v1=0, sample_size_v2=0, ppl=1.9, wps=587.2, ups=0.24, wpb=2446.2, bsz=64, num_updates=9580, lr=2.01458e-05, gnorm=4.027, clip=100, loss_scale=64, train_wall=42, gb_free=6.5, wall=38688
2023-05-08 10:41:28 - progress_bar.py[line:272] - INFO: epoch 012:     82 / 866 loss=2.196, loss_v1=0, loss_v2=0, nll_loss=0.975, ntokens=2236.1, nsentences=64, sample_size=2236.1, sample_size_v1=0, sample_size_v2=0, ppl=1.97, wps=543.9, ups=0.24, wpb=2236.1, bsz=64, num_updates=9590, lr=2.01335e-05, gnorm=4.931, clip=100, loss_scale=64, train_wall=41, gb_free=7.1, wall=38729
2023-05-08 10:42:08 - progress_bar.py[line:272] - INFO: epoch 012:     92 / 866 loss=2.199, loss_v1=0, loss_v2=0, nll_loss=0.977, ntokens=2133.1, nsentences=64, sample_size=2133.1, sample_size_v1=0, sample_size_v2=0, ppl=1.97, wps=523.5, ups=0.25, wpb=2133.1, bsz=64, num_updates=9600, lr=2.01212e-05, gnorm=4.561, clip=100, loss_scale=64, train_wall=41, gb_free=7.4, wall=38769
2023-05-08 10:42:49 - progress_bar.py[line:272] - INFO: epoch 012:    102 / 866 loss=2.239, loss_v1=0, loss_v2=0, nll_loss=1.024, ntokens=2053.1, nsentences=64, sample_size=2053.1, sample_size_v1=0, sample_size_v2=0, ppl=2.03, wps=510.1, ups=0.25, wpb=2053.1, bsz=64, num_updates=9610, lr=2.01089e-05, gnorm=5.562, clip=100, loss_scale=64, train_wall=40, gb_free=7.4, wall=38810
2023-05-08 10:43:29 - progress_bar.py[line:272] - INFO: epoch 012:    112 / 866 loss=2.285, loss_v1=0, loss_v2=0, nll_loss=1.071, ntokens=2059.9, nsentences=64, sample_size=2059.9, sample_size_v1=0, sample_size_v2=0, ppl=2.1, wps=510.7, ups=0.25, wpb=2059.9, bsz=64, num_updates=9620, lr=2.00966e-05, gnorm=5.014, clip=100, loss_scale=64, train_wall=40, gb_free=6.3, wall=38850
2023-05-08 10:44:10 - progress_bar.py[line:272] - INFO: epoch 012:    122 / 866 loss=2.272, loss_v1=0, loss_v2=0, nll_loss=1.057, ntokens=2153.6, nsentences=64, sample_size=2153.6, sample_size_v1=0, sample_size_v2=0, ppl=2.08, wps=526.5, ups=0.24, wpb=2153.6, bsz=64, num_updates=9630, lr=2.00844e-05, gnorm=4.632, clip=100, loss_scale=64, train_wall=41, gb_free=6.9, wall=38891
2023-05-08 10:44:51 - progress_bar.py[line:272] - INFO: epoch 012:    132 / 866 loss=2.245, loss_v1=0, loss_v2=0, nll_loss=1.027, ntokens=2226.4, nsentences=64, sample_size=2226.4, sample_size_v1=0, sample_size_v2=0, ppl=2.04, wps=538.3, ups=0.24, wpb=2226.4, bsz=64, num_updates=9640, lr=2.00721e-05, gnorm=4.58, clip=100, loss_scale=64, train_wall=41, gb_free=6.9, wall=38932
2023-05-08 10:45:32 - progress_bar.py[line:272] - INFO: epoch 012:    142 / 866 loss=2.226, loss_v1=0, loss_v2=0, nll_loss=1.007, ntokens=2247.7, nsentences=64, sample_size=2247.7, sample_size_v1=0, sample_size_v2=0, ppl=2.01, wps=546.8, ups=0.24, wpb=2247.7, bsz=64, num_updates=9650, lr=2.00598e-05, gnorm=4.379, clip=100, loss_scale=64, train_wall=41, gb_free=7, wall=38973
2023-05-08 10:46:13 - progress_bar.py[line:272] - INFO: epoch 012:    152 / 866 loss=2.235, loss_v1=0, loss_v2=0, nll_loss=1.018, ntokens=2190.1, nsentences=64, sample_size=2190.1, sample_size_v1=0, sample_size_v2=0, ppl=2.02, wps=530.9, ups=0.24, wpb=2190.1, bsz=64, num_updates=9660, lr=2.00475e-05, gnorm=4.6, clip=100, loss_scale=64, train_wall=41, gb_free=6.9, wall=39015
2023-05-08 10:46:54 - progress_bar.py[line:272] - INFO: epoch 012:    162 / 866 loss=2.255, loss_v1=0, loss_v2=0, nll_loss=1.038, ntokens=2159.5, nsentences=64, sample_size=2159.5, sample_size_v1=0, sample_size_v2=0, ppl=2.05, wps=527.5, ups=0.24, wpb=2159.5, bsz=64, num_updates=9670, lr=2.00352e-05, gnorm=4.775, clip=100, loss_scale=64, train_wall=41, gb_free=7.2, wall=39056
2023-05-08 10:47:35 - progress_bar.py[line:272] - INFO: epoch 012:    172 / 866 loss=2.267, loss_v1=0, loss_v2=0, nll_loss=1.053, ntokens=2057.6, nsentences=64, sample_size=2057.6, sample_size_v1=0, sample_size_v2=0, ppl=2.07, wps=510.9, ups=0.25, wpb=2057.6, bsz=64, num_updates=9680, lr=2.00229e-05, gnorm=5.169, clip=100, loss_scale=64, train_wall=40, gb_free=7.5, wall=39096
2023-05-08 10:48:16 - progress_bar.py[line:272] - INFO: epoch 012:    182 / 866 loss=2.224, loss_v1=0, loss_v2=0, nll_loss=1.004, ntokens=2189.4, nsentences=64, sample_size=2189.4, sample_size_v1=0, sample_size_v2=0, ppl=2.01, wps=528.1, ups=0.24, wpb=2189.4, bsz=64, num_updates=9690, lr=2.00106e-05, gnorm=4.862, clip=100, loss_scale=64, train_wall=41, gb_free=7.3, wall=39137
2023-05-08 10:48:57 - progress_bar.py[line:272] - INFO: epoch 012:    192 / 866 loss=2.237, loss_v1=0, loss_v2=0, nll_loss=1.021, ntokens=2214.7, nsentences=64, sample_size=2214.7, sample_size_v1=0, sample_size_v2=0, ppl=2.03, wps=542.9, ups=0.25, wpb=2214.7, bsz=64, num_updates=9700, lr=1.99984e-05, gnorm=4.806, clip=100, loss_scale=64, train_wall=41, gb_free=6.8, wall=39178
2023-05-08 10:49:38 - progress_bar.py[line:272] - INFO: epoch 012:    202 / 866 loss=2.269, loss_v1=0, loss_v2=0, nll_loss=1.054, ntokens=2086.6, nsentences=64, sample_size=2086.6, sample_size_v1=0, sample_size_v2=0, ppl=2.08, wps=512.8, ups=0.25, wpb=2086.6, bsz=64, num_updates=9710, lr=1.99861e-05, gnorm=5.13, clip=100, loss_scale=64, train_wall=41, gb_free=6.9, wall=39219
2023-05-08 10:50:18 - progress_bar.py[line:272] - INFO: epoch 012:    212 / 866 loss=2.292, loss_v1=0, loss_v2=0, nll_loss=1.08, ntokens=2014.6, nsentences=64, sample_size=2014.6, sample_size_v1=0, sample_size_v2=0, ppl=2.11, wps=501.3, ups=0.25, wpb=2014.6, bsz=64, num_updates=9720, lr=1.99738e-05, gnorm=5.141, clip=100, loss_scale=64, train_wall=40, gb_free=7.3, wall=39259
2023-05-08 10:50:58 - progress_bar.py[line:272] - INFO: epoch 012:    222 / 866 loss=2.283, loss_v1=0, loss_v2=0, nll_loss=1.071, ntokens=2222.5, nsentences=64, sample_size=2222.5, sample_size_v1=0, sample_size_v2=0, ppl=2.1, wps=552.7, ups=0.25, wpb=2222.5, bsz=64, num_updates=9730, lr=1.99615e-05, gnorm=5.019, clip=100, loss_scale=64, train_wall=40, gb_free=7.1, wall=39299
2023-05-08 10:51:38 - progress_bar.py[line:272] - INFO: epoch 012:    232 / 866 loss=2.301, loss_v1=0, loss_v2=0, nll_loss=1.088, ntokens=2130.9, nsentences=64, sample_size=2130.9, sample_size_v1=0, sample_size_v2=0, ppl=2.13, wps=532.1, ups=0.25, wpb=2130.9, bsz=64, num_updates=9740, lr=1.99492e-05, gnorm=4.898, clip=100, loss_scale=64, train_wall=40, gb_free=7.6, wall=39339
2023-05-08 10:52:18 - progress_bar.py[line:272] - INFO: epoch 012:    242 / 866 loss=2.282, loss_v1=0, loss_v2=0, nll_loss=1.071, ntokens=2192.7, nsentences=64, sample_size=2192.7, sample_size_v1=0, sample_size_v2=0, ppl=2.1, wps=544.3, ups=0.25, wpb=2192.7, bsz=64, num_updates=9750, lr=1.99369e-05, gnorm=4.73, clip=100, loss_scale=64, train_wall=40, gb_free=7.1, wall=39380
2023-05-08 10:52:59 - progress_bar.py[line:272] - INFO: epoch 012:    252 / 866 loss=2.304, loss_v1=0, loss_v2=0, nll_loss=1.094, ntokens=2103.6, nsentences=64, sample_size=2103.6, sample_size_v1=0, sample_size_v2=0, ppl=2.13, wps=522, ups=0.25, wpb=2103.6, bsz=64, num_updates=9760, lr=1.99247e-05, gnorm=4.843, clip=100, loss_scale=64, train_wall=40, gb_free=7.5, wall=39420
2023-05-08 10:53:39 - progress_bar.py[line:272] - INFO: epoch 012:    262 / 866 loss=2.298, loss_v1=0, loss_v2=0, nll_loss=1.087, ntokens=2158.9, nsentences=64, sample_size=2158.9, sample_size_v1=0, sample_size_v2=0, ppl=2.13, wps=538.9, ups=0.25, wpb=2158.9, bsz=64, num_updates=9770, lr=1.99124e-05, gnorm=5.061, clip=100, loss_scale=64, train_wall=40, gb_free=7.7, wall=39460
2023-05-08 10:54:19 - progress_bar.py[line:272] - INFO: epoch 012:    272 / 866 loss=2.276, loss_v1=0, loss_v2=0, nll_loss=1.062, ntokens=2133.5, nsentences=64, sample_size=2133.5, sample_size_v1=0, sample_size_v2=0, ppl=2.09, wps=531, ups=0.25, wpb=2133.5, bsz=64, num_updates=9780, lr=1.99001e-05, gnorm=4.724, clip=100, loss_scale=64, train_wall=40, gb_free=8, wall=39500
2023-05-08 10:54:59 - progress_bar.py[line:272] - INFO: epoch 012:    282 / 866 loss=2.297, loss_v1=0, loss_v2=0, nll_loss=1.087, ntokens=2167.2, nsentences=64, sample_size=2167.2, sample_size_v1=0, sample_size_v2=0, ppl=2.12, wps=537.6, ups=0.25, wpb=2167.2, bsz=64, num_updates=9790, lr=1.98878e-05, gnorm=4.938, clip=100, loss_scale=64, train_wall=40, gb_free=6.9, wall=39540
2023-05-08 10:55:39 - progress_bar.py[line:272] - INFO: epoch 012:    292 / 866 loss=2.267, loss_v1=0, loss_v2=0, nll_loss=1.051, ntokens=2121.1, nsentences=64, sample_size=2121.1, sample_size_v1=0, sample_size_v2=0, ppl=2.07, wps=528.6, ups=0.25, wpb=2121.1, bsz=64, num_updates=9800, lr=1.98755e-05, gnorm=5.098, clip=100, loss_scale=64, train_wall=40, gb_free=7.8, wall=39581
2023-05-08 10:56:19 - progress_bar.py[line:272] - INFO: epoch 012:    302 / 866 loss=2.276, loss_v1=0, loss_v2=0, nll_loss=1.065, ntokens=2135.1, nsentences=64, sample_size=2135.1, sample_size_v1=0, sample_size_v2=0, ppl=2.09, wps=533.1, ups=0.25, wpb=2135.1, bsz=64, num_updates=9810, lr=1.98632e-05, gnorm=5.008, clip=100, loss_scale=64, train_wall=40, gb_free=7.9, wall=39621
2023-05-08 10:57:00 - progress_bar.py[line:272] - INFO: epoch 012:    312 / 866 loss=2.269, loss_v1=0, loss_v2=0, nll_loss=1.053, ntokens=2131.6, nsentences=64, sample_size=2131.6, sample_size_v1=0, sample_size_v2=0, ppl=2.08, wps=531.2, ups=0.25, wpb=2131.6, bsz=64, num_updates=9820, lr=1.9851e-05, gnorm=5.005, clip=100, loss_scale=64, train_wall=40, gb_free=7.8, wall=39661
2023-05-08 10:57:40 - progress_bar.py[line:272] - INFO: epoch 012:    322 / 866 loss=2.303, loss_v1=0, loss_v2=0, nll_loss=1.092, ntokens=1957, nsentences=64, sample_size=1957, sample_size_v1=0, sample_size_v2=0, ppl=2.13, wps=489.3, ups=0.25, wpb=1957, bsz=64, num_updates=9830, lr=1.98387e-05, gnorm=5.377, clip=100, loss_scale=64, train_wall=40, gb_free=7.7, wall=39701
2023-05-08 10:58:20 - progress_bar.py[line:272] - INFO: epoch 012:    332 / 866 loss=2.282, loss_v1=0, loss_v2=0, nll_loss=1.069, ntokens=2161.6, nsentences=64, sample_size=2161.6, sample_size_v1=0, sample_size_v2=0, ppl=2.1, wps=537.8, ups=0.25, wpb=2161.6, bsz=64, num_updates=9840, lr=1.98264e-05, gnorm=4.804, clip=100, loss_scale=64, train_wall=40, gb_free=7.6, wall=39741
2023-05-08 10:59:00 - progress_bar.py[line:272] - INFO: epoch 012:    342 / 866 loss=2.268, loss_v1=0, loss_v2=0, nll_loss=1.053, ntokens=2014.9, nsentences=64, sample_size=2014.9, sample_size_v1=0, sample_size_v2=0, ppl=2.08, wps=504.2, ups=0.25, wpb=2014.9, bsz=64, num_updates=9850, lr=1.98141e-05, gnorm=4.828, clip=100, loss_scale=64, train_wall=40, gb_free=8.2, wall=39781
2023-05-08 10:59:39 - progress_bar.py[line:272] - INFO: epoch 012:    352 / 866 loss=2.301, loss_v1=0, loss_v2=0, nll_loss=1.092, ntokens=1958, nsentences=64, sample_size=1958, sample_size_v1=0, sample_size_v2=0, ppl=2.13, wps=493.1, ups=0.25, wpb=1958, bsz=64, num_updates=9860, lr=1.98018e-05, gnorm=5.788, clip=100, loss_scale=64, train_wall=40, gb_free=8.2, wall=39821
2023-05-08 11:00:19 - progress_bar.py[line:272] - INFO: epoch 012:    362 / 866 loss=2.308, loss_v1=0, loss_v2=0, nll_loss=1.099, ntokens=1964.4, nsentences=64, sample_size=1964.4, sample_size_v1=0, sample_size_v2=0, ppl=2.14, wps=494.7, ups=0.25, wpb=1964.4, bsz=64, num_updates=9870, lr=1.97895e-05, gnorm=5.607, clip=100, loss_scale=64, train_wall=40, gb_free=7.7, wall=39860
2023-05-08 11:00:59 - progress_bar.py[line:272] - INFO: epoch 012:    372 / 866 loss=2.289, loss_v1=0, loss_v2=0, nll_loss=1.076, ntokens=2038.1, nsentences=64, sample_size=2038.1, sample_size_v1=0, sample_size_v2=0, ppl=2.11, wps=509.4, ups=0.25, wpb=2038.1, bsz=64, num_updates=9880, lr=1.97773e-05, gnorm=4.96, clip=100, loss_scale=64, train_wall=40, gb_free=8, wall=39900
2023-05-08 11:01:39 - progress_bar.py[line:272] - INFO: epoch 012:    382 / 866 loss=2.266, loss_v1=0, loss_v2=0, nll_loss=1.051, ntokens=2164.2, nsentences=64, sample_size=2164.2, sample_size_v1=0, sample_size_v2=0, ppl=2.07, wps=542.2, ups=0.25, wpb=2164.2, bsz=64, num_updates=9890, lr=1.9765e-05, gnorm=4.811, clip=100, loss_scale=64, train_wall=40, gb_free=7.5, wall=39940
2023-05-08 11:02:19 - progress_bar.py[line:272] - INFO: epoch 012:    392 / 866 loss=2.278, loss_v1=0, loss_v2=0, nll_loss=1.066, ntokens=2067.8, nsentences=64, sample_size=2067.8, sample_size_v1=0, sample_size_v2=0, ppl=2.09, wps=517.6, ups=0.25, wpb=2067.8, bsz=64, num_updates=9900, lr=1.97527e-05, gnorm=5.35, clip=100, loss_scale=64, train_wall=40, gb_free=8.2, wall=39980
2023-05-08 11:02:59 - progress_bar.py[line:272] - INFO: epoch 012:    402 / 866 loss=2.288, loss_v1=0, loss_v2=0, nll_loss=1.074, ntokens=2036, nsentences=64, sample_size=2036, sample_size_v1=0, sample_size_v2=0, ppl=2.11, wps=507.3, ups=0.25, wpb=2036, bsz=64, num_updates=9910, lr=1.97404e-05, gnorm=5.261, clip=100, loss_scale=64, train_wall=40, gb_free=7.6, wall=40020
2023-05-08 11:03:39 - progress_bar.py[line:272] - INFO: epoch 012:    412 / 866 loss=2.278, loss_v1=0, loss_v2=0, nll_loss=1.067, ntokens=2161.9, nsentences=64, sample_size=2161.9, sample_size_v1=0, sample_size_v2=0, ppl=2.09, wps=539.8, ups=0.25, wpb=2161.9, bsz=64, num_updates=9920, lr=1.97281e-05, gnorm=4.989, clip=100, loss_scale=64, train_wall=40, gb_free=7.5, wall=40060
2023-05-08 11:04:19 - progress_bar.py[line:272] - INFO: epoch 012:    422 / 866 loss=2.265, loss_v1=0, loss_v2=0, nll_loss=1.049, ntokens=2082.2, nsentences=64, sample_size=2082.2, sample_size_v1=0, sample_size_v2=0, ppl=2.07, wps=519.8, ups=0.25, wpb=2082.2, bsz=64, num_updates=9930, lr=1.97158e-05, gnorm=4.81, clip=100, loss_scale=64, train_wall=40, gb_free=7.2, wall=40100
2023-05-08 11:04:59 - progress_bar.py[line:272] - INFO: epoch 012:    432 / 866 loss=2.265, loss_v1=0, loss_v2=0, nll_loss=1.051, ntokens=2104.8, nsentences=64, sample_size=2104.8, sample_size_v1=0, sample_size_v2=0, ppl=2.07, wps=526, ups=0.25, wpb=2104.8, bsz=64, num_updates=9940, lr=1.97035e-05, gnorm=4.919, clip=100, loss_scale=64, train_wall=40, gb_free=8.1, wall=40140
2023-05-08 11:05:39 - progress_bar.py[line:272] - INFO: epoch 012:    442 / 866 loss=2.31, loss_v1=0, loss_v2=0, nll_loss=1.097, ntokens=2064.2, nsentences=64, sample_size=2064.2, sample_size_v1=0, sample_size_v2=0, ppl=2.14, wps=515, ups=0.25, wpb=2064.2, bsz=64, num_updates=9950, lr=1.96913e-05, gnorm=4.962, clip=100, loss_scale=64, train_wall=40, gb_free=7.3, wall=40181
2023-05-08 11:06:19 - progress_bar.py[line:272] - INFO: epoch 012:    452 / 866 loss=2.293, loss_v1=0, loss_v2=0, nll_loss=1.083, ntokens=1981.6, nsentences=64, sample_size=1981.6, sample_size_v1=0, sample_size_v2=0, ppl=2.12, wps=496.4, ups=0.25, wpb=1981.6, bsz=64, num_updates=9960, lr=1.9679e-05, gnorm=5.409, clip=100, loss_scale=64, train_wall=40, gb_free=8.3, wall=40220
2023-05-08 11:07:00 - progress_bar.py[line:272] - INFO: epoch 012:    462 / 866 loss=2.293, loss_v1=0, loss_v2=0, nll_loss=1.082, ntokens=2192.3, nsentences=64, sample_size=2192.3, sample_size_v1=0, sample_size_v2=0, ppl=2.12, wps=544.7, ups=0.25, wpb=2192.3, bsz=64, num_updates=9970, lr=1.96667e-05, gnorm=5.089, clip=100, loss_scale=64, train_wall=40, gb_free=7.3, wall=40261
2023-05-08 11:07:40 - progress_bar.py[line:272] - INFO: epoch 012:    472 / 866 loss=2.289, loss_v1=0, loss_v2=0, nll_loss=1.077, ntokens=2142.5, nsentences=64, sample_size=2142.5, sample_size_v1=0, sample_size_v2=0, ppl=2.11, wps=528.5, ups=0.25, wpb=2142.5, bsz=64, num_updates=9980, lr=1.96544e-05, gnorm=4.999, clip=100, loss_scale=64, train_wall=40, gb_free=7.3, wall=40301
2023-05-08 11:08:20 - progress_bar.py[line:272] - INFO: epoch 012:    482 / 866 loss=2.279, loss_v1=0, loss_v2=0, nll_loss=1.065, ntokens=2178.2, nsentences=64, sample_size=2178.2, sample_size_v1=0, sample_size_v2=0, ppl=2.09, wps=540.7, ups=0.25, wpb=2178.2, bsz=64, num_updates=9990, lr=1.96421e-05, gnorm=5.201, clip=100, loss_scale=64, train_wall=40, gb_free=8.2, wall=40342
2023-05-08 11:09:00 - progress_bar.py[line:272] - INFO: epoch 012:    492 / 866 loss=2.267, loss_v1=0, loss_v2=0, nll_loss=1.052, ntokens=2054.4, nsentences=64, sample_size=2054.4, sample_size_v1=0, sample_size_v2=0, ppl=2.07, wps=513.8, ups=0.25, wpb=2054.4, bsz=64, num_updates=10000, lr=1.96298e-05, gnorm=4.983, clip=100, loss_scale=64, train_wall=40, gb_free=7.5, wall=40382
2023-05-08 11:09:40 - progress_bar.py[line:272] - INFO: epoch 012:    502 / 866 loss=2.279, loss_v1=0, loss_v2=0, nll_loss=1.067, ntokens=2074.9, nsentences=64, sample_size=2074.9, sample_size_v1=0, sample_size_v2=0, ppl=2.1, wps=519.2, ups=0.25, wpb=2074.9, bsz=64, num_updates=10010, lr=1.96176e-05, gnorm=5.264, clip=100, loss_scale=64, train_wall=40, gb_free=7.9, wall=40421
2023-05-08 11:10:20 - progress_bar.py[line:272] - INFO: epoch 012:    512 / 866 loss=2.309, loss_v1=0, loss_v2=0, nll_loss=1.097, ntokens=2141.6, nsentences=64, sample_size=2141.6, sample_size_v1=0, sample_size_v2=0, ppl=2.14, wps=536.7, ups=0.25, wpb=2141.6, bsz=64, num_updates=10020, lr=1.96053e-05, gnorm=5.107, clip=100, loss_scale=64, train_wall=40, gb_free=7, wall=40461
2023-05-08 11:11:00 - progress_bar.py[line:272] - INFO: epoch 012:    522 / 866 loss=2.268, loss_v1=0, loss_v2=0, nll_loss=1.054, ntokens=2127.1, nsentences=64, sample_size=2127.1, sample_size_v1=0, sample_size_v2=0, ppl=2.08, wps=535, ups=0.25, wpb=2127.1, bsz=64, num_updates=10030, lr=1.9593e-05, gnorm=4.832, clip=100, loss_scale=64, train_wall=40, gb_free=8.1, wall=40501
2023-05-08 11:11:40 - progress_bar.py[line:272] - INFO: epoch 012:    532 / 866 loss=2.279, loss_v1=0, loss_v2=0, nll_loss=1.066, ntokens=2031, nsentences=64, sample_size=2031, sample_size_v1=0, sample_size_v2=0, ppl=2.09, wps=510.1, ups=0.25, wpb=2031, bsz=64, num_updates=10040, lr=1.95807e-05, gnorm=5.151, clip=100, loss_scale=64, train_wall=40, gb_free=8.3, wall=40541
2023-05-08 11:12:20 - progress_bar.py[line:272] - INFO: epoch 012:    542 / 866 loss=2.29, loss_v1=0, loss_v2=0, nll_loss=1.078, ntokens=2149.8, nsentences=64, sample_size=2149.8, sample_size_v1=0, sample_size_v2=0, ppl=2.11, wps=536.5, ups=0.25, wpb=2149.8, bsz=64, num_updates=10050, lr=1.95684e-05, gnorm=5.113, clip=100, loss_scale=64, train_wall=40, gb_free=7.3, wall=40581
2023-05-08 11:13:00 - progress_bar.py[line:272] - INFO: epoch 012:    552 / 866 loss=2.305, loss_v1=0, loss_v2=0, nll_loss=1.097, ntokens=2323, nsentences=64, sample_size=2323, sample_size_v1=0, sample_size_v2=0, ppl=2.14, wps=576.2, ups=0.25, wpb=2323, bsz=64, num_updates=10060, lr=1.95561e-05, gnorm=4.613, clip=100, loss_scale=128, train_wall=40, gb_free=7.4, wall=40621
2023-05-08 11:13:04 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2023-05-08 11:13:44 - progress_bar.py[line:272] - INFO: epoch 012:    563 / 866 loss=2.285, loss_v1=0, loss_v2=0, nll_loss=1.073, ntokens=2255.1, nsentences=64, sample_size=2255.1, sample_size_v1=0, sample_size_v2=0, ppl=2.1, wps=510.4, ups=0.23, wpb=2255.1, bsz=64, num_updates=10070, lr=1.95439e-05, gnorm=5.005, clip=100, loss_scale=64, train_wall=44, gb_free=8.4, wall=40666
2023-05-08 11:14:25 - progress_bar.py[line:272] - INFO: epoch 012:    573 / 866 loss=2.286, loss_v1=0, loss_v2=0, nll_loss=1.074, ntokens=2226.9, nsentences=64, sample_size=2226.9, sample_size_v1=0, sample_size_v2=0, ppl=2.1, wps=555.2, ups=0.25, wpb=2226.9, bsz=64, num_updates=10080, lr=1.95316e-05, gnorm=4.871, clip=100, loss_scale=64, train_wall=40, gb_free=7.3, wall=40706
2023-05-08 11:15:05 - progress_bar.py[line:272] - INFO: epoch 012:    583 / 866 loss=2.292, loss_v1=0, loss_v2=0, nll_loss=1.079, ntokens=2080.8, nsentences=64, sample_size=2080.8, sample_size_v1=0, sample_size_v2=0, ppl=2.11, wps=519.2, ups=0.25, wpb=2080.8, bsz=64, num_updates=10090, lr=1.95193e-05, gnorm=4.941, clip=100, loss_scale=64, train_wall=40, gb_free=8.2, wall=40746
2023-05-08 11:15:45 - progress_bar.py[line:272] - INFO: epoch 012:    593 / 866 loss=2.27, loss_v1=0, loss_v2=0, nll_loss=1.056, ntokens=2115.7, nsentences=64, sample_size=2115.7, sample_size_v1=0, sample_size_v2=0, ppl=2.08, wps=523.7, ups=0.25, wpb=2115.7, bsz=64, num_updates=10100, lr=1.9507e-05, gnorm=4.909, clip=100, loss_scale=64, train_wall=40, gb_free=8, wall=40786
2023-05-08 11:16:25 - progress_bar.py[line:272] - INFO: epoch 012:    603 / 866 loss=2.264, loss_v1=0, loss_v2=0, nll_loss=1.05, ntokens=2098.7, nsentences=64, sample_size=2098.7, sample_size_v1=0, sample_size_v2=0, ppl=2.07, wps=522.9, ups=0.25, wpb=2098.7, bsz=64, num_updates=10110, lr=1.94947e-05, gnorm=5.042, clip=100, loss_scale=64, train_wall=40, gb_free=7.8, wall=40826
2023-05-08 11:17:06 - progress_bar.py[line:272] - INFO: epoch 012:    613 / 866 loss=2.297, loss_v1=0, loss_v2=0, nll_loss=1.086, ntokens=1926.8, nsentences=64, sample_size=1926.8, sample_size_v1=0, sample_size_v2=0, ppl=2.12, wps=477.7, ups=0.25, wpb=1926.8, bsz=64, num_updates=10120, lr=1.94824e-05, gnorm=5.767, clip=100, loss_scale=64, train_wall=40, gb_free=8.3, wall=40867
2023-05-08 11:17:46 - progress_bar.py[line:272] - INFO: epoch 012:    623 / 866 loss=2.289, loss_v1=0, loss_v2=0, nll_loss=1.075, ntokens=2033.1, nsentences=64, sample_size=2033.1, sample_size_v1=0, sample_size_v2=0, ppl=2.11, wps=507.6, ups=0.25, wpb=2033.1, bsz=64, num_updates=10130, lr=1.94701e-05, gnorm=5.107, clip=100, loss_scale=64, train_wall=40, gb_free=7.4, wall=40907
2023-05-08 11:18:25 - progress_bar.py[line:272] - INFO: epoch 012:    633 / 866 loss=2.282, loss_v1=0, loss_v2=0, nll_loss=1.07, ntokens=2004.2, nsentences=64, sample_size=2004.2, sample_size_v1=0, sample_size_v2=0, ppl=2.1, wps=503.7, ups=0.25, wpb=2004.2, bsz=64, num_updates=10140, lr=1.94579e-05, gnorm=5.833, clip=100, loss_scale=64, train_wall=40, gb_free=7.9, wall=40946
2023-05-08 11:19:05 - progress_bar.py[line:272] - INFO: epoch 012:    643 / 866 loss=2.257, loss_v1=0, loss_v2=0, nll_loss=1.038, ntokens=2093.4, nsentences=64, sample_size=2093.4, sample_size_v1=0, sample_size_v2=0, ppl=2.05, wps=523.7, ups=0.25, wpb=2093.4, bsz=64, num_updates=10150, lr=1.94456e-05, gnorm=5.137, clip=100, loss_scale=64, train_wall=40, gb_free=8.1, wall=40986
2023-05-08 11:19:45 - progress_bar.py[line:272] - INFO: epoch 012:    653 / 866 loss=2.291, loss_v1=0, loss_v2=0, nll_loss=1.083, ntokens=1993.1, nsentences=64, sample_size=1993.1, sample_size_v1=0, sample_size_v2=0, ppl=2.12, wps=500.6, ups=0.25, wpb=1993.1, bsz=64, num_updates=10160, lr=1.94333e-05, gnorm=5.405, clip=100, loss_scale=64, train_wall=40, gb_free=8.3, wall=41026
2023-05-08 11:20:25 - progress_bar.py[line:272] - INFO: epoch 012:    663 / 866 loss=2.3, loss_v1=0, loss_v2=0, nll_loss=1.088, ntokens=1918.6, nsentences=64, sample_size=1918.6, sample_size_v1=0, sample_size_v2=0, ppl=2.13, wps=483.3, ups=0.25, wpb=1918.6, bsz=64, num_updates=10170, lr=1.9421e-05, gnorm=5.63, clip=100, loss_scale=64, train_wall=40, gb_free=8, wall=41066
2023-05-08 11:21:05 - progress_bar.py[line:272] - INFO: epoch 012:    673 / 866 loss=2.29, loss_v1=0, loss_v2=0, nll_loss=1.076, ntokens=2027.7, nsentences=64, sample_size=2027.7, sample_size_v1=0, sample_size_v2=0, ppl=2.11, wps=507.3, ups=0.25, wpb=2027.7, bsz=64, num_updates=10180, lr=1.94087e-05, gnorm=4.786, clip=100, loss_scale=64, train_wall=40, gb_free=8.1, wall=41106
2023-05-08 11:21:45 - progress_bar.py[line:272] - INFO: epoch 012:    683 / 866 loss=2.269, loss_v1=0, loss_v2=0, nll_loss=1.056, ntokens=2046.4, nsentences=64, sample_size=2046.4, sample_size_v1=0, sample_size_v2=0, ppl=2.08, wps=513.9, ups=0.25, wpb=2046.4, bsz=64, num_updates=10190, lr=1.93964e-05, gnorm=5.404, clip=100, loss_scale=64, train_wall=40, gb_free=8.3, wall=41146
2023-05-08 11:22:25 - progress_bar.py[line:272] - INFO: epoch 012:    693 / 866 loss=2.284, loss_v1=0, loss_v2=0, nll_loss=1.072, ntokens=2056, nsentences=64, sample_size=2056, sample_size_v1=0, sample_size_v2=0, ppl=2.1, wps=512.7, ups=0.25, wpb=2056, bsz=64, num_updates=10200, lr=1.93842e-05, gnorm=5.346, clip=100, loss_scale=64, train_wall=40, gb_free=7.4, wall=41186
2023-05-08 11:23:05 - progress_bar.py[line:272] - INFO: epoch 012:    703 / 866 loss=2.291, loss_v1=0, loss_v2=0, nll_loss=1.079, ntokens=2024.1, nsentences=64, sample_size=2024.1, sample_size_v1=0, sample_size_v2=0, ppl=2.11, wps=507.1, ups=0.25, wpb=2024.1, bsz=64, num_updates=10210, lr=1.93719e-05, gnorm=5.261, clip=100, loss_scale=64, train_wall=40, gb_free=8.1, wall=41226
2023-05-08 11:23:45 - progress_bar.py[line:272] - INFO: epoch 012:    713 / 866 loss=2.301, loss_v1=0, loss_v2=0, nll_loss=1.091, ntokens=1917, nsentences=64, sample_size=1917, sample_size_v1=0, sample_size_v2=0, ppl=2.13, wps=480.6, ups=0.25, wpb=1917, bsz=64, num_updates=10220, lr=1.93596e-05, gnorm=5.459, clip=100, loss_scale=64, train_wall=40, gb_free=8.2, wall=41266
2023-05-08 11:24:24 - progress_bar.py[line:272] - INFO: epoch 012:    723 / 866 loss=2.267, loss_v1=0, loss_v2=0, nll_loss=1.053, ntokens=1956.9, nsentences=64, sample_size=1956.9, sample_size_v1=0, sample_size_v2=0, ppl=2.07, wps=491.3, ups=0.25, wpb=1956.9, bsz=64, num_updates=10230, lr=1.93473e-05, gnorm=5.429, clip=100, loss_scale=64, train_wall=40, gb_free=8.4, wall=41306
2023-05-08 11:25:04 - progress_bar.py[line:272] - INFO: epoch 012:    733 / 866 loss=2.261, loss_v1=0, loss_v2=0, nll_loss=1.044, ntokens=2031.5, nsentences=64, sample_size=2031.5, sample_size_v1=0, sample_size_v2=0, ppl=2.06, wps=508.1, ups=0.25, wpb=2031.5, bsz=64, num_updates=10240, lr=1.9335e-05, gnorm=4.796, clip=100, loss_scale=64, train_wall=40, gb_free=7.3, wall=41346
2023-05-08 11:25:44 - progress_bar.py[line:272] - INFO: epoch 012:    743 / 866 loss=2.257, loss_v1=0, loss_v2=0, nll_loss=1.039, ntokens=2149.2, nsentences=64, sample_size=2149.2, sample_size_v1=0, sample_size_v2=0, ppl=2.06, wps=536, ups=0.25, wpb=2149.2, bsz=64, num_updates=10250, lr=1.93227e-05, gnorm=5.103, clip=100, loss_scale=64, train_wall=40, gb_free=7.9, wall=41386
2023-05-08 11:26:25 - progress_bar.py[line:272] - INFO: epoch 012:    753 / 866 loss=2.257, loss_v1=0, loss_v2=0, nll_loss=1.042, ntokens=2078, nsentences=64, sample_size=2078, sample_size_v1=0, sample_size_v2=0, ppl=2.06, wps=516.4, ups=0.25, wpb=2078, bsz=64, num_updates=10260, lr=1.93105e-05, gnorm=5.178, clip=100, loss_scale=64, train_wall=40, gb_free=7.8, wall=41426
2023-05-08 11:27:05 - progress_bar.py[line:272] - INFO: epoch 012:    763 / 866 loss=2.265, loss_v1=0, loss_v2=0, nll_loss=1.052, ntokens=2147.9, nsentences=64, sample_size=2147.9, sample_size_v1=0, sample_size_v2=0, ppl=2.07, wps=534.4, ups=0.25, wpb=2147.9, bsz=64, num_updates=10270, lr=1.92982e-05, gnorm=5.143, clip=100, loss_scale=64, train_wall=40, gb_free=7.9, wall=41466
2023-05-08 11:27:45 - progress_bar.py[line:272] - INFO: epoch 012:    773 / 866 loss=2.269, loss_v1=0, loss_v2=0, nll_loss=1.054, ntokens=2095.5, nsentences=64, sample_size=2095.5, sample_size_v1=0, sample_size_v2=0, ppl=2.08, wps=526.9, ups=0.25, wpb=2095.5, bsz=64, num_updates=10280, lr=1.92859e-05, gnorm=5.4, clip=100, loss_scale=64, train_wall=40, gb_free=7.9, wall=41506
2023-05-08 11:28:25 - progress_bar.py[line:272] - INFO: epoch 012:    783 / 866 loss=2.255, loss_v1=0, loss_v2=0, nll_loss=1.038, ntokens=2224.5, nsentences=64, sample_size=2224.5, sample_size_v1=0, sample_size_v2=0, ppl=2.05, wps=552, ups=0.25, wpb=2224.5, bsz=64, num_updates=10290, lr=1.92736e-05, gnorm=4.748, clip=100, loss_scale=64, train_wall=40, gb_free=7.6, wall=41546
2023-05-08 11:29:05 - progress_bar.py[line:272] - INFO: epoch 012:    793 / 866 loss=2.296, loss_v1=0, loss_v2=0, nll_loss=1.087, ntokens=2005.5, nsentences=64, sample_size=2005.5, sample_size_v1=0, sample_size_v2=0, ppl=2.12, wps=503.7, ups=0.25, wpb=2005.5, bsz=64, num_updates=10300, lr=1.92613e-05, gnorm=5.182, clip=100, loss_scale=64, train_wall=40, gb_free=7.9, wall=41586
2023-05-08 11:29:45 - progress_bar.py[line:272] - INFO: epoch 012:    803 / 866 loss=2.274, loss_v1=0, loss_v2=0, nll_loss=1.057, ntokens=1972.7, nsentences=64, sample_size=1972.7, sample_size_v1=0, sample_size_v2=0, ppl=2.08, wps=496.7, ups=0.25, wpb=1972.7, bsz=64, num_updates=10310, lr=1.9249e-05, gnorm=5.056, clip=100, loss_scale=64, train_wall=40, gb_free=7.2, wall=41626
2023-05-08 11:30:25 - progress_bar.py[line:272] - INFO: epoch 012:    813 / 866 loss=2.246, loss_v1=0, loss_v2=0, nll_loss=1.03, ntokens=2109.3, nsentences=64, sample_size=2109.3, sample_size_v1=0, sample_size_v2=0, ppl=2.04, wps=527, ups=0.25, wpb=2109.3, bsz=64, num_updates=10320, lr=1.92368e-05, gnorm=4.808, clip=100, loss_scale=64, train_wall=40, gb_free=6.7, wall=41666
2023-05-08 11:31:05 - progress_bar.py[line:272] - INFO: epoch 012:    823 / 866 loss=2.264, loss_v1=0, loss_v2=0, nll_loss=1.05, ntokens=2101.2, nsentences=64, sample_size=2101.2, sample_size_v1=0, sample_size_v2=0, ppl=2.07, wps=522.9, ups=0.25, wpb=2101.2, bsz=64, num_updates=10330, lr=1.92245e-05, gnorm=4.953, clip=100, loss_scale=64, train_wall=40, gb_free=7.5, wall=41706
2023-05-08 11:31:45 - progress_bar.py[line:272] - INFO: epoch 012:    833 / 866 loss=2.258, loss_v1=0, loss_v2=0, nll_loss=1.043, ntokens=2208.2, nsentences=64, sample_size=2208.2, sample_size_v1=0, sample_size_v2=0, ppl=2.06, wps=542.8, ups=0.25, wpb=2208.2, bsz=64, num_updates=10340, lr=1.92122e-05, gnorm=4.498, clip=100, loss_scale=64, train_wall=41, gb_free=8.2, wall=41747
2023-05-08 11:32:26 - progress_bar.py[line:272] - INFO: epoch 012:    843 / 866 loss=2.27, loss_v1=0, loss_v2=0, nll_loss=1.054, ntokens=2121.2, nsentences=64, sample_size=2121.2, sample_size_v1=0, sample_size_v2=0, ppl=2.08, wps=528.2, ups=0.25, wpb=2121.2, bsz=64, num_updates=10350, lr=1.91999e-05, gnorm=4.748, clip=100, loss_scale=64, train_wall=40, gb_free=8.2, wall=41787
2023-05-08 11:33:06 - progress_bar.py[line:272] - INFO: epoch 012:    853 / 866 loss=2.254, loss_v1=0, loss_v2=0, nll_loss=1.04, ntokens=2191.4, nsentences=64, sample_size=2191.4, sample_size_v1=0, sample_size_v2=0, ppl=2.06, wps=543.4, ups=0.25, wpb=2191.4, bsz=64, num_updates=10360, lr=1.91876e-05, gnorm=4.714, clip=100, loss_scale=64, train_wall=40, gb_free=7.5, wall=41827
2023-05-08 11:33:46 - progress_bar.py[line:272] - INFO: epoch 012:    863 / 866 loss=2.28, loss_v1=0, loss_v2=0, nll_loss=1.065, ntokens=2023.2, nsentences=64, sample_size=2023.2, sample_size_v1=0, sample_size_v2=0, ppl=2.09, wps=505.8, ups=0.25, wpb=2023.2, bsz=64, num_updates=10370, lr=1.91753e-05, gnorm=5.239, clip=100, loss_scale=64, train_wall=40, gb_free=7.7, wall=41867
2023-05-08 11:33:57 - train.py[line:332] - INFO: end of epoch 12 (average epoch stats below)
local datafile ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 1 begin to initialize row_count and line_idx-to-offset mapping
2023-05-08 11:33:57 - progress_bar.py[line:282] - INFO: epoch 012 | loss 2.267 | loss_v1 0 | loss_v2 0 | nll_loss 1.053 | ntokens 2103.75 | nsentences 63.972 | sample_size 2103.75 | sample_size_v1 0 | sample_size_v2 0 | ppl 2.07 | wps 521.5 | ups 0.25 | wpb 2103.8 | bsz 64 | num_updates 10373 | lr 1.91716e-05 | gnorm 5.037 | clip 100 | loss_scale 64 | train_wall 3479 | gb_free 8.7 | wall 41878
2023-05-08 11:33:57 - trainer.py[line:639] - INFO: loading train data for epoch 13
local datafile ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 0 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 0 finished initializing row_count and line_idx-to-offset mapping
file ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 0 row count 27700 total row count 55400
slice_id 0 seek offset 0
2023-05-08 11:33:58 - trainer.py[line:703] - INFO: begin training epoch 13
2023-05-08 11:33:58 - train.py[line:305] - INFO: Start iterating over samples
local datafile ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 1 finished initializing row_count and line_idx-to-offset mapping
file ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 1 row count 27700 total row count 55400
slice_id 1 seek offset 27700
2023-05-08 11:34:27 - progress_bar.py[line:272] - INFO: epoch 013:      7 / 866 loss=2.24, loss_v1=0, loss_v2=0, nll_loss=1.022, ntokens=2063.1, nsentences=61.6, sample_size=2063.1, sample_size_v1=0, sample_size_v2=0, ppl=2.03, wps=502.1, ups=0.24, wpb=2063.1, bsz=61.6, num_updates=10380, lr=1.9163e-05, gnorm=4.927, clip=100, loss_scale=64, train_wall=39, gb_free=7.5, wall=41908
2023-05-08 11:35:08 - progress_bar.py[line:272] - INFO: epoch 013:     17 / 866 loss=2.216, loss_v1=0, loss_v2=0, nll_loss=0.998, ntokens=2075.1, nsentences=64, sample_size=2075.1, sample_size_v1=0, sample_size_v2=0, ppl=2, wps=512.8, ups=0.25, wpb=2075.1, bsz=64, num_updates=10390, lr=1.91508e-05, gnorm=5.467, clip=100, loss_scale=64, train_wall=40, gb_free=7.3, wall=41949
2023-05-08 11:35:48 - progress_bar.py[line:272] - INFO: epoch 013:     27 / 866 loss=2.234, loss_v1=0, loss_v2=0, nll_loss=1.013, ntokens=1975.4, nsentences=64, sample_size=1975.4, sample_size_v1=0, sample_size_v2=0, ppl=2.02, wps=485.1, ups=0.25, wpb=1975.4, bsz=64, num_updates=10400, lr=1.91385e-05, gnorm=5.137, clip=100, loss_scale=64, train_wall=41, gb_free=7.1, wall=41989
2023-05-08 11:36:29 - progress_bar.py[line:272] - INFO: epoch 013:     37 / 866 loss=2.16, loss_v1=0, loss_v2=0, nll_loss=0.935, ntokens=2214.8, nsentences=64, sample_size=2214.8, sample_size_v1=0, sample_size_v2=0, ppl=1.91, wps=542.4, ups=0.24, wpb=2214.8, bsz=64, num_updates=10410, lr=1.91262e-05, gnorm=4.431, clip=100, loss_scale=64, train_wall=41, gb_free=7.6, wall=42030
2023-05-08 11:37:09 - progress_bar.py[line:272] - INFO: epoch 013:     47 / 866 loss=2.202, loss_v1=0, loss_v2=0, nll_loss=0.981, ntokens=2012, nsentences=64, sample_size=2012, sample_size_v1=0, sample_size_v2=0, ppl=1.97, wps=497.9, ups=0.25, wpb=2012, bsz=64, num_updates=10420, lr=1.91139e-05, gnorm=4.902, clip=100, loss_scale=64, train_wall=40, gb_free=7, wall=42071
2023-05-08 11:37:50 - progress_bar.py[line:272] - INFO: epoch 013:     57 / 866 loss=2.147, loss_v1=0, loss_v2=0, nll_loss=0.919, ntokens=2065.2, nsentences=64, sample_size=2065.2, sample_size_v1=0, sample_size_v2=0, ppl=1.89, wps=511.6, ups=0.25, wpb=2065.2, bsz=64, num_updates=10430, lr=1.91016e-05, gnorm=5.142, clip=100, loss_scale=64, train_wall=40, gb_free=7.6, wall=42111
2023-05-08 11:38:31 - progress_bar.py[line:272] - INFO: epoch 013:     67 / 866 loss=2.09, loss_v1=0, loss_v2=0, nll_loss=0.855, ntokens=2385, nsentences=64, sample_size=2385, sample_size_v1=0, sample_size_v2=0, ppl=1.81, wps=573.9, ups=0.24, wpb=2385, bsz=64, num_updates=10440, lr=1.90893e-05, gnorm=4.24, clip=100, loss_scale=64, train_wall=42, gb_free=6.4, wall=42153
2023-05-08 11:39:13 - progress_bar.py[line:272] - INFO: epoch 013:     77 / 866 loss=2.16, loss_v1=0, loss_v2=0, nll_loss=0.932, ntokens=2320.6, nsentences=64, sample_size=2320.6, sample_size_v1=0, sample_size_v2=0, ppl=1.91, wps=559.7, ups=0.24, wpb=2320.6, bsz=64, num_updates=10450, lr=1.90771e-05, gnorm=4.219, clip=100, loss_scale=64, train_wall=41, gb_free=7.3, wall=42194
2023-05-08 11:39:54 - progress_bar.py[line:272] - INFO: epoch 013:     87 / 866 loss=2.207, loss_v1=0, loss_v2=0, nll_loss=0.986, ntokens=2178.1, nsentences=64, sample_size=2178.1, sample_size_v1=0, sample_size_v2=0, ppl=1.98, wps=530.6, ups=0.24, wpb=2178.1, bsz=64, num_updates=10460, lr=1.90648e-05, gnorm=4.506, clip=100, loss_scale=64, train_wall=41, gb_free=6.9, wall=42235
2023-05-08 11:40:35 - progress_bar.py[line:272] - INFO: epoch 013:     97 / 866 loss=2.182, loss_v1=0, loss_v2=0, nll_loss=0.958, ntokens=2142.7, nsentences=64, sample_size=2142.7, sample_size_v1=0, sample_size_v2=0, ppl=1.94, wps=527.1, ups=0.25, wpb=2142.7, bsz=64, num_updates=10470, lr=1.90525e-05, gnorm=4.49, clip=100, loss_scale=64, train_wall=41, gb_free=6.2, wall=42276
2023-05-08 11:41:15 - progress_bar.py[line:272] - INFO: epoch 013:    107 / 866 loss=2.258, loss_v1=0, loss_v2=0, nll_loss=1.043, ntokens=2011.7, nsentences=64, sample_size=2011.7, sample_size_v1=0, sample_size_v2=0, ppl=2.06, wps=502, ups=0.25, wpb=2011.7, bsz=64, num_updates=10480, lr=1.90402e-05, gnorm=4.867, clip=100, loss_scale=64, train_wall=40, gb_free=6.8, wall=42316
2023-05-08 11:41:55 - progress_bar.py[line:272] - INFO: epoch 013:    117 / 866 loss=2.267, loss_v1=0, loss_v2=0, nll_loss=1.052, ntokens=2101.1, nsentences=64, sample_size=2101.1, sample_size_v1=0, sample_size_v2=0, ppl=2.07, wps=516.3, ups=0.25, wpb=2101.1, bsz=64, num_updates=10490, lr=1.90279e-05, gnorm=4.69, clip=100, loss_scale=64, train_wall=41, gb_free=6.9, wall=42356
2023-05-08 11:42:36 - progress_bar.py[line:272] - INFO: epoch 013:    127 / 866 loss=2.25, loss_v1=0, loss_v2=0, nll_loss=1.033, ntokens=2224.4, nsentences=64, sample_size=2224.4, sample_size_v1=0, sample_size_v2=0, ppl=2.05, wps=540.9, ups=0.24, wpb=2224.4, bsz=64, num_updates=10500, lr=1.90156e-05, gnorm=4.499, clip=100, loss_scale=64, train_wall=41, gb_free=7.3, wall=42398
2023-05-08 11:43:17 - progress_bar.py[line:272] - INFO: epoch 013:    137 / 866 loss=2.217, loss_v1=0, loss_v2=0, nll_loss=0.997, ntokens=2240.2, nsentences=64, sample_size=2240.2, sample_size_v1=0, sample_size_v2=0, ppl=2, wps=547.3, ups=0.24, wpb=2240.2, bsz=64, num_updates=10510, lr=1.90034e-05, gnorm=4.095, clip=100, loss_scale=64, train_wall=41, gb_free=7.3, wall=42439
2023-05-08 11:43:59 - progress_bar.py[line:272] - INFO: epoch 013:    147 / 866 loss=2.209, loss_v1=0, loss_v2=0, nll_loss=0.987, ntokens=2170.9, nsentences=64, sample_size=2170.9, sample_size_v1=0, sample_size_v2=0, ppl=1.98, wps=526.5, ups=0.24, wpb=2170.9, bsz=64, num_updates=10520, lr=1.89911e-05, gnorm=4.364, clip=100, loss_scale=64, train_wall=41, gb_free=7.2, wall=42480
2023-05-08 11:44:40 - progress_bar.py[line:272] - INFO: epoch 013:    157 / 866 loss=2.232, loss_v1=0, loss_v2=0, nll_loss=1.014, ntokens=2265.1, nsentences=64, sample_size=2265.1, sample_size_v1=0, sample_size_v2=0, ppl=2.02, wps=547.8, ups=0.24, wpb=2265.1, bsz=64, num_updates=10530, lr=1.89788e-05, gnorm=4.493, clip=100, loss_scale=64, train_wall=41, gb_free=7.1, wall=42521
2023-05-08 11:45:21 - progress_bar.py[line:272] - INFO: epoch 013:    167 / 866 loss=2.229, loss_v1=0, loss_v2=0, nll_loss=1.008, ntokens=2117.6, nsentences=64, sample_size=2117.6, sample_size_v1=0, sample_size_v2=0, ppl=2.01, wps=519.9, ups=0.25, wpb=2117.6, bsz=64, num_updates=10540, lr=1.89665e-05, gnorm=4.9, clip=100, loss_scale=64, train_wall=41, gb_free=6.4, wall=42562
2023-05-08 11:46:01 - progress_bar.py[line:272] - INFO: epoch 013:    177 / 866 loss=2.242, loss_v1=0, loss_v2=0, nll_loss=1.025, ntokens=2059.5, nsentences=64, sample_size=2059.5, sample_size_v1=0, sample_size_v2=0, ppl=2.04, wps=506.6, ups=0.25, wpb=2059.5, bsz=64, num_updates=10550, lr=1.89542e-05, gnorm=4.836, clip=100, loss_scale=64, train_wall=41, gb_free=7.1, wall=42603
2023-05-08 11:46:42 - progress_bar.py[line:272] - INFO: epoch 013:    187 / 866 loss=2.209, loss_v1=0, loss_v2=0, nll_loss=0.987, ntokens=2187.4, nsentences=64, sample_size=2187.4, sample_size_v1=0, sample_size_v2=0, ppl=1.98, wps=533.7, ups=0.24, wpb=2187.4, bsz=64, num_updates=10560, lr=1.89419e-05, gnorm=4.731, clip=100, loss_scale=64, train_wall=41, gb_free=6.7, wall=42644
2023-05-08 11:47:23 - progress_bar.py[line:272] - INFO: epoch 013:    197 / 866 loss=2.233, loss_v1=0, loss_v2=0, nll_loss=1.015, ntokens=2211.2, nsentences=64, sample_size=2211.2, sample_size_v1=0, sample_size_v2=0, ppl=2.02, wps=539.4, ups=0.24, wpb=2211.2, bsz=64, num_updates=10570, lr=1.89297e-05, gnorm=4.53, clip=100, loss_scale=64, train_wall=41, gb_free=7.6, wall=42685
2023-05-08 11:48:04 - progress_bar.py[line:272] - INFO: epoch 013:    207 / 866 loss=2.27, loss_v1=0, loss_v2=0, nll_loss=1.055, ntokens=1950.8, nsentences=64, sample_size=1950.8, sample_size_v1=0, sample_size_v2=0, ppl=2.08, wps=485.8, ups=0.25, wpb=1950.8, bsz=64, num_updates=10580, lr=1.89174e-05, gnorm=4.795, clip=100, loss_scale=128, train_wall=40, gb_free=7, wall=42725
2023-05-08 11:48:16 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2023-05-08 11:48:48 - progress_bar.py[line:272] - INFO: epoch 013:    218 / 866 loss=2.275, loss_v1=0, loss_v2=0, nll_loss=1.063, ntokens=2190.7, nsentences=64, sample_size=2190.7, sample_size_v1=0, sample_size_v2=0, ppl=2.09, wps=494.4, ups=0.23, wpb=2190.7, bsz=64, num_updates=10590, lr=1.89051e-05, gnorm=4.635, clip=100, loss_scale=64, train_wall=44, gb_free=7.9, wall=42769
2023-05-08 11:49:28 - progress_bar.py[line:272] - INFO: epoch 013:    228 / 866 loss=2.267, loss_v1=0, loss_v2=0, nll_loss=1.051, ntokens=2165.7, nsentences=64, sample_size=2165.7, sample_size_v1=0, sample_size_v2=0, ppl=2.07, wps=536.6, ups=0.25, wpb=2165.7, bsz=64, num_updates=10600, lr=1.88928e-05, gnorm=4.561, clip=100, loss_scale=64, train_wall=40, gb_free=8, wall=42809
2023-05-08 11:50:08 - progress_bar.py[line:272] - INFO: epoch 013:    238 / 866 loss=2.291, loss_v1=0, loss_v2=0, nll_loss=1.08, ntokens=2129.1, nsentences=64, sample_size=2129.1, sample_size_v1=0, sample_size_v2=0, ppl=2.11, wps=529.7, ups=0.25, wpb=2129.1, bsz=64, num_updates=10610, lr=1.88805e-05, gnorm=4.694, clip=100, loss_scale=64, train_wall=40, gb_free=7.8, wall=42850
2023-05-08 11:50:49 - progress_bar.py[line:272] - INFO: epoch 013:    248 / 866 loss=2.266, loss_v1=0, loss_v2=0, nll_loss=1.051, ntokens=2173.3, nsentences=64, sample_size=2173.3, sample_size_v1=0, sample_size_v2=0, ppl=2.07, wps=538.7, ups=0.25, wpb=2173.3, bsz=64, num_updates=10620, lr=1.88682e-05, gnorm=4.631, clip=100, loss_scale=64, train_wall=40, gb_free=7.7, wall=42890
2023-05-08 11:51:29 - progress_bar.py[line:272] - INFO: epoch 013:    258 / 866 loss=2.277, loss_v1=0, loss_v2=0, nll_loss=1.065, ntokens=2109.7, nsentences=64, sample_size=2109.7, sample_size_v1=0, sample_size_v2=0, ppl=2.09, wps=526, ups=0.25, wpb=2109.7, bsz=64, num_updates=10630, lr=1.88559e-05, gnorm=5.203, clip=100, loss_scale=64, train_wall=40, gb_free=7.8, wall=42930
2023-05-08 11:52:09 - progress_bar.py[line:272] - INFO: epoch 013:    268 / 866 loss=2.272, loss_v1=0, loss_v2=0, nll_loss=1.057, ntokens=2130.6, nsentences=64, sample_size=2130.6, sample_size_v1=0, sample_size_v2=0, ppl=2.08, wps=530.1, ups=0.25, wpb=2130.6, bsz=64, num_updates=10640, lr=1.88437e-05, gnorm=4.846, clip=100, loss_scale=64, train_wall=40, gb_free=8, wall=42970
2023-05-08 11:52:49 - progress_bar.py[line:272] - INFO: epoch 013:    278 / 866 loss=2.263, loss_v1=0, loss_v2=0, nll_loss=1.05, ntokens=2172.4, nsentences=64, sample_size=2172.4, sample_size_v1=0, sample_size_v2=0, ppl=2.07, wps=537.8, ups=0.25, wpb=2172.4, bsz=64, num_updates=10650, lr=1.88314e-05, gnorm=4.852, clip=100, loss_scale=64, train_wall=40, gb_free=7.7, wall=43011
2023-05-08 11:53:30 - progress_bar.py[line:272] - INFO: epoch 013:    288 / 866 loss=2.257, loss_v1=0, loss_v2=0, nll_loss=1.039, ntokens=2196.8, nsentences=64, sample_size=2196.8, sample_size_v1=0, sample_size_v2=0, ppl=2.06, wps=543.7, ups=0.25, wpb=2196.8, bsz=64, num_updates=10660, lr=1.88191e-05, gnorm=4.538, clip=100, loss_scale=64, train_wall=40, gb_free=7.8, wall=43051
2023-05-08 11:54:10 - progress_bar.py[line:272] - INFO: epoch 013:    298 / 866 loss=2.255, loss_v1=0, loss_v2=0, nll_loss=1.042, ntokens=2080.1, nsentences=64, sample_size=2080.1, sample_size_v1=0, sample_size_v2=0, ppl=2.06, wps=519.9, ups=0.25, wpb=2080.1, bsz=64, num_updates=10670, lr=1.88068e-05, gnorm=4.744, clip=100, loss_scale=64, train_wall=40, gb_free=8.2, wall=43091
2023-05-08 11:54:50 - progress_bar.py[line:272] - INFO: epoch 013:    308 / 866 loss=2.261, loss_v1=0, loss_v2=0, nll_loss=1.046, ntokens=2155.7, nsentences=64, sample_size=2155.7, sample_size_v1=0, sample_size_v2=0, ppl=2.06, wps=534, ups=0.25, wpb=2155.7, bsz=64, num_updates=10680, lr=1.87945e-05, gnorm=4.774, clip=100, loss_scale=64, train_wall=40, gb_free=8.1, wall=43131
2023-05-08 11:55:30 - progress_bar.py[line:272] - INFO: epoch 013:    318 / 866 loss=2.261, loss_v1=0, loss_v2=0, nll_loss=1.043, ntokens=2007.1, nsentences=64, sample_size=2007.1, sample_size_v1=0, sample_size_v2=0, ppl=2.06, wps=499.7, ups=0.25, wpb=2007.1, bsz=64, num_updates=10690, lr=1.87822e-05, gnorm=5.275, clip=100, loss_scale=64, train_wall=40, gb_free=8.1, wall=43172
2023-05-08 11:56:10 - progress_bar.py[line:272] - INFO: epoch 013:    328 / 866 loss=2.287, loss_v1=0, loss_v2=0, nll_loss=1.077, ntokens=2043.2, nsentences=64, sample_size=2043.2, sample_size_v1=0, sample_size_v2=0, ppl=2.11, wps=512.9, ups=0.25, wpb=2043.2, bsz=64, num_updates=10700, lr=1.877e-05, gnorm=5.051, clip=100, loss_scale=64, train_wall=40, gb_free=8, wall=43211
2023-05-08 11:56:51 - progress_bar.py[line:272] - INFO: epoch 013:    338 / 866 loss=2.243, loss_v1=0, loss_v2=0, nll_loss=1.024, ntokens=2147.1, nsentences=64, sample_size=2147.1, sample_size_v1=0, sample_size_v2=0, ppl=2.03, wps=532.9, ups=0.25, wpb=2147.1, bsz=64, num_updates=10710, lr=1.87577e-05, gnorm=4.447, clip=100, loss_scale=64, train_wall=40, gb_free=8, wall=43252
2023-05-08 11:57:30 - progress_bar.py[line:272] - INFO: epoch 013:    348 / 866 loss=2.266, loss_v1=0, loss_v2=0, nll_loss=1.054, ntokens=1910.8, nsentences=64, sample_size=1910.8, sample_size_v1=0, sample_size_v2=0, ppl=2.08, wps=480.8, ups=0.25, wpb=1910.8, bsz=64, num_updates=10720, lr=1.87454e-05, gnorm=5.311, clip=100, loss_scale=64, train_wall=40, gb_free=7.9, wall=43291
2023-05-08 11:58:10 - progress_bar.py[line:272] - INFO: epoch 013:    358 / 866 loss=2.292, loss_v1=0, loss_v2=0, nll_loss=1.079, ntokens=1995.2, nsentences=64, sample_size=1995.2, sample_size_v1=0, sample_size_v2=0, ppl=2.11, wps=501.2, ups=0.25, wpb=1995.2, bsz=64, num_updates=10730, lr=1.87331e-05, gnorm=5.728, clip=100, loss_scale=64, train_wall=40, gb_free=8.2, wall=43331
2023-05-08 11:58:50 - progress_bar.py[line:272] - INFO: epoch 013:    368 / 866 loss=2.272, loss_v1=0, loss_v2=0, nll_loss=1.057, ntokens=1984.4, nsentences=64, sample_size=1984.4, sample_size_v1=0, sample_size_v2=0, ppl=2.08, wps=498.9, ups=0.25, wpb=1984.4, bsz=64, num_updates=10740, lr=1.87208e-05, gnorm=5.018, clip=100, loss_scale=64, train_wall=40, gb_free=7.8, wall=43371
2023-05-08 11:59:30 - progress_bar.py[line:272] - INFO: epoch 013:    378 / 866 loss=2.258, loss_v1=0, loss_v2=0, nll_loss=1.041, ntokens=2113.8, nsentences=64, sample_size=2113.8, sample_size_v1=0, sample_size_v2=0, ppl=2.06, wps=527.5, ups=0.25, wpb=2113.8, bsz=64, num_updates=10750, lr=1.87085e-05, gnorm=4.724, clip=100, loss_scale=64, train_wall=40, gb_free=8.2, wall=43411
2023-05-08 12:00:10 - progress_bar.py[line:272] - INFO: epoch 013:    388 / 866 loss=2.247, loss_v1=0, loss_v2=0, nll_loss=1.032, ntokens=2138.6, nsentences=64, sample_size=2138.6, sample_size_v1=0, sample_size_v2=0, ppl=2.04, wps=534.7, ups=0.25, wpb=2138.6, bsz=64, num_updates=10760, lr=1.86963e-05, gnorm=4.673, clip=100, loss_scale=64, train_wall=40, gb_free=7.5, wall=43451
2023-05-08 12:00:50 - progress_bar.py[line:272] - INFO: epoch 013:    398 / 866 loss=2.276, loss_v1=0, loss_v2=0, nll_loss=1.063, ntokens=2064.6, nsentences=64, sample_size=2064.6, sample_size_v1=0, sample_size_v2=0, ppl=2.09, wps=516.6, ups=0.25, wpb=2064.6, bsz=64, num_updates=10770, lr=1.8684e-05, gnorm=5.012, clip=100, loss_scale=64, train_wall=40, gb_free=7.2, wall=43491
2023-05-08 12:01:30 - progress_bar.py[line:272] - INFO: epoch 013:    408 / 866 loss=2.263, loss_v1=0, loss_v2=0, nll_loss=1.049, ntokens=2069, nsentences=64, sample_size=2069, sample_size_v1=0, sample_size_v2=0, ppl=2.07, wps=518.3, ups=0.25, wpb=2069, bsz=64, num_updates=10780, lr=1.86717e-05, gnorm=4.888, clip=100, loss_scale=64, train_wall=40, gb_free=7.7, wall=43531
2023-05-08 12:02:10 - progress_bar.py[line:272] - INFO: epoch 013:    418 / 866 loss=2.244, loss_v1=0, loss_v2=0, nll_loss=1.028, ntokens=2098.3, nsentences=64, sample_size=2098.3, sample_size_v1=0, sample_size_v2=0, ppl=2.04, wps=523.1, ups=0.25, wpb=2098.3, bsz=64, num_updates=10790, lr=1.86594e-05, gnorm=5.041, clip=100, loss_scale=64, train_wall=40, gb_free=7.2, wall=43571
2023-05-08 12:02:50 - progress_bar.py[line:272] - INFO: epoch 013:    428 / 866 loss=2.241, loss_v1=0, loss_v2=0, nll_loss=1.022, ntokens=2110.8, nsentences=64, sample_size=2110.8, sample_size_v1=0, sample_size_v2=0, ppl=2.03, wps=525.6, ups=0.25, wpb=2110.8, bsz=64, num_updates=10800, lr=1.86471e-05, gnorm=4.537, clip=100, loss_scale=64, train_wall=40, gb_free=7.7, wall=43611
2023-05-08 12:03:30 - progress_bar.py[line:272] - INFO: epoch 013:    438 / 866 loss=2.276, loss_v1=0, loss_v2=0, nll_loss=1.062, ntokens=2124.1, nsentences=64, sample_size=2124.1, sample_size_v1=0, sample_size_v2=0, ppl=2.09, wps=530.6, ups=0.25, wpb=2124.1, bsz=64, num_updates=10810, lr=1.86348e-05, gnorm=4.887, clip=100, loss_scale=64, train_wall=40, gb_free=8, wall=43651
2023-05-08 12:04:11 - progress_bar.py[line:272] - INFO: epoch 013:    448 / 866 loss=2.29, loss_v1=0, loss_v2=0, nll_loss=1.077, ntokens=1996.8, nsentences=64, sample_size=1996.8, sample_size_v1=0, sample_size_v2=0, ppl=2.11, wps=495.1, ups=0.25, wpb=1996.8, bsz=64, num_updates=10820, lr=1.86226e-05, gnorm=5.37, clip=100, loss_scale=64, train_wall=40, gb_free=7.7, wall=43692
2023-05-08 12:04:51 - progress_bar.py[line:272] - INFO: epoch 013:    458 / 866 loss=2.269, loss_v1=0, loss_v2=0, nll_loss=1.056, ntokens=2079.8, nsentences=64, sample_size=2079.8, sample_size_v1=0, sample_size_v2=0, ppl=2.08, wps=515.2, ups=0.25, wpb=2079.8, bsz=64, num_updates=10830, lr=1.86103e-05, gnorm=5.053, clip=100, loss_scale=64, train_wall=40, gb_free=8, wall=43732
2023-05-08 12:05:31 - progress_bar.py[line:272] - INFO: epoch 013:    468 / 866 loss=2.266, loss_v1=0, loss_v2=0, nll_loss=1.049, ntokens=2164.7, nsentences=64, sample_size=2164.7, sample_size_v1=0, sample_size_v2=0, ppl=2.07, wps=537.6, ups=0.25, wpb=2164.7, bsz=64, num_updates=10840, lr=1.8598e-05, gnorm=5.061, clip=100, loss_scale=64, train_wall=40, gb_free=7.4, wall=43772
2023-05-08 12:06:12 - progress_bar.py[line:272] - INFO: epoch 013:    478 / 866 loss=2.272, loss_v1=0, loss_v2=0, nll_loss=1.058, ntokens=2220, nsentences=64, sample_size=2220, sample_size_v1=0, sample_size_v2=0, ppl=2.08, wps=547.9, ups=0.25, wpb=2220, bsz=64, num_updates=10850, lr=1.85857e-05, gnorm=5.004, clip=100, loss_scale=64, train_wall=40, gb_free=8, wall=43813
2023-05-08 12:06:52 - progress_bar.py[line:272] - INFO: epoch 013:    488 / 866 loss=2.247, loss_v1=0, loss_v2=0, nll_loss=1.029, ntokens=2033.8, nsentences=64, sample_size=2033.8, sample_size_v1=0, sample_size_v2=0, ppl=2.04, wps=507.3, ups=0.25, wpb=2033.8, bsz=64, num_updates=10860, lr=1.85734e-05, gnorm=4.64, clip=100, loss_scale=64, train_wall=40, gb_free=8.3, wall=43853
2023-05-08 12:07:32 - progress_bar.py[line:272] - INFO: epoch 013:    498 / 866 loss=2.242, loss_v1=0, loss_v2=0, nll_loss=1.025, ntokens=2069, nsentences=64, sample_size=2069, sample_size_v1=0, sample_size_v2=0, ppl=2.04, wps=515.6, ups=0.25, wpb=2069, bsz=64, num_updates=10870, lr=1.85611e-05, gnorm=5.061, clip=100, loss_scale=64, train_wall=40, gb_free=8.5, wall=43893
2023-05-08 12:08:12 - progress_bar.py[line:272] - INFO: epoch 013:    508 / 866 loss=2.284, loss_v1=0, loss_v2=0, nll_loss=1.072, ntokens=2115.2, nsentences=64, sample_size=2115.2, sample_size_v1=0, sample_size_v2=0, ppl=2.1, wps=529, ups=0.25, wpb=2115.2, bsz=64, num_updates=10880, lr=1.85488e-05, gnorm=4.725, clip=100, loss_scale=64, train_wall=40, gb_free=7.9, wall=43933
2023-05-08 12:08:52 - progress_bar.py[line:272] - INFO: epoch 013:    518 / 866 loss=2.268, loss_v1=0, loss_v2=0, nll_loss=1.052, ntokens=2197.1, nsentences=64, sample_size=2197.1, sample_size_v1=0, sample_size_v2=0, ppl=2.07, wps=548.3, ups=0.25, wpb=2197.1, bsz=64, num_updates=10890, lr=1.85366e-05, gnorm=4.831, clip=100, loss_scale=64, train_wall=40, gb_free=8.1, wall=43973
2023-05-08 12:09:32 - progress_bar.py[line:272] - INFO: epoch 013:    528 / 866 loss=2.268, loss_v1=0, loss_v2=0, nll_loss=1.054, ntokens=1974.3, nsentences=64, sample_size=1974.3, sample_size_v1=0, sample_size_v2=0, ppl=2.08, wps=493, ups=0.25, wpb=1974.3, bsz=64, num_updates=10900, lr=1.85243e-05, gnorm=4.75, clip=100, loss_scale=64, train_wall=40, gb_free=8.3, wall=44013
2023-05-08 12:10:12 - progress_bar.py[line:272] - INFO: epoch 013:    538 / 866 loss=2.252, loss_v1=0, loss_v2=0, nll_loss=1.036, ntokens=2123.8, nsentences=64, sample_size=2123.8, sample_size_v1=0, sample_size_v2=0, ppl=2.05, wps=527.1, ups=0.25, wpb=2123.8, bsz=64, num_updates=10910, lr=1.8512e-05, gnorm=4.837, clip=100, loss_scale=64, train_wall=40, gb_free=7.5, wall=44053
2023-05-08 12:10:53 - progress_bar.py[line:272] - INFO: epoch 013:    548 / 866 loss=2.284, loss_v1=0, loss_v2=0, nll_loss=1.072, ntokens=2308.9, nsentences=64, sample_size=2308.9, sample_size_v1=0, sample_size_v2=0, ppl=2.1, wps=567, ups=0.25, wpb=2308.9, bsz=64, num_updates=10920, lr=1.84997e-05, gnorm=4.575, clip=100, loss_scale=64, train_wall=41, gb_free=8.1, wall=44094
2023-05-08 12:11:34 - progress_bar.py[line:272] - INFO: epoch 013:    558 / 866 loss=2.269, loss_v1=0, loss_v2=0, nll_loss=1.055, ntokens=2284.3, nsentences=64, sample_size=2284.3, sample_size_v1=0, sample_size_v2=0, ppl=2.08, wps=562.8, ups=0.25, wpb=2284.3, bsz=64, num_updates=10930, lr=1.84874e-05, gnorm=4.43, clip=100, loss_scale=64, train_wall=41, gb_free=7.2, wall=44135
2023-05-08 12:12:14 - progress_bar.py[line:272] - INFO: epoch 013:    568 / 866 loss=2.269, loss_v1=0, loss_v2=0, nll_loss=1.054, ntokens=2217.8, nsentences=64, sample_size=2217.8, sample_size_v1=0, sample_size_v2=0, ppl=2.08, wps=549.7, ups=0.25, wpb=2217.8, bsz=64, num_updates=10940, lr=1.84751e-05, gnorm=4.856, clip=100, loss_scale=64, train_wall=40, gb_free=7.4, wall=44175
2023-05-08 12:12:54 - progress_bar.py[line:272] - INFO: epoch 013:    578 / 866 loss=2.262, loss_v1=0, loss_v2=0, nll_loss=1.048, ntokens=2124.1, nsentences=64, sample_size=2124.1, sample_size_v1=0, sample_size_v2=0, ppl=2.07, wps=527.5, ups=0.25, wpb=2124.1, bsz=64, num_updates=10950, lr=1.84629e-05, gnorm=4.666, clip=100, loss_scale=64, train_wall=40, gb_free=7.5, wall=44215
2023-05-08 12:13:35 - progress_bar.py[line:272] - INFO: epoch 013:    588 / 866 loss=2.276, loss_v1=0, loss_v2=0, nll_loss=1.062, ntokens=2074.5, nsentences=64, sample_size=2074.5, sample_size_v1=0, sample_size_v2=0, ppl=2.09, wps=514.4, ups=0.25, wpb=2074.5, bsz=64, num_updates=10960, lr=1.84506e-05, gnorm=5.275, clip=100, loss_scale=64, train_wall=40, gb_free=7.8, wall=44256
2023-05-08 12:14:15 - progress_bar.py[line:272] - INFO: epoch 013:    598 / 866 loss=2.24, loss_v1=0, loss_v2=0, nll_loss=1.024, ntokens=2145.5, nsentences=64, sample_size=2145.5, sample_size_v1=0, sample_size_v2=0, ppl=2.03, wps=525, ups=0.24, wpb=2145.5, bsz=64, num_updates=10970, lr=1.84383e-05, gnorm=4.827, clip=100, loss_scale=64, train_wall=41, gb_free=8.4, wall=44297
2023-05-08 12:14:56 - progress_bar.py[line:272] - INFO: epoch 013:    608 / 866 loss=2.253, loss_v1=0, loss_v2=0, nll_loss=1.038, ntokens=1989.2, nsentences=64, sample_size=1989.2, sample_size_v1=0, sample_size_v2=0, ppl=2.05, wps=494.6, ups=0.25, wpb=1989.2, bsz=64, num_updates=10980, lr=1.8426e-05, gnorm=5.449, clip=100, loss_scale=64, train_wall=40, gb_free=7.4, wall=44337
2023-05-08 12:15:36 - progress_bar.py[line:272] - INFO: epoch 013:    618 / 866 loss=2.286, loss_v1=0, loss_v2=0, nll_loss=1.073, ntokens=1954.5, nsentences=64, sample_size=1954.5, sample_size_v1=0, sample_size_v2=0, ppl=2.1, wps=488.6, ups=0.25, wpb=1954.5, bsz=64, num_updates=10990, lr=1.84137e-05, gnorm=5.311, clip=100, loss_scale=64, train_wall=40, gb_free=8.1, wall=44377
2023-05-08 12:16:16 - progress_bar.py[line:272] - INFO: epoch 013:    628 / 866 loss=2.263, loss_v1=0, loss_v2=0, nll_loss=1.048, ntokens=2038.9, nsentences=64, sample_size=2038.9, sample_size_v1=0, sample_size_v2=0, ppl=2.07, wps=509.2, ups=0.25, wpb=2038.9, bsz=64, num_updates=11000, lr=1.84014e-05, gnorm=5.169, clip=100, loss_scale=64, train_wall=40, gb_free=8.1, wall=44417
2023-05-08 12:16:56 - progress_bar.py[line:272] - INFO: epoch 013:    638 / 866 loss=2.25, loss_v1=0, loss_v2=0, nll_loss=1.032, ntokens=2076.7, nsentences=64, sample_size=2076.7, sample_size_v1=0, sample_size_v2=0, ppl=2.04, wps=518.9, ups=0.25, wpb=2076.7, bsz=64, num_updates=11010, lr=1.83892e-05, gnorm=4.938, clip=100, loss_scale=64, train_wall=40, gb_free=8.1, wall=44457
2023-05-08 12:17:35 - progress_bar.py[line:272] - INFO: epoch 013:    648 / 866 loss=2.263, loss_v1=0, loss_v2=0, nll_loss=1.047, ntokens=2031.8, nsentences=64, sample_size=2031.8, sample_size_v1=0, sample_size_v2=0, ppl=2.07, wps=511.6, ups=0.25, wpb=2031.8, bsz=64, num_updates=11020, lr=1.83769e-05, gnorm=5.155, clip=100, loss_scale=64, train_wall=40, gb_free=7.9, wall=44497
2023-05-08 12:18:15 - progress_bar.py[line:272] - INFO: epoch 013:    658 / 866 loss=2.285, loss_v1=0, loss_v2=0, nll_loss=1.075, ntokens=1925.9, nsentences=64, sample_size=1925.9, sample_size_v1=0, sample_size_v2=0, ppl=2.11, wps=485.3, ups=0.25, wpb=1925.9, bsz=64, num_updates=11030, lr=1.83646e-05, gnorm=5.312, clip=100, loss_scale=64, train_wall=40, gb_free=7.7, wall=44536
2023-05-08 12:18:55 - progress_bar.py[line:272] - INFO: epoch 013:    668 / 866 loss=2.268, loss_v1=0, loss_v2=0, nll_loss=1.051, ntokens=1987.1, nsentences=64, sample_size=1987.1, sample_size_v1=0, sample_size_v2=0, ppl=2.07, wps=495.8, ups=0.25, wpb=1987.1, bsz=64, num_updates=11040, lr=1.83523e-05, gnorm=4.893, clip=100, loss_scale=64, train_wall=40, gb_free=7.3, wall=44576
2023-05-08 12:19:35 - progress_bar.py[line:272] - INFO: epoch 013:    678 / 866 loss=2.263, loss_v1=0, loss_v2=0, nll_loss=1.049, ntokens=2078.2, nsentences=64, sample_size=2078.2, sample_size_v1=0, sample_size_v2=0, ppl=2.07, wps=519.2, ups=0.25, wpb=2078.2, bsz=64, num_updates=11050, lr=1.834e-05, gnorm=4.636, clip=100, loss_scale=64, train_wall=40, gb_free=7.9, wall=44616
2023-05-08 12:20:15 - progress_bar.py[line:272] - INFO: epoch 013:    688 / 866 loss=2.259, loss_v1=0, loss_v2=0, nll_loss=1.044, ntokens=1984.8, nsentences=64, sample_size=1984.8, sample_size_v1=0, sample_size_v2=0, ppl=2.06, wps=498, ups=0.25, wpb=1984.8, bsz=64, num_updates=11060, lr=1.83277e-05, gnorm=5.16, clip=100, loss_scale=64, train_wall=40, gb_free=8.1, wall=44656
2023-05-08 12:20:55 - progress_bar.py[line:272] - INFO: epoch 013:    698 / 866 loss=2.267, loss_v1=0, loss_v2=0, nll_loss=1.051, ntokens=2119.6, nsentences=64, sample_size=2119.6, sample_size_v1=0, sample_size_v2=0, ppl=2.07, wps=527.8, ups=0.25, wpb=2119.6, bsz=64, num_updates=11070, lr=1.83155e-05, gnorm=4.843, clip=100, loss_scale=64, train_wall=40, gb_free=8.1, wall=44696
2023-05-08 12:21:35 - progress_bar.py[line:272] - INFO: epoch 013:    708 / 866 loss=2.276, loss_v1=0, loss_v2=0, nll_loss=1.064, ntokens=1968.4, nsentences=64, sample_size=1968.4, sample_size_v1=0, sample_size_v2=0, ppl=2.09, wps=492.1, ups=0.25, wpb=1968.4, bsz=64, num_updates=11080, lr=1.83032e-05, gnorm=4.944, clip=100, loss_scale=64, train_wall=40, gb_free=8.1, wall=44736
2023-05-08 12:22:15 - progress_bar.py[line:272] - INFO: epoch 013:    718 / 866 loss=2.272, loss_v1=0, loss_v2=0, nll_loss=1.058, ntokens=1904, nsentences=64, sample_size=1904, sample_size_v1=0, sample_size_v2=0, ppl=2.08, wps=477.1, ups=0.25, wpb=1904, bsz=64, num_updates=11090, lr=1.82909e-05, gnorm=5.335, clip=100, loss_scale=64, train_wall=40, gb_free=8.4, wall=44776
2023-05-08 12:22:55 - progress_bar.py[line:272] - INFO: epoch 013:    728 / 866 loss=2.231, loss_v1=0, loss_v2=0, nll_loss=1.013, ntokens=2000.2, nsentences=64, sample_size=2000.2, sample_size_v1=0, sample_size_v2=0, ppl=2.02, wps=500.7, ups=0.25, wpb=2000.2, bsz=64, num_updates=11100, lr=1.82786e-05, gnorm=4.794, clip=100, loss_scale=128, train_wall=40, gb_free=7.7, wall=44816
2023-05-08 12:23:03 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2023-05-08 12:23:39 - progress_bar.py[line:272] - INFO: epoch 013:    739 / 866 loss=2.249, loss_v1=0, loss_v2=0, nll_loss=1.032, ntokens=2097.9, nsentences=64, sample_size=2097.9, sample_size_v1=0, sample_size_v2=0, ppl=2.04, wps=476.3, ups=0.23, wpb=2097.9, bsz=64, num_updates=11110, lr=1.82663e-05, gnorm=4.932, clip=100, loss_scale=64, train_wall=44, gb_free=7.9, wall=44860
2023-05-08 12:24:20 - progress_bar.py[line:272] - INFO: epoch 013:    749 / 866 loss=2.227, loss_v1=0, loss_v2=0, nll_loss=1.006, ntokens=2148.5, nsentences=64, sample_size=2148.5, sample_size_v1=0, sample_size_v2=0, ppl=2.01, wps=530.6, ups=0.25, wpb=2148.5, bsz=64, num_updates=11120, lr=1.8254e-05, gnorm=4.565, clip=100, loss_scale=64, train_wall=40, gb_free=7.9, wall=44901
2023-05-08 12:25:00 - progress_bar.py[line:272] - INFO: epoch 013:    759 / 866 loss=2.253, loss_v1=0, loss_v2=0, nll_loss=1.039, ntokens=2034.8, nsentences=64, sample_size=2034.8, sample_size_v1=0, sample_size_v2=0, ppl=2.06, wps=509.5, ups=0.25, wpb=2034.8, bsz=64, num_updates=11130, lr=1.82417e-05, gnorm=4.93, clip=100, loss_scale=64, train_wall=40, gb_free=7.9, wall=44941
2023-05-08 12:25:40 - progress_bar.py[line:272] - INFO: epoch 013:    769 / 866 loss=2.244, loss_v1=0, loss_v2=0, nll_loss=1.027, ntokens=2112.7, nsentences=64, sample_size=2112.7, sample_size_v1=0, sample_size_v2=0, ppl=2.04, wps=527.5, ups=0.25, wpb=2112.7, bsz=64, num_updates=11140, lr=1.82295e-05, gnorm=5.142, clip=100, loss_scale=64, train_wall=40, gb_free=8.2, wall=44981
2023-05-08 12:26:20 - progress_bar.py[line:272] - INFO: epoch 013:    779 / 866 loss=2.24, loss_v1=0, loss_v2=0, nll_loss=1.021, ntokens=2311.6, nsentences=64, sample_size=2311.6, sample_size_v1=0, sample_size_v2=0, ppl=2.03, wps=572, ups=0.25, wpb=2311.6, bsz=64, num_updates=11150, lr=1.82172e-05, gnorm=4.704, clip=100, loss_scale=64, train_wall=40, gb_free=7.9, wall=45021
2023-05-08 12:27:00 - progress_bar.py[line:272] - INFO: epoch 013:    789 / 866 loss=2.262, loss_v1=0, loss_v2=0, nll_loss=1.047, ntokens=1956.5, nsentences=64, sample_size=1956.5, sample_size_v1=0, sample_size_v2=0, ppl=2.07, wps=491.3, ups=0.25, wpb=1956.5, bsz=64, num_updates=11160, lr=1.82049e-05, gnorm=5.298, clip=100, loss_scale=64, train_wall=40, gb_free=8.2, wall=45061
2023-05-08 12:27:40 - progress_bar.py[line:272] - INFO: epoch 013:    799 / 866 loss=2.263, loss_v1=0, loss_v2=0, nll_loss=1.048, ntokens=2067.5, nsentences=64, sample_size=2067.5, sample_size_v1=0, sample_size_v2=0, ppl=2.07, wps=518.3, ups=0.25, wpb=2067.5, bsz=64, num_updates=11170, lr=1.81926e-05, gnorm=5.092, clip=100, loss_scale=64, train_wall=40, gb_free=7.9, wall=45101
2023-05-08 12:28:20 - progress_bar.py[line:272] - INFO: epoch 013:    809 / 866 loss=2.234, loss_v1=0, loss_v2=0, nll_loss=1.015, ntokens=2011.6, nsentences=64, sample_size=2011.6, sample_size_v1=0, sample_size_v2=0, ppl=2.02, wps=503.6, ups=0.25, wpb=2011.6, bsz=64, num_updates=11180, lr=1.81803e-05, gnorm=4.947, clip=100, loss_scale=64, train_wall=40, gb_free=8.1, wall=45141
2023-05-08 12:29:00 - progress_bar.py[line:272] - INFO: epoch 013:    819 / 866 loss=2.233, loss_v1=0, loss_v2=0, nll_loss=1.016, ntokens=2062, nsentences=64, sample_size=2062, sample_size_v1=0, sample_size_v2=0, ppl=2.02, wps=510.9, ups=0.25, wpb=2062, bsz=64, num_updates=11190, lr=1.8168e-05, gnorm=5.15, clip=100, loss_scale=64, train_wall=40, gb_free=8.2, wall=45181
2023-05-08 12:29:41 - progress_bar.py[line:272] - INFO: epoch 013:    829 / 866 loss=2.239, loss_v1=0, loss_v2=0, nll_loss=1.022, ntokens=2180.5, nsentences=64, sample_size=2180.5, sample_size_v1=0, sample_size_v2=0, ppl=2.03, wps=534, ups=0.24, wpb=2180.5, bsz=64, num_updates=11200, lr=1.81558e-05, gnorm=4.368, clip=100, loss_scale=64, train_wall=41, gb_free=8.4, wall=45222
2023-05-08 12:30:22 - progress_bar.py[line:272] - INFO: epoch 013:    839 / 866 loss=2.249, loss_v1=0, loss_v2=0, nll_loss=1.033, ntokens=2134.9, nsentences=64, sample_size=2134.9, sample_size_v1=0, sample_size_v2=0, ppl=2.05, wps=525.9, ups=0.25, wpb=2134.9, bsz=64, num_updates=11210, lr=1.81435e-05, gnorm=4.594, clip=100, loss_scale=64, train_wall=41, gb_free=8.3, wall=45263
2023-05-08 12:31:02 - progress_bar.py[line:272] - INFO: epoch 013:    849 / 866 loss=2.238, loss_v1=0, loss_v2=0, nll_loss=1.021, ntokens=2218.6, nsentences=64, sample_size=2218.6, sample_size_v1=0, sample_size_v2=0, ppl=2.03, wps=549.3, ups=0.25, wpb=2218.6, bsz=64, num_updates=11220, lr=1.81312e-05, gnorm=4.352, clip=100, loss_scale=64, train_wall=40, gb_free=7.7, wall=45303
2023-05-08 12:31:42 - progress_bar.py[line:272] - INFO: epoch 013:    859 / 866 loss=2.241, loss_v1=0, loss_v2=0, nll_loss=1.025, ntokens=2042.9, nsentences=64, sample_size=2042.9, sample_size_v1=0, sample_size_v2=0, ppl=2.04, wps=506.8, ups=0.25, wpb=2042.9, bsz=64, num_updates=11230, lr=1.81189e-05, gnorm=5.011, clip=100, loss_scale=64, train_wall=40, gb_free=7.8, wall=45343
2023-05-08 12:32:09 - train.py[line:332] - INFO: end of epoch 13 (average epoch stats below)
local datafile ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 1 begin to initialize row_count and line_idx-to-offset mapping
2023-05-08 12:32:09 - progress_bar.py[line:282] - INFO: epoch 013 | loss 2.249 | loss_v1 0 | loss_v2 0 | nll_loss 1.032 | ntokens 2103.12 | nsentences 63.972 | sample_size 2103.12 | sample_size_v1 0 | sample_size_v2 0 | ppl 2.04 | wps 520.3 | ups 0.25 | wpb 2103.1 | bsz 64 | num_updates 11237 | lr 1.81103e-05 | gnorm 4.849 | clip 100 | loss_scale 64 | train_wall 3486 | gb_free 8.7 | wall 45370
2023-05-08 12:32:09 - trainer.py[line:639] - INFO: loading train data for epoch 14
local datafile ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 0 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 0 finished initializing row_count and line_idx-to-offset mapping
file ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 0 row count 27700 total row count 55400
slice_id 0 seek offset 0
2023-05-08 12:32:11 - trainer.py[line:703] - INFO: begin training epoch 14
2023-05-08 12:32:11 - train.py[line:305] - INFO: Start iterating over samples
local datafile ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 1 finished initializing row_count and line_idx-to-offset mapping
file ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 1 row count 27700 total row count 55400
slice_id 1 seek offset 27700
2023-05-08 12:32:23 - progress_bar.py[line:272] - INFO: epoch 014:      3 / 866 loss=2.261, loss_v1=0, loss_v2=0, nll_loss=1.043, ntokens=2095.2, nsentences=61.6, sample_size=2095.2, sample_size_v1=0, sample_size_v2=0, ppl=2.06, wps=510.4, ups=0.24, wpb=2095.2, bsz=61.6, num_updates=11240, lr=1.81066e-05, gnorm=4.672, clip=100, loss_scale=64, train_wall=39, gb_free=7.3, wall=45384
2023-05-08 12:33:04 - progress_bar.py[line:272] - INFO: epoch 014:     13 / 866 loss=2.206, loss_v1=0, loss_v2=0, nll_loss=0.985, ntokens=2047.5, nsentences=64, sample_size=2047.5, sample_size_v1=0, sample_size_v2=0, ppl=1.98, wps=504.2, ups=0.25, wpb=2047.5, bsz=64, num_updates=11250, lr=1.80943e-05, gnorm=5.047, clip=100, loss_scale=64, train_wall=41, gb_free=7.4, wall=45425
2023-05-08 12:33:44 - progress_bar.py[line:272] - INFO: epoch 014:     23 / 866 loss=2.183, loss_v1=0, loss_v2=0, nll_loss=0.959, ntokens=2054.4, nsentences=64, sample_size=2054.4, sample_size_v1=0, sample_size_v2=0, ppl=1.94, wps=508, ups=0.25, wpb=2054.4, bsz=64, num_updates=11260, lr=1.80821e-05, gnorm=4.789, clip=100, loss_scale=64, train_wall=40, gb_free=7.7, wall=45466
2023-05-08 12:34:25 - progress_bar.py[line:272] - INFO: epoch 014:     33 / 866 loss=2.169, loss_v1=0, loss_v2=0, nll_loss=0.941, ntokens=2091.8, nsentences=64, sample_size=2091.8, sample_size_v1=0, sample_size_v2=0, ppl=1.92, wps=515.5, ups=0.25, wpb=2091.8, bsz=64, num_updates=11270, lr=1.80698e-05, gnorm=4.779, clip=100, loss_scale=64, train_wall=41, gb_free=6.4, wall=45506
2023-05-08 12:35:06 - progress_bar.py[line:272] - INFO: epoch 014:     43 / 866 loss=2.143, loss_v1=0, loss_v2=0, nll_loss=0.916, ntokens=2128, nsentences=64, sample_size=2128, sample_size_v1=0, sample_size_v2=0, ppl=1.89, wps=522, ups=0.25, wpb=2128, bsz=64, num_updates=11280, lr=1.80575e-05, gnorm=4.591, clip=100, loss_scale=64, train_wall=41, gb_free=7.3, wall=45547
2023-05-08 12:35:46 - progress_bar.py[line:272] - INFO: epoch 014:     53 / 866 loss=2.195, loss_v1=0, loss_v2=0, nll_loss=0.972, ntokens=1987.1, nsentences=64, sample_size=1987.1, sample_size_v1=0, sample_size_v2=0, ppl=1.96, wps=491.7, ups=0.25, wpb=1987.1, bsz=64, num_updates=11290, lr=1.80452e-05, gnorm=4.767, clip=100, loss_scale=64, train_wall=40, gb_free=7.8, wall=45587
2023-05-08 12:36:27 - progress_bar.py[line:272] - INFO: epoch 014:     63 / 866 loss=2.07, loss_v1=0, loss_v2=0, nll_loss=0.833, ntokens=2273.9, nsentences=64, sample_size=2273.9, sample_size_v1=0, sample_size_v2=0, ppl=1.78, wps=555.5, ups=0.24, wpb=2273.9, bsz=64, num_updates=11300, lr=1.80329e-05, gnorm=4.289, clip=100, loss_scale=64, train_wall=41, gb_free=6.5, wall=45628
2023-05-08 12:37:09 - progress_bar.py[line:272] - INFO: epoch 014:     73 / 866 loss=2.126, loss_v1=0, loss_v2=0, nll_loss=0.894, ntokens=2436.8, nsentences=64, sample_size=2436.8, sample_size_v1=0, sample_size_v2=0, ppl=1.86, wps=584.1, ups=0.24, wpb=2436.8, bsz=64, num_updates=11310, lr=1.80206e-05, gnorm=3.877, clip=100, loss_scale=64, train_wall=42, gb_free=6.2, wall=45670
2023-05-08 12:37:50 - progress_bar.py[line:272] - INFO: epoch 014:     83 / 866 loss=2.17, loss_v1=0, loss_v2=0, nll_loss=0.945, ntokens=2209.4, nsentences=64, sample_size=2209.4, sample_size_v1=0, sample_size_v2=0, ppl=1.93, wps=537, ups=0.24, wpb=2209.4, bsz=64, num_updates=11320, lr=1.80084e-05, gnorm=4.734, clip=100, loss_scale=64, train_wall=41, gb_free=6.3, wall=45711
2023-05-08 12:38:31 - progress_bar.py[line:272] - INFO: epoch 014:     93 / 866 loss=2.143, loss_v1=0, loss_v2=0, nll_loss=0.914, ntokens=2158.2, nsentences=64, sample_size=2158.2, sample_size_v1=0, sample_size_v2=0, ppl=1.88, wps=530.6, ups=0.25, wpb=2158.2, bsz=64, num_updates=11330, lr=1.79961e-05, gnorm=4.338, clip=100, loss_scale=64, train_wall=41, gb_free=7.3, wall=45752
2023-05-08 12:39:11 - progress_bar.py[line:272] - INFO: epoch 014:    103 / 866 loss=2.231, loss_v1=0, loss_v2=0, nll_loss=1.014, ntokens=1999.5, nsentences=64, sample_size=1999.5, sample_size_v1=0, sample_size_v2=0, ppl=2.02, wps=496.9, ups=0.25, wpb=1999.5, bsz=64, num_updates=11340, lr=1.79838e-05, gnorm=5.321, clip=100, loss_scale=64, train_wall=40, gb_free=7.7, wall=45792
2023-05-08 12:39:51 - progress_bar.py[line:272] - INFO: epoch 014:    113 / 866 loss=2.246, loss_v1=0, loss_v2=0, nll_loss=1.027, ntokens=2058.9, nsentences=64, sample_size=2058.9, sample_size_v1=0, sample_size_v2=0, ppl=2.04, wps=508.1, ups=0.25, wpb=2058.9, bsz=64, num_updates=11350, lr=1.79715e-05, gnorm=5.02, clip=100, loss_scale=64, train_wall=40, gb_free=7, wall=45833
2023-05-08 12:40:33 - progress_bar.py[line:272] - INFO: epoch 014:    123 / 866 loss=2.234, loss_v1=0, loss_v2=0, nll_loss=1.017, ntokens=2201.6, nsentences=64, sample_size=2201.6, sample_size_v1=0, sample_size_v2=0, ppl=2.02, wps=536.4, ups=0.24, wpb=2201.6, bsz=64, num_updates=11360, lr=1.79592e-05, gnorm=4.696, clip=100, loss_scale=64, train_wall=41, gb_free=6.8, wall=45874
2023-05-08 12:41:13 - progress_bar.py[line:272] - INFO: epoch 014:    133 / 866 loss=2.206, loss_v1=0, loss_v2=0, nll_loss=0.982, ntokens=2208, nsentences=64, sample_size=2208, sample_size_v1=0, sample_size_v2=0, ppl=1.97, wps=538.7, ups=0.24, wpb=2208, bsz=64, num_updates=11370, lr=1.79469e-05, gnorm=4.466, clip=100, loss_scale=64, train_wall=41, gb_free=7.1, wall=45915
2023-05-08 12:41:55 - progress_bar.py[line:272] - INFO: epoch 014:    143 / 866 loss=2.194, loss_v1=0, loss_v2=0, nll_loss=0.973, ntokens=2264.9, nsentences=64, sample_size=2264.9, sample_size_v1=0, sample_size_v2=0, ppl=1.96, wps=548.6, ups=0.24, wpb=2264.9, bsz=64, num_updates=11380, lr=1.79346e-05, gnorm=4.285, clip=100, loss_scale=64, train_wall=41, gb_free=6.4, wall=45956
2023-05-08 12:42:36 - progress_bar.py[line:272] - INFO: epoch 014:    153 / 866 loss=2.2, loss_v1=0, loss_v2=0, nll_loss=0.978, ntokens=2165, nsentences=64, sample_size=2165, sample_size_v1=0, sample_size_v2=0, ppl=1.97, wps=522.9, ups=0.24, wpb=2165, bsz=64, num_updates=11390, lr=1.79224e-05, gnorm=4.301, clip=100, loss_scale=64, train_wall=41, gb_free=6.4, wall=45997
2023-05-08 12:43:17 - progress_bar.py[line:272] - INFO: epoch 014:    163 / 866 loss=2.212, loss_v1=0, loss_v2=0, nll_loss=0.99, ntokens=2159.1, nsentences=64, sample_size=2159.1, sample_size_v1=0, sample_size_v2=0, ppl=1.99, wps=527, ups=0.24, wpb=2159.1, bsz=64, num_updates=11400, lr=1.79101e-05, gnorm=4.552, clip=100, loss_scale=64, train_wall=41, gb_free=7.8, wall=46038
2023-05-08 12:43:57 - progress_bar.py[line:272] - INFO: epoch 014:    173 / 866 loss=2.227, loss_v1=0, loss_v2=0, nll_loss=1.007, ntokens=2040.6, nsentences=64, sample_size=2040.6, sample_size_v1=0, sample_size_v2=0, ppl=2.01, wps=505.9, ups=0.25, wpb=2040.6, bsz=64, num_updates=11410, lr=1.78978e-05, gnorm=4.936, clip=100, loss_scale=64, train_wall=40, gb_free=6.9, wall=46079
2023-05-08 12:44:39 - progress_bar.py[line:272] - INFO: epoch 014:    183 / 866 loss=2.191, loss_v1=0, loss_v2=0, nll_loss=0.967, ntokens=2201.4, nsentences=64, sample_size=2201.4, sample_size_v1=0, sample_size_v2=0, ppl=1.96, wps=536.2, ups=0.24, wpb=2201.4, bsz=64, num_updates=11420, lr=1.78855e-05, gnorm=4.393, clip=100, loss_scale=64, train_wall=41, gb_free=7.6, wall=46120
2023-05-08 12:45:20 - progress_bar.py[line:272] - INFO: epoch 014:    193 / 866 loss=2.203, loss_v1=0, loss_v2=0, nll_loss=0.981, ntokens=2205.9, nsentences=64, sample_size=2205.9, sample_size_v1=0, sample_size_v2=0, ppl=1.97, wps=538.6, ups=0.24, wpb=2205.9, bsz=64, num_updates=11430, lr=1.78732e-05, gnorm=4.758, clip=100, loss_scale=64, train_wall=41, gb_free=7.3, wall=46161
2023-05-08 12:46:00 - progress_bar.py[line:272] - INFO: epoch 014:    203 / 866 loss=2.235, loss_v1=0, loss_v2=0, nll_loss=1.016, ntokens=2075.5, nsentences=64, sample_size=2075.5, sample_size_v1=0, sample_size_v2=0, ppl=2.02, wps=510.6, ups=0.25, wpb=2075.5, bsz=64, num_updates=11440, lr=1.78609e-05, gnorm=4.728, clip=100, loss_scale=64, train_wall=41, gb_free=7.6, wall=46201
2023-05-08 12:46:40 - progress_bar.py[line:272] - INFO: epoch 014:    213 / 866 loss=2.248, loss_v1=0, loss_v2=0, nll_loss=1.033, ntokens=2063.9, nsentences=64, sample_size=2063.9, sample_size_v1=0, sample_size_v2=0, ppl=2.05, wps=512.1, ups=0.25, wpb=2063.9, bsz=64, num_updates=11450, lr=1.78487e-05, gnorm=4.727, clip=100, loss_scale=64, train_wall=40, gb_free=7.6, wall=46242
2023-05-08 12:47:21 - progress_bar.py[line:272] - INFO: epoch 014:    223 / 866 loss=2.241, loss_v1=0, loss_v2=0, nll_loss=1.023, ntokens=2222.1, nsentences=64, sample_size=2222.1, sample_size_v1=0, sample_size_v2=0, ppl=2.03, wps=551.8, ups=0.25, wpb=2222.1, bsz=64, num_updates=11460, lr=1.78364e-05, gnorm=4.548, clip=100, loss_scale=64, train_wall=40, gb_free=7.7, wall=46282
2023-05-08 12:48:01 - progress_bar.py[line:272] - INFO: epoch 014:    233 / 866 loss=2.271, loss_v1=0, loss_v2=0, nll_loss=1.056, ntokens=2107.2, nsentences=64, sample_size=2107.2, sample_size_v1=0, sample_size_v2=0, ppl=2.08, wps=527, ups=0.25, wpb=2107.2, bsz=64, num_updates=11470, lr=1.78241e-05, gnorm=4.785, clip=100, loss_scale=64, train_wall=40, gb_free=8.2, wall=46322
2023-05-08 12:48:41 - progress_bar.py[line:272] - INFO: epoch 014:    243 / 866 loss=2.246, loss_v1=0, loss_v2=0, nll_loss=1.031, ntokens=2185.9, nsentences=64, sample_size=2185.9, sample_size_v1=0, sample_size_v2=0, ppl=2.04, wps=541.3, ups=0.25, wpb=2185.9, bsz=64, num_updates=11480, lr=1.78118e-05, gnorm=4.381, clip=100, loss_scale=64, train_wall=40, gb_free=7.9, wall=46362
2023-05-08 12:49:21 - progress_bar.py[line:272] - INFO: epoch 014:    253 / 866 loss=2.258, loss_v1=0, loss_v2=0, nll_loss=1.041, ntokens=2123.8, nsentences=64, sample_size=2123.8, sample_size_v1=0, sample_size_v2=0, ppl=2.06, wps=527, ups=0.25, wpb=2123.8, bsz=64, num_updates=11490, lr=1.77995e-05, gnorm=4.64, clip=100, loss_scale=64, train_wall=40, gb_free=7.1, wall=46403
2023-05-08 12:50:01 - progress_bar.py[line:272] - INFO: epoch 014:    263 / 866 loss=2.255, loss_v1=0, loss_v2=0, nll_loss=1.04, ntokens=2145.7, nsentences=64, sample_size=2145.7, sample_size_v1=0, sample_size_v2=0, ppl=2.06, wps=535.6, ups=0.25, wpb=2145.7, bsz=64, num_updates=11500, lr=1.77872e-05, gnorm=4.713, clip=100, loss_scale=64, train_wall=40, gb_free=7.1, wall=46443
2023-05-08 12:50:42 - progress_bar.py[line:272] - INFO: epoch 014:    273 / 866 loss=2.243, loss_v1=0, loss_v2=0, nll_loss=1.025, ntokens=2144.3, nsentences=64, sample_size=2144.3, sample_size_v1=0, sample_size_v2=0, ppl=2.04, wps=532.9, ups=0.25, wpb=2144.3, bsz=64, num_updates=11510, lr=1.7775e-05, gnorm=4.645, clip=100, loss_scale=64, train_wall=40, gb_free=7.2, wall=46483
2023-05-08 12:51:22 - progress_bar.py[line:272] - INFO: epoch 014:    283 / 866 loss=2.257, loss_v1=0, loss_v2=0, nll_loss=1.043, ntokens=2148.3, nsentences=64, sample_size=2148.3, sample_size_v1=0, sample_size_v2=0, ppl=2.06, wps=532.5, ups=0.25, wpb=2148.3, bsz=64, num_updates=11520, lr=1.77627e-05, gnorm=4.557, clip=100, loss_scale=64, train_wall=40, gb_free=7.4, wall=46523
2023-05-08 12:52:02 - progress_bar.py[line:272] - INFO: epoch 014:    293 / 866 loss=2.229, loss_v1=0, loss_v2=0, nll_loss=1.007, ntokens=2141.2, nsentences=64, sample_size=2141.2, sample_size_v1=0, sample_size_v2=0, ppl=2.01, wps=531.5, ups=0.25, wpb=2141.2, bsz=64, num_updates=11530, lr=1.77504e-05, gnorm=4.778, clip=100, loss_scale=64, train_wall=40, gb_free=6.5, wall=46563
2023-05-08 12:52:43 - progress_bar.py[line:272] - INFO: epoch 014:    303 / 866 loss=2.229, loss_v1=0, loss_v2=0, nll_loss=1.012, ntokens=2142.7, nsentences=64, sample_size=2142.7, sample_size_v1=0, sample_size_v2=0, ppl=2.02, wps=531.8, ups=0.25, wpb=2142.7, bsz=64, num_updates=11540, lr=1.77381e-05, gnorm=4.762, clip=100, loss_scale=64, train_wall=40, gb_free=7.4, wall=46604
2023-05-08 12:53:23 - progress_bar.py[line:272] - INFO: epoch 014:    313 / 866 loss=2.239, loss_v1=0, loss_v2=0, nll_loss=1.019, ntokens=2106.8, nsentences=64, sample_size=2106.8, sample_size_v1=0, sample_size_v2=0, ppl=2.03, wps=525.7, ups=0.25, wpb=2106.8, bsz=64, num_updates=11550, lr=1.77258e-05, gnorm=4.709, clip=100, loss_scale=64, train_wall=40, gb_free=7.8, wall=46644
2023-05-08 12:54:03 - progress_bar.py[line:272] - INFO: epoch 014:    323 / 866 loss=2.26, loss_v1=0, loss_v2=0, nll_loss=1.044, ntokens=1985.8, nsentences=64, sample_size=1985.8, sample_size_v1=0, sample_size_v2=0, ppl=2.06, wps=497.2, ups=0.25, wpb=1985.8, bsz=64, num_updates=11560, lr=1.77135e-05, gnorm=5.019, clip=100, loss_scale=64, train_wall=40, gb_free=7.8, wall=46684
2023-05-08 12:54:43 - progress_bar.py[line:272] - INFO: epoch 014:    333 / 866 loss=2.238, loss_v1=0, loss_v2=0, nll_loss=1.021, ntokens=2134.8, nsentences=64, sample_size=2134.8, sample_size_v1=0, sample_size_v2=0, ppl=2.03, wps=533.2, ups=0.25, wpb=2134.8, bsz=64, num_updates=11570, lr=1.77013e-05, gnorm=4.574, clip=100, loss_scale=64, train_wall=40, gb_free=7.7, wall=46724
2023-05-08 12:55:23 - progress_bar.py[line:272] - INFO: epoch 014:    343 / 866 loss=2.228, loss_v1=0, loss_v2=0, nll_loss=1.009, ntokens=2000.4, nsentences=64, sample_size=2000.4, sample_size_v1=0, sample_size_v2=0, ppl=2.01, wps=498.4, ups=0.25, wpb=2000.4, bsz=64, num_updates=11580, lr=1.7689e-05, gnorm=4.659, clip=100, loss_scale=64, train_wall=40, gb_free=8.2, wall=46764
2023-05-08 12:56:03 - progress_bar.py[line:272] - INFO: epoch 014:    353 / 866 loss=2.274, loss_v1=0, loss_v2=0, nll_loss=1.061, ntokens=1984.7, nsentences=64, sample_size=1984.7, sample_size_v1=0, sample_size_v2=0, ppl=2.09, wps=498.2, ups=0.25, wpb=1984.7, bsz=64, num_updates=11590, lr=1.76767e-05, gnorm=5.264, clip=100, loss_scale=64, train_wall=40, gb_free=6.9, wall=46804
2023-05-08 12:56:43 - progress_bar.py[line:272] - INFO: epoch 014:    363 / 866 loss=2.268, loss_v1=0, loss_v2=0, nll_loss=1.054, ntokens=1971.5, nsentences=64, sample_size=1971.5, sample_size_v1=0, sample_size_v2=0, ppl=2.08, wps=493.4, ups=0.25, wpb=1971.5, bsz=64, num_updates=11600, lr=1.76644e-05, gnorm=5.092, clip=100, loss_scale=64, train_wall=40, gb_free=7.8, wall=46844
2023-05-08 12:57:23 - progress_bar.py[line:272] - INFO: epoch 014:    373 / 866 loss=2.235, loss_v1=0, loss_v2=0, nll_loss=1.015, ntokens=2020.9, nsentences=64, sample_size=2020.9, sample_size_v1=0, sample_size_v2=0, ppl=2.02, wps=504, ups=0.25, wpb=2020.9, bsz=64, num_updates=11610, lr=1.76521e-05, gnorm=5.156, clip=100, loss_scale=64, train_wall=40, gb_free=8.1, wall=46884
2023-05-08 12:58:03 - progress_bar.py[line:272] - INFO: epoch 014:    383 / 866 loss=2.231, loss_v1=0, loss_v2=0, nll_loss=1.013, ntokens=2159.1, nsentences=64, sample_size=2159.1, sample_size_v1=0, sample_size_v2=0, ppl=2.02, wps=539.9, ups=0.25, wpb=2159.1, bsz=64, num_updates=11620, lr=1.76398e-05, gnorm=4.63, clip=100, loss_scale=128, train_wall=40, gb_free=7.8, wall=46924
2023-05-08 12:58:19 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2023-05-08 12:58:47 - progress_bar.py[line:272] - INFO: epoch 014:    394 / 866 loss=2.255, loss_v1=0, loss_v2=0, nll_loss=1.041, ntokens=1983.8, nsentences=64, sample_size=1983.8, sample_size_v1=0, sample_size_v2=0, ppl=2.06, wps=449, ups=0.23, wpb=1983.8, bsz=64, num_updates=11630, lr=1.76275e-05, gnorm=5.604, clip=100, loss_scale=64, train_wall=44, gb_free=8.1, wall=46968
2023-05-08 12:59:27 - progress_bar.py[line:272] - INFO: epoch 014:    404 / 866 loss=2.239, loss_v1=0, loss_v2=0, nll_loss=1.02, ntokens=2131.8, nsentences=64, sample_size=2131.8, sample_size_v1=0, sample_size_v2=0, ppl=2.03, wps=528.8, ups=0.25, wpb=2131.8, bsz=64, num_updates=11640, lr=1.76153e-05, gnorm=4.423, clip=100, loss_scale=64, train_wall=40, gb_free=7.3, wall=47008
2023-05-08 13:00:07 - progress_bar.py[line:272] - INFO: epoch 014:    414 / 866 loss=2.235, loss_v1=0, loss_v2=0, nll_loss=1.019, ntokens=2133.5, nsentences=64, sample_size=2133.5, sample_size_v1=0, sample_size_v2=0, ppl=2.03, wps=530.8, ups=0.25, wpb=2133.5, bsz=64, num_updates=11650, lr=1.7603e-05, gnorm=4.967, clip=100, loss_scale=64, train_wall=40, gb_free=5.5, wall=47049
2023-05-08 13:00:48 - progress_bar.py[line:272] - INFO: epoch 014:    424 / 866 loss=2.217, loss_v1=0, loss_v2=0, nll_loss=0.995, ntokens=2063.4, nsentences=64, sample_size=2063.4, sample_size_v1=0, sample_size_v2=0, ppl=1.99, wps=514.1, ups=0.25, wpb=2063.4, bsz=64, num_updates=11660, lr=1.75907e-05, gnorm=4.473, clip=100, loss_scale=64, train_wall=40, gb_free=7.7, wall=47089
2023-05-08 13:01:28 - progress_bar.py[line:272] - INFO: epoch 014:    434 / 866 loss=2.238, loss_v1=0, loss_v2=0, nll_loss=1.021, ntokens=2107.9, nsentences=64, sample_size=2107.9, sample_size_v1=0, sample_size_v2=0, ppl=2.03, wps=525.5, ups=0.25, wpb=2107.9, bsz=64, num_updates=11670, lr=1.75784e-05, gnorm=4.595, clip=100, loss_scale=64, train_wall=40, gb_free=8.1, wall=47129
2023-05-08 13:02:08 - progress_bar.py[line:272] - INFO: epoch 014:    444 / 866 loss=2.278, loss_v1=0, loss_v2=0, nll_loss=1.061, ntokens=2030.8, nsentences=64, sample_size=2030.8, sample_size_v1=0, sample_size_v2=0, ppl=2.09, wps=503.1, ups=0.25, wpb=2030.8, bsz=64, num_updates=11680, lr=1.75661e-05, gnorm=4.8, clip=100, loss_scale=64, train_wall=40, gb_free=8.2, wall=47169
2023-05-08 13:02:48 - progress_bar.py[line:272] - INFO: epoch 014:    454 / 866 loss=2.253, loss_v1=0, loss_v2=0, nll_loss=1.039, ntokens=2015.3, nsentences=64, sample_size=2015.3, sample_size_v1=0, sample_size_v2=0, ppl=2.06, wps=504.3, ups=0.25, wpb=2015.3, bsz=64, num_updates=11690, lr=1.75538e-05, gnorm=5.103, clip=100, loss_scale=64, train_wall=40, gb_free=7.8, wall=47209
2023-05-08 13:03:28 - progress_bar.py[line:272] - INFO: epoch 014:    464 / 866 loss=2.249, loss_v1=0, loss_v2=0, nll_loss=1.032, ntokens=2171.2, nsentences=64, sample_size=2171.2, sample_size_v1=0, sample_size_v2=0, ppl=2.04, wps=538.5, ups=0.25, wpb=2171.2, bsz=64, num_updates=11700, lr=1.75416e-05, gnorm=4.771, clip=100, loss_scale=64, train_wall=40, gb_free=8, wall=47249
2023-05-08 13:04:09 - progress_bar.py[line:272] - INFO: epoch 014:    474 / 866 loss=2.254, loss_v1=0, loss_v2=0, nll_loss=1.036, ntokens=2208.2, nsentences=64, sample_size=2208.2, sample_size_v1=0, sample_size_v2=0, ppl=2.05, wps=546.6, ups=0.25, wpb=2208.2, bsz=64, num_updates=11710, lr=1.75293e-05, gnorm=4.86, clip=100, loss_scale=64, train_wall=40, gb_free=8.2, wall=47290
2023-05-08 13:04:49 - progress_bar.py[line:272] - INFO: epoch 014:    484 / 866 loss=2.237, loss_v1=0, loss_v2=0, nll_loss=1.02, ntokens=2144.3, nsentences=64, sample_size=2144.3, sample_size_v1=0, sample_size_v2=0, ppl=2.03, wps=532.9, ups=0.25, wpb=2144.3, bsz=64, num_updates=11720, lr=1.7517e-05, gnorm=4.774, clip=100, loss_scale=64, train_wall=40, gb_free=7.8, wall=47330
2023-05-08 13:05:29 - progress_bar.py[line:272] - INFO: epoch 014:    494 / 866 loss=2.224, loss_v1=0, loss_v2=0, nll_loss=1.005, ntokens=2045, nsentences=64, sample_size=2045, sample_size_v1=0, sample_size_v2=0, ppl=2.01, wps=509.1, ups=0.25, wpb=2045, bsz=64, num_updates=11730, lr=1.75047e-05, gnorm=4.667, clip=100, loss_scale=64, train_wall=40, gb_free=7.6, wall=47370
2023-05-08 13:06:09 - progress_bar.py[line:272] - INFO: epoch 014:    504 / 866 loss=2.251, loss_v1=0, loss_v2=0, nll_loss=1.035, ntokens=2073.9, nsentences=64, sample_size=2073.9, sample_size_v1=0, sample_size_v2=0, ppl=2.05, wps=518.3, ups=0.25, wpb=2073.9, bsz=64, num_updates=11740, lr=1.74924e-05, gnorm=5.141, clip=100, loss_scale=64, train_wall=40, gb_free=7.8, wall=47410
2023-05-08 13:06:49 - progress_bar.py[line:272] - INFO: epoch 014:    514 / 866 loss=2.262, loss_v1=0, loss_v2=0, nll_loss=1.047, ntokens=2170.7, nsentences=64, sample_size=2170.7, sample_size_v1=0, sample_size_v2=0, ppl=2.07, wps=544.9, ups=0.25, wpb=2170.7, bsz=64, num_updates=11750, lr=1.74801e-05, gnorm=4.368, clip=100, loss_scale=64, train_wall=40, gb_free=8.1, wall=47450
2023-05-08 13:07:29 - progress_bar.py[line:272] - INFO: epoch 014:    524 / 866 loss=2.233, loss_v1=0, loss_v2=0, nll_loss=1.013, ntokens=2105.4, nsentences=64, sample_size=2105.4, sample_size_v1=0, sample_size_v2=0, ppl=2.02, wps=525.6, ups=0.25, wpb=2105.4, bsz=64, num_updates=11760, lr=1.74679e-05, gnorm=5.078, clip=100, loss_scale=64, train_wall=40, gb_free=8, wall=47490
2023-05-08 13:08:09 - progress_bar.py[line:272] - INFO: epoch 014:    534 / 866 loss=2.228, loss_v1=0, loss_v2=0, nll_loss=1.009, ntokens=2042.8, nsentences=64, sample_size=2042.8, sample_size_v1=0, sample_size_v2=0, ppl=2.01, wps=510.5, ups=0.25, wpb=2042.8, bsz=64, num_updates=11770, lr=1.74556e-05, gnorm=4.884, clip=100, loss_scale=64, train_wall=40, gb_free=7.5, wall=47530
2023-05-08 13:08:49 - progress_bar.py[line:272] - INFO: epoch 014:    544 / 866 loss=2.26, loss_v1=0, loss_v2=0, nll_loss=1.044, ntokens=2184.6, nsentences=64, sample_size=2184.6, sample_size_v1=0, sample_size_v2=0, ppl=2.06, wps=545.7, ups=0.25, wpb=2184.6, bsz=64, num_updates=11780, lr=1.74433e-05, gnorm=4.541, clip=100, loss_scale=64, train_wall=40, gb_free=7.8, wall=47570
2023-05-08 13:09:30 - progress_bar.py[line:272] - INFO: epoch 014:    554 / 866 loss=2.255, loss_v1=0, loss_v2=0, nll_loss=1.04, ntokens=2311.7, nsentences=64, sample_size=2311.7, sample_size_v1=0, sample_size_v2=0, ppl=2.06, wps=570, ups=0.25, wpb=2311.7, bsz=64, num_updates=11790, lr=1.7431e-05, gnorm=4.343, clip=100, loss_scale=64, train_wall=41, gb_free=7.6, wall=47611
2023-05-08 13:10:10 - progress_bar.py[line:272] - INFO: epoch 014:    564 / 866 loss=2.244, loss_v1=0, loss_v2=0, nll_loss=1.026, ntokens=2250.1, nsentences=64, sample_size=2250.1, sample_size_v1=0, sample_size_v2=0, ppl=2.04, wps=559.1, ups=0.25, wpb=2250.1, bsz=64, num_updates=11800, lr=1.74187e-05, gnorm=4.918, clip=100, loss_scale=64, train_wall=40, gb_free=7.3, wall=47651
2023-05-08 13:10:50 - progress_bar.py[line:272] - INFO: epoch 014:    574 / 866 loss=2.247, loss_v1=0, loss_v2=0, nll_loss=1.03, ntokens=2186.6, nsentences=64, sample_size=2186.6, sample_size_v1=0, sample_size_v2=0, ppl=2.04, wps=544.1, ups=0.25, wpb=2186.6, bsz=64, num_updates=11810, lr=1.74064e-05, gnorm=4.526, clip=100, loss_scale=64, train_wall=40, gb_free=7.3, wall=47691
2023-05-08 13:11:31 - progress_bar.py[line:272] - INFO: epoch 014:    584 / 866 loss=2.255, loss_v1=0, loss_v2=0, nll_loss=1.039, ntokens=2097.5, nsentences=64, sample_size=2097.5, sample_size_v1=0, sample_size_v2=0, ppl=2.06, wps=519.2, ups=0.25, wpb=2097.5, bsz=64, num_updates=11820, lr=1.73942e-05, gnorm=5.055, clip=100, loss_scale=64, train_wall=40, gb_free=7, wall=47732
2023-05-08 13:12:11 - progress_bar.py[line:272] - INFO: epoch 014:    594 / 866 loss=2.228, loss_v1=0, loss_v2=0, nll_loss=1.009, ntokens=2123.3, nsentences=64, sample_size=2123.3, sample_size_v1=0, sample_size_v2=0, ppl=2.01, wps=523.8, ups=0.25, wpb=2123.3, bsz=64, num_updates=11830, lr=1.73819e-05, gnorm=5.057, clip=100, loss_scale=64, train_wall=40, gb_free=7.7, wall=47772
2023-05-08 13:12:51 - progress_bar.py[line:272] - INFO: epoch 014:    604 / 866 loss=2.228, loss_v1=0, loss_v2=0, nll_loss=1.011, ntokens=2066.5, nsentences=64, sample_size=2066.5, sample_size_v1=0, sample_size_v2=0, ppl=2.02, wps=514.1, ups=0.25, wpb=2066.5, bsz=64, num_updates=11840, lr=1.73696e-05, gnorm=4.872, clip=100, loss_scale=64, train_wall=40, gb_free=7.6, wall=47812
2023-05-08 13:13:31 - progress_bar.py[line:272] - INFO: epoch 014:    614 / 866 loss=2.264, loss_v1=0, loss_v2=0, nll_loss=1.048, ntokens=1920.8, nsentences=64, sample_size=1920.8, sample_size_v1=0, sample_size_v2=0, ppl=2.07, wps=479.7, ups=0.25, wpb=1920.8, bsz=64, num_updates=11850, lr=1.73573e-05, gnorm=5.501, clip=100, loss_scale=64, train_wall=40, gb_free=8, wall=47852
2023-05-08 13:14:11 - progress_bar.py[line:272] - INFO: epoch 014:    624 / 866 loss=2.25, loss_v1=0, loss_v2=0, nll_loss=1.031, ntokens=2039.6, nsentences=64, sample_size=2039.6, sample_size_v1=0, sample_size_v2=0, ppl=2.04, wps=509, ups=0.25, wpb=2039.6, bsz=64, num_updates=11860, lr=1.7345e-05, gnorm=4.933, clip=100, loss_scale=64, train_wall=40, gb_free=8.1, wall=47893
2023-05-08 13:14:51 - progress_bar.py[line:272] - INFO: epoch 014:    634 / 866 loss=2.237, loss_v1=0, loss_v2=0, nll_loss=1.02, ntokens=2012.5, nsentences=64, sample_size=2012.5, sample_size_v1=0, sample_size_v2=0, ppl=2.03, wps=505.2, ups=0.25, wpb=2012.5, bsz=64, num_updates=11870, lr=1.73327e-05, gnorm=5.147, clip=100, loss_scale=64, train_wall=40, gb_free=8.3, wall=47932
2023-05-08 13:15:31 - progress_bar.py[line:272] - INFO: epoch 014:    644 / 866 loss=2.232, loss_v1=0, loss_v2=0, nll_loss=1.012, ntokens=2085, nsentences=64, sample_size=2085, sample_size_v1=0, sample_size_v2=0, ppl=2.02, wps=522.7, ups=0.25, wpb=2085, bsz=64, num_updates=11880, lr=1.73204e-05, gnorm=5.319, clip=100, loss_scale=64, train_wall=40, gb_free=7.8, wall=47972
2023-05-08 13:16:11 - progress_bar.py[line:272] - INFO: epoch 014:    654 / 866 loss=2.248, loss_v1=0, loss_v2=0, nll_loss=1.033, ntokens=1951, nsentences=64, sample_size=1951, sample_size_v1=0, sample_size_v2=0, ppl=2.05, wps=490.1, ups=0.25, wpb=1951, bsz=64, num_updates=11890, lr=1.73082e-05, gnorm=4.926, clip=100, loss_scale=64, train_wall=40, gb_free=7.8, wall=48012
2023-05-08 13:16:51 - progress_bar.py[line:272] - INFO: epoch 014:    664 / 866 loss=2.261, loss_v1=0, loss_v2=0, nll_loss=1.047, ntokens=1940, nsentences=64, sample_size=1940, sample_size_v1=0, sample_size_v2=0, ppl=2.07, wps=487.6, ups=0.25, wpb=1940, bsz=64, num_updates=11900, lr=1.72959e-05, gnorm=5.437, clip=100, loss_scale=64, train_wall=40, gb_free=8.2, wall=48052
2023-05-08 13:17:31 - progress_bar.py[line:272] - INFO: epoch 014:    674 / 866 loss=2.243, loss_v1=0, loss_v2=0, nll_loss=1.023, ntokens=2070.8, nsentences=64, sample_size=2070.8, sample_size_v1=0, sample_size_v2=0, ppl=2.03, wps=516.6, ups=0.25, wpb=2070.8, bsz=64, num_updates=11910, lr=1.72836e-05, gnorm=5.058, clip=100, loss_scale=64, train_wall=40, gb_free=7.8, wall=48092
2023-05-08 13:18:11 - progress_bar.py[line:272] - INFO: epoch 014:    684 / 866 loss=2.231, loss_v1=0, loss_v2=0, nll_loss=1.014, ntokens=2040.2, nsentences=64, sample_size=2040.2, sample_size_v1=0, sample_size_v2=0, ppl=2.02, wps=512.4, ups=0.25, wpb=2040.2, bsz=64, num_updates=11920, lr=1.72713e-05, gnorm=4.791, clip=100, loss_scale=64, train_wall=40, gb_free=8.2, wall=48132
2023-05-08 13:18:51 - progress_bar.py[line:272] - INFO: epoch 014:    694 / 866 loss=2.25, loss_v1=0, loss_v2=0, nll_loss=1.034, ntokens=2072.2, nsentences=64, sample_size=2072.2, sample_size_v1=0, sample_size_v2=0, ppl=2.05, wps=515.6, ups=0.25, wpb=2072.2, bsz=64, num_updates=11930, lr=1.7259e-05, gnorm=5.3, clip=100, loss_scale=64, train_wall=40, gb_free=7.3, wall=48172
2023-05-08 13:19:31 - progress_bar.py[line:272] - INFO: epoch 014:    704 / 866 loss=2.245, loss_v1=0, loss_v2=0, nll_loss=1.027, ntokens=2017.9, nsentences=64, sample_size=2017.9, sample_size_v1=0, sample_size_v2=0, ppl=2.04, wps=504.4, ups=0.25, wpb=2017.9, bsz=64, num_updates=11940, lr=1.72467e-05, gnorm=4.953, clip=100, loss_scale=64, train_wall=40, gb_free=8.2, wall=48212
2023-05-08 13:20:11 - progress_bar.py[line:272] - INFO: epoch 014:    714 / 866 loss=2.263, loss_v1=0, loss_v2=0, nll_loss=1.048, ntokens=1871.5, nsentences=64, sample_size=1871.5, sample_size_v1=0, sample_size_v2=0, ppl=2.07, wps=470.7, ups=0.25, wpb=1871.5, bsz=64, num_updates=11950, lr=1.72345e-05, gnorm=5.693, clip=100, loss_scale=64, train_wall=40, gb_free=7.6, wall=48252
2023-05-08 13:20:51 - progress_bar.py[line:272] - INFO: epoch 014:    724 / 866 loss=2.221, loss_v1=0, loss_v2=0, nll_loss=1.001, ntokens=1998.5, nsentences=64, sample_size=1998.5, sample_size_v1=0, sample_size_v2=0, ppl=2, wps=498.3, ups=0.25, wpb=1998.5, bsz=64, num_updates=11960, lr=1.72222e-05, gnorm=4.981, clip=100, loss_scale=64, train_wall=40, gb_free=8.1, wall=48292
2023-05-08 13:21:31 - progress_bar.py[line:272] - INFO: epoch 014:    734 / 866 loss=2.219, loss_v1=0, loss_v2=0, nll_loss=0.999, ntokens=2017.8, nsentences=64, sample_size=2017.8, sample_size_v1=0, sample_size_v2=0, ppl=2, wps=502.6, ups=0.25, wpb=2017.8, bsz=64, num_updates=11970, lr=1.72099e-05, gnorm=5.283, clip=100, loss_scale=64, train_wall=40, gb_free=8, wall=48332
2023-05-08 13:22:11 - progress_bar.py[line:272] - INFO: epoch 014:    744 / 866 loss=2.214, loss_v1=0, loss_v2=0, nll_loss=0.991, ntokens=2152.2, nsentences=64, sample_size=2152.2, sample_size_v1=0, sample_size_v2=0, ppl=1.99, wps=535.5, ups=0.25, wpb=2152.2, bsz=64, num_updates=11980, lr=1.71976e-05, gnorm=4.949, clip=100, loss_scale=64, train_wall=40, gb_free=7.2, wall=48372
2023-05-08 13:22:51 - progress_bar.py[line:272] - INFO: epoch 014:    754 / 866 loss=2.215, loss_v1=0, loss_v2=0, nll_loss=0.995, ntokens=2102.9, nsentences=64, sample_size=2102.9, sample_size_v1=0, sample_size_v2=0, ppl=1.99, wps=524.2, ups=0.25, wpb=2102.9, bsz=64, num_updates=11990, lr=1.71853e-05, gnorm=5.054, clip=100, loss_scale=64, train_wall=40, gb_free=7.8, wall=48412
2023-05-08 13:23:31 - progress_bar.py[line:272] - INFO: epoch 014:    764 / 866 loss=2.227, loss_v1=0, loss_v2=0, nll_loss=1.01, ntokens=2112.8, nsentences=64, sample_size=2112.8, sample_size_v1=0, sample_size_v2=0, ppl=2.01, wps=524.8, ups=0.25, wpb=2112.8, bsz=64, num_updates=12000, lr=1.7173e-05, gnorm=5.148, clip=100, loss_scale=64, train_wall=40, gb_free=8.2, wall=48453
2023-05-08 13:24:11 - progress_bar.py[line:272] - INFO: epoch 014:    774 / 866 loss=2.222, loss_v1=0, loss_v2=0, nll_loss=1.002, ntokens=2150, nsentences=64, sample_size=2150, sample_size_v1=0, sample_size_v2=0, ppl=2, wps=539.8, ups=0.25, wpb=2150, bsz=64, num_updates=12010, lr=1.71608e-05, gnorm=5.18, clip=100, loss_scale=64, train_wall=40, gb_free=7.7, wall=48492
2023-05-08 13:24:52 - progress_bar.py[line:272] - INFO: epoch 014:    784 / 866 loss=2.22, loss_v1=0, loss_v2=0, nll_loss=0.999, ntokens=2176.4, nsentences=64, sample_size=2176.4, sample_size_v1=0, sample_size_v2=0, ppl=2, wps=540.6, ups=0.25, wpb=2176.4, bsz=64, num_updates=12020, lr=1.71485e-05, gnorm=4.918, clip=100, loss_scale=64, train_wall=40, gb_free=7.9, wall=48533
2023-05-08 13:25:31 - progress_bar.py[line:272] - INFO: epoch 014:    794 / 866 loss=2.255, loss_v1=0, loss_v2=0, nll_loss=1.041, ntokens=2016.9, nsentences=64, sample_size=2016.9, sample_size_v1=0, sample_size_v2=0, ppl=2.06, wps=506.9, ups=0.25, wpb=2016.9, bsz=64, num_updates=12030, lr=1.71362e-05, gnorm=5.7, clip=100, loss_scale=64, train_wall=40, gb_free=8, wall=48572
2023-05-08 13:26:11 - progress_bar.py[line:272] - INFO: epoch 014:    804 / 866 loss=2.231, loss_v1=0, loss_v2=0, nll_loss=1.011, ntokens=1963, nsentences=64, sample_size=1963, sample_size_v1=0, sample_size_v2=0, ppl=2.01, wps=494.6, ups=0.25, wpb=1963, bsz=64, num_updates=12040, lr=1.71239e-05, gnorm=5.072, clip=100, loss_scale=64, train_wall=40, gb_free=8, wall=48612
2023-05-08 13:26:51 - progress_bar.py[line:272] - INFO: epoch 014:    814 / 866 loss=2.212, loss_v1=0, loss_v2=0, nll_loss=0.99, ntokens=2102.1, nsentences=64, sample_size=2102.1, sample_size_v1=0, sample_size_v2=0, ppl=1.99, wps=524.2, ups=0.25, wpb=2102.1, bsz=64, num_updates=12050, lr=1.71116e-05, gnorm=5.074, clip=100, loss_scale=64, train_wall=40, gb_free=8.2, wall=48652
2023-05-08 13:27:31 - progress_bar.py[line:272] - INFO: epoch 014:    824 / 866 loss=2.215, loss_v1=0, loss_v2=0, nll_loss=0.996, ntokens=2124.1, nsentences=64, sample_size=2124.1, sample_size_v1=0, sample_size_v2=0, ppl=1.99, wps=526.7, ups=0.25, wpb=2124.1, bsz=64, num_updates=12060, lr=1.70993e-05, gnorm=4.738, clip=100, loss_scale=64, train_wall=40, gb_free=7.4, wall=48693
2023-05-08 13:28:12 - progress_bar.py[line:272] - INFO: epoch 014:    834 / 866 loss=2.211, loss_v1=0, loss_v2=0, nll_loss=0.989, ntokens=2173.1, nsentences=64, sample_size=2173.1, sample_size_v1=0, sample_size_v2=0, ppl=1.98, wps=535.1, ups=0.25, wpb=2173.1, bsz=64, num_updates=12070, lr=1.70871e-05, gnorm=4.492, clip=100, loss_scale=64, train_wall=41, gb_free=8.3, wall=48733
2023-05-08 13:28:52 - progress_bar.py[line:272] - INFO: epoch 014:    844 / 866 loss=2.228, loss_v1=0, loss_v2=0, nll_loss=1.009, ntokens=2148.3, nsentences=64, sample_size=2148.3, sample_size_v1=0, sample_size_v2=0, ppl=2.01, wps=534.6, ups=0.25, wpb=2148.3, bsz=64, num_updates=12080, lr=1.70748e-05, gnorm=4.833, clip=100, loss_scale=64, train_wall=40, gb_free=8.1, wall=48773
2023-05-08 13:29:33 - progress_bar.py[line:272] - INFO: epoch 014:    854 / 866 loss=2.205, loss_v1=0, loss_v2=0, nll_loss=0.984, ntokens=2153.4, nsentences=64, sample_size=2153.4, sample_size_v1=0, sample_size_v2=0, ppl=1.98, wps=534.5, ups=0.25, wpb=2153.4, bsz=64, num_updates=12090, lr=1.70625e-05, gnorm=4.595, clip=100, loss_scale=64, train_wall=40, gb_free=7.8, wall=48814
2023-05-08 13:30:13 - progress_bar.py[line:272] - INFO: epoch 014:    864 / 866 loss=2.251, loss_v1=0, loss_v2=0, nll_loss=1.035, ntokens=2070.8, nsentences=64, sample_size=2070.8, sample_size_v1=0, sample_size_v2=0, ppl=2.05, wps=517, ups=0.25, wpb=2070.8, bsz=64, num_updates=12100, lr=1.70502e-05, gnorm=5.13, clip=100, loss_scale=64, train_wall=40, gb_free=7.8, wall=48854
2023-05-08 13:30:19 - train.py[line:332] - INFO: end of epoch 14 (average epoch stats below)
local datafile ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 1 begin to initialize row_count and line_idx-to-offset mapping
2023-05-08 13:30:19 - progress_bar.py[line:282] - INFO: epoch 014 | loss 2.228 | loss_v1 0 | loss_v2 0 | nll_loss 1.009 | ntokens 2102.89 | nsentences 63.972 | sample_size 2102.89 | sample_size_v1 0 | sample_size_v2 0 | ppl 2.01 | wps 521.2 | ups 0.25 | wpb 2102.9 | bsz 64 | num_updates 12102 | lr 1.70477e-05 | gnorm 4.841 | clip 100 | loss_scale 64 | train_wall 3484 | gb_free 8.7 | wall 48860
2023-05-08 13:30:19 - trainer.py[line:639] - INFO: loading train data for epoch 15
local datafile ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 0 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 0 finished initializing row_count and line_idx-to-offset mapping
file ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 0 row count 27700 total row count 55400
slice_id 0 seek offset 0
2023-05-08 13:30:21 - trainer.py[line:703] - INFO: begin training epoch 15
2023-05-08 13:30:21 - train.py[line:305] - INFO: Start iterating over samples
local datafile ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 1 finished initializing row_count and line_idx-to-offset mapping
file ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 1 row count 27700 total row count 55400
slice_id 1 seek offset 27700
2023-05-08 13:30:54 - progress_bar.py[line:272] - INFO: epoch 015:      8 / 866 loss=2.188, loss_v1=0, loss_v2=0, nll_loss=0.962, ntokens=2070.9, nsentences=61.6, sample_size=2070.9, sample_size_v1=0, sample_size_v2=0, ppl=1.95, wps=502.3, ups=0.24, wpb=2070.9, bsz=61.6, num_updates=12110, lr=1.70379e-05, gnorm=4.578, clip=100, loss_scale=64, train_wall=39, gb_free=6.5, wall=48895
2023-05-08 13:31:34 - progress_bar.py[line:272] - INFO: epoch 015:     18 / 866 loss=2.171, loss_v1=0, loss_v2=0, nll_loss=0.948, ntokens=2050.4, nsentences=64, sample_size=2050.4, sample_size_v1=0, sample_size_v2=0, ppl=1.93, wps=505.7, ups=0.25, wpb=2050.4, bsz=64, num_updates=12120, lr=1.70256e-05, gnorm=4.922, clip=100, loss_scale=64, train_wall=40, gb_free=7.4, wall=48935
2023-05-08 13:32:15 - progress_bar.py[line:272] - INFO: epoch 015:     28 / 866 loss=2.195, loss_v1=0, loss_v2=0, nll_loss=0.971, ntokens=1965.3, nsentences=64, sample_size=1965.3, sample_size_v1=0, sample_size_v2=0, ppl=1.96, wps=488, ups=0.25, wpb=1965.3, bsz=64, num_updates=12130, lr=1.70133e-05, gnorm=5.26, clip=100, loss_scale=64, train_wall=40, gb_free=7.7, wall=48976
2023-05-08 13:32:56 - progress_bar.py[line:272] - INFO: epoch 015:     38 / 866 loss=2.116, loss_v1=0, loss_v2=0, nll_loss=0.884, ntokens=2219.2, nsentences=64, sample_size=2219.2, sample_size_v1=0, sample_size_v2=0, ppl=1.85, wps=543.1, ups=0.24, wpb=2219.2, bsz=64, num_updates=12140, lr=1.70011e-05, gnorm=4.437, clip=100, loss_scale=128, train_wall=41, gb_free=7.7, wall=49017
2023-05-08 13:33:12 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2023-05-08 13:33:40 - progress_bar.py[line:272] - INFO: epoch 015:     49 / 866 loss=2.156, loss_v1=0, loss_v2=0, nll_loss=0.929, ntokens=2083.7, nsentences=64, sample_size=2083.7, sample_size_v1=0, sample_size_v2=0, ppl=1.9, wps=467.9, ups=0.22, wpb=2083.7, bsz=64, num_updates=12150, lr=1.69888e-05, gnorm=4.86, clip=100, loss_scale=64, train_wall=44, gb_free=7, wall=49061
2023-05-08 13:34:20 - progress_bar.py[line:272] - INFO: epoch 015:     59 / 866 loss=2.095, loss_v1=0, loss_v2=0, nll_loss=0.861, ntokens=2024.1, nsentences=64, sample_size=2024.1, sample_size_v1=0, sample_size_v2=0, ppl=1.82, wps=505.6, ups=0.25, wpb=2024.1, bsz=64, num_updates=12160, lr=1.69765e-05, gnorm=5.148, clip=100, loss_scale=64, train_wall=40, gb_free=7.7, wall=49101
2023-05-08 13:35:02 - progress_bar.py[line:272] - INFO: epoch 015:     69 / 866 loss=2.072, loss_v1=0, loss_v2=0, nll_loss=0.834, ntokens=2467.6, nsentences=64, sample_size=2467.6, sample_size_v1=0, sample_size_v2=0, ppl=1.78, wps=586.9, ups=0.24, wpb=2467.6, bsz=64, num_updates=12170, lr=1.69642e-05, gnorm=3.962, clip=100, loss_scale=64, train_wall=42, gb_free=7.1, wall=49143
2023-05-08 13:35:44 - progress_bar.py[line:272] - INFO: epoch 015:     79 / 866 loss=2.13, loss_v1=0, loss_v2=0, nll_loss=0.899, ntokens=2322.4, nsentences=64, sample_size=2322.4, sample_size_v1=0, sample_size_v2=0, ppl=1.86, wps=560.4, ups=0.24, wpb=2322.4, bsz=64, num_updates=12180, lr=1.69519e-05, gnorm=4.422, clip=100, loss_scale=64, train_wall=41, gb_free=6.5, wall=49185
2023-05-08 13:36:24 - progress_bar.py[line:272] - INFO: epoch 015:     89 / 866 loss=2.174, loss_v1=0, loss_v2=0, nll_loss=0.95, ntokens=2129.6, nsentences=64, sample_size=2129.6, sample_size_v1=0, sample_size_v2=0, ppl=1.93, wps=521.9, ups=0.25, wpb=2129.6, bsz=64, num_updates=12190, lr=1.69396e-05, gnorm=4.944, clip=100, loss_scale=64, train_wall=41, gb_free=6.1, wall=49226
2023-05-08 13:37:05 - progress_bar.py[line:272] - INFO: epoch 015:     99 / 866 loss=2.15, loss_v1=0, loss_v2=0, nll_loss=0.923, ntokens=2114.8, nsentences=64, sample_size=2114.8, sample_size_v1=0, sample_size_v2=0, ppl=1.9, wps=523, ups=0.25, wpb=2114.8, bsz=64, num_updates=12200, lr=1.69274e-05, gnorm=4.958, clip=100, loss_scale=64, train_wall=40, gb_free=8.2, wall=49266
2023-05-08 13:37:45 - progress_bar.py[line:272] - INFO: epoch 015:    109 / 866 loss=2.217, loss_v1=0, loss_v2=0, nll_loss=0.995, ntokens=2026.2, nsentences=64, sample_size=2026.2, sample_size_v1=0, sample_size_v2=0, ppl=1.99, wps=505, ups=0.25, wpb=2026.2, bsz=64, num_updates=12210, lr=1.69151e-05, gnorm=5.072, clip=100, loss_scale=64, train_wall=40, gb_free=7.9, wall=49306
2023-05-08 13:38:26 - progress_bar.py[line:272] - INFO: epoch 015:    119 / 866 loss=2.217, loss_v1=0, loss_v2=0, nll_loss=0.997, ntokens=2135.1, nsentences=64, sample_size=2135.1, sample_size_v1=0, sample_size_v2=0, ppl=2, wps=522, ups=0.24, wpb=2135.1, bsz=64, num_updates=12220, lr=1.69028e-05, gnorm=4.737, clip=100, loss_scale=64, train_wall=41, gb_free=6.4, wall=49347
2023-05-08 13:39:07 - progress_bar.py[line:272] - INFO: epoch 015:    129 / 866 loss=2.21, loss_v1=0, loss_v2=0, nll_loss=0.987, ntokens=2211.4, nsentences=64, sample_size=2211.4, sample_size_v1=0, sample_size_v2=0, ppl=1.98, wps=538.9, ups=0.24, wpb=2211.4, bsz=64, num_updates=12230, lr=1.68905e-05, gnorm=4.654, clip=100, loss_scale=64, train_wall=41, gb_free=6.9, wall=49388
2023-05-08 13:39:48 - progress_bar.py[line:272] - INFO: epoch 015:    139 / 866 loss=2.176, loss_v1=0, loss_v2=0, nll_loss=0.952, ntokens=2236.8, nsentences=64, sample_size=2236.8, sample_size_v1=0, sample_size_v2=0, ppl=1.93, wps=542, ups=0.24, wpb=2236.8, bsz=64, num_updates=12240, lr=1.68782e-05, gnorm=4.584, clip=100, loss_scale=64, train_wall=41, gb_free=6.5, wall=49429
2023-05-08 13:40:30 - progress_bar.py[line:272] - INFO: epoch 015:    149 / 866 loss=2.165, loss_v1=0, loss_v2=0, nll_loss=0.938, ntokens=2172.4, nsentences=64, sample_size=2172.4, sample_size_v1=0, sample_size_v2=0, ppl=1.92, wps=525.3, ups=0.24, wpb=2172.4, bsz=64, num_updates=12250, lr=1.68659e-05, gnorm=4.36, clip=100, loss_scale=64, train_wall=41, gb_free=6.5, wall=49471
2023-05-08 13:41:11 - progress_bar.py[line:272] - INFO: epoch 015:    159 / 866 loss=2.195, loss_v1=0, loss_v2=0, nll_loss=0.973, ntokens=2229.6, nsentences=64, sample_size=2229.6, sample_size_v1=0, sample_size_v2=0, ppl=1.96, wps=541.3, ups=0.24, wpb=2229.6, bsz=64, num_updates=12260, lr=1.68537e-05, gnorm=4.647, clip=100, loss_scale=64, train_wall=41, gb_free=7.6, wall=49512
2023-05-08 13:41:51 - progress_bar.py[line:272] - INFO: epoch 015:    169 / 866 loss=2.191, loss_v1=0, loss_v2=0, nll_loss=0.967, ntokens=2095.1, nsentences=64, sample_size=2095.1, sample_size_v1=0, sample_size_v2=0, ppl=1.95, wps=518, ups=0.25, wpb=2095.1, bsz=64, num_updates=12270, lr=1.68414e-05, gnorm=4.577, clip=100, loss_scale=64, train_wall=40, gb_free=7.6, wall=49552
2023-05-08 13:42:32 - progress_bar.py[line:272] - INFO: epoch 015:    179 / 866 loss=2.185, loss_v1=0, loss_v2=0, nll_loss=0.961, ntokens=2124.2, nsentences=64, sample_size=2124.2, sample_size_v1=0, sample_size_v2=0, ppl=1.95, wps=520.7, ups=0.25, wpb=2124.2, bsz=64, num_updates=12280, lr=1.68291e-05, gnorm=4.87, clip=100, loss_scale=64, train_wall=41, gb_free=6.8, wall=49593
2023-05-08 13:43:13 - progress_bar.py[line:272] - INFO: epoch 015:    189 / 866 loss=2.183, loss_v1=0, loss_v2=0, nll_loss=0.958, ntokens=2185.3, nsentences=64, sample_size=2185.3, sample_size_v1=0, sample_size_v2=0, ppl=1.94, wps=534.6, ups=0.24, wpb=2185.3, bsz=64, num_updates=12290, lr=1.68168e-05, gnorm=4.816, clip=100, loss_scale=64, train_wall=41, gb_free=7.8, wall=49634
2023-05-08 13:43:54 - progress_bar.py[line:272] - INFO: epoch 015:    199 / 866 loss=2.196, loss_v1=0, loss_v2=0, nll_loss=0.974, ntokens=2178.1, nsentences=64, sample_size=2178.1, sample_size_v1=0, sample_size_v2=0, ppl=1.96, wps=533.2, ups=0.24, wpb=2178.1, bsz=64, num_updates=12300, lr=1.68045e-05, gnorm=4.677, clip=100, loss_scale=64, train_wall=41, gb_free=7.9, wall=49675
2023-05-08 13:44:34 - progress_bar.py[line:272] - INFO: epoch 015:    209 / 866 loss=2.225, loss_v1=0, loss_v2=0, nll_loss=1.006, ntokens=1953.8, nsentences=64, sample_size=1953.8, sample_size_v1=0, sample_size_v2=0, ppl=2.01, wps=486.8, ups=0.25, wpb=1953.8, bsz=64, num_updates=12310, lr=1.67922e-05, gnorm=4.99, clip=100, loss_scale=64, train_wall=40, gb_free=6.5, wall=49715
2023-05-08 13:45:14 - progress_bar.py[line:272] - INFO: epoch 015:    219 / 866 loss=2.23, loss_v1=0, loss_v2=0, nll_loss=1.011, ntokens=2210.3, nsentences=64, sample_size=2210.3, sample_size_v1=0, sample_size_v2=0, ppl=2.02, wps=549.1, ups=0.25, wpb=2210.3, bsz=64, num_updates=12320, lr=1.678e-05, gnorm=4.528, clip=100, loss_scale=64, train_wall=40, gb_free=7.6, wall=49755
2023-05-08 13:45:54 - progress_bar.py[line:272] - INFO: epoch 015:    229 / 866 loss=2.227, loss_v1=0, loss_v2=0, nll_loss=1.008, ntokens=2168.5, nsentences=64, sample_size=2168.5, sample_size_v1=0, sample_size_v2=0, ppl=2.01, wps=540.2, ups=0.25, wpb=2168.5, bsz=64, num_updates=12330, lr=1.67677e-05, gnorm=4.305, clip=100, loss_scale=64, train_wall=40, gb_free=8, wall=49795
2023-05-08 13:46:34 - progress_bar.py[line:272] - INFO: epoch 015:    239 / 866 loss=2.233, loss_v1=0, loss_v2=0, nll_loss=1.013, ntokens=2160.5, nsentences=64, sample_size=2160.5, sample_size_v1=0, sample_size_v2=0, ppl=2.02, wps=537.9, ups=0.25, wpb=2160.5, bsz=64, num_updates=12340, lr=1.67554e-05, gnorm=4.391, clip=100, loss_scale=64, train_wall=40, gb_free=7.1, wall=49836
2023-05-08 13:47:15 - progress_bar.py[line:272] - INFO: epoch 015:    249 / 866 loss=2.226, loss_v1=0, loss_v2=0, nll_loss=1.007, ntokens=2135.9, nsentences=64, sample_size=2135.9, sample_size_v1=0, sample_size_v2=0, ppl=2.01, wps=529.8, ups=0.25, wpb=2135.9, bsz=64, num_updates=12350, lr=1.67431e-05, gnorm=4.644, clip=100, loss_scale=64, train_wall=40, gb_free=7.5, wall=49876
2023-05-08 13:47:55 - progress_bar.py[line:272] - INFO: epoch 015:    259 / 866 loss=2.236, loss_v1=0, loss_v2=0, nll_loss=1.019, ntokens=2120, nsentences=64, sample_size=2120, sample_size_v1=0, sample_size_v2=0, ppl=2.03, wps=528.3, ups=0.25, wpb=2120, bsz=64, num_updates=12360, lr=1.67308e-05, gnorm=4.913, clip=100, loss_scale=64, train_wall=40, gb_free=7.4, wall=49916
2023-05-08 13:48:35 - progress_bar.py[line:272] - INFO: epoch 015:    269 / 866 loss=2.236, loss_v1=0, loss_v2=0, nll_loss=1.017, ntokens=2134.9, nsentences=64, sample_size=2134.9, sample_size_v1=0, sample_size_v2=0, ppl=2.02, wps=533.6, ups=0.25, wpb=2134.9, bsz=64, num_updates=12370, lr=1.67185e-05, gnorm=4.624, clip=100, loss_scale=64, train_wall=40, gb_free=7.3, wall=49956
2023-05-08 13:49:15 - progress_bar.py[line:272] - INFO: epoch 015:    279 / 866 loss=2.219, loss_v1=0, loss_v2=0, nll_loss=1.001, ntokens=2176.7, nsentences=64, sample_size=2176.7, sample_size_v1=0, sample_size_v2=0, ppl=2, wps=540.5, ups=0.25, wpb=2176.7, bsz=64, num_updates=12380, lr=1.67062e-05, gnorm=4.456, clip=100, loss_scale=64, train_wall=40, gb_free=7, wall=49996
2023-05-08 13:49:56 - progress_bar.py[line:272] - INFO: epoch 015:    289 / 866 loss=2.212, loss_v1=0, loss_v2=0, nll_loss=0.99, ntokens=2182.2, nsentences=64, sample_size=2182.2, sample_size_v1=0, sample_size_v2=0, ppl=1.99, wps=538.9, ups=0.25, wpb=2182.2, bsz=64, num_updates=12390, lr=1.6694e-05, gnorm=4.678, clip=100, loss_scale=64, train_wall=40, gb_free=8.3, wall=50037
2023-05-08 13:50:36 - progress_bar.py[line:272] - INFO: epoch 015:    299 / 866 loss=2.211, loss_v1=0, loss_v2=0, nll_loss=0.99, ntokens=2111.5, nsentences=64, sample_size=2111.5, sample_size_v1=0, sample_size_v2=0, ppl=1.99, wps=527.7, ups=0.25, wpb=2111.5, bsz=64, num_updates=12400, lr=1.66817e-05, gnorm=4.694, clip=100, loss_scale=64, train_wall=40, gb_free=7.4, wall=50077
2023-05-08 13:51:16 - progress_bar.py[line:272] - INFO: epoch 015:    309 / 866 loss=2.216, loss_v1=0, loss_v2=0, nll_loss=0.997, ntokens=2156.3, nsentences=64, sample_size=2156.3, sample_size_v1=0, sample_size_v2=0, ppl=2, wps=538.2, ups=0.25, wpb=2156.3, bsz=64, num_updates=12410, lr=1.66694e-05, gnorm=4.886, clip=100, loss_scale=64, train_wall=40, gb_free=7.6, wall=50117
2023-05-08 13:51:56 - progress_bar.py[line:272] - INFO: epoch 015:    319 / 866 loss=2.224, loss_v1=0, loss_v2=0, nll_loss=1.003, ntokens=1965.2, nsentences=64, sample_size=1965.2, sample_size_v1=0, sample_size_v2=0, ppl=2, wps=492.4, ups=0.25, wpb=1965.2, bsz=64, num_updates=12420, lr=1.66571e-05, gnorm=5.146, clip=100, loss_scale=64, train_wall=40, gb_free=8.1, wall=50157
2023-05-08 13:52:36 - progress_bar.py[line:272] - INFO: epoch 015:    329 / 866 loss=2.237, loss_v1=0, loss_v2=0, nll_loss=1.019, ntokens=2086.5, nsentences=64, sample_size=2086.5, sample_size_v1=0, sample_size_v2=0, ppl=2.03, wps=522.8, ups=0.25, wpb=2086.5, bsz=64, num_updates=12430, lr=1.66448e-05, gnorm=4.62, clip=100, loss_scale=64, train_wall=40, gb_free=7.6, wall=50197
2023-05-08 13:53:16 - progress_bar.py[line:272] - INFO: epoch 015:    339 / 866 loss=2.199, loss_v1=0, loss_v2=0, nll_loss=0.976, ntokens=2091.7, nsentences=64, sample_size=2091.7, sample_size_v1=0, sample_size_v2=0, ppl=1.97, wps=520.1, ups=0.25, wpb=2091.7, bsz=64, num_updates=12440, lr=1.66325e-05, gnorm=4.453, clip=100, loss_scale=64, train_wall=40, gb_free=8, wall=50237
2023-05-08 13:53:56 - progress_bar.py[line:272] - INFO: epoch 015:    349 / 866 loss=2.228, loss_v1=0, loss_v2=0, nll_loss=1.01, ntokens=1919.4, nsentences=64, sample_size=1919.4, sample_size_v1=0, sample_size_v2=0, ppl=2.01, wps=482.6, ups=0.25, wpb=1919.4, bsz=64, num_updates=12450, lr=1.66203e-05, gnorm=5.031, clip=100, loss_scale=64, train_wall=40, gb_free=7.9, wall=50277
2023-05-08 13:54:35 - progress_bar.py[line:272] - INFO: epoch 015:    359 / 866 loss=2.246, loss_v1=0, loss_v2=0, nll_loss=1.03, ntokens=1989.5, nsentences=64, sample_size=1989.5, sample_size_v1=0, sample_size_v2=0, ppl=2.04, wps=499.9, ups=0.25, wpb=1989.5, bsz=64, num_updates=12460, lr=1.6608e-05, gnorm=5.121, clip=100, loss_scale=64, train_wall=40, gb_free=7.7, wall=50316
2023-05-08 13:55:15 - progress_bar.py[line:272] - INFO: epoch 015:    369 / 866 loss=2.233, loss_v1=0, loss_v2=0, nll_loss=1.014, ntokens=1991.8, nsentences=64, sample_size=1991.8, sample_size_v1=0, sample_size_v2=0, ppl=2.02, wps=499.7, ups=0.25, wpb=1991.8, bsz=64, num_updates=12470, lr=1.65957e-05, gnorm=5.08, clip=100, loss_scale=64, train_wall=40, gb_free=8, wall=50356
2023-05-08 13:55:55 - progress_bar.py[line:272] - INFO: epoch 015:    379 / 866 loss=2.211, loss_v1=0, loss_v2=0, nll_loss=0.99, ntokens=2163.2, nsentences=64, sample_size=2163.2, sample_size_v1=0, sample_size_v2=0, ppl=1.99, wps=539.9, ups=0.25, wpb=2163.2, bsz=64, num_updates=12480, lr=1.65834e-05, gnorm=4.567, clip=100, loss_scale=64, train_wall=40, gb_free=7.3, wall=50396
2023-05-08 13:56:35 - progress_bar.py[line:272] - INFO: epoch 015:    389 / 866 loss=2.218, loss_v1=0, loss_v2=0, nll_loss=0.998, ntokens=2094.7, nsentences=64, sample_size=2094.7, sample_size_v1=0, sample_size_v2=0, ppl=2, wps=524.6, ups=0.25, wpb=2094.7, bsz=64, num_updates=12490, lr=1.65711e-05, gnorm=4.989, clip=100, loss_scale=64, train_wall=40, gb_free=8, wall=50436
2023-05-08 13:57:15 - progress_bar.py[line:272] - INFO: epoch 015:    399 / 866 loss=2.233, loss_v1=0, loss_v2=0, nll_loss=1.015, ntokens=2065.6, nsentences=64, sample_size=2065.6, sample_size_v1=0, sample_size_v2=0, ppl=2.02, wps=515.9, ups=0.25, wpb=2065.6, bsz=64, num_updates=12500, lr=1.65588e-05, gnorm=5.246, clip=100, loss_scale=64, train_wall=40, gb_free=8, wall=50476
2023-05-08 13:57:55 - progress_bar.py[line:272] - INFO: epoch 015:    409 / 866 loss=2.218, loss_v1=0, loss_v2=0, nll_loss=0.997, ntokens=2097.8, nsentences=64, sample_size=2097.8, sample_size_v1=0, sample_size_v2=0, ppl=2, wps=524.4, ups=0.25, wpb=2097.8, bsz=64, num_updates=12510, lr=1.65466e-05, gnorm=4.73, clip=100, loss_scale=64, train_wall=40, gb_free=7.9, wall=50516
2023-05-08 13:58:35 - progress_bar.py[line:272] - INFO: epoch 015:    419 / 866 loss=2.208, loss_v1=0, loss_v2=0, nll_loss=0.988, ntokens=2079.6, nsentences=64, sample_size=2079.6, sample_size_v1=0, sample_size_v2=0, ppl=1.98, wps=519.8, ups=0.25, wpb=2079.6, bsz=64, num_updates=12520, lr=1.65343e-05, gnorm=4.747, clip=100, loss_scale=64, train_wall=40, gb_free=7.5, wall=50556
2023-05-08 13:59:16 - progress_bar.py[line:272] - INFO: epoch 015:    429 / 866 loss=2.19, loss_v1=0, loss_v2=0, nll_loss=0.965, ntokens=2113.6, nsentences=64, sample_size=2113.6, sample_size_v1=0, sample_size_v2=0, ppl=1.95, wps=525.3, ups=0.25, wpb=2113.6, bsz=64, num_updates=12530, lr=1.6522e-05, gnorm=4.685, clip=100, loss_scale=64, train_wall=40, gb_free=8, wall=50597
2023-05-08 13:59:56 - progress_bar.py[line:272] - INFO: epoch 015:    439 / 866 loss=2.238, loss_v1=0, loss_v2=0, nll_loss=1.02, ntokens=2126.8, nsentences=64, sample_size=2126.8, sample_size_v1=0, sample_size_v2=0, ppl=2.03, wps=529.2, ups=0.25, wpb=2126.8, bsz=64, num_updates=12540, lr=1.65097e-05, gnorm=5.061, clip=100, loss_scale=64, train_wall=40, gb_free=6.7, wall=50637
2023-05-08 14:00:36 - progress_bar.py[line:272] - INFO: epoch 015:    449 / 866 loss=2.246, loss_v1=0, loss_v2=0, nll_loss=1.028, ntokens=1954.9, nsentences=64, sample_size=1954.9, sample_size_v1=0, sample_size_v2=0, ppl=2.04, wps=488.6, ups=0.25, wpb=1954.9, bsz=64, num_updates=12550, lr=1.64974e-05, gnorm=5.193, clip=100, loss_scale=64, train_wall=40, gb_free=7.6, wall=50677
2023-05-08 14:01:16 - progress_bar.py[line:272] - INFO: epoch 015:    459 / 866 loss=2.224, loss_v1=0, loss_v2=0, nll_loss=1.007, ntokens=2137.8, nsentences=64, sample_size=2137.8, sample_size_v1=0, sample_size_v2=0, ppl=2.01, wps=528.4, ups=0.25, wpb=2137.8, bsz=64, num_updates=12560, lr=1.64851e-05, gnorm=4.76, clip=100, loss_scale=64, train_wall=40, gb_free=7.9, wall=50717
2023-05-08 14:01:57 - progress_bar.py[line:272] - INFO: epoch 015:    469 / 866 loss=2.229, loss_v1=0, loss_v2=0, nll_loss=1.009, ntokens=2137.7, nsentences=64, sample_size=2137.7, sample_size_v1=0, sample_size_v2=0, ppl=2.01, wps=528.8, ups=0.25, wpb=2137.7, bsz=64, num_updates=12570, lr=1.64729e-05, gnorm=4.898, clip=100, loss_scale=64, train_wall=40, gb_free=6.9, wall=50758
2023-05-08 14:02:37 - progress_bar.py[line:272] - INFO: epoch 015:    479 / 866 loss=2.23, loss_v1=0, loss_v2=0, nll_loss=1.01, ntokens=2235.1, nsentences=64, sample_size=2235.1, sample_size_v1=0, sample_size_v2=0, ppl=2.01, wps=550.8, ups=0.25, wpb=2235.1, bsz=64, num_updates=12580, lr=1.64606e-05, gnorm=4.544, clip=100, loss_scale=64, train_wall=41, gb_free=7.9, wall=50798
2023-05-08 14:03:17 - progress_bar.py[line:272] - INFO: epoch 015:    489 / 866 loss=2.202, loss_v1=0, loss_v2=0, nll_loss=0.981, ntokens=2035.1, nsentences=64, sample_size=2035.1, sample_size_v1=0, sample_size_v2=0, ppl=1.97, wps=507.1, ups=0.25, wpb=2035.1, bsz=64, num_updates=12590, lr=1.64483e-05, gnorm=4.683, clip=100, loss_scale=64, train_wall=40, gb_free=8, wall=50838
2023-05-08 14:03:57 - progress_bar.py[line:272] - INFO: epoch 015:    499 / 866 loss=2.204, loss_v1=0, loss_v2=0, nll_loss=0.982, ntokens=2054, nsentences=64, sample_size=2054, sample_size_v1=0, sample_size_v2=0, ppl=1.98, wps=512.7, ups=0.25, wpb=2054, bsz=64, num_updates=12600, lr=1.6436e-05, gnorm=4.733, clip=100, loss_scale=64, train_wall=40, gb_free=7.6, wall=50879
2023-05-08 14:04:37 - progress_bar.py[line:272] - INFO: epoch 015:    509 / 866 loss=2.24, loss_v1=0, loss_v2=0, nll_loss=1.022, ntokens=2115, nsentences=64, sample_size=2115, sample_size_v1=0, sample_size_v2=0, ppl=2.03, wps=528.2, ups=0.25, wpb=2115, bsz=64, num_updates=12610, lr=1.64237e-05, gnorm=4.922, clip=100, loss_scale=64, train_wall=40, gb_free=8, wall=50919
2023-05-08 14:05:17 - progress_bar.py[line:272] - INFO: epoch 015:    519 / 866 loss=2.223, loss_v1=0, loss_v2=0, nll_loss=1.002, ntokens=2183.2, nsentences=64, sample_size=2183.2, sample_size_v1=0, sample_size_v2=0, ppl=2, wps=546.5, ups=0.25, wpb=2183.2, bsz=64, num_updates=12620, lr=1.64114e-05, gnorm=4.623, clip=100, loss_scale=64, train_wall=40, gb_free=8.3, wall=50959
2023-05-08 14:05:57 - progress_bar.py[line:272] - INFO: epoch 015:    529 / 866 loss=2.221, loss_v1=0, loss_v2=0, nll_loss=1.001, ntokens=1999.1, nsentences=64, sample_size=1999.1, sample_size_v1=0, sample_size_v2=0, ppl=2, wps=501.9, ups=0.25, wpb=1999.1, bsz=64, num_updates=12630, lr=1.63991e-05, gnorm=4.917, clip=100, loss_scale=64, train_wall=40, gb_free=7.9, wall=50998
2023-05-08 14:06:37 - progress_bar.py[line:272] - INFO: epoch 015:    539 / 866 loss=2.215, loss_v1=0, loss_v2=0, nll_loss=0.993, ntokens=2154.9, nsentences=64, sample_size=2154.9, sample_size_v1=0, sample_size_v2=0, ppl=1.99, wps=537.5, ups=0.25, wpb=2154.9, bsz=64, num_updates=12640, lr=1.63869e-05, gnorm=4.664, clip=100, loss_scale=64, train_wall=40, gb_free=7.8, wall=51038
2023-05-08 14:07:18 - progress_bar.py[line:272] - INFO: epoch 015:    549 / 866 loss=2.243, loss_v1=0, loss_v2=0, nll_loss=1.026, ntokens=2316.9, nsentences=64, sample_size=2316.9, sample_size_v1=0, sample_size_v2=0, ppl=2.04, wps=574.1, ups=0.25, wpb=2316.9, bsz=64, num_updates=12650, lr=1.63746e-05, gnorm=4.487, clip=100, loss_scale=64, train_wall=40, gb_free=7.9, wall=51079
2023-05-08 14:07:42 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2023-05-08 14:08:02 - progress_bar.py[line:272] - INFO: epoch 015:    560 / 866 loss=2.217, loss_v1=0, loss_v2=0, nll_loss=0.998, ntokens=2230.6, nsentences=64, sample_size=2230.6, sample_size_v1=0, sample_size_v2=0, ppl=2, wps=504.3, ups=0.23, wpb=2230.6, bsz=64, num_updates=12660, lr=1.63623e-05, gnorm=4.606, clip=100, loss_scale=64, train_wall=44, gb_free=8.2, wall=51123
2023-05-08 14:08:42 - progress_bar.py[line:272] - INFO: epoch 015:    570 / 866 loss=2.229, loss_v1=0, loss_v2=0, nll_loss=1.009, ntokens=2250.3, nsentences=64, sample_size=2250.3, sample_size_v1=0, sample_size_v2=0, ppl=2.01, wps=558.2, ups=0.25, wpb=2250.3, bsz=64, num_updates=12670, lr=1.635e-05, gnorm=4.618, clip=100, loss_scale=64, train_wall=40, gb_free=7.6, wall=51163
2023-05-08 14:09:23 - progress_bar.py[line:272] - INFO: epoch 015:    580 / 866 loss=2.228, loss_v1=0, loss_v2=0, nll_loss=1.009, ntokens=2106.6, nsentences=64, sample_size=2106.6, sample_size_v1=0, sample_size_v2=0, ppl=2.01, wps=523.3, ups=0.25, wpb=2106.6, bsz=64, num_updates=12680, lr=1.63377e-05, gnorm=4.963, clip=100, loss_scale=64, train_wall=40, gb_free=7.4, wall=51204
2023-05-08 14:10:03 - progress_bar.py[line:272] - INFO: epoch 015:    590 / 866 loss=2.24, loss_v1=0, loss_v2=0, nll_loss=1.021, ntokens=2037.9, nsentences=64, sample_size=2037.9, sample_size_v1=0, sample_size_v2=0, ppl=2.03, wps=506.4, ups=0.25, wpb=2037.9, bsz=64, num_updates=12690, lr=1.63254e-05, gnorm=5.276, clip=100, loss_scale=64, train_wall=40, gb_free=8.5, wall=51244
2023-05-08 14:10:43 - progress_bar.py[line:272] - INFO: epoch 015:    600 / 866 loss=2.189, loss_v1=0, loss_v2=0, nll_loss=0.967, ntokens=2132.3, nsentences=64, sample_size=2132.3, sample_size_v1=0, sample_size_v2=0, ppl=1.95, wps=529.6, ups=0.25, wpb=2132.3, bsz=64, num_updates=12700, lr=1.63132e-05, gnorm=4.7, clip=100, loss_scale=64, train_wall=40, gb_free=7.6, wall=51284
2023-05-08 14:11:23 - progress_bar.py[line:272] - INFO: epoch 015:    610 / 866 loss=2.229, loss_v1=0, loss_v2=0, nll_loss=1.011, ntokens=2005.6, nsentences=64, sample_size=2005.6, sample_size_v1=0, sample_size_v2=0, ppl=2.01, wps=498.9, ups=0.25, wpb=2005.6, bsz=64, num_updates=12710, lr=1.63009e-05, gnorm=5.211, clip=100, loss_scale=64, train_wall=40, gb_free=8.2, wall=51324
2023-05-08 14:12:03 - progress_bar.py[line:272] - INFO: epoch 015:    620 / 866 loss=2.244, loss_v1=0, loss_v2=0, nll_loss=1.026, ntokens=1964.6, nsentences=64, sample_size=1964.6, sample_size_v1=0, sample_size_v2=0, ppl=2.04, wps=489.3, ups=0.25, wpb=1964.6, bsz=64, num_updates=12720, lr=1.62886e-05, gnorm=5.306, clip=100, loss_scale=64, train_wall=40, gb_free=8.3, wall=51365
2023-05-08 14:12:44 - progress_bar.py[line:272] - INFO: epoch 015:    630 / 866 loss=2.221, loss_v1=0, loss_v2=0, nll_loss=1, ntokens=2054.6, nsentences=64, sample_size=2054.6, sample_size_v1=0, sample_size_v2=0, ppl=2, wps=512.5, ups=0.25, wpb=2054.6, bsz=64, num_updates=12730, lr=1.62763e-05, gnorm=4.647, clip=100, loss_scale=64, train_wall=40, gb_free=7.7, wall=51405
2023-05-08 14:13:24 - progress_bar.py[line:272] - INFO: epoch 015:    640 / 866 loss=2.213, loss_v1=0, loss_v2=0, nll_loss=0.992, ntokens=2049.7, nsentences=64, sample_size=2049.7, sample_size_v1=0, sample_size_v2=0, ppl=1.99, wps=511.5, ups=0.25, wpb=2049.7, bsz=64, num_updates=12740, lr=1.6264e-05, gnorm=5.1, clip=100, loss_scale=64, train_wall=40, gb_free=7.3, wall=51445
2023-05-08 14:14:03 - progress_bar.py[line:272] - INFO: epoch 015:    650 / 866 loss=2.219, loss_v1=0, loss_v2=0, nll_loss=0.999, ntokens=2026.3, nsentences=64, sample_size=2026.3, sample_size_v1=0, sample_size_v2=0, ppl=2, wps=509.8, ups=0.25, wpb=2026.3, bsz=64, num_updates=12750, lr=1.62517e-05, gnorm=4.862, clip=100, loss_scale=64, train_wall=40, gb_free=7.5, wall=51484
2023-05-08 14:14:43 - progress_bar.py[line:272] - INFO: epoch 015:    660 / 866 loss=2.242, loss_v1=0, loss_v2=0, nll_loss=1.026, ntokens=1918, nsentences=64, sample_size=1918, sample_size_v1=0, sample_size_v2=0, ppl=2.04, wps=481.7, ups=0.25, wpb=1918, bsz=64, num_updates=12760, lr=1.62395e-05, gnorm=5.458, clip=100, loss_scale=64, train_wall=40, gb_free=8.3, wall=51524
2023-05-08 14:15:23 - progress_bar.py[line:272] - INFO: epoch 015:    670 / 866 loss=2.228, loss_v1=0, loss_v2=0, nll_loss=1.008, ntokens=1996.5, nsentences=64, sample_size=1996.5, sample_size_v1=0, sample_size_v2=0, ppl=2.01, wps=495.8, ups=0.25, wpb=1996.5, bsz=64, num_updates=12770, lr=1.62272e-05, gnorm=5.134, clip=100, loss_scale=64, train_wall=40, gb_free=7.8, wall=51565
2023-05-08 14:16:03 - progress_bar.py[line:272] - INFO: epoch 015:    680 / 866 loss=2.209, loss_v1=0, loss_v2=0, nll_loss=0.987, ntokens=2076.1, nsentences=64, sample_size=2076.1, sample_size_v1=0, sample_size_v2=0, ppl=1.98, wps=519, ups=0.25, wpb=2076.1, bsz=64, num_updates=12780, lr=1.62149e-05, gnorm=4.853, clip=100, loss_scale=64, train_wall=40, gb_free=7.5, wall=51605
2023-05-08 14:16:43 - progress_bar.py[line:272] - INFO: epoch 015:    690 / 866 loss=2.215, loss_v1=0, loss_v2=0, nll_loss=0.997, ntokens=2026.9, nsentences=64, sample_size=2026.9, sample_size_v1=0, sample_size_v2=0, ppl=2, wps=507.5, ups=0.25, wpb=2026.9, bsz=64, num_updates=12790, lr=1.62026e-05, gnorm=5.007, clip=100, loss_scale=64, train_wall=40, gb_free=6.8, wall=51644
2023-05-08 14:17:23 - progress_bar.py[line:272] - INFO: epoch 015:    700 / 866 loss=2.231, loss_v1=0, loss_v2=0, nll_loss=1.011, ntokens=2087, nsentences=64, sample_size=2087, sample_size_v1=0, sample_size_v2=0, ppl=2.01, wps=522, ups=0.25, wpb=2087, bsz=64, num_updates=12800, lr=1.61903e-05, gnorm=5.001, clip=100, loss_scale=64, train_wall=40, gb_free=8, wall=51684
2023-05-08 14:18:03 - progress_bar.py[line:272] - INFO: epoch 015:    710 / 866 loss=2.231, loss_v1=0, loss_v2=0, nll_loss=1.012, ntokens=1923.4, nsentences=64, sample_size=1923.4, sample_size_v1=0, sample_size_v2=0, ppl=2.02, wps=479.5, ups=0.25, wpb=1923.4, bsz=64, num_updates=12810, lr=1.6178e-05, gnorm=5.241, clip=100, loss_scale=64, train_wall=40, gb_free=7.6, wall=51725
2023-05-08 14:18:44 - progress_bar.py[line:272] - INFO: epoch 015:    720 / 866 loss=2.225, loss_v1=0, loss_v2=0, nll_loss=1.007, ntokens=1913.9, nsentences=64, sample_size=1913.9, sample_size_v1=0, sample_size_v2=0, ppl=2.01, wps=476.2, ups=0.25, wpb=1913.9, bsz=64, num_updates=12820, lr=1.61658e-05, gnorm=5.055, clip=100, loss_scale=64, train_wall=40, gb_free=7.2, wall=51765
2023-05-08 14:19:23 - progress_bar.py[line:272] - INFO: epoch 015:    730 / 866 loss=2.19, loss_v1=0, loss_v2=0, nll_loss=0.966, ntokens=2011.1, nsentences=64, sample_size=2011.1, sample_size_v1=0, sample_size_v2=0, ppl=1.95, wps=504.9, ups=0.25, wpb=2011.1, bsz=64, num_updates=12830, lr=1.61535e-05, gnorm=4.938, clip=100, loss_scale=64, train_wall=40, gb_free=8.2, wall=51805
2023-05-08 14:20:04 - progress_bar.py[line:272] - INFO: epoch 015:    740 / 866 loss=2.214, loss_v1=0, loss_v2=0, nll_loss=0.992, ntokens=2124.3, nsentences=64, sample_size=2124.3, sample_size_v1=0, sample_size_v2=0, ppl=1.99, wps=528.7, ups=0.25, wpb=2124.3, bsz=64, num_updates=12840, lr=1.61412e-05, gnorm=5.031, clip=100, loss_scale=64, train_wall=40, gb_free=7.7, wall=51845
2023-05-08 14:20:44 - progress_bar.py[line:272] - INFO: epoch 015:    750 / 866 loss=2.186, loss_v1=0, loss_v2=0, nll_loss=0.962, ntokens=2131.9, nsentences=64, sample_size=2131.9, sample_size_v1=0, sample_size_v2=0, ppl=1.95, wps=529.9, ups=0.25, wpb=2131.9, bsz=64, num_updates=12850, lr=1.61289e-05, gnorm=4.909, clip=100, loss_scale=64, train_wall=40, gb_free=8, wall=51885
2023-05-08 14:21:24 - progress_bar.py[line:272] - INFO: epoch 015:    760 / 866 loss=2.206, loss_v1=0, loss_v2=0, nll_loss=0.985, ntokens=2080.6, nsentences=64, sample_size=2080.6, sample_size_v1=0, sample_size_v2=0, ppl=1.98, wps=518, ups=0.25, wpb=2080.6, bsz=64, num_updates=12860, lr=1.61166e-05, gnorm=5.152, clip=100, loss_scale=64, train_wall=40, gb_free=7.6, wall=51925
2023-05-08 14:22:04 - progress_bar.py[line:272] - INFO: epoch 015:    770 / 866 loss=2.197, loss_v1=0, loss_v2=0, nll_loss=0.975, ntokens=2072.8, nsentences=64, sample_size=2072.8, sample_size_v1=0, sample_size_v2=0, ppl=1.97, wps=516.8, ups=0.25, wpb=2072.8, bsz=64, num_updates=12870, lr=1.61043e-05, gnorm=5.072, clip=100, loss_scale=64, train_wall=40, gb_free=8.3, wall=51965
2023-05-08 14:22:45 - progress_bar.py[line:272] - INFO: epoch 015:    780 / 866 loss=2.206, loss_v1=0, loss_v2=0, nll_loss=0.983, ntokens=2340.3, nsentences=64, sample_size=2340.3, sample_size_v1=0, sample_size_v2=0, ppl=1.98, wps=577.8, ups=0.25, wpb=2340.3, bsz=64, num_updates=12880, lr=1.6092e-05, gnorm=5.023, clip=100, loss_scale=64, train_wall=40, gb_free=7.7, wall=52006
2023-05-08 14:23:24 - progress_bar.py[line:272] - INFO: epoch 015:    790 / 866 loss=2.226, loss_v1=0, loss_v2=0, nll_loss=1.005, ntokens=1961, nsentences=64, sample_size=1961, sample_size_v1=0, sample_size_v2=0, ppl=2.01, wps=493.3, ups=0.25, wpb=1961, bsz=64, num_updates=12890, lr=1.60798e-05, gnorm=5.177, clip=100, loss_scale=64, train_wall=40, gb_free=7.2, wall=52046
2023-05-08 14:24:04 - progress_bar.py[line:272] - INFO: epoch 015:    800 / 866 loss=2.229, loss_v1=0, loss_v2=0, nll_loss=1.009, ntokens=2027.5, nsentences=64, sample_size=2027.5, sample_size_v1=0, sample_size_v2=0, ppl=2.01, wps=509.2, ups=0.25, wpb=2027.5, bsz=64, num_updates=12900, lr=1.60675e-05, gnorm=5.178, clip=100, loss_scale=64, train_wall=40, gb_free=8.1, wall=52085
2023-05-08 14:24:44 - progress_bar.py[line:272] - INFO: epoch 015:    810 / 866 loss=2.191, loss_v1=0, loss_v2=0, nll_loss=0.966, ntokens=2021.4, nsentences=64, sample_size=2021.4, sample_size_v1=0, sample_size_v2=0, ppl=1.95, wps=507.9, ups=0.25, wpb=2021.4, bsz=64, num_updates=12910, lr=1.60552e-05, gnorm=5.435, clip=100, loss_scale=64, train_wall=40, gb_free=7.8, wall=52125
2023-05-08 14:25:24 - progress_bar.py[line:272] - INFO: epoch 015:    820 / 866 loss=2.189, loss_v1=0, loss_v2=0, nll_loss=0.966, ntokens=2070, nsentences=64, sample_size=2070, sample_size_v1=0, sample_size_v2=0, ppl=1.95, wps=517.2, ups=0.25, wpb=2070, bsz=64, num_updates=12920, lr=1.60429e-05, gnorm=4.868, clip=100, loss_scale=64, train_wall=40, gb_free=7.8, wall=52165
2023-05-08 14:26:05 - progress_bar.py[line:272] - INFO: epoch 015:    830 / 866 loss=2.189, loss_v1=0, loss_v2=0, nll_loss=0.967, ntokens=2200.4, nsentences=64, sample_size=2200.4, sample_size_v1=0, sample_size_v2=0, ppl=1.95, wps=540.6, ups=0.25, wpb=2200.4, bsz=64, num_updates=12930, lr=1.60306e-05, gnorm=4.437, clip=100, loss_scale=64, train_wall=41, gb_free=8, wall=52206
2023-05-08 14:26:45 - progress_bar.py[line:272] - INFO: epoch 015:    840 / 866 loss=2.208, loss_v1=0, loss_v2=0, nll_loss=0.987, ntokens=2111.9, nsentences=64, sample_size=2111.9, sample_size_v1=0, sample_size_v2=0, ppl=1.98, wps=523.4, ups=0.25, wpb=2111.9, bsz=64, num_updates=12940, lr=1.60183e-05, gnorm=5.02, clip=100, loss_scale=64, train_wall=40, gb_free=7.6, wall=52246
2023-05-08 14:27:26 - progress_bar.py[line:272] - INFO: epoch 015:    850 / 866 loss=2.195, loss_v1=0, loss_v2=0, nll_loss=0.971, ntokens=2216.5, nsentences=64, sample_size=2216.5, sample_size_v1=0, sample_size_v2=0, ppl=1.96, wps=546.8, ups=0.25, wpb=2216.5, bsz=64, num_updates=12950, lr=1.60061e-05, gnorm=4.452, clip=100, loss_scale=64, train_wall=40, gb_free=8.1, wall=52287
2023-05-08 14:28:06 - progress_bar.py[line:272] - INFO: epoch 015:    860 / 866 loss=2.197, loss_v1=0, loss_v2=0, nll_loss=0.976, ntokens=2044.3, nsentences=64, sample_size=2044.3, sample_size_v1=0, sample_size_v2=0, ppl=1.97, wps=507.5, ups=0.25, wpb=2044.3, bsz=64, num_updates=12960, lr=1.59938e-05, gnorm=4.795, clip=100, loss_scale=64, train_wall=40, gb_free=8.1, wall=52327
2023-05-08 14:28:29 - train.py[line:332] - INFO: end of epoch 15 (average epoch stats below)
local datafile ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 1 begin to initialize row_count and line_idx-to-offset mapping
2023-05-08 14:28:29 - progress_bar.py[line:282] - INFO: epoch 015 | loss 2.207 | loss_v1 0 | loss_v2 0 | nll_loss 0.985 | ntokens 2103.59 | nsentences 63.972 | sample_size 2103.59 | sample_size_v1 0 | sample_size_v2 0 | ppl 1.98 | wps 520.9 | ups 0.25 | wpb 2103.6 | bsz 64 | num_updates 12966 | lr 1.59864e-05 | gnorm 4.838 | clip 100 | loss_scale 64 | train_wall 3483 | gb_free 8.7 | wall 52350
2023-05-08 14:28:29 - trainer.py[line:639] - INFO: loading train data for epoch 16
local datafile ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 0 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 0 finished initializing row_count and line_idx-to-offset mapping
file ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 0 row count 27700 total row count 55400
slice_id 0 seek offset 0
2023-05-08 14:28:30 - trainer.py[line:703] - INFO: begin training epoch 16
2023-05-08 14:28:30 - train.py[line:305] - INFO: Start iterating over samples
local datafile ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 1 finished initializing row_count and line_idx-to-offset mapping
file ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 1 row count 27700 total row count 55400
slice_id 1 seek offset 27700
2023-05-08 14:28:47 - progress_bar.py[line:272] - INFO: epoch 016:      4 / 866 loss=2.209, loss_v1=0, loss_v2=0, nll_loss=0.986, ntokens=2092.9, nsentences=61.6, sample_size=2092.9, sample_size_v1=0, sample_size_v2=0, ppl=1.98, wps=508.9, ups=0.24, wpb=2092.9, bsz=61.6, num_updates=12970, lr=1.59815e-05, gnorm=4.892, clip=100, loss_scale=64, train_wall=39, gb_free=7.1, wall=52368
2023-05-08 14:29:27 - progress_bar.py[line:272] - INFO: epoch 016:     14 / 866 loss=2.168, loss_v1=0, loss_v2=0, nll_loss=0.941, ntokens=2059.7, nsentences=64, sample_size=2059.7, sample_size_v1=0, sample_size_v2=0, ppl=1.92, wps=510.8, ups=0.25, wpb=2059.7, bsz=64, num_updates=12980, lr=1.59692e-05, gnorm=5.049, clip=100, loss_scale=64, train_wall=40, gb_free=7.5, wall=52409
2023-05-08 14:30:08 - progress_bar.py[line:272] - INFO: epoch 016:     24 / 866 loss=2.141, loss_v1=0, loss_v2=0, nll_loss=0.914, ntokens=2025.5, nsentences=64, sample_size=2025.5, sample_size_v1=0, sample_size_v2=0, ppl=1.88, wps=501.2, ups=0.25, wpb=2025.5, bsz=64, num_updates=12990, lr=1.59569e-05, gnorm=5.044, clip=100, loss_scale=64, train_wall=40, gb_free=7.6, wall=52449
2023-05-08 14:30:48 - progress_bar.py[line:272] - INFO: epoch 016:     34 / 866 loss=2.12, loss_v1=0, loss_v2=0, nll_loss=0.886, ntokens=2115.7, nsentences=64, sample_size=2115.7, sample_size_v1=0, sample_size_v2=0, ppl=1.85, wps=521.5, ups=0.25, wpb=2115.7, bsz=64, num_updates=13000, lr=1.59446e-05, gnorm=4.521, clip=100, loss_scale=64, train_wall=41, gb_free=7.4, wall=52490
2023-05-08 14:31:29 - progress_bar.py[line:272] - INFO: epoch 016:     44 / 866 loss=2.116, loss_v1=0, loss_v2=0, nll_loss=0.886, ntokens=2111.3, nsentences=64, sample_size=2111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.85, wps=519.8, ups=0.25, wpb=2111.3, bsz=64, num_updates=13010, lr=1.59324e-05, gnorm=4.943, clip=100, loss_scale=64, train_wall=41, gb_free=7.2, wall=52530
2023-05-08 14:32:09 - progress_bar.py[line:272] - INFO: epoch 016:     54 / 866 loss=2.136, loss_v1=0, loss_v2=0, nll_loss=0.907, ntokens=2019.6, nsentences=64, sample_size=2019.6, sample_size_v1=0, sample_size_v2=0, ppl=1.88, wps=499.9, ups=0.25, wpb=2019.6, bsz=64, num_updates=13020, lr=1.59201e-05, gnorm=4.888, clip=100, loss_scale=64, train_wall=40, gb_free=7.5, wall=52571
2023-05-08 14:32:50 - progress_bar.py[line:272] - INFO: epoch 016:     64 / 866 loss=2.04, loss_v1=0, loss_v2=0, nll_loss=0.8, ntokens=2283.9, nsentences=64, sample_size=2283.9, sample_size_v1=0, sample_size_v2=0, ppl=1.74, wps=556.5, ups=0.24, wpb=2283.9, bsz=64, num_updates=13030, lr=1.59078e-05, gnorm=4.617, clip=100, loss_scale=64, train_wall=41, gb_free=6.9, wall=52612
2023-05-08 14:33:32 - progress_bar.py[line:272] - INFO: epoch 016:     74 / 866 loss=2.097, loss_v1=0, loss_v2=0, nll_loss=0.863, ntokens=2393.5, nsentences=64, sample_size=2393.5, sample_size_v1=0, sample_size_v2=0, ppl=1.82, wps=574.4, ups=0.24, wpb=2393.5, bsz=64, num_updates=13040, lr=1.58955e-05, gnorm=4.297, clip=100, loss_scale=64, train_wall=42, gb_free=6.4, wall=52653
2023-05-08 14:34:13 - progress_bar.py[line:272] - INFO: epoch 016:     84 / 866 loss=2.134, loss_v1=0, loss_v2=0, nll_loss=0.902, ntokens=2213.9, nsentences=64, sample_size=2213.9, sample_size_v1=0, sample_size_v2=0, ppl=1.87, wps=537.1, ups=0.24, wpb=2213.9, bsz=64, num_updates=13050, lr=1.58832e-05, gnorm=4.885, clip=100, loss_scale=64, train_wall=41, gb_free=6.8, wall=52695
2023-05-08 14:34:54 - progress_bar.py[line:272] - INFO: epoch 016:     94 / 866 loss=2.108, loss_v1=0, loss_v2=0, nll_loss=0.876, ntokens=2148.5, nsentences=64, sample_size=2148.5, sample_size_v1=0, sample_size_v2=0, ppl=1.83, wps=529.9, ups=0.25, wpb=2148.5, bsz=64, num_updates=13060, lr=1.58709e-05, gnorm=4.6, clip=100, loss_scale=64, train_wall=41, gb_free=8, wall=52735
2023-05-08 14:35:34 - progress_bar.py[line:272] - INFO: epoch 016:    104 / 866 loss=2.189, loss_v1=0, loss_v2=0, nll_loss=0.967, ntokens=2017.3, nsentences=64, sample_size=2017.3, sample_size_v1=0, sample_size_v2=0, ppl=1.95, wps=500, ups=0.25, wpb=2017.3, bsz=64, num_updates=13070, lr=1.58587e-05, gnorm=5.28, clip=100, loss_scale=64, train_wall=40, gb_free=7.9, wall=52775
2023-05-08 14:36:15 - progress_bar.py[line:272] - INFO: epoch 016:    114 / 866 loss=2.208, loss_v1=0, loss_v2=0, nll_loss=0.986, ntokens=2055.6, nsentences=64, sample_size=2055.6, sample_size_v1=0, sample_size_v2=0, ppl=1.98, wps=505.5, ups=0.25, wpb=2055.6, bsz=64, num_updates=13080, lr=1.58464e-05, gnorm=5.018, clip=100, loss_scale=64, train_wall=41, gb_free=7.6, wall=52816
2023-05-08 14:36:56 - progress_bar.py[line:272] - INFO: epoch 016:    124 / 866 loss=2.193, loss_v1=0, loss_v2=0, nll_loss=0.969, ntokens=2215.8, nsentences=64, sample_size=2215.8, sample_size_v1=0, sample_size_v2=0, ppl=1.96, wps=536.9, ups=0.24, wpb=2215.8, bsz=64, num_updates=13090, lr=1.58341e-05, gnorm=5.051, clip=100, loss_scale=64, train_wall=41, gb_free=7.1, wall=52857
2023-05-08 14:37:37 - progress_bar.py[line:272] - INFO: epoch 016:    134 / 866 loss=2.162, loss_v1=0, loss_v2=0, nll_loss=0.934, ntokens=2192.9, nsentences=64, sample_size=2192.9, sample_size_v1=0, sample_size_v2=0, ppl=1.91, wps=533.6, ups=0.24, wpb=2192.9, bsz=64, num_updates=13100, lr=1.58218e-05, gnorm=4.633, clip=100, loss_scale=64, train_wall=41, gb_free=7.8, wall=52898
2023-05-08 14:38:19 - progress_bar.py[line:272] - INFO: epoch 016:    144 / 866 loss=2.159, loss_v1=0, loss_v2=0, nll_loss=0.931, ntokens=2257.1, nsentences=64, sample_size=2257.1, sample_size_v1=0, sample_size_v2=0, ppl=1.91, wps=547.4, ups=0.24, wpb=2257.1, bsz=64, num_updates=13110, lr=1.58095e-05, gnorm=4.406, clip=100, loss_scale=64, train_wall=41, gb_free=6.7, wall=52940
2023-05-08 14:39:00 - progress_bar.py[line:272] - INFO: epoch 016:    154 / 866 loss=2.156, loss_v1=0, loss_v2=0, nll_loss=0.93, ntokens=2212.4, nsentences=64, sample_size=2212.4, sample_size_v1=0, sample_size_v2=0, ppl=1.91, wps=536.1, ups=0.24, wpb=2212.4, bsz=64, num_updates=13120, lr=1.57972e-05, gnorm=4.712, clip=100, loss_scale=64, train_wall=41, gb_free=6.7, wall=52981
2023-05-08 14:39:41 - progress_bar.py[line:272] - INFO: epoch 016:    164 / 866 loss=2.166, loss_v1=0, loss_v2=0, nll_loss=0.938, ntokens=2162.6, nsentences=64, sample_size=2162.6, sample_size_v1=0, sample_size_v2=0, ppl=1.92, wps=530.9, ups=0.25, wpb=2162.6, bsz=64, num_updates=13130, lr=1.57849e-05, gnorm=4.789, clip=100, loss_scale=64, train_wall=41, gb_free=6.4, wall=53022
2023-05-08 14:40:21 - progress_bar.py[line:272] - INFO: epoch 016:    174 / 866 loss=2.187, loss_v1=0, loss_v2=0, nll_loss=0.963, ntokens=2000.4, nsentences=64, sample_size=2000.4, sample_size_v1=0, sample_size_v2=0, ppl=1.95, wps=496.9, ups=0.25, wpb=2000.4, bsz=64, num_updates=13140, lr=1.57727e-05, gnorm=4.836, clip=100, loss_scale=64, train_wall=40, gb_free=7.6, wall=53062
2023-05-08 14:41:02 - progress_bar.py[line:272] - INFO: epoch 016:    184 / 866 loss=2.153, loss_v1=0, loss_v2=0, nll_loss=0.925, ntokens=2214.2, nsentences=64, sample_size=2214.2, sample_size_v1=0, sample_size_v2=0, ppl=1.9, wps=538.6, ups=0.24, wpb=2214.2, bsz=64, num_updates=13150, lr=1.57604e-05, gnorm=4.888, clip=100, loss_scale=64, train_wall=41, gb_free=7.4, wall=53103
2023-05-08 14:41:43 - progress_bar.py[line:272] - INFO: epoch 016:    194 / 866 loss=2.16, loss_v1=0, loss_v2=0, nll_loss=0.933, ntokens=2214.5, nsentences=64, sample_size=2214.5, sample_size_v1=0, sample_size_v2=0, ppl=1.91, wps=539.8, ups=0.24, wpb=2214.5, bsz=64, num_updates=13160, lr=1.57481e-05, gnorm=4.579, clip=100, loss_scale=64, train_wall=41, gb_free=6.6, wall=53144
2023-05-08 14:42:23 - progress_bar.py[line:272] - INFO: epoch 016:    204 / 866 loss=2.194, loss_v1=0, loss_v2=0, nll_loss=0.971, ntokens=2031.5, nsentences=64, sample_size=2031.5, sample_size_v1=0, sample_size_v2=0, ppl=1.96, wps=503, ups=0.25, wpb=2031.5, bsz=64, num_updates=13170, lr=1.57358e-05, gnorm=4.812, clip=100, loss_scale=128, train_wall=40, gb_free=7.3, wall=53184
2023-05-08 14:42:35 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2023-05-08 14:43:08 - progress_bar.py[line:272] - INFO: epoch 016:    215 / 866 loss=2.2, loss_v1=0, loss_v2=0, nll_loss=0.977, ntokens=2118.8, nsentences=64, sample_size=2118.8, sample_size_v1=0, sample_size_v2=0, ppl=1.97, wps=479.6, ups=0.23, wpb=2118.8, bsz=64, num_updates=13180, lr=1.57235e-05, gnorm=4.647, clip=100, loss_scale=64, train_wall=44, gb_free=8, wall=53229
2023-05-08 14:43:48 - progress_bar.py[line:272] - INFO: epoch 016:    225 / 866 loss=2.195, loss_v1=0, loss_v2=0, nll_loss=0.973, ntokens=2190.1, nsentences=64, sample_size=2190.1, sample_size_v1=0, sample_size_v2=0, ppl=1.96, wps=545.2, ups=0.25, wpb=2190.1, bsz=64, num_updates=13190, lr=1.57112e-05, gnorm=4.749, clip=100, loss_scale=64, train_wall=40, gb_free=7.1, wall=53269
2023-05-08 14:44:28 - progress_bar.py[line:272] - INFO: epoch 016:    235 / 866 loss=2.223, loss_v1=0, loss_v2=0, nll_loss=1.002, ntokens=2099.1, nsentences=64, sample_size=2099.1, sample_size_v1=0, sample_size_v2=0, ppl=2, wps=525.3, ups=0.25, wpb=2099.1, bsz=64, num_updates=13200, lr=1.5699e-05, gnorm=5.188, clip=100, loss_scale=64, train_wall=40, gb_free=7.6, wall=53309
2023-05-08 14:45:08 - progress_bar.py[line:272] - INFO: epoch 016:    245 / 866 loss=2.206, loss_v1=0, loss_v2=0, nll_loss=0.985, ntokens=2235, nsentences=64, sample_size=2235, sample_size_v1=0, sample_size_v2=0, ppl=1.98, wps=554.1, ups=0.25, wpb=2235, bsz=64, num_updates=13210, lr=1.56867e-05, gnorm=4.684, clip=100, loss_scale=64, train_wall=40, gb_free=7.6, wall=53349
2023-05-08 14:45:48 - progress_bar.py[line:272] - INFO: epoch 016:    255 / 866 loss=2.212, loss_v1=0, loss_v2=0, nll_loss=0.99, ntokens=2084.7, nsentences=64, sample_size=2084.7, sample_size_v1=0, sample_size_v2=0, ppl=1.99, wps=518, ups=0.25, wpb=2084.7, bsz=64, num_updates=13220, lr=1.56744e-05, gnorm=4.878, clip=100, loss_scale=64, train_wall=40, gb_free=8.2, wall=53389
2023-05-08 14:46:29 - progress_bar.py[line:272] - INFO: epoch 016:    265 / 866 loss=2.204, loss_v1=0, loss_v2=0, nll_loss=0.984, ntokens=2160.1, nsentences=64, sample_size=2160.1, sample_size_v1=0, sample_size_v2=0, ppl=1.98, wps=534.9, ups=0.25, wpb=2160.1, bsz=64, num_updates=13230, lr=1.56621e-05, gnorm=5.192, clip=100, loss_scale=64, train_wall=40, gb_free=7.6, wall=53430
2023-05-08 14:47:09 - progress_bar.py[line:272] - INFO: epoch 016:    275 / 866 loss=2.196, loss_v1=0, loss_v2=0, nll_loss=0.972, ntokens=2134.5, nsentences=64, sample_size=2134.5, sample_size_v1=0, sample_size_v2=0, ppl=1.96, wps=528, ups=0.25, wpb=2134.5, bsz=64, num_updates=13240, lr=1.56498e-05, gnorm=4.46, clip=100, loss_scale=64, train_wall=40, gb_free=7.7, wall=53470
2023-05-08 14:47:49 - progress_bar.py[line:272] - INFO: epoch 016:    285 / 866 loss=2.204, loss_v1=0, loss_v2=0, nll_loss=0.984, ntokens=2188.7, nsentences=64, sample_size=2188.7, sample_size_v1=0, sample_size_v2=0, ppl=1.98, wps=543.6, ups=0.25, wpb=2188.7, bsz=64, num_updates=13250, lr=1.56375e-05, gnorm=4.713, clip=100, loss_scale=64, train_wall=40, gb_free=6.4, wall=53510
2023-05-08 14:48:29 - progress_bar.py[line:272] - INFO: epoch 016:    295 / 866 loss=2.19, loss_v1=0, loss_v2=0, nll_loss=0.965, ntokens=2116.1, nsentences=64, sample_size=2116.1, sample_size_v1=0, sample_size_v2=0, ppl=1.95, wps=527.6, ups=0.25, wpb=2116.1, bsz=64, num_updates=13260, lr=1.56253e-05, gnorm=4.922, clip=100, loss_scale=64, train_wall=40, gb_free=7.7, wall=53551
2023-05-08 14:49:10 - progress_bar.py[line:272] - INFO: epoch 016:    305 / 866 loss=2.185, loss_v1=0, loss_v2=0, nll_loss=0.962, ntokens=2158, nsentences=64, sample_size=2158, sample_size_v1=0, sample_size_v2=0, ppl=1.95, wps=536.9, ups=0.25, wpb=2158, bsz=64, num_updates=13270, lr=1.5613e-05, gnorm=4.735, clip=100, loss_scale=64, train_wall=40, gb_free=7.4, wall=53591
2023-05-08 14:49:50 - progress_bar.py[line:272] - INFO: epoch 016:    315 / 866 loss=2.192, loss_v1=0, loss_v2=0, nll_loss=0.969, ntokens=2042.9, nsentences=64, sample_size=2042.9, sample_size_v1=0, sample_size_v2=0, ppl=1.96, wps=511, ups=0.25, wpb=2042.9, bsz=64, num_updates=13280, lr=1.56007e-05, gnorm=5.069, clip=100, loss_scale=64, train_wall=40, gb_free=7.8, wall=53631
2023-05-08 14:50:30 - progress_bar.py[line:272] - INFO: epoch 016:    325 / 866 loss=2.216, loss_v1=0, loss_v2=0, nll_loss=0.995, ntokens=2007.5, nsentences=64, sample_size=2007.5, sample_size_v1=0, sample_size_v2=0, ppl=1.99, wps=502.8, ups=0.25, wpb=2007.5, bsz=64, num_updates=13290, lr=1.55884e-05, gnorm=5.26, clip=100, loss_scale=64, train_wall=40, gb_free=8.1, wall=53671
2023-05-08 14:51:10 - progress_bar.py[line:272] - INFO: epoch 016:    335 / 866 loss=2.19, loss_v1=0, loss_v2=0, nll_loss=0.966, ntokens=2136.8, nsentences=64, sample_size=2136.8, sample_size_v1=0, sample_size_v2=0, ppl=1.95, wps=532.9, ups=0.25, wpb=2136.8, bsz=64, num_updates=13300, lr=1.55761e-05, gnorm=4.6, clip=100, loss_scale=64, train_wall=40, gb_free=7.9, wall=53711
2023-05-08 14:51:50 - progress_bar.py[line:272] - INFO: epoch 016:    345 / 866 loss=2.182, loss_v1=0, loss_v2=0, nll_loss=0.958, ntokens=1972.8, nsentences=64, sample_size=1972.8, sample_size_v1=0, sample_size_v2=0, ppl=1.94, wps=492.7, ups=0.25, wpb=1972.8, bsz=64, num_updates=13310, lr=1.55638e-05, gnorm=4.893, clip=100, loss_scale=64, train_wall=40, gb_free=7.4, wall=53751
2023-05-08 14:52:30 - progress_bar.py[line:272] - INFO: epoch 016:    355 / 866 loss=2.227, loss_v1=0, loss_v2=0, nll_loss=1.009, ntokens=1977.7, nsentences=64, sample_size=1977.7, sample_size_v1=0, sample_size_v2=0, ppl=2.01, wps=496.9, ups=0.25, wpb=1977.7, bsz=64, num_updates=13320, lr=1.55516e-05, gnorm=5.52, clip=100, loss_scale=64, train_wall=40, gb_free=8.1, wall=53791
2023-05-08 14:53:09 - progress_bar.py[line:272] - INFO: epoch 016:    365 / 866 loss=2.203, loss_v1=0, loss_v2=0, nll_loss=0.98, ntokens=1988.4, nsentences=64, sample_size=1988.4, sample_size_v1=0, sample_size_v2=0, ppl=1.97, wps=498.9, ups=0.25, wpb=1988.4, bsz=64, num_updates=13330, lr=1.55393e-05, gnorm=4.893, clip=100, loss_scale=64, train_wall=40, gb_free=7.3, wall=53830
2023-05-08 14:53:49 - progress_bar.py[line:272] - INFO: epoch 016:    375 / 866 loss=2.201, loss_v1=0, loss_v2=0, nll_loss=0.977, ntokens=2082.7, nsentences=64, sample_size=2082.7, sample_size_v1=0, sample_size_v2=0, ppl=1.97, wps=521.2, ups=0.25, wpb=2082.7, bsz=64, num_updates=13340, lr=1.5527e-05, gnorm=5.359, clip=100, loss_scale=64, train_wall=40, gb_free=8.2, wall=53870
2023-05-08 14:54:29 - progress_bar.py[line:272] - INFO: epoch 016:    385 / 866 loss=2.188, loss_v1=0, loss_v2=0, nll_loss=0.965, ntokens=2151.8, nsentences=64, sample_size=2151.8, sample_size_v1=0, sample_size_v2=0, ppl=1.95, wps=537.5, ups=0.25, wpb=2151.8, bsz=64, num_updates=13350, lr=1.55147e-05, gnorm=4.631, clip=100, loss_scale=64, train_wall=40, gb_free=8, wall=53911
2023-05-08 14:55:09 - progress_bar.py[line:272] - INFO: epoch 016:    395 / 866 loss=2.207, loss_v1=0, loss_v2=0, nll_loss=0.988, ntokens=1979, nsentences=64, sample_size=1979, sample_size_v1=0, sample_size_v2=0, ppl=1.98, wps=496.6, ups=0.25, wpb=1979, bsz=64, num_updates=13360, lr=1.55024e-05, gnorm=5.54, clip=100, loss_scale=64, train_wall=40, gb_free=7.9, wall=53950
2023-05-08 14:55:49 - progress_bar.py[line:272] - INFO: epoch 016:    405 / 866 loss=2.193, loss_v1=0, loss_v2=0, nll_loss=0.969, ntokens=2126.6, nsentences=64, sample_size=2126.6, sample_size_v1=0, sample_size_v2=0, ppl=1.96, wps=530.6, ups=0.25, wpb=2126.6, bsz=64, num_updates=13370, lr=1.54901e-05, gnorm=4.566, clip=100, loss_scale=64, train_wall=40, gb_free=8.2, wall=53990
2023-05-08 14:56:30 - progress_bar.py[line:272] - INFO: epoch 016:    415 / 866 loss=2.187, loss_v1=0, loss_v2=0, nll_loss=0.964, ntokens=2132, nsentences=64, sample_size=2132, sample_size_v1=0, sample_size_v2=0, ppl=1.95, wps=526.6, ups=0.25, wpb=2132, bsz=64, num_updates=13380, lr=1.54778e-05, gnorm=4.859, clip=100, loss_scale=64, train_wall=40, gb_free=8.1, wall=54031
2023-05-08 14:57:10 - progress_bar.py[line:272] - INFO: epoch 016:    425 / 866 loss=2.171, loss_v1=0, loss_v2=0, nll_loss=0.946, ntokens=2066.9, nsentences=64, sample_size=2066.9, sample_size_v1=0, sample_size_v2=0, ppl=1.93, wps=514.7, ups=0.25, wpb=2066.9, bsz=64, num_updates=13390, lr=1.54656e-05, gnorm=4.79, clip=100, loss_scale=64, train_wall=40, gb_free=7.6, wall=54071
2023-05-08 14:57:50 - progress_bar.py[line:272] - INFO: epoch 016:    435 / 866 loss=2.196, loss_v1=0, loss_v2=0, nll_loss=0.972, ntokens=2117.6, nsentences=64, sample_size=2117.6, sample_size_v1=0, sample_size_v2=0, ppl=1.96, wps=529.4, ups=0.25, wpb=2117.6, bsz=64, num_updates=13400, lr=1.54533e-05, gnorm=4.915, clip=100, loss_scale=64, train_wall=40, gb_free=8.3, wall=54111
2023-05-08 14:58:30 - progress_bar.py[line:272] - INFO: epoch 016:    445 / 866 loss=2.227, loss_v1=0, loss_v2=0, nll_loss=1.006, ntokens=2033.2, nsentences=64, sample_size=2033.2, sample_size_v1=0, sample_size_v2=0, ppl=2.01, wps=504.6, ups=0.25, wpb=2033.2, bsz=64, num_updates=13410, lr=1.5441e-05, gnorm=5.016, clip=100, loss_scale=64, train_wall=40, gb_free=7.7, wall=54151
2023-05-08 14:59:10 - progress_bar.py[line:272] - INFO: epoch 016:    455 / 866 loss=2.209, loss_v1=0, loss_v2=0, nll_loss=0.989, ntokens=2027.7, nsentences=64, sample_size=2027.7, sample_size_v1=0, sample_size_v2=0, ppl=1.98, wps=507.2, ups=0.25, wpb=2027.7, bsz=64, num_updates=13420, lr=1.54287e-05, gnorm=5.066, clip=100, loss_scale=64, train_wall=40, gb_free=7.9, wall=54191
2023-05-08 14:59:51 - progress_bar.py[line:272] - INFO: epoch 016:    465 / 866 loss=2.209, loss_v1=0, loss_v2=0, nll_loss=0.988, ntokens=2165.9, nsentences=64, sample_size=2165.9, sample_size_v1=0, sample_size_v2=0, ppl=1.98, wps=537.6, ups=0.25, wpb=2165.9, bsz=64, num_updates=13430, lr=1.54164e-05, gnorm=4.813, clip=100, loss_scale=64, train_wall=40, gb_free=7.7, wall=54232
2023-05-08 15:00:31 - progress_bar.py[line:272] - INFO: epoch 016:    475 / 866 loss=2.212, loss_v1=0, loss_v2=0, nll_loss=0.989, ntokens=2209.3, nsentences=64, sample_size=2209.3, sample_size_v1=0, sample_size_v2=0, ppl=1.99, wps=545.7, ups=0.25, wpb=2209.3, bsz=64, num_updates=13440, lr=1.54041e-05, gnorm=5.178, clip=100, loss_scale=64, train_wall=40, gb_free=7.7, wall=54272
2023-05-08 15:01:11 - progress_bar.py[line:272] - INFO: epoch 016:    485 / 866 loss=2.195, loss_v1=0, loss_v2=0, nll_loss=0.971, ntokens=2141.6, nsentences=64, sample_size=2141.6, sample_size_v1=0, sample_size_v2=0, ppl=1.96, wps=532.1, ups=0.25, wpb=2141.6, bsz=64, num_updates=13450, lr=1.53919e-05, gnorm=4.852, clip=100, loss_scale=64, train_wall=40, gb_free=7.6, wall=54312
2023-05-08 15:01:51 - progress_bar.py[line:272] - INFO: epoch 016:    495 / 866 loss=2.169, loss_v1=0, loss_v2=0, nll_loss=0.943, ntokens=2039.9, nsentences=64, sample_size=2039.9, sample_size_v1=0, sample_size_v2=0, ppl=1.92, wps=508, ups=0.25, wpb=2039.9, bsz=64, num_updates=13460, lr=1.53796e-05, gnorm=4.882, clip=100, loss_scale=64, train_wall=40, gb_free=8.4, wall=54353
2023-05-08 15:02:31 - progress_bar.py[line:272] - INFO: epoch 016:    505 / 866 loss=2.21, loss_v1=0, loss_v2=0, nll_loss=0.988, ntokens=2071.4, nsentences=64, sample_size=2071.4, sample_size_v1=0, sample_size_v2=0, ppl=1.98, wps=518.7, ups=0.25, wpb=2071.4, bsz=64, num_updates=13470, lr=1.53673e-05, gnorm=4.863, clip=100, loss_scale=64, train_wall=40, gb_free=7.8, wall=54392
2023-05-08 15:03:11 - progress_bar.py[line:272] - INFO: epoch 016:    515 / 866 loss=2.216, loss_v1=0, loss_v2=0, nll_loss=0.995, ntokens=2210, nsentences=64, sample_size=2210, sample_size_v1=0, sample_size_v2=0, ppl=1.99, wps=551.8, ups=0.25, wpb=2210, bsz=64, num_updates=13480, lr=1.5355e-05, gnorm=4.717, clip=100, loss_scale=64, train_wall=40, gb_free=7.5, wall=54433
2023-05-08 15:03:51 - progress_bar.py[line:272] - INFO: epoch 016:    525 / 866 loss=2.199, loss_v1=0, loss_v2=0, nll_loss=0.975, ntokens=2045, nsentences=64, sample_size=2045, sample_size_v1=0, sample_size_v2=0, ppl=1.97, wps=515.1, ups=0.25, wpb=2045, bsz=64, num_updates=13490, lr=1.53427e-05, gnorm=5.141, clip=100, loss_scale=64, train_wall=40, gb_free=8, wall=54472
2023-05-08 15:04:31 - progress_bar.py[line:272] - INFO: epoch 016:    535 / 866 loss=2.184, loss_v1=0, loss_v2=0, nll_loss=0.958, ntokens=2054.6, nsentences=64, sample_size=2054.6, sample_size_v1=0, sample_size_v2=0, ppl=1.94, wps=513.6, ups=0.25, wpb=2054.6, bsz=64, num_updates=13500, lr=1.53304e-05, gnorm=4.978, clip=100, loss_scale=64, train_wall=40, gb_free=7.6, wall=54512
2023-05-08 15:05:11 - progress_bar.py[line:272] - INFO: epoch 016:    545 / 866 loss=2.206, loss_v1=0, loss_v2=0, nll_loss=0.985, ntokens=2233, nsentences=64, sample_size=2233, sample_size_v1=0, sample_size_v2=0, ppl=1.98, wps=555.3, ups=0.25, wpb=2233, bsz=64, num_updates=13510, lr=1.53182e-05, gnorm=4.463, clip=100, loss_scale=64, train_wall=40, gb_free=7.5, wall=54552
2023-05-08 15:05:52 - progress_bar.py[line:272] - INFO: epoch 016:    555 / 866 loss=2.221, loss_v1=0, loss_v2=0, nll_loss=1.002, ntokens=2288.8, nsentences=64, sample_size=2288.8, sample_size_v1=0, sample_size_v2=0, ppl=2, wps=559.4, ups=0.24, wpb=2288.8, bsz=64, num_updates=13520, lr=1.53059e-05, gnorm=4.559, clip=100, loss_scale=64, train_wall=41, gb_free=7.8, wall=54593
2023-05-08 15:06:33 - progress_bar.py[line:272] - INFO: epoch 016:    565 / 866 loss=2.199, loss_v1=0, loss_v2=0, nll_loss=0.975, ntokens=2258.2, nsentences=64, sample_size=2258.2, sample_size_v1=0, sample_size_v2=0, ppl=1.97, wps=557.7, ups=0.25, wpb=2258.2, bsz=64, num_updates=13530, lr=1.52936e-05, gnorm=4.645, clip=100, loss_scale=64, train_wall=40, gb_free=7.7, wall=54634
2023-05-08 15:07:13 - progress_bar.py[line:272] - INFO: epoch 016:    575 / 866 loss=2.199, loss_v1=0, loss_v2=0, nll_loss=0.976, ntokens=2151.4, nsentences=64, sample_size=2151.4, sample_size_v1=0, sample_size_v2=0, ppl=1.97, wps=533.6, ups=0.25, wpb=2151.4, bsz=64, num_updates=13540, lr=1.52813e-05, gnorm=5.024, clip=100, loss_scale=64, train_wall=40, gb_free=7.9, wall=54674
2023-05-08 15:07:53 - progress_bar.py[line:272] - INFO: epoch 016:    585 / 866 loss=2.215, loss_v1=0, loss_v2=0, nll_loss=0.994, ntokens=2120.4, nsentences=64, sample_size=2120.4, sample_size_v1=0, sample_size_v2=0, ppl=1.99, wps=525.4, ups=0.25, wpb=2120.4, bsz=64, num_updates=13550, lr=1.5269e-05, gnorm=5.079, clip=100, loss_scale=64, train_wall=40, gb_free=7.9, wall=54715
2023-05-08 15:08:34 - progress_bar.py[line:272] - INFO: epoch 016:    595 / 866 loss=2.189, loss_v1=0, loss_v2=0, nll_loss=0.964, ntokens=2112.8, nsentences=64, sample_size=2112.8, sample_size_v1=0, sample_size_v2=0, ppl=1.95, wps=524.2, ups=0.25, wpb=2112.8, bsz=64, num_updates=13560, lr=1.52567e-05, gnorm=4.849, clip=100, loss_scale=64, train_wall=40, gb_free=7.9, wall=54755
2023-05-08 15:09:14 - progress_bar.py[line:272] - INFO: epoch 016:    605 / 866 loss=2.181, loss_v1=0, loss_v2=0, nll_loss=0.958, ntokens=2046.6, nsentences=64, sample_size=2046.6, sample_size_v1=0, sample_size_v2=0, ppl=1.94, wps=510.5, ups=0.25, wpb=2046.6, bsz=64, num_updates=13570, lr=1.52445e-05, gnorm=5.183, clip=100, loss_scale=64, train_wall=40, gb_free=8.4, wall=54795
2023-05-08 15:09:54 - progress_bar.py[line:272] - INFO: epoch 016:    615 / 866 loss=2.22, loss_v1=0, loss_v2=0, nll_loss=0.999, ntokens=1940.8, nsentences=64, sample_size=1940.8, sample_size_v1=0, sample_size_v2=0, ppl=2, wps=485.2, ups=0.25, wpb=1940.8, bsz=64, num_updates=13580, lr=1.52322e-05, gnorm=5.173, clip=100, loss_scale=64, train_wall=40, gb_free=7.6, wall=54835
2023-05-08 15:10:34 - progress_bar.py[line:272] - INFO: epoch 016:    625 / 866 loss=2.2, loss_v1=0, loss_v2=0, nll_loss=0.978, ntokens=2027, nsentences=64, sample_size=2027, sample_size_v1=0, sample_size_v2=0, ppl=1.97, wps=506.8, ups=0.25, wpb=2027, bsz=64, num_updates=13590, lr=1.52199e-05, gnorm=5.097, clip=100, loss_scale=64, train_wall=40, gb_free=8.1, wall=54875
2023-05-08 15:11:14 - progress_bar.py[line:272] - INFO: epoch 016:    635 / 866 loss=2.197, loss_v1=0, loss_v2=0, nll_loss=0.974, ntokens=2022.9, nsentences=64, sample_size=2022.9, sample_size_v1=0, sample_size_v2=0, ppl=1.96, wps=505.5, ups=0.25, wpb=2022.9, bsz=64, num_updates=13600, lr=1.52076e-05, gnorm=5.221, clip=100, loss_scale=64, train_wall=40, gb_free=8.1, wall=54915
2023-05-08 15:11:54 - progress_bar.py[line:272] - INFO: epoch 016:    645 / 866 loss=2.194, loss_v1=0, loss_v2=0, nll_loss=0.969, ntokens=2094, nsentences=64, sample_size=2094, sample_size_v1=0, sample_size_v2=0, ppl=1.96, wps=525.5, ups=0.25, wpb=2094, bsz=64, num_updates=13610, lr=1.51953e-05, gnorm=5.169, clip=100, loss_scale=64, train_wall=40, gb_free=8, wall=54955
2023-05-08 15:12:34 - progress_bar.py[line:272] - INFO: epoch 016:    655 / 866 loss=2.2, loss_v1=0, loss_v2=0, nll_loss=0.978, ntokens=1921.7, nsentences=64, sample_size=1921.7, sample_size_v1=0, sample_size_v2=0, ppl=1.97, wps=483, ups=0.25, wpb=1921.7, bsz=64, num_updates=13620, lr=1.5183e-05, gnorm=5.489, clip=100, loss_scale=64, train_wall=40, gb_free=7.8, wall=54995
2023-05-08 15:13:13 - progress_bar.py[line:272] - INFO: epoch 016:    665 / 866 loss=2.218, loss_v1=0, loss_v2=0, nll_loss=0.998, ntokens=1956.7, nsentences=64, sample_size=1956.7, sample_size_v1=0, sample_size_v2=0, ppl=2, wps=491.1, ups=0.25, wpb=1956.7, bsz=64, num_updates=13630, lr=1.51707e-05, gnorm=5.595, clip=100, loss_scale=64, train_wall=40, gb_free=8.4, wall=55034
2023-05-08 15:13:53 - progress_bar.py[line:272] - INFO: epoch 016:    675 / 866 loss=2.194, loss_v1=0, loss_v2=0, nll_loss=0.968, ntokens=2060, nsentences=64, sample_size=2060, sample_size_v1=0, sample_size_v2=0, ppl=1.96, wps=514.1, ups=0.25, wpb=2060, bsz=64, num_updates=13640, lr=1.51585e-05, gnorm=4.95, clip=100, loss_scale=64, train_wall=40, gb_free=7.2, wall=55075
2023-05-08 15:14:33 - progress_bar.py[line:272] - INFO: epoch 016:    685 / 866 loss=2.194, loss_v1=0, loss_v2=0, nll_loss=0.971, ntokens=2032.5, nsentences=64, sample_size=2032.5, sample_size_v1=0, sample_size_v2=0, ppl=1.96, wps=511.3, ups=0.25, wpb=2032.5, bsz=64, num_updates=13650, lr=1.51462e-05, gnorm=5.377, clip=100, loss_scale=64, train_wall=40, gb_free=7.8, wall=55114
2023-05-08 15:15:13 - progress_bar.py[line:272] - INFO: epoch 016:    695 / 866 loss=2.211, loss_v1=0, loss_v2=0, nll_loss=0.991, ntokens=2093.2, nsentences=64, sample_size=2093.2, sample_size_v1=0, sample_size_v2=0, ppl=1.99, wps=521.6, ups=0.25, wpb=2093.2, bsz=64, num_updates=13660, lr=1.51339e-05, gnorm=5.205, clip=100, loss_scale=64, train_wall=40, gb_free=6.7, wall=55154
2023-05-08 15:15:54 - progress_bar.py[line:272] - INFO: epoch 016:    705 / 866 loss=2.2, loss_v1=0, loss_v2=0, nll_loss=0.976, ntokens=1996.1, nsentences=64, sample_size=1996.1, sample_size_v1=0, sample_size_v2=0, ppl=1.97, wps=496.8, ups=0.25, wpb=1996.1, bsz=64, num_updates=13670, lr=1.51216e-05, gnorm=5.044, clip=100, loss_scale=64, train_wall=40, gb_free=8.1, wall=55195
2023-05-08 15:16:33 - progress_bar.py[line:272] - INFO: epoch 016:    715 / 866 loss=2.206, loss_v1=0, loss_v2=0, nll_loss=0.986, ntokens=1876.5, nsentences=64, sample_size=1876.5, sample_size_v1=0, sample_size_v2=0, ppl=1.98, wps=471.4, ups=0.25, wpb=1876.5, bsz=64, num_updates=13680, lr=1.51093e-05, gnorm=5.415, clip=100, loss_scale=64, train_wall=40, gb_free=8, wall=55234
2023-05-08 15:16:57 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2023-05-08 15:17:17 - progress_bar.py[line:272] - INFO: epoch 016:    726 / 866 loss=2.165, loss_v1=0, loss_v2=0, nll_loss=0.94, ntokens=2015.5, nsentences=64, sample_size=2015.5, sample_size_v1=0, sample_size_v2=0, ppl=1.92, wps=459.7, ups=0.23, wpb=2015.5, bsz=64, num_updates=13690, lr=1.5097e-05, gnorm=4.875, clip=100, loss_scale=64, train_wall=44, gb_free=7.3, wall=55278
2023-05-08 15:17:57 - progress_bar.py[line:272] - INFO: epoch 016:    736 / 866 loss=2.175, loss_v1=0, loss_v2=0, nll_loss=0.951, ntokens=2067.7, nsentences=64, sample_size=2067.7, sample_size_v1=0, sample_size_v2=0, ppl=1.93, wps=518, ups=0.25, wpb=2067.7, bsz=64, num_updates=13700, lr=1.50848e-05, gnorm=5.112, clip=100, loss_scale=64, train_wall=40, gb_free=8.1, wall=55318
2023-05-08 15:18:37 - progress_bar.py[line:272] - INFO: epoch 016:    746 / 866 loss=2.175, loss_v1=0, loss_v2=0, nll_loss=0.947, ntokens=2136.1, nsentences=64, sample_size=2136.1, sample_size_v1=0, sample_size_v2=0, ppl=1.93, wps=533.8, ups=0.25, wpb=2136.1, bsz=64, num_updates=13710, lr=1.50725e-05, gnorm=4.87, clip=100, loss_scale=64, train_wall=40, gb_free=7.9, wall=55358
2023-05-08 15:19:17 - progress_bar.py[line:272] - INFO: epoch 016:    756 / 866 loss=2.18, loss_v1=0, loss_v2=0, nll_loss=0.957, ntokens=2079.3, nsentences=64, sample_size=2079.3, sample_size_v1=0, sample_size_v2=0, ppl=1.94, wps=520.1, ups=0.25, wpb=2079.3, bsz=64, num_updates=13720, lr=1.50602e-05, gnorm=4.981, clip=100, loss_scale=64, train_wall=40, gb_free=7.5, wall=55398
2023-05-08 15:19:57 - progress_bar.py[line:272] - INFO: epoch 016:    766 / 866 loss=2.18, loss_v1=0, loss_v2=0, nll_loss=0.956, ntokens=2087.9, nsentences=64, sample_size=2087.9, sample_size_v1=0, sample_size_v2=0, ppl=1.94, wps=523.2, ups=0.25, wpb=2087.9, bsz=64, num_updates=13730, lr=1.50479e-05, gnorm=4.755, clip=100, loss_scale=64, train_wall=40, gb_free=7.9, wall=55438
2023-05-08 15:20:37 - progress_bar.py[line:272] - INFO: epoch 016:    776 / 866 loss=2.185, loss_v1=0, loss_v2=0, nll_loss=0.959, ntokens=2232.1, nsentences=64, sample_size=2232.1, sample_size_v1=0, sample_size_v2=0, ppl=1.94, wps=559, ups=0.25, wpb=2232.1, bsz=64, num_updates=13740, lr=1.50356e-05, gnorm=5.318, clip=100, loss_scale=64, train_wall=40, gb_free=7.8, wall=55478
2023-05-08 15:21:17 - progress_bar.py[line:272] - INFO: epoch 016:    786 / 866 loss=2.191, loss_v1=0, loss_v2=0, nll_loss=0.966, ntokens=2088.2, nsentences=64, sample_size=2088.2, sample_size_v1=0, sample_size_v2=0, ppl=1.95, wps=522.7, ups=0.25, wpb=2088.2, bsz=64, num_updates=13750, lr=1.50233e-05, gnorm=4.947, clip=100, loss_scale=64, train_wall=40, gb_free=8.1, wall=55518
2023-05-08 15:21:57 - progress_bar.py[line:272] - INFO: epoch 016:    796 / 866 loss=2.209, loss_v1=0, loss_v2=0, nll_loss=0.988, ntokens=2068.1, nsentences=64, sample_size=2068.1, sample_size_v1=0, sample_size_v2=0, ppl=1.98, wps=519.2, ups=0.25, wpb=2068.1, bsz=64, num_updates=13760, lr=1.50111e-05, gnorm=5.22, clip=100, loss_scale=64, train_wall=40, gb_free=7.5, wall=55558
2023-05-08 15:22:36 - progress_bar.py[line:272] - INFO: epoch 016:    806 / 866 loss=2.188, loss_v1=0, loss_v2=0, nll_loss=0.962, ntokens=1919.9, nsentences=64, sample_size=1919.9, sample_size_v1=0, sample_size_v2=0, ppl=1.95, wps=484.6, ups=0.25, wpb=1919.9, bsz=64, num_updates=13770, lr=1.49988e-05, gnorm=5.471, clip=100, loss_scale=64, train_wall=40, gb_free=8.1, wall=55597
2023-05-08 15:23:17 - progress_bar.py[line:272] - INFO: epoch 016:    816 / 866 loss=2.171, loss_v1=0, loss_v2=0, nll_loss=0.943, ntokens=2099.5, nsentences=64, sample_size=2099.5, sample_size_v1=0, sample_size_v2=0, ppl=1.92, wps=521.4, ups=0.25, wpb=2099.5, bsz=64, num_updates=13780, lr=1.49865e-05, gnorm=4.804, clip=100, loss_scale=64, train_wall=40, gb_free=7.4, wall=55638
2023-05-08 15:23:57 - progress_bar.py[line:272] - INFO: epoch 016:    826 / 866 loss=2.161, loss_v1=0, loss_v2=0, nll_loss=0.936, ntokens=2152.1, nsentences=64, sample_size=2152.1, sample_size_v1=0, sample_size_v2=0, ppl=1.91, wps=534.8, ups=0.25, wpb=2152.1, bsz=64, num_updates=13790, lr=1.49742e-05, gnorm=4.587, clip=100, loss_scale=64, train_wall=40, gb_free=7.9, wall=55678
2023-05-08 15:24:37 - progress_bar.py[line:272] - INFO: epoch 016:    836 / 866 loss=2.177, loss_v1=0, loss_v2=0, nll_loss=0.953, ntokens=2165.2, nsentences=64, sample_size=2165.2, sample_size_v1=0, sample_size_v2=0, ppl=1.94, wps=537.2, ups=0.25, wpb=2165.2, bsz=64, num_updates=13800, lr=1.49619e-05, gnorm=4.71, clip=100, loss_scale=64, train_wall=40, gb_free=8.2, wall=55718
2023-05-08 15:25:18 - progress_bar.py[line:272] - INFO: epoch 016:    846 / 866 loss=2.171, loss_v1=0, loss_v2=0, nll_loss=0.943, ntokens=2171.3, nsentences=64, sample_size=2171.3, sample_size_v1=0, sample_size_v2=0, ppl=1.92, wps=536.8, ups=0.25, wpb=2171.3, bsz=64, num_updates=13810, lr=1.49496e-05, gnorm=4.554, clip=100, loss_scale=64, train_wall=40, gb_free=8, wall=55759
2023-05-08 15:25:58 - progress_bar.py[line:272] - INFO: epoch 016:    856 / 866 loss=2.169, loss_v1=0, loss_v2=0, nll_loss=0.945, ntokens=2114.8, nsentences=64, sample_size=2114.8, sample_size_v1=0, sample_size_v2=0, ppl=1.93, wps=525.4, ups=0.25, wpb=2114.8, bsz=64, num_updates=13820, lr=1.49374e-05, gnorm=4.555, clip=100, loss_scale=64, train_wall=40, gb_free=7.9, wall=55799
local datafile ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 1 begin to initialize row_count and line_idx-to-offset mapping
2023-05-08 15:26:36 - progress_bar.py[line:272] - INFO: epoch 016:    866 / 866 loss=2.202, loss_v1=0, loss_v2=0, nll_loss=0.98, ntokens=2017.9, nsentences=61.6, sample_size=2017.9, sample_size_v1=0, sample_size_v2=0, ppl=1.97, wps=523.9, ups=0.26, wpb=2017.9, bsz=61.6, num_updates=13830, lr=1.49251e-05, gnorm=4.829, clip=100, loss_scale=64, train_wall=38, gb_free=8.7, wall=55838
2023-05-08 15:26:36 - train.py[line:332] - INFO: end of epoch 16 (average epoch stats below)
2023-05-08 15:26:36 - progress_bar.py[line:282] - INFO: epoch 016 | loss 2.185 | loss_v1 0 | loss_v2 0 | nll_loss 0.96 | ntokens 2103.48 | nsentences 63.972 | sample_size 2103.48 | sample_size_v1 0 | sample_size_v2 0 | ppl 1.95 | wps 521.1 | ups 0.25 | wpb 2103.5 | bsz 64 | num_updates 13830 | lr 1.49251e-05 | gnorm 4.925 | clip 100 | loss_scale 64 | train_wall 3481 | gb_free 8.7 | wall 55838
2023-05-08 15:26:36 - trainer.py[line:639] - INFO: loading train data for epoch 17
local datafile ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 0 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 1 finished initializing row_count and line_idx-to-offset mapping
file ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 1 row count 27700 total row count 55400
slice_id 1 seek offset 27700
local datafile ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 0 finished initializing row_count and line_idx-to-offset mapping
file ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 0 row count 27700 total row count 55400
slice_id 0 seek offset 0
2023-05-08 15:26:38 - trainer.py[line:703] - INFO: begin training epoch 17
2023-05-08 15:26:38 - train.py[line:305] - INFO: Start iterating over samples
2023-05-08 15:27:19 - progress_bar.py[line:272] - INFO: epoch 017:     10 / 866 loss=2.152, loss_v1=0, loss_v2=0, nll_loss=0.923, ntokens=2137.4, nsentences=64, sample_size=2137.4, sample_size_v1=0, sample_size_v2=0, ppl=1.9, wps=500.5, ups=0.23, wpb=2137.4, bsz=64, num_updates=13840, lr=1.49128e-05, gnorm=5.067, clip=100, loss_scale=64, train_wall=41, gb_free=6.3, wall=55880
2023-05-08 15:28:00 - progress_bar.py[line:272] - INFO: epoch 017:     20 / 866 loss=2.125, loss_v1=0, loss_v2=0, nll_loss=0.895, ntokens=2050.9, nsentences=64, sample_size=2050.9, sample_size_v1=0, sample_size_v2=0, ppl=1.86, wps=503.5, ups=0.25, wpb=2050.9, bsz=64, num_updates=13850, lr=1.49005e-05, gnorm=5.112, clip=100, loss_scale=64, train_wall=41, gb_free=7.8, wall=55921
2023-05-08 15:28:40 - progress_bar.py[line:272] - INFO: epoch 017:     30 / 866 loss=2.134, loss_v1=0, loss_v2=0, nll_loss=0.904, ntokens=1987.5, nsentences=64, sample_size=1987.5, sample_size_v1=0, sample_size_v2=0, ppl=1.87, wps=492.3, ups=0.25, wpb=1987.5, bsz=64, num_updates=13860, lr=1.48882e-05, gnorm=5.266, clip=100, loss_scale=64, train_wall=40, gb_free=7.4, wall=55961
2023-05-08 15:29:22 - progress_bar.py[line:272] - INFO: epoch 017:     40 / 866 loss=2.076, loss_v1=0, loss_v2=0, nll_loss=0.839, ntokens=2238.7, nsentences=64, sample_size=2238.7, sample_size_v1=0, sample_size_v2=0, ppl=1.79, wps=539, ups=0.24, wpb=2238.7, bsz=64, num_updates=13870, lr=1.48759e-05, gnorm=4.6, clip=100, loss_scale=64, train_wall=41, gb_free=7.6, wall=56003
2023-05-08 15:30:02 - progress_bar.py[line:272] - INFO: epoch 017:     50 / 866 loss=2.124, loss_v1=0, loss_v2=0, nll_loss=0.895, ntokens=1995.1, nsentences=64, sample_size=1995.1, sample_size_v1=0, sample_size_v2=0, ppl=1.86, wps=494, ups=0.25, wpb=1995.1, bsz=64, num_updates=13880, lr=1.48636e-05, gnorm=5.153, clip=100, loss_scale=64, train_wall=40, gb_free=7.4, wall=56043
2023-05-08 15:30:42 - progress_bar.py[line:272] - INFO: epoch 017:     60 / 866 loss=2.045, loss_v1=0, loss_v2=0, nll_loss=0.805, ntokens=2062.8, nsentences=64, sample_size=2062.8, sample_size_v1=0, sample_size_v2=0, ppl=1.75, wps=514.3, ups=0.25, wpb=2062.8, bsz=64, num_updates=13890, lr=1.48514e-05, gnorm=5.36, clip=100, loss_scale=64, train_wall=40, gb_free=6.4, wall=56083
2023-05-08 15:31:24 - progress_bar.py[line:272] - INFO: epoch 017:     70 / 866 loss=2.047, loss_v1=0, loss_v2=0, nll_loss=0.806, ntokens=2476.7, nsentences=64, sample_size=2476.7, sample_size_v1=0, sample_size_v2=0, ppl=1.75, wps=592.2, ups=0.24, wpb=2476.7, bsz=64, num_updates=13900, lr=1.48391e-05, gnorm=3.971, clip=100, loss_scale=64, train_wall=42, gb_free=7, wall=56125
2023-05-08 15:32:06 - progress_bar.py[line:272] - INFO: epoch 017:     80 / 866 loss=2.092, loss_v1=0, loss_v2=0, nll_loss=0.855, ntokens=2320.5, nsentences=64, sample_size=2320.5, sample_size_v1=0, sample_size_v2=0, ppl=1.81, wps=559.8, ups=0.24, wpb=2320.5, bsz=64, num_updates=13910, lr=1.48268e-05, gnorm=4.502, clip=100, loss_scale=64, train_wall=41, gb_free=6.8, wall=56167
2023-05-08 15:32:46 - progress_bar.py[line:272] - INFO: epoch 017:     90 / 866 loss=2.129, loss_v1=0, loss_v2=0, nll_loss=0.898, ntokens=2123.9, nsentences=64, sample_size=2123.9, sample_size_v1=0, sample_size_v2=0, ppl=1.86, wps=519.9, ups=0.24, wpb=2123.9, bsz=64, num_updates=13920, lr=1.48145e-05, gnorm=4.673, clip=100, loss_scale=64, train_wall=41, gb_free=7.4, wall=56208
2023-05-08 15:33:27 - progress_bar.py[line:272] - INFO: epoch 017:    100 / 866 loss=2.121, loss_v1=0, loss_v2=0, nll_loss=0.891, ntokens=2077.5, nsentences=64, sample_size=2077.5, sample_size_v1=0, sample_size_v2=0, ppl=1.85, wps=514.6, ups=0.25, wpb=2077.5, bsz=64, num_updates=13930, lr=1.48022e-05, gnorm=4.971, clip=100, loss_scale=64, train_wall=40, gb_free=7.2, wall=56248
2023-05-08 15:34:07 - progress_bar.py[line:272] - INFO: epoch 017:    110 / 866 loss=2.178, loss_v1=0, loss_v2=0, nll_loss=0.954, ntokens=2029.9, nsentences=64, sample_size=2029.9, sample_size_v1=0, sample_size_v2=0, ppl=1.94, wps=504.6, ups=0.25, wpb=2029.9, bsz=64, num_updates=13940, lr=1.47899e-05, gnorm=5.221, clip=100, loss_scale=64, train_wall=40, gb_free=7.2, wall=56288
2023-05-08 15:34:48 - progress_bar.py[line:272] - INFO: epoch 017:    120 / 866 loss=2.172, loss_v1=0, loss_v2=0, nll_loss=0.945, ntokens=2169.2, nsentences=64, sample_size=2169.2, sample_size_v1=0, sample_size_v2=0, ppl=1.93, wps=523.3, ups=0.24, wpb=2169.2, bsz=64, num_updates=13950, lr=1.47777e-05, gnorm=4.778, clip=100, loss_scale=64, train_wall=41, gb_free=7, wall=56330
2023-05-08 15:35:30 - progress_bar.py[line:272] - INFO: epoch 017:    130 / 866 loss=2.164, loss_v1=0, loss_v2=0, nll_loss=0.937, ntokens=2201.3, nsentences=64, sample_size=2201.3, sample_size_v1=0, sample_size_v2=0, ppl=1.91, wps=534.1, ups=0.24, wpb=2201.3, bsz=64, num_updates=13960, lr=1.47654e-05, gnorm=4.605, clip=100, loss_scale=64, train_wall=41, gb_free=6.8, wall=56371
2023-05-08 15:36:11 - progress_bar.py[line:272] - INFO: epoch 017:    140 / 866 loss=2.135, loss_v1=0, loss_v2=0, nll_loss=0.905, ntokens=2246.8, nsentences=64, sample_size=2246.8, sample_size_v1=0, sample_size_v2=0, ppl=1.87, wps=547.3, ups=0.24, wpb=2246.8, bsz=64, num_updates=13970, lr=1.47531e-05, gnorm=4.574, clip=100, loss_scale=64, train_wall=41, gb_free=6.2, wall=56412
2023-05-08 15:36:52 - progress_bar.py[line:272] - INFO: epoch 017:    150 / 866 loss=2.122, loss_v1=0, loss_v2=0, nll_loss=0.89, ntokens=2170, nsentences=64, sample_size=2170, sample_size_v1=0, sample_size_v2=0, ppl=1.85, wps=527.1, ups=0.24, wpb=2170, bsz=64, num_updates=13980, lr=1.47408e-05, gnorm=4.653, clip=100, loss_scale=64, train_wall=41, gb_free=7.3, wall=56453
2023-05-08 15:37:33 - progress_bar.py[line:272] - INFO: epoch 017:    160 / 866 loss=2.156, loss_v1=0, loss_v2=0, nll_loss=0.927, ntokens=2205.1, nsentences=64, sample_size=2205.1, sample_size_v1=0, sample_size_v2=0, ppl=1.9, wps=537.2, ups=0.24, wpb=2205.1, bsz=64, num_updates=13990, lr=1.47285e-05, gnorm=5.052, clip=100, loss_scale=64, train_wall=41, gb_free=7.5, wall=56494
2023-05-08 15:38:14 - progress_bar.py[line:272] - INFO: epoch 017:    170 / 866 loss=2.153, loss_v1=0, loss_v2=0, nll_loss=0.924, ntokens=2090.1, nsentences=64, sample_size=2090.1, sample_size_v1=0, sample_size_v2=0, ppl=1.9, wps=514.7, ups=0.25, wpb=2090.1, bsz=64, num_updates=14000, lr=1.47162e-05, gnorm=5.032, clip=100, loss_scale=64, train_wall=41, gb_free=7.6, wall=56535
2023-05-08 15:38:55 - progress_bar.py[line:272] - INFO: epoch 017:    180 / 866 loss=2.141, loss_v1=0, loss_v2=0, nll_loss=0.911, ntokens=2119.6, nsentences=64, sample_size=2119.6, sample_size_v1=0, sample_size_v2=0, ppl=1.88, wps=516.4, ups=0.24, wpb=2119.6, bsz=64, num_updates=14010, lr=1.4704e-05, gnorm=4.801, clip=100, loss_scale=64, train_wall=41, gb_free=7.2, wall=56576
2023-05-08 15:39:36 - progress_bar.py[line:272] - INFO: epoch 017:    190 / 866 loss=2.144, loss_v1=0, loss_v2=0, nll_loss=0.915, ntokens=2205.1, nsentences=64, sample_size=2205.1, sample_size_v1=0, sample_size_v2=0, ppl=1.89, wps=538.3, ups=0.24, wpb=2205.1, bsz=64, num_updates=14020, lr=1.46917e-05, gnorm=4.914, clip=100, loss_scale=64, train_wall=41, gb_free=6.9, wall=56617
2023-05-08 15:40:16 - progress_bar.py[line:272] - INFO: epoch 017:    200 / 866 loss=2.158, loss_v1=0, loss_v2=0, nll_loss=0.93, ntokens=2135.3, nsentences=64, sample_size=2135.3, sample_size_v1=0, sample_size_v2=0, ppl=1.91, wps=523.3, ups=0.25, wpb=2135.3, bsz=64, num_updates=14030, lr=1.46794e-05, gnorm=4.978, clip=100, loss_scale=64, train_wall=41, gb_free=8, wall=56658
2023-05-08 15:40:57 - progress_bar.py[line:272] - INFO: epoch 017:    210 / 866 loss=2.184, loss_v1=0, loss_v2=0, nll_loss=0.961, ntokens=2011.1, nsentences=64, sample_size=2011.1, sample_size_v1=0, sample_size_v2=0, ppl=1.95, wps=501, ups=0.25, wpb=2011.1, bsz=64, num_updates=14040, lr=1.46671e-05, gnorm=5.077, clip=100, loss_scale=64, train_wall=40, gb_free=7.5, wall=56698
2023-05-08 15:41:37 - progress_bar.py[line:272] - INFO: epoch 017:    220 / 866 loss=2.178, loss_v1=0, loss_v2=0, nll_loss=0.953, ntokens=2199.5, nsentences=64, sample_size=2199.5, sample_size_v1=0, sample_size_v2=0, ppl=1.94, wps=548.8, ups=0.25, wpb=2199.5, bsz=64, num_updates=14050, lr=1.46548e-05, gnorm=4.795, clip=100, loss_scale=64, train_wall=40, gb_free=7.5, wall=56738
2023-05-08 15:42:17 - progress_bar.py[line:272] - INFO: epoch 017:    230 / 866 loss=2.186, loss_v1=0, loss_v2=0, nll_loss=0.96, ntokens=2148.4, nsentences=64, sample_size=2148.4, sample_size_v1=0, sample_size_v2=0, ppl=1.95, wps=535, ups=0.25, wpb=2148.4, bsz=64, num_updates=14060, lr=1.46425e-05, gnorm=4.964, clip=100, loss_scale=64, train_wall=40, gb_free=7.3, wall=56778
2023-05-08 15:42:57 - progress_bar.py[line:272] - INFO: epoch 017:    240 / 866 loss=2.183, loss_v1=0, loss_v2=0, nll_loss=0.959, ntokens=2187.6, nsentences=64, sample_size=2187.6, sample_size_v1=0, sample_size_v2=0, ppl=1.94, wps=543.1, ups=0.25, wpb=2187.6, bsz=64, num_updates=14070, lr=1.46303e-05, gnorm=4.834, clip=100, loss_scale=64, train_wall=40, gb_free=7.1, wall=56818
2023-05-08 15:43:37 - progress_bar.py[line:272] - INFO: epoch 017:    250 / 866 loss=2.192, loss_v1=0, loss_v2=0, nll_loss=0.969, ntokens=2106.9, nsentences=64, sample_size=2106.9, sample_size_v1=0, sample_size_v2=0, ppl=1.96, wps=521.4, ups=0.25, wpb=2106.9, bsz=64, num_updates=14080, lr=1.4618e-05, gnorm=5.144, clip=100, loss_scale=64, train_wall=40, gb_free=7.1, wall=56859
2023-05-08 15:44:18 - progress_bar.py[line:272] - INFO: epoch 017:    260 / 866 loss=2.202, loss_v1=0, loss_v2=0, nll_loss=0.978, ntokens=2131.9, nsentences=64, sample_size=2131.9, sample_size_v1=0, sample_size_v2=0, ppl=1.97, wps=527.3, ups=0.25, wpb=2131.9, bsz=64, num_updates=14090, lr=1.46057e-05, gnorm=5.18, clip=100, loss_scale=64, train_wall=40, gb_free=7.4, wall=56899
2023-05-08 15:44:58 - progress_bar.py[line:272] - INFO: epoch 017:    270 / 866 loss=2.174, loss_v1=0, loss_v2=0, nll_loss=0.948, ntokens=2130.1, nsentences=64, sample_size=2130.1, sample_size_v1=0, sample_size_v2=0, ppl=1.93, wps=532.5, ups=0.25, wpb=2130.1, bsz=64, num_updates=14100, lr=1.45934e-05, gnorm=4.699, clip=100, loss_scale=64, train_wall=40, gb_free=7.1, wall=56939
2023-05-08 15:45:38 - progress_bar.py[line:272] - INFO: epoch 017:    280 / 866 loss=2.18, loss_v1=0, loss_v2=0, nll_loss=0.955, ntokens=2196.7, nsentences=64, sample_size=2196.7, sample_size_v1=0, sample_size_v2=0, ppl=1.94, wps=544.6, ups=0.25, wpb=2196.7, bsz=64, num_updates=14110, lr=1.45811e-05, gnorm=4.971, clip=100, loss_scale=64, train_wall=40, gb_free=7.2, wall=56979
2023-05-08 15:46:18 - progress_bar.py[line:272] - INFO: epoch 017:    290 / 866 loss=2.167, loss_v1=0, loss_v2=0, nll_loss=0.941, ntokens=2140.2, nsentences=64, sample_size=2140.2, sample_size_v1=0, sample_size_v2=0, ppl=1.92, wps=534.5, ups=0.25, wpb=2140.2, bsz=64, num_updates=14120, lr=1.45688e-05, gnorm=4.851, clip=100, loss_scale=64, train_wall=40, gb_free=8.2, wall=57019
2023-05-08 15:46:58 - progress_bar.py[line:272] - INFO: epoch 017:    300 / 866 loss=2.169, loss_v1=0, loss_v2=0, nll_loss=0.943, ntokens=2142.2, nsentences=64, sample_size=2142.2, sample_size_v1=0, sample_size_v2=0, ppl=1.92, wps=535.4, ups=0.25, wpb=2142.2, bsz=64, num_updates=14130, lr=1.45565e-05, gnorm=4.852, clip=100, loss_scale=64, train_wall=40, gb_free=6.8, wall=57059
2023-05-08 15:47:38 - progress_bar.py[line:272] - INFO: epoch 017:    310 / 866 loss=2.162, loss_v1=0, loss_v2=0, nll_loss=0.936, ntokens=2129.3, nsentences=64, sample_size=2129.3, sample_size_v1=0, sample_size_v2=0, ppl=1.91, wps=532.1, ups=0.25, wpb=2129.3, bsz=64, num_updates=14140, lr=1.45443e-05, gnorm=5.062, clip=100, loss_scale=64, train_wall=40, gb_free=7.1, wall=57099
2023-05-08 15:48:18 - progress_bar.py[line:272] - INFO: epoch 017:    320 / 866 loss=2.183, loss_v1=0, loss_v2=0, nll_loss=0.958, ntokens=1976.4, nsentences=64, sample_size=1976.4, sample_size_v1=0, sample_size_v2=0, ppl=1.94, wps=494.9, ups=0.25, wpb=1976.4, bsz=64, num_updates=14150, lr=1.4532e-05, gnorm=5.432, clip=100, loss_scale=64, train_wall=40, gb_free=7.7, wall=57139
2023-05-08 15:48:58 - progress_bar.py[line:272] - INFO: epoch 017:    330 / 866 loss=2.194, loss_v1=0, loss_v2=0, nll_loss=0.97, ntokens=2097.8, nsentences=64, sample_size=2097.8, sample_size_v1=0, sample_size_v2=0, ppl=1.96, wps=524.7, ups=0.25, wpb=2097.8, bsz=64, num_updates=14160, lr=1.45197e-05, gnorm=5.122, clip=100, loss_scale=64, train_wall=40, gb_free=7.8, wall=57179
2023-05-08 15:49:39 - progress_bar.py[line:272] - INFO: epoch 017:    340 / 866 loss=2.154, loss_v1=0, loss_v2=0, nll_loss=0.926, ntokens=2080.8, nsentences=64, sample_size=2080.8, sample_size_v1=0, sample_size_v2=0, ppl=1.9, wps=516.7, ups=0.25, wpb=2080.8, bsz=64, num_updates=14170, lr=1.45074e-05, gnorm=4.766, clip=100, loss_scale=64, train_wall=40, gb_free=7.8, wall=57220
2023-05-08 15:50:18 - progress_bar.py[line:272] - INFO: epoch 017:    350 / 866 loss=2.187, loss_v1=0, loss_v2=0, nll_loss=0.962, ntokens=1936.9, nsentences=64, sample_size=1936.9, sample_size_v1=0, sample_size_v2=0, ppl=1.95, wps=488.2, ups=0.25, wpb=1936.9, bsz=64, num_updates=14180, lr=1.44951e-05, gnorm=5.548, clip=100, loss_scale=64, train_wall=40, gb_free=8, wall=57259
2023-05-08 15:50:58 - progress_bar.py[line:272] - INFO: epoch 017:    360 / 866 loss=2.193, loss_v1=0, loss_v2=0, nll_loss=0.973, ntokens=1968.7, nsentences=64, sample_size=1968.7, sample_size_v1=0, sample_size_v2=0, ppl=1.96, wps=496.3, ups=0.25, wpb=1968.7, bsz=64, num_updates=14190, lr=1.44828e-05, gnorm=5.623, clip=100, loss_scale=64, train_wall=40, gb_free=7.9, wall=57299
2023-05-08 15:51:38 - progress_bar.py[line:272] - INFO: epoch 017:    370 / 866 loss=2.194, loss_v1=0, loss_v2=0, nll_loss=0.97, ntokens=1983.4, nsentences=64, sample_size=1983.4, sample_size_v1=0, sample_size_v2=0, ppl=1.96, wps=497.4, ups=0.25, wpb=1983.4, bsz=64, num_updates=14200, lr=1.44706e-05, gnorm=5.548, clip=100, loss_scale=128, train_wall=40, gb_free=8.4, wall=57339
2023-05-08 15:51:54 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2023-05-08 15:52:22 - progress_bar.py[line:272] - INFO: epoch 017:    381 / 866 loss=2.16, loss_v1=0, loss_v2=0, nll_loss=0.932, ntokens=2175.4, nsentences=64, sample_size=2175.4, sample_size_v1=0, sample_size_v2=0, ppl=1.91, wps=493.7, ups=0.23, wpb=2175.4, bsz=64, num_updates=14210, lr=1.44583e-05, gnorm=4.659, clip=100, loss_scale=64, train_wall=44, gb_free=7.7, wall=57383
2023-05-08 15:53:02 - progress_bar.py[line:272] - INFO: epoch 017:    391 / 866 loss=2.178, loss_v1=0, loss_v2=0, nll_loss=0.954, ntokens=2040.6, nsentences=64, sample_size=2040.6, sample_size_v1=0, sample_size_v2=0, ppl=1.94, wps=510.7, ups=0.25, wpb=2040.6, bsz=64, num_updates=14220, lr=1.4446e-05, gnorm=5.394, clip=100, loss_scale=64, train_wall=40, gb_free=8, wall=57423
2023-05-08 15:53:42 - progress_bar.py[line:272] - INFO: epoch 017:    401 / 866 loss=2.184, loss_v1=0, loss_v2=0, nll_loss=0.961, ntokens=2039.7, nsentences=64, sample_size=2039.7, sample_size_v1=0, sample_size_v2=0, ppl=1.95, wps=507.3, ups=0.25, wpb=2039.7, bsz=64, num_updates=14230, lr=1.44337e-05, gnorm=5.075, clip=100, loss_scale=64, train_wall=40, gb_free=7.6, wall=57463
2023-05-08 15:54:22 - progress_bar.py[line:272] - INFO: epoch 017:    411 / 866 loss=2.167, loss_v1=0, loss_v2=0, nll_loss=0.941, ntokens=2145.8, nsentences=64, sample_size=2145.8, sample_size_v1=0, sample_size_v2=0, ppl=1.92, wps=535.3, ups=0.25, wpb=2145.8, bsz=64, num_updates=14240, lr=1.44214e-05, gnorm=4.696, clip=100, loss_scale=64, train_wall=40, gb_free=7.8, wall=57503
2023-05-08 15:55:02 - progress_bar.py[line:272] - INFO: epoch 017:    421 / 866 loss=2.157, loss_v1=0, loss_v2=0, nll_loss=0.931, ntokens=2060.2, nsentences=64, sample_size=2060.2, sample_size_v1=0, sample_size_v2=0, ppl=1.91, wps=516.5, ups=0.25, wpb=2060.2, bsz=64, num_updates=14250, lr=1.44091e-05, gnorm=4.891, clip=100, loss_scale=64, train_wall=40, gb_free=7.7, wall=57543
2023-05-08 15:55:42 - progress_bar.py[line:272] - INFO: epoch 017:    431 / 866 loss=2.154, loss_v1=0, loss_v2=0, nll_loss=0.925, ntokens=2139.4, nsentences=64, sample_size=2139.4, sample_size_v1=0, sample_size_v2=0, ppl=1.9, wps=534.6, ups=0.25, wpb=2139.4, bsz=64, num_updates=14260, lr=1.43969e-05, gnorm=4.708, clip=100, loss_scale=64, train_wall=40, gb_free=7.6, wall=57583
2023-05-08 15:56:22 - progress_bar.py[line:272] - INFO: epoch 017:    441 / 866 loss=2.2, loss_v1=0, loss_v2=0, nll_loss=0.977, ntokens=2084.1, nsentences=64, sample_size=2084.1, sample_size_v1=0, sample_size_v2=0, ppl=1.97, wps=518.8, ups=0.25, wpb=2084.1, bsz=64, num_updates=14270, lr=1.43846e-05, gnorm=5.066, clip=100, loss_scale=64, train_wall=40, gb_free=7.8, wall=57623
2023-05-08 15:57:02 - progress_bar.py[line:272] - INFO: epoch 017:    451 / 866 loss=2.188, loss_v1=0, loss_v2=0, nll_loss=0.962, ntokens=1968.6, nsentences=64, sample_size=1968.6, sample_size_v1=0, sample_size_v2=0, ppl=1.95, wps=491.8, ups=0.25, wpb=1968.6, bsz=64, num_updates=14280, lr=1.43723e-05, gnorm=5.305, clip=100, loss_scale=64, train_wall=40, gb_free=7.1, wall=57663
2023-05-08 15:57:43 - progress_bar.py[line:272] - INFO: epoch 017:    461 / 866 loss=2.189, loss_v1=0, loss_v2=0, nll_loss=0.966, ntokens=2166.2, nsentences=64, sample_size=2166.2, sample_size_v1=0, sample_size_v2=0, ppl=1.95, wps=536.6, ups=0.25, wpb=2166.2, bsz=64, num_updates=14290, lr=1.436e-05, gnorm=5.174, clip=100, loss_scale=64, train_wall=40, gb_free=7.4, wall=57704
2023-05-08 15:58:23 - progress_bar.py[line:272] - INFO: epoch 017:    471 / 866 loss=2.179, loss_v1=0, loss_v2=0, nll_loss=0.954, ntokens=2148.8, nsentences=64, sample_size=2148.8, sample_size_v1=0, sample_size_v2=0, ppl=1.94, wps=535.9, ups=0.25, wpb=2148.8, bsz=64, num_updates=14300, lr=1.43477e-05, gnorm=5.135, clip=100, loss_scale=64, train_wall=40, gb_free=8, wall=57744
2023-05-08 15:59:03 - progress_bar.py[line:272] - INFO: epoch 017:    481 / 866 loss=2.18, loss_v1=0, loss_v2=0, nll_loss=0.953, ntokens=2201, nsentences=64, sample_size=2201, sample_size_v1=0, sample_size_v2=0, ppl=1.94, wps=545.2, ups=0.25, wpb=2201, bsz=64, num_updates=14310, lr=1.43354e-05, gnorm=4.981, clip=100, loss_scale=64, train_wall=40, gb_free=8.4, wall=57784
2023-05-08 15:59:43 - progress_bar.py[line:272] - INFO: epoch 017:    491 / 866 loss=2.156, loss_v1=0, loss_v2=0, nll_loss=0.929, ntokens=2074.4, nsentences=64, sample_size=2074.4, sample_size_v1=0, sample_size_v2=0, ppl=1.9, wps=516.2, ups=0.25, wpb=2074.4, bsz=64, num_updates=14320, lr=1.43232e-05, gnorm=4.999, clip=100, loss_scale=64, train_wall=40, gb_free=7, wall=57824
2023-05-08 16:00:23 - progress_bar.py[line:272] - INFO: epoch 017:    501 / 866 loss=2.164, loss_v1=0, loss_v2=0, nll_loss=0.937, ntokens=2027.2, nsentences=64, sample_size=2027.2, sample_size_v1=0, sample_size_v2=0, ppl=1.91, wps=506.1, ups=0.25, wpb=2027.2, bsz=64, num_updates=14330, lr=1.43109e-05, gnorm=5.374, clip=100, loss_scale=64, train_wall=40, gb_free=8.1, wall=57864
2023-05-08 16:01:03 - progress_bar.py[line:272] - INFO: epoch 017:    511 / 866 loss=2.215, loss_v1=0, loss_v2=0, nll_loss=0.995, ntokens=2140.6, nsentences=64, sample_size=2140.6, sample_size_v1=0, sample_size_v2=0, ppl=1.99, wps=535.6, ups=0.25, wpb=2140.6, bsz=64, num_updates=14340, lr=1.42986e-05, gnorm=5.132, clip=100, loss_scale=64, train_wall=40, gb_free=8.4, wall=57904
2023-05-08 16:01:43 - progress_bar.py[line:272] - INFO: epoch 017:    521 / 866 loss=2.159, loss_v1=0, loss_v2=0, nll_loss=0.931, ntokens=2179.5, nsentences=64, sample_size=2179.5, sample_size_v1=0, sample_size_v2=0, ppl=1.91, wps=549.3, ups=0.25, wpb=2179.5, bsz=64, num_updates=14350, lr=1.42863e-05, gnorm=4.431, clip=100, loss_scale=64, train_wall=40, gb_free=7.7, wall=57944
2023-05-08 16:02:23 - progress_bar.py[line:272] - INFO: epoch 017:    531 / 866 loss=2.175, loss_v1=0, loss_v2=0, nll_loss=0.95, ntokens=2003.1, nsentences=64, sample_size=2003.1, sample_size_v1=0, sample_size_v2=0, ppl=1.93, wps=502.1, ups=0.25, wpb=2003.1, bsz=64, num_updates=14360, lr=1.4274e-05, gnorm=5.279, clip=100, loss_scale=64, train_wall=40, gb_free=7.9, wall=57984
2023-05-08 16:03:03 - progress_bar.py[line:272] - INFO: epoch 017:    541 / 866 loss=2.174, loss_v1=0, loss_v2=0, nll_loss=0.949, ntokens=2145.8, nsentences=64, sample_size=2145.8, sample_size_v1=0, sample_size_v2=0, ppl=1.93, wps=531.7, ups=0.25, wpb=2145.8, bsz=64, num_updates=14370, lr=1.42617e-05, gnorm=4.565, clip=100, loss_scale=64, train_wall=40, gb_free=8.3, wall=58024
2023-05-08 16:03:44 - progress_bar.py[line:272] - INFO: epoch 017:    551 / 866 loss=2.189, loss_v1=0, loss_v2=0, nll_loss=0.965, ntokens=2299.8, nsentences=64, sample_size=2299.8, sample_size_v1=0, sample_size_v2=0, ppl=1.95, wps=569.8, ups=0.25, wpb=2299.8, bsz=64, num_updates=14380, lr=1.42494e-05, gnorm=4.564, clip=100, loss_scale=64, train_wall=40, gb_free=7.6, wall=58065
2023-05-08 16:04:24 - progress_bar.py[line:272] - INFO: epoch 017:    561 / 866 loss=2.184, loss_v1=0, loss_v2=0, nll_loss=0.96, ntokens=2246, nsentences=64, sample_size=2246, sample_size_v1=0, sample_size_v2=0, ppl=1.95, wps=557.4, ups=0.25, wpb=2246, bsz=64, num_updates=14390, lr=1.42372e-05, gnorm=4.807, clip=100, loss_scale=64, train_wall=40, gb_free=7.7, wall=58105
2023-05-08 16:05:04 - progress_bar.py[line:272] - INFO: epoch 017:    571 / 866 loss=2.185, loss_v1=0, loss_v2=0, nll_loss=0.96, ntokens=2220.8, nsentences=64, sample_size=2220.8, sample_size_v1=0, sample_size_v2=0, ppl=1.94, wps=555.1, ups=0.25, wpb=2220.8, bsz=64, num_updates=14400, lr=1.42249e-05, gnorm=4.509, clip=100, loss_scale=64, train_wall=40, gb_free=8.3, wall=58145
2023-05-08 16:05:44 - progress_bar.py[line:272] - INFO: epoch 017:    581 / 866 loss=2.185, loss_v1=0, loss_v2=0, nll_loss=0.961, ntokens=2124.7, nsentences=64, sample_size=2124.7, sample_size_v1=0, sample_size_v2=0, ppl=1.95, wps=527.8, ups=0.25, wpb=2124.7, bsz=64, num_updates=14410, lr=1.42126e-05, gnorm=4.768, clip=100, loss_scale=64, train_wall=40, gb_free=6.9, wall=58185
2023-05-08 16:06:24 - progress_bar.py[line:272] - INFO: epoch 017:    591 / 866 loss=2.194, loss_v1=0, loss_v2=0, nll_loss=0.97, ntokens=2033, nsentences=64, sample_size=2033, sample_size_v1=0, sample_size_v2=0, ppl=1.96, wps=505.2, ups=0.25, wpb=2033, bsz=64, num_updates=14420, lr=1.42003e-05, gnorm=5.105, clip=100, loss_scale=64, train_wall=40, gb_free=6.9, wall=58225
2023-05-08 16:07:05 - progress_bar.py[line:272] - INFO: epoch 017:    601 / 866 loss=2.143, loss_v1=0, loss_v2=0, nll_loss=0.915, ntokens=2167.4, nsentences=64, sample_size=2167.4, sample_size_v1=0, sample_size_v2=0, ppl=1.89, wps=535.6, ups=0.25, wpb=2167.4, bsz=64, num_updates=14430, lr=1.4188e-05, gnorm=4.632, clip=100, loss_scale=64, train_wall=40, gb_free=8, wall=58266
2023-05-08 16:07:45 - progress_bar.py[line:272] - INFO: epoch 017:    611 / 866 loss=2.189, loss_v1=0, loss_v2=0, nll_loss=0.967, ntokens=1954.2, nsentences=64, sample_size=1954.2, sample_size_v1=0, sample_size_v2=0, ppl=1.95, wps=489.7, ups=0.25, wpb=1954.2, bsz=64, num_updates=14440, lr=1.41757e-05, gnorm=5.315, clip=100, loss_scale=64, train_wall=40, gb_free=8.3, wall=58306
2023-05-08 16:08:25 - progress_bar.py[line:272] - INFO: epoch 017:    621 / 866 loss=2.191, loss_v1=0, loss_v2=0, nll_loss=0.965, ntokens=2011.9, nsentences=64, sample_size=2011.9, sample_size_v1=0, sample_size_v2=0, ppl=1.95, wps=503.6, ups=0.25, wpb=2011.9, bsz=64, num_updates=14450, lr=1.41635e-05, gnorm=5.061, clip=100, loss_scale=64, train_wall=40, gb_free=8.1, wall=58346
2023-05-08 16:09:05 - progress_bar.py[line:272] - INFO: epoch 017:    631 / 866 loss=2.17, loss_v1=0, loss_v2=0, nll_loss=0.944, ntokens=2024.1, nsentences=64, sample_size=2024.1, sample_size_v1=0, sample_size_v2=0, ppl=1.92, wps=506.3, ups=0.25, wpb=2024.1, bsz=64, num_updates=14460, lr=1.41512e-05, gnorm=4.71, clip=100, loss_scale=64, train_wall=40, gb_free=7.5, wall=58386
2023-05-08 16:09:45 - progress_bar.py[line:272] - INFO: epoch 017:    641 / 866 loss=2.164, loss_v1=0, loss_v2=0, nll_loss=0.937, ntokens=2038, nsentences=64, sample_size=2038, sample_size_v1=0, sample_size_v2=0, ppl=1.91, wps=511.6, ups=0.25, wpb=2038, bsz=64, num_updates=14470, lr=1.41389e-05, gnorm=5.174, clip=100, loss_scale=64, train_wall=40, gb_free=8.3, wall=58426
2023-05-08 16:10:24 - progress_bar.py[line:272] - INFO: epoch 017:    651 / 866 loss=2.179, loss_v1=0, loss_v2=0, nll_loss=0.954, ntokens=2054.8, nsentences=64, sample_size=2054.8, sample_size_v1=0, sample_size_v2=0, ppl=1.94, wps=515.2, ups=0.25, wpb=2054.8, bsz=64, num_updates=14480, lr=1.41266e-05, gnorm=4.991, clip=100, loss_scale=64, train_wall=40, gb_free=8, wall=58466
2023-05-08 16:11:04 - progress_bar.py[line:272] - INFO: epoch 017:    661 / 866 loss=2.208, loss_v1=0, loss_v2=0, nll_loss=0.987, ntokens=1912, nsentences=64, sample_size=1912, sample_size_v1=0, sample_size_v2=0, ppl=1.98, wps=480.3, ups=0.25, wpb=1912, bsz=64, num_updates=14490, lr=1.41143e-05, gnorm=5.639, clip=100, loss_scale=64, train_wall=40, gb_free=7.8, wall=58505
2023-05-08 16:11:44 - progress_bar.py[line:272] - INFO: epoch 017:    671 / 866 loss=2.18, loss_v1=0, loss_v2=0, nll_loss=0.955, ntokens=2020, nsentences=64, sample_size=2020, sample_size_v1=0, sample_size_v2=0, ppl=1.94, wps=503.2, ups=0.25, wpb=2020, bsz=64, num_updates=14500, lr=1.4102e-05, gnorm=5.213, clip=100, loss_scale=64, train_wall=40, gb_free=7.8, wall=58545
2023-05-08 16:12:24 - progress_bar.py[line:272] - INFO: epoch 017:    681 / 866 loss=2.167, loss_v1=0, loss_v2=0, nll_loss=0.938, ntokens=2053.7, nsentences=64, sample_size=2053.7, sample_size_v1=0, sample_size_v2=0, ppl=1.92, wps=512.6, ups=0.25, wpb=2053.7, bsz=64, num_updates=14510, lr=1.40898e-05, gnorm=4.922, clip=100, loss_scale=64, train_wall=40, gb_free=7.3, wall=58586
2023-05-08 16:13:05 - progress_bar.py[line:272] - INFO: epoch 017:    691 / 866 loss=2.178, loss_v1=0, loss_v2=0, nll_loss=0.955, ntokens=2002, nsentences=64, sample_size=2002, sample_size_v1=0, sample_size_v2=0, ppl=1.94, wps=494.9, ups=0.25, wpb=2002, bsz=64, num_updates=14520, lr=1.40775e-05, gnorm=5.206, clip=100, loss_scale=64, train_wall=40, gb_free=8, wall=58626
2023-05-08 16:13:45 - progress_bar.py[line:272] - INFO: epoch 017:    701 / 866 loss=2.181, loss_v1=0, loss_v2=0, nll_loss=0.956, ntokens=2092.2, nsentences=64, sample_size=2092.2, sample_size_v1=0, sample_size_v2=0, ppl=1.94, wps=519.9, ups=0.25, wpb=2092.2, bsz=64, num_updates=14530, lr=1.40652e-05, gnorm=5.241, clip=100, loss_scale=64, train_wall=40, gb_free=8.1, wall=58666
2023-05-08 16:14:25 - progress_bar.py[line:272] - INFO: epoch 017:    711 / 866 loss=2.188, loss_v1=0, loss_v2=0, nll_loss=0.963, ntokens=1922.9, nsentences=64, sample_size=1922.9, sample_size_v1=0, sample_size_v2=0, ppl=1.95, wps=481.8, ups=0.25, wpb=1922.9, bsz=64, num_updates=14540, lr=1.40529e-05, gnorm=5.325, clip=100, loss_scale=64, train_wall=40, gb_free=8.1, wall=58706
2023-05-08 16:15:05 - progress_bar.py[line:272] - INFO: epoch 017:    721 / 866 loss=2.17, loss_v1=0, loss_v2=0, nll_loss=0.945, ntokens=1920.7, nsentences=64, sample_size=1920.7, sample_size_v1=0, sample_size_v2=0, ppl=1.93, wps=479, ups=0.25, wpb=1920.7, bsz=64, num_updates=14550, lr=1.40406e-05, gnorm=5.024, clip=100, loss_scale=64, train_wall=40, gb_free=7.7, wall=58746
2023-05-08 16:15:45 - progress_bar.py[line:272] - INFO: epoch 017:    731 / 866 loss=2.153, loss_v1=0, loss_v2=0, nll_loss=0.925, ntokens=2019.1, nsentences=64, sample_size=2019.1, sample_size_v1=0, sample_size_v2=0, ppl=1.9, wps=506, ups=0.25, wpb=2019.1, bsz=64, num_updates=14560, lr=1.40283e-05, gnorm=4.989, clip=100, loss_scale=64, train_wall=40, gb_free=7.8, wall=58786
2023-05-08 16:16:25 - progress_bar.py[line:272] - INFO: epoch 017:    741 / 866 loss=2.16, loss_v1=0, loss_v2=0, nll_loss=0.932, ntokens=2131.3, nsentences=64, sample_size=2131.3, sample_size_v1=0, sample_size_v2=0, ppl=1.91, wps=531.4, ups=0.25, wpb=2131.3, bsz=64, num_updates=14570, lr=1.40161e-05, gnorm=5.064, clip=100, loss_scale=64, train_wall=40, gb_free=7.8, wall=58826
2023-05-08 16:17:05 - progress_bar.py[line:272] - INFO: epoch 017:    751 / 866 loss=2.151, loss_v1=0, loss_v2=0, nll_loss=0.922, ntokens=2103.9, nsentences=64, sample_size=2103.9, sample_size_v1=0, sample_size_v2=0, ppl=1.89, wps=524.2, ups=0.25, wpb=2103.9, bsz=64, num_updates=14580, lr=1.40038e-05, gnorm=4.889, clip=100, loss_scale=64, train_wall=40, gb_free=7.3, wall=58866
2023-05-08 16:17:45 - progress_bar.py[line:272] - INFO: epoch 017:    761 / 866 loss=2.158, loss_v1=0, loss_v2=0, nll_loss=0.933, ntokens=2112.8, nsentences=64, sample_size=2112.8, sample_size_v1=0, sample_size_v2=0, ppl=1.91, wps=528.1, ups=0.25, wpb=2112.8, bsz=64, num_updates=14590, lr=1.39915e-05, gnorm=5.199, clip=100, loss_scale=64, train_wall=40, gb_free=7.8, wall=58906
2023-05-08 16:18:25 - progress_bar.py[line:272] - INFO: epoch 017:    771 / 866 loss=2.155, loss_v1=0, loss_v2=0, nll_loss=0.929, ntokens=2055, nsentences=64, sample_size=2055, sample_size_v1=0, sample_size_v2=0, ppl=1.9, wps=514.6, ups=0.25, wpb=2055, bsz=64, num_updates=14600, lr=1.39792e-05, gnorm=5.745, clip=100, loss_scale=64, train_wall=40, gb_free=8, wall=58946
2023-05-08 16:19:06 - progress_bar.py[line:272] - INFO: epoch 017:    781 / 866 loss=2.161, loss_v1=0, loss_v2=0, nll_loss=0.932, ntokens=2337.4, nsentences=64, sample_size=2337.4, sample_size_v1=0, sample_size_v2=0, ppl=1.91, wps=578, ups=0.25, wpb=2337.4, bsz=64, num_updates=14610, lr=1.39669e-05, gnorm=5.134, clip=100, loss_scale=64, train_wall=40, gb_free=8, wall=58987
2023-05-08 16:19:45 - progress_bar.py[line:272] - INFO: epoch 017:    791 / 866 loss=2.186, loss_v1=0, loss_v2=0, nll_loss=0.963, ntokens=1979.7, nsentences=64, sample_size=1979.7, sample_size_v1=0, sample_size_v2=0, ppl=1.95, wps=497.4, ups=0.25, wpb=1979.7, bsz=64, num_updates=14620, lr=1.39546e-05, gnorm=5.147, clip=100, loss_scale=64, train_wall=40, gb_free=7.7, wall=59027
2023-05-08 16:20:25 - progress_bar.py[line:272] - INFO: epoch 017:    801 / 866 loss=2.171, loss_v1=0, loss_v2=0, nll_loss=0.945, ntokens=2007.4, nsentences=64, sample_size=2007.4, sample_size_v1=0, sample_size_v2=0, ppl=1.93, wps=504.9, ups=0.25, wpb=2007.4, bsz=64, num_updates=14630, lr=1.39423e-05, gnorm=5.156, clip=100, loss_scale=64, train_wall=40, gb_free=7.4, wall=59066
2023-05-08 16:21:05 - progress_bar.py[line:272] - INFO: epoch 017:    811 / 866 loss=2.15, loss_v1=0, loss_v2=0, nll_loss=0.919, ntokens=2059.7, nsentences=64, sample_size=2059.7, sample_size_v1=0, sample_size_v2=0, ppl=1.89, wps=514.2, ups=0.25, wpb=2059.7, bsz=64, num_updates=14640, lr=1.39301e-05, gnorm=5.119, clip=100, loss_scale=64, train_wall=40, gb_free=7.9, wall=59106
2023-05-08 16:21:45 - progress_bar.py[line:272] - INFO: epoch 017:    821 / 866 loss=2.147, loss_v1=0, loss_v2=0, nll_loss=0.918, ntokens=2072.2, nsentences=64, sample_size=2072.2, sample_size_v1=0, sample_size_v2=0, ppl=1.89, wps=517.4, ups=0.25, wpb=2072.2, bsz=64, num_updates=14650, lr=1.39178e-05, gnorm=4.969, clip=100, loss_scale=64, train_wall=40, gb_free=6.3, wall=59146
2023-05-08 16:22:27 - progress_bar.py[line:272] - INFO: epoch 017:    831 / 866 loss=2.142, loss_v1=0, loss_v2=0, nll_loss=0.915, ntokens=2201.4, nsentences=64, sample_size=2201.4, sample_size_v1=0, sample_size_v2=0, ppl=1.89, wps=534.2, ups=0.24, wpb=2201.4, bsz=64, num_updates=14660, lr=1.39055e-05, gnorm=4.531, clip=100, loss_scale=64, train_wall=41, gb_free=7.9, wall=59188
2023-05-08 16:23:07 - progress_bar.py[line:272] - INFO: epoch 017:    841 / 866 loss=2.154, loss_v1=0, loss_v2=0, nll_loss=0.926, ntokens=2111.2, nsentences=64, sample_size=2111.2, sample_size_v1=0, sample_size_v2=0, ppl=1.9, wps=525, ups=0.25, wpb=2111.2, bsz=64, num_updates=14670, lr=1.38932e-05, gnorm=4.804, clip=100, loss_scale=64, train_wall=40, gb_free=8.1, wall=59228
2023-05-08 16:23:47 - progress_bar.py[line:272] - INFO: epoch 017:    851 / 866 loss=2.148, loss_v1=0, loss_v2=0, nll_loss=0.919, ntokens=2219.1, nsentences=64, sample_size=2219.1, sample_size_v1=0, sample_size_v2=0, ppl=1.89, wps=549.6, ups=0.25, wpb=2219.1, bsz=64, num_updates=14680, lr=1.38809e-05, gnorm=4.374, clip=100, loss_scale=64, train_wall=40, gb_free=7.7, wall=59268
2023-05-08 16:24:27 - progress_bar.py[line:272] - INFO: epoch 017:    861 / 866 loss=2.154, loss_v1=0, loss_v2=0, nll_loss=0.929, ntokens=2050.8, nsentences=64, sample_size=2050.8, sample_size_v1=0, sample_size_v2=0, ppl=1.9, wps=511.1, ups=0.25, wpb=2050.8, bsz=64, num_updates=14690, lr=1.38686e-05, gnorm=5.051, clip=100, loss_scale=64, train_wall=40, gb_free=7.6, wall=59308
2023-05-08 16:24:46 - train.py[line:332] - INFO: end of epoch 17 (average epoch stats below)
2023-05-08 16:24:46 - progress_bar.py[line:282] - INFO: epoch 017 | loss 2.163 | loss_v1 0 | loss_v2 0 | nll_loss 0.936 | ntokens 2102.68 | nsentences 63.972 | sample_size 2102.68 | sample_size_v1 0 | sample_size_v2 0 | ppl 1.91 | wps 521.2 | ups 0.25 | wpb 2102.7 | bsz 64 | num_updates 14695 | lr 1.38625e-05 | gnorm 4.988 | clip 100 | loss_scale 64 | train_wall 3483 | gb_free 8.7 | wall 59327
2023-05-08 16:24:46 - trainer.py[line:639] - INFO: loading train data for epoch 18
local datafile ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 0 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 1 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 0 finished initializing row_count and line_idx-to-offset mapping
file ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 0 row count 27700 total row count 55400
slice_id 0 seek offset 0
2023-05-08 16:24:48 - trainer.py[line:703] - INFO: begin training epoch 18
2023-05-08 16:24:48 - train.py[line:305] - INFO: Start iterating over samples
local datafile ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 1 finished initializing row_count and line_idx-to-offset mapping
file ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 1 row count 27700 total row count 55400
slice_id 1 seek offset 27700
2023-05-08 16:25:12 - progress_bar.py[line:272] - INFO: epoch 018:      5 / 866 loss=2.152, loss_v1=0, loss_v2=0, nll_loss=0.925, ntokens=2048.9, nsentences=61.6, sample_size=2048.9, sample_size_v1=0, sample_size_v2=0, ppl=1.9, wps=461.9, ups=0.23, wpb=2048.9, bsz=61.6, num_updates=14700, lr=1.38564e-05, gnorm=5.11, clip=100, loss_scale=64, train_wall=42, gb_free=7.5, wall=59353
2023-05-08 16:26:09 - progress_bar.py[line:272] - INFO: epoch 018:     15 / 866 loss=2.141, loss_v1=0, loss_v2=0, nll_loss=0.909, ntokens=2078.3, nsentences=64, sample_size=2078.3, sample_size_v1=0, sample_size_v2=0, ppl=1.88, wps=365.6, ups=0.18, wpb=2078.3, bsz=64, num_updates=14710, lr=1.38441e-05, gnorm=4.961, clip=100, loss_scale=64, train_wall=57, gb_free=7.3, wall=59410
2023-05-08 16:26:51 - progress_bar.py[line:272] - INFO: epoch 018:     25 / 866 loss=2.104, loss_v1=0, loss_v2=0, nll_loss=0.871, ntokens=1994.7, nsentences=64, sample_size=1994.7, sample_size_v1=0, sample_size_v2=0, ppl=1.83, wps=464.7, ups=0.23, wpb=1994.7, bsz=64, num_updates=14720, lr=1.38318e-05, gnorm=5.03, clip=100, loss_scale=128, train_wall=43, gb_free=8.3, wall=59453
2023-05-08 16:27:29 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2023-05-08 16:27:37 - progress_bar.py[line:272] - INFO: epoch 018:     36 / 866 loss=2.073, loss_v1=0, loss_v2=0, nll_loss=0.835, ntokens=2168.3, nsentences=64, sample_size=2168.3, sample_size_v1=0, sample_size_v2=0, ppl=1.78, wps=473.4, ups=0.22, wpb=2168.3, bsz=64, num_updates=14730, lr=1.38195e-05, gnorm=4.567, clip=100, loss_scale=64, train_wall=46, gb_free=6.6, wall=59498
2023-05-08 16:28:36 - progress_bar.py[line:272] - INFO: epoch 018:     46 / 866 loss=2.087, loss_v1=0, loss_v2=0, nll_loss=0.851, ntokens=2017.3, nsentences=64, sample_size=2017.3, sample_size_v1=0, sample_size_v2=0, ppl=1.8, wps=344.5, ups=0.17, wpb=2017.3, bsz=64, num_updates=14740, lr=1.38072e-05, gnorm=4.948, clip=100, loss_scale=64, train_wall=58, gb_free=8, wall=59557
2023-05-08 16:29:17 - progress_bar.py[line:272] - INFO: epoch 018:     56 / 866 loss=2.068, loss_v1=0, loss_v2=0, nll_loss=0.833, ntokens=2095.1, nsentences=64, sample_size=2095.1, sample_size_v1=0, sample_size_v2=0, ppl=1.78, wps=512.4, ups=0.24, wpb=2095.1, bsz=64, num_updates=14750, lr=1.37949e-05, gnorm=5.259, clip=100, loss_scale=64, train_wall=41, gb_free=7.8, wall=59598
2023-05-08 16:29:58 - progress_bar.py[line:272] - INFO: epoch 018:     66 / 866 loss=2.008, loss_v1=0, loss_v2=0, nll_loss=0.762, ntokens=2319.7, nsentences=64, sample_size=2319.7, sample_size_v1=0, sample_size_v2=0, ppl=1.7, wps=560.5, ups=0.24, wpb=2319.7, bsz=64, num_updates=14760, lr=1.37827e-05, gnorm=4.82, clip=100, loss_scale=64, train_wall=41, gb_free=6.7, wall=59639
2023-05-08 16:30:40 - progress_bar.py[line:272] - INFO: epoch 018:     76 / 866 loss=2.06, loss_v1=0, loss_v2=0, nll_loss=0.821, ntokens=2406.4, nsentences=64, sample_size=2406.4, sample_size_v1=0, sample_size_v2=0, ppl=1.77, wps=576.4, ups=0.24, wpb=2406.4, bsz=64, num_updates=14770, lr=1.37704e-05, gnorm=4.559, clip=100, loss_scale=64, train_wall=42, gb_free=6.3, wall=59681
2023-05-08 16:31:21 - progress_bar.py[line:272] - INFO: epoch 018:     86 / 866 loss=2.105, loss_v1=0, loss_v2=0, nll_loss=0.87, ntokens=2127.2, nsentences=64, sample_size=2127.2, sample_size_v1=0, sample_size_v2=0, ppl=1.83, wps=516.2, ups=0.24, wpb=2127.2, bsz=64, num_updates=14780, lr=1.37581e-05, gnorm=4.711, clip=100, loss_scale=64, train_wall=41, gb_free=7.1, wall=59722
2023-05-08 16:32:02 - progress_bar.py[line:272] - INFO: epoch 018:     96 / 866 loss=2.088, loss_v1=0, loss_v2=0, nll_loss=0.852, ntokens=2135.5, nsentences=64, sample_size=2135.5, sample_size_v1=0, sample_size_v2=0, ppl=1.81, wps=523.8, ups=0.25, wpb=2135.5, bsz=64, num_updates=14790, lr=1.37458e-05, gnorm=4.696, clip=100, loss_scale=64, train_wall=41, gb_free=6.6, wall=59763
2023-05-08 16:32:42 - progress_bar.py[line:272] - INFO: epoch 018:    106 / 866 loss=2.146, loss_v1=0, loss_v2=0, nll_loss=0.919, ntokens=2037, nsentences=64, sample_size=2037, sample_size_v1=0, sample_size_v2=0, ppl=1.89, wps=502.9, ups=0.25, wpb=2037, bsz=64, num_updates=14800, lr=1.37335e-05, gnorm=5.148, clip=100, loss_scale=64, train_wall=40, gb_free=6.5, wall=59803
2023-05-08 16:33:23 - progress_bar.py[line:272] - INFO: epoch 018:    116 / 866 loss=2.166, loss_v1=0, loss_v2=0, nll_loss=0.939, ntokens=2065.5, nsentences=64, sample_size=2065.5, sample_size_v1=0, sample_size_v2=0, ppl=1.92, wps=508.2, ups=0.25, wpb=2065.5, bsz=64, num_updates=14810, lr=1.37212e-05, gnorm=4.918, clip=100, loss_scale=64, train_wall=41, gb_free=6.7, wall=59844
2023-05-08 16:34:04 - progress_bar.py[line:272] - INFO: epoch 018:    126 / 866 loss=2.144, loss_v1=0, loss_v2=0, nll_loss=0.915, ntokens=2234.5, nsentences=64, sample_size=2234.5, sample_size_v1=0, sample_size_v2=0, ppl=1.89, wps=542.2, ups=0.24, wpb=2234.5, bsz=64, num_updates=14820, lr=1.3709e-05, gnorm=4.807, clip=100, loss_scale=64, train_wall=41, gb_free=7.5, wall=59885
2023-05-08 16:34:45 - progress_bar.py[line:272] - INFO: epoch 018:    136 / 866 loss=2.124, loss_v1=0, loss_v2=0, nll_loss=0.891, ntokens=2248.4, nsentences=64, sample_size=2248.4, sample_size_v1=0, sample_size_v2=0, ppl=1.85, wps=550.1, ups=0.24, wpb=2248.4, bsz=64, num_updates=14830, lr=1.36967e-05, gnorm=4.799, clip=100, loss_scale=64, train_wall=41, gb_free=6.6, wall=59926
2023-05-08 16:35:26 - progress_bar.py[line:272] - INFO: epoch 018:    146 / 866 loss=2.101, loss_v1=0, loss_v2=0, nll_loss=0.868, ntokens=2176.4, nsentences=64, sample_size=2176.4, sample_size_v1=0, sample_size_v2=0, ppl=1.82, wps=528.2, ups=0.24, wpb=2176.4, bsz=64, num_updates=14840, lr=1.36844e-05, gnorm=4.737, clip=100, loss_scale=64, train_wall=41, gb_free=6.9, wall=59967
2023-05-08 16:36:08 - progress_bar.py[line:272] - INFO: epoch 018:    156 / 866 loss=2.133, loss_v1=0, loss_v2=0, nll_loss=0.903, ntokens=2231.2, nsentences=64, sample_size=2231.2, sample_size_v1=0, sample_size_v2=0, ppl=1.87, wps=540.5, ups=0.24, wpb=2231.2, bsz=64, num_updates=14850, lr=1.36721e-05, gnorm=4.866, clip=100, loss_scale=64, train_wall=41, gb_free=7.2, wall=60009
2023-05-08 16:36:48 - progress_bar.py[line:272] - INFO: epoch 018:    166 / 866 loss=2.12, loss_v1=0, loss_v2=0, nll_loss=0.887, ntokens=2161.1, nsentences=64, sample_size=2161.1, sample_size_v1=0, sample_size_v2=0, ppl=1.85, wps=533.2, ups=0.25, wpb=2161.1, bsz=64, num_updates=14860, lr=1.36598e-05, gnorm=4.963, clip=100, loss_scale=64, train_wall=40, gb_free=6.6, wall=60049
2023-05-08 16:37:29 - progress_bar.py[line:272] - INFO: epoch 018:    176 / 866 loss=2.14, loss_v1=0, loss_v2=0, nll_loss=0.909, ntokens=2050, nsentences=64, sample_size=2050, sample_size_v1=0, sample_size_v2=0, ppl=1.88, wps=504.7, ups=0.25, wpb=2050, bsz=64, num_updates=14870, lr=1.36475e-05, gnorm=5.092, clip=100, loss_scale=64, train_wall=41, gb_free=7.1, wall=60090
2023-05-08 16:38:10 - progress_bar.py[line:272] - INFO: epoch 018:    186 / 866 loss=2.114, loss_v1=0, loss_v2=0, nll_loss=0.882, ntokens=2187.5, nsentences=64, sample_size=2187.5, sample_size_v1=0, sample_size_v2=0, ppl=1.84, wps=534.1, ups=0.24, wpb=2187.5, bsz=64, num_updates=14880, lr=1.36352e-05, gnorm=5.107, clip=100, loss_scale=64, train_wall=41, gb_free=7.3, wall=60131
2023-05-08 16:38:51 - progress_bar.py[line:272] - INFO: epoch 018:    196 / 866 loss=2.128, loss_v1=0, loss_v2=0, nll_loss=0.897, ntokens=2200.1, nsentences=64, sample_size=2200.1, sample_size_v1=0, sample_size_v2=0, ppl=1.86, wps=537, ups=0.24, wpb=2200.1, bsz=64, num_updates=14890, lr=1.3623e-05, gnorm=4.76, clip=100, loss_scale=64, train_wall=41, gb_free=7.4, wall=60172
2023-05-08 16:39:31 - progress_bar.py[line:272] - INFO: epoch 018:    206 / 866 loss=2.145, loss_v1=0, loss_v2=0, nll_loss=0.915, ntokens=1976.2, nsentences=64, sample_size=1976.2, sample_size_v1=0, sample_size_v2=0, ppl=1.89, wps=491.7, ups=0.25, wpb=1976.2, bsz=64, num_updates=14900, lr=1.36107e-05, gnorm=5.059, clip=100, loss_scale=64, train_wall=40, gb_free=7.7, wall=60212
2023-05-08 16:40:11 - progress_bar.py[line:272] - INFO: epoch 018:    216 / 866 loss=2.165, loss_v1=0, loss_v2=0, nll_loss=0.94, ntokens=2173.5, nsentences=64, sample_size=2173.5, sample_size_v1=0, sample_size_v2=0, ppl=1.92, wps=539.7, ups=0.25, wpb=2173.5, bsz=64, num_updates=14910, lr=1.35984e-05, gnorm=4.667, clip=100, loss_scale=64, train_wall=40, gb_free=8.1, wall=60252
2023-05-08 16:40:51 - progress_bar.py[line:272] - INFO: epoch 018:    226 / 866 loss=2.155, loss_v1=0, loss_v2=0, nll_loss=0.927, ntokens=2179, nsentences=64, sample_size=2179, sample_size_v1=0, sample_size_v2=0, ppl=1.9, wps=543.1, ups=0.25, wpb=2179, bsz=64, num_updates=14920, lr=1.35861e-05, gnorm=4.801, clip=100, loss_scale=64, train_wall=40, gb_free=7.8, wall=60292
2023-05-08 16:41:31 - progress_bar.py[line:272] - INFO: epoch 018:    236 / 866 loss=2.183, loss_v1=0, loss_v2=0, nll_loss=0.956, ntokens=2107.4, nsentences=64, sample_size=2107.4, sample_size_v1=0, sample_size_v2=0, ppl=1.94, wps=526.7, ups=0.25, wpb=2107.4, bsz=64, num_updates=14930, lr=1.35738e-05, gnorm=5.249, clip=100, loss_scale=64, train_wall=40, gb_free=7.7, wall=60332
2023-05-08 16:42:12 - progress_bar.py[line:272] - INFO: epoch 018:    246 / 866 loss=2.159, loss_v1=0, loss_v2=0, nll_loss=0.933, ntokens=2213.1, nsentences=64, sample_size=2213.1, sample_size_v1=0, sample_size_v2=0, ppl=1.91, wps=546.5, ups=0.25, wpb=2213.1, bsz=64, num_updates=14940, lr=1.35615e-05, gnorm=4.829, clip=100, loss_scale=64, train_wall=40, gb_free=8, wall=60373
2023-05-08 16:42:52 - progress_bar.py[line:272] - INFO: epoch 018:    256 / 866 loss=2.158, loss_v1=0, loss_v2=0, nll_loss=0.93, ntokens=2108.5, nsentences=64, sample_size=2108.5, sample_size_v1=0, sample_size_v2=0, ppl=1.91, wps=525.2, ups=0.25, wpb=2108.5, bsz=64, num_updates=14950, lr=1.35493e-05, gnorm=4.791, clip=100, loss_scale=64, train_wall=40, gb_free=7.7, wall=60413
2023-05-08 16:43:32 - progress_bar.py[line:272] - INFO: epoch 018:    266 / 866 loss=2.164, loss_v1=0, loss_v2=0, nll_loss=0.937, ntokens=2109.6, nsentences=64, sample_size=2109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.92, wps=525.4, ups=0.25, wpb=2109.6, bsz=64, num_updates=14960, lr=1.3537e-05, gnorm=5.079, clip=100, loss_scale=64, train_wall=40, gb_free=6.8, wall=60453
2023-05-08 16:44:12 - progress_bar.py[line:272] - INFO: epoch 018:    276 / 866 loss=2.153, loss_v1=0, loss_v2=0, nll_loss=0.924, ntokens=2168.3, nsentences=64, sample_size=2168.3, sample_size_v1=0, sample_size_v2=0, ppl=1.9, wps=539.8, ups=0.25, wpb=2168.3, bsz=64, num_updates=14970, lr=1.35247e-05, gnorm=4.735, clip=100, loss_scale=64, train_wall=40, gb_free=7.1, wall=60493
2023-05-08 16:44:52 - progress_bar.py[line:272] - INFO: epoch 018:    286 / 866 loss=2.157, loss_v1=0, loss_v2=0, nll_loss=0.933, ntokens=2179.9, nsentences=64, sample_size=2179.9, sample_size_v1=0, sample_size_v2=0, ppl=1.91, wps=542.6, ups=0.25, wpb=2179.9, bsz=64, num_updates=14980, lr=1.35124e-05, gnorm=5.149, clip=100, loss_scale=64, train_wall=40, gb_free=7.5, wall=60534
2023-05-08 16:45:33 - progress_bar.py[line:272] - INFO: epoch 018:    296 / 866 loss=2.14, loss_v1=0, loss_v2=0, nll_loss=0.91, ntokens=2147.9, nsentences=64, sample_size=2147.9, sample_size_v1=0, sample_size_v2=0, ppl=1.88, wps=534.1, ups=0.25, wpb=2147.9, bsz=64, num_updates=14990, lr=1.35001e-05, gnorm=5.18, clip=100, loss_scale=64, train_wall=40, gb_free=7.2, wall=60574
2023-05-08 16:46:13 - progress_bar.py[line:272] - INFO: epoch 018:    306 / 866 loss=2.144, loss_v1=0, loss_v2=0, nll_loss=0.914, ntokens=2129.4, nsentences=64, sample_size=2129.4, sample_size_v1=0, sample_size_v2=0, ppl=1.88, wps=530.7, ups=0.25, wpb=2129.4, bsz=64, num_updates=15000, lr=1.34878e-05, gnorm=4.921, clip=100, loss_scale=64, train_wall=40, gb_free=7.2, wall=60614
2023-05-08 16:46:53 - progress_bar.py[line:272] - INFO: epoch 018:    316 / 866 loss=2.152, loss_v1=0, loss_v2=0, nll_loss=0.925, ntokens=2049.6, nsentences=64, sample_size=2049.6, sample_size_v1=0, sample_size_v2=0, ppl=1.9, wps=512, ups=0.25, wpb=2049.6, bsz=64, num_updates=15010, lr=1.34756e-05, gnorm=5.107, clip=100, loss_scale=64, train_wall=40, gb_free=7, wall=60654
2023-05-08 16:47:33 - progress_bar.py[line:272] - INFO: epoch 018:    326 / 866 loss=2.177, loss_v1=0, loss_v2=0, nll_loss=0.953, ntokens=2016.2, nsentences=64, sample_size=2016.2, sample_size_v1=0, sample_size_v2=0, ppl=1.94, wps=506.8, ups=0.25, wpb=2016.2, bsz=64, num_updates=15020, lr=1.34633e-05, gnorm=5.011, clip=100, loss_scale=64, train_wall=40, gb_free=8, wall=60694
2023-05-08 16:48:13 - progress_bar.py[line:272] - INFO: epoch 018:    336 / 866 loss=2.135, loss_v1=0, loss_v2=0, nll_loss=0.903, ntokens=2129.6, nsentences=64, sample_size=2129.6, sample_size_v1=0, sample_size_v2=0, ppl=1.87, wps=532.1, ups=0.25, wpb=2129.6, bsz=64, num_updates=15030, lr=1.3451e-05, gnorm=4.635, clip=100, loss_scale=64, train_wall=40, gb_free=7.7, wall=60734
2023-05-08 16:48:53 - progress_bar.py[line:272] - INFO: epoch 018:    346 / 866 loss=2.152, loss_v1=0, loss_v2=0, nll_loss=0.924, ntokens=1943.9, nsentences=64, sample_size=1943.9, sample_size_v1=0, sample_size_v2=0, ppl=1.9, wps=487, ups=0.25, wpb=1943.9, bsz=64, num_updates=15040, lr=1.34387e-05, gnorm=5.044, clip=100, loss_scale=64, train_wall=40, gb_free=7.7, wall=60774
2023-05-08 16:49:32 - progress_bar.py[line:272] - INFO: epoch 018:    356 / 866 loss=2.184, loss_v1=0, loss_v2=0, nll_loss=0.961, ntokens=1991.6, nsentences=64, sample_size=1991.6, sample_size_v1=0, sample_size_v2=0, ppl=1.95, wps=502, ups=0.25, wpb=1991.6, bsz=64, num_updates=15050, lr=1.34264e-05, gnorm=5.479, clip=100, loss_scale=64, train_wall=40, gb_free=8.3, wall=60813
2023-05-08 16:50:12 - progress_bar.py[line:272] - INFO: epoch 018:    366 / 866 loss=2.158, loss_v1=0, loss_v2=0, nll_loss=0.932, ntokens=1975.6, nsentences=64, sample_size=1975.6, sample_size_v1=0, sample_size_v2=0, ppl=1.91, wps=497.1, ups=0.25, wpb=1975.6, bsz=64, num_updates=15060, lr=1.34141e-05, gnorm=5.226, clip=100, loss_scale=64, train_wall=40, gb_free=8.1, wall=60853
2023-05-08 16:50:52 - progress_bar.py[line:272] - INFO: epoch 018:    376 / 866 loss=2.161, loss_v1=0, loss_v2=0, nll_loss=0.932, ntokens=2108.1, nsentences=64, sample_size=2108.1, sample_size_v1=0, sample_size_v2=0, ppl=1.91, wps=527, ups=0.25, wpb=2108.1, bsz=64, num_updates=15070, lr=1.34019e-05, gnorm=5.202, clip=100, loss_scale=64, train_wall=40, gb_free=7.8, wall=60893
2023-05-08 16:51:32 - progress_bar.py[line:272] - INFO: epoch 018:    386 / 866 loss=2.144, loss_v1=0, loss_v2=0, nll_loss=0.915, ntokens=2138, nsentences=64, sample_size=2138, sample_size_v1=0, sample_size_v2=0, ppl=1.89, wps=529.2, ups=0.25, wpb=2138, bsz=64, num_updates=15080, lr=1.33896e-05, gnorm=4.78, clip=100, loss_scale=64, train_wall=40, gb_free=7.7, wall=60933
2023-05-08 16:52:12 - progress_bar.py[line:272] - INFO: epoch 018:    396 / 866 loss=2.165, loss_v1=0, loss_v2=0, nll_loss=0.94, ntokens=2024.2, nsentences=64, sample_size=2024.2, sample_size_v1=0, sample_size_v2=0, ppl=1.92, wps=508.2, ups=0.25, wpb=2024.2, bsz=64, num_updates=15090, lr=1.33773e-05, gnorm=5.349, clip=100, loss_scale=64, train_wall=40, gb_free=7.2, wall=60973
2023-05-08 16:52:52 - progress_bar.py[line:272] - INFO: epoch 018:    406 / 866 loss=2.145, loss_v1=0, loss_v2=0, nll_loss=0.915, ntokens=2079.1, nsentences=64, sample_size=2079.1, sample_size_v1=0, sample_size_v2=0, ppl=1.89, wps=519.9, ups=0.25, wpb=2079.1, bsz=64, num_updates=15100, lr=1.3365e-05, gnorm=5.009, clip=100, loss_scale=64, train_wall=40, gb_free=7.5, wall=61013
2023-05-08 16:53:32 - progress_bar.py[line:272] - INFO: epoch 018:    416 / 866 loss=2.142, loss_v1=0, loss_v2=0, nll_loss=0.913, ntokens=2132.3, nsentences=64, sample_size=2132.3, sample_size_v1=0, sample_size_v2=0, ppl=1.88, wps=532.1, ups=0.25, wpb=2132.3, bsz=64, num_updates=15110, lr=1.33527e-05, gnorm=4.953, clip=100, loss_scale=64, train_wall=40, gb_free=7.9, wall=61053
2023-05-08 16:54:12 - progress_bar.py[line:272] - INFO: epoch 018:    426 / 866 loss=2.124, loss_v1=0, loss_v2=0, nll_loss=0.893, ntokens=2080.3, nsentences=64, sample_size=2080.3, sample_size_v1=0, sample_size_v2=0, ppl=1.86, wps=519.1, ups=0.25, wpb=2080.3, bsz=64, num_updates=15120, lr=1.33404e-05, gnorm=4.658, clip=100, loss_scale=64, train_wall=40, gb_free=7.3, wall=61093
2023-05-08 16:54:52 - progress_bar.py[line:272] - INFO: epoch 018:    436 / 866 loss=2.163, loss_v1=0, loss_v2=0, nll_loss=0.936, ntokens=2138.3, nsentences=64, sample_size=2138.3, sample_size_v1=0, sample_size_v2=0, ppl=1.91, wps=536, ups=0.25, wpb=2138.3, bsz=64, num_updates=15130, lr=1.33281e-05, gnorm=4.807, clip=100, loss_scale=64, train_wall=40, gb_free=7.3, wall=61133
2023-05-08 16:55:32 - progress_bar.py[line:272] - INFO: epoch 018:    446 / 866 loss=2.178, loss_v1=0, loss_v2=0, nll_loss=0.952, ntokens=2024.4, nsentences=64, sample_size=2024.4, sample_size_v1=0, sample_size_v2=0, ppl=1.93, wps=502.8, ups=0.25, wpb=2024.4, bsz=64, num_updates=15140, lr=1.33159e-05, gnorm=5.584, clip=100, loss_scale=64, train_wall=40, gb_free=7.2, wall=61174
2023-05-08 16:56:13 - progress_bar.py[line:272] - INFO: epoch 018:    456 / 866 loss=2.163, loss_v1=0, loss_v2=0, nll_loss=0.936, ntokens=2040.8, nsentences=64, sample_size=2040.8, sample_size_v1=0, sample_size_v2=0, ppl=1.91, wps=506.4, ups=0.25, wpb=2040.8, bsz=64, num_updates=15150, lr=1.33036e-05, gnorm=5.101, clip=100, loss_scale=64, train_wall=40, gb_free=7.9, wall=61214
2023-05-08 16:56:53 - progress_bar.py[line:272] - INFO: epoch 018:    466 / 866 loss=2.163, loss_v1=0, loss_v2=0, nll_loss=0.937, ntokens=2147.8, nsentences=64, sample_size=2147.8, sample_size_v1=0, sample_size_v2=0, ppl=1.91, wps=535.3, ups=0.25, wpb=2147.8, bsz=64, num_updates=15160, lr=1.32913e-05, gnorm=5.003, clip=100, loss_scale=64, train_wall=40, gb_free=7.8, wall=61254
2023-05-08 16:57:33 - progress_bar.py[line:272] - INFO: epoch 018:    476 / 866 loss=2.172, loss_v1=0, loss_v2=0, nll_loss=0.945, ntokens=2236, nsentences=64, sample_size=2236, sample_size_v1=0, sample_size_v2=0, ppl=1.93, wps=552.2, ups=0.25, wpb=2236, bsz=64, num_updates=15170, lr=1.3279e-05, gnorm=4.774, clip=100, loss_scale=64, train_wall=40, gb_free=7.8, wall=61295
2023-05-08 16:58:13 - progress_bar.py[line:272] - INFO: epoch 018:    486 / 866 loss=2.15, loss_v1=0, loss_v2=0, nll_loss=0.922, ntokens=2102.6, nsentences=64, sample_size=2102.6, sample_size_v1=0, sample_size_v2=0, ppl=1.89, wps=525, ups=0.25, wpb=2102.6, bsz=64, num_updates=15180, lr=1.32667e-05, gnorm=4.762, clip=100, loss_scale=64, train_wall=40, gb_free=7.6, wall=61335
2023-05-08 16:58:53 - progress_bar.py[line:272] - INFO: epoch 018:    496 / 866 loss=2.125, loss_v1=0, loss_v2=0, nll_loss=0.893, ntokens=2024.7, nsentences=64, sample_size=2024.7, sample_size_v1=0, sample_size_v2=0, ppl=1.86, wps=506.8, ups=0.25, wpb=2024.7, bsz=64, num_updates=15190, lr=1.32544e-05, gnorm=4.948, clip=100, loss_scale=64, train_wall=40, gb_free=8.1, wall=61375
2023-05-08 16:59:33 - progress_bar.py[line:272] - INFO: epoch 018:    506 / 866 loss=2.168, loss_v1=0, loss_v2=0, nll_loss=0.941, ntokens=2098.8, nsentences=64, sample_size=2098.8, sample_size_v1=0, sample_size_v2=0, ppl=1.92, wps=525.9, ups=0.25, wpb=2098.8, bsz=64, num_updates=15200, lr=1.32422e-05, gnorm=5.13, clip=100, loss_scale=64, train_wall=40, gb_free=7.5, wall=61414
2023-05-08 17:00:13 - progress_bar.py[line:272] - INFO: epoch 018:    516 / 866 loss=2.166, loss_v1=0, loss_v2=0, nll_loss=0.939, ntokens=2219, nsentences=64, sample_size=2219, sample_size_v1=0, sample_size_v2=0, ppl=1.92, wps=555.4, ups=0.25, wpb=2219, bsz=64, num_updates=15210, lr=1.32299e-05, gnorm=4.625, clip=100, loss_scale=64, train_wall=40, gb_free=7.9, wall=61454
2023-05-08 17:00:53 - progress_bar.py[line:272] - INFO: epoch 018:    526 / 866 loss=2.153, loss_v1=0, loss_v2=0, nll_loss=0.925, ntokens=2002, nsentences=64, sample_size=2002, sample_size_v1=0, sample_size_v2=0, ppl=1.9, wps=501, ups=0.25, wpb=2002, bsz=64, num_updates=15220, lr=1.32176e-05, gnorm=5.311, clip=100, loss_scale=64, train_wall=40, gb_free=8.1, wall=61494
2023-05-08 17:01:33 - progress_bar.py[line:272] - INFO: epoch 018:    536 / 866 loss=2.137, loss_v1=0, loss_v2=0, nll_loss=0.906, ntokens=2077.6, nsentences=64, sample_size=2077.6, sample_size_v1=0, sample_size_v2=0, ppl=1.87, wps=520.7, ups=0.25, wpb=2077.6, bsz=64, num_updates=15230, lr=1.32053e-05, gnorm=4.974, clip=100, loss_scale=64, train_wall=40, gb_free=7.9, wall=61534
2023-05-08 17:02:13 - progress_bar.py[line:272] - INFO: epoch 018:    546 / 866 loss=2.163, loss_v1=0, loss_v2=0, nll_loss=0.936, ntokens=2278.3, nsentences=64, sample_size=2278.3, sample_size_v1=0, sample_size_v2=0, ppl=1.91, wps=567, ups=0.25, wpb=2278.3, bsz=64, num_updates=15240, lr=1.3193e-05, gnorm=4.399, clip=100, loss_scale=128, train_wall=40, gb_free=7.6, wall=61574
2023-05-08 17:02:46 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2023-05-08 17:02:58 - progress_bar.py[line:272] - INFO: epoch 018:    557 / 866 loss=2.17, loss_v1=0, loss_v2=0, nll_loss=0.945, ntokens=2248.4, nsentences=64, sample_size=2248.4, sample_size_v1=0, sample_size_v2=0, ppl=1.93, wps=507, ups=0.23, wpb=2248.4, bsz=64, num_updates=15250, lr=1.31807e-05, gnorm=4.623, clip=100, loss_scale=64, train_wall=44, gb_free=8.1, wall=61619
2023-05-08 17:03:38 - progress_bar.py[line:272] - INFO: epoch 018:    567 / 866 loss=2.156, loss_v1=0, loss_v2=0, nll_loss=0.928, ntokens=2212.7, nsentences=64, sample_size=2212.7, sample_size_v1=0, sample_size_v2=0, ppl=1.9, wps=553.3, ups=0.25, wpb=2212.7, bsz=64, num_updates=15260, lr=1.31685e-05, gnorm=4.907, clip=100, loss_scale=64, train_wall=40, gb_free=8.1, wall=61659
2023-05-08 17:04:18 - progress_bar.py[line:272] - INFO: epoch 018:    577 / 866 loss=2.152, loss_v1=0, loss_v2=0, nll_loss=0.924, ntokens=2143.4, nsentences=64, sample_size=2143.4, sample_size_v1=0, sample_size_v2=0, ppl=1.9, wps=534.1, ups=0.25, wpb=2143.4, bsz=64, num_updates=15270, lr=1.31562e-05, gnorm=4.897, clip=100, loss_scale=64, train_wall=40, gb_free=8.1, wall=61699
2023-05-08 17:04:58 - progress_bar.py[line:272] - INFO: epoch 018:    587 / 866 loss=2.179, loss_v1=0, loss_v2=0, nll_loss=0.954, ntokens=2086.5, nsentences=64, sample_size=2086.5, sample_size_v1=0, sample_size_v2=0, ppl=1.94, wps=519.3, ups=0.25, wpb=2086.5, bsz=64, num_updates=15280, lr=1.31439e-05, gnorm=5.546, clip=100, loss_scale=64, train_wall=40, gb_free=8.4, wall=61739
2023-05-08 17:05:38 - progress_bar.py[line:272] - INFO: epoch 018:    597 / 866 loss=2.128, loss_v1=0, loss_v2=0, nll_loss=0.897, ntokens=2154.7, nsentences=64, sample_size=2154.7, sample_size_v1=0, sample_size_v2=0, ppl=1.86, wps=535, ups=0.25, wpb=2154.7, bsz=64, num_updates=15290, lr=1.31316e-05, gnorm=4.632, clip=100, loss_scale=64, train_wall=40, gb_free=7.7, wall=61779
2023-05-08 17:06:18 - progress_bar.py[line:272] - INFO: epoch 018:    607 / 866 loss=2.148, loss_v1=0, loss_v2=0, nll_loss=0.921, ntokens=2011.2, nsentences=64, sample_size=2011.2, sample_size_v1=0, sample_size_v2=0, ppl=1.89, wps=502.6, ups=0.25, wpb=2011.2, bsz=64, num_updates=15300, lr=1.31193e-05, gnorm=5.21, clip=100, loss_scale=64, train_wall=40, gb_free=7.3, wall=61819
2023-05-08 17:06:58 - progress_bar.py[line:272] - INFO: epoch 018:    617 / 866 loss=2.171, loss_v1=0, loss_v2=0, nll_loss=0.945, ntokens=1941.8, nsentences=64, sample_size=1941.8, sample_size_v1=0, sample_size_v2=0, ppl=1.93, wps=487.8, ups=0.25, wpb=1941.8, bsz=64, num_updates=15310, lr=1.3107e-05, gnorm=5.326, clip=100, loss_scale=64, train_wall=40, gb_free=7.8, wall=61859
2023-05-08 17:07:38 - progress_bar.py[line:272] - INFO: epoch 018:    627 / 866 loss=2.155, loss_v1=0, loss_v2=0, nll_loss=0.926, ntokens=2052.9, nsentences=64, sample_size=2052.9, sample_size_v1=0, sample_size_v2=0, ppl=1.9, wps=513, ups=0.25, wpb=2052.9, bsz=64, num_updates=15320, lr=1.30948e-05, gnorm=5.27, clip=100, loss_scale=64, train_wall=40, gb_free=8.2, wall=61899
2023-05-08 17:08:18 - progress_bar.py[line:272] - INFO: epoch 018:    637 / 866 loss=2.144, loss_v1=0, loss_v2=0, nll_loss=0.916, ntokens=2035.5, nsentences=64, sample_size=2035.5, sample_size_v1=0, sample_size_v2=0, ppl=1.89, wps=509.7, ups=0.25, wpb=2035.5, bsz=64, num_updates=15330, lr=1.30825e-05, gnorm=5.214, clip=100, loss_scale=64, train_wall=40, gb_free=8, wall=61939
2023-05-08 17:08:58 - progress_bar.py[line:272] - INFO: epoch 018:    647 / 866 loss=2.152, loss_v1=0, loss_v2=0, nll_loss=0.923, ntokens=2063.3, nsentences=64, sample_size=2063.3, sample_size_v1=0, sample_size_v2=0, ppl=1.9, wps=519.5, ups=0.25, wpb=2063.3, bsz=64, num_updates=15340, lr=1.30702e-05, gnorm=5.329, clip=100, loss_scale=64, train_wall=40, gb_free=8.2, wall=61979
2023-05-08 17:09:37 - progress_bar.py[line:272] - INFO: epoch 018:    657 / 866 loss=2.172, loss_v1=0, loss_v2=0, nll_loss=0.947, ntokens=1895.4, nsentences=64, sample_size=1895.4, sample_size_v1=0, sample_size_v2=0, ppl=1.93, wps=479, ups=0.25, wpb=1895.4, bsz=64, num_updates=15350, lr=1.30579e-05, gnorm=5.565, clip=100, loss_scale=64, train_wall=40, gb_free=7.9, wall=62018
2023-05-08 17:10:18 - progress_bar.py[line:272] - INFO: epoch 018:    667 / 866 loss=2.161, loss_v1=0, loss_v2=0, nll_loss=0.934, ntokens=2004.3, nsentences=64, sample_size=2004.3, sample_size_v1=0, sample_size_v2=0, ppl=1.91, wps=499.1, ups=0.25, wpb=2004.3, bsz=64, num_updates=15360, lr=1.30456e-05, gnorm=5.438, clip=100, loss_scale=64, train_wall=40, gb_free=7.8, wall=62059
2023-05-08 17:10:58 - progress_bar.py[line:272] - INFO: epoch 018:    677 / 866 loss=2.156, loss_v1=0, loss_v2=0, nll_loss=0.927, ntokens=2088.4, nsentences=64, sample_size=2088.4, sample_size_v1=0, sample_size_v2=0, ppl=1.9, wps=520.3, ups=0.25, wpb=2088.4, bsz=64, num_updates=15370, lr=1.30333e-05, gnorm=5.043, clip=100, loss_scale=64, train_wall=40, gb_free=8.1, wall=62099
2023-05-08 17:11:37 - progress_bar.py[line:272] - INFO: epoch 018:    687 / 866 loss=2.147, loss_v1=0, loss_v2=0, nll_loss=0.919, ntokens=1980.4, nsentences=64, sample_size=1980.4, sample_size_v1=0, sample_size_v2=0, ppl=1.89, wps=498.3, ups=0.25, wpb=1980.4, bsz=64, num_updates=15380, lr=1.3021e-05, gnorm=5.166, clip=100, loss_scale=64, train_wall=40, gb_free=8.4, wall=62139
2023-05-08 17:12:18 - progress_bar.py[line:272] - INFO: epoch 018:    697 / 866 loss=2.162, loss_v1=0, loss_v2=0, nll_loss=0.936, ntokens=2133.2, nsentences=64, sample_size=2133.2, sample_size_v1=0, sample_size_v2=0, ppl=1.91, wps=531.4, ups=0.25, wpb=2133.2, bsz=64, num_updates=15390, lr=1.30088e-05, gnorm=5.1, clip=100, loss_scale=64, train_wall=40, gb_free=7.1, wall=62179
2023-05-08 17:12:57 - progress_bar.py[line:272] - INFO: epoch 018:    707 / 866 loss=2.164, loss_v1=0, loss_v2=0, nll_loss=0.936, ntokens=1972.1, nsentences=64, sample_size=1972.1, sample_size_v1=0, sample_size_v2=0, ppl=1.91, wps=494.2, ups=0.25, wpb=1972.1, bsz=64, num_updates=15400, lr=1.29965e-05, gnorm=5.286, clip=100, loss_scale=64, train_wall=40, gb_free=8.2, wall=62219
2023-05-08 17:13:37 - progress_bar.py[line:272] - INFO: epoch 018:    717 / 866 loss=2.154, loss_v1=0, loss_v2=0, nll_loss=0.926, ntokens=1886.4, nsentences=64, sample_size=1886.4, sample_size_v1=0, sample_size_v2=0, ppl=1.9, wps=471.9, ups=0.25, wpb=1886.4, bsz=64, num_updates=15410, lr=1.29842e-05, gnorm=5.222, clip=100, loss_scale=64, train_wall=40, gb_free=8, wall=62259
2023-05-08 17:14:17 - progress_bar.py[line:272] - INFO: epoch 018:    727 / 866 loss=2.127, loss_v1=0, loss_v2=0, nll_loss=0.897, ntokens=1984.1, nsentences=64, sample_size=1984.1, sample_size_v1=0, sample_size_v2=0, ppl=1.86, wps=498.6, ups=0.25, wpb=1984.1, bsz=64, num_updates=15420, lr=1.29719e-05, gnorm=5.532, clip=100, loss_scale=64, train_wall=40, gb_free=8.3, wall=62298
2023-05-08 17:14:57 - progress_bar.py[line:272] - INFO: epoch 018:    737 / 866 loss=2.136, loss_v1=0, loss_v2=0, nll_loss=0.906, ntokens=2105.3, nsentences=64, sample_size=2105.3, sample_size_v1=0, sample_size_v2=0, ppl=1.87, wps=526.6, ups=0.25, wpb=2105.3, bsz=64, num_updates=15430, lr=1.29596e-05, gnorm=5.143, clip=100, loss_scale=64, train_wall=40, gb_free=7.8, wall=62338
2023-05-08 17:15:37 - progress_bar.py[line:272] - INFO: epoch 018:    747 / 866 loss=2.127, loss_v1=0, loss_v2=0, nll_loss=0.893, ntokens=2126.6, nsentences=64, sample_size=2126.6, sample_size_v1=0, sample_size_v2=0, ppl=1.86, wps=530.2, ups=0.25, wpb=2126.6, bsz=64, num_updates=15440, lr=1.29473e-05, gnorm=4.944, clip=100, loss_scale=64, train_wall=40, gb_free=7.5, wall=62378
2023-05-08 17:16:17 - progress_bar.py[line:272] - INFO: epoch 018:    757 / 866 loss=2.14, loss_v1=0, loss_v2=0, nll_loss=0.91, ntokens=2055.9, nsentences=64, sample_size=2055.9, sample_size_v1=0, sample_size_v2=0, ppl=1.88, wps=514.1, ups=0.25, wpb=2055.9, bsz=64, num_updates=15450, lr=1.29351e-05, gnorm=5.368, clip=100, loss_scale=64, train_wall=40, gb_free=7.9, wall=62418
2023-05-08 17:16:57 - progress_bar.py[line:272] - INFO: epoch 018:    767 / 866 loss=2.135, loss_v1=0, loss_v2=0, nll_loss=0.908, ntokens=2104.6, nsentences=64, sample_size=2104.6, sample_size_v1=0, sample_size_v2=0, ppl=1.88, wps=525.6, ups=0.25, wpb=2104.6, bsz=64, num_updates=15460, lr=1.29228e-05, gnorm=5.162, clip=100, loss_scale=64, train_wall=40, gb_free=8.3, wall=62458
2023-05-08 17:17:38 - progress_bar.py[line:272] - INFO: epoch 018:    777 / 866 loss=2.152, loss_v1=0, loss_v2=0, nll_loss=0.923, ntokens=2258.8, nsentences=64, sample_size=2258.8, sample_size_v1=0, sample_size_v2=0, ppl=1.9, wps=562.5, ups=0.25, wpb=2258.8, bsz=64, num_updates=15470, lr=1.29105e-05, gnorm=5.031, clip=100, loss_scale=64, train_wall=40, gb_free=7.9, wall=62499
2023-05-08 17:18:17 - progress_bar.py[line:272] - INFO: epoch 018:    787 / 866 loss=2.153, loss_v1=0, loss_v2=0, nll_loss=0.923, ntokens=2038.1, nsentences=64, sample_size=2038.1, sample_size_v1=0, sample_size_v2=0, ppl=1.9, wps=511.7, ups=0.25, wpb=2038.1, bsz=64, num_updates=15480, lr=1.28982e-05, gnorm=5.097, clip=100, loss_scale=64, train_wall=40, gb_free=7.7, wall=62538
2023-05-08 17:18:57 - progress_bar.py[line:272] - INFO: epoch 018:    797 / 866 loss=2.157, loss_v1=0, loss_v2=0, nll_loss=0.93, ntokens=2084.7, nsentences=64, sample_size=2084.7, sample_size_v1=0, sample_size_v2=0, ppl=1.91, wps=522, ups=0.25, wpb=2084.7, bsz=64, num_updates=15490, lr=1.28859e-05, gnorm=5.362, clip=100, loss_scale=64, train_wall=40, gb_free=7.9, wall=62578
2023-05-08 17:19:37 - progress_bar.py[line:272] - INFO: epoch 018:    807 / 866 loss=2.139, loss_v1=0, loss_v2=0, nll_loss=0.908, ntokens=1945.9, nsentences=64, sample_size=1945.9, sample_size_v1=0, sample_size_v2=0, ppl=1.88, wps=490.8, ups=0.25, wpb=1945.9, bsz=64, num_updates=15500, lr=1.28736e-05, gnorm=5.401, clip=100, loss_scale=64, train_wall=40, gb_free=7.8, wall=62618
2023-05-08 17:20:17 - progress_bar.py[line:272] - INFO: epoch 018:    817 / 866 loss=2.128, loss_v1=0, loss_v2=0, nll_loss=0.894, ntokens=2085.3, nsentences=64, sample_size=2085.3, sample_size_v1=0, sample_size_v2=0, ppl=1.86, wps=517.7, ups=0.25, wpb=2085.3, bsz=64, num_updates=15510, lr=1.28614e-05, gnorm=5.042, clip=100, loss_scale=64, train_wall=40, gb_free=8, wall=62658
2023-05-08 17:20:58 - progress_bar.py[line:272] - INFO: epoch 018:    827 / 866 loss=2.112, loss_v1=0, loss_v2=0, nll_loss=0.882, ntokens=2163, nsentences=64, sample_size=2163, sample_size_v1=0, sample_size_v2=0, ppl=1.84, wps=535.4, ups=0.25, wpb=2163, bsz=64, num_updates=15520, lr=1.28491e-05, gnorm=4.604, clip=100, loss_scale=64, train_wall=40, gb_free=8.1, wall=62699
2023-05-08 17:21:38 - progress_bar.py[line:272] - INFO: epoch 018:    837 / 866 loss=2.137, loss_v1=0, loss_v2=0, nll_loss=0.908, ntokens=2161.7, nsentences=64, sample_size=2161.7, sample_size_v1=0, sample_size_v2=0, ppl=1.88, wps=533.5, ups=0.25, wpb=2161.7, bsz=64, num_updates=15530, lr=1.28368e-05, gnorm=4.801, clip=100, loss_scale=64, train_wall=40, gb_free=8.2, wall=62739
2023-05-08 17:22:18 - progress_bar.py[line:272] - INFO: epoch 018:    847 / 866 loss=2.127, loss_v1=0, loss_v2=0, nll_loss=0.896, ntokens=2168.3, nsentences=64, sample_size=2168.3, sample_size_v1=0, sample_size_v2=0, ppl=1.86, wps=540.3, ups=0.25, wpb=2168.3, bsz=64, num_updates=15540, lr=1.28245e-05, gnorm=4.965, clip=100, loss_scale=64, train_wall=40, gb_free=6.9, wall=62779
2023-05-08 17:22:59 - progress_bar.py[line:272] - INFO: epoch 018:    857 / 866 loss=2.117, loss_v1=0, loss_v2=0, nll_loss=0.884, ntokens=2080.9, nsentences=64, sample_size=2080.9, sample_size_v1=0, sample_size_v2=0, ppl=1.85, wps=516.2, ups=0.25, wpb=2080.9, bsz=64, num_updates=15550, lr=1.28122e-05, gnorm=4.946, clip=100, loss_scale=64, train_wall=40, gb_free=7.8, wall=62820
2023-05-08 17:23:33 - train.py[line:332] - INFO: end of epoch 18 (average epoch stats below)
local datafile ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 1 begin to initialize row_count and line_idx-to-offset mapping
2023-05-08 17:23:33 - progress_bar.py[line:282] - INFO: epoch 018 | loss 2.142 | loss_v1 0 | loss_v2 0 | nll_loss 0.912 | ntokens 2102.71 | nsentences 63.972 | sample_size 2102.71 | sample_size_v1 0 | sample_size_v2 0 | ppl 1.88 | wps 515.1 | ups 0.24 | wpb 2102.7 | bsz 64 | num_updates 15559 | lr 1.28012e-05 | gnorm 5.014 | clip 100 | loss_scale 64 | train_wall 3520 | gb_free 8.7 | wall 62854
2023-05-08 17:23:33 - trainer.py[line:639] - INFO: loading train data for epoch 19
local datafile ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 0 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 0 finished initializing row_count and line_idx-to-offset mapping
file ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 0 row count 27700 total row count 55400
slice_id 0 seek offset 0
2023-05-08 17:23:35 - trainer.py[line:703] - INFO: begin training epoch 19
2023-05-08 17:23:35 - train.py[line:305] - INFO: Start iterating over samples
local datafile ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 1 finished initializing row_count and line_idx-to-offset mapping
file ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 1 row count 27700 total row count 55400
slice_id 1 seek offset 27700
2023-05-08 17:23:39 - progress_bar.py[line:272] - INFO: epoch 019:      1 / 866 loss=2.164, loss_v1=0, loss_v2=0, nll_loss=0.939, ntokens=2052.4, nsentences=61.6, sample_size=2052.4, sample_size_v1=0, sample_size_v2=0, ppl=1.92, wps=504.6, ups=0.25, wpb=2052.4, bsz=61.6, num_updates=15560, lr=1.27999e-05, gnorm=4.877, clip=100, loss_scale=64, train_wall=39, gb_free=7.6, wall=62860
2023-05-08 17:24:20 - progress_bar.py[line:272] - INFO: epoch 019:     11 / 866 loss=2.096, loss_v1=0, loss_v2=0, nll_loss=0.861, ntokens=2113.9, nsentences=64, sample_size=2113.9, sample_size_v1=0, sample_size_v2=0, ppl=1.82, wps=522.2, ups=0.25, wpb=2113.9, bsz=64, num_updates=15570, lr=1.27877e-05, gnorm=5.212, clip=100, loss_scale=64, train_wall=40, gb_free=7.8, wall=62901
2023-05-08 17:25:00 - progress_bar.py[line:272] - INFO: epoch 019:     21 / 866 loss=2.084, loss_v1=0, loss_v2=0, nll_loss=0.847, ntokens=2073.7, nsentences=64, sample_size=2073.7, sample_size_v1=0, sample_size_v2=0, ppl=1.8, wps=514.7, ups=0.25, wpb=2073.7, bsz=64, num_updates=15580, lr=1.27754e-05, gnorm=5.024, clip=100, loss_scale=64, train_wall=40, gb_free=7.5, wall=62941
2023-05-08 17:25:40 - progress_bar.py[line:272] - INFO: epoch 019:     31 / 866 loss=2.082, loss_v1=0, loss_v2=0, nll_loss=0.846, ntokens=1996.7, nsentences=64, sample_size=1996.7, sample_size_v1=0, sample_size_v2=0, ppl=1.8, wps=495.5, ups=0.25, wpb=1996.7, bsz=64, num_updates=15590, lr=1.27631e-05, gnorm=5.091, clip=100, loss_scale=64, train_wall=40, gb_free=7.4, wall=62981
2023-05-08 17:26:21 - progress_bar.py[line:272] - INFO: epoch 019:     41 / 866 loss=2.041, loss_v1=0, loss_v2=0, nll_loss=0.799, ntokens=2234.3, nsentences=64, sample_size=2234.3, sample_size_v1=0, sample_size_v2=0, ppl=1.74, wps=545.1, ups=0.24, wpb=2234.3, bsz=64, num_updates=15600, lr=1.27508e-05, gnorm=4.781, clip=100, loss_scale=64, train_wall=41, gb_free=7.2, wall=63022
2023-05-08 17:27:02 - progress_bar.py[line:272] - INFO: epoch 019:     51 / 866 loss=2.091, loss_v1=0, loss_v2=0, nll_loss=0.858, ntokens=1960.1, nsentences=64, sample_size=1960.1, sample_size_v1=0, sample_size_v2=0, ppl=1.81, wps=486.2, ups=0.25, wpb=1960.1, bsz=64, num_updates=15610, lr=1.27385e-05, gnorm=4.958, clip=100, loss_scale=64, train_wall=40, gb_free=7.5, wall=63063
2023-05-08 17:27:42 - progress_bar.py[line:272] - INFO: epoch 019:     61 / 866 loss=2.004, loss_v1=0, loss_v2=0, nll_loss=0.76, ntokens=2153.5, nsentences=64, sample_size=2153.5, sample_size_v1=0, sample_size_v2=0, ppl=1.69, wps=532.3, ups=0.25, wpb=2153.5, bsz=64, num_updates=15620, lr=1.27262e-05, gnorm=4.858, clip=100, loss_scale=64, train_wall=40, gb_free=6.3, wall=63103
2023-05-08 17:28:24 - progress_bar.py[line:272] - INFO: epoch 019:     71 / 866 loss=2.024, loss_v1=0, loss_v2=0, nll_loss=0.779, ntokens=2421, nsentences=64, sample_size=2421, sample_size_v1=0, sample_size_v2=0, ppl=1.72, wps=580.1, ups=0.24, wpb=2421, bsz=64, num_updates=15630, lr=1.27139e-05, gnorm=4.574, clip=100, loss_scale=64, train_wall=42, gb_free=6.2, wall=63145
2023-05-08 17:29:05 - progress_bar.py[line:272] - INFO: epoch 019:     81 / 866 loss=2.069, loss_v1=0, loss_v2=0, nll_loss=0.831, ntokens=2316.3, nsentences=64, sample_size=2316.3, sample_size_v1=0, sample_size_v2=0, ppl=1.78, wps=560.3, ups=0.24, wpb=2316.3, bsz=64, num_updates=15640, lr=1.27017e-05, gnorm=4.738, clip=100, loss_scale=64, train_wall=41, gb_free=7.6, wall=63186
2023-05-08 17:29:46 - progress_bar.py[line:272] - INFO: epoch 019:     91 / 866 loss=2.082, loss_v1=0, loss_v2=0, nll_loss=0.844, ntokens=2094.9, nsentences=64, sample_size=2094.9, sample_size_v1=0, sample_size_v2=0, ppl=1.8, wps=512.1, ups=0.24, wpb=2094.9, bsz=64, num_updates=15650, lr=1.26894e-05, gnorm=5.107, clip=100, loss_scale=64, train_wall=41, gb_free=7.7, wall=63227
2023-05-08 17:30:26 - progress_bar.py[line:272] - INFO: epoch 019:    101 / 866 loss=2.079, loss_v1=0, loss_v2=0, nll_loss=0.843, ntokens=2060.7, nsentences=64, sample_size=2060.7, sample_size_v1=0, sample_size_v2=0, ppl=1.79, wps=511.6, ups=0.25, wpb=2060.7, bsz=64, num_updates=15660, lr=1.26771e-05, gnorm=4.994, clip=100, loss_scale=64, train_wall=40, gb_free=7.2, wall=63268
2023-05-08 17:31:07 - progress_bar.py[line:272] - INFO: epoch 019:    111 / 866 loss=2.137, loss_v1=0, loss_v2=0, nll_loss=0.908, ntokens=2077.3, nsentences=64, sample_size=2077.3, sample_size_v1=0, sample_size_v2=0, ppl=1.88, wps=516, ups=0.25, wpb=2077.3, bsz=64, num_updates=15670, lr=1.26648e-05, gnorm=5.294, clip=100, loss_scale=64, train_wall=40, gb_free=7.5, wall=63308
2023-05-08 17:31:48 - progress_bar.py[line:272] - INFO: epoch 019:    121 / 866 loss=2.134, loss_v1=0, loss_v2=0, nll_loss=0.903, ntokens=2148.3, nsentences=64, sample_size=2148.3, sample_size_v1=0, sample_size_v2=0, ppl=1.87, wps=525, ups=0.24, wpb=2148.3, bsz=64, num_updates=15680, lr=1.26525e-05, gnorm=4.974, clip=100, loss_scale=64, train_wall=41, gb_free=7.3, wall=63349
2023-05-08 17:32:29 - progress_bar.py[line:272] - INFO: epoch 019:    131 / 866 loss=2.118, loss_v1=0, loss_v2=0, nll_loss=0.885, ntokens=2209, nsentences=64, sample_size=2209, sample_size_v1=0, sample_size_v2=0, ppl=1.85, wps=537.4, ups=0.24, wpb=2209, bsz=64, num_updates=15690, lr=1.26402e-05, gnorm=4.791, clip=100, loss_scale=64, train_wall=41, gb_free=7.4, wall=63390
2023-05-08 17:33:10 - progress_bar.py[line:272] - INFO: epoch 019:    141 / 866 loss=2.084, loss_v1=0, loss_v2=0, nll_loss=0.847, ntokens=2260.2, nsentences=64, sample_size=2260.2, sample_size_v1=0, sample_size_v2=0, ppl=1.8, wps=550.8, ups=0.24, wpb=2260.2, bsz=64, num_updates=15700, lr=1.2628e-05, gnorm=4.581, clip=100, loss_scale=64, train_wall=41, gb_free=7.4, wall=63431
2023-05-08 17:33:51 - progress_bar.py[line:272] - INFO: epoch 019:    151 / 866 loss=2.088, loss_v1=0, loss_v2=0, nll_loss=0.854, ntokens=2183.5, nsentences=64, sample_size=2183.5, sample_size_v1=0, sample_size_v2=0, ppl=1.81, wps=528.3, ups=0.24, wpb=2183.5, bsz=64, num_updates=15710, lr=1.26157e-05, gnorm=4.797, clip=100, loss_scale=64, train_wall=41, gb_free=5.9, wall=63472
2023-05-08 17:34:32 - progress_bar.py[line:272] - INFO: epoch 019:    161 / 866 loss=2.123, loss_v1=0, loss_v2=0, nll_loss=0.89, ntokens=2170.1, nsentences=64, sample_size=2170.1, sample_size_v1=0, sample_size_v2=0, ppl=1.85, wps=531, ups=0.24, wpb=2170.1, bsz=64, num_updates=15720, lr=1.26034e-05, gnorm=5.041, clip=100, loss_scale=64, train_wall=41, gb_free=7.6, wall=63513
2023-05-08 17:35:12 - progress_bar.py[line:272] - INFO: epoch 019:    171 / 866 loss=2.112, loss_v1=0, loss_v2=0, nll_loss=0.878, ntokens=2098.8, nsentences=64, sample_size=2098.8, sample_size_v1=0, sample_size_v2=0, ppl=1.84, wps=519.9, ups=0.25, wpb=2098.8, bsz=64, num_updates=15730, lr=1.25911e-05, gnorm=5.028, clip=100, loss_scale=64, train_wall=40, gb_free=7.6, wall=63553
2023-05-08 17:35:53 - progress_bar.py[line:272] - INFO: epoch 019:    181 / 866 loss=2.101, loss_v1=0, loss_v2=0, nll_loss=0.865, ntokens=2149.7, nsentences=64, sample_size=2149.7, sample_size_v1=0, sample_size_v2=0, ppl=1.82, wps=526, ups=0.24, wpb=2149.7, bsz=64, num_updates=15740, lr=1.25788e-05, gnorm=4.929, clip=100, loss_scale=64, train_wall=41, gb_free=7.4, wall=63594
2023-05-08 17:36:34 - progress_bar.py[line:272] - INFO: epoch 019:    191 / 866 loss=2.101, loss_v1=0, loss_v2=0, nll_loss=0.867, ntokens=2205, nsentences=64, sample_size=2205, sample_size_v1=0, sample_size_v2=0, ppl=1.82, wps=539, ups=0.24, wpb=2205, bsz=64, num_updates=15750, lr=1.25665e-05, gnorm=4.874, clip=100, loss_scale=64, train_wall=41, gb_free=7.2, wall=63635
2023-05-08 17:37:15 - progress_bar.py[line:272] - INFO: epoch 019:    201 / 866 loss=2.119, loss_v1=0, loss_v2=0, nll_loss=0.885, ntokens=2106.8, nsentences=64, sample_size=2106.8, sample_size_v1=0, sample_size_v2=0, ppl=1.85, wps=519, ups=0.25, wpb=2106.8, bsz=64, num_updates=15760, lr=1.25543e-05, gnorm=5.322, clip=100, loss_scale=128, train_wall=41, gb_free=7.7, wall=63676
2023-05-08 17:37:55 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2023-05-08 17:37:59 - progress_bar.py[line:272] - INFO: epoch 019:    212 / 866 loss=2.138, loss_v1=0, loss_v2=0, nll_loss=0.909, ntokens=2026.2, nsentences=64, sample_size=2026.2, sample_size_v1=0, sample_size_v2=0, ppl=1.88, wps=457.1, ups=0.23, wpb=2026.2, bsz=64, num_updates=15770, lr=1.2542e-05, gnorm=5.037, clip=100, loss_scale=64, train_wall=44, gb_free=7.2, wall=63720
2023-05-08 17:38:39 - progress_bar.py[line:272] - INFO: epoch 019:    222 / 866 loss=2.13, loss_v1=0, loss_v2=0, nll_loss=0.9, ntokens=2222.5, nsentences=64, sample_size=2222.5, sample_size_v1=0, sample_size_v2=0, ppl=1.87, wps=551.3, ups=0.25, wpb=2222.5, bsz=64, num_updates=15780, lr=1.25297e-05, gnorm=4.936, clip=100, loss_scale=64, train_wall=40, gb_free=7.1, wall=63760
2023-05-08 17:39:20 - progress_bar.py[line:272] - INFO: epoch 019:    232 / 866 loss=2.148, loss_v1=0, loss_v2=0, nll_loss=0.918, ntokens=2130.9, nsentences=64, sample_size=2130.9, sample_size_v1=0, sample_size_v2=0, ppl=1.89, wps=527.7, ups=0.25, wpb=2130.9, bsz=64, num_updates=15790, lr=1.25174e-05, gnorm=4.89, clip=100, loss_scale=64, train_wall=40, gb_free=7.6, wall=63801
2023-05-08 17:40:00 - progress_bar.py[line:272] - INFO: epoch 019:    242 / 866 loss=2.139, loss_v1=0, loss_v2=0, nll_loss=0.907, ntokens=2192.7, nsentences=64, sample_size=2192.7, sample_size_v1=0, sample_size_v2=0, ppl=1.88, wps=544.6, ups=0.25, wpb=2192.7, bsz=64, num_updates=15800, lr=1.25051e-05, gnorm=4.629, clip=100, loss_scale=64, train_wall=40, gb_free=7.1, wall=63841
2023-05-08 17:40:40 - progress_bar.py[line:272] - INFO: epoch 019:    252 / 866 loss=2.156, loss_v1=0, loss_v2=0, nll_loss=0.93, ntokens=2103.6, nsentences=64, sample_size=2103.6, sample_size_v1=0, sample_size_v2=0, ppl=1.91, wps=522.3, ups=0.25, wpb=2103.6, bsz=64, num_updates=15810, lr=1.24928e-05, gnorm=5.181, clip=100, loss_scale=64, train_wall=40, gb_free=7.5, wall=63881
2023-05-08 17:41:20 - progress_bar.py[line:272] - INFO: epoch 019:    262 / 866 loss=2.15, loss_v1=0, loss_v2=0, nll_loss=0.922, ntokens=2158.9, nsentences=64, sample_size=2158.9, sample_size_v1=0, sample_size_v2=0, ppl=1.89, wps=538.9, ups=0.25, wpb=2158.9, bsz=64, num_updates=15820, lr=1.24806e-05, gnorm=5.379, clip=100, loss_scale=64, train_wall=40, gb_free=7.7, wall=63921
2023-05-08 17:42:00 - progress_bar.py[line:272] - INFO: epoch 019:    272 / 866 loss=2.122, loss_v1=0, loss_v2=0, nll_loss=0.89, ntokens=2133.5, nsentences=64, sample_size=2133.5, sample_size_v1=0, sample_size_v2=0, ppl=1.85, wps=532.1, ups=0.25, wpb=2133.5, bsz=64, num_updates=15830, lr=1.24683e-05, gnorm=4.939, clip=100, loss_scale=64, train_wall=40, gb_free=8, wall=63962
2023-05-08 17:42:41 - progress_bar.py[line:272] - INFO: epoch 019:    282 / 866 loss=2.148, loss_v1=0, loss_v2=0, nll_loss=0.92, ntokens=2167.2, nsentences=64, sample_size=2167.2, sample_size_v1=0, sample_size_v2=0, ppl=1.89, wps=537.7, ups=0.25, wpb=2167.2, bsz=64, num_updates=15840, lr=1.2456e-05, gnorm=4.648, clip=100, loss_scale=64, train_wall=40, gb_free=6.9, wall=64002
2023-05-08 17:43:21 - progress_bar.py[line:272] - INFO: epoch 019:    292 / 866 loss=2.123, loss_v1=0, loss_v2=0, nll_loss=0.891, ntokens=2121.1, nsentences=64, sample_size=2121.1, sample_size_v1=0, sample_size_v2=0, ppl=1.85, wps=527.4, ups=0.25, wpb=2121.1, bsz=64, num_updates=15850, lr=1.24437e-05, gnorm=4.901, clip=100, loss_scale=64, train_wall=40, gb_free=7.8, wall=64042
2023-05-08 17:44:01 - progress_bar.py[line:272] - INFO: epoch 019:    302 / 866 loss=2.124, loss_v1=0, loss_v2=0, nll_loss=0.893, ntokens=2135.1, nsentences=64, sample_size=2135.1, sample_size_v1=0, sample_size_v2=0, ppl=1.86, wps=534.2, ups=0.25, wpb=2135.1, bsz=64, num_updates=15860, lr=1.24314e-05, gnorm=5.327, clip=100, loss_scale=64, train_wall=40, gb_free=7.9, wall=64082
2023-05-08 17:44:41 - progress_bar.py[line:272] - INFO: epoch 019:    312 / 866 loss=2.118, loss_v1=0, loss_v2=0, nll_loss=0.886, ntokens=2131.6, nsentences=64, sample_size=2131.6, sample_size_v1=0, sample_size_v2=0, ppl=1.85, wps=531.1, ups=0.25, wpb=2131.6, bsz=64, num_updates=15870, lr=1.24191e-05, gnorm=4.695, clip=100, loss_scale=64, train_wall=40, gb_free=7.8, wall=64122
2023-05-08 17:45:21 - progress_bar.py[line:272] - INFO: epoch 019:    322 / 866 loss=2.148, loss_v1=0, loss_v2=0, nll_loss=0.921, ntokens=1957, nsentences=64, sample_size=1957, sample_size_v1=0, sample_size_v2=0, ppl=1.89, wps=491.9, ups=0.25, wpb=1957, bsz=64, num_updates=15880, lr=1.24068e-05, gnorm=5.547, clip=100, loss_scale=64, train_wall=40, gb_free=7.7, wall=64162
2023-05-08 17:46:01 - progress_bar.py[line:272] - INFO: epoch 019:    332 / 866 loss=2.13, loss_v1=0, loss_v2=0, nll_loss=0.899, ntokens=2161.6, nsentences=64, sample_size=2161.6, sample_size_v1=0, sample_size_v2=0, ppl=1.86, wps=540.2, ups=0.25, wpb=2161.6, bsz=64, num_updates=15890, lr=1.23946e-05, gnorm=4.661, clip=100, loss_scale=64, train_wall=40, gb_free=7.6, wall=64202
2023-05-08 17:46:41 - progress_bar.py[line:272] - INFO: epoch 019:    342 / 866 loss=2.113, loss_v1=0, loss_v2=0, nll_loss=0.879, ntokens=2014.9, nsentences=64, sample_size=2014.9, sample_size_v1=0, sample_size_v2=0, ppl=1.84, wps=504, ups=0.25, wpb=2014.9, bsz=64, num_updates=15900, lr=1.23823e-05, gnorm=4.923, clip=100, loss_scale=64, train_wall=40, gb_free=8.2, wall=64242
2023-05-08 17:47:21 - progress_bar.py[line:272] - INFO: epoch 019:    352 / 866 loss=2.156, loss_v1=0, loss_v2=0, nll_loss=0.93, ntokens=1958, nsentences=64, sample_size=1958, sample_size_v1=0, sample_size_v2=0, ppl=1.9, wps=493.1, ups=0.25, wpb=1958, bsz=64, num_updates=15910, lr=1.237e-05, gnorm=5.083, clip=100, loss_scale=64, train_wall=40, gb_free=8.2, wall=64282
2023-05-08 17:48:00 - progress_bar.py[line:272] - INFO: epoch 019:    362 / 866 loss=2.15, loss_v1=0, loss_v2=0, nll_loss=0.923, ntokens=1964.4, nsentences=64, sample_size=1964.4, sample_size_v1=0, sample_size_v2=0, ppl=1.9, wps=495.4, ups=0.25, wpb=1964.4, bsz=64, num_updates=15920, lr=1.23577e-05, gnorm=5.651, clip=100, loss_scale=64, train_wall=40, gb_free=7.7, wall=64321
2023-05-08 17:48:40 - progress_bar.py[line:272] - INFO: epoch 019:    372 / 866 loss=2.139, loss_v1=0, loss_v2=0, nll_loss=0.909, ntokens=2038.1, nsentences=64, sample_size=2038.1, sample_size_v1=0, sample_size_v2=0, ppl=1.88, wps=507.5, ups=0.25, wpb=2038.1, bsz=64, num_updates=15930, lr=1.23454e-05, gnorm=5.01, clip=100, loss_scale=64, train_wall=40, gb_free=8, wall=64362
2023-05-08 17:49:20 - progress_bar.py[line:272] - INFO: epoch 019:    382 / 866 loss=2.116, loss_v1=0, loss_v2=0, nll_loss=0.883, ntokens=2164.2, nsentences=64, sample_size=2164.2, sample_size_v1=0, sample_size_v2=0, ppl=1.84, wps=540.3, ups=0.25, wpb=2164.2, bsz=64, num_updates=15940, lr=1.23331e-05, gnorm=4.765, clip=100, loss_scale=64, train_wall=40, gb_free=7.5, wall=64402
2023-05-08 17:50:00 - progress_bar.py[line:272] - INFO: epoch 019:    392 / 866 loss=2.139, loss_v1=0, loss_v2=0, nll_loss=0.91, ntokens=2067.8, nsentences=64, sample_size=2067.8, sample_size_v1=0, sample_size_v2=0, ppl=1.88, wps=519.4, ups=0.25, wpb=2067.8, bsz=64, num_updates=15950, lr=1.23209e-05, gnorm=4.889, clip=100, loss_scale=64, train_wall=40, gb_free=8.2, wall=64441
2023-05-08 17:50:40 - progress_bar.py[line:272] - INFO: epoch 019:    402 / 866 loss=2.136, loss_v1=0, loss_v2=0, nll_loss=0.907, ntokens=2036, nsentences=64, sample_size=2036, sample_size_v1=0, sample_size_v2=0, ppl=1.87, wps=509.3, ups=0.25, wpb=2036, bsz=64, num_updates=15960, lr=1.23086e-05, gnorm=5.235, clip=100, loss_scale=64, train_wall=40, gb_free=7.6, wall=64481
2023-05-08 17:51:20 - progress_bar.py[line:272] - INFO: epoch 019:    412 / 866 loss=2.126, loss_v1=0, loss_v2=0, nll_loss=0.895, ntokens=2161.9, nsentences=64, sample_size=2161.9, sample_size_v1=0, sample_size_v2=0, ppl=1.86, wps=537.5, ups=0.25, wpb=2161.9, bsz=64, num_updates=15970, lr=1.22963e-05, gnorm=5.029, clip=100, loss_scale=64, train_wall=40, gb_free=7.5, wall=64522
2023-05-08 17:52:01 - progress_bar.py[line:272] - INFO: epoch 019:    422 / 866 loss=2.113, loss_v1=0, loss_v2=0, nll_loss=0.882, ntokens=2082.2, nsentences=64, sample_size=2082.2, sample_size_v1=0, sample_size_v2=0, ppl=1.84, wps=518.6, ups=0.25, wpb=2082.2, bsz=64, num_updates=15980, lr=1.2284e-05, gnorm=5.092, clip=100, loss_scale=64, train_wall=40, gb_free=7.2, wall=64562
2023-05-08 17:52:41 - progress_bar.py[line:272] - INFO: epoch 019:    432 / 866 loss=2.117, loss_v1=0, loss_v2=0, nll_loss=0.884, ntokens=2104.8, nsentences=64, sample_size=2104.8, sample_size_v1=0, sample_size_v2=0, ppl=1.85, wps=526.6, ups=0.25, wpb=2104.8, bsz=64, num_updates=15990, lr=1.22717e-05, gnorm=4.944, clip=100, loss_scale=64, train_wall=40, gb_free=8.1, wall=64602
2023-05-08 17:53:21 - progress_bar.py[line:272] - INFO: epoch 019:    442 / 866 loss=2.157, loss_v1=0, loss_v2=0, nll_loss=0.928, ntokens=2064.2, nsentences=64, sample_size=2064.2, sample_size_v1=0, sample_size_v2=0, ppl=1.9, wps=514.5, ups=0.25, wpb=2064.2, bsz=64, num_updates=16000, lr=1.22594e-05, gnorm=5.397, clip=100, loss_scale=64, train_wall=40, gb_free=7.3, wall=64642
2023-05-08 17:54:01 - progress_bar.py[line:272] - INFO: epoch 019:    452 / 866 loss=2.145, loss_v1=0, loss_v2=0, nll_loss=0.914, ntokens=1981.6, nsentences=64, sample_size=1981.6, sample_size_v1=0, sample_size_v2=0, ppl=1.88, wps=496.1, ups=0.25, wpb=1981.6, bsz=64, num_updates=16010, lr=1.22472e-05, gnorm=5.115, clip=100, loss_scale=64, train_wall=40, gb_free=8.3, wall=64682
2023-05-08 17:54:41 - progress_bar.py[line:272] - INFO: epoch 019:    462 / 866 loss=2.146, loss_v1=0, loss_v2=0, nll_loss=0.917, ntokens=2192.3, nsentences=64, sample_size=2192.3, sample_size_v1=0, sample_size_v2=0, ppl=1.89, wps=544.3, ups=0.25, wpb=2192.3, bsz=64, num_updates=16020, lr=1.22349e-05, gnorm=5.1, clip=100, loss_scale=64, train_wall=40, gb_free=7.3, wall=64722
2023-05-08 17:55:21 - progress_bar.py[line:272] - INFO: epoch 019:    472 / 866 loss=2.146, loss_v1=0, loss_v2=0, nll_loss=0.918, ntokens=2142.5, nsentences=64, sample_size=2142.5, sample_size_v1=0, sample_size_v2=0, ppl=1.89, wps=533.1, ups=0.25, wpb=2142.5, bsz=64, num_updates=16030, lr=1.22226e-05, gnorm=5.523, clip=100, loss_scale=64, train_wall=40, gb_free=7.3, wall=64762
2023-05-08 17:56:02 - progress_bar.py[line:272] - INFO: epoch 019:    482 / 866 loss=2.133, loss_v1=0, loss_v2=0, nll_loss=0.902, ntokens=2178.2, nsentences=64, sample_size=2178.2, sample_size_v1=0, sample_size_v2=0, ppl=1.87, wps=539.1, ups=0.25, wpb=2178.2, bsz=64, num_updates=16040, lr=1.22103e-05, gnorm=4.878, clip=100, loss_scale=64, train_wall=40, gb_free=8.2, wall=64803
2023-05-08 17:56:42 - progress_bar.py[line:272] - INFO: epoch 019:    492 / 866 loss=2.112, loss_v1=0, loss_v2=0, nll_loss=0.877, ntokens=2054.4, nsentences=64, sample_size=2054.4, sample_size_v1=0, sample_size_v2=0, ppl=1.84, wps=513.3, ups=0.25, wpb=2054.4, bsz=64, num_updates=16050, lr=1.2198e-05, gnorm=5.189, clip=100, loss_scale=64, train_wall=40, gb_free=7.5, wall=64843
2023-05-08 17:57:22 - progress_bar.py[line:272] - INFO: epoch 019:    502 / 866 loss=2.132, loss_v1=0, loss_v2=0, nll_loss=0.903, ntokens=2074.9, nsentences=64, sample_size=2074.9, sample_size_v1=0, sample_size_v2=0, ppl=1.87, wps=518.3, ups=0.25, wpb=2074.9, bsz=64, num_updates=16060, lr=1.21857e-05, gnorm=5.273, clip=100, loss_scale=64, train_wall=40, gb_free=7.9, wall=64883
2023-05-08 17:58:02 - progress_bar.py[line:272] - INFO: epoch 019:    512 / 866 loss=2.159, loss_v1=0, loss_v2=0, nll_loss=0.932, ntokens=2141.6, nsentences=64, sample_size=2141.6, sample_size_v1=0, sample_size_v2=0, ppl=1.91, wps=536.5, ups=0.25, wpb=2141.6, bsz=64, num_updates=16070, lr=1.21735e-05, gnorm=5.208, clip=100, loss_scale=64, train_wall=40, gb_free=7, wall=64923
2023-05-08 17:58:42 - progress_bar.py[line:272] - INFO: epoch 019:    522 / 866 loss=2.121, loss_v1=0, loss_v2=0, nll_loss=0.889, ntokens=2127.1, nsentences=64, sample_size=2127.1, sample_size_v1=0, sample_size_v2=0, ppl=1.85, wps=529.9, ups=0.25, wpb=2127.1, bsz=64, num_updates=16080, lr=1.21612e-05, gnorm=4.89, clip=100, loss_scale=64, train_wall=40, gb_free=8.1, wall=64963
2023-05-08 17:59:22 - progress_bar.py[line:272] - INFO: epoch 019:    532 / 866 loss=2.128, loss_v1=0, loss_v2=0, nll_loss=0.896, ntokens=2031, nsentences=64, sample_size=2031, sample_size_v1=0, sample_size_v2=0, ppl=1.86, wps=507.5, ups=0.25, wpb=2031, bsz=64, num_updates=16090, lr=1.21489e-05, gnorm=5.216, clip=100, loss_scale=64, train_wall=40, gb_free=8.3, wall=65003
2023-05-08 18:00:02 - progress_bar.py[line:272] - INFO: epoch 019:    542 / 866 loss=2.131, loss_v1=0, loss_v2=0, nll_loss=0.901, ntokens=2149.8, nsentences=64, sample_size=2149.8, sample_size_v1=0, sample_size_v2=0, ppl=1.87, wps=535.6, ups=0.25, wpb=2149.8, bsz=64, num_updates=16100, lr=1.21366e-05, gnorm=5.052, clip=100, loss_scale=64, train_wall=40, gb_free=7.3, wall=65043
2023-05-08 18:00:42 - progress_bar.py[line:272] - INFO: epoch 019:    552 / 866 loss=2.146, loss_v1=0, loss_v2=0, nll_loss=0.917, ntokens=2323, nsentences=64, sample_size=2323, sample_size_v1=0, sample_size_v2=0, ppl=1.89, wps=575.1, ups=0.25, wpb=2323, bsz=64, num_updates=16110, lr=1.21243e-05, gnorm=4.5, clip=100, loss_scale=64, train_wall=40, gb_free=7.4, wall=65083
2023-05-08 18:01:23 - progress_bar.py[line:272] - INFO: epoch 019:    562 / 866 loss=2.145, loss_v1=0, loss_v2=0, nll_loss=0.916, ntokens=2243.9, nsentences=64, sample_size=2243.9, sample_size_v1=0, sample_size_v2=0, ppl=1.89, wps=556, ups=0.25, wpb=2243.9, bsz=64, num_updates=16120, lr=1.2112e-05, gnorm=5.14, clip=100, loss_scale=64, train_wall=40, gb_free=8.3, wall=65124
2023-05-08 18:02:03 - progress_bar.py[line:272] - INFO: epoch 019:    572 / 866 loss=2.125, loss_v1=0, loss_v2=0, nll_loss=0.894, ntokens=2202.4, nsentences=64, sample_size=2202.4, sample_size_v1=0, sample_size_v2=0, ppl=1.86, wps=547.9, ups=0.25, wpb=2202.4, bsz=64, num_updates=16130, lr=1.20997e-05, gnorm=4.965, clip=100, loss_scale=64, train_wall=40, gb_free=7.4, wall=65164
2023-05-08 18:02:43 - progress_bar.py[line:272] - INFO: epoch 019:    582 / 866 loss=2.145, loss_v1=0, loss_v2=0, nll_loss=0.916, ntokens=2123.1, nsentences=64, sample_size=2123.1, sample_size_v1=0, sample_size_v2=0, ppl=1.89, wps=529.1, ups=0.25, wpb=2123.1, bsz=64, num_updates=16140, lr=1.20875e-05, gnorm=5.146, clip=100, loss_scale=64, train_wall=40, gb_free=7.4, wall=65204
2023-05-08 18:03:23 - progress_bar.py[line:272] - INFO: epoch 019:    592 / 866 loss=2.143, loss_v1=0, loss_v2=0, nll_loss=0.913, ntokens=2089, nsentences=64, sample_size=2089, sample_size_v1=0, sample_size_v2=0, ppl=1.88, wps=518.7, ups=0.25, wpb=2089, bsz=64, num_updates=16150, lr=1.20752e-05, gnorm=5.115, clip=100, loss_scale=64, train_wall=40, gb_free=7.3, wall=65244
2023-05-08 18:04:03 - progress_bar.py[line:272] - INFO: epoch 019:    602 / 866 loss=2.103, loss_v1=0, loss_v2=0, nll_loss=0.87, ntokens=2122.3, nsentences=64, sample_size=2122.3, sample_size_v1=0, sample_size_v2=0, ppl=1.83, wps=528, ups=0.25, wpb=2122.3, bsz=64, num_updates=16160, lr=1.20629e-05, gnorm=4.975, clip=100, loss_scale=64, train_wall=40, gb_free=8.3, wall=65285
2023-05-08 18:04:43 - progress_bar.py[line:272] - INFO: epoch 019:    612 / 866 loss=2.147, loss_v1=0, loss_v2=0, nll_loss=0.921, ntokens=1933.1, nsentences=64, sample_size=1933.1, sample_size_v1=0, sample_size_v2=0, ppl=1.89, wps=484.7, ups=0.25, wpb=1933.1, bsz=64, num_updates=16170, lr=1.20506e-05, gnorm=5.721, clip=100, loss_scale=64, train_wall=40, gb_free=8.1, wall=65324
2023-05-08 18:05:23 - progress_bar.py[line:272] - INFO: epoch 019:    622 / 866 loss=2.145, loss_v1=0, loss_v2=0, nll_loss=0.914, ntokens=2007.3, nsentences=64, sample_size=2007.3, sample_size_v1=0, sample_size_v2=0, ppl=1.88, wps=500.4, ups=0.25, wpb=2007.3, bsz=64, num_updates=16180, lr=1.20383e-05, gnorm=5.237, clip=100, loss_scale=64, train_wall=40, gb_free=7.7, wall=65365
2023-05-08 18:06:03 - progress_bar.py[line:272] - INFO: epoch 019:    632 / 866 loss=2.137, loss_v1=0, loss_v2=0, nll_loss=0.906, ntokens=2011.8, nsentences=64, sample_size=2011.8, sample_size_v1=0, sample_size_v2=0, ppl=1.87, wps=505.7, ups=0.25, wpb=2011.8, bsz=64, num_updates=16190, lr=1.2026e-05, gnorm=5.409, clip=100, loss_scale=64, train_wall=40, gb_free=8.1, wall=65404
2023-05-08 18:06:43 - progress_bar.py[line:272] - INFO: epoch 019:    642 / 866 loss=2.119, loss_v1=0, loss_v2=0, nll_loss=0.887, ntokens=2063.3, nsentences=64, sample_size=2063.3, sample_size_v1=0, sample_size_v2=0, ppl=1.85, wps=517, ups=0.25, wpb=2063.3, bsz=64, num_updates=16200, lr=1.20138e-05, gnorm=5.129, clip=100, loss_scale=64, train_wall=40, gb_free=7.5, wall=65444
2023-05-08 18:07:23 - progress_bar.py[line:272] - INFO: epoch 019:    652 / 866 loss=2.138, loss_v1=0, loss_v2=0, nll_loss=0.908, ntokens=2019.1, nsentences=64, sample_size=2019.1, sample_size_v1=0, sample_size_v2=0, ppl=1.88, wps=506.3, ups=0.25, wpb=2019.1, bsz=64, num_updates=16210, lr=1.20015e-05, gnorm=5.104, clip=100, loss_scale=64, train_wall=40, gb_free=8.7, wall=65484
2023-05-08 18:08:03 - progress_bar.py[line:272] - INFO: epoch 019:    662 / 866 loss=2.16, loss_v1=0, loss_v2=0, nll_loss=0.935, ntokens=1927, nsentences=64, sample_size=1927, sample_size_v1=0, sample_size_v2=0, ppl=1.91, wps=482.8, ups=0.25, wpb=1927, bsz=64, num_updates=16220, lr=1.19892e-05, gnorm=5.945, clip=100, loss_scale=64, train_wall=40, gb_free=6.9, wall=65524
2023-05-08 18:08:43 - progress_bar.py[line:272] - INFO: epoch 019:    672 / 866 loss=2.142, loss_v1=0, loss_v2=0, nll_loss=0.91, ntokens=2033.9, nsentences=64, sample_size=2033.9, sample_size_v1=0, sample_size_v2=0, ppl=1.88, wps=508.5, ups=0.25, wpb=2033.9, bsz=64, num_updates=16230, lr=1.19769e-05, gnorm=5.185, clip=100, loss_scale=64, train_wall=40, gb_free=8.1, wall=65564
2023-05-08 18:09:23 - progress_bar.py[line:272] - INFO: epoch 019:    682 / 866 loss=2.127, loss_v1=0, loss_v2=0, nll_loss=0.894, ntokens=2076.8, nsentences=64, sample_size=2076.8, sample_size_v1=0, sample_size_v2=0, ppl=1.86, wps=520.4, ups=0.25, wpb=2076.8, bsz=64, num_updates=16240, lr=1.19646e-05, gnorm=5.493, clip=100, loss_scale=64, train_wall=40, gb_free=7.9, wall=65604
2023-05-08 18:10:03 - progress_bar.py[line:272] - INFO: epoch 019:    692 / 866 loss=2.136, loss_v1=0, loss_v2=0, nll_loss=0.909, ntokens=1991.3, nsentences=64, sample_size=1991.3, sample_size_v1=0, sample_size_v2=0, ppl=1.88, wps=495.8, ups=0.25, wpb=1991.3, bsz=64, num_updates=16250, lr=1.19523e-05, gnorm=5.749, clip=100, loss_scale=64, train_wall=40, gb_free=8.3, wall=65644
2023-05-08 18:10:43 - progress_bar.py[line:272] - INFO: epoch 019:    702 / 866 loss=2.142, loss_v1=0, loss_v2=0, nll_loss=0.913, ntokens=2062.5, nsentences=64, sample_size=2062.5, sample_size_v1=0, sample_size_v2=0, ppl=1.88, wps=516.5, ups=0.25, wpb=2062.5, bsz=64, num_updates=16260, lr=1.19401e-05, gnorm=5.432, clip=100, loss_scale=64, train_wall=40, gb_free=8, wall=65684
2023-05-08 18:11:23 - progress_bar.py[line:272] - INFO: epoch 019:    712 / 866 loss=2.146, loss_v1=0, loss_v2=0, nll_loss=0.915, ntokens=1917.3, nsentences=64, sample_size=1917.3, sample_size_v1=0, sample_size_v2=0, ppl=1.89, wps=481.6, ups=0.25, wpb=1917.3, bsz=64, num_updates=16270, lr=1.19278e-05, gnorm=5.599, clip=100, loss_scale=64, train_wall=40, gb_free=8.3, wall=65724
2023-05-08 18:12:03 - progress_bar.py[line:272] - INFO: epoch 019:    722 / 866 loss=2.114, loss_v1=0, loss_v2=0, nll_loss=0.882, ntokens=1946.1, nsentences=64, sample_size=1946.1, sample_size_v1=0, sample_size_v2=0, ppl=1.84, wps=487.6, ups=0.25, wpb=1946.1, bsz=64, num_updates=16280, lr=1.19155e-05, gnorm=5.348, clip=100, loss_scale=64, train_wall=40, gb_free=7.9, wall=65764
2023-05-08 18:12:34 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2023-05-08 18:12:47 - progress_bar.py[line:272] - INFO: epoch 019:    733 / 866 loss=2.111, loss_v1=0, loss_v2=0, nll_loss=0.88, ntokens=2037.5, nsentences=64, sample_size=2037.5, sample_size_v1=0, sample_size_v2=0, ppl=1.84, wps=465, ups=0.23, wpb=2037.5, bsz=64, num_updates=16290, lr=1.19032e-05, gnorm=5.076, clip=100, loss_scale=64, train_wall=44, gb_free=7.3, wall=65808
2023-05-08 18:13:27 - progress_bar.py[line:272] - INFO: epoch 019:    743 / 866 loss=2.119, loss_v1=0, loss_v2=0, nll_loss=0.885, ntokens=2149.2, nsentences=64, sample_size=2149.2, sample_size_v1=0, sample_size_v2=0, ppl=1.85, wps=535.3, ups=0.25, wpb=2149.2, bsz=64, num_updates=16300, lr=1.18909e-05, gnorm=5.174, clip=100, loss_scale=64, train_wall=40, gb_free=7.9, wall=65848
2023-05-08 18:14:07 - progress_bar.py[line:272] - INFO: epoch 019:    753 / 866 loss=2.108, loss_v1=0, loss_v2=0, nll_loss=0.871, ntokens=2078, nsentences=64, sample_size=2078, sample_size_v1=0, sample_size_v2=0, ppl=1.83, wps=520.3, ups=0.25, wpb=2078, bsz=64, num_updates=16310, lr=1.18786e-05, gnorm=5.279, clip=100, loss_scale=64, train_wall=40, gb_free=7.8, wall=65888
2023-05-08 18:14:47 - progress_bar.py[line:272] - INFO: epoch 019:    763 / 866 loss=2.113, loss_v1=0, loss_v2=0, nll_loss=0.881, ntokens=2147.9, nsentences=64, sample_size=2147.9, sample_size_v1=0, sample_size_v2=0, ppl=1.84, wps=534.5, ups=0.25, wpb=2147.9, bsz=64, num_updates=16320, lr=1.18664e-05, gnorm=5.002, clip=100, loss_scale=64, train_wall=40, gb_free=7.9, wall=65928
2023-05-08 18:15:27 - progress_bar.py[line:272] - INFO: epoch 019:    773 / 866 loss=2.127, loss_v1=0, loss_v2=0, nll_loss=0.897, ntokens=2095.5, nsentences=64, sample_size=2095.5, sample_size_v1=0, sample_size_v2=0, ppl=1.86, wps=526.4, ups=0.25, wpb=2095.5, bsz=64, num_updates=16330, lr=1.18541e-05, gnorm=5.648, clip=100, loss_scale=64, train_wall=40, gb_free=7.9, wall=65968
2023-05-08 18:16:07 - progress_bar.py[line:272] - INFO: epoch 019:    783 / 866 loss=2.117, loss_v1=0, loss_v2=0, nll_loss=0.882, ntokens=2224.5, nsentences=64, sample_size=2224.5, sample_size_v1=0, sample_size_v2=0, ppl=1.84, wps=551.9, ups=0.25, wpb=2224.5, bsz=64, num_updates=16340, lr=1.18418e-05, gnorm=4.974, clip=100, loss_scale=64, train_wall=40, gb_free=7.6, wall=66008
2023-05-08 18:16:47 - progress_bar.py[line:272] - INFO: epoch 019:    793 / 866 loss=2.146, loss_v1=0, loss_v2=0, nll_loss=0.918, ntokens=2005.5, nsentences=64, sample_size=2005.5, sample_size_v1=0, sample_size_v2=0, ppl=1.89, wps=503.1, ups=0.25, wpb=2005.5, bsz=64, num_updates=16350, lr=1.18295e-05, gnorm=5.434, clip=100, loss_scale=64, train_wall=40, gb_free=7.9, wall=66048
2023-05-08 18:17:27 - progress_bar.py[line:272] - INFO: epoch 019:    803 / 866 loss=2.129, loss_v1=0, loss_v2=0, nll_loss=0.898, ntokens=1972.7, nsentences=64, sample_size=1972.7, sample_size_v1=0, sample_size_v2=0, ppl=1.86, wps=492.6, ups=0.25, wpb=1972.7, bsz=64, num_updates=16360, lr=1.18172e-05, gnorm=5.476, clip=100, loss_scale=64, train_wall=40, gb_free=7.2, wall=66088
2023-05-08 18:18:07 - progress_bar.py[line:272] - INFO: epoch 019:    813 / 866 loss=2.104, loss_v1=0, loss_v2=0, nll_loss=0.868, ntokens=2109.3, nsentences=64, sample_size=2109.3, sample_size_v1=0, sample_size_v2=0, ppl=1.83, wps=527.8, ups=0.25, wpb=2109.3, bsz=64, num_updates=16370, lr=1.18049e-05, gnorm=5.18, clip=100, loss_scale=64, train_wall=40, gb_free=6.7, wall=66128
2023-05-08 18:18:47 - progress_bar.py[line:272] - INFO: epoch 019:    823 / 866 loss=2.11, loss_v1=0, loss_v2=0, nll_loss=0.876, ntokens=2101.2, nsentences=64, sample_size=2101.2, sample_size_v1=0, sample_size_v2=0, ppl=1.84, wps=523.4, ups=0.25, wpb=2101.2, bsz=64, num_updates=16380, lr=1.17926e-05, gnorm=5.192, clip=100, loss_scale=64, train_wall=40, gb_free=7.5, wall=66168
2023-05-08 18:19:28 - progress_bar.py[line:272] - INFO: epoch 019:    833 / 866 loss=2.095, loss_v1=0, loss_v2=0, nll_loss=0.862, ntokens=2208.2, nsentences=64, sample_size=2208.2, sample_size_v1=0, sample_size_v2=0, ppl=1.82, wps=543, ups=0.25, wpb=2208.2, bsz=64, num_updates=16390, lr=1.17804e-05, gnorm=4.762, clip=100, loss_scale=64, train_wall=41, gb_free=8.2, wall=66209
2023-05-08 18:20:08 - progress_bar.py[line:272] - INFO: epoch 019:    843 / 866 loss=2.111, loss_v1=0, loss_v2=0, nll_loss=0.88, ntokens=2121.2, nsentences=64, sample_size=2121.2, sample_size_v1=0, sample_size_v2=0, ppl=1.84, wps=529.2, ups=0.25, wpb=2121.2, bsz=64, num_updates=16400, lr=1.17681e-05, gnorm=4.785, clip=100, loss_scale=64, train_wall=40, gb_free=8.2, wall=66249
2023-05-08 18:20:48 - progress_bar.py[line:272] - INFO: epoch 019:    853 / 866 loss=2.097, loss_v1=0, loss_v2=0, nll_loss=0.861, ntokens=2191.4, nsentences=64, sample_size=2191.4, sample_size_v1=0, sample_size_v2=0, ppl=1.82, wps=543.8, ups=0.25, wpb=2191.4, bsz=64, num_updates=16410, lr=1.17558e-05, gnorm=4.799, clip=100, loss_scale=64, train_wall=40, gb_free=7.5, wall=66289
2023-05-08 18:21:28 - progress_bar.py[line:272] - INFO: epoch 019:    863 / 866 loss=2.12, loss_v1=0, loss_v2=0, nll_loss=0.888, ntokens=2023.2, nsentences=64, sample_size=2023.2, sample_size_v1=0, sample_size_v2=0, ppl=1.85, wps=506.7, ups=0.25, wpb=2023.2, bsz=64, num_updates=16420, lr=1.17435e-05, gnorm=5.293, clip=100, loss_scale=64, train_wall=40, gb_free=7.7, wall=66329
2023-05-08 18:21:39 - train.py[line:332] - INFO: end of epoch 19 (average epoch stats below)
local datafile ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 1 begin to initialize row_count and line_idx-to-offset mapping
2023-05-08 18:21:39 - progress_bar.py[line:282] - INFO: epoch 019 | loss 2.121 | loss_v1 0 | loss_v2 0 | nll_loss 0.889 | ntokens 2103.52 | nsentences 63.972 | sample_size 2103.52 | sample_size_v1 0 | sample_size_v2 0 | ppl 1.85 | wps 521.5 | ups 0.25 | wpb 2103.5 | bsz 64 | num_updates 16423 | lr 1.17398e-05 | gnorm 5.1 | clip 100 | loss_scale 64 | train_wall 3479 | gb_free 8.7 | wall 66340
2023-05-08 18:21:39 - trainer.py[line:639] - INFO: loading train data for epoch 20
local datafile ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 0 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 0 finished initializing row_count and line_idx-to-offset mapping
file ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 0 row count 27700 total row count 55400
slice_id 0 seek offset 0
2023-05-08 18:21:40 - trainer.py[line:703] - INFO: begin training epoch 20
2023-05-08 18:21:40 - train.py[line:305] - INFO: Start iterating over samples
local datafile ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 1 finished initializing row_count and line_idx-to-offset mapping
file ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 1 row count 27700 total row count 55400
slice_id 1 seek offset 27700
2023-05-08 18:22:09 - progress_bar.py[line:272] - INFO: epoch 020:      7 / 866 loss=2.094, loss_v1=0, loss_v2=0, nll_loss=0.86, ntokens=2063.1, nsentences=61.6, sample_size=2063.1, sample_size_v1=0, sample_size_v2=0, ppl=1.81, wps=503.5, ups=0.24, wpb=2063.1, bsz=61.6, num_updates=16430, lr=1.17312e-05, gnorm=5.532, clip=100, loss_scale=64, train_wall=39, gb_free=7.5, wall=66370
2023-05-08 18:22:49 - progress_bar.py[line:272] - INFO: epoch 020:     17 / 866 loss=2.081, loss_v1=0, loss_v2=0, nll_loss=0.844, ntokens=2075.1, nsentences=64, sample_size=2075.1, sample_size_v1=0, sample_size_v2=0, ppl=1.79, wps=513.3, ups=0.25, wpb=2075.1, bsz=64, num_updates=16440, lr=1.17189e-05, gnorm=5.482, clip=100, loss_scale=64, train_wall=40, gb_free=7.3, wall=66410
2023-05-08 18:23:30 - progress_bar.py[line:272] - INFO: epoch 020:     27 / 866 loss=2.082, loss_v1=0, loss_v2=0, nll_loss=0.845, ntokens=1975.4, nsentences=64, sample_size=1975.4, sample_size_v1=0, sample_size_v2=0, ppl=1.8, wps=490, ups=0.25, wpb=1975.4, bsz=64, num_updates=16450, lr=1.17067e-05, gnorm=5.197, clip=100, loss_scale=64, train_wall=40, gb_free=7.1, wall=66451
2023-05-08 18:24:10 - progress_bar.py[line:272] - INFO: epoch 020:     37 / 866 loss=2.027, loss_v1=0, loss_v2=0, nll_loss=0.784, ntokens=2214.8, nsentences=64, sample_size=2214.8, sample_size_v1=0, sample_size_v2=0, ppl=1.72, wps=543.1, ups=0.25, wpb=2214.8, bsz=64, num_updates=16460, lr=1.16944e-05, gnorm=5.074, clip=100, loss_scale=64, train_wall=41, gb_free=7.6, wall=66492
2023-05-08 18:24:51 - progress_bar.py[line:272] - INFO: epoch 020:     47 / 866 loss=2.055, loss_v1=0, loss_v2=0, nll_loss=0.816, ntokens=2012, nsentences=64, sample_size=2012, sample_size_v1=0, sample_size_v2=0, ppl=1.76, wps=499.3, ups=0.25, wpb=2012, bsz=64, num_updates=16470, lr=1.16821e-05, gnorm=5.086, clip=100, loss_scale=64, train_wall=40, gb_free=7, wall=66532
2023-05-08 18:25:31 - progress_bar.py[line:272] - INFO: epoch 020:     57 / 866 loss=2.015, loss_v1=0, loss_v2=0, nll_loss=0.774, ntokens=2065.2, nsentences=64, sample_size=2065.2, sample_size_v1=0, sample_size_v2=0, ppl=1.71, wps=511.8, ups=0.25, wpb=2065.2, bsz=64, num_updates=16480, lr=1.16698e-05, gnorm=5.033, clip=100, loss_scale=64, train_wall=40, gb_free=7.6, wall=66572
2023-05-08 18:26:13 - progress_bar.py[line:272] - INFO: epoch 020:     67 / 866 loss=1.975, loss_v1=0, loss_v2=0, nll_loss=0.724, ntokens=2385, nsentences=64, sample_size=2385, sample_size_v1=0, sample_size_v2=0, ppl=1.65, wps=574.3, ups=0.24, wpb=2385, bsz=64, num_updates=16490, lr=1.16575e-05, gnorm=4.427, clip=100, loss_scale=64, train_wall=41, gb_free=6.4, wall=66614
2023-05-08 18:26:54 - progress_bar.py[line:272] - INFO: epoch 020:     77 / 866 loss=2.031, loss_v1=0, loss_v2=0, nll_loss=0.789, ntokens=2320.6, nsentences=64, sample_size=2320.6, sample_size_v1=0, sample_size_v2=0, ppl=1.73, wps=555.1, ups=0.24, wpb=2320.6, bsz=64, num_updates=16500, lr=1.16452e-05, gnorm=4.653, clip=100, loss_scale=64, train_wall=42, gb_free=7.3, wall=66656
2023-05-08 18:27:36 - progress_bar.py[line:272] - INFO: epoch 020:     87 / 866 loss=2.071, loss_v1=0, loss_v2=0, nll_loss=0.832, ntokens=2178.1, nsentences=64, sample_size=2178.1, sample_size_v1=0, sample_size_v2=0, ppl=1.78, wps=530.5, ups=0.24, wpb=2178.1, bsz=64, num_updates=16510, lr=1.1633e-05, gnorm=5.137, clip=100, loss_scale=64, train_wall=41, gb_free=6.9, wall=66697
2023-05-08 18:28:16 - progress_bar.py[line:272] - INFO: epoch 020:     97 / 866 loss=2.051, loss_v1=0, loss_v2=0, nll_loss=0.809, ntokens=2142.7, nsentences=64, sample_size=2142.7, sample_size_v1=0, sample_size_v2=0, ppl=1.75, wps=527.3, ups=0.25, wpb=2142.7, bsz=64, num_updates=16520, lr=1.16207e-05, gnorm=5.272, clip=100, loss_scale=64, train_wall=41, gb_free=6.2, wall=66737
2023-05-08 18:28:56 - progress_bar.py[line:272] - INFO: epoch 020:    107 / 866 loss=2.108, loss_v1=0, loss_v2=0, nll_loss=0.876, ntokens=2011.7, nsentences=64, sample_size=2011.7, sample_size_v1=0, sample_size_v2=0, ppl=1.84, wps=501.5, ups=0.25, wpb=2011.7, bsz=64, num_updates=16530, lr=1.16084e-05, gnorm=5.338, clip=100, loss_scale=64, train_wall=40, gb_free=6.8, wall=66777
2023-05-08 18:29:37 - progress_bar.py[line:272] - INFO: epoch 020:    117 / 866 loss=2.122, loss_v1=0, loss_v2=0, nll_loss=0.89, ntokens=2101.1, nsentences=64, sample_size=2101.1, sample_size_v1=0, sample_size_v2=0, ppl=1.85, wps=517.2, ups=0.25, wpb=2101.1, bsz=64, num_updates=16540, lr=1.15961e-05, gnorm=5.176, clip=100, loss_scale=64, train_wall=41, gb_free=6.9, wall=66818
2023-05-08 18:30:18 - progress_bar.py[line:272] - INFO: epoch 020:    127 / 866 loss=2.115, loss_v1=0, loss_v2=0, nll_loss=0.881, ntokens=2224.4, nsentences=64, sample_size=2224.4, sample_size_v1=0, sample_size_v2=0, ppl=1.84, wps=540.9, ups=0.24, wpb=2224.4, bsz=64, num_updates=16550, lr=1.15838e-05, gnorm=5.156, clip=100, loss_scale=64, train_wall=41, gb_free=7.3, wall=66859
2023-05-08 18:30:59 - progress_bar.py[line:272] - INFO: epoch 020:    137 / 866 loss=2.08, loss_v1=0, loss_v2=0, nll_loss=0.843, ntokens=2240.2, nsentences=64, sample_size=2240.2, sample_size_v1=0, sample_size_v2=0, ppl=1.79, wps=545.8, ups=0.24, wpb=2240.2, bsz=64, num_updates=16560, lr=1.15715e-05, gnorm=4.655, clip=100, loss_scale=64, train_wall=41, gb_free=7.3, wall=66900
2023-05-08 18:31:40 - progress_bar.py[line:272] - INFO: epoch 020:    147 / 866 loss=2.064, loss_v1=0, loss_v2=0, nll_loss=0.826, ntokens=2170.9, nsentences=64, sample_size=2170.9, sample_size_v1=0, sample_size_v2=0, ppl=1.77, wps=526, ups=0.24, wpb=2170.9, bsz=64, num_updates=16570, lr=1.15592e-05, gnorm=4.81, clip=100, loss_scale=64, train_wall=41, gb_free=7.2, wall=66941
2023-05-08 18:32:22 - progress_bar.py[line:272] - INFO: epoch 020:    157 / 866 loss=2.093, loss_v1=0, loss_v2=0, nll_loss=0.859, ntokens=2265.1, nsentences=64, sample_size=2265.1, sample_size_v1=0, sample_size_v2=0, ppl=1.81, wps=546.4, ups=0.24, wpb=2265.1, bsz=64, num_updates=16580, lr=1.1547e-05, gnorm=5.255, clip=100, loss_scale=64, train_wall=41, gb_free=7.1, wall=66983
2023-05-08 18:33:02 - progress_bar.py[line:272] - INFO: epoch 020:    167 / 866 loss=2.083, loss_v1=0, loss_v2=0, nll_loss=0.846, ntokens=2117.6, nsentences=64, sample_size=2117.6, sample_size_v1=0, sample_size_v2=0, ppl=1.8, wps=521.7, ups=0.25, wpb=2117.6, bsz=64, num_updates=16590, lr=1.15347e-05, gnorm=5.013, clip=100, loss_scale=64, train_wall=41, gb_free=6.4, wall=67024
2023-05-08 18:33:43 - progress_bar.py[line:272] - INFO: epoch 020:    177 / 866 loss=2.093, loss_v1=0, loss_v2=0, nll_loss=0.857, ntokens=2059.5, nsentences=64, sample_size=2059.5, sample_size_v1=0, sample_size_v2=0, ppl=1.81, wps=508.7, ups=0.25, wpb=2059.5, bsz=64, num_updates=16600, lr=1.15224e-05, gnorm=5.258, clip=100, loss_scale=64, train_wall=40, gb_free=7.1, wall=67064
2023-05-08 18:34:24 - progress_bar.py[line:272] - INFO: epoch 020:    187 / 866 loss=2.074, loss_v1=0, loss_v2=0, nll_loss=0.836, ntokens=2187.4, nsentences=64, sample_size=2187.4, sample_size_v1=0, sample_size_v2=0, ppl=1.79, wps=532.6, ups=0.24, wpb=2187.4, bsz=64, num_updates=16610, lr=1.15101e-05, gnorm=4.997, clip=100, loss_scale=64, train_wall=41, gb_free=6.7, wall=67105
2023-05-08 18:35:05 - progress_bar.py[line:272] - INFO: epoch 020:    197 / 866 loss=2.096, loss_v1=0, loss_v2=0, nll_loss=0.86, ntokens=2211.2, nsentences=64, sample_size=2211.2, sample_size_v1=0, sample_size_v2=0, ppl=1.82, wps=537.1, ups=0.24, wpb=2211.2, bsz=64, num_updates=16620, lr=1.14978e-05, gnorm=4.868, clip=100, loss_scale=64, train_wall=41, gb_free=7.6, wall=67146
2023-05-08 18:35:45 - progress_bar.py[line:272] - INFO: epoch 020:    207 / 866 loss=2.11, loss_v1=0, loss_v2=0, nll_loss=0.876, ntokens=1950.8, nsentences=64, sample_size=1950.8, sample_size_v1=0, sample_size_v2=0, ppl=1.84, wps=483.5, ups=0.25, wpb=1950.8, bsz=64, num_updates=16630, lr=1.14855e-05, gnorm=5.004, clip=100, loss_scale=64, train_wall=40, gb_free=7, wall=67187
2023-05-08 18:36:26 - progress_bar.py[line:272] - INFO: epoch 020:    217 / 866 loss=2.125, loss_v1=0, loss_v2=0, nll_loss=0.895, ntokens=2217.4, nsentences=64, sample_size=2217.4, sample_size_v1=0, sample_size_v2=0, ppl=1.86, wps=544.5, ups=0.25, wpb=2217.4, bsz=64, num_updates=16640, lr=1.14733e-05, gnorm=4.611, clip=100, loss_scale=64, train_wall=41, gb_free=7.5, wall=67227
2023-05-08 18:37:07 - progress_bar.py[line:272] - INFO: epoch 020:    227 / 866 loss=2.107, loss_v1=0, loss_v2=0, nll_loss=0.875, ntokens=2163.3, nsentences=64, sample_size=2163.3, sample_size_v1=0, sample_size_v2=0, ppl=1.83, wps=536.7, ups=0.25, wpb=2163.3, bsz=64, num_updates=16650, lr=1.1461e-05, gnorm=5.161, clip=100, loss_scale=64, train_wall=40, gb_free=7.1, wall=67268
2023-05-08 18:37:47 - progress_bar.py[line:272] - INFO: epoch 020:    237 / 866 loss=2.142, loss_v1=0, loss_v2=0, nll_loss=0.909, ntokens=2102.5, nsentences=64, sample_size=2102.5, sample_size_v1=0, sample_size_v2=0, ppl=1.88, wps=525, ups=0.25, wpb=2102.5, bsz=64, num_updates=16660, lr=1.14487e-05, gnorm=5.284, clip=100, loss_scale=64, train_wall=40, gb_free=7, wall=67308
2023-05-08 18:38:27 - progress_bar.py[line:272] - INFO: epoch 020:    247 / 866 loss=2.117, loss_v1=0, loss_v2=0, nll_loss=0.884, ntokens=2200.6, nsentences=64, sample_size=2200.6, sample_size_v1=0, sample_size_v2=0, ppl=1.85, wps=544.6, ups=0.25, wpb=2200.6, bsz=64, num_updates=16670, lr=1.14364e-05, gnorm=4.87, clip=100, loss_scale=64, train_wall=40, gb_free=7.3, wall=67348
2023-05-08 18:39:07 - progress_bar.py[line:272] - INFO: epoch 020:    257 / 866 loss=2.117, loss_v1=0, loss_v2=0, nll_loss=0.887, ntokens=2098, nsentences=64, sample_size=2098, sample_size_v1=0, sample_size_v2=0, ppl=1.85, wps=522.7, ups=0.25, wpb=2098, bsz=64, num_updates=16680, lr=1.14241e-05, gnorm=5.129, clip=100, loss_scale=64, train_wall=40, gb_free=7.5, wall=67388
2023-05-08 18:39:48 - progress_bar.py[line:272] - INFO: epoch 020:    267 / 866 loss=2.119, loss_v1=0, loss_v2=0, nll_loss=0.886, ntokens=2119.1, nsentences=64, sample_size=2119.1, sample_size_v1=0, sample_size_v2=0, ppl=1.85, wps=521, ups=0.25, wpb=2119.1, bsz=64, num_updates=16690, lr=1.14118e-05, gnorm=4.955, clip=100, loss_scale=64, train_wall=41, gb_free=7.5, wall=67429
2023-05-08 18:40:28 - progress_bar.py[line:272] - INFO: epoch 020:    277 / 866 loss=2.115, loss_v1=0, loss_v2=0, nll_loss=0.882, ntokens=2198.3, nsentences=64, sample_size=2198.3, sample_size_v1=0, sample_size_v2=0, ppl=1.84, wps=540.2, ups=0.25, wpb=2198.3, bsz=64, num_updates=16700, lr=1.13996e-05, gnorm=4.859, clip=100, loss_scale=64, train_wall=41, gb_free=7.5, wall=67470
2023-05-08 18:41:09 - progress_bar.py[line:272] - INFO: epoch 020:    287 / 866 loss=2.106, loss_v1=0, loss_v2=0, nll_loss=0.874, ntokens=2164.9, nsentences=64, sample_size=2164.9, sample_size_v1=0, sample_size_v2=0, ppl=1.83, wps=536.8, ups=0.25, wpb=2164.9, bsz=64, num_updates=16710, lr=1.13873e-05, gnorm=4.799, clip=100, loss_scale=64, train_wall=40, gb_free=7.3, wall=67510
2023-05-08 18:41:49 - progress_bar.py[line:272] - INFO: epoch 020:    297 / 866 loss=2.111, loss_v1=0, loss_v2=0, nll_loss=0.879, ntokens=2121.1, nsentences=64, sample_size=2121.1, sample_size_v1=0, sample_size_v2=0, ppl=1.84, wps=523.7, ups=0.25, wpb=2121.1, bsz=64, num_updates=16720, lr=1.1375e-05, gnorm=5.235, clip=100, loss_scale=64, train_wall=40, gb_free=7.1, wall=67550
2023-05-08 18:42:30 - progress_bar.py[line:272] - INFO: epoch 020:    307 / 866 loss=2.104, loss_v1=0, loss_v2=0, nll_loss=0.869, ntokens=2127, nsentences=64, sample_size=2127, sample_size_v1=0, sample_size_v2=0, ppl=1.83, wps=527.3, ups=0.25, wpb=2127, bsz=64, num_updates=16730, lr=1.13627e-05, gnorm=4.886, clip=100, loss_scale=64, train_wall=40, gb_free=8.3, wall=67591
2023-05-08 18:43:10 - progress_bar.py[line:272] - INFO: epoch 020:    317 / 866 loss=2.107, loss_v1=0, loss_v2=0, nll_loss=0.874, ntokens=2050.8, nsentences=64, sample_size=2050.8, sample_size_v1=0, sample_size_v2=0, ppl=1.83, wps=511.8, ups=0.25, wpb=2050.8, bsz=64, num_updates=16740, lr=1.13504e-05, gnorm=5.181, clip=100, loss_scale=64, train_wall=40, gb_free=7.8, wall=67631
2023-05-08 18:43:50 - progress_bar.py[line:272] - INFO: epoch 020:    327 / 866 loss=2.124, loss_v1=0, loss_v2=0, nll_loss=0.894, ntokens=2048.6, nsentences=64, sample_size=2048.6, sample_size_v1=0, sample_size_v2=0, ppl=1.86, wps=511.9, ups=0.25, wpb=2048.6, bsz=64, num_updates=16750, lr=1.13381e-05, gnorm=5.55, clip=100, loss_scale=64, train_wall=40, gb_free=7.7, wall=67671
2023-05-08 18:44:30 - progress_bar.py[line:272] - INFO: epoch 020:    337 / 866 loss=2.09, loss_v1=0, loss_v2=0, nll_loss=0.855, ntokens=2101.6, nsentences=64, sample_size=2101.6, sample_size_v1=0, sample_size_v2=0, ppl=1.81, wps=521.9, ups=0.25, wpb=2101.6, bsz=64, num_updates=16760, lr=1.13259e-05, gnorm=4.703, clip=100, loss_scale=64, train_wall=40, gb_free=7.2, wall=67711
2023-05-08 18:45:10 - progress_bar.py[line:272] - INFO: epoch 020:    347 / 866 loss=2.107, loss_v1=0, loss_v2=0, nll_loss=0.872, ntokens=1929.9, nsentences=64, sample_size=1929.9, sample_size_v1=0, sample_size_v2=0, ppl=1.83, wps=481, ups=0.25, wpb=1929.9, bsz=64, num_updates=16770, lr=1.13136e-05, gnorm=5.537, clip=100, loss_scale=64, train_wall=40, gb_free=7.8, wall=67751
2023-05-08 18:45:50 - progress_bar.py[line:272] - INFO: epoch 020:    357 / 866 loss=2.142, loss_v1=0, loss_v2=0, nll_loss=0.912, ntokens=1986.1, nsentences=64, sample_size=1986.1, sample_size_v1=0, sample_size_v2=0, ppl=1.88, wps=494.2, ups=0.25, wpb=1986.1, bsz=64, num_updates=16780, lr=1.13013e-05, gnorm=5.771, clip=100, loss_scale=64, train_wall=40, gb_free=8.2, wall=67791
2023-05-08 18:46:31 - progress_bar.py[line:272] - INFO: epoch 020:    367 / 866 loss=2.124, loss_v1=0, loss_v2=0, nll_loss=0.894, ntokens=1980.8, nsentences=64, sample_size=1980.8, sample_size_v1=0, sample_size_v2=0, ppl=1.86, wps=489.6, ups=0.25, wpb=1980.8, bsz=64, num_updates=16790, lr=1.1289e-05, gnorm=5.528, clip=100, loss_scale=64, train_wall=40, gb_free=8, wall=67832
2023-05-08 18:47:11 - progress_bar.py[line:272] - INFO: epoch 020:    377 / 866 loss=2.113, loss_v1=0, loss_v2=0, nll_loss=0.88, ntokens=2127.1, nsentences=64, sample_size=2127.1, sample_size_v1=0, sample_size_v2=0, ppl=1.84, wps=524.4, ups=0.25, wpb=2127.1, bsz=64, num_updates=16800, lr=1.12767e-05, gnorm=5.254, clip=100, loss_scale=128, train_wall=41, gb_free=7.5, wall=67872
2023-05-08 18:47:51 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2023-05-08 18:47:55 - progress_bar.py[line:272] - INFO: epoch 020:    388 / 866 loss=2.096, loss_v1=0, loss_v2=0, nll_loss=0.86, ntokens=2100.5, nsentences=64, sample_size=2100.5, sample_size_v1=0, sample_size_v2=0, ppl=1.82, wps=476.3, ups=0.23, wpb=2100.5, bsz=64, num_updates=16810, lr=1.12644e-05, gnorm=5.092, clip=100, loss_scale=64, train_wall=44, gb_free=7.5, wall=67917
2023-05-08 18:48:36 - progress_bar.py[line:272] - INFO: epoch 020:    398 / 866 loss=2.128, loss_v1=0, loss_v2=0, nll_loss=0.899, ntokens=2064.6, nsentences=64, sample_size=2064.6, sample_size_v1=0, sample_size_v2=0, ppl=1.87, wps=513.4, ups=0.25, wpb=2064.6, bsz=64, num_updates=16820, lr=1.12521e-05, gnorm=5.707, clip=100, loss_scale=64, train_wall=40, gb_free=7.2, wall=67957
2023-05-08 18:49:16 - progress_bar.py[line:272] - INFO: epoch 020:    408 / 866 loss=2.111, loss_v1=0, loss_v2=0, nll_loss=0.879, ntokens=2069, nsentences=64, sample_size=2069, sample_size_v1=0, sample_size_v2=0, ppl=1.84, wps=515.4, ups=0.25, wpb=2069, bsz=64, num_updates=16830, lr=1.12399e-05, gnorm=5.369, clip=100, loss_scale=64, train_wall=40, gb_free=7.7, wall=67997
2023-05-08 18:49:56 - progress_bar.py[line:272] - INFO: epoch 020:    418 / 866 loss=2.088, loss_v1=0, loss_v2=0, nll_loss=0.852, ntokens=2098.3, nsentences=64, sample_size=2098.3, sample_size_v1=0, sample_size_v2=0, ppl=1.8, wps=521.3, ups=0.25, wpb=2098.3, bsz=64, num_updates=16840, lr=1.12276e-05, gnorm=5.076, clip=100, loss_scale=64, train_wall=40, gb_free=7.2, wall=68037
2023-05-08 18:50:36 - progress_bar.py[line:272] - INFO: epoch 020:    428 / 866 loss=2.093, loss_v1=0, loss_v2=0, nll_loss=0.858, ntokens=2110.8, nsentences=64, sample_size=2110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.81, wps=523.4, ups=0.25, wpb=2110.8, bsz=64, num_updates=16850, lr=1.12153e-05, gnorm=5.152, clip=100, loss_scale=64, train_wall=40, gb_free=7.7, wall=68078
2023-05-08 18:51:17 - progress_bar.py[line:272] - INFO: epoch 020:    438 / 866 loss=2.125, loss_v1=0, loss_v2=0, nll_loss=0.893, ntokens=2124.1, nsentences=64, sample_size=2124.1, sample_size_v1=0, sample_size_v2=0, ppl=1.86, wps=527.9, ups=0.25, wpb=2124.1, bsz=64, num_updates=16860, lr=1.1203e-05, gnorm=5.002, clip=100, loss_scale=64, train_wall=40, gb_free=8, wall=68118
2023-05-08 18:51:57 - progress_bar.py[line:272] - INFO: epoch 020:    448 / 866 loss=2.14, loss_v1=0, loss_v2=0, nll_loss=0.91, ntokens=1996.8, nsentences=64, sample_size=1996.8, sample_size_v1=0, sample_size_v2=0, ppl=1.88, wps=495, ups=0.25, wpb=1996.8, bsz=64, num_updates=16870, lr=1.11907e-05, gnorm=5.295, clip=100, loss_scale=64, train_wall=40, gb_free=7.7, wall=68158
2023-05-08 18:52:37 - progress_bar.py[line:272] - INFO: epoch 020:    458 / 866 loss=2.12, loss_v1=0, loss_v2=0, nll_loss=0.889, ntokens=2079.8, nsentences=64, sample_size=2079.8, sample_size_v1=0, sample_size_v2=0, ppl=1.85, wps=514.7, ups=0.25, wpb=2079.8, bsz=64, num_updates=16880, lr=1.11784e-05, gnorm=5.135, clip=100, loss_scale=64, train_wall=40, gb_free=8, wall=68199
2023-05-08 18:53:18 - progress_bar.py[line:272] - INFO: epoch 020:    468 / 866 loss=2.125, loss_v1=0, loss_v2=0, nll_loss=0.894, ntokens=2164.7, nsentences=64, sample_size=2164.7, sample_size_v1=0, sample_size_v2=0, ppl=1.86, wps=538.5, ups=0.25, wpb=2164.7, bsz=64, num_updates=16890, lr=1.11662e-05, gnorm=5.19, clip=100, loss_scale=64, train_wall=40, gb_free=7.4, wall=68239
2023-05-08 18:53:58 - progress_bar.py[line:272] - INFO: epoch 020:    478 / 866 loss=2.13, loss_v1=0, loss_v2=0, nll_loss=0.898, ntokens=2220, nsentences=64, sample_size=2220, sample_size_v1=0, sample_size_v2=0, ppl=1.86, wps=548.4, ups=0.25, wpb=2220, bsz=64, num_updates=16900, lr=1.11539e-05, gnorm=4.96, clip=100, loss_scale=64, train_wall=40, gb_free=8, wall=68279
2023-05-08 18:54:38 - progress_bar.py[line:272] - INFO: epoch 020:    488 / 866 loss=2.092, loss_v1=0, loss_v2=0, nll_loss=0.856, ntokens=2033.8, nsentences=64, sample_size=2033.8, sample_size_v1=0, sample_size_v2=0, ppl=1.81, wps=504.5, ups=0.25, wpb=2033.8, bsz=64, num_updates=16910, lr=1.11416e-05, gnorm=5.382, clip=100, loss_scale=64, train_wall=40, gb_free=8.3, wall=68320
2023-05-08 18:55:19 - progress_bar.py[line:272] - INFO: epoch 020:    498 / 866 loss=2.093, loss_v1=0, loss_v2=0, nll_loss=0.857, ntokens=2069, nsentences=64, sample_size=2069, sample_size_v1=0, sample_size_v2=0, ppl=1.81, wps=513.1, ups=0.25, wpb=2069, bsz=64, num_updates=16920, lr=1.11293e-05, gnorm=5.268, clip=100, loss_scale=64, train_wall=40, gb_free=8.5, wall=68360
2023-05-08 18:55:59 - progress_bar.py[line:272] - INFO: epoch 020:    508 / 866 loss=2.128, loss_v1=0, loss_v2=0, nll_loss=0.897, ntokens=2115.2, nsentences=64, sample_size=2115.2, sample_size_v1=0, sample_size_v2=0, ppl=1.86, wps=522.6, ups=0.25, wpb=2115.2, bsz=64, num_updates=16930, lr=1.1117e-05, gnorm=5.421, clip=100, loss_scale=64, train_wall=40, gb_free=7.9, wall=68400
2023-05-08 18:56:39 - progress_bar.py[line:272] - INFO: epoch 020:    518 / 866 loss=2.117, loss_v1=0, loss_v2=0, nll_loss=0.885, ntokens=2197.1, nsentences=64, sample_size=2197.1, sample_size_v1=0, sample_size_v2=0, ppl=1.85, wps=548.8, ups=0.25, wpb=2197.1, bsz=64, num_updates=16940, lr=1.11047e-05, gnorm=5.174, clip=100, loss_scale=64, train_wall=40, gb_free=8.1, wall=68440
2023-05-08 18:57:19 - progress_bar.py[line:272] - INFO: epoch 020:    528 / 866 loss=2.116, loss_v1=0, loss_v2=0, nll_loss=0.884, ntokens=1974.3, nsentences=64, sample_size=1974.3, sample_size_v1=0, sample_size_v2=0, ppl=1.85, wps=496.1, ups=0.25, wpb=1974.3, bsz=64, num_updates=16950, lr=1.10925e-05, gnorm=5.655, clip=100, loss_scale=64, train_wall=40, gb_free=8.3, wall=68480
2023-05-08 18:57:59 - progress_bar.py[line:272] - INFO: epoch 020:    538 / 866 loss=2.096, loss_v1=0, loss_v2=0, nll_loss=0.861, ntokens=2123.8, nsentences=64, sample_size=2123.8, sample_size_v1=0, sample_size_v2=0, ppl=1.82, wps=530.3, ups=0.25, wpb=2123.8, bsz=64, num_updates=16960, lr=1.10802e-05, gnorm=4.931, clip=100, loss_scale=64, train_wall=40, gb_free=7.5, wall=68520
2023-05-08 18:58:40 - progress_bar.py[line:272] - INFO: epoch 020:    548 / 866 loss=2.125, loss_v1=0, loss_v2=0, nll_loss=0.894, ntokens=2308.9, nsentences=64, sample_size=2308.9, sample_size_v1=0, sample_size_v2=0, ppl=1.86, wps=571.3, ups=0.25, wpb=2308.9, bsz=64, num_updates=16970, lr=1.10679e-05, gnorm=4.813, clip=100, loss_scale=64, train_wall=40, gb_free=8.1, wall=68561
2023-05-08 18:59:20 - progress_bar.py[line:272] - INFO: epoch 020:    558 / 866 loss=2.129, loss_v1=0, loss_v2=0, nll_loss=0.898, ntokens=2284.3, nsentences=64, sample_size=2284.3, sample_size_v1=0, sample_size_v2=0, ppl=1.86, wps=559.9, ups=0.25, wpb=2284.3, bsz=64, num_updates=16980, lr=1.10556e-05, gnorm=4.718, clip=100, loss_scale=64, train_wall=41, gb_free=7.2, wall=68601
2023-05-08 19:00:01 - progress_bar.py[line:272] - INFO: epoch 020:    568 / 866 loss=2.112, loss_v1=0, loss_v2=0, nll_loss=0.88, ntokens=2217.8, nsentences=64, sample_size=2217.8, sample_size_v1=0, sample_size_v2=0, ppl=1.84, wps=548.5, ups=0.25, wpb=2217.8, bsz=64, num_updates=16990, lr=1.10433e-05, gnorm=5.011, clip=100, loss_scale=64, train_wall=40, gb_free=7.4, wall=68642
2023-05-08 19:00:41 - progress_bar.py[line:272] - INFO: epoch 020:    578 / 866 loss=2.11, loss_v1=0, loss_v2=0, nll_loss=0.876, ntokens=2124.1, nsentences=64, sample_size=2124.1, sample_size_v1=0, sample_size_v2=0, ppl=1.84, wps=528.2, ups=0.25, wpb=2124.1, bsz=64, num_updates=17000, lr=1.1031e-05, gnorm=5.001, clip=100, loss_scale=64, train_wall=40, gb_free=7.5, wall=68682
2023-05-08 19:01:21 - progress_bar.py[line:272] - INFO: epoch 020:    588 / 866 loss=2.136, loss_v1=0, loss_v2=0, nll_loss=0.906, ntokens=2074.5, nsentences=64, sample_size=2074.5, sample_size_v1=0, sample_size_v2=0, ppl=1.87, wps=515.3, ups=0.25, wpb=2074.5, bsz=64, num_updates=17010, lr=1.10188e-05, gnorm=5.318, clip=100, loss_scale=64, train_wall=40, gb_free=7.8, wall=68722
2023-05-08 19:02:02 - progress_bar.py[line:272] - INFO: epoch 020:    598 / 866 loss=2.095, loss_v1=0, loss_v2=0, nll_loss=0.859, ntokens=2145.5, nsentences=64, sample_size=2145.5, sample_size_v1=0, sample_size_v2=0, ppl=1.81, wps=531.4, ups=0.25, wpb=2145.5, bsz=64, num_updates=17020, lr=1.10065e-05, gnorm=4.798, clip=100, loss_scale=64, train_wall=40, gb_free=8.4, wall=68763
2023-05-08 19:02:42 - progress_bar.py[line:272] - INFO: epoch 020:    608 / 866 loss=2.1, loss_v1=0, loss_v2=0, nll_loss=0.869, ntokens=1989.2, nsentences=64, sample_size=1989.2, sample_size_v1=0, sample_size_v2=0, ppl=1.83, wps=494.7, ups=0.25, wpb=1989.2, bsz=64, num_updates=17030, lr=1.09942e-05, gnorm=5.698, clip=100, loss_scale=64, train_wall=40, gb_free=7.4, wall=68803
2023-05-08 19:03:22 - progress_bar.py[line:272] - INFO: epoch 020:    618 / 866 loss=2.137, loss_v1=0, loss_v2=0, nll_loss=0.907, ntokens=1954.5, nsentences=64, sample_size=1954.5, sample_size_v1=0, sample_size_v2=0, ppl=1.88, wps=488.7, ups=0.25, wpb=1954.5, bsz=64, num_updates=17040, lr=1.09819e-05, gnorm=5.292, clip=100, loss_scale=64, train_wall=40, gb_free=8.1, wall=68843
2023-05-08 19:04:02 - progress_bar.py[line:272] - INFO: epoch 020:    628 / 866 loss=2.115, loss_v1=0, loss_v2=0, nll_loss=0.88, ntokens=2038.9, nsentences=64, sample_size=2038.9, sample_size_v1=0, sample_size_v2=0, ppl=1.84, wps=508.6, ups=0.25, wpb=2038.9, bsz=64, num_updates=17050, lr=1.09696e-05, gnorm=5.232, clip=100, loss_scale=64, train_wall=40, gb_free=8.1, wall=68883
2023-05-08 19:04:42 - progress_bar.py[line:272] - INFO: epoch 020:    638 / 866 loss=2.104, loss_v1=0, loss_v2=0, nll_loss=0.87, ntokens=2076.7, nsentences=64, sample_size=2076.7, sample_size_v1=0, sample_size_v2=0, ppl=1.83, wps=516.8, ups=0.25, wpb=2076.7, bsz=64, num_updates=17060, lr=1.09573e-05, gnorm=5.281, clip=100, loss_scale=64, train_wall=40, gb_free=8.1, wall=68923
2023-05-08 19:05:22 - progress_bar.py[line:272] - INFO: epoch 020:    648 / 866 loss=2.115, loss_v1=0, loss_v2=0, nll_loss=0.883, ntokens=2031.8, nsentences=64, sample_size=2031.8, sample_size_v1=0, sample_size_v2=0, ppl=1.84, wps=505.6, ups=0.25, wpb=2031.8, bsz=64, num_updates=17070, lr=1.0945e-05, gnorm=5.261, clip=100, loss_scale=64, train_wall=40, gb_free=7.9, wall=68963
2023-05-08 19:06:02 - progress_bar.py[line:272] - INFO: epoch 020:    658 / 866 loss=2.132, loss_v1=0, loss_v2=0, nll_loss=0.902, ntokens=1925.9, nsentences=64, sample_size=1925.9, sample_size_v1=0, sample_size_v2=0, ppl=1.87, wps=481.2, ups=0.25, wpb=1925.9, bsz=64, num_updates=17080, lr=1.09328e-05, gnorm=6.153, clip=100, loss_scale=64, train_wall=40, gb_free=7.7, wall=69003
2023-05-08 19:06:43 - progress_bar.py[line:272] - INFO: epoch 020:    668 / 866 loss=2.125, loss_v1=0, loss_v2=0, nll_loss=0.893, ntokens=1987.1, nsentences=64, sample_size=1987.1, sample_size_v1=0, sample_size_v2=0, ppl=1.86, wps=492.9, ups=0.25, wpb=1987.1, bsz=64, num_updates=17090, lr=1.09205e-05, gnorm=5.886, clip=100, loss_scale=64, train_wall=40, gb_free=7.3, wall=69044
2023-05-08 19:07:23 - progress_bar.py[line:272] - INFO: epoch 020:    678 / 866 loss=2.114, loss_v1=0, loss_v2=0, nll_loss=0.88, ntokens=2078.2, nsentences=64, sample_size=2078.2, sample_size_v1=0, sample_size_v2=0, ppl=1.84, wps=517.3, ups=0.25, wpb=2078.2, bsz=64, num_updates=17100, lr=1.09082e-05, gnorm=4.87, clip=100, loss_scale=64, train_wall=40, gb_free=7.9, wall=69084
2023-05-08 19:08:03 - progress_bar.py[line:272] - INFO: epoch 020:    688 / 866 loss=2.105, loss_v1=0, loss_v2=0, nll_loss=0.871, ntokens=1984.8, nsentences=64, sample_size=1984.8, sample_size_v1=0, sample_size_v2=0, ppl=1.83, wps=496.3, ups=0.25, wpb=1984.8, bsz=64, num_updates=17110, lr=1.08959e-05, gnorm=5.39, clip=100, loss_scale=64, train_wall=40, gb_free=8.1, wall=69124
2023-05-08 19:08:43 - progress_bar.py[line:272] - INFO: epoch 020:    698 / 866 loss=2.123, loss_v1=0, loss_v2=0, nll_loss=0.893, ntokens=2119.6, nsentences=64, sample_size=2119.6, sample_size_v1=0, sample_size_v2=0, ppl=1.86, wps=524.4, ups=0.25, wpb=2119.6, bsz=64, num_updates=17120, lr=1.08836e-05, gnorm=5.59, clip=100, loss_scale=64, train_wall=40, gb_free=8.1, wall=69164
2023-05-08 19:09:24 - progress_bar.py[line:272] - INFO: epoch 020:    708 / 866 loss=2.12, loss_v1=0, loss_v2=0, nll_loss=0.887, ntokens=1968.4, nsentences=64, sample_size=1968.4, sample_size_v1=0, sample_size_v2=0, ppl=1.85, wps=488.2, ups=0.25, wpb=1968.4, bsz=64, num_updates=17130, lr=1.08713e-05, gnorm=5.647, clip=100, loss_scale=64, train_wall=40, gb_free=8.1, wall=69205
2023-05-08 19:10:03 - progress_bar.py[line:272] - INFO: epoch 020:    718 / 866 loss=2.109, loss_v1=0, loss_v2=0, nll_loss=0.875, ntokens=1904, nsentences=64, sample_size=1904, sample_size_v1=0, sample_size_v2=0, ppl=1.83, wps=477, ups=0.25, wpb=1904, bsz=64, num_updates=17140, lr=1.08591e-05, gnorm=5.155, clip=100, loss_scale=64, train_wall=40, gb_free=8.4, wall=69245
2023-05-08 19:10:43 - progress_bar.py[line:272] - INFO: epoch 020:    728 / 866 loss=2.084, loss_v1=0, loss_v2=0, nll_loss=0.849, ntokens=2000.2, nsentences=64, sample_size=2000.2, sample_size_v1=0, sample_size_v2=0, ppl=1.8, wps=500.4, ups=0.25, wpb=2000.2, bsz=64, num_updates=17150, lr=1.08468e-05, gnorm=5.384, clip=100, loss_scale=64, train_wall=40, gb_free=7.7, wall=69285
2023-05-08 19:11:23 - progress_bar.py[line:272] - INFO: epoch 020:    738 / 866 loss=2.111, loss_v1=0, loss_v2=0, nll_loss=0.88, ntokens=2072.1, nsentences=64, sample_size=2072.1, sample_size_v1=0, sample_size_v2=0, ppl=1.84, wps=518.3, ups=0.25, wpb=2072.1, bsz=64, num_updates=17160, lr=1.08345e-05, gnorm=5.281, clip=100, loss_scale=64, train_wall=40, gb_free=8, wall=69325
2023-05-08 19:12:04 - progress_bar.py[line:272] - INFO: epoch 020:    748 / 866 loss=2.094, loss_v1=0, loss_v2=0, nll_loss=0.856, ntokens=2155.4, nsentences=64, sample_size=2155.4, sample_size_v1=0, sample_size_v2=0, ppl=1.81, wps=535, ups=0.25, wpb=2155.4, bsz=64, num_updates=17170, lr=1.08222e-05, gnorm=5.189, clip=100, loss_scale=64, train_wall=40, gb_free=8, wall=69365
2023-05-08 19:12:44 - progress_bar.py[line:272] - INFO: epoch 020:    758 / 866 loss=2.098, loss_v1=0, loss_v2=0, nll_loss=0.862, ntokens=2038.7, nsentences=64, sample_size=2038.7, sample_size_v1=0, sample_size_v2=0, ppl=1.82, wps=508.3, ups=0.25, wpb=2038.7, bsz=64, num_updates=17180, lr=1.08099e-05, gnorm=5.171, clip=100, loss_scale=64, train_wall=40, gb_free=7.8, wall=69405
2023-05-08 19:13:24 - progress_bar.py[line:272] - INFO: epoch 020:    768 / 866 loss=2.094, loss_v1=0, loss_v2=0, nll_loss=0.86, ntokens=2125.8, nsentences=64, sample_size=2125.8, sample_size_v1=0, sample_size_v2=0, ppl=1.82, wps=529.7, ups=0.25, wpb=2125.8, bsz=64, num_updates=17190, lr=1.07976e-05, gnorm=5.204, clip=100, loss_scale=64, train_wall=40, gb_free=7.7, wall=69445
2023-05-08 19:14:04 - progress_bar.py[line:272] - INFO: epoch 020:    778 / 866 loss=2.11, loss_v1=0, loss_v2=0, nll_loss=0.878, ntokens=2262.1, nsentences=64, sample_size=2262.1, sample_size_v1=0, sample_size_v2=0, ppl=1.84, wps=562.2, ups=0.25, wpb=2262.1, bsz=64, num_updates=17200, lr=1.07854e-05, gnorm=5.073, clip=100, loss_scale=64, train_wall=40, gb_free=8.3, wall=69485
2023-05-08 19:14:44 - progress_bar.py[line:272] - INFO: epoch 020:    788 / 866 loss=2.117, loss_v1=0, loss_v2=0, nll_loss=0.882, ntokens=2004.5, nsentences=64, sample_size=2004.5, sample_size_v1=0, sample_size_v2=0, ppl=1.84, wps=497.9, ups=0.25, wpb=2004.5, bsz=64, num_updates=17210, lr=1.07731e-05, gnorm=5.431, clip=100, loss_scale=64, train_wall=40, gb_free=7.4, wall=69526
2023-05-08 19:15:24 - progress_bar.py[line:272] - INFO: epoch 020:    798 / 866 loss=2.118, loss_v1=0, loss_v2=0, nll_loss=0.886, ntokens=2086.3, nsentences=64, sample_size=2086.3, sample_size_v1=0, sample_size_v2=0, ppl=1.85, wps=523.3, ups=0.25, wpb=2086.3, bsz=64, num_updates=17220, lr=1.07608e-05, gnorm=5.514, clip=100, loss_scale=64, train_wall=40, gb_free=7.9, wall=69565
2023-05-08 19:16:04 - progress_bar.py[line:272] - INFO: epoch 020:    808 / 866 loss=2.097, loss_v1=0, loss_v2=0, nll_loss=0.863, ntokens=1960.4, nsentences=64, sample_size=1960.4, sample_size_v1=0, sample_size_v2=0, ppl=1.82, wps=493.6, ups=0.25, wpb=1960.4, bsz=64, num_updates=17230, lr=1.07485e-05, gnorm=5.618, clip=100, loss_scale=64, train_wall=40, gb_free=7.9, wall=69605
2023-05-08 19:16:45 - progress_bar.py[line:272] - INFO: epoch 020:    818 / 866 loss=2.083, loss_v1=0, loss_v2=0, nll_loss=0.844, ntokens=2086.6, nsentences=64, sample_size=2086.6, sample_size_v1=0, sample_size_v2=0, ppl=1.8, wps=514.9, ups=0.25, wpb=2086.6, bsz=64, num_updates=17240, lr=1.07362e-05, gnorm=5.165, clip=100, loss_scale=64, train_wall=40, gb_free=7.8, wall=69646
2023-05-08 19:17:26 - progress_bar.py[line:272] - INFO: epoch 020:    828 / 866 loss=2.077, loss_v1=0, loss_v2=0, nll_loss=0.84, ntokens=2166.7, nsentences=64, sample_size=2166.7, sample_size_v1=0, sample_size_v2=0, ppl=1.79, wps=525.9, ups=0.24, wpb=2166.7, bsz=64, num_updates=17250, lr=1.07239e-05, gnorm=4.947, clip=100, loss_scale=64, train_wall=41, gb_free=8.1, wall=69687
2023-05-08 19:18:07 - progress_bar.py[line:272] - INFO: epoch 020:    838 / 866 loss=2.09, loss_v1=0, loss_v2=0, nll_loss=0.857, ntokens=2156.5, nsentences=64, sample_size=2156.5, sample_size_v1=0, sample_size_v2=0, ppl=1.81, wps=524.4, ups=0.24, wpb=2156.5, bsz=64, num_updates=17260, lr=1.07117e-05, gnorm=4.861, clip=100, loss_scale=64, train_wall=41, gb_free=8, wall=69728
2023-05-08 19:18:48 - progress_bar.py[line:272] - INFO: epoch 020:    848 / 866 loss=2.087, loss_v1=0, loss_v2=0, nll_loss=0.851, ntokens=2196.7, nsentences=64, sample_size=2196.7, sample_size_v1=0, sample_size_v2=0, ppl=1.8, wps=537.8, ups=0.24, wpb=2196.7, bsz=64, num_updates=17270, lr=1.06994e-05, gnorm=4.925, clip=100, loss_scale=64, train_wall=41, gb_free=7, wall=69769
2023-05-08 19:19:29 - progress_bar.py[line:272] - INFO: epoch 020:    858 / 866 loss=2.072, loss_v1=0, loss_v2=0, nll_loss=0.834, ntokens=2061.2, nsentences=64, sample_size=2061.2, sample_size_v1=0, sample_size_v2=0, ppl=1.78, wps=505.4, ups=0.25, wpb=2061.2, bsz=64, num_updates=17280, lr=1.06871e-05, gnorm=5.08, clip=100, loss_scale=64, train_wall=41, gb_free=8, wall=69810
2023-05-08 19:20:00 - checkpoint_utils.py[line:64] - INFO: Preparing to save checkpoint for epoch 20 @ 17288 updates
2023-05-08 19:20:00 - trainer.py[line:431] - INFO: Saving checkpoint to ../../checkpoints/OFA/sgcls_checkpoints/_30_3e-5_480/tmp/checkpoint20.pt
local datafile ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 1 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 1 finished initializing row_count and line_idx-to-offset mapping
file ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 1 row count 27700 total row count 55400
slice_id 1 seek offset 27700
2023-05-08 19:20:06 - trainer.py[line:441] - INFO: Finished saving checkpoint to ../../checkpoints/OFA/sgcls_checkpoints/_30_3e-5_480/tmp/checkpoint20.pt
2023-05-08 19:20:11 - checkpoint_utils.py[line:133] - INFO: Saved checkpoint ../../checkpoints/OFA/sgcls_checkpoints/_30_3e-5_480/tmp/checkpoint20.pt (epoch 20 @ 17288 updates, score None) (writing took 11.721595525974408 seconds)
2023-05-08 19:20:11 - train.py[line:332] - INFO: end of epoch 20 (average epoch stats below)
2023-05-08 19:20:11 - progress_bar.py[line:282] - INFO: epoch 020 | loss 2.101 | loss_v1 0 | loss_v2 0 | nll_loss 0.867 | ntokens 2102.89 | nsentences 63.972 | sample_size 2102.89 | sample_size_v1 0 | sample_size_v2 0 | ppl 1.82 | wps 517.8 | ups 0.25 | wpb 2102.9 | bsz 64 | num_updates 17288 | lr 1.06773e-05 | gnorm 5.18 | clip 100 | loss_scale 64 | train_wall 3495 | gb_free 8.7 | wall 69852
2023-05-08 19:20:11 - trainer.py[line:639] - INFO: loading train data for epoch 21
local datafile ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 0 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 0 finished initializing row_count and line_idx-to-offset mapping
file ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 0 row count 27700 total row count 55400
slice_id 0 seek offset 0
2023-05-08 19:20:13 - trainer.py[line:703] - INFO: begin training epoch 21
2023-05-08 19:20:13 - train.py[line:305] - INFO: Start iterating over samples
2023-05-08 19:20:22 - progress_bar.py[line:272] - INFO: epoch 021:      2 / 866 loss=2.126, loss_v1=0, loss_v2=0, nll_loss=0.895, ntokens=2068.6, nsentences=61.6, sample_size=2068.6, sample_size_v1=0, sample_size_v2=0, ppl=1.86, wps=388.9, ups=0.19, wpb=2068.6, bsz=61.6, num_updates=17290, lr=1.06748e-05, gnorm=5.531, clip=100, loss_scale=64, train_wall=39, gb_free=7.2, wall=69863
2023-05-08 19:21:02 - progress_bar.py[line:272] - INFO: epoch 021:     12 / 866 loss=2.057, loss_v1=0, loss_v2=0, nll_loss=0.816, ntokens=2074.7, nsentences=64, sample_size=2074.7, sample_size_v1=0, sample_size_v2=0, ppl=1.76, wps=513.5, ups=0.25, wpb=2074.7, bsz=64, num_updates=17300, lr=1.06625e-05, gnorm=5.285, clip=100, loss_scale=64, train_wall=40, gb_free=8, wall=69903
2023-05-08 19:21:43 - progress_bar.py[line:272] - INFO: epoch 021:     22 / 866 loss=2.048, loss_v1=0, loss_v2=0, nll_loss=0.808, ntokens=2062.9, nsentences=64, sample_size=2062.9, sample_size_v1=0, sample_size_v2=0, ppl=1.75, wps=508.2, ups=0.25, wpb=2062.9, bsz=64, num_updates=17310, lr=1.06502e-05, gnorm=5.322, clip=100, loss_scale=64, train_wall=41, gb_free=7.7, wall=69944
2023-05-08 19:22:23 - progress_bar.py[line:272] - INFO: epoch 021:     32 / 866 loss=2.036, loss_v1=0, loss_v2=0, nll_loss=0.793, ntokens=2052.7, nsentences=64, sample_size=2052.7, sample_size_v1=0, sample_size_v2=0, ppl=1.73, wps=505.3, ups=0.25, wpb=2052.7, bsz=64, num_updates=17320, lr=1.06379e-05, gnorm=5.23, clip=100, loss_scale=64, train_wall=41, gb_free=6.7, wall=69985
2023-05-08 19:22:32 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2023-05-08 19:23:09 - progress_bar.py[line:272] - INFO: epoch 021:     43 / 866 loss=2.009, loss_v1=0, loss_v2=0, nll_loss=0.765, ntokens=2147.9, nsentences=64, sample_size=2147.9, sample_size_v1=0, sample_size_v2=0, ppl=1.7, wps=473, ups=0.22, wpb=2147.9, bsz=64, num_updates=17330, lr=1.06257e-05, gnorm=5.034, clip=100, loss_scale=64, train_wall=45, gb_free=7.3, wall=70030
2023-05-08 19:23:50 - progress_bar.py[line:272] - INFO: epoch 021:     53 / 866 loss=2.046, loss_v1=0, loss_v2=0, nll_loss=0.805, ntokens=1987.1, nsentences=64, sample_size=1987.1, sample_size_v1=0, sample_size_v2=0, ppl=1.75, wps=484.7, ups=0.24, wpb=1987.1, bsz=64, num_updates=17340, lr=1.06134e-05, gnorm=5.39, clip=100, loss_scale=64, train_wall=41, gb_free=7.8, wall=70071
2023-05-08 19:24:31 - progress_bar.py[line:272] - INFO: epoch 021:     63 / 866 loss=1.952, loss_v1=0, loss_v2=0, nll_loss=0.704, ntokens=2273.9, nsentences=64, sample_size=2273.9, sample_size_v1=0, sample_size_v2=0, ppl=1.63, wps=552.6, ups=0.24, wpb=2273.9, bsz=64, num_updates=17350, lr=1.06011e-05, gnorm=4.825, clip=100, loss_scale=64, train_wall=41, gb_free=6.5, wall=70112
2023-05-08 19:25:13 - progress_bar.py[line:272] - INFO: epoch 021:     73 / 866 loss=2.006, loss_v1=0, loss_v2=0, nll_loss=0.759, ntokens=2436.8, nsentences=64, sample_size=2436.8, sample_size_v1=0, sample_size_v2=0, ppl=1.69, wps=582.5, ups=0.24, wpb=2436.8, bsz=64, num_updates=17360, lr=1.05888e-05, gnorm=4.593, clip=100, loss_scale=64, train_wall=42, gb_free=6.2, wall=70154
2023-05-08 19:25:54 - progress_bar.py[line:272] - INFO: epoch 021:     83 / 866 loss=2.048, loss_v1=0, loss_v2=0, nll_loss=0.807, ntokens=2209.4, nsentences=64, sample_size=2209.4, sample_size_v1=0, sample_size_v2=0, ppl=1.75, wps=535.7, ups=0.24, wpb=2209.4, bsz=64, num_updates=17370, lr=1.05765e-05, gnorm=5.459, clip=100, loss_scale=64, train_wall=41, gb_free=6.3, wall=70195
2023-05-08 19:26:35 - progress_bar.py[line:272] - INFO: epoch 021:     93 / 866 loss=2.017, loss_v1=0, loss_v2=0, nll_loss=0.771, ntokens=2158.2, nsentences=64, sample_size=2158.2, sample_size_v1=0, sample_size_v2=0, ppl=1.71, wps=526.3, ups=0.24, wpb=2158.2, bsz=64, num_updates=17380, lr=1.05642e-05, gnorm=4.926, clip=100, loss_scale=64, train_wall=41, gb_free=7.3, wall=70236
2023-05-08 19:27:16 - progress_bar.py[line:272] - INFO: epoch 021:    103 / 866 loss=2.091, loss_v1=0, loss_v2=0, nll_loss=0.857, ntokens=1999.5, nsentences=64, sample_size=1999.5, sample_size_v1=0, sample_size_v2=0, ppl=1.81, wps=490, ups=0.25, wpb=1999.5, bsz=64, num_updates=17390, lr=1.0552e-05, gnorm=5.422, clip=100, loss_scale=64, train_wall=41, gb_free=7.7, wall=70277
2023-05-08 19:27:57 - progress_bar.py[line:272] - INFO: epoch 021:    113 / 866 loss=2.098, loss_v1=0, loss_v2=0, nll_loss=0.863, ntokens=2058.9, nsentences=64, sample_size=2058.9, sample_size_v1=0, sample_size_v2=0, ppl=1.82, wps=500.6, ups=0.24, wpb=2058.9, bsz=64, num_updates=17400, lr=1.05397e-05, gnorm=5.111, clip=100, loss_scale=64, train_wall=41, gb_free=7, wall=70318
2023-05-08 19:28:39 - progress_bar.py[line:272] - INFO: epoch 021:    123 / 866 loss=2.095, loss_v1=0, loss_v2=0, nll_loss=0.861, ntokens=2201.6, nsentences=64, sample_size=2201.6, sample_size_v1=0, sample_size_v2=0, ppl=1.82, wps=530.6, ups=0.24, wpb=2201.6, bsz=64, num_updates=17410, lr=1.05274e-05, gnorm=5.411, clip=100, loss_scale=64, train_wall=41, gb_free=6.8, wall=70360
2023-05-08 19:29:20 - progress_bar.py[line:272] - INFO: epoch 021:    133 / 866 loss=2.071, loss_v1=0, loss_v2=0, nll_loss=0.831, ntokens=2208, nsentences=64, sample_size=2208, sample_size_v1=0, sample_size_v2=0, ppl=1.78, wps=536.4, ups=0.24, wpb=2208, bsz=64, num_updates=17420, lr=1.05151e-05, gnorm=5.035, clip=100, loss_scale=64, train_wall=41, gb_free=7.1, wall=70401
2023-05-08 19:30:01 - progress_bar.py[line:272] - INFO: epoch 021:    143 / 866 loss=2.051, loss_v1=0, loss_v2=0, nll_loss=0.81, ntokens=2264.9, nsentences=64, sample_size=2264.9, sample_size_v1=0, sample_size_v2=0, ppl=1.75, wps=547.6, ups=0.24, wpb=2264.9, bsz=64, num_updates=17430, lr=1.05028e-05, gnorm=4.544, clip=100, loss_scale=64, train_wall=41, gb_free=6.4, wall=70442
2023-05-08 19:30:42 - progress_bar.py[line:272] - INFO: epoch 021:    153 / 866 loss=2.055, loss_v1=0, loss_v2=0, nll_loss=0.817, ntokens=2165, nsentences=64, sample_size=2165, sample_size_v1=0, sample_size_v2=0, ppl=1.76, wps=524.4, ups=0.24, wpb=2165, bsz=64, num_updates=17440, lr=1.04905e-05, gnorm=5.003, clip=100, loss_scale=64, train_wall=41, gb_free=6.4, wall=70483
2023-05-08 19:31:24 - progress_bar.py[line:272] - INFO: epoch 021:    163 / 866 loss=2.073, loss_v1=0, loss_v2=0, nll_loss=0.835, ntokens=2159.1, nsentences=64, sample_size=2159.1, sample_size_v1=0, sample_size_v2=0, ppl=1.78, wps=524.2, ups=0.24, wpb=2159.1, bsz=64, num_updates=17450, lr=1.04783e-05, gnorm=5.212, clip=100, loss_scale=64, train_wall=41, gb_free=7.8, wall=70525
2023-05-08 19:32:04 - progress_bar.py[line:272] - INFO: epoch 021:    173 / 866 loss=2.088, loss_v1=0, loss_v2=0, nll_loss=0.853, ntokens=2040.6, nsentences=64, sample_size=2040.6, sample_size_v1=0, sample_size_v2=0, ppl=1.81, wps=505.4, ups=0.25, wpb=2040.6, bsz=64, num_updates=17460, lr=1.0466e-05, gnorm=5.542, clip=100, loss_scale=64, train_wall=40, gb_free=6.9, wall=70565
2023-05-08 19:32:45 - progress_bar.py[line:272] - INFO: epoch 021:    183 / 866 loss=2.053, loss_v1=0, loss_v2=0, nll_loss=0.811, ntokens=2201.4, nsentences=64, sample_size=2201.4, sample_size_v1=0, sample_size_v2=0, ppl=1.76, wps=532.9, ups=0.24, wpb=2201.4, bsz=64, num_updates=17470, lr=1.04537e-05, gnorm=5.048, clip=100, loss_scale=64, train_wall=41, gb_free=7.6, wall=70606
2023-05-08 19:33:26 - progress_bar.py[line:272] - INFO: epoch 021:    193 / 866 loss=2.067, loss_v1=0, loss_v2=0, nll_loss=0.828, ntokens=2205.9, nsentences=64, sample_size=2205.9, sample_size_v1=0, sample_size_v2=0, ppl=1.77, wps=538.3, ups=0.24, wpb=2205.9, bsz=64, num_updates=17480, lr=1.04414e-05, gnorm=5.333, clip=100, loss_scale=64, train_wall=41, gb_free=7.3, wall=70647
2023-05-08 19:34:07 - progress_bar.py[line:272] - INFO: epoch 021:    203 / 866 loss=2.086, loss_v1=0, loss_v2=0, nll_loss=0.849, ntokens=2075.5, nsentences=64, sample_size=2075.5, sample_size_v1=0, sample_size_v2=0, ppl=1.8, wps=508.8, ups=0.25, wpb=2075.5, bsz=64, num_updates=17490, lr=1.04291e-05, gnorm=5.297, clip=100, loss_scale=64, train_wall=41, gb_free=7.6, wall=70688
2023-05-08 19:34:48 - progress_bar.py[line:272] - INFO: epoch 021:    213 / 866 loss=2.096, loss_v1=0, loss_v2=0, nll_loss=0.861, ntokens=2063.9, nsentences=64, sample_size=2063.9, sample_size_v1=0, sample_size_v2=0, ppl=1.82, wps=507.4, ups=0.25, wpb=2063.9, bsz=64, num_updates=17500, lr=1.04168e-05, gnorm=5.713, clip=100, loss_scale=64, train_wall=41, gb_free=7.6, wall=70729
2023-05-08 19:35:28 - progress_bar.py[line:272] - INFO: epoch 021:    223 / 866 loss=2.09, loss_v1=0, loss_v2=0, nll_loss=0.856, ntokens=2222.1, nsentences=64, sample_size=2222.1, sample_size_v1=0, sample_size_v2=0, ppl=1.81, wps=549.7, ups=0.25, wpb=2222.1, bsz=64, num_updates=17510, lr=1.04046e-05, gnorm=4.919, clip=100, loss_scale=64, train_wall=40, gb_free=7.7, wall=70769
2023-05-08 19:36:08 - progress_bar.py[line:272] - INFO: epoch 021:    233 / 866 loss=2.116, loss_v1=0, loss_v2=0, nll_loss=0.883, ntokens=2107.2, nsentences=64, sample_size=2107.2, sample_size_v1=0, sample_size_v2=0, ppl=1.84, wps=523.7, ups=0.25, wpb=2107.2, bsz=64, num_updates=17520, lr=1.03923e-05, gnorm=5.035, clip=100, loss_scale=64, train_wall=40, gb_free=8.2, wall=70809
2023-05-08 19:36:49 - progress_bar.py[line:272] - INFO: epoch 021:    243 / 866 loss=2.097, loss_v1=0, loss_v2=0, nll_loss=0.859, ntokens=2185.9, nsentences=64, sample_size=2185.9, sample_size_v1=0, sample_size_v2=0, ppl=1.81, wps=540.2, ups=0.25, wpb=2185.9, bsz=64, num_updates=17530, lr=1.038e-05, gnorm=5.243, clip=100, loss_scale=64, train_wall=40, gb_free=7.9, wall=70850
2023-05-08 19:37:29 - progress_bar.py[line:272] - INFO: epoch 021:    253 / 866 loss=2.112, loss_v1=0, loss_v2=0, nll_loss=0.881, ntokens=2123.8, nsentences=64, sample_size=2123.8, sample_size_v1=0, sample_size_v2=0, ppl=1.84, wps=525.1, ups=0.25, wpb=2123.8, bsz=64, num_updates=17540, lr=1.03677e-05, gnorm=5.185, clip=100, loss_scale=64, train_wall=40, gb_free=7.1, wall=70890
2023-05-08 19:38:09 - progress_bar.py[line:272] - INFO: epoch 021:    263 / 866 loss=2.109, loss_v1=0, loss_v2=0, nll_loss=0.876, ntokens=2145.7, nsentences=64, sample_size=2145.7, sample_size_v1=0, sample_size_v2=0, ppl=1.84, wps=534.1, ups=0.25, wpb=2145.7, bsz=64, num_updates=17550, lr=1.03554e-05, gnorm=5.24, clip=100, loss_scale=64, train_wall=40, gb_free=7.1, wall=70931
2023-05-08 19:38:50 - progress_bar.py[line:272] - INFO: epoch 021:    273 / 866 loss=2.094, loss_v1=0, loss_v2=0, nll_loss=0.858, ntokens=2144.3, nsentences=64, sample_size=2144.3, sample_size_v1=0, sample_size_v2=0, ppl=1.81, wps=531.5, ups=0.25, wpb=2144.3, bsz=64, num_updates=17560, lr=1.03431e-05, gnorm=5.136, clip=100, loss_scale=64, train_wall=40, gb_free=7.2, wall=70971
2023-05-08 19:39:30 - progress_bar.py[line:272] - INFO: epoch 021:    283 / 866 loss=2.104, loss_v1=0, loss_v2=0, nll_loss=0.871, ntokens=2148.3, nsentences=64, sample_size=2148.3, sample_size_v1=0, sample_size_v2=0, ppl=1.83, wps=529.8, ups=0.25, wpb=2148.3, bsz=64, num_updates=17570, lr=1.03308e-05, gnorm=5.085, clip=100, loss_scale=64, train_wall=41, gb_free=7.4, wall=71011
2023-05-08 19:40:11 - progress_bar.py[line:272] - INFO: epoch 021:    293 / 866 loss=2.081, loss_v1=0, loss_v2=0, nll_loss=0.846, ntokens=2141.2, nsentences=64, sample_size=2141.2, sample_size_v1=0, sample_size_v2=0, ppl=1.8, wps=525.7, ups=0.25, wpb=2141.2, bsz=64, num_updates=17580, lr=1.03186e-05, gnorm=5.145, clip=100, loss_scale=64, train_wall=41, gb_free=6.5, wall=71052
2023-05-08 19:40:52 - progress_bar.py[line:272] - INFO: epoch 021:    303 / 866 loss=2.086, loss_v1=0, loss_v2=0, nll_loss=0.85, ntokens=2142.7, nsentences=64, sample_size=2142.7, sample_size_v1=0, sample_size_v2=0, ppl=1.8, wps=526, ups=0.25, wpb=2142.7, bsz=64, num_updates=17590, lr=1.03063e-05, gnorm=5.525, clip=100, loss_scale=64, train_wall=41, gb_free=7.4, wall=71093
2023-05-08 19:41:33 - progress_bar.py[line:272] - INFO: epoch 021:    313 / 866 loss=2.09, loss_v1=0, loss_v2=0, nll_loss=0.853, ntokens=2106.8, nsentences=64, sample_size=2106.8, sample_size_v1=0, sample_size_v2=0, ppl=1.81, wps=516.8, ups=0.25, wpb=2106.8, bsz=64, num_updates=17600, lr=1.0294e-05, gnorm=5.456, clip=100, loss_scale=64, train_wall=41, gb_free=7.8, wall=71134
2023-05-08 19:42:13 - progress_bar.py[line:272] - INFO: epoch 021:    323 / 866 loss=2.103, loss_v1=0, loss_v2=0, nll_loss=0.869, ntokens=1985.8, nsentences=64, sample_size=1985.8, sample_size_v1=0, sample_size_v2=0, ppl=1.83, wps=493.6, ups=0.25, wpb=1985.8, bsz=64, num_updates=17610, lr=1.02817e-05, gnorm=5.948, clip=100, loss_scale=64, train_wall=40, gb_free=7.8, wall=71174
2023-05-08 19:42:53 - progress_bar.py[line:272] - INFO: epoch 021:    333 / 866 loss=2.087, loss_v1=0, loss_v2=0, nll_loss=0.851, ntokens=2134.8, nsentences=64, sample_size=2134.8, sample_size_v1=0, sample_size_v2=0, ppl=1.8, wps=527.7, ups=0.25, wpb=2134.8, bsz=64, num_updates=17620, lr=1.02694e-05, gnorm=4.998, clip=100, loss_scale=64, train_wall=40, gb_free=7.7, wall=71214
2023-05-08 19:43:33 - progress_bar.py[line:272] - INFO: epoch 021:    343 / 866 loss=2.075, loss_v1=0, loss_v2=0, nll_loss=0.837, ntokens=2000.4, nsentences=64, sample_size=2000.4, sample_size_v1=0, sample_size_v2=0, ppl=1.79, wps=497.7, ups=0.25, wpb=2000.4, bsz=64, num_updates=17630, lr=1.02571e-05, gnorm=5.239, clip=100, loss_scale=64, train_wall=40, gb_free=8.2, wall=71255
2023-05-08 19:44:14 - progress_bar.py[line:272] - INFO: epoch 021:    353 / 866 loss=2.122, loss_v1=0, loss_v2=0, nll_loss=0.89, ntokens=1984.7, nsentences=64, sample_size=1984.7, sample_size_v1=0, sample_size_v2=0, ppl=1.85, wps=495.3, ups=0.25, wpb=1984.7, bsz=64, num_updates=17640, lr=1.02449e-05, gnorm=5.892, clip=100, loss_scale=64, train_wall=40, gb_free=6.9, wall=71295
2023-05-08 19:44:53 - progress_bar.py[line:272] - INFO: epoch 021:    363 / 866 loss=2.109, loss_v1=0, loss_v2=0, nll_loss=0.876, ntokens=1971.5, nsentences=64, sample_size=1971.5, sample_size_v1=0, sample_size_v2=0, ppl=1.84, wps=494.6, ups=0.25, wpb=1971.5, bsz=64, num_updates=17650, lr=1.02326e-05, gnorm=5.897, clip=100, loss_scale=64, train_wall=40, gb_free=7.8, wall=71335
2023-05-08 19:45:33 - progress_bar.py[line:272] - INFO: epoch 021:    373 / 866 loss=2.087, loss_v1=0, loss_v2=0, nll_loss=0.852, ntokens=2020.9, nsentences=64, sample_size=2020.9, sample_size_v1=0, sample_size_v2=0, ppl=1.8, wps=504.8, ups=0.25, wpb=2020.9, bsz=64, num_updates=17660, lr=1.02203e-05, gnorm=5.518, clip=100, loss_scale=64, train_wall=40, gb_free=8.1, wall=71375
2023-05-08 19:46:14 - progress_bar.py[line:272] - INFO: epoch 021:    383 / 866 loss=2.086, loss_v1=0, loss_v2=0, nll_loss=0.848, ntokens=2159.1, nsentences=64, sample_size=2159.1, sample_size_v1=0, sample_size_v2=0, ppl=1.8, wps=536.6, ups=0.25, wpb=2159.1, bsz=64, num_updates=17670, lr=1.0208e-05, gnorm=5.325, clip=100, loss_scale=64, train_wall=40, gb_free=7.8, wall=71415
2023-05-08 19:46:54 - progress_bar.py[line:272] - INFO: epoch 021:    393 / 866 loss=2.11, loss_v1=0, loss_v2=0, nll_loss=0.877, ntokens=2036.6, nsentences=64, sample_size=2036.6, sample_size_v1=0, sample_size_v2=0, ppl=1.84, wps=504.2, ups=0.25, wpb=2036.6, bsz=64, num_updates=17680, lr=1.01957e-05, gnorm=5.668, clip=100, loss_scale=64, train_wall=40, gb_free=8.1, wall=71455
2023-05-08 19:47:35 - progress_bar.py[line:272] - INFO: epoch 021:    403 / 866 loss=2.094, loss_v1=0, loss_v2=0, nll_loss=0.86, ntokens=2108, nsentences=64, sample_size=2108, sample_size_v1=0, sample_size_v2=0, ppl=1.82, wps=519.4, ups=0.25, wpb=2108, bsz=64, num_updates=17690, lr=1.01834e-05, gnorm=5.225, clip=100, loss_scale=64, train_wall=41, gb_free=7.6, wall=71496
2023-05-08 19:48:15 - progress_bar.py[line:272] - INFO: epoch 021:    413 / 866 loss=2.087, loss_v1=0, loss_v2=0, nll_loss=0.851, ntokens=2140.1, nsentences=64, sample_size=2140.1, sample_size_v1=0, sample_size_v2=0, ppl=1.8, wps=526, ups=0.25, wpb=2140.1, bsz=64, num_updates=17700, lr=1.01712e-05, gnorm=5.365, clip=100, loss_scale=64, train_wall=41, gb_free=7.7, wall=71536
2023-05-08 19:48:56 - progress_bar.py[line:272] - INFO: epoch 021:    423 / 866 loss=2.062, loss_v1=0, loss_v2=0, nll_loss=0.823, ntokens=2052.3, nsentences=64, sample_size=2052.3, sample_size_v1=0, sample_size_v2=0, ppl=1.77, wps=505.5, ups=0.25, wpb=2052.3, bsz=64, num_updates=17710, lr=1.01589e-05, gnorm=5.204, clip=100, loss_scale=64, train_wall=41, gb_free=7.4, wall=71577
2023-05-08 19:49:37 - progress_bar.py[line:272] - INFO: epoch 021:    433 / 866 loss=2.086, loss_v1=0, loss_v2=0, nll_loss=0.85, ntokens=2119, nsentences=64, sample_size=2119, sample_size_v1=0, sample_size_v2=0, ppl=1.8, wps=522.8, ups=0.25, wpb=2119, bsz=64, num_updates=17720, lr=1.01466e-05, gnorm=5.218, clip=100, loss_scale=64, train_wall=40, gb_free=8.1, wall=71618
2023-05-08 19:50:17 - progress_bar.py[line:272] - INFO: epoch 021:    443 / 866 loss=2.127, loss_v1=0, loss_v2=0, nll_loss=0.895, ntokens=2046.8, nsentences=64, sample_size=2046.8, sample_size_v1=0, sample_size_v2=0, ppl=1.86, wps=506.2, ups=0.25, wpb=2046.8, bsz=64, num_updates=17730, lr=1.01343e-05, gnorm=5.497, clip=100, loss_scale=64, train_wall=40, gb_free=8.1, wall=71658
2023-05-08 19:50:57 - progress_bar.py[line:272] - INFO: epoch 021:    453 / 866 loss=2.099, loss_v1=0, loss_v2=0, nll_loss=0.864, ntokens=2003, nsentences=64, sample_size=2003, sample_size_v1=0, sample_size_v2=0, ppl=1.82, wps=497, ups=0.25, wpb=2003, bsz=64, num_updates=17740, lr=1.0122e-05, gnorm=5.485, clip=100, loss_scale=64, train_wall=40, gb_free=8.2, wall=71698
2023-05-08 19:51:38 - progress_bar.py[line:272] - INFO: epoch 021:    463 / 866 loss=2.109, loss_v1=0, loss_v2=0, nll_loss=0.877, ntokens=2168.7, nsentences=64, sample_size=2168.7, sample_size_v1=0, sample_size_v2=0, ppl=1.84, wps=537.8, ups=0.25, wpb=2168.7, bsz=64, num_updates=17750, lr=1.01097e-05, gnorm=5.429, clip=100, loss_scale=64, train_wall=40, gb_free=7.9, wall=71739
2023-05-08 19:52:18 - progress_bar.py[line:272] - INFO: epoch 021:    473 / 866 loss=2.112, loss_v1=0, loss_v2=0, nll_loss=0.88, ntokens=2189.3, nsentences=64, sample_size=2189.3, sample_size_v1=0, sample_size_v2=0, ppl=1.84, wps=540.6, ups=0.25, wpb=2189.3, bsz=64, num_updates=17760, lr=1.00975e-05, gnorm=5.343, clip=100, loss_scale=64, train_wall=40, gb_free=6.6, wall=71779
2023-05-08 19:52:59 - progress_bar.py[line:272] - INFO: epoch 021:    483 / 866 loss=2.094, loss_v1=0, loss_v2=0, nll_loss=0.857, ntokens=2149.8, nsentences=64, sample_size=2149.8, sample_size_v1=0, sample_size_v2=0, ppl=1.81, wps=529, ups=0.25, wpb=2149.8, bsz=64, num_updates=17770, lr=1.00852e-05, gnorm=5.373, clip=100, loss_scale=64, train_wall=41, gb_free=7.9, wall=71820
2023-05-08 19:53:39 - progress_bar.py[line:272] - INFO: epoch 021:    493 / 866 loss=2.076, loss_v1=0, loss_v2=0, nll_loss=0.838, ntokens=2050.1, nsentences=64, sample_size=2050.1, sample_size_v1=0, sample_size_v2=0, ppl=1.79, wps=505.1, ups=0.25, wpb=2050.1, bsz=64, num_updates=17780, lr=1.00729e-05, gnorm=5.306, clip=100, loss_scale=64, train_wall=41, gb_free=8.1, wall=71860
2023-05-08 19:54:20 - progress_bar.py[line:272] - INFO: epoch 021:    503 / 866 loss=2.098, loss_v1=0, loss_v2=0, nll_loss=0.863, ntokens=2092.8, nsentences=64, sample_size=2092.8, sample_size_v1=0, sample_size_v2=0, ppl=1.82, wps=519.5, ups=0.25, wpb=2092.8, bsz=64, num_updates=17790, lr=1.00606e-05, gnorm=5.317, clip=100, loss_scale=64, train_wall=40, gb_free=8.1, wall=71901
2023-05-08 19:55:00 - progress_bar.py[line:272] - INFO: epoch 021:    513 / 866 loss=2.115, loss_v1=0, loss_v2=0, nll_loss=0.882, ntokens=2135.9, nsentences=64, sample_size=2135.9, sample_size_v1=0, sample_size_v2=0, ppl=1.84, wps=534.2, ups=0.25, wpb=2135.9, bsz=64, num_updates=17800, lr=1.00483e-05, gnorm=5.339, clip=100, loss_scale=64, train_wall=40, gb_free=8, wall=71941
2023-05-08 19:55:39 - progress_bar.py[line:272] - INFO: epoch 021:    523 / 866 loss=2.09, loss_v1=0, loss_v2=0, nll_loss=0.855, ntokens=2121.2, nsentences=64, sample_size=2121.2, sample_size_v1=0, sample_size_v2=0, ppl=1.81, wps=532.5, ups=0.25, wpb=2121.2, bsz=64, num_updates=17810, lr=1.0036e-05, gnorm=5.07, clip=100, loss_scale=64, train_wall=40, gb_free=8.2, wall=71981
2023-05-08 19:56:19 - progress_bar.py[line:272] - INFO: epoch 021:    533 / 866 loss=2.084, loss_v1=0, loss_v2=0, nll_loss=0.846, ntokens=2043.5, nsentences=64, sample_size=2043.5, sample_size_v1=0, sample_size_v2=0, ppl=1.8, wps=510.3, ups=0.25, wpb=2043.5, bsz=64, num_updates=17820, lr=1.00237e-05, gnorm=5.032, clip=100, loss_scale=64, train_wall=40, gb_free=8.2, wall=72021
2023-05-08 19:57:00 - progress_bar.py[line:272] - INFO: epoch 021:    543 / 866 loss=2.108, loss_v1=0, loss_v2=0, nll_loss=0.874, ntokens=2165.2, nsentences=64, sample_size=2165.2, sample_size_v1=0, sample_size_v2=0, ppl=1.83, wps=540.4, ups=0.25, wpb=2165.2, bsz=64, num_updates=17830, lr=1.00115e-05, gnorm=5.51, clip=100, loss_scale=64, train_wall=40, gb_free=7.7, wall=72061
2023-05-08 19:57:20 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2023-05-08 19:57:44 - progress_bar.py[line:272] - INFO: epoch 021:    554 / 866 loss=2.108, loss_v1=0, loss_v2=0, nll_loss=0.875, ntokens=2296.7, nsentences=64, sample_size=2296.7, sample_size_v1=0, sample_size_v2=0, ppl=1.83, wps=516.1, ups=0.22, wpb=2296.7, bsz=64, num_updates=17840, lr=9.99918e-06, gnorm=4.655, clip=100, loss_scale=64, train_wall=44, gb_free=7.6, wall=72105
2023-05-08 19:58:24 - progress_bar.py[line:272] - INFO: epoch 021:    564 / 866 loss=2.101, loss_v1=0, loss_v2=0, nll_loss=0.867, ntokens=2250.1, nsentences=64, sample_size=2250.1, sample_size_v1=0, sample_size_v2=0, ppl=1.82, wps=558.4, ups=0.25, wpb=2250.1, bsz=64, num_updates=17850, lr=9.9869e-06, gnorm=4.993, clip=100, loss_scale=64, train_wall=40, gb_free=7.3, wall=72145
2023-05-08 19:59:05 - progress_bar.py[line:272] - INFO: epoch 021:    574 / 866 loss=2.094, loss_v1=0, loss_v2=0, nll_loss=0.858, ntokens=2186.6, nsentences=64, sample_size=2186.6, sample_size_v1=0, sample_size_v2=0, ppl=1.81, wps=544.3, ups=0.25, wpb=2186.6, bsz=64, num_updates=17860, lr=9.97461e-06, gnorm=4.951, clip=100, loss_scale=64, train_wall=40, gb_free=7.3, wall=72186
2023-05-08 19:59:45 - progress_bar.py[line:272] - INFO: epoch 021:    584 / 866 loss=2.11, loss_v1=0, loss_v2=0, nll_loss=0.876, ntokens=2097.5, nsentences=64, sample_size=2097.5, sample_size_v1=0, sample_size_v2=0, ppl=1.84, wps=519.3, ups=0.25, wpb=2097.5, bsz=64, num_updates=17870, lr=9.96233e-06, gnorm=5.732, clip=100, loss_scale=64, train_wall=40, gb_free=7, wall=72226
2023-05-08 20:00:26 - progress_bar.py[line:272] - INFO: epoch 021:    594 / 866 loss=2.088, loss_v1=0, loss_v2=0, nll_loss=0.851, ntokens=2123.3, nsentences=64, sample_size=2123.3, sample_size_v1=0, sample_size_v2=0, ppl=1.8, wps=522.6, ups=0.25, wpb=2123.3, bsz=64, num_updates=17880, lr=9.95005e-06, gnorm=5.286, clip=100, loss_scale=64, train_wall=41, gb_free=7.7, wall=72267
2023-05-08 20:01:06 - progress_bar.py[line:272] - INFO: epoch 021:    604 / 866 loss=2.076, loss_v1=0, loss_v2=0, nll_loss=0.84, ntokens=2066.5, nsentences=64, sample_size=2066.5, sample_size_v1=0, sample_size_v2=0, ppl=1.79, wps=511.1, ups=0.25, wpb=2066.5, bsz=64, num_updates=17890, lr=9.93776e-06, gnorm=5.337, clip=100, loss_scale=64, train_wall=40, gb_free=7.6, wall=72307
2023-05-08 20:01:46 - progress_bar.py[line:272] - INFO: epoch 021:    614 / 866 loss=2.111, loss_v1=0, loss_v2=0, nll_loss=0.88, ntokens=1920.8, nsentences=64, sample_size=1920.8, sample_size_v1=0, sample_size_v2=0, ppl=1.84, wps=476.4, ups=0.25, wpb=1920.8, bsz=64, num_updates=17900, lr=9.92548e-06, gnorm=6.057, clip=100, loss_scale=64, train_wall=40, gb_free=8, wall=72347
2023-05-08 20:02:26 - progress_bar.py[line:272] - INFO: epoch 021:    624 / 866 loss=2.105, loss_v1=0, loss_v2=0, nll_loss=0.868, ntokens=2039.6, nsentences=64, sample_size=2039.6, sample_size_v1=0, sample_size_v2=0, ppl=1.83, wps=507.7, ups=0.25, wpb=2039.6, bsz=64, num_updates=17910, lr=9.91319e-06, gnorm=5.322, clip=100, loss_scale=64, train_wall=40, gb_free=8.1, wall=72388
2023-05-08 20:03:06 - progress_bar.py[line:272] - INFO: epoch 021:    634 / 866 loss=2.087, loss_v1=0, loss_v2=0, nll_loss=0.851, ntokens=2012.5, nsentences=64, sample_size=2012.5, sample_size_v1=0, sample_size_v2=0, ppl=1.8, wps=503.1, ups=0.25, wpb=2012.5, bsz=64, num_updates=17920, lr=9.90091e-06, gnorm=5.209, clip=100, loss_scale=64, train_wall=40, gb_free=8.3, wall=72428
2023-05-08 20:03:47 - progress_bar.py[line:272] - INFO: epoch 021:    644 / 866 loss=2.087, loss_v1=0, loss_v2=0, nll_loss=0.851, ntokens=2085, nsentences=64, sample_size=2085, sample_size_v1=0, sample_size_v2=0, ppl=1.8, wps=516.1, ups=0.25, wpb=2085, bsz=64, num_updates=17930, lr=9.88863e-06, gnorm=5.491, clip=100, loss_scale=64, train_wall=40, gb_free=7.8, wall=72468
2023-05-08 20:04:27 - progress_bar.py[line:272] - INFO: epoch 021:    654 / 866 loss=2.105, loss_v1=0, loss_v2=0, nll_loss=0.871, ntokens=1951, nsentences=64, sample_size=1951, sample_size_v1=0, sample_size_v2=0, ppl=1.83, wps=487, ups=0.25, wpb=1951, bsz=64, num_updates=17940, lr=9.87634e-06, gnorm=5.706, clip=100, loss_scale=64, train_wall=40, gb_free=7.8, wall=72508
2023-05-08 20:05:07 - progress_bar.py[line:272] - INFO: epoch 021:    664 / 866 loss=2.119, loss_v1=0, loss_v2=0, nll_loss=0.887, ntokens=1940, nsentences=64, sample_size=1940, sample_size_v1=0, sample_size_v2=0, ppl=1.85, wps=483.7, ups=0.25, wpb=1940, bsz=64, num_updates=17950, lr=9.86406e-06, gnorm=6.091, clip=100, loss_scale=64, train_wall=40, gb_free=8.2, wall=72548
2023-05-08 20:05:47 - progress_bar.py[line:272] - INFO: epoch 021:    674 / 866 loss=2.099, loss_v1=0, loss_v2=0, nll_loss=0.863, ntokens=2070.8, nsentences=64, sample_size=2070.8, sample_size_v1=0, sample_size_v2=0, ppl=1.82, wps=514.3, ups=0.25, wpb=2070.8, bsz=64, num_updates=17960, lr=9.85177e-06, gnorm=5.469, clip=100, loss_scale=64, train_wall=40, gb_free=7.8, wall=72588
2023-05-08 20:06:27 - progress_bar.py[line:272] - INFO: epoch 021:    684 / 866 loss=2.087, loss_v1=0, loss_v2=0, nll_loss=0.851, ntokens=2040.2, nsentences=64, sample_size=2040.2, sample_size_v1=0, sample_size_v2=0, ppl=1.8, wps=509.6, ups=0.25, wpb=2040.2, bsz=64, num_updates=17970, lr=9.83949e-06, gnorm=5.554, clip=100, loss_scale=64, train_wall=40, gb_free=8.2, wall=72628
2023-05-08 20:07:08 - progress_bar.py[line:272] - INFO: epoch 021:    694 / 866 loss=2.107, loss_v1=0, loss_v2=0, nll_loss=0.876, ntokens=2072.2, nsentences=64, sample_size=2072.2, sample_size_v1=0, sample_size_v2=0, ppl=1.84, wps=514.6, ups=0.25, wpb=2072.2, bsz=64, num_updates=17980, lr=9.8272e-06, gnorm=5.452, clip=100, loss_scale=64, train_wall=40, gb_free=7.3, wall=72669
2023-05-08 20:07:48 - progress_bar.py[line:272] - INFO: epoch 021:    704 / 866 loss=2.096, loss_v1=0, loss_v2=0, nll_loss=0.862, ntokens=2017.9, nsentences=64, sample_size=2017.9, sample_size_v1=0, sample_size_v2=0, ppl=1.82, wps=501.4, ups=0.25, wpb=2017.9, bsz=64, num_updates=17990, lr=9.81492e-06, gnorm=5.365, clip=100, loss_scale=64, train_wall=40, gb_free=8.2, wall=72709
2023-05-08 20:08:28 - progress_bar.py[line:272] - INFO: epoch 021:    714 / 866 loss=2.104, loss_v1=0, loss_v2=0, nll_loss=0.869, ntokens=1871.5, nsentences=64, sample_size=1871.5, sample_size_v1=0, sample_size_v2=0, ppl=1.83, wps=468.6, ups=0.25, wpb=1871.5, bsz=64, num_updates=18000, lr=9.80264e-06, gnorm=5.679, clip=100, loss_scale=64, train_wall=40, gb_free=7.6, wall=72749
2023-05-08 20:09:08 - progress_bar.py[line:272] - INFO: epoch 021:    724 / 866 loss=2.069, loss_v1=0, loss_v2=0, nll_loss=0.831, ntokens=1998.5, nsentences=64, sample_size=1998.5, sample_size_v1=0, sample_size_v2=0, ppl=1.78, wps=498.7, ups=0.25, wpb=1998.5, bsz=64, num_updates=18010, lr=9.79035e-06, gnorm=5.225, clip=100, loss_scale=64, train_wall=40, gb_free=8.1, wall=72789
2023-05-08 20:09:48 - progress_bar.py[line:272] - INFO: epoch 021:    734 / 866 loss=2.085, loss_v1=0, loss_v2=0, nll_loss=0.851, ntokens=2017.8, nsentences=64, sample_size=2017.8, sample_size_v1=0, sample_size_v2=0, ppl=1.8, wps=503, ups=0.25, wpb=2017.8, bsz=64, num_updates=18020, lr=9.77807e-06, gnorm=5.523, clip=100, loss_scale=64, train_wall=40, gb_free=8, wall=72829
2023-05-08 20:10:28 - progress_bar.py[line:272] - INFO: epoch 021:    744 / 866 loss=2.082, loss_v1=0, loss_v2=0, nll_loss=0.845, ntokens=2152.2, nsentences=64, sample_size=2152.2, sample_size_v1=0, sample_size_v2=0, ppl=1.8, wps=536.2, ups=0.25, wpb=2152.2, bsz=64, num_updates=18030, lr=9.76578e-06, gnorm=5.112, clip=100, loss_scale=64, train_wall=40, gb_free=7.2, wall=72869
2023-05-08 20:11:08 - progress_bar.py[line:272] - INFO: epoch 021:    754 / 866 loss=2.075, loss_v1=0, loss_v2=0, nll_loss=0.834, ntokens=2102.9, nsentences=64, sample_size=2102.9, sample_size_v1=0, sample_size_v2=0, ppl=1.78, wps=524.9, ups=0.25, wpb=2102.9, bsz=64, num_updates=18040, lr=9.7535e-06, gnorm=5.326, clip=100, loss_scale=64, train_wall=40, gb_free=7.8, wall=72909
2023-05-08 20:11:48 - progress_bar.py[line:272] - INFO: epoch 021:    764 / 866 loss=2.08, loss_v1=0, loss_v2=0, nll_loss=0.842, ntokens=2112.8, nsentences=64, sample_size=2112.8, sample_size_v1=0, sample_size_v2=0, ppl=1.79, wps=525.4, ups=0.25, wpb=2112.8, bsz=64, num_updates=18050, lr=9.74122e-06, gnorm=5.189, clip=100, loss_scale=64, train_wall=40, gb_free=8.2, wall=72950
2023-05-08 20:12:28 - progress_bar.py[line:272] - INFO: epoch 021:    774 / 866 loss=2.087, loss_v1=0, loss_v2=0, nll_loss=0.854, ntokens=2150, nsentences=64, sample_size=2150, sample_size_v1=0, sample_size_v2=0, ppl=1.81, wps=539.4, ups=0.25, wpb=2150, bsz=64, num_updates=18060, lr=9.72893e-06, gnorm=5.501, clip=100, loss_scale=64, train_wall=40, gb_free=7.7, wall=72989
2023-05-08 20:13:09 - progress_bar.py[line:272] - INFO: epoch 021:    784 / 866 loss=2.09, loss_v1=0, loss_v2=0, nll_loss=0.855, ntokens=2176.4, nsentences=64, sample_size=2176.4, sample_size_v1=0, sample_size_v2=0, ppl=1.81, wps=536.9, ups=0.25, wpb=2176.4, bsz=64, num_updates=18070, lr=9.71665e-06, gnorm=5.57, clip=100, loss_scale=64, train_wall=40, gb_free=7.9, wall=73030
2023-05-08 20:13:49 - progress_bar.py[line:272] - INFO: epoch 021:    794 / 866 loss=2.11, loss_v1=0, loss_v2=0, nll_loss=0.875, ntokens=2016.9, nsentences=64, sample_size=2016.9, sample_size_v1=0, sample_size_v2=0, ppl=1.83, wps=506.8, ups=0.25, wpb=2016.9, bsz=64, num_updates=18080, lr=9.70436e-06, gnorm=5.697, clip=100, loss_scale=64, train_wall=40, gb_free=8, wall=73070
2023-05-08 20:14:28 - progress_bar.py[line:272] - INFO: epoch 021:    804 / 866 loss=2.09, loss_v1=0, loss_v2=0, nll_loss=0.854, ntokens=1963, nsentences=64, sample_size=1963, sample_size_v1=0, sample_size_v2=0, ppl=1.81, wps=493.6, ups=0.25, wpb=1963, bsz=64, num_updates=18090, lr=9.69208e-06, gnorm=5.745, clip=100, loss_scale=64, train_wall=40, gb_free=8, wall=73110
2023-05-08 20:15:09 - progress_bar.py[line:272] - INFO: epoch 021:    814 / 866 loss=2.074, loss_v1=0, loss_v2=0, nll_loss=0.835, ntokens=2102.1, nsentences=64, sample_size=2102.1, sample_size_v1=0, sample_size_v2=0, ppl=1.78, wps=523.9, ups=0.25, wpb=2102.1, bsz=64, num_updates=18100, lr=9.6798e-06, gnorm=5.341, clip=100, loss_scale=64, train_wall=40, gb_free=8.2, wall=73150
2023-05-08 20:15:49 - progress_bar.py[line:272] - INFO: epoch 021:    824 / 866 loss=2.067, loss_v1=0, loss_v2=0, nll_loss=0.827, ntokens=2124.1, nsentences=64, sample_size=2124.1, sample_size_v1=0, sample_size_v2=0, ppl=1.77, wps=525.6, ups=0.25, wpb=2124.1, bsz=64, num_updates=18110, lr=9.66751e-06, gnorm=5.025, clip=100, loss_scale=64, train_wall=40, gb_free=7.4, wall=73190
2023-05-08 20:16:30 - progress_bar.py[line:272] - INFO: epoch 021:    834 / 866 loss=2.057, loss_v1=0, loss_v2=0, nll_loss=0.818, ntokens=2173.1, nsentences=64, sample_size=2173.1, sample_size_v1=0, sample_size_v2=0, ppl=1.76, wps=534.8, ups=0.25, wpb=2173.1, bsz=64, num_updates=18120, lr=9.65523e-06, gnorm=4.909, clip=100, loss_scale=64, train_wall=41, gb_free=8.3, wall=73231
2023-05-08 20:17:10 - progress_bar.py[line:272] - INFO: epoch 021:    844 / 866 loss=2.074, loss_v1=0, loss_v2=0, nll_loss=0.838, ntokens=2148.3, nsentences=64, sample_size=2148.3, sample_size_v1=0, sample_size_v2=0, ppl=1.79, wps=533.5, ups=0.25, wpb=2148.3, bsz=64, num_updates=18130, lr=9.64294e-06, gnorm=5.158, clip=100, loss_scale=64, train_wall=40, gb_free=8.1, wall=73271
2023-05-08 20:17:50 - progress_bar.py[line:272] - INFO: epoch 021:    854 / 866 loss=2.052, loss_v1=0, loss_v2=0, nll_loss=0.812, ntokens=2153.4, nsentences=64, sample_size=2153.4, sample_size_v1=0, sample_size_v2=0, ppl=1.76, wps=531.5, ups=0.25, wpb=2153.4, bsz=64, num_updates=18140, lr=9.63066e-06, gnorm=4.981, clip=100, loss_scale=64, train_wall=40, gb_free=7.8, wall=73311
2023-05-08 20:18:31 - progress_bar.py[line:272] - INFO: epoch 021:    864 / 866 loss=2.096, loss_v1=0, loss_v2=0, nll_loss=0.861, ntokens=2070.8, nsentences=64, sample_size=2070.8, sample_size_v1=0, sample_size_v2=0, ppl=1.82, wps=513.5, ups=0.25, wpb=2070.8, bsz=64, num_updates=18150, lr=9.61838e-06, gnorm=5.311, clip=100, loss_scale=64, train_wall=40, gb_free=7.8, wall=73352
local datafile ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 1 begin to initialize row_count and line_idx-to-offset mapping
2023-05-08 20:18:37 - train.py[line:332] - INFO: end of epoch 21 (average epoch stats below)
2023-05-08 20:18:37 - progress_bar.py[line:282] - INFO: epoch 021 | loss 2.083 | loss_v1 0 | loss_v2 0 | nll_loss 0.847 | ntokens 2102.78 | nsentences 63.972 | sample_size 2102.78 | sample_size_v1 0 | sample_size_v2 0 | ppl 1.8 | wps 518.2 | ups 0.25 | wpb 2102.8 | bsz 64 | num_updates 18152 | lr 9.61592e-06 | gnorm 5.314 | clip 100 | loss_scale 64 | train_wall 3499 | gb_free 8.7 | wall 73358
2023-05-08 20:18:37 - trainer.py[line:639] - INFO: loading train data for epoch 22
local datafile ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 0 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 1 finished initializing row_count and line_idx-to-offset mapping
file ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 1 row count 27700 total row count 55400
slice_id 1 seek offset 27700
local datafile ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 0 finished initializing row_count and line_idx-to-offset mapping
file ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 0 row count 27700 total row count 55400
slice_id 0 seek offset 0
2023-05-08 20:18:39 - trainer.py[line:703] - INFO: begin training epoch 22
2023-05-08 20:18:39 - train.py[line:305] - INFO: Start iterating over samples
2023-05-08 20:19:12 - progress_bar.py[line:272] - INFO: epoch 022:      8 / 866 loss=2.05, loss_v1=0, loss_v2=0, nll_loss=0.809, ntokens=2070.9, nsentences=61.6, sample_size=2070.9, sample_size_v1=0, sample_size_v2=0, ppl=1.75, wps=498.5, ups=0.24, wpb=2070.9, bsz=61.6, num_updates=18160, lr=9.60609e-06, gnorm=5.345, clip=100, loss_scale=64, train_wall=39, gb_free=6.5, wall=73393
2023-05-08 20:19:53 - progress_bar.py[line:272] - INFO: epoch 022:     18 / 866 loss=2.043, loss_v1=0, loss_v2=0, nll_loss=0.803, ntokens=2050.4, nsentences=64, sample_size=2050.4, sample_size_v1=0, sample_size_v2=0, ppl=1.74, wps=504.5, ups=0.25, wpb=2050.4, bsz=64, num_updates=18170, lr=9.59381e-06, gnorm=5.879, clip=100, loss_scale=64, train_wall=41, gb_free=7.4, wall=73434
2023-05-08 20:20:33 - progress_bar.py[line:272] - INFO: epoch 022:     28 / 866 loss=2.049, loss_v1=0, loss_v2=0, nll_loss=0.808, ntokens=1965.3, nsentences=64, sample_size=1965.3, sample_size_v1=0, sample_size_v2=0, ppl=1.75, wps=485.3, ups=0.25, wpb=1965.3, bsz=64, num_updates=18180, lr=9.58152e-06, gnorm=5.677, clip=100, loss_scale=64, train_wall=40, gb_free=7.7, wall=73475
2023-05-08 20:21:15 - progress_bar.py[line:272] - INFO: epoch 022:     38 / 866 loss=1.993, loss_v1=0, loss_v2=0, nll_loss=0.745, ntokens=2219.2, nsentences=64, sample_size=2219.2, sample_size_v1=0, sample_size_v2=0, ppl=1.68, wps=538.6, ups=0.24, wpb=2219.2, bsz=64, num_updates=18190, lr=9.56924e-06, gnorm=5.11, clip=100, loss_scale=64, train_wall=41, gb_free=7.7, wall=73516
2023-05-08 20:21:55 - progress_bar.py[line:272] - INFO: epoch 022:     48 / 866 loss=2.022, loss_v1=0, loss_v2=0, nll_loss=0.779, ntokens=2006.4, nsentences=64, sample_size=2006.4, sample_size_v1=0, sample_size_v2=0, ppl=1.72, wps=493.1, ups=0.25, wpb=2006.4, bsz=64, num_updates=18200, lr=9.55696e-06, gnorm=5.392, clip=100, loss_scale=64, train_wall=41, gb_free=7, wall=73556
2023-05-08 20:22:36 - progress_bar.py[line:272] - INFO: epoch 022:     58 / 866 loss=1.968, loss_v1=0, loss_v2=0, nll_loss=0.72, ntokens=2051.7, nsentences=64, sample_size=2051.7, sample_size_v1=0, sample_size_v2=0, ppl=1.65, wps=509.2, ups=0.25, wpb=2051.7, bsz=64, num_updates=18210, lr=9.54467e-06, gnorm=5.695, clip=100, loss_scale=64, train_wall=40, gb_free=7.9, wall=73597
2023-05-08 20:23:18 - progress_bar.py[line:272] - INFO: epoch 022:     68 / 866 loss=1.95, loss_v1=0, loss_v2=0, nll_loss=0.699, ntokens=2441.3, nsentences=64, sample_size=2441.3, sample_size_v1=0, sample_size_v2=0, ppl=1.62, wps=580.5, ups=0.24, wpb=2441.3, bsz=64, num_updates=18220, lr=9.53239e-06, gnorm=4.682, clip=100, loss_scale=64, train_wall=42, gb_free=6.3, wall=73639
2023-05-08 20:23:59 - progress_bar.py[line:272] - INFO: epoch 022:     78 / 866 loss=2.012, loss_v1=0, loss_v2=0, nll_loss=0.765, ntokens=2331.2, nsentences=64, sample_size=2331.2, sample_size_v1=0, sample_size_v2=0, ppl=1.7, wps=560.2, ups=0.24, wpb=2331.2, bsz=64, num_updates=18230, lr=9.5201e-06, gnorm=4.942, clip=100, loss_scale=64, train_wall=42, gb_free=5.9, wall=73680
2023-05-08 20:24:40 - progress_bar.py[line:272] - INFO: epoch 022:     88 / 866 loss=2.033, loss_v1=0, loss_v2=0, nll_loss=0.789, ntokens=2130.8, nsentences=64, sample_size=2130.8, sample_size_v1=0, sample_size_v2=0, ppl=1.73, wps=518.3, ups=0.24, wpb=2130.8, bsz=64, num_updates=18240, lr=9.50782e-06, gnorm=5.959, clip=100, loss_scale=64, train_wall=41, gb_free=7.3, wall=73722
2023-05-08 20:25:22 - progress_bar.py[line:272] - INFO: epoch 022:     98 / 866 loss=2.024, loss_v1=0, loss_v2=0, nll_loss=0.779, ntokens=2150, nsentences=64, sample_size=2150, sample_size_v1=0, sample_size_v2=0, ppl=1.72, wps=522.4, ups=0.24, wpb=2150, bsz=64, num_updates=18250, lr=9.49554e-06, gnorm=5.537, clip=100, loss_scale=64, train_wall=41, gb_free=7.6, wall=73763
2023-05-08 20:26:02 - progress_bar.py[line:272] - INFO: epoch 022:    108 / 866 loss=2.082, loss_v1=0, loss_v2=0, nll_loss=0.847, ntokens=2012.3, nsentences=64, sample_size=2012.3, sample_size_v1=0, sample_size_v2=0, ppl=1.8, wps=494.3, ups=0.25, wpb=2012.3, bsz=64, num_updates=18260, lr=9.48325e-06, gnorm=5.781, clip=100, loss_scale=64, train_wall=41, gb_free=8.1, wall=73803
2023-05-08 20:26:44 - progress_bar.py[line:272] - INFO: epoch 022:    118 / 866 loss=2.083, loss_v1=0, loss_v2=0, nll_loss=0.847, ntokens=2123.2, nsentences=64, sample_size=2123.2, sample_size_v1=0, sample_size_v2=0, ppl=1.8, wps=512.8, ups=0.24, wpb=2123.2, bsz=64, num_updates=18270, lr=9.47097e-06, gnorm=5.583, clip=100, loss_scale=64, train_wall=41, gb_free=7.2, wall=73845
2023-05-08 20:27:25 - progress_bar.py[line:272] - INFO: epoch 022:    128 / 866 loss=2.085, loss_v1=0, loss_v2=0, nll_loss=0.847, ntokens=2216.2, nsentences=64, sample_size=2216.2, sample_size_v1=0, sample_size_v2=0, ppl=1.8, wps=534.7, ups=0.24, wpb=2216.2, bsz=64, num_updates=18280, lr=9.45868e-06, gnorm=5.72, clip=100, loss_scale=64, train_wall=41, gb_free=7.7, wall=73886
2023-05-08 20:28:06 - progress_bar.py[line:272] - INFO: epoch 022:    138 / 866 loss=2.04, loss_v1=0, loss_v2=0, nll_loss=0.797, ntokens=2223.9, nsentences=64, sample_size=2223.9, sample_size_v1=0, sample_size_v2=0, ppl=1.74, wps=542, ups=0.24, wpb=2223.9, bsz=64, num_updates=18290, lr=9.4464e-06, gnorm=5.038, clip=100, loss_scale=64, train_wall=41, gb_free=7.3, wall=73927
2023-05-08 20:28:48 - progress_bar.py[line:272] - INFO: epoch 022:    148 / 866 loss=2.025, loss_v1=0, loss_v2=0, nll_loss=0.782, ntokens=2202.7, nsentences=64, sample_size=2202.7, sample_size_v1=0, sample_size_v2=0, ppl=1.72, wps=532.3, ups=0.24, wpb=2202.7, bsz=64, num_updates=18300, lr=9.43412e-06, gnorm=4.951, clip=100, loss_scale=64, train_wall=41, gb_free=6.8, wall=73969
2023-05-08 20:29:29 - progress_bar.py[line:272] - INFO: epoch 022:    158 / 866 loss=2.065, loss_v1=0, loss_v2=0, nll_loss=0.828, ntokens=2218.6, nsentences=64, sample_size=2218.6, sample_size_v1=0, sample_size_v2=0, ppl=1.78, wps=536.1, ups=0.24, wpb=2218.6, bsz=64, num_updates=18310, lr=9.42183e-06, gnorm=5.439, clip=100, loss_scale=64, train_wall=41, gb_free=7.5, wall=74010
2023-05-08 20:30:10 - progress_bar.py[line:272] - INFO: epoch 022:    168 / 866 loss=2.06, loss_v1=0, loss_v2=0, nll_loss=0.821, ntokens=2127.3, nsentences=64, sample_size=2127.3, sample_size_v1=0, sample_size_v2=0, ppl=1.77, wps=523, ups=0.25, wpb=2127.3, bsz=64, num_updates=18320, lr=9.40955e-06, gnorm=5.443, clip=100, loss_scale=64, train_wall=41, gb_free=7.8, wall=74051
2023-05-08 20:30:51 - progress_bar.py[line:272] - INFO: epoch 022:    178 / 866 loss=2.053, loss_v1=0, loss_v2=0, nll_loss=0.812, ntokens=2069.7, nsentences=64, sample_size=2069.7, sample_size_v1=0, sample_size_v2=0, ppl=1.76, wps=505.8, ups=0.24, wpb=2069.7, bsz=64, num_updates=18330, lr=9.39726e-06, gnorm=5.467, clip=100, loss_scale=64, train_wall=41, gb_free=7.4, wall=74092
2023-05-08 20:31:32 - progress_bar.py[line:272] - INFO: epoch 022:    188 / 866 loss=2.044, loss_v1=0, loss_v2=0, nll_loss=0.802, ntokens=2227.8, nsentences=64, sample_size=2227.8, sample_size_v1=0, sample_size_v2=0, ppl=1.74, wps=540.8, ups=0.24, wpb=2227.8, bsz=64, num_updates=18340, lr=9.38498e-06, gnorm=5.364, clip=100, loss_scale=64, train_wall=41, gb_free=7.4, wall=74133
2023-05-08 20:32:00 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2023-05-08 20:32:17 - progress_bar.py[line:272] - INFO: epoch 022:    199 / 866 loss=2.062, loss_v1=0, loss_v2=0, nll_loss=0.823, ntokens=2158.4, nsentences=64, sample_size=2158.4, sample_size_v1=0, sample_size_v2=0, ppl=1.77, wps=480.8, ups=0.22, wpb=2158.4, bsz=64, num_updates=18350, lr=9.3727e-06, gnorm=5.368, clip=100, loss_scale=64, train_wall=45, gb_free=7.9, wall=74178
2023-05-08 20:32:57 - progress_bar.py[line:272] - INFO: epoch 022:    209 / 866 loss=2.076, loss_v1=0, loss_v2=0, nll_loss=0.839, ntokens=1953.8, nsentences=64, sample_size=1953.8, sample_size_v1=0, sample_size_v2=0, ppl=1.79, wps=485.8, ups=0.25, wpb=1953.8, bsz=64, num_updates=18360, lr=9.36041e-06, gnorm=5.5, clip=100, loss_scale=64, train_wall=40, gb_free=6.5, wall=74218
2023-05-08 20:33:37 - progress_bar.py[line:272] - INFO: epoch 022:    219 / 866 loss=2.087, loss_v1=0, loss_v2=0, nll_loss=0.852, ntokens=2210.3, nsentences=64, sample_size=2210.3, sample_size_v1=0, sample_size_v2=0, ppl=1.81, wps=548.3, ups=0.25, wpb=2210.3, bsz=64, num_updates=18370, lr=9.34813e-06, gnorm=5.301, clip=100, loss_scale=64, train_wall=40, gb_free=7.6, wall=74258
2023-05-08 20:34:17 - progress_bar.py[line:272] - INFO: epoch 022:    229 / 866 loss=2.08, loss_v1=0, loss_v2=0, nll_loss=0.844, ntokens=2168.5, nsentences=64, sample_size=2168.5, sample_size_v1=0, sample_size_v2=0, ppl=1.79, wps=539.3, ups=0.25, wpb=2168.5, bsz=64, num_updates=18380, lr=9.33584e-06, gnorm=5.146, clip=100, loss_scale=64, train_wall=40, gb_free=8, wall=74298
2023-05-08 20:34:58 - progress_bar.py[line:272] - INFO: epoch 022:    239 / 866 loss=2.082, loss_v1=0, loss_v2=0, nll_loss=0.843, ntokens=2160.5, nsentences=64, sample_size=2160.5, sample_size_v1=0, sample_size_v2=0, ppl=1.79, wps=537.5, ups=0.25, wpb=2160.5, bsz=64, num_updates=18390, lr=9.32356e-06, gnorm=5.118, clip=100, loss_scale=64, train_wall=40, gb_free=7.1, wall=74339
2023-05-08 20:35:38 - progress_bar.py[line:272] - INFO: epoch 022:    249 / 866 loss=2.085, loss_v1=0, loss_v2=0, nll_loss=0.847, ntokens=2135.9, nsentences=64, sample_size=2135.9, sample_size_v1=0, sample_size_v2=0, ppl=1.8, wps=527.1, ups=0.25, wpb=2135.9, bsz=64, num_updates=18400, lr=9.31128e-06, gnorm=5.573, clip=100, loss_scale=64, train_wall=40, gb_free=7.5, wall=74379
2023-05-08 20:36:18 - progress_bar.py[line:272] - INFO: epoch 022:    259 / 866 loss=2.088, loss_v1=0, loss_v2=0, nll_loss=0.853, ntokens=2120, nsentences=64, sample_size=2120, sample_size_v1=0, sample_size_v2=0, ppl=1.81, wps=525.8, ups=0.25, wpb=2120, bsz=64, num_updates=18410, lr=9.29899e-06, gnorm=5.286, clip=100, loss_scale=64, train_wall=40, gb_free=7.4, wall=74420
2023-05-08 20:36:59 - progress_bar.py[line:272] - INFO: epoch 022:    269 / 866 loss=2.089, loss_v1=0, loss_v2=0, nll_loss=0.854, ntokens=2134.9, nsentences=64, sample_size=2134.9, sample_size_v1=0, sample_size_v2=0, ppl=1.81, wps=524, ups=0.25, wpb=2134.9, bsz=64, num_updates=18420, lr=9.28671e-06, gnorm=5.476, clip=100, loss_scale=64, train_wall=41, gb_free=7.3, wall=74460
2023-05-08 20:37:40 - progress_bar.py[line:272] - INFO: epoch 022:    279 / 866 loss=2.074, loss_v1=0, loss_v2=0, nll_loss=0.836, ntokens=2176.7, nsentences=64, sample_size=2176.7, sample_size_v1=0, sample_size_v2=0, ppl=1.79, wps=533, ups=0.24, wpb=2176.7, bsz=64, num_updates=18430, lr=9.27442e-06, gnorm=5.413, clip=100, loss_scale=64, train_wall=41, gb_free=7, wall=74501
2023-05-08 20:38:20 - progress_bar.py[line:272] - INFO: epoch 022:    289 / 866 loss=2.07, loss_v1=0, loss_v2=0, nll_loss=0.831, ntokens=2182.2, nsentences=64, sample_size=2182.2, sample_size_v1=0, sample_size_v2=0, ppl=1.78, wps=539.3, ups=0.25, wpb=2182.2, bsz=64, num_updates=18440, lr=9.26214e-06, gnorm=5.229, clip=100, loss_scale=64, train_wall=40, gb_free=8.3, wall=74542
2023-05-08 20:39:01 - progress_bar.py[line:272] - INFO: epoch 022:    299 / 866 loss=2.074, loss_v1=0, loss_v2=0, nll_loss=0.837, ntokens=2111.5, nsentences=64, sample_size=2111.5, sample_size_v1=0, sample_size_v2=0, ppl=1.79, wps=523.4, ups=0.25, wpb=2111.5, bsz=64, num_updates=18450, lr=9.24986e-06, gnorm=5.583, clip=100, loss_scale=64, train_wall=40, gb_free=7.4, wall=74582
2023-05-08 20:39:41 - progress_bar.py[line:272] - INFO: epoch 022:    309 / 866 loss=2.076, loss_v1=0, loss_v2=0, nll_loss=0.839, ntokens=2156.3, nsentences=64, sample_size=2156.3, sample_size_v1=0, sample_size_v2=0, ppl=1.79, wps=534.4, ups=0.25, wpb=2156.3, bsz=64, num_updates=18460, lr=9.23757e-06, gnorm=5.56, clip=100, loss_scale=64, train_wall=40, gb_free=7.6, wall=74622
2023-05-08 20:40:22 - progress_bar.py[line:272] - INFO: epoch 022:    319 / 866 loss=2.08, loss_v1=0, loss_v2=0, nll_loss=0.841, ntokens=1965.2, nsentences=64, sample_size=1965.2, sample_size_v1=0, sample_size_v2=0, ppl=1.79, wps=486.2, ups=0.25, wpb=1965.2, bsz=64, num_updates=18470, lr=9.22529e-06, gnorm=6.219, clip=100, loss_scale=64, train_wall=40, gb_free=8.1, wall=74663
2023-05-08 20:41:02 - progress_bar.py[line:272] - INFO: epoch 022:    329 / 866 loss=2.095, loss_v1=0, loss_v2=0, nll_loss=0.861, ntokens=2086.5, nsentences=64, sample_size=2086.5, sample_size_v1=0, sample_size_v2=0, ppl=1.82, wps=519.4, ups=0.25, wpb=2086.5, bsz=64, num_updates=18480, lr=9.213e-06, gnorm=5.414, clip=100, loss_scale=64, train_wall=40, gb_free=7.6, wall=74703
2023-05-08 20:41:42 - progress_bar.py[line:272] - INFO: epoch 022:    339 / 866 loss=2.054, loss_v1=0, loss_v2=0, nll_loss=0.813, ntokens=2091.7, nsentences=64, sample_size=2091.7, sample_size_v1=0, sample_size_v2=0, ppl=1.76, wps=513.7, ups=0.25, wpb=2091.7, bsz=64, num_updates=18490, lr=9.20072e-06, gnorm=5.171, clip=100, loss_scale=64, train_wall=41, gb_free=8, wall=74744
2023-05-08 20:42:23 - progress_bar.py[line:272] - INFO: epoch 022:    349 / 866 loss=2.077, loss_v1=0, loss_v2=0, nll_loss=0.839, ntokens=1919.4, nsentences=64, sample_size=1919.4, sample_size_v1=0, sample_size_v2=0, ppl=1.79, wps=478.9, ups=0.25, wpb=1919.4, bsz=64, num_updates=18500, lr=9.18844e-06, gnorm=5.966, clip=100, loss_scale=64, train_wall=40, gb_free=7.9, wall=74784
2023-05-08 20:43:03 - progress_bar.py[line:272] - INFO: epoch 022:    359 / 866 loss=2.104, loss_v1=0, loss_v2=0, nll_loss=0.871, ntokens=1989.5, nsentences=64, sample_size=1989.5, sample_size_v1=0, sample_size_v2=0, ppl=1.83, wps=496.3, ups=0.25, wpb=1989.5, bsz=64, num_updates=18510, lr=9.17615e-06, gnorm=6, clip=100, loss_scale=64, train_wall=40, gb_free=7.7, wall=74824
2023-05-08 20:43:43 - progress_bar.py[line:272] - INFO: epoch 022:    369 / 866 loss=2.087, loss_v1=0, loss_v2=0, nll_loss=0.852, ntokens=1991.8, nsentences=64, sample_size=1991.8, sample_size_v1=0, sample_size_v2=0, ppl=1.8, wps=495.7, ups=0.25, wpb=1991.8, bsz=64, num_updates=18520, lr=9.16387e-06, gnorm=5.771, clip=100, loss_scale=64, train_wall=40, gb_free=8, wall=74864
2023-05-08 20:44:23 - progress_bar.py[line:272] - INFO: epoch 022:    379 / 866 loss=2.071, loss_v1=0, loss_v2=0, nll_loss=0.833, ntokens=2163.2, nsentences=64, sample_size=2163.2, sample_size_v1=0, sample_size_v2=0, ppl=1.78, wps=536.6, ups=0.25, wpb=2163.2, bsz=64, num_updates=18530, lr=9.15158e-06, gnorm=5.437, clip=100, loss_scale=64, train_wall=40, gb_free=7.3, wall=74904
2023-05-08 20:45:03 - progress_bar.py[line:272] - INFO: epoch 022:    389 / 866 loss=2.073, loss_v1=0, loss_v2=0, nll_loss=0.834, ntokens=2094.7, nsentences=64, sample_size=2094.7, sample_size_v1=0, sample_size_v2=0, ppl=1.78, wps=521, ups=0.25, wpb=2094.7, bsz=64, num_updates=18540, lr=9.1393e-06, gnorm=5.533, clip=100, loss_scale=64, train_wall=40, gb_free=8, wall=74944
2023-05-08 20:45:43 - progress_bar.py[line:272] - INFO: epoch 022:    399 / 866 loss=2.087, loss_v1=0, loss_v2=0, nll_loss=0.853, ntokens=2065.6, nsentences=64, sample_size=2065.6, sample_size_v1=0, sample_size_v2=0, ppl=1.81, wps=514.8, ups=0.25, wpb=2065.6, bsz=64, num_updates=18550, lr=9.12702e-06, gnorm=5.824, clip=100, loss_scale=64, train_wall=40, gb_free=8, wall=74985
2023-05-08 20:46:24 - progress_bar.py[line:272] - INFO: epoch 022:    409 / 866 loss=2.071, loss_v1=0, loss_v2=0, nll_loss=0.834, ntokens=2097.8, nsentences=64, sample_size=2097.8, sample_size_v1=0, sample_size_v2=0, ppl=1.78, wps=520.3, ups=0.25, wpb=2097.8, bsz=64, num_updates=18560, lr=9.11473e-06, gnorm=5.534, clip=100, loss_scale=64, train_wall=40, gb_free=7.9, wall=75025
2023-05-08 20:47:04 - progress_bar.py[line:272] - INFO: epoch 022:    419 / 866 loss=2.057, loss_v1=0, loss_v2=0, nll_loss=0.819, ntokens=2079.6, nsentences=64, sample_size=2079.6, sample_size_v1=0, sample_size_v2=0, ppl=1.76, wps=518.1, ups=0.25, wpb=2079.6, bsz=64, num_updates=18570, lr=9.10245e-06, gnorm=5.405, clip=100, loss_scale=64, train_wall=40, gb_free=7.5, wall=75065
2023-05-08 20:47:44 - progress_bar.py[line:272] - INFO: epoch 022:    429 / 866 loss=2.051, loss_v1=0, loss_v2=0, nll_loss=0.811, ntokens=2113.6, nsentences=64, sample_size=2113.6, sample_size_v1=0, sample_size_v2=0, ppl=1.75, wps=526.8, ups=0.25, wpb=2113.6, bsz=64, num_updates=18580, lr=9.09016e-06, gnorm=5.307, clip=100, loss_scale=64, train_wall=40, gb_free=8, wall=75105
2023-05-08 20:48:24 - progress_bar.py[line:272] - INFO: epoch 022:    439 / 866 loss=2.096, loss_v1=0, loss_v2=0, nll_loss=0.86, ntokens=2126.8, nsentences=64, sample_size=2126.8, sample_size_v1=0, sample_size_v2=0, ppl=1.82, wps=528.3, ups=0.25, wpb=2126.8, bsz=64, num_updates=18590, lr=9.07788e-06, gnorm=5.589, clip=100, loss_scale=64, train_wall=40, gb_free=6.7, wall=75145
2023-05-08 20:49:04 - progress_bar.py[line:272] - INFO: epoch 022:    449 / 866 loss=2.099, loss_v1=0, loss_v2=0, nll_loss=0.863, ntokens=1954.9, nsentences=64, sample_size=1954.9, sample_size_v1=0, sample_size_v2=0, ppl=1.82, wps=488.2, ups=0.25, wpb=1954.9, bsz=64, num_updates=18600, lr=9.0656e-06, gnorm=5.835, clip=100, loss_scale=64, train_wall=40, gb_free=7.6, wall=75186
2023-05-08 20:49:45 - progress_bar.py[line:272] - INFO: epoch 022:    459 / 866 loss=2.084, loss_v1=0, loss_v2=0, nll_loss=0.848, ntokens=2137.8, nsentences=64, sample_size=2137.8, sample_size_v1=0, sample_size_v2=0, ppl=1.8, wps=527.6, ups=0.25, wpb=2137.8, bsz=64, num_updates=18610, lr=9.05331e-06, gnorm=5.291, clip=100, loss_scale=64, train_wall=40, gb_free=7.9, wall=75226
2023-05-08 20:50:25 - progress_bar.py[line:272] - INFO: epoch 022:    469 / 866 loss=2.088, loss_v1=0, loss_v2=0, nll_loss=0.854, ntokens=2137.7, nsentences=64, sample_size=2137.7, sample_size_v1=0, sample_size_v2=0, ppl=1.81, wps=527.4, ups=0.25, wpb=2137.7, bsz=64, num_updates=18620, lr=9.04103e-06, gnorm=5.474, clip=100, loss_scale=64, train_wall=40, gb_free=6.9, wall=75267
2023-05-08 20:51:06 - progress_bar.py[line:272] - INFO: epoch 022:    479 / 866 loss=2.093, loss_v1=0, loss_v2=0, nll_loss=0.858, ntokens=2235.1, nsentences=64, sample_size=2235.1, sample_size_v1=0, sample_size_v2=0, ppl=1.81, wps=546.5, ups=0.24, wpb=2235.1, bsz=64, num_updates=18630, lr=9.02874e-06, gnorm=5.586, clip=100, loss_scale=64, train_wall=41, gb_free=7.9, wall=75307
2023-05-08 20:51:47 - progress_bar.py[line:272] - INFO: epoch 022:    489 / 866 loss=2.064, loss_v1=0, loss_v2=0, nll_loss=0.823, ntokens=2035.1, nsentences=64, sample_size=2035.1, sample_size_v1=0, sample_size_v2=0, ppl=1.77, wps=505.6, ups=0.25, wpb=2035.1, bsz=64, num_updates=18640, lr=9.01646e-06, gnorm=5.293, clip=100, loss_scale=64, train_wall=40, gb_free=8, wall=75348
2023-05-08 20:52:27 - progress_bar.py[line:272] - INFO: epoch 022:    499 / 866 loss=2.066, loss_v1=0, loss_v2=0, nll_loss=0.827, ntokens=2054, nsentences=64, sample_size=2054, sample_size_v1=0, sample_size_v2=0, ppl=1.77, wps=509, ups=0.25, wpb=2054, bsz=64, num_updates=18650, lr=9.00418e-06, gnorm=5.72, clip=100, loss_scale=64, train_wall=40, gb_free=7.6, wall=75388
2023-05-08 20:53:07 - progress_bar.py[line:272] - INFO: epoch 022:    509 / 866 loss=2.094, loss_v1=0, loss_v2=0, nll_loss=0.859, ntokens=2115, nsentences=64, sample_size=2115, sample_size_v1=0, sample_size_v2=0, ppl=1.81, wps=526.1, ups=0.25, wpb=2115, bsz=64, num_updates=18660, lr=8.99189e-06, gnorm=5.659, clip=100, loss_scale=64, train_wall=40, gb_free=8, wall=75428
2023-05-08 20:53:47 - progress_bar.py[line:272] - INFO: epoch 022:    519 / 866 loss=2.081, loss_v1=0, loss_v2=0, nll_loss=0.844, ntokens=2183.2, nsentences=64, sample_size=2183.2, sample_size_v1=0, sample_size_v2=0, ppl=1.8, wps=543.1, ups=0.25, wpb=2183.2, bsz=64, num_updates=18670, lr=8.97961e-06, gnorm=5.266, clip=100, loss_scale=64, train_wall=40, gb_free=8.3, wall=75468
2023-05-08 20:54:27 - progress_bar.py[line:272] - INFO: epoch 022:    529 / 866 loss=2.083, loss_v1=0, loss_v2=0, nll_loss=0.846, ntokens=1999.1, nsentences=64, sample_size=1999.1, sample_size_v1=0, sample_size_v2=0, ppl=1.8, wps=498.8, ups=0.25, wpb=1999.1, bsz=64, num_updates=18680, lr=8.96732e-06, gnorm=6.19, clip=100, loss_scale=64, train_wall=40, gb_free=7.9, wall=75509
2023-05-08 20:55:08 - progress_bar.py[line:272] - INFO: epoch 022:    539 / 866 loss=2.068, loss_v1=0, loss_v2=0, nll_loss=0.829, ntokens=2154.9, nsentences=64, sample_size=2154.9, sample_size_v1=0, sample_size_v2=0, ppl=1.78, wps=534.8, ups=0.25, wpb=2154.9, bsz=64, num_updates=18690, lr=8.95504e-06, gnorm=5.141, clip=100, loss_scale=64, train_wall=40, gb_free=7.8, wall=75549
2023-05-08 20:55:49 - progress_bar.py[line:272] - INFO: epoch 022:    549 / 866 loss=2.101, loss_v1=0, loss_v2=0, nll_loss=0.867, ntokens=2316.9, nsentences=64, sample_size=2316.9, sample_size_v1=0, sample_size_v2=0, ppl=1.82, wps=567.6, ups=0.24, wpb=2316.9, bsz=64, num_updates=18700, lr=8.94276e-06, gnorm=5.387, clip=100, loss_scale=64, train_wall=41, gb_free=7.9, wall=75590
2023-05-08 20:56:29 - progress_bar.py[line:272] - INFO: epoch 022:    559 / 866 loss=2.088, loss_v1=0, loss_v2=0, nll_loss=0.852, ntokens=2265.3, nsentences=64, sample_size=2265.3, sample_size_v1=0, sample_size_v2=0, ppl=1.8, wps=554.5, ups=0.24, wpb=2265.3, bsz=64, num_updates=18710, lr=8.93047e-06, gnorm=5.121, clip=100, loss_scale=64, train_wall=41, gb_free=7.2, wall=75631
2023-05-08 20:57:10 - progress_bar.py[line:272] - INFO: epoch 022:    569 / 866 loss=2.08, loss_v1=0, loss_v2=0, nll_loss=0.843, ntokens=2199.1, nsentences=64, sample_size=2199.1, sample_size_v1=0, sample_size_v2=0, ppl=1.79, wps=544.8, ups=0.25, wpb=2199.1, bsz=64, num_updates=18720, lr=8.91819e-06, gnorm=5.258, clip=100, loss_scale=64, train_wall=40, gb_free=7.5, wall=75671
2023-05-08 20:57:51 - progress_bar.py[line:272] - INFO: epoch 022:    579 / 866 loss=2.076, loss_v1=0, loss_v2=0, nll_loss=0.839, ntokens=2122.1, nsentences=64, sample_size=2122.1, sample_size_v1=0, sample_size_v2=0, ppl=1.79, wps=520.5, ups=0.25, wpb=2122.1, bsz=64, num_updates=18730, lr=8.9059e-06, gnorm=5.437, clip=100, loss_scale=64, train_wall=41, gb_free=7.4, wall=75712
2023-05-08 20:58:31 - progress_bar.py[line:272] - INFO: epoch 022:    589 / 866 loss=2.098, loss_v1=0, loss_v2=0, nll_loss=0.863, ntokens=2075.5, nsentences=64, sample_size=2075.5, sample_size_v1=0, sample_size_v2=0, ppl=1.82, wps=512.9, ups=0.25, wpb=2075.5, bsz=64, num_updates=18740, lr=8.89362e-06, gnorm=5.997, clip=100, loss_scale=64, train_wall=40, gb_free=7, wall=75752
2023-05-08 20:59:11 - progress_bar.py[line:272] - INFO: epoch 022:    599 / 866 loss=2.056, loss_v1=0, loss_v2=0, nll_loss=0.816, ntokens=2123.9, nsentences=64, sample_size=2123.9, sample_size_v1=0, sample_size_v2=0, ppl=1.76, wps=525.5, ups=0.25, wpb=2123.9, bsz=64, num_updates=18750, lr=8.88134e-06, gnorm=5.464, clip=100, loss_scale=64, train_wall=40, gb_free=8.6, wall=75793
2023-05-08 20:59:52 - progress_bar.py[line:272] - INFO: epoch 022:    609 / 866 loss=2.071, loss_v1=0, loss_v2=0, nll_loss=0.836, ntokens=2007.2, nsentences=64, sample_size=2007.2, sample_size_v1=0, sample_size_v2=0, ppl=1.79, wps=497.2, ups=0.25, wpb=2007.2, bsz=64, num_updates=18760, lr=8.86905e-06, gnorm=5.895, clip=100, loss_scale=64, train_wall=40, gb_free=6.7, wall=75833
2023-05-08 21:00:32 - progress_bar.py[line:272] - INFO: epoch 022:    619 / 866 loss=2.101, loss_v1=0, loss_v2=0, nll_loss=0.868, ntokens=1950, nsentences=64, sample_size=1950, sample_size_v1=0, sample_size_v2=0, ppl=1.82, wps=487.6, ups=0.25, wpb=1950, bsz=64, num_updates=18770, lr=8.85677e-06, gnorm=6.203, clip=100, loss_scale=64, train_wall=40, gb_free=8.1, wall=75873
2023-05-08 21:01:12 - progress_bar.py[line:272] - INFO: epoch 022:    629 / 866 loss=2.068, loss_v1=0, loss_v2=0, nll_loss=0.828, ntokens=2034.9, nsentences=64, sample_size=2034.9, sample_size_v1=0, sample_size_v2=0, ppl=1.78, wps=505.4, ups=0.25, wpb=2034.9, bsz=64, num_updates=18780, lr=8.84448e-06, gnorm=5.853, clip=100, loss_scale=64, train_wall=40, gb_free=8.3, wall=75913
2023-05-08 21:01:52 - progress_bar.py[line:272] - INFO: epoch 022:    639 / 866 loss=2.07, loss_v1=0, loss_v2=0, nll_loss=0.832, ntokens=2084.2, nsentences=64, sample_size=2084.2, sample_size_v1=0, sample_size_v2=0, ppl=1.78, wps=517.4, ups=0.25, wpb=2084.2, bsz=64, num_updates=18790, lr=8.8322e-06, gnorm=5.596, clip=100, loss_scale=64, train_wall=40, gb_free=7.3, wall=75954
2023-05-08 21:02:32 - progress_bar.py[line:272] - INFO: epoch 022:    649 / 866 loss=2.082, loss_v1=0, loss_v2=0, nll_loss=0.846, ntokens=2024.1, nsentences=64, sample_size=2024.1, sample_size_v1=0, sample_size_v2=0, ppl=1.8, wps=508.4, ups=0.25, wpb=2024.1, bsz=64, num_updates=18800, lr=8.81992e-06, gnorm=5.956, clip=100, loss_scale=64, train_wall=40, gb_free=7.8, wall=75993
2023-05-08 21:03:12 - progress_bar.py[line:272] - INFO: epoch 022:    659 / 866 loss=2.101, loss_v1=0, loss_v2=0, nll_loss=0.867, ntokens=1897.3, nsentences=64, sample_size=1897.3, sample_size_v1=0, sample_size_v2=0, ppl=1.82, wps=472.6, ups=0.25, wpb=1897.3, bsz=64, num_updates=18810, lr=8.80763e-06, gnorm=6.442, clip=100, loss_scale=64, train_wall=40, gb_free=8.4, wall=76033
2023-05-08 21:03:53 - progress_bar.py[line:272] - INFO: epoch 022:    669 / 866 loss=2.095, loss_v1=0, loss_v2=0, nll_loss=0.861, ntokens=2007.8, nsentences=64, sample_size=2007.8, sample_size_v1=0, sample_size_v2=0, ppl=1.82, wps=497.8, ups=0.25, wpb=2007.8, bsz=64, num_updates=18820, lr=8.79535e-06, gnorm=5.932, clip=100, loss_scale=64, train_wall=40, gb_free=7.7, wall=76074
2023-05-08 21:04:33 - progress_bar.py[line:272] - INFO: epoch 022:    679 / 866 loss=2.078, loss_v1=0, loss_v2=0, nll_loss=0.84, ntokens=2082.9, nsentences=64, sample_size=2082.9, sample_size_v1=0, sample_size_v2=0, ppl=1.79, wps=519.1, ups=0.25, wpb=2082.9, bsz=64, num_updates=18830, lr=8.78306e-06, gnorm=5.772, clip=100, loss_scale=64, train_wall=40, gb_free=7.8, wall=76114
2023-05-08 21:05:13 - progress_bar.py[line:272] - INFO: epoch 022:    689 / 866 loss=2.076, loss_v1=0, loss_v2=0, nll_loss=0.837, ntokens=1992.1, nsentences=64, sample_size=1992.1, sample_size_v1=0, sample_size_v2=0, ppl=1.79, wps=495.4, ups=0.25, wpb=1992.1, bsz=64, num_updates=18840, lr=8.77078e-06, gnorm=5.757, clip=100, loss_scale=64, train_wall=40, gb_free=6.9, wall=76154
2023-05-08 21:05:53 - progress_bar.py[line:272] - INFO: epoch 022:    699 / 866 loss=2.1, loss_v1=0, loss_v2=0, nll_loss=0.866, ntokens=2100.7, nsentences=64, sample_size=2100.7, sample_size_v1=0, sample_size_v2=0, ppl=1.82, wps=520.1, ups=0.25, wpb=2100.7, bsz=64, num_updates=18850, lr=8.7585e-06, gnorm=5.88, clip=100, loss_scale=64, train_wall=40, gb_free=7.9, wall=76195
2023-05-08 21:06:34 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2023-05-08 21:06:38 - progress_bar.py[line:272] - INFO: epoch 022:    710 / 866 loss=2.088, loss_v1=0, loss_v2=0, nll_loss=0.854, ntokens=1953.4, nsentences=64, sample_size=1953.4, sample_size_v1=0, sample_size_v2=0, ppl=1.81, wps=441.6, ups=0.23, wpb=1953.4, bsz=64, num_updates=18860, lr=8.74621e-06, gnorm=5.849, clip=100, loss_scale=64, train_wall=44, gb_free=7.4, wall=76239
2023-05-08 21:07:18 - progress_bar.py[line:272] - INFO: epoch 022:    720 / 866 loss=2.063, loss_v1=0, loss_v2=0, nll_loss=0.823, ntokens=1913.9, nsentences=64, sample_size=1913.9, sample_size_v1=0, sample_size_v2=0, ppl=1.77, wps=476.6, ups=0.25, wpb=1913.9, bsz=64, num_updates=18870, lr=8.73393e-06, gnorm=5.71, clip=100, loss_scale=64, train_wall=40, gb_free=7.2, wall=76279
2023-05-08 21:07:58 - progress_bar.py[line:272] - INFO: epoch 022:    730 / 866 loss=2.06, loss_v1=0, loss_v2=0, nll_loss=0.821, ntokens=2011.1, nsentences=64, sample_size=2011.1, sample_size_v1=0, sample_size_v2=0, ppl=1.77, wps=501.8, ups=0.25, wpb=2011.1, bsz=64, num_updates=18880, lr=8.72164e-06, gnorm=5.903, clip=100, loss_scale=64, train_wall=40, gb_free=8.2, wall=76319
2023-05-08 21:08:38 - progress_bar.py[line:272] - INFO: epoch 022:    740 / 866 loss=2.083, loss_v1=0, loss_v2=0, nll_loss=0.849, ntokens=2124.3, nsentences=64, sample_size=2124.3, sample_size_v1=0, sample_size_v2=0, ppl=1.8, wps=526.1, ups=0.25, wpb=2124.3, bsz=64, num_updates=18890, lr=8.70936e-06, gnorm=5.746, clip=100, loss_scale=64, train_wall=40, gb_free=7.7, wall=76359
2023-05-08 21:09:19 - progress_bar.py[line:272] - INFO: epoch 022:    750 / 866 loss=2.055, loss_v1=0, loss_v2=0, nll_loss=0.814, ntokens=2131.9, nsentences=64, sample_size=2131.9, sample_size_v1=0, sample_size_v2=0, ppl=1.76, wps=522, ups=0.24, wpb=2131.9, bsz=64, num_updates=18900, lr=8.69708e-06, gnorm=5.474, clip=100, loss_scale=64, train_wall=41, gb_free=8, wall=76400
2023-05-08 21:10:00 - progress_bar.py[line:272] - INFO: epoch 022:    760 / 866 loss=2.068, loss_v1=0, loss_v2=0, nll_loss=0.828, ntokens=2080.6, nsentences=64, sample_size=2080.6, sample_size_v1=0, sample_size_v2=0, ppl=1.78, wps=514.2, ups=0.25, wpb=2080.6, bsz=64, num_updates=18910, lr=8.68479e-06, gnorm=5.745, clip=100, loss_scale=64, train_wall=40, gb_free=7.6, wall=76441
2023-05-08 21:10:40 - progress_bar.py[line:272] - INFO: epoch 022:    770 / 866 loss=2.061, loss_v1=0, loss_v2=0, nll_loss=0.823, ntokens=2072.8, nsentences=64, sample_size=2072.8, sample_size_v1=0, sample_size_v2=0, ppl=1.77, wps=512.6, ups=0.25, wpb=2072.8, bsz=64, num_updates=18920, lr=8.67251e-06, gnorm=5.918, clip=100, loss_scale=64, train_wall=40, gb_free=8.3, wall=76481
2023-05-08 21:11:21 - progress_bar.py[line:272] - INFO: epoch 022:    780 / 866 loss=2.082, loss_v1=0, loss_v2=0, nll_loss=0.845, ntokens=2340.3, nsentences=64, sample_size=2340.3, sample_size_v1=0, sample_size_v2=0, ppl=1.8, wps=572.8, ups=0.24, wpb=2340.3, bsz=64, num_updates=18930, lr=8.66022e-06, gnorm=5.139, clip=100, loss_scale=64, train_wall=41, gb_free=7.7, wall=76522
2023-05-08 21:12:01 - progress_bar.py[line:272] - INFO: epoch 022:    790 / 866 loss=2.077, loss_v1=0, loss_v2=0, nll_loss=0.84, ntokens=1961, nsentences=64, sample_size=1961, sample_size_v1=0, sample_size_v2=0, ppl=1.79, wps=488.9, ups=0.25, wpb=1961, bsz=64, num_updates=18940, lr=8.64794e-06, gnorm=5.946, clip=100, loss_scale=64, train_wall=40, gb_free=7.2, wall=76562
2023-05-08 21:12:41 - progress_bar.py[line:272] - INFO: epoch 022:    800 / 866 loss=2.088, loss_v1=0, loss_v2=0, nll_loss=0.852, ntokens=2027.5, nsentences=64, sample_size=2027.5, sample_size_v1=0, sample_size_v2=0, ppl=1.8, wps=504.8, ups=0.25, wpb=2027.5, bsz=64, num_updates=18950, lr=8.63566e-06, gnorm=5.758, clip=100, loss_scale=64, train_wall=40, gb_free=8.1, wall=76602
2023-05-08 21:13:21 - progress_bar.py[line:272] - INFO: epoch 022:    810 / 866 loss=2.052, loss_v1=0, loss_v2=0, nll_loss=0.811, ntokens=2021.4, nsentences=64, sample_size=2021.4, sample_size_v1=0, sample_size_v2=0, ppl=1.75, wps=506.5, ups=0.25, wpb=2021.4, bsz=64, num_updates=18960, lr=8.62337e-06, gnorm=5.579, clip=100, loss_scale=64, train_wall=40, gb_free=7.8, wall=76642
2023-05-08 21:14:01 - progress_bar.py[line:272] - INFO: epoch 022:    820 / 866 loss=2.044, loss_v1=0, loss_v2=0, nll_loss=0.803, ntokens=2070, nsentences=64, sample_size=2070, sample_size_v1=0, sample_size_v2=0, ppl=1.74, wps=515.6, ups=0.25, wpb=2070, bsz=64, num_updates=18970, lr=8.61109e-06, gnorm=5.384, clip=100, loss_scale=64, train_wall=40, gb_free=7.8, wall=76682
2023-05-08 21:14:42 - progress_bar.py[line:272] - INFO: epoch 022:    830 / 866 loss=2.046, loss_v1=0, loss_v2=0, nll_loss=0.804, ntokens=2200.4, nsentences=64, sample_size=2200.4, sample_size_v1=0, sample_size_v2=0, ppl=1.75, wps=533.9, ups=0.24, wpb=2200.4, bsz=64, num_updates=18980, lr=8.5988e-06, gnorm=5.121, clip=100, loss_scale=64, train_wall=41, gb_free=8, wall=76724
2023-05-08 21:15:23 - progress_bar.py[line:272] - INFO: epoch 022:    840 / 866 loss=2.06, loss_v1=0, loss_v2=0, nll_loss=0.822, ntokens=2111.9, nsentences=64, sample_size=2111.9, sample_size_v1=0, sample_size_v2=0, ppl=1.77, wps=521.6, ups=0.25, wpb=2111.9, bsz=64, num_updates=18990, lr=8.58652e-06, gnorm=5.247, clip=100, loss_scale=64, train_wall=40, gb_free=7.6, wall=76764
2023-05-08 21:16:03 - progress_bar.py[line:272] - INFO: epoch 022:    850 / 866 loss=2.049, loss_v1=0, loss_v2=0, nll_loss=0.81, ntokens=2216.5, nsentences=64, sample_size=2216.5, sample_size_v1=0, sample_size_v2=0, ppl=1.75, wps=547.1, ups=0.25, wpb=2216.5, bsz=64, num_updates=19000, lr=8.57424e-06, gnorm=4.927, clip=100, loss_scale=64, train_wall=40, gb_free=8.1, wall=76805
2023-05-08 21:16:44 - progress_bar.py[line:272] - INFO: epoch 022:    860 / 866 loss=2.042, loss_v1=0, loss_v2=0, nll_loss=0.8, ntokens=2044.3, nsentences=64, sample_size=2044.3, sample_size_v1=0, sample_size_v2=0, ppl=1.74, wps=507.4, ups=0.25, wpb=2044.3, bsz=64, num_updates=19010, lr=8.56195e-06, gnorm=5.455, clip=100, loss_scale=64, train_wall=40, gb_free=8.1, wall=76845
2023-05-08 21:17:06 - train.py[line:332] - INFO: end of epoch 22 (average epoch stats below)
local datafile ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 1 begin to initialize row_count and line_idx-to-offset mapping
2023-05-08 21:17:06 - progress_bar.py[line:282] - INFO: epoch 022 | loss 2.067 | loss_v1 0 | loss_v2 0 | nll_loss 0.829 | ntokens 2103.46 | nsentences 63.972 | sample_size 2103.46 | sample_size_v1 0 | sample_size_v2 0 | ppl 1.78 | wps 517.9 | ups 0.25 | wpb 2103.5 | bsz 64 | num_updates 19016 | lr 8.55458e-06 | gnorm 5.55 | clip 100 | loss_scale 64 | train_wall 3503 | gb_free 8.7 | wall 76868
2023-05-08 21:17:06 - trainer.py[line:639] - INFO: loading train data for epoch 23
local datafile ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 0 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 0 finished initializing row_count and line_idx-to-offset mapping
file ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 0 row count 27700 total row count 55400
slice_id 0 seek offset 0
2023-05-08 21:17:08 - trainer.py[line:703] - INFO: begin training epoch 23
2023-05-08 21:17:08 - train.py[line:305] - INFO: Start iterating over samples
local datafile ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 1 finished initializing row_count and line_idx-to-offset mapping
file ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 1 row count 27700 total row count 55400
slice_id 1 seek offset 27700
2023-05-08 21:17:25 - progress_bar.py[line:272] - INFO: epoch 023:      4 / 866 loss=2.071, loss_v1=0, loss_v2=0, nll_loss=0.833, ntokens=2092.9, nsentences=61.6, sample_size=2092.9, sample_size_v1=0, sample_size_v2=0, ppl=1.78, wps=506.1, ups=0.24, wpb=2092.9, bsz=61.6, num_updates=19020, lr=8.54967e-06, gnorm=5.919, clip=100, loss_scale=64, train_wall=39, gb_free=7.1, wall=76886
2023-05-08 21:18:06 - progress_bar.py[line:272] - INFO: epoch 023:     14 / 866 loss=2.042, loss_v1=0, loss_v2=0, nll_loss=0.8, ntokens=2059.7, nsentences=64, sample_size=2059.7, sample_size_v1=0, sample_size_v2=0, ppl=1.74, wps=507.9, ups=0.25, wpb=2059.7, bsz=64, num_updates=19030, lr=8.53738e-06, gnorm=6, clip=100, loss_scale=64, train_wall=41, gb_free=7.5, wall=76927
2023-05-08 21:18:46 - progress_bar.py[line:272] - INFO: epoch 023:     24 / 866 loss=2.009, loss_v1=0, loss_v2=0, nll_loss=0.764, ntokens=2025.5, nsentences=64, sample_size=2025.5, sample_size_v1=0, sample_size_v2=0, ppl=1.7, wps=500.3, ups=0.25, wpb=2025.5, bsz=64, num_updates=19040, lr=8.5251e-06, gnorm=5.908, clip=100, loss_scale=64, train_wall=40, gb_free=7.6, wall=76967
2023-05-08 21:19:27 - progress_bar.py[line:272] - INFO: epoch 023:     34 / 866 loss=1.998, loss_v1=0, loss_v2=0, nll_loss=0.75, ntokens=2115.7, nsentences=64, sample_size=2115.7, sample_size_v1=0, sample_size_v2=0, ppl=1.68, wps=517.8, ups=0.24, wpb=2115.7, bsz=64, num_updates=19050, lr=8.51282e-06, gnorm=5.896, clip=100, loss_scale=64, train_wall=41, gb_free=7.4, wall=77008
2023-05-08 21:20:08 - progress_bar.py[line:272] - INFO: epoch 023:     44 / 866 loss=1.988, loss_v1=0, loss_v2=0, nll_loss=0.741, ntokens=2111.3, nsentences=64, sample_size=2111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.67, wps=518.8, ups=0.25, wpb=2111.3, bsz=64, num_updates=19060, lr=8.50053e-06, gnorm=5.548, clip=100, loss_scale=64, train_wall=41, gb_free=7.2, wall=77049
2023-05-08 21:20:48 - progress_bar.py[line:272] - INFO: epoch 023:     54 / 866 loss=2.007, loss_v1=0, loss_v2=0, nll_loss=0.763, ntokens=2019.6, nsentences=64, sample_size=2019.6, sample_size_v1=0, sample_size_v2=0, ppl=1.7, wps=496.8, ups=0.25, wpb=2019.6, bsz=64, num_updates=19070, lr=8.48825e-06, gnorm=5.77, clip=100, loss_scale=64, train_wall=41, gb_free=7.5, wall=77090
2023-05-08 21:21:30 - progress_bar.py[line:272] - INFO: epoch 023:     64 / 866 loss=1.932, loss_v1=0, loss_v2=0, nll_loss=0.68, ntokens=2283.9, nsentences=64, sample_size=2283.9, sample_size_v1=0, sample_size_v2=0, ppl=1.6, wps=551.2, ups=0.24, wpb=2283.9, bsz=64, num_updates=19080, lr=8.47596e-06, gnorm=4.969, clip=100, loss_scale=64, train_wall=41, gb_free=6.9, wall=77131
2023-05-08 21:22:12 - progress_bar.py[line:272] - INFO: epoch 023:     74 / 866 loss=1.98, loss_v1=0, loss_v2=0, nll_loss=0.73, ntokens=2393.5, nsentences=64, sample_size=2393.5, sample_size_v1=0, sample_size_v2=0, ppl=1.66, wps=572.1, ups=0.24, wpb=2393.5, bsz=64, num_updates=19090, lr=8.46368e-06, gnorm=4.869, clip=100, loss_scale=64, train_wall=42, gb_free=6.4, wall=77173
2023-05-08 21:22:53 - progress_bar.py[line:272] - INFO: epoch 023:     84 / 866 loss=2.01, loss_v1=0, loss_v2=0, nll_loss=0.763, ntokens=2213.9, nsentences=64, sample_size=2213.9, sample_size_v1=0, sample_size_v2=0, ppl=1.7, wps=535.2, ups=0.24, wpb=2213.9, bsz=64, num_updates=19100, lr=8.4514e-06, gnorm=5.804, clip=100, loss_scale=64, train_wall=41, gb_free=6.8, wall=77214
2023-05-08 21:23:34 - progress_bar.py[line:272] - INFO: epoch 023:     94 / 866 loss=1.988, loss_v1=0, loss_v2=0, nll_loss=0.739, ntokens=2148.5, nsentences=64, sample_size=2148.5, sample_size_v1=0, sample_size_v2=0, ppl=1.67, wps=524.3, ups=0.24, wpb=2148.5, bsz=64, num_updates=19110, lr=8.43911e-06, gnorm=5.62, clip=100, loss_scale=64, train_wall=41, gb_free=8, wall=77255
2023-05-08 21:24:15 - progress_bar.py[line:272] - INFO: epoch 023:    104 / 866 loss=2.066, loss_v1=0, loss_v2=0, nll_loss=0.828, ntokens=2017.3, nsentences=64, sample_size=2017.3, sample_size_v1=0, sample_size_v2=0, ppl=1.78, wps=494.1, ups=0.24, wpb=2017.3, bsz=64, num_updates=19120, lr=8.42683e-06, gnorm=6.057, clip=100, loss_scale=64, train_wall=41, gb_free=7.9, wall=77296
2023-05-08 21:24:56 - progress_bar.py[line:272] - INFO: epoch 023:    114 / 866 loss=2.074, loss_v1=0, loss_v2=0, nll_loss=0.837, ntokens=2055.6, nsentences=64, sample_size=2055.6, sample_size_v1=0, sample_size_v2=0, ppl=1.79, wps=500.6, ups=0.24, wpb=2055.6, bsz=64, num_updates=19130, lr=8.41454e-06, gnorm=5.748, clip=100, loss_scale=64, train_wall=41, gb_free=7.6, wall=77337
2023-05-08 21:25:37 - progress_bar.py[line:272] - INFO: epoch 023:    124 / 866 loss=2.068, loss_v1=0, loss_v2=0, nll_loss=0.829, ntokens=2215.8, nsentences=64, sample_size=2215.8, sample_size_v1=0, sample_size_v2=0, ppl=1.78, wps=538, ups=0.24, wpb=2215.8, bsz=64, num_updates=19140, lr=8.40226e-06, gnorm=5.649, clip=100, loss_scale=64, train_wall=41, gb_free=7.1, wall=77378
2023-05-08 21:26:18 - progress_bar.py[line:272] - INFO: epoch 023:    134 / 866 loss=2.033, loss_v1=0, loss_v2=0, nll_loss=0.789, ntokens=2192.9, nsentences=64, sample_size=2192.9, sample_size_v1=0, sample_size_v2=0, ppl=1.73, wps=534, ups=0.24, wpb=2192.9, bsz=64, num_updates=19150, lr=8.38998e-06, gnorm=5.432, clip=100, loss_scale=64, train_wall=41, gb_free=7.8, wall=77419
2023-05-08 21:27:00 - progress_bar.py[line:272] - INFO: epoch 023:    144 / 866 loss=2.022, loss_v1=0, loss_v2=0, nll_loss=0.777, ntokens=2257.1, nsentences=64, sample_size=2257.1, sample_size_v1=0, sample_size_v2=0, ppl=1.71, wps=544.8, ups=0.24, wpb=2257.1, bsz=64, num_updates=19160, lr=8.37769e-06, gnorm=4.927, clip=100, loss_scale=64, train_wall=41, gb_free=6.7, wall=77461
2023-05-08 21:27:41 - progress_bar.py[line:272] - INFO: epoch 023:    154 / 866 loss=2.029, loss_v1=0, loss_v2=0, nll_loss=0.789, ntokens=2212.4, nsentences=64, sample_size=2212.4, sample_size_v1=0, sample_size_v2=0, ppl=1.73, wps=533.6, ups=0.24, wpb=2212.4, bsz=64, num_updates=19170, lr=8.36541e-06, gnorm=5.576, clip=100, loss_scale=64, train_wall=41, gb_free=6.7, wall=77502
2023-05-08 21:28:22 - progress_bar.py[line:272] - INFO: epoch 023:    164 / 866 loss=2.042, loss_v1=0, loss_v2=0, nll_loss=0.801, ntokens=2162.6, nsentences=64, sample_size=2162.6, sample_size_v1=0, sample_size_v2=0, ppl=1.74, wps=525.8, ups=0.24, wpb=2162.6, bsz=64, num_updates=19180, lr=8.35312e-06, gnorm=5.658, clip=100, loss_scale=64, train_wall=41, gb_free=6.4, wall=77543
2023-05-08 21:29:03 - progress_bar.py[line:272] - INFO: epoch 023:    174 / 866 loss=2.053, loss_v1=0, loss_v2=0, nll_loss=0.813, ntokens=2000.4, nsentences=64, sample_size=2000.4, sample_size_v1=0, sample_size_v2=0, ppl=1.76, wps=490.5, ups=0.25, wpb=2000.4, bsz=64, num_updates=19190, lr=8.34084e-06, gnorm=6.359, clip=100, loss_scale=64, train_wall=41, gb_free=7.6, wall=77584
2023-05-08 21:29:44 - progress_bar.py[line:272] - INFO: epoch 023:    184 / 866 loss=2.031, loss_v1=0, loss_v2=0, nll_loss=0.788, ntokens=2214.2, nsentences=64, sample_size=2214.2, sample_size_v1=0, sample_size_v2=0, ppl=1.73, wps=535.8, ups=0.24, wpb=2214.2, bsz=64, num_updates=19200, lr=8.32856e-06, gnorm=5.423, clip=100, loss_scale=64, train_wall=41, gb_free=7.4, wall=77625
2023-05-08 21:30:25 - progress_bar.py[line:272] - INFO: epoch 023:    194 / 866 loss=2.037, loss_v1=0, loss_v2=0, nll_loss=0.795, ntokens=2214.5, nsentences=64, sample_size=2214.5, sample_size_v1=0, sample_size_v2=0, ppl=1.73, wps=538.4, ups=0.24, wpb=2214.5, bsz=64, num_updates=19210, lr=8.31627e-06, gnorm=5.654, clip=100, loss_scale=64, train_wall=41, gb_free=6.6, wall=77667
2023-05-08 21:31:06 - progress_bar.py[line:272] - INFO: epoch 023:    204 / 866 loss=2.059, loss_v1=0, loss_v2=0, nll_loss=0.818, ntokens=2031.5, nsentences=64, sample_size=2031.5, sample_size_v1=0, sample_size_v2=0, ppl=1.76, wps=501.3, ups=0.25, wpb=2031.5, bsz=64, num_updates=19220, lr=8.30399e-06, gnorm=5.517, clip=100, loss_scale=64, train_wall=40, gb_free=7.3, wall=77707
2023-05-08 21:31:46 - progress_bar.py[line:272] - INFO: epoch 023:    214 / 866 loss=2.067, loss_v1=0, loss_v2=0, nll_loss=0.829, ntokens=2119.7, nsentences=64, sample_size=2119.7, sample_size_v1=0, sample_size_v2=0, ppl=1.78, wps=525.2, ups=0.25, wpb=2119.7, bsz=64, num_updates=19230, lr=8.2917e-06, gnorm=5.112, clip=100, loss_scale=64, train_wall=40, gb_free=7.6, wall=77747
2023-05-08 21:32:27 - progress_bar.py[line:272] - INFO: epoch 023:    224 / 866 loss=2.06, loss_v1=0, loss_v2=0, nll_loss=0.822, ntokens=2165.1, nsentences=64, sample_size=2165.1, sample_size_v1=0, sample_size_v2=0, ppl=1.77, wps=538.2, ups=0.25, wpb=2165.1, bsz=64, num_updates=19240, lr=8.27942e-06, gnorm=5.517, clip=100, loss_scale=64, train_wall=40, gb_free=7.6, wall=77788
2023-05-08 21:33:07 - progress_bar.py[line:272] - INFO: epoch 023:    234 / 866 loss=2.078, loss_v1=0, loss_v2=0, nll_loss=0.842, ntokens=2130, nsentences=64, sample_size=2130, sample_size_v1=0, sample_size_v2=0, ppl=1.79, wps=531.5, ups=0.25, wpb=2130, bsz=64, num_updates=19250, lr=8.26714e-06, gnorm=5.381, clip=100, loss_scale=64, train_wall=40, gb_free=7.6, wall=77828
2023-05-08 21:33:47 - progress_bar.py[line:272] - INFO: epoch 023:    244 / 866 loss=2.067, loss_v1=0, loss_v2=0, nll_loss=0.826, ntokens=2215.8, nsentences=64, sample_size=2215.8, sample_size_v1=0, sample_size_v2=0, ppl=1.77, wps=547.5, ups=0.25, wpb=2215.8, bsz=64, num_updates=19260, lr=8.25485e-06, gnorm=5.427, clip=100, loss_scale=64, train_wall=40, gb_free=6.9, wall=77868
2023-05-08 21:34:28 - progress_bar.py[line:272] - INFO: epoch 023:    254 / 866 loss=2.076, loss_v1=0, loss_v2=0, nll_loss=0.839, ntokens=2094.8, nsentences=64, sample_size=2094.8, sample_size_v1=0, sample_size_v2=0, ppl=1.79, wps=517, ups=0.25, wpb=2094.8, bsz=64, num_updates=19270, lr=8.24257e-06, gnorm=5.641, clip=100, loss_scale=64, train_wall=40, gb_free=7.5, wall=77909
2023-05-08 21:35:08 - progress_bar.py[line:272] - INFO: epoch 023:    264 / 866 loss=2.075, loss_v1=0, loss_v2=0, nll_loss=0.838, ntokens=2161.1, nsentences=64, sample_size=2161.1, sample_size_v1=0, sample_size_v2=0, ppl=1.79, wps=536.4, ups=0.25, wpb=2161.1, bsz=64, num_updates=19280, lr=8.23028e-06, gnorm=5.52, clip=100, loss_scale=64, train_wall=40, gb_free=7, wall=77949
2023-05-08 21:35:48 - progress_bar.py[line:272] - INFO: epoch 023:    274 / 866 loss=2.059, loss_v1=0, loss_v2=0, nll_loss=0.82, ntokens=2135.8, nsentences=64, sample_size=2135.8, sample_size_v1=0, sample_size_v2=0, ppl=1.77, wps=526.7, ups=0.25, wpb=2135.8, bsz=64, num_updates=19290, lr=8.218e-06, gnorm=5.741, clip=100, loss_scale=64, train_wall=41, gb_free=5.5, wall=77990
2023-05-08 21:36:29 - progress_bar.py[line:272] - INFO: epoch 023:    284 / 866 loss=2.076, loss_v1=0, loss_v2=0, nll_loss=0.838, ntokens=2152.8, nsentences=64, sample_size=2152.8, sample_size_v1=0, sample_size_v2=0, ppl=1.79, wps=530.3, ups=0.25, wpb=2152.8, bsz=64, num_updates=19300, lr=8.20572e-06, gnorm=5.586, clip=100, loss_scale=64, train_wall=41, gb_free=7.5, wall=78030
2023-05-08 21:37:10 - progress_bar.py[line:272] - INFO: epoch 023:    294 / 866 loss=2.053, loss_v1=0, loss_v2=0, nll_loss=0.812, ntokens=2143.4, nsentences=64, sample_size=2143.4, sample_size_v1=0, sample_size_v2=0, ppl=1.76, wps=529.2, ups=0.25, wpb=2143.4, bsz=64, num_updates=19310, lr=8.19343e-06, gnorm=5.416, clip=100, loss_scale=64, train_wall=40, gb_free=8, wall=78071
2023-05-08 21:37:50 - progress_bar.py[line:272] - INFO: epoch 023:    304 / 866 loss=2.054, loss_v1=0, loss_v2=0, nll_loss=0.815, ntokens=2147.4, nsentences=64, sample_size=2147.4, sample_size_v1=0, sample_size_v2=0, ppl=1.76, wps=527.8, ups=0.25, wpb=2147.4, bsz=64, num_updates=19320, lr=8.18115e-06, gnorm=5.709, clip=100, loss_scale=64, train_wall=41, gb_free=7.7, wall=78111
2023-05-08 21:38:31 - progress_bar.py[line:272] - INFO: epoch 023:    314 / 866 loss=2.062, loss_v1=0, loss_v2=0, nll_loss=0.821, ntokens=2051.3, nsentences=64, sample_size=2051.3, sample_size_v1=0, sample_size_v2=0, ppl=1.77, wps=508.5, ups=0.25, wpb=2051.3, bsz=64, num_updates=19330, lr=8.16886e-06, gnorm=5.654, clip=100, loss_scale=64, train_wall=40, gb_free=8.4, wall=78152
2023-05-08 21:39:11 - progress_bar.py[line:272] - INFO: epoch 023:    324 / 866 loss=2.074, loss_v1=0, loss_v2=0, nll_loss=0.836, ntokens=2017.8, nsentences=64, sample_size=2017.8, sample_size_v1=0, sample_size_v2=0, ppl=1.78, wps=500.6, ups=0.25, wpb=2017.8, bsz=64, num_updates=19340, lr=8.15658e-06, gnorm=5.565, clip=100, loss_scale=64, train_wall=40, gb_free=7.6, wall=78192
2023-05-08 21:39:51 - progress_bar.py[line:272] - INFO: epoch 023:    334 / 866 loss=2.051, loss_v1=0, loss_v2=0, nll_loss=0.811, ntokens=2125.2, nsentences=64, sample_size=2125.2, sample_size_v1=0, sample_size_v2=0, ppl=1.75, wps=530.7, ups=0.25, wpb=2125.2, bsz=64, num_updates=19350, lr=8.1443e-06, gnorm=5.49, clip=100, loss_scale=64, train_wall=40, gb_free=7.9, wall=78232
2023-05-08 21:40:31 - progress_bar.py[line:272] - INFO: epoch 023:    344 / 866 loss=2.044, loss_v1=0, loss_v2=0, nll_loss=0.804, ntokens=1996.4, nsentences=64, sample_size=1996.4, sample_size_v1=0, sample_size_v2=0, ppl=1.75, wps=496.7, ups=0.25, wpb=1996.4, bsz=64, num_updates=19360, lr=8.13201e-06, gnorm=5.79, clip=100, loss_scale=64, train_wall=40, gb_free=7.9, wall=78272
2023-05-08 21:41:12 - progress_bar.py[line:272] - INFO: epoch 023:    354 / 866 loss=2.09, loss_v1=0, loss_v2=0, nll_loss=0.855, ntokens=1992.2, nsentences=64, sample_size=1992.2, sample_size_v1=0, sample_size_v2=0, ppl=1.81, wps=493.1, ups=0.25, wpb=1992.2, bsz=64, num_updates=19370, lr=8.11973e-06, gnorm=5.876, clip=100, loss_scale=64, train_wall=40, gb_free=7.7, wall=78313
2023-05-08 21:41:20 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2023-05-08 21:41:56 - progress_bar.py[line:272] - INFO: epoch 023:    365 / 866 loss=2.069, loss_v1=0, loss_v2=0, nll_loss=0.829, ntokens=1971.4, nsentences=64, sample_size=1971.4, sample_size_v1=0, sample_size_v2=0, ppl=1.78, wps=445.8, ups=0.23, wpb=1971.4, bsz=64, num_updates=19380, lr=8.10744e-06, gnorm=6.031, clip=100, loss_scale=64, train_wall=44, gb_free=7.3, wall=78357
2023-05-08 21:42:36 - progress_bar.py[line:272] - INFO: epoch 023:    375 / 866 loss=2.068, loss_v1=0, loss_v2=0, nll_loss=0.83, ntokens=2082.7, nsentences=64, sample_size=2082.7, sample_size_v1=0, sample_size_v2=0, ppl=1.78, wps=517.7, ups=0.25, wpb=2082.7, bsz=64, num_updates=19390, lr=8.09516e-06, gnorm=5.702, clip=100, loss_scale=64, train_wall=40, gb_free=8.2, wall=78397
2023-05-08 21:43:17 - progress_bar.py[line:272] - INFO: epoch 023:    385 / 866 loss=2.051, loss_v1=0, loss_v2=0, nll_loss=0.812, ntokens=2151.8, nsentences=64, sample_size=2151.8, sample_size_v1=0, sample_size_v2=0, ppl=1.76, wps=531.4, ups=0.25, wpb=2151.8, bsz=64, num_updates=19400, lr=8.08288e-06, gnorm=5.507, clip=100, loss_scale=64, train_wall=40, gb_free=8, wall=78438
2023-05-08 21:43:57 - progress_bar.py[line:272] - INFO: epoch 023:    395 / 866 loss=2.08, loss_v1=0, loss_v2=0, nll_loss=0.844, ntokens=1979, nsentences=64, sample_size=1979, sample_size_v1=0, sample_size_v2=0, ppl=1.8, wps=495.2, ups=0.25, wpb=1979, bsz=64, num_updates=19410, lr=8.07059e-06, gnorm=6.753, clip=100, loss_scale=64, train_wall=40, gb_free=7.9, wall=78478
2023-05-08 21:44:37 - progress_bar.py[line:272] - INFO: epoch 023:    405 / 866 loss=2.052, loss_v1=0, loss_v2=0, nll_loss=0.812, ntokens=2126.6, nsentences=64, sample_size=2126.6, sample_size_v1=0, sample_size_v2=0, ppl=1.76, wps=529.2, ups=0.25, wpb=2126.6, bsz=64, num_updates=19420, lr=8.05831e-06, gnorm=5.469, clip=100, loss_scale=64, train_wall=40, gb_free=8.2, wall=78518
2023-05-08 21:45:17 - progress_bar.py[line:272] - INFO: epoch 023:    415 / 866 loss=2.06, loss_v1=0, loss_v2=0, nll_loss=0.821, ntokens=2132, nsentences=64, sample_size=2132, sample_size_v1=0, sample_size_v2=0, ppl=1.77, wps=529.6, ups=0.25, wpb=2132, bsz=64, num_updates=19430, lr=8.04602e-06, gnorm=5.939, clip=100, loss_scale=64, train_wall=40, gb_free=8.1, wall=78558
2023-05-08 21:45:58 - progress_bar.py[line:272] - INFO: epoch 023:    425 / 866 loss=2.028, loss_v1=0, loss_v2=0, nll_loss=0.785, ntokens=2066.9, nsentences=64, sample_size=2066.9, sample_size_v1=0, sample_size_v2=0, ppl=1.72, wps=509.1, ups=0.25, wpb=2066.9, bsz=64, num_updates=19440, lr=8.03374e-06, gnorm=5.432, clip=100, loss_scale=64, train_wall=41, gb_free=7.6, wall=78599
2023-05-08 21:46:38 - progress_bar.py[line:272] - INFO: epoch 023:    435 / 866 loss=2.06, loss_v1=0, loss_v2=0, nll_loss=0.822, ntokens=2117.6, nsentences=64, sample_size=2117.6, sample_size_v1=0, sample_size_v2=0, ppl=1.77, wps=527.3, ups=0.25, wpb=2117.6, bsz=64, num_updates=19450, lr=8.02146e-06, gnorm=5.664, clip=100, loss_scale=64, train_wall=40, gb_free=8.3, wall=78639
2023-05-08 21:47:18 - progress_bar.py[line:272] - INFO: epoch 023:    445 / 866 loss=2.088, loss_v1=0, loss_v2=0, nll_loss=0.852, ntokens=2033.2, nsentences=64, sample_size=2033.2, sample_size_v1=0, sample_size_v2=0, ppl=1.8, wps=499.1, ups=0.25, wpb=2033.2, bsz=64, num_updates=19460, lr=8.00917e-06, gnorm=6.124, clip=100, loss_scale=64, train_wall=41, gb_free=7.7, wall=78680
2023-05-08 21:47:59 - progress_bar.py[line:272] - INFO: epoch 023:    455 / 866 loss=2.075, loss_v1=0, loss_v2=0, nll_loss=0.837, ntokens=2027.7, nsentences=64, sample_size=2027.7, sample_size_v1=0, sample_size_v2=0, ppl=1.79, wps=503.2, ups=0.25, wpb=2027.7, bsz=64, num_updates=19470, lr=7.99689e-06, gnorm=6.019, clip=100, loss_scale=64, train_wall=40, gb_free=7.9, wall=78720
2023-05-08 21:48:40 - progress_bar.py[line:272] - INFO: epoch 023:    465 / 866 loss=2.079, loss_v1=0, loss_v2=0, nll_loss=0.843, ntokens=2165.9, nsentences=64, sample_size=2165.9, sample_size_v1=0, sample_size_v2=0, ppl=1.79, wps=528.3, ups=0.24, wpb=2165.9, bsz=64, num_updates=19480, lr=7.9846e-06, gnorm=5.525, clip=100, loss_scale=64, train_wall=41, gb_free=7.7, wall=78761
2023-05-08 21:49:20 - progress_bar.py[line:272] - INFO: epoch 023:    475 / 866 loss=2.084, loss_v1=0, loss_v2=0, nll_loss=0.848, ntokens=2209.3, nsentences=64, sample_size=2209.3, sample_size_v1=0, sample_size_v2=0, ppl=1.8, wps=543, ups=0.25, wpb=2209.3, bsz=64, num_updates=19490, lr=7.97232e-06, gnorm=5.976, clip=100, loss_scale=64, train_wall=41, gb_free=7.7, wall=78802
2023-05-08 21:50:01 - progress_bar.py[line:272] - INFO: epoch 023:    485 / 866 loss=2.06, loss_v1=0, loss_v2=0, nll_loss=0.821, ntokens=2141.6, nsentences=64, sample_size=2141.6, sample_size_v1=0, sample_size_v2=0, ppl=1.77, wps=531.4, ups=0.25, wpb=2141.6, bsz=64, num_updates=19500, lr=7.96004e-06, gnorm=5.74, clip=100, loss_scale=64, train_wall=40, gb_free=7.6, wall=78842
2023-05-08 21:50:41 - progress_bar.py[line:272] - INFO: epoch 023:    495 / 866 loss=2.038, loss_v1=0, loss_v2=0, nll_loss=0.795, ntokens=2039.9, nsentences=64, sample_size=2039.9, sample_size_v1=0, sample_size_v2=0, ppl=1.74, wps=507.6, ups=0.25, wpb=2039.9, bsz=64, num_updates=19510, lr=7.94775e-06, gnorm=5.608, clip=100, loss_scale=64, train_wall=40, gb_free=8.4, wall=78882
2023-05-08 21:51:21 - progress_bar.py[line:272] - INFO: epoch 023:    505 / 866 loss=2.074, loss_v1=0, loss_v2=0, nll_loss=0.836, ntokens=2071.4, nsentences=64, sample_size=2071.4, sample_size_v1=0, sample_size_v2=0, ppl=1.78, wps=517.2, ups=0.25, wpb=2071.4, bsz=64, num_updates=19520, lr=7.93547e-06, gnorm=5.908, clip=100, loss_scale=64, train_wall=40, gb_free=7.8, wall=78922
2023-05-08 21:52:01 - progress_bar.py[line:272] - INFO: epoch 023:    515 / 866 loss=2.08, loss_v1=0, loss_v2=0, nll_loss=0.842, ntokens=2210, nsentences=64, sample_size=2210, sample_size_v1=0, sample_size_v2=0, ppl=1.79, wps=546.5, ups=0.25, wpb=2210, bsz=64, num_updates=19530, lr=7.92318e-06, gnorm=5.392, clip=100, loss_scale=64, train_wall=40, gb_free=7.5, wall=78963
2023-05-08 21:52:41 - progress_bar.py[line:272] - INFO: epoch 023:    525 / 866 loss=2.065, loss_v1=0, loss_v2=0, nll_loss=0.826, ntokens=2045, nsentences=64, sample_size=2045, sample_size_v1=0, sample_size_v2=0, ppl=1.77, wps=511.3, ups=0.25, wpb=2045, bsz=64, num_updates=19540, lr=7.9109e-06, gnorm=5.895, clip=100, loss_scale=64, train_wall=40, gb_free=8, wall=79003
2023-05-08 21:53:21 - progress_bar.py[line:272] - INFO: epoch 023:    535 / 866 loss=2.051, loss_v1=0, loss_v2=0, nll_loss=0.81, ntokens=2054.6, nsentences=64, sample_size=2054.6, sample_size_v1=0, sample_size_v2=0, ppl=1.75, wps=513.2, ups=0.25, wpb=2054.6, bsz=64, num_updates=19550, lr=7.89862e-06, gnorm=5.891, clip=100, loss_scale=64, train_wall=40, gb_free=7.6, wall=79043
2023-05-08 21:54:02 - progress_bar.py[line:272] - INFO: epoch 023:    545 / 866 loss=2.071, loss_v1=0, loss_v2=0, nll_loss=0.833, ntokens=2233, nsentences=64, sample_size=2233, sample_size_v1=0, sample_size_v2=0, ppl=1.78, wps=553.6, ups=0.25, wpb=2233, bsz=64, num_updates=19560, lr=7.88633e-06, gnorm=5.515, clip=100, loss_scale=64, train_wall=40, gb_free=7.5, wall=79083
2023-05-08 21:54:42 - progress_bar.py[line:272] - INFO: epoch 023:    555 / 866 loss=2.086, loss_v1=0, loss_v2=0, nll_loss=0.849, ntokens=2288.8, nsentences=64, sample_size=2288.8, sample_size_v1=0, sample_size_v2=0, ppl=1.8, wps=563.4, ups=0.25, wpb=2288.8, bsz=64, num_updates=19570, lr=7.87405e-06, gnorm=5.368, clip=100, loss_scale=64, train_wall=41, gb_free=7.8, wall=79124
2023-05-08 21:55:23 - progress_bar.py[line:272] - INFO: epoch 023:    565 / 866 loss=2.059, loss_v1=0, loss_v2=0, nll_loss=0.82, ntokens=2258.2, nsentences=64, sample_size=2258.2, sample_size_v1=0, sample_size_v2=0, ppl=1.76, wps=560.1, ups=0.25, wpb=2258.2, bsz=64, num_updates=19580, lr=7.86176e-06, gnorm=5.228, clip=100, loss_scale=64, train_wall=40, gb_free=7.7, wall=79164
2023-05-08 21:56:03 - progress_bar.py[line:272] - INFO: epoch 023:    575 / 866 loss=2.057, loss_v1=0, loss_v2=0, nll_loss=0.818, ntokens=2151.4, nsentences=64, sample_size=2151.4, sample_size_v1=0, sample_size_v2=0, ppl=1.76, wps=533, ups=0.25, wpb=2151.4, bsz=64, num_updates=19590, lr=7.84948e-06, gnorm=5.63, clip=100, loss_scale=64, train_wall=40, gb_free=7.9, wall=79204
2023-05-08 21:56:44 - progress_bar.py[line:272] - INFO: epoch 023:    585 / 866 loss=2.082, loss_v1=0, loss_v2=0, nll_loss=0.845, ntokens=2120.4, nsentences=64, sample_size=2120.4, sample_size_v1=0, sample_size_v2=0, ppl=1.8, wps=522.2, ups=0.25, wpb=2120.4, bsz=64, num_updates=19600, lr=7.8372e-06, gnorm=5.828, clip=100, loss_scale=64, train_wall=41, gb_free=7.9, wall=79245
2023-05-08 21:57:24 - progress_bar.py[line:272] - INFO: epoch 023:    595 / 866 loss=2.059, loss_v1=0, loss_v2=0, nll_loss=0.819, ntokens=2112.8, nsentences=64, sample_size=2112.8, sample_size_v1=0, sample_size_v2=0, ppl=1.76, wps=521.2, ups=0.25, wpb=2112.8, bsz=64, num_updates=19610, lr=7.82491e-06, gnorm=5.689, clip=100, loss_scale=64, train_wall=40, gb_free=7.9, wall=79285
2023-05-08 21:58:05 - progress_bar.py[line:272] - INFO: epoch 023:    605 / 866 loss=2.044, loss_v1=0, loss_v2=0, nll_loss=0.803, ntokens=2046.6, nsentences=64, sample_size=2046.6, sample_size_v1=0, sample_size_v2=0, ppl=1.75, wps=506.1, ups=0.25, wpb=2046.6, bsz=64, num_updates=19620, lr=7.81263e-06, gnorm=6.063, clip=100, loss_scale=64, train_wall=40, gb_free=8.4, wall=79326
2023-05-08 21:58:45 - progress_bar.py[line:272] - INFO: epoch 023:    615 / 866 loss=2.082, loss_v1=0, loss_v2=0, nll_loss=0.849, ntokens=1940.8, nsentences=64, sample_size=1940.8, sample_size_v1=0, sample_size_v2=0, ppl=1.8, wps=484.2, ups=0.25, wpb=1940.8, bsz=64, num_updates=19630, lr=7.80034e-06, gnorm=6.214, clip=100, loss_scale=64, train_wall=40, gb_free=7.6, wall=79366
2023-05-08 21:59:25 - progress_bar.py[line:272] - INFO: epoch 023:    625 / 866 loss=2.069, loss_v1=0, loss_v2=0, nll_loss=0.83, ntokens=2027, nsentences=64, sample_size=2027, sample_size_v1=0, sample_size_v2=0, ppl=1.78, wps=504.9, ups=0.25, wpb=2027, bsz=64, num_updates=19640, lr=7.78806e-06, gnorm=6.323, clip=100, loss_scale=64, train_wall=40, gb_free=8.1, wall=79406
2023-05-08 22:00:05 - progress_bar.py[line:272] - INFO: epoch 023:    635 / 866 loss=2.062, loss_v1=0, loss_v2=0, nll_loss=0.822, ntokens=2022.9, nsentences=64, sample_size=2022.9, sample_size_v1=0, sample_size_v2=0, ppl=1.77, wps=505.7, ups=0.25, wpb=2022.9, bsz=64, num_updates=19650, lr=7.77578e-06, gnorm=5.883, clip=100, loss_scale=64, train_wall=40, gb_free=8.1, wall=79446
2023-05-08 22:00:45 - progress_bar.py[line:272] - INFO: epoch 023:    645 / 866 loss=2.061, loss_v1=0, loss_v2=0, nll_loss=0.822, ntokens=2094, nsentences=64, sample_size=2094, sample_size_v1=0, sample_size_v2=0, ppl=1.77, wps=524.8, ups=0.25, wpb=2094, bsz=64, num_updates=19660, lr=7.76349e-06, gnorm=6.155, clip=100, loss_scale=64, train_wall=40, gb_free=8, wall=79486
2023-05-08 22:01:25 - progress_bar.py[line:272] - INFO: epoch 023:    655 / 866 loss=2.074, loss_v1=0, loss_v2=0, nll_loss=0.837, ntokens=1921.7, nsentences=64, sample_size=1921.7, sample_size_v1=0, sample_size_v2=0, ppl=1.79, wps=481.2, ups=0.25, wpb=1921.7, bsz=64, num_updates=19670, lr=7.75121e-06, gnorm=6.023, clip=100, loss_scale=64, train_wall=40, gb_free=7.8, wall=79526
2023-05-08 22:02:05 - progress_bar.py[line:272] - INFO: epoch 023:    665 / 866 loss=2.092, loss_v1=0, loss_v2=0, nll_loss=0.858, ntokens=1956.7, nsentences=64, sample_size=1956.7, sample_size_v1=0, sample_size_v2=0, ppl=1.81, wps=490.1, ups=0.25, wpb=1956.7, bsz=64, num_updates=19680, lr=7.73892e-06, gnorm=6.112, clip=100, loss_scale=64, train_wall=40, gb_free=8.4, wall=79566
2023-05-08 22:02:45 - progress_bar.py[line:272] - INFO: epoch 023:    675 / 866 loss=2.065, loss_v1=0, loss_v2=0, nll_loss=0.825, ntokens=2060, nsentences=64, sample_size=2060, sample_size_v1=0, sample_size_v2=0, ppl=1.77, wps=511.9, ups=0.25, wpb=2060, bsz=64, num_updates=19690, lr=7.72664e-06, gnorm=5.816, clip=100, loss_scale=64, train_wall=40, gb_free=7.2, wall=79606
2023-05-08 22:03:25 - progress_bar.py[line:272] - INFO: epoch 023:    685 / 866 loss=2.064, loss_v1=0, loss_v2=0, nll_loss=0.824, ntokens=2032.5, nsentences=64, sample_size=2032.5, sample_size_v1=0, sample_size_v2=0, ppl=1.77, wps=507.2, ups=0.25, wpb=2032.5, bsz=64, num_updates=19700, lr=7.71436e-06, gnorm=5.9, clip=100, loss_scale=64, train_wall=40, gb_free=7.8, wall=79646
2023-05-08 22:04:05 - progress_bar.py[line:272] - INFO: epoch 023:    695 / 866 loss=2.081, loss_v1=0, loss_v2=0, nll_loss=0.844, ntokens=2093.2, nsentences=64, sample_size=2093.2, sample_size_v1=0, sample_size_v2=0, ppl=1.8, wps=518.7, ups=0.25, wpb=2093.2, bsz=64, num_updates=19710, lr=7.70207e-06, gnorm=5.878, clip=100, loss_scale=64, train_wall=40, gb_free=6.7, wall=79687
2023-05-08 22:04:46 - progress_bar.py[line:272] - INFO: epoch 023:    705 / 866 loss=2.069, loss_v1=0, loss_v2=0, nll_loss=0.832, ntokens=1996.1, nsentences=64, sample_size=1996.1, sample_size_v1=0, sample_size_v2=0, ppl=1.78, wps=497.1, ups=0.25, wpb=1996.1, bsz=64, num_updates=19720, lr=7.68979e-06, gnorm=5.939, clip=100, loss_scale=64, train_wall=40, gb_free=8.1, wall=79727
2023-05-08 22:05:25 - progress_bar.py[line:272] - INFO: epoch 023:    715 / 866 loss=2.077, loss_v1=0, loss_v2=0, nll_loss=0.841, ntokens=1876.5, nsentences=64, sample_size=1876.5, sample_size_v1=0, sample_size_v2=0, ppl=1.79, wps=470.6, ups=0.25, wpb=1876.5, bsz=64, num_updates=19730, lr=7.6775e-06, gnorm=6.432, clip=100, loss_scale=64, train_wall=40, gb_free=8, wall=79767
2023-05-08 22:06:06 - progress_bar.py[line:272] - INFO: epoch 023:    725 / 866 loss=2.042, loss_v1=0, loss_v2=0, nll_loss=0.8, ntokens=2014.8, nsentences=64, sample_size=2014.8, sample_size_v1=0, sample_size_v2=0, ppl=1.74, wps=501.6, ups=0.25, wpb=2014.8, bsz=64, num_updates=19740, lr=7.66522e-06, gnorm=5.846, clip=100, loss_scale=64, train_wall=40, gb_free=7.8, wall=79807
2023-05-08 22:06:46 - progress_bar.py[line:272] - INFO: epoch 023:    735 / 866 loss=2.063, loss_v1=0, loss_v2=0, nll_loss=0.825, ntokens=2046.5, nsentences=64, sample_size=2046.5, sample_size_v1=0, sample_size_v2=0, ppl=1.77, wps=507.8, ups=0.25, wpb=2046.5, bsz=64, num_updates=19750, lr=7.65294e-06, gnorm=5.89, clip=100, loss_scale=64, train_wall=40, gb_free=8, wall=79847
2023-05-08 22:07:26 - progress_bar.py[line:272] - INFO: epoch 023:    745 / 866 loss=2.049, loss_v1=0, loss_v2=0, nll_loss=0.81, ntokens=2137.6, nsentences=64, sample_size=2137.6, sample_size_v1=0, sample_size_v2=0, ppl=1.75, wps=527.6, ups=0.25, wpb=2137.6, bsz=64, num_updates=19760, lr=7.64065e-06, gnorm=5.953, clip=100, loss_scale=64, train_wall=40, gb_free=7.5, wall=79888
2023-05-08 22:08:07 - progress_bar.py[line:272] - INFO: epoch 023:    755 / 866 loss=2.051, loss_v1=0, loss_v2=0, nll_loss=0.81, ntokens=2092.3, nsentences=64, sample_size=2092.3, sample_size_v1=0, sample_size_v2=0, ppl=1.75, wps=519.5, ups=0.25, wpb=2092.3, bsz=64, num_updates=19770, lr=7.62837e-06, gnorm=6.046, clip=100, loss_scale=64, train_wall=40, gb_free=8.1, wall=79928
2023-05-08 22:08:47 - progress_bar.py[line:272] - INFO: epoch 023:    765 / 866 loss=2.053, loss_v1=0, loss_v2=0, nll_loss=0.811, ntokens=2095.6, nsentences=64, sample_size=2095.6, sample_size_v1=0, sample_size_v2=0, ppl=1.75, wps=521.9, ups=0.25, wpb=2095.6, bsz=64, num_updates=19780, lr=7.61608e-06, gnorm=5.643, clip=100, loss_scale=64, train_wall=40, gb_free=6.7, wall=79968
2023-05-08 22:09:27 - progress_bar.py[line:272] - INFO: epoch 023:    775 / 866 loss=2.068, loss_v1=0, loss_v2=0, nll_loss=0.829, ntokens=2161.6, nsentences=64, sample_size=2161.6, sample_size_v1=0, sample_size_v2=0, ppl=1.78, wps=536.8, ups=0.25, wpb=2161.6, bsz=64, num_updates=19790, lr=7.6038e-06, gnorm=5.976, clip=100, loss_scale=64, train_wall=40, gb_free=7.9, wall=80008
2023-05-08 22:10:08 - progress_bar.py[line:272] - INFO: epoch 023:    785 / 866 loss=2.056, loss_v1=0, loss_v2=0, nll_loss=0.817, ntokens=2138.6, nsentences=64, sample_size=2138.6, sample_size_v1=0, sample_size_v2=0, ppl=1.76, wps=530.1, ups=0.25, wpb=2138.6, bsz=64, num_updates=19800, lr=7.59152e-06, gnorm=5.806, clip=100, loss_scale=64, train_wall=40, gb_free=7.5, wall=80049
2023-05-08 22:10:48 - progress_bar.py[line:272] - INFO: epoch 023:    795 / 866 loss=2.082, loss_v1=0, loss_v2=0, nll_loss=0.844, ntokens=2075.8, nsentences=64, sample_size=2075.8, sample_size_v1=0, sample_size_v2=0, ppl=1.8, wps=518.2, ups=0.25, wpb=2075.8, bsz=64, num_updates=19810, lr=7.57923e-06, gnorm=6.229, clip=100, loss_scale=64, train_wall=40, gb_free=7.5, wall=80089
2023-05-08 22:11:27 - progress_bar.py[line:272] - INFO: epoch 023:    805 / 866 loss=2.064, loss_v1=0, loss_v2=0, nll_loss=0.825, ntokens=1921.7, nsentences=64, sample_size=1921.7, sample_size_v1=0, sample_size_v2=0, ppl=1.77, wps=481.9, ups=0.25, wpb=1921.7, bsz=64, num_updates=19820, lr=7.56695e-06, gnorm=6.341, clip=100, loss_scale=64, train_wall=40, gb_free=7.5, wall=80129
2023-05-08 22:12:08 - progress_bar.py[line:272] - INFO: epoch 023:    815 / 866 loss=2.032, loss_v1=0, loss_v2=0, nll_loss=0.789, ntokens=2107.8, nsentences=64, sample_size=2107.8, sample_size_v1=0, sample_size_v2=0, ppl=1.73, wps=524.1, ups=0.25, wpb=2107.8, bsz=64, num_updates=19830, lr=7.55466e-06, gnorm=5.709, clip=100, loss_scale=64, train_wall=40, gb_free=8, wall=80169
2023-05-08 22:12:48 - progress_bar.py[line:272] - INFO: epoch 023:    825 / 866 loss=2.037, loss_v1=0, loss_v2=0, nll_loss=0.795, ntokens=2129.9, nsentences=64, sample_size=2129.9, sample_size_v1=0, sample_size_v2=0, ppl=1.73, wps=527.8, ups=0.25, wpb=2129.9, bsz=64, num_updates=19840, lr=7.54238e-06, gnorm=5.443, clip=100, loss_scale=64, train_wall=40, gb_free=8.3, wall=80209
2023-05-08 22:13:29 - progress_bar.py[line:272] - INFO: epoch 023:    835 / 866 loss=2.037, loss_v1=0, loss_v2=0, nll_loss=0.795, ntokens=2180.9, nsentences=64, sample_size=2180.9, sample_size_v1=0, sample_size_v2=0, ppl=1.73, wps=537.4, ups=0.25, wpb=2180.9, bsz=64, num_updates=19850, lr=7.5301e-06, gnorm=5.455, clip=100, loss_scale=64, train_wall=41, gb_free=8.1, wall=80250
2023-05-08 22:14:09 - progress_bar.py[line:272] - INFO: epoch 023:    845 / 866 loss=2.036, loss_v1=0, loss_v2=0, nll_loss=0.794, ntokens=2162.5, nsentences=64, sample_size=2162.5, sample_size_v1=0, sample_size_v2=0, ppl=1.73, wps=537.6, ups=0.25, wpb=2162.5, bsz=64, num_updates=19860, lr=7.51781e-06, gnorm=5.604, clip=100, loss_scale=64, train_wall=40, gb_free=7.5, wall=80290
2023-05-08 22:14:49 - progress_bar.py[line:272] - INFO: epoch 023:    855 / 866 loss=2.024, loss_v1=0, loss_v2=0, nll_loss=0.781, ntokens=2115.5, nsentences=64, sample_size=2115.5, sample_size_v1=0, sample_size_v2=0, ppl=1.72, wps=524.6, ups=0.25, wpb=2115.5, bsz=64, num_updates=19870, lr=7.50553e-06, gnorm=5.48, clip=100, loss_scale=64, train_wall=40, gb_free=8.3, wall=80330
2023-05-08 22:15:29 - progress_bar.py[line:272] - INFO: epoch 023:    865 / 866 loss=2.069, loss_v1=0, loss_v2=0, nll_loss=0.832, ntokens=2106.8, nsentences=64, sample_size=2106.8, sample_size_v1=0, sample_size_v2=0, ppl=1.78, wps=525.7, ups=0.25, wpb=2106.8, bsz=64, num_updates=19880, lr=7.49324e-06, gnorm=5.817, clip=100, loss_scale=64, train_wall=40, gb_free=7.8, wall=80370
2023-05-08 22:15:32 - train.py[line:332] - INFO: end of epoch 23 (average epoch stats below)
local datafile ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 1 begin to initialize row_count and line_idx-to-offset mapping
2023-05-08 22:15:32 - progress_bar.py[line:282] - INFO: epoch 023 | loss 2.053 | loss_v1 0 | loss_v2 0 | nll_loss 0.813 | ntokens 2103.4 | nsentences 63.972 | sample_size 2103.4 | sample_size_v1 0 | sample_size_v2 0 | ppl 1.76 | wps 519 | ups 0.25 | wpb 2103.4 | bsz 64 | num_updates 19881 | lr 7.49202e-06 | gnorm 5.743 | clip 100 | loss_scale 64 | train_wall 3499 | gb_free 8.7 | wall 80373
2023-05-08 22:15:32 - trainer.py[line:639] - INFO: loading train data for epoch 24
local datafile ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 0 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 0 finished initializing row_count and line_idx-to-offset mapping
file ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 0 row count 27700 total row count 55400
slice_id 0 seek offset 0
2023-05-08 22:15:34 - trainer.py[line:703] - INFO: begin training epoch 24
2023-05-08 22:15:34 - train.py[line:305] - INFO: Start iterating over samples
local datafile ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 1 finished initializing row_count and line_idx-to-offset mapping
file ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 1 row count 27700 total row count 55400
slice_id 1 seek offset 27700
2023-05-08 22:15:50 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2023-05-08 22:16:15 - progress_bar.py[line:272] - INFO: epoch 024:     10 / 866 loss=2.042, loss_v1=0, loss_v2=0, nll_loss=0.801, ntokens=2052.1, nsentences=61.6, sample_size=2052.1, sample_size_v1=0, sample_size_v2=0, ppl=1.74, wps=451.9, ups=0.22, wpb=2052.1, bsz=61.6, num_updates=19890, lr=7.48096e-06, gnorm=6.054, clip=100, loss_scale=64, train_wall=43, gb_free=6.3, wall=80416
2023-05-08 22:16:55 - progress_bar.py[line:272] - INFO: epoch 024:     20 / 866 loss=2.011, loss_v1=0, loss_v2=0, nll_loss=0.764, ntokens=2050.9, nsentences=64, sample_size=2050.9, sample_size_v1=0, sample_size_v2=0, ppl=1.7, wps=504, ups=0.25, wpb=2050.9, bsz=64, num_updates=19900, lr=7.46868e-06, gnorm=6.341, clip=100, loss_scale=64, train_wall=41, gb_free=7.8, wall=80456
2023-05-08 22:17:36 - progress_bar.py[line:272] - INFO: epoch 024:     30 / 866 loss=2.01, loss_v1=0, loss_v2=0, nll_loss=0.763, ntokens=1987.5, nsentences=64, sample_size=1987.5, sample_size_v1=0, sample_size_v2=0, ppl=1.7, wps=489.2, ups=0.25, wpb=1987.5, bsz=64, num_updates=19910, lr=7.45639e-06, gnorm=6.095, clip=100, loss_scale=64, train_wall=41, gb_free=7.4, wall=80497
2023-05-08 22:18:17 - progress_bar.py[line:272] - INFO: epoch 024:     40 / 866 loss=1.963, loss_v1=0, loss_v2=0, nll_loss=0.712, ntokens=2238.7, nsentences=64, sample_size=2238.7, sample_size_v1=0, sample_size_v2=0, ppl=1.64, wps=541.5, ups=0.24, wpb=2238.7, bsz=64, num_updates=19920, lr=7.44411e-06, gnorm=5.514, clip=100, loss_scale=64, train_wall=41, gb_free=7.6, wall=80538
2023-05-08 22:18:58 - progress_bar.py[line:272] - INFO: epoch 024:     50 / 866 loss=1.998, loss_v1=0, loss_v2=0, nll_loss=0.752, ntokens=1995.1, nsentences=64, sample_size=1995.1, sample_size_v1=0, sample_size_v2=0, ppl=1.68, wps=491.5, ups=0.25, wpb=1995.1, bsz=64, num_updates=19930, lr=7.43182e-06, gnorm=5.829, clip=100, loss_scale=64, train_wall=41, gb_free=7.4, wall=80579
2023-05-08 22:19:39 - progress_bar.py[line:272] - INFO: epoch 024:     60 / 866 loss=1.94, loss_v1=0, loss_v2=0, nll_loss=0.687, ntokens=2062.8, nsentences=64, sample_size=2062.8, sample_size_v1=0, sample_size_v2=0, ppl=1.61, wps=508.5, ups=0.25, wpb=2062.8, bsz=64, num_updates=19940, lr=7.41954e-06, gnorm=5.694, clip=100, loss_scale=64, train_wall=41, gb_free=6.4, wall=80620
2023-05-08 22:20:21 - progress_bar.py[line:272] - INFO: epoch 024:     70 / 866 loss=1.943, loss_v1=0, loss_v2=0, nll_loss=0.691, ntokens=2476.7, nsentences=64, sample_size=2476.7, sample_size_v1=0, sample_size_v2=0, ppl=1.61, wps=589, ups=0.24, wpb=2476.7, bsz=64, num_updates=19950, lr=7.40726e-06, gnorm=4.87, clip=100, loss_scale=64, train_wall=42, gb_free=7, wall=80662
2023-05-08 22:21:02 - progress_bar.py[line:272] - INFO: epoch 024:     80 / 866 loss=1.986, loss_v1=0, loss_v2=0, nll_loss=0.738, ntokens=2320.5, nsentences=64, sample_size=2320.5, sample_size_v1=0, sample_size_v2=0, ppl=1.67, wps=557.1, ups=0.24, wpb=2320.5, bsz=64, num_updates=19960, lr=7.39497e-06, gnorm=5.909, clip=100, loss_scale=64, train_wall=42, gb_free=6.8, wall=80703
2023-05-08 22:21:43 - progress_bar.py[line:272] - INFO: epoch 024:     90 / 866 loss=2.017, loss_v1=0, loss_v2=0, nll_loss=0.772, ntokens=2123.9, nsentences=64, sample_size=2123.9, sample_size_v1=0, sample_size_v2=0, ppl=1.71, wps=518.5, ups=0.24, wpb=2123.9, bsz=64, num_updates=19970, lr=7.38269e-06, gnorm=6.12, clip=100, loss_scale=64, train_wall=41, gb_free=7.4, wall=80744
2023-05-08 22:22:24 - progress_bar.py[line:272] - INFO: epoch 024:    100 / 866 loss=2.009, loss_v1=0, loss_v2=0, nll_loss=0.762, ntokens=2077.5, nsentences=64, sample_size=2077.5, sample_size_v1=0, sample_size_v2=0, ppl=1.7, wps=512.5, ups=0.25, wpb=2077.5, bsz=64, num_updates=19980, lr=7.3704e-06, gnorm=5.896, clip=100, loss_scale=64, train_wall=40, gb_free=7.2, wall=80785
2023-05-08 22:23:04 - progress_bar.py[line:272] - INFO: epoch 024:    110 / 866 loss=2.057, loss_v1=0, loss_v2=0, nll_loss=0.817, ntokens=2029.9, nsentences=64, sample_size=2029.9, sample_size_v1=0, sample_size_v2=0, ppl=1.76, wps=502.4, ups=0.25, wpb=2029.9, bsz=64, num_updates=19990, lr=7.35812e-06, gnorm=6.163, clip=100, loss_scale=64, train_wall=40, gb_free=7.2, wall=80825
2023-05-08 22:23:45 - progress_bar.py[line:272] - INFO: epoch 024:    120 / 866 loss=2.054, loss_v1=0, loss_v2=0, nll_loss=0.815, ntokens=2169.2, nsentences=64, sample_size=2169.2, sample_size_v1=0, sample_size_v2=0, ppl=1.76, wps=528.5, ups=0.24, wpb=2169.2, bsz=64, num_updates=20000, lr=7.34584e-06, gnorm=5.614, clip=100, loss_scale=64, train_wall=41, gb_free=7, wall=80866
2023-05-08 22:24:26 - progress_bar.py[line:272] - INFO: epoch 024:    130 / 866 loss=2.045, loss_v1=0, loss_v2=0, nll_loss=0.803, ntokens=2201.3, nsentences=64, sample_size=2201.3, sample_size_v1=0, sample_size_v2=0, ppl=1.74, wps=533.7, ups=0.24, wpb=2201.3, bsz=64, num_updates=20010, lr=7.33355e-06, gnorm=5.847, clip=100, loss_scale=64, train_wall=41, gb_free=6.8, wall=80908
2023-05-08 22:25:08 - progress_bar.py[line:272] - INFO: epoch 024:    140 / 866 loss=2.012, loss_v1=0, loss_v2=0, nll_loss=0.766, ntokens=2246.8, nsentences=64, sample_size=2246.8, sample_size_v1=0, sample_size_v2=0, ppl=1.7, wps=545.9, ups=0.24, wpb=2246.8, bsz=64, num_updates=20020, lr=7.32127e-06, gnorm=5.372, clip=100, loss_scale=64, train_wall=41, gb_free=6.2, wall=80949
2023-05-08 22:25:49 - progress_bar.py[line:272] - INFO: epoch 024:    150 / 866 loss=2.005, loss_v1=0, loss_v2=0, nll_loss=0.759, ntokens=2170, nsentences=64, sample_size=2170, sample_size_v1=0, sample_size_v2=0, ppl=1.69, wps=522.8, ups=0.24, wpb=2170, bsz=64, num_updates=20030, lr=7.30898e-06, gnorm=5.476, clip=100, loss_scale=64, train_wall=41, gb_free=7.3, wall=80990
2023-05-08 22:26:31 - progress_bar.py[line:272] - INFO: epoch 024:    160 / 866 loss=2.039, loss_v1=0, loss_v2=0, nll_loss=0.798, ntokens=2205.1, nsentences=64, sample_size=2205.1, sample_size_v1=0, sample_size_v2=0, ppl=1.74, wps=532.5, ups=0.24, wpb=2205.1, bsz=64, num_updates=20040, lr=7.2967e-06, gnorm=5.627, clip=100, loss_scale=64, train_wall=41, gb_free=7.5, wall=81032
2023-05-08 22:27:11 - progress_bar.py[line:272] - INFO: epoch 024:    170 / 866 loss=2.032, loss_v1=0, loss_v2=0, nll_loss=0.79, ntokens=2090.1, nsentences=64, sample_size=2090.1, sample_size_v1=0, sample_size_v2=0, ppl=1.73, wps=514.1, ups=0.25, wpb=2090.1, bsz=64, num_updates=20050, lr=7.28442e-06, gnorm=6.019, clip=100, loss_scale=64, train_wall=41, gb_free=7.6, wall=81072
2023-05-08 22:27:52 - progress_bar.py[line:272] - INFO: epoch 024:    180 / 866 loss=2.022, loss_v1=0, loss_v2=0, nll_loss=0.778, ntokens=2119.6, nsentences=64, sample_size=2119.6, sample_size_v1=0, sample_size_v2=0, ppl=1.71, wps=514.6, ups=0.24, wpb=2119.6, bsz=64, num_updates=20060, lr=7.27213e-06, gnorm=5.868, clip=100, loss_scale=64, train_wall=41, gb_free=7.2, wall=81113
2023-05-08 22:28:34 - progress_bar.py[line:272] - INFO: epoch 024:    190 / 866 loss=2.022, loss_v1=0, loss_v2=0, nll_loss=0.779, ntokens=2205.1, nsentences=64, sample_size=2205.1, sample_size_v1=0, sample_size_v2=0, ppl=1.72, wps=534.9, ups=0.24, wpb=2205.1, bsz=64, num_updates=20070, lr=7.25985e-06, gnorm=5.948, clip=100, loss_scale=64, train_wall=41, gb_free=6.9, wall=81155
2023-05-08 22:29:15 - progress_bar.py[line:272] - INFO: epoch 024:    200 / 866 loss=2.04, loss_v1=0, loss_v2=0, nll_loss=0.798, ntokens=2135.3, nsentences=64, sample_size=2135.3, sample_size_v1=0, sample_size_v2=0, ppl=1.74, wps=520.8, ups=0.24, wpb=2135.3, bsz=64, num_updates=20080, lr=7.24756e-06, gnorm=6.026, clip=100, loss_scale=64, train_wall=41, gb_free=8, wall=81196
2023-05-08 22:29:55 - progress_bar.py[line:272] - INFO: epoch 024:    210 / 866 loss=2.055, loss_v1=0, loss_v2=0, nll_loss=0.815, ntokens=2011.1, nsentences=64, sample_size=2011.1, sample_size_v1=0, sample_size_v2=0, ppl=1.76, wps=499.2, ups=0.25, wpb=2011.1, bsz=64, num_updates=20090, lr=7.23528e-06, gnorm=5.968, clip=100, loss_scale=64, train_wall=40, gb_free=7.5, wall=81236
2023-05-08 22:30:35 - progress_bar.py[line:272] - INFO: epoch 024:    220 / 866 loss=2.057, loss_v1=0, loss_v2=0, nll_loss=0.818, ntokens=2199.5, nsentences=64, sample_size=2199.5, sample_size_v1=0, sample_size_v2=0, ppl=1.76, wps=546.1, ups=0.25, wpb=2199.5, bsz=64, num_updates=20100, lr=7.223e-06, gnorm=5.343, clip=100, loss_scale=64, train_wall=40, gb_free=7.5, wall=81276
2023-05-08 22:31:16 - progress_bar.py[line:272] - INFO: epoch 024:    230 / 866 loss=2.06, loss_v1=0, loss_v2=0, nll_loss=0.822, ntokens=2148.4, nsentences=64, sample_size=2148.4, sample_size_v1=0, sample_size_v2=0, ppl=1.77, wps=531.6, ups=0.25, wpb=2148.4, bsz=64, num_updates=20110, lr=7.21071e-06, gnorm=5.628, clip=100, loss_scale=64, train_wall=40, gb_free=7.3, wall=81317
2023-05-08 22:31:56 - progress_bar.py[line:272] - INFO: epoch 024:    240 / 866 loss=2.052, loss_v1=0, loss_v2=0, nll_loss=0.811, ntokens=2187.6, nsentences=64, sample_size=2187.6, sample_size_v1=0, sample_size_v2=0, ppl=1.75, wps=545.1, ups=0.25, wpb=2187.6, bsz=64, num_updates=20120, lr=7.19843e-06, gnorm=5.639, clip=100, loss_scale=64, train_wall=40, gb_free=7.1, wall=81357
2023-05-08 22:32:36 - progress_bar.py[line:272] - INFO: epoch 024:    250 / 866 loss=2.057, loss_v1=0, loss_v2=0, nll_loss=0.815, ntokens=2106.9, nsentences=64, sample_size=2106.9, sample_size_v1=0, sample_size_v2=0, ppl=1.76, wps=520.4, ups=0.25, wpb=2106.9, bsz=64, num_updates=20130, lr=7.18614e-06, gnorm=5.877, clip=100, loss_scale=64, train_wall=40, gb_free=7.1, wall=81397
2023-05-08 22:33:16 - progress_bar.py[line:272] - INFO: epoch 024:    260 / 866 loss=2.071, loss_v1=0, loss_v2=0, nll_loss=0.833, ntokens=2131.9, nsentences=64, sample_size=2131.9, sample_size_v1=0, sample_size_v2=0, ppl=1.78, wps=529.9, ups=0.25, wpb=2131.9, bsz=64, num_updates=20140, lr=7.17386e-06, gnorm=5.877, clip=100, loss_scale=64, train_wall=40, gb_free=7.4, wall=81438
2023-05-08 22:33:57 - progress_bar.py[line:272] - INFO: epoch 024:    270 / 866 loss=2.05, loss_v1=0, loss_v2=0, nll_loss=0.81, ntokens=2130.1, nsentences=64, sample_size=2130.1, sample_size_v1=0, sample_size_v2=0, ppl=1.75, wps=530, ups=0.25, wpb=2130.1, bsz=64, num_updates=20150, lr=7.16158e-06, gnorm=5.926, clip=100, loss_scale=64, train_wall=40, gb_free=7.1, wall=81478
2023-05-08 22:34:37 - progress_bar.py[line:272] - INFO: epoch 024:    280 / 866 loss=2.059, loss_v1=0, loss_v2=0, nll_loss=0.82, ntokens=2196.7, nsentences=64, sample_size=2196.7, sample_size_v1=0, sample_size_v2=0, ppl=1.77, wps=540.5, ups=0.25, wpb=2196.7, bsz=64, num_updates=20160, lr=7.14929e-06, gnorm=5.726, clip=100, loss_scale=64, train_wall=41, gb_free=7.2, wall=81518
2023-05-08 22:35:18 - progress_bar.py[line:272] - INFO: epoch 024:    290 / 866 loss=2.046, loss_v1=0, loss_v2=0, nll_loss=0.805, ntokens=2140.2, nsentences=64, sample_size=2140.2, sample_size_v1=0, sample_size_v2=0, ppl=1.75, wps=527.9, ups=0.25, wpb=2140.2, bsz=64, num_updates=20170, lr=7.13701e-06, gnorm=5.933, clip=100, loss_scale=64, train_wall=40, gb_free=8.2, wall=81559
2023-05-08 22:35:58 - progress_bar.py[line:272] - INFO: epoch 024:    300 / 866 loss=2.047, loss_v1=0, loss_v2=0, nll_loss=0.807, ntokens=2142.2, nsentences=64, sample_size=2142.2, sample_size_v1=0, sample_size_v2=0, ppl=1.75, wps=529.8, ups=0.25, wpb=2142.2, bsz=64, num_updates=20180, lr=7.12472e-06, gnorm=5.955, clip=100, loss_scale=64, train_wall=40, gb_free=6.8, wall=81599
2023-05-08 22:36:39 - progress_bar.py[line:272] - INFO: epoch 024:    310 / 866 loss=2.042, loss_v1=0, loss_v2=0, nll_loss=0.801, ntokens=2129.3, nsentences=64, sample_size=2129.3, sample_size_v1=0, sample_size_v2=0, ppl=1.74, wps=527.1, ups=0.25, wpb=2129.3, bsz=64, num_updates=20190, lr=7.11244e-06, gnorm=6.153, clip=100, loss_scale=64, train_wall=40, gb_free=7.1, wall=81640
2023-05-08 22:37:19 - progress_bar.py[line:272] - INFO: epoch 024:    320 / 866 loss=2.056, loss_v1=0, loss_v2=0, nll_loss=0.816, ntokens=1976.4, nsentences=64, sample_size=1976.4, sample_size_v1=0, sample_size_v2=0, ppl=1.76, wps=489.5, ups=0.25, wpb=1976.4, bsz=64, num_updates=20200, lr=7.10016e-06, gnorm=6.344, clip=100, loss_scale=64, train_wall=40, gb_free=7.7, wall=81680
2023-05-08 22:37:59 - progress_bar.py[line:272] - INFO: epoch 024:    330 / 866 loss=2.064, loss_v1=0, loss_v2=0, nll_loss=0.825, ntokens=2097.8, nsentences=64, sample_size=2097.8, sample_size_v1=0, sample_size_v2=0, ppl=1.77, wps=518.9, ups=0.25, wpb=2097.8, bsz=64, num_updates=20210, lr=7.08787e-06, gnorm=5.842, clip=100, loss_scale=64, train_wall=40, gb_free=7.8, wall=81721
2023-05-08 22:38:40 - progress_bar.py[line:272] - INFO: epoch 024:    340 / 866 loss=2.027, loss_v1=0, loss_v2=0, nll_loss=0.784, ntokens=2080.8, nsentences=64, sample_size=2080.8, sample_size_v1=0, sample_size_v2=0, ppl=1.72, wps=512, ups=0.25, wpb=2080.8, bsz=64, num_updates=20220, lr=7.07559e-06, gnorm=5.781, clip=100, loss_scale=64, train_wall=41, gb_free=7.8, wall=81761
2023-05-08 22:39:20 - progress_bar.py[line:272] - INFO: epoch 024:    350 / 866 loss=2.065, loss_v1=0, loss_v2=0, nll_loss=0.826, ntokens=1936.9, nsentences=64, sample_size=1936.9, sample_size_v1=0, sample_size_v2=0, ppl=1.77, wps=484.1, ups=0.25, wpb=1936.9, bsz=64, num_updates=20230, lr=7.0633e-06, gnorm=6.635, clip=100, loss_scale=64, train_wall=40, gb_free=8, wall=81801
2023-05-08 22:40:00 - progress_bar.py[line:272] - INFO: epoch 024:    360 / 866 loss=2.072, loss_v1=0, loss_v2=0, nll_loss=0.835, ntokens=1968.7, nsentences=64, sample_size=1968.7, sample_size_v1=0, sample_size_v2=0, ppl=1.78, wps=490.8, ups=0.25, wpb=1968.7, bsz=64, num_updates=20240, lr=7.05102e-06, gnorm=6.347, clip=100, loss_scale=64, train_wall=40, gb_free=7.9, wall=81841
2023-05-08 22:40:40 - progress_bar.py[line:272] - INFO: epoch 024:    370 / 866 loss=2.065, loss_v1=0, loss_v2=0, nll_loss=0.826, ntokens=1983.4, nsentences=64, sample_size=1983.4, sample_size_v1=0, sample_size_v2=0, ppl=1.77, wps=493.3, ups=0.25, wpb=1983.4, bsz=64, num_updates=20250, lr=7.03874e-06, gnorm=6.36, clip=100, loss_scale=64, train_wall=40, gb_free=8.4, wall=81882
2023-05-08 22:41:21 - progress_bar.py[line:272] - INFO: epoch 024:    380 / 866 loss=2.041, loss_v1=0, loss_v2=0, nll_loss=0.799, ntokens=2204.3, nsentences=64, sample_size=2204.3, sample_size_v1=0, sample_size_v2=0, ppl=1.74, wps=543.2, ups=0.25, wpb=2204.3, bsz=64, num_updates=20260, lr=7.02645e-06, gnorm=5.492, clip=100, loss_scale=64, train_wall=41, gb_free=8, wall=81922
2023-05-08 22:42:01 - progress_bar.py[line:272] - INFO: epoch 024:    390 / 866 loss=2.057, loss_v1=0, loss_v2=0, nll_loss=0.817, ntokens=2074.9, nsentences=64, sample_size=2074.9, sample_size_v1=0, sample_size_v2=0, ppl=1.76, wps=513.8, ups=0.25, wpb=2074.9, bsz=64, num_updates=20270, lr=7.01417e-06, gnorm=6.238, clip=100, loss_scale=64, train_wall=40, gb_free=7.4, wall=81963
2023-05-08 22:42:42 - progress_bar.py[line:272] - INFO: epoch 024:    400 / 866 loss=2.058, loss_v1=0, loss_v2=0, nll_loss=0.818, ntokens=2042.3, nsentences=64, sample_size=2042.3, sample_size_v1=0, sample_size_v2=0, ppl=1.76, wps=502.4, ups=0.25, wpb=2042.3, bsz=64, num_updates=20280, lr=7.00188e-06, gnorm=5.933, clip=100, loss_scale=64, train_wall=41, gb_free=7.6, wall=82003
2023-05-08 22:43:22 - progress_bar.py[line:272] - INFO: epoch 024:    410 / 866 loss=2.043, loss_v1=0, loss_v2=0, nll_loss=0.802, ntokens=2135.2, nsentences=64, sample_size=2135.2, sample_size_v1=0, sample_size_v2=0, ppl=1.74, wps=529.5, ups=0.25, wpb=2135.2, bsz=64, num_updates=20290, lr=6.9896e-06, gnorm=5.739, clip=100, loss_scale=64, train_wall=40, gb_free=7.5, wall=82044
2023-05-08 22:44:03 - progress_bar.py[line:272] - INFO: epoch 024:    420 / 866 loss=2.031, loss_v1=0, loss_v2=0, nll_loss=0.79, ntokens=2077.1, nsentences=64, sample_size=2077.1, sample_size_v1=0, sample_size_v2=0, ppl=1.73, wps=514.8, ups=0.25, wpb=2077.1, bsz=64, num_updates=20300, lr=6.97732e-06, gnorm=6.113, clip=100, loss_scale=64, train_wall=40, gb_free=7, wall=82084
2023-05-08 22:44:43 - progress_bar.py[line:272] - INFO: epoch 024:    430 / 866 loss=2.026, loss_v1=0, loss_v2=0, nll_loss=0.783, ntokens=2138.6, nsentences=64, sample_size=2138.6, sample_size_v1=0, sample_size_v2=0, ppl=1.72, wps=526.4, ups=0.25, wpb=2138.6, bsz=64, num_updates=20310, lr=6.96503e-06, gnorm=5.623, clip=100, loss_scale=64, train_wall=41, gb_free=7.6, wall=82125
2023-05-08 22:45:24 - progress_bar.py[line:272] - INFO: epoch 024:    440 / 866 loss=2.075, loss_v1=0, loss_v2=0, nll_loss=0.838, ntokens=2073.6, nsentences=64, sample_size=2073.6, sample_size_v1=0, sample_size_v2=0, ppl=1.79, wps=507.8, ups=0.24, wpb=2073.6, bsz=64, num_updates=20320, lr=6.95275e-06, gnorm=6.18, clip=100, loss_scale=64, train_wall=41, gb_free=8.1, wall=82165
2023-05-08 22:46:05 - progress_bar.py[line:272] - INFO: epoch 024:    450 / 866 loss=2.071, loss_v1=0, loss_v2=0, nll_loss=0.832, ntokens=1959.4, nsentences=64, sample_size=1959.4, sample_size_v1=0, sample_size_v2=0, ppl=1.78, wps=481.1, ups=0.25, wpb=1959.4, bsz=64, num_updates=20330, lr=6.94046e-06, gnorm=6.18, clip=100, loss_scale=64, train_wall=41, gb_free=8.2, wall=82206
2023-05-08 22:46:46 - progress_bar.py[line:272] - INFO: epoch 024:    460 / 866 loss=2.063, loss_v1=0, loss_v2=0, nll_loss=0.823, ntokens=2156, nsentences=64, sample_size=2156, sample_size_v1=0, sample_size_v2=0, ppl=1.77, wps=529.6, ups=0.25, wpb=2156, bsz=64, num_updates=20340, lr=6.92818e-06, gnorm=5.906, clip=100, loss_scale=64, train_wall=41, gb_free=8, wall=82247
2023-05-08 22:47:26 - progress_bar.py[line:272] - INFO: epoch 024:    470 / 866 loss=2.063, loss_v1=0, loss_v2=0, nll_loss=0.826, ntokens=2146.1, nsentences=64, sample_size=2146.1, sample_size_v1=0, sample_size_v2=0, ppl=1.77, wps=528.9, ups=0.25, wpb=2146.1, bsz=64, num_updates=20350, lr=6.9159e-06, gnorm=6.104, clip=100, loss_scale=64, train_wall=41, gb_free=7.9, wall=82287
2023-05-08 22:48:07 - progress_bar.py[line:272] - INFO: epoch 024:    480 / 866 loss=2.065, loss_v1=0, loss_v2=0, nll_loss=0.827, ntokens=2219.3, nsentences=64, sample_size=2219.3, sample_size_v1=0, sample_size_v2=0, ppl=1.77, wps=548.1, ups=0.25, wpb=2219.3, bsz=64, num_updates=20360, lr=6.90361e-06, gnorm=6.004, clip=100, loss_scale=64, train_wall=40, gb_free=6, wall=82328
2023-05-08 22:48:47 - progress_bar.py[line:272] - INFO: epoch 024:    490 / 866 loss=2.037, loss_v1=0, loss_v2=0, nll_loss=0.794, ntokens=2055.4, nsentences=64, sample_size=2055.4, sample_size_v1=0, sample_size_v2=0, ppl=1.73, wps=509.9, ups=0.25, wpb=2055.4, bsz=64, num_updates=20370, lr=6.89133e-06, gnorm=5.742, clip=100, loss_scale=64, train_wall=40, gb_free=6.7, wall=82368
2023-05-08 22:49:28 - progress_bar.py[line:272] - INFO: epoch 024:    500 / 866 loss=2.041, loss_v1=0, loss_v2=0, nll_loss=0.8, ntokens=2029.7, nsentences=64, sample_size=2029.7, sample_size_v1=0, sample_size_v2=0, ppl=1.74, wps=502, ups=0.25, wpb=2029.7, bsz=64, num_updates=20380, lr=6.87904e-06, gnorm=5.845, clip=100, loss_scale=64, train_wall=40, gb_free=7.8, wall=82409
2023-05-08 22:50:08 - progress_bar.py[line:272] - INFO: epoch 024:    510 / 866 loss=2.075, loss_v1=0, loss_v2=0, nll_loss=0.838, ntokens=2148.4, nsentences=64, sample_size=2148.4, sample_size_v1=0, sample_size_v2=0, ppl=1.79, wps=532, ups=0.25, wpb=2148.4, bsz=64, num_updates=20390, lr=6.86676e-06, gnorm=5.901, clip=100, loss_scale=64, train_wall=40, gb_free=7.2, wall=82449
2023-05-08 22:50:36 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2023-05-08 22:50:52 - progress_bar.py[line:272] - INFO: epoch 024:    521 / 866 loss=2.044, loss_v1=0, loss_v2=0, nll_loss=0.802, ntokens=2185.1, nsentences=64, sample_size=2185.1, sample_size_v1=0, sample_size_v2=0, ppl=1.74, wps=495.4, ups=0.23, wpb=2185.1, bsz=64, num_updates=20400, lr=6.85448e-06, gnorm=5.881, clip=100, loss_scale=64, train_wall=44, gb_free=7.7, wall=82493
2023-05-08 22:51:32 - progress_bar.py[line:272] - INFO: epoch 024:    531 / 866 loss=2.052, loss_v1=0, loss_v2=0, nll_loss=0.812, ntokens=2003.1, nsentences=64, sample_size=2003.1, sample_size_v1=0, sample_size_v2=0, ppl=1.76, wps=500.4, ups=0.25, wpb=2003.1, bsz=64, num_updates=20410, lr=6.84219e-06, gnorm=6.184, clip=100, loss_scale=64, train_wall=40, gb_free=7.9, wall=82533
2023-05-08 22:52:13 - progress_bar.py[line:272] - INFO: epoch 024:    541 / 866 loss=2.047, loss_v1=0, loss_v2=0, nll_loss=0.806, ntokens=2145.8, nsentences=64, sample_size=2145.8, sample_size_v1=0, sample_size_v2=0, ppl=1.75, wps=528.8, ups=0.25, wpb=2145.8, bsz=64, num_updates=20420, lr=6.82991e-06, gnorm=5.465, clip=100, loss_scale=64, train_wall=41, gb_free=8.3, wall=82574
2023-05-08 22:52:53 - progress_bar.py[line:272] - INFO: epoch 024:    551 / 866 loss=2.066, loss_v1=0, loss_v2=0, nll_loss=0.829, ntokens=2299.8, nsentences=64, sample_size=2299.8, sample_size_v1=0, sample_size_v2=0, ppl=1.78, wps=565, ups=0.25, wpb=2299.8, bsz=64, num_updates=20430, lr=6.81762e-06, gnorm=5.65, clip=100, loss_scale=64, train_wall=41, gb_free=7.6, wall=82614
2023-05-08 22:53:34 - progress_bar.py[line:272] - INFO: epoch 024:    561 / 866 loss=2.06, loss_v1=0, loss_v2=0, nll_loss=0.82, ntokens=2246, nsentences=64, sample_size=2246, sample_size_v1=0, sample_size_v2=0, ppl=1.77, wps=553.5, ups=0.25, wpb=2246, bsz=64, num_updates=20440, lr=6.80534e-06, gnorm=5.953, clip=100, loss_scale=64, train_wall=41, gb_free=7.7, wall=82655
2023-05-08 22:54:14 - progress_bar.py[line:272] - INFO: epoch 024:    571 / 866 loss=2.05, loss_v1=0, loss_v2=0, nll_loss=0.809, ntokens=2220.8, nsentences=64, sample_size=2220.8, sample_size_v1=0, sample_size_v2=0, ppl=1.75, wps=547.6, ups=0.25, wpb=2220.8, bsz=64, num_updates=20450, lr=6.79306e-06, gnorm=5.571, clip=100, loss_scale=64, train_wall=41, gb_free=8.3, wall=82696
2023-05-08 22:54:55 - progress_bar.py[line:272] - INFO: epoch 024:    581 / 866 loss=2.058, loss_v1=0, loss_v2=0, nll_loss=0.818, ntokens=2124.7, nsentences=64, sample_size=2124.7, sample_size_v1=0, sample_size_v2=0, ppl=1.76, wps=523.4, ups=0.25, wpb=2124.7, bsz=64, num_updates=20460, lr=6.78077e-06, gnorm=6.204, clip=100, loss_scale=64, train_wall=41, gb_free=6.9, wall=82736
2023-05-08 22:55:36 - progress_bar.py[line:272] - INFO: epoch 024:    591 / 866 loss=2.074, loss_v1=0, loss_v2=0, nll_loss=0.836, ntokens=2033, nsentences=64, sample_size=2033, sample_size_v1=0, sample_size_v2=0, ppl=1.78, wps=500.6, ups=0.25, wpb=2033, bsz=64, num_updates=20470, lr=6.76849e-06, gnorm=6.741, clip=100, loss_scale=64, train_wall=41, gb_free=6.9, wall=82777
2023-05-08 22:56:16 - progress_bar.py[line:272] - INFO: epoch 024:    601 / 866 loss=2.027, loss_v1=0, loss_v2=0, nll_loss=0.783, ntokens=2167.4, nsentences=64, sample_size=2167.4, sample_size_v1=0, sample_size_v2=0, ppl=1.72, wps=535, ups=0.25, wpb=2167.4, bsz=64, num_updates=20480, lr=6.7562e-06, gnorm=5.537, clip=100, loss_scale=64, train_wall=40, gb_free=8, wall=82817
2023-05-08 22:56:56 - progress_bar.py[line:272] - INFO: epoch 024:    611 / 866 loss=2.062, loss_v1=0, loss_v2=0, nll_loss=0.824, ntokens=1954.2, nsentences=64, sample_size=1954.2, sample_size_v1=0, sample_size_v2=0, ppl=1.77, wps=485.4, ups=0.25, wpb=1954.2, bsz=64, num_updates=20490, lr=6.74392e-06, gnorm=6.711, clip=100, loss_scale=64, train_wall=40, gb_free=8.3, wall=82858
2023-05-08 22:57:37 - progress_bar.py[line:272] - INFO: epoch 024:    621 / 866 loss=2.07, loss_v1=0, loss_v2=0, nll_loss=0.833, ntokens=2011.9, nsentences=64, sample_size=2011.9, sample_size_v1=0, sample_size_v2=0, ppl=1.78, wps=499.4, ups=0.25, wpb=2011.9, bsz=64, num_updates=20500, lr=6.73164e-06, gnorm=6.482, clip=100, loss_scale=64, train_wall=40, gb_free=8.1, wall=82898
2023-05-08 22:58:17 - progress_bar.py[line:272] - INFO: epoch 024:    631 / 866 loss=2.049, loss_v1=0, loss_v2=0, nll_loss=0.808, ntokens=2024.1, nsentences=64, sample_size=2024.1, sample_size_v1=0, sample_size_v2=0, ppl=1.75, wps=504.3, ups=0.25, wpb=2024.1, bsz=64, num_updates=20510, lr=6.71935e-06, gnorm=6.142, clip=100, loss_scale=64, train_wall=40, gb_free=7.5, wall=82938
2023-05-08 22:58:57 - progress_bar.py[line:272] - INFO: epoch 024:    641 / 866 loss=2.042, loss_v1=0, loss_v2=0, nll_loss=0.801, ntokens=2038, nsentences=64, sample_size=2038, sample_size_v1=0, sample_size_v2=0, ppl=1.74, wps=508.9, ups=0.25, wpb=2038, bsz=64, num_updates=20520, lr=6.70707e-06, gnorm=6.425, clip=100, loss_scale=64, train_wall=40, gb_free=8.3, wall=82978
2023-05-08 22:59:37 - progress_bar.py[line:272] - INFO: epoch 024:    651 / 866 loss=2.06, loss_v1=0, loss_v2=0, nll_loss=0.82, ntokens=2054.8, nsentences=64, sample_size=2054.8, sample_size_v1=0, sample_size_v2=0, ppl=1.77, wps=515.8, ups=0.25, wpb=2054.8, bsz=64, num_updates=20530, lr=6.69478e-06, gnorm=6.297, clip=100, loss_scale=64, train_wall=40, gb_free=8, wall=83018
2023-05-08 23:00:17 - progress_bar.py[line:272] - INFO: epoch 024:    661 / 866 loss=2.091, loss_v1=0, loss_v2=0, nll_loss=0.856, ntokens=1912, nsentences=64, sample_size=1912, sample_size_v1=0, sample_size_v2=0, ppl=1.81, wps=479.2, ups=0.25, wpb=1912, bsz=64, num_updates=20540, lr=6.6825e-06, gnorm=6.753, clip=100, loss_scale=64, train_wall=40, gb_free=7.8, wall=83058
2023-05-08 23:00:57 - progress_bar.py[line:272] - INFO: epoch 024:    671 / 866 loss=2.058, loss_v1=0, loss_v2=0, nll_loss=0.818, ntokens=2020, nsentences=64, sample_size=2020, sample_size_v1=0, sample_size_v2=0, ppl=1.76, wps=501.6, ups=0.25, wpb=2020, bsz=64, num_updates=20550, lr=6.67022e-06, gnorm=6.347, clip=100, loss_scale=64, train_wall=40, gb_free=7.8, wall=83098
2023-05-08 23:01:37 - progress_bar.py[line:272] - INFO: epoch 024:    681 / 866 loss=2.052, loss_v1=0, loss_v2=0, nll_loss=0.81, ntokens=2053.7, nsentences=64, sample_size=2053.7, sample_size_v1=0, sample_size_v2=0, ppl=1.75, wps=513.4, ups=0.25, wpb=2053.7, bsz=64, num_updates=20560, lr=6.65793e-06, gnorm=6.041, clip=100, loss_scale=64, train_wall=40, gb_free=7.3, wall=83138
2023-05-08 23:02:17 - progress_bar.py[line:272] - INFO: epoch 024:    691 / 866 loss=2.059, loss_v1=0, loss_v2=0, nll_loss=0.819, ntokens=2002, nsentences=64, sample_size=2002, sample_size_v1=0, sample_size_v2=0, ppl=1.76, wps=497.3, ups=0.25, wpb=2002, bsz=64, num_updates=20570, lr=6.64565e-06, gnorm=6.174, clip=100, loss_scale=64, train_wall=40, gb_free=8, wall=83178
2023-05-08 23:02:58 - progress_bar.py[line:272] - INFO: epoch 024:    701 / 866 loss=2.064, loss_v1=0, loss_v2=0, nll_loss=0.825, ntokens=2092.2, nsentences=64, sample_size=2092.2, sample_size_v1=0, sample_size_v2=0, ppl=1.77, wps=518.7, ups=0.25, wpb=2092.2, bsz=64, num_updates=20580, lr=6.63336e-06, gnorm=6.062, clip=100, loss_scale=64, train_wall=40, gb_free=8.1, wall=83219
2023-05-08 23:03:38 - progress_bar.py[line:272] - INFO: epoch 024:    711 / 866 loss=2.068, loss_v1=0, loss_v2=0, nll_loss=0.83, ntokens=1922.9, nsentences=64, sample_size=1922.9, sample_size_v1=0, sample_size_v2=0, ppl=1.78, wps=479, ups=0.25, wpb=1922.9, bsz=64, num_updates=20590, lr=6.62108e-06, gnorm=6.64, clip=100, loss_scale=64, train_wall=40, gb_free=8.1, wall=83259
2023-05-08 23:04:18 - progress_bar.py[line:272] - INFO: epoch 024:    721 / 866 loss=2.036, loss_v1=0, loss_v2=0, nll_loss=0.794, ntokens=1920.7, nsentences=64, sample_size=1920.7, sample_size_v1=0, sample_size_v2=0, ppl=1.73, wps=475.1, ups=0.25, wpb=1920.7, bsz=64, num_updates=20600, lr=6.6088e-06, gnorm=6.136, clip=100, loss_scale=64, train_wall=40, gb_free=7.7, wall=83299
2023-05-08 23:04:59 - progress_bar.py[line:272] - INFO: epoch 024:    731 / 866 loss=2.036, loss_v1=0, loss_v2=0, nll_loss=0.794, ntokens=2019.1, nsentences=64, sample_size=2019.1, sample_size_v1=0, sample_size_v2=0, ppl=1.73, wps=500.3, ups=0.25, wpb=2019.1, bsz=64, num_updates=20610, lr=6.59651e-06, gnorm=6.228, clip=100, loss_scale=64, train_wall=40, gb_free=7.8, wall=83340
2023-05-08 23:05:39 - progress_bar.py[line:272] - INFO: epoch 024:    741 / 866 loss=2.049, loss_v1=0, loss_v2=0, nll_loss=0.811, ntokens=2131.3, nsentences=64, sample_size=2131.3, sample_size_v1=0, sample_size_v2=0, ppl=1.75, wps=524.2, ups=0.25, wpb=2131.3, bsz=64, num_updates=20620, lr=6.58423e-06, gnorm=5.756, clip=100, loss_scale=64, train_wall=41, gb_free=7.8, wall=83380
2023-05-08 23:06:20 - progress_bar.py[line:272] - INFO: epoch 024:    751 / 866 loss=2.035, loss_v1=0, loss_v2=0, nll_loss=0.793, ntokens=2103.9, nsentences=64, sample_size=2103.9, sample_size_v1=0, sample_size_v2=0, ppl=1.73, wps=519.3, ups=0.25, wpb=2103.9, bsz=64, num_updates=20630, lr=6.57194e-06, gnorm=6.193, clip=100, loss_scale=64, train_wall=40, gb_free=7.3, wall=83421
2023-05-08 23:07:00 - progress_bar.py[line:272] - INFO: epoch 024:    761 / 866 loss=2.047, loss_v1=0, loss_v2=0, nll_loss=0.805, ntokens=2112.8, nsentences=64, sample_size=2112.8, sample_size_v1=0, sample_size_v2=0, ppl=1.75, wps=522.7, ups=0.25, wpb=2112.8, bsz=64, num_updates=20640, lr=6.55966e-06, gnorm=6.125, clip=100, loss_scale=64, train_wall=40, gb_free=7.8, wall=83461
2023-05-08 23:07:40 - progress_bar.py[line:272] - INFO: epoch 024:    771 / 866 loss=2.041, loss_v1=0, loss_v2=0, nll_loss=0.799, ntokens=2055, nsentences=64, sample_size=2055, sample_size_v1=0, sample_size_v2=0, ppl=1.74, wps=511.5, ups=0.25, wpb=2055, bsz=64, num_updates=20650, lr=6.54738e-06, gnorm=6.178, clip=100, loss_scale=64, train_wall=40, gb_free=8, wall=83501
2023-05-08 23:08:21 - progress_bar.py[line:272] - INFO: epoch 024:    781 / 866 loss=2.054, loss_v1=0, loss_v2=0, nll_loss=0.813, ntokens=2337.4, nsentences=64, sample_size=2337.4, sample_size_v1=0, sample_size_v2=0, ppl=1.76, wps=575.5, ups=0.25, wpb=2337.4, bsz=64, num_updates=20660, lr=6.53509e-06, gnorm=5.642, clip=100, loss_scale=64, train_wall=41, gb_free=8, wall=83542
2023-05-08 23:09:01 - progress_bar.py[line:272] - INFO: epoch 024:    791 / 866 loss=2.064, loss_v1=0, loss_v2=0, nll_loss=0.825, ntokens=1979.7, nsentences=64, sample_size=1979.7, sample_size_v1=0, sample_size_v2=0, ppl=1.77, wps=496.2, ups=0.25, wpb=1979.7, bsz=64, num_updates=20670, lr=6.52281e-06, gnorm=6.339, clip=100, loss_scale=64, train_wall=40, gb_free=7.7, wall=83582
2023-05-08 23:09:41 - progress_bar.py[line:272] - INFO: epoch 024:    801 / 866 loss=2.054, loss_v1=0, loss_v2=0, nll_loss=0.813, ntokens=2007.4, nsentences=64, sample_size=2007.4, sample_size_v1=0, sample_size_v2=0, ppl=1.76, wps=503.7, ups=0.25, wpb=2007.4, bsz=64, num_updates=20680, lr=6.51052e-06, gnorm=5.937, clip=100, loss_scale=64, train_wall=40, gb_free=7.4, wall=83622
2023-05-08 23:10:21 - progress_bar.py[line:272] - INFO: epoch 024:    811 / 866 loss=2.028, loss_v1=0, loss_v2=0, nll_loss=0.785, ntokens=2059.7, nsentences=64, sample_size=2059.7, sample_size_v1=0, sample_size_v2=0, ppl=1.72, wps=513.5, ups=0.25, wpb=2059.7, bsz=64, num_updates=20690, lr=6.49824e-06, gnorm=6.413, clip=100, loss_scale=64, train_wall=40, gb_free=7.9, wall=83662
2023-05-08 23:11:01 - progress_bar.py[line:272] - INFO: epoch 024:    821 / 866 loss=2.029, loss_v1=0, loss_v2=0, nll_loss=0.786, ntokens=2072.2, nsentences=64, sample_size=2072.2, sample_size_v1=0, sample_size_v2=0, ppl=1.72, wps=517.4, ups=0.25, wpb=2072.2, bsz=64, num_updates=20700, lr=6.48596e-06, gnorm=6.119, clip=100, loss_scale=64, train_wall=40, gb_free=6.3, wall=83702
2023-05-08 23:11:42 - progress_bar.py[line:272] - INFO: epoch 024:    831 / 866 loss=2.016, loss_v1=0, loss_v2=0, nll_loss=0.772, ntokens=2201.4, nsentences=64, sample_size=2201.4, sample_size_v1=0, sample_size_v2=0, ppl=1.71, wps=538.2, ups=0.24, wpb=2201.4, bsz=64, num_updates=20710, lr=6.47367e-06, gnorm=5.483, clip=100, loss_scale=64, train_wall=41, gb_free=7.9, wall=83743
2023-05-08 23:12:22 - progress_bar.py[line:272] - INFO: epoch 024:    841 / 866 loss=2.034, loss_v1=0, loss_v2=0, nll_loss=0.793, ntokens=2111.2, nsentences=64, sample_size=2111.2, sample_size_v1=0, sample_size_v2=0, ppl=1.73, wps=524.4, ups=0.25, wpb=2111.2, bsz=64, num_updates=20720, lr=6.46139e-06, gnorm=5.718, clip=100, loss_scale=64, train_wall=40, gb_free=8.1, wall=83783
2023-05-08 23:13:03 - progress_bar.py[line:272] - INFO: epoch 024:    851 / 866 loss=2.025, loss_v1=0, loss_v2=0, nll_loss=0.782, ntokens=2219.1, nsentences=64, sample_size=2219.1, sample_size_v1=0, sample_size_v2=0, ppl=1.72, wps=546.7, ups=0.25, wpb=2219.1, bsz=64, num_updates=20730, lr=6.4491e-06, gnorm=5.505, clip=100, loss_scale=64, train_wall=41, gb_free=7.7, wall=83824
2023-05-08 23:13:43 - progress_bar.py[line:272] - INFO: epoch 024:    861 / 866 loss=2.032, loss_v1=0, loss_v2=0, nll_loss=0.79, ntokens=2050.8, nsentences=64, sample_size=2050.8, sample_size_v1=0, sample_size_v2=0, ppl=1.73, wps=507.8, ups=0.25, wpb=2050.8, bsz=64, num_updates=20740, lr=6.43682e-06, gnorm=6.234, clip=100, loss_scale=64, train_wall=40, gb_free=7.6, wall=83864
2023-05-08 23:14:02 - train.py[line:332] - INFO: end of epoch 24 (average epoch stats below)
local datafile ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 1 begin to initialize row_count and line_idx-to-offset mapping
2023-05-08 23:14:02 - progress_bar.py[line:282] - INFO: epoch 024 | loss 2.042 | loss_v1 0 | loss_v2 0 | nll_loss 0.801 | ntokens 2103.34 | nsentences 63.972 | sample_size 2103.34 | sample_size_v1 0 | sample_size_v2 0 | ppl 1.74 | wps 517.8 | ups 0.25 | wpb 2103.3 | bsz 64 | num_updates 20745 | lr 6.43068e-06 | gnorm 5.975 | clip 100 | loss_scale 64 | train_wall 3503 | gb_free 8.7 | wall 83883
2023-05-08 23:14:02 - trainer.py[line:639] - INFO: loading train data for epoch 25
local datafile ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 0 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 1 finished initializing row_count and line_idx-to-offset mapping
file ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 1 row count 27700 total row count 55400
local datafile ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 0 finished initializing row_count and line_idx-to-offset mapping
file ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 0 row count 27700 total row count 55400
slice_id 1 seek offset 27700
slice_id 0 seek offset 0
2023-05-08 23:14:03 - trainer.py[line:703] - INFO: begin training epoch 25
2023-05-08 23:14:03 - train.py[line:305] - INFO: Start iterating over samples
2023-05-08 23:14:24 - progress_bar.py[line:272] - INFO: epoch 025:      5 / 866 loss=2.039, loss_v1=0, loss_v2=0, nll_loss=0.797, ntokens=2048.9, nsentences=61.6, sample_size=2048.9, sample_size_v1=0, sample_size_v2=0, ppl=1.74, wps=495, ups=0.24, wpb=2048.9, bsz=61.6, num_updates=20750, lr=6.42454e-06, gnorm=6.254, clip=100, loss_scale=64, train_wall=39, gb_free=7.5, wall=83905
2023-05-08 23:15:05 - progress_bar.py[line:272] - INFO: epoch 025:     15 / 866 loss=2.033, loss_v1=0, loss_v2=0, nll_loss=0.791, ntokens=2078.3, nsentences=64, sample_size=2078.3, sample_size_v1=0, sample_size_v2=0, ppl=1.73, wps=513.2, ups=0.25, wpb=2078.3, bsz=64, num_updates=20760, lr=6.41225e-06, gnorm=6.638, clip=100, loss_scale=64, train_wall=40, gb_free=7.3, wall=83946
2023-05-08 23:15:45 - progress_bar.py[line:272] - INFO: epoch 025:     25 / 866 loss=1.995, loss_v1=0, loss_v2=0, nll_loss=0.747, ntokens=1994.7, nsentences=64, sample_size=1994.7, sample_size_v1=0, sample_size_v2=0, ppl=1.68, wps=494.1, ups=0.25, wpb=1994.7, bsz=64, num_updates=20770, lr=6.39997e-06, gnorm=6.228, clip=100, loss_scale=64, train_wall=40, gb_free=8.3, wall=83986
2023-05-08 23:16:26 - progress_bar.py[line:272] - INFO: epoch 025:     35 / 866 loss=1.967, loss_v1=0, loss_v2=0, nll_loss=0.715, ntokens=2148.6, nsentences=64, sample_size=2148.6, sample_size_v1=0, sample_size_v2=0, ppl=1.64, wps=526.9, ups=0.25, wpb=2148.6, bsz=64, num_updates=20780, lr=6.38768e-06, gnorm=6.058, clip=100, loss_scale=64, train_wall=41, gb_free=7.3, wall=84027
2023-05-08 23:17:07 - progress_bar.py[line:272] - INFO: epoch 025:     45 / 866 loss=1.968, loss_v1=0, loss_v2=0, nll_loss=0.718, ntokens=2074.7, nsentences=64, sample_size=2074.7, sample_size_v1=0, sample_size_v2=0, ppl=1.64, wps=510, ups=0.25, wpb=2074.7, bsz=64, num_updates=20790, lr=6.3754e-06, gnorm=5.948, clip=100, loss_scale=64, train_wall=41, gb_free=6.9, wall=84068
2023-05-08 23:17:47 - progress_bar.py[line:272] - INFO: epoch 025:     55 / 866 loss=1.969, loss_v1=0, loss_v2=0, nll_loss=0.719, ntokens=2045.2, nsentences=64, sample_size=2045.2, sample_size_v1=0, sample_size_v2=0, ppl=1.65, wps=504.7, ups=0.25, wpb=2045.2, bsz=64, num_updates=20800, lr=6.36312e-06, gnorm=5.975, clip=100, loss_scale=64, train_wall=40, gb_free=7.3, wall=84108
2023-05-08 23:18:29 - progress_bar.py[line:272] - INFO: epoch 025:     65 / 866 loss=1.919, loss_v1=0, loss_v2=0, nll_loss=0.663, ntokens=2303.2, nsentences=64, sample_size=2303.2, sample_size_v1=0, sample_size_v2=0, ppl=1.58, wps=556.5, ups=0.24, wpb=2303.2, bsz=64, num_updates=20810, lr=6.35083e-06, gnorm=5.447, clip=100, loss_scale=64, train_wall=41, gb_free=6.7, wall=84150
2023-05-08 23:19:11 - progress_bar.py[line:272] - INFO: epoch 025:     75 / 866 loss=1.956, loss_v1=0, loss_v2=0, nll_loss=0.705, ntokens=2413.7, nsentences=64, sample_size=2413.7, sample_size_v1=0, sample_size_v2=0, ppl=1.63, wps=574.4, ups=0.24, wpb=2413.7, bsz=64, num_updates=20820, lr=6.33855e-06, gnorm=5.126, clip=100, loss_scale=64, train_wall=42, gb_free=6.7, wall=84192
2023-05-08 23:19:52 - progress_bar.py[line:272] - INFO: epoch 025:     85 / 866 loss=2.002, loss_v1=0, loss_v2=0, nll_loss=0.756, ntokens=2169.1, nsentences=64, sample_size=2169.1, sample_size_v1=0, sample_size_v2=0, ppl=1.69, wps=527.3, ups=0.24, wpb=2169.1, bsz=64, num_updates=20830, lr=6.32626e-06, gnorm=6.771, clip=100, loss_scale=64, train_wall=41, gb_free=7.6, wall=84233
2023-05-08 23:20:32 - progress_bar.py[line:272] - INFO: epoch 025:     95 / 866 loss=1.972, loss_v1=0, loss_v2=0, nll_loss=0.722, ntokens=2152.5, nsentences=64, sample_size=2152.5, sample_size_v1=0, sample_size_v2=0, ppl=1.65, wps=529.3, ups=0.25, wpb=2152.5, bsz=64, num_updates=20840, lr=6.31398e-06, gnorm=6.227, clip=100, loss_scale=64, train_wall=41, gb_free=7.9, wall=84274
2023-05-08 23:21:13 - progress_bar.py[line:272] - INFO: epoch 025:    105 / 866 loss=2.037, loss_v1=0, loss_v2=0, nll_loss=0.795, ntokens=2018, nsentences=64, sample_size=2018, sample_size_v1=0, sample_size_v2=0, ppl=1.74, wps=498.5, ups=0.25, wpb=2018, bsz=64, num_updates=20850, lr=6.3017e-06, gnorm=6.29, clip=100, loss_scale=64, train_wall=40, gb_free=7.4, wall=84314
2023-05-08 23:21:54 - progress_bar.py[line:272] - INFO: epoch 025:    115 / 866 loss=2.052, loss_v1=0, loss_v2=0, nll_loss=0.812, ntokens=2044, nsentences=64, sample_size=2044, sample_size_v1=0, sample_size_v2=0, ppl=1.76, wps=500.9, ups=0.25, wpb=2044, bsz=64, num_updates=20860, lr=6.28941e-06, gnorm=6.559, clip=100, loss_scale=64, train_wall=41, gb_free=7.4, wall=84355
2023-05-08 23:22:35 - progress_bar.py[line:272] - INFO: epoch 025:    125 / 866 loss=2.045, loss_v1=0, loss_v2=0, nll_loss=0.804, ntokens=2237.3, nsentences=64, sample_size=2237.3, sample_size_v1=0, sample_size_v2=0, ppl=1.75, wps=540.9, ups=0.24, wpb=2237.3, bsz=64, num_updates=20870, lr=6.27713e-06, gnorm=6.076, clip=100, loss_scale=64, train_wall=41, gb_free=6.6, wall=84396
2023-05-08 23:23:16 - progress_bar.py[line:272] - INFO: epoch 025:    135 / 866 loss=2.017, loss_v1=0, loss_v2=0, nll_loss=0.771, ntokens=2191.3, nsentences=64, sample_size=2191.3, sample_size_v1=0, sample_size_v2=0, ppl=1.71, wps=534.4, ups=0.24, wpb=2191.3, bsz=64, num_updates=20880, lr=6.26484e-06, gnorm=6.148, clip=100, loss_scale=64, train_wall=41, gb_free=7.8, wall=84437
2023-05-08 23:23:58 - progress_bar.py[line:272] - INFO: epoch 025:    145 / 866 loss=1.998, loss_v1=0, loss_v2=0, nll_loss=0.749, ntokens=2255.5, nsentences=64, sample_size=2255.5, sample_size_v1=0, sample_size_v2=0, ppl=1.68, wps=536.3, ups=0.24, wpb=2255.5, bsz=64, num_updates=20890, lr=6.25256e-06, gnorm=6.043, clip=100, loss_scale=64, train_wall=42, gb_free=6.8, wall=84479
2023-05-08 23:24:40 - progress_bar.py[line:272] - INFO: epoch 025:    155 / 866 loss=2.017, loss_v1=0, loss_v2=0, nll_loss=0.774, ntokens=2187.3, nsentences=64, sample_size=2187.3, sample_size_v1=0, sample_size_v2=0, ppl=1.71, wps=524, ups=0.24, wpb=2187.3, bsz=64, num_updates=20900, lr=6.24028e-06, gnorm=6.469, clip=100, loss_scale=64, train_wall=42, gb_free=7, wall=84521
2023-05-08 23:25:17 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2023-05-08 23:25:25 - progress_bar.py[line:272] - INFO: epoch 025:    166 / 866 loss=2.02, loss_v1=0, loss_v2=0, nll_loss=0.776, ntokens=2149.2, nsentences=64, sample_size=2149.2, sample_size_v1=0, sample_size_v2=0, ppl=1.71, wps=479.6, ups=0.22, wpb=2149.2, bsz=64, num_updates=20910, lr=6.22799e-06, gnorm=6.113, clip=100, loss_scale=64, train_wall=45, gb_free=6.6, wall=84566
2023-05-08 23:26:05 - progress_bar.py[line:272] - INFO: epoch 025:    176 / 866 loss=2.034, loss_v1=0, loss_v2=0, nll_loss=0.791, ntokens=2050, nsentences=64, sample_size=2050, sample_size_v1=0, sample_size_v2=0, ppl=1.73, wps=504.5, ups=0.25, wpb=2050, bsz=64, num_updates=20920, lr=6.21571e-06, gnorm=6.505, clip=100, loss_scale=64, train_wall=41, gb_free=7.1, wall=84607
2023-05-08 23:26:47 - progress_bar.py[line:272] - INFO: epoch 025:    186 / 866 loss=2.009, loss_v1=0, loss_v2=0, nll_loss=0.763, ntokens=2187.5, nsentences=64, sample_size=2187.5, sample_size_v1=0, sample_size_v2=0, ppl=1.7, wps=529.1, ups=0.24, wpb=2187.5, bsz=64, num_updates=20930, lr=6.20342e-06, gnorm=6.232, clip=100, loss_scale=64, train_wall=41, gb_free=7.3, wall=84648
2023-05-08 23:27:28 - progress_bar.py[line:272] - INFO: epoch 025:    196 / 866 loss=2.025, loss_v1=0, loss_v2=0, nll_loss=0.781, ntokens=2200.1, nsentences=64, sample_size=2200.1, sample_size_v1=0, sample_size_v2=0, ppl=1.72, wps=532.3, ups=0.24, wpb=2200.1, bsz=64, num_updates=20940, lr=6.19114e-06, gnorm=5.82, clip=100, loss_scale=64, train_wall=41, gb_free=7.4, wall=84689
2023-05-08 23:28:08 - progress_bar.py[line:272] - INFO: epoch 025:    206 / 866 loss=2.027, loss_v1=0, loss_v2=0, nll_loss=0.784, ntokens=1976.2, nsentences=64, sample_size=1976.2, sample_size_v1=0, sample_size_v2=0, ppl=1.72, wps=490, ups=0.25, wpb=1976.2, bsz=64, num_updates=20950, lr=6.17886e-06, gnorm=6.357, clip=100, loss_scale=64, train_wall=40, gb_free=7.7, wall=84730
2023-05-08 23:28:49 - progress_bar.py[line:272] - INFO: epoch 025:    216 / 866 loss=2.054, loss_v1=0, loss_v2=0, nll_loss=0.814, ntokens=2173.5, nsentences=64, sample_size=2173.5, sample_size_v1=0, sample_size_v2=0, ppl=1.76, wps=533.9, ups=0.25, wpb=2173.5, bsz=64, num_updates=20960, lr=6.16657e-06, gnorm=6.028, clip=100, loss_scale=64, train_wall=41, gb_free=8.1, wall=84770
2023-05-08 23:29:30 - progress_bar.py[line:272] - INFO: epoch 025:    226 / 866 loss=2.041, loss_v1=0, loss_v2=0, nll_loss=0.8, ntokens=2179, nsentences=64, sample_size=2179, sample_size_v1=0, sample_size_v2=0, ppl=1.74, wps=537.8, ups=0.25, wpb=2179, bsz=64, num_updates=20970, lr=6.15429e-06, gnorm=5.964, clip=100, loss_scale=64, train_wall=40, gb_free=7.8, wall=84811
2023-05-08 23:30:10 - progress_bar.py[line:272] - INFO: epoch 025:    236 / 866 loss=2.072, loss_v1=0, loss_v2=0, nll_loss=0.836, ntokens=2107.4, nsentences=64, sample_size=2107.4, sample_size_v1=0, sample_size_v2=0, ppl=1.78, wps=522.9, ups=0.25, wpb=2107.4, bsz=64, num_updates=20980, lr=6.142e-06, gnorm=5.917, clip=100, loss_scale=64, train_wall=40, gb_free=7.7, wall=84851
2023-05-08 23:30:51 - progress_bar.py[line:272] - INFO: epoch 025:    246 / 866 loss=2.045, loss_v1=0, loss_v2=0, nll_loss=0.801, ntokens=2213.1, nsentences=64, sample_size=2213.1, sample_size_v1=0, sample_size_v2=0, ppl=1.74, wps=540.2, ups=0.24, wpb=2213.1, bsz=64, num_updates=20990, lr=6.12972e-06, gnorm=6.042, clip=100, loss_scale=64, train_wall=41, gb_free=8, wall=84892
2023-05-08 23:31:31 - progress_bar.py[line:272] - INFO: epoch 025:    256 / 866 loss=2.043, loss_v1=0, loss_v2=0, nll_loss=0.801, ntokens=2108.5, nsentences=64, sample_size=2108.5, sample_size_v1=0, sample_size_v2=0, ppl=1.74, wps=521.9, ups=0.25, wpb=2108.5, bsz=64, num_updates=21000, lr=6.11744e-06, gnorm=5.962, clip=100, loss_scale=64, train_wall=40, gb_free=7.7, wall=84932
2023-05-08 23:32:12 - progress_bar.py[line:272] - INFO: epoch 025:    266 / 866 loss=2.059, loss_v1=0, loss_v2=0, nll_loss=0.818, ntokens=2109.6, nsentences=64, sample_size=2109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.76, wps=518.1, ups=0.25, wpb=2109.6, bsz=64, num_updates=21010, lr=6.10515e-06, gnorm=6.275, clip=100, loss_scale=64, train_wall=41, gb_free=6.8, wall=84973
2023-05-08 23:32:53 - progress_bar.py[line:272] - INFO: epoch 025:    276 / 866 loss=2.044, loss_v1=0, loss_v2=0, nll_loss=0.804, ntokens=2168.3, nsentences=64, sample_size=2168.3, sample_size_v1=0, sample_size_v2=0, ppl=1.75, wps=534.6, ups=0.25, wpb=2168.3, bsz=64, num_updates=21020, lr=6.09287e-06, gnorm=5.75, clip=100, loss_scale=64, train_wall=41, gb_free=7.1, wall=85014
2023-05-08 23:33:33 - progress_bar.py[line:272] - INFO: epoch 025:    286 / 866 loss=2.045, loss_v1=0, loss_v2=0, nll_loss=0.804, ntokens=2179.9, nsentences=64, sample_size=2179.9, sample_size_v1=0, sample_size_v2=0, ppl=1.75, wps=538.6, ups=0.25, wpb=2179.9, bsz=64, num_updates=21030, lr=6.08058e-06, gnorm=6.194, clip=100, loss_scale=64, train_wall=40, gb_free=7.5, wall=85054
2023-05-08 23:34:14 - progress_bar.py[line:272] - INFO: epoch 025:    296 / 866 loss=2.031, loss_v1=0, loss_v2=0, nll_loss=0.788, ntokens=2147.9, nsentences=64, sample_size=2147.9, sample_size_v1=0, sample_size_v2=0, ppl=1.73, wps=530.5, ups=0.25, wpb=2147.9, bsz=64, num_updates=21040, lr=6.0683e-06, gnorm=6.085, clip=100, loss_scale=64, train_wall=40, gb_free=7.2, wall=85095
2023-05-08 23:34:54 - progress_bar.py[line:272] - INFO: epoch 025:    306 / 866 loss=2.036, loss_v1=0, loss_v2=0, nll_loss=0.794, ntokens=2129.4, nsentences=64, sample_size=2129.4, sample_size_v1=0, sample_size_v2=0, ppl=1.73, wps=528, ups=0.25, wpb=2129.4, bsz=64, num_updates=21050, lr=6.05602e-06, gnorm=6.272, clip=100, loss_scale=64, train_wall=40, gb_free=7.2, wall=85135
2023-05-08 23:35:34 - progress_bar.py[line:272] - INFO: epoch 025:    316 / 866 loss=2.04, loss_v1=0, loss_v2=0, nll_loss=0.798, ntokens=2049.6, nsentences=64, sample_size=2049.6, sample_size_v1=0, sample_size_v2=0, ppl=1.74, wps=507.4, ups=0.25, wpb=2049.6, bsz=64, num_updates=21060, lr=6.04373e-06, gnorm=6.411, clip=100, loss_scale=64, train_wall=40, gb_free=7, wall=85175
2023-05-08 23:36:15 - progress_bar.py[line:272] - INFO: epoch 025:    326 / 866 loss=2.059, loss_v1=0, loss_v2=0, nll_loss=0.819, ntokens=2016.2, nsentences=64, sample_size=2016.2, sample_size_v1=0, sample_size_v2=0, ppl=1.76, wps=500, ups=0.25, wpb=2016.2, bsz=64, num_updates=21070, lr=6.03145e-06, gnorm=6.687, clip=100, loss_scale=64, train_wall=40, gb_free=8, wall=85216
2023-05-08 23:36:55 - progress_bar.py[line:272] - INFO: epoch 025:    336 / 866 loss=2.025, loss_v1=0, loss_v2=0, nll_loss=0.782, ntokens=2129.6, nsentences=64, sample_size=2129.6, sample_size_v1=0, sample_size_v2=0, ppl=1.72, wps=525.6, ups=0.25, wpb=2129.6, bsz=64, num_updates=21080, lr=6.01916e-06, gnorm=5.69, clip=100, loss_scale=64, train_wall=40, gb_free=7.7, wall=85256
2023-05-08 23:37:36 - progress_bar.py[line:272] - INFO: epoch 025:    346 / 866 loss=2.037, loss_v1=0, loss_v2=0, nll_loss=0.796, ntokens=1943.9, nsentences=64, sample_size=1943.9, sample_size_v1=0, sample_size_v2=0, ppl=1.74, wps=480.5, ups=0.25, wpb=1943.9, bsz=64, num_updates=21090, lr=6.00688e-06, gnorm=6.066, clip=100, loss_scale=64, train_wall=40, gb_free=7.7, wall=85297
2023-05-08 23:38:16 - progress_bar.py[line:272] - INFO: epoch 025:    356 / 866 loss=2.075, loss_v1=0, loss_v2=0, nll_loss=0.837, ntokens=1991.6, nsentences=64, sample_size=1991.6, sample_size_v1=0, sample_size_v2=0, ppl=1.79, wps=494.2, ups=0.25, wpb=1991.6, bsz=64, num_updates=21100, lr=5.9946e-06, gnorm=6.31, clip=100, loss_scale=64, train_wall=40, gb_free=8.3, wall=85337
2023-05-08 23:38:56 - progress_bar.py[line:272] - INFO: epoch 025:    366 / 866 loss=2.042, loss_v1=0, loss_v2=0, nll_loss=0.801, ntokens=1975.6, nsentences=64, sample_size=1975.6, sample_size_v1=0, sample_size_v2=0, ppl=1.74, wps=492.1, ups=0.25, wpb=1975.6, bsz=64, num_updates=21110, lr=5.98231e-06, gnorm=6.528, clip=100, loss_scale=64, train_wall=40, gb_free=8.1, wall=85377
2023-05-08 23:39:36 - progress_bar.py[line:272] - INFO: epoch 025:    376 / 866 loss=2.047, loss_v1=0, loss_v2=0, nll_loss=0.805, ntokens=2108.1, nsentences=64, sample_size=2108.1, sample_size_v1=0, sample_size_v2=0, ppl=1.75, wps=523.3, ups=0.25, wpb=2108.1, bsz=64, num_updates=21120, lr=5.97003e-06, gnorm=6.637, clip=100, loss_scale=64, train_wall=40, gb_free=7.8, wall=85417
2023-05-08 23:40:17 - progress_bar.py[line:272] - INFO: epoch 025:    386 / 866 loss=2.024, loss_v1=0, loss_v2=0, nll_loss=0.78, ntokens=2138, nsentences=64, sample_size=2138, sample_size_v1=0, sample_size_v2=0, ppl=1.72, wps=530.1, ups=0.25, wpb=2138, bsz=64, num_updates=21130, lr=5.95774e-06, gnorm=5.74, clip=100, loss_scale=64, train_wall=40, gb_free=7.7, wall=85458
2023-05-08 23:40:57 - progress_bar.py[line:272] - INFO: epoch 025:    396 / 866 loss=2.058, loss_v1=0, loss_v2=0, nll_loss=0.819, ntokens=2024.2, nsentences=64, sample_size=2024.2, sample_size_v1=0, sample_size_v2=0, ppl=1.76, wps=507.2, ups=0.25, wpb=2024.2, bsz=64, num_updates=21140, lr=5.94546e-06, gnorm=6.699, clip=100, loss_scale=64, train_wall=40, gb_free=7.2, wall=85498
2023-05-08 23:41:37 - progress_bar.py[line:272] - INFO: epoch 025:    406 / 866 loss=2.039, loss_v1=0, loss_v2=0, nll_loss=0.797, ntokens=2079.1, nsentences=64, sample_size=2079.1, sample_size_v1=0, sample_size_v2=0, ppl=1.74, wps=518, ups=0.25, wpb=2079.1, bsz=64, num_updates=21150, lr=5.93318e-06, gnorm=6.078, clip=100, loss_scale=64, train_wall=40, gb_free=7.5, wall=85538
2023-05-08 23:42:17 - progress_bar.py[line:272] - INFO: epoch 025:    416 / 866 loss=2.035, loss_v1=0, loss_v2=0, nll_loss=0.794, ntokens=2132.3, nsentences=64, sample_size=2132.3, sample_size_v1=0, sample_size_v2=0, ppl=1.73, wps=526.6, ups=0.25, wpb=2132.3, bsz=64, num_updates=21160, lr=5.92089e-06, gnorm=6.047, clip=100, loss_scale=64, train_wall=40, gb_free=7.9, wall=85578
2023-05-08 23:42:58 - progress_bar.py[line:272] - INFO: epoch 025:    426 / 866 loss=2.006, loss_v1=0, loss_v2=0, nll_loss=0.759, ntokens=2080.3, nsentences=64, sample_size=2080.3, sample_size_v1=0, sample_size_v2=0, ppl=1.69, wps=511.4, ups=0.25, wpb=2080.3, bsz=64, num_updates=21170, lr=5.90861e-06, gnorm=5.816, clip=100, loss_scale=64, train_wall=41, gb_free=7.3, wall=85619
2023-05-08 23:43:38 - progress_bar.py[line:272] - INFO: epoch 025:    436 / 866 loss=2.049, loss_v1=0, loss_v2=0, nll_loss=0.808, ntokens=2138.3, nsentences=64, sample_size=2138.3, sample_size_v1=0, sample_size_v2=0, ppl=1.75, wps=531.5, ups=0.25, wpb=2138.3, bsz=64, num_updates=21180, lr=5.89632e-06, gnorm=6.093, clip=100, loss_scale=64, train_wall=40, gb_free=7.3, wall=85659
2023-05-08 23:44:19 - progress_bar.py[line:272] - INFO: epoch 025:    446 / 866 loss=2.064, loss_v1=0, loss_v2=0, nll_loss=0.825, ntokens=2024.4, nsentences=64, sample_size=2024.4, sample_size_v1=0, sample_size_v2=0, ppl=1.77, wps=501.4, ups=0.25, wpb=2024.4, bsz=64, num_updates=21190, lr=5.88404e-06, gnorm=6.811, clip=100, loss_scale=64, train_wall=40, gb_free=7.2, wall=85700
2023-05-08 23:44:59 - progress_bar.py[line:272] - INFO: epoch 025:    456 / 866 loss=2.054, loss_v1=0, loss_v2=0, nll_loss=0.813, ntokens=2040.8, nsentences=64, sample_size=2040.8, sample_size_v1=0, sample_size_v2=0, ppl=1.76, wps=507.5, ups=0.25, wpb=2040.8, bsz=64, num_updates=21200, lr=5.87175e-06, gnorm=6.544, clip=100, loss_scale=64, train_wall=40, gb_free=7.9, wall=85740
2023-05-08 23:45:39 - progress_bar.py[line:272] - INFO: epoch 025:    466 / 866 loss=2.051, loss_v1=0, loss_v2=0, nll_loss=0.81, ntokens=2147.8, nsentences=64, sample_size=2147.8, sample_size_v1=0, sample_size_v2=0, ppl=1.75, wps=534.4, ups=0.25, wpb=2147.8, bsz=64, num_updates=21210, lr=5.85947e-06, gnorm=5.972, clip=100, loss_scale=64, train_wall=40, gb_free=7.8, wall=85780
2023-05-08 23:46:20 - progress_bar.py[line:272] - INFO: epoch 025:    476 / 866 loss=2.064, loss_v1=0, loss_v2=0, nll_loss=0.825, ntokens=2236, nsentences=64, sample_size=2236, sample_size_v1=0, sample_size_v2=0, ppl=1.77, wps=544.9, ups=0.24, wpb=2236, bsz=64, num_updates=21220, lr=5.84719e-06, gnorm=6.406, clip=100, loss_scale=64, train_wall=41, gb_free=7.8, wall=85821
2023-05-08 23:47:01 - progress_bar.py[line:272] - INFO: epoch 025:    486 / 866 loss=2.046, loss_v1=0, loss_v2=0, nll_loss=0.805, ntokens=2102.6, nsentences=64, sample_size=2102.6, sample_size_v1=0, sample_size_v2=0, ppl=1.75, wps=519.4, ups=0.25, wpb=2102.6, bsz=64, num_updates=21230, lr=5.8349e-06, gnorm=6.36, clip=100, loss_scale=64, train_wall=40, gb_free=7.6, wall=85862
2023-05-08 23:47:41 - progress_bar.py[line:272] - INFO: epoch 025:    496 / 866 loss=2.017, loss_v1=0, loss_v2=0, nll_loss=0.771, ntokens=2024.7, nsentences=64, sample_size=2024.7, sample_size_v1=0, sample_size_v2=0, ppl=1.71, wps=503, ups=0.25, wpb=2024.7, bsz=64, num_updates=21240, lr=5.82262e-06, gnorm=6.124, clip=100, loss_scale=64, train_wall=40, gb_free=8.1, wall=85902
2023-05-08 23:48:21 - progress_bar.py[line:272] - INFO: epoch 025:    506 / 866 loss=2.056, loss_v1=0, loss_v2=0, nll_loss=0.816, ntokens=2098.8, nsentences=64, sample_size=2098.8, sample_size_v1=0, sample_size_v2=0, ppl=1.76, wps=519.9, ups=0.25, wpb=2098.8, bsz=64, num_updates=21250, lr=5.81033e-06, gnorm=6.643, clip=100, loss_scale=64, train_wall=40, gb_free=7.5, wall=85942
2023-05-08 23:49:01 - progress_bar.py[line:272] - INFO: epoch 025:    516 / 866 loss=2.063, loss_v1=0, loss_v2=0, nll_loss=0.824, ntokens=2219, nsentences=64, sample_size=2219, sample_size_v1=0, sample_size_v2=0, ppl=1.77, wps=552.8, ups=0.25, wpb=2219, bsz=64, num_updates=21260, lr=5.79805e-06, gnorm=5.969, clip=100, loss_scale=64, train_wall=40, gb_free=7.9, wall=85982
2023-05-08 23:49:41 - progress_bar.py[line:272] - INFO: epoch 025:    526 / 866 loss=2.042, loss_v1=0, loss_v2=0, nll_loss=0.801, ntokens=2002, nsentences=64, sample_size=2002, sample_size_v1=0, sample_size_v2=0, ppl=1.74, wps=504.2, ups=0.25, wpb=2002, bsz=64, num_updates=21270, lr=5.78577e-06, gnorm=6.277, clip=100, loss_scale=64, train_wall=40, gb_free=8.1, wall=86022
2023-05-08 23:50:21 - progress_bar.py[line:272] - INFO: epoch 025:    536 / 866 loss=2.031, loss_v1=0, loss_v2=0, nll_loss=0.788, ntokens=2077.6, nsentences=64, sample_size=2077.6, sample_size_v1=0, sample_size_v2=0, ppl=1.73, wps=518.6, ups=0.25, wpb=2077.6, bsz=64, num_updates=21280, lr=5.77348e-06, gnorm=6.477, clip=100, loss_scale=64, train_wall=40, gb_free=7.9, wall=86062
2023-05-08 23:51:01 - progress_bar.py[line:272] - INFO: epoch 025:    546 / 866 loss=2.055, loss_v1=0, loss_v2=0, nll_loss=0.815, ntokens=2278.3, nsentences=64, sample_size=2278.3, sample_size_v1=0, sample_size_v2=0, ppl=1.76, wps=564.4, ups=0.25, wpb=2278.3, bsz=64, num_updates=21290, lr=5.7612e-06, gnorm=6.093, clip=100, loss_scale=64, train_wall=40, gb_free=7.6, wall=86103
2023-05-08 23:51:42 - progress_bar.py[line:272] - INFO: epoch 025:    556 / 866 loss=2.061, loss_v1=0, loss_v2=0, nll_loss=0.822, ntokens=2260.8, nsentences=64, sample_size=2260.8, sample_size_v1=0, sample_size_v2=0, ppl=1.77, wps=556.6, ups=0.25, wpb=2260.8, bsz=64, num_updates=21300, lr=5.74891e-06, gnorm=5.711, clip=100, loss_scale=64, train_wall=41, gb_free=7.3, wall=86143
2023-05-08 23:52:22 - progress_bar.py[line:272] - INFO: epoch 025:    566 / 866 loss=2.045, loss_v1=0, loss_v2=0, nll_loss=0.804, ntokens=2249.8, nsentences=64, sample_size=2249.8, sample_size_v1=0, sample_size_v2=0, ppl=1.75, wps=557, ups=0.25, wpb=2249.8, bsz=64, num_updates=21310, lr=5.73663e-06, gnorm=6, clip=100, loss_scale=64, train_wall=40, gb_free=6.8, wall=86184
2023-05-08 23:53:03 - progress_bar.py[line:272] - INFO: epoch 025:    576 / 866 loss=2.038, loss_v1=0, loss_v2=0, nll_loss=0.796, ntokens=2151, nsentences=64, sample_size=2151, sample_size_v1=0, sample_size_v2=0, ppl=1.74, wps=530.4, ups=0.25, wpb=2151, bsz=64, num_updates=21320, lr=5.72435e-06, gnorm=6.143, clip=100, loss_scale=64, train_wall=41, gb_free=7.4, wall=86224
2023-05-08 23:53:44 - progress_bar.py[line:272] - INFO: epoch 025:    586 / 866 loss=2.072, loss_v1=0, loss_v2=0, nll_loss=0.833, ntokens=2121, nsentences=64, sample_size=2121, sample_size_v1=0, sample_size_v2=0, ppl=1.78, wps=519.8, ups=0.25, wpb=2121, bsz=64, num_updates=21330, lr=5.71206e-06, gnorm=6.364, clip=100, loss_scale=64, train_wall=41, gb_free=7.6, wall=86265
2023-05-08 23:54:24 - progress_bar.py[line:272] - INFO: epoch 025:    596 / 866 loss=2.028, loss_v1=0, loss_v2=0, nll_loss=0.784, ntokens=2106.7, nsentences=64, sample_size=2106.7, sample_size_v1=0, sample_size_v2=0, ppl=1.72, wps=521.4, ups=0.25, wpb=2106.7, bsz=64, num_updates=21340, lr=5.69978e-06, gnorm=5.698, clip=100, loss_scale=64, train_wall=40, gb_free=7.4, wall=86305
2023-05-08 23:55:04 - progress_bar.py[line:272] - INFO: epoch 025:    606 / 866 loss=2.029, loss_v1=0, loss_v2=0, nll_loss=0.785, ntokens=2021.9, nsentences=64, sample_size=2021.9, sample_size_v1=0, sample_size_v2=0, ppl=1.72, wps=503.6, ups=0.25, wpb=2021.9, bsz=64, num_updates=21350, lr=5.68749e-06, gnorm=6.318, clip=100, loss_scale=64, train_wall=40, gb_free=8.1, wall=86346
2023-05-08 23:55:45 - progress_bar.py[line:272] - INFO: epoch 025:    616 / 866 loss=2.059, loss_v1=0, loss_v2=0, nll_loss=0.823, ntokens=1934.7, nsentences=64, sample_size=1934.7, sample_size_v1=0, sample_size_v2=0, ppl=1.77, wps=481.6, ups=0.25, wpb=1934.7, bsz=64, num_updates=21360, lr=5.67521e-06, gnorm=6.683, clip=100, loss_scale=64, train_wall=40, gb_free=8.6, wall=86386
2023-05-08 23:56:25 - progress_bar.py[line:272] - INFO: epoch 025:    626 / 866 loss=2.052, loss_v1=0, loss_v2=0, nll_loss=0.813, ntokens=2062.4, nsentences=64, sample_size=2062.4, sample_size_v1=0, sample_size_v2=0, ppl=1.76, wps=510.4, ups=0.25, wpb=2062.4, bsz=64, num_updates=21370, lr=5.66293e-06, gnorm=6.614, clip=100, loss_scale=64, train_wall=40, gb_free=8, wall=86426
2023-05-08 23:57:05 - progress_bar.py[line:272] - INFO: epoch 025:    636 / 866 loss=2.031, loss_v1=0, loss_v2=0, nll_loss=0.788, ntokens=2032.4, nsentences=64, sample_size=2032.4, sample_size_v1=0, sample_size_v2=0, ppl=1.73, wps=502.7, ups=0.25, wpb=2032.4, bsz=64, num_updates=21380, lr=5.65064e-06, gnorm=6.44, clip=100, loss_scale=64, train_wall=40, gb_free=7.7, wall=86467
2023-05-08 23:57:45 - progress_bar.py[line:272] - INFO: epoch 025:    646 / 866 loss=2.044, loss_v1=0, loss_v2=0, nll_loss=0.802, ntokens=2066.6, nsentences=64, sample_size=2066.6, sample_size_v1=0, sample_size_v2=0, ppl=1.74, wps=515.8, ups=0.25, wpb=2066.6, bsz=64, num_updates=21390, lr=5.63836e-06, gnorm=6.505, clip=100, loss_scale=64, train_wall=40, gb_free=8.5, wall=86507
2023-05-08 23:58:26 - progress_bar.py[line:272] - INFO: epoch 025:    656 / 866 loss=2.058, loss_v1=0, loss_v2=0, nll_loss=0.819, ntokens=1902.3, nsentences=64, sample_size=1902.3, sample_size_v1=0, sample_size_v2=0, ppl=1.76, wps=474.2, ups=0.25, wpb=1902.3, bsz=64, num_updates=21400, lr=5.62607e-06, gnorm=6.907, clip=100, loss_scale=64, train_wall=40, gb_free=8.3, wall=86547
2023-05-08 23:59:06 - progress_bar.py[line:272] - INFO: epoch 025:    666 / 866 loss=2.064, loss_v1=0, loss_v2=0, nll_loss=0.826, ntokens=1976.5, nsentences=64, sample_size=1976.5, sample_size_v1=0, sample_size_v2=0, ppl=1.77, wps=491.4, ups=0.25, wpb=1976.5, bsz=64, num_updates=21410, lr=5.61379e-06, gnorm=6.85, clip=100, loss_scale=64, train_wall=40, gb_free=7.5, wall=86587
2023-05-08 23:59:46 - progress_bar.py[line:272] - INFO: epoch 025:    676 / 866 loss=2.046, loss_v1=0, loss_v2=0, nll_loss=0.805, ntokens=2075, nsentences=64, sample_size=2075, sample_size_v1=0, sample_size_v2=0, ppl=1.75, wps=514.8, ups=0.25, wpb=2075, bsz=64, num_updates=21420, lr=5.60151e-06, gnorm=6.257, clip=100, loss_scale=128, train_wall=40, gb_free=7.7, wall=86627
2023-05-08 23:59:50 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2023-05-09 00:00:30 - progress_bar.py[line:272] - INFO: epoch 025:    687 / 866 loss=2.039, loss_v1=0, loss_v2=0, nll_loss=0.798, ntokens=1980.4, nsentences=64, sample_size=1980.4, sample_size_v1=0, sample_size_v2=0, ppl=1.74, wps=449.5, ups=0.23, wpb=1980.4, bsz=64, num_updates=21430, lr=5.58922e-06, gnorm=6.732, clip=100, loss_scale=64, train_wall=44, gb_free=8.4, wall=86671
2023-05-09 00:01:11 - progress_bar.py[line:272] - INFO: epoch 025:    697 / 866 loss=2.063, loss_v1=0, loss_v2=0, nll_loss=0.824, ntokens=2133.2, nsentences=64, sample_size=2133.2, sample_size_v1=0, sample_size_v2=0, ppl=1.77, wps=527.6, ups=0.25, wpb=2133.2, bsz=64, num_updates=21440, lr=5.57694e-06, gnorm=6.794, clip=100, loss_scale=64, train_wall=40, gb_free=7.1, wall=86712
2023-05-09 00:01:51 - progress_bar.py[line:272] - INFO: epoch 025:    707 / 866 loss=2.051, loss_v1=0, loss_v2=0, nll_loss=0.81, ntokens=1972.1, nsentences=64, sample_size=1972.1, sample_size_v1=0, sample_size_v2=0, ppl=1.75, wps=488.4, ups=0.25, wpb=1972.1, bsz=64, num_updates=21450, lr=5.56465e-06, gnorm=6.379, clip=100, loss_scale=64, train_wall=40, gb_free=8.2, wall=86752
2023-05-09 00:02:32 - progress_bar.py[line:272] - INFO: epoch 025:    717 / 866 loss=2.043, loss_v1=0, loss_v2=0, nll_loss=0.802, ntokens=1886.4, nsentences=64, sample_size=1886.4, sample_size_v1=0, sample_size_v2=0, ppl=1.74, wps=465.6, ups=0.25, wpb=1886.4, bsz=64, num_updates=21460, lr=5.55237e-06, gnorm=6.336, clip=100, loss_scale=64, train_wall=40, gb_free=8, wall=86793
2023-05-09 00:03:12 - progress_bar.py[line:272] - INFO: epoch 025:    727 / 866 loss=2.028, loss_v1=0, loss_v2=0, nll_loss=0.785, ntokens=1984.1, nsentences=64, sample_size=1984.1, sample_size_v1=0, sample_size_v2=0, ppl=1.72, wps=493.3, ups=0.25, wpb=1984.1, bsz=64, num_updates=21470, lr=5.54009e-06, gnorm=6.144, clip=100, loss_scale=64, train_wall=40, gb_free=8.3, wall=86833
2023-05-09 00:03:52 - progress_bar.py[line:272] - INFO: epoch 025:    737 / 866 loss=2.035, loss_v1=0, loss_v2=0, nll_loss=0.796, ntokens=2105.3, nsentences=64, sample_size=2105.3, sample_size_v1=0, sample_size_v2=0, ppl=1.74, wps=519.4, ups=0.25, wpb=2105.3, bsz=64, num_updates=21480, lr=5.5278e-06, gnorm=6.393, clip=100, loss_scale=64, train_wall=40, gb_free=7.8, wall=86873
2023-05-09 00:04:33 - progress_bar.py[line:272] - INFO: epoch 025:    747 / 866 loss=2.028, loss_v1=0, loss_v2=0, nll_loss=0.785, ntokens=2126.6, nsentences=64, sample_size=2126.6, sample_size_v1=0, sample_size_v2=0, ppl=1.72, wps=520.3, ups=0.24, wpb=2126.6, bsz=64, num_updates=21490, lr=5.51552e-06, gnorm=5.775, clip=100, loss_scale=64, train_wall=41, gb_free=7.5, wall=86914
2023-05-09 00:05:14 - progress_bar.py[line:272] - INFO: epoch 025:    757 / 866 loss=2.039, loss_v1=0, loss_v2=0, nll_loss=0.797, ntokens=2055.9, nsentences=64, sample_size=2055.9, sample_size_v1=0, sample_size_v2=0, ppl=1.74, wps=505.5, ups=0.25, wpb=2055.9, bsz=64, num_updates=21500, lr=5.50323e-06, gnorm=6.365, clip=100, loss_scale=64, train_wall=41, gb_free=7.9, wall=86955
2023-05-09 00:05:54 - progress_bar.py[line:272] - INFO: epoch 025:    767 / 866 loss=2.032, loss_v1=0, loss_v2=0, nll_loss=0.789, ntokens=2104.6, nsentences=64, sample_size=2104.6, sample_size_v1=0, sample_size_v2=0, ppl=1.73, wps=518.5, ups=0.25, wpb=2104.6, bsz=64, num_updates=21510, lr=5.49095e-06, gnorm=6.433, clip=100, loss_scale=64, train_wall=41, gb_free=8.3, wall=86996
2023-05-09 00:06:35 - progress_bar.py[line:272] - INFO: epoch 025:    777 / 866 loss=2.049, loss_v1=0, loss_v2=0, nll_loss=0.807, ntokens=2258.8, nsentences=64, sample_size=2258.8, sample_size_v1=0, sample_size_v2=0, ppl=1.75, wps=558.3, ups=0.25, wpb=2258.8, bsz=64, num_updates=21520, lr=5.47867e-06, gnorm=5.888, clip=100, loss_scale=64, train_wall=40, gb_free=7.9, wall=87036
2023-05-09 00:07:15 - progress_bar.py[line:272] - INFO: epoch 025:    787 / 866 loss=2.049, loss_v1=0, loss_v2=0, nll_loss=0.808, ntokens=2038.1, nsentences=64, sample_size=2038.1, sample_size_v1=0, sample_size_v2=0, ppl=1.75, wps=507.4, ups=0.25, wpb=2038.1, bsz=64, num_updates=21530, lr=5.46638e-06, gnorm=6.748, clip=100, loss_scale=64, train_wall=40, gb_free=7.7, wall=87076
2023-05-09 00:07:55 - progress_bar.py[line:272] - INFO: epoch 025:    797 / 866 loss=2.054, loss_v1=0, loss_v2=0, nll_loss=0.813, ntokens=2084.7, nsentences=64, sample_size=2084.7, sample_size_v1=0, sample_size_v2=0, ppl=1.76, wps=518.9, ups=0.25, wpb=2084.7, bsz=64, num_updates=21540, lr=5.4541e-06, gnorm=6.463, clip=100, loss_scale=64, train_wall=40, gb_free=7.9, wall=87116
2023-05-09 00:08:35 - progress_bar.py[line:272] - INFO: epoch 025:    807 / 866 loss=2.03, loss_v1=0, loss_v2=0, nll_loss=0.786, ntokens=1945.9, nsentences=64, sample_size=1945.9, sample_size_v1=0, sample_size_v2=0, ppl=1.72, wps=487.3, ups=0.25, wpb=1945.9, bsz=64, num_updates=21550, lr=5.44181e-06, gnorm=6.716, clip=100, loss_scale=64, train_wall=40, gb_free=7.8, wall=87156
2023-05-09 00:09:16 - progress_bar.py[line:272] - INFO: epoch 025:    817 / 866 loss=2.02, loss_v1=0, loss_v2=0, nll_loss=0.775, ntokens=2085.3, nsentences=64, sample_size=2085.3, sample_size_v1=0, sample_size_v2=0, ppl=1.71, wps=515.9, ups=0.25, wpb=2085.3, bsz=64, num_updates=21560, lr=5.42953e-06, gnorm=6.345, clip=100, loss_scale=64, train_wall=40, gb_free=8, wall=87197
2023-05-09 00:09:56 - progress_bar.py[line:272] - INFO: epoch 025:    827 / 866 loss=2.012, loss_v1=0, loss_v2=0, nll_loss=0.767, ntokens=2163, nsentences=64, sample_size=2163, sample_size_v1=0, sample_size_v2=0, ppl=1.7, wps=532.5, ups=0.25, wpb=2163, bsz=64, num_updates=21570, lr=5.41725e-06, gnorm=5.856, clip=100, loss_scale=64, train_wall=41, gb_free=8.1, wall=87237
2023-05-09 00:10:37 - progress_bar.py[line:272] - INFO: epoch 025:    837 / 866 loss=2.025, loss_v1=0, loss_v2=0, nll_loss=0.78, ntokens=2161.7, nsentences=64, sample_size=2161.7, sample_size_v1=0, sample_size_v2=0, ppl=1.72, wps=526.7, ups=0.24, wpb=2161.7, bsz=64, num_updates=21580, lr=5.40496e-06, gnorm=6.058, clip=100, loss_scale=64, train_wall=41, gb_free=8.2, wall=87278
2023-05-09 00:11:18 - progress_bar.py[line:272] - INFO: epoch 025:    847 / 866 loss=2.017, loss_v1=0, loss_v2=0, nll_loss=0.773, ntokens=2168.3, nsentences=64, sample_size=2168.3, sample_size_v1=0, sample_size_v2=0, ppl=1.71, wps=536.1, ups=0.25, wpb=2168.3, bsz=64, num_updates=21590, lr=5.39268e-06, gnorm=5.893, clip=100, loss_scale=64, train_wall=40, gb_free=6.9, wall=87319
2023-05-09 00:11:59 - progress_bar.py[line:272] - INFO: epoch 025:    857 / 866 loss=2.004, loss_v1=0, loss_v2=0, nll_loss=0.759, ntokens=2080.9, nsentences=64, sample_size=2080.9, sample_size_v1=0, sample_size_v2=0, ppl=1.69, wps=509.5, ups=0.24, wpb=2080.9, bsz=64, num_updates=21600, lr=5.38039e-06, gnorm=5.82, clip=100, loss_scale=64, train_wall=41, gb_free=7.8, wall=87360
local datafile ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 1 begin to initialize row_count and line_idx-to-offset mapping
2023-05-09 00:12:33 - train.py[line:332] - INFO: end of epoch 25 (average epoch stats below)
2023-05-09 00:12:33 - progress_bar.py[line:282] - INFO: epoch 025 | loss 2.033 | loss_v1 0 | loss_v2 0 | nll_loss 0.791 | ntokens 2102.57 | nsentences 63.972 | sample_size 2102.57 | sample_size_v1 0 | sample_size_v2 0 | ppl 1.73 | wps 517.3 | ups 0.25 | wpb 2102.6 | bsz 64 | num_updates 21609 | lr 5.36934e-06 | gnorm 6.234 | clip 100 | loss_scale 64 | train_wall 3505 | gb_free 8.7 | wall 87395
2023-05-09 00:12:33 - trainer.py[line:639] - INFO: loading train data for epoch 26
local datafile ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 0 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 0 finished initializing row_count and line_idx-to-offset mapping
file ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 0 row count 27700 total row count 55400
slice_id 0 seek offset 0
local datafile ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 1 finished initializing row_count and line_idx-to-offset mapping
file ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 1 row count 27700 total row count 55400
2023-05-09 00:12:35 - trainer.py[line:703] - INFO: begin training epoch 26
2023-05-09 00:12:35 - train.py[line:305] - INFO: Start iterating over samples
slice_id 1 seek offset 27700
2023-05-09 00:12:40 - progress_bar.py[line:272] - INFO: epoch 026:      1 / 866 loss=2.064, loss_v1=0, loss_v2=0, nll_loss=0.827, ntokens=2052.4, nsentences=61.6, sample_size=2052.4, sample_size_v1=0, sample_size_v2=0, ppl=1.77, wps=500.7, ups=0.24, wpb=2052.4, bsz=61.6, num_updates=21610, lr=5.36811e-06, gnorm=6.596, clip=100, loss_scale=64, train_wall=39, gb_free=7.6, wall=87401
2023-05-09 00:13:20 - progress_bar.py[line:272] - INFO: epoch 026:     11 / 866 loss=2.003, loss_v1=0, loss_v2=0, nll_loss=0.757, ntokens=2113.9, nsentences=64, sample_size=2113.9, sample_size_v1=0, sample_size_v2=0, ppl=1.69, wps=518.2, ups=0.25, wpb=2113.9, bsz=64, num_updates=21620, lr=5.35583e-06, gnorm=6.31, clip=100, loss_scale=64, train_wall=41, gb_free=7.8, wall=87441
2023-05-09 00:14:01 - progress_bar.py[line:272] - INFO: epoch 026:     21 / 866 loss=1.99, loss_v1=0, loss_v2=0, nll_loss=0.743, ntokens=2073.7, nsentences=64, sample_size=2073.7, sample_size_v1=0, sample_size_v2=0, ppl=1.67, wps=511.5, ups=0.25, wpb=2073.7, bsz=64, num_updates=21630, lr=5.34354e-06, gnorm=6.464, clip=100, loss_scale=64, train_wall=40, gb_free=7.5, wall=87482
2023-05-09 00:14:42 - progress_bar.py[line:272] - INFO: epoch 026:     31 / 866 loss=1.991, loss_v1=0, loss_v2=0, nll_loss=0.743, ntokens=1996.7, nsentences=64, sample_size=1996.7, sample_size_v1=0, sample_size_v2=0, ppl=1.67, wps=491.8, ups=0.25, wpb=1996.7, bsz=64, num_updates=21640, lr=5.33126e-06, gnorm=6.711, clip=100, loss_scale=64, train_wall=41, gb_free=7.4, wall=87523
2023-05-09 00:15:23 - progress_bar.py[line:272] - INFO: epoch 026:     41 / 866 loss=1.952, loss_v1=0, loss_v2=0, nll_loss=0.698, ntokens=2234.3, nsentences=64, sample_size=2234.3, sample_size_v1=0, sample_size_v2=0, ppl=1.62, wps=540.8, ups=0.24, wpb=2234.3, bsz=64, num_updates=21650, lr=5.31897e-06, gnorm=5.935, clip=100, loss_scale=64, train_wall=41, gb_free=7.2, wall=87564
2023-05-09 00:16:04 - progress_bar.py[line:272] - INFO: epoch 026:     51 / 866 loss=1.986, loss_v1=0, loss_v2=0, nll_loss=0.737, ntokens=1960.1, nsentences=64, sample_size=1960.1, sample_size_v1=0, sample_size_v2=0, ppl=1.67, wps=481.4, ups=0.25, wpb=1960.1, bsz=64, num_updates=21660, lr=5.30669e-06, gnorm=6.912, clip=100, loss_scale=64, train_wall=41, gb_free=7.5, wall=87605
2023-05-09 00:16:45 - progress_bar.py[line:272] - INFO: epoch 026:     61 / 866 loss=1.918, loss_v1=0, loss_v2=0, nll_loss=0.662, ntokens=2153.5, nsentences=64, sample_size=2153.5, sample_size_v1=0, sample_size_v2=0, ppl=1.58, wps=525.7, ups=0.24, wpb=2153.5, bsz=64, num_updates=21670, lr=5.29441e-06, gnorm=5.946, clip=100, loss_scale=64, train_wall=41, gb_free=6.3, wall=87646
2023-05-09 00:17:27 - progress_bar.py[line:272] - INFO: epoch 026:     71 / 866 loss=1.932, loss_v1=0, loss_v2=0, nll_loss=0.678, ntokens=2421, nsentences=64, sample_size=2421, sample_size_v1=0, sample_size_v2=0, ppl=1.6, wps=576.4, ups=0.24, wpb=2421, bsz=64, num_updates=21680, lr=5.28212e-06, gnorm=5.181, clip=100, loss_scale=64, train_wall=42, gb_free=6.2, wall=87688
2023-05-09 00:18:08 - progress_bar.py[line:272] - INFO: epoch 026:     81 / 866 loss=1.976, loss_v1=0, loss_v2=0, nll_loss=0.728, ntokens=2316.3, nsentences=64, sample_size=2316.3, sample_size_v1=0, sample_size_v2=0, ppl=1.66, wps=553.6, ups=0.24, wpb=2316.3, bsz=64, num_updates=21690, lr=5.26984e-06, gnorm=6.162, clip=100, loss_scale=64, train_wall=42, gb_free=7.6, wall=87730
2023-05-09 00:18:12 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2023-05-09 00:18:53 - progress_bar.py[line:272] - INFO: epoch 026:     92 / 866 loss=1.977, loss_v1=0, loss_v2=0, nll_loss=0.729, ntokens=2133.1, nsentences=64, sample_size=2133.1, sample_size_v1=0, sample_size_v2=0, ppl=1.66, wps=474.7, ups=0.22, wpb=2133.1, bsz=64, num_updates=21700, lr=5.25755e-06, gnorm=6.097, clip=100, loss_scale=32, train_wall=45, gb_free=7.4, wall=87774
2023-05-09 00:19:34 - progress_bar.py[line:272] - INFO: epoch 026:    102 / 866 loss=2.009, loss_v1=0, loss_v2=0, nll_loss=0.763, ntokens=2053.1, nsentences=64, sample_size=2053.1, sample_size_v1=0, sample_size_v2=0, ppl=1.7, wps=505.3, ups=0.25, wpb=2053.1, bsz=64, num_updates=21710, lr=5.24527e-06, gnorm=6.654, clip=100, loss_scale=32, train_wall=41, gb_free=7.4, wall=87815
2023-05-09 00:20:14 - progress_bar.py[line:272] - INFO: epoch 026:    112 / 866 loss=2.043, loss_v1=0, loss_v2=0, nll_loss=0.802, ntokens=2059.9, nsentences=64, sample_size=2059.9, sample_size_v1=0, sample_size_v2=0, ppl=1.74, wps=508.4, ups=0.25, wpb=2059.9, bsz=64, num_updates=21720, lr=5.23299e-06, gnorm=6.864, clip=100, loss_scale=32, train_wall=40, gb_free=6.3, wall=87856
2023-05-09 00:20:56 - progress_bar.py[line:272] - INFO: epoch 026:    122 / 866 loss=2.041, loss_v1=0, loss_v2=0, nll_loss=0.799, ntokens=2153.6, nsentences=64, sample_size=2153.6, sample_size_v1=0, sample_size_v2=0, ppl=1.74, wps=523.3, ups=0.24, wpb=2153.6, bsz=64, num_updates=21730, lr=5.2207e-06, gnorm=7.132, clip=100, loss_scale=32, train_wall=41, gb_free=6.9, wall=87897
2023-05-09 00:21:37 - progress_bar.py[line:272] - INFO: epoch 026:    132 / 866 loss=2.024, loss_v1=0, loss_v2=0, nll_loss=0.779, ntokens=2226.4, nsentences=64, sample_size=2226.4, sample_size_v1=0, sample_size_v2=0, ppl=1.72, wps=537.2, ups=0.24, wpb=2226.4, bsz=64, num_updates=21740, lr=5.20842e-06, gnorm=6.528, clip=100, loss_scale=32, train_wall=41, gb_free=6.9, wall=87938
2023-05-09 00:22:18 - progress_bar.py[line:272] - INFO: epoch 026:    142 / 866 loss=1.993, loss_v1=0, loss_v2=0, nll_loss=0.745, ntokens=2247.7, nsentences=64, sample_size=2247.7, sample_size_v1=0, sample_size_v2=0, ppl=1.68, wps=544.5, ups=0.24, wpb=2247.7, bsz=64, num_updates=21750, lr=5.19613e-06, gnorm=5.884, clip=100, loss_scale=32, train_wall=41, gb_free=7, wall=87979
2023-05-09 00:23:00 - progress_bar.py[line:272] - INFO: epoch 026:    152 / 866 loss=1.999, loss_v1=0, loss_v2=0, nll_loss=0.753, ntokens=2190.1, nsentences=64, sample_size=2190.1, sample_size_v1=0, sample_size_v2=0, ppl=1.68, wps=531.2, ups=0.24, wpb=2190.1, bsz=64, num_updates=21760, lr=5.18385e-06, gnorm=6.24, clip=100, loss_scale=32, train_wall=41, gb_free=6.9, wall=88021
2023-05-09 00:23:41 - progress_bar.py[line:272] - INFO: epoch 026:    162 / 866 loss=2.021, loss_v1=0, loss_v2=0, nll_loss=0.776, ntokens=2159.5, nsentences=64, sample_size=2159.5, sample_size_v1=0, sample_size_v2=0, ppl=1.71, wps=526.7, ups=0.24, wpb=2159.5, bsz=64, num_updates=21770, lr=5.17157e-06, gnorm=6.069, clip=100, loss_scale=32, train_wall=41, gb_free=7.2, wall=88062
2023-05-09 00:24:21 - progress_bar.py[line:272] - INFO: epoch 026:    172 / 866 loss=2.033, loss_v1=0, loss_v2=0, nll_loss=0.79, ntokens=2057.6, nsentences=64, sample_size=2057.6, sample_size_v1=0, sample_size_v2=0, ppl=1.73, wps=510.8, ups=0.25, wpb=2057.6, bsz=64, num_updates=21780, lr=5.15928e-06, gnorm=6.841, clip=100, loss_scale=32, train_wall=40, gb_free=7.5, wall=88102
2023-05-09 00:25:02 - progress_bar.py[line:272] - INFO: epoch 026:    182 / 866 loss=1.997, loss_v1=0, loss_v2=0, nll_loss=0.75, ntokens=2189.4, nsentences=64, sample_size=2189.4, sample_size_v1=0, sample_size_v2=0, ppl=1.68, wps=532.5, ups=0.24, wpb=2189.4, bsz=64, num_updates=21790, lr=5.147e-06, gnorm=6.015, clip=100, loss_scale=32, train_wall=41, gb_free=7.3, wall=88143
2023-05-09 00:25:43 - progress_bar.py[line:272] - INFO: epoch 026:    192 / 866 loss=2.011, loss_v1=0, loss_v2=0, nll_loss=0.766, ntokens=2214.7, nsentences=64, sample_size=2214.7, sample_size_v1=0, sample_size_v2=0, ppl=1.7, wps=541.5, ups=0.24, wpb=2214.7, bsz=64, num_updates=21800, lr=5.13471e-06, gnorm=6.281, clip=100, loss_scale=32, train_wall=41, gb_free=6.8, wall=88184
2023-05-09 00:26:24 - progress_bar.py[line:272] - INFO: epoch 026:    202 / 866 loss=2.029, loss_v1=0, loss_v2=0, nll_loss=0.785, ntokens=2086.6, nsentences=64, sample_size=2086.6, sample_size_v1=0, sample_size_v2=0, ppl=1.72, wps=512.2, ups=0.25, wpb=2086.6, bsz=64, num_updates=21810, lr=5.12243e-06, gnorm=6.517, clip=100, loss_scale=32, train_wall=41, gb_free=6.9, wall=88225
2023-05-09 00:27:04 - progress_bar.py[line:272] - INFO: epoch 026:    212 / 866 loss=2.036, loss_v1=0, loss_v2=0, nll_loss=0.793, ntokens=2014.6, nsentences=64, sample_size=2014.6, sample_size_v1=0, sample_size_v2=0, ppl=1.73, wps=500.9, ups=0.25, wpb=2014.6, bsz=64, num_updates=21820, lr=5.11015e-06, gnorm=6.371, clip=100, loss_scale=32, train_wall=40, gb_free=7.3, wall=88265
2023-05-09 00:27:44 - progress_bar.py[line:272] - INFO: epoch 026:    222 / 866 loss=2.033, loss_v1=0, loss_v2=0, nll_loss=0.79, ntokens=2222.5, nsentences=64, sample_size=2222.5, sample_size_v1=0, sample_size_v2=0, ppl=1.73, wps=551.5, ups=0.25, wpb=2222.5, bsz=64, num_updates=21830, lr=5.09786e-06, gnorm=5.831, clip=100, loss_scale=32, train_wall=40, gb_free=7.1, wall=88305
2023-05-09 00:28:24 - progress_bar.py[line:272] - INFO: epoch 026:    232 / 866 loss=2.043, loss_v1=0, loss_v2=0, nll_loss=0.803, ntokens=2130.9, nsentences=64, sample_size=2130.9, sample_size_v1=0, sample_size_v2=0, ppl=1.75, wps=531.4, ups=0.25, wpb=2130.9, bsz=64, num_updates=21840, lr=5.08558e-06, gnorm=5.92, clip=100, loss_scale=32, train_wall=40, gb_free=7.6, wall=88345
2023-05-09 00:29:05 - progress_bar.py[line:272] - INFO: epoch 026:    242 / 866 loss=2.033, loss_v1=0, loss_v2=0, nll_loss=0.789, ntokens=2192.7, nsentences=64, sample_size=2192.7, sample_size_v1=0, sample_size_v2=0, ppl=1.73, wps=543.4, ups=0.25, wpb=2192.7, bsz=64, num_updates=21850, lr=5.07329e-06, gnorm=5.515, clip=100, loss_scale=32, train_wall=40, gb_free=7.1, wall=88386
2023-05-09 00:29:45 - progress_bar.py[line:272] - INFO: epoch 026:    252 / 866 loss=2.055, loss_v1=0, loss_v2=0, nll_loss=0.814, ntokens=2103.6, nsentences=64, sample_size=2103.6, sample_size_v1=0, sample_size_v2=0, ppl=1.76, wps=520.6, ups=0.25, wpb=2103.6, bsz=64, num_updates=21860, lr=5.06101e-06, gnorm=6.44, clip=100, loss_scale=32, train_wall=40, gb_free=7.5, wall=88426
2023-05-09 00:30:25 - progress_bar.py[line:272] - INFO: epoch 026:    262 / 866 loss=2.051, loss_v1=0, loss_v2=0, nll_loss=0.81, ntokens=2158.9, nsentences=64, sample_size=2158.9, sample_size_v1=0, sample_size_v2=0, ppl=1.75, wps=537.3, ups=0.25, wpb=2158.9, bsz=64, num_updates=21870, lr=5.04873e-06, gnorm=6.137, clip=100, loss_scale=32, train_wall=40, gb_free=7.7, wall=88466
2023-05-09 00:31:06 - progress_bar.py[line:272] - INFO: epoch 026:    272 / 866 loss=2.026, loss_v1=0, loss_v2=0, nll_loss=0.782, ntokens=2133.5, nsentences=64, sample_size=2133.5, sample_size_v1=0, sample_size_v2=0, ppl=1.72, wps=528.4, ups=0.25, wpb=2133.5, bsz=64, num_updates=21880, lr=5.03644e-06, gnorm=6.142, clip=100, loss_scale=32, train_wall=40, gb_free=8, wall=88507
2023-05-09 00:31:46 - progress_bar.py[line:272] - INFO: epoch 026:    282 / 866 loss=2.045, loss_v1=0, loss_v2=0, nll_loss=0.804, ntokens=2167.2, nsentences=64, sample_size=2167.2, sample_size_v1=0, sample_size_v2=0, ppl=1.75, wps=533.9, ups=0.25, wpb=2167.2, bsz=64, num_updates=21890, lr=5.02416e-06, gnorm=6.069, clip=100, loss_scale=32, train_wall=41, gb_free=6.9, wall=88547
2023-05-09 00:32:26 - progress_bar.py[line:272] - INFO: epoch 026:    292 / 866 loss=2.027, loss_v1=0, loss_v2=0, nll_loss=0.783, ntokens=2121.1, nsentences=64, sample_size=2121.1, sample_size_v1=0, sample_size_v2=0, ppl=1.72, wps=528.2, ups=0.25, wpb=2121.1, bsz=64, num_updates=21900, lr=5.01187e-06, gnorm=6.624, clip=100, loss_scale=32, train_wall=40, gb_free=7.8, wall=88587
2023-05-09 00:33:07 - progress_bar.py[line:272] - INFO: epoch 026:    302 / 866 loss=2.03, loss_v1=0, loss_v2=0, nll_loss=0.787, ntokens=2135.1, nsentences=64, sample_size=2135.1, sample_size_v1=0, sample_size_v2=0, ppl=1.73, wps=531.7, ups=0.25, wpb=2135.1, bsz=64, num_updates=21910, lr=4.99959e-06, gnorm=6.129, clip=100, loss_scale=32, train_wall=40, gb_free=7.9, wall=88628
2023-05-09 00:33:47 - progress_bar.py[line:272] - INFO: epoch 026:    312 / 866 loss=2.02, loss_v1=0, loss_v2=0, nll_loss=0.775, ntokens=2131.6, nsentences=64, sample_size=2131.6, sample_size_v1=0, sample_size_v2=0, ppl=1.71, wps=530.7, ups=0.25, wpb=2131.6, bsz=64, num_updates=21920, lr=4.98731e-06, gnorm=6.014, clip=100, loss_scale=32, train_wall=40, gb_free=7.8, wall=88668
2023-05-09 00:34:27 - progress_bar.py[line:272] - INFO: epoch 026:    322 / 866 loss=2.046, loss_v1=0, loss_v2=0, nll_loss=0.805, ntokens=1957, nsentences=64, sample_size=1957, sample_size_v1=0, sample_size_v2=0, ppl=1.75, wps=491, ups=0.25, wpb=1957, bsz=64, num_updates=21930, lr=4.97502e-06, gnorm=6.743, clip=100, loss_scale=32, train_wall=40, gb_free=7.7, wall=88708
2023-05-09 00:35:07 - progress_bar.py[line:272] - INFO: epoch 026:    332 / 866 loss=2.029, loss_v1=0, loss_v2=0, nll_loss=0.785, ntokens=2161.6, nsentences=64, sample_size=2161.6, sample_size_v1=0, sample_size_v2=0, ppl=1.72, wps=539.6, ups=0.25, wpb=2161.6, bsz=64, num_updates=21940, lr=4.96274e-06, gnorm=6.486, clip=100, loss_scale=32, train_wall=40, gb_free=7.6, wall=88748
2023-05-09 00:35:47 - progress_bar.py[line:272] - INFO: epoch 026:    342 / 866 loss=2.013, loss_v1=0, loss_v2=0, nll_loss=0.769, ntokens=2014.9, nsentences=64, sample_size=2014.9, sample_size_v1=0, sample_size_v2=0, ppl=1.7, wps=502.2, ups=0.25, wpb=2014.9, bsz=64, num_updates=21950, lr=4.95045e-06, gnorm=6.551, clip=100, loss_scale=32, train_wall=40, gb_free=8.2, wall=88788
2023-05-09 00:36:27 - progress_bar.py[line:272] - INFO: epoch 026:    352 / 866 loss=2.053, loss_v1=0, loss_v2=0, nll_loss=0.813, ntokens=1958, nsentences=64, sample_size=1958, sample_size_v1=0, sample_size_v2=0, ppl=1.76, wps=491.5, ups=0.25, wpb=1958, bsz=64, num_updates=21960, lr=4.93817e-06, gnorm=6.98, clip=100, loss_scale=32, train_wall=40, gb_free=8.2, wall=88828
2023-05-09 00:37:06 - progress_bar.py[line:272] - INFO: epoch 026:    362 / 866 loss=2.06, loss_v1=0, loss_v2=0, nll_loss=0.821, ntokens=1964.4, nsentences=64, sample_size=1964.4, sample_size_v1=0, sample_size_v2=0, ppl=1.77, wps=492.8, ups=0.25, wpb=1964.4, bsz=64, num_updates=21970, lr=4.92589e-06, gnorm=7.317, clip=100, loss_scale=32, train_wall=40, gb_free=7.7, wall=88868
2023-05-09 00:37:47 - progress_bar.py[line:272] - INFO: epoch 026:    372 / 866 loss=2.036, loss_v1=0, loss_v2=0, nll_loss=0.795, ntokens=2038.1, nsentences=64, sample_size=2038.1, sample_size_v1=0, sample_size_v2=0, ppl=1.73, wps=507.3, ups=0.25, wpb=2038.1, bsz=64, num_updates=21980, lr=4.9136e-06, gnorm=6.811, clip=100, loss_scale=32, train_wall=40, gb_free=8, wall=88908
2023-05-09 00:38:27 - progress_bar.py[line:272] - INFO: epoch 026:    382 / 866 loss=2.022, loss_v1=0, loss_v2=0, nll_loss=0.779, ntokens=2164.2, nsentences=64, sample_size=2164.2, sample_size_v1=0, sample_size_v2=0, ppl=1.72, wps=540.6, ups=0.25, wpb=2164.2, bsz=64, num_updates=21990, lr=4.90132e-06, gnorm=5.976, clip=100, loss_scale=32, train_wall=40, gb_free=7.5, wall=88948
2023-05-09 00:39:07 - progress_bar.py[line:272] - INFO: epoch 026:    392 / 866 loss=2.045, loss_v1=0, loss_v2=0, nll_loss=0.803, ntokens=2067.8, nsentences=64, sample_size=2067.8, sample_size_v1=0, sample_size_v2=0, ppl=1.74, wps=518.2, ups=0.25, wpb=2067.8, bsz=64, num_updates=22000, lr=4.88903e-06, gnorm=6.698, clip=100, loss_scale=32, train_wall=40, gb_free=8.2, wall=88988
2023-05-09 00:39:47 - progress_bar.py[line:272] - INFO: epoch 026:    402 / 866 loss=2.035, loss_v1=0, loss_v2=0, nll_loss=0.792, ntokens=2036, nsentences=64, sample_size=2036, sample_size_v1=0, sample_size_v2=0, ppl=1.73, wps=507.8, ups=0.25, wpb=2036, bsz=64, num_updates=22010, lr=4.87675e-06, gnorm=6.515, clip=100, loss_scale=32, train_wall=40, gb_free=7.6, wall=89028
2023-05-09 00:40:27 - progress_bar.py[line:272] - INFO: epoch 026:    412 / 866 loss=2.035, loss_v1=0, loss_v2=0, nll_loss=0.793, ntokens=2161.9, nsentences=64, sample_size=2161.9, sample_size_v1=0, sample_size_v2=0, ppl=1.73, wps=536.1, ups=0.25, wpb=2161.9, bsz=64, num_updates=22020, lr=4.86447e-06, gnorm=6.156, clip=100, loss_scale=32, train_wall=40, gb_free=7.5, wall=89068
2023-05-09 00:41:07 - progress_bar.py[line:272] - INFO: epoch 026:    422 / 866 loss=2.01, loss_v1=0, loss_v2=0, nll_loss=0.764, ntokens=2082.2, nsentences=64, sample_size=2082.2, sample_size_v1=0, sample_size_v2=0, ppl=1.7, wps=516.7, ups=0.25, wpb=2082.2, bsz=64, num_updates=22030, lr=4.85218e-06, gnorm=6.143, clip=100, loss_scale=32, train_wall=40, gb_free=7.2, wall=89108
2023-05-09 00:41:47 - progress_bar.py[line:272] - INFO: epoch 026:    432 / 866 loss=2.023, loss_v1=0, loss_v2=0, nll_loss=0.781, ntokens=2104.8, nsentences=64, sample_size=2104.8, sample_size_v1=0, sample_size_v2=0, ppl=1.72, wps=525.1, ups=0.25, wpb=2104.8, bsz=64, num_updates=22040, lr=4.8399e-06, gnorm=5.983, clip=100, loss_scale=32, train_wall=40, gb_free=8.1, wall=89149
2023-05-09 00:42:28 - progress_bar.py[line:272] - INFO: epoch 026:    442 / 866 loss=2.052, loss_v1=0, loss_v2=0, nll_loss=0.813, ntokens=2064.2, nsentences=64, sample_size=2064.2, sample_size_v1=0, sample_size_v2=0, ppl=1.76, wps=513.8, ups=0.25, wpb=2064.2, bsz=64, num_updates=22050, lr=4.82761e-06, gnorm=6.52, clip=100, loss_scale=32, train_wall=40, gb_free=7.3, wall=89189
2023-05-09 00:43:08 - progress_bar.py[line:272] - INFO: epoch 026:    452 / 866 loss=2.044, loss_v1=0, loss_v2=0, nll_loss=0.803, ntokens=1981.6, nsentences=64, sample_size=1981.6, sample_size_v1=0, sample_size_v2=0, ppl=1.74, wps=495.1, ups=0.25, wpb=1981.6, bsz=64, num_updates=22060, lr=4.81533e-06, gnorm=6.781, clip=100, loss_scale=32, train_wall=40, gb_free=8.3, wall=89229
2023-05-09 00:43:48 - progress_bar.py[line:272] - INFO: epoch 026:    462 / 866 loss=2.054, loss_v1=0, loss_v2=0, nll_loss=0.813, ntokens=2192.3, nsentences=64, sample_size=2192.3, sample_size_v1=0, sample_size_v2=0, ppl=1.76, wps=543.9, ups=0.25, wpb=2192.3, bsz=64, num_updates=22070, lr=4.80305e-06, gnorm=6.353, clip=100, loss_scale=32, train_wall=40, gb_free=7.3, wall=89269
2023-05-09 00:44:28 - progress_bar.py[line:272] - INFO: epoch 026:    472 / 866 loss=2.058, loss_v1=0, loss_v2=0, nll_loss=0.818, ntokens=2142.5, nsentences=64, sample_size=2142.5, sample_size_v1=0, sample_size_v2=0, ppl=1.76, wps=531.8, ups=0.25, wpb=2142.5, bsz=64, num_updates=22080, lr=4.79076e-06, gnorm=6.443, clip=100, loss_scale=32, train_wall=40, gb_free=7.3, wall=89309
2023-05-09 00:45:09 - progress_bar.py[line:272] - INFO: epoch 026:    482 / 866 loss=2.038, loss_v1=0, loss_v2=0, nll_loss=0.796, ntokens=2178.2, nsentences=64, sample_size=2178.2, sample_size_v1=0, sample_size_v2=0, ppl=1.74, wps=538.9, ups=0.25, wpb=2178.2, bsz=64, num_updates=22090, lr=4.77848e-06, gnorm=6.478, clip=100, loss_scale=32, train_wall=40, gb_free=8.2, wall=89350
2023-05-09 00:45:49 - progress_bar.py[line:272] - INFO: epoch 026:    492 / 866 loss=2.022, loss_v1=0, loss_v2=0, nll_loss=0.778, ntokens=2054.4, nsentences=64, sample_size=2054.4, sample_size_v1=0, sample_size_v2=0, ppl=1.71, wps=512.4, ups=0.25, wpb=2054.4, bsz=64, num_updates=22100, lr=4.76619e-06, gnorm=6.433, clip=100, loss_scale=32, train_wall=40, gb_free=7.5, wall=89390
2023-05-09 00:46:29 - progress_bar.py[line:272] - INFO: epoch 026:    502 / 866 loss=2.038, loss_v1=0, loss_v2=0, nll_loss=0.797, ntokens=2074.9, nsentences=64, sample_size=2074.9, sample_size_v1=0, sample_size_v2=0, ppl=1.74, wps=518.3, ups=0.25, wpb=2074.9, bsz=64, num_updates=22110, lr=4.75391e-06, gnorm=6.843, clip=100, loss_scale=32, train_wall=40, gb_free=7.9, wall=89430
2023-05-09 00:47:09 - progress_bar.py[line:272] - INFO: epoch 026:    512 / 866 loss=2.064, loss_v1=0, loss_v2=0, nll_loss=0.825, ntokens=2141.6, nsentences=64, sample_size=2141.6, sample_size_v1=0, sample_size_v2=0, ppl=1.77, wps=535.2, ups=0.25, wpb=2141.6, bsz=64, num_updates=22120, lr=4.74163e-06, gnorm=7.015, clip=100, loss_scale=32, train_wall=40, gb_free=7, wall=89470
2023-05-09 00:47:49 - progress_bar.py[line:272] - INFO: epoch 026:    522 / 866 loss=2.022, loss_v1=0, loss_v2=0, nll_loss=0.778, ntokens=2127.1, nsentences=64, sample_size=2127.1, sample_size_v1=0, sample_size_v2=0, ppl=1.71, wps=534.4, ups=0.25, wpb=2127.1, bsz=64, num_updates=22130, lr=4.72934e-06, gnorm=6.127, clip=100, loss_scale=32, train_wall=40, gb_free=8.1, wall=89510
2023-05-09 00:48:29 - progress_bar.py[line:272] - INFO: epoch 026:    532 / 866 loss=2.03, loss_v1=0, loss_v2=0, nll_loss=0.786, ntokens=2031, nsentences=64, sample_size=2031, sample_size_v1=0, sample_size_v2=0, ppl=1.72, wps=507.7, ups=0.25, wpb=2031, bsz=64, num_updates=22140, lr=4.71706e-06, gnorm=6.028, clip=100, loss_scale=32, train_wall=40, gb_free=8.3, wall=89550
2023-05-09 00:49:09 - progress_bar.py[line:272] - INFO: epoch 026:    542 / 866 loss=2.042, loss_v1=0, loss_v2=0, nll_loss=0.8, ntokens=2149.8, nsentences=64, sample_size=2149.8, sample_size_v1=0, sample_size_v2=0, ppl=1.74, wps=535.5, ups=0.25, wpb=2149.8, bsz=64, num_updates=22150, lr=4.70477e-06, gnorm=6.512, clip=100, loss_scale=32, train_wall=40, gb_free=7.3, wall=89590
2023-05-09 00:49:49 - progress_bar.py[line:272] - INFO: epoch 026:    552 / 866 loss=2.049, loss_v1=0, loss_v2=0, nll_loss=0.808, ntokens=2323, nsentences=64, sample_size=2323, sample_size_v1=0, sample_size_v2=0, ppl=1.75, wps=572.3, ups=0.25, wpb=2323, bsz=64, num_updates=22160, lr=4.69249e-06, gnorm=6.001, clip=100, loss_scale=32, train_wall=41, gb_free=7.4, wall=89630
2023-05-09 00:50:30 - progress_bar.py[line:272] - INFO: epoch 026:    562 / 866 loss=2.05, loss_v1=0, loss_v2=0, nll_loss=0.81, ntokens=2243.9, nsentences=64, sample_size=2243.9, sample_size_v1=0, sample_size_v2=0, ppl=1.75, wps=555.1, ups=0.25, wpb=2243.9, bsz=64, num_updates=22170, lr=4.68021e-06, gnorm=6.437, clip=100, loss_scale=32, train_wall=40, gb_free=8.3, wall=89671
2023-05-09 00:51:10 - progress_bar.py[line:272] - INFO: epoch 026:    572 / 866 loss=2.032, loss_v1=0, loss_v2=0, nll_loss=0.789, ntokens=2202.4, nsentences=64, sample_size=2202.4, sample_size_v1=0, sample_size_v2=0, ppl=1.73, wps=546.1, ups=0.25, wpb=2202.4, bsz=64, num_updates=22180, lr=4.66792e-06, gnorm=5.953, clip=100, loss_scale=32, train_wall=40, gb_free=7.4, wall=89711
2023-05-09 00:51:50 - progress_bar.py[line:272] - INFO: epoch 026:    582 / 866 loss=2.046, loss_v1=0, loss_v2=0, nll_loss=0.805, ntokens=2123.1, nsentences=64, sample_size=2123.1, sample_size_v1=0, sample_size_v2=0, ppl=1.75, wps=528.5, ups=0.25, wpb=2123.1, bsz=64, num_updates=22190, lr=4.65564e-06, gnorm=6.467, clip=100, loss_scale=32, train_wall=40, gb_free=7.4, wall=89751
2023-05-09 00:52:31 - progress_bar.py[line:272] - INFO: epoch 026:    592 / 866 loss=2.05, loss_v1=0, loss_v2=0, nll_loss=0.808, ntokens=2089, nsentences=64, sample_size=2089, sample_size_v1=0, sample_size_v2=0, ppl=1.75, wps=517.6, ups=0.25, wpb=2089, bsz=64, num_updates=22200, lr=4.64335e-06, gnorm=6.593, clip=100, loss_scale=32, train_wall=40, gb_free=7.3, wall=89792
2023-05-09 00:53:11 - progress_bar.py[line:272] - INFO: epoch 026:    602 / 866 loss=2.016, loss_v1=0, loss_v2=0, nll_loss=0.77, ntokens=2122.3, nsentences=64, sample_size=2122.3, sample_size_v1=0, sample_size_v2=0, ppl=1.71, wps=526.8, ups=0.25, wpb=2122.3, bsz=64, num_updates=22210, lr=4.63107e-06, gnorm=5.94, clip=100, loss_scale=64, train_wall=40, gb_free=8.3, wall=89832
2023-05-09 00:53:51 - progress_bar.py[line:272] - INFO: epoch 026:    612 / 866 loss=2.05, loss_v1=0, loss_v2=0, nll_loss=0.81, ntokens=1933.1, nsentences=64, sample_size=1933.1, sample_size_v1=0, sample_size_v2=0, ppl=1.75, wps=484.3, ups=0.25, wpb=1933.1, bsz=64, num_updates=22220, lr=4.61879e-06, gnorm=7.118, clip=100, loss_scale=64, train_wall=40, gb_free=8.1, wall=89872
2023-05-09 00:54:31 - progress_bar.py[line:272] - INFO: epoch 026:    622 / 866 loss=2.048, loss_v1=0, loss_v2=0, nll_loss=0.808, ntokens=2007.3, nsentences=64, sample_size=2007.3, sample_size_v1=0, sample_size_v2=0, ppl=1.75, wps=499.9, ups=0.25, wpb=2007.3, bsz=64, num_updates=22230, lr=4.6065e-06, gnorm=6.891, clip=100, loss_scale=64, train_wall=40, gb_free=7.7, wall=89912
2023-05-09 00:55:11 - progress_bar.py[line:272] - INFO: epoch 026:    632 / 866 loss=2.042, loss_v1=0, loss_v2=0, nll_loss=0.801, ntokens=2011.8, nsentences=64, sample_size=2011.8, sample_size_v1=0, sample_size_v2=0, ppl=1.74, wps=503.8, ups=0.25, wpb=2011.8, bsz=64, num_updates=22240, lr=4.59422e-06, gnorm=6.328, clip=100, loss_scale=64, train_wall=40, gb_free=8.1, wall=89952
2023-05-09 00:55:51 - progress_bar.py[line:272] - INFO: epoch 026:    642 / 866 loss=2.024, loss_v1=0, loss_v2=0, nll_loss=0.78, ntokens=2063.3, nsentences=64, sample_size=2063.3, sample_size_v1=0, sample_size_v2=0, ppl=1.72, wps=515.1, ups=0.25, wpb=2063.3, bsz=64, num_updates=22250, lr=4.58193e-06, gnorm=6.504, clip=100, loss_scale=64, train_wall=40, gb_free=7.5, wall=89992
2023-05-09 00:56:31 - progress_bar.py[line:272] - INFO: epoch 026:    652 / 866 loss=2.045, loss_v1=0, loss_v2=0, nll_loss=0.804, ntokens=2019.1, nsentences=64, sample_size=2019.1, sample_size_v1=0, sample_size_v2=0, ppl=1.75, wps=505.2, ups=0.25, wpb=2019.1, bsz=64, num_updates=22260, lr=4.56965e-06, gnorm=6.776, clip=100, loss_scale=64, train_wall=40, gb_free=8.7, wall=90032
2023-05-09 00:57:11 - progress_bar.py[line:272] - INFO: epoch 026:    662 / 866 loss=2.074, loss_v1=0, loss_v2=0, nll_loss=0.837, ntokens=1927, nsentences=64, sample_size=1927, sample_size_v1=0, sample_size_v2=0, ppl=1.79, wps=485.3, ups=0.25, wpb=1927, bsz=64, num_updates=22270, lr=4.55737e-06, gnorm=7.204, clip=100, loss_scale=64, train_wall=40, gb_free=6.9, wall=90072
2023-05-09 00:57:51 - progress_bar.py[line:272] - INFO: epoch 026:    672 / 866 loss=2.042, loss_v1=0, loss_v2=0, nll_loss=0.8, ntokens=2033.9, nsentences=64, sample_size=2033.9, sample_size_v1=0, sample_size_v2=0, ppl=1.74, wps=507.6, ups=0.25, wpb=2033.9, bsz=64, num_updates=22280, lr=4.54508e-06, gnorm=6.786, clip=100, loss_scale=64, train_wall=40, gb_free=8.1, wall=90112
2023-05-09 00:58:31 - progress_bar.py[line:272] - INFO: epoch 026:    682 / 866 loss=2.038, loss_v1=0, loss_v2=0, nll_loss=0.795, ntokens=2076.8, nsentences=64, sample_size=2076.8, sample_size_v1=0, sample_size_v2=0, ppl=1.74, wps=520.6, ups=0.25, wpb=2076.8, bsz=64, num_updates=22290, lr=4.5328e-06, gnorm=6.567, clip=100, loss_scale=64, train_wall=40, gb_free=7.9, wall=90152
2023-05-09 00:59:11 - progress_bar.py[line:272] - INFO: epoch 026:    692 / 866 loss=2.046, loss_v1=0, loss_v2=0, nll_loss=0.805, ntokens=1991.3, nsentences=64, sample_size=1991.3, sample_size_v1=0, sample_size_v2=0, ppl=1.75, wps=494.3, ups=0.25, wpb=1991.3, bsz=64, num_updates=22300, lr=4.52051e-06, gnorm=6.593, clip=100, loss_scale=64, train_wall=40, gb_free=8.3, wall=90192
2023-05-09 00:59:51 - progress_bar.py[line:272] - INFO: epoch 026:    702 / 866 loss=2.053, loss_v1=0, loss_v2=0, nll_loss=0.813, ntokens=2062.5, nsentences=64, sample_size=2062.5, sample_size_v1=0, sample_size_v2=0, ppl=1.76, wps=515.8, ups=0.25, wpb=2062.5, bsz=64, num_updates=22310, lr=4.50823e-06, gnorm=6.607, clip=100, loss_scale=64, train_wall=40, gb_free=8, wall=90232
2023-05-09 01:00:31 - progress_bar.py[line:272] - INFO: epoch 026:    712 / 866 loss=2.049, loss_v1=0, loss_v2=0, nll_loss=0.807, ntokens=1917.3, nsentences=64, sample_size=1917.3, sample_size_v1=0, sample_size_v2=0, ppl=1.75, wps=478.3, ups=0.25, wpb=1917.3, bsz=64, num_updates=22320, lr=4.49595e-06, gnorm=7.009, clip=100, loss_scale=64, train_wall=40, gb_free=8.3, wall=90272
2023-05-09 01:01:11 - progress_bar.py[line:272] - INFO: epoch 026:    722 / 866 loss=2.02, loss_v1=0, loss_v2=0, nll_loss=0.776, ntokens=1946.1, nsentences=64, sample_size=1946.1, sample_size_v1=0, sample_size_v2=0, ppl=1.71, wps=486.7, ups=0.25, wpb=1946.1, bsz=64, num_updates=22330, lr=4.48366e-06, gnorm=6.512, clip=100, loss_scale=64, train_wall=40, gb_free=7.9, wall=90312
2023-05-09 01:01:51 - progress_bar.py[line:272] - INFO: epoch 026:    732 / 866 loss=2.021, loss_v1=0, loss_v2=0, nll_loss=0.777, ntokens=2021.9, nsentences=64, sample_size=2021.9, sample_size_v1=0, sample_size_v2=0, ppl=1.71, wps=507, ups=0.25, wpb=2021.9, bsz=64, num_updates=22340, lr=4.47138e-06, gnorm=6.166, clip=100, loss_scale=64, train_wall=40, gb_free=7.4, wall=90352
2023-05-09 01:02:31 - progress_bar.py[line:272] - INFO: epoch 026:    742 / 866 loss=2.035, loss_v1=0, loss_v2=0, nll_loss=0.794, ntokens=2148.8, nsentences=64, sample_size=2148.8, sample_size_v1=0, sample_size_v2=0, ppl=1.73, wps=536, ups=0.25, wpb=2148.8, bsz=64, num_updates=22350, lr=4.45909e-06, gnorm=6.181, clip=100, loss_scale=64, train_wall=40, gb_free=7.9, wall=90392
2023-05-09 01:03:11 - progress_bar.py[line:272] - INFO: epoch 026:    752 / 866 loss=2.022, loss_v1=0, loss_v2=0, nll_loss=0.78, ntokens=2084.2, nsentences=64, sample_size=2084.2, sample_size_v1=0, sample_size_v2=0, ppl=1.72, wps=520.5, ups=0.25, wpb=2084.2, bsz=64, num_updates=22360, lr=4.44681e-06, gnorm=6.363, clip=100, loss_scale=64, train_wall=40, gb_free=8.1, wall=90432
2023-05-09 01:03:51 - progress_bar.py[line:272] - INFO: epoch 026:    762 / 866 loss=2.031, loss_v1=0, loss_v2=0, nll_loss=0.789, ntokens=2125.4, nsentences=64, sample_size=2125.4, sample_size_v1=0, sample_size_v2=0, ppl=1.73, wps=528.9, ups=0.25, wpb=2125.4, bsz=64, num_updates=22370, lr=4.43453e-06, gnorm=6.276, clip=100, loss_scale=64, train_wall=40, gb_free=8.3, wall=90472
2023-05-09 01:04:31 - progress_bar.py[line:272] - INFO: epoch 026:    772 / 866 loss=2.028, loss_v1=0, loss_v2=0, nll_loss=0.784, ntokens=2085.7, nsentences=64, sample_size=2085.7, sample_size_v1=0, sample_size_v2=0, ppl=1.72, wps=522.7, ups=0.25, wpb=2085.7, bsz=64, num_updates=22380, lr=4.42224e-06, gnorm=6.578, clip=100, loss_scale=64, train_wall=40, gb_free=6.6, wall=90512
2023-05-09 01:05:11 - progress_bar.py[line:272] - INFO: epoch 026:    782 / 866 loss=2.043, loss_v1=0, loss_v2=0, nll_loss=0.801, ntokens=2278.8, nsentences=64, sample_size=2278.8, sample_size_v1=0, sample_size_v2=0, ppl=1.74, wps=564.6, ups=0.25, wpb=2278.8, bsz=64, num_updates=22390, lr=4.40996e-06, gnorm=6.284, clip=100, loss_scale=64, train_wall=40, gb_free=8, wall=90553
2023-05-09 01:05:51 - progress_bar.py[line:272] - INFO: epoch 026:    792 / 866 loss=2.053, loss_v1=0, loss_v2=0, nll_loss=0.813, ntokens=1976.5, nsentences=64, sample_size=1976.5, sample_size_v1=0, sample_size_v2=0, ppl=1.76, wps=495.5, ups=0.25, wpb=1976.5, bsz=64, num_updates=22400, lr=4.39767e-06, gnorm=6.998, clip=100, loss_scale=64, train_wall=40, gb_free=8.4, wall=90592
2023-05-09 01:06:31 - progress_bar.py[line:272] - INFO: epoch 026:    802 / 866 loss=2.038, loss_v1=0, loss_v2=0, nll_loss=0.795, ntokens=1992.1, nsentences=64, sample_size=1992.1, sample_size_v1=0, sample_size_v2=0, ppl=1.74, wps=500.5, ups=0.25, wpb=1992.1, bsz=64, num_updates=22410, lr=4.38539e-06, gnorm=6.314, clip=100, loss_scale=64, train_wall=40, gb_free=8.1, wall=90632
2023-05-09 01:07:11 - progress_bar.py[line:272] - INFO: epoch 026:    812 / 866 loss=2.019, loss_v1=0, loss_v2=0, nll_loss=0.773, ntokens=2094, nsentences=64, sample_size=2094, sample_size_v1=0, sample_size_v2=0, ppl=1.71, wps=522.7, ups=0.25, wpb=2094, bsz=64, num_updates=22420, lr=4.37311e-06, gnorm=6.595, clip=100, loss_scale=64, train_wall=40, gb_free=7.9, wall=90672
2023-05-09 01:07:51 - progress_bar.py[line:272] - INFO: epoch 026:    822 / 866 loss=2.023, loss_v1=0, loss_v2=0, nll_loss=0.778, ntokens=2092, nsentences=64, sample_size=2092, sample_size_v1=0, sample_size_v2=0, ppl=1.71, wps=520.8, ups=0.25, wpb=2092, bsz=64, num_updates=22430, lr=4.36082e-06, gnorm=6.529, clip=100, loss_scale=64, train_wall=40, gb_free=7.6, wall=90713
2023-05-09 01:08:32 - progress_bar.py[line:272] - INFO: epoch 026:    832 / 866 loss=2.006, loss_v1=0, loss_v2=0, nll_loss=0.761, ntokens=2219.9, nsentences=64, sample_size=2219.9, sample_size_v1=0, sample_size_v2=0, ppl=1.69, wps=544, ups=0.25, wpb=2219.9, bsz=64, num_updates=22440, lr=4.34854e-06, gnorm=5.953, clip=100, loss_scale=64, train_wall=41, gb_free=8.2, wall=90753
2023-05-09 01:09:13 - progress_bar.py[line:272] - INFO: epoch 026:    842 / 866 loss=2.017, loss_v1=0, loss_v2=0, nll_loss=0.773, ntokens=2113, nsentences=64, sample_size=2113, sample_size_v1=0, sample_size_v2=0, ppl=1.71, wps=524.2, ups=0.25, wpb=2113, bsz=64, num_updates=22450, lr=4.33625e-06, gnorm=6.468, clip=100, loss_scale=64, train_wall=40, gb_free=7.7, wall=90794
2023-05-09 01:09:53 - progress_bar.py[line:272] - INFO: epoch 026:    852 / 866 loss=2.007, loss_v1=0, loss_v2=0, nll_loss=0.761, ntokens=2190.2, nsentences=64, sample_size=2190.2, sample_size_v1=0, sample_size_v2=0, ppl=1.69, wps=540, ups=0.25, wpb=2190.2, bsz=64, num_updates=22460, lr=4.32397e-06, gnorm=6.086, clip=100, loss_scale=64, train_wall=41, gb_free=8.2, wall=90834
2023-05-09 01:10:33 - progress_bar.py[line:272] - INFO: epoch 026:    862 / 866 loss=2.02, loss_v1=0, loss_v2=0, nll_loss=0.776, ntokens=2026.6, nsentences=64, sample_size=2026.6, sample_size_v1=0, sample_size_v2=0, ppl=1.71, wps=506.2, ups=0.25, wpb=2026.6, bsz=64, num_updates=22470, lr=4.31169e-06, gnorm=6.239, clip=100, loss_scale=64, train_wall=40, gb_free=7.2, wall=90874
2023-05-09 01:10:48 - train.py[line:332] - INFO: end of epoch 26 (average epoch stats below)
local datafile ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 1 begin to initialize row_count and line_idx-to-offset mapping
2023-05-09 01:10:48 - progress_bar.py[line:282] - INFO: epoch 026 | loss 2.027 | loss_v1 0 | loss_v2 0 | nll_loss 0.784 | ntokens 2103.32 | nsentences 63.972 | sample_size 2103.32 | sample_size_v1 0 | sample_size_v2 0 | ppl 1.72 | wps 520.7 | ups 0.25 | wpb 2103.3 | bsz 64 | num_updates 22474 | lr 4.30677e-06 | gnorm 6.41 | clip 100 | loss_scale 64 | train_wall 3488 | gb_free 8.7 | wall 90889
2023-05-09 01:10:48 - trainer.py[line:639] - INFO: loading train data for epoch 27
local datafile ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 0 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 1 finished initializing row_count and line_idx-to-offset mapping
file ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 1 row count 27700 total row count 55400
slice_id 1 seek offset 27700
local datafile ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 0 finished initializing row_count and line_idx-to-offset mapping
file ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 0 row count 27700 total row count 55400
slice_id 0 seek offset 0
2023-05-09 01:10:49 - trainer.py[line:703] - INFO: begin training epoch 27
2023-05-09 01:10:49 - train.py[line:305] - INFO: Start iterating over samples
2023-05-09 01:11:14 - progress_bar.py[line:272] - INFO: epoch 027:      6 / 866 loss=2.022, loss_v1=0, loss_v2=0, nll_loss=0.78, ntokens=2056, nsentences=61.6, sample_size=2056, sample_size_v1=0, sample_size_v2=0, ppl=1.72, wps=500.5, ups=0.24, wpb=2056, bsz=61.6, num_updates=22480, lr=4.2994e-06, gnorm=6.514, clip=100, loss_scale=64, train_wall=39, gb_free=7.5, wall=90915
2023-05-09 01:11:55 - progress_bar.py[line:272] - INFO: epoch 027:     16 / 866 loss=2.016, loss_v1=0, loss_v2=0, nll_loss=0.772, ntokens=2094.4, nsentences=64, sample_size=2094.4, sample_size_v1=0, sample_size_v2=0, ppl=1.71, wps=518.6, ups=0.25, wpb=2094.4, bsz=64, num_updates=22490, lr=4.28712e-06, gnorm=7.084, clip=100, loss_scale=64, train_wall=40, gb_free=7.5, wall=90956
2023-05-09 01:12:35 - progress_bar.py[line:272] - INFO: epoch 027:     26 / 866 loss=1.988, loss_v1=0, loss_v2=0, nll_loss=0.739, ntokens=1961.6, nsentences=64, sample_size=1961.6, sample_size_v1=0, sample_size_v2=0, ppl=1.67, wps=486.5, ups=0.25, wpb=1961.6, bsz=64, num_updates=22500, lr=4.27483e-06, gnorm=6.972, clip=100, loss_scale=64, train_wall=40, gb_free=7.8, wall=90996
2023-05-09 01:13:16 - progress_bar.py[line:272] - INFO: epoch 027:     36 / 866 loss=1.954, loss_v1=0, loss_v2=0, nll_loss=0.7, ntokens=2199.4, nsentences=64, sample_size=2199.4, sample_size_v1=0, sample_size_v2=0, ppl=1.62, wps=538.8, ups=0.24, wpb=2199.4, bsz=64, num_updates=22510, lr=4.26255e-06, gnorm=6.003, clip=100, loss_scale=64, train_wall=41, gb_free=6.6, wall=91037
2023-05-09 01:13:56 - progress_bar.py[line:272] - INFO: epoch 027:     46 / 866 loss=1.961, loss_v1=0, loss_v2=0, nll_loss=0.71, ntokens=2017.3, nsentences=64, sample_size=2017.3, sample_size_v1=0, sample_size_v2=0, ppl=1.64, wps=499.6, ups=0.25, wpb=2017.3, bsz=64, num_updates=22520, lr=4.25027e-06, gnorm=6.361, clip=100, loss_scale=64, train_wall=40, gb_free=8, wall=91077
2023-05-09 01:14:37 - progress_bar.py[line:272] - INFO: epoch 027:     56 / 866 loss=1.948, loss_v1=0, loss_v2=0, nll_loss=0.694, ntokens=2095.1, nsentences=64, sample_size=2095.1, sample_size_v1=0, sample_size_v2=0, ppl=1.62, wps=517, ups=0.25, wpb=2095.1, bsz=64, num_updates=22530, lr=4.23798e-06, gnorm=6.641, clip=100, loss_scale=64, train_wall=40, gb_free=7.8, wall=91118
2023-05-09 01:15:18 - progress_bar.py[line:272] - INFO: epoch 027:     66 / 866 loss=1.904, loss_v1=0, loss_v2=0, nll_loss=0.646, ntokens=2319.7, nsentences=64, sample_size=2319.7, sample_size_v1=0, sample_size_v2=0, ppl=1.56, wps=560.7, ups=0.24, wpb=2319.7, bsz=64, num_updates=22540, lr=4.2257e-06, gnorm=5.889, clip=100, loss_scale=64, train_wall=41, gb_free=6.7, wall=91159
2023-05-09 01:16:00 - progress_bar.py[line:272] - INFO: epoch 027:     76 / 866 loss=1.952, loss_v1=0, loss_v2=0, nll_loss=0.7, ntokens=2406.4, nsentences=64, sample_size=2406.4, sample_size_v1=0, sample_size_v2=0, ppl=1.62, wps=575.5, ups=0.24, wpb=2406.4, bsz=64, num_updates=22550, lr=4.21341e-06, gnorm=5.511, clip=100, loss_scale=64, train_wall=42, gb_free=6.3, wall=91201
2023-05-09 01:16:41 - progress_bar.py[line:272] - INFO: epoch 027:     86 / 866 loss=1.986, loss_v1=0, loss_v2=0, nll_loss=0.74, ntokens=2127.2, nsentences=64, sample_size=2127.2, sample_size_v1=0, sample_size_v2=0, ppl=1.67, wps=520.1, ups=0.24, wpb=2127.2, bsz=64, num_updates=22560, lr=4.20113e-06, gnorm=6.633, clip=100, loss_scale=64, train_wall=41, gb_free=7.1, wall=91242
2023-05-09 01:17:21 - progress_bar.py[line:272] - INFO: epoch 027:     96 / 866 loss=1.968, loss_v1=0, loss_v2=0, nll_loss=0.718, ntokens=2135.5, nsentences=64, sample_size=2135.5, sample_size_v1=0, sample_size_v2=0, ppl=1.65, wps=525.5, ups=0.25, wpb=2135.5, bsz=64, num_updates=22570, lr=4.18885e-06, gnorm=6.658, clip=100, loss_scale=64, train_wall=41, gb_free=6.6, wall=91283
2023-05-09 01:18:02 - progress_bar.py[line:272] - INFO: epoch 027:    106 / 866 loss=2.023, loss_v1=0, loss_v2=0, nll_loss=0.78, ntokens=2037, nsentences=64, sample_size=2037, sample_size_v1=0, sample_size_v2=0, ppl=1.72, wps=505.5, ups=0.25, wpb=2037, bsz=64, num_updates=22580, lr=4.17656e-06, gnorm=6.844, clip=100, loss_scale=64, train_wall=40, gb_free=6.5, wall=91323
2023-05-09 01:18:43 - progress_bar.py[line:272] - INFO: epoch 027:    116 / 866 loss=2.047, loss_v1=0, loss_v2=0, nll_loss=0.807, ntokens=2065.5, nsentences=64, sample_size=2065.5, sample_size_v1=0, sample_size_v2=0, ppl=1.75, wps=506, ups=0.24, wpb=2065.5, bsz=64, num_updates=22590, lr=4.16428e-06, gnorm=7.001, clip=100, loss_scale=64, train_wall=41, gb_free=6.7, wall=91364
2023-05-09 01:18:59 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2023-05-09 01:19:28 - progress_bar.py[line:272] - INFO: epoch 027:    127 / 866 loss=2.038, loss_v1=0, loss_v2=0, nll_loss=0.795, ntokens=2232.4, nsentences=64, sample_size=2232.4, sample_size_v1=0, sample_size_v2=0, ppl=1.74, wps=493.2, ups=0.22, wpb=2232.4, bsz=64, num_updates=22600, lr=4.15199e-06, gnorm=6.755, clip=100, loss_scale=32, train_wall=45, gb_free=7.3, wall=91409
2023-05-09 01:20:09 - progress_bar.py[line:272] - INFO: epoch 027:    137 / 866 loss=2, loss_v1=0, loss_v2=0, nll_loss=0.753, ntokens=2240.2, nsentences=64, sample_size=2240.2, sample_size_v1=0, sample_size_v2=0, ppl=1.69, wps=546.4, ups=0.24, wpb=2240.2, bsz=64, num_updates=22610, lr=4.13971e-06, gnorm=6.524, clip=100, loss_scale=32, train_wall=41, gb_free=7.3, wall=91450
2023-05-09 01:20:50 - progress_bar.py[line:272] - INFO: epoch 027:    147 / 866 loss=1.987, loss_v1=0, loss_v2=0, nll_loss=0.738, ntokens=2170.9, nsentences=64, sample_size=2170.9, sample_size_v1=0, sample_size_v2=0, ppl=1.67, wps=525.8, ups=0.24, wpb=2170.9, bsz=64, num_updates=22620, lr=4.12743e-06, gnorm=6.763, clip=100, loss_scale=32, train_wall=41, gb_free=7.2, wall=91491
2023-05-09 01:21:32 - progress_bar.py[line:272] - INFO: epoch 027:    157 / 866 loss=2.017, loss_v1=0, loss_v2=0, nll_loss=0.772, ntokens=2265.1, nsentences=64, sample_size=2265.1, sample_size_v1=0, sample_size_v2=0, ppl=1.71, wps=547, ups=0.24, wpb=2265.1, bsz=64, num_updates=22630, lr=4.11514e-06, gnorm=6.561, clip=100, loss_scale=32, train_wall=41, gb_free=7.1, wall=91533
2023-05-09 01:22:12 - progress_bar.py[line:272] - INFO: epoch 027:    167 / 866 loss=2.01, loss_v1=0, loss_v2=0, nll_loss=0.764, ntokens=2117.6, nsentences=64, sample_size=2117.6, sample_size_v1=0, sample_size_v2=0, ppl=1.7, wps=521.2, ups=0.25, wpb=2117.6, bsz=64, num_updates=22640, lr=4.10286e-06, gnorm=6.835, clip=100, loss_scale=32, train_wall=41, gb_free=6.4, wall=91573
2023-05-09 01:22:53 - progress_bar.py[line:272] - INFO: epoch 027:    177 / 866 loss=2.017, loss_v1=0, loss_v2=0, nll_loss=0.772, ntokens=2059.5, nsentences=64, sample_size=2059.5, sample_size_v1=0, sample_size_v2=0, ppl=1.71, wps=507.9, ups=0.25, wpb=2059.5, bsz=64, num_updates=22650, lr=4.09057e-06, gnorm=6.989, clip=100, loss_scale=32, train_wall=41, gb_free=7.1, wall=91614
2023-05-09 01:23:34 - progress_bar.py[line:272] - INFO: epoch 027:    187 / 866 loss=1.993, loss_v1=0, loss_v2=0, nll_loss=0.744, ntokens=2187.4, nsentences=64, sample_size=2187.4, sample_size_v1=0, sample_size_v2=0, ppl=1.67, wps=532.8, ups=0.24, wpb=2187.4, bsz=64, num_updates=22660, lr=4.07829e-06, gnorm=6.102, clip=100, loss_scale=32, train_wall=41, gb_free=6.7, wall=91655
2023-05-09 01:24:15 - progress_bar.py[line:272] - INFO: epoch 027:    197 / 866 loss=2.014, loss_v1=0, loss_v2=0, nll_loss=0.768, ntokens=2211.2, nsentences=64, sample_size=2211.2, sample_size_v1=0, sample_size_v2=0, ppl=1.7, wps=538, ups=0.24, wpb=2211.2, bsz=64, num_updates=22670, lr=4.06601e-06, gnorm=6.555, clip=100, loss_scale=32, train_wall=41, gb_free=7.6, wall=91696
2023-05-09 01:24:55 - progress_bar.py[line:272] - INFO: epoch 027:    207 / 866 loss=2.026, loss_v1=0, loss_v2=0, nll_loss=0.782, ntokens=1950.8, nsentences=64, sample_size=1950.8, sample_size_v1=0, sample_size_v2=0, ppl=1.72, wps=486.3, ups=0.25, wpb=1950.8, bsz=64, num_updates=22680, lr=4.05372e-06, gnorm=7.22, clip=100, loss_scale=32, train_wall=40, gb_free=7, wall=91736
2023-05-09 01:25:35 - progress_bar.py[line:272] - INFO: epoch 027:    217 / 866 loss=2.045, loss_v1=0, loss_v2=0, nll_loss=0.805, ntokens=2217.4, nsentences=64, sample_size=2217.4, sample_size_v1=0, sample_size_v2=0, ppl=1.75, wps=548.3, ups=0.25, wpb=2217.4, bsz=64, num_updates=22690, lr=4.04144e-06, gnorm=6.119, clip=100, loss_scale=32, train_wall=40, gb_free=7.5, wall=91777
2023-05-09 01:26:16 - progress_bar.py[line:272] - INFO: epoch 027:    227 / 866 loss=2.024, loss_v1=0, loss_v2=0, nll_loss=0.781, ntokens=2163.3, nsentences=64, sample_size=2163.3, sample_size_v1=0, sample_size_v2=0, ppl=1.72, wps=537.8, ups=0.25, wpb=2163.3, bsz=64, num_updates=22700, lr=4.02915e-06, gnorm=6.285, clip=100, loss_scale=32, train_wall=40, gb_free=7.1, wall=91817
2023-05-09 01:26:56 - progress_bar.py[line:272] - INFO: epoch 027:    237 / 866 loss=2.055, loss_v1=0, loss_v2=0, nll_loss=0.815, ntokens=2102.5, nsentences=64, sample_size=2102.5, sample_size_v1=0, sample_size_v2=0, ppl=1.76, wps=524.9, ups=0.25, wpb=2102.5, bsz=64, num_updates=22710, lr=4.01687e-06, gnorm=6.631, clip=100, loss_scale=32, train_wall=40, gb_free=7, wall=91857
2023-05-09 01:27:36 - progress_bar.py[line:272] - INFO: epoch 027:    247 / 866 loss=2.034, loss_v1=0, loss_v2=0, nll_loss=0.791, ntokens=2200.6, nsentences=64, sample_size=2200.6, sample_size_v1=0, sample_size_v2=0, ppl=1.73, wps=543.7, ups=0.25, wpb=2200.6, bsz=64, num_updates=22720, lr=4.00459e-06, gnorm=6.387, clip=100, loss_scale=32, train_wall=40, gb_free=7.3, wall=91897
2023-05-09 01:28:17 - progress_bar.py[line:272] - INFO: epoch 027:    257 / 866 loss=2.031, loss_v1=0, loss_v2=0, nll_loss=0.788, ntokens=2098, nsentences=64, sample_size=2098, sample_size_v1=0, sample_size_v2=0, ppl=1.73, wps=519.4, ups=0.25, wpb=2098, bsz=64, num_updates=22730, lr=3.9923e-06, gnorm=6.314, clip=100, loss_scale=32, train_wall=40, gb_free=7.5, wall=91938
2023-05-09 01:28:57 - progress_bar.py[line:272] - INFO: epoch 027:    267 / 866 loss=2.038, loss_v1=0, loss_v2=0, nll_loss=0.795, ntokens=2119.1, nsentences=64, sample_size=2119.1, sample_size_v1=0, sample_size_v2=0, ppl=1.73, wps=524.3, ups=0.25, wpb=2119.1, bsz=64, num_updates=22740, lr=3.98002e-06, gnorm=6.53, clip=100, loss_scale=32, train_wall=40, gb_free=7.5, wall=91978
2023-05-09 01:29:37 - progress_bar.py[line:272] - INFO: epoch 027:    277 / 866 loss=2.043, loss_v1=0, loss_v2=0, nll_loss=0.8, ntokens=2198.3, nsentences=64, sample_size=2198.3, sample_size_v1=0, sample_size_v2=0, ppl=1.74, wps=545.5, ups=0.25, wpb=2198.3, bsz=64, num_updates=22750, lr=3.96773e-06, gnorm=6.61, clip=100, loss_scale=32, train_wall=40, gb_free=7.5, wall=92018
2023-05-09 01:30:18 - progress_bar.py[line:272] - INFO: epoch 027:    287 / 866 loss=2.028, loss_v1=0, loss_v2=0, nll_loss=0.784, ntokens=2164.9, nsentences=64, sample_size=2164.9, sample_size_v1=0, sample_size_v2=0, ppl=1.72, wps=538.1, ups=0.25, wpb=2164.9, bsz=64, num_updates=22760, lr=3.95545e-06, gnorm=6.383, clip=100, loss_scale=32, train_wall=40, gb_free=7.3, wall=92059
2023-05-09 01:30:58 - progress_bar.py[line:272] - INFO: epoch 027:    297 / 866 loss=2.03, loss_v1=0, loss_v2=0, nll_loss=0.787, ntokens=2121.1, nsentences=64, sample_size=2121.1, sample_size_v1=0, sample_size_v2=0, ppl=1.73, wps=528.9, ups=0.25, wpb=2121.1, bsz=64, num_updates=22770, lr=3.94317e-06, gnorm=7.063, clip=100, loss_scale=32, train_wall=40, gb_free=7.1, wall=92099
2023-05-09 01:31:38 - progress_bar.py[line:272] - INFO: epoch 027:    307 / 866 loss=2.025, loss_v1=0, loss_v2=0, nll_loss=0.782, ntokens=2127, nsentences=64, sample_size=2127, sample_size_v1=0, sample_size_v2=0, ppl=1.72, wps=529.4, ups=0.25, wpb=2127, bsz=64, num_updates=22780, lr=3.93088e-06, gnorm=6.991, clip=100, loss_scale=32, train_wall=40, gb_free=8.3, wall=92139
2023-05-09 01:32:18 - progress_bar.py[line:272] - INFO: epoch 027:    317 / 866 loss=2.031, loss_v1=0, loss_v2=0, nll_loss=0.788, ntokens=2050.8, nsentences=64, sample_size=2050.8, sample_size_v1=0, sample_size_v2=0, ppl=1.73, wps=513, ups=0.25, wpb=2050.8, bsz=64, num_updates=22790, lr=3.9186e-06, gnorm=6.779, clip=100, loss_scale=32, train_wall=40, gb_free=7.8, wall=92179
2023-05-09 01:32:58 - progress_bar.py[line:272] - INFO: epoch 027:    327 / 866 loss=2.042, loss_v1=0, loss_v2=0, nll_loss=0.8, ntokens=2048.6, nsentences=64, sample_size=2048.6, sample_size_v1=0, sample_size_v2=0, ppl=1.74, wps=513.2, ups=0.25, wpb=2048.6, bsz=64, num_updates=22800, lr=3.90631e-06, gnorm=7.156, clip=100, loss_scale=32, train_wall=40, gb_free=7.7, wall=92219
2023-05-09 01:33:38 - progress_bar.py[line:272] - INFO: epoch 027:    337 / 866 loss=2.007, loss_v1=0, loss_v2=0, nll_loss=0.761, ntokens=2101.6, nsentences=64, sample_size=2101.6, sample_size_v1=0, sample_size_v2=0, ppl=1.69, wps=522.2, ups=0.25, wpb=2101.6, bsz=64, num_updates=22810, lr=3.89403e-06, gnorm=6.243, clip=100, loss_scale=32, train_wall=40, gb_free=7.2, wall=92259
2023-05-09 01:34:18 - progress_bar.py[line:272] - INFO: epoch 027:    347 / 866 loss=2.024, loss_v1=0, loss_v2=0, nll_loss=0.781, ntokens=1929.9, nsentences=64, sample_size=1929.9, sample_size_v1=0, sample_size_v2=0, ppl=1.72, wps=481.2, ups=0.25, wpb=1929.9, bsz=64, num_updates=22820, lr=3.88175e-06, gnorm=7.023, clip=100, loss_scale=32, train_wall=40, gb_free=7.8, wall=92299
2023-05-09 01:34:58 - progress_bar.py[line:272] - INFO: epoch 027:    357 / 866 loss=2.059, loss_v1=0, loss_v2=0, nll_loss=0.82, ntokens=1986.1, nsentences=64, sample_size=1986.1, sample_size_v1=0, sample_size_v2=0, ppl=1.76, wps=496.4, ups=0.25, wpb=1986.1, bsz=64, num_updates=22830, lr=3.86946e-06, gnorm=6.854, clip=100, loss_scale=32, train_wall=40, gb_free=8.2, wall=92339
2023-05-09 01:35:38 - progress_bar.py[line:272] - INFO: epoch 027:    367 / 866 loss=2.041, loss_v1=0, loss_v2=0, nll_loss=0.8, ntokens=1980.8, nsentences=64, sample_size=1980.8, sample_size_v1=0, sample_size_v2=0, ppl=1.74, wps=494.9, ups=0.25, wpb=1980.8, bsz=64, num_updates=22840, lr=3.85718e-06, gnorm=7.378, clip=100, loss_scale=32, train_wall=40, gb_free=8, wall=92379
2023-05-09 01:36:18 - progress_bar.py[line:272] - INFO: epoch 027:    377 / 866 loss=2.033, loss_v1=0, loss_v2=0, nll_loss=0.791, ntokens=2127.1, nsentences=64, sample_size=2127.1, sample_size_v1=0, sample_size_v2=0, ppl=1.73, wps=528.2, ups=0.25, wpb=2127.1, bsz=64, num_updates=22850, lr=3.84489e-06, gnorm=6.459, clip=100, loss_scale=32, train_wall=40, gb_free=7.5, wall=92420
2023-05-09 01:36:59 - progress_bar.py[line:272] - INFO: epoch 027:    387 / 866 loss=2.034, loss_v1=0, loss_v2=0, nll_loss=0.792, ntokens=2166.8, nsentences=64, sample_size=2166.8, sample_size_v1=0, sample_size_v2=0, ppl=1.73, wps=538.6, ups=0.25, wpb=2166.8, bsz=64, num_updates=22860, lr=3.83261e-06, gnorm=6.676, clip=100, loss_scale=32, train_wall=40, gb_free=7.9, wall=92460
2023-05-09 01:37:39 - progress_bar.py[line:272] - INFO: epoch 027:    397 / 866 loss=2.033, loss_v1=0, loss_v2=0, nll_loss=0.789, ntokens=2016.2, nsentences=64, sample_size=2016.2, sample_size_v1=0, sample_size_v2=0, ppl=1.73, wps=501.2, ups=0.25, wpb=2016.2, bsz=64, num_updates=22870, lr=3.82033e-06, gnorm=7.278, clip=100, loss_scale=32, train_wall=40, gb_free=7.4, wall=92500
2023-05-09 01:38:19 - progress_bar.py[line:272] - INFO: epoch 027:    407 / 866 loss=2.032, loss_v1=0, loss_v2=0, nll_loss=0.79, ntokens=2083.1, nsentences=64, sample_size=2083.1, sample_size_v1=0, sample_size_v2=0, ppl=1.73, wps=518, ups=0.25, wpb=2083.1, bsz=64, num_updates=22880, lr=3.80804e-06, gnorm=6.37, clip=100, loss_scale=32, train_wall=40, gb_free=7.4, wall=92540
2023-05-09 01:38:59 - progress_bar.py[line:272] - INFO: epoch 027:    417 / 866 loss=2.017, loss_v1=0, loss_v2=0, nll_loss=0.772, ntokens=2117.4, nsentences=64, sample_size=2117.4, sample_size_v1=0, sample_size_v2=0, ppl=1.71, wps=528.9, ups=0.25, wpb=2117.4, bsz=64, num_updates=22890, lr=3.79576e-06, gnorm=6.635, clip=100, loss_scale=32, train_wall=40, gb_free=8.1, wall=92580
2023-05-09 01:39:39 - progress_bar.py[line:272] - INFO: epoch 027:    427 / 866 loss=2.005, loss_v1=0, loss_v2=0, nll_loss=0.759, ntokens=2086.1, nsentences=64, sample_size=2086.1, sample_size_v1=0, sample_size_v2=0, ppl=1.69, wps=520.2, ups=0.25, wpb=2086.1, bsz=64, num_updates=22900, lr=3.78347e-06, gnorm=5.95, clip=100, loss_scale=32, train_wall=40, gb_free=7.6, wall=92620
2023-05-09 01:40:19 - progress_bar.py[line:272] - INFO: epoch 027:    437 / 866 loss=2.04, loss_v1=0, loss_v2=0, nll_loss=0.798, ntokens=2130.3, nsentences=64, sample_size=2130.3, sample_size_v1=0, sample_size_v2=0, ppl=1.74, wps=532, ups=0.25, wpb=2130.3, bsz=64, num_updates=22910, lr=3.77119e-06, gnorm=6.732, clip=100, loss_scale=32, train_wall=40, gb_free=8, wall=92660
2023-05-09 01:40:59 - progress_bar.py[line:272] - INFO: epoch 027:    447 / 866 loss=2.053, loss_v1=0, loss_v2=0, nll_loss=0.812, ntokens=2002.9, nsentences=64, sample_size=2002.9, sample_size_v1=0, sample_size_v2=0, ppl=1.76, wps=500, ups=0.25, wpb=2002.9, bsz=64, num_updates=22920, lr=3.75891e-06, gnorm=7.014, clip=100, loss_scale=32, train_wall=40, gb_free=7.2, wall=92700
2023-05-09 01:41:40 - progress_bar.py[line:272] - INFO: epoch 027:    457 / 866 loss=2.038, loss_v1=0, loss_v2=0, nll_loss=0.795, ntokens=2062.3, nsentences=64, sample_size=2062.3, sample_size_v1=0, sample_size_v2=0, ppl=1.74, wps=512.7, ups=0.25, wpb=2062.3, bsz=64, num_updates=22930, lr=3.74662e-06, gnorm=6.531, clip=100, loss_scale=32, train_wall=40, gb_free=6.8, wall=92741
2023-05-09 01:42:20 - progress_bar.py[line:272] - INFO: epoch 027:    467 / 866 loss=2.042, loss_v1=0, loss_v2=0, nll_loss=0.8, ntokens=2158.4, nsentences=64, sample_size=2158.4, sample_size_v1=0, sample_size_v2=0, ppl=1.74, wps=537.7, ups=0.25, wpb=2158.4, bsz=64, num_updates=22940, lr=3.73434e-06, gnorm=6.37, clip=100, loss_scale=32, train_wall=40, gb_free=7.4, wall=92781
2023-05-09 01:43:00 - progress_bar.py[line:272] - INFO: epoch 027:    477 / 866 loss=2.052, loss_v1=0, loss_v2=0, nll_loss=0.812, ntokens=2238.4, nsentences=64, sample_size=2238.4, sample_size_v1=0, sample_size_v2=0, ppl=1.76, wps=552.4, ups=0.25, wpb=2238.4, bsz=64, num_updates=22950, lr=3.72205e-06, gnorm=6.848, clip=100, loss_scale=32, train_wall=40, gb_free=8.2, wall=92821
2023-05-09 01:43:40 - progress_bar.py[line:272] - INFO: epoch 027:    487 / 866 loss=2.025, loss_v1=0, loss_v2=0, nll_loss=0.782, ntokens=2060.3, nsentences=64, sample_size=2060.3, sample_size_v1=0, sample_size_v2=0, ppl=1.72, wps=513.5, ups=0.25, wpb=2060.3, bsz=64, num_updates=22960, lr=3.70977e-06, gnorm=6.535, clip=100, loss_scale=32, train_wall=40, gb_free=8.4, wall=92861
2023-05-09 01:44:21 - progress_bar.py[line:272] - INFO: epoch 027:    497 / 866 loss=2.016, loss_v1=0, loss_v2=0, nll_loss=0.772, ntokens=2048.4, nsentences=64, sample_size=2048.4, sample_size_v1=0, sample_size_v2=0, ppl=1.71, wps=509.8, ups=0.25, wpb=2048.4, bsz=64, num_updates=22970, lr=3.69749e-06, gnorm=6.487, clip=100, loss_scale=32, train_wall=40, gb_free=7.2, wall=92902
2023-05-09 01:45:01 - progress_bar.py[line:272] - INFO: epoch 027:    507 / 866 loss=2.039, loss_v1=0, loss_v2=0, nll_loss=0.798, ntokens=2101.5, nsentences=64, sample_size=2101.5, sample_size_v1=0, sample_size_v2=0, ppl=1.74, wps=524.5, ups=0.25, wpb=2101.5, bsz=64, num_updates=22980, lr=3.6852e-06, gnorm=6.817, clip=100, loss_scale=32, train_wall=40, gb_free=7.6, wall=92942
2023-05-09 01:45:41 - progress_bar.py[line:272] - INFO: epoch 027:    517 / 866 loss=2.052, loss_v1=0, loss_v2=0, nll_loss=0.81, ntokens=2207.3, nsentences=64, sample_size=2207.3, sample_size_v1=0, sample_size_v2=0, ppl=1.75, wps=551.9, ups=0.25, wpb=2207.3, bsz=64, num_updates=22990, lr=3.67292e-06, gnorm=6.794, clip=100, loss_scale=32, train_wall=40, gb_free=8.1, wall=92982
2023-05-09 01:46:20 - progress_bar.py[line:272] - INFO: epoch 027:    527 / 866 loss=2.029, loss_v1=0, loss_v2=0, nll_loss=0.785, ntokens=1979.5, nsentences=64, sample_size=1979.5, sample_size_v1=0, sample_size_v2=0, ppl=1.72, wps=498.6, ups=0.25, wpb=1979.5, bsz=64, num_updates=23000, lr=3.66063e-06, gnorm=7.285, clip=100, loss_scale=32, train_wall=40, gb_free=8.2, wall=93021
2023-05-09 01:47:00 - progress_bar.py[line:272] - INFO: epoch 027:    537 / 866 loss=2.02, loss_v1=0, loss_v2=0, nll_loss=0.774, ntokens=2105, nsentences=64, sample_size=2105, sample_size_v1=0, sample_size_v2=0, ppl=1.71, wps=526.3, ups=0.25, wpb=2105, bsz=64, num_updates=23010, lr=3.64835e-06, gnorm=6.255, clip=100, loss_scale=32, train_wall=40, gb_free=8.1, wall=93061
2023-05-09 01:47:41 - progress_bar.py[line:272] - INFO: epoch 027:    547 / 866 loss=2.046, loss_v1=0, loss_v2=0, nll_loss=0.804, ntokens=2281.5, nsentences=64, sample_size=2281.5, sample_size_v1=0, sample_size_v2=0, ppl=1.75, wps=564, ups=0.25, wpb=2281.5, bsz=64, num_updates=23020, lr=3.63607e-06, gnorm=6.125, clip=100, loss_scale=32, train_wall=40, gb_free=7.6, wall=93102
2023-05-09 01:48:22 - progress_bar.py[line:272] - INFO: epoch 027:    557 / 866 loss=2.05, loss_v1=0, loss_v2=0, nll_loss=0.81, ntokens=2288, nsentences=64, sample_size=2288, sample_size_v1=0, sample_size_v2=0, ppl=1.75, wps=561.5, ups=0.25, wpb=2288, bsz=64, num_updates=23030, lr=3.62378e-06, gnorm=5.766, clip=100, loss_scale=32, train_wall=41, gb_free=8.1, wall=93143
2023-05-09 01:49:02 - progress_bar.py[line:272] - INFO: epoch 027:    567 / 866 loss=2.034, loss_v1=0, loss_v2=0, nll_loss=0.792, ntokens=2212.7, nsentences=64, sample_size=2212.7, sample_size_v1=0, sample_size_v2=0, ppl=1.73, wps=552.2, ups=0.25, wpb=2212.7, bsz=64, num_updates=23040, lr=3.6115e-06, gnorm=6.119, clip=100, loss_scale=32, train_wall=40, gb_free=8.1, wall=93183
2023-05-09 01:49:42 - progress_bar.py[line:272] - INFO: epoch 027:    577 / 866 loss=2.025, loss_v1=0, loss_v2=0, nll_loss=0.782, ntokens=2143.4, nsentences=64, sample_size=2143.4, sample_size_v1=0, sample_size_v2=0, ppl=1.72, wps=534, ups=0.25, wpb=2143.4, bsz=64, num_updates=23050, lr=3.59921e-06, gnorm=6.195, clip=100, loss_scale=32, train_wall=40, gb_free=8.1, wall=93223
2023-05-09 01:50:22 - progress_bar.py[line:272] - INFO: epoch 027:    587 / 866 loss=2.059, loss_v1=0, loss_v2=0, nll_loss=0.82, ntokens=2086.5, nsentences=64, sample_size=2086.5, sample_size_v1=0, sample_size_v2=0, ppl=1.77, wps=516.3, ups=0.25, wpb=2086.5, bsz=64, num_updates=23060, lr=3.58693e-06, gnorm=6.612, clip=100, loss_scale=32, train_wall=40, gb_free=8.4, wall=93263
2023-05-09 01:51:03 - progress_bar.py[line:272] - INFO: epoch 027:    597 / 866 loss=2.008, loss_v1=0, loss_v2=0, nll_loss=0.762, ntokens=2154.7, nsentences=64, sample_size=2154.7, sample_size_v1=0, sample_size_v2=0, ppl=1.7, wps=531.3, ups=0.25, wpb=2154.7, bsz=64, num_updates=23070, lr=3.57465e-06, gnorm=6.018, clip=100, loss_scale=32, train_wall=41, gb_free=7.7, wall=93304
2023-05-09 01:51:43 - progress_bar.py[line:272] - INFO: epoch 027:    607 / 866 loss=2.028, loss_v1=0, loss_v2=0, nll_loss=0.784, ntokens=2011.2, nsentences=64, sample_size=2011.2, sample_size_v1=0, sample_size_v2=0, ppl=1.72, wps=501.9, ups=0.25, wpb=2011.2, bsz=64, num_updates=23080, lr=3.56236e-06, gnorm=6.807, clip=100, loss_scale=32, train_wall=40, gb_free=7.3, wall=93344
2023-05-09 01:52:23 - progress_bar.py[line:272] - INFO: epoch 027:    617 / 866 loss=2.047, loss_v1=0, loss_v2=0, nll_loss=0.806, ntokens=1941.8, nsentences=64, sample_size=1941.8, sample_size_v1=0, sample_size_v2=0, ppl=1.75, wps=486.8, ups=0.25, wpb=1941.8, bsz=64, num_updates=23090, lr=3.55008e-06, gnorm=7.44, clip=100, loss_scale=32, train_wall=40, gb_free=7.8, wall=93384
2023-05-09 01:53:03 - progress_bar.py[line:272] - INFO: epoch 027:    627 / 866 loss=2.04, loss_v1=0, loss_v2=0, nll_loss=0.798, ntokens=2052.9, nsentences=64, sample_size=2052.9, sample_size_v1=0, sample_size_v2=0, ppl=1.74, wps=511.2, ups=0.25, wpb=2052.9, bsz=64, num_updates=23100, lr=3.53779e-06, gnorm=6.975, clip=100, loss_scale=32, train_wall=40, gb_free=8.2, wall=93424
2023-05-09 01:53:43 - progress_bar.py[line:272] - INFO: epoch 027:    637 / 866 loss=2.026, loss_v1=0, loss_v2=0, nll_loss=0.782, ntokens=2035.5, nsentences=64, sample_size=2035.5, sample_size_v1=0, sample_size_v2=0, ppl=1.72, wps=508.7, ups=0.25, wpb=2035.5, bsz=64, num_updates=23110, lr=3.52551e-06, gnorm=7.13, clip=100, loss_scale=64, train_wall=40, gb_free=8, wall=93464
2023-05-09 01:54:23 - progress_bar.py[line:272] - INFO: epoch 027:    647 / 866 loss=2.039, loss_v1=0, loss_v2=0, nll_loss=0.798, ntokens=2063.3, nsentences=64, sample_size=2063.3, sample_size_v1=0, sample_size_v2=0, ppl=1.74, wps=517.4, ups=0.25, wpb=2063.3, bsz=64, num_updates=23120, lr=3.51323e-06, gnorm=7.068, clip=100, loss_scale=64, train_wall=40, gb_free=8.2, wall=93504
2023-05-09 01:55:03 - progress_bar.py[line:272] - INFO: epoch 027:    657 / 866 loss=2.05, loss_v1=0, loss_v2=0, nll_loss=0.809, ntokens=1895.4, nsentences=64, sample_size=1895.4, sample_size_v1=0, sample_size_v2=0, ppl=1.75, wps=476.6, ups=0.25, wpb=1895.4, bsz=64, num_updates=23130, lr=3.50094e-06, gnorm=7.394, clip=100, loss_scale=64, train_wall=40, gb_free=7.9, wall=93544
2023-05-09 01:55:43 - progress_bar.py[line:272] - INFO: epoch 027:    667 / 866 loss=2.048, loss_v1=0, loss_v2=0, nll_loss=0.806, ntokens=2004.3, nsentences=64, sample_size=2004.3, sample_size_v1=0, sample_size_v2=0, ppl=1.75, wps=500.6, ups=0.25, wpb=2004.3, bsz=64, num_updates=23140, lr=3.48866e-06, gnorm=7.034, clip=100, loss_scale=64, train_wall=40, gb_free=7.8, wall=93584
2023-05-09 01:56:23 - progress_bar.py[line:272] - INFO: epoch 027:    677 / 866 loss=2.035, loss_v1=0, loss_v2=0, nll_loss=0.792, ntokens=2088.4, nsentences=64, sample_size=2088.4, sample_size_v1=0, sample_size_v2=0, ppl=1.73, wps=521.8, ups=0.25, wpb=2088.4, bsz=64, num_updates=23150, lr=3.47637e-06, gnorm=6.454, clip=100, loss_scale=64, train_wall=40, gb_free=8.1, wall=93624
2023-05-09 01:57:03 - progress_bar.py[line:272] - INFO: epoch 027:    687 / 866 loss=2.031, loss_v1=0, loss_v2=0, nll_loss=0.788, ntokens=1980.4, nsentences=64, sample_size=1980.4, sample_size_v1=0, sample_size_v2=0, ppl=1.73, wps=495, ups=0.25, wpb=1980.4, bsz=64, num_updates=23160, lr=3.46409e-06, gnorm=6.853, clip=100, loss_scale=64, train_wall=40, gb_free=8.4, wall=93664
2023-05-09 01:57:43 - progress_bar.py[line:272] - INFO: epoch 027:    697 / 866 loss=2.056, loss_v1=0, loss_v2=0, nll_loss=0.816, ntokens=2133.2, nsentences=64, sample_size=2133.2, sample_size_v1=0, sample_size_v2=0, ppl=1.76, wps=528.1, ups=0.25, wpb=2133.2, bsz=64, num_updates=23170, lr=3.45181e-06, gnorm=6.74, clip=100, loss_scale=64, train_wall=40, gb_free=7.1, wall=93704
2023-05-09 01:58:23 - progress_bar.py[line:272] - INFO: epoch 027:    707 / 866 loss=2.044, loss_v1=0, loss_v2=0, nll_loss=0.802, ntokens=1972.1, nsentences=64, sample_size=1972.1, sample_size_v1=0, sample_size_v2=0, ppl=1.74, wps=494.3, ups=0.25, wpb=1972.1, bsz=64, num_updates=23180, lr=3.43952e-06, gnorm=6.891, clip=100, loss_scale=64, train_wall=40, gb_free=8.2, wall=93744
2023-05-09 01:59:03 - progress_bar.py[line:272] - INFO: epoch 027:    717 / 866 loss=2.036, loss_v1=0, loss_v2=0, nll_loss=0.794, ntokens=1886.4, nsentences=64, sample_size=1886.4, sample_size_v1=0, sample_size_v2=0, ppl=1.73, wps=472.6, ups=0.25, wpb=1886.4, bsz=64, num_updates=23190, lr=3.42724e-06, gnorm=7.277, clip=100, loss_scale=64, train_wall=40, gb_free=8, wall=93784
2023-05-09 01:59:43 - progress_bar.py[line:272] - INFO: epoch 027:    727 / 866 loss=2.014, loss_v1=0, loss_v2=0, nll_loss=0.768, ntokens=1984.1, nsentences=64, sample_size=1984.1, sample_size_v1=0, sample_size_v2=0, ppl=1.7, wps=497.3, ups=0.25, wpb=1984.1, bsz=64, num_updates=23200, lr=3.41495e-06, gnorm=6.729, clip=100, loss_scale=64, train_wall=40, gb_free=8.3, wall=93824
2023-05-09 02:00:23 - progress_bar.py[line:272] - INFO: epoch 027:    737 / 866 loss=2.022, loss_v1=0, loss_v2=0, nll_loss=0.778, ntokens=2105.3, nsentences=64, sample_size=2105.3, sample_size_v1=0, sample_size_v2=0, ppl=1.71, wps=525.3, ups=0.25, wpb=2105.3, bsz=64, num_updates=23210, lr=3.40267e-06, gnorm=6.357, clip=100, loss_scale=64, train_wall=40, gb_free=7.8, wall=93864
2023-05-09 02:01:03 - progress_bar.py[line:272] - INFO: epoch 027:    747 / 866 loss=2.017, loss_v1=0, loss_v2=0, nll_loss=0.773, ntokens=2126.6, nsentences=64, sample_size=2126.6, sample_size_v1=0, sample_size_v2=0, ppl=1.71, wps=529.7, ups=0.25, wpb=2126.6, bsz=64, num_updates=23220, lr=3.39039e-06, gnorm=6.518, clip=100, loss_scale=64, train_wall=40, gb_free=7.5, wall=93904
2023-05-09 02:01:43 - progress_bar.py[line:272] - INFO: epoch 027:    757 / 866 loss=2.021, loss_v1=0, loss_v2=0, nll_loss=0.778, ntokens=2055.9, nsentences=64, sample_size=2055.9, sample_size_v1=0, sample_size_v2=0, ppl=1.71, wps=512.5, ups=0.25, wpb=2055.9, bsz=64, num_updates=23230, lr=3.3781e-06, gnorm=6.892, clip=100, loss_scale=64, train_wall=40, gb_free=7.9, wall=93944
2023-05-09 02:02:23 - progress_bar.py[line:272] - INFO: epoch 027:    767 / 866 loss=2.023, loss_v1=0, loss_v2=0, nll_loss=0.779, ntokens=2104.6, nsentences=64, sample_size=2104.6, sample_size_v1=0, sample_size_v2=0, ppl=1.72, wps=525.4, ups=0.25, wpb=2104.6, bsz=64, num_updates=23240, lr=3.36582e-06, gnorm=6.215, clip=100, loss_scale=64, train_wall=40, gb_free=8.3, wall=93984
2023-05-09 02:03:03 - progress_bar.py[line:272] - INFO: epoch 027:    777 / 866 loss=2.039, loss_v1=0, loss_v2=0, nll_loss=0.797, ntokens=2258.8, nsentences=64, sample_size=2258.8, sample_size_v1=0, sample_size_v2=0, ppl=1.74, wps=562.2, ups=0.25, wpb=2258.8, bsz=64, num_updates=23250, lr=3.35353e-06, gnorm=6.328, clip=100, loss_scale=64, train_wall=40, gb_free=7.9, wall=94024
2023-05-09 02:03:43 - progress_bar.py[line:272] - INFO: epoch 027:    787 / 866 loss=2.038, loss_v1=0, loss_v2=0, nll_loss=0.796, ntokens=2038.1, nsentences=64, sample_size=2038.1, sample_size_v1=0, sample_size_v2=0, ppl=1.74, wps=511, ups=0.25, wpb=2038.1, bsz=64, num_updates=23260, lr=3.34125e-06, gnorm=6.756, clip=100, loss_scale=64, train_wall=40, gb_free=7.7, wall=94064
2023-05-09 02:04:23 - progress_bar.py[line:272] - INFO: epoch 027:    797 / 866 loss=2.044, loss_v1=0, loss_v2=0, nll_loss=0.803, ntokens=2084.7, nsentences=64, sample_size=2084.7, sample_size_v1=0, sample_size_v2=0, ppl=1.74, wps=521.5, ups=0.25, wpb=2084.7, bsz=64, num_updates=23270, lr=3.32897e-06, gnorm=6.587, clip=100, loss_scale=64, train_wall=40, gb_free=7.9, wall=94104
2023-05-09 02:05:03 - progress_bar.py[line:272] - INFO: epoch 027:    807 / 866 loss=2.019, loss_v1=0, loss_v2=0, nll_loss=0.774, ntokens=1945.9, nsentences=64, sample_size=1945.9, sample_size_v1=0, sample_size_v2=0, ppl=1.71, wps=489.8, ups=0.25, wpb=1945.9, bsz=64, num_updates=23280, lr=3.31668e-06, gnorm=6.852, clip=100, loss_scale=64, train_wall=40, gb_free=7.8, wall=94144
2023-05-09 02:05:43 - progress_bar.py[line:272] - INFO: epoch 027:    817 / 866 loss=2.014, loss_v1=0, loss_v2=0, nll_loss=0.769, ntokens=2085.3, nsentences=64, sample_size=2085.3, sample_size_v1=0, sample_size_v2=0, ppl=1.7, wps=519.1, ups=0.25, wpb=2085.3, bsz=64, num_updates=23290, lr=3.3044e-06, gnorm=6.659, clip=100, loss_scale=64, train_wall=40, gb_free=8, wall=94184
2023-05-09 02:06:24 - progress_bar.py[line:272] - INFO: epoch 027:    827 / 866 loss=2.006, loss_v1=0, loss_v2=0, nll_loss=0.759, ntokens=2163, nsentences=64, sample_size=2163, sample_size_v1=0, sample_size_v2=0, ppl=1.69, wps=533.4, ups=0.25, wpb=2163, bsz=64, num_updates=23300, lr=3.29211e-06, gnorm=6.435, clip=100, loss_scale=64, train_wall=41, gb_free=8.1, wall=94225
2023-05-09 02:07:04 - progress_bar.py[line:272] - INFO: epoch 027:    837 / 866 loss=2.019, loss_v1=0, loss_v2=0, nll_loss=0.774, ntokens=2161.7, nsentences=64, sample_size=2161.7, sample_size_v1=0, sample_size_v2=0, ppl=1.71, wps=531.7, ups=0.25, wpb=2161.7, bsz=64, num_updates=23310, lr=3.27983e-06, gnorm=6.577, clip=100, loss_scale=64, train_wall=41, gb_free=8.2, wall=94265
2023-05-09 02:07:44 - progress_bar.py[line:272] - INFO: epoch 027:    847 / 866 loss=2.008, loss_v1=0, loss_v2=0, nll_loss=0.762, ntokens=2168.3, nsentences=64, sample_size=2168.3, sample_size_v1=0, sample_size_v2=0, ppl=1.7, wps=539.6, ups=0.25, wpb=2168.3, bsz=64, num_updates=23320, lr=3.26755e-06, gnorm=6.525, clip=100, loss_scale=64, train_wall=40, gb_free=6.9, wall=94306
2023-05-09 02:08:25 - progress_bar.py[line:272] - INFO: epoch 027:    857 / 866 loss=1.999, loss_v1=0, loss_v2=0, nll_loss=0.753, ntokens=2080.9, nsentences=64, sample_size=2080.9, sample_size_v1=0, sample_size_v2=0, ppl=1.69, wps=517.4, ups=0.25, wpb=2080.9, bsz=64, num_updates=23330, lr=3.25526e-06, gnorm=6.391, clip=100, loss_scale=64, train_wall=40, gb_free=7.8, wall=94346
2023-05-09 02:08:59 - train.py[line:332] - INFO: end of epoch 27 (average epoch stats below)
local datafile ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 1 begin to initialize row_count and line_idx-to-offset mapping
2023-05-09 02:08:59 - progress_bar.py[line:282] - INFO: epoch 027 | loss 2.023 | loss_v1 0 | loss_v2 0 | nll_loss 0.779 | ntokens 2102.95 | nsentences 63.972 | sample_size 2102.95 | sample_size_v1 0 | sample_size_v2 0 | ppl 1.72 | wps 521 | ups 0.25 | wpb 2102.9 | bsz 64 | num_updates 23339 | lr 3.24421e-06 | gnorm 6.638 | clip 100 | loss_scale 64 | train_wall 3485 | gb_free 8.7 | wall 94380
2023-05-09 02:08:59 - trainer.py[line:639] - INFO: loading train data for epoch 28
local datafile ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 0 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 0 finished initializing row_count and line_idx-to-offset mappinglocal datafile ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 1 finished initializing row_count and line_idx-to-offset mapping

file ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 1 row count 27700 total row count 55400
file ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 0 row count 27700 total row count 55400
slice_id 1 seek offset 27700
slice_id 0 seek offset 0
2023-05-09 02:09:01 - trainer.py[line:703] - INFO: begin training epoch 28
2023-05-09 02:09:01 - train.py[line:305] - INFO: Start iterating over samples
2023-05-09 02:09:05 - progress_bar.py[line:272] - INFO: epoch 028:      1 / 866 loss=2.051, loss_v1=0, loss_v2=0, nll_loss=0.812, ntokens=2052.4, nsentences=61.6, sample_size=2052.4, sample_size_v1=0, sample_size_v2=0, ppl=1.76, wps=503.6, ups=0.25, wpb=2052.4, bsz=61.6, num_updates=23340, lr=3.24298e-06, gnorm=6.545, clip=100, loss_scale=64, train_wall=39, gb_free=7.6, wall=94387
2023-05-09 02:09:46 - progress_bar.py[line:272] - INFO: epoch 028:     11 / 866 loss=1.994, loss_v1=0, loss_v2=0, nll_loss=0.746, ntokens=2113.9, nsentences=64, sample_size=2113.9, sample_size_v1=0, sample_size_v2=0, ppl=1.68, wps=521.6, ups=0.25, wpb=2113.9, bsz=64, num_updates=23350, lr=3.23069e-06, gnorm=6.752, clip=100, loss_scale=64, train_wall=40, gb_free=7.8, wall=94427
2023-05-09 02:10:26 - progress_bar.py[line:272] - INFO: epoch 028:     21 / 866 loss=1.984, loss_v1=0, loss_v2=0, nll_loss=0.736, ntokens=2073.7, nsentences=64, sample_size=2073.7, sample_size_v1=0, sample_size_v2=0, ppl=1.67, wps=514.2, ups=0.25, wpb=2073.7, bsz=64, num_updates=23360, lr=3.21841e-06, gnorm=6.845, clip=100, loss_scale=64, train_wall=40, gb_free=7.5, wall=94467
2023-05-09 02:11:07 - progress_bar.py[line:272] - INFO: epoch 028:     31 / 866 loss=1.981, loss_v1=0, loss_v2=0, nll_loss=0.732, ntokens=1996.7, nsentences=64, sample_size=1996.7, sample_size_v1=0, sample_size_v2=0, ppl=1.66, wps=495.3, ups=0.25, wpb=1996.7, bsz=64, num_updates=23370, lr=3.20613e-06, gnorm=6.934, clip=100, loss_scale=64, train_wall=40, gb_free=7.4, wall=94508
2023-05-09 02:11:48 - progress_bar.py[line:272] - INFO: epoch 028:     41 / 866 loss=1.942, loss_v1=0, loss_v2=0, nll_loss=0.688, ntokens=2234.3, nsentences=64, sample_size=2234.3, sample_size_v1=0, sample_size_v2=0, ppl=1.61, wps=544.6, ups=0.24, wpb=2234.3, bsz=64, num_updates=23380, lr=3.19384e-06, gnorm=6.484, clip=100, loss_scale=64, train_wall=41, gb_free=7.2, wall=94549
2023-05-09 02:12:28 - progress_bar.py[line:272] - INFO: epoch 028:     51 / 866 loss=1.982, loss_v1=0, loss_v2=0, nll_loss=0.732, ntokens=1960.1, nsentences=64, sample_size=1960.1, sample_size_v1=0, sample_size_v2=0, ppl=1.66, wps=486.1, ups=0.25, wpb=1960.1, bsz=64, num_updates=23390, lr=3.18156e-06, gnorm=7.197, clip=100, loss_scale=64, train_wall=40, gb_free=7.5, wall=94589
2023-05-09 02:13:09 - progress_bar.py[line:272] - INFO: epoch 028:     61 / 866 loss=1.909, loss_v1=0, loss_v2=0, nll_loss=0.65, ntokens=2153.5, nsentences=64, sample_size=2153.5, sample_size_v1=0, sample_size_v2=0, ppl=1.57, wps=531.8, ups=0.25, wpb=2153.5, bsz=64, num_updates=23400, lr=3.16927e-06, gnorm=6.4, clip=100, loss_scale=64, train_wall=40, gb_free=6.3, wall=94630
2023-05-09 02:13:50 - progress_bar.py[line:272] - INFO: epoch 028:     71 / 866 loss=1.925, loss_v1=0, loss_v2=0, nll_loss=0.668, ntokens=2421, nsentences=64, sample_size=2421, sample_size_v1=0, sample_size_v2=0, ppl=1.59, wps=580.7, ups=0.24, wpb=2421, bsz=64, num_updates=23410, lr=3.15699e-06, gnorm=5.663, clip=100, loss_scale=64, train_wall=42, gb_free=6.2, wall=94671
2023-05-09 02:14:32 - progress_bar.py[line:272] - INFO: epoch 028:     81 / 866 loss=1.965, loss_v1=0, loss_v2=0, nll_loss=0.714, ntokens=2316.3, nsentences=64, sample_size=2316.3, sample_size_v1=0, sample_size_v2=0, ppl=1.64, wps=560.4, ups=0.24, wpb=2316.3, bsz=64, num_updates=23420, lr=3.14471e-06, gnorm=6.901, clip=100, loss_scale=64, train_wall=41, gb_free=7.6, wall=94713
2023-05-09 02:15:12 - progress_bar.py[line:272] - INFO: epoch 028:     91 / 866 loss=1.98, loss_v1=0, loss_v2=0, nll_loss=0.733, ntokens=2094.9, nsentences=64, sample_size=2094.9, sample_size_v1=0, sample_size_v2=0, ppl=1.66, wps=514.2, ups=0.25, wpb=2094.9, bsz=64, num_updates=23430, lr=3.13242e-06, gnorm=6.744, clip=100, loss_scale=64, train_wall=41, gb_free=7.7, wall=94753
2023-05-09 02:15:53 - progress_bar.py[line:272] - INFO: epoch 028:    101 / 866 loss=1.978, loss_v1=0, loss_v2=0, nll_loss=0.73, ntokens=2060.7, nsentences=64, sample_size=2060.7, sample_size_v1=0, sample_size_v2=0, ppl=1.66, wps=510.6, ups=0.25, wpb=2060.7, bsz=64, num_updates=23440, lr=3.12014e-06, gnorm=6.747, clip=100, loss_scale=64, train_wall=40, gb_free=7.2, wall=94794
2023-05-09 02:16:33 - progress_bar.py[line:272] - INFO: epoch 028:    111 / 866 loss=2.029, loss_v1=0, loss_v2=0, nll_loss=0.787, ntokens=2077.3, nsentences=64, sample_size=2077.3, sample_size_v1=0, sample_size_v2=0, ppl=1.73, wps=515, ups=0.25, wpb=2077.3, bsz=64, num_updates=23450, lr=3.10785e-06, gnorm=7.144, clip=100, loss_scale=64, train_wall=40, gb_free=7.5, wall=94834
2023-05-09 02:17:14 - progress_bar.py[line:272] - INFO: epoch 028:    121 / 866 loss=2.034, loss_v1=0, loss_v2=0, nll_loss=0.793, ntokens=2148.3, nsentences=64, sample_size=2148.3, sample_size_v1=0, sample_size_v2=0, ppl=1.73, wps=524.8, ups=0.24, wpb=2148.3, bsz=64, num_updates=23460, lr=3.09557e-06, gnorm=7.529, clip=100, loss_scale=64, train_wall=41, gb_free=7.3, wall=94875
2023-05-09 02:17:55 - progress_bar.py[line:272] - INFO: epoch 028:    131 / 866 loss=2.023, loss_v1=0, loss_v2=0, nll_loss=0.779, ntokens=2209, nsentences=64, sample_size=2209, sample_size_v1=0, sample_size_v2=0, ppl=1.72, wps=536.7, ups=0.24, wpb=2209, bsz=64, num_updates=23470, lr=3.08329e-06, gnorm=7.224, clip=100, loss_scale=64, train_wall=41, gb_free=7.4, wall=94916
2023-05-09 02:18:36 - progress_bar.py[line:272] - INFO: epoch 028:    141 / 866 loss=1.987, loss_v1=0, loss_v2=0, nll_loss=0.738, ntokens=2260.2, nsentences=64, sample_size=2260.2, sample_size_v1=0, sample_size_v2=0, ppl=1.67, wps=550.4, ups=0.24, wpb=2260.2, bsz=64, num_updates=23480, lr=3.071e-06, gnorm=6.229, clip=100, loss_scale=64, train_wall=41, gb_free=7.4, wall=94957
2023-05-09 02:19:18 - progress_bar.py[line:272] - INFO: epoch 028:    151 / 866 loss=1.994, loss_v1=0, loss_v2=0, nll_loss=0.746, ntokens=2183.5, nsentences=64, sample_size=2183.5, sample_size_v1=0, sample_size_v2=0, ppl=1.68, wps=527.8, ups=0.24, wpb=2183.5, bsz=64, num_updates=23490, lr=3.05872e-06, gnorm=6.589, clip=100, loss_scale=64, train_wall=41, gb_free=5.9, wall=94999
2023-05-09 02:19:58 - progress_bar.py[line:272] - INFO: epoch 028:    161 / 866 loss=2.016, loss_v1=0, loss_v2=0, nll_loss=0.771, ntokens=2170.1, nsentences=64, sample_size=2170.1, sample_size_v1=0, sample_size_v2=0, ppl=1.71, wps=529.9, ups=0.24, wpb=2170.1, bsz=64, num_updates=23500, lr=3.04643e-06, gnorm=6.856, clip=100, loss_scale=64, train_wall=41, gb_free=7.6, wall=95040
2023-05-09 02:20:39 - progress_bar.py[line:272] - INFO: epoch 028:    171 / 866 loss=2.012, loss_v1=0, loss_v2=0, nll_loss=0.767, ntokens=2098.8, nsentences=64, sample_size=2098.8, sample_size_v1=0, sample_size_v2=0, ppl=1.7, wps=519.8, ups=0.25, wpb=2098.8, bsz=64, num_updates=23510, lr=3.03415e-06, gnorm=7.238, clip=100, loss_scale=64, train_wall=40, gb_free=7.6, wall=95080
2023-05-09 02:21:20 - progress_bar.py[line:272] - INFO: epoch 028:    181 / 866 loss=2.006, loss_v1=0, loss_v2=0, nll_loss=0.76, ntokens=2149.7, nsentences=64, sample_size=2149.7, sample_size_v1=0, sample_size_v2=0, ppl=1.69, wps=523.9, ups=0.24, wpb=2149.7, bsz=64, num_updates=23520, lr=3.02187e-06, gnorm=7.101, clip=100, loss_scale=64, train_wall=41, gb_free=7.4, wall=95121
2023-05-09 02:22:01 - progress_bar.py[line:272] - INFO: epoch 028:    191 / 866 loss=2.006, loss_v1=0, loss_v2=0, nll_loss=0.76, ntokens=2205, nsentences=64, sample_size=2205, sample_size_v1=0, sample_size_v2=0, ppl=1.69, wps=537.5, ups=0.24, wpb=2205, bsz=64, num_updates=23530, lr=3.00958e-06, gnorm=6.996, clip=100, loss_scale=64, train_wall=41, gb_free=7.2, wall=95162
2023-05-09 02:22:42 - progress_bar.py[line:272] - INFO: epoch 028:    201 / 866 loss=2.021, loss_v1=0, loss_v2=0, nll_loss=0.777, ntokens=2106.8, nsentences=64, sample_size=2106.8, sample_size_v1=0, sample_size_v2=0, ppl=1.71, wps=517.7, ups=0.25, wpb=2106.8, bsz=64, num_updates=23540, lr=2.9973e-06, gnorm=7.21, clip=100, loss_scale=64, train_wall=41, gb_free=7.7, wall=95203
2023-05-09 02:23:22 - progress_bar.py[line:272] - INFO: epoch 028:    211 / 866 loss=2.034, loss_v1=0, loss_v2=0, nll_loss=0.792, ntokens=2003.5, nsentences=64, sample_size=2003.5, sample_size_v1=0, sample_size_v2=0, ppl=1.73, wps=497.1, ups=0.25, wpb=2003.5, bsz=64, num_updates=23550, lr=2.98501e-06, gnorm=6.983, clip=100, loss_scale=64, train_wall=40, gb_free=7.2, wall=95243
2023-05-09 02:24:02 - progress_bar.py[line:272] - INFO: epoch 028:    221 / 866 loss=2.03, loss_v1=0, loss_v2=0, nll_loss=0.787, ntokens=2219.2, nsentences=64, sample_size=2219.2, sample_size_v1=0, sample_size_v2=0, ppl=1.73, wps=551.6, ups=0.25, wpb=2219.2, bsz=64, num_updates=23560, lr=2.97273e-06, gnorm=6.254, clip=100, loss_scale=64, train_wall=40, gb_free=6.8, wall=95283
2023-05-09 02:24:42 - progress_bar.py[line:272] - INFO: epoch 028:    231 / 866 loss=2.031, loss_v1=0, loss_v2=0, nll_loss=0.789, ntokens=2133.9, nsentences=64, sample_size=2133.9, sample_size_v1=0, sample_size_v2=0, ppl=1.73, wps=532, ups=0.25, wpb=2133.9, bsz=64, num_updates=23570, lr=2.96045e-06, gnorm=6.334, clip=100, loss_scale=64, train_wall=40, gb_free=8, wall=95323
2023-05-09 02:25:23 - progress_bar.py[line:272] - INFO: epoch 028:    241 / 866 loss=2.041, loss_v1=0, loss_v2=0, nll_loss=0.8, ntokens=2186, nsentences=64, sample_size=2186, sample_size_v1=0, sample_size_v2=0, ppl=1.74, wps=541, ups=0.25, wpb=2186, bsz=64, num_updates=23580, lr=2.94816e-06, gnorm=6.717, clip=100, loss_scale=64, train_wall=40, gb_free=7.8, wall=95364
2023-05-09 02:26:03 - progress_bar.py[line:272] - INFO: epoch 028:    251 / 866 loss=2.033, loss_v1=0, loss_v2=0, nll_loss=0.79, ntokens=2114, nsentences=64, sample_size=2114, sample_size_v1=0, sample_size_v2=0, ppl=1.73, wps=519.9, ups=0.25, wpb=2114, bsz=64, num_updates=23590, lr=2.93588e-06, gnorm=6.685, clip=100, loss_scale=64, train_wall=41, gb_free=7.9, wall=95404
2023-05-09 02:26:43 - progress_bar.py[line:272] - INFO: epoch 028:    261 / 866 loss=2.045, loss_v1=0, loss_v2=0, nll_loss=0.804, ntokens=2157.6, nsentences=64, sample_size=2157.6, sample_size_v1=0, sample_size_v2=0, ppl=1.75, wps=537.9, ups=0.25, wpb=2157.6, bsz=64, num_updates=23600, lr=2.92359e-06, gnorm=6.499, clip=100, loss_scale=64, train_wall=40, gb_free=7.5, wall=95445
2023-05-09 02:27:24 - progress_bar.py[line:272] - INFO: epoch 028:    271 / 866 loss=2.021, loss_v1=0, loss_v2=0, nll_loss=0.775, ntokens=2130.4, nsentences=64, sample_size=2130.4, sample_size_v1=0, sample_size_v2=0, ppl=1.71, wps=529.7, ups=0.25, wpb=2130.4, bsz=64, num_updates=23610, lr=2.91131e-06, gnorm=6.461, clip=100, loss_scale=64, train_wall=40, gb_free=7.4, wall=95485
2023-05-09 02:27:56 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2023-05-09 02:28:08 - progress_bar.py[line:272] - INFO: epoch 028:    282 / 866 loss=2.047, loss_v1=0, loss_v2=0, nll_loss=0.805, ntokens=2173.1, nsentences=64, sample_size=2173.1, sample_size_v1=0, sample_size_v2=0, ppl=1.75, wps=491.6, ups=0.23, wpb=2173.1, bsz=64, num_updates=23620, lr=2.89903e-06, gnorm=6.716, clip=100, loss_scale=64, train_wall=44, gb_free=6.9, wall=95529
2023-05-09 02:28:48 - progress_bar.py[line:272] - INFO: epoch 028:    292 / 866 loss=2.018, loss_v1=0, loss_v2=0, nll_loss=0.773, ntokens=2121.1, nsentences=64, sample_size=2121.1, sample_size_v1=0, sample_size_v2=0, ppl=1.71, wps=528.6, ups=0.25, wpb=2121.1, bsz=64, num_updates=23630, lr=2.88674e-06, gnorm=6.778, clip=100, loss_scale=64, train_wall=40, gb_free=7.8, wall=95569
2023-05-09 02:29:28 - progress_bar.py[line:272] - INFO: epoch 028:    302 / 866 loss=2.024, loss_v1=0, loss_v2=0, nll_loss=0.779, ntokens=2135.1, nsentences=64, sample_size=2135.1, sample_size_v1=0, sample_size_v2=0, ppl=1.72, wps=532.2, ups=0.25, wpb=2135.1, bsz=64, num_updates=23640, lr=2.87446e-06, gnorm=6.442, clip=100, loss_scale=64, train_wall=40, gb_free=7.9, wall=95609
2023-05-09 02:30:08 - progress_bar.py[line:272] - INFO: epoch 028:    312 / 866 loss=2.014, loss_v1=0, loss_v2=0, nll_loss=0.769, ntokens=2131.6, nsentences=64, sample_size=2131.6, sample_size_v1=0, sample_size_v2=0, ppl=1.7, wps=530.4, ups=0.25, wpb=2131.6, bsz=64, num_updates=23650, lr=2.86217e-06, gnorm=6.565, clip=100, loss_scale=64, train_wall=40, gb_free=7.8, wall=95649
2023-05-09 02:30:48 - progress_bar.py[line:272] - INFO: epoch 028:    322 / 866 loss=2.043, loss_v1=0, loss_v2=0, nll_loss=0.802, ntokens=1957, nsentences=64, sample_size=1957, sample_size_v1=0, sample_size_v2=0, ppl=1.74, wps=490.7, ups=0.25, wpb=1957, bsz=64, num_updates=23660, lr=2.84989e-06, gnorm=7.158, clip=100, loss_scale=64, train_wall=40, gb_free=7.7, wall=95689
2023-05-09 02:31:28 - progress_bar.py[line:272] - INFO: epoch 028:    332 / 866 loss=2.02, loss_v1=0, loss_v2=0, nll_loss=0.776, ntokens=2161.6, nsentences=64, sample_size=2161.6, sample_size_v1=0, sample_size_v2=0, ppl=1.71, wps=539.5, ups=0.25, wpb=2161.6, bsz=64, num_updates=23670, lr=2.83761e-06, gnorm=6.818, clip=100, loss_scale=64, train_wall=40, gb_free=7.6, wall=95729
2023-05-09 02:32:08 - progress_bar.py[line:272] - INFO: epoch 028:    342 / 866 loss=2.004, loss_v1=0, loss_v2=0, nll_loss=0.758, ntokens=2014.9, nsentences=64, sample_size=2014.9, sample_size_v1=0, sample_size_v2=0, ppl=1.69, wps=502.9, ups=0.25, wpb=2014.9, bsz=64, num_updates=23680, lr=2.82532e-06, gnorm=6.581, clip=100, loss_scale=64, train_wall=40, gb_free=8.2, wall=95769
2023-05-09 02:32:48 - progress_bar.py[line:272] - INFO: epoch 028:    352 / 866 loss=2.045, loss_v1=0, loss_v2=0, nll_loss=0.804, ntokens=1958, nsentences=64, sample_size=1958, sample_size_v1=0, sample_size_v2=0, ppl=1.75, wps=491.7, ups=0.25, wpb=1958, bsz=64, num_updates=23690, lr=2.81304e-06, gnorm=7.501, clip=100, loss_scale=64, train_wall=40, gb_free=8.2, wall=95809
2023-05-09 02:33:28 - progress_bar.py[line:272] - INFO: epoch 028:    362 / 866 loss=2.051, loss_v1=0, loss_v2=0, nll_loss=0.81, ntokens=1964.4, nsentences=64, sample_size=1964.4, sample_size_v1=0, sample_size_v2=0, ppl=1.75, wps=493.3, ups=0.25, wpb=1964.4, bsz=64, num_updates=23700, lr=2.80075e-06, gnorm=7.309, clip=100, loss_scale=64, train_wall=40, gb_free=7.7, wall=95849
2023-05-09 02:34:08 - progress_bar.py[line:272] - INFO: epoch 028:    372 / 866 loss=2.032, loss_v1=0, loss_v2=0, nll_loss=0.789, ntokens=2038.1, nsentences=64, sample_size=2038.1, sample_size_v1=0, sample_size_v2=0, ppl=1.73, wps=508.9, ups=0.25, wpb=2038.1, bsz=64, num_updates=23710, lr=2.78847e-06, gnorm=6.995, clip=100, loss_scale=64, train_wall=40, gb_free=8, wall=95889
2023-05-09 02:34:48 - progress_bar.py[line:272] - INFO: epoch 028:    382 / 866 loss=2.02, loss_v1=0, loss_v2=0, nll_loss=0.776, ntokens=2164.2, nsentences=64, sample_size=2164.2, sample_size_v1=0, sample_size_v2=0, ppl=1.71, wps=539.1, ups=0.25, wpb=2164.2, bsz=64, num_updates=23720, lr=2.77619e-06, gnorm=6.347, clip=100, loss_scale=64, train_wall=40, gb_free=7.5, wall=95929
2023-05-09 02:35:28 - progress_bar.py[line:272] - INFO: epoch 028:    392 / 866 loss=2.044, loss_v1=0, loss_v2=0, nll_loss=0.803, ntokens=2067.8, nsentences=64, sample_size=2067.8, sample_size_v1=0, sample_size_v2=0, ppl=1.74, wps=518.1, ups=0.25, wpb=2067.8, bsz=64, num_updates=23730, lr=2.7639e-06, gnorm=7.133, clip=100, loss_scale=64, train_wall=40, gb_free=8.2, wall=95969
2023-05-09 02:36:08 - progress_bar.py[line:272] - INFO: epoch 028:    402 / 866 loss=2.031, loss_v1=0, loss_v2=0, nll_loss=0.787, ntokens=2036, nsentences=64, sample_size=2036, sample_size_v1=0, sample_size_v2=0, ppl=1.73, wps=506.5, ups=0.25, wpb=2036, bsz=64, num_updates=23740, lr=2.75162e-06, gnorm=6.633, clip=100, loss_scale=64, train_wall=40, gb_free=7.6, wall=96009
2023-05-09 02:36:48 - progress_bar.py[line:272] - INFO: epoch 028:    412 / 866 loss=2.03, loss_v1=0, loss_v2=0, nll_loss=0.787, ntokens=2161.9, nsentences=64, sample_size=2161.9, sample_size_v1=0, sample_size_v2=0, ppl=1.73, wps=540.1, ups=0.25, wpb=2161.9, bsz=64, num_updates=23750, lr=2.73933e-06, gnorm=6.638, clip=100, loss_scale=64, train_wall=40, gb_free=7.5, wall=96049
2023-05-09 02:37:29 - progress_bar.py[line:272] - INFO: epoch 028:    422 / 866 loss=2.004, loss_v1=0, loss_v2=0, nll_loss=0.758, ntokens=2082.2, nsentences=64, sample_size=2082.2, sample_size_v1=0, sample_size_v2=0, ppl=1.69, wps=518.5, ups=0.25, wpb=2082.2, bsz=64, num_updates=23760, lr=2.72705e-06, gnorm=6.825, clip=100, loss_scale=64, train_wall=40, gb_free=7.2, wall=96090
2023-05-09 02:38:09 - progress_bar.py[line:272] - INFO: epoch 028:    432 / 866 loss=2.014, loss_v1=0, loss_v2=0, nll_loss=0.77, ntokens=2104.8, nsentences=64, sample_size=2104.8, sample_size_v1=0, sample_size_v2=0, ppl=1.7, wps=525.6, ups=0.25, wpb=2104.8, bsz=64, num_updates=23770, lr=2.71477e-06, gnorm=6.764, clip=100, loss_scale=64, train_wall=40, gb_free=8.1, wall=96130
2023-05-09 02:38:49 - progress_bar.py[line:272] - INFO: epoch 028:    442 / 866 loss=2.048, loss_v1=0, loss_v2=0, nll_loss=0.808, ntokens=2064.2, nsentences=64, sample_size=2064.2, sample_size_v1=0, sample_size_v2=0, ppl=1.75, wps=513.9, ups=0.25, wpb=2064.2, bsz=64, num_updates=23780, lr=2.70248e-06, gnorm=7.058, clip=100, loss_scale=64, train_wall=40, gb_free=7.3, wall=96170
2023-05-09 02:39:29 - progress_bar.py[line:272] - INFO: epoch 028:    452 / 866 loss=2.036, loss_v1=0, loss_v2=0, nll_loss=0.794, ntokens=1981.6, nsentences=64, sample_size=1981.6, sample_size_v1=0, sample_size_v2=0, ppl=1.73, wps=495.5, ups=0.25, wpb=1981.6, bsz=64, num_updates=23790, lr=2.6902e-06, gnorm=7.283, clip=100, loss_scale=64, train_wall=40, gb_free=8.3, wall=96210
2023-05-09 02:40:09 - progress_bar.py[line:272] - INFO: epoch 028:    462 / 866 loss=2.046, loss_v1=0, loss_v2=0, nll_loss=0.804, ntokens=2192.3, nsentences=64, sample_size=2192.3, sample_size_v1=0, sample_size_v2=0, ppl=1.75, wps=544.4, ups=0.25, wpb=2192.3, bsz=64, num_updates=23800, lr=2.67791e-06, gnorm=6.985, clip=100, loss_scale=64, train_wall=40, gb_free=7.3, wall=96250
2023-05-09 02:40:49 - progress_bar.py[line:272] - INFO: epoch 028:    472 / 866 loss=2.047, loss_v1=0, loss_v2=0, nll_loss=0.805, ntokens=2142.5, nsentences=64, sample_size=2142.5, sample_size_v1=0, sample_size_v2=0, ppl=1.75, wps=533, ups=0.25, wpb=2142.5, bsz=64, num_updates=23810, lr=2.66563e-06, gnorm=7.158, clip=100, loss_scale=64, train_wall=40, gb_free=7.3, wall=96290
2023-05-09 02:41:30 - progress_bar.py[line:272] - INFO: epoch 028:    482 / 866 loss=2.027, loss_v1=0, loss_v2=0, nll_loss=0.783, ntokens=2178.2, nsentences=64, sample_size=2178.2, sample_size_v1=0, sample_size_v2=0, ppl=1.72, wps=540.2, ups=0.25, wpb=2178.2, bsz=64, num_updates=23820, lr=2.65335e-06, gnorm=6.474, clip=100, loss_scale=64, train_wall=40, gb_free=8.2, wall=96331
2023-05-09 02:42:10 - progress_bar.py[line:272] - INFO: epoch 028:    492 / 866 loss=2.014, loss_v1=0, loss_v2=0, nll_loss=0.768, ntokens=2054.4, nsentences=64, sample_size=2054.4, sample_size_v1=0, sample_size_v2=0, ppl=1.7, wps=513, ups=0.25, wpb=2054.4, bsz=64, num_updates=23830, lr=2.64106e-06, gnorm=6.778, clip=100, loss_scale=64, train_wall=40, gb_free=7.5, wall=96371
2023-05-09 02:42:50 - progress_bar.py[line:272] - INFO: epoch 028:    502 / 866 loss=2.03, loss_v1=0, loss_v2=0, nll_loss=0.787, ntokens=2074.9, nsentences=64, sample_size=2074.9, sample_size_v1=0, sample_size_v2=0, ppl=1.73, wps=518.9, ups=0.25, wpb=2074.9, bsz=64, num_updates=23840, lr=2.62878e-06, gnorm=7.283, clip=100, loss_scale=64, train_wall=40, gb_free=7.9, wall=96411
2023-05-09 02:43:30 - progress_bar.py[line:272] - INFO: epoch 028:    512 / 866 loss=2.058, loss_v1=0, loss_v2=0, nll_loss=0.819, ntokens=2141.6, nsentences=64, sample_size=2141.6, sample_size_v1=0, sample_size_v2=0, ppl=1.76, wps=535.6, ups=0.25, wpb=2141.6, bsz=64, num_updates=23850, lr=2.61649e-06, gnorm=7.424, clip=100, loss_scale=64, train_wall=40, gb_free=7, wall=96451
2023-05-09 02:44:10 - progress_bar.py[line:272] - INFO: epoch 028:    522 / 866 loss=2.021, loss_v1=0, loss_v2=0, nll_loss=0.777, ntokens=2127.1, nsentences=64, sample_size=2127.1, sample_size_v1=0, sample_size_v2=0, ppl=1.71, wps=531.8, ups=0.25, wpb=2127.1, bsz=64, num_updates=23860, lr=2.60421e-06, gnorm=6.34, clip=100, loss_scale=64, train_wall=40, gb_free=8.1, wall=96491
2023-05-09 02:44:49 - progress_bar.py[line:272] - INFO: epoch 028:    532 / 866 loss=2.018, loss_v1=0, loss_v2=0, nll_loss=0.774, ntokens=2031, nsentences=64, sample_size=2031, sample_size_v1=0, sample_size_v2=0, ppl=1.71, wps=509.5, ups=0.25, wpb=2031, bsz=64, num_updates=23870, lr=2.59193e-06, gnorm=6.42, clip=100, loss_scale=64, train_wall=40, gb_free=8.3, wall=96531
2023-05-09 02:45:30 - progress_bar.py[line:272] - INFO: epoch 028:    542 / 866 loss=2.037, loss_v1=0, loss_v2=0, nll_loss=0.794, ntokens=2149.8, nsentences=64, sample_size=2149.8, sample_size_v1=0, sample_size_v2=0, ppl=1.73, wps=533.9, ups=0.25, wpb=2149.8, bsz=64, num_updates=23880, lr=2.57964e-06, gnorm=6.496, clip=100, loss_scale=64, train_wall=40, gb_free=7.3, wall=96571
2023-05-09 02:46:10 - progress_bar.py[line:272] - INFO: epoch 028:    552 / 866 loss=2.045, loss_v1=0, loss_v2=0, nll_loss=0.803, ntokens=2323, nsentences=64, sample_size=2323, sample_size_v1=0, sample_size_v2=0, ppl=1.74, wps=575.5, ups=0.25, wpb=2323, bsz=64, num_updates=23890, lr=2.56736e-06, gnorm=6.08, clip=100, loss_scale=64, train_wall=40, gb_free=7.4, wall=96611
2023-05-09 02:46:50 - progress_bar.py[line:272] - INFO: epoch 028:    562 / 866 loss=2.04, loss_v1=0, loss_v2=0, nll_loss=0.797, ntokens=2243.9, nsentences=64, sample_size=2243.9, sample_size_v1=0, sample_size_v2=0, ppl=1.74, wps=556, ups=0.25, wpb=2243.9, bsz=64, num_updates=23900, lr=2.55507e-06, gnorm=6.817, clip=100, loss_scale=64, train_wall=40, gb_free=8.3, wall=96652
2023-05-09 02:47:31 - progress_bar.py[line:272] - INFO: epoch 028:    572 / 866 loss=2.02, loss_v1=0, loss_v2=0, nll_loss=0.777, ntokens=2202.4, nsentences=64, sample_size=2202.4, sample_size_v1=0, sample_size_v2=0, ppl=1.71, wps=549.4, ups=0.25, wpb=2202.4, bsz=64, num_updates=23910, lr=2.54279e-06, gnorm=6.245, clip=100, loss_scale=64, train_wall=40, gb_free=7.4, wall=96692
2023-05-09 02:48:11 - progress_bar.py[line:272] - INFO: epoch 028:    582 / 866 loss=2.041, loss_v1=0, loss_v2=0, nll_loss=0.799, ntokens=2123.1, nsentences=64, sample_size=2123.1, sample_size_v1=0, sample_size_v2=0, ppl=1.74, wps=528.3, ups=0.25, wpb=2123.1, bsz=64, num_updates=23920, lr=2.53051e-06, gnorm=7.061, clip=100, loss_scale=64, train_wall=40, gb_free=7.4, wall=96732
2023-05-09 02:48:51 - progress_bar.py[line:272] - INFO: epoch 028:    592 / 866 loss=2.042, loss_v1=0, loss_v2=0, nll_loss=0.799, ntokens=2089, nsentences=64, sample_size=2089, sample_size_v1=0, sample_size_v2=0, ppl=1.74, wps=518.5, ups=0.25, wpb=2089, bsz=64, num_updates=23930, lr=2.51822e-06, gnorm=7.081, clip=100, loss_scale=64, train_wall=40, gb_free=7.3, wall=96772
2023-05-09 02:49:31 - progress_bar.py[line:272] - INFO: epoch 028:    602 / 866 loss=2.006, loss_v1=0, loss_v2=0, nll_loss=0.759, ntokens=2122.3, nsentences=64, sample_size=2122.3, sample_size_v1=0, sample_size_v2=0, ppl=1.69, wps=526.5, ups=0.25, wpb=2122.3, bsz=64, num_updates=23940, lr=2.50594e-06, gnorm=6.251, clip=100, loss_scale=64, train_wall=40, gb_free=8.3, wall=96812
2023-05-09 02:50:11 - progress_bar.py[line:272] - INFO: epoch 028:    612 / 866 loss=2.04, loss_v1=0, loss_v2=0, nll_loss=0.798, ntokens=1933.1, nsentences=64, sample_size=1933.1, sample_size_v1=0, sample_size_v2=0, ppl=1.74, wps=484.4, ups=0.25, wpb=1933.1, bsz=64, num_updates=23950, lr=2.49365e-06, gnorm=7.064, clip=100, loss_scale=64, train_wall=40, gb_free=8.1, wall=96852
2023-05-09 02:50:51 - progress_bar.py[line:272] - INFO: epoch 028:    622 / 866 loss=2.039, loss_v1=0, loss_v2=0, nll_loss=0.797, ntokens=2007.3, nsentences=64, sample_size=2007.3, sample_size_v1=0, sample_size_v2=0, ppl=1.74, wps=498.9, ups=0.25, wpb=2007.3, bsz=64, num_updates=23960, lr=2.48137e-06, gnorm=6.929, clip=100, loss_scale=64, train_wall=40, gb_free=7.7, wall=96893
2023-05-09 02:51:31 - progress_bar.py[line:272] - INFO: epoch 028:    632 / 866 loss=2.03, loss_v1=0, loss_v2=0, nll_loss=0.786, ntokens=2011.8, nsentences=64, sample_size=2011.8, sample_size_v1=0, sample_size_v2=0, ppl=1.72, wps=504, ups=0.25, wpb=2011.8, bsz=64, num_updates=23970, lr=2.46909e-06, gnorm=7.417, clip=100, loss_scale=64, train_wall=40, gb_free=8.1, wall=96933
2023-05-09 02:52:11 - progress_bar.py[line:272] - INFO: epoch 028:    642 / 866 loss=2.02, loss_v1=0, loss_v2=0, nll_loss=0.776, ntokens=2063.3, nsentences=64, sample_size=2063.3, sample_size_v1=0, sample_size_v2=0, ppl=1.71, wps=516.6, ups=0.25, wpb=2063.3, bsz=64, num_updates=23980, lr=2.4568e-06, gnorm=6.974, clip=100, loss_scale=64, train_wall=40, gb_free=7.5, wall=96972
2023-05-09 02:52:51 - progress_bar.py[line:272] - INFO: epoch 028:    652 / 866 loss=2.036, loss_v1=0, loss_v2=0, nll_loss=0.793, ntokens=2019.1, nsentences=64, sample_size=2019.1, sample_size_v1=0, sample_size_v2=0, ppl=1.73, wps=506.7, ups=0.25, wpb=2019.1, bsz=64, num_updates=23990, lr=2.44452e-06, gnorm=6.857, clip=100, loss_scale=64, train_wall=40, gb_free=8.7, wall=97012
2023-05-09 02:53:31 - progress_bar.py[line:272] - INFO: epoch 028:    662 / 866 loss=2.063, loss_v1=0, loss_v2=0, nll_loss=0.824, ntokens=1927, nsentences=64, sample_size=1927, sample_size_v1=0, sample_size_v2=0, ppl=1.77, wps=483.9, ups=0.25, wpb=1927, bsz=64, num_updates=24000, lr=2.43223e-06, gnorm=7.815, clip=100, loss_scale=64, train_wall=40, gb_free=6.9, wall=97052
2023-05-09 02:54:11 - progress_bar.py[line:272] - INFO: epoch 028:    672 / 866 loss=2.039, loss_v1=0, loss_v2=0, nll_loss=0.797, ntokens=2033.9, nsentences=64, sample_size=2033.9, sample_size_v1=0, sample_size_v2=0, ppl=1.74, wps=505.2, ups=0.25, wpb=2033.9, bsz=64, num_updates=24010, lr=2.41995e-06, gnorm=7.364, clip=100, loss_scale=64, train_wall=40, gb_free=8.1, wall=97092
2023-05-09 02:54:51 - progress_bar.py[line:272] - INFO: epoch 028:    682 / 866 loss=2.026, loss_v1=0, loss_v2=0, nll_loss=0.782, ntokens=2076.8, nsentences=64, sample_size=2076.8, sample_size_v1=0, sample_size_v2=0, ppl=1.72, wps=518.3, ups=0.25, wpb=2076.8, bsz=64, num_updates=24020, lr=2.40767e-06, gnorm=6.944, clip=100, loss_scale=64, train_wall=40, gb_free=7.9, wall=97132
2023-05-09 02:55:31 - progress_bar.py[line:272] - INFO: epoch 028:    692 / 866 loss=2.041, loss_v1=0, loss_v2=0, nll_loss=0.8, ntokens=1991.3, nsentences=64, sample_size=1991.3, sample_size_v1=0, sample_size_v2=0, ppl=1.74, wps=497, ups=0.25, wpb=1991.3, bsz=64, num_updates=24030, lr=2.39538e-06, gnorm=7.344, clip=100, loss_scale=64, train_wall=40, gb_free=8.3, wall=97173
2023-05-09 02:56:11 - progress_bar.py[line:272] - INFO: epoch 028:    702 / 866 loss=2.049, loss_v1=0, loss_v2=0, nll_loss=0.809, ntokens=2062.5, nsentences=64, sample_size=2062.5, sample_size_v1=0, sample_size_v2=0, ppl=1.75, wps=516.5, ups=0.25, wpb=2062.5, bsz=64, num_updates=24040, lr=2.3831e-06, gnorm=6.766, clip=100, loss_scale=64, train_wall=40, gb_free=8, wall=97212
2023-05-09 02:56:51 - progress_bar.py[line:272] - INFO: epoch 028:    712 / 866 loss=2.042, loss_v1=0, loss_v2=0, nll_loss=0.8, ntokens=1917.3, nsentences=64, sample_size=1917.3, sample_size_v1=0, sample_size_v2=0, ppl=1.74, wps=480.5, ups=0.25, wpb=1917.3, bsz=64, num_updates=24050, lr=2.37081e-06, gnorm=7.355, clip=100, loss_scale=64, train_wall=40, gb_free=8.3, wall=97252
2023-05-09 02:57:31 - progress_bar.py[line:272] - INFO: epoch 028:    722 / 866 loss=2.017, loss_v1=0, loss_v2=0, nll_loss=0.772, ntokens=1946.1, nsentences=64, sample_size=1946.1, sample_size_v1=0, sample_size_v2=0, ppl=1.71, wps=485.7, ups=0.25, wpb=1946.1, bsz=64, num_updates=24060, lr=2.35853e-06, gnorm=6.435, clip=100, loss_scale=64, train_wall=40, gb_free=7.9, wall=97292
2023-05-09 02:58:11 - progress_bar.py[line:272] - INFO: epoch 028:    732 / 866 loss=2.021, loss_v1=0, loss_v2=0, nll_loss=0.776, ntokens=2021.9, nsentences=64, sample_size=2021.9, sample_size_v1=0, sample_size_v2=0, ppl=1.71, wps=506.6, ups=0.25, wpb=2021.9, bsz=64, num_updates=24070, lr=2.34625e-06, gnorm=6.41, clip=100, loss_scale=64, train_wall=40, gb_free=7.4, wall=97332
2023-05-09 02:58:51 - progress_bar.py[line:272] - INFO: epoch 028:    742 / 866 loss=2.026, loss_v1=0, loss_v2=0, nll_loss=0.782, ntokens=2148.8, nsentences=64, sample_size=2148.8, sample_size_v1=0, sample_size_v2=0, ppl=1.72, wps=535.8, ups=0.25, wpb=2148.8, bsz=64, num_updates=24080, lr=2.33396e-06, gnorm=6.587, clip=100, loss_scale=64, train_wall=40, gb_free=7.9, wall=97372
2023-05-09 02:59:32 - progress_bar.py[line:272] - INFO: epoch 028:    752 / 866 loss=2.01, loss_v1=0, loss_v2=0, nll_loss=0.765, ntokens=2084.2, nsentences=64, sample_size=2084.2, sample_size_v1=0, sample_size_v2=0, ppl=1.7, wps=519.1, ups=0.25, wpb=2084.2, bsz=64, num_updates=24090, lr=2.32168e-06, gnorm=6.916, clip=100, loss_scale=64, train_wall=40, gb_free=8.1, wall=97413
2023-05-09 03:00:12 - progress_bar.py[line:272] - INFO: epoch 028:    762 / 866 loss=2.031, loss_v1=0, loss_v2=0, nll_loss=0.788, ntokens=2125.4, nsentences=64, sample_size=2125.4, sample_size_v1=0, sample_size_v2=0, ppl=1.73, wps=528.2, ups=0.25, wpb=2125.4, bsz=64, num_updates=24100, lr=2.30939e-06, gnorm=7.033, clip=100, loss_scale=64, train_wall=40, gb_free=8.3, wall=97453
2023-05-09 03:00:52 - progress_bar.py[line:272] - INFO: epoch 028:    772 / 866 loss=2.025, loss_v1=0, loss_v2=0, nll_loss=0.782, ntokens=2085.7, nsentences=64, sample_size=2085.7, sample_size_v1=0, sample_size_v2=0, ppl=1.72, wps=522.5, ups=0.25, wpb=2085.7, bsz=64, num_updates=24110, lr=2.29711e-06, gnorm=6.82, clip=100, loss_scale=64, train_wall=40, gb_free=6.6, wall=97493
2023-05-09 03:01:32 - progress_bar.py[line:272] - INFO: epoch 028:    782 / 866 loss=2.036, loss_v1=0, loss_v2=0, nll_loss=0.795, ntokens=2278.8, nsentences=64, sample_size=2278.8, sample_size_v1=0, sample_size_v2=0, ppl=1.73, wps=564.4, ups=0.25, wpb=2278.8, bsz=64, num_updates=24120, lr=2.28483e-06, gnorm=6.748, clip=100, loss_scale=64, train_wall=40, gb_free=8, wall=97533
2023-05-09 03:02:12 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2023-05-09 03:02:16 - progress_bar.py[line:272] - INFO: epoch 028:    793 / 866 loss=2.051, loss_v1=0, loss_v2=0, nll_loss=0.811, ntokens=2003.4, nsentences=64, sample_size=2003.4, sample_size_v1=0, sample_size_v2=0, ppl=1.75, wps=458.2, ups=0.23, wpb=2003.4, bsz=64, num_updates=24130, lr=2.27254e-06, gnorm=6.902, clip=100, loss_scale=64, train_wall=44, gb_free=7.9, wall=97577
2023-05-09 03:02:56 - progress_bar.py[line:272] - INFO: epoch 028:    803 / 866 loss=2.032, loss_v1=0, loss_v2=0, nll_loss=0.789, ntokens=1972.7, nsentences=64, sample_size=1972.7, sample_size_v1=0, sample_size_v2=0, ppl=1.73, wps=496.7, ups=0.25, wpb=1972.7, bsz=64, num_updates=24140, lr=2.26026e-06, gnorm=6.95, clip=100, loss_scale=64, train_wall=40, gb_free=7.2, wall=97617
2023-05-09 03:03:36 - progress_bar.py[line:272] - INFO: epoch 028:    813 / 866 loss=2.015, loss_v1=0, loss_v2=0, nll_loss=0.769, ntokens=2109.3, nsentences=64, sample_size=2109.3, sample_size_v1=0, sample_size_v2=0, ppl=1.7, wps=525, ups=0.25, wpb=2109.3, bsz=64, num_updates=24150, lr=2.24797e-06, gnorm=6.596, clip=100, loss_scale=64, train_wall=40, gb_free=6.7, wall=97657
2023-05-09 03:04:16 - progress_bar.py[line:272] - INFO: epoch 028:    823 / 866 loss=2.018, loss_v1=0, loss_v2=0, nll_loss=0.772, ntokens=2101.2, nsentences=64, sample_size=2101.2, sample_size_v1=0, sample_size_v2=0, ppl=1.71, wps=519.5, ups=0.25, wpb=2101.2, bsz=64, num_updates=24160, lr=2.23569e-06, gnorm=6.449, clip=100, loss_scale=64, train_wall=40, gb_free=7.5, wall=97697
2023-05-09 03:04:57 - progress_bar.py[line:272] - INFO: epoch 028:    833 / 866 loss=2.005, loss_v1=0, loss_v2=0, nll_loss=0.759, ntokens=2208.2, nsentences=64, sample_size=2208.2, sample_size_v1=0, sample_size_v2=0, ppl=1.69, wps=541.7, ups=0.25, wpb=2208.2, bsz=64, num_updates=24170, lr=2.22341e-06, gnorm=6.309, clip=100, loss_scale=64, train_wall=41, gb_free=8.2, wall=97738
2023-05-09 03:05:37 - progress_bar.py[line:272] - INFO: epoch 028:    843 / 866 loss=2.006, loss_v1=0, loss_v2=0, nll_loss=0.76, ntokens=2121.2, nsentences=64, sample_size=2121.2, sample_size_v1=0, sample_size_v2=0, ppl=1.69, wps=527.3, ups=0.25, wpb=2121.2, bsz=64, num_updates=24180, lr=2.21112e-06, gnorm=6.459, clip=100, loss_scale=64, train_wall=40, gb_free=8.2, wall=97778
2023-05-09 03:06:18 - progress_bar.py[line:272] - INFO: epoch 028:    853 / 866 loss=1.998, loss_v1=0, loss_v2=0, nll_loss=0.751, ntokens=2191.4, nsentences=64, sample_size=2191.4, sample_size_v1=0, sample_size_v2=0, ppl=1.68, wps=542.2, ups=0.25, wpb=2191.4, bsz=64, num_updates=24190, lr=2.19884e-06, gnorm=6.525, clip=100, loss_scale=64, train_wall=40, gb_free=7.5, wall=97819
2023-05-09 03:06:58 - progress_bar.py[line:272] - INFO: epoch 028:    863 / 866 loss=2.017, loss_v1=0, loss_v2=0, nll_loss=0.773, ntokens=2023.2, nsentences=64, sample_size=2023.2, sample_size_v1=0, sample_size_v2=0, ppl=1.71, wps=504.6, ups=0.25, wpb=2023.2, bsz=64, num_updates=24200, lr=2.18655e-06, gnorm=7.391, clip=100, loss_scale=64, train_wall=40, gb_free=7.7, wall=97859
2023-05-09 03:07:08 - train.py[line:332] - INFO: end of epoch 28 (average epoch stats below)
local datafile ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 1 begin to initialize row_count and line_idx-to-offset mapping
2023-05-09 03:07:08 - progress_bar.py[line:282] - INFO: epoch 028 | loss 2.02 | loss_v1 0 | loss_v2 0 | nll_loss 0.776 | ntokens 2103.43 | nsentences 63.972 | sample_size 2103.43 | sample_size_v1 0 | sample_size_v2 0 | ppl 1.71 | wps 520.9 | ups 0.25 | wpb 2103.4 | bsz 64 | num_updates 24203 | lr 2.18287e-06 | gnorm 6.82 | clip 100 | loss_scale 64 | train_wall 3483 | gb_free 8.7 | wall 97869
2023-05-09 03:07:08 - trainer.py[line:639] - INFO: loading train data for epoch 29
local datafile ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 0 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 1 finished initializing row_count and line_idx-to-offset mapping
file ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 1 row count 27700 total row count 55400
slice_id 1 seek offset 27700
local datafile ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 0 finished initializing row_count and line_idx-to-offset mapping
file ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 0 row count 27700 total row count 55400
slice_id 0 seek offset 0
2023-05-09 03:07:10 - trainer.py[line:703] - INFO: begin training epoch 29
2023-05-09 03:07:10 - train.py[line:305] - INFO: Start iterating over samples
2023-05-09 03:07:39 - progress_bar.py[line:272] - INFO: epoch 029:      7 / 866 loss=2.014, loss_v1=0, loss_v2=0, nll_loss=0.771, ntokens=2063.1, nsentences=61.6, sample_size=2063.1, sample_size_v1=0, sample_size_v2=0, ppl=1.71, wps=502.5, ups=0.24, wpb=2063.1, bsz=61.6, num_updates=24210, lr=2.17427e-06, gnorm=6.597, clip=100, loss_scale=64, train_wall=39, gb_free=7.5, wall=97900
2023-05-09 03:08:19 - progress_bar.py[line:272] - INFO: epoch 029:     17 / 866 loss=2.003, loss_v1=0, loss_v2=0, nll_loss=0.757, ntokens=2075.1, nsentences=64, sample_size=2075.1, sample_size_v1=0, sample_size_v2=0, ppl=1.69, wps=512.5, ups=0.25, wpb=2075.1, bsz=64, num_updates=24220, lr=2.16199e-06, gnorm=7.817, clip=100, loss_scale=64, train_wall=40, gb_free=7.3, wall=97940
2023-05-09 03:09:00 - progress_bar.py[line:272] - INFO: epoch 029:     27 / 866 loss=1.995, loss_v1=0, loss_v2=0, nll_loss=0.748, ntokens=1975.4, nsentences=64, sample_size=1975.4, sample_size_v1=0, sample_size_v2=0, ppl=1.68, wps=488.7, ups=0.25, wpb=1975.4, bsz=64, num_updates=24230, lr=2.1497e-06, gnorm=7.032, clip=100, loss_scale=64, train_wall=40, gb_free=7.1, wall=97981
2023-05-09 03:09:41 - progress_bar.py[line:272] - INFO: epoch 029:     37 / 866 loss=1.948, loss_v1=0, loss_v2=0, nll_loss=0.694, ntokens=2214.8, nsentences=64, sample_size=2214.8, sample_size_v1=0, sample_size_v2=0, ppl=1.62, wps=541.6, ups=0.24, wpb=2214.8, bsz=64, num_updates=24240, lr=2.13742e-06, gnorm=6.617, clip=100, loss_scale=64, train_wall=41, gb_free=7.6, wall=98022
2023-05-09 03:10:21 - progress_bar.py[line:272] - INFO: epoch 029:     47 / 866 loss=1.969, loss_v1=0, loss_v2=0, nll_loss=0.719, ntokens=2012, nsentences=64, sample_size=2012, sample_size_v1=0, sample_size_v2=0, ppl=1.65, wps=497.9, ups=0.25, wpb=2012, bsz=64, num_updates=24250, lr=2.12513e-06, gnorm=6.846, clip=100, loss_scale=64, train_wall=40, gb_free=7, wall=98062
2023-05-09 03:11:01 - progress_bar.py[line:272] - INFO: epoch 029:     57 / 866 loss=1.936, loss_v1=0, loss_v2=0, nll_loss=0.681, ntokens=2065.2, nsentences=64, sample_size=2065.2, sample_size_v1=0, sample_size_v2=0, ppl=1.6, wps=510.9, ups=0.25, wpb=2065.2, bsz=64, num_updates=24260, lr=2.11285e-06, gnorm=6.738, clip=100, loss_scale=64, train_wall=40, gb_free=7.6, wall=98102
2023-05-09 03:11:43 - progress_bar.py[line:272] - INFO: epoch 029:     67 / 866 loss=1.897, loss_v1=0, loss_v2=0, nll_loss=0.636, ntokens=2385, nsentences=64, sample_size=2385, sample_size_v1=0, sample_size_v2=0, ppl=1.55, wps=572.3, ups=0.24, wpb=2385, bsz=64, num_updates=24270, lr=2.10057e-06, gnorm=5.833, clip=100, loss_scale=64, train_wall=42, gb_free=6.4, wall=98144
2023-05-09 03:12:25 - progress_bar.py[line:272] - INFO: epoch 029:     77 / 866 loss=1.95, loss_v1=0, loss_v2=0, nll_loss=0.696, ntokens=2320.6, nsentences=64, sample_size=2320.6, sample_size_v1=0, sample_size_v2=0, ppl=1.62, wps=558.4, ups=0.24, wpb=2320.6, bsz=64, num_updates=24280, lr=2.08828e-06, gnorm=6.114, clip=100, loss_scale=64, train_wall=42, gb_free=7.3, wall=98186
2023-05-09 03:13:06 - progress_bar.py[line:272] - INFO: epoch 029:     87 / 866 loss=1.989, loss_v1=0, loss_v2=0, nll_loss=0.741, ntokens=2178.1, nsentences=64, sample_size=2178.1, sample_size_v1=0, sample_size_v2=0, ppl=1.67, wps=528, ups=0.24, wpb=2178.1, bsz=64, num_updates=24290, lr=2.076e-06, gnorm=6.742, clip=100, loss_scale=64, train_wall=41, gb_free=6.9, wall=98227
2023-05-09 03:13:47 - progress_bar.py[line:272] - INFO: epoch 029:     97 / 866 loss=1.968, loss_v1=0, loss_v2=0, nll_loss=0.717, ntokens=2142.7, nsentences=64, sample_size=2142.7, sample_size_v1=0, sample_size_v2=0, ppl=1.64, wps=524.2, ups=0.24, wpb=2142.7, bsz=64, num_updates=24300, lr=2.06371e-06, gnorm=6.674, clip=100, loss_scale=64, train_wall=41, gb_free=6.2, wall=98268
2023-05-09 03:14:27 - progress_bar.py[line:272] - INFO: epoch 029:    107 / 866 loss=2.015, loss_v1=0, loss_v2=0, nll_loss=0.771, ntokens=2011.7, nsentences=64, sample_size=2011.7, sample_size_v1=0, sample_size_v2=0, ppl=1.71, wps=501.5, ups=0.25, wpb=2011.7, bsz=64, num_updates=24310, lr=2.05143e-06, gnorm=7.172, clip=100, loss_scale=64, train_wall=40, gb_free=6.8, wall=98308
2023-05-09 03:15:08 - progress_bar.py[line:272] - INFO: epoch 029:    117 / 866 loss=2.038, loss_v1=0, loss_v2=0, nll_loss=0.797, ntokens=2101.1, nsentences=64, sample_size=2101.1, sample_size_v1=0, sample_size_v2=0, ppl=1.74, wps=516.5, ups=0.25, wpb=2101.1, bsz=64, num_updates=24320, lr=2.03915e-06, gnorm=7.386, clip=100, loss_scale=64, train_wall=41, gb_free=6.9, wall=98349
2023-05-09 03:15:49 - progress_bar.py[line:272] - INFO: epoch 029:    127 / 866 loss=2.041, loss_v1=0, loss_v2=0, nll_loss=0.8, ntokens=2224.4, nsentences=64, sample_size=2224.4, sample_size_v1=0, sample_size_v2=0, ppl=1.74, wps=540.3, ups=0.24, wpb=2224.4, bsz=64, num_updates=24330, lr=2.02686e-06, gnorm=7.18, clip=100, loss_scale=64, train_wall=41, gb_free=7.3, wall=98390
2023-05-09 03:16:30 - progress_bar.py[line:272] - INFO: epoch 029:    137 / 866 loss=1.998, loss_v1=0, loss_v2=0, nll_loss=0.751, ntokens=2240.2, nsentences=64, sample_size=2240.2, sample_size_v1=0, sample_size_v2=0, ppl=1.68, wps=546.6, ups=0.24, wpb=2240.2, bsz=64, num_updates=24340, lr=2.01458e-06, gnorm=6.678, clip=100, loss_scale=64, train_wall=41, gb_free=7.3, wall=98431
2023-05-09 03:17:11 - progress_bar.py[line:272] - INFO: epoch 029:    147 / 866 loss=1.978, loss_v1=0, loss_v2=0, nll_loss=0.729, ntokens=2170.9, nsentences=64, sample_size=2170.9, sample_size_v1=0, sample_size_v2=0, ppl=1.66, wps=525.4, ups=0.24, wpb=2170.9, bsz=64, num_updates=24350, lr=2.00229e-06, gnorm=6.5, clip=100, loss_scale=64, train_wall=41, gb_free=7.2, wall=98472
2023-05-09 03:17:40 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2023-05-09 03:17:56 - progress_bar.py[line:272] - INFO: epoch 029:    158 / 866 loss=2.009, loss_v1=0, loss_v2=0, nll_loss=0.763, ntokens=2214.5, nsentences=64, sample_size=2214.5, sample_size_v1=0, sample_size_v2=0, ppl=1.7, wps=488.6, ups=0.22, wpb=2214.5, bsz=64, num_updates=24360, lr=1.99001e-06, gnorm=6.661, clip=100, loss_scale=32, train_wall=45, gb_free=7.5, wall=98517
2023-05-09 03:18:37 - progress_bar.py[line:272] - INFO: epoch 029:    168 / 866 loss=2.017, loss_v1=0, loss_v2=0, nll_loss=0.773, ntokens=2127.3, nsentences=64, sample_size=2127.3, sample_size_v1=0, sample_size_v2=0, ppl=1.71, wps=523.5, ups=0.25, wpb=2127.3, bsz=64, num_updates=24370, lr=1.97773e-06, gnorm=6.988, clip=100, loss_scale=32, train_wall=41, gb_free=7.8, wall=98558
2023-05-09 03:19:18 - progress_bar.py[line:272] - INFO: epoch 029:    178 / 866 loss=2.013, loss_v1=0, loss_v2=0, nll_loss=0.768, ntokens=2069.7, nsentences=64, sample_size=2069.7, sample_size_v1=0, sample_size_v2=0, ppl=1.7, wps=508.9, ups=0.25, wpb=2069.7, bsz=64, num_updates=24380, lr=1.96544e-06, gnorm=6.938, clip=100, loss_scale=32, train_wall=41, gb_free=7.4, wall=98599
2023-05-09 03:19:59 - progress_bar.py[line:272] - INFO: epoch 029:    188 / 866 loss=2.002, loss_v1=0, loss_v2=0, nll_loss=0.755, ntokens=2227.8, nsentences=64, sample_size=2227.8, sample_size_v1=0, sample_size_v2=0, ppl=1.69, wps=542.8, ups=0.24, wpb=2227.8, bsz=64, num_updates=24390, lr=1.95316e-06, gnorm=6.491, clip=100, loss_scale=32, train_wall=41, gb_free=7.4, wall=98640
2023-05-09 03:20:40 - progress_bar.py[line:272] - INFO: epoch 029:    198 / 866 loss=2.016, loss_v1=0, loss_v2=0, nll_loss=0.771, ntokens=2162.5, nsentences=64, sample_size=2162.5, sample_size_v1=0, sample_size_v2=0, ppl=1.71, wps=527.5, ups=0.24, wpb=2162.5, bsz=64, num_updates=24400, lr=1.94087e-06, gnorm=7.096, clip=100, loss_scale=32, train_wall=41, gb_free=7.2, wall=98681
2023-05-09 03:21:20 - progress_bar.py[line:272] - INFO: epoch 029:    208 / 866 loss=2.017, loss_v1=0, loss_v2=0, nll_loss=0.773, ntokens=1967.7, nsentences=64, sample_size=1967.7, sample_size_v1=0, sample_size_v2=0, ppl=1.71, wps=490.9, ups=0.25, wpb=1967.7, bsz=64, num_updates=24410, lr=1.92859e-06, gnorm=7.001, clip=100, loss_scale=32, train_wall=40, gb_free=7.4, wall=98721
2023-05-09 03:22:00 - progress_bar.py[line:272] - INFO: epoch 029:    218 / 866 loss=2.04, loss_v1=0, loss_v2=0, nll_loss=0.798, ntokens=2200.8, nsentences=64, sample_size=2200.8, sample_size_v1=0, sample_size_v2=0, ppl=1.74, wps=546.8, ups=0.25, wpb=2200.8, bsz=64, num_updates=24420, lr=1.9163e-06, gnorm=6.628, clip=100, loss_scale=32, train_wall=40, gb_free=7.9, wall=98761
2023-05-09 03:22:40 - progress_bar.py[line:272] - INFO: epoch 029:    228 / 866 loss=2.023, loss_v1=0, loss_v2=0, nll_loss=0.78, ntokens=2165.7, nsentences=64, sample_size=2165.7, sample_size_v1=0, sample_size_v2=0, ppl=1.72, wps=535.5, ups=0.25, wpb=2165.7, bsz=64, num_updates=24430, lr=1.90402e-06, gnorm=6.513, clip=100, loss_scale=32, train_wall=40, gb_free=8, wall=98802
2023-05-09 03:23:21 - progress_bar.py[line:272] - INFO: epoch 029:    238 / 866 loss=2.042, loss_v1=0, loss_v2=0, nll_loss=0.801, ntokens=2129.1, nsentences=64, sample_size=2129.1, sample_size_v1=0, sample_size_v2=0, ppl=1.74, wps=527.8, ups=0.25, wpb=2129.1, bsz=64, num_updates=24440, lr=1.89174e-06, gnorm=6.436, clip=100, loss_scale=32, train_wall=40, gb_free=7.8, wall=98842
2023-05-09 03:24:01 - progress_bar.py[line:272] - INFO: epoch 029:    248 / 866 loss=2.035, loss_v1=0, loss_v2=0, nll_loss=0.792, ntokens=2173.3, nsentences=64, sample_size=2173.3, sample_size_v1=0, sample_size_v2=0, ppl=1.73, wps=537.9, ups=0.25, wpb=2173.3, bsz=64, num_updates=24450, lr=1.87945e-06, gnorm=6.54, clip=100, loss_scale=32, train_wall=40, gb_free=7.7, wall=98882
2023-05-09 03:24:41 - progress_bar.py[line:272] - INFO: epoch 029:    258 / 866 loss=2.039, loss_v1=0, loss_v2=0, nll_loss=0.796, ntokens=2109.7, nsentences=64, sample_size=2109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.74, wps=525.9, ups=0.25, wpb=2109.7, bsz=64, num_updates=24460, lr=1.86717e-06, gnorm=6.575, clip=100, loss_scale=32, train_wall=40, gb_free=7.8, wall=98922
2023-05-09 03:25:22 - progress_bar.py[line:272] - INFO: epoch 029:    268 / 866 loss=2.034, loss_v1=0, loss_v2=0, nll_loss=0.791, ntokens=2130.6, nsentences=64, sample_size=2130.6, sample_size_v1=0, sample_size_v2=0, ppl=1.73, wps=530.8, ups=0.25, wpb=2130.6, bsz=64, num_updates=24470, lr=1.85488e-06, gnorm=6.686, clip=100, loss_scale=32, train_wall=40, gb_free=8, wall=98963
2023-05-09 03:26:02 - progress_bar.py[line:272] - INFO: epoch 029:    278 / 866 loss=2.03, loss_v1=0, loss_v2=0, nll_loss=0.786, ntokens=2172.4, nsentences=64, sample_size=2172.4, sample_size_v1=0, sample_size_v2=0, ppl=1.72, wps=539.1, ups=0.25, wpb=2172.4, bsz=64, num_updates=24480, lr=1.8426e-06, gnorm=6.391, clip=100, loss_scale=32, train_wall=40, gb_free=7.7, wall=99003
2023-05-09 03:26:42 - progress_bar.py[line:272] - INFO: epoch 029:    288 / 866 loss=2.019, loss_v1=0, loss_v2=0, nll_loss=0.775, ntokens=2196.8, nsentences=64, sample_size=2196.8, sample_size_v1=0, sample_size_v2=0, ppl=1.71, wps=544.9, ups=0.25, wpb=2196.8, bsz=64, num_updates=24490, lr=1.83032e-06, gnorm=5.962, clip=100, loss_scale=32, train_wall=40, gb_free=7.8, wall=99043
2023-05-09 03:27:22 - progress_bar.py[line:272] - INFO: epoch 029:    298 / 866 loss=2.016, loss_v1=0, loss_v2=0, nll_loss=0.771, ntokens=2080.1, nsentences=64, sample_size=2080.1, sample_size_v1=0, sample_size_v2=0, ppl=1.71, wps=517.8, ups=0.25, wpb=2080.1, bsz=64, num_updates=24500, lr=1.81803e-06, gnorm=7.172, clip=100, loss_scale=32, train_wall=40, gb_free=8.2, wall=99083
2023-05-09 03:28:03 - progress_bar.py[line:272] - INFO: epoch 029:    308 / 866 loss=2.02, loss_v1=0, loss_v2=0, nll_loss=0.775, ntokens=2155.7, nsentences=64, sample_size=2155.7, sample_size_v1=0, sample_size_v2=0, ppl=1.71, wps=534, ups=0.25, wpb=2155.7, bsz=64, num_updates=24510, lr=1.80575e-06, gnorm=6.516, clip=100, loss_scale=32, train_wall=40, gb_free=8.1, wall=99124
2023-05-09 03:28:43 - progress_bar.py[line:272] - INFO: epoch 029:    318 / 866 loss=2.016, loss_v1=0, loss_v2=0, nll_loss=0.772, ntokens=2007.1, nsentences=64, sample_size=2007.1, sample_size_v1=0, sample_size_v2=0, ppl=1.71, wps=499.6, ups=0.25, wpb=2007.1, bsz=64, num_updates=24520, lr=1.79346e-06, gnorm=6.704, clip=100, loss_scale=32, train_wall=40, gb_free=8.1, wall=99164
2023-05-09 03:29:23 - progress_bar.py[line:272] - INFO: epoch 029:    328 / 866 loss=2.036, loss_v1=0, loss_v2=0, nll_loss=0.795, ntokens=2043.2, nsentences=64, sample_size=2043.2, sample_size_v1=0, sample_size_v2=0, ppl=1.73, wps=512.7, ups=0.25, wpb=2043.2, bsz=64, num_updates=24530, lr=1.78118e-06, gnorm=7.116, clip=100, loss_scale=32, train_wall=40, gb_free=8, wall=99204
2023-05-09 03:30:03 - progress_bar.py[line:272] - INFO: epoch 029:    338 / 866 loss=1.999, loss_v1=0, loss_v2=0, nll_loss=0.753, ntokens=2147.1, nsentences=64, sample_size=2147.1, sample_size_v1=0, sample_size_v2=0, ppl=1.69, wps=533.8, ups=0.25, wpb=2147.1, bsz=64, num_updates=24540, lr=1.7689e-06, gnorm=6.411, clip=100, loss_scale=32, train_wall=40, gb_free=8, wall=99244
2023-05-09 03:30:43 - progress_bar.py[line:272] - INFO: epoch 029:    348 / 866 loss=2.021, loss_v1=0, loss_v2=0, nll_loss=0.776, ntokens=1910.8, nsentences=64, sample_size=1910.8, sample_size_v1=0, sample_size_v2=0, ppl=1.71, wps=480.9, ups=0.25, wpb=1910.8, bsz=64, num_updates=24550, lr=1.75661e-06, gnorm=7.102, clip=100, loss_scale=32, train_wall=40, gb_free=7.9, wall=99284
2023-05-09 03:31:22 - progress_bar.py[line:272] - INFO: epoch 029:    358 / 866 loss=2.059, loss_v1=0, loss_v2=0, nll_loss=0.819, ntokens=1995.2, nsentences=64, sample_size=1995.2, sample_size_v1=0, sample_size_v2=0, ppl=1.76, wps=501.9, ups=0.25, wpb=1995.2, bsz=64, num_updates=24560, lr=1.74433e-06, gnorm=6.73, clip=100, loss_scale=32, train_wall=40, gb_free=8.2, wall=99324
2023-05-09 03:32:02 - progress_bar.py[line:272] - INFO: epoch 029:    368 / 866 loss=2.034, loss_v1=0, loss_v2=0, nll_loss=0.791, ntokens=1984.4, nsentences=64, sample_size=1984.4, sample_size_v1=0, sample_size_v2=0, ppl=1.73, wps=496.7, ups=0.25, wpb=1984.4, bsz=64, num_updates=24570, lr=1.73204e-06, gnorm=7.174, clip=100, loss_scale=32, train_wall=40, gb_free=7.8, wall=99364
2023-05-09 03:32:43 - progress_bar.py[line:272] - INFO: epoch 029:    378 / 866 loss=2.025, loss_v1=0, loss_v2=0, nll_loss=0.782, ntokens=2113.8, nsentences=64, sample_size=2113.8, sample_size_v1=0, sample_size_v2=0, ppl=1.72, wps=525.6, ups=0.25, wpb=2113.8, bsz=64, num_updates=24580, lr=1.71976e-06, gnorm=6.871, clip=100, loss_scale=32, train_wall=40, gb_free=8.2, wall=99404
2023-05-09 03:33:23 - progress_bar.py[line:272] - INFO: epoch 029:    388 / 866 loss=2.023, loss_v1=0, loss_v2=0, nll_loss=0.779, ntokens=2138.6, nsentences=64, sample_size=2138.6, sample_size_v1=0, sample_size_v2=0, ppl=1.72, wps=535.2, ups=0.25, wpb=2138.6, bsz=64, num_updates=24590, lr=1.70748e-06, gnorm=6.688, clip=100, loss_scale=32, train_wall=40, gb_free=7.5, wall=99444
2023-05-09 03:34:02 - progress_bar.py[line:272] - INFO: epoch 029:    398 / 866 loss=2.037, loss_v1=0, loss_v2=0, nll_loss=0.795, ntokens=2064.6, nsentences=64, sample_size=2064.6, sample_size_v1=0, sample_size_v2=0, ppl=1.73, wps=517.5, ups=0.25, wpb=2064.6, bsz=64, num_updates=24600, lr=1.69519e-06, gnorm=7.626, clip=100, loss_scale=32, train_wall=40, gb_free=7.2, wall=99484
2023-05-09 03:34:42 - progress_bar.py[line:272] - INFO: epoch 029:    408 / 866 loss=2.023, loss_v1=0, loss_v2=0, nll_loss=0.779, ntokens=2069, nsentences=64, sample_size=2069, sample_size_v1=0, sample_size_v2=0, ppl=1.72, wps=517.5, ups=0.25, wpb=2069, bsz=64, num_updates=24610, lr=1.68291e-06, gnorm=6.712, clip=100, loss_scale=32, train_wall=40, gb_free=7.7, wall=99524
2023-05-09 03:35:22 - progress_bar.py[line:272] - INFO: epoch 029:    418 / 866 loss=2.007, loss_v1=0, loss_v2=0, nll_loss=0.762, ntokens=2098.3, nsentences=64, sample_size=2098.3, sample_size_v1=0, sample_size_v2=0, ppl=1.7, wps=524.2, ups=0.25, wpb=2098.3, bsz=64, num_updates=24620, lr=1.67062e-06, gnorm=6.812, clip=100, loss_scale=32, train_wall=40, gb_free=7.2, wall=99564
2023-05-09 03:36:03 - progress_bar.py[line:272] - INFO: epoch 029:    428 / 866 loss=2.006, loss_v1=0, loss_v2=0, nll_loss=0.761, ntokens=2110.8, nsentences=64, sample_size=2110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.69, wps=527.1, ups=0.25, wpb=2110.8, bsz=64, num_updates=24630, lr=1.65834e-06, gnorm=6.577, clip=100, loss_scale=32, train_wall=40, gb_free=7.7, wall=99604
2023-05-09 03:36:42 - progress_bar.py[line:272] - INFO: epoch 029:    438 / 866 loss=2.041, loss_v1=0, loss_v2=0, nll_loss=0.8, ntokens=2124.1, nsentences=64, sample_size=2124.1, sample_size_v1=0, sample_size_v2=0, ppl=1.74, wps=531.8, ups=0.25, wpb=2124.1, bsz=64, num_updates=24640, lr=1.64606e-06, gnorm=7.579, clip=100, loss_scale=32, train_wall=40, gb_free=8, wall=99644
2023-05-09 03:37:22 - progress_bar.py[line:272] - INFO: epoch 029:    448 / 866 loss=2.046, loss_v1=0, loss_v2=0, nll_loss=0.806, ntokens=1996.8, nsentences=64, sample_size=1996.8, sample_size_v1=0, sample_size_v2=0, ppl=1.75, wps=499.2, ups=0.25, wpb=1996.8, bsz=64, num_updates=24650, lr=1.63377e-06, gnorm=7.319, clip=100, loss_scale=32, train_wall=40, gb_free=7.7, wall=99684
2023-05-09 03:38:03 - progress_bar.py[line:272] - INFO: epoch 029:    458 / 866 loss=2.036, loss_v1=0, loss_v2=0, nll_loss=0.793, ntokens=2079.8, nsentences=64, sample_size=2079.8, sample_size_v1=0, sample_size_v2=0, ppl=1.73, wps=517.7, ups=0.25, wpb=2079.8, bsz=64, num_updates=24660, lr=1.62149e-06, gnorm=7.019, clip=100, loss_scale=32, train_wall=40, gb_free=8, wall=99724
2023-05-09 03:38:43 - progress_bar.py[line:272] - INFO: epoch 029:    468 / 866 loss=2.043, loss_v1=0, loss_v2=0, nll_loss=0.802, ntokens=2164.7, nsentences=64, sample_size=2164.7, sample_size_v1=0, sample_size_v2=0, ppl=1.74, wps=539, ups=0.25, wpb=2164.7, bsz=64, num_updates=24670, lr=1.6092e-06, gnorm=6.882, clip=100, loss_scale=32, train_wall=40, gb_free=7.4, wall=99764
2023-05-09 03:39:23 - progress_bar.py[line:272] - INFO: epoch 029:    478 / 866 loss=2.046, loss_v1=0, loss_v2=0, nll_loss=0.805, ntokens=2220, nsentences=64, sample_size=2220, sample_size_v1=0, sample_size_v2=0, ppl=1.75, wps=549.6, ups=0.25, wpb=2220, bsz=64, num_updates=24680, lr=1.59692e-06, gnorm=6.726, clip=100, loss_scale=32, train_wall=40, gb_free=8, wall=99804
2023-05-09 03:40:03 - progress_bar.py[line:272] - INFO: epoch 029:    488 / 866 loss=2.016, loss_v1=0, loss_v2=0, nll_loss=0.772, ntokens=2033.8, nsentences=64, sample_size=2033.8, sample_size_v1=0, sample_size_v2=0, ppl=1.71, wps=508.2, ups=0.25, wpb=2033.8, bsz=64, num_updates=24690, lr=1.58464e-06, gnorm=6.502, clip=100, loss_scale=32, train_wall=40, gb_free=8.3, wall=99844
2023-05-09 03:40:43 - progress_bar.py[line:272] - INFO: epoch 029:    498 / 866 loss=2.012, loss_v1=0, loss_v2=0, nll_loss=0.767, ntokens=2069, nsentences=64, sample_size=2069, sample_size_v1=0, sample_size_v2=0, ppl=1.7, wps=515.7, ups=0.25, wpb=2069, bsz=64, num_updates=24700, lr=1.57235e-06, gnorm=6.9, clip=100, loss_scale=32, train_wall=40, gb_free=8.5, wall=99884
2023-05-09 03:41:23 - progress_bar.py[line:272] - INFO: epoch 029:    508 / 866 loss=2.043, loss_v1=0, loss_v2=0, nll_loss=0.801, ntokens=2115.2, nsentences=64, sample_size=2115.2, sample_size_v1=0, sample_size_v2=0, ppl=1.74, wps=529, ups=0.25, wpb=2115.2, bsz=64, num_updates=24710, lr=1.56007e-06, gnorm=6.902, clip=100, loss_scale=32, train_wall=40, gb_free=7.9, wall=99924
2023-05-09 03:42:03 - progress_bar.py[line:272] - INFO: epoch 029:    518 / 866 loss=2.042, loss_v1=0, loss_v2=0, nll_loss=0.801, ntokens=2197.1, nsentences=64, sample_size=2197.1, sample_size_v1=0, sample_size_v2=0, ppl=1.74, wps=547.6, ups=0.25, wpb=2197.1, bsz=64, num_updates=24720, lr=1.54778e-06, gnorm=6.569, clip=100, loss_scale=32, train_wall=40, gb_free=8.1, wall=99965
2023-05-09 03:42:43 - progress_bar.py[line:272] - INFO: epoch 029:    528 / 866 loss=2.03, loss_v1=0, loss_v2=0, nll_loss=0.787, ntokens=1974.3, nsentences=64, sample_size=1974.3, sample_size_v1=0, sample_size_v2=0, ppl=1.73, wps=495.9, ups=0.25, wpb=1974.3, bsz=64, num_updates=24730, lr=1.5355e-06, gnorm=6.943, clip=100, loss_scale=32, train_wall=40, gb_free=8.3, wall=100004
2023-05-09 03:43:23 - progress_bar.py[line:272] - INFO: epoch 029:    538 / 866 loss=2.015, loss_v1=0, loss_v2=0, nll_loss=0.769, ntokens=2123.8, nsentences=64, sample_size=2123.8, sample_size_v1=0, sample_size_v2=0, ppl=1.7, wps=531.4, ups=0.25, wpb=2123.8, bsz=64, num_updates=24740, lr=1.52322e-06, gnorm=6.661, clip=100, loss_scale=32, train_wall=40, gb_free=7.5, wall=100044
2023-05-09 03:44:04 - progress_bar.py[line:272] - INFO: epoch 029:    548 / 866 loss=2.052, loss_v1=0, loss_v2=0, nll_loss=0.811, ntokens=2308.9, nsentences=64, sample_size=2308.9, sample_size_v1=0, sample_size_v2=0, ppl=1.75, wps=573.1, ups=0.25, wpb=2308.9, bsz=64, num_updates=24750, lr=1.51093e-06, gnorm=6.53, clip=100, loss_scale=32, train_wall=40, gb_free=8.1, wall=100085
2023-05-09 03:44:44 - progress_bar.py[line:272] - INFO: epoch 029:    558 / 866 loss=2.037, loss_v1=0, loss_v2=0, nll_loss=0.794, ntokens=2284.3, nsentences=64, sample_size=2284.3, sample_size_v1=0, sample_size_v2=0, ppl=1.73, wps=566.1, ups=0.25, wpb=2284.3, bsz=64, num_updates=24760, lr=1.49865e-06, gnorm=6.336, clip=100, loss_scale=32, train_wall=40, gb_free=7.2, wall=100125
2023-05-09 03:45:24 - progress_bar.py[line:272] - INFO: epoch 029:    568 / 866 loss=2.033, loss_v1=0, loss_v2=0, nll_loss=0.791, ntokens=2217.8, nsentences=64, sample_size=2217.8, sample_size_v1=0, sample_size_v2=0, ppl=1.73, wps=553.2, ups=0.25, wpb=2217.8, bsz=64, num_updates=24770, lr=1.48636e-06, gnorm=6.547, clip=100, loss_scale=32, train_wall=40, gb_free=7.4, wall=100165
2023-05-09 03:46:04 - progress_bar.py[line:272] - INFO: epoch 029:    578 / 866 loss=2.023, loss_v1=0, loss_v2=0, nll_loss=0.78, ntokens=2124.1, nsentences=64, sample_size=2124.1, sample_size_v1=0, sample_size_v2=0, ppl=1.72, wps=529.2, ups=0.25, wpb=2124.1, bsz=64, num_updates=24780, lr=1.47408e-06, gnorm=6.7, clip=100, loss_scale=32, train_wall=40, gb_free=7.5, wall=100205
2023-05-09 03:46:44 - progress_bar.py[line:272] - INFO: epoch 029:    588 / 866 loss=2.055, loss_v1=0, loss_v2=0, nll_loss=0.815, ntokens=2074.5, nsentences=64, sample_size=2074.5, sample_size_v1=0, sample_size_v2=0, ppl=1.76, wps=517, ups=0.25, wpb=2074.5, bsz=64, num_updates=24790, lr=1.4618e-06, gnorm=6.965, clip=100, loss_scale=32, train_wall=40, gb_free=7.8, wall=100245
2023-05-09 03:47:25 - progress_bar.py[line:272] - INFO: epoch 029:    598 / 866 loss=2.014, loss_v1=0, loss_v2=0, nll_loss=0.769, ntokens=2145.5, nsentences=64, sample_size=2145.5, sample_size_v1=0, sample_size_v2=0, ppl=1.7, wps=531.9, ups=0.25, wpb=2145.5, bsz=64, num_updates=24800, lr=1.44951e-06, gnorm=6.484, clip=100, loss_scale=32, train_wall=40, gb_free=8.4, wall=100286
2023-05-09 03:48:05 - progress_bar.py[line:272] - INFO: epoch 029:    608 / 866 loss=2.015, loss_v1=0, loss_v2=0, nll_loss=0.77, ntokens=1989.2, nsentences=64, sample_size=1989.2, sample_size_v1=0, sample_size_v2=0, ppl=1.71, wps=497.6, ups=0.25, wpb=1989.2, bsz=64, num_updates=24810, lr=1.43723e-06, gnorm=6.808, clip=100, loss_scale=32, train_wall=40, gb_free=7.4, wall=100326
2023-05-09 03:48:44 - progress_bar.py[line:272] - INFO: epoch 029:    618 / 866 loss=2.052, loss_v1=0, loss_v2=0, nll_loss=0.813, ntokens=1954.5, nsentences=64, sample_size=1954.5, sample_size_v1=0, sample_size_v2=0, ppl=1.76, wps=490.5, ups=0.25, wpb=1954.5, bsz=64, num_updates=24820, lr=1.42494e-06, gnorm=7.053, clip=100, loss_scale=32, train_wall=40, gb_free=8.1, wall=100366
2023-05-09 03:49:25 - progress_bar.py[line:272] - INFO: epoch 029:    628 / 866 loss=2.026, loss_v1=0, loss_v2=0, nll_loss=0.782, ntokens=2038.9, nsentences=64, sample_size=2038.9, sample_size_v1=0, sample_size_v2=0, ppl=1.72, wps=507.8, ups=0.25, wpb=2038.9, bsz=64, num_updates=24830, lr=1.41266e-06, gnorm=7.099, clip=100, loss_scale=32, train_wall=40, gb_free=8.1, wall=100406
2023-05-09 03:50:05 - progress_bar.py[line:272] - INFO: epoch 029:    638 / 866 loss=2.02, loss_v1=0, loss_v2=0, nll_loss=0.776, ntokens=2076.7, nsentences=64, sample_size=2076.7, sample_size_v1=0, sample_size_v2=0, ppl=1.71, wps=519, ups=0.25, wpb=2076.7, bsz=64, num_updates=24840, lr=1.40038e-06, gnorm=7.056, clip=100, loss_scale=32, train_wall=40, gb_free=8.1, wall=100446
2023-05-09 03:50:44 - progress_bar.py[line:272] - INFO: epoch 029:    648 / 866 loss=2.032, loss_v1=0, loss_v2=0, nll_loss=0.789, ntokens=2031.8, nsentences=64, sample_size=2031.8, sample_size_v1=0, sample_size_v2=0, ppl=1.73, wps=511.8, ups=0.25, wpb=2031.8, bsz=64, num_updates=24850, lr=1.38809e-06, gnorm=6.737, clip=100, loss_scale=32, train_wall=40, gb_free=7.9, wall=100485
2023-05-09 03:51:24 - progress_bar.py[line:272] - INFO: epoch 029:    658 / 866 loss=2.056, loss_v1=0, loss_v2=0, nll_loss=0.816, ntokens=1925.9, nsentences=64, sample_size=1925.9, sample_size_v1=0, sample_size_v2=0, ppl=1.76, wps=482.5, ups=0.25, wpb=1925.9, bsz=64, num_updates=24860, lr=1.37581e-06, gnorm=7.203, clip=100, loss_scale=32, train_wall=40, gb_free=7.7, wall=100525
2023-05-09 03:52:04 - progress_bar.py[line:272] - INFO: epoch 029:    668 / 866 loss=2.044, loss_v1=0, loss_v2=0, nll_loss=0.804, ntokens=1987.1, nsentences=64, sample_size=1987.1, sample_size_v1=0, sample_size_v2=0, ppl=1.75, wps=494.6, ups=0.25, wpb=1987.1, bsz=64, num_updates=24870, lr=1.36352e-06, gnorm=6.99, clip=100, loss_scale=64, train_wall=40, gb_free=7.3, wall=100566
2023-05-09 03:52:44 - progress_bar.py[line:272] - INFO: epoch 029:    678 / 866 loss=2.031, loss_v1=0, loss_v2=0, nll_loss=0.788, ntokens=2078.2, nsentences=64, sample_size=2078.2, sample_size_v1=0, sample_size_v2=0, ppl=1.73, wps=520.6, ups=0.25, wpb=2078.2, bsz=64, num_updates=24880, lr=1.35124e-06, gnorm=6.899, clip=100, loss_scale=64, train_wall=40, gb_free=7.9, wall=100605
2023-05-09 03:53:24 - progress_bar.py[line:272] - INFO: epoch 029:    688 / 866 loss=2.031, loss_v1=0, loss_v2=0, nll_loss=0.788, ntokens=1984.8, nsentences=64, sample_size=1984.8, sample_size_v1=0, sample_size_v2=0, ppl=1.73, wps=498.2, ups=0.25, wpb=1984.8, bsz=64, num_updates=24890, lr=1.33896e-06, gnorm=6.896, clip=100, loss_scale=64, train_wall=40, gb_free=8.1, wall=100645
2023-05-09 03:54:04 - progress_bar.py[line:272] - INFO: epoch 029:    698 / 866 loss=2.051, loss_v1=0, loss_v2=0, nll_loss=0.81, ntokens=2119.6, nsentences=64, sample_size=2119.6, sample_size_v1=0, sample_size_v2=0, ppl=1.75, wps=528, ups=0.25, wpb=2119.6, bsz=64, num_updates=24900, lr=1.32667e-06, gnorm=6.61, clip=100, loss_scale=64, train_wall=40, gb_free=8.1, wall=100685
2023-05-09 03:54:44 - progress_bar.py[line:272] - INFO: epoch 029:    708 / 866 loss=2.042, loss_v1=0, loss_v2=0, nll_loss=0.801, ntokens=1968.4, nsentences=64, sample_size=1968.4, sample_size_v1=0, sample_size_v2=0, ppl=1.74, wps=493.8, ups=0.25, wpb=1968.4, bsz=64, num_updates=24910, lr=1.31439e-06, gnorm=6.718, clip=100, loss_scale=64, train_wall=40, gb_free=8.1, wall=100725
2023-05-09 03:55:24 - progress_bar.py[line:272] - INFO: epoch 029:    718 / 866 loss=2.029, loss_v1=0, loss_v2=0, nll_loss=0.785, ntokens=1904, nsentences=64, sample_size=1904, sample_size_v1=0, sample_size_v2=0, ppl=1.72, wps=477.8, ups=0.25, wpb=1904, bsz=64, num_updates=24920, lr=1.3021e-06, gnorm=7.119, clip=100, loss_scale=64, train_wall=40, gb_free=8.4, wall=100765
2023-05-09 03:56:04 - progress_bar.py[line:272] - INFO: epoch 029:    728 / 866 loss=2.004, loss_v1=0, loss_v2=0, nll_loss=0.756, ntokens=2000.2, nsentences=64, sample_size=2000.2, sample_size_v1=0, sample_size_v2=0, ppl=1.69, wps=501.4, ups=0.25, wpb=2000.2, bsz=64, num_updates=24930, lr=1.28982e-06, gnorm=6.538, clip=100, loss_scale=64, train_wall=40, gb_free=7.7, wall=100805
2023-05-09 03:56:44 - progress_bar.py[line:272] - INFO: epoch 029:    738 / 866 loss=2.033, loss_v1=0, loss_v2=0, nll_loss=0.79, ntokens=2072.1, nsentences=64, sample_size=2072.1, sample_size_v1=0, sample_size_v2=0, ppl=1.73, wps=518.1, ups=0.25, wpb=2072.1, bsz=64, num_updates=24940, lr=1.27754e-06, gnorm=6.886, clip=100, loss_scale=64, train_wall=40, gb_free=8, wall=100845
2023-05-09 03:57:24 - progress_bar.py[line:272] - INFO: epoch 029:    748 / 866 loss=2.014, loss_v1=0, loss_v2=0, nll_loss=0.769, ntokens=2155.4, nsentences=64, sample_size=2155.4, sample_size_v1=0, sample_size_v2=0, ppl=1.7, wps=535.4, ups=0.25, wpb=2155.4, bsz=64, num_updates=24950, lr=1.26525e-06, gnorm=6.339, clip=100, loss_scale=64, train_wall=40, gb_free=8, wall=100885
2023-05-09 03:58:04 - progress_bar.py[line:272] - INFO: epoch 029:    758 / 866 loss=2.021, loss_v1=0, loss_v2=0, nll_loss=0.777, ntokens=2038.7, nsentences=64, sample_size=2038.7, sample_size_v1=0, sample_size_v2=0, ppl=1.71, wps=510.3, ups=0.25, wpb=2038.7, bsz=64, num_updates=24960, lr=1.25297e-06, gnorm=7.008, clip=100, loss_scale=64, train_wall=40, gb_free=7.8, wall=100925
2023-05-09 03:58:44 - progress_bar.py[line:272] - INFO: epoch 029:    768 / 866 loss=2.016, loss_v1=0, loss_v2=0, nll_loss=0.771, ntokens=2125.8, nsentences=64, sample_size=2125.8, sample_size_v1=0, sample_size_v2=0, ppl=1.71, wps=530.9, ups=0.25, wpb=2125.8, bsz=64, num_updates=24970, lr=1.24068e-06, gnorm=6.583, clip=100, loss_scale=64, train_wall=40, gb_free=7.7, wall=100965
2023-05-09 03:59:24 - progress_bar.py[line:272] - INFO: epoch 029:    778 / 866 loss=2.037, loss_v1=0, loss_v2=0, nll_loss=0.796, ntokens=2262.1, nsentences=64, sample_size=2262.1, sample_size_v1=0, sample_size_v2=0, ppl=1.74, wps=563.5, ups=0.25, wpb=2262.1, bsz=64, num_updates=24980, lr=1.2284e-06, gnorm=6.766, clip=100, loss_scale=64, train_wall=40, gb_free=8.3, wall=101005
2023-05-09 04:00:04 - progress_bar.py[line:272] - INFO: epoch 029:    788 / 866 loss=2.034, loss_v1=0, loss_v2=0, nll_loss=0.792, ntokens=2004.5, nsentences=64, sample_size=2004.5, sample_size_v1=0, sample_size_v2=0, ppl=1.73, wps=502.8, ups=0.25, wpb=2004.5, bsz=64, num_updates=24990, lr=1.21612e-06, gnorm=7.313, clip=100, loss_scale=64, train_wall=40, gb_free=7.4, wall=101045
2023-05-09 04:00:44 - progress_bar.py[line:272] - INFO: epoch 029:    798 / 866 loss=2.042, loss_v1=0, loss_v2=0, nll_loss=0.801, ntokens=2086.3, nsentences=64, sample_size=2086.3, sample_size_v1=0, sample_size_v2=0, ppl=1.74, wps=520.4, ups=0.25, wpb=2086.3, bsz=64, num_updates=25000, lr=1.20383e-06, gnorm=7.056, clip=100, loss_scale=64, train_wall=40, gb_free=7.9, wall=101085
2023-05-09 04:01:24 - progress_bar.py[line:272] - INFO: epoch 029:    808 / 866 loss=2.017, loss_v1=0, loss_v2=0, nll_loss=0.771, ntokens=1960.4, nsentences=64, sample_size=1960.4, sample_size_v1=0, sample_size_v2=0, ppl=1.71, wps=491.2, ups=0.25, wpb=1960.4, bsz=64, num_updates=25010, lr=1.19155e-06, gnorm=7.025, clip=100, loss_scale=64, train_wall=40, gb_free=7.9, wall=101125
2023-05-09 04:02:04 - progress_bar.py[line:272] - INFO: epoch 029:    818 / 866 loss=2.009, loss_v1=0, loss_v2=0, nll_loss=0.762, ntokens=2086.6, nsentences=64, sample_size=2086.6, sample_size_v1=0, sample_size_v2=0, ppl=1.7, wps=518.3, ups=0.25, wpb=2086.6, bsz=64, num_updates=25020, lr=1.17926e-06, gnorm=7.027, clip=100, loss_scale=64, train_wall=40, gb_free=7.8, wall=101166
2023-05-09 04:02:45 - progress_bar.py[line:272] - INFO: epoch 029:    828 / 866 loss=2.005, loss_v1=0, loss_v2=0, nll_loss=0.758, ntokens=2166.7, nsentences=64, sample_size=2166.7, sample_size_v1=0, sample_size_v2=0, ppl=1.69, wps=533.4, ups=0.25, wpb=2166.7, bsz=64, num_updates=25030, lr=1.16698e-06, gnorm=6.293, clip=100, loss_scale=64, train_wall=41, gb_free=8.1, wall=101206
2023-05-09 04:03:26 - progress_bar.py[line:272] - INFO: epoch 029:    838 / 866 loss=2.014, loss_v1=0, loss_v2=0, nll_loss=0.769, ntokens=2156.5, nsentences=64, sample_size=2156.5, sample_size_v1=0, sample_size_v2=0, ppl=1.7, wps=533.2, ups=0.25, wpb=2156.5, bsz=64, num_updates=25040, lr=1.1547e-06, gnorm=6.355, clip=100, loss_scale=64, train_wall=40, gb_free=8, wall=101247
2023-05-09 04:04:06 - progress_bar.py[line:272] - INFO: epoch 029:    848 / 866 loss=2.018, loss_v1=0, loss_v2=0, nll_loss=0.774, ntokens=2196.7, nsentences=64, sample_size=2196.7, sample_size_v1=0, sample_size_v2=0, ppl=1.71, wps=544.6, ups=0.25, wpb=2196.7, bsz=64, num_updates=25050, lr=1.14241e-06, gnorm=6.474, clip=100, loss_scale=64, train_wall=40, gb_free=7, wall=101287
2023-05-09 04:04:46 - progress_bar.py[line:272] - INFO: epoch 029:    858 / 866 loss=2, loss_v1=0, loss_v2=0, nll_loss=0.752, ntokens=2061.2, nsentences=64, sample_size=2061.2, sample_size_v1=0, sample_size_v2=0, ppl=1.68, wps=514.8, ups=0.25, wpb=2061.2, bsz=64, num_updates=25060, lr=1.13013e-06, gnorm=6.555, clip=100, loss_scale=64, train_wall=40, gb_free=8, wall=101327
2023-05-09 04:05:16 - train.py[line:332] - INFO: end of epoch 29 (average epoch stats below)
local datafile ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 1 begin to initialize row_count and line_idx-to-offset mapping
2023-05-09 04:05:16 - progress_bar.py[line:282] - INFO: epoch 029 | loss 2.019 | loss_v1 0 | loss_v2 0 | nll_loss 0.775 | ntokens 2102.83 | nsentences 63.972 | sample_size 2102.83 | sample_size_v1 0 | sample_size_v2 0 | ppl 1.71 | wps 521.5 | ups 0.25 | wpb 2102.8 | bsz 64 | num_updates 25068 | lr 1.1203e-06 | gnorm 6.792 | clip 100 | loss_scale 64 | train_wall 3482 | gb_free 8.7 | wall 101358
2023-05-09 04:05:16 - trainer.py[line:639] - INFO: loading train data for epoch 30
local datafile ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 0 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 1 finished initializing row_count and line_idx-to-offset mapping
file ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 1 row count 27700 total row count 55400
slice_id 1 seek offset 27700
local datafile ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 0 finished initializing row_count and line_idx-to-offset mapping
file ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 0 row count 27700 total row count 55400
slice_id 0 seek offset 0
2023-05-09 04:05:18 - trainer.py[line:703] - INFO: begin training epoch 30
2023-05-09 04:05:18 - train.py[line:305] - INFO: Start iterating over samples
2023-05-09 04:05:27 - progress_bar.py[line:272] - INFO: epoch 030:      2 / 866 loss=2.052, loss_v1=0, loss_v2=0, nll_loss=0.812, ntokens=2068.6, nsentences=61.6, sample_size=2068.6, sample_size_v1=0, sample_size_v2=0, ppl=1.76, wps=506.8, ups=0.24, wpb=2068.6, bsz=61.6, num_updates=25070, lr=1.11784e-06, gnorm=6.926, clip=100, loss_scale=64, train_wall=39, gb_free=7.2, wall=101368
2023-05-09 04:06:07 - progress_bar.py[line:272] - INFO: epoch 030:     12 / 866 loss=1.993, loss_v1=0, loss_v2=0, nll_loss=0.745, ntokens=2074.7, nsentences=64, sample_size=2074.7, sample_size_v1=0, sample_size_v2=0, ppl=1.68, wps=513.6, ups=0.25, wpb=2074.7, bsz=64, num_updates=25080, lr=1.10556e-06, gnorm=7.281, clip=100, loss_scale=64, train_wall=40, gb_free=8, wall=101408
2023-05-09 04:06:48 - progress_bar.py[line:272] - INFO: epoch 030:     22 / 866 loss=1.984, loss_v1=0, loss_v2=0, nll_loss=0.737, ntokens=2062.9, nsentences=64, sample_size=2062.9, sample_size_v1=0, sample_size_v2=0, ppl=1.67, wps=510.2, ups=0.25, wpb=2062.9, bsz=64, num_updates=25090, lr=1.09328e-06, gnorm=7.175, clip=100, loss_scale=64, train_wall=40, gb_free=7.7, wall=101449
2023-05-09 04:07:28 - progress_bar.py[line:272] - INFO: epoch 030:     32 / 866 loss=1.976, loss_v1=0, loss_v2=0, nll_loss=0.726, ntokens=2052.7, nsentences=64, sample_size=2052.7, sample_size_v1=0, sample_size_v2=0, ppl=1.65, wps=507.7, ups=0.25, wpb=2052.7, bsz=64, num_updates=25100, lr=1.08099e-06, gnorm=7.115, clip=100, loss_scale=64, train_wall=40, gb_free=6.7, wall=101489
2023-05-09 04:08:09 - progress_bar.py[line:272] - INFO: epoch 030:     42 / 866 loss=1.953, loss_v1=0, loss_v2=0, nll_loss=0.701, ntokens=2166.2, nsentences=64, sample_size=2166.2, sample_size_v1=0, sample_size_v2=0, ppl=1.63, wps=529.7, ups=0.24, wpb=2166.2, bsz=64, num_updates=25110, lr=1.06871e-06, gnorm=6.815, clip=100, loss_scale=64, train_wall=41, gb_free=7.8, wall=101530
2023-05-09 04:08:49 - progress_bar.py[line:272] - INFO: epoch 030:     52 / 866 loss=1.985, loss_v1=0, loss_v2=0, nll_loss=0.736, ntokens=1980.2, nsentences=64, sample_size=1980.2, sample_size_v1=0, sample_size_v2=0, ppl=1.67, wps=489.4, ups=0.25, wpb=1980.2, bsz=64, num_updates=25120, lr=1.05642e-06, gnorm=7.173, clip=100, loss_scale=64, train_wall=40, gb_free=8, wall=101570
2023-05-09 04:09:30 - progress_bar.py[line:272] - INFO: epoch 030:     62 / 866 loss=1.906, loss_v1=0, loss_v2=0, nll_loss=0.647, ntokens=2226.9, nsentences=64, sample_size=2226.9, sample_size_v1=0, sample_size_v2=0, ppl=1.57, wps=547.1, ups=0.25, wpb=2226.9, bsz=64, num_updates=25130, lr=1.04414e-06, gnorm=6.048, clip=100, loss_scale=64, train_wall=41, gb_free=6.5, wall=101611
2023-05-09 04:10:12 - progress_bar.py[line:272] - INFO: epoch 030:     72 / 866 loss=1.937, loss_v1=0, loss_v2=0, nll_loss=0.682, ntokens=2446.2, nsentences=64, sample_size=2446.2, sample_size_v1=0, sample_size_v2=0, ppl=1.6, wps=582.9, ups=0.24, wpb=2446.2, bsz=64, num_updates=25140, lr=1.03186e-06, gnorm=6.294, clip=100, loss_scale=64, train_wall=42, gb_free=6.5, wall=101653
2023-05-09 04:10:53 - progress_bar.py[line:272] - INFO: epoch 030:     82 / 866 loss=1.971, loss_v1=0, loss_v2=0, nll_loss=0.72, ntokens=2236.1, nsentences=64, sample_size=2236.1, sample_size_v1=0, sample_size_v2=0, ppl=1.65, wps=541.4, ups=0.24, wpb=2236.1, bsz=64, num_updates=25150, lr=1.01957e-06, gnorm=7.4, clip=100, loss_scale=64, train_wall=41, gb_free=7.1, wall=101694
2023-05-09 04:11:34 - progress_bar.py[line:272] - INFO: epoch 030:     92 / 866 loss=1.963, loss_v1=0, loss_v2=0, nll_loss=0.711, ntokens=2133.1, nsentences=64, sample_size=2133.1, sample_size_v1=0, sample_size_v2=0, ppl=1.64, wps=522.2, ups=0.24, wpb=2133.1, bsz=64, num_updates=25160, lr=1.00729e-06, gnorm=6.59, clip=100, loss_scale=64, train_wall=41, gb_free=7.4, wall=101735
2023-05-09 04:12:14 - progress_bar.py[line:272] - INFO: epoch 030:    102 / 866 loss=1.991, loss_v1=0, loss_v2=0, nll_loss=0.744, ntokens=2053.1, nsentences=64, sample_size=2053.1, sample_size_v1=0, sample_size_v2=0, ppl=1.67, wps=509.8, ups=0.25, wpb=2053.1, bsz=64, num_updates=25170, lr=9.95005e-07, gnorm=7.114, clip=100, loss_scale=64, train_wall=40, gb_free=7.4, wall=101776
2023-05-09 04:12:55 - progress_bar.py[line:272] - INFO: epoch 030:    112 / 866 loss=2.03, loss_v1=0, loss_v2=0, nll_loss=0.788, ntokens=2059.9, nsentences=64, sample_size=2059.9, sample_size_v1=0, sample_size_v2=0, ppl=1.73, wps=510.8, ups=0.25, wpb=2059.9, bsz=64, num_updates=25180, lr=9.8272e-07, gnorm=7.233, clip=100, loss_scale=64, train_wall=40, gb_free=6.3, wall=101816
2023-05-09 04:13:36 - progress_bar.py[line:272] - INFO: epoch 030:    122 / 866 loss=2.031, loss_v1=0, loss_v2=0, nll_loss=0.789, ntokens=2153.6, nsentences=64, sample_size=2153.6, sample_size_v1=0, sample_size_v2=0, ppl=1.73, wps=526.5, ups=0.24, wpb=2153.6, bsz=64, num_updates=25190, lr=9.70436e-07, gnorm=7.496, clip=100, loss_scale=64, train_wall=41, gb_free=6.9, wall=101857
2023-05-09 04:14:17 - progress_bar.py[line:272] - INFO: epoch 030:    132 / 866 loss=2.01, loss_v1=0, loss_v2=0, nll_loss=0.764, ntokens=2226.4, nsentences=64, sample_size=2226.4, sample_size_v1=0, sample_size_v2=0, ppl=1.7, wps=539.6, ups=0.24, wpb=2226.4, bsz=64, num_updates=25200, lr=9.58152e-07, gnorm=6.982, clip=100, loss_scale=64, train_wall=41, gb_free=6.9, wall=101898
2023-05-09 04:14:58 - progress_bar.py[line:272] - INFO: epoch 030:    142 / 866 loss=1.986, loss_v1=0, loss_v2=0, nll_loss=0.738, ntokens=2247.7, nsentences=64, sample_size=2247.7, sample_size_v1=0, sample_size_v2=0, ppl=1.67, wps=547.5, ups=0.24, wpb=2247.7, bsz=64, num_updates=25210, lr=9.45868e-07, gnorm=6.404, clip=100, loss_scale=64, train_wall=41, gb_free=7, wall=101939
2023-05-09 04:15:39 - progress_bar.py[line:272] - INFO: epoch 030:    152 / 866 loss=1.991, loss_v1=0, loss_v2=0, nll_loss=0.742, ntokens=2190.1, nsentences=64, sample_size=2190.1, sample_size_v1=0, sample_size_v2=0, ppl=1.67, wps=530.2, ups=0.24, wpb=2190.1, bsz=64, num_updates=25220, lr=9.33584e-07, gnorm=6.837, clip=100, loss_scale=64, train_wall=41, gb_free=6.9, wall=101980
2023-05-09 04:16:20 - progress_bar.py[line:272] - INFO: epoch 030:    162 / 866 loss=2.016, loss_v1=0, loss_v2=0, nll_loss=0.771, ntokens=2159.5, nsentences=64, sample_size=2159.5, sample_size_v1=0, sample_size_v2=0, ppl=1.71, wps=527.1, ups=0.24, wpb=2159.5, bsz=64, num_updates=25230, lr=9.213e-07, gnorm=7.182, clip=100, loss_scale=64, train_wall=41, gb_free=7.2, wall=102021
2023-05-09 04:17:01 - progress_bar.py[line:272] - INFO: epoch 030:    172 / 866 loss=2.023, loss_v1=0, loss_v2=0, nll_loss=0.78, ntokens=2057.6, nsentences=64, sample_size=2057.6, sample_size_v1=0, sample_size_v2=0, ppl=1.72, wps=511.7, ups=0.25, wpb=2057.6, bsz=64, num_updates=25240, lr=9.09016e-07, gnorm=7.627, clip=100, loss_scale=64, train_wall=40, gb_free=7.5, wall=102062
2023-05-09 04:17:42 - progress_bar.py[line:272] - INFO: epoch 030:    182 / 866 loss=1.995, loss_v1=0, loss_v2=0, nll_loss=0.748, ntokens=2189.4, nsentences=64, sample_size=2189.4, sample_size_v1=0, sample_size_v2=0, ppl=1.68, wps=532.2, ups=0.24, wpb=2189.4, bsz=64, num_updates=25250, lr=8.96732e-07, gnorm=7.011, clip=100, loss_scale=64, train_wall=41, gb_free=7.3, wall=102103
2023-05-09 04:18:10 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2023-05-09 04:18:27 - progress_bar.py[line:272] - INFO: epoch 030:    193 / 866 loss=2.012, loss_v1=0, loss_v2=0, nll_loss=0.768, ntokens=2217.3, nsentences=64, sample_size=2217.3, sample_size_v1=0, sample_size_v2=0, ppl=1.7, wps=494.7, ups=0.22, wpb=2217.3, bsz=64, num_updates=25260, lr=8.84448e-07, gnorm=6.934, clip=100, loss_scale=32, train_wall=45, gb_free=7.3, wall=102148
2023-05-09 04:19:07 - progress_bar.py[line:272] - INFO: epoch 030:    203 / 866 loss=2.022, loss_v1=0, loss_v2=0, nll_loss=0.779, ntokens=2075.5, nsentences=64, sample_size=2075.5, sample_size_v1=0, sample_size_v2=0, ppl=1.72, wps=511.5, ups=0.25, wpb=2075.5, bsz=64, num_updates=25270, lr=8.72164e-07, gnorm=7.292, clip=100, loss_scale=32, train_wall=41, gb_free=7.6, wall=102188
2023-05-09 04:19:48 - progress_bar.py[line:272] - INFO: epoch 030:    213 / 866 loss=2.025, loss_v1=0, loss_v2=0, nll_loss=0.781, ntokens=2063.9, nsentences=64, sample_size=2063.9, sample_size_v1=0, sample_size_v2=0, ppl=1.72, wps=510.6, ups=0.25, wpb=2063.9, bsz=64, num_updates=25280, lr=8.5988e-07, gnorm=6.674, clip=100, loss_scale=32, train_wall=40, gb_free=7.6, wall=102229
2023-05-09 04:20:28 - progress_bar.py[line:272] - INFO: epoch 030:    223 / 866 loss=2.024, loss_v1=0, loss_v2=0, nll_loss=0.78, ntokens=2222.1, nsentences=64, sample_size=2222.1, sample_size_v1=0, sample_size_v2=0, ppl=1.72, wps=550.3, ups=0.25, wpb=2222.1, bsz=64, num_updates=25290, lr=8.47596e-07, gnorm=6.486, clip=100, loss_scale=32, train_wall=40, gb_free=7.7, wall=102269
2023-05-09 04:21:08 - progress_bar.py[line:272] - INFO: epoch 030:    233 / 866 loss=2.04, loss_v1=0, loss_v2=0, nll_loss=0.799, ntokens=2107.2, nsentences=64, sample_size=2107.2, sample_size_v1=0, sample_size_v2=0, ppl=1.74, wps=528, ups=0.25, wpb=2107.2, bsz=64, num_updates=25300, lr=8.35312e-07, gnorm=7.304, clip=100, loss_scale=32, train_wall=40, gb_free=8.2, wall=102309
2023-05-09 04:21:48 - progress_bar.py[line:272] - INFO: epoch 030:    243 / 866 loss=2.033, loss_v1=0, loss_v2=0, nll_loss=0.79, ntokens=2185.9, nsentences=64, sample_size=2185.9, sample_size_v1=0, sample_size_v2=0, ppl=1.73, wps=542.2, ups=0.25, wpb=2185.9, bsz=64, num_updates=25310, lr=8.23028e-07, gnorm=6.507, clip=100, loss_scale=32, train_wall=40, gb_free=7.9, wall=102349
2023-05-09 04:22:28 - progress_bar.py[line:272] - INFO: epoch 030:    253 / 866 loss=2.044, loss_v1=0, loss_v2=0, nll_loss=0.803, ntokens=2123.8, nsentences=64, sample_size=2123.8, sample_size_v1=0, sample_size_v2=0, ppl=1.74, wps=527.6, ups=0.25, wpb=2123.8, bsz=64, num_updates=25320, lr=8.10744e-07, gnorm=6.617, clip=100, loss_scale=32, train_wall=40, gb_free=7.1, wall=102389
2023-05-09 04:23:09 - progress_bar.py[line:272] - INFO: epoch 030:    263 / 866 loss=2.04, loss_v1=0, loss_v2=0, nll_loss=0.798, ntokens=2145.7, nsentences=64, sample_size=2145.7, sample_size_v1=0, sample_size_v2=0, ppl=1.74, wps=532.9, ups=0.25, wpb=2145.7, bsz=64, num_updates=25330, lr=7.9846e-07, gnorm=6.536, clip=100, loss_scale=32, train_wall=40, gb_free=7.1, wall=102430
2023-05-09 04:23:49 - progress_bar.py[line:272] - INFO: epoch 030:    273 / 866 loss=2.023, loss_v1=0, loss_v2=0, nll_loss=0.779, ntokens=2144.3, nsentences=64, sample_size=2144.3, sample_size_v1=0, sample_size_v2=0, ppl=1.72, wps=532.1, ups=0.25, wpb=2144.3, bsz=64, num_updates=25340, lr=7.86176e-07, gnorm=6.67, clip=100, loss_scale=32, train_wall=40, gb_free=7.2, wall=102470
2023-05-09 04:24:29 - progress_bar.py[line:272] - INFO: epoch 030:    283 / 866 loss=2.044, loss_v1=0, loss_v2=0, nll_loss=0.803, ntokens=2148.3, nsentences=64, sample_size=2148.3, sample_size_v1=0, sample_size_v2=0, ppl=1.74, wps=531.9, ups=0.25, wpb=2148.3, bsz=64, num_updates=25350, lr=7.73892e-07, gnorm=6.53, clip=100, loss_scale=32, train_wall=40, gb_free=7.4, wall=102510
2023-05-09 04:25:09 - progress_bar.py[line:272] - INFO: epoch 030:    293 / 866 loss=2.012, loss_v1=0, loss_v2=0, nll_loss=0.767, ntokens=2141.2, nsentences=64, sample_size=2141.2, sample_size_v1=0, sample_size_v2=0, ppl=1.7, wps=534.2, ups=0.25, wpb=2141.2, bsz=64, num_updates=25360, lr=7.61608e-07, gnorm=6.446, clip=100, loss_scale=32, train_wall=40, gb_free=6.5, wall=102551
2023-05-09 04:25:49 - progress_bar.py[line:272] - INFO: epoch 030:    303 / 866 loss=2.013, loss_v1=0, loss_v2=0, nll_loss=0.768, ntokens=2142.7, nsentences=64, sample_size=2142.7, sample_size_v1=0, sample_size_v2=0, ppl=1.7, wps=534.9, ups=0.25, wpb=2142.7, bsz=64, num_updates=25370, lr=7.49324e-07, gnorm=6.958, clip=100, loss_scale=32, train_wall=40, gb_free=7.4, wall=102591
2023-05-09 04:26:30 - progress_bar.py[line:272] - INFO: epoch 030:    313 / 866 loss=2.02, loss_v1=0, loss_v2=0, nll_loss=0.775, ntokens=2106.8, nsentences=64, sample_size=2106.8, sample_size_v1=0, sample_size_v2=0, ppl=1.71, wps=525.6, ups=0.25, wpb=2106.8, bsz=64, num_updates=25380, lr=7.3704e-07, gnorm=6.502, clip=100, loss_scale=32, train_wall=40, gb_free=7.8, wall=102631
2023-05-09 04:27:09 - progress_bar.py[line:272] - INFO: epoch 030:    323 / 866 loss=2.032, loss_v1=0, loss_v2=0, nll_loss=0.789, ntokens=1985.8, nsentences=64, sample_size=1985.8, sample_size_v1=0, sample_size_v2=0, ppl=1.73, wps=498, ups=0.25, wpb=1985.8, bsz=64, num_updates=25390, lr=7.24756e-07, gnorm=7.171, clip=100, loss_scale=32, train_wall=40, gb_free=7.8, wall=102671
2023-05-09 04:27:49 - progress_bar.py[line:272] - INFO: epoch 030:    333 / 866 loss=2.014, loss_v1=0, loss_v2=0, nll_loss=0.769, ntokens=2134.8, nsentences=64, sample_size=2134.8, sample_size_v1=0, sample_size_v2=0, ppl=1.7, wps=534.3, ups=0.25, wpb=2134.8, bsz=64, num_updates=25400, lr=7.12472e-07, gnorm=6.492, clip=100, loss_scale=32, train_wall=40, gb_free=7.7, wall=102711
2023-05-09 04:28:29 - progress_bar.py[line:272] - INFO: epoch 030:    343 / 866 loss=2.008, loss_v1=0, loss_v2=0, nll_loss=0.762, ntokens=2000.4, nsentences=64, sample_size=2000.4, sample_size_v1=0, sample_size_v2=0, ppl=1.7, wps=500.1, ups=0.25, wpb=2000.4, bsz=64, num_updates=25410, lr=7.00188e-07, gnorm=6.81, clip=100, loss_scale=32, train_wall=40, gb_free=8.2, wall=102751
2023-05-09 04:29:09 - progress_bar.py[line:272] - INFO: epoch 030:    353 / 866 loss=2.049, loss_v1=0, loss_v2=0, nll_loss=0.807, ntokens=1984.7, nsentences=64, sample_size=1984.7, sample_size_v1=0, sample_size_v2=0, ppl=1.75, wps=498.8, ups=0.25, wpb=1984.7, bsz=64, num_updates=25420, lr=6.87904e-07, gnorm=6.873, clip=100, loss_scale=32, train_wall=40, gb_free=6.9, wall=102790
2023-05-09 04:29:49 - progress_bar.py[line:272] - INFO: epoch 030:    363 / 866 loss=2.045, loss_v1=0, loss_v2=0, nll_loss=0.804, ntokens=1971.5, nsentences=64, sample_size=1971.5, sample_size_v1=0, sample_size_v2=0, ppl=1.75, wps=490.6, ups=0.25, wpb=1971.5, bsz=64, num_updates=25430, lr=6.7562e-07, gnorm=6.992, clip=100, loss_scale=32, train_wall=40, gb_free=7.8, wall=102831
2023-05-09 04:30:29 - progress_bar.py[line:272] - INFO: epoch 030:    373 / 866 loss=2.012, loss_v1=0, loss_v2=0, nll_loss=0.767, ntokens=2020.9, nsentences=64, sample_size=2020.9, sample_size_v1=0, sample_size_v2=0, ppl=1.7, wps=506.4, ups=0.25, wpb=2020.9, bsz=64, num_updates=25440, lr=6.63336e-07, gnorm=6.806, clip=100, loss_scale=32, train_wall=40, gb_free=8.1, wall=102870
2023-05-09 04:31:09 - progress_bar.py[line:272] - INFO: epoch 030:    383 / 866 loss=2.026, loss_v1=0, loss_v2=0, nll_loss=0.783, ntokens=2159.1, nsentences=64, sample_size=2159.1, sample_size_v1=0, sample_size_v2=0, ppl=1.72, wps=541.2, ups=0.25, wpb=2159.1, bsz=64, num_updates=25450, lr=6.51052e-07, gnorm=6.374, clip=100, loss_scale=32, train_wall=40, gb_free=7.8, wall=102910
2023-05-09 04:31:49 - progress_bar.py[line:272] - INFO: epoch 030:    393 / 866 loss=2.041, loss_v1=0, loss_v2=0, nll_loss=0.799, ntokens=2036.6, nsentences=64, sample_size=2036.6, sample_size_v1=0, sample_size_v2=0, ppl=1.74, wps=510.3, ups=0.25, wpb=2036.6, bsz=64, num_updates=25460, lr=6.38768e-07, gnorm=7.14, clip=100, loss_scale=32, train_wall=40, gb_free=8.1, wall=102950
2023-05-09 04:32:29 - progress_bar.py[line:272] - INFO: epoch 030:    403 / 866 loss=2.027, loss_v1=0, loss_v2=0, nll_loss=0.783, ntokens=2108, nsentences=64, sample_size=2108, sample_size_v1=0, sample_size_v2=0, ppl=1.72, wps=524.5, ups=0.25, wpb=2108, bsz=64, num_updates=25470, lr=6.26484e-07, gnorm=6.733, clip=100, loss_scale=32, train_wall=40, gb_free=7.6, wall=102990
2023-05-09 04:33:09 - progress_bar.py[line:272] - INFO: epoch 030:    413 / 866 loss=2.02, loss_v1=0, loss_v2=0, nll_loss=0.777, ntokens=2140.1, nsentences=64, sample_size=2140.1, sample_size_v1=0, sample_size_v2=0, ppl=1.71, wps=535.1, ups=0.25, wpb=2140.1, bsz=64, num_updates=25480, lr=6.142e-07, gnorm=6.473, clip=100, loss_scale=32, train_wall=40, gb_free=7.7, wall=103030
2023-05-09 04:33:49 - progress_bar.py[line:272] - INFO: epoch 030:    423 / 866 loss=1.997, loss_v1=0, loss_v2=0, nll_loss=0.751, ntokens=2052.3, nsentences=64, sample_size=2052.3, sample_size_v1=0, sample_size_v2=0, ppl=1.68, wps=511.6, ups=0.25, wpb=2052.3, bsz=64, num_updates=25490, lr=6.01916e-07, gnorm=6.549, clip=100, loss_scale=32, train_wall=40, gb_free=7.4, wall=103071
2023-05-09 04:34:29 - progress_bar.py[line:272] - INFO: epoch 030:    433 / 866 loss=2.024, loss_v1=0, loss_v2=0, nll_loss=0.78, ntokens=2119, nsentences=64, sample_size=2119, sample_size_v1=0, sample_size_v2=0, ppl=1.72, wps=531, ups=0.25, wpb=2119, bsz=64, num_updates=25500, lr=5.89632e-07, gnorm=6.775, clip=100, loss_scale=32, train_wall=40, gb_free=8.1, wall=103110
2023-05-09 04:35:09 - progress_bar.py[line:272] - INFO: epoch 030:    443 / 866 loss=2.055, loss_v1=0, loss_v2=0, nll_loss=0.816, ntokens=2046.8, nsentences=64, sample_size=2046.8, sample_size_v1=0, sample_size_v2=0, ppl=1.76, wps=510.3, ups=0.25, wpb=2046.8, bsz=64, num_updates=25510, lr=5.77348e-07, gnorm=7.178, clip=100, loss_scale=32, train_wall=40, gb_free=8.1, wall=103151
2023-05-09 04:35:49 - progress_bar.py[line:272] - INFO: epoch 030:    453 / 866 loss=2.03, loss_v1=0, loss_v2=0, nll_loss=0.787, ntokens=2003, nsentences=64, sample_size=2003, sample_size_v1=0, sample_size_v2=0, ppl=1.73, wps=501.4, ups=0.25, wpb=2003, bsz=64, num_updates=25520, lr=5.65064e-07, gnorm=6.498, clip=100, loss_scale=32, train_wall=40, gb_free=8.2, wall=103191
2023-05-09 04:36:30 - progress_bar.py[line:272] - INFO: epoch 030:    463 / 866 loss=2.048, loss_v1=0, loss_v2=0, nll_loss=0.808, ntokens=2168.7, nsentences=64, sample_size=2168.7, sample_size_v1=0, sample_size_v2=0, ppl=1.75, wps=538.1, ups=0.25, wpb=2168.7, bsz=64, num_updates=25530, lr=5.5278e-07, gnorm=6.757, clip=100, loss_scale=32, train_wall=40, gb_free=7.9, wall=103231
2023-05-09 04:37:10 - progress_bar.py[line:272] - INFO: epoch 030:    473 / 866 loss=2.041, loss_v1=0, loss_v2=0, nll_loss=0.799, ntokens=2189.3, nsentences=64, sample_size=2189.3, sample_size_v1=0, sample_size_v2=0, ppl=1.74, wps=543.9, ups=0.25, wpb=2189.3, bsz=64, num_updates=25540, lr=5.40496e-07, gnorm=6.621, clip=100, loss_scale=32, train_wall=40, gb_free=6.6, wall=103271
2023-05-09 04:37:50 - progress_bar.py[line:272] - INFO: epoch 030:    483 / 866 loss=2.03, loss_v1=0, loss_v2=0, nll_loss=0.787, ntokens=2149.8, nsentences=64, sample_size=2149.8, sample_size_v1=0, sample_size_v2=0, ppl=1.73, wps=534.3, ups=0.25, wpb=2149.8, bsz=64, num_updates=25550, lr=5.28212e-07, gnorm=6.871, clip=100, loss_scale=32, train_wall=40, gb_free=7.9, wall=103311
2023-05-09 04:38:30 - progress_bar.py[line:272] - INFO: epoch 030:    493 / 866 loss=2.012, loss_v1=0, loss_v2=0, nll_loss=0.767, ntokens=2050.1, nsentences=64, sample_size=2050.1, sample_size_v1=0, sample_size_v2=0, ppl=1.7, wps=511.1, ups=0.25, wpb=2050.1, bsz=64, num_updates=25560, lr=5.15928e-07, gnorm=6.664, clip=100, loss_scale=32, train_wall=40, gb_free=8.1, wall=103351
2023-05-09 04:39:11 - progress_bar.py[line:272] - INFO: epoch 030:    503 / 866 loss=2.036, loss_v1=0, loss_v2=0, nll_loss=0.795, ntokens=2092.8, nsentences=64, sample_size=2092.8, sample_size_v1=0, sample_size_v2=0, ppl=1.73, wps=520.8, ups=0.25, wpb=2092.8, bsz=64, num_updates=25570, lr=5.03644e-07, gnorm=6.853, clip=100, loss_scale=32, train_wall=40, gb_free=8.1, wall=103392
2023-05-09 04:39:50 - progress_bar.py[line:272] - INFO: epoch 030:    513 / 866 loss=2.052, loss_v1=0, loss_v2=0, nll_loss=0.812, ntokens=2135.9, nsentences=64, sample_size=2135.9, sample_size_v1=0, sample_size_v2=0, ppl=1.76, wps=535.8, ups=0.25, wpb=2135.9, bsz=64, num_updates=25580, lr=4.9136e-07, gnorm=7.131, clip=100, loss_scale=32, train_wall=40, gb_free=8, wall=103431
2023-05-09 04:40:30 - progress_bar.py[line:272] - INFO: epoch 030:    523 / 866 loss=2.028, loss_v1=0, loss_v2=0, nll_loss=0.785, ntokens=2121.2, nsentences=64, sample_size=2121.2, sample_size_v1=0, sample_size_v2=0, ppl=1.72, wps=533.6, ups=0.25, wpb=2121.2, bsz=64, num_updates=25590, lr=4.79076e-07, gnorm=6.472, clip=100, loss_scale=32, train_wall=40, gb_free=8.2, wall=103471
2023-05-09 04:41:10 - progress_bar.py[line:272] - INFO: epoch 030:    533 / 866 loss=2.015, loss_v1=0, loss_v2=0, nll_loss=0.77, ntokens=2043.5, nsentences=64, sample_size=2043.5, sample_size_v1=0, sample_size_v2=0, ppl=1.71, wps=510.7, ups=0.25, wpb=2043.5, bsz=64, num_updates=25600, lr=4.66792e-07, gnorm=6.661, clip=100, loss_scale=32, train_wall=40, gb_free=8.2, wall=103511
2023-05-09 04:41:50 - progress_bar.py[line:272] - INFO: epoch 030:    543 / 866 loss=2.04, loss_v1=0, loss_v2=0, nll_loss=0.799, ntokens=2165.2, nsentences=64, sample_size=2165.2, sample_size_v1=0, sample_size_v2=0, ppl=1.74, wps=541, ups=0.25, wpb=2165.2, bsz=64, num_updates=25610, lr=4.54508e-07, gnorm=6.765, clip=100, loss_scale=32, train_wall=40, gb_free=7.7, wall=103551
2023-05-09 04:42:31 - progress_bar.py[line:272] - INFO: epoch 030:    553 / 866 loss=2.048, loss_v1=0, loss_v2=0, nll_loss=0.806, ntokens=2290, nsentences=64, sample_size=2290, sample_size_v1=0, sample_size_v2=0, ppl=1.75, wps=566.3, ups=0.25, wpb=2290, bsz=64, num_updates=25620, lr=4.42224e-07, gnorm=6.248, clip=100, loss_scale=32, train_wall=40, gb_free=8.1, wall=103592
2023-05-09 04:43:11 - progress_bar.py[line:272] - INFO: epoch 030:    563 / 866 loss=2.034, loss_v1=0, loss_v2=0, nll_loss=0.792, ntokens=2255.1, nsentences=64, sample_size=2255.1, sample_size_v1=0, sample_size_v2=0, ppl=1.73, wps=560.1, ups=0.25, wpb=2255.1, bsz=64, num_updates=25630, lr=4.2994e-07, gnorm=6.312, clip=100, loss_scale=32, train_wall=40, gb_free=8.4, wall=103632
2023-05-09 04:43:51 - progress_bar.py[line:272] - INFO: epoch 030:    573 / 866 loss=2.022, loss_v1=0, loss_v2=0, nll_loss=0.779, ntokens=2226.9, nsentences=64, sample_size=2226.9, sample_size_v1=0, sample_size_v2=0, ppl=1.72, wps=554.8, ups=0.25, wpb=2226.9, bsz=64, num_updates=25640, lr=4.17656e-07, gnorm=6.732, clip=100, loss_scale=32, train_wall=40, gb_free=7.3, wall=103672
2023-05-09 04:44:31 - progress_bar.py[line:272] - INFO: epoch 030:    583 / 866 loss=2.041, loss_v1=0, loss_v2=0, nll_loss=0.8, ntokens=2080.8, nsentences=64, sample_size=2080.8, sample_size_v1=0, sample_size_v2=0, ppl=1.74, wps=519.5, ups=0.25, wpb=2080.8, bsz=64, num_updates=25650, lr=4.05372e-07, gnorm=7.064, clip=100, loss_scale=32, train_wall=40, gb_free=8.2, wall=103712
2023-05-09 04:45:11 - progress_bar.py[line:272] - INFO: epoch 030:    593 / 866 loss=2.024, loss_v1=0, loss_v2=0, nll_loss=0.779, ntokens=2115.7, nsentences=64, sample_size=2115.7, sample_size_v1=0, sample_size_v2=0, ppl=1.72, wps=523.5, ups=0.25, wpb=2115.7, bsz=64, num_updates=25660, lr=3.93088e-07, gnorm=6.651, clip=100, loss_scale=32, train_wall=40, gb_free=8, wall=103753
2023-05-09 04:45:52 - progress_bar.py[line:272] - INFO: epoch 030:    603 / 866 loss=2.015, loss_v1=0, loss_v2=0, nll_loss=0.77, ntokens=2098.7, nsentences=64, sample_size=2098.7, sample_size_v1=0, sample_size_v2=0, ppl=1.71, wps=522.1, ups=0.25, wpb=2098.7, bsz=64, num_updates=25670, lr=3.80804e-07, gnorm=6.69, clip=100, loss_scale=32, train_wall=40, gb_free=7.8, wall=103793
2023-05-09 04:46:32 - progress_bar.py[line:272] - INFO: epoch 030:    613 / 866 loss=2.043, loss_v1=0, loss_v2=0, nll_loss=0.803, ntokens=1926.8, nsentences=64, sample_size=1926.8, sample_size_v1=0, sample_size_v2=0, ppl=1.74, wps=482.1, ups=0.25, wpb=1926.8, bsz=64, num_updates=25680, lr=3.6852e-07, gnorm=7.696, clip=100, loss_scale=32, train_wall=40, gb_free=8.3, wall=103833
2023-05-09 04:47:12 - progress_bar.py[line:272] - INFO: epoch 030:    623 / 866 loss=2.041, loss_v1=0, loss_v2=0, nll_loss=0.799, ntokens=2033.1, nsentences=64, sample_size=2033.1, sample_size_v1=0, sample_size_v2=0, ppl=1.74, wps=507.1, ups=0.25, wpb=2033.1, bsz=64, num_updates=25690, lr=3.56236e-07, gnorm=6.68, clip=100, loss_scale=32, train_wall=40, gb_free=7.4, wall=103873
2023-05-09 04:47:52 - progress_bar.py[line:272] - INFO: epoch 030:    633 / 866 loss=2.03, loss_v1=0, loss_v2=0, nll_loss=0.787, ntokens=2004.2, nsentences=64, sample_size=2004.2, sample_size_v1=0, sample_size_v2=0, ppl=1.73, wps=503.8, ups=0.25, wpb=2004.2, bsz=64, num_updates=25700, lr=3.43952e-07, gnorm=6.656, clip=100, loss_scale=32, train_wall=40, gb_free=7.9, wall=103913
2023-05-09 04:48:32 - progress_bar.py[line:272] - INFO: epoch 030:    643 / 866 loss=2.012, loss_v1=0, loss_v2=0, nll_loss=0.767, ntokens=2093.4, nsentences=64, sample_size=2093.4, sample_size_v1=0, sample_size_v2=0, ppl=1.7, wps=521.2, ups=0.25, wpb=2093.4, bsz=64, num_updates=25710, lr=3.31668e-07, gnorm=6.931, clip=100, loss_scale=32, train_wall=40, gb_free=8.1, wall=103953
2023-05-09 04:49:12 - progress_bar.py[line:272] - INFO: epoch 030:    653 / 866 loss=2.042, loss_v1=0, loss_v2=0, nll_loss=0.801, ntokens=1993.1, nsentences=64, sample_size=1993.1, sample_size_v1=0, sample_size_v2=0, ppl=1.74, wps=498.3, ups=0.25, wpb=1993.1, bsz=64, num_updates=25720, lr=3.19384e-07, gnorm=6.64, clip=100, loss_scale=32, train_wall=40, gb_free=8.3, wall=103993
2023-05-09 04:49:51 - progress_bar.py[line:272] - INFO: epoch 030:    663 / 866 loss=2.054, loss_v1=0, loss_v2=0, nll_loss=0.814, ntokens=1918.6, nsentences=64, sample_size=1918.6, sample_size_v1=0, sample_size_v2=0, ppl=1.76, wps=483.5, ups=0.25, wpb=1918.6, bsz=64, num_updates=25730, lr=3.071e-07, gnorm=7.205, clip=100, loss_scale=32, train_wall=40, gb_free=8, wall=104033
2023-05-09 04:50:31 - progress_bar.py[line:272] - INFO: epoch 030:    673 / 866 loss=2.04, loss_v1=0, loss_v2=0, nll_loss=0.798, ntokens=2027.7, nsentences=64, sample_size=2027.7, sample_size_v1=0, sample_size_v2=0, ppl=1.74, wps=507, ups=0.25, wpb=2027.7, bsz=64, num_updates=25740, lr=2.94816e-07, gnorm=6.936, clip=100, loss_scale=32, train_wall=40, gb_free=8.1, wall=104073
2023-05-09 04:51:11 - progress_bar.py[line:272] - INFO: epoch 030:    683 / 866 loss=2.025, loss_v1=0, loss_v2=0, nll_loss=0.781, ntokens=2046.4, nsentences=64, sample_size=2046.4, sample_size_v1=0, sample_size_v2=0, ppl=1.72, wps=513.7, ups=0.25, wpb=2046.4, bsz=64, num_updates=25750, lr=2.82532e-07, gnorm=7.047, clip=100, loss_scale=32, train_wall=40, gb_free=8.3, wall=104112
2023-05-09 04:51:51 - progress_bar.py[line:272] - INFO: epoch 030:    693 / 866 loss=2.04, loss_v1=0, loss_v2=0, nll_loss=0.799, ntokens=2056, nsentences=64, sample_size=2056, sample_size_v1=0, sample_size_v2=0, ppl=1.74, wps=512.2, ups=0.25, wpb=2056, bsz=64, num_updates=25760, lr=2.70248e-07, gnorm=7.098, clip=100, loss_scale=32, train_wall=40, gb_free=7.4, wall=104152
2023-05-09 04:52:31 - progress_bar.py[line:272] - INFO: epoch 030:    703 / 866 loss=2.036, loss_v1=0, loss_v2=0, nll_loss=0.794, ntokens=2024.1, nsentences=64, sample_size=2024.1, sample_size_v1=0, sample_size_v2=0, ppl=1.73, wps=506.9, ups=0.25, wpb=2024.1, bsz=64, num_updates=25770, lr=2.57964e-07, gnorm=6.658, clip=100, loss_scale=64, train_wall=40, gb_free=8.1, wall=104192
2023-05-09 04:53:11 - progress_bar.py[line:272] - INFO: epoch 030:    713 / 866 loss=2.036, loss_v1=0, loss_v2=0, nll_loss=0.793, ntokens=1917, nsentences=64, sample_size=1917, sample_size_v1=0, sample_size_v2=0, ppl=1.73, wps=479.9, ups=0.25, wpb=1917, bsz=64, num_updates=25780, lr=2.4568e-07, gnorm=6.594, clip=100, loss_scale=64, train_wall=40, gb_free=8.2, wall=104232
2023-05-09 04:53:51 - progress_bar.py[line:272] - INFO: epoch 030:    723 / 866 loss=2.011, loss_v1=0, loss_v2=0, nll_loss=0.765, ntokens=1956.9, nsentences=64, sample_size=1956.9, sample_size_v1=0, sample_size_v2=0, ppl=1.7, wps=489, ups=0.25, wpb=1956.9, bsz=64, num_updates=25790, lr=2.33396e-07, gnorm=6.596, clip=100, loss_scale=64, train_wall=40, gb_free=8.4, wall=104272
2023-05-09 04:54:31 - progress_bar.py[line:272] - INFO: epoch 030:    733 / 866 loss=2.016, loss_v1=0, loss_v2=0, nll_loss=0.77, ntokens=2031.5, nsentences=64, sample_size=2031.5, sample_size_v1=0, sample_size_v2=0, ppl=1.7, wps=507.5, ups=0.25, wpb=2031.5, bsz=64, num_updates=25800, lr=2.21112e-07, gnorm=6.575, clip=100, loss_scale=64, train_wall=40, gb_free=7.3, wall=104312
2023-05-09 04:55:11 - progress_bar.py[line:272] - INFO: epoch 030:    743 / 866 loss=2.028, loss_v1=0, loss_v2=0, nll_loss=0.784, ntokens=2149.2, nsentences=64, sample_size=2149.2, sample_size_v1=0, sample_size_v2=0, ppl=1.72, wps=535.5, ups=0.25, wpb=2149.2, bsz=64, num_updates=25810, lr=2.08828e-07, gnorm=6.736, clip=100, loss_scale=64, train_wall=40, gb_free=7.9, wall=104353
2023-05-09 04:55:51 - progress_bar.py[line:272] - INFO: epoch 030:    753 / 866 loss=2.014, loss_v1=0, loss_v2=0, nll_loss=0.769, ntokens=2078, nsentences=64, sample_size=2078, sample_size_v1=0, sample_size_v2=0, ppl=1.7, wps=520.2, ups=0.25, wpb=2078, bsz=64, num_updates=25820, lr=1.96544e-07, gnorm=6.43, clip=100, loss_scale=64, train_wall=40, gb_free=7.8, wall=104393
2023-05-09 04:56:32 - progress_bar.py[line:272] - INFO: epoch 030:    763 / 866 loss=2.019, loss_v1=0, loss_v2=0, nll_loss=0.774, ntokens=2147.9, nsentences=64, sample_size=2147.9, sample_size_v1=0, sample_size_v2=0, ppl=1.71, wps=534.4, ups=0.25, wpb=2147.9, bsz=64, num_updates=25830, lr=1.8426e-07, gnorm=6.292, clip=100, loss_scale=64, train_wall=40, gb_free=7.9, wall=104433
2023-05-09 04:57:11 - progress_bar.py[line:272] - INFO: epoch 030:    773 / 866 loss=2.034, loss_v1=0, loss_v2=0, nll_loss=0.792, ntokens=2095.5, nsentences=64, sample_size=2095.5, sample_size_v1=0, sample_size_v2=0, ppl=1.73, wps=526.2, ups=0.25, wpb=2095.5, bsz=64, num_updates=25840, lr=1.71976e-07, gnorm=6.722, clip=100, loss_scale=64, train_wall=40, gb_free=7.9, wall=104473
2023-05-09 04:57:52 - progress_bar.py[line:272] - INFO: epoch 030:    783 / 866 loss=2.028, loss_v1=0, loss_v2=0, nll_loss=0.785, ntokens=2224.5, nsentences=64, sample_size=2224.5, sample_size_v1=0, sample_size_v2=0, ppl=1.72, wps=551.6, ups=0.25, wpb=2224.5, bsz=64, num_updates=25850, lr=1.59692e-07, gnorm=6.809, clip=100, loss_scale=64, train_wall=40, gb_free=7.6, wall=104513
2023-05-09 04:58:32 - progress_bar.py[line:272] - INFO: epoch 030:    793 / 866 loss=2.046, loss_v1=0, loss_v2=0, nll_loss=0.806, ntokens=2005.5, nsentences=64, sample_size=2005.5, sample_size_v1=0, sample_size_v2=0, ppl=1.75, wps=498.2, ups=0.25, wpb=2005.5, bsz=64, num_updates=25860, lr=1.47408e-07, gnorm=7.097, clip=100, loss_scale=64, train_wall=40, gb_free=7.9, wall=104553
2023-05-09 04:59:12 - progress_bar.py[line:272] - INFO: epoch 030:    803 / 866 loss=2.03, loss_v1=0, loss_v2=0, nll_loss=0.786, ntokens=1972.7, nsentences=64, sample_size=1972.7, sample_size_v1=0, sample_size_v2=0, ppl=1.72, wps=496.3, ups=0.25, wpb=1972.7, bsz=64, num_updates=25870, lr=1.35124e-07, gnorm=6.829, clip=100, loss_scale=64, train_wall=40, gb_free=7.2, wall=104593
2023-05-09 04:59:52 - progress_bar.py[line:272] - INFO: epoch 030:    813 / 866 loss=2.008, loss_v1=0, loss_v2=0, nll_loss=0.762, ntokens=2109.3, nsentences=64, sample_size=2109.3, sample_size_v1=0, sample_size_v2=0, ppl=1.7, wps=527.2, ups=0.25, wpb=2109.3, bsz=64, num_updates=25880, lr=1.2284e-07, gnorm=6.866, clip=100, loss_scale=64, train_wall=40, gb_free=6.7, wall=104633
2023-05-09 05:00:32 - progress_bar.py[line:272] - INFO: epoch 030:    823 / 866 loss=2.018, loss_v1=0, loss_v2=0, nll_loss=0.772, ntokens=2101.2, nsentences=64, sample_size=2101.2, sample_size_v1=0, sample_size_v2=0, ppl=1.71, wps=522.9, ups=0.25, wpb=2101.2, bsz=64, num_updates=25890, lr=1.10556e-07, gnorm=6.788, clip=100, loss_scale=64, train_wall=40, gb_free=7.5, wall=104673
2023-05-09 05:01:13 - progress_bar.py[line:272] - INFO: epoch 030:    833 / 866 loss=2.001, loss_v1=0, loss_v2=0, nll_loss=0.755, ntokens=2208.2, nsentences=64, sample_size=2208.2, sample_size_v1=0, sample_size_v2=0, ppl=1.69, wps=542.9, ups=0.25, wpb=2208.2, bsz=64, num_updates=25900, lr=9.8272e-08, gnorm=6.214, clip=100, loss_scale=64, train_wall=41, gb_free=8.2, wall=104714
2023-05-09 05:01:53 - progress_bar.py[line:272] - INFO: epoch 030:    843 / 866 loss=2.012, loss_v1=0, loss_v2=0, nll_loss=0.766, ntokens=2121.2, nsentences=64, sample_size=2121.2, sample_size_v1=0, sample_size_v2=0, ppl=1.7, wps=528.8, ups=0.25, wpb=2121.2, bsz=64, num_updates=25910, lr=8.5988e-08, gnorm=6.528, clip=100, loss_scale=64, train_wall=40, gb_free=8.2, wall=104754
2023-05-09 05:02:33 - progress_bar.py[line:272] - INFO: epoch 030:    853 / 866 loss=2.003, loss_v1=0, loss_v2=0, nll_loss=0.757, ntokens=2191.4, nsentences=64, sample_size=2191.4, sample_size_v1=0, sample_size_v2=0, ppl=1.69, wps=543.3, ups=0.25, wpb=2191.4, bsz=64, num_updates=25920, lr=7.3704e-08, gnorm=6.317, clip=100, loss_scale=64, train_wall=40, gb_free=7.5, wall=104794
2023-05-09 05:03:13 - progress_bar.py[line:272] - INFO: epoch 030:    863 / 866 loss=2.024, loss_v1=0, loss_v2=0, nll_loss=0.78, ntokens=2023.2, nsentences=64, sample_size=2023.2, sample_size_v1=0, sample_size_v2=0, ppl=1.72, wps=506.3, ups=0.25, wpb=2023.2, bsz=64, num_updates=25930, lr=6.142e-08, gnorm=6.854, clip=100, loss_scale=64, train_wall=40, gb_free=7.7, wall=104834
slice_id 1 seek offset 11440
2023-05-09 05:03:24 - train.py[line:445] - INFO: begin validation on "valid" subset
slice_id 0 seek offset 0
slice_id 1 seek offset 11440
slice_id 0 seek offset 0
/home/zcai75/Github/OFA/fairseq/fairseq/search.py:140: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  beams_buf = indices_buf // vocab_size
/home/zcai75/Github/OFA/fairseq/fairseq/search.py:140: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  beams_buf = indices_buf // vocab_size
/home/zcai75/Github/OFA_forked/models/sequence_generator.py:705: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  unfin_idx = bbsz_idx // beam_size
/home/zcai75/Github/OFA_forked/models/sequence_generator.py:705: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  unfin_idx = bbsz_idx // beam_size
2343729 <sub> train<pred> on<obj> track<sub> window<pred> on<obj> train<sub> window<pred> on<obj> train<sub> door<pred> on<obj> train ['<sub> windshield<pred> on<obj> train<sub> window<pred> on<obj> train<sub> train<pred> has<obj> window<sub> house<pred> near<obj> train<sub> tree<pred> near<obj> house']
2325977 <sub> window<pred> on<obj> bus<sub> window<pred> on<obj> bus<sub> tire<pred> on<obj> bus<sub> window<pred> on<obj> bus ['<sub> head<pred> of<obj> bear<sub> bear<pred> in<obj> bowl<sub> bowl<pred> with<obj> bear']
2023-05-09 05:03:40 - progress_bar.py[line:272] - INFO: epoch 030 | valid on 'valid' subset:     11 / 2860 loss=2.634, loss_v1=0, loss_v2=0, nll_loss=1.449, ntokens=292, nsentences=8, sample_size=292.0, sample_size_v1=0, sample_size_v2=0
2023-05-09 05:03:55 - progress_bar.py[line:272] - INFO: epoch 030 | valid on 'valid' subset:     21 / 2860 loss=2.655, loss_v1=0, loss_v2=0, nll_loss=1.467, ntokens=299, nsentences=8, sample_size=299.0, sample_size_v1=0, sample_size_v2=0
2023-05-09 05:04:08 - progress_bar.py[line:272] - INFO: epoch 030 | valid on 'valid' subset:     31 / 2860 loss=2.502, loss_v1=0, loss_v2=0, nll_loss=1.292, ntokens=319, nsentences=8, sample_size=319.0, sample_size_v1=0, sample_size_v2=0
2023-05-09 05:04:23 - progress_bar.py[line:272] - INFO: epoch 030 | valid on 'valid' subset:     41 / 2860 loss=2.402, loss_v1=0, loss_v2=0, nll_loss=1.184, ntokens=251, nsentences=8, sample_size=251.0, sample_size_v1=0, sample_size_v2=0
2343478 <sub> boy<pred> has<obj> hair<pred> wearing<obj> shirt<pred> wearing<obj> pant<pred> wearing<obj> shoe<pred> wearing<obj> shoe<pred> has<obj> arm<pred> has<obj> arm<pred> has<obj> arm<sub> window<pred> on<obj> building<sub> window<pred> on<obj> building<sub> window<pred> on<obj> building ['<sub> girl<pred> wearing<obj> helmet<pred> wearing<obj> short<pred> wearing<obj> shirt<pred> wearing<obj> sock<pred> wearing<obj> sock<sub> man<pred> wearing<obj> shirt<pred> has<obj> head<pred> has<obj> arm<pred> has<obj> hand<pred> has<obj> hand<pred> has<obj> leg<sub> child<pred> behind<obj> fence<sub> woman<pred> behind<obj> fence<sub> bench<pred> behind<obj> fence']
2325675 <sub> man<pred> holding<obj> phone<pred> has<obj> hair<pred> wearing<obj> shirt<pred> has<obj> nose<sub> phone<pred> in<obj> hand<sub> hand<pred> holding<obj> phone<sub> phone<pred> in<obj> hand ['<sub> man<pred> wearing<obj> pant<sub> cat<pred> in<obj> drawer']
2023-05-09 05:04:38 - progress_bar.py[line:272] - INFO: epoch 030 | valid on 'valid' subset:     51 / 2860 loss=2.429, loss_v1=0, loss_v2=0, nll_loss=1.208, ntokens=259, nsentences=8, sample_size=259.0, sample_size_v1=0, sample_size_v2=0
2023-05-09 05:04:51 - progress_bar.py[line:272] - INFO: epoch 030 | valid on 'valid' subset:     61 / 2860 loss=2.37, loss_v1=0, loss_v2=0, nll_loss=1.145, ntokens=268, nsentences=8, sample_size=268.0, sample_size_v1=0, sample_size_v2=0
2023-05-09 05:05:07 - progress_bar.py[line:272] - INFO: epoch 030 | valid on 'valid' subset:     71 / 2860 loss=2.47, loss_v1=0, loss_v2=0, nll_loss=1.251, ntokens=306, nsentences=8, sample_size=306.0, sample_size_v1=0, sample_size_v2=0
2023-05-09 05:05:22 - progress_bar.py[line:272] - INFO: epoch 030 | valid on 'valid' subset:     81 / 2860 loss=2.607, loss_v1=0, loss_v2=0, nll_loss=1.416, ntokens=217, nsentences=8, sample_size=217.0, sample_size_v1=0, sample_size_v2=0
2023-05-09 05:05:36 - progress_bar.py[line:272] - INFO: epoch 030 | valid on 'valid' subset:     91 / 2860 loss=2.511, loss_v1=0, loss_v2=0, nll_loss=1.304, ntokens=233, nsentences=8, sample_size=233.0, sample_size_v1=0, sample_size_v2=0
2343237 <sub> person<pred> on<obj> skateboard<sub> person<pred> on<obj> skateboard<sub> person<pred> on<obj> skateboard ['<sub> man<pred> above<obj> skateboard<pred> wearing<obj> shoe<pred> wearing<obj> sock<pred> wearing<obj> shirt<sub> person<pred> standing on<obj> skateboard<pred> has<obj> head<sub> skateboard<pred> for<obj> shoe<sub> leg<pred> of<obj> person<sub> leg<pred> of<obj> person<sub> head<pred> of<obj> person']
2325378 <sub> tail<pred> of<obj> elephant<sub> ear<pred> of<obj> elephant<sub> leg<pred> of<obj> elephant<sub> leg<pred> of<obj> elephant<sub> leg<pred> of<obj> elephant<sub> leg<pred> of<obj> elephant<sub> head<pred> of<obj> elephant ['<sub> elephant<pred> near<obj> elephant<pred> has<obj> trunk<pred> has<obj> truck<sub> rock<pred> behind<obj> elephant<sub> ear<pred> on<obj> elephant']
2023-05-09 05:05:51 - progress_bar.py[line:272] - INFO: epoch 030 | valid on 'valid' subset:    101 / 2860 loss=2.378, loss_v1=0, loss_v2=0, nll_loss=1.153, ntokens=309, nsentences=8, sample_size=309.0, sample_size_v1=0, sample_size_v2=0
2023-05-09 05:06:05 - progress_bar.py[line:272] - INFO: epoch 030 | valid on 'valid' subset:    111 / 2860 loss=2.528, loss_v1=0, loss_v2=0, nll_loss=1.323, ntokens=325, nsentences=8, sample_size=325.0, sample_size_v1=0, sample_size_v2=0
2023-05-09 05:06:20 - progress_bar.py[line:272] - INFO: epoch 030 | valid on 'valid' subset:    121 / 2860 loss=2.417, loss_v1=0, loss_v2=0, nll_loss=1.206, ntokens=274, nsentences=8, sample_size=274.0, sample_size_v1=0, sample_size_v2=0
2023-05-09 05:06:34 - progress_bar.py[line:272] - INFO: epoch 030 | valid on 'valid' subset:    131 / 2860 loss=2.381, loss_v1=0, loss_v2=0, nll_loss=1.154, ntokens=306, nsentences=8, sample_size=306.0, sample_size_v1=0, sample_size_v2=0
2023-05-09 05:06:48 - progress_bar.py[line:272] - INFO: epoch 030 | valid on 'valid' subset:    141 / 2860 loss=2.209, loss_v1=0, loss_v2=0, nll_loss=0.965, ntokens=295, nsentences=8, sample_size=295.0, sample_size_v1=0, sample_size_v2=0
2325083 <sub> dog<pred> on<obj> bed<pred> has<obj> ear<pred> has<obj> ear<pred> has<obj> paw<pred> has<obj> paw<sub> pillow<pred> on<obj> bed<sub> pillow<pred> on<obj> bed<sub> pillow<pred> on<obj> bed<sub> pillow<pred> on<obj> bed ['<sub> cat<pred> in front of<obj> window<pred> laying on<obj> desk<pred> has<obj> ear<pred> has<obj> eye<pred> has<obj> eye<pred> has<obj> nose<pred> has<obj> paw<pred> has<obj> paw<pred> has<obj> head']
2342980 <sub> skier<pred> on<obj> hill<sub> skier<pred> on<obj> hill<sub> skier<pred> on<obj> hill<sub> skier<pred> on<obj> hill<sub> skier<pred> on<obj> hill<sub> skier<pred> on<obj> hill<sub> skier<pred> on<obj> hill<sub> skier<pred> on<obj> hill ['<sub> snow<pred> covering<obj> mountain<sub> snow<pred> on<obj> roof<sub> roof<pred> on<obj> building<sub> railing<pred> of<obj> building<sub> pant<pred> of<obj> skier<sub> skier<pred> holding<obj> pole<sub> person<pred> holding<obj> pole<pred> using<obj> ski<sub> person<pred> on<obj> ski<sub> people<pred> on<obj> snow<sub> man<pred> wearing<obj> pant<sub> snow<pred> covering<obj> tree<sub> pole<pred> on<obj> man<sub> snow<pred> on<obj> roof']
2023-05-09 05:07:03 - progress_bar.py[line:272] - INFO: epoch 030 | valid on 'valid' subset:    151 / 2860 loss=2.363, loss_v1=0, loss_v2=0, nll_loss=1.139, ntokens=313, nsentences=8, sample_size=313.0, sample_size_v1=0, sample_size_v2=0
2023-05-09 05:07:18 - progress_bar.py[line:272] - INFO: epoch 030 | valid on 'valid' subset:    161 / 2860 loss=2.569, loss_v1=0, loss_v2=0, nll_loss=1.369, ntokens=317, nsentences=8, sample_size=317.0, sample_size_v1=0, sample_size_v2=0
2023-05-09 05:07:34 - progress_bar.py[line:272] - INFO: epoch 030 | valid on 'valid' subset:    171 / 2860 loss=2.562, loss_v1=0, loss_v2=0, nll_loss=1.361, ntokens=334, nsentences=8, sample_size=334.0, sample_size_v1=0, sample_size_v2=0
2023-05-09 05:07:48 - progress_bar.py[line:272] - INFO: epoch 030 | valid on 'valid' subset:    181 / 2860 loss=2.408, loss_v1=0, loss_v2=0, nll_loss=1.189, ntokens=300, nsentences=8, sample_size=300.0, sample_size_v1=0, sample_size_v2=0
2023-05-09 05:08:04 - progress_bar.py[line:272] - INFO: epoch 030 | valid on 'valid' subset:    191 / 2860 loss=2.607, loss_v1=0, loss_v2=0, nll_loss=1.41, ntokens=411, nsentences=8, sample_size=411.0, sample_size_v1=0, sample_size_v2=0
2324795 <sub> elephant<pred> has<obj> trunk<pred> has<obj> ear<pred> has<obj> leg<pred> has<obj> leg<pred> has<obj> head<sub> fence<pred> behind<obj> elephant ['<sub> jacket<pred> on<obj> man<sub> fence<pred> along<obj> sidewalk<sub> man<pred> at<obj> sidewalk<pred> at<obj> sidewalk']
2342714 <sub> woman<pred> has<obj> hair<sub> woman<pred> has<obj> hair ['<sub> head<pred> of<obj> sheep<sub> head<pred> of<obj> sheep<sub> head<pred> of<obj> sheep<sub> head<pred> of<obj> sheep<sub> head<pred> of<obj> sheep']
2023-05-09 05:08:18 - progress_bar.py[line:272] - INFO: epoch 030 | valid on 'valid' subset:    201 / 2860 loss=2.432, loss_v1=0, loss_v2=0, nll_loss=1.211, ntokens=346, nsentences=8, sample_size=346.0, sample_size_v1=0, sample_size_v2=0
2023-05-09 05:08:34 - progress_bar.py[line:272] - INFO: epoch 030 | valid on 'valid' subset:    211 / 2860 loss=2.45, loss_v1=0, loss_v2=0, nll_loss=1.229, ntokens=429, nsentences=8, sample_size=429.0, sample_size_v1=0, sample_size_v2=0
2023-05-09 05:08:50 - progress_bar.py[line:272] - INFO: epoch 030 | valid on 'valid' subset:    221 / 2860 loss=2.387, loss_v1=0, loss_v2=0, nll_loss=1.163, ntokens=318, nsentences=8, sample_size=318.0, sample_size_v1=0, sample_size_v2=0
2023-05-09 05:09:06 - progress_bar.py[line:272] - INFO: epoch 030 | valid on 'valid' subset:    231 / 2860 loss=2.291, loss_v1=0, loss_v2=0, nll_loss=1.053, ntokens=449, nsentences=8, sample_size=449.0, sample_size_v1=0, sample_size_v2=0
2023-05-09 05:09:21 - progress_bar.py[line:272] - INFO: epoch 030 | valid on 'valid' subset:    241 / 2860 loss=2.409, loss_v1=0, loss_v2=0, nll_loss=1.187, ntokens=350, nsentences=8, sample_size=350.0, sample_size_v1=0, sample_size_v2=0
2324511 <sub> person<pred> wearing<obj> sneaker<pred> wearing<obj> short<sub> man<pred> wearing<obj> short<pred> holding<obj> racket<pred> wearing<obj> shirt<sub> man<pred> wearing<obj> short<pred> wearing<obj> shirt<sub> man<pred> wearing<obj> sneaker<pred> wearing<obj> sneaker<sub> man<pred> wearing<obj> shirt<sub> man<pred> wearing<obj> short ['<sub> man<pred> holding<obj> racket<sub> man<pred> in<obj> hat<pred> in<obj> shirt<sub> man<pred> in<obj> shirt<sub> shirt<pred> in<obj> hat<sub> man<pred> in<obj> shirt<pred> in<obj> coat']
2342454 <sub> man<pred> on<obj> bench<pred> wearing<obj> pant<pred> wearing<obj> shirt<pred> wearing<obj> shoe<pred> wearing<obj> shoe<pred> wearing<obj> pant<sub> car<pred> on<obj> street<sub> car<pred> on<obj> street<sub> window<pred> on<obj> building<sub> window<pred> on<obj> building<sub> window<pred> on<obj> building<sub> window<pred> on<obj> building ['<sub> person<pred> sitting on<obj> bench<pred> with<obj> shirt<pred> has<obj> pant<sub> street<pred> with<obj> people<sub> sign<pred> on<obj> post<pred> on<obj> pole<sub> leg<pred> above<obj> person<sub> leg<pred> on<obj> person<sub> shoe<pred> of<obj> person']
2023-05-09 05:09:35 - progress_bar.py[line:272] - INFO: epoch 030 | valid on 'valid' subset:    251 / 2860 loss=2.585, loss_v1=0, loss_v2=0, nll_loss=1.388, ntokens=351, nsentences=8, sample_size=351.0, sample_size_v1=0, sample_size_v2=0
2023-05-09 05:09:51 - progress_bar.py[line:272] - INFO: epoch 030 | valid on 'valid' subset:    261 / 2860 loss=2.585, loss_v1=0, loss_v2=0, nll_loss=1.38, ntokens=338, nsentences=8, sample_size=338.0, sample_size_v1=0, sample_size_v2=0
2023-05-09 05:10:05 - progress_bar.py[line:272] - INFO: epoch 030 | valid on 'valid' subset:    271 / 2860 loss=2.429, loss_v1=0, loss_v2=0, nll_loss=1.211, ntokens=411, nsentences=8, sample_size=411.0, sample_size_v1=0, sample_size_v2=0
2023-05-09 05:10:19 - progress_bar.py[line:272] - INFO: epoch 030 | valid on 'valid' subset:    281 / 2860 loss=2.384, loss_v1=0, loss_v2=0, nll_loss=1.167, ntokens=301, nsentences=8, sample_size=301.0, sample_size_v1=0, sample_size_v2=0
2023-05-09 05:10:34 - progress_bar.py[line:272] - INFO: epoch 030 | valid on 'valid' subset:    291 / 2860 loss=2.617, loss_v1=0, loss_v2=0, nll_loss=1.421, ntokens=330, nsentences=8, sample_size=330.0, sample_size_v1=0, sample_size_v2=0
2324219 <sub> dog<pred> has<obj> tail<pred> has<obj> ear<pred> has<obj> leg ['<sub> boy<pred> carrying<obj> helmet<pred> wearing<obj> glove<sub> player<pred> behind<obj> boy']
2342212 <sub> person<pred> walking on<obj> street<sub> person<pred> walking on<obj> street<sub> person<pred> walking on<obj> street<sub> person<pred> walking on<obj> street<sub> person<pred> walking on<obj> street<sub> person<pred> walking on<obj> street<sub> person<pred> walking on<obj> street<sub> person<pred> walking on<obj> street<sub> person<pred> walking on<obj> street<sub> person<pred> walking on<obj> street ['<sub> kid<pred> near<obj> bike<sub> sign<pred> near<obj> building<sub> man<pred> on<obj> street<sub> bike<pred> has<obj> tire<pred> near<obj> stand<pred> parked on<obj> street<sub> people<pred> under<obj> umbrella<pred> walking on<obj> street<sub> boy<pred> near<obj> bike<sub> man<pred> wears<obj> shirt<pred> wears<obj> short<sub> woman<pred> wearing<obj> shirt<sub> person<pred> wearing<obj> shirt']
2023-05-09 05:10:48 - progress_bar.py[line:272] - INFO: epoch 030 | valid on 'valid' subset:    301 / 2860 loss=2.644, loss_v1=0, loss_v2=0, nll_loss=1.456, ntokens=302, nsentences=8, sample_size=302.0, sample_size_v1=0, sample_size_v2=0
2023-05-09 05:11:02 - progress_bar.py[line:272] - INFO: epoch 030 | valid on 'valid' subset:    311 / 2860 loss=2.344, loss_v1=0, loss_v2=0, nll_loss=1.115, ntokens=307, nsentences=8, sample_size=307.0, sample_size_v1=0, sample_size_v2=0
2023-05-09 05:11:17 - progress_bar.py[line:272] - INFO: epoch 030 | valid on 'valid' subset:    321 / 2860 loss=2.526, loss_v1=0, loss_v2=0, nll_loss=1.325, ntokens=359, nsentences=8, sample_size=359.0, sample_size_v1=0, sample_size_v2=0
2023-05-09 05:11:32 - progress_bar.py[line:272] - INFO: epoch 030 | valid on 'valid' subset:    331 / 2860 loss=2.347, loss_v1=0, loss_v2=0, nll_loss=1.116, ntokens=304, nsentences=8, sample_size=304.0, sample_size_v1=0, sample_size_v2=0
2023-05-09 05:11:47 - progress_bar.py[line:272] - INFO: epoch 030 | valid on 'valid' subset:    341 / 2860 loss=2.579, loss_v1=0, loss_v2=0, nll_loss=1.378, ntokens=304, nsentences=8, sample_size=304.0, sample_size_v1=0, sample_size_v2=0
2323939 <sub> plate<pred> on<obj> table<sub> food<pred> on<obj> plate<sub> food<pred> on<obj> plate<sub> food<pred> on<obj> plate<sub> food<pred> on<obj> plate<sub> food<pred> on<obj> plate ['<sub> food<pred> on<obj> plate<sub> light<pred> on<obj> plate<sub> hand<pred> of<obj> person']
2341969 <sub> man<pred> on<obj> bike<sub> person<pred> on<obj> bike<sub> person<pred> on<obj> bike<sub> person<pred> on<obj> bike<sub> person<pred> on<obj> bike<sub> person<pred> on<obj> bike<sub> person<pred> on<obj> bike ['<sub> person<pred> riding<obj> horse<sub> tree<pred> has<obj> branch<sub> man<pred> on<obj> horse<sub> man<pred> behind<obj> cow<pred> behind<obj> cow<pred> behind<obj> cow<pred> behind<obj> cow<pred> behind<obj> cow<pred> riding<obj> horse<pred> riding<obj> horse']
2023-05-09 05:12:01 - progress_bar.py[line:272] - INFO: epoch 030 | valid on 'valid' subset:    351 / 2860 loss=2.4, loss_v1=0, loss_v2=0, nll_loss=1.179, ntokens=272, nsentences=8, sample_size=272.0, sample_size_v1=0, sample_size_v2=0
2023-05-09 05:12:15 - progress_bar.py[line:272] - INFO: epoch 030 | valid on 'valid' subset:    361 / 2860 loss=2.557, loss_v1=0, loss_v2=0, nll_loss=1.354, ntokens=300, nsentences=8, sample_size=300.0, sample_size_v1=0, sample_size_v2=0
2023-05-09 05:12:30 - progress_bar.py[line:272] - INFO: epoch 030 | valid on 'valid' subset:    371 / 2860 loss=2.51, loss_v1=0, loss_v2=0, nll_loss=1.298, ntokens=279, nsentences=8, sample_size=279.0, sample_size_v1=0, sample_size_v2=0
2023-05-09 05:12:44 - progress_bar.py[line:272] - INFO: epoch 030 | valid on 'valid' subset:    381 / 2860 loss=2.46, loss_v1=0, loss_v2=0, nll_loss=1.256, ntokens=197, nsentences=8, sample_size=197.0, sample_size_v1=0, sample_size_v2=0
2023-05-09 05:12:59 - progress_bar.py[line:272] - INFO: epoch 030 | valid on 'valid' subset:    391 / 2860 loss=2.483, loss_v1=0, loss_v2=0, nll_loss=1.272, ntokens=485, nsentences=8, sample_size=485.0, sample_size_v1=0, sample_size_v2=0
2323646 <sub> man<pred> wearing<obj> shirt<pred> wearing<obj> pant<pred> has<obj> hand<pred> has<obj> hand<pred> has<obj> ear<pred> has<obj> ear<pred> has<obj> nose<pred> wearing<obj> glass<pred> wearing<obj> pant<sub> glass<pred> on<obj> face<sub> man<pred> wearing<obj> shirt ['<sub> hair<pred> on<obj> woman<pred> on<obj> head<sub> head<pred> of<obj> woman']
2341718 <sub> pole<pred> holding<obj> sign<sub> sign<pred> on<obj> pole<sub> sign<pred> on<obj> pole<sub> sign<pred> on<obj> pole ['<sub> bird<pred> on<obj> bike<sub> wire<pred> on<obj> bike']
2023-05-09 05:13:16 - progress_bar.py[line:272] - INFO: epoch 030 | valid on 'valid' subset:    401 / 2860 loss=2.473, loss_v1=0, loss_v2=0, nll_loss=1.256, ntokens=346, nsentences=8, sample_size=346.0, sample_size_v1=0, sample_size_v2=0
2023-05-09 05:13:31 - progress_bar.py[line:272] - INFO: epoch 030 | valid on 'valid' subset:    411 / 2860 loss=2.377, loss_v1=0, loss_v2=0, nll_loss=1.157, ntokens=306, nsentences=8, sample_size=306.0, sample_size_v1=0, sample_size_v2=0
2023-05-09 05:13:48 - progress_bar.py[line:272] - INFO: epoch 030 | valid on 'valid' subset:    421 / 2860 loss=2.486, loss_v1=0, loss_v2=0, nll_loss=1.278, ntokens=260, nsentences=8, sample_size=260.0, sample_size_v1=0, sample_size_v2=0
2023-05-09 05:14:03 - progress_bar.py[line:272] - INFO: epoch 030 | valid on 'valid' subset:    431 / 2860 loss=2.398, loss_v1=0, loss_v2=0, nll_loss=1.172, ntokens=296, nsentences=8, sample_size=296.0, sample_size_v1=0, sample_size_v2=0
2023-05-09 05:14:16 - progress_bar.py[line:272] - INFO: epoch 030 | valid on 'valid' subset:    441 / 2860 loss=2.212, loss_v1=0, loss_v2=0, nll_loss=0.969, ntokens=320, nsentences=8, sample_size=320.0, sample_size_v1=0, sample_size_v2=0
2341458 <sub> giraffe<pred> has<obj> neck<pred> has<obj> leg<pred> has<obj> leg<pred> has<obj> leg<pred> has<obj> leg<pred> has<obj> tail<pred> has<obj> head ['<sub> man<pred> wearing<obj> shirt<pred> near<obj> truck<sub> man<pred> wearing<obj> shirt<sub> truck<pred> has<obj> tire<sub> windshield<pred> on<obj> truck']
2323363 <sub> train<pred> on<obj> track<pred> on<obj> track<sub> wheel<pred> on<obj> train<sub> wheel<pred> on<obj> train<sub> wheel<pred> on<obj> train<sub> wheel<pred> on<obj> train<sub> wheel<pred> on<obj> train<sub> wheel<pred> on<obj> train ['<sub> rock<pred> on<obj> track<pred> on<obj> track<pred> on<obj> track<sub> rock<pred> on<obj> track<sub> man<pred> near<obj> train<sub> window<pred> on<obj> train<sub> window<pred> on<obj> train<sub> window<pred> on<obj> train']
2023-05-09 05:14:30 - progress_bar.py[line:272] - INFO: epoch 030 | valid on 'valid' subset:    451 / 2860 loss=2.297, loss_v1=0, loss_v2=0, nll_loss=1.068, ntokens=282, nsentences=8, sample_size=282.0, sample_size_v1=0, sample_size_v2=0
2023-05-09 05:14:45 - progress_bar.py[line:272] - INFO: epoch 030 | valid on 'valid' subset:    461 / 2860 loss=2.379, loss_v1=0, loss_v2=0, nll_loss=1.155, ntokens=266, nsentences=8, sample_size=266.0, sample_size_v1=0, sample_size_v2=0
2023-05-09 05:15:00 - progress_bar.py[line:272] - INFO: epoch 030 | valid on 'valid' subset:    471 / 2860 loss=2.523, loss_v1=0, loss_v2=0, nll_loss=1.319, ntokens=371, nsentences=8, sample_size=371.0, sample_size_v1=0, sample_size_v2=0
2023-05-09 05:15:13 - progress_bar.py[line:272] - INFO: epoch 030 | valid on 'valid' subset:    481 / 2860 loss=2.378, loss_v1=0, loss_v2=0, nll_loss=1.159, ntokens=250, nsentences=8, sample_size=250.0, sample_size_v1=0, sample_size_v2=0
2023-05-09 05:15:29 - progress_bar.py[line:272] - INFO: epoch 030 | valid on 'valid' subset:    491 / 2860 loss=2.548, loss_v1=0, loss_v2=0, nll_loss=1.341, ntokens=292, nsentences=8, sample_size=292.0, sample_size_v1=0, sample_size_v2=0
2323062 <sub> clock<pred> has<obj> face<pred> has<obj> hand<sub> hand<pred> on<obj> clock<sub> building<pred> has<obj> clock ['<sub> cow<pred> near<obj> cow<pred> near<obj> cow<sub> cow<pred> near<obj> cow<pred> near<obj> cow<sub> cow<pred> near<obj> cow<pred> near<obj> cow<sub> cow<pred> near<obj> cow']
2341172 <sub> leaf<pred> on<obj> branch<sub> bird<pred> on<obj> branch<pred> has<obj> head<pred> has<obj> wing<pred> has<obj> tail ['<sub> dog<pred> has<obj> ear<pred> has<obj> ear<pred> has<obj> leg<sub> person<pred> has<obj> pant']
2023-05-09 05:15:44 - progress_bar.py[line:272] - INFO: epoch 030 | valid on 'valid' subset:    501 / 2860 loss=2.395, loss_v1=0, loss_v2=0, nll_loss=1.181, ntokens=348, nsentences=8, sample_size=348.0, sample_size_v1=0, sample_size_v2=0
2023-05-09 05:15:56 - progress_bar.py[line:272] - INFO: epoch 030 | valid on 'valid' subset:    511 / 2860 loss=2.363, loss_v1=0, loss_v2=0, nll_loss=1.132, ntokens=180, nsentences=8, sample_size=180.0, sample_size_v1=0, sample_size_v2=0
2023-05-09 05:16:10 - progress_bar.py[line:272] - INFO: epoch 030 | valid on 'valid' subset:    521 / 2860 loss=2.363, loss_v1=0, loss_v2=0, nll_loss=1.14, ntokens=255, nsentences=8, sample_size=255.0, sample_size_v1=0, sample_size_v2=0
2023-05-09 05:16:24 - progress_bar.py[line:272] - INFO: epoch 030 | valid on 'valid' subset:    531 / 2860 loss=2.27, loss_v1=0, loss_v2=0, nll_loss=1.026, ntokens=194, nsentences=8, sample_size=194.0, sample_size_v1=0, sample_size_v2=0
2023-05-09 05:16:37 - progress_bar.py[line:272] - INFO: epoch 030 | valid on 'valid' subset:    541 / 2860 loss=2.628, loss_v1=0, loss_v2=0, nll_loss=1.437, ntokens=244, nsentences=8, sample_size=244.0, sample_size_v1=0, sample_size_v2=0
2340847 <sub> dog<pred> on<obj> surfboard<sub> dog<pred> on<obj> surfboard ['<sub> man<pred> riding<obj> wave<pred> riding<obj> surfboard']
2322769 <sub> man<pred> wearing<obj> shirt<pred> wearing<obj> pant<sub> man<pred> wearing<obj> shirt<pred> holding<obj> paper<pred> wearing<obj> tie<sub> man<pred> wearing<obj> shirt<pred> holding<obj> paper<sub> sign<pred> behind<obj> man<sub> sign<pred> behind<obj> man<sub> sign<pred> behind<obj> man<sub> sign<pred> behind<obj> man<sub> sign<pred> behind<obj> man ['<sub> head<pred> of<obj> woman<sub> leg<pred> of<obj> woman<sub> light<pred> of<obj> bike<pred> on<obj> motorcycle<sub> tire<pred> of<obj> bike<sub> tire<pred> of<obj> bike<sub> tire<pred> on<obj> car<pred> of<obj> truck<sub> woman<pred> wearing<obj> shirt<pred> on<obj> motorcycle<sub> plate<pred> of<obj> vehicle<pred> on<obj> car<sub> hat<pred> on<obj> man<sub> shirt<pred> on<obj> woman']
2023-05-09 05:16:51 - progress_bar.py[line:272] - INFO: epoch 030 | valid on 'valid' subset:    551 / 2860 loss=2.388, loss_v1=0, loss_v2=0, nll_loss=1.166, ntokens=301, nsentences=8, sample_size=301.0, sample_size_v1=0, sample_size_v2=0
2023-05-09 05:17:05 - progress_bar.py[line:272] - INFO: epoch 030 | valid on 'valid' subset:    561 / 2860 loss=2.563, loss_v1=0, loss_v2=0, nll_loss=1.362, ntokens=190, nsentences=8, sample_size=190.0, sample_size_v1=0, sample_size_v2=0
2023-05-09 05:17:18 - progress_bar.py[line:272] - INFO: epoch 030 | valid on 'valid' subset:    571 / 2860 loss=2.255, loss_v1=0, loss_v2=0, nll_loss=1.018, ntokens=228, nsentences=8, sample_size=228.0, sample_size_v1=0, sample_size_v2=0
2023-05-09 05:17:34 - progress_bar.py[line:272] - INFO: epoch 030 | valid on 'valid' subset:    581 / 2860 loss=2.398, loss_v1=0, loss_v2=0, nll_loss=1.172, ntokens=419, nsentences=8, sample_size=419.0, sample_size_v1=0, sample_size_v2=0
2023-05-09 05:17:47 - progress_bar.py[line:272] - INFO: epoch 030 | valid on 'valid' subset:    591 / 2860 loss=2.513, loss_v1=0, loss_v2=0, nll_loss=1.307, ntokens=272, nsentences=8, sample_size=272.0, sample_size_v1=0, sample_size_v2=0
2322487 <sub> sheep<pred> has<obj> head<pred> has<obj> leg<pred> has<obj> leg<pred> has<obj> leg<pred> has<obj> leg<pred> has<obj> leg<pred> has<obj> leg<pred> has<obj> leg<pred> has<obj> leg<sub> sheep<pred> has<obj> head<pred> has<obj> leg<pred> has<obj> leg<pred> has<obj> leg<sub> sheep<pred> has<obj> leg ['<sub> man<pred> holding<obj> bottle<pred> holding<obj> umbrella<pred> holding<obj> umbrella<sub> umbrella<pred> over<obj> man<sub> umbrella<pred> over<obj> man<sub> man<pred> holding<obj> umbrella<sub> man<pred> holding<obj> bottle']
2340556 <sub> man<pred> near<obj> bus<sub> man<pred> near<obj> bus<sub> wheel<pred> on<obj> bus<sub> wheel<pred> on<obj> bus<sub> wheel<pred> on<obj> bus<sub> wheel<pred> on<obj> bus<sub> window<pred> on<obj> bus<sub> window<pred> on<obj> bus<sub> window<pred> on<obj> bus<sub> window<pred> on<obj> bus<sub> window<pred> on<obj> bus<sub> wheel<pred> on<obj> bus<sub> wheel<pred> on<obj> bus ['<sub> person<pred> holding<obj> jacket<pred> wearing<obj> shirt<pred> wearing<obj> pant<pred> wearing<obj> shoe<sub> woman<pred> carrying<obj> bag<pred> wearing<obj> pant<sub> person<pred> holding<obj> bag<sub> wheel<pred> on<obj> airplane<sub> guy<pred> wearing<obj> short<sub> guy<pred> wearing<obj> shirt<pred> wearing<obj> pant']
2023-05-09 05:18:02 - progress_bar.py[line:272] - INFO: epoch 030 | valid on 'valid' subset:    601 / 2860 loss=2.56, loss_v1=0, loss_v2=0, nll_loss=1.36, ntokens=250, nsentences=8, sample_size=250.0, sample_size_v1=0, sample_size_v2=0
2023-05-09 05:18:17 - progress_bar.py[line:272] - INFO: epoch 030 | valid on 'valid' subset:    611 / 2860 loss=2.48, loss_v1=0, loss_v2=0, nll_loss=1.263, ntokens=215, nsentences=8, sample_size=215.0, sample_size_v1=0, sample_size_v2=0
2023-05-09 05:18:31 - progress_bar.py[line:272] - INFO: epoch 030 | valid on 'valid' subset:    621 / 2860 loss=2.333, loss_v1=0, loss_v2=0, nll_loss=1.102, ntokens=316, nsentences=8, sample_size=316.0, sample_size_v1=0, sample_size_v2=0
2023-05-09 05:18:45 - progress_bar.py[line:272] - INFO: epoch 030 | valid on 'valid' subset:    631 / 2860 loss=2.494, loss_v1=0, loss_v2=0, nll_loss=1.279, ntokens=208, nsentences=8, sample_size=208.0, sample_size_v1=0, sample_size_v2=0
2023-05-09 05:19:00 - progress_bar.py[line:272] - INFO: epoch 030 | valid on 'valid' subset:    641 / 2860 loss=2.72, loss_v1=0, loss_v2=0, nll_loss=1.538, ntokens=237, nsentences=8, sample_size=237.0, sample_size_v1=0, sample_size_v2=0
2322201 <sub> man<pred> holding<obj> racket<pred> wearing<obj> short<pred> wearing<obj> shirt<pred> wearing<obj> sneaker<pred> wearing<obj> sock<sub> man<pred> wearing<obj> shirt<pred> wearing<obj> sneaker<pred> wearing<obj> sneaker<pred> wearing<obj> sock<pred> wearing<obj> sock<pred> wearing<obj> sock<pred> wearing<obj> sock<sub> player<pred> wearing<obj> sock<pred> wearing<obj> sock ['<sub> glove<pred> on<obj> hand<sub> man<pred> wearing<obj> helmet<pred> wearing<obj> pant<pred> wearing<obj> glove<pred> sitting on<obj> bench<sub> man<pred> wearing<obj> sneaker<sub> hand<pred> of<obj> man<sub> helmet<pred> on<obj> head<sub> player<pred> wearing<obj> shirt']
2340256 <sub> player<pred> wearing<obj> helmet<sub> man<pred> wearing<obj> shirt ['<sub> man<pred> wearing<obj> shirt<sub> man<pred> on<obj> man']
2023-05-09 05:19:15 - progress_bar.py[line:272] - INFO: epoch 030 | valid on 'valid' subset:    651 / 2860 loss=2.48, loss_v1=0, loss_v2=0, nll_loss=1.27, ntokens=265, nsentences=8, sample_size=265.0, sample_size_v1=0, sample_size_v2=0
2023-05-09 05:19:29 - progress_bar.py[line:272] - INFO: epoch 030 | valid on 'valid' subset:    661 / 2860 loss=2.589, loss_v1=0, loss_v2=0, nll_loss=1.388, ntokens=269, nsentences=8, sample_size=269.0, sample_size_v1=0, sample_size_v2=0
2023-05-09 05:19:43 - progress_bar.py[line:272] - INFO: epoch 030 | valid on 'valid' subset:    671 / 2860 loss=2.723, loss_v1=0, loss_v2=0, nll_loss=1.549, ntokens=250, nsentences=8, sample_size=250.0, sample_size_v1=0, sample_size_v2=0
2023-05-09 05:19:56 - progress_bar.py[line:272] - INFO: epoch 030 | valid on 'valid' subset:    681 / 2860 loss=2.435, loss_v1=0, loss_v2=0, nll_loss=1.216, ntokens=231, nsentences=8, sample_size=231.0, sample_size_v1=0, sample_size_v2=0
2023-05-09 05:20:10 - progress_bar.py[line:272] - INFO: epoch 030 | valid on 'valid' subset:    691 / 2860 loss=2.521, loss_v1=0, loss_v2=0, nll_loss=1.32, ntokens=374, nsentences=8, sample_size=374.0, sample_size_v1=0, sample_size_v2=0
2339847 <sub> banana<pred> in<obj> basket<sub> banana<pred> in<obj> basket<sub> banana<pred> in<obj> basket<sub> banana<pred> in<obj> basket<sub> banana<pred> in<obj> basket<sub> banana<pred> in<obj> basket<sub> banana<pred> in<obj> basket<sub> banana<pred> in<obj> basket<sub> banana<pred> in<obj> basket<sub> banana<pred> in<obj> basket ['<sub> hand<pred> on<obj> laptop<sub> laptop<pred> has<obj> screen<sub> book<pred> on<obj> table<sub> book<pred> on<obj> table<sub> screen<pred> has<obj> laptop<sub> shirt<pred> of<obj> person']
2321918 <sub> man<pred> on<obj> surfboard<pred> riding<obj> wave<pred> has<obj> hand<pred> has<obj> arm<pred> has<obj> leg<pred> has<obj> hair ['<sub> man<pred> with<obj> surfboard<pred> with<obj> hair']
2023-05-09 05:20:25 - progress_bar.py[line:272] - INFO: epoch 030 | valid on 'valid' subset:    701 / 2860 loss=2.439, loss_v1=0, loss_v2=0, nll_loss=1.222, ntokens=255, nsentences=8, sample_size=255.0, sample_size_v1=0, sample_size_v2=0
2023-05-09 05:20:39 - progress_bar.py[line:272] - INFO: epoch 030 | valid on 'valid' subset:    711 / 2860 loss=2.419, loss_v1=0, loss_v2=0, nll_loss=1.2, ntokens=303, nsentences=8, sample_size=303.0, sample_size_v1=0, sample_size_v2=0
2023-05-09 05:20:54 - progress_bar.py[line:272] - INFO: epoch 030 | valid on 'valid' subset:    721 / 2860 loss=2.489, loss_v1=0, loss_v2=0, nll_loss=1.286, ntokens=190, nsentences=8, sample_size=190.0, sample_size_v1=0, sample_size_v2=0
2023-05-09 05:21:08 - progress_bar.py[line:272] - INFO: epoch 030 | valid on 'valid' subset:    731 / 2860 loss=2.285, loss_v1=0, loss_v2=0, nll_loss=1.047, ntokens=306, nsentences=8, sample_size=306.0, sample_size_v1=0, sample_size_v2=0
2023-05-09 05:21:23 - progress_bar.py[line:272] - INFO: epoch 030 | valid on 'valid' subset:    741 / 2860 loss=2.605, loss_v1=0, loss_v2=0, nll_loss=1.402, ntokens=219, nsentences=8, sample_size=219.0, sample_size_v1=0, sample_size_v2=0
2321636 <sub> tire<pred> of<obj> bike<sub> seat<pred> of<obj> bike<sub> bike<pred> near<obj> fence<sub> bike<pred> near<obj> fence ['<sub> car<pred> parked on<obj> street<sub> building<pred> near<obj> bus<sub> bus<pred> above<obj> street<pred> has<obj> window<sub> tree<pred> behind<obj> bus<sub> tree<pred> in front of<obj> building<sub> window<pred> on<obj> bus<sub> window<pred> on<obj> bus']
2339501 <sub> person<pred> holding<obj> surfboard<sub> person<pred> holding<obj> surfboard<sub> person<pred> holding<obj> surfboard<sub> person<pred> holding<obj> surfboard<sub> man<pred> holding<obj> surfboard<sub> man<pred> holding<obj> surfboard<sub> man<pred> holding<obj> surfboard<sub> man<pred> holding<obj> surfboard<sub> hand<pred> holding<obj> surfboard<sub> hand<pred> holding<obj> surfboard<sub> man<pred> holding<obj> surfboard ['<sub> man<pred> riding<obj> wave<sub> man<pred> standing on<obj> board<sub> board<pred> under<obj> arm<sub> man<pred> under<obj> arm<pred> holding<obj> board<sub> arm<pred> under<obj> board<pred> of<obj> person<sub> surfboard<pred> behind<obj> man<sub> man<pred> in<obj> wave<pred> watching<obj> man<sub> person<pred> has<obj> head<sub> person<pred> has<obj> arm<sub> leg<pred> of<obj> person<sub> leg<pred> of<obj> person<sub> leg<pred> of<obj> man<sub> man<pred> watching<obj> man<sub> person<pred> above<obj> surfboard']
2023-05-09 05:21:38 - progress_bar.py[line:272] - INFO: epoch 030 | valid on 'valid' subset:    751 / 2860 loss=2.42, loss_v1=0, loss_v2=0, nll_loss=1.199, ntokens=407, nsentences=8, sample_size=407.0, sample_size_v1=0, sample_size_v2=0
2023-05-09 05:21:52 - progress_bar.py[line:272] - INFO: epoch 030 | valid on 'valid' subset:    761 / 2860 loss=2.491, loss_v1=0, loss_v2=0, nll_loss=1.287, ntokens=265, nsentences=8, sample_size=265.0, sample_size_v1=0, sample_size_v2=0
2023-05-09 05:22:07 - progress_bar.py[line:272] - INFO: epoch 030 | valid on 'valid' subset:    771 / 2860 loss=2.485, loss_v1=0, loss_v2=0, nll_loss=1.276, ntokens=390, nsentences=8, sample_size=390.0, sample_size_v1=0, sample_size_v2=0
2023-05-09 05:22:23 - progress_bar.py[line:272] - INFO: epoch 030 | valid on 'valid' subset:    781 / 2860 loss=2.381, loss_v1=0, loss_v2=0, nll_loss=1.159, ntokens=330, nsentences=8, sample_size=330.0, sample_size_v1=0, sample_size_v2=0
2023-05-09 05:22:37 - progress_bar.py[line:272] - INFO: epoch 030 | valid on 'valid' subset:    791 / 2860 loss=2.68, loss_v1=0, loss_v2=0, nll_loss=1.497, ntokens=153, nsentences=8, sample_size=153.0, sample_size_v1=0, sample_size_v2=0
2321336 <sub> box<pred> on<obj> sidewalk<sub> box<pred> on<obj> sidewalk<sub> box<pred> on<obj> sidewalk ['<sub> tree<pred> in front of<obj> house<pred> near<obj> house<sub> wire<pred> on<obj> pole<sub> toilet<pred> in front of<obj> pole<sub> window<pred> on<obj> house<sub> car<pred> in front of<obj> house']
2339141 <sub> man<pred> sitting on<obj> bench<pred> wearing<obj> sneaker<pred> wearing<obj> shoe<pred> wearing<obj> shoe<pred> wearing<obj> pant<pred> has<obj> hair<sub> man<pred> sitting on<obj> bench<pred> wearing<obj> sneaker<pred> wearing<obj> sneaker<pred> wearing<obj> pant<pred> wearing<obj> shirt<sub> bag<pred> on<obj> bench<sub> bag<pred> on<obj> bench<sub> bag<pred> on<obj> bench ['<sub> man<pred> wearing<obj> short<pred> wearing<obj> hat<pred> wearing<obj> shirt<sub> hat<pred> on<obj> man<sub> leaf<pred> on<obj> tree']
2023-05-09 05:22:53 - progress_bar.py[line:272] - INFO: epoch 030 | valid on 'valid' subset:    801 / 2860 loss=2.543, loss_v1=0, loss_v2=0, nll_loss=1.338, ntokens=305, nsentences=8, sample_size=305.0, sample_size_v1=0, sample_size_v2=0
2023-05-09 05:23:07 - progress_bar.py[line:272] - INFO: epoch 030 | valid on 'valid' subset:    811 / 2860 loss=2.47, loss_v1=0, loss_v2=0, nll_loss=1.26, ntokens=273, nsentences=8, sample_size=273.0, sample_size_v1=0, sample_size_v2=0
2023-05-09 05:23:20 - progress_bar.py[line:272] - INFO: epoch 030 | valid on 'valid' subset:    821 / 2860 loss=2.433, loss_v1=0, loss_v2=0, nll_loss=1.221, ntokens=275, nsentences=8, sample_size=275.0, sample_size_v1=0, sample_size_v2=0
2023-05-09 05:23:34 - progress_bar.py[line:272] - INFO: epoch 030 | valid on 'valid' subset:    831 / 2860 loss=2.375, loss_v1=0, loss_v2=0, nll_loss=1.151, ntokens=358, nsentences=8, sample_size=358.0, sample_size_v1=0, sample_size_v2=0
2023-05-09 05:23:50 - progress_bar.py[line:272] - INFO: epoch 030 | valid on 'valid' subset:    841 / 2860 loss=2.645, loss_v1=0, loss_v2=0, nll_loss=1.45, ntokens=242, nsentences=8, sample_size=242.0, sample_size_v1=0, sample_size_v2=0
2338809 <sub> fork<pred> on<obj> plate<sub> plate<pred> on<obj> table<sub> glass<pred> on<obj> table ['<sub> food<pred> on<obj> desk<pred> on<obj> plate<sub> bottle<pred> on<obj> desk']
2321060 <sub> train<pred> on<obj> track<pred> on<obj> track<pred> on<obj> track<sub> track<pred> near<obj> track<sub> track<pred> near<obj> track<sub> track<pred> near<obj> track<sub> track<pred> near<obj> track<sub> track<pred> near<obj> track<sub> track<pred> near<obj> track<sub> track<pred> near<obj> track<sub> track<pred> near<obj> track ['<sub> man<pred> riding<obj> train<pred> wearing<obj> hat<pred> in<obj> train<sub> house<pred> near<obj> track<sub> man<pred> on<obj> train<sub> leg<pred> of<obj> man<sub> building<pred> near<obj> track<sub> building<pred> near<obj> train']
2023-05-09 05:24:04 - progress_bar.py[line:272] - INFO: epoch 030 | valid on 'valid' subset:    851 / 2860 loss=2.49, loss_v1=0, loss_v2=0, nll_loss=1.279, ntokens=220, nsentences=8, sample_size=220.0, sample_size_v1=0, sample_size_v2=0
2023-05-09 05:24:18 - progress_bar.py[line:272] - INFO: epoch 030 | valid on 'valid' subset:    861 / 2860 loss=2.289, loss_v1=0, loss_v2=0, nll_loss=1.056, ntokens=247, nsentences=8, sample_size=247.0, sample_size_v1=0, sample_size_v2=0
2023-05-09 05:24:32 - progress_bar.py[line:272] - INFO: epoch 030 | valid on 'valid' subset:    871 / 2860 loss=2.566, loss_v1=0, loss_v2=0, nll_loss=1.367, ntokens=262, nsentences=8, sample_size=262.0, sample_size_v1=0, sample_size_v2=0
2023-05-09 05:24:46 - progress_bar.py[line:272] - INFO: epoch 030 | valid on 'valid' subset:    881 / 2860 loss=2.39, loss_v1=0, loss_v2=0, nll_loss=1.173, ntokens=288, nsentences=8, sample_size=288.0, sample_size_v1=0, sample_size_v2=0
2023-05-09 05:25:00 - progress_bar.py[line:272] - INFO: epoch 030 | valid on 'valid' subset:    891 / 2860 loss=2.228, loss_v1=0, loss_v2=0, nll_loss=0.989, ntokens=288, nsentences=8, sample_size=288.0, sample_size_v1=0, sample_size_v2=0
2338457 <sub> flag<pred> on<obj> boat<sub> boat<pred> has<obj> flag<sub> flag<pred> on<obj> boat ['<sub> towel<pred> on<obj> bed<sub> bed<pred> in<obj> room<sub> bed<pred> in<obj> room<sub> table<pred> near<obj> bed']
2320764 <sub> boy<pred> on<obj> skateboard<sub> boy<pred> on<obj> skateboard<sub> boy<pred> on<obj> skateboard<sub> boy<pred> on<obj> skateboard<sub> boy<pred> on<obj> skateboard<sub> boy<pred> on<obj> skateboard<sub> boy<pred> on<obj> skateboard<sub> boy<pred> on<obj> skateboard<sub> boy<pred> on<obj> skateboard<sub> boy<pred> on<obj> skateboard<sub> boy<pred> on<obj> skateboard<sub> boy<pred> on<obj> skateboard<sub> window<pred> on<obj> building<sub> window<pred> on<obj> building<sub> window<pred> on ['<sub> person<pred> on<obj> sidewalk<pred> wearing<obj> shirt<pred> riding<obj> skateboard<pred> has<obj> jean<pred> on<obj> skateboard<sub> man<pred> wearing<obj> jacket<sub> woman<pred> standing on<obj> jacket<sub> person<pred> on<obj> skateboard<sub> person<pred> has<obj> shirt<sub> window<pred> of<obj> building<sub> man<pred> has<obj> shirt<pred> wearing<obj> shirt<pred> wearing<obj> shirt<sub> person<pred> watching<obj> man<sub> person<pred> watching<obj> man<sub> man<pred> in<obj> shirt<sub> people<pred> in<obj> building<sub> kid<pred> in<obj>']
2023-05-09 05:25:15 - progress_bar.py[line:272] - INFO: epoch 030 | valid on 'valid' subset:    901 / 2860 loss=2.673, loss_v1=0, loss_v2=0, nll_loss=1.481, ntokens=318, nsentences=8, sample_size=318.0, sample_size_v1=0, sample_size_v2=0
2023-05-09 05:25:32 - progress_bar.py[line:272] - INFO: epoch 030 | valid on 'valid' subset:    911 / 2860 loss=2.405, loss_v1=0, loss_v2=0, nll_loss=1.189, ntokens=215, nsentences=8, sample_size=215.0, sample_size_v1=0, sample_size_v2=0
2023-05-09 05:25:47 - progress_bar.py[line:272] - INFO: epoch 030 | valid on 'valid' subset:    921 / 2860 loss=2.499, loss_v1=0, loss_v2=0, nll_loss=1.284, ntokens=356, nsentences=8, sample_size=356.0, sample_size_v1=0, sample_size_v2=0
2023-05-09 05:26:02 - progress_bar.py[line:272] - INFO: epoch 030 | valid on 'valid' subset:    931 / 2860 loss=2.518, loss_v1=0, loss_v2=0, nll_loss=1.311, ntokens=285, nsentences=8, sample_size=285.0, sample_size_v1=0, sample_size_v2=0
2023-05-09 05:26:18 - progress_bar.py[line:272] - INFO: epoch 030 | valid on 'valid' subset:    941 / 2860 loss=2.441, loss_v1=0, loss_v2=0, nll_loss=1.227, ntokens=381, nsentences=8, sample_size=381.0, sample_size_v1=0, sample_size_v2=0
2320489 <sub> ear<pred> of<obj> elephant<sub> ear<pred> of<obj> elephant<sub> trunk<pred> of<obj> elephant<sub> eye<pred> of<obj> elephant<sub> eye<pred> of<obj> elephant<sub> head<pred> of<obj> elephant<sub> tree<pred> behind<obj> elephant<sub> tree<pred> behind<obj> elephant<sub> tree<pred> behind<obj> elephant<sub> tree<pred> behind<obj> elephant ['<sub> number<pred> under<obj> window<sub> window<pred> on<obj> train<pred> above<obj> number<sub> windshield<pred> on<obj> train<pred> of<obj> train<sub> train<pred> on<obj> track<sub> light<pred> of<obj> train<sub> track<pred> of<obj> train<sub> door<pred> of<obj> train<sub> train<pred> on<obj> track<sub> train<pred> has<obj> window']
2338097 <sub> man<pred> wearing<obj> shirt<pred> wearing<obj> jean<pred> has<obj> hair<pred> has<obj> hand<sub> man<pred> wearing<obj> shirt<pred> has<obj> hand<pred> has<obj> hand<pred> has<obj> hand<pred> has<obj> head<pred> wearing<obj> shirt<pred> wearing<obj> pant<pred> has<obj> hand<pred> has<obj> hand<pred> has<obj> hair<pred> wearing<obj> shoe<pred> wearing<obj> shoe<sub> cup<pred> above<obj> table<sub> cup<pred> above<obj> table<sub> cup<pred> above<obj> table ['<sub> towel<pred> on<obj> counter<sub> glass<pred> on<obj> face<sub> basket<pred> on<obj> counter<sub> bottle<pred> on<obj> counter<sub> woman<pred> wearing<obj> shirt<sub> woman<pred> has<obj> face<sub> bottle<pred> on<obj> counter<sub> woman<pred> wearing<obj> shirt<pred> wearing<obj> jean<sub> shirt<pred> on<obj> woman']
2023-05-09 05:26:32 - progress_bar.py[line:272] - INFO: epoch 030 | valid on 'valid' subset:    951 / 2860 loss=2.371, loss_v1=0, loss_v2=0, nll_loss=1.149, ntokens=365, nsentences=8, sample_size=365.0, sample_size_v1=0, sample_size_v2=0
2023-05-09 05:26:47 - progress_bar.py[line:272] - INFO: epoch 030 | valid on 'valid' subset:    961 / 2860 loss=2.303, loss_v1=0, loss_v2=0, nll_loss=1.074, ntokens=245, nsentences=8, sample_size=245.0, sample_size_v1=0, sample_size_v2=0
2023-05-09 05:27:03 - progress_bar.py[line:272] - INFO: epoch 030 | valid on 'valid' subset:    971 / 2860 loss=2.314, loss_v1=0, loss_v2=0, nll_loss=1.081, ntokens=264, nsentences=8, sample_size=264.0, sample_size_v1=0, sample_size_v2=0
2023-05-09 05:27:18 - progress_bar.py[line:272] - INFO: epoch 030 | valid on 'valid' subset:    981 / 2860 loss=2.182, loss_v1=0, loss_v2=0, nll_loss=0.944, ntokens=386, nsentences=8, sample_size=386.0, sample_size_v1=0, sample_size_v2=0
2023-05-09 05:27:35 - progress_bar.py[line:272] - INFO: epoch 030 | valid on 'valid' subset:    991 / 2860 loss=2.567, loss_v1=0, loss_v2=0, nll_loss=1.364, ntokens=267, nsentences=8, sample_size=267.0, sample_size_v1=0, sample_size_v2=0
2337758 <sub> man<pred> has<obj> hair<pred> wearing<obj> shirt<pred> has<obj> ear<pred> has<obj> eye<pred> has<obj> nose<pred> has<obj> neck<pred> has<obj> head<pred> has<obj> eye<pred> has<obj> mouth<pred> has<obj> finger<pred> has<obj> finger<pred> has<obj> finger<pred> has<obj> finger<pred> has<obj> finger<pred> has<obj> finger<pred> has<obj> finger<pred> has<obj> finger<sub> window<pred> on<obj> building<sub> window<pred> on<obj> building<sub> window<pred> on<obj> building ['<sub> man<pred> at<obj> table<pred> on<obj> glass<pred> in<obj> shirt<sub> woman<pred> wearing<obj> shirt<sub> man<pred> wearing<obj> glass<pred> wearing<obj> shirt<sub> woman<pred> with<obj> hair<sub> man<pred> wearing<obj> shirt<sub> person<pred> wearing<obj> shirt<sub> head<pred> of<obj> person']
2320210 <sub> bear<pred> has<obj> nose<pred> has<obj> paw<pred> has<obj> paw<pred> has<obj> paw<pred> has<obj> paw<pred> has<obj> paw<pred> has<obj> paw<pred> has<obj> ear<pred> has<obj> ear<pred> has<obj> head<sub> fence<pred> behind<obj> bear<sub> tree<pred> behind<obj> bear<sub> tree<pred> behind<obj> bear<sub> tree<pred> behind<obj> bear<sub> tree<pred> behind<obj> bear ['<sub> nose<pred> of<obj> cat<pred> on<obj> cat<sub> eye<pred> on<obj> cat<sub> eye<pred> on<obj> cat<sub> paw<pred> on<obj> cat<sub> paw<pred> of<obj> cat<sub> head<pred> of<obj> cat<sub> ear<pred> on<obj> cat<sub> ear<pred> of<obj> cat<sub> ear<pred> on<obj> cat<sub> cat<pred> has<obj> ear<pred> has<obj> eye<pred> has<obj> eye<sub> eye<pred> on<obj> cat']
2023-05-09 05:27:49 - progress_bar.py[line:272] - INFO: epoch 030 | valid on 'valid' subset:   1001 / 2860 loss=2.328, loss_v1=0, loss_v2=0, nll_loss=1.106, ntokens=410, nsentences=8, sample_size=410.0, sample_size_v1=0, sample_size_v2=0
2023-05-09 05:28:06 - progress_bar.py[line:272] - INFO: epoch 030 | valid on 'valid' subset:   1011 / 2860 loss=2.466, loss_v1=0, loss_v2=0, nll_loss=1.257, ntokens=232, nsentences=8, sample_size=232.0, sample_size_v1=0, sample_size_v2=0
2023-05-09 05:28:21 - progress_bar.py[line:272] - INFO: epoch 030 | valid on 'valid' subset:   1021 / 2860 loss=2.69, loss_v1=0, loss_v2=0, nll_loss=1.503, ntokens=290, nsentences=8, sample_size=290.0, sample_size_v1=0, sample_size_v2=0
2023-05-09 05:28:35 - progress_bar.py[line:272] - INFO: epoch 030 | valid on 'valid' subset:   1031 / 2860 loss=2.499, loss_v1=0, loss_v2=0, nll_loss=1.287, ntokens=315, nsentences=8, sample_size=315.0, sample_size_v1=0, sample_size_v2=0
2023-05-09 05:28:50 - progress_bar.py[line:272] - INFO: epoch 030 | valid on 'valid' subset:   1041 / 2860 loss=2.598, loss_v1=0, loss_v2=0, nll_loss=1.397, ntokens=249, nsentences=8, sample_size=249.0, sample_size_v1=0, sample_size_v2=0
2337395 <sub> cow<pred> in<obj> snow<sub> cow<pred> in<obj> snow<sub> cow<pred> in<obj> snow<sub> cow<pred> in<obj> snow<sub> cow<pred> in<obj> snow<sub> cow<pred> in<obj> snow ['<sub> boat<pred> sitting on<obj> snow<pred> on<obj> snow<sub> tree<pred> on<obj> mountain<sub> tree<pred> on<obj> mountain<sub> tree<pred> on<obj> mountain<sub> tree<pred> on<obj> mountain<sub> tree<pred> on<obj> mountain<sub> tree<pred> on<obj> mountain']
2319934 <sub> people<pred> on<obj> board<sub> person<pred> on<obj> board<sub> person<pred> on<obj> board<sub> person<pred> on<obj> board<sub> person<pred> on<obj> board ['<sub> man<pred> has<obj> helmet<sub> snow<pred> has<obj> track']
2023-05-09 05:29:04 - progress_bar.py[line:272] - INFO: epoch 030 | valid on 'valid' subset:   1051 / 2860 loss=2.383, loss_v1=0, loss_v2=0, nll_loss=1.162, ntokens=297, nsentences=8, sample_size=297.0, sample_size_v1=0, sample_size_v2=0
2023-05-09 05:29:19 - progress_bar.py[line:272] - INFO: epoch 030 | valid on 'valid' subset:   1061 / 2860 loss=2.418, loss_v1=0, loss_v2=0, nll_loss=1.191, ntokens=236, nsentences=8, sample_size=236.0, sample_size_v1=0, sample_size_v2=0
2023-05-09 05:29:34 - progress_bar.py[line:272] - INFO: epoch 030 | valid on 'valid' subset:   1071 / 2860 loss=2.2, loss_v1=0, loss_v2=0, nll_loss=0.965, ntokens=398, nsentences=8, sample_size=398.0, sample_size_v1=0, sample_size_v2=0
2023-05-09 05:29:48 - progress_bar.py[line:272] - INFO: epoch 030 | valid on 'valid' subset:   1081 / 2860 loss=2.554, loss_v1=0, loss_v2=0, nll_loss=1.356, ntokens=290, nsentences=8, sample_size=290.0, sample_size_v1=0, sample_size_v2=0
2023-05-09 05:30:02 - progress_bar.py[line:272] - INFO: epoch 030 | valid on 'valid' subset:   1091 / 2860 loss=2.491, loss_v1=0, loss_v2=0, nll_loss=1.276, ntokens=245, nsentences=8, sample_size=245.0, sample_size_v1=0, sample_size_v2=0
2319661 <sub> plate<pred> on<obj> table<sub> plate<pred> on<obj> table<pred> of<obj> food<sub> food<pred> on<obj> plate ['<sub> pizza<pred> on<obj> plate<sub> plate<pred> on<obj> table<sub> glass<pred> on<obj> table<sub> bowl<pred> on<obj> table']
2337075 <sub> man<pred> wearing<obj> shirt<pred> wearing<obj> glass<pred> wearing<obj> glass<pred> has<obj> face<sub> man<pred> wearing<obj> shirt<pred> wearing<obj> glass<pred> has<obj> face<sub> man<pred> wearing<obj> shirt<pred> wearing<obj> glass<pred> has<obj> face<sub> man<pred> wearing<obj> shirt<sub> glass<pred> on<obj> face<sub> face<pred> of<obj> man<sub> face<pred> of<obj> man<sub> face<pred> of<obj> man<sub> face<pred> of<obj> man<sub> face<pred> of<obj> man<sub> face<pred> of<obj> man<sub> face<pred> of<obj> man ['<sub> banana<pred> on<obj> head<sub> banana<pred> on<obj> head<sub> man<pred> wearing<obj> shirt<sub> men<pred> wearing<obj> banana<sub> banana<pred> on<obj> head<sub> face<pred> of<obj> man<sub> face<pred> of<obj> person<sub> hand<pred> of<obj> person<sub> man<pred> holding<obj> food<sub> logo<pred> in<obj> shirt<sub> hand<pred> of<obj> man<sub> hand<pred> of<obj> man']
2023-05-09 05:30:16 - progress_bar.py[line:272] - INFO: epoch 030 | valid on 'valid' subset:   1101 / 2860 loss=2.589, loss_v1=0, loss_v2=0, nll_loss=1.38, ntokens=429, nsentences=8, sample_size=429.0, sample_size_v1=0, sample_size_v2=0
2023-05-09 05:30:32 - progress_bar.py[line:272] - INFO: epoch 030 | valid on 'valid' subset:   1111 / 2860 loss=2.554, loss_v1=0, loss_v2=0, nll_loss=1.355, ntokens=356, nsentences=8, sample_size=356.0, sample_size_v1=0, sample_size_v2=0
2023-05-09 05:30:48 - progress_bar.py[line:272] - INFO: epoch 030 | valid on 'valid' subset:   1121 / 2860 loss=2.489, loss_v1=0, loss_v2=0, nll_loss=1.277, ntokens=201, nsentences=8, sample_size=201.0, sample_size_v1=0, sample_size_v2=0
2023-05-09 05:31:02 - progress_bar.py[line:272] - INFO: epoch 030 | valid on 'valid' subset:   1131 / 2860 loss=2.637, loss_v1=0, loss_v2=0, nll_loss=1.445, ntokens=225, nsentences=8, sample_size=225.0, sample_size_v1=0, sample_size_v2=0
2023-05-09 05:31:18 - progress_bar.py[line:272] - INFO: epoch 030 | valid on 'valid' subset:   1141 / 2860 loss=2.209, loss_v1=0, loss_v2=0, nll_loss=0.975, ntokens=284, nsentences=8, sample_size=284.0, sample_size_v1=0, sample_size_v2=0
2336793 <sub> window<pred> on<obj> building<sub> window<pred> on<obj> building<sub> window<pred> on<obj> building<sub> window<pred> on<obj> building<sub> window<pred> on<obj> building<sub> window<pred> on<obj> building ['<sub> window<pred> on<obj> bus<sub> window<pred> on<obj> bus<sub> window<pred> on<obj> bus<sub> window<pred> on<obj> bus<sub> window<pred> on<obj> bus<sub> window<pred> on<obj> bus<sub> window<pred> on<obj> bus']
2319402 <sub> wheel<pred> on<obj> bus<sub> wheel<pred> on<obj> bus<sub> wheel<pred> on<obj> bus<sub> people<pred> on<obj> bus<sub> bus<pred> on<obj> street<sub> tree<pred> behind<obj> building<sub> building<pred> behind<obj> bus<sub> building<pred> behind<obj> bus<sub> building<pred> behind<obj> bus<sub> building<pred> behind<obj> bus<sub> window<pred> on<obj> building<sub> window<pred> on<obj> building<sub> window<pred> on<obj> building<sub> window<pred> on<obj> building<sub> window<pred> on<obj> building ['<sub> man<pred> wearing<obj> shirt<sub> building<pred> on<obj> sidewalk']
2023-05-09 05:31:32 - progress_bar.py[line:272] - INFO: epoch 030 | valid on 'valid' subset:   1151 / 2860 loss=2.458, loss_v1=0, loss_v2=0, nll_loss=1.247, ntokens=265, nsentences=8, sample_size=265.0, sample_size_v1=0, sample_size_v2=0
2023-05-09 05:31:47 - progress_bar.py[line:272] - INFO: epoch 030 | valid on 'valid' subset:   1161 / 2860 loss=2.235, loss_v1=0, loss_v2=0, nll_loss=0.99, ntokens=331, nsentences=8, sample_size=331.0, sample_size_v1=0, sample_size_v2=0
2023-05-09 05:32:01 - progress_bar.py[line:272] - INFO: epoch 030 | valid on 'valid' subset:   1171 / 2860 loss=2.237, loss_v1=0, loss_v2=0, nll_loss=0.992, ntokens=300, nsentences=8, sample_size=300.0, sample_size_v1=0, sample_size_v2=0
2023-05-09 05:32:16 - progress_bar.py[line:272] - INFO: epoch 030 | valid on 'valid' subset:   1181 / 2860 loss=2.369, loss_v1=0, loss_v2=0, nll_loss=1.14, ntokens=300, nsentences=8, sample_size=300.0, sample_size_v1=0, sample_size_v2=0
2023-05-09 05:32:32 - progress_bar.py[line:272] - INFO: epoch 030 | valid on 'valid' subset:   1191 / 2860 loss=2.454, loss_v1=0, loss_v2=0, nll_loss=1.24, ntokens=338, nsentences=8, sample_size=338.0, sample_size_v1=0, sample_size_v2=0
2319123 <sub> head<pred> of<obj> giraffe<sub> neck<pred> of<obj> giraffe<sub> leg<pred> of<obj> giraffe<sub> leg<pred> of<obj> giraffe<sub> leg<pred> of<obj> giraffe<sub> leg<pred> of<obj> giraffe ['<sub> giraffe<pred> has<obj> head<sub> tree<pred> near<obj> giraffe<sub> leg<pred> on<obj> giraffe<sub> leg<pred> on<obj> giraffe<sub> leg<pred> of<obj> giraffe<sub> tail<pred> of<obj> giraffe<sub> head<pred> of<obj> giraffe']
2336515 <sub> woman<pred> holding<obj> racket<pred> wearing<obj> shirt<pred> wearing<obj> sneaker<pred> wearing<obj> sneaker<pred> has<obj> leg<pred> has<obj> leg<pred> has<obj> leg<pred> has<obj> leg<pred> has<obj> leg<pred> has<obj> leg<pred> has<obj> leg<pred> has<obj> leg<pred> has<obj> hand<pred> has<obj> hand<pred> wearing<obj> shoe<pred> wearing<obj> short<sub> racket<pred> in<obj> hand<sub> hand<pred> holding<obj> racket<sub> hand<pred> holding<obj> racket<sub> shoe<pred> on<obj> woman<sub> shoe<pred> on<obj> woman ['<sub> man<pred> wearing<obj> shoe<pred> in<obj> shirt<pred> wearing<obj> short<pred> has<obj> hair<sub> shoe<pred> of<obj> man<sub> leg<pred> on<obj> man<sub> leg<pred> on<obj> man<sub> arm<pred> on<obj> man<sub> arm<pred> on<obj> person']
2023-05-09 05:32:48 - progress_bar.py[line:272] - INFO: epoch 030 | valid on 'valid' subset:   1201 / 2860 loss=2.299, loss_v1=0, loss_v2=0, nll_loss=1.065, ntokens=310, nsentences=8, sample_size=310.0, sample_size_v1=0, sample_size_v2=0
2023-05-09 05:33:02 - progress_bar.py[line:272] - INFO: epoch 030 | valid on 'valid' subset:   1211 / 2860 loss=2.558, loss_v1=0, loss_v2=0, nll_loss=1.351, ntokens=323, nsentences=8, sample_size=323.0, sample_size_v1=0, sample_size_v2=0
2023-05-09 05:33:18 - progress_bar.py[line:272] - INFO: epoch 030 | valid on 'valid' subset:   1221 / 2860 loss=2.583, loss_v1=0, loss_v2=0, nll_loss=1.381, ntokens=325, nsentences=8, sample_size=325.0, sample_size_v1=0, sample_size_v2=0
2023-05-09 05:33:33 - progress_bar.py[line:272] - INFO: epoch 030 | valid on 'valid' subset:   1231 / 2860 loss=2.518, loss_v1=0, loss_v2=0, nll_loss=1.321, ntokens=228, nsentences=8, sample_size=228.0, sample_size_v1=0, sample_size_v2=0
2023-05-09 05:33:48 - progress_bar.py[line:272] - INFO: epoch 030 | valid on 'valid' subset:   1241 / 2860 loss=2.553, loss_v1=0, loss_v2=0, nll_loss=1.349, ntokens=523, nsentences=8, sample_size=523.0, sample_size_v1=0, sample_size_v2=0
2336235 <sub> woman<pred> sitting on<obj> bench<pred> has<obj> hair<pred> has<obj> head<pred> has<obj> arm<pred> has<obj> hand<pred> has<obj> head<pred> has<obj> hand<pred> has<obj> face<sub> bench<pred> has<obj> leg<pred> has<obj> leg<pred> has<obj> seat ['<sub> cat<pred> on<obj> car<pred> looking at<obj> person<sub> car<pred> has<obj> light<sub> person<pred> has<obj> arm<pred> has<obj> head<pred> has<obj> hand<pred> has<obj> leg<pred> has<obj> hair<pred> has<obj> shoe']
2318852 <sub> window<pred> on<obj> bus<sub> window<pred> on<obj> bus<sub> window<pred> on<obj> bus<sub> window<pred> on<obj> bus<sub> window<pred> on<obj> bus<sub> window<pred> on<obj> bus<sub> window<pred> on<obj> bus<sub> window<pred> on<obj> bus<sub> window<pred> on<obj> bus<sub> window<pred> on<obj> bus<sub> window<pred> on<obj> bus<sub> window<pred> on<obj> bus<sub> window<pred> on<obj> bus<sub> window<pred> on<obj> bus ['<sub> tree<pred> near<obj> train<sub> sign<pred> on<obj> bus<sub> sign<pred> near<obj> train<sub> sign<pred> near<obj> bus<sub> sign<pred> on<obj> bus<sub> window<pred> of<obj> train<sub> window<pred> of<obj> train<sub> window<pred> of<obj> train<sub> windshield<pred> on<obj> train<sub> roof<pred> on<obj> building']
2023-05-09 05:34:03 - progress_bar.py[line:272] - INFO: epoch 030 | valid on 'valid' subset:   1251 / 2860 loss=2.53, loss_v1=0, loss_v2=0, nll_loss=1.327, ntokens=270, nsentences=8, sample_size=270.0, sample_size_v1=0, sample_size_v2=0
2023-05-09 05:34:17 - progress_bar.py[line:272] - INFO: epoch 030 | valid on 'valid' subset:   1261 / 2860 loss=2.584, loss_v1=0, loss_v2=0, nll_loss=1.391, ntokens=251, nsentences=8, sample_size=251.0, sample_size_v1=0, sample_size_v2=0
2023-05-09 05:34:32 - progress_bar.py[line:272] - INFO: epoch 030 | valid on 'valid' subset:   1271 / 2860 loss=2.347, loss_v1=0, loss_v2=0, nll_loss=1.123, ntokens=232, nsentences=8, sample_size=232.0, sample_size_v1=0, sample_size_v2=0
2023-05-09 05:34:48 - progress_bar.py[line:272] - INFO: epoch 030 | valid on 'valid' subset:   1281 / 2860 loss=2.465, loss_v1=0, loss_v2=0, nll_loss=1.25, ntokens=317, nsentences=8, sample_size=317.0, sample_size_v1=0, sample_size_v2=0
2023-05-09 05:35:03 - progress_bar.py[line:272] - INFO: epoch 030 | valid on 'valid' subset:   1291 / 2860 loss=2.558, loss_v1=0, loss_v2=0, nll_loss=1.352, ntokens=396, nsentences=8, sample_size=396.0, sample_size_v1=0, sample_size_v2=0
2318578 <sub> dog<pred> in<obj> car<pred> has<obj> nose<pred> has<obj> mouth<pred> has<obj> ear<pred> has<obj> ear<sub> car<pred> has<obj> window<pred> has<obj> door ['<sub> bear<pred> has<obj> ear<sub> ear<pred> on<obj> bear']
2335972 <sub> giraffe<pred> has<obj> neck<pred> has<obj> leg<pred> has<obj> leg<pred> has<obj> leg<pred> has<obj> tail<pred> has<obj> head<sub> zebra<pred> has<obj> head ['<sub> animal<pred> on<obj> rock<pred> on<obj> rock<sub> giraffe<pred> has<obj> leg<sub> zebra<pred> has<obj> eye']
2023-05-09 05:35:16 - progress_bar.py[line:272] - INFO: epoch 030 | valid on 'valid' subset:   1301 / 2860 loss=2.668, loss_v1=0, loss_v2=0, nll_loss=1.471, ntokens=202, nsentences=8, sample_size=202.0, sample_size_v1=0, sample_size_v2=0
2023-05-09 05:35:31 - progress_bar.py[line:272] - INFO: epoch 030 | valid on 'valid' subset:   1311 / 2860 loss=2.571, loss_v1=0, loss_v2=0, nll_loss=1.369, ntokens=230, nsentences=8, sample_size=230.0, sample_size_v1=0, sample_size_v2=0
2023-05-09 05:35:45 - progress_bar.py[line:272] - INFO: epoch 030 | valid on 'valid' subset:   1321 / 2860 loss=2.402, loss_v1=0, loss_v2=0, nll_loss=1.179, ntokens=356, nsentences=8, sample_size=356.0, sample_size_v1=0, sample_size_v2=0
2023-05-09 05:35:59 - progress_bar.py[line:272] - INFO: epoch 030 | valid on 'valid' subset:   1331 / 2860 loss=2.465, loss_v1=0, loss_v2=0, nll_loss=1.255, ntokens=296, nsentences=8, sample_size=296.0, sample_size_v1=0, sample_size_v2=0
2023-05-09 05:36:15 - progress_bar.py[line:272] - INFO: epoch 030 | valid on 'valid' subset:   1341 / 2860 loss=2.623, loss_v1=0, loss_v2=0, nll_loss=1.426, ntokens=307, nsentences=8, sample_size=307.0, sample_size_v1=0, sample_size_v2=0
2318313 <sub> man<pred> holding<obj> surfboard<sub> man<pred> holding<obj> surfboard<sub> man<pred> holding<obj> surfboard<sub> man<pred> holding<obj> surfboard<sub> man<pred> holding<obj> surfboard ['<sub> flag<pred> hanging from<obj> tree<pred> hanging from<obj> tree<pred> hanging from<obj> tree<sub> fence<pred> in<obj> building<sub> board<pred> on<obj> trunk<pred> on<obj> trunk<sub> trunk<pred> under<obj> board<sub> trunk<pred> on<obj> tree<sub> railing<pred> on<obj> building<sub> tree<pred> along<obj> building<sub> tree<pred> along<obj> building<sub> tree<pred> along<obj> building<sub> tree<pred> along<obj> building']
2335683 <sub> window<pred> on<obj> building<sub> window<pred> on<obj> building<sub> window<pred> on<obj> building<sub> window<pred> on<obj> building<sub> window<pred> on<obj> building<sub> window<pred> on<obj> building<sub> window<pred> on<obj> building<sub> window<pred> on<obj> building<sub> window<pred> on<obj> building<sub> window<pred> on<obj> building<sub> window<pred> on<obj> building<sub> window<pred> on<obj> building<sub> window<pred> on<obj> building<sub> window<pred> on<obj> building ['<sub> tower<pred> above<obj> hill<sub> car<pred> in<obj> street<sub> car<pred> with<obj> light']
2023-05-09 05:36:30 - progress_bar.py[line:272] - INFO: epoch 030 | valid on 'valid' subset:   1351 / 2860 loss=2.558, loss_v1=0, loss_v2=0, nll_loss=1.348, ntokens=351, nsentences=8, sample_size=351.0, sample_size_v1=0, sample_size_v2=0
2023-05-09 05:36:46 - progress_bar.py[line:272] - INFO: epoch 030 | valid on 'valid' subset:   1361 / 2860 loss=2.491, loss_v1=0, loss_v2=0, nll_loss=1.283, ntokens=236, nsentences=8, sample_size=236.0, sample_size_v1=0, sample_size_v2=0
2023-05-09 05:37:02 - progress_bar.py[line:272] - INFO: epoch 030 | valid on 'valid' subset:   1371 / 2860 loss=2.43, loss_v1=0, loss_v2=0, nll_loss=1.203, ntokens=375, nsentences=8, sample_size=375.0, sample_size_v1=0, sample_size_v2=0
2023-05-09 05:37:18 - progress_bar.py[line:272] - INFO: epoch 030 | valid on 'valid' subset:   1381 / 2860 loss=2.311, loss_v1=0, loss_v2=0, nll_loss=1.078, ntokens=323, nsentences=8, sample_size=323.0, sample_size_v1=0, sample_size_v2=0
2023-05-09 05:37:33 - progress_bar.py[line:272] - INFO: epoch 030 | valid on 'valid' subset:   1391 / 2860 loss=2.426, loss_v1=0, loss_v2=0, nll_loss=1.206, ntokens=281, nsentences=8, sample_size=281.0, sample_size_v1=0, sample_size_v2=0
2335409 <sub> boy<pred> riding<obj> skateboard<pred> wearing<obj> helmet<pred> wearing<obj> shirt<pred> wearing<obj> sneaker<pred> wearing<obj> sneaker<pred> wearing<obj> sneaker<pred> wearing<obj> sneaker<sub> leg<pred> of<obj> boy<sub> leg<pred> of<obj> boy<sub> leg<pred> of<obj> boy ['<sub> head<pred> of<obj> man<sub> leg<pred> of<obj> man<sub> man<pred> wearing<obj> jacket<pred> on<obj> skateboard<pred> wearing<obj> shirt']
2318065 <sub> wheel<pred> on<obj> skateboard<sub> wheel<pred> on<obj> skateboard<sub> wheel<pred> on<obj> skateboard<sub> wheel<pred> on<obj> skateboard<sub> man<pred> holding<obj> skateboard<sub> man<pred> holding<obj> skateboard<sub> man<pred> holding<obj> skateboard<sub> man<pred> holding<obj> skateboard<sub> man<pred> holding<obj> skateboard<sub> man<pred> holding<obj> skateboard<sub> man<pred> holding<obj> skateboard<sub> man<pred> holding<obj> skateboard ['<sub> man<pred> holding<obj> board<pred> wearing<obj> pant<pred> carrying<obj> skateboard<pred> wearing<obj> hat<sub> boy<pred> wearing<obj> shirt<pred> on<obj> skateboard<pred> wearing<obj> jean<sub> wheel<pred> on<obj> board<sub> window<pred> on<obj> bus<sub> window<pred> on<obj> bus<sub> window<pred> on<obj> bus<sub> boy<pred> on<obj> skateboard<sub> man<pred> wearing<obj> shoe<sub> fence<pred> near<obj> man<pred> near<obj> boy<sub> tree<pred> near<obj> fence<sub> wheel<pred> of<obj> skateboard<sub> sneaker<pred> of']
2023-05-09 05:37:49 - progress_bar.py[line:272] - INFO: epoch 030 | valid on 'valid' subset:   1401 / 2860 loss=2.465, loss_v1=0, loss_v2=0, nll_loss=1.25, ntokens=295, nsentences=8, sample_size=295.0, sample_size_v1=0, sample_size_v2=0
2023-05-09 05:38:03 - progress_bar.py[line:272] - INFO: epoch 030 | valid on 'valid' subset:   1411 / 2860 loss=2.481, loss_v1=0, loss_v2=0, nll_loss=1.264, ntokens=299, nsentences=8, sample_size=299.0, sample_size_v1=0, sample_size_v2=0
2023-05-09 05:38:19 - progress_bar.py[line:272] - INFO: epoch 030 | valid on 'valid' subset:   1421 / 2860 loss=2.802, loss_v1=0, loss_v2=0, nll_loss=1.63, ntokens=325, nsentences=8, sample_size=325.0, sample_size_v1=0, sample_size_v2=0
2023-05-09 05:38:35 - progress_bar.py[line:272] - INFO: epoch 030 | valid on 'valid' subset:   1431 / 2860 loss=2.482, loss_v1=0, loss_v2=0, nll_loss=1.27, ntokens=265, nsentences=8, sample_size=265.0, sample_size_v1=0, sample_size_v2=0
2023-05-09 05:38:51 - progress_bar.py[line:272] - INFO: epoch 030 | valid on 'valid' subset:   1441 / 2860 loss=2.483, loss_v1=0, loss_v2=0, nll_loss=1.269, ntokens=376, nsentences=8, sample_size=376.0, sample_size_v1=0, sample_size_v2=0
2335114 <sub> bus<pred> on<obj> street<sub> people<pred> on<obj> sidewalk<sub> sign<pred> on<obj> pole<sub> sign<pred> on<obj> pole<sub> sign<pred> on<obj> pole ['<sub> tire<pred> on<obj> car<sub> window<pred> on<obj> car<sub> tree<pred> near<obj> street<sub> car<pred> on<obj> street<sub> bus<pred> on<obj> street<sub> car<pred> on<obj> street']
2317818 <sub> roof<pred> on<obj> building<sub> window<pred> on<obj> building<sub> window<pred> on<obj> building<sub> window<pred> on<obj> building<sub> window<pred> on<obj> building<sub> window<pred> on<obj> building<sub> tower<pred> on<obj> building ['<sub> clock<pred> on<obj> building<pred> on<obj> tower<sub> building<pred> with<obj> clock<pred> with<obj> clock<pred> has<obj> tower<pred> has<obj> flag<sub> hand<pred> across<obj> clock<sub> flag<pred> on<obj> pole']
2023-05-09 05:39:06 - progress_bar.py[line:272] - INFO: epoch 030 | valid on 'valid' subset:   1451 / 2860 loss=2.519, loss_v1=0, loss_v2=0, nll_loss=1.31, ntokens=253, nsentences=8, sample_size=253.0, sample_size_v1=0, sample_size_v2=0
2023-05-09 05:39:20 - progress_bar.py[line:272] - INFO: epoch 030 | valid on 'valid' subset:   1461 / 2860 loss=2.476, loss_v1=0, loss_v2=0, nll_loss=1.268, ntokens=432, nsentences=8, sample_size=432.0, sample_size_v1=0, sample_size_v2=0
2023-05-09 05:39:35 - progress_bar.py[line:272] - INFO: epoch 030 | valid on 'valid' subset:   1471 / 2860 loss=2.405, loss_v1=0, loss_v2=0, nll_loss=1.181, ntokens=329, nsentences=8, sample_size=329.0, sample_size_v1=0, sample_size_v2=0
2023-05-09 05:39:49 - progress_bar.py[line:272] - INFO: epoch 030 | valid on 'valid' subset:   1481 / 2860 loss=2.14, loss_v1=0, loss_v2=0, nll_loss=0.895, ntokens=344, nsentences=8, sample_size=344.0, sample_size_v1=0, sample_size_v2=0
2023-05-09 05:40:04 - progress_bar.py[line:272] - INFO: epoch 030 | valid on 'valid' subset:   1491 / 2860 loss=2.525, loss_v1=0, loss_v2=0, nll_loss=1.314, ntokens=271, nsentences=8, sample_size=271.0, sample_size_v1=0, sample_size_v2=0
2317554 <sub> pizza<pred> on<obj> plate ['<sub> pizza<pred> in<obj> table<sub> table<pred> under<obj> pizza']
2334815 <sub> man<pred> wearing<obj> shirt<pred> holding<obj> phone<pred> has<obj> hair<pred> has<obj> nose<pred> has<obj> finger<pred> has<obj> finger<pred> has<obj> finger<pred> has<obj> finger<pred> has<obj> finger<pred> has<obj> finger<pred> has<obj> finger<pred> has<obj> finger<pred> has<obj> finger<pred> has<obj> finger<pred> has<obj> finger<pred> has<obj> finger ['<sub> leg<pred> of<obj> person<sub> leg<pred> of<obj> person<sub> leg<pred> of<obj> person<sub> leg<pred> of<obj> person<sub> leg<pred> of<obj> woman<sub> person<pred> in<obj> house']
2023-05-09 05:40:20 - progress_bar.py[line:272] - INFO: epoch 030 | valid on 'valid' subset:   1501 / 2860 loss=2.392, loss_v1=0, loss_v2=0, nll_loss=1.168, ntokens=255, nsentences=8, sample_size=255.0, sample_size_v1=0, sample_size_v2=0
2023-05-09 05:40:36 - progress_bar.py[line:272] - INFO: epoch 030 | valid on 'valid' subset:   1511 / 2860 loss=2.516, loss_v1=0, loss_v2=0, nll_loss=1.304, ntokens=465, nsentences=8, sample_size=465.0, sample_size_v1=0, sample_size_v2=0
2023-05-09 05:40:52 - progress_bar.py[line:272] - INFO: epoch 030 | valid on 'valid' subset:   1521 / 2860 loss=2.679, loss_v1=0, loss_v2=0, nll_loss=1.493, ntokens=231, nsentences=8, sample_size=231.0, sample_size_v1=0, sample_size_v2=0
2023-05-09 05:41:08 - progress_bar.py[line:272] - INFO: epoch 030 | valid on 'valid' subset:   1531 / 2860 loss=2.606, loss_v1=0, loss_v2=0, nll_loss=1.415, ntokens=330, nsentences=8, sample_size=330.0, sample_size_v1=0, sample_size_v2=0
2023-05-09 05:41:22 - progress_bar.py[line:272] - INFO: epoch 030 | valid on 'valid' subset:   1541 / 2860 loss=2.453, loss_v1=0, loss_v2=0, nll_loss=1.236, ntokens=273, nsentences=8, sample_size=273.0, sample_size_v1=0, sample_size_v2=0
2334527 <sub> hat<pred> on<obj> head<sub> horse<pred> has<obj> eye<pred> has<obj> ear<pred> has<obj> nose<pred> has<obj> mouth<pred> has<obj> head<sub> man<pred> wearing<obj> hat<pred> wearing<obj> shirt<pred> riding<obj> horse<pred> wearing<obj> hat<sub> ear<pred> of<obj> horse<sub> ear<pred> of<obj> horse<sub> ear<pred> of<obj> horse<sub> nose<pred> of<obj> horse ['<sub> pizza<pred> walking on<obj> table<sub> bag<pred> on<obj> table<sub> box<pred> under<obj> table<sub> cup<pred> on<obj> table']
2317297 <sub> person<pred> holding<obj> umbrella<pred> wearing<obj> jean<sub> shoe<pred> on<obj> person<sub> shoe<pred> on<obj> person<sub> shoe<pred> on<obj> person<sub> shoe<pred> on<obj> person<sub> shoe<pred> on<obj> person<sub> shoe<pred> on<obj> person<sub> shoe<pred> on<obj> person<sub> shoe<pred> on<obj> person<sub> shoe<pred> on<obj> person<sub> shoe<pred> on<obj> person<sub> shoe<pred> on<obj> person<sub> jean<pred> on<obj> person<sub> shoe<pred> on<obj> person ['<sub> phone<pred> in<obj> hand<sub> woman<pred> on<obj> phone<pred> sitting on<obj> seat<pred> holding<obj> phone<pred> on<obj> plane<pred> wears<obj> jean<pred> wears<obj> shirt<pred> has<obj> hair<pred> has<obj> hair<sub> shirt<pred> on<obj> woman<sub> woman<pred> on<obj> plane<sub> woman<pred> wearing<obj> shirt<sub> hair<pred> on<obj> woman<sub> jean<pred> on<obj> leg']
2023-05-09 05:41:37 - progress_bar.py[line:272] - INFO: epoch 030 | valid on 'valid' subset:   1551 / 2860 loss=2.654, loss_v1=0, loss_v2=0, nll_loss=1.468, ntokens=328, nsentences=8, sample_size=328.0, sample_size_v1=0, sample_size_v2=0
2023-05-09 05:41:52 - progress_bar.py[line:272] - INFO: epoch 030 | valid on 'valid' subset:   1561 / 2860 loss=2.511, loss_v1=0, loss_v2=0, nll_loss=1.308, ntokens=344, nsentences=8, sample_size=344.0, sample_size_v1=0, sample_size_v2=0
2023-05-09 05:42:06 - progress_bar.py[line:272] - INFO: epoch 030 | valid on 'valid' subset:   1571 / 2860 loss=2.358, loss_v1=0, loss_v2=0, nll_loss=1.137, ntokens=329, nsentences=8, sample_size=329.0, sample_size_v1=0, sample_size_v2=0
2023-05-09 05:42:20 - progress_bar.py[line:272] - INFO: epoch 030 | valid on 'valid' subset:   1581 / 2860 loss=2.331, loss_v1=0, loss_v2=0, nll_loss=1.092, ntokens=313, nsentences=8, sample_size=313.0, sample_size_v1=0, sample_size_v2=0
2023-05-09 05:42:38 - progress_bar.py[line:272] - INFO: epoch 030 | valid on 'valid' subset:   1591 / 2860 loss=2.336, loss_v1=0, loss_v2=0, nll_loss=1.1, ntokens=482, nsentences=8, sample_size=482.0, sample_size_v1=0, sample_size_v2=0
2334234 <sub> window<pred> on<obj> train<pred> on<obj> train<sub> window<pred> on<obj> train<pred> on<obj> train<sub> window<pred> on<obj> train<sub> window<pred> on<obj> train<sub> window<pred> on<obj> train<sub> handle<pred> on<obj> door<sub> handle<pred> on<obj> door<sub> handle<pred> on<obj> door<sub> handle<pred> on<obj> door ['<sub> person<pred> using<obj> laptop<pred> sitting on<obj> chair<sub> arm<pred> on<obj> chair<sub> woman<pred> with<obj> laptop<sub> woman<pred> on<obj> screen']
2317047 <sub> man<pred> wearing<obj> shirt<pred> wearing<obj> glass<pred> with<obj> hair<sub> man<pred> wearing<obj> shirt<pred> wearing<obj> shirt<pred> with<obj> hair<sub> man<pred> wearing<obj> shirt<pred> with<obj> hair<sub> glass<pred> on<obj> face<sub> man<pred> wearing<obj> shirt<sub> man<pred> wearing<obj> shirt<sub> glass<pred> on<obj> face ['<sub> head<pred> of<obj> man<pred> of<obj> man<sub> eye<pred> of<obj> person<sub> eye<pred> of<obj> man<sub> mouth<pred> of<obj> man<pred> of<obj> man<sub> person<pred> has<obj> head<sub> man<pred> has<obj> head<pred> with<obj> person<sub> man<pred> holding<obj> box<pred> with<obj> hair<sub> chair<pred> behind<obj> people<sub> woman<pred> has<obj> eye<sub> nose<pred> on<obj> person<sub> hand<pred> on<obj> man<sub> eye<pred> of<obj> man']
2023-05-09 05:42:54 - progress_bar.py[line:272] - INFO: epoch 030 | valid on 'valid' subset:   1601 / 2860 loss=2.482, loss_v1=0, loss_v2=0, nll_loss=1.273, ntokens=308, nsentences=8, sample_size=308.0, sample_size_v1=0, sample_size_v2=0
2023-05-09 05:43:08 - progress_bar.py[line:272] - INFO: epoch 030 | valid on 'valid' subset:   1611 / 2860 loss=2.393, loss_v1=0, loss_v2=0, nll_loss=1.166, ntokens=275, nsentences=8, sample_size=275.0, sample_size_v1=0, sample_size_v2=0
2023-05-09 05:43:24 - progress_bar.py[line:272] - INFO: epoch 030 | valid on 'valid' subset:   1621 / 2860 loss=2.345, loss_v1=0, loss_v2=0, nll_loss=1.117, ntokens=238, nsentences=8, sample_size=238.0, sample_size_v1=0, sample_size_v2=0
2023-05-09 05:43:39 - progress_bar.py[line:272] - INFO: epoch 030 | valid on 'valid' subset:   1631 / 2860 loss=2.624, loss_v1=0, loss_v2=0, nll_loss=1.425, ntokens=269, nsentences=8, sample_size=269.0, sample_size_v1=0, sample_size_v2=0
2023-05-09 05:43:54 - progress_bar.py[line:272] - INFO: epoch 030 | valid on 'valid' subset:   1641 / 2860 loss=2.55, loss_v1=0, loss_v2=0, nll_loss=1.341, ntokens=438, nsentences=8, sample_size=438.0, sample_size_v1=0, sample_size_v2=0
2333942 <sub> dog<pred> has<obj> head<pred> has<obj> ear<pred> has<obj> ear<pred> has<obj> leg<pred> has<obj> leg<pred> has<obj> leg<sub> bag<pred> behind<obj> dog ['<sub> pant<pred> on<obj> woman<sub> seat<pred> of<obj> bike<sub> woman<pred> wearing<obj> sneaker<pred> wearing<obj> shirt<sub> basket<pred> on<obj> bike']
2316790 <sub> man<pred> has<obj> head<pred> has<obj> arm<pred> has<obj> ear<pred> has<obj> nose<pred> has<obj> mouth<pred> has<obj> hair<pred> has<obj> hand<pred> wearing<obj> coat<pred> wearing<obj> tie<sub> building<pred> behind<obj> man<sub> building<pred> behind<obj> man ['<sub> car<pred> has<obj> wheel<pred> has<obj> door<pred> has<obj> window<pred> has<obj> window<sub> man<pred> on<obj> sidewalk<sub> door<pred> has<obj> handle<sub> car<pred> parked on<obj> street']
2023-05-09 05:44:10 - progress_bar.py[line:272] - INFO: epoch 030 | valid on 'valid' subset:   1651 / 2860 loss=2.608, loss_v1=0, loss_v2=0, nll_loss=1.41, ntokens=343, nsentences=8, sample_size=343.0, sample_size_v1=0, sample_size_v2=0
2023-05-09 05:44:27 - progress_bar.py[line:272] - INFO: epoch 030 | valid on 'valid' subset:   1661 / 2860 loss=2.536, loss_v1=0, loss_v2=0, nll_loss=1.328, ntokens=256, nsentences=8, sample_size=256.0, sample_size_v1=0, sample_size_v2=0
2023-05-09 05:44:41 - progress_bar.py[line:272] - INFO: epoch 030 | valid on 'valid' subset:   1671 / 2860 loss=2.341, loss_v1=0, loss_v2=0, nll_loss=1.115, ntokens=330, nsentences=8, sample_size=330.0, sample_size_v1=0, sample_size_v2=0
2023-05-09 05:44:54 - progress_bar.py[line:272] - INFO: epoch 030 | valid on 'valid' subset:   1681 / 2860 loss=2.537, loss_v1=0, loss_v2=0, nll_loss=1.334, ntokens=236, nsentences=8, sample_size=236.0, sample_size_v1=0, sample_size_v2=0
2023-05-09 05:45:08 - progress_bar.py[line:272] - INFO: epoch 030 | valid on 'valid' subset:   1691 / 2860 loss=2.529, loss_v1=0, loss_v2=0, nll_loss=1.329, ntokens=356, nsentences=8, sample_size=356.0, sample_size_v1=0, sample_size_v2=0
2333632 <sub> man<pred> wearing<obj> jacket<sub> man<pred> wearing<obj> jacket<sub> man<pred> wearing<obj> jacket<sub> man<pred> wearing<obj> jacket ['<sub> shirt<pred> on<obj> man<sub> person<pred> in<obj> stand<sub> woman<pred> holding<obj> racket<sub> man<pred> wearing<obj> shirt']
2316531 <sub> horse<pred> has<obj> tail<sub> tree<pred> has<obj> leaf<sub> tree<pred> has<obj> leaf<sub> tree<pred> has<obj> leaf<sub> tree<pred> has<obj> leaf ['<sub> cow<pred> has<obj> nose<pred> has<obj> ear<pred> has<obj> leg<pred> has<obj> mouth<sub> ear<pred> of<obj> cow<sub> ear<pred> of<obj> cow<sub> nose<pred> on<obj> cow<sub> nose<pred> of<obj> cow<sub> mouth<pred> of<obj> cow<sub> roof<pred> on<obj> house']
2023-05-09 05:45:22 - progress_bar.py[line:272] - INFO: epoch 030 | valid on 'valid' subset:   1701 / 2860 loss=2.455, loss_v1=0, loss_v2=0, nll_loss=1.238, ntokens=290, nsentences=8, sample_size=290.0, sample_size_v1=0, sample_size_v2=0
2023-05-09 05:45:36 - progress_bar.py[line:272] - INFO: epoch 030 | valid on 'valid' subset:   1711 / 2860 loss=2.422, loss_v1=0, loss_v2=0, nll_loss=1.199, ntokens=319, nsentences=8, sample_size=319.0, sample_size_v1=0, sample_size_v2=0
2023-05-09 05:45:51 - progress_bar.py[line:272] - INFO: epoch 030 | valid on 'valid' subset:   1721 / 2860 loss=2.328, loss_v1=0, loss_v2=0, nll_loss=1.093, ntokens=384, nsentences=8, sample_size=384.0, sample_size_v1=0, sample_size_v2=0
2023-05-09 05:46:06 - progress_bar.py[line:272] - INFO: epoch 030 | valid on 'valid' subset:   1731 / 2860 loss=2.609, loss_v1=0, loss_v2=0, nll_loss=1.423, ntokens=238, nsentences=8, sample_size=238.0, sample_size_v1=0, sample_size_v2=0
2023-05-09 05:46:22 - progress_bar.py[line:272] - INFO: epoch 030 | valid on 'valid' subset:   1741 / 2860 loss=2.414, loss_v1=0, loss_v2=0, nll_loss=1.192, ntokens=371, nsentences=8, sample_size=371.0, sample_size_v1=0, sample_size_v2=0
2333340 <sub> man<pred> sitting on<obj> bench<sub> person<pred> sitting on<obj> bench<sub> person<pred> sitting on<obj> bench<sub> person<pred> sitting on<obj> bench<sub> person<pred> sitting on<obj> bench<sub> person<pred> sitting on<obj> bench<sub> person<pred> sitting on<obj> bench<sub> people<pred> sitting on<obj> bench<sub> people<pred> sitting on<obj> bench<sub> people<pred> sitting on<obj> bench ['<sub> man<pred> on<obj> elephant<sub> person<pred> riding<obj> elephant<sub> person<pred> riding<obj> elephant<sub> person<pred> riding<obj> elephant<sub> person<pred> riding<obj> elephant<sub> person<pred> riding<obj> elephant<sub> person<pred> riding<obj> elephant<sub> elephant<pred> carrying<obj> sign<sub> face<pred> on<obj> elephant<sub> leg<pred> on<obj> elephant']
2316284 <sub> skier<pred> on<obj> ski<sub> track<pred> in<obj> snow<sub> track<pred> in<obj> snow<sub> tree<pred> in<obj> snow<sub> tree<pred> in<obj> snow<sub> tree<pred> in<obj> snow<sub> tree<pred> in<obj> snow<sub> tree<pred> in<obj> snow<sub> tree<pred> in<obj> snow<sub> tree<pred> in<obj> snow<sub> tree<pred> in<obj> snow<sub> tree<pred> in<obj> snow<sub> trunk<pred> of<obj> tree<sub> trunk<pred> of<obj> tree<sub> trunk<pred> of<obj> tree ['<sub> snow<pred> on<obj> snow<sub> snow<pred> covered in<obj> snow<pred> on<obj> mountain<sub> tree<pred> in<obj> snow<pred> behind<obj> man<sub> tree<pred> covered in<obj> snow<sub> branch<pred> on<obj> hill<sub> ski<pred> on<obj> skier<sub> man<pred> in<obj> snow<sub> boot<pred> of<obj> person<sub> board<pred> in<obj> snow']
2023-05-09 05:46:36 - progress_bar.py[line:272] - INFO: epoch 030 | valid on 'valid' subset:   1751 / 2860 loss=2.452, loss_v1=0, loss_v2=0, nll_loss=1.237, ntokens=347, nsentences=8, sample_size=347.0, sample_size_v1=0, sample_size_v2=0
2023-05-09 05:46:49 - progress_bar.py[line:272] - INFO: epoch 030 | valid on 'valid' subset:   1761 / 2860 loss=2.451, loss_v1=0, loss_v2=0, nll_loss=1.233, ntokens=232, nsentences=8, sample_size=232.0, sample_size_v1=0, sample_size_v2=0
2023-05-09 05:47:02 - progress_bar.py[line:272] - INFO: epoch 030 | valid on 'valid' subset:   1771 / 2860 loss=2.35, loss_v1=0, loss_v2=0, nll_loss=1.136, ntokens=222, nsentences=8, sample_size=222.0, sample_size_v1=0, sample_size_v2=0
2023-05-09 05:47:17 - progress_bar.py[line:272] - INFO: epoch 030 | valid on 'valid' subset:   1781 / 2860 loss=2.619, loss_v1=0, loss_v2=0, nll_loss=1.412, ntokens=298, nsentences=8, sample_size=298.0, sample_size_v1=0, sample_size_v2=0
2023-05-09 05:47:31 - progress_bar.py[line:272] - INFO: epoch 030 | valid on 'valid' subset:   1791 / 2860 loss=2.309, loss_v1=0, loss_v2=0, nll_loss=1.073, ntokens=273, nsentences=8, sample_size=273.0, sample_size_v1=0, sample_size_v2=0
2316002 <sub> bus<pred> on<obj> street<sub> people<pred> walking on<obj> sidewalk<sub> window<pred> on<obj> building<sub> window<pred> on<obj> building<sub> window<pred> on<obj> building ['<sub> sign<pred> on<obj> sidewalk<sub> sign<pred> on<obj> sidewalk<sub> tree<pred> in front of<obj> building<sub> street<pred> near<obj> sign<sub> street<pred> near<obj> sidewalk']
2333035 <sub> person<pred> on<obj> bike<sub> person<pred> on<obj> bike<sub> people<pred> on<obj> bike<sub> people<pred> on<obj> bike<sub> people<pred> on<obj> bike<sub> bike<pred> on<obj> street<sub> bike<pred> on<obj> street<sub> bike<pred> on<obj> street<sub> bike<pred> on<obj> street<sub> bike<pred> on<obj> street<sub> people<pred> on<obj> bike ['<sub> tree<pred> near<obj> street<sub> sign<pred> on<obj> pole<sub> man<pred> wears<obj> shirt<sub> man<pred> has<obj> head<sub> man<pred> has<obj> arm<pred> has<obj> leg<pred> with<obj> hat']
2023-05-09 05:47:45 - progress_bar.py[line:272] - INFO: epoch 030 | valid on 'valid' subset:   1801 / 2860 loss=2.603, loss_v1=0, loss_v2=0, nll_loss=1.405, ntokens=261, nsentences=8, sample_size=261.0, sample_size_v1=0, sample_size_v2=0
2023-05-09 05:48:00 - progress_bar.py[line:272] - INFO: epoch 030 | valid on 'valid' subset:   1811 / 2860 loss=2.508, loss_v1=0, loss_v2=0, nll_loss=1.3, ntokens=282, nsentences=8, sample_size=282.0, sample_size_v1=0, sample_size_v2=0
2023-05-09 05:48:15 - progress_bar.py[line:272] - INFO: epoch 030 | valid on 'valid' subset:   1821 / 2860 loss=2.313, loss_v1=0, loss_v2=0, nll_loss=1.085, ntokens=222, nsentences=8, sample_size=222.0, sample_size_v1=0, sample_size_v2=0
2023-05-09 05:48:28 - progress_bar.py[line:272] - INFO: epoch 030 | valid on 'valid' subset:   1831 / 2860 loss=2.538, loss_v1=0, loss_v2=0, nll_loss=1.333, ntokens=222, nsentences=8, sample_size=222.0, sample_size_v1=0, sample_size_v2=0
2023-05-09 05:48:43 - progress_bar.py[line:272] - INFO: epoch 030 | valid on 'valid' subset:   1841 / 2860 loss=2.347, loss_v1=0, loss_v2=0, nll_loss=1.129, ntokens=238, nsentences=8, sample_size=238.0, sample_size_v1=0, sample_size_v2=0
2332689 <sub> glass<pred> on<obj> table<sub> glass<pred> on<obj> table<sub> glass<pred> on<obj> table ['<sub> banana<pred> in<obj> box<sub> box<pred> has<obj> fruit<sub> bag<pred> has<obj> fruit']
2315701 <sub> man<pred> has<obj> head<pred> has<obj> arm<pred> has<obj> arm<pred> has<obj> hand<pred> has<obj> hair<pred> wearing<obj> shirt<pred> wearing<obj> jean<pred> has<obj> hair<sub> man<pred> wearing<obj> shirt<pred> wearing<obj> pant<pred> has<obj> hair<sub> tree<pred> behind<obj> man<sub> tree<pred> behind<obj> man<sub> tree<pred> behind<obj> man<sub> tree<pred> behind<obj> man<sub> tree<pred> behind<obj> man<sub> tree<pred> behind<obj> man<sub> tree<pred> behind<obj> man ['<sub> person<pred> has<obj> hair<pred> sitting on<obj> chair<sub> hair<pred> belonging to<obj> person<sub> person<pred> sitting on<obj> chair<sub> jean<pred> on<obj> person<sub> lady<pred> sitting on<obj> chair<pred> sitting on<obj> chair<sub> bag<pred> near<obj> truck<sub> light<pred> on<obj> car']
2023-05-09 05:48:58 - progress_bar.py[line:272] - INFO: epoch 030 | valid on 'valid' subset:   1851 / 2860 loss=2.421, loss_v1=0, loss_v2=0, nll_loss=1.197, ntokens=316, nsentences=8, sample_size=316.0, sample_size_v1=0, sample_size_v2=0
2023-05-09 05:49:14 - progress_bar.py[line:272] - INFO: epoch 030 | valid on 'valid' subset:   1861 / 2860 loss=2.41, loss_v1=0, loss_v2=0, nll_loss=1.187, ntokens=246, nsentences=8, sample_size=246.0, sample_size_v1=0, sample_size_v2=0
2023-05-09 05:49:27 - progress_bar.py[line:272] - INFO: epoch 030 | valid on 'valid' subset:   1871 / 2860 loss=2.428, loss_v1=0, loss_v2=0, nll_loss=1.209, ntokens=263, nsentences=8, sample_size=263.0, sample_size_v1=0, sample_size_v2=0
2023-05-09 05:49:40 - progress_bar.py[line:272] - INFO: epoch 030 | valid on 'valid' subset:   1881 / 2860 loss=2.412, loss_v1=0, loss_v2=0, nll_loss=1.191, ntokens=405, nsentences=8, sample_size=405.0, sample_size_v1=0, sample_size_v2=0
2023-05-09 05:49:54 - progress_bar.py[line:272] - INFO: epoch 030 | valid on 'valid' subset:   1891 / 2860 loss=2.251, loss_v1=0, loss_v2=0, nll_loss=1, ntokens=296, nsentences=8, sample_size=296.0, sample_size_v1=0, sample_size_v2=0
2315386 <sub> man<pred> wearing<obj> jean<pred> wearing<obj> shirt<pred> on<obj> skateboard<pred> wearing<obj> shoe<pred> wearing<obj> jean<pred> wearing<obj> shoe<pred> has<obj> hair<sub> fence<pred> behind<obj> man<sub> tree<pred> behind<obj> fence<sub> tree<pred> behind<obj> fence ['<sub> person<pred> wearing<obj> jean<pred> holding<obj> skateboard<sub> fence<pred> on<obj> fence<pred> on<obj> fence<sub> truck<pred> on<obj> skateboard']
2332329 <sub> kite<pred> has<obj> tail<sub> kite<pred> has<obj> tail ['<sub> kite<pred> lying on<obj> beach<sub> kite<pred> lying on<obj> beach<sub> kite<pred> lying on<obj> beach<sub> kite<pred> lying on<obj> beach<sub> kite<pred> lying on<obj> beach']
2023-05-09 05:50:08 - progress_bar.py[line:272] - INFO: epoch 030 | valid on 'valid' subset:   1901 / 2860 loss=2.481, loss_v1=0, loss_v2=0, nll_loss=1.269, ntokens=225, nsentences=8, sample_size=225.0, sample_size_v1=0, sample_size_v2=0
2023-05-09 05:50:20 - progress_bar.py[line:272] - INFO: epoch 030 | valid on 'valid' subset:   1911 / 2860 loss=2.31, loss_v1=0, loss_v2=0, nll_loss=1.083, ntokens=235, nsentences=8, sample_size=235.0, sample_size_v1=0, sample_size_v2=0
2023-05-09 05:50:32 - progress_bar.py[line:272] - INFO: epoch 030 | valid on 'valid' subset:   1921 / 2860 loss=2.626, loss_v1=0, loss_v2=0, nll_loss=1.429, ntokens=192, nsentences=8, sample_size=192.0, sample_size_v1=0, sample_size_v2=0
2023-05-09 05:50:45 - progress_bar.py[line:272] - INFO: epoch 030 | valid on 'valid' subset:   1931 / 2860 loss=2.56, loss_v1=0, loss_v2=0, nll_loss=1.358, ntokens=232, nsentences=8, sample_size=232.0, sample_size_v1=0, sample_size_v2=0
2023-05-09 05:50:58 - progress_bar.py[line:272] - INFO: epoch 030 | valid on 'valid' subset:   1941 / 2860 loss=2.446, loss_v1=0, loss_v2=0, nll_loss=1.227, ntokens=192, nsentences=8, sample_size=192.0, sample_size_v1=0, sample_size_v2=0
2331944 <sub> woman<pred> has<obj> hair<pred> wearing<obj> jean<pred> wearing<obj> shirt<pred> has<obj> nose<pred> has<obj> hand<sub> person<pred> wearing<obj> jean ['<sub> person<pred> has<obj> hair<sub> boy<pred> wearing<obj> jean<pred> has<obj> hand<pred> has<obj> hand<sub> hand<pred> holding<obj> plate<sub> fork<pred> on<obj> hand']
2414722 <sub> person<pred> on<obj> surfboard<sub> man<pred> on<obj> surfboard ['<sub> man<pred> holding<obj> surfboard<sub> surfboard<pred> under<obj> arm']
2023-05-09 05:51:10 - progress_bar.py[line:272] - INFO: epoch 030 | valid on 'valid' subset:   1951 / 2860 loss=2.626, loss_v1=0, loss_v2=0, nll_loss=1.432, ntokens=222, nsentences=8, sample_size=222.0, sample_size_v1=0, sample_size_v2=0
2023-05-09 05:51:22 - progress_bar.py[line:272] - INFO: epoch 030 | valid on 'valid' subset:   1961 / 2860 loss=2.67, loss_v1=0, loss_v2=0, nll_loss=1.489, ntokens=192, nsentences=8, sample_size=192.0, sample_size_v1=0, sample_size_v2=0
2023-05-09 05:51:35 - progress_bar.py[line:272] - INFO: epoch 030 | valid on 'valid' subset:   1971 / 2860 loss=2.309, loss_v1=0, loss_v2=0, nll_loss=1.087, ntokens=255, nsentences=8, sample_size=255.0, sample_size_v1=0, sample_size_v2=0
2023-05-09 05:51:49 - progress_bar.py[line:272] - INFO: epoch 030 | valid on 'valid' subset:   1981 / 2860 loss=2.543, loss_v1=0, loss_v2=0, nll_loss=1.346, ntokens=168, nsentences=8, sample_size=168.0, sample_size_v1=0, sample_size_v2=0
2023-05-09 05:52:01 - progress_bar.py[line:272] - INFO: epoch 030 | valid on 'valid' subset:   1991 / 2860 loss=2.433, loss_v1=0, loss_v2=0, nll_loss=1.215, ntokens=287, nsentences=8, sample_size=287.0, sample_size_v1=0, sample_size_v2=0
2414338 <sub> plate<pred> on<obj> table<sub> cup<pred> on<obj> table<sub> food<pred> on<obj> plate<sub> food<pred> on<obj> plate<sub> food<pred> on<obj> plate ['<sub> glass<pred> near<obj> plate<sub> plate<pred> on<obj> table<sub> table<pred> under<obj> plate']
2331507 <sub> pillow<pred> above<obj> bed<sub> pillow<pred> above<obj> bed<sub> pillow<pred> above<obj> bed<sub> pillow<pred> above<obj> bed<sub> pillow<pred> above<obj> bed<sub> pillow<pred> above<obj> bed<sub> pillow<pred> above<obj> bed<sub> pillow<pred> above<obj> bed<sub> pillow<pred> above<obj> bed<sub> pillow<pred> above<obj> bed<sub> pillow<pred> above<obj> bed<sub> pillow<pred> above<obj> bed<sub> pillow<pred> above<obj> bed<sub> pillow<pred> above<obj> bed ['<sub> drawer<pred> to<obj> desk<sub> bed<pred> in<obj> room<sub> bed<pred> in<obj> room<sub> lamp<pred> on<obj> desk<sub> chair<pred> at<obj> desk']
2023-05-09 05:52:15 - progress_bar.py[line:272] - INFO: epoch 030 | valid on 'valid' subset:   2001 / 2860 loss=2.494, loss_v1=0, loss_v2=0, nll_loss=1.281, ntokens=196, nsentences=8, sample_size=196.0, sample_size_v1=0, sample_size_v2=0
2023-05-09 05:52:29 - progress_bar.py[line:272] - INFO: epoch 030 | valid on 'valid' subset:   2011 / 2860 loss=2.461, loss_v1=0, loss_v2=0, nll_loss=1.253, ntokens=274, nsentences=8, sample_size=274.0, sample_size_v1=0, sample_size_v2=0
2023-05-09 05:52:42 - progress_bar.py[line:272] - INFO: epoch 030 | valid on 'valid' subset:   2021 / 2860 loss=2.539, loss_v1=0, loss_v2=0, nll_loss=1.34, ntokens=259, nsentences=8, sample_size=259.0, sample_size_v1=0, sample_size_v2=0
2023-05-09 05:52:55 - progress_bar.py[line:272] - INFO: epoch 030 | valid on 'valid' subset:   2031 / 2860 loss=2.52, loss_v1=0, loss_v2=0, nll_loss=1.319, ntokens=231, nsentences=8, sample_size=231.0, sample_size_v1=0, sample_size_v2=0
2023-05-09 05:53:06 - progress_bar.py[line:272] - INFO: epoch 030 | valid on 'valid' subset:   2041 / 2860 loss=2.47, loss_v1=0, loss_v2=0, nll_loss=1.269, ntokens=189, nsentences=8, sample_size=189.0, sample_size_v1=0, sample_size_v2=0
2413924 <sub> dog<pred> on<obj> bed<sub> dog<pred> on<obj> bed<sub> pillow<pred> on<obj> bed ['<sub> laptop<pred> on<obj> table<pred> has<obj> screen<sub> laptop<pred> on<obj> table<pred> has<obj> screen<sub> laptop<pred> on<obj> table<pred> has<obj> screen']
2331130 <sub> cat<pred> on<obj> bed<pred> on<obj> bed<sub> pillow<pred> on<obj> bed<sub> pillow<pred> on<obj> bed<sub> pillow<pred> on<obj> bed<sub> pillow<pred> on<obj> bed ['<sub> cat<pred> has<obj> paw<pred> has<obj> paw<pred> has<obj> paw<sub> paw<pred> of<obj> cat<sub> paw<pred> of<obj> cat<sub> ear<pred> on<obj> cat<sub> paw<pred> of<obj> cat']
2023-05-09 05:53:19 - progress_bar.py[line:272] - INFO: epoch 030 | valid on 'valid' subset:   2051 / 2860 loss=2.461, loss_v1=0, loss_v2=0, nll_loss=1.253, ntokens=271, nsentences=8, sample_size=271.0, sample_size_v1=0, sample_size_v2=0
2023-05-09 05:53:33 - progress_bar.py[line:272] - INFO: epoch 030 | valid on 'valid' subset:   2061 / 2860 loss=2.454, loss_v1=0, loss_v2=0, nll_loss=1.238, ntokens=274, nsentences=8, sample_size=274.0, sample_size_v1=0, sample_size_v2=0
2023-05-09 05:53:45 - progress_bar.py[line:272] - INFO: epoch 030 | valid on 'valid' subset:   2071 / 2860 loss=2.422, loss_v1=0, loss_v2=0, nll_loss=1.192, ntokens=284, nsentences=8, sample_size=284.0, sample_size_v1=0, sample_size_v2=0
2023-05-09 05:53:56 - progress_bar.py[line:272] - INFO: epoch 030 | valid on 'valid' subset:   2081 / 2860 loss=2.383, loss_v1=0, loss_v2=0, nll_loss=1.153, ntokens=255, nsentences=8, sample_size=255.0, sample_size_v1=0, sample_size_v2=0
2023-05-09 05:54:07 - progress_bar.py[line:272] - INFO: epoch 030 | valid on 'valid' subset:   2091 / 2860 loss=2.27, loss_v1=0, loss_v2=0, nll_loss=1.037, ntokens=275, nsentences=8, sample_size=275.0, sample_size_v1=0, sample_size_v2=0
2413537 <sub> bowl<pred> on<obj> table<sub> bowl<pred> on<obj> table<sub> bowl<pred> on<obj> table<sub> bowl<pred> on<obj> table ['<sub> person<pred> wearing<obj> shirt<pred> wearing<obj> glove<pred> wearing<obj> glove<sub> person<pred> wearing<obj> shirt<pred> wearing<obj> pant<sub> box<pred> near<obj> person']
2330749 <sub> window<pred> on<obj> building<sub> window<pred> on<obj> building<sub> window<pred> on<obj> building<sub> window<pred> on<obj> building<sub> window<pred> on<obj> building<sub> sign<pred> on<obj> building<sub> sign<pred> on<obj> building<sub> sign<pred> on<obj> building<sub> sign<pred> on<obj> building<sub> sign<pred> on<obj> building<sub> sign<pred> on<obj> building<sub> sign<pred> on<obj> building ['<sub> window<pred> of<obj> building<sub> window<pred> on<obj> building<sub> window<pred> on<obj> building<sub> window<pred> on<obj> building<sub> window<pred> of<obj> building<sub> window<pred> of<obj> building<sub> window<pred> on<obj> building<sub> sign<pred> on<obj> pole<sub> window<pred> on<obj> building<sub> window<pred> on<obj> building<sub> window<pred> on<obj> building<sub> window<pred> on<obj> building<sub> building<pred> has<obj> window<sub> window<pred> on<obj> building']
2023-05-09 05:54:20 - progress_bar.py[line:272] - INFO: epoch 030 | valid on 'valid' subset:   2101 / 2860 loss=2.293, loss_v1=0, loss_v2=0, nll_loss=1.063, ntokens=258, nsentences=8, sample_size=258.0, sample_size_v1=0, sample_size_v2=0
2023-05-09 05:54:31 - progress_bar.py[line:272] - INFO: epoch 030 | valid on 'valid' subset:   2111 / 2860 loss=2.549, loss_v1=0, loss_v2=0, nll_loss=1.348, ntokens=171, nsentences=8, sample_size=171.0, sample_size_v1=0, sample_size_v2=0
2023-05-09 05:54:44 - progress_bar.py[line:272] - INFO: epoch 030 | valid on 'valid' subset:   2121 / 2860 loss=2.309, loss_v1=0, loss_v2=0, nll_loss=1.077, ntokens=245, nsentences=8, sample_size=245.0, sample_size_v1=0, sample_size_v2=0
2023-05-09 05:54:58 - progress_bar.py[line:272] - INFO: epoch 030 | valid on 'valid' subset:   2131 / 2860 loss=2.696, loss_v1=0, loss_v2=0, nll_loss=1.514, ntokens=204, nsentences=8, sample_size=204.0, sample_size_v1=0, sample_size_v2=0
2023-05-09 05:55:11 - progress_bar.py[line:272] - INFO: epoch 030 | valid on 'valid' subset:   2141 / 2860 loss=2.495, loss_v1=0, loss_v2=0, nll_loss=1.29, ntokens=216, nsentences=8, sample_size=216.0, sample_size_v1=0, sample_size_v2=0
2330389 <sub> tail<pred> of<obj> horse<sub> leg<pred> of<obj> horse<sub> leg<pred> of<obj> horse<sub> leg<pred> of<obj> horse<sub> leg<pred> of<obj> horse ['<sub> leg<pred> of<obj> cow<sub> leg<pred> of<obj> cow<sub> tail<pred> of<obj> cow<sub> cow<pred> has<obj> eye<sub> neck<pred> of<obj> cow']
2413179 <sub> window<pred> on<obj> building<sub> window<pred> on<obj> building<sub> window<pred> on<obj> building<sub> window<pred> on<obj> building<sub> window<pred> on<obj> building<sub> window<pred> on<obj> building<sub> window<pred> on<obj> building<sub> window<pred> on<obj> building<sub> window<pred> on<obj> building<sub> window<pred> on<obj> building<sub> window<pred> on<obj> building<sub> window<pred> on<obj> building<sub> window<pred> on<obj> building<sub> window<pred> on<obj> building<sub> window<pred> on<obj> building<sub> window<pred> on<obj> building<sub> window<pred> on ['<sub> building<pred> with<obj> window<pred> with<obj> window<pred> with<obj> window<pred> with<obj> window<pred> with<obj> window<sub> window<pred> has<obj> curtain<sub> clock<pred> in front of<obj> tree']
2023-05-09 05:55:25 - progress_bar.py[line:272] - INFO: epoch 030 | valid on 'valid' subset:   2151 / 2860 loss=2.582, loss_v1=0, loss_v2=0, nll_loss=1.382, ntokens=296, nsentences=8, sample_size=296.0, sample_size_v1=0, sample_size_v2=0
2023-05-09 05:55:38 - progress_bar.py[line:272] - INFO: epoch 030 | valid on 'valid' subset:   2161 / 2860 loss=2.516, loss_v1=0, loss_v2=0, nll_loss=1.308, ntokens=193, nsentences=8, sample_size=193.0, sample_size_v1=0, sample_size_v2=0
2023-05-09 05:55:53 - progress_bar.py[line:272] - INFO: epoch 030 | valid on 'valid' subset:   2171 / 2860 loss=2.723, loss_v1=0, loss_v2=0, nll_loss=1.546, ntokens=323, nsentences=8, sample_size=323.0, sample_size_v1=0, sample_size_v2=0
2023-05-09 05:56:08 - progress_bar.py[line:272] - INFO: epoch 030 | valid on 'valid' subset:   2181 / 2860 loss=2.492, loss_v1=0, loss_v2=0, nll_loss=1.283, ntokens=191, nsentences=8, sample_size=191.0, sample_size_v1=0, sample_size_v2=0
2023-05-09 05:56:22 - progress_bar.py[line:272] - INFO: epoch 030 | valid on 'valid' subset:   2191 / 2860 loss=2.486, loss_v1=0, loss_v2=0, nll_loss=1.276, ntokens=215, nsentences=8, sample_size=215.0, sample_size_v1=0, sample_size_v2=0
2412850 <sub> dog<pred> near<obj> train<sub> train<pred> on<obj> track<sub> window<pred> on<obj> train<sub> window<pred> on<obj> train<sub> window<pred> on<obj> train<sub> window<pred> on<obj> train<sub> window<pred> on<obj> train<sub> window<pred> on<obj> train<sub> window<pred> on<obj> train<sub> window<pred> on<obj> train ['<sub> plant<pred> on<obj> hill<pred> has<obj> flower<pred> has<obj> leaf<sub> flower<pred> under<obj> plant<sub> building<pred> has<obj> roof<sub> tree<pred> has<obj> trunk']
2330046 <sub> car<pred> on<obj> street<sub> car<pred> on<obj> street ['<sub> car<pred> on<obj> street<sub> car<pred> on<obj> street']
2023-05-09 05:56:36 - progress_bar.py[line:272] - INFO: epoch 030 | valid on 'valid' subset:   2201 / 2860 loss=2.58, loss_v1=0, loss_v2=0, nll_loss=1.382, ntokens=286, nsentences=8, sample_size=286.0, sample_size_v1=0, sample_size_v2=0
2023-05-09 05:56:50 - progress_bar.py[line:272] - INFO: epoch 030 | valid on 'valid' subset:   2211 / 2860 loss=2.516, loss_v1=0, loss_v2=0, nll_loss=1.31, ntokens=326, nsentences=8, sample_size=326.0, sample_size_v1=0, sample_size_v2=0
2023-05-09 05:57:03 - progress_bar.py[line:272] - INFO: epoch 030 | valid on 'valid' subset:   2221 / 2860 loss=2.624, loss_v1=0, loss_v2=0, nll_loss=1.434, ntokens=194, nsentences=8, sample_size=194.0, sample_size_v1=0, sample_size_v2=0
2023-05-09 05:57:17 - progress_bar.py[line:272] - INFO: epoch 030 | valid on 'valid' subset:   2231 / 2860 loss=2.588, loss_v1=0, loss_v2=0, nll_loss=1.39, ntokens=270, nsentences=8, sample_size=270.0, sample_size_v1=0, sample_size_v2=0
2023-05-09 05:57:30 - progress_bar.py[line:272] - INFO: epoch 030 | valid on 'valid' subset:   2241 / 2860 loss=2.693, loss_v1=0, loss_v2=0, nll_loss=1.514, ntokens=200, nsentences=8, sample_size=200.0, sample_size_v1=0, sample_size_v2=0
2412516 <sub> airplane<pred> has<obj> wing<pred> has<obj> wing ['<sub> airplane<pred> in front of<obj> plane<sub> plane<pred> near<obj> airplane']
2329672 <sub> table<pred> with<obj> chair<pred> with<obj> chair<pred> with<obj> chair<pred> with<obj> chair<pred> with<obj> chair<pred> with<obj> chair<pred> with<obj> chair<pred> with<obj> chair<pred> with<obj> chair<pred> with<obj> chair<pred> with<obj> chair<pred> with<obj> chair<pred> with<obj> chair<pred> with<obj> chair<pred> with<obj> chair<pred> with<obj> chair<pred> with<obj> chair<pred> with<obj> chair<pred> with<obj> chair<pred> with<obj> chair<pred> with<obj> chair<pred> with<obj> chair<pred> with<obj> chair<pred> with<obj> chair<pred> with ['<sub> pizza<pred> on<obj> paper<sub> pizza<pred> on<obj> paper<sub> pizza<pred> on<obj> paper<sub> table<pred> with<obj> leg']
2023-05-09 05:57:45 - progress_bar.py[line:272] - INFO: epoch 030 | valid on 'valid' subset:   2251 / 2860 loss=2.42, loss_v1=0, loss_v2=0, nll_loss=1.208, ntokens=289, nsentences=8, sample_size=289.0, sample_size_v1=0, sample_size_v2=0
2023-05-09 05:57:59 - progress_bar.py[line:272] - INFO: epoch 030 | valid on 'valid' subset:   2261 / 2860 loss=2.463, loss_v1=0, loss_v2=0, nll_loss=1.252, ntokens=322, nsentences=8, sample_size=322.0, sample_size_v1=0, sample_size_v2=0
2023-05-09 05:58:12 - progress_bar.py[line:272] - INFO: epoch 030 | valid on 'valid' subset:   2271 / 2860 loss=2.49, loss_v1=0, loss_v2=0, nll_loss=1.277, ntokens=271, nsentences=8, sample_size=271.0, sample_size_v1=0, sample_size_v2=0
2023-05-09 05:58:27 - progress_bar.py[line:272] - INFO: epoch 030 | valid on 'valid' subset:   2281 / 2860 loss=2.521, loss_v1=0, loss_v2=0, nll_loss=1.312, ntokens=254, nsentences=8, sample_size=254.0, sample_size_v1=0, sample_size_v2=0
2023-05-09 05:58:40 - progress_bar.py[line:272] - INFO: epoch 030 | valid on 'valid' subset:   2291 / 2860 loss=2.658, loss_v1=0, loss_v2=0, nll_loss=1.468, ntokens=208, nsentences=8, sample_size=208.0, sample_size_v1=0, sample_size_v2=0
2329338 <sub> flower<pred> in<obj> vase<sub> flower<pred> in<obj> vase<sub> flower<pred> in<obj> vase<sub> flower<pred> in<obj> vase<sub> flower<pred> in<obj> vase ['<sub> vase<pred> of<obj> flower<pred> on<obj> table<sub> flower<pred> in<obj> vase<sub> flower<pred> in<obj> vase<sub> flower<pred> in<obj> vase']
2412193 <sub> person<pred> standing on<obj> sidewalk<sub> person<pred> standing on<obj> sidewalk<sub> person<pred> standing on<obj> sidewalk<sub> person<pred> standing on<obj> sidewalk<sub> person<pred> standing on<obj> sidewalk ['<sub> wheel<pred> of<obj> truck<sub> tree<pred> near<obj> truck<sub> car<pred> in front of<obj> truck']
2023-05-09 05:58:52 - progress_bar.py[line:272] - INFO: epoch 030 | valid on 'valid' subset:   2301 / 2860 loss=2.535, loss_v1=0, loss_v2=0, nll_loss=1.326, ntokens=224, nsentences=8, sample_size=224.0, sample_size_v1=0, sample_size_v2=0
2023-05-09 05:59:07 - progress_bar.py[line:272] - INFO: epoch 030 | valid on 'valid' subset:   2311 / 2860 loss=2.54, loss_v1=0, loss_v2=0, nll_loss=1.338, ntokens=387, nsentences=8, sample_size=387.0, sample_size_v1=0, sample_size_v2=0
2023-05-09 05:59:21 - progress_bar.py[line:272] - INFO: epoch 030 | valid on 'valid' subset:   2321 / 2860 loss=2.359, loss_v1=0, loss_v2=0, nll_loss=1.139, ntokens=276, nsentences=8, sample_size=276.0, sample_size_v1=0, sample_size_v2=0
2023-05-09 05:59:35 - progress_bar.py[line:272] - INFO: epoch 030 | valid on 'valid' subset:   2331 / 2860 loss=2.392, loss_v1=0, loss_v2=0, nll_loss=1.175, ntokens=293, nsentences=8, sample_size=293.0, sample_size_v1=0, sample_size_v2=0
2023-05-09 05:59:48 - progress_bar.py[line:272] - INFO: epoch 030 | valid on 'valid' subset:   2341 / 2860 loss=2.551, loss_v1=0, loss_v2=0, nll_loss=1.351, ntokens=266, nsentences=8, sample_size=266.0, sample_size_v1=0, sample_size_v2=0
2329029 <sub> man<pred> riding<obj> wave<pred> on<obj> surfboard<sub> man<pred> on<obj> surfboard<sub> man<pred> on<obj> surfboard ['<sub> person<pred> in<obj> wave<sub> surfboard<pred> in<obj> wave<sub> wave<pred> of<obj> wave<sub> train<pred> on<obj> wave<sub> wave<pred> of<obj> wave']
2411850 <sub> flower<pred> in<obj> vase<sub> vase<pred> on<obj> table<pred> holding<obj> flower ['<sub> plant<pred> in<obj> vase<pred> in<obj> vase<sub> vase<pred> near<obj> vase<sub> leaf<pred> on<obj> vase']
2023-05-09 06:00:02 - progress_bar.py[line:272] - INFO: epoch 030 | valid on 'valid' subset:   2351 / 2860 loss=2.23, loss_v1=0, loss_v2=0, nll_loss=0.987, ntokens=263, nsentences=8, sample_size=263.0, sample_size_v1=0, sample_size_v2=0
2023-05-09 06:00:17 - progress_bar.py[line:272] - INFO: epoch 030 | valid on 'valid' subset:   2361 / 2860 loss=2.534, loss_v1=0, loss_v2=0, nll_loss=1.329, ntokens=312, nsentences=8, sample_size=312.0, sample_size_v1=0, sample_size_v2=0
2023-05-09 06:00:32 - progress_bar.py[line:272] - INFO: epoch 030 | valid on 'valid' subset:   2371 / 2860 loss=2.498, loss_v1=0, loss_v2=0, nll_loss=1.297, ntokens=375, nsentences=8, sample_size=375.0, sample_size_v1=0, sample_size_v2=0
2023-05-09 06:00:46 - progress_bar.py[line:272] - INFO: epoch 030 | valid on 'valid' subset:   2381 / 2860 loss=2.674, loss_v1=0, loss_v2=0, nll_loss=1.486, ntokens=219, nsentences=8, sample_size=219.0, sample_size_v1=0, sample_size_v2=0
2023-05-09 06:01:01 - progress_bar.py[line:272] - INFO: epoch 030 | valid on 'valid' subset:   2391 / 2860 loss=2.629, loss_v1=0, loss_v2=0, nll_loss=1.431, ntokens=396, nsentences=8, sample_size=396.0, sample_size_v1=0, sample_size_v2=0
2411524 <sub> glass<pred> on<obj> table<sub> glass<pred> on<obj> table<sub> plate<pred> on<obj> table<sub> plate<pred> on<obj> table<sub> plate<pred> on<obj> table ['<sub> plate<pred> in<obj> cabinet<sub> window<pred> above<obj> sink<sub> cabinet<pred> has<obj> handle<sub> woman<pred> near<obj> window<sub> light<pred> over<obj> counter<sub> board<pred> on<obj> counter']
2328738 <sub> people<pred> standing on<obj> beach<sub> people<pred> standing on<obj> beach<sub> people<pred> standing on<obj> beach<sub> people<pred> standing on<obj> beach<sub> people<pred> standing on<obj> beach<sub> people<pred> standing on<obj> beach<sub> people<pred> standing on<obj> beach<sub> people<pred> standing on<obj> beach ['<sub> trunk<pred> on<obj> elephant<sub> person<pred> wearing<obj> hat<sub> person<pred> wearing<obj> shirt<sub> person<pred> riding<obj> elephant<sub> head<pred> of<obj> elephant<sub> head<pred> of<obj> elephant<sub> eye<pred> of<obj> elephant<sub> elephant<pred> has<obj> trunk<sub> mouth<pred> of<obj> elephant<sub> leg<pred> of<obj> elephant']
2023-05-09 06:01:16 - progress_bar.py[line:272] - INFO: epoch 030 | valid on 'valid' subset:   2401 / 2860 loss=2.661, loss_v1=0, loss_v2=0, nll_loss=1.471, ntokens=289, nsentences=8, sample_size=289.0, sample_size_v1=0, sample_size_v2=0
2023-05-09 06:01:30 - progress_bar.py[line:272] - INFO: epoch 030 | valid on 'valid' subset:   2411 / 2860 loss=2.497, loss_v1=0, loss_v2=0, nll_loss=1.298, ntokens=172, nsentences=8, sample_size=172.0, sample_size_v1=0, sample_size_v2=0
2023-05-09 06:01:44 - progress_bar.py[line:272] - INFO: epoch 030 | valid on 'valid' subset:   2421 / 2860 loss=2.313, loss_v1=0, loss_v2=0, nll_loss=1.084, ntokens=264, nsentences=8, sample_size=264.0, sample_size_v1=0, sample_size_v2=0
2023-05-09 06:01:57 - progress_bar.py[line:272] - INFO: epoch 030 | valid on 'valid' subset:   2431 / 2860 loss=2.422, loss_v1=0, loss_v2=0, nll_loss=1.204, ntokens=331, nsentences=8, sample_size=331.0, sample_size_v1=0, sample_size_v2=0
2023-05-09 06:02:11 - progress_bar.py[line:272] - INFO: epoch 030 | valid on 'valid' subset:   2441 / 2860 loss=2.565, loss_v1=0, loss_v2=0, nll_loss=1.372, ntokens=338, nsentences=8, sample_size=338.0, sample_size_v1=0, sample_size_v2=0
2415472 <sub> head<pred> of<obj> cat<sub> tail<pred> of<obj> cat<sub> leg<pred> of<obj> cat<sub> leg<pred> of<obj> cat<sub> leg<pred> of<obj> cat<sub> leg<pred> of<obj> cat<sub> cat<pred> on<obj> table<sub> tail<pred> of<obj> cat ['<sub> man<pred> in<obj> chair<sub> woman<pred> in<obj> chair<sub> cup<pred> on<obj> table<sub> chair<pred> in<obj> room<sub> table<pred> in<obj> room<sub> cup<pred> on<obj> table<sub> chair<pred> in<obj> room<sub> pillow<pred> in<obj> chair']
2328401 <sub> bear<pred> has<obj> ear<pred> has<obj> mouth<pred> has<obj> head ['<sub> wheel<pred> of<obj> bike<sub> light<pred> of<obj> bike']
2023-05-09 06:02:26 - progress_bar.py[line:272] - INFO: epoch 030 | valid on 'valid' subset:   2451 / 2860 loss=2.563, loss_v1=0, loss_v2=0, nll_loss=1.357, ntokens=250, nsentences=8, sample_size=250.0, sample_size_v1=0, sample_size_v2=0
2023-05-09 06:02:40 - progress_bar.py[line:272] - INFO: epoch 030 | valid on 'valid' subset:   2461 / 2860 loss=2.527, loss_v1=0, loss_v2=0, nll_loss=1.323, ntokens=239, nsentences=8, sample_size=239.0, sample_size_v1=0, sample_size_v2=0
2023-05-09 06:02:54 - progress_bar.py[line:272] - INFO: epoch 030 | valid on 'valid' subset:   2471 / 2860 loss=2.658, loss_v1=0, loss_v2=0, nll_loss=1.467, ntokens=320, nsentences=8, sample_size=320.0, sample_size_v1=0, sample_size_v2=0
2023-05-09 06:03:09 - progress_bar.py[line:272] - INFO: epoch 030 | valid on 'valid' subset:   2481 / 2860 loss=2.297, loss_v1=0, loss_v2=0, nll_loss=1.063, ntokens=264, nsentences=8, sample_size=264.0, sample_size_v1=0, sample_size_v2=0
2023-05-09 06:03:22 - progress_bar.py[line:272] - INFO: epoch 030 | valid on 'valid' subset:   2491 / 2860 loss=2.647, loss_v1=0, loss_v2=0, nll_loss=1.461, ntokens=209, nsentences=8, sample_size=209.0, sample_size_v1=0, sample_size_v2=0
2328121 <sub> food<pred> on<obj> plate<pred> on<obj> table<sub> vegetable<pred> on<obj> plate<sub> vegetable<pred> on<obj> plate<sub> vegetable<pred> on<obj> plate<sub> vegetable<pred> on<obj> plate ['<sub> food<pred> sitting on<obj> table<sub> leaf<pred> on<obj> table<sub> food<pred> sitting on<obj> plate<sub> food<pred> sitting on<obj> table']
2415810 <sub> nose<pred> of<obj> plane<sub> wheel<pred> under<obj> plane<sub> wheel<pred> under<obj> plane<sub> wheel<pred> under<obj> plane<sub> wheel<pred> under<obj> plane<sub> wheel<pred> under<obj> plane<sub> wheel<pred> under<obj> plane<sub> wheel<pred> under<obj> plane<sub> wheel<pred> under<obj> plane<sub> wheel<pred> under<obj> plane<sub> wheel<pred> under<obj> plane<sub> wheel<pred> under<obj> plane<sub> wheel<pred> under<obj> plane<sub> wheel<pred> under<obj> plane ['<sub> wheel<pred> on<obj> plane<sub> wheel<pred> on<obj> plane<sub> roof<pred> on<obj> house<sub> tail<pred> of<obj> plane']
2023-05-09 06:03:38 - progress_bar.py[line:272] - INFO: epoch 030 | valid on 'valid' subset:   2501 / 2860 loss=2.359, loss_v1=0, loss_v2=0, nll_loss=1.129, ntokens=328, nsentences=8, sample_size=328.0, sample_size_v1=0, sample_size_v2=0
2023-05-09 06:03:52 - progress_bar.py[line:272] - INFO: epoch 030 | valid on 'valid' subset:   2511 / 2860 loss=2.357, loss_v1=0, loss_v2=0, nll_loss=1.133, ntokens=289, nsentences=8, sample_size=289.0, sample_size_v1=0, sample_size_v2=0
2023-05-09 06:04:06 - progress_bar.py[line:272] - INFO: epoch 030 | valid on 'valid' subset:   2521 / 2860 loss=2.501, loss_v1=0, loss_v2=0, nll_loss=1.297, ntokens=198, nsentences=8, sample_size=198.0, sample_size_v1=0, sample_size_v2=0
2023-05-09 06:04:19 - progress_bar.py[line:272] - INFO: epoch 030 | valid on 'valid' subset:   2531 / 2860 loss=2.565, loss_v1=0, loss_v2=0, nll_loss=1.367, ntokens=256, nsentences=8, sample_size=256.0, sample_size_v1=0, sample_size_v2=0
2023-05-09 06:04:33 - progress_bar.py[line:272] - INFO: epoch 030 | valid on 'valid' subset:   2541 / 2860 loss=2.438, loss_v1=0, loss_v2=0, nll_loss=1.223, ntokens=285, nsentences=8, sample_size=285.0, sample_size_v1=0, sample_size_v2=0
2416102 <sub> tail<pred> of<obj> plane<pred> of<obj> plane<sub> wing<pred> of<obj> plane<sub> nose<pred> of<obj> plane<sub> plane<pred> in<obj> plane<sub> plane<pred> in<obj> plane<sub> plane<pred> in<obj> plane ['<sub> wing<pred> on<obj> plane<sub> wing<pred> on<obj> plane<sub> wing<pred> on<obj> plane<sub> wheel<pred> on<obj> plane']
2327847 <sub> branch<pred> on<obj> tree<sub> branch<pred> on<obj> tree<sub> branch<pred> on<obj> tree<sub> branch<pred> on<obj> tree<sub> branch<pred> on<obj> tree<sub> branch<pred> on<obj> tree<sub> branch<pred> on<obj> tree<sub> branch<pred> on<obj> tree<sub> branch<pred> on<obj> tree<sub> branch<pred> on<obj> tree<sub> branch<pred> on<obj> tree<sub> branch<pred> on<obj> tree<sub> branch<pred> on<obj> tree<sub> branch<pred> on<obj> tree<sub> branch<pred> on<obj> tree<sub> branch<pred> on<obj> tree<sub> branch<pred> on ['<sub> people<pred> riding<obj> elephant<sub> person<pred> wearing<obj> shirt<sub> seat<pred> mounted on<obj> elephant<sub> man<pred> riding<obj> elephant<pred> wearing<obj> shirt<pred> has<obj> hair<pred> has<obj> head<sub> woman<pred> sitting on<obj> elephant<pred> riding<obj> elephant<sub> ear<pred> belonging to<obj> elephant<sub> trunk<pred> belonging to<obj> elephant<sub> leaf<pred> on<obj> tree<sub> leaf<pred> on<obj> tree<sub> leaf<pred> on<obj> tree<sub> leaf<pred> on<obj> tree<sub> man<pred> wearing<obj> shirt<sub> hair<pred> on<obj> head<sub> woman']
2023-05-09 06:04:48 - progress_bar.py[line:272] - INFO: epoch 030 | valid on 'valid' subset:   2551 / 2860 loss=2.216, loss_v1=0, loss_v2=0, nll_loss=0.976, ntokens=483, nsentences=8, sample_size=483.0, sample_size_v1=0, sample_size_v2=0
2023-05-09 06:05:02 - progress_bar.py[line:272] - INFO: epoch 030 | valid on 'valid' subset:   2561 / 2860 loss=2.436, loss_v1=0, loss_v2=0, nll_loss=1.218, ntokens=228, nsentences=8, sample_size=228.0, sample_size_v1=0, sample_size_v2=0
2023-05-09 06:05:16 - progress_bar.py[line:272] - INFO: epoch 030 | valid on 'valid' subset:   2571 / 2860 loss=2.568, loss_v1=0, loss_v2=0, nll_loss=1.368, ntokens=221, nsentences=8, sample_size=221.0, sample_size_v1=0, sample_size_v2=0
2023-05-09 06:05:30 - progress_bar.py[line:272] - INFO: epoch 030 | valid on 'valid' subset:   2581 / 2860 loss=2.508, loss_v1=0, loss_v2=0, nll_loss=1.307, ntokens=178, nsentences=8, sample_size=178.0, sample_size_v1=0, sample_size_v2=0
2023-05-09 06:05:44 - progress_bar.py[line:272] - INFO: epoch 030 | valid on 'valid' subset:   2591 / 2860 loss=2.209, loss_v1=0, loss_v2=0, nll_loss=0.969, ntokens=323, nsentences=8, sample_size=323.0, sample_size_v1=0, sample_size_v2=0
2327533 <sub> eye<pred> of<obj> cat<sub> eye<pred> of<obj> cat<sub> nose<pred> of<obj> cat<sub> cat<pred> has<obj> eye<pred> has<obj> eye<pred> has<obj> eye ['<sub> tail<pred> of<obj> cat<sub> neck<pred> of<obj> cat<sub> ear<pred> of<obj> cat']
2416395 <sub> head<pred> of<obj> man<sub> hand<pred> of<obj> man<sub> leg<pred> of<obj> man<sub> man<pred> on<obj> surfboard<pred> riding<obj> wave<sub> wave<pred> behind<obj> man<sub> wave<pred> behind<obj> man ['<sub> man<pred> wearing<obj> short<pred> on<obj> surfboard<pred> has<obj> arm<sub> hair<pred> on<obj> man<sub> arm<pred> on<obj> man']
2023-05-09 06:05:58 - progress_bar.py[line:272] - INFO: epoch 030 | valid on 'valid' subset:   2601 / 2860 loss=2.287, loss_v1=0, loss_v2=0, nll_loss=1.055, ntokens=323, nsentences=8, sample_size=323.0, sample_size_v1=0, sample_size_v2=0
2023-05-09 06:06:12 - progress_bar.py[line:272] - INFO: epoch 030 | valid on 'valid' subset:   2611 / 2860 loss=2.305, loss_v1=0, loss_v2=0, nll_loss=1.075, ntokens=266, nsentences=8, sample_size=266.0, sample_size_v1=0, sample_size_v2=0
2023-05-09 06:06:26 - progress_bar.py[line:272] - INFO: epoch 030 | valid on 'valid' subset:   2621 / 2860 loss=2.438, loss_v1=0, loss_v2=0, nll_loss=1.213, ntokens=287, nsentences=8, sample_size=287.0, sample_size_v1=0, sample_size_v2=0
2023-05-09 06:06:41 - progress_bar.py[line:272] - INFO: epoch 030 | valid on 'valid' subset:   2631 / 2860 loss=2.549, loss_v1=0, loss_v2=0, nll_loss=1.353, ntokens=366, nsentences=8, sample_size=366.0, sample_size_v1=0, sample_size_v2=0
2023-05-09 06:06:55 - progress_bar.py[line:272] - INFO: epoch 030 | valid on 'valid' subset:   2641 / 2860 loss=2.545, loss_v1=0, loss_v2=0, nll_loss=1.337, ntokens=222, nsentences=8, sample_size=222.0, sample_size_v1=0, sample_size_v2=0
2327247 <sub> man<pred> on<obj> surfboard<pred> riding<obj> wave<sub> head<pred> of<obj> man<sub> arm<pred> of<obj> man<sub> arm<pred> of<obj> man<sub> leg<pred> of<obj> man ['<sub> man<pred> on<obj> board<pred> has<obj> hair<pred> on<obj> surfboard<pred> riding<obj> wave']
2416707 <sub> roof<pred> of<obj> building<sub> roof<pred> of<obj> building ['<sub> cat<pred> in<obj> boat<sub> table<pred> on<obj> rock']
2023-05-09 06:07:11 - progress_bar.py[line:272] - INFO: epoch 030 | valid on 'valid' subset:   2651 / 2860 loss=2.46, loss_v1=0, loss_v2=0, nll_loss=1.245, ntokens=315, nsentences=8, sample_size=315.0, sample_size_v1=0, sample_size_v2=0
2023-05-09 06:07:24 - progress_bar.py[line:272] - INFO: epoch 030 | valid on 'valid' subset:   2661 / 2860 loss=2.455, loss_v1=0, loss_v2=0, nll_loss=1.246, ntokens=214, nsentences=8, sample_size=214.0, sample_size_v1=0, sample_size_v2=0
2023-05-09 06:07:38 - progress_bar.py[line:272] - INFO: epoch 030 | valid on 'valid' subset:   2671 / 2860 loss=2.432, loss_v1=0, loss_v2=0, nll_loss=1.218, ntokens=243, nsentences=8, sample_size=243.0, sample_size_v1=0, sample_size_v2=0
2023-05-09 06:07:51 - progress_bar.py[line:272] - INFO: epoch 030 | valid on 'valid' subset:   2681 / 2860 loss=2.227, loss_v1=0, loss_v2=0, nll_loss=0.987, ntokens=275, nsentences=8, sample_size=275.0, sample_size_v1=0, sample_size_v2=0
2023-05-09 06:08:04 - progress_bar.py[line:272] - INFO: epoch 030 | valid on 'valid' subset:   2691 / 2860 loss=2.872, loss_v1=0, loss_v2=0, nll_loss=1.713, ntokens=135, nsentences=8, sample_size=135.0, sample_size_v1=0, sample_size_v2=0
2326906 <sub> man<pred> wearing<obj> shoe<pred> wearing<obj> shoe<pred> wearing<obj> tie<pred> wearing<obj> jacket<pred> has<obj> hand<sub> shoe<pred> on<obj> man<sub> shoe<pred> on<obj> man<sub> shoe<pred> on<obj> man<sub> shoe<pred> on<obj> man<sub> shoe<pred> on<obj> man<sub> shoe<pred> on<obj> man ['<sub> handle<pred> on<obj> cabinet<pred> on<obj> cabinet<pred> on<obj> door<sub> leg<pred> of<obj> chair<sub> door<pred> with<obj> handle']
2417019 <sub> sign<pred> on<obj> pole<sub> sign<pred> on<obj> pole<sub> sign<pred> on<obj> pole<sub> sign<pred> on<obj> pole<sub> sign<pred> on<obj> pole ['<sub> airplane<pred> has<obj> wing<sub> tree<pred> under<obj> airplane']
2023-05-09 06:08:17 - progress_bar.py[line:272] - INFO: epoch 030 | valid on 'valid' subset:   2701 / 2860 loss=2.609, loss_v1=0, loss_v2=0, nll_loss=1.418, ntokens=136, nsentences=8, sample_size=136.0, sample_size_v1=0, sample_size_v2=0
2023-05-09 06:08:31 - progress_bar.py[line:272] - INFO: epoch 030 | valid on 'valid' subset:   2711 / 2860 loss=2.488, loss_v1=0, loss_v2=0, nll_loss=1.278, ntokens=193, nsentences=8, sample_size=193.0, sample_size_v1=0, sample_size_v2=0
2023-05-09 06:08:44 - progress_bar.py[line:272] - INFO: epoch 030 | valid on 'valid' subset:   2721 / 2860 loss=2.644, loss_v1=0, loss_v2=0, nll_loss=1.449, ntokens=328, nsentences=8, sample_size=328.0, sample_size_v1=0, sample_size_v2=0
2023-05-09 06:08:57 - progress_bar.py[line:272] - INFO: epoch 030 | valid on 'valid' subset:   2731 / 2860 loss=2.377, loss_v1=0, loss_v2=0, nll_loss=1.152, ntokens=273, nsentences=8, sample_size=273.0, sample_size_v1=0, sample_size_v2=0
2023-05-09 06:09:11 - progress_bar.py[line:272] - INFO: epoch 030 | valid on 'valid' subset:   2741 / 2860 loss=2.494, loss_v1=0, loss_v2=0, nll_loss=1.28, ntokens=293, nsentences=8, sample_size=293.0, sample_size_v1=0, sample_size_v2=0
2417337 <sub> skier<pred> on<obj> snow<sub> skier<pred> on<obj> snow<sub> mountain<pred> covered in<obj> snow<sub> mountain<pred> covered in<obj> snow<sub> mountain<pred> covered in<obj> snow ['<sub> person<pred> holding<obj> pole<pred> holding<obj> pole<sub> snow<pred> on<obj> beach<sub> man<pred> on<obj> ski<pred> on<obj> ski<sub> skier<pred> standing on<obj> snow<sub> coat<pred> on<obj> man']
2326604 <sub> zebra<pred> has<obj> ear<pred> has<obj> ear<pred> has<obj> leg<pred> has<obj> leg<pred> has<obj> leg<pred> has<obj> leg<pred> has<obj> leg<pred> has<obj> leg<pred> has<obj> leg<pred> has<obj> leg<pred> has<obj> leg<sub> zebra<pred> has<obj> ear<pred> has<obj> ear<pred> has<obj> leg<pred> has<obj> leg ['<sub> leg<pred> on<obj> zebra<sub> leg<pred> on<obj> zebra<sub> leg<pred> on<obj> zebra<sub> leg<pred> of<obj> zebra<sub> ear<pred> of<obj> zebra<sub> ear<pred> of<obj> zebra<sub> leg<pred> on<obj> zebra<sub> leg<pred> on<obj> zebra<sub> leg<pred> on<obj> zebra<sub> leg<pred> on<obj> zebra<sub> head<pred> of<obj> zebra<sub> head<pred> of<obj> zebra']
2023-05-09 06:09:25 - progress_bar.py[line:272] - INFO: epoch 030 | valid on 'valid' subset:   2751 / 2860 loss=2.422, loss_v1=0, loss_v2=0, nll_loss=1.2, ntokens=378, nsentences=8, sample_size=378.0, sample_size_v1=0, sample_size_v2=0
2023-05-09 06:09:40 - progress_bar.py[line:272] - INFO: epoch 030 | valid on 'valid' subset:   2761 / 2860 loss=2.446, loss_v1=0, loss_v2=0, nll_loss=1.233, ntokens=263, nsentences=8, sample_size=263.0, sample_size_v1=0, sample_size_v2=0
2023-05-09 06:09:54 - progress_bar.py[line:272] - INFO: epoch 030 | valid on 'valid' subset:   2771 / 2860 loss=2.538, loss_v1=0, loss_v2=0, nll_loss=1.332, ntokens=296, nsentences=8, sample_size=296.0, sample_size_v1=0, sample_size_v2=0
2023-05-09 06:10:09 - progress_bar.py[line:272] - INFO: epoch 030 | valid on 'valid' subset:   2781 / 2860 loss=2.557, loss_v1=0, loss_v2=0, nll_loss=1.352, ntokens=194, nsentences=8, sample_size=194.0, sample_size_v1=0, sample_size_v2=0
2023-05-09 06:10:26 - progress_bar.py[line:272] - INFO: epoch 030 | valid on 'valid' subset:   2791 / 2860 loss=2.479, loss_v1=0, loss_v2=0, nll_loss=1.269, ntokens=224, nsentences=8, sample_size=224.0, sample_size_v1=0, sample_size_v2=0
2417626 <sub> player<pred> has<obj> head<pred> has<obj> hand<pred> has<obj> hand<pred> has<obj> arm<pred> wearing<obj> short<pred> wearing<obj> shirt<pred> has<obj> hair<sub> racket<pred> has<obj> handle<sub> hand<pred> holding<obj> racket ['<sub> player<pred> has<obj> pant<sub> hat<pred> on<obj> head<sub> hat<pred> on<obj> head<sub> hat<pred> on<obj> head<sub> man<pred> with<obj> glove<pred> wearing<obj> hat']
2326324 <sub> girl<pred> has<obj> shoe<pred> has<obj> pant<pred> has<obj> shirt<pred> has<obj> hair<pred> has<obj> pant<sub> building<pred> has<obj> window<pred> has<obj> window<pred> has<obj> window<pred> has<obj> window<pred> has<obj> window<pred> has<obj> window<pred> has<obj> window<pred> has<obj> window<pred> has<obj> window ['<sub> plant<pred> in<obj> pot<sub> shoe<pred> of<obj> man<sub> shoe<pred> of<obj> man<sub> umbrella<pred> of<obj> man<sub> man<pred> has<obj> leg<pred> wears<obj> glass<pred> wearing<obj> shoe<pred> wearing<obj> pant<pred> wearing<obj> jacket<pred> with<obj> umbrella<pred> holding<obj> umbrella<sub> leg<pred> of<obj> man<sub> jacket<pred> of<obj> man<sub> glass<pred> of<obj> man<sub> shirt<pred> of<obj> man<sub> door<pred> behind<obj> man<pred> with<obj> window<sub> plant<pred> hanging from<obj> pot']
2023-05-09 06:10:40 - progress_bar.py[line:272] - INFO: epoch 030 | valid on 'valid' subset:   2801 / 2860 loss=2.599, loss_v1=0, loss_v2=0, nll_loss=1.404, ntokens=274, nsentences=8, sample_size=274.0, sample_size_v1=0, sample_size_v2=0
2023-05-09 06:10:55 - progress_bar.py[line:272] - INFO: epoch 030 | valid on 'valid' subset:   2811 / 2860 loss=2.498, loss_v1=0, loss_v2=0, nll_loss=1.289, ntokens=223, nsentences=8, sample_size=223.0, sample_size_v1=0, sample_size_v2=0
2023-05-09 06:11:10 - progress_bar.py[line:272] - INFO: epoch 030 | valid on 'valid' subset:   2821 / 2860 loss=2.363, loss_v1=0, loss_v2=0, nll_loss=1.137, ntokens=305, nsentences=8, sample_size=305.0, sample_size_v1=0, sample_size_v2=0
2023-05-09 06:11:25 - progress_bar.py[line:272] - INFO: epoch 030 | valid on 'valid' subset:   2831 / 2860 loss=2.571, loss_v1=0, loss_v2=0, nll_loss=1.371, ntokens=232, nsentences=8, sample_size=232.0, sample_size_v1=0, sample_size_v2=0
2023-05-09 06:11:40 - progress_bar.py[line:272] - INFO: epoch 030 | valid on 'valid' subset:   2841 / 2860 loss=2.67, loss_v1=0, loss_v2=0, nll_loss=1.481, ntokens=301, nsentences=8, sample_size=301.0, sample_size_v1=0, sample_size_v2=0
2417938 <sub> nose<pred> of<obj> dog<sub> dog<pred> on<obj> chair<sub> ear<pred> of<obj> dog<sub> ear<pred> of<obj> dog ['<sub> banana<pred> has<obj> banana<sub> chair<pred> at<obj> table']
2326034 <sub> tree<pred> covered in<obj> snow<sub> tree<pred> covered in<obj> snow<sub> tree<pred> covered in<obj> snow<pred> covered in<obj> snow<sub> tree<pred> covered in<obj> snow<pred> covered in<obj> snow<pred> covered in<obj> snow<pred> covered in<obj> snow<sub> tree<pred> covered in<obj> snow<sub> tree<pred> covered in<obj> snow<sub> tree<pred> covered in<obj> snow<sub> tree<pred> covered in<obj> snow ['<sub> snow<pred> covering<obj> snow<sub> snow<pred> covering<obj> snow<sub> snow<pred> covering<obj> snow<sub> snow<pred> covering<obj> snow<sub> snow<pred> covered in<obj> snow<sub> tree<pred> in<obj> snow<sub> head<pred> of<obj> person<pred> of<obj> man<sub> leg<pred> of<obj> man<sub> leg<pred> of<obj> man<pred> of<obj> person<sub> leg<pred> of<obj> person<sub> hand<pred> of<obj> man<sub> head<pred> of<obj> person<sub> arm<pred> of<obj> person<pred> of<obj> man<sub> arm<pred> of<obj> man<sub> arm<pred>']
2023-05-09 06:11:55 - progress_bar.py[line:272] - INFO: epoch 030 | valid on 'valid' subset:   2851 / 2860 loss=2.613, loss_v1=0, loss_v2=0, nll_loss=1.418, ntokens=295, nsentences=8, sample_size=295.0, sample_size_v1=0, sample_size_v2=0
local datafile ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 1 begin to initialize row_count and line_idx-to-offset mapping
2023-05-09 06:12:06 - progress_bar.py[line:282] - INFO: epoch 030 | valid on 'valid' subset | loss 2.457 | loss_v1 0 | loss_v2 0 | nll_loss 1.243 | ntokens 286.856 | nsentences 8 | sample_size 286.856 | sample_size_v1 0 | sample_size_v2 0 | ppl 2.37 | wps 199 | wpb 286.9 | bsz 8 | num_updates 25933
2023-05-09 06:12:06 - checkpoint_utils.py[line:64] - INFO: Preparing to save checkpoint for epoch 30 @ 25933 updates
2023-05-09 06:12:06 - trainer.py[line:431] - INFO: Saving checkpoint to ../../checkpoints/OFA/sgcls_checkpoints/_30_3e-5_480/tmp/checkpoint30.pt
local datafile ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 1 finished initializing row_count and line_idx-to-offset mapping
file ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 1 row count 27700 total row count 55400
slice_id 1 seek offset 27700
2023-05-09 06:12:13 - trainer.py[line:441] - INFO: Finished saving checkpoint to ../../checkpoints/OFA/sgcls_checkpoints/_30_3e-5_480/tmp/checkpoint30.pt
2023-05-09 06:12:50 - checkpoint_utils.py[line:133] - INFO: Saved checkpoint ../../checkpoints/OFA/sgcls_checkpoints/_30_3e-5_480/tmp/checkpoint30.pt (epoch 30 @ 25933 updates, score 2.457) (writing took 43.76994259603089 seconds)
2023-05-09 06:12:50 - train.py[line:332] - INFO: end of epoch 30 (average epoch stats below)
2023-05-09 06:12:50 - progress_bar.py[line:282] - INFO: epoch 030 | loss 2.019 | loss_v1 0 | loss_v2 0 | nll_loss 0.775 | ntokens 2103.48 | nsentences 63.972 | sample_size 2103.48 | sample_size_v1 0 | sample_size_v2 0 | ppl 1.71 | wps 237.7 | ups 0.11 | wpb 2103.5 | bsz 64 | num_updates 25933 | lr 5.77348e-08 | gnorm 6.798 | clip 100 | loss_scale 64 | train_wall 3481 | gb_free 8.7 | wall 109011
2023-05-09 06:12:50 - trainer.py[line:639] - INFO: loading train data for epoch 31
local datafile ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 0 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 0 finished initializing row_count and line_idx-to-offset mapping
file ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 0 row count 27700 total row count 55400
slice_id 0 seek offset 0
2023-05-09 06:12:51 - train.py[line:214] - INFO: done training in 109010.6 seconds
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                  train/bsz ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:                 train/clip ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:              train/gb_free ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:                train/gnorm █▁▂▃▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▅▅▅▅▆▆▆▆
wandb:                 train/loss █▂▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:           train/loss_scale ▁▄█▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄
wandb:              train/loss_v1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:              train/loss_v2 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:                   train/lr ▅██▇▇▇▇▆▆▆▆▅▅▅▅▅▄▄▄▄▃▃▃▃▂▂▂▂▁▁
wandb:             train/nll_loss █▂▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:           train/nsentences ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:              train/ntokens ▁▆▆▄▆▇▅▆▄▆▆█▅▄▇▇▄▄▇▄▄▇▇▆▃▆▅▇▄▇
wandb:                  train/ppl █▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:          train/sample_size ▁▆▆▄▆▇▅▆▄▆▆█▅▄▇▇▄▄▇▄▄▇▇▆▃▆▅▇▄▇
wandb:       train/sample_size_v1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/sample_size_v2 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:           train/train_wall ▃▁▁▂▂▂▂▂▁▁▁▁▂▂▂▁▂█▁▄▄▅▄▅▅▃▂▂▂▁
wandb:                  train/ups █████████████████▇███████████▁
wandb:                 train/wall ▁▁▁▂▂▂▂▃▃▃▃▄▄▄▄▄▅▅▅▅▆▆▆▆▇▇▇▇▇█
wandb:                  train/wpb ▁▆▆▄▆▇▅▆▄▆▆█▅▄▇▇▄▄▇▄▄▇▆▆▃▆▄▆▄▇
wandb:                  train/wps █████████████████████████████▁
wandb:            train_inner/bsz ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:           train_inner/clip ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:        train_inner/gb_free ▆▆▇▄▆▂▇▁▇▅▆▄▅▄▇▅▃█▆▅▆▄█▆▅▅▇█▇▅█▇▆▄█▇▇▄▆▅
wandb:          train_inner/gnorm ▆▂▁▂▄▃▆▅▅▆▅▆▆▆▅▅▅▄▅▄▅▅▅▆▆▅▅▅▆▆▆▆▇▇█▆▇██▇
wandb:           train_inner/loss █▃▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     train_inner/loss_scale ▁▁▄█▄▄▄▄▄▄▄▂▄▄▄▄▄▄▄▄▄▄█▄▄▄▄▄▄▄▄▄▄▂▄▂▄▄▄▄
wandb:        train_inner/loss_v1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:        train_inner/loss_v2 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:             train_inner/lr ▂▅███▇▇▇▇▇▇▆▆▆▆▆▅▅▅▅▅▄▄▄▄▄▃▃▃▃▃▃▂▂▂▂▂▁▁▁
wandb:       train_inner/nll_loss █▃▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     train_inner/nsentences ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:        train_inner/ntokens ▂▅▃▅▆█▂▇▄▁▂▂▆▂▂▅▆▆▃▅▆▄▁▂▃▇▃▂▄▇▅▅▄▆▁▇▂▄▂▆
wandb:            train_inner/ppl █▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:    train_inner/sample_size ▂▅▃▅▆█▂▇▄▁▂▂▆▂▂▅▆▆▃▅▆▄▁▂▃▇▃▂▄▇▅▅▄▆▁▇▂▄▂▆
wandb: train_inner/sample_size_v1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: train_inner/sample_size_v2 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     train_inner/train_wall ▁▃▁▁▁▃▁▁▁▁▁▁▁▁▁▁▃▃▁▁▁▁█▁▁▃▃▁▁▃▁▁▁▃▁▁▁▃▁▁
wandb:            train_inner/ups █████▄██████████▄▄████▁██████▄███▄██████
wandb:           train_inner/wall ▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███
wandb:            train_inner/wpb ▂▅▃▅▆█▂▇▄▁▂▂▆▂▂▅▆▆▃▅▆▄▁▂▃▇▃▂▄▇▅▅▄▆▁▇▂▄▂▆
wandb:            train_inner/wps ▄▆▅▆▇█▄█▅▃▄▄▇▄▄▇▆▆▅▇▇▅▁▄▅▇▄▄▅▆▆▆▆▆▃█▄▅▅▇
wandb:                  valid/bsz ▁
wandb:                 valid/loss ▁
wandb:              valid/loss_v1 ▁
wandb:              valid/loss_v2 ▁
wandb:             valid/nll_loss ▁
wandb:           valid/nsentences ▁
wandb:              valid/ntokens ▁
wandb:                  valid/ppl ▁
wandb:          valid/sample_size ▁
wandb:       valid/sample_size_v1 ▁
wandb:       valid/sample_size_v2 ▁
wandb:                  valid/wpb ▁
wandb:                  valid/wps ▁
wandb: 
wandb: Run summary:
wandb:                  train/bsz 64.0
wandb:                 train/clip 100.0
wandb:              train/gb_free 8.7
wandb:                train/gnorm 6.798
wandb:                 train/loss 2.019
wandb:           train/loss_scale 64.0
wandb:              train/loss_v1 0.0
wandb:              train/loss_v2 0.0
wandb:                   train/lr 0.0
wandb:             train/nll_loss 0.775
wandb:           train/nsentences 63.972
wandb:              train/ntokens 2103.476
wandb:                  train/ppl 1.71
wandb:          train/sample_size 2103.476
wandb:       train/sample_size_v1 0.0
wandb:       train/sample_size_v2 0.0
wandb:           train/train_wall 3481.0
wandb:                  train/ups 0.11
wandb:                 train/wall 109011.0
wandb:                  train/wpb 2103.5
wandb:                  train/wps 237.7
wandb:            train_inner/bsz 64.0
wandb:           train_inner/clip 100.0
wandb:        train_inner/gb_free 7.7
wandb:          train_inner/gnorm 6.854
wandb:           train_inner/loss 2.024
wandb:     train_inner/loss_scale 64.0
wandb:        train_inner/loss_v1 0.0
wandb:        train_inner/loss_v2 0.0
wandb:             train_inner/lr 0.0
wandb:       train_inner/nll_loss 0.78
wandb:     train_inner/nsentences 64.0
wandb:        train_inner/ntokens 2023.2
wandb:            train_inner/ppl 1.72
wandb:    train_inner/sample_size 2023.2
wandb: train_inner/sample_size_v1 0.0
wandb: train_inner/sample_size_v2 0.0
wandb:     train_inner/train_wall 40.0
wandb:            train_inner/ups 0.25
wandb:           train_inner/wall 104834.0
wandb:            train_inner/wpb 2023.2
wandb:            train_inner/wps 506.3
wandb:                  valid/bsz 8.0
wandb:                 valid/loss 2.457
wandb:              valid/loss_v1 0.0
wandb:              valid/loss_v2 0.0
wandb:             valid/nll_loss 1.243
wandb:           valid/nsentences 8.0
wandb:              valid/ntokens 286.856
wandb:                  valid/ppl 2.37
wandb:          valid/sample_size 286.856
wandb:       valid/sample_size_v1 0.0
wandb:       valid/sample_size_v2 0.0
wandb:                  valid/wpb 286.9
wandb:                  valid/wps 199.0
wandb: 
wandb: 🚀 View run tmp at: https://wandb.ai/jackcai1206/OFA-VG/runs/8x2h18ua
wandb: Synced 6 W&B file(s), 0 media file(s), 2 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230507_235602-8x2h18ua/logs

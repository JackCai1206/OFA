/data/hulab/zcai75/anaconda3/envs/vilt/lib/python3.8/site-packages/torch/distributed/launch.py:178: FutureWarning: The module torch.distributed.launch is deprecated
and will be removed in future. Use torchrun.
Note that --use_env is set by default in torchrun.
If your script expects `--local_rank` argument to be set, please
change it to read from `os.environ['LOCAL_RANK']` instead. See 
https://pytorch.org/docs/stable/distributed.html#launch-utility for 
further instructions

  warnings.warn(
WARNING:torch.distributed.run:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
2023-05-06 03:07:19 - utils.py[line:255] - INFO: distributed init (rank 2): env://
2023-05-06 03:07:19 - utils.py[line:261] - INFO: Start init
2023-05-06 03:07:19 - distributed_c10d.py[line:228] - INFO: Added key: store_based_barrier_key:1 to store for rank: 2
2023-05-06 03:07:19 - utils.py[line:255] - INFO: distributed init (rank 1): env://
2023-05-06 03:07:19 - utils.py[line:261] - INFO: Start init
2023-05-06 03:07:19 - distributed_c10d.py[line:228] - INFO: Added key: store_based_barrier_key:1 to store for rank: 1
2023-05-06 03:07:19 - utils.py[line:255] - INFO: distributed init (rank 0): env://
2023-05-06 03:07:19 - utils.py[line:261] - INFO: Start init
2023-05-06 03:07:19 - distributed_c10d.py[line:228] - INFO: Added key: store_based_barrier_key:1 to store for rank: 0
2023-05-06 03:07:19 - distributed_c10d.py[line:262] - INFO: Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 3 nodes.
2023-05-06 03:07:19 - utils.py[line:271] - INFO: initialized host AMD4RTX3090GPU14 as rank 0
single-machine distributed training is initialized.
2023-05-06 03:07:19 - distributed_c10d.py[line:262] - INFO: Rank 2: Completed store-based barrier for key:store_based_barrier_key:1 with 3 nodes.
2023-05-06 03:07:19 - utils.py[line:271] - INFO: initialized host AMD4RTX3090GPU14 as rank 2
single-machine distributed training is initialized.
2023-05-06 03:07:19 - distributed_c10d.py[line:262] - INFO: Rank 1: Completed store-based barrier for key:store_based_barrier_key:1 with 3 nodes.
2023-05-06 03:07:19 - utils.py[line:271] - INFO: initialized host AMD4RTX3090GPU14 as rank 1
single-machine distributed training is initialized.
2023-05-06 03:07:20 - train.py[line:77] - INFO: {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 10, 'log_format': 'simple', 'log_file': None, 'tensorboard_logdir': './tensorboard/_30_3e-5_512', 'wandb_project': 'OFA-VG', 'azureml_logging': False, 'seed': 1, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': 512, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': '../../ofa_module', 'empty_cache_freq': 0, 'all_gather_list_size': 2097152, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 3, 'distributed_num_procs': 3, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': 'env://', 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': True, 'ddp_backend': 'pytorch_ddp', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': True, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_algorithm': 'LocalSGD', 'localsgd_frequency': 3, 'nprocs_per_node': 3, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False}, 'dataset': {'_name': None, 'num_workers': 0, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': None, 'batch_size': 3, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 30, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': 7, 'disable_validation': False, 'max_tokens_valid': None, 'batch_size_valid': 3, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0}, 'optimization': {'_name': None, 'max_epoch': 30, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 1.0, 'sentence_avg': False, 'update_freq': [8], 'lr': [3e-05], 'stop_min_lr': -1.0, 'use_bmuf': False}, 'checkpoint': {'_name': None, 'save_dir': '../../checkpoints/OFA/sgcls_checkpoints/_30_3e-5_512/tmp', 'restore_file': '../../checkpoints/ofa_large.pt', 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 10, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': 1, 'no_save': False, 'no_epoch_checkpoints': False, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': True, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1, 'use_ema_weights_to_init_param': False, 'use_latest_weights_to_init_ema': False}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 3}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': Namespace(_name='ofa_large', activation_fn='gelu', adam_betas='(0.9,0.999)', adam_eps=1e-08, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, add_type_embedding=True, all_gather_list_size=2097152, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, arch='ofa_large', attention_dropout=0.0, attn_scale_factor=2, azureml_logging=False, batch_size=3, batch_size_valid=3, best_checkpoint_metric='loss', bf16=False, bitfit=False, bpe=None, bpe_dir='../../utils/BPE', broadcast_buffers=False, bucket_cap_mb=25, checkpoint_shard_count=1, checkpoint_suffix='', clip_norm=1.0, code_dict_size=8192, code_image_size=128, code_layernorm_embedding=True, combine_valid_subsets=None, constraint_range=None, cpu=False, cpu_offload=False, criterion='adjust_label_smoothed_cross_entropy', cross_self_attention=False, curriculum=0, data='../../dataset/OFA_data/sgcls/vg_train_full.tsv,../../dataset/OFA_data/sgcls/vg_val_full.tsv', data_buffer_size=10, dataset_impl=None, ddp_backend='pytorch_ddp', ddp_comm_hook='none', decoder_attention_heads=16, decoder_drop_path_rate=0.1, decoder_embed_dim=1024, decoder_embed_path=None, decoder_ffn_embed_dim=4096, decoder_input_dim=1024, decoder_layerdrop=0, decoder_layers=12, decoder_layers_to_keep=None, decoder_learned_pos=True, decoder_normalize_before=True, decoder_output_dim=1024, device_id=0, disable_entangle=True, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_num_procs=3, distributed_port=-1, distributed_rank=0, distributed_world_size=3, drop_worst_after=0, drop_worst_ratio=0.0, dropout=0.1, ema_decay=0.9999, ema_fp32=False, ema_seed_model=None, ema_start_update=0, ema_update_freq=1, empty_cache_freq=0, encoder_attention_heads=16, encoder_drop_path_rate=0.1, encoder_embed_dim=1024, encoder_embed_path=None, encoder_ffn_embed_dim=4096, encoder_layerdrop=0, encoder_layers=12, encoder_layers_to_keep=None, encoder_learned_pos=True, encoder_normalize_before=True, end_learning_rate=0.0, entangle_position_embedding=False, eos=2, eval_args='{"beam":5,"max_len_a":0,"max_len_b":200}', eval_print_samples=False, fast_stat_sync=False, find_unused_parameters=True, finetune_from_model=None, fix_batches_to_gpus=False, fixed_validation_seed=7, force_anneal=None, fp16=True, fp16_adam_stats=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=512, fp32_reduce_scatter=False, freeze_decoder_embedding=False, freeze_encoder_embedding=False, gen_subset='test', gradient_as_bucket_view=False, heartbeat_timeout=-1, ignore_eos=False, ignore_prefix_size=0, ignore_unused_valid_subsets=False, image_bucket_size=42, imagenet_default_mean_and_std=False, keep_best_checkpoints=1, keep_interval_updates=-1, keep_interval_updates_pattern=-1, keep_last_epochs=-1, label_smoothing=0.1, layernorm_embedding=True, load_checkpoint_on_all_dp_ranks=False, localsgd_frequency=3, log_file=None, log_format='simple', log_interval=10, lr=[3e-05], lr_scheduler='polynomial_decay', max_epoch=30, max_source_positions=1024, max_src_length=100, max_target_positions=1024, max_tgt_length=100, max_tokens=None, max_tokens_valid=None, max_update=0, max_valid_steps=None, maximize_best_checkpoint_metric=True, memory_efficient_bf16=False, memory_efficient_fp16=False, min_loss_scale=0.0001, min_params_to_wrap=100000000, model_parallel_size=1, no_cross_attention=False, no_epoch_checkpoints=False, no_last_checkpoints=False, no_progress_bar=False, no_reshard_after_forward=False, no_save=False, no_save_optimizer_state=False, no_scale_embedding=True, no_seed_provided=False, no_token_positional_embeddings=False, nprocs_per_node=3, num_bins=480, num_shards=1, num_workers=0, on_cpu_convert_precision=False, optimizer='adam', optimizer_overrides='{}', orig_patch_image_size=256, pad=1, patch_image_size=512, patch_layernorm_embedding=True, patience=-1, pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, plasma_path='/tmp/plasma', pooler_activation_fn='tanh', pooler_classifier='mlp', pooler_dropout=0.0, power=1.0, profile=False, quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, quantization_config_path=None, reg_alpha=1.0, relu_dropout=0.0, report_accuracy=False, required_batch_size_multiple=8, required_seq_len_multiple=1, reset_dataloader=False, reset_logging=False, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, resnet_drop_path_rate=0.0, resnet_type='resnet152', restore_file='../../checkpoints/ofa_large.pt', sample_patch_num=196, save_dir='../../checkpoints/OFA/sgcls_checkpoints/_30_3e-5_512/tmp', save_interval=10, save_interval_updates=0, scale_attn=True, scale_fc=True, scale_heads=True, scale_resids=False, scoring='bleu', seed=1, selected_cols=None, sentence_avg=False, shard_id=0, share_all_embeddings=True, share_decoder_input_output_embed=True, simul_type=None, skip_invalid_size_inputs_valid_test=False, slowmo_algorithm='LocalSGD', slowmo_momentum=None, stop_min_lr=-1.0, stop_time_hours=0, store_ema=False, suppress_crashes=False, sync_bn=False, task='sgcls', tensorboard_logdir='./tensorboard/_30_3e-5_512', threshold_loss_scale=None, token_bucket_size=256, tokenizer=None, total_num_update=1000000, tpu=False, train_subset='train', unk=3, update_freq=[8], use_bmuf=False, use_ema_weights_to_init_param=False, use_latest_weights_to_init_ema=False, use_old_adam=False, use_plasma_view=False, use_rdrop=False, use_sharded_state=False, user_dir='../../ofa_module', valid_subset='valid', validate_after_updates=0, validate_interval=30, validate_interval_updates=0, vg_json_dir=None, wandb_project='OFA-VG', warmup_ratio=0.06, warmup_updates=0, weight_decay=0.01, write_checkpoints_asynchronously=False, zero_sharding='none'), 'task': {'_name': 'sgcls', 'data': '../../dataset/OFA_data/sgcls/vg_train_full.tsv,../../dataset/OFA_data/sgcls/vg_val_full.tsv', 'selected_cols': None, 'bpe': None, 'bpe_dir': '../../utils/BPE', 'max_source_positions': 1024, 'max_target_positions': 1024, 'max_src_length': 100, 'max_tgt_length': 100, 'code_dict_size': 8192, 'patch_image_size': 512, 'orig_patch_image_size': 256, 'num_bins': 480, 'imagenet_default_mean_and_std': False, 'constraint_range': None, 'eval_args': '{"beam":5,"max_len_a":0,"max_len_b":200}', 'eval_print_samples': False, 'vg_json_dir': None}, 'criterion': {'_name': 'adjust_label_smoothed_cross_entropy', 'label_smoothing': 0.1, 'report_accuracy': False, 'ignore_prefix_size': 0, 'ignore_eos': False, 'sentence_avg': False, 'drop_worst_ratio': 0.0, 'drop_worst_after': 0, 'use_rdrop': False, 'reg_alpha': 1.0, 'sample_patch_num': 196, 'constraint_range': None}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9,0.999)', 'adam_eps': 1e-08, 'weight_decay': 0.01, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': False, 'lr': [3e-05]}, 'lr_scheduler': {'_name': 'polynomial_decay', 'warmup_updates': 0, 'warmup_ratio': 0.06, 'force_anneal': None, 'end_learning_rate': 0.0, 'power': 1.0, 'total_num_update': 1000000.0, 'lr': [3e-05]}, 'scoring': {'_name': 'bleu', 'pad': 1, 'eos': 2, 'unk': 3}, 'bpe': None, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}, 'simul_type': None}
2023-05-06 03:07:20 - sg_cls.py[line:82] - INFO: sgcls setup: source dictionary: 50747 types
2023-05-06 03:07:20 - sg_cls.py[line:83] - INFO: sgcls setup: target dictionary: 50747 types
/data/hulab/zcai75/anaconda3/envs/vilt/lib/python3.8/site-packages/torch/functional.py:478: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at  ../aten/src/ATen/native/TensorShape.cpp:2894.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/data/hulab/zcai75/anaconda3/envs/vilt/lib/python3.8/site-packages/torch/functional.py:478: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at  ../aten/src/ATen/native/TensorShape.cpp:2894.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/data/hulab/zcai75/anaconda3/envs/vilt/lib/python3.8/site-packages/torch/functional.py:478: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at  ../aten/src/ATen/native/TensorShape.cpp:2894.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
2023-05-06 03:07:26 - train.py[line:110] - INFO: OFAModel(
  (encoder): TransformerEncoder(
    (encoder_dropout): Dropout(p=0.2, inplace=False)
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(50747, 1024, padding_idx=1)
    (layernorm_embedding): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (type_embedding): Embedding(2, 1024)
    (embed_images): ResNet(
      (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)
      (layer1): Sequential(
        (0): Bottleneck(
          (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (downsample): Sequential(
            (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (drop_path): Identity()
        )
        (1): Bottleneck(
          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (2): Bottleneck(
          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
      )
      (layer2): Sequential(
        (0): Bottleneck(
          (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (downsample): Sequential(
            (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
            (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (drop_path): Identity()
        )
        (1): Bottleneck(
          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (2): Bottleneck(
          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (3): Bottleneck(
          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (4): Bottleneck(
          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (5): Bottleneck(
          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (6): Bottleneck(
          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (7): Bottleneck(
          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
      )
      (layer3): Sequential(
        (0): Bottleneck(
          (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (downsample): Sequential(
            (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)
            (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (drop_path): Identity()
        )
        (1): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (2): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (3): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (4): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (5): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (6): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (7): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (8): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (9): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (10): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (11): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (12): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (13): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (14): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (15): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (16): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (17): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (18): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (19): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (20): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (21): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (22): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (23): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (24): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (25): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (26): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (27): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (28): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (29): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (30): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (31): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (32): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (33): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (34): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (35): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
      )
    )
    (image_proj): Linear(in_features=1024, out_features=1024, bias=True)
    (patch_layernorm_embedding): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (embed_positions): Embedding(1026, 1024)
    (embed_image_positions): Embedding(1765, 1024)
    (pos_ln): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (image_pos_ln): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (pos_q_linear): Linear(in_features=1024, out_features=1024, bias=True)
    (pos_k_linear): Linear(in_features=1024, out_features=1024, bias=True)
    (layers): ModuleList(
      (0): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=1024, out_features=4096, bias=True)
        (fc2): Linear(in_features=4096, out_features=1024, bias=True)
        (attn_ln): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)
        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (drop_path): Identity()
      )
      (1): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=1024, out_features=4096, bias=True)
        (fc2): Linear(in_features=4096, out_features=1024, bias=True)
        (attn_ln): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)
        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(p=0.00909090880304575)
      )
      (2): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=1024, out_features=4096, bias=True)
        (fc2): Linear(in_features=4096, out_features=1024, bias=True)
        (attn_ln): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)
        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(p=0.0181818176060915)
      )
      (3): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=1024, out_features=4096, bias=True)
        (fc2): Linear(in_features=4096, out_features=1024, bias=True)
        (attn_ln): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)
        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(p=0.027272727340459824)
      )
      (4): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=1024, out_features=4096, bias=True)
        (fc2): Linear(in_features=4096, out_features=1024, bias=True)
        (attn_ln): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)
        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(p=0.036363635212183)
      )
      (5): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=1024, out_features=4096, bias=True)
        (fc2): Linear(in_features=4096, out_features=1024, bias=True)
        (attn_ln): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)
        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(p=0.045454543083906174)
      )
      (6): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=1024, out_features=4096, bias=True)
        (fc2): Linear(in_features=4096, out_features=1024, bias=True)
        (attn_ln): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)
        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(p=0.054545458406209946)
      )
      (7): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=1024, out_features=4096, bias=True)
        (fc2): Linear(in_features=4096, out_features=1024, bias=True)
        (attn_ln): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)
        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(p=0.06363636255264282)
      )
      (8): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=1024, out_features=4096, bias=True)
        (fc2): Linear(in_features=4096, out_features=1024, bias=True)
        (attn_ln): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)
        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(p=0.0727272778749466)
      )
      (9): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=1024, out_features=4096, bias=True)
        (fc2): Linear(in_features=4096, out_features=1024, bias=True)
        (attn_ln): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)
        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(p=0.08181818574666977)
      )
      (10): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=1024, out_features=4096, bias=True)
        (fc2): Linear(in_features=4096, out_features=1024, bias=True)
        (attn_ln): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)
        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(p=0.09090909361839294)
      )
      (11): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=1024, out_features=4096, bias=True)
        (fc2): Linear(in_features=4096, out_features=1024, bias=True)
        (attn_ln): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)
        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(p=0.10000000149011612)
      )
    )
    (layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (token_rel_pos_table_list): ModuleList(
      (0): Embedding(511, 16)
      (1): Embedding(511, 16)
      (2): Embedding(511, 16)
      (3): Embedding(511, 16)
      (4): Embedding(511, 16)
      (5): Embedding(511, 16)
      (6): Embedding(511, 16)
      (7): Embedding(511, 16)
      (8): Embedding(511, 16)
      (9): Embedding(511, 16)
      (10): Embedding(511, 16)
      (11): Embedding(511, 16)
    )
    (image_rel_pos_table_list): ModuleList(
      (0): Embedding(6892, 16)
      (1): Embedding(6892, 16)
      (2): Embedding(6892, 16)
      (3): Embedding(6892, 16)
      (4): Embedding(6892, 16)
      (5): Embedding(6892, 16)
      (6): Embedding(6892, 16)
      (7): Embedding(6892, 16)
      (8): Embedding(6892, 16)
      (9): Embedding(6892, 16)
      (10): Embedding(6892, 16)
      (11): Embedding(6892, 16)
    )
  )
  (decoder): TransformerDecoder(
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(50747, 1024, padding_idx=1)
    (layernorm_embedding): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (embed_positions): Embedding(1026, 1024)
    (embed_image_positions): Embedding(1765, 1024)
    (pos_ln): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (image_pos_ln): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (self_pos_q_linear): Linear(in_features=1024, out_features=1024, bias=True)
    (self_pos_k_linear): Linear(in_features=1024, out_features=1024, bias=True)
    (cross_pos_q_linear): Linear(in_features=1024, out_features=1024, bias=True)
    (cross_pos_k_linear): Linear(in_features=1024, out_features=1024, bias=True)
    (code_layernorm_embedding): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (layers): ModuleList(
      (0): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)
        )
        (self_attn_ln): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (cross_attn_ln): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=1024, out_features=4096, bias=True)
        (fc2): Linear(in_features=4096, out_features=1024, bias=True)
        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (drop_path): Identity()
      )
      (1): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)
        )
        (self_attn_ln): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (cross_attn_ln): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=1024, out_features=4096, bias=True)
        (fc2): Linear(in_features=4096, out_features=1024, bias=True)
        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(p=0.00909090880304575)
      )
      (2): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)
        )
        (self_attn_ln): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (cross_attn_ln): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=1024, out_features=4096, bias=True)
        (fc2): Linear(in_features=4096, out_features=1024, bias=True)
        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(p=0.0181818176060915)
      )
      (3): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)
        )
        (self_attn_ln): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (cross_attn_ln): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=1024, out_features=4096, bias=True)
        (fc2): Linear(in_features=4096, out_features=1024, bias=True)
        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(p=0.027272727340459824)
      )
      (4): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)
        )
        (self_attn_ln): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (cross_attn_ln): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=1024, out_features=4096, bias=True)
        (fc2): Linear(in_features=4096, out_features=1024, bias=True)
        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(p=0.036363635212183)
      )
      (5): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)
        )
        (self_attn_ln): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (cross_attn_ln): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=1024, out_features=4096, bias=True)
        (fc2): Linear(in_features=4096, out_features=1024, bias=True)
        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(p=0.045454543083906174)
      )
      (6): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)
        )
        (self_attn_ln): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (cross_attn_ln): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=1024, out_features=4096, bias=True)
        (fc2): Linear(in_features=4096, out_features=1024, bias=True)
        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(p=0.054545458406209946)
      )
      (7): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)
        )
        (self_attn_ln): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (cross_attn_ln): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=1024, out_features=4096, bias=True)
        (fc2): Linear(in_features=4096, out_features=1024, bias=True)
        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(p=0.06363636255264282)
      )
      (8): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)
        )
        (self_attn_ln): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (cross_attn_ln): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=1024, out_features=4096, bias=True)
        (fc2): Linear(in_features=4096, out_features=1024, bias=True)
        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(p=0.0727272778749466)
      )
      (9): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)
        )
        (self_attn_ln): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (cross_attn_ln): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=1024, out_features=4096, bias=True)
        (fc2): Linear(in_features=4096, out_features=1024, bias=True)
        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(p=0.08181818574666977)
      )
      (10): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)
        )
        (self_attn_ln): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (cross_attn_ln): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=1024, out_features=4096, bias=True)
        (fc2): Linear(in_features=4096, out_features=1024, bias=True)
        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(p=0.09090909361839294)
      )
      (11): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)
        )
        (self_attn_ln): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (cross_attn_ln): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=1024, out_features=4096, bias=True)
        (fc2): Linear(in_features=4096, out_features=1024, bias=True)
        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(p=0.10000000149011612)
      )
    )
    (layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (output_projection): Linear(in_features=1024, out_features=50747, bias=False)
    (token_rel_pos_table_list): ModuleList(
      (0): Embedding(511, 16)
      (1): Embedding(511, 16)
      (2): Embedding(511, 16)
      (3): Embedding(511, 16)
      (4): Embedding(511, 16)
      (5): Embedding(511, 16)
      (6): Embedding(511, 16)
      (7): Embedding(511, 16)
      (8): Embedding(511, 16)
      (9): Embedding(511, 16)
      (10): Embedding(511, 16)
      (11): Embedding(511, 16)
    )
    (image_rel_pos_table_list): ModuleList(
      (0): Embedding(6892, 16)
      (1): Embedding(6892, 16)
      (2): Embedding(6892, 16)
      (3): Embedding(6892, 16)
      (4): Embedding(6892, 16)
      (5): Embedding(6892, 16)
      (6): Embedding(6892, 16)
      (7): Embedding(6892, 16)
      (8): Embedding(6892, 16)
      (9): Embedding(6892, 16)
      (10): Embedding(6892, 16)
      (11): Embedding(6892, 16)
    )
  )
  (classification_heads): ModuleDict()
)
2023-05-06 03:07:26 - train.py[line:111] - INFO: task: SGClsTask
2023-05-06 03:07:26 - train.py[line:112] - INFO: model: OFAModel
2023-05-06 03:07:26 - train.py[line:113] - INFO: criterion: AdjustLabelSmoothedCrossEntropyCriterion
2023-05-06 03:07:26 - train.py[line:114] - INFO: num. shared model params: 464,058,112 (num. trained: 464,058,112)
2023-05-06 03:07:26 - train.py[line:121] - INFO: num. expert model params: 0 (num. trained: 0)
local datafile ../../dataset/OFA_data/sgcls/vg_val_full.tsv slice_id 0 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../dataset/OFA_data/sgcls/vg_val_full.tsv slice_id 1 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../dataset/OFA_data/sgcls/vg_val_full.tsv slice_id 2 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../dataset/OFA_data/sgcls/vg_val_full.tsv slice_id 0 finished initializing row_count and line_idx-to-offset mapping
file ../../dataset/OFA_data/sgcls/vg_val_full.tsv slice_id 0 row count 7627 total row count 22880
/data/hulab/zcai75/anaconda3/envs/vilt/lib/python3.8/site-packages/torchvision/transforms/transforms.py:332: UserWarning: Argument 'interpolation' of type int is deprecated since 0.13 and will be removed in 0.15. Please use InterpolationMode enum.
  warnings.warn(
local datafile ../../dataset/OFA_data/sgcls/vg_val_full.tsv slice_id 2 finished initializing row_count and line_idx-to-offset mapping
file ../../dataset/OFA_data/sgcls/vg_val_full.tsv slice_id 2 row count 7626 total row count 22880
/data/hulab/zcai75/anaconda3/envs/vilt/lib/python3.8/site-packages/torchvision/transforms/transforms.py:332: UserWarning: Argument 'interpolation' of type int is deprecated since 0.13 and will be removed in 0.15. Please use InterpolationMode enum.
  warnings.warn(
local datafile ../../dataset/OFA_data/sgcls/vg_val_full.tsv slice_id 1 finished initializing row_count and line_idx-to-offset mapping
file ../../dataset/OFA_data/sgcls/vg_val_full.tsv slice_id 1 row count 7627 total row count 22880
/data/hulab/zcai75/anaconda3/envs/vilt/lib/python3.8/site-packages/torchvision/transforms/transforms.py:332: UserWarning: Argument 'interpolation' of type int is deprecated since 0.13 and will be removed in 0.15. Please use InterpolationMode enum.
  warnings.warn(
2023-05-06 03:07:27 - distributed_c10d.py[line:228] - INFO: Added key: store_based_barrier_key:2 to store for rank: 0
2023-05-06 03:07:27 - distributed_c10d.py[line:262] - INFO: Rank 0: Completed store-based barrier for key:store_based_barrier_key:2 with 3 nodes.
2023-05-06 03:07:27 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_tokens.weight <- decoder.embed_tokens.weight
2023-05-06 03:07:27 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_tokens.weight <- decoder.output_projection.weight
2023-05-06 03:07:27 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer1.0.conv1.bias
2023-05-06 03:07:27 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer1.0.conv2.bias
2023-05-06 03:07:27 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer1.0.conv3.bias
2023-05-06 03:07:27 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer1.0.downsample.0.bias
2023-05-06 03:07:27 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer1.1.conv1.bias
2023-05-06 03:07:27 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer1.1.conv2.bias
2023-05-06 03:07:27 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer1.1.conv3.bias
2023-05-06 03:07:27 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer1.2.conv1.bias
2023-05-06 03:07:27 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer1.2.conv2.bias
2023-05-06 03:07:27 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer1.2.conv3.bias
2023-05-06 03:07:27 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.0.conv1.bias
2023-05-06 03:07:27 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.0.conv2.bias
2023-05-06 03:07:27 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.0.conv3.bias
2023-05-06 03:07:27 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.0.downsample.0.bias
2023-05-06 03:07:27 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.1.conv1.bias
2023-05-06 03:07:27 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.1.conv2.bias
2023-05-06 03:07:27 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.1.conv3.bias
2023-05-06 03:07:27 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.2.conv1.bias
2023-05-06 03:07:27 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.2.conv2.bias
2023-05-06 03:07:27 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.2.conv3.bias
2023-05-06 03:07:27 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.3.conv1.bias
2023-05-06 03:07:27 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.3.conv2.bias
2023-05-06 03:07:27 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.3.conv3.bias
2023-05-06 03:07:27 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.4.conv1.bias
2023-05-06 03:07:27 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.4.conv2.bias
2023-05-06 03:07:27 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.4.conv3.bias
2023-05-06 03:07:27 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.5.conv1.bias
2023-05-06 03:07:27 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.5.conv2.bias
2023-05-06 03:07:27 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.5.conv3.bias
2023-05-06 03:07:27 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.6.conv1.bias
2023-05-06 03:07:27 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.6.conv2.bias
2023-05-06 03:07:27 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.6.conv3.bias
2023-05-06 03:07:27 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.7.conv1.bias
2023-05-06 03:07:27 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.7.conv2.bias
2023-05-06 03:07:27 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.7.conv3.bias
2023-05-06 03:07:27 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.0.conv1.bias
2023-05-06 03:07:27 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.0.conv2.bias
2023-05-06 03:07:27 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.0.conv3.bias
2023-05-06 03:07:27 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.0.downsample.0.bias
2023-05-06 03:07:27 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.1.conv1.bias
2023-05-06 03:07:27 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.1.conv2.bias
2023-05-06 03:07:27 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.1.conv3.bias
2023-05-06 03:07:27 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.2.conv1.bias
2023-05-06 03:07:27 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.2.conv2.bias
2023-05-06 03:07:27 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.2.conv3.bias
2023-05-06 03:07:27 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.3.conv1.bias
2023-05-06 03:07:27 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.3.conv2.bias
2023-05-06 03:07:27 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.3.conv3.bias
2023-05-06 03:07:27 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.4.conv1.bias
2023-05-06 03:07:27 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.4.conv2.bias
2023-05-06 03:07:27 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.4.conv3.bias
2023-05-06 03:07:27 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.5.conv1.bias
2023-05-06 03:07:27 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.5.conv2.bias
2023-05-06 03:07:27 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.5.conv3.bias
2023-05-06 03:07:27 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.6.conv1.bias
2023-05-06 03:07:27 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.6.conv2.bias
2023-05-06 03:07:27 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.6.conv3.bias
2023-05-06 03:07:27 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.7.conv1.bias
2023-05-06 03:07:27 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.7.conv2.bias
2023-05-06 03:07:27 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.7.conv3.bias
2023-05-06 03:07:27 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.8.conv1.bias
2023-05-06 03:07:27 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.8.conv2.bias
2023-05-06 03:07:27 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.8.conv3.bias
2023-05-06 03:07:27 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.9.conv1.bias
2023-05-06 03:07:27 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.9.conv2.bias
2023-05-06 03:07:27 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.9.conv3.bias
2023-05-06 03:07:27 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.10.conv1.bias
2023-05-06 03:07:27 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.10.conv2.bias
2023-05-06 03:07:27 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.10.conv3.bias
2023-05-06 03:07:27 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.11.conv1.bias
2023-05-06 03:07:27 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.11.conv2.bias
2023-05-06 03:07:27 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.11.conv3.bias
2023-05-06 03:07:27 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.12.conv1.bias
2023-05-06 03:07:27 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.12.conv2.bias
2023-05-06 03:07:27 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.12.conv3.bias
2023-05-06 03:07:27 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.13.conv1.bias
2023-05-06 03:07:27 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.13.conv2.bias
2023-05-06 03:07:27 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.13.conv3.bias
2023-05-06 03:07:27 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.14.conv1.bias
2023-05-06 03:07:27 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.14.conv2.bias
2023-05-06 03:07:27 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.14.conv3.bias
2023-05-06 03:07:27 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.15.conv1.bias
2023-05-06 03:07:27 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.15.conv2.bias
2023-05-06 03:07:27 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.15.conv3.bias
2023-05-06 03:07:27 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.16.conv1.bias
2023-05-06 03:07:27 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.16.conv2.bias
2023-05-06 03:07:27 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.16.conv3.bias
2023-05-06 03:07:27 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.17.conv1.bias
2023-05-06 03:07:27 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.17.conv2.bias
2023-05-06 03:07:27 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.17.conv3.bias
2023-05-06 03:07:27 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.18.conv1.bias
2023-05-06 03:07:27 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.18.conv2.bias
2023-05-06 03:07:27 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.18.conv3.bias
2023-05-06 03:07:27 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.19.conv1.bias
2023-05-06 03:07:27 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.19.conv2.bias
2023-05-06 03:07:27 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.19.conv3.bias
2023-05-06 03:07:27 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.20.conv1.bias
2023-05-06 03:07:27 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.20.conv2.bias
2023-05-06 03:07:27 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.20.conv3.bias
2023-05-06 03:07:27 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.21.conv1.bias
2023-05-06 03:07:27 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.21.conv2.bias
2023-05-06 03:07:27 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.21.conv3.bias
2023-05-06 03:07:27 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.22.conv1.bias
2023-05-06 03:07:27 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.22.conv2.bias
2023-05-06 03:07:27 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.22.conv3.bias
2023-05-06 03:07:27 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.23.conv1.bias
2023-05-06 03:07:27 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.23.conv2.bias
2023-05-06 03:07:27 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.23.conv3.bias
2023-05-06 03:07:27 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.24.conv1.bias
2023-05-06 03:07:27 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.24.conv2.bias
2023-05-06 03:07:27 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.24.conv3.bias
2023-05-06 03:07:27 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.25.conv1.bias
2023-05-06 03:07:27 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.25.conv2.bias
2023-05-06 03:07:27 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.25.conv3.bias
2023-05-06 03:07:27 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.26.conv1.bias
2023-05-06 03:07:27 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.26.conv2.bias
2023-05-06 03:07:27 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.26.conv3.bias
2023-05-06 03:07:27 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.27.conv1.bias
2023-05-06 03:07:27 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.27.conv2.bias
2023-05-06 03:07:27 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.27.conv3.bias
2023-05-06 03:07:27 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.28.conv1.bias
2023-05-06 03:07:27 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.28.conv2.bias
2023-05-06 03:07:27 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.28.conv3.bias
2023-05-06 03:07:27 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.29.conv1.bias
2023-05-06 03:07:27 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.29.conv2.bias
2023-05-06 03:07:27 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.29.conv3.bias
2023-05-06 03:07:27 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.30.conv1.bias
2023-05-06 03:07:27 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.30.conv2.bias
2023-05-06 03:07:27 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.30.conv3.bias
2023-05-06 03:07:27 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.31.conv1.bias
2023-05-06 03:07:27 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.31.conv2.bias
2023-05-06 03:07:27 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.31.conv3.bias
2023-05-06 03:07:27 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.32.conv1.bias
2023-05-06 03:07:27 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.32.conv2.bias
2023-05-06 03:07:27 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.32.conv3.bias
2023-05-06 03:07:27 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.33.conv1.bias
2023-05-06 03:07:27 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.33.conv2.bias
2023-05-06 03:07:27 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.33.conv3.bias
2023-05-06 03:07:27 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.34.conv1.bias
2023-05-06 03:07:27 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.34.conv2.bias
2023-05-06 03:07:27 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.34.conv3.bias
2023-05-06 03:07:27 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.35.conv1.bias
2023-05-06 03:07:27 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.35.conv2.bias
2023-05-06 03:07:27 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.35.conv3.bias
2023-05-06 03:07:27 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- decoder.output_projection.bias
2023-05-06 03:07:27 - utils.py[line:759] - INFO: ***********************CUDA enviroments for all 3 workers***********************
2023-05-06 03:07:27 - utils.py[line:761] - INFO: rank   0: capabilities =  8.6  ; total memory = 23.688 GB ; name = NVIDIA GeForce RTX 3090 Ti              
2023-05-06 03:07:27 - utils.py[line:761] - INFO: rank   1: capabilities =  8.6  ; total memory = 23.688 GB ; name = NVIDIA GeForce RTX 3090 Ti              
2023-05-06 03:07:27 - utils.py[line:761] - INFO: rank   2: capabilities =  8.6  ; total memory = 23.688 GB ; name = NVIDIA GeForce RTX 3090 Ti              
2023-05-06 03:07:27 - utils.py[line:767] - INFO: ***********************CUDA enviroments for all 3 workers***********************
2023-05-06 03:07:27 - train.py[line:152] - INFO: training on 3 devices (GPUs/TPUs)
2023-05-06 03:07:27 - train.py[line:157] - INFO: max tokens per device = None and max sentences per device = 3
2023-05-06 03:07:27 - trainer.py[line:458] - INFO: Preparing to load checkpoint ../../checkpoints/ofa_large.pt
2023-05-06 03:07:27 - trainer.py[line:624] - INFO: No existing checkpoint found ../../checkpoints/ofa_large.pt
2023-05-06 03:07:27 - trainer.py[line:639] - INFO: loading train data for epoch 1
local datafile ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 1 begin to initialize row_count and line_idx-to-offset mappinglocal datafile ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 2 begin to initialize row_count and line_idx-to-offset mapping

local datafile ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 0 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 1 finished initializing row_count and line_idx-to-offset mapping
file ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 1 row count 18467 total row count 55400
local datafile ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 0 finished initializing row_count and line_idx-to-offset mapping
file ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 0 row count 18467 total row count 55400
local datafile ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 2 finished initializing row_count and line_idx-to-offset mapping
file ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 2 row count 18466 total row count 55400
slice_id 1 seek offset 18467
slice_id 2 seek offset 36934
slice_id 0 seek offset 0
Total steps 23100, warmup steps 1386, warmup_factor 0.0007215007215007215Total steps 23100, warmup steps 1386, warmup_factor 0.0007215007215007215

Total steps 23100, warmup steps 1386, warmup_factor 0.0007215007215007215
wandb: Currently logged in as: jackcai1206. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.15.2 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /home/zcai75/Github/OFA_forked/run_scripts/sgcls/wandb/run-20230506_030730-nudz2fe1
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run tmp
wandb: ⭐️ View project at https://wandb.ai/jackcai1206/OFA-VG
wandb: 🚀 View run at https://wandb.ai/jackcai1206/OFA-VG/runs/nudz2fe1
2023-05-06 03:07:36 - trainer.py[line:703] - INFO: begin training epoch 1
2023-05-06 03:07:36 - train.py[line:305] - INFO: Start iterating over samples
2023-05-06 03:07:42 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2023-05-06 03:07:47 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2023-05-06 03:07:52 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2023-05-06 03:08:30 - progress_bar.py[line:272] - INFO: epoch 001:     13 / 770 loss=10.827, loss_v1=0, loss_v2=0, nll_loss=10.804, ntokens=2297.4, nsentences=72, sample_size=2297.4, sample_size_v1=0, sample_size_v2=0, ppl=1787.51, wps=608.8, ups=0.27, wpb=2297.4, bsz=72, num_updates=10, lr=2.1645e-07, gnorm=33.164, clip=100, loss_scale=16, train_wall=54, gb_free=5.3, wall=63
2023-05-06 03:09:07 - progress_bar.py[line:272] - INFO: epoch 001:     23 / 770 loss=10.711, loss_v1=0, loss_v2=0, nll_loss=10.675, ntokens=2374.5, nsentences=72, sample_size=2374.5, sample_size_v1=0, sample_size_v2=0, ppl=1634.79, wps=639.9, ups=0.27, wpb=2374.5, bsz=72, num_updates=20, lr=4.329e-07, gnorm=34.68, clip=100, loss_scale=16, train_wall=37, gb_free=5.1, wall=100
2023-05-06 03:09:44 - progress_bar.py[line:272] - INFO: epoch 001:     33 / 770 loss=10.036, loss_v1=0, loss_v2=0, nll_loss=9.925, ntokens=2151.2, nsentences=72, sample_size=2151.2, sample_size_v1=0, sample_size_v2=0, ppl=971.94, wps=583.1, ups=0.27, wpb=2151.2, bsz=72, num_updates=30, lr=6.49351e-07, gnorm=30.958, clip=100, loss_scale=16, train_wall=37, gb_free=5.8, wall=137
2023-05-06 03:10:21 - progress_bar.py[line:272] - INFO: epoch 001:     43 / 770 loss=9.003, loss_v1=0, loss_v2=0, nll_loss=8.776, ntokens=2195.4, nsentences=72, sample_size=2195.4, sample_size_v1=0, sample_size_v2=0, ppl=438.3, wps=590.3, ups=0.27, wpb=2195.4, bsz=72, num_updates=40, lr=8.65801e-07, gnorm=22.355, clip=100, loss_scale=16, train_wall=37, gb_free=5.1, wall=175
2023-05-06 03:10:59 - progress_bar.py[line:272] - INFO: epoch 001:     53 / 770 loss=8.157, loss_v1=0, loss_v2=0, nll_loss=7.831, ntokens=2352.1, nsentences=72, sample_size=2352.1, sample_size_v1=0, sample_size_v2=0, ppl=227.64, wps=626.7, ups=0.27, wpb=2352.1, bsz=72, num_updates=50, lr=1.08225e-06, gnorm=19.118, clip=100, loss_scale=16, train_wall=37, gb_free=5.3, wall=212
2023-05-06 03:11:36 - progress_bar.py[line:272] - INFO: epoch 001:     63 / 770 loss=7.604, loss_v1=0, loss_v2=0, nll_loss=7.208, ntokens=2294.1, nsentences=72, sample_size=2294.1, sample_size_v1=0, sample_size_v2=0, ppl=147.85, wps=617.6, ups=0.27, wpb=2294.1, bsz=72, num_updates=60, lr=1.2987e-06, gnorm=15.178, clip=100, loss_scale=16, train_wall=37, gb_free=4.8, wall=249
2023-05-06 03:12:13 - progress_bar.py[line:272] - INFO: epoch 001:     73 / 770 loss=7.173, loss_v1=0, loss_v2=0, nll_loss=6.718, ntokens=2299.1, nsentences=72, sample_size=2299.1, sample_size_v1=0, sample_size_v2=0, ppl=105.28, wps=620.2, ups=0.27, wpb=2299.1, bsz=72, num_updates=70, lr=1.51515e-06, gnorm=11.868, clip=100, loss_scale=16, train_wall=37, gb_free=5.1, wall=286
2023-05-06 03:12:50 - progress_bar.py[line:272] - INFO: epoch 001:     83 / 770 loss=6.763, loss_v1=0, loss_v2=0, nll_loss=6.258, ntokens=2374.1, nsentences=72, sample_size=2374.1, sample_size_v1=0, sample_size_v2=0, ppl=76.55, wps=635.5, ups=0.27, wpb=2374.1, bsz=72, num_updates=80, lr=1.7316e-06, gnorm=10.663, clip=100, loss_scale=16, train_wall=37, gb_free=4.9, wall=324
2023-05-06 03:13:28 - progress_bar.py[line:272] - INFO: epoch 001:     93 / 770 loss=6.607, loss_v1=0, loss_v2=0, nll_loss=6.083, ntokens=2556, nsentences=71.6, sample_size=2556, sample_size_v1=0, sample_size_v2=0, ppl=67.8, wps=673.9, ups=0.26, wpb=2556, bsz=71.6, num_updates=90, lr=1.94805e-06, gnorm=9.007, clip=100, loss_scale=16, train_wall=38, gb_free=4.8, wall=362
2023-05-06 03:14:06 - progress_bar.py[line:272] - INFO: epoch 001:    103 / 770 loss=6.418, loss_v1=0, loss_v2=0, nll_loss=5.869, ntokens=2358, nsentences=72, sample_size=2358, sample_size_v1=0, sample_size_v2=0, ppl=58.45, wps=626.3, ups=0.27, wpb=2358, bsz=72, num_updates=100, lr=2.1645e-06, gnorm=7.916, clip=100, loss_scale=16, train_wall=38, gb_free=4.2, wall=399
2023-05-06 03:14:43 - progress_bar.py[line:272] - INFO: epoch 001:    113 / 770 loss=6.283, loss_v1=0, loss_v2=0, nll_loss=5.719, ntokens=2360.4, nsentences=72, sample_size=2360.4, sample_size_v1=0, sample_size_v2=0, ppl=52.66, wps=630.4, ups=0.27, wpb=2360.4, bsz=72, num_updates=110, lr=2.38095e-06, gnorm=7.621, clip=100, loss_scale=16, train_wall=37, gb_free=5.2, wall=437
2023-05-06 03:15:21 - progress_bar.py[line:272] - INFO: epoch 001:    123 / 770 loss=5.999, loss_v1=0, loss_v2=0, nll_loss=5.401, ntokens=2344.7, nsentences=72, sample_size=2344.7, sample_size_v1=0, sample_size_v2=0, ppl=42.24, wps=629.1, ups=0.27, wpb=2344.7, bsz=72, num_updates=120, lr=2.5974e-06, gnorm=7.306, clip=100, loss_scale=16, train_wall=37, gb_free=4.9, wall=474
2023-05-06 03:15:58 - progress_bar.py[line:272] - INFO: epoch 001:    133 / 770 loss=5.89, loss_v1=0, loss_v2=0, nll_loss=5.275, ntokens=2279.2, nsentences=72, sample_size=2279.2, sample_size_v1=0, sample_size_v2=0, ppl=38.71, wps=610.8, ups=0.27, wpb=2279.2, bsz=72, num_updates=130, lr=2.81385e-06, gnorm=7.478, clip=100, loss_scale=16, train_wall=37, gb_free=5.7, wall=511
2023-05-06 03:16:35 - progress_bar.py[line:272] - INFO: epoch 001:    143 / 770 loss=5.728, loss_v1=0, loss_v2=0, nll_loss=5.087, ntokens=2258.1, nsentences=72, sample_size=2258.1, sample_size_v1=0, sample_size_v2=0, ppl=34, wps=610.5, ups=0.27, wpb=2258.1, bsz=72, num_updates=140, lr=3.0303e-06, gnorm=7.347, clip=100, loss_scale=16, train_wall=37, gb_free=5, wall=548
2023-05-06 03:17:12 - progress_bar.py[line:272] - INFO: epoch 001:    153 / 770 loss=5.504, loss_v1=0, loss_v2=0, nll_loss=4.828, ntokens=2275.7, nsentences=72, sample_size=2275.7, sample_size_v1=0, sample_size_v2=0, ppl=28.4, wps=610.4, ups=0.27, wpb=2275.7, bsz=72, num_updates=150, lr=3.24675e-06, gnorm=6.913, clip=100, loss_scale=16, train_wall=37, gb_free=5.1, wall=586
2023-05-06 03:17:50 - progress_bar.py[line:272] - INFO: epoch 001:    163 / 770 loss=5.261, loss_v1=0, loss_v2=0, nll_loss=4.548, ntokens=2411.2, nsentences=72, sample_size=2411.2, sample_size_v1=0, sample_size_v2=0, ppl=23.39, wps=643.4, ups=0.27, wpb=2411.2, bsz=72, num_updates=160, lr=3.4632e-06, gnorm=6.823, clip=100, loss_scale=16, train_wall=37, gb_free=4.6, wall=623
2023-05-06 03:18:27 - progress_bar.py[line:272] - INFO: epoch 001:    173 / 770 loss=5.025, loss_v1=0, loss_v2=0, nll_loss=4.273, ntokens=2359.9, nsentences=72, sample_size=2359.9, sample_size_v1=0, sample_size_v2=0, ppl=19.33, wps=629.6, ups=0.27, wpb=2359.9, bsz=72, num_updates=170, lr=3.67965e-06, gnorm=6.174, clip=100, loss_scale=16, train_wall=37, gb_free=3.9, wall=661
2023-05-06 03:19:05 - progress_bar.py[line:272] - INFO: epoch 001:    183 / 770 loss=4.842, loss_v1=0, loss_v2=0, nll_loss=4.061, ntokens=2429.8, nsentences=72, sample_size=2429.8, sample_size_v1=0, sample_size_v2=0, ppl=16.69, wps=647.6, ups=0.27, wpb=2429.8, bsz=72, num_updates=180, lr=3.8961e-06, gnorm=6.283, clip=100, loss_scale=16, train_wall=37, gb_free=5, wall=698
2023-05-06 03:19:42 - progress_bar.py[line:272] - INFO: epoch 001:    193 / 770 loss=4.716, loss_v1=0, loss_v2=0, nll_loss=3.915, ntokens=2378.7, nsentences=72, sample_size=2378.7, sample_size_v1=0, sample_size_v2=0, ppl=15.09, wps=631.8, ups=0.27, wpb=2378.7, bsz=72, num_updates=190, lr=4.11255e-06, gnorm=5.428, clip=100, loss_scale=16, train_wall=38, gb_free=4.6, wall=736
2023-05-06 03:20:20 - progress_bar.py[line:272] - INFO: epoch 001:    203 / 770 loss=4.606, loss_v1=0, loss_v2=0, nll_loss=3.786, ntokens=2393.7, nsentences=72, sample_size=2393.7, sample_size_v1=0, sample_size_v2=0, ppl=13.79, wps=636.8, ups=0.27, wpb=2393.7, bsz=72, num_updates=200, lr=4.329e-06, gnorm=5.289, clip=100, loss_scale=16, train_wall=38, gb_free=4.7, wall=773
2023-05-06 03:20:58 - progress_bar.py[line:272] - INFO: epoch 001:    213 / 770 loss=4.496, loss_v1=0, loss_v2=0, nll_loss=3.66, ntokens=2401.6, nsentences=72, sample_size=2401.6, sample_size_v1=0, sample_size_v2=0, ppl=12.64, wps=640.5, ups=0.27, wpb=2401.6, bsz=72, num_updates=210, lr=4.54545e-06, gnorm=5.066, clip=100, loss_scale=16, train_wall=37, gb_free=5, wall=811
2023-05-06 03:21:35 - progress_bar.py[line:272] - INFO: epoch 001:    223 / 770 loss=4.45, loss_v1=0, loss_v2=0, nll_loss=3.602, ntokens=2337.8, nsentences=72, sample_size=2337.8, sample_size_v1=0, sample_size_v2=0, ppl=12.14, wps=626.8, ups=0.27, wpb=2337.8, bsz=72, num_updates=220, lr=4.7619e-06, gnorm=4.893, clip=100, loss_scale=16, train_wall=37, gb_free=4.3, wall=848
2023-05-06 03:22:12 - progress_bar.py[line:272] - INFO: epoch 001:    233 / 770 loss=4.344, loss_v1=0, loss_v2=0, nll_loss=3.48, ntokens=2235.5, nsentences=72, sample_size=2235.5, sample_size_v1=0, sample_size_v2=0, ppl=11.16, wps=602.4, ups=0.27, wpb=2235.5, bsz=72, num_updates=230, lr=4.97835e-06, gnorm=4.336, clip=100, loss_scale=16, train_wall=37, gb_free=4.7, wall=885
2023-05-06 03:22:50 - progress_bar.py[line:272] - INFO: epoch 001:    243 / 770 loss=4.26, loss_v1=0, loss_v2=0, nll_loss=3.381, ntokens=2480.1, nsentences=72, sample_size=2480.1, sample_size_v1=0, sample_size_v2=0, ppl=10.42, wps=658.8, ups=0.27, wpb=2480.1, bsz=72, num_updates=240, lr=5.19481e-06, gnorm=4.215, clip=100, loss_scale=16, train_wall=38, gb_free=5.1, wall=923
2023-05-06 03:23:27 - progress_bar.py[line:272] - INFO: epoch 001:    253 / 770 loss=4.26, loss_v1=0, loss_v2=0, nll_loss=3.379, ntokens=2413.9, nsentences=72, sample_size=2413.9, sample_size_v1=0, sample_size_v2=0, ppl=10.4, wps=646, ups=0.27, wpb=2413.9, bsz=72, num_updates=250, lr=5.41126e-06, gnorm=4.188, clip=100, loss_scale=16, train_wall=37, gb_free=5.5, wall=960
2023-05-06 03:24:05 - progress_bar.py[line:272] - INFO: epoch 001:    263 / 770 loss=4.188, loss_v1=0, loss_v2=0, nll_loss=3.299, ntokens=2506, nsentences=72, sample_size=2506, sample_size_v1=0, sample_size_v2=0, ppl=9.84, wps=666.6, ups=0.27, wpb=2506, bsz=72, num_updates=260, lr=5.62771e-06, gnorm=4.011, clip=100, loss_scale=16, train_wall=38, gb_free=5.2, wall=998
2023-05-06 03:24:41 - progress_bar.py[line:272] - INFO: epoch 001:    273 / 770 loss=4.195, loss_v1=0, loss_v2=0, nll_loss=3.306, ntokens=2317.1, nsentences=72, sample_size=2317.1, sample_size_v1=0, sample_size_v2=0, ppl=9.89, wps=628.1, ups=0.27, wpb=2317.1, bsz=72, num_updates=270, lr=5.84416e-06, gnorm=3.955, clip=100, loss_scale=16, train_wall=37, gb_free=5.7, wall=1035
2023-05-06 03:25:18 - progress_bar.py[line:272] - INFO: epoch 001:    283 / 770 loss=4.174, loss_v1=0, loss_v2=0, nll_loss=3.284, ntokens=2358.4, nsentences=72, sample_size=2358.4, sample_size_v1=0, sample_size_v2=0, ppl=9.74, wps=636.9, ups=0.27, wpb=2358.4, bsz=72, num_updates=280, lr=6.06061e-06, gnorm=3.847, clip=100, loss_scale=16, train_wall=37, gb_free=5, wall=1072
2023-05-06 03:25:55 - progress_bar.py[line:272] - INFO: epoch 001:    293 / 770 loss=4.105, loss_v1=0, loss_v2=0, nll_loss=3.205, ntokens=2462.9, nsentences=72, sample_size=2462.9, sample_size_v1=0, sample_size_v2=0, ppl=9.22, wps=666.7, ups=0.27, wpb=2462.9, bsz=72, num_updates=290, lr=6.27706e-06, gnorm=3.693, clip=100, loss_scale=16, train_wall=37, gb_free=5.2, wall=1109
2023-05-06 03:26:32 - progress_bar.py[line:272] - INFO: epoch 001:    303 / 770 loss=4.065, loss_v1=0, loss_v2=0, nll_loss=3.16, ntokens=2405.9, nsentences=72, sample_size=2405.9, sample_size_v1=0, sample_size_v2=0, ppl=8.94, wps=650.7, ups=0.27, wpb=2405.9, bsz=72, num_updates=300, lr=6.49351e-06, gnorm=3.887, clip=100, loss_scale=16, train_wall=37, gb_free=4.9, wall=1146
2023-05-06 03:27:09 - progress_bar.py[line:272] - INFO: epoch 001:    313 / 770 loss=3.991, loss_v1=0, loss_v2=0, nll_loss=3.074, ntokens=2313.9, nsentences=72, sample_size=2313.9, sample_size_v1=0, sample_size_v2=0, ppl=8.42, wps=629.4, ups=0.27, wpb=2313.9, bsz=72, num_updates=310, lr=6.70996e-06, gnorm=3.553, clip=100, loss_scale=16, train_wall=37, gb_free=5.3, wall=1182
2023-05-06 03:27:46 - progress_bar.py[line:272] - INFO: epoch 001:    323 / 770 loss=3.903, loss_v1=0, loss_v2=0, nll_loss=2.974, ntokens=2366.9, nsentences=72, sample_size=2366.9, sample_size_v1=0, sample_size_v2=0, ppl=7.85, wps=636.8, ups=0.27, wpb=2366.9, bsz=72, num_updates=320, lr=6.92641e-06, gnorm=3.524, clip=100, loss_scale=16, train_wall=37, gb_free=4.8, wall=1220
2023-05-06 03:28:23 - progress_bar.py[line:272] - INFO: epoch 001:    333 / 770 loss=3.861, loss_v1=0, loss_v2=0, nll_loss=2.927, ntokens=2397.2, nsentences=72, sample_size=2397.2, sample_size_v1=0, sample_size_v2=0, ppl=7.61, wps=649.5, ups=0.27, wpb=2397.2, bsz=72, num_updates=330, lr=7.14286e-06, gnorm=3.636, clip=100, loss_scale=16, train_wall=37, gb_free=4.8, wall=1257
2023-05-06 03:29:00 - progress_bar.py[line:272] - INFO: epoch 001:    343 / 770 loss=3.793, loss_v1=0, loss_v2=0, nll_loss=2.848, ntokens=2466.8, nsentences=72, sample_size=2466.8, sample_size_v1=0, sample_size_v2=0, ppl=7.2, wps=668.2, ups=0.27, wpb=2466.8, bsz=72, num_updates=340, lr=7.35931e-06, gnorm=3.684, clip=100, loss_scale=16, train_wall=37, gb_free=5.4, wall=1293
2023-05-06 03:29:37 - progress_bar.py[line:272] - INFO: epoch 001:    353 / 770 loss=3.737, loss_v1=0, loss_v2=0, nll_loss=2.784, ntokens=2566.3, nsentences=72, sample_size=2566.3, sample_size_v1=0, sample_size_v2=0, ppl=6.89, wps=689.9, ups=0.27, wpb=2566.3, bsz=72, num_updates=350, lr=7.57576e-06, gnorm=3.281, clip=100, loss_scale=16, train_wall=37, gb_free=5.4, wall=1331
2023-05-06 03:30:14 - progress_bar.py[line:272] - INFO: epoch 001:    363 / 770 loss=3.707, loss_v1=0, loss_v2=0, nll_loss=2.75, ntokens=2513.8, nsentences=72, sample_size=2513.8, sample_size_v1=0, sample_size_v2=0, ppl=6.73, wps=679.9, ups=0.27, wpb=2513.8, bsz=72, num_updates=360, lr=7.79221e-06, gnorm=3.302, clip=100, loss_scale=16, train_wall=37, gb_free=4.9, wall=1368
2023-05-06 03:30:52 - progress_bar.py[line:272] - INFO: epoch 001:    373 / 770 loss=3.61, loss_v1=0, loss_v2=0, nll_loss=2.639, ntokens=2473.3, nsentences=72, sample_size=2473.3, sample_size_v1=0, sample_size_v2=0, ppl=6.23, wps=665.3, ups=0.27, wpb=2473.3, bsz=72, num_updates=370, lr=8.00866e-06, gnorm=3.09, clip=100, loss_scale=16, train_wall=37, gb_free=5, wall=1405
2023-05-06 03:31:29 - progress_bar.py[line:272] - INFO: epoch 001:    383 / 770 loss=3.563, loss_v1=0, loss_v2=0, nll_loss=2.583, ntokens=2445.3, nsentences=72, sample_size=2445.3, sample_size_v1=0, sample_size_v2=0, ppl=5.99, wps=661.5, ups=0.27, wpb=2445.3, bsz=72, num_updates=380, lr=8.22511e-06, gnorm=3.013, clip=100, loss_scale=16, train_wall=37, gb_free=5.3, wall=1442
2023-05-06 03:32:05 - progress_bar.py[line:272] - INFO: epoch 001:    393 / 770 loss=3.513, loss_v1=0, loss_v2=0, nll_loss=2.525, ntokens=2380.6, nsentences=72, sample_size=2380.6, sample_size_v1=0, sample_size_v2=0, ppl=5.76, wps=643.9, ups=0.27, wpb=2380.6, bsz=72, num_updates=390, lr=8.44156e-06, gnorm=3.042, clip=100, loss_scale=16, train_wall=37, gb_free=5.5, wall=1479
2023-05-06 03:32:43 - progress_bar.py[line:272] - INFO: epoch 001:    403 / 770 loss=3.464, loss_v1=0, loss_v2=0, nll_loss=2.469, ntokens=2415.4, nsentences=72, sample_size=2415.4, sample_size_v1=0, sample_size_v2=0, ppl=5.54, wps=650.7, ups=0.27, wpb=2415.4, bsz=72, num_updates=400, lr=8.65801e-06, gnorm=3.058, clip=100, loss_scale=16, train_wall=37, gb_free=5.7, wall=1516
2023-05-06 03:33:20 - progress_bar.py[line:272] - INFO: epoch 001:    413 / 770 loss=3.352, loss_v1=0, loss_v2=0, nll_loss=2.34, ntokens=2448.9, nsentences=72, sample_size=2448.9, sample_size_v1=0, sample_size_v2=0, ppl=5.06, wps=660.6, ups=0.27, wpb=2448.9, bsz=72, num_updates=410, lr=8.87446e-06, gnorm=2.937, clip=100, loss_scale=16, train_wall=37, gb_free=4.8, wall=1553
2023-05-06 03:33:57 - progress_bar.py[line:272] - INFO: epoch 001:    423 / 770 loss=3.352, loss_v1=0, loss_v2=0, nll_loss=2.338, ntokens=2393.5, nsentences=72, sample_size=2393.5, sample_size_v1=0, sample_size_v2=0, ppl=5.06, wps=648.5, ups=0.27, wpb=2393.5, bsz=72, num_updates=420, lr=9.09091e-06, gnorm=2.92, clip=100, loss_scale=16, train_wall=37, gb_free=5, wall=1590
2023-05-06 03:34:33 - progress_bar.py[line:272] - INFO: epoch 001:    433 / 770 loss=3.293, loss_v1=0, loss_v2=0, nll_loss=2.27, ntokens=2287.8, nsentences=72, sample_size=2287.8, sample_size_v1=0, sample_size_v2=0, ppl=4.82, wps=622.6, ups=0.27, wpb=2287.8, bsz=72, num_updates=430, lr=9.30736e-06, gnorm=2.838, clip=100, loss_scale=16, train_wall=37, gb_free=5.8, wall=1627
2023-05-06 03:35:10 - progress_bar.py[line:272] - INFO: epoch 001:    443 / 770 loss=3.263, loss_v1=0, loss_v2=0, nll_loss=2.236, ntokens=2390.2, nsentences=72, sample_size=2390.2, sample_size_v1=0, sample_size_v2=0, ppl=4.71, wps=645.6, ups=0.27, wpb=2390.2, bsz=72, num_updates=440, lr=9.52381e-06, gnorm=2.683, clip=100, loss_scale=16, train_wall=37, gb_free=5.5, wall=1664
2023-05-06 03:35:48 - progress_bar.py[line:272] - INFO: epoch 001:    453 / 770 loss=3.22, loss_v1=0, loss_v2=0, nll_loss=2.184, ntokens=2221.8, nsentences=72, sample_size=2221.8, sample_size_v1=0, sample_size_v2=0, ppl=4.54, wps=597, ups=0.27, wpb=2221.8, bsz=72, num_updates=450, lr=9.74026e-06, gnorm=2.863, clip=100, loss_scale=16, train_wall=37, gb_free=5, wall=1701
2023-05-06 03:36:24 - progress_bar.py[line:272] - INFO: epoch 001:    463 / 770 loss=3.149, loss_v1=0, loss_v2=0, nll_loss=2.103, ntokens=2325.8, nsentences=72, sample_size=2325.8, sample_size_v1=0, sample_size_v2=0, ppl=4.3, wps=630.4, ups=0.27, wpb=2325.8, bsz=72, num_updates=460, lr=9.95671e-06, gnorm=2.628, clip=100, loss_scale=16, train_wall=37, gb_free=5.8, wall=1738
2023-05-06 03:37:01 - progress_bar.py[line:272] - INFO: epoch 001:    473 / 770 loss=3.157, loss_v1=0, loss_v2=0, nll_loss=2.11, ntokens=2295.4, nsentences=72, sample_size=2295.4, sample_size_v1=0, sample_size_v2=0, ppl=4.32, wps=624.7, ups=0.27, wpb=2295.4, bsz=72, num_updates=470, lr=1.01732e-05, gnorm=2.729, clip=100, loss_scale=16, train_wall=37, gb_free=5.6, wall=1775
2023-05-06 03:37:38 - progress_bar.py[line:272] - INFO: epoch 001:    483 / 770 loss=3.12, loss_v1=0, loss_v2=0, nll_loss=2.069, ntokens=2289.2, nsentences=72, sample_size=2289.2, sample_size_v1=0, sample_size_v2=0, ppl=4.2, wps=622, ups=0.27, wpb=2289.2, bsz=72, num_updates=480, lr=1.03896e-05, gnorm=2.583, clip=100, loss_scale=16, train_wall=37, gb_free=5.5, wall=1811
2023-05-06 03:38:15 - progress_bar.py[line:272] - INFO: epoch 001:    493 / 770 loss=3.087, loss_v1=0, loss_v2=0, nll_loss=2.026, ntokens=2272.3, nsentences=72, sample_size=2272.3, sample_size_v1=0, sample_size_v2=0, ppl=4.07, wps=617.6, ups=0.27, wpb=2272.3, bsz=72, num_updates=490, lr=1.06061e-05, gnorm=2.459, clip=100, loss_scale=16, train_wall=37, gb_free=5.9, wall=1848
2023-05-06 03:38:52 - progress_bar.py[line:272] - INFO: epoch 001:    503 / 770 loss=3.057, loss_v1=0, loss_v2=0, nll_loss=1.992, ntokens=2392.2, nsentences=72, sample_size=2392.2, sample_size_v1=0, sample_size_v2=0, ppl=3.98, wps=644.4, ups=0.27, wpb=2392.2, bsz=72, num_updates=500, lr=1.08225e-05, gnorm=2.313, clip=100, loss_scale=16, train_wall=37, gb_free=5.1, wall=1885
2023-05-06 03:39:29 - progress_bar.py[line:272] - INFO: epoch 001:    513 / 770 loss=3.016, loss_v1=0, loss_v2=0, nll_loss=1.942, ntokens=2414.5, nsentences=72, sample_size=2414.5, sample_size_v1=0, sample_size_v2=0, ppl=3.84, wps=649.9, ups=0.27, wpb=2414.5, bsz=72, num_updates=510, lr=1.1039e-05, gnorm=2.304, clip=100, loss_scale=16, train_wall=37, gb_free=5.5, wall=1922
2023-05-06 03:40:06 - progress_bar.py[line:272] - INFO: epoch 001:    523 / 770 loss=2.972, loss_v1=0, loss_v2=0, nll_loss=1.891, ntokens=2313.5, nsentences=72, sample_size=2313.5, sample_size_v1=0, sample_size_v2=0, ppl=3.71, wps=628.1, ups=0.27, wpb=2313.5, bsz=72, num_updates=520, lr=1.12554e-05, gnorm=2.496, clip=100, loss_scale=32, train_wall=37, gb_free=5.7, wall=1959
2023-05-06 03:40:43 - progress_bar.py[line:272] - INFO: epoch 001:    533 / 770 loss=2.939, loss_v1=0, loss_v2=0, nll_loss=1.853, ntokens=2300.1, nsentences=72, sample_size=2300.1, sample_size_v1=0, sample_size_v2=0, ppl=3.61, wps=623.4, ups=0.27, wpb=2300.1, bsz=72, num_updates=530, lr=1.14719e-05, gnorm=2.36, clip=100, loss_scale=32, train_wall=37, gb_free=5.7, wall=1996
2023-05-06 03:41:20 - progress_bar.py[line:272] - INFO: epoch 001:    543 / 770 loss=2.935, loss_v1=0, loss_v2=0, nll_loss=1.845, ntokens=2450.6, nsentences=72, sample_size=2450.6, sample_size_v1=0, sample_size_v2=0, ppl=3.59, wps=662, ups=0.27, wpb=2450.6, bsz=72, num_updates=540, lr=1.16883e-05, gnorm=2.224, clip=100, loss_scale=32, train_wall=37, gb_free=5.1, wall=2033
2023-05-06 03:41:57 - progress_bar.py[line:272] - INFO: epoch 001:    553 / 770 loss=2.895, loss_v1=0, loss_v2=0, nll_loss=1.797, ntokens=2322, nsentences=72, sample_size=2322, sample_size_v1=0, sample_size_v2=0, ppl=3.48, wps=627.4, ups=0.27, wpb=2322, bsz=72, num_updates=550, lr=1.19048e-05, gnorm=2.291, clip=100, loss_scale=32, train_wall=37, gb_free=5.6, wall=2070
2023-05-06 03:42:34 - progress_bar.py[line:272] - INFO: epoch 001:    563 / 770 loss=2.91, loss_v1=0, loss_v2=0, nll_loss=1.813, ntokens=2277.5, nsentences=72, sample_size=2277.5, sample_size_v1=0, sample_size_v2=0, ppl=3.51, wps=620.1, ups=0.27, wpb=2277.5, bsz=72, num_updates=560, lr=1.21212e-05, gnorm=2.387, clip=100, loss_scale=32, train_wall=37, gb_free=5.9, wall=2107
2023-05-06 03:43:11 - progress_bar.py[line:272] - INFO: epoch 001:    573 / 770 loss=2.849, loss_v1=0, loss_v2=0, nll_loss=1.742, ntokens=2336.2, nsentences=72, sample_size=2336.2, sample_size_v1=0, sample_size_v2=0, ppl=3.35, wps=633.1, ups=0.27, wpb=2336.2, bsz=72, num_updates=570, lr=1.23377e-05, gnorm=2.103, clip=100, loss_scale=32, train_wall=37, gb_free=5.4, wall=2144
2023-05-06 03:43:47 - progress_bar.py[line:272] - INFO: epoch 001:    583 / 770 loss=2.867, loss_v1=0, loss_v2=0, nll_loss=1.761, ntokens=2332, nsentences=72, sample_size=2332, sample_size_v1=0, sample_size_v2=0, ppl=3.39, wps=633.8, ups=0.27, wpb=2332, bsz=72, num_updates=580, lr=1.25541e-05, gnorm=2.16, clip=100, loss_scale=32, train_wall=37, gb_free=5.6, wall=2181
2023-05-06 03:44:24 - progress_bar.py[line:272] - INFO: epoch 001:    593 / 770 loss=2.838, loss_v1=0, loss_v2=0, nll_loss=1.729, ntokens=2264.4, nsentences=72, sample_size=2264.4, sample_size_v1=0, sample_size_v2=0, ppl=3.31, wps=614.3, ups=0.27, wpb=2264.4, bsz=72, num_updates=590, lr=1.27706e-05, gnorm=2.29, clip=100, loss_scale=32, train_wall=37, gb_free=5.7, wall=2217
2023-05-06 03:45:01 - progress_bar.py[line:272] - INFO: epoch 001:    603 / 770 loss=2.808, loss_v1=0, loss_v2=0, nll_loss=1.689, ntokens=2388.1, nsentences=72, sample_size=2388.1, sample_size_v1=0, sample_size_v2=0, ppl=3.23, wps=643.9, ups=0.27, wpb=2388.1, bsz=72, num_updates=600, lr=1.2987e-05, gnorm=2.037, clip=100, loss_scale=32, train_wall=37, gb_free=5.9, wall=2255
2023-05-06 03:45:38 - progress_bar.py[line:272] - INFO: epoch 001:    613 / 770 loss=2.791, loss_v1=0, loss_v2=0, nll_loss=1.669, ntokens=2509.2, nsentences=72, sample_size=2509.2, sample_size_v1=0, sample_size_v2=0, ppl=3.18, wps=679, ups=0.27, wpb=2509.2, bsz=72, num_updates=610, lr=1.32035e-05, gnorm=2.054, clip=100, loss_scale=32, train_wall=37, gb_free=5.3, wall=2292
2023-05-06 03:46:15 - progress_bar.py[line:272] - INFO: epoch 001:    623 / 770 loss=2.783, loss_v1=0, loss_v2=0, nll_loss=1.66, ntokens=2381, nsentences=72, sample_size=2381, sample_size_v1=0, sample_size_v2=0, ppl=3.16, wps=645.6, ups=0.27, wpb=2381, bsz=72, num_updates=620, lr=1.34199e-05, gnorm=2.17, clip=100, loss_scale=32, train_wall=37, gb_free=5.1, wall=2328
2023-05-06 03:46:52 - progress_bar.py[line:272] - INFO: epoch 001:    633 / 770 loss=2.77, loss_v1=0, loss_v2=0, nll_loss=1.643, ntokens=2467.7, nsentences=72, sample_size=2467.7, sample_size_v1=0, sample_size_v2=0, ppl=3.12, wps=668.4, ups=0.27, wpb=2467.7, bsz=72, num_updates=630, lr=1.36364e-05, gnorm=1.949, clip=100, loss_scale=32, train_wall=37, gb_free=5.3, wall=2365
2023-05-06 03:47:29 - progress_bar.py[line:272] - INFO: epoch 001:    643 / 770 loss=2.745, loss_v1=0, loss_v2=0, nll_loss=1.615, ntokens=2339.6, nsentences=72, sample_size=2339.6, sample_size_v1=0, sample_size_v2=0, ppl=3.06, wps=636.5, ups=0.27, wpb=2339.6, bsz=72, num_updates=640, lr=1.38528e-05, gnorm=2.075, clip=100, loss_scale=32, train_wall=37, gb_free=5.5, wall=2402
2023-05-06 03:48:06 - progress_bar.py[line:272] - INFO: epoch 001:    653 / 770 loss=2.706, loss_v1=0, loss_v2=0, nll_loss=1.568, ntokens=2447.5, nsentences=72, sample_size=2447.5, sample_size_v1=0, sample_size_v2=0, ppl=2.97, wps=661.9, ups=0.27, wpb=2447.5, bsz=72, num_updates=650, lr=1.40693e-05, gnorm=1.95, clip=100, loss_scale=32, train_wall=37, gb_free=5.6, wall=2439
2023-05-06 03:48:43 - progress_bar.py[line:272] - INFO: epoch 001:    663 / 770 loss=2.756, loss_v1=0, loss_v2=0, nll_loss=1.623, ntokens=2199.2, nsentences=72, sample_size=2199.2, sample_size_v1=0, sample_size_v2=0, ppl=3.08, wps=596.4, ups=0.27, wpb=2199.2, bsz=72, num_updates=660, lr=1.42857e-05, gnorm=2.303, clip=100, loss_scale=32, train_wall=37, gb_free=6, wall=2476
2023-05-06 03:49:20 - progress_bar.py[line:272] - INFO: epoch 001:    673 / 770 loss=2.74, loss_v1=0, loss_v2=0, nll_loss=1.604, ntokens=2282.3, nsentences=72, sample_size=2282.3, sample_size_v1=0, sample_size_v2=0, ppl=3.04, wps=615.2, ups=0.27, wpb=2282.3, bsz=72, num_updates=670, lr=1.45022e-05, gnorm=2.045, clip=100, loss_scale=32, train_wall=37, gb_free=5.8, wall=2513
2023-05-06 03:49:57 - progress_bar.py[line:272] - INFO: epoch 001:    683 / 770 loss=2.731, loss_v1=0, loss_v2=0, nll_loss=1.594, ntokens=2373, nsentences=72, sample_size=2373, sample_size_v1=0, sample_size_v2=0, ppl=3.02, wps=637.5, ups=0.27, wpb=2373, bsz=72, num_updates=680, lr=1.47186e-05, gnorm=1.882, clip=100, loss_scale=32, train_wall=37, gb_free=4.8, wall=2550
2023-05-06 03:50:34 - progress_bar.py[line:272] - INFO: epoch 001:    693 / 770 loss=2.703, loss_v1=0, loss_v2=0, nll_loss=1.559, ntokens=2333, nsentences=72, sample_size=2333, sample_size_v1=0, sample_size_v2=0, ppl=2.95, wps=631.5, ups=0.27, wpb=2333, bsz=72, num_updates=690, lr=1.49351e-05, gnorm=1.934, clip=100, loss_scale=32, train_wall=37, gb_free=6, wall=2587
2023-05-06 03:51:11 - progress_bar.py[line:272] - INFO: epoch 001:    703 / 770 loss=2.711, loss_v1=0, loss_v2=0, nll_loss=1.569, ntokens=2398.4, nsentences=72, sample_size=2398.4, sample_size_v1=0, sample_size_v2=0, ppl=2.97, wps=644.4, ups=0.27, wpb=2398.4, bsz=72, num_updates=700, lr=1.51515e-05, gnorm=1.994, clip=100, loss_scale=32, train_wall=37, gb_free=5.7, wall=2624
2023-05-06 03:51:48 - progress_bar.py[line:272] - INFO: epoch 001:    713 / 770 loss=2.683, loss_v1=0, loss_v2=0, nll_loss=1.535, ntokens=2380.4, nsentences=72, sample_size=2380.4, sample_size_v1=0, sample_size_v2=0, ppl=2.9, wps=642.8, ups=0.27, wpb=2380.4, bsz=72, num_updates=710, lr=1.5368e-05, gnorm=1.764, clip=100, loss_scale=32, train_wall=37, gb_free=5.2, wall=2661
2023-05-06 03:52:25 - progress_bar.py[line:272] - INFO: epoch 001:    723 / 770 loss=2.697, loss_v1=0, loss_v2=0, nll_loss=1.55, ntokens=2421.7, nsentences=72, sample_size=2421.7, sample_size_v1=0, sample_size_v2=0, ppl=2.93, wps=652.6, ups=0.27, wpb=2421.7, bsz=72, num_updates=720, lr=1.55844e-05, gnorm=1.878, clip=100, loss_scale=32, train_wall=37, gb_free=5.1, wall=2699
2023-05-06 03:53:02 - progress_bar.py[line:272] - INFO: epoch 001:    733 / 770 loss=2.695, loss_v1=0, loss_v2=0, nll_loss=1.549, ntokens=2457.5, nsentences=72, sample_size=2457.5, sample_size_v1=0, sample_size_v2=0, ppl=2.93, wps=665.2, ups=0.27, wpb=2457.5, bsz=72, num_updates=730, lr=1.58009e-05, gnorm=1.91, clip=100, loss_scale=32, train_wall=37, gb_free=5.9, wall=2736
2023-05-06 03:53:39 - progress_bar.py[line:272] - INFO: epoch 001:    743 / 770 loss=2.692, loss_v1=0, loss_v2=0, nll_loss=1.544, ntokens=2362.1, nsentences=72, sample_size=2362.1, sample_size_v1=0, sample_size_v2=0, ppl=2.92, wps=639.7, ups=0.27, wpb=2362.1, bsz=72, num_updates=740, lr=1.60173e-05, gnorm=1.909, clip=100, loss_scale=32, train_wall=37, gb_free=5.7, wall=2772
2023-05-06 03:54:16 - progress_bar.py[line:272] - INFO: epoch 001:    753 / 770 loss=2.684, loss_v1=0, loss_v2=0, nll_loss=1.532, ntokens=2445.2, nsentences=72, sample_size=2445.2, sample_size_v1=0, sample_size_v2=0, ppl=2.89, wps=658.4, ups=0.27, wpb=2445.2, bsz=72, num_updates=750, lr=1.62338e-05, gnorm=1.892, clip=100, loss_scale=32, train_wall=37, gb_free=5.3, wall=2810
2023-05-06 03:54:53 - progress_bar.py[line:272] - INFO: epoch 001:    763 / 770 loss=2.679, loss_v1=0, loss_v2=0, nll_loss=1.527, ntokens=2347.8, nsentences=72, sample_size=2347.8, sample_size_v1=0, sample_size_v2=0, ppl=2.88, wps=636.7, ups=0.27, wpb=2347.8, bsz=72, num_updates=760, lr=1.64502e-05, gnorm=1.793, clip=100, loss_scale=32, train_wall=37, gb_free=5.1, wall=2846
2023-05-06 03:55:17 - train.py[line:332] - INFO: end of epoch 1 (average epoch stats below)
local datafile ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 2 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 1 begin to initialize row_count and line_idx-to-offset mapping
2023-05-06 03:55:17 - progress_bar.py[line:282] - INFO: epoch 001 | loss 4.2 | loss_v1 0 | loss_v2 0 | nll_loss 3.3 | ntokens 2365.25 | nsentences 71.948 | sample_size 2365.25 | sample_size_v1 0 | sample_size_v2 0 | ppl 9.85 | wps 637.7 | ups 0.27 | wpb 2365.3 | bsz 71.9 | num_updates 767 | lr 1.66017e-05 | gnorm 5.466 | clip 100 | loss_scale 32 | train_wall 2858 | gb_free 6.1 | wall 2871
2023-05-06 03:55:17 - trainer.py[line:639] - INFO: loading train data for epoch 2
local datafile ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 0 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 0 finished initializing row_count and line_idx-to-offset mapping
file ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 0 row count 18467 total row count 55400
/data/hulab/zcai75/anaconda3/envs/vilt/lib/python3.8/site-packages/torchvision/transforms/transforms.py:332: UserWarning: Argument 'interpolation' of type int is deprecated since 0.13 and will be removed in 0.15. Please use InterpolationMode enum.
  warnings.warn(
slice_id 0 seek offset 0
2023-05-06 03:55:19 - trainer.py[line:703] - INFO: begin training epoch 2
2023-05-06 03:55:19 - train.py[line:305] - INFO: Start iterating over samples
local datafile ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 1 finished initializing row_count and line_idx-to-offset mapping
file ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 1 row count 18467 total row count 55400
local datafile ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 2 finished initializing row_count and line_idx-to-offset mapping
file ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 2 row count 18466 total row count 55400
slice_id 1 seek offset 18467
slice_id 2 seek offset 36934
2023-05-06 03:55:31 - progress_bar.py[line:272] - INFO: epoch 002:      3 / 770 loss=2.661, loss_v1=0, loss_v2=0, nll_loss=1.508, ntokens=2276.5, nsentences=68.4, sample_size=2276.5, sample_size_v1=0, sample_size_v2=0, ppl=2.84, wps=602.7, ups=0.26, wpb=2276.5, bsz=68.4, num_updates=770, lr=1.66667e-05, gnorm=1.885, clip=100, loss_scale=32, train_wall=36, gb_free=4.9, wall=2884
2023-05-06 03:56:08 - progress_bar.py[line:272] - INFO: epoch 002:     13 / 770 loss=2.626, loss_v1=0, loss_v2=0, nll_loss=1.466, ntokens=2297.4, nsentences=72, sample_size=2297.4, sample_size_v1=0, sample_size_v2=0, ppl=2.76, wps=618.5, ups=0.27, wpb=2297.4, bsz=72, num_updates=780, lr=1.68831e-05, gnorm=1.98, clip=100, loss_scale=32, train_wall=37, gb_free=5.3, wall=2921
2023-05-06 03:56:45 - progress_bar.py[line:272] - INFO: epoch 002:     23 / 770 loss=2.605, loss_v1=0, loss_v2=0, nll_loss=1.44, ntokens=2363.9, nsentences=71.6, sample_size=2363.9, sample_size_v1=0, sample_size_v2=0, ppl=2.71, wps=638.5, ups=0.27, wpb=2363.9, bsz=71.6, num_updates=790, lr=1.70996e-05, gnorm=2.036, clip=100, loss_scale=32, train_wall=37, gb_free=5.1, wall=2958
2023-05-06 03:57:22 - progress_bar.py[line:272] - INFO: epoch 002:     33 / 770 loss=2.624, loss_v1=0, loss_v2=0, nll_loss=1.464, ntokens=2155.4, nsentences=72, sample_size=2155.4, sample_size_v1=0, sample_size_v2=0, ppl=2.76, wps=584.8, ups=0.27, wpb=2155.4, bsz=72, num_updates=800, lr=1.7316e-05, gnorm=1.911, clip=100, loss_scale=32, train_wall=37, gb_free=5.7, wall=2995
2023-05-06 03:57:59 - progress_bar.py[line:272] - INFO: epoch 002:     43 / 770 loss=2.605, loss_v1=0, loss_v2=0, nll_loss=1.44, ntokens=2187.7, nsentences=72, sample_size=2187.7, sample_size_v1=0, sample_size_v2=0, ppl=2.71, wps=590.2, ups=0.27, wpb=2187.7, bsz=72, num_updates=810, lr=1.75325e-05, gnorm=1.787, clip=100, loss_scale=32, train_wall=37, gb_free=5.4, wall=3032
2023-05-06 03:58:37 - progress_bar.py[line:272] - INFO: epoch 002:     53 / 770 loss=2.543, loss_v1=0, loss_v2=0, nll_loss=1.368, ntokens=2354.6, nsentences=72, sample_size=2354.6, sample_size_v1=0, sample_size_v2=0, ppl=2.58, wps=627.5, ups=0.27, wpb=2354.6, bsz=72, num_updates=820, lr=1.77489e-05, gnorm=1.754, clip=100, loss_scale=32, train_wall=37, gb_free=5.3, wall=3070
2023-05-06 03:59:14 - progress_bar.py[line:272] - INFO: epoch 002:     63 / 770 loss=2.599, loss_v1=0, loss_v2=0, nll_loss=1.438, ntokens=2293, nsentences=72, sample_size=2293, sample_size_v1=0, sample_size_v2=0, ppl=2.71, wps=617.5, ups=0.27, wpb=2293, bsz=72, num_updates=830, lr=1.79654e-05, gnorm=1.859, clip=100, loss_scale=32, train_wall=37, gb_free=4.7, wall=3107
2023-05-06 03:59:51 - progress_bar.py[line:272] - INFO: epoch 002:     73 / 770 loss=2.534, loss_v1=0, loss_v2=0, nll_loss=1.358, ntokens=2295.1, nsentences=72, sample_size=2295.1, sample_size_v1=0, sample_size_v2=0, ppl=2.56, wps=617.8, ups=0.27, wpb=2295.1, bsz=72, num_updates=840, lr=1.81818e-05, gnorm=1.889, clip=100, loss_scale=32, train_wall=37, gb_free=5.1, wall=3144
2023-05-06 04:00:28 - progress_bar.py[line:272] - INFO: epoch 002:     83 / 770 loss=2.472, loss_v1=0, loss_v2=0, nll_loss=1.283, ntokens=2381, nsentences=72, sample_size=2381, sample_size_v1=0, sample_size_v2=0, ppl=2.43, wps=636, ups=0.27, wpb=2381, bsz=72, num_updates=850, lr=1.83983e-05, gnorm=1.674, clip=100, loss_scale=32, train_wall=37, gb_free=4.9, wall=3182
2023-05-06 04:01:06 - progress_bar.py[line:272] - INFO: epoch 002:     93 / 770 loss=2.535, loss_v1=0, loss_v2=0, nll_loss=1.358, ntokens=2565.8, nsentences=72, sample_size=2565.8, sample_size_v1=0, sample_size_v2=0, ppl=2.56, wps=674, ups=0.26, wpb=2565.8, bsz=72, num_updates=860, lr=1.86147e-05, gnorm=1.808, clip=100, loss_scale=32, train_wall=38, gb_free=4.8, wall=3220
2023-05-06 04:01:44 - progress_bar.py[line:272] - INFO: epoch 002:    103 / 770 loss=2.524, loss_v1=0, loss_v2=0, nll_loss=1.347, ntokens=2358, nsentences=72, sample_size=2358, sample_size_v1=0, sample_size_v2=0, ppl=2.54, wps=625.8, ups=0.27, wpb=2358, bsz=72, num_updates=870, lr=1.88312e-05, gnorm=1.809, clip=100, loss_scale=32, train_wall=38, gb_free=4.2, wall=3257
2023-05-06 04:02:22 - progress_bar.py[line:272] - INFO: epoch 002:    113 / 770 loss=2.567, loss_v1=0, loss_v2=0, nll_loss=1.397, ntokens=2360.4, nsentences=72, sample_size=2360.4, sample_size_v1=0, sample_size_v2=0, ppl=2.63, wps=629.8, ups=0.27, wpb=2360.4, bsz=72, num_updates=880, lr=1.90476e-05, gnorm=1.789, clip=100, loss_scale=32, train_wall=37, gb_free=5.2, wall=3295
2023-05-06 04:02:59 - progress_bar.py[line:272] - INFO: epoch 002:    123 / 770 loss=2.525, loss_v1=0, loss_v2=0, nll_loss=1.348, ntokens=2344.7, nsentences=72, sample_size=2344.7, sample_size_v1=0, sample_size_v2=0, ppl=2.55, wps=629.1, ups=0.27, wpb=2344.7, bsz=72, num_updates=890, lr=1.92641e-05, gnorm=1.767, clip=100, loss_scale=32, train_wall=37, gb_free=4.9, wall=3332
2023-05-06 04:03:36 - progress_bar.py[line:272] - INFO: epoch 002:    133 / 770 loss=2.583, loss_v1=0, loss_v2=0, nll_loss=1.414, ntokens=2279.2, nsentences=72, sample_size=2279.2, sample_size_v1=0, sample_size_v2=0, ppl=2.66, wps=614.4, ups=0.27, wpb=2279.2, bsz=72, num_updates=900, lr=1.94805e-05, gnorm=1.859, clip=100, loss_scale=32, train_wall=37, gb_free=5.7, wall=3369
2023-05-06 04:04:13 - progress_bar.py[line:272] - INFO: epoch 002:    143 / 770 loss=2.602, loss_v1=0, loss_v2=0, nll_loss=1.434, ntokens=2258.1, nsentences=72, sample_size=2258.1, sample_size_v1=0, sample_size_v2=0, ppl=2.7, wps=607.2, ups=0.27, wpb=2258.1, bsz=72, num_updates=910, lr=1.9697e-05, gnorm=1.714, clip=100, loss_scale=32, train_wall=37, gb_free=5, wall=3406
2023-05-06 04:04:51 - progress_bar.py[line:272] - INFO: epoch 002:    153 / 770 loss=2.613, loss_v1=0, loss_v2=0, nll_loss=1.445, ntokens=2275.7, nsentences=72, sample_size=2275.7, sample_size_v1=0, sample_size_v2=0, ppl=2.72, wps=607.6, ups=0.27, wpb=2275.7, bsz=72, num_updates=920, lr=1.99134e-05, gnorm=1.71, clip=100, loss_scale=32, train_wall=37, gb_free=5.1, wall=3444
2023-05-06 04:05:28 - progress_bar.py[line:272] - INFO: epoch 002:    163 / 770 loss=2.58, loss_v1=0, loss_v2=0, nll_loss=1.408, ntokens=2411.2, nsentences=72, sample_size=2411.2, sample_size_v1=0, sample_size_v2=0, ppl=2.65, wps=643.5, ups=0.27, wpb=2411.2, bsz=72, num_updates=930, lr=2.01299e-05, gnorm=1.648, clip=100, loss_scale=32, train_wall=37, gb_free=4.6, wall=3481
2023-05-06 04:06:06 - progress_bar.py[line:272] - INFO: epoch 002:    173 / 770 loss=2.575, loss_v1=0, loss_v2=0, nll_loss=1.403, ntokens=2359.9, nsentences=72, sample_size=2359.9, sample_size_v1=0, sample_size_v2=0, ppl=2.64, wps=629.9, ups=0.27, wpb=2359.9, bsz=72, num_updates=940, lr=2.03463e-05, gnorm=1.564, clip=100, loss_scale=32, train_wall=37, gb_free=3.9, wall=3519
2023-05-06 04:06:43 - progress_bar.py[line:272] - INFO: epoch 002:    183 / 770 loss=2.554, loss_v1=0, loss_v2=0, nll_loss=1.378, ntokens=2429.8, nsentences=72, sample_size=2429.8, sample_size_v1=0, sample_size_v2=0, ppl=2.6, wps=648.6, ups=0.27, wpb=2429.8, bsz=72, num_updates=950, lr=2.05628e-05, gnorm=1.535, clip=100, loss_scale=32, train_wall=37, gb_free=5, wall=3556
2023-05-06 04:07:21 - progress_bar.py[line:272] - INFO: epoch 002:    193 / 770 loss=2.532, loss_v1=0, loss_v2=0, nll_loss=1.354, ntokens=2378.7, nsentences=72, sample_size=2378.7, sample_size_v1=0, sample_size_v2=0, ppl=2.56, wps=632.3, ups=0.27, wpb=2378.7, bsz=72, num_updates=960, lr=2.07792e-05, gnorm=1.616, clip=100, loss_scale=32, train_wall=38, gb_free=4.6, wall=3594
2023-05-06 04:07:58 - progress_bar.py[line:272] - INFO: epoch 002:    203 / 770 loss=2.554, loss_v1=0, loss_v2=0, nll_loss=1.377, ntokens=2393.7, nsentences=72, sample_size=2393.7, sample_size_v1=0, sample_size_v2=0, ppl=2.6, wps=636.3, ups=0.27, wpb=2393.7, bsz=72, num_updates=970, lr=2.09957e-05, gnorm=1.549, clip=100, loss_scale=32, train_wall=38, gb_free=4.7, wall=3632
2023-05-06 04:08:36 - progress_bar.py[line:272] - INFO: epoch 002:    213 / 770 loss=2.547, loss_v1=0, loss_v2=0, nll_loss=1.367, ntokens=2401.6, nsentences=72, sample_size=2401.6, sample_size_v1=0, sample_size_v2=0, ppl=2.58, wps=641.8, ups=0.27, wpb=2401.6, bsz=72, num_updates=980, lr=2.12121e-05, gnorm=1.596, clip=100, loss_scale=32, train_wall=37, gb_free=5, wall=3669
2023-05-06 04:09:13 - progress_bar.py[line:272] - INFO: epoch 002:    223 / 770 loss=2.538, loss_v1=0, loss_v2=0, nll_loss=1.362, ntokens=2337.8, nsentences=72, sample_size=2337.8, sample_size_v1=0, sample_size_v2=0, ppl=2.57, wps=626.9, ups=0.27, wpb=2337.8, bsz=72, num_updates=990, lr=2.14286e-05, gnorm=1.709, clip=100, loss_scale=32, train_wall=37, gb_free=4.3, wall=3706
2023-05-06 04:09:50 - progress_bar.py[line:272] - INFO: epoch 002:    233 / 770 loss=2.533, loss_v1=0, loss_v2=0, nll_loss=1.353, ntokens=2235.5, nsentences=72, sample_size=2235.5, sample_size_v1=0, sample_size_v2=0, ppl=2.55, wps=602.2, ups=0.27, wpb=2235.5, bsz=72, num_updates=1000, lr=2.1645e-05, gnorm=1.747, clip=100, loss_scale=32, train_wall=37, gb_free=4.6, wall=3743
2023-05-06 04:10:28 - progress_bar.py[line:272] - INFO: epoch 002:    243 / 770 loss=2.516, loss_v1=0, loss_v2=0, nll_loss=1.335, ntokens=2480.1, nsentences=72, sample_size=2480.1, sample_size_v1=0, sample_size_v2=0, ppl=2.52, wps=659, ups=0.27, wpb=2480.1, bsz=72, num_updates=1010, lr=2.18615e-05, gnorm=1.562, clip=100, loss_scale=32, train_wall=38, gb_free=5.1, wall=3781
2023-05-06 04:11:05 - progress_bar.py[line:272] - INFO: epoch 002:    253 / 770 loss=2.53, loss_v1=0, loss_v2=0, nll_loss=1.35, ntokens=2413.9, nsentences=72, sample_size=2413.9, sample_size_v1=0, sample_size_v2=0, ppl=2.55, wps=645.4, ups=0.27, wpb=2413.9, bsz=72, num_updates=1020, lr=2.20779e-05, gnorm=1.559, clip=100, loss_scale=32, train_wall=37, gb_free=5.5, wall=3818
2023-05-06 04:11:43 - progress_bar.py[line:272] - INFO: epoch 002:    263 / 770 loss=2.54, loss_v1=0, loss_v2=0, nll_loss=1.36, ntokens=2506, nsentences=72, sample_size=2506, sample_size_v1=0, sample_size_v2=0, ppl=2.57, wps=665.4, ups=0.27, wpb=2506, bsz=72, num_updates=1030, lr=2.22944e-05, gnorm=1.461, clip=100, loss_scale=64, train_wall=38, gb_free=5.2, wall=3856
2023-05-06 04:12:20 - progress_bar.py[line:272] - INFO: epoch 002:    273 / 770 loss=2.561, loss_v1=0, loss_v2=0, nll_loss=1.385, ntokens=2317.1, nsentences=72, sample_size=2317.1, sample_size_v1=0, sample_size_v2=0, ppl=2.61, wps=627.7, ups=0.27, wpb=2317.1, bsz=72, num_updates=1040, lr=2.25108e-05, gnorm=1.585, clip=100, loss_scale=64, train_wall=37, gb_free=5.7, wall=3893
2023-05-06 04:12:57 - progress_bar.py[line:272] - INFO: epoch 002:    283 / 770 loss=2.573, loss_v1=0, loss_v2=0, nll_loss=1.4, ntokens=2358.4, nsentences=72, sample_size=2358.4, sample_size_v1=0, sample_size_v2=0, ppl=2.64, wps=637.3, ups=0.27, wpb=2358.4, bsz=72, num_updates=1050, lr=2.27273e-05, gnorm=1.592, clip=100, loss_scale=64, train_wall=37, gb_free=5, wall=3930
2023-05-06 04:13:34 - progress_bar.py[line:272] - INFO: epoch 002:    293 / 770 loss=2.581, loss_v1=0, loss_v2=0, nll_loss=1.408, ntokens=2462.9, nsentences=72, sample_size=2462.9, sample_size_v1=0, sample_size_v2=0, ppl=2.65, wps=667.9, ups=0.27, wpb=2462.9, bsz=72, num_updates=1060, lr=2.29437e-05, gnorm=1.524, clip=100, loss_scale=64, train_wall=37, gb_free=5.2, wall=3967
2023-05-06 04:14:11 - progress_bar.py[line:272] - INFO: epoch 002:    303 / 770 loss=2.568, loss_v1=0, loss_v2=0, nll_loss=1.393, ntokens=2405.9, nsentences=72, sample_size=2405.9, sample_size_v1=0, sample_size_v2=0, ppl=2.63, wps=651.5, ups=0.27, wpb=2405.9, bsz=72, num_updates=1070, lr=2.31602e-05, gnorm=1.506, clip=100, loss_scale=64, train_wall=37, gb_free=4.9, wall=4004
2023-05-06 04:14:48 - progress_bar.py[line:272] - INFO: epoch 002:    313 / 770 loss=2.577, loss_v1=0, loss_v2=0, nll_loss=1.402, ntokens=2313.9, nsentences=72, sample_size=2313.9, sample_size_v1=0, sample_size_v2=0, ppl=2.64, wps=625, ups=0.27, wpb=2313.9, bsz=72, num_updates=1080, lr=2.33766e-05, gnorm=1.465, clip=100, loss_scale=64, train_wall=37, gb_free=5.2, wall=4041
2023-05-06 04:15:25 - progress_bar.py[line:272] - INFO: epoch 002:    323 / 770 loss=2.568, loss_v1=0, loss_v2=0, nll_loss=1.392, ntokens=2366.9, nsentences=72, sample_size=2366.9, sample_size_v1=0, sample_size_v2=0, ppl=2.62, wps=631, ups=0.27, wpb=2366.9, bsz=72, num_updates=1090, lr=2.35931e-05, gnorm=1.542, clip=100, loss_scale=64, train_wall=37, gb_free=4.8, wall=4078
2023-05-06 04:16:02 - progress_bar.py[line:272] - INFO: epoch 002:    333 / 770 loss=2.566, loss_v1=0, loss_v2=0, nll_loss=1.391, ntokens=2397.2, nsentences=72, sample_size=2397.2, sample_size_v1=0, sample_size_v2=0, ppl=2.62, wps=646.4, ups=0.27, wpb=2397.2, bsz=72, num_updates=1100, lr=2.38095e-05, gnorm=1.551, clip=100, loss_scale=64, train_wall=37, gb_free=4.8, wall=4115
2023-05-06 04:16:39 - progress_bar.py[line:272] - INFO: epoch 002:    343 / 770 loss=2.568, loss_v1=0, loss_v2=0, nll_loss=1.391, ntokens=2466.8, nsentences=72, sample_size=2466.8, sample_size_v1=0, sample_size_v2=0, ppl=2.62, wps=663.3, ups=0.27, wpb=2466.8, bsz=72, num_updates=1110, lr=2.4026e-05, gnorm=1.425, clip=100, loss_scale=64, train_wall=37, gb_free=5.4, wall=4153
2023-05-06 04:17:17 - progress_bar.py[line:272] - INFO: epoch 002:    353 / 770 loss=2.562, loss_v1=0, loss_v2=0, nll_loss=1.383, ntokens=2566.3, nsentences=72, sample_size=2566.3, sample_size_v1=0, sample_size_v2=0, ppl=2.61, wps=686.7, ups=0.27, wpb=2566.3, bsz=72, num_updates=1120, lr=2.42424e-05, gnorm=1.528, clip=100, loss_scale=64, train_wall=37, gb_free=5.4, wall=4190
2023-05-06 04:17:54 - progress_bar.py[line:272] - INFO: epoch 002:    363 / 770 loss=2.545, loss_v1=0, loss_v2=0, nll_loss=1.366, ntokens=2513.8, nsentences=72, sample_size=2513.8, sample_size_v1=0, sample_size_v2=0, ppl=2.58, wps=675.6, ups=0.27, wpb=2513.8, bsz=72, num_updates=1130, lr=2.44589e-05, gnorm=1.486, clip=100, loss_scale=64, train_wall=37, gb_free=4.9, wall=4227
2023-05-06 04:18:31 - progress_bar.py[line:272] - INFO: epoch 002:    373 / 770 loss=2.548, loss_v1=0, loss_v2=0, nll_loss=1.37, ntokens=2473.3, nsentences=72, sample_size=2473.3, sample_size_v1=0, sample_size_v2=0, ppl=2.59, wps=666.1, ups=0.27, wpb=2473.3, bsz=72, num_updates=1140, lr=2.46753e-05, gnorm=1.368, clip=100, loss_scale=64, train_wall=37, gb_free=5, wall=4264
2023-05-06 04:19:08 - progress_bar.py[line:272] - INFO: epoch 002:    383 / 770 loss=2.543, loss_v1=0, loss_v2=0, nll_loss=1.364, ntokens=2445.3, nsentences=72, sample_size=2445.3, sample_size_v1=0, sample_size_v2=0, ppl=2.57, wps=661.1, ups=0.27, wpb=2445.3, bsz=72, num_updates=1150, lr=2.48918e-05, gnorm=1.481, clip=100, loss_scale=64, train_wall=37, gb_free=5.3, wall=4301
2023-05-06 04:19:45 - progress_bar.py[line:272] - INFO: epoch 002:    393 / 770 loss=2.558, loss_v1=0, loss_v2=0, nll_loss=1.38, ntokens=2380.6, nsentences=72, sample_size=2380.6, sample_size_v1=0, sample_size_v2=0, ppl=2.6, wps=644.1, ups=0.27, wpb=2380.6, bsz=72, num_updates=1160, lr=2.51082e-05, gnorm=1.598, clip=100, loss_scale=64, train_wall=37, gb_free=5.5, wall=4338
2023-05-06 04:20:22 - progress_bar.py[line:272] - INFO: epoch 002:    403 / 770 loss=2.544, loss_v1=0, loss_v2=0, nll_loss=1.365, ntokens=2415.4, nsentences=72, sample_size=2415.4, sample_size_v1=0, sample_size_v2=0, ppl=2.58, wps=653.6, ups=0.27, wpb=2415.4, bsz=72, num_updates=1170, lr=2.53247e-05, gnorm=1.563, clip=100, loss_scale=64, train_wall=37, gb_free=5.7, wall=4375
2023-05-06 04:20:59 - progress_bar.py[line:272] - INFO: epoch 002:    413 / 770 loss=2.5, loss_v1=0, loss_v2=0, nll_loss=1.314, ntokens=2448.9, nsentences=72, sample_size=2448.9, sample_size_v1=0, sample_size_v2=0, ppl=2.49, wps=661.7, ups=0.27, wpb=2448.9, bsz=72, num_updates=1180, lr=2.55411e-05, gnorm=1.414, clip=100, loss_scale=64, train_wall=37, gb_free=4.8, wall=4412
2023-05-06 04:21:36 - progress_bar.py[line:272] - INFO: epoch 002:    423 / 770 loss=2.53, loss_v1=0, loss_v2=0, nll_loss=1.349, ntokens=2393.5, nsentences=72, sample_size=2393.5, sample_size_v1=0, sample_size_v2=0, ppl=2.55, wps=648.3, ups=0.27, wpb=2393.5, bsz=72, num_updates=1190, lr=2.57576e-05, gnorm=1.536, clip=100, loss_scale=64, train_wall=37, gb_free=5, wall=4449
2023-05-06 04:22:13 - progress_bar.py[line:272] - INFO: epoch 002:    433 / 770 loss=2.537, loss_v1=0, loss_v2=0, nll_loss=1.356, ntokens=2287.8, nsentences=72, sample_size=2287.8, sample_size_v1=0, sample_size_v2=0, ppl=2.56, wps=621.8, ups=0.27, wpb=2287.8, bsz=72, num_updates=1200, lr=2.5974e-05, gnorm=1.606, clip=100, loss_scale=64, train_wall=37, gb_free=5.8, wall=4486
2023-05-06 04:22:50 - progress_bar.py[line:272] - INFO: epoch 002:    443 / 770 loss=2.552, loss_v1=0, loss_v2=0, nll_loss=1.372, ntokens=2390.2, nsentences=72, sample_size=2390.2, sample_size_v1=0, sample_size_v2=0, ppl=2.59, wps=646.8, ups=0.27, wpb=2390.2, bsz=72, num_updates=1210, lr=2.61905e-05, gnorm=1.487, clip=100, loss_scale=64, train_wall=37, gb_free=5.5, wall=4523
2023-05-06 04:23:27 - progress_bar.py[line:272] - INFO: epoch 002:    453 / 770 loss=2.543, loss_v1=0, loss_v2=0, nll_loss=1.362, ntokens=2221.8, nsentences=72, sample_size=2221.8, sample_size_v1=0, sample_size_v2=0, ppl=2.57, wps=603.8, ups=0.27, wpb=2221.8, bsz=72, num_updates=1220, lr=2.64069e-05, gnorm=1.565, clip=100, loss_scale=64, train_wall=37, gb_free=5.1, wall=4560
2023-05-06 04:24:03 - progress_bar.py[line:272] - INFO: epoch 002:    463 / 770 loss=2.5, loss_v1=0, loss_v2=0, nll_loss=1.317, ntokens=2325.8, nsentences=72, sample_size=2325.8, sample_size_v1=0, sample_size_v2=0, ppl=2.49, wps=630.1, ups=0.27, wpb=2325.8, bsz=72, num_updates=1230, lr=2.66234e-05, gnorm=1.522, clip=100, loss_scale=64, train_wall=37, gb_free=5.8, wall=4597
2023-05-06 04:24:40 - progress_bar.py[line:272] - INFO: epoch 002:    473 / 770 loss=2.523, loss_v1=0, loss_v2=0, nll_loss=1.338, ntokens=2295.4, nsentences=72, sample_size=2295.4, sample_size_v1=0, sample_size_v2=0, ppl=2.53, wps=624.9, ups=0.27, wpb=2295.4, bsz=72, num_updates=1240, lr=2.68398e-05, gnorm=1.625, clip=100, loss_scale=64, train_wall=37, gb_free=5.6, wall=4633
2023-05-06 04:25:17 - progress_bar.py[line:272] - INFO: epoch 002:    483 / 770 loss=2.546, loss_v1=0, loss_v2=0, nll_loss=1.366, ntokens=2289.2, nsentences=72, sample_size=2289.2, sample_size_v1=0, sample_size_v2=0, ppl=2.58, wps=622, ups=0.27, wpb=2289.2, bsz=72, num_updates=1250, lr=2.70563e-05, gnorm=1.59, clip=100, loss_scale=64, train_wall=37, gb_free=5.5, wall=4670
2023-05-06 04:25:54 - progress_bar.py[line:272] - INFO: epoch 002:    493 / 770 loss=2.56, loss_v1=0, loss_v2=0, nll_loss=1.382, ntokens=2272.3, nsentences=72, sample_size=2272.3, sample_size_v1=0, sample_size_v2=0, ppl=2.61, wps=617, ups=0.27, wpb=2272.3, bsz=72, num_updates=1260, lr=2.72727e-05, gnorm=1.702, clip=100, loss_scale=64, train_wall=37, gb_free=5.9, wall=4707
2023-05-06 04:26:31 - progress_bar.py[line:272] - INFO: epoch 002:    503 / 770 loss=2.55, loss_v1=0, loss_v2=0, nll_loss=1.37, ntokens=2392.2, nsentences=72, sample_size=2392.2, sample_size_v1=0, sample_size_v2=0, ppl=2.59, wps=645.6, ups=0.27, wpb=2392.2, bsz=72, num_updates=1270, lr=2.74892e-05, gnorm=1.495, clip=100, loss_scale=64, train_wall=37, gb_free=5.1, wall=4744
2023-05-06 04:27:08 - progress_bar.py[line:272] - INFO: epoch 002:    513 / 770 loss=2.526, loss_v1=0, loss_v2=0, nll_loss=1.344, ntokens=2414.5, nsentences=72, sample_size=2414.5, sample_size_v1=0, sample_size_v2=0, ppl=2.54, wps=652.9, ups=0.27, wpb=2414.5, bsz=72, num_updates=1280, lr=2.77056e-05, gnorm=1.472, clip=100, loss_scale=64, train_wall=37, gb_free=5.5, wall=4781
2023-05-06 04:27:45 - progress_bar.py[line:272] - INFO: epoch 002:    523 / 770 loss=2.524, loss_v1=0, loss_v2=0, nll_loss=1.339, ntokens=2313.5, nsentences=72, sample_size=2313.5, sample_size_v1=0, sample_size_v2=0, ppl=2.53, wps=629.7, ups=0.27, wpb=2313.5, bsz=72, num_updates=1290, lr=2.79221e-05, gnorm=1.597, clip=100, loss_scale=64, train_wall=37, gb_free=5.7, wall=4818
2023-05-06 04:28:21 - progress_bar.py[line:272] - INFO: epoch 002:    533 / 770 loss=2.514, loss_v1=0, loss_v2=0, nll_loss=1.331, ntokens=2300.1, nsentences=72, sample_size=2300.1, sample_size_v1=0, sample_size_v2=0, ppl=2.52, wps=625.3, ups=0.27, wpb=2300.1, bsz=72, num_updates=1300, lr=2.81385e-05, gnorm=1.56, clip=100, loss_scale=64, train_wall=37, gb_free=5.7, wall=4855
2023-05-06 04:28:58 - progress_bar.py[line:272] - INFO: epoch 002:    543 / 770 loss=2.527, loss_v1=0, loss_v2=0, nll_loss=1.342, ntokens=2450.6, nsentences=72, sample_size=2450.6, sample_size_v1=0, sample_size_v2=0, ppl=2.54, wps=662.9, ups=0.27, wpb=2450.6, bsz=72, num_updates=1310, lr=2.8355e-05, gnorm=1.633, clip=100, loss_scale=64, train_wall=37, gb_free=5.1, wall=4892
2023-05-06 04:29:35 - progress_bar.py[line:272] - INFO: epoch 002:    553 / 770 loss=2.524, loss_v1=0, loss_v2=0, nll_loss=1.34, ntokens=2322, nsentences=72, sample_size=2322, sample_size_v1=0, sample_size_v2=0, ppl=2.53, wps=627.6, ups=0.27, wpb=2322, bsz=72, num_updates=1320, lr=2.85714e-05, gnorm=1.59, clip=100, loss_scale=64, train_wall=37, gb_free=5.6, wall=4929
2023-05-06 04:30:12 - progress_bar.py[line:272] - INFO: epoch 002:    563 / 770 loss=2.524, loss_v1=0, loss_v2=0, nll_loss=1.342, ntokens=2277.5, nsentences=72, sample_size=2277.5, sample_size_v1=0, sample_size_v2=0, ppl=2.54, wps=620.2, ups=0.27, wpb=2277.5, bsz=72, num_updates=1330, lr=2.87879e-05, gnorm=1.572, clip=100, loss_scale=64, train_wall=37, gb_free=5.9, wall=4965
2023-05-06 04:30:49 - progress_bar.py[line:272] - INFO: epoch 002:    573 / 770 loss=2.506, loss_v1=0, loss_v2=0, nll_loss=1.32, ntokens=2336.2, nsentences=72, sample_size=2336.2, sample_size_v1=0, sample_size_v2=0, ppl=2.5, wps=634.1, ups=0.27, wpb=2336.2, bsz=72, num_updates=1340, lr=2.90043e-05, gnorm=1.681, clip=100, loss_scale=64, train_wall=37, gb_free=5.4, wall=5002
2023-05-06 04:31:26 - progress_bar.py[line:272] - INFO: epoch 002:    583 / 770 loss=2.514, loss_v1=0, loss_v2=0, nll_loss=1.332, ntokens=2332, nsentences=72, sample_size=2332, sample_size_v1=0, sample_size_v2=0, ppl=2.52, wps=634.5, ups=0.27, wpb=2332, bsz=72, num_updates=1350, lr=2.92208e-05, gnorm=1.662, clip=100, loss_scale=64, train_wall=37, gb_free=5.6, wall=5039
2023-05-06 04:32:02 - progress_bar.py[line:272] - INFO: epoch 002:    593 / 770 loss=2.515, loss_v1=0, loss_v2=0, nll_loss=1.328, ntokens=2264.4, nsentences=72, sample_size=2264.4, sample_size_v1=0, sample_size_v2=0, ppl=2.51, wps=614.9, ups=0.27, wpb=2264.4, bsz=72, num_updates=1360, lr=2.94372e-05, gnorm=1.633, clip=100, loss_scale=64, train_wall=37, gb_free=5.7, wall=5076
2023-05-06 04:32:40 - progress_bar.py[line:272] - INFO: epoch 002:    603 / 770 loss=2.501, loss_v1=0, loss_v2=0, nll_loss=1.313, ntokens=2388.1, nsentences=72, sample_size=2388.1, sample_size_v1=0, sample_size_v2=0, ppl=2.48, wps=643.8, ups=0.27, wpb=2388.1, bsz=72, num_updates=1370, lr=2.96537e-05, gnorm=1.623, clip=100, loss_scale=64, train_wall=37, gb_free=5.9, wall=5113
2023-05-06 04:33:17 - progress_bar.py[line:272] - INFO: epoch 002:    613 / 770 loss=2.495, loss_v1=0, loss_v2=0, nll_loss=1.313, ntokens=2509.2, nsentences=72, sample_size=2509.2, sample_size_v1=0, sample_size_v2=0, ppl=2.48, wps=679.2, ups=0.27, wpb=2509.2, bsz=72, num_updates=1380, lr=2.98701e-05, gnorm=1.861, clip=100, loss_scale=64, train_wall=37, gb_free=5.3, wall=5150
2023-05-06 04:33:53 - progress_bar.py[line:272] - INFO: epoch 002:    623 / 770 loss=2.5, loss_v1=0, loss_v2=0, nll_loss=1.312, ntokens=2381, nsentences=72, sample_size=2381, sample_size_v1=0, sample_size_v2=0, ppl=2.48, wps=645.2, ups=0.27, wpb=2381, bsz=72, num_updates=1390, lr=2.99945e-05, gnorm=1.907, clip=100, loss_scale=64, train_wall=37, gb_free=5.1, wall=5187
2023-05-06 04:34:31 - progress_bar.py[line:272] - INFO: epoch 002:    633 / 770 loss=2.512, loss_v1=0, loss_v2=0, nll_loss=1.326, ntokens=2467.7, nsentences=72, sample_size=2467.7, sample_size_v1=0, sample_size_v2=0, ppl=2.51, wps=662.3, ups=0.27, wpb=2467.7, bsz=72, num_updates=1400, lr=2.99807e-05, gnorm=1.806, clip=100, loss_scale=64, train_wall=37, gb_free=5.3, wall=5224
2023-05-06 04:35:07 - progress_bar.py[line:272] - INFO: epoch 002:    643 / 770 loss=2.491, loss_v1=0, loss_v2=0, nll_loss=1.305, ntokens=2339.6, nsentences=72, sample_size=2339.6, sample_size_v1=0, sample_size_v2=0, ppl=2.47, wps=636.6, ups=0.27, wpb=2339.6, bsz=72, num_updates=1410, lr=2.99668e-05, gnorm=1.745, clip=100, loss_scale=64, train_wall=37, gb_free=5.5, wall=5261
2023-05-06 04:35:44 - progress_bar.py[line:272] - INFO: epoch 002:    653 / 770 loss=2.469, loss_v1=0, loss_v2=0, nll_loss=1.277, ntokens=2447.5, nsentences=72, sample_size=2447.5, sample_size_v1=0, sample_size_v2=0, ppl=2.42, wps=661.2, ups=0.27, wpb=2447.5, bsz=72, num_updates=1420, lr=2.9953e-05, gnorm=1.66, clip=100, loss_scale=64, train_wall=37, gb_free=5.6, wall=5298
2023-05-06 04:36:21 - progress_bar.py[line:272] - INFO: epoch 002:    663 / 770 loss=2.509, loss_v1=0, loss_v2=0, nll_loss=1.325, ntokens=2199.2, nsentences=72, sample_size=2199.2, sample_size_v1=0, sample_size_v2=0, ppl=2.5, wps=597.4, ups=0.27, wpb=2199.2, bsz=72, num_updates=1430, lr=2.99392e-05, gnorm=1.93, clip=100, loss_scale=64, train_wall=37, gb_free=6, wall=5335
2023-05-06 04:36:58 - progress_bar.py[line:272] - INFO: epoch 002:    673 / 770 loss=2.515, loss_v1=0, loss_v2=0, nll_loss=1.331, ntokens=2282.3, nsentences=72, sample_size=2282.3, sample_size_v1=0, sample_size_v2=0, ppl=2.52, wps=620.5, ups=0.27, wpb=2282.3, bsz=72, num_updates=1440, lr=2.99254e-05, gnorm=1.917, clip=100, loss_scale=64, train_wall=37, gb_free=5.7, wall=5371
2023-05-06 04:37:35 - progress_bar.py[line:272] - INFO: epoch 002:    683 / 770 loss=2.503, loss_v1=0, loss_v2=0, nll_loss=1.317, ntokens=2373, nsentences=72, sample_size=2373, sample_size_v1=0, sample_size_v2=0, ppl=2.49, wps=644.2, ups=0.27, wpb=2373, bsz=72, num_updates=1450, lr=2.99116e-05, gnorm=1.602, clip=100, loss_scale=64, train_wall=37, gb_free=4.8, wall=5408
2023-05-06 04:38:12 - progress_bar.py[line:272] - INFO: epoch 002:    693 / 770 loss=2.487, loss_v1=0, loss_v2=0, nll_loss=1.298, ntokens=2333, nsentences=72, sample_size=2333, sample_size_v1=0, sample_size_v2=0, ppl=2.46, wps=636.3, ups=0.27, wpb=2333, bsz=72, num_updates=1460, lr=2.98978e-05, gnorm=1.696, clip=100, loss_scale=64, train_wall=37, gb_free=6, wall=5445
2023-05-06 04:38:49 - progress_bar.py[line:272] - INFO: epoch 002:    703 / 770 loss=2.49, loss_v1=0, loss_v2=0, nll_loss=1.303, ntokens=2398.4, nsentences=72, sample_size=2398.4, sample_size_v1=0, sample_size_v2=0, ppl=2.47, wps=646.8, ups=0.27, wpb=2398.4, bsz=72, num_updates=1470, lr=2.98839e-05, gnorm=1.666, clip=100, loss_scale=64, train_wall=37, gb_free=5.7, wall=5482
2023-05-06 04:39:26 - progress_bar.py[line:272] - INFO: epoch 002:    713 / 770 loss=2.486, loss_v1=0, loss_v2=0, nll_loss=1.296, ntokens=2380.4, nsentences=72, sample_size=2380.4, sample_size_v1=0, sample_size_v2=0, ppl=2.46, wps=642, ups=0.27, wpb=2380.4, bsz=72, num_updates=1480, lr=2.98701e-05, gnorm=1.591, clip=100, loss_scale=64, train_wall=37, gb_free=5.2, wall=5519
2023-05-06 04:40:03 - progress_bar.py[line:272] - INFO: epoch 002:    723 / 770 loss=2.49, loss_v1=0, loss_v2=0, nll_loss=1.304, ntokens=2421.7, nsentences=72, sample_size=2421.7, sample_size_v1=0, sample_size_v2=0, ppl=2.47, wps=648.3, ups=0.27, wpb=2421.7, bsz=72, num_updates=1490, lr=2.98563e-05, gnorm=1.823, clip=100, loss_scale=64, train_wall=37, gb_free=5.1, wall=5556
2023-05-06 04:40:40 - progress_bar.py[line:272] - INFO: epoch 002:    733 / 770 loss=2.498, loss_v1=0, loss_v2=0, nll_loss=1.312, ntokens=2457.5, nsentences=72, sample_size=2457.5, sample_size_v1=0, sample_size_v2=0, ppl=2.48, wps=664.2, ups=0.27, wpb=2457.5, bsz=72, num_updates=1500, lr=2.98425e-05, gnorm=1.805, clip=100, loss_scale=64, train_wall=37, gb_free=5.9, wall=5593
2023-05-06 04:41:17 - progress_bar.py[line:272] - INFO: epoch 002:    743 / 770 loss=2.507, loss_v1=0, loss_v2=0, nll_loss=1.322, ntokens=2362.1, nsentences=72, sample_size=2362.1, sample_size_v1=0, sample_size_v2=0, ppl=2.5, wps=638.1, ups=0.27, wpb=2362.1, bsz=72, num_updates=1510, lr=2.98287e-05, gnorm=1.879, clip=100, loss_scale=64, train_wall=37, gb_free=5.7, wall=5630
2023-05-06 04:41:54 - progress_bar.py[line:272] - INFO: epoch 002:    753 / 770 loss=2.5, loss_v1=0, loss_v2=0, nll_loss=1.313, ntokens=2445.2, nsentences=72, sample_size=2445.2, sample_size_v1=0, sample_size_v2=0, ppl=2.48, wps=658.7, ups=0.27, wpb=2445.2, bsz=72, num_updates=1520, lr=2.98149e-05, gnorm=1.861, clip=100, loss_scale=64, train_wall=37, gb_free=5.3, wall=5668
2023-05-06 04:42:31 - progress_bar.py[line:272] - INFO: epoch 002:    763 / 770 loss=2.499, loss_v1=0, loss_v2=0, nll_loss=1.311, ntokens=2347.8, nsentences=72, sample_size=2347.8, sample_size_v1=0, sample_size_v2=0, ppl=2.48, wps=636.1, ups=0.27, wpb=2347.8, bsz=72, num_updates=1530, lr=2.98011e-05, gnorm=1.921, clip=100, loss_scale=64, train_wall=37, gb_free=5.1, wall=5704
2023-05-06 04:42:55 - train.py[line:332] - INFO: end of epoch 2 (average epoch stats below)
local datafile ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 2 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 1 begin to initialize row_count and line_idx-to-offset mapping
2023-05-06 04:42:55 - progress_bar.py[line:282] - INFO: epoch 002 | loss 2.538 | loss_v1 0 | loss_v2 0 | nll_loss 1.358 | ntokens 2365.46 | nsentences 71.948 | sample_size 2365.46 | sample_size_v1 0 | sample_size_v2 0 | ppl 2.56 | wps 637.3 | ups 0.27 | wpb 2365.5 | bsz 71.9 | num_updates 1537 | lr 2.97914e-05 | gnorm 1.667 | clip 100 | loss_scale 128 | train_wall 2852 | gb_free 6.1 | wall 5729
2023-05-06 04:42:55 - trainer.py[line:639] - INFO: loading train data for epoch 3
local datafile ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 0 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 2 finished initializing row_count and line_idx-to-offset mapping
file ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 2 row count 18466 total row count 55400
local datafile ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 0 finished initializing row_count and line_idx-to-offset mapping
file ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 0 row count 18467 total row count 55400
slice_id 2 seek offset 36934
slice_id 0 seek offset 0
2023-05-06 04:42:57 - trainer.py[line:703] - INFO: begin training epoch 3
2023-05-06 04:42:57 - train.py[line:305] - INFO: Start iterating over samples
local datafile ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 1 finished initializing row_count and line_idx-to-offset mapping
file ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 1 row count 18467 total row count 55400
slice_id 1 seek offset 18467
2023-05-06 04:43:09 - progress_bar.py[line:272] - INFO: epoch 003:      3 / 770 loss=2.487, loss_v1=0, loss_v2=0, nll_loss=1.3, ntokens=2276.5, nsentences=68.4, sample_size=2276.5, sample_size_v1=0, sample_size_v2=0, ppl=2.46, wps=609.2, ups=0.27, wpb=2276.5, bsz=68.4, num_updates=1540, lr=2.97872e-05, gnorm=2.058, clip=100, loss_scale=128, train_wall=35, gb_free=4.9, wall=5742
2023-05-06 04:43:46 - progress_bar.py[line:272] - INFO: epoch 003:     13 / 770 loss=2.452, loss_v1=0, loss_v2=0, nll_loss=1.259, ntokens=2297.4, nsentences=72, sample_size=2297.4, sample_size_v1=0, sample_size_v2=0, ppl=2.39, wps=619.2, ups=0.27, wpb=2297.4, bsz=72, num_updates=1550, lr=2.97734e-05, gnorm=2.161, clip=100, loss_scale=128, train_wall=37, gb_free=5.3, wall=5779
2023-05-06 04:44:23 - progress_bar.py[line:272] - INFO: epoch 003:     23 / 770 loss=2.438, loss_v1=0, loss_v2=0, nll_loss=1.245, ntokens=2374.5, nsentences=72, sample_size=2374.5, sample_size_v1=0, sample_size_v2=0, ppl=2.37, wps=637.8, ups=0.27, wpb=2374.5, bsz=72, num_updates=1560, lr=2.97596e-05, gnorm=2.069, clip=100, loss_scale=128, train_wall=37, gb_free=5.1, wall=5816
2023-05-06 04:45:00 - progress_bar.py[line:272] - INFO: epoch 003:     33 / 770 loss=2.465, loss_v1=0, loss_v2=0, nll_loss=1.273, ntokens=2151.2, nsentences=72, sample_size=2151.2, sample_size_v1=0, sample_size_v2=0, ppl=2.42, wps=583.1, ups=0.27, wpb=2151.2, bsz=72, num_updates=1570, lr=2.97458e-05, gnorm=2.513, clip=100, loss_scale=128, train_wall=37, gb_free=5.8, wall=5853
2023-05-06 04:45:37 - progress_bar.py[line:272] - INFO: epoch 003:     43 / 770 loss=2.448, loss_v1=0, loss_v2=0, nll_loss=1.257, ntokens=2195.4, nsentences=72, sample_size=2195.4, sample_size_v1=0, sample_size_v2=0, ppl=2.39, wps=590.5, ups=0.27, wpb=2195.4, bsz=72, num_updates=1580, lr=2.9732e-05, gnorm=2.483, clip=100, loss_scale=128, train_wall=37, gb_free=5.2, wall=5890
2023-05-06 04:46:15 - progress_bar.py[line:272] - INFO: epoch 003:     53 / 770 loss=2.394, loss_v1=0, loss_v2=0, nll_loss=1.194, ntokens=2352.1, nsentences=72, sample_size=2352.1, sample_size_v1=0, sample_size_v2=0, ppl=2.29, wps=625.6, ups=0.27, wpb=2352.1, bsz=72, num_updates=1590, lr=2.97182e-05, gnorm=2.37, clip=100, loss_scale=128, train_wall=38, gb_free=5.3, wall=5928
2023-05-06 04:46:52 - progress_bar.py[line:272] - INFO: epoch 003:     63 / 770 loss=2.436, loss_v1=0, loss_v2=0, nll_loss=1.244, ntokens=2294.1, nsentences=72, sample_size=2294.1, sample_size_v1=0, sample_size_v2=0, ppl=2.37, wps=618.7, ups=0.27, wpb=2294.1, bsz=72, num_updates=1600, lr=2.97043e-05, gnorm=2.443, clip=100, loss_scale=128, train_wall=37, gb_free=4.8, wall=5965
2023-05-06 04:47:29 - progress_bar.py[line:272] - INFO: epoch 003:     73 / 770 loss=2.391, loss_v1=0, loss_v2=0, nll_loss=1.19, ntokens=2299.1, nsentences=72, sample_size=2299.1, sample_size_v1=0, sample_size_v2=0, ppl=2.28, wps=617.4, ups=0.27, wpb=2299.1, bsz=72, num_updates=1610, lr=2.96905e-05, gnorm=2.312, clip=100, loss_scale=128, train_wall=37, gb_free=5.1, wall=6002
2023-05-06 04:48:07 - progress_bar.py[line:272] - INFO: epoch 003:     83 / 770 loss=2.346, loss_v1=0, loss_v2=0, nll_loss=1.14, ntokens=2374.1, nsentences=72, sample_size=2374.1, sample_size_v1=0, sample_size_v2=0, ppl=2.2, wps=631, ups=0.27, wpb=2374.1, bsz=72, num_updates=1620, lr=2.96767e-05, gnorm=2.242, clip=100, loss_scale=128, train_wall=38, gb_free=4.9, wall=6040
2023-05-06 04:48:44 - progress_bar.py[line:272] - INFO: epoch 003:     93 / 770 loss=2.382, loss_v1=0, loss_v2=0, nll_loss=1.184, ntokens=2574.3, nsentences=72, sample_size=2574.3, sample_size_v1=0, sample_size_v2=0, ppl=2.27, wps=678.6, ups=0.26, wpb=2574.3, bsz=72, num_updates=1630, lr=2.96629e-05, gnorm=2.354, clip=100, loss_scale=128, train_wall=38, gb_free=4.8, wall=6078
2023-05-06 04:49:22 - progress_bar.py[line:272] - INFO: epoch 003:    103 / 770 loss=2.385, loss_v1=0, loss_v2=0, nll_loss=1.182, ntokens=2350.9, nsentences=72, sample_size=2350.9, sample_size_v1=0, sample_size_v2=0, ppl=2.27, wps=623.4, ups=0.27, wpb=2350.9, bsz=72, num_updates=1640, lr=2.96491e-05, gnorm=2.806, clip=100, loss_scale=128, train_wall=38, gb_free=4.2, wall=6115
2023-05-06 04:50:00 - progress_bar.py[line:272] - INFO: epoch 003:    113 / 770 loss=2.414, loss_v1=0, loss_v2=0, nll_loss=1.22, ntokens=2359.4, nsentences=72, sample_size=2359.4, sample_size_v1=0, sample_size_v2=0, ppl=2.33, wps=629.2, ups=0.27, wpb=2359.4, bsz=72, num_updates=1650, lr=2.96353e-05, gnorm=2.864, clip=100, loss_scale=128, train_wall=37, gb_free=5.2, wall=6153
2023-05-06 04:50:37 - progress_bar.py[line:272] - INFO: epoch 003:    123 / 770 loss=2.385, loss_v1=0, loss_v2=0, nll_loss=1.185, ntokens=2348.4, nsentences=72, sample_size=2348.4, sample_size_v1=0, sample_size_v2=0, ppl=2.27, wps=630.9, ups=0.27, wpb=2348.4, bsz=72, num_updates=1660, lr=2.96214e-05, gnorm=2.279, clip=100, loss_scale=128, train_wall=37, gb_free=4.9, wall=6190
2023-05-06 04:51:14 - progress_bar.py[line:272] - INFO: epoch 003:    133 / 770 loss=2.439, loss_v1=0, loss_v2=0, nll_loss=1.247, ntokens=2270.8, nsentences=72, sample_size=2270.8, sample_size_v1=0, sample_size_v2=0, ppl=2.37, wps=613.7, ups=0.27, wpb=2270.8, bsz=72, num_updates=1670, lr=2.96076e-05, gnorm=2.584, clip=100, loss_scale=128, train_wall=37, gb_free=5.7, wall=6227
2023-05-06 04:51:51 - progress_bar.py[line:272] - INFO: epoch 003:    143 / 770 loss=2.469, loss_v1=0, loss_v2=0, nll_loss=1.28, ntokens=2264, nsentences=72, sample_size=2264, sample_size_v1=0, sample_size_v2=0, ppl=2.43, wps=613.6, ups=0.27, wpb=2264, bsz=72, num_updates=1680, lr=2.95938e-05, gnorm=2.489, clip=100, loss_scale=128, train_wall=37, gb_free=5.6, wall=6264
2023-05-06 04:52:28 - progress_bar.py[line:272] - INFO: epoch 003:    153 / 770 loss=2.484, loss_v1=0, loss_v2=0, nll_loss=1.294, ntokens=2278.7, nsentences=72, sample_size=2278.7, sample_size_v1=0, sample_size_v2=0, ppl=2.45, wps=612.1, ups=0.27, wpb=2278.7, bsz=72, num_updates=1690, lr=2.958e-05, gnorm=2.33, clip=100, loss_scale=128, train_wall=37, gb_free=5.1, wall=6301
2023-05-06 04:53:06 - progress_bar.py[line:272] - INFO: epoch 003:    163 / 770 loss=2.452, loss_v1=0, loss_v2=0, nll_loss=1.261, ntokens=2408.3, nsentences=72, sample_size=2408.3, sample_size_v1=0, sample_size_v2=0, ppl=2.4, wps=641.5, ups=0.27, wpb=2408.3, bsz=72, num_updates=1700, lr=2.95662e-05, gnorm=2.097, clip=100, loss_scale=128, train_wall=37, gb_free=4.6, wall=6339
2023-05-06 04:53:43 - progress_bar.py[line:272] - INFO: epoch 003:    173 / 770 loss=2.446, loss_v1=0, loss_v2=0, nll_loss=1.254, ntokens=2363.3, nsentences=72, sample_size=2363.3, sample_size_v1=0, sample_size_v2=0, ppl=2.39, wps=626.7, ups=0.27, wpb=2363.3, bsz=72, num_updates=1710, lr=2.95524e-05, gnorm=2.139, clip=100, loss_scale=128, train_wall=38, gb_free=3.9, wall=6377
2023-05-06 04:54:21 - progress_bar.py[line:272] - INFO: epoch 003:    183 / 770 loss=2.429, loss_v1=0, loss_v2=0, nll_loss=1.234, ntokens=2423.2, nsentences=72, sample_size=2423.2, sample_size_v1=0, sample_size_v2=0, ppl=2.35, wps=645.2, ups=0.27, wpb=2423.2, bsz=72, num_updates=1720, lr=2.95385e-05, gnorm=2.077, clip=100, loss_scale=128, train_wall=38, gb_free=5, wall=6414
2023-05-06 04:54:59 - progress_bar.py[line:272] - INFO: epoch 003:    193 / 770 loss=2.411, loss_v1=0, loss_v2=0, nll_loss=1.215, ntokens=2377.5, nsentences=72, sample_size=2377.5, sample_size_v1=0, sample_size_v2=0, ppl=2.32, wps=630.8, ups=0.27, wpb=2377.5, bsz=72, num_updates=1730, lr=2.95247e-05, gnorm=2.026, clip=100, loss_scale=128, train_wall=38, gb_free=4.6, wall=6452
2023-05-06 04:55:36 - progress_bar.py[line:272] - INFO: epoch 003:    203 / 770 loss=2.438, loss_v1=0, loss_v2=0, nll_loss=1.245, ntokens=2399.3, nsentences=72, sample_size=2399.3, sample_size_v1=0, sample_size_v2=0, ppl=2.37, wps=639, ups=0.27, wpb=2399.3, bsz=72, num_updates=1740, lr=2.95109e-05, gnorm=2.118, clip=100, loss_scale=128, train_wall=38, gb_free=4.7, wall=6489
2023-05-06 04:56:14 - progress_bar.py[line:272] - INFO: epoch 003:    213 / 770 loss=2.433, loss_v1=0, loss_v2=0, nll_loss=1.237, ntokens=2410.5, nsentences=72, sample_size=2410.5, sample_size_v1=0, sample_size_v2=0, ppl=2.36, wps=643.8, ups=0.27, wpb=2410.5, bsz=72, num_updates=1750, lr=2.94971e-05, gnorm=2.18, clip=100, loss_scale=128, train_wall=37, gb_free=5.1, wall=6527
2023-05-06 04:56:51 - progress_bar.py[line:272] - INFO: epoch 003:    223 / 770 loss=2.429, loss_v1=0, loss_v2=0, nll_loss=1.234, ntokens=2328.1, nsentences=72, sample_size=2328.1, sample_size_v1=0, sample_size_v2=0, ppl=2.35, wps=623.8, ups=0.27, wpb=2328.1, bsz=72, num_updates=1760, lr=2.94833e-05, gnorm=2.236, clip=100, loss_scale=128, train_wall=37, gb_free=4.3, wall=6564
2023-05-06 04:57:28 - progress_bar.py[line:272] - INFO: epoch 003:    233 / 770 loss=2.423, loss_v1=0, loss_v2=0, nll_loss=1.231, ntokens=2238.5, nsentences=72, sample_size=2238.5, sample_size_v1=0, sample_size_v2=0, ppl=2.35, wps=603.6, ups=0.27, wpb=2238.5, bsz=72, num_updates=1770, lr=2.94695e-05, gnorm=2.412, clip=100, loss_scale=128, train_wall=37, gb_free=4.7, wall=6601
2023-05-06 04:58:05 - progress_bar.py[line:272] - INFO: epoch 003:    243 / 770 loss=2.404, loss_v1=0, loss_v2=0, nll_loss=1.204, ntokens=2476.5, nsentences=72, sample_size=2476.5, sample_size_v1=0, sample_size_v2=0, ppl=2.3, wps=660.7, ups=0.27, wpb=2476.5, bsz=72, num_updates=1780, lr=2.94557e-05, gnorm=2.423, clip=100, loss_scale=128, train_wall=37, gb_free=5.1, wall=6639
2023-05-06 04:58:43 - progress_bar.py[line:272] - INFO: epoch 003:    253 / 770 loss=2.413, loss_v1=0, loss_v2=0, nll_loss=1.218, ntokens=2416.1, nsentences=72, sample_size=2416.1, sample_size_v1=0, sample_size_v2=0, ppl=2.33, wps=646.8, ups=0.27, wpb=2416.1, bsz=72, num_updates=1790, lr=2.94418e-05, gnorm=2.744, clip=100, loss_scale=128, train_wall=37, gb_free=5.4, wall=6676
2023-05-06 04:59:20 - progress_bar.py[line:272] - INFO: epoch 003:    263 / 770 loss=2.435, loss_v1=0, loss_v2=0, nll_loss=1.239, ntokens=2510, nsentences=72, sample_size=2510, sample_size_v1=0, sample_size_v2=0, ppl=2.36, wps=667.6, ups=0.27, wpb=2510, bsz=72, num_updates=1800, lr=2.9428e-05, gnorm=2.358, clip=100, loss_scale=128, train_wall=38, gb_free=5.2, wall=6714
2023-05-06 04:59:57 - progress_bar.py[line:272] - INFO: epoch 003:    273 / 770 loss=2.448, loss_v1=0, loss_v2=0, nll_loss=1.257, ntokens=2312.4, nsentences=72, sample_size=2312.4, sample_size_v1=0, sample_size_v2=0, ppl=2.39, wps=626.8, ups=0.27, wpb=2312.4, bsz=72, num_updates=1810, lr=2.94142e-05, gnorm=2.559, clip=100, loss_scale=128, train_wall=37, gb_free=5.7, wall=6751
2023-05-06 05:00:34 - progress_bar.py[line:272] - INFO: epoch 003:    283 / 770 loss=2.461, loss_v1=0, loss_v2=0, nll_loss=1.27, ntokens=2358.7, nsentences=72, sample_size=2358.7, sample_size_v1=0, sample_size_v2=0, ppl=2.41, wps=635.7, ups=0.27, wpb=2358.7, bsz=72, num_updates=1820, lr=2.94004e-05, gnorm=2.619, clip=100, loss_scale=128, train_wall=37, gb_free=5, wall=6788
2023-05-06 05:01:11 - progress_bar.py[line:272] - INFO: epoch 003:    293 / 770 loss=2.472, loss_v1=0, loss_v2=0, nll_loss=1.284, ntokens=2460.5, nsentences=72, sample_size=2460.5, sample_size_v1=0, sample_size_v2=0, ppl=2.43, wps=666.8, ups=0.27, wpb=2460.5, bsz=72, num_updates=1830, lr=2.93866e-05, gnorm=2.533, clip=100, loss_scale=128, train_wall=37, gb_free=5.2, wall=6825
2023-05-06 05:01:48 - progress_bar.py[line:272] - INFO: epoch 003:    303 / 770 loss=2.465, loss_v1=0, loss_v2=0, nll_loss=1.275, ntokens=2411, nsentences=72, sample_size=2411, sample_size_v1=0, sample_size_v2=0, ppl=2.42, wps=650.7, ups=0.27, wpb=2411, bsz=72, num_updates=1840, lr=2.93728e-05, gnorm=2.588, clip=100, loss_scale=128, train_wall=37, gb_free=5.3, wall=6862
2023-05-06 05:02:25 - progress_bar.py[line:272] - INFO: epoch 003:    313 / 770 loss=2.48, loss_v1=0, loss_v2=0, nll_loss=1.293, ntokens=2310.5, nsentences=72, sample_size=2310.5, sample_size_v1=0, sample_size_v2=0, ppl=2.45, wps=628.6, ups=0.27, wpb=2310.5, bsz=72, num_updates=1850, lr=2.93589e-05, gnorm=2.88, clip=100, loss_scale=128, train_wall=37, gb_free=5.2, wall=6898
2023-05-06 05:03:02 - progress_bar.py[line:272] - INFO: epoch 003:    323 / 770 loss=2.46, loss_v1=0, loss_v2=0, nll_loss=1.269, ntokens=2363.2, nsentences=72, sample_size=2363.2, sample_size_v1=0, sample_size_v2=0, ppl=2.41, wps=637, ups=0.27, wpb=2363.2, bsz=72, num_updates=1860, lr=2.93451e-05, gnorm=3.01, clip=100, loss_scale=128, train_wall=37, gb_free=4.8, wall=6936
2023-05-06 05:03:39 - progress_bar.py[line:272] - INFO: epoch 003:    333 / 770 loss=2.47, loss_v1=0, loss_v2=0, nll_loss=1.281, ntokens=2411.5, nsentences=72, sample_size=2411.5, sample_size_v1=0, sample_size_v2=0, ppl=2.43, wps=651.8, ups=0.27, wpb=2411.5, bsz=72, num_updates=1870, lr=2.93313e-05, gnorm=2.655, clip=100, loss_scale=128, train_wall=37, gb_free=4.8, wall=6973
2023-05-06 05:04:16 - progress_bar.py[line:272] - INFO: epoch 003:    343 / 770 loss=2.474, loss_v1=0, loss_v2=0, nll_loss=1.285, ntokens=2464.7, nsentences=72, sample_size=2464.7, sample_size_v1=0, sample_size_v2=0, ppl=2.44, wps=665.4, ups=0.27, wpb=2464.7, bsz=72, num_updates=1880, lr=2.93175e-05, gnorm=2.533, clip=100, loss_scale=128, train_wall=37, gb_free=5.2, wall=7010
2023-05-06 05:04:53 - progress_bar.py[line:272] - INFO: epoch 003:    353 / 770 loss=2.467, loss_v1=0, loss_v2=0, nll_loss=1.275, ntokens=2566.2, nsentences=72, sample_size=2566.2, sample_size_v1=0, sample_size_v2=0, ppl=2.42, wps=690.7, ups=0.27, wpb=2566.2, bsz=72, num_updates=1890, lr=2.93037e-05, gnorm=2.882, clip=100, loss_scale=128, train_wall=37, gb_free=5.4, wall=7047
2023-05-06 05:05:30 - progress_bar.py[line:272] - INFO: epoch 003:    363 / 770 loss=2.449, loss_v1=0, loss_v2=0, nll_loss=1.26, ntokens=2508.3, nsentences=72, sample_size=2508.3, sample_size_v1=0, sample_size_v2=0, ppl=2.39, wps=677.7, ups=0.27, wpb=2508.3, bsz=72, num_updates=1900, lr=2.92899e-05, gnorm=2.676, clip=100, loss_scale=128, train_wall=37, gb_free=4.9, wall=7084
2023-05-06 05:06:08 - progress_bar.py[line:272] - INFO: epoch 003:    373 / 770 loss=2.455, loss_v1=0, loss_v2=0, nll_loss=1.265, ntokens=2477.7, nsentences=72, sample_size=2477.7, sample_size_v1=0, sample_size_v2=0, ppl=2.4, wps=667.1, ups=0.27, wpb=2477.7, bsz=72, num_updates=1910, lr=2.9276e-05, gnorm=2.582, clip=100, loss_scale=128, train_wall=37, gb_free=5, wall=7121
2023-05-06 05:06:22 - trainer.py[line:1303] - WARNING: OOM: Ran out of memory with exception: CUDA out of memory. Tried to allocate 306.00 MiB (GPU 2; 23.69 GiB total capacity; 19.25 GiB already allocated; 25.69 MiB free; 21.90 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
2023-05-06 05:06:22 - trainer.py[line:1306] - WARNING: |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |       0 B  |       0 B  |       0 B  |       0 B  |
|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |
|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |
|---------------------------------------------------------------------------|
| Active memory         |       0 B  |       0 B  |       0 B  |       0 B  |
|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |
|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |
|---------------------------------------------------------------------------|
| GPU reserved memory   |       0 B  |       0 B  |       0 B  |       0 B  |
|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |
|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |
|---------------------------------------------------------------------------|
| Non-releasable memory |       0 B  |       0 B  |       0 B  |       0 B  |
|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |
|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |
|---------------------------------------------------------------------------|
| Allocations           |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Active allocs         |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

2023-05-06 05:06:22 - trainer.py[line:1306] - WARNING: |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 1                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |       0 B  |       0 B  |       0 B  |       0 B  |
|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |
|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |
|---------------------------------------------------------------------------|
| Active memory         |       0 B  |       0 B  |       0 B  |       0 B  |
|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |
|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |
|---------------------------------------------------------------------------|
| GPU reserved memory   |       0 B  |       0 B  |       0 B  |       0 B  |
|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |
|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |
|---------------------------------------------------------------------------|
| Non-releasable memory |       0 B  |       0 B  |       0 B  |       0 B  |
|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |
|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |
|---------------------------------------------------------------------------|
| Allocations           |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Active allocs         |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

2023-05-06 05:06:22 - trainer.py[line:1306] - WARNING: |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 2                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 1            |        cudaMalloc retries: 11        |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   19129 MB |   20522 MB |    1178 TB |    1178 TB |
|       from large pool |   19031 MB |   20281 MB |    1167 TB |    1167 TB |
|       from small pool |      97 MB |     242 MB |      10 TB |      10 TB |
|---------------------------------------------------------------------------|
| Active memory         |   19129 MB |   20522 MB |    1178 TB |    1178 TB |
|       from large pool |   19031 MB |   20281 MB |    1167 TB |    1167 TB |
|       from small pool |      97 MB |     242 MB |      10 TB |      10 TB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   22428 MB |   22428 MB |  251150 MB |  228722 MB |
|       from large pool |   22316 MB |   22316 MB |  247510 MB |  225194 MB |
|       from small pool |     112 MB |     274 MB |    3640 MB |    3528 MB |
|---------------------------------------------------------------------------|
| Non-releasable memory |    2724 MB |    5700 MB |    1127 TB |    1127 TB |
|       from large pool |    2710 MB |    5672 MB |    1116 TB |    1116 TB |
|       from small pool |      14 MB |      36 MB |      11 TB |      11 TB |
|---------------------------------------------------------------------------|
| Allocations           |    3815    |    4393    |  110643 K  |  110640 K  |
|       from large pool |    1018    |    1133    |   52775 K  |   52774 K  |
|       from small pool |    2797    |    3297    |   57868 K  |   57865 K  |
|---------------------------------------------------------------------------|
| Active allocs         |    3815    |    4393    |  110643 K  |  110640 K  |
|       from large pool |    1018    |    1133    |   52775 K  |   52774 K  |
|       from small pool |    2797    |    3297    |   57868 K  |   57865 K  |
|---------------------------------------------------------------------------|
| GPU reserved segments |     201    |     281    |    3630    |    3429    |
|       from large pool |     145    |     145    |    1810    |    1665    |
|       from small pool |      56    |     137    |    1820    |    1764    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |      59    |     224    |   49114 K  |   49113 K  |
|       from large pool |      37    |     104    |   24426 K  |   24426 K  |
|       from small pool |      22    |     130    |   24687 K  |   24687 K  |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

2023-05-06 05:06:22 - trainer.py[line:796] - WARNING: attempting to recover from OOM in forward/backward pass
[E ProcessGroupNCCL.cpp:737] [Rank 0] Watchdog caught collective operation timeout: WorkNCCL(SeqNum=63249, OpType=ALLREDUCE, Timeout(ms)=1800000) ran for 1804464 milliseconds before timing out.
[E ProcessGroupNCCL.cpp:737] [Rank 2] Watchdog caught collective operation timeout: WorkNCCL(SeqNum=63249, OpType=ALLREDUCE, Timeout(ms)=1800000) ran for 1804634 milliseconds before timing out.
[E ProcessGroupNCCL.cpp:737] [Rank 1] Watchdog caught collective operation timeout: WorkNCCL(SeqNum=63249, OpType=ALLREDUCE, Timeout(ms)=1800000) ran for 1804658 milliseconds before timing out.
[E ProcessGroupNCCL.cpp:414] Some NCCL operations have failed or timed out. Due to the asynchronous nature of CUDA kernels, subsequent GPU operations might run on corrupted/incomplete data. To avoid this inconsistency, we are taking the entire process down.
terminate called after throwing an instance of 'std::runtime_error'
Traceback (most recent call last):
  what():  [Rank 2] Watchdog caught collective operation timeout: WorkNCCL(SeqNum=63249, OpType=ALLREDUCE, Timeout(ms)=1800000) ran for 1804634 milliseconds before timing out.  File "../../train.py", line 539, in <module>

WARNING:torch.distributed.elastic.multiprocessing.api:Sending process 1367028 closing signal SIGTERM
WARNING:torch.distributed.elastic.multiprocessing.api:Sending process 1367029 closing signal SIGTERM
ERROR:torch.distributed.elastic.multiprocessing.api:failed (exitcode: -6) local_rank: 2 (pid: 1367030) of binary: /data/hulab/zcai75/anaconda3/envs/vilt/bin/python3
Traceback (most recent call last):
  File "/data/hulab/zcai75/anaconda3/envs/vilt/lib/python3.8/runpy.py", line 194, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File "/data/hulab/zcai75/anaconda3/envs/vilt/lib/python3.8/runpy.py", line 87, in _run_code
    exec(code, run_globals)
  File "/data/hulab/zcai75/anaconda3/envs/vilt/lib/python3.8/site-packages/torch/distributed/launch.py", line 193, in <module>
    main()
  File "/data/hulab/zcai75/anaconda3/envs/vilt/lib/python3.8/site-packages/torch/distributed/launch.py", line 189, in main
    launch(args)
  File "/data/hulab/zcai75/anaconda3/envs/vilt/lib/python3.8/site-packages/torch/distributed/launch.py", line 174, in launch
    run(args)
  File "/data/hulab/zcai75/anaconda3/envs/vilt/lib/python3.8/site-packages/torch/distributed/run.py", line 752, in run
    elastic_launch(
  File "/data/hulab/zcai75/anaconda3/envs/vilt/lib/python3.8/site-packages/torch/distributed/launcher/api.py", line 131, in __call__
    return launch_agent(self._config, self._entrypoint, list(args))
  File "/data/hulab/zcai75/anaconda3/envs/vilt/lib/python3.8/site-packages/torch/distributed/launcher/api.py", line 245, in launch_agent
    raise ChildFailedError(
torch.distributed.elastic.multiprocessing.errors.ChildFailedError: 
========================================================
../../train.py FAILED
--------------------------------------------------------
Failures:
  <NO_OTHER_FAILURES>
--------------------------------------------------------
Root Cause (first observed failure):
[0]:
  time      : 2023-05-06_05:36:33
  host      : AMD4RTX3090GPU14
  rank      : 2 (local_rank: 2)
  exitcode  : -6 (pid: 1367030)
  error_file: <N/A>
  traceback : Signal 6 (SIGABRT) received by PID 1367030
========================================================

2023-05-25 23:23:01 - utils.py[line:255] - INFO: distributed init (rank 0): env://
2023-05-25 23:23:01 - utils.py[line:261] - INFO: Start init
2023-05-25 23:23:01 - distributed_c10d.py[line:228] - INFO: Added key: store_based_barrier_key:1 to store for rank: 0
2023-05-25 23:23:01 - distributed_c10d.py[line:262] - INFO: Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 1 nodes.
2023-05-25 23:23:01 - utils.py[line:271] - INFO: initialized host AMD4RTX3090GPU14 as rank 0
single-machine distributed training is initialized.
2023-05-25 23:23:02 - train.py[line:77] - INFO: {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 10, 'log_format': 'simple', 'log_file': None, 'tensorboard_logdir': './tensorboard/_30_3e-5_512', 'wandb_project': 'OFA-VG', 'azureml_logging': False, 'seed': 1, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': True, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': 512, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': '../../ofa_module', 'empty_cache_freq': 0, 'all_gather_list_size': 2097152, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': 'env://', 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': True, 'ddp_backend': 'pytorch_ddp', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': True, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_algorithm': 'LocalSGD', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': True, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False}, 'dataset': {'_name': None, 'num_workers': 0, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': None, 'batch_size': 8, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 30, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': 7, 'disable_validation': False, 'max_tokens_valid': None, 'batch_size_valid': 8, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0}, 'optimization': {'_name': None, 'max_epoch': 30, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 1.0, 'sentence_avg': False, 'update_freq': [4], 'lr': [3e-05], 'stop_min_lr': -1.0, 'use_bmuf': False}, 'checkpoint': {'_name': None, 'save_dir': '../../checkpoints/OFA/sgcls_checkpoints/_30_3e-5_512_base_nosrcbbox', 'restore_file': '../../checkpoints/ofa_base.pt', 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 4, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': 1, 'no_save': False, 'no_epoch_checkpoints': False, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': True, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1, 'use_ema_weights_to_init_param': False, 'use_latest_weights_to_init_ema': False}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': Namespace(_name='ofa_base', activation_fn='gelu', adam_betas='(0.9,0.999)', adam_eps=1e-08, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, add_type_embedding=True, all_gather_list_size=2097152, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, arch='ofa_base', attention_dropout=0.0, attn_scale_factor=2, azureml_logging=False, batch_size=8, batch_size_valid=8, best_checkpoint_metric='loss', bf16=False, bitfit=False, bpe=None, bpe_dir='../../utils/BPE', broadcast_buffers=False, bucket_cap_mb=25, checkpoint_shard_count=1, checkpoint_suffix='', clip_norm=1.0, code_dict_size=8192, code_image_size=128, code_layernorm_embedding=True, combine_valid_subsets=None, constraint_range=None, cpu=False, cpu_offload=False, criterion='adjust_label_smoothed_cross_entropy', cross_self_attention=False, curriculum=0, data='../../dataset/OFA_data/sgcls/vg_train_full.tsv,../../dataset/OFA_data/sgcls/vg_val_full.tsv', data_buffer_size=10, dataset_impl=None, ddp_backend='pytorch_ddp', ddp_comm_hook='none', decoder_attention_heads=12, decoder_drop_path_rate=0.1, decoder_embed_dim=768, decoder_embed_path=None, decoder_ffn_embed_dim=3072, decoder_input_dim=768, decoder_layerdrop=0, decoder_layers=6, decoder_layers_to_keep=None, decoder_learned_pos=True, decoder_normalize_before=True, decoder_output_dim=768, device_id=0, disable_entangle=True, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_num_procs=1, distributed_port=-1, distributed_rank=0, distributed_world_size=1, drop_worst_after=0, drop_worst_ratio=0.0, dropout=0.1, ema_decay=0.9999, ema_fp32=False, ema_seed_model=None, ema_start_update=0, ema_update_freq=1, empty_cache_freq=0, encoder_attention_heads=12, encoder_drop_path_rate=0.1, encoder_embed_dim=768, encoder_embed_path=None, encoder_ffn_embed_dim=3072, encoder_layerdrop=0, encoder_layers=6, encoder_layers_to_keep=None, encoder_learned_pos=True, encoder_normalize_before=True, end_learning_rate=0.0, entangle_position_embedding=False, eos=2, eval_args='{"beam":5,"max_len_a":0,"max_len_b":200}', eval_print_samples=False, fast_stat_sync=False, find_unused_parameters=True, finetune_from_model=None, fix_batches_to_gpus=False, fixed_validation_seed=7, force_anneal=None, fp16=True, fp16_adam_stats=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=512, fp32_reduce_scatter=False, freeze_decoder_embedding=False, freeze_encoder_embedding=False, gen_subset='test', gradient_as_bucket_view=False, heartbeat_timeout=-1, ignore_eos=False, ignore_prefix_size=0, ignore_unused_valid_subsets=False, image_bucket_size=42, imagenet_default_mean_and_std=False, keep_best_checkpoints=1, keep_interval_updates=-1, keep_interval_updates_pattern=-1, keep_last_epochs=-1, label_smoothing=0.1, layernorm_embedding=True, load_checkpoint_on_all_dp_ranks=False, localsgd_frequency=3, log_file=None, log_format='simple', log_interval=10, lr=[3e-05], lr_scheduler='polynomial_decay', max_epoch=30, max_source_positions=1024, max_src_length=100, max_target_positions=1024, max_tgt_length=100, max_tokens=None, max_tokens_valid=None, max_update=0, max_valid_steps=None, maximize_best_checkpoint_metric=True, memory_efficient_bf16=False, memory_efficient_fp16=True, min_loss_scale=0.0001, min_params_to_wrap=100000000, model_parallel_size=1, no_cross_attention=False, no_epoch_checkpoints=False, no_last_checkpoints=False, no_progress_bar=False, no_reshard_after_forward=False, no_save=False, no_save_optimizer_state=False, no_scale_embedding=True, no_seed_provided=False, no_token_positional_embeddings=False, nprocs_per_node=1, num_bins=1000, num_shards=1, num_workers=0, on_cpu_convert_precision=False, optimizer='adam', optimizer_overrides='{}', orig_patch_image_size=256, pad=1, patch_image_size=512, patch_layernorm_embedding=True, patience=-1, pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, plasma_path='/tmp/plasma', pooler_activation_fn='tanh', pooler_classifier='mlp', pooler_dropout=0.0, power=1.0, profile=False, quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, quantization_config_path=None, reg_alpha=1.0, relu_dropout=0.0, report_accuracy=False, required_batch_size_multiple=8, required_seq_len_multiple=1, reset_dataloader=False, reset_logging=False, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, resnet_drop_path_rate=0.0, resnet_type='resnet101', restore_file='../../checkpoints/ofa_base.pt', sample_patch_num=196, save_dir='../../checkpoints/OFA/sgcls_checkpoints/_30_3e-5_512_base_nosrcbbox', save_interval=4, save_interval_updates=0, scale_attn=True, scale_fc=True, scale_heads=True, scale_resids=False, scoring='bleu', seed=1, selected_cols=None, sentence_avg=False, shard_id=0, share_all_embeddings=True, share_decoder_input_output_embed=True, simul_type=None, skip_invalid_size_inputs_valid_test=False, slowmo_algorithm='LocalSGD', slowmo_momentum=None, stop_min_lr=-1.0, stop_time_hours=0, store_ema=False, suppress_crashes=False, sync_bn=False, task='sgcls', tensorboard_logdir='./tensorboard/_30_3e-5_512', threshold_loss_scale=None, token_bucket_size=256, tokenizer=None, total_num_update=1000000, tpu=False, train_subset='train', unk=3, update_freq=[4], use_bmuf=False, use_ema_weights_to_init_param=False, use_latest_weights_to_init_ema=False, use_old_adam=False, use_plasma_view=False, use_rdrop=False, use_sharded_state=False, user_dir='../../ofa_module', valid_subset='valid', validate_after_updates=0, validate_interval=30, validate_interval_updates=0, vg_json_dir=None, wandb_project='OFA-VG', warmup_ratio=0.06, warmup_updates=0, weight_decay=0.01, write_checkpoints_asynchronously=False, zero_sharding='none'), 'task': {'_name': 'sgcls', 'data': '../../dataset/OFA_data/sgcls/vg_train_full.tsv,../../dataset/OFA_data/sgcls/vg_val_full.tsv', 'selected_cols': None, 'bpe': None, 'bpe_dir': '../../utils/BPE', 'max_source_positions': 1024, 'max_target_positions': 1024, 'max_src_length': 100, 'max_tgt_length': 100, 'code_dict_size': 8192, 'patch_image_size': 512, 'orig_patch_image_size': 256, 'num_bins': 1000, 'imagenet_default_mean_and_std': False, 'constraint_range': None, 'eval_args': '{"beam":5,"max_len_a":0,"max_len_b":200}', 'eval_print_samples': False, 'vg_json_dir': None}, 'criterion': {'_name': 'adjust_label_smoothed_cross_entropy', 'label_smoothing': 0.1, 'report_accuracy': False, 'ignore_prefix_size': 0, 'ignore_eos': False, 'sentence_avg': False, 'drop_worst_ratio': 0.0, 'drop_worst_after': 0, 'use_rdrop': False, 'reg_alpha': 1.0, 'sample_patch_num': 196, 'constraint_range': None}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9,0.999)', 'adam_eps': 1e-08, 'weight_decay': 0.01, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': False, 'lr': [3e-05]}, 'lr_scheduler': {'_name': 'polynomial_decay', 'warmup_updates': 0, 'warmup_ratio': 0.06, 'force_anneal': None, 'end_learning_rate': 0.0, 'power': 1.0, 'total_num_update': 1000000.0, 'lr': [3e-05]}, 'scoring': {'_name': 'bleu', 'pad': 1, 'eos': 2, 'unk': 3}, 'bpe': None, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}, 'simul_type': None}
2023-05-25 23:23:02 - sg_cls.py[line:82] - INFO: sgcls setup: source dictionary: 51267 types
2023-05-25 23:23:02 - sg_cls.py[line:83] - INFO: sgcls setup: target dictionary: 51267 types
/data/hulab/zcai75/anaconda3/envs/vilt/lib/python3.8/site-packages/torch/functional.py:478: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at  ../aten/src/ATen/native/TensorShape.cpp:2894.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
2023-05-25 23:23:05 - train.py[line:110] - INFO: OFAModel(
  (encoder): TransformerEncoder(
    (encoder_dropout): Dropout(p=0.2, inplace=False)
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(51267, 768, padding_idx=1)
    (layernorm_embedding): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (type_embedding): Embedding(2, 768)
    (embed_images): ResNet(
      (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)
      (layer1): Sequential(
        (0): Bottleneck(
          (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (downsample): Sequential(
            (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (drop_path): Identity()
        )
        (1): Bottleneck(
          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (2): Bottleneck(
          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
      )
      (layer2): Sequential(
        (0): Bottleneck(
          (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (downsample): Sequential(
            (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
            (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (drop_path): Identity()
        )
        (1): Bottleneck(
          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (2): Bottleneck(
          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (3): Bottleneck(
          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
      )
      (layer3): Sequential(
        (0): Bottleneck(
          (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (downsample): Sequential(
            (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)
            (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (drop_path): Identity()
        )
        (1): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (2): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (3): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (4): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (5): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (6): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (7): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (8): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (9): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (10): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (11): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (12): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (13): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (14): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (15): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (16): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (17): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (18): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (19): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (20): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (21): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (22): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
      )
    )
    (image_proj): Linear(in_features=1024, out_features=768, bias=True)
    (patch_layernorm_embedding): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (embed_positions): Embedding(1026, 768)
    (embed_image_positions): Embedding(1765, 768)
    (pos_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (image_pos_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (pos_q_linear): Linear(in_features=768, out_features=768, bias=True)
    (pos_k_linear): Linear(in_features=768, out_features=768, bias=True)
    (layers): ModuleList(
      (0): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): Identity()
      )
      (1): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(p=0.019999999552965164)
      )
      (2): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(p=0.03999999910593033)
      )
      (3): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(p=0.06000000238418579)
      )
      (4): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(p=0.07999999821186066)
      )
      (5): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(p=0.10000000149011612)
      )
    )
    (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (token_rel_pos_table_list): ModuleList(
      (0): Embedding(511, 12)
      (1): Embedding(511, 12)
      (2): Embedding(511, 12)
      (3): Embedding(511, 12)
      (4): Embedding(511, 12)
      (5): Embedding(511, 12)
    )
    (image_rel_pos_table_list): ModuleList(
      (0): Embedding(6892, 12)
      (1): Embedding(6892, 12)
      (2): Embedding(6892, 12)
      (3): Embedding(6892, 12)
      (4): Embedding(6892, 12)
      (5): Embedding(6892, 12)
    )
  )
  (decoder): TransformerDecoder(
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(51267, 768, padding_idx=1)
    (layernorm_embedding): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (embed_positions): Embedding(1026, 768)
    (embed_image_positions): Embedding(1765, 768)
    (pos_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (image_pos_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (self_pos_q_linear): Linear(in_features=768, out_features=768, bias=True)
    (self_pos_k_linear): Linear(in_features=768, out_features=768, bias=True)
    (cross_pos_q_linear): Linear(in_features=768, out_features=768, bias=True)
    (cross_pos_k_linear): Linear(in_features=768, out_features=768, bias=True)
    (code_layernorm_embedding): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (layers): ModuleList(
      (0): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (cross_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): Identity()
      )
      (1): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (cross_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(p=0.019999999552965164)
      )
      (2): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (cross_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(p=0.03999999910593033)
      )
      (3): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (cross_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(p=0.06000000238418579)
      )
      (4): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (cross_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(p=0.07999999821186066)
      )
      (5): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (cross_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(p=0.10000000149011612)
      )
    )
    (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (output_projection): Linear(in_features=768, out_features=51267, bias=False)
    (token_rel_pos_table_list): ModuleList(
      (0): Embedding(511, 12)
      (1): Embedding(511, 12)
      (2): Embedding(511, 12)
      (3): Embedding(511, 12)
      (4): Embedding(511, 12)
      (5): Embedding(511, 12)
    )
    (image_rel_pos_table_list): ModuleList(
      (0): Embedding(6892, 12)
      (1): Embedding(6892, 12)
      (2): Embedding(6892, 12)
      (3): Embedding(6892, 12)
      (4): Embedding(6892, 12)
      (5): Embedding(6892, 12)
    )
  )
  (classification_heads): ModuleDict()
)
2023-05-25 23:23:05 - train.py[line:111] - INFO: task: SGClsTask
2023-05-25 23:23:05 - train.py[line:112] - INFO: model: OFAModel
2023-05-25 23:23:05 - train.py[line:113] - INFO: criterion: AdjustLabelSmoothedCrossEntropyCriterion
2023-05-25 23:23:05 - train.py[line:114] - INFO: num. shared model params: 175,948,616 (num. trained: 175,948,616)
2023-05-25 23:23:05 - train.py[line:121] - INFO: num. expert model params: 0 (num. trained: 0)
local datafile ../../dataset/OFA_data/sgcls/vg_val_full.tsv slice_id 0 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../dataset/OFA_data/sgcls/vg_val_full.tsv slice_id 0 finished initializing row_count and line_idx-to-offset mapping
file ../../dataset/OFA_data/sgcls/vg_val_full.tsv slice_id 0 row count 22880 total row count 22880
/data/hulab/zcai75/anaconda3/envs/vilt/lib/python3.8/site-packages/torchvision/transforms/transforms.py:332: UserWarning: Argument 'interpolation' of type int is deprecated since 0.13 and will be removed in 0.15. Please use InterpolationMode enum.
  warnings.warn(
2023-05-25 23:23:05 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_tokens.weight <- decoder.embed_tokens.weight
2023-05-25 23:23:05 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_tokens.weight <- decoder.output_projection.weight
2023-05-25 23:23:05 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer1.0.conv1.bias
2023-05-25 23:23:05 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer1.0.conv2.bias
2023-05-25 23:23:05 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer1.0.conv3.bias
2023-05-25 23:23:05 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer1.0.downsample.0.bias
2023-05-25 23:23:05 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer1.1.conv1.bias
2023-05-25 23:23:05 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer1.1.conv2.bias
2023-05-25 23:23:05 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer1.1.conv3.bias
2023-05-25 23:23:05 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer1.2.conv1.bias
2023-05-25 23:23:05 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer1.2.conv2.bias
2023-05-25 23:23:05 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer1.2.conv3.bias
2023-05-25 23:23:05 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.0.conv1.bias
2023-05-25 23:23:05 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.0.conv2.bias
2023-05-25 23:23:05 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.0.conv3.bias
2023-05-25 23:23:05 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.0.downsample.0.bias
2023-05-25 23:23:05 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.1.conv1.bias
2023-05-25 23:23:05 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.1.conv2.bias
2023-05-25 23:23:05 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.1.conv3.bias
2023-05-25 23:23:05 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.2.conv1.bias
2023-05-25 23:23:05 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.2.conv2.bias
2023-05-25 23:23:05 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.2.conv3.bias
2023-05-25 23:23:05 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.3.conv1.bias
2023-05-25 23:23:05 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.3.conv2.bias
2023-05-25 23:23:05 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.3.conv3.bias
2023-05-25 23:23:05 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.0.conv1.bias
2023-05-25 23:23:05 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.0.conv2.bias
2023-05-25 23:23:05 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.0.conv3.bias
2023-05-25 23:23:05 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.0.downsample.0.bias
2023-05-25 23:23:05 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.1.conv1.bias
2023-05-25 23:23:05 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.1.conv2.bias
2023-05-25 23:23:05 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.1.conv3.bias
2023-05-25 23:23:05 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.2.conv1.bias
2023-05-25 23:23:05 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.2.conv2.bias
2023-05-25 23:23:05 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.2.conv3.bias
2023-05-25 23:23:05 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.3.conv1.bias
2023-05-25 23:23:05 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.3.conv2.bias
2023-05-25 23:23:05 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.3.conv3.bias
2023-05-25 23:23:05 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.4.conv1.bias
2023-05-25 23:23:05 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.4.conv2.bias
2023-05-25 23:23:05 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.4.conv3.bias
2023-05-25 23:23:05 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.5.conv1.bias
2023-05-25 23:23:05 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.5.conv2.bias
2023-05-25 23:23:05 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.5.conv3.bias
2023-05-25 23:23:05 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.6.conv1.bias
2023-05-25 23:23:05 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.6.conv2.bias
2023-05-25 23:23:05 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.6.conv3.bias
2023-05-25 23:23:05 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.7.conv1.bias
2023-05-25 23:23:05 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.7.conv2.bias
2023-05-25 23:23:05 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.7.conv3.bias
2023-05-25 23:23:05 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.8.conv1.bias
2023-05-25 23:23:05 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.8.conv2.bias
2023-05-25 23:23:05 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.8.conv3.bias
2023-05-25 23:23:05 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.9.conv1.bias
2023-05-25 23:23:05 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.9.conv2.bias
2023-05-25 23:23:05 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.9.conv3.bias
2023-05-25 23:23:05 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.10.conv1.bias
2023-05-25 23:23:05 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.10.conv2.bias
2023-05-25 23:23:05 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.10.conv3.bias
2023-05-25 23:23:05 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.11.conv1.bias
2023-05-25 23:23:05 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.11.conv2.bias
2023-05-25 23:23:05 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.11.conv3.bias
2023-05-25 23:23:05 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.12.conv1.bias
2023-05-25 23:23:05 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.12.conv2.bias
2023-05-25 23:23:05 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.12.conv3.bias
2023-05-25 23:23:05 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.13.conv1.bias
2023-05-25 23:23:05 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.13.conv2.bias
2023-05-25 23:23:05 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.13.conv3.bias
2023-05-25 23:23:05 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.14.conv1.bias
2023-05-25 23:23:05 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.14.conv2.bias
2023-05-25 23:23:05 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.14.conv3.bias
2023-05-25 23:23:05 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.15.conv1.bias
2023-05-25 23:23:05 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.15.conv2.bias
2023-05-25 23:23:05 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.15.conv3.bias
2023-05-25 23:23:05 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.16.conv1.bias
2023-05-25 23:23:05 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.16.conv2.bias
2023-05-25 23:23:05 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.16.conv3.bias
2023-05-25 23:23:05 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.17.conv1.bias
2023-05-25 23:23:05 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.17.conv2.bias
2023-05-25 23:23:05 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.17.conv3.bias
2023-05-25 23:23:05 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.18.conv1.bias
2023-05-25 23:23:05 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.18.conv2.bias
2023-05-25 23:23:05 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.18.conv3.bias
2023-05-25 23:23:05 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.19.conv1.bias
2023-05-25 23:23:05 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.19.conv2.bias
2023-05-25 23:23:05 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.19.conv3.bias
2023-05-25 23:23:05 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.20.conv1.bias
2023-05-25 23:23:05 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.20.conv2.bias
2023-05-25 23:23:05 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.20.conv3.bias
2023-05-25 23:23:05 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.21.conv1.bias
2023-05-25 23:23:05 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.21.conv2.bias
2023-05-25 23:23:05 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.21.conv3.bias
2023-05-25 23:23:05 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.22.conv1.bias
2023-05-25 23:23:05 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.22.conv2.bias
2023-05-25 23:23:05 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.22.conv3.bias
2023-05-25 23:23:05 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- decoder.output_projection.bias
2023-05-25 23:23:05 - utils.py[line:759] - INFO: ***********************CUDA enviroments for all 1 workers***********************
2023-05-25 23:23:05 - utils.py[line:761] - INFO: rank   0: capabilities =  8.6  ; total memory = 23.688 GB ; name = NVIDIA GeForce RTX 3090 Ti              
2023-05-25 23:23:05 - utils.py[line:767] - INFO: ***********************CUDA enviroments for all 1 workers***********************
2023-05-25 23:23:05 - train.py[line:152] - INFO: training on 1 devices (GPUs/TPUs)
2023-05-25 23:23:05 - train.py[line:157] - INFO: max tokens per device = None and max sentences per device = 8
2023-05-25 23:23:05 - trainer.py[line:458] - INFO: Preparing to load checkpoint ../../checkpoints/ofa_base.pt
2023-05-25 23:23:05 - trainer.py[line:624] - INFO: No existing checkpoint found ../../checkpoints/ofa_base.pt
2023-05-25 23:23:05 - trainer.py[line:639] - INFO: loading train data for epoch 1
local datafile ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 0 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 0 finished initializing row_count and line_idx-to-offset mapping
file ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 0 row count 55400 total row count 55400
slice_id 0 seek offset 0
Total steps 51960, warmup steps 3117, warmup_factor 0.0003208213025344883
wandb: Currently logged in as: jackcai1206. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.15.3 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /home/zcai75/Github/OFA_forked/run_scripts/sgcls/wandb/run-20230525_232308-kx739tj6
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run _30_3e-5_512_base_nosrcbbox
wandb: ⭐️ View project at https://wandb.ai/jackcai1206/OFA-VG
wandb: 🚀 View run at https://wandb.ai/jackcai1206/OFA-VG/runs/kx739tj6
2023-05-25 23:23:14 - trainer.py[line:703] - INFO: begin training epoch 1
2023-05-25 23:23:14 - train.py[line:305] - INFO: Start iterating over samples
/home/zcai75/Github/OFA/fairseq/fairseq/utils.py:372: UserWarning: amp_C fused kernels unavailable, disabling multi_tensor_l2norm; you may get better performance by installing NVIDIA's apex library
  warnings.warn(
2023-05-25 23:23:18 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2023-05-25 23:23:37 - progress_bar.py[line:272] - INFO: epoch 001:     11 / 1732 loss=11.25, loss_v1=0, loss_v2=0, nll_loss=11.278, ntokens=1109.8, nsentences=32, sample_size=1109.8, sample_size_v1=0, sample_size_v2=0, ppl=2482.87, wps=567.5, ups=0.53, wpb=1109.8, bsz=32, num_updates=10, lr=9.62464e-08, gnorm=20.567, clip=100, loss_scale=64, train_wall=23, gb_free=11.4, wall=32
2023-05-25 23:23:56 - progress_bar.py[line:272] - INFO: epoch 001:     21 / 1732 loss=11.246, loss_v1=0, loss_v2=0, nll_loss=11.273, ntokens=1106.8, nsentences=32, sample_size=1106.8, sample_size_v1=0, sample_size_v2=0, ppl=2475.31, wps=590.1, ups=0.53, wpb=1106.8, bsz=32, num_updates=20, lr=1.92493e-07, gnorm=21.147, clip=100, loss_scale=64, train_wall=19, gb_free=11.2, wall=51
2023-05-25 23:24:15 - progress_bar.py[line:272] - INFO: epoch 001:     31 / 1732 loss=11.253, loss_v1=0, loss_v2=0, nll_loss=11.281, ntokens=958.4, nsentences=32, sample_size=958.4, sample_size_v1=0, sample_size_v2=0, ppl=2488.42, wps=511.7, ups=0.53, wpb=958.4, bsz=32, num_updates=30, lr=2.88739e-07, gnorm=20.552, clip=100, loss_scale=64, train_wall=19, gb_free=11.1, wall=70
2023-05-25 23:24:34 - progress_bar.py[line:272] - INFO: epoch 001:     41 / 1732 loss=11.262, loss_v1=0, loss_v2=0, nll_loss=11.291, ntokens=1207.2, nsentences=32, sample_size=1207.2, sample_size_v1=0, sample_size_v2=0, ppl=2505.64, wps=633.1, ups=0.52, wpb=1207.2, bsz=32, num_updates=40, lr=3.84986e-07, gnorm=21.2, clip=100, loss_scale=64, train_wall=19, gb_free=10.9, wall=89
2023-05-25 23:24:53 - progress_bar.py[line:272] - INFO: epoch 001:     51 / 1732 loss=11.236, loss_v1=0, loss_v2=0, nll_loss=11.262, ntokens=1028.6, nsentences=32, sample_size=1028.6, sample_size_v1=0, sample_size_v2=0, ppl=2455.85, wps=546, ups=0.53, wpb=1028.6, bsz=32, num_updates=50, lr=4.81232e-07, gnorm=20.939, clip=100, loss_scale=64, train_wall=19, gb_free=11.2, wall=108
2023-05-25 23:25:12 - progress_bar.py[line:272] - INFO: epoch 001:     61 / 1732 loss=11.197, loss_v1=0, loss_v2=0, nll_loss=11.219, ntokens=1123.9, nsentences=32, sample_size=1123.9, sample_size_v1=0, sample_size_v2=0, ppl=2383.88, wps=598.7, ups=0.53, wpb=1123.9, bsz=32, num_updates=60, lr=5.77478e-07, gnorm=22.534, clip=100, loss_scale=64, train_wall=19, gb_free=10.2, wall=126
2023-05-25 23:25:25 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2023-05-25 23:25:33 - progress_bar.py[line:272] - INFO: epoch 001:     72 / 1732 loss=11.156, loss_v1=0, loss_v2=0, nll_loss=11.173, ntokens=1392.3, nsentences=32, sample_size=1392.3, sample_size_v1=0, sample_size_v2=0, ppl=2309.28, wps=646, ups=0.46, wpb=1392.3, bsz=32, num_updates=70, lr=6.73725e-07, gnorm=21.604, clip=100, loss_scale=32, train_wall=22, gb_free=10.7, wall=148
2023-05-25 23:25:52 - progress_bar.py[line:272] - INFO: epoch 001:     82 / 1732 loss=11.113, loss_v1=0, loss_v2=0, nll_loss=11.125, ntokens=1199, nsentences=32, sample_size=1199, sample_size_v1=0, sample_size_v2=0, ppl=2233.59, wps=621.9, ups=0.52, wpb=1199, bsz=32, num_updates=80, lr=7.69971e-07, gnorm=21.769, clip=100, loss_scale=32, train_wall=19, gb_free=10.8, wall=167
2023-05-25 23:26:12 - progress_bar.py[line:272] - INFO: epoch 001:     92 / 1732 loss=11.047, loss_v1=0, loss_v2=0, nll_loss=11.053, ntokens=1081.9, nsentences=32, sample_size=1081.9, sample_size_v1=0, sample_size_v2=0, ppl=2124.26, wps=568, ups=0.53, wpb=1081.9, bsz=32, num_updates=90, lr=8.66218e-07, gnorm=21.717, clip=100, loss_scale=32, train_wall=19, gb_free=11.1, wall=186
2023-05-25 23:26:30 - progress_bar.py[line:272] - INFO: epoch 001:    102 / 1732 loss=10.991, loss_v1=0, loss_v2=0, nll_loss=10.99, ntokens=1017.7, nsentences=32, sample_size=1017.7, sample_size_v1=0, sample_size_v2=0, ppl=2034.38, wps=543.2, ups=0.53, wpb=1017.7, bsz=32, num_updates=100, lr=9.62464e-07, gnorm=21.318, clip=100, loss_scale=32, train_wall=19, gb_free=11, wall=205
2023-05-25 23:26:49 - progress_bar.py[line:272] - INFO: epoch 001:    112 / 1732 loss=10.881, loss_v1=0, loss_v2=0, nll_loss=10.868, ntokens=1026.3, nsentences=32, sample_size=1026.3, sample_size_v1=0, sample_size_v2=0, ppl=1869.01, wps=545.1, ups=0.53, wpb=1026.3, bsz=32, num_updates=110, lr=1.05871e-06, gnorm=20.801, clip=100, loss_scale=32, train_wall=19, gb_free=10.2, wall=224
2023-05-25 23:27:08 - progress_bar.py[line:272] - INFO: epoch 001:    122 / 1732 loss=10.75, loss_v1=0, loss_v2=0, nll_loss=10.722, ntokens=1103.7, nsentences=32, sample_size=1103.7, sample_size_v1=0, sample_size_v2=0, ppl=1689.57, wps=577.1, ups=0.52, wpb=1103.7, bsz=32, num_updates=120, lr=1.15496e-06, gnorm=20.818, clip=100, loss_scale=32, train_wall=19, gb_free=10.8, wall=243
2023-05-25 23:27:27 - progress_bar.py[line:272] - INFO: epoch 001:    132 / 1732 loss=10.566, loss_v1=0, loss_v2=0, nll_loss=10.517, ntokens=1224.5, nsentences=32, sample_size=1224.5, sample_size_v1=0, sample_size_v2=0, ppl=1465.63, wps=637.9, ups=0.52, wpb=1224.5, bsz=32, num_updates=130, lr=1.2512e-06, gnorm=20.695, clip=100, loss_scale=32, train_wall=19, gb_free=10.7, wall=262
2023-05-25 23:27:47 - progress_bar.py[line:272] - INFO: epoch 001:    142 / 1732 loss=10.36, loss_v1=0, loss_v2=0, nll_loss=10.289, ntokens=1223.2, nsentences=32, sample_size=1223.2, sample_size_v1=0, sample_size_v2=0, ppl=1250.83, wps=639, ups=0.52, wpb=1223.2, bsz=32, num_updates=140, lr=1.34745e-06, gnorm=20.532, clip=100, loss_scale=32, train_wall=19, gb_free=10.8, wall=281
2023-05-25 23:28:06 - progress_bar.py[line:272] - INFO: epoch 001:    152 / 1732 loss=10.134, loss_v1=0, loss_v2=0, nll_loss=10.038, ntokens=1158.5, nsentences=32, sample_size=1158.5, sample_size_v1=0, sample_size_v2=0, ppl=1051.04, wps=601.9, ups=0.52, wpb=1158.5, bsz=32, num_updates=150, lr=1.4437e-06, gnorm=20.247, clip=100, loss_scale=32, train_wall=19, gb_free=10.7, wall=301
2023-05-25 23:28:25 - progress_bar.py[line:272] - INFO: epoch 001:    162 / 1732 loss=9.857, loss_v1=0, loss_v2=0, nll_loss=9.729, ntokens=1101.3, nsentences=32, sample_size=1101.3, sample_size_v1=0, sample_size_v2=0, ppl=848.92, wps=578.1, ups=0.52, wpb=1101.3, bsz=32, num_updates=160, lr=1.53994e-06, gnorm=19.201, clip=100, loss_scale=32, train_wall=19, gb_free=11, wall=320
2023-05-25 23:28:44 - progress_bar.py[line:272] - INFO: epoch 001:    172 / 1732 loss=9.543, loss_v1=0, loss_v2=0, nll_loss=9.381, ntokens=937.9, nsentences=32, sample_size=937.9, sample_size_v1=0, sample_size_v2=0, ppl=666.72, wps=499, ups=0.53, wpb=937.9, bsz=32, num_updates=170, lr=1.63619e-06, gnorm=17.813, clip=100, loss_scale=32, train_wall=19, gb_free=11.2, wall=338
2023-05-25 23:29:03 - progress_bar.py[line:272] - INFO: epoch 001:    182 / 1732 loss=9.189, loss_v1=0, loss_v2=0, nll_loss=8.987, ntokens=1177.8, nsentences=32, sample_size=1177.8, sample_size_v1=0, sample_size_v2=0, ppl=507.45, wps=615.2, ups=0.52, wpb=1177.8, bsz=32, num_updates=180, lr=1.73244e-06, gnorm=15.753, clip=100, loss_scale=32, train_wall=19, gb_free=10.6, wall=358
2023-05-25 23:29:22 - progress_bar.py[line:272] - INFO: epoch 001:    192 / 1732 loss=8.929, loss_v1=0, loss_v2=0, nll_loss=8.697, ntokens=1116, nsentences=32, sample_size=1116, sample_size_v1=0, sample_size_v2=0, ppl=415.12, wps=586.1, ups=0.53, wpb=1116, bsz=32, num_updates=190, lr=1.82868e-06, gnorm=13.741, clip=100, loss_scale=32, train_wall=19, gb_free=10.6, wall=377
2023-05-25 23:29:41 - progress_bar.py[line:272] - INFO: epoch 001:    202 / 1732 loss=8.608, loss_v1=0, loss_v2=0, nll_loss=8.34, ntokens=1088.7, nsentences=32, sample_size=1088.7, sample_size_v1=0, sample_size_v2=0, ppl=323.99, wps=577.5, ups=0.53, wpb=1088.7, bsz=32, num_updates=200, lr=1.92493e-06, gnorm=12.318, clip=100, loss_scale=32, train_wall=19, gb_free=10.7, wall=395
2023-05-25 23:29:59 - progress_bar.py[line:272] - INFO: epoch 001:    212 / 1732 loss=8.346, loss_v1=0, loss_v2=0, nll_loss=8.048, ntokens=1014.1, nsentences=32, sample_size=1014.1, sample_size_v1=0, sample_size_v2=0, ppl=264.59, wps=542.3, ups=0.53, wpb=1014.1, bsz=32, num_updates=210, lr=2.02117e-06, gnorm=10.567, clip=100, loss_scale=32, train_wall=19, gb_free=11, wall=414
2023-05-25 23:30:18 - progress_bar.py[line:272] - INFO: epoch 001:    222 / 1732 loss=8.125, loss_v1=0, loss_v2=0, nll_loss=7.8, ntokens=1144.1, nsentences=32, sample_size=1144.1, sample_size_v1=0, sample_size_v2=0, ppl=222.93, wps=611.8, ups=0.53, wpb=1144.1, bsz=32, num_updates=220, lr=2.11742e-06, gnorm=9.674, clip=100, loss_scale=32, train_wall=19, gb_free=10.8, wall=433
2023-05-25 23:30:37 - progress_bar.py[line:272] - INFO: epoch 001:    232 / 1732 loss=7.955, loss_v1=0, loss_v2=0, nll_loss=7.609, ntokens=1097.8, nsentences=32, sample_size=1097.8, sample_size_v1=0, sample_size_v2=0, ppl=195.21, wps=583.3, ups=0.53, wpb=1097.8, bsz=32, num_updates=230, lr=2.21367e-06, gnorm=8.676, clip=100, loss_scale=32, train_wall=19, gb_free=11.3, wall=452
2023-05-25 23:30:56 - progress_bar.py[line:272] - INFO: epoch 001:    242 / 1732 loss=7.778, loss_v1=0, loss_v2=0, nll_loss=7.411, ntokens=1115.1, nsentences=32, sample_size=1115.1, sample_size_v1=0, sample_size_v2=0, ppl=170.24, wps=590.4, ups=0.53, wpb=1115.1, bsz=32, num_updates=240, lr=2.30991e-06, gnorm=8.118, clip=100, loss_scale=32, train_wall=19, gb_free=10.8, wall=471
2023-05-25 23:31:15 - progress_bar.py[line:272] - INFO: epoch 001:    252 / 1732 loss=7.666, loss_v1=0, loss_v2=0, nll_loss=7.284, ntokens=1167.7, nsentences=32, sample_size=1167.7, sample_size_v1=0, sample_size_v2=0, ppl=155.88, wps=620.4, ups=0.53, wpb=1167.7, bsz=32, num_updates=250, lr=2.40616e-06, gnorm=7.679, clip=100, loss_scale=32, train_wall=19, gb_free=11.5, wall=489
2023-05-25 23:31:33 - progress_bar.py[line:272] - INFO: epoch 001:    262 / 1732 loss=7.513, loss_v1=0, loss_v2=0, nll_loss=7.113, ntokens=1134.1, nsentences=32, sample_size=1134.1, sample_size_v1=0, sample_size_v2=0, ppl=138.46, wps=606.8, ups=0.54, wpb=1134.1, bsz=32, num_updates=260, lr=2.50241e-06, gnorm=7.196, clip=100, loss_scale=32, train_wall=19, gb_free=11.3, wall=508
2023-05-25 23:31:52 - progress_bar.py[line:272] - INFO: epoch 001:    272 / 1732 loss=7.451, loss_v1=0, loss_v2=0, nll_loss=7.044, ntokens=1139, nsentences=32, sample_size=1139, sample_size_v1=0, sample_size_v2=0, ppl=131.93, wps=605.1, ups=0.53, wpb=1139, bsz=32, num_updates=270, lr=2.59865e-06, gnorm=6.961, clip=100, loss_scale=32, train_wall=19, gb_free=11.6, wall=527
2023-05-25 23:32:11 - progress_bar.py[line:272] - INFO: epoch 001:    282 / 1732 loss=7.352, loss_v1=0, loss_v2=0, nll_loss=6.932, ntokens=1161.5, nsentences=32, sample_size=1161.5, sample_size_v1=0, sample_size_v2=0, ppl=122.13, wps=614, ups=0.53, wpb=1161.5, bsz=32, num_updates=280, lr=2.6949e-06, gnorm=6.602, clip=100, loss_scale=32, train_wall=19, gb_free=10.7, wall=546
2023-05-25 23:32:30 - progress_bar.py[line:272] - INFO: epoch 001:    292 / 1732 loss=7.286, loss_v1=0, loss_v2=0, nll_loss=6.858, ntokens=1114.9, nsentences=32, sample_size=1114.9, sample_size_v1=0, sample_size_v2=0, ppl=115.98, wps=595.4, ups=0.53, wpb=1114.9, bsz=32, num_updates=290, lr=2.79115e-06, gnorm=6.347, clip=100, loss_scale=32, train_wall=19, gb_free=11.2, wall=565
2023-05-25 23:32:49 - progress_bar.py[line:272] - INFO: epoch 001:    302 / 1732 loss=7.225, loss_v1=0, loss_v2=0, nll_loss=6.789, ntokens=1109.4, nsentences=32, sample_size=1109.4, sample_size_v1=0, sample_size_v2=0, ppl=110.59, wps=589.8, ups=0.53, wpb=1109.4, bsz=32, num_updates=300, lr=2.88739e-06, gnorm=6.266, clip=100, loss_scale=32, train_wall=19, gb_free=11.5, wall=583
2023-05-25 23:33:07 - progress_bar.py[line:272] - INFO: epoch 001:    312 / 1732 loss=7.139, loss_v1=0, loss_v2=0, nll_loss=6.694, ntokens=1061.9, nsentences=32, sample_size=1061.9, sample_size_v1=0, sample_size_v2=0, ppl=103.52, wps=568.6, ups=0.54, wpb=1061.9, bsz=32, num_updates=310, lr=2.98364e-06, gnorm=6.036, clip=100, loss_scale=32, train_wall=19, gb_free=11.5, wall=602
2023-05-25 23:33:26 - progress_bar.py[line:272] - INFO: epoch 001:    322 / 1732 loss=7.111, loss_v1=0, loss_v2=0, nll_loss=6.662, ntokens=1000.1, nsentences=32, sample_size=1000.1, sample_size_v1=0, sample_size_v2=0, ppl=101.26, wps=539.2, ups=0.54, wpb=1000.1, bsz=32, num_updates=320, lr=3.07988e-06, gnorm=5.921, clip=100, loss_scale=32, train_wall=19, gb_free=11.3, wall=621
2023-05-25 23:33:45 - progress_bar.py[line:272] - INFO: epoch 001:    332 / 1732 loss=6.985, loss_v1=0, loss_v2=0, nll_loss=6.521, ntokens=1031.9, nsentences=32, sample_size=1031.9, sample_size_v1=0, sample_size_v2=0, ppl=91.86, wps=554.4, ups=0.54, wpb=1031.9, bsz=32, num_updates=330, lr=3.17613e-06, gnorm=5.713, clip=100, loss_scale=32, train_wall=19, gb_free=11.2, wall=639
2023-05-25 23:34:03 - progress_bar.py[line:272] - INFO: epoch 001:    342 / 1732 loss=6.957, loss_v1=0, loss_v2=0, nll_loss=6.49, ntokens=926.6, nsentences=32, sample_size=926.6, sample_size_v1=0, sample_size_v2=0, ppl=89.86, wps=501, ups=0.54, wpb=926.6, bsz=32, num_updates=340, lr=3.27238e-06, gnorm=5.681, clip=100, loss_scale=32, train_wall=18, gb_free=11.8, wall=658
2023-05-25 23:34:22 - progress_bar.py[line:272] - INFO: epoch 001:    352 / 1732 loss=6.868, loss_v1=0, loss_v2=0, nll_loss=6.391, ntokens=952.9, nsentences=32, sample_size=952.9, sample_size_v1=0, sample_size_v2=0, ppl=83.91, wps=514.5, ups=0.54, wpb=952.9, bsz=32, num_updates=350, lr=3.36862e-06, gnorm=5.607, clip=100, loss_scale=32, train_wall=18, gb_free=11.8, wall=676
2023-05-25 23:34:40 - progress_bar.py[line:272] - INFO: epoch 001:    362 / 1732 loss=6.814, loss_v1=0, loss_v2=0, nll_loss=6.329, ntokens=940.7, nsentences=32, sample_size=940.7, sample_size_v1=0, sample_size_v2=0, ppl=80.41, wps=507.7, ups=0.54, wpb=940.7, bsz=32, num_updates=360, lr=3.46487e-06, gnorm=5.495, clip=100, loss_scale=32, train_wall=18, gb_free=11.6, wall=695
2023-05-25 23:34:59 - progress_bar.py[line:272] - INFO: epoch 001:    372 / 1732 loss=6.722, loss_v1=0, loss_v2=0, nll_loss=6.227, ntokens=975.5, nsentences=32, sample_size=975.5, sample_size_v1=0, sample_size_v2=0, ppl=74.89, wps=526.9, ups=0.54, wpb=975.5, bsz=32, num_updates=370, lr=3.56112e-06, gnorm=5.433, clip=100, loss_scale=32, train_wall=18, gb_free=11.7, wall=713
2023-05-25 23:35:17 - progress_bar.py[line:272] - INFO: epoch 001:    382 / 1732 loss=6.623, loss_v1=0, loss_v2=0, nll_loss=6.116, ntokens=1062, nsentences=32, sample_size=1062, sample_size_v1=0, sample_size_v2=0, ppl=69.35, wps=566.9, ups=0.53, wpb=1062, bsz=32, num_updates=380, lr=3.65736e-06, gnorm=5.25, clip=100, loss_scale=32, train_wall=19, gb_free=11.2, wall=732
2023-05-25 23:35:36 - progress_bar.py[line:272] - INFO: epoch 001:    392 / 1732 loss=6.478, loss_v1=0, loss_v2=0, nll_loss=5.954, ntokens=1004.1, nsentences=32, sample_size=1004.1, sample_size_v1=0, sample_size_v2=0, ppl=62.01, wps=541.9, ups=0.54, wpb=1004.1, bsz=32, num_updates=390, lr=3.75361e-06, gnorm=5.426, clip=100, loss_scale=32, train_wall=18, gb_free=11.8, wall=751
2023-05-25 23:35:55 - progress_bar.py[line:272] - INFO: epoch 001:    402 / 1732 loss=6.383, loss_v1=0, loss_v2=0, nll_loss=5.847, ntokens=1005.2, nsentences=32, sample_size=1005.2, sample_size_v1=0, sample_size_v2=0, ppl=57.56, wps=539.1, ups=0.54, wpb=1005.2, bsz=32, num_updates=400, lr=3.84986e-06, gnorm=5.21, clip=100, loss_scale=32, train_wall=19, gb_free=11.3, wall=769
2023-05-25 23:36:13 - progress_bar.py[line:272] - INFO: epoch 001:    412 / 1732 loss=6.241, loss_v1=0, loss_v2=0, nll_loss=5.686, ntokens=1091.2, nsentences=32, sample_size=1091.2, sample_size_v1=0, sample_size_v2=0, ppl=51.49, wps=586, ups=0.54, wpb=1091.2, bsz=32, num_updates=410, lr=3.9461e-06, gnorm=5.172, clip=100, loss_scale=32, train_wall=19, gb_free=11.3, wall=788
2023-05-25 23:36:32 - progress_bar.py[line:272] - INFO: epoch 001:    422 / 1732 loss=6.141, loss_v1=0, loss_v2=0, nll_loss=5.572, ntokens=1011.2, nsentences=32, sample_size=1011.2, sample_size_v1=0, sample_size_v2=0, ppl=47.56, wps=542.4, ups=0.54, wpb=1011.2, bsz=32, num_updates=420, lr=4.04235e-06, gnorm=5.157, clip=100, loss_scale=32, train_wall=19, gb_free=11.3, wall=806
2023-05-25 23:36:50 - progress_bar.py[line:272] - INFO: epoch 001:    432 / 1732 loss=5.97, loss_v1=0, loss_v2=0, nll_loss=5.378, ntokens=1006.8, nsentences=32, sample_size=1006.8, sample_size_v1=0, sample_size_v2=0, ppl=41.59, wps=542.9, ups=0.54, wpb=1006.8, bsz=32, num_updates=430, lr=4.13859e-06, gnorm=4.885, clip=100, loss_scale=32, train_wall=19, gb_free=11.7, wall=825
2023-05-25 23:37:09 - progress_bar.py[line:272] - INFO: epoch 001:    442 / 1732 loss=5.881, loss_v1=0, loss_v2=0, nll_loss=5.274, ntokens=979.7, nsentences=32, sample_size=979.7, sample_size_v1=0, sample_size_v2=0, ppl=38.69, wps=527.8, ups=0.54, wpb=979.7, bsz=32, num_updates=440, lr=4.23484e-06, gnorm=4.682, clip=100, loss_scale=32, train_wall=19, gb_free=11, wall=844
2023-05-25 23:37:27 - progress_bar.py[line:272] - INFO: epoch 001:    452 / 1732 loss=5.735, loss_v1=0, loss_v2=0, nll_loss=5.107, ntokens=913.2, nsentences=32, sample_size=913.2, sample_size_v1=0, sample_size_v2=0, ppl=34.46, wps=493.4, ups=0.54, wpb=913.2, bsz=32, num_updates=450, lr=4.33109e-06, gnorm=4.671, clip=100, loss_scale=32, train_wall=18, gb_free=11.9, wall=862
2023-05-25 23:37:46 - progress_bar.py[line:272] - INFO: epoch 001:    462 / 1732 loss=5.601, loss_v1=0, loss_v2=0, nll_loss=4.955, ntokens=1070.3, nsentences=32, sample_size=1070.3, sample_size_v1=0, sample_size_v2=0, ppl=31.02, wps=574.6, ups=0.54, wpb=1070.3, bsz=32, num_updates=460, lr=4.42733e-06, gnorm=4.594, clip=100, loss_scale=32, train_wall=19, gb_free=11, wall=881
2023-05-25 23:38:05 - progress_bar.py[line:272] - INFO: epoch 001:    472 / 1732 loss=5.489, loss_v1=0, loss_v2=0, nll_loss=4.826, ntokens=1036.2, nsentences=32, sample_size=1036.2, sample_size_v1=0, sample_size_v2=0, ppl=28.36, wps=552.5, ups=0.53, wpb=1036.2, bsz=32, num_updates=470, lr=4.52358e-06, gnorm=4.394, clip=100, loss_scale=32, train_wall=19, gb_free=11.1, wall=899
2023-05-25 23:38:23 - progress_bar.py[line:272] - INFO: epoch 001:    482 / 1732 loss=5.412, loss_v1=0, loss_v2=0, nll_loss=4.737, ntokens=990.8, nsentences=32, sample_size=990.8, sample_size_v1=0, sample_size_v2=0, ppl=26.66, wps=534.6, ups=0.54, wpb=990.8, bsz=32, num_updates=480, lr=4.61983e-06, gnorm=4.448, clip=100, loss_scale=32, train_wall=19, gb_free=11.9, wall=918
2023-05-25 23:38:42 - progress_bar.py[line:272] - INFO: epoch 001:    492 / 1732 loss=5.296, loss_v1=0, loss_v2=0, nll_loss=4.604, ntokens=948.5, nsentences=32, sample_size=948.5, sample_size_v1=0, sample_size_v2=0, ppl=24.32, wps=510.1, ups=0.54, wpb=948.5, bsz=32, num_updates=490, lr=4.71607e-06, gnorm=4.238, clip=100, loss_scale=32, train_wall=19, gb_free=11.2, wall=937
2023-05-25 23:39:00 - progress_bar.py[line:272] - INFO: epoch 001:    502 / 1732 loss=5.24, loss_v1=0, loss_v2=0, nll_loss=4.54, ntokens=961.7, nsentences=32, sample_size=961.7, sample_size_v1=0, sample_size_v2=0, ppl=23.26, wps=521.9, ups=0.54, wpb=961.7, bsz=32, num_updates=500, lr=4.81232e-06, gnorm=4.115, clip=100, loss_scale=32, train_wall=18, gb_free=11.3, wall=955
2023-05-25 23:39:19 - progress_bar.py[line:272] - INFO: epoch 001:    512 / 1732 loss=5.22, loss_v1=0, loss_v2=0, nll_loss=4.516, ntokens=1041.1, nsentences=32, sample_size=1041.1, sample_size_v1=0, sample_size_v2=0, ppl=22.89, wps=561.5, ups=0.54, wpb=1041.1, bsz=32, num_updates=510, lr=4.90857e-06, gnorm=3.95, clip=100, loss_scale=32, train_wall=19, gb_free=10.7, wall=974
2023-05-25 23:39:37 - progress_bar.py[line:272] - INFO: epoch 001:    522 / 1732 loss=5.142, loss_v1=0, loss_v2=0, nll_loss=4.425, ntokens=995.3, nsentences=32, sample_size=995.3, sample_size_v1=0, sample_size_v2=0, ppl=21.49, wps=539.5, ups=0.54, wpb=995.3, bsz=32, num_updates=520, lr=5.00481e-06, gnorm=3.971, clip=100, loss_scale=32, train_wall=18, gb_free=11.7, wall=992
2023-05-25 23:39:56 - progress_bar.py[line:272] - INFO: epoch 001:    532 / 1732 loss=5.071, loss_v1=0, loss_v2=0, nll_loss=4.345, ntokens=942.5, nsentences=32, sample_size=942.5, sample_size_v1=0, sample_size_v2=0, ppl=20.32, wps=510.9, ups=0.54, wpb=942.5, bsz=32, num_updates=530, lr=5.10106e-06, gnorm=3.778, clip=100, loss_scale=32, train_wall=18, gb_free=12, wall=1010
2023-05-25 23:40:14 - progress_bar.py[line:272] - INFO: epoch 001:    542 / 1732 loss=4.991, loss_v1=0, loss_v2=0, nll_loss=4.253, ntokens=994, nsentences=32, sample_size=994, sample_size_v1=0, sample_size_v2=0, ppl=19.07, wps=537.7, ups=0.54, wpb=994, bsz=32, num_updates=540, lr=5.19731e-06, gnorm=3.557, clip=100, loss_scale=32, train_wall=18, gb_free=11, wall=1029
2023-05-25 23:40:33 - progress_bar.py[line:272] - INFO: epoch 001:    552 / 1732 loss=4.99, loss_v1=0, loss_v2=0, nll_loss=4.252, ntokens=1035.9, nsentences=32, sample_size=1035.9, sample_size_v1=0, sample_size_v2=0, ppl=19.05, wps=557.3, ups=0.54, wpb=1035.9, bsz=32, num_updates=550, lr=5.29355e-06, gnorm=3.532, clip=100, loss_scale=32, train_wall=19, gb_free=10.9, wall=1048
2023-05-25 23:40:52 - progress_bar.py[line:272] - INFO: epoch 001:    562 / 1732 loss=4.868, loss_v1=0, loss_v2=0, nll_loss=4.112, ntokens=1016.1, nsentences=32, sample_size=1016.1, sample_size_v1=0, sample_size_v2=0, ppl=17.3, wps=545.9, ups=0.54, wpb=1016.1, bsz=32, num_updates=560, lr=5.3898e-06, gnorm=3.413, clip=100, loss_scale=32, train_wall=19, gb_free=11.9, wall=1066
2023-05-25 23:41:10 - progress_bar.py[line:272] - INFO: epoch 001:    572 / 1732 loss=4.868, loss_v1=0, loss_v2=0, nll_loss=4.112, ntokens=1005.3, nsentences=32, sample_size=1005.3, sample_size_v1=0, sample_size_v2=0, ppl=17.29, wps=538.5, ups=0.54, wpb=1005.3, bsz=32, num_updates=570, lr=5.48604e-06, gnorm=3.38, clip=100, loss_scale=32, train_wall=19, gb_free=11.1, wall=1085
2023-05-25 23:41:29 - progress_bar.py[line:272] - INFO: epoch 001:    582 / 1732 loss=4.829, loss_v1=0, loss_v2=0, nll_loss=4.067, ntokens=1004.5, nsentences=32, sample_size=1004.5, sample_size_v1=0, sample_size_v2=0, ppl=16.77, wps=536.6, ups=0.53, wpb=1004.5, bsz=32, num_updates=580, lr=5.58229e-06, gnorm=3.42, clip=100, loss_scale=64, train_wall=19, gb_free=11.4, wall=1104
2023-05-25 23:41:48 - progress_bar.py[line:272] - INFO: epoch 001:    592 / 1732 loss=4.744, loss_v1=0, loss_v2=0, nll_loss=3.97, ntokens=950.1, nsentences=32, sample_size=950.1, sample_size_v1=0, sample_size_v2=0, ppl=15.67, wps=508.3, ups=0.53, wpb=950.1, bsz=32, num_updates=590, lr=5.67854e-06, gnorm=3.476, clip=100, loss_scale=64, train_wall=19, gb_free=11.2, wall=1122
2023-05-25 23:42:06 - progress_bar.py[line:272] - INFO: epoch 001:    602 / 1732 loss=4.732, loss_v1=0, loss_v2=0, nll_loss=3.956, ntokens=920.7, nsentences=32, sample_size=920.7, sample_size_v1=0, sample_size_v2=0, ppl=15.52, wps=498.2, ups=0.54, wpb=920.7, bsz=32, num_updates=600, lr=5.77478e-06, gnorm=3.36, clip=100, loss_scale=64, train_wall=18, gb_free=11.8, wall=1141
2023-05-25 23:42:25 - progress_bar.py[line:272] - INFO: epoch 001:    612 / 1732 loss=4.649, loss_v1=0, loss_v2=0, nll_loss=3.862, ntokens=908, nsentences=32, sample_size=908, sample_size_v1=0, sample_size_v2=0, ppl=14.55, wps=491.3, ups=0.54, wpb=908, bsz=32, num_updates=610, lr=5.87103e-06, gnorm=3.343, clip=100, loss_scale=64, train_wall=18, gb_free=11.5, wall=1159
2023-05-25 23:42:43 - progress_bar.py[line:272] - INFO: epoch 001:    622 / 1732 loss=4.582, loss_v1=0, loss_v2=0, nll_loss=3.784, ntokens=856.3, nsentences=32, sample_size=856.3, sample_size_v1=0, sample_size_v2=0, ppl=13.77, wps=467.1, ups=0.55, wpb=856.3, bsz=32, num_updates=620, lr=5.96728e-06, gnorm=3.314, clip=100, loss_scale=64, train_wall=18, gb_free=11, wall=1178
2023-05-25 23:43:01 - progress_bar.py[line:272] - INFO: epoch 001:    632 / 1732 loss=4.611, loss_v1=0, loss_v2=0, nll_loss=3.817, ntokens=935.9, nsentences=32, sample_size=935.9, sample_size_v1=0, sample_size_v2=0, ppl=14.09, wps=507, ups=0.54, wpb=935.9, bsz=32, num_updates=630, lr=6.06352e-06, gnorm=3.201, clip=100, loss_scale=64, train_wall=18, gb_free=11.9, wall=1196
2023-05-25 23:43:20 - progress_bar.py[line:272] - INFO: epoch 001:    642 / 1732 loss=4.507, loss_v1=0, loss_v2=0, nll_loss=3.697, ntokens=946.6, nsentences=32, sample_size=946.6, sample_size_v1=0, sample_size_v2=0, ppl=12.96, wps=512.9, ups=0.54, wpb=946.6, bsz=32, num_updates=640, lr=6.15977e-06, gnorm=2.967, clip=100, loss_scale=64, train_wall=18, gb_free=11.2, wall=1215
2023-05-25 23:43:38 - progress_bar.py[line:272] - INFO: epoch 001:    652 / 1732 loss=4.501, loss_v1=0, loss_v2=0, nll_loss=3.689, ntokens=952.7, nsentences=32, sample_size=952.7, sample_size_v1=0, sample_size_v2=0, ppl=12.9, wps=518, ups=0.54, wpb=952.7, bsz=32, num_updates=650, lr=6.25602e-06, gnorm=2.981, clip=100, loss_scale=64, train_wall=18, gb_free=12.2, wall=1233
2023-05-25 23:43:57 - progress_bar.py[line:272] - INFO: epoch 001:    662 / 1732 loss=4.483, loss_v1=0, loss_v2=0, nll_loss=3.669, ntokens=882.3, nsentences=32, sample_size=882.3, sample_size_v1=0, sample_size_v2=0, ppl=12.72, wps=479.3, ups=0.54, wpb=882.3, bsz=32, num_updates=660, lr=6.35226e-06, gnorm=3.056, clip=100, loss_scale=64, train_wall=18, gb_free=10.7, wall=1251
2023-05-25 23:44:15 - progress_bar.py[line:272] - INFO: epoch 001:    672 / 1732 loss=4.412, loss_v1=0, loss_v2=0, nll_loss=3.587, ntokens=943.8, nsentences=32, sample_size=943.8, sample_size_v1=0, sample_size_v2=0, ppl=12.02, wps=509.7, ups=0.54, wpb=943.8, bsz=32, num_updates=670, lr=6.44851e-06, gnorm=2.985, clip=100, loss_scale=64, train_wall=18, gb_free=11.7, wall=1270
2023-05-25 23:44:34 - progress_bar.py[line:272] - INFO: epoch 001:    682 / 1732 loss=4.339, loss_v1=0, loss_v2=0, nll_loss=3.501, ntokens=981.8, nsentences=32, sample_size=981.8, sample_size_v1=0, sample_size_v2=0, ppl=11.32, wps=531.7, ups=0.54, wpb=981.8, bsz=32, num_updates=680, lr=6.54475e-06, gnorm=2.743, clip=100, loss_scale=64, train_wall=18, gb_free=11.6, wall=1288
2023-05-25 23:44:52 - progress_bar.py[line:272] - INFO: epoch 001:    692 / 1732 loss=4.356, loss_v1=0, loss_v2=0, nll_loss=3.52, ntokens=939.1, nsentences=32, sample_size=939.1, sample_size_v1=0, sample_size_v2=0, ppl=11.47, wps=505.2, ups=0.54, wpb=939.1, bsz=32, num_updates=690, lr=6.641e-06, gnorm=2.778, clip=100, loss_scale=64, train_wall=19, gb_free=11.8, wall=1307
2023-05-25 23:45:11 - progress_bar.py[line:272] - INFO: epoch 001:    702 / 1732 loss=4.284, loss_v1=0, loss_v2=0, nll_loss=3.439, ntokens=974.5, nsentences=32, sample_size=974.5, sample_size_v1=0, sample_size_v2=0, ppl=10.84, wps=525.1, ups=0.54, wpb=974.5, bsz=32, num_updates=700, lr=6.73725e-06, gnorm=2.684, clip=100, loss_scale=64, train_wall=19, gb_free=11.6, wall=1325
2023-05-25 23:45:29 - progress_bar.py[line:272] - INFO: epoch 001:    712 / 1732 loss=4.221, loss_v1=0, loss_v2=0, nll_loss=3.365, ntokens=913.9, nsentences=32, sample_size=913.9, sample_size_v1=0, sample_size_v2=0, ppl=10.31, wps=493.9, ups=0.54, wpb=913.9, bsz=32, num_updates=710, lr=6.83349e-06, gnorm=2.62, clip=100, loss_scale=64, train_wall=18, gb_free=11.8, wall=1344
2023-05-25 23:45:48 - progress_bar.py[line:272] - INFO: epoch 001:    722 / 1732 loss=4.211, loss_v1=0, loss_v2=0, nll_loss=3.351, ntokens=864.8, nsentences=32, sample_size=864.8, sample_size_v1=0, sample_size_v2=0, ppl=10.21, wps=469.9, ups=0.54, wpb=864.8, bsz=32, num_updates=720, lr=6.92974e-06, gnorm=2.821, clip=100, loss_scale=64, train_wall=18, gb_free=11.6, wall=1362
2023-05-25 23:46:06 - progress_bar.py[line:272] - INFO: epoch 001:    732 / 1732 loss=4.138, loss_v1=0, loss_v2=0, nll_loss=3.27, ntokens=937.9, nsentences=32, sample_size=937.9, sample_size_v1=0, sample_size_v2=0, ppl=9.65, wps=507.8, ups=0.54, wpb=937.9, bsz=32, num_updates=730, lr=7.02599e-06, gnorm=2.598, clip=100, loss_scale=64, train_wall=18, gb_free=11.2, wall=1381
2023-05-25 23:46:25 - progress_bar.py[line:272] - INFO: epoch 001:    742 / 1732 loss=4.102, loss_v1=0, loss_v2=0, nll_loss=3.227, ntokens=1015.7, nsentences=32, sample_size=1015.7, sample_size_v1=0, sample_size_v2=0, ppl=9.36, wps=549.7, ups=0.54, wpb=1015.7, bsz=32, num_updates=740, lr=7.12223e-06, gnorm=2.555, clip=100, loss_scale=64, train_wall=18, gb_free=11.5, wall=1399
2023-05-25 23:46:43 - progress_bar.py[line:272] - INFO: epoch 001:    752 / 1732 loss=4.051, loss_v1=0, loss_v2=0, nll_loss=3.166, ntokens=960.1, nsentences=32, sample_size=960.1, sample_size_v1=0, sample_size_v2=0, ppl=8.98, wps=517.9, ups=0.54, wpb=960.1, bsz=32, num_updates=750, lr=7.21848e-06, gnorm=2.547, clip=100, loss_scale=64, train_wall=19, gb_free=11.8, wall=1418
2023-05-25 23:47:02 - progress_bar.py[line:272] - INFO: epoch 001:    762 / 1732 loss=4.048, loss_v1=0, loss_v2=0, nll_loss=3.165, ntokens=973.7, nsentences=32, sample_size=973.7, sample_size_v1=0, sample_size_v2=0, ppl=8.97, wps=526.1, ups=0.54, wpb=973.7, bsz=32, num_updates=760, lr=7.31473e-06, gnorm=2.489, clip=100, loss_scale=64, train_wall=18, gb_free=11.9, wall=1436
2023-05-25 23:47:20 - progress_bar.py[line:272] - INFO: epoch 001:    772 / 1732 loss=3.964, loss_v1=0, loss_v2=0, nll_loss=3.068, ntokens=955.8, nsentences=32, sample_size=955.8, sample_size_v1=0, sample_size_v2=0, ppl=8.39, wps=515.8, ups=0.54, wpb=955.8, bsz=32, num_updates=770, lr=7.41097e-06, gnorm=2.431, clip=100, loss_scale=64, train_wall=19, gb_free=10.4, wall=1455
2023-05-25 23:47:39 - progress_bar.py[line:272] - INFO: epoch 001:    782 / 1732 loss=3.998, loss_v1=0, loss_v2=0, nll_loss=3.105, ntokens=1024.5, nsentences=32, sample_size=1024.5, sample_size_v1=0, sample_size_v2=0, ppl=8.6, wps=552.5, ups=0.54, wpb=1024.5, bsz=32, num_updates=780, lr=7.50722e-06, gnorm=2.405, clip=100, loss_scale=64, train_wall=19, gb_free=11.7, wall=1473
2023-05-25 23:47:57 - progress_bar.py[line:272] - INFO: epoch 001:    792 / 1732 loss=3.909, loss_v1=0, loss_v2=0, nll_loss=3.006, ntokens=1023.9, nsentences=32, sample_size=1023.9, sample_size_v1=0, sample_size_v2=0, ppl=8.04, wps=553.8, ups=0.54, wpb=1023.9, bsz=32, num_updates=790, lr=7.60346e-06, gnorm=2.333, clip=100, loss_scale=64, train_wall=18, gb_free=12, wall=1492
2023-05-25 23:48:16 - progress_bar.py[line:272] - INFO: epoch 001:    802 / 1732 loss=3.879, loss_v1=0, loss_v2=0, nll_loss=2.967, ntokens=971.6, nsentences=32, sample_size=971.6, sample_size_v1=0, sample_size_v2=0, ppl=7.82, wps=527.1, ups=0.54, wpb=971.6, bsz=32, num_updates=800, lr=7.69971e-06, gnorm=2.273, clip=100, loss_scale=64, train_wall=18, gb_free=11.7, wall=1510
2023-05-25 23:48:34 - progress_bar.py[line:272] - INFO: epoch 001:    812 / 1732 loss=3.841, loss_v1=0, loss_v2=0, nll_loss=2.924, ntokens=942.1, nsentences=32, sample_size=942.1, sample_size_v1=0, sample_size_v2=0, ppl=7.59, wps=510.8, ups=0.54, wpb=942.1, bsz=32, num_updates=810, lr=7.79596e-06, gnorm=2.158, clip=100, loss_scale=64, train_wall=18, gb_free=11.6, wall=1529
2023-05-25 23:48:53 - progress_bar.py[line:272] - INFO: epoch 001:    822 / 1732 loss=3.805, loss_v1=0, loss_v2=0, nll_loss=2.881, ntokens=921.5, nsentences=32, sample_size=921.5, sample_size_v1=0, sample_size_v2=0, ppl=7.37, wps=497.7, ups=0.54, wpb=921.5, bsz=32, num_updates=820, lr=7.8922e-06, gnorm=2.287, clip=100, loss_scale=64, train_wall=18, gb_free=11.4, wall=1547
2023-05-25 23:49:11 - progress_bar.py[line:272] - INFO: epoch 001:    832 / 1732 loss=3.752, loss_v1=0, loss_v2=0, nll_loss=2.82, ntokens=907.9, nsentences=32, sample_size=907.9, sample_size_v1=0, sample_size_v2=0, ppl=7.06, wps=493.8, ups=0.54, wpb=907.9, bsz=32, num_updates=830, lr=7.98845e-06, gnorm=2.216, clip=100, loss_scale=64, train_wall=18, gb_free=11.8, wall=1566
2023-05-25 23:49:29 - progress_bar.py[line:272] - INFO: epoch 001:    842 / 1732 loss=3.683, loss_v1=0, loss_v2=0, nll_loss=2.744, ntokens=950.4, nsentences=32, sample_size=950.4, sample_size_v1=0, sample_size_v2=0, ppl=6.7, wps=517.1, ups=0.54, wpb=950.4, bsz=32, num_updates=840, lr=8.0847e-06, gnorm=2.173, clip=100, loss_scale=64, train_wall=18, gb_free=11.4, wall=1584
2023-05-25 23:49:48 - progress_bar.py[line:272] - INFO: epoch 001:    852 / 1732 loss=3.745, loss_v1=0, loss_v2=0, nll_loss=2.808, ntokens=997.8, nsentences=32, sample_size=997.8, sample_size_v1=0, sample_size_v2=0, ppl=7, wps=539.8, ups=0.54, wpb=997.8, bsz=32, num_updates=850, lr=8.18094e-06, gnorm=2.236, clip=100, loss_scale=64, train_wall=18, gb_free=11.8, wall=1603
2023-05-25 23:50:07 - progress_bar.py[line:272] - INFO: epoch 001:    862 / 1732 loss=3.64, loss_v1=0, loss_v2=0, nll_loss=2.688, ntokens=931.8, nsentences=32, sample_size=931.8, sample_size_v1=0, sample_size_v2=0, ppl=6.45, wps=500.6, ups=0.54, wpb=931.8, bsz=32, num_updates=860, lr=8.27719e-06, gnorm=2.162, clip=100, loss_scale=64, train_wall=19, gb_free=11, wall=1621
2023-05-25 23:50:25 - progress_bar.py[line:272] - INFO: epoch 001:    872 / 1732 loss=3.639, loss_v1=0, loss_v2=0, nll_loss=2.683, ntokens=965, nsentences=32, sample_size=965, sample_size_v1=0, sample_size_v2=0, ppl=6.42, wps=524.3, ups=0.54, wpb=965, bsz=32, num_updates=870, lr=8.37344e-06, gnorm=1.989, clip=100, loss_scale=64, train_wall=18, gb_free=11.6, wall=1640
2023-05-25 23:50:43 - progress_bar.py[line:272] - INFO: epoch 001:    882 / 1732 loss=3.566, loss_v1=0, loss_v2=0, nll_loss=2.603, ntokens=987.7, nsentences=32, sample_size=987.7, sample_size_v1=0, sample_size_v2=0, ppl=6.08, wps=533.7, ups=0.54, wpb=987.7, bsz=32, num_updates=880, lr=8.46968e-06, gnorm=2.151, clip=100, loss_scale=64, train_wall=18, gb_free=11.3, wall=1658
2023-05-25 23:51:02 - progress_bar.py[line:272] - INFO: epoch 001:    892 / 1732 loss=3.544, loss_v1=0, loss_v2=0, nll_loss=2.574, ntokens=1003.5, nsentences=32, sample_size=1003.5, sample_size_v1=0, sample_size_v2=0, ppl=5.95, wps=541.2, ups=0.54, wpb=1003.5, bsz=32, num_updates=890, lr=8.56593e-06, gnorm=2.229, clip=100, loss_scale=64, train_wall=19, gb_free=11.1, wall=1677
2023-05-25 23:51:21 - progress_bar.py[line:272] - INFO: epoch 001:    902 / 1732 loss=3.524, loss_v1=0, loss_v2=0, nll_loss=2.551, ntokens=1046.1, nsentences=32, sample_size=1046.1, sample_size_v1=0, sample_size_v2=0, ppl=5.86, wps=565.5, ups=0.54, wpb=1046.1, bsz=32, num_updates=900, lr=8.66218e-06, gnorm=2.256, clip=100, loss_scale=64, train_wall=18, gb_free=11.2, wall=1695
2023-05-25 23:51:39 - progress_bar.py[line:272] - INFO: epoch 001:    912 / 1732 loss=3.541, loss_v1=0, loss_v2=0, nll_loss=2.569, ntokens=948.6, nsentences=32, sample_size=948.6, sample_size_v1=0, sample_size_v2=0, ppl=5.93, wps=513.1, ups=0.54, wpb=948.6, bsz=32, num_updates=910, lr=8.75842e-06, gnorm=2.168, clip=100, loss_scale=64, train_wall=18, gb_free=11, wall=1714
2023-05-25 23:51:58 - progress_bar.py[line:272] - INFO: epoch 001:    922 / 1732 loss=3.54, loss_v1=0, loss_v2=0, nll_loss=2.563, ntokens=1004.6, nsentences=32, sample_size=1004.6, sample_size_v1=0, sample_size_v2=0, ppl=5.91, wps=540.5, ups=0.54, wpb=1004.6, bsz=32, num_updates=920, lr=8.85467e-06, gnorm=2.123, clip=100, loss_scale=64, train_wall=19, gb_free=11.3, wall=1732
2023-05-25 23:52:16 - progress_bar.py[line:272] - INFO: epoch 001:    932 / 1732 loss=3.498, loss_v1=0, loss_v2=0, nll_loss=2.514, ntokens=1036.8, nsentences=32, sample_size=1036.8, sample_size_v1=0, sample_size_v2=0, ppl=5.71, wps=554.6, ups=0.53, wpb=1036.8, bsz=32, num_updates=930, lr=8.95091e-06, gnorm=2.061, clip=100, loss_scale=64, train_wall=19, gb_free=10.9, wall=1751
2023-05-25 23:52:35 - progress_bar.py[line:272] - INFO: epoch 001:    942 / 1732 loss=3.491, loss_v1=0, loss_v2=0, nll_loss=2.506, ntokens=1063.3, nsentences=32, sample_size=1063.3, sample_size_v1=0, sample_size_v2=0, ppl=5.68, wps=565.4, ups=0.53, wpb=1063.3, bsz=32, num_updates=940, lr=9.04716e-06, gnorm=2.002, clip=100, loss_scale=64, train_wall=19, gb_free=11.6, wall=1770
2023-05-25 23:52:54 - progress_bar.py[line:272] - INFO: epoch 001:    952 / 1732 loss=3.427, loss_v1=0, loss_v2=0, nll_loss=2.434, ntokens=1011.4, nsentences=32, sample_size=1011.4, sample_size_v1=0, sample_size_v2=0, ppl=5.4, wps=540.9, ups=0.53, wpb=1011.4, bsz=32, num_updates=950, lr=9.14341e-06, gnorm=2.051, clip=100, loss_scale=64, train_wall=19, gb_free=11.5, wall=1788
2023-05-25 23:53:13 - progress_bar.py[line:272] - INFO: epoch 001:    962 / 1732 loss=3.478, loss_v1=0, loss_v2=0, nll_loss=2.491, ntokens=1071.4, nsentences=32, sample_size=1071.4, sample_size_v1=0, sample_size_v2=0, ppl=5.62, wps=571.6, ups=0.53, wpb=1071.4, bsz=32, num_updates=960, lr=9.23965e-06, gnorm=2.218, clip=100, loss_scale=64, train_wall=19, gb_free=11.8, wall=1807
2023-05-25 23:53:31 - progress_bar.py[line:272] - INFO: epoch 001:    972 / 1732 loss=3.452, loss_v1=0, loss_v2=0, nll_loss=2.46, ntokens=1038.3, nsentences=32, sample_size=1038.3, sample_size_v1=0, sample_size_v2=0, ppl=5.5, wps=552.4, ups=0.53, wpb=1038.3, bsz=32, num_updates=970, lr=9.3359e-06, gnorm=2.048, clip=100, loss_scale=64, train_wall=19, gb_free=10.7, wall=1826
2023-05-25 23:53:50 - progress_bar.py[line:272] - INFO: epoch 001:    982 / 1732 loss=3.399, loss_v1=0, loss_v2=0, nll_loss=2.398, ntokens=1035.4, nsentences=32, sample_size=1035.4, sample_size_v1=0, sample_size_v2=0, ppl=5.27, wps=551.3, ups=0.53, wpb=1035.4, bsz=32, num_updates=980, lr=9.43215e-06, gnorm=2.078, clip=100, loss_scale=64, train_wall=19, gb_free=11.3, wall=1845
2023-05-25 23:54:09 - progress_bar.py[line:272] - INFO: epoch 001:    992 / 1732 loss=3.378, loss_v1=0, loss_v2=0, nll_loss=2.372, ntokens=1026.6, nsentences=32, sample_size=1026.6, sample_size_v1=0, sample_size_v2=0, ppl=5.18, wps=546.7, ups=0.53, wpb=1026.6, bsz=32, num_updates=990, lr=9.52839e-06, gnorm=1.959, clip=100, loss_scale=64, train_wall=19, gb_free=11.4, wall=1864
2023-05-25 23:54:28 - progress_bar.py[line:272] - INFO: epoch 001:   1002 / 1732 loss=3.366, loss_v1=0, loss_v2=0, nll_loss=2.357, ntokens=1023.8, nsentences=32, sample_size=1023.8, sample_size_v1=0, sample_size_v2=0, ppl=5.12, wps=548.5, ups=0.54, wpb=1023.8, bsz=32, num_updates=1000, lr=9.62464e-06, gnorm=1.974, clip=100, loss_scale=64, train_wall=19, gb_free=11.1, wall=1882
2023-05-25 23:54:46 - progress_bar.py[line:272] - INFO: epoch 001:   1012 / 1732 loss=3.341, loss_v1=0, loss_v2=0, nll_loss=2.329, ntokens=987.2, nsentences=32, sample_size=987.2, sample_size_v1=0, sample_size_v2=0, ppl=5.02, wps=530.4, ups=0.54, wpb=987.2, bsz=32, num_updates=1010, lr=9.72089e-06, gnorm=1.983, clip=100, loss_scale=64, train_wall=19, gb_free=11.3, wall=1901
2023-05-25 23:55:05 - progress_bar.py[line:272] - INFO: epoch 001:   1022 / 1732 loss=3.344, loss_v1=0, loss_v2=0, nll_loss=2.332, ntokens=1063.7, nsentences=32, sample_size=1063.7, sample_size_v1=0, sample_size_v2=0, ppl=5.03, wps=567.3, ups=0.53, wpb=1063.7, bsz=32, num_updates=1020, lr=9.81713e-06, gnorm=2.027, clip=100, loss_scale=64, train_wall=19, gb_free=10.7, wall=1920
2023-05-25 23:55:24 - progress_bar.py[line:272] - INFO: epoch 001:   1032 / 1732 loss=3.336, loss_v1=0, loss_v2=0, nll_loss=2.32, ntokens=1117.6, nsentences=32, sample_size=1117.6, sample_size_v1=0, sample_size_v2=0, ppl=4.99, wps=589.9, ups=0.53, wpb=1117.6, bsz=32, num_updates=1030, lr=9.91338e-06, gnorm=2.043, clip=100, loss_scale=64, train_wall=19, gb_free=11.5, wall=1939
2023-05-25 23:55:43 - progress_bar.py[line:272] - INFO: epoch 001:   1042 / 1732 loss=3.314, loss_v1=0, loss_v2=0, nll_loss=2.293, ntokens=1067.2, nsentences=32, sample_size=1067.2, sample_size_v1=0, sample_size_v2=0, ppl=4.9, wps=566.7, ups=0.53, wpb=1067.2, bsz=32, num_updates=1040, lr=1.00096e-05, gnorm=2.05, clip=100, loss_scale=64, train_wall=19, gb_free=10.8, wall=1957
2023-05-25 23:56:01 - progress_bar.py[line:272] - INFO: epoch 001:   1052 / 1732 loss=3.282, loss_v1=0, loss_v2=0, nll_loss=2.252, ntokens=1041, nsentences=32, sample_size=1041, sample_size_v1=0, sample_size_v2=0, ppl=4.76, wps=558.7, ups=0.54, wpb=1041, bsz=32, num_updates=1050, lr=1.01059e-05, gnorm=1.97, clip=100, loss_scale=64, train_wall=19, gb_free=11.2, wall=1976
2023-05-25 23:56:20 - progress_bar.py[line:272] - INFO: epoch 001:   1062 / 1732 loss=3.31, loss_v1=0, loss_v2=0, nll_loss=2.287, ntokens=1046.1, nsentences=32, sample_size=1046.1, sample_size_v1=0, sample_size_v2=0, ppl=4.88, wps=557.7, ups=0.53, wpb=1046.1, bsz=32, num_updates=1060, lr=1.02021e-05, gnorm=2.089, clip=100, loss_scale=64, train_wall=19, gb_free=11.1, wall=1995
2023-05-25 23:56:39 - progress_bar.py[line:272] - INFO: epoch 001:   1072 / 1732 loss=3.252, loss_v1=0, loss_v2=0, nll_loss=2.219, ntokens=994.4, nsentences=32, sample_size=994.4, sample_size_v1=0, sample_size_v2=0, ppl=4.66, wps=530.7, ups=0.53, wpb=994.4, bsz=32, num_updates=1070, lr=1.02984e-05, gnorm=1.963, clip=100, loss_scale=64, train_wall=19, gb_free=11.5, wall=2014
2023-05-25 23:56:58 - progress_bar.py[line:272] - INFO: epoch 001:   1082 / 1732 loss=3.274, loss_v1=0, loss_v2=0, nll_loss=2.242, ntokens=1041.7, nsentences=32, sample_size=1041.7, sample_size_v1=0, sample_size_v2=0, ppl=4.73, wps=552.5, ups=0.53, wpb=1041.7, bsz=32, num_updates=1080, lr=1.03946e-05, gnorm=1.944, clip=100, loss_scale=64, train_wall=19, gb_free=11.2, wall=2032
2023-05-25 23:57:17 - progress_bar.py[line:272] - INFO: epoch 001:   1092 / 1732 loss=3.249, loss_v1=0, loss_v2=0, nll_loss=2.214, ntokens=1060.8, nsentences=32, sample_size=1060.8, sample_size_v1=0, sample_size_v2=0, ppl=4.64, wps=563.4, ups=0.53, wpb=1060.8, bsz=32, num_updates=1090, lr=1.04909e-05, gnorm=1.893, clip=100, loss_scale=128, train_wall=19, gb_free=11.6, wall=2051
2023-05-25 23:57:35 - progress_bar.py[line:272] - INFO: epoch 001:   1102 / 1732 loss=3.25, loss_v1=0, loss_v2=0, nll_loss=2.214, ntokens=1049.1, nsentences=32, sample_size=1049.1, sample_size_v1=0, sample_size_v2=0, ppl=4.64, wps=560.8, ups=0.53, wpb=1049.1, bsz=32, num_updates=1100, lr=1.05871e-05, gnorm=1.933, clip=100, loss_scale=128, train_wall=19, gb_free=10.5, wall=2070
2023-05-25 23:57:54 - progress_bar.py[line:272] - INFO: epoch 001:   1112 / 1732 loss=3.198, loss_v1=0, loss_v2=0, nll_loss=2.153, ntokens=1025.7, nsentences=32, sample_size=1025.7, sample_size_v1=0, sample_size_v2=0, ppl=4.45, wps=546.4, ups=0.53, wpb=1025.7, bsz=32, num_updates=1110, lr=1.06833e-05, gnorm=1.918, clip=100, loss_scale=128, train_wall=19, gb_free=11.3, wall=2089
2023-05-25 23:58:13 - progress_bar.py[line:272] - INFO: epoch 001:   1122 / 1732 loss=3.245, loss_v1=0, loss_v2=0, nll_loss=2.207, ntokens=976.1, nsentences=32, sample_size=976.1, sample_size_v1=0, sample_size_v2=0, ppl=4.62, wps=521.6, ups=0.53, wpb=976.1, bsz=32, num_updates=1120, lr=1.07796e-05, gnorm=2.156, clip=100, loss_scale=128, train_wall=19, gb_free=11.3, wall=2107
2023-05-25 23:58:32 - progress_bar.py[line:272] - INFO: epoch 001:   1132 / 1732 loss=3.191, loss_v1=0, loss_v2=0, nll_loss=2.144, ntokens=969.4, nsentences=32, sample_size=969.4, sample_size_v1=0, sample_size_v2=0, ppl=4.42, wps=517.7, ups=0.53, wpb=969.4, bsz=32, num_updates=1130, lr=1.08758e-05, gnorm=2.147, clip=100, loss_scale=128, train_wall=19, gb_free=11.7, wall=2126
2023-05-25 23:58:50 - progress_bar.py[line:272] - INFO: epoch 001:   1142 / 1732 loss=3.187, loss_v1=0, loss_v2=0, nll_loss=2.142, ntokens=1032.5, nsentences=32, sample_size=1032.5, sample_size_v1=0, sample_size_v2=0, ppl=4.41, wps=551.4, ups=0.53, wpb=1032.5, bsz=32, num_updates=1140, lr=1.09721e-05, gnorm=2.015, clip=100, loss_scale=128, train_wall=19, gb_free=11.1, wall=2145
2023-05-25 23:59:09 - progress_bar.py[line:272] - INFO: epoch 001:   1152 / 1732 loss=3.187, loss_v1=0, loss_v2=0, nll_loss=2.139, ntokens=1026.9, nsentences=32, sample_size=1026.9, sample_size_v1=0, sample_size_v2=0, ppl=4.41, wps=549.4, ups=0.54, wpb=1026.9, bsz=32, num_updates=1150, lr=1.10683e-05, gnorm=1.958, clip=100, loss_scale=128, train_wall=19, gb_free=11.4, wall=2164
2023-05-25 23:59:28 - progress_bar.py[line:272] - INFO: epoch 001:   1162 / 1732 loss=3.144, loss_v1=0, loss_v2=0, nll_loss=2.089, ntokens=1008.4, nsentences=32, sample_size=1008.4, sample_size_v1=0, sample_size_v2=0, ppl=4.26, wps=537.3, ups=0.53, wpb=1008.4, bsz=32, num_updates=1160, lr=1.11646e-05, gnorm=2.034, clip=100, loss_scale=128, train_wall=19, gb_free=11.3, wall=2182
2023-05-25 23:59:47 - progress_bar.py[line:272] - INFO: epoch 001:   1172 / 1732 loss=3.133, loss_v1=0, loss_v2=0, nll_loss=2.075, ntokens=1048.6, nsentences=32, sample_size=1048.6, sample_size_v1=0, sample_size_v2=0, ppl=4.21, wps=557.7, ups=0.53, wpb=1048.6, bsz=32, num_updates=1170, lr=1.12608e-05, gnorm=1.993, clip=100, loss_scale=128, train_wall=19, gb_free=10.8, wall=2201
2023-05-26 00:00:05 - progress_bar.py[line:272] - INFO: epoch 001:   1182 / 1732 loss=3.153, loss_v1=0, loss_v2=0, nll_loss=2.098, ntokens=1018.1, nsentences=32, sample_size=1018.1, sample_size_v1=0, sample_size_v2=0, ppl=4.28, wps=543.5, ups=0.53, wpb=1018.1, bsz=32, num_updates=1180, lr=1.13571e-05, gnorm=2.157, clip=100, loss_scale=128, train_wall=19, gb_free=11.4, wall=2220
2023-05-26 00:00:24 - progress_bar.py[line:272] - INFO: epoch 001:   1192 / 1732 loss=3.159, loss_v1=0, loss_v2=0, nll_loss=2.103, ntokens=1011.4, nsentences=32, sample_size=1011.4, sample_size_v1=0, sample_size_v2=0, ppl=4.3, wps=536.2, ups=0.53, wpb=1011.4, bsz=32, num_updates=1190, lr=1.14533e-05, gnorm=2.044, clip=100, loss_scale=128, train_wall=19, gb_free=11.4, wall=2239
2023-05-26 00:00:43 - progress_bar.py[line:272] - INFO: epoch 001:   1202 / 1732 loss=3.081, loss_v1=0, loss_v2=0, nll_loss=2.015, ntokens=1128.3, nsentences=32, sample_size=1128.3, sample_size_v1=0, sample_size_v2=0, ppl=4.04, wps=597.9, ups=0.53, wpb=1128.3, bsz=32, num_updates=1200, lr=1.15496e-05, gnorm=1.974, clip=100, loss_scale=128, train_wall=19, gb_free=11.1, wall=2258
2023-05-26 00:01:02 - progress_bar.py[line:272] - INFO: epoch 001:   1212 / 1732 loss=3.091, loss_v1=0, loss_v2=0, nll_loss=2.027, ntokens=1031.6, nsentences=32, sample_size=1031.6, sample_size_v1=0, sample_size_v2=0, ppl=4.07, wps=547.9, ups=0.53, wpb=1031.6, bsz=32, num_updates=1210, lr=1.16458e-05, gnorm=2.005, clip=100, loss_scale=128, train_wall=19, gb_free=10.9, wall=2277
2023-05-26 00:01:21 - progress_bar.py[line:272] - INFO: epoch 001:   1222 / 1732 loss=3.122, loss_v1=0, loss_v2=0, nll_loss=2.057, ntokens=1024, nsentences=32, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=4.16, wps=547.6, ups=0.53, wpb=1024, bsz=32, num_updates=1220, lr=1.17421e-05, gnorm=2.041, clip=100, loss_scale=128, train_wall=19, gb_free=10.8, wall=2295
2023-05-26 00:01:39 - progress_bar.py[line:272] - INFO: epoch 001:   1232 / 1732 loss=3.071, loss_v1=0, loss_v2=0, nll_loss=2.004, ntokens=1035.1, nsentences=32, sample_size=1035.1, sample_size_v1=0, sample_size_v2=0, ppl=4.01, wps=553.1, ups=0.53, wpb=1035.1, bsz=32, num_updates=1230, lr=1.18383e-05, gnorm=2.032, clip=100, loss_scale=128, train_wall=19, gb_free=11.4, wall=2314
2023-05-26 00:01:58 - progress_bar.py[line:272] - INFO: epoch 001:   1242 / 1732 loss=3.052, loss_v1=0, loss_v2=0, nll_loss=1.98, ntokens=1078.3, nsentences=32, sample_size=1078.3, sample_size_v1=0, sample_size_v2=0, ppl=3.94, wps=571.7, ups=0.53, wpb=1078.3, bsz=32, num_updates=1240, lr=1.19346e-05, gnorm=2.109, clip=100, loss_scale=128, train_wall=19, gb_free=11.4, wall=2333
2023-05-26 00:02:17 - progress_bar.py[line:272] - INFO: epoch 001:   1252 / 1732 loss=3.059, loss_v1=0, loss_v2=0, nll_loss=1.985, ntokens=1106.3, nsentences=32, sample_size=1106.3, sample_size_v1=0, sample_size_v2=0, ppl=3.96, wps=586.5, ups=0.53, wpb=1106.3, bsz=32, num_updates=1250, lr=1.20308e-05, gnorm=2.114, clip=100, loss_scale=128, train_wall=19, gb_free=10.9, wall=2352
2023-05-26 00:02:36 - progress_bar.py[line:272] - INFO: epoch 001:   1262 / 1732 loss=3.07, loss_v1=0, loss_v2=0, nll_loss=1.999, ntokens=1064, nsentences=32, sample_size=1064, sample_size_v1=0, sample_size_v2=0, ppl=4, wps=563.3, ups=0.53, wpb=1064, bsz=32, num_updates=1260, lr=1.2127e-05, gnorm=2.151, clip=100, loss_scale=128, train_wall=19, gb_free=10.9, wall=2371
2023-05-26 00:02:55 - progress_bar.py[line:272] - INFO: epoch 001:   1272 / 1732 loss=3.048, loss_v1=0, loss_v2=0, nll_loss=1.972, ntokens=1010.3, nsentences=32, sample_size=1010.3, sample_size_v1=0, sample_size_v2=0, ppl=3.92, wps=540.5, ups=0.53, wpb=1010.3, bsz=32, num_updates=1270, lr=1.22233e-05, gnorm=1.981, clip=100, loss_scale=128, train_wall=19, gb_free=10.9, wall=2389
2023-05-26 00:03:14 - progress_bar.py[line:272] - INFO: epoch 001:   1282 / 1732 loss=3.03, loss_v1=0, loss_v2=0, nll_loss=1.953, ntokens=1073.6, nsentences=32, sample_size=1073.6, sample_size_v1=0, sample_size_v2=0, ppl=3.87, wps=567.4, ups=0.53, wpb=1073.6, bsz=32, num_updates=1280, lr=1.23195e-05, gnorm=2.129, clip=100, loss_scale=128, train_wall=19, gb_free=10.4, wall=2408
2023-05-26 00:03:32 - progress_bar.py[line:272] - INFO: epoch 001:   1292 / 1732 loss=3.052, loss_v1=0, loss_v2=0, nll_loss=1.976, ntokens=1095.2, nsentences=32, sample_size=1095.2, sample_size_v1=0, sample_size_v2=0, ppl=3.93, wps=581.1, ups=0.53, wpb=1095.2, bsz=32, num_updates=1290, lr=1.24158e-05, gnorm=1.935, clip=100, loss_scale=128, train_wall=19, gb_free=10.7, wall=2427
2023-05-26 00:03:51 - progress_bar.py[line:272] - INFO: epoch 001:   1302 / 1732 loss=2.994, loss_v1=0, loss_v2=0, nll_loss=1.912, ntokens=1099.5, nsentences=32, sample_size=1099.5, sample_size_v1=0, sample_size_v2=0, ppl=3.76, wps=584.9, ups=0.53, wpb=1099.5, bsz=32, num_updates=1300, lr=1.2512e-05, gnorm=1.923, clip=100, loss_scale=128, train_wall=19, gb_free=10.4, wall=2446
2023-05-26 00:04:10 - progress_bar.py[line:272] - INFO: epoch 001:   1312 / 1732 loss=3.028, loss_v1=0, loss_v2=0, nll_loss=1.945, ntokens=1055.4, nsentences=32, sample_size=1055.4, sample_size_v1=0, sample_size_v2=0, ppl=3.85, wps=555.8, ups=0.53, wpb=1055.4, bsz=32, num_updates=1310, lr=1.26083e-05, gnorm=1.932, clip=100, loss_scale=128, train_wall=19, gb_free=11.4, wall=2465
2023-05-26 00:04:29 - progress_bar.py[line:272] - INFO: epoch 001:   1322 / 1732 loss=3.021, loss_v1=0, loss_v2=0, nll_loss=1.943, ntokens=1120.6, nsentences=32, sample_size=1120.6, sample_size_v1=0, sample_size_v2=0, ppl=3.85, wps=588.4, ups=0.53, wpb=1120.6, bsz=32, num_updates=1320, lr=1.27045e-05, gnorm=2.08, clip=100, loss_scale=128, train_wall=19, gb_free=10.6, wall=2484
2023-05-26 00:04:48 - progress_bar.py[line:272] - INFO: epoch 001:   1332 / 1732 loss=2.955, loss_v1=0, loss_v2=0, nll_loss=1.866, ntokens=1081, nsentences=32, sample_size=1081, sample_size_v1=0, sample_size_v2=0, ppl=3.64, wps=573, ups=0.53, wpb=1081, bsz=32, num_updates=1330, lr=1.28008e-05, gnorm=1.971, clip=100, loss_scale=128, train_wall=19, gb_free=11.1, wall=2503
2023-05-26 00:05:07 - progress_bar.py[line:272] - INFO: epoch 001:   1342 / 1732 loss=2.999, loss_v1=0, loss_v2=0, nll_loss=1.914, ntokens=1183.5, nsentences=32, sample_size=1183.5, sample_size_v1=0, sample_size_v2=0, ppl=3.77, wps=622.5, ups=0.53, wpb=1183.5, bsz=32, num_updates=1340, lr=1.2897e-05, gnorm=2.01, clip=100, loss_scale=128, train_wall=19, gb_free=10.4, wall=2522
2023-05-26 00:05:26 - progress_bar.py[line:272] - INFO: epoch 001:   1352 / 1732 loss=2.994, loss_v1=0, loss_v2=0, nll_loss=1.905, ntokens=1129.4, nsentences=32, sample_size=1129.4, sample_size_v1=0, sample_size_v2=0, ppl=3.75, wps=593.8, ups=0.53, wpb=1129.4, bsz=32, num_updates=1350, lr=1.29933e-05, gnorm=2.096, clip=100, loss_scale=128, train_wall=19, gb_free=11, wall=2541
2023-05-26 00:05:45 - progress_bar.py[line:272] - INFO: epoch 001:   1362 / 1732 loss=2.948, loss_v1=0, loss_v2=0, nll_loss=1.86, ntokens=1092.5, nsentences=32, sample_size=1092.5, sample_size_v1=0, sample_size_v2=0, ppl=3.63, wps=576.2, ups=0.53, wpb=1092.5, bsz=32, num_updates=1360, lr=1.30895e-05, gnorm=2.17, clip=100, loss_scale=128, train_wall=19, gb_free=10.3, wall=2560
2023-05-26 00:06:04 - progress_bar.py[line:272] - INFO: epoch 001:   1372 / 1732 loss=3.008, loss_v1=0, loss_v2=0, nll_loss=1.919, ntokens=1098.3, nsentences=32, sample_size=1098.3, sample_size_v1=0, sample_size_v2=0, ppl=3.78, wps=580.4, ups=0.53, wpb=1098.3, bsz=32, num_updates=1370, lr=1.31858e-05, gnorm=1.94, clip=100, loss_scale=128, train_wall=19, gb_free=11.6, wall=2579
2023-05-26 00:06:23 - progress_bar.py[line:272] - INFO: epoch 001:   1382 / 1732 loss=2.99, loss_v1=0, loss_v2=0, nll_loss=1.904, ntokens=1160, nsentences=32, sample_size=1160, sample_size_v1=0, sample_size_v2=0, ppl=3.74, wps=616.4, ups=0.53, wpb=1160, bsz=32, num_updates=1380, lr=1.3282e-05, gnorm=1.892, clip=100, loss_scale=128, train_wall=19, gb_free=10.9, wall=2597
2023-05-26 00:06:41 - progress_bar.py[line:272] - INFO: epoch 001:   1392 / 1732 loss=2.939, loss_v1=0, loss_v2=0, nll_loss=1.846, ntokens=1049.4, nsentences=32, sample_size=1049.4, sample_size_v1=0, sample_size_v2=0, ppl=3.6, wps=563, ups=0.54, wpb=1049.4, bsz=32, num_updates=1390, lr=1.33782e-05, gnorm=1.887, clip=100, loss_scale=128, train_wall=19, gb_free=11.2, wall=2616
2023-05-26 00:07:00 - progress_bar.py[line:272] - INFO: epoch 001:   1402 / 1732 loss=2.915, loss_v1=0, loss_v2=0, nll_loss=1.816, ntokens=1133.7, nsentences=32, sample_size=1133.7, sample_size_v1=0, sample_size_v2=0, ppl=3.52, wps=599.5, ups=0.53, wpb=1133.7, bsz=32, num_updates=1400, lr=1.34745e-05, gnorm=1.982, clip=100, loss_scale=128, train_wall=19, gb_free=10.2, wall=2635
2023-05-26 00:07:20 - progress_bar.py[line:272] - INFO: epoch 001:   1412 / 1732 loss=2.935, loss_v1=0, loss_v2=0, nll_loss=1.838, ntokens=1246.7, nsentences=32, sample_size=1246.7, sample_size_v1=0, sample_size_v2=0, ppl=3.57, wps=651.9, ups=0.52, wpb=1246.7, bsz=32, num_updates=1410, lr=1.35707e-05, gnorm=1.884, clip=100, loss_scale=128, train_wall=19, gb_free=10.8, wall=2654
2023-05-26 00:07:39 - progress_bar.py[line:272] - INFO: epoch 001:   1422 / 1732 loss=2.95, loss_v1=0, loss_v2=0, nll_loss=1.854, ntokens=1259.2, nsentences=32, sample_size=1259.2, sample_size_v1=0, sample_size_v2=0, ppl=3.61, wps=653.6, ups=0.52, wpb=1259.2, bsz=32, num_updates=1420, lr=1.3667e-05, gnorm=1.933, clip=100, loss_scale=128, train_wall=19, gb_free=10.7, wall=2673
2023-05-26 00:07:58 - progress_bar.py[line:272] - INFO: epoch 001:   1432 / 1732 loss=2.9, loss_v1=0, loss_v2=0, nll_loss=1.801, ntokens=1215.6, nsentences=32, sample_size=1215.6, sample_size_v1=0, sample_size_v2=0, ppl=3.48, wps=642.2, ups=0.53, wpb=1215.6, bsz=32, num_updates=1430, lr=1.37632e-05, gnorm=1.935, clip=100, loss_scale=128, train_wall=19, gb_free=11.2, wall=2692
2023-05-26 00:08:17 - progress_bar.py[line:272] - INFO: epoch 001:   1442 / 1732 loss=2.915, loss_v1=0, loss_v2=0, nll_loss=1.814, ntokens=1136.6, nsentences=32, sample_size=1136.6, sample_size_v1=0, sample_size_v2=0, ppl=3.52, wps=603.2, ups=0.53, wpb=1136.6, bsz=32, num_updates=1440, lr=1.38595e-05, gnorm=1.936, clip=100, loss_scale=128, train_wall=19, gb_free=11.2, wall=2711
2023-05-26 00:08:35 - progress_bar.py[line:272] - INFO: epoch 001:   1452 / 1732 loss=2.905, loss_v1=0, loss_v2=0, nll_loss=1.8, ntokens=1140.1, nsentences=32, sample_size=1140.1, sample_size_v1=0, sample_size_v2=0, ppl=3.48, wps=603.7, ups=0.53, wpb=1140.1, bsz=32, num_updates=1450, lr=1.39557e-05, gnorm=1.988, clip=100, loss_scale=128, train_wall=19, gb_free=11.7, wall=2730
2023-05-26 00:08:54 - progress_bar.py[line:272] - INFO: epoch 001:   1462 / 1732 loss=2.863, loss_v1=0, loss_v2=0, nll_loss=1.754, ntokens=1170.3, nsentences=32, sample_size=1170.3, sample_size_v1=0, sample_size_v2=0, ppl=3.37, wps=618.6, ups=0.53, wpb=1170.3, bsz=32, num_updates=1460, lr=1.4052e-05, gnorm=1.919, clip=100, loss_scale=128, train_wall=19, gb_free=10.6, wall=2749
2023-05-26 00:09:13 - progress_bar.py[line:272] - INFO: epoch 001:   1472 / 1732 loss=2.875, loss_v1=0, loss_v2=0, nll_loss=1.769, ntokens=1139, nsentences=32, sample_size=1139, sample_size_v1=0, sample_size_v2=0, ppl=3.41, wps=601.9, ups=0.53, wpb=1139, bsz=32, num_updates=1470, lr=1.41482e-05, gnorm=2.104, clip=100, loss_scale=128, train_wall=19, gb_free=11.7, wall=2768
2023-05-26 00:09:32 - progress_bar.py[line:272] - INFO: epoch 001:   1482 / 1732 loss=2.878, loss_v1=0, loss_v2=0, nll_loss=1.769, ntokens=1051.3, nsentences=32, sample_size=1051.3, sample_size_v1=0, sample_size_v2=0, ppl=3.41, wps=560.8, ups=0.53, wpb=1051.3, bsz=32, num_updates=1480, lr=1.42445e-05, gnorm=1.995, clip=100, loss_scale=128, train_wall=19, gb_free=10.6, wall=2787
2023-05-26 00:09:51 - progress_bar.py[line:272] - INFO: epoch 001:   1492 / 1732 loss=2.856, loss_v1=0, loss_v2=0, nll_loss=1.744, ntokens=1143, nsentences=32, sample_size=1143, sample_size_v1=0, sample_size_v2=0, ppl=3.35, wps=604.9, ups=0.53, wpb=1143, bsz=32, num_updates=1490, lr=1.43407e-05, gnorm=1.841, clip=100, loss_scale=128, train_wall=19, gb_free=11.5, wall=2806
2023-05-26 00:10:10 - progress_bar.py[line:272] - INFO: epoch 001:   1502 / 1732 loss=2.845, loss_v1=0, loss_v2=0, nll_loss=1.739, ntokens=1131.9, nsentences=32, sample_size=1131.9, sample_size_v1=0, sample_size_v2=0, ppl=3.34, wps=599.3, ups=0.53, wpb=1131.9, bsz=32, num_updates=1500, lr=1.4437e-05, gnorm=1.826, clip=100, loss_scale=128, train_wall=19, gb_free=10.3, wall=2824
2023-05-26 00:10:29 - progress_bar.py[line:272] - INFO: epoch 001:   1512 / 1732 loss=2.869, loss_v1=0, loss_v2=0, nll_loss=1.756, ntokens=1058.6, nsentences=32, sample_size=1058.6, sample_size_v1=0, sample_size_v2=0, ppl=3.38, wps=564.8, ups=0.53, wpb=1058.6, bsz=32, num_updates=1510, lr=1.45332e-05, gnorm=2.029, clip=100, loss_scale=128, train_wall=19, gb_free=10.8, wall=2843
2023-05-26 00:10:47 - progress_bar.py[line:272] - INFO: epoch 001:   1522 / 1732 loss=2.88, loss_v1=0, loss_v2=0, nll_loss=1.772, ntokens=1011, nsentences=32, sample_size=1011, sample_size_v1=0, sample_size_v2=0, ppl=3.42, wps=542.3, ups=0.54, wpb=1011, bsz=32, num_updates=1520, lr=1.46295e-05, gnorm=1.909, clip=100, loss_scale=128, train_wall=19, gb_free=11.8, wall=2862
2023-05-26 00:11:06 - progress_bar.py[line:272] - INFO: epoch 001:   1532 / 1732 loss=2.875, loss_v1=0, loss_v2=0, nll_loss=1.765, ntokens=1075.4, nsentences=32, sample_size=1075.4, sample_size_v1=0, sample_size_v2=0, ppl=3.4, wps=568.6, ups=0.53, wpb=1075.4, bsz=32, num_updates=1530, lr=1.47257e-05, gnorm=1.915, clip=100, loss_scale=128, train_wall=19, gb_free=10.7, wall=2881
2023-05-26 00:11:25 - progress_bar.py[line:272] - INFO: epoch 001:   1542 / 1732 loss=2.833, loss_v1=0, loss_v2=0, nll_loss=1.715, ntokens=1113.4, nsentences=32, sample_size=1113.4, sample_size_v1=0, sample_size_v2=0, ppl=3.28, wps=590, ups=0.53, wpb=1113.4, bsz=32, num_updates=1540, lr=1.48219e-05, gnorm=1.846, clip=100, loss_scale=128, train_wall=19, gb_free=11, wall=2900
2023-05-26 00:11:44 - progress_bar.py[line:272] - INFO: epoch 001:   1552 / 1732 loss=2.852, loss_v1=0, loss_v2=0, nll_loss=1.745, ntokens=1059, nsentences=32, sample_size=1059, sample_size_v1=0, sample_size_v2=0, ppl=3.35, wps=564.1, ups=0.53, wpb=1059, bsz=32, num_updates=1550, lr=1.49182e-05, gnorm=1.966, clip=100, loss_scale=128, train_wall=19, gb_free=11.3, wall=2918
2023-05-26 00:12:03 - progress_bar.py[line:272] - INFO: epoch 001:   1562 / 1732 loss=2.83, loss_v1=0, loss_v2=0, nll_loss=1.71, ntokens=1107.4, nsentences=32, sample_size=1107.4, sample_size_v1=0, sample_size_v2=0, ppl=3.27, wps=588.6, ups=0.53, wpb=1107.4, bsz=32, num_updates=1560, lr=1.50144e-05, gnorm=1.706, clip=100, loss_scale=128, train_wall=19, gb_free=11.2, wall=2937
2023-05-26 00:12:21 - progress_bar.py[line:272] - INFO: epoch 001:   1572 / 1732 loss=2.844, loss_v1=0, loss_v2=0, nll_loss=1.728, ntokens=1068.7, nsentences=32, sample_size=1068.7, sample_size_v1=0, sample_size_v2=0, ppl=3.31, wps=569.2, ups=0.53, wpb=1068.7, bsz=32, num_updates=1570, lr=1.51107e-05, gnorm=1.83, clip=100, loss_scale=128, train_wall=19, gb_free=11.6, wall=2956
2023-05-26 00:12:40 - progress_bar.py[line:272] - INFO: epoch 001:   1582 / 1732 loss=2.89, loss_v1=0, loss_v2=0, nll_loss=1.783, ntokens=1012.7, nsentences=32, sample_size=1012.7, sample_size_v1=0, sample_size_v2=0, ppl=3.44, wps=539.2, ups=0.53, wpb=1012.7, bsz=32, num_updates=1580, lr=1.52069e-05, gnorm=1.971, clip=100, loss_scale=128, train_wall=19, gb_free=10.6, wall=2975
2023-05-26 00:12:59 - progress_bar.py[line:272] - INFO: epoch 001:   1592 / 1732 loss=2.823, loss_v1=0, loss_v2=0, nll_loss=1.707, ntokens=1072.6, nsentences=32, sample_size=1072.6, sample_size_v1=0, sample_size_v2=0, ppl=3.26, wps=569.9, ups=0.53, wpb=1072.6, bsz=32, num_updates=1590, lr=1.53032e-05, gnorm=1.882, clip=100, loss_scale=128, train_wall=19, gb_free=11.6, wall=2994
2023-05-26 00:13:18 - progress_bar.py[line:272] - INFO: epoch 001:   1602 / 1732 loss=2.799, loss_v1=0, loss_v2=0, nll_loss=1.675, ntokens=1101.7, nsentences=32, sample_size=1101.7, sample_size_v1=0, sample_size_v2=0, ppl=3.19, wps=584.7, ups=0.53, wpb=1101.7, bsz=32, num_updates=1600, lr=1.53994e-05, gnorm=1.836, clip=100, loss_scale=128, train_wall=19, gb_free=10.5, wall=3013
2023-05-26 00:13:37 - progress_bar.py[line:272] - INFO: epoch 001:   1612 / 1732 loss=2.771, loss_v1=0, loss_v2=0, nll_loss=1.648, ntokens=1156, nsentences=32, sample_size=1156, sample_size_v1=0, sample_size_v2=0, ppl=3.13, wps=610.2, ups=0.53, wpb=1156, bsz=32, num_updates=1610, lr=1.54957e-05, gnorm=1.759, clip=100, loss_scale=256, train_wall=19, gb_free=11.4, wall=3031
2023-05-26 00:13:56 - progress_bar.py[line:272] - INFO: epoch 001:   1622 / 1732 loss=2.762, loss_v1=0, loss_v2=0, nll_loss=1.633, ntokens=1098.4, nsentences=32, sample_size=1098.4, sample_size_v1=0, sample_size_v2=0, ppl=3.1, wps=579.4, ups=0.53, wpb=1098.4, bsz=32, num_updates=1620, lr=1.55919e-05, gnorm=1.743, clip=100, loss_scale=256, train_wall=19, gb_free=11.5, wall=3050
2023-05-26 00:14:15 - progress_bar.py[line:272] - INFO: epoch 001:   1632 / 1732 loss=2.786, loss_v1=0, loss_v2=0, nll_loss=1.662, ntokens=1161.4, nsentences=32, sample_size=1161.4, sample_size_v1=0, sample_size_v2=0, ppl=3.16, wps=615.4, ups=0.53, wpb=1161.4, bsz=32, num_updates=1630, lr=1.56882e-05, gnorm=1.914, clip=100, loss_scale=256, train_wall=19, gb_free=11.6, wall=3069
2023-05-26 00:14:34 - progress_bar.py[line:272] - INFO: epoch 001:   1642 / 1732 loss=2.725, loss_v1=0, loss_v2=0, nll_loss=1.591, ntokens=1223.1, nsentences=32, sample_size=1223.1, sample_size_v1=0, sample_size_v2=0, ppl=3.01, wps=646.3, ups=0.53, wpb=1223.1, bsz=32, num_updates=1640, lr=1.57844e-05, gnorm=1.666, clip=100, loss_scale=256, train_wall=19, gb_free=10.9, wall=3088
2023-05-26 00:14:52 - progress_bar.py[line:272] - INFO: epoch 001:   1652 / 1732 loss=2.774, loss_v1=0, loss_v2=0, nll_loss=1.647, ntokens=1045.5, nsentences=32, sample_size=1045.5, sample_size_v1=0, sample_size_v2=0, ppl=3.13, wps=557.3, ups=0.53, wpb=1045.5, bsz=32, num_updates=1650, lr=1.58807e-05, gnorm=1.837, clip=100, loss_scale=256, train_wall=19, gb_free=11.2, wall=3107
2023-05-26 00:15:11 - progress_bar.py[line:272] - INFO: epoch 001:   1662 / 1732 loss=2.792, loss_v1=0, loss_v2=0, nll_loss=1.664, ntokens=1037.9, nsentences=32, sample_size=1037.9, sample_size_v1=0, sample_size_v2=0, ppl=3.17, wps=550.7, ups=0.53, wpb=1037.9, bsz=32, num_updates=1660, lr=1.59769e-05, gnorm=1.81, clip=100, loss_scale=256, train_wall=19, gb_free=11.4, wall=3126
2023-05-26 00:15:30 - progress_bar.py[line:272] - INFO: epoch 001:   1672 / 1732 loss=2.769, loss_v1=0, loss_v2=0, nll_loss=1.642, ntokens=1009.9, nsentences=32, sample_size=1009.9, sample_size_v1=0, sample_size_v2=0, ppl=3.12, wps=539.7, ups=0.53, wpb=1009.9, bsz=32, num_updates=1670, lr=1.60731e-05, gnorm=1.786, clip=100, loss_scale=256, train_wall=19, gb_free=10.9, wall=3145
2023-05-26 00:15:49 - progress_bar.py[line:272] - INFO: epoch 001:   1682 / 1732 loss=2.76, loss_v1=0, loss_v2=0, nll_loss=1.631, ntokens=1181.4, nsentences=32, sample_size=1181.4, sample_size_v1=0, sample_size_v2=0, ppl=3.1, wps=620.9, ups=0.53, wpb=1181.4, bsz=32, num_updates=1680, lr=1.61694e-05, gnorm=1.773, clip=100, loss_scale=256, train_wall=19, gb_free=11.3, wall=3164
2023-05-26 00:16:08 - progress_bar.py[line:272] - INFO: epoch 001:   1692 / 1732 loss=2.745, loss_v1=0, loss_v2=0, nll_loss=1.614, ntokens=1233.5, nsentences=32, sample_size=1233.5, sample_size_v1=0, sample_size_v2=0, ppl=3.06, wps=643.6, ups=0.52, wpb=1233.5, bsz=32, num_updates=1690, lr=1.62656e-05, gnorm=1.729, clip=100, loss_scale=256, train_wall=19, gb_free=10.8, wall=3183
2023-05-26 00:16:27 - progress_bar.py[line:272] - INFO: epoch 001:   1702 / 1732 loss=2.751, loss_v1=0, loss_v2=0, nll_loss=1.618, ntokens=1273, nsentences=32, sample_size=1273, sample_size_v1=0, sample_size_v2=0, ppl=3.07, wps=666.1, ups=0.52, wpb=1273, bsz=32, num_updates=1700, lr=1.63619e-05, gnorm=1.709, clip=100, loss_scale=256, train_wall=19, gb_free=10.7, wall=3202
2023-05-26 00:16:46 - progress_bar.py[line:272] - INFO: epoch 001:   1712 / 1732 loss=2.759, loss_v1=0, loss_v2=0, nll_loss=1.626, ntokens=1144.5, nsentences=32, sample_size=1144.5, sample_size_v1=0, sample_size_v2=0, ppl=3.09, wps=606.8, ups=0.53, wpb=1144.5, bsz=32, num_updates=1710, lr=1.64581e-05, gnorm=1.841, clip=100, loss_scale=256, train_wall=19, gb_free=11.4, wall=3221
2023-05-26 00:17:05 - progress_bar.py[line:272] - INFO: epoch 001:   1722 / 1732 loss=2.73, loss_v1=0, loss_v2=0, nll_loss=1.596, ntokens=1176.1, nsentences=32, sample_size=1176.1, sample_size_v1=0, sample_size_v2=0, ppl=3.02, wps=619.4, ups=0.53, wpb=1176.1, bsz=32, num_updates=1720, lr=1.65544e-05, gnorm=1.707, clip=100, loss_scale=256, train_wall=19, gb_free=11.3, wall=3240
2023-05-26 00:17:23 - progress_bar.py[line:272] - INFO: epoch 001:   1732 / 1732 loss=2.777, loss_v1=0, loss_v2=0, nll_loss=1.646, ntokens=1056.7, nsentences=29.6, sample_size=1056.7, sample_size_v1=0, sample_size_v2=0, ppl=3.13, wps=604.5, ups=0.57, wpb=1056.7, bsz=29.6, num_updates=1730, lr=1.66506e-05, gnorm=1.756, clip=100, loss_scale=256, train_wall=17, gb_free=11.7, wall=3257
2023-05-26 00:17:23 - train.py[line:332] - INFO: end of epoch 1 (average epoch stats below)
2023-05-26 00:17:23 - progress_bar.py[line:282] - INFO: epoch 001 | loss 4.864 | loss_v1 0 | loss_v2 0 | nll_loss 4.062 | ntokens 1051.34 | nsentences 31.986 | sample_size 1051.34 | sample_size_v1 0 | sample_size_v2 0 | ppl 16.7 | wps 560.6 | ups 0.53 | wpb 1051.3 | bsz 32 | num_updates 1730 | lr 1.66506e-05 | gnorm 4.919 | clip 100 | loss_scale 256 | train_wall 3242 | gb_free 11.7 | wall 3257
2023-05-26 00:17:23 - trainer.py[line:639] - INFO: loading train data for epoch 2
local datafile ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 0 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 0 finished initializing row_count and line_idx-to-offset mapping
file ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 0 row count 55400 total row count 55400
/data/hulab/zcai75/anaconda3/envs/vilt/lib/python3.8/site-packages/torchvision/transforms/transforms.py:332: UserWarning: Argument 'interpolation' of type int is deprecated since 0.13 and will be removed in 0.15. Please use InterpolationMode enum.
  warnings.warn(
slice_id 0 seek offset 0
2023-05-26 00:17:25 - trainer.py[line:703] - INFO: begin training epoch 2
2023-05-26 00:17:25 - train.py[line:305] - INFO: Start iterating over samples
2023-05-26 00:17:44 - progress_bar.py[line:272] - INFO: epoch 002:     10 / 1732 loss=2.698, loss_v1=0, loss_v2=0, nll_loss=1.561, ntokens=1132.5, nsentences=32, sample_size=1132.5, sample_size_v1=0, sample_size_v2=0, ppl=2.95, wps=533.4, ups=0.47, wpb=1132.5, bsz=32, num_updates=1740, lr=1.67469e-05, gnorm=1.964, clip=100, loss_scale=256, train_wall=19, gb_free=10.2, wall=3278
2023-05-26 00:18:03 - progress_bar.py[line:272] - INFO: epoch 002:     20 / 1732 loss=2.587, loss_v1=0, loss_v2=0, nll_loss=1.43, ntokens=1079.2, nsentences=32, sample_size=1079.2, sample_size_v1=0, sample_size_v2=0, ppl=2.69, wps=573.9, ups=0.53, wpb=1079.2, bsz=32, num_updates=1750, lr=1.68431e-05, gnorm=2.003, clip=100, loss_scale=256, train_wall=19, gb_free=11.4, wall=3297
2023-05-26 00:18:21 - progress_bar.py[line:272] - INFO: epoch 002:     30 / 1732 loss=2.67, loss_v1=0, loss_v2=0, nll_loss=1.52, ntokens=962.6, nsentences=32, sample_size=962.6, sample_size_v1=0, sample_size_v2=0, ppl=2.87, wps=513.9, ups=0.53, wpb=962.6, bsz=32, num_updates=1760, lr=1.69394e-05, gnorm=2.406, clip=100, loss_scale=256, train_wall=19, gb_free=11.3, wall=3316
2023-05-26 00:18:40 - progress_bar.py[line:272] - INFO: epoch 002:     40 / 1732 loss=2.465, loss_v1=0, loss_v2=0, nll_loss=1.297, ntokens=1211.6, nsentences=32, sample_size=1211.6, sample_size_v1=0, sample_size_v2=0, ppl=2.46, wps=634.6, ups=0.52, wpb=1211.6, bsz=32, num_updates=1770, lr=1.70356e-05, gnorm=1.856, clip=100, loss_scale=256, train_wall=19, gb_free=11.3, wall=3335
2023-05-26 00:18:59 - progress_bar.py[line:272] - INFO: epoch 002:     50 / 1732 loss=2.619, loss_v1=0, loss_v2=0, nll_loss=1.458, ntokens=1054.8, nsentences=32, sample_size=1054.8, sample_size_v1=0, sample_size_v2=0, ppl=2.75, wps=559.4, ups=0.53, wpb=1054.8, bsz=32, num_updates=1780, lr=1.71319e-05, gnorm=2.389, clip=100, loss_scale=256, train_wall=19, gb_free=11.1, wall=3354
2023-05-26 00:19:18 - progress_bar.py[line:272] - INFO: epoch 002:     60 / 1732 loss=2.309, loss_v1=0, loss_v2=0, nll_loss=1.121, ntokens=1049.9, nsentences=32, sample_size=1049.9, sample_size_v1=0, sample_size_v2=0, ppl=2.17, wps=562.9, ups=0.54, wpb=1049.9, bsz=32, num_updates=1790, lr=1.72281e-05, gnorm=1.937, clip=100, loss_scale=256, train_wall=19, gb_free=10.3, wall=3373
2023-05-26 00:19:37 - progress_bar.py[line:272] - INFO: epoch 002:     70 / 1732 loss=2.394, loss_v1=0, loss_v2=0, nll_loss=1.206, ntokens=1412, nsentences=32, sample_size=1412, sample_size_v1=0, sample_size_v2=0, ppl=2.31, wps=723.1, ups=0.51, wpb=1412, bsz=32, num_updates=1800, lr=1.73244e-05, gnorm=1.772, clip=100, loss_scale=256, train_wall=19, gb_free=10.8, wall=3392
2023-05-26 00:19:57 - progress_bar.py[line:272] - INFO: epoch 002:     80 / 1732 loss=2.48, loss_v1=0, loss_v2=0, nll_loss=1.309, ntokens=1259.9, nsentences=32, sample_size=1259.9, sample_size_v1=0, sample_size_v2=0, ppl=2.48, wps=649.2, ups=0.52, wpb=1259.9, bsz=32, num_updates=1810, lr=1.74206e-05, gnorm=1.957, clip=100, loss_scale=256, train_wall=19, gb_free=10.6, wall=3412
2023-05-26 00:20:16 - progress_bar.py[line:272] - INFO: epoch 002:     90 / 1732 loss=2.57, loss_v1=0, loss_v2=0, nll_loss=1.409, ntokens=1086.9, nsentences=32, sample_size=1086.9, sample_size_v1=0, sample_size_v2=0, ppl=2.66, wps=571, ups=0.53, wpb=1086.9, bsz=32, num_updates=1820, lr=1.75168e-05, gnorm=1.763, clip=100, loss_scale=256, train_wall=19, gb_free=11, wall=3431
2023-05-26 00:20:35 - progress_bar.py[line:272] - INFO: epoch 002:    100 / 1732 loss=2.558, loss_v1=0, loss_v2=0, nll_loss=1.404, ntokens=1024.5, nsentences=32, sample_size=1024.5, sample_size_v1=0, sample_size_v2=0, ppl=2.65, wps=547.6, ups=0.53, wpb=1024.5, bsz=32, num_updates=1830, lr=1.76131e-05, gnorm=2.295, clip=100, loss_scale=256, train_wall=19, gb_free=10.9, wall=3449
2023-05-26 00:20:53 - progress_bar.py[line:272] - INFO: epoch 002:    110 / 1732 loss=2.732, loss_v1=0, loss_v2=0, nll_loss=1.592, ntokens=1011.2, nsentences=32, sample_size=1011.2, sample_size_v1=0, sample_size_v2=0, ppl=3.01, wps=538.1, ups=0.53, wpb=1011.2, bsz=32, num_updates=1840, lr=1.77093e-05, gnorm=1.858, clip=100, loss_scale=256, train_wall=19, gb_free=11, wall=3468
2023-05-26 00:21:13 - progress_bar.py[line:272] - INFO: epoch 002:    120 / 1732 loss=2.658, loss_v1=0, loss_v2=0, nll_loss=1.508, ntokens=1124.3, nsentences=32, sample_size=1124.3, sample_size_v1=0, sample_size_v2=0, ppl=2.84, wps=587.6, ups=0.52, wpb=1124.3, bsz=32, num_updates=1850, lr=1.78056e-05, gnorm=1.557, clip=100, loss_scale=256, train_wall=19, gb_free=10.6, wall=3487
2023-05-26 00:21:32 - progress_bar.py[line:272] - INFO: epoch 002:    130 / 1732 loss=2.638, loss_v1=0, loss_v2=0, nll_loss=1.485, ntokens=1171.7, nsentences=32, sample_size=1171.7, sample_size_v1=0, sample_size_v2=0, ppl=2.8, wps=610.9, ups=0.52, wpb=1171.7, bsz=32, num_updates=1860, lr=1.79018e-05, gnorm=1.481, clip=100, loss_scale=256, train_wall=19, gb_free=10.2, wall=3506
2023-05-26 00:21:51 - progress_bar.py[line:272] - INFO: epoch 002:    140 / 1732 loss=2.596, loss_v1=0, loss_v2=0, nll_loss=1.437, ntokens=1245, nsentences=32, sample_size=1245, sample_size_v1=0, sample_size_v2=0, ppl=2.71, wps=651.2, ups=0.52, wpb=1245, bsz=32, num_updates=1870, lr=1.79981e-05, gnorm=1.571, clip=100, loss_scale=256, train_wall=19, gb_free=10.2, wall=3526
2023-05-26 00:22:10 - progress_bar.py[line:272] - INFO: epoch 002:    150 / 1732 loss=2.575, loss_v1=0, loss_v2=0, nll_loss=1.415, ntokens=1172.1, nsentences=32, sample_size=1172.1, sample_size_v1=0, sample_size_v2=0, ppl=2.67, wps=609.7, ups=0.52, wpb=1172.1, bsz=32, num_updates=1880, lr=1.80943e-05, gnorm=1.472, clip=100, loss_scale=256, train_wall=19, gb_free=11, wall=3545
2023-05-26 00:22:29 - progress_bar.py[line:272] - INFO: epoch 002:    160 / 1732 loss=2.582, loss_v1=0, loss_v2=0, nll_loss=1.423, ntokens=1127.8, nsentences=32, sample_size=1127.8, sample_size_v1=0, sample_size_v2=0, ppl=2.68, wps=590.8, ups=0.52, wpb=1127.8, bsz=32, num_updates=1890, lr=1.81906e-05, gnorm=1.595, clip=100, loss_scale=256, train_wall=19, gb_free=10.9, wall=3564
2023-05-26 00:22:48 - progress_bar.py[line:272] - INFO: epoch 002:    170 / 1732 loss=2.567, loss_v1=0, loss_v2=0, nll_loss=1.401, ntokens=965.3, nsentences=32, sample_size=965.3, sample_size_v1=0, sample_size_v2=0, ppl=2.64, wps=511.6, ups=0.53, wpb=965.3, bsz=32, num_updates=1900, lr=1.82868e-05, gnorm=1.713, clip=100, loss_scale=256, train_wall=19, gb_free=11.4, wall=3583
2023-05-26 00:23:07 - progress_bar.py[line:272] - INFO: epoch 002:    180 / 1732 loss=2.53, loss_v1=0, loss_v2=0, nll_loss=1.363, ntokens=1102.7, nsentences=32, sample_size=1102.7, sample_size_v1=0, sample_size_v2=0, ppl=2.57, wps=579.8, ups=0.53, wpb=1102.7, bsz=32, num_updates=1910, lr=1.83831e-05, gnorm=1.776, clip=100, loss_scale=256, train_wall=19, gb_free=10.9, wall=3602
2023-05-26 00:23:26 - progress_bar.py[line:272] - INFO: epoch 002:    190 / 1732 loss=2.577, loss_v1=0, loss_v2=0, nll_loss=1.417, ntokens=1120.1, nsentences=32, sample_size=1120.1, sample_size_v1=0, sample_size_v2=0, ppl=2.67, wps=588, ups=0.52, wpb=1120.1, bsz=32, num_updates=1920, lr=1.84793e-05, gnorm=1.613, clip=100, loss_scale=256, train_wall=19, gb_free=10.7, wall=3621
2023-05-26 00:23:45 - progress_bar.py[line:272] - INFO: epoch 002:    200 / 1732 loss=2.608, loss_v1=0, loss_v2=0, nll_loss=1.45, ntokens=1100.1, nsentences=32, sample_size=1100.1, sample_size_v1=0, sample_size_v2=0, ppl=2.73, wps=583.1, ups=0.53, wpb=1100.1, bsz=32, num_updates=1930, lr=1.85756e-05, gnorm=1.629, clip=100, loss_scale=256, train_wall=19, gb_free=11.7, wall=3640
2023-05-26 00:24:04 - progress_bar.py[line:272] - INFO: epoch 002:    210 / 1732 loss=2.733, loss_v1=0, loss_v2=0, nll_loss=1.592, ntokens=1012.9, nsentences=32, sample_size=1012.9, sample_size_v1=0, sample_size_v2=0, ppl=3.01, wps=543.9, ups=0.54, wpb=1012.9, bsz=32, num_updates=1940, lr=1.86718e-05, gnorm=1.783, clip=100, loss_scale=256, train_wall=19, gb_free=11.3, wall=3658
2023-05-26 00:24:22 - progress_bar.py[line:272] - INFO: epoch 002:    220 / 1732 loss=2.723, loss_v1=0, loss_v2=0, nll_loss=1.583, ntokens=1142.1, nsentences=32, sample_size=1142.1, sample_size_v1=0, sample_size_v2=0, ppl=2.99, wps=611.5, ups=0.54, wpb=1142.1, bsz=32, num_updates=1950, lr=1.8768e-05, gnorm=1.617, clip=100, loss_scale=256, train_wall=19, gb_free=11.2, wall=3677
2023-05-26 00:24:41 - progress_bar.py[line:272] - INFO: epoch 002:    230 / 1732 loss=2.756, loss_v1=0, loss_v2=0, nll_loss=1.618, ntokens=1099.8, nsentences=32, sample_size=1099.8, sample_size_v1=0, sample_size_v2=0, ppl=3.07, wps=587.6, ups=0.53, wpb=1099.8, bsz=32, num_updates=1960, lr=1.88643e-05, gnorm=1.714, clip=100, loss_scale=256, train_wall=19, gb_free=11, wall=3696
2023-05-26 00:25:00 - progress_bar.py[line:272] - INFO: epoch 002:    240 / 1732 loss=2.772, loss_v1=0, loss_v2=0, nll_loss=1.633, ntokens=1111.4, nsentences=32, sample_size=1111.4, sample_size_v1=0, sample_size_v2=0, ppl=3.1, wps=593.2, ups=0.53, wpb=1111.4, bsz=32, num_updates=1970, lr=1.89605e-05, gnorm=1.625, clip=100, loss_scale=256, train_wall=19, gb_free=10.9, wall=3714
2023-05-26 00:25:19 - progress_bar.py[line:272] - INFO: epoch 002:    250 / 1732 loss=2.721, loss_v1=0, loss_v2=0, nll_loss=1.578, ntokens=1170.4, nsentences=32, sample_size=1170.4, sample_size_v1=0, sample_size_v2=0, ppl=2.99, wps=620.6, ups=0.53, wpb=1170.4, bsz=32, num_updates=1980, lr=1.90568e-05, gnorm=1.568, clip=100, loss_scale=256, train_wall=19, gb_free=11.1, wall=3733
2023-05-26 00:25:37 - progress_bar.py[line:272] - INFO: epoch 002:    260 / 1732 loss=2.741, loss_v1=0, loss_v2=0, nll_loss=1.605, ntokens=1120.1, nsentences=32, sample_size=1120.1, sample_size_v1=0, sample_size_v2=0, ppl=3.04, wps=599.7, ups=0.54, wpb=1120.1, bsz=32, num_updates=1990, lr=1.9153e-05, gnorm=1.64, clip=100, loss_scale=256, train_wall=19, gb_free=11.5, wall=3752
2023-05-26 00:25:56 - progress_bar.py[line:272] - INFO: epoch 002:    270 / 1732 loss=2.713, loss_v1=0, loss_v2=0, nll_loss=1.567, ntokens=1146.7, nsentences=32, sample_size=1146.7, sample_size_v1=0, sample_size_v2=0, ppl=2.96, wps=611.2, ups=0.53, wpb=1146.7, bsz=32, num_updates=2000, lr=1.92493e-05, gnorm=1.46, clip=100, loss_scale=256, train_wall=19, gb_free=10.9, wall=3771
2023-05-26 00:26:15 - progress_bar.py[line:272] - INFO: epoch 002:    280 / 1732 loss=2.718, loss_v1=0, loss_v2=0, nll_loss=1.574, ntokens=1171.6, nsentences=32, sample_size=1171.6, sample_size_v1=0, sample_size_v2=0, ppl=2.98, wps=621.4, ups=0.53, wpb=1171.6, bsz=32, num_updates=2010, lr=1.93455e-05, gnorm=1.535, clip=100, loss_scale=256, train_wall=19, gb_free=11, wall=3790
2023-05-26 00:26:34 - progress_bar.py[line:272] - INFO: epoch 002:    290 / 1732 loss=2.692, loss_v1=0, loss_v2=0, nll_loss=1.547, ntokens=1121.4, nsentences=32, sample_size=1121.4, sample_size_v1=0, sample_size_v2=0, ppl=2.92, wps=597.8, ups=0.53, wpb=1121.4, bsz=32, num_updates=2020, lr=1.94418e-05, gnorm=1.484, clip=100, loss_scale=256, train_wall=19, gb_free=11.8, wall=3808
2023-05-26 00:26:52 - progress_bar.py[line:272] - INFO: epoch 002:    300 / 1732 loss=2.722, loss_v1=0, loss_v2=0, nll_loss=1.578, ntokens=1116.4, nsentences=32, sample_size=1116.4, sample_size_v1=0, sample_size_v2=0, ppl=2.99, wps=595.5, ups=0.53, wpb=1116.4, bsz=32, num_updates=2030, lr=1.9538e-05, gnorm=1.495, clip=100, loss_scale=256, train_wall=19, gb_free=10.6, wall=3827
2023-05-26 00:27:11 - progress_bar.py[line:272] - INFO: epoch 002:    310 / 1732 loss=2.674, loss_v1=0, loss_v2=0, nll_loss=1.526, ntokens=1069.4, nsentences=32, sample_size=1069.4, sample_size_v1=0, sample_size_v2=0, ppl=2.88, wps=571.7, ups=0.53, wpb=1069.4, bsz=32, num_updates=2040, lr=1.96343e-05, gnorm=1.608, clip=100, loss_scale=256, train_wall=19, gb_free=10.8, wall=3846
2023-05-26 00:27:30 - progress_bar.py[line:272] - INFO: epoch 002:    320 / 1732 loss=2.715, loss_v1=0, loss_v2=0, nll_loss=1.567, ntokens=1013.1, nsentences=32, sample_size=1013.1, sample_size_v1=0, sample_size_v2=0, ppl=2.96, wps=545.9, ups=0.54, wpb=1013.1, bsz=32, num_updates=2050, lr=1.97305e-05, gnorm=1.633, clip=100, loss_scale=256, train_wall=19, gb_free=11.3, wall=3864
2023-05-26 00:27:48 - progress_bar.py[line:272] - INFO: epoch 002:    330 / 1732 loss=2.717, loss_v1=0, loss_v2=0, nll_loss=1.572, ntokens=1024.4, nsentences=32, sample_size=1024.4, sample_size_v1=0, sample_size_v2=0, ppl=2.97, wps=551.9, ups=0.54, wpb=1024.4, bsz=32, num_updates=2060, lr=1.98268e-05, gnorm=1.564, clip=100, loss_scale=256, train_wall=19, gb_free=11.1, wall=3883
2023-05-26 00:28:07 - progress_bar.py[line:272] - INFO: epoch 002:    340 / 1732 loss=2.673, loss_v1=0, loss_v2=0, nll_loss=1.526, ntokens=959.9, nsentences=32, sample_size=959.9, sample_size_v1=0, sample_size_v2=0, ppl=2.88, wps=518.8, ups=0.54, wpb=959.9, bsz=32, num_updates=2070, lr=1.9923e-05, gnorm=1.588, clip=100, loss_scale=256, train_wall=18, gb_free=11.4, wall=3901
2023-05-26 00:28:25 - progress_bar.py[line:272] - INFO: epoch 002:    350 / 1732 loss=2.675, loss_v1=0, loss_v2=0, nll_loss=1.522, ntokens=909.7, nsentences=32, sample_size=909.7, sample_size_v1=0, sample_size_v2=0, ppl=2.87, wps=491.6, ups=0.54, wpb=909.7, bsz=32, num_updates=2080, lr=2.00192e-05, gnorm=1.698, clip=100, loss_scale=256, train_wall=18, gb_free=11.7, wall=3920
2023-05-26 00:28:44 - progress_bar.py[line:272] - INFO: epoch 002:    360 / 1732 loss=2.703, loss_v1=0, loss_v2=0, nll_loss=1.555, ntokens=938.9, nsentences=32, sample_size=938.9, sample_size_v1=0, sample_size_v2=0, ppl=2.94, wps=506.9, ups=0.54, wpb=938.9, bsz=32, num_updates=2090, lr=2.01155e-05, gnorm=1.585, clip=100, loss_scale=256, train_wall=18, gb_free=11.6, wall=3938
2023-05-26 00:29:02 - progress_bar.py[line:272] - INFO: epoch 002:    370 / 1732 loss=2.715, loss_v1=0, loss_v2=0, nll_loss=1.569, ntokens=953.9, nsentences=32, sample_size=953.9, sample_size_v1=0, sample_size_v2=0, ppl=2.97, wps=516.2, ups=0.54, wpb=953.9, bsz=32, num_updates=2100, lr=2.02117e-05, gnorm=1.661, clip=100, loss_scale=256, train_wall=18, gb_free=12, wall=3957
2023-05-26 00:29:21 - progress_bar.py[line:272] - INFO: epoch 002:    380 / 1732 loss=2.705, loss_v1=0, loss_v2=0, nll_loss=1.556, ntokens=1091.6, nsentences=32, sample_size=1091.6, sample_size_v1=0, sample_size_v2=0, ppl=2.94, wps=587.7, ups=0.54, wpb=1091.6, bsz=32, num_updates=2110, lr=2.0308e-05, gnorm=1.484, clip=100, loss_scale=256, train_wall=19, gb_free=11.7, wall=3976
2023-05-26 00:29:39 - progress_bar.py[line:272] - INFO: epoch 002:    390 / 1732 loss=2.689, loss_v1=0, loss_v2=0, nll_loss=1.539, ntokens=1027.2, nsentences=32, sample_size=1027.2, sample_size_v1=0, sample_size_v2=0, ppl=2.91, wps=552.7, ups=0.54, wpb=1027.2, bsz=32, num_updates=2120, lr=2.04042e-05, gnorm=1.608, clip=100, loss_scale=512, train_wall=19, gb_free=11.5, wall=3994
2023-05-26 00:29:58 - progress_bar.py[line:272] - INFO: epoch 002:    400 / 1732 loss=2.659, loss_v1=0, loss_v2=0, nll_loss=1.505, ntokens=977.7, nsentences=32, sample_size=977.7, sample_size_v1=0, sample_size_v2=0, ppl=2.84, wps=527.9, ups=0.54, wpb=977.7, bsz=32, num_updates=2130, lr=2.05005e-05, gnorm=1.632, clip=100, loss_scale=512, train_wall=18, gb_free=11.4, wall=4013
2023-05-26 00:30:17 - progress_bar.py[line:272] - INFO: epoch 002:    410 / 1732 loss=2.661, loss_v1=0, loss_v2=0, nll_loss=1.506, ntokens=1069.8, nsentences=32, sample_size=1069.8, sample_size_v1=0, sample_size_v2=0, ppl=2.84, wps=574.8, ups=0.54, wpb=1069.8, bsz=32, num_updates=2140, lr=2.05967e-05, gnorm=1.583, clip=100, loss_scale=512, train_wall=19, gb_free=11.5, wall=4031
2023-05-26 00:30:35 - progress_bar.py[line:272] - INFO: epoch 002:    420 / 1732 loss=2.64, loss_v1=0, loss_v2=0, nll_loss=1.485, ntokens=1036.4, nsentences=32, sample_size=1036.4, sample_size_v1=0, sample_size_v2=0, ppl=2.8, wps=556.3, ups=0.54, wpb=1036.4, bsz=32, num_updates=2150, lr=2.0693e-05, gnorm=1.629, clip=100, loss_scale=512, train_wall=19, gb_free=10.7, wall=4050
2023-05-26 00:30:54 - progress_bar.py[line:272] - INFO: epoch 002:    430 / 1732 loss=2.655, loss_v1=0, loss_v2=0, nll_loss=1.498, ntokens=1013.2, nsentences=32, sample_size=1013.2, sample_size_v1=0, sample_size_v2=0, ppl=2.83, wps=544.9, ups=0.54, wpb=1013.2, bsz=32, num_updates=2160, lr=2.07892e-05, gnorm=1.684, clip=100, loss_scale=512, train_wall=19, gb_free=11.1, wall=4069
2023-05-26 00:31:12 - progress_bar.py[line:272] - INFO: epoch 002:    440 / 1732 loss=2.672, loss_v1=0, loss_v2=0, nll_loss=1.52, ntokens=989.2, nsentences=32, sample_size=989.2, sample_size_v1=0, sample_size_v2=0, ppl=2.87, wps=533.5, ups=0.54, wpb=989.2, bsz=32, num_updates=2170, lr=2.08855e-05, gnorm=1.471, clip=100, loss_scale=512, train_wall=19, gb_free=11.7, wall=4087
2023-05-26 00:31:31 - progress_bar.py[line:272] - INFO: epoch 002:    450 / 1732 loss=2.674, loss_v1=0, loss_v2=0, nll_loss=1.52, ntokens=915.3, nsentences=32, sample_size=915.3, sample_size_v1=0, sample_size_v2=0, ppl=2.87, wps=493.9, ups=0.54, wpb=915.3, bsz=32, num_updates=2180, lr=2.09817e-05, gnorm=1.636, clip=100, loss_scale=512, train_wall=19, gb_free=11.8, wall=4106
2023-05-26 00:31:49 - progress_bar.py[line:272] - INFO: epoch 002:    460 / 1732 loss=2.662, loss_v1=0, loss_v2=0, nll_loss=1.51, ntokens=1040.5, nsentences=32, sample_size=1040.5, sample_size_v1=0, sample_size_v2=0, ppl=2.85, wps=561.1, ups=0.54, wpb=1040.5, bsz=32, num_updates=2190, lr=2.1078e-05, gnorm=1.537, clip=100, loss_scale=512, train_wall=19, gb_free=11.3, wall=4124
2023-05-26 00:32:08 - progress_bar.py[line:272] - INFO: epoch 002:    470 / 1732 loss=2.663, loss_v1=0, loss_v2=0, nll_loss=1.503, ntokens=1036.3, nsentences=32, sample_size=1036.3, sample_size_v1=0, sample_size_v2=0, ppl=2.83, wps=553.1, ups=0.53, wpb=1036.3, bsz=32, num_updates=2200, lr=2.11742e-05, gnorm=1.57, clip=100, loss_scale=512, train_wall=19, gb_free=11.8, wall=4143
2023-05-26 00:32:27 - progress_bar.py[line:272] - INFO: epoch 002:    480 / 1732 loss=2.671, loss_v1=0, loss_v2=0, nll_loss=1.518, ntokens=1040.5, nsentences=32, sample_size=1040.5, sample_size_v1=0, sample_size_v2=0, ppl=2.86, wps=559.7, ups=0.54, wpb=1040.5, bsz=32, num_updates=2210, lr=2.12705e-05, gnorm=1.53, clip=100, loss_scale=512, train_wall=19, gb_free=9.9, wall=4161
2023-05-26 00:32:45 - progress_bar.py[line:272] - INFO: epoch 002:    490 / 1732 loss=2.641, loss_v1=0, loss_v2=0, nll_loss=1.486, ntokens=919.9, nsentences=32, sample_size=919.9, sample_size_v1=0, sample_size_v2=0, ppl=2.8, wps=497.5, ups=0.54, wpb=919.9, bsz=32, num_updates=2220, lr=2.13667e-05, gnorm=1.602, clip=100, loss_scale=512, train_wall=18, gb_free=10.5, wall=4180
2023-05-26 00:33:04 - progress_bar.py[line:272] - INFO: epoch 002:    500 / 1732 loss=2.632, loss_v1=0, loss_v2=0, nll_loss=1.469, ntokens=950.8, nsentences=32, sample_size=950.8, sample_size_v1=0, sample_size_v2=0, ppl=2.77, wps=514.8, ups=0.54, wpb=950.8, bsz=32, num_updates=2230, lr=2.14629e-05, gnorm=1.588, clip=100, loss_scale=512, train_wall=18, gb_free=11.5, wall=4198
2023-05-26 00:33:22 - progress_bar.py[line:272] - INFO: epoch 002:    510 / 1732 loss=2.666, loss_v1=0, loss_v2=0, nll_loss=1.513, ntokens=1039.6, nsentences=32, sample_size=1039.6, sample_size_v1=0, sample_size_v2=0, ppl=2.85, wps=559, ups=0.54, wpb=1039.6, bsz=32, num_updates=2240, lr=2.15592e-05, gnorm=1.489, clip=100, loss_scale=512, train_wall=19, gb_free=10.9, wall=4217
2023-05-26 00:33:41 - progress_bar.py[line:272] - INFO: epoch 002:    520 / 1732 loss=2.639, loss_v1=0, loss_v2=0, nll_loss=1.48, ntokens=1010.1, nsentences=32, sample_size=1010.1, sample_size_v1=0, sample_size_v2=0, ppl=2.79, wps=546.8, ups=0.54, wpb=1010.1, bsz=32, num_updates=2250, lr=2.16554e-05, gnorm=1.555, clip=100, loss_scale=512, train_wall=18, gb_free=11.7, wall=4236
2023-05-26 00:33:59 - progress_bar.py[line:272] - INFO: epoch 002:    530 / 1732 loss=2.64, loss_v1=0, loss_v2=0, nll_loss=1.477, ntokens=937.1, nsentences=32, sample_size=937.1, sample_size_v1=0, sample_size_v2=0, ppl=2.78, wps=508.3, ups=0.54, wpb=937.1, bsz=32, num_updates=2260, lr=2.17517e-05, gnorm=1.547, clip=100, loss_scale=512, train_wall=18, gb_free=11.5, wall=4254
2023-05-26 00:34:18 - progress_bar.py[line:272] - INFO: epoch 002:    540 / 1732 loss=2.637, loss_v1=0, loss_v2=0, nll_loss=1.479, ntokens=998.6, nsentences=32, sample_size=998.6, sample_size_v1=0, sample_size_v2=0, ppl=2.79, wps=539.9, ups=0.54, wpb=998.6, bsz=32, num_updates=2270, lr=2.18479e-05, gnorm=1.54, clip=100, loss_scale=512, train_wall=18, gb_free=11.9, wall=4272
2023-05-26 00:34:36 - progress_bar.py[line:272] - INFO: epoch 002:    550 / 1732 loss=2.682, loss_v1=0, loss_v2=0, nll_loss=1.529, ntokens=1026.6, nsentences=32, sample_size=1026.6, sample_size_v1=0, sample_size_v2=0, ppl=2.89, wps=553.3, ups=0.54, wpb=1026.6, bsz=32, num_updates=2280, lr=2.19442e-05, gnorm=1.522, clip=100, loss_scale=512, train_wall=19, gb_free=10.9, wall=4291
2023-05-26 00:34:51 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 256.0
2023-05-26 00:34:57 - progress_bar.py[line:272] - INFO: epoch 002:    561 / 1732 loss=2.652, loss_v1=0, loss_v2=0, nll_loss=1.492, ntokens=1013.6, nsentences=32, sample_size=1013.6, sample_size_v1=0, sample_size_v2=0, ppl=2.81, wps=497.6, ups=0.49, wpb=1013.6, bsz=32, num_updates=2290, lr=2.20404e-05, gnorm=1.675, clip=100, loss_scale=256, train_wall=20, gb_free=11.3, wall=4311
2023-05-26 00:35:15 - progress_bar.py[line:272] - INFO: epoch 002:    571 / 1732 loss=2.677, loss_v1=0, loss_v2=0, nll_loss=1.521, ntokens=990.9, nsentences=32, sample_size=990.9, sample_size_v1=0, sample_size_v2=0, ppl=2.87, wps=533.5, ups=0.54, wpb=990.9, bsz=32, num_updates=2300, lr=2.21367e-05, gnorm=1.678, clip=100, loss_scale=256, train_wall=19, gb_free=11.8, wall=4330
2023-05-26 00:35:34 - progress_bar.py[line:272] - INFO: epoch 002:    581 / 1732 loss=2.647, loss_v1=0, loss_v2=0, nll_loss=1.488, ntokens=1021.6, nsentences=32, sample_size=1021.6, sample_size_v1=0, sample_size_v2=0, ppl=2.8, wps=544.5, ups=0.53, wpb=1021.6, bsz=32, num_updates=2310, lr=2.22329e-05, gnorm=1.624, clip=100, loss_scale=256, train_wall=19, gb_free=10.7, wall=4349
2023-05-26 00:35:53 - progress_bar.py[line:272] - INFO: epoch 002:    591 / 1732 loss=2.647, loss_v1=0, loss_v2=0, nll_loss=1.487, ntokens=934.4, nsentences=32, sample_size=934.4, sample_size_v1=0, sample_size_v2=0, ppl=2.8, wps=503.5, ups=0.54, wpb=934.4, bsz=32, num_updates=2320, lr=2.23292e-05, gnorm=1.625, clip=100, loss_scale=256, train_wall=19, gb_free=10.7, wall=4367
2023-05-26 00:36:11 - progress_bar.py[line:272] - INFO: epoch 002:    601 / 1732 loss=2.63, loss_v1=0, loss_v2=0, nll_loss=1.475, ntokens=941.2, nsentences=32, sample_size=941.2, sample_size_v1=0, sample_size_v2=0, ppl=2.78, wps=507.4, ups=0.54, wpb=941.2, bsz=32, num_updates=2330, lr=2.24254e-05, gnorm=1.647, clip=100, loss_scale=256, train_wall=19, gb_free=11.6, wall=4386
2023-05-26 00:36:30 - progress_bar.py[line:272] - INFO: epoch 002:    611 / 1732 loss=2.625, loss_v1=0, loss_v2=0, nll_loss=1.461, ntokens=911.9, nsentences=32, sample_size=911.9, sample_size_v1=0, sample_size_v2=0, ppl=2.75, wps=494.3, ups=0.54, wpb=911.9, bsz=32, num_updates=2340, lr=2.25217e-05, gnorm=1.547, clip=100, loss_scale=256, train_wall=18, gb_free=11.7, wall=4404
2023-05-26 00:36:48 - progress_bar.py[line:272] - INFO: epoch 002:    621 / 1732 loss=2.654, loss_v1=0, loss_v2=0, nll_loss=1.496, ntokens=845.9, nsentences=32, sample_size=845.9, sample_size_v1=0, sample_size_v2=0, ppl=2.82, wps=461.4, ups=0.55, wpb=845.9, bsz=32, num_updates=2350, lr=2.26179e-05, gnorm=1.681, clip=100, loss_scale=256, train_wall=18, gb_free=12, wall=4423
2023-05-26 00:37:06 - progress_bar.py[line:272] - INFO: epoch 002:    631 / 1732 loss=2.632, loss_v1=0, loss_v2=0, nll_loss=1.473, ntokens=949.2, nsentences=32, sample_size=949.2, sample_size_v1=0, sample_size_v2=0, ppl=2.78, wps=513.4, ups=0.54, wpb=949.2, bsz=32, num_updates=2360, lr=2.27141e-05, gnorm=1.687, clip=100, loss_scale=256, train_wall=18, gb_free=11.2, wall=4441
2023-05-26 00:37:25 - progress_bar.py[line:272] - INFO: epoch 002:    641 / 1732 loss=2.645, loss_v1=0, loss_v2=0, nll_loss=1.487, ntokens=915.8, nsentences=32, sample_size=915.8, sample_size_v1=0, sample_size_v2=0, ppl=2.8, wps=497.6, ups=0.54, wpb=915.8, bsz=32, num_updates=2370, lr=2.28104e-05, gnorm=1.695, clip=100, loss_scale=256, train_wall=18, gb_free=11.8, wall=4460
2023-05-26 00:37:43 - progress_bar.py[line:272] - INFO: epoch 002:    651 / 1732 loss=2.646, loss_v1=0, loss_v2=0, nll_loss=1.486, ntokens=990.2, nsentences=32, sample_size=990.2, sample_size_v1=0, sample_size_v2=0, ppl=2.8, wps=537.7, ups=0.54, wpb=990.2, bsz=32, num_updates=2380, lr=2.29066e-05, gnorm=1.631, clip=100, loss_scale=256, train_wall=18, gb_free=11.7, wall=4478
2023-05-26 00:38:02 - progress_bar.py[line:272] - INFO: epoch 002:    661 / 1732 loss=2.651, loss_v1=0, loss_v2=0, nll_loss=1.488, ntokens=863.9, nsentences=32, sample_size=863.9, sample_size_v1=0, sample_size_v2=0, ppl=2.8, wps=473.1, ups=0.55, wpb=863.9, bsz=32, num_updates=2390, lr=2.30029e-05, gnorm=1.636, clip=100, loss_scale=256, train_wall=18, gb_free=11.5, wall=4496
2023-05-26 00:38:20 - progress_bar.py[line:272] - INFO: epoch 002:    671 / 1732 loss=2.644, loss_v1=0, loss_v2=0, nll_loss=1.487, ntokens=943.7, nsentences=32, sample_size=943.7, sample_size_v1=0, sample_size_v2=0, ppl=2.8, wps=509.9, ups=0.54, wpb=943.7, bsz=32, num_updates=2400, lr=2.30991e-05, gnorm=1.694, clip=100, loss_scale=256, train_wall=18, gb_free=11.4, wall=4515
2023-05-26 00:38:39 - progress_bar.py[line:272] - INFO: epoch 002:    681 / 1732 loss=2.628, loss_v1=0, loss_v2=0, nll_loss=1.466, ntokens=972.8, nsentences=32, sample_size=972.8, sample_size_v1=0, sample_size_v2=0, ppl=2.76, wps=527.4, ups=0.54, wpb=972.8, bsz=32, num_updates=2410, lr=2.31954e-05, gnorm=1.708, clip=100, loss_scale=256, train_wall=18, gb_free=11, wall=4533
2023-05-26 00:38:57 - progress_bar.py[line:272] - INFO: epoch 002:    691 / 1732 loss=2.657, loss_v1=0, loss_v2=0, nll_loss=1.499, ntokens=949, nsentences=32, sample_size=949, sample_size_v1=0, sample_size_v2=0, ppl=2.83, wps=511.6, ups=0.54, wpb=949, bsz=32, num_updates=2420, lr=2.32916e-05, gnorm=1.649, clip=100, loss_scale=256, train_wall=19, gb_free=11.8, wall=4552
2023-05-26 00:39:16 - progress_bar.py[line:272] - INFO: epoch 002:    701 / 1732 loss=2.595, loss_v1=0, loss_v2=0, nll_loss=1.431, ntokens=988.7, nsentences=32, sample_size=988.7, sample_size_v1=0, sample_size_v2=0, ppl=2.7, wps=533.1, ups=0.54, wpb=988.7, bsz=32, num_updates=2430, lr=2.33879e-05, gnorm=1.516, clip=100, loss_scale=256, train_wall=19, gb_free=11.8, wall=4570
2023-05-26 00:39:34 - progress_bar.py[line:272] - INFO: epoch 002:    711 / 1732 loss=2.645, loss_v1=0, loss_v2=0, nll_loss=1.483, ntokens=913.9, nsentences=32, sample_size=913.9, sample_size_v1=0, sample_size_v2=0, ppl=2.8, wps=495.6, ups=0.54, wpb=913.9, bsz=32, num_updates=2440, lr=2.34841e-05, gnorm=1.533, clip=100, loss_scale=256, train_wall=18, gb_free=11.6, wall=4589
2023-05-26 00:39:52 - progress_bar.py[line:272] - INFO: epoch 002:    721 / 1732 loss=2.601, loss_v1=0, loss_v2=0, nll_loss=1.439, ntokens=854.5, nsentences=32, sample_size=854.5, sample_size_v1=0, sample_size_v2=0, ppl=2.71, wps=465, ups=0.54, wpb=854.5, bsz=32, num_updates=2450, lr=2.35804e-05, gnorm=1.768, clip=100, loss_scale=256, train_wall=18, gb_free=11.4, wall=4607
2023-05-26 00:40:11 - progress_bar.py[line:272] - INFO: epoch 002:    731 / 1732 loss=2.607, loss_v1=0, loss_v2=0, nll_loss=1.443, ntokens=932.8, nsentences=32, sample_size=932.8, sample_size_v1=0, sample_size_v2=0, ppl=2.72, wps=507, ups=0.54, wpb=932.8, bsz=32, num_updates=2460, lr=2.36766e-05, gnorm=1.585, clip=100, loss_scale=256, train_wall=18, gb_free=11.6, wall=4626
2023-05-26 00:40:29 - progress_bar.py[line:272] - INFO: epoch 002:    741 / 1732 loss=2.595, loss_v1=0, loss_v2=0, nll_loss=1.427, ntokens=1003.7, nsentences=32, sample_size=1003.7, sample_size_v1=0, sample_size_v2=0, ppl=2.69, wps=542.9, ups=0.54, wpb=1003.7, bsz=32, num_updates=2470, lr=2.37729e-05, gnorm=1.633, clip=100, loss_scale=256, train_wall=18, gb_free=11.4, wall=4644
2023-05-26 00:40:48 - progress_bar.py[line:272] - INFO: epoch 002:    751 / 1732 loss=2.616, loss_v1=0, loss_v2=0, nll_loss=1.451, ntokens=975.7, nsentences=32, sample_size=975.7, sample_size_v1=0, sample_size_v2=0, ppl=2.73, wps=526.1, ups=0.54, wpb=975.7, bsz=32, num_updates=2480, lr=2.38691e-05, gnorm=1.64, clip=100, loss_scale=256, train_wall=19, gb_free=11, wall=4663
2023-05-26 00:41:06 - progress_bar.py[line:272] - INFO: epoch 002:    761 / 1732 loss=2.594, loss_v1=0, loss_v2=0, nll_loss=1.433, ntokens=974.2, nsentences=32, sample_size=974.2, sample_size_v1=0, sample_size_v2=0, ppl=2.7, wps=528.3, ups=0.54, wpb=974.2, bsz=32, num_updates=2490, lr=2.39654e-05, gnorm=1.546, clip=100, loss_scale=256, train_wall=18, gb_free=11.5, wall=4681
2023-05-26 00:41:25 - progress_bar.py[line:272] - INFO: epoch 002:    771 / 1732 loss=2.596, loss_v1=0, loss_v2=0, nll_loss=1.425, ntokens=924.9, nsentences=32, sample_size=924.9, sample_size_v1=0, sample_size_v2=0, ppl=2.68, wps=502.4, ups=0.54, wpb=924.9, bsz=32, num_updates=2500, lr=2.40616e-05, gnorm=1.515, clip=100, loss_scale=256, train_wall=18, gb_free=11.7, wall=4699
2023-05-26 00:41:43 - progress_bar.py[line:272] - INFO: epoch 002:    781 / 1732 loss=2.623, loss_v1=0, loss_v2=0, nll_loss=1.463, ntokens=1053.4, nsentences=32, sample_size=1053.4, sample_size_v1=0, sample_size_v2=0, ppl=2.76, wps=567.3, ups=0.54, wpb=1053.4, bsz=32, num_updates=2510, lr=2.41578e-05, gnorm=1.537, clip=100, loss_scale=256, train_wall=19, gb_free=11.7, wall=4718
2023-05-26 00:42:02 - progress_bar.py[line:272] - INFO: epoch 002:    791 / 1732 loss=2.602, loss_v1=0, loss_v2=0, nll_loss=1.431, ntokens=1022, nsentences=32, sample_size=1022, sample_size_v1=0, sample_size_v2=0, ppl=2.7, wps=552.6, ups=0.54, wpb=1022, bsz=32, num_updates=2520, lr=2.42541e-05, gnorm=1.514, clip=100, loss_scale=256, train_wall=18, gb_free=11.4, wall=4736
2023-05-26 00:42:20 - progress_bar.py[line:272] - INFO: epoch 002:    801 / 1732 loss=2.601, loss_v1=0, loss_v2=0, nll_loss=1.437, ntokens=984.3, nsentences=32, sample_size=984.3, sample_size_v1=0, sample_size_v2=0, ppl=2.71, wps=533.3, ups=0.54, wpb=984.3, bsz=32, num_updates=2530, lr=2.43503e-05, gnorm=1.535, clip=100, loss_scale=256, train_wall=18, gb_free=11.1, wall=4755
2023-05-26 00:42:39 - progress_bar.py[line:272] - INFO: epoch 002:    811 / 1732 loss=2.599, loss_v1=0, loss_v2=0, nll_loss=1.43, ntokens=931.4, nsentences=32, sample_size=931.4, sample_size_v1=0, sample_size_v2=0, ppl=2.69, wps=505.1, ups=0.54, wpb=931.4, bsz=32, num_updates=2540, lr=2.44466e-05, gnorm=1.586, clip=100, loss_scale=256, train_wall=18, gb_free=11.4, wall=4773
2023-05-26 00:42:57 - progress_bar.py[line:272] - INFO: epoch 002:    821 / 1732 loss=2.622, loss_v1=0, loss_v2=0, nll_loss=1.459, ntokens=915.1, nsentences=32, sample_size=915.1, sample_size_v1=0, sample_size_v2=0, ppl=2.75, wps=494.1, ups=0.54, wpb=915.1, bsz=32, num_updates=2550, lr=2.45428e-05, gnorm=1.704, clip=100, loss_scale=256, train_wall=18, gb_free=10.2, wall=4792
2023-05-26 00:43:16 - progress_bar.py[line:272] - INFO: epoch 002:    831 / 1732 loss=2.586, loss_v1=0, loss_v2=0, nll_loss=1.417, ntokens=914.9, nsentences=32, sample_size=914.9, sample_size_v1=0, sample_size_v2=0, ppl=2.67, wps=497.6, ups=0.54, wpb=914.9, bsz=32, num_updates=2560, lr=2.46391e-05, gnorm=1.566, clip=100, loss_scale=256, train_wall=18, gb_free=11.6, wall=4810
2023-05-26 00:43:34 - progress_bar.py[line:272] - INFO: epoch 002:    841 / 1732 loss=2.591, loss_v1=0, loss_v2=0, nll_loss=1.422, ntokens=933, nsentences=32, sample_size=933, sample_size_v1=0, sample_size_v2=0, ppl=2.68, wps=504.2, ups=0.54, wpb=933, bsz=32, num_updates=2570, lr=2.47353e-05, gnorm=1.562, clip=100, loss_scale=256, train_wall=18, gb_free=11.7, wall=4829
2023-05-26 00:43:53 - progress_bar.py[line:272] - INFO: epoch 002:    851 / 1732 loss=2.604, loss_v1=0, loss_v2=0, nll_loss=1.439, ntokens=1005.2, nsentences=32, sample_size=1005.2, sample_size_v1=0, sample_size_v2=0, ppl=2.71, wps=543.8, ups=0.54, wpb=1005.2, bsz=32, num_updates=2580, lr=2.48316e-05, gnorm=1.564, clip=100, loss_scale=256, train_wall=18, gb_free=11.4, wall=4847
2023-05-26 00:44:11 - progress_bar.py[line:272] - INFO: epoch 002:    861 / 1732 loss=2.576, loss_v1=0, loss_v2=0, nll_loss=1.406, ntokens=942.6, nsentences=32, sample_size=942.6, sample_size_v1=0, sample_size_v2=0, ppl=2.65, wps=509.2, ups=0.54, wpb=942.6, bsz=32, num_updates=2590, lr=2.49278e-05, gnorm=1.608, clip=100, loss_scale=256, train_wall=18, gb_free=11.3, wall=4866
2023-05-26 00:44:30 - progress_bar.py[line:272] - INFO: epoch 002:    871 / 1732 loss=2.603, loss_v1=0, loss_v2=0, nll_loss=1.436, ntokens=962.7, nsentences=32, sample_size=962.7, sample_size_v1=0, sample_size_v2=0, ppl=2.71, wps=522, ups=0.54, wpb=962.7, bsz=32, num_updates=2600, lr=2.50241e-05, gnorm=1.553, clip=100, loss_scale=256, train_wall=18, gb_free=11.8, wall=4884
2023-05-26 00:44:48 - progress_bar.py[line:272] - INFO: epoch 002:    881 / 1732 loss=2.547, loss_v1=0, loss_v2=0, nll_loss=1.377, ntokens=988.4, nsentences=32, sample_size=988.4, sample_size_v1=0, sample_size_v2=0, ppl=2.6, wps=532, ups=0.54, wpb=988.4, bsz=32, num_updates=2610, lr=2.51203e-05, gnorm=1.516, clip=100, loss_scale=256, train_wall=19, gb_free=12.1, wall=4903
2023-05-26 00:45:07 - progress_bar.py[line:272] - INFO: epoch 002:    891 / 1732 loss=2.531, loss_v1=0, loss_v2=0, nll_loss=1.351, ntokens=1001.4, nsentences=32, sample_size=1001.4, sample_size_v1=0, sample_size_v2=0, ppl=2.55, wps=538.9, ups=0.54, wpb=1001.4, bsz=32, num_updates=2620, lr=2.52166e-05, gnorm=1.54, clip=100, loss_scale=256, train_wall=19, gb_free=11.4, wall=4921
2023-05-26 00:45:25 - progress_bar.py[line:272] - INFO: epoch 002:    901 / 1732 loss=2.537, loss_v1=0, loss_v2=0, nll_loss=1.364, ntokens=1032.4, nsentences=32, sample_size=1032.4, sample_size_v1=0, sample_size_v2=0, ppl=2.57, wps=556.7, ups=0.54, wpb=1032.4, bsz=32, num_updates=2630, lr=2.53128e-05, gnorm=1.564, clip=100, loss_scale=256, train_wall=19, gb_free=11.7, wall=4940
2023-05-26 00:45:44 - progress_bar.py[line:272] - INFO: epoch 002:    911 / 1732 loss=2.582, loss_v1=0, loss_v2=0, nll_loss=1.413, ntokens=960.1, nsentences=32, sample_size=960.1, sample_size_v1=0, sample_size_v2=0, ppl=2.66, wps=520.8, ups=0.54, wpb=960.1, bsz=32, num_updates=2640, lr=2.5409e-05, gnorm=1.628, clip=100, loss_scale=256, train_wall=18, gb_free=12, wall=4958
2023-05-26 00:46:02 - progress_bar.py[line:272] - INFO: epoch 002:    921 / 1732 loss=2.612, loss_v1=0, loss_v2=0, nll_loss=1.443, ntokens=986.3, nsentences=32, sample_size=986.3, sample_size_v1=0, sample_size_v2=0, ppl=2.72, wps=530.8, ups=0.54, wpb=986.3, bsz=32, num_updates=2650, lr=2.55053e-05, gnorm=1.678, clip=100, loss_scale=256, train_wall=19, gb_free=11.4, wall=4977
2023-05-26 00:46:21 - progress_bar.py[line:272] - INFO: epoch 002:    931 / 1732 loss=2.559, loss_v1=0, loss_v2=0, nll_loss=1.391, ntokens=1050.4, nsentences=32, sample_size=1050.4, sample_size_v1=0, sample_size_v2=0, ppl=2.62, wps=561.4, ups=0.53, wpb=1050.4, bsz=32, num_updates=2660, lr=2.56015e-05, gnorm=1.695, clip=100, loss_scale=256, train_wall=19, gb_free=11.5, wall=4996
2023-05-26 00:46:40 - progress_bar.py[line:272] - INFO: epoch 002:    941 / 1732 loss=2.576, loss_v1=0, loss_v2=0, nll_loss=1.406, ntokens=1052.3, nsentences=32, sample_size=1052.3, sample_size_v1=0, sample_size_v2=0, ppl=2.65, wps=559.1, ups=0.53, wpb=1052.3, bsz=32, num_updates=2670, lr=2.56978e-05, gnorm=1.518, clip=100, loss_scale=256, train_wall=19, gb_free=10.1, wall=5015
2023-05-26 00:46:59 - progress_bar.py[line:272] - INFO: epoch 002:    951 / 1732 loss=2.564, loss_v1=0, loss_v2=0, nll_loss=1.391, ntokens=1037.8, nsentences=32, sample_size=1037.8, sample_size_v1=0, sample_size_v2=0, ppl=2.62, wps=554.7, ups=0.53, wpb=1037.8, bsz=32, num_updates=2680, lr=2.5794e-05, gnorm=1.524, clip=100, loss_scale=256, train_wall=19, gb_free=11.1, wall=5033
2023-05-26 00:47:17 - progress_bar.py[line:272] - INFO: epoch 002:    961 / 1732 loss=2.57, loss_v1=0, loss_v2=0, nll_loss=1.4, ntokens=1067.9, nsentences=32, sample_size=1067.9, sample_size_v1=0, sample_size_v2=0, ppl=2.64, wps=569.1, ups=0.53, wpb=1067.9, bsz=32, num_updates=2690, lr=2.58903e-05, gnorm=1.49, clip=100, loss_scale=256, train_wall=19, gb_free=11.3, wall=5052
2023-05-26 00:47:36 - progress_bar.py[line:272] - INFO: epoch 002:    971 / 1732 loss=2.598, loss_v1=0, loss_v2=0, nll_loss=1.431, ntokens=1026.9, nsentences=32, sample_size=1026.9, sample_size_v1=0, sample_size_v2=0, ppl=2.7, wps=548.9, ups=0.53, wpb=1026.9, bsz=32, num_updates=2700, lr=2.59865e-05, gnorm=1.51, clip=100, loss_scale=256, train_wall=19, gb_free=10.3, wall=5071
2023-05-26 00:47:55 - progress_bar.py[line:272] - INFO: epoch 002:    981 / 1732 loss=2.56, loss_v1=0, loss_v2=0, nll_loss=1.388, ntokens=1016.8, nsentences=32, sample_size=1016.8, sample_size_v1=0, sample_size_v2=0, ppl=2.62, wps=540, ups=0.53, wpb=1016.8, bsz=32, num_updates=2710, lr=2.60828e-05, gnorm=1.546, clip=100, loss_scale=256, train_wall=19, gb_free=11.1, wall=5090
2023-05-26 00:48:14 - progress_bar.py[line:272] - INFO: epoch 002:    991 / 1732 loss=2.565, loss_v1=0, loss_v2=0, nll_loss=1.393, ntokens=1042.2, nsentences=32, sample_size=1042.2, sample_size_v1=0, sample_size_v2=0, ppl=2.63, wps=554, ups=0.53, wpb=1042.2, bsz=32, num_updates=2720, lr=2.6179e-05, gnorm=1.489, clip=100, loss_scale=256, train_wall=19, gb_free=11.4, wall=5108
2023-05-26 00:48:32 - progress_bar.py[line:272] - INFO: epoch 002:   1001 / 1732 loss=2.546, loss_v1=0, loss_v2=0, nll_loss=1.371, ntokens=1019, nsentences=32, sample_size=1019, sample_size_v1=0, sample_size_v2=0, ppl=2.59, wps=547.9, ups=0.54, wpb=1019, bsz=32, num_updates=2730, lr=2.62753e-05, gnorm=1.565, clip=100, loss_scale=256, train_wall=19, gb_free=11.3, wall=5127
2023-05-26 00:48:51 - progress_bar.py[line:272] - INFO: epoch 002:   1011 / 1732 loss=2.557, loss_v1=0, loss_v2=0, nll_loss=1.385, ntokens=995.8, nsentences=32, sample_size=995.8, sample_size_v1=0, sample_size_v2=0, ppl=2.61, wps=533.4, ups=0.54, wpb=995.8, bsz=32, num_updates=2740, lr=2.63715e-05, gnorm=1.511, clip=100, loss_scale=256, train_wall=19, gb_free=11.5, wall=5146
2023-05-26 00:49:10 - progress_bar.py[line:272] - INFO: epoch 002:   1021 / 1732 loss=2.541, loss_v1=0, loss_v2=0, nll_loss=1.366, ntokens=1050, nsentences=32, sample_size=1050, sample_size_v1=0, sample_size_v2=0, ppl=2.58, wps=559.5, ups=0.53, wpb=1050, bsz=32, num_updates=2750, lr=2.64678e-05, gnorm=1.618, clip=100, loss_scale=256, train_wall=19, gb_free=10.5, wall=5164
2023-05-26 00:49:29 - progress_bar.py[line:272] - INFO: epoch 002:   1031 / 1732 loss=2.56, loss_v1=0, loss_v2=0, nll_loss=1.388, ntokens=1125.6, nsentences=32, sample_size=1125.6, sample_size_v1=0, sample_size_v2=0, ppl=2.62, wps=594.5, ups=0.53, wpb=1125.6, bsz=32, num_updates=2760, lr=2.6564e-05, gnorm=1.479, clip=100, loss_scale=256, train_wall=19, gb_free=11.1, wall=5183
2023-05-26 00:49:47 - progress_bar.py[line:272] - INFO: epoch 002:   1041 / 1732 loss=2.567, loss_v1=0, loss_v2=0, nll_loss=1.391, ntokens=1038.5, nsentences=32, sample_size=1038.5, sample_size_v1=0, sample_size_v2=0, ppl=2.62, wps=553.1, ups=0.53, wpb=1038.5, bsz=32, num_updates=2770, lr=2.66603e-05, gnorm=1.553, clip=100, loss_scale=256, train_wall=19, gb_free=11.5, wall=5202
2023-05-26 00:50:06 - progress_bar.py[line:272] - INFO: epoch 002:   1051 / 1732 loss=2.559, loss_v1=0, loss_v2=0, nll_loss=1.388, ntokens=1067.2, nsentences=32, sample_size=1067.2, sample_size_v1=0, sample_size_v2=0, ppl=2.62, wps=570.6, ups=0.53, wpb=1067.2, bsz=32, num_updates=2780, lr=2.67565e-05, gnorm=1.609, clip=100, loss_scale=256, train_wall=19, gb_free=11.8, wall=5221
2023-05-26 00:50:25 - progress_bar.py[line:272] - INFO: epoch 002:   1061 / 1732 loss=2.547, loss_v1=0, loss_v2=0, nll_loss=1.369, ntokens=1037.8, nsentences=32, sample_size=1037.8, sample_size_v1=0, sample_size_v2=0, ppl=2.58, wps=553.4, ups=0.53, wpb=1037.8, bsz=32, num_updates=2790, lr=2.68527e-05, gnorm=1.463, clip=100, loss_scale=256, train_wall=19, gb_free=11.5, wall=5240
2023-05-26 00:50:44 - progress_bar.py[line:272] - INFO: epoch 002:   1071 / 1732 loss=2.543, loss_v1=0, loss_v2=0, nll_loss=1.37, ntokens=999.8, nsentences=32, sample_size=999.8, sample_size_v1=0, sample_size_v2=0, ppl=2.59, wps=533.6, ups=0.53, wpb=999.8, bsz=32, num_updates=2800, lr=2.6949e-05, gnorm=1.478, clip=100, loss_scale=512, train_wall=19, gb_free=10.7, wall=5258
2023-05-26 00:51:03 - progress_bar.py[line:272] - INFO: epoch 002:   1081 / 1732 loss=2.569, loss_v1=0, loss_v2=0, nll_loss=1.396, ntokens=1039.7, nsentences=32, sample_size=1039.7, sample_size_v1=0, sample_size_v2=0, ppl=2.63, wps=552.2, ups=0.53, wpb=1039.7, bsz=32, num_updates=2810, lr=2.70452e-05, gnorm=1.58, clip=100, loss_scale=512, train_wall=19, gb_free=11.1, wall=5277
2023-05-26 00:51:21 - progress_bar.py[line:272] - INFO: epoch 002:   1091 / 1732 loss=2.558, loss_v1=0, loss_v2=0, nll_loss=1.383, ntokens=1090, nsentences=32, sample_size=1090, sample_size_v1=0, sample_size_v2=0, ppl=2.61, wps=576.7, ups=0.53, wpb=1090, bsz=32, num_updates=2820, lr=2.71415e-05, gnorm=1.47, clip=100, loss_scale=512, train_wall=19, gb_free=11.4, wall=5296
2023-05-26 00:51:40 - progress_bar.py[line:272] - INFO: epoch 002:   1101 / 1732 loss=2.566, loss_v1=0, loss_v2=0, nll_loss=1.395, ntokens=1006.7, nsentences=32, sample_size=1006.7, sample_size_v1=0, sample_size_v2=0, ppl=2.63, wps=538, ups=0.53, wpb=1006.7, bsz=32, num_updates=2830, lr=2.72377e-05, gnorm=1.421, clip=100, loss_scale=512, train_wall=19, gb_free=11.1, wall=5315
2023-05-26 00:51:59 - progress_bar.py[line:272] - INFO: epoch 002:   1111 / 1732 loss=2.543, loss_v1=0, loss_v2=0, nll_loss=1.366, ntokens=1054.1, nsentences=32, sample_size=1054.1, sample_size_v1=0, sample_size_v2=0, ppl=2.58, wps=559.1, ups=0.53, wpb=1054.1, bsz=32, num_updates=2840, lr=2.7334e-05, gnorm=1.366, clip=100, loss_scale=512, train_wall=19, gb_free=11.5, wall=5334
2023-05-26 00:52:18 - progress_bar.py[line:272] - INFO: epoch 002:   1121 / 1732 loss=2.566, loss_v1=0, loss_v2=0, nll_loss=1.395, ntokens=962.9, nsentences=32, sample_size=962.9, sample_size_v1=0, sample_size_v2=0, ppl=2.63, wps=512.9, ups=0.53, wpb=962.9, bsz=32, num_updates=2850, lr=2.74302e-05, gnorm=1.554, clip=100, loss_scale=512, train_wall=19, gb_free=11.5, wall=5352
2023-05-26 00:52:36 - progress_bar.py[line:272] - INFO: epoch 002:   1131 / 1732 loss=2.565, loss_v1=0, loss_v2=0, nll_loss=1.389, ntokens=991.2, nsentences=32, sample_size=991.2, sample_size_v1=0, sample_size_v2=0, ppl=2.62, wps=528.8, ups=0.53, wpb=991.2, bsz=32, num_updates=2860, lr=2.75265e-05, gnorm=1.549, clip=100, loss_scale=512, train_wall=19, gb_free=11.7, wall=5371
2023-05-26 00:52:55 - progress_bar.py[line:272] - INFO: epoch 002:   1141 / 1732 loss=2.563, loss_v1=0, loss_v2=0, nll_loss=1.392, ntokens=1017.8, nsentences=32, sample_size=1017.8, sample_size_v1=0, sample_size_v2=0, ppl=2.62, wps=544.6, ups=0.54, wpb=1017.8, bsz=32, num_updates=2870, lr=2.76227e-05, gnorm=1.552, clip=100, loss_scale=512, train_wall=19, gb_free=11.3, wall=5390
2023-05-26 00:53:14 - progress_bar.py[line:272] - INFO: epoch 002:   1151 / 1732 loss=2.556, loss_v1=0, loss_v2=0, nll_loss=1.379, ntokens=1034.7, nsentences=32, sample_size=1034.7, sample_size_v1=0, sample_size_v2=0, ppl=2.6, wps=553.8, ups=0.54, wpb=1034.7, bsz=32, num_updates=2880, lr=2.7719e-05, gnorm=1.481, clip=100, loss_scale=512, train_wall=19, gb_free=10.9, wall=5409
2023-05-26 00:53:33 - progress_bar.py[line:272] - INFO: epoch 002:   1161 / 1732 loss=2.509, loss_v1=0, loss_v2=0, nll_loss=1.33, ntokens=995.8, nsentences=32, sample_size=995.8, sample_size_v1=0, sample_size_v2=0, ppl=2.51, wps=530.9, ups=0.53, wpb=995.8, bsz=32, num_updates=2890, lr=2.78152e-05, gnorm=1.582, clip=100, loss_scale=512, train_wall=19, gb_free=11.4, wall=5427
2023-05-26 00:53:51 - progress_bar.py[line:272] - INFO: epoch 002:   1171 / 1732 loss=2.545, loss_v1=0, loss_v2=0, nll_loss=1.367, ntokens=1049.1, nsentences=32, sample_size=1049.1, sample_size_v1=0, sample_size_v2=0, ppl=2.58, wps=558.6, ups=0.53, wpb=1049.1, bsz=32, num_updates=2900, lr=2.79115e-05, gnorm=1.421, clip=100, loss_scale=512, train_wall=19, gb_free=11.5, wall=5446
2023-05-26 00:54:10 - progress_bar.py[line:272] - INFO: epoch 002:   1181 / 1732 loss=2.533, loss_v1=0, loss_v2=0, nll_loss=1.359, ntokens=1019.2, nsentences=32, sample_size=1019.2, sample_size_v1=0, sample_size_v2=0, ppl=2.56, wps=546.4, ups=0.54, wpb=1019.2, bsz=32, num_updates=2910, lr=2.80077e-05, gnorm=1.453, clip=100, loss_scale=512, train_wall=19, gb_free=10.4, wall=5465
2023-05-26 00:54:29 - progress_bar.py[line:272] - INFO: epoch 002:   1191 / 1732 loss=2.587, loss_v1=0, loss_v2=0, nll_loss=1.414, ntokens=1005.4, nsentences=32, sample_size=1005.4, sample_size_v1=0, sample_size_v2=0, ppl=2.66, wps=537.4, ups=0.53, wpb=1005.4, bsz=32, num_updates=2920, lr=2.81039e-05, gnorm=1.481, clip=100, loss_scale=512, train_wall=19, gb_free=11.5, wall=5483
2023-05-26 00:54:48 - progress_bar.py[line:272] - INFO: epoch 002:   1201 / 1732 loss=2.508, loss_v1=0, loss_v2=0, nll_loss=1.327, ntokens=1106.6, nsentences=32, sample_size=1106.6, sample_size_v1=0, sample_size_v2=0, ppl=2.51, wps=586.8, ups=0.53, wpb=1106.6, bsz=32, num_updates=2930, lr=2.82002e-05, gnorm=1.378, clip=100, loss_scale=512, train_wall=19, gb_free=11.2, wall=5502
2023-05-26 00:55:07 - progress_bar.py[line:272] - INFO: epoch 002:   1211 / 1732 loss=2.524, loss_v1=0, loss_v2=0, nll_loss=1.344, ntokens=1064.4, nsentences=32, sample_size=1064.4, sample_size_v1=0, sample_size_v2=0, ppl=2.54, wps=564.5, ups=0.53, wpb=1064.4, bsz=32, num_updates=2940, lr=2.82964e-05, gnorm=1.424, clip=100, loss_scale=512, train_wall=19, gb_free=11.4, wall=5521
2023-05-26 00:55:25 - progress_bar.py[line:272] - INFO: epoch 002:   1221 / 1732 loss=2.568, loss_v1=0, loss_v2=0, nll_loss=1.393, ntokens=1029, nsentences=32, sample_size=1029, sample_size_v1=0, sample_size_v2=0, ppl=2.63, wps=550.9, ups=0.54, wpb=1029, bsz=32, num_updates=2950, lr=2.83927e-05, gnorm=1.584, clip=100, loss_scale=512, train_wall=19, gb_free=11.6, wall=5540
2023-05-26 00:55:44 - progress_bar.py[line:272] - INFO: epoch 002:   1231 / 1732 loss=2.524, loss_v1=0, loss_v2=0, nll_loss=1.344, ntokens=1027, nsentences=32, sample_size=1027, sample_size_v1=0, sample_size_v2=0, ppl=2.54, wps=548, ups=0.53, wpb=1027, bsz=32, num_updates=2960, lr=2.84889e-05, gnorm=1.42, clip=100, loss_scale=512, train_wall=19, gb_free=11.4, wall=5559
2023-05-26 00:56:03 - progress_bar.py[line:272] - INFO: epoch 002:   1241 / 1732 loss=2.491, loss_v1=0, loss_v2=0, nll_loss=1.312, ntokens=1099, nsentences=32, sample_size=1099, sample_size_v1=0, sample_size_v2=0, ppl=2.48, wps=581.8, ups=0.53, wpb=1099, bsz=32, num_updates=2970, lr=2.85852e-05, gnorm=1.448, clip=100, loss_scale=512, train_wall=19, gb_free=11.7, wall=5577
2023-05-26 00:56:22 - progress_bar.py[line:272] - INFO: epoch 002:   1251 / 1732 loss=2.514, loss_v1=0, loss_v2=0, nll_loss=1.332, ntokens=1063.8, nsentences=32, sample_size=1063.8, sample_size_v1=0, sample_size_v2=0, ppl=2.52, wps=565.1, ups=0.53, wpb=1063.8, bsz=32, num_updates=2980, lr=2.86814e-05, gnorm=1.441, clip=100, loss_scale=512, train_wall=19, gb_free=11.2, wall=5596
2023-05-26 00:56:40 - progress_bar.py[line:272] - INFO: epoch 002:   1261 / 1732 loss=2.519, loss_v1=0, loss_v2=0, nll_loss=1.34, ntokens=1068.4, nsentences=32, sample_size=1068.4, sample_size_v1=0, sample_size_v2=0, ppl=2.53, wps=569.5, ups=0.53, wpb=1068.4, bsz=32, num_updates=2990, lr=2.87777e-05, gnorm=1.458, clip=100, loss_scale=512, train_wall=19, gb_free=11, wall=5615
2023-05-26 00:56:59 - progress_bar.py[line:272] - INFO: epoch 002:   1271 / 1732 loss=2.539, loss_v1=0, loss_v2=0, nll_loss=1.361, ntokens=1028.5, nsentences=32, sample_size=1028.5, sample_size_v1=0, sample_size_v2=0, ppl=2.57, wps=549.9, ups=0.53, wpb=1028.5, bsz=32, num_updates=3000, lr=2.88739e-05, gnorm=1.516, clip=100, loss_scale=512, train_wall=19, gb_free=11.8, wall=5634
2023-05-26 00:57:18 - progress_bar.py[line:272] - INFO: epoch 002:   1281 / 1732 loss=2.519, loss_v1=0, loss_v2=0, nll_loss=1.337, ntokens=1068.6, nsentences=32, sample_size=1068.6, sample_size_v1=0, sample_size_v2=0, ppl=2.53, wps=564.7, ups=0.53, wpb=1068.6, bsz=32, num_updates=3010, lr=2.89702e-05, gnorm=1.548, clip=100, loss_scale=512, train_wall=19, gb_free=11.3, wall=5653
2023-05-26 00:57:37 - progress_bar.py[line:272] - INFO: epoch 002:   1291 / 1732 loss=2.542, loss_v1=0, loss_v2=0, nll_loss=1.367, ntokens=1084.2, nsentences=32, sample_size=1084.2, sample_size_v1=0, sample_size_v2=0, ppl=2.58, wps=575.1, ups=0.53, wpb=1084.2, bsz=32, num_updates=3020, lr=2.90664e-05, gnorm=1.55, clip=100, loss_scale=512, train_wall=19, gb_free=11.5, wall=5672
2023-05-26 00:57:56 - progress_bar.py[line:272] - INFO: epoch 002:   1301 / 1732 loss=2.508, loss_v1=0, loss_v2=0, nll_loss=1.327, ntokens=1090.9, nsentences=32, sample_size=1090.9, sample_size_v1=0, sample_size_v2=0, ppl=2.51, wps=581, ups=0.53, wpb=1090.9, bsz=32, num_updates=3030, lr=2.91627e-05, gnorm=1.426, clip=100, loss_scale=512, train_wall=19, gb_free=11.3, wall=5690
2023-05-26 00:58:15 - progress_bar.py[line:272] - INFO: epoch 002:   1311 / 1732 loss=2.551, loss_v1=0, loss_v2=0, nll_loss=1.372, ntokens=1079.3, nsentences=32, sample_size=1079.3, sample_size_v1=0, sample_size_v2=0, ppl=2.59, wps=566.9, ups=0.53, wpb=1079.3, bsz=32, num_updates=3040, lr=2.92589e-05, gnorm=1.521, clip=100, loss_scale=512, train_wall=19, gb_free=10.9, wall=5709
2023-05-26 00:58:34 - progress_bar.py[line:272] - INFO: epoch 002:   1321 / 1732 loss=2.52, loss_v1=0, loss_v2=0, nll_loss=1.343, ntokens=1098.3, nsentences=32, sample_size=1098.3, sample_size_v1=0, sample_size_v2=0, ppl=2.54, wps=582.2, ups=0.53, wpb=1098.3, bsz=32, num_updates=3050, lr=2.93551e-05, gnorm=1.476, clip=100, loss_scale=512, train_wall=19, gb_free=9.2, wall=5728
2023-05-26 00:58:52 - progress_bar.py[line:272] - INFO: epoch 002:   1331 / 1732 loss=2.487, loss_v1=0, loss_v2=0, nll_loss=1.303, ntokens=1102.8, nsentences=32, sample_size=1102.8, sample_size_v1=0, sample_size_v2=0, ppl=2.47, wps=585.8, ups=0.53, wpb=1102.8, bsz=32, num_updates=3060, lr=2.94514e-05, gnorm=1.382, clip=100, loss_scale=512, train_wall=19, gb_free=11.3, wall=5747
2023-05-26 00:59:11 - progress_bar.py[line:272] - INFO: epoch 002:   1341 / 1732 loss=2.518, loss_v1=0, loss_v2=0, nll_loss=1.337, ntokens=1167.8, nsentences=32, sample_size=1167.8, sample_size_v1=0, sample_size_v2=0, ppl=2.53, wps=616.9, ups=0.53, wpb=1167.8, bsz=32, num_updates=3070, lr=2.95476e-05, gnorm=1.399, clip=100, loss_scale=512, train_wall=19, gb_free=10.9, wall=5766
2023-05-26 00:59:30 - progress_bar.py[line:272] - INFO: epoch 002:   1351 / 1732 loss=2.524, loss_v1=0, loss_v2=0, nll_loss=1.347, ntokens=1137.2, nsentences=32, sample_size=1137.2, sample_size_v1=0, sample_size_v2=0, ppl=2.54, wps=600.4, ups=0.53, wpb=1137.2, bsz=32, num_updates=3080, lr=2.96439e-05, gnorm=1.449, clip=100, loss_scale=512, train_wall=19, gb_free=11, wall=5785
2023-05-26 00:59:49 - progress_bar.py[line:272] - INFO: epoch 002:   1361 / 1732 loss=2.482, loss_v1=0, loss_v2=0, nll_loss=1.298, ntokens=1107.4, nsentences=32, sample_size=1107.4, sample_size_v1=0, sample_size_v2=0, ppl=2.46, wps=584.9, ups=0.53, wpb=1107.4, bsz=32, num_updates=3090, lr=2.97401e-05, gnorm=1.394, clip=100, loss_scale=512, train_wall=19, gb_free=11.3, wall=5804
2023-05-26 01:00:08 - progress_bar.py[line:272] - INFO: epoch 002:   1371 / 1732 loss=2.528, loss_v1=0, loss_v2=0, nll_loss=1.348, ntokens=1105.1, nsentences=32, sample_size=1105.1, sample_size_v1=0, sample_size_v2=0, ppl=2.55, wps=587.4, ups=0.53, wpb=1105.1, bsz=32, num_updates=3100, lr=2.98364e-05, gnorm=1.459, clip=100, loss_scale=512, train_wall=19, gb_free=11.6, wall=5823
2023-05-26 01:00:27 - progress_bar.py[line:272] - INFO: epoch 002:   1381 / 1732 loss=2.54, loss_v1=0, loss_v2=0, nll_loss=1.363, ntokens=1138.6, nsentences=32, sample_size=1138.6, sample_size_v1=0, sample_size_v2=0, ppl=2.57, wps=605.8, ups=0.53, wpb=1138.6, bsz=32, num_updates=3110, lr=2.99326e-05, gnorm=1.397, clip=100, loss_scale=512, train_wall=19, gb_free=11.3, wall=5842
2023-05-26 01:00:46 - progress_bar.py[line:272] - INFO: epoch 002:   1391 / 1732 loss=2.519, loss_v1=0, loss_v2=0, nll_loss=1.341, ntokens=1079.9, nsentences=32, sample_size=1079.9, sample_size_v1=0, sample_size_v2=0, ppl=2.53, wps=578.7, ups=0.54, wpb=1079.9, bsz=32, num_updates=3120, lr=2.99982e-05, gnorm=1.403, clip=100, loss_scale=512, train_wall=19, gb_free=10.9, wall=5860
2023-05-26 01:01:04 - progress_bar.py[line:272] - INFO: epoch 002:   1401 / 1732 loss=2.496, loss_v1=0, loss_v2=0, nll_loss=1.309, ntokens=1107.2, nsentences=32, sample_size=1107.2, sample_size_v1=0, sample_size_v2=0, ppl=2.48, wps=587.6, ups=0.53, wpb=1107.2, bsz=32, num_updates=3130, lr=2.9992e-05, gnorm=1.492, clip=100, loss_scale=512, train_wall=19, gb_free=11.7, wall=5879
2023-05-26 01:01:23 - progress_bar.py[line:272] - INFO: epoch 002:   1411 / 1732 loss=2.52, loss_v1=0, loss_v2=0, nll_loss=1.341, ntokens=1229.2, nsentences=32, sample_size=1229.2, sample_size_v1=0, sample_size_v2=0, ppl=2.53, wps=649.3, ups=0.53, wpb=1229.2, bsz=32, num_updates=3140, lr=2.99859e-05, gnorm=1.382, clip=100, loss_scale=512, train_wall=19, gb_free=10.9, wall=5898
2023-05-26 01:01:43 - progress_bar.py[line:272] - INFO: epoch 002:   1421 / 1732 loss=2.525, loss_v1=0, loss_v2=0, nll_loss=1.346, ntokens=1255.1, nsentences=32, sample_size=1255.1, sample_size_v1=0, sample_size_v2=0, ppl=2.54, wps=652.7, ups=0.52, wpb=1255.1, bsz=32, num_updates=3150, lr=2.99797e-05, gnorm=1.441, clip=100, loss_scale=512, train_wall=19, gb_free=9.9, wall=5917
2023-05-26 01:02:01 - progress_bar.py[line:272] - INFO: epoch 002:   1431 / 1732 loss=2.491, loss_v1=0, loss_v2=0, nll_loss=1.307, ntokens=1244.5, nsentences=32, sample_size=1244.5, sample_size_v1=0, sample_size_v2=0, ppl=2.47, wps=657.7, ups=0.53, wpb=1244.5, bsz=32, num_updates=3160, lr=2.99736e-05, gnorm=1.359, clip=100, loss_scale=512, train_wall=19, gb_free=10.7, wall=5936
2023-05-26 01:02:20 - progress_bar.py[line:272] - INFO: epoch 002:   1441 / 1732 loss=2.518, loss_v1=0, loss_v2=0, nll_loss=1.34, ntokens=1138.5, nsentences=32, sample_size=1138.5, sample_size_v1=0, sample_size_v2=0, ppl=2.53, wps=606.1, ups=0.53, wpb=1138.5, bsz=32, num_updates=3170, lr=2.99674e-05, gnorm=1.409, clip=100, loss_scale=512, train_wall=19, gb_free=11.1, wall=5955
2023-05-26 01:02:39 - progress_bar.py[line:272] - INFO: epoch 002:   1451 / 1732 loss=2.518, loss_v1=0, loss_v2=0, nll_loss=1.332, ntokens=1144.4, nsentences=32, sample_size=1144.4, sample_size_v1=0, sample_size_v2=0, ppl=2.52, wps=605.9, ups=0.53, wpb=1144.4, bsz=32, num_updates=3180, lr=2.99613e-05, gnorm=1.388, clip=100, loss_scale=512, train_wall=19, gb_free=10.8, wall=5974
2023-05-26 01:02:58 - progress_bar.py[line:272] - INFO: epoch 002:   1461 / 1732 loss=2.496, loss_v1=0, loss_v2=0, nll_loss=1.314, ntokens=1149.6, nsentences=32, sample_size=1149.6, sample_size_v1=0, sample_size_v2=0, ppl=2.49, wps=610.9, ups=0.53, wpb=1149.6, bsz=32, num_updates=3190, lr=2.99552e-05, gnorm=1.319, clip=100, loss_scale=512, train_wall=19, gb_free=10.9, wall=5993
2023-05-26 01:03:17 - progress_bar.py[line:272] - INFO: epoch 002:   1471 / 1732 loss=2.488, loss_v1=0, loss_v2=0, nll_loss=1.306, ntokens=1162.5, nsentences=32, sample_size=1162.5, sample_size_v1=0, sample_size_v2=0, ppl=2.47, wps=612.2, ups=0.53, wpb=1162.5, bsz=32, num_updates=3200, lr=2.9949e-05, gnorm=1.426, clip=100, loss_scale=512, train_wall=19, gb_free=11.7, wall=6012
2023-05-26 01:03:36 - progress_bar.py[line:272] - INFO: epoch 002:   1481 / 1732 loss=2.525, loss_v1=0, loss_v2=0, nll_loss=1.338, ntokens=1033.9, nsentences=32, sample_size=1033.9, sample_size_v1=0, sample_size_v2=0, ppl=2.53, wps=552.3, ups=0.53, wpb=1033.9, bsz=32, num_updates=3210, lr=2.99429e-05, gnorm=1.44, clip=100, loss_scale=512, train_wall=19, gb_free=11, wall=6030
2023-05-26 01:03:55 - progress_bar.py[line:272] - INFO: epoch 002:   1491 / 1732 loss=2.509, loss_v1=0, loss_v2=0, nll_loss=1.33, ntokens=1139.7, nsentences=32, sample_size=1139.7, sample_size_v1=0, sample_size_v2=0, ppl=2.51, wps=603, ups=0.53, wpb=1139.7, bsz=32, num_updates=3220, lr=2.99367e-05, gnorm=1.365, clip=100, loss_scale=512, train_wall=19, gb_free=11.3, wall=6049
2023-05-26 01:04:13 - progress_bar.py[line:272] - INFO: epoch 002:   1501 / 1732 loss=2.465, loss_v1=0, loss_v2=0, nll_loss=1.281, ntokens=1132.8, nsentences=32, sample_size=1132.8, sample_size_v1=0, sample_size_v2=0, ppl=2.43, wps=599.9, ups=0.53, wpb=1132.8, bsz=32, num_updates=3230, lr=2.99306e-05, gnorm=1.385, clip=100, loss_scale=512, train_wall=19, gb_free=10.6, wall=6068
2023-05-26 01:04:32 - progress_bar.py[line:272] - INFO: epoch 002:   1511 / 1732 loss=2.497, loss_v1=0, loss_v2=0, nll_loss=1.31, ntokens=1056, nsentences=32, sample_size=1056, sample_size_v1=0, sample_size_v2=0, ppl=2.48, wps=565.2, ups=0.54, wpb=1056, bsz=32, num_updates=3240, lr=2.99245e-05, gnorm=1.579, clip=100, loss_scale=512, train_wall=19, gb_free=10.8, wall=6087
2023-05-26 01:04:51 - progress_bar.py[line:272] - INFO: epoch 002:   1521 / 1732 loss=2.525, loss_v1=0, loss_v2=0, nll_loss=1.348, ntokens=1046.7, nsentences=32, sample_size=1046.7, sample_size_v1=0, sample_size_v2=0, ppl=2.55, wps=558.2, ups=0.53, wpb=1046.7, bsz=32, num_updates=3250, lr=2.99183e-05, gnorm=1.419, clip=100, loss_scale=512, train_wall=19, gb_free=11.6, wall=6106
2023-05-26 01:05:10 - progress_bar.py[line:272] - INFO: epoch 002:   1531 / 1732 loss=2.541, loss_v1=0, loss_v2=0, nll_loss=1.358, ntokens=1056, nsentences=32, sample_size=1056, sample_size_v1=0, sample_size_v2=0, ppl=2.56, wps=561.5, ups=0.53, wpb=1056, bsz=32, num_updates=3260, lr=2.99122e-05, gnorm=1.417, clip=100, loss_scale=512, train_wall=19, gb_free=10.7, wall=6124
2023-05-26 01:05:29 - progress_bar.py[line:272] - INFO: epoch 002:   1541 / 1732 loss=2.488, loss_v1=0, loss_v2=0, nll_loss=1.308, ntokens=1105.6, nsentences=32, sample_size=1105.6, sample_size_v1=0, sample_size_v2=0, ppl=2.48, wps=584, ups=0.53, wpb=1105.6, bsz=32, num_updates=3270, lr=2.9906e-05, gnorm=1.42, clip=100, loss_scale=512, train_wall=19, gb_free=11.4, wall=6143
2023-05-26 01:05:47 - progress_bar.py[line:272] - INFO: epoch 002:   1551 / 1732 loss=2.485, loss_v1=0, loss_v2=0, nll_loss=1.301, ntokens=1073.3, nsentences=32, sample_size=1073.3, sample_size_v1=0, sample_size_v2=0, ppl=2.46, wps=571.2, ups=0.53, wpb=1073.3, bsz=32, num_updates=3280, lr=2.98999e-05, gnorm=1.403, clip=100, loss_scale=512, train_wall=19, gb_free=11.3, wall=6162
2023-05-26 01:06:06 - progress_bar.py[line:272] - INFO: epoch 002:   1561 / 1732 loss=2.507, loss_v1=0, loss_v2=0, nll_loss=1.323, ntokens=1091.5, nsentences=32, sample_size=1091.5, sample_size_v1=0, sample_size_v2=0, ppl=2.5, wps=581.2, ups=0.53, wpb=1091.5, bsz=32, num_updates=3290, lr=2.98937e-05, gnorm=1.347, clip=100, loss_scale=512, train_wall=19, gb_free=11.4, wall=6181
2023-05-26 01:06:25 - progress_bar.py[line:272] - INFO: epoch 002:   1571 / 1732 loss=2.536, loss_v1=0, loss_v2=0, nll_loss=1.356, ntokens=1079.7, nsentences=32, sample_size=1079.7, sample_size_v1=0, sample_size_v2=0, ppl=2.56, wps=572.3, ups=0.53, wpb=1079.7, bsz=32, num_updates=3300, lr=2.98876e-05, gnorm=1.497, clip=100, loss_scale=512, train_wall=19, gb_free=10.6, wall=6200
2023-05-26 01:06:44 - progress_bar.py[line:272] - INFO: epoch 002:   1581 / 1732 loss=2.536, loss_v1=0, loss_v2=0, nll_loss=1.361, ntokens=984.8, nsentences=32, sample_size=984.8, sample_size_v1=0, sample_size_v2=0, ppl=2.57, wps=525.7, ups=0.53, wpb=984.8, bsz=32, num_updates=3310, lr=2.98815e-05, gnorm=1.614, clip=100, loss_scale=512, train_wall=19, gb_free=10.9, wall=6219
2023-05-26 01:06:48 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 512.0
2023-05-26 01:07:05 - progress_bar.py[line:272] - INFO: epoch 002:   1592 / 1732 loss=2.502, loss_v1=0, loss_v2=0, nll_loss=1.315, ntokens=1089.6, nsentences=32, sample_size=1089.6, sample_size_v1=0, sample_size_v2=0, ppl=2.49, wps=526.2, ups=0.48, wpb=1089.6, bsz=32, num_updates=3320, lr=2.98753e-05, gnorm=1.39, clip=100, loss_scale=512, train_wall=21, gb_free=11.6, wall=6239
2023-05-26 01:07:23 - progress_bar.py[line:272] - INFO: epoch 002:   1602 / 1732 loss=2.476, loss_v1=0, loss_v2=0, nll_loss=1.292, ntokens=1101.7, nsentences=32, sample_size=1101.7, sample_size_v1=0, sample_size_v2=0, ppl=2.45, wps=586.2, ups=0.53, wpb=1101.7, bsz=32, num_updates=3330, lr=2.98692e-05, gnorm=1.362, clip=100, loss_scale=512, train_wall=19, gb_free=10.5, wall=6258
2023-05-26 01:07:42 - progress_bar.py[line:272] - INFO: epoch 002:   1612 / 1732 loss=2.467, loss_v1=0, loss_v2=0, nll_loss=1.278, ntokens=1156, nsentences=32, sample_size=1156, sample_size_v1=0, sample_size_v2=0, ppl=2.42, wps=610.7, ups=0.53, wpb=1156, bsz=32, num_updates=3340, lr=2.9863e-05, gnorm=1.439, clip=100, loss_scale=512, train_wall=19, gb_free=11.4, wall=6277
2023-05-26 01:08:01 - progress_bar.py[line:272] - INFO: epoch 002:   1622 / 1732 loss=2.466, loss_v1=0, loss_v2=0, nll_loss=1.279, ntokens=1098.4, nsentences=32, sample_size=1098.4, sample_size_v1=0, sample_size_v2=0, ppl=2.43, wps=579.9, ups=0.53, wpb=1098.4, bsz=32, num_updates=3350, lr=2.98569e-05, gnorm=1.349, clip=100, loss_scale=512, train_wall=19, gb_free=11.5, wall=6296
2023-05-26 01:08:20 - progress_bar.py[line:272] - INFO: epoch 002:   1632 / 1732 loss=2.48, loss_v1=0, loss_v2=0, nll_loss=1.298, ntokens=1161.4, nsentences=32, sample_size=1161.4, sample_size_v1=0, sample_size_v2=0, ppl=2.46, wps=614.6, ups=0.53, wpb=1161.4, bsz=32, num_updates=3360, lr=2.98507e-05, gnorm=1.399, clip=100, loss_scale=512, train_wall=19, gb_free=11.6, wall=6315
2023-05-26 01:08:39 - progress_bar.py[line:272] - INFO: epoch 002:   1642 / 1732 loss=2.447, loss_v1=0, loss_v2=0, nll_loss=1.251, ntokens=1223.1, nsentences=32, sample_size=1223.1, sample_size_v1=0, sample_size_v2=0, ppl=2.38, wps=646.3, ups=0.53, wpb=1223.1, bsz=32, num_updates=3370, lr=2.98446e-05, gnorm=1.251, clip=100, loss_scale=512, train_wall=19, gb_free=10.9, wall=6334
2023-05-26 01:08:58 - progress_bar.py[line:272] - INFO: epoch 002:   1652 / 1732 loss=2.478, loss_v1=0, loss_v2=0, nll_loss=1.296, ntokens=1045.5, nsentences=32, sample_size=1045.5, sample_size_v1=0, sample_size_v2=0, ppl=2.46, wps=557.8, ups=0.53, wpb=1045.5, bsz=32, num_updates=3380, lr=2.98385e-05, gnorm=1.5, clip=100, loss_scale=512, train_wall=19, gb_free=11.2, wall=6352
2023-05-26 01:09:17 - progress_bar.py[line:272] - INFO: epoch 002:   1662 / 1732 loss=2.504, loss_v1=0, loss_v2=0, nll_loss=1.316, ntokens=1037.9, nsentences=32, sample_size=1037.9, sample_size_v1=0, sample_size_v2=0, ppl=2.49, wps=550.5, ups=0.53, wpb=1037.9, bsz=32, num_updates=3390, lr=2.98323e-05, gnorm=1.384, clip=100, loss_scale=512, train_wall=19, gb_free=11.4, wall=6371
2023-05-26 01:09:35 - progress_bar.py[line:272] - INFO: epoch 002:   1672 / 1732 loss=2.482, loss_v1=0, loss_v2=0, nll_loss=1.302, ntokens=1009.9, nsentences=32, sample_size=1009.9, sample_size_v1=0, sample_size_v2=0, ppl=2.47, wps=539.9, ups=0.53, wpb=1009.9, bsz=32, num_updates=3400, lr=2.98262e-05, gnorm=1.476, clip=100, loss_scale=512, train_wall=19, gb_free=10.9, wall=6390
2023-05-26 01:09:54 - progress_bar.py[line:272] - INFO: epoch 002:   1682 / 1732 loss=2.458, loss_v1=0, loss_v2=0, nll_loss=1.269, ntokens=1181.4, nsentences=32, sample_size=1181.4, sample_size_v1=0, sample_size_v2=0, ppl=2.41, wps=620.3, ups=0.53, wpb=1181.4, bsz=32, num_updates=3410, lr=2.982e-05, gnorm=1.405, clip=100, loss_scale=512, train_wall=19, gb_free=11.3, wall=6409
2023-05-26 01:10:14 - progress_bar.py[line:272] - INFO: epoch 002:   1692 / 1732 loss=2.458, loss_v1=0, loss_v2=0, nll_loss=1.27, ntokens=1233.5, nsentences=32, sample_size=1233.5, sample_size_v1=0, sample_size_v2=0, ppl=2.41, wps=643.5, ups=0.52, wpb=1233.5, bsz=32, num_updates=3420, lr=2.98139e-05, gnorm=1.303, clip=100, loss_scale=512, train_wall=19, gb_free=10.8, wall=6428
2023-05-26 01:10:33 - progress_bar.py[line:272] - INFO: epoch 002:   1702 / 1732 loss=2.477, loss_v1=0, loss_v2=0, nll_loss=1.292, ntokens=1273, nsentences=32, sample_size=1273, sample_size_v1=0, sample_size_v2=0, ppl=2.45, wps=664.9, ups=0.52, wpb=1273, bsz=32, num_updates=3430, lr=2.98078e-05, gnorm=1.284, clip=100, loss_scale=512, train_wall=19, gb_free=10.7, wall=6447
2023-05-26 01:10:52 - progress_bar.py[line:272] - INFO: epoch 002:   1712 / 1732 loss=2.484, loss_v1=0, loss_v2=0, nll_loss=1.295, ntokens=1144.5, nsentences=32, sample_size=1144.5, sample_size_v1=0, sample_size_v2=0, ppl=2.45, wps=604.5, ups=0.53, wpb=1144.5, bsz=32, num_updates=3440, lr=2.98016e-05, gnorm=1.33, clip=100, loss_scale=512, train_wall=19, gb_free=11.4, wall=6466
2023-05-26 01:11:11 - progress_bar.py[line:272] - INFO: epoch 002:   1722 / 1732 loss=2.475, loss_v1=0, loss_v2=0, nll_loss=1.288, ntokens=1176.1, nsentences=32, sample_size=1176.1, sample_size_v1=0, sample_size_v2=0, ppl=2.44, wps=617.4, ups=0.52, wpb=1176.1, bsz=32, num_updates=3450, lr=2.97955e-05, gnorm=1.376, clip=100, loss_scale=512, train_wall=19, gb_free=11.3, wall=6485
2023-05-26 01:11:28 - progress_bar.py[line:272] - INFO: epoch 002:   1732 / 1732 loss=2.517, loss_v1=0, loss_v2=0, nll_loss=1.334, ntokens=1056.7, nsentences=29.6, sample_size=1056.7, sample_size_v1=0, sample_size_v2=0, ppl=2.52, wps=603.4, ups=0.57, wpb=1056.7, bsz=29.6, num_updates=3460, lr=2.97893e-05, gnorm=1.434, clip=100, loss_scale=512, train_wall=17, gb_free=11.7, wall=6503
2023-05-26 01:11:28 - train.py[line:332] - INFO: end of epoch 2 (average epoch stats below)
2023-05-26 01:11:28 - progress_bar.py[line:282] - INFO: epoch 002 | loss 2.578 | loss_v1 0 | loss_v2 0 | nll_loss 1.41 | ntokens 1051.58 | nsentences 31.986 | sample_size 1051.58 | sample_size_v1 0 | sample_size_v2 0 | ppl 2.66 | wps 560.5 | ups 0.53 | wpb 1051.6 | bsz 32 | num_updates 3460 | lr 2.97893e-05 | gnorm 1.558 | clip 100 | loss_scale 512 | train_wall 3238 | gb_free 11.7 | wall 6503
2023-05-26 01:11:28 - trainer.py[line:639] - INFO: loading train data for epoch 3
local datafile ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 0 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 0 finished initializing row_count and line_idx-to-offset mapping
file ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 0 row count 55400 total row count 55400
slice_id 0 seek offset 0
2023-05-26 01:11:30 - trainer.py[line:703] - INFO: begin training epoch 3
2023-05-26 01:11:30 - train.py[line:305] - INFO: Start iterating over samples
2023-05-26 01:11:50 - progress_bar.py[line:272] - INFO: epoch 003:     10 / 1732 loss=2.426, loss_v1=0, loss_v2=0, nll_loss=1.234, ntokens=1132.5, nsentences=32, sample_size=1132.5, sample_size_v1=0, sample_size_v2=0, ppl=2.35, wps=531.2, ups=0.47, wpb=1132.5, bsz=32, num_updates=3470, lr=2.97832e-05, gnorm=1.527, clip=100, loss_scale=512, train_wall=19, gb_free=10.2, wall=6524
2023-05-26 01:12:08 - progress_bar.py[line:272] - INFO: epoch 003:     20 / 1732 loss=2.35, loss_v1=0, loss_v2=0, nll_loss=1.146, ntokens=1079.2, nsentences=32, sample_size=1079.2, sample_size_v1=0, sample_size_v2=0, ppl=2.21, wps=572.6, ups=0.53, wpb=1079.2, bsz=32, num_updates=3480, lr=2.9777e-05, gnorm=1.437, clip=100, loss_scale=512, train_wall=19, gb_free=11.4, wall=6543
2023-05-26 01:12:27 - progress_bar.py[line:272] - INFO: epoch 003:     30 / 1732 loss=2.426, loss_v1=0, loss_v2=0, nll_loss=1.233, ntokens=962.6, nsentences=32, sample_size=962.6, sample_size_v1=0, sample_size_v2=0, ppl=2.35, wps=513.3, ups=0.53, wpb=962.6, bsz=32, num_updates=3490, lr=2.97709e-05, gnorm=1.738, clip=100, loss_scale=512, train_wall=19, gb_free=11.3, wall=6562
2023-05-26 01:12:46 - progress_bar.py[line:272] - INFO: epoch 003:     40 / 1732 loss=2.249, loss_v1=0, loss_v2=0, nll_loss=1.038, ntokens=1211.6, nsentences=32, sample_size=1211.6, sample_size_v1=0, sample_size_v2=0, ppl=2.05, wps=632.9, ups=0.52, wpb=1211.6, bsz=32, num_updates=3500, lr=2.97648e-05, gnorm=1.378, clip=100, loss_scale=512, train_wall=19, gb_free=11.3, wall=6581
2023-05-26 01:13:05 - progress_bar.py[line:272] - INFO: epoch 003:     50 / 1732 loss=2.357, loss_v1=0, loss_v2=0, nll_loss=1.153, ntokens=1054.8, nsentences=32, sample_size=1054.8, sample_size_v1=0, sample_size_v2=0, ppl=2.22, wps=558.3, ups=0.53, wpb=1054.8, bsz=32, num_updates=3510, lr=2.97586e-05, gnorm=1.799, clip=100, loss_scale=512, train_wall=19, gb_free=11.1, wall=6600
2023-05-26 01:13:24 - progress_bar.py[line:272] - INFO: epoch 003:     60 / 1732 loss=2.135, loss_v1=0, loss_v2=0, nll_loss=0.909, ntokens=1049.9, nsentences=32, sample_size=1049.9, sample_size_v1=0, sample_size_v2=0, ppl=1.88, wps=562, ups=0.54, wpb=1049.9, bsz=32, num_updates=3520, lr=2.97525e-05, gnorm=1.593, clip=100, loss_scale=512, train_wall=19, gb_free=10.3, wall=6619
2023-05-26 01:13:43 - progress_bar.py[line:272] - INFO: epoch 003:     70 / 1732 loss=2.177, loss_v1=0, loss_v2=0, nll_loss=0.952, ntokens=1412, nsentences=32, sample_size=1412, sample_size_v1=0, sample_size_v2=0, ppl=1.93, wps=723, ups=0.51, wpb=1412, bsz=32, num_updates=3530, lr=2.97463e-05, gnorm=1.371, clip=90, loss_scale=512, train_wall=19, gb_free=10.8, wall=6638
2023-05-26 01:14:03 - progress_bar.py[line:272] - INFO: epoch 003:     80 / 1732 loss=2.245, loss_v1=0, loss_v2=0, nll_loss=1.031, ntokens=1259.9, nsentences=32, sample_size=1259.9, sample_size_v1=0, sample_size_v2=0, ppl=2.04, wps=649.2, ups=0.52, wpb=1259.9, bsz=32, num_updates=3540, lr=2.97402e-05, gnorm=1.436, clip=100, loss_scale=512, train_wall=19, gb_free=10.6, wall=6658
2023-05-26 01:14:22 - progress_bar.py[line:272] - INFO: epoch 003:     90 / 1732 loss=2.342, loss_v1=0, loss_v2=0, nll_loss=1.133, ntokens=1086.9, nsentences=32, sample_size=1086.9, sample_size_v1=0, sample_size_v2=0, ppl=2.19, wps=569.5, ups=0.52, wpb=1086.9, bsz=32, num_updates=3550, lr=2.9734e-05, gnorm=1.372, clip=100, loss_scale=512, train_wall=19, gb_free=11, wall=6677
2023-05-26 01:14:41 - progress_bar.py[line:272] - INFO: epoch 003:    100 / 1732 loss=2.326, loss_v1=0, loss_v2=0, nll_loss=1.128, ntokens=1024.5, nsentences=32, sample_size=1024.5, sample_size_v1=0, sample_size_v2=0, ppl=2.19, wps=547.5, ups=0.53, wpb=1024.5, bsz=32, num_updates=3560, lr=2.97279e-05, gnorm=1.63, clip=100, loss_scale=512, train_wall=19, gb_free=10.9, wall=6695
2023-05-26 01:14:59 - progress_bar.py[line:272] - INFO: epoch 003:    110 / 1732 loss=2.503, loss_v1=0, loss_v2=0, nll_loss=1.318, ntokens=1011.2, nsentences=32, sample_size=1011.2, sample_size_v1=0, sample_size_v2=0, ppl=2.49, wps=537.5, ups=0.53, wpb=1011.2, bsz=32, num_updates=3570, lr=2.97218e-05, gnorm=1.529, clip=100, loss_scale=512, train_wall=19, gb_free=11, wall=6714
2023-05-26 01:15:19 - progress_bar.py[line:272] - INFO: epoch 003:    120 / 1732 loss=2.44, loss_v1=0, loss_v2=0, nll_loss=1.247, ntokens=1124.3, nsentences=32, sample_size=1124.3, sample_size_v1=0, sample_size_v2=0, ppl=2.37, wps=588.5, ups=0.52, wpb=1124.3, bsz=32, num_updates=3580, lr=2.97156e-05, gnorm=1.36, clip=100, loss_scale=512, train_wall=19, gb_free=10.6, wall=6733
2023-05-26 01:15:38 - progress_bar.py[line:272] - INFO: epoch 003:    130 / 1732 loss=2.417, loss_v1=0, loss_v2=0, nll_loss=1.221, ntokens=1171.7, nsentences=32, sample_size=1171.7, sample_size_v1=0, sample_size_v2=0, ppl=2.33, wps=609.6, ups=0.52, wpb=1171.7, bsz=32, num_updates=3590, lr=2.97095e-05, gnorm=1.283, clip=100, loss_scale=512, train_wall=19, gb_free=10.2, wall=6752
2023-05-26 01:15:57 - progress_bar.py[line:272] - INFO: epoch 003:    140 / 1732 loss=2.385, loss_v1=0, loss_v2=0, nll_loss=1.186, ntokens=1245, nsentences=32, sample_size=1245, sample_size_v1=0, sample_size_v2=0, ppl=2.27, wps=650.1, ups=0.52, wpb=1245, bsz=32, num_updates=3600, lr=2.97033e-05, gnorm=1.373, clip=100, loss_scale=512, train_wall=19, gb_free=10.2, wall=6772
2023-05-26 01:16:16 - progress_bar.py[line:272] - INFO: epoch 003:    150 / 1732 loss=2.357, loss_v1=0, loss_v2=0, nll_loss=1.156, ntokens=1172.1, nsentences=32, sample_size=1172.1, sample_size_v1=0, sample_size_v2=0, ppl=2.23, wps=609.4, ups=0.52, wpb=1172.1, bsz=32, num_updates=3610, lr=2.96972e-05, gnorm=1.292, clip=100, loss_scale=512, train_wall=19, gb_free=11, wall=6791
2023-05-26 01:16:35 - progress_bar.py[line:272] - INFO: epoch 003:    160 / 1732 loss=2.381, loss_v1=0, loss_v2=0, nll_loss=1.183, ntokens=1127.8, nsentences=32, sample_size=1127.8, sample_size_v1=0, sample_size_v2=0, ppl=2.27, wps=590, ups=0.52, wpb=1127.8, bsz=32, num_updates=3620, lr=2.96911e-05, gnorm=1.287, clip=100, loss_scale=512, train_wall=19, gb_free=10.9, wall=6810
2023-05-26 01:16:54 - progress_bar.py[line:272] - INFO: epoch 003:    170 / 1732 loss=2.375, loss_v1=0, loss_v2=0, nll_loss=1.172, ntokens=965.3, nsentences=32, sample_size=965.3, sample_size_v1=0, sample_size_v2=0, ppl=2.25, wps=512.5, ups=0.53, wpb=965.3, bsz=32, num_updates=3630, lr=2.96849e-05, gnorm=1.457, clip=100, loss_scale=512, train_wall=19, gb_free=11.4, wall=6829
2023-05-26 01:17:13 - progress_bar.py[line:272] - INFO: epoch 003:    180 / 1732 loss=2.335, loss_v1=0, loss_v2=0, nll_loss=1.132, ntokens=1102.7, nsentences=32, sample_size=1102.7, sample_size_v1=0, sample_size_v2=0, ppl=2.19, wps=579.7, ups=0.53, wpb=1102.7, bsz=32, num_updates=3640, lr=2.96788e-05, gnorm=1.486, clip=90, loss_scale=512, train_wall=19, gb_free=10.9, wall=6848
2023-05-26 01:17:32 - progress_bar.py[line:272] - INFO: epoch 003:    190 / 1732 loss=2.357, loss_v1=0, loss_v2=0, nll_loss=1.154, ntokens=1120.1, nsentences=32, sample_size=1120.1, sample_size_v1=0, sample_size_v2=0, ppl=2.23, wps=588.2, ups=0.53, wpb=1120.1, bsz=32, num_updates=3650, lr=2.96726e-05, gnorm=1.365, clip=100, loss_scale=512, train_wall=19, gb_free=10.7, wall=6867
2023-05-26 01:17:51 - progress_bar.py[line:272] - INFO: epoch 003:    200 / 1732 loss=2.409, loss_v1=0, loss_v2=0, nll_loss=1.214, ntokens=1100.1, nsentences=32, sample_size=1100.1, sample_size_v1=0, sample_size_v2=0, ppl=2.32, wps=581.8, ups=0.53, wpb=1100.1, bsz=32, num_updates=3660, lr=2.96665e-05, gnorm=1.405, clip=100, loss_scale=512, train_wall=19, gb_free=11.7, wall=6886
2023-05-26 01:18:10 - progress_bar.py[line:272] - INFO: epoch 003:    210 / 1732 loss=2.515, loss_v1=0, loss_v2=0, nll_loss=1.332, ntokens=1012.9, nsentences=32, sample_size=1012.9, sample_size_v1=0, sample_size_v2=0, ppl=2.52, wps=543, ups=0.54, wpb=1012.9, bsz=32, num_updates=3670, lr=2.96603e-05, gnorm=1.548, clip=100, loss_scale=512, train_wall=19, gb_free=11.3, wall=6904
2023-05-26 01:18:28 - progress_bar.py[line:272] - INFO: epoch 003:    220 / 1732 loss=2.504, loss_v1=0, loss_v2=0, nll_loss=1.318, ntokens=1142.1, nsentences=32, sample_size=1142.1, sample_size_v1=0, sample_size_v2=0, ppl=2.49, wps=610.9, ups=0.53, wpb=1142.1, bsz=32, num_updates=3680, lr=2.96542e-05, gnorm=1.447, clip=100, loss_scale=512, train_wall=19, gb_free=11.2, wall=6923
2023-05-26 01:18:34 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 256.0
2023-05-26 01:18:49 - progress_bar.py[line:272] - INFO: epoch 003:    231 / 1732 loss=2.541, loss_v1=0, loss_v2=0, nll_loss=1.362, ntokens=1079.8, nsentences=32, sample_size=1079.8, sample_size_v1=0, sample_size_v2=0, ppl=2.57, wps=526, ups=0.49, wpb=1079.8, bsz=32, num_updates=3690, lr=2.96481e-05, gnorm=1.636, clip=100, loss_scale=256, train_wall=20, gb_free=11.6, wall=6944
2023-05-26 01:19:08 - progress_bar.py[line:272] - INFO: epoch 003:    241 / 1732 loss=2.549, loss_v1=0, loss_v2=0, nll_loss=1.372, ntokens=1114.7, nsentences=32, sample_size=1114.7, sample_size_v1=0, sample_size_v2=0, ppl=2.59, wps=593.7, ups=0.53, wpb=1114.7, bsz=32, num_updates=3700, lr=2.96419e-05, gnorm=1.46, clip=100, loss_scale=256, train_wall=19, gb_free=11.6, wall=6962
2023-05-26 01:19:27 - progress_bar.py[line:272] - INFO: epoch 003:    251 / 1732 loss=2.513, loss_v1=0, loss_v2=0, nll_loss=1.33, ntokens=1172.1, nsentences=32, sample_size=1172.1, sample_size_v1=0, sample_size_v2=0, ppl=2.51, wps=621.5, ups=0.53, wpb=1172.1, bsz=32, num_updates=3710, lr=2.96358e-05, gnorm=1.34, clip=100, loss_scale=256, train_wall=19, gb_free=11.6, wall=6981
2023-05-26 01:19:45 - progress_bar.py[line:272] - INFO: epoch 003:    261 / 1732 loss=2.55, loss_v1=0, loss_v2=0, nll_loss=1.371, ntokens=1139.9, nsentences=32, sample_size=1139.9, sample_size_v1=0, sample_size_v2=0, ppl=2.59, wps=609, ups=0.53, wpb=1139.9, bsz=32, num_updates=3720, lr=2.96296e-05, gnorm=1.352, clip=100, loss_scale=256, train_wall=19, gb_free=11.1, wall=7000
2023-05-26 01:20:04 - progress_bar.py[line:272] - INFO: epoch 003:    271 / 1732 loss=2.503, loss_v1=0, loss_v2=0, nll_loss=1.319, ntokens=1145.3, nsentences=32, sample_size=1145.3, sample_size_v1=0, sample_size_v2=0, ppl=2.5, wps=607.5, ups=0.53, wpb=1145.3, bsz=32, num_updates=3730, lr=2.96235e-05, gnorm=1.413, clip=100, loss_scale=256, train_wall=19, gb_free=11.2, wall=7019
2023-05-26 01:20:23 - progress_bar.py[line:272] - INFO: epoch 003:    281 / 1732 loss=2.533, loss_v1=0, loss_v2=0, nll_loss=1.351, ntokens=1149.7, nsentences=32, sample_size=1149.7, sample_size_v1=0, sample_size_v2=0, ppl=2.55, wps=606.1, ups=0.53, wpb=1149.7, bsz=32, num_updates=3740, lr=2.96173e-05, gnorm=1.342, clip=100, loss_scale=256, train_wall=19, gb_free=11.7, wall=7038
2023-05-26 01:20:42 - progress_bar.py[line:272] - INFO: epoch 003:    291 / 1732 loss=2.493, loss_v1=0, loss_v2=0, nll_loss=1.308, ntokens=1130.5, nsentences=32, sample_size=1130.5, sample_size_v1=0, sample_size_v2=0, ppl=2.48, wps=601.8, ups=0.53, wpb=1130.5, bsz=32, num_updates=3750, lr=2.96112e-05, gnorm=1.265, clip=100, loss_scale=256, train_wall=19, gb_free=11.3, wall=7057
2023-05-26 01:21:01 - progress_bar.py[line:272] - INFO: epoch 003:    301 / 1732 loss=2.523, loss_v1=0, loss_v2=0, nll_loss=1.344, ntokens=1109.1, nsentences=32, sample_size=1109.1, sample_size_v1=0, sample_size_v2=0, ppl=2.54, wps=590.4, ups=0.53, wpb=1109.1, bsz=32, num_updates=3760, lr=2.96051e-05, gnorm=1.471, clip=100, loss_scale=256, train_wall=19, gb_free=11.5, wall=7075
2023-05-26 01:21:19 - progress_bar.py[line:272] - INFO: epoch 003:    311 / 1732 loss=2.482, loss_v1=0, loss_v2=0, nll_loss=1.295, ntokens=1067.3, nsentences=32, sample_size=1067.3, sample_size_v1=0, sample_size_v2=0, ppl=2.45, wps=570.9, ups=0.53, wpb=1067.3, bsz=32, num_updates=3770, lr=2.95989e-05, gnorm=1.393, clip=100, loss_scale=256, train_wall=19, gb_free=11.5, wall=7094
2023-05-26 01:21:38 - progress_bar.py[line:272] - INFO: epoch 003:    321 / 1732 loss=2.537, loss_v1=0, loss_v2=0, nll_loss=1.356, ntokens=1001.7, nsentences=32, sample_size=1001.7, sample_size_v1=0, sample_size_v2=0, ppl=2.56, wps=540.6, ups=0.54, wpb=1001.7, bsz=32, num_updates=3780, lr=2.95928e-05, gnorm=1.458, clip=100, loss_scale=256, train_wall=18, gb_free=11.8, wall=7113
2023-05-26 01:21:57 - progress_bar.py[line:272] - INFO: epoch 003:    331 / 1732 loss=2.533, loss_v1=0, loss_v2=0, nll_loss=1.355, ntokens=1019.4, nsentences=32, sample_size=1019.4, sample_size_v1=0, sample_size_v2=0, ppl=2.56, wps=547.6, ups=0.54, wpb=1019.4, bsz=32, num_updates=3790, lr=2.95866e-05, gnorm=1.391, clip=100, loss_scale=256, train_wall=19, gb_free=11.9, wall=7131
2023-05-26 01:22:15 - progress_bar.py[line:272] - INFO: epoch 003:    341 / 1732 loss=2.493, loss_v1=0, loss_v2=0, nll_loss=1.308, ntokens=952.2, nsentences=32, sample_size=952.2, sample_size_v1=0, sample_size_v2=0, ppl=2.48, wps=514.1, ups=0.54, wpb=952.2, bsz=32, num_updates=3800, lr=2.95805e-05, gnorm=1.445, clip=100, loss_scale=256, train_wall=18, gb_free=11.4, wall=7150
2023-05-26 01:22:34 - progress_bar.py[line:272] - INFO: epoch 003:    351 / 1732 loss=2.518, loss_v1=0, loss_v2=0, nll_loss=1.335, ntokens=941.5, nsentences=32, sample_size=941.5, sample_size_v1=0, sample_size_v2=0, ppl=2.52, wps=508.9, ups=0.54, wpb=941.5, bsz=32, num_updates=3810, lr=2.95744e-05, gnorm=1.566, clip=100, loss_scale=256, train_wall=18, gb_free=11.5, wall=7168
2023-05-26 01:22:52 - progress_bar.py[line:272] - INFO: epoch 003:    361 / 1732 loss=2.532, loss_v1=0, loss_v2=0, nll_loss=1.349, ntokens=925.7, nsentences=32, sample_size=925.7, sample_size_v1=0, sample_size_v2=0, ppl=2.55, wps=500.9, ups=0.54, wpb=925.7, bsz=32, num_updates=3820, lr=2.95682e-05, gnorm=1.513, clip=100, loss_scale=256, train_wall=18, gb_free=11.5, wall=7187
2023-05-26 01:23:11 - progress_bar.py[line:272] - INFO: epoch 003:    371 / 1732 loss=2.553, loss_v1=0, loss_v2=0, nll_loss=1.375, ntokens=989.1, nsentences=32, sample_size=989.1, sample_size_v1=0, sample_size_v2=0, ppl=2.59, wps=533.1, ups=0.54, wpb=989.1, bsz=32, num_updates=3830, lr=2.95621e-05, gnorm=1.523, clip=100, loss_scale=256, train_wall=19, gb_free=11, wall=7205
2023-05-26 01:23:29 - progress_bar.py[line:272] - INFO: epoch 003:    381 / 1732 loss=2.539, loss_v1=0, loss_v2=0, nll_loss=1.358, ntokens=1071.8, nsentences=32, sample_size=1071.8, sample_size_v1=0, sample_size_v2=0, ppl=2.56, wps=578.2, ups=0.54, wpb=1071.8, bsz=32, num_updates=3840, lr=2.95559e-05, gnorm=1.459, clip=100, loss_scale=256, train_wall=19, gb_free=11.3, wall=7224
2023-05-26 01:23:48 - progress_bar.py[line:272] - INFO: epoch 003:    391 / 1732 loss=2.511, loss_v1=0, loss_v2=0, nll_loss=1.33, ntokens=986, nsentences=32, sample_size=986, sample_size_v1=0, sample_size_v2=0, ppl=2.51, wps=530.4, ups=0.54, wpb=986, bsz=32, num_updates=3850, lr=2.95498e-05, gnorm=1.549, clip=100, loss_scale=256, train_wall=19, gb_free=11.6, wall=7243
2023-05-26 01:24:06 - progress_bar.py[line:272] - INFO: epoch 003:    401 / 1732 loss=2.502, loss_v1=0, loss_v2=0, nll_loss=1.316, ntokens=999.1, nsentences=32, sample_size=999.1, sample_size_v1=0, sample_size_v2=0, ppl=2.49, wps=538.7, ups=0.54, wpb=999.1, bsz=32, num_updates=3860, lr=2.95436e-05, gnorm=1.525, clip=100, loss_scale=256, train_wall=19, gb_free=11.3, wall=7261
2023-05-26 01:24:25 - progress_bar.py[line:272] - INFO: epoch 003:    411 / 1732 loss=2.495, loss_v1=0, loss_v2=0, nll_loss=1.31, ntokens=1079.4, nsentences=32, sample_size=1079.4, sample_size_v1=0, sample_size_v2=0, ppl=2.48, wps=578.8, ups=0.54, wpb=1079.4, bsz=32, num_updates=3870, lr=2.95375e-05, gnorm=1.464, clip=100, loss_scale=256, train_wall=19, gb_free=11.5, wall=7280
2023-05-26 01:24:44 - progress_bar.py[line:272] - INFO: epoch 003:    421 / 1732 loss=2.478, loss_v1=0, loss_v2=0, nll_loss=1.292, ntokens=1019, nsentences=32, sample_size=1019, sample_size_v1=0, sample_size_v2=0, ppl=2.45, wps=547.1, ups=0.54, wpb=1019, bsz=32, num_updates=3880, lr=2.95314e-05, gnorm=1.448, clip=100, loss_scale=256, train_wall=19, gb_free=11.3, wall=7298
2023-05-26 01:25:02 - progress_bar.py[line:272] - INFO: epoch 003:    431 / 1732 loss=2.493, loss_v1=0, loss_v2=0, nll_loss=1.307, ntokens=1019.7, nsentences=32, sample_size=1019.7, sample_size_v1=0, sample_size_v2=0, ppl=2.47, wps=547.7, ups=0.54, wpb=1019.7, bsz=32, num_updates=3890, lr=2.95252e-05, gnorm=1.486, clip=100, loss_scale=256, train_wall=19, gb_free=11.3, wall=7317
2023-05-26 01:25:21 - progress_bar.py[line:272] - INFO: epoch 003:    441 / 1732 loss=2.512, loss_v1=0, loss_v2=0, nll_loss=1.33, ntokens=990.4, nsentences=32, sample_size=990.4, sample_size_v1=0, sample_size_v2=0, ppl=2.51, wps=534.5, ups=0.54, wpb=990.4, bsz=32, num_updates=3900, lr=2.95191e-05, gnorm=1.435, clip=100, loss_scale=256, train_wall=18, gb_free=11.9, wall=7336
2023-05-26 01:25:39 - progress_bar.py[line:272] - INFO: epoch 003:    451 / 1732 loss=2.511, loss_v1=0, loss_v2=0, nll_loss=1.326, ntokens=920.2, nsentences=32, sample_size=920.2, sample_size_v1=0, sample_size_v2=0, ppl=2.51, wps=495.7, ups=0.54, wpb=920.2, bsz=32, num_updates=3910, lr=2.95129e-05, gnorm=1.473, clip=100, loss_scale=256, train_wall=19, gb_free=10.9, wall=7354
2023-05-26 01:25:58 - progress_bar.py[line:272] - INFO: epoch 003:    461 / 1732 loss=2.521, loss_v1=0, loss_v2=0, nll_loss=1.34, ntokens=1038.5, nsentences=32, sample_size=1038.5, sample_size_v1=0, sample_size_v2=0, ppl=2.53, wps=559.5, ups=0.54, wpb=1038.5, bsz=32, num_updates=3920, lr=2.95068e-05, gnorm=1.451, clip=100, loss_scale=256, train_wall=19, gb_free=11.2, wall=7373
2023-05-26 01:26:17 - progress_bar.py[line:272] - INFO: epoch 003:    471 / 1732 loss=2.51, loss_v1=0, loss_v2=0, nll_loss=1.323, ntokens=1039.4, nsentences=32, sample_size=1039.4, sample_size_v1=0, sample_size_v2=0, ppl=2.5, wps=555.2, ups=0.53, wpb=1039.4, bsz=32, num_updates=3930, lr=2.95006e-05, gnorm=1.511, clip=100, loss_scale=256, train_wall=19, gb_free=11.7, wall=7391
2023-05-26 01:26:35 - progress_bar.py[line:272] - INFO: epoch 003:    481 / 1732 loss=2.52, loss_v1=0, loss_v2=0, nll_loss=1.34, ntokens=1025, nsentences=32, sample_size=1025, sample_size_v1=0, sample_size_v2=0, ppl=2.53, wps=550.8, ups=0.54, wpb=1025, bsz=32, num_updates=3940, lr=2.94945e-05, gnorm=1.498, clip=100, loss_scale=256, train_wall=19, gb_free=11.8, wall=7410
2023-05-26 01:26:54 - progress_bar.py[line:272] - INFO: epoch 003:    491 / 1732 loss=2.501, loss_v1=0, loss_v2=0, nll_loss=1.317, ntokens=939.5, nsentences=32, sample_size=939.5, sample_size_v1=0, sample_size_v2=0, ppl=2.49, wps=507.2, ups=0.54, wpb=939.5, bsz=32, num_updates=3950, lr=2.94884e-05, gnorm=1.51, clip=100, loss_scale=256, train_wall=18, gb_free=10.8, wall=7429
2023-05-26 01:27:12 - progress_bar.py[line:272] - INFO: epoch 003:    501 / 1732 loss=2.489, loss_v1=0, loss_v2=0, nll_loss=1.3, ntokens=938, nsentences=32, sample_size=938, sample_size_v1=0, sample_size_v2=0, ppl=2.46, wps=510, ups=0.54, wpb=938, bsz=32, num_updates=3960, lr=2.94822e-05, gnorm=1.485, clip=100, loss_scale=256, train_wall=18, gb_free=11.6, wall=7447
2023-05-26 01:27:31 - progress_bar.py[line:272] - INFO: epoch 003:    511 / 1732 loss=2.532, loss_v1=0, loss_v2=0, nll_loss=1.352, ntokens=1040.7, nsentences=32, sample_size=1040.7, sample_size_v1=0, sample_size_v2=0, ppl=2.55, wps=561.5, ups=0.54, wpb=1040.7, bsz=32, num_updates=3970, lr=2.94761e-05, gnorm=1.394, clip=100, loss_scale=256, train_wall=19, gb_free=12, wall=7465
2023-05-26 01:27:49 - progress_bar.py[line:272] - INFO: epoch 003:    521 / 1732 loss=2.481, loss_v1=0, loss_v2=0, nll_loss=1.294, ntokens=1020.1, nsentences=32, sample_size=1020.1, sample_size_v1=0, sample_size_v2=0, ppl=2.45, wps=551.7, ups=0.54, wpb=1020.1, bsz=32, num_updates=3980, lr=2.94699e-05, gnorm=1.427, clip=100, loss_scale=256, train_wall=18, gb_free=11.6, wall=7484
2023-05-26 01:28:08 - progress_bar.py[line:272] - INFO: epoch 003:    531 / 1732 loss=2.512, loss_v1=0, loss_v2=0, nll_loss=1.328, ntokens=931.7, nsentences=32, sample_size=931.7, sample_size_v1=0, sample_size_v2=0, ppl=2.51, wps=505.4, ups=0.54, wpb=931.7, bsz=32, num_updates=3990, lr=2.94638e-05, gnorm=1.567, clip=100, loss_scale=256, train_wall=18, gb_free=11.6, wall=7502
2023-05-26 01:28:26 - progress_bar.py[line:272] - INFO: epoch 003:    541 / 1732 loss=2.497, loss_v1=0, loss_v2=0, nll_loss=1.313, ntokens=994.8, nsentences=32, sample_size=994.8, sample_size_v1=0, sample_size_v2=0, ppl=2.49, wps=539.5, ups=0.54, wpb=994.8, bsz=32, num_updates=4000, lr=2.94577e-05, gnorm=1.474, clip=100, loss_scale=256, train_wall=18, gb_free=12, wall=7521
2023-05-26 01:28:45 - progress_bar.py[line:272] - INFO: epoch 003:    551 / 1732 loss=2.532, loss_v1=0, loss_v2=0, nll_loss=1.35, ntokens=1021.9, nsentences=32, sample_size=1021.9, sample_size_v1=0, sample_size_v2=0, ppl=2.55, wps=548.5, ups=0.54, wpb=1021.9, bsz=32, num_updates=4010, lr=2.94515e-05, gnorm=1.448, clip=100, loss_scale=256, train_wall=19, gb_free=11.3, wall=7539
2023-05-26 01:29:03 - progress_bar.py[line:272] - INFO: epoch 003:    561 / 1732 loss=2.528, loss_v1=0, loss_v2=0, nll_loss=1.345, ntokens=1030.9, nsentences=32, sample_size=1030.9, sample_size_v1=0, sample_size_v2=0, ppl=2.54, wps=554.5, ups=0.54, wpb=1030.9, bsz=32, num_updates=4020, lr=2.94454e-05, gnorm=1.543, clip=100, loss_scale=256, train_wall=19, gb_free=11.3, wall=7558
2023-05-26 01:29:22 - progress_bar.py[line:272] - INFO: epoch 003:    571 / 1732 loss=2.539, loss_v1=0, loss_v2=0, nll_loss=1.358, ntokens=990.9, nsentences=32, sample_size=990.9, sample_size_v1=0, sample_size_v2=0, ppl=2.56, wps=532.6, ups=0.54, wpb=990.9, bsz=32, num_updates=4030, lr=2.94392e-05, gnorm=1.504, clip=100, loss_scale=256, train_wall=19, gb_free=11.8, wall=7577
2023-05-26 01:29:41 - progress_bar.py[line:272] - INFO: epoch 003:    581 / 1732 loss=2.507, loss_v1=0, loss_v2=0, nll_loss=1.323, ntokens=1021.6, nsentences=32, sample_size=1021.6, sample_size_v1=0, sample_size_v2=0, ppl=2.5, wps=545, ups=0.53, wpb=1021.6, bsz=32, num_updates=4040, lr=2.94331e-05, gnorm=1.482, clip=100, loss_scale=256, train_wall=19, gb_free=10.7, wall=7595
2023-05-26 01:29:59 - progress_bar.py[line:272] - INFO: epoch 003:    591 / 1732 loss=2.5, loss_v1=0, loss_v2=0, nll_loss=1.317, ntokens=934.4, nsentences=32, sample_size=934.4, sample_size_v1=0, sample_size_v2=0, ppl=2.49, wps=502.3, ups=0.54, wpb=934.4, bsz=32, num_updates=4050, lr=2.94269e-05, gnorm=1.582, clip=100, loss_scale=256, train_wall=19, gb_free=10.7, wall=7614
2023-05-26 01:30:18 - progress_bar.py[line:272] - INFO: epoch 003:    601 / 1732 loss=2.483, loss_v1=0, loss_v2=0, nll_loss=1.3, ntokens=941.2, nsentences=32, sample_size=941.2, sample_size_v1=0, sample_size_v2=0, ppl=2.46, wps=507.1, ups=0.54, wpb=941.2, bsz=32, num_updates=4060, lr=2.94208e-05, gnorm=1.64, clip=100, loss_scale=256, train_wall=19, gb_free=11.6, wall=7633
2023-05-26 01:30:36 - progress_bar.py[line:272] - INFO: epoch 003:    611 / 1732 loss=2.493, loss_v1=0, loss_v2=0, nll_loss=1.304, ntokens=911.9, nsentences=32, sample_size=911.9, sample_size_v1=0, sample_size_v2=0, ppl=2.47, wps=494.2, ups=0.54, wpb=911.9, bsz=32, num_updates=4070, lr=2.94147e-05, gnorm=1.658, clip=100, loss_scale=256, train_wall=18, gb_free=11.7, wall=7651
2023-05-26 01:30:55 - progress_bar.py[line:272] - INFO: epoch 003:    621 / 1732 loss=2.526, loss_v1=0, loss_v2=0, nll_loss=1.345, ntokens=845.9, nsentences=32, sample_size=845.9, sample_size_v1=0, sample_size_v2=0, ppl=2.54, wps=460.5, ups=0.54, wpb=845.9, bsz=32, num_updates=4080, lr=2.94085e-05, gnorm=1.749, clip=100, loss_scale=256, train_wall=18, gb_free=12, wall=7669
2023-05-26 01:31:13 - progress_bar.py[line:272] - INFO: epoch 003:    631 / 1732 loss=2.487, loss_v1=0, loss_v2=0, nll_loss=1.3, ntokens=949.2, nsentences=32, sample_size=949.2, sample_size_v1=0, sample_size_v2=0, ppl=2.46, wps=513.3, ups=0.54, wpb=949.2, bsz=32, num_updates=4090, lr=2.94024e-05, gnorm=1.672, clip=100, loss_scale=256, train_wall=18, gb_free=11.2, wall=7688
2023-05-26 01:31:32 - progress_bar.py[line:272] - INFO: epoch 003:    641 / 1732 loss=2.522, loss_v1=0, loss_v2=0, nll_loss=1.342, ntokens=915.8, nsentences=32, sample_size=915.8, sample_size_v1=0, sample_size_v2=0, ppl=2.54, wps=496.8, ups=0.54, wpb=915.8, bsz=32, num_updates=4100, lr=2.93962e-05, gnorm=1.675, clip=100, loss_scale=256, train_wall=18, gb_free=11.8, wall=7706
2023-05-26 01:31:50 - progress_bar.py[line:272] - INFO: epoch 003:    651 / 1732 loss=2.516, loss_v1=0, loss_v2=0, nll_loss=1.33, ntokens=990.2, nsentences=32, sample_size=990.2, sample_size_v1=0, sample_size_v2=0, ppl=2.51, wps=538.1, ups=0.54, wpb=990.2, bsz=32, num_updates=4110, lr=2.93901e-05, gnorm=1.679, clip=100, loss_scale=256, train_wall=18, gb_free=11.7, wall=7725
2023-05-26 01:32:08 - progress_bar.py[line:272] - INFO: epoch 003:    661 / 1732 loss=2.527, loss_v1=0, loss_v2=0, nll_loss=1.345, ntokens=863.9, nsentences=32, sample_size=863.9, sample_size_v1=0, sample_size_v2=0, ppl=2.54, wps=473.6, ups=0.55, wpb=863.9, bsz=32, num_updates=4120, lr=2.93839e-05, gnorm=1.781, clip=100, loss_scale=256, train_wall=18, gb_free=11.5, wall=7743
2023-05-26 01:32:27 - progress_bar.py[line:272] - INFO: epoch 003:    671 / 1732 loss=2.513, loss_v1=0, loss_v2=0, nll_loss=1.332, ntokens=943.7, nsentences=32, sample_size=943.7, sample_size_v1=0, sample_size_v2=0, ppl=2.52, wps=508.8, ups=0.54, wpb=943.7, bsz=32, num_updates=4130, lr=2.93778e-05, gnorm=1.571, clip=100, loss_scale=256, train_wall=19, gb_free=11.4, wall=7762
2023-05-26 01:32:45 - progress_bar.py[line:272] - INFO: epoch 003:    681 / 1732 loss=2.503, loss_v1=0, loss_v2=0, nll_loss=1.316, ntokens=972.8, nsentences=32, sample_size=972.8, sample_size_v1=0, sample_size_v2=0, ppl=2.49, wps=526.2, ups=0.54, wpb=972.8, bsz=32, num_updates=4140, lr=2.93717e-05, gnorm=1.64, clip=100, loss_scale=256, train_wall=18, gb_free=11, wall=7780
2023-05-26 01:33:04 - progress_bar.py[line:272] - INFO: epoch 003:    691 / 1732 loss=2.523, loss_v1=0, loss_v2=0, nll_loss=1.344, ntokens=949, nsentences=32, sample_size=949, sample_size_v1=0, sample_size_v2=0, ppl=2.54, wps=512.2, ups=0.54, wpb=949, bsz=32, num_updates=4150, lr=2.93655e-05, gnorm=1.72, clip=100, loss_scale=256, train_wall=18, gb_free=11.8, wall=7799
2023-05-26 01:33:22 - progress_bar.py[line:272] - INFO: epoch 003:    701 / 1732 loss=2.478, loss_v1=0, loss_v2=0, nll_loss=1.287, ntokens=988.7, nsentences=32, sample_size=988.7, sample_size_v1=0, sample_size_v2=0, ppl=2.44, wps=533.2, ups=0.54, wpb=988.7, bsz=32, num_updates=4160, lr=2.93594e-05, gnorm=1.476, clip=100, loss_scale=256, train_wall=19, gb_free=11.8, wall=7817
2023-05-26 01:33:41 - progress_bar.py[line:272] - INFO: epoch 003:    711 / 1732 loss=2.517, loss_v1=0, loss_v2=0, nll_loss=1.336, ntokens=913.9, nsentences=32, sample_size=913.9, sample_size_v1=0, sample_size_v2=0, ppl=2.52, wps=495.3, ups=0.54, wpb=913.9, bsz=32, num_updates=4170, lr=2.93532e-05, gnorm=1.594, clip=100, loss_scale=256, train_wall=18, gb_free=11.6, wall=7836
2023-05-26 01:33:59 - progress_bar.py[line:272] - INFO: epoch 003:    721 / 1732 loss=2.48, loss_v1=0, loss_v2=0, nll_loss=1.294, ntokens=854.5, nsentences=32, sample_size=854.5, sample_size_v1=0, sample_size_v2=0, ppl=2.45, wps=465, ups=0.54, wpb=854.5, bsz=32, num_updates=4180, lr=2.93471e-05, gnorm=1.839, clip=100, loss_scale=256, train_wall=18, gb_free=11.4, wall=7854
2023-05-26 01:34:18 - progress_bar.py[line:272] - INFO: epoch 003:    731 / 1732 loss=2.487, loss_v1=0, loss_v2=0, nll_loss=1.301, ntokens=932.8, nsentences=32, sample_size=932.8, sample_size_v1=0, sample_size_v2=0, ppl=2.46, wps=507.3, ups=0.54, wpb=932.8, bsz=32, num_updates=4190, lr=2.93409e-05, gnorm=1.632, clip=100, loss_scale=256, train_wall=18, gb_free=11.6, wall=7872
2023-05-26 01:34:36 - progress_bar.py[line:272] - INFO: epoch 003:    741 / 1732 loss=2.474, loss_v1=0, loss_v2=0, nll_loss=1.283, ntokens=1003.7, nsentences=32, sample_size=1003.7, sample_size_v1=0, sample_size_v2=0, ppl=2.43, wps=541.5, ups=0.54, wpb=1003.7, bsz=32, num_updates=4200, lr=2.93348e-05, gnorm=1.718, clip=100, loss_scale=512, train_wall=19, gb_free=11.4, wall=7891
2023-05-26 01:34:55 - progress_bar.py[line:272] - INFO: epoch 003:    751 / 1732 loss=2.487, loss_v1=0, loss_v2=0, nll_loss=1.3, ntokens=975.7, nsentences=32, sample_size=975.7, sample_size_v1=0, sample_size_v2=0, ppl=2.46, wps=525, ups=0.54, wpb=975.7, bsz=32, num_updates=4210, lr=2.93287e-05, gnorm=1.704, clip=100, loss_scale=512, train_wall=19, gb_free=11, wall=7909
2023-05-26 01:35:13 - progress_bar.py[line:272] - INFO: epoch 003:    761 / 1732 loss=2.473, loss_v1=0, loss_v2=0, nll_loss=1.287, ntokens=974.2, nsentences=32, sample_size=974.2, sample_size_v1=0, sample_size_v2=0, ppl=2.44, wps=527.5, ups=0.54, wpb=974.2, bsz=32, num_updates=4220, lr=2.93225e-05, gnorm=1.66, clip=100, loss_scale=512, train_wall=18, gb_free=11.5, wall=7928
2023-05-26 01:35:32 - progress_bar.py[line:272] - INFO: epoch 003:    771 / 1732 loss=2.486, loss_v1=0, loss_v2=0, nll_loss=1.299, ntokens=924.9, nsentences=32, sample_size=924.9, sample_size_v1=0, sample_size_v2=0, ppl=2.46, wps=502.3, ups=0.54, wpb=924.9, bsz=32, num_updates=4230, lr=2.93164e-05, gnorm=1.92, clip=100, loss_scale=512, train_wall=18, gb_free=11.7, wall=7946
2023-05-26 01:35:50 - progress_bar.py[line:272] - INFO: epoch 003:    781 / 1732 loss=2.495, loss_v1=0, loss_v2=0, nll_loss=1.309, ntokens=1053.4, nsentences=32, sample_size=1053.4, sample_size_v1=0, sample_size_v2=0, ppl=2.48, wps=567.4, ups=0.54, wpb=1053.4, bsz=32, num_updates=4240, lr=2.93102e-05, gnorm=1.665, clip=100, loss_scale=512, train_wall=19, gb_free=11.7, wall=7965
2023-05-26 01:36:09 - progress_bar.py[line:272] - INFO: epoch 003:    791 / 1732 loss=2.489, loss_v1=0, loss_v2=0, nll_loss=1.304, ntokens=1022, nsentences=32, sample_size=1022, sample_size_v1=0, sample_size_v2=0, ppl=2.47, wps=552.2, ups=0.54, wpb=1022, bsz=32, num_updates=4250, lr=2.93041e-05, gnorm=1.671, clip=100, loss_scale=512, train_wall=18, gb_free=11.4, wall=7983
2023-05-26 01:36:27 - progress_bar.py[line:272] - INFO: epoch 003:    801 / 1732 loss=2.478, loss_v1=0, loss_v2=0, nll_loss=1.288, ntokens=984.3, nsentences=32, sample_size=984.3, sample_size_v1=0, sample_size_v2=0, ppl=2.44, wps=532.5, ups=0.54, wpb=984.3, bsz=32, num_updates=4260, lr=2.9298e-05, gnorm=1.637, clip=100, loss_scale=512, train_wall=18, gb_free=11.1, wall=8002
2023-05-26 01:36:46 - progress_bar.py[line:272] - INFO: epoch 003:    811 / 1732 loss=2.481, loss_v1=0, loss_v2=0, nll_loss=1.295, ntokens=931.4, nsentences=32, sample_size=931.4, sample_size_v1=0, sample_size_v2=0, ppl=2.45, wps=503.8, ups=0.54, wpb=931.4, bsz=32, num_updates=4270, lr=2.92918e-05, gnorm=1.665, clip=100, loss_scale=512, train_wall=18, gb_free=11.4, wall=8020
2023-05-26 01:37:04 - progress_bar.py[line:272] - INFO: epoch 003:    821 / 1732 loss=2.505, loss_v1=0, loss_v2=0, nll_loss=1.318, ntokens=915.1, nsentences=32, sample_size=915.1, sample_size_v1=0, sample_size_v2=0, ppl=2.49, wps=493.9, ups=0.54, wpb=915.1, bsz=32, num_updates=4280, lr=2.92857e-05, gnorm=1.876, clip=100, loss_scale=512, train_wall=18, gb_free=10.2, wall=8039
2023-05-26 01:37:23 - progress_bar.py[line:272] - INFO: epoch 003:    831 / 1732 loss=2.478, loss_v1=0, loss_v2=0, nll_loss=1.291, ntokens=914.9, nsentences=32, sample_size=914.9, sample_size_v1=0, sample_size_v2=0, ppl=2.45, wps=496.2, ups=0.54, wpb=914.9, bsz=32, num_updates=4290, lr=2.92795e-05, gnorm=1.695, clip=100, loss_scale=512, train_wall=18, gb_free=11.6, wall=8057
2023-05-26 01:37:41 - progress_bar.py[line:272] - INFO: epoch 003:    841 / 1732 loss=2.487, loss_v1=0, loss_v2=0, nll_loss=1.299, ntokens=933, nsentences=32, sample_size=933, sample_size_v1=0, sample_size_v2=0, ppl=2.46, wps=507.9, ups=0.54, wpb=933, bsz=32, num_updates=4300, lr=2.92734e-05, gnorm=1.748, clip=100, loss_scale=512, train_wall=18, gb_free=11.7, wall=8076
2023-05-26 01:38:00 - progress_bar.py[line:272] - INFO: epoch 003:    851 / 1732 loss=2.486, loss_v1=0, loss_v2=0, nll_loss=1.301, ntokens=1005.2, nsentences=32, sample_size=1005.2, sample_size_v1=0, sample_size_v2=0, ppl=2.46, wps=543.9, ups=0.54, wpb=1005.2, bsz=32, num_updates=4310, lr=2.92672e-05, gnorm=1.602, clip=100, loss_scale=512, train_wall=18, gb_free=11.4, wall=8094
2023-05-26 01:38:18 - progress_bar.py[line:272] - INFO: epoch 003:    861 / 1732 loss=2.47, loss_v1=0, loss_v2=0, nll_loss=1.281, ntokens=942.6, nsentences=32, sample_size=942.6, sample_size_v1=0, sample_size_v2=0, ppl=2.43, wps=509.2, ups=0.54, wpb=942.6, bsz=32, num_updates=4320, lr=2.92611e-05, gnorm=1.821, clip=100, loss_scale=512, train_wall=18, gb_free=11.3, wall=8113
2023-05-26 01:38:37 - progress_bar.py[line:272] - INFO: epoch 003:    871 / 1732 loss=2.49, loss_v1=0, loss_v2=0, nll_loss=1.303, ntokens=962.7, nsentences=32, sample_size=962.7, sample_size_v1=0, sample_size_v2=0, ppl=2.47, wps=521.7, ups=0.54, wpb=962.7, bsz=32, num_updates=4330, lr=2.9255e-05, gnorm=1.72, clip=100, loss_scale=512, train_wall=18, gb_free=11.8, wall=8131
2023-05-26 01:38:55 - progress_bar.py[line:272] - INFO: epoch 003:    881 / 1732 loss=2.437, loss_v1=0, loss_v2=0, nll_loss=1.247, ntokens=988.4, nsentences=32, sample_size=988.4, sample_size_v1=0, sample_size_v2=0, ppl=2.37, wps=531.5, ups=0.54, wpb=988.4, bsz=32, num_updates=4340, lr=2.92488e-05, gnorm=1.719, clip=100, loss_scale=512, train_wall=19, gb_free=12.1, wall=8150
2023-05-26 01:39:14 - progress_bar.py[line:272] - INFO: epoch 003:    891 / 1732 loss=2.42, loss_v1=0, loss_v2=0, nll_loss=1.223, ntokens=1001.4, nsentences=32, sample_size=1001.4, sample_size_v1=0, sample_size_v2=0, ppl=2.33, wps=539.1, ups=0.54, wpb=1001.4, bsz=32, num_updates=4350, lr=2.92427e-05, gnorm=1.642, clip=100, loss_scale=512, train_wall=19, gb_free=11.4, wall=8168
2023-05-26 01:39:32 - progress_bar.py[line:272] - INFO: epoch 003:    901 / 1732 loss=2.426, loss_v1=0, loss_v2=0, nll_loss=1.233, ntokens=1032.4, nsentences=32, sample_size=1032.4, sample_size_v1=0, sample_size_v2=0, ppl=2.35, wps=556.5, ups=0.54, wpb=1032.4, bsz=32, num_updates=4360, lr=2.92365e-05, gnorm=1.619, clip=100, loss_scale=512, train_wall=19, gb_free=11.7, wall=8187
2023-05-26 01:39:51 - progress_bar.py[line:272] - INFO: epoch 003:    911 / 1732 loss=2.477, loss_v1=0, loss_v2=0, nll_loss=1.289, ntokens=960.1, nsentences=32, sample_size=960.1, sample_size_v1=0, sample_size_v2=0, ppl=2.44, wps=518.7, ups=0.54, wpb=960.1, bsz=32, num_updates=4370, lr=2.92304e-05, gnorm=1.766, clip=100, loss_scale=512, train_wall=18, gb_free=12, wall=8205
2023-05-26 01:40:09 - progress_bar.py[line:272] - INFO: epoch 003:    921 / 1732 loss=2.49, loss_v1=0, loss_v2=0, nll_loss=1.303, ntokens=986.3, nsentences=32, sample_size=986.3, sample_size_v1=0, sample_size_v2=0, ppl=2.47, wps=531.3, ups=0.54, wpb=986.3, bsz=32, num_updates=4380, lr=2.92242e-05, gnorm=1.712, clip=100, loss_scale=512, train_wall=19, gb_free=11.4, wall=8224
2023-05-26 01:40:28 - progress_bar.py[line:272] - INFO: epoch 003:    931 / 1732 loss=2.458, loss_v1=0, loss_v2=0, nll_loss=1.272, ntokens=1050.4, nsentences=32, sample_size=1050.4, sample_size_v1=0, sample_size_v2=0, ppl=2.41, wps=561.7, ups=0.53, wpb=1050.4, bsz=32, num_updates=4390, lr=2.92181e-05, gnorm=1.717, clip=100, loss_scale=512, train_wall=19, gb_free=11.5, wall=8243
2023-05-26 01:40:47 - progress_bar.py[line:272] - INFO: epoch 003:    941 / 1732 loss=2.458, loss_v1=0, loss_v2=0, nll_loss=1.266, ntokens=1052.3, nsentences=32, sample_size=1052.3, sample_size_v1=0, sample_size_v2=0, ppl=2.4, wps=559, ups=0.53, wpb=1052.3, bsz=32, num_updates=4400, lr=2.9212e-05, gnorm=1.645, clip=100, loss_scale=512, train_wall=19, gb_free=10.1, wall=8262
2023-05-26 01:41:06 - progress_bar.py[line:272] - INFO: epoch 003:    951 / 1732 loss=2.462, loss_v1=0, loss_v2=0, nll_loss=1.273, ntokens=1037.8, nsentences=32, sample_size=1037.8, sample_size_v1=0, sample_size_v2=0, ppl=2.42, wps=553.2, ups=0.53, wpb=1037.8, bsz=32, num_updates=4410, lr=2.92058e-05, gnorm=1.7, clip=100, loss_scale=512, train_wall=19, gb_free=11.1, wall=8280
2023-05-26 01:41:24 - progress_bar.py[line:272] - INFO: epoch 003:    961 / 1732 loss=2.462, loss_v1=0, loss_v2=0, nll_loss=1.272, ntokens=1067.9, nsentences=32, sample_size=1067.9, sample_size_v1=0, sample_size_v2=0, ppl=2.42, wps=568.5, ups=0.53, wpb=1067.9, bsz=32, num_updates=4420, lr=2.91997e-05, gnorm=1.655, clip=100, loss_scale=512, train_wall=19, gb_free=11.3, wall=8299
2023-05-26 01:41:43 - progress_bar.py[line:272] - INFO: epoch 003:    971 / 1732 loss=2.499, loss_v1=0, loss_v2=0, nll_loss=1.315, ntokens=1026.9, nsentences=32, sample_size=1026.9, sample_size_v1=0, sample_size_v2=0, ppl=2.49, wps=548.1, ups=0.53, wpb=1026.9, bsz=32, num_updates=4430, lr=2.91935e-05, gnorm=1.755, clip=100, loss_scale=512, train_wall=19, gb_free=10.3, wall=8318
2023-05-26 01:42:02 - progress_bar.py[line:272] - INFO: epoch 003:    981 / 1732 loss=2.459, loss_v1=0, loss_v2=0, nll_loss=1.268, ntokens=1016.8, nsentences=32, sample_size=1016.8, sample_size_v1=0, sample_size_v2=0, ppl=2.41, wps=538.1, ups=0.53, wpb=1016.8, bsz=32, num_updates=4440, lr=2.91874e-05, gnorm=1.661, clip=100, loss_scale=512, train_wall=19, gb_free=11.1, wall=8337
2023-05-26 01:42:21 - progress_bar.py[line:272] - INFO: epoch 003:    991 / 1732 loss=2.469, loss_v1=0, loss_v2=0, nll_loss=1.279, ntokens=1042.2, nsentences=32, sample_size=1042.2, sample_size_v1=0, sample_size_v2=0, ppl=2.43, wps=553.6, ups=0.53, wpb=1042.2, bsz=32, num_updates=4450, lr=2.91813e-05, gnorm=1.68, clip=100, loss_scale=512, train_wall=19, gb_free=11.4, wall=8356
2023-05-26 01:42:40 - progress_bar.py[line:272] - INFO: epoch 003:   1001 / 1732 loss=2.446, loss_v1=0, loss_v2=0, nll_loss=1.253, ntokens=1019, nsentences=32, sample_size=1019, sample_size_v1=0, sample_size_v2=0, ppl=2.38, wps=547.6, ups=0.54, wpb=1019, bsz=32, num_updates=4460, lr=2.91751e-05, gnorm=1.672, clip=100, loss_scale=512, train_wall=19, gb_free=11.3, wall=8374
2023-05-26 01:42:58 - progress_bar.py[line:272] - INFO: epoch 003:   1011 / 1732 loss=2.461, loss_v1=0, loss_v2=0, nll_loss=1.272, ntokens=995.8, nsentences=32, sample_size=995.8, sample_size_v1=0, sample_size_v2=0, ppl=2.42, wps=532.7, ups=0.53, wpb=995.8, bsz=32, num_updates=4470, lr=2.9169e-05, gnorm=1.652, clip=100, loss_scale=512, train_wall=19, gb_free=11.5, wall=8393
2023-05-26 01:43:17 - progress_bar.py[line:272] - INFO: epoch 003:   1021 / 1732 loss=2.437, loss_v1=0, loss_v2=0, nll_loss=1.245, ntokens=1050, nsentences=32, sample_size=1050, sample_size_v1=0, sample_size_v2=0, ppl=2.37, wps=559.8, ups=0.53, wpb=1050, bsz=32, num_updates=4480, lr=2.91628e-05, gnorm=1.847, clip=100, loss_scale=512, train_wall=19, gb_free=10.5, wall=8412
2023-05-26 01:43:36 - progress_bar.py[line:272] - INFO: epoch 003:   1031 / 1732 loss=2.461, loss_v1=0, loss_v2=0, nll_loss=1.269, ntokens=1125.6, nsentences=32, sample_size=1125.6, sample_size_v1=0, sample_size_v2=0, ppl=2.41, wps=593.4, ups=0.53, wpb=1125.6, bsz=32, num_updates=4490, lr=2.91567e-05, gnorm=1.618, clip=100, loss_scale=512, train_wall=19, gb_free=11.1, wall=8431
2023-05-26 01:43:51 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 256.0
2023-05-26 01:43:57 - progress_bar.py[line:272] - INFO: epoch 003:   1042 / 1732 loss=2.456, loss_v1=0, loss_v2=0, nll_loss=1.265, ntokens=1078.7, nsentences=32, sample_size=1078.7, sample_size_v1=0, sample_size_v2=0, ppl=2.4, wps=522.4, ups=0.48, wpb=1078.7, bsz=32, num_updates=4500, lr=2.91505e-05, gnorm=1.73, clip=100, loss_scale=256, train_wall=21, gb_free=10.8, wall=8451
2023-05-26 01:44:15 - progress_bar.py[line:272] - INFO: epoch 003:   1052 / 1732 loss=2.466, loss_v1=0, loss_v2=0, nll_loss=1.276, ntokens=1041, nsentences=32, sample_size=1041, sample_size_v1=0, sample_size_v2=0, ppl=2.42, wps=559.5, ups=0.54, wpb=1041, bsz=32, num_updates=4510, lr=2.91444e-05, gnorm=1.962, clip=100, loss_scale=256, train_wall=19, gb_free=11.2, wall=8470
2023-05-26 01:44:34 - progress_bar.py[line:272] - INFO: epoch 003:   1062 / 1732 loss=2.456, loss_v1=0, loss_v2=0, nll_loss=1.267, ntokens=1046.1, nsentences=32, sample_size=1046.1, sample_size_v1=0, sample_size_v2=0, ppl=2.41, wps=557.4, ups=0.53, wpb=1046.1, bsz=32, num_updates=4520, lr=2.91383e-05, gnorm=1.738, clip=100, loss_scale=256, train_wall=19, gb_free=11.1, wall=8489
2023-05-26 01:44:53 - progress_bar.py[line:272] - INFO: epoch 003:   1072 / 1732 loss=2.456, loss_v1=0, loss_v2=0, nll_loss=1.264, ntokens=994.4, nsentences=32, sample_size=994.4, sample_size_v1=0, sample_size_v2=0, ppl=2.4, wps=530.3, ups=0.53, wpb=994.4, bsz=32, num_updates=4530, lr=2.91321e-05, gnorm=1.749, clip=100, loss_scale=256, train_wall=19, gb_free=11.5, wall=8507
2023-05-26 01:45:12 - progress_bar.py[line:272] - INFO: epoch 003:   1082 / 1732 loss=2.478, loss_v1=0, loss_v2=0, nll_loss=1.294, ntokens=1041.7, nsentences=32, sample_size=1041.7, sample_size_v1=0, sample_size_v2=0, ppl=2.45, wps=551, ups=0.53, wpb=1041.7, bsz=32, num_updates=4540, lr=2.9126e-05, gnorm=1.753, clip=100, loss_scale=256, train_wall=19, gb_free=11.2, wall=8526
2023-05-26 01:45:30 - progress_bar.py[line:272] - INFO: epoch 003:   1092 / 1732 loss=2.461, loss_v1=0, loss_v2=0, nll_loss=1.266, ntokens=1060.8, nsentences=32, sample_size=1060.8, sample_size_v1=0, sample_size_v2=0, ppl=2.4, wps=563, ups=0.53, wpb=1060.8, bsz=32, num_updates=4550, lr=2.91198e-05, gnorm=1.862, clip=100, loss_scale=256, train_wall=19, gb_free=11.6, wall=8545
2023-05-26 01:45:49 - progress_bar.py[line:272] - INFO: epoch 003:   1102 / 1732 loss=2.462, loss_v1=0, loss_v2=0, nll_loss=1.274, ntokens=1049.1, nsentences=32, sample_size=1049.1, sample_size_v1=0, sample_size_v2=0, ppl=2.42, wps=560.2, ups=0.53, wpb=1049.1, bsz=32, num_updates=4560, lr=2.91137e-05, gnorm=1.756, clip=100, loss_scale=256, train_wall=19, gb_free=10.5, wall=8564
2023-05-26 01:46:08 - progress_bar.py[line:272] - INFO: epoch 003:   1112 / 1732 loss=2.45, loss_v1=0, loss_v2=0, nll_loss=1.258, ntokens=1025.7, nsentences=32, sample_size=1025.7, sample_size_v1=0, sample_size_v2=0, ppl=2.39, wps=544.6, ups=0.53, wpb=1025.7, bsz=32, num_updates=4570, lr=2.91075e-05, gnorm=1.748, clip=100, loss_scale=256, train_wall=19, gb_free=11.3, wall=8583
2023-05-26 01:46:27 - progress_bar.py[line:272] - INFO: epoch 003:   1122 / 1732 loss=2.464, loss_v1=0, loss_v2=0, nll_loss=1.276, ntokens=976.1, nsentences=32, sample_size=976.1, sample_size_v1=0, sample_size_v2=0, ppl=2.42, wps=521.7, ups=0.53, wpb=976.1, bsz=32, num_updates=4580, lr=2.91014e-05, gnorm=1.967, clip=100, loss_scale=256, train_wall=19, gb_free=11.3, wall=8601
2023-05-26 01:46:45 - progress_bar.py[line:272] - INFO: epoch 003:   1132 / 1732 loss=2.468, loss_v1=0, loss_v2=0, nll_loss=1.28, ntokens=969.4, nsentences=32, sample_size=969.4, sample_size_v1=0, sample_size_v2=0, ppl=2.43, wps=518.4, ups=0.53, wpb=969.4, bsz=32, num_updates=4590, lr=2.90953e-05, gnorm=2.114, clip=100, loss_scale=256, train_wall=19, gb_free=11.7, wall=8620
2023-05-26 01:47:04 - progress_bar.py[line:272] - INFO: epoch 003:   1142 / 1732 loss=2.466, loss_v1=0, loss_v2=0, nll_loss=1.277, ntokens=1032.5, nsentences=32, sample_size=1032.5, sample_size_v1=0, sample_size_v2=0, ppl=2.42, wps=550.3, ups=0.53, wpb=1032.5, bsz=32, num_updates=4600, lr=2.90891e-05, gnorm=1.921, clip=100, loss_scale=256, train_wall=19, gb_free=11.1, wall=8639
2023-05-26 01:47:23 - progress_bar.py[line:272] - INFO: epoch 003:   1152 / 1732 loss=2.446, loss_v1=0, loss_v2=0, nll_loss=1.254, ntokens=1026.9, nsentences=32, sample_size=1026.9, sample_size_v1=0, sample_size_v2=0, ppl=2.39, wps=548.8, ups=0.53, wpb=1026.9, bsz=32, num_updates=4610, lr=2.9083e-05, gnorm=1.988, clip=100, loss_scale=256, train_wall=19, gb_free=11.4, wall=8658
2023-05-26 01:47:42 - progress_bar.py[line:272] - INFO: epoch 003:   1162 / 1732 loss=2.426, loss_v1=0, loss_v2=0, nll_loss=1.232, ntokens=1008.4, nsentences=32, sample_size=1008.4, sample_size_v1=0, sample_size_v2=0, ppl=2.35, wps=536, ups=0.53, wpb=1008.4, bsz=32, num_updates=4620, lr=2.90768e-05, gnorm=2, clip=100, loss_scale=256, train_wall=19, gb_free=11.3, wall=8676
2023-05-26 01:48:01 - progress_bar.py[line:272] - INFO: epoch 003:   1172 / 1732 loss=2.448, loss_v1=0, loss_v2=0, nll_loss=1.255, ntokens=1048.6, nsentences=32, sample_size=1048.6, sample_size_v1=0, sample_size_v2=0, ppl=2.39, wps=556.5, ups=0.53, wpb=1048.6, bsz=32, num_updates=4630, lr=2.90707e-05, gnorm=1.847, clip=100, loss_scale=256, train_wall=19, gb_free=10.8, wall=8695
2023-05-26 01:48:19 - progress_bar.py[line:272] - INFO: epoch 003:   1182 / 1732 loss=2.436, loss_v1=0, loss_v2=0, nll_loss=1.244, ntokens=1018.1, nsentences=32, sample_size=1018.1, sample_size_v1=0, sample_size_v2=0, ppl=2.37, wps=545.7, ups=0.54, wpb=1018.1, bsz=32, num_updates=4640, lr=2.90646e-05, gnorm=1.896, clip=100, loss_scale=256, train_wall=19, gb_free=11.4, wall=8714
2023-05-26 01:48:38 - progress_bar.py[line:272] - INFO: epoch 003:   1192 / 1732 loss=2.483, loss_v1=0, loss_v2=0, nll_loss=1.295, ntokens=1011.4, nsentences=32, sample_size=1011.4, sample_size_v1=0, sample_size_v2=0, ppl=2.45, wps=539.7, ups=0.53, wpb=1011.4, bsz=32, num_updates=4650, lr=2.90584e-05, gnorm=1.976, clip=100, loss_scale=256, train_wall=19, gb_free=11.4, wall=8733
2023-05-26 01:48:57 - progress_bar.py[line:272] - INFO: epoch 003:   1202 / 1732 loss=2.415, loss_v1=0, loss_v2=0, nll_loss=1.217, ntokens=1128.3, nsentences=32, sample_size=1128.3, sample_size_v1=0, sample_size_v2=0, ppl=2.33, wps=598, ups=0.53, wpb=1128.3, bsz=32, num_updates=4660, lr=2.90523e-05, gnorm=1.804, clip=100, loss_scale=256, train_wall=19, gb_free=11.1, wall=8752
2023-05-26 01:49:16 - progress_bar.py[line:272] - INFO: epoch 003:   1212 / 1732 loss=2.451, loss_v1=0, loss_v2=0, nll_loss=1.262, ntokens=1031.6, nsentences=32, sample_size=1031.6, sample_size_v1=0, sample_size_v2=0, ppl=2.4, wps=546.7, ups=0.53, wpb=1031.6, bsz=32, num_updates=4670, lr=2.90461e-05, gnorm=1.874, clip=100, loss_scale=256, train_wall=19, gb_free=10.9, wall=8770
2023-05-26 01:49:34 - progress_bar.py[line:272] - INFO: epoch 003:   1222 / 1732 loss=2.481, loss_v1=0, loss_v2=0, nll_loss=1.29, ntokens=1024, nsentences=32, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=2.45, wps=547.1, ups=0.53, wpb=1024, bsz=32, num_updates=4680, lr=2.904e-05, gnorm=1.863, clip=100, loss_scale=256, train_wall=19, gb_free=10.8, wall=8789
2023-05-26 01:49:53 - progress_bar.py[line:272] - INFO: epoch 003:   1232 / 1732 loss=2.436, loss_v1=0, loss_v2=0, nll_loss=1.244, ntokens=1035.1, nsentences=32, sample_size=1035.1, sample_size_v1=0, sample_size_v2=0, ppl=2.37, wps=552.4, ups=0.53, wpb=1035.1, bsz=32, num_updates=4690, lr=2.90338e-05, gnorm=1.805, clip=100, loss_scale=256, train_wall=19, gb_free=11.4, wall=8808
2023-05-26 01:50:12 - progress_bar.py[line:272] - INFO: epoch 003:   1242 / 1732 loss=2.389, loss_v1=0, loss_v2=0, nll_loss=1.19, ntokens=1078.3, nsentences=32, sample_size=1078.3, sample_size_v1=0, sample_size_v2=0, ppl=2.28, wps=571.8, ups=0.53, wpb=1078.3, bsz=32, num_updates=4700, lr=2.90277e-05, gnorm=1.993, clip=100, loss_scale=256, train_wall=19, gb_free=11.4, wall=8827
2023-05-26 01:50:31 - progress_bar.py[line:272] - INFO: epoch 003:   1252 / 1732 loss=2.418, loss_v1=0, loss_v2=0, nll_loss=1.224, ntokens=1106.3, nsentences=32, sample_size=1106.3, sample_size_v1=0, sample_size_v2=0, ppl=2.34, wps=585.8, ups=0.53, wpb=1106.3, bsz=32, num_updates=4710, lr=2.90216e-05, gnorm=1.757, clip=100, loss_scale=256, train_wall=19, gb_free=10.9, wall=8846
2023-05-26 01:50:50 - progress_bar.py[line:272] - INFO: epoch 003:   1262 / 1732 loss=2.456, loss_v1=0, loss_v2=0, nll_loss=1.266, ntokens=1064, nsentences=32, sample_size=1064, sample_size_v1=0, sample_size_v2=0, ppl=2.4, wps=565.2, ups=0.53, wpb=1064, bsz=32, num_updates=4720, lr=2.90154e-05, gnorm=1.903, clip=100, loss_scale=256, train_wall=19, gb_free=10.9, wall=8864
2023-05-26 01:51:09 - progress_bar.py[line:272] - INFO: epoch 003:   1272 / 1732 loss=2.453, loss_v1=0, loss_v2=0, nll_loss=1.261, ntokens=1010.3, nsentences=32, sample_size=1010.3, sample_size_v1=0, sample_size_v2=0, ppl=2.4, wps=540.6, ups=0.54, wpb=1010.3, bsz=32, num_updates=4730, lr=2.90093e-05, gnorm=1.961, clip=100, loss_scale=256, train_wall=19, gb_free=10.9, wall=8883
2023-05-26 01:51:27 - progress_bar.py[line:272] - INFO: epoch 003:   1282 / 1732 loss=2.438, loss_v1=0, loss_v2=0, nll_loss=1.246, ntokens=1073.6, nsentences=32, sample_size=1073.6, sample_size_v1=0, sample_size_v2=0, ppl=2.37, wps=565.6, ups=0.53, wpb=1073.6, bsz=32, num_updates=4740, lr=2.90031e-05, gnorm=1.801, clip=100, loss_scale=256, train_wall=19, gb_free=10.4, wall=8902
2023-05-26 01:51:46 - progress_bar.py[line:272] - INFO: epoch 003:   1292 / 1732 loss=2.439, loss_v1=0, loss_v2=0, nll_loss=1.247, ntokens=1095.2, nsentences=32, sample_size=1095.2, sample_size_v1=0, sample_size_v2=0, ppl=2.37, wps=579.6, ups=0.53, wpb=1095.2, bsz=32, num_updates=4750, lr=2.8997e-05, gnorm=1.72, clip=100, loss_scale=256, train_wall=19, gb_free=10.7, wall=8921
2023-05-26 01:52:05 - progress_bar.py[line:272] - INFO: epoch 003:   1302 / 1732 loss=2.439, loss_v1=0, loss_v2=0, nll_loss=1.247, ntokens=1099.5, nsentences=32, sample_size=1099.5, sample_size_v1=0, sample_size_v2=0, ppl=2.37, wps=583.3, ups=0.53, wpb=1099.5, bsz=32, num_updates=4760, lr=2.89908e-05, gnorm=1.768, clip=100, loss_scale=256, train_wall=19, gb_free=10.4, wall=8940
2023-05-26 01:52:24 - progress_bar.py[line:272] - INFO: epoch 003:   1312 / 1732 loss=2.477, loss_v1=0, loss_v2=0, nll_loss=1.287, ntokens=1055.4, nsentences=32, sample_size=1055.4, sample_size_v1=0, sample_size_v2=0, ppl=2.44, wps=554.4, ups=0.53, wpb=1055.4, bsz=32, num_updates=4770, lr=2.89847e-05, gnorm=2.11, clip=100, loss_scale=256, train_wall=19, gb_free=11.4, wall=8959
2023-05-26 01:52:43 - progress_bar.py[line:272] - INFO: epoch 003:   1322 / 1732 loss=2.427, loss_v1=0, loss_v2=0, nll_loss=1.234, ntokens=1120.6, nsentences=32, sample_size=1120.6, sample_size_v1=0, sample_size_v2=0, ppl=2.35, wps=591.8, ups=0.53, wpb=1120.6, bsz=32, num_updates=4780, lr=2.89786e-05, gnorm=1.857, clip=100, loss_scale=256, train_wall=19, gb_free=10.6, wall=8978
2023-05-26 01:53:02 - progress_bar.py[line:272] - INFO: epoch 003:   1332 / 1732 loss=2.399, loss_v1=0, loss_v2=0, nll_loss=1.203, ntokens=1081, nsentences=32, sample_size=1081, sample_size_v1=0, sample_size_v2=0, ppl=2.3, wps=573.6, ups=0.53, wpb=1081, bsz=32, num_updates=4790, lr=2.89724e-05, gnorm=1.95, clip=100, loss_scale=256, train_wall=19, gb_free=11.1, wall=8997
2023-05-26 01:53:21 - progress_bar.py[line:272] - INFO: epoch 003:   1342 / 1732 loss=2.42, loss_v1=0, loss_v2=0, nll_loss=1.226, ntokens=1183.5, nsentences=32, sample_size=1183.5, sample_size_v1=0, sample_size_v2=0, ppl=2.34, wps=624.8, ups=0.53, wpb=1183.5, bsz=32, num_updates=4800, lr=2.89663e-05, gnorm=1.807, clip=100, loss_scale=256, train_wall=19, gb_free=10.4, wall=9016
2023-05-26 01:53:40 - progress_bar.py[line:272] - INFO: epoch 003:   1352 / 1732 loss=2.435, loss_v1=0, loss_v2=0, nll_loss=1.242, ntokens=1129.4, nsentences=32, sample_size=1129.4, sample_size_v1=0, sample_size_v2=0, ppl=2.36, wps=597.2, ups=0.53, wpb=1129.4, bsz=32, num_updates=4810, lr=2.89601e-05, gnorm=1.954, clip=100, loss_scale=256, train_wall=19, gb_free=11, wall=9035
2023-05-26 01:53:59 - progress_bar.py[line:272] - INFO: epoch 003:   1362 / 1732 loss=2.405, loss_v1=0, loss_v2=0, nll_loss=1.208, ntokens=1092.5, nsentences=32, sample_size=1092.5, sample_size_v1=0, sample_size_v2=0, ppl=2.31, wps=576.4, ups=0.53, wpb=1092.5, bsz=32, num_updates=4820, lr=2.8954e-05, gnorm=1.836, clip=100, loss_scale=256, train_wall=19, gb_free=10.3, wall=9054
2023-05-26 01:54:18 - progress_bar.py[line:272] - INFO: epoch 003:   1372 / 1732 loss=2.445, loss_v1=0, loss_v2=0, nll_loss=1.253, ntokens=1098.3, nsentences=32, sample_size=1098.3, sample_size_v1=0, sample_size_v2=0, ppl=2.38, wps=584.2, ups=0.53, wpb=1098.3, bsz=32, num_updates=4830, lr=2.89479e-05, gnorm=1.855, clip=100, loss_scale=256, train_wall=19, gb_free=11.6, wall=9072
2023-05-26 01:54:37 - progress_bar.py[line:272] - INFO: epoch 003:   1382 / 1732 loss=2.45, loss_v1=0, loss_v2=0, nll_loss=1.259, ntokens=1160, nsentences=32, sample_size=1160, sample_size_v1=0, sample_size_v2=0, ppl=2.39, wps=616.1, ups=0.53, wpb=1160, bsz=32, num_updates=4840, lr=2.89417e-05, gnorm=1.891, clip=100, loss_scale=256, train_wall=19, gb_free=10.9, wall=9091
2023-05-26 01:54:55 - progress_bar.py[line:272] - INFO: epoch 003:   1392 / 1732 loss=2.435, loss_v1=0, loss_v2=0, nll_loss=1.244, ntokens=1049.4, nsentences=32, sample_size=1049.4, sample_size_v1=0, sample_size_v2=0, ppl=2.37, wps=562.7, ups=0.54, wpb=1049.4, bsz=32, num_updates=4850, lr=2.89356e-05, gnorm=2.107, clip=100, loss_scale=256, train_wall=19, gb_free=11.2, wall=9110
2023-05-26 01:55:14 - progress_bar.py[line:272] - INFO: epoch 003:   1402 / 1732 loss=2.415, loss_v1=0, loss_v2=0, nll_loss=1.216, ntokens=1133.7, nsentences=32, sample_size=1133.7, sample_size_v1=0, sample_size_v2=0, ppl=2.32, wps=594, ups=0.52, wpb=1133.7, bsz=32, num_updates=4860, lr=2.89294e-05, gnorm=1.735, clip=100, loss_scale=256, train_wall=19, gb_free=10.2, wall=9129
2023-05-26 01:55:33 - progress_bar.py[line:272] - INFO: epoch 003:   1412 / 1732 loss=2.451, loss_v1=0, loss_v2=0, nll_loss=1.262, ntokens=1246.7, nsentences=32, sample_size=1246.7, sample_size_v1=0, sample_size_v2=0, ppl=2.4, wps=659, ups=0.53, wpb=1246.7, bsz=32, num_updates=4870, lr=2.89233e-05, gnorm=1.659, clip=100, loss_scale=256, train_wall=19, gb_free=10.8, wall=9148
2023-05-26 01:55:52 - progress_bar.py[line:272] - INFO: epoch 003:   1422 / 1732 loss=2.435, loss_v1=0, loss_v2=0, nll_loss=1.24, ntokens=1259.2, nsentences=32, sample_size=1259.2, sample_size_v1=0, sample_size_v2=0, ppl=2.36, wps=656.6, ups=0.52, wpb=1259.2, bsz=32, num_updates=4880, lr=2.89171e-05, gnorm=1.648, clip=100, loss_scale=256, train_wall=19, gb_free=10.7, wall=9167
2023-05-26 01:56:11 - progress_bar.py[line:272] - INFO: epoch 003:   1432 / 1732 loss=2.41, loss_v1=0, loss_v2=0, nll_loss=1.218, ntokens=1215.6, nsentences=32, sample_size=1215.6, sample_size_v1=0, sample_size_v2=0, ppl=2.33, wps=643, ups=0.53, wpb=1215.6, bsz=32, num_updates=4890, lr=2.8911e-05, gnorm=1.661, clip=100, loss_scale=256, train_wall=19, gb_free=11.2, wall=9186
2023-05-26 01:56:30 - progress_bar.py[line:272] - INFO: epoch 003:   1442 / 1732 loss=2.437, loss_v1=0, loss_v2=0, nll_loss=1.24, ntokens=1136.6, nsentences=32, sample_size=1136.6, sample_size_v1=0, sample_size_v2=0, ppl=2.36, wps=603.7, ups=0.53, wpb=1136.6, bsz=32, num_updates=4900, lr=2.89049e-05, gnorm=1.789, clip=100, loss_scale=256, train_wall=19, gb_free=11.2, wall=9205
2023-05-26 01:56:49 - progress_bar.py[line:272] - INFO: epoch 003:   1452 / 1732 loss=2.445, loss_v1=0, loss_v2=0, nll_loss=1.254, ntokens=1140.1, nsentences=32, sample_size=1140.1, sample_size_v1=0, sample_size_v2=0, ppl=2.38, wps=605.3, ups=0.53, wpb=1140.1, bsz=32, num_updates=4910, lr=2.88987e-05, gnorm=1.746, clip=100, loss_scale=256, train_wall=19, gb_free=11.7, wall=9224
2023-05-26 01:57:08 - progress_bar.py[line:272] - INFO: epoch 003:   1462 / 1732 loss=2.402, loss_v1=0, loss_v2=0, nll_loss=1.206, ntokens=1170.3, nsentences=32, sample_size=1170.3, sample_size_v1=0, sample_size_v2=0, ppl=2.31, wps=618.4, ups=0.53, wpb=1170.3, bsz=32, num_updates=4920, lr=2.88926e-05, gnorm=1.611, clip=100, loss_scale=256, train_wall=19, gb_free=10.6, wall=9243
2023-05-26 01:57:27 - progress_bar.py[line:272] - INFO: epoch 003:   1472 / 1732 loss=2.415, loss_v1=0, loss_v2=0, nll_loss=1.22, ntokens=1139, nsentences=32, sample_size=1139, sample_size_v1=0, sample_size_v2=0, ppl=2.33, wps=601.8, ups=0.53, wpb=1139, bsz=32, num_updates=4930, lr=2.88864e-05, gnorm=2.051, clip=100, loss_scale=256, train_wall=19, gb_free=11.7, wall=9261
2023-05-26 01:57:46 - progress_bar.py[line:272] - INFO: epoch 003:   1482 / 1732 loss=2.463, loss_v1=0, loss_v2=0, nll_loss=1.272, ntokens=1051.3, nsentences=32, sample_size=1051.3, sample_size_v1=0, sample_size_v2=0, ppl=2.41, wps=561.4, ups=0.53, wpb=1051.3, bsz=32, num_updates=4940, lr=2.88803e-05, gnorm=2.007, clip=100, loss_scale=256, train_wall=19, gb_free=10.6, wall=9280
2023-05-26 01:58:04 - progress_bar.py[line:272] - INFO: epoch 003:   1492 / 1732 loss=2.424, loss_v1=0, loss_v2=0, nll_loss=1.23, ntokens=1143, nsentences=32, sample_size=1143, sample_size_v1=0, sample_size_v2=0, ppl=2.35, wps=604.9, ups=0.53, wpb=1143, bsz=32, num_updates=4950, lr=2.88741e-05, gnorm=1.879, clip=100, loss_scale=256, train_wall=19, gb_free=11.5, wall=9299
2023-05-26 01:58:23 - progress_bar.py[line:272] - INFO: epoch 003:   1502 / 1732 loss=2.386, loss_v1=0, loss_v2=0, nll_loss=1.187, ntokens=1131.9, nsentences=32, sample_size=1131.9, sample_size_v1=0, sample_size_v2=0, ppl=2.28, wps=597.4, ups=0.53, wpb=1131.9, bsz=32, num_updates=4960, lr=2.8868e-05, gnorm=1.878, clip=100, loss_scale=256, train_wall=19, gb_free=10.3, wall=9318
2023-05-26 01:58:42 - progress_bar.py[line:272] - INFO: epoch 003:   1512 / 1732 loss=2.426, loss_v1=0, loss_v2=0, nll_loss=1.233, ntokens=1058.6, nsentences=32, sample_size=1058.6, sample_size_v1=0, sample_size_v2=0, ppl=2.35, wps=566.1, ups=0.53, wpb=1058.6, bsz=32, num_updates=4970, lr=2.88619e-05, gnorm=2.026, clip=100, loss_scale=256, train_wall=19, gb_free=10.8, wall=9337
2023-05-26 01:59:01 - progress_bar.py[line:272] - INFO: epoch 003:   1522 / 1732 loss=2.46, loss_v1=0, loss_v2=0, nll_loss=1.268, ntokens=1011, nsentences=32, sample_size=1011, sample_size_v1=0, sample_size_v2=0, ppl=2.41, wps=541.9, ups=0.54, wpb=1011, bsz=32, num_updates=4980, lr=2.88557e-05, gnorm=2.055, clip=100, loss_scale=256, train_wall=19, gb_free=11.8, wall=9355
2023-05-26 01:59:20 - progress_bar.py[line:272] - INFO: epoch 003:   1532 / 1732 loss=2.453, loss_v1=0, loss_v2=0, nll_loss=1.262, ntokens=1075.4, nsentences=32, sample_size=1075.4, sample_size_v1=0, sample_size_v2=0, ppl=2.4, wps=569.3, ups=0.53, wpb=1075.4, bsz=32, num_updates=4990, lr=2.88496e-05, gnorm=1.879, clip=100, loss_scale=256, train_wall=19, gb_free=10.7, wall=9374
2023-05-26 01:59:39 - progress_bar.py[line:272] - INFO: epoch 003:   1542 / 1732 loss=2.414, loss_v1=0, loss_v2=0, nll_loss=1.219, ntokens=1113.4, nsentences=32, sample_size=1113.4, sample_size_v1=0, sample_size_v2=0, ppl=2.33, wps=589.4, ups=0.53, wpb=1113.4, bsz=32, num_updates=5000, lr=2.88434e-05, gnorm=1.765, clip=100, loss_scale=256, train_wall=19, gb_free=11, wall=9393
2023-05-26 01:59:57 - progress_bar.py[line:272] - INFO: epoch 003:   1552 / 1732 loss=2.406, loss_v1=0, loss_v2=0, nll_loss=1.212, ntokens=1059, nsentences=32, sample_size=1059, sample_size_v1=0, sample_size_v2=0, ppl=2.32, wps=563.4, ups=0.53, wpb=1059, bsz=32, num_updates=5010, lr=2.88373e-05, gnorm=1.806, clip=100, loss_scale=512, train_wall=19, gb_free=11.3, wall=9412
2023-05-26 02:00:16 - progress_bar.py[line:272] - INFO: epoch 003:   1562 / 1732 loss=2.438, loss_v1=0, loss_v2=0, nll_loss=1.243, ntokens=1107.4, nsentences=32, sample_size=1107.4, sample_size_v1=0, sample_size_v2=0, ppl=2.37, wps=588.2, ups=0.53, wpb=1107.4, bsz=32, num_updates=5020, lr=2.88312e-05, gnorm=1.815, clip=100, loss_scale=512, train_wall=19, gb_free=11.2, wall=9431
2023-05-26 02:00:35 - progress_bar.py[line:272] - INFO: epoch 003:   1572 / 1732 loss=2.45, loss_v1=0, loss_v2=0, nll_loss=1.259, ntokens=1068.7, nsentences=32, sample_size=1068.7, sample_size_v1=0, sample_size_v2=0, ppl=2.39, wps=568.5, ups=0.53, wpb=1068.7, bsz=32, num_updates=5030, lr=2.8825e-05, gnorm=1.959, clip=100, loss_scale=512, train_wall=19, gb_free=11.6, wall=9450
2023-05-26 02:00:37 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 256.0
2023-05-26 02:00:56 - progress_bar.py[line:272] - INFO: epoch 003:   1583 / 1732 loss=2.469, loss_v1=0, loss_v2=0, nll_loss=1.281, ntokens=1007.5, nsentences=32, sample_size=1007.5, sample_size_v1=0, sample_size_v2=0, ppl=2.43, wps=487.3, ups=0.48, wpb=1007.5, bsz=32, num_updates=5040, lr=2.88189e-05, gnorm=2.042, clip=100, loss_scale=256, train_wall=21, gb_free=11.3, wall=9470
2023-05-26 02:01:14 - progress_bar.py[line:272] - INFO: epoch 003:   1593 / 1732 loss=2.409, loss_v1=0, loss_v2=0, nll_loss=1.213, ntokens=1081.3, nsentences=32, sample_size=1081.3, sample_size_v1=0, sample_size_v2=0, ppl=2.32, wps=575.1, ups=0.53, wpb=1081.3, bsz=32, num_updates=5050, lr=2.88127e-05, gnorm=1.749, clip=100, loss_scale=256, train_wall=19, gb_free=11.6, wall=9489
2023-05-26 02:01:33 - progress_bar.py[line:272] - INFO: epoch 003:   1603 / 1732 loss=2.404, loss_v1=0, loss_v2=0, nll_loss=1.208, ntokens=1092.4, nsentences=32, sample_size=1092.4, sample_size_v1=0, sample_size_v2=0, ppl=2.31, wps=580.2, ups=0.53, wpb=1092.4, bsz=32, num_updates=5060, lr=2.88066e-05, gnorm=1.697, clip=100, loss_scale=256, train_wall=19, gb_free=11.7, wall=9508
2023-05-26 02:01:52 - progress_bar.py[line:272] - INFO: epoch 003:   1613 / 1732 loss=2.398, loss_v1=0, loss_v2=0, nll_loss=1.2, ntokens=1153.1, nsentences=32, sample_size=1153.1, sample_size_v1=0, sample_size_v2=0, ppl=2.3, wps=606.8, ups=0.53, wpb=1153.1, bsz=32, num_updates=5070, lr=2.88004e-05, gnorm=1.732, clip=100, loss_scale=256, train_wall=19, gb_free=10.7, wall=9527
2023-05-26 02:02:11 - progress_bar.py[line:272] - INFO: epoch 003:   1623 / 1732 loss=2.398, loss_v1=0, loss_v2=0, nll_loss=1.202, ntokens=1098.4, nsentences=32, sample_size=1098.4, sample_size_v1=0, sample_size_v2=0, ppl=2.3, wps=581.9, ups=0.53, wpb=1098.4, bsz=32, num_updates=5080, lr=2.87943e-05, gnorm=1.888, clip=100, loss_scale=256, train_wall=19, gb_free=10.9, wall=9546
2023-05-26 02:02:30 - progress_bar.py[line:272] - INFO: epoch 003:   1633 / 1732 loss=2.404, loss_v1=0, loss_v2=0, nll_loss=1.206, ntokens=1178.3, nsentences=32, sample_size=1178.3, sample_size_v1=0, sample_size_v2=0, ppl=2.31, wps=623.1, ups=0.53, wpb=1178.3, bsz=32, num_updates=5090, lr=2.87882e-05, gnorm=1.708, clip=100, loss_scale=256, train_wall=19, gb_free=11.5, wall=9565
2023-05-26 02:02:49 - progress_bar.py[line:272] - INFO: epoch 003:   1643 / 1732 loss=2.381, loss_v1=0, loss_v2=0, nll_loss=1.181, ntokens=1238.2, nsentences=32, sample_size=1238.2, sample_size_v1=0, sample_size_v2=0, ppl=2.27, wps=653.7, ups=0.53, wpb=1238.2, bsz=32, num_updates=5100, lr=2.8782e-05, gnorm=1.621, clip=100, loss_scale=256, train_wall=19, gb_free=11.3, wall=9584
2023-05-26 02:03:08 - progress_bar.py[line:272] - INFO: epoch 003:   1653 / 1732 loss=2.436, loss_v1=0, loss_v2=0, nll_loss=1.244, ntokens=993.8, nsentences=32, sample_size=993.8, sample_size_v1=0, sample_size_v2=0, ppl=2.37, wps=530.9, ups=0.53, wpb=993.8, bsz=32, num_updates=5110, lr=2.87759e-05, gnorm=2.241, clip=100, loss_scale=256, train_wall=19, gb_free=11.6, wall=9602
2023-05-26 02:03:27 - progress_bar.py[line:272] - INFO: epoch 003:   1663 / 1732 loss=2.441, loss_v1=0, loss_v2=0, nll_loss=1.245, ntokens=1051.4, nsentences=32, sample_size=1051.4, sample_size_v1=0, sample_size_v2=0, ppl=2.37, wps=556.5, ups=0.53, wpb=1051.4, bsz=32, num_updates=5120, lr=2.87697e-05, gnorm=1.864, clip=100, loss_scale=256, train_wall=19, gb_free=11.1, wall=9621
2023-05-26 02:03:45 - progress_bar.py[line:272] - INFO: epoch 003:   1673 / 1732 loss=2.396, loss_v1=0, loss_v2=0, nll_loss=1.201, ntokens=1033, nsentences=32, sample_size=1033, sample_size_v1=0, sample_size_v2=0, ppl=2.3, wps=552.4, ups=0.53, wpb=1033, bsz=32, num_updates=5130, lr=2.87636e-05, gnorm=2.05, clip=100, loss_scale=256, train_wall=19, gb_free=10.8, wall=9640
2023-05-26 02:04:04 - progress_bar.py[line:272] - INFO: epoch 003:   1683 / 1732 loss=2.38, loss_v1=0, loss_v2=0, nll_loss=1.182, ntokens=1168.8, nsentences=32, sample_size=1168.8, sample_size_v1=0, sample_size_v2=0, ppl=2.27, wps=614.7, ups=0.53, wpb=1168.8, bsz=32, num_updates=5140, lr=2.87574e-05, gnorm=1.773, clip=100, loss_scale=256, train_wall=19, gb_free=11.2, wall=9659
2023-05-26 02:04:24 - progress_bar.py[line:272] - INFO: epoch 003:   1693 / 1732 loss=2.395, loss_v1=0, loss_v2=0, nll_loss=1.197, ntokens=1251.1, nsentences=32, sample_size=1251.1, sample_size_v1=0, sample_size_v2=0, ppl=2.29, wps=652.9, ups=0.52, wpb=1251.1, bsz=32, num_updates=5150, lr=2.87513e-05, gnorm=1.602, clip=100, loss_scale=256, train_wall=19, gb_free=11.1, wall=9678
2023-05-26 02:04:43 - progress_bar.py[line:272] - INFO: epoch 003:   1703 / 1732 loss=2.412, loss_v1=0, loss_v2=0, nll_loss=1.218, ntokens=1247.1, nsentences=32, sample_size=1247.1, sample_size_v1=0, sample_size_v2=0, ppl=2.33, wps=653.5, ups=0.52, wpb=1247.1, bsz=32, num_updates=5160, lr=2.87452e-05, gnorm=1.769, clip=100, loss_scale=256, train_wall=19, gb_free=11.2, wall=9697
2023-05-26 02:05:02 - progress_bar.py[line:272] - INFO: epoch 003:   1713 / 1732 loss=2.406, loss_v1=0, loss_v2=0, nll_loss=1.208, ntokens=1176.1, nsentences=32, sample_size=1176.1, sample_size_v1=0, sample_size_v2=0, ppl=2.31, wps=620.1, ups=0.53, wpb=1176.1, bsz=32, num_updates=5170, lr=2.8739e-05, gnorm=1.684, clip=100, loss_scale=256, train_wall=19, gb_free=9.2, wall=9716
2023-05-26 02:05:21 - progress_bar.py[line:272] - INFO: epoch 003:   1723 / 1732 loss=2.415, loss_v1=0, loss_v2=0, nll_loss=1.22, ntokens=1147.2, nsentences=32, sample_size=1147.2, sample_size_v1=0, sample_size_v2=0, ppl=2.33, wps=604.1, ups=0.53, wpb=1147.2, bsz=32, num_updates=5180, lr=2.87329e-05, gnorm=1.734, clip=100, loss_scale=256, train_wall=19, gb_free=10.3, wall=9735
2023-05-26 02:05:36 - train.py[line:332] - INFO: end of epoch 3 (average epoch stats below)
2023-05-26 02:05:36 - progress_bar.py[line:282] - INFO: epoch 003 | loss 2.451 | loss_v1 0 | loss_v2 0 | nll_loss 1.261 | ntokens 1051.51 | nsentences 31.986 | sample_size 1051.51 | sample_size_v1 0 | sample_size_v2 0 | ppl 2.4 | wps 559.8 | ups 0.53 | wpb 1051.5 | bsz 32 | num_updates 5189 | lr 2.87274e-05 | gnorm 1.68 | clip 99.9 | loss_scale 256 | train_wall 3240 | gb_free 11.7 | wall 9751
2023-05-26 02:05:36 - trainer.py[line:639] - INFO: loading train data for epoch 4
local datafile ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 0 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 0 finished initializing row_count and line_idx-to-offset mapping
file ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 0 row count 55400 total row count 55400
slice_id 0 seek offset 0
2023-05-26 02:05:38 - trainer.py[line:703] - INFO: begin training epoch 4
2023-05-26 02:05:38 - train.py[line:305] - INFO: Start iterating over samples
2023-05-26 02:05:40 - progress_bar.py[line:272] - INFO: epoch 004:      1 / 1732 loss=2.467, loss_v1=0, loss_v2=0, nll_loss=1.275, ntokens=1067.2, nsentences=29.6, sample_size=1067.2, sample_size_v1=0, sample_size_v2=0, ppl=2.42, wps=547.5, ups=0.51, wpb=1067.2, bsz=29.6, num_updates=5190, lr=2.87267e-05, gnorm=2.02, clip=100, loss_scale=256, train_wall=17, gb_free=11.4, wall=9755
2023-05-26 02:05:59 - progress_bar.py[line:272] - INFO: epoch 004:     11 / 1732 loss=2.349, loss_v1=0, loss_v2=0, nll_loss=1.147, ntokens=1109.8, nsentences=32, sample_size=1109.8, sample_size_v1=0, sample_size_v2=0, ppl=2.21, wps=585.8, ups=0.53, wpb=1109.8, bsz=32, num_updates=5200, lr=2.87206e-05, gnorm=2.049, clip=100, loss_scale=256, train_wall=19, gb_free=11.4, wall=9774
2023-05-26 02:06:18 - progress_bar.py[line:272] - INFO: epoch 004:     21 / 1732 loss=2.291, loss_v1=0, loss_v2=0, nll_loss=1.08, ntokens=1106.8, nsentences=32, sample_size=1106.8, sample_size_v1=0, sample_size_v2=0, ppl=2.11, wps=588.3, ups=0.53, wpb=1106.8, bsz=32, num_updates=5210, lr=2.87145e-05, gnorm=1.621, clip=100, loss_scale=256, train_wall=19, gb_free=11.2, wall=9793
2023-05-26 02:06:37 - progress_bar.py[line:272] - INFO: epoch 004:     31 / 1732 loss=2.35, loss_v1=0, loss_v2=0, nll_loss=1.146, ntokens=958.4, nsentences=32, sample_size=958.4, sample_size_v1=0, sample_size_v2=0, ppl=2.21, wps=509.7, ups=0.53, wpb=958.4, bsz=32, num_updates=5220, lr=2.87083e-05, gnorm=2.114, clip=100, loss_scale=256, train_wall=19, gb_free=11.1, wall=9811
2023-05-26 02:06:56 - progress_bar.py[line:272] - INFO: epoch 004:     41 / 1732 loss=2.213, loss_v1=0, loss_v2=0, nll_loss=0.995, ntokens=1207.2, nsentences=32, sample_size=1207.2, sample_size_v1=0, sample_size_v2=0, ppl=1.99, wps=632.7, ups=0.52, wpb=1207.2, bsz=32, num_updates=5230, lr=2.87022e-05, gnorm=1.458, clip=90, loss_scale=256, train_wall=19, gb_free=10.9, wall=9830
2023-05-26 02:07:15 - progress_bar.py[line:272] - INFO: epoch 004:     51 / 1732 loss=2.294, loss_v1=0, loss_v2=0, nll_loss=1.084, ntokens=1028.6, nsentences=32, sample_size=1028.6, sample_size_v1=0, sample_size_v2=0, ppl=2.12, wps=546.2, ups=0.53, wpb=1028.6, bsz=32, num_updates=5240, lr=2.8696e-05, gnorm=2.071, clip=100, loss_scale=256, train_wall=19, gb_free=11.2, wall=9849
2023-05-26 02:07:33 - progress_bar.py[line:272] - INFO: epoch 004:     61 / 1732 loss=2.08, loss_v1=0, loss_v2=0, nll_loss=0.847, ntokens=1123.9, nsentences=32, sample_size=1123.9, sample_size_v1=0, sample_size_v2=0, ppl=1.8, wps=597.6, ups=0.53, wpb=1123.9, bsz=32, num_updates=5250, lr=2.86899e-05, gnorm=1.591, clip=100, loss_scale=256, train_wall=19, gb_free=10.1, wall=9868
2023-05-26 02:07:53 - progress_bar.py[line:272] - INFO: epoch 004:     71 / 1732 loss=2.156, loss_v1=0, loss_v2=0, nll_loss=0.929, ntokens=1363.4, nsentences=32, sample_size=1363.4, sample_size_v1=0, sample_size_v2=0, ppl=1.9, wps=701.6, ups=0.51, wpb=1363.4, bsz=32, num_updates=5260, lr=2.86837e-05, gnorm=1.336, clip=100, loss_scale=256, train_wall=19, gb_free=10.1, wall=9888
2023-05-26 02:08:12 - progress_bar.py[line:272] - INFO: epoch 004:     81 / 1732 loss=2.205, loss_v1=0, loss_v2=0, nll_loss=0.985, ntokens=1263, nsentences=32, sample_size=1263, sample_size_v1=0, sample_size_v2=0, ppl=1.98, wps=653.9, ups=0.52, wpb=1263, bsz=32, num_updates=5270, lr=2.86776e-05, gnorm=1.486, clip=100, loss_scale=256, train_wall=19, gb_free=11.3, wall=9907
2023-05-26 02:08:31 - progress_bar.py[line:272] - INFO: epoch 004:     91 / 1732 loss=2.276, loss_v1=0, loss_v2=0, nll_loss=1.062, ntokens=1062.5, nsentences=32, sample_size=1062.5, sample_size_v1=0, sample_size_v2=0, ppl=2.09, wps=558.5, ups=0.53, wpb=1062.5, bsz=32, num_updates=5280, lr=2.86715e-05, gnorm=1.481, clip=100, loss_scale=256, train_wall=19, gb_free=11.4, wall=9926
2023-05-26 02:08:50 - progress_bar.py[line:272] - INFO: epoch 004:    101 / 1732 loss=2.294, loss_v1=0, loss_v2=0, nll_loss=1.09, ntokens=1023.5, nsentences=32, sample_size=1023.5, sample_size_v1=0, sample_size_v2=0, ppl=2.13, wps=547, ups=0.53, wpb=1023.5, bsz=32, num_updates=5290, lr=2.86653e-05, gnorm=1.84, clip=100, loss_scale=256, train_wall=19, gb_free=11, wall=9945
2023-05-26 02:09:09 - progress_bar.py[line:272] - INFO: epoch 004:    111 / 1732 loss=2.439, loss_v1=0, loss_v2=0, nll_loss=1.244, ntokens=1034.7, nsentences=32, sample_size=1034.7, sample_size_v1=0, sample_size_v2=0, ppl=2.37, wps=551, ups=0.53, wpb=1034.7, bsz=32, num_updates=5300, lr=2.86592e-05, gnorm=1.717, clip=100, loss_scale=256, train_wall=19, gb_free=11.2, wall=9963
2023-05-26 02:09:28 - progress_bar.py[line:272] - INFO: epoch 004:    121 / 1732 loss=2.397, loss_v1=0, loss_v2=0, nll_loss=1.198, ntokens=1114.4, nsentences=32, sample_size=1114.4, sample_size_v1=0, sample_size_v2=0, ppl=2.29, wps=583.1, ups=0.52, wpb=1114.4, bsz=32, num_updates=5310, lr=2.8653e-05, gnorm=1.618, clip=100, loss_scale=256, train_wall=19, gb_free=11.4, wall=9982
2023-05-26 02:09:47 - progress_bar.py[line:272] - INFO: epoch 004:    131 / 1732 loss=2.372, loss_v1=0, loss_v2=0, nll_loss=1.168, ntokens=1176.2, nsentences=32, sample_size=1176.2, sample_size_v1=0, sample_size_v2=0, ppl=2.25, wps=612.7, ups=0.52, wpb=1176.2, bsz=32, num_updates=5320, lr=2.86469e-05, gnorm=1.553, clip=100, loss_scale=256, train_wall=19, gb_free=11.2, wall=10002
2023-05-26 02:10:06 - progress_bar.py[line:272] - INFO: epoch 004:    141 / 1732 loss=2.322, loss_v1=0, loss_v2=0, nll_loss=1.118, ntokens=1252.9, nsentences=32, sample_size=1252.9, sample_size_v1=0, sample_size_v2=0, ppl=2.17, wps=654.5, ups=0.52, wpb=1252.9, bsz=32, num_updates=5330, lr=2.86407e-05, gnorm=1.457, clip=100, loss_scale=256, train_wall=19, gb_free=11.2, wall=10021
2023-05-26 02:10:25 - progress_bar.py[line:272] - INFO: epoch 004:    151 / 1732 loss=2.312, loss_v1=0, loss_v2=0, nll_loss=1.105, ntokens=1168.3, nsentences=32, sample_size=1168.3, sample_size_v1=0, sample_size_v2=0, ppl=2.15, wps=606.5, ups=0.52, wpb=1168.3, bsz=32, num_updates=5340, lr=2.86346e-05, gnorm=1.48, clip=100, loss_scale=256, train_wall=19, gb_free=9.9, wall=10040
2023-05-26 02:10:44 - progress_bar.py[line:272] - INFO: epoch 004:    161 / 1732 loss=2.331, loss_v1=0, loss_v2=0, nll_loss=1.127, ntokens=1106.1, nsentences=32, sample_size=1106.1, sample_size_v1=0, sample_size_v2=0, ppl=2.18, wps=581.5, ups=0.53, wpb=1106.1, bsz=32, num_updates=5350, lr=2.86285e-05, gnorm=1.711, clip=100, loss_scale=256, train_wall=19, gb_free=11.3, wall=10059
2023-05-26 02:11:03 - progress_bar.py[line:272] - INFO: epoch 004:    171 / 1732 loss=2.334, loss_v1=0, loss_v2=0, nll_loss=1.127, ntokens=969.4, nsentences=32, sample_size=969.4, sample_size_v1=0, sample_size_v2=0, ppl=2.18, wps=515.7, ups=0.53, wpb=969.4, bsz=32, num_updates=5360, lr=2.86223e-05, gnorm=1.724, clip=100, loss_scale=256, train_wall=19, gb_free=11.3, wall=10078
2023-05-26 02:11:22 - progress_bar.py[line:272] - INFO: epoch 004:    181 / 1732 loss=2.29, loss_v1=0, loss_v2=0, nll_loss=1.082, ntokens=1122.2, nsentences=32, sample_size=1122.2, sample_size_v1=0, sample_size_v2=0, ppl=2.12, wps=590.6, ups=0.53, wpb=1122.2, bsz=32, num_updates=5370, lr=2.86162e-05, gnorm=1.601, clip=100, loss_scale=256, train_wall=19, gb_free=11.1, wall=10097
2023-05-26 02:11:41 - progress_bar.py[line:272] - INFO: epoch 004:    191 / 1732 loss=2.298, loss_v1=0, loss_v2=0, nll_loss=1.088, ntokens=1130.1, nsentences=32, sample_size=1130.1, sample_size_v1=0, sample_size_v2=0, ppl=2.13, wps=593.9, ups=0.53, wpb=1130.1, bsz=32, num_updates=5380, lr=2.861e-05, gnorm=1.668, clip=100, loss_scale=256, train_wall=19, gb_free=10.9, wall=10116
2023-05-26 02:12:00 - progress_bar.py[line:272] - INFO: epoch 004:    201 / 1732 loss=2.38, loss_v1=0, loss_v2=0, nll_loss=1.181, ntokens=1092.1, nsentences=32, sample_size=1092.1, sample_size_v1=0, sample_size_v2=0, ppl=2.27, wps=580.4, ups=0.53, wpb=1092.1, bsz=32, num_updates=5390, lr=2.86039e-05, gnorm=1.765, clip=100, loss_scale=256, train_wall=19, gb_free=11.3, wall=10135
2023-05-26 02:12:19 - progress_bar.py[line:272] - INFO: epoch 004:    211 / 1732 loss=2.458, loss_v1=0, loss_v2=0, nll_loss=1.269, ntokens=1010.6, nsentences=32, sample_size=1010.6, sample_size_v1=0, sample_size_v2=0, ppl=2.41, wps=541.2, ups=0.54, wpb=1010.6, bsz=32, num_updates=5400, lr=2.85978e-05, gnorm=1.744, clip=100, loss_scale=256, train_wall=19, gb_free=11, wall=10153
2023-05-26 02:12:37 - progress_bar.py[line:272] - INFO: epoch 004:    221 / 1732 loss=2.45, loss_v1=0, loss_v2=0, nll_loss=1.255, ntokens=1140.8, nsentences=32, sample_size=1140.8, sample_size_v1=0, sample_size_v2=0, ppl=2.39, wps=610.9, ups=0.54, wpb=1140.8, bsz=32, num_updates=5410, lr=2.85916e-05, gnorm=1.659, clip=100, loss_scale=256, train_wall=19, gb_free=10.6, wall=10172
2023-05-26 02:12:56 - progress_bar.py[line:272] - INFO: epoch 004:    231 / 1732 loss=2.476, loss_v1=0, loss_v2=0, nll_loss=1.29, ntokens=1093.8, nsentences=32, sample_size=1093.8, sample_size_v1=0, sample_size_v2=0, ppl=2.45, wps=586.5, ups=0.54, wpb=1093.8, bsz=32, num_updates=5420, lr=2.85855e-05, gnorm=1.728, clip=100, loss_scale=256, train_wall=19, gb_free=11.6, wall=10191
2023-05-26 02:13:15 - progress_bar.py[line:272] - INFO: epoch 004:    241 / 1732 loss=2.489, loss_v1=0, loss_v2=0, nll_loss=1.301, ntokens=1114.7, nsentences=32, sample_size=1114.7, sample_size_v1=0, sample_size_v2=0, ppl=2.46, wps=596.2, ups=0.53, wpb=1114.7, bsz=32, num_updates=5430, lr=2.85793e-05, gnorm=1.713, clip=100, loss_scale=256, train_wall=19, gb_free=11.6, wall=10209
2023-05-26 02:13:34 - progress_bar.py[line:272] - INFO: epoch 004:    251 / 1732 loss=2.461, loss_v1=0, loss_v2=0, nll_loss=1.273, ntokens=1172.1, nsentences=32, sample_size=1172.1, sample_size_v1=0, sample_size_v2=0, ppl=2.42, wps=622.4, ups=0.53, wpb=1172.1, bsz=32, num_updates=5440, lr=2.85732e-05, gnorm=1.608, clip=100, loss_scale=256, train_wall=19, gb_free=11.6, wall=10228
2023-05-26 02:13:52 - progress_bar.py[line:272] - INFO: epoch 004:    261 / 1732 loss=2.486, loss_v1=0, loss_v2=0, nll_loss=1.3, ntokens=1139.9, nsentences=32, sample_size=1139.9, sample_size_v1=0, sample_size_v2=0, ppl=2.46, wps=610.5, ups=0.54, wpb=1139.9, bsz=32, num_updates=5450, lr=2.8567e-05, gnorm=1.628, clip=100, loss_scale=256, train_wall=19, gb_free=11.1, wall=10247
2023-05-26 02:14:11 - progress_bar.py[line:272] - INFO: epoch 004:    271 / 1732 loss=2.447, loss_v1=0, loss_v2=0, nll_loss=1.254, ntokens=1145.3, nsentences=32, sample_size=1145.3, sample_size_v1=0, sample_size_v2=0, ppl=2.38, wps=608.8, ups=0.53, wpb=1145.3, bsz=32, num_updates=5460, lr=2.85609e-05, gnorm=1.7, clip=100, loss_scale=256, train_wall=19, gb_free=11.2, wall=10266
2023-05-26 02:14:30 - progress_bar.py[line:272] - INFO: epoch 004:    281 / 1732 loss=2.474, loss_v1=0, loss_v2=0, nll_loss=1.285, ntokens=1149.7, nsentences=32, sample_size=1149.7, sample_size_v1=0, sample_size_v2=0, ppl=2.44, wps=610.8, ups=0.53, wpb=1149.7, bsz=32, num_updates=5470, lr=2.85548e-05, gnorm=1.633, clip=100, loss_scale=256, train_wall=19, gb_free=11.7, wall=10285
2023-05-26 02:14:49 - progress_bar.py[line:272] - INFO: epoch 004:    291 / 1732 loss=2.435, loss_v1=0, loss_v2=0, nll_loss=1.244, ntokens=1130.5, nsentences=32, sample_size=1130.5, sample_size_v1=0, sample_size_v2=0, ppl=2.37, wps=604, ups=0.53, wpb=1130.5, bsz=32, num_updates=5480, lr=2.85486e-05, gnorm=1.862, clip=100, loss_scale=256, train_wall=19, gb_free=11.3, wall=10303
2023-05-26 02:15:07 - progress_bar.py[line:272] - INFO: epoch 004:    301 / 1732 loss=2.463, loss_v1=0, loss_v2=0, nll_loss=1.272, ntokens=1109.1, nsentences=32, sample_size=1109.1, sample_size_v1=0, sample_size_v2=0, ppl=2.42, wps=591.7, ups=0.53, wpb=1109.1, bsz=32, num_updates=5490, lr=2.85425e-05, gnorm=1.739, clip=100, loss_scale=256, train_wall=19, gb_free=11.5, wall=10322
2023-05-26 02:15:26 - progress_bar.py[line:272] - INFO: epoch 004:    311 / 1732 loss=2.429, loss_v1=0, loss_v2=0, nll_loss=1.237, ntokens=1067.3, nsentences=32, sample_size=1067.3, sample_size_v1=0, sample_size_v2=0, ppl=2.36, wps=572.5, ups=0.54, wpb=1067.3, bsz=32, num_updates=5500, lr=2.85363e-05, gnorm=1.887, clip=100, loss_scale=256, train_wall=19, gb_free=11.5, wall=10341
2023-05-26 02:15:45 - progress_bar.py[line:272] - INFO: epoch 004:    321 / 1732 loss=2.48, loss_v1=0, loss_v2=0, nll_loss=1.289, ntokens=1001.7, nsentences=32, sample_size=1001.7, sample_size_v1=0, sample_size_v2=0, ppl=2.44, wps=540.2, ups=0.54, wpb=1001.7, bsz=32, num_updates=5510, lr=2.85302e-05, gnorm=1.74, clip=100, loss_scale=256, train_wall=19, gb_free=11.8, wall=10359
2023-05-26 02:16:03 - progress_bar.py[line:272] - INFO: epoch 004:    331 / 1732 loss=2.476, loss_v1=0, loss_v2=0, nll_loss=1.29, ntokens=1019.4, nsentences=32, sample_size=1019.4, sample_size_v1=0, sample_size_v2=0, ppl=2.45, wps=548.7, ups=0.54, wpb=1019.4, bsz=32, num_updates=5520, lr=2.8524e-05, gnorm=1.959, clip=100, loss_scale=256, train_wall=19, gb_free=11.9, wall=10378
2023-05-26 02:16:22 - progress_bar.py[line:272] - INFO: epoch 004:    341 / 1732 loss=2.442, loss_v1=0, loss_v2=0, nll_loss=1.251, ntokens=952.2, nsentences=32, sample_size=952.2, sample_size_v1=0, sample_size_v2=0, ppl=2.38, wps=515.7, ups=0.54, wpb=952.2, bsz=32, num_updates=5530, lr=2.85179e-05, gnorm=2.05, clip=100, loss_scale=256, train_wall=18, gb_free=11.4, wall=10396
2023-05-26 02:16:40 - progress_bar.py[line:272] - INFO: epoch 004:    351 / 1732 loss=2.466, loss_v1=0, loss_v2=0, nll_loss=1.277, ntokens=941.5, nsentences=32, sample_size=941.5, sample_size_v1=0, sample_size_v2=0, ppl=2.42, wps=510.1, ups=0.54, wpb=941.5, bsz=32, num_updates=5540, lr=2.85118e-05, gnorm=2.069, clip=100, loss_scale=256, train_wall=18, gb_free=11.5, wall=10415
2023-05-26 02:16:59 - progress_bar.py[line:272] - INFO: epoch 004:    361 / 1732 loss=2.483, loss_v1=0, loss_v2=0, nll_loss=1.29, ntokens=925.7, nsentences=32, sample_size=925.7, sample_size_v1=0, sample_size_v2=0, ppl=2.45, wps=501.3, ups=0.54, wpb=925.7, bsz=32, num_updates=5550, lr=2.85056e-05, gnorm=2.136, clip=100, loss_scale=512, train_wall=18, gb_free=11.5, wall=10433
2023-05-26 02:17:17 - progress_bar.py[line:272] - INFO: epoch 004:    371 / 1732 loss=2.494, loss_v1=0, loss_v2=0, nll_loss=1.31, ntokens=989.1, nsentences=32, sample_size=989.1, sample_size_v1=0, sample_size_v2=0, ppl=2.48, wps=533.4, ups=0.54, wpb=989.1, bsz=32, num_updates=5560, lr=2.84995e-05, gnorm=1.997, clip=100, loss_scale=512, train_wall=19, gb_free=11, wall=10452
2023-05-26 02:17:36 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 256.0
2023-05-26 02:17:37 - progress_bar.py[line:272] - INFO: epoch 004:    382 / 1732 loss=2.481, loss_v1=0, loss_v2=0, nll_loss=1.293, ntokens=1044, nsentences=32, sample_size=1044, sample_size_v1=0, sample_size_v2=0, ppl=2.45, wps=514.5, ups=0.49, wpb=1044, bsz=32, num_updates=5570, lr=2.84933e-05, gnorm=1.887, clip=100, loss_scale=256, train_wall=20, gb_free=11.2, wall=10472
2023-05-26 02:17:56 - progress_bar.py[line:272] - INFO: epoch 004:    392 / 1732 loss=2.46, loss_v1=0, loss_v2=0, nll_loss=1.271, ntokens=1004.1, nsentences=32, sample_size=1004.1, sample_size_v1=0, sample_size_v2=0, ppl=2.41, wps=542.1, ups=0.54, wpb=1004.1, bsz=32, num_updates=5580, lr=2.84872e-05, gnorm=1.771, clip=100, loss_scale=256, train_wall=18, gb_free=11.8, wall=10491
2023-05-26 02:18:15 - progress_bar.py[line:272] - INFO: epoch 004:    402 / 1732 loss=2.447, loss_v1=0, loss_v2=0, nll_loss=1.254, ntokens=1005.2, nsentences=32, sample_size=1005.2, sample_size_v1=0, sample_size_v2=0, ppl=2.39, wps=541.9, ups=0.54, wpb=1005.2, bsz=32, num_updates=5590, lr=2.84811e-05, gnorm=2.013, clip=100, loss_scale=256, train_wall=19, gb_free=11.3, wall=10509
2023-05-26 02:18:33 - progress_bar.py[line:272] - INFO: epoch 004:    412 / 1732 loss=2.443, loss_v1=0, loss_v2=0, nll_loss=1.252, ntokens=1091.2, nsentences=32, sample_size=1091.2, sample_size_v1=0, sample_size_v2=0, ppl=2.38, wps=586.9, ups=0.54, wpb=1091.2, bsz=32, num_updates=5600, lr=2.84749e-05, gnorm=1.833, clip=100, loss_scale=256, train_wall=19, gb_free=11.3, wall=10528
2023-05-26 02:18:52 - progress_bar.py[line:272] - INFO: epoch 004:    422 / 1732 loss=2.438, loss_v1=0, loss_v2=0, nll_loss=1.244, ntokens=1011.2, nsentences=32, sample_size=1011.2, sample_size_v1=0, sample_size_v2=0, ppl=2.37, wps=543, ups=0.54, wpb=1011.2, bsz=32, num_updates=5610, lr=2.84688e-05, gnorm=1.811, clip=100, loss_scale=256, train_wall=19, gb_free=11.3, wall=10546
2023-05-26 02:19:10 - progress_bar.py[line:272] - INFO: epoch 004:    432 / 1732 loss=2.445, loss_v1=0, loss_v2=0, nll_loss=1.254, ntokens=1006.8, nsentences=32, sample_size=1006.8, sample_size_v1=0, sample_size_v2=0, ppl=2.38, wps=542.6, ups=0.54, wpb=1006.8, bsz=32, num_updates=5620, lr=2.84626e-05, gnorm=1.862, clip=100, loss_scale=256, train_wall=19, gb_free=11.7, wall=10565
2023-05-26 02:19:29 - progress_bar.py[line:272] - INFO: epoch 004:    442 / 1732 loss=2.471, loss_v1=0, loss_v2=0, nll_loss=1.282, ntokens=979.7, nsentences=32, sample_size=979.7, sample_size_v1=0, sample_size_v2=0, ppl=2.43, wps=528, ups=0.54, wpb=979.7, bsz=32, num_updates=5630, lr=2.84565e-05, gnorm=1.928, clip=100, loss_scale=256, train_wall=19, gb_free=11, wall=10584
2023-05-26 02:19:47 - progress_bar.py[line:272] - INFO: epoch 004:    452 / 1732 loss=2.461, loss_v1=0, loss_v2=0, nll_loss=1.273, ntokens=913.2, nsentences=32, sample_size=913.2, sample_size_v1=0, sample_size_v2=0, ppl=2.42, wps=494.4, ups=0.54, wpb=913.2, bsz=32, num_updates=5640, lr=2.84503e-05, gnorm=2.137, clip=100, loss_scale=256, train_wall=18, gb_free=11.9, wall=10602
2023-05-26 02:20:06 - progress_bar.py[line:272] - INFO: epoch 004:    462 / 1732 loss=2.474, loss_v1=0, loss_v2=0, nll_loss=1.283, ntokens=1070.3, nsentences=32, sample_size=1070.3, sample_size_v1=0, sample_size_v2=0, ppl=2.43, wps=576.8, ups=0.54, wpb=1070.3, bsz=32, num_updates=5650, lr=2.84442e-05, gnorm=1.902, clip=100, loss_scale=256, train_wall=19, gb_free=11, wall=10621
2023-05-26 02:20:25 - progress_bar.py[line:272] - INFO: epoch 004:    472 / 1732 loss=2.465, loss_v1=0, loss_v2=0, nll_loss=1.274, ntokens=1036.2, nsentences=32, sample_size=1036.2, sample_size_v1=0, sample_size_v2=0, ppl=2.42, wps=554.4, ups=0.54, wpb=1036.2, bsz=32, num_updates=5660, lr=2.84381e-05, gnorm=2.043, clip=100, loss_scale=256, train_wall=19, gb_free=11.1, wall=10639
2023-05-26 02:20:43 - progress_bar.py[line:272] - INFO: epoch 004:    482 / 1732 loss=2.463, loss_v1=0, loss_v2=0, nll_loss=1.274, ntokens=990.8, nsentences=32, sample_size=990.8, sample_size_v1=0, sample_size_v2=0, ppl=2.42, wps=535.5, ups=0.54, wpb=990.8, bsz=32, num_updates=5670, lr=2.84319e-05, gnorm=2.032, clip=100, loss_scale=256, train_wall=18, gb_free=11.9, wall=10658
2023-05-26 02:21:02 - progress_bar.py[line:272] - INFO: epoch 004:    492 / 1732 loss=2.457, loss_v1=0, loss_v2=0, nll_loss=1.269, ntokens=948.5, nsentences=32, sample_size=948.5, sample_size_v1=0, sample_size_v2=0, ppl=2.41, wps=510.3, ups=0.54, wpb=948.5, bsz=32, num_updates=5680, lr=2.84258e-05, gnorm=2.03, clip=100, loss_scale=256, train_wall=19, gb_free=11.2, wall=10676
2023-05-26 02:21:20 - progress_bar.py[line:272] - INFO: epoch 004:    502 / 1732 loss=2.444, loss_v1=0, loss_v2=0, nll_loss=1.251, ntokens=961.7, nsentences=32, sample_size=961.7, sample_size_v1=0, sample_size_v2=0, ppl=2.38, wps=522.8, ups=0.54, wpb=961.7, bsz=32, num_updates=5690, lr=2.84196e-05, gnorm=2.031, clip=100, loss_scale=256, train_wall=18, gb_free=11.3, wall=10695
2023-05-26 02:21:39 - progress_bar.py[line:272] - INFO: epoch 004:    512 / 1732 loss=2.485, loss_v1=0, loss_v2=0, nll_loss=1.297, ntokens=1041.1, nsentences=32, sample_size=1041.1, sample_size_v1=0, sample_size_v2=0, ppl=2.46, wps=562.7, ups=0.54, wpb=1041.1, bsz=32, num_updates=5700, lr=2.84135e-05, gnorm=1.985, clip=100, loss_scale=256, train_wall=18, gb_free=10.7, wall=10713
2023-05-26 02:21:57 - progress_bar.py[line:272] - INFO: epoch 004:    522 / 1732 loss=2.431, loss_v1=0, loss_v2=0, nll_loss=1.239, ntokens=995.3, nsentences=32, sample_size=995.3, sample_size_v1=0, sample_size_v2=0, ppl=2.36, wps=540.2, ups=0.54, wpb=995.3, bsz=32, num_updates=5710, lr=2.84073e-05, gnorm=2.138, clip=100, loss_scale=256, train_wall=18, gb_free=11.7, wall=10732
2023-05-26 02:22:15 - progress_bar.py[line:272] - INFO: epoch 004:    532 / 1732 loss=2.462, loss_v1=0, loss_v2=0, nll_loss=1.272, ntokens=942.5, nsentences=32, sample_size=942.5, sample_size_v1=0, sample_size_v2=0, ppl=2.41, wps=511, ups=0.54, wpb=942.5, bsz=32, num_updates=5720, lr=2.84012e-05, gnorm=2.211, clip=100, loss_scale=256, train_wall=18, gb_free=12, wall=10750
2023-05-26 02:22:34 - progress_bar.py[line:272] - INFO: epoch 004:    542 / 1732 loss=2.459, loss_v1=0, loss_v2=0, nll_loss=1.268, ntokens=994, nsentences=32, sample_size=994, sample_size_v1=0, sample_size_v2=0, ppl=2.41, wps=537.1, ups=0.54, wpb=994, bsz=32, num_updates=5730, lr=2.83951e-05, gnorm=1.94, clip=100, loss_scale=256, train_wall=18, gb_free=11, wall=10769
2023-05-26 02:22:53 - progress_bar.py[line:272] - INFO: epoch 004:    552 / 1732 loss=2.485, loss_v1=0, loss_v2=0, nll_loss=1.299, ntokens=1035.9, nsentences=32, sample_size=1035.9, sample_size_v1=0, sample_size_v2=0, ppl=2.46, wps=558, ups=0.54, wpb=1035.9, bsz=32, num_updates=5740, lr=2.83889e-05, gnorm=1.936, clip=100, loss_scale=256, train_wall=19, gb_free=10.9, wall=10787
2023-05-26 02:23:11 - progress_bar.py[line:272] - INFO: epoch 004:    562 / 1732 loss=2.473, loss_v1=0, loss_v2=0, nll_loss=1.283, ntokens=1016.1, nsentences=32, sample_size=1016.1, sample_size_v1=0, sample_size_v2=0, ppl=2.43, wps=547.9, ups=0.54, wpb=1016.1, bsz=32, num_updates=5750, lr=2.83828e-05, gnorm=2.072, clip=100, loss_scale=256, train_wall=19, gb_free=11.9, wall=10806
2023-05-26 02:23:30 - progress_bar.py[line:272] - INFO: epoch 004:    572 / 1732 loss=2.485, loss_v1=0, loss_v2=0, nll_loss=1.298, ntokens=1005.3, nsentences=32, sample_size=1005.3, sample_size_v1=0, sample_size_v2=0, ppl=2.46, wps=540.1, ups=0.54, wpb=1005.3, bsz=32, num_updates=5760, lr=2.83766e-05, gnorm=1.98, clip=100, loss_scale=256, train_wall=19, gb_free=11.1, wall=10824
2023-05-26 02:23:48 - progress_bar.py[line:272] - INFO: epoch 004:    582 / 1732 loss=2.462, loss_v1=0, loss_v2=0, nll_loss=1.272, ntokens=1004.5, nsentences=32, sample_size=1004.5, sample_size_v1=0, sample_size_v2=0, ppl=2.42, wps=537.3, ups=0.53, wpb=1004.5, bsz=32, num_updates=5770, lr=2.83705e-05, gnorm=1.91, clip=100, loss_scale=256, train_wall=19, gb_free=11.4, wall=10843
2023-05-26 02:24:07 - progress_bar.py[line:272] - INFO: epoch 004:    592 / 1732 loss=2.441, loss_v1=0, loss_v2=0, nll_loss=1.248, ntokens=950.1, nsentences=32, sample_size=950.1, sample_size_v1=0, sample_size_v2=0, ppl=2.37, wps=510.1, ups=0.54, wpb=950.1, bsz=32, num_updates=5780, lr=2.83644e-05, gnorm=2.081, clip=100, loss_scale=256, train_wall=19, gb_free=11.2, wall=10862
2023-05-26 02:24:25 - progress_bar.py[line:272] - INFO: epoch 004:    602 / 1732 loss=2.423, loss_v1=0, loss_v2=0, nll_loss=1.233, ntokens=920.7, nsentences=32, sample_size=920.7, sample_size_v1=0, sample_size_v2=0, ppl=2.35, wps=499.2, ups=0.54, wpb=920.7, bsz=32, num_updates=5790, lr=2.83582e-05, gnorm=2.132, clip=100, loss_scale=256, train_wall=18, gb_free=11.8, wall=10880
2023-05-26 02:24:44 - progress_bar.py[line:272] - INFO: epoch 004:    612 / 1732 loss=2.46, loss_v1=0, loss_v2=0, nll_loss=1.264, ntokens=908, nsentences=32, sample_size=908, sample_size_v1=0, sample_size_v2=0, ppl=2.4, wps=492.3, ups=0.54, wpb=908, bsz=32, num_updates=5800, lr=2.83521e-05, gnorm=2.236, clip=100, loss_scale=256, train_wall=18, gb_free=11.5, wall=10899
2023-05-26 02:25:02 - progress_bar.py[line:272] - INFO: epoch 004:    622 / 1732 loss=2.48, loss_v1=0, loss_v2=0, nll_loss=1.293, ntokens=856.3, nsentences=32, sample_size=856.3, sample_size_v1=0, sample_size_v2=0, ppl=2.45, wps=467.7, ups=0.55, wpb=856.3, bsz=32, num_updates=5810, lr=2.83459e-05, gnorm=2.302, clip=100, loss_scale=256, train_wall=18, gb_free=11, wall=10917
2023-05-26 02:25:21 - progress_bar.py[line:272] - INFO: epoch 004:    632 / 1732 loss=2.454, loss_v1=0, loss_v2=0, nll_loss=1.265, ntokens=935.9, nsentences=32, sample_size=935.9, sample_size_v1=0, sample_size_v2=0, ppl=2.4, wps=507.6, ups=0.54, wpb=935.9, bsz=32, num_updates=5820, lr=2.83398e-05, gnorm=2.286, clip=100, loss_scale=256, train_wall=18, gb_free=11.9, wall=10935
2023-05-26 02:25:39 - progress_bar.py[line:272] - INFO: epoch 004:    642 / 1732 loss=2.466, loss_v1=0, loss_v2=0, nll_loss=1.274, ntokens=946.6, nsentences=32, sample_size=946.6, sample_size_v1=0, sample_size_v2=0, ppl=2.42, wps=514.5, ups=0.54, wpb=946.6, bsz=32, num_updates=5830, lr=2.83336e-05, gnorm=2.014, clip=100, loss_scale=256, train_wall=18, gb_free=11.2, wall=10954
2023-05-26 02:25:57 - progress_bar.py[line:272] - INFO: epoch 004:    652 / 1732 loss=2.471, loss_v1=0, loss_v2=0, nll_loss=1.283, ntokens=952.7, nsentences=32, sample_size=952.7, sample_size_v1=0, sample_size_v2=0, ppl=2.43, wps=519.6, ups=0.55, wpb=952.7, bsz=32, num_updates=5840, lr=2.83275e-05, gnorm=2.143, clip=100, loss_scale=256, train_wall=18, gb_free=12.2, wall=10972
2023-05-26 02:26:16 - progress_bar.py[line:272] - INFO: epoch 004:    662 / 1732 loss=2.472, loss_v1=0, loss_v2=0, nll_loss=1.285, ntokens=882.3, nsentences=32, sample_size=882.3, sample_size_v1=0, sample_size_v2=0, ppl=2.44, wps=481.3, ups=0.55, wpb=882.3, bsz=32, num_updates=5850, lr=2.83214e-05, gnorm=2.508, clip=100, loss_scale=256, train_wall=18, gb_free=10.7, wall=10990
2023-05-26 02:26:34 - progress_bar.py[line:272] - INFO: epoch 004:    672 / 1732 loss=2.482, loss_v1=0, loss_v2=0, nll_loss=1.295, ntokens=943.8, nsentences=32, sample_size=943.8, sample_size_v1=0, sample_size_v2=0, ppl=2.45, wps=511.6, ups=0.54, wpb=943.8, bsz=32, num_updates=5860, lr=2.83152e-05, gnorm=2.177, clip=100, loss_scale=256, train_wall=18, gb_free=11.7, wall=11009
2023-05-26 02:26:53 - progress_bar.py[line:272] - INFO: epoch 004:    682 / 1732 loss=2.445, loss_v1=0, loss_v2=0, nll_loss=1.252, ntokens=981.8, nsentences=32, sample_size=981.8, sample_size_v1=0, sample_size_v2=0, ppl=2.38, wps=531.9, ups=0.54, wpb=981.8, bsz=32, num_updates=5870, lr=2.83091e-05, gnorm=2.16, clip=100, loss_scale=256, train_wall=18, gb_free=11.6, wall=11027
2023-05-26 02:27:11 - progress_bar.py[line:272] - INFO: epoch 004:    692 / 1732 loss=2.473, loss_v1=0, loss_v2=0, nll_loss=1.289, ntokens=939.1, nsentences=32, sample_size=939.1, sample_size_v1=0, sample_size_v2=0, ppl=2.44, wps=506.5, ups=0.54, wpb=939.1, bsz=32, num_updates=5880, lr=2.83029e-05, gnorm=2.242, clip=100, loss_scale=256, train_wall=19, gb_free=11.8, wall=11046
2023-05-26 02:27:30 - progress_bar.py[line:272] - INFO: epoch 004:    702 / 1732 loss=2.435, loss_v1=0, loss_v2=0, nll_loss=1.236, ntokens=974.5, nsentences=32, sample_size=974.5, sample_size_v1=0, sample_size_v2=0, ppl=2.36, wps=527.6, ups=0.54, wpb=974.5, bsz=32, num_updates=5890, lr=2.82968e-05, gnorm=2.041, clip=100, loss_scale=256, train_wall=18, gb_free=11.6, wall=11064
2023-05-26 02:27:48 - progress_bar.py[line:272] - INFO: epoch 004:    712 / 1732 loss=2.471, loss_v1=0, loss_v2=0, nll_loss=1.284, ntokens=913.9, nsentences=32, sample_size=913.9, sample_size_v1=0, sample_size_v2=0, ppl=2.43, wps=491.4, ups=0.54, wpb=913.9, bsz=32, num_updates=5900, lr=2.82906e-05, gnorm=2.186, clip=100, loss_scale=256, train_wall=19, gb_free=11.8, wall=11083
2023-05-26 02:28:07 - progress_bar.py[line:272] - INFO: epoch 004:    722 / 1732 loss=2.444, loss_v1=0, loss_v2=0, nll_loss=1.256, ntokens=864.8, nsentences=32, sample_size=864.8, sample_size_v1=0, sample_size_v2=0, ppl=2.39, wps=470.8, ups=0.54, wpb=864.8, bsz=32, num_updates=5910, lr=2.82845e-05, gnorm=2.359, clip=100, loss_scale=256, train_wall=18, gb_free=11.6, wall=11101
2023-05-26 02:28:25 - progress_bar.py[line:272] - INFO: epoch 004:    732 / 1732 loss=2.436, loss_v1=0, loss_v2=0, nll_loss=1.243, ntokens=937.9, nsentences=32, sample_size=937.9, sample_size_v1=0, sample_size_v2=0, ppl=2.37, wps=508.8, ups=0.54, wpb=937.9, bsz=32, num_updates=5920, lr=2.82784e-05, gnorm=2.263, clip=100, loss_scale=256, train_wall=18, gb_free=11.3, wall=11120
2023-05-26 02:28:44 - progress_bar.py[line:272] - INFO: epoch 004:    742 / 1732 loss=2.426, loss_v1=0, loss_v2=0, nll_loss=1.23, ntokens=1015.7, nsentences=32, sample_size=1015.7, sample_size_v1=0, sample_size_v2=0, ppl=2.34, wps=550.3, ups=0.54, wpb=1015.7, bsz=32, num_updates=5930, lr=2.82722e-05, gnorm=2.079, clip=100, loss_scale=256, train_wall=18, gb_free=11.5, wall=11138
2023-05-26 02:29:02 - progress_bar.py[line:272] - INFO: epoch 004:    752 / 1732 loss=2.446, loss_v1=0, loss_v2=0, nll_loss=1.254, ntokens=960.1, nsentences=32, sample_size=960.1, sample_size_v1=0, sample_size_v2=0, ppl=2.39, wps=517.5, ups=0.54, wpb=960.1, bsz=32, num_updates=5940, lr=2.82661e-05, gnorm=2.135, clip=100, loss_scale=256, train_wall=19, gb_free=11.8, wall=11157
2023-05-26 02:29:21 - progress_bar.py[line:272] - INFO: epoch 004:    762 / 1732 loss=2.434, loss_v1=0, loss_v2=0, nll_loss=1.244, ntokens=973.7, nsentences=32, sample_size=973.7, sample_size_v1=0, sample_size_v2=0, ppl=2.37, wps=527.8, ups=0.54, wpb=973.7, bsz=32, num_updates=5950, lr=2.82599e-05, gnorm=2.056, clip=100, loss_scale=256, train_wall=18, gb_free=11.9, wall=11175
2023-05-26 02:29:39 - progress_bar.py[line:272] - INFO: epoch 004:    772 / 1732 loss=2.442, loss_v1=0, loss_v2=0, nll_loss=1.249, ntokens=955.8, nsentences=32, sample_size=955.8, sample_size_v1=0, sample_size_v2=0, ppl=2.38, wps=517.7, ups=0.54, wpb=955.8, bsz=32, num_updates=5960, lr=2.82538e-05, gnorm=2.364, clip=100, loss_scale=256, train_wall=18, gb_free=10.4, wall=11194
2023-05-26 02:29:58 - progress_bar.py[line:272] - INFO: epoch 004:    782 / 1732 loss=2.455, loss_v1=0, loss_v2=0, nll_loss=1.265, ntokens=1024.5, nsentences=32, sample_size=1024.5, sample_size_v1=0, sample_size_v2=0, ppl=2.4, wps=554.2, ups=0.54, wpb=1024.5, bsz=32, num_updates=5970, lr=2.82477e-05, gnorm=1.996, clip=100, loss_scale=256, train_wall=18, gb_free=11.6, wall=11212
2023-05-26 02:30:16 - progress_bar.py[line:272] - INFO: epoch 004:    792 / 1732 loss=2.454, loss_v1=0, loss_v2=0, nll_loss=1.263, ntokens=1023.9, nsentences=32, sample_size=1023.9, sample_size_v1=0, sample_size_v2=0, ppl=2.4, wps=554.6, ups=0.54, wpb=1023.9, bsz=32, num_updates=5980, lr=2.82415e-05, gnorm=2.172, clip=100, loss_scale=256, train_wall=18, gb_free=12, wall=11231
2023-05-26 02:30:34 - progress_bar.py[line:272] - INFO: epoch 004:    802 / 1732 loss=2.434, loss_v1=0, loss_v2=0, nll_loss=1.241, ntokens=971.6, nsentences=32, sample_size=971.6, sample_size_v1=0, sample_size_v2=0, ppl=2.36, wps=527.4, ups=0.54, wpb=971.6, bsz=32, num_updates=5990, lr=2.82354e-05, gnorm=2.206, clip=100, loss_scale=256, train_wall=18, gb_free=11.7, wall=11249
2023-05-26 02:30:53 - progress_bar.py[line:272] - INFO: epoch 004:    812 / 1732 loss=2.456, loss_v1=0, loss_v2=0, nll_loss=1.263, ntokens=942.1, nsentences=32, sample_size=942.1, sample_size_v1=0, sample_size_v2=0, ppl=2.4, wps=511.1, ups=0.54, wpb=942.1, bsz=32, num_updates=6000, lr=2.82292e-05, gnorm=2.098, clip=100, loss_scale=256, train_wall=18, gb_free=11.6, wall=11268
2023-05-26 02:31:11 - progress_bar.py[line:272] - INFO: epoch 004:    822 / 1732 loss=2.448, loss_v1=0, loss_v2=0, nll_loss=1.256, ntokens=921.5, nsentences=32, sample_size=921.5, sample_size_v1=0, sample_size_v2=0, ppl=2.39, wps=498.3, ups=0.54, wpb=921.5, bsz=32, num_updates=6010, lr=2.82231e-05, gnorm=2.35, clip=100, loss_scale=256, train_wall=18, gb_free=11.4, wall=11286
2023-05-26 02:31:30 - progress_bar.py[line:272] - INFO: epoch 004:    832 / 1732 loss=2.446, loss_v1=0, loss_v2=0, nll_loss=1.254, ntokens=907.9, nsentences=32, sample_size=907.9, sample_size_v1=0, sample_size_v2=0, ppl=2.39, wps=494, ups=0.54, wpb=907.9, bsz=32, num_updates=6020, lr=2.82169e-05, gnorm=2.137, clip=100, loss_scale=256, train_wall=18, gb_free=11.9, wall=11304
2023-05-26 02:31:48 - progress_bar.py[line:272] - INFO: epoch 004:    842 / 1732 loss=2.434, loss_v1=0, loss_v2=0, nll_loss=1.237, ntokens=950.4, nsentences=32, sample_size=950.4, sample_size_v1=0, sample_size_v2=0, ppl=2.36, wps=517.4, ups=0.54, wpb=950.4, bsz=32, num_updates=6030, lr=2.82108e-05, gnorm=2.213, clip=100, loss_scale=256, train_wall=18, gb_free=11.4, wall=11323
2023-05-26 02:32:07 - progress_bar.py[line:272] - INFO: epoch 004:    852 / 1732 loss=2.453, loss_v1=0, loss_v2=0, nll_loss=1.265, ntokens=997.8, nsentences=32, sample_size=997.8, sample_size_v1=0, sample_size_v2=0, ppl=2.4, wps=539.2, ups=0.54, wpb=997.8, bsz=32, num_updates=6040, lr=2.82047e-05, gnorm=1.954, clip=100, loss_scale=256, train_wall=18, gb_free=11.8, wall=11341
2023-05-26 02:32:25 - progress_bar.py[line:272] - INFO: epoch 004:    862 / 1732 loss=2.429, loss_v1=0, loss_v2=0, nll_loss=1.234, ntokens=931.8, nsentences=32, sample_size=931.8, sample_size_v1=0, sample_size_v2=0, ppl=2.35, wps=504.6, ups=0.54, wpb=931.8, bsz=32, num_updates=6050, lr=2.81985e-05, gnorm=2.383, clip=100, loss_scale=256, train_wall=18, gb_free=11, wall=11360
2023-05-26 02:32:44 - progress_bar.py[line:272] - INFO: epoch 004:    872 / 1732 loss=2.435, loss_v1=0, loss_v2=0, nll_loss=1.242, ntokens=965, nsentences=32, sample_size=965, sample_size_v1=0, sample_size_v2=0, ppl=2.37, wps=522.3, ups=0.54, wpb=965, bsz=32, num_updates=6060, lr=2.81924e-05, gnorm=2.136, clip=100, loss_scale=256, train_wall=18, gb_free=11.6, wall=11378
2023-05-26 02:33:02 - progress_bar.py[line:272] - INFO: epoch 004:    882 / 1732 loss=2.384, loss_v1=0, loss_v2=0, nll_loss=1.187, ntokens=987.7, nsentences=32, sample_size=987.7, sample_size_v1=0, sample_size_v2=0, ppl=2.28, wps=532, ups=0.54, wpb=987.7, bsz=32, num_updates=6070, lr=2.81862e-05, gnorm=2.15, clip=100, loss_scale=256, train_wall=19, gb_free=11.3, wall=11397
2023-05-26 02:33:21 - progress_bar.py[line:272] - INFO: epoch 004:    892 / 1732 loss=2.391, loss_v1=0, loss_v2=0, nll_loss=1.191, ntokens=1003.5, nsentences=32, sample_size=1003.5, sample_size_v1=0, sample_size_v2=0, ppl=2.28, wps=540.2, ups=0.54, wpb=1003.5, bsz=32, num_updates=6080, lr=2.81801e-05, gnorm=2.023, clip=100, loss_scale=256, train_wall=19, gb_free=11.1, wall=11415
2023-05-26 02:33:39 - progress_bar.py[line:272] - INFO: epoch 004:    902 / 1732 loss=2.385, loss_v1=0, loss_v2=0, nll_loss=1.187, ntokens=1046.1, nsentences=32, sample_size=1046.1, sample_size_v1=0, sample_size_v2=0, ppl=2.28, wps=564.1, ups=0.54, wpb=1046.1, bsz=32, num_updates=6090, lr=2.81739e-05, gnorm=1.886, clip=100, loss_scale=512, train_wall=19, gb_free=11.2, wall=11434
2023-05-26 02:33:58 - progress_bar.py[line:272] - INFO: epoch 004:    912 / 1732 loss=2.458, loss_v1=0, loss_v2=0, nll_loss=1.267, ntokens=948.6, nsentences=32, sample_size=948.6, sample_size_v1=0, sample_size_v2=0, ppl=2.41, wps=512.9, ups=0.54, wpb=948.6, bsz=32, num_updates=6100, lr=2.81678e-05, gnorm=2.093, clip=100, loss_scale=512, train_wall=18, gb_free=11, wall=11452
2023-05-26 02:34:00 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 256.0
2023-05-26 02:34:18 - progress_bar.py[line:272] - INFO: epoch 004:    923 / 1732 loss=2.412, loss_v1=0, loss_v2=0, nll_loss=1.214, ntokens=1023.3, nsentences=32, sample_size=1023.3, sample_size_v1=0, sample_size_v2=0, ppl=2.32, wps=501.3, ups=0.49, wpb=1023.3, bsz=32, num_updates=6110, lr=2.81617e-05, gnorm=2.001, clip=100, loss_scale=256, train_wall=20, gb_free=11.1, wall=11473
2023-05-26 02:34:37 - progress_bar.py[line:272] - INFO: epoch 004:    933 / 1732 loss=2.418, loss_v1=0, loss_v2=0, nll_loss=1.226, ntokens=1034.6, nsentences=32, sample_size=1034.6, sample_size_v1=0, sample_size_v2=0, ppl=2.34, wps=553.8, ups=0.54, wpb=1034.6, bsz=32, num_updates=6120, lr=2.81555e-05, gnorm=2.142, clip=100, loss_scale=256, train_wall=19, gb_free=11.1, wall=11492
2023-05-26 02:34:56 - progress_bar.py[line:272] - INFO: epoch 004:    943 / 1732 loss=2.439, loss_v1=0, loss_v2=0, nll_loss=1.244, ntokens=1054.1, nsentences=32, sample_size=1054.1, sample_size_v1=0, sample_size_v2=0, ppl=2.37, wps=561.5, ups=0.53, wpb=1054.1, bsz=32, num_updates=6130, lr=2.81494e-05, gnorm=2.1, clip=100, loss_scale=256, train_wall=19, gb_free=11.3, wall=11510
2023-05-26 02:35:14 - progress_bar.py[line:272] - INFO: epoch 004:    953 / 1732 loss=2.424, loss_v1=0, loss_v2=0, nll_loss=1.231, ntokens=1032.2, nsentences=32, sample_size=1032.2, sample_size_v1=0, sample_size_v2=0, ppl=2.35, wps=550.8, ups=0.53, wpb=1032.2, bsz=32, num_updates=6140, lr=2.81432e-05, gnorm=2.162, clip=100, loss_scale=256, train_wall=19, gb_free=10.9, wall=11529
2023-05-26 02:35:33 - progress_bar.py[line:272] - INFO: epoch 004:    963 / 1732 loss=2.429, loss_v1=0, loss_v2=0, nll_loss=1.234, ntokens=1069.2, nsentences=32, sample_size=1069.2, sample_size_v1=0, sample_size_v2=0, ppl=2.35, wps=570.8, ups=0.53, wpb=1069.2, bsz=32, num_updates=6150, lr=2.81371e-05, gnorm=2.083, clip=100, loss_scale=256, train_wall=19, gb_free=11.2, wall=11548
2023-05-26 02:35:52 - progress_bar.py[line:272] - INFO: epoch 004:    973 / 1732 loss=2.441, loss_v1=0, loss_v2=0, nll_loss=1.249, ntokens=1034.1, nsentences=32, sample_size=1034.1, sample_size_v1=0, sample_size_v2=0, ppl=2.38, wps=550.1, ups=0.53, wpb=1034.1, bsz=32, num_updates=6160, lr=2.8131e-05, gnorm=1.956, clip=100, loss_scale=256, train_wall=19, gb_free=11.2, wall=11567
2023-05-26 02:36:11 - progress_bar.py[line:272] - INFO: epoch 004:    983 / 1732 loss=2.43, loss_v1=0, loss_v2=0, nll_loss=1.236, ntokens=1026.6, nsentences=32, sample_size=1026.6, sample_size_v1=0, sample_size_v2=0, ppl=2.36, wps=544.8, ups=0.53, wpb=1026.6, bsz=32, num_updates=6170, lr=2.81248e-05, gnorm=2.053, clip=100, loss_scale=256, train_wall=19, gb_free=11.2, wall=11585
2023-05-26 02:36:30 - progress_bar.py[line:272] - INFO: epoch 004:    993 / 1732 loss=2.428, loss_v1=0, loss_v2=0, nll_loss=1.233, ntokens=1041.8, nsentences=32, sample_size=1041.8, sample_size_v1=0, sample_size_v2=0, ppl=2.35, wps=554.7, ups=0.53, wpb=1041.8, bsz=32, num_updates=6180, lr=2.81187e-05, gnorm=2.132, clip=100, loss_scale=256, train_wall=19, gb_free=11.4, wall=11604
2023-05-26 02:36:48 - progress_bar.py[line:272] - INFO: epoch 004:   1003 / 1732 loss=2.411, loss_v1=0, loss_v2=0, nll_loss=1.214, ntokens=1018, nsentences=32, sample_size=1018, sample_size_v1=0, sample_size_v2=0, ppl=2.32, wps=546, ups=0.54, wpb=1018, bsz=32, num_updates=6190, lr=2.81125e-05, gnorm=1.978, clip=100, loss_scale=256, train_wall=19, gb_free=11.2, wall=11623
2023-05-26 02:37:07 - progress_bar.py[line:272] - INFO: epoch 004:   1013 / 1732 loss=2.42, loss_v1=0, loss_v2=0, nll_loss=1.226, ntokens=965, nsentences=32, sample_size=965, sample_size_v1=0, sample_size_v2=0, ppl=2.34, wps=520.6, ups=0.54, wpb=965, bsz=32, num_updates=6200, lr=2.81064e-05, gnorm=2.035, clip=100, loss_scale=256, train_wall=19, gb_free=11.9, wall=11641
2023-05-26 02:37:26 - progress_bar.py[line:272] - INFO: epoch 004:   1023 / 1732 loss=2.408, loss_v1=0, loss_v2=0, nll_loss=1.213, ntokens=1087.1, nsentences=32, sample_size=1087.1, sample_size_v1=0, sample_size_v2=0, ppl=2.32, wps=577.3, ups=0.53, wpb=1087.1, bsz=32, num_updates=6210, lr=2.81002e-05, gnorm=1.962, clip=100, loss_scale=256, train_wall=19, gb_free=11, wall=11660
2023-05-26 02:37:44 - progress_bar.py[line:272] - INFO: epoch 004:   1033 / 1732 loss=2.42, loss_v1=0, loss_v2=0, nll_loss=1.224, ntokens=1100.3, nsentences=32, sample_size=1100.3, sample_size_v1=0, sample_size_v2=0, ppl=2.34, wps=582.7, ups=0.53, wpb=1100.3, bsz=32, num_updates=6220, lr=2.80941e-05, gnorm=1.998, clip=100, loss_scale=256, train_wall=19, gb_free=11.7, wall=11679
2023-05-26 02:38:03 - progress_bar.py[line:272] - INFO: epoch 004:   1043 / 1732 loss=2.426, loss_v1=0, loss_v2=0, nll_loss=1.23, ntokens=1068.2, nsentences=32, sample_size=1068.2, sample_size_v1=0, sample_size_v2=0, ppl=2.35, wps=567.1, ups=0.53, wpb=1068.2, bsz=32, num_updates=6230, lr=2.8088e-05, gnorm=2.178, clip=100, loss_scale=256, train_wall=19, gb_free=11.2, wall=11698
2023-05-26 02:38:22 - progress_bar.py[line:272] - INFO: epoch 004:   1053 / 1732 loss=2.425, loss_v1=0, loss_v2=0, nll_loss=1.231, ntokens=1062.8, nsentences=32, sample_size=1062.8, sample_size_v1=0, sample_size_v2=0, ppl=2.35, wps=570.2, ups=0.54, wpb=1062.8, bsz=32, num_updates=6240, lr=2.80818e-05, gnorm=2.004, clip=100, loss_scale=256, train_wall=19, gb_free=11.5, wall=11717
2023-05-26 02:38:41 - progress_bar.py[line:272] - INFO: epoch 004:   1063 / 1732 loss=2.415, loss_v1=0, loss_v2=0, nll_loss=1.218, ntokens=1030.9, nsentences=32, sample_size=1030.9, sample_size_v1=0, sample_size_v2=0, ppl=2.33, wps=550.6, ups=0.53, wpb=1030.9, bsz=32, num_updates=6250, lr=2.80757e-05, gnorm=1.918, clip=100, loss_scale=256, train_wall=19, gb_free=11.1, wall=11735
2023-05-26 02:38:59 - progress_bar.py[line:272] - INFO: epoch 004:   1073 / 1732 loss=2.436, loss_v1=0, loss_v2=0, nll_loss=1.242, ntokens=999.3, nsentences=32, sample_size=999.3, sample_size_v1=0, sample_size_v2=0, ppl=2.37, wps=533.5, ups=0.53, wpb=999.3, bsz=32, num_updates=6260, lr=2.80695e-05, gnorm=1.993, clip=100, loss_scale=256, train_wall=19, gb_free=11.3, wall=11754
2023-05-26 02:39:18 - progress_bar.py[line:272] - INFO: epoch 004:   1083 / 1732 loss=2.437, loss_v1=0, loss_v2=0, nll_loss=1.246, ntokens=1054.9, nsentences=32, sample_size=1054.9, sample_size_v1=0, sample_size_v2=0, ppl=2.37, wps=557.1, ups=0.53, wpb=1054.9, bsz=32, num_updates=6270, lr=2.80634e-05, gnorm=1.981, clip=100, loss_scale=256, train_wall=19, gb_free=10.5, wall=11773
2023-05-26 02:39:37 - progress_bar.py[line:272] - INFO: epoch 004:   1093 / 1732 loss=2.421, loss_v1=0, loss_v2=0, nll_loss=1.222, ntokens=1060.6, nsentences=32, sample_size=1060.6, sample_size_v1=0, sample_size_v2=0, ppl=2.33, wps=563.9, ups=0.53, wpb=1060.6, bsz=32, num_updates=6280, lr=2.80572e-05, gnorm=2.021, clip=100, loss_scale=256, train_wall=19, gb_free=11.1, wall=11792
2023-05-26 02:39:56 - progress_bar.py[line:272] - INFO: epoch 004:   1103 / 1732 loss=2.429, loss_v1=0, loss_v2=0, nll_loss=1.237, ntokens=1039.1, nsentences=32, sample_size=1039.1, sample_size_v1=0, sample_size_v2=0, ppl=2.36, wps=554.5, ups=0.53, wpb=1039.1, bsz=32, num_updates=6290, lr=2.80511e-05, gnorm=2.02, clip=100, loss_scale=256, train_wall=19, gb_free=11.7, wall=11811
2023-05-26 02:40:15 - progress_bar.py[line:272] - INFO: epoch 004:   1113 / 1732 loss=2.418, loss_v1=0, loss_v2=0, nll_loss=1.222, ntokens=1008.5, nsentences=32, sample_size=1008.5, sample_size_v1=0, sample_size_v2=0, ppl=2.33, wps=538.1, ups=0.53, wpb=1008.5, bsz=32, num_updates=6300, lr=2.8045e-05, gnorm=2.002, clip=100, loss_scale=256, train_wall=19, gb_free=11.4, wall=11829
2023-05-26 02:40:33 - progress_bar.py[line:272] - INFO: epoch 004:   1123 / 1732 loss=2.419, loss_v1=0, loss_v2=0, nll_loss=1.224, ntokens=976.6, nsentences=32, sample_size=976.6, sample_size_v1=0, sample_size_v2=0, ppl=2.34, wps=519.8, ups=0.53, wpb=976.6, bsz=32, num_updates=6310, lr=2.80388e-05, gnorm=2.181, clip=100, loss_scale=256, train_wall=19, gb_free=10.8, wall=11848
2023-05-26 02:40:52 - progress_bar.py[line:272] - INFO: epoch 004:   1133 / 1732 loss=2.431, loss_v1=0, loss_v2=0, nll_loss=1.238, ntokens=965.2, nsentences=32, sample_size=965.2, sample_size_v1=0, sample_size_v2=0, ppl=2.36, wps=516.5, ups=0.54, wpb=965.2, bsz=32, num_updates=6320, lr=2.80327e-05, gnorm=2.119, clip=100, loss_scale=256, train_wall=19, gb_free=10.6, wall=11867
2023-05-26 02:41:11 - progress_bar.py[line:272] - INFO: epoch 004:   1143 / 1732 loss=2.428, loss_v1=0, loss_v2=0, nll_loss=1.233, ntokens=1060.3, nsentences=32, sample_size=1060.3, sample_size_v1=0, sample_size_v2=0, ppl=2.35, wps=565.6, ups=0.53, wpb=1060.3, bsz=32, num_updates=6330, lr=2.80265e-05, gnorm=2.012, clip=100, loss_scale=256, train_wall=19, gb_free=11.1, wall=11886
2023-05-26 02:41:30 - progress_bar.py[line:272] - INFO: epoch 004:   1153 / 1732 loss=2.415, loss_v1=0, loss_v2=0, nll_loss=1.22, ntokens=1009.1, nsentences=32, sample_size=1009.1, sample_size_v1=0, sample_size_v2=0, ppl=2.33, wps=539.8, ups=0.53, wpb=1009.1, bsz=32, num_updates=6340, lr=2.80204e-05, gnorm=2.039, clip=100, loss_scale=256, train_wall=19, gb_free=11.7, wall=11904
2023-05-26 02:41:48 - progress_bar.py[line:272] - INFO: epoch 004:   1163 / 1732 loss=2.402, loss_v1=0, loss_v2=0, nll_loss=1.205, ntokens=999.2, nsentences=32, sample_size=999.2, sample_size_v1=0, sample_size_v2=0, ppl=2.31, wps=531.5, ups=0.53, wpb=999.2, bsz=32, num_updates=6350, lr=2.80142e-05, gnorm=2.125, clip=100, loss_scale=256, train_wall=19, gb_free=11.2, wall=11923
2023-05-26 02:42:07 - progress_bar.py[line:272] - INFO: epoch 004:   1173 / 1732 loss=2.414, loss_v1=0, loss_v2=0, nll_loss=1.216, ntokens=1077.2, nsentences=32, sample_size=1077.2, sample_size_v1=0, sample_size_v2=0, ppl=2.32, wps=573.5, ups=0.53, wpb=1077.2, bsz=32, num_updates=6360, lr=2.80081e-05, gnorm=2.024, clip=100, loss_scale=256, train_wall=19, gb_free=11.3, wall=11942
2023-05-26 02:42:26 - progress_bar.py[line:272] - INFO: epoch 004:   1183 / 1732 loss=2.408, loss_v1=0, loss_v2=0, nll_loss=1.214, ntokens=988.2, nsentences=32, sample_size=988.2, sample_size_v1=0, sample_size_v2=0, ppl=2.32, wps=530.5, ups=0.54, wpb=988.2, bsz=32, num_updates=6370, lr=2.8002e-05, gnorm=2.158, clip=100, loss_scale=256, train_wall=19, gb_free=11.5, wall=11960
2023-05-26 02:42:45 - progress_bar.py[line:272] - INFO: epoch 004:   1193 / 1732 loss=2.431, loss_v1=0, loss_v2=0, nll_loss=1.234, ntokens=1028.6, nsentences=32, sample_size=1028.6, sample_size_v1=0, sample_size_v2=0, ppl=2.35, wps=550, ups=0.53, wpb=1028.6, bsz=32, num_updates=6380, lr=2.79958e-05, gnorm=2.028, clip=100, loss_scale=256, train_wall=19, gb_free=11.2, wall=11979
2023-05-26 02:43:03 - progress_bar.py[line:272] - INFO: epoch 004:   1203 / 1732 loss=2.391, loss_v1=0, loss_v2=0, nll_loss=1.192, ntokens=1142.6, nsentences=32, sample_size=1142.6, sample_size_v1=0, sample_size_v2=0, ppl=2.28, wps=603.9, ups=0.53, wpb=1142.6, bsz=32, num_updates=6390, lr=2.79897e-05, gnorm=1.905, clip=100, loss_scale=256, train_wall=19, gb_free=10.3, wall=11998
2023-05-26 02:43:22 - progress_bar.py[line:272] - INFO: epoch 004:   1213 / 1732 loss=2.413, loss_v1=0, loss_v2=0, nll_loss=1.219, ntokens=1010.9, nsentences=32, sample_size=1010.9, sample_size_v1=0, sample_size_v2=0, ppl=2.33, wps=538.4, ups=0.53, wpb=1010.9, bsz=32, num_updates=6400, lr=2.79835e-05, gnorm=1.985, clip=100, loss_scale=256, train_wall=19, gb_free=11.7, wall=12017
2023-05-26 02:43:41 - progress_bar.py[line:272] - INFO: epoch 004:   1223 / 1732 loss=2.445, loss_v1=0, loss_v2=0, nll_loss=1.251, ntokens=1033.2, nsentences=32, sample_size=1033.2, sample_size_v1=0, sample_size_v2=0, ppl=2.38, wps=550.6, ups=0.53, wpb=1033.2, bsz=32, num_updates=6410, lr=2.79774e-05, gnorm=2.105, clip=100, loss_scale=256, train_wall=19, gb_free=11.2, wall=12036
2023-05-26 02:44:00 - progress_bar.py[line:272] - INFO: epoch 004:   1233 / 1732 loss=2.401, loss_v1=0, loss_v2=0, nll_loss=1.205, ntokens=1038.6, nsentences=32, sample_size=1038.6, sample_size_v1=0, sample_size_v2=0, ppl=2.31, wps=555.1, ups=0.53, wpb=1038.6, bsz=32, num_updates=6420, lr=2.79713e-05, gnorm=2.048, clip=100, loss_scale=256, train_wall=19, gb_free=11, wall=12054
2023-05-26 02:44:18 - progress_bar.py[line:272] - INFO: epoch 004:   1243 / 1732 loss=2.358, loss_v1=0, loss_v2=0, nll_loss=1.155, ntokens=1063.3, nsentences=32, sample_size=1063.3, sample_size_v1=0, sample_size_v2=0, ppl=2.23, wps=566.1, ups=0.53, wpb=1063.3, bsz=32, num_updates=6430, lr=2.79651e-05, gnorm=2.094, clip=100, loss_scale=256, train_wall=19, gb_free=11.4, wall=12073
2023-05-26 02:44:37 - progress_bar.py[line:272] - INFO: epoch 004:   1253 / 1732 loss=2.378, loss_v1=0, loss_v2=0, nll_loss=1.177, ntokens=1098.7, nsentences=32, sample_size=1098.7, sample_size_v1=0, sample_size_v2=0, ppl=2.26, wps=582, ups=0.53, wpb=1098.7, bsz=32, num_updates=6440, lr=2.7959e-05, gnorm=1.964, clip=100, loss_scale=256, train_wall=19, gb_free=11.3, wall=12092
2023-05-26 02:44:56 - progress_bar.py[line:272] - INFO: epoch 004:   1263 / 1732 loss=2.42, loss_v1=0, loss_v2=0, nll_loss=1.227, ntokens=1070.8, nsentences=32, sample_size=1070.8, sample_size_v1=0, sample_size_v2=0, ppl=2.34, wps=569.7, ups=0.53, wpb=1070.8, bsz=32, num_updates=6450, lr=2.79528e-05, gnorm=2.121, clip=100, loss_scale=256, train_wall=19, gb_free=11.1, wall=12111
2023-05-26 02:45:15 - progress_bar.py[line:272] - INFO: epoch 004:   1273 / 1732 loss=2.427, loss_v1=0, loss_v2=0, nll_loss=1.229, ntokens=1005.1, nsentences=32, sample_size=1005.1, sample_size_v1=0, sample_size_v2=0, ppl=2.34, wps=537.9, ups=0.54, wpb=1005.1, bsz=32, num_updates=6460, lr=2.79467e-05, gnorm=2.238, clip=100, loss_scale=256, train_wall=19, gb_free=10.8, wall=12130
2023-05-26 02:45:34 - progress_bar.py[line:272] - INFO: epoch 004:   1283 / 1732 loss=2.403, loss_v1=0, loss_v2=0, nll_loss=1.208, ntokens=1101.8, nsentences=32, sample_size=1101.8, sample_size_v1=0, sample_size_v2=0, ppl=2.31, wps=581.8, ups=0.53, wpb=1101.8, bsz=32, num_updates=6470, lr=2.79405e-05, gnorm=2.207, clip=100, loss_scale=256, train_wall=19, gb_free=11.4, wall=12148
2023-05-26 02:45:53 - progress_bar.py[line:272] - INFO: epoch 004:   1293 / 1732 loss=2.4, loss_v1=0, loss_v2=0, nll_loss=1.204, ntokens=1084.4, nsentences=32, sample_size=1084.4, sample_size_v1=0, sample_size_v2=0, ppl=2.3, wps=575.3, ups=0.53, wpb=1084.4, bsz=32, num_updates=6480, lr=2.79344e-05, gnorm=2.031, clip=100, loss_scale=256, train_wall=19, gb_free=11.4, wall=12167
2023-05-26 02:46:12 - progress_bar.py[line:272] - INFO: epoch 004:   1303 / 1732 loss=2.409, loss_v1=0, loss_v2=0, nll_loss=1.211, ntokens=1102.4, nsentences=32, sample_size=1102.4, sample_size_v1=0, sample_size_v2=0, ppl=2.32, wps=584.5, ups=0.53, wpb=1102.4, bsz=32, num_updates=6490, lr=2.79283e-05, gnorm=1.954, clip=100, loss_scale=256, train_wall=19, gb_free=10.9, wall=12186
2023-05-26 02:46:30 - progress_bar.py[line:272] - INFO: epoch 004:   1313 / 1732 loss=2.44, loss_v1=0, loss_v2=0, nll_loss=1.246, ntokens=1055.3, nsentences=32, sample_size=1055.3, sample_size_v1=0, sample_size_v2=0, ppl=2.37, wps=556.5, ups=0.53, wpb=1055.3, bsz=32, num_updates=6500, lr=2.79221e-05, gnorm=2.179, clip=100, loss_scale=256, train_wall=19, gb_free=10.7, wall=12205
2023-05-26 02:46:49 - progress_bar.py[line:272] - INFO: epoch 004:   1323 / 1732 loss=2.387, loss_v1=0, loss_v2=0, nll_loss=1.191, ntokens=1103.3, nsentences=32, sample_size=1103.3, sample_size_v1=0, sample_size_v2=0, ppl=2.28, wps=584, ups=0.53, wpb=1103.3, bsz=32, num_updates=6510, lr=2.7916e-05, gnorm=2.009, clip=100, loss_scale=256, train_wall=19, gb_free=11.2, wall=12224
2023-05-26 02:47:08 - progress_bar.py[line:272] - INFO: epoch 004:   1333 / 1732 loss=2.375, loss_v1=0, loss_v2=0, nll_loss=1.174, ntokens=1100.8, nsentences=32, sample_size=1100.8, sample_size_v1=0, sample_size_v2=0, ppl=2.26, wps=584.6, ups=0.53, wpb=1100.8, bsz=32, num_updates=6520, lr=2.79098e-05, gnorm=1.943, clip=100, loss_scale=256, train_wall=19, gb_free=11.1, wall=12243
2023-05-26 02:47:27 - progress_bar.py[line:272] - INFO: epoch 004:   1343 / 1732 loss=2.388, loss_v1=0, loss_v2=0, nll_loss=1.19, ntokens=1190.4, nsentences=32, sample_size=1190.4, sample_size_v1=0, sample_size_v2=0, ppl=2.28, wps=629.4, ups=0.53, wpb=1190.4, bsz=32, num_updates=6530, lr=2.79037e-05, gnorm=1.868, clip=100, loss_scale=256, train_wall=19, gb_free=11.1, wall=12262
2023-05-26 02:47:46 - progress_bar.py[line:272] - INFO: epoch 004:   1353 / 1732 loss=2.398, loss_v1=0, loss_v2=0, nll_loss=1.199, ntokens=1120.7, nsentences=32, sample_size=1120.7, sample_size_v1=0, sample_size_v2=0, ppl=2.3, wps=592.3, ups=0.53, wpb=1120.7, bsz=32, num_updates=6540, lr=2.78975e-05, gnorm=1.958, clip=100, loss_scale=256, train_wall=19, gb_free=11.4, wall=12281
2023-05-26 02:48:05 - progress_bar.py[line:272] - INFO: epoch 004:   1363 / 1732 loss=2.372, loss_v1=0, loss_v2=0, nll_loss=1.172, ntokens=1088.2, nsentences=32, sample_size=1088.2, sample_size_v1=0, sample_size_v2=0, ppl=2.25, wps=575.8, ups=0.53, wpb=1088.2, bsz=32, num_updates=6550, lr=2.78914e-05, gnorm=2.043, clip=100, loss_scale=256, train_wall=19, gb_free=11.8, wall=12300
2023-05-26 02:48:24 - progress_bar.py[line:272] - INFO: epoch 004:   1373 / 1732 loss=2.42, loss_v1=0, loss_v2=0, nll_loss=1.224, ntokens=1114.2, nsentences=32, sample_size=1114.2, sample_size_v1=0, sample_size_v2=0, ppl=2.34, wps=593, ups=0.53, wpb=1114.2, bsz=32, num_updates=6560, lr=2.78853e-05, gnorm=1.985, clip=100, loss_scale=256, train_wall=19, gb_free=11.3, wall=12318
2023-05-26 02:48:43 - progress_bar.py[line:272] - INFO: epoch 004:   1383 / 1732 loss=2.41, loss_v1=0, loss_v2=0, nll_loss=1.214, ntokens=1148.9, nsentences=32, sample_size=1148.9, sample_size_v1=0, sample_size_v2=0, ppl=2.32, wps=609.8, ups=0.53, wpb=1148.9, bsz=32, num_updates=6570, lr=2.78791e-05, gnorm=1.844, clip=100, loss_scale=256, train_wall=19, gb_free=11.5, wall=12337
2023-05-26 02:49:01 - progress_bar.py[line:272] - INFO: epoch 004:   1393 / 1732 loss=2.406, loss_v1=0, loss_v2=0, nll_loss=1.21, ntokens=1033.6, nsentences=32, sample_size=1033.6, sample_size_v1=0, sample_size_v2=0, ppl=2.31, wps=554, ups=0.54, wpb=1033.6, bsz=32, num_updates=6580, lr=2.7873e-05, gnorm=2.042, clip=100, loss_scale=256, train_wall=19, gb_free=11, wall=12356
2023-05-26 02:49:20 - progress_bar.py[line:272] - INFO: epoch 004:   1403 / 1732 loss=2.395, loss_v1=0, loss_v2=0, nll_loss=1.195, ntokens=1148.6, nsentences=32, sample_size=1148.6, sample_size_v1=0, sample_size_v2=0, ppl=2.29, wps=609.4, ups=0.53, wpb=1148.6, bsz=32, num_updates=6590, lr=2.78668e-05, gnorm=1.949, clip=100, loss_scale=256, train_wall=19, gb_free=11.4, wall=12375
2023-05-26 02:49:39 - progress_bar.py[line:272] - INFO: epoch 004:   1413 / 1732 loss=2.423, loss_v1=0, loss_v2=0, nll_loss=1.23, ntokens=1251.8, nsentences=32, sample_size=1251.8, sample_size_v1=0, sample_size_v2=0, ppl=2.35, wps=661.7, ups=0.53, wpb=1251.8, bsz=32, num_updates=6600, lr=2.78607e-05, gnorm=1.907, clip=100, loss_scale=256, train_wall=19, gb_free=11.1, wall=12394
2023-05-26 02:49:58 - progress_bar.py[line:272] - INFO: epoch 004:   1423 / 1732 loss=2.392, loss_v1=0, loss_v2=0, nll_loss=1.192, ntokens=1276.2, nsentences=32, sample_size=1276.2, sample_size_v1=0, sample_size_v2=0, ppl=2.29, wps=666, ups=0.52, wpb=1276.2, bsz=32, num_updates=6610, lr=2.78546e-05, gnorm=1.811, clip=100, loss_scale=256, train_wall=19, gb_free=11.2, wall=12413
2023-05-26 02:50:08 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 256.0
2023-05-26 02:50:19 - progress_bar.py[line:272] - INFO: epoch 004:   1434 / 1732 loss=2.381, loss_v1=0, loss_v2=0, nll_loss=1.184, ntokens=1194.5, nsentences=32, sample_size=1194.5, sample_size_v1=0, sample_size_v2=0, ppl=2.27, wps=577.4, ups=0.48, wpb=1194.5, bsz=32, num_updates=6620, lr=2.78484e-05, gnorm=1.88, clip=100, loss_scale=256, train_wall=21, gb_free=11.1, wall=12434
2023-05-26 02:50:38 - progress_bar.py[line:272] - INFO: epoch 004:   1444 / 1732 loss=2.407, loss_v1=0, loss_v2=0, nll_loss=1.209, ntokens=1129.1, nsentences=32, sample_size=1129.1, sample_size_v1=0, sample_size_v2=0, ppl=2.31, wps=598.1, ups=0.53, wpb=1129.1, bsz=32, num_updates=6630, lr=2.78423e-05, gnorm=2.052, clip=100, loss_scale=256, train_wall=19, gb_free=10.6, wall=12452
2023-05-26 02:50:57 - progress_bar.py[line:272] - INFO: epoch 004:   1454 / 1732 loss=2.412, loss_v1=0, loss_v2=0, nll_loss=1.214, ntokens=1122, nsentences=32, sample_size=1122, sample_size_v1=0, sample_size_v2=0, ppl=2.32, wps=597.4, ups=0.53, wpb=1122, bsz=32, num_updates=6640, lr=2.78361e-05, gnorm=1.824, clip=100, loss_scale=256, train_wall=19, gb_free=10.8, wall=12471
2023-05-26 02:51:16 - progress_bar.py[line:272] - INFO: epoch 004:   1464 / 1732 loss=2.367, loss_v1=0, loss_v2=0, nll_loss=1.165, ntokens=1182.3, nsentences=32, sample_size=1182.3, sample_size_v1=0, sample_size_v2=0, ppl=2.24, wps=622.9, ups=0.53, wpb=1182.3, bsz=32, num_updates=6650, lr=2.783e-05, gnorm=1.977, clip=100, loss_scale=256, train_wall=19, gb_free=11.2, wall=12490
2023-05-26 02:51:34 - progress_bar.py[line:272] - INFO: epoch 004:   1474 / 1732 loss=2.399, loss_v1=0, loss_v2=0, nll_loss=1.203, ntokens=1095.3, nsentences=32, sample_size=1095.3, sample_size_v1=0, sample_size_v2=0, ppl=2.3, wps=582.7, ups=0.53, wpb=1095.3, bsz=32, num_updates=6660, lr=2.78238e-05, gnorm=2.23, clip=100, loss_scale=256, train_wall=19, gb_free=11.3, wall=12509
2023-05-26 02:51:53 - progress_bar.py[line:272] - INFO: epoch 004:   1484 / 1732 loss=2.427, loss_v1=0, loss_v2=0, nll_loss=1.229, ntokens=1096.5, nsentences=32, sample_size=1096.5, sample_size_v1=0, sample_size_v2=0, ppl=2.34, wps=583.2, ups=0.53, wpb=1096.5, bsz=32, num_updates=6670, lr=2.78177e-05, gnorm=2.085, clip=100, loss_scale=256, train_wall=19, gb_free=10.6, wall=12528
2023-05-26 02:52:12 - progress_bar.py[line:272] - INFO: epoch 004:   1494 / 1732 loss=2.396, loss_v1=0, loss_v2=0, nll_loss=1.2, ntokens=1106.4, nsentences=32, sample_size=1106.4, sample_size_v1=0, sample_size_v2=0, ppl=2.3, wps=585.2, ups=0.53, wpb=1106.4, bsz=32, num_updates=6680, lr=2.78116e-05, gnorm=1.936, clip=100, loss_scale=256, train_wall=19, gb_free=11, wall=12547
2023-05-26 02:52:31 - progress_bar.py[line:272] - INFO: epoch 004:   1504 / 1732 loss=2.348, loss_v1=0, loss_v2=0, nll_loss=1.144, ntokens=1153.1, nsentences=32, sample_size=1153.1, sample_size_v1=0, sample_size_v2=0, ppl=2.21, wps=611.2, ups=0.53, wpb=1153.1, bsz=32, num_updates=6690, lr=2.78054e-05, gnorm=2.089, clip=100, loss_scale=256, train_wall=19, gb_free=10.9, wall=12566
2023-05-26 02:52:50 - progress_bar.py[line:272] - INFO: epoch 004:   1514 / 1732 loss=2.406, loss_v1=0, loss_v2=0, nll_loss=1.209, ntokens=1041.2, nsentences=32, sample_size=1041.2, sample_size_v1=0, sample_size_v2=0, ppl=2.31, wps=557.8, ups=0.54, wpb=1041.2, bsz=32, num_updates=6700, lr=2.77993e-05, gnorm=2.144, clip=100, loss_scale=256, train_wall=19, gb_free=11.7, wall=12584
2023-05-26 02:53:08 - progress_bar.py[line:272] - INFO: epoch 004:   1524 / 1732 loss=2.437, loss_v1=0, loss_v2=0, nll_loss=1.244, ntokens=1034.8, nsentences=32, sample_size=1034.8, sample_size_v1=0, sample_size_v2=0, ppl=2.37, wps=554.2, ups=0.54, wpb=1034.8, bsz=32, num_updates=6710, lr=2.77931e-05, gnorm=2.174, clip=100, loss_scale=256, train_wall=19, gb_free=10.5, wall=12603
2023-05-26 02:53:27 - progress_bar.py[line:272] - INFO: epoch 004:   1534 / 1732 loss=2.403, loss_v1=0, loss_v2=0, nll_loss=1.203, ntokens=1092.4, nsentences=32, sample_size=1092.4, sample_size_v1=0, sample_size_v2=0, ppl=2.3, wps=576.9, ups=0.53, wpb=1092.4, bsz=32, num_updates=6720, lr=2.7787e-05, gnorm=2.058, clip=100, loss_scale=256, train_wall=19, gb_free=11, wall=12622
2023-05-26 02:53:46 - progress_bar.py[line:272] - INFO: epoch 004:   1544 / 1732 loss=2.389, loss_v1=0, loss_v2=0, nll_loss=1.191, ntokens=1091.8, nsentences=32, sample_size=1091.8, sample_size_v1=0, sample_size_v2=0, ppl=2.28, wps=579.6, ups=0.53, wpb=1091.8, bsz=32, num_updates=6730, lr=2.77808e-05, gnorm=1.947, clip=100, loss_scale=256, train_wall=19, gb_free=11.5, wall=12641
2023-05-26 02:54:05 - progress_bar.py[line:272] - INFO: epoch 004:   1554 / 1732 loss=2.379, loss_v1=0, loss_v2=0, nll_loss=1.18, ntokens=1040, nsentences=32, sample_size=1040, sample_size_v1=0, sample_size_v2=0, ppl=2.27, wps=555.2, ups=0.53, wpb=1040, bsz=32, num_updates=6740, lr=2.77747e-05, gnorm=2.126, clip=100, loss_scale=256, train_wall=19, gb_free=11.4, wall=12659
2023-05-26 02:54:24 - progress_bar.py[line:272] - INFO: epoch 004:   1564 / 1732 loss=2.414, loss_v1=0, loss_v2=0, nll_loss=1.218, ntokens=1120.2, nsentences=32, sample_size=1120.2, sample_size_v1=0, sample_size_v2=0, ppl=2.33, wps=595.7, ups=0.53, wpb=1120.2, bsz=32, num_updates=6750, lr=2.77686e-05, gnorm=1.919, clip=100, loss_scale=256, train_wall=19, gb_free=11.6, wall=12678
2023-05-26 02:54:42 - progress_bar.py[line:272] - INFO: epoch 004:   1574 / 1732 loss=2.422, loss_v1=0, loss_v2=0, nll_loss=1.228, ntokens=1055.9, nsentences=32, sample_size=1055.9, sample_size_v1=0, sample_size_v2=0, ppl=2.34, wps=559.7, ups=0.53, wpb=1055.9, bsz=32, num_updates=6760, lr=2.77624e-05, gnorm=2.24, clip=100, loss_scale=256, train_wall=19, gb_free=11.2, wall=12697
2023-05-26 02:55:01 - progress_bar.py[line:272] - INFO: epoch 004:   1584 / 1732 loss=2.424, loss_v1=0, loss_v2=0, nll_loss=1.231, ntokens=1026.8, nsentences=32, sample_size=1026.8, sample_size_v1=0, sample_size_v2=0, ppl=2.35, wps=546.9, ups=0.53, wpb=1026.8, bsz=32, num_updates=6770, lr=2.77563e-05, gnorm=2.218, clip=100, loss_scale=256, train_wall=19, gb_free=10.8, wall=12716
2023-05-26 02:55:20 - progress_bar.py[line:272] - INFO: epoch 004:   1594 / 1732 loss=2.381, loss_v1=0, loss_v2=0, nll_loss=1.18, ntokens=1068.7, nsentences=32, sample_size=1068.7, sample_size_v1=0, sample_size_v2=0, ppl=2.27, wps=567.8, ups=0.53, wpb=1068.7, bsz=32, num_updates=6780, lr=2.77501e-05, gnorm=2.059, clip=100, loss_scale=256, train_wall=19, gb_free=11.3, wall=12735
2023-05-26 02:55:39 - progress_bar.py[line:272] - INFO: epoch 004:   1604 / 1732 loss=2.38, loss_v1=0, loss_v2=0, nll_loss=1.181, ntokens=1089, nsentences=32, sample_size=1089, sample_size_v1=0, sample_size_v2=0, ppl=2.27, wps=579.4, ups=0.53, wpb=1089, bsz=32, num_updates=6790, lr=2.7744e-05, gnorm=1.96, clip=100, loss_scale=256, train_wall=19, gb_free=10.8, wall=12754
2023-05-26 02:55:58 - progress_bar.py[line:272] - INFO: epoch 004:   1614 / 1732 loss=2.358, loss_v1=0, loss_v2=0, nll_loss=1.154, ntokens=1186.1, nsentences=32, sample_size=1186.1, sample_size_v1=0, sample_size_v2=0, ppl=2.23, wps=622.8, ups=0.53, wpb=1186.1, bsz=32, num_updates=6800, lr=2.77379e-05, gnorm=1.9, clip=100, loss_scale=256, train_wall=19, gb_free=10.9, wall=12773
2023-05-26 02:56:17 - progress_bar.py[line:272] - INFO: epoch 004:   1624 / 1732 loss=2.392, loss_v1=0, loss_v2=0, nll_loss=1.194, ntokens=1074.1, nsentences=32, sample_size=1074.1, sample_size_v1=0, sample_size_v2=0, ppl=2.29, wps=571.1, ups=0.53, wpb=1074.1, bsz=32, num_updates=6810, lr=2.77317e-05, gnorm=2.018, clip=100, loss_scale=256, train_wall=19, gb_free=11.6, wall=12791
2023-05-26 02:56:36 - progress_bar.py[line:272] - INFO: epoch 004:   1634 / 1732 loss=2.367, loss_v1=0, loss_v2=0, nll_loss=1.164, ntokens=1178.9, nsentences=32, sample_size=1178.9, sample_size_v1=0, sample_size_v2=0, ppl=2.24, wps=623.5, ups=0.53, wpb=1178.9, bsz=32, num_updates=6820, lr=2.77256e-05, gnorm=2.005, clip=100, loss_scale=256, train_wall=19, gb_free=11.5, wall=12810
2023-05-26 02:56:55 - progress_bar.py[line:272] - INFO: epoch 004:   1644 / 1732 loss=2.342, loss_v1=0, loss_v2=0, nll_loss=1.138, ntokens=1265.1, nsentences=32, sample_size=1265.1, sample_size_v1=0, sample_size_v2=0, ppl=2.2, wps=664.1, ups=0.52, wpb=1265.1, bsz=32, num_updates=6830, lr=2.77194e-05, gnorm=1.713, clip=100, loss_scale=256, train_wall=19, gb_free=10.9, wall=12829
2023-05-26 02:57:13 - progress_bar.py[line:272] - INFO: epoch 004:   1654 / 1732 loss=2.416, loss_v1=0, loss_v2=0, nll_loss=1.222, ntokens=974.9, nsentences=32, sample_size=974.9, sample_size_v1=0, sample_size_v2=0, ppl=2.33, wps=522.4, ups=0.54, wpb=974.9, bsz=32, num_updates=6840, lr=2.77133e-05, gnorm=2.423, clip=100, loss_scale=256, train_wall=19, gb_free=11.5, wall=12848
2023-05-26 02:57:32 - progress_bar.py[line:272] - INFO: epoch 004:   1664 / 1732 loss=2.412, loss_v1=0, loss_v2=0, nll_loss=1.212, ntokens=1041.8, nsentences=32, sample_size=1041.8, sample_size_v1=0, sample_size_v2=0, ppl=2.32, wps=552.9, ups=0.53, wpb=1041.8, bsz=32, num_updates=6850, lr=2.77071e-05, gnorm=2.122, clip=100, loss_scale=256, train_wall=19, gb_free=11.1, wall=12867
2023-05-26 02:57:51 - progress_bar.py[line:272] - INFO: epoch 004:   1674 / 1732 loss=2.362, loss_v1=0, loss_v2=0, nll_loss=1.163, ntokens=1052.3, nsentences=32, sample_size=1052.3, sample_size_v1=0, sample_size_v2=0, ppl=2.24, wps=562.7, ups=0.53, wpb=1052.3, bsz=32, num_updates=6860, lr=2.7701e-05, gnorm=2.162, clip=100, loss_scale=256, train_wall=19, gb_free=11.3, wall=12886
2023-05-26 02:58:10 - progress_bar.py[line:272] - INFO: epoch 004:   1684 / 1732 loss=2.345, loss_v1=0, loss_v2=0, nll_loss=1.142, ntokens=1169.1, nsentences=32, sample_size=1169.1, sample_size_v1=0, sample_size_v2=0, ppl=2.21, wps=614.3, ups=0.53, wpb=1169.1, bsz=32, num_updates=6870, lr=2.76949e-05, gnorm=1.948, clip=100, loss_scale=256, train_wall=19, gb_free=11.5, wall=12905
2023-05-26 02:58:29 - progress_bar.py[line:272] - INFO: epoch 004:   1694 / 1732 loss=2.374, loss_v1=0, loss_v2=0, nll_loss=1.174, ntokens=1257.3, nsentences=32, sample_size=1257.3, sample_size_v1=0, sample_size_v2=0, ppl=2.26, wps=654.3, ups=0.52, wpb=1257.3, bsz=32, num_updates=6880, lr=2.76887e-05, gnorm=1.832, clip=100, loss_scale=256, train_wall=19, gb_free=10.1, wall=12924
2023-05-26 02:58:48 - progress_bar.py[line:272] - INFO: epoch 004:   1704 / 1732 loss=2.375, loss_v1=0, loss_v2=0, nll_loss=1.175, ntokens=1232.6, nsentences=32, sample_size=1232.6, sample_size_v1=0, sample_size_v2=0, ppl=2.26, wps=641.8, ups=0.52, wpb=1232.6, bsz=32, num_updates=6890, lr=2.76826e-05, gnorm=1.867, clip=100, loss_scale=256, train_wall=19, gb_free=11.3, wall=12943
2023-05-26 02:59:07 - progress_bar.py[line:272] - INFO: epoch 004:   1714 / 1732 loss=2.384, loss_v1=0, loss_v2=0, nll_loss=1.184, ntokens=1181.2, nsentences=32, sample_size=1181.2, sample_size_v1=0, sample_size_v2=0, ppl=2.27, wps=623.8, ups=0.53, wpb=1181.2, bsz=32, num_updates=6900, lr=2.76764e-05, gnorm=1.986, clip=100, loss_scale=256, train_wall=19, gb_free=11.2, wall=12962
2023-05-26 02:59:26 - progress_bar.py[line:272] - INFO: epoch 004:   1724 / 1732 loss=2.388, loss_v1=0, loss_v2=0, nll_loss=1.19, ntokens=1135.1, nsentences=32, sample_size=1135.1, sample_size_v1=0, sample_size_v2=0, ppl=2.28, wps=597.7, ups=0.53, wpb=1135.1, bsz=32, num_updates=6910, lr=2.76703e-05, gnorm=1.963, clip=100, loss_scale=256, train_wall=19, gb_free=11.7, wall=12981
2023-05-26 02:59:40 - checkpoint_utils.py[line:64] - INFO: Preparing to save checkpoint for epoch 4 @ 6918 updates
2023-05-26 02:59:40 - trainer.py[line:431] - INFO: Saving checkpoint to ../../checkpoints/OFA/sgcls_checkpoints/_30_3e-5_512_base_nosrcbbox/checkpoint4.pt
2023-05-26 02:59:43 - trainer.py[line:441] - INFO: Finished saving checkpoint to ../../checkpoints/OFA/sgcls_checkpoints/_30_3e-5_512_base_nosrcbbox/checkpoint4.pt
2023-05-26 02:59:44 - checkpoint_utils.py[line:133] - INFO: Saved checkpoint ../../checkpoints/OFA/sgcls_checkpoints/_30_3e-5_512_base_nosrcbbox/checkpoint4.pt (epoch 4 @ 6918 updates, score None) (writing took 4.355654021026567 seconds)
2023-05-26 02:59:44 - train.py[line:332] - INFO: end of epoch 4 (average epoch stats below)
2023-05-26 02:59:44 - progress_bar.py[line:282] - INFO: epoch 004 | loss 2.41 | loss_v1 0 | loss_v2 0 | nll_loss 1.214 | ntokens 1051.49 | nsentences 31.986 | sample_size 1051.49 | sample_size_v1 0 | sample_size_v2 0 | ppl 2.32 | wps 559.7 | ups 0.53 | wpb 1051.5 | bsz 32 | num_updates 6918 | lr 2.76654e-05 | gnorm 1.987 | clip 99.9 | loss_scale 256 | train_wall 3236 | gb_free 11.7 | wall 12999
2023-05-26 02:59:44 - trainer.py[line:639] - INFO: loading train data for epoch 5
local datafile ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 0 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 0 finished initializing row_count and line_idx-to-offset mapping
file ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 0 row count 55400 total row count 55400
slice_id 0 seek offset 0
2023-05-26 02:59:46 - trainer.py[line:703] - INFO: begin training epoch 5
2023-05-26 02:59:46 - train.py[line:305] - INFO: Start iterating over samples
2023-05-26 02:59:51 - progress_bar.py[line:272] - INFO: epoch 005:      2 / 1732 loss=2.432, loss_v1=0, loss_v2=0, nll_loss=1.237, ntokens=1104.4, nsentences=29.6, sample_size=1104.4, sample_size_v1=0, sample_size_v2=0, ppl=2.36, wps=453.7, ups=0.41, wpb=1104.4, bsz=29.6, num_updates=6920, lr=2.76641e-05, gnorm=2.217, clip=100, loss_scale=256, train_wall=18, gb_free=10.9, wall=13005
2023-05-26 03:00:10 - progress_bar.py[line:272] - INFO: epoch 005:     12 / 1732 loss=2.322, loss_v1=0, loss_v2=0, nll_loss=1.115, ntokens=1057.9, nsentences=32, sample_size=1057.9, sample_size_v1=0, sample_size_v2=0, ppl=2.17, wps=559.9, ups=0.53, wpb=1057.9, bsz=32, num_updates=6930, lr=2.7658e-05, gnorm=2.103, clip=100, loss_scale=256, train_wall=19, gb_free=11.6, wall=13024
2023-05-26 03:00:28 - progress_bar.py[line:272] - INFO: epoch 005:     22 / 1732 loss=2.269, loss_v1=0, loss_v2=0, nll_loss=1.056, ntokens=1106.7, nsentences=32, sample_size=1106.7, sample_size_v1=0, sample_size_v2=0, ppl=2.08, wps=586.3, ups=0.53, wpb=1106.7, bsz=32, num_updates=6940, lr=2.76519e-05, gnorm=1.711, clip=100, loss_scale=256, train_wall=19, gb_free=11.4, wall=13043
2023-05-26 03:00:47 - progress_bar.py[line:272] - INFO: epoch 005:     32 / 1732 loss=2.32, loss_v1=0, loss_v2=0, nll_loss=1.111, ntokens=985.4, nsentences=32, sample_size=985.4, sample_size_v1=0, sample_size_v2=0, ppl=2.16, wps=522.7, ups=0.53, wpb=985.4, bsz=32, num_updates=6950, lr=2.76457e-05, gnorm=2.277, clip=100, loss_scale=256, train_wall=19, gb_free=10.5, wall=13062
2023-05-26 03:01:06 - progress_bar.py[line:272] - INFO: epoch 005:     42 / 1732 loss=2.175, loss_v1=0, loss_v2=0, nll_loss=0.954, ntokens=1168.8, nsentences=32, sample_size=1168.8, sample_size_v1=0, sample_size_v2=0, ppl=1.94, wps=615.3, ups=0.53, wpb=1168.8, bsz=32, num_updates=6960, lr=2.76396e-05, gnorm=1.726, clip=100, loss_scale=256, train_wall=19, gb_free=11.9, wall=13081
2023-05-26 03:01:25 - progress_bar.py[line:272] - INFO: epoch 005:     52 / 1732 loss=2.249, loss_v1=0, loss_v2=0, nll_loss=1.035, ntokens=1030.1, nsentences=32, sample_size=1030.1, sample_size_v1=0, sample_size_v2=0, ppl=2.05, wps=545.1, ups=0.53, wpb=1030.1, bsz=32, num_updates=6970, lr=2.76334e-05, gnorm=2.168, clip=100, loss_scale=256, train_wall=19, gb_free=11.7, wall=13100
2023-05-26 03:01:44 - progress_bar.py[line:272] - INFO: epoch 005:     62 / 1732 loss=2.047, loss_v1=0, loss_v2=0, nll_loss=0.808, ntokens=1192.6, nsentences=32, sample_size=1192.6, sample_size_v1=0, sample_size_v2=0, ppl=1.75, wps=629.3, ups=0.53, wpb=1192.6, bsz=32, num_updates=6980, lr=2.76273e-05, gnorm=1.542, clip=100, loss_scale=256, train_wall=19, gb_free=10.7, wall=13119
2023-05-26 03:02:04 - progress_bar.py[line:272] - INFO: epoch 005:     72 / 1732 loss=2.145, loss_v1=0, loss_v2=0, nll_loss=0.916, ntokens=1389.6, nsentences=32, sample_size=1389.6, sample_size_v1=0, sample_size_v2=0, ppl=1.89, wps=714.5, ups=0.51, wpb=1389.6, bsz=32, num_updates=6990, lr=2.76212e-05, gnorm=1.408, clip=100, loss_scale=256, train_wall=19, gb_free=10.7, wall=13138
2023-05-26 03:02:23 - progress_bar.py[line:272] - INFO: epoch 005:     82 / 1732 loss=2.188, loss_v1=0, loss_v2=0, nll_loss=0.969, ntokens=1199, nsentences=32, sample_size=1199, sample_size_v1=0, sample_size_v2=0, ppl=1.96, wps=621.4, ups=0.52, wpb=1199, bsz=32, num_updates=7000, lr=2.7615e-05, gnorm=1.676, clip=100, loss_scale=256, train_wall=19, gb_free=10.8, wall=13158
2023-05-26 03:02:42 - progress_bar.py[line:272] - INFO: epoch 005:     92 / 1732 loss=2.211, loss_v1=0, loss_v2=0, nll_loss=0.988, ntokens=1081.9, nsentences=32, sample_size=1081.9, sample_size_v1=0, sample_size_v2=0, ppl=1.98, wps=567.6, ups=0.52, wpb=1081.9, bsz=32, num_updates=7010, lr=2.76089e-05, gnorm=1.561, clip=100, loss_scale=256, train_wall=19, gb_free=11.1, wall=13177
2023-05-26 03:03:01 - progress_bar.py[line:272] - INFO: epoch 005:    102 / 1732 loss=2.305, loss_v1=0, loss_v2=0, nll_loss=1.102, ntokens=1017.7, nsentences=32, sample_size=1017.7, sample_size_v1=0, sample_size_v2=0, ppl=2.15, wps=543.3, ups=0.53, wpb=1017.7, bsz=32, num_updates=7020, lr=2.76027e-05, gnorm=2.076, clip=100, loss_scale=256, train_wall=19, gb_free=11, wall=13195
2023-05-26 03:03:20 - progress_bar.py[line:272] - INFO: epoch 005:    112 / 1732 loss=2.419, loss_v1=0, loss_v2=0, nll_loss=1.222, ntokens=1026.3, nsentences=32, sample_size=1026.3, sample_size_v1=0, sample_size_v2=0, ppl=2.33, wps=544.2, ups=0.53, wpb=1026.3, bsz=32, num_updates=7030, lr=2.75966e-05, gnorm=2.008, clip=100, loss_scale=256, train_wall=19, gb_free=10.2, wall=13214
2023-05-26 03:03:39 - progress_bar.py[line:272] - INFO: epoch 005:    122 / 1732 loss=2.377, loss_v1=0, loss_v2=0, nll_loss=1.178, ntokens=1103.7, nsentences=32, sample_size=1103.7, sample_size_v1=0, sample_size_v2=0, ppl=2.26, wps=576.7, ups=0.52, wpb=1103.7, bsz=32, num_updates=7040, lr=2.75904e-05, gnorm=1.851, clip=100, loss_scale=256, train_wall=19, gb_free=10.8, wall=13233
2023-05-26 03:03:58 - progress_bar.py[line:272] - INFO: epoch 005:    132 / 1732 loss=2.322, loss_v1=0, loss_v2=0, nll_loss=1.112, ntokens=1224.5, nsentences=32, sample_size=1224.5, sample_size_v1=0, sample_size_v2=0, ppl=2.16, wps=637, ups=0.52, wpb=1224.5, bsz=32, num_updates=7050, lr=2.75843e-05, gnorm=1.608, clip=100, loss_scale=256, train_wall=19, gb_free=10.7, wall=13253
2023-05-26 03:04:17 - progress_bar.py[line:272] - INFO: epoch 005:    142 / 1732 loss=2.299, loss_v1=0, loss_v2=0, nll_loss=1.092, ntokens=1223.2, nsentences=32, sample_size=1223.2, sample_size_v1=0, sample_size_v2=0, ppl=2.13, wps=637.6, ups=0.52, wpb=1223.2, bsz=32, num_updates=7060, lr=2.75782e-05, gnorm=1.563, clip=100, loss_scale=256, train_wall=19, gb_free=10.8, wall=13272
2023-05-26 03:04:36 - progress_bar.py[line:272] - INFO: epoch 005:    152 / 1732 loss=2.303, loss_v1=0, loss_v2=0, nll_loss=1.095, ntokens=1158.5, nsentences=32, sample_size=1158.5, sample_size_v1=0, sample_size_v2=0, ppl=2.14, wps=603.4, ups=0.52, wpb=1158.5, bsz=32, num_updates=7070, lr=2.7572e-05, gnorm=1.584, clip=100, loss_scale=256, train_wall=19, gb_free=10.7, wall=13291
2023-05-26 03:04:55 - progress_bar.py[line:272] - INFO: epoch 005:    162 / 1732 loss=2.301, loss_v1=0, loss_v2=0, nll_loss=1.093, ntokens=1101.3, nsentences=32, sample_size=1101.3, sample_size_v1=0, sample_size_v2=0, ppl=2.13, wps=577.9, ups=0.52, wpb=1101.3, bsz=32, num_updates=7080, lr=2.75659e-05, gnorm=1.857, clip=100, loss_scale=256, train_wall=19, gb_free=11, wall=13310
2023-05-26 03:05:14 - progress_bar.py[line:272] - INFO: epoch 005:    172 / 1732 loss=2.328, loss_v1=0, loss_v2=0, nll_loss=1.121, ntokens=937.9, nsentences=32, sample_size=937.9, sample_size_v1=0, sample_size_v2=0, ppl=2.17, wps=499.1, ups=0.53, wpb=937.9, bsz=32, num_updates=7090, lr=2.75597e-05, gnorm=2.002, clip=100, loss_scale=256, train_wall=19, gb_free=11.2, wall=13329
2023-05-26 03:05:33 - progress_bar.py[line:272] - INFO: epoch 005:    182 / 1732 loss=2.265, loss_v1=0, loss_v2=0, nll_loss=1.053, ntokens=1177.8, nsentences=32, sample_size=1177.8, sample_size_v1=0, sample_size_v2=0, ppl=2.07, wps=615.5, ups=0.52, wpb=1177.8, bsz=32, num_updates=7100, lr=2.75536e-05, gnorm=1.746, clip=100, loss_scale=256, train_wall=19, gb_free=10.6, wall=13348
2023-05-26 03:05:52 - progress_bar.py[line:272] - INFO: epoch 005:    192 / 1732 loss=2.282, loss_v1=0, loss_v2=0, nll_loss=1.07, ntokens=1116, nsentences=32, sample_size=1116, sample_size_v1=0, sample_size_v2=0, ppl=2.1, wps=587.1, ups=0.53, wpb=1116, bsz=32, num_updates=7110, lr=2.75474e-05, gnorm=1.761, clip=100, loss_scale=256, train_wall=19, gb_free=10.6, wall=13367
2023-05-26 03:06:11 - progress_bar.py[line:272] - INFO: epoch 005:    202 / 1732 loss=2.37, loss_v1=0, loss_v2=0, nll_loss=1.171, ntokens=1088.7, nsentences=32, sample_size=1088.7, sample_size_v1=0, sample_size_v2=0, ppl=2.25, wps=577.3, ups=0.53, wpb=1088.7, bsz=32, num_updates=7120, lr=2.75413e-05, gnorm=1.912, clip=100, loss_scale=256, train_wall=19, gb_free=10.7, wall=13386
2023-05-26 03:06:30 - progress_bar.py[line:272] - INFO: epoch 005:    212 / 1732 loss=2.416, loss_v1=0, loss_v2=0, nll_loss=1.219, ntokens=1014.1, nsentences=32, sample_size=1014.1, sample_size_v1=0, sample_size_v2=0, ppl=2.33, wps=542.7, ups=0.54, wpb=1014.1, bsz=32, num_updates=7130, lr=2.75352e-05, gnorm=1.911, clip=100, loss_scale=512, train_wall=19, gb_free=11, wall=13405
2023-05-26 03:06:41 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 256.0
2023-05-26 03:06:50 - progress_bar.py[line:272] - INFO: epoch 005:    223 / 1732 loss=2.413, loss_v1=0, loss_v2=0, nll_loss=1.216, ntokens=1168.8, nsentences=32, sample_size=1168.8, sample_size_v1=0, sample_size_v2=0, ppl=2.32, wps=569.6, ups=0.49, wpb=1168.8, bsz=32, num_updates=7140, lr=2.7529e-05, gnorm=1.838, clip=100, loss_scale=256, train_wall=20, gb_free=11.3, wall=13425
2023-05-26 03:07:09 - progress_bar.py[line:272] - INFO: epoch 005:    233 / 1732 loss=2.458, loss_v1=0, loss_v2=0, nll_loss=1.267, ntokens=1078.6, nsentences=32, sample_size=1078.6, sample_size_v1=0, sample_size_v2=0, ppl=2.41, wps=579, ups=0.54, wpb=1078.6, bsz=32, num_updates=7150, lr=2.75229e-05, gnorm=2.003, clip=100, loss_scale=256, train_wall=19, gb_free=11.5, wall=13444
2023-05-26 03:07:28 - progress_bar.py[line:272] - INFO: epoch 005:    243 / 1732 loss=2.447, loss_v1=0, loss_v2=0, nll_loss=1.257, ntokens=1123.3, nsentences=32, sample_size=1123.3, sample_size_v1=0, sample_size_v2=0, ppl=2.39, wps=596.6, ups=0.53, wpb=1123.3, bsz=32, num_updates=7160, lr=2.75167e-05, gnorm=1.836, clip=100, loss_scale=256, train_wall=19, gb_free=11.5, wall=13463
2023-05-26 03:07:47 - progress_bar.py[line:272] - INFO: epoch 005:    253 / 1732 loss=2.447, loss_v1=0, loss_v2=0, nll_loss=1.255, ntokens=1167.4, nsentences=32, sample_size=1167.4, sample_size_v1=0, sample_size_v2=0, ppl=2.39, wps=621.2, ups=0.53, wpb=1167.4, bsz=32, num_updates=7170, lr=2.75106e-05, gnorm=1.888, clip=100, loss_scale=256, train_wall=19, gb_free=10.8, wall=13481
2023-05-26 03:08:05 - progress_bar.py[line:272] - INFO: epoch 005:    263 / 1732 loss=2.442, loss_v1=0, loss_v2=0, nll_loss=1.249, ntokens=1123.9, nsentences=32, sample_size=1123.9, sample_size_v1=0, sample_size_v2=0, ppl=2.38, wps=600, ups=0.53, wpb=1123.9, bsz=32, num_updates=7180, lr=2.75045e-05, gnorm=1.864, clip=100, loss_scale=256, train_wall=19, gb_free=10.8, wall=13500
2023-05-26 03:08:24 - progress_bar.py[line:272] - INFO: epoch 005:    273 / 1732 loss=2.426, loss_v1=0, loss_v2=0, nll_loss=1.231, ntokens=1154.8, nsentences=32, sample_size=1154.8, sample_size_v1=0, sample_size_v2=0, ppl=2.35, wps=613.9, ups=0.53, wpb=1154.8, bsz=32, num_updates=7190, lr=2.74983e-05, gnorm=1.854, clip=100, loss_scale=256, train_wall=19, gb_free=11, wall=13519
2023-05-26 03:08:43 - progress_bar.py[line:272] - INFO: epoch 005:    283 / 1732 loss=2.447, loss_v1=0, loss_v2=0, nll_loss=1.254, ntokens=1146.7, nsentences=32, sample_size=1146.7, sample_size_v1=0, sample_size_v2=0, ppl=2.39, wps=607.9, ups=0.53, wpb=1146.7, bsz=32, num_updates=7200, lr=2.74922e-05, gnorm=1.886, clip=100, loss_scale=256, train_wall=19, gb_free=11.2, wall=13538
2023-05-26 03:09:02 - progress_bar.py[line:272] - INFO: epoch 005:    293 / 1732 loss=2.41, loss_v1=0, loss_v2=0, nll_loss=1.216, ntokens=1122.6, nsentences=32, sample_size=1122.6, sample_size_v1=0, sample_size_v2=0, ppl=2.32, wps=599.2, ups=0.53, wpb=1122.6, bsz=32, num_updates=7210, lr=2.7486e-05, gnorm=2.045, clip=100, loss_scale=256, train_wall=19, gb_free=10.3, wall=13556
2023-05-26 03:09:21 - progress_bar.py[line:272] - INFO: epoch 005:    303 / 1732 loss=2.412, loss_v1=0, loss_v2=0, nll_loss=1.216, ntokens=1117.4, nsentences=32, sample_size=1117.4, sample_size_v1=0, sample_size_v2=0, ppl=2.32, wps=597.6, ups=0.53, wpb=1117.4, bsz=32, num_updates=7220, lr=2.74799e-05, gnorm=2.016, clip=100, loss_scale=256, train_wall=19, gb_free=11.1, wall=13575
2023-05-26 03:09:39 - progress_bar.py[line:272] - INFO: epoch 005:    313 / 1732 loss=2.423, loss_v1=0, loss_v2=0, nll_loss=1.229, ntokens=1045.5, nsentences=32, sample_size=1045.5, sample_size_v1=0, sample_size_v2=0, ppl=2.34, wps=560.6, ups=0.54, wpb=1045.5, bsz=32, num_updates=7230, lr=2.74737e-05, gnorm=2.035, clip=100, loss_scale=256, train_wall=19, gb_free=11.7, wall=13594
2023-05-26 03:09:58 - progress_bar.py[line:272] - INFO: epoch 005:    323 / 1732 loss=2.452, loss_v1=0, loss_v2=0, nll_loss=1.259, ntokens=1005.7, nsentences=32, sample_size=1005.7, sample_size_v1=0, sample_size_v2=0, ppl=2.39, wps=541.4, ups=0.54, wpb=1005.7, bsz=32, num_updates=7240, lr=2.74676e-05, gnorm=2.037, clip=100, loss_scale=256, train_wall=19, gb_free=11.2, wall=13612
2023-05-26 03:10:16 - progress_bar.py[line:272] - INFO: epoch 005:    333 / 1732 loss=2.437, loss_v1=0, loss_v2=0, nll_loss=1.246, ntokens=1019.2, nsentences=32, sample_size=1019.2, sample_size_v1=0, sample_size_v2=0, ppl=2.37, wps=549, ups=0.54, wpb=1019.2, bsz=32, num_updates=7250, lr=2.74615e-05, gnorm=2.124, clip=100, loss_scale=256, train_wall=19, gb_free=11.3, wall=13631
2023-05-26 03:10:35 - progress_bar.py[line:272] - INFO: epoch 005:    343 / 1732 loss=2.416, loss_v1=0, loss_v2=0, nll_loss=1.222, ntokens=919.2, nsentences=32, sample_size=919.2, sample_size_v1=0, sample_size_v2=0, ppl=2.33, wps=497, ups=0.54, wpb=919.2, bsz=32, num_updates=7260, lr=2.74553e-05, gnorm=2.203, clip=100, loss_scale=256, train_wall=18, gb_free=11.8, wall=13649
2023-05-26 03:10:53 - progress_bar.py[line:272] - INFO: epoch 005:    353 / 1732 loss=2.436, loss_v1=0, loss_v2=0, nll_loss=1.243, ntokens=968.9, nsentences=32, sample_size=968.9, sample_size_v1=0, sample_size_v2=0, ppl=2.37, wps=522.7, ups=0.54, wpb=968.9, bsz=32, num_updates=7270, lr=2.74492e-05, gnorm=2.151, clip=100, loss_scale=256, train_wall=19, gb_free=10.6, wall=13668
2023-05-26 03:11:12 - progress_bar.py[line:272] - INFO: epoch 005:    363 / 1732 loss=2.471, loss_v1=0, loss_v2=0, nll_loss=1.279, ntokens=932.1, nsentences=32, sample_size=932.1, sample_size_v1=0, sample_size_v2=0, ppl=2.43, wps=505.2, ups=0.54, wpb=932.1, bsz=32, num_updates=7280, lr=2.7443e-05, gnorm=2.036, clip=100, loss_scale=256, train_wall=18, gb_free=11.5, wall=13686
2023-05-26 03:11:30 - progress_bar.py[line:272] - INFO: epoch 005:    373 / 1732 loss=2.459, loss_v1=0, loss_v2=0, nll_loss=1.269, ntokens=967.4, nsentences=32, sample_size=967.4, sample_size_v1=0, sample_size_v2=0, ppl=2.41, wps=522.1, ups=0.54, wpb=967.4, bsz=32, num_updates=7290, lr=2.74369e-05, gnorm=2.047, clip=100, loss_scale=256, train_wall=18, gb_free=11.8, wall=13705
2023-05-26 03:11:49 - progress_bar.py[line:272] - INFO: epoch 005:    383 / 1732 loss=2.449, loss_v1=0, loss_v2=0, nll_loss=1.258, ntokens=1070.5, nsentences=32, sample_size=1070.5, sample_size_v1=0, sample_size_v2=0, ppl=2.39, wps=577.3, ups=0.54, wpb=1070.5, bsz=32, num_updates=7300, lr=2.74307e-05, gnorm=2.002, clip=100, loss_scale=256, train_wall=19, gb_free=11.4, wall=13724
2023-05-26 03:12:07 - progress_bar.py[line:272] - INFO: epoch 005:    393 / 1732 loss=2.44, loss_v1=0, loss_v2=0, nll_loss=1.249, ntokens=990.3, nsentences=32, sample_size=990.3, sample_size_v1=0, sample_size_v2=0, ppl=2.38, wps=534.3, ups=0.54, wpb=990.3, bsz=32, num_updates=7310, lr=2.74246e-05, gnorm=2.096, clip=100, loss_scale=256, train_wall=19, gb_free=11.6, wall=13742
2023-05-26 03:12:26 - progress_bar.py[line:272] - INFO: epoch 005:    403 / 1732 loss=2.413, loss_v1=0, loss_v2=0, nll_loss=1.218, ntokens=1045, nsentences=32, sample_size=1045, sample_size_v1=0, sample_size_v2=0, ppl=2.33, wps=561.7, ups=0.54, wpb=1045, bsz=32, num_updates=7320, lr=2.74185e-05, gnorm=1.979, clip=100, loss_scale=256, train_wall=19, gb_free=11.2, wall=13761
2023-05-26 03:12:45 - progress_bar.py[line:272] - INFO: epoch 005:    413 / 1732 loss=2.412, loss_v1=0, loss_v2=0, nll_loss=1.217, ntokens=1078.5, nsentences=32, sample_size=1078.5, sample_size_v1=0, sample_size_v2=0, ppl=2.32, wps=578.9, ups=0.54, wpb=1078.5, bsz=32, num_updates=7330, lr=2.74123e-05, gnorm=1.773, clip=100, loss_scale=256, train_wall=19, gb_free=11.3, wall=13779
2023-05-26 03:13:03 - progress_bar.py[line:272] - INFO: epoch 005:    423 / 1732 loss=2.395, loss_v1=0, loss_v2=0, nll_loss=1.196, ntokens=985.4, nsentences=32, sample_size=985.4, sample_size_v1=0, sample_size_v2=0, ppl=2.29, wps=529.1, ups=0.54, wpb=985.4, bsz=32, num_updates=7340, lr=2.74062e-05, gnorm=1.968, clip=100, loss_scale=256, train_wall=19, gb_free=11.2, wall=13798
2023-05-26 03:13:22 - progress_bar.py[line:272] - INFO: epoch 005:    433 / 1732 loss=2.413, loss_v1=0, loss_v2=0, nll_loss=1.218, ntokens=1024.2, nsentences=32, sample_size=1024.2, sample_size_v1=0, sample_size_v2=0, ppl=2.33, wps=551.2, ups=0.54, wpb=1024.2, bsz=32, num_updates=7350, lr=2.74e-05, gnorm=2.001, clip=100, loss_scale=256, train_wall=19, gb_free=11.6, wall=13817
2023-05-26 03:13:40 - progress_bar.py[line:272] - INFO: epoch 005:    443 / 1732 loss=2.454, loss_v1=0, loss_v2=0, nll_loss=1.264, ntokens=966.7, nsentences=32, sample_size=966.7, sample_size_v1=0, sample_size_v2=0, ppl=2.4, wps=520.8, ups=0.54, wpb=966.7, bsz=32, num_updates=7360, lr=2.73939e-05, gnorm=2.059, clip=100, loss_scale=256, train_wall=19, gb_free=11.7, wall=13835
2023-05-26 03:13:59 - progress_bar.py[line:272] - INFO: epoch 005:    453 / 1732 loss=2.434, loss_v1=0, loss_v2=0, nll_loss=1.241, ntokens=911.8, nsentences=32, sample_size=911.8, sample_size_v1=0, sample_size_v2=0, ppl=2.36, wps=492.7, ups=0.54, wpb=911.8, bsz=32, num_updates=7370, lr=2.73878e-05, gnorm=2.18, clip=100, loss_scale=256, train_wall=18, gb_free=11.6, wall=13854
2023-05-26 03:14:18 - progress_bar.py[line:272] - INFO: epoch 005:    463 / 1732 loss=2.452, loss_v1=0, loss_v2=0, nll_loss=1.259, ntokens=1072.4, nsentences=32, sample_size=1072.4, sample_size_v1=0, sample_size_v2=0, ppl=2.39, wps=576, ups=0.54, wpb=1072.4, bsz=32, num_updates=7380, lr=2.73816e-05, gnorm=1.919, clip=100, loss_scale=256, train_wall=19, gb_free=11.1, wall=13872
2023-05-26 03:14:36 - progress_bar.py[line:272] - INFO: epoch 005:    473 / 1732 loss=2.435, loss_v1=0, loss_v2=0, nll_loss=1.239, ntokens=1059.2, nsentences=32, sample_size=1059.2, sample_size_v1=0, sample_size_v2=0, ppl=2.36, wps=565.1, ups=0.53, wpb=1059.2, bsz=32, num_updates=7390, lr=2.73755e-05, gnorm=2.035, clip=100, loss_scale=256, train_wall=19, gb_free=10.5, wall=13891
2023-05-26 03:14:55 - progress_bar.py[line:272] - INFO: epoch 005:    483 / 1732 loss=2.433, loss_v1=0, loss_v2=0, nll_loss=1.24, ntokens=966.6, nsentences=32, sample_size=966.6, sample_size_v1=0, sample_size_v2=0, ppl=2.36, wps=522.7, ups=0.54, wpb=966.6, bsz=32, num_updates=7400, lr=2.73693e-05, gnorm=2.188, clip=100, loss_scale=256, train_wall=18, gb_free=11.7, wall=13909
2023-05-26 03:15:13 - progress_bar.py[line:272] - INFO: epoch 005:    493 / 1732 loss=2.433, loss_v1=0, loss_v2=0, nll_loss=1.242, ntokens=940.2, nsentences=32, sample_size=940.2, sample_size_v1=0, sample_size_v2=0, ppl=2.37, wps=506.9, ups=0.54, wpb=940.2, bsz=32, num_updates=7410, lr=2.73632e-05, gnorm=2.19, clip=100, loss_scale=256, train_wall=19, gb_free=11.8, wall=13928
2023-05-26 03:15:32 - progress_bar.py[line:272] - INFO: epoch 005:    503 / 1732 loss=2.427, loss_v1=0, loss_v2=0, nll_loss=1.232, ntokens=988.6, nsentences=32, sample_size=988.6, sample_size_v1=0, sample_size_v2=0, ppl=2.35, wps=536.5, ups=0.54, wpb=988.6, bsz=32, num_updates=7420, lr=2.7357e-05, gnorm=2.122, clip=100, loss_scale=256, train_wall=18, gb_free=11.8, wall=13946
2023-05-26 03:15:50 - progress_bar.py[line:272] - INFO: epoch 005:    513 / 1732 loss=2.449, loss_v1=0, loss_v2=0, nll_loss=1.257, ntokens=1035, nsentences=32, sample_size=1035, sample_size_v1=0, sample_size_v2=0, ppl=2.39, wps=558.1, ups=0.54, wpb=1035, bsz=32, num_updates=7430, lr=2.73509e-05, gnorm=2.137, clip=100, loss_scale=256, train_wall=19, gb_free=11.7, wall=13965
2023-05-26 03:16:09 - progress_bar.py[line:272] - INFO: epoch 005:    523 / 1732 loss=2.417, loss_v1=0, loss_v2=0, nll_loss=1.222, ntokens=997.6, nsentences=32, sample_size=997.6, sample_size_v1=0, sample_size_v2=0, ppl=2.33, wps=541.1, ups=0.54, wpb=997.6, bsz=32, num_updates=7440, lr=2.73448e-05, gnorm=2.157, clip=100, loss_scale=256, train_wall=18, gb_free=11.8, wall=13983
2023-05-26 03:16:27 - progress_bar.py[line:272] - INFO: epoch 005:    533 / 1732 loss=2.423, loss_v1=0, loss_v2=0, nll_loss=1.227, ntokens=935, nsentences=32, sample_size=935, sample_size_v1=0, sample_size_v2=0, ppl=2.34, wps=507.7, ups=0.54, wpb=935, bsz=32, num_updates=7450, lr=2.73386e-05, gnorm=2.324, clip=100, loss_scale=256, train_wall=18, gb_free=11.8, wall=14002
2023-05-26 03:16:46 - progress_bar.py[line:272] - INFO: epoch 005:    543 / 1732 loss=2.434, loss_v1=0, loss_v2=0, nll_loss=1.241, ntokens=1003.8, nsentences=32, sample_size=1003.8, sample_size_v1=0, sample_size_v2=0, ppl=2.36, wps=542, ups=0.54, wpb=1003.8, bsz=32, num_updates=7460, lr=2.73325e-05, gnorm=2.013, clip=100, loss_scale=256, train_wall=18, gb_free=11.3, wall=14020
2023-05-26 03:17:04 - progress_bar.py[line:272] - INFO: epoch 005:    553 / 1732 loss=2.463, loss_v1=0, loss_v2=0, nll_loss=1.274, ntokens=1017.4, nsentences=32, sample_size=1017.4, sample_size_v1=0, sample_size_v2=0, ppl=2.42, wps=548.6, ups=0.54, wpb=1017.4, bsz=32, num_updates=7470, lr=2.73263e-05, gnorm=1.981, clip=100, loss_scale=256, train_wall=19, gb_free=11.8, wall=14039
2023-05-26 03:17:23 - progress_bar.py[line:272] - INFO: epoch 005:    563 / 1732 loss=2.453, loss_v1=0, loss_v2=0, nll_loss=1.262, ntokens=1008.2, nsentences=32, sample_size=1008.2, sample_size_v1=0, sample_size_v2=0, ppl=2.4, wps=543.2, ups=0.54, wpb=1008.2, bsz=32, num_updates=7480, lr=2.73202e-05, gnorm=2.221, clip=100, loss_scale=256, train_wall=19, gb_free=12, wall=14058
2023-05-26 03:17:42 - progress_bar.py[line:272] - INFO: epoch 005:    573 / 1732 loss=2.453, loss_v1=0, loss_v2=0, nll_loss=1.262, ntokens=1041.3, nsentences=32, sample_size=1041.3, sample_size_v1=0, sample_size_v2=0, ppl=2.4, wps=556.9, ups=0.53, wpb=1041.3, bsz=32, num_updates=7490, lr=2.7314e-05, gnorm=2.075, clip=100, loss_scale=256, train_wall=19, gb_free=11, wall=14076
2023-05-26 03:18:00 - progress_bar.py[line:272] - INFO: epoch 005:    583 / 1732 loss=2.438, loss_v1=0, loss_v2=0, nll_loss=1.245, ntokens=981.7, nsentences=32, sample_size=981.7, sample_size_v1=0, sample_size_v2=0, ppl=2.37, wps=526.1, ups=0.54, wpb=981.7, bsz=32, num_updates=7500, lr=2.73079e-05, gnorm=2.124, clip=100, loss_scale=256, train_wall=19, gb_free=11.8, wall=14095
2023-05-26 03:18:19 - progress_bar.py[line:272] - INFO: epoch 005:    593 / 1732 loss=2.405, loss_v1=0, loss_v2=0, nll_loss=1.209, ntokens=957.4, nsentences=32, sample_size=957.4, sample_size_v1=0, sample_size_v2=0, ppl=2.31, wps=513.2, ups=0.54, wpb=957.4, bsz=32, num_updates=7510, lr=2.73018e-05, gnorm=2.292, clip=100, loss_scale=256, train_wall=19, gb_free=11.7, wall=14114
2023-05-26 03:18:37 - progress_bar.py[line:272] - INFO: epoch 005:    603 / 1732 loss=2.409, loss_v1=0, loss_v2=0, nll_loss=1.216, ntokens=911.2, nsentences=32, sample_size=911.2, sample_size_v1=0, sample_size_v2=0, ppl=2.32, wps=494.6, ups=0.54, wpb=911.2, bsz=32, num_updates=7520, lr=2.72956e-05, gnorm=2.277, clip=100, loss_scale=256, train_wall=18, gb_free=11.8, wall=14132
2023-05-26 03:18:56 - progress_bar.py[line:272] - INFO: epoch 005:    613 / 1732 loss=2.431, loss_v1=0, loss_v2=0, nll_loss=1.235, ntokens=893.3, nsentences=32, sample_size=893.3, sample_size_v1=0, sample_size_v2=0, ppl=2.35, wps=484.1, ups=0.54, wpb=893.3, bsz=32, num_updates=7530, lr=2.72895e-05, gnorm=2.404, clip=100, loss_scale=256, train_wall=18, gb_free=11.7, wall=14150
2023-05-26 03:19:14 - progress_bar.py[line:272] - INFO: epoch 005:    623 / 1732 loss=2.448, loss_v1=0, loss_v2=0, nll_loss=1.254, ntokens=887.2, nsentences=32, sample_size=887.2, sample_size_v1=0, sample_size_v2=0, ppl=2.39, wps=483.8, ups=0.55, wpb=887.2, bsz=32, num_updates=7540, lr=2.72833e-05, gnorm=2.423, clip=100, loss_scale=256, train_wall=18, gb_free=11.1, wall=14169
2023-05-26 03:19:33 - progress_bar.py[line:272] - INFO: epoch 005:    633 / 1732 loss=2.43, loss_v1=0, loss_v2=0, nll_loss=1.239, ntokens=925, nsentences=32, sample_size=925, sample_size_v1=0, sample_size_v2=0, ppl=2.36, wps=501.9, ups=0.54, wpb=925, bsz=32, num_updates=7550, lr=2.72772e-05, gnorm=2.443, clip=100, loss_scale=256, train_wall=18, gb_free=11.6, wall=14187
2023-05-26 03:19:51 - progress_bar.py[line:272] - INFO: epoch 005:    643 / 1732 loss=2.444, loss_v1=0, loss_v2=0, nll_loss=1.247, ntokens=963.8, nsentences=32, sample_size=963.8, sample_size_v1=0, sample_size_v2=0, ppl=2.37, wps=523.1, ups=0.54, wpb=963.8, bsz=32, num_updates=7560, lr=2.72711e-05, gnorm=2.219, clip=100, loss_scale=256, train_wall=18, gb_free=11.8, wall=14206
2023-05-26 03:20:09 - progress_bar.py[line:272] - INFO: epoch 005:    653 / 1732 loss=2.447, loss_v1=0, loss_v2=0, nll_loss=1.257, ntokens=928, nsentences=32, sample_size=928, sample_size_v1=0, sample_size_v2=0, ppl=2.39, wps=507, ups=0.55, wpb=928, bsz=32, num_updates=7570, lr=2.72649e-05, gnorm=2.368, clip=100, loss_scale=256, train_wall=18, gb_free=11.9, wall=14224
2023-05-26 03:20:28 - progress_bar.py[line:272] - INFO: epoch 005:    663 / 1732 loss=2.442, loss_v1=0, loss_v2=0, nll_loss=1.251, ntokens=882.9, nsentences=32, sample_size=882.9, sample_size_v1=0, sample_size_v2=0, ppl=2.38, wps=480.7, ups=0.54, wpb=882.9, bsz=32, num_updates=7580, lr=2.72588e-05, gnorm=2.505, clip=100, loss_scale=256, train_wall=18, gb_free=11.5, wall=14242
2023-05-26 03:20:46 - progress_bar.py[line:272] - INFO: epoch 005:    673 / 1732 loss=2.456, loss_v1=0, loss_v2=0, nll_loss=1.266, ntokens=954.3, nsentences=32, sample_size=954.3, sample_size_v1=0, sample_size_v2=0, ppl=2.41, wps=516, ups=0.54, wpb=954.3, bsz=32, num_updates=7590, lr=2.72526e-05, gnorm=2.37, clip=100, loss_scale=256, train_wall=18, gb_free=11.8, wall=14261
2023-05-26 03:21:05 - progress_bar.py[line:272] - INFO: epoch 005:    683 / 1732 loss=2.423, loss_v1=0, loss_v2=0, nll_loss=1.227, ntokens=960.5, nsentences=32, sample_size=960.5, sample_size_v1=0, sample_size_v2=0, ppl=2.34, wps=520.4, ups=0.54, wpb=960.5, bsz=32, num_updates=7600, lr=2.72465e-05, gnorm=2.411, clip=100, loss_scale=256, train_wall=18, gb_free=11.9, wall=14279
2023-05-26 03:21:23 - progress_bar.py[line:272] - INFO: epoch 005:    693 / 1732 loss=2.445, loss_v1=0, loss_v2=0, nll_loss=1.258, ntokens=962.9, nsentences=32, sample_size=962.9, sample_size_v1=0, sample_size_v2=0, ppl=2.39, wps=517.6, ups=0.54, wpb=962.9, bsz=32, num_updates=7610, lr=2.72403e-05, gnorm=2.381, clip=100, loss_scale=256, train_wall=19, gb_free=11.2, wall=14298
2023-05-26 03:21:42 - progress_bar.py[line:272] - INFO: epoch 005:    703 / 1732 loss=2.402, loss_v1=0, loss_v2=0, nll_loss=1.2, ntokens=972.9, nsentences=32, sample_size=972.9, sample_size_v1=0, sample_size_v2=0, ppl=2.3, wps=525.3, ups=0.54, wpb=972.9, bsz=32, num_updates=7620, lr=2.72342e-05, gnorm=2.171, clip=100, loss_scale=256, train_wall=18, gb_free=11.6, wall=14316
2023-05-26 03:22:00 - progress_bar.py[line:272] - INFO: epoch 005:    713 / 1732 loss=2.449, loss_v1=0, loss_v2=0, nll_loss=1.258, ntokens=898.6, nsentences=32, sample_size=898.6, sample_size_v1=0, sample_size_v2=0, ppl=2.39, wps=488.5, ups=0.54, wpb=898.6, bsz=32, num_updates=7630, lr=2.72281e-05, gnorm=2.349, clip=100, loss_scale=256, train_wall=18, gb_free=11.8, wall=14335
2023-05-26 03:22:19 - progress_bar.py[line:272] - INFO: epoch 005:    723 / 1732 loss=2.408, loss_v1=0, loss_v2=0, nll_loss=1.214, ntokens=877.5, nsentences=32, sample_size=877.5, sample_size_v1=0, sample_size_v2=0, ppl=2.32, wps=477.8, ups=0.54, wpb=877.5, bsz=32, num_updates=7640, lr=2.72219e-05, gnorm=2.427, clip=100, loss_scale=256, train_wall=18, gb_free=12, wall=14353
2023-05-26 03:22:37 - progress_bar.py[line:272] - INFO: epoch 005:    733 / 1732 loss=2.415, loss_v1=0, loss_v2=0, nll_loss=1.219, ntokens=959.6, nsentences=32, sample_size=959.6, sample_size_v1=0, sample_size_v2=0, ppl=2.33, wps=519.6, ups=0.54, wpb=959.6, bsz=32, num_updates=7650, lr=2.72158e-05, gnorm=2.256, clip=100, loss_scale=512, train_wall=18, gb_free=11, wall=14372
2023-05-26 03:22:48 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 256.0
2023-05-26 03:22:57 - progress_bar.py[line:272] - INFO: epoch 005:    744 / 1732 loss=2.404, loss_v1=0, loss_v2=0, nll_loss=1.206, ntokens=984.4, nsentences=32, sample_size=984.4, sample_size_v1=0, sample_size_v2=0, ppl=2.31, wps=485, ups=0.49, wpb=984.4, bsz=32, num_updates=7660, lr=2.72096e-05, gnorm=2.123, clip=100, loss_scale=256, train_wall=20, gb_free=11, wall=14392
2023-05-26 03:23:16 - progress_bar.py[line:272] - INFO: epoch 005:    754 / 1732 loss=2.425, loss_v1=0, loss_v2=0, nll_loss=1.229, ntokens=976.3, nsentences=32, sample_size=976.3, sample_size_v1=0, sample_size_v2=0, ppl=2.34, wps=526.5, ups=0.54, wpb=976.3, bsz=32, num_updates=7670, lr=2.72035e-05, gnorm=2.248, clip=100, loss_scale=256, train_wall=19, gb_free=11.5, wall=14410
2023-05-26 03:23:34 - progress_bar.py[line:272] - INFO: epoch 005:    764 / 1732 loss=2.416, loss_v1=0, loss_v2=0, nll_loss=1.225, ntokens=943.8, nsentences=32, sample_size=943.8, sample_size_v1=0, sample_size_v2=0, ppl=2.34, wps=513.2, ups=0.54, wpb=943.8, bsz=32, num_updates=7680, lr=2.71973e-05, gnorm=2.31, clip=100, loss_scale=256, train_wall=18, gb_free=11.8, wall=14429
2023-05-26 03:23:53 - progress_bar.py[line:272] - INFO: epoch 005:    774 / 1732 loss=2.411, loss_v1=0, loss_v2=0, nll_loss=1.213, ntokens=1000.5, nsentences=32, sample_size=1000.5, sample_size_v1=0, sample_size_v2=0, ppl=2.32, wps=540.5, ups=0.54, wpb=1000.5, bsz=32, num_updates=7690, lr=2.71912e-05, gnorm=2.338, clip=100, loss_scale=256, train_wall=18, gb_free=11.4, wall=14447
2023-05-26 03:24:11 - progress_bar.py[line:272] - INFO: epoch 005:    784 / 1732 loss=2.421, loss_v1=0, loss_v2=0, nll_loss=1.228, ntokens=1008.3, nsentences=32, sample_size=1008.3, sample_size_v1=0, sample_size_v2=0, ppl=2.34, wps=545.3, ups=0.54, wpb=1008.3, bsz=32, num_updates=7700, lr=2.71851e-05, gnorm=2.111, clip=100, loss_scale=256, train_wall=18, gb_free=11.3, wall=14466
2023-05-26 03:24:30 - progress_bar.py[line:272] - INFO: epoch 005:    794 / 1732 loss=2.422, loss_v1=0, loss_v2=0, nll_loss=1.227, ntokens=1024.7, nsentences=32, sample_size=1024.7, sample_size_v1=0, sample_size_v2=0, ppl=2.34, wps=554.9, ups=0.54, wpb=1024.7, bsz=32, num_updates=7710, lr=2.71789e-05, gnorm=2.325, clip=100, loss_scale=256, train_wall=18, gb_free=11.7, wall=14484
2023-05-26 03:24:48 - progress_bar.py[line:272] - INFO: epoch 005:    804 / 1732 loss=2.418, loss_v1=0, loss_v2=0, nll_loss=1.223, ntokens=947.8, nsentences=32, sample_size=947.8, sample_size_v1=0, sample_size_v2=0, ppl=2.33, wps=514, ups=0.54, wpb=947.8, bsz=32, num_updates=7720, lr=2.71728e-05, gnorm=2.278, clip=100, loss_scale=256, train_wall=18, gb_free=11.6, wall=14503
2023-05-26 03:25:07 - progress_bar.py[line:272] - INFO: epoch 005:    814 / 1732 loss=2.423, loss_v1=0, loss_v2=0, nll_loss=1.228, ntokens=938.1, nsentences=32, sample_size=938.1, sample_size_v1=0, sample_size_v2=0, ppl=2.34, wps=507.6, ups=0.54, wpb=938.1, bsz=32, num_updates=7730, lr=2.71666e-05, gnorm=2.21, clip=100, loss_scale=256, train_wall=18, gb_free=11.8, wall=14521
2023-05-26 03:25:25 - progress_bar.py[line:272] - INFO: epoch 005:    824 / 1732 loss=2.427, loss_v1=0, loss_v2=0, nll_loss=1.232, ntokens=923.7, nsentences=32, sample_size=923.7, sample_size_v1=0, sample_size_v2=0, ppl=2.35, wps=498.5, ups=0.54, wpb=923.7, bsz=32, num_updates=7740, lr=2.71605e-05, gnorm=2.396, clip=100, loss_scale=256, train_wall=18, gb_free=11.1, wall=14540
2023-05-26 03:25:43 - progress_bar.py[line:272] - INFO: epoch 005:    834 / 1732 loss=2.428, loss_v1=0, loss_v2=0, nll_loss=1.235, ntokens=890.1, nsentences=32, sample_size=890.1, sample_size_v1=0, sample_size_v2=0, ppl=2.35, wps=486.5, ups=0.55, wpb=890.1, bsz=32, num_updates=7750, lr=2.71544e-05, gnorm=2.459, clip=100, loss_scale=256, train_wall=18, gb_free=11.9, wall=14558
2023-05-26 03:26:02 - progress_bar.py[line:272] - INFO: epoch 005:    844 / 1732 loss=2.406, loss_v1=0, loss_v2=0, nll_loss=1.207, ntokens=972.2, nsentences=32, sample_size=972.2, sample_size_v1=0, sample_size_v2=0, ppl=2.31, wps=529, ups=0.54, wpb=972.2, bsz=32, num_updates=7760, lr=2.71482e-05, gnorm=2.25, clip=100, loss_scale=256, train_wall=18, gb_free=11.5, wall=14577
2023-05-26 03:26:20 - progress_bar.py[line:272] - INFO: epoch 005:    854 / 1732 loss=2.414, loss_v1=0, loss_v2=0, nll_loss=1.221, ntokens=976.8, nsentences=32, sample_size=976.8, sample_size_v1=0, sample_size_v2=0, ppl=2.33, wps=526.2, ups=0.54, wpb=976.8, bsz=32, num_updates=7770, lr=2.71421e-05, gnorm=2.149, clip=100, loss_scale=256, train_wall=19, gb_free=11.5, wall=14595
2023-05-26 03:26:39 - progress_bar.py[line:272] - INFO: epoch 005:    864 / 1732 loss=2.433, loss_v1=0, loss_v2=0, nll_loss=1.238, ntokens=958.7, nsentences=32, sample_size=958.7, sample_size_v1=0, sample_size_v2=0, ppl=2.36, wps=518.5, ups=0.54, wpb=958.7, bsz=32, num_updates=7780, lr=2.71359e-05, gnorm=2.266, clip=100, loss_scale=256, train_wall=18, gb_free=11.4, wall=14614
2023-05-26 03:26:57 - progress_bar.py[line:272] - INFO: epoch 005:    874 / 1732 loss=2.383, loss_v1=0, loss_v2=0, nll_loss=1.185, ntokens=975.5, nsentences=32, sample_size=975.5, sample_size_v1=0, sample_size_v2=0, ppl=2.27, wps=527.8, ups=0.54, wpb=975.5, bsz=32, num_updates=7790, lr=2.71298e-05, gnorm=2.259, clip=100, loss_scale=256, train_wall=18, gb_free=11, wall=14632
2023-05-26 03:27:16 - progress_bar.py[line:272] - INFO: epoch 005:    884 / 1732 loss=2.362, loss_v1=0, loss_v2=0, nll_loss=1.161, ntokens=977.6, nsentences=32, sample_size=977.6, sample_size_v1=0, sample_size_v2=0, ppl=2.24, wps=526.9, ups=0.54, wpb=977.6, bsz=32, num_updates=7800, lr=2.71236e-05, gnorm=2.25, clip=100, loss_scale=256, train_wall=19, gb_free=11.3, wall=14651
2023-05-26 03:27:34 - progress_bar.py[line:272] - INFO: epoch 005:    894 / 1732 loss=2.37, loss_v1=0, loss_v2=0, nll_loss=1.168, ntokens=1010, nsentences=32, sample_size=1010, sample_size_v1=0, sample_size_v2=0, ppl=2.25, wps=544.5, ups=0.54, wpb=1010, bsz=32, num_updates=7810, lr=2.71175e-05, gnorm=1.98, clip=100, loss_scale=256, train_wall=19, gb_free=10.9, wall=14669
2023-05-26 03:27:53 - progress_bar.py[line:272] - INFO: epoch 005:    904 / 1732 loss=2.367, loss_v1=0, loss_v2=0, nll_loss=1.167, ntokens=1055.2, nsentences=32, sample_size=1055.2, sample_size_v1=0, sample_size_v2=0, ppl=2.24, wps=569.2, ups=0.54, wpb=1055.2, bsz=32, num_updates=7820, lr=2.71114e-05, gnorm=1.971, clip=100, loss_scale=256, train_wall=19, gb_free=11.5, wall=14688
2023-05-26 03:28:12 - progress_bar.py[line:272] - INFO: epoch 005:    914 / 1732 loss=2.45, loss_v1=0, loss_v2=0, nll_loss=1.259, ntokens=927.8, nsentences=32, sample_size=927.8, sample_size_v1=0, sample_size_v2=0, ppl=2.39, wps=502.1, ups=0.54, wpb=927.8, bsz=32, num_updates=7830, lr=2.71052e-05, gnorm=2.418, clip=100, loss_scale=256, train_wall=18, gb_free=11.8, wall=14706
2023-05-26 03:28:30 - progress_bar.py[line:272] - INFO: epoch 005:    924 / 1732 loss=2.376, loss_v1=0, loss_v2=0, nll_loss=1.177, ntokens=1031.4, nsentences=32, sample_size=1031.4, sample_size_v1=0, sample_size_v2=0, ppl=2.26, wps=552.8, ups=0.54, wpb=1031.4, bsz=32, num_updates=7840, lr=2.70991e-05, gnorm=2.196, clip=100, loss_scale=256, train_wall=19, gb_free=11.4, wall=14725
2023-05-26 03:28:49 - progress_bar.py[line:272] - INFO: epoch 005:    934 / 1732 loss=2.398, loss_v1=0, loss_v2=0, nll_loss=1.201, ntokens=1020.2, nsentences=32, sample_size=1020.2, sample_size_v1=0, sample_size_v2=0, ppl=2.3, wps=546.5, ups=0.54, wpb=1020.2, bsz=32, num_updates=7850, lr=2.70929e-05, gnorm=2.338, clip=100, loss_scale=256, train_wall=19, gb_free=11.7, wall=14744
2023-05-26 03:29:08 - progress_bar.py[line:272] - INFO: epoch 005:    944 / 1732 loss=2.412, loss_v1=0, loss_v2=0, nll_loss=1.215, ntokens=1062, nsentences=32, sample_size=1062, sample_size_v1=0, sample_size_v2=0, ppl=2.32, wps=563.8, ups=0.53, wpb=1062, bsz=32, num_updates=7860, lr=2.70868e-05, gnorm=2.092, clip=100, loss_scale=256, train_wall=19, gb_free=10.9, wall=14762
2023-05-26 03:29:26 - progress_bar.py[line:272] - INFO: epoch 005:    954 / 1732 loss=2.394, loss_v1=0, loss_v2=0, nll_loss=1.197, ntokens=1041, nsentences=32, sample_size=1041, sample_size_v1=0, sample_size_v2=0, ppl=2.29, wps=556.2, ups=0.53, wpb=1041, bsz=32, num_updates=7870, lr=2.70806e-05, gnorm=2.439, clip=100, loss_scale=256, train_wall=19, gb_free=10.9, wall=14781
2023-05-26 03:29:45 - progress_bar.py[line:272] - INFO: epoch 005:    964 / 1732 loss=2.404, loss_v1=0, loss_v2=0, nll_loss=1.207, ntokens=1053, nsentences=32, sample_size=1053, sample_size_v1=0, sample_size_v2=0, ppl=2.31, wps=562.6, ups=0.53, wpb=1053, bsz=32, num_updates=7880, lr=2.70745e-05, gnorm=2.362, clip=100, loss_scale=256, train_wall=19, gb_free=11.4, wall=14800
2023-05-26 03:30:04 - progress_bar.py[line:272] - INFO: epoch 005:    974 / 1732 loss=2.41, loss_v1=0, loss_v2=0, nll_loss=1.215, ntokens=1051.9, nsentences=32, sample_size=1051.9, sample_size_v1=0, sample_size_v2=0, ppl=2.32, wps=559.2, ups=0.53, wpb=1051.9, bsz=32, num_updates=7890, lr=2.70684e-05, gnorm=2.127, clip=100, loss_scale=256, train_wall=19, gb_free=11.4, wall=14819
2023-05-26 03:30:23 - progress_bar.py[line:272] - INFO: epoch 005:    984 / 1732 loss=2.403, loss_v1=0, loss_v2=0, nll_loss=1.206, ntokens=1029.3, nsentences=32, sample_size=1029.3, sample_size_v1=0, sample_size_v2=0, ppl=2.31, wps=547, ups=0.53, wpb=1029.3, bsz=32, num_updates=7900, lr=2.70622e-05, gnorm=2.078, clip=100, loss_scale=256, train_wall=19, gb_free=10.9, wall=14837
2023-05-26 03:30:42 - progress_bar.py[line:272] - INFO: epoch 005:    994 / 1732 loss=2.404, loss_v1=0, loss_v2=0, nll_loss=1.205, ntokens=1030.4, nsentences=32, sample_size=1030.4, sample_size_v1=0, sample_size_v2=0, ppl=2.3, wps=550.1, ups=0.53, wpb=1030.4, bsz=32, num_updates=7910, lr=2.70561e-05, gnorm=2.353, clip=100, loss_scale=256, train_wall=19, gb_free=11.4, wall=14856
2023-05-26 03:31:00 - progress_bar.py[line:272] - INFO: epoch 005:   1004 / 1732 loss=2.396, loss_v1=0, loss_v2=0, nll_loss=1.199, ntokens=995.4, nsentences=32, sample_size=995.4, sample_size_v1=0, sample_size_v2=0, ppl=2.3, wps=533.5, ups=0.54, wpb=995.4, bsz=32, num_updates=7920, lr=2.70499e-05, gnorm=2.192, clip=100, loss_scale=256, train_wall=19, gb_free=11.8, wall=14875
2023-05-26 03:31:19 - progress_bar.py[line:272] - INFO: epoch 005:   1014 / 1732 loss=2.392, loss_v1=0, loss_v2=0, nll_loss=1.194, ntokens=997.1, nsentences=32, sample_size=997.1, sample_size_v1=0, sample_size_v2=0, ppl=2.29, wps=535.5, ups=0.54, wpb=997.1, bsz=32, num_updates=7930, lr=2.70438e-05, gnorm=2.189, clip=100, loss_scale=256, train_wall=19, gb_free=11.4, wall=14893
2023-05-26 03:31:38 - progress_bar.py[line:272] - INFO: epoch 005:   1024 / 1732 loss=2.394, loss_v1=0, loss_v2=0, nll_loss=1.197, ntokens=1086.7, nsentences=32, sample_size=1086.7, sample_size_v1=0, sample_size_v2=0, ppl=2.29, wps=578.3, ups=0.53, wpb=1086.7, bsz=32, num_updates=7940, lr=2.70377e-05, gnorm=2.158, clip=100, loss_scale=256, train_wall=19, gb_free=11.2, wall=14912
2023-05-26 03:31:56 - progress_bar.py[line:272] - INFO: epoch 005:   1034 / 1732 loss=2.394, loss_v1=0, loss_v2=0, nll_loss=1.194, ntokens=1103.2, nsentences=32, sample_size=1103.2, sample_size_v1=0, sample_size_v2=0, ppl=2.29, wps=584.2, ups=0.53, wpb=1103.2, bsz=32, num_updates=7950, lr=2.70315e-05, gnorm=2.108, clip=100, loss_scale=256, train_wall=19, gb_free=10.8, wall=14931
2023-05-26 03:32:15 - progress_bar.py[line:272] - INFO: epoch 005:   1044 / 1732 loss=2.393, loss_v1=0, loss_v2=0, nll_loss=1.194, ntokens=1052.8, nsentences=32, sample_size=1052.8, sample_size_v1=0, sample_size_v2=0, ppl=2.29, wps=559.6, ups=0.53, wpb=1052.8, bsz=32, num_updates=7960, lr=2.70254e-05, gnorm=2.348, clip=100, loss_scale=256, train_wall=19, gb_free=11.2, wall=14950
2023-05-26 03:32:34 - progress_bar.py[line:272] - INFO: epoch 005:   1054 / 1732 loss=2.416, loss_v1=0, loss_v2=0, nll_loss=1.221, ntokens=1068, nsentences=32, sample_size=1068, sample_size_v1=0, sample_size_v2=0, ppl=2.33, wps=572.2, ups=0.54, wpb=1068, bsz=32, num_updates=7970, lr=2.70192e-05, gnorm=2.133, clip=100, loss_scale=256, train_wall=19, gb_free=10, wall=14969
2023-05-26 03:32:53 - progress_bar.py[line:272] - INFO: epoch 005:   1064 / 1732 loss=2.389, loss_v1=0, loss_v2=0, nll_loss=1.19, ntokens=1024.1, nsentences=32, sample_size=1024.1, sample_size_v1=0, sample_size_v2=0, ppl=2.28, wps=547.4, ups=0.53, wpb=1024.1, bsz=32, num_updates=7980, lr=2.70131e-05, gnorm=2.334, clip=100, loss_scale=256, train_wall=19, gb_free=11.6, wall=14987
2023-05-26 03:33:11 - progress_bar.py[line:272] - INFO: epoch 005:   1074 / 1732 loss=2.396, loss_v1=0, loss_v2=0, nll_loss=1.199, ntokens=1002.8, nsentences=32, sample_size=1002.8, sample_size_v1=0, sample_size_v2=0, ppl=2.3, wps=534.6, ups=0.53, wpb=1002.8, bsz=32, num_updates=7990, lr=2.70069e-05, gnorm=2.109, clip=100, loss_scale=256, train_wall=19, gb_free=11.3, wall=15006
2023-05-26 03:33:30 - progress_bar.py[line:272] - INFO: epoch 005:   1084 / 1732 loss=2.413, loss_v1=0, loss_v2=0, nll_loss=1.217, ntokens=1060.4, nsentences=32, sample_size=1060.4, sample_size_v1=0, sample_size_v2=0, ppl=2.33, wps=559.3, ups=0.53, wpb=1060.4, bsz=32, num_updates=8000, lr=2.70008e-05, gnorm=2.265, clip=100, loss_scale=256, train_wall=19, gb_free=10.3, wall=15025
2023-05-26 03:33:49 - progress_bar.py[line:272] - INFO: epoch 005:   1094 / 1732 loss=2.398, loss_v1=0, loss_v2=0, nll_loss=1.198, ntokens=1050.5, nsentences=32, sample_size=1050.5, sample_size_v1=0, sample_size_v2=0, ppl=2.29, wps=560.4, ups=0.53, wpb=1050.5, bsz=32, num_updates=8010, lr=2.69947e-05, gnorm=2.234, clip=100, loss_scale=256, train_wall=19, gb_free=10.8, wall=15044
2023-05-26 03:34:08 - progress_bar.py[line:272] - INFO: epoch 005:   1104 / 1732 loss=2.396, loss_v1=0, loss_v2=0, nll_loss=1.2, ntokens=1042.3, nsentences=32, sample_size=1042.3, sample_size_v1=0, sample_size_v2=0, ppl=2.3, wps=554.3, ups=0.53, wpb=1042.3, bsz=32, num_updates=8020, lr=2.69885e-05, gnorm=2.082, clip=100, loss_scale=256, train_wall=19, gb_free=11.2, wall=15063
2023-05-26 03:34:27 - progress_bar.py[line:272] - INFO: epoch 005:   1114 / 1732 loss=2.396, loss_v1=0, loss_v2=0, nll_loss=1.197, ntokens=1000.7, nsentences=32, sample_size=1000.7, sample_size_v1=0, sample_size_v2=0, ppl=2.29, wps=532.6, ups=0.53, wpb=1000.7, bsz=32, num_updates=8030, lr=2.69824e-05, gnorm=2.309, clip=100, loss_scale=256, train_wall=19, gb_free=11.3, wall=15081
2023-05-26 03:34:46 - progress_bar.py[line:272] - INFO: epoch 005:   1124 / 1732 loss=2.391, loss_v1=0, loss_v2=0, nll_loss=1.193, ntokens=989.1, nsentences=32, sample_size=989.1, sample_size_v1=0, sample_size_v2=0, ppl=2.29, wps=525.1, ups=0.53, wpb=989.1, bsz=32, num_updates=8040, lr=2.69762e-05, gnorm=2.324, clip=100, loss_scale=256, train_wall=19, gb_free=10.8, wall=15100
2023-05-26 03:35:04 - progress_bar.py[line:272] - INFO: epoch 005:   1134 / 1732 loss=2.406, loss_v1=0, loss_v2=0, nll_loss=1.209, ntokens=968.8, nsentences=32, sample_size=968.8, sample_size_v1=0, sample_size_v2=0, ppl=2.31, wps=513.7, ups=0.53, wpb=968.8, bsz=32, num_updates=8050, lr=2.69701e-05, gnorm=2.315, clip=100, loss_scale=256, train_wall=19, gb_free=11.4, wall=15119
2023-05-26 03:35:23 - progress_bar.py[line:272] - INFO: epoch 005:   1144 / 1732 loss=2.401, loss_v1=0, loss_v2=0, nll_loss=1.204, ntokens=1034.3, nsentences=32, sample_size=1034.3, sample_size_v1=0, sample_size_v2=0, ppl=2.3, wps=552.4, ups=0.53, wpb=1034.3, bsz=32, num_updates=8060, lr=2.69639e-05, gnorm=2.325, clip=100, loss_scale=256, train_wall=19, gb_free=11.6, wall=15138
2023-05-26 03:35:42 - progress_bar.py[line:272] - INFO: epoch 005:   1154 / 1732 loss=2.397, loss_v1=0, loss_v2=0, nll_loss=1.199, ntokens=1025.8, nsentences=32, sample_size=1025.8, sample_size_v1=0, sample_size_v2=0, ppl=2.3, wps=545.8, ups=0.53, wpb=1025.8, bsz=32, num_updates=8070, lr=2.69578e-05, gnorm=2.309, clip=100, loss_scale=256, train_wall=19, gb_free=10.3, wall=15157
2023-05-26 03:36:01 - progress_bar.py[line:272] - INFO: epoch 005:   1164 / 1732 loss=2.371, loss_v1=0, loss_v2=0, nll_loss=1.17, ntokens=1008, nsentences=32, sample_size=1008, sample_size_v1=0, sample_size_v2=0, ppl=2.25, wps=536.8, ups=0.53, wpb=1008, bsz=32, num_updates=8080, lr=2.69517e-05, gnorm=2.25, clip=100, loss_scale=256, train_wall=19, gb_free=11.5, wall=15175
2023-05-26 03:36:20 - progress_bar.py[line:272] - INFO: epoch 005:   1174 / 1732 loss=2.392, loss_v1=0, loss_v2=0, nll_loss=1.193, ntokens=1081.1, nsentences=32, sample_size=1081.1, sample_size_v1=0, sample_size_v2=0, ppl=2.29, wps=576.5, ups=0.53, wpb=1081.1, bsz=32, num_updates=8090, lr=2.69455e-05, gnorm=2.137, clip=100, loss_scale=256, train_wall=19, gb_free=11, wall=15194
2023-05-26 03:36:38 - progress_bar.py[line:272] - INFO: epoch 005:   1184 / 1732 loss=2.389, loss_v1=0, loss_v2=0, nll_loss=1.191, ntokens=962, nsentences=32, sample_size=962, sample_size_v1=0, sample_size_v2=0, ppl=2.28, wps=516.5, ups=0.54, wpb=962, bsz=32, num_updates=8100, lr=2.69394e-05, gnorm=2.344, clip=100, loss_scale=256, train_wall=19, gb_free=11.7, wall=15213
2023-05-26 03:36:57 - progress_bar.py[line:272] - INFO: epoch 005:   1194 / 1732 loss=2.408, loss_v1=0, loss_v2=0, nll_loss=1.21, ntokens=1042.6, nsentences=32, sample_size=1042.6, sample_size_v1=0, sample_size_v2=0, ppl=2.31, wps=556, ups=0.53, wpb=1042.6, bsz=32, num_updates=8110, lr=2.69332e-05, gnorm=2.398, clip=100, loss_scale=256, train_wall=19, gb_free=11.5, wall=15232
2023-05-26 03:37:16 - progress_bar.py[line:272] - INFO: epoch 005:   1204 / 1732 loss=2.359, loss_v1=0, loss_v2=0, nll_loss=1.157, ntokens=1150.2, nsentences=32, sample_size=1150.2, sample_size_v1=0, sample_size_v2=0, ppl=2.23, wps=605.8, ups=0.53, wpb=1150.2, bsz=32, num_updates=8120, lr=2.69271e-05, gnorm=2.104, clip=100, loss_scale=256, train_wall=19, gb_free=11.3, wall=15251
2023-05-26 03:37:35 - progress_bar.py[line:272] - INFO: epoch 005:   1214 / 1732 loss=2.395, loss_v1=0, loss_v2=0, nll_loss=1.199, ntokens=996.3, nsentences=32, sample_size=996.3, sample_size_v1=0, sample_size_v2=0, ppl=2.3, wps=532.9, ups=0.53, wpb=996.3, bsz=32, num_updates=8130, lr=2.6921e-05, gnorm=2.187, clip=100, loss_scale=256, train_wall=19, gb_free=11.7, wall=15269
2023-05-26 03:37:53 - progress_bar.py[line:272] - INFO: epoch 005:   1224 / 1732 loss=2.418, loss_v1=0, loss_v2=0, nll_loss=1.221, ntokens=1056.3, nsentences=32, sample_size=1056.3, sample_size_v1=0, sample_size_v2=0, ppl=2.33, wps=561.9, ups=0.53, wpb=1056.3, bsz=32, num_updates=8140, lr=2.69148e-05, gnorm=2.2, clip=100, loss_scale=256, train_wall=19, gb_free=11.5, wall=15288
2023-05-26 03:38:12 - progress_bar.py[line:272] - INFO: epoch 005:   1234 / 1732 loss=2.382, loss_v1=0, loss_v2=0, nll_loss=1.183, ntokens=1012.2, nsentences=32, sample_size=1012.2, sample_size_v1=0, sample_size_v2=0, ppl=2.27, wps=541.9, ups=0.54, wpb=1012.2, bsz=32, num_updates=8150, lr=2.69087e-05, gnorm=2.224, clip=100, loss_scale=256, train_wall=19, gb_free=11.6, wall=15307
2023-05-26 03:38:31 - progress_bar.py[line:272] - INFO: epoch 005:   1244 / 1732 loss=2.328, loss_v1=0, loss_v2=0, nll_loss=1.122, ntokens=1090.2, nsentences=32, sample_size=1090.2, sample_size_v1=0, sample_size_v2=0, ppl=2.18, wps=579.9, ups=0.53, wpb=1090.2, bsz=32, num_updates=8160, lr=2.69025e-05, gnorm=2.15, clip=100, loss_scale=256, train_wall=19, gb_free=11.4, wall=15326
2023-05-26 03:38:50 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 256.0
2023-05-26 03:38:52 - progress_bar.py[line:272] - INFO: epoch 005:   1255 / 1732 loss=2.361, loss_v1=0, loss_v2=0, nll_loss=1.157, ntokens=1088.6, nsentences=32, sample_size=1088.6, sample_size_v1=0, sample_size_v2=0, ppl=2.23, wps=526.9, ups=0.48, wpb=1088.6, bsz=32, num_updates=8170, lr=2.68964e-05, gnorm=2.132, clip=100, loss_scale=256, train_wall=21, gb_free=11.4, wall=15346
2023-05-26 03:39:10 - progress_bar.py[line:272] - INFO: epoch 005:   1265 / 1732 loss=2.405, loss_v1=0, loss_v2=0, nll_loss=1.212, ntokens=1072.6, nsentences=32, sample_size=1072.6, sample_size_v1=0, sample_size_v2=0, ppl=2.32, wps=569.9, ups=0.53, wpb=1072.6, bsz=32, num_updates=8180, lr=2.68902e-05, gnorm=2.271, clip=100, loss_scale=256, train_wall=19, gb_free=12, wall=15365
2023-05-26 03:39:29 - progress_bar.py[line:272] - INFO: epoch 005:   1275 / 1732 loss=2.393, loss_v1=0, loss_v2=0, nll_loss=1.191, ntokens=1036.2, nsentences=32, sample_size=1036.2, sample_size_v1=0, sample_size_v2=0, ppl=2.28, wps=551.6, ups=0.53, wpb=1036.2, bsz=32, num_updates=8190, lr=2.68841e-05, gnorm=2.309, clip=100, loss_scale=256, train_wall=19, gb_free=11.3, wall=15384
2023-05-26 03:39:48 - progress_bar.py[line:272] - INFO: epoch 005:   1285 / 1732 loss=2.387, loss_v1=0, loss_v2=0, nll_loss=1.189, ntokens=1069.5, nsentences=32, sample_size=1069.5, sample_size_v1=0, sample_size_v2=0, ppl=2.28, wps=566.4, ups=0.53, wpb=1069.5, bsz=32, num_updates=8200, lr=2.6878e-05, gnorm=2.109, clip=100, loss_scale=256, train_wall=19, gb_free=11.4, wall=15403
2023-05-26 03:40:07 - progress_bar.py[line:272] - INFO: epoch 005:   1295 / 1732 loss=2.376, loss_v1=0, loss_v2=0, nll_loss=1.176, ntokens=1106.6, nsentences=32, sample_size=1106.6, sample_size_v1=0, sample_size_v2=0, ppl=2.26, wps=586.1, ups=0.53, wpb=1106.6, bsz=32, num_updates=8210, lr=2.68718e-05, gnorm=2.064, clip=100, loss_scale=256, train_wall=19, gb_free=10.6, wall=15422
2023-05-26 03:40:26 - progress_bar.py[line:272] - INFO: epoch 005:   1305 / 1732 loss=2.402, loss_v1=0, loss_v2=0, nll_loss=1.202, ntokens=1087.8, nsentences=32, sample_size=1087.8, sample_size_v1=0, sample_size_v2=0, ppl=2.3, wps=575.9, ups=0.53, wpb=1087.8, bsz=32, num_updates=8220, lr=2.68657e-05, gnorm=2.166, clip=100, loss_scale=256, train_wall=19, gb_free=10.8, wall=15440
2023-05-26 03:40:45 - progress_bar.py[line:272] - INFO: epoch 005:   1315 / 1732 loss=2.399, loss_v1=0, loss_v2=0, nll_loss=1.202, ntokens=1038.9, nsentences=32, sample_size=1038.9, sample_size_v1=0, sample_size_v2=0, ppl=2.3, wps=548.1, ups=0.53, wpb=1038.9, bsz=32, num_updates=8230, lr=2.68595e-05, gnorm=2.258, clip=100, loss_scale=256, train_wall=19, gb_free=11.2, wall=15459
2023-05-26 03:41:04 - progress_bar.py[line:272] - INFO: epoch 005:   1325 / 1732 loss=2.363, loss_v1=0, loss_v2=0, nll_loss=1.163, ntokens=1136.1, nsentences=32, sample_size=1136.1, sample_size_v1=0, sample_size_v2=0, ppl=2.24, wps=600.3, ups=0.53, wpb=1136.1, bsz=32, num_updates=8240, lr=2.68534e-05, gnorm=2.105, clip=100, loss_scale=256, train_wall=19, gb_free=10.6, wall=15478
2023-05-26 03:41:22 - progress_bar.py[line:272] - INFO: epoch 005:   1335 / 1732 loss=2.355, loss_v1=0, loss_v2=0, nll_loss=1.151, ntokens=1103.3, nsentences=32, sample_size=1103.3, sample_size_v1=0, sample_size_v2=0, ppl=2.22, wps=587.5, ups=0.53, wpb=1103.3, bsz=32, num_updates=8250, lr=2.68472e-05, gnorm=2.067, clip=100, loss_scale=256, train_wall=19, gb_free=10.3, wall=15497
2023-05-26 03:41:41 - progress_bar.py[line:272] - INFO: epoch 005:   1345 / 1732 loss=2.365, loss_v1=0, loss_v2=0, nll_loss=1.166, ntokens=1182.5, nsentences=32, sample_size=1182.5, sample_size_v1=0, sample_size_v2=0, ppl=2.24, wps=622.2, ups=0.53, wpb=1182.5, bsz=32, num_updates=8260, lr=2.68411e-05, gnorm=2.09, clip=100, loss_scale=256, train_wall=19, gb_free=11.1, wall=15516
2023-05-26 03:42:00 - progress_bar.py[line:272] - INFO: epoch 005:   1355 / 1732 loss=2.354, loss_v1=0, loss_v2=0, nll_loss=1.148, ntokens=1122.3, nsentences=32, sample_size=1122.3, sample_size_v1=0, sample_size_v2=0, ppl=2.22, wps=593.7, ups=0.53, wpb=1122.3, bsz=32, num_updates=8270, lr=2.6835e-05, gnorm=2.106, clip=100, loss_scale=256, train_wall=19, gb_free=11.3, wall=15535
2023-05-26 03:42:19 - progress_bar.py[line:272] - INFO: epoch 005:   1365 / 1732 loss=2.367, loss_v1=0, loss_v2=0, nll_loss=1.167, ntokens=1083.1, nsentences=32, sample_size=1083.1, sample_size_v1=0, sample_size_v2=0, ppl=2.24, wps=574.2, ups=0.53, wpb=1083.1, bsz=32, num_updates=8280, lr=2.68288e-05, gnorm=2.118, clip=100, loss_scale=256, train_wall=19, gb_free=11.6, wall=15554
2023-05-26 03:42:38 - progress_bar.py[line:272] - INFO: epoch 005:   1375 / 1732 loss=2.402, loss_v1=0, loss_v2=0, nll_loss=1.203, ntokens=1095.5, nsentences=32, sample_size=1095.5, sample_size_v1=0, sample_size_v2=0, ppl=2.3, wps=582.8, ups=0.53, wpb=1095.5, bsz=32, num_updates=8290, lr=2.68227e-05, gnorm=2.122, clip=100, loss_scale=256, train_wall=19, gb_free=11.3, wall=15573
2023-05-26 03:42:57 - progress_bar.py[line:272] - INFO: epoch 005:   1385 / 1732 loss=2.379, loss_v1=0, loss_v2=0, nll_loss=1.181, ntokens=1167.7, nsentences=32, sample_size=1167.7, sample_size_v1=0, sample_size_v2=0, ppl=2.27, wps=618, ups=0.53, wpb=1167.7, bsz=32, num_updates=8300, lr=2.68165e-05, gnorm=1.936, clip=100, loss_scale=256, train_wall=19, gb_free=11.1, wall=15592
2023-05-26 03:43:16 - progress_bar.py[line:272] - INFO: epoch 005:   1395 / 1732 loss=2.377, loss_v1=0, loss_v2=0, nll_loss=1.176, ntokens=1051.3, nsentences=32, sample_size=1051.3, sample_size_v1=0, sample_size_v2=0, ppl=2.26, wps=561.2, ups=0.53, wpb=1051.3, bsz=32, num_updates=8310, lr=2.68104e-05, gnorm=2.197, clip=100, loss_scale=256, train_wall=19, gb_free=11.1, wall=15610
2023-05-26 03:43:35 - progress_bar.py[line:272] - INFO: epoch 005:   1405 / 1732 loss=2.374, loss_v1=0, loss_v2=0, nll_loss=1.172, ntokens=1161.5, nsentences=32, sample_size=1161.5, sample_size_v1=0, sample_size_v2=0, ppl=2.25, wps=615.5, ups=0.53, wpb=1161.5, bsz=32, num_updates=8320, lr=2.68043e-05, gnorm=2.04, clip=100, loss_scale=256, train_wall=19, gb_free=11, wall=15629
2023-05-26 03:43:54 - progress_bar.py[line:272] - INFO: epoch 005:   1415 / 1732 loss=2.398, loss_v1=0, loss_v2=0, nll_loss=1.203, ntokens=1285.3, nsentences=32, sample_size=1285.3, sample_size_v1=0, sample_size_v2=0, ppl=2.3, wps=677.7, ups=0.53, wpb=1285.3, bsz=32, num_updates=8330, lr=2.67981e-05, gnorm=1.927, clip=100, loss_scale=256, train_wall=19, gb_free=10.7, wall=15648
2023-05-26 03:44:13 - progress_bar.py[line:272] - INFO: epoch 005:   1425 / 1732 loss=2.364, loss_v1=0, loss_v2=0, nll_loss=1.161, ntokens=1231.8, nsentences=32, sample_size=1231.8, sample_size_v1=0, sample_size_v2=0, ppl=2.24, wps=644.3, ups=0.52, wpb=1231.8, bsz=32, num_updates=8340, lr=2.6792e-05, gnorm=1.87, clip=100, loss_scale=256, train_wall=19, gb_free=10, wall=15667
2023-05-26 03:44:32 - progress_bar.py[line:272] - INFO: epoch 005:   1435 / 1732 loss=2.364, loss_v1=0, loss_v2=0, nll_loss=1.164, ntokens=1210.6, nsentences=32, sample_size=1210.6, sample_size_v1=0, sample_size_v2=0, ppl=2.24, wps=642.1, ups=0.53, wpb=1210.6, bsz=32, num_updates=8350, lr=2.67858e-05, gnorm=1.869, clip=100, loss_scale=256, train_wall=19, gb_free=11.3, wall=15686
2023-05-26 03:44:50 - progress_bar.py[line:272] - INFO: epoch 005:   1445 / 1732 loss=2.393, loss_v1=0, loss_v2=0, nll_loss=1.195, ntokens=1117.4, nsentences=32, sample_size=1117.4, sample_size_v1=0, sample_size_v2=0, ppl=2.29, wps=593.8, ups=0.53, wpb=1117.4, bsz=32, num_updates=8360, lr=2.67797e-05, gnorm=2.099, clip=100, loss_scale=256, train_wall=19, gb_free=11.3, wall=15705
2023-05-26 03:45:09 - progress_bar.py[line:272] - INFO: epoch 005:   1455 / 1732 loss=2.388, loss_v1=0, loss_v2=0, nll_loss=1.188, ntokens=1125.4, nsentences=32, sample_size=1125.4, sample_size_v1=0, sample_size_v2=0, ppl=2.28, wps=597.3, ups=0.53, wpb=1125.4, bsz=32, num_updates=8370, lr=2.67735e-05, gnorm=2.026, clip=100, loss_scale=256, train_wall=19, gb_free=11.1, wall=15724
2023-05-26 03:45:28 - progress_bar.py[line:272] - INFO: epoch 005:   1465 / 1732 loss=2.33, loss_v1=0, loss_v2=0, nll_loss=1.124, ntokens=1185.4, nsentences=32, sample_size=1185.4, sample_size_v1=0, sample_size_v2=0, ppl=2.18, wps=624.7, ups=0.53, wpb=1185.4, bsz=32, num_updates=8380, lr=2.67674e-05, gnorm=1.991, clip=100, loss_scale=256, train_wall=19, gb_free=11.2, wall=15743
2023-05-26 03:45:47 - progress_bar.py[line:272] - INFO: epoch 005:   1475 / 1732 loss=2.391, loss_v1=0, loss_v2=0, nll_loss=1.193, ntokens=1082.9, nsentences=32, sample_size=1082.9, sample_size_v1=0, sample_size_v2=0, ppl=2.29, wps=575.1, ups=0.53, wpb=1082.9, bsz=32, num_updates=8390, lr=2.67613e-05, gnorm=2.012, clip=100, loss_scale=256, train_wall=19, gb_free=11, wall=15762
2023-05-26 03:46:06 - progress_bar.py[line:272] - INFO: epoch 005:   1485 / 1732 loss=2.397, loss_v1=0, loss_v2=0, nll_loss=1.197, ntokens=1103.4, nsentences=32, sample_size=1103.4, sample_size_v1=0, sample_size_v2=0, ppl=2.29, wps=586.3, ups=0.53, wpb=1103.4, bsz=32, num_updates=8400, lr=2.67551e-05, gnorm=2.037, clip=100, loss_scale=256, train_wall=19, gb_free=10.6, wall=15780
2023-05-26 03:46:25 - progress_bar.py[line:272] - INFO: epoch 005:   1495 / 1732 loss=2.367, loss_v1=0, loss_v2=0, nll_loss=1.169, ntokens=1111.1, nsentences=32, sample_size=1111.1, sample_size_v1=0, sample_size_v2=0, ppl=2.25, wps=587.4, ups=0.53, wpb=1111.1, bsz=32, num_updates=8410, lr=2.6749e-05, gnorm=2.046, clip=100, loss_scale=256, train_wall=19, gb_free=10.5, wall=15799
2023-05-26 03:46:44 - progress_bar.py[line:272] - INFO: epoch 005:   1505 / 1732 loss=2.335, loss_v1=0, loss_v2=0, nll_loss=1.13, ntokens=1137.1, nsentences=32, sample_size=1137.1, sample_size_v1=0, sample_size_v2=0, ppl=2.19, wps=603.6, ups=0.53, wpb=1137.1, bsz=32, num_updates=8420, lr=2.67428e-05, gnorm=1.975, clip=100, loss_scale=256, train_wall=19, gb_free=11.7, wall=15818
2023-05-26 03:47:02 - progress_bar.py[line:272] - INFO: epoch 005:   1515 / 1732 loss=2.389, loss_v1=0, loss_v2=0, nll_loss=1.19, ntokens=1046.4, nsentences=32, sample_size=1046.4, sample_size_v1=0, sample_size_v2=0, ppl=2.28, wps=558.6, ups=0.53, wpb=1046.4, bsz=32, num_updates=8430, lr=2.67367e-05, gnorm=2.135, clip=100, loss_scale=256, train_wall=19, gb_free=11.1, wall=15837
2023-05-26 03:47:21 - progress_bar.py[line:272] - INFO: epoch 005:   1525 / 1732 loss=2.419, loss_v1=0, loss_v2=0, nll_loss=1.225, ntokens=1040.6, nsentences=32, sample_size=1040.6, sample_size_v1=0, sample_size_v2=0, ppl=2.34, wps=555.1, ups=0.53, wpb=1040.6, bsz=32, num_updates=8440, lr=2.67305e-05, gnorm=2.151, clip=100, loss_scale=256, train_wall=19, gb_free=11, wall=15856
2023-05-26 03:47:40 - progress_bar.py[line:272] - INFO: epoch 005:   1535 / 1732 loss=2.379, loss_v1=0, loss_v2=0, nll_loss=1.176, ntokens=1087.5, nsentences=32, sample_size=1087.5, sample_size_v1=0, sample_size_v2=0, ppl=2.26, wps=573.2, ups=0.53, wpb=1087.5, bsz=32, num_updates=8450, lr=2.67244e-05, gnorm=2.251, clip=100, loss_scale=256, train_wall=19, gb_free=10.8, wall=15875
2023-05-26 03:47:59 - progress_bar.py[line:272] - INFO: epoch 005:   1545 / 1732 loss=2.352, loss_v1=0, loss_v2=0, nll_loss=1.15, ntokens=1079.7, nsentences=32, sample_size=1079.7, sample_size_v1=0, sample_size_v2=0, ppl=2.22, wps=574, ups=0.53, wpb=1079.7, bsz=32, num_updates=8460, lr=2.67183e-05, gnorm=2.023, clip=100, loss_scale=256, train_wall=19, gb_free=11.5, wall=15894
2023-05-26 03:48:18 - progress_bar.py[line:272] - INFO: epoch 005:   1555 / 1732 loss=2.356, loss_v1=0, loss_v2=0, nll_loss=1.154, ntokens=1057.3, nsentences=32, sample_size=1057.3, sample_size_v1=0, sample_size_v2=0, ppl=2.23, wps=563.5, ups=0.53, wpb=1057.3, bsz=32, num_updates=8470, lr=2.67121e-05, gnorm=2.12, clip=100, loss_scale=256, train_wall=19, gb_free=11.2, wall=15912
2023-05-26 03:48:36 - progress_bar.py[line:272] - INFO: epoch 005:   1565 / 1732 loss=2.407, loss_v1=0, loss_v2=0, nll_loss=1.211, ntokens=1124.1, nsentences=32, sample_size=1124.1, sample_size_v1=0, sample_size_v2=0, ppl=2.31, wps=597.6, ups=0.53, wpb=1124.1, bsz=32, num_updates=8480, lr=2.6706e-05, gnorm=2.002, clip=100, loss_scale=256, train_wall=19, gb_free=10.6, wall=15931
2023-05-26 03:48:55 - progress_bar.py[line:272] - INFO: epoch 005:   1575 / 1732 loss=2.396, loss_v1=0, loss_v2=0, nll_loss=1.197, ntokens=1025.1, nsentences=32, sample_size=1025.1, sample_size_v1=0, sample_size_v2=0, ppl=2.29, wps=544.2, ups=0.53, wpb=1025.1, bsz=32, num_updates=8490, lr=2.66998e-05, gnorm=2.331, clip=100, loss_scale=256, train_wall=19, gb_free=11.7, wall=15950
2023-05-26 03:49:14 - progress_bar.py[line:272] - INFO: epoch 005:   1585 / 1732 loss=2.395, loss_v1=0, loss_v2=0, nll_loss=1.198, ntokens=1049.1, nsentences=32, sample_size=1049.1, sample_size_v1=0, sample_size_v2=0, ppl=2.29, wps=554.6, ups=0.53, wpb=1049.1, bsz=32, num_updates=8500, lr=2.66937e-05, gnorm=2.193, clip=100, loss_scale=256, train_wall=19, gb_free=10.6, wall=15969
2023-05-26 03:49:33 - progress_bar.py[line:272] - INFO: epoch 005:   1595 / 1732 loss=2.359, loss_v1=0, loss_v2=0, nll_loss=1.155, ntokens=1072.1, nsentences=32, sample_size=1072.1, sample_size_v1=0, sample_size_v2=0, ppl=2.23, wps=568.9, ups=0.53, wpb=1072.1, bsz=32, num_updates=8510, lr=2.66875e-05, gnorm=2.008, clip=100, loss_scale=256, train_wall=19, gb_free=11, wall=15988
2023-05-26 03:49:52 - progress_bar.py[line:272] - INFO: epoch 005:   1605 / 1732 loss=2.366, loss_v1=0, loss_v2=0, nll_loss=1.165, ntokens=1099, nsentences=32, sample_size=1099, sample_size_v1=0, sample_size_v2=0, ppl=2.24, wps=584.7, ups=0.53, wpb=1099, bsz=32, num_updates=8520, lr=2.66814e-05, gnorm=1.901, clip=100, loss_scale=256, train_wall=19, gb_free=11.2, wall=16007
2023-05-26 03:50:11 - progress_bar.py[line:272] - INFO: epoch 005:   1615 / 1732 loss=2.33, loss_v1=0, loss_v2=0, nll_loss=1.124, ntokens=1176.8, nsentences=32, sample_size=1176.8, sample_size_v1=0, sample_size_v2=0, ppl=2.18, wps=618.4, ups=0.53, wpb=1176.8, bsz=32, num_updates=8530, lr=2.66753e-05, gnorm=1.956, clip=100, loss_scale=256, train_wall=19, gb_free=11.4, wall=16026
2023-05-26 03:50:30 - progress_bar.py[line:272] - INFO: epoch 005:   1625 / 1732 loss=2.374, loss_v1=0, loss_v2=0, nll_loss=1.174, ntokens=1075.4, nsentences=32, sample_size=1075.4, sample_size_v1=0, sample_size_v2=0, ppl=2.26, wps=569, ups=0.53, wpb=1075.4, bsz=32, num_updates=8540, lr=2.66691e-05, gnorm=2.254, clip=100, loss_scale=256, train_wall=19, gb_free=10.6, wall=16044
2023-05-26 03:50:49 - progress_bar.py[line:272] - INFO: epoch 005:   1635 / 1732 loss=2.341, loss_v1=0, loss_v2=0, nll_loss=1.136, ntokens=1182.6, nsentences=32, sample_size=1182.6, sample_size_v1=0, sample_size_v2=0, ppl=2.2, wps=627.1, ups=0.53, wpb=1182.6, bsz=32, num_updates=8550, lr=2.6663e-05, gnorm=2.035, clip=100, loss_scale=256, train_wall=19, gb_free=10.6, wall=16063
2023-05-26 03:51:08 - progress_bar.py[line:272] - INFO: epoch 005:   1645 / 1732 loss=2.324, loss_v1=0, loss_v2=0, nll_loss=1.118, ntokens=1274.6, nsentences=32, sample_size=1274.6, sample_size_v1=0, sample_size_v2=0, ppl=2.17, wps=669.3, ups=0.53, wpb=1274.6, bsz=32, num_updates=8560, lr=2.66568e-05, gnorm=1.811, clip=100, loss_scale=256, train_wall=19, gb_free=11, wall=16082
2023-05-26 03:51:26 - progress_bar.py[line:272] - INFO: epoch 005:   1655 / 1732 loss=2.394, loss_v1=0, loss_v2=0, nll_loss=1.198, ntokens=951.7, nsentences=32, sample_size=951.7, sample_size_v1=0, sample_size_v2=0, ppl=2.29, wps=509.2, ups=0.54, wpb=951.7, bsz=32, num_updates=8570, lr=2.66507e-05, gnorm=2.508, clip=100, loss_scale=256, train_wall=19, gb_free=11.2, wall=16101
2023-05-26 03:51:45 - progress_bar.py[line:272] - INFO: epoch 005:   1665 / 1732 loss=2.397, loss_v1=0, loss_v2=0, nll_loss=1.196, ntokens=1028.1, nsentences=32, sample_size=1028.1, sample_size_v1=0, sample_size_v2=0, ppl=2.29, wps=545.9, ups=0.53, wpb=1028.1, bsz=32, num_updates=8580, lr=2.66446e-05, gnorm=2.27, clip=100, loss_scale=256, train_wall=19, gb_free=11, wall=16120
2023-05-26 03:52:04 - progress_bar.py[line:272] - INFO: epoch 005:   1675 / 1732 loss=2.327, loss_v1=0, loss_v2=0, nll_loss=1.122, ntokens=1102.6, nsentences=32, sample_size=1102.6, sample_size_v1=0, sample_size_v2=0, ppl=2.18, wps=586.9, ups=0.53, wpb=1102.6, bsz=32, num_updates=8590, lr=2.66384e-05, gnorm=2.193, clip=100, loss_scale=256, train_wall=19, gb_free=9.9, wall=16139
2023-05-26 03:52:23 - progress_bar.py[line:272] - INFO: epoch 005:   1685 / 1732 loss=2.334, loss_v1=0, loss_v2=0, nll_loss=1.13, ntokens=1141.1, nsentences=32, sample_size=1141.1, sample_size_v1=0, sample_size_v2=0, ppl=2.19, wps=602, ups=0.53, wpb=1141.1, bsz=32, num_updates=8600, lr=2.66323e-05, gnorm=2.021, clip=100, loss_scale=256, train_wall=19, gb_free=11.4, wall=16158
2023-05-26 03:52:42 - progress_bar.py[line:272] - INFO: epoch 005:   1695 / 1732 loss=2.363, loss_v1=0, loss_v2=0, nll_loss=1.161, ntokens=1274.5, nsentences=32, sample_size=1274.5, sample_size_v1=0, sample_size_v2=0, ppl=2.24, wps=662, ups=0.52, wpb=1274.5, bsz=32, num_updates=8610, lr=2.66261e-05, gnorm=1.847, clip=100, loss_scale=256, train_wall=19, gb_free=11.2, wall=16177
2023-05-26 03:53:01 - progress_bar.py[line:272] - INFO: epoch 005:   1705 / 1732 loss=2.353, loss_v1=0, loss_v2=0, nll_loss=1.15, ntokens=1217, nsentences=32, sample_size=1217, sample_size_v1=0, sample_size_v2=0, ppl=2.22, wps=637.4, ups=0.52, wpb=1217, bsz=32, num_updates=8620, lr=2.662e-05, gnorm=1.963, clip=100, loss_scale=256, train_wall=19, gb_free=10.8, wall=16196
2023-05-26 03:53:20 - progress_bar.py[line:272] - INFO: epoch 005:   1715 / 1732 loss=2.343, loss_v1=0, loss_v2=0, nll_loss=1.139, ntokens=1196, nsentences=32, sample_size=1196, sample_size_v1=0, sample_size_v2=0, ppl=2.2, wps=630.5, ups=0.53, wpb=1196, bsz=32, num_updates=8630, lr=2.66138e-05, gnorm=2.035, clip=100, loss_scale=256, train_wall=19, gb_free=10.8, wall=16215
2023-05-26 03:53:39 - progress_bar.py[line:272] - INFO: epoch 005:   1725 / 1732 loss=2.371, loss_v1=0, loss_v2=0, nll_loss=1.172, ntokens=1108.9, nsentences=32, sample_size=1108.9, sample_size_v1=0, sample_size_v2=0, ppl=2.25, wps=585.1, ups=0.53, wpb=1108.9, bsz=32, num_updates=8640, lr=2.66077e-05, gnorm=2.055, clip=100, loss_scale=256, train_wall=19, gb_free=11.3, wall=16234
2023-05-26 03:53:51 - train.py[line:332] - INFO: end of epoch 5 (average epoch stats below)
2023-05-26 03:53:51 - progress_bar.py[line:282] - INFO: epoch 005 | loss 2.385 | loss_v1 0 | loss_v2 0 | nll_loss 1.186 | ntokens 1051.68 | nsentences 31.986 | sample_size 1051.68 | sample_size_v1 0 | sample_size_v2 0 | ppl 2.28 | wps 560.1 | ups 0.53 | wpb 1051.7 | bsz 32 | num_updates 8647 | lr 2.66034e-05 | gnorm 2.11 | clip 100 | loss_scale 256 | train_wall 3238 | gb_free 11.7 | wall 16246
2023-05-26 03:53:51 - trainer.py[line:639] - INFO: loading train data for epoch 6
local datafile ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 0 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 0 finished initializing row_count and line_idx-to-offset mapping
file ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 0 row count 55400 total row count 55400
slice_id 0 seek offset 0
2023-05-26 03:53:53 - trainer.py[line:703] - INFO: begin training epoch 6
2023-05-26 03:53:53 - train.py[line:305] - INFO: Start iterating over samples
2023-05-26 03:53:59 - progress_bar.py[line:272] - INFO: epoch 006:      3 / 1732 loss=2.385, loss_v1=0, loss_v2=0, nll_loss=1.184, ntokens=1127.6, nsentences=29.6, sample_size=1127.6, sample_size_v1=0, sample_size_v2=0, ppl=2.27, wps=572.2, ups=0.51, wpb=1127.6, bsz=29.6, num_updates=8650, lr=2.66016e-05, gnorm=2.314, clip=100, loss_scale=256, train_wall=18, gb_free=11, wall=16254
2023-05-26 03:54:18 - progress_bar.py[line:272] - INFO: epoch 006:     13 / 1732 loss=2.323, loss_v1=0, loss_v2=0, nll_loss=1.118, ntokens=1037.7, nsentences=32, sample_size=1037.7, sample_size_v1=0, sample_size_v2=0, ppl=2.17, wps=549.4, ups=0.53, wpb=1037.7, bsz=32, num_updates=8660, lr=2.65954e-05, gnorm=2.092, clip=100, loss_scale=256, train_wall=19, gb_free=11, wall=16273
2023-05-26 03:54:37 - progress_bar.py[line:272] - INFO: epoch 006:     23 / 1732 loss=2.258, loss_v1=0, loss_v2=0, nll_loss=1.044, ntokens=1082, nsentences=32, sample_size=1082, sample_size_v1=0, sample_size_v2=0, ppl=2.06, wps=575.1, ups=0.53, wpb=1082, bsz=32, num_updates=8670, lr=2.65893e-05, gnorm=1.784, clip=100, loss_scale=256, train_wall=19, gb_free=11.4, wall=16291
2023-05-26 03:54:56 - progress_bar.py[line:272] - INFO: epoch 006:     33 / 1732 loss=2.256, loss_v1=0, loss_v2=0, nll_loss=1.04, ntokens=1032.3, nsentences=32, sample_size=1032.3, sample_size_v1=0, sample_size_v2=0, ppl=2.06, wps=545, ups=0.53, wpb=1032.3, bsz=32, num_updates=8680, lr=2.65831e-05, gnorm=2.072, clip=100, loss_scale=256, train_wall=19, gb_free=10.2, wall=16310
2023-05-26 03:55:11 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 256.0
2023-05-26 03:55:16 - progress_bar.py[line:272] - INFO: epoch 006:     44 / 1732 loss=2.177, loss_v1=0, loss_v2=0, nll_loss=0.956, ntokens=1152.3, nsentences=32, sample_size=1152.3, sample_size_v1=0, sample_size_v2=0, ppl=1.94, wps=555.8, ups=0.48, wpb=1152.3, bsz=32, num_updates=8690, lr=2.6577e-05, gnorm=1.813, clip=90, loss_scale=256, train_wall=21, gb_free=10.9, wall=16331
2023-05-26 03:55:35 - progress_bar.py[line:272] - INFO: epoch 006:     54 / 1732 loss=2.203, loss_v1=0, loss_v2=0, nll_loss=0.987, ntokens=1025.8, nsentences=32, sample_size=1025.8, sample_size_v1=0, sample_size_v2=0, ppl=1.98, wps=544.1, ups=0.53, wpb=1025.8, bsz=32, num_updates=8700, lr=2.65708e-05, gnorm=2.288, clip=100, loss_scale=256, train_wall=19, gb_free=11.2, wall=16350
2023-05-26 03:55:54 - progress_bar.py[line:272] - INFO: epoch 006:     64 / 1732 loss=2.024, loss_v1=0, loss_v2=0, nll_loss=0.783, ntokens=1253.8, nsentences=32, sample_size=1253.8, sample_size_v1=0, sample_size_v2=0, ppl=1.72, wps=657.9, ups=0.52, wpb=1253.8, bsz=32, num_updates=8710, lr=2.65647e-05, gnorm=1.412, clip=90, loss_scale=256, train_wall=19, gb_free=10.7, wall=16369
2023-05-26 03:56:14 - progress_bar.py[line:272] - INFO: epoch 006:     74 / 1732 loss=2.141, loss_v1=0, loss_v2=0, nll_loss=0.908, ntokens=1358.9, nsentences=32, sample_size=1358.9, sample_size_v1=0, sample_size_v2=0, ppl=1.88, wps=696.7, ups=0.51, wpb=1358.9, bsz=32, num_updates=8720, lr=2.65586e-05, gnorm=1.362, clip=100, loss_scale=256, train_wall=19, gb_free=10.3, wall=16388
2023-05-26 03:56:33 - progress_bar.py[line:272] - INFO: epoch 006:     84 / 1732 loss=2.186, loss_v1=0, loss_v2=0, nll_loss=0.969, ntokens=1166.6, nsentences=32, sample_size=1166.6, sample_size_v1=0, sample_size_v2=0, ppl=1.96, wps=607.3, ups=0.52, wpb=1166.6, bsz=32, num_updates=8730, lr=2.65524e-05, gnorm=1.796, clip=100, loss_scale=256, train_wall=19, gb_free=10.5, wall=16408
2023-05-26 03:56:52 - progress_bar.py[line:272] - INFO: epoch 006:     94 / 1732 loss=2.166, loss_v1=0, loss_v2=0, nll_loss=0.94, ntokens=1099.4, nsentences=32, sample_size=1099.4, sample_size_v1=0, sample_size_v2=0, ppl=1.92, wps=580.2, ups=0.53, wpb=1099.4, bsz=32, num_updates=8740, lr=2.65463e-05, gnorm=1.677, clip=100, loss_scale=256, train_wall=19, gb_free=11.6, wall=16427
2023-05-26 03:57:11 - progress_bar.py[line:272] - INFO: epoch 006:    104 / 1732 loss=2.347, loss_v1=0, loss_v2=0, nll_loss=1.146, ntokens=968, nsentences=32, sample_size=968, sample_size_v1=0, sample_size_v2=0, ppl=2.21, wps=517.2, ups=0.53, wpb=968, bsz=32, num_updates=8750, lr=2.65401e-05, gnorm=2.447, clip=100, loss_scale=256, train_wall=19, gb_free=11.3, wall=16445
2023-05-26 03:57:30 - progress_bar.py[line:272] - INFO: epoch 006:    114 / 1732 loss=2.403, loss_v1=0, loss_v2=0, nll_loss=1.206, ntokens=1043.8, nsentences=32, sample_size=1043.8, sample_size_v1=0, sample_size_v2=0, ppl=2.31, wps=550.9, ups=0.53, wpb=1043.8, bsz=32, num_updates=8760, lr=2.6534e-05, gnorm=2.242, clip=100, loss_scale=256, train_wall=19, gb_free=11.4, wall=16464
2023-05-26 03:57:49 - progress_bar.py[line:272] - INFO: epoch 006:    124 / 1732 loss=2.343, loss_v1=0, loss_v2=0, nll_loss=1.139, ntokens=1156.9, nsentences=32, sample_size=1156.9, sample_size_v1=0, sample_size_v2=0, ppl=2.2, wps=602.4, ups=0.52, wpb=1156.9, bsz=32, num_updates=8770, lr=2.65279e-05, gnorm=1.887, clip=100, loss_scale=256, train_wall=19, gb_free=10.8, wall=16484
2023-05-26 03:58:08 - progress_bar.py[line:272] - INFO: epoch 006:    134 / 1732 loss=2.292, loss_v1=0, loss_v2=0, nll_loss=1.081, ntokens=1187.1, nsentences=32, sample_size=1187.1, sample_size_v1=0, sample_size_v2=0, ppl=2.12, wps=621.7, ups=0.52, wpb=1187.1, bsz=32, num_updates=8780, lr=2.65217e-05, gnorm=1.719, clip=100, loss_scale=256, train_wall=19, gb_free=11.4, wall=16503
2023-05-26 03:58:27 - progress_bar.py[line:272] - INFO: epoch 006:    144 / 1732 loss=2.282, loss_v1=0, loss_v2=0, nll_loss=1.073, ntokens=1239.8, nsentences=32, sample_size=1239.8, sample_size_v1=0, sample_size_v2=0, ppl=2.1, wps=642.6, ups=0.52, wpb=1239.8, bsz=32, num_updates=8790, lr=2.65156e-05, gnorm=1.778, clip=100, loss_scale=256, train_wall=19, gb_free=10.5, wall=16522
2023-05-26 03:58:46 - progress_bar.py[line:272] - INFO: epoch 006:    154 / 1732 loss=2.29, loss_v1=0, loss_v2=0, nll_loss=1.08, ntokens=1177.9, nsentences=32, sample_size=1177.9, sample_size_v1=0, sample_size_v2=0, ppl=2.11, wps=613, ups=0.52, wpb=1177.9, bsz=32, num_updates=8800, lr=2.65094e-05, gnorm=1.682, clip=100, loss_scale=256, train_wall=19, gb_free=10.5, wall=16541
2023-05-26 03:59:05 - progress_bar.py[line:272] - INFO: epoch 006:    164 / 1732 loss=2.269, loss_v1=0, loss_v2=0, nll_loss=1.058, ntokens=1064.5, nsentences=32, sample_size=1064.5, sample_size_v1=0, sample_size_v2=0, ppl=2.08, wps=561.7, ups=0.53, wpb=1064.5, bsz=32, num_updates=8810, lr=2.65033e-05, gnorm=1.932, clip=100, loss_scale=256, train_wall=19, gb_free=10.2, wall=16560
2023-05-26 03:59:24 - progress_bar.py[line:272] - INFO: epoch 006:    174 / 1732 loss=2.299, loss_v1=0, loss_v2=0, nll_loss=1.089, ntokens=918.2, nsentences=32, sample_size=918.2, sample_size_v1=0, sample_size_v2=0, ppl=2.13, wps=488.9, ups=0.53, wpb=918.2, bsz=32, num_updates=8820, lr=2.64971e-05, gnorm=2.226, clip=100, loss_scale=256, train_wall=19, gb_free=11.3, wall=16579
2023-05-26 03:59:43 - progress_bar.py[line:272] - INFO: epoch 006:    184 / 1732 loss=2.248, loss_v1=0, loss_v2=0, nll_loss=1.034, ntokens=1196.7, nsentences=32, sample_size=1196.7, sample_size_v1=0, sample_size_v2=0, ppl=2.05, wps=626.5, ups=0.52, wpb=1196.7, bsz=32, num_updates=8830, lr=2.6491e-05, gnorm=1.689, clip=100, loss_scale=256, train_wall=19, gb_free=11.2, wall=16598
2023-05-26 04:00:02 - progress_bar.py[line:272] - INFO: epoch 006:    194 / 1732 loss=2.272, loss_v1=0, loss_v2=0, nll_loss=1.059, ntokens=1132.8, nsentences=32, sample_size=1132.8, sample_size_v1=0, sample_size_v2=0, ppl=2.08, wps=594.5, ups=0.52, wpb=1132.8, bsz=32, num_updates=8840, lr=2.64849e-05, gnorm=1.923, clip=100, loss_scale=256, train_wall=19, gb_free=10.8, wall=16617
2023-05-26 04:00:21 - progress_bar.py[line:272] - INFO: epoch 006:    204 / 1732 loss=2.366, loss_v1=0, loss_v2=0, nll_loss=1.165, ntokens=1052.4, nsentences=32, sample_size=1052.4, sample_size_v1=0, sample_size_v2=0, ppl=2.24, wps=562, ups=0.53, wpb=1052.4, bsz=32, num_updates=8850, lr=2.64787e-05, gnorm=2.027, clip=100, loss_scale=256, train_wall=19, gb_free=11.1, wall=16636
2023-05-26 04:00:40 - progress_bar.py[line:272] - INFO: epoch 006:    214 / 1732 loss=2.394, loss_v1=0, loss_v2=0, nll_loss=1.195, ntokens=1074.9, nsentences=32, sample_size=1074.9, sample_size_v1=0, sample_size_v2=0, ppl=2.29, wps=572.9, ups=0.53, wpb=1074.9, bsz=32, num_updates=8860, lr=2.64726e-05, gnorm=1.935, clip=100, loss_scale=256, train_wall=19, gb_free=11.2, wall=16655
2023-05-26 04:00:59 - progress_bar.py[line:272] - INFO: epoch 006:    224 / 1732 loss=2.395, loss_v1=0, loss_v2=0, nll_loss=1.197, ntokens=1100.1, nsentences=32, sample_size=1100.1, sample_size_v1=0, sample_size_v2=0, ppl=2.29, wps=589.4, ups=0.54, wpb=1100.1, bsz=32, num_updates=8870, lr=2.64664e-05, gnorm=1.94, clip=100, loss_scale=256, train_wall=19, gb_free=11.3, wall=16673
2023-05-26 04:01:17 - progress_bar.py[line:272] - INFO: epoch 006:    234 / 1732 loss=2.436, loss_v1=0, loss_v2=0, nll_loss=1.243, ntokens=1090.7, nsentences=32, sample_size=1090.7, sample_size_v1=0, sample_size_v2=0, ppl=2.37, wps=583.7, ups=0.54, wpb=1090.7, bsz=32, num_updates=8880, lr=2.64603e-05, gnorm=2.039, clip=100, loss_scale=256, train_wall=19, gb_free=11.3, wall=16692
2023-05-26 04:01:36 - progress_bar.py[line:272] - INFO: epoch 006:    244 / 1732 loss=2.422, loss_v1=0, loss_v2=0, nll_loss=1.229, ntokens=1157.9, nsentences=32, sample_size=1157.9, sample_size_v1=0, sample_size_v2=0, ppl=2.34, wps=615.4, ups=0.53, wpb=1157.9, bsz=32, num_updates=8890, lr=2.64541e-05, gnorm=1.903, clip=100, loss_scale=256, train_wall=19, gb_free=10.7, wall=16711
2023-05-26 04:01:55 - progress_bar.py[line:272] - INFO: epoch 006:    254 / 1732 loss=2.416, loss_v1=0, loss_v2=0, nll_loss=1.221, ntokens=1151.4, nsentences=32, sample_size=1151.4, sample_size_v1=0, sample_size_v2=0, ppl=2.33, wps=612.5, ups=0.53, wpb=1151.4, bsz=32, num_updates=8900, lr=2.6448e-05, gnorm=1.845, clip=100, loss_scale=256, train_wall=19, gb_free=11.2, wall=16729
2023-05-26 04:02:14 - progress_bar.py[line:272] - INFO: epoch 006:    264 / 1732 loss=2.413, loss_v1=0, loss_v2=0, nll_loss=1.218, ntokens=1137.5, nsentences=32, sample_size=1137.5, sample_size_v1=0, sample_size_v2=0, ppl=2.33, wps=606.3, ups=0.53, wpb=1137.5, bsz=32, num_updates=8910, lr=2.64419e-05, gnorm=1.812, clip=100, loss_scale=256, train_wall=19, gb_free=10.7, wall=16748
2023-05-26 04:02:32 - progress_bar.py[line:272] - INFO: epoch 006:    274 / 1732 loss=2.397, loss_v1=0, loss_v2=0, nll_loss=1.2, ntokens=1136.4, nsentences=32, sample_size=1136.4, sample_size_v1=0, sample_size_v2=0, ppl=2.3, wps=602.5, ups=0.53, wpb=1136.4, bsz=32, num_updates=8920, lr=2.64357e-05, gnorm=1.938, clip=100, loss_scale=256, train_wall=19, gb_free=9.5, wall=16767
2023-05-26 04:02:51 - progress_bar.py[line:272] - INFO: epoch 006:    284 / 1732 loss=2.424, loss_v1=0, loss_v2=0, nll_loss=1.228, ntokens=1138.6, nsentences=32, sample_size=1138.6, sample_size_v1=0, sample_size_v2=0, ppl=2.34, wps=604.1, ups=0.53, wpb=1138.6, bsz=32, num_updates=8930, lr=2.64296e-05, gnorm=2.034, clip=100, loss_scale=256, train_wall=19, gb_free=11.2, wall=16786
2023-05-26 04:03:10 - progress_bar.py[line:272] - INFO: epoch 006:    294 / 1732 loss=2.386, loss_v1=0, loss_v2=0, nll_loss=1.19, ntokens=1144.7, nsentences=32, sample_size=1144.7, sample_size_v1=0, sample_size_v2=0, ppl=2.28, wps=609.7, ups=0.53, wpb=1144.7, bsz=32, num_updates=8940, lr=2.64234e-05, gnorm=2.035, clip=100, loss_scale=256, train_wall=19, gb_free=11.3, wall=16805
2023-05-26 04:03:29 - progress_bar.py[line:272] - INFO: epoch 006:    304 / 1732 loss=2.395, loss_v1=0, loss_v2=0, nll_loss=1.196, ntokens=1100.1, nsentences=32, sample_size=1100.1, sample_size_v1=0, sample_size_v2=0, ppl=2.29, wps=588.2, ups=0.53, wpb=1100.1, bsz=32, num_updates=8950, lr=2.64173e-05, gnorm=2.224, clip=100, loss_scale=256, train_wall=19, gb_free=11.4, wall=16823
2023-05-26 04:03:47 - progress_bar.py[line:272] - INFO: epoch 006:    314 / 1732 loss=2.398, loss_v1=0, loss_v2=0, nll_loss=1.201, ntokens=1016.6, nsentences=32, sample_size=1016.6, sample_size_v1=0, sample_size_v2=0, ppl=2.3, wps=546.8, ups=0.54, wpb=1016.6, bsz=32, num_updates=8960, lr=2.64112e-05, gnorm=2.202, clip=100, loss_scale=256, train_wall=19, gb_free=11.9, wall=16842
2023-05-26 04:04:06 - progress_bar.py[line:272] - INFO: epoch 006:    324 / 1732 loss=2.415, loss_v1=0, loss_v2=0, nll_loss=1.219, ntokens=1018.7, nsentences=32, sample_size=1018.7, sample_size_v1=0, sample_size_v2=0, ppl=2.33, wps=546.4, ups=0.54, wpb=1018.7, bsz=32, num_updates=8970, lr=2.6405e-05, gnorm=2.176, clip=100, loss_scale=256, train_wall=19, gb_free=11.3, wall=16861
2023-05-26 04:04:25 - progress_bar.py[line:272] - INFO: epoch 006:    334 / 1732 loss=2.418, loss_v1=0, loss_v2=0, nll_loss=1.225, ntokens=1018.9, nsentences=32, sample_size=1018.9, sample_size_v1=0, sample_size_v2=0, ppl=2.34, wps=550.7, ups=0.54, wpb=1018.9, bsz=32, num_updates=8980, lr=2.63989e-05, gnorm=2.217, clip=100, loss_scale=256, train_wall=18, gb_free=11.7, wall=16879
2023-05-26 04:04:43 - progress_bar.py[line:272] - INFO: epoch 006:    344 / 1732 loss=2.386, loss_v1=0, loss_v2=0, nll_loss=1.187, ntokens=921, nsentences=32, sample_size=921, sample_size_v1=0, sample_size_v2=0, ppl=2.28, wps=499.1, ups=0.54, wpb=921, bsz=32, num_updates=8990, lr=2.63927e-05, gnorm=2.409, clip=100, loss_scale=256, train_wall=18, gb_free=11.4, wall=16898
2023-05-26 04:05:02 - progress_bar.py[line:272] - INFO: epoch 006:    354 / 1732 loss=2.413, loss_v1=0, loss_v2=0, nll_loss=1.219, ntokens=961.9, nsentences=32, sample_size=961.9, sample_size_v1=0, sample_size_v2=0, ppl=2.33, wps=518.5, ups=0.54, wpb=961.9, bsz=32, num_updates=9000, lr=2.63866e-05, gnorm=2.299, clip=100, loss_scale=256, train_wall=19, gb_free=11.3, wall=16916
2023-05-26 04:05:20 - progress_bar.py[line:272] - INFO: epoch 006:    364 / 1732 loss=2.444, loss_v1=0, loss_v2=0, nll_loss=1.249, ntokens=927.9, nsentences=32, sample_size=927.9, sample_size_v1=0, sample_size_v2=0, ppl=2.38, wps=501.9, ups=0.54, wpb=927.9, bsz=32, num_updates=9010, lr=2.63804e-05, gnorm=2.285, clip=100, loss_scale=256, train_wall=18, gb_free=11.8, wall=16935
2023-05-26 04:05:39 - progress_bar.py[line:272] - INFO: epoch 006:    374 / 1732 loss=2.439, loss_v1=0, loss_v2=0, nll_loss=1.246, ntokens=1000.4, nsentences=32, sample_size=1000.4, sample_size_v1=0, sample_size_v2=0, ppl=2.37, wps=539.6, ups=0.54, wpb=1000.4, bsz=32, num_updates=9020, lr=2.63743e-05, gnorm=2.294, clip=100, loss_scale=256, train_wall=19, gb_free=11.5, wall=16953
2023-05-26 04:05:57 - progress_bar.py[line:272] - INFO: epoch 006:    384 / 1732 loss=2.424, loss_v1=0, loss_v2=0, nll_loss=1.23, ntokens=1084.8, nsentences=32, sample_size=1084.8, sample_size_v1=0, sample_size_v2=0, ppl=2.35, wps=584.6, ups=0.54, wpb=1084.8, bsz=32, num_updates=9030, lr=2.63682e-05, gnorm=2.284, clip=100, loss_scale=256, train_wall=19, gb_free=10.9, wall=16972
2023-05-26 04:06:16 - progress_bar.py[line:272] - INFO: epoch 006:    394 / 1732 loss=2.418, loss_v1=0, loss_v2=0, nll_loss=1.224, ntokens=950.6, nsentences=32, sample_size=950.6, sample_size_v1=0, sample_size_v2=0, ppl=2.34, wps=514.8, ups=0.54, wpb=950.6, bsz=32, num_updates=9040, lr=2.6362e-05, gnorm=2.272, clip=100, loss_scale=256, train_wall=18, gb_free=11.7, wall=16990
2023-05-26 04:06:34 - progress_bar.py[line:272] - INFO: epoch 006:    404 / 1732 loss=2.377, loss_v1=0, loss_v2=0, nll_loss=1.176, ntokens=1060.5, nsentences=32, sample_size=1060.5, sample_size_v1=0, sample_size_v2=0, ppl=2.26, wps=568.3, ups=0.54, wpb=1060.5, bsz=32, num_updates=9050, lr=2.63559e-05, gnorm=2.264, clip=100, loss_scale=256, train_wall=19, gb_free=11.1, wall=17009
2023-05-26 04:06:53 - progress_bar.py[line:272] - INFO: epoch 006:    414 / 1732 loss=2.384, loss_v1=0, loss_v2=0, nll_loss=1.187, ntokens=1066.1, nsentences=32, sample_size=1066.1, sample_size_v1=0, sample_size_v2=0, ppl=2.28, wps=570.6, ups=0.54, wpb=1066.1, bsz=32, num_updates=9060, lr=2.63497e-05, gnorm=1.972, clip=100, loss_scale=256, train_wall=19, gb_free=9.9, wall=17028
2023-05-26 04:07:12 - progress_bar.py[line:272] - INFO: epoch 006:    424 / 1732 loss=2.368, loss_v1=0, loss_v2=0, nll_loss=1.165, ntokens=992.6, nsentences=32, sample_size=992.6, sample_size_v1=0, sample_size_v2=0, ppl=2.24, wps=534.3, ups=0.54, wpb=992.6, bsz=32, num_updates=9070, lr=2.63436e-05, gnorm=2.087, clip=100, loss_scale=256, train_wall=19, gb_free=11.7, wall=17046
2023-05-26 04:07:30 - progress_bar.py[line:272] - INFO: epoch 006:    434 / 1732 loss=2.401, loss_v1=0, loss_v2=0, nll_loss=1.205, ntokens=1018.1, nsentences=32, sample_size=1018.1, sample_size_v1=0, sample_size_v2=0, ppl=2.3, wps=548, ups=0.54, wpb=1018.1, bsz=32, num_updates=9080, lr=2.63374e-05, gnorm=2.116, clip=100, loss_scale=256, train_wall=19, gb_free=11.8, wall=17065
2023-05-26 04:07:49 - progress_bar.py[line:272] - INFO: epoch 006:    444 / 1732 loss=2.423, loss_v1=0, loss_v2=0, nll_loss=1.228, ntokens=952.1, nsentences=32, sample_size=952.1, sample_size_v1=0, sample_size_v2=0, ppl=2.34, wps=513.9, ups=0.54, wpb=952.1, bsz=32, num_updates=9090, lr=2.63313e-05, gnorm=2.21, clip=100, loss_scale=256, train_wall=18, gb_free=11.7, wall=17083
2023-05-26 04:08:07 - progress_bar.py[line:272] - INFO: epoch 006:    454 / 1732 loss=2.419, loss_v1=0, loss_v2=0, nll_loss=1.226, ntokens=919.5, nsentences=32, sample_size=919.5, sample_size_v1=0, sample_size_v2=0, ppl=2.34, wps=497, ups=0.54, wpb=919.5, bsz=32, num_updates=9100, lr=2.63252e-05, gnorm=2.425, clip=100, loss_scale=256, train_wall=18, gb_free=11.4, wall=17102
2023-05-26 04:08:26 - progress_bar.py[line:272] - INFO: epoch 006:    464 / 1732 loss=2.425, loss_v1=0, loss_v2=0, nll_loss=1.228, ntokens=1076.9, nsentences=32, sample_size=1076.9, sample_size_v1=0, sample_size_v2=0, ppl=2.34, wps=577.3, ups=0.54, wpb=1076.9, bsz=32, num_updates=9110, lr=2.6319e-05, gnorm=2.243, clip=100, loss_scale=256, train_wall=19, gb_free=11.7, wall=17120
2023-05-26 04:08:45 - progress_bar.py[line:272] - INFO: epoch 006:    474 / 1732 loss=2.419, loss_v1=0, loss_v2=0, nll_loss=1.222, ntokens=1067.6, nsentences=32, sample_size=1067.6, sample_size_v1=0, sample_size_v2=0, ppl=2.33, wps=569.6, ups=0.53, wpb=1067.6, bsz=32, num_updates=9120, lr=2.63129e-05, gnorm=2.302, clip=100, loss_scale=256, train_wall=19, gb_free=11.8, wall=17139
2023-05-26 04:09:03 - progress_bar.py[line:272] - INFO: epoch 006:    484 / 1732 loss=2.41, loss_v1=0, loss_v2=0, nll_loss=1.214, ntokens=966.8, nsentences=32, sample_size=966.8, sample_size_v1=0, sample_size_v2=0, ppl=2.32, wps=523.1, ups=0.54, wpb=966.8, bsz=32, num_updates=9130, lr=2.63067e-05, gnorm=2.381, clip=100, loss_scale=256, train_wall=18, gb_free=11.6, wall=17158
2023-05-26 04:09:22 - progress_bar.py[line:272] - INFO: epoch 006:    494 / 1732 loss=2.407, loss_v1=0, loss_v2=0, nll_loss=1.213, ntokens=937.9, nsentences=32, sample_size=937.9, sample_size_v1=0, sample_size_v2=0, ppl=2.32, wps=503.9, ups=0.54, wpb=937.9, bsz=32, num_updates=9140, lr=2.63006e-05, gnorm=2.381, clip=100, loss_scale=256, train_wall=19, gb_free=11.3, wall=17176
2023-05-26 04:09:40 - progress_bar.py[line:272] - INFO: epoch 006:    504 / 1732 loss=2.411, loss_v1=0, loss_v2=0, nll_loss=1.214, ntokens=981, nsentences=32, sample_size=981, sample_size_v1=0, sample_size_v2=0, ppl=2.32, wps=532.9, ups=0.54, wpb=981, bsz=32, num_updates=9150, lr=2.62945e-05, gnorm=2.257, clip=100, loss_scale=256, train_wall=18, gb_free=11.4, wall=17195
2023-05-26 04:09:59 - progress_bar.py[line:272] - INFO: epoch 006:    514 / 1732 loss=2.423, loss_v1=0, loss_v2=0, nll_loss=1.229, ntokens=1052.2, nsentences=32, sample_size=1052.2, sample_size_v1=0, sample_size_v2=0, ppl=2.34, wps=566.3, ups=0.54, wpb=1052.2, bsz=32, num_updates=9160, lr=2.62883e-05, gnorm=2.206, clip=100, loss_scale=256, train_wall=19, gb_free=11.7, wall=17213
2023-05-26 04:10:17 - progress_bar.py[line:272] - INFO: epoch 006:    524 / 1732 loss=2.394, loss_v1=0, loss_v2=0, nll_loss=1.195, ntokens=980.8, nsentences=32, sample_size=980.8, sample_size_v1=0, sample_size_v2=0, ppl=2.29, wps=531.3, ups=0.54, wpb=980.8, bsz=32, num_updates=9170, lr=2.62822e-05, gnorm=2.41, clip=100, loss_scale=256, train_wall=18, gb_free=11.6, wall=17232
2023-05-26 04:10:36 - progress_bar.py[line:272] - INFO: epoch 006:    534 / 1732 loss=2.4, loss_v1=0, loss_v2=0, nll_loss=1.203, ntokens=944.9, nsentences=32, sample_size=944.9, sample_size_v1=0, sample_size_v2=0, ppl=2.3, wps=512.8, ups=0.54, wpb=944.9, bsz=32, num_updates=9180, lr=2.6276e-05, gnorm=2.377, clip=100, loss_scale=256, train_wall=18, gb_free=11.5, wall=17250
2023-05-26 04:10:54 - progress_bar.py[line:272] - INFO: epoch 006:    544 / 1732 loss=2.412, loss_v1=0, loss_v2=0, nll_loss=1.216, ntokens=998.9, nsentences=32, sample_size=998.9, sample_size_v1=0, sample_size_v2=0, ppl=2.32, wps=538.9, ups=0.54, wpb=998.9, bsz=32, num_updates=9190, lr=2.62699e-05, gnorm=2.203, clip=100, loss_scale=256, train_wall=19, gb_free=11.5, wall=17269
2023-05-26 04:11:13 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 256.0
2023-05-26 04:11:14 - progress_bar.py[line:272] - INFO: epoch 006:    555 / 1732 loss=2.445, loss_v1=0, loss_v2=0, nll_loss=1.253, ntokens=1037.5, nsentences=32, sample_size=1037.5, sample_size_v1=0, sample_size_v2=0, ppl=2.38, wps=509.4, ups=0.49, wpb=1037.5, bsz=32, num_updates=9200, lr=2.62637e-05, gnorm=2.229, clip=100, loss_scale=256, train_wall=20, gb_free=11.3, wall=17289
2023-05-26 04:11:33 - progress_bar.py[line:272] - INFO: epoch 006:    565 / 1732 loss=2.432, loss_v1=0, loss_v2=0, nll_loss=1.238, ntokens=1014, nsentences=32, sample_size=1014, sample_size_v1=0, sample_size_v2=0, ppl=2.36, wps=540.3, ups=0.53, wpb=1014, bsz=32, num_updates=9210, lr=2.62576e-05, gnorm=2.343, clip=100, loss_scale=256, train_wall=19, gb_free=11.2, wall=17308
2023-05-26 04:11:52 - progress_bar.py[line:272] - INFO: epoch 006:    575 / 1732 loss=2.416, loss_v1=0, loss_v2=0, nll_loss=1.22, ntokens=1007.3, nsentences=32, sample_size=1007.3, sample_size_v1=0, sample_size_v2=0, ppl=2.33, wps=539.3, ups=0.54, wpb=1007.3, bsz=32, num_updates=9220, lr=2.62515e-05, gnorm=2.373, clip=100, loss_scale=256, train_wall=19, gb_free=11.5, wall=17327
2023-05-26 04:12:11 - progress_bar.py[line:272] - INFO: epoch 006:    585 / 1732 loss=2.427, loss_v1=0, loss_v2=0, nll_loss=1.233, ntokens=980.6, nsentences=32, sample_size=980.6, sample_size_v1=0, sample_size_v2=0, ppl=2.35, wps=524.6, ups=0.54, wpb=980.6, bsz=32, num_updates=9230, lr=2.62453e-05, gnorm=2.452, clip=100, loss_scale=256, train_wall=19, gb_free=11.6, wall=17345
2023-05-26 04:12:29 - progress_bar.py[line:272] - INFO: epoch 006:    595 / 1732 loss=2.382, loss_v1=0, loss_v2=0, nll_loss=1.183, ntokens=961.9, nsentences=32, sample_size=961.9, sample_size_v1=0, sample_size_v2=0, ppl=2.27, wps=516.6, ups=0.54, wpb=961.9, bsz=32, num_updates=9240, lr=2.62392e-05, gnorm=2.533, clip=100, loss_scale=256, train_wall=19, gb_free=11.6, wall=17364
2023-05-26 04:12:48 - progress_bar.py[line:272] - INFO: epoch 006:    605 / 1732 loss=2.383, loss_v1=0, loss_v2=0, nll_loss=1.186, ntokens=879.8, nsentences=32, sample_size=879.8, sample_size_v1=0, sample_size_v2=0, ppl=2.28, wps=479.1, ups=0.54, wpb=879.8, bsz=32, num_updates=9250, lr=2.6233e-05, gnorm=2.656, clip=100, loss_scale=256, train_wall=18, gb_free=12, wall=17382
2023-05-26 04:13:06 - progress_bar.py[line:272] - INFO: epoch 006:    615 / 1732 loss=2.418, loss_v1=0, loss_v2=0, nll_loss=1.221, ntokens=903.1, nsentences=32, sample_size=903.1, sample_size_v1=0, sample_size_v2=0, ppl=2.33, wps=487.2, ups=0.54, wpb=903.1, bsz=32, num_updates=9260, lr=2.62269e-05, gnorm=2.716, clip=100, loss_scale=256, train_wall=19, gb_free=11.7, wall=17401
2023-05-26 04:13:25 - progress_bar.py[line:272] - INFO: epoch 006:    625 / 1732 loss=2.417, loss_v1=0, loss_v2=0, nll_loss=1.222, ntokens=898.6, nsentences=32, sample_size=898.6, sample_size_v1=0, sample_size_v2=0, ppl=2.33, wps=489.1, ups=0.54, wpb=898.6, bsz=32, num_updates=9270, lr=2.62207e-05, gnorm=2.627, clip=100, loss_scale=256, train_wall=18, gb_free=11.4, wall=17419
2023-05-26 04:13:43 - progress_bar.py[line:272] - INFO: epoch 006:    635 / 1732 loss=2.419, loss_v1=0, loss_v2=0, nll_loss=1.226, ntokens=897.1, nsentences=32, sample_size=897.1, sample_size_v1=0, sample_size_v2=0, ppl=2.34, wps=489, ups=0.55, wpb=897.1, bsz=32, num_updates=9280, lr=2.62146e-05, gnorm=2.564, clip=100, loss_scale=256, train_wall=18, gb_free=11.8, wall=17438
2023-05-26 04:14:01 - progress_bar.py[line:272] - INFO: epoch 006:    645 / 1732 loss=2.415, loss_v1=0, loss_v2=0, nll_loss=1.217, ntokens=1010.4, nsentences=32, sample_size=1010.4, sample_size_v1=0, sample_size_v2=0, ppl=2.32, wps=545.2, ups=0.54, wpb=1010.4, bsz=32, num_updates=9290, lr=2.62085e-05, gnorm=2.253, clip=100, loss_scale=256, train_wall=19, gb_free=11.8, wall=17456
2023-05-26 04:14:20 - progress_bar.py[line:272] - INFO: epoch 006:    655 / 1732 loss=2.419, loss_v1=0, loss_v2=0, nll_loss=1.225, ntokens=879.8, nsentences=32, sample_size=879.8, sample_size_v1=0, sample_size_v2=0, ppl=2.34, wps=480.2, ups=0.55, wpb=879.8, bsz=32, num_updates=9300, lr=2.62023e-05, gnorm=2.5, clip=100, loss_scale=256, train_wall=18, gb_free=11.8, wall=17474
2023-05-26 04:14:38 - progress_bar.py[line:272] - INFO: epoch 006:    665 / 1732 loss=2.418, loss_v1=0, loss_v2=0, nll_loss=1.224, ntokens=893.8, nsentences=32, sample_size=893.8, sample_size_v1=0, sample_size_v2=0, ppl=2.34, wps=488.4, ups=0.55, wpb=893.8, bsz=32, num_updates=9310, lr=2.61962e-05, gnorm=2.626, clip=100, loss_scale=256, train_wall=18, gb_free=12, wall=17493
2023-05-26 04:14:57 - progress_bar.py[line:272] - INFO: epoch 006:    675 / 1732 loss=2.424, loss_v1=0, loss_v2=0, nll_loss=1.23, ntokens=961.9, nsentences=32, sample_size=961.9, sample_size_v1=0, sample_size_v2=0, ppl=2.35, wps=519.3, ups=0.54, wpb=961.9, bsz=32, num_updates=9320, lr=2.619e-05, gnorm=2.552, clip=100, loss_scale=256, train_wall=18, gb_free=10.9, wall=17511
2023-05-26 04:15:15 - progress_bar.py[line:272] - INFO: epoch 006:    685 / 1732 loss=2.412, loss_v1=0, loss_v2=0, nll_loss=1.216, ntokens=961.5, nsentences=32, sample_size=961.5, sample_size_v1=0, sample_size_v2=0, ppl=2.32, wps=522, ups=0.54, wpb=961.5, bsz=32, num_updates=9330, lr=2.61839e-05, gnorm=2.613, clip=100, loss_scale=256, train_wall=18, gb_free=11.5, wall=17530
2023-05-26 04:15:34 - progress_bar.py[line:272] - INFO: epoch 006:    695 / 1732 loss=2.424, loss_v1=0, loss_v2=0, nll_loss=1.232, ntokens=1007.2, nsentences=32, sample_size=1007.2, sample_size_v1=0, sample_size_v2=0, ppl=2.35, wps=538.3, ups=0.53, wpb=1007.2, bsz=32, num_updates=9340, lr=2.61778e-05, gnorm=2.372, clip=100, loss_scale=256, train_wall=19, gb_free=10.5, wall=17548
2023-05-26 04:15:52 - progress_bar.py[line:272] - INFO: epoch 006:    705 / 1732 loss=2.384, loss_v1=0, loss_v2=0, nll_loss=1.179, ntokens=925.6, nsentences=32, sample_size=925.6, sample_size_v1=0, sample_size_v2=0, ppl=2.26, wps=501.7, ups=0.54, wpb=925.6, bsz=32, num_updates=9350, lr=2.61716e-05, gnorm=2.454, clip=100, loss_scale=256, train_wall=18, gb_free=11.8, wall=17567
2023-05-26 04:16:11 - progress_bar.py[line:272] - INFO: epoch 006:    715 / 1732 loss=2.417, loss_v1=0, loss_v2=0, nll_loss=1.225, ntokens=890.5, nsentences=32, sample_size=890.5, sample_size_v1=0, sample_size_v2=0, ppl=2.34, wps=483.6, ups=0.54, wpb=890.5, bsz=32, num_updates=9360, lr=2.61655e-05, gnorm=2.545, clip=100, loss_scale=256, train_wall=18, gb_free=11.7, wall=17585
2023-05-26 04:16:29 - progress_bar.py[line:272] - INFO: epoch 006:    725 / 1732 loss=2.377, loss_v1=0, loss_v2=0, nll_loss=1.179, ntokens=904.8, nsentences=32, sample_size=904.8, sample_size_v1=0, sample_size_v2=0, ppl=2.26, wps=491.5, ups=0.54, wpb=904.8, bsz=32, num_updates=9370, lr=2.61593e-05, gnorm=2.601, clip=100, loss_scale=256, train_wall=18, gb_free=11.5, wall=17604
2023-05-26 04:16:47 - progress_bar.py[line:272] - INFO: epoch 006:    735 / 1732 loss=2.398, loss_v1=0, loss_v2=0, nll_loss=1.199, ntokens=965.8, nsentences=32, sample_size=965.8, sample_size_v1=0, sample_size_v2=0, ppl=2.3, wps=524.8, ups=0.54, wpb=965.8, bsz=32, num_updates=9380, lr=2.61532e-05, gnorm=2.388, clip=100, loss_scale=256, train_wall=18, gb_free=11.6, wall=17622
2023-05-26 04:17:06 - progress_bar.py[line:272] - INFO: epoch 006:    745 / 1732 loss=2.377, loss_v1=0, loss_v2=0, nll_loss=1.176, ntokens=978.3, nsentences=32, sample_size=978.3, sample_size_v1=0, sample_size_v2=0, ppl=2.26, wps=527.7, ups=0.54, wpb=978.3, bsz=32, num_updates=9390, lr=2.6147e-05, gnorm=2.457, clip=100, loss_scale=256, train_wall=19, gb_free=11.1, wall=17641
2023-05-26 04:17:25 - progress_bar.py[line:272] - INFO: epoch 006:    755 / 1732 loss=2.397, loss_v1=0, loss_v2=0, nll_loss=1.2, ntokens=975.4, nsentences=32, sample_size=975.4, sample_size_v1=0, sample_size_v2=0, ppl=2.3, wps=525.7, ups=0.54, wpb=975.4, bsz=32, num_updates=9400, lr=2.61409e-05, gnorm=2.538, clip=100, loss_scale=256, train_wall=19, gb_free=11.7, wall=17659
2023-05-26 04:17:43 - progress_bar.py[line:272] - INFO: epoch 006:    765 / 1732 loss=2.385, loss_v1=0, loss_v2=0, nll_loss=1.189, ntokens=948.8, nsentences=32, sample_size=948.8, sample_size_v1=0, sample_size_v2=0, ppl=2.28, wps=512.6, ups=0.54, wpb=948.8, bsz=32, num_updates=9410, lr=2.61348e-05, gnorm=2.451, clip=100, loss_scale=256, train_wall=18, gb_free=10.9, wall=17678
2023-05-26 04:18:02 - progress_bar.py[line:272] - INFO: epoch 006:    775 / 1732 loss=2.402, loss_v1=0, loss_v2=0, nll_loss=1.203, ntokens=1002.4, nsentences=32, sample_size=1002.4, sample_size_v1=0, sample_size_v2=0, ppl=2.3, wps=542.4, ups=0.54, wpb=1002.4, bsz=32, num_updates=9420, lr=2.61286e-05, gnorm=2.53, clip=100, loss_scale=256, train_wall=18, gb_free=11.5, wall=17696
2023-05-26 04:18:20 - progress_bar.py[line:272] - INFO: epoch 006:    785 / 1732 loss=2.398, loss_v1=0, loss_v2=0, nll_loss=1.202, ntokens=1003.9, nsentences=32, sample_size=1003.9, sample_size_v1=0, sample_size_v2=0, ppl=2.3, wps=542.2, ups=0.54, wpb=1003.9, bsz=32, num_updates=9430, lr=2.61225e-05, gnorm=2.45, clip=100, loss_scale=256, train_wall=18, gb_free=11.2, wall=17715
2023-05-26 04:18:38 - progress_bar.py[line:272] - INFO: epoch 006:    795 / 1732 loss=2.406, loss_v1=0, loss_v2=0, nll_loss=1.211, ntokens=1051.8, nsentences=32, sample_size=1051.8, sample_size_v1=0, sample_size_v2=0, ppl=2.31, wps=569.5, ups=0.54, wpb=1051.8, bsz=32, num_updates=9440, lr=2.61163e-05, gnorm=2.438, clip=100, loss_scale=256, train_wall=18, gb_free=11.1, wall=17733
2023-05-26 04:18:57 - progress_bar.py[line:272] - INFO: epoch 006:    805 / 1732 loss=2.398, loss_v1=0, loss_v2=0, nll_loss=1.197, ntokens=913, nsentences=32, sample_size=913, sample_size_v1=0, sample_size_v2=0, ppl=2.29, wps=494.3, ups=0.54, wpb=913, bsz=32, num_updates=9450, lr=2.61102e-05, gnorm=2.55, clip=100, loss_scale=256, train_wall=18, gb_free=11.1, wall=17752
2023-05-26 04:19:15 - progress_bar.py[line:272] - INFO: epoch 006:    815 / 1732 loss=2.392, loss_v1=0, loss_v2=0, nll_loss=1.195, ntokens=936.3, nsentences=32, sample_size=936.3, sample_size_v1=0, sample_size_v2=0, ppl=2.29, wps=508.2, ups=0.54, wpb=936.3, bsz=32, num_updates=9460, lr=2.6104e-05, gnorm=2.444, clip=100, loss_scale=256, train_wall=18, gb_free=11.7, wall=17770
2023-05-26 04:19:34 - progress_bar.py[line:272] - INFO: epoch 006:    825 / 1732 loss=2.405, loss_v1=0, loss_v2=0, nll_loss=1.208, ntokens=931.3, nsentences=32, sample_size=931.3, sample_size_v1=0, sample_size_v2=0, ppl=2.31, wps=503, ups=0.54, wpb=931.3, bsz=32, num_updates=9470, lr=2.60979e-05, gnorm=2.57, clip=100, loss_scale=256, train_wall=18, gb_free=12, wall=17789
2023-05-26 04:19:52 - progress_bar.py[line:272] - INFO: epoch 006:    835 / 1732 loss=2.402, loss_v1=0, loss_v2=0, nll_loss=1.206, ntokens=897.4, nsentences=32, sample_size=897.4, sample_size_v1=0, sample_size_v2=0, ppl=2.31, wps=489.3, ups=0.55, wpb=897.4, bsz=32, num_updates=9480, lr=2.60918e-05, gnorm=2.472, clip=100, loss_scale=256, train_wall=18, gb_free=11.6, wall=17807
2023-05-26 04:20:11 - progress_bar.py[line:272] - INFO: epoch 006:    845 / 1732 loss=2.379, loss_v1=0, loss_v2=0, nll_loss=1.177, ntokens=987.4, nsentences=32, sample_size=987.4, sample_size_v1=0, sample_size_v2=0, ppl=2.26, wps=536.9, ups=0.54, wpb=987.4, bsz=32, num_updates=9490, lr=2.60856e-05, gnorm=2.561, clip=100, loss_scale=256, train_wall=18, gb_free=11.2, wall=17825
2023-05-26 04:20:29 - progress_bar.py[line:272] - INFO: epoch 006:    855 / 1732 loss=2.395, loss_v1=0, loss_v2=0, nll_loss=1.201, ntokens=952, nsentences=32, sample_size=952, sample_size_v1=0, sample_size_v2=0, ppl=2.3, wps=515.3, ups=0.54, wpb=952, bsz=32, num_updates=9500, lr=2.60795e-05, gnorm=2.512, clip=100, loss_scale=256, train_wall=18, gb_free=11.8, wall=17844
2023-05-26 04:20:48 - progress_bar.py[line:272] - INFO: epoch 006:    865 / 1732 loss=2.408, loss_v1=0, loss_v2=0, nll_loss=1.211, ntokens=968.1, nsentences=32, sample_size=968.1, sample_size_v1=0, sample_size_v2=0, ppl=2.31, wps=523.1, ups=0.54, wpb=968.1, bsz=32, num_updates=9510, lr=2.60733e-05, gnorm=2.547, clip=100, loss_scale=256, train_wall=18, gb_free=11.5, wall=17862
2023-05-26 04:21:06 - progress_bar.py[line:272] - INFO: epoch 006:    875 / 1732 loss=2.368, loss_v1=0, loss_v2=0, nll_loss=1.168, ntokens=985.7, nsentences=32, sample_size=985.7, sample_size_v1=0, sample_size_v2=0, ppl=2.25, wps=532.7, ups=0.54, wpb=985.7, bsz=32, num_updates=9520, lr=2.60672e-05, gnorm=2.437, clip=100, loss_scale=256, train_wall=18, gb_free=11.4, wall=17881
2023-05-26 04:21:25 - progress_bar.py[line:272] - INFO: epoch 006:    885 / 1732 loss=2.344, loss_v1=0, loss_v2=0, nll_loss=1.14, ntokens=961.4, nsentences=32, sample_size=961.4, sample_size_v1=0, sample_size_v2=0, ppl=2.2, wps=518.8, ups=0.54, wpb=961.4, bsz=32, num_updates=9530, lr=2.60611e-05, gnorm=2.433, clip=100, loss_scale=256, train_wall=19, gb_free=11.4, wall=17899
2023-05-26 04:21:43 - progress_bar.py[line:272] - INFO: epoch 006:    895 / 1732 loss=2.343, loss_v1=0, loss_v2=0, nll_loss=1.138, ntokens=1031.3, nsentences=32, sample_size=1031.3, sample_size_v1=0, sample_size_v2=0, ppl=2.2, wps=556.3, ups=0.54, wpb=1031.3, bsz=32, num_updates=9540, lr=2.60549e-05, gnorm=2.226, clip=100, loss_scale=256, train_wall=19, gb_free=11.7, wall=17918
2023-05-26 04:22:02 - progress_bar.py[line:272] - INFO: epoch 006:    905 / 1732 loss=2.346, loss_v1=0, loss_v2=0, nll_loss=1.144, ntokens=1040.4, nsentences=32, sample_size=1040.4, sample_size_v1=0, sample_size_v2=0, ppl=2.21, wps=559.9, ups=0.54, wpb=1040.4, bsz=32, num_updates=9550, lr=2.60488e-05, gnorm=2.256, clip=100, loss_scale=256, train_wall=19, gb_free=11.1, wall=17936
2023-05-26 04:22:20 - progress_bar.py[line:272] - INFO: epoch 006:    915 / 1732 loss=2.42, loss_v1=0, loss_v2=0, nll_loss=1.224, ntokens=937.6, nsentences=32, sample_size=937.6, sample_size_v1=0, sample_size_v2=0, ppl=2.34, wps=509, ups=0.54, wpb=937.6, bsz=32, num_updates=9560, lr=2.60426e-05, gnorm=2.596, clip=100, loss_scale=256, train_wall=18, gb_free=12, wall=17955
2023-05-26 04:22:39 - progress_bar.py[line:272] - INFO: epoch 006:    925 / 1732 loss=2.359, loss_v1=0, loss_v2=0, nll_loss=1.158, ntokens=1005.1, nsentences=32, sample_size=1005.1, sample_size_v1=0, sample_size_v2=0, ppl=2.23, wps=537.4, ups=0.53, wpb=1005.1, bsz=32, num_updates=9570, lr=2.60365e-05, gnorm=2.482, clip=100, loss_scale=256, train_wall=19, gb_free=11.8, wall=17974
2023-05-26 04:22:58 - progress_bar.py[line:272] - INFO: epoch 006:    935 / 1732 loss=2.373, loss_v1=0, loss_v2=0, nll_loss=1.174, ntokens=1058.5, nsentences=32, sample_size=1058.5, sample_size_v1=0, sample_size_v2=0, ppl=2.26, wps=565.7, ups=0.53, wpb=1058.5, bsz=32, num_updates=9580, lr=2.60303e-05, gnorm=2.389, clip=100, loss_scale=256, train_wall=19, gb_free=11.3, wall=17992
2023-05-26 04:23:17 - progress_bar.py[line:272] - INFO: epoch 006:    945 / 1732 loss=2.394, loss_v1=0, loss_v2=0, nll_loss=1.196, ntokens=1055.4, nsentences=32, sample_size=1055.4, sample_size_v1=0, sample_size_v2=0, ppl=2.29, wps=559.8, ups=0.53, wpb=1055.4, bsz=32, num_updates=9590, lr=2.60242e-05, gnorm=2.264, clip=100, loss_scale=256, train_wall=19, gb_free=11.2, wall=18011
2023-05-26 04:23:35 - progress_bar.py[line:272] - INFO: epoch 006:    955 / 1732 loss=2.38, loss_v1=0, loss_v2=0, nll_loss=1.182, ntokens=1040.2, nsentences=32, sample_size=1040.2, sample_size_v1=0, sample_size_v2=0, ppl=2.27, wps=555.7, ups=0.53, wpb=1040.2, bsz=32, num_updates=9600, lr=2.60181e-05, gnorm=2.407, clip=100, loss_scale=256, train_wall=19, gb_free=11.4, wall=18030
2023-05-26 04:23:54 - progress_bar.py[line:272] - INFO: epoch 006:    965 / 1732 loss=2.387, loss_v1=0, loss_v2=0, nll_loss=1.188, ntokens=1047.7, nsentences=32, sample_size=1047.7, sample_size_v1=0, sample_size_v2=0, ppl=2.28, wps=559.7, ups=0.53, wpb=1047.7, bsz=32, num_updates=9610, lr=2.60119e-05, gnorm=2.601, clip=100, loss_scale=256, train_wall=19, gb_free=11.4, wall=18049
2023-05-26 04:24:13 - progress_bar.py[line:272] - INFO: epoch 006:    975 / 1732 loss=2.385, loss_v1=0, loss_v2=0, nll_loss=1.188, ntokens=1038, nsentences=32, sample_size=1038, sample_size_v1=0, sample_size_v2=0, ppl=2.28, wps=552.6, ups=0.53, wpb=1038, bsz=32, num_updates=9620, lr=2.60058e-05, gnorm=2.388, clip=100, loss_scale=256, train_wall=19, gb_free=11.6, wall=18067
2023-05-26 04:24:32 - progress_bar.py[line:272] - INFO: epoch 006:    985 / 1732 loss=2.388, loss_v1=0, loss_v2=0, nll_loss=1.188, ntokens=1034.6, nsentences=32, sample_size=1034.6, sample_size_v1=0, sample_size_v2=0, ppl=2.28, wps=548.9, ups=0.53, wpb=1034.6, bsz=32, num_updates=9630, lr=2.59996e-05, gnorm=2.416, clip=100, loss_scale=256, train_wall=19, gb_free=11.6, wall=18086
2023-05-26 04:24:50 - progress_bar.py[line:272] - INFO: epoch 006:    995 / 1732 loss=2.376, loss_v1=0, loss_v2=0, nll_loss=1.175, ntokens=1048.7, nsentences=32, sample_size=1048.7, sample_size_v1=0, sample_size_v2=0, ppl=2.26, wps=559.1, ups=0.53, wpb=1048.7, bsz=32, num_updates=9640, lr=2.59935e-05, gnorm=2.475, clip=100, loss_scale=256, train_wall=19, gb_free=10.6, wall=18105
2023-05-26 04:25:09 - progress_bar.py[line:272] - INFO: epoch 006:   1005 / 1732 loss=2.376, loss_v1=0, loss_v2=0, nll_loss=1.176, ntokens=981.9, nsentences=32, sample_size=981.9, sample_size_v1=0, sample_size_v2=0, ppl=2.26, wps=526.4, ups=0.54, wpb=981.9, bsz=32, num_updates=9650, lr=2.59873e-05, gnorm=2.455, clip=100, loss_scale=256, train_wall=19, gb_free=11.5, wall=18124
2023-05-26 04:25:28 - progress_bar.py[line:272] - INFO: epoch 006:   1015 / 1732 loss=2.383, loss_v1=0, loss_v2=0, nll_loss=1.183, ntokens=996.6, nsentences=32, sample_size=996.6, sample_size_v1=0, sample_size_v2=0, ppl=2.27, wps=536, ups=0.54, wpb=996.6, bsz=32, num_updates=9660, lr=2.59812e-05, gnorm=2.367, clip=100, loss_scale=256, train_wall=19, gb_free=11.7, wall=18142
2023-05-26 04:25:47 - progress_bar.py[line:272] - INFO: epoch 006:   1025 / 1732 loss=2.367, loss_v1=0, loss_v2=0, nll_loss=1.168, ntokens=1087.5, nsentences=32, sample_size=1087.5, sample_size_v1=0, sample_size_v2=0, ppl=2.25, wps=574.6, ups=0.53, wpb=1087.5, bsz=32, num_updates=9670, lr=2.59751e-05, gnorm=2.41, clip=100, loss_scale=256, train_wall=19, gb_free=10.8, wall=18161
2023-05-26 04:26:05 - progress_bar.py[line:272] - INFO: epoch 006:   1035 / 1732 loss=2.375, loss_v1=0, loss_v2=0, nll_loss=1.173, ntokens=1118.6, nsentences=32, sample_size=1118.6, sample_size_v1=0, sample_size_v2=0, ppl=2.25, wps=594.1, ups=0.53, wpb=1118.6, bsz=32, num_updates=9680, lr=2.59689e-05, gnorm=2.171, clip=100, loss_scale=256, train_wall=19, gb_free=11.4, wall=18180
2023-05-26 04:26:24 - progress_bar.py[line:272] - INFO: epoch 006:   1045 / 1732 loss=2.373, loss_v1=0, loss_v2=0, nll_loss=1.172, ntokens=1030.7, nsentences=32, sample_size=1030.7, sample_size_v1=0, sample_size_v2=0, ppl=2.25, wps=548, ups=0.53, wpb=1030.7, bsz=32, num_updates=9690, lr=2.59628e-05, gnorm=2.641, clip=100, loss_scale=256, train_wall=19, gb_free=11.6, wall=18199
2023-05-26 04:26:43 - progress_bar.py[line:272] - INFO: epoch 006:   1055 / 1732 loss=2.381, loss_v1=0, loss_v2=0, nll_loss=1.183, ntokens=1077.2, nsentences=32, sample_size=1077.2, sample_size_v1=0, sample_size_v2=0, ppl=2.27, wps=576.5, ups=0.54, wpb=1077.2, bsz=32, num_updates=9700, lr=2.59566e-05, gnorm=2.559, clip=100, loss_scale=256, train_wall=19, gb_free=11.1, wall=18218
2023-05-26 04:27:02 - progress_bar.py[line:272] - INFO: epoch 006:   1065 / 1732 loss=2.378, loss_v1=0, loss_v2=0, nll_loss=1.177, ntokens=1021, nsentences=32, sample_size=1021, sample_size_v1=0, sample_size_v2=0, ppl=2.26, wps=545.4, ups=0.53, wpb=1021, bsz=32, num_updates=9710, lr=2.59505e-05, gnorm=2.327, clip=100, loss_scale=256, train_wall=19, gb_free=11.3, wall=18236
2023-05-26 04:27:07 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 256.0
2023-05-26 04:27:22 - progress_bar.py[line:272] - INFO: epoch 006:   1076 / 1732 loss=2.379, loss_v1=0, loss_v2=0, nll_loss=1.18, ntokens=1011.7, nsentences=32, sample_size=1011.7, sample_size_v1=0, sample_size_v2=0, ppl=2.27, wps=490, ups=0.48, wpb=1011.7, bsz=32, num_updates=9720, lr=2.59444e-05, gnorm=2.461, clip=100, loss_scale=256, train_wall=21, gb_free=11.5, wall=18257
2023-05-26 04:27:41 - progress_bar.py[line:272] - INFO: epoch 006:   1086 / 1732 loss=2.375, loss_v1=0, loss_v2=0, nll_loss=1.176, ntokens=1073.8, nsentences=32, sample_size=1073.8, sample_size_v1=0, sample_size_v2=0, ppl=2.26, wps=567.5, ups=0.53, wpb=1073.8, bsz=32, num_updates=9730, lr=2.59382e-05, gnorm=2.362, clip=100, loss_scale=256, train_wall=19, gb_free=11.2, wall=18276
2023-05-26 04:28:00 - progress_bar.py[line:272] - INFO: epoch 006:   1096 / 1732 loss=2.384, loss_v1=0, loss_v2=0, nll_loss=1.182, ntokens=1044.2, nsentences=32, sample_size=1044.2, sample_size_v1=0, sample_size_v2=0, ppl=2.27, wps=557.3, ups=0.53, wpb=1044.2, bsz=32, num_updates=9740, lr=2.59321e-05, gnorm=2.514, clip=100, loss_scale=256, train_wall=19, gb_free=11, wall=18295
2023-05-26 04:28:19 - progress_bar.py[line:272] - INFO: epoch 006:   1106 / 1732 loss=2.366, loss_v1=0, loss_v2=0, nll_loss=1.168, ntokens=1073, nsentences=32, sample_size=1073, sample_size_v1=0, sample_size_v2=0, ppl=2.25, wps=569.6, ups=0.53, wpb=1073, bsz=32, num_updates=9750, lr=2.59259e-05, gnorm=2.305, clip=100, loss_scale=256, train_wall=19, gb_free=11.2, wall=18313
2023-05-26 04:28:37 - progress_bar.py[line:272] - INFO: epoch 006:   1116 / 1732 loss=2.387, loss_v1=0, loss_v2=0, nll_loss=1.187, ntokens=936.7, nsentences=32, sample_size=936.7, sample_size_v1=0, sample_size_v2=0, ppl=2.28, wps=500.3, ups=0.53, wpb=936.7, bsz=32, num_updates=9760, lr=2.59198e-05, gnorm=2.467, clip=100, loss_scale=256, train_wall=19, gb_free=11.1, wall=18332
2023-05-26 04:28:56 - progress_bar.py[line:272] - INFO: epoch 006:   1126 / 1732 loss=2.371, loss_v1=0, loss_v2=0, nll_loss=1.171, ntokens=1021, nsentences=32, sample_size=1021, sample_size_v1=0, sample_size_v2=0, ppl=2.25, wps=542.8, ups=0.53, wpb=1021, bsz=32, num_updates=9770, lr=2.59136e-05, gnorm=2.445, clip=100, loss_scale=256, train_wall=19, gb_free=10.9, wall=18351
2023-05-26 04:29:15 - progress_bar.py[line:272] - INFO: epoch 006:   1136 / 1732 loss=2.385, loss_v1=0, loss_v2=0, nll_loss=1.186, ntokens=969.6, nsentences=32, sample_size=969.6, sample_size_v1=0, sample_size_v2=0, ppl=2.27, wps=518.3, ups=0.53, wpb=969.6, bsz=32, num_updates=9780, lr=2.59075e-05, gnorm=2.569, clip=100, loss_scale=256, train_wall=19, gb_free=11.7, wall=18370
2023-05-26 04:29:34 - progress_bar.py[line:272] - INFO: epoch 006:   1146 / 1732 loss=2.381, loss_v1=0, loss_v2=0, nll_loss=1.181, ntokens=1029.8, nsentences=32, sample_size=1029.8, sample_size_v1=0, sample_size_v2=0, ppl=2.27, wps=549.8, ups=0.53, wpb=1029.8, bsz=32, num_updates=9790, lr=2.59014e-05, gnorm=2.312, clip=100, loss_scale=256, train_wall=19, gb_free=11.4, wall=18388
2023-05-26 04:29:52 - progress_bar.py[line:272] - INFO: epoch 006:   1156 / 1732 loss=2.367, loss_v1=0, loss_v2=0, nll_loss=1.167, ntokens=1017, nsentences=32, sample_size=1017, sample_size_v1=0, sample_size_v2=0, ppl=2.25, wps=542.7, ups=0.53, wpb=1017, bsz=32, num_updates=9800, lr=2.58952e-05, gnorm=2.369, clip=100, loss_scale=256, train_wall=19, gb_free=10.6, wall=18407
2023-05-26 04:30:11 - progress_bar.py[line:272] - INFO: epoch 006:   1166 / 1732 loss=2.371, loss_v1=0, loss_v2=0, nll_loss=1.17, ntokens=1020.6, nsentences=32, sample_size=1020.6, sample_size_v1=0, sample_size_v2=0, ppl=2.25, wps=544.6, ups=0.53, wpb=1020.6, bsz=32, num_updates=9810, lr=2.58891e-05, gnorm=2.364, clip=100, loss_scale=256, train_wall=19, gb_free=11.5, wall=18426
2023-05-26 04:30:30 - progress_bar.py[line:272] - INFO: epoch 006:   1176 / 1732 loss=2.353, loss_v1=0, loss_v2=0, nll_loss=1.15, ntokens=1064.1, nsentences=32, sample_size=1064.1, sample_size_v1=0, sample_size_v2=0, ppl=2.22, wps=567.6, ups=0.53, wpb=1064.1, bsz=32, num_updates=9820, lr=2.58829e-05, gnorm=2.241, clip=100, loss_scale=256, train_wall=19, gb_free=11.1, wall=18445
2023-05-26 04:30:49 - progress_bar.py[line:272] - INFO: epoch 006:   1186 / 1732 loss=2.377, loss_v1=0, loss_v2=0, nll_loss=1.178, ntokens=966.7, nsentences=32, sample_size=966.7, sample_size_v1=0, sample_size_v2=0, ppl=2.26, wps=517.1, ups=0.53, wpb=966.7, bsz=32, num_updates=9830, lr=2.58768e-05, gnorm=2.49, clip=100, loss_scale=256, train_wall=19, gb_free=11.6, wall=18463
2023-05-26 04:31:07 - progress_bar.py[line:272] - INFO: epoch 006:   1196 / 1732 loss=2.375, loss_v1=0, loss_v2=0, nll_loss=1.173, ntokens=1072.1, nsentences=32, sample_size=1072.1, sample_size_v1=0, sample_size_v2=0, ppl=2.26, wps=572, ups=0.53, wpb=1072.1, bsz=32, num_updates=9840, lr=2.58706e-05, gnorm=2.402, clip=100, loss_scale=256, train_wall=19, gb_free=11.2, wall=18482
2023-05-26 04:31:26 - progress_bar.py[line:272] - INFO: epoch 006:   1206 / 1732 loss=2.345, loss_v1=0, loss_v2=0, nll_loss=1.142, ntokens=1115.4, nsentences=32, sample_size=1115.4, sample_size_v1=0, sample_size_v2=0, ppl=2.21, wps=589, ups=0.53, wpb=1115.4, bsz=32, num_updates=9850, lr=2.58645e-05, gnorm=2.208, clip=100, loss_scale=256, train_wall=19, gb_free=11.8, wall=18501
2023-05-26 04:31:45 - progress_bar.py[line:272] - INFO: epoch 006:   1216 / 1732 loss=2.38, loss_v1=0, loss_v2=0, nll_loss=1.181, ntokens=1038.1, nsentences=32, sample_size=1038.1, sample_size_v1=0, sample_size_v2=0, ppl=2.27, wps=554.2, ups=0.53, wpb=1038.1, bsz=32, num_updates=9860, lr=2.58584e-05, gnorm=2.384, clip=100, loss_scale=256, train_wall=19, gb_free=10.9, wall=18520
2023-05-26 04:32:04 - progress_bar.py[line:272] - INFO: epoch 006:   1226 / 1732 loss=2.385, loss_v1=0, loss_v2=0, nll_loss=1.184, ntokens=1020.3, nsentences=32, sample_size=1020.3, sample_size_v1=0, sample_size_v2=0, ppl=2.27, wps=542.6, ups=0.53, wpb=1020.3, bsz=32, num_updates=9870, lr=2.58522e-05, gnorm=2.307, clip=100, loss_scale=256, train_wall=19, gb_free=11.4, wall=18539
2023-05-26 04:32:23 - progress_bar.py[line:272] - INFO: epoch 006:   1236 / 1732 loss=2.348, loss_v1=0, loss_v2=0, nll_loss=1.146, ntokens=1034, nsentences=32, sample_size=1034, sample_size_v1=0, sample_size_v2=0, ppl=2.21, wps=552.4, ups=0.53, wpb=1034, bsz=32, num_updates=9880, lr=2.58461e-05, gnorm=2.363, clip=100, loss_scale=256, train_wall=19, gb_free=11, wall=18557
2023-05-26 04:32:41 - progress_bar.py[line:272] - INFO: epoch 006:   1246 / 1732 loss=2.314, loss_v1=0, loss_v2=0, nll_loss=1.106, ntokens=1109.3, nsentences=32, sample_size=1109.3, sample_size_v1=0, sample_size_v2=0, ppl=2.15, wps=588.5, ups=0.53, wpb=1109.3, bsz=32, num_updates=9890, lr=2.58399e-05, gnorm=2.356, clip=100, loss_scale=256, train_wall=19, gb_free=10.7, wall=18576
2023-05-26 04:33:00 - progress_bar.py[line:272] - INFO: epoch 006:   1256 / 1732 loss=2.347, loss_v1=0, loss_v2=0, nll_loss=1.143, ntokens=1060.4, nsentences=32, sample_size=1060.4, sample_size_v1=0, sample_size_v2=0, ppl=2.21, wps=565.4, ups=0.53, wpb=1060.4, bsz=32, num_updates=9900, lr=2.58338e-05, gnorm=2.242, clip=100, loss_scale=256, train_wall=19, gb_free=11.2, wall=18595
2023-05-26 04:33:19 - progress_bar.py[line:272] - INFO: epoch 006:   1266 / 1732 loss=2.388, loss_v1=0, loss_v2=0, nll_loss=1.191, ntokens=1048.7, nsentences=32, sample_size=1048.7, sample_size_v1=0, sample_size_v2=0, ppl=2.28, wps=557.6, ups=0.53, wpb=1048.7, bsz=32, num_updates=9910, lr=2.58277e-05, gnorm=2.493, clip=100, loss_scale=256, train_wall=19, gb_free=11.5, wall=18614
2023-05-26 04:33:38 - progress_bar.py[line:272] - INFO: epoch 006:   1276 / 1732 loss=2.367, loss_v1=0, loss_v2=0, nll_loss=1.164, ntokens=1075.2, nsentences=32, sample_size=1075.2, sample_size_v1=0, sample_size_v2=0, ppl=2.24, wps=570, ups=0.53, wpb=1075.2, bsz=32, num_updates=9920, lr=2.58215e-05, gnorm=2.199, clip=100, loss_scale=256, train_wall=19, gb_free=11, wall=18633
2023-05-26 04:33:57 - progress_bar.py[line:272] - INFO: epoch 006:   1286 / 1732 loss=2.371, loss_v1=0, loss_v2=0, nll_loss=1.172, ntokens=1038.1, nsentences=32, sample_size=1038.1, sample_size_v1=0, sample_size_v2=0, ppl=2.25, wps=551.8, ups=0.53, wpb=1038.1, bsz=32, num_updates=9930, lr=2.58154e-05, gnorm=2.416, clip=100, loss_scale=256, train_wall=19, gb_free=11.6, wall=18651
2023-05-26 04:34:16 - progress_bar.py[line:272] - INFO: epoch 006:   1296 / 1732 loss=2.344, loss_v1=0, loss_v2=0, nll_loss=1.14, ntokens=1121.3, nsentences=32, sample_size=1121.3, sample_size_v1=0, sample_size_v2=0, ppl=2.2, wps=593.1, ups=0.53, wpb=1121.3, bsz=32, num_updates=9940, lr=2.58092e-05, gnorm=2.223, clip=100, loss_scale=256, train_wall=19, gb_free=11.6, wall=18670
2023-05-26 04:34:35 - progress_bar.py[line:272] - INFO: epoch 006:   1306 / 1732 loss=2.391, loss_v1=0, loss_v2=0, nll_loss=1.191, ntokens=1091, nsentences=32, sample_size=1091, sample_size_v1=0, sample_size_v2=0, ppl=2.28, wps=575.2, ups=0.53, wpb=1091, bsz=32, num_updates=9950, lr=2.58031e-05, gnorm=2.33, clip=100, loss_scale=256, train_wall=19, gb_free=10.8, wall=18689
2023-05-26 04:34:54 - progress_bar.py[line:272] - INFO: epoch 006:   1316 / 1732 loss=2.375, loss_v1=0, loss_v2=0, nll_loss=1.175, ntokens=1049.3, nsentences=32, sample_size=1049.3, sample_size_v1=0, sample_size_v2=0, ppl=2.26, wps=555.7, ups=0.53, wpb=1049.3, bsz=32, num_updates=9960, lr=2.57969e-05, gnorm=2.393, clip=100, loss_scale=256, train_wall=19, gb_free=11.3, wall=18708
2023-05-26 04:35:12 - progress_bar.py[line:272] - INFO: epoch 006:   1326 / 1732 loss=2.348, loss_v1=0, loss_v2=0, nll_loss=1.145, ntokens=1110.6, nsentences=32, sample_size=1110.6, sample_size_v1=0, sample_size_v2=0, ppl=2.21, wps=587.3, ups=0.53, wpb=1110.6, bsz=32, num_updates=9970, lr=2.57908e-05, gnorm=2.231, clip=100, loss_scale=256, train_wall=19, gb_free=11.5, wall=18727
2023-05-26 04:35:31 - progress_bar.py[line:272] - INFO: epoch 006:   1336 / 1732 loss=2.339, loss_v1=0, loss_v2=0, nll_loss=1.134, ntokens=1122.3, nsentences=32, sample_size=1122.3, sample_size_v1=0, sample_size_v2=0, ppl=2.19, wps=595.5, ups=0.53, wpb=1122.3, bsz=32, num_updates=9980, lr=2.57847e-05, gnorm=2.337, clip=100, loss_scale=256, train_wall=19, gb_free=10.9, wall=18746
2023-05-26 04:35:50 - progress_bar.py[line:272] - INFO: epoch 006:   1346 / 1732 loss=2.345, loss_v1=0, loss_v2=0, nll_loss=1.143, ntokens=1171.7, nsentences=32, sample_size=1171.7, sample_size_v1=0, sample_size_v2=0, ppl=2.21, wps=616.5, ups=0.53, wpb=1171.7, bsz=32, num_updates=9990, lr=2.57785e-05, gnorm=2.168, clip=100, loss_scale=256, train_wall=19, gb_free=11, wall=18765
2023-05-26 04:36:09 - progress_bar.py[line:272] - INFO: epoch 006:   1356 / 1732 loss=2.333, loss_v1=0, loss_v2=0, nll_loss=1.127, ntokens=1137.3, nsentences=32, sample_size=1137.3, sample_size_v1=0, sample_size_v2=0, ppl=2.18, wps=600.8, ups=0.53, wpb=1137.3, bsz=32, num_updates=10000, lr=2.57724e-05, gnorm=2.185, clip=100, loss_scale=256, train_wall=19, gb_free=11.4, wall=18784
2023-05-26 04:36:28 - progress_bar.py[line:272] - INFO: epoch 006:   1366 / 1732 loss=2.349, loss_v1=0, loss_v2=0, nll_loss=1.146, ntokens=1081.4, nsentences=32, sample_size=1081.4, sample_size_v1=0, sample_size_v2=0, ppl=2.21, wps=573.7, ups=0.53, wpb=1081.4, bsz=32, num_updates=10010, lr=2.57662e-05, gnorm=2.342, clip=100, loss_scale=256, train_wall=19, gb_free=11.4, wall=18803
2023-05-26 04:36:47 - progress_bar.py[line:272] - INFO: epoch 006:   1376 / 1732 loss=2.395, loss_v1=0, loss_v2=0, nll_loss=1.196, ntokens=1111.5, nsentences=32, sample_size=1111.5, sample_size_v1=0, sample_size_v2=0, ppl=2.29, wps=590.1, ups=0.53, wpb=1111.5, bsz=32, num_updates=10020, lr=2.57601e-05, gnorm=2.399, clip=100, loss_scale=256, train_wall=19, gb_free=11.1, wall=18822
2023-05-26 04:37:06 - progress_bar.py[line:272] - INFO: epoch 006:   1386 / 1732 loss=2.35, loss_v1=0, loss_v2=0, nll_loss=1.147, ntokens=1153.3, nsentences=32, sample_size=1153.3, sample_size_v1=0, sample_size_v2=0, ppl=2.22, wps=613.5, ups=0.53, wpb=1153.3, bsz=32, num_updates=10030, lr=2.57539e-05, gnorm=2.209, clip=100, loss_scale=256, train_wall=19, gb_free=11.7, wall=18840
2023-05-26 04:37:25 - progress_bar.py[line:272] - INFO: epoch 006:   1396 / 1732 loss=2.35, loss_v1=0, loss_v2=0, nll_loss=1.146, ntokens=1044.6, nsentences=32, sample_size=1044.6, sample_size_v1=0, sample_size_v2=0, ppl=2.21, wps=555.5, ups=0.53, wpb=1044.6, bsz=32, num_updates=10040, lr=2.57478e-05, gnorm=2.411, clip=100, loss_scale=256, train_wall=19, gb_free=11.3, wall=18859
2023-05-26 04:37:43 - progress_bar.py[line:272] - INFO: epoch 006:   1406 / 1732 loss=2.361, loss_v1=0, loss_v2=0, nll_loss=1.16, ntokens=1163.8, nsentences=32, sample_size=1163.8, sample_size_v1=0, sample_size_v2=0, ppl=2.23, wps=615.2, ups=0.53, wpb=1163.8, bsz=32, num_updates=10050, lr=2.57417e-05, gnorm=2.228, clip=100, loss_scale=256, train_wall=19, gb_free=11.5, wall=18878
2023-05-26 04:38:02 - progress_bar.py[line:272] - INFO: epoch 006:   1416 / 1732 loss=2.375, loss_v1=0, loss_v2=0, nll_loss=1.176, ntokens=1281, nsentences=32, sample_size=1281, sample_size_v1=0, sample_size_v2=0, ppl=2.26, wps=673.2, ups=0.53, wpb=1281, bsz=32, num_updates=10060, lr=2.57355e-05, gnorm=2.033, clip=100, loss_scale=256, train_wall=19, gb_free=10.6, wall=18897
2023-05-26 04:38:08 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 128.0
2023-05-26 04:38:23 - progress_bar.py[line:272] - INFO: epoch 006:   1427 / 1732 loss=2.33, loss_v1=0, loss_v2=0, nll_loss=1.124, ntokens=1221.2, nsentences=32, sample_size=1221.2, sample_size_v1=0, sample_size_v2=0, ppl=2.18, wps=583.9, ups=0.48, wpb=1221.2, bsz=32, num_updates=10070, lr=2.57294e-05, gnorm=2.01, clip=100, loss_scale=128, train_wall=21, gb_free=11.6, wall=18918
2023-05-26 04:38:42 - progress_bar.py[line:272] - INFO: epoch 006:   1437 / 1732 loss=2.344, loss_v1=0, loss_v2=0, nll_loss=1.143, ntokens=1217.2, nsentences=32, sample_size=1217.2, sample_size_v1=0, sample_size_v2=0, ppl=2.21, wps=643.4, ups=0.53, wpb=1217.2, bsz=32, num_updates=10080, lr=2.57232e-05, gnorm=1.956, clip=100, loss_scale=128, train_wall=19, gb_free=9.6, wall=18937
2023-05-26 04:39:01 - progress_bar.py[line:272] - INFO: epoch 006:   1447 / 1732 loss=2.369, loss_v1=0, loss_v2=0, nll_loss=1.167, ntokens=1115.7, nsentences=32, sample_size=1115.7, sample_size_v1=0, sample_size_v2=0, ppl=2.25, wps=594.9, ups=0.53, wpb=1115.7, bsz=32, num_updates=10090, lr=2.57171e-05, gnorm=2.25, clip=100, loss_scale=128, train_wall=19, gb_free=11.6, wall=18956
2023-05-26 04:39:20 - progress_bar.py[line:272] - INFO: epoch 006:   1457 / 1732 loss=2.368, loss_v1=0, loss_v2=0, nll_loss=1.166, ntokens=1111.8, nsentences=32, sample_size=1111.8, sample_size_v1=0, sample_size_v2=0, ppl=2.24, wps=588.1, ups=0.53, wpb=1111.8, bsz=32, num_updates=10100, lr=2.5711e-05, gnorm=2.209, clip=100, loss_scale=128, train_wall=19, gb_free=10.6, wall=18975
2023-05-26 04:39:39 - progress_bar.py[line:272] - INFO: epoch 006:   1467 / 1732 loss=2.31, loss_v1=0, loss_v2=0, nll_loss=1.102, ntokens=1202.5, nsentences=32, sample_size=1202.5, sample_size_v1=0, sample_size_v2=0, ppl=2.15, wps=633.9, ups=0.53, wpb=1202.5, bsz=32, num_updates=10110, lr=2.57048e-05, gnorm=2.131, clip=100, loss_scale=128, train_wall=19, gb_free=11.3, wall=18994
2023-05-26 04:39:58 - progress_bar.py[line:272] - INFO: epoch 006:   1477 / 1732 loss=2.378, loss_v1=0, loss_v2=0, nll_loss=1.179, ntokens=1052.1, nsentences=32, sample_size=1052.1, sample_size_v1=0, sample_size_v2=0, ppl=2.26, wps=560.3, ups=0.53, wpb=1052.1, bsz=32, num_updates=10120, lr=2.56987e-05, gnorm=2.345, clip=100, loss_scale=128, train_wall=19, gb_free=10.7, wall=19012
2023-05-26 04:40:17 - progress_bar.py[line:272] - INFO: epoch 006:   1487 / 1732 loss=2.377, loss_v1=0, loss_v2=0, nll_loss=1.176, ntokens=1147.5, nsentences=32, sample_size=1147.5, sample_size_v1=0, sample_size_v2=0, ppl=2.26, wps=607.8, ups=0.53, wpb=1147.5, bsz=32, num_updates=10130, lr=2.56925e-05, gnorm=2.254, clip=100, loss_scale=128, train_wall=19, gb_free=10.8, wall=19031
2023-05-26 04:40:35 - progress_bar.py[line:272] - INFO: epoch 006:   1497 / 1732 loss=2.347, loss_v1=0, loss_v2=0, nll_loss=1.144, ntokens=1083.9, nsentences=32, sample_size=1083.9, sample_size_v1=0, sample_size_v2=0, ppl=2.21, wps=574.3, ups=0.53, wpb=1083.9, bsz=32, num_updates=10140, lr=2.56864e-05, gnorm=2.248, clip=100, loss_scale=128, train_wall=19, gb_free=11.5, wall=19050
2023-05-26 04:40:54 - progress_bar.py[line:272] - INFO: epoch 006:   1507 / 1732 loss=2.301, loss_v1=0, loss_v2=0, nll_loss=1.092, ntokens=1112.5, nsentences=32, sample_size=1112.5, sample_size_v1=0, sample_size_v2=0, ppl=2.13, wps=590.8, ups=0.53, wpb=1112.5, bsz=32, num_updates=10150, lr=2.56802e-05, gnorm=2.153, clip=100, loss_scale=128, train_wall=19, gb_free=11.5, wall=19069
2023-05-26 04:41:13 - progress_bar.py[line:272] - INFO: epoch 006:   1517 / 1732 loss=2.376, loss_v1=0, loss_v2=0, nll_loss=1.175, ntokens=1063, nsentences=32, sample_size=1063, sample_size_v1=0, sample_size_v2=0, ppl=2.26, wps=565.9, ups=0.53, wpb=1063, bsz=32, num_updates=10160, lr=2.56741e-05, gnorm=2.241, clip=100, loss_scale=128, train_wall=19, gb_free=10.7, wall=19088
2023-05-26 04:41:32 - progress_bar.py[line:272] - INFO: epoch 006:   1527 / 1732 loss=2.399, loss_v1=0, loss_v2=0, nll_loss=1.203, ntokens=1062.3, nsentences=32, sample_size=1062.3, sample_size_v1=0, sample_size_v2=0, ppl=2.3, wps=565, ups=0.53, wpb=1062.3, bsz=32, num_updates=10170, lr=2.5668e-05, gnorm=2.248, clip=100, loss_scale=128, train_wall=19, gb_free=11.1, wall=19107
2023-05-26 04:41:51 - progress_bar.py[line:272] - INFO: epoch 006:   1537 / 1732 loss=2.353, loss_v1=0, loss_v2=0, nll_loss=1.147, ntokens=1067, nsentences=32, sample_size=1067, sample_size_v1=0, sample_size_v2=0, ppl=2.21, wps=564.4, ups=0.53, wpb=1067, bsz=32, num_updates=10180, lr=2.56618e-05, gnorm=2.35, clip=100, loss_scale=128, train_wall=19, gb_free=11, wall=19125
2023-05-26 04:42:10 - progress_bar.py[line:272] - INFO: epoch 006:   1547 / 1732 loss=2.333, loss_v1=0, loss_v2=0, nll_loss=1.131, ntokens=1093.5, nsentences=32, sample_size=1093.5, sample_size_v1=0, sample_size_v2=0, ppl=2.19, wps=580.3, ups=0.53, wpb=1093.5, bsz=32, num_updates=10190, lr=2.56557e-05, gnorm=2.132, clip=100, loss_scale=128, train_wall=19, gb_free=11.2, wall=19144
2023-05-26 04:42:28 - progress_bar.py[line:272] - INFO: epoch 006:   1557 / 1732 loss=2.343, loss_v1=0, loss_v2=0, nll_loss=1.138, ntokens=1051.1, nsentences=32, sample_size=1051.1, sample_size_v1=0, sample_size_v2=0, ppl=2.2, wps=560.4, ups=0.53, wpb=1051.1, bsz=32, num_updates=10200, lr=2.56495e-05, gnorm=2.28, clip=100, loss_scale=128, train_wall=19, gb_free=11.2, wall=19163
2023-05-26 04:42:47 - progress_bar.py[line:272] - INFO: epoch 006:   1567 / 1732 loss=2.389, loss_v1=0, loss_v2=0, nll_loss=1.191, ntokens=1097.1, nsentences=32, sample_size=1097.1, sample_size_v1=0, sample_size_v2=0, ppl=2.28, wps=583.1, ups=0.53, wpb=1097.1, bsz=32, num_updates=10210, lr=2.56434e-05, gnorm=2.248, clip=100, loss_scale=128, train_wall=19, gb_free=10.6, wall=19182
2023-05-26 04:43:06 - progress_bar.py[line:272] - INFO: epoch 006:   1577 / 1732 loss=2.385, loss_v1=0, loss_v2=0, nll_loss=1.185, ntokens=1002.1, nsentences=32, sample_size=1002.1, sample_size_v1=0, sample_size_v2=0, ppl=2.27, wps=534.4, ups=0.53, wpb=1002.1, bsz=32, num_updates=10220, lr=2.56372e-05, gnorm=2.488, clip=100, loss_scale=128, train_wall=19, gb_free=11.8, wall=19201
2023-05-26 04:43:25 - progress_bar.py[line:272] - INFO: epoch 006:   1587 / 1732 loss=2.372, loss_v1=0, loss_v2=0, nll_loss=1.172, ntokens=1081.3, nsentences=32, sample_size=1081.3, sample_size_v1=0, sample_size_v2=0, ppl=2.25, wps=570.4, ups=0.53, wpb=1081.3, bsz=32, num_updates=10230, lr=2.56311e-05, gnorm=2.201, clip=100, loss_scale=128, train_wall=19, gb_free=10.8, wall=19220
2023-05-26 04:43:44 - progress_bar.py[line:272] - INFO: epoch 006:   1597 / 1732 loss=2.331, loss_v1=0, loss_v2=0, nll_loss=1.126, ntokens=1084.4, nsentences=32, sample_size=1084.4, sample_size_v1=0, sample_size_v2=0, ppl=2.18, wps=576.6, ups=0.53, wpb=1084.4, bsz=32, num_updates=10240, lr=2.5625e-05, gnorm=2.219, clip=100, loss_scale=128, train_wall=19, gb_free=10.9, wall=19238
2023-05-26 04:44:03 - progress_bar.py[line:272] - INFO: epoch 006:   1607 / 1732 loss=2.338, loss_v1=0, loss_v2=0, nll_loss=1.133, ntokens=1122.8, nsentences=32, sample_size=1122.8, sample_size_v1=0, sample_size_v2=0, ppl=2.19, wps=595.2, ups=0.53, wpb=1122.8, bsz=32, num_updates=10250, lr=2.56188e-05, gnorm=2.149, clip=100, loss_scale=128, train_wall=19, gb_free=10.9, wall=19257
2023-05-26 04:44:22 - progress_bar.py[line:272] - INFO: epoch 006:   1617 / 1732 loss=2.318, loss_v1=0, loss_v2=0, nll_loss=1.112, ntokens=1114.5, nsentences=32, sample_size=1114.5, sample_size_v1=0, sample_size_v2=0, ppl=2.16, wps=588.4, ups=0.53, wpb=1114.5, bsz=32, num_updates=10260, lr=2.56127e-05, gnorm=2.145, clip=100, loss_scale=128, train_wall=19, gb_free=11.3, wall=19276
2023-05-26 04:44:41 - progress_bar.py[line:272] - INFO: epoch 006:   1627 / 1732 loss=2.347, loss_v1=0, loss_v2=0, nll_loss=1.142, ntokens=1162.3, nsentences=32, sample_size=1162.3, sample_size_v1=0, sample_size_v2=0, ppl=2.21, wps=613.1, ups=0.53, wpb=1162.3, bsz=32, num_updates=10270, lr=2.56065e-05, gnorm=2.331, clip=100, loss_scale=128, train_wall=19, gb_free=11.2, wall=19295
2023-05-26 04:44:59 - progress_bar.py[line:272] - INFO: epoch 006:   1637 / 1732 loss=2.324, loss_v1=0, loss_v2=0, nll_loss=1.118, ntokens=1115.7, nsentences=32, sample_size=1115.7, sample_size_v1=0, sample_size_v2=0, ppl=2.17, wps=589.6, ups=0.53, wpb=1115.7, bsz=32, num_updates=10280, lr=2.56004e-05, gnorm=2.225, clip=100, loss_scale=128, train_wall=19, gb_free=11.3, wall=19314
2023-05-26 04:45:19 - progress_bar.py[line:272] - INFO: epoch 006:   1647 / 1732 loss=2.31, loss_v1=0, loss_v2=0, nll_loss=1.103, ntokens=1285, nsentences=32, sample_size=1285, sample_size_v1=0, sample_size_v2=0, ppl=2.15, wps=675.4, ups=0.53, wpb=1285, bsz=32, num_updates=10290, lr=2.55943e-05, gnorm=1.893, clip=100, loss_scale=128, train_wall=19, gb_free=11.1, wall=19333
2023-05-26 04:45:37 - progress_bar.py[line:272] - INFO: epoch 006:   1657 / 1732 loss=2.384, loss_v1=0, loss_v2=0, nll_loss=1.184, ntokens=952, nsentences=32, sample_size=952, sample_size_v1=0, sample_size_v2=0, ppl=2.27, wps=508.9, ups=0.53, wpb=952, bsz=32, num_updates=10300, lr=2.55881e-05, gnorm=2.651, clip=100, loss_scale=128, train_wall=19, gb_free=11.3, wall=19352
2023-05-26 04:45:56 - progress_bar.py[line:272] - INFO: epoch 006:   1667 / 1732 loss=2.361, loss_v1=0, loss_v2=0, nll_loss=1.156, ntokens=1028.1, nsentences=32, sample_size=1028.1, sample_size_v1=0, sample_size_v2=0, ppl=2.23, wps=546.7, ups=0.53, wpb=1028.1, bsz=32, num_updates=10310, lr=2.5582e-05, gnorm=2.256, clip=100, loss_scale=128, train_wall=19, gb_free=11.4, wall=19371
2023-05-26 04:46:15 - progress_bar.py[line:272] - INFO: epoch 006:   1677 / 1732 loss=2.307, loss_v1=0, loss_v2=0, nll_loss=1.101, ntokens=1135.4, nsentences=32, sample_size=1135.4, sample_size_v1=0, sample_size_v2=0, ppl=2.14, wps=602.2, ups=0.53, wpb=1135.4, bsz=32, num_updates=10320, lr=2.55758e-05, gnorm=2.331, clip=100, loss_scale=128, train_wall=19, gb_free=10.5, wall=19390
2023-05-26 04:46:34 - progress_bar.py[line:272] - INFO: epoch 006:   1687 / 1732 loss=2.33, loss_v1=0, loss_v2=0, nll_loss=1.126, ntokens=1154.5, nsentences=32, sample_size=1154.5, sample_size_v1=0, sample_size_v2=0, ppl=2.18, wps=609, ups=0.53, wpb=1154.5, bsz=32, num_updates=10330, lr=2.55697e-05, gnorm=2.237, clip=100, loss_scale=128, train_wall=19, gb_free=10, wall=19409
2023-05-26 04:46:53 - progress_bar.py[line:272] - INFO: epoch 006:   1697 / 1732 loss=2.326, loss_v1=0, loss_v2=0, nll_loss=1.12, ntokens=1302.5, nsentences=32, sample_size=1302.5, sample_size_v1=0, sample_size_v2=0, ppl=2.17, wps=673.7, ups=0.52, wpb=1302.5, bsz=32, num_updates=10340, lr=2.55635e-05, gnorm=1.85, clip=100, loss_scale=128, train_wall=19, gb_free=10.7, wall=19428
2023-05-26 04:47:12 - progress_bar.py[line:272] - INFO: epoch 006:   1707 / 1732 loss=2.34, loss_v1=0, loss_v2=0, nll_loss=1.136, ntokens=1171.1, nsentences=32, sample_size=1171.1, sample_size_v1=0, sample_size_v2=0, ppl=2.2, wps=617.6, ups=0.53, wpb=1171.1, bsz=32, num_updates=10350, lr=2.55574e-05, gnorm=2.121, clip=100, loss_scale=128, train_wall=19, gb_free=11.7, wall=19447
2023-05-26 04:47:31 - progress_bar.py[line:272] - INFO: epoch 006:   1717 / 1732 loss=2.333, loss_v1=0, loss_v2=0, nll_loss=1.128, ntokens=1206.1, nsentences=32, sample_size=1206.1, sample_size_v1=0, sample_size_v2=0, ppl=2.19, wps=633.7, ups=0.53, wpb=1206.1, bsz=32, num_updates=10360, lr=2.55513e-05, gnorm=2.041, clip=100, loss_scale=128, train_wall=19, gb_free=11.2, wall=19466
2023-05-26 04:47:50 - progress_bar.py[line:272] - INFO: epoch 006:   1727 / 1732 loss=2.376, loss_v1=0, loss_v2=0, nll_loss=1.176, ntokens=1102.3, nsentences=32, sample_size=1102.3, sample_size_v1=0, sample_size_v2=0, ppl=2.26, wps=582.5, ups=0.53, wpb=1102.3, bsz=32, num_updates=10370, lr=2.55451e-05, gnorm=2.161, clip=100, loss_scale=128, train_wall=19, gb_free=11.2, wall=19485
2023-05-26 04:47:58 - train.py[line:332] - INFO: end of epoch 6 (average epoch stats below)
2023-05-26 04:47:58 - progress_bar.py[line:282] - INFO: epoch 006 | loss 2.364 | loss_v1 0 | loss_v2 0 | nll_loss 1.163 | ntokens 1051.54 | nsentences 31.986 | sample_size 1051.54 | sample_size_v1 0 | sample_size_v2 0 | ppl 2.24 | wps 559.6 | ups 0.53 | wpb 1051.5 | bsz 32 | num_updates 10375 | lr 2.5542e-05 | gnorm 2.269 | clip 99.9 | loss_scale 128 | train_wall 3239 | gb_free 11.7 | wall 19493
2023-05-26 04:47:58 - trainer.py[line:639] - INFO: loading train data for epoch 7
local datafile ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 0 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 0 finished initializing row_count and line_idx-to-offset mapping
file ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 0 row count 55400 total row count 55400
slice_id 0 seek offset 0
2023-05-26 04:48:00 - trainer.py[line:703] - INFO: begin training epoch 7
2023-05-26 04:48:00 - train.py[line:305] - INFO: Start iterating over samples
2023-05-26 04:48:10 - progress_bar.py[line:272] - INFO: epoch 007:      5 / 1732 loss=2.332, loss_v1=0, loss_v2=0, nll_loss=1.125, ntokens=1084.5, nsentences=29.6, sample_size=1084.5, sample_size_v1=0, sample_size_v2=0, ppl=2.18, wps=547.3, ups=0.5, wpb=1084.5, bsz=29.6, num_updates=10380, lr=2.5539e-05, gnorm=2.429, clip=100, loss_scale=128, train_wall=18, gb_free=11.2, wall=19505
2023-05-26 04:48:29 - progress_bar.py[line:272] - INFO: epoch 007:     15 / 1732 loss=2.303, loss_v1=0, loss_v2=0, nll_loss=1.095, ntokens=1089.9, nsentences=32, sample_size=1089.9, sample_size_v1=0, sample_size_v2=0, ppl=2.14, wps=579.1, ups=0.53, wpb=1089.9, bsz=32, num_updates=10390, lr=2.55328e-05, gnorm=1.986, clip=100, loss_scale=128, train_wall=19, gb_free=11, wall=19523
2023-05-26 04:48:48 - progress_bar.py[line:272] - INFO: epoch 007:     25 / 1732 loss=2.271, loss_v1=0, loss_v2=0, nll_loss=1.06, ntokens=998.7, nsentences=32, sample_size=998.7, sample_size_v1=0, sample_size_v2=0, ppl=2.08, wps=531.2, ups=0.53, wpb=998.7, bsz=32, num_updates=10400, lr=2.55267e-05, gnorm=2.015, clip=100, loss_scale=128, train_wall=19, gb_free=11.6, wall=19542
2023-05-26 04:49:07 - progress_bar.py[line:272] - INFO: epoch 007:     35 / 1732 loss=2.198, loss_v1=0, loss_v2=0, nll_loss=0.976, ntokens=1115.2, nsentences=32, sample_size=1115.2, sample_size_v1=0, sample_size_v2=0, ppl=1.97, wps=588.9, ups=0.53, wpb=1115.2, bsz=32, num_updates=10410, lr=2.55205e-05, gnorm=2.024, clip=100, loss_scale=128, train_wall=19, gb_free=11, wall=19561
2023-05-26 04:49:25 - progress_bar.py[line:272] - INFO: epoch 007:     45 / 1732 loss=2.181, loss_v1=0, loss_v2=0, nll_loss=0.96, ntokens=1103.9, nsentences=32, sample_size=1103.9, sample_size_v1=0, sample_size_v2=0, ppl=1.94, wps=583.3, ups=0.53, wpb=1103.9, bsz=32, num_updates=10420, lr=2.55144e-05, gnorm=1.898, clip=90, loss_scale=128, train_wall=19, gb_free=10.6, wall=19580
2023-05-26 04:49:44 - progress_bar.py[line:272] - INFO: epoch 007:     55 / 1732 loss=2.154, loss_v1=0, loss_v2=0, nll_loss=0.931, ntokens=1058.4, nsentences=32, sample_size=1058.4, sample_size_v1=0, sample_size_v2=0, ppl=1.91, wps=561.7, ups=0.53, wpb=1058.4, bsz=32, num_updates=10430, lr=2.55083e-05, gnorm=2.126, clip=100, loss_scale=128, train_wall=19, gb_free=10.9, wall=19599
2023-05-26 04:50:03 - progress_bar.py[line:272] - INFO: epoch 007:     65 / 1732 loss=2.016, loss_v1=0, loss_v2=0, nll_loss=0.774, ntokens=1260.1, nsentences=32, sample_size=1260.1, sample_size_v1=0, sample_size_v2=0, ppl=1.71, wps=658.9, ups=0.52, wpb=1260.1, bsz=32, num_updates=10440, lr=2.55021e-05, gnorm=1.393, clip=100, loss_scale=128, train_wall=19, gb_free=10.5, wall=19618
2023-05-26 04:50:23 - progress_bar.py[line:272] - INFO: epoch 007:     75 / 1732 loss=2.127, loss_v1=0, loss_v2=0, nll_loss=0.895, ntokens=1372.4, nsentences=32, sample_size=1372.4, sample_size_v1=0, sample_size_v2=0, ppl=1.86, wps=701.5, ups=0.51, wpb=1372.4, bsz=32, num_updates=10450, lr=2.5496e-05, gnorm=1.441, clip=100, loss_scale=128, train_wall=20, gb_free=10.5, wall=19638
2023-05-26 04:50:42 - progress_bar.py[line:272] - INFO: epoch 007:     85 / 1732 loss=2.199, loss_v1=0, loss_v2=0, nll_loss=0.98, ntokens=1112.6, nsentences=32, sample_size=1112.6, sample_size_v1=0, sample_size_v2=0, ppl=1.97, wps=582.3, ups=0.52, wpb=1112.6, bsz=32, num_updates=10460, lr=2.54898e-05, gnorm=1.893, clip=100, loss_scale=128, train_wall=19, gb_free=11.4, wall=19657
2023-05-26 04:51:01 - progress_bar.py[line:272] - INFO: epoch 007:     95 / 1732 loss=2.149, loss_v1=0, loss_v2=0, nll_loss=0.92, ntokens=1092.3, nsentences=32, sample_size=1092.3, sample_size_v1=0, sample_size_v2=0, ppl=1.89, wps=578, ups=0.53, wpb=1092.3, bsz=32, num_updates=10470, lr=2.54837e-05, gnorm=1.81, clip=90, loss_scale=128, train_wall=19, gb_free=11.6, wall=19676
2023-05-26 04:51:20 - progress_bar.py[line:272] - INFO: epoch 007:    105 / 1732 loss=2.325, loss_v1=0, loss_v2=0, nll_loss=1.122, ntokens=995.3, nsentences=32, sample_size=995.3, sample_size_v1=0, sample_size_v2=0, ppl=2.18, wps=530.8, ups=0.53, wpb=995.3, bsz=32, num_updates=10480, lr=2.54776e-05, gnorm=2.397, clip=100, loss_scale=128, train_wall=19, gb_free=11.1, wall=19694
2023-05-26 04:51:39 - progress_bar.py[line:272] - INFO: epoch 007:    115 / 1732 loss=2.391, loss_v1=0, loss_v2=0, nll_loss=1.192, ntokens=1032.5, nsentences=32, sample_size=1032.5, sample_size_v1=0, sample_size_v2=0, ppl=2.28, wps=544.6, ups=0.53, wpb=1032.5, bsz=32, num_updates=10490, lr=2.54714e-05, gnorm=2.201, clip=100, loss_scale=128, train_wall=19, gb_free=11.1, wall=19713
2023-05-26 04:51:58 - progress_bar.py[line:272] - INFO: epoch 007:    125 / 1732 loss=2.318, loss_v1=0, loss_v2=0, nll_loss=1.111, ntokens=1181.7, nsentences=32, sample_size=1181.7, sample_size_v1=0, sample_size_v2=0, ppl=2.16, wps=614, ups=0.52, wpb=1181.7, bsz=32, num_updates=10500, lr=2.54653e-05, gnorm=1.916, clip=100, loss_scale=128, train_wall=19, gb_free=10.4, wall=19733
2023-05-26 04:52:17 - progress_bar.py[line:272] - INFO: epoch 007:    135 / 1732 loss=2.291, loss_v1=0, loss_v2=0, nll_loss=1.082, ntokens=1179.6, nsentences=32, sample_size=1179.6, sample_size_v1=0, sample_size_v2=0, ppl=2.12, wps=618.3, ups=0.52, wpb=1179.6, bsz=32, num_updates=10510, lr=2.54591e-05, gnorm=1.911, clip=100, loss_scale=128, train_wall=19, gb_free=11.4, wall=19752
2023-05-26 04:52:36 - progress_bar.py[line:272] - INFO: epoch 007:    145 / 1732 loss=2.253, loss_v1=0, loss_v2=0, nll_loss=1.039, ntokens=1246.8, nsentences=32, sample_size=1246.8, sample_size_v1=0, sample_size_v2=0, ppl=2.05, wps=645.3, ups=0.52, wpb=1246.8, bsz=32, num_updates=10520, lr=2.5453e-05, gnorm=1.732, clip=100, loss_scale=128, train_wall=19, gb_free=11, wall=19771
2023-05-26 04:52:56 - progress_bar.py[line:272] - INFO: epoch 007:    155 / 1732 loss=2.282, loss_v1=0, loss_v2=0, nll_loss=1.072, ntokens=1151.6, nsentences=32, sample_size=1151.6, sample_size_v1=0, sample_size_v2=0, ppl=2.1, wps=598.2, ups=0.52, wpb=1151.6, bsz=32, num_updates=10530, lr=2.54468e-05, gnorm=1.856, clip=100, loss_scale=128, train_wall=19, gb_free=10.8, wall=19790
2023-05-26 04:53:15 - progress_bar.py[line:272] - INFO: epoch 007:    165 / 1732 loss=2.25, loss_v1=0, loss_v2=0, nll_loss=1.038, ntokens=1062.3, nsentences=32, sample_size=1062.3, sample_size_v1=0, sample_size_v2=0, ppl=2.05, wps=561.8, ups=0.53, wpb=1062.3, bsz=32, num_updates=10540, lr=2.54407e-05, gnorm=2.086, clip=100, loss_scale=128, train_wall=19, gb_free=11.3, wall=19809
2023-05-26 04:53:33 - progress_bar.py[line:272] - INFO: epoch 007:    175 / 1732 loss=2.284, loss_v1=0, loss_v2=0, nll_loss=1.072, ntokens=958.4, nsentences=32, sample_size=958.4, sample_size_v1=0, sample_size_v2=0, ppl=2.1, wps=507.8, ups=0.53, wpb=958.4, bsz=32, num_updates=10550, lr=2.54346e-05, gnorm=2.236, clip=100, loss_scale=128, train_wall=19, gb_free=10.7, wall=19828
2023-05-26 04:53:53 - progress_bar.py[line:272] - INFO: epoch 007:    185 / 1732 loss=2.227, loss_v1=0, loss_v2=0, nll_loss=1.009, ntokens=1173.4, nsentences=32, sample_size=1173.4, sample_size_v1=0, sample_size_v2=0, ppl=2.01, wps=614.1, ups=0.52, wpb=1173.4, bsz=32, num_updates=10560, lr=2.54284e-05, gnorm=1.74, clip=100, loss_scale=128, train_wall=19, gb_free=9.8, wall=19847
2023-05-26 04:54:12 - progress_bar.py[line:272] - INFO: epoch 007:    195 / 1732 loss=2.276, loss_v1=0, loss_v2=0, nll_loss=1.065, ntokens=1144.6, nsentences=32, sample_size=1144.6, sample_size_v1=0, sample_size_v2=0, ppl=2.09, wps=600, ups=0.52, wpb=1144.6, bsz=32, num_updates=10570, lr=2.54223e-05, gnorm=2.153, clip=100, loss_scale=128, train_wall=19, gb_free=10.6, wall=19866
2023-05-26 04:54:30 - progress_bar.py[line:272] - INFO: epoch 007:    205 / 1732 loss=2.352, loss_v1=0, loss_v2=0, nll_loss=1.151, ntokens=1021.8, nsentences=32, sample_size=1021.8, sample_size_v1=0, sample_size_v2=0, ppl=2.22, wps=548.7, ups=0.54, wpb=1021.8, bsz=32, num_updates=10580, lr=2.54161e-05, gnorm=2.29, clip=100, loss_scale=256, train_wall=19, gb_free=11.7, wall=19885
2023-05-26 04:54:49 - progress_bar.py[line:272] - INFO: epoch 007:    215 / 1732 loss=2.38, loss_v1=0, loss_v2=0, nll_loss=1.178, ntokens=1094.3, nsentences=32, sample_size=1094.3, sample_size_v1=0, sample_size_v2=0, ppl=2.26, wps=581.9, ups=0.53, wpb=1094.3, bsz=32, num_updates=10590, lr=2.541e-05, gnorm=2.054, clip=100, loss_scale=256, train_wall=19, gb_free=11.5, wall=19904
2023-05-26 04:55:08 - progress_bar.py[line:272] - INFO: epoch 007:    225 / 1732 loss=2.369, loss_v1=0, loss_v2=0, nll_loss=1.168, ntokens=1095.2, nsentences=32, sample_size=1095.2, sample_size_v1=0, sample_size_v2=0, ppl=2.25, wps=584.2, ups=0.53, wpb=1095.2, bsz=32, num_updates=10600, lr=2.54038e-05, gnorm=2.097, clip=100, loss_scale=256, train_wall=19, gb_free=10.9, wall=19922
2023-05-26 04:55:26 - progress_bar.py[line:272] - INFO: epoch 007:    235 / 1732 loss=2.423, loss_v1=0, loss_v2=0, nll_loss=1.228, ntokens=1090, nsentences=32, sample_size=1090, sample_size_v1=0, sample_size_v2=0, ppl=2.34, wps=583.3, ups=0.54, wpb=1090, bsz=32, num_updates=10610, lr=2.53977e-05, gnorm=2.169, clip=100, loss_scale=256, train_wall=19, gb_free=11.2, wall=19941
2023-05-26 04:55:45 - progress_bar.py[line:272] - INFO: epoch 007:    245 / 1732 loss=2.402, loss_v1=0, loss_v2=0, nll_loss=1.207, ntokens=1178.2, nsentences=32, sample_size=1178.2, sample_size_v1=0, sample_size_v2=0, ppl=2.31, wps=626.2, ups=0.53, wpb=1178.2, bsz=32, num_updates=10620, lr=2.53916e-05, gnorm=1.935, clip=100, loss_scale=256, train_wall=19, gb_free=10.8, wall=19960
2023-05-26 04:56:04 - progress_bar.py[line:272] - INFO: epoch 007:    255 / 1732 loss=2.393, loss_v1=0, loss_v2=0, nll_loss=1.194, ntokens=1128.2, nsentences=32, sample_size=1128.2, sample_size_v1=0, sample_size_v2=0, ppl=2.29, wps=602.4, ups=0.53, wpb=1128.2, bsz=32, num_updates=10630, lr=2.53854e-05, gnorm=2.04, clip=100, loss_scale=256, train_wall=19, gb_free=11.8, wall=19979
2023-05-26 04:56:23 - progress_bar.py[line:272] - INFO: epoch 007:    265 / 1732 loss=2.389, loss_v1=0, loss_v2=0, nll_loss=1.19, ntokens=1148, nsentences=32, sample_size=1148, sample_size_v1=0, sample_size_v2=0, ppl=2.28, wps=611.5, ups=0.53, wpb=1148, bsz=32, num_updates=10640, lr=2.53793e-05, gnorm=2.127, clip=100, loss_scale=256, train_wall=19, gb_free=11.3, wall=19997
2023-05-26 04:56:42 - progress_bar.py[line:272] - INFO: epoch 007:    275 / 1732 loss=2.38, loss_v1=0, loss_v2=0, nll_loss=1.181, ntokens=1140.3, nsentences=32, sample_size=1140.3, sample_size_v1=0, sample_size_v2=0, ppl=2.27, wps=604.3, ups=0.53, wpb=1140.3, bsz=32, num_updates=10650, lr=2.53731e-05, gnorm=2.19, clip=100, loss_scale=256, train_wall=19, gb_free=11.4, wall=20016
2023-05-26 04:57:01 - progress_bar.py[line:272] - INFO: epoch 007:    285 / 1732 loss=2.397, loss_v1=0, loss_v2=0, nll_loss=1.199, ntokens=1154.4, nsentences=32, sample_size=1154.4, sample_size_v1=0, sample_size_v2=0, ppl=2.3, wps=612.2, ups=0.53, wpb=1154.4, bsz=32, num_updates=10660, lr=2.5367e-05, gnorm=2.231, clip=100, loss_scale=256, train_wall=19, gb_free=10.3, wall=20035
2023-05-26 04:57:19 - progress_bar.py[line:272] - INFO: epoch 007:    295 / 1732 loss=2.373, loss_v1=0, loss_v2=0, nll_loss=1.175, ntokens=1115.8, nsentences=32, sample_size=1115.8, sample_size_v1=0, sample_size_v2=0, ppl=2.26, wps=595.3, ups=0.53, wpb=1115.8, bsz=32, num_updates=10670, lr=2.53609e-05, gnorm=2.235, clip=100, loss_scale=256, train_wall=19, gb_free=11.4, wall=20054
2023-05-26 04:57:38 - progress_bar.py[line:272] - INFO: epoch 007:    305 / 1732 loss=2.368, loss_v1=0, loss_v2=0, nll_loss=1.167, ntokens=1102.2, nsentences=32, sample_size=1102.2, sample_size_v1=0, sample_size_v2=0, ppl=2.25, wps=588.7, ups=0.53, wpb=1102.2, bsz=32, num_updates=10680, lr=2.53547e-05, gnorm=2.335, clip=100, loss_scale=256, train_wall=19, gb_free=11, wall=20073
2023-05-26 04:57:57 - progress_bar.py[line:272] - INFO: epoch 007:    315 / 1732 loss=2.384, loss_v1=0, loss_v2=0, nll_loss=1.184, ntokens=1020.3, nsentences=32, sample_size=1020.3, sample_size_v1=0, sample_size_v2=0, ppl=2.27, wps=548.7, ups=0.54, wpb=1020.3, bsz=32, num_updates=10690, lr=2.53486e-05, gnorm=2.419, clip=100, loss_scale=256, train_wall=19, gb_free=11.5, wall=20091
2023-05-26 04:58:15 - progress_bar.py[line:272] - INFO: epoch 007:    325 / 1732 loss=2.396, loss_v1=0, loss_v2=0, nll_loss=1.198, ntokens=1011.9, nsentences=32, sample_size=1011.9, sample_size_v1=0, sample_size_v2=0, ppl=2.29, wps=543.5, ups=0.54, wpb=1011.9, bsz=32, num_updates=10700, lr=2.53424e-05, gnorm=2.458, clip=100, loss_scale=256, train_wall=19, gb_free=11.7, wall=20110
2023-05-26 04:58:34 - progress_bar.py[line:272] - INFO: epoch 007:    335 / 1732 loss=2.401, loss_v1=0, loss_v2=0, nll_loss=1.206, ntokens=1020.9, nsentences=32, sample_size=1020.9, sample_size_v1=0, sample_size_v2=0, ppl=2.31, wps=550, ups=0.54, wpb=1020.9, bsz=32, num_updates=10710, lr=2.53363e-05, gnorm=2.477, clip=100, loss_scale=256, train_wall=19, gb_free=11.8, wall=20128
2023-05-26 04:58:52 - progress_bar.py[line:272] - INFO: epoch 007:    345 / 1732 loss=2.358, loss_v1=0, loss_v2=0, nll_loss=1.156, ntokens=903.9, nsentences=32, sample_size=903.9, sample_size_v1=0, sample_size_v2=0, ppl=2.23, wps=489.3, ups=0.54, wpb=903.9, bsz=32, num_updates=10720, lr=2.53301e-05, gnorm=2.68, clip=100, loss_scale=256, train_wall=18, gb_free=11.6, wall=20147
2023-05-26 04:59:11 - progress_bar.py[line:272] - INFO: epoch 007:    355 / 1732 loss=2.398, loss_v1=0, loss_v2=0, nll_loss=1.201, ntokens=961.9, nsentences=32, sample_size=961.9, sample_size_v1=0, sample_size_v2=0, ppl=2.3, wps=518.9, ups=0.54, wpb=961.9, bsz=32, num_updates=10730, lr=2.5324e-05, gnorm=2.624, clip=100, loss_scale=256, train_wall=19, gb_free=11.8, wall=20165
2023-05-26 04:59:29 - progress_bar.py[line:272] - INFO: epoch 007:    365 / 1732 loss=2.423, loss_v1=0, loss_v2=0, nll_loss=1.226, ntokens=955.9, nsentences=32, sample_size=955.9, sample_size_v1=0, sample_size_v2=0, ppl=2.34, wps=516, ups=0.54, wpb=955.9, bsz=32, num_updates=10740, lr=2.53179e-05, gnorm=2.399, clip=100, loss_scale=256, train_wall=18, gb_free=11, wall=20184
2023-05-26 04:59:48 - progress_bar.py[line:272] - INFO: epoch 007:    375 / 1732 loss=2.416, loss_v1=0, loss_v2=0, nll_loss=1.222, ntokens=987.5, nsentences=32, sample_size=987.5, sample_size_v1=0, sample_size_v2=0, ppl=2.33, wps=533.9, ups=0.54, wpb=987.5, bsz=32, num_updates=10750, lr=2.53117e-05, gnorm=2.426, clip=100, loss_scale=256, train_wall=18, gb_free=11.6, wall=20203
2023-05-26 05:00:06 - progress_bar.py[line:272] - INFO: epoch 007:    385 / 1732 loss=2.406, loss_v1=0, loss_v2=0, nll_loss=1.21, ntokens=1084.2, nsentences=32, sample_size=1084.2, sample_size_v1=0, sample_size_v2=0, ppl=2.31, wps=583, ups=0.54, wpb=1084.2, bsz=32, num_updates=10760, lr=2.53056e-05, gnorm=2.295, clip=100, loss_scale=256, train_wall=19, gb_free=11.6, wall=20221
2023-05-26 05:00:25 - progress_bar.py[line:272] - INFO: epoch 007:    395 / 1732 loss=2.402, loss_v1=0, loss_v2=0, nll_loss=1.205, ntokens=924.7, nsentences=32, sample_size=924.7, sample_size_v1=0, sample_size_v2=0, ppl=2.3, wps=501.1, ups=0.54, wpb=924.7, bsz=32, num_updates=10770, lr=2.52994e-05, gnorm=2.653, clip=100, loss_scale=256, train_wall=18, gb_free=11.6, wall=20240
2023-05-26 05:00:44 - progress_bar.py[line:272] - INFO: epoch 007:    405 / 1732 loss=2.353, loss_v1=0, loss_v2=0, nll_loss=1.151, ntokens=1086.5, nsentences=32, sample_size=1086.5, sample_size_v1=0, sample_size_v2=0, ppl=2.22, wps=582, ups=0.54, wpb=1086.5, bsz=32, num_updates=10780, lr=2.52933e-05, gnorm=2.104, clip=100, loss_scale=256, train_wall=19, gb_free=11.8, wall=20258
2023-05-26 05:01:02 - progress_bar.py[line:272] - INFO: epoch 007:    415 / 1732 loss=2.37, loss_v1=0, loss_v2=0, nll_loss=1.17, ntokens=1059.1, nsentences=32, sample_size=1059.1, sample_size_v1=0, sample_size_v2=0, ppl=2.25, wps=568, ups=0.54, wpb=1059.1, bsz=32, num_updates=10790, lr=2.52871e-05, gnorm=2.191, clip=100, loss_scale=256, train_wall=19, gb_free=11.9, wall=20277
2023-05-26 05:01:21 - progress_bar.py[line:272] - INFO: epoch 007:    425 / 1732 loss=2.336, loss_v1=0, loss_v2=0, nll_loss=1.13, ntokens=994.5, nsentences=32, sample_size=994.5, sample_size_v1=0, sample_size_v2=0, ppl=2.19, wps=534, ups=0.54, wpb=994.5, bsz=32, num_updates=10800, lr=2.5281e-05, gnorm=2.248, clip=100, loss_scale=256, train_wall=19, gb_free=11.6, wall=20296
2023-05-26 05:01:39 - progress_bar.py[line:272] - INFO: epoch 007:    435 / 1732 loss=2.39, loss_v1=0, loss_v2=0, nll_loss=1.193, ntokens=1024.5, nsentences=32, sample_size=1024.5, sample_size_v1=0, sample_size_v2=0, ppl=2.29, wps=551.3, ups=0.54, wpb=1024.5, bsz=32, num_updates=10810, lr=2.52749e-05, gnorm=2.173, clip=100, loss_scale=256, train_wall=19, gb_free=11.8, wall=20314
2023-05-26 05:01:58 - progress_bar.py[line:272] - INFO: epoch 007:    445 / 1732 loss=2.402, loss_v1=0, loss_v2=0, nll_loss=1.206, ntokens=956.5, nsentences=32, sample_size=956.5, sample_size_v1=0, sample_size_v2=0, ppl=2.31, wps=515.2, ups=0.54, wpb=956.5, bsz=32, num_updates=10820, lr=2.52687e-05, gnorm=2.283, clip=100, loss_scale=256, train_wall=19, gb_free=11, wall=20333
2023-05-26 05:02:16 - progress_bar.py[line:272] - INFO: epoch 007:    455 / 1732 loss=2.395, loss_v1=0, loss_v2=0, nll_loss=1.198, ntokens=932.1, nsentences=32, sample_size=932.1, sample_size_v1=0, sample_size_v2=0, ppl=2.29, wps=505.1, ups=0.54, wpb=932.1, bsz=32, num_updates=10830, lr=2.52626e-05, gnorm=2.494, clip=100, loss_scale=256, train_wall=18, gb_free=11.5, wall=20351
2023-05-26 05:02:35 - progress_bar.py[line:272] - INFO: epoch 007:    465 / 1732 loss=2.416, loss_v1=0, loss_v2=0, nll_loss=1.22, ntokens=1058.7, nsentences=32, sample_size=1058.7, sample_size_v1=0, sample_size_v2=0, ppl=2.33, wps=567, ups=0.54, wpb=1058.7, bsz=32, num_updates=10840, lr=2.52564e-05, gnorm=2.29, clip=100, loss_scale=256, train_wall=19, gb_free=11.1, wall=20370
2023-05-26 05:02:54 - progress_bar.py[line:272] - INFO: epoch 007:    475 / 1732 loss=2.407, loss_v1=0, loss_v2=0, nll_loss=1.208, ntokens=1061.8, nsentences=32, sample_size=1061.8, sample_size_v1=0, sample_size_v2=0, ppl=2.31, wps=567.1, ups=0.53, wpb=1061.8, bsz=32, num_updates=10850, lr=2.52503e-05, gnorm=2.334, clip=100, loss_scale=256, train_wall=19, gb_free=11.4, wall=20389
2023-05-26 05:03:12 - progress_bar.py[line:272] - INFO: epoch 007:    485 / 1732 loss=2.382, loss_v1=0, loss_v2=0, nll_loss=1.183, ntokens=980.2, nsentences=32, sample_size=980.2, sample_size_v1=0, sample_size_v2=0, ppl=2.27, wps=530, ups=0.54, wpb=980.2, bsz=32, num_updates=10860, lr=2.52441e-05, gnorm=2.319, clip=100, loss_scale=256, train_wall=18, gb_free=11.2, wall=20407
2023-05-26 05:03:31 - progress_bar.py[line:272] - INFO: epoch 007:    495 / 1732 loss=2.379, loss_v1=0, loss_v2=0, nll_loss=1.183, ntokens=928.7, nsentences=32, sample_size=928.7, sample_size_v1=0, sample_size_v2=0, ppl=2.27, wps=500.7, ups=0.54, wpb=928.7, bsz=32, num_updates=10870, lr=2.5238e-05, gnorm=2.47, clip=100, loss_scale=256, train_wall=19, gb_free=12, wall=20426
2023-05-26 05:03:49 - progress_bar.py[line:272] - INFO: epoch 007:    505 / 1732 loss=2.396, loss_v1=0, loss_v2=0, nll_loss=1.198, ntokens=974.8, nsentences=32, sample_size=974.8, sample_size_v1=0, sample_size_v2=0, ppl=2.29, wps=529.4, ups=0.54, wpb=974.8, bsz=32, num_updates=10880, lr=2.52319e-05, gnorm=2.482, clip=100, loss_scale=256, train_wall=18, gb_free=11.5, wall=20444
2023-05-26 05:04:08 - progress_bar.py[line:272] - INFO: epoch 007:    515 / 1732 loss=2.397, loss_v1=0, loss_v2=0, nll_loss=1.2, ntokens=1073.1, nsentences=32, sample_size=1073.1, sample_size_v1=0, sample_size_v2=0, ppl=2.3, wps=576.2, ups=0.54, wpb=1073.1, bsz=32, num_updates=10890, lr=2.52257e-05, gnorm=2.362, clip=100, loss_scale=256, train_wall=19, gb_free=11.2, wall=20463
2023-05-26 05:04:26 - progress_bar.py[line:272] - INFO: epoch 007:    525 / 1732 loss=2.382, loss_v1=0, loss_v2=0, nll_loss=1.184, ntokens=955.6, nsentences=32, sample_size=955.6, sample_size_v1=0, sample_size_v2=0, ppl=2.27, wps=517.7, ups=0.54, wpb=955.6, bsz=32, num_updates=10900, lr=2.52196e-05, gnorm=2.559, clip=100, loss_scale=256, train_wall=18, gb_free=11.7, wall=20481
2023-05-26 05:04:45 - progress_bar.py[line:272] - INFO: epoch 007:    535 / 1732 loss=2.379, loss_v1=0, loss_v2=0, nll_loss=1.178, ntokens=948.7, nsentences=32, sample_size=948.7, sample_size_v1=0, sample_size_v2=0, ppl=2.26, wps=514.7, ups=0.54, wpb=948.7, bsz=32, num_updates=10910, lr=2.52134e-05, gnorm=2.607, clip=100, loss_scale=256, train_wall=18, gb_free=11.3, wall=20500
2023-05-26 05:05:03 - progress_bar.py[line:272] - INFO: epoch 007:    545 / 1732 loss=2.395, loss_v1=0, loss_v2=0, nll_loss=1.197, ntokens=1010, nsentences=32, sample_size=1010, sample_size_v1=0, sample_size_v2=0, ppl=2.29, wps=545, ups=0.54, wpb=1010, bsz=32, num_updates=10920, lr=2.52073e-05, gnorm=2.425, clip=100, loss_scale=256, train_wall=19, gb_free=11.1, wall=20518
2023-05-26 05:05:22 - progress_bar.py[line:272] - INFO: epoch 007:    555 / 1732 loss=2.429, loss_v1=0, loss_v2=0, nll_loss=1.236, ntokens=1039.8, nsentences=32, sample_size=1039.8, sample_size_v1=0, sample_size_v2=0, ppl=2.36, wps=560.3, ups=0.54, wpb=1039.8, bsz=32, num_updates=10930, lr=2.52012e-05, gnorm=2.467, clip=100, loss_scale=256, train_wall=19, gb_free=11.3, wall=20537
2023-05-26 05:05:41 - progress_bar.py[line:272] - INFO: epoch 007:    565 / 1732 loss=2.408, loss_v1=0, loss_v2=0, nll_loss=1.21, ntokens=1014, nsentences=32, sample_size=1014, sample_size_v1=0, sample_size_v2=0, ppl=2.31, wps=544.8, ups=0.54, wpb=1014, bsz=32, num_updates=10940, lr=2.5195e-05, gnorm=2.638, clip=100, loss_scale=256, train_wall=19, gb_free=11.2, wall=20555
2023-05-26 05:05:59 - progress_bar.py[line:272] - INFO: epoch 007:    575 / 1732 loss=2.399, loss_v1=0, loss_v2=0, nll_loss=1.201, ntokens=1007.3, nsentences=32, sample_size=1007.3, sample_size_v1=0, sample_size_v2=0, ppl=2.3, wps=539.4, ups=0.54, wpb=1007.3, bsz=32, num_updates=10950, lr=2.51889e-05, gnorm=2.617, clip=100, loss_scale=256, train_wall=19, gb_free=11.5, wall=20574
2023-05-26 05:06:18 - progress_bar.py[line:272] - INFO: epoch 007:    585 / 1732 loss=2.403, loss_v1=0, loss_v2=0, nll_loss=1.206, ntokens=980.6, nsentences=32, sample_size=980.6, sample_size_v1=0, sample_size_v2=0, ppl=2.31, wps=524.3, ups=0.53, wpb=980.6, bsz=32, num_updates=10960, lr=2.51827e-05, gnorm=2.425, clip=100, loss_scale=256, train_wall=19, gb_free=11.6, wall=20593
2023-05-26 05:06:37 - progress_bar.py[line:272] - INFO: epoch 007:    595 / 1732 loss=2.362, loss_v1=0, loss_v2=0, nll_loss=1.161, ntokens=961.9, nsentences=32, sample_size=961.9, sample_size_v1=0, sample_size_v2=0, ppl=2.24, wps=516.6, ups=0.54, wpb=961.9, bsz=32, num_updates=10970, lr=2.51766e-05, gnorm=2.338, clip=100, loss_scale=256, train_wall=19, gb_free=11.6, wall=20611
2023-05-26 05:06:55 - progress_bar.py[line:272] - INFO: epoch 007:    605 / 1732 loss=2.369, loss_v1=0, loss_v2=0, nll_loss=1.171, ntokens=879.8, nsentences=32, sample_size=879.8, sample_size_v1=0, sample_size_v2=0, ppl=2.25, wps=478, ups=0.54, wpb=879.8, bsz=32, num_updates=10980, lr=2.51704e-05, gnorm=2.621, clip=100, loss_scale=256, train_wall=18, gb_free=12, wall=20630
2023-05-26 05:07:14 - progress_bar.py[line:272] - INFO: epoch 007:    615 / 1732 loss=2.402, loss_v1=0, loss_v2=0, nll_loss=1.203, ntokens=903.1, nsentences=32, sample_size=903.1, sample_size_v1=0, sample_size_v2=0, ppl=2.3, wps=487.7, ups=0.54, wpb=903.1, bsz=32, num_updates=10990, lr=2.51643e-05, gnorm=2.809, clip=100, loss_scale=256, train_wall=18, gb_free=11.7, wall=20648
2023-05-26 05:07:32 - progress_bar.py[line:272] - INFO: epoch 007:    625 / 1732 loss=2.402, loss_v1=0, loss_v2=0, nll_loss=1.204, ntokens=898.6, nsentences=32, sample_size=898.6, sample_size_v1=0, sample_size_v2=0, ppl=2.3, wps=488.4, ups=0.54, wpb=898.6, bsz=32, num_updates=11000, lr=2.51582e-05, gnorm=2.8, clip=100, loss_scale=256, train_wall=18, gb_free=11.4, wall=20667
2023-05-26 05:07:50 - progress_bar.py[line:272] - INFO: epoch 007:    635 / 1732 loss=2.402, loss_v1=0, loss_v2=0, nll_loss=1.207, ntokens=897.1, nsentences=32, sample_size=897.1, sample_size_v1=0, sample_size_v2=0, ppl=2.31, wps=488.5, ups=0.54, wpb=897.1, bsz=32, num_updates=11010, lr=2.5152e-05, gnorm=2.773, clip=100, loss_scale=256, train_wall=18, gb_free=11.8, wall=20685
2023-05-26 05:08:09 - progress_bar.py[line:272] - INFO: epoch 007:    645 / 1732 loss=2.398, loss_v1=0, loss_v2=0, nll_loss=1.199, ntokens=1010.4, nsentences=32, sample_size=1010.4, sample_size_v1=0, sample_size_v2=0, ppl=2.3, wps=545.9, ups=0.54, wpb=1010.4, bsz=32, num_updates=11020, lr=2.51459e-05, gnorm=2.572, clip=100, loss_scale=256, train_wall=18, gb_free=11.8, wall=20703
2023-05-26 05:08:27 - progress_bar.py[line:272] - INFO: epoch 007:    655 / 1732 loss=2.398, loss_v1=0, loss_v2=0, nll_loss=1.202, ntokens=879.8, nsentences=32, sample_size=879.8, sample_size_v1=0, sample_size_v2=0, ppl=2.3, wps=480.4, ups=0.55, wpb=879.8, bsz=32, num_updates=11030, lr=2.51397e-05, gnorm=2.713, clip=100, loss_scale=256, train_wall=18, gb_free=11.8, wall=20722
2023-05-26 05:08:45 - progress_bar.py[line:272] - INFO: epoch 007:    665 / 1732 loss=2.397, loss_v1=0, loss_v2=0, nll_loss=1.202, ntokens=893.8, nsentences=32, sample_size=893.8, sample_size_v1=0, sample_size_v2=0, ppl=2.3, wps=488.5, ups=0.55, wpb=893.8, bsz=32, num_updates=11040, lr=2.51336e-05, gnorm=2.789, clip=100, loss_scale=256, train_wall=18, gb_free=12, wall=20740
2023-05-26 05:09:04 - progress_bar.py[line:272] - INFO: epoch 007:    675 / 1732 loss=2.403, loss_v1=0, loss_v2=0, nll_loss=1.205, ntokens=961.9, nsentences=32, sample_size=961.9, sample_size_v1=0, sample_size_v2=0, ppl=2.31, wps=518.1, ups=0.54, wpb=961.9, bsz=32, num_updates=11050, lr=2.51274e-05, gnorm=2.606, clip=100, loss_scale=256, train_wall=19, gb_free=10.9, wall=20759
2023-05-26 05:09:22 - progress_bar.py[line:272] - INFO: epoch 007:    685 / 1732 loss=2.396, loss_v1=0, loss_v2=0, nll_loss=1.197, ntokens=961.5, nsentences=32, sample_size=961.5, sample_size_v1=0, sample_size_v2=0, ppl=2.29, wps=521.5, ups=0.54, wpb=961.5, bsz=32, num_updates=11060, lr=2.51213e-05, gnorm=2.816, clip=100, loss_scale=256, train_wall=18, gb_free=11.5, wall=20777
2023-05-26 05:09:41 - progress_bar.py[line:272] - INFO: epoch 007:    695 / 1732 loss=2.402, loss_v1=0, loss_v2=0, nll_loss=1.209, ntokens=1007.2, nsentences=32, sample_size=1007.2, sample_size_v1=0, sample_size_v2=0, ppl=2.31, wps=538.8, ups=0.53, wpb=1007.2, bsz=32, num_updates=11070, lr=2.51152e-05, gnorm=2.636, clip=100, loss_scale=256, train_wall=19, gb_free=10.5, wall=20796
2023-05-26 05:10:00 - progress_bar.py[line:272] - INFO: epoch 007:    705 / 1732 loss=2.367, loss_v1=0, loss_v2=0, nll_loss=1.161, ntokens=925.6, nsentences=32, sample_size=925.6, sample_size_v1=0, sample_size_v2=0, ppl=2.24, wps=502.1, ups=0.54, wpb=925.6, bsz=32, num_updates=11080, lr=2.5109e-05, gnorm=2.449, clip=100, loss_scale=256, train_wall=18, gb_free=11.8, wall=20814
2023-05-26 05:10:12 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 256.0
2023-05-26 05:10:20 - progress_bar.py[line:272] - INFO: epoch 007:    716 / 1732 loss=2.405, loss_v1=0, loss_v2=0, nll_loss=1.209, ntokens=890.3, nsentences=32, sample_size=890.3, sample_size_v1=0, sample_size_v2=0, ppl=2.31, wps=441.5, ups=0.5, wpb=890.3, bsz=32, num_updates=11090, lr=2.51029e-05, gnorm=2.589, clip=100, loss_scale=256, train_wall=20, gb_free=11.7, wall=20834
2023-05-26 05:10:38 - progress_bar.py[line:272] - INFO: epoch 007:    726 / 1732 loss=2.362, loss_v1=0, loss_v2=0, nll_loss=1.163, ntokens=913.6, nsentences=32, sample_size=913.6, sample_size_v1=0, sample_size_v2=0, ppl=2.24, wps=495.5, ups=0.54, wpb=913.6, bsz=32, num_updates=11100, lr=2.50967e-05, gnorm=2.76, clip=100, loss_scale=256, train_wall=18, gb_free=11.1, wall=20853
2023-05-26 05:10:57 - progress_bar.py[line:272] - INFO: epoch 007:    736 / 1732 loss=2.378, loss_v1=0, loss_v2=0, nll_loss=1.176, ntokens=979.7, nsentences=32, sample_size=979.7, sample_size_v1=0, sample_size_v2=0, ppl=2.26, wps=532.1, ups=0.54, wpb=979.7, bsz=32, num_updates=11110, lr=2.50906e-05, gnorm=2.745, clip=100, loss_scale=256, train_wall=18, gb_free=11.8, wall=20871
2023-05-26 05:11:15 - progress_bar.py[line:272] - INFO: epoch 007:    746 / 1732 loss=2.372, loss_v1=0, loss_v2=0, nll_loss=1.169, ntokens=974.7, nsentences=32, sample_size=974.7, sample_size_v1=0, sample_size_v2=0, ppl=2.25, wps=524.8, ups=0.54, wpb=974.7, bsz=32, num_updates=11120, lr=2.50845e-05, gnorm=2.58, clip=100, loss_scale=256, train_wall=19, gb_free=11.5, wall=20890
2023-05-26 05:11:34 - progress_bar.py[line:272] - INFO: epoch 007:    756 / 1732 loss=2.376, loss_v1=0, loss_v2=0, nll_loss=1.176, ntokens=977.2, nsentences=32, sample_size=977.2, sample_size_v1=0, sample_size_v2=0, ppl=2.26, wps=528, ups=0.54, wpb=977.2, bsz=32, num_updates=11130, lr=2.50783e-05, gnorm=2.447, clip=100, loss_scale=256, train_wall=18, gb_free=11.2, wall=20908
2023-05-26 05:11:52 - progress_bar.py[line:272] - INFO: epoch 007:    766 / 1732 loss=2.371, loss_v1=0, loss_v2=0, nll_loss=1.174, ntokens=933.3, nsentences=32, sample_size=933.3, sample_size_v1=0, sample_size_v2=0, ppl=2.26, wps=505.8, ups=0.54, wpb=933.3, bsz=32, num_updates=11140, lr=2.50722e-05, gnorm=2.663, clip=100, loss_scale=256, train_wall=18, gb_free=11.6, wall=20927
2023-05-26 05:12:11 - progress_bar.py[line:272] - INFO: epoch 007:    776 / 1732 loss=2.377, loss_v1=0, loss_v2=0, nll_loss=1.175, ntokens=1027.3, nsentences=32, sample_size=1027.3, sample_size_v1=0, sample_size_v2=0, ppl=2.26, wps=554.8, ups=0.54, wpb=1027.3, bsz=32, num_updates=11150, lr=2.5066e-05, gnorm=2.555, clip=100, loss_scale=256, train_wall=18, gb_free=11.3, wall=20945
2023-05-26 05:12:29 - progress_bar.py[line:272] - INFO: epoch 007:    786 / 1732 loss=2.388, loss_v1=0, loss_v2=0, nll_loss=1.19, ntokens=1013.1, nsentences=32, sample_size=1013.1, sample_size_v1=0, sample_size_v2=0, ppl=2.28, wps=548.8, ups=0.54, wpb=1013.1, bsz=32, num_updates=11160, lr=2.50599e-05, gnorm=2.593, clip=100, loss_scale=256, train_wall=18, gb_free=11.9, wall=20964
2023-05-26 05:12:48 - progress_bar.py[line:272] - INFO: epoch 007:    796 / 1732 loss=2.379, loss_v1=0, loss_v2=0, nll_loss=1.182, ntokens=1030.3, nsentences=32, sample_size=1030.3, sample_size_v1=0, sample_size_v2=0, ppl=2.27, wps=556.7, ups=0.54, wpb=1030.3, bsz=32, num_updates=11170, lr=2.50537e-05, gnorm=2.535, clip=100, loss_scale=256, train_wall=18, gb_free=11.2, wall=20982
2023-05-26 05:13:06 - progress_bar.py[line:272] - INFO: epoch 007:    806 / 1732 loss=2.378, loss_v1=0, loss_v2=0, nll_loss=1.176, ntokens=912.3, nsentences=32, sample_size=912.3, sample_size_v1=0, sample_size_v2=0, ppl=2.26, wps=494.3, ups=0.54, wpb=912.3, bsz=32, num_updates=11180, lr=2.50476e-05, gnorm=2.637, clip=100, loss_scale=256, train_wall=18, gb_free=11.8, wall=21001
2023-05-26 05:13:25 - progress_bar.py[line:272] - INFO: epoch 007:    816 / 1732 loss=2.38, loss_v1=0, loss_v2=0, nll_loss=1.18, ntokens=920, nsentences=32, sample_size=920, sample_size_v1=0, sample_size_v2=0, ppl=2.27, wps=498.4, ups=0.54, wpb=920, bsz=32, num_updates=11190, lr=2.50415e-05, gnorm=2.589, clip=100, loss_scale=256, train_wall=18, gb_free=11, wall=21019
2023-05-26 05:13:43 - progress_bar.py[line:272] - INFO: epoch 007:    826 / 1732 loss=2.384, loss_v1=0, loss_v2=0, nll_loss=1.186, ntokens=944.4, nsentences=32, sample_size=944.4, sample_size_v1=0, sample_size_v2=0, ppl=2.28, wps=509, ups=0.54, wpb=944.4, bsz=32, num_updates=11200, lr=2.50353e-05, gnorm=2.599, clip=100, loss_scale=256, train_wall=19, gb_free=11.6, wall=21038
2023-05-26 05:14:01 - progress_bar.py[line:272] - INFO: epoch 007:    836 / 1732 loss=2.388, loss_v1=0, loss_v2=0, nll_loss=1.189, ntokens=894, nsentences=32, sample_size=894, sample_size_v1=0, sample_size_v2=0, ppl=2.28, wps=488, ups=0.55, wpb=894, bsz=32, num_updates=11210, lr=2.50292e-05, gnorm=2.725, clip=100, loss_scale=256, train_wall=18, gb_free=11.8, wall=21056
2023-05-26 05:14:20 - progress_bar.py[line:272] - INFO: epoch 007:    846 / 1732 loss=2.359, loss_v1=0, loss_v2=0, nll_loss=1.155, ntokens=995.1, nsentences=32, sample_size=995.1, sample_size_v1=0, sample_size_v2=0, ppl=2.23, wps=539, ups=0.54, wpb=995.1, bsz=32, num_updates=11220, lr=2.5023e-05, gnorm=2.415, clip=100, loss_scale=256, train_wall=18, gb_free=11.6, wall=21075
2023-05-26 05:14:38 - progress_bar.py[line:272] - INFO: epoch 007:    856 / 1732 loss=2.379, loss_v1=0, loss_v2=0, nll_loss=1.184, ntokens=944.9, nsentences=32, sample_size=944.9, sample_size_v1=0, sample_size_v2=0, ppl=2.27, wps=511.8, ups=0.54, wpb=944.9, bsz=32, num_updates=11230, lr=2.50169e-05, gnorm=2.754, clip=100, loss_scale=256, train_wall=18, gb_free=11.6, wall=21093
2023-05-26 05:14:57 - progress_bar.py[line:272] - INFO: epoch 007:    866 / 1732 loss=2.396, loss_v1=0, loss_v2=0, nll_loss=1.196, ntokens=954.3, nsentences=32, sample_size=954.3, sample_size_v1=0, sample_size_v2=0, ppl=2.29, wps=516.9, ups=0.54, wpb=954.3, bsz=32, num_updates=11240, lr=2.50107e-05, gnorm=2.969, clip=100, loss_scale=256, train_wall=18, gb_free=11.3, wall=21111
2023-05-26 05:15:15 - progress_bar.py[line:272] - INFO: epoch 007:    876 / 1732 loss=2.332, loss_v1=0, loss_v2=0, nll_loss=1.127, ntokens=1023, nsentences=32, sample_size=1023, sample_size_v1=0, sample_size_v2=0, ppl=2.18, wps=550.7, ups=0.54, wpb=1023, bsz=32, num_updates=11250, lr=2.50046e-05, gnorm=2.434, clip=100, loss_scale=256, train_wall=19, gb_free=11.4, wall=21130
2023-05-26 05:15:34 - progress_bar.py[line:272] - INFO: epoch 007:    886 / 1732 loss=2.334, loss_v1=0, loss_v2=0, nll_loss=1.13, ntokens=963.8, nsentences=32, sample_size=963.8, sample_size_v1=0, sample_size_v2=0, ppl=2.19, wps=518.9, ups=0.54, wpb=963.8, bsz=32, num_updates=11260, lr=2.49985e-05, gnorm=2.623, clip=100, loss_scale=256, train_wall=19, gb_free=11, wall=21149
2023-05-26 05:15:52 - progress_bar.py[line:272] - INFO: epoch 007:    896 / 1732 loss=2.326, loss_v1=0, loss_v2=0, nll_loss=1.117, ntokens=1021.4, nsentences=32, sample_size=1021.4, sample_size_v1=0, sample_size_v2=0, ppl=2.17, wps=551.4, ups=0.54, wpb=1021.4, bsz=32, num_updates=11270, lr=2.49923e-05, gnorm=2.357, clip=100, loss_scale=256, train_wall=18, gb_free=11.5, wall=21167
2023-05-26 05:16:11 - progress_bar.py[line:272] - INFO: epoch 007:    906 / 1732 loss=2.332, loss_v1=0, loss_v2=0, nll_loss=1.129, ntokens=1030.5, nsentences=32, sample_size=1030.5, sample_size_v1=0, sample_size_v2=0, ppl=2.19, wps=554, ups=0.54, wpb=1030.5, bsz=32, num_updates=11280, lr=2.49862e-05, gnorm=2.342, clip=100, loss_scale=256, train_wall=19, gb_free=10.6, wall=21186
2023-05-26 05:16:30 - progress_bar.py[line:272] - INFO: epoch 007:    916 / 1732 loss=2.399, loss_v1=0, loss_v2=0, nll_loss=1.201, ntokens=932.7, nsentences=32, sample_size=932.7, sample_size_v1=0, sample_size_v2=0, ppl=2.3, wps=505.9, ups=0.54, wpb=932.7, bsz=32, num_updates=11290, lr=2.498e-05, gnorm=2.861, clip=100, loss_scale=256, train_wall=18, gb_free=11.3, wall=21204
2023-05-26 05:16:48 - progress_bar.py[line:272] - INFO: epoch 007:    926 / 1732 loss=2.353, loss_v1=0, loss_v2=0, nll_loss=1.151, ntokens=1024.6, nsentences=32, sample_size=1024.6, sample_size_v1=0, sample_size_v2=0, ppl=2.22, wps=547.9, ups=0.53, wpb=1024.6, bsz=32, num_updates=11300, lr=2.49739e-05, gnorm=2.555, clip=100, loss_scale=256, train_wall=19, gb_free=11.3, wall=21223
2023-05-26 05:17:07 - progress_bar.py[line:272] - INFO: epoch 007:    936 / 1732 loss=2.34, loss_v1=0, loss_v2=0, nll_loss=1.137, ntokens=1056.9, nsentences=32, sample_size=1056.9, sample_size_v1=0, sample_size_v2=0, ppl=2.2, wps=564.4, ups=0.53, wpb=1056.9, bsz=32, num_updates=11310, lr=2.49678e-05, gnorm=2.413, clip=100, loss_scale=256, train_wall=19, gb_free=11.5, wall=21242
2023-05-26 05:17:26 - progress_bar.py[line:272] - INFO: epoch 007:    946 / 1732 loss=2.38, loss_v1=0, loss_v2=0, nll_loss=1.18, ntokens=1053.9, nsentences=32, sample_size=1053.9, sample_size_v1=0, sample_size_v2=0, ppl=2.27, wps=560.1, ups=0.53, wpb=1053.9, bsz=32, num_updates=11320, lr=2.49616e-05, gnorm=2.296, clip=100, loss_scale=256, train_wall=19, gb_free=11.2, wall=21260
2023-05-26 05:17:44 - progress_bar.py[line:272] - INFO: epoch 007:    956 / 1732 loss=2.36, loss_v1=0, loss_v2=0, nll_loss=1.159, ntokens=1038.8, nsentences=32, sample_size=1038.8, sample_size_v1=0, sample_size_v2=0, ppl=2.23, wps=556, ups=0.54, wpb=1038.8, bsz=32, num_updates=11330, lr=2.49555e-05, gnorm=2.501, clip=100, loss_scale=256, train_wall=19, gb_free=11.2, wall=21279
2023-05-26 05:18:03 - progress_bar.py[line:272] - INFO: epoch 007:    966 / 1732 loss=2.373, loss_v1=0, loss_v2=0, nll_loss=1.173, ntokens=1045.2, nsentences=32, sample_size=1045.2, sample_size_v1=0, sample_size_v2=0, ppl=2.26, wps=556.9, ups=0.53, wpb=1045.2, bsz=32, num_updates=11340, lr=2.49493e-05, gnorm=2.592, clip=100, loss_scale=256, train_wall=19, gb_free=11.5, wall=21298
2023-05-26 05:18:22 - progress_bar.py[line:272] - INFO: epoch 007:    976 / 1732 loss=2.365, loss_v1=0, loss_v2=0, nll_loss=1.163, ntokens=1030.4, nsentences=32, sample_size=1030.4, sample_size_v1=0, sample_size_v2=0, ppl=2.24, wps=547.9, ups=0.53, wpb=1030.4, bsz=32, num_updates=11350, lr=2.49432e-05, gnorm=2.375, clip=100, loss_scale=256, train_wall=19, gb_free=11.7, wall=21317
2023-05-26 05:18:41 - progress_bar.py[line:272] - INFO: epoch 007:    986 / 1732 loss=2.368, loss_v1=0, loss_v2=0, nll_loss=1.168, ntokens=1042.1, nsentences=32, sample_size=1042.1, sample_size_v1=0, sample_size_v2=0, ppl=2.25, wps=551.1, ups=0.53, wpb=1042.1, bsz=32, num_updates=11360, lr=2.4937e-05, gnorm=2.344, clip=100, loss_scale=256, train_wall=19, gb_free=10.8, wall=21336
2023-05-26 05:19:00 - progress_bar.py[line:272] - INFO: epoch 007:    996 / 1732 loss=2.357, loss_v1=0, loss_v2=0, nll_loss=1.153, ntokens=1036.4, nsentences=32, sample_size=1036.4, sample_size_v1=0, sample_size_v2=0, ppl=2.22, wps=554.3, ups=0.53, wpb=1036.4, bsz=32, num_updates=11370, lr=2.49309e-05, gnorm=2.632, clip=100, loss_scale=256, train_wall=19, gb_free=11.7, wall=21354
2023-05-26 05:19:19 - progress_bar.py[line:272] - INFO: epoch 007:   1006 / 1732 loss=2.348, loss_v1=0, loss_v2=0, nll_loss=1.145, ntokens=1007.9, nsentences=32, sample_size=1007.9, sample_size_v1=0, sample_size_v2=0, ppl=2.21, wps=534.6, ups=0.53, wpb=1007.9, bsz=32, num_updates=11380, lr=2.49248e-05, gnorm=2.43, clip=100, loss_scale=256, train_wall=19, gb_free=11.5, wall=21373
2023-05-26 05:19:37 - progress_bar.py[line:272] - INFO: epoch 007:   1016 / 1732 loss=2.367, loss_v1=0, loss_v2=0, nll_loss=1.167, ntokens=979.4, nsentences=32, sample_size=979.4, sample_size_v1=0, sample_size_v2=0, ppl=2.25, wps=526.5, ups=0.54, wpb=979.4, bsz=32, num_updates=11390, lr=2.49186e-05, gnorm=2.66, clip=100, loss_scale=256, train_wall=19, gb_free=11.6, wall=21392
2023-05-26 05:19:56 - progress_bar.py[line:272] - INFO: epoch 007:   1026 / 1732 loss=2.361, loss_v1=0, loss_v2=0, nll_loss=1.159, ntokens=1095, nsentences=32, sample_size=1095, sample_size_v1=0, sample_size_v2=0, ppl=2.23, wps=578.8, ups=0.53, wpb=1095, bsz=32, num_updates=11400, lr=2.49125e-05, gnorm=2.461, clip=100, loss_scale=256, train_wall=19, gb_free=11.3, wall=21411
2023-05-26 05:20:15 - progress_bar.py[line:272] - INFO: epoch 007:   1036 / 1732 loss=2.349, loss_v1=0, loss_v2=0, nll_loss=1.146, ntokens=1118.5, nsentences=32, sample_size=1118.5, sample_size_v1=0, sample_size_v2=0, ppl=2.21, wps=592, ups=0.53, wpb=1118.5, bsz=32, num_updates=11410, lr=2.49063e-05, gnorm=2.391, clip=100, loss_scale=256, train_wall=19, gb_free=11.2, wall=21430
2023-05-26 05:20:34 - progress_bar.py[line:272] - INFO: epoch 007:   1046 / 1732 loss=2.356, loss_v1=0, loss_v2=0, nll_loss=1.152, ntokens=1013.5, nsentences=32, sample_size=1013.5, sample_size_v1=0, sample_size_v2=0, ppl=2.22, wps=540.8, ups=0.53, wpb=1013.5, bsz=32, num_updates=11420, lr=2.49002e-05, gnorm=2.807, clip=100, loss_scale=256, train_wall=19, gb_free=11.7, wall=21448
2023-05-26 05:20:52 - progress_bar.py[line:272] - INFO: epoch 007:   1056 / 1732 loss=2.362, loss_v1=0, loss_v2=0, nll_loss=1.162, ntokens=1086.8, nsentences=32, sample_size=1086.8, sample_size_v1=0, sample_size_v2=0, ppl=2.24, wps=579.7, ups=0.53, wpb=1086.8, bsz=32, num_updates=11430, lr=2.4894e-05, gnorm=2.533, clip=100, loss_scale=256, train_wall=19, gb_free=11.2, wall=21467
2023-05-26 05:21:11 - progress_bar.py[line:272] - INFO: epoch 007:   1066 / 1732 loss=2.35, loss_v1=0, loss_v2=0, nll_loss=1.146, ntokens=1024.1, nsentences=32, sample_size=1024.1, sample_size_v1=0, sample_size_v2=0, ppl=2.21, wps=547.3, ups=0.53, wpb=1024.1, bsz=32, num_updates=11440, lr=2.48879e-05, gnorm=2.317, clip=100, loss_scale=256, train_wall=19, gb_free=11.2, wall=21486
2023-05-26 05:21:30 - progress_bar.py[line:272] - INFO: epoch 007:   1076 / 1732 loss=2.389, loss_v1=0, loss_v2=0, nll_loss=1.19, ntokens=1000.2, nsentences=32, sample_size=1000.2, sample_size_v1=0, sample_size_v2=0, ppl=2.28, wps=531, ups=0.53, wpb=1000.2, bsz=32, num_updates=11450, lr=2.48818e-05, gnorm=2.484, clip=100, loss_scale=256, train_wall=19, gb_free=11.5, wall=21505
2023-05-26 05:21:49 - progress_bar.py[line:272] - INFO: epoch 007:   1086 / 1732 loss=2.357, loss_v1=0, loss_v2=0, nll_loss=1.156, ntokens=1073.8, nsentences=32, sample_size=1073.8, sample_size_v1=0, sample_size_v2=0, ppl=2.23, wps=567.2, ups=0.53, wpb=1073.8, bsz=32, num_updates=11460, lr=2.48756e-05, gnorm=2.255, clip=100, loss_scale=256, train_wall=19, gb_free=11.2, wall=21524
2023-05-26 05:22:08 - progress_bar.py[line:272] - INFO: epoch 007:   1096 / 1732 loss=2.367, loss_v1=0, loss_v2=0, nll_loss=1.166, ntokens=1044.2, nsentences=32, sample_size=1044.2, sample_size_v1=0, sample_size_v2=0, ppl=2.24, wps=557, ups=0.53, wpb=1044.2, bsz=32, num_updates=11470, lr=2.48695e-05, gnorm=2.479, clip=100, loss_scale=256, train_wall=19, gb_free=11, wall=21542
2023-05-26 05:22:27 - progress_bar.py[line:272] - INFO: epoch 007:   1106 / 1732 loss=2.35, loss_v1=0, loss_v2=0, nll_loss=1.148, ntokens=1073, nsentences=32, sample_size=1073, sample_size_v1=0, sample_size_v2=0, ppl=2.22, wps=569.8, ups=0.53, wpb=1073, bsz=32, num_updates=11480, lr=2.48633e-05, gnorm=2.402, clip=100, loss_scale=256, train_wall=19, gb_free=11.2, wall=21561
2023-05-26 05:22:45 - progress_bar.py[line:272] - INFO: epoch 007:   1116 / 1732 loss=2.366, loss_v1=0, loss_v2=0, nll_loss=1.163, ntokens=936.7, nsentences=32, sample_size=936.7, sample_size_v1=0, sample_size_v2=0, ppl=2.24, wps=500.2, ups=0.53, wpb=936.7, bsz=32, num_updates=11490, lr=2.48572e-05, gnorm=2.447, clip=100, loss_scale=256, train_wall=19, gb_free=11.1, wall=21580
2023-05-26 05:23:04 - progress_bar.py[line:272] - INFO: epoch 007:   1126 / 1732 loss=2.353, loss_v1=0, loss_v2=0, nll_loss=1.153, ntokens=1021, nsentences=32, sample_size=1021, sample_size_v1=0, sample_size_v2=0, ppl=2.22, wps=542.7, ups=0.53, wpb=1021, bsz=32, num_updates=11500, lr=2.48511e-05, gnorm=2.407, clip=100, loss_scale=256, train_wall=19, gb_free=10.9, wall=21599
2023-05-26 05:23:23 - progress_bar.py[line:272] - INFO: epoch 007:   1136 / 1732 loss=2.37, loss_v1=0, loss_v2=0, nll_loss=1.167, ntokens=969.6, nsentences=32, sample_size=969.6, sample_size_v1=0, sample_size_v2=0, ppl=2.25, wps=518.8, ups=0.54, wpb=969.6, bsz=32, num_updates=11510, lr=2.48449e-05, gnorm=2.467, clip=100, loss_scale=256, train_wall=19, gb_free=11.7, wall=21617
2023-05-26 05:23:42 - progress_bar.py[line:272] - INFO: epoch 007:   1146 / 1732 loss=2.359, loss_v1=0, loss_v2=0, nll_loss=1.157, ntokens=1029.8, nsentences=32, sample_size=1029.8, sample_size_v1=0, sample_size_v2=0, ppl=2.23, wps=548.2, ups=0.53, wpb=1029.8, bsz=32, num_updates=11520, lr=2.48388e-05, gnorm=2.423, clip=100, loss_scale=256, train_wall=19, gb_free=11.4, wall=21636
2023-05-26 05:24:00 - progress_bar.py[line:272] - INFO: epoch 007:   1156 / 1732 loss=2.35, loss_v1=0, loss_v2=0, nll_loss=1.148, ntokens=1017, nsentences=32, sample_size=1017, sample_size_v1=0, sample_size_v2=0, ppl=2.22, wps=542.2, ups=0.53, wpb=1017, bsz=32, num_updates=11530, lr=2.48326e-05, gnorm=2.409, clip=100, loss_scale=256, train_wall=19, gb_free=10.6, wall=21655
2023-05-26 05:24:19 - progress_bar.py[line:272] - INFO: epoch 007:   1166 / 1732 loss=2.355, loss_v1=0, loss_v2=0, nll_loss=1.151, ntokens=1020.6, nsentences=32, sample_size=1020.6, sample_size_v1=0, sample_size_v2=0, ppl=2.22, wps=543.7, ups=0.53, wpb=1020.6, bsz=32, num_updates=11540, lr=2.48265e-05, gnorm=2.5, clip=100, loss_scale=256, train_wall=19, gb_free=11.5, wall=21674
2023-05-26 05:24:38 - progress_bar.py[line:272] - INFO: epoch 007:   1176 / 1732 loss=2.338, loss_v1=0, loss_v2=0, nll_loss=1.133, ntokens=1064.1, nsentences=32, sample_size=1064.1, sample_size_v1=0, sample_size_v2=0, ppl=2.19, wps=565.7, ups=0.53, wpb=1064.1, bsz=32, num_updates=11550, lr=2.48203e-05, gnorm=2.343, clip=100, loss_scale=256, train_wall=19, gb_free=11.1, wall=21693
2023-05-26 05:24:57 - progress_bar.py[line:272] - INFO: epoch 007:   1186 / 1732 loss=2.358, loss_v1=0, loss_v2=0, nll_loss=1.158, ntokens=966.7, nsentences=32, sample_size=966.7, sample_size_v1=0, sample_size_v2=0, ppl=2.23, wps=518.2, ups=0.54, wpb=966.7, bsz=32, num_updates=11560, lr=2.48142e-05, gnorm=2.757, clip=100, loss_scale=256, train_wall=19, gb_free=11.6, wall=21711
2023-05-26 05:25:15 - progress_bar.py[line:272] - INFO: epoch 007:   1196 / 1732 loss=2.355, loss_v1=0, loss_v2=0, nll_loss=1.152, ntokens=1072.1, nsentences=32, sample_size=1072.1, sample_size_v1=0, sample_size_v2=0, ppl=2.22, wps=569.9, ups=0.53, wpb=1072.1, bsz=32, num_updates=11570, lr=2.48081e-05, gnorm=2.361, clip=100, loss_scale=256, train_wall=19, gb_free=11.2, wall=21730
2023-05-26 05:25:34 - progress_bar.py[line:272] - INFO: epoch 007:   1206 / 1732 loss=2.325, loss_v1=0, loss_v2=0, nll_loss=1.119, ntokens=1115.4, nsentences=32, sample_size=1115.4, sample_size_v1=0, sample_size_v2=0, ppl=2.17, wps=589.5, ups=0.53, wpb=1115.4, bsz=32, num_updates=11580, lr=2.48019e-05, gnorm=2.218, clip=100, loss_scale=256, train_wall=19, gb_free=11.8, wall=21749
2023-05-26 05:25:53 - progress_bar.py[line:272] - INFO: epoch 007:   1216 / 1732 loss=2.364, loss_v1=0, loss_v2=0, nll_loss=1.165, ntokens=1038.1, nsentences=32, sample_size=1038.1, sample_size_v1=0, sample_size_v2=0, ppl=2.24, wps=553.8, ups=0.53, wpb=1038.1, bsz=32, num_updates=11590, lr=2.47958e-05, gnorm=2.516, clip=100, loss_scale=256, train_wall=19, gb_free=10.9, wall=21768
2023-05-26 05:26:12 - progress_bar.py[line:272] - INFO: epoch 007:   1226 / 1732 loss=2.366, loss_v1=0, loss_v2=0, nll_loss=1.163, ntokens=1020.3, nsentences=32, sample_size=1020.3, sample_size_v1=0, sample_size_v2=0, ppl=2.24, wps=542.8, ups=0.53, wpb=1020.3, bsz=32, num_updates=11600, lr=2.47896e-05, gnorm=2.437, clip=100, loss_scale=512, train_wall=19, gb_free=11.4, wall=21787
2023-05-26 05:26:14 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 256.0
2023-05-26 05:26:32 - progress_bar.py[line:272] - INFO: epoch 007:   1237 / 1732 loss=2.325, loss_v1=0, loss_v2=0, nll_loss=1.121, ntokens=1040.4, nsentences=32, sample_size=1040.4, sample_size_v1=0, sample_size_v2=0, ppl=2.17, wps=506.9, ups=0.49, wpb=1040.4, bsz=32, num_updates=11610, lr=2.47835e-05, gnorm=2.467, clip=100, loss_scale=256, train_wall=20, gb_free=11.4, wall=21807
2023-05-26 05:26:51 - progress_bar.py[line:272] - INFO: epoch 007:   1247 / 1732 loss=2.302, loss_v1=0, loss_v2=0, nll_loss=1.091, ntokens=1124.4, nsentences=32, sample_size=1124.4, sample_size_v1=0, sample_size_v2=0, ppl=2.13, wps=595.6, ups=0.53, wpb=1124.4, bsz=32, num_updates=11620, lr=2.47773e-05, gnorm=2.347, clip=100, loss_scale=256, train_wall=19, gb_free=11.6, wall=21826
2023-05-26 05:27:10 - progress_bar.py[line:272] - INFO: epoch 007:   1257 / 1732 loss=2.328, loss_v1=0, loss_v2=0, nll_loss=1.123, ntokens=1053.7, nsentences=32, sample_size=1053.7, sample_size_v1=0, sample_size_v2=0, ppl=2.18, wps=561.7, ups=0.53, wpb=1053.7, bsz=32, num_updates=11630, lr=2.47712e-05, gnorm=2.327, clip=100, loss_scale=256, train_wall=19, gb_free=11.2, wall=21845
2023-05-26 05:27:29 - progress_bar.py[line:272] - INFO: epoch 007:   1267 / 1732 loss=2.361, loss_v1=0, loss_v2=0, nll_loss=1.161, ntokens=1037.3, nsentences=32, sample_size=1037.3, sample_size_v1=0, sample_size_v2=0, ppl=2.24, wps=549, ups=0.53, wpb=1037.3, bsz=32, num_updates=11640, lr=2.47651e-05, gnorm=2.45, clip=100, loss_scale=256, train_wall=19, gb_free=11.3, wall=21864
2023-05-26 05:27:48 - progress_bar.py[line:272] - INFO: epoch 007:   1277 / 1732 loss=2.359, loss_v1=0, loss_v2=0, nll_loss=1.156, ntokens=1060.8, nsentences=32, sample_size=1060.8, sample_size_v1=0, sample_size_v2=0, ppl=2.23, wps=563.2, ups=0.53, wpb=1060.8, bsz=32, num_updates=11650, lr=2.47589e-05, gnorm=2.369, clip=100, loss_scale=256, train_wall=19, gb_free=10.9, wall=21882
2023-05-26 05:28:07 - progress_bar.py[line:272] - INFO: epoch 007:   1287 / 1732 loss=2.346, loss_v1=0, loss_v2=0, nll_loss=1.142, ntokens=1057.7, nsentences=32, sample_size=1057.7, sample_size_v1=0, sample_size_v2=0, ppl=2.21, wps=562.4, ups=0.53, wpb=1057.7, bsz=32, num_updates=11660, lr=2.47528e-05, gnorm=2.412, clip=100, loss_scale=256, train_wall=19, gb_free=11.1, wall=21901
2023-05-26 05:28:25 - progress_bar.py[line:272] - INFO: epoch 007:   1297 / 1732 loss=2.336, loss_v1=0, loss_v2=0, nll_loss=1.132, ntokens=1105.1, nsentences=32, sample_size=1105.1, sample_size_v1=0, sample_size_v2=0, ppl=2.19, wps=586.3, ups=0.53, wpb=1105.1, bsz=32, num_updates=11670, lr=2.47466e-05, gnorm=2.126, clip=100, loss_scale=256, train_wall=19, gb_free=11.5, wall=21920
2023-05-26 05:28:44 - progress_bar.py[line:272] - INFO: epoch 007:   1307 / 1732 loss=2.376, loss_v1=0, loss_v2=0, nll_loss=1.174, ntokens=1096.7, nsentences=32, sample_size=1096.7, sample_size_v1=0, sample_size_v2=0, ppl=2.26, wps=576.8, ups=0.53, wpb=1096.7, bsz=32, num_updates=11680, lr=2.47405e-05, gnorm=2.377, clip=100, loss_scale=256, train_wall=19, gb_free=11.5, wall=21939
2023-05-26 05:29:03 - progress_bar.py[line:272] - INFO: epoch 007:   1317 / 1732 loss=2.355, loss_v1=0, loss_v2=0, nll_loss=1.152, ntokens=1048.7, nsentences=32, sample_size=1048.7, sample_size_v1=0, sample_size_v2=0, ppl=2.22, wps=554.6, ups=0.53, wpb=1048.7, bsz=32, num_updates=11690, lr=2.47344e-05, gnorm=2.587, clip=100, loss_scale=256, train_wall=19, gb_free=11.6, wall=21958
2023-05-26 05:29:22 - progress_bar.py[line:272] - INFO: epoch 007:   1327 / 1732 loss=2.327, loss_v1=0, loss_v2=0, nll_loss=1.122, ntokens=1124.5, nsentences=32, sample_size=1124.5, sample_size_v1=0, sample_size_v2=0, ppl=2.18, wps=593.7, ups=0.53, wpb=1124.5, bsz=32, num_updates=11700, lr=2.47282e-05, gnorm=2.337, clip=100, loss_scale=256, train_wall=19, gb_free=11.3, wall=21977
2023-05-26 05:29:41 - progress_bar.py[line:272] - INFO: epoch 007:   1337 / 1732 loss=2.315, loss_v1=0, loss_v2=0, nll_loss=1.107, ntokens=1126.2, nsentences=32, sample_size=1126.2, sample_size_v1=0, sample_size_v2=0, ppl=2.15, wps=598.8, ups=0.53, wpb=1126.2, bsz=32, num_updates=11710, lr=2.47221e-05, gnorm=2.287, clip=100, loss_scale=256, train_wall=19, gb_free=11.2, wall=21996
2023-05-26 05:30:00 - progress_bar.py[line:272] - INFO: epoch 007:   1347 / 1732 loss=2.337, loss_v1=0, loss_v2=0, nll_loss=1.134, ntokens=1159.1, nsentences=32, sample_size=1159.1, sample_size_v1=0, sample_size_v2=0, ppl=2.19, wps=610.5, ups=0.53, wpb=1159.1, bsz=32, num_updates=11720, lr=2.47159e-05, gnorm=2.115, clip=100, loss_scale=256, train_wall=19, gb_free=11.5, wall=22015
2023-05-26 05:30:19 - progress_bar.py[line:272] - INFO: epoch 007:   1357 / 1732 loss=2.315, loss_v1=0, loss_v2=0, nll_loss=1.106, ntokens=1146.3, nsentences=32, sample_size=1146.3, sample_size_v1=0, sample_size_v2=0, ppl=2.15, wps=604.7, ups=0.53, wpb=1146.3, bsz=32, num_updates=11730, lr=2.47098e-05, gnorm=2.291, clip=100, loss_scale=256, train_wall=19, gb_free=10.9, wall=22034
2023-05-26 05:30:38 - progress_bar.py[line:272] - INFO: epoch 007:   1367 / 1732 loss=2.337, loss_v1=0, loss_v2=0, nll_loss=1.132, ntokens=1081.6, nsentences=32, sample_size=1081.6, sample_size_v1=0, sample_size_v2=0, ppl=2.19, wps=573.7, ups=0.53, wpb=1081.6, bsz=32, num_updates=11740, lr=2.47036e-05, gnorm=2.394, clip=100, loss_scale=256, train_wall=19, gb_free=11, wall=22053
2023-05-26 05:30:57 - progress_bar.py[line:272] - INFO: epoch 007:   1377 / 1732 loss=2.373, loss_v1=0, loss_v2=0, nll_loss=1.174, ntokens=1107.3, nsentences=32, sample_size=1107.3, sample_size_v1=0, sample_size_v2=0, ppl=2.26, wps=589.1, ups=0.53, wpb=1107.3, bsz=32, num_updates=11750, lr=2.46975e-05, gnorm=2.434, clip=100, loss_scale=256, train_wall=19, gb_free=11.5, wall=22071
2023-05-26 05:31:15 - progress_bar.py[line:272] - INFO: epoch 007:   1387 / 1732 loss=2.331, loss_v1=0, loss_v2=0, nll_loss=1.125, ntokens=1152.6, nsentences=32, sample_size=1152.6, sample_size_v1=0, sample_size_v2=0, ppl=2.18, wps=614.3, ups=0.53, wpb=1152.6, bsz=32, num_updates=11760, lr=2.46914e-05, gnorm=2.249, clip=100, loss_scale=256, train_wall=19, gb_free=11.5, wall=22090
2023-05-26 05:31:34 - progress_bar.py[line:272] - INFO: epoch 007:   1397 / 1732 loss=2.338, loss_v1=0, loss_v2=0, nll_loss=1.134, ntokens=1066.5, nsentences=32, sample_size=1066.5, sample_size_v1=0, sample_size_v2=0, ppl=2.19, wps=566.5, ups=0.53, wpb=1066.5, bsz=32, num_updates=11770, lr=2.46852e-05, gnorm=2.473, clip=100, loss_scale=256, train_wall=19, gb_free=11.4, wall=22109
2023-05-26 05:31:53 - progress_bar.py[line:272] - INFO: epoch 007:   1407 / 1732 loss=2.345, loss_v1=0, loss_v2=0, nll_loss=1.141, ntokens=1152.8, nsentences=32, sample_size=1152.8, sample_size_v1=0, sample_size_v2=0, ppl=2.21, wps=611.1, ups=0.53, wpb=1152.8, bsz=32, num_updates=11780, lr=2.46791e-05, gnorm=2.309, clip=100, loss_scale=256, train_wall=19, gb_free=11.4, wall=22128
2023-05-26 05:32:12 - progress_bar.py[line:272] - INFO: epoch 007:   1417 / 1732 loss=2.362, loss_v1=0, loss_v2=0, nll_loss=1.161, ntokens=1290.7, nsentences=32, sample_size=1290.7, sample_size_v1=0, sample_size_v2=0, ppl=2.24, wps=677.1, ups=0.52, wpb=1290.7, bsz=32, num_updates=11790, lr=2.46729e-05, gnorm=2.067, clip=100, loss_scale=256, train_wall=19, gb_free=10.9, wall=22147
2023-05-26 05:32:31 - progress_bar.py[line:272] - INFO: epoch 007:   1427 / 1732 loss=2.321, loss_v1=0, loss_v2=0, nll_loss=1.114, ntokens=1220.7, nsentences=32, sample_size=1220.7, sample_size_v1=0, sample_size_v2=0, ppl=2.16, wps=640.2, ups=0.52, wpb=1220.7, bsz=32, num_updates=11800, lr=2.46668e-05, gnorm=2.187, clip=100, loss_scale=256, train_wall=19, gb_free=11.6, wall=22166
2023-05-26 05:32:50 - progress_bar.py[line:272] - INFO: epoch 007:   1437 / 1732 loss=2.33, loss_v1=0, loss_v2=0, nll_loss=1.126, ntokens=1217.2, nsentences=32, sample_size=1217.2, sample_size_v1=0, sample_size_v2=0, ppl=2.18, wps=642.6, ups=0.53, wpb=1217.2, bsz=32, num_updates=11810, lr=2.46606e-05, gnorm=2.046, clip=100, loss_scale=256, train_wall=19, gb_free=9.6, wall=22185
2023-05-26 05:33:09 - progress_bar.py[line:272] - INFO: epoch 007:   1447 / 1732 loss=2.349, loss_v1=0, loss_v2=0, nll_loss=1.145, ntokens=1115.7, nsentences=32, sample_size=1115.7, sample_size_v1=0, sample_size_v2=0, ppl=2.21, wps=594.3, ups=0.53, wpb=1115.7, bsz=32, num_updates=11820, lr=2.46545e-05, gnorm=2.197, clip=100, loss_scale=256, train_wall=19, gb_free=11.6, wall=22204
2023-05-26 05:33:28 - progress_bar.py[line:272] - INFO: epoch 007:   1457 / 1732 loss=2.35, loss_v1=0, loss_v2=0, nll_loss=1.149, ntokens=1111.8, nsentences=32, sample_size=1111.8, sample_size_v1=0, sample_size_v2=0, ppl=2.22, wps=588.6, ups=0.53, wpb=1111.8, bsz=32, num_updates=11830, lr=2.46484e-05, gnorm=2.408, clip=100, loss_scale=256, train_wall=19, gb_free=10.6, wall=22223
2023-05-26 05:33:47 - progress_bar.py[line:272] - INFO: epoch 007:   1467 / 1732 loss=2.295, loss_v1=0, loss_v2=0, nll_loss=1.085, ntokens=1202.5, nsentences=32, sample_size=1202.5, sample_size_v1=0, sample_size_v2=0, ppl=2.12, wps=634.2, ups=0.53, wpb=1202.5, bsz=32, num_updates=11840, lr=2.46422e-05, gnorm=2.162, clip=100, loss_scale=256, train_wall=19, gb_free=11.3, wall=22242
2023-05-26 05:34:06 - progress_bar.py[line:272] - INFO: epoch 007:   1477 / 1732 loss=2.363, loss_v1=0, loss_v2=0, nll_loss=1.164, ntokens=1052.1, nsentences=32, sample_size=1052.1, sample_size_v1=0, sample_size_v2=0, ppl=2.24, wps=558.8, ups=0.53, wpb=1052.1, bsz=32, num_updates=11850, lr=2.46361e-05, gnorm=2.435, clip=100, loss_scale=256, train_wall=19, gb_free=10.7, wall=22260
2023-05-26 05:34:25 - progress_bar.py[line:272] - INFO: epoch 007:   1487 / 1732 loss=2.36, loss_v1=0, loss_v2=0, nll_loss=1.156, ntokens=1147.5, nsentences=32, sample_size=1147.5, sample_size_v1=0, sample_size_v2=0, ppl=2.23, wps=609.2, ups=0.53, wpb=1147.5, bsz=32, num_updates=11860, lr=2.46299e-05, gnorm=2.267, clip=100, loss_scale=256, train_wall=19, gb_free=10.8, wall=22279
2023-05-26 05:34:43 - progress_bar.py[line:272] - INFO: epoch 007:   1497 / 1732 loss=2.327, loss_v1=0, loss_v2=0, nll_loss=1.122, ntokens=1083.9, nsentences=32, sample_size=1083.9, sample_size_v1=0, sample_size_v2=0, ppl=2.18, wps=573.5, ups=0.53, wpb=1083.9, bsz=32, num_updates=11870, lr=2.46238e-05, gnorm=2.34, clip=100, loss_scale=256, train_wall=19, gb_free=11.5, wall=22298
2023-05-26 05:35:02 - progress_bar.py[line:272] - INFO: epoch 007:   1507 / 1732 loss=2.285, loss_v1=0, loss_v2=0, nll_loss=1.075, ntokens=1112.5, nsentences=32, sample_size=1112.5, sample_size_v1=0, sample_size_v2=0, ppl=2.11, wps=591.8, ups=0.53, wpb=1112.5, bsz=32, num_updates=11880, lr=2.46177e-05, gnorm=2.305, clip=100, loss_scale=256, train_wall=19, gb_free=11.5, wall=22317
2023-05-26 05:35:21 - progress_bar.py[line:272] - INFO: epoch 007:   1517 / 1732 loss=2.361, loss_v1=0, loss_v2=0, nll_loss=1.158, ntokens=1063, nsentences=32, sample_size=1063, sample_size_v1=0, sample_size_v2=0, ppl=2.23, wps=566.8, ups=0.53, wpb=1063, bsz=32, num_updates=11890, lr=2.46115e-05, gnorm=2.334, clip=100, loss_scale=256, train_wall=19, gb_free=10.7, wall=22336
2023-05-26 05:35:40 - progress_bar.py[line:272] - INFO: epoch 007:   1527 / 1732 loss=2.379, loss_v1=0, loss_v2=0, nll_loss=1.181, ntokens=1062.3, nsentences=32, sample_size=1062.3, sample_size_v1=0, sample_size_v2=0, ppl=2.27, wps=565.9, ups=0.53, wpb=1062.3, bsz=32, num_updates=11900, lr=2.46054e-05, gnorm=2.345, clip=100, loss_scale=256, train_wall=19, gb_free=11.1, wall=22354
2023-05-26 05:35:59 - progress_bar.py[line:272] - INFO: epoch 007:   1537 / 1732 loss=2.336, loss_v1=0, loss_v2=0, nll_loss=1.129, ntokens=1067, nsentences=32, sample_size=1067, sample_size_v1=0, sample_size_v2=0, ppl=2.19, wps=562.7, ups=0.53, wpb=1067, bsz=32, num_updates=11910, lr=2.45992e-05, gnorm=2.273, clip=100, loss_scale=256, train_wall=19, gb_free=11, wall=22373
2023-05-26 05:36:18 - progress_bar.py[line:272] - INFO: epoch 007:   1547 / 1732 loss=2.315, loss_v1=0, loss_v2=0, nll_loss=1.11, ntokens=1093.5, nsentences=32, sample_size=1093.5, sample_size_v1=0, sample_size_v2=0, ppl=2.16, wps=581.1, ups=0.53, wpb=1093.5, bsz=32, num_updates=11920, lr=2.45931e-05, gnorm=2.264, clip=100, loss_scale=256, train_wall=19, gb_free=11.2, wall=22392
2023-05-26 05:36:36 - progress_bar.py[line:272] - INFO: epoch 007:   1557 / 1732 loss=2.323, loss_v1=0, loss_v2=0, nll_loss=1.117, ntokens=1051.1, nsentences=32, sample_size=1051.1, sample_size_v1=0, sample_size_v2=0, ppl=2.17, wps=559.9, ups=0.53, wpb=1051.1, bsz=32, num_updates=11930, lr=2.45869e-05, gnorm=2.284, clip=100, loss_scale=256, train_wall=19, gb_free=11.2, wall=22411
2023-05-26 05:36:55 - progress_bar.py[line:272] - INFO: epoch 007:   1567 / 1732 loss=2.366, loss_v1=0, loss_v2=0, nll_loss=1.165, ntokens=1097.1, nsentences=32, sample_size=1097.1, sample_size_v1=0, sample_size_v2=0, ppl=2.24, wps=582.7, ups=0.53, wpb=1097.1, bsz=32, num_updates=11940, lr=2.45808e-05, gnorm=2.224, clip=100, loss_scale=256, train_wall=19, gb_free=10.6, wall=22430
2023-05-26 05:37:14 - progress_bar.py[line:272] - INFO: epoch 007:   1577 / 1732 loss=2.37, loss_v1=0, loss_v2=0, nll_loss=1.17, ntokens=1002.1, nsentences=32, sample_size=1002.1, sample_size_v1=0, sample_size_v2=0, ppl=2.25, wps=533.5, ups=0.53, wpb=1002.1, bsz=32, num_updates=11950, lr=2.45747e-05, gnorm=2.669, clip=100, loss_scale=256, train_wall=19, gb_free=11.8, wall=22449
2023-05-26 05:37:33 - progress_bar.py[line:272] - INFO: epoch 007:   1587 / 1732 loss=2.351, loss_v1=0, loss_v2=0, nll_loss=1.148, ntokens=1081.3, nsentences=32, sample_size=1081.3, sample_size_v1=0, sample_size_v2=0, ppl=2.22, wps=569.5, ups=0.53, wpb=1081.3, bsz=32, num_updates=11960, lr=2.45685e-05, gnorm=2.419, clip=100, loss_scale=256, train_wall=19, gb_free=10.8, wall=22468
2023-05-26 05:37:52 - progress_bar.py[line:272] - INFO: epoch 007:   1597 / 1732 loss=2.317, loss_v1=0, loss_v2=0, nll_loss=1.109, ntokens=1084.4, nsentences=32, sample_size=1084.4, sample_size_v1=0, sample_size_v2=0, ppl=2.16, wps=576.5, ups=0.53, wpb=1084.4, bsz=32, num_updates=11970, lr=2.45624e-05, gnorm=2.287, clip=100, loss_scale=256, train_wall=19, gb_free=10.9, wall=22486
2023-05-26 05:38:11 - progress_bar.py[line:272] - INFO: epoch 007:   1607 / 1732 loss=2.322, loss_v1=0, loss_v2=0, nll_loss=1.115, ntokens=1122.8, nsentences=32, sample_size=1122.8, sample_size_v1=0, sample_size_v2=0, ppl=2.17, wps=595.4, ups=0.53, wpb=1122.8, bsz=32, num_updates=11980, lr=2.45562e-05, gnorm=2.061, clip=100, loss_scale=256, train_wall=19, gb_free=10.9, wall=22505
2023-05-26 05:38:30 - progress_bar.py[line:272] - INFO: epoch 007:   1617 / 1732 loss=2.3, loss_v1=0, loss_v2=0, nll_loss=1.091, ntokens=1114.5, nsentences=32, sample_size=1114.5, sample_size_v1=0, sample_size_v2=0, ppl=2.13, wps=587.8, ups=0.53, wpb=1114.5, bsz=32, num_updates=11990, lr=2.45501e-05, gnorm=2.437, clip=100, loss_scale=256, train_wall=19, gb_free=11.3, wall=22524
2023-05-26 05:38:49 - progress_bar.py[line:272] - INFO: epoch 007:   1627 / 1732 loss=2.331, loss_v1=0, loss_v2=0, nll_loss=1.127, ntokens=1162.3, nsentences=32, sample_size=1162.3, sample_size_v1=0, sample_size_v2=0, ppl=2.18, wps=612.4, ups=0.53, wpb=1162.3, bsz=32, num_updates=12000, lr=2.45439e-05, gnorm=2.355, clip=100, loss_scale=256, train_wall=19, gb_free=11.2, wall=22543
2023-05-26 05:39:07 - progress_bar.py[line:272] - INFO: epoch 007:   1637 / 1732 loss=2.308, loss_v1=0, loss_v2=0, nll_loss=1.1, ntokens=1115.7, nsentences=32, sample_size=1115.7, sample_size_v1=0, sample_size_v2=0, ppl=2.14, wps=593.8, ups=0.53, wpb=1115.7, bsz=32, num_updates=12010, lr=2.45378e-05, gnorm=2.23, clip=100, loss_scale=256, train_wall=19, gb_free=11.3, wall=22562
2023-05-26 05:39:26 - progress_bar.py[line:272] - INFO: epoch 007:   1647 / 1732 loss=2.292, loss_v1=0, loss_v2=0, nll_loss=1.084, ntokens=1285, nsentences=32, sample_size=1285, sample_size_v1=0, sample_size_v2=0, ppl=2.12, wps=673, ups=0.52, wpb=1285, bsz=32, num_updates=12020, lr=2.45317e-05, gnorm=2.002, clip=100, loss_scale=256, train_wall=19, gb_free=11.1, wall=22581
2023-05-26 05:39:45 - progress_bar.py[line:272] - INFO: epoch 007:   1657 / 1732 loss=2.368, loss_v1=0, loss_v2=0, nll_loss=1.167, ntokens=952, nsentences=32, sample_size=952, sample_size_v1=0, sample_size_v2=0, ppl=2.25, wps=509.9, ups=0.54, wpb=952, bsz=32, num_updates=12030, lr=2.45255e-05, gnorm=2.828, clip=100, loss_scale=256, train_wall=19, gb_free=11.3, wall=22600
2023-05-26 05:40:04 - progress_bar.py[line:272] - INFO: epoch 007:   1667 / 1732 loss=2.345, loss_v1=0, loss_v2=0, nll_loss=1.139, ntokens=1028.1, nsentences=32, sample_size=1028.1, sample_size_v1=0, sample_size_v2=0, ppl=2.2, wps=546.4, ups=0.53, wpb=1028.1, bsz=32, num_updates=12040, lr=2.45194e-05, gnorm=2.467, clip=100, loss_scale=256, train_wall=19, gb_free=11.4, wall=22619
2023-05-26 05:40:23 - progress_bar.py[line:272] - INFO: epoch 007:   1677 / 1732 loss=2.289, loss_v1=0, loss_v2=0, nll_loss=1.08, ntokens=1135.4, nsentences=32, sample_size=1135.4, sample_size_v1=0, sample_size_v2=0, ppl=2.11, wps=601.3, ups=0.53, wpb=1135.4, bsz=32, num_updates=12050, lr=2.45132e-05, gnorm=2.372, clip=100, loss_scale=256, train_wall=19, gb_free=10.5, wall=22638
2023-05-26 05:40:42 - progress_bar.py[line:272] - INFO: epoch 007:   1687 / 1732 loss=2.311, loss_v1=0, loss_v2=0, nll_loss=1.105, ntokens=1154.5, nsentences=32, sample_size=1154.5, sample_size_v1=0, sample_size_v2=0, ppl=2.15, wps=608.9, ups=0.53, wpb=1154.5, bsz=32, num_updates=12060, lr=2.45071e-05, gnorm=2.236, clip=100, loss_scale=256, train_wall=19, gb_free=10, wall=22656
2023-05-26 05:41:01 - progress_bar.py[line:272] - INFO: epoch 007:   1697 / 1732 loss=2.309, loss_v1=0, loss_v2=0, nll_loss=1.101, ntokens=1302.5, nsentences=32, sample_size=1302.5, sample_size_v1=0, sample_size_v2=0, ppl=2.15, wps=674.8, ups=0.52, wpb=1302.5, bsz=32, num_updates=12070, lr=2.4501e-05, gnorm=1.969, clip=100, loss_scale=256, train_wall=19, gb_free=10.7, wall=22676
2023-05-26 05:41:20 - progress_bar.py[line:272] - INFO: epoch 007:   1707 / 1732 loss=2.325, loss_v1=0, loss_v2=0, nll_loss=1.119, ntokens=1171.1, nsentences=32, sample_size=1171.1, sample_size_v1=0, sample_size_v2=0, ppl=2.17, wps=617.2, ups=0.53, wpb=1171.1, bsz=32, num_updates=12080, lr=2.44948e-05, gnorm=2.106, clip=100, loss_scale=256, train_wall=19, gb_free=11.7, wall=22695
2023-05-26 05:41:39 - progress_bar.py[line:272] - INFO: epoch 007:   1717 / 1732 loss=2.313, loss_v1=0, loss_v2=0, nll_loss=1.106, ntokens=1206.1, nsentences=32, sample_size=1206.1, sample_size_v1=0, sample_size_v2=0, ppl=2.15, wps=634.4, ups=0.53, wpb=1206.1, bsz=32, num_updates=12090, lr=2.44887e-05, gnorm=2.167, clip=100, loss_scale=256, train_wall=19, gb_free=11.2, wall=22714
2023-05-26 05:41:58 - progress_bar.py[line:272] - INFO: epoch 007:   1727 / 1732 loss=2.35, loss_v1=0, loss_v2=0, nll_loss=1.147, ntokens=1102.3, nsentences=32, sample_size=1102.3, sample_size_v1=0, sample_size_v2=0, ppl=2.22, wps=583.8, ups=0.53, wpb=1102.3, bsz=32, num_updates=12100, lr=2.44825e-05, gnorm=2.31, clip=100, loss_scale=256, train_wall=19, gb_free=11.2, wall=22733
2023-05-26 05:42:06 - train.py[line:332] - INFO: end of epoch 7 (average epoch stats below)
2023-05-26 05:42:06 - progress_bar.py[line:282] - INFO: epoch 007 | loss 2.346 | loss_v1 0 | loss_v2 0 | nll_loss 1.143 | ntokens 1051.81 | nsentences 31.986 | sample_size 1051.81 | sample_size_v1 0 | sample_size_v2 0 | ppl 2.21 | wps 560.3 | ups 0.53 | wpb 1051.8 | bsz 32 | num_updates 12105 | lr 2.44795e-05 | gnorm 2.365 | clip 99.9 | loss_scale 256 | train_wall 3240 | gb_free 11.7 | wall 22741
2023-05-26 05:42:06 - trainer.py[line:639] - INFO: loading train data for epoch 8
local datafile ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 0 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 0 finished initializing row_count and line_idx-to-offset mapping
file ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 0 row count 55400 total row count 55400
slice_id 0 seek offset 0
2023-05-26 05:42:08 - trainer.py[line:703] - INFO: begin training epoch 8
2023-05-26 05:42:08 - train.py[line:305] - INFO: Start iterating over samples
2023-05-26 05:42:18 - progress_bar.py[line:272] - INFO: epoch 008:      5 / 1732 loss=2.315, loss_v1=0, loss_v2=0, nll_loss=1.106, ntokens=1084.5, nsentences=29.6, sample_size=1084.5, sample_size_v1=0, sample_size_v2=0, ppl=2.15, wps=550.8, ups=0.51, wpb=1084.5, bsz=29.6, num_updates=12110, lr=2.44764e-05, gnorm=2.457, clip=100, loss_scale=256, train_wall=18, gb_free=11.2, wall=22752
2023-05-26 05:42:31 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 256.0
2023-05-26 05:42:38 - progress_bar.py[line:272] - INFO: epoch 008:     16 / 1732 loss=2.271, loss_v1=0, loss_v2=0, nll_loss=1.06, ntokens=1119.5, nsentences=32, sample_size=1119.5, sample_size_v1=0, sample_size_v2=0, ppl=2.08, wps=541.1, ups=0.48, wpb=1119.5, bsz=32, num_updates=12120, lr=2.44702e-05, gnorm=1.963, clip=100, loss_scale=256, train_wall=21, gb_free=11.2, wall=22773
2023-05-26 05:42:57 - progress_bar.py[line:272] - INFO: epoch 008:     26 / 1732 loss=2.283, loss_v1=0, loss_v2=0, nll_loss=1.071, ntokens=973, nsentences=32, sample_size=973, sample_size_v1=0, sample_size_v2=0, ppl=2.1, wps=518, ups=0.53, wpb=973, bsz=32, num_updates=12130, lr=2.44641e-05, gnorm=2.316, clip=100, loss_scale=256, train_wall=19, gb_free=11.5, wall=22792
2023-05-26 05:43:16 - progress_bar.py[line:272] - INFO: epoch 008:     36 / 1732 loss=2.162, loss_v1=0, loss_v2=0, nll_loss=0.939, ntokens=1153.4, nsentences=32, sample_size=1153.4, sample_size_v1=0, sample_size_v2=0, ppl=1.92, wps=606.5, ups=0.53, wpb=1153.4, bsz=32, num_updates=12140, lr=2.4458e-05, gnorm=2.012, clip=100, loss_scale=256, train_wall=19, gb_free=10.4, wall=22811
2023-05-26 05:43:35 - progress_bar.py[line:272] - INFO: epoch 008:     46 / 1732 loss=2.166, loss_v1=0, loss_v2=0, nll_loss=0.942, ntokens=1066.8, nsentences=32, sample_size=1066.8, sample_size_v1=0, sample_size_v2=0, ppl=1.92, wps=567, ups=0.53, wpb=1066.8, bsz=32, num_updates=12150, lr=2.44518e-05, gnorm=1.993, clip=90, loss_scale=256, train_wall=19, gb_free=11.6, wall=22830
2023-05-26 05:43:54 - progress_bar.py[line:272] - INFO: epoch 008:     56 / 1732 loss=2.121, loss_v1=0, loss_v2=0, nll_loss=0.896, ntokens=1077, nsentences=32, sample_size=1077, sample_size_v1=0, sample_size_v2=0, ppl=1.86, wps=570.5, ups=0.53, wpb=1077, bsz=32, num_updates=12160, lr=2.44457e-05, gnorm=2.112, clip=100, loss_scale=256, train_wall=19, gb_free=11.5, wall=22849
2023-05-26 05:44:13 - progress_bar.py[line:272] - INFO: epoch 008:     66 / 1732 loss=1.998, loss_v1=0, loss_v2=0, nll_loss=0.753, ntokens=1294.5, nsentences=32, sample_size=1294.5, sample_size_v1=0, sample_size_v2=0, ppl=1.69, wps=673.7, ups=0.52, wpb=1294.5, bsz=32, num_updates=12170, lr=2.44395e-05, gnorm=1.467, clip=100, loss_scale=256, train_wall=19, gb_free=10.5, wall=22868
2023-05-26 05:44:33 - progress_bar.py[line:272] - INFO: epoch 008:     76 / 1732 loss=2.109, loss_v1=0, loss_v2=0, nll_loss=0.876, ntokens=1343.5, nsentences=32, sample_size=1343.5, sample_size_v1=0, sample_size_v2=0, ppl=1.83, wps=689.4, ups=0.51, wpb=1343.5, bsz=32, num_updates=12180, lr=2.44334e-05, gnorm=1.575, clip=100, loss_scale=256, train_wall=19, gb_free=10.1, wall=22887
2023-05-26 05:44:52 - progress_bar.py[line:272] - INFO: epoch 008:     86 / 1732 loss=2.199, loss_v1=0, loss_v2=0, nll_loss=0.981, ntokens=1107.4, nsentences=32, sample_size=1107.4, sample_size_v1=0, sample_size_v2=0, ppl=1.97, wps=580.3, ups=0.52, wpb=1107.4, bsz=32, num_updates=12190, lr=2.44272e-05, gnorm=1.961, clip=100, loss_scale=256, train_wall=19, gb_free=10.8, wall=22906
2023-05-26 05:45:11 - progress_bar.py[line:272] - INFO: epoch 008:     96 / 1732 loss=2.153, loss_v1=0, loss_v2=0, nll_loss=0.926, ntokens=1069.5, nsentences=32, sample_size=1069.5, sample_size_v1=0, sample_size_v2=0, ppl=1.9, wps=565.9, ups=0.53, wpb=1069.5, bsz=32, num_updates=12200, lr=2.44211e-05, gnorm=1.923, clip=100, loss_scale=256, train_wall=19, gb_free=10.4, wall=22925
2023-05-26 05:45:29 - progress_bar.py[line:272] - INFO: epoch 008:    106 / 1732 loss=2.307, loss_v1=0, loss_v2=0, nll_loss=1.102, ntokens=998.2, nsentences=32, sample_size=998.2, sample_size_v1=0, sample_size_v2=0, ppl=2.15, wps=532, ups=0.53, wpb=998.2, bsz=32, num_updates=12210, lr=2.4415e-05, gnorm=2.434, clip=100, loss_scale=256, train_wall=19, gb_free=10.4, wall=22944
2023-05-26 05:45:48 - progress_bar.py[line:272] - INFO: epoch 008:    116 / 1732 loss=2.372, loss_v1=0, loss_v2=0, nll_loss=1.171, ntokens=1049.3, nsentences=32, sample_size=1049.3, sample_size_v1=0, sample_size_v2=0, ppl=2.25, wps=552.8, ups=0.53, wpb=1049.3, bsz=32, num_updates=12220, lr=2.44088e-05, gnorm=2.384, clip=100, loss_scale=256, train_wall=19, gb_free=10.5, wall=22963
2023-05-26 05:46:08 - progress_bar.py[line:272] - INFO: epoch 008:    126 / 1732 loss=2.291, loss_v1=0, loss_v2=0, nll_loss=1.08, ntokens=1187.5, nsentences=32, sample_size=1187.5, sample_size_v1=0, sample_size_v2=0, ppl=2.11, wps=617.5, ups=0.52, wpb=1187.5, bsz=32, num_updates=12230, lr=2.44027e-05, gnorm=2.013, clip=100, loss_scale=256, train_wall=19, gb_free=10.9, wall=22982
2023-05-26 05:46:27 - progress_bar.py[line:272] - INFO: epoch 008:    136 / 1732 loss=2.279, loss_v1=0, loss_v2=0, nll_loss=1.068, ntokens=1228, nsentences=32, sample_size=1228, sample_size_v1=0, sample_size_v2=0, ppl=2.1, wps=642.7, ups=0.52, wpb=1228, bsz=32, num_updates=12240, lr=2.43965e-05, gnorm=2.025, clip=100, loss_scale=256, train_wall=19, gb_free=10.4, wall=23001
2023-05-26 05:46:46 - progress_bar.py[line:272] - INFO: epoch 008:    146 / 1732 loss=2.227, loss_v1=0, loss_v2=0, nll_loss=1.011, ntokens=1192.9, nsentences=32, sample_size=1192.9, sample_size_v1=0, sample_size_v2=0, ppl=2.02, wps=619.5, ups=0.52, wpb=1192.9, bsz=32, num_updates=12250, lr=2.43904e-05, gnorm=1.958, clip=100, loss_scale=256, train_wall=19, gb_free=10.6, wall=23021
2023-05-26 05:47:05 - progress_bar.py[line:272] - INFO: epoch 008:    156 / 1732 loss=2.277, loss_v1=0, loss_v2=0, nll_loss=1.065, ntokens=1174.3, nsentences=32, sample_size=1174.3, sample_size_v1=0, sample_size_v2=0, ppl=2.09, wps=609.6, ups=0.52, wpb=1174.3, bsz=32, num_updates=12260, lr=2.43843e-05, gnorm=1.948, clip=100, loss_scale=256, train_wall=19, gb_free=11.1, wall=23040
2023-05-26 05:47:24 - progress_bar.py[line:272] - INFO: epoch 008:    166 / 1732 loss=2.239, loss_v1=0, loss_v2=0, nll_loss=1.025, ntokens=1039.2, nsentences=32, sample_size=1039.2, sample_size_v1=0, sample_size_v2=0, ppl=2.04, wps=549.8, ups=0.53, wpb=1039.2, bsz=32, num_updates=12270, lr=2.43781e-05, gnorm=2.298, clip=100, loss_scale=256, train_wall=19, gb_free=10.5, wall=23059
2023-05-26 05:47:43 - progress_bar.py[line:272] - INFO: epoch 008:    176 / 1732 loss=2.264, loss_v1=0, loss_v2=0, nll_loss=1.051, ntokens=982.6, nsentences=32, sample_size=982.6, sample_size_v1=0, sample_size_v2=0, ppl=2.07, wps=520.7, ups=0.53, wpb=982.6, bsz=32, num_updates=12280, lr=2.4372e-05, gnorm=2.523, clip=100, loss_scale=256, train_wall=19, gb_free=11, wall=23078
2023-05-26 05:48:02 - progress_bar.py[line:272] - INFO: epoch 008:    186 / 1732 loss=2.202, loss_v1=0, loss_v2=0, nll_loss=0.982, ntokens=1142, nsentences=32, sample_size=1142, sample_size_v1=0, sample_size_v2=0, ppl=1.97, wps=597.8, ups=0.52, wpb=1142, bsz=32, num_updates=12290, lr=2.43658e-05, gnorm=1.993, clip=100, loss_scale=256, train_wall=19, gb_free=11.1, wall=23097
2023-05-26 05:48:21 - progress_bar.py[line:272] - INFO: epoch 008:    196 / 1732 loss=2.265, loss_v1=0, loss_v2=0, nll_loss=1.052, ntokens=1152.2, nsentences=32, sample_size=1152.2, sample_size_v1=0, sample_size_v2=0, ppl=2.07, wps=601, ups=0.52, wpb=1152.2, bsz=32, num_updates=12300, lr=2.43597e-05, gnorm=2.06, clip=100, loss_scale=256, train_wall=19, gb_free=11, wall=23116
2023-05-26 05:48:40 - progress_bar.py[line:272] - INFO: epoch 008:    206 / 1732 loss=2.344, loss_v1=0, loss_v2=0, nll_loss=1.141, ntokens=995.3, nsentences=32, sample_size=995.3, sample_size_v1=0, sample_size_v2=0, ppl=2.21, wps=535.3, ups=0.54, wpb=995.3, bsz=32, num_updates=12310, lr=2.43535e-05, gnorm=2.487, clip=100, loss_scale=256, train_wall=19, gb_free=11.3, wall=23135
2023-05-26 05:48:59 - progress_bar.py[line:272] - INFO: epoch 008:    216 / 1732 loss=2.358, loss_v1=0, loss_v2=0, nll_loss=1.154, ntokens=1119.9, nsentences=32, sample_size=1119.9, sample_size_v1=0, sample_size_v2=0, ppl=2.23, wps=597.7, ups=0.53, wpb=1119.9, bsz=32, num_updates=12320, lr=2.43474e-05, gnorm=2.264, clip=100, loss_scale=256, train_wall=19, gb_free=11.2, wall=23153
2023-05-26 05:49:17 - progress_bar.py[line:272] - INFO: epoch 008:    226 / 1732 loss=2.351, loss_v1=0, loss_v2=0, nll_loss=1.151, ntokens=1111.6, nsentences=32, sample_size=1111.6, sample_size_v1=0, sample_size_v2=0, ppl=2.22, wps=594.8, ups=0.54, wpb=1111.6, bsz=32, num_updates=12330, lr=2.43413e-05, gnorm=2.327, clip=100, loss_scale=256, train_wall=19, gb_free=11.4, wall=23172
2023-05-26 05:49:36 - progress_bar.py[line:272] - INFO: epoch 008:    236 / 1732 loss=2.404, loss_v1=0, loss_v2=0, nll_loss=1.205, ntokens=1076.5, nsentences=32, sample_size=1076.5, sample_size_v1=0, sample_size_v2=0, ppl=2.3, wps=575.9, ups=0.53, wpb=1076.5, bsz=32, num_updates=12340, lr=2.43351e-05, gnorm=2.31, clip=100, loss_scale=256, train_wall=19, gb_free=11.4, wall=23191
2023-05-26 05:49:55 - progress_bar.py[line:272] - INFO: epoch 008:    246 / 1732 loss=2.38, loss_v1=0, loss_v2=0, nll_loss=1.182, ntokens=1166.2, nsentences=32, sample_size=1166.2, sample_size_v1=0, sample_size_v2=0, ppl=2.27, wps=620.5, ups=0.53, wpb=1166.2, bsz=32, num_updates=12350, lr=2.4329e-05, gnorm=2.118, clip=100, loss_scale=256, train_wall=19, gb_free=11.6, wall=23209
2023-05-26 05:50:14 - progress_bar.py[line:272] - INFO: epoch 008:    256 / 1732 loss=2.367, loss_v1=0, loss_v2=0, nll_loss=1.166, ntokens=1137.6, nsentences=32, sample_size=1137.6, sample_size_v1=0, sample_size_v2=0, ppl=2.24, wps=605.8, ups=0.53, wpb=1137.6, bsz=32, num_updates=12360, lr=2.43228e-05, gnorm=2.202, clip=100, loss_scale=256, train_wall=19, gb_free=11.4, wall=23228
2023-05-26 05:50:32 - progress_bar.py[line:272] - INFO: epoch 008:    266 / 1732 loss=2.37, loss_v1=0, loss_v2=0, nll_loss=1.168, ntokens=1142, nsentences=32, sample_size=1142, sample_size_v1=0, sample_size_v2=0, ppl=2.25, wps=608.7, ups=0.53, wpb=1142, bsz=32, num_updates=12370, lr=2.43167e-05, gnorm=2.061, clip=100, loss_scale=256, train_wall=19, gb_free=10.9, wall=23247
2023-05-26 05:50:51 - progress_bar.py[line:272] - INFO: epoch 008:    276 / 1732 loss=2.369, loss_v1=0, loss_v2=0, nll_loss=1.17, ntokens=1142.5, nsentences=32, sample_size=1142.5, sample_size_v1=0, sample_size_v2=0, ppl=2.25, wps=606.1, ups=0.53, wpb=1142.5, bsz=32, num_updates=12380, lr=2.43105e-05, gnorm=2.38, clip=100, loss_scale=256, train_wall=19, gb_free=10.8, wall=23266
2023-05-26 05:51:10 - progress_bar.py[line:272] - INFO: epoch 008:    286 / 1732 loss=2.366, loss_v1=0, loss_v2=0, nll_loss=1.164, ntokens=1155.8, nsentences=32, sample_size=1155.8, sample_size_v1=0, sample_size_v2=0, ppl=2.24, wps=612.6, ups=0.53, wpb=1155.8, bsz=32, num_updates=12390, lr=2.43044e-05, gnorm=2.132, clip=100, loss_scale=256, train_wall=19, gb_free=11.2, wall=23285
2023-05-26 05:51:29 - progress_bar.py[line:272] - INFO: epoch 008:    296 / 1732 loss=2.358, loss_v1=0, loss_v2=0, nll_loss=1.159, ntokens=1134.4, nsentences=32, sample_size=1134.4, sample_size_v1=0, sample_size_v2=0, ppl=2.23, wps=604.8, ups=0.53, wpb=1134.4, bsz=32, num_updates=12400, lr=2.42983e-05, gnorm=2.277, clip=100, loss_scale=256, train_wall=19, gb_free=11, wall=23303
2023-05-26 05:51:48 - progress_bar.py[line:272] - INFO: epoch 008:    306 / 1732 loss=2.343, loss_v1=0, loss_v2=0, nll_loss=1.138, ntokens=1078.8, nsentences=32, sample_size=1078.8, sample_size_v1=0, sample_size_v2=0, ppl=2.2, wps=576.9, ups=0.53, wpb=1078.8, bsz=32, num_updates=12410, lr=2.42921e-05, gnorm=2.521, clip=100, loss_scale=256, train_wall=19, gb_free=10.9, wall=23322
2023-05-26 05:52:06 - progress_bar.py[line:272] - INFO: epoch 008:    316 / 1732 loss=2.372, loss_v1=0, loss_v2=0, nll_loss=1.172, ntokens=1033.6, nsentences=32, sample_size=1033.6, sample_size_v1=0, sample_size_v2=0, ppl=2.25, wps=555, ups=0.54, wpb=1033.6, bsz=32, num_updates=12420, lr=2.4286e-05, gnorm=2.49, clip=100, loss_scale=256, train_wall=19, gb_free=10.8, wall=23341
2023-05-26 05:52:25 - progress_bar.py[line:272] - INFO: epoch 008:    326 / 1732 loss=2.387, loss_v1=0, loss_v2=0, nll_loss=1.189, ntokens=1006.1, nsentences=32, sample_size=1006.1, sample_size_v1=0, sample_size_v2=0, ppl=2.28, wps=541.5, ups=0.54, wpb=1006.1, bsz=32, num_updates=12430, lr=2.42798e-05, gnorm=2.609, clip=100, loss_scale=256, train_wall=19, gb_free=11.6, wall=23359
2023-05-26 05:52:43 - progress_bar.py[line:272] - INFO: epoch 008:    336 / 1732 loss=2.371, loss_v1=0, loss_v2=0, nll_loss=1.172, ntokens=1005.9, nsentences=32, sample_size=1005.9, sample_size_v1=0, sample_size_v2=0, ppl=2.25, wps=543.6, ups=0.54, wpb=1005.9, bsz=32, num_updates=12440, lr=2.42737e-05, gnorm=2.469, clip=100, loss_scale=256, train_wall=18, gb_free=11.4, wall=23378
2023-05-26 05:53:02 - progress_bar.py[line:272] - INFO: epoch 008:    346 / 1732 loss=2.348, loss_v1=0, loss_v2=0, nll_loss=1.145, ntokens=909.3, nsentences=32, sample_size=909.3, sample_size_v1=0, sample_size_v2=0, ppl=2.21, wps=491, ups=0.54, wpb=909.3, bsz=32, num_updates=12450, lr=2.42676e-05, gnorm=2.742, clip=100, loss_scale=256, train_wall=18, gb_free=11.3, wall=23396
2023-05-26 05:53:20 - progress_bar.py[line:272] - INFO: epoch 008:    356 / 1732 loss=2.386, loss_v1=0, loss_v2=0, nll_loss=1.187, ntokens=955.2, nsentences=32, sample_size=955.2, sample_size_v1=0, sample_size_v2=0, ppl=2.28, wps=516.6, ups=0.54, wpb=955.2, bsz=32, num_updates=12460, lr=2.42614e-05, gnorm=2.742, clip=100, loss_scale=256, train_wall=18, gb_free=11.4, wall=23415
2023-05-26 05:53:39 - progress_bar.py[line:272] - INFO: epoch 008:    366 / 1732 loss=2.395, loss_v1=0, loss_v2=0, nll_loss=1.195, ntokens=951.9, nsentences=32, sample_size=951.9, sample_size_v1=0, sample_size_v2=0, ppl=2.29, wps=514.7, ups=0.54, wpb=951.9, bsz=32, num_updates=12470, lr=2.42553e-05, gnorm=2.603, clip=100, loss_scale=256, train_wall=18, gb_free=11.5, wall=23433
2023-05-26 05:53:57 - progress_bar.py[line:272] - INFO: epoch 008:    376 / 1732 loss=2.4, loss_v1=0, loss_v2=0, nll_loss=1.204, ntokens=1015.4, nsentences=32, sample_size=1015.4, sample_size_v1=0, sample_size_v2=0, ppl=2.3, wps=548.7, ups=0.54, wpb=1015.4, bsz=32, num_updates=12480, lr=2.42491e-05, gnorm=2.54, clip=100, loss_scale=256, train_wall=18, gb_free=11.4, wall=23452
2023-05-26 05:54:16 - progress_bar.py[line:272] - INFO: epoch 008:    386 / 1732 loss=2.387, loss_v1=0, loss_v2=0, nll_loss=1.189, ntokens=1063.1, nsentences=32, sample_size=1063.1, sample_size_v1=0, sample_size_v2=0, ppl=2.28, wps=572.4, ups=0.54, wpb=1063.1, bsz=32, num_updates=12490, lr=2.4243e-05, gnorm=2.575, clip=100, loss_scale=256, train_wall=19, gb_free=11.4, wall=23471
2023-05-26 05:54:34 - progress_bar.py[line:272] - INFO: epoch 008:    396 / 1732 loss=2.37, loss_v1=0, loss_v2=0, nll_loss=1.169, ntokens=950.2, nsentences=32, sample_size=950.2, sample_size_v1=0, sample_size_v2=0, ppl=2.25, wps=513.9, ups=0.54, wpb=950.2, bsz=32, num_updates=12500, lr=2.42368e-05, gnorm=2.723, clip=100, loss_scale=256, train_wall=18, gb_free=11.3, wall=23489
2023-05-26 05:54:53 - progress_bar.py[line:272] - INFO: epoch 008:    406 / 1732 loss=2.35, loss_v1=0, loss_v2=0, nll_loss=1.147, ntokens=1066.6, nsentences=32, sample_size=1066.6, sample_size_v1=0, sample_size_v2=0, ppl=2.21, wps=572.3, ups=0.54, wpb=1066.6, bsz=32, num_updates=12510, lr=2.42307e-05, gnorm=2.149, clip=100, loss_scale=256, train_wall=19, gb_free=11.2, wall=23508
2023-05-26 05:55:12 - progress_bar.py[line:272] - INFO: epoch 008:    416 / 1732 loss=2.344, loss_v1=0, loss_v2=0, nll_loss=1.142, ntokens=1055.1, nsentences=32, sample_size=1055.1, sample_size_v1=0, sample_size_v2=0, ppl=2.21, wps=566, ups=0.54, wpb=1055.1, bsz=32, num_updates=12520, lr=2.42246e-05, gnorm=2.41, clip=100, loss_scale=256, train_wall=19, gb_free=11.5, wall=23526
2023-05-26 05:55:30 - progress_bar.py[line:272] - INFO: epoch 008:    426 / 1732 loss=2.326, loss_v1=0, loss_v2=0, nll_loss=1.118, ntokens=988.1, nsentences=32, sample_size=988.1, sample_size_v1=0, sample_size_v2=0, ppl=2.17, wps=530.8, ups=0.54, wpb=988.1, bsz=32, num_updates=12530, lr=2.42184e-05, gnorm=2.472, clip=100, loss_scale=256, train_wall=19, gb_free=11, wall=23545
2023-05-26 05:55:49 - progress_bar.py[line:272] - INFO: epoch 008:    436 / 1732 loss=2.376, loss_v1=0, loss_v2=0, nll_loss=1.177, ntokens=1044.5, nsentences=32, sample_size=1044.5, sample_size_v1=0, sample_size_v2=0, ppl=2.26, wps=562.7, ups=0.54, wpb=1044.5, bsz=32, num_updates=12540, lr=2.42123e-05, gnorm=2.345, clip=100, loss_scale=256, train_wall=19, gb_free=11.1, wall=23563
2023-05-26 05:56:07 - progress_bar.py[line:272] - INFO: epoch 008:    446 / 1732 loss=2.378, loss_v1=0, loss_v2=0, nll_loss=1.178, ntokens=952.9, nsentences=32, sample_size=952.9, sample_size_v1=0, sample_size_v2=0, ppl=2.26, wps=513.5, ups=0.54, wpb=952.9, bsz=32, num_updates=12550, lr=2.42061e-05, gnorm=2.391, clip=100, loss_scale=256, train_wall=19, gb_free=10.9, wall=23582
2023-05-26 05:56:26 - progress_bar.py[line:272] - INFO: epoch 008:    456 / 1732 loss=2.38, loss_v1=0, loss_v2=0, nll_loss=1.183, ntokens=925.5, nsentences=32, sample_size=925.5, sample_size_v1=0, sample_size_v2=0, ppl=2.27, wps=501.5, ups=0.54, wpb=925.5, bsz=32, num_updates=12560, lr=2.42e-05, gnorm=2.6, clip=100, loss_scale=256, train_wall=18, gb_free=11.6, wall=23600
2023-05-26 05:56:45 - progress_bar.py[line:272] - INFO: epoch 008:    466 / 1732 loss=2.392, loss_v1=0, loss_v2=0, nll_loss=1.191, ntokens=1063.6, nsentences=32, sample_size=1063.6, sample_size_v1=0, sample_size_v2=0, ppl=2.28, wps=569.4, ups=0.54, wpb=1063.6, bsz=32, num_updates=12570, lr=2.41938e-05, gnorm=2.469, clip=100, loss_scale=256, train_wall=19, gb_free=11.4, wall=23619
2023-05-26 05:57:03 - progress_bar.py[line:272] - INFO: epoch 008:    476 / 1732 loss=2.396, loss_v1=0, loss_v2=0, nll_loss=1.197, ntokens=1057.9, nsentences=32, sample_size=1057.9, sample_size_v1=0, sample_size_v2=0, ppl=2.29, wps=566.2, ups=0.54, wpb=1057.9, bsz=32, num_updates=12580, lr=2.41877e-05, gnorm=2.431, clip=100, loss_scale=256, train_wall=19, gb_free=11.3, wall=23638
2023-05-26 05:57:22 - progress_bar.py[line:272] - INFO: epoch 008:    486 / 1732 loss=2.361, loss_v1=0, loss_v2=0, nll_loss=1.161, ntokens=966.1, nsentences=32, sample_size=966.1, sample_size_v1=0, sample_size_v2=0, ppl=2.24, wps=521.9, ups=0.54, wpb=966.1, bsz=32, num_updates=12590, lr=2.41816e-05, gnorm=2.53, clip=100, loss_scale=256, train_wall=18, gb_free=11.3, wall=23656
2023-05-26 05:57:40 - progress_bar.py[line:272] - INFO: epoch 008:    496 / 1732 loss=2.363, loss_v1=0, loss_v2=0, nll_loss=1.162, ntokens=932.2, nsentences=32, sample_size=932.2, sample_size_v1=0, sample_size_v2=0, ppl=2.24, wps=504.4, ups=0.54, wpb=932.2, bsz=32, num_updates=12600, lr=2.41754e-05, gnorm=2.491, clip=100, loss_scale=256, train_wall=18, gb_free=11.7, wall=23675
2023-05-26 05:57:59 - progress_bar.py[line:272] - INFO: epoch 008:    506 / 1732 loss=2.38, loss_v1=0, loss_v2=0, nll_loss=1.18, ntokens=994.9, nsentences=32, sample_size=994.9, sample_size_v1=0, sample_size_v2=0, ppl=2.27, wps=538.5, ups=0.54, wpb=994.9, bsz=32, num_updates=12610, lr=2.41693e-05, gnorm=2.597, clip=100, loss_scale=256, train_wall=18, gb_free=11.5, wall=23693
2023-05-26 05:58:17 - progress_bar.py[line:272] - INFO: epoch 008:    516 / 1732 loss=2.378, loss_v1=0, loss_v2=0, nll_loss=1.178, ntokens=1062.8, nsentences=32, sample_size=1062.8, sample_size_v1=0, sample_size_v2=0, ppl=2.26, wps=573, ups=0.54, wpb=1062.8, bsz=32, num_updates=12620, lr=2.41631e-05, gnorm=2.36, clip=100, loss_scale=256, train_wall=19, gb_free=11.6, wall=23712
2023-05-26 05:58:34 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 256.0
2023-05-26 05:58:37 - progress_bar.py[line:272] - INFO: epoch 008:    527 / 1732 loss=2.365, loss_v1=0, loss_v2=0, nll_loss=1.164, ntokens=947.6, nsentences=32, sample_size=947.6, sample_size_v1=0, sample_size_v2=0, ppl=2.24, wps=469.6, ups=0.5, wpb=947.6, bsz=32, num_updates=12630, lr=2.4157e-05, gnorm=2.628, clip=100, loss_scale=256, train_wall=20, gb_free=11.6, wall=23732
2023-05-26 05:58:56 - progress_bar.py[line:272] - INFO: epoch 008:    537 / 1732 loss=2.353, loss_v1=0, loss_v2=0, nll_loss=1.152, ntokens=964.7, nsentences=32, sample_size=964.7, sample_size_v1=0, sample_size_v2=0, ppl=2.22, wps=522.4, ups=0.54, wpb=964.7, bsz=32, num_updates=12640, lr=2.41509e-05, gnorm=2.569, clip=100, loss_scale=256, train_wall=18, gb_free=11.9, wall=23751
2023-05-26 05:59:14 - progress_bar.py[line:272] - INFO: epoch 008:    547 / 1732 loss=2.385, loss_v1=0, loss_v2=0, nll_loss=1.185, ntokens=1033.6, nsentences=32, sample_size=1033.6, sample_size_v1=0, sample_size_v2=0, ppl=2.27, wps=557.5, ups=0.54, wpb=1033.6, bsz=32, num_updates=12650, lr=2.41447e-05, gnorm=2.53, clip=100, loss_scale=256, train_wall=19, gb_free=11.7, wall=23769
2023-05-26 05:59:33 - progress_bar.py[line:272] - INFO: epoch 008:    557 / 1732 loss=2.403, loss_v1=0, loss_v2=0, nll_loss=1.208, ntokens=1010.2, nsentences=32, sample_size=1010.2, sample_size_v1=0, sample_size_v2=0, ppl=2.31, wps=545.1, ups=0.54, wpb=1010.2, bsz=32, num_updates=12660, lr=2.41386e-05, gnorm=2.4, clip=100, loss_scale=256, train_wall=19, gb_free=11.8, wall=23788
2023-05-26 05:59:52 - progress_bar.py[line:272] - INFO: epoch 008:    567 / 1732 loss=2.409, loss_v1=0, loss_v2=0, nll_loss=1.212, ntokens=1004.9, nsentences=32, sample_size=1004.9, sample_size_v1=0, sample_size_v2=0, ppl=2.32, wps=541, ups=0.54, wpb=1004.9, bsz=32, num_updates=12670, lr=2.41324e-05, gnorm=2.494, clip=100, loss_scale=256, train_wall=19, gb_free=11.7, wall=23806
2023-05-26 06:00:10 - progress_bar.py[line:272] - INFO: epoch 008:    577 / 1732 loss=2.376, loss_v1=0, loss_v2=0, nll_loss=1.175, ntokens=1011.7, nsentences=32, sample_size=1011.7, sample_size_v1=0, sample_size_v2=0, ppl=2.26, wps=541.6, ups=0.54, wpb=1011.7, bsz=32, num_updates=12680, lr=2.41263e-05, gnorm=2.518, clip=100, loss_scale=256, train_wall=19, gb_free=11.6, wall=23825
2023-05-26 06:00:29 - progress_bar.py[line:272] - INFO: epoch 008:    587 / 1732 loss=2.384, loss_v1=0, loss_v2=0, nll_loss=1.184, ntokens=962.2, nsentences=32, sample_size=962.2, sample_size_v1=0, sample_size_v2=0, ppl=2.27, wps=516.5, ups=0.54, wpb=962.2, bsz=32, num_updates=12690, lr=2.41201e-05, gnorm=2.567, clip=100, loss_scale=256, train_wall=19, gb_free=12, wall=23844
2023-05-26 06:00:47 - progress_bar.py[line:272] - INFO: epoch 008:    597 / 1732 loss=2.328, loss_v1=0, loss_v2=0, nll_loss=1.125, ntokens=975.4, nsentences=32, sample_size=975.4, sample_size_v1=0, sample_size_v2=0, ppl=2.18, wps=524.4, ups=0.54, wpb=975.4, bsz=32, num_updates=12700, lr=2.4114e-05, gnorm=2.524, clip=100, loss_scale=256, train_wall=19, gb_free=11.7, wall=23862
2023-05-26 06:01:06 - progress_bar.py[line:272] - INFO: epoch 008:    607 / 1732 loss=2.377, loss_v1=0, loss_v2=0, nll_loss=1.179, ntokens=882.8, nsentences=32, sample_size=882.8, sample_size_v1=0, sample_size_v2=0, ppl=2.26, wps=480.2, ups=0.54, wpb=882.8, bsz=32, num_updates=12710, lr=2.41079e-05, gnorm=2.867, clip=100, loss_scale=256, train_wall=18, gb_free=11.3, wall=23881
2023-05-26 06:01:24 - progress_bar.py[line:272] - INFO: epoch 008:    617 / 1732 loss=2.378, loss_v1=0, loss_v2=0, nll_loss=1.176, ntokens=866.1, nsentences=32, sample_size=866.1, sample_size_v1=0, sample_size_v2=0, ppl=2.26, wps=470.6, ups=0.54, wpb=866.1, bsz=32, num_updates=12720, lr=2.41017e-05, gnorm=2.913, clip=100, loss_scale=256, train_wall=18, gb_free=11.5, wall=23899
2023-05-26 06:01:43 - progress_bar.py[line:272] - INFO: epoch 008:    627 / 1732 loss=2.375, loss_v1=0, loss_v2=0, nll_loss=1.175, ntokens=930.6, nsentences=32, sample_size=930.6, sample_size_v1=0, sample_size_v2=0, ppl=2.26, wps=505.9, ups=0.54, wpb=930.6, bsz=32, num_updates=12730, lr=2.40956e-05, gnorm=2.665, clip=100, loss_scale=256, train_wall=18, gb_free=11.9, wall=23917
2023-05-26 06:02:01 - progress_bar.py[line:272] - INFO: epoch 008:    637 / 1732 loss=2.39, loss_v1=0, loss_v2=0, nll_loss=1.191, ntokens=914.3, nsentences=32, sample_size=914.3, sample_size_v1=0, sample_size_v2=0, ppl=2.28, wps=496.9, ups=0.54, wpb=914.3, bsz=32, num_updates=12740, lr=2.40894e-05, gnorm=2.755, clip=100, loss_scale=256, train_wall=18, gb_free=11.6, wall=23936
2023-05-26 06:02:20 - progress_bar.py[line:272] - INFO: epoch 008:    647 / 1732 loss=2.384, loss_v1=0, loss_v2=0, nll_loss=1.184, ntokens=980.8, nsentences=32, sample_size=980.8, sample_size_v1=0, sample_size_v2=0, ppl=2.27, wps=530.4, ups=0.54, wpb=980.8, bsz=32, num_updates=12750, lr=2.40833e-05, gnorm=2.533, clip=100, loss_scale=256, train_wall=18, gb_free=11.8, wall=23954
2023-05-26 06:02:38 - progress_bar.py[line:272] - INFO: epoch 008:    657 / 1732 loss=2.384, loss_v1=0, loss_v2=0, nll_loss=1.187, ntokens=894.4, nsentences=32, sample_size=894.4, sample_size_v1=0, sample_size_v2=0, ppl=2.28, wps=488.5, ups=0.55, wpb=894.4, bsz=32, num_updates=12760, lr=2.40771e-05, gnorm=2.756, clip=100, loss_scale=256, train_wall=18, gb_free=11.8, wall=23973
2023-05-26 06:02:56 - progress_bar.py[line:272] - INFO: epoch 008:    667 / 1732 loss=2.369, loss_v1=0, loss_v2=0, nll_loss=1.171, ntokens=903.9, nsentences=32, sample_size=903.9, sample_size_v1=0, sample_size_v2=0, ppl=2.25, wps=492.1, ups=0.54, wpb=903.9, bsz=32, num_updates=12770, lr=2.4071e-05, gnorm=2.788, clip=100, loss_scale=256, train_wall=18, gb_free=11.5, wall=23991
2023-05-26 06:03:15 - progress_bar.py[line:272] - INFO: epoch 008:    677 / 1732 loss=2.378, loss_v1=0, loss_v2=0, nll_loss=1.176, ntokens=985.3, nsentences=32, sample_size=985.3, sample_size_v1=0, sample_size_v2=0, ppl=2.26, wps=532.2, ups=0.54, wpb=985.3, bsz=32, num_updates=12780, lr=2.40649e-05, gnorm=2.883, clip=100, loss_scale=256, train_wall=18, gb_free=11.8, wall=24009
2023-05-26 06:03:33 - progress_bar.py[line:272] - INFO: epoch 008:    687 / 1732 loss=2.388, loss_v1=0, loss_v2=0, nll_loss=1.19, ntokens=943.2, nsentences=32, sample_size=943.2, sample_size_v1=0, sample_size_v2=0, ppl=2.28, wps=511.3, ups=0.54, wpb=943.2, bsz=32, num_updates=12790, lr=2.40587e-05, gnorm=2.878, clip=100, loss_scale=256, train_wall=18, gb_free=11.9, wall=24028
2023-05-26 06:03:52 - progress_bar.py[line:272] - INFO: epoch 008:    697 / 1732 loss=2.379, loss_v1=0, loss_v2=0, nll_loss=1.182, ntokens=1005.6, nsentences=32, sample_size=1005.6, sample_size_v1=0, sample_size_v2=0, ppl=2.27, wps=538.4, ups=0.54, wpb=1005.6, bsz=32, num_updates=12800, lr=2.40526e-05, gnorm=2.537, clip=100, loss_scale=256, train_wall=19, gb_free=10.9, wall=24047
2023-05-26 06:04:10 - progress_bar.py[line:272] - INFO: epoch 008:    707 / 1732 loss=2.365, loss_v1=0, loss_v2=0, nll_loss=1.159, ntokens=903.4, nsentences=32, sample_size=903.4, sample_size_v1=0, sample_size_v2=0, ppl=2.23, wps=491.5, ups=0.54, wpb=903.4, bsz=32, num_updates=12810, lr=2.40464e-05, gnorm=2.813, clip=100, loss_scale=256, train_wall=18, gb_free=11.6, wall=24065
2023-05-26 06:04:29 - progress_bar.py[line:272] - INFO: epoch 008:    717 / 1732 loss=2.364, loss_v1=0, loss_v2=0, nll_loss=1.164, ntokens=882.7, nsentences=32, sample_size=882.7, sample_size_v1=0, sample_size_v2=0, ppl=2.24, wps=480.2, ups=0.54, wpb=882.7, bsz=32, num_updates=12820, lr=2.40403e-05, gnorm=2.729, clip=100, loss_scale=256, train_wall=18, gb_free=11.6, wall=24083
2023-05-26 06:04:47 - progress_bar.py[line:272] - INFO: epoch 008:    727 / 1732 loss=2.35, loss_v1=0, loss_v2=0, nll_loss=1.15, ntokens=909.8, nsentences=32, sample_size=909.8, sample_size_v1=0, sample_size_v2=0, ppl=2.22, wps=493.2, ups=0.54, wpb=909.8, bsz=32, num_updates=12830, lr=2.40342e-05, gnorm=2.874, clip=100, loss_scale=256, train_wall=18, gb_free=11.9, wall=24102
2023-05-26 06:05:06 - progress_bar.py[line:272] - INFO: epoch 008:    737 / 1732 loss=2.356, loss_v1=0, loss_v2=0, nll_loss=1.153, ntokens=998.8, nsentences=32, sample_size=998.8, sample_size_v1=0, sample_size_v2=0, ppl=2.22, wps=540.5, ups=0.54, wpb=998.8, bsz=32, num_updates=12840, lr=2.4028e-05, gnorm=2.812, clip=100, loss_scale=256, train_wall=18, gb_free=11.5, wall=24120
2023-05-26 06:05:24 - progress_bar.py[line:272] - INFO: epoch 008:    747 / 1732 loss=2.349, loss_v1=0, loss_v2=0, nll_loss=1.144, ntokens=980.5, nsentences=32, sample_size=980.5, sample_size_v1=0, sample_size_v2=0, ppl=2.21, wps=526.7, ups=0.54, wpb=980.5, bsz=32, num_updates=12850, lr=2.40219e-05, gnorm=2.65, clip=100, loss_scale=256, train_wall=19, gb_free=11.3, wall=24139
2023-05-26 06:05:43 - progress_bar.py[line:272] - INFO: epoch 008:    757 / 1732 loss=2.359, loss_v1=0, loss_v2=0, nll_loss=1.159, ntokens=949.2, nsentences=32, sample_size=949.2, sample_size_v1=0, sample_size_v2=0, ppl=2.23, wps=515.1, ups=0.54, wpb=949.2, bsz=32, num_updates=12860, lr=2.40157e-05, gnorm=2.54, clip=100, loss_scale=256, train_wall=18, gb_free=11.6, wall=24157
2023-05-26 06:06:01 - progress_bar.py[line:272] - INFO: epoch 008:    767 / 1732 loss=2.353, loss_v1=0, loss_v2=0, nll_loss=1.153, ntokens=941.7, nsentences=32, sample_size=941.7, sample_size_v1=0, sample_size_v2=0, ppl=2.22, wps=510.8, ups=0.54, wpb=941.7, bsz=32, num_updates=12870, lr=2.40096e-05, gnorm=2.865, clip=100, loss_scale=256, train_wall=18, gb_free=11.9, wall=24176
2023-05-26 06:06:20 - progress_bar.py[line:272] - INFO: epoch 008:    777 / 1732 loss=2.365, loss_v1=0, loss_v2=0, nll_loss=1.161, ntokens=1028.6, nsentences=32, sample_size=1028.6, sample_size_v1=0, sample_size_v2=0, ppl=2.24, wps=554.1, ups=0.54, wpb=1028.6, bsz=32, num_updates=12880, lr=2.40034e-05, gnorm=2.578, clip=100, loss_scale=256, train_wall=19, gb_free=11.8, wall=24194
2023-05-26 06:06:38 - progress_bar.py[line:272] - INFO: epoch 008:    787 / 1732 loss=2.368, loss_v1=0, loss_v2=0, nll_loss=1.169, ntokens=1016.6, nsentences=32, sample_size=1016.6, sample_size_v1=0, sample_size_v2=0, ppl=2.25, wps=550.3, ups=0.54, wpb=1016.6, bsz=32, num_updates=12890, lr=2.39973e-05, gnorm=2.639, clip=100, loss_scale=256, train_wall=18, gb_free=11.3, wall=24213
2023-05-26 06:06:57 - progress_bar.py[line:272] - INFO: epoch 008:    797 / 1732 loss=2.366, loss_v1=0, loss_v2=0, nll_loss=1.165, ntokens=1038, nsentences=32, sample_size=1038, sample_size_v1=0, sample_size_v2=0, ppl=2.24, wps=560.9, ups=0.54, wpb=1038, bsz=32, num_updates=12900, lr=2.39912e-05, gnorm=2.679, clip=100, loss_scale=256, train_wall=18, gb_free=11.6, wall=24231
2023-05-26 06:07:15 - progress_bar.py[line:272] - INFO: epoch 008:    807 / 1732 loss=2.356, loss_v1=0, loss_v2=0, nll_loss=1.152, ntokens=915, nsentences=32, sample_size=915, sample_size_v1=0, sample_size_v2=0, ppl=2.22, wps=495.6, ups=0.54, wpb=915, bsz=32, num_updates=12910, lr=2.3985e-05, gnorm=2.68, clip=100, loss_scale=256, train_wall=18, gb_free=11.4, wall=24250
2023-05-26 06:07:34 - progress_bar.py[line:272] - INFO: epoch 008:    817 / 1732 loss=2.373, loss_v1=0, loss_v2=0, nll_loss=1.173, ntokens=917.4, nsentences=32, sample_size=917.4, sample_size_v1=0, sample_size_v2=0, ppl=2.25, wps=495.7, ups=0.54, wpb=917.4, bsz=32, num_updates=12920, lr=2.39789e-05, gnorm=2.806, clip=100, loss_scale=256, train_wall=18, gb_free=11.7, wall=24268
2023-05-26 06:07:52 - progress_bar.py[line:272] - INFO: epoch 008:    827 / 1732 loss=2.368, loss_v1=0, loss_v2=0, nll_loss=1.167, ntokens=930.6, nsentences=32, sample_size=930.6, sample_size_v1=0, sample_size_v2=0, ppl=2.25, wps=503.5, ups=0.54, wpb=930.6, bsz=32, num_updates=12930, lr=2.39727e-05, gnorm=2.636, clip=100, loss_scale=256, train_wall=18, gb_free=11.7, wall=24287
2023-05-26 06:08:10 - progress_bar.py[line:272] - INFO: epoch 008:    837 / 1732 loss=2.37, loss_v1=0, loss_v2=0, nll_loss=1.169, ntokens=894.5, nsentences=32, sample_size=894.5, sample_size_v1=0, sample_size_v2=0, ppl=2.25, wps=488.7, ups=0.55, wpb=894.5, bsz=32, num_updates=12940, lr=2.39666e-05, gnorm=2.97, clip=100, loss_scale=256, train_wall=18, gb_free=11.7, wall=24305
2023-05-26 06:08:29 - progress_bar.py[line:272] - INFO: epoch 008:    847 / 1732 loss=2.344, loss_v1=0, loss_v2=0, nll_loss=1.14, ntokens=1012.6, nsentences=32, sample_size=1012.6, sample_size_v1=0, sample_size_v2=0, ppl=2.2, wps=547.7, ups=0.54, wpb=1012.6, bsz=32, num_updates=12950, lr=2.39604e-05, gnorm=2.683, clip=100, loss_scale=256, train_wall=18, gb_free=10.6, wall=24324
2023-05-26 06:08:47 - progress_bar.py[line:272] - INFO: epoch 008:    857 / 1732 loss=2.364, loss_v1=0, loss_v2=0, nll_loss=1.166, ntokens=920, nsentences=32, sample_size=920, sample_size_v1=0, sample_size_v2=0, ppl=2.24, wps=499, ups=0.54, wpb=920, bsz=32, num_updates=12960, lr=2.39543e-05, gnorm=2.901, clip=100, loss_scale=256, train_wall=18, gb_free=11.7, wall=24342
2023-05-26 06:09:06 - progress_bar.py[line:272] - INFO: epoch 008:    867 / 1732 loss=2.371, loss_v1=0, loss_v2=0, nll_loss=1.171, ntokens=979.9, nsentences=32, sample_size=979.9, sample_size_v1=0, sample_size_v2=0, ppl=2.25, wps=530.6, ups=0.54, wpb=979.9, bsz=32, num_updates=12970, lr=2.39482e-05, gnorm=2.739, clip=100, loss_scale=256, train_wall=18, gb_free=11.3, wall=24360
2023-05-26 06:09:24 - progress_bar.py[line:272] - INFO: epoch 008:    877 / 1732 loss=2.307, loss_v1=0, loss_v2=0, nll_loss=1.098, ntokens=994.5, nsentences=32, sample_size=994.5, sample_size_v1=0, sample_size_v2=0, ppl=2.14, wps=536.6, ups=0.54, wpb=994.5, bsz=32, num_updates=12980, lr=2.3942e-05, gnorm=2.624, clip=100, loss_scale=256, train_wall=19, gb_free=11.7, wall=24379
2023-05-26 06:09:43 - progress_bar.py[line:272] - INFO: epoch 008:    887 / 1732 loss=2.321, loss_v1=0, loss_v2=0, nll_loss=1.116, ntokens=982, nsentences=32, sample_size=982, sample_size_v1=0, sample_size_v2=0, ppl=2.17, wps=528.4, ups=0.54, wpb=982, bsz=32, num_updates=12990, lr=2.39359e-05, gnorm=2.714, clip=100, loss_scale=256, train_wall=19, gb_free=11.2, wall=24398
2023-05-26 06:10:01 - progress_bar.py[line:272] - INFO: epoch 008:    897 / 1732 loss=2.3, loss_v1=0, loss_v2=0, nll_loss=1.089, ntokens=1034.6, nsentences=32, sample_size=1034.6, sample_size_v1=0, sample_size_v2=0, ppl=2.13, wps=557.4, ups=0.54, wpb=1034.6, bsz=32, num_updates=13000, lr=2.39297e-05, gnorm=2.475, clip=100, loss_scale=256, train_wall=19, gb_free=11.5, wall=24416
2023-05-26 06:10:20 - progress_bar.py[line:272] - INFO: epoch 008:    907 / 1732 loss=2.31, loss_v1=0, loss_v2=0, nll_loss=1.105, ntokens=1016.8, nsentences=32, sample_size=1016.8, sample_size_v1=0, sample_size_v2=0, ppl=2.15, wps=547.3, ups=0.54, wpb=1016.8, bsz=32, num_updates=13010, lr=2.39236e-05, gnorm=2.539, clip=100, loss_scale=256, train_wall=19, gb_free=11.6, wall=24435
2023-05-26 06:10:39 - progress_bar.py[line:272] - INFO: epoch 008:    917 / 1732 loss=2.4, loss_v1=0, loss_v2=0, nll_loss=1.203, ntokens=936.4, nsentences=32, sample_size=936.4, sample_size_v1=0, sample_size_v2=0, ppl=2.3, wps=506.2, ups=0.54, wpb=936.4, bsz=32, num_updates=13020, lr=2.39174e-05, gnorm=2.969, clip=100, loss_scale=256, train_wall=18, gb_free=11.8, wall=24453
2023-05-26 06:10:57 - progress_bar.py[line:272] - INFO: epoch 008:    927 / 1732 loss=2.328, loss_v1=0, loss_v2=0, nll_loss=1.123, ntokens=1039.7, nsentences=32, sample_size=1039.7, sample_size_v1=0, sample_size_v2=0, ppl=2.18, wps=556, ups=0.53, wpb=1039.7, bsz=32, num_updates=13030, lr=2.39113e-05, gnorm=2.595, clip=100, loss_scale=256, train_wall=19, gb_free=11.5, wall=24472
2023-05-26 06:11:16 - progress_bar.py[line:272] - INFO: epoch 008:    937 / 1732 loss=2.337, loss_v1=0, loss_v2=0, nll_loss=1.133, ntokens=1061.1, nsentences=32, sample_size=1061.1, sample_size_v1=0, sample_size_v2=0, ppl=2.19, wps=565.6, ups=0.53, wpb=1061.1, bsz=32, num_updates=13040, lr=2.39052e-05, gnorm=2.656, clip=100, loss_scale=256, train_wall=19, gb_free=11.5, wall=24491
2023-05-26 06:11:35 - progress_bar.py[line:272] - INFO: epoch 008:    947 / 1732 loss=2.35, loss_v1=0, loss_v2=0, nll_loss=1.146, ntokens=1042.4, nsentences=32, sample_size=1042.4, sample_size_v1=0, sample_size_v2=0, ppl=2.21, wps=553.8, ups=0.53, wpb=1042.4, bsz=32, num_updates=13050, lr=2.3899e-05, gnorm=2.56, clip=100, loss_scale=256, train_wall=19, gb_free=11.2, wall=24510
2023-05-26 06:11:54 - progress_bar.py[line:272] - INFO: epoch 008:    957 / 1732 loss=2.35, loss_v1=0, loss_v2=0, nll_loss=1.147, ntokens=1046.8, nsentences=32, sample_size=1046.8, sample_size_v1=0, sample_size_v2=0, ppl=2.21, wps=559.9, ups=0.53, wpb=1046.8, bsz=32, num_updates=13060, lr=2.38929e-05, gnorm=2.591, clip=100, loss_scale=256, train_wall=19, gb_free=11.1, wall=24528
2023-05-26 06:12:12 - progress_bar.py[line:272] - INFO: epoch 008:    967 / 1732 loss=2.355, loss_v1=0, loss_v2=0, nll_loss=1.154, ntokens=1036.4, nsentences=32, sample_size=1036.4, sample_size_v1=0, sample_size_v2=0, ppl=2.23, wps=554.2, ups=0.53, wpb=1036.4, bsz=32, num_updates=13070, lr=2.38867e-05, gnorm=2.865, clip=100, loss_scale=256, train_wall=19, gb_free=11.3, wall=24547
2023-05-26 06:12:31 - progress_bar.py[line:272] - INFO: epoch 008:    977 / 1732 loss=2.351, loss_v1=0, loss_v2=0, nll_loss=1.148, ntokens=1035.2, nsentences=32, sample_size=1035.2, sample_size_v1=0, sample_size_v2=0, ppl=2.22, wps=549.1, ups=0.53, wpb=1035.2, bsz=32, num_updates=13080, lr=2.38806e-05, gnorm=2.494, clip=100, loss_scale=256, train_wall=19, gb_free=10.4, wall=24566
2023-05-26 06:12:50 - progress_bar.py[line:272] - INFO: epoch 008:    987 / 1732 loss=2.35, loss_v1=0, loss_v2=0, nll_loss=1.147, ntokens=1020.1, nsentences=32, sample_size=1020.1, sample_size_v1=0, sample_size_v2=0, ppl=2.21, wps=539.5, ups=0.53, wpb=1020.1, bsz=32, num_updates=13090, lr=2.38745e-05, gnorm=2.549, clip=100, loss_scale=256, train_wall=19, gb_free=11.3, wall=24585
2023-05-26 06:13:09 - progress_bar.py[line:272] - INFO: epoch 008:    997 / 1732 loss=2.341, loss_v1=0, loss_v2=0, nll_loss=1.135, ntokens=1032.4, nsentences=32, sample_size=1032.4, sample_size_v1=0, sample_size_v2=0, ppl=2.2, wps=553, ups=0.54, wpb=1032.4, bsz=32, num_updates=13100, lr=2.38683e-05, gnorm=2.815, clip=100, loss_scale=256, train_wall=19, gb_free=11.7, wall=24603
2023-05-26 06:13:27 - progress_bar.py[line:272] - INFO: epoch 008:   1007 / 1732 loss=2.337, loss_v1=0, loss_v2=0, nll_loss=1.133, ntokens=1018.9, nsentences=32, sample_size=1018.9, sample_size_v1=0, sample_size_v2=0, ppl=2.19, wps=545.9, ups=0.54, wpb=1018.9, bsz=32, num_updates=13110, lr=2.38622e-05, gnorm=2.664, clip=100, loss_scale=256, train_wall=19, gb_free=11.3, wall=24622
2023-05-26 06:13:46 - progress_bar.py[line:272] - INFO: epoch 008:   1017 / 1732 loss=2.332, loss_v1=0, loss_v2=0, nll_loss=1.128, ntokens=1024.8, nsentences=32, sample_size=1024.8, sample_size_v1=0, sample_size_v2=0, ppl=2.19, wps=548.3, ups=0.53, wpb=1024.8, bsz=32, num_updates=13120, lr=2.3856e-05, gnorm=2.552, clip=100, loss_scale=256, train_wall=19, gb_free=10.5, wall=24641
2023-05-26 06:14:05 - progress_bar.py[line:272] - INFO: epoch 008:   1027 / 1732 loss=2.363, loss_v1=0, loss_v2=0, nll_loss=1.161, ntokens=1051.5, nsentences=32, sample_size=1051.5, sample_size_v1=0, sample_size_v2=0, ppl=2.24, wps=558.4, ups=0.53, wpb=1051.5, bsz=32, num_updates=13130, lr=2.38499e-05, gnorm=2.71, clip=100, loss_scale=256, train_wall=19, gb_free=11.3, wall=24660
2023-05-26 06:14:24 - progress_bar.py[line:272] - INFO: epoch 008:   1037 / 1732 loss=2.335, loss_v1=0, loss_v2=0, nll_loss=1.129, ntokens=1129.2, nsentences=32, sample_size=1129.2, sample_size_v1=0, sample_size_v2=0, ppl=2.19, wps=597.7, ups=0.53, wpb=1129.2, bsz=32, num_updates=13140, lr=2.38437e-05, gnorm=2.441, clip=100, loss_scale=512, train_wall=19, gb_free=11.5, wall=24678
2023-05-26 06:14:26 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 256.0
2023-05-26 06:14:44 - progress_bar.py[line:272] - INFO: epoch 008:   1048 / 1732 loss=2.331, loss_v1=0, loss_v2=0, nll_loss=1.126, ntokens=1025.8, nsentences=32, sample_size=1025.8, sample_size_v1=0, sample_size_v2=0, ppl=2.18, wps=498.7, ups=0.49, wpb=1025.8, bsz=32, num_updates=13150, lr=2.38376e-05, gnorm=2.771, clip=100, loss_scale=256, train_wall=21, gb_free=11.4, wall=24699
2023-05-26 06:15:03 - progress_bar.py[line:272] - INFO: epoch 008:   1058 / 1732 loss=2.351, loss_v1=0, loss_v2=0, nll_loss=1.148, ntokens=1082.8, nsentences=32, sample_size=1082.8, sample_size_v1=0, sample_size_v2=0, ppl=2.22, wps=577.5, ups=0.53, wpb=1082.8, bsz=32, num_updates=13160, lr=2.38315e-05, gnorm=2.417, clip=100, loss_scale=256, train_wall=19, gb_free=11.8, wall=24718
2023-05-26 06:15:22 - progress_bar.py[line:272] - INFO: epoch 008:   1068 / 1732 loss=2.339, loss_v1=0, loss_v2=0, nll_loss=1.135, ntokens=1002.9, nsentences=32, sample_size=1002.9, sample_size_v1=0, sample_size_v2=0, ppl=2.2, wps=537.7, ups=0.54, wpb=1002.9, bsz=32, num_updates=13170, lr=2.38253e-05, gnorm=2.461, clip=100, loss_scale=256, train_wall=19, gb_free=11.7, wall=24736
2023-05-26 06:15:41 - progress_bar.py[line:272] - INFO: epoch 008:   1078 / 1732 loss=2.367, loss_v1=0, loss_v2=0, nll_loss=1.167, ntokens=1000.2, nsentences=32, sample_size=1000.2, sample_size_v1=0, sample_size_v2=0, ppl=2.25, wps=530.5, ups=0.53, wpb=1000.2, bsz=32, num_updates=13180, lr=2.38192e-05, gnorm=2.627, clip=100, loss_scale=256, train_wall=19, gb_free=11.5, wall=24755
2023-05-26 06:16:00 - progress_bar.py[line:272] - INFO: epoch 008:   1088 / 1732 loss=2.329, loss_v1=0, loss_v2=0, nll_loss=1.123, ntokens=1078.6, nsentences=32, sample_size=1078.6, sample_size_v1=0, sample_size_v2=0, ppl=2.18, wps=570.7, ups=0.53, wpb=1078.6, bsz=32, num_updates=13190, lr=2.3813e-05, gnorm=2.291, clip=100, loss_scale=256, train_wall=19, gb_free=11.4, wall=24774
2023-05-26 06:16:18 - progress_bar.py[line:272] - INFO: epoch 008:   1098 / 1732 loss=2.36, loss_v1=0, loss_v2=0, nll_loss=1.157, ntokens=1045.6, nsentences=32, sample_size=1045.6, sample_size_v1=0, sample_size_v2=0, ppl=2.23, wps=558.5, ups=0.53, wpb=1045.6, bsz=32, num_updates=13200, lr=2.38069e-05, gnorm=2.695, clip=100, loss_scale=256, train_wall=19, gb_free=10.8, wall=24793
2023-05-26 06:16:37 - progress_bar.py[line:272] - INFO: epoch 008:   1108 / 1732 loss=2.329, loss_v1=0, loss_v2=0, nll_loss=1.126, ntokens=1058.8, nsentences=32, sample_size=1058.8, sample_size_v1=0, sample_size_v2=0, ppl=2.18, wps=562.9, ups=0.53, wpb=1058.8, bsz=32, num_updates=13210, lr=2.38007e-05, gnorm=2.604, clip=100, loss_scale=256, train_wall=19, gb_free=11.6, wall=24812
2023-05-26 06:16:56 - progress_bar.py[line:272] - INFO: epoch 008:   1118 / 1732 loss=2.345, loss_v1=0, loss_v2=0, nll_loss=1.139, ntokens=944.7, nsentences=32, sample_size=944.7, sample_size_v1=0, sample_size_v2=0, ppl=2.2, wps=503.1, ups=0.53, wpb=944.7, bsz=32, num_updates=13220, lr=2.37946e-05, gnorm=2.658, clip=100, loss_scale=256, train_wall=19, gb_free=11.2, wall=24831
2023-05-26 06:17:15 - progress_bar.py[line:272] - INFO: epoch 008:   1128 / 1732 loss=2.342, loss_v1=0, loss_v2=0, nll_loss=1.14, ntokens=1025.9, nsentences=32, sample_size=1025.9, sample_size_v1=0, sample_size_v2=0, ppl=2.2, wps=545.5, ups=0.53, wpb=1025.9, bsz=32, num_updates=13230, lr=2.37885e-05, gnorm=2.427, clip=100, loss_scale=256, train_wall=19, gb_free=10.7, wall=24849
2023-05-26 06:17:33 - progress_bar.py[line:272] - INFO: epoch 008:   1138 / 1732 loss=2.345, loss_v1=0, loss_v2=0, nll_loss=1.14, ntokens=989.2, nsentences=32, sample_size=989.2, sample_size_v1=0, sample_size_v2=0, ppl=2.2, wps=529, ups=0.53, wpb=989.2, bsz=32, num_updates=13240, lr=2.37823e-05, gnorm=2.467, clip=100, loss_scale=256, train_wall=19, gb_free=11.6, wall=24868
2023-05-26 06:17:52 - progress_bar.py[line:272] - INFO: epoch 008:   1148 / 1732 loss=2.347, loss_v1=0, loss_v2=0, nll_loss=1.145, ntokens=1007.7, nsentences=32, sample_size=1007.7, sample_size_v1=0, sample_size_v2=0, ppl=2.21, wps=539.5, ups=0.54, wpb=1007.7, bsz=32, num_updates=13250, lr=2.37762e-05, gnorm=2.697, clip=100, loss_scale=256, train_wall=19, gb_free=11.5, wall=24887
2023-05-26 06:18:11 - progress_bar.py[line:272] - INFO: epoch 008:   1158 / 1732 loss=2.319, loss_v1=0, loss_v2=0, nll_loss=1.115, ntokens=1016, nsentences=32, sample_size=1016, sample_size_v1=0, sample_size_v2=0, ppl=2.17, wps=540.5, ups=0.53, wpb=1016, bsz=32, num_updates=13260, lr=2.377e-05, gnorm=2.773, clip=100, loss_scale=256, train_wall=19, gb_free=10.8, wall=24906
2023-05-26 06:18:18 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 128.0
2023-05-26 06:18:31 - progress_bar.py[line:272] - INFO: epoch 008:   1169 / 1732 loss=2.34, loss_v1=0, loss_v2=0, nll_loss=1.133, ntokens=1016.7, nsentences=32, sample_size=1016.7, sample_size_v1=0, sample_size_v2=0, ppl=2.19, wps=494, ups=0.49, wpb=1016.7, bsz=32, num_updates=13270, lr=2.37639e-05, gnorm=2.493, clip=100, loss_scale=128, train_wall=21, gb_free=11.1, wall=24926
2023-05-26 06:18:50 - progress_bar.py[line:272] - INFO: epoch 008:   1179 / 1732 loss=2.312, loss_v1=0, loss_v2=0, nll_loss=1.105, ntokens=1057.9, nsentences=32, sample_size=1057.9, sample_size_v1=0, sample_size_v2=0, ppl=2.15, wps=565, ups=0.53, wpb=1057.9, bsz=32, num_updates=13280, lr=2.37578e-05, gnorm=2.65, clip=100, loss_scale=128, train_wall=19, gb_free=11.6, wall=24945
2023-05-26 06:19:09 - progress_bar.py[line:272] - INFO: epoch 008:   1189 / 1732 loss=2.342, loss_v1=0, loss_v2=0, nll_loss=1.139, ntokens=993.6, nsentences=32, sample_size=993.6, sample_size_v1=0, sample_size_v2=0, ppl=2.2, wps=530.4, ups=0.53, wpb=993.6, bsz=32, num_updates=13290, lr=2.37516e-05, gnorm=2.626, clip=100, loss_scale=128, train_wall=19, gb_free=11, wall=24964
2023-05-26 06:19:28 - progress_bar.py[line:272] - INFO: epoch 008:   1199 / 1732 loss=2.322, loss_v1=0, loss_v2=0, nll_loss=1.113, ntokens=1103.9, nsentences=32, sample_size=1103.9, sample_size_v1=0, sample_size_v2=0, ppl=2.16, wps=586.1, ups=0.53, wpb=1103.9, bsz=32, num_updates=13300, lr=2.37455e-05, gnorm=2.45, clip=100, loss_scale=128, train_wall=19, gb_free=10.8, wall=24982
2023-05-26 06:19:47 - progress_bar.py[line:272] - INFO: epoch 008:   1209 / 1732 loss=2.32, loss_v1=0, loss_v2=0, nll_loss=1.116, ntokens=1079.5, nsentences=32, sample_size=1079.5, sample_size_v1=0, sample_size_v2=0, ppl=2.17, wps=570.2, ups=0.53, wpb=1079.5, bsz=32, num_updates=13310, lr=2.37393e-05, gnorm=2.539, clip=100, loss_scale=128, train_wall=19, gb_free=11.2, wall=25001
2023-05-26 06:20:05 - progress_bar.py[line:272] - INFO: epoch 008:   1219 / 1732 loss=2.375, loss_v1=0, loss_v2=0, nll_loss=1.176, ntokens=1009.3, nsentences=32, sample_size=1009.3, sample_size_v1=0, sample_size_v2=0, ppl=2.26, wps=540.5, ups=0.54, wpb=1009.3, bsz=32, num_updates=13320, lr=2.37332e-05, gnorm=2.658, clip=100, loss_scale=128, train_wall=19, gb_free=11.3, wall=25020
2023-05-26 06:20:24 - progress_bar.py[line:272] - INFO: epoch 008:   1229 / 1732 loss=2.335, loss_v1=0, loss_v2=0, nll_loss=1.13, ntokens=1052.5, nsentences=32, sample_size=1052.5, sample_size_v1=0, sample_size_v2=0, ppl=2.19, wps=561.2, ups=0.53, wpb=1052.5, bsz=32, num_updates=13330, lr=2.3727e-05, gnorm=2.499, clip=100, loss_scale=128, train_wall=19, gb_free=11.1, wall=25039
2023-05-26 06:20:43 - progress_bar.py[line:272] - INFO: epoch 008:   1239 / 1732 loss=2.293, loss_v1=0, loss_v2=0, nll_loss=1.084, ntokens=1065.1, nsentences=32, sample_size=1065.1, sample_size_v1=0, sample_size_v2=0, ppl=2.12, wps=565.8, ups=0.53, wpb=1065.1, bsz=32, num_updates=13340, lr=2.37209e-05, gnorm=2.682, clip=100, loss_scale=128, train_wall=19, gb_free=10.7, wall=25058
2023-05-26 06:21:02 - progress_bar.py[line:272] - INFO: epoch 008:   1249 / 1732 loss=2.301, loss_v1=0, loss_v2=0, nll_loss=1.092, ntokens=1065.4, nsentences=32, sample_size=1065.4, sample_size_v1=0, sample_size_v2=0, ppl=2.13, wps=561.5, ups=0.53, wpb=1065.4, bsz=32, num_updates=13350, lr=2.37148e-05, gnorm=2.469, clip=100, loss_scale=128, train_wall=19, gb_free=11.5, wall=25077
2023-05-26 06:21:21 - progress_bar.py[line:272] - INFO: epoch 008:   1259 / 1732 loss=2.324, loss_v1=0, loss_v2=0, nll_loss=1.117, ntokens=1045.9, nsentences=32, sample_size=1045.9, sample_size_v1=0, sample_size_v2=0, ppl=2.17, wps=556.6, ups=0.53, wpb=1045.9, bsz=32, num_updates=13360, lr=2.37086e-05, gnorm=2.522, clip=100, loss_scale=128, train_wall=19, gb_free=11.5, wall=25095
2023-05-26 06:21:39 - progress_bar.py[line:272] - INFO: epoch 008:   1269 / 1732 loss=2.342, loss_v1=0, loss_v2=0, nll_loss=1.139, ntokens=1069.2, nsentences=32, sample_size=1069.2, sample_size_v1=0, sample_size_v2=0, ppl=2.2, wps=569.5, ups=0.53, wpb=1069.2, bsz=32, num_updates=13370, lr=2.37025e-05, gnorm=2.412, clip=100, loss_scale=128, train_wall=19, gb_free=11.4, wall=25114
2023-05-26 06:21:58 - progress_bar.py[line:272] - INFO: epoch 008:   1279 / 1732 loss=2.333, loss_v1=0, loss_v2=0, nll_loss=1.127, ntokens=1067, nsentences=32, sample_size=1067, sample_size_v1=0, sample_size_v2=0, ppl=2.18, wps=564.9, ups=0.53, wpb=1067, bsz=32, num_updates=13380, lr=2.36963e-05, gnorm=2.429, clip=100, loss_scale=128, train_wall=19, gb_free=10.9, wall=25133
2023-05-26 06:22:17 - progress_bar.py[line:272] - INFO: epoch 008:   1289 / 1732 loss=2.326, loss_v1=0, loss_v2=0, nll_loss=1.12, ntokens=1071, nsentences=32, sample_size=1071, sample_size_v1=0, sample_size_v2=0, ppl=2.17, wps=566, ups=0.53, wpb=1071, bsz=32, num_updates=13390, lr=2.36902e-05, gnorm=2.509, clip=100, loss_scale=128, train_wall=19, gb_free=10.4, wall=25152
2023-05-26 06:22:36 - progress_bar.py[line:272] - INFO: epoch 008:   1299 / 1732 loss=2.324, loss_v1=0, loss_v2=0, nll_loss=1.12, ntokens=1078.1, nsentences=32, sample_size=1078.1, sample_size_v1=0, sample_size_v2=0, ppl=2.17, wps=575.4, ups=0.53, wpb=1078.1, bsz=32, num_updates=13400, lr=2.3684e-05, gnorm=2.586, clip=100, loss_scale=128, train_wall=19, gb_free=11.4, wall=25171
2023-05-26 06:22:55 - progress_bar.py[line:272] - INFO: epoch 008:   1309 / 1732 loss=2.367, loss_v1=0, loss_v2=0, nll_loss=1.164, ntokens=1085.2, nsentences=32, sample_size=1085.2, sample_size_v1=0, sample_size_v2=0, ppl=2.24, wps=570.1, ups=0.53, wpb=1085.2, bsz=32, num_updates=13410, lr=2.36779e-05, gnorm=2.486, clip=100, loss_scale=128, train_wall=19, gb_free=10.9, wall=25190
2023-05-26 06:23:14 - progress_bar.py[line:272] - INFO: epoch 008:   1319 / 1732 loss=2.32, loss_v1=0, loss_v2=0, nll_loss=1.114, ntokens=1092.6, nsentences=32, sample_size=1092.6, sample_size_v1=0, sample_size_v2=0, ppl=2.17, wps=579, ups=0.53, wpb=1092.6, bsz=32, num_updates=13420, lr=2.36718e-05, gnorm=2.622, clip=100, loss_scale=128, train_wall=19, gb_free=10.9, wall=25209
2023-05-26 06:23:33 - progress_bar.py[line:272] - INFO: epoch 008:   1329 / 1732 loss=2.3, loss_v1=0, loss_v2=0, nll_loss=1.092, ntokens=1106.3, nsentences=32, sample_size=1106.3, sample_size_v1=0, sample_size_v2=0, ppl=2.13, wps=583.5, ups=0.53, wpb=1106.3, bsz=32, num_updates=13430, lr=2.36656e-05, gnorm=2.583, clip=100, loss_scale=128, train_wall=19, gb_free=11.3, wall=25228
2023-05-26 06:23:52 - progress_bar.py[line:272] - INFO: epoch 008:   1339 / 1732 loss=2.312, loss_v1=0, loss_v2=0, nll_loss=1.103, ntokens=1120.5, nsentences=32, sample_size=1120.5, sample_size_v1=0, sample_size_v2=0, ppl=2.15, wps=594.4, ups=0.53, wpb=1120.5, bsz=32, num_updates=13440, lr=2.36595e-05, gnorm=2.526, clip=100, loss_scale=128, train_wall=19, gb_free=11, wall=25246
2023-05-26 06:24:11 - progress_bar.py[line:272] - INFO: epoch 008:   1349 / 1732 loss=2.312, loss_v1=0, loss_v2=0, nll_loss=1.107, ntokens=1187.2, nsentences=32, sample_size=1187.2, sample_size_v1=0, sample_size_v2=0, ppl=2.15, wps=625.1, ups=0.53, wpb=1187.2, bsz=32, num_updates=13450, lr=2.36533e-05, gnorm=2.448, clip=100, loss_scale=128, train_wall=19, gb_free=11.3, wall=25265
2023-05-26 06:24:30 - progress_bar.py[line:272] - INFO: epoch 008:   1359 / 1732 loss=2.292, loss_v1=0, loss_v2=0, nll_loss=1.081, ntokens=1104.5, nsentences=32, sample_size=1104.5, sample_size_v1=0, sample_size_v2=0, ppl=2.11, wps=582.9, ups=0.53, wpb=1104.5, bsz=32, num_updates=13460, lr=2.36472e-05, gnorm=2.502, clip=100, loss_scale=128, train_wall=19, gb_free=11.2, wall=25284
2023-05-26 06:24:49 - progress_bar.py[line:272] - INFO: epoch 008:   1369 / 1732 loss=2.346, loss_v1=0, loss_v2=0, nll_loss=1.143, ntokens=1096, nsentences=32, sample_size=1096, sample_size_v1=0, sample_size_v2=0, ppl=2.21, wps=579.8, ups=0.53, wpb=1096, bsz=32, num_updates=13470, lr=2.36411e-05, gnorm=2.582, clip=100, loss_scale=128, train_wall=19, gb_free=11.2, wall=25303
2023-05-26 06:25:07 - progress_bar.py[line:272] - INFO: epoch 008:   1379 / 1732 loss=2.344, loss_v1=0, loss_v2=0, nll_loss=1.139, ntokens=1115.7, nsentences=32, sample_size=1115.7, sample_size_v1=0, sample_size_v2=0, ppl=2.2, wps=594.9, ups=0.53, wpb=1115.7, bsz=32, num_updates=13480, lr=2.36349e-05, gnorm=2.678, clip=100, loss_scale=128, train_wall=19, gb_free=11.4, wall=25322
2023-05-26 06:25:26 - progress_bar.py[line:272] - INFO: epoch 008:   1389 / 1732 loss=2.326, loss_v1=0, loss_v2=0, nll_loss=1.12, ntokens=1122.1, nsentences=32, sample_size=1122.1, sample_size_v1=0, sample_size_v2=0, ppl=2.17, wps=597.9, ups=0.53, wpb=1122.1, bsz=32, num_updates=13490, lr=2.36288e-05, gnorm=2.635, clip=100, loss_scale=128, train_wall=19, gb_free=11.5, wall=25341
2023-05-26 06:25:45 - progress_bar.py[line:272] - INFO: epoch 008:   1399 / 1732 loss=2.302, loss_v1=0, loss_v2=0, nll_loss=1.094, ntokens=1113, nsentences=32, sample_size=1113, sample_size_v1=0, sample_size_v2=0, ppl=2.13, wps=589.7, ups=0.53, wpb=1113, bsz=32, num_updates=13500, lr=2.36226e-05, gnorm=2.61, clip=100, loss_scale=128, train_wall=19, gb_free=11.1, wall=25360
2023-05-26 06:26:04 - progress_bar.py[line:272] - INFO: epoch 008:   1409 / 1732 loss=2.344, loss_v1=0, loss_v2=0, nll_loss=1.14, ntokens=1156.6, nsentences=32, sample_size=1156.6, sample_size_v1=0, sample_size_v2=0, ppl=2.2, wps=613.3, ups=0.53, wpb=1156.6, bsz=32, num_updates=13510, lr=2.36165e-05, gnorm=2.501, clip=100, loss_scale=128, train_wall=19, gb_free=11.1, wall=25379
2023-05-26 06:26:23 - progress_bar.py[line:272] - INFO: epoch 008:   1419 / 1732 loss=2.341, loss_v1=0, loss_v2=0, nll_loss=1.137, ntokens=1290.6, nsentences=32, sample_size=1290.6, sample_size_v1=0, sample_size_v2=0, ppl=2.2, wps=676, ups=0.52, wpb=1290.6, bsz=32, num_updates=13520, lr=2.36103e-05, gnorm=2.475, clip=100, loss_scale=128, train_wall=19, gb_free=10.5, wall=25398
2023-05-26 06:26:42 - progress_bar.py[line:272] - INFO: epoch 008:   1429 / 1732 loss=2.301, loss_v1=0, loss_v2=0, nll_loss=1.093, ntokens=1226.2, nsentences=32, sample_size=1226.2, sample_size_v1=0, sample_size_v2=0, ppl=2.13, wps=647, ups=0.53, wpb=1226.2, bsz=32, num_updates=13530, lr=2.36042e-05, gnorm=2.263, clip=100, loss_scale=128, train_wall=19, gb_free=11.2, wall=25417
2023-05-26 06:27:01 - progress_bar.py[line:272] - INFO: epoch 008:   1439 / 1732 loss=2.306, loss_v1=0, loss_v2=0, nll_loss=1.099, ntokens=1192.7, nsentences=32, sample_size=1192.7, sample_size_v1=0, sample_size_v2=0, ppl=2.14, wps=630.1, ups=0.53, wpb=1192.7, bsz=32, num_updates=13540, lr=2.35981e-05, gnorm=2.265, clip=100, loss_scale=128, train_wall=19, gb_free=11, wall=25436
2023-05-26 06:27:20 - progress_bar.py[line:272] - INFO: epoch 008:   1449 / 1732 loss=2.334, loss_v1=0, loss_v2=0, nll_loss=1.128, ntokens=1089.5, nsentences=32, sample_size=1089.5, sample_size_v1=0, sample_size_v2=0, ppl=2.19, wps=579.4, ups=0.53, wpb=1089.5, bsz=32, num_updates=13550, lr=2.35919e-05, gnorm=2.455, clip=100, loss_scale=128, train_wall=19, gb_free=11.4, wall=25454
2023-05-26 06:27:39 - progress_bar.py[line:272] - INFO: epoch 008:   1459 / 1732 loss=2.304, loss_v1=0, loss_v2=0, nll_loss=1.096, ntokens=1160, nsentences=32, sample_size=1160, sample_size_v1=0, sample_size_v2=0, ppl=2.14, wps=612.7, ups=0.53, wpb=1160, bsz=32, num_updates=13560, lr=2.35858e-05, gnorm=2.331, clip=100, loss_scale=128, train_wall=19, gb_free=11.1, wall=25473
2023-05-26 06:27:58 - progress_bar.py[line:272] - INFO: epoch 008:   1469 / 1732 loss=2.316, loss_v1=0, loss_v2=0, nll_loss=1.109, ntokens=1187.1, nsentences=32, sample_size=1187.1, sample_size_v1=0, sample_size_v2=0, ppl=2.16, wps=625.7, ups=0.53, wpb=1187.1, bsz=32, num_updates=13570, lr=2.35796e-05, gnorm=2.442, clip=100, loss_scale=128, train_wall=19, gb_free=11.3, wall=25492
2023-05-26 06:28:16 - progress_bar.py[line:272] - INFO: epoch 008:   1479 / 1732 loss=2.339, loss_v1=0, loss_v2=0, nll_loss=1.135, ntokens=1029.5, nsentences=32, sample_size=1029.5, sample_size_v1=0, sample_size_v2=0, ppl=2.2, wps=548.7, ups=0.53, wpb=1029.5, bsz=32, num_updates=13580, lr=2.35735e-05, gnorm=2.711, clip=100, loss_scale=128, train_wall=19, gb_free=11.1, wall=25511
2023-05-26 06:28:35 - progress_bar.py[line:272] - INFO: epoch 008:   1489 / 1732 loss=2.337, loss_v1=0, loss_v2=0, nll_loss=1.132, ntokens=1147, nsentences=32, sample_size=1147, sample_size_v1=0, sample_size_v2=0, ppl=2.19, wps=607.5, ups=0.53, wpb=1147, bsz=32, num_updates=13590, lr=2.35673e-05, gnorm=2.493, clip=100, loss_scale=128, train_wall=19, gb_free=11.3, wall=25530
2023-05-26 06:28:54 - progress_bar.py[line:272] - INFO: epoch 008:   1499 / 1732 loss=2.306, loss_v1=0, loss_v2=0, nll_loss=1.098, ntokens=1095.4, nsentences=32, sample_size=1095.4, sample_size_v1=0, sample_size_v2=0, ppl=2.14, wps=581.4, ups=0.53, wpb=1095.4, bsz=32, num_updates=13600, lr=2.35612e-05, gnorm=2.455, clip=100, loss_scale=128, train_wall=19, gb_free=10.8, wall=25549
2023-05-26 06:29:13 - progress_bar.py[line:272] - INFO: epoch 008:   1509 / 1732 loss=2.278, loss_v1=0, loss_v2=0, nll_loss=1.068, ntokens=1114.3, nsentences=32, sample_size=1114.3, sample_size_v1=0, sample_size_v2=0, ppl=2.1, wps=592.9, ups=0.53, wpb=1114.3, bsz=32, num_updates=13610, lr=2.35551e-05, gnorm=2.333, clip=100, loss_scale=128, train_wall=19, gb_free=11.4, wall=25568
2023-05-26 06:29:32 - progress_bar.py[line:272] - INFO: epoch 008:   1519 / 1732 loss=2.346, loss_v1=0, loss_v2=0, nll_loss=1.141, ntokens=1050.9, nsentences=32, sample_size=1050.9, sample_size_v1=0, sample_size_v2=0, ppl=2.2, wps=560, ups=0.53, wpb=1050.9, bsz=32, num_updates=13620, lr=2.35489e-05, gnorm=2.575, clip=100, loss_scale=128, train_wall=19, gb_free=11.4, wall=25586
2023-05-26 06:29:50 - progress_bar.py[line:272] - INFO: epoch 008:   1529 / 1732 loss=2.356, loss_v1=0, loss_v2=0, nll_loss=1.155, ntokens=1056.3, nsentences=32, sample_size=1056.3, sample_size_v1=0, sample_size_v2=0, ppl=2.23, wps=561.4, ups=0.53, wpb=1056.3, bsz=32, num_updates=13630, lr=2.35428e-05, gnorm=2.619, clip=100, loss_scale=128, train_wall=19, gb_free=10.8, wall=25605
2023-05-26 06:30:09 - progress_bar.py[line:272] - INFO: epoch 008:   1539 / 1732 loss=2.326, loss_v1=0, loss_v2=0, nll_loss=1.115, ntokens=1083.3, nsentences=32, sample_size=1083.3, sample_size_v1=0, sample_size_v2=0, ppl=2.17, wps=571.2, ups=0.53, wpb=1083.3, bsz=32, num_updates=13640, lr=2.35366e-05, gnorm=2.424, clip=100, loss_scale=128, train_wall=19, gb_free=11, wall=25624
2023-05-26 06:30:28 - progress_bar.py[line:272] - INFO: epoch 008:   1549 / 1732 loss=2.291, loss_v1=0, loss_v2=0, nll_loss=1.084, ntokens=1075, nsentences=32, sample_size=1075, sample_size_v1=0, sample_size_v2=0, ppl=2.12, wps=572.8, ups=0.53, wpb=1075, bsz=32, num_updates=13650, lr=2.35305e-05, gnorm=2.416, clip=100, loss_scale=128, train_wall=19, gb_free=11.4, wall=25643
2023-05-26 06:30:47 - progress_bar.py[line:272] - INFO: epoch 008:   1559 / 1732 loss=2.315, loss_v1=0, loss_v2=0, nll_loss=1.108, ntokens=1092, nsentences=32, sample_size=1092, sample_size_v1=0, sample_size_v2=0, ppl=2.16, wps=580.7, ups=0.53, wpb=1092, bsz=32, num_updates=13660, lr=2.35244e-05, gnorm=2.373, clip=100, loss_scale=128, train_wall=19, gb_free=11.3, wall=25662
2023-05-26 06:31:06 - progress_bar.py[line:272] - INFO: epoch 008:   1569 / 1732 loss=2.35, loss_v1=0, loss_v2=0, nll_loss=1.147, ntokens=1059.1, nsentences=32, sample_size=1059.1, sample_size_v1=0, sample_size_v2=0, ppl=2.21, wps=561.4, ups=0.53, wpb=1059.1, bsz=32, num_updates=13670, lr=2.35182e-05, gnorm=2.576, clip=100, loss_scale=128, train_wall=19, gb_free=10.7, wall=25681
2023-05-26 06:31:25 - progress_bar.py[line:272] - INFO: epoch 008:   1579 / 1732 loss=2.347, loss_v1=0, loss_v2=0, nll_loss=1.144, ntokens=1008.7, nsentences=32, sample_size=1008.7, sample_size_v1=0, sample_size_v2=0, ppl=2.21, wps=537.5, ups=0.53, wpb=1008.7, bsz=32, num_updates=13680, lr=2.35121e-05, gnorm=2.766, clip=100, loss_scale=128, train_wall=19, gb_free=11.2, wall=25699
2023-05-26 06:31:44 - progress_bar.py[line:272] - INFO: epoch 008:   1589 / 1732 loss=2.338, loss_v1=0, loss_v2=0, nll_loss=1.135, ntokens=1092.2, nsentences=32, sample_size=1092.2, sample_size_v1=0, sample_size_v2=0, ppl=2.2, wps=577.1, ups=0.53, wpb=1092.2, bsz=32, num_updates=13690, lr=2.35059e-05, gnorm=2.314, clip=100, loss_scale=128, train_wall=19, gb_free=11.4, wall=25718
2023-05-26 06:32:02 - progress_bar.py[line:272] - INFO: epoch 008:   1599 / 1732 loss=2.302, loss_v1=0, loss_v2=0, nll_loss=1.093, ntokens=1061.1, nsentences=32, sample_size=1061.1, sample_size_v1=0, sample_size_v2=0, ppl=2.13, wps=565, ups=0.53, wpb=1061.1, bsz=32, num_updates=13700, lr=2.34998e-05, gnorm=2.436, clip=100, loss_scale=128, train_wall=19, gb_free=11.3, wall=25737
2023-05-26 06:32:21 - progress_bar.py[line:272] - INFO: epoch 008:   1609 / 1732 loss=2.295, loss_v1=0, loss_v2=0, nll_loss=1.084, ntokens=1155.5, nsentences=32, sample_size=1155.5, sample_size_v1=0, sample_size_v2=0, ppl=2.12, wps=609.1, ups=0.53, wpb=1155.5, bsz=32, num_updates=13710, lr=2.34936e-05, gnorm=2.477, clip=100, loss_scale=128, train_wall=19, gb_free=10.9, wall=25756
2023-05-26 06:32:40 - progress_bar.py[line:272] - INFO: epoch 008:   1619 / 1732 loss=2.282, loss_v1=0, loss_v2=0, nll_loss=1.072, ntokens=1123.8, nsentences=32, sample_size=1123.8, sample_size_v1=0, sample_size_v2=0, ppl=2.1, wps=594.2, ups=0.53, wpb=1123.8, bsz=32, num_updates=13720, lr=2.34875e-05, gnorm=2.564, clip=100, loss_scale=128, train_wall=19, gb_free=10.9, wall=25775
2023-05-26 06:32:59 - progress_bar.py[line:272] - INFO: epoch 008:   1629 / 1732 loss=2.314, loss_v1=0, loss_v2=0, nll_loss=1.106, ntokens=1172.3, nsentences=32, sample_size=1172.3, sample_size_v1=0, sample_size_v2=0, ppl=2.15, wps=616.6, ups=0.53, wpb=1172.3, bsz=32, num_updates=13730, lr=2.34814e-05, gnorm=2.601, clip=100, loss_scale=128, train_wall=19, gb_free=11.2, wall=25794
2023-05-26 06:33:18 - progress_bar.py[line:272] - INFO: epoch 008:   1639 / 1732 loss=2.288, loss_v1=0, loss_v2=0, nll_loss=1.077, ntokens=1139.8, nsentences=32, sample_size=1139.8, sample_size_v1=0, sample_size_v2=0, ppl=2.11, wps=608.1, ups=0.53, wpb=1139.8, bsz=32, num_updates=13740, lr=2.34752e-05, gnorm=2.4, clip=100, loss_scale=128, train_wall=19, gb_free=10.8, wall=25813
2023-05-26 06:33:37 - progress_bar.py[line:272] - INFO: epoch 008:   1649 / 1732 loss=2.289, loss_v1=0, loss_v2=0, nll_loss=1.08, ntokens=1200.9, nsentences=32, sample_size=1200.9, sample_size_v1=0, sample_size_v2=0, ppl=2.11, wps=632.2, ups=0.53, wpb=1200.9, bsz=32, num_updates=13750, lr=2.34691e-05, gnorm=2.328, clip=100, loss_scale=128, train_wall=19, gb_free=11.3, wall=25832
2023-05-26 06:33:56 - progress_bar.py[line:272] - INFO: epoch 008:   1659 / 1732 loss=2.352, loss_v1=0, loss_v2=0, nll_loss=1.149, ntokens=965.2, nsentences=32, sample_size=965.2, sample_size_v1=0, sample_size_v2=0, ppl=2.22, wps=516.1, ups=0.53, wpb=965.2, bsz=32, num_updates=13760, lr=2.34629e-05, gnorm=2.757, clip=100, loss_scale=128, train_wall=19, gb_free=11.1, wall=25850
2023-05-26 06:34:14 - progress_bar.py[line:272] - INFO: epoch 008:   1669 / 1732 loss=2.316, loss_v1=0, loss_v2=0, nll_loss=1.108, ntokens=1018.2, nsentences=32, sample_size=1018.2, sample_size_v1=0, sample_size_v2=0, ppl=2.15, wps=542.9, ups=0.53, wpb=1018.2, bsz=32, num_updates=13770, lr=2.34568e-05, gnorm=2.591, clip=100, loss_scale=128, train_wall=19, gb_free=11.8, wall=25869
2023-05-26 06:34:34 - progress_bar.py[line:272] - INFO: epoch 008:   1679 / 1732 loss=2.274, loss_v1=0, loss_v2=0, nll_loss=1.063, ntokens=1155.9, nsentences=32, sample_size=1155.9, sample_size_v1=0, sample_size_v2=0, ppl=2.09, wps=607.5, ups=0.53, wpb=1155.9, bsz=32, num_updates=13780, lr=2.34506e-05, gnorm=2.482, clip=100, loss_scale=256, train_wall=19, gb_free=10.8, wall=25888
2023-05-26 06:34:53 - progress_bar.py[line:272] - INFO: epoch 008:   1689 / 1732 loss=2.306, loss_v1=0, loss_v2=0, nll_loss=1.1, ntokens=1198.6, nsentences=32, sample_size=1198.6, sample_size_v1=0, sample_size_v2=0, ppl=2.14, wps=629.6, ups=0.53, wpb=1198.6, bsz=32, num_updates=13790, lr=2.34445e-05, gnorm=2.237, clip=100, loss_scale=256, train_wall=19, gb_free=10.4, wall=25907
2023-05-26 06:35:12 - progress_bar.py[line:272] - INFO: epoch 008:   1699 / 1732 loss=2.285, loss_v1=0, loss_v2=0, nll_loss=1.073, ntokens=1300, nsentences=32, sample_size=1300, sample_size_v1=0, sample_size_v2=0, ppl=2.1, wps=676.9, ups=0.52, wpb=1300, bsz=32, num_updates=13800, lr=2.34384e-05, gnorm=1.992, clip=100, loss_scale=256, train_wall=19, gb_free=11.1, wall=25926
2023-05-26 06:35:31 - progress_bar.py[line:272] - INFO: epoch 008:   1709 / 1732 loss=2.33, loss_v1=0, loss_v2=0, nll_loss=1.125, ntokens=1178.3, nsentences=32, sample_size=1178.3, sample_size_v1=0, sample_size_v2=0, ppl=2.18, wps=623.3, ups=0.53, wpb=1178.3, bsz=32, num_updates=13810, lr=2.34322e-05, gnorm=2.342, clip=100, loss_scale=256, train_wall=19, gb_free=11.3, wall=25945
2023-05-26 06:35:50 - progress_bar.py[line:272] - INFO: epoch 008:   1719 / 1732 loss=2.287, loss_v1=0, loss_v2=0, nll_loss=1.077, ntokens=1171.3, nsentences=32, sample_size=1171.3, sample_size_v1=0, sample_size_v2=0, ppl=2.11, wps=614, ups=0.52, wpb=1171.3, bsz=32, num_updates=13820, lr=2.34261e-05, gnorm=2.245, clip=100, loss_scale=256, train_wall=19, gb_free=10.9, wall=25964
2023-05-26 06:36:09 - progress_bar.py[line:272] - INFO: epoch 008:   1729 / 1732 loss=2.341, loss_v1=0, loss_v2=0, nll_loss=1.136, ntokens=1095.7, nsentences=32, sample_size=1095.7, sample_size_v1=0, sample_size_v2=0, ppl=2.2, wps=579.8, ups=0.53, wpb=1095.7, bsz=32, num_updates=13830, lr=2.34199e-05, gnorm=2.309, clip=100, loss_scale=256, train_wall=19, gb_free=10.8, wall=25983
2023-05-26 06:36:13 - checkpoint_utils.py[line:64] - INFO: Preparing to save checkpoint for epoch 8 @ 13833 updates
2023-05-26 06:36:13 - trainer.py[line:431] - INFO: Saving checkpoint to ../../checkpoints/OFA/sgcls_checkpoints/_30_3e-5_512_base_nosrcbbox/checkpoint8.pt
2023-05-26 06:36:16 - trainer.py[line:441] - INFO: Finished saving checkpoint to ../../checkpoints/OFA/sgcls_checkpoints/_30_3e-5_512_base_nosrcbbox/checkpoint8.pt
2023-05-26 06:36:20 - checkpoint_utils.py[line:133] - INFO: Saved checkpoint ../../checkpoints/OFA/sgcls_checkpoints/_30_3e-5_512_base_nosrcbbox/checkpoint8.pt (epoch 8 @ 13833 updates, score None) (writing took 7.516371141187847 seconds)
2023-05-26 06:36:20 - train.py[line:332] - INFO: end of epoch 8 (average epoch stats below)
2023-05-26 06:36:20 - progress_bar.py[line:282] - INFO: epoch 008 | loss 2.329 | loss_v1 0 | loss_v2 0 | nll_loss 1.124 | ntokens 1051.8 | nsentences 31.986 | sample_size 1051.8 | sample_size_v1 0 | sample_size_v2 0 | ppl 2.18 | wps 558.5 | ups 0.53 | wpb 1051.8 | bsz 32 | num_updates 13833 | lr 2.34181e-05 | gnorm 2.493 | clip 99.9 | loss_scale 256 | train_wall 3239 | gb_free 11.7 | wall 25995
2023-05-26 06:36:20 - trainer.py[line:639] - INFO: loading train data for epoch 9
local datafile ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 0 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 0 finished initializing row_count and line_idx-to-offset mapping
file ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 0 row count 55400 total row count 55400
slice_id 0 seek offset 0
2023-05-26 06:36:22 - trainer.py[line:703] - INFO: begin training epoch 9
2023-05-26 06:36:22 - train.py[line:305] - INFO: Start iterating over samples
2023-05-26 06:36:36 - progress_bar.py[line:272] - INFO: epoch 009:      7 / 1732 loss=2.28, loss_v1=0, loss_v2=0, nll_loss=1.068, ntokens=1093.3, nsentences=29.6, sample_size=1093.3, sample_size_v1=0, sample_size_v2=0, ppl=2.1, wps=402, ups=0.37, wpb=1093.3, bsz=29.6, num_updates=13840, lr=2.34138e-05, gnorm=2.525, clip=100, loss_scale=256, train_wall=18, gb_free=11.2, wall=26011
2023-05-26 06:36:55 - progress_bar.py[line:272] - INFO: epoch 009:     17 / 1732 loss=2.245, loss_v1=0, loss_v2=0, nll_loss=1.031, ntokens=1095.7, nsentences=32, sample_size=1095.7, sample_size_v1=0, sample_size_v2=0, ppl=2.04, wps=579.9, ups=0.53, wpb=1095.7, bsz=32, num_updates=13850, lr=2.34077e-05, gnorm=2.309, clip=100, loss_scale=256, train_wall=19, gb_free=11, wall=26029
2023-05-26 06:37:14 - progress_bar.py[line:272] - INFO: epoch 009:     27 / 1732 loss=2.287, loss_v1=0, loss_v2=0, nll_loss=1.077, ntokens=954.5, nsentences=32, sample_size=954.5, sample_size_v1=0, sample_size_v2=0, ppl=2.11, wps=507.4, ups=0.53, wpb=954.5, bsz=32, num_updates=13860, lr=2.34015e-05, gnorm=2.436, clip=100, loss_scale=256, train_wall=19, gb_free=10.7, wall=26048
2023-05-26 06:37:33 - progress_bar.py[line:272] - INFO: epoch 009:     37 / 1732 loss=2.131, loss_v1=0, loss_v2=0, nll_loss=0.905, ntokens=1179.3, nsentences=32, sample_size=1179.3, sample_size_v1=0, sample_size_v2=0, ppl=1.87, wps=618.9, ups=0.52, wpb=1179.3, bsz=32, num_updates=13870, lr=2.33954e-05, gnorm=1.946, clip=100, loss_scale=256, train_wall=19, gb_free=10.9, wall=26067
2023-05-26 06:37:51 - progress_bar.py[line:272] - INFO: epoch 009:     47 / 1732 loss=2.164, loss_v1=0, loss_v2=0, nll_loss=0.936, ntokens=1055.1, nsentences=32, sample_size=1055.1, sample_size_v1=0, sample_size_v2=0, ppl=1.91, wps=559.9, ups=0.53, wpb=1055.1, bsz=32, num_updates=13880, lr=2.33892e-05, gnorm=2.239, clip=90, loss_scale=256, train_wall=19, gb_free=10.8, wall=26086
2023-05-26 06:38:10 - progress_bar.py[line:272] - INFO: epoch 009:     57 / 1732 loss=2.087, loss_v1=0, loss_v2=0, nll_loss=0.861, ntokens=1048.7, nsentences=32, sample_size=1048.7, sample_size_v1=0, sample_size_v2=0, ppl=1.82, wps=557.8, ups=0.53, wpb=1048.7, bsz=32, num_updates=13890, lr=2.33831e-05, gnorm=2.354, clip=100, loss_scale=256, train_wall=19, gb_free=11.2, wall=26105
2023-05-26 06:38:30 - progress_bar.py[line:272] - INFO: epoch 009:     67 / 1732 loss=1.993, loss_v1=0, loss_v2=0, nll_loss=0.748, ntokens=1356.1, nsentences=32, sample_size=1356.1, sample_size_v1=0, sample_size_v2=0, ppl=1.68, wps=700.6, ups=0.52, wpb=1356.1, bsz=32, num_updates=13900, lr=2.33769e-05, gnorm=1.441, clip=100, loss_scale=256, train_wall=19, gb_free=10.3, wall=26124
2023-05-26 06:38:49 - progress_bar.py[line:272] - INFO: epoch 009:     77 / 1732 loss=2.105, loss_v1=0, loss_v2=0, nll_loss=0.87, ntokens=1273.9, nsentences=32, sample_size=1273.9, sample_size_v1=0, sample_size_v2=0, ppl=1.83, wps=657.1, ups=0.52, wpb=1273.9, bsz=32, num_updates=13910, lr=2.33708e-05, gnorm=1.955, clip=100, loss_scale=256, train_wall=19, gb_free=11.1, wall=26144
2023-05-26 06:39:08 - progress_bar.py[line:272] - INFO: epoch 009:     87 / 1732 loss=2.182, loss_v1=0, loss_v2=0, nll_loss=0.963, ntokens=1141.2, nsentences=32, sample_size=1141.2, sample_size_v1=0, sample_size_v2=0, ppl=1.95, wps=593.9, ups=0.52, wpb=1141.2, bsz=32, num_updates=13920, lr=2.33647e-05, gnorm=2.088, clip=100, loss_scale=256, train_wall=19, gb_free=10.6, wall=26163
2023-05-26 06:39:27 - progress_bar.py[line:272] - INFO: epoch 009:     97 / 1732 loss=2.139, loss_v1=0, loss_v2=0, nll_loss=0.91, ntokens=1080.1, nsentences=32, sample_size=1080.1, sample_size_v1=0, sample_size_v2=0, ppl=1.88, wps=569.7, ups=0.53, wpb=1080.1, bsz=32, num_updates=13930, lr=2.33585e-05, gnorm=2.088, clip=100, loss_scale=256, train_wall=19, gb_free=10.1, wall=26182
2023-05-26 06:39:46 - progress_bar.py[line:272] - INFO: epoch 009:    107 / 1732 loss=2.301, loss_v1=0, loss_v2=0, nll_loss=1.096, ntokens=981.4, nsentences=32, sample_size=981.4, sample_size_v1=0, sample_size_v2=0, ppl=2.14, wps=523.8, ups=0.53, wpb=981.4, bsz=32, num_updates=13940, lr=2.33524e-05, gnorm=2.506, clip=100, loss_scale=256, train_wall=19, gb_free=11, wall=26201
2023-05-26 06:40:05 - progress_bar.py[line:272] - INFO: epoch 009:    117 / 1732 loss=2.348, loss_v1=0, loss_v2=0, nll_loss=1.143, ntokens=1060.7, nsentences=32, sample_size=1060.7, sample_size_v1=0, sample_size_v2=0, ppl=2.21, wps=559.4, ups=0.53, wpb=1060.7, bsz=32, num_updates=13950, lr=2.33462e-05, gnorm=2.566, clip=100, loss_scale=256, train_wall=19, gb_free=10.6, wall=26220
2023-05-26 06:40:24 - progress_bar.py[line:272] - INFO: epoch 009:    127 / 1732 loss=2.287, loss_v1=0, loss_v2=0, nll_loss=1.077, ntokens=1185.5, nsentences=32, sample_size=1185.5, sample_size_v1=0, sample_size_v2=0, ppl=2.11, wps=616.3, ups=0.52, wpb=1185.5, bsz=32, num_updates=13960, lr=2.33401e-05, gnorm=2.321, clip=100, loss_scale=256, train_wall=19, gb_free=11.1, wall=26239
2023-05-26 06:40:43 - progress_bar.py[line:272] - INFO: epoch 009:    137 / 1732 loss=2.255, loss_v1=0, loss_v2=0, nll_loss=1.041, ntokens=1222.2, nsentences=32, sample_size=1222.2, sample_size_v1=0, sample_size_v2=0, ppl=2.06, wps=640.6, ups=0.52, wpb=1222.2, bsz=32, num_updates=13970, lr=2.33339e-05, gnorm=2.154, clip=100, loss_scale=256, train_wall=19, gb_free=11, wall=26258
2023-05-26 06:41:03 - progress_bar.py[line:272] - INFO: epoch 009:    147 / 1732 loss=2.211, loss_v1=0, loss_v2=0, nll_loss=0.992, ntokens=1207.1, nsentences=32, sample_size=1207.1, sample_size_v1=0, sample_size_v2=0, ppl=1.99, wps=625.8, ups=0.52, wpb=1207.1, bsz=32, num_updates=13980, lr=2.33278e-05, gnorm=2.085, clip=100, loss_scale=256, train_wall=19, gb_free=10.9, wall=26277
2023-05-26 06:41:22 - progress_bar.py[line:272] - INFO: epoch 009:    157 / 1732 loss=2.263, loss_v1=0, loss_v2=0, nll_loss=1.05, ntokens=1172.8, nsentences=32, sample_size=1172.8, sample_size_v1=0, sample_size_v2=0, ppl=2.07, wps=608.6, ups=0.52, wpb=1172.8, bsz=32, num_updates=13990, lr=2.33217e-05, gnorm=2.04, clip=100, loss_scale=256, train_wall=19, gb_free=11.1, wall=26296
2023-05-26 06:41:41 - progress_bar.py[line:272] - INFO: epoch 009:    167 / 1732 loss=2.231, loss_v1=0, loss_v2=0, nll_loss=1.016, ntokens=1009.5, nsentences=32, sample_size=1009.5, sample_size_v1=0, sample_size_v2=0, ppl=2.02, wps=534.2, ups=0.53, wpb=1009.5, bsz=32, num_updates=14000, lr=2.33155e-05, gnorm=2.438, clip=100, loss_scale=256, train_wall=19, gb_free=10.3, wall=26315
2023-05-26 06:42:00 - progress_bar.py[line:272] - INFO: epoch 009:    177 / 1732 loss=2.245, loss_v1=0, loss_v2=0, nll_loss=1.029, ntokens=994.5, nsentences=32, sample_size=994.5, sample_size_v1=0, sample_size_v2=0, ppl=2.04, wps=528.4, ups=0.53, wpb=994.5, bsz=32, num_updates=14010, lr=2.33094e-05, gnorm=2.474, clip=100, loss_scale=256, train_wall=19, gb_free=10.8, wall=26334
2023-05-26 06:42:19 - progress_bar.py[line:272] - INFO: epoch 009:    187 / 1732 loss=2.187, loss_v1=0, loss_v2=0, nll_loss=0.966, ntokens=1141.8, nsentences=32, sample_size=1141.8, sample_size_v1=0, sample_size_v2=0, ppl=1.95, wps=596.4, ups=0.52, wpb=1141.8, bsz=32, num_updates=14020, lr=2.33032e-05, gnorm=2.127, clip=100, loss_scale=256, train_wall=19, gb_free=10.5, wall=26353
2023-05-26 06:42:38 - progress_bar.py[line:272] - INFO: epoch 009:    197 / 1732 loss=2.249, loss_v1=0, loss_v2=0, nll_loss=1.035, ntokens=1173.2, nsentences=32, sample_size=1173.2, sample_size_v1=0, sample_size_v2=0, ppl=2.05, wps=617.8, ups=0.53, wpb=1173.2, bsz=32, num_updates=14030, lr=2.32971e-05, gnorm=2.225, clip=100, loss_scale=256, train_wall=19, gb_free=11.4, wall=26372
2023-05-26 06:42:56 - progress_bar.py[line:272] - INFO: epoch 009:    207 / 1732 loss=2.345, loss_v1=0, loss_v2=0, nll_loss=1.142, ntokens=957.1, nsentences=32, sample_size=957.1, sample_size_v1=0, sample_size_v2=0, ppl=2.21, wps=514.3, ups=0.54, wpb=957.1, bsz=32, num_updates=14040, lr=2.3291e-05, gnorm=2.727, clip=100, loss_scale=256, train_wall=19, gb_free=10.7, wall=26391
2023-05-26 06:43:15 - progress_bar.py[line:272] - INFO: epoch 009:    217 / 1732 loss=2.349, loss_v1=0, loss_v2=0, nll_loss=1.144, ntokens=1157.1, nsentences=32, sample_size=1157.1, sample_size_v1=0, sample_size_v2=0, ppl=2.21, wps=617, ups=0.53, wpb=1157.1, bsz=32, num_updates=14050, lr=2.32848e-05, gnorm=2.333, clip=100, loss_scale=256, train_wall=19, gb_free=11.2, wall=26410
2023-05-26 06:43:34 - progress_bar.py[line:272] - INFO: epoch 009:    227 / 1732 loss=2.34, loss_v1=0, loss_v2=0, nll_loss=1.137, ntokens=1106.8, nsentences=32, sample_size=1106.8, sample_size_v1=0, sample_size_v2=0, ppl=2.2, wps=590.9, ups=0.53, wpb=1106.8, bsz=32, num_updates=14060, lr=2.32787e-05, gnorm=2.48, clip=100, loss_scale=256, train_wall=19, gb_free=10.9, wall=26428
2023-05-26 06:43:52 - progress_bar.py[line:272] - INFO: epoch 009:    237 / 1732 loss=2.393, loss_v1=0, loss_v2=0, nll_loss=1.194, ntokens=1060.1, nsentences=32, sample_size=1060.1, sample_size_v1=0, sample_size_v2=0, ppl=2.29, wps=567.2, ups=0.54, wpb=1060.1, bsz=32, num_updates=14070, lr=2.32725e-05, gnorm=2.487, clip=100, loss_scale=256, train_wall=19, gb_free=10.7, wall=26447
2023-05-26 06:44:11 - progress_bar.py[line:272] - INFO: epoch 009:    247 / 1732 loss=2.351, loss_v1=0, loss_v2=0, nll_loss=1.151, ntokens=1188.4, nsentences=32, sample_size=1188.4, sample_size_v1=0, sample_size_v2=0, ppl=2.22, wps=631.3, ups=0.53, wpb=1188.4, bsz=32, num_updates=14080, lr=2.32664e-05, gnorm=2.141, clip=100, loss_scale=256, train_wall=19, gb_free=10.9, wall=26466
2023-05-26 06:44:30 - progress_bar.py[line:272] - INFO: epoch 009:    257 / 1732 loss=2.352, loss_v1=0, loss_v2=0, nll_loss=1.149, ntokens=1118.5, nsentences=32, sample_size=1118.5, sample_size_v1=0, sample_size_v2=0, ppl=2.22, wps=596.1, ups=0.53, wpb=1118.5, bsz=32, num_updates=14090, lr=2.32602e-05, gnorm=2.3, clip=100, loss_scale=256, train_wall=19, gb_free=11.2, wall=26485
2023-05-26 06:44:49 - progress_bar.py[line:272] - INFO: epoch 009:    267 / 1732 loss=2.343, loss_v1=0, loss_v2=0, nll_loss=1.139, ntokens=1162.2, nsentences=32, sample_size=1162.2, sample_size_v1=0, sample_size_v2=0, ppl=2.2, wps=618.7, ups=0.53, wpb=1162.2, bsz=32, num_updates=14100, lr=2.32541e-05, gnorm=2.185, clip=100, loss_scale=256, train_wall=19, gb_free=11.2, wall=26504
2023-05-26 06:45:08 - progress_bar.py[line:272] - INFO: epoch 009:    277 / 1732 loss=2.357, loss_v1=0, loss_v2=0, nll_loss=1.155, ntokens=1137.3, nsentences=32, sample_size=1137.3, sample_size_v1=0, sample_size_v2=0, ppl=2.23, wps=603.6, ups=0.53, wpb=1137.3, bsz=32, num_updates=14110, lr=2.3248e-05, gnorm=2.267, clip=100, loss_scale=256, train_wall=19, gb_free=11.3, wall=26522
2023-05-26 06:45:27 - progress_bar.py[line:272] - INFO: epoch 009:    287 / 1732 loss=2.334, loss_v1=0, loss_v2=0, nll_loss=1.129, ntokens=1149.1, nsentences=32, sample_size=1149.1, sample_size_v1=0, sample_size_v2=0, ppl=2.19, wps=609.5, ups=0.53, wpb=1149.1, bsz=32, num_updates=14120, lr=2.32418e-05, gnorm=2.294, clip=100, loss_scale=256, train_wall=19, gb_free=10.6, wall=26541
2023-05-26 06:45:45 - progress_bar.py[line:272] - INFO: epoch 009:    297 / 1732 loss=2.347, loss_v1=0, loss_v2=0, nll_loss=1.146, ntokens=1120.1, nsentences=32, sample_size=1120.1, sample_size_v1=0, sample_size_v2=0, ppl=2.21, wps=598.7, ups=0.53, wpb=1120.1, bsz=32, num_updates=14130, lr=2.32357e-05, gnorm=2.522, clip=100, loss_scale=256, train_wall=19, gb_free=10.9, wall=26560
2023-05-26 06:45:55 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 128.0
2023-05-26 06:46:06 - progress_bar.py[line:272] - INFO: epoch 009:    308 / 1732 loss=2.342, loss_v1=0, loss_v2=0, nll_loss=1.139, ntokens=1075, nsentences=32, sample_size=1075, sample_size_v1=0, sample_size_v2=0, ppl=2.2, wps=524.9, ups=0.49, wpb=1075, bsz=32, num_updates=14140, lr=2.32295e-05, gnorm=2.65, clip=100, loss_scale=128, train_wall=20, gb_free=11.7, wall=26580
2023-05-26 06:46:24 - progress_bar.py[line:272] - INFO: epoch 009:    318 / 1732 loss=2.348, loss_v1=0, loss_v2=0, nll_loss=1.143, ntokens=1026, nsentences=32, sample_size=1026, sample_size_v1=0, sample_size_v2=0, ppl=2.21, wps=550.2, ups=0.54, wpb=1026, bsz=32, num_updates=14150, lr=2.32234e-05, gnorm=2.726, clip=100, loss_scale=128, train_wall=19, gb_free=11.3, wall=26599
2023-05-26 06:46:43 - progress_bar.py[line:272] - INFO: epoch 009:    328 / 1732 loss=2.381, loss_v1=0, loss_v2=0, nll_loss=1.183, ntokens=1009.5, nsentences=32, sample_size=1009.5, sample_size_v1=0, sample_size_v2=0, ppl=2.27, wps=544.6, ups=0.54, wpb=1009.5, bsz=32, num_updates=14160, lr=2.32172e-05, gnorm=2.688, clip=100, loss_scale=128, train_wall=19, gb_free=11.7, wall=26618
2023-05-26 06:47:01 - progress_bar.py[line:272] - INFO: epoch 009:    338 / 1732 loss=2.339, loss_v1=0, loss_v2=0, nll_loss=1.136, ntokens=991.1, nsentences=32, sample_size=991.1, sample_size_v1=0, sample_size_v2=0, ppl=2.2, wps=534.7, ups=0.54, wpb=991.1, bsz=32, num_updates=14170, lr=2.32111e-05, gnorm=2.646, clip=100, loss_scale=128, train_wall=19, gb_free=11.7, wall=26636
2023-05-26 06:47:20 - progress_bar.py[line:272] - INFO: epoch 009:    348 / 1732 loss=2.34, loss_v1=0, loss_v2=0, nll_loss=1.136, ntokens=913.6, nsentences=32, sample_size=913.6, sample_size_v1=0, sample_size_v2=0, ppl=2.2, wps=493.4, ups=0.54, wpb=913.6, bsz=32, num_updates=14180, lr=2.3205e-05, gnorm=3.046, clip=100, loss_scale=128, train_wall=18, gb_free=11.6, wall=26655
2023-05-26 06:47:38 - progress_bar.py[line:272] - INFO: epoch 009:    358 / 1732 loss=2.38, loss_v1=0, loss_v2=0, nll_loss=1.181, ntokens=943, nsentences=32, sample_size=943, sample_size_v1=0, sample_size_v2=0, ppl=2.27, wps=510.9, ups=0.54, wpb=943, bsz=32, num_updates=14190, lr=2.31988e-05, gnorm=2.899, clip=100, loss_scale=128, train_wall=18, gb_free=11.9, wall=26673
2023-05-26 06:47:57 - progress_bar.py[line:272] - INFO: epoch 009:    368 / 1732 loss=2.373, loss_v1=0, loss_v2=0, nll_loss=1.171, ntokens=960.6, nsentences=32, sample_size=960.6, sample_size_v1=0, sample_size_v2=0, ppl=2.25, wps=517.4, ups=0.54, wpb=960.6, bsz=32, num_updates=14200, lr=2.31927e-05, gnorm=2.82, clip=100, loss_scale=128, train_wall=19, gb_free=11.5, wall=26692
2023-05-26 06:48:16 - progress_bar.py[line:272] - INFO: epoch 009:    378 / 1732 loss=2.386, loss_v1=0, loss_v2=0, nll_loss=1.188, ntokens=1043.2, nsentences=32, sample_size=1043.2, sample_size_v1=0, sample_size_v2=0, ppl=2.28, wps=563, ups=0.54, wpb=1043.2, bsz=32, num_updates=14210, lr=2.31865e-05, gnorm=2.551, clip=100, loss_scale=128, train_wall=19, gb_free=11.8, wall=26710
2023-05-26 06:48:34 - progress_bar.py[line:272] - INFO: epoch 009:    388 / 1732 loss=2.349, loss_v1=0, loss_v2=0, nll_loss=1.147, ntokens=1053.2, nsentences=32, sample_size=1053.2, sample_size_v1=0, sample_size_v2=0, ppl=2.21, wps=566.5, ups=0.54, wpb=1053.2, bsz=32, num_updates=14220, lr=2.31804e-05, gnorm=2.695, clip=100, loss_scale=128, train_wall=19, gb_free=11.1, wall=26729
2023-05-26 06:48:53 - progress_bar.py[line:272] - INFO: epoch 009:    398 / 1732 loss=2.367, loss_v1=0, loss_v2=0, nll_loss=1.166, ntokens=977.4, nsentences=32, sample_size=977.4, sample_size_v1=0, sample_size_v2=0, ppl=2.24, wps=527.6, ups=0.54, wpb=977.4, bsz=32, num_updates=14230, lr=2.31743e-05, gnorm=2.811, clip=100, loss_scale=128, train_wall=18, gb_free=10.9, wall=26747
2023-05-26 06:49:11 - progress_bar.py[line:272] - INFO: epoch 009:    408 / 1732 loss=2.341, loss_v1=0, loss_v2=0, nll_loss=1.138, ntokens=1058.6, nsentences=32, sample_size=1058.6, sample_size_v1=0, sample_size_v2=0, ppl=2.2, wps=567.1, ups=0.54, wpb=1058.6, bsz=32, num_updates=14240, lr=2.31681e-05, gnorm=2.432, clip=100, loss_scale=128, train_wall=19, gb_free=11.5, wall=26766
2023-05-26 06:49:30 - progress_bar.py[line:272] - INFO: epoch 009:    418 / 1732 loss=2.311, loss_v1=0, loss_v2=0, nll_loss=1.104, ntokens=1021.6, nsentences=32, sample_size=1021.6, sample_size_v1=0, sample_size_v2=0, ppl=2.15, wps=548.5, ups=0.54, wpb=1021.6, bsz=32, num_updates=14250, lr=2.3162e-05, gnorm=2.498, clip=100, loss_scale=128, train_wall=19, gb_free=11, wall=26785
2023-05-26 06:49:49 - progress_bar.py[line:272] - INFO: epoch 009:    428 / 1732 loss=2.318, loss_v1=0, loss_v2=0, nll_loss=1.11, ntokens=1016.5, nsentences=32, sample_size=1016.5, sample_size_v1=0, sample_size_v2=0, ppl=2.16, wps=546.4, ups=0.54, wpb=1016.5, bsz=32, num_updates=14260, lr=2.31558e-05, gnorm=2.617, clip=100, loss_scale=128, train_wall=19, gb_free=11.2, wall=26803
2023-05-26 06:50:07 - progress_bar.py[line:272] - INFO: epoch 009:    438 / 1732 loss=2.351, loss_v1=0, loss_v2=0, nll_loss=1.148, ntokens=1018.5, nsentences=32, sample_size=1018.5, sample_size_v1=0, sample_size_v2=0, ppl=2.22, wps=550.1, ups=0.54, wpb=1018.5, bsz=32, num_updates=14270, lr=2.31497e-05, gnorm=2.392, clip=100, loss_scale=128, train_wall=18, gb_free=11.7, wall=26822
2023-05-26 06:50:26 - progress_bar.py[line:272] - INFO: epoch 009:    448 / 1732 loss=2.366, loss_v1=0, loss_v2=0, nll_loss=1.165, ntokens=946.6, nsentences=32, sample_size=946.6, sample_size_v1=0, sample_size_v2=0, ppl=2.24, wps=509.3, ups=0.54, wpb=946.6, bsz=32, num_updates=14280, lr=2.31435e-05, gnorm=2.741, clip=100, loss_scale=128, train_wall=19, gb_free=11.5, wall=26840
2023-05-26 06:50:44 - progress_bar.py[line:272] - INFO: epoch 009:    458 / 1732 loss=2.359, loss_v1=0, loss_v2=0, nll_loss=1.157, ntokens=971.2, nsentences=32, sample_size=971.2, sample_size_v1=0, sample_size_v2=0, ppl=2.23, wps=524.6, ups=0.54, wpb=971.2, bsz=32, num_updates=14290, lr=2.31374e-05, gnorm=2.634, clip=100, loss_scale=128, train_wall=18, gb_free=11.8, wall=26859
2023-05-26 06:51:03 - progress_bar.py[line:272] - INFO: epoch 009:    468 / 1732 loss=2.365, loss_v1=0, loss_v2=0, nll_loss=1.163, ntokens=1064.3, nsentences=32, sample_size=1064.3, sample_size_v1=0, sample_size_v2=0, ppl=2.24, wps=566.9, ups=0.53, wpb=1064.3, bsz=32, num_updates=14300, lr=2.31313e-05, gnorm=2.807, clip=100, loss_scale=128, train_wall=19, gb_free=11.3, wall=26878
2023-05-26 06:51:22 - progress_bar.py[line:272] - INFO: epoch 009:    478 / 1732 loss=2.386, loss_v1=0, loss_v2=0, nll_loss=1.184, ntokens=1027.7, nsentences=32, sample_size=1027.7, sample_size_v1=0, sample_size_v2=0, ppl=2.27, wps=551.7, ups=0.54, wpb=1027.7, bsz=32, num_updates=14310, lr=2.31251e-05, gnorm=2.687, clip=100, loss_scale=128, train_wall=19, gb_free=11.7, wall=26896
2023-05-26 06:51:40 - progress_bar.py[line:272] - INFO: epoch 009:    488 / 1732 loss=2.331, loss_v1=0, loss_v2=0, nll_loss=1.128, ntokens=925.6, nsentences=32, sample_size=925.6, sample_size_v1=0, sample_size_v2=0, ppl=2.19, wps=500.9, ups=0.54, wpb=925.6, bsz=32, num_updates=14320, lr=2.3119e-05, gnorm=2.763, clip=100, loss_scale=128, train_wall=18, gb_free=12, wall=26915
2023-05-26 06:51:59 - progress_bar.py[line:272] - INFO: epoch 009:    498 / 1732 loss=2.346, loss_v1=0, loss_v2=0, nll_loss=1.145, ntokens=952.7, nsentences=32, sample_size=952.7, sample_size_v1=0, sample_size_v2=0, ppl=2.21, wps=514.3, ups=0.54, wpb=952.7, bsz=32, num_updates=14330, lr=2.31128e-05, gnorm=2.911, clip=100, loss_scale=128, train_wall=18, gb_free=12.1, wall=26933
2023-05-26 06:52:17 - progress_bar.py[line:272] - INFO: epoch 009:    508 / 1732 loss=2.364, loss_v1=0, loss_v2=0, nll_loss=1.161, ntokens=1034.3, nsentences=32, sample_size=1034.3, sample_size_v1=0, sample_size_v2=0, ppl=2.24, wps=558.3, ups=0.54, wpb=1034.3, bsz=32, num_updates=14340, lr=2.31067e-05, gnorm=2.668, clip=100, loss_scale=128, train_wall=18, gb_free=11.7, wall=26952
2023-05-26 06:52:36 - progress_bar.py[line:272] - INFO: epoch 009:    518 / 1732 loss=2.35, loss_v1=0, loss_v2=0, nll_loss=1.147, ntokens=1032.2, nsentences=32, sample_size=1032.2, sample_size_v1=0, sample_size_v2=0, ppl=2.21, wps=557, ups=0.54, wpb=1032.2, bsz=32, num_updates=14350, lr=2.31005e-05, gnorm=2.438, clip=100, loss_scale=128, train_wall=19, gb_free=11.7, wall=26970
2023-05-26 06:52:54 - progress_bar.py[line:272] - INFO: epoch 009:    528 / 1732 loss=2.359, loss_v1=0, loss_v2=0, nll_loss=1.157, ntokens=941.1, nsentences=32, sample_size=941.1, sample_size_v1=0, sample_size_v2=0, ppl=2.23, wps=510.1, ups=0.54, wpb=941.1, bsz=32, num_updates=14360, lr=2.30944e-05, gnorm=2.793, clip=100, loss_scale=128, train_wall=18, gb_free=11.9, wall=26989
2023-05-26 06:53:13 - progress_bar.py[line:272] - INFO: epoch 009:    538 / 1732 loss=2.338, loss_v1=0, loss_v2=0, nll_loss=1.134, ntokens=972.3, nsentences=32, sample_size=972.3, sample_size_v1=0, sample_size_v2=0, ppl=2.19, wps=525.5, ups=0.54, wpb=972.3, bsz=32, num_updates=14370, lr=2.30883e-05, gnorm=2.572, clip=100, loss_scale=128, train_wall=18, gb_free=11.2, wall=27007
2023-05-26 06:53:31 - progress_bar.py[line:272] - INFO: epoch 009:    548 / 1732 loss=2.377, loss_v1=0, loss_v2=0, nll_loss=1.178, ntokens=1027.8, nsentences=32, sample_size=1027.8, sample_size_v1=0, sample_size_v2=0, ppl=2.26, wps=553.6, ups=0.54, wpb=1027.8, bsz=32, num_updates=14380, lr=2.30821e-05, gnorm=2.763, clip=100, loss_scale=128, train_wall=19, gb_free=11.6, wall=27026
2023-05-26 06:53:50 - progress_bar.py[line:272] - INFO: epoch 009:    558 / 1732 loss=2.384, loss_v1=0, loss_v2=0, nll_loss=1.186, ntokens=1021.9, nsentences=32, sample_size=1021.9, sample_size_v1=0, sample_size_v2=0, ppl=2.27, wps=551, ups=0.54, wpb=1021.9, bsz=32, num_updates=14390, lr=2.3076e-05, gnorm=2.478, clip=100, loss_scale=128, train_wall=19, gb_free=10.9, wall=27044
2023-05-26 06:54:08 - progress_bar.py[line:272] - INFO: epoch 009:    568 / 1732 loss=2.384, loss_v1=0, loss_v2=0, nll_loss=1.185, ntokens=1014.9, nsentences=32, sample_size=1014.9, sample_size_v1=0, sample_size_v2=0, ppl=2.27, wps=543.2, ups=0.54, wpb=1014.9, bsz=32, num_updates=14400, lr=2.30698e-05, gnorm=2.631, clip=100, loss_scale=128, train_wall=19, gb_free=11.1, wall=27063
2023-05-26 06:54:27 - progress_bar.py[line:272] - INFO: epoch 009:    578 / 1732 loss=2.36, loss_v1=0, loss_v2=0, nll_loss=1.158, ntokens=991.4, nsentences=32, sample_size=991.4, sample_size_v1=0, sample_size_v2=0, ppl=2.23, wps=531.6, ups=0.54, wpb=991.4, bsz=32, num_updates=14410, lr=2.30637e-05, gnorm=2.822, clip=100, loss_scale=128, train_wall=19, gb_free=11.2, wall=27082
2023-05-26 06:54:46 - progress_bar.py[line:272] - INFO: epoch 009:    588 / 1732 loss=2.355, loss_v1=0, loss_v2=0, nll_loss=1.152, ntokens=965.9, nsentences=32, sample_size=965.9, sample_size_v1=0, sample_size_v2=0, ppl=2.22, wps=518.2, ups=0.54, wpb=965.9, bsz=32, num_updates=14420, lr=2.30576e-05, gnorm=2.642, clip=100, loss_scale=128, train_wall=19, gb_free=11.6, wall=27100
2023-05-26 06:55:04 - progress_bar.py[line:272] - INFO: epoch 009:    598 / 1732 loss=2.32, loss_v1=0, loss_v2=0, nll_loss=1.116, ntokens=957.4, nsentences=32, sample_size=957.4, sample_size_v1=0, sample_size_v2=0, ppl=2.17, wps=515, ups=0.54, wpb=957.4, bsz=32, num_updates=14430, lr=2.30514e-05, gnorm=2.66, clip=100, loss_scale=128, train_wall=19, gb_free=11.9, wall=27119
2023-05-26 06:55:23 - progress_bar.py[line:272] - INFO: epoch 009:    608 / 1732 loss=2.353, loss_v1=0, loss_v2=0, nll_loss=1.152, ntokens=893.5, nsentences=32, sample_size=893.5, sample_size_v1=0, sample_size_v2=0, ppl=2.22, wps=485.1, ups=0.54, wpb=893.5, bsz=32, num_updates=14440, lr=2.30453e-05, gnorm=2.96, clip=100, loss_scale=128, train_wall=18, gb_free=11.1, wall=27137
2023-05-26 06:55:41 - progress_bar.py[line:272] - INFO: epoch 009:    618 / 1732 loss=2.373, loss_v1=0, loss_v2=0, nll_loss=1.17, ntokens=860.2, nsentences=32, sample_size=860.2, sample_size_v1=0, sample_size_v2=0, ppl=2.25, wps=467.7, ups=0.54, wpb=860.2, bsz=32, num_updates=14450, lr=2.30391e-05, gnorm=3.206, clip=100, loss_scale=128, train_wall=18, gb_free=11.7, wall=27156
2023-05-26 06:56:00 - progress_bar.py[line:272] - INFO: epoch 009:    628 / 1732 loss=2.353, loss_v1=0, loss_v2=0, nll_loss=1.149, ntokens=929, nsentences=32, sample_size=929, sample_size_v1=0, sample_size_v2=0, ppl=2.22, wps=505.3, ups=0.54, wpb=929, bsz=32, num_updates=14460, lr=2.3033e-05, gnorm=2.807, clip=100, loss_scale=128, train_wall=18, gb_free=11.7, wall=27174
2023-05-26 06:56:18 - progress_bar.py[line:272] - INFO: epoch 009:    638 / 1732 loss=2.369, loss_v1=0, loss_v2=0, nll_loss=1.171, ntokens=921.3, nsentences=32, sample_size=921.3, sample_size_v1=0, sample_size_v2=0, ppl=2.25, wps=499.9, ups=0.54, wpb=921.3, bsz=32, num_updates=14470, lr=2.30268e-05, gnorm=2.941, clip=100, loss_scale=128, train_wall=18, gb_free=11.8, wall=27193
2023-05-26 06:56:36 - progress_bar.py[line:272] - INFO: epoch 009:    648 / 1732 loss=2.369, loss_v1=0, loss_v2=0, nll_loss=1.165, ntokens=983.5, nsentences=32, sample_size=983.5, sample_size_v1=0, sample_size_v2=0, ppl=2.24, wps=532.8, ups=0.54, wpb=983.5, bsz=32, num_updates=14480, lr=2.30207e-05, gnorm=2.647, clip=100, loss_scale=128, train_wall=18, gb_free=11.5, wall=27211
2023-05-26 06:56:55 - progress_bar.py[line:272] - INFO: epoch 009:    658 / 1732 loss=2.359, loss_v1=0, loss_v2=0, nll_loss=1.159, ntokens=892.2, nsentences=32, sample_size=892.2, sample_size_v1=0, sample_size_v2=0, ppl=2.23, wps=482.1, ups=0.54, wpb=892.2, bsz=32, num_updates=14490, lr=2.30146e-05, gnorm=2.915, clip=100, loss_scale=128, train_wall=18, gb_free=11.4, wall=27230
2023-05-26 06:57:13 - progress_bar.py[line:272] - INFO: epoch 009:    668 / 1732 loss=2.352, loss_v1=0, loss_v2=0, nll_loss=1.152, ntokens=910, nsentences=32, sample_size=910, sample_size_v1=0, sample_size_v2=0, ppl=2.22, wps=494.2, ups=0.54, wpb=910, bsz=32, num_updates=14500, lr=2.30084e-05, gnorm=3.012, clip=100, loss_scale=128, train_wall=18, gb_free=11.1, wall=27248
2023-05-26 06:57:32 - progress_bar.py[line:272] - INFO: epoch 009:    678 / 1732 loss=2.375, loss_v1=0, loss_v2=0, nll_loss=1.173, ntokens=980.2, nsentences=32, sample_size=980.2, sample_size_v1=0, sample_size_v2=0, ppl=2.25, wps=529.8, ups=0.54, wpb=980.2, bsz=32, num_updates=14510, lr=2.30023e-05, gnorm=2.934, clip=100, loss_scale=128, train_wall=18, gb_free=11.8, wall=27267
2023-05-26 06:57:50 - progress_bar.py[line:272] - INFO: epoch 009:    688 / 1732 loss=2.367, loss_v1=0, loss_v2=0, nll_loss=1.166, ntokens=942, nsentences=32, sample_size=942, sample_size_v1=0, sample_size_v2=0, ppl=2.24, wps=510.7, ups=0.54, wpb=942, bsz=32, num_updates=14520, lr=2.29961e-05, gnorm=3.028, clip=100, loss_scale=128, train_wall=18, gb_free=11.8, wall=27285
2023-05-26 06:58:09 - progress_bar.py[line:272] - INFO: epoch 009:    698 / 1732 loss=2.356, loss_v1=0, loss_v2=0, nll_loss=1.157, ntokens=1001.9, nsentences=32, sample_size=1001.9, sample_size_v1=0, sample_size_v2=0, ppl=2.23, wps=535.4, ups=0.53, wpb=1001.9, bsz=32, num_updates=14530, lr=2.299e-05, gnorm=2.886, clip=100, loss_scale=128, train_wall=19, gb_free=11.7, wall=27304
2023-05-26 06:58:27 - progress_bar.py[line:272] - INFO: epoch 009:    708 / 1732 loss=2.351, loss_v1=0, loss_v2=0, nll_loss=1.144, ntokens=907.1, nsentences=32, sample_size=907.1, sample_size_v1=0, sample_size_v2=0, ppl=2.21, wps=492.9, ups=0.54, wpb=907.1, bsz=32, num_updates=14540, lr=2.29838e-05, gnorm=2.836, clip=100, loss_scale=128, train_wall=18, gb_free=11.7, wall=27322
2023-05-26 06:58:46 - progress_bar.py[line:272] - INFO: epoch 009:    718 / 1732 loss=2.348, loss_v1=0, loss_v2=0, nll_loss=1.145, ntokens=882, nsentences=32, sample_size=882, sample_size_v1=0, sample_size_v2=0, ppl=2.21, wps=480.2, ups=0.54, wpb=882, bsz=32, num_updates=14550, lr=2.29777e-05, gnorm=2.875, clip=100, loss_scale=128, train_wall=18, gb_free=12, wall=27341
2023-05-26 06:59:04 - progress_bar.py[line:272] - INFO: epoch 009:    728 / 1732 loss=2.33, loss_v1=0, loss_v2=0, nll_loss=1.127, ntokens=917.5, nsentences=32, sample_size=917.5, sample_size_v1=0, sample_size_v2=0, ppl=2.18, wps=496.4, ups=0.54, wpb=917.5, bsz=32, num_updates=14560, lr=2.29716e-05, gnorm=3.022, clip=100, loss_scale=128, train_wall=18, gb_free=11.5, wall=27359
2023-05-26 06:59:23 - progress_bar.py[line:272] - INFO: epoch 009:    738 / 1732 loss=2.347, loss_v1=0, loss_v2=0, nll_loss=1.142, ntokens=991.8, nsentences=32, sample_size=991.8, sample_size_v1=0, sample_size_v2=0, ppl=2.21, wps=538.2, ups=0.54, wpb=991.8, bsz=32, num_updates=14570, lr=2.29654e-05, gnorm=2.893, clip=100, loss_scale=128, train_wall=18, gb_free=11.6, wall=27377
2023-05-26 06:59:41 - progress_bar.py[line:272] - INFO: epoch 009:    748 / 1732 loss=2.344, loss_v1=0, loss_v2=0, nll_loss=1.138, ntokens=986.3, nsentences=32, sample_size=986.3, sample_size_v1=0, sample_size_v2=0, ppl=2.2, wps=529.8, ups=0.54, wpb=986.3, bsz=32, num_updates=14580, lr=2.29593e-05, gnorm=2.749, clip=100, loss_scale=128, train_wall=19, gb_free=11.6, wall=27396
2023-05-26 07:00:00 - progress_bar.py[line:272] - INFO: epoch 009:    758 / 1732 loss=2.328, loss_v1=0, loss_v2=0, nll_loss=1.124, ntokens=946.6, nsentences=32, sample_size=946.6, sample_size_v1=0, sample_size_v2=0, ppl=2.18, wps=512.4, ups=0.54, wpb=946.6, bsz=32, num_updates=14590, lr=2.29531e-05, gnorm=2.668, clip=100, loss_scale=128, train_wall=18, gb_free=11.4, wall=27415
2023-05-26 07:00:18 - progress_bar.py[line:272] - INFO: epoch 009:    768 / 1732 loss=2.344, loss_v1=0, loss_v2=0, nll_loss=1.144, ntokens=947.6, nsentences=32, sample_size=947.6, sample_size_v1=0, sample_size_v2=0, ppl=2.21, wps=513.8, ups=0.54, wpb=947.6, bsz=32, num_updates=14600, lr=2.2947e-05, gnorm=2.818, clip=100, loss_scale=128, train_wall=18, gb_free=11.3, wall=27433
2023-05-26 07:00:37 - progress_bar.py[line:272] - INFO: epoch 009:    778 / 1732 loss=2.343, loss_v1=0, loss_v2=0, nll_loss=1.137, ntokens=1017.6, nsentences=32, sample_size=1017.6, sample_size_v1=0, sample_size_v2=0, ppl=2.2, wps=548.6, ups=0.54, wpb=1017.6, bsz=32, num_updates=14610, lr=2.29409e-05, gnorm=2.825, clip=100, loss_scale=128, train_wall=19, gb_free=12, wall=27452
2023-05-26 07:00:55 - progress_bar.py[line:272] - INFO: epoch 009:    788 / 1732 loss=2.348, loss_v1=0, loss_v2=0, nll_loss=1.147, ntokens=1010.8, nsentences=32, sample_size=1010.8, sample_size_v1=0, sample_size_v2=0, ppl=2.21, wps=545.9, ups=0.54, wpb=1010.8, bsz=32, num_updates=14620, lr=2.29347e-05, gnorm=2.851, clip=100, loss_scale=128, train_wall=18, gb_free=11.3, wall=27470
2023-05-26 07:01:14 - progress_bar.py[line:272] - INFO: epoch 009:    798 / 1732 loss=2.343, loss_v1=0, loss_v2=0, nll_loss=1.141, ntokens=1050, nsentences=32, sample_size=1050, sample_size_v1=0, sample_size_v2=0, ppl=2.21, wps=567.4, ups=0.54, wpb=1050, bsz=32, num_updates=14630, lr=2.29286e-05, gnorm=2.7, clip=100, loss_scale=128, train_wall=18, gb_free=11.6, wall=27489
2023-05-26 07:01:32 - progress_bar.py[line:272] - INFO: epoch 009:    808 / 1732 loss=2.344, loss_v1=0, loss_v2=0, nll_loss=1.138, ntokens=907.2, nsentences=32, sample_size=907.2, sample_size_v1=0, sample_size_v2=0, ppl=2.2, wps=492.2, ups=0.54, wpb=907.2, bsz=32, num_updates=14640, lr=2.29224e-05, gnorm=2.928, clip=100, loss_scale=128, train_wall=18, gb_free=11.2, wall=27507
2023-05-26 07:01:51 - progress_bar.py[line:272] - INFO: epoch 009:    818 / 1732 loss=2.354, loss_v1=0, loss_v2=0, nll_loss=1.151, ntokens=917.4, nsentences=32, sample_size=917.4, sample_size_v1=0, sample_size_v2=0, ppl=2.22, wps=496.9, ups=0.54, wpb=917.4, bsz=32, num_updates=14650, lr=2.29163e-05, gnorm=2.945, clip=100, loss_scale=256, train_wall=18, gb_free=11.8, wall=27525
2023-05-26 07:02:09 - progress_bar.py[line:272] - INFO: epoch 009:    828 / 1732 loss=2.344, loss_v1=0, loss_v2=0, nll_loss=1.142, ntokens=929.3, nsentences=32, sample_size=929.3, sample_size_v1=0, sample_size_v2=0, ppl=2.21, wps=501.1, ups=0.54, wpb=929.3, bsz=32, num_updates=14660, lr=2.29101e-05, gnorm=2.717, clip=100, loss_scale=256, train_wall=19, gb_free=11.8, wall=27544
2023-05-26 07:02:28 - progress_bar.py[line:272] - INFO: epoch 009:    838 / 1732 loss=2.353, loss_v1=0, loss_v2=0, nll_loss=1.149, ntokens=901, nsentences=32, sample_size=901, sample_size_v1=0, sample_size_v2=0, ppl=2.22, wps=490.9, ups=0.54, wpb=901, bsz=32, num_updates=14670, lr=2.2904e-05, gnorm=2.932, clip=100, loss_scale=256, train_wall=18, gb_free=11.7, wall=27562
2023-05-26 07:02:46 - progress_bar.py[line:272] - INFO: epoch 009:    848 / 1732 loss=2.333, loss_v1=0, loss_v2=0, nll_loss=1.127, ntokens=1016.3, nsentences=32, sample_size=1016.3, sample_size_v1=0, sample_size_v2=0, ppl=2.18, wps=549.1, ups=0.54, wpb=1016.3, bsz=32, num_updates=14680, lr=2.28979e-05, gnorm=2.843, clip=100, loss_scale=256, train_wall=18, gb_free=10.8, wall=27581
2023-05-26 07:03:05 - progress_bar.py[line:272] - INFO: epoch 009:    858 / 1732 loss=2.343, loss_v1=0, loss_v2=0, nll_loss=1.143, ntokens=923.8, nsentences=32, sample_size=923.8, sample_size_v1=0, sample_size_v2=0, ppl=2.21, wps=502, ups=0.54, wpb=923.8, bsz=32, num_updates=14690, lr=2.28917e-05, gnorm=3.316, clip=100, loss_scale=256, train_wall=18, gb_free=11.6, wall=27599
2023-05-26 07:03:23 - progress_bar.py[line:272] - INFO: epoch 009:    868 / 1732 loss=2.356, loss_v1=0, loss_v2=0, nll_loss=1.154, ntokens=966.1, nsentences=32, sample_size=966.1, sample_size_v1=0, sample_size_v2=0, ppl=2.23, wps=522.4, ups=0.54, wpb=966.1, bsz=32, num_updates=14700, lr=2.28856e-05, gnorm=2.941, clip=100, loss_scale=256, train_wall=18, gb_free=11.7, wall=27618
2023-05-26 07:03:42 - progress_bar.py[line:272] - INFO: epoch 009:    878 / 1732 loss=2.289, loss_v1=0, loss_v2=0, nll_loss=1.078, ntokens=1016.8, nsentences=32, sample_size=1016.8, sample_size_v1=0, sample_size_v2=0, ppl=2.11, wps=547.8, ups=0.54, wpb=1016.8, bsz=32, num_updates=14710, lr=2.28794e-05, gnorm=2.733, clip=100, loss_scale=256, train_wall=19, gb_free=11.5, wall=27636
2023-05-26 07:04:00 - progress_bar.py[line:272] - INFO: epoch 009:    888 / 1732 loss=2.308, loss_v1=0, loss_v2=0, nll_loss=1.101, ntokens=961.8, nsentences=32, sample_size=961.8, sample_size_v1=0, sample_size_v2=0, ppl=2.15, wps=518.2, ups=0.54, wpb=961.8, bsz=32, num_updates=14720, lr=2.28733e-05, gnorm=2.917, clip=100, loss_scale=256, train_wall=19, gb_free=11.3, wall=27655
2023-05-26 07:04:19 - progress_bar.py[line:272] - INFO: epoch 009:    898 / 1732 loss=2.278, loss_v1=0, loss_v2=0, nll_loss=1.064, ntokens=1063.3, nsentences=32, sample_size=1063.3, sample_size_v1=0, sample_size_v2=0, ppl=2.09, wps=572.5, ups=0.54, wpb=1063.3, bsz=32, num_updates=14730, lr=2.28671e-05, gnorm=2.614, clip=100, loss_scale=256, train_wall=19, gb_free=11, wall=27673
2023-05-26 07:04:37 - progress_bar.py[line:272] - INFO: epoch 009:    908 / 1732 loss=2.301, loss_v1=0, loss_v2=0, nll_loss=1.095, ntokens=987.4, nsentences=32, sample_size=987.4, sample_size_v1=0, sample_size_v2=0, ppl=2.14, wps=533.1, ups=0.54, wpb=987.4, bsz=32, num_updates=14740, lr=2.2861e-05, gnorm=2.886, clip=100, loss_scale=256, train_wall=18, gb_free=11.6, wall=27692
2023-05-26 07:04:56 - progress_bar.py[line:272] - INFO: epoch 009:    918 / 1732 loss=2.387, loss_v1=0, loss_v2=0, nll_loss=1.189, ntokens=968, nsentences=32, sample_size=968, sample_size_v1=0, sample_size_v2=0, ppl=2.28, wps=522.3, ups=0.54, wpb=968, bsz=32, num_updates=14750, lr=2.28549e-05, gnorm=3.205, clip=100, loss_scale=256, train_wall=19, gb_free=10.7, wall=27711
2023-05-26 07:05:15 - progress_bar.py[line:272] - INFO: epoch 009:    928 / 1732 loss=2.308, loss_v1=0, loss_v2=0, nll_loss=1.099, ntokens=1026.7, nsentences=32, sample_size=1026.7, sample_size_v1=0, sample_size_v2=0, ppl=2.14, wps=549.5, ups=0.54, wpb=1026.7, bsz=32, num_updates=14760, lr=2.28487e-05, gnorm=2.709, clip=100, loss_scale=256, train_wall=19, gb_free=11.3, wall=27729
2023-05-26 07:05:18 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 128.0
2023-05-26 07:05:35 - progress_bar.py[line:272] - INFO: epoch 009:    939 / 1732 loss=2.322, loss_v1=0, loss_v2=0, nll_loss=1.118, ntokens=1038.5, nsentences=32, sample_size=1038.5, sample_size_v1=0, sample_size_v2=0, ppl=2.17, wps=504, ups=0.49, wpb=1038.5, bsz=32, num_updates=14770, lr=2.28426e-05, gnorm=2.847, clip=100, loss_scale=128, train_wall=21, gb_free=11.2, wall=27750
2023-05-26 07:05:54 - progress_bar.py[line:272] - INFO: epoch 009:    949 / 1732 loss=2.333, loss_v1=0, loss_v2=0, nll_loss=1.128, ntokens=1037.9, nsentences=32, sample_size=1037.9, sample_size_v1=0, sample_size_v2=0, ppl=2.19, wps=551.5, ups=0.53, wpb=1037.9, bsz=32, num_updates=14780, lr=2.28364e-05, gnorm=2.778, clip=100, loss_scale=128, train_wall=19, gb_free=11.3, wall=27769
2023-05-26 07:06:13 - progress_bar.py[line:272] - INFO: epoch 009:    959 / 1732 loss=2.318, loss_v1=0, loss_v2=0, nll_loss=1.111, ntokens=1070.6, nsentences=32, sample_size=1070.6, sample_size_v1=0, sample_size_v2=0, ppl=2.16, wps=569.8, ups=0.53, wpb=1070.6, bsz=32, num_updates=14790, lr=2.28303e-05, gnorm=2.539, clip=100, loss_scale=128, train_wall=19, gb_free=11.2, wall=27787
2023-05-26 07:06:32 - progress_bar.py[line:272] - INFO: epoch 009:    969 / 1732 loss=2.361, loss_v1=0, loss_v2=0, nll_loss=1.16, ntokens=1025.9, nsentences=32, sample_size=1025.9, sample_size_v1=0, sample_size_v2=0, ppl=2.23, wps=548.3, ups=0.53, wpb=1025.9, bsz=32, num_updates=14800, lr=2.28242e-05, gnorm=2.973, clip=100, loss_scale=128, train_wall=19, gb_free=11.3, wall=27806
2023-05-26 07:06:50 - progress_bar.py[line:272] - INFO: epoch 009:    979 / 1732 loss=2.333, loss_v1=0, loss_v2=0, nll_loss=1.127, ntokens=1025.3, nsentences=32, sample_size=1025.3, sample_size_v1=0, sample_size_v2=0, ppl=2.18, wps=542.8, ups=0.53, wpb=1025.3, bsz=32, num_updates=14810, lr=2.2818e-05, gnorm=2.534, clip=100, loss_scale=128, train_wall=19, gb_free=11, wall=27825
2023-05-26 07:07:09 - progress_bar.py[line:272] - INFO: epoch 009:    989 / 1732 loss=2.326, loss_v1=0, loss_v2=0, nll_loss=1.12, ntokens=1057.2, nsentences=32, sample_size=1057.2, sample_size_v1=0, sample_size_v2=0, ppl=2.17, wps=560.7, ups=0.53, wpb=1057.2, bsz=32, num_updates=14820, lr=2.28119e-05, gnorm=2.634, clip=100, loss_scale=128, train_wall=19, gb_free=11.1, wall=27844
2023-05-26 07:07:28 - progress_bar.py[line:272] - INFO: epoch 009:    999 / 1732 loss=2.326, loss_v1=0, loss_v2=0, nll_loss=1.119, ntokens=989.7, nsentences=32, sample_size=989.7, sample_size_v1=0, sample_size_v2=0, ppl=2.17, wps=530.8, ups=0.54, wpb=989.7, bsz=32, num_updates=14830, lr=2.28057e-05, gnorm=2.896, clip=100, loss_scale=128, train_wall=19, gb_free=11.8, wall=27863
2023-05-26 07:07:47 - progress_bar.py[line:272] - INFO: epoch 009:   1009 / 1732 loss=2.332, loss_v1=0, loss_v2=0, nll_loss=1.126, ntokens=1040.9, nsentences=32, sample_size=1040.9, sample_size_v1=0, sample_size_v2=0, ppl=2.18, wps=555.1, ups=0.53, wpb=1040.9, bsz=32, num_updates=14840, lr=2.27996e-05, gnorm=2.812, clip=100, loss_scale=128, train_wall=19, gb_free=10.8, wall=27881
2023-05-26 07:08:05 - progress_bar.py[line:272] - INFO: epoch 009:   1019 / 1732 loss=2.305, loss_v1=0, loss_v2=0, nll_loss=1.098, ntokens=1021.6, nsentences=32, sample_size=1021.6, sample_size_v1=0, sample_size_v2=0, ppl=2.14, wps=548.1, ups=0.54, wpb=1021.6, bsz=32, num_updates=14850, lr=2.27934e-05, gnorm=2.688, clip=100, loss_scale=128, train_wall=19, gb_free=11.3, wall=27900
2023-05-26 07:08:24 - progress_bar.py[line:272] - INFO: epoch 009:   1029 / 1732 loss=2.329, loss_v1=0, loss_v2=0, nll_loss=1.122, ntokens=1092, nsentences=32, sample_size=1092, sample_size_v1=0, sample_size_v2=0, ppl=2.18, wps=573.8, ups=0.53, wpb=1092, bsz=32, num_updates=14860, lr=2.27873e-05, gnorm=2.568, clip=100, loss_scale=128, train_wall=19, gb_free=10.6, wall=27919
2023-05-26 07:08:43 - progress_bar.py[line:272] - INFO: epoch 009:   1039 / 1732 loss=2.345, loss_v1=0, loss_v2=0, nll_loss=1.14, ntokens=1077.1, nsentences=32, sample_size=1077.1, sample_size_v1=0, sample_size_v2=0, ppl=2.2, wps=572.6, ups=0.53, wpb=1077.1, bsz=32, num_updates=14870, lr=2.27812e-05, gnorm=2.86, clip=100, loss_scale=128, train_wall=19, gb_free=10.9, wall=27938
2023-05-26 07:09:02 - progress_bar.py[line:272] - INFO: epoch 009:   1049 / 1732 loss=2.321, loss_v1=0, loss_v2=0, nll_loss=1.116, ntokens=1018.7, nsentences=32, sample_size=1018.7, sample_size_v1=0, sample_size_v2=0, ppl=2.17, wps=544.7, ups=0.53, wpb=1018.7, bsz=32, num_updates=14880, lr=2.2775e-05, gnorm=3.032, clip=100, loss_scale=128, train_wall=19, gb_free=11.5, wall=27957
2023-05-26 07:09:21 - progress_bar.py[line:272] - INFO: epoch 009:   1059 / 1732 loss=2.332, loss_v1=0, loss_v2=0, nll_loss=1.128, ntokens=1090.9, nsentences=32, sample_size=1090.9, sample_size_v1=0, sample_size_v2=0, ppl=2.19, wps=581.8, ups=0.53, wpb=1090.9, bsz=32, num_updates=14890, lr=2.27689e-05, gnorm=2.486, clip=100, loss_scale=128, train_wall=19, gb_free=11.5, wall=27975
2023-05-26 07:09:39 - progress_bar.py[line:272] - INFO: epoch 009:   1069 / 1732 loss=2.321, loss_v1=0, loss_v2=0, nll_loss=1.114, ntokens=979.2, nsentences=32, sample_size=979.2, sample_size_v1=0, sample_size_v2=0, ppl=2.17, wps=524.2, ups=0.54, wpb=979.2, bsz=32, num_updates=14900, lr=2.27627e-05, gnorm=2.676, clip=100, loss_scale=128, train_wall=19, gb_free=11.3, wall=27994
2023-05-26 07:09:58 - progress_bar.py[line:272] - INFO: epoch 009:   1079 / 1732 loss=2.347, loss_v1=0, loss_v2=0, nll_loss=1.144, ntokens=1044.7, nsentences=32, sample_size=1044.7, sample_size_v1=0, sample_size_v2=0, ppl=2.21, wps=552.9, ups=0.53, wpb=1044.7, bsz=32, num_updates=14910, lr=2.27566e-05, gnorm=2.623, clip=100, loss_scale=128, train_wall=19, gb_free=11, wall=28013
2023-05-26 07:10:17 - progress_bar.py[line:272] - INFO: epoch 009:   1089 / 1732 loss=2.314, loss_v1=0, loss_v2=0, nll_loss=1.106, ntokens=1065.4, nsentences=32, sample_size=1065.4, sample_size_v1=0, sample_size_v2=0, ppl=2.15, wps=563.5, ups=0.53, wpb=1065.4, bsz=32, num_updates=14920, lr=2.27504e-05, gnorm=2.759, clip=100, loss_scale=128, train_wall=19, gb_free=11.4, wall=28032
2023-05-26 07:10:36 - progress_bar.py[line:272] - INFO: epoch 009:   1099 / 1732 loss=2.337, loss_v1=0, loss_v2=0, nll_loss=1.133, ntokens=1034.8, nsentences=32, sample_size=1034.8, sample_size_v1=0, sample_size_v2=0, ppl=2.19, wps=552.4, ups=0.53, wpb=1034.8, bsz=32, num_updates=14930, lr=2.27443e-05, gnorm=2.904, clip=100, loss_scale=128, train_wall=19, gb_free=10.5, wall=28051
2023-05-26 07:10:55 - progress_bar.py[line:272] - INFO: epoch 009:   1109 / 1732 loss=2.321, loss_v1=0, loss_v2=0, nll_loss=1.114, ntokens=1058.4, nsentences=32, sample_size=1058.4, sample_size_v1=0, sample_size_v2=0, ppl=2.16, wps=560.8, ups=0.53, wpb=1058.4, bsz=32, num_updates=14940, lr=2.27382e-05, gnorm=2.751, clip=100, loss_scale=128, train_wall=19, gb_free=10.4, wall=28069
2023-05-26 07:11:13 - progress_bar.py[line:272] - INFO: epoch 009:   1119 / 1732 loss=2.324, loss_v1=0, loss_v2=0, nll_loss=1.119, ntokens=966, nsentences=32, sample_size=966, sample_size_v1=0, sample_size_v2=0, ppl=2.17, wps=514.8, ups=0.53, wpb=966, bsz=32, num_updates=14950, lr=2.2732e-05, gnorm=2.785, clip=100, loss_scale=128, train_wall=19, gb_free=10.9, wall=28088
2023-05-26 07:11:32 - progress_bar.py[line:272] - INFO: epoch 009:   1129 / 1732 loss=2.322, loss_v1=0, loss_v2=0, nll_loss=1.116, ntokens=1007.5, nsentences=32, sample_size=1007.5, sample_size_v1=0, sample_size_v2=0, ppl=2.17, wps=535.7, ups=0.53, wpb=1007.5, bsz=32, num_updates=14960, lr=2.27259e-05, gnorm=2.633, clip=100, loss_scale=128, train_wall=19, gb_free=11.4, wall=28107
2023-05-26 07:11:51 - progress_bar.py[line:272] - INFO: epoch 009:   1139 / 1732 loss=2.336, loss_v1=0, loss_v2=0, nll_loss=1.13, ntokens=999.7, nsentences=32, sample_size=999.7, sample_size_v1=0, sample_size_v2=0, ppl=2.19, wps=534.1, ups=0.53, wpb=999.7, bsz=32, num_updates=14970, lr=2.27197e-05, gnorm=2.674, clip=100, loss_scale=128, train_wall=19, gb_free=11.1, wall=28126
2023-05-26 07:12:10 - progress_bar.py[line:272] - INFO: epoch 009:   1149 / 1732 loss=2.328, loss_v1=0, loss_v2=0, nll_loss=1.124, ntokens=999, nsentences=32, sample_size=999, sample_size_v1=0, sample_size_v2=0, ppl=2.18, wps=533.3, ups=0.53, wpb=999, bsz=32, num_updates=14980, lr=2.27136e-05, gnorm=2.633, clip=100, loss_scale=128, train_wall=19, gb_free=11.4, wall=28144
2023-05-26 07:12:29 - progress_bar.py[line:272] - INFO: epoch 009:   1159 / 1732 loss=2.306, loss_v1=0, loss_v2=0, nll_loss=1.099, ntokens=1014.2, nsentences=32, sample_size=1014.2, sample_size_v1=0, sample_size_v2=0, ppl=2.14, wps=539.8, ups=0.53, wpb=1014.2, bsz=32, num_updates=14990, lr=2.27075e-05, gnorm=2.743, clip=100, loss_scale=128, train_wall=19, gb_free=11.5, wall=28163
2023-05-26 07:12:47 - progress_bar.py[line:272] - INFO: epoch 009:   1169 / 1732 loss=2.321, loss_v1=0, loss_v2=0, nll_loss=1.113, ntokens=1031, nsentences=32, sample_size=1031, sample_size_v1=0, sample_size_v2=0, ppl=2.16, wps=547.9, ups=0.53, wpb=1031, bsz=32, num_updates=15000, lr=2.27013e-05, gnorm=2.709, clip=100, loss_scale=128, train_wall=19, gb_free=11.1, wall=28182
2023-05-26 07:13:06 - progress_bar.py[line:272] - INFO: epoch 009:   1179 / 1732 loss=2.299, loss_v1=0, loss_v2=0, nll_loss=1.089, ntokens=1057.9, nsentences=32, sample_size=1057.9, sample_size_v1=0, sample_size_v2=0, ppl=2.13, wps=565.2, ups=0.53, wpb=1057.9, bsz=32, num_updates=15010, lr=2.26952e-05, gnorm=2.761, clip=100, loss_scale=128, train_wall=19, gb_free=11.6, wall=28201
2023-05-26 07:13:25 - progress_bar.py[line:272] - INFO: epoch 009:   1189 / 1732 loss=2.325, loss_v1=0, loss_v2=0, nll_loss=1.119, ntokens=993.6, nsentences=32, sample_size=993.6, sample_size_v1=0, sample_size_v2=0, ppl=2.17, wps=529, ups=0.53, wpb=993.6, bsz=32, num_updates=15020, lr=2.2689e-05, gnorm=2.714, clip=100, loss_scale=128, train_wall=19, gb_free=11, wall=28220
2023-05-26 07:13:44 - progress_bar.py[line:272] - INFO: epoch 009:   1199 / 1732 loss=2.307, loss_v1=0, loss_v2=0, nll_loss=1.099, ntokens=1103.9, nsentences=32, sample_size=1103.9, sample_size_v1=0, sample_size_v2=0, ppl=2.14, wps=585.4, ups=0.53, wpb=1103.9, bsz=32, num_updates=15030, lr=2.26829e-05, gnorm=2.666, clip=100, loss_scale=128, train_wall=19, gb_free=10.8, wall=28238
2023-05-26 07:14:03 - progress_bar.py[line:272] - INFO: epoch 009:   1209 / 1732 loss=2.303, loss_v1=0, loss_v2=0, nll_loss=1.094, ntokens=1079.5, nsentences=32, sample_size=1079.5, sample_size_v1=0, sample_size_v2=0, ppl=2.14, wps=569.7, ups=0.53, wpb=1079.5, bsz=32, num_updates=15040, lr=2.26767e-05, gnorm=2.628, clip=100, loss_scale=128, train_wall=19, gb_free=11.2, wall=28257
2023-05-26 07:14:21 - progress_bar.py[line:272] - INFO: epoch 009:   1219 / 1732 loss=2.358, loss_v1=0, loss_v2=0, nll_loss=1.159, ntokens=1009.3, nsentences=32, sample_size=1009.3, sample_size_v1=0, sample_size_v2=0, ppl=2.23, wps=540.4, ups=0.54, wpb=1009.3, bsz=32, num_updates=15050, lr=2.26706e-05, gnorm=2.923, clip=100, loss_scale=128, train_wall=19, gb_free=11.3, wall=28276
2023-05-26 07:14:40 - progress_bar.py[line:272] - INFO: epoch 009:   1229 / 1732 loss=2.317, loss_v1=0, loss_v2=0, nll_loss=1.109, ntokens=1052.5, nsentences=32, sample_size=1052.5, sample_size_v1=0, sample_size_v2=0, ppl=2.16, wps=561.8, ups=0.53, wpb=1052.5, bsz=32, num_updates=15060, lr=2.26645e-05, gnorm=2.567, clip=100, loss_scale=128, train_wall=19, gb_free=11.1, wall=28295
2023-05-26 07:14:59 - progress_bar.py[line:272] - INFO: epoch 009:   1239 / 1732 loss=2.282, loss_v1=0, loss_v2=0, nll_loss=1.071, ntokens=1065.1, nsentences=32, sample_size=1065.1, sample_size_v1=0, sample_size_v2=0, ppl=2.1, wps=565.2, ups=0.53, wpb=1065.1, bsz=32, num_updates=15070, lr=2.26583e-05, gnorm=2.544, clip=100, loss_scale=128, train_wall=19, gb_free=10.7, wall=28314
2023-05-26 07:15:18 - progress_bar.py[line:272] - INFO: epoch 009:   1249 / 1732 loss=2.284, loss_v1=0, loss_v2=0, nll_loss=1.073, ntokens=1065.4, nsentences=32, sample_size=1065.4, sample_size_v1=0, sample_size_v2=0, ppl=2.1, wps=565.8, ups=0.53, wpb=1065.4, bsz=32, num_updates=15080, lr=2.26522e-05, gnorm=2.771, clip=100, loss_scale=128, train_wall=19, gb_free=11.5, wall=28332
2023-05-26 07:15:37 - progress_bar.py[line:272] - INFO: epoch 009:   1259 / 1732 loss=2.305, loss_v1=0, loss_v2=0, nll_loss=1.096, ntokens=1045.9, nsentences=32, sample_size=1045.9, sample_size_v1=0, sample_size_v2=0, ppl=2.14, wps=555.4, ups=0.53, wpb=1045.9, bsz=32, num_updates=15090, lr=2.2646e-05, gnorm=2.612, clip=100, loss_scale=128, train_wall=19, gb_free=11.5, wall=28351
2023-05-26 07:15:55 - progress_bar.py[line:272] - INFO: epoch 009:   1269 / 1732 loss=2.325, loss_v1=0, loss_v2=0, nll_loss=1.121, ntokens=1069.2, nsentences=32, sample_size=1069.2, sample_size_v1=0, sample_size_v2=0, ppl=2.18, wps=568.1, ups=0.53, wpb=1069.2, bsz=32, num_updates=15100, lr=2.26399e-05, gnorm=2.656, clip=100, loss_scale=128, train_wall=19, gb_free=11.4, wall=28370
2023-05-26 07:16:14 - progress_bar.py[line:272] - INFO: epoch 009:   1279 / 1732 loss=2.316, loss_v1=0, loss_v2=0, nll_loss=1.107, ntokens=1067, nsentences=32, sample_size=1067, sample_size_v1=0, sample_size_v2=0, ppl=2.15, wps=564.5, ups=0.53, wpb=1067, bsz=32, num_updates=15110, lr=2.26337e-05, gnorm=2.696, clip=100, loss_scale=128, train_wall=19, gb_free=10.9, wall=28389
2023-05-26 07:16:33 - progress_bar.py[line:272] - INFO: epoch 009:   1289 / 1732 loss=2.311, loss_v1=0, loss_v2=0, nll_loss=1.102, ntokens=1071, nsentences=32, sample_size=1071, sample_size_v1=0, sample_size_v2=0, ppl=2.15, wps=565.6, ups=0.53, wpb=1071, bsz=32, num_updates=15120, lr=2.26276e-05, gnorm=2.733, clip=100, loss_scale=128, train_wall=19, gb_free=10.4, wall=28408
2023-05-26 07:16:52 - progress_bar.py[line:272] - INFO: epoch 009:   1299 / 1732 loss=2.31, loss_v1=0, loss_v2=0, nll_loss=1.104, ntokens=1078.1, nsentences=32, sample_size=1078.1, sample_size_v1=0, sample_size_v2=0, ppl=2.15, wps=574.5, ups=0.53, wpb=1078.1, bsz=32, num_updates=15130, lr=2.26215e-05, gnorm=2.568, clip=100, loss_scale=128, train_wall=19, gb_free=11.4, wall=28427
2023-05-26 07:17:11 - progress_bar.py[line:272] - INFO: epoch 009:   1309 / 1732 loss=2.355, loss_v1=0, loss_v2=0, nll_loss=1.152, ntokens=1085.2, nsentences=32, sample_size=1085.2, sample_size_v1=0, sample_size_v2=0, ppl=2.22, wps=570.5, ups=0.53, wpb=1085.2, bsz=32, num_updates=15140, lr=2.26153e-05, gnorm=2.933, clip=100, loss_scale=128, train_wall=19, gb_free=10.9, wall=28446
2023-05-26 07:17:30 - progress_bar.py[line:272] - INFO: epoch 009:   1319 / 1732 loss=2.305, loss_v1=0, loss_v2=0, nll_loss=1.097, ntokens=1092.6, nsentences=32, sample_size=1092.6, sample_size_v1=0, sample_size_v2=0, ppl=2.14, wps=578.6, ups=0.53, wpb=1092.6, bsz=32, num_updates=15150, lr=2.26092e-05, gnorm=2.695, clip=100, loss_scale=128, train_wall=19, gb_free=10.9, wall=28465
2023-05-26 07:17:49 - progress_bar.py[line:272] - INFO: epoch 009:   1329 / 1732 loss=2.286, loss_v1=0, loss_v2=0, nll_loss=1.076, ntokens=1106.3, nsentences=32, sample_size=1106.3, sample_size_v1=0, sample_size_v2=0, ppl=2.11, wps=582.3, ups=0.53, wpb=1106.3, bsz=32, num_updates=15160, lr=2.2603e-05, gnorm=2.659, clip=100, loss_scale=128, train_wall=19, gb_free=11.3, wall=28484
2023-05-26 07:18:08 - progress_bar.py[line:272] - INFO: epoch 009:   1339 / 1732 loss=2.299, loss_v1=0, loss_v2=0, nll_loss=1.088, ntokens=1120.5, nsentences=32, sample_size=1120.5, sample_size_v1=0, sample_size_v2=0, ppl=2.13, wps=594.4, ups=0.53, wpb=1120.5, bsz=32, num_updates=15170, lr=2.25969e-05, gnorm=2.79, clip=100, loss_scale=128, train_wall=19, gb_free=11, wall=28502
2023-05-26 07:18:27 - progress_bar.py[line:272] - INFO: epoch 009:   1349 / 1732 loss=2.296, loss_v1=0, loss_v2=0, nll_loss=1.088, ntokens=1187.2, nsentences=32, sample_size=1187.2, sample_size_v1=0, sample_size_v2=0, ppl=2.13, wps=625, ups=0.53, wpb=1187.2, bsz=32, num_updates=15180, lr=2.25907e-05, gnorm=2.587, clip=100, loss_scale=128, train_wall=19, gb_free=11.3, wall=28521
2023-05-26 07:18:46 - progress_bar.py[line:272] - INFO: epoch 009:   1359 / 1732 loss=2.276, loss_v1=0, loss_v2=0, nll_loss=1.064, ntokens=1104.5, nsentences=32, sample_size=1104.5, sample_size_v1=0, sample_size_v2=0, ppl=2.09, wps=584.4, ups=0.53, wpb=1104.5, bsz=32, num_updates=15190, lr=2.25846e-05, gnorm=2.737, clip=100, loss_scale=128, train_wall=19, gb_free=11.2, wall=28540
2023-05-26 07:19:05 - progress_bar.py[line:272] - INFO: epoch 009:   1369 / 1732 loss=2.329, loss_v1=0, loss_v2=0, nll_loss=1.122, ntokens=1096, nsentences=32, sample_size=1096, sample_size_v1=0, sample_size_v2=0, ppl=2.18, wps=579.9, ups=0.53, wpb=1096, bsz=32, num_updates=15200, lr=2.25785e-05, gnorm=2.691, clip=100, loss_scale=128, train_wall=19, gb_free=11.2, wall=28559
2023-05-26 07:19:23 - progress_bar.py[line:272] - INFO: epoch 009:   1379 / 1732 loss=2.333, loss_v1=0, loss_v2=0, nll_loss=1.129, ntokens=1115.7, nsentences=32, sample_size=1115.7, sample_size_v1=0, sample_size_v2=0, ppl=2.19, wps=596, ups=0.53, wpb=1115.7, bsz=32, num_updates=15210, lr=2.25723e-05, gnorm=2.854, clip=100, loss_scale=128, train_wall=19, gb_free=11.4, wall=28578
2023-05-26 07:19:42 - progress_bar.py[line:272] - INFO: epoch 009:   1389 / 1732 loss=2.307, loss_v1=0, loss_v2=0, nll_loss=1.099, ntokens=1122.1, nsentences=32, sample_size=1122.1, sample_size_v1=0, sample_size_v2=0, ppl=2.14, wps=597.9, ups=0.53, wpb=1122.1, bsz=32, num_updates=15220, lr=2.25662e-05, gnorm=2.723, clip=100, loss_scale=128, train_wall=19, gb_free=11.5, wall=28597
2023-05-26 07:20:01 - progress_bar.py[line:272] - INFO: epoch 009:   1399 / 1732 loss=2.29, loss_v1=0, loss_v2=0, nll_loss=1.08, ntokens=1113, nsentences=32, sample_size=1113, sample_size_v1=0, sample_size_v2=0, ppl=2.11, wps=590.3, ups=0.53, wpb=1113, bsz=32, num_updates=15230, lr=2.256e-05, gnorm=2.497, clip=100, loss_scale=128, train_wall=19, gb_free=11.1, wall=28616
2023-05-26 07:20:20 - progress_bar.py[line:272] - INFO: epoch 009:   1409 / 1732 loss=2.333, loss_v1=0, loss_v2=0, nll_loss=1.127, ntokens=1156.6, nsentences=32, sample_size=1156.6, sample_size_v1=0, sample_size_v2=0, ppl=2.18, wps=612.1, ups=0.53, wpb=1156.6, bsz=32, num_updates=15240, lr=2.25539e-05, gnorm=2.683, clip=100, loss_scale=128, train_wall=19, gb_free=11.1, wall=28635
2023-05-26 07:20:39 - progress_bar.py[line:272] - INFO: epoch 009:   1419 / 1732 loss=2.328, loss_v1=0, loss_v2=0, nll_loss=1.125, ntokens=1290.6, nsentences=32, sample_size=1290.6, sample_size_v1=0, sample_size_v2=0, ppl=2.18, wps=674.9, ups=0.52, wpb=1290.6, bsz=32, num_updates=15250, lr=2.25478e-05, gnorm=2.588, clip=100, loss_scale=128, train_wall=19, gb_free=10.5, wall=28654
2023-05-26 07:20:58 - progress_bar.py[line:272] - INFO: epoch 009:   1429 / 1732 loss=2.288, loss_v1=0, loss_v2=0, nll_loss=1.077, ntokens=1226.2, nsentences=32, sample_size=1226.2, sample_size_v1=0, sample_size_v2=0, ppl=2.11, wps=646.8, ups=0.53, wpb=1226.2, bsz=32, num_updates=15260, lr=2.25416e-05, gnorm=2.571, clip=100, loss_scale=128, train_wall=19, gb_free=11.2, wall=28673
2023-05-26 07:21:17 - progress_bar.py[line:272] - INFO: epoch 009:   1439 / 1732 loss=2.29, loss_v1=0, loss_v2=0, nll_loss=1.083, ntokens=1192.7, nsentences=32, sample_size=1192.7, sample_size_v1=0, sample_size_v2=0, ppl=2.12, wps=629.2, ups=0.53, wpb=1192.7, bsz=32, num_updates=15270, lr=2.25355e-05, gnorm=2.476, clip=100, loss_scale=128, train_wall=19, gb_free=11, wall=28692
2023-05-26 07:21:36 - progress_bar.py[line:272] - INFO: epoch 009:   1449 / 1732 loss=2.314, loss_v1=0, loss_v2=0, nll_loss=1.106, ntokens=1089.5, nsentences=32, sample_size=1089.5, sample_size_v1=0, sample_size_v2=0, ppl=2.15, wps=580.1, ups=0.53, wpb=1089.5, bsz=32, num_updates=15280, lr=2.25293e-05, gnorm=2.769, clip=100, loss_scale=256, train_wall=19, gb_free=11.4, wall=28710
2023-05-26 07:21:55 - progress_bar.py[line:272] - INFO: epoch 009:   1459 / 1732 loss=2.291, loss_v1=0, loss_v2=0, nll_loss=1.081, ntokens=1160, nsentences=32, sample_size=1160, sample_size_v1=0, sample_size_v2=0, ppl=2.12, wps=611.9, ups=0.53, wpb=1160, bsz=32, num_updates=15290, lr=2.25232e-05, gnorm=2.443, clip=100, loss_scale=256, train_wall=19, gb_free=11.1, wall=28729
2023-05-26 07:22:14 - progress_bar.py[line:272] - INFO: epoch 009:   1469 / 1732 loss=2.3, loss_v1=0, loss_v2=0, nll_loss=1.091, ntokens=1187.1, nsentences=32, sample_size=1187.1, sample_size_v1=0, sample_size_v2=0, ppl=2.13, wps=624.9, ups=0.53, wpb=1187.1, bsz=32, num_updates=15300, lr=2.2517e-05, gnorm=2.737, clip=100, loss_scale=256, train_wall=19, gb_free=11.3, wall=28748
2023-05-26 07:22:32 - progress_bar.py[line:272] - INFO: epoch 009:   1479 / 1732 loss=2.323, loss_v1=0, loss_v2=0, nll_loss=1.116, ntokens=1029.5, nsentences=32, sample_size=1029.5, sample_size_v1=0, sample_size_v2=0, ppl=2.17, wps=547.2, ups=0.53, wpb=1029.5, bsz=32, num_updates=15310, lr=2.25109e-05, gnorm=2.721, clip=100, loss_scale=256, train_wall=19, gb_free=11.1, wall=28767
2023-05-26 07:22:51 - progress_bar.py[line:272] - INFO: epoch 009:   1489 / 1732 loss=2.319, loss_v1=0, loss_v2=0, nll_loss=1.112, ntokens=1147, nsentences=32, sample_size=1147, sample_size_v1=0, sample_size_v2=0, ppl=2.16, wps=607.8, ups=0.53, wpb=1147, bsz=32, num_updates=15320, lr=2.25048e-05, gnorm=2.432, clip=100, loss_scale=256, train_wall=19, gb_free=11.3, wall=28786
2023-05-26 07:23:10 - progress_bar.py[line:272] - INFO: epoch 009:   1499 / 1732 loss=2.293, loss_v1=0, loss_v2=0, nll_loss=1.083, ntokens=1095.4, nsentences=32, sample_size=1095.4, sample_size_v1=0, sample_size_v2=0, ppl=2.12, wps=581.2, ups=0.53, wpb=1095.4, bsz=32, num_updates=15330, lr=2.24986e-05, gnorm=2.507, clip=100, loss_scale=256, train_wall=19, gb_free=10.8, wall=28805
2023-05-26 07:23:29 - progress_bar.py[line:272] - INFO: epoch 009:   1509 / 1732 loss=2.265, loss_v1=0, loss_v2=0, nll_loss=1.055, ntokens=1114.3, nsentences=32, sample_size=1114.3, sample_size_v1=0, sample_size_v2=0, ppl=2.08, wps=592.6, ups=0.53, wpb=1114.3, bsz=32, num_updates=15340, lr=2.24925e-05, gnorm=2.609, clip=100, loss_scale=256, train_wall=19, gb_free=11.4, wall=28824
2023-05-26 07:23:48 - progress_bar.py[line:272] - INFO: epoch 009:   1519 / 1732 loss=2.329, loss_v1=0, loss_v2=0, nll_loss=1.121, ntokens=1050.9, nsentences=32, sample_size=1050.9, sample_size_v1=0, sample_size_v2=0, ppl=2.18, wps=559.8, ups=0.53, wpb=1050.9, bsz=32, num_updates=15350, lr=2.24863e-05, gnorm=2.678, clip=100, loss_scale=256, train_wall=19, gb_free=11.4, wall=28842
2023-05-26 07:24:07 - progress_bar.py[line:272] - INFO: epoch 009:   1529 / 1732 loss=2.34, loss_v1=0, loss_v2=0, nll_loss=1.138, ntokens=1056.3, nsentences=32, sample_size=1056.3, sample_size_v1=0, sample_size_v2=0, ppl=2.2, wps=562.7, ups=0.53, wpb=1056.3, bsz=32, num_updates=15360, lr=2.24802e-05, gnorm=2.82, clip=100, loss_scale=256, train_wall=19, gb_free=10.8, wall=28861
2023-05-26 07:24:26 - progress_bar.py[line:272] - INFO: epoch 009:   1539 / 1732 loss=2.31, loss_v1=0, loss_v2=0, nll_loss=1.101, ntokens=1083.3, nsentences=32, sample_size=1083.3, sample_size_v1=0, sample_size_v2=0, ppl=2.14, wps=571.6, ups=0.53, wpb=1083.3, bsz=32, num_updates=15370, lr=2.2474e-05, gnorm=2.552, clip=100, loss_scale=256, train_wall=19, gb_free=11, wall=28880
2023-05-26 07:24:44 - progress_bar.py[line:272] - INFO: epoch 009:   1549 / 1732 loss=2.277, loss_v1=0, loss_v2=0, nll_loss=1.067, ntokens=1075, nsentences=32, sample_size=1075, sample_size_v1=0, sample_size_v2=0, ppl=2.09, wps=571.6, ups=0.53, wpb=1075, bsz=32, num_updates=15380, lr=2.24679e-05, gnorm=2.556, clip=100, loss_scale=256, train_wall=19, gb_free=11.4, wall=28899
2023-05-26 07:25:03 - progress_bar.py[line:272] - INFO: epoch 009:   1559 / 1732 loss=2.294, loss_v1=0, loss_v2=0, nll_loss=1.084, ntokens=1092, nsentences=32, sample_size=1092, sample_size_v1=0, sample_size_v2=0, ppl=2.12, wps=580.2, ups=0.53, wpb=1092, bsz=32, num_updates=15390, lr=2.24618e-05, gnorm=2.42, clip=100, loss_scale=256, train_wall=19, gb_free=11.3, wall=28918
2023-05-26 07:25:22 - progress_bar.py[line:272] - INFO: epoch 009:   1569 / 1732 loss=2.337, loss_v1=0, loss_v2=0, nll_loss=1.133, ntokens=1059.1, nsentences=32, sample_size=1059.1, sample_size_v1=0, sample_size_v2=0, ppl=2.19, wps=561.5, ups=0.53, wpb=1059.1, bsz=32, num_updates=15400, lr=2.24556e-05, gnorm=2.673, clip=100, loss_scale=256, train_wall=19, gb_free=10.7, wall=28937
2023-05-26 07:25:41 - progress_bar.py[line:272] - INFO: epoch 009:   1579 / 1732 loss=2.33, loss_v1=0, loss_v2=0, nll_loss=1.125, ntokens=1008.7, nsentences=32, sample_size=1008.7, sample_size_v1=0, sample_size_v2=0, ppl=2.18, wps=537.9, ups=0.53, wpb=1008.7, bsz=32, num_updates=15410, lr=2.24495e-05, gnorm=2.726, clip=100, loss_scale=256, train_wall=19, gb_free=11.2, wall=28955
2023-05-26 07:26:00 - progress_bar.py[line:272] - INFO: epoch 009:   1589 / 1732 loss=2.319, loss_v1=0, loss_v2=0, nll_loss=1.112, ntokens=1092.2, nsentences=32, sample_size=1092.2, sample_size_v1=0, sample_size_v2=0, ppl=2.16, wps=578, ups=0.53, wpb=1092.2, bsz=32, num_updates=15420, lr=2.24433e-05, gnorm=2.48, clip=100, loss_scale=256, train_wall=19, gb_free=11.4, wall=28974
2023-05-26 07:26:18 - progress_bar.py[line:272] - INFO: epoch 009:   1599 / 1732 loss=2.285, loss_v1=0, loss_v2=0, nll_loss=1.074, ntokens=1061.1, nsentences=32, sample_size=1061.1, sample_size_v1=0, sample_size_v2=0, ppl=2.11, wps=564.3, ups=0.53, wpb=1061.1, bsz=32, num_updates=15430, lr=2.24372e-05, gnorm=2.55, clip=100, loss_scale=256, train_wall=19, gb_free=11.3, wall=28993
2023-05-26 07:26:37 - progress_bar.py[line:272] - INFO: epoch 009:   1609 / 1732 loss=2.28, loss_v1=0, loss_v2=0, nll_loss=1.069, ntokens=1155.5, nsentences=32, sample_size=1155.5, sample_size_v1=0, sample_size_v2=0, ppl=2.1, wps=609.1, ups=0.53, wpb=1155.5, bsz=32, num_updates=15440, lr=2.24311e-05, gnorm=2.497, clip=100, loss_scale=256, train_wall=19, gb_free=10.9, wall=29012
2023-05-26 07:26:56 - progress_bar.py[line:272] - INFO: epoch 009:   1619 / 1732 loss=2.267, loss_v1=0, loss_v2=0, nll_loss=1.055, ntokens=1123.8, nsentences=32, sample_size=1123.8, sample_size_v1=0, sample_size_v2=0, ppl=2.08, wps=594.5, ups=0.53, wpb=1123.8, bsz=32, num_updates=15450, lr=2.24249e-05, gnorm=2.547, clip=100, loss_scale=256, train_wall=19, gb_free=10.9, wall=29031
2023-05-26 07:27:15 - progress_bar.py[line:272] - INFO: epoch 009:   1629 / 1732 loss=2.303, loss_v1=0, loss_v2=0, nll_loss=1.096, ntokens=1172.3, nsentences=32, sample_size=1172.3, sample_size_v1=0, sample_size_v2=0, ppl=2.14, wps=615.7, ups=0.53, wpb=1172.3, bsz=32, num_updates=15460, lr=2.24188e-05, gnorm=2.518, clip=100, loss_scale=256, train_wall=19, gb_free=11.2, wall=29050
2023-05-26 07:27:34 - progress_bar.py[line:272] - INFO: epoch 009:   1639 / 1732 loss=2.278, loss_v1=0, loss_v2=0, nll_loss=1.065, ntokens=1139.8, nsentences=32, sample_size=1139.8, sample_size_v1=0, sample_size_v2=0, ppl=2.09, wps=606.4, ups=0.53, wpb=1139.8, bsz=32, num_updates=15470, lr=2.24126e-05, gnorm=2.63, clip=100, loss_scale=256, train_wall=19, gb_free=10.8, wall=29069
2023-05-26 07:27:53 - progress_bar.py[line:272] - INFO: epoch 009:   1649 / 1732 loss=2.276, loss_v1=0, loss_v2=0, nll_loss=1.066, ntokens=1200.9, nsentences=32, sample_size=1200.9, sample_size_v1=0, sample_size_v2=0, ppl=2.09, wps=632.5, ups=0.53, wpb=1200.9, bsz=32, num_updates=15480, lr=2.24065e-05, gnorm=2.411, clip=100, loss_scale=256, train_wall=19, gb_free=11.3, wall=29088
2023-05-26 07:28:12 - progress_bar.py[line:272] - INFO: epoch 009:   1659 / 1732 loss=2.337, loss_v1=0, loss_v2=0, nll_loss=1.132, ntokens=965.2, nsentences=32, sample_size=965.2, sample_size_v1=0, sample_size_v2=0, ppl=2.19, wps=515.3, ups=0.53, wpb=965.2, bsz=32, num_updates=15490, lr=2.24003e-05, gnorm=2.992, clip=100, loss_scale=256, train_wall=19, gb_free=11.1, wall=29107
2023-05-26 07:28:31 - progress_bar.py[line:272] - INFO: epoch 009:   1669 / 1732 loss=2.303, loss_v1=0, loss_v2=0, nll_loss=1.092, ntokens=1018.2, nsentences=32, sample_size=1018.2, sample_size_v1=0, sample_size_v2=0, ppl=2.13, wps=543.8, ups=0.53, wpb=1018.2, bsz=32, num_updates=15500, lr=2.23942e-05, gnorm=2.785, clip=100, loss_scale=256, train_wall=19, gb_free=11.8, wall=29125
2023-05-26 07:28:50 - progress_bar.py[line:272] - INFO: epoch 009:   1679 / 1732 loss=2.258, loss_v1=0, loss_v2=0, nll_loss=1.044, ntokens=1155.9, nsentences=32, sample_size=1155.9, sample_size_v1=0, sample_size_v2=0, ppl=2.06, wps=607.1, ups=0.53, wpb=1155.9, bsz=32, num_updates=15510, lr=2.23881e-05, gnorm=2.502, clip=100, loss_scale=256, train_wall=19, gb_free=10.8, wall=29144
2023-05-26 07:29:09 - progress_bar.py[line:272] - INFO: epoch 009:   1689 / 1732 loss=2.289, loss_v1=0, loss_v2=0, nll_loss=1.08, ntokens=1198.6, nsentences=32, sample_size=1198.6, sample_size_v1=0, sample_size_v2=0, ppl=2.11, wps=629, ups=0.52, wpb=1198.6, bsz=32, num_updates=15520, lr=2.23819e-05, gnorm=2.515, clip=100, loss_scale=256, train_wall=19, gb_free=10.4, wall=29163
2023-05-26 07:29:28 - progress_bar.py[line:272] - INFO: epoch 009:   1699 / 1732 loss=2.272, loss_v1=0, loss_v2=0, nll_loss=1.059, ntokens=1300, nsentences=32, sample_size=1300, sample_size_v1=0, sample_size_v2=0, ppl=2.08, wps=675.5, ups=0.52, wpb=1300, bsz=32, num_updates=15530, lr=2.23758e-05, gnorm=2.082, clip=100, loss_scale=256, train_wall=19, gb_free=11.1, wall=29183
2023-05-26 07:29:47 - progress_bar.py[line:272] - INFO: epoch 009:   1709 / 1732 loss=2.313, loss_v1=0, loss_v2=0, nll_loss=1.107, ntokens=1178.3, nsentences=32, sample_size=1178.3, sample_size_v1=0, sample_size_v2=0, ppl=2.15, wps=623, ups=0.53, wpb=1178.3, bsz=32, num_updates=15540, lr=2.23696e-05, gnorm=2.391, clip=100, loss_scale=256, train_wall=19, gb_free=11.3, wall=29202
2023-05-26 07:30:06 - progress_bar.py[line:272] - INFO: epoch 009:   1719 / 1732 loss=2.273, loss_v1=0, loss_v2=0, nll_loss=1.061, ntokens=1171.3, nsentences=32, sample_size=1171.3, sample_size_v1=0, sample_size_v2=0, ppl=2.09, wps=614.2, ups=0.52, wpb=1171.3, bsz=32, num_updates=15550, lr=2.23635e-05, gnorm=2.336, clip=100, loss_scale=256, train_wall=19, gb_free=10.9, wall=29221
2023-05-26 07:30:25 - progress_bar.py[line:272] - INFO: epoch 009:   1729 / 1732 loss=2.326, loss_v1=0, loss_v2=0, nll_loss=1.121, ntokens=1095.7, nsentences=32, sample_size=1095.7, sample_size_v1=0, sample_size_v2=0, ppl=2.17, wps=574.4, ups=0.52, wpb=1095.7, bsz=32, num_updates=15560, lr=2.23573e-05, gnorm=2.508, clip=100, loss_scale=256, train_wall=19, gb_free=10.8, wall=29240
2023-05-26 07:30:29 - train.py[line:332] - INFO: end of epoch 9 (average epoch stats below)
2023-05-26 07:30:29 - progress_bar.py[line:282] - INFO: epoch 009 | loss 2.313 | loss_v1 0 | loss_v2 0 | nll_loss 1.106 | ntokens 1051.59 | nsentences 31.986 | sample_size 1051.59 | sample_size_v1 0 | sample_size_v2 0 | ppl 2.15 | wps 560 | ups 0.53 | wpb 1051.6 | bsz 32 | num_updates 15563 | lr 2.23555e-05 | gnorm 2.636 | clip 99.9 | loss_scale 256 | train_wall 3241 | gb_free 11.7 | wall 29244
2023-05-26 07:30:29 - trainer.py[line:639] - INFO: loading train data for epoch 10
local datafile ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 0 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 0 finished initializing row_count and line_idx-to-offset mapping
file ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 0 row count 55400 total row count 55400
slice_id 0 seek offset 0
2023-05-26 07:30:31 - trainer.py[line:703] - INFO: begin training epoch 10
2023-05-26 07:30:31 - train.py[line:305] - INFO: Start iterating over samples
2023-05-26 07:30:45 - progress_bar.py[line:272] - INFO: epoch 010:      7 / 1732 loss=2.268, loss_v1=0, loss_v2=0, nll_loss=1.053, ntokens=1093.3, nsentences=29.6, sample_size=1093.3, sample_size_v1=0, sample_size_v2=0, ppl=2.08, wps=556.6, ups=0.51, wpb=1093.3, bsz=29.6, num_updates=15570, lr=2.23512e-05, gnorm=2.702, clip=100, loss_scale=256, train_wall=18, gb_free=11.2, wall=29259
2023-05-26 07:31:04 - progress_bar.py[line:272] - INFO: epoch 010:     17 / 1732 loss=2.235, loss_v1=0, loss_v2=0, nll_loss=1.021, ntokens=1095.7, nsentences=32, sample_size=1095.7, sample_size_v1=0, sample_size_v2=0, ppl=2.03, wps=579.6, ups=0.53, wpb=1095.7, bsz=32, num_updates=15580, lr=2.23451e-05, gnorm=2.283, clip=100, loss_scale=256, train_wall=19, gb_free=11, wall=29278
2023-05-26 07:31:22 - progress_bar.py[line:272] - INFO: epoch 010:     27 / 1732 loss=2.271, loss_v1=0, loss_v2=0, nll_loss=1.057, ntokens=954.5, nsentences=32, sample_size=954.5, sample_size_v1=0, sample_size_v2=0, ppl=2.08, wps=507.6, ups=0.53, wpb=954.5, bsz=32, num_updates=15590, lr=2.23389e-05, gnorm=2.42, clip=100, loss_scale=256, train_wall=19, gb_free=10.7, wall=29297
2023-05-26 07:31:41 - progress_bar.py[line:272] - INFO: epoch 010:     37 / 1732 loss=2.12, loss_v1=0, loss_v2=0, nll_loss=0.893, ntokens=1179.3, nsentences=32, sample_size=1179.3, sample_size_v1=0, sample_size_v2=0, ppl=1.86, wps=621.1, ups=0.53, wpb=1179.3, bsz=32, num_updates=15600, lr=2.23328e-05, gnorm=2.063, clip=100, loss_scale=256, train_wall=19, gb_free=10.9, wall=29316
2023-05-26 07:32:00 - progress_bar.py[line:272] - INFO: epoch 010:     47 / 1732 loss=2.15, loss_v1=0, loss_v2=0, nll_loss=0.923, ntokens=1055.1, nsentences=32, sample_size=1055.1, sample_size_v1=0, sample_size_v2=0, ppl=1.9, wps=560.4, ups=0.53, wpb=1055.1, bsz=32, num_updates=15610, lr=2.23266e-05, gnorm=2.321, clip=90, loss_scale=256, train_wall=19, gb_free=10.8, wall=29335
2023-05-26 07:32:19 - progress_bar.py[line:272] - INFO: epoch 010:     57 / 1732 loss=2.075, loss_v1=0, loss_v2=0, nll_loss=0.844, ntokens=1048.7, nsentences=32, sample_size=1048.7, sample_size_v1=0, sample_size_v2=0, ppl=1.79, wps=558.4, ups=0.53, wpb=1048.7, bsz=32, num_updates=15620, lr=2.23205e-05, gnorm=2.355, clip=100, loss_scale=256, train_wall=19, gb_free=11.2, wall=29354
2023-05-26 07:32:38 - progress_bar.py[line:272] - INFO: epoch 010:     67 / 1732 loss=1.982, loss_v1=0, loss_v2=0, nll_loss=0.737, ntokens=1356.1, nsentences=32, sample_size=1356.1, sample_size_v1=0, sample_size_v2=0, ppl=1.67, wps=700.8, ups=0.52, wpb=1356.1, bsz=32, num_updates=15630, lr=2.23144e-05, gnorm=1.593, clip=100, loss_scale=256, train_wall=19, gb_free=10.3, wall=29373
2023-05-26 07:32:58 - progress_bar.py[line:272] - INFO: epoch 010:     77 / 1732 loss=2.092, loss_v1=0, loss_v2=0, nll_loss=0.86, ntokens=1273.9, nsentences=32, sample_size=1273.9, sample_size_v1=0, sample_size_v2=0, ppl=1.81, wps=657.5, ups=0.52, wpb=1273.9, bsz=32, num_updates=15640, lr=2.23082e-05, gnorm=2.178, clip=100, loss_scale=256, train_wall=19, gb_free=11.1, wall=29392
2023-05-26 07:33:17 - progress_bar.py[line:272] - INFO: epoch 010:     87 / 1732 loss=2.168, loss_v1=0, loss_v2=0, nll_loss=0.943, ntokens=1141.2, nsentences=32, sample_size=1141.2, sample_size_v1=0, sample_size_v2=0, ppl=1.92, wps=595.3, ups=0.52, wpb=1141.2, bsz=32, num_updates=15650, lr=2.23021e-05, gnorm=2.223, clip=100, loss_scale=256, train_wall=19, gb_free=10.6, wall=29412
2023-05-26 07:33:36 - progress_bar.py[line:272] - INFO: epoch 010:     97 / 1732 loss=2.125, loss_v1=0, loss_v2=0, nll_loss=0.897, ntokens=1080.1, nsentences=32, sample_size=1080.1, sample_size_v1=0, sample_size_v2=0, ppl=1.86, wps=569.8, ups=0.53, wpb=1080.1, bsz=32, num_updates=15660, lr=2.22959e-05, gnorm=2.275, clip=100, loss_scale=256, train_wall=19, gb_free=10.1, wall=29431
2023-05-26 07:33:55 - progress_bar.py[line:272] - INFO: epoch 010:    107 / 1732 loss=2.281, loss_v1=0, loss_v2=0, nll_loss=1.073, ntokens=981.4, nsentences=32, sample_size=981.4, sample_size_v1=0, sample_size_v2=0, ppl=2.1, wps=524.6, ups=0.53, wpb=981.4, bsz=32, num_updates=15670, lr=2.22898e-05, gnorm=2.709, clip=100, loss_scale=256, train_wall=19, gb_free=11, wall=29449
2023-05-26 07:34:14 - progress_bar.py[line:272] - INFO: epoch 010:    117 / 1732 loss=2.334, loss_v1=0, loss_v2=0, nll_loss=1.128, ntokens=1060.7, nsentences=32, sample_size=1060.7, sample_size_v1=0, sample_size_v2=0, ppl=2.19, wps=559.6, ups=0.53, wpb=1060.7, bsz=32, num_updates=15680, lr=2.22836e-05, gnorm=2.768, clip=100, loss_scale=256, train_wall=19, gb_free=10.6, wall=29468
2023-05-26 07:34:33 - progress_bar.py[line:272] - INFO: epoch 010:    127 / 1732 loss=2.272, loss_v1=0, loss_v2=0, nll_loss=1.06, ntokens=1185.5, nsentences=32, sample_size=1185.5, sample_size_v1=0, sample_size_v2=0, ppl=2.08, wps=615.7, ups=0.52, wpb=1185.5, bsz=32, num_updates=15690, lr=2.22775e-05, gnorm=2.43, clip=100, loss_scale=256, train_wall=19, gb_free=11.1, wall=29488
2023-05-26 07:34:35 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 128.0
2023-05-26 07:34:54 - progress_bar.py[line:272] - INFO: epoch 010:    138 / 1732 loss=2.238, loss_v1=0, loss_v2=0, nll_loss=1.022, ntokens=1228, nsentences=32, sample_size=1228, sample_size_v1=0, sample_size_v2=0, ppl=2.03, wps=585.9, ups=0.48, wpb=1228, bsz=32, num_updates=15700, lr=2.22714e-05, gnorm=2.484, clip=100, loss_scale=128, train_wall=21, gb_free=11, wall=29508
2023-05-26 07:35:13 - progress_bar.py[line:272] - INFO: epoch 010:    148 / 1732 loss=2.193, loss_v1=0, loss_v2=0, nll_loss=0.973, ntokens=1210.4, nsentences=32, sample_size=1210.4, sample_size_v1=0, sample_size_v2=0, ppl=1.96, wps=627.6, ups=0.52, wpb=1210.4, bsz=32, num_updates=15710, lr=2.22652e-05, gnorm=2.117, clip=100, loss_scale=128, train_wall=19, gb_free=10.6, wall=29528
2023-05-26 07:35:32 - progress_bar.py[line:272] - INFO: epoch 010:    158 / 1732 loss=2.244, loss_v1=0, loss_v2=0, nll_loss=1.028, ntokens=1139, nsentences=32, sample_size=1139, sample_size_v1=0, sample_size_v2=0, ppl=2.04, wps=593.1, ups=0.52, wpb=1139, bsz=32, num_updates=15720, lr=2.22591e-05, gnorm=2.28, clip=100, loss_scale=128, train_wall=19, gb_free=11.2, wall=29547
2023-05-26 07:35:51 - progress_bar.py[line:272] - INFO: epoch 010:    168 / 1732 loss=2.225, loss_v1=0, loss_v2=0, nll_loss=1.009, ntokens=1015.2, nsentences=32, sample_size=1015.2, sample_size_v1=0, sample_size_v2=0, ppl=2.01, wps=537.3, ups=0.53, wpb=1015.2, bsz=32, num_updates=15730, lr=2.22529e-05, gnorm=2.701, clip=100, loss_scale=128, train_wall=19, gb_free=11.4, wall=29566
2023-05-26 07:36:10 - progress_bar.py[line:272] - INFO: epoch 010:    178 / 1732 loss=2.224, loss_v1=0, loss_v2=0, nll_loss=1.006, ntokens=1025.5, nsentences=32, sample_size=1025.5, sample_size_v1=0, sample_size_v2=0, ppl=2.01, wps=541.6, ups=0.53, wpb=1025.5, bsz=32, num_updates=15740, lr=2.22468e-05, gnorm=2.547, clip=100, loss_scale=128, train_wall=19, gb_free=11, wall=29585
2023-05-26 07:36:29 - progress_bar.py[line:272] - INFO: epoch 010:    188 / 1732 loss=2.188, loss_v1=0, loss_v2=0, nll_loss=0.966, ntokens=1150.5, nsentences=32, sample_size=1150.5, sample_size_v1=0, sample_size_v2=0, ppl=1.95, wps=602.2, ups=0.52, wpb=1150.5, bsz=32, num_updates=15750, lr=2.22406e-05, gnorm=2.208, clip=100, loss_scale=128, train_wall=19, gb_free=11.1, wall=29604
2023-05-26 07:36:48 - progress_bar.py[line:272] - INFO: epoch 010:    198 / 1732 loss=2.244, loss_v1=0, loss_v2=0, nll_loss=1.03, ntokens=1142.2, nsentences=32, sample_size=1142.2, sample_size_v1=0, sample_size_v2=0, ppl=2.04, wps=601.3, ups=0.53, wpb=1142.2, bsz=32, num_updates=15760, lr=2.22345e-05, gnorm=2.502, clip=100, loss_scale=128, train_wall=19, gb_free=11, wall=29623
2023-05-26 07:37:07 - progress_bar.py[line:272] - INFO: epoch 010:    208 / 1732 loss=2.331, loss_v1=0, loss_v2=0, nll_loss=1.127, ntokens=961.8, nsentences=32, sample_size=961.8, sample_size_v1=0, sample_size_v2=0, ppl=2.18, wps=518.8, ups=0.54, wpb=961.8, bsz=32, num_updates=15770, lr=2.22284e-05, gnorm=2.967, clip=100, loss_scale=128, train_wall=19, gb_free=11.1, wall=29641
2023-05-26 07:37:26 - progress_bar.py[line:272] - INFO: epoch 010:    218 / 1732 loss=2.329, loss_v1=0, loss_v2=0, nll_loss=1.122, ntokens=1149.2, nsentences=32, sample_size=1149.2, sample_size_v1=0, sample_size_v2=0, ppl=2.18, wps=613.4, ups=0.53, wpb=1149.2, bsz=32, num_updates=15780, lr=2.22222e-05, gnorm=2.613, clip=100, loss_scale=128, train_wall=19, gb_free=11.5, wall=29660
2023-05-26 07:37:44 - progress_bar.py[line:272] - INFO: epoch 010:    228 / 1732 loss=2.327, loss_v1=0, loss_v2=0, nll_loss=1.122, ntokens=1111.8, nsentences=32, sample_size=1111.8, sample_size_v1=0, sample_size_v2=0, ppl=2.18, wps=594.2, ups=0.53, wpb=1111.8, bsz=32, num_updates=15790, lr=2.22161e-05, gnorm=2.62, clip=100, loss_scale=128, train_wall=19, gb_free=11.6, wall=29679
2023-05-26 07:38:03 - progress_bar.py[line:272] - INFO: epoch 010:    238 / 1732 loss=2.368, loss_v1=0, loss_v2=0, nll_loss=1.166, ntokens=1085.4, nsentences=32, sample_size=1085.4, sample_size_v1=0, sample_size_v2=0, ppl=2.24, wps=579.7, ups=0.53, wpb=1085.4, bsz=32, num_updates=15800, lr=2.22099e-05, gnorm=2.58, clip=100, loss_scale=128, train_wall=19, gb_free=11.5, wall=29698
2023-05-26 07:38:22 - progress_bar.py[line:272] - INFO: epoch 010:    248 / 1732 loss=2.324, loss_v1=0, loss_v2=0, nll_loss=1.121, ntokens=1171.6, nsentences=32, sample_size=1171.6, sample_size_v1=0, sample_size_v2=0, ppl=2.17, wps=621.7, ups=0.53, wpb=1171.6, bsz=32, num_updates=15810, lr=2.22038e-05, gnorm=2.349, clip=100, loss_scale=128, train_wall=19, gb_free=11.3, wall=29716
2023-05-26 07:38:41 - progress_bar.py[line:272] - INFO: epoch 010:    258 / 1732 loss=2.348, loss_v1=0, loss_v2=0, nll_loss=1.145, ntokens=1118, nsentences=32, sample_size=1118, sample_size_v1=0, sample_size_v2=0, ppl=2.21, wps=595.2, ups=0.53, wpb=1118, bsz=32, num_updates=15820, lr=2.21977e-05, gnorm=2.669, clip=100, loss_scale=128, train_wall=19, gb_free=11.4, wall=29735
2023-05-26 07:38:59 - progress_bar.py[line:272] - INFO: epoch 010:    268 / 1732 loss=2.326, loss_v1=0, loss_v2=0, nll_loss=1.119, ntokens=1160.8, nsentences=32, sample_size=1160.8, sample_size_v1=0, sample_size_v2=0, ppl=2.17, wps=618.6, ups=0.53, wpb=1160.8, bsz=32, num_updates=15830, lr=2.21915e-05, gnorm=2.351, clip=100, loss_scale=128, train_wall=19, gb_free=11.6, wall=29754
2023-05-26 07:39:18 - progress_bar.py[line:272] - INFO: epoch 010:    278 / 1732 loss=2.339, loss_v1=0, loss_v2=0, nll_loss=1.136, ntokens=1136.9, nsentences=32, sample_size=1136.9, sample_size_v1=0, sample_size_v2=0, ppl=2.2, wps=603.1, ups=0.53, wpb=1136.9, bsz=32, num_updates=15840, lr=2.21854e-05, gnorm=2.73, clip=100, loss_scale=128, train_wall=19, gb_free=11.3, wall=29773
2023-05-26 07:39:37 - progress_bar.py[line:272] - INFO: epoch 010:    288 / 1732 loss=2.315, loss_v1=0, loss_v2=0, nll_loss=1.107, ntokens=1173.3, nsentences=32, sample_size=1173.3, sample_size_v1=0, sample_size_v2=0, ppl=2.15, wps=621, ups=0.53, wpb=1173.3, bsz=32, num_updates=15850, lr=2.21792e-05, gnorm=2.381, clip=100, loss_scale=128, train_wall=19, gb_free=11.2, wall=29792
2023-05-26 07:39:56 - progress_bar.py[line:272] - INFO: epoch 010:    298 / 1732 loss=2.329, loss_v1=0, loss_v2=0, nll_loss=1.126, ntokens=1074.2, nsentences=32, sample_size=1074.2, sample_size_v1=0, sample_size_v2=0, ppl=2.18, wps=575.3, ups=0.54, wpb=1074.2, bsz=32, num_updates=15860, lr=2.21731e-05, gnorm=2.757, clip=100, loss_scale=128, train_wall=19, gb_free=11.8, wall=29810
2023-05-26 07:40:15 - progress_bar.py[line:272] - INFO: epoch 010:    308 / 1732 loss=2.318, loss_v1=0, loss_v2=0, nll_loss=1.111, ntokens=1090.6, nsentences=32, sample_size=1090.6, sample_size_v1=0, sample_size_v2=0, ppl=2.16, wps=582.7, ups=0.53, wpb=1090.6, bsz=32, num_updates=15870, lr=2.21669e-05, gnorm=2.72, clip=100, loss_scale=128, train_wall=19, gb_free=11.7, wall=29829
2023-05-26 07:40:33 - progress_bar.py[line:272] - INFO: epoch 010:    318 / 1732 loss=2.333, loss_v1=0, loss_v2=0, nll_loss=1.128, ntokens=1026, nsentences=32, sample_size=1026, sample_size_v1=0, sample_size_v2=0, ppl=2.19, wps=550.3, ups=0.54, wpb=1026, bsz=32, num_updates=15880, lr=2.21608e-05, gnorm=2.967, clip=100, loss_scale=128, train_wall=19, gb_free=11.3, wall=29848
2023-05-26 07:40:52 - progress_bar.py[line:272] - INFO: epoch 010:    328 / 1732 loss=2.364, loss_v1=0, loss_v2=0, nll_loss=1.163, ntokens=1009.5, nsentences=32, sample_size=1009.5, sample_size_v1=0, sample_size_v2=0, ppl=2.24, wps=544.8, ups=0.54, wpb=1009.5, bsz=32, num_updates=15890, lr=2.21547e-05, gnorm=2.879, clip=100, loss_scale=128, train_wall=18, gb_free=11.7, wall=29866
2023-05-26 07:41:10 - progress_bar.py[line:272] - INFO: epoch 010:    338 / 1732 loss=2.323, loss_v1=0, loss_v2=0, nll_loss=1.117, ntokens=991.1, nsentences=32, sample_size=991.1, sample_size_v1=0, sample_size_v2=0, ppl=2.17, wps=535.3, ups=0.54, wpb=991.1, bsz=32, num_updates=15900, lr=2.21485e-05, gnorm=2.861, clip=100, loss_scale=128, train_wall=18, gb_free=11.7, wall=29885
2023-05-26 07:41:29 - progress_bar.py[line:272] - INFO: epoch 010:    348 / 1732 loss=2.324, loss_v1=0, loss_v2=0, nll_loss=1.118, ntokens=913.6, nsentences=32, sample_size=913.6, sample_size_v1=0, sample_size_v2=0, ppl=2.17, wps=494.8, ups=0.54, wpb=913.6, bsz=32, num_updates=15910, lr=2.21424e-05, gnorm=3.003, clip=100, loss_scale=128, train_wall=18, gb_free=11.6, wall=29903
2023-05-26 07:41:47 - progress_bar.py[line:272] - INFO: epoch 010:    358 / 1732 loss=2.361, loss_v1=0, loss_v2=0, nll_loss=1.158, ntokens=943, nsentences=32, sample_size=943, sample_size_v1=0, sample_size_v2=0, ppl=2.23, wps=509.5, ups=0.54, wpb=943, bsz=32, num_updates=15920, lr=2.21362e-05, gnorm=3.016, clip=100, loss_scale=128, train_wall=18, gb_free=11.9, wall=29922
2023-05-26 07:42:06 - progress_bar.py[line:272] - INFO: epoch 010:    368 / 1732 loss=2.361, loss_v1=0, loss_v2=0, nll_loss=1.157, ntokens=960.6, nsentences=32, sample_size=960.6, sample_size_v1=0, sample_size_v2=0, ppl=2.23, wps=517.4, ups=0.54, wpb=960.6, bsz=32, num_updates=15930, lr=2.21301e-05, gnorm=2.966, clip=100, loss_scale=128, train_wall=19, gb_free=11.5, wall=29940
2023-05-26 07:42:24 - progress_bar.py[line:272] - INFO: epoch 010:    378 / 1732 loss=2.368, loss_v1=0, loss_v2=0, nll_loss=1.169, ntokens=1043.2, nsentences=32, sample_size=1043.2, sample_size_v1=0, sample_size_v2=0, ppl=2.25, wps=562.5, ups=0.54, wpb=1043.2, bsz=32, num_updates=15940, lr=2.21239e-05, gnorm=2.677, clip=100, loss_scale=128, train_wall=19, gb_free=11.8, wall=29959
2023-05-26 07:42:43 - progress_bar.py[line:272] - INFO: epoch 010:    388 / 1732 loss=2.336, loss_v1=0, loss_v2=0, nll_loss=1.132, ntokens=1053.2, nsentences=32, sample_size=1053.2, sample_size_v1=0, sample_size_v2=0, ppl=2.19, wps=566.2, ups=0.54, wpb=1053.2, bsz=32, num_updates=15950, lr=2.21178e-05, gnorm=2.668, clip=100, loss_scale=128, train_wall=19, gb_free=11.1, wall=29978
2023-05-26 07:43:01 - progress_bar.py[line:272] - INFO: epoch 010:    398 / 1732 loss=2.35, loss_v1=0, loss_v2=0, nll_loss=1.147, ntokens=977.4, nsentences=32, sample_size=977.4, sample_size_v1=0, sample_size_v2=0, ppl=2.21, wps=528.7, ups=0.54, wpb=977.4, bsz=32, num_updates=15960, lr=2.21117e-05, gnorm=2.996, clip=100, loss_scale=128, train_wall=18, gb_free=10.9, wall=29996
2023-05-26 07:43:20 - progress_bar.py[line:272] - INFO: epoch 010:    408 / 1732 loss=2.327, loss_v1=0, loss_v2=0, nll_loss=1.121, ntokens=1058.6, nsentences=32, sample_size=1058.6, sample_size_v1=0, sample_size_v2=0, ppl=2.18, wps=567.7, ups=0.54, wpb=1058.6, bsz=32, num_updates=15970, lr=2.21055e-05, gnorm=2.574, clip=100, loss_scale=128, train_wall=19, gb_free=11.5, wall=30015
2023-05-26 07:43:39 - progress_bar.py[line:272] - INFO: epoch 010:    418 / 1732 loss=2.291, loss_v1=0, loss_v2=0, nll_loss=1.081, ntokens=1021.6, nsentences=32, sample_size=1021.6, sample_size_v1=0, sample_size_v2=0, ppl=2.12, wps=548.9, ups=0.54, wpb=1021.6, bsz=32, num_updates=15980, lr=2.20994e-05, gnorm=2.63, clip=100, loss_scale=128, train_wall=19, gb_free=11, wall=30033
2023-05-26 07:43:57 - progress_bar.py[line:272] - INFO: epoch 010:    428 / 1732 loss=2.302, loss_v1=0, loss_v2=0, nll_loss=1.093, ntokens=1016.5, nsentences=32, sample_size=1016.5, sample_size_v1=0, sample_size_v2=0, ppl=2.13, wps=546.1, ups=0.54, wpb=1016.5, bsz=32, num_updates=15990, lr=2.20932e-05, gnorm=2.865, clip=100, loss_scale=128, train_wall=19, gb_free=11.2, wall=30052
2023-05-26 07:44:16 - progress_bar.py[line:272] - INFO: epoch 010:    438 / 1732 loss=2.338, loss_v1=0, loss_v2=0, nll_loss=1.134, ntokens=1018.5, nsentences=32, sample_size=1018.5, sample_size_v1=0, sample_size_v2=0, ppl=2.2, wps=549.7, ups=0.54, wpb=1018.5, bsz=32, num_updates=16000, lr=2.20871e-05, gnorm=2.6, clip=100, loss_scale=128, train_wall=18, gb_free=11.7, wall=30070
2023-05-26 07:44:34 - progress_bar.py[line:272] - INFO: epoch 010:    448 / 1732 loss=2.351, loss_v1=0, loss_v2=0, nll_loss=1.147, ntokens=946.6, nsentences=32, sample_size=946.6, sample_size_v1=0, sample_size_v2=0, ppl=2.21, wps=510.3, ups=0.54, wpb=946.6, bsz=32, num_updates=16010, lr=2.2081e-05, gnorm=2.963, clip=100, loss_scale=128, train_wall=19, gb_free=11.5, wall=30089
2023-05-26 07:44:53 - progress_bar.py[line:272] - INFO: epoch 010:    458 / 1732 loss=2.346, loss_v1=0, loss_v2=0, nll_loss=1.144, ntokens=971.2, nsentences=32, sample_size=971.2, sample_size_v1=0, sample_size_v2=0, ppl=2.21, wps=524.9, ups=0.54, wpb=971.2, bsz=32, num_updates=16020, lr=2.20748e-05, gnorm=2.843, clip=100, loss_scale=128, train_wall=18, gb_free=11.8, wall=30108
2023-05-26 07:45:12 - progress_bar.py[line:272] - INFO: epoch 010:    468 / 1732 loss=2.353, loss_v1=0, loss_v2=0, nll_loss=1.149, ntokens=1064.3, nsentences=32, sample_size=1064.3, sample_size_v1=0, sample_size_v2=0, ppl=2.22, wps=568.1, ups=0.53, wpb=1064.3, bsz=32, num_updates=16030, lr=2.20687e-05, gnorm=2.73, clip=100, loss_scale=128, train_wall=19, gb_free=11.3, wall=30126
2023-05-26 07:45:30 - progress_bar.py[line:272] - INFO: epoch 010:    478 / 1732 loss=2.369, loss_v1=0, loss_v2=0, nll_loss=1.167, ntokens=1027.7, nsentences=32, sample_size=1027.7, sample_size_v1=0, sample_size_v2=0, ppl=2.25, wps=552.8, ups=0.54, wpb=1027.7, bsz=32, num_updates=16040, lr=2.20625e-05, gnorm=3.027, clip=100, loss_scale=128, train_wall=19, gb_free=11.7, wall=30145
2023-05-26 07:45:49 - progress_bar.py[line:272] - INFO: epoch 010:    488 / 1732 loss=2.317, loss_v1=0, loss_v2=0, nll_loss=1.112, ntokens=925.6, nsentences=32, sample_size=925.6, sample_size_v1=0, sample_size_v2=0, ppl=2.16, wps=500.8, ups=0.54, wpb=925.6, bsz=32, num_updates=16050, lr=2.20564e-05, gnorm=3.057, clip=100, loss_scale=128, train_wall=18, gb_free=12, wall=30163
2023-05-26 07:46:07 - progress_bar.py[line:272] - INFO: epoch 010:    498 / 1732 loss=2.328, loss_v1=0, loss_v2=0, nll_loss=1.125, ntokens=952.7, nsentences=32, sample_size=952.7, sample_size_v1=0, sample_size_v2=0, ppl=2.18, wps=515.3, ups=0.54, wpb=952.7, bsz=32, num_updates=16060, lr=2.20502e-05, gnorm=3.012, clip=100, loss_scale=128, train_wall=18, gb_free=12.1, wall=30182
2023-05-26 07:46:26 - progress_bar.py[line:272] - INFO: epoch 010:    508 / 1732 loss=2.346, loss_v1=0, loss_v2=0, nll_loss=1.141, ntokens=1034.3, nsentences=32, sample_size=1034.3, sample_size_v1=0, sample_size_v2=0, ppl=2.21, wps=558.9, ups=0.54, wpb=1034.3, bsz=32, num_updates=16070, lr=2.20441e-05, gnorm=2.79, clip=100, loss_scale=128, train_wall=18, gb_free=11.7, wall=30200
2023-05-26 07:46:44 - progress_bar.py[line:272] - INFO: epoch 010:    518 / 1732 loss=2.331, loss_v1=0, loss_v2=0, nll_loss=1.126, ntokens=1032.2, nsentences=32, sample_size=1032.2, sample_size_v1=0, sample_size_v2=0, ppl=2.18, wps=558.5, ups=0.54, wpb=1032.2, bsz=32, num_updates=16080, lr=2.2038e-05, gnorm=2.629, clip=100, loss_scale=128, train_wall=18, gb_free=11.7, wall=30219
2023-05-26 07:47:03 - progress_bar.py[line:272] - INFO: epoch 010:    528 / 1732 loss=2.342, loss_v1=0, loss_v2=0, nll_loss=1.139, ntokens=941.1, nsentences=32, sample_size=941.1, sample_size_v1=0, sample_size_v2=0, ppl=2.2, wps=510.7, ups=0.54, wpb=941.1, bsz=32, num_updates=16090, lr=2.20318e-05, gnorm=3.195, clip=100, loss_scale=128, train_wall=18, gb_free=11.9, wall=30237
2023-05-26 07:47:21 - progress_bar.py[line:272] - INFO: epoch 010:    538 / 1732 loss=2.319, loss_v1=0, loss_v2=0, nll_loss=1.111, ntokens=972.3, nsentences=32, sample_size=972.3, sample_size_v1=0, sample_size_v2=0, ppl=2.16, wps=525.7, ups=0.54, wpb=972.3, bsz=32, num_updates=16100, lr=2.20257e-05, gnorm=2.944, clip=100, loss_scale=128, train_wall=18, gb_free=11.2, wall=30256
2023-05-26 07:47:40 - progress_bar.py[line:272] - INFO: epoch 010:    548 / 1732 loss=2.362, loss_v1=0, loss_v2=0, nll_loss=1.161, ntokens=1027.8, nsentences=32, sample_size=1027.8, sample_size_v1=0, sample_size_v2=0, ppl=2.24, wps=553.5, ups=0.54, wpb=1027.8, bsz=32, num_updates=16110, lr=2.20195e-05, gnorm=2.844, clip=100, loss_scale=128, train_wall=19, gb_free=11.6, wall=30274
2023-05-26 07:47:58 - progress_bar.py[line:272] - INFO: epoch 010:    558 / 1732 loss=2.367, loss_v1=0, loss_v2=0, nll_loss=1.166, ntokens=1021.9, nsentences=32, sample_size=1021.9, sample_size_v1=0, sample_size_v2=0, ppl=2.24, wps=550.9, ups=0.54, wpb=1021.9, bsz=32, num_updates=16120, lr=2.20134e-05, gnorm=2.714, clip=100, loss_scale=128, train_wall=19, gb_free=10.9, wall=30293
2023-05-26 07:48:17 - progress_bar.py[line:272] - INFO: epoch 010:    568 / 1732 loss=2.369, loss_v1=0, loss_v2=0, nll_loss=1.169, ntokens=1014.9, nsentences=32, sample_size=1014.9, sample_size_v1=0, sample_size_v2=0, ppl=2.25, wps=544.9, ups=0.54, wpb=1014.9, bsz=32, num_updates=16130, lr=2.20072e-05, gnorm=2.909, clip=100, loss_scale=128, train_wall=19, gb_free=11.1, wall=30312
2023-05-26 07:48:36 - progress_bar.py[line:272] - INFO: epoch 010:    578 / 1732 loss=2.342, loss_v1=0, loss_v2=0, nll_loss=1.138, ntokens=991.4, nsentences=32, sample_size=991.4, sample_size_v1=0, sample_size_v2=0, ppl=2.2, wps=531.4, ups=0.54, wpb=991.4, bsz=32, num_updates=16140, lr=2.20011e-05, gnorm=2.969, clip=100, loss_scale=128, train_wall=19, gb_free=11.2, wall=30330
2023-05-26 07:48:54 - progress_bar.py[line:272] - INFO: epoch 010:    588 / 1732 loss=2.342, loss_v1=0, loss_v2=0, nll_loss=1.137, ntokens=965.9, nsentences=32, sample_size=965.9, sample_size_v1=0, sample_size_v2=0, ppl=2.2, wps=517.6, ups=0.54, wpb=965.9, bsz=32, num_updates=16150, lr=2.1995e-05, gnorm=2.951, clip=100, loss_scale=128, train_wall=19, gb_free=11.6, wall=30349
2023-05-26 07:49:13 - progress_bar.py[line:272] - INFO: epoch 010:    598 / 1732 loss=2.306, loss_v1=0, loss_v2=0, nll_loss=1.099, ntokens=957.4, nsentences=32, sample_size=957.4, sample_size_v1=0, sample_size_v2=0, ppl=2.14, wps=514.7, ups=0.54, wpb=957.4, bsz=32, num_updates=16160, lr=2.19888e-05, gnorm=2.877, clip=100, loss_scale=128, train_wall=19, gb_free=11.9, wall=30367
2023-05-26 07:49:31 - progress_bar.py[line:272] - INFO: epoch 010:    608 / 1732 loss=2.333, loss_v1=0, loss_v2=0, nll_loss=1.131, ntokens=893.5, nsentences=32, sample_size=893.5, sample_size_v1=0, sample_size_v2=0, ppl=2.19, wps=484.5, ups=0.54, wpb=893.5, bsz=32, num_updates=16170, lr=2.19827e-05, gnorm=3.271, clip=100, loss_scale=128, train_wall=18, gb_free=11.1, wall=30386
2023-05-26 07:49:50 - progress_bar.py[line:272] - INFO: epoch 010:    618 / 1732 loss=2.355, loss_v1=0, loss_v2=0, nll_loss=1.151, ntokens=860.2, nsentences=32, sample_size=860.2, sample_size_v1=0, sample_size_v2=0, ppl=2.22, wps=467.2, ups=0.54, wpb=860.2, bsz=32, num_updates=16180, lr=2.19765e-05, gnorm=3.469, clip=100, loss_scale=128, train_wall=18, gb_free=11.7, wall=30404
2023-05-26 07:50:08 - progress_bar.py[line:272] - INFO: epoch 010:    628 / 1732 loss=2.334, loss_v1=0, loss_v2=0, nll_loss=1.128, ntokens=929, nsentences=32, sample_size=929, sample_size_v1=0, sample_size_v2=0, ppl=2.19, wps=505.8, ups=0.54, wpb=929, bsz=32, num_updates=16190, lr=2.19704e-05, gnorm=3.15, clip=100, loss_scale=128, train_wall=18, gb_free=11.7, wall=30423
2023-05-26 07:50:27 - progress_bar.py[line:272] - INFO: epoch 010:    638 / 1732 loss=2.351, loss_v1=0, loss_v2=0, nll_loss=1.15, ntokens=921.3, nsentences=32, sample_size=921.3, sample_size_v1=0, sample_size_v2=0, ppl=2.22, wps=498.3, ups=0.54, wpb=921.3, bsz=32, num_updates=16200, lr=2.19643e-05, gnorm=3.174, clip=100, loss_scale=128, train_wall=18, gb_free=11.8, wall=30441
2023-05-26 07:50:45 - progress_bar.py[line:272] - INFO: epoch 010:    648 / 1732 loss=2.344, loss_v1=0, loss_v2=0, nll_loss=1.139, ntokens=983.5, nsentences=32, sample_size=983.5, sample_size_v1=0, sample_size_v2=0, ppl=2.2, wps=532.3, ups=0.54, wpb=983.5, bsz=32, num_updates=16210, lr=2.19581e-05, gnorm=2.981, clip=100, loss_scale=256, train_wall=18, gb_free=11.5, wall=30460
2023-05-26 07:51:03 - progress_bar.py[line:272] - INFO: epoch 010:    658 / 1732 loss=2.341, loss_v1=0, loss_v2=0, nll_loss=1.138, ntokens=892.2, nsentences=32, sample_size=892.2, sample_size_v1=0, sample_size_v2=0, ppl=2.2, wps=487.8, ups=0.55, wpb=892.2, bsz=32, num_updates=16220, lr=2.1952e-05, gnorm=3.244, clip=100, loss_scale=256, train_wall=18, gb_free=11.4, wall=30478
2023-05-26 07:51:22 - progress_bar.py[line:272] - INFO: epoch 010:    668 / 1732 loss=2.333, loss_v1=0, loss_v2=0, nll_loss=1.13, ntokens=910, nsentences=32, sample_size=910, sample_size_v1=0, sample_size_v2=0, ppl=2.19, wps=494, ups=0.54, wpb=910, bsz=32, num_updates=16230, lr=2.19458e-05, gnorm=3.196, clip=100, loss_scale=256, train_wall=18, gb_free=11.1, wall=30496
2023-05-26 07:51:40 - progress_bar.py[line:272] - INFO: epoch 010:    678 / 1732 loss=2.359, loss_v1=0, loss_v2=0, nll_loss=1.156, ntokens=980.2, nsentences=32, sample_size=980.2, sample_size_v1=0, sample_size_v2=0, ppl=2.23, wps=529.6, ups=0.54, wpb=980.2, bsz=32, num_updates=16240, lr=2.19397e-05, gnorm=3.213, clip=100, loss_scale=256, train_wall=18, gb_free=11.8, wall=30515
2023-05-26 07:51:59 - progress_bar.py[line:272] - INFO: epoch 010:    688 / 1732 loss=2.355, loss_v1=0, loss_v2=0, nll_loss=1.152, ntokens=942, nsentences=32, sample_size=942, sample_size_v1=0, sample_size_v2=0, ppl=2.22, wps=510.8, ups=0.54, wpb=942, bsz=32, num_updates=16250, lr=2.19335e-05, gnorm=3.132, clip=100, loss_scale=256, train_wall=18, gb_free=11.8, wall=30533
2023-05-26 07:52:17 - progress_bar.py[line:272] - INFO: epoch 010:    698 / 1732 loss=2.343, loss_v1=0, loss_v2=0, nll_loss=1.141, ntokens=1001.9, nsentences=32, sample_size=1001.9, sample_size_v1=0, sample_size_v2=0, ppl=2.21, wps=536, ups=0.53, wpb=1001.9, bsz=32, num_updates=16260, lr=2.19274e-05, gnorm=2.956, clip=100, loss_scale=256, train_wall=19, gb_free=11.7, wall=30552
2023-05-26 07:52:36 - progress_bar.py[line:272] - INFO: epoch 010:    708 / 1732 loss=2.333, loss_v1=0, loss_v2=0, nll_loss=1.126, ntokens=907.1, nsentences=32, sample_size=907.1, sample_size_v1=0, sample_size_v2=0, ppl=2.18, wps=492.9, ups=0.54, wpb=907.1, bsz=32, num_updates=16270, lr=2.19213e-05, gnorm=3.151, clip=100, loss_scale=256, train_wall=18, gb_free=11.7, wall=30570
2023-05-26 07:52:54 - progress_bar.py[line:272] - INFO: epoch 010:    718 / 1732 loss=2.329, loss_v1=0, loss_v2=0, nll_loss=1.123, ntokens=882, nsentences=32, sample_size=882, sample_size_v1=0, sample_size_v2=0, ppl=2.18, wps=479.3, ups=0.54, wpb=882, bsz=32, num_updates=16280, lr=2.19151e-05, gnorm=2.992, clip=100, loss_scale=256, train_wall=18, gb_free=12, wall=30589
2023-05-26 07:53:13 - progress_bar.py[line:272] - INFO: epoch 010:    728 / 1732 loss=2.314, loss_v1=0, loss_v2=0, nll_loss=1.111, ntokens=917.5, nsentences=32, sample_size=917.5, sample_size_v1=0, sample_size_v2=0, ppl=2.16, wps=496.6, ups=0.54, wpb=917.5, bsz=32, num_updates=16290, lr=2.1909e-05, gnorm=3.083, clip=100, loss_scale=256, train_wall=18, gb_free=11.5, wall=30607
2023-05-26 07:53:31 - progress_bar.py[line:272] - INFO: epoch 010:    738 / 1732 loss=2.327, loss_v1=0, loss_v2=0, nll_loss=1.12, ntokens=991.8, nsentences=32, sample_size=991.8, sample_size_v1=0, sample_size_v2=0, ppl=2.17, wps=538.5, ups=0.54, wpb=991.8, bsz=32, num_updates=16300, lr=2.19028e-05, gnorm=2.949, clip=100, loss_scale=256, train_wall=18, gb_free=11.6, wall=30626
2023-05-26 07:53:50 - progress_bar.py[line:272] - INFO: epoch 010:    748 / 1732 loss=2.329, loss_v1=0, loss_v2=0, nll_loss=1.121, ntokens=986.3, nsentences=32, sample_size=986.3, sample_size_v1=0, sample_size_v2=0, ppl=2.18, wps=530.3, ups=0.54, wpb=986.3, bsz=32, num_updates=16310, lr=2.18967e-05, gnorm=3.059, clip=100, loss_scale=256, train_wall=19, gb_free=11.6, wall=30644
2023-05-26 07:54:08 - progress_bar.py[line:272] - INFO: epoch 010:    758 / 1732 loss=2.312, loss_v1=0, loss_v2=0, nll_loss=1.106, ntokens=946.6, nsentences=32, sample_size=946.6, sample_size_v1=0, sample_size_v2=0, ppl=2.15, wps=512, ups=0.54, wpb=946.6, bsz=32, num_updates=16320, lr=2.18905e-05, gnorm=2.796, clip=100, loss_scale=256, train_wall=18, gb_free=11.4, wall=30663
2023-05-26 07:54:10 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 128.0
2023-05-26 07:54:28 - progress_bar.py[line:272] - INFO: epoch 010:    769 / 1732 loss=2.336, loss_v1=0, loss_v2=0, nll_loss=1.134, ntokens=931.4, nsentences=32, sample_size=931.4, sample_size_v1=0, sample_size_v2=0, ppl=2.19, wps=461.5, ups=0.5, wpb=931.4, bsz=32, num_updates=16330, lr=2.18844e-05, gnorm=3.194, clip=100, loss_scale=128, train_wall=20, gb_free=11.9, wall=30683
2023-05-26 07:54:47 - progress_bar.py[line:272] - INFO: epoch 010:    779 / 1732 loss=2.328, loss_v1=0, loss_v2=0, nll_loss=1.121, ntokens=1031.1, nsentences=32, sample_size=1031.1, sample_size_v1=0, sample_size_v2=0, ppl=2.17, wps=555.9, ups=0.54, wpb=1031.1, bsz=32, num_updates=16340, lr=2.18783e-05, gnorm=2.993, clip=100, loss_scale=128, train_wall=19, gb_free=11.3, wall=30702
2023-05-26 07:55:05 - progress_bar.py[line:272] - INFO: epoch 010:    789 / 1732 loss=2.326, loss_v1=0, loss_v2=0, nll_loss=1.12, ntokens=1004.1, nsentences=32, sample_size=1004.1, sample_size_v1=0, sample_size_v2=0, ppl=2.17, wps=542.4, ups=0.54, wpb=1004.1, bsz=32, num_updates=16350, lr=2.18721e-05, gnorm=3.016, clip=100, loss_scale=128, train_wall=18, gb_free=11.9, wall=30720
2023-05-26 07:55:24 - progress_bar.py[line:272] - INFO: epoch 010:    799 / 1732 loss=2.334, loss_v1=0, loss_v2=0, nll_loss=1.131, ntokens=1038.9, nsentences=32, sample_size=1038.9, sample_size_v1=0, sample_size_v2=0, ppl=2.19, wps=560.5, ups=0.54, wpb=1038.9, bsz=32, num_updates=16360, lr=2.1866e-05, gnorm=3.033, clip=100, loss_scale=128, train_wall=19, gb_free=11.4, wall=30739
2023-05-26 07:55:42 - progress_bar.py[line:272] - INFO: epoch 010:    809 / 1732 loss=2.324, loss_v1=0, loss_v2=0, nll_loss=1.118, ntokens=922.8, nsentences=32, sample_size=922.8, sample_size_v1=0, sample_size_v2=0, ppl=2.17, wps=500.3, ups=0.54, wpb=922.8, bsz=32, num_updates=16370, lr=2.18598e-05, gnorm=3.042, clip=100, loss_scale=128, train_wall=18, gb_free=11.7, wall=30757
2023-05-26 07:56:01 - progress_bar.py[line:272] - INFO: epoch 010:    819 / 1732 loss=2.336, loss_v1=0, loss_v2=0, nll_loss=1.13, ntokens=909.6, nsentences=32, sample_size=909.6, sample_size_v1=0, sample_size_v2=0, ppl=2.19, wps=492.2, ups=0.54, wpb=909.6, bsz=32, num_updates=16380, lr=2.18537e-05, gnorm=3.369, clip=100, loss_scale=128, train_wall=18, gb_free=11.8, wall=30776
2023-05-26 07:56:19 - progress_bar.py[line:272] - INFO: epoch 010:    829 / 1732 loss=2.314, loss_v1=0, loss_v2=0, nll_loss=1.109, ntokens=917.4, nsentences=32, sample_size=917.4, sample_size_v1=0, sample_size_v2=0, ppl=2.16, wps=496, ups=0.54, wpb=917.4, bsz=32, num_updates=16390, lr=2.18476e-05, gnorm=2.965, clip=100, loss_scale=128, train_wall=18, gb_free=11.8, wall=30794
2023-05-26 07:56:38 - progress_bar.py[line:272] - INFO: epoch 010:    839 / 1732 loss=2.343, loss_v1=0, loss_v2=0, nll_loss=1.139, ntokens=902.5, nsentences=32, sample_size=902.5, sample_size_v1=0, sample_size_v2=0, ppl=2.2, wps=493.7, ups=0.55, wpb=902.5, bsz=32, num_updates=16400, lr=2.18414e-05, gnorm=3.223, clip=100, loss_scale=128, train_wall=18, gb_free=11.8, wall=30812
2023-05-26 07:56:56 - progress_bar.py[line:272] - INFO: epoch 010:    849 / 1732 loss=2.323, loss_v1=0, loss_v2=0, nll_loss=1.116, ntokens=1036.8, nsentences=32, sample_size=1036.8, sample_size_v1=0, sample_size_v2=0, ppl=2.17, wps=558.3, ups=0.54, wpb=1036.8, bsz=32, num_updates=16410, lr=2.18353e-05, gnorm=3.07, clip=100, loss_scale=128, train_wall=19, gb_free=11.4, wall=30831
2023-05-26 07:57:15 - progress_bar.py[line:272] - INFO: epoch 010:    859 / 1732 loss=2.32, loss_v1=0, loss_v2=0, nll_loss=1.117, ntokens=930.3, nsentences=32, sample_size=930.3, sample_size_v1=0, sample_size_v2=0, ppl=2.17, wps=505.1, ups=0.54, wpb=930.3, bsz=32, num_updates=16420, lr=2.18291e-05, gnorm=3.133, clip=100, loss_scale=128, train_wall=18, gb_free=11.4, wall=30849
2023-05-26 07:57:33 - progress_bar.py[line:272] - INFO: epoch 010:    869 / 1732 loss=2.342, loss_v1=0, loss_v2=0, nll_loss=1.138, ntokens=962.2, nsentences=32, sample_size=962.2, sample_size_v1=0, sample_size_v2=0, ppl=2.2, wps=520.7, ups=0.54, wpb=962.2, bsz=32, num_updates=16430, lr=2.1823e-05, gnorm=2.975, clip=100, loss_scale=128, train_wall=18, gb_free=11.6, wall=30868
2023-05-26 07:57:52 - progress_bar.py[line:272] - INFO: epoch 010:    879 / 1732 loss=2.268, loss_v1=0, loss_v2=0, nll_loss=1.055, ntokens=1001.9, nsentences=32, sample_size=1001.9, sample_size_v1=0, sample_size_v2=0, ppl=2.08, wps=539.4, ups=0.54, wpb=1001.9, bsz=32, num_updates=16440, lr=2.18168e-05, gnorm=2.87, clip=100, loss_scale=128, train_wall=19, gb_free=11.7, wall=30886
2023-05-26 07:58:10 - progress_bar.py[line:272] - INFO: epoch 010:    889 / 1732 loss=2.27, loss_v1=0, loss_v2=0, nll_loss=1.059, ntokens=975.7, nsentences=32, sample_size=975.7, sample_size_v1=0, sample_size_v2=0, ppl=2.08, wps=525.9, ups=0.54, wpb=975.7, bsz=32, num_updates=16450, lr=2.18107e-05, gnorm=3.018, clip=100, loss_scale=128, train_wall=19, gb_free=11.6, wall=30905
2023-05-26 07:58:29 - progress_bar.py[line:272] - INFO: epoch 010:    899 / 1732 loss=2.272, loss_v1=0, loss_v2=0, nll_loss=1.058, ntokens=1055.9, nsentences=32, sample_size=1055.9, sample_size_v1=0, sample_size_v2=0, ppl=2.08, wps=567.3, ups=0.54, wpb=1055.9, bsz=32, num_updates=16460, lr=2.18046e-05, gnorm=2.893, clip=100, loss_scale=128, train_wall=19, gb_free=11.1, wall=30924
2023-05-26 07:58:47 - progress_bar.py[line:272] - INFO: epoch 010:    909 / 1732 loss=2.305, loss_v1=0, loss_v2=0, nll_loss=1.097, ntokens=975.2, nsentences=32, sample_size=975.2, sample_size_v1=0, sample_size_v2=0, ppl=2.14, wps=527.5, ups=0.54, wpb=975.2, bsz=32, num_updates=16470, lr=2.17984e-05, gnorm=3, clip=100, loss_scale=128, train_wall=18, gb_free=11.8, wall=30942
2023-05-26 07:59:06 - progress_bar.py[line:272] - INFO: epoch 010:    919 / 1732 loss=2.353, loss_v1=0, loss_v2=0, nll_loss=1.151, ntokens=988.7, nsentences=32, sample_size=988.7, sample_size_v1=0, sample_size_v2=0, ppl=2.22, wps=532.6, ups=0.54, wpb=988.7, bsz=32, num_updates=16480, lr=2.17923e-05, gnorm=3.077, clip=100, loss_scale=128, train_wall=19, gb_free=11, wall=30961
2023-05-26 07:59:25 - progress_bar.py[line:272] - INFO: epoch 010:    929 / 1732 loss=2.302, loss_v1=0, loss_v2=0, nll_loss=1.093, ntokens=1019.8, nsentences=32, sample_size=1019.8, sample_size_v1=0, sample_size_v2=0, ppl=2.13, wps=547.5, ups=0.54, wpb=1019.8, bsz=32, num_updates=16490, lr=2.17861e-05, gnorm=2.928, clip=100, loss_scale=128, train_wall=19, gb_free=10.9, wall=30979
2023-05-26 07:59:43 - progress_bar.py[line:272] - INFO: epoch 010:    939 / 1732 loss=2.313, loss_v1=0, loss_v2=0, nll_loss=1.107, ntokens=1047.7, nsentences=32, sample_size=1047.7, sample_size_v1=0, sample_size_v2=0, ppl=2.15, wps=556.8, ups=0.53, wpb=1047.7, bsz=32, num_updates=16500, lr=2.178e-05, gnorm=3.019, clip=100, loss_scale=128, train_wall=19, gb_free=11.2, wall=30998
2023-05-26 08:00:02 - progress_bar.py[line:272] - INFO: epoch 010:    949 / 1732 loss=2.318, loss_v1=0, loss_v2=0, nll_loss=1.11, ntokens=1037.9, nsentences=32, sample_size=1037.9, sample_size_v1=0, sample_size_v2=0, ppl=2.16, wps=551.5, ups=0.53, wpb=1037.9, bsz=32, num_updates=16510, lr=2.17738e-05, gnorm=2.822, clip=100, loss_scale=128, train_wall=19, gb_free=11.3, wall=31017
2023-05-26 08:00:21 - progress_bar.py[line:272] - INFO: epoch 010:    959 / 1732 loss=2.306, loss_v1=0, loss_v2=0, nll_loss=1.099, ntokens=1070.6, nsentences=32, sample_size=1070.6, sample_size_v1=0, sample_size_v2=0, ppl=2.14, wps=570, ups=0.53, wpb=1070.6, bsz=32, num_updates=16520, lr=2.17677e-05, gnorm=2.821, clip=100, loss_scale=128, train_wall=19, gb_free=11.2, wall=31036
2023-05-26 08:00:40 - progress_bar.py[line:272] - INFO: epoch 010:    969 / 1732 loss=2.347, loss_v1=0, loss_v2=0, nll_loss=1.145, ntokens=1025.9, nsentences=32, sample_size=1025.9, sample_size_v1=0, sample_size_v2=0, ppl=2.21, wps=548.1, ups=0.53, wpb=1025.9, bsz=32, num_updates=16530, lr=2.17616e-05, gnorm=3.23, clip=100, loss_scale=128, train_wall=19, gb_free=11.3, wall=31054
2023-05-26 08:00:59 - progress_bar.py[line:272] - INFO: epoch 010:    979 / 1732 loss=2.311, loss_v1=0, loss_v2=0, nll_loss=1.102, ntokens=1025.3, nsentences=32, sample_size=1025.3, sample_size_v1=0, sample_size_v2=0, ppl=2.15, wps=543.3, ups=0.53, wpb=1025.3, bsz=32, num_updates=16540, lr=2.17554e-05, gnorm=2.819, clip=100, loss_scale=128, train_wall=19, gb_free=11, wall=31073
2023-05-26 08:01:17 - progress_bar.py[line:272] - INFO: epoch 010:    989 / 1732 loss=2.314, loss_v1=0, loss_v2=0, nll_loss=1.108, ntokens=1057.2, nsentences=32, sample_size=1057.2, sample_size_v1=0, sample_size_v2=0, ppl=2.16, wps=560.2, ups=0.53, wpb=1057.2, bsz=32, num_updates=16550, lr=2.17493e-05, gnorm=2.88, clip=100, loss_scale=128, train_wall=19, gb_free=11.1, wall=31092
2023-05-26 08:01:36 - progress_bar.py[line:272] - INFO: epoch 010:    999 / 1732 loss=2.312, loss_v1=0, loss_v2=0, nll_loss=1.102, ntokens=989.7, nsentences=32, sample_size=989.7, sample_size_v1=0, sample_size_v2=0, ppl=2.15, wps=532.2, ups=0.54, wpb=989.7, bsz=32, num_updates=16560, lr=2.17431e-05, gnorm=3.409, clip=100, loss_scale=128, train_wall=19, gb_free=11.8, wall=31111
2023-05-26 08:01:55 - progress_bar.py[line:272] - INFO: epoch 010:   1009 / 1732 loss=2.316, loss_v1=0, loss_v2=0, nll_loss=1.109, ntokens=1040.9, nsentences=32, sample_size=1040.9, sample_size_v1=0, sample_size_v2=0, ppl=2.16, wps=556.1, ups=0.53, wpb=1040.9, bsz=32, num_updates=16570, lr=2.1737e-05, gnorm=3.245, clip=100, loss_scale=128, train_wall=19, gb_free=10.8, wall=31129
2023-05-26 08:02:13 - progress_bar.py[line:272] - INFO: epoch 010:   1019 / 1732 loss=2.288, loss_v1=0, loss_v2=0, nll_loss=1.079, ntokens=1021.6, nsentences=32, sample_size=1021.6, sample_size_v1=0, sample_size_v2=0, ppl=2.11, wps=547.3, ups=0.54, wpb=1021.6, bsz=32, num_updates=16580, lr=2.17309e-05, gnorm=3.035, clip=100, loss_scale=128, train_wall=19, gb_free=11.3, wall=31148
2023-05-26 08:02:32 - progress_bar.py[line:272] - INFO: epoch 010:   1029 / 1732 loss=2.309, loss_v1=0, loss_v2=0, nll_loss=1.101, ntokens=1092, nsentences=32, sample_size=1092, sample_size_v1=0, sample_size_v2=0, ppl=2.14, wps=574.8, ups=0.53, wpb=1092, bsz=32, num_updates=16590, lr=2.17247e-05, gnorm=2.827, clip=100, loss_scale=128, train_wall=19, gb_free=10.6, wall=31167
2023-05-26 08:02:51 - progress_bar.py[line:272] - INFO: epoch 010:   1039 / 1732 loss=2.329, loss_v1=0, loss_v2=0, nll_loss=1.123, ntokens=1077.1, nsentences=32, sample_size=1077.1, sample_size_v1=0, sample_size_v2=0, ppl=2.18, wps=573.4, ups=0.53, wpb=1077.1, bsz=32, num_updates=16600, lr=2.17186e-05, gnorm=2.915, clip=100, loss_scale=128, train_wall=19, gb_free=10.9, wall=31186
2023-05-26 08:03:10 - progress_bar.py[line:272] - INFO: epoch 010:   1049 / 1732 loss=2.308, loss_v1=0, loss_v2=0, nll_loss=1.101, ntokens=1018.7, nsentences=32, sample_size=1018.7, sample_size_v1=0, sample_size_v2=0, ppl=2.14, wps=544.3, ups=0.53, wpb=1018.7, bsz=32, num_updates=16610, lr=2.17124e-05, gnorm=3.173, clip=100, loss_scale=128, train_wall=19, gb_free=11.5, wall=31205
2023-05-26 08:03:29 - progress_bar.py[line:272] - INFO: epoch 010:   1059 / 1732 loss=2.316, loss_v1=0, loss_v2=0, nll_loss=1.109, ntokens=1090.9, nsentences=32, sample_size=1090.9, sample_size_v1=0, sample_size_v2=0, ppl=2.16, wps=581.6, ups=0.53, wpb=1090.9, bsz=32, num_updates=16620, lr=2.17063e-05, gnorm=2.8, clip=100, loss_scale=128, train_wall=19, gb_free=11.5, wall=31223
2023-05-26 08:03:47 - progress_bar.py[line:272] - INFO: epoch 010:   1069 / 1732 loss=2.302, loss_v1=0, loss_v2=0, nll_loss=1.093, ntokens=979.2, nsentences=32, sample_size=979.2, sample_size_v1=0, sample_size_v2=0, ppl=2.13, wps=524.6, ups=0.54, wpb=979.2, bsz=32, num_updates=16630, lr=2.17001e-05, gnorm=2.95, clip=100, loss_scale=128, train_wall=19, gb_free=11.3, wall=31242
2023-05-26 08:04:06 - progress_bar.py[line:272] - INFO: epoch 010:   1079 / 1732 loss=2.328, loss_v1=0, loss_v2=0, nll_loss=1.123, ntokens=1044.7, nsentences=32, sample_size=1044.7, sample_size_v1=0, sample_size_v2=0, ppl=2.18, wps=553.4, ups=0.53, wpb=1044.7, bsz=32, num_updates=16640, lr=2.1694e-05, gnorm=2.89, clip=100, loss_scale=128, train_wall=19, gb_free=11, wall=31261
2023-05-26 08:04:25 - progress_bar.py[line:272] - INFO: epoch 010:   1089 / 1732 loss=2.301, loss_v1=0, loss_v2=0, nll_loss=1.092, ntokens=1065.4, nsentences=32, sample_size=1065.4, sample_size_v1=0, sample_size_v2=0, ppl=2.13, wps=563.5, ups=0.53, wpb=1065.4, bsz=32, num_updates=16650, lr=2.16879e-05, gnorm=2.756, clip=100, loss_scale=128, train_wall=19, gb_free=11.4, wall=31280
2023-05-26 08:04:44 - progress_bar.py[line:272] - INFO: epoch 010:   1099 / 1732 loss=2.32, loss_v1=0, loss_v2=0, nll_loss=1.113, ntokens=1034.8, nsentences=32, sample_size=1034.8, sample_size_v1=0, sample_size_v2=0, ppl=2.16, wps=553, ups=0.53, wpb=1034.8, bsz=32, num_updates=16660, lr=2.16817e-05, gnorm=3.013, clip=100, loss_scale=128, train_wall=19, gb_free=10.5, wall=31299
2023-05-26 08:05:03 - progress_bar.py[line:272] - INFO: epoch 010:   1109 / 1732 loss=2.307, loss_v1=0, loss_v2=0, nll_loss=1.099, ntokens=1058.4, nsentences=32, sample_size=1058.4, sample_size_v1=0, sample_size_v2=0, ppl=2.14, wps=562.2, ups=0.53, wpb=1058.4, bsz=32, num_updates=16670, lr=2.16756e-05, gnorm=2.929, clip=100, loss_scale=128, train_wall=19, gb_free=10.4, wall=31317
2023-05-26 08:05:21 - progress_bar.py[line:272] - INFO: epoch 010:   1119 / 1732 loss=2.31, loss_v1=0, loss_v2=0, nll_loss=1.102, ntokens=966, nsentences=32, sample_size=966, sample_size_v1=0, sample_size_v2=0, ppl=2.15, wps=515.2, ups=0.53, wpb=966, bsz=32, num_updates=16680, lr=2.16694e-05, gnorm=2.968, clip=100, loss_scale=128, train_wall=19, gb_free=10.9, wall=31336
2023-05-26 08:05:40 - progress_bar.py[line:272] - INFO: epoch 010:   1129 / 1732 loss=2.305, loss_v1=0, loss_v2=0, nll_loss=1.098, ntokens=1007.5, nsentences=32, sample_size=1007.5, sample_size_v1=0, sample_size_v2=0, ppl=2.14, wps=531, ups=0.53, wpb=1007.5, bsz=32, num_updates=16690, lr=2.16633e-05, gnorm=2.897, clip=100, loss_scale=128, train_wall=19, gb_free=11.4, wall=31355
2023-05-26 08:05:59 - progress_bar.py[line:272] - INFO: epoch 010:   1139 / 1732 loss=2.317, loss_v1=0, loss_v2=0, nll_loss=1.109, ntokens=999.7, nsentences=32, sample_size=999.7, sample_size_v1=0, sample_size_v2=0, ppl=2.16, wps=534.7, ups=0.53, wpb=999.7, bsz=32, num_updates=16700, lr=2.16571e-05, gnorm=3.021, clip=100, loss_scale=128, train_wall=19, gb_free=11.1, wall=31374
2023-05-26 08:06:18 - progress_bar.py[line:272] - INFO: epoch 010:   1149 / 1732 loss=2.307, loss_v1=0, loss_v2=0, nll_loss=1.1, ntokens=999, nsentences=32, sample_size=999, sample_size_v1=0, sample_size_v2=0, ppl=2.14, wps=533.3, ups=0.53, wpb=999, bsz=32, num_updates=16710, lr=2.1651e-05, gnorm=2.751, clip=100, loss_scale=128, train_wall=19, gb_free=11.4, wall=31393
2023-05-26 08:06:37 - progress_bar.py[line:272] - INFO: epoch 010:   1159 / 1732 loss=2.289, loss_v1=0, loss_v2=0, nll_loss=1.08, ntokens=1014.2, nsentences=32, sample_size=1014.2, sample_size_v1=0, sample_size_v2=0, ppl=2.11, wps=540.7, ups=0.53, wpb=1014.2, bsz=32, num_updates=16720, lr=2.16449e-05, gnorm=3.049, clip=100, loss_scale=128, train_wall=19, gb_free=11.5, wall=31411
2023-05-26 08:06:55 - progress_bar.py[line:272] - INFO: epoch 010:   1169 / 1732 loss=2.299, loss_v1=0, loss_v2=0, nll_loss=1.09, ntokens=1031, nsentences=32, sample_size=1031, sample_size_v1=0, sample_size_v2=0, ppl=2.13, wps=547.9, ups=0.53, wpb=1031, bsz=32, num_updates=16730, lr=2.16387e-05, gnorm=2.823, clip=100, loss_scale=128, train_wall=19, gb_free=11.1, wall=31430
2023-05-26 08:07:14 - progress_bar.py[line:272] - INFO: epoch 010:   1179 / 1732 loss=2.28, loss_v1=0, loss_v2=0, nll_loss=1.067, ntokens=1057.9, nsentences=32, sample_size=1057.9, sample_size_v1=0, sample_size_v2=0, ppl=2.1, wps=565.4, ups=0.53, wpb=1057.9, bsz=32, num_updates=16740, lr=2.16326e-05, gnorm=2.858, clip=100, loss_scale=128, train_wall=19, gb_free=11.6, wall=31449
2023-05-26 08:07:33 - progress_bar.py[line:272] - INFO: epoch 010:   1189 / 1732 loss=2.307, loss_v1=0, loss_v2=0, nll_loss=1.1, ntokens=993.6, nsentences=32, sample_size=993.6, sample_size_v1=0, sample_size_v2=0, ppl=2.14, wps=529.8, ups=0.53, wpb=993.6, bsz=32, num_updates=16750, lr=2.16264e-05, gnorm=2.746, clip=100, loss_scale=128, train_wall=19, gb_free=11, wall=31468
2023-05-26 08:07:52 - progress_bar.py[line:272] - INFO: epoch 010:   1199 / 1732 loss=2.29, loss_v1=0, loss_v2=0, nll_loss=1.078, ntokens=1103.9, nsentences=32, sample_size=1103.9, sample_size_v1=0, sample_size_v2=0, ppl=2.11, wps=586.7, ups=0.53, wpb=1103.9, bsz=32, num_updates=16760, lr=2.16203e-05, gnorm=2.737, clip=100, loss_scale=128, train_wall=19, gb_free=10.8, wall=31486
2023-05-26 08:08:11 - progress_bar.py[line:272] - INFO: epoch 010:   1209 / 1732 loss=2.289, loss_v1=0, loss_v2=0, nll_loss=1.08, ntokens=1079.5, nsentences=32, sample_size=1079.5, sample_size_v1=0, sample_size_v2=0, ppl=2.11, wps=570.6, ups=0.53, wpb=1079.5, bsz=32, num_updates=16770, lr=2.16142e-05, gnorm=2.97, clip=100, loss_scale=128, train_wall=19, gb_free=11.2, wall=31505
2023-05-26 08:08:29 - progress_bar.py[line:272] - INFO: epoch 010:   1219 / 1732 loss=2.341, loss_v1=0, loss_v2=0, nll_loss=1.139, ntokens=1009.3, nsentences=32, sample_size=1009.3, sample_size_v1=0, sample_size_v2=0, ppl=2.2, wps=540.6, ups=0.54, wpb=1009.3, bsz=32, num_updates=16780, lr=2.1608e-05, gnorm=3.055, clip=100, loss_scale=128, train_wall=19, gb_free=11.3, wall=31524
2023-05-26 08:08:48 - progress_bar.py[line:272] - INFO: epoch 010:   1229 / 1732 loss=2.299, loss_v1=0, loss_v2=0, nll_loss=1.089, ntokens=1052.5, nsentences=32, sample_size=1052.5, sample_size_v1=0, sample_size_v2=0, ppl=2.13, wps=560.7, ups=0.53, wpb=1052.5, bsz=32, num_updates=16790, lr=2.16019e-05, gnorm=2.946, clip=100, loss_scale=128, train_wall=19, gb_free=11.1, wall=31543
2023-05-26 08:09:07 - progress_bar.py[line:272] - INFO: epoch 010:   1239 / 1732 loss=2.266, loss_v1=0, loss_v2=0, nll_loss=1.054, ntokens=1065.1, nsentences=32, sample_size=1065.1, sample_size_v1=0, sample_size_v2=0, ppl=2.08, wps=565.5, ups=0.53, wpb=1065.1, bsz=32, num_updates=16800, lr=2.15957e-05, gnorm=2.862, clip=100, loss_scale=128, train_wall=19, gb_free=10.7, wall=31562
2023-05-26 08:09:26 - progress_bar.py[line:272] - INFO: epoch 010:   1249 / 1732 loss=2.269, loss_v1=0, loss_v2=0, nll_loss=1.057, ntokens=1065.4, nsentences=32, sample_size=1065.4, sample_size_v1=0, sample_size_v2=0, ppl=2.08, wps=565.6, ups=0.53, wpb=1065.4, bsz=32, num_updates=16810, lr=2.15896e-05, gnorm=2.87, clip=100, loss_scale=128, train_wall=19, gb_free=11.5, wall=31580
2023-05-26 08:09:45 - progress_bar.py[line:272] - INFO: epoch 010:   1259 / 1732 loss=2.29, loss_v1=0, loss_v2=0, nll_loss=1.079, ntokens=1045.9, nsentences=32, sample_size=1045.9, sample_size_v1=0, sample_size_v2=0, ppl=2.11, wps=556.4, ups=0.53, wpb=1045.9, bsz=32, num_updates=16820, lr=2.15834e-05, gnorm=2.849, clip=100, loss_scale=128, train_wall=19, gb_free=11.5, wall=31599
2023-05-26 08:10:03 - progress_bar.py[line:272] - INFO: epoch 010:   1269 / 1732 loss=2.313, loss_v1=0, loss_v2=0, nll_loss=1.106, ntokens=1069.2, nsentences=32, sample_size=1069.2, sample_size_v1=0, sample_size_v2=0, ppl=2.15, wps=569, ups=0.53, wpb=1069.2, bsz=32, num_updates=16830, lr=2.15773e-05, gnorm=2.836, clip=100, loss_scale=128, train_wall=19, gb_free=11.4, wall=31618
2023-05-26 08:10:22 - progress_bar.py[line:272] - INFO: epoch 010:   1279 / 1732 loss=2.299, loss_v1=0, loss_v2=0, nll_loss=1.09, ntokens=1067, nsentences=32, sample_size=1067, sample_size_v1=0, sample_size_v2=0, ppl=2.13, wps=564.8, ups=0.53, wpb=1067, bsz=32, num_updates=16840, lr=2.15712e-05, gnorm=2.89, clip=100, loss_scale=256, train_wall=19, gb_free=10.9, wall=31637
2023-05-26 08:10:41 - progress_bar.py[line:272] - INFO: epoch 010:   1289 / 1732 loss=2.295, loss_v1=0, loss_v2=0, nll_loss=1.084, ntokens=1071, nsentences=32, sample_size=1071, sample_size_v1=0, sample_size_v2=0, ppl=2.12, wps=565.6, ups=0.53, wpb=1071, bsz=32, num_updates=16850, lr=2.1565e-05, gnorm=2.884, clip=100, loss_scale=256, train_wall=19, gb_free=10.4, wall=31656
2023-05-26 08:11:00 - progress_bar.py[line:272] - INFO: epoch 010:   1299 / 1732 loss=2.297, loss_v1=0, loss_v2=0, nll_loss=1.09, ntokens=1078.1, nsentences=32, sample_size=1078.1, sample_size_v1=0, sample_size_v2=0, ppl=2.13, wps=575.7, ups=0.53, wpb=1078.1, bsz=32, num_updates=16860, lr=2.15589e-05, gnorm=2.851, clip=100, loss_scale=256, train_wall=19, gb_free=11.4, wall=31675
2023-05-26 08:11:19 - progress_bar.py[line:272] - INFO: epoch 010:   1309 / 1732 loss=2.339, loss_v1=0, loss_v2=0, nll_loss=1.134, ntokens=1085.2, nsentences=32, sample_size=1085.2, sample_size_v1=0, sample_size_v2=0, ppl=2.19, wps=569.9, ups=0.53, wpb=1085.2, bsz=32, num_updates=16870, lr=2.15527e-05, gnorm=2.974, clip=100, loss_scale=256, train_wall=19, gb_free=10.9, wall=31694
2023-05-26 08:11:38 - progress_bar.py[line:272] - INFO: epoch 010:   1319 / 1732 loss=2.289, loss_v1=0, loss_v2=0, nll_loss=1.079, ntokens=1092.6, nsentences=32, sample_size=1092.6, sample_size_v1=0, sample_size_v2=0, ppl=2.11, wps=578.8, ups=0.53, wpb=1092.6, bsz=32, num_updates=16880, lr=2.15466e-05, gnorm=2.924, clip=100, loss_scale=256, train_wall=19, gb_free=10.9, wall=31713
2023-05-26 08:11:57 - progress_bar.py[line:272] - INFO: epoch 010:   1329 / 1732 loss=2.269, loss_v1=0, loss_v2=0, nll_loss=1.057, ntokens=1106.3, nsentences=32, sample_size=1106.3, sample_size_v1=0, sample_size_v2=0, ppl=2.08, wps=584.2, ups=0.53, wpb=1106.3, bsz=32, num_updates=16890, lr=2.15404e-05, gnorm=2.71, clip=100, loss_scale=256, train_wall=19, gb_free=11.3, wall=31732
2023-05-26 08:12:16 - progress_bar.py[line:272] - INFO: epoch 010:   1339 / 1732 loss=2.286, loss_v1=0, loss_v2=0, nll_loss=1.074, ntokens=1120.5, nsentences=32, sample_size=1120.5, sample_size_v1=0, sample_size_v2=0, ppl=2.11, wps=594.9, ups=0.53, wpb=1120.5, bsz=32, num_updates=16900, lr=2.15343e-05, gnorm=3.052, clip=100, loss_scale=256, train_wall=19, gb_free=11, wall=31750
2023-05-26 08:12:35 - progress_bar.py[line:272] - INFO: epoch 010:   1349 / 1732 loss=2.283, loss_v1=0, loss_v2=0, nll_loss=1.073, ntokens=1187.2, nsentences=32, sample_size=1187.2, sample_size_v1=0, sample_size_v2=0, ppl=2.1, wps=623.9, ups=0.53, wpb=1187.2, bsz=32, num_updates=16910, lr=2.15282e-05, gnorm=2.66, clip=100, loss_scale=256, train_wall=19, gb_free=11.3, wall=31769
2023-05-26 08:12:54 - progress_bar.py[line:272] - INFO: epoch 010:   1359 / 1732 loss=2.261, loss_v1=0, loss_v2=0, nll_loss=1.047, ntokens=1104.5, nsentences=32, sample_size=1104.5, sample_size_v1=0, sample_size_v2=0, ppl=2.07, wps=582.8, ups=0.53, wpb=1104.5, bsz=32, num_updates=16920, lr=2.1522e-05, gnorm=2.739, clip=100, loss_scale=256, train_wall=19, gb_free=11.2, wall=31788
2023-05-26 08:13:13 - progress_bar.py[line:272] - INFO: epoch 010:   1369 / 1732 loss=2.311, loss_v1=0, loss_v2=0, nll_loss=1.103, ntokens=1096, nsentences=32, sample_size=1096, sample_size_v1=0, sample_size_v2=0, ppl=2.15, wps=579.6, ups=0.53, wpb=1096, bsz=32, num_updates=16930, lr=2.15159e-05, gnorm=3.013, clip=100, loss_scale=256, train_wall=19, gb_free=11.2, wall=31807
2023-05-26 08:13:31 - progress_bar.py[line:272] - INFO: epoch 010:   1379 / 1732 loss=2.316, loss_v1=0, loss_v2=0, nll_loss=1.11, ntokens=1115.7, nsentences=32, sample_size=1115.7, sample_size_v1=0, sample_size_v2=0, ppl=2.16, wps=596.5, ups=0.53, wpb=1115.7, bsz=32, num_updates=16940, lr=2.15097e-05, gnorm=3.191, clip=100, loss_scale=256, train_wall=19, gb_free=11.4, wall=31826
2023-05-26 08:13:50 - progress_bar.py[line:272] - INFO: epoch 010:   1389 / 1732 loss=2.297, loss_v1=0, loss_v2=0, nll_loss=1.087, ntokens=1122.1, nsentences=32, sample_size=1122.1, sample_size_v1=0, sample_size_v2=0, ppl=2.12, wps=597.9, ups=0.53, wpb=1122.1, bsz=32, num_updates=16950, lr=2.15036e-05, gnorm=3.046, clip=100, loss_scale=256, train_wall=19, gb_free=11.5, wall=31845
2023-05-26 08:14:09 - progress_bar.py[line:272] - INFO: epoch 010:   1399 / 1732 loss=2.272, loss_v1=0, loss_v2=0, nll_loss=1.061, ntokens=1113, nsentences=32, sample_size=1113, sample_size_v1=0, sample_size_v2=0, ppl=2.09, wps=589.7, ups=0.53, wpb=1113, bsz=32, num_updates=16960, lr=2.14975e-05, gnorm=2.767, clip=100, loss_scale=256, train_wall=19, gb_free=11.1, wall=31864
2023-05-26 08:14:11 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 128.0
2023-05-26 08:14:30 - progress_bar.py[line:272] - INFO: epoch 010:   1410 / 1732 loss=2.324, loss_v1=0, loss_v2=0, nll_loss=1.119, ntokens=1192.3, nsentences=32, sample_size=1192.3, sample_size_v1=0, sample_size_v2=0, ppl=2.17, wps=576.5, ups=0.48, wpb=1192.3, bsz=32, num_updates=16970, lr=2.14913e-05, gnorm=2.728, clip=100, loss_scale=128, train_wall=21, gb_free=10.9, wall=31884
2023-05-26 08:14:49 - progress_bar.py[line:272] - INFO: epoch 010:   1420 / 1732 loss=2.298, loss_v1=0, loss_v2=0, nll_loss=1.088, ntokens=1265.6, nsentences=32, sample_size=1265.6, sample_size_v1=0, sample_size_v2=0, ppl=2.13, wps=662.4, ups=0.52, wpb=1265.6, bsz=32, num_updates=16980, lr=2.14852e-05, gnorm=2.842, clip=100, loss_scale=128, train_wall=19, gb_free=11.1, wall=31903
2023-05-26 08:15:08 - progress_bar.py[line:272] - INFO: epoch 010:   1430 / 1732 loss=2.27, loss_v1=0, loss_v2=0, nll_loss=1.059, ntokens=1231, nsentences=32, sample_size=1231, sample_size_v1=0, sample_size_v2=0, ppl=2.08, wps=647.2, ups=0.53, wpb=1231, bsz=32, num_updates=16990, lr=2.1479e-05, gnorm=2.655, clip=100, loss_scale=128, train_wall=19, gb_free=10.2, wall=31922
2023-05-26 08:15:27 - progress_bar.py[line:272] - INFO: epoch 010:   1440 / 1732 loss=2.295, loss_v1=0, loss_v2=0, nll_loss=1.088, ntokens=1169.2, nsentences=32, sample_size=1169.2, sample_size_v1=0, sample_size_v2=0, ppl=2.13, wps=619.9, ups=0.53, wpb=1169.2, bsz=32, num_updates=17000, lr=2.14729e-05, gnorm=2.882, clip=100, loss_scale=128, train_wall=19, gb_free=11.3, wall=31941
2023-05-26 08:15:45 - progress_bar.py[line:272] - INFO: epoch 010:   1450 / 1732 loss=2.289, loss_v1=0, loss_v2=0, nll_loss=1.079, ntokens=1100.3, nsentences=32, sample_size=1100.3, sample_size_v1=0, sample_size_v2=0, ppl=2.11, wps=583.8, ups=0.53, wpb=1100.3, bsz=32, num_updates=17010, lr=2.14667e-05, gnorm=2.736, clip=100, loss_scale=128, train_wall=19, gb_free=11, wall=31960
2023-05-26 08:16:04 - progress_bar.py[line:272] - INFO: epoch 010:   1460 / 1732 loss=2.284, loss_v1=0, loss_v2=0, nll_loss=1.073, ntokens=1171.4, nsentences=32, sample_size=1171.4, sample_size_v1=0, sample_size_v2=0, ppl=2.1, wps=619.4, ups=0.53, wpb=1171.4, bsz=32, num_updates=17020, lr=2.14606e-05, gnorm=2.701, clip=100, loss_scale=128, train_wall=19, gb_free=11.1, wall=31979
2023-05-26 08:16:23 - progress_bar.py[line:272] - INFO: epoch 010:   1470 / 1732 loss=2.279, loss_v1=0, loss_v2=0, nll_loss=1.069, ntokens=1176.9, nsentences=32, sample_size=1176.9, sample_size_v1=0, sample_size_v2=0, ppl=2.1, wps=618.9, ups=0.53, wpb=1176.9, bsz=32, num_updates=17030, lr=2.14545e-05, gnorm=2.805, clip=100, loss_scale=128, train_wall=19, gb_free=9.8, wall=31998
2023-05-26 08:16:42 - progress_bar.py[line:272] - INFO: epoch 010:   1480 / 1732 loss=2.309, loss_v1=0, loss_v2=0, nll_loss=1.1, ntokens=1035.6, nsentences=32, sample_size=1035.6, sample_size_v1=0, sample_size_v2=0, ppl=2.14, wps=552.1, ups=0.53, wpb=1035.6, bsz=32, num_updates=17040, lr=2.14483e-05, gnorm=3.058, clip=100, loss_scale=128, train_wall=19, gb_free=11.3, wall=32017
2023-05-26 08:17:01 - progress_bar.py[line:272] - INFO: epoch 010:   1490 / 1732 loss=2.3, loss_v1=0, loss_v2=0, nll_loss=1.091, ntokens=1129.4, nsentences=32, sample_size=1129.4, sample_size_v1=0, sample_size_v2=0, ppl=2.13, wps=596.8, ups=0.53, wpb=1129.4, bsz=32, num_updates=17050, lr=2.14422e-05, gnorm=2.703, clip=100, loss_scale=128, train_wall=19, gb_free=11.4, wall=32036
2023-05-26 08:17:20 - progress_bar.py[line:272] - INFO: epoch 010:   1500 / 1732 loss=2.27, loss_v1=0, loss_v2=0, nll_loss=1.056, ntokens=1104.6, nsentences=32, sample_size=1104.6, sample_size_v1=0, sample_size_v2=0, ppl=2.08, wps=586.9, ups=0.53, wpb=1104.6, bsz=32, num_updates=17060, lr=2.1436e-05, gnorm=2.795, clip=100, loss_scale=128, train_wall=19, gb_free=11.2, wall=32055
2023-05-26 08:17:39 - progress_bar.py[line:272] - INFO: epoch 010:   1510 / 1732 loss=2.265, loss_v1=0, loss_v2=0, nll_loss=1.054, ntokens=1117.2, nsentences=32, sample_size=1117.2, sample_size_v1=0, sample_size_v2=0, ppl=2.08, wps=594.2, ups=0.53, wpb=1117.2, bsz=32, num_updates=17070, lr=2.14299e-05, gnorm=2.755, clip=100, loss_scale=128, train_wall=19, gb_free=11, wall=32073
2023-05-26 08:17:57 - progress_bar.py[line:272] - INFO: epoch 010:   1520 / 1732 loss=2.308, loss_v1=0, loss_v2=0, nll_loss=1.1, ntokens=1039.7, nsentences=32, sample_size=1039.7, sample_size_v1=0, sample_size_v2=0, ppl=2.14, wps=554.4, ups=0.53, wpb=1039.7, bsz=32, num_updates=17080, lr=2.14237e-05, gnorm=2.792, clip=100, loss_scale=128, train_wall=19, gb_free=11.5, wall=32092
2023-05-26 08:18:16 - progress_bar.py[line:272] - INFO: epoch 010:   1530 / 1732 loss=2.329, loss_v1=0, loss_v2=0, nll_loss=1.123, ntokens=1056.8, nsentences=32, sample_size=1056.8, sample_size_v1=0, sample_size_v2=0, ppl=2.18, wps=562.7, ups=0.53, wpb=1056.8, bsz=32, num_updates=17090, lr=2.14176e-05, gnorm=2.982, clip=100, loss_scale=128, train_wall=19, gb_free=10.6, wall=32111
2023-05-26 08:18:35 - progress_bar.py[line:272] - INFO: epoch 010:   1540 / 1732 loss=2.273, loss_v1=0, loss_v2=0, nll_loss=1.06, ntokens=1106.8, nsentences=32, sample_size=1106.8, sample_size_v1=0, sample_size_v2=0, ppl=2.08, wps=584.5, ups=0.53, wpb=1106.8, bsz=32, num_updates=17100, lr=2.14115e-05, gnorm=2.616, clip=100, loss_scale=128, train_wall=19, gb_free=10.9, wall=32130
2023-05-26 08:18:54 - progress_bar.py[line:272] - INFO: epoch 010:   1550 / 1732 loss=2.266, loss_v1=0, loss_v2=0, nll_loss=1.055, ntokens=1063.7, nsentences=32, sample_size=1063.7, sample_size_v1=0, sample_size_v2=0, ppl=2.08, wps=566, ups=0.53, wpb=1063.7, bsz=32, num_updates=17110, lr=2.14053e-05, gnorm=2.689, clip=100, loss_scale=128, train_wall=19, gb_free=10.8, wall=32149
2023-05-26 08:19:13 - progress_bar.py[line:272] - INFO: epoch 010:   1560 / 1732 loss=2.286, loss_v1=0, loss_v2=0, nll_loss=1.075, ntokens=1090.1, nsentences=32, sample_size=1090.1, sample_size_v1=0, sample_size_v2=0, ppl=2.11, wps=580.4, ups=0.53, wpb=1090.1, bsz=32, num_updates=17120, lr=2.13992e-05, gnorm=2.665, clip=100, loss_scale=128, train_wall=19, gb_free=10.4, wall=32167
2023-05-26 08:19:32 - progress_bar.py[line:272] - INFO: epoch 010:   1570 / 1732 loss=2.325, loss_v1=0, loss_v2=0, nll_loss=1.12, ntokens=1073.5, nsentences=32, sample_size=1073.5, sample_size_v1=0, sample_size_v2=0, ppl=2.17, wps=569.4, ups=0.53, wpb=1073.5, bsz=32, num_updates=17130, lr=2.1393e-05, gnorm=2.807, clip=100, loss_scale=128, train_wall=19, gb_free=11.1, wall=32186
2023-05-26 08:19:50 - progress_bar.py[line:272] - INFO: epoch 010:   1580 / 1732 loss=2.317, loss_v1=0, loss_v2=0, nll_loss=1.112, ntokens=980.3, nsentences=32, sample_size=980.3, sample_size_v1=0, sample_size_v2=0, ppl=2.16, wps=523.1, ups=0.53, wpb=980.3, bsz=32, num_updates=17140, lr=2.13869e-05, gnorm=3.106, clip=100, loss_scale=128, train_wall=19, gb_free=11.6, wall=32205
2023-05-26 08:20:09 - progress_bar.py[line:272] - INFO: epoch 010:   1590 / 1732 loss=2.291, loss_v1=0, loss_v2=0, nll_loss=1.08, ntokens=1103, nsentences=32, sample_size=1103, sample_size_v1=0, sample_size_v2=0, ppl=2.11, wps=582.6, ups=0.53, wpb=1103, bsz=32, num_updates=17150, lr=2.13808e-05, gnorm=2.723, clip=100, loss_scale=128, train_wall=19, gb_free=10.6, wall=32224
2023-05-26 08:20:28 - progress_bar.py[line:272] - INFO: epoch 010:   1600 / 1732 loss=2.269, loss_v1=0, loss_v2=0, nll_loss=1.055, ntokens=1067.6, nsentences=32, sample_size=1067.6, sample_size_v1=0, sample_size_v2=0, ppl=2.08, wps=567.5, ups=0.53, wpb=1067.6, bsz=32, num_updates=17160, lr=2.13746e-05, gnorm=2.72, clip=100, loss_scale=128, train_wall=19, gb_free=11, wall=32243
2023-05-26 08:20:47 - progress_bar.py[line:272] - INFO: epoch 010:   1610 / 1732 loss=2.266, loss_v1=0, loss_v2=0, nll_loss=1.054, ntokens=1149.4, nsentences=32, sample_size=1149.4, sample_size_v1=0, sample_size_v2=0, ppl=2.08, wps=605.7, ups=0.53, wpb=1149.4, bsz=32, num_updates=17170, lr=2.13685e-05, gnorm=2.845, clip=100, loss_scale=128, train_wall=19, gb_free=11.2, wall=32262
2023-05-26 08:21:06 - progress_bar.py[line:272] - INFO: epoch 010:   1620 / 1732 loss=2.251, loss_v1=0, loss_v2=0, nll_loss=1.036, ntokens=1143.9, nsentences=32, sample_size=1143.9, sample_size_v1=0, sample_size_v2=0, ppl=2.05, wps=602.3, ups=0.53, wpb=1143.9, bsz=32, num_updates=17180, lr=2.13623e-05, gnorm=2.888, clip=100, loss_scale=128, train_wall=19, gb_free=10.5, wall=32281
2023-05-26 08:21:25 - progress_bar.py[line:272] - INFO: epoch 010:   1630 / 1732 loss=2.284, loss_v1=0, loss_v2=0, nll_loss=1.074, ntokens=1148.8, nsentences=32, sample_size=1148.8, sample_size_v1=0, sample_size_v2=0, ppl=2.11, wps=606.2, ups=0.53, wpb=1148.8, bsz=32, num_updates=17190, lr=2.13562e-05, gnorm=2.878, clip=100, loss_scale=128, train_wall=19, gb_free=11.1, wall=32300
2023-05-26 08:21:44 - progress_bar.py[line:272] - INFO: epoch 010:   1640 / 1732 loss=2.26, loss_v1=0, loss_v2=0, nll_loss=1.047, ntokens=1148.2, nsentences=32, sample_size=1148.2, sample_size_v1=0, sample_size_v2=0, ppl=2.07, wps=611.2, ups=0.53, wpb=1148.2, bsz=32, num_updates=17200, lr=2.135e-05, gnorm=2.891, clip=100, loss_scale=128, train_wall=19, gb_free=11, wall=32319
2023-05-26 08:22:03 - progress_bar.py[line:272] - INFO: epoch 010:   1650 / 1732 loss=2.269, loss_v1=0, loss_v2=0, nll_loss=1.057, ntokens=1158.7, nsentences=32, sample_size=1158.7, sample_size_v1=0, sample_size_v2=0, ppl=2.08, wps=612.1, ups=0.53, wpb=1158.7, bsz=32, num_updates=17210, lr=2.13439e-05, gnorm=2.927, clip=100, loss_scale=128, train_wall=19, gb_free=11.7, wall=32337
2023-05-26 08:22:22 - progress_bar.py[line:272] - INFO: epoch 010:   1660 / 1732 loss=2.308, loss_v1=0, loss_v2=0, nll_loss=1.101, ntokens=997.6, nsentences=32, sample_size=997.6, sample_size_v1=0, sample_size_v2=0, ppl=2.14, wps=532.1, ups=0.53, wpb=997.6, bsz=32, num_updates=17220, lr=2.13378e-05, gnorm=3.126, clip=100, loss_scale=128, train_wall=19, gb_free=11.3, wall=32356
2023-05-26 08:22:40 - progress_bar.py[line:272] - INFO: epoch 010:   1670 / 1732 loss=2.292, loss_v1=0, loss_v2=0, nll_loss=1.081, ntokens=1015.8, nsentences=32, sample_size=1015.8, sample_size_v1=0, sample_size_v2=0, ppl=2.12, wps=543.2, ups=0.53, wpb=1015.8, bsz=32, num_updates=17230, lr=2.13316e-05, gnorm=2.984, clip=100, loss_scale=128, train_wall=19, gb_free=11.4, wall=32375
2023-05-26 08:22:59 - progress_bar.py[line:272] - INFO: epoch 010:   1680 / 1732 loss=2.238, loss_v1=0, loss_v2=0, nll_loss=1.02, ntokens=1181.3, nsentences=32, sample_size=1181.3, sample_size_v1=0, sample_size_v2=0, ppl=2.03, wps=620.9, ups=0.53, wpb=1181.3, bsz=32, num_updates=17240, lr=2.13255e-05, gnorm=2.833, clip=100, loss_scale=128, train_wall=19, gb_free=11.1, wall=32394
2023-05-26 08:23:18 - progress_bar.py[line:272] - INFO: epoch 010:   1690 / 1732 loss=2.267, loss_v1=0, loss_v2=0, nll_loss=1.056, ntokens=1198.5, nsentences=32, sample_size=1198.5, sample_size_v1=0, sample_size_v2=0, ppl=2.08, wps=627, ups=0.52, wpb=1198.5, bsz=32, num_updates=17250, lr=2.13193e-05, gnorm=2.8, clip=100, loss_scale=128, train_wall=19, gb_free=10.8, wall=32413
2023-05-26 08:23:38 - progress_bar.py[line:272] - INFO: epoch 010:   1700 / 1732 loss=2.264, loss_v1=0, loss_v2=0, nll_loss=1.05, ntokens=1281, nsentences=32, sample_size=1281, sample_size_v1=0, sample_size_v2=0, ppl=2.07, wps=668.4, ups=0.52, wpb=1281, bsz=32, num_updates=17260, lr=2.13132e-05, gnorm=2.513, clip=100, loss_scale=128, train_wall=19, gb_free=11.4, wall=32432
2023-05-26 08:23:57 - progress_bar.py[line:272] - INFO: epoch 010:   1710 / 1732 loss=2.288, loss_v1=0, loss_v2=0, nll_loss=1.078, ntokens=1170.9, nsentences=32, sample_size=1170.9, sample_size_v1=0, sample_size_v2=0, ppl=2.11, wps=618.6, ups=0.53, wpb=1170.9, bsz=32, num_updates=17270, lr=2.1307e-05, gnorm=2.749, clip=100, loss_scale=128, train_wall=19, gb_free=10.2, wall=32451
2023-05-26 08:24:16 - progress_bar.py[line:272] - INFO: epoch 010:   1720 / 1732 loss=2.263, loss_v1=0, loss_v2=0, nll_loss=1.052, ntokens=1171, nsentences=32, sample_size=1171, sample_size_v1=0, sample_size_v2=0, ppl=2.07, wps=615.2, ups=0.53, wpb=1171, bsz=32, num_updates=17280, lr=2.13009e-05, gnorm=2.591, clip=100, loss_scale=128, train_wall=19, gb_free=11.3, wall=32470
2023-05-26 08:24:34 - progress_bar.py[line:272] - INFO: epoch 010:   1730 / 1732 loss=2.319, loss_v1=0, loss_v2=0, nll_loss=1.111, ntokens=1126.4, nsentences=32, sample_size=1126.4, sample_size_v1=0, sample_size_v2=0, ppl=2.16, wps=596.2, ups=0.53, wpb=1126.4, bsz=32, num_updates=17290, lr=2.12948e-05, gnorm=2.633, clip=100, loss_scale=128, train_wall=19, gb_free=11.2, wall=32489
2023-05-26 08:24:37 - train.py[line:332] - INFO: end of epoch 10 (average epoch stats below)
2023-05-26 08:24:37 - progress_bar.py[line:282] - INFO: epoch 010 | loss 2.297 | loss_v1 0 | loss_v2 0 | nll_loss 1.088 | ntokens 1051.53 | nsentences 31.986 | sample_size 1051.53 | sample_size_v1 0 | sample_size_v2 0 | ppl 2.13 | wps 559.9 | ups 0.53 | wpb 1051.5 | bsz 32 | num_updates 17292 | lr 2.12935e-05 | gnorm 2.837 | clip 99.9 | loss_scale 128 | train_wall 3240 | gb_free 11.7 | wall 32492
2023-05-26 08:24:37 - trainer.py[line:639] - INFO: loading train data for epoch 11
local datafile ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 0 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 0 finished initializing row_count and line_idx-to-offset mapping
file ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 0 row count 55400 total row count 55400
slice_id 0 seek offset 0
2023-05-26 08:24:39 - trainer.py[line:703] - INFO: begin training epoch 11
2023-05-26 08:24:39 - train.py[line:305] - INFO: Start iterating over samples
2023-05-26 08:24:54 - progress_bar.py[line:272] - INFO: epoch 011:      8 / 1732 loss=2.24, loss_v1=0, loss_v2=0, nll_loss=1.023, ntokens=1080.1, nsentences=29.6, sample_size=1080.1, sample_size_v1=0, sample_size_v2=0, ppl=2.03, wps=547.2, ups=0.51, wpb=1080.1, bsz=29.6, num_updates=17300, lr=2.12886e-05, gnorm=3.115, clip=100, loss_scale=128, train_wall=18, gb_free=10.3, wall=32509
2023-05-26 08:25:13 - progress_bar.py[line:272] - INFO: epoch 011:     18 / 1732 loss=2.208, loss_v1=0, loss_v2=0, nll_loss=0.991, ntokens=1071.6, nsentences=32, sample_size=1071.6, sample_size_v1=0, sample_size_v2=0, ppl=1.99, wps=567.8, ups=0.53, wpb=1071.6, bsz=32, num_updates=17310, lr=2.12825e-05, gnorm=2.599, clip=100, loss_scale=128, train_wall=19, gb_free=11.1, wall=32528
2023-05-26 08:25:32 - progress_bar.py[line:272] - INFO: epoch 011:     28 / 1732 loss=2.268, loss_v1=0, loss_v2=0, nll_loss=1.054, ntokens=959.8, nsentences=32, sample_size=959.8, sample_size_v1=0, sample_size_v2=0, ppl=2.08, wps=512.2, ups=0.53, wpb=959.8, bsz=32, num_updates=17320, lr=2.12763e-05, gnorm=2.858, clip=100, loss_scale=128, train_wall=19, gb_free=11.3, wall=32546
2023-05-26 08:25:51 - progress_bar.py[line:272] - INFO: epoch 011:     38 / 1732 loss=2.097, loss_v1=0, loss_v2=0, nll_loss=0.866, ntokens=1177.1, nsentences=32, sample_size=1177.1, sample_size_v1=0, sample_size_v2=0, ppl=1.82, wps=618, ups=0.53, wpb=1177.1, bsz=32, num_updates=17330, lr=2.12702e-05, gnorm=2.239, clip=100, loss_scale=128, train_wall=19, gb_free=11.3, wall=32566
2023-05-26 08:26:10 - progress_bar.py[line:272] - INFO: epoch 011:     48 / 1732 loss=2.144, loss_v1=0, loss_v2=0, nll_loss=0.918, ntokens=1064.2, nsentences=32, sample_size=1064.2, sample_size_v1=0, sample_size_v2=0, ppl=1.89, wps=563.8, ups=0.53, wpb=1064.2, bsz=32, num_updates=17340, lr=2.12641e-05, gnorm=2.654, clip=100, loss_scale=128, train_wall=19, gb_free=10.8, wall=32584
2023-05-26 08:26:28 - progress_bar.py[line:272] - INFO: epoch 011:     58 / 1732 loss=2.041, loss_v1=0, loss_v2=0, nll_loss=0.806, ntokens=1039.9, nsentences=32, sample_size=1039.9, sample_size_v1=0, sample_size_v2=0, ppl=1.75, wps=556.5, ups=0.54, wpb=1039.9, bsz=32, num_updates=17350, lr=2.12579e-05, gnorm=2.629, clip=100, loss_scale=128, train_wall=19, gb_free=11.6, wall=32603
2023-05-26 08:26:48 - progress_bar.py[line:272] - INFO: epoch 011:     68 / 1732 loss=1.984, loss_v1=0, loss_v2=0, nll_loss=0.738, ntokens=1401.1, nsentences=32, sample_size=1401.1, sample_size_v1=0, sample_size_v2=0, ppl=1.67, wps=718.6, ups=0.51, wpb=1401.1, bsz=32, num_updates=17360, lr=2.12518e-05, gnorm=1.804, clip=100, loss_scale=128, train_wall=19, gb_free=10, wall=32623
2023-05-26 08:27:07 - progress_bar.py[line:272] - INFO: epoch 011:     78 / 1732 loss=2.08, loss_v1=0, loss_v2=0, nll_loss=0.848, ntokens=1268.8, nsentences=32, sample_size=1268.8, sample_size_v1=0, sample_size_v2=0, ppl=1.8, wps=654, ups=0.52, wpb=1268.8, bsz=32, num_updates=17370, lr=2.12456e-05, gnorm=2.346, clip=100, loss_scale=128, train_wall=19, gb_free=9.9, wall=32642
2023-05-26 08:27:26 - progress_bar.py[line:272] - INFO: epoch 011:     88 / 1732 loss=2.155, loss_v1=0, loss_v2=0, nll_loss=0.927, ntokens=1100.2, nsentences=32, sample_size=1100.2, sample_size_v1=0, sample_size_v2=0, ppl=1.9, wps=575.5, ups=0.52, wpb=1100.2, bsz=32, num_updates=17380, lr=2.12395e-05, gnorm=2.639, clip=100, loss_scale=128, train_wall=19, gb_free=11, wall=32661
2023-05-26 08:27:45 - progress_bar.py[line:272] - INFO: epoch 011:     98 / 1732 loss=2.113, loss_v1=0, loss_v2=0, nll_loss=0.884, ntokens=1080.6, nsentences=32, sample_size=1080.6, sample_size_v1=0, sample_size_v2=0, ppl=1.85, wps=571.3, ups=0.53, wpb=1080.6, bsz=32, num_updates=17390, lr=2.12333e-05, gnorm=2.401, clip=100, loss_scale=128, train_wall=19, gb_free=11.3, wall=32680
2023-05-26 08:28:04 - progress_bar.py[line:272] - INFO: epoch 011:    108 / 1732 loss=2.297, loss_v1=0, loss_v2=0, nll_loss=1.089, ntokens=978.3, nsentences=32, sample_size=978.3, sample_size_v1=0, sample_size_v2=0, ppl=2.13, wps=523.8, ups=0.54, wpb=978.3, bsz=32, num_updates=17400, lr=2.12272e-05, gnorm=2.874, clip=100, loss_scale=128, train_wall=19, gb_free=11.7, wall=32699
2023-05-26 08:28:23 - progress_bar.py[line:272] - INFO: epoch 011:    118 / 1732 loss=2.302, loss_v1=0, loss_v2=0, nll_loss=1.093, ntokens=1087, nsentences=32, sample_size=1087, sample_size_v1=0, sample_size_v2=0, ppl=2.13, wps=571.8, ups=0.53, wpb=1087, bsz=32, num_updates=17410, lr=2.12211e-05, gnorm=2.902, clip=100, loss_scale=128, train_wall=19, gb_free=10.9, wall=32718
2023-05-26 08:28:42 - progress_bar.py[line:272] - INFO: epoch 011:    128 / 1732 loss=2.263, loss_v1=0, loss_v2=0, nll_loss=1.049, ntokens=1177.5, nsentences=32, sample_size=1177.5, sample_size_v1=0, sample_size_v2=0, ppl=2.07, wps=613, ups=0.52, wpb=1177.5, bsz=32, num_updates=17420, lr=2.12149e-05, gnorm=2.624, clip=100, loss_scale=128, train_wall=19, gb_free=11.4, wall=32737
2023-05-26 08:29:01 - progress_bar.py[line:272] - INFO: epoch 011:    138 / 1732 loss=2.227, loss_v1=0, loss_v2=0, nll_loss=1.01, ntokens=1228, nsentences=32, sample_size=1228, sample_size_v1=0, sample_size_v2=0, ppl=2.01, wps=643, ups=0.52, wpb=1228, bsz=32, num_updates=17430, lr=2.12088e-05, gnorm=2.457, clip=100, loss_scale=128, train_wall=19, gb_free=11, wall=32756
2023-05-26 08:29:21 - progress_bar.py[line:272] - INFO: epoch 011:    148 / 1732 loss=2.18, loss_v1=0, loss_v2=0, nll_loss=0.958, ntokens=1210.4, nsentences=32, sample_size=1210.4, sample_size_v1=0, sample_size_v2=0, ppl=1.94, wps=626.8, ups=0.52, wpb=1210.4, bsz=32, num_updates=17440, lr=2.12026e-05, gnorm=2.315, clip=100, loss_scale=128, train_wall=19, gb_free=10.6, wall=32775
2023-05-26 08:29:40 - progress_bar.py[line:272] - INFO: epoch 011:    158 / 1732 loss=2.235, loss_v1=0, loss_v2=0, nll_loss=1.02, ntokens=1139, nsentences=32, sample_size=1139, sample_size_v1=0, sample_size_v2=0, ppl=2.03, wps=592.3, ups=0.52, wpb=1139, bsz=32, num_updates=17450, lr=2.11965e-05, gnorm=2.598, clip=100, loss_scale=128, train_wall=19, gb_free=11.2, wall=32795
2023-05-26 08:29:59 - progress_bar.py[line:272] - INFO: epoch 011:    168 / 1732 loss=2.211, loss_v1=0, loss_v2=0, nll_loss=0.992, ntokens=1015.2, nsentences=32, sample_size=1015.2, sample_size_v1=0, sample_size_v2=0, ppl=1.99, wps=537.8, ups=0.53, wpb=1015.2, bsz=32, num_updates=17460, lr=2.11903e-05, gnorm=2.783, clip=100, loss_scale=128, train_wall=19, gb_free=11.4, wall=32813
2023-05-26 08:30:18 - progress_bar.py[line:272] - INFO: epoch 011:    178 / 1732 loss=2.21, loss_v1=0, loss_v2=0, nll_loss=0.992, ntokens=1025.5, nsentences=32, sample_size=1025.5, sample_size_v1=0, sample_size_v2=0, ppl=1.99, wps=541.8, ups=0.53, wpb=1025.5, bsz=32, num_updates=17470, lr=2.11842e-05, gnorm=2.767, clip=100, loss_scale=128, train_wall=19, gb_free=11, wall=32832
2023-05-26 08:30:37 - progress_bar.py[line:272] - INFO: epoch 011:    188 / 1732 loss=2.173, loss_v1=0, loss_v2=0, nll_loss=0.95, ntokens=1150.5, nsentences=32, sample_size=1150.5, sample_size_v1=0, sample_size_v2=0, ppl=1.93, wps=601.4, ups=0.52, wpb=1150.5, bsz=32, num_updates=17480, lr=2.11781e-05, gnorm=2.437, clip=100, loss_scale=256, train_wall=19, gb_free=11.1, wall=32852
2023-05-26 08:30:56 - progress_bar.py[line:272] - INFO: epoch 011:    198 / 1732 loss=2.234, loss_v1=0, loss_v2=0, nll_loss=1.017, ntokens=1142.2, nsentences=32, sample_size=1142.2, sample_size_v1=0, sample_size_v2=0, ppl=2.02, wps=601.6, ups=0.53, wpb=1142.2, bsz=32, num_updates=17490, lr=2.11719e-05, gnorm=2.669, clip=100, loss_scale=256, train_wall=19, gb_free=11, wall=32871
2023-05-26 08:31:14 - progress_bar.py[line:272] - INFO: epoch 011:    208 / 1732 loss=2.316, loss_v1=0, loss_v2=0, nll_loss=1.11, ntokens=961.8, nsentences=32, sample_size=961.8, sample_size_v1=0, sample_size_v2=0, ppl=2.16, wps=518.3, ups=0.54, wpb=961.8, bsz=32, num_updates=17500, lr=2.11658e-05, gnorm=3.191, clip=100, loss_scale=256, train_wall=19, gb_free=11.1, wall=32889
2023-05-26 08:31:33 - progress_bar.py[line:272] - INFO: epoch 011:    218 / 1732 loss=2.31, loss_v1=0, loss_v2=0, nll_loss=1.101, ntokens=1149.2, nsentences=32, sample_size=1149.2, sample_size_v1=0, sample_size_v2=0, ppl=2.15, wps=613.3, ups=0.53, wpb=1149.2, bsz=32, num_updates=17510, lr=2.11596e-05, gnorm=2.729, clip=100, loss_scale=256, train_wall=19, gb_free=11.5, wall=32908
2023-05-26 08:31:52 - progress_bar.py[line:272] - INFO: epoch 011:    228 / 1732 loss=2.312, loss_v1=0, loss_v2=0, nll_loss=1.106, ntokens=1111.8, nsentences=32, sample_size=1111.8, sample_size_v1=0, sample_size_v2=0, ppl=2.15, wps=594.1, ups=0.53, wpb=1111.8, bsz=32, num_updates=17520, lr=2.11535e-05, gnorm=2.777, clip=100, loss_scale=256, train_wall=19, gb_free=11.6, wall=32927
2023-05-26 08:32:11 - progress_bar.py[line:272] - INFO: epoch 011:    238 / 1732 loss=2.356, loss_v1=0, loss_v2=0, nll_loss=1.152, ntokens=1085.4, nsentences=32, sample_size=1085.4, sample_size_v1=0, sample_size_v2=0, ppl=2.22, wps=580.4, ups=0.53, wpb=1085.4, bsz=32, num_updates=17530, lr=2.11473e-05, gnorm=2.833, clip=100, loss_scale=256, train_wall=19, gb_free=11.5, wall=32945
2023-05-26 08:32:29 - progress_bar.py[line:272] - INFO: epoch 011:    248 / 1732 loss=2.307, loss_v1=0, loss_v2=0, nll_loss=1.099, ntokens=1171.6, nsentences=32, sample_size=1171.6, sample_size_v1=0, sample_size_v2=0, ppl=2.14, wps=622.1, ups=0.53, wpb=1171.6, bsz=32, num_updates=17540, lr=2.11412e-05, gnorm=2.476, clip=100, loss_scale=256, train_wall=19, gb_free=11.3, wall=32964
2023-05-26 08:32:48 - progress_bar.py[line:272] - INFO: epoch 011:    258 / 1732 loss=2.335, loss_v1=0, loss_v2=0, nll_loss=1.132, ntokens=1118, nsentences=32, sample_size=1118, sample_size_v1=0, sample_size_v2=0, ppl=2.19, wps=596.6, ups=0.53, wpb=1118, bsz=32, num_updates=17550, lr=2.11351e-05, gnorm=2.778, clip=100, loss_scale=256, train_wall=19, gb_free=11.4, wall=32983
2023-05-26 08:33:07 - progress_bar.py[line:272] - INFO: epoch 011:    268 / 1732 loss=2.309, loss_v1=0, loss_v2=0, nll_loss=1.1, ntokens=1160.8, nsentences=32, sample_size=1160.8, sample_size_v1=0, sample_size_v2=0, ppl=2.14, wps=618.8, ups=0.53, wpb=1160.8, bsz=32, num_updates=17560, lr=2.11289e-05, gnorm=2.471, clip=100, loss_scale=256, train_wall=19, gb_free=11.6, wall=33002
2023-05-26 08:33:26 - progress_bar.py[line:272] - INFO: epoch 011:    278 / 1732 loss=2.324, loss_v1=0, loss_v2=0, nll_loss=1.118, ntokens=1136.9, nsentences=32, sample_size=1136.9, sample_size_v1=0, sample_size_v2=0, ppl=2.17, wps=602.6, ups=0.53, wpb=1136.9, bsz=32, num_updates=17570, lr=2.11228e-05, gnorm=2.884, clip=100, loss_scale=256, train_wall=19, gb_free=11.3, wall=33020
2023-05-26 08:33:45 - progress_bar.py[line:272] - INFO: epoch 011:    288 / 1732 loss=2.298, loss_v1=0, loss_v2=0, nll_loss=1.09, ntokens=1173.3, nsentences=32, sample_size=1173.3, sample_size_v1=0, sample_size_v2=0, ppl=2.13, wps=621.8, ups=0.53, wpb=1173.3, bsz=32, num_updates=17580, lr=2.11166e-05, gnorm=2.396, clip=100, loss_scale=256, train_wall=19, gb_free=11.2, wall=33039
2023-05-26 08:34:03 - progress_bar.py[line:272] - INFO: epoch 011:    298 / 1732 loss=2.315, loss_v1=0, loss_v2=0, nll_loss=1.109, ntokens=1074.2, nsentences=32, sample_size=1074.2, sample_size_v1=0, sample_size_v2=0, ppl=2.16, wps=575.7, ups=0.54, wpb=1074.2, bsz=32, num_updates=17590, lr=2.11105e-05, gnorm=2.967, clip=100, loss_scale=256, train_wall=19, gb_free=11.8, wall=33058
2023-05-26 08:34:22 - progress_bar.py[line:272] - INFO: epoch 011:    308 / 1732 loss=2.302, loss_v1=0, loss_v2=0, nll_loss=1.094, ntokens=1090.6, nsentences=32, sample_size=1090.6, sample_size_v1=0, sample_size_v2=0, ppl=2.13, wps=582.1, ups=0.53, wpb=1090.6, bsz=32, num_updates=17600, lr=2.11044e-05, gnorm=3.034, clip=100, loss_scale=256, train_wall=19, gb_free=11.7, wall=33077
2023-05-26 08:34:41 - progress_bar.py[line:272] - INFO: epoch 011:    318 / 1732 loss=2.317, loss_v1=0, loss_v2=0, nll_loss=1.109, ntokens=1026, nsentences=32, sample_size=1026, sample_size_v1=0, sample_size_v2=0, ppl=2.16, wps=549.9, ups=0.54, wpb=1026, bsz=32, num_updates=17610, lr=2.10982e-05, gnorm=3.2, clip=100, loss_scale=256, train_wall=19, gb_free=11.3, wall=33095
2023-05-26 08:34:57 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 128.0
2023-05-26 08:35:01 - progress_bar.py[line:272] - INFO: epoch 011:    329 / 1732 loss=2.342, loss_v1=0, loss_v2=0, nll_loss=1.138, ntokens=1006.8, nsentences=32, sample_size=1006.8, sample_size_v1=0, sample_size_v2=0, ppl=2.2, wps=493.8, ups=0.49, wpb=1006.8, bsz=32, num_updates=17620, lr=2.10921e-05, gnorm=3.155, clip=100, loss_scale=128, train_wall=20, gb_free=11.3, wall=33116
2023-05-26 08:35:20 - progress_bar.py[line:272] - INFO: epoch 011:    339 / 1732 loss=2.304, loss_v1=0, loss_v2=0, nll_loss=1.098, ntokens=950.6, nsentences=32, sample_size=950.6, sample_size_v1=0, sample_size_v2=0, ppl=2.14, wps=512.3, ups=0.54, wpb=950.6, bsz=32, num_updates=17630, lr=2.10859e-05, gnorm=3.144, clip=100, loss_scale=128, train_wall=19, gb_free=11.7, wall=33134
2023-05-26 08:35:38 - progress_bar.py[line:272] - INFO: epoch 011:    349 / 1732 loss=2.31, loss_v1=0, loss_v2=0, nll_loss=1.102, ntokens=919.8, nsentences=32, sample_size=919.8, sample_size_v1=0, sample_size_v2=0, ppl=2.15, wps=497.5, ups=0.54, wpb=919.8, bsz=32, num_updates=17640, lr=2.10798e-05, gnorm=3.322, clip=100, loss_scale=128, train_wall=18, gb_free=11.9, wall=33153
2023-05-26 08:35:57 - progress_bar.py[line:272] - INFO: epoch 011:    359 / 1732 loss=2.347, loss_v1=0, loss_v2=0, nll_loss=1.144, ntokens=933.3, nsentences=32, sample_size=933.3, sample_size_v1=0, sample_size_v2=0, ppl=2.21, wps=503.8, ups=0.54, wpb=933.3, bsz=32, num_updates=17650, lr=2.10736e-05, gnorm=3.414, clip=100, loss_scale=128, train_wall=18, gb_free=11.2, wall=33171
2023-05-26 08:36:15 - progress_bar.py[line:272] - INFO: epoch 011:    369 / 1732 loss=2.346, loss_v1=0, loss_v2=0, nll_loss=1.142, ntokens=971.1, nsentences=32, sample_size=971.1, sample_size_v1=0, sample_size_v2=0, ppl=2.21, wps=523.7, ups=0.54, wpb=971.1, bsz=32, num_updates=17660, lr=2.10675e-05, gnorm=3.169, clip=100, loss_scale=128, train_wall=19, gb_free=11.5, wall=33190
2023-05-26 08:36:34 - progress_bar.py[line:272] - INFO: epoch 011:    379 / 1732 loss=2.347, loss_v1=0, loss_v2=0, nll_loss=1.144, ntokens=1075.7, nsentences=32, sample_size=1075.7, sample_size_v1=0, sample_size_v2=0, ppl=2.21, wps=580.7, ups=0.54, wpb=1075.7, bsz=32, num_updates=17670, lr=2.10614e-05, gnorm=2.93, clip=100, loss_scale=128, train_wall=18, gb_free=11, wall=33208
2023-05-26 08:36:52 - progress_bar.py[line:272] - INFO: epoch 011:    389 / 1732 loss=2.325, loss_v1=0, loss_v2=0, nll_loss=1.12, ntokens=1027.5, nsentences=32, sample_size=1027.5, sample_size_v1=0, sample_size_v2=0, ppl=2.17, wps=552.9, ups=0.54, wpb=1027.5, bsz=32, num_updates=17680, lr=2.10552e-05, gnorm=3.126, clip=100, loss_scale=128, train_wall=19, gb_free=11.6, wall=33227
2023-05-26 08:37:11 - progress_bar.py[line:272] - INFO: epoch 011:    399 / 1732 loss=2.327, loss_v1=0, loss_v2=0, nll_loss=1.121, ntokens=981.4, nsentences=32, sample_size=981.4, sample_size_v1=0, sample_size_v2=0, ppl=2.17, wps=529, ups=0.54, wpb=981.4, bsz=32, num_updates=17690, lr=2.10491e-05, gnorm=3.282, clip=100, loss_scale=128, train_wall=19, gb_free=11.4, wall=33246
2023-05-26 08:37:30 - progress_bar.py[line:272] - INFO: epoch 011:    409 / 1732 loss=2.313, loss_v1=0, loss_v2=0, nll_loss=1.106, ntokens=1066.6, nsentences=32, sample_size=1066.6, sample_size_v1=0, sample_size_v2=0, ppl=2.15, wps=571.4, ups=0.54, wpb=1066.6, bsz=32, num_updates=17700, lr=2.10429e-05, gnorm=2.811, clip=100, loss_scale=128, train_wall=19, gb_free=11.5, wall=33264
2023-05-26 08:37:48 - progress_bar.py[line:272] - INFO: epoch 011:    419 / 1732 loss=2.285, loss_v1=0, loss_v2=0, nll_loss=1.075, ntokens=1023.6, nsentences=32, sample_size=1023.6, sample_size_v1=0, sample_size_v2=0, ppl=2.11, wps=550.3, ups=0.54, wpb=1023.6, bsz=32, num_updates=17710, lr=2.10368e-05, gnorm=2.807, clip=100, loss_scale=128, train_wall=19, gb_free=11.2, wall=33283
2023-05-26 08:38:07 - progress_bar.py[line:272] - INFO: epoch 011:    429 / 1732 loss=2.288, loss_v1=0, loss_v2=0, nll_loss=1.077, ntokens=1011.5, nsentences=32, sample_size=1011.5, sample_size_v1=0, sample_size_v2=0, ppl=2.11, wps=544.3, ups=0.54, wpb=1011.5, bsz=32, num_updates=17720, lr=2.10306e-05, gnorm=2.951, clip=100, loss_scale=128, train_wall=19, gb_free=11.6, wall=33301
2023-05-26 08:38:25 - progress_bar.py[line:272] - INFO: epoch 011:    439 / 1732 loss=2.322, loss_v1=0, loss_v2=0, nll_loss=1.116, ntokens=1024.1, nsentences=32, sample_size=1024.1, sample_size_v1=0, sample_size_v2=0, ppl=2.17, wps=551.1, ups=0.54, wpb=1024.1, bsz=32, num_updates=17730, lr=2.10245e-05, gnorm=2.961, clip=100, loss_scale=128, train_wall=19, gb_free=10.8, wall=33320
2023-05-26 08:38:44 - progress_bar.py[line:272] - INFO: epoch 011:    449 / 1732 loss=2.333, loss_v1=0, loss_v2=0, nll_loss=1.128, ntokens=917.8, nsentences=32, sample_size=917.8, sample_size_v1=0, sample_size_v2=0, ppl=2.19, wps=490.1, ups=0.53, wpb=917.8, bsz=32, num_updates=17740, lr=2.10184e-05, gnorm=2.98, clip=100, loss_scale=128, train_wall=19, gb_free=11.3, wall=33339
2023-05-26 08:39:03 - progress_bar.py[line:272] - INFO: epoch 011:    459 / 1732 loss=2.329, loss_v1=0, loss_v2=0, nll_loss=1.123, ntokens=1003.6, nsentences=32, sample_size=1003.6, sample_size_v1=0, sample_size_v2=0, ppl=2.18, wps=542.1, ups=0.54, wpb=1003.6, bsz=32, num_updates=17750, lr=2.10122e-05, gnorm=3.132, clip=100, loss_scale=128, train_wall=18, gb_free=11.6, wall=33357
2023-05-26 08:39:21 - progress_bar.py[line:272] - INFO: epoch 011:    469 / 1732 loss=2.334, loss_v1=0, loss_v2=0, nll_loss=1.128, ntokens=1054.5, nsentences=32, sample_size=1054.5, sample_size_v1=0, sample_size_v2=0, ppl=2.19, wps=561.8, ups=0.53, wpb=1054.5, bsz=32, num_updates=17760, lr=2.10061e-05, gnorm=3.094, clip=100, loss_scale=128, train_wall=19, gb_free=10.6, wall=33376
2023-05-26 08:39:40 - progress_bar.py[line:272] - INFO: epoch 011:    479 / 1732 loss=2.35, loss_v1=0, loss_v2=0, nll_loss=1.146, ntokens=1034.5, nsentences=32, sample_size=1034.5, sample_size_v1=0, sample_size_v2=0, ppl=2.21, wps=556.8, ups=0.54, wpb=1034.5, bsz=32, num_updates=17770, lr=2.09999e-05, gnorm=3.032, clip=100, loss_scale=128, train_wall=19, gb_free=11.6, wall=33395
2023-05-26 08:39:58 - progress_bar.py[line:272] - INFO: epoch 011:    489 / 1732 loss=2.306, loss_v1=0, loss_v2=0, nll_loss=1.099, ntokens=912, nsentences=32, sample_size=912, sample_size_v1=0, sample_size_v2=0, ppl=2.14, wps=492.6, ups=0.54, wpb=912, bsz=32, num_updates=17780, lr=2.09938e-05, gnorm=3.056, clip=100, loss_scale=128, train_wall=18, gb_free=11.6, wall=33413
2023-05-26 08:40:17 - progress_bar.py[line:272] - INFO: epoch 011:    499 / 1732 loss=2.308, loss_v1=0, loss_v2=0, nll_loss=1.103, ntokens=957.3, nsentences=32, sample_size=957.3, sample_size_v1=0, sample_size_v2=0, ppl=2.15, wps=518.1, ups=0.54, wpb=957.3, bsz=32, num_updates=17790, lr=2.09877e-05, gnorm=3.359, clip=100, loss_scale=128, train_wall=18, gb_free=11.4, wall=33432
2023-05-26 08:40:36 - progress_bar.py[line:272] - INFO: epoch 011:    509 / 1732 loss=2.338, loss_v1=0, loss_v2=0, nll_loss=1.133, ntokens=1025.1, nsentences=32, sample_size=1025.1, sample_size_v1=0, sample_size_v2=0, ppl=2.19, wps=552.9, ups=0.54, wpb=1025.1, bsz=32, num_updates=17800, lr=2.09815e-05, gnorm=2.955, clip=100, loss_scale=128, train_wall=19, gb_free=11.7, wall=33450
2023-05-26 08:40:54 - progress_bar.py[line:272] - INFO: epoch 011:    519 / 1732 loss=2.31, loss_v1=0, loss_v2=0, nll_loss=1.102, ntokens=1029.2, nsentences=32, sample_size=1029.2, sample_size_v1=0, sample_size_v2=0, ppl=2.15, wps=556.4, ups=0.54, wpb=1029.2, bsz=32, num_updates=17810, lr=2.09754e-05, gnorm=2.963, clip=100, loss_scale=128, train_wall=18, gb_free=11.9, wall=33469
2023-05-26 08:41:12 - progress_bar.py[line:272] - INFO: epoch 011:    529 / 1732 loss=2.332, loss_v1=0, loss_v2=0, nll_loss=1.128, ntokens=945, nsentences=32, sample_size=945, sample_size_v1=0, sample_size_v2=0, ppl=2.19, wps=512.9, ups=0.54, wpb=945, bsz=32, num_updates=17820, lr=2.09692e-05, gnorm=3.357, clip=100, loss_scale=128, train_wall=18, gb_free=11.5, wall=33487
2023-05-26 08:41:31 - progress_bar.py[line:272] - INFO: epoch 011:    539 / 1732 loss=2.31, loss_v1=0, loss_v2=0, nll_loss=1.102, ntokens=990.9, nsentences=32, sample_size=990.9, sample_size_v1=0, sample_size_v2=0, ppl=2.15, wps=535.3, ups=0.54, wpb=990.9, bsz=32, num_updates=17830, lr=2.09631e-05, gnorm=2.995, clip=100, loss_scale=128, train_wall=18, gb_free=11.4, wall=33506
2023-05-26 08:41:50 - progress_bar.py[line:272] - INFO: epoch 011:    549 / 1732 loss=2.346, loss_v1=0, loss_v2=0, nll_loss=1.143, ntokens=1038.3, nsentences=32, sample_size=1038.3, sample_size_v1=0, sample_size_v2=0, ppl=2.21, wps=559.3, ups=0.54, wpb=1038.3, bsz=32, num_updates=17840, lr=2.09569e-05, gnorm=3.07, clip=100, loss_scale=128, train_wall=19, gb_free=11.5, wall=33524
2023-05-26 08:42:08 - progress_bar.py[line:272] - INFO: epoch 011:    559 / 1732 loss=2.333, loss_v1=0, loss_v2=0, nll_loss=1.13, ntokens=1016.1, nsentences=32, sample_size=1016.1, sample_size_v1=0, sample_size_v2=0, ppl=2.19, wps=546.5, ups=0.54, wpb=1016.1, bsz=32, num_updates=17850, lr=2.09508e-05, gnorm=3.223, clip=100, loss_scale=128, train_wall=19, gb_free=11, wall=33543
2023-05-26 08:42:27 - progress_bar.py[line:272] - INFO: epoch 011:    569 / 1732 loss=2.363, loss_v1=0, loss_v2=0, nll_loss=1.16, ntokens=1004.9, nsentences=32, sample_size=1004.9, sample_size_v1=0, sample_size_v2=0, ppl=2.24, wps=539, ups=0.54, wpb=1004.9, bsz=32, num_updates=17860, lr=2.09447e-05, gnorm=3.243, clip=100, loss_scale=128, train_wall=19, gb_free=11.2, wall=33561
2023-05-26 08:42:45 - progress_bar.py[line:272] - INFO: epoch 011:    579 / 1732 loss=2.317, loss_v1=0, loss_v2=0, nll_loss=1.11, ntokens=1003.1, nsentences=32, sample_size=1003.1, sample_size_v1=0, sample_size_v2=0, ppl=2.16, wps=537.4, ups=0.54, wpb=1003.1, bsz=32, num_updates=17870, lr=2.09385e-05, gnorm=3.325, clip=100, loss_scale=128, train_wall=19, gb_free=11, wall=33580
2023-05-26 08:43:04 - progress_bar.py[line:272] - INFO: epoch 011:    589 / 1732 loss=2.328, loss_v1=0, loss_v2=0, nll_loss=1.122, ntokens=951.2, nsentences=32, sample_size=951.2, sample_size_v1=0, sample_size_v2=0, ppl=2.18, wps=510.6, ups=0.54, wpb=951.2, bsz=32, num_updates=17880, lr=2.09324e-05, gnorm=3.339, clip=100, loss_scale=128, train_wall=19, gb_free=10.7, wall=33599
2023-05-26 08:43:23 - progress_bar.py[line:272] - INFO: epoch 011:    599 / 1732 loss=2.282, loss_v1=0, loss_v2=0, nll_loss=1.072, ntokens=935, nsentences=32, sample_size=935, sample_size_v1=0, sample_size_v2=0, ppl=2.1, wps=505.1, ups=0.54, wpb=935, bsz=32, num_updates=17890, lr=2.09262e-05, gnorm=3.227, clip=100, loss_scale=128, train_wall=18, gb_free=12.1, wall=33617
2023-05-26 08:43:41 - progress_bar.py[line:272] - INFO: epoch 011:    609 / 1732 loss=2.322, loss_v1=0, loss_v2=0, nll_loss=1.118, ntokens=917.6, nsentences=32, sample_size=917.6, sample_size_v1=0, sample_size_v2=0, ppl=2.17, wps=496.1, ups=0.54, wpb=917.6, bsz=32, num_updates=17900, lr=2.09201e-05, gnorm=3.408, clip=100, loss_scale=128, train_wall=18, gb_free=10.5, wall=33636
2023-05-26 08:43:59 - progress_bar.py[line:272] - INFO: epoch 011:    619 / 1732 loss=2.345, loss_v1=0, loss_v2=0, nll_loss=1.139, ntokens=845.1, nsentences=32, sample_size=845.1, sample_size_v1=0, sample_size_v2=0, ppl=2.2, wps=460.9, ups=0.55, wpb=845.1, bsz=32, num_updates=17910, lr=2.09139e-05, gnorm=3.573, clip=100, loss_scale=128, train_wall=18, gb_free=11.7, wall=33654
2023-05-26 08:44:18 - progress_bar.py[line:272] - INFO: epoch 011:    629 / 1732 loss=2.309, loss_v1=0, loss_v2=0, nll_loss=1.099, ntokens=934.9, nsentences=32, sample_size=934.9, sample_size_v1=0, sample_size_v2=0, ppl=2.14, wps=507.9, ups=0.54, wpb=934.9, bsz=32, num_updates=17920, lr=2.09078e-05, gnorm=3.279, clip=100, loss_scale=128, train_wall=18, gb_free=11.9, wall=33672
2023-05-26 08:44:36 - progress_bar.py[line:272] - INFO: epoch 011:    639 / 1732 loss=2.344, loss_v1=0, loss_v2=0, nll_loss=1.143, ntokens=925.6, nsentences=32, sample_size=925.6, sample_size_v1=0, sample_size_v2=0, ppl=2.21, wps=500.6, ups=0.54, wpb=925.6, bsz=32, num_updates=17930, lr=2.09017e-05, gnorm=3.473, clip=100, loss_scale=128, train_wall=18, gb_free=11.4, wall=33691
2023-05-26 08:44:55 - progress_bar.py[line:272] - INFO: epoch 011:    649 / 1732 loss=2.324, loss_v1=0, loss_v2=0, nll_loss=1.118, ntokens=987, nsentences=32, sample_size=987, sample_size_v1=0, sample_size_v2=0, ppl=2.17, wps=536, ups=0.54, wpb=987, bsz=32, num_updates=17940, lr=2.08955e-05, gnorm=3.242, clip=100, loss_scale=128, train_wall=18, gb_free=11.4, wall=33709
2023-05-26 08:45:13 - progress_bar.py[line:272] - INFO: epoch 011:    659 / 1732 loss=2.328, loss_v1=0, loss_v2=0, nll_loss=1.122, ntokens=871.8, nsentences=32, sample_size=871.8, sample_size_v1=0, sample_size_v2=0, ppl=2.18, wps=476.4, ups=0.55, wpb=871.8, bsz=32, num_updates=17950, lr=2.08894e-05, gnorm=3.254, clip=100, loss_scale=128, train_wall=18, gb_free=12.1, wall=33728
2023-05-26 08:45:31 - progress_bar.py[line:272] - INFO: epoch 011:    669 / 1732 loss=2.329, loss_v1=0, loss_v2=0, nll_loss=1.126, ntokens=918, nsentences=32, sample_size=918, sample_size_v1=0, sample_size_v2=0, ppl=2.18, wps=497.9, ups=0.54, wpb=918, bsz=32, num_updates=17960, lr=2.08832e-05, gnorm=3.259, clip=100, loss_scale=128, train_wall=18, gb_free=11.4, wall=33746
2023-05-26 08:45:50 - progress_bar.py[line:272] - INFO: epoch 011:    679 / 1732 loss=2.342, loss_v1=0, loss_v2=0, nll_loss=1.136, ntokens=982.1, nsentences=32, sample_size=982.1, sample_size_v1=0, sample_size_v2=0, ppl=2.2, wps=530.4, ups=0.54, wpb=982.1, bsz=32, num_updates=17970, lr=2.08771e-05, gnorm=3.581, clip=100, loss_scale=128, train_wall=18, gb_free=11.8, wall=33765
2023-05-26 08:46:08 - progress_bar.py[line:272] - INFO: epoch 011:    689 / 1732 loss=2.335, loss_v1=0, loss_v2=0, nll_loss=1.129, ntokens=949.7, nsentences=32, sample_size=949.7, sample_size_v1=0, sample_size_v2=0, ppl=2.19, wps=513.7, ups=0.54, wpb=949.7, bsz=32, num_updates=17980, lr=2.0871e-05, gnorm=3.231, clip=100, loss_scale=128, train_wall=18, gb_free=10.7, wall=33783
2023-05-26 08:46:27 - progress_bar.py[line:272] - INFO: epoch 011:    699 / 1732 loss=2.318, loss_v1=0, loss_v2=0, nll_loss=1.115, ntokens=981.3, nsentences=32, sample_size=981.3, sample_size_v1=0, sample_size_v2=0, ppl=2.17, wps=527, ups=0.54, wpb=981.3, bsz=32, num_updates=17990, lr=2.08648e-05, gnorm=3.341, clip=100, loss_scale=128, train_wall=19, gb_free=11.6, wall=33802
2023-05-26 08:46:46 - progress_bar.py[line:272] - INFO: epoch 011:    709 / 1732 loss=2.309, loss_v1=0, loss_v2=0, nll_loss=1.099, ntokens=928.2, nsentences=32, sample_size=928.2, sample_size_v1=0, sample_size_v2=0, ppl=2.14, wps=504.5, ups=0.54, wpb=928.2, bsz=32, num_updates=18000, lr=2.08587e-05, gnorm=3.294, clip=100, loss_scale=128, train_wall=18, gb_free=11.1, wall=33820
2023-05-26 08:47:04 - progress_bar.py[line:272] - INFO: epoch 011:    719 / 1732 loss=2.319, loss_v1=0, loss_v2=0, nll_loss=1.112, ntokens=863.5, nsentences=32, sample_size=863.5, sample_size_v1=0, sample_size_v2=0, ppl=2.16, wps=470.4, ups=0.54, wpb=863.5, bsz=32, num_updates=18010, lr=2.08525e-05, gnorm=3.371, clip=100, loss_scale=128, train_wall=18, gb_free=12, wall=33839
2023-05-26 08:47:22 - progress_bar.py[line:272] - INFO: epoch 011:    729 / 1732 loss=2.304, loss_v1=0, loss_v2=0, nll_loss=1.099, ntokens=920.7, nsentences=32, sample_size=920.7, sample_size_v1=0, sample_size_v2=0, ppl=2.14, wps=497.4, ups=0.54, wpb=920.7, bsz=32, num_updates=18020, lr=2.08464e-05, gnorm=3.477, clip=100, loss_scale=128, train_wall=18, gb_free=11.8, wall=33857
2023-05-26 08:47:41 - progress_bar.py[line:272] - INFO: epoch 011:    739 / 1732 loss=2.303, loss_v1=0, loss_v2=0, nll_loss=1.096, ntokens=1016.5, nsentences=32, sample_size=1016.5, sample_size_v1=0, sample_size_v2=0, ppl=2.14, wps=551, ups=0.54, wpb=1016.5, bsz=32, num_updates=18030, lr=2.08402e-05, gnorm=3.512, clip=100, loss_scale=128, train_wall=18, gb_free=11.5, wall=33876
2023-05-26 08:47:59 - progress_bar.py[line:272] - INFO: epoch 011:    749 / 1732 loss=2.306, loss_v1=0, loss_v2=0, nll_loss=1.095, ntokens=964.9, nsentences=32, sample_size=964.9, sample_size_v1=0, sample_size_v2=0, ppl=2.14, wps=519.4, ups=0.54, wpb=964.9, bsz=32, num_updates=18040, lr=2.08341e-05, gnorm=3.316, clip=100, loss_scale=128, train_wall=19, gb_free=11.6, wall=33894
2023-05-26 08:48:18 - progress_bar.py[line:272] - INFO: epoch 011:    759 / 1732 loss=2.295, loss_v1=0, loss_v2=0, nll_loss=1.086, ntokens=966.4, nsentences=32, sample_size=966.4, sample_size_v1=0, sample_size_v2=0, ppl=2.12, wps=523.5, ups=0.54, wpb=966.4, bsz=32, num_updates=18050, lr=2.0828e-05, gnorm=3.173, clip=100, loss_scale=128, train_wall=18, gb_free=11.5, wall=33913
2023-05-26 08:48:36 - progress_bar.py[line:272] - INFO: epoch 011:    769 / 1732 loss=2.319, loss_v1=0, loss_v2=0, nll_loss=1.115, ntokens=931.4, nsentences=32, sample_size=931.4, sample_size_v1=0, sample_size_v2=0, ppl=2.17, wps=505.6, ups=0.54, wpb=931.4, bsz=32, num_updates=18060, lr=2.08218e-05, gnorm=3.282, clip=100, loss_scale=128, train_wall=18, gb_free=11.9, wall=33931
2023-05-26 08:48:55 - progress_bar.py[line:272] - INFO: epoch 011:    779 / 1732 loss=2.313, loss_v1=0, loss_v2=0, nll_loss=1.104, ntokens=1031.1, nsentences=32, sample_size=1031.1, sample_size_v1=0, sample_size_v2=0, ppl=2.15, wps=556.6, ups=0.54, wpb=1031.1, bsz=32, num_updates=18070, lr=2.08157e-05, gnorm=3.035, clip=100, loss_scale=128, train_wall=18, gb_free=11.3, wall=33950
2023-05-26 08:49:13 - progress_bar.py[line:272] - INFO: epoch 011:    789 / 1732 loss=2.315, loss_v1=0, loss_v2=0, nll_loss=1.108, ntokens=1004.1, nsentences=32, sample_size=1004.1, sample_size_v1=0, sample_size_v2=0, ppl=2.16, wps=543.7, ups=0.54, wpb=1004.1, bsz=32, num_updates=18080, lr=2.08095e-05, gnorm=3.251, clip=100, loss_scale=128, train_wall=18, gb_free=11.9, wall=33968
2023-05-26 08:49:32 - progress_bar.py[line:272] - INFO: epoch 011:    799 / 1732 loss=2.318, loss_v1=0, loss_v2=0, nll_loss=1.113, ntokens=1038.9, nsentences=32, sample_size=1038.9, sample_size_v1=0, sample_size_v2=0, ppl=2.16, wps=561.8, ups=0.54, wpb=1038.9, bsz=32, num_updates=18090, lr=2.08034e-05, gnorm=3.134, clip=100, loss_scale=128, train_wall=18, gb_free=11.4, wall=33986
2023-05-26 08:49:50 - progress_bar.py[line:272] - INFO: epoch 011:    809 / 1732 loss=2.311, loss_v1=0, loss_v2=0, nll_loss=1.104, ntokens=922.8, nsentences=32, sample_size=922.8, sample_size_v1=0, sample_size_v2=0, ppl=2.15, wps=500, ups=0.54, wpb=922.8, bsz=32, num_updates=18100, lr=2.07972e-05, gnorm=3.322, clip=100, loss_scale=128, train_wall=18, gb_free=11.7, wall=34005
2023-05-26 08:50:09 - progress_bar.py[line:272] - INFO: epoch 011:    819 / 1732 loss=2.326, loss_v1=0, loss_v2=0, nll_loss=1.119, ntokens=909.6, nsentences=32, sample_size=909.6, sample_size_v1=0, sample_size_v2=0, ppl=2.17, wps=492.8, ups=0.54, wpb=909.6, bsz=32, num_updates=18110, lr=2.07911e-05, gnorm=3.628, clip=100, loss_scale=128, train_wall=18, gb_free=11.8, wall=34023
2023-05-26 08:50:27 - progress_bar.py[line:272] - INFO: epoch 011:    829 / 1732 loss=2.298, loss_v1=0, loss_v2=0, nll_loss=1.09, ntokens=917.4, nsentences=32, sample_size=917.4, sample_size_v1=0, sample_size_v2=0, ppl=2.13, wps=496.3, ups=0.54, wpb=917.4, bsz=32, num_updates=18120, lr=2.0785e-05, gnorm=3.252, clip=100, loss_scale=128, train_wall=18, gb_free=11.8, wall=34042
2023-05-26 08:50:46 - progress_bar.py[line:272] - INFO: epoch 011:    839 / 1732 loss=2.325, loss_v1=0, loss_v2=0, nll_loss=1.12, ntokens=902.5, nsentences=32, sample_size=902.5, sample_size_v1=0, sample_size_v2=0, ppl=2.17, wps=493, ups=0.55, wpb=902.5, bsz=32, num_updates=18130, lr=2.07788e-05, gnorm=3.601, clip=100, loss_scale=256, train_wall=18, gb_free=11.8, wall=34060
2023-05-26 08:51:04 - progress_bar.py[line:272] - INFO: epoch 011:    849 / 1732 loss=2.311, loss_v1=0, loss_v2=0, nll_loss=1.103, ntokens=1036.8, nsentences=32, sample_size=1036.8, sample_size_v1=0, sample_size_v2=0, ppl=2.15, wps=558.8, ups=0.54, wpb=1036.8, bsz=32, num_updates=18140, lr=2.07727e-05, gnorm=3.273, clip=100, loss_scale=256, train_wall=19, gb_free=11.4, wall=34079
2023-05-26 08:51:23 - progress_bar.py[line:272] - INFO: epoch 011:    859 / 1732 loss=2.299, loss_v1=0, loss_v2=0, nll_loss=1.093, ntokens=930.3, nsentences=32, sample_size=930.3, sample_size_v1=0, sample_size_v2=0, ppl=2.13, wps=505, ups=0.54, wpb=930.3, bsz=32, num_updates=18150, lr=2.07665e-05, gnorm=3.464, clip=100, loss_scale=256, train_wall=18, gb_free=11.4, wall=34097
2023-05-26 08:51:41 - progress_bar.py[line:272] - INFO: epoch 011:    869 / 1732 loss=2.326, loss_v1=0, loss_v2=0, nll_loss=1.121, ntokens=962.2, nsentences=32, sample_size=962.2, sample_size_v1=0, sample_size_v2=0, ppl=2.17, wps=520.3, ups=0.54, wpb=962.2, bsz=32, num_updates=18160, lr=2.07604e-05, gnorm=3.476, clip=100, loss_scale=256, train_wall=18, gb_free=11.6, wall=34116
2023-05-26 08:52:00 - progress_bar.py[line:272] - INFO: epoch 011:    879 / 1732 loss=2.256, loss_v1=0, loss_v2=0, nll_loss=1.041, ntokens=1001.9, nsentences=32, sample_size=1001.9, sample_size_v1=0, sample_size_v2=0, ppl=2.06, wps=537.3, ups=0.54, wpb=1001.9, bsz=32, num_updates=18170, lr=2.07543e-05, gnorm=3.117, clip=100, loss_scale=256, train_wall=19, gb_free=11.7, wall=34134
2023-05-26 08:52:18 - progress_bar.py[line:272] - INFO: epoch 011:    889 / 1732 loss=2.255, loss_v1=0, loss_v2=0, nll_loss=1.041, ntokens=975.7, nsentences=32, sample_size=975.7, sample_size_v1=0, sample_size_v2=0, ppl=2.06, wps=526.5, ups=0.54, wpb=975.7, bsz=32, num_updates=18180, lr=2.07481e-05, gnorm=3.404, clip=100, loss_scale=256, train_wall=19, gb_free=11.6, wall=34153
2023-05-26 08:52:37 - progress_bar.py[line:272] - INFO: epoch 011:    899 / 1732 loss=2.251, loss_v1=0, loss_v2=0, nll_loss=1.035, ntokens=1055.9, nsentences=32, sample_size=1055.9, sample_size_v1=0, sample_size_v2=0, ppl=2.05, wps=568.4, ups=0.54, wpb=1055.9, bsz=32, num_updates=18190, lr=2.0742e-05, gnorm=3.102, clip=100, loss_scale=256, train_wall=19, gb_free=11.1, wall=34171
2023-05-26 08:52:52 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 128.0
2023-05-26 08:52:57 - progress_bar.py[line:272] - INFO: epoch 011:    910 / 1732 loss=2.3, loss_v1=0, loss_v2=0, nll_loss=1.09, ntokens=976.2, nsentences=32, sample_size=976.2, sample_size_v1=0, sample_size_v2=0, ppl=2.13, wps=480.9, ups=0.49, wpb=976.2, bsz=32, num_updates=18200, lr=2.07358e-05, gnorm=3.347, clip=100, loss_scale=128, train_wall=20, gb_free=11.5, wall=34192
2023-05-26 08:53:16 - progress_bar.py[line:272] - INFO: epoch 011:    920 / 1732 loss=2.334, loss_v1=0, loss_v2=0, nll_loss=1.131, ntokens=983.5, nsentences=32, sample_size=983.5, sample_size_v1=0, sample_size_v2=0, ppl=2.19, wps=530.4, ups=0.54, wpb=983.5, bsz=32, num_updates=18210, lr=2.07297e-05, gnorm=3.462, clip=100, loss_scale=128, train_wall=19, gb_free=11.7, wall=34210
2023-05-26 08:53:34 - progress_bar.py[line:272] - INFO: epoch 011:    930 / 1732 loss=2.289, loss_v1=0, loss_v2=0, nll_loss=1.079, ntokens=1038.6, nsentences=32, sample_size=1038.6, sample_size_v1=0, sample_size_v2=0, ppl=2.11, wps=555.4, ups=0.53, wpb=1038.6, bsz=32, num_updates=18220, lr=2.07235e-05, gnorm=3.221, clip=100, loss_scale=128, train_wall=19, gb_free=11.7, wall=34229
2023-05-26 08:53:53 - progress_bar.py[line:272] - INFO: epoch 011:    940 / 1732 loss=2.288, loss_v1=0, loss_v2=0, nll_loss=1.078, ntokens=1043.2, nsentences=32, sample_size=1043.2, sample_size_v1=0, sample_size_v2=0, ppl=2.11, wps=554.6, ups=0.53, wpb=1043.2, bsz=32, num_updates=18230, lr=2.07174e-05, gnorm=3.223, clip=100, loss_scale=128, train_wall=19, gb_free=10.9, wall=34248
2023-05-26 08:54:12 - progress_bar.py[line:272] - INFO: epoch 011:    950 / 1732 loss=2.303, loss_v1=0, loss_v2=0, nll_loss=1.094, ntokens=1038.6, nsentences=32, sample_size=1038.6, sample_size_v1=0, sample_size_v2=0, ppl=2.14, wps=552.8, ups=0.53, wpb=1038.6, bsz=32, num_updates=18240, lr=2.07113e-05, gnorm=3.249, clip=100, loss_scale=128, train_wall=19, gb_free=11.6, wall=34267
2023-05-26 08:54:31 - progress_bar.py[line:272] - INFO: epoch 011:    960 / 1732 loss=2.299, loss_v1=0, loss_v2=0, nll_loss=1.09, ntokens=1044.3, nsentences=32, sample_size=1044.3, sample_size_v1=0, sample_size_v2=0, ppl=2.13, wps=556.9, ups=0.53, wpb=1044.3, bsz=32, num_updates=18250, lr=2.07051e-05, gnorm=3.065, clip=100, loss_scale=128, train_wall=19, gb_free=11.4, wall=34285
2023-05-26 08:54:49 - progress_bar.py[line:272] - INFO: epoch 011:    970 / 1732 loss=2.321, loss_v1=0, loss_v2=0, nll_loss=1.115, ntokens=1054.8, nsentences=32, sample_size=1054.8, sample_size_v1=0, sample_size_v2=0, ppl=2.17, wps=564.2, ups=0.53, wpb=1054.8, bsz=32, num_updates=18260, lr=2.0699e-05, gnorm=3.422, clip=100, loss_scale=128, train_wall=19, gb_free=11.5, wall=34304
2023-05-26 08:55:08 - progress_bar.py[line:272] - INFO: epoch 011:    980 / 1732 loss=2.293, loss_v1=0, loss_v2=0, nll_loss=1.082, ntokens=1012, nsentences=32, sample_size=1012, sample_size_v1=0, sample_size_v2=0, ppl=2.12, wps=536.1, ups=0.53, wpb=1012, bsz=32, num_updates=18270, lr=2.06928e-05, gnorm=3.177, clip=100, loss_scale=128, train_wall=19, gb_free=11.5, wall=34323
2023-05-26 08:55:27 - progress_bar.py[line:272] - INFO: epoch 011:    990 / 1732 loss=2.304, loss_v1=0, loss_v2=0, nll_loss=1.096, ntokens=1049.1, nsentences=32, sample_size=1049.1, sample_size_v1=0, sample_size_v2=0, ppl=2.14, wps=556.6, ups=0.53, wpb=1049.1, bsz=32, num_updates=18280, lr=2.06867e-05, gnorm=3.163, clip=100, loss_scale=128, train_wall=19, gb_free=11.4, wall=34342
2023-05-26 08:55:46 - progress_bar.py[line:272] - INFO: epoch 011:   1000 / 1732 loss=2.29, loss_v1=0, loss_v2=0, nll_loss=1.08, ntokens=1015.5, nsentences=32, sample_size=1015.5, sample_size_v1=0, sample_size_v2=0, ppl=2.11, wps=545.1, ups=0.54, wpb=1015.5, bsz=32, num_updates=18290, lr=2.06805e-05, gnorm=3.486, clip=100, loss_scale=128, train_wall=19, gb_free=11.7, wall=34360
2023-05-26 08:56:04 - progress_bar.py[line:272] - INFO: epoch 011:   1010 / 1732 loss=2.305, loss_v1=0, loss_v2=0, nll_loss=1.095, ntokens=1013.4, nsentences=32, sample_size=1013.4, sample_size_v1=0, sample_size_v2=0, ppl=2.14, wps=541.9, ups=0.53, wpb=1013.4, bsz=32, num_updates=18300, lr=2.06744e-05, gnorm=3.58, clip=100, loss_scale=128, train_wall=19, gb_free=11.7, wall=34379
2023-05-26 08:56:23 - progress_bar.py[line:272] - INFO: epoch 011:   1020 / 1732 loss=2.272, loss_v1=0, loss_v2=0, nll_loss=1.06, ntokens=1035.8, nsentences=32, sample_size=1035.8, sample_size_v1=0, sample_size_v2=0, ppl=2.08, wps=553.2, ups=0.53, wpb=1035.8, bsz=32, num_updates=18310, lr=2.06683e-05, gnorm=3.143, clip=100, loss_scale=128, train_wall=19, gb_free=11.3, wall=34398
2023-05-26 08:56:42 - progress_bar.py[line:272] - INFO: epoch 011:   1030 / 1732 loss=2.303, loss_v1=0, loss_v2=0, nll_loss=1.094, ntokens=1101.6, nsentences=32, sample_size=1101.6, sample_size_v1=0, sample_size_v2=0, ppl=2.14, wps=580.9, ups=0.53, wpb=1101.6, bsz=32, num_updates=18320, lr=2.06621e-05, gnorm=3.107, clip=100, loss_scale=128, train_wall=19, gb_free=11.2, wall=34417
2023-05-26 08:57:01 - progress_bar.py[line:272] - INFO: epoch 011:   1040 / 1732 loss=2.298, loss_v1=0, loss_v2=0, nll_loss=1.088, ntokens=1070.8, nsentences=32, sample_size=1070.8, sample_size_v1=0, sample_size_v2=0, ppl=2.13, wps=569.6, ups=0.53, wpb=1070.8, bsz=32, num_updates=18330, lr=2.0656e-05, gnorm=3.405, clip=100, loss_scale=128, train_wall=19, gb_free=10.8, wall=34436
2023-05-26 08:57:20 - progress_bar.py[line:272] - INFO: epoch 011:   1050 / 1732 loss=2.303, loss_v1=0, loss_v2=0, nll_loss=1.096, ntokens=1039.3, nsentences=32, sample_size=1039.3, sample_size_v1=0, sample_size_v2=0, ppl=2.14, wps=556, ups=0.53, wpb=1039.3, bsz=32, num_updates=18340, lr=2.06498e-05, gnorm=3.376, clip=100, loss_scale=128, train_wall=19, gb_free=11.4, wall=34454
2023-05-26 08:57:38 - progress_bar.py[line:272] - INFO: epoch 011:   1060 / 1732 loss=2.292, loss_v1=0, loss_v2=0, nll_loss=1.083, ntokens=1066.3, nsentences=32, sample_size=1066.3, sample_size_v1=0, sample_size_v2=0, ppl=2.12, wps=568.4, ups=0.53, wpb=1066.3, bsz=32, num_updates=18350, lr=2.06437e-05, gnorm=3.073, clip=100, loss_scale=128, train_wall=19, gb_free=10.9, wall=34473
2023-05-26 08:57:57 - progress_bar.py[line:272] - INFO: epoch 011:   1070 / 1732 loss=2.297, loss_v1=0, loss_v2=0, nll_loss=1.088, ntokens=985.6, nsentences=32, sample_size=985.6, sample_size_v1=0, sample_size_v2=0, ppl=2.13, wps=527.9, ups=0.54, wpb=985.6, bsz=32, num_updates=18360, lr=2.06376e-05, gnorm=3.31, clip=100, loss_scale=128, train_wall=19, gb_free=10.9, wall=34492
2023-05-26 08:58:16 - progress_bar.py[line:272] - INFO: epoch 011:   1080 / 1732 loss=2.307, loss_v1=0, loss_v2=0, nll_loss=1.1, ntokens=1039.6, nsentences=32, sample_size=1039.6, sample_size_v1=0, sample_size_v2=0, ppl=2.14, wps=550.4, ups=0.53, wpb=1039.6, bsz=32, num_updates=18370, lr=2.06314e-05, gnorm=3.34, clip=100, loss_scale=128, train_wall=19, gb_free=11.1, wall=34511
2023-05-26 08:58:35 - progress_bar.py[line:272] - INFO: epoch 011:   1090 / 1732 loss=2.293, loss_v1=0, loss_v2=0, nll_loss=1.084, ntokens=1074, nsentences=32, sample_size=1074, sample_size_v1=0, sample_size_v2=0, ppl=2.12, wps=568.4, ups=0.53, wpb=1074, bsz=32, num_updates=18380, lr=2.06253e-05, gnorm=3.043, clip=100, loss_scale=128, train_wall=19, gb_free=11.2, wall=34530
2023-05-26 08:58:54 - progress_bar.py[line:272] - INFO: epoch 011:   1100 / 1732 loss=2.304, loss_v1=0, loss_v2=0, nll_loss=1.095, ntokens=1032, nsentences=32, sample_size=1032, sample_size_v1=0, sample_size_v2=0, ppl=2.14, wps=551.7, ups=0.53, wpb=1032, bsz=32, num_updates=18390, lr=2.06191e-05, gnorm=3.608, clip=100, loss_scale=128, train_wall=19, gb_free=11.5, wall=34548
2023-05-26 08:59:12 - progress_bar.py[line:272] - INFO: epoch 011:   1110 / 1732 loss=2.295, loss_v1=0, loss_v2=0, nll_loss=1.085, ntokens=1053.3, nsentences=32, sample_size=1053.3, sample_size_v1=0, sample_size_v2=0, ppl=2.12, wps=560, ups=0.53, wpb=1053.3, bsz=32, num_updates=18400, lr=2.0613e-05, gnorm=3.243, clip=100, loss_scale=128, train_wall=19, gb_free=11.4, wall=34567
2023-05-26 08:59:31 - progress_bar.py[line:272] - INFO: epoch 011:   1120 / 1732 loss=2.3, loss_v1=0, loss_v2=0, nll_loss=1.092, ntokens=958.1, nsentences=32, sample_size=958.1, sample_size_v1=0, sample_size_v2=0, ppl=2.13, wps=510.9, ups=0.53, wpb=958.1, bsz=32, num_updates=18410, lr=2.06068e-05, gnorm=3.347, clip=100, loss_scale=128, train_wall=19, gb_free=11.5, wall=34586
2023-05-26 08:59:50 - progress_bar.py[line:272] - INFO: epoch 011:   1130 / 1732 loss=2.278, loss_v1=0, loss_v2=0, nll_loss=1.067, ntokens=1008.8, nsentences=32, sample_size=1008.8, sample_size_v1=0, sample_size_v2=0, ppl=2.1, wps=537.3, ups=0.53, wpb=1008.8, bsz=32, num_updates=18420, lr=2.06007e-05, gnorm=3.068, clip=100, loss_scale=128, train_wall=19, gb_free=11.5, wall=34605
2023-05-26 09:00:09 - progress_bar.py[line:272] - INFO: epoch 011:   1140 / 1732 loss=2.296, loss_v1=0, loss_v2=0, nll_loss=1.085, ntokens=1003.3, nsentences=32, sample_size=1003.3, sample_size_v1=0, sample_size_v2=0, ppl=2.12, wps=537.2, ups=0.54, wpb=1003.3, bsz=32, num_updates=18430, lr=2.05946e-05, gnorm=3.289, clip=100, loss_scale=128, train_wall=19, gb_free=11.7, wall=34623
2023-05-26 09:00:27 - progress_bar.py[line:272] - INFO: epoch 011:   1150 / 1732 loss=2.287, loss_v1=0, loss_v2=0, nll_loss=1.078, ntokens=1020.4, nsentences=32, sample_size=1020.4, sample_size_v1=0, sample_size_v2=0, ppl=2.11, wps=544.9, ups=0.53, wpb=1020.4, bsz=32, num_updates=18440, lr=2.05884e-05, gnorm=3.23, clip=100, loss_scale=128, train_wall=19, gb_free=11.6, wall=34642
2023-05-26 09:00:46 - progress_bar.py[line:272] - INFO: epoch 011:   1160 / 1732 loss=2.275, loss_v1=0, loss_v2=0, nll_loss=1.066, ntokens=995, nsentences=32, sample_size=995, sample_size_v1=0, sample_size_v2=0, ppl=2.09, wps=529.8, ups=0.53, wpb=995, bsz=32, num_updates=18450, lr=2.05823e-05, gnorm=3.511, clip=100, loss_scale=128, train_wall=19, gb_free=11.3, wall=34661
2023-05-26 09:01:05 - progress_bar.py[line:272] - INFO: epoch 011:   1170 / 1732 loss=2.275, loss_v1=0, loss_v2=0, nll_loss=1.062, ntokens=1051.7, nsentences=32, sample_size=1051.7, sample_size_v1=0, sample_size_v2=0, ppl=2.09, wps=558.2, ups=0.53, wpb=1051.7, bsz=32, num_updates=18460, lr=2.05761e-05, gnorm=3.061, clip=100, loss_scale=128, train_wall=19, gb_free=11, wall=34680
2023-05-26 09:01:24 - progress_bar.py[line:272] - INFO: epoch 011:   1180 / 1732 loss=2.27, loss_v1=0, loss_v2=0, nll_loss=1.057, ntokens=1021, nsentences=32, sample_size=1021, sample_size_v1=0, sample_size_v2=0, ppl=2.08, wps=546.6, ups=0.54, wpb=1021, bsz=32, num_updates=18470, lr=2.057e-05, gnorm=3.352, clip=100, loss_scale=128, train_wall=19, gb_free=11.6, wall=34698
2023-05-26 09:01:42 - progress_bar.py[line:272] - INFO: epoch 011:   1190 / 1732 loss=2.293, loss_v1=0, loss_v2=0, nll_loss=1.086, ntokens=996.9, nsentences=32, sample_size=996.9, sample_size_v1=0, sample_size_v2=0, ppl=2.12, wps=531, ups=0.53, wpb=996.9, bsz=32, num_updates=18480, lr=2.05638e-05, gnorm=3.109, clip=100, loss_scale=128, train_wall=19, gb_free=11.2, wall=34717
2023-05-26 09:02:01 - progress_bar.py[line:272] - INFO: epoch 011:   1200 / 1732 loss=2.28, loss_v1=0, loss_v2=0, nll_loss=1.067, ntokens=1118, nsentences=32, sample_size=1118, sample_size_v1=0, sample_size_v2=0, ppl=2.1, wps=592.4, ups=0.53, wpb=1118, bsz=32, num_updates=18490, lr=2.05577e-05, gnorm=3.126, clip=100, loss_scale=128, train_wall=19, gb_free=11.3, wall=34736
2023-05-26 09:02:20 - progress_bar.py[line:272] - INFO: epoch 011:   1210 / 1732 loss=2.263, loss_v1=0, loss_v2=0, nll_loss=1.05, ntokens=1074.7, nsentences=32, sample_size=1074.7, sample_size_v1=0, sample_size_v2=0, ppl=2.07, wps=568.4, ups=0.53, wpb=1074.7, bsz=32, num_updates=18500, lr=2.05516e-05, gnorm=3.201, clip=100, loss_scale=128, train_wall=19, gb_free=11.3, wall=34755
2023-05-26 09:02:39 - progress_bar.py[line:272] - INFO: epoch 011:   1220 / 1732 loss=2.325, loss_v1=0, loss_v2=0, nll_loss=1.121, ntokens=1018.6, nsentences=32, sample_size=1018.6, sample_size_v1=0, sample_size_v2=0, ppl=2.18, wps=544.8, ups=0.53, wpb=1018.6, bsz=32, num_updates=18510, lr=2.05454e-05, gnorm=3.339, clip=100, loss_scale=128, train_wall=19, gb_free=11.4, wall=34774
2023-05-26 09:02:58 - progress_bar.py[line:272] - INFO: epoch 011:   1230 / 1732 loss=2.276, loss_v1=0, loss_v2=0, nll_loss=1.064, ntokens=1037.6, nsentences=32, sample_size=1037.6, sample_size_v1=0, sample_size_v2=0, ppl=2.09, wps=553.8, ups=0.53, wpb=1037.6, bsz=32, num_updates=18520, lr=2.05393e-05, gnorm=3.005, clip=100, loss_scale=128, train_wall=19, gb_free=11, wall=34792
2023-05-26 09:03:17 - progress_bar.py[line:272] - INFO: epoch 011:   1240 / 1732 loss=2.256, loss_v1=0, loss_v2=0, nll_loss=1.042, ntokens=1099.9, nsentences=32, sample_size=1099.9, sample_size_v1=0, sample_size_v2=0, ppl=2.06, wps=583, ups=0.53, wpb=1099.9, bsz=32, num_updates=18530, lr=2.05331e-05, gnorm=3.153, clip=100, loss_scale=128, train_wall=19, gb_free=11, wall=34811
2023-05-26 09:03:35 - progress_bar.py[line:272] - INFO: epoch 011:   1250 / 1732 loss=2.259, loss_v1=0, loss_v2=0, nll_loss=1.047, ntokens=1054.2, nsentences=32, sample_size=1054.2, sample_size_v1=0, sample_size_v2=0, ppl=2.07, wps=560.3, ups=0.53, wpb=1054.2, bsz=32, num_updates=18540, lr=2.0527e-05, gnorm=3.147, clip=100, loss_scale=128, train_wall=19, gb_free=11, wall=34830
2023-05-26 09:03:54 - progress_bar.py[line:272] - INFO: epoch 011:   1260 / 1732 loss=2.263, loss_v1=0, loss_v2=0, nll_loss=1.049, ntokens=1034.2, nsentences=32, sample_size=1034.2, sample_size_v1=0, sample_size_v2=0, ppl=2.07, wps=550, ups=0.53, wpb=1034.2, bsz=32, num_updates=18550, lr=2.05209e-05, gnorm=3.19, clip=100, loss_scale=128, train_wall=19, gb_free=11.2, wall=34849
2023-05-26 09:04:13 - progress_bar.py[line:272] - INFO: epoch 011:   1270 / 1732 loss=2.305, loss_v1=0, loss_v2=0, nll_loss=1.097, ntokens=1069.3, nsentences=32, sample_size=1069.3, sample_size_v1=0, sample_size_v2=0, ppl=2.14, wps=569.6, ups=0.53, wpb=1069.3, bsz=32, num_updates=18560, lr=2.05147e-05, gnorm=2.987, clip=100, loss_scale=128, train_wall=19, gb_free=11.4, wall=34868
2023-05-26 09:04:32 - progress_bar.py[line:272] - INFO: epoch 011:   1280 / 1732 loss=2.281, loss_v1=0, loss_v2=0, nll_loss=1.069, ntokens=1062.1, nsentences=32, sample_size=1062.1, sample_size_v1=0, sample_size_v2=0, ppl=2.1, wps=562.1, ups=0.53, wpb=1062.1, bsz=32, num_updates=18570, lr=2.05086e-05, gnorm=2.976, clip=100, loss_scale=128, train_wall=19, gb_free=11.5, wall=34886
2023-05-26 09:04:51 - progress_bar.py[line:272] - INFO: epoch 011:   1290 / 1732 loss=2.286, loss_v1=0, loss_v2=0, nll_loss=1.074, ntokens=1082.8, nsentences=32, sample_size=1082.8, sample_size_v1=0, sample_size_v2=0, ppl=2.1, wps=571.8, ups=0.53, wpb=1082.8, bsz=32, num_updates=18580, lr=2.05024e-05, gnorm=3.288, clip=100, loss_scale=128, train_wall=19, gb_free=11.2, wall=34905
2023-05-26 09:05:10 - progress_bar.py[line:272] - INFO: epoch 011:   1300 / 1732 loss=2.285, loss_v1=0, loss_v2=0, nll_loss=1.076, ntokens=1083.5, nsentences=32, sample_size=1083.5, sample_size_v1=0, sample_size_v2=0, ppl=2.11, wps=578.2, ups=0.53, wpb=1083.5, bsz=32, num_updates=18590, lr=2.04963e-05, gnorm=3.158, clip=100, loss_scale=128, train_wall=19, gb_free=11.3, wall=34924
2023-05-26 09:05:29 - progress_bar.py[line:272] - INFO: epoch 011:   1310 / 1732 loss=2.322, loss_v1=0, loss_v2=0, nll_loss=1.115, ntokens=1072.8, nsentences=32, sample_size=1072.8, sample_size_v1=0, sample_size_v2=0, ppl=2.17, wps=564.3, ups=0.53, wpb=1072.8, bsz=32, num_updates=18600, lr=2.04901e-05, gnorm=3.384, clip=100, loss_scale=128, train_wall=19, gb_free=11.2, wall=34943
2023-05-26 09:05:47 - progress_bar.py[line:272] - INFO: epoch 011:   1320 / 1732 loss=2.269, loss_v1=0, loss_v2=0, nll_loss=1.058, ntokens=1105.6, nsentences=32, sample_size=1105.6, sample_size_v1=0, sample_size_v2=0, ppl=2.08, wps=585.5, ups=0.53, wpb=1105.6, bsz=32, num_updates=18610, lr=2.0484e-05, gnorm=3.071, clip=100, loss_scale=128, train_wall=19, gb_free=10.1, wall=34962
2023-05-26 09:06:06 - progress_bar.py[line:272] - INFO: epoch 011:   1330 / 1732 loss=2.253, loss_v1=0, loss_v2=0, nll_loss=1.039, ntokens=1099.6, nsentences=32, sample_size=1099.6, sample_size_v1=0, sample_size_v2=0, ppl=2.05, wps=580.6, ups=0.53, wpb=1099.6, bsz=32, num_updates=18620, lr=2.04779e-05, gnorm=2.944, clip=100, loss_scale=128, train_wall=19, gb_free=11, wall=34981
2023-05-26 09:06:25 - progress_bar.py[line:272] - INFO: epoch 011:   1340 / 1732 loss=2.273, loss_v1=0, loss_v2=0, nll_loss=1.061, ntokens=1139, nsentences=32, sample_size=1139, sample_size_v1=0, sample_size_v2=0, ppl=2.09, wps=604.2, ups=0.53, wpb=1139, bsz=32, num_updates=18630, lr=2.04717e-05, gnorm=3.113, clip=100, loss_scale=128, train_wall=19, gb_free=11.2, wall=35000
2023-05-26 09:06:44 - progress_bar.py[line:272] - INFO: epoch 011:   1350 / 1732 loss=2.271, loss_v1=0, loss_v2=0, nll_loss=1.06, ntokens=1168.9, nsentences=32, sample_size=1168.9, sample_size_v1=0, sample_size_v2=0, ppl=2.09, wps=617.1, ups=0.53, wpb=1168.9, bsz=32, num_updates=18640, lr=2.04656e-05, gnorm=2.905, clip=100, loss_scale=128, train_wall=19, gb_free=11.2, wall=35019
2023-05-26 09:07:03 - progress_bar.py[line:272] - INFO: epoch 011:   1360 / 1732 loss=2.253, loss_v1=0, loss_v2=0, nll_loss=1.037, ntokens=1107.8, nsentences=32, sample_size=1107.8, sample_size_v1=0, sample_size_v2=0, ppl=2.05, wps=584.1, ups=0.53, wpb=1107.8, bsz=32, num_updates=18650, lr=2.04594e-05, gnorm=2.978, clip=100, loss_scale=128, train_wall=19, gb_free=10.8, wall=35038
2023-05-26 09:07:22 - progress_bar.py[line:272] - INFO: epoch 011:   1370 / 1732 loss=2.283, loss_v1=0, loss_v2=0, nll_loss=1.071, ntokens=1111.1, nsentences=32, sample_size=1111.1, sample_size_v1=0, sample_size_v2=0, ppl=2.1, wps=588.8, ups=0.53, wpb=1111.1, bsz=32, num_updates=18660, lr=2.04533e-05, gnorm=3.204, clip=100, loss_scale=128, train_wall=19, gb_free=11.1, wall=35057
2023-05-26 09:07:41 - progress_bar.py[line:272] - INFO: epoch 011:   1380 / 1732 loss=2.307, loss_v1=0, loss_v2=0, nll_loss=1.1, ntokens=1113.4, nsentences=32, sample_size=1113.4, sample_size_v1=0, sample_size_v2=0, ppl=2.14, wps=592.6, ups=0.53, wpb=1113.4, bsz=32, num_updates=18670, lr=2.04471e-05, gnorm=3.291, clip=100, loss_scale=128, train_wall=19, gb_free=10.5, wall=35075
2023-05-26 09:08:00 - progress_bar.py[line:272] - INFO: epoch 011:   1390 / 1732 loss=2.286, loss_v1=0, loss_v2=0, nll_loss=1.075, ntokens=1104, nsentences=32, sample_size=1104, sample_size_v1=0, sample_size_v2=0, ppl=2.11, wps=589.7, ups=0.53, wpb=1104, bsz=32, num_updates=18680, lr=2.0441e-05, gnorm=3.302, clip=100, loss_scale=128, train_wall=19, gb_free=11.3, wall=35094
2023-05-26 09:08:18 - progress_bar.py[line:272] - INFO: epoch 011:   1400 / 1732 loss=2.252, loss_v1=0, loss_v2=0, nll_loss=1.037, ntokens=1114.6, nsentences=32, sample_size=1114.6, sample_size_v1=0, sample_size_v2=0, ppl=2.05, wps=590.7, ups=0.53, wpb=1114.6, bsz=32, num_updates=18690, lr=2.04349e-05, gnorm=3.448, clip=100, loss_scale=128, train_wall=19, gb_free=11.1, wall=35113
2023-05-26 09:08:37 - progress_bar.py[line:272] - INFO: epoch 011:   1410 / 1732 loss=2.308, loss_v1=0, loss_v2=0, nll_loss=1.1, ntokens=1192.3, nsentences=32, sample_size=1192.3, sample_size_v1=0, sample_size_v2=0, ppl=2.14, wps=632.4, ups=0.53, wpb=1192.3, bsz=32, num_updates=18700, lr=2.04287e-05, gnorm=3.005, clip=100, loss_scale=128, train_wall=19, gb_free=10.9, wall=35132
2023-05-26 09:08:56 - progress_bar.py[line:272] - INFO: epoch 011:   1420 / 1732 loss=2.286, loss_v1=0, loss_v2=0, nll_loss=1.075, ntokens=1265.6, nsentences=32, sample_size=1265.6, sample_size_v1=0, sample_size_v2=0, ppl=2.11, wps=660.4, ups=0.52, wpb=1265.6, bsz=32, num_updates=18710, lr=2.04226e-05, gnorm=2.932, clip=100, loss_scale=256, train_wall=19, gb_free=11.1, wall=35151
2023-05-26 09:09:15 - progress_bar.py[line:272] - INFO: epoch 011:   1430 / 1732 loss=2.254, loss_v1=0, loss_v2=0, nll_loss=1.039, ntokens=1231, nsentences=32, sample_size=1231, sample_size_v1=0, sample_size_v2=0, ppl=2.05, wps=648.3, ups=0.53, wpb=1231, bsz=32, num_updates=18720, lr=2.04164e-05, gnorm=2.817, clip=100, loss_scale=256, train_wall=19, gb_free=10.2, wall=35170
2023-05-26 09:09:34 - progress_bar.py[line:272] - INFO: epoch 011:   1440 / 1732 loss=2.282, loss_v1=0, loss_v2=0, nll_loss=1.074, ntokens=1169.2, nsentences=32, sample_size=1169.2, sample_size_v1=0, sample_size_v2=0, ppl=2.11, wps=620.2, ups=0.53, wpb=1169.2, bsz=32, num_updates=18730, lr=2.04103e-05, gnorm=3.068, clip=100, loss_scale=256, train_wall=19, gb_free=11.3, wall=35189
2023-05-26 09:09:53 - progress_bar.py[line:272] - INFO: epoch 011:   1450 / 1732 loss=2.276, loss_v1=0, loss_v2=0, nll_loss=1.064, ntokens=1100.3, nsentences=32, sample_size=1100.3, sample_size_v1=0, sample_size_v2=0, ppl=2.09, wps=584.4, ups=0.53, wpb=1100.3, bsz=32, num_updates=18740, lr=2.04042e-05, gnorm=2.975, clip=100, loss_scale=256, train_wall=19, gb_free=11, wall=35208
2023-05-26 09:10:12 - progress_bar.py[line:272] - INFO: epoch 011:   1460 / 1732 loss=2.267, loss_v1=0, loss_v2=0, nll_loss=1.053, ntokens=1171.4, nsentences=32, sample_size=1171.4, sample_size_v1=0, sample_size_v2=0, ppl=2.08, wps=620.4, ups=0.53, wpb=1171.4, bsz=32, num_updates=18750, lr=2.0398e-05, gnorm=2.942, clip=100, loss_scale=256, train_wall=19, gb_free=11.1, wall=35227
2023-05-26 09:10:31 - progress_bar.py[line:272] - INFO: epoch 011:   1470 / 1732 loss=2.264, loss_v1=0, loss_v2=0, nll_loss=1.051, ntokens=1176.9, nsentences=32, sample_size=1176.9, sample_size_v1=0, sample_size_v2=0, ppl=2.07, wps=618.5, ups=0.53, wpb=1176.9, bsz=32, num_updates=18760, lr=2.03919e-05, gnorm=2.972, clip=100, loss_scale=256, train_wall=19, gb_free=9.8, wall=35246
2023-05-26 09:10:50 - progress_bar.py[line:272] - INFO: epoch 011:   1480 / 1732 loss=2.296, loss_v1=0, loss_v2=0, nll_loss=1.087, ntokens=1035.6, nsentences=32, sample_size=1035.6, sample_size_v1=0, sample_size_v2=0, ppl=2.12, wps=553.2, ups=0.53, wpb=1035.6, bsz=32, num_updates=18770, lr=2.03857e-05, gnorm=3.409, clip=100, loss_scale=256, train_wall=19, gb_free=11.3, wall=35264
2023-05-26 09:11:09 - progress_bar.py[line:272] - INFO: epoch 011:   1490 / 1732 loss=2.281, loss_v1=0, loss_v2=0, nll_loss=1.07, ntokens=1129.4, nsentences=32, sample_size=1129.4, sample_size_v1=0, sample_size_v2=0, ppl=2.1, wps=597.3, ups=0.53, wpb=1129.4, bsz=32, num_updates=18780, lr=2.03796e-05, gnorm=3.116, clip=100, loss_scale=256, train_wall=19, gb_free=11.4, wall=35283
2023-05-26 09:11:28 - progress_bar.py[line:272] - INFO: epoch 011:   1500 / 1732 loss=2.255, loss_v1=0, loss_v2=0, nll_loss=1.04, ntokens=1104.6, nsentences=32, sample_size=1104.6, sample_size_v1=0, sample_size_v2=0, ppl=2.06, wps=585.4, ups=0.53, wpb=1104.6, bsz=32, num_updates=18790, lr=2.03734e-05, gnorm=3.107, clip=100, loss_scale=256, train_wall=19, gb_free=11.2, wall=35302
2023-05-26 09:11:46 - progress_bar.py[line:272] - INFO: epoch 011:   1510 / 1732 loss=2.248, loss_v1=0, loss_v2=0, nll_loss=1.035, ntokens=1117.2, nsentences=32, sample_size=1117.2, sample_size_v1=0, sample_size_v2=0, ppl=2.05, wps=595.1, ups=0.53, wpb=1117.2, bsz=32, num_updates=18800, lr=2.03673e-05, gnorm=3.039, clip=100, loss_scale=256, train_wall=19, gb_free=11, wall=35321
2023-05-26 09:12:05 - progress_bar.py[line:272] - INFO: epoch 011:   1520 / 1732 loss=2.287, loss_v1=0, loss_v2=0, nll_loss=1.076, ntokens=1039.7, nsentences=32, sample_size=1039.7, sample_size_v1=0, sample_size_v2=0, ppl=2.11, wps=554.5, ups=0.53, wpb=1039.7, bsz=32, num_updates=18810, lr=2.03612e-05, gnorm=3.196, clip=100, loss_scale=256, train_wall=19, gb_free=11.5, wall=35340
2023-05-26 09:12:24 - progress_bar.py[line:272] - INFO: epoch 011:   1530 / 1732 loss=2.311, loss_v1=0, loss_v2=0, nll_loss=1.103, ntokens=1056.8, nsentences=32, sample_size=1056.8, sample_size_v1=0, sample_size_v2=0, ppl=2.15, wps=562.1, ups=0.53, wpb=1056.8, bsz=32, num_updates=18820, lr=2.0355e-05, gnorm=3.372, clip=100, loss_scale=256, train_wall=19, gb_free=10.6, wall=35359
2023-05-26 09:12:31 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 128.0
2023-05-26 09:12:45 - progress_bar.py[line:272] - INFO: epoch 011:   1541 / 1732 loss=2.261, loss_v1=0, loss_v2=0, nll_loss=1.046, ntokens=1080.1, nsentences=32, sample_size=1080.1, sample_size_v1=0, sample_size_v2=0, ppl=2.07, wps=520.2, ups=0.48, wpb=1080.1, bsz=32, num_updates=18830, lr=2.03489e-05, gnorm=3.25, clip=100, loss_scale=128, train_wall=21, gb_free=11.4, wall=35379
2023-05-26 09:13:03 - progress_bar.py[line:272] - INFO: epoch 011:   1551 / 1732 loss=2.252, loss_v1=0, loss_v2=0, nll_loss=1.039, ntokens=1073.3, nsentences=32, sample_size=1073.3, sample_size_v1=0, sample_size_v2=0, ppl=2.05, wps=569.9, ups=0.53, wpb=1073.3, bsz=32, num_updates=18840, lr=2.03427e-05, gnorm=3.11, clip=100, loss_scale=128, train_wall=19, gb_free=11.3, wall=35398
2023-05-26 09:13:22 - progress_bar.py[line:272] - INFO: epoch 011:   1561 / 1732 loss=2.267, loss_v1=0, loss_v2=0, nll_loss=1.055, ntokens=1091.5, nsentences=32, sample_size=1091.5, sample_size_v1=0, sample_size_v2=0, ppl=2.08, wps=581.2, ups=0.53, wpb=1091.5, bsz=32, num_updates=18850, lr=2.03366e-05, gnorm=2.805, clip=100, loss_scale=128, train_wall=19, gb_free=11.4, wall=35417
2023-05-26 09:13:41 - progress_bar.py[line:272] - INFO: epoch 011:   1571 / 1732 loss=2.296, loss_v1=0, loss_v2=0, nll_loss=1.087, ntokens=1079.7, nsentences=32, sample_size=1079.7, sample_size_v1=0, sample_size_v2=0, ppl=2.12, wps=571.9, ups=0.53, wpb=1079.7, bsz=32, num_updates=18860, lr=2.03304e-05, gnorm=3.069, clip=100, loss_scale=128, train_wall=19, gb_free=10.6, wall=35436
2023-05-26 09:14:00 - progress_bar.py[line:272] - INFO: epoch 011:   1581 / 1732 loss=2.311, loss_v1=0, loss_v2=0, nll_loss=1.104, ntokens=984.8, nsentences=32, sample_size=984.8, sample_size_v1=0, sample_size_v2=0, ppl=2.15, wps=525.5, ups=0.53, wpb=984.8, bsz=32, num_updates=18870, lr=2.03243e-05, gnorm=3.452, clip=100, loss_scale=128, train_wall=19, gb_free=10.9, wall=35455
2023-05-26 09:14:19 - progress_bar.py[line:272] - INFO: epoch 011:   1591 / 1732 loss=2.267, loss_v1=0, loss_v2=0, nll_loss=1.054, ntokens=1097.4, nsentences=32, sample_size=1097.4, sample_size_v1=0, sample_size_v2=0, ppl=2.08, wps=580, ups=0.53, wpb=1097.4, bsz=32, num_updates=18880, lr=2.03182e-05, gnorm=3.117, clip=100, loss_scale=128, train_wall=19, gb_free=11.1, wall=35473
2023-05-26 09:14:38 - progress_bar.py[line:272] - INFO: epoch 011:   1601 / 1732 loss=2.25, loss_v1=0, loss_v2=0, nll_loss=1.035, ntokens=1085.9, nsentences=32, sample_size=1085.9, sample_size_v1=0, sample_size_v2=0, ppl=2.05, wps=579.6, ups=0.53, wpb=1085.9, bsz=32, num_updates=18890, lr=2.0312e-05, gnorm=3.089, clip=100, loss_scale=128, train_wall=19, gb_free=11.5, wall=35492
2023-05-26 09:14:57 - progress_bar.py[line:272] - INFO: epoch 011:   1611 / 1732 loss=2.253, loss_v1=0, loss_v2=0, nll_loss=1.039, ntokens=1158.1, nsentences=32, sample_size=1158.1, sample_size_v1=0, sample_size_v2=0, ppl=2.05, wps=608.2, ups=0.53, wpb=1158.1, bsz=32, num_updates=18900, lr=2.03059e-05, gnorm=2.923, clip=100, loss_scale=128, train_wall=19, gb_free=11, wall=35511
2023-05-26 09:15:16 - progress_bar.py[line:272] - INFO: epoch 011:   1621 / 1732 loss=2.249, loss_v1=0, loss_v2=0, nll_loss=1.034, ntokens=1113.1, nsentences=32, sample_size=1113.1, sample_size_v1=0, sample_size_v2=0, ppl=2.05, wps=587.3, ups=0.53, wpb=1113.1, bsz=32, num_updates=18910, lr=2.02997e-05, gnorm=3.44, clip=100, loss_scale=128, train_wall=19, gb_free=11.2, wall=35530
2023-05-26 09:15:34 - progress_bar.py[line:272] - INFO: epoch 011:   1631 / 1732 loss=2.263, loss_v1=0, loss_v2=0, nll_loss=1.05, ntokens=1151.4, nsentences=32, sample_size=1151.4, sample_size_v1=0, sample_size_v2=0, ppl=2.07, wps=608.8, ups=0.53, wpb=1151.4, bsz=32, num_updates=18920, lr=2.02936e-05, gnorm=3.064, clip=100, loss_scale=128, train_wall=19, gb_free=11.2, wall=35549
2023-05-26 09:15:54 - progress_bar.py[line:272] - INFO: epoch 011:   1641 / 1732 loss=2.248, loss_v1=0, loss_v2=0, nll_loss=1.033, ntokens=1178.1, nsentences=32, sample_size=1178.1, sample_size_v1=0, sample_size_v2=0, ppl=2.05, wps=617.8, ups=0.52, wpb=1178.1, bsz=32, num_updates=18930, lr=2.02875e-05, gnorm=2.954, clip=100, loss_scale=128, train_wall=19, gb_free=10.1, wall=35568
2023-05-26 09:16:12 - progress_bar.py[line:272] - INFO: epoch 011:   1651 / 1732 loss=2.26, loss_v1=0, loss_v2=0, nll_loss=1.048, ntokens=1103.6, nsentences=32, sample_size=1103.6, sample_size_v1=0, sample_size_v2=0, ppl=2.07, wps=588.3, ups=0.53, wpb=1103.6, bsz=32, num_updates=18940, lr=2.02813e-05, gnorm=3.222, clip=100, loss_scale=128, train_wall=19, gb_free=12, wall=35587
2023-05-26 09:16:31 - progress_bar.py[line:272] - INFO: epoch 011:   1661 / 1732 loss=2.292, loss_v1=0, loss_v2=0, nll_loss=1.082, ntokens=1033.5, nsentences=32, sample_size=1033.5, sample_size_v1=0, sample_size_v2=0, ppl=2.12, wps=548.2, ups=0.53, wpb=1033.5, bsz=32, num_updates=18950, lr=2.02752e-05, gnorm=3.5, clip=100, loss_scale=128, train_wall=19, gb_free=10.8, wall=35606
2023-05-26 09:16:50 - progress_bar.py[line:272] - INFO: epoch 011:   1671 / 1732 loss=2.268, loss_v1=0, loss_v2=0, nll_loss=1.055, ntokens=998, nsentences=32, sample_size=998, sample_size_v1=0, sample_size_v2=0, ppl=2.08, wps=534.8, ups=0.54, wpb=998, bsz=32, num_updates=18960, lr=2.0269e-05, gnorm=3.514, clip=100, loss_scale=128, train_wall=19, gb_free=11.2, wall=35624
2023-05-26 09:17:09 - progress_bar.py[line:272] - INFO: epoch 011:   1681 / 1732 loss=2.231, loss_v1=0, loss_v2=0, nll_loss=1.014, ntokens=1185.3, nsentences=32, sample_size=1185.3, sample_size_v1=0, sample_size_v2=0, ppl=2.02, wps=621.8, ups=0.52, wpb=1185.3, bsz=32, num_updates=18970, lr=2.02629e-05, gnorm=3.179, clip=100, loss_scale=128, train_wall=19, gb_free=11.4, wall=35644
2023-05-26 09:17:28 - progress_bar.py[line:272] - INFO: epoch 011:   1691 / 1732 loss=2.245, loss_v1=0, loss_v2=0, nll_loss=1.032, ntokens=1205.4, nsentences=32, sample_size=1205.4, sample_size_v1=0, sample_size_v2=0, ppl=2.04, wps=629.8, ups=0.52, wpb=1205.4, bsz=32, num_updates=18980, lr=2.02567e-05, gnorm=2.797, clip=100, loss_scale=128, train_wall=19, gb_free=10.6, wall=35663
2023-05-26 09:17:47 - progress_bar.py[line:272] - INFO: epoch 011:   1701 / 1732 loss=2.26, loss_v1=0, loss_v2=0, nll_loss=1.045, ntokens=1274, nsentences=32, sample_size=1274, sample_size_v1=0, sample_size_v2=0, ppl=2.06, wps=665, ups=0.52, wpb=1274, bsz=32, num_updates=18990, lr=2.02506e-05, gnorm=2.663, clip=100, loss_scale=128, train_wall=19, gb_free=11.3, wall=35682
2023-05-26 09:18:06 - progress_bar.py[line:272] - INFO: epoch 011:   1711 / 1732 loss=2.277, loss_v1=0, loss_v2=0, nll_loss=1.065, ntokens=1171.2, nsentences=32, sample_size=1171.2, sample_size_v1=0, sample_size_v2=0, ppl=2.09, wps=618.3, ups=0.53, wpb=1171.2, bsz=32, num_updates=19000, lr=2.02445e-05, gnorm=2.803, clip=100, loss_scale=128, train_wall=19, gb_free=11.4, wall=35701
2023-05-26 09:18:25 - progress_bar.py[line:272] - INFO: epoch 011:   1721 / 1732 loss=2.242, loss_v1=0, loss_v2=0, nll_loss=1.028, ntokens=1173.7, nsentences=32, sample_size=1173.7, sample_size_v1=0, sample_size_v2=0, ppl=2.04, wps=616.6, ups=0.53, wpb=1173.7, bsz=32, num_updates=19010, lr=2.02383e-05, gnorm=2.756, clip=100, loss_scale=128, train_wall=19, gb_free=10.8, wall=35720
2023-05-26 09:18:44 - progress_bar.py[line:272] - INFO: epoch 011:   1731 / 1732 loss=2.309, loss_v1=0, loss_v2=0, nll_loss=1.101, ntokens=1135.4, nsentences=32, sample_size=1135.4, sample_size_v1=0, sample_size_v2=0, ppl=2.15, wps=601.1, ups=0.53, wpb=1135.4, bsz=32, num_updates=19020, lr=2.02322e-05, gnorm=2.782, clip=100, loss_scale=128, train_wall=19, gb_free=11.2, wall=35739
2023-05-26 09:18:45 - train.py[line:332] - INFO: end of epoch 11 (average epoch stats below)
2023-05-26 09:18:45 - progress_bar.py[line:282] - INFO: epoch 011 | loss 2.282 | loss_v1 0 | loss_v2 0 | nll_loss 1.071 | ntokens 1051.49 | nsentences 31.986 | sample_size 1051.49 | sample_size_v1 0 | sample_size_v2 0 | ppl 2.1 | wps 559.8 | ups 0.53 | wpb 1051.5 | bsz 32 | num_updates 19021 | lr 2.02316e-05 | gnorm 3.096 | clip 100 | loss_scale 128 | train_wall 3240 | gb_free 11.7 | wall 35739
2023-05-26 09:18:45 - trainer.py[line:639] - INFO: loading train data for epoch 12
local datafile ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 0 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 0 finished initializing row_count and line_idx-to-offset mapping
file ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 0 row count 55400 total row count 55400
slice_id 0 seek offset 0
2023-05-26 09:18:46 - trainer.py[line:703] - INFO: begin training epoch 12
2023-05-26 09:18:46 - train.py[line:305] - INFO: Start iterating over samples
2023-05-26 09:19:04 - progress_bar.py[line:272] - INFO: epoch 012:      9 / 1732 loss=2.224, loss_v1=0, loss_v2=0, nll_loss=1.005, ntokens=1061, nsentences=29.6, sample_size=1061, sample_size_v1=0, sample_size_v2=0, ppl=2.01, wps=536.7, ups=0.51, wpb=1061, bsz=29.6, num_updates=19030, lr=2.0226e-05, gnorm=3.362, clip=100, loss_scale=128, train_wall=18, gb_free=11, wall=35758
2023-05-26 09:19:23 - progress_bar.py[line:272] - INFO: epoch 012:     19 / 1732 loss=2.175, loss_v1=0, loss_v2=0, nll_loss=0.954, ntokens=1084.7, nsentences=32, sample_size=1084.7, sample_size_v1=0, sample_size_v2=0, ppl=1.94, wps=574.5, ups=0.53, wpb=1084.7, bsz=32, num_updates=19040, lr=2.02199e-05, gnorm=2.945, clip=100, loss_scale=128, train_wall=19, gb_free=11.5, wall=35777
2023-05-26 09:19:41 - progress_bar.py[line:272] - INFO: epoch 012:     29 / 1732 loss=2.254, loss_v1=0, loss_v2=0, nll_loss=1.039, ntokens=941, nsentences=32, sample_size=941, sample_size_v1=0, sample_size_v2=0, ppl=2.05, wps=501.2, ups=0.53, wpb=941, bsz=32, num_updates=19050, lr=2.02137e-05, gnorm=3.194, clip=100, loss_scale=128, train_wall=19, gb_free=11.4, wall=35796
2023-05-26 09:20:01 - progress_bar.py[line:272] - INFO: epoch 012:     39 / 1732 loss=2.057, loss_v1=0, loss_v2=0, nll_loss=0.822, ntokens=1243.8, nsentences=32, sample_size=1243.8, sample_size_v1=0, sample_size_v2=0, ppl=1.77, wps=649.7, ups=0.52, wpb=1243.8, bsz=32, num_updates=19060, lr=2.02076e-05, gnorm=2.297, clip=100, loss_scale=128, train_wall=19, gb_free=10.4, wall=35815
2023-05-26 09:20:19 - progress_bar.py[line:272] - INFO: epoch 012:     49 / 1732 loss=2.154, loss_v1=0, loss_v2=0, nll_loss=0.928, ntokens=1045.9, nsentences=32, sample_size=1045.9, sample_size_v1=0, sample_size_v2=0, ppl=1.9, wps=554.7, ups=0.53, wpb=1045.9, bsz=32, num_updates=19070, lr=2.02015e-05, gnorm=2.964, clip=100, loss_scale=128, train_wall=19, gb_free=10.8, wall=35834
2023-05-26 09:20:38 - progress_bar.py[line:272] - INFO: epoch 012:     59 / 1732 loss=2.02, loss_v1=0, loss_v2=0, nll_loss=0.781, ntokens=1005.7, nsentences=32, sample_size=1005.7, sample_size_v1=0, sample_size_v2=0, ppl=1.72, wps=539.3, ups=0.54, wpb=1005.7, bsz=32, num_updates=19080, lr=2.01953e-05, gnorm=2.891, clip=100, loss_scale=128, train_wall=19, gb_free=11.6, wall=35853
2023-05-26 09:20:58 - progress_bar.py[line:272] - INFO: epoch 012:     69 / 1732 loss=1.99, loss_v1=0, loss_v2=0, nll_loss=0.746, ntokens=1433.6, nsentences=32, sample_size=1433.6, sample_size_v1=0, sample_size_v2=0, ppl=1.68, wps=730.5, ups=0.51, wpb=1433.6, bsz=32, num_updates=19090, lr=2.01892e-05, gnorm=1.971, clip=100, loss_scale=128, train_wall=20, gb_free=10.7, wall=35872
2023-05-26 09:21:17 - progress_bar.py[line:272] - INFO: epoch 012:     79 / 1732 loss=2.053, loss_v1=0, loss_v2=0, nll_loss=0.817, ntokens=1268.1, nsentences=32, sample_size=1268.1, sample_size_v1=0, sample_size_v2=0, ppl=1.76, wps=654.1, ups=0.52, wpb=1268.1, bsz=32, num_updates=19100, lr=2.0183e-05, gnorm=2.512, clip=100, loss_scale=128, train_wall=19, gb_free=10.3, wall=35892
2023-05-26 09:21:36 - progress_bar.py[line:272] - INFO: epoch 012:     89 / 1732 loss=2.152, loss_v1=0, loss_v2=0, nll_loss=0.922, ntokens=1075.5, nsentences=32, sample_size=1075.5, sample_size_v1=0, sample_size_v2=0, ppl=1.9, wps=563.9, ups=0.52, wpb=1075.5, bsz=32, num_updates=19110, lr=2.01769e-05, gnorm=2.959, clip=100, loss_scale=128, train_wall=19, gb_free=10, wall=35911
2023-05-26 09:21:55 - progress_bar.py[line:272] - INFO: epoch 012:     99 / 1732 loss=2.114, loss_v1=0, loss_v2=0, nll_loss=0.887, ntokens=1059.8, nsentences=32, sample_size=1059.8, sample_size_v1=0, sample_size_v2=0, ppl=1.85, wps=562.6, ups=0.53, wpb=1059.8, bsz=32, num_updates=19120, lr=2.01708e-05, gnorm=2.93, clip=100, loss_scale=128, train_wall=19, gb_free=11.9, wall=35930
2023-05-26 09:22:14 - progress_bar.py[line:272] - INFO: epoch 012:    109 / 1732 loss=2.277, loss_v1=0, loss_v2=0, nll_loss=1.067, ntokens=996.8, nsentences=32, sample_size=996.8, sample_size_v1=0, sample_size_v2=0, ppl=2.09, wps=532.1, ups=0.53, wpb=996.8, bsz=32, num_updates=19130, lr=2.01646e-05, gnorm=3.058, clip=100, loss_scale=128, train_wall=19, gb_free=11.6, wall=35948
2023-05-26 09:22:33 - progress_bar.py[line:272] - INFO: epoch 012:    119 / 1732 loss=2.277, loss_v1=0, loss_v2=0, nll_loss=1.066, ntokens=1100.1, nsentences=32, sample_size=1100.1, sample_size_v1=0, sample_size_v2=0, ppl=2.09, wps=576.4, ups=0.52, wpb=1100.1, bsz=32, num_updates=19140, lr=2.01585e-05, gnorm=3.234, clip=100, loss_scale=128, train_wall=19, gb_free=10.3, wall=35968
2023-05-26 09:22:52 - progress_bar.py[line:272] - INFO: epoch 012:    129 / 1732 loss=2.258, loss_v1=0, loss_v2=0, nll_loss=1.043, ntokens=1171.3, nsentences=32, sample_size=1171.3, sample_size_v1=0, sample_size_v2=0, ppl=2.06, wps=610.2, ups=0.52, wpb=1171.3, bsz=32, num_updates=19150, lr=2.01523e-05, gnorm=2.907, clip=100, loss_scale=128, train_wall=19, gb_free=10.6, wall=35987
2023-05-26 09:23:11 - progress_bar.py[line:272] - INFO: epoch 012:    139 / 1732 loss=2.205, loss_v1=0, loss_v2=0, nll_loss=0.985, ntokens=1243.3, nsentences=32, sample_size=1243.3, sample_size_v1=0, sample_size_v2=0, ppl=1.98, wps=649, ups=0.52, wpb=1243.3, bsz=32, num_updates=19160, lr=2.01462e-05, gnorm=2.914, clip=100, loss_scale=128, train_wall=19, gb_free=10.3, wall=36006
2023-05-26 09:23:31 - progress_bar.py[line:272] - INFO: epoch 012:    149 / 1732 loss=2.172, loss_v1=0, loss_v2=0, nll_loss=0.95, ntokens=1177.5, nsentences=32, sample_size=1177.5, sample_size_v1=0, sample_size_v2=0, ppl=1.93, wps=610.5, ups=0.52, wpb=1177.5, bsz=32, num_updates=19170, lr=2.014e-05, gnorm=2.777, clip=100, loss_scale=128, train_wall=19, gb_free=10.3, wall=36025
2023-05-26 09:23:50 - progress_bar.py[line:272] - INFO: epoch 012:    159 / 1732 loss=2.222, loss_v1=0, loss_v2=0, nll_loss=1.004, ntokens=1139.9, nsentences=32, sample_size=1139.9, sample_size_v1=0, sample_size_v2=0, ppl=2.01, wps=594.5, ups=0.52, wpb=1139.9, bsz=32, num_updates=19180, lr=2.01339e-05, gnorm=2.925, clip=100, loss_scale=128, train_wall=19, gb_free=11.5, wall=36044
2023-05-26 09:24:09 - progress_bar.py[line:272] - INFO: epoch 012:    169 / 1732 loss=2.202, loss_v1=0, loss_v2=0, nll_loss=0.982, ntokens=986.6, nsentences=32, sample_size=986.6, sample_size_v1=0, sample_size_v2=0, ppl=1.98, wps=522.5, ups=0.53, wpb=986.6, bsz=32, num_updates=19190, lr=2.01278e-05, gnorm=3.402, clip=100, loss_scale=128, train_wall=19, gb_free=11.4, wall=36063
2023-05-26 09:24:28 - progress_bar.py[line:272] - INFO: epoch 012:    179 / 1732 loss=2.186, loss_v1=0, loss_v2=0, nll_loss=0.965, ntokens=1076.1, nsentences=32, sample_size=1076.1, sample_size_v1=0, sample_size_v2=0, ppl=1.95, wps=566.7, ups=0.53, wpb=1076.1, bsz=32, num_updates=19200, lr=2.01216e-05, gnorm=3.08, clip=100, loss_scale=128, train_wall=19, gb_free=10.6, wall=36082
2023-05-26 09:24:47 - progress_bar.py[line:272] - INFO: epoch 012:    189 / 1732 loss=2.171, loss_v1=0, loss_v2=0, nll_loss=0.947, ntokens=1120.4, nsentences=32, sample_size=1120.4, sample_size_v1=0, sample_size_v2=0, ppl=1.93, wps=587.9, ups=0.52, wpb=1120.4, bsz=32, num_updates=19210, lr=2.01155e-05, gnorm=2.898, clip=100, loss_scale=128, train_wall=19, gb_free=11.7, wall=36101
2023-05-26 09:25:06 - progress_bar.py[line:272] - INFO: epoch 012:    199 / 1732 loss=2.229, loss_v1=0, loss_v2=0, nll_loss=1.011, ntokens=1141, nsentences=32, sample_size=1141, sample_size_v1=0, sample_size_v2=0, ppl=2.02, wps=603, ups=0.53, wpb=1141, bsz=32, num_updates=19220, lr=2.01093e-05, gnorm=2.971, clip=100, loss_scale=128, train_wall=19, gb_free=11.6, wall=36120
2023-05-26 09:25:24 - progress_bar.py[line:272] - INFO: epoch 012:    209 / 1732 loss=2.31, loss_v1=0, loss_v2=0, nll_loss=1.102, ntokens=970.7, nsentences=32, sample_size=970.7, sample_size_v1=0, sample_size_v2=0, ppl=2.15, wps=521.4, ups=0.54, wpb=970.7, bsz=32, num_updates=19230, lr=2.01032e-05, gnorm=3.619, clip=100, loss_scale=128, train_wall=19, gb_free=10.3, wall=36139
2023-05-26 09:25:43 - progress_bar.py[line:272] - INFO: epoch 012:    219 / 1732 loss=2.296, loss_v1=0, loss_v2=0, nll_loss=1.087, ntokens=1152.7, nsentences=32, sample_size=1152.7, sample_size_v1=0, sample_size_v2=0, ppl=2.12, wps=616.7, ups=0.53, wpb=1152.7, bsz=32, num_updates=19240, lr=2.0097e-05, gnorm=3.248, clip=100, loss_scale=128, train_wall=19, gb_free=11.3, wall=36158
2023-05-26 09:26:02 - progress_bar.py[line:272] - INFO: epoch 012:    229 / 1732 loss=2.29, loss_v1=0, loss_v2=0, nll_loss=1.08, ntokens=1096.1, nsentences=32, sample_size=1096.1, sample_size_v1=0, sample_size_v2=0, ppl=2.11, wps=586.4, ups=0.54, wpb=1096.1, bsz=32, num_updates=19250, lr=2.00909e-05, gnorm=2.979, clip=100, loss_scale=128, train_wall=19, gb_free=11.7, wall=36176
2023-05-26 09:26:20 - progress_bar.py[line:272] - INFO: epoch 012:    239 / 1732 loss=2.329, loss_v1=0, loss_v2=0, nll_loss=1.123, ntokens=1117, nsentences=32, sample_size=1117, sample_size_v1=0, sample_size_v2=0, ppl=2.18, wps=595.7, ups=0.53, wpb=1117, bsz=32, num_updates=19260, lr=2.00848e-05, gnorm=2.915, clip=100, loss_scale=128, train_wall=19, gb_free=10.8, wall=36195
2023-05-26 09:26:39 - progress_bar.py[line:272] - INFO: epoch 012:    249 / 1732 loss=2.292, loss_v1=0, loss_v2=0, nll_loss=1.083, ntokens=1165.4, nsentences=32, sample_size=1165.4, sample_size_v1=0, sample_size_v2=0, ppl=2.12, wps=618.1, ups=0.53, wpb=1165.4, bsz=32, num_updates=19270, lr=2.00786e-05, gnorm=2.891, clip=100, loss_scale=128, train_wall=19, gb_free=11.3, wall=36214
2023-05-26 09:26:58 - progress_bar.py[line:272] - INFO: epoch 012:    259 / 1732 loss=2.308, loss_v1=0, loss_v2=0, nll_loss=1.101, ntokens=1119.2, nsentences=32, sample_size=1119.2, sample_size_v1=0, sample_size_v2=0, ppl=2.15, wps=598, ups=0.53, wpb=1119.2, bsz=32, num_updates=19280, lr=2.00725e-05, gnorm=3.236, clip=100, loss_scale=128, train_wall=19, gb_free=11.2, wall=36233
2023-05-26 09:27:17 - progress_bar.py[line:272] - INFO: epoch 012:    269 / 1732 loss=2.299, loss_v1=0, loss_v2=0, nll_loss=1.089, ntokens=1154.8, nsentences=32, sample_size=1154.8, sample_size_v1=0, sample_size_v2=0, ppl=2.13, wps=615.4, ups=0.53, wpb=1154.8, bsz=32, num_updates=19290, lr=2.00663e-05, gnorm=2.983, clip=100, loss_scale=128, train_wall=19, gb_free=11.1, wall=36251
2023-05-26 09:27:36 - progress_bar.py[line:272] - INFO: epoch 012:    279 / 1732 loss=2.305, loss_v1=0, loss_v2=0, nll_loss=1.096, ntokens=1151.7, nsentences=32, sample_size=1151.7, sample_size_v1=0, sample_size_v2=0, ppl=2.14, wps=610.1, ups=0.53, wpb=1151.7, bsz=32, num_updates=19300, lr=2.00602e-05, gnorm=3.146, clip=100, loss_scale=128, train_wall=19, gb_free=10.9, wall=36270
2023-05-26 09:27:54 - progress_bar.py[line:272] - INFO: epoch 012:    289 / 1732 loss=2.277, loss_v1=0, loss_v2=0, nll_loss=1.066, ntokens=1147.9, nsentences=32, sample_size=1147.9, sample_size_v1=0, sample_size_v2=0, ppl=2.09, wps=611, ups=0.53, wpb=1147.9, bsz=32, num_updates=19310, lr=2.00541e-05, gnorm=2.843, clip=100, loss_scale=128, train_wall=19, gb_free=11.8, wall=36289
2023-05-26 09:28:13 - progress_bar.py[line:272] - INFO: epoch 012:    299 / 1732 loss=2.289, loss_v1=0, loss_v2=0, nll_loss=1.081, ntokens=1105.2, nsentences=32, sample_size=1105.2, sample_size_v1=0, sample_size_v2=0, ppl=2.12, wps=591, ups=0.53, wpb=1105.2, bsz=32, num_updates=19320, lr=2.00479e-05, gnorm=3.057, clip=100, loss_scale=128, train_wall=19, gb_free=11.1, wall=36308
2023-05-26 09:28:32 - progress_bar.py[line:272] - INFO: epoch 012:    309 / 1732 loss=2.288, loss_v1=0, loss_v2=0, nll_loss=1.078, ntokens=1071, nsentences=32, sample_size=1071, sample_size_v1=0, sample_size_v2=0, ppl=2.11, wps=573.2, ups=0.54, wpb=1071, bsz=32, num_updates=19330, lr=2.00418e-05, gnorm=3.267, clip=100, loss_scale=128, train_wall=19, gb_free=11.3, wall=36326
2023-05-26 09:28:50 - progress_bar.py[line:272] - INFO: epoch 012:    319 / 1732 loss=2.311, loss_v1=0, loss_v2=0, nll_loss=1.102, ntokens=1020.8, nsentences=32, sample_size=1020.8, sample_size_v1=0, sample_size_v2=0, ppl=2.15, wps=548.3, ups=0.54, wpb=1020.8, bsz=32, num_updates=19340, lr=2.00356e-05, gnorm=3.738, clip=100, loss_scale=256, train_wall=19, gb_free=11.7, wall=36345
2023-05-26 09:29:00 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 128.0
2023-05-26 09:29:11 - progress_bar.py[line:272] - INFO: epoch 012:    330 / 1732 loss=2.339, loss_v1=0, loss_v2=0, nll_loss=1.135, ntokens=1028.7, nsentences=32, sample_size=1028.7, sample_size_v1=0, sample_size_v2=0, ppl=2.2, wps=504.1, ups=0.49, wpb=1028.7, bsz=32, num_updates=19350, lr=2.00295e-05, gnorm=3.371, clip=100, loss_scale=128, train_wall=20, gb_free=11.1, wall=36365
2023-05-26 09:29:29 - progress_bar.py[line:272] - INFO: epoch 012:    340 / 1732 loss=2.281, loss_v1=0, loss_v2=0, nll_loss=1.071, ntokens=959.9, nsentences=32, sample_size=959.9, sample_size_v1=0, sample_size_v2=0, ppl=2.1, wps=518.3, ups=0.54, wpb=959.9, bsz=32, num_updates=19360, lr=2.00233e-05, gnorm=3.568, clip=100, loss_scale=128, train_wall=18, gb_free=11.4, wall=36384
2023-05-26 09:29:48 - progress_bar.py[line:272] - INFO: epoch 012:    350 / 1732 loss=2.3, loss_v1=0, loss_v2=0, nll_loss=1.092, ntokens=909.7, nsentences=32, sample_size=909.7, sample_size_v1=0, sample_size_v2=0, ppl=2.13, wps=492.7, ups=0.54, wpb=909.7, bsz=32, num_updates=19370, lr=2.00172e-05, gnorm=3.786, clip=100, loss_scale=128, train_wall=18, gb_free=11.7, wall=36402
2023-05-26 09:30:06 - progress_bar.py[line:272] - INFO: epoch 012:    360 / 1732 loss=2.324, loss_v1=0, loss_v2=0, nll_loss=1.118, ntokens=938.9, nsentences=32, sample_size=938.9, sample_size_v1=0, sample_size_v2=0, ppl=2.17, wps=507, ups=0.54, wpb=938.9, bsz=32, num_updates=19380, lr=2.00111e-05, gnorm=3.701, clip=100, loss_scale=128, train_wall=18, gb_free=11.6, wall=36421
2023-05-26 09:30:25 - progress_bar.py[line:272] - INFO: epoch 012:    370 / 1732 loss=2.334, loss_v1=0, loss_v2=0, nll_loss=1.127, ntokens=953.9, nsentences=32, sample_size=953.9, sample_size_v1=0, sample_size_v2=0, ppl=2.18, wps=516.3, ups=0.54, wpb=953.9, bsz=32, num_updates=19390, lr=2.00049e-05, gnorm=3.678, clip=100, loss_scale=128, train_wall=18, gb_free=12, wall=36439
2023-05-26 09:30:43 - progress_bar.py[line:272] - INFO: epoch 012:    380 / 1732 loss=2.322, loss_v1=0, loss_v2=0, nll_loss=1.117, ntokens=1091.6, nsentences=32, sample_size=1091.6, sample_size_v1=0, sample_size_v2=0, ppl=2.17, wps=587.4, ups=0.54, wpb=1091.6, bsz=32, num_updates=19400, lr=1.99988e-05, gnorm=3.58, clip=100, loss_scale=128, train_wall=19, gb_free=11.7, wall=36458
2023-05-26 09:31:02 - progress_bar.py[line:272] - INFO: epoch 012:    390 / 1732 loss=2.311, loss_v1=0, loss_v2=0, nll_loss=1.104, ntokens=1027.2, nsentences=32, sample_size=1027.2, sample_size_v1=0, sample_size_v2=0, ppl=2.15, wps=552.4, ups=0.54, wpb=1027.2, bsz=32, num_updates=19410, lr=1.99926e-05, gnorm=3.621, clip=100, loss_scale=128, train_wall=19, gb_free=11.5, wall=36477
2023-05-26 09:31:20 - progress_bar.py[line:272] - INFO: epoch 012:    400 / 1732 loss=2.308, loss_v1=0, loss_v2=0, nll_loss=1.1, ntokens=977.7, nsentences=32, sample_size=977.7, sample_size_v1=0, sample_size_v2=0, ppl=2.14, wps=528, ups=0.54, wpb=977.7, bsz=32, num_updates=19420, lr=1.99865e-05, gnorm=3.811, clip=100, loss_scale=128, train_wall=18, gb_free=11.4, wall=36495
2023-05-26 09:31:39 - progress_bar.py[line:272] - INFO: epoch 012:    410 / 1732 loss=2.29, loss_v1=0, loss_v2=0, nll_loss=1.081, ntokens=1069.8, nsentences=32, sample_size=1069.8, sample_size_v1=0, sample_size_v2=0, ppl=2.11, wps=574, ups=0.54, wpb=1069.8, bsz=32, num_updates=19430, lr=1.99803e-05, gnorm=3.059, clip=100, loss_scale=128, train_wall=19, gb_free=11.5, wall=36514
2023-05-26 09:31:58 - progress_bar.py[line:272] - INFO: epoch 012:    420 / 1732 loss=2.264, loss_v1=0, loss_v2=0, nll_loss=1.051, ntokens=1036.4, nsentences=32, sample_size=1036.4, sample_size_v1=0, sample_size_v2=0, ppl=2.07, wps=555.8, ups=0.54, wpb=1036.4, bsz=32, num_updates=19440, lr=1.99742e-05, gnorm=3.408, clip=100, loss_scale=128, train_wall=19, gb_free=10.7, wall=36532
2023-05-26 09:32:16 - progress_bar.py[line:272] - INFO: epoch 012:    430 / 1732 loss=2.27, loss_v1=0, loss_v2=0, nll_loss=1.057, ntokens=1013.2, nsentences=32, sample_size=1013.2, sample_size_v1=0, sample_size_v2=0, ppl=2.08, wps=545.3, ups=0.54, wpb=1013.2, bsz=32, num_updates=19450, lr=1.99681e-05, gnorm=3.292, clip=100, loss_scale=128, train_wall=19, gb_free=11.1, wall=36551
2023-05-26 09:32:35 - progress_bar.py[line:272] - INFO: epoch 012:    440 / 1732 loss=2.31, loss_v1=0, loss_v2=0, nll_loss=1.103, ntokens=989.2, nsentences=32, sample_size=989.2, sample_size_v1=0, sample_size_v2=0, ppl=2.15, wps=533.3, ups=0.54, wpb=989.2, bsz=32, num_updates=19460, lr=1.99619e-05, gnorm=3.28, clip=100, loss_scale=128, train_wall=19, gb_free=11.7, wall=36570
2023-05-26 09:32:53 - progress_bar.py[line:272] - INFO: epoch 012:    450 / 1732 loss=2.309, loss_v1=0, loss_v2=0, nll_loss=1.101, ntokens=915.3, nsentences=32, sample_size=915.3, sample_size_v1=0, sample_size_v2=0, ppl=2.15, wps=493.6, ups=0.54, wpb=915.3, bsz=32, num_updates=19470, lr=1.99558e-05, gnorm=3.595, clip=100, loss_scale=128, train_wall=19, gb_free=11.8, wall=36588
2023-05-26 09:33:12 - progress_bar.py[line:272] - INFO: epoch 012:    460 / 1732 loss=2.315, loss_v1=0, loss_v2=0, nll_loss=1.109, ntokens=1040.5, nsentences=32, sample_size=1040.5, sample_size_v1=0, sample_size_v2=0, ppl=2.16, wps=560.8, ups=0.54, wpb=1040.5, bsz=32, num_updates=19480, lr=1.99496e-05, gnorm=3.5, clip=100, loss_scale=128, train_wall=19, gb_free=11.3, wall=36607
2023-05-26 09:33:31 - progress_bar.py[line:272] - INFO: epoch 012:    470 / 1732 loss=2.324, loss_v1=0, loss_v2=0, nll_loss=1.118, ntokens=1036.3, nsentences=32, sample_size=1036.3, sample_size_v1=0, sample_size_v2=0, ppl=2.17, wps=553.1, ups=0.53, wpb=1036.3, bsz=32, num_updates=19490, lr=1.99435e-05, gnorm=3.361, clip=100, loss_scale=128, train_wall=19, gb_free=11.8, wall=36625
2023-05-26 09:33:49 - progress_bar.py[line:272] - INFO: epoch 012:    480 / 1732 loss=2.32, loss_v1=0, loss_v2=0, nll_loss=1.111, ntokens=1040.5, nsentences=32, sample_size=1040.5, sample_size_v1=0, sample_size_v2=0, ppl=2.16, wps=558, ups=0.54, wpb=1040.5, bsz=32, num_updates=19500, lr=1.99374e-05, gnorm=3.313, clip=100, loss_scale=128, train_wall=19, gb_free=9.9, wall=36644
2023-05-26 09:34:08 - progress_bar.py[line:272] - INFO: epoch 012:    490 / 1732 loss=2.299, loss_v1=0, loss_v2=0, nll_loss=1.092, ntokens=919.9, nsentences=32, sample_size=919.9, sample_size_v1=0, sample_size_v2=0, ppl=2.13, wps=498.5, ups=0.54, wpb=919.9, bsz=32, num_updates=19510, lr=1.99312e-05, gnorm=3.5, clip=100, loss_scale=128, train_wall=18, gb_free=10.5, wall=36663
2023-05-26 09:34:26 - progress_bar.py[line:272] - INFO: epoch 012:    500 / 1732 loss=2.286, loss_v1=0, loss_v2=0, nll_loss=1.079, ntokens=950.8, nsentences=32, sample_size=950.8, sample_size_v1=0, sample_size_v2=0, ppl=2.11, wps=515.4, ups=0.54, wpb=950.8, bsz=32, num_updates=19520, lr=1.99251e-05, gnorm=3.627, clip=100, loss_scale=128, train_wall=18, gb_free=11.5, wall=36681
2023-05-26 09:34:45 - progress_bar.py[line:272] - INFO: epoch 012:    510 / 1732 loss=2.335, loss_v1=0, loss_v2=0, nll_loss=1.128, ntokens=1039.6, nsentences=32, sample_size=1039.6, sample_size_v1=0, sample_size_v2=0, ppl=2.19, wps=560.4, ups=0.54, wpb=1039.6, bsz=32, num_updates=19530, lr=1.99189e-05, gnorm=3.373, clip=100, loss_scale=128, train_wall=19, gb_free=10.9, wall=36700
2023-05-26 09:35:03 - progress_bar.py[line:272] - INFO: epoch 012:    520 / 1732 loss=2.28, loss_v1=0, loss_v2=0, nll_loss=1.068, ntokens=1010.1, nsentences=32, sample_size=1010.1, sample_size_v1=0, sample_size_v2=0, ppl=2.1, wps=547.3, ups=0.54, wpb=1010.1, bsz=32, num_updates=19540, lr=1.99128e-05, gnorm=3.224, clip=100, loss_scale=128, train_wall=18, gb_free=11.7, wall=36718
2023-05-26 09:35:22 - progress_bar.py[line:272] - INFO: epoch 012:    530 / 1732 loss=2.313, loss_v1=0, loss_v2=0, nll_loss=1.107, ntokens=937.1, nsentences=32, sample_size=937.1, sample_size_v1=0, sample_size_v2=0, ppl=2.15, wps=508.4, ups=0.54, wpb=937.1, bsz=32, num_updates=19550, lr=1.99066e-05, gnorm=3.988, clip=100, loss_scale=128, train_wall=18, gb_free=11.5, wall=36736
2023-05-26 09:35:40 - progress_bar.py[line:272] - INFO: epoch 012:    540 / 1732 loss=2.298, loss_v1=0, loss_v2=0, nll_loss=1.089, ntokens=998.6, nsentences=32, sample_size=998.6, sample_size_v1=0, sample_size_v2=0, ppl=2.13, wps=540.3, ups=0.54, wpb=998.6, bsz=32, num_updates=19560, lr=1.99005e-05, gnorm=3.414, clip=100, loss_scale=128, train_wall=18, gb_free=11.9, wall=36755
2023-05-26 09:35:59 - progress_bar.py[line:272] - INFO: epoch 012:    550 / 1732 loss=2.336, loss_v1=0, loss_v2=0, nll_loss=1.13, ntokens=1026.6, nsentences=32, sample_size=1026.6, sample_size_v1=0, sample_size_v2=0, ppl=2.19, wps=552, ups=0.54, wpb=1026.6, bsz=32, num_updates=19570, lr=1.98944e-05, gnorm=3.539, clip=100, loss_scale=128, train_wall=19, gb_free=10.9, wall=36774
2023-05-26 09:36:17 - progress_bar.py[line:272] - INFO: epoch 012:    560 / 1732 loss=2.317, loss_v1=0, loss_v2=0, nll_loss=1.111, ntokens=1014, nsentences=32, sample_size=1014, sample_size_v1=0, sample_size_v2=0, ppl=2.16, wps=545.7, ups=0.54, wpb=1014, bsz=32, num_updates=19580, lr=1.98882e-05, gnorm=3.635, clip=100, loss_scale=128, train_wall=19, gb_free=11.7, wall=36792
2023-05-26 09:36:36 - progress_bar.py[line:272] - INFO: epoch 012:    570 / 1732 loss=2.349, loss_v1=0, loss_v2=0, nll_loss=1.146, ntokens=1025.9, nsentences=32, sample_size=1025.9, sample_size_v1=0, sample_size_v2=0, ppl=2.21, wps=547.9, ups=0.53, wpb=1025.9, bsz=32, num_updates=19590, lr=1.98821e-05, gnorm=3.764, clip=100, loss_scale=128, train_wall=19, gb_free=11.2, wall=36811
2023-05-26 09:36:55 - progress_bar.py[line:272] - INFO: epoch 012:    580 / 1732 loss=2.309, loss_v1=0, loss_v2=0, nll_loss=1.101, ntokens=999.5, nsentences=32, sample_size=999.5, sample_size_v1=0, sample_size_v2=0, ppl=2.15, wps=534.3, ups=0.53, wpb=999.5, bsz=32, num_updates=19600, lr=1.98759e-05, gnorm=3.514, clip=100, loss_scale=128, train_wall=19, gb_free=11.1, wall=36830
2023-05-26 09:37:13 - progress_bar.py[line:272] - INFO: epoch 012:    590 / 1732 loss=2.305, loss_v1=0, loss_v2=0, nll_loss=1.096, ntokens=927.2, nsentences=32, sample_size=927.2, sample_size_v1=0, sample_size_v2=0, ppl=2.14, wps=499, ups=0.54, wpb=927.2, bsz=32, num_updates=19610, lr=1.98698e-05, gnorm=3.88, clip=100, loss_scale=128, train_wall=19, gb_free=12.1, wall=36848
2023-05-26 09:37:32 - progress_bar.py[line:272] - INFO: epoch 012:    600 / 1732 loss=2.27, loss_v1=0, loss_v2=0, nll_loss=1.059, ntokens=957.2, nsentences=32, sample_size=957.2, sample_size_v1=0, sample_size_v2=0, ppl=2.08, wps=515, ups=0.54, wpb=957.2, bsz=32, num_updates=19620, lr=1.98636e-05, gnorm=3.511, clip=100, loss_scale=128, train_wall=19, gb_free=11.3, wall=36867
2023-05-26 09:37:51 - progress_bar.py[line:272] - INFO: epoch 012:    610 / 1732 loss=2.298, loss_v1=0, loss_v2=0, nll_loss=1.092, ntokens=913.5, nsentences=32, sample_size=913.5, sample_size_v1=0, sample_size_v2=0, ppl=2.13, wps=494.6, ups=0.54, wpb=913.5, bsz=32, num_updates=19630, lr=1.98575e-05, gnorm=3.915, clip=100, loss_scale=128, train_wall=18, gb_free=11.9, wall=36885
2023-05-26 09:38:09 - progress_bar.py[line:272] - INFO: epoch 012:    620 / 1732 loss=2.334, loss_v1=0, loss_v2=0, nll_loss=1.128, ntokens=845.3, nsentences=32, sample_size=845.3, sample_size_v1=0, sample_size_v2=0, ppl=2.19, wps=461.6, ups=0.55, wpb=845.3, bsz=32, num_updates=19640, lr=1.98514e-05, gnorm=4.21, clip=100, loss_scale=128, train_wall=18, gb_free=11.9, wall=36904
2023-05-26 09:38:27 - progress_bar.py[line:272] - INFO: epoch 012:    630 / 1732 loss=2.295, loss_v1=0, loss_v2=0, nll_loss=1.084, ntokens=937, nsentences=32, sample_size=937, sample_size_v1=0, sample_size_v2=0, ppl=2.12, wps=508.5, ups=0.54, wpb=937, bsz=32, num_updates=19650, lr=1.98452e-05, gnorm=3.692, clip=100, loss_scale=128, train_wall=18, gb_free=11.3, wall=36922
2023-05-26 09:38:46 - progress_bar.py[line:272] - INFO: epoch 012:    640 / 1732 loss=2.325, loss_v1=0, loss_v2=0, nll_loss=1.122, ntokens=921.7, nsentences=32, sample_size=921.7, sample_size_v1=0, sample_size_v2=0, ppl=2.18, wps=498.9, ups=0.54, wpb=921.7, bsz=32, num_updates=19660, lr=1.98391e-05, gnorm=4.011, clip=100, loss_scale=128, train_wall=18, gb_free=11.1, wall=36940
2023-05-26 09:39:04 - progress_bar.py[line:272] - INFO: epoch 012:    650 / 1732 loss=2.309, loss_v1=0, loss_v2=0, nll_loss=1.101, ntokens=995.3, nsentences=32, sample_size=995.3, sample_size_v1=0, sample_size_v2=0, ppl=2.14, wps=540.4, ups=0.54, wpb=995.3, bsz=32, num_updates=19670, lr=1.98329e-05, gnorm=3.517, clip=100, loss_scale=128, train_wall=18, gb_free=11.2, wall=36959
2023-05-26 09:39:22 - progress_bar.py[line:272] - INFO: epoch 012:    660 / 1732 loss=2.311, loss_v1=0, loss_v2=0, nll_loss=1.104, ntokens=859.4, nsentences=32, sample_size=859.4, sample_size_v1=0, sample_size_v2=0, ppl=2.15, wps=471.3, ups=0.55, wpb=859.4, bsz=32, num_updates=19680, lr=1.98268e-05, gnorm=3.955, clip=100, loss_scale=128, train_wall=18, gb_free=11.9, wall=36977
2023-05-26 09:39:41 - progress_bar.py[line:272] - INFO: epoch 012:    670 / 1732 loss=2.319, loss_v1=0, loss_v2=0, nll_loss=1.113, ntokens=914.5, nsentences=32, sample_size=914.5, sample_size_v1=0, sample_size_v2=0, ppl=2.16, wps=494.8, ups=0.54, wpb=914.5, bsz=32, num_updates=19690, lr=1.98206e-05, gnorm=4.034, clip=100, loss_scale=128, train_wall=18, gb_free=11.4, wall=36996
2023-05-26 09:39:59 - progress_bar.py[line:272] - INFO: epoch 012:    680 / 1732 loss=2.318, loss_v1=0, loss_v2=0, nll_loss=1.111, ntokens=998, nsentences=32, sample_size=998, sample_size_v1=0, sample_size_v2=0, ppl=2.16, wps=539.4, ups=0.54, wpb=998, bsz=32, num_updates=19700, lr=1.98145e-05, gnorm=3.873, clip=100, loss_scale=128, train_wall=18, gb_free=11.2, wall=37014
2023-05-26 09:40:18 - progress_bar.py[line:272] - INFO: epoch 012:    690 / 1732 loss=2.316, loss_v1=0, loss_v2=0, nll_loss=1.108, ntokens=956.7, nsentences=32, sample_size=956.7, sample_size_v1=0, sample_size_v2=0, ppl=2.15, wps=515.6, ups=0.54, wpb=956.7, bsz=32, num_updates=19710, lr=1.98084e-05, gnorm=3.863, clip=100, loss_scale=128, train_wall=19, gb_free=10.6, wall=37033
2023-05-26 09:40:37 - progress_bar.py[line:272] - INFO: epoch 012:    700 / 1732 loss=2.293, loss_v1=0, loss_v2=0, nll_loss=1.086, ntokens=979.4, nsentences=32, sample_size=979.4, sample_size_v1=0, sample_size_v2=0, ppl=2.12, wps=528.1, ups=0.54, wpb=979.4, bsz=32, num_updates=19720, lr=1.98022e-05, gnorm=3.542, clip=100, loss_scale=128, train_wall=19, gb_free=11.7, wall=37051
2023-05-26 09:40:55 - progress_bar.py[line:272] - INFO: epoch 012:    710 / 1732 loss=2.307, loss_v1=0, loss_v2=0, nll_loss=1.098, ntokens=915.1, nsentences=32, sample_size=915.1, sample_size_v1=0, sample_size_v2=0, ppl=2.14, wps=496.2, ups=0.54, wpb=915.1, bsz=32, num_updates=19730, lr=1.97961e-05, gnorm=3.737, clip=100, loss_scale=128, train_wall=18, gb_free=11.6, wall=37070
2023-05-26 09:41:13 - progress_bar.py[line:272] - INFO: epoch 012:    720 / 1732 loss=2.296, loss_v1=0, loss_v2=0, nll_loss=1.087, ntokens=848.7, nsentences=32, sample_size=848.7, sample_size_v1=0, sample_size_v2=0, ppl=2.12, wps=461.9, ups=0.54, wpb=848.7, bsz=32, num_updates=19740, lr=1.97899e-05, gnorm=3.999, clip=100, loss_scale=128, train_wall=18, gb_free=10.9, wall=37088
2023-05-26 09:41:32 - progress_bar.py[line:272] - INFO: epoch 012:    730 / 1732 loss=2.289, loss_v1=0, loss_v2=0, nll_loss=1.082, ntokens=943.7, nsentences=32, sample_size=943.7, sample_size_v1=0, sample_size_v2=0, ppl=2.12, wps=510.9, ups=0.54, wpb=943.7, bsz=32, num_updates=19750, lr=1.97838e-05, gnorm=3.833, clip=100, loss_scale=128, train_wall=18, gb_free=11.9, wall=37106
2023-05-26 09:41:50 - progress_bar.py[line:272] - INFO: epoch 012:    740 / 1732 loss=2.291, loss_v1=0, loss_v2=0, nll_loss=1.081, ntokens=1007.2, nsentences=32, sample_size=1007.2, sample_size_v1=0, sample_size_v2=0, ppl=2.12, wps=544.7, ups=0.54, wpb=1007.2, bsz=32, num_updates=19760, lr=1.97777e-05, gnorm=3.613, clip=100, loss_scale=128, train_wall=18, gb_free=11.4, wall=37125
2023-05-26 09:42:09 - progress_bar.py[line:272] - INFO: epoch 012:    750 / 1732 loss=2.288, loss_v1=0, loss_v2=0, nll_loss=1.075, ntokens=970.2, nsentences=32, sample_size=970.2, sample_size_v1=0, sample_size_v2=0, ppl=2.11, wps=522.1, ups=0.54, wpb=970.2, bsz=32, num_updates=19770, lr=1.97715e-05, gnorm=3.714, clip=100, loss_scale=128, train_wall=19, gb_free=11.7, wall=37144
2023-05-26 09:42:27 - progress_bar.py[line:272] - INFO: epoch 012:    760 / 1732 loss=2.285, loss_v1=0, loss_v2=0, nll_loss=1.075, ntokens=974, nsentences=32, sample_size=974, sample_size_v1=0, sample_size_v2=0, ppl=2.11, wps=526.1, ups=0.54, wpb=974, bsz=32, num_updates=19780, lr=1.97654e-05, gnorm=3.763, clip=100, loss_scale=128, train_wall=18, gb_free=11.3, wall=37162
2023-05-26 09:42:46 - progress_bar.py[line:272] - INFO: epoch 012:    770 / 1732 loss=2.297, loss_v1=0, loss_v2=0, nll_loss=1.09, ntokens=922.1, nsentences=32, sample_size=922.1, sample_size_v1=0, sample_size_v2=0, ppl=2.13, wps=500.9, ups=0.54, wpb=922.1, bsz=32, num_updates=19790, lr=1.97592e-05, gnorm=3.864, clip=100, loss_scale=128, train_wall=18, gb_free=11.8, wall=37180
2023-05-26 09:43:04 - progress_bar.py[line:272] - INFO: epoch 012:    780 / 1732 loss=2.284, loss_v1=0, loss_v2=0, nll_loss=1.073, ntokens=1056.6, nsentences=32, sample_size=1056.6, sample_size_v1=0, sample_size_v2=0, ppl=2.1, wps=569.4, ups=0.54, wpb=1056.6, bsz=32, num_updates=19800, lr=1.97531e-05, gnorm=3.182, clip=100, loss_scale=128, train_wall=19, gb_free=11.3, wall=37199
2023-05-26 09:43:23 - progress_bar.py[line:272] - INFO: epoch 012:    790 / 1732 loss=2.301, loss_v1=0, loss_v2=0, nll_loss=1.092, ntokens=1011.9, nsentences=32, sample_size=1011.9, sample_size_v1=0, sample_size_v2=0, ppl=2.13, wps=548.9, ups=0.54, wpb=1011.9, bsz=32, num_updates=19810, lr=1.97469e-05, gnorm=3.971, clip=100, loss_scale=128, train_wall=18, gb_free=10.9, wall=37217
2023-05-26 09:43:41 - progress_bar.py[line:272] - INFO: epoch 012:    800 / 1732 loss=2.305, loss_v1=0, loss_v2=0, nll_loss=1.098, ntokens=1000.1, nsentences=32, sample_size=1000.1, sample_size_v1=0, sample_size_v2=0, ppl=2.14, wps=539.5, ups=0.54, wpb=1000.1, bsz=32, num_updates=19820, lr=1.97408e-05, gnorm=3.805, clip=100, loss_scale=128, train_wall=19, gb_free=11.8, wall=37236
2023-05-26 09:44:00 - progress_bar.py[line:272] - INFO: epoch 012:    810 / 1732 loss=2.295, loss_v1=0, loss_v2=0, nll_loss=1.085, ntokens=918.3, nsentences=32, sample_size=918.3, sample_size_v1=0, sample_size_v2=0, ppl=2.12, wps=497.3, ups=0.54, wpb=918.3, bsz=32, num_updates=19830, lr=1.97347e-05, gnorm=3.953, clip=100, loss_scale=128, train_wall=18, gb_free=11.5, wall=37254
2023-05-26 09:44:18 - progress_bar.py[line:272] - INFO: epoch 012:    820 / 1732 loss=2.304, loss_v1=0, loss_v2=0, nll_loss=1.095, ntokens=912.3, nsentences=32, sample_size=912.3, sample_size_v1=0, sample_size_v2=0, ppl=2.14, wps=493.5, ups=0.54, wpb=912.3, bsz=32, num_updates=19840, lr=1.97285e-05, gnorm=3.92, clip=100, loss_scale=128, train_wall=18, gb_free=11.6, wall=37273
2023-05-26 09:44:37 - progress_bar.py[line:272] - INFO: epoch 012:    830 / 1732 loss=2.284, loss_v1=0, loss_v2=0, nll_loss=1.073, ntokens=919.5, nsentences=32, sample_size=919.5, sample_size_v1=0, sample_size_v2=0, ppl=2.1, wps=497.9, ups=0.54, wpb=919.5, bsz=32, num_updates=19850, lr=1.97224e-05, gnorm=3.788, clip=100, loss_scale=128, train_wall=18, gb_free=11.7, wall=37291
2023-05-26 09:44:55 - progress_bar.py[line:272] - INFO: epoch 012:    840 / 1732 loss=2.309, loss_v1=0, loss_v2=0, nll_loss=1.101, ntokens=917.9, nsentences=32, sample_size=917.9, sample_size_v1=0, sample_size_v2=0, ppl=2.14, wps=500.1, ups=0.54, wpb=917.9, bsz=32, num_updates=19860, lr=1.97162e-05, gnorm=3.814, clip=100, loss_scale=256, train_wall=18, gb_free=11.2, wall=37310
2023-05-26 09:44:57 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 128.0
2023-05-26 09:45:15 - progress_bar.py[line:272] - INFO: epoch 012:    851 / 1732 loss=2.3, loss_v1=0, loss_v2=0, nll_loss=1.091, ntokens=1005.2, nsentences=32, sample_size=1005.2, sample_size_v1=0, sample_size_v2=0, ppl=2.13, wps=495.6, ups=0.49, wpb=1005.2, bsz=32, num_updates=19870, lr=1.97101e-05, gnorm=3.774, clip=100, loss_scale=128, train_wall=20, gb_free=11.4, wall=37330
2023-05-26 09:45:34 - progress_bar.py[line:272] - INFO: epoch 012:    861 / 1732 loss=2.28, loss_v1=0, loss_v2=0, nll_loss=1.071, ntokens=942.6, nsentences=32, sample_size=942.6, sample_size_v1=0, sample_size_v2=0, ppl=2.1, wps=510.1, ups=0.54, wpb=942.6, bsz=32, num_updates=19880, lr=1.97039e-05, gnorm=4.046, clip=100, loss_scale=128, train_wall=18, gb_free=11.3, wall=37349
2023-05-26 09:45:52 - progress_bar.py[line:272] - INFO: epoch 012:    871 / 1732 loss=2.301, loss_v1=0, loss_v2=0, nll_loss=1.094, ntokens=962.7, nsentences=32, sample_size=962.7, sample_size_v1=0, sample_size_v2=0, ppl=2.13, wps=521.4, ups=0.54, wpb=962.7, bsz=32, num_updates=19890, lr=1.96978e-05, gnorm=3.902, clip=100, loss_scale=128, train_wall=18, gb_free=11.8, wall=37367
2023-05-26 09:46:11 - progress_bar.py[line:272] - INFO: epoch 012:    881 / 1732 loss=2.255, loss_v1=0, loss_v2=0, nll_loss=1.04, ntokens=988.4, nsentences=32, sample_size=988.4, sample_size_v1=0, sample_size_v2=0, ppl=2.06, wps=531.9, ups=0.54, wpb=988.4, bsz=32, num_updates=19900, lr=1.96917e-05, gnorm=3.675, clip=100, loss_scale=128, train_wall=19, gb_free=12.1, wall=37386
2023-05-26 09:46:30 - progress_bar.py[line:272] - INFO: epoch 012:    891 / 1732 loss=2.238, loss_v1=0, loss_v2=0, nll_loss=1.023, ntokens=1001.4, nsentences=32, sample_size=1001.4, sample_size_v1=0, sample_size_v2=0, ppl=2.03, wps=539.5, ups=0.54, wpb=1001.4, bsz=32, num_updates=19910, lr=1.96855e-05, gnorm=3.497, clip=100, loss_scale=128, train_wall=19, gb_free=11.4, wall=37404
2023-05-26 09:46:48 - progress_bar.py[line:272] - INFO: epoch 012:    901 / 1732 loss=2.234, loss_v1=0, loss_v2=0, nll_loss=1.015, ntokens=1032.4, nsentences=32, sample_size=1032.4, sample_size_v1=0, sample_size_v2=0, ppl=2.02, wps=556.8, ups=0.54, wpb=1032.4, bsz=32, num_updates=19920, lr=1.96794e-05, gnorm=3.567, clip=100, loss_scale=128, train_wall=19, gb_free=11.7, wall=37423
2023-05-26 09:47:07 - progress_bar.py[line:272] - INFO: epoch 012:    911 / 1732 loss=2.293, loss_v1=0, loss_v2=0, nll_loss=1.083, ntokens=960.1, nsentences=32, sample_size=960.1, sample_size_v1=0, sample_size_v2=0, ppl=2.12, wps=514.6, ups=0.54, wpb=960.1, bsz=32, num_updates=19930, lr=1.96732e-05, gnorm=3.882, clip=100, loss_scale=128, train_wall=19, gb_free=12, wall=37441
2023-05-26 09:47:25 - progress_bar.py[line:272] - INFO: epoch 012:    921 / 1732 loss=2.301, loss_v1=0, loss_v2=0, nll_loss=1.093, ntokens=986.3, nsentences=32, sample_size=986.3, sample_size_v1=0, sample_size_v2=0, ppl=2.13, wps=531.2, ups=0.54, wpb=986.3, bsz=32, num_updates=19940, lr=1.96671e-05, gnorm=3.87, clip=100, loss_scale=128, train_wall=19, gb_free=11.4, wall=37460
2023-05-26 09:47:44 - progress_bar.py[line:272] - INFO: epoch 012:    931 / 1732 loss=2.268, loss_v1=0, loss_v2=0, nll_loss=1.056, ntokens=1050.4, nsentences=32, sample_size=1050.4, sample_size_v1=0, sample_size_v2=0, ppl=2.08, wps=560.9, ups=0.53, wpb=1050.4, bsz=32, num_updates=19950, lr=1.9661e-05, gnorm=3.726, clip=100, loss_scale=128, train_wall=19, gb_free=11.5, wall=37479
2023-05-26 09:48:03 - progress_bar.py[line:272] - INFO: epoch 012:    941 / 1732 loss=2.271, loss_v1=0, loss_v2=0, nll_loss=1.061, ntokens=1052.3, nsentences=32, sample_size=1052.3, sample_size_v1=0, sample_size_v2=0, ppl=2.09, wps=559.1, ups=0.53, wpb=1052.3, bsz=32, num_updates=19960, lr=1.96548e-05, gnorm=3.576, clip=100, loss_scale=128, train_wall=19, gb_free=10.1, wall=37498
2023-05-26 09:48:22 - progress_bar.py[line:272] - INFO: epoch 012:    951 / 1732 loss=2.291, loss_v1=0, loss_v2=0, nll_loss=1.08, ntokens=1037.8, nsentences=32, sample_size=1037.8, sample_size_v1=0, sample_size_v2=0, ppl=2.11, wps=554.3, ups=0.53, wpb=1037.8, bsz=32, num_updates=19970, lr=1.96487e-05, gnorm=3.895, clip=100, loss_scale=128, train_wall=19, gb_free=11.1, wall=37516
2023-05-26 09:48:40 - progress_bar.py[line:272] - INFO: epoch 012:    961 / 1732 loss=2.282, loss_v1=0, loss_v2=0, nll_loss=1.07, ntokens=1067.9, nsentences=32, sample_size=1067.9, sample_size_v1=0, sample_size_v2=0, ppl=2.1, wps=569, ups=0.53, wpb=1067.9, bsz=32, num_updates=19980, lr=1.96425e-05, gnorm=3.772, clip=100, loss_scale=128, train_wall=19, gb_free=11.3, wall=37535
2023-05-26 09:48:59 - progress_bar.py[line:272] - INFO: epoch 012:    971 / 1732 loss=2.31, loss_v1=0, loss_v2=0, nll_loss=1.103, ntokens=1026.9, nsentences=32, sample_size=1026.9, sample_size_v1=0, sample_size_v2=0, ppl=2.15, wps=548.1, ups=0.53, wpb=1026.9, bsz=32, num_updates=19990, lr=1.96364e-05, gnorm=3.815, clip=100, loss_scale=128, train_wall=19, gb_free=10.3, wall=37554
2023-05-26 09:49:18 - progress_bar.py[line:272] - INFO: epoch 012:    981 / 1732 loss=2.274, loss_v1=0, loss_v2=0, nll_loss=1.063, ntokens=1016.8, nsentences=32, sample_size=1016.8, sample_size_v1=0, sample_size_v2=0, ppl=2.09, wps=538.8, ups=0.53, wpb=1016.8, bsz=32, num_updates=20000, lr=1.96302e-05, gnorm=3.473, clip=100, loss_scale=128, train_wall=19, gb_free=11.1, wall=37573
2023-05-26 09:49:37 - progress_bar.py[line:272] - INFO: epoch 012:    991 / 1732 loss=2.295, loss_v1=0, loss_v2=0, nll_loss=1.085, ntokens=1042.2, nsentences=32, sample_size=1042.2, sample_size_v1=0, sample_size_v2=0, ppl=2.12, wps=554.2, ups=0.53, wpb=1042.2, bsz=32, num_updates=20010, lr=1.96241e-05, gnorm=3.889, clip=100, loss_scale=128, train_wall=19, gb_free=11.4, wall=37591
2023-05-26 09:49:55 - progress_bar.py[line:272] - INFO: epoch 012:   1001 / 1732 loss=2.273, loss_v1=0, loss_v2=0, nll_loss=1.06, ntokens=1019, nsentences=32, sample_size=1019, sample_size_v1=0, sample_size_v2=0, ppl=2.08, wps=547.6, ups=0.54, wpb=1019, bsz=32, num_updates=20020, lr=1.9618e-05, gnorm=3.881, clip=100, loss_scale=128, train_wall=19, gb_free=11.3, wall=37610
2023-05-26 09:50:14 - progress_bar.py[line:272] - INFO: epoch 012:   1011 / 1732 loss=2.293, loss_v1=0, loss_v2=0, nll_loss=1.083, ntokens=995.8, nsentences=32, sample_size=995.8, sample_size_v1=0, sample_size_v2=0, ppl=2.12, wps=533.2, ups=0.54, wpb=995.8, bsz=32, num_updates=20030, lr=1.96118e-05, gnorm=3.843, clip=100, loss_scale=128, train_wall=19, gb_free=11.5, wall=37629
2023-05-26 09:50:33 - progress_bar.py[line:272] - INFO: epoch 012:   1021 / 1732 loss=2.263, loss_v1=0, loss_v2=0, nll_loss=1.05, ntokens=1050, nsentences=32, sample_size=1050, sample_size_v1=0, sample_size_v2=0, ppl=2.07, wps=559.5, ups=0.53, wpb=1050, bsz=32, num_updates=20040, lr=1.96057e-05, gnorm=3.524, clip=100, loss_scale=128, train_wall=19, gb_free=10.5, wall=37648
2023-05-26 09:50:52 - progress_bar.py[line:272] - INFO: epoch 012:   1031 / 1732 loss=2.286, loss_v1=0, loss_v2=0, nll_loss=1.076, ntokens=1125.6, nsentences=32, sample_size=1125.6, sample_size_v1=0, sample_size_v2=0, ppl=2.11, wps=592.6, ups=0.53, wpb=1125.6, bsz=32, num_updates=20050, lr=1.95995e-05, gnorm=3.431, clip=100, loss_scale=128, train_wall=19, gb_free=11.1, wall=37667
2023-05-26 09:51:11 - progress_bar.py[line:272] - INFO: epoch 012:   1041 / 1732 loss=2.28, loss_v1=0, loss_v2=0, nll_loss=1.066, ntokens=1038.5, nsentences=32, sample_size=1038.5, sample_size_v1=0, sample_size_v2=0, ppl=2.09, wps=552.4, ups=0.53, wpb=1038.5, bsz=32, num_updates=20060, lr=1.95934e-05, gnorm=3.746, clip=100, loss_scale=128, train_wall=19, gb_free=11.5, wall=37685
2023-05-26 09:51:29 - progress_bar.py[line:272] - INFO: epoch 012:   1051 / 1732 loss=2.288, loss_v1=0, loss_v2=0, nll_loss=1.079, ntokens=1067.2, nsentences=32, sample_size=1067.2, sample_size_v1=0, sample_size_v2=0, ppl=2.11, wps=571.2, ups=0.54, wpb=1067.2, bsz=32, num_updates=20070, lr=1.95872e-05, gnorm=4.035, clip=100, loss_scale=128, train_wall=19, gb_free=11.8, wall=37704
2023-05-26 09:51:48 - progress_bar.py[line:272] - INFO: epoch 012:   1061 / 1732 loss=2.281, loss_v1=0, loss_v2=0, nll_loss=1.071, ntokens=1037.8, nsentences=32, sample_size=1037.8, sample_size_v1=0, sample_size_v2=0, ppl=2.1, wps=554.1, ups=0.53, wpb=1037.8, bsz=32, num_updates=20080, lr=1.95811e-05, gnorm=3.701, clip=100, loss_scale=128, train_wall=19, gb_free=11.5, wall=37723
2023-05-26 09:52:07 - progress_bar.py[line:272] - INFO: epoch 012:   1071 / 1732 loss=2.271, loss_v1=0, loss_v2=0, nll_loss=1.058, ntokens=999.8, nsentences=32, sample_size=999.8, sample_size_v1=0, sample_size_v2=0, ppl=2.08, wps=533.4, ups=0.53, wpb=999.8, bsz=32, num_updates=20090, lr=1.9575e-05, gnorm=3.857, clip=100, loss_scale=128, train_wall=19, gb_free=10.7, wall=37741
2023-05-26 09:52:26 - progress_bar.py[line:272] - INFO: epoch 012:   1081 / 1732 loss=2.288, loss_v1=0, loss_v2=0, nll_loss=1.077, ntokens=1039.7, nsentences=32, sample_size=1039.7, sample_size_v1=0, sample_size_v2=0, ppl=2.11, wps=551.3, ups=0.53, wpb=1039.7, bsz=32, num_updates=20100, lr=1.95688e-05, gnorm=3.884, clip=100, loss_scale=128, train_wall=19, gb_free=11.1, wall=37760
2023-05-26 09:52:45 - progress_bar.py[line:272] - INFO: epoch 012:   1091 / 1732 loss=2.282, loss_v1=0, loss_v2=0, nll_loss=1.072, ntokens=1090, nsentences=32, sample_size=1090, sample_size_v1=0, sample_size_v2=0, ppl=2.1, wps=577.6, ups=0.53, wpb=1090, bsz=32, num_updates=20110, lr=1.95627e-05, gnorm=3.773, clip=100, loss_scale=128, train_wall=19, gb_free=11.4, wall=37779
2023-05-26 09:53:03 - progress_bar.py[line:272] - INFO: epoch 012:   1101 / 1732 loss=2.302, loss_v1=0, loss_v2=0, nll_loss=1.093, ntokens=1006.7, nsentences=32, sample_size=1006.7, sample_size_v1=0, sample_size_v2=0, ppl=2.13, wps=537.8, ups=0.53, wpb=1006.7, bsz=32, num_updates=20120, lr=1.95565e-05, gnorm=3.911, clip=100, loss_scale=128, train_wall=19, gb_free=11.1, wall=37798
2023-05-26 09:53:22 - progress_bar.py[line:272] - INFO: epoch 012:   1111 / 1732 loss=2.271, loss_v1=0, loss_v2=0, nll_loss=1.057, ntokens=1054.1, nsentences=32, sample_size=1054.1, sample_size_v1=0, sample_size_v2=0, ppl=2.08, wps=559, ups=0.53, wpb=1054.1, bsz=32, num_updates=20130, lr=1.95504e-05, gnorm=3.383, clip=100, loss_scale=128, train_wall=19, gb_free=11.5, wall=37817
2023-05-26 09:53:41 - progress_bar.py[line:272] - INFO: epoch 012:   1121 / 1732 loss=2.273, loss_v1=0, loss_v2=0, nll_loss=1.062, ntokens=962.9, nsentences=32, sample_size=962.9, sample_size_v1=0, sample_size_v2=0, ppl=2.09, wps=513.7, ups=0.53, wpb=962.9, bsz=32, num_updates=20140, lr=1.95443e-05, gnorm=3.852, clip=100, loss_scale=128, train_wall=19, gb_free=11.5, wall=37836
2023-05-26 09:54:00 - progress_bar.py[line:272] - INFO: epoch 012:   1131 / 1732 loss=2.272, loss_v1=0, loss_v2=0, nll_loss=1.061, ntokens=991.2, nsentences=32, sample_size=991.2, sample_size_v1=0, sample_size_v2=0, ppl=2.09, wps=528.4, ups=0.53, wpb=991.2, bsz=32, num_updates=20150, lr=1.95381e-05, gnorm=3.775, clip=100, loss_scale=128, train_wall=19, gb_free=11.7, wall=37854
2023-05-26 09:54:18 - progress_bar.py[line:272] - INFO: epoch 012:   1141 / 1732 loss=2.282, loss_v1=0, loss_v2=0, nll_loss=1.07, ntokens=1017.8, nsentences=32, sample_size=1017.8, sample_size_v1=0, sample_size_v2=0, ppl=2.1, wps=544.1, ups=0.53, wpb=1017.8, bsz=32, num_updates=20160, lr=1.9532e-05, gnorm=3.814, clip=100, loss_scale=128, train_wall=19, gb_free=11.3, wall=37873
2023-05-26 09:54:37 - progress_bar.py[line:272] - INFO: epoch 012:   1151 / 1732 loss=2.265, loss_v1=0, loss_v2=0, nll_loss=1.051, ntokens=1034.7, nsentences=32, sample_size=1034.7, sample_size_v1=0, sample_size_v2=0, ppl=2.07, wps=552.6, ups=0.53, wpb=1034.7, bsz=32, num_updates=20170, lr=1.95258e-05, gnorm=3.526, clip=100, loss_scale=128, train_wall=19, gb_free=10.9, wall=37892
2023-05-26 09:54:56 - progress_bar.py[line:272] - INFO: epoch 012:   1161 / 1732 loss=2.243, loss_v1=0, loss_v2=0, nll_loss=1.03, ntokens=995.8, nsentences=32, sample_size=995.8, sample_size_v1=0, sample_size_v2=0, ppl=2.04, wps=530.2, ups=0.53, wpb=995.8, bsz=32, num_updates=20180, lr=1.95197e-05, gnorm=3.803, clip=100, loss_scale=128, train_wall=19, gb_free=11.4, wall=37911
2023-05-26 09:55:15 - progress_bar.py[line:272] - INFO: epoch 012:   1171 / 1732 loss=2.267, loss_v1=0, loss_v2=0, nll_loss=1.053, ntokens=1049.1, nsentences=32, sample_size=1049.1, sample_size_v1=0, sample_size_v2=0, ppl=2.08, wps=557.8, ups=0.53, wpb=1049.1, bsz=32, num_updates=20190, lr=1.95135e-05, gnorm=3.399, clip=100, loss_scale=128, train_wall=19, gb_free=11.5, wall=37929
2023-05-26 09:55:33 - progress_bar.py[line:272] - INFO: epoch 012:   1181 / 1732 loss=2.246, loss_v1=0, loss_v2=0, nll_loss=1.029, ntokens=1019.2, nsentences=32, sample_size=1019.2, sample_size_v1=0, sample_size_v2=0, ppl=2.04, wps=545.3, ups=0.53, wpb=1019.2, bsz=32, num_updates=20200, lr=1.95074e-05, gnorm=3.713, clip=100, loss_scale=128, train_wall=19, gb_free=10.4, wall=37948
2023-05-26 09:55:52 - progress_bar.py[line:272] - INFO: epoch 012:   1191 / 1732 loss=2.299, loss_v1=0, loss_v2=0, nll_loss=1.091, ntokens=1005.4, nsentences=32, sample_size=1005.4, sample_size_v1=0, sample_size_v2=0, ppl=2.13, wps=536.1, ups=0.53, wpb=1005.4, bsz=32, num_updates=20210, lr=1.95013e-05, gnorm=3.877, clip=100, loss_scale=128, train_wall=19, gb_free=11.5, wall=37967
2023-05-26 09:56:11 - progress_bar.py[line:272] - INFO: epoch 012:   1201 / 1732 loss=2.254, loss_v1=0, loss_v2=0, nll_loss=1.039, ntokens=1106.6, nsentences=32, sample_size=1106.6, sample_size_v1=0, sample_size_v2=0, ppl=2.06, wps=586.7, ups=0.53, wpb=1106.6, bsz=32, num_updates=20220, lr=1.94951e-05, gnorm=3.674, clip=100, loss_scale=128, train_wall=19, gb_free=11.2, wall=37986
2023-05-26 09:56:30 - progress_bar.py[line:272] - INFO: epoch 012:   1211 / 1732 loss=2.256, loss_v1=0, loss_v2=0, nll_loss=1.042, ntokens=1064.4, nsentences=32, sample_size=1064.4, sample_size_v1=0, sample_size_v2=0, ppl=2.06, wps=564, ups=0.53, wpb=1064.4, bsz=32, num_updates=20230, lr=1.9489e-05, gnorm=3.576, clip=100, loss_scale=128, train_wall=19, gb_free=11.4, wall=38005
2023-05-26 09:56:49 - progress_bar.py[line:272] - INFO: epoch 012:   1221 / 1732 loss=2.308, loss_v1=0, loss_v2=0, nll_loss=1.102, ntokens=1029, nsentences=32, sample_size=1029, sample_size_v1=0, sample_size_v2=0, ppl=2.15, wps=551.2, ups=0.54, wpb=1029, bsz=32, num_updates=20240, lr=1.94828e-05, gnorm=3.915, clip=100, loss_scale=128, train_wall=19, gb_free=11.6, wall=38023
2023-05-26 09:57:07 - progress_bar.py[line:272] - INFO: epoch 012:   1231 / 1732 loss=2.255, loss_v1=0, loss_v2=0, nll_loss=1.04, ntokens=1027, nsentences=32, sample_size=1027, sample_size_v1=0, sample_size_v2=0, ppl=2.06, wps=548.1, ups=0.53, wpb=1027, bsz=32, num_updates=20250, lr=1.94767e-05, gnorm=3.41, clip=100, loss_scale=128, train_wall=19, gb_free=11.4, wall=38042
2023-05-26 09:57:26 - progress_bar.py[line:272] - INFO: epoch 012:   1241 / 1732 loss=2.235, loss_v1=0, loss_v2=0, nll_loss=1.02, ntokens=1099, nsentences=32, sample_size=1099, sample_size_v1=0, sample_size_v2=0, ppl=2.03, wps=581.9, ups=0.53, wpb=1099, bsz=32, num_updates=20260, lr=1.94705e-05, gnorm=3.614, clip=100, loss_scale=128, train_wall=19, gb_free=11.7, wall=38061
2023-05-26 09:57:45 - progress_bar.py[line:272] - INFO: epoch 012:   1251 / 1732 loss=2.245, loss_v1=0, loss_v2=0, nll_loss=1.031, ntokens=1063.8, nsentences=32, sample_size=1063.8, sample_size_v1=0, sample_size_v2=0, ppl=2.04, wps=565.5, ups=0.53, wpb=1063.8, bsz=32, num_updates=20270, lr=1.94644e-05, gnorm=3.501, clip=100, loss_scale=128, train_wall=19, gb_free=11.2, wall=38080
2023-05-26 09:58:04 - progress_bar.py[line:272] - INFO: epoch 012:   1261 / 1732 loss=2.258, loss_v1=0, loss_v2=0, nll_loss=1.045, ntokens=1068.4, nsentences=32, sample_size=1068.4, sample_size_v1=0, sample_size_v2=0, ppl=2.06, wps=568.4, ups=0.53, wpb=1068.4, bsz=32, num_updates=20280, lr=1.94583e-05, gnorm=3.544, clip=100, loss_scale=128, train_wall=19, gb_free=11, wall=38098
2023-05-26 09:58:22 - progress_bar.py[line:272] - INFO: epoch 012:   1271 / 1732 loss=2.282, loss_v1=0, loss_v2=0, nll_loss=1.07, ntokens=1028.5, nsentences=32, sample_size=1028.5, sample_size_v1=0, sample_size_v2=0, ppl=2.1, wps=551, ups=0.54, wpb=1028.5, bsz=32, num_updates=20290, lr=1.94521e-05, gnorm=3.492, clip=100, loss_scale=128, train_wall=19, gb_free=11.8, wall=38117
2023-05-26 09:58:41 - progress_bar.py[line:272] - INFO: epoch 012:   1281 / 1732 loss=2.257, loss_v1=0, loss_v2=0, nll_loss=1.043, ntokens=1068.6, nsentences=32, sample_size=1068.6, sample_size_v1=0, sample_size_v2=0, ppl=2.06, wps=564.4, ups=0.53, wpb=1068.6, bsz=32, num_updates=20300, lr=1.9446e-05, gnorm=3.657, clip=100, loss_scale=128, train_wall=19, gb_free=11.3, wall=38136
2023-05-26 09:59:00 - progress_bar.py[line:272] - INFO: epoch 012:   1291 / 1732 loss=2.269, loss_v1=0, loss_v2=0, nll_loss=1.056, ntokens=1084.2, nsentences=32, sample_size=1084.2, sample_size_v1=0, sample_size_v2=0, ppl=2.08, wps=575.5, ups=0.53, wpb=1084.2, bsz=32, num_updates=20310, lr=1.94398e-05, gnorm=3.322, clip=100, loss_scale=128, train_wall=19, gb_free=11.5, wall=38155
2023-05-26 09:59:19 - progress_bar.py[line:272] - INFO: epoch 012:   1301 / 1732 loss=2.265, loss_v1=0, loss_v2=0, nll_loss=1.053, ntokens=1090.9, nsentences=32, sample_size=1090.9, sample_size_v1=0, sample_size_v2=0, ppl=2.07, wps=580.8, ups=0.53, wpb=1090.9, bsz=32, num_updates=20320, lr=1.94337e-05, gnorm=3.297, clip=100, loss_scale=128, train_wall=19, gb_free=11.3, wall=38174
2023-05-26 09:59:38 - progress_bar.py[line:272] - INFO: epoch 012:   1311 / 1732 loss=2.305, loss_v1=0, loss_v2=0, nll_loss=1.095, ntokens=1079.3, nsentences=32, sample_size=1079.3, sample_size_v1=0, sample_size_v2=0, ppl=2.14, wps=565.8, ups=0.52, wpb=1079.3, bsz=32, num_updates=20330, lr=1.94276e-05, gnorm=3.804, clip=100, loss_scale=128, train_wall=19, gb_free=10.9, wall=38193
2023-05-26 09:59:57 - progress_bar.py[line:272] - INFO: epoch 012:   1321 / 1732 loss=2.258, loss_v1=0, loss_v2=0, nll_loss=1.046, ntokens=1098.3, nsentences=32, sample_size=1098.3, sample_size_v1=0, sample_size_v2=0, ppl=2.06, wps=581.2, ups=0.53, wpb=1098.3, bsz=32, num_updates=20340, lr=1.94214e-05, gnorm=3.392, clip=100, loss_scale=128, train_wall=19, gb_free=9.2, wall=38212
2023-05-26 10:00:16 - progress_bar.py[line:272] - INFO: epoch 012:   1331 / 1732 loss=2.238, loss_v1=0, loss_v2=0, nll_loss=1.022, ntokens=1102.8, nsentences=32, sample_size=1102.8, sample_size_v1=0, sample_size_v2=0, ppl=2.03, wps=583.1, ups=0.53, wpb=1102.8, bsz=32, num_updates=20350, lr=1.94153e-05, gnorm=3.234, clip=100, loss_scale=128, train_wall=19, gb_free=11.3, wall=38231
2023-05-26 10:00:35 - progress_bar.py[line:272] - INFO: epoch 012:   1341 / 1732 loss=2.255, loss_v1=0, loss_v2=0, nll_loss=1.04, ntokens=1167.8, nsentences=32, sample_size=1167.8, sample_size_v1=0, sample_size_v2=0, ppl=2.06, wps=616.9, ups=0.53, wpb=1167.8, bsz=32, num_updates=20360, lr=1.94091e-05, gnorm=3.587, clip=100, loss_scale=128, train_wall=19, gb_free=10.9, wall=38250
2023-05-26 10:00:54 - progress_bar.py[line:272] - INFO: epoch 012:   1351 / 1732 loss=2.258, loss_v1=0, loss_v2=0, nll_loss=1.046, ntokens=1137.2, nsentences=32, sample_size=1137.2, sample_size_v1=0, sample_size_v2=0, ppl=2.06, wps=600.4, ups=0.53, wpb=1137.2, bsz=32, num_updates=20370, lr=1.9403e-05, gnorm=3.407, clip=100, loss_scale=128, train_wall=19, gb_free=11, wall=38268
2023-05-26 10:01:13 - progress_bar.py[line:272] - INFO: epoch 012:   1361 / 1732 loss=2.229, loss_v1=0, loss_v2=0, nll_loss=1.011, ntokens=1107.4, nsentences=32, sample_size=1107.4, sample_size_v1=0, sample_size_v2=0, ppl=2.02, wps=584.3, ups=0.53, wpb=1107.4, bsz=32, num_updates=20380, lr=1.93968e-05, gnorm=3.424, clip=100, loss_scale=256, train_wall=19, gb_free=11.3, wall=38287
2023-05-26 10:01:20 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 128.0
2023-05-26 10:01:33 - progress_bar.py[line:272] - INFO: epoch 012:   1372 / 1732 loss=2.273, loss_v1=0, loss_v2=0, nll_loss=1.06, ntokens=1101.1, nsentences=32, sample_size=1101.1, sample_size_v1=0, sample_size_v2=0, ppl=2.09, wps=533.6, ups=0.48, wpb=1101.1, bsz=32, num_updates=20390, lr=1.93907e-05, gnorm=3.457, clip=100, loss_scale=128, train_wall=21, gb_free=11.6, wall=38308
2023-05-26 10:01:52 - progress_bar.py[line:272] - INFO: epoch 012:   1382 / 1732 loss=2.281, loss_v1=0, loss_v2=0, nll_loss=1.071, ntokens=1160, nsentences=32, sample_size=1160, sample_size_v1=0, sample_size_v2=0, ppl=2.1, wps=614.8, ups=0.53, wpb=1160, bsz=32, num_updates=20400, lr=1.93846e-05, gnorm=3.531, clip=100, loss_scale=128, train_wall=19, gb_free=10.9, wall=38327
2023-05-26 10:02:11 - progress_bar.py[line:272] - INFO: epoch 012:   1392 / 1732 loss=2.275, loss_v1=0, loss_v2=0, nll_loss=1.063, ntokens=1049.4, nsentences=32, sample_size=1049.4, sample_size_v1=0, sample_size_v2=0, ppl=2.09, wps=562.2, ups=0.54, wpb=1049.4, bsz=32, num_updates=20410, lr=1.93784e-05, gnorm=3.703, clip=100, loss_scale=128, train_wall=19, gb_free=11.2, wall=38346
2023-05-26 10:02:30 - progress_bar.py[line:272] - INFO: epoch 012:   1402 / 1732 loss=2.246, loss_v1=0, loss_v2=0, nll_loss=1.031, ntokens=1133.7, nsentences=32, sample_size=1133.7, sample_size_v1=0, sample_size_v2=0, ppl=2.04, wps=600.4, ups=0.53, wpb=1133.7, bsz=32, num_updates=20420, lr=1.93723e-05, gnorm=3.601, clip=100, loss_scale=128, train_wall=19, gb_free=10.2, wall=38364
2023-05-26 10:02:49 - progress_bar.py[line:272] - INFO: epoch 012:   1412 / 1732 loss=2.284, loss_v1=0, loss_v2=0, nll_loss=1.074, ntokens=1246.7, nsentences=32, sample_size=1246.7, sample_size_v1=0, sample_size_v2=0, ppl=2.11, wps=660.2, ups=0.53, wpb=1246.7, bsz=32, num_updates=20430, lr=1.93661e-05, gnorm=3.193, clip=100, loss_scale=128, train_wall=19, gb_free=10.8, wall=38383
2023-05-26 10:03:08 - progress_bar.py[line:272] - INFO: epoch 012:   1422 / 1732 loss=2.27, loss_v1=0, loss_v2=0, nll_loss=1.056, ntokens=1259.2, nsentences=32, sample_size=1259.2, sample_size_v1=0, sample_size_v2=0, ppl=2.08, wps=657.7, ups=0.52, wpb=1259.2, bsz=32, num_updates=20440, lr=1.936e-05, gnorm=3.374, clip=100, loss_scale=128, train_wall=19, gb_free=10.7, wall=38403
2023-05-26 10:03:27 - progress_bar.py[line:272] - INFO: epoch 012:   1432 / 1732 loss=2.243, loss_v1=0, loss_v2=0, nll_loss=1.028, ntokens=1215.6, nsentences=32, sample_size=1215.6, sample_size_v1=0, sample_size_v2=0, ppl=2.04, wps=641.9, ups=0.53, wpb=1215.6, bsz=32, num_updates=20450, lr=1.93538e-05, gnorm=3.226, clip=100, loss_scale=128, train_wall=19, gb_free=11.2, wall=38421
2023-05-26 10:03:46 - progress_bar.py[line:272] - INFO: epoch 012:   1442 / 1732 loss=2.265, loss_v1=0, loss_v2=0, nll_loss=1.055, ntokens=1136.6, nsentences=32, sample_size=1136.6, sample_size_v1=0, sample_size_v2=0, ppl=2.08, wps=602.5, ups=0.53, wpb=1136.6, bsz=32, num_updates=20460, lr=1.93477e-05, gnorm=3.381, clip=100, loss_scale=128, train_wall=19, gb_free=11.2, wall=38440
2023-05-26 10:04:04 - progress_bar.py[line:272] - INFO: epoch 012:   1452 / 1732 loss=2.269, loss_v1=0, loss_v2=0, nll_loss=1.055, ntokens=1140.1, nsentences=32, sample_size=1140.1, sample_size_v1=0, sample_size_v2=0, ppl=2.08, wps=605.3, ups=0.53, wpb=1140.1, bsz=32, num_updates=20470, lr=1.93416e-05, gnorm=3.662, clip=100, loss_scale=128, train_wall=19, gb_free=11.7, wall=38459
2023-05-26 10:04:23 - progress_bar.py[line:272] - INFO: epoch 012:   1462 / 1732 loss=2.244, loss_v1=0, loss_v2=0, nll_loss=1.027, ntokens=1170.3, nsentences=32, sample_size=1170.3, sample_size_v1=0, sample_size_v2=0, ppl=2.04, wps=618.1, ups=0.53, wpb=1170.3, bsz=32, num_updates=20480, lr=1.93354e-05, gnorm=3.307, clip=100, loss_scale=128, train_wall=19, gb_free=10.6, wall=38478
2023-05-26 10:04:42 - progress_bar.py[line:272] - INFO: epoch 012:   1472 / 1732 loss=2.246, loss_v1=0, loss_v2=0, nll_loss=1.033, ntokens=1139, nsentences=32, sample_size=1139, sample_size_v1=0, sample_size_v2=0, ppl=2.05, wps=602.8, ups=0.53, wpb=1139, bsz=32, num_updates=20490, lr=1.93293e-05, gnorm=3.672, clip=100, loss_scale=128, train_wall=19, gb_free=11.7, wall=38497
2023-05-26 10:05:01 - progress_bar.py[line:272] - INFO: epoch 012:   1482 / 1732 loss=2.288, loss_v1=0, loss_v2=0, nll_loss=1.079, ntokens=1051.3, nsentences=32, sample_size=1051.3, sample_size_v1=0, sample_size_v2=0, ppl=2.11, wps=559.1, ups=0.53, wpb=1051.3, bsz=32, num_updates=20500, lr=1.93231e-05, gnorm=3.815, clip=100, loss_scale=128, train_wall=19, gb_free=10.6, wall=38516
2023-05-26 10:05:20 - progress_bar.py[line:272] - INFO: epoch 012:   1492 / 1732 loss=2.259, loss_v1=0, loss_v2=0, nll_loss=1.045, ntokens=1143, nsentences=32, sample_size=1143, sample_size_v1=0, sample_size_v2=0, ppl=2.06, wps=604.6, ups=0.53, wpb=1143, bsz=32, num_updates=20510, lr=1.9317e-05, gnorm=3.484, clip=100, loss_scale=128, train_wall=19, gb_free=11.5, wall=38535
2023-05-26 10:05:39 - progress_bar.py[line:272] - INFO: epoch 012:   1502 / 1732 loss=2.222, loss_v1=0, loss_v2=0, nll_loss=1.004, ntokens=1131.9, nsentences=32, sample_size=1131.9, sample_size_v1=0, sample_size_v2=0, ppl=2.01, wps=597.4, ups=0.53, wpb=1131.9, bsz=32, num_updates=20520, lr=1.93109e-05, gnorm=3.563, clip=100, loss_scale=128, train_wall=19, gb_free=10.3, wall=38554
2023-05-26 10:05:58 - progress_bar.py[line:272] - INFO: epoch 012:   1512 / 1732 loss=2.254, loss_v1=0, loss_v2=0, nll_loss=1.041, ntokens=1058.6, nsentences=32, sample_size=1058.6, sample_size_v1=0, sample_size_v2=0, ppl=2.06, wps=564.9, ups=0.53, wpb=1058.6, bsz=32, num_updates=20530, lr=1.93047e-05, gnorm=3.723, clip=100, loss_scale=128, train_wall=19, gb_free=10.8, wall=38572
2023-05-26 10:06:16 - progress_bar.py[line:272] - INFO: epoch 012:   1522 / 1732 loss=2.285, loss_v1=0, loss_v2=0, nll_loss=1.074, ntokens=1011, nsentences=32, sample_size=1011, sample_size_v1=0, sample_size_v2=0, ppl=2.11, wps=541.2, ups=0.54, wpb=1011, bsz=32, num_updates=20540, lr=1.92986e-05, gnorm=3.957, clip=100, loss_scale=128, train_wall=19, gb_free=11.8, wall=38591
2023-05-26 10:06:35 - progress_bar.py[line:272] - INFO: epoch 012:   1532 / 1732 loss=2.279, loss_v1=0, loss_v2=0, nll_loss=1.068, ntokens=1075.4, nsentences=32, sample_size=1075.4, sample_size_v1=0, sample_size_v2=0, ppl=2.1, wps=568.5, ups=0.53, wpb=1075.4, bsz=32, num_updates=20550, lr=1.92924e-05, gnorm=3.697, clip=100, loss_scale=128, train_wall=19, gb_free=10.7, wall=38610
2023-05-26 10:06:54 - progress_bar.py[line:272] - INFO: epoch 012:   1542 / 1732 loss=2.248, loss_v1=0, loss_v2=0, nll_loss=1.032, ntokens=1113.4, nsentences=32, sample_size=1113.4, sample_size_v1=0, sample_size_v2=0, ppl=2.04, wps=589.9, ups=0.53, wpb=1113.4, bsz=32, num_updates=20560, lr=1.92863e-05, gnorm=3.727, clip=100, loss_scale=128, train_wall=19, gb_free=11, wall=38629
2023-05-26 10:07:13 - progress_bar.py[line:272] - INFO: epoch 012:   1552 / 1732 loss=2.237, loss_v1=0, loss_v2=0, nll_loss=1.021, ntokens=1059, nsentences=32, sample_size=1059, sample_size_v1=0, sample_size_v2=0, ppl=2.03, wps=564.1, ups=0.53, wpb=1059, bsz=32, num_updates=20570, lr=1.92801e-05, gnorm=3.654, clip=100, loss_scale=128, train_wall=19, gb_free=11.3, wall=38648
2023-05-26 10:07:32 - progress_bar.py[line:272] - INFO: epoch 012:   1562 / 1732 loss=2.255, loss_v1=0, loss_v2=0, nll_loss=1.042, ntokens=1107.4, nsentences=32, sample_size=1107.4, sample_size_v1=0, sample_size_v2=0, ppl=2.06, wps=588.1, ups=0.53, wpb=1107.4, bsz=32, num_updates=20580, lr=1.9274e-05, gnorm=3.269, clip=100, loss_scale=128, train_wall=19, gb_free=11.2, wall=38666
2023-05-26 10:07:51 - progress_bar.py[line:272] - INFO: epoch 012:   1572 / 1732 loss=2.272, loss_v1=0, loss_v2=0, nll_loss=1.06, ntokens=1068.7, nsentences=32, sample_size=1068.7, sample_size_v1=0, sample_size_v2=0, ppl=2.08, wps=567.9, ups=0.53, wpb=1068.7, bsz=32, num_updates=20590, lr=1.92679e-05, gnorm=3.715, clip=100, loss_scale=128, train_wall=19, gb_free=11.6, wall=38685
2023-05-26 10:08:09 - progress_bar.py[line:272] - INFO: epoch 012:   1582 / 1732 loss=2.297, loss_v1=0, loss_v2=0, nll_loss=1.088, ntokens=1012.7, nsentences=32, sample_size=1012.7, sample_size_v1=0, sample_size_v2=0, ppl=2.13, wps=537.9, ups=0.53, wpb=1012.7, bsz=32, num_updates=20600, lr=1.92617e-05, gnorm=4.032, clip=100, loss_scale=128, train_wall=19, gb_free=10.6, wall=38704
2023-05-26 10:08:28 - progress_bar.py[line:272] - INFO: epoch 012:   1592 / 1732 loss=2.241, loss_v1=0, loss_v2=0, nll_loss=1.025, ntokens=1072.6, nsentences=32, sample_size=1072.6, sample_size_v1=0, sample_size_v2=0, ppl=2.04, wps=569.1, ups=0.53, wpb=1072.6, bsz=32, num_updates=20610, lr=1.92556e-05, gnorm=3.684, clip=100, loss_scale=128, train_wall=19, gb_free=11.6, wall=38723
2023-05-26 10:08:47 - progress_bar.py[line:272] - INFO: epoch 012:   1602 / 1732 loss=2.227, loss_v1=0, loss_v2=0, nll_loss=1.01, ntokens=1101.7, nsentences=32, sample_size=1101.7, sample_size_v1=0, sample_size_v2=0, ppl=2.01, wps=585.6, ups=0.53, wpb=1101.7, bsz=32, num_updates=20620, lr=1.92494e-05, gnorm=3.268, clip=100, loss_scale=128, train_wall=19, gb_free=10.5, wall=38742
2023-05-26 10:09:06 - progress_bar.py[line:272] - INFO: epoch 012:   1612 / 1732 loss=2.238, loss_v1=0, loss_v2=0, nll_loss=1.021, ntokens=1156, nsentences=32, sample_size=1156, sample_size_v1=0, sample_size_v2=0, ppl=2.03, wps=610.5, ups=0.53, wpb=1156, bsz=32, num_updates=20630, lr=1.92433e-05, gnorm=3.446, clip=100, loss_scale=128, train_wall=19, gb_free=11.4, wall=38761
2023-05-26 10:09:25 - progress_bar.py[line:272] - INFO: epoch 012:   1622 / 1732 loss=2.242, loss_v1=0, loss_v2=0, nll_loss=1.027, ntokens=1098.4, nsentences=32, sample_size=1098.4, sample_size_v1=0, sample_size_v2=0, ppl=2.04, wps=578.4, ups=0.53, wpb=1098.4, bsz=32, num_updates=20640, lr=1.92371e-05, gnorm=3.768, clip=100, loss_scale=128, train_wall=19, gb_free=11.5, wall=38780
2023-05-26 10:09:44 - progress_bar.py[line:272] - INFO: epoch 012:   1632 / 1732 loss=2.243, loss_v1=0, loss_v2=0, nll_loss=1.027, ntokens=1161.4, nsentences=32, sample_size=1161.4, sample_size_v1=0, sample_size_v2=0, ppl=2.04, wps=614.9, ups=0.53, wpb=1161.4, bsz=32, num_updates=20650, lr=1.9231e-05, gnorm=3.471, clip=100, loss_scale=128, train_wall=19, gb_free=11.6, wall=38799
2023-05-26 10:10:03 - progress_bar.py[line:272] - INFO: epoch 012:   1642 / 1732 loss=2.228, loss_v1=0, loss_v2=0, nll_loss=1.011, ntokens=1223.1, nsentences=32, sample_size=1223.1, sample_size_v1=0, sample_size_v2=0, ppl=2.02, wps=645.2, ups=0.53, wpb=1223.1, bsz=32, num_updates=20660, lr=1.92249e-05, gnorm=3.308, clip=100, loss_scale=128, train_wall=19, gb_free=10.9, wall=38818
2023-05-26 10:10:22 - progress_bar.py[line:272] - INFO: epoch 012:   1652 / 1732 loss=2.25, loss_v1=0, loss_v2=0, nll_loss=1.035, ntokens=1045.5, nsentences=32, sample_size=1045.5, sample_size_v1=0, sample_size_v2=0, ppl=2.05, wps=557.7, ups=0.53, wpb=1045.5, bsz=32, num_updates=20670, lr=1.92187e-05, gnorm=3.863, clip=100, loss_scale=128, train_wall=19, gb_free=11.2, wall=38836
2023-05-26 10:10:41 - progress_bar.py[line:272] - INFO: epoch 012:   1662 / 1732 loss=2.281, loss_v1=0, loss_v2=0, nll_loss=1.071, ntokens=1037.9, nsentences=32, sample_size=1037.9, sample_size_v1=0, sample_size_v2=0, ppl=2.1, wps=551.4, ups=0.53, wpb=1037.9, bsz=32, num_updates=20680, lr=1.92126e-05, gnorm=3.801, clip=100, loss_scale=128, train_wall=19, gb_free=11.4, wall=38855
2023-05-26 10:10:59 - progress_bar.py[line:272] - INFO: epoch 012:   1672 / 1732 loss=2.252, loss_v1=0, loss_v2=0, nll_loss=1.036, ntokens=1009.9, nsentences=32, sample_size=1009.9, sample_size_v1=0, sample_size_v2=0, ppl=2.05, wps=541, ups=0.54, wpb=1009.9, bsz=32, num_updates=20690, lr=1.92064e-05, gnorm=3.898, clip=100, loss_scale=128, train_wall=19, gb_free=10.9, wall=38874
2023-05-26 10:11:18 - progress_bar.py[line:272] - INFO: epoch 012:   1682 / 1732 loss=2.22, loss_v1=0, loss_v2=0, nll_loss=1, ntokens=1181.4, nsentences=32, sample_size=1181.4, sample_size_v1=0, sample_size_v2=0, ppl=2, wps=620.3, ups=0.53, wpb=1181.4, bsz=32, num_updates=20700, lr=1.92003e-05, gnorm=3.428, clip=100, loss_scale=128, train_wall=19, gb_free=11.3, wall=38893
2023-05-26 10:11:37 - progress_bar.py[line:272] - INFO: epoch 012:   1692 / 1732 loss=2.22, loss_v1=0, loss_v2=0, nll_loss=1.003, ntokens=1233.5, nsentences=32, sample_size=1233.5, sample_size_v1=0, sample_size_v2=0, ppl=2, wps=643, ups=0.52, wpb=1233.5, bsz=32, num_updates=20710, lr=1.91942e-05, gnorm=3.175, clip=100, loss_scale=128, train_wall=19, gb_free=10.8, wall=38912
2023-05-26 10:11:57 - progress_bar.py[line:272] - INFO: epoch 012:   1702 / 1732 loss=2.245, loss_v1=0, loss_v2=0, nll_loss=1.029, ntokens=1273, nsentences=32, sample_size=1273, sample_size_v1=0, sample_size_v2=0, ppl=2.04, wps=665.5, ups=0.52, wpb=1273, bsz=32, num_updates=20720, lr=1.9188e-05, gnorm=3.189, clip=100, loss_scale=128, train_wall=19, gb_free=10.7, wall=38931
2023-05-26 10:12:15 - progress_bar.py[line:272] - INFO: epoch 012:   1712 / 1732 loss=2.263, loss_v1=0, loss_v2=0, nll_loss=1.049, ntokens=1144.5, nsentences=32, sample_size=1144.5, sample_size_v1=0, sample_size_v2=0, ppl=2.07, wps=605.8, ups=0.53, wpb=1144.5, bsz=32, num_updates=20730, lr=1.91819e-05, gnorm=3.427, clip=100, loss_scale=128, train_wall=19, gb_free=11.4, wall=38950
2023-05-26 10:12:34 - progress_bar.py[line:272] - INFO: epoch 012:   1722 / 1732 loss=2.236, loss_v1=0, loss_v2=0, nll_loss=1.021, ntokens=1176.1, nsentences=32, sample_size=1176.1, sample_size_v1=0, sample_size_v2=0, ppl=2.03, wps=617.1, ups=0.52, wpb=1176.1, bsz=32, num_updates=20740, lr=1.91757e-05, gnorm=3.369, clip=100, loss_scale=128, train_wall=19, gb_free=11.3, wall=38969
2023-05-26 10:12:52 - progress_bar.py[line:272] - INFO: epoch 012:   1732 / 1732 loss=2.282, loss_v1=0, loss_v2=0, nll_loss=1.071, ntokens=1056.7, nsentences=29.6, sample_size=1056.7, sample_size_v1=0, sample_size_v2=0, ppl=2.1, wps=602.4, ups=0.57, wpb=1056.7, bsz=29.6, num_updates=20750, lr=1.91696e-05, gnorm=3.507, clip=100, loss_scale=128, train_wall=18, gb_free=11.7, wall=38987
2023-05-26 10:12:52 - checkpoint_utils.py[line:64] - INFO: Preparing to save checkpoint for epoch 12 @ 20750 updates
2023-05-26 10:12:52 - trainer.py[line:431] - INFO: Saving checkpoint to ../../checkpoints/OFA/sgcls_checkpoints/_30_3e-5_512_base_nosrcbbox/checkpoint12.pt
2023-05-26 10:12:55 - trainer.py[line:441] - INFO: Finished saving checkpoint to ../../checkpoints/OFA/sgcls_checkpoints/_30_3e-5_512_base_nosrcbbox/checkpoint12.pt
2023-05-26 10:12:59 - checkpoint_utils.py[line:133] - INFO: Saved checkpoint ../../checkpoints/OFA/sgcls_checkpoints/_30_3e-5_512_base_nosrcbbox/checkpoint12.pt (epoch 12 @ 20750 updates, score None) (writing took 7.204519636929035 seconds)
2023-05-26 10:12:59 - train.py[line:332] - INFO: end of epoch 12 (average epoch stats below)
2023-05-26 10:12:59 - progress_bar.py[line:282] - INFO: epoch 012 | loss 2.266 | loss_v1 0 | loss_v2 0 | nll_loss 1.054 | ntokens 1051.69 | nsentences 31.986 | sample_size 1051.69 | sample_size_v1 0 | sample_size_v2 0 | ppl 2.08 | wps 558.7 | ups 0.53 | wpb 1051.7 | bsz 32 | num_updates 20750 | lr 1.91696e-05 | gnorm 3.518 | clip 100 | loss_scale 128 | train_wall 3240 | gb_free 11.7 | wall 38994
2023-05-26 10:12:59 - trainer.py[line:639] - INFO: loading train data for epoch 13
local datafile ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 0 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 0 finished initializing row_count and line_idx-to-offset mapping
file ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 0 row count 55400 total row count 55400
slice_id 0 seek offset 0
2023-05-26 10:13:01 - trainer.py[line:703] - INFO: begin training epoch 13
2023-05-26 10:13:01 - train.py[line:305] - INFO: Start iterating over samples
2023-05-26 10:13:21 - progress_bar.py[line:272] - INFO: epoch 013:     10 / 1732 loss=2.226, loss_v1=0, loss_v2=0, nll_loss=1.007, ntokens=1132.5, nsentences=32, sample_size=1132.5, sample_size_v1=0, sample_size_v2=0, ppl=2.01, wps=397.5, ups=0.35, wpb=1132.5, bsz=32, num_updates=20760, lr=1.91634e-05, gnorm=3.682, clip=100, loss_scale=128, train_wall=19, gb_free=10.2, wall=39015
2023-05-26 10:13:39 - progress_bar.py[line:272] - INFO: epoch 013:     20 / 1732 loss=2.156, loss_v1=0, loss_v2=0, nll_loss=0.933, ntokens=1079.2, nsentences=32, sample_size=1079.2, sample_size_v1=0, sample_size_v2=0, ppl=1.91, wps=573.1, ups=0.53, wpb=1079.2, bsz=32, num_updates=20770, lr=1.91573e-05, gnorm=3.698, clip=100, loss_scale=128, train_wall=19, gb_free=11.4, wall=39034
2023-05-26 10:13:58 - progress_bar.py[line:272] - INFO: epoch 013:     30 / 1732 loss=2.191, loss_v1=0, loss_v2=0, nll_loss=0.97, ntokens=962.6, nsentences=32, sample_size=962.6, sample_size_v1=0, sample_size_v2=0, ppl=1.96, wps=512.4, ups=0.53, wpb=962.6, bsz=32, num_updates=20780, lr=1.91512e-05, gnorm=3.826, clip=100, loss_scale=128, train_wall=19, gb_free=11.3, wall=39053
2023-05-26 10:14:17 - progress_bar.py[line:272] - INFO: epoch 013:     40 / 1732 loss=2.057, loss_v1=0, loss_v2=0, nll_loss=0.819, ntokens=1211.6, nsentences=32, sample_size=1211.6, sample_size_v1=0, sample_size_v2=0, ppl=1.76, wps=633.8, ups=0.52, wpb=1211.6, bsz=32, num_updates=20790, lr=1.9145e-05, gnorm=2.936, clip=100, loss_scale=128, train_wall=19, gb_free=11.3, wall=39072
2023-05-26 10:14:36 - progress_bar.py[line:272] - INFO: epoch 013:     50 / 1732 loss=2.132, loss_v1=0, loss_v2=0, nll_loss=0.907, ntokens=1054.8, nsentences=32, sample_size=1054.8, sample_size_v1=0, sample_size_v2=0, ppl=1.88, wps=559.1, ups=0.53, wpb=1054.8, bsz=32, num_updates=20800, lr=1.91389e-05, gnorm=3.31, clip=100, loss_scale=128, train_wall=19, gb_free=11.1, wall=39091
2023-05-26 10:14:55 - progress_bar.py[line:272] - INFO: epoch 013:     60 / 1732 loss=1.974, loss_v1=0, loss_v2=0, nll_loss=0.728, ntokens=1049.9, nsentences=32, sample_size=1049.9, sample_size_v1=0, sample_size_v2=0, ppl=1.66, wps=561.9, ups=0.54, wpb=1049.9, bsz=32, num_updates=20810, lr=1.91327e-05, gnorm=3.141, clip=100, loss_scale=128, train_wall=19, gb_free=10.3, wall=39109
2023-05-26 10:15:14 - progress_bar.py[line:272] - INFO: epoch 013:     70 / 1732 loss=2, loss_v1=0, loss_v2=0, nll_loss=0.758, ntokens=1412, nsentences=32, sample_size=1412, sample_size_v1=0, sample_size_v2=0, ppl=1.69, wps=723.2, ups=0.51, wpb=1412, bsz=32, num_updates=20820, lr=1.91266e-05, gnorm=2.339, clip=100, loss_scale=128, train_wall=19, gb_free=10.8, wall=39129
2023-05-26 10:15:34 - progress_bar.py[line:272] - INFO: epoch 013:     80 / 1732 loss=2.043, loss_v1=0, loss_v2=0, nll_loss=0.803, ntokens=1259.9, nsentences=32, sample_size=1259.9, sample_size_v1=0, sample_size_v2=0, ppl=1.75, wps=648.5, ups=0.51, wpb=1259.9, bsz=32, num_updates=20830, lr=1.91204e-05, gnorm=2.939, clip=100, loss_scale=128, train_wall=19, gb_free=10.6, wall=39148
2023-05-26 10:15:53 - progress_bar.py[line:272] - INFO: epoch 013:     90 / 1732 loss=2.134, loss_v1=0, loss_v2=0, nll_loss=0.905, ntokens=1086.9, nsentences=32, sample_size=1086.9, sample_size_v1=0, sample_size_v2=0, ppl=1.87, wps=568.8, ups=0.52, wpb=1086.9, bsz=32, num_updates=20840, lr=1.91143e-05, gnorm=3.497, clip=100, loss_scale=128, train_wall=19, gb_free=11, wall=39168
2023-05-26 10:16:12 - progress_bar.py[line:272] - INFO: epoch 013:    100 / 1732 loss=2.119, loss_v1=0, loss_v2=0, nll_loss=0.893, ntokens=1024.5, nsentences=32, sample_size=1024.5, sample_size_v1=0, sample_size_v2=0, ppl=1.86, wps=546.1, ups=0.53, wpb=1024.5, bsz=32, num_updates=20850, lr=1.91082e-05, gnorm=3.278, clip=100, loss_scale=128, train_wall=19, gb_free=10.9, wall=39186
2023-05-26 10:16:30 - progress_bar.py[line:272] - INFO: epoch 013:    110 / 1732 loss=2.263, loss_v1=0, loss_v2=0, nll_loss=1.051, ntokens=1011.2, nsentences=32, sample_size=1011.2, sample_size_v1=0, sample_size_v2=0, ppl=2.07, wps=538.2, ups=0.53, wpb=1011.2, bsz=32, num_updates=20860, lr=1.9102e-05, gnorm=3.684, clip=100, loss_scale=128, train_wall=19, gb_free=11, wall=39205
2023-05-26 10:16:50 - progress_bar.py[line:272] - INFO: epoch 013:    120 / 1732 loss=2.25, loss_v1=0, loss_v2=0, nll_loss=1.035, ntokens=1124.3, nsentences=32, sample_size=1124.3, sample_size_v1=0, sample_size_v2=0, ppl=2.05, wps=587.5, ups=0.52, wpb=1124.3, bsz=32, num_updates=20870, lr=1.90959e-05, gnorm=3.548, clip=100, loss_scale=128, train_wall=19, gb_free=10.6, wall=39224
2023-05-26 10:17:09 - progress_bar.py[line:272] - INFO: epoch 013:    130 / 1732 loss=2.225, loss_v1=0, loss_v2=0, nll_loss=1.007, ntokens=1171.7, nsentences=32, sample_size=1171.7, sample_size_v1=0, sample_size_v2=0, ppl=2.01, wps=608.6, ups=0.52, wpb=1171.7, bsz=32, num_updates=20880, lr=1.90897e-05, gnorm=3.28, clip=100, loss_scale=128, train_wall=19, gb_free=10.2, wall=39244
2023-05-26 10:17:28 - progress_bar.py[line:272] - INFO: epoch 013:    140 / 1732 loss=2.195, loss_v1=0, loss_v2=0, nll_loss=0.973, ntokens=1245, nsentences=32, sample_size=1245, sample_size_v1=0, sample_size_v2=0, ppl=1.96, wps=650.3, ups=0.52, wpb=1245, bsz=32, num_updates=20890, lr=1.90836e-05, gnorm=3.429, clip=100, loss_scale=128, train_wall=19, gb_free=10.2, wall=39263
2023-05-26 10:17:47 - progress_bar.py[line:272] - INFO: epoch 013:    150 / 1732 loss=2.164, loss_v1=0, loss_v2=0, nll_loss=0.942, ntokens=1172.1, nsentences=32, sample_size=1172.1, sample_size_v1=0, sample_size_v2=0, ppl=1.92, wps=609.1, ups=0.52, wpb=1172.1, bsz=32, num_updates=20900, lr=1.90775e-05, gnorm=3.269, clip=100, loss_scale=256, train_wall=19, gb_free=11, wall=39282
2023-05-26 10:18:03 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 128.0
2023-05-26 10:18:08 - progress_bar.py[line:272] - INFO: epoch 013:    161 / 1732 loss=2.201, loss_v1=0, loss_v2=0, nll_loss=0.98, ntokens=1127.7, nsentences=32, sample_size=1127.7, sample_size_v1=0, sample_size_v2=0, ppl=1.97, wps=538, ups=0.48, wpb=1127.7, bsz=32, num_updates=20910, lr=1.90713e-05, gnorm=3.399, clip=100, loss_scale=128, train_wall=21, gb_free=11.3, wall=39303
2023-05-26 10:18:27 - progress_bar.py[line:272] - INFO: epoch 013:    171 / 1732 loss=2.202, loss_v1=0, loss_v2=0, nll_loss=0.981, ntokens=969.4, nsentences=32, sample_size=969.4, sample_size_v1=0, sample_size_v2=0, ppl=1.97, wps=513.9, ups=0.53, wpb=969.4, bsz=32, num_updates=20920, lr=1.90652e-05, gnorm=4.047, clip=100, loss_scale=128, train_wall=19, gb_free=11.3, wall=39322
2023-05-26 10:18:46 - progress_bar.py[line:272] - INFO: epoch 013:    181 / 1732 loss=2.16, loss_v1=0, loss_v2=0, nll_loss=0.936, ntokens=1122.2, nsentences=32, sample_size=1122.2, sample_size_v1=0, sample_size_v2=0, ppl=1.91, wps=589.5, ups=0.53, wpb=1122.2, bsz=32, num_updates=20930, lr=1.9059e-05, gnorm=3.501, clip=100, loss_scale=128, train_wall=19, gb_free=11.1, wall=39341
2023-05-26 10:19:05 - progress_bar.py[line:272] - INFO: epoch 013:    191 / 1732 loss=2.165, loss_v1=0, loss_v2=0, nll_loss=0.94, ntokens=1130.1, nsentences=32, sample_size=1130.1, sample_size_v1=0, sample_size_v2=0, ppl=1.92, wps=586.9, ups=0.52, wpb=1130.1, bsz=32, num_updates=20940, lr=1.90529e-05, gnorm=3.455, clip=100, loss_scale=128, train_wall=19, gb_free=10.9, wall=39360
2023-05-26 10:19:24 - progress_bar.py[line:272] - INFO: epoch 013:    201 / 1732 loss=2.231, loss_v1=0, loss_v2=0, nll_loss=1.014, ntokens=1092.1, nsentences=32, sample_size=1092.1, sample_size_v1=0, sample_size_v2=0, ppl=2.02, wps=580.4, ups=0.53, wpb=1092.1, bsz=32, num_updates=20950, lr=1.90467e-05, gnorm=3.722, clip=100, loss_scale=128, train_wall=19, gb_free=11.3, wall=39379
2023-05-26 10:19:43 - progress_bar.py[line:272] - INFO: epoch 013:    211 / 1732 loss=2.288, loss_v1=0, loss_v2=0, nll_loss=1.079, ntokens=1010.6, nsentences=32, sample_size=1010.6, sample_size_v1=0, sample_size_v2=0, ppl=2.11, wps=540.3, ups=0.53, wpb=1010.6, bsz=32, num_updates=20960, lr=1.90406e-05, gnorm=3.799, clip=100, loss_scale=128, train_wall=19, gb_free=11, wall=39398
2023-05-26 10:20:02 - progress_bar.py[line:272] - INFO: epoch 013:    221 / 1732 loss=2.278, loss_v1=0, loss_v2=0, nll_loss=1.065, ntokens=1140.8, nsentences=32, sample_size=1140.8, sample_size_v1=0, sample_size_v2=0, ppl=2.09, wps=610.1, ups=0.53, wpb=1140.8, bsz=32, num_updates=20970, lr=1.90345e-05, gnorm=3.679, clip=100, loss_scale=128, train_wall=19, gb_free=10.6, wall=39416
2023-05-26 10:20:20 - progress_bar.py[line:272] - INFO: epoch 013:    231 / 1732 loss=2.285, loss_v1=0, loss_v2=0, nll_loss=1.074, ntokens=1093.8, nsentences=32, sample_size=1093.8, sample_size_v1=0, sample_size_v2=0, ppl=2.1, wps=585.7, ups=0.54, wpb=1093.8, bsz=32, num_updates=20980, lr=1.90283e-05, gnorm=3.428, clip=100, loss_scale=128, train_wall=19, gb_free=11.6, wall=39435
2023-05-26 10:20:39 - progress_bar.py[line:272] - INFO: epoch 013:    241 / 1732 loss=2.305, loss_v1=0, loss_v2=0, nll_loss=1.097, ntokens=1114.7, nsentences=32, sample_size=1114.7, sample_size_v1=0, sample_size_v2=0, ppl=2.14, wps=593.4, ups=0.53, wpb=1114.7, bsz=32, num_updates=20990, lr=1.90222e-05, gnorm=3.739, clip=100, loss_scale=128, train_wall=19, gb_free=11.6, wall=39454
2023-05-26 10:20:58 - progress_bar.py[line:272] - INFO: epoch 013:    251 / 1732 loss=2.277, loss_v1=0, loss_v2=0, nll_loss=1.068, ntokens=1172.1, nsentences=32, sample_size=1172.1, sample_size_v1=0, sample_size_v2=0, ppl=2.1, wps=621.8, ups=0.53, wpb=1172.1, bsz=32, num_updates=21000, lr=1.9016e-05, gnorm=3.578, clip=100, loss_scale=128, train_wall=19, gb_free=11.6, wall=39473
2023-05-26 10:21:17 - progress_bar.py[line:272] - INFO: epoch 013:    261 / 1732 loss=2.303, loss_v1=0, loss_v2=0, nll_loss=1.094, ntokens=1139.9, nsentences=32, sample_size=1139.9, sample_size_v1=0, sample_size_v2=0, ppl=2.13, wps=610.3, ups=0.54, wpb=1139.9, bsz=32, num_updates=21010, lr=1.90099e-05, gnorm=3.661, clip=100, loss_scale=128, train_wall=19, gb_free=11.1, wall=39491
2023-05-26 10:21:35 - progress_bar.py[line:272] - INFO: epoch 013:    271 / 1732 loss=2.27, loss_v1=0, loss_v2=0, nll_loss=1.057, ntokens=1145.3, nsentences=32, sample_size=1145.3, sample_size_v1=0, sample_size_v2=0, ppl=2.08, wps=608.3, ups=0.53, wpb=1145.3, bsz=32, num_updates=21020, lr=1.90037e-05, gnorm=3.452, clip=100, loss_scale=128, train_wall=19, gb_free=11.2, wall=39510
2023-05-26 10:21:54 - progress_bar.py[line:272] - INFO: epoch 013:    281 / 1732 loss=2.301, loss_v1=0, loss_v2=0, nll_loss=1.091, ntokens=1149.7, nsentences=32, sample_size=1149.7, sample_size_v1=0, sample_size_v2=0, ppl=2.13, wps=610.6, ups=0.53, wpb=1149.7, bsz=32, num_updates=21030, lr=1.89976e-05, gnorm=3.62, clip=100, loss_scale=128, train_wall=19, gb_free=11.7, wall=39529
2023-05-26 10:22:13 - progress_bar.py[line:272] - INFO: epoch 013:    291 / 1732 loss=2.258, loss_v1=0, loss_v2=0, nll_loss=1.046, ntokens=1130.5, nsentences=32, sample_size=1130.5, sample_size_v1=0, sample_size_v2=0, ppl=2.06, wps=602.5, ups=0.53, wpb=1130.5, bsz=32, num_updates=21040, lr=1.89915e-05, gnorm=3.473, clip=100, loss_scale=128, train_wall=19, gb_free=11.3, wall=39548
2023-05-26 10:22:32 - progress_bar.py[line:272] - INFO: epoch 013:    301 / 1732 loss=2.275, loss_v1=0, loss_v2=0, nll_loss=1.064, ntokens=1109.1, nsentences=32, sample_size=1109.1, sample_size_v1=0, sample_size_v2=0, ppl=2.09, wps=591.2, ups=0.53, wpb=1109.1, bsz=32, num_updates=21050, lr=1.89853e-05, gnorm=3.902, clip=100, loss_scale=128, train_wall=19, gb_free=11.5, wall=39566
2023-05-26 10:22:50 - progress_bar.py[line:272] - INFO: epoch 013:    311 / 1732 loss=2.265, loss_v1=0, loss_v2=0, nll_loss=1.052, ntokens=1067.3, nsentences=32, sample_size=1067.3, sample_size_v1=0, sample_size_v2=0, ppl=2.07, wps=571.2, ups=0.54, wpb=1067.3, bsz=32, num_updates=21060, lr=1.89792e-05, gnorm=3.948, clip=100, loss_scale=128, train_wall=19, gb_free=11.5, wall=39585
2023-05-26 10:23:09 - progress_bar.py[line:272] - INFO: epoch 013:    321 / 1732 loss=2.31, loss_v1=0, loss_v2=0, nll_loss=1.102, ntokens=1001.7, nsentences=32, sample_size=1001.7, sample_size_v1=0, sample_size_v2=0, ppl=2.15, wps=540.7, ups=0.54, wpb=1001.7, bsz=32, num_updates=21070, lr=1.8973e-05, gnorm=4.02, clip=100, loss_scale=128, train_wall=18, gb_free=11.8, wall=39604
2023-05-26 10:23:28 - progress_bar.py[line:272] - INFO: epoch 013:    331 / 1732 loss=2.31, loss_v1=0, loss_v2=0, nll_loss=1.103, ntokens=1019.4, nsentences=32, sample_size=1019.4, sample_size_v1=0, sample_size_v2=0, ppl=2.15, wps=549.2, ups=0.54, wpb=1019.4, bsz=32, num_updates=21080, lr=1.89669e-05, gnorm=4.027, clip=100, loss_scale=128, train_wall=19, gb_free=11.9, wall=39622
2023-05-26 10:23:46 - progress_bar.py[line:272] - INFO: epoch 013:    341 / 1732 loss=2.263, loss_v1=0, loss_v2=0, nll_loss=1.05, ntokens=952.2, nsentences=32, sample_size=952.2, sample_size_v1=0, sample_size_v2=0, ppl=2.07, wps=514.8, ups=0.54, wpb=952.2, bsz=32, num_updates=21090, lr=1.89608e-05, gnorm=4.356, clip=100, loss_scale=128, train_wall=18, gb_free=11.4, wall=39641
2023-05-26 10:24:05 - progress_bar.py[line:272] - INFO: epoch 013:    351 / 1732 loss=2.292, loss_v1=0, loss_v2=0, nll_loss=1.082, ntokens=941.5, nsentences=32, sample_size=941.5, sample_size_v1=0, sample_size_v2=0, ppl=2.12, wps=508.9, ups=0.54, wpb=941.5, bsz=32, num_updates=21100, lr=1.89546e-05, gnorm=4.2, clip=100, loss_scale=128, train_wall=18, gb_free=11.5, wall=39659
2023-05-26 10:24:23 - progress_bar.py[line:272] - INFO: epoch 013:    361 / 1732 loss=2.314, loss_v1=0, loss_v2=0, nll_loss=1.107, ntokens=925.7, nsentences=32, sample_size=925.7, sample_size_v1=0, sample_size_v2=0, ppl=2.15, wps=500.1, ups=0.54, wpb=925.7, bsz=32, num_updates=21110, lr=1.89485e-05, gnorm=4.436, clip=100, loss_scale=128, train_wall=18, gb_free=11.5, wall=39678
2023-05-26 10:24:42 - progress_bar.py[line:272] - INFO: epoch 013:    371 / 1732 loss=2.31, loss_v1=0, loss_v2=0, nll_loss=1.1, ntokens=989.1, nsentences=32, sample_size=989.1, sample_size_v1=0, sample_size_v2=0, ppl=2.14, wps=533.6, ups=0.54, wpb=989.1, bsz=32, num_updates=21120, lr=1.89423e-05, gnorm=4.311, clip=100, loss_scale=128, train_wall=19, gb_free=11, wall=39696
2023-05-26 10:25:00 - progress_bar.py[line:272] - INFO: epoch 013:    381 / 1732 loss=2.317, loss_v1=0, loss_v2=0, nll_loss=1.11, ntokens=1071.8, nsentences=32, sample_size=1071.8, sample_size_v1=0, sample_size_v2=0, ppl=2.16, wps=579, ups=0.54, wpb=1071.8, bsz=32, num_updates=21130, lr=1.89362e-05, gnorm=3.996, clip=100, loss_scale=128, train_wall=18, gb_free=11.3, wall=39715
2023-05-26 10:25:19 - progress_bar.py[line:272] - INFO: epoch 013:    391 / 1732 loss=2.291, loss_v1=0, loss_v2=0, nll_loss=1.082, ntokens=986, nsentences=32, sample_size=986, sample_size_v1=0, sample_size_v2=0, ppl=2.12, wps=531.4, ups=0.54, wpb=986, bsz=32, num_updates=21140, lr=1.893e-05, gnorm=4.047, clip=100, loss_scale=128, train_wall=19, gb_free=11.6, wall=39733
2023-05-26 10:25:37 - progress_bar.py[line:272] - INFO: epoch 013:    401 / 1732 loss=2.294, loss_v1=0, loss_v2=0, nll_loss=1.083, ntokens=999.1, nsentences=32, sample_size=999.1, sample_size_v1=0, sample_size_v2=0, ppl=2.12, wps=537.7, ups=0.54, wpb=999.1, bsz=32, num_updates=21150, lr=1.89239e-05, gnorm=4.171, clip=100, loss_scale=128, train_wall=19, gb_free=11.3, wall=39752
2023-05-26 10:25:56 - progress_bar.py[line:272] - INFO: epoch 013:    411 / 1732 loss=2.274, loss_v1=0, loss_v2=0, nll_loss=1.063, ntokens=1079.4, nsentences=32, sample_size=1079.4, sample_size_v1=0, sample_size_v2=0, ppl=2.09, wps=578.9, ups=0.54, wpb=1079.4, bsz=32, num_updates=21160, lr=1.89178e-05, gnorm=3.536, clip=100, loss_scale=128, train_wall=19, gb_free=11.5, wall=39771
2023-05-26 10:26:15 - progress_bar.py[line:272] - INFO: epoch 013:    421 / 1732 loss=2.251, loss_v1=0, loss_v2=0, nll_loss=1.036, ntokens=1019, nsentences=32, sample_size=1019, sample_size_v1=0, sample_size_v2=0, ppl=2.05, wps=547.1, ups=0.54, wpb=1019, bsz=32, num_updates=21170, lr=1.89116e-05, gnorm=3.84, clip=100, loss_scale=128, train_wall=19, gb_free=11.3, wall=39789
2023-05-26 10:26:33 - progress_bar.py[line:272] - INFO: epoch 013:    431 / 1732 loss=2.259, loss_v1=0, loss_v2=0, nll_loss=1.045, ntokens=1019.7, nsentences=32, sample_size=1019.7, sample_size_v1=0, sample_size_v2=0, ppl=2.06, wps=549.2, ups=0.54, wpb=1019.7, bsz=32, num_updates=21180, lr=1.89055e-05, gnorm=3.713, clip=100, loss_scale=128, train_wall=19, gb_free=11.3, wall=39808
2023-05-26 10:26:52 - progress_bar.py[line:272] - INFO: epoch 013:    441 / 1732 loss=2.287, loss_v1=0, loss_v2=0, nll_loss=1.077, ntokens=990.4, nsentences=32, sample_size=990.4, sample_size_v1=0, sample_size_v2=0, ppl=2.11, wps=534.4, ups=0.54, wpb=990.4, bsz=32, num_updates=21190, lr=1.88993e-05, gnorm=3.606, clip=100, loss_scale=128, train_wall=19, gb_free=11.9, wall=39826
2023-05-26 10:27:10 - progress_bar.py[line:272] - INFO: epoch 013:    451 / 1732 loss=2.287, loss_v1=0, loss_v2=0, nll_loss=1.076, ntokens=920.2, nsentences=32, sample_size=920.2, sample_size_v1=0, sample_size_v2=0, ppl=2.11, wps=496.4, ups=0.54, wpb=920.2, bsz=32, num_updates=21200, lr=1.88932e-05, gnorm=3.758, clip=100, loss_scale=128, train_wall=19, gb_free=10.9, wall=39845
2023-05-26 10:27:29 - progress_bar.py[line:272] - INFO: epoch 013:    461 / 1732 loss=2.311, loss_v1=0, loss_v2=0, nll_loss=1.104, ntokens=1038.5, nsentences=32, sample_size=1038.5, sample_size_v1=0, sample_size_v2=0, ppl=2.15, wps=559.1, ups=0.54, wpb=1038.5, bsz=32, num_updates=21210, lr=1.8887e-05, gnorm=4.221, clip=100, loss_scale=128, train_wall=19, gb_free=11.2, wall=39863
2023-05-26 10:27:48 - progress_bar.py[line:272] - INFO: epoch 013:    471 / 1732 loss=2.299, loss_v1=0, loss_v2=0, nll_loss=1.089, ntokens=1039.4, nsentences=32, sample_size=1039.4, sample_size_v1=0, sample_size_v2=0, ppl=2.13, wps=555.8, ups=0.53, wpb=1039.4, bsz=32, num_updates=21220, lr=1.88809e-05, gnorm=3.752, clip=100, loss_scale=128, train_wall=19, gb_free=11.7, wall=39882
2023-05-26 10:28:06 - progress_bar.py[line:272] - INFO: epoch 013:    481 / 1732 loss=2.296, loss_v1=0, loss_v2=0, nll_loss=1.085, ntokens=1025, nsentences=32, sample_size=1025, sample_size_v1=0, sample_size_v2=0, ppl=2.12, wps=550.7, ups=0.54, wpb=1025, bsz=32, num_updates=21230, lr=1.88748e-05, gnorm=4.034, clip=100, loss_scale=128, train_wall=19, gb_free=11.8, wall=39901
2023-05-26 10:28:25 - progress_bar.py[line:272] - INFO: epoch 013:    491 / 1732 loss=2.282, loss_v1=0, loss_v2=0, nll_loss=1.073, ntokens=939.5, nsentences=32, sample_size=939.5, sample_size_v1=0, sample_size_v2=0, ppl=2.1, wps=506.1, ups=0.54, wpb=939.5, bsz=32, num_updates=21240, lr=1.88686e-05, gnorm=3.978, clip=100, loss_scale=128, train_wall=19, gb_free=10.8, wall=39919
2023-05-26 10:28:43 - progress_bar.py[line:272] - INFO: epoch 013:    501 / 1732 loss=2.277, loss_v1=0, loss_v2=0, nll_loss=1.068, ntokens=938, nsentences=32, sample_size=938, sample_size_v1=0, sample_size_v2=0, ppl=2.1, wps=509.1, ups=0.54, wpb=938, bsz=32, num_updates=21250, lr=1.88625e-05, gnorm=4.18, clip=100, loss_scale=128, train_wall=18, gb_free=11.6, wall=39938
2023-05-26 10:29:02 - progress_bar.py[line:272] - INFO: epoch 013:    511 / 1732 loss=2.318, loss_v1=0, loss_v2=0, nll_loss=1.111, ntokens=1040.7, nsentences=32, sample_size=1040.7, sample_size_v1=0, sample_size_v2=0, ppl=2.16, wps=562.1, ups=0.54, wpb=1040.7, bsz=32, num_updates=21260, lr=1.88563e-05, gnorm=4.119, clip=100, loss_scale=128, train_wall=18, gb_free=12, wall=39956
2023-05-26 10:29:20 - progress_bar.py[line:272] - INFO: epoch 013:    521 / 1732 loss=2.257, loss_v1=0, loss_v2=0, nll_loss=1.043, ntokens=1020.1, nsentences=32, sample_size=1020.1, sample_size_v1=0, sample_size_v2=0, ppl=2.06, wps=551.2, ups=0.54, wpb=1020.1, bsz=32, num_updates=21270, lr=1.88502e-05, gnorm=3.848, clip=100, loss_scale=128, train_wall=18, gb_free=11.6, wall=39975
2023-05-26 10:29:39 - progress_bar.py[line:272] - INFO: epoch 013:    531 / 1732 loss=2.292, loss_v1=0, loss_v2=0, nll_loss=1.082, ntokens=931.7, nsentences=32, sample_size=931.7, sample_size_v1=0, sample_size_v2=0, ppl=2.12, wps=504.4, ups=0.54, wpb=931.7, bsz=32, num_updates=21280, lr=1.88441e-05, gnorm=4.227, clip=100, loss_scale=128, train_wall=18, gb_free=11.6, wall=39993
2023-05-26 10:29:57 - progress_bar.py[line:272] - INFO: epoch 013:    541 / 1732 loss=2.287, loss_v1=0, loss_v2=0, nll_loss=1.077, ntokens=994.8, nsentences=32, sample_size=994.8, sample_size_v1=0, sample_size_v2=0, ppl=2.11, wps=539.2, ups=0.54, wpb=994.8, bsz=32, num_updates=21290, lr=1.88379e-05, gnorm=4.019, clip=100, loss_scale=128, train_wall=18, gb_free=12, wall=40012
2023-05-26 10:30:16 - progress_bar.py[line:272] - INFO: epoch 013:    551 / 1732 loss=2.315, loss_v1=0, loss_v2=0, nll_loss=1.108, ntokens=1021.9, nsentences=32, sample_size=1021.9, sample_size_v1=0, sample_size_v2=0, ppl=2.15, wps=548.1, ups=0.54, wpb=1021.9, bsz=32, num_updates=21300, lr=1.88318e-05, gnorm=3.801, clip=100, loss_scale=128, train_wall=19, gb_free=11.3, wall=40030
2023-05-26 10:30:34 - progress_bar.py[line:272] - INFO: epoch 013:    561 / 1732 loss=2.31, loss_v1=0, loss_v2=0, nll_loss=1.102, ntokens=1030.9, nsentences=32, sample_size=1030.9, sample_size_v1=0, sample_size_v2=0, ppl=2.15, wps=554, ups=0.54, wpb=1030.9, bsz=32, num_updates=21310, lr=1.88256e-05, gnorm=4.197, clip=100, loss_scale=128, train_wall=19, gb_free=11.3, wall=40049
2023-05-26 10:30:53 - progress_bar.py[line:272] - INFO: epoch 013:    571 / 1732 loss=2.325, loss_v1=0, loss_v2=0, nll_loss=1.119, ntokens=990.9, nsentences=32, sample_size=990.9, sample_size_v1=0, sample_size_v2=0, ppl=2.17, wps=533, ups=0.54, wpb=990.9, bsz=32, num_updates=21320, lr=1.88195e-05, gnorm=4.255, clip=100, loss_scale=128, train_wall=19, gb_free=11.8, wall=40068
2023-05-26 10:31:12 - progress_bar.py[line:272] - INFO: epoch 013:    581 / 1732 loss=2.293, loss_v1=0, loss_v2=0, nll_loss=1.084, ntokens=1021.6, nsentences=32, sample_size=1021.6, sample_size_v1=0, sample_size_v2=0, ppl=2.12, wps=545.2, ups=0.53, wpb=1021.6, bsz=32, num_updates=21330, lr=1.88133e-05, gnorm=3.96, clip=100, loss_scale=128, train_wall=19, gb_free=10.7, wall=40086
2023-05-26 10:31:30 - progress_bar.py[line:272] - INFO: epoch 013:    591 / 1732 loss=2.285, loss_v1=0, loss_v2=0, nll_loss=1.074, ntokens=934.4, nsentences=32, sample_size=934.4, sample_size_v1=0, sample_size_v2=0, ppl=2.11, wps=502.3, ups=0.54, wpb=934.4, bsz=32, num_updates=21340, lr=1.88072e-05, gnorm=4.298, clip=100, loss_scale=128, train_wall=19, gb_free=10.7, wall=40105
2023-05-26 10:31:49 - progress_bar.py[line:272] - INFO: epoch 013:    601 / 1732 loss=2.261, loss_v1=0, loss_v2=0, nll_loss=1.049, ntokens=941.2, nsentences=32, sample_size=941.2, sample_size_v1=0, sample_size_v2=0, ppl=2.07, wps=507.3, ups=0.54, wpb=941.2, bsz=32, num_updates=21350, lr=1.88011e-05, gnorm=3.991, clip=100, loss_scale=128, train_wall=19, gb_free=11.6, wall=40124
2023-05-26 10:32:07 - progress_bar.py[line:272] - INFO: epoch 013:    611 / 1732 loss=2.285, loss_v1=0, loss_v2=0, nll_loss=1.076, ntokens=911.9, nsentences=32, sample_size=911.9, sample_size_v1=0, sample_size_v2=0, ppl=2.11, wps=494.3, ups=0.54, wpb=911.9, bsz=32, num_updates=21360, lr=1.87949e-05, gnorm=4.652, clip=100, loss_scale=128, train_wall=18, gb_free=11.7, wall=40142
2023-05-26 10:32:26 - progress_bar.py[line:272] - INFO: epoch 013:    621 / 1732 loss=2.314, loss_v1=0, loss_v2=0, nll_loss=1.105, ntokens=845.9, nsentences=32, sample_size=845.9, sample_size_v1=0, sample_size_v2=0, ppl=2.15, wps=460.5, ups=0.54, wpb=845.9, bsz=32, num_updates=21370, lr=1.87888e-05, gnorm=4.766, clip=100, loss_scale=128, train_wall=18, gb_free=12, wall=40160
2023-05-26 10:32:44 - progress_bar.py[line:272] - INFO: epoch 013:    631 / 1732 loss=2.272, loss_v1=0, loss_v2=0, nll_loss=1.059, ntokens=949.2, nsentences=32, sample_size=949.2, sample_size_v1=0, sample_size_v2=0, ppl=2.08, wps=513.7, ups=0.54, wpb=949.2, bsz=32, num_updates=21380, lr=1.87826e-05, gnorm=3.855, clip=100, loss_scale=128, train_wall=18, gb_free=11.2, wall=40179
2023-05-26 10:33:03 - progress_bar.py[line:272] - INFO: epoch 013:    641 / 1732 loss=2.315, loss_v1=0, loss_v2=0, nll_loss=1.109, ntokens=915.8, nsentences=32, sample_size=915.8, sample_size_v1=0, sample_size_v2=0, ppl=2.16, wps=497.2, ups=0.54, wpb=915.8, bsz=32, num_updates=21390, lr=1.87765e-05, gnorm=4.484, clip=100, loss_scale=128, train_wall=18, gb_free=11.8, wall=40197
2023-05-26 10:33:21 - progress_bar.py[line:272] - INFO: epoch 013:    651 / 1732 loss=2.288, loss_v1=0, loss_v2=0, nll_loss=1.078, ntokens=990.2, nsentences=32, sample_size=990.2, sample_size_v1=0, sample_size_v2=0, ppl=2.11, wps=538, ups=0.54, wpb=990.2, bsz=32, num_updates=21400, lr=1.87703e-05, gnorm=3.986, clip=100, loss_scale=128, train_wall=18, gb_free=11.7, wall=40216
2023-05-26 10:33:39 - progress_bar.py[line:272] - INFO: epoch 013:    661 / 1732 loss=2.298, loss_v1=0, loss_v2=0, nll_loss=1.088, ntokens=863.9, nsentences=32, sample_size=863.9, sample_size_v1=0, sample_size_v2=0, ppl=2.13, wps=472.5, ups=0.55, wpb=863.9, bsz=32, num_updates=21410, lr=1.87642e-05, gnorm=4.777, clip=100, loss_scale=128, train_wall=18, gb_free=11.5, wall=40234
2023-05-26 10:33:58 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 128.0
2023-05-26 10:34:00 - progress_bar.py[line:272] - INFO: epoch 013:    672 / 1732 loss=2.31, loss_v1=0, loss_v2=0, nll_loss=1.103, ntokens=919.2, nsentences=32, sample_size=919.2, sample_size_v1=0, sample_size_v2=0, ppl=2.15, wps=452.4, ups=0.49, wpb=919.2, bsz=32, num_updates=21420, lr=1.87581e-05, gnorm=4.547, clip=100, loss_scale=128, train_wall=20, gb_free=11.4, wall=40254
2023-05-26 10:34:18 - progress_bar.py[line:272] - INFO: epoch 013:    682 / 1732 loss=2.283, loss_v1=0, loss_v2=0, nll_loss=1.072, ntokens=981.8, nsentences=32, sample_size=981.8, sample_size_v1=0, sample_size_v2=0, ppl=2.1, wps=531.3, ups=0.54, wpb=981.8, bsz=32, num_updates=21430, lr=1.87519e-05, gnorm=4.241, clip=100, loss_scale=128, train_wall=18, gb_free=11.6, wall=40273
2023-05-26 10:34:37 - progress_bar.py[line:272] - INFO: epoch 013:    692 / 1732 loss=2.308, loss_v1=0, loss_v2=0, nll_loss=1.099, ntokens=939.1, nsentences=32, sample_size=939.1, sample_size_v1=0, sample_size_v2=0, ppl=2.14, wps=505.1, ups=0.54, wpb=939.1, bsz=32, num_updates=21440, lr=1.87458e-05, gnorm=4.5, clip=100, loss_scale=128, train_wall=19, gb_free=11.8, wall=40291
2023-05-26 10:34:55 - progress_bar.py[line:272] - INFO: epoch 013:    702 / 1732 loss=2.269, loss_v1=0, loss_v2=0, nll_loss=1.058, ntokens=974.5, nsentences=32, sample_size=974.5, sample_size_v1=0, sample_size_v2=0, ppl=2.08, wps=526, ups=0.54, wpb=974.5, bsz=32, num_updates=21450, lr=1.87396e-05, gnorm=3.935, clip=100, loss_scale=128, train_wall=18, gb_free=11.6, wall=40310
2023-05-26 10:35:14 - progress_bar.py[line:272] - INFO: epoch 013:    712 / 1732 loss=2.294, loss_v1=0, loss_v2=0, nll_loss=1.084, ntokens=913.9, nsentences=32, sample_size=913.9, sample_size_v1=0, sample_size_v2=0, ppl=2.12, wps=495.8, ups=0.54, wpb=913.9, bsz=32, num_updates=21460, lr=1.87335e-05, gnorm=4.506, clip=100, loss_scale=128, train_wall=18, gb_free=11.8, wall=40328
2023-05-26 10:35:32 - progress_bar.py[line:272] - INFO: epoch 013:    722 / 1732 loss=2.273, loss_v1=0, loss_v2=0, nll_loss=1.061, ntokens=864.8, nsentences=32, sample_size=864.8, sample_size_v1=0, sample_size_v2=0, ppl=2.09, wps=470.4, ups=0.54, wpb=864.8, bsz=32, num_updates=21470, lr=1.87274e-05, gnorm=4.686, clip=100, loss_scale=128, train_wall=18, gb_free=11.6, wall=40347
2023-05-26 10:35:50 - progress_bar.py[line:272] - INFO: epoch 013:    732 / 1732 loss=2.275, loss_v1=0, loss_v2=0, nll_loss=1.065, ntokens=937.9, nsentences=32, sample_size=937.9, sample_size_v1=0, sample_size_v2=0, ppl=2.09, wps=507.8, ups=0.54, wpb=937.9, bsz=32, num_updates=21480, lr=1.87212e-05, gnorm=4.555, clip=100, loss_scale=128, train_wall=18, gb_free=11.3, wall=40365
2023-05-26 10:36:09 - progress_bar.py[line:272] - INFO: epoch 013:    742 / 1732 loss=2.272, loss_v1=0, loss_v2=0, nll_loss=1.06, ntokens=1015.7, nsentences=32, sample_size=1015.7, sample_size_v1=0, sample_size_v2=0, ppl=2.09, wps=549.8, ups=0.54, wpb=1015.7, bsz=32, num_updates=21490, lr=1.87151e-05, gnorm=4.138, clip=100, loss_scale=128, train_wall=18, gb_free=11.5, wall=40384
2023-05-26 10:36:28 - progress_bar.py[line:272] - INFO: epoch 013:    752 / 1732 loss=2.278, loss_v1=0, loss_v2=0, nll_loss=1.064, ntokens=960.1, nsentences=32, sample_size=960.1, sample_size_v1=0, sample_size_v2=0, ppl=2.09, wps=516.8, ups=0.54, wpb=960.1, bsz=32, num_updates=21500, lr=1.87089e-05, gnorm=4.287, clip=100, loss_scale=128, train_wall=19, gb_free=11.8, wall=40402
2023-05-26 10:36:46 - progress_bar.py[line:272] - INFO: epoch 013:    762 / 1732 loss=2.268, loss_v1=0, loss_v2=0, nll_loss=1.055, ntokens=973.7, nsentences=32, sample_size=973.7, sample_size_v1=0, sample_size_v2=0, ppl=2.08, wps=527.5, ups=0.54, wpb=973.7, bsz=32, num_updates=21510, lr=1.87028e-05, gnorm=4.178, clip=100, loss_scale=128, train_wall=18, gb_free=11.9, wall=40421
2023-05-26 10:37:04 - progress_bar.py[line:272] - INFO: epoch 013:    772 / 1732 loss=2.271, loss_v1=0, loss_v2=0, nll_loss=1.063, ntokens=955.8, nsentences=32, sample_size=955.8, sample_size_v1=0, sample_size_v2=0, ppl=2.09, wps=517.3, ups=0.54, wpb=955.8, bsz=32, num_updates=21520, lr=1.86966e-05, gnorm=4.763, clip=100, loss_scale=128, train_wall=18, gb_free=10.4, wall=40439
2023-05-26 10:37:23 - progress_bar.py[line:272] - INFO: epoch 013:    782 / 1732 loss=2.28, loss_v1=0, loss_v2=0, nll_loss=1.069, ntokens=1024.5, nsentences=32, sample_size=1024.5, sample_size_v1=0, sample_size_v2=0, ppl=2.1, wps=554.1, ups=0.54, wpb=1024.5, bsz=32, num_updates=21530, lr=1.86905e-05, gnorm=3.857, clip=100, loss_scale=128, train_wall=18, gb_free=11.6, wall=40458
2023-05-26 10:37:41 - progress_bar.py[line:272] - INFO: epoch 013:    792 / 1732 loss=2.294, loss_v1=0, loss_v2=0, nll_loss=1.083, ntokens=1023.9, nsentences=32, sample_size=1023.9, sample_size_v1=0, sample_size_v2=0, ppl=2.12, wps=553.6, ups=0.54, wpb=1023.9, bsz=32, num_updates=21540, lr=1.86844e-05, gnorm=4.634, clip=100, loss_scale=128, train_wall=18, gb_free=12, wall=40476
2023-05-26 10:38:00 - progress_bar.py[line:272] - INFO: epoch 013:    802 / 1732 loss=2.275, loss_v1=0, loss_v2=0, nll_loss=1.063, ntokens=971.6, nsentences=32, sample_size=971.6, sample_size_v1=0, sample_size_v2=0, ppl=2.09, wps=526.5, ups=0.54, wpb=971.6, bsz=32, num_updates=21550, lr=1.86782e-05, gnorm=4.179, clip=100, loss_scale=128, train_wall=18, gb_free=11.7, wall=40495
2023-05-26 10:38:18 - progress_bar.py[line:272] - INFO: epoch 013:    812 / 1732 loss=2.288, loss_v1=0, loss_v2=0, nll_loss=1.079, ntokens=942.1, nsentences=32, sample_size=942.1, sample_size_v1=0, sample_size_v2=0, ppl=2.11, wps=510.5, ups=0.54, wpb=942.1, bsz=32, num_updates=21560, lr=1.86721e-05, gnorm=4.429, clip=100, loss_scale=128, train_wall=18, gb_free=11.6, wall=40513
2023-05-26 10:38:37 - progress_bar.py[line:272] - INFO: epoch 013:    822 / 1732 loss=2.276, loss_v1=0, loss_v2=0, nll_loss=1.062, ntokens=921.5, nsentences=32, sample_size=921.5, sample_size_v1=0, sample_size_v2=0, ppl=2.09, wps=497.6, ups=0.54, wpb=921.5, bsz=32, num_updates=21570, lr=1.86659e-05, gnorm=4.709, clip=100, loss_scale=128, train_wall=18, gb_free=11.4, wall=40532
2023-05-26 10:38:55 - progress_bar.py[line:272] - INFO: epoch 013:    832 / 1732 loss=2.284, loss_v1=0, loss_v2=0, nll_loss=1.073, ntokens=907.9, nsentences=32, sample_size=907.9, sample_size_v1=0, sample_size_v2=0, ppl=2.1, wps=493.1, ups=0.54, wpb=907.9, bsz=32, num_updates=21580, lr=1.86598e-05, gnorm=4.499, clip=100, loss_scale=128, train_wall=18, gb_free=11.9, wall=40550
2023-05-26 10:39:14 - progress_bar.py[line:272] - INFO: epoch 013:    842 / 1732 loss=2.274, loss_v1=0, loss_v2=0, nll_loss=1.062, ntokens=950.4, nsentences=32, sample_size=950.4, sample_size_v1=0, sample_size_v2=0, ppl=2.09, wps=517.1, ups=0.54, wpb=950.4, bsz=32, num_updates=21590, lr=1.86536e-05, gnorm=4.595, clip=100, loss_scale=128, train_wall=18, gb_free=11.4, wall=40568
2023-05-26 10:39:32 - progress_bar.py[line:272] - INFO: epoch 013:    852 / 1732 loss=2.292, loss_v1=0, loss_v2=0, nll_loss=1.082, ntokens=997.8, nsentences=32, sample_size=997.8, sample_size_v1=0, sample_size_v2=0, ppl=2.12, wps=540, ups=0.54, wpb=997.8, bsz=32, num_updates=21600, lr=1.86475e-05, gnorm=4.422, clip=100, loss_scale=128, train_wall=18, gb_free=11.8, wall=40587
2023-05-26 10:39:51 - progress_bar.py[line:272] - INFO: epoch 013:    862 / 1732 loss=2.268, loss_v1=0, loss_v2=0, nll_loss=1.058, ntokens=931.8, nsentences=32, sample_size=931.8, sample_size_v1=0, sample_size_v2=0, ppl=2.08, wps=503.7, ups=0.54, wpb=931.8, bsz=32, num_updates=21610, lr=1.86414e-05, gnorm=4.512, clip=100, loss_scale=128, train_wall=18, gb_free=11, wall=40605
2023-05-26 10:40:09 - progress_bar.py[line:272] - INFO: epoch 013:    872 / 1732 loss=2.269, loss_v1=0, loss_v2=0, nll_loss=1.058, ntokens=965, nsentences=32, sample_size=965, sample_size_v1=0, sample_size_v2=0, ppl=2.08, wps=522.8, ups=0.54, wpb=965, bsz=32, num_updates=21620, lr=1.86352e-05, gnorm=4.316, clip=100, loss_scale=128, train_wall=18, gb_free=11.6, wall=40624
2023-05-26 10:40:28 - progress_bar.py[line:272] - INFO: epoch 013:    882 / 1732 loss=2.23, loss_v1=0, loss_v2=0, nll_loss=1.013, ntokens=987.7, nsentences=32, sample_size=987.7, sample_size_v1=0, sample_size_v2=0, ppl=2.02, wps=532, ups=0.54, wpb=987.7, bsz=32, num_updates=21630, lr=1.86291e-05, gnorm=4.379, clip=100, loss_scale=128, train_wall=19, gb_free=11.3, wall=40642
2023-05-26 10:40:46 - progress_bar.py[line:272] - INFO: epoch 013:    892 / 1732 loss=2.226, loss_v1=0, loss_v2=0, nll_loss=1.01, ntokens=1003.5, nsentences=32, sample_size=1003.5, sample_size_v1=0, sample_size_v2=0, ppl=2.01, wps=538.7, ups=0.54, wpb=1003.5, bsz=32, num_updates=21640, lr=1.86229e-05, gnorm=4.279, clip=100, loss_scale=128, train_wall=19, gb_free=11.1, wall=40661
2023-05-26 10:41:05 - progress_bar.py[line:272] - INFO: epoch 013:    902 / 1732 loss=2.225, loss_v1=0, loss_v2=0, nll_loss=1.006, ntokens=1046.1, nsentences=32, sample_size=1046.1, sample_size_v1=0, sample_size_v2=0, ppl=2.01, wps=563.9, ups=0.54, wpb=1046.1, bsz=32, num_updates=21650, lr=1.86168e-05, gnorm=3.914, clip=100, loss_scale=128, train_wall=19, gb_free=11.2, wall=40680
2023-05-26 10:41:23 - progress_bar.py[line:272] - INFO: epoch 013:    912 / 1732 loss=2.284, loss_v1=0, loss_v2=0, nll_loss=1.074, ntokens=948.6, nsentences=32, sample_size=948.6, sample_size_v1=0, sample_size_v2=0, ppl=2.11, wps=512.9, ups=0.54, wpb=948.6, bsz=32, num_updates=21660, lr=1.86107e-05, gnorm=4.557, clip=100, loss_scale=128, train_wall=18, gb_free=11, wall=40698
2023-05-26 10:41:42 - progress_bar.py[line:272] - INFO: epoch 013:    922 / 1732 loss=2.271, loss_v1=0, loss_v2=0, nll_loss=1.059, ntokens=1004.6, nsentences=32, sample_size=1004.6, sample_size_v1=0, sample_size_v2=0, ppl=2.08, wps=539.9, ups=0.54, wpb=1004.6, bsz=32, num_updates=21670, lr=1.86045e-05, gnorm=4.408, clip=100, loss_scale=128, train_wall=19, gb_free=11.3, wall=40717
2023-05-26 10:42:01 - progress_bar.py[line:272] - INFO: epoch 013:    932 / 1732 loss=2.259, loss_v1=0, loss_v2=0, nll_loss=1.046, ntokens=1036.8, nsentences=32, sample_size=1036.8, sample_size_v1=0, sample_size_v2=0, ppl=2.07, wps=552.9, ups=0.53, wpb=1036.8, bsz=32, num_updates=21680, lr=1.85984e-05, gnorm=4.613, clip=100, loss_scale=128, train_wall=19, gb_free=10.9, wall=40735
2023-05-26 10:42:20 - progress_bar.py[line:272] - INFO: epoch 013:    942 / 1732 loss=2.268, loss_v1=0, loss_v2=0, nll_loss=1.056, ntokens=1063.3, nsentences=32, sample_size=1063.3, sample_size_v1=0, sample_size_v2=0, ppl=2.08, wps=564.5, ups=0.53, wpb=1063.3, bsz=32, num_updates=21690, lr=1.85922e-05, gnorm=4.372, clip=100, loss_scale=128, train_wall=19, gb_free=11.5, wall=40754
2023-05-26 10:42:38 - progress_bar.py[line:272] - INFO: epoch 013:    952 / 1732 loss=2.274, loss_v1=0, loss_v2=0, nll_loss=1.061, ntokens=1011.4, nsentences=32, sample_size=1011.4, sample_size_v1=0, sample_size_v2=0, ppl=2.09, wps=539.3, ups=0.53, wpb=1011.4, bsz=32, num_updates=21700, lr=1.85861e-05, gnorm=4.437, clip=100, loss_scale=128, train_wall=19, gb_free=11.5, wall=40773
2023-05-26 10:42:57 - progress_bar.py[line:272] - INFO: epoch 013:    962 / 1732 loss=2.266, loss_v1=0, loss_v2=0, nll_loss=1.053, ntokens=1071.4, nsentences=32, sample_size=1071.4, sample_size_v1=0, sample_size_v2=0, ppl=2.08, wps=571, ups=0.53, wpb=1071.4, bsz=32, num_updates=21710, lr=1.85799e-05, gnorm=4.472, clip=100, loss_scale=128, train_wall=19, gb_free=11.8, wall=40792
2023-05-26 10:43:16 - progress_bar.py[line:272] - INFO: epoch 013:    972 / 1732 loss=2.288, loss_v1=0, loss_v2=0, nll_loss=1.077, ntokens=1038.3, nsentences=32, sample_size=1038.3, sample_size_v1=0, sample_size_v2=0, ppl=2.11, wps=551, ups=0.53, wpb=1038.3, bsz=32, num_updates=21720, lr=1.85738e-05, gnorm=4.217, clip=100, loss_scale=128, train_wall=19, gb_free=10.7, wall=40811
2023-05-26 10:43:35 - progress_bar.py[line:272] - INFO: epoch 013:    982 / 1732 loss=2.261, loss_v1=0, loss_v2=0, nll_loss=1.048, ntokens=1035.4, nsentences=32, sample_size=1035.4, sample_size_v1=0, sample_size_v2=0, ppl=2.07, wps=549.6, ups=0.53, wpb=1035.4, bsz=32, num_updates=21730, lr=1.85677e-05, gnorm=4.095, clip=100, loss_scale=128, train_wall=19, gb_free=11.3, wall=40830
2023-05-26 10:43:54 - progress_bar.py[line:272] - INFO: epoch 013:    992 / 1732 loss=2.281, loss_v1=0, loss_v2=0, nll_loss=1.07, ntokens=1026.6, nsentences=32, sample_size=1026.6, sample_size_v1=0, sample_size_v2=0, ppl=2.1, wps=545.3, ups=0.53, wpb=1026.6, bsz=32, num_updates=21740, lr=1.85615e-05, gnorm=4.379, clip=100, loss_scale=128, train_wall=19, gb_free=11.4, wall=40848
2023-05-26 10:44:12 - progress_bar.py[line:272] - INFO: epoch 013:   1002 / 1732 loss=2.25, loss_v1=0, loss_v2=0, nll_loss=1.034, ntokens=1023.8, nsentences=32, sample_size=1023.8, sample_size_v1=0, sample_size_v2=0, ppl=2.05, wps=547.3, ups=0.53, wpb=1023.8, bsz=32, num_updates=21750, lr=1.85554e-05, gnorm=4.665, clip=100, loss_scale=128, train_wall=19, gb_free=11, wall=40867
2023-05-26 10:44:31 - progress_bar.py[line:272] - INFO: epoch 013:   1012 / 1732 loss=2.277, loss_v1=0, loss_v2=0, nll_loss=1.064, ntokens=987.2, nsentences=32, sample_size=987.2, sample_size_v1=0, sample_size_v2=0, ppl=2.09, wps=530.3, ups=0.54, wpb=987.2, bsz=32, num_updates=21760, lr=1.85492e-05, gnorm=4.396, clip=100, loss_scale=128, train_wall=19, gb_free=11.3, wall=40886
2023-05-26 10:44:50 - progress_bar.py[line:272] - INFO: epoch 013:   1022 / 1732 loss=2.248, loss_v1=0, loss_v2=0, nll_loss=1.035, ntokens=1063.7, nsentences=32, sample_size=1063.7, sample_size_v1=0, sample_size_v2=0, ppl=2.05, wps=567.1, ups=0.53, wpb=1063.7, bsz=32, num_updates=21770, lr=1.85431e-05, gnorm=4.379, clip=100, loss_scale=128, train_wall=19, gb_free=10.7, wall=40904
2023-05-26 10:45:09 - progress_bar.py[line:272] - INFO: epoch 013:   1032 / 1732 loss=2.258, loss_v1=0, loss_v2=0, nll_loss=1.043, ntokens=1117.6, nsentences=32, sample_size=1117.6, sample_size_v1=0, sample_size_v2=0, ppl=2.06, wps=589.9, ups=0.53, wpb=1117.6, bsz=32, num_updates=21780, lr=1.85369e-05, gnorm=4.234, clip=100, loss_scale=128, train_wall=19, gb_free=11.5, wall=40923
2023-05-26 10:45:28 - progress_bar.py[line:272] - INFO: epoch 013:   1042 / 1732 loss=2.261, loss_v1=0, loss_v2=0, nll_loss=1.047, ntokens=1067.2, nsentences=32, sample_size=1067.2, sample_size_v1=0, sample_size_v2=0, ppl=2.07, wps=567.1, ups=0.53, wpb=1067.2, bsz=32, num_updates=21790, lr=1.85308e-05, gnorm=4.386, clip=100, loss_scale=128, train_wall=19, gb_free=10.8, wall=40942
2023-05-26 10:45:46 - progress_bar.py[line:272] - INFO: epoch 013:   1052 / 1732 loss=2.275, loss_v1=0, loss_v2=0, nll_loss=1.065, ntokens=1041, nsentences=32, sample_size=1041, sample_size_v1=0, sample_size_v2=0, ppl=2.09, wps=558.9, ups=0.54, wpb=1041, bsz=32, num_updates=21800, lr=1.85247e-05, gnorm=4.665, clip=100, loss_scale=128, train_wall=19, gb_free=11.2, wall=40961
2023-05-26 10:46:05 - progress_bar.py[line:272] - INFO: epoch 013:   1062 / 1732 loss=2.259, loss_v1=0, loss_v2=0, nll_loss=1.046, ntokens=1046.1, nsentences=32, sample_size=1046.1, sample_size_v1=0, sample_size_v2=0, ppl=2.06, wps=556.6, ups=0.53, wpb=1046.1, bsz=32, num_updates=21810, lr=1.85185e-05, gnorm=4.113, clip=100, loss_scale=128, train_wall=19, gb_free=11.1, wall=40980
2023-05-26 10:46:24 - progress_bar.py[line:272] - INFO: epoch 013:   1072 / 1732 loss=2.266, loss_v1=0, loss_v2=0, nll_loss=1.052, ntokens=994.4, nsentences=32, sample_size=994.4, sample_size_v1=0, sample_size_v2=0, ppl=2.07, wps=531.1, ups=0.53, wpb=994.4, bsz=32, num_updates=21820, lr=1.85124e-05, gnorm=4.441, clip=100, loss_scale=128, train_wall=19, gb_free=11.5, wall=40998
2023-05-26 10:46:43 - progress_bar.py[line:272] - INFO: epoch 013:   1082 / 1732 loss=2.283, loss_v1=0, loss_v2=0, nll_loss=1.072, ntokens=1041.7, nsentences=32, sample_size=1041.7, sample_size_v1=0, sample_size_v2=0, ppl=2.1, wps=551.5, ups=0.53, wpb=1041.7, bsz=32, num_updates=21830, lr=1.85062e-05, gnorm=4.375, clip=100, loss_scale=128, train_wall=19, gb_free=11.2, wall=41017
2023-05-26 10:47:01 - progress_bar.py[line:272] - INFO: epoch 013:   1092 / 1732 loss=2.265, loss_v1=0, loss_v2=0, nll_loss=1.052, ntokens=1060.8, nsentences=32, sample_size=1060.8, sample_size_v1=0, sample_size_v2=0, ppl=2.07, wps=562.7, ups=0.53, wpb=1060.8, bsz=32, num_updates=21840, lr=1.85001e-05, gnorm=4.113, clip=100, loss_scale=128, train_wall=19, gb_free=11.6, wall=41036
2023-05-26 10:47:20 - progress_bar.py[line:272] - INFO: epoch 013:   1102 / 1732 loss=2.273, loss_v1=0, loss_v2=0, nll_loss=1.06, ntokens=1049.1, nsentences=32, sample_size=1049.1, sample_size_v1=0, sample_size_v2=0, ppl=2.09, wps=559.9, ups=0.53, wpb=1049.1, bsz=32, num_updates=21850, lr=1.8494e-05, gnorm=4.431, clip=100, loss_scale=128, train_wall=19, gb_free=10.5, wall=41055
2023-05-26 10:47:39 - progress_bar.py[line:272] - INFO: epoch 013:   1112 / 1732 loss=2.255, loss_v1=0, loss_v2=0, nll_loss=1.041, ntokens=1025.7, nsentences=32, sample_size=1025.7, sample_size_v1=0, sample_size_v2=0, ppl=2.06, wps=545.5, ups=0.53, wpb=1025.7, bsz=32, num_updates=21860, lr=1.84878e-05, gnorm=4.071, clip=100, loss_scale=128, train_wall=19, gb_free=11.3, wall=41074
2023-05-26 10:47:58 - progress_bar.py[line:272] - INFO: epoch 013:   1122 / 1732 loss=2.252, loss_v1=0, loss_v2=0, nll_loss=1.038, ntokens=976.1, nsentences=32, sample_size=976.1, sample_size_v1=0, sample_size_v2=0, ppl=2.05, wps=520.5, ups=0.53, wpb=976.1, bsz=32, num_updates=21870, lr=1.84817e-05, gnorm=4.301, clip=100, loss_scale=128, train_wall=19, gb_free=11.3, wall=41092
2023-05-26 10:48:16 - progress_bar.py[line:272] - INFO: epoch 013:   1132 / 1732 loss=2.266, loss_v1=0, loss_v2=0, nll_loss=1.055, ntokens=969.4, nsentences=32, sample_size=969.4, sample_size_v1=0, sample_size_v2=0, ppl=2.08, wps=516.8, ups=0.53, wpb=969.4, bsz=32, num_updates=21880, lr=1.84755e-05, gnorm=4.141, clip=100, loss_scale=128, train_wall=19, gb_free=11.7, wall=41111
2023-05-26 10:48:35 - progress_bar.py[line:272] - INFO: epoch 013:   1142 / 1732 loss=2.26, loss_v1=0, loss_v2=0, nll_loss=1.046, ntokens=1032.5, nsentences=32, sample_size=1032.5, sample_size_v1=0, sample_size_v2=0, ppl=2.07, wps=549.9, ups=0.53, wpb=1032.5, bsz=32, num_updates=21890, lr=1.84694e-05, gnorm=4.234, clip=100, loss_scale=128, train_wall=19, gb_free=11.1, wall=41130
2023-05-26 10:48:54 - progress_bar.py[line:272] - INFO: epoch 013:   1152 / 1732 loss=2.242, loss_v1=0, loss_v2=0, nll_loss=1.026, ntokens=1026.9, nsentences=32, sample_size=1026.9, sample_size_v1=0, sample_size_v2=0, ppl=2.04, wps=548.3, ups=0.53, wpb=1026.9, bsz=32, num_updates=21900, lr=1.84632e-05, gnorm=4.048, clip=100, loss_scale=128, train_wall=19, gb_free=11.4, wall=41149
2023-05-26 10:49:13 - progress_bar.py[line:272] - INFO: epoch 013:   1162 / 1732 loss=2.231, loss_v1=0, loss_v2=0, nll_loss=1.016, ntokens=1008.4, nsentences=32, sample_size=1008.4, sample_size_v1=0, sample_size_v2=0, ppl=2.02, wps=536.1, ups=0.53, wpb=1008.4, bsz=32, num_updates=21910, lr=1.84571e-05, gnorm=4.445, clip=100, loss_scale=128, train_wall=19, gb_free=11.3, wall=41167
2023-05-26 10:49:32 - progress_bar.py[line:272] - INFO: epoch 013:   1172 / 1732 loss=2.252, loss_v1=0, loss_v2=0, nll_loss=1.037, ntokens=1048.6, nsentences=32, sample_size=1048.6, sample_size_v1=0, sample_size_v2=0, ppl=2.05, wps=557.7, ups=0.53, wpb=1048.6, bsz=32, num_updates=21920, lr=1.8451e-05, gnorm=4.01, clip=100, loss_scale=128, train_wall=19, gb_free=10.8, wall=41186
2023-05-26 10:49:50 - progress_bar.py[line:272] - INFO: epoch 013:   1182 / 1732 loss=2.235, loss_v1=0, loss_v2=0, nll_loss=1.018, ntokens=1018.1, nsentences=32, sample_size=1018.1, sample_size_v1=0, sample_size_v2=0, ppl=2.03, wps=543.8, ups=0.53, wpb=1018.1, bsz=32, num_updates=21930, lr=1.84448e-05, gnorm=4.381, clip=100, loss_scale=128, train_wall=19, gb_free=11.4, wall=41205
2023-05-26 10:50:01 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 128.0
2023-05-26 10:50:11 - progress_bar.py[line:272] - INFO: epoch 013:   1193 / 1732 loss=2.266, loss_v1=0, loss_v2=0, nll_loss=1.055, ntokens=1009.9, nsentences=32, sample_size=1009.9, sample_size_v1=0, sample_size_v2=0, ppl=2.08, wps=491.5, ups=0.49, wpb=1009.9, bsz=32, num_updates=21940, lr=1.84387e-05, gnorm=4.031, clip=100, loss_scale=128, train_wall=21, gb_free=11.2, wall=41226
2023-05-26 10:50:30 - progress_bar.py[line:272] - INFO: epoch 013:   1203 / 1732 loss=2.237, loss_v1=0, loss_v2=0, nll_loss=1.02, ntokens=1142.6, nsentences=32, sample_size=1142.6, sample_size_v1=0, sample_size_v2=0, ppl=2.03, wps=603.5, ups=0.53, wpb=1142.6, bsz=32, num_updates=21950, lr=1.84325e-05, gnorm=3.911, clip=100, loss_scale=128, train_wall=19, gb_free=10.3, wall=41245
2023-05-26 10:50:49 - progress_bar.py[line:272] - INFO: epoch 013:   1213 / 1732 loss=2.256, loss_v1=0, loss_v2=0, nll_loss=1.042, ntokens=1010.9, nsentences=32, sample_size=1010.9, sample_size_v1=0, sample_size_v2=0, ppl=2.06, wps=538.7, ups=0.53, wpb=1010.9, bsz=32, num_updates=21960, lr=1.84264e-05, gnorm=4.119, clip=100, loss_scale=128, train_wall=19, gb_free=11.7, wall=41263
2023-05-26 10:51:07 - progress_bar.py[line:272] - INFO: epoch 013:   1223 / 1732 loss=2.283, loss_v1=0, loss_v2=0, nll_loss=1.074, ntokens=1033.2, nsentences=32, sample_size=1033.2, sample_size_v1=0, sample_size_v2=0, ppl=2.11, wps=550.2, ups=0.53, wpb=1033.2, bsz=32, num_updates=21970, lr=1.84202e-05, gnorm=4.346, clip=100, loss_scale=128, train_wall=19, gb_free=11.2, wall=41282
2023-05-26 10:51:26 - progress_bar.py[line:272] - INFO: epoch 013:   1233 / 1732 loss=2.24, loss_v1=0, loss_v2=0, nll_loss=1.023, ntokens=1038.6, nsentences=32, sample_size=1038.6, sample_size_v1=0, sample_size_v2=0, ppl=2.03, wps=554.6, ups=0.53, wpb=1038.6, bsz=32, num_updates=21980, lr=1.84141e-05, gnorm=3.987, clip=100, loss_scale=128, train_wall=19, gb_free=11, wall=41301
2023-05-26 10:51:45 - progress_bar.py[line:272] - INFO: epoch 013:   1243 / 1732 loss=2.211, loss_v1=0, loss_v2=0, nll_loss=0.992, ntokens=1063.3, nsentences=32, sample_size=1063.3, sample_size_v1=0, sample_size_v2=0, ppl=1.99, wps=564.7, ups=0.53, wpb=1063.3, bsz=32, num_updates=21990, lr=1.8408e-05, gnorm=4.267, clip=100, loss_scale=128, train_wall=19, gb_free=11.4, wall=41320
2023-05-26 10:52:04 - progress_bar.py[line:272] - INFO: epoch 013:   1253 / 1732 loss=2.216, loss_v1=0, loss_v2=0, nll_loss=0.998, ntokens=1098.7, nsentences=32, sample_size=1098.7, sample_size_v1=0, sample_size_v2=0, ppl=2, wps=580.2, ups=0.53, wpb=1098.7, bsz=32, num_updates=22000, lr=1.84018e-05, gnorm=3.947, clip=100, loss_scale=128, train_wall=19, gb_free=11.3, wall=41339
2023-05-26 10:52:23 - progress_bar.py[line:272] - INFO: epoch 013:   1263 / 1732 loss=2.253, loss_v1=0, loss_v2=0, nll_loss=1.039, ntokens=1070.8, nsentences=32, sample_size=1070.8, sample_size_v1=0, sample_size_v2=0, ppl=2.06, wps=569.1, ups=0.53, wpb=1070.8, bsz=32, num_updates=22010, lr=1.83957e-05, gnorm=4.093, clip=100, loss_scale=128, train_wall=19, gb_free=11.1, wall=41357
2023-05-26 10:52:41 - progress_bar.py[line:272] - INFO: epoch 013:   1273 / 1732 loss=2.272, loss_v1=0, loss_v2=0, nll_loss=1.061, ntokens=1005.1, nsentences=32, sample_size=1005.1, sample_size_v1=0, sample_size_v2=0, ppl=2.09, wps=536.7, ups=0.53, wpb=1005.1, bsz=32, num_updates=22020, lr=1.83895e-05, gnorm=4.395, clip=100, loss_scale=128, train_wall=19, gb_free=10.8, wall=41376
2023-05-26 10:53:00 - progress_bar.py[line:272] - INFO: epoch 013:   1283 / 1732 loss=2.238, loss_v1=0, loss_v2=0, nll_loss=1.022, ntokens=1101.8, nsentences=32, sample_size=1101.8, sample_size_v1=0, sample_size_v2=0, ppl=2.03, wps=581.5, ups=0.53, wpb=1101.8, bsz=32, num_updates=22030, lr=1.83834e-05, gnorm=4.123, clip=100, loss_scale=128, train_wall=19, gb_free=11.4, wall=41395
2023-05-26 10:53:19 - progress_bar.py[line:272] - INFO: epoch 013:   1293 / 1732 loss=2.248, loss_v1=0, loss_v2=0, nll_loss=1.032, ntokens=1084.4, nsentences=32, sample_size=1084.4, sample_size_v1=0, sample_size_v2=0, ppl=2.04, wps=573.6, ups=0.53, wpb=1084.4, bsz=32, num_updates=22040, lr=1.83772e-05, gnorm=3.656, clip=100, loss_scale=128, train_wall=19, gb_free=11.4, wall=41414
2023-05-26 10:53:38 - progress_bar.py[line:272] - INFO: epoch 013:   1303 / 1732 loss=2.258, loss_v1=0, loss_v2=0, nll_loss=1.046, ntokens=1102.4, nsentences=32, sample_size=1102.4, sample_size_v1=0, sample_size_v2=0, ppl=2.06, wps=583.9, ups=0.53, wpb=1102.4, bsz=32, num_updates=22050, lr=1.83711e-05, gnorm=3.941, clip=100, loss_scale=128, train_wall=19, gb_free=10.9, wall=41433
2023-05-26 10:53:57 - progress_bar.py[line:272] - INFO: epoch 013:   1313 / 1732 loss=2.288, loss_v1=0, loss_v2=0, nll_loss=1.078, ntokens=1055.3, nsentences=32, sample_size=1055.3, sample_size_v1=0, sample_size_v2=0, ppl=2.11, wps=554.7, ups=0.53, wpb=1055.3, bsz=32, num_updates=22060, lr=1.8365e-05, gnorm=4.333, clip=100, loss_scale=128, train_wall=19, gb_free=10.7, wall=41452
2023-05-26 10:54:16 - progress_bar.py[line:272] - INFO: epoch 013:   1323 / 1732 loss=2.231, loss_v1=0, loss_v2=0, nll_loss=1.016, ntokens=1103.3, nsentences=32, sample_size=1103.3, sample_size_v1=0, sample_size_v2=0, ppl=2.02, wps=583.4, ups=0.53, wpb=1103.3, bsz=32, num_updates=22070, lr=1.83588e-05, gnorm=3.985, clip=100, loss_scale=128, train_wall=19, gb_free=11.2, wall=41471
2023-05-26 10:54:35 - progress_bar.py[line:272] - INFO: epoch 013:   1333 / 1732 loss=2.225, loss_v1=0, loss_v2=0, nll_loss=1.006, ntokens=1100.8, nsentences=32, sample_size=1100.8, sample_size_v1=0, sample_size_v2=0, ppl=2.01, wps=577.5, ups=0.52, wpb=1100.8, bsz=32, num_updates=22080, lr=1.83527e-05, gnorm=3.877, clip=100, loss_scale=128, train_wall=19, gb_free=11.1, wall=41490
2023-05-26 10:54:54 - progress_bar.py[line:272] - INFO: epoch 013:   1343 / 1732 loss=2.237, loss_v1=0, loss_v2=0, nll_loss=1.02, ntokens=1190.4, nsentences=32, sample_size=1190.4, sample_size_v1=0, sample_size_v2=0, ppl=2.03, wps=626.6, ups=0.53, wpb=1190.4, bsz=32, num_updates=22090, lr=1.83465e-05, gnorm=4.285, clip=100, loss_scale=128, train_wall=19, gb_free=11.1, wall=41509
2023-05-26 10:55:13 - progress_bar.py[line:272] - INFO: epoch 013:   1353 / 1732 loss=2.237, loss_v1=0, loss_v2=0, nll_loss=1.022, ntokens=1120.7, nsentences=32, sample_size=1120.7, sample_size_v1=0, sample_size_v2=0, ppl=2.03, wps=593.1, ups=0.53, wpb=1120.7, bsz=32, num_updates=22100, lr=1.83404e-05, gnorm=3.895, clip=100, loss_scale=128, train_wall=19, gb_free=11.4, wall=41528
2023-05-26 10:55:32 - progress_bar.py[line:272] - INFO: epoch 013:   1363 / 1732 loss=2.22, loss_v1=0, loss_v2=0, nll_loss=1, ntokens=1088.2, nsentences=32, sample_size=1088.2, sample_size_v1=0, sample_size_v2=0, ppl=2, wps=574, ups=0.53, wpb=1088.2, bsz=32, num_updates=22110, lr=1.83343e-05, gnorm=4.167, clip=100, loss_scale=128, train_wall=19, gb_free=11.8, wall=41547
2023-05-26 10:55:51 - progress_bar.py[line:272] - INFO: epoch 013:   1373 / 1732 loss=2.263, loss_v1=0, loss_v2=0, nll_loss=1.05, ntokens=1114.2, nsentences=32, sample_size=1114.2, sample_size_v1=0, sample_size_v2=0, ppl=2.07, wps=592.1, ups=0.53, wpb=1114.2, bsz=32, num_updates=22120, lr=1.83281e-05, gnorm=4.325, clip=100, loss_scale=128, train_wall=19, gb_free=11.3, wall=41566
2023-05-26 10:56:10 - progress_bar.py[line:272] - INFO: epoch 013:   1383 / 1732 loss=2.258, loss_v1=0, loss_v2=0, nll_loss=1.045, ntokens=1148.9, nsentences=32, sample_size=1148.9, sample_size_v1=0, sample_size_v2=0, ppl=2.06, wps=609.7, ups=0.53, wpb=1148.9, bsz=32, num_updates=22130, lr=1.8322e-05, gnorm=4.278, clip=100, loss_scale=128, train_wall=19, gb_free=11.5, wall=41584
2023-05-26 10:56:28 - progress_bar.py[line:272] - INFO: epoch 013:   1393 / 1732 loss=2.261, loss_v1=0, loss_v2=0, nll_loss=1.048, ntokens=1033.6, nsentences=32, sample_size=1033.6, sample_size_v1=0, sample_size_v2=0, ppl=2.07, wps=552.4, ups=0.53, wpb=1033.6, bsz=32, num_updates=22140, lr=1.83158e-05, gnorm=4.444, clip=100, loss_scale=128, train_wall=19, gb_free=11, wall=41603
2023-05-26 10:56:47 - progress_bar.py[line:272] - INFO: epoch 013:   1403 / 1732 loss=2.238, loss_v1=0, loss_v2=0, nll_loss=1.022, ntokens=1148.6, nsentences=32, sample_size=1148.6, sample_size_v1=0, sample_size_v2=0, ppl=2.03, wps=609.5, ups=0.53, wpb=1148.6, bsz=32, num_updates=22150, lr=1.83097e-05, gnorm=4.07, clip=100, loss_scale=128, train_wall=19, gb_free=11.4, wall=41622
2023-05-26 10:57:06 - progress_bar.py[line:272] - INFO: epoch 013:   1413 / 1732 loss=2.269, loss_v1=0, loss_v2=0, nll_loss=1.056, ntokens=1251.8, nsentences=32, sample_size=1251.8, sample_size_v1=0, sample_size_v2=0, ppl=2.08, wps=660, ups=0.53, wpb=1251.8, bsz=32, num_updates=22160, lr=1.83035e-05, gnorm=4.069, clip=100, loss_scale=128, train_wall=19, gb_free=11.1, wall=41641
2023-05-26 10:57:25 - progress_bar.py[line:272] - INFO: epoch 013:   1423 / 1732 loss=2.247, loss_v1=0, loss_v2=0, nll_loss=1.031, ntokens=1276.2, nsentences=32, sample_size=1276.2, sample_size_v1=0, sample_size_v2=0, ppl=2.04, wps=666.2, ups=0.52, wpb=1276.2, bsz=32, num_updates=22170, lr=1.82974e-05, gnorm=3.972, clip=100, loss_scale=128, train_wall=19, gb_free=11.2, wall=41660
2023-05-26 10:57:44 - progress_bar.py[line:272] - INFO: epoch 013:   1433 / 1732 loss=2.234, loss_v1=0, loss_v2=0, nll_loss=1.018, ntokens=1210.9, nsentences=32, sample_size=1210.9, sample_size_v1=0, sample_size_v2=0, ppl=2.02, wps=640.3, ups=0.53, wpb=1210.9, bsz=32, num_updates=22180, lr=1.82913e-05, gnorm=3.983, clip=100, loss_scale=128, train_wall=19, gb_free=11.3, wall=41679
2023-05-26 10:58:03 - progress_bar.py[line:272] - INFO: epoch 013:   1443 / 1732 loss=2.244, loss_v1=0, loss_v2=0, nll_loss=1.031, ntokens=1130.8, nsentences=32, sample_size=1130.8, sample_size_v1=0, sample_size_v2=0, ppl=2.04, wps=598.4, ups=0.53, wpb=1130.8, bsz=32, num_updates=22190, lr=1.82851e-05, gnorm=4.025, clip=100, loss_scale=128, train_wall=19, gb_free=10.8, wall=41698
2023-05-26 10:58:22 - progress_bar.py[line:272] - INFO: epoch 013:   1453 / 1732 loss=2.258, loss_v1=0, loss_v2=0, nll_loss=1.044, ntokens=1116.6, nsentences=32, sample_size=1116.6, sample_size_v1=0, sample_size_v2=0, ppl=2.06, wps=594.2, ups=0.53, wpb=1116.6, bsz=32, num_updates=22200, lr=1.8279e-05, gnorm=4.458, clip=100, loss_scale=128, train_wall=19, gb_free=10.8, wall=41717
2023-05-26 10:58:41 - progress_bar.py[line:272] - INFO: epoch 013:   1463 / 1732 loss=2.223, loss_v1=0, loss_v2=0, nll_loss=1.004, ntokens=1191.9, nsentences=32, sample_size=1191.9, sample_size_v1=0, sample_size_v2=0, ppl=2.01, wps=626.7, ups=0.53, wpb=1191.9, bsz=32, num_updates=22210, lr=1.82728e-05, gnorm=3.984, clip=100, loss_scale=128, train_wall=19, gb_free=10.3, wall=41736
2023-05-26 10:59:00 - progress_bar.py[line:272] - INFO: epoch 013:   1473 / 1732 loss=2.238, loss_v1=0, loss_v2=0, nll_loss=1.023, ntokens=1103.1, nsentences=32, sample_size=1103.1, sample_size_v1=0, sample_size_v2=0, ppl=2.03, wps=585.6, ups=0.53, wpb=1103.1, bsz=32, num_updates=22220, lr=1.82667e-05, gnorm=4.555, clip=100, loss_scale=128, train_wall=19, gb_free=11.3, wall=41755
2023-05-26 10:59:19 - progress_bar.py[line:272] - INFO: epoch 013:   1483 / 1732 loss=2.272, loss_v1=0, loss_v2=0, nll_loss=1.059, ntokens=1083.9, nsentences=32, sample_size=1083.9, sample_size_v1=0, sample_size_v2=0, ppl=2.08, wps=577.6, ups=0.53, wpb=1083.9, bsz=32, num_updates=22230, lr=1.82605e-05, gnorm=4.396, clip=100, loss_scale=128, train_wall=19, gb_free=11.7, wall=41773
2023-05-26 10:59:38 - progress_bar.py[line:272] - INFO: epoch 013:   1493 / 1732 loss=2.247, loss_v1=0, loss_v2=0, nll_loss=1.032, ntokens=1119.2, nsentences=32, sample_size=1119.2, sample_size_v1=0, sample_size_v2=0, ppl=2.04, wps=589.8, ups=0.53, wpb=1119.2, bsz=32, num_updates=22240, lr=1.82544e-05, gnorm=4.223, clip=100, loss_scale=128, train_wall=19, gb_free=11.6, wall=41792
2023-05-26 10:59:57 - progress_bar.py[line:272] - INFO: epoch 013:   1503 / 1732 loss=2.206, loss_v1=0, loss_v2=0, nll_loss=0.987, ntokens=1138.8, nsentences=32, sample_size=1138.8, sample_size_v1=0, sample_size_v2=0, ppl=1.98, wps=602.3, ups=0.53, wpb=1138.8, bsz=32, num_updates=22250, lr=1.82483e-05, gnorm=4.067, clip=100, loss_scale=128, train_wall=19, gb_free=11.6, wall=41811
2023-05-26 11:00:15 - progress_bar.py[line:272] - INFO: epoch 013:   1513 / 1732 loss=2.236, loss_v1=0, loss_v2=0, nll_loss=1.02, ntokens=1063.2, nsentences=32, sample_size=1063.2, sample_size_v1=0, sample_size_v2=0, ppl=2.03, wps=566.7, ups=0.53, wpb=1063.2, bsz=32, num_updates=22260, lr=1.82421e-05, gnorm=4.39, clip=100, loss_scale=128, train_wall=19, gb_free=11.2, wall=41830
2023-05-26 11:00:34 - progress_bar.py[line:272] - INFO: epoch 013:   1523 / 1732 loss=2.288, loss_v1=0, loss_v2=0, nll_loss=1.078, ntokens=1020.5, nsentences=32, sample_size=1020.5, sample_size_v1=0, sample_size_v2=0, ppl=2.11, wps=545.8, ups=0.53, wpb=1020.5, bsz=32, num_updates=22270, lr=1.8236e-05, gnorm=4.539, clip=100, loss_scale=128, train_wall=19, gb_free=11.2, wall=41849
2023-05-26 11:00:53 - progress_bar.py[line:272] - INFO: epoch 013:   1533 / 1732 loss=2.253, loss_v1=0, loss_v2=0, nll_loss=1.039, ntokens=1081, nsentences=32, sample_size=1081, sample_size_v1=0, sample_size_v2=0, ppl=2.06, wps=570.4, ups=0.53, wpb=1081, bsz=32, num_updates=22280, lr=1.82298e-05, gnorm=4.253, clip=100, loss_scale=128, train_wall=19, gb_free=11.2, wall=41868
2023-05-26 11:01:12 - progress_bar.py[line:272] - INFO: epoch 013:   1543 / 1732 loss=2.232, loss_v1=0, loss_v2=0, nll_loss=1.014, ntokens=1109.5, nsentences=32, sample_size=1109.5, sample_size_v1=0, sample_size_v2=0, ppl=2.02, wps=586.5, ups=0.53, wpb=1109.5, bsz=32, num_updates=22290, lr=1.82237e-05, gnorm=4.353, clip=100, loss_scale=128, train_wall=19, gb_free=10.9, wall=41887
2023-05-26 11:01:31 - progress_bar.py[line:272] - INFO: epoch 013:   1553 / 1732 loss=2.223, loss_v1=0, loss_v2=0, nll_loss=1.005, ntokens=1034.9, nsentences=32, sample_size=1034.9, sample_size_v1=0, sample_size_v2=0, ppl=2.01, wps=552, ups=0.53, wpb=1034.9, bsz=32, num_updates=22300, lr=1.82176e-05, gnorm=4.169, clip=100, loss_scale=128, train_wall=19, gb_free=11.3, wall=41905
2023-05-26 11:01:49 - progress_bar.py[line:272] - INFO: epoch 013:   1563 / 1732 loss=2.241, loss_v1=0, loss_v2=0, nll_loss=1.026, ntokens=1130.9, nsentences=32, sample_size=1130.9, sample_size_v1=0, sample_size_v2=0, ppl=2.04, wps=600.4, ups=0.53, wpb=1130.9, bsz=32, num_updates=22310, lr=1.82114e-05, gnorm=3.609, clip=100, loss_scale=128, train_wall=19, gb_free=11.7, wall=41924
2023-05-26 11:02:08 - progress_bar.py[line:272] - INFO: epoch 013:   1573 / 1732 loss=2.263, loss_v1=0, loss_v2=0, nll_loss=1.049, ntokens=1064.8, nsentences=32, sample_size=1064.8, sample_size_v1=0, sample_size_v2=0, ppl=2.07, wps=564.8, ups=0.53, wpb=1064.8, bsz=32, num_updates=22320, lr=1.82053e-05, gnorm=4.301, clip=100, loss_scale=128, train_wall=19, gb_free=10.8, wall=41943
2023-05-26 11:02:27 - progress_bar.py[line:272] - INFO: epoch 013:   1583 / 1732 loss=2.273, loss_v1=0, loss_v2=0, nll_loss=1.062, ntokens=1007.5, nsentences=32, sample_size=1007.5, sample_size_v1=0, sample_size_v2=0, ppl=2.09, wps=536.3, ups=0.53, wpb=1007.5, bsz=32, num_updates=22330, lr=1.81991e-05, gnorm=4.561, clip=100, loss_scale=128, train_wall=19, gb_free=11.3, wall=41962
2023-05-26 11:02:46 - progress_bar.py[line:272] - INFO: epoch 013:   1593 / 1732 loss=2.221, loss_v1=0, loss_v2=0, nll_loss=1.004, ntokens=1081.3, nsentences=32, sample_size=1081.3, sample_size_v1=0, sample_size_v2=0, ppl=2.01, wps=574.6, ups=0.53, wpb=1081.3, bsz=32, num_updates=22340, lr=1.8193e-05, gnorm=4.104, clip=100, loss_scale=128, train_wall=19, gb_free=11.6, wall=41981
2023-05-26 11:03:05 - progress_bar.py[line:272] - INFO: epoch 013:   1603 / 1732 loss=2.211, loss_v1=0, loss_v2=0, nll_loss=0.993, ntokens=1092.4, nsentences=32, sample_size=1092.4, sample_size_v1=0, sample_size_v2=0, ppl=1.99, wps=580.7, ups=0.53, wpb=1092.4, bsz=32, num_updates=22350, lr=1.81868e-05, gnorm=4.125, clip=100, loss_scale=128, train_wall=19, gb_free=11.7, wall=41999
2023-05-26 11:03:24 - progress_bar.py[line:272] - INFO: epoch 013:   1613 / 1732 loss=2.217, loss_v1=0, loss_v2=0, nll_loss=0.997, ntokens=1153.1, nsentences=32, sample_size=1153.1, sample_size_v1=0, sample_size_v2=0, ppl=2, wps=605.7, ups=0.53, wpb=1153.1, bsz=32, num_updates=22360, lr=1.81807e-05, gnorm=4.309, clip=100, loss_scale=128, train_wall=19, gb_free=10.7, wall=42018
2023-05-26 11:03:43 - progress_bar.py[line:272] - INFO: epoch 013:   1623 / 1732 loss=2.227, loss_v1=0, loss_v2=0, nll_loss=1.01, ntokens=1098.4, nsentences=32, sample_size=1098.4, sample_size_v1=0, sample_size_v2=0, ppl=2.01, wps=580.1, ups=0.53, wpb=1098.4, bsz=32, num_updates=22370, lr=1.81746e-05, gnorm=4.62, clip=100, loss_scale=128, train_wall=19, gb_free=10.9, wall=42037
2023-05-26 11:04:02 - progress_bar.py[line:272] - INFO: epoch 013:   1633 / 1732 loss=2.221, loss_v1=0, loss_v2=0, nll_loss=1.003, ntokens=1178.3, nsentences=32, sample_size=1178.3, sample_size_v1=0, sample_size_v2=0, ppl=2, wps=622.5, ups=0.53, wpb=1178.3, bsz=32, num_updates=22380, lr=1.81684e-05, gnorm=4.109, clip=100, loss_scale=128, train_wall=19, gb_free=11.5, wall=42056
2023-05-26 11:04:21 - progress_bar.py[line:272] - INFO: epoch 013:   1643 / 1732 loss=2.216, loss_v1=0, loss_v2=0, nll_loss=0.998, ntokens=1238.2, nsentences=32, sample_size=1238.2, sample_size_v1=0, sample_size_v2=0, ppl=2, wps=653, ups=0.53, wpb=1238.2, bsz=32, num_updates=22390, lr=1.81623e-05, gnorm=4.077, clip=100, loss_scale=128, train_wall=19, gb_free=11.3, wall=42075
2023-05-26 11:04:39 - progress_bar.py[line:272] - INFO: epoch 013:   1653 / 1732 loss=2.25, loss_v1=0, loss_v2=0, nll_loss=1.035, ntokens=993.8, nsentences=32, sample_size=993.8, sample_size_v1=0, sample_size_v2=0, ppl=2.05, wps=530.2, ups=0.53, wpb=993.8, bsz=32, num_updates=22400, lr=1.81561e-05, gnorm=4.789, clip=100, loss_scale=128, train_wall=19, gb_free=11.6, wall=42094
2023-05-26 11:04:58 - progress_bar.py[line:272] - INFO: epoch 013:   1663 / 1732 loss=2.257, loss_v1=0, loss_v2=0, nll_loss=1.044, ntokens=1051.4, nsentences=32, sample_size=1051.4, sample_size_v1=0, sample_size_v2=0, ppl=2.06, wps=557.1, ups=0.53, wpb=1051.4, bsz=32, num_updates=22410, lr=1.815e-05, gnorm=4.517, clip=100, loss_scale=128, train_wall=19, gb_free=11.1, wall=42113
2023-05-26 11:05:17 - progress_bar.py[line:272] - INFO: epoch 013:   1673 / 1732 loss=2.218, loss_v1=0, loss_v2=0, nll_loss=1, ntokens=1033, nsentences=32, sample_size=1033, sample_size_v1=0, sample_size_v2=0, ppl=2, wps=552.9, ups=0.54, wpb=1033, bsz=32, num_updates=22420, lr=1.81438e-05, gnorm=4.705, clip=100, loss_scale=128, train_wall=19, gb_free=10.8, wall=42132
2023-05-26 11:05:36 - progress_bar.py[line:272] - INFO: epoch 013:   1683 / 1732 loss=2.205, loss_v1=0, loss_v2=0, nll_loss=0.984, ntokens=1168.8, nsentences=32, sample_size=1168.8, sample_size_v1=0, sample_size_v2=0, ppl=1.98, wps=615.3, ups=0.53, wpb=1168.8, bsz=32, num_updates=22430, lr=1.81377e-05, gnorm=4.006, clip=100, loss_scale=128, train_wall=19, gb_free=11.2, wall=42151
2023-05-26 11:05:55 - progress_bar.py[line:272] - INFO: epoch 013:   1693 / 1732 loss=2.213, loss_v1=0, loss_v2=0, nll_loss=0.995, ntokens=1251.1, nsentences=32, sample_size=1251.1, sample_size_v1=0, sample_size_v2=0, ppl=1.99, wps=651.6, ups=0.52, wpb=1251.1, bsz=32, num_updates=22440, lr=1.81316e-05, gnorm=3.687, clip=100, loss_scale=128, train_wall=19, gb_free=11.1, wall=42170
2023-05-26 11:06:12 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 128.0
2023-05-26 11:06:16 - progress_bar.py[line:272] - INFO: epoch 013:   1704 / 1732 loss=2.243, loss_v1=0, loss_v2=0, nll_loss=1.028, ntokens=1219.8, nsentences=32, sample_size=1219.8, sample_size_v1=0, sample_size_v2=0, ppl=2.04, wps=581.9, ups=0.48, wpb=1219.8, bsz=32, num_updates=22450, lr=1.81254e-05, gnorm=4.024, clip=100, loss_scale=128, train_wall=21, gb_free=11.3, wall=42191
2023-05-26 11:06:35 - progress_bar.py[line:272] - INFO: epoch 013:   1714 / 1732 loss=2.236, loss_v1=0, loss_v2=0, nll_loss=1.018, ntokens=1181.2, nsentences=32, sample_size=1181.2, sample_size_v1=0, sample_size_v2=0, ppl=2.03, wps=622.7, ups=0.53, wpb=1181.2, bsz=32, num_updates=22460, lr=1.81193e-05, gnorm=4.225, clip=100, loss_scale=128, train_wall=19, gb_free=11.2, wall=42210
2023-05-26 11:06:54 - progress_bar.py[line:272] - INFO: epoch 013:   1724 / 1732 loss=2.228, loss_v1=0, loss_v2=0, nll_loss=1.012, ntokens=1135.1, nsentences=32, sample_size=1135.1, sample_size_v1=0, sample_size_v2=0, ppl=2.02, wps=597.2, ups=0.53, wpb=1135.1, bsz=32, num_updates=22470, lr=1.81131e-05, gnorm=4.113, clip=100, loss_scale=128, train_wall=19, gb_free=11.7, wall=42229
2023-05-26 11:07:08 - train.py[line:332] - INFO: end of epoch 13 (average epoch stats below)
2023-05-26 11:07:08 - progress_bar.py[line:282] - INFO: epoch 013 | loss 2.25 | loss_v1 0 | loss_v2 0 | nll_loss 1.036 | ntokens 1051.42 | nsentences 31.986 | sample_size 1051.42 | sample_size_v1 0 | sample_size_v2 0 | ppl 2.05 | wps 559.3 | ups 0.53 | wpb 1051.4 | bsz 32 | num_updates 22478 | lr 1.81082e-05 | gnorm 4.094 | clip 100 | loss_scale 128 | train_wall 3241 | gb_free 11.7 | wall 42243
2023-05-26 11:07:08 - trainer.py[line:639] - INFO: loading train data for epoch 14
local datafile ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 0 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 0 finished initializing row_count and line_idx-to-offset mapping
file ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 0 row count 55400 total row count 55400
slice_id 0 seek offset 0
2023-05-26 11:07:10 - trainer.py[line:703] - INFO: begin training epoch 14
2023-05-26 11:07:10 - train.py[line:305] - INFO: Start iterating over samples
2023-05-26 11:07:14 - progress_bar.py[line:272] - INFO: epoch 014:      2 / 1732 loss=2.279, loss_v1=0, loss_v2=0, nll_loss=1.066, ntokens=1104.4, nsentences=29.6, sample_size=1104.4, sample_size_v1=0, sample_size_v2=0, ppl=2.09, wps=558.6, ups=0.51, wpb=1104.4, bsz=29.6, num_updates=22480, lr=1.8107e-05, gnorm=4.327, clip=100, loss_scale=128, train_wall=18, gb_free=10.9, wall=42249
2023-05-26 11:07:33 - progress_bar.py[line:272] - INFO: epoch 014:     12 / 1732 loss=2.189, loss_v1=0, loss_v2=0, nll_loss=0.967, ntokens=1057.9, nsentences=32, sample_size=1057.9, sample_size_v1=0, sample_size_v2=0, ppl=1.95, wps=559.2, ups=0.53, wpb=1057.9, bsz=32, num_updates=22490, lr=1.81009e-05, gnorm=4.489, clip=100, loss_scale=128, train_wall=19, gb_free=11.6, wall=42267
2023-05-26 11:07:52 - progress_bar.py[line:272] - INFO: epoch 014:     22 / 1732 loss=2.138, loss_v1=0, loss_v2=0, nll_loss=0.913, ntokens=1106.7, nsentences=32, sample_size=1106.7, sample_size_v1=0, sample_size_v2=0, ppl=1.88, wps=586.7, ups=0.53, wpb=1106.7, bsz=32, num_updates=22500, lr=1.80947e-05, gnorm=4.286, clip=100, loss_scale=128, train_wall=19, gb_free=11.4, wall=42286
2023-05-26 11:08:11 - progress_bar.py[line:272] - INFO: epoch 014:     32 / 1732 loss=2.156, loss_v1=0, loss_v2=0, nll_loss=0.93, ntokens=985.4, nsentences=32, sample_size=985.4, sample_size_v1=0, sample_size_v2=0, ppl=1.91, wps=523.3, ups=0.53, wpb=985.4, bsz=32, num_updates=22510, lr=1.80886e-05, gnorm=4.33, clip=100, loss_scale=128, train_wall=19, gb_free=10.5, wall=42305
2023-05-26 11:08:30 - progress_bar.py[line:272] - INFO: epoch 014:     42 / 1732 loss=2.051, loss_v1=0, loss_v2=0, nll_loss=0.816, ntokens=1168.8, nsentences=32, sample_size=1168.8, sample_size_v1=0, sample_size_v2=0, ppl=1.76, wps=615.1, ups=0.53, wpb=1168.8, bsz=32, num_updates=22520, lr=1.80824e-05, gnorm=3.526, clip=100, loss_scale=128, train_wall=19, gb_free=11.9, wall=42324
2023-05-26 11:08:48 - progress_bar.py[line:272] - INFO: epoch 014:     52 / 1732 loss=2.101, loss_v1=0, loss_v2=0, nll_loss=0.87, ntokens=1030.1, nsentences=32, sample_size=1030.1, sample_size_v1=0, sample_size_v2=0, ppl=1.83, wps=545.4, ups=0.53, wpb=1030.1, bsz=32, num_updates=22530, lr=1.80763e-05, gnorm=3.776, clip=100, loss_scale=128, train_wall=19, gb_free=11.7, wall=42343
2023-05-26 11:09:07 - progress_bar.py[line:272] - INFO: epoch 014:     62 / 1732 loss=1.937, loss_v1=0, loss_v2=0, nll_loss=0.687, ntokens=1192.6, nsentences=32, sample_size=1192.6, sample_size_v1=0, sample_size_v2=0, ppl=1.61, wps=630.3, ups=0.53, wpb=1192.6, bsz=32, num_updates=22540, lr=1.80701e-05, gnorm=3.331, clip=100, loss_scale=128, train_wall=19, gb_free=10.7, wall=42362
2023-05-26 11:09:27 - progress_bar.py[line:272] - INFO: epoch 014:     72 / 1732 loss=2.02, loss_v1=0, loss_v2=0, nll_loss=0.78, ntokens=1389.6, nsentences=32, sample_size=1389.6, sample_size_v1=0, sample_size_v2=0, ppl=1.72, wps=713.2, ups=0.51, wpb=1389.6, bsz=32, num_updates=22550, lr=1.8064e-05, gnorm=2.996, clip=100, loss_scale=128, train_wall=19, gb_free=10.7, wall=42381
2023-05-26 11:09:46 - progress_bar.py[line:272] - INFO: epoch 014:     82 / 1732 loss=2.057, loss_v1=0, loss_v2=0, nll_loss=0.819, ntokens=1199, nsentences=32, sample_size=1199, sample_size_v1=0, sample_size_v2=0, ppl=1.76, wps=621.3, ups=0.52, wpb=1199, bsz=32, num_updates=22560, lr=1.80579e-05, gnorm=3.961, clip=100, loss_scale=128, train_wall=19, gb_free=10.8, wall=42401
2023-05-26 11:10:05 - progress_bar.py[line:272] - INFO: epoch 014:     92 / 1732 loss=2.074, loss_v1=0, loss_v2=0, nll_loss=0.837, ntokens=1081.9, nsentences=32, sample_size=1081.9, sample_size_v1=0, sample_size_v2=0, ppl=1.79, wps=567.4, ups=0.52, wpb=1081.9, bsz=32, num_updates=22570, lr=1.80517e-05, gnorm=3.888, clip=100, loss_scale=128, train_wall=19, gb_free=11.1, wall=42420
2023-05-26 11:10:24 - progress_bar.py[line:272] - INFO: epoch 014:    102 / 1732 loss=2.138, loss_v1=0, loss_v2=0, nll_loss=0.914, ntokens=1017.7, nsentences=32, sample_size=1017.7, sample_size_v1=0, sample_size_v2=0, ppl=1.88, wps=543.5, ups=0.53, wpb=1017.7, bsz=32, num_updates=22580, lr=1.80456e-05, gnorm=4.13, clip=100, loss_scale=128, train_wall=19, gb_free=11, wall=42439
2023-05-26 11:10:43 - progress_bar.py[line:272] - INFO: epoch 014:    112 / 1732 loss=2.26, loss_v1=0, loss_v2=0, nll_loss=1.049, ntokens=1026.3, nsentences=32, sample_size=1026.3, sample_size_v1=0, sample_size_v2=0, ppl=2.07, wps=544.4, ups=0.53, wpb=1026.3, bsz=32, num_updates=22590, lr=1.80394e-05, gnorm=4.377, clip=100, loss_scale=128, train_wall=19, gb_free=10.2, wall=42457
2023-05-26 11:11:02 - progress_bar.py[line:272] - INFO: epoch 014:    122 / 1732 loss=2.235, loss_v1=0, loss_v2=0, nll_loss=1.018, ntokens=1103.7, nsentences=32, sample_size=1103.7, sample_size_v1=0, sample_size_v2=0, ppl=2.03, wps=576.1, ups=0.52, wpb=1103.7, bsz=32, num_updates=22600, lr=1.80333e-05, gnorm=4.751, clip=100, loss_scale=128, train_wall=19, gb_free=10.8, wall=42477
2023-05-26 11:11:21 - progress_bar.py[line:272] - INFO: epoch 014:    132 / 1732 loss=2.195, loss_v1=0, loss_v2=0, nll_loss=0.972, ntokens=1224.5, nsentences=32, sample_size=1224.5, sample_size_v1=0, sample_size_v2=0, ppl=1.96, wps=638.1, ups=0.52, wpb=1224.5, bsz=32, num_updates=22610, lr=1.80271e-05, gnorm=4.011, clip=100, loss_scale=128, train_wall=19, gb_free=10.7, wall=42496
2023-05-26 11:11:40 - progress_bar.py[line:272] - INFO: epoch 014:    142 / 1732 loss=2.168, loss_v1=0, loss_v2=0, nll_loss=0.943, ntokens=1223.2, nsentences=32, sample_size=1223.2, sample_size_v1=0, sample_size_v2=0, ppl=1.92, wps=638, ups=0.52, wpb=1223.2, bsz=32, num_updates=22620, lr=1.8021e-05, gnorm=3.93, clip=100, loss_scale=128, train_wall=19, gb_free=10.8, wall=42515
2023-05-26 11:12:00 - progress_bar.py[line:272] - INFO: epoch 014:    152 / 1732 loss=2.164, loss_v1=0, loss_v2=0, nll_loss=0.941, ntokens=1158.5, nsentences=32, sample_size=1158.5, sample_size_v1=0, sample_size_v2=0, ppl=1.92, wps=602.7, ups=0.52, wpb=1158.5, bsz=32, num_updates=22630, lr=1.80149e-05, gnorm=3.878, clip=100, loss_scale=128, train_wall=19, gb_free=10.7, wall=42534
2023-05-26 11:12:19 - progress_bar.py[line:272] - INFO: epoch 014:    162 / 1732 loss=2.178, loss_v1=0, loss_v2=0, nll_loss=0.956, ntokens=1101.3, nsentences=32, sample_size=1101.3, sample_size_v1=0, sample_size_v2=0, ppl=1.94, wps=577.9, ups=0.52, wpb=1101.3, bsz=32, num_updates=22640, lr=1.80087e-05, gnorm=4.192, clip=100, loss_scale=128, train_wall=19, gb_free=11, wall=42553
2023-05-26 11:12:37 - progress_bar.py[line:272] - INFO: epoch 014:    172 / 1732 loss=2.205, loss_v1=0, loss_v2=0, nll_loss=0.983, ntokens=937.9, nsentences=32, sample_size=937.9, sample_size_v1=0, sample_size_v2=0, ppl=1.98, wps=499.5, ups=0.53, wpb=937.9, bsz=32, num_updates=22650, lr=1.80026e-05, gnorm=4.812, clip=100, loss_scale=128, train_wall=19, gb_free=11.2, wall=42572
2023-05-26 11:12:56 - progress_bar.py[line:272] - INFO: epoch 014:    182 / 1732 loss=2.144, loss_v1=0, loss_v2=0, nll_loss=0.918, ntokens=1177.8, nsentences=32, sample_size=1177.8, sample_size_v1=0, sample_size_v2=0, ppl=1.89, wps=616.2, ups=0.52, wpb=1177.8, bsz=32, num_updates=22660, lr=1.79964e-05, gnorm=3.999, clip=100, loss_scale=128, train_wall=19, gb_free=10.6, wall=42591
2023-05-26 11:13:15 - progress_bar.py[line:272] - INFO: epoch 014:    192 / 1732 loss=2.156, loss_v1=0, loss_v2=0, nll_loss=0.931, ntokens=1116, nsentences=32, sample_size=1116, sample_size_v1=0, sample_size_v2=0, ppl=1.91, wps=587.6, ups=0.53, wpb=1116, bsz=32, num_updates=22670, lr=1.79903e-05, gnorm=3.867, clip=100, loss_scale=128, train_wall=19, gb_free=10.6, wall=42610
2023-05-26 11:13:34 - progress_bar.py[line:272] - INFO: epoch 014:    202 / 1732 loss=2.23, loss_v1=0, loss_v2=0, nll_loss=1.013, ntokens=1088.7, nsentences=32, sample_size=1088.7, sample_size_v1=0, sample_size_v2=0, ppl=2.02, wps=578.2, ups=0.53, wpb=1088.7, bsz=32, num_updates=22680, lr=1.79842e-05, gnorm=4.344, clip=100, loss_scale=128, train_wall=19, gb_free=10.7, wall=42629
2023-05-26 11:13:53 - progress_bar.py[line:272] - INFO: epoch 014:    212 / 1732 loss=2.258, loss_v1=0, loss_v2=0, nll_loss=1.044, ntokens=1014.1, nsentences=32, sample_size=1014.1, sample_size_v1=0, sample_size_v2=0, ppl=2.06, wps=542.7, ups=0.54, wpb=1014.1, bsz=32, num_updates=22690, lr=1.7978e-05, gnorm=4.593, clip=100, loss_scale=128, train_wall=19, gb_free=11, wall=42648
2023-05-26 11:14:12 - progress_bar.py[line:272] - INFO: epoch 014:    222 / 1732 loss=2.267, loss_v1=0, loss_v2=0, nll_loss=1.053, ntokens=1144.1, nsentences=32, sample_size=1144.1, sample_size_v1=0, sample_size_v2=0, ppl=2.08, wps=611.5, ups=0.53, wpb=1144.1, bsz=32, num_updates=22700, lr=1.79719e-05, gnorm=4.399, clip=100, loss_scale=128, train_wall=19, gb_free=10.8, wall=42666
2023-05-26 11:14:30 - progress_bar.py[line:272] - INFO: epoch 014:    232 / 1732 loss=2.274, loss_v1=0, loss_v2=0, nll_loss=1.062, ntokens=1097.8, nsentences=32, sample_size=1097.8, sample_size_v1=0, sample_size_v2=0, ppl=2.09, wps=587.9, ups=0.54, wpb=1097.8, bsz=32, num_updates=22710, lr=1.79657e-05, gnorm=4.074, clip=100, loss_scale=128, train_wall=19, gb_free=11.3, wall=42685
2023-05-26 11:14:49 - progress_bar.py[line:272] - INFO: epoch 014:    242 / 1732 loss=2.269, loss_v1=0, loss_v2=0, nll_loss=1.057, ntokens=1115.1, nsentences=32, sample_size=1115.1, sample_size_v1=0, sample_size_v2=0, ppl=2.08, wps=594.2, ups=0.53, wpb=1115.1, bsz=32, num_updates=22720, lr=1.79596e-05, gnorm=4.065, clip=100, loss_scale=128, train_wall=19, gb_free=10.8, wall=42704
2023-05-26 11:15:08 - progress_bar.py[line:272] - INFO: epoch 014:    252 / 1732 loss=2.279, loss_v1=0, loss_v2=0, nll_loss=1.069, ntokens=1167.7, nsentences=32, sample_size=1167.7, sample_size_v1=0, sample_size_v2=0, ppl=2.1, wps=622.5, ups=0.53, wpb=1167.7, bsz=32, num_updates=22730, lr=1.79534e-05, gnorm=3.937, clip=100, loss_scale=128, train_wall=19, gb_free=11.5, wall=42723
2023-05-26 11:15:27 - progress_bar.py[line:272] - INFO: epoch 014:    262 / 1732 loss=2.288, loss_v1=0, loss_v2=0, nll_loss=1.077, ntokens=1134.1, nsentences=32, sample_size=1134.1, sample_size_v1=0, sample_size_v2=0, ppl=2.11, wps=606.4, ups=0.53, wpb=1134.1, bsz=32, num_updates=22740, lr=1.79473e-05, gnorm=4.216, clip=100, loss_scale=128, train_wall=19, gb_free=11.3, wall=42741
2023-05-26 11:15:45 - progress_bar.py[line:272] - INFO: epoch 014:    272 / 1732 loss=2.248, loss_v1=0, loss_v2=0, nll_loss=1.032, ntokens=1139, nsentences=32, sample_size=1139, sample_size_v1=0, sample_size_v2=0, ppl=2.04, wps=606, ups=0.53, wpb=1139, bsz=32, num_updates=22750, lr=1.79412e-05, gnorm=4.134, clip=100, loss_scale=128, train_wall=19, gb_free=11.6, wall=42760
2023-05-26 11:16:04 - progress_bar.py[line:272] - INFO: epoch 014:    282 / 1732 loss=2.278, loss_v1=0, loss_v2=0, nll_loss=1.066, ntokens=1161.5, nsentences=32, sample_size=1161.5, sample_size_v1=0, sample_size_v2=0, ppl=2.09, wps=614.4, ups=0.53, wpb=1161.5, bsz=32, num_updates=22760, lr=1.7935e-05, gnorm=4.168, clip=100, loss_scale=128, train_wall=19, gb_free=10.7, wall=42779
2023-05-26 11:16:23 - progress_bar.py[line:272] - INFO: epoch 014:    292 / 1732 loss=2.247, loss_v1=0, loss_v2=0, nll_loss=1.033, ntokens=1114.9, nsentences=32, sample_size=1114.9, sample_size_v1=0, sample_size_v2=0, ppl=2.05, wps=595.7, ups=0.53, wpb=1114.9, bsz=32, num_updates=22770, lr=1.79289e-05, gnorm=4.193, clip=100, loss_scale=128, train_wall=19, gb_free=11.2, wall=42798
2023-05-26 11:16:42 - progress_bar.py[line:272] - INFO: epoch 014:    302 / 1732 loss=2.252, loss_v1=0, loss_v2=0, nll_loss=1.038, ntokens=1109.4, nsentences=32, sample_size=1109.4, sample_size_v1=0, sample_size_v2=0, ppl=2.05, wps=592.2, ups=0.53, wpb=1109.4, bsz=32, num_updates=22780, lr=1.79227e-05, gnorm=4.153, clip=100, loss_scale=128, train_wall=19, gb_free=11.5, wall=42816
2023-05-26 11:17:01 - progress_bar.py[line:272] - INFO: epoch 014:    312 / 1732 loss=2.256, loss_v1=0, loss_v2=0, nll_loss=1.042, ntokens=1061.9, nsentences=32, sample_size=1061.9, sample_size_v1=0, sample_size_v2=0, ppl=2.06, wps=566.9, ups=0.53, wpb=1061.9, bsz=32, num_updates=22790, lr=1.79166e-05, gnorm=4.443, clip=100, loss_scale=128, train_wall=19, gb_free=11.5, wall=42835
2023-05-26 11:17:19 - progress_bar.py[line:272] - INFO: epoch 014:    322 / 1732 loss=2.302, loss_v1=0, loss_v2=0, nll_loss=1.092, ntokens=1000.1, nsentences=32, sample_size=1000.1, sample_size_v1=0, sample_size_v2=0, ppl=2.13, wps=538.6, ups=0.54, wpb=1000.1, bsz=32, num_updates=22800, lr=1.79104e-05, gnorm=5.069, clip=100, loss_scale=128, train_wall=19, gb_free=11.3, wall=42854
2023-05-26 11:17:38 - progress_bar.py[line:272] - INFO: epoch 014:    332 / 1732 loss=2.293, loss_v1=0, loss_v2=0, nll_loss=1.084, ntokens=1031.9, nsentences=32, sample_size=1031.9, sample_size_v1=0, sample_size_v2=0, ppl=2.12, wps=555.2, ups=0.54, wpb=1031.9, bsz=32, num_updates=22810, lr=1.79043e-05, gnorm=4.531, clip=100, loss_scale=128, train_wall=19, gb_free=11.2, wall=42872
2023-05-26 11:17:56 - progress_bar.py[line:272] - INFO: epoch 014:    342 / 1732 loss=2.249, loss_v1=0, loss_v2=0, nll_loss=1.034, ntokens=926.6, nsentences=32, sample_size=926.6, sample_size_v1=0, sample_size_v2=0, ppl=2.05, wps=502.5, ups=0.54, wpb=926.6, bsz=32, num_updates=22820, lr=1.78982e-05, gnorm=4.808, clip=100, loss_scale=128, train_wall=18, gb_free=11.8, wall=42891
2023-05-26 11:18:15 - progress_bar.py[line:272] - INFO: epoch 014:    352 / 1732 loss=2.269, loss_v1=0, loss_v2=0, nll_loss=1.057, ntokens=952.9, nsentences=32, sample_size=952.9, sample_size_v1=0, sample_size_v2=0, ppl=2.08, wps=514.3, ups=0.54, wpb=952.9, bsz=32, num_updates=22830, lr=1.7892e-05, gnorm=4.953, clip=100, loss_scale=128, train_wall=18, gb_free=11.8, wall=42909
2023-05-26 11:18:33 - progress_bar.py[line:272] - INFO: epoch 014:    362 / 1732 loss=2.299, loss_v1=0, loss_v2=0, nll_loss=1.091, ntokens=940.7, nsentences=32, sample_size=940.7, sample_size_v1=0, sample_size_v2=0, ppl=2.13, wps=507.8, ups=0.54, wpb=940.7, bsz=32, num_updates=22840, lr=1.78859e-05, gnorm=5.049, clip=100, loss_scale=128, train_wall=18, gb_free=11.6, wall=42928
2023-05-26 11:18:52 - progress_bar.py[line:272] - INFO: epoch 014:    372 / 1732 loss=2.288, loss_v1=0, loss_v2=0, nll_loss=1.076, ntokens=975.5, nsentences=32, sample_size=975.5, sample_size_v1=0, sample_size_v2=0, ppl=2.11, wps=525.8, ups=0.54, wpb=975.5, bsz=32, num_updates=22850, lr=1.78797e-05, gnorm=4.802, clip=100, loss_scale=128, train_wall=19, gb_free=11.7, wall=42946
2023-05-26 11:19:10 - progress_bar.py[line:272] - INFO: epoch 014:    382 / 1732 loss=2.297, loss_v1=0, loss_v2=0, nll_loss=1.086, ntokens=1062, nsentences=32, sample_size=1062, sample_size_v1=0, sample_size_v2=0, ppl=2.12, wps=572, ups=0.54, wpb=1062, bsz=32, num_updates=22860, lr=1.78736e-05, gnorm=4.512, clip=100, loss_scale=128, train_wall=19, gb_free=11.2, wall=42965
2023-05-26 11:19:29 - progress_bar.py[line:272] - INFO: epoch 014:    392 / 1732 loss=2.28, loss_v1=0, loss_v2=0, nll_loss=1.07, ntokens=1004.1, nsentences=32, sample_size=1004.1, sample_size_v1=0, sample_size_v2=0, ppl=2.1, wps=541.4, ups=0.54, wpb=1004.1, bsz=32, num_updates=22870, lr=1.78675e-05, gnorm=4.673, clip=100, loss_scale=128, train_wall=19, gb_free=11.8, wall=42984
2023-05-26 11:19:47 - progress_bar.py[line:272] - INFO: epoch 014:    402 / 1732 loss=2.272, loss_v1=0, loss_v2=0, nll_loss=1.061, ntokens=1005.2, nsentences=32, sample_size=1005.2, sample_size_v1=0, sample_size_v2=0, ppl=2.09, wps=540.8, ups=0.54, wpb=1005.2, bsz=32, num_updates=22880, lr=1.78613e-05, gnorm=4.903, clip=100, loss_scale=128, train_wall=19, gb_free=11.3, wall=43002
2023-05-26 11:20:06 - progress_bar.py[line:272] - INFO: epoch 014:    412 / 1732 loss=2.255, loss_v1=0, loss_v2=0, nll_loss=1.042, ntokens=1091.2, nsentences=32, sample_size=1091.2, sample_size_v1=0, sample_size_v2=0, ppl=2.06, wps=586, ups=0.54, wpb=1091.2, bsz=32, num_updates=22890, lr=1.78552e-05, gnorm=4.172, clip=100, loss_scale=128, train_wall=19, gb_free=11.3, wall=43021
2023-05-26 11:20:25 - progress_bar.py[line:272] - INFO: epoch 014:    422 / 1732 loss=2.236, loss_v1=0, loss_v2=0, nll_loss=1.02, ntokens=1011.2, nsentences=32, sample_size=1011.2, sample_size_v1=0, sample_size_v2=0, ppl=2.03, wps=543.3, ups=0.54, wpb=1011.2, bsz=32, num_updates=22900, lr=1.7849e-05, gnorm=4.545, clip=100, loss_scale=128, train_wall=19, gb_free=11.3, wall=43039
2023-05-26 11:20:43 - progress_bar.py[line:272] - INFO: epoch 014:    432 / 1732 loss=2.246, loss_v1=0, loss_v2=0, nll_loss=1.03, ntokens=1006.8, nsentences=32, sample_size=1006.8, sample_size_v1=0, sample_size_v2=0, ppl=2.04, wps=536.7, ups=0.53, wpb=1006.8, bsz=32, num_updates=22910, lr=1.78429e-05, gnorm=4.464, clip=100, loss_scale=128, train_wall=19, gb_free=11.7, wall=43058
2023-05-26 11:21:02 - progress_bar.py[line:272] - INFO: epoch 014:    442 / 1732 loss=2.277, loss_v1=0, loss_v2=0, nll_loss=1.065, ntokens=979.7, nsentences=32, sample_size=979.7, sample_size_v1=0, sample_size_v2=0, ppl=2.09, wps=526.9, ups=0.54, wpb=979.7, bsz=32, num_updates=22920, lr=1.78367e-05, gnorm=4.701, clip=100, loss_scale=128, train_wall=19, gb_free=11, wall=43077
2023-05-26 11:21:21 - progress_bar.py[line:272] - INFO: epoch 014:    452 / 1732 loss=2.272, loss_v1=0, loss_v2=0, nll_loss=1.06, ntokens=913.2, nsentences=32, sample_size=913.2, sample_size_v1=0, sample_size_v2=0, ppl=2.08, wps=494.1, ups=0.54, wpb=913.2, bsz=32, num_updates=22930, lr=1.78306e-05, gnorm=4.609, clip=100, loss_scale=128, train_wall=18, gb_free=11.9, wall=43095
2023-05-26 11:21:39 - progress_bar.py[line:272] - INFO: epoch 014:    462 / 1732 loss=2.296, loss_v1=0, loss_v2=0, nll_loss=1.088, ntokens=1070.3, nsentences=32, sample_size=1070.3, sample_size_v1=0, sample_size_v2=0, ppl=2.13, wps=576.4, ups=0.54, wpb=1070.3, bsz=32, num_updates=22940, lr=1.78245e-05, gnorm=4.612, clip=100, loss_scale=128, train_wall=19, gb_free=11, wall=43114
2023-05-26 11:21:58 - progress_bar.py[line:272] - INFO: epoch 014:    472 / 1732 loss=2.286, loss_v1=0, loss_v2=0, nll_loss=1.074, ntokens=1036.2, nsentences=32, sample_size=1036.2, sample_size_v1=0, sample_size_v2=0, ppl=2.11, wps=553.1, ups=0.53, wpb=1036.2, bsz=32, num_updates=22950, lr=1.78183e-05, gnorm=4.703, clip=100, loss_scale=128, train_wall=19, gb_free=11.1, wall=43133
2023-05-26 11:22:16 - progress_bar.py[line:272] - INFO: epoch 014:    482 / 1732 loss=2.269, loss_v1=0, loss_v2=0, nll_loss=1.055, ntokens=990.8, nsentences=32, sample_size=990.8, sample_size_v1=0, sample_size_v2=0, ppl=2.08, wps=534.8, ups=0.54, wpb=990.8, bsz=32, num_updates=22960, lr=1.78122e-05, gnorm=4.802, clip=100, loss_scale=256, train_wall=18, gb_free=11.9, wall=43151
2023-05-26 11:22:20 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 128.0
2023-05-26 11:22:37 - progress_bar.py[line:272] - INFO: epoch 014:    493 / 1732 loss=2.266, loss_v1=0, loss_v2=0, nll_loss=1.054, ntokens=925.6, nsentences=32, sample_size=925.6, sample_size_v1=0, sample_size_v2=0, ppl=2.08, wps=455, ups=0.49, wpb=925.6, bsz=32, num_updates=22970, lr=1.7806e-05, gnorm=4.771, clip=100, loss_scale=128, train_wall=20, gb_free=11.8, wall=43171
2023-05-26 11:22:55 - progress_bar.py[line:272] - INFO: epoch 014:    503 / 1732 loss=2.274, loss_v1=0, loss_v2=0, nll_loss=1.064, ntokens=988.6, nsentences=32, sample_size=988.6, sample_size_v1=0, sample_size_v2=0, ppl=2.09, wps=536.3, ups=0.54, wpb=988.6, bsz=32, num_updates=22980, lr=1.77999e-05, gnorm=5.109, clip=100, loss_scale=128, train_wall=18, gb_free=11.8, wall=43190
2023-05-26 11:23:14 - progress_bar.py[line:272] - INFO: epoch 014:    513 / 1732 loss=2.291, loss_v1=0, loss_v2=0, nll_loss=1.08, ntokens=1035, nsentences=32, sample_size=1035, sample_size_v1=0, sample_size_v2=0, ppl=2.11, wps=557.6, ups=0.54, wpb=1035, bsz=32, num_updates=22990, lr=1.77937e-05, gnorm=4.259, clip=100, loss_scale=128, train_wall=19, gb_free=11.7, wall=43208
2023-05-26 11:23:32 - progress_bar.py[line:272] - INFO: epoch 014:    523 / 1732 loss=2.253, loss_v1=0, loss_v2=0, nll_loss=1.039, ntokens=997.6, nsentences=32, sample_size=997.6, sample_size_v1=0, sample_size_v2=0, ppl=2.05, wps=539.6, ups=0.54, wpb=997.6, bsz=32, num_updates=23000, lr=1.77876e-05, gnorm=4.639, clip=100, loss_scale=128, train_wall=18, gb_free=11.8, wall=43227
2023-05-26 11:23:51 - progress_bar.py[line:272] - INFO: epoch 014:    533 / 1732 loss=2.261, loss_v1=0, loss_v2=0, nll_loss=1.049, ntokens=935, nsentences=32, sample_size=935, sample_size_v1=0, sample_size_v2=0, ppl=2.07, wps=507.4, ups=0.54, wpb=935, bsz=32, num_updates=23010, lr=1.77815e-05, gnorm=4.722, clip=100, loss_scale=128, train_wall=18, gb_free=11.8, wall=43245
2023-05-26 11:24:09 - progress_bar.py[line:272] - INFO: epoch 014:    543 / 1732 loss=2.279, loss_v1=0, loss_v2=0, nll_loss=1.067, ntokens=1003.8, nsentences=32, sample_size=1003.8, sample_size_v1=0, sample_size_v2=0, ppl=2.09, wps=542.2, ups=0.54, wpb=1003.8, bsz=32, num_updates=23020, lr=1.77753e-05, gnorm=4.845, clip=100, loss_scale=128, train_wall=18, gb_free=11.3, wall=43264
2023-05-26 11:24:28 - progress_bar.py[line:272] - INFO: epoch 014:    553 / 1732 loss=2.303, loss_v1=0, loss_v2=0, nll_loss=1.094, ntokens=1017.4, nsentences=32, sample_size=1017.4, sample_size_v1=0, sample_size_v2=0, ppl=2.14, wps=548, ups=0.54, wpb=1017.4, bsz=32, num_updates=23030, lr=1.77692e-05, gnorm=4.333, clip=100, loss_scale=128, train_wall=19, gb_free=11.8, wall=43282
2023-05-26 11:24:46 - progress_bar.py[line:272] - INFO: epoch 014:    563 / 1732 loss=2.296, loss_v1=0, loss_v2=0, nll_loss=1.086, ntokens=1008.2, nsentences=32, sample_size=1008.2, sample_size_v1=0, sample_size_v2=0, ppl=2.12, wps=542.5, ups=0.54, wpb=1008.2, bsz=32, num_updates=23040, lr=1.7763e-05, gnorm=4.712, clip=100, loss_scale=128, train_wall=19, gb_free=12, wall=43301
2023-05-26 11:25:05 - progress_bar.py[line:272] - INFO: epoch 014:    573 / 1732 loss=2.295, loss_v1=0, loss_v2=0, nll_loss=1.086, ntokens=1041.3, nsentences=32, sample_size=1041.3, sample_size_v1=0, sample_size_v2=0, ppl=2.12, wps=555.9, ups=0.53, wpb=1041.3, bsz=32, num_updates=23050, lr=1.77569e-05, gnorm=4.699, clip=100, loss_scale=128, train_wall=19, gb_free=11, wall=43320
2023-05-26 11:25:24 - progress_bar.py[line:272] - INFO: epoch 014:    583 / 1732 loss=2.285, loss_v1=0, loss_v2=0, nll_loss=1.075, ntokens=981.7, nsentences=32, sample_size=981.7, sample_size_v1=0, sample_size_v2=0, ppl=2.11, wps=525.5, ups=0.54, wpb=981.7, bsz=32, num_updates=23060, lr=1.77508e-05, gnorm=4.898, clip=100, loss_scale=128, train_wall=19, gb_free=11.8, wall=43338
2023-05-26 11:25:42 - progress_bar.py[line:272] - INFO: epoch 014:    593 / 1732 loss=2.245, loss_v1=0, loss_v2=0, nll_loss=1.029, ntokens=957.4, nsentences=32, sample_size=957.4, sample_size_v1=0, sample_size_v2=0, ppl=2.04, wps=513.1, ups=0.54, wpb=957.4, bsz=32, num_updates=23070, lr=1.77446e-05, gnorm=4.864, clip=100, loss_scale=128, train_wall=19, gb_free=11.7, wall=43357
2023-05-26 11:26:01 - progress_bar.py[line:272] - INFO: epoch 014:    603 / 1732 loss=2.254, loss_v1=0, loss_v2=0, nll_loss=1.042, ntokens=911.2, nsentences=32, sample_size=911.2, sample_size_v1=0, sample_size_v2=0, ppl=2.06, wps=493.5, ups=0.54, wpb=911.2, bsz=32, num_updates=23080, lr=1.77385e-05, gnorm=5.204, clip=100, loss_scale=128, train_wall=18, gb_free=11.8, wall=43376
2023-05-26 11:26:19 - progress_bar.py[line:272] - INFO: epoch 014:    613 / 1732 loss=2.281, loss_v1=0, loss_v2=0, nll_loss=1.071, ntokens=893.3, nsentences=32, sample_size=893.3, sample_size_v1=0, sample_size_v2=0, ppl=2.1, wps=483.5, ups=0.54, wpb=893.3, bsz=32, num_updates=23090, lr=1.77323e-05, gnorm=5.354, clip=100, loss_scale=128, train_wall=18, gb_free=11.7, wall=43394
2023-05-26 11:26:38 - progress_bar.py[line:272] - INFO: epoch 014:    623 / 1732 loss=2.288, loss_v1=0, loss_v2=0, nll_loss=1.077, ntokens=887.2, nsentences=32, sample_size=887.2, sample_size_v1=0, sample_size_v2=0, ppl=2.11, wps=484.1, ups=0.55, wpb=887.2, bsz=32, num_updates=23100, lr=1.77262e-05, gnorm=5.122, clip=100, loss_scale=128, train_wall=18, gb_free=11.1, wall=43412
2023-05-26 11:26:56 - progress_bar.py[line:272] - INFO: epoch 014:    633 / 1732 loss=2.271, loss_v1=0, loss_v2=0, nll_loss=1.057, ntokens=925, nsentences=32, sample_size=925, sample_size_v1=0, sample_size_v2=0, ppl=2.08, wps=501, ups=0.54, wpb=925, bsz=32, num_updates=23110, lr=1.772e-05, gnorm=4.888, clip=100, loss_scale=128, train_wall=18, gb_free=11.6, wall=43431
2023-05-26 11:27:15 - progress_bar.py[line:272] - INFO: epoch 014:    643 / 1732 loss=2.287, loss_v1=0, loss_v2=0, nll_loss=1.078, ntokens=963.8, nsentences=32, sample_size=963.8, sample_size_v1=0, sample_size_v2=0, ppl=2.11, wps=521.5, ups=0.54, wpb=963.8, bsz=32, num_updates=23120, lr=1.77139e-05, gnorm=5.078, clip=100, loss_scale=128, train_wall=18, gb_free=11.8, wall=43449
2023-05-26 11:27:33 - progress_bar.py[line:272] - INFO: epoch 014:    653 / 1732 loss=2.268, loss_v1=0, loss_v2=0, nll_loss=1.055, ntokens=928, nsentences=32, sample_size=928, sample_size_v1=0, sample_size_v2=0, ppl=2.08, wps=506.6, ups=0.55, wpb=928, bsz=32, num_updates=23130, lr=1.77078e-05, gnorm=4.701, clip=100, loss_scale=128, train_wall=18, gb_free=11.9, wall=43468
2023-05-26 11:27:51 - progress_bar.py[line:272] - INFO: epoch 014:    663 / 1732 loss=2.27, loss_v1=0, loss_v2=0, nll_loss=1.059, ntokens=882.9, nsentences=32, sample_size=882.9, sample_size_v1=0, sample_size_v2=0, ppl=2.08, wps=480.4, ups=0.54, wpb=882.9, bsz=32, num_updates=23140, lr=1.77016e-05, gnorm=5.427, clip=100, loss_scale=128, train_wall=18, gb_free=11.5, wall=43486
2023-05-26 11:28:10 - progress_bar.py[line:272] - INFO: epoch 014:    673 / 1732 loss=2.306, loss_v1=0, loss_v2=0, nll_loss=1.098, ntokens=954.3, nsentences=32, sample_size=954.3, sample_size_v1=0, sample_size_v2=0, ppl=2.14, wps=515, ups=0.54, wpb=954.3, bsz=32, num_updates=23150, lr=1.76955e-05, gnorm=5.53, clip=100, loss_scale=128, train_wall=19, gb_free=11.8, wall=43505
2023-05-26 11:28:28 - progress_bar.py[line:272] - INFO: epoch 014:    683 / 1732 loss=2.268, loss_v1=0, loss_v2=0, nll_loss=1.055, ntokens=960.5, nsentences=32, sample_size=960.5, sample_size_v1=0, sample_size_v2=0, ppl=2.08, wps=521.5, ups=0.54, wpb=960.5, bsz=32, num_updates=23160, lr=1.76893e-05, gnorm=5.2, clip=100, loss_scale=128, train_wall=18, gb_free=11.9, wall=43523
2023-05-26 11:28:47 - progress_bar.py[line:272] - INFO: epoch 014:    693 / 1732 loss=2.294, loss_v1=0, loss_v2=0, nll_loss=1.084, ntokens=962.9, nsentences=32, sample_size=962.9, sample_size_v1=0, sample_size_v2=0, ppl=2.12, wps=518.7, ups=0.54, wpb=962.9, bsz=32, num_updates=23170, lr=1.76832e-05, gnorm=5.125, clip=100, loss_scale=128, train_wall=19, gb_free=11.2, wall=43542
2023-05-26 11:29:05 - progress_bar.py[line:272] - INFO: epoch 014:    703 / 1732 loss=2.24, loss_v1=0, loss_v2=0, nll_loss=1.024, ntokens=972.9, nsentences=32, sample_size=972.9, sample_size_v1=0, sample_size_v2=0, ppl=2.03, wps=524.6, ups=0.54, wpb=972.9, bsz=32, num_updates=23180, lr=1.7677e-05, gnorm=4.872, clip=100, loss_scale=128, train_wall=19, gb_free=11.6, wall=43560
2023-05-26 11:29:24 - progress_bar.py[line:272] - INFO: epoch 014:    713 / 1732 loss=2.284, loss_v1=0, loss_v2=0, nll_loss=1.073, ntokens=898.6, nsentences=32, sample_size=898.6, sample_size_v1=0, sample_size_v2=0, ppl=2.1, wps=487.6, ups=0.54, wpb=898.6, bsz=32, num_updates=23190, lr=1.76709e-05, gnorm=5.066, clip=100, loss_scale=128, train_wall=18, gb_free=11.8, wall=43579
2023-05-26 11:29:42 - progress_bar.py[line:272] - INFO: epoch 014:    723 / 1732 loss=2.249, loss_v1=0, loss_v2=0, nll_loss=1.036, ntokens=877.5, nsentences=32, sample_size=877.5, sample_size_v1=0, sample_size_v2=0, ppl=2.05, wps=477.8, ups=0.54, wpb=877.5, bsz=32, num_updates=23200, lr=1.76648e-05, gnorm=5.035, clip=100, loss_scale=128, train_wall=18, gb_free=12, wall=43597
2023-05-26 11:30:01 - progress_bar.py[line:272] - INFO: epoch 014:    733 / 1732 loss=2.261, loss_v1=0, loss_v2=0, nll_loss=1.049, ntokens=959.6, nsentences=32, sample_size=959.6, sample_size_v1=0, sample_size_v2=0, ppl=2.07, wps=519.7, ups=0.54, wpb=959.6, bsz=32, num_updates=23210, lr=1.76586e-05, gnorm=4.971, clip=100, loss_scale=128, train_wall=18, gb_free=11, wall=43615
2023-05-26 11:30:19 - progress_bar.py[line:272] - INFO: epoch 014:    743 / 1732 loss=2.259, loss_v1=0, loss_v2=0, nll_loss=1.045, ntokens=991.8, nsentences=32, sample_size=991.8, sample_size_v1=0, sample_size_v2=0, ppl=2.06, wps=537.6, ups=0.54, wpb=991.8, bsz=32, num_updates=23220, lr=1.76525e-05, gnorm=4.994, clip=100, loss_scale=128, train_wall=18, gb_free=11.4, wall=43634
2023-05-26 11:30:38 - progress_bar.py[line:272] - INFO: epoch 014:    753 / 1732 loss=2.259, loss_v1=0, loss_v2=0, nll_loss=1.044, ntokens=968.6, nsentences=32, sample_size=968.6, sample_size_v1=0, sample_size_v2=0, ppl=2.06, wps=521.6, ups=0.54, wpb=968.6, bsz=32, num_updates=23230, lr=1.76463e-05, gnorm=4.817, clip=100, loss_scale=128, train_wall=19, gb_free=11.5, wall=43652
2023-05-26 11:30:56 - progress_bar.py[line:272] - INFO: epoch 014:    763 / 1732 loss=2.253, loss_v1=0, loss_v2=0, nll_loss=1.038, ntokens=964, nsentences=32, sample_size=964, sample_size_v1=0, sample_size_v2=0, ppl=2.05, wps=523.2, ups=0.54, wpb=964, bsz=32, num_updates=23240, lr=1.76402e-05, gnorm=4.792, clip=100, loss_scale=128, train_wall=18, gb_free=11.6, wall=43671
2023-05-26 11:31:15 - progress_bar.py[line:272] - INFO: epoch 014:    773 / 1732 loss=2.264, loss_v1=0, loss_v2=0, nll_loss=1.053, ntokens=971.7, nsentences=32, sample_size=971.7, sample_size_v1=0, sample_size_v2=0, ppl=2.08, wps=526.3, ups=0.54, wpb=971.7, bsz=32, num_updates=23250, lr=1.76341e-05, gnorm=5.195, clip=100, loss_scale=128, train_wall=18, gb_free=11.5, wall=43689
2023-05-26 11:31:33 - progress_bar.py[line:272] - INFO: epoch 014:    783 / 1732 loss=2.258, loss_v1=0, loss_v2=0, nll_loss=1.044, ntokens=1008.4, nsentences=32, sample_size=1008.4, sample_size_v1=0, sample_size_v2=0, ppl=2.06, wps=545.5, ups=0.54, wpb=1008.4, bsz=32, num_updates=23260, lr=1.76279e-05, gnorm=4.672, clip=100, loss_scale=128, train_wall=18, gb_free=11.2, wall=43708
2023-05-26 11:31:52 - progress_bar.py[line:272] - INFO: epoch 014:    793 / 1732 loss=2.268, loss_v1=0, loss_v2=0, nll_loss=1.055, ntokens=1034.6, nsentences=32, sample_size=1034.6, sample_size_v1=0, sample_size_v2=0, ppl=2.08, wps=560.3, ups=0.54, wpb=1034.6, bsz=32, num_updates=23270, lr=1.76218e-05, gnorm=5.125, clip=100, loss_scale=128, train_wall=18, gb_free=11.4, wall=43726
2023-05-26 11:32:10 - progress_bar.py[line:272] - INFO: epoch 014:    803 / 1732 loss=2.268, loss_v1=0, loss_v2=0, nll_loss=1.056, ntokens=964.4, nsentences=32, sample_size=964.4, sample_size_v1=0, sample_size_v2=0, ppl=2.08, wps=522, ups=0.54, wpb=964.4, bsz=32, num_updates=23280, lr=1.76156e-05, gnorm=5.113, clip=100, loss_scale=128, train_wall=18, gb_free=10.9, wall=43745
2023-05-26 11:32:28 - progress_bar.py[line:272] - INFO: epoch 014:    813 / 1732 loss=2.272, loss_v1=0, loss_v2=0, nll_loss=1.062, ntokens=940.9, nsentences=32, sample_size=940.9, sample_size_v1=0, sample_size_v2=0, ppl=2.09, wps=510, ups=0.54, wpb=940.9, bsz=32, num_updates=23290, lr=1.76095e-05, gnorm=5.334, clip=100, loss_scale=128, train_wall=18, gb_free=10.8, wall=43763
2023-05-26 11:32:47 - progress_bar.py[line:272] - INFO: epoch 014:    823 / 1732 loss=2.264, loss_v1=0, loss_v2=0, nll_loss=1.049, ntokens=915.1, nsentences=32, sample_size=915.1, sample_size_v1=0, sample_size_v2=0, ppl=2.07, wps=493.6, ups=0.54, wpb=915.1, bsz=32, num_updates=23300, lr=1.76033e-05, gnorm=5.609, clip=100, loss_scale=128, train_wall=19, gb_free=11.5, wall=43782
2023-05-26 11:33:05 - progress_bar.py[line:272] - INFO: epoch 014:    833 / 1732 loss=2.269, loss_v1=0, loss_v2=0, nll_loss=1.056, ntokens=907.5, nsentences=32, sample_size=907.5, sample_size_v1=0, sample_size_v2=0, ppl=2.08, wps=494.1, ups=0.54, wpb=907.5, bsz=32, num_updates=23310, lr=1.75972e-05, gnorm=5.393, clip=100, loss_scale=128, train_wall=18, gb_free=11.8, wall=43800
2023-05-26 11:33:24 - progress_bar.py[line:272] - INFO: epoch 014:    843 / 1732 loss=2.248, loss_v1=0, loss_v2=0, nll_loss=1.034, ntokens=950.7, nsentences=32, sample_size=950.7, sample_size_v1=0, sample_size_v2=0, ppl=2.05, wps=516.8, ups=0.54, wpb=950.7, bsz=32, num_updates=23320, lr=1.75911e-05, gnorm=5.195, clip=100, loss_scale=128, train_wall=18, gb_free=11.8, wall=43818
2023-05-26 11:33:42 - progress_bar.py[line:272] - INFO: epoch 014:    853 / 1732 loss=2.266, loss_v1=0, loss_v2=0, nll_loss=1.053, ntokens=1006.3, nsentences=32, sample_size=1006.3, sample_size_v1=0, sample_size_v2=0, ppl=2.08, wps=542.3, ups=0.54, wpb=1006.3, bsz=32, num_updates=23330, lr=1.75849e-05, gnorm=5.434, clip=100, loss_scale=128, train_wall=19, gb_free=11.1, wall=43837
2023-05-26 11:34:01 - progress_bar.py[line:272] - INFO: epoch 014:    863 / 1732 loss=2.26, loss_v1=0, loss_v2=0, nll_loss=1.048, ntokens=933.3, nsentences=32, sample_size=933.3, sample_size_v1=0, sample_size_v2=0, ppl=2.07, wps=504.4, ups=0.54, wpb=933.3, bsz=32, num_updates=23340, lr=1.75788e-05, gnorm=5.305, clip=100, loss_scale=128, train_wall=18, gb_free=11.4, wall=43856
2023-05-26 11:34:19 - progress_bar.py[line:272] - INFO: epoch 014:    873 / 1732 loss=2.245, loss_v1=0, loss_v2=0, nll_loss=1.031, ntokens=966.4, nsentences=32, sample_size=966.4, sample_size_v1=0, sample_size_v2=0, ppl=2.04, wps=523.2, ups=0.54, wpb=966.4, bsz=32, num_updates=23350, lr=1.75726e-05, gnorm=5.057, clip=100, loss_scale=128, train_wall=18, gb_free=11.3, wall=43874
2023-05-26 11:34:38 - progress_bar.py[line:272] - INFO: epoch 014:    883 / 1732 loss=2.202, loss_v1=0, loss_v2=0, nll_loss=0.981, ntokens=985.5, nsentences=32, sample_size=985.5, sample_size_v1=0, sample_size_v2=0, ppl=1.97, wps=529.6, ups=0.54, wpb=985.5, bsz=32, num_updates=23360, lr=1.75665e-05, gnorm=5.026, clip=100, loss_scale=128, train_wall=19, gb_free=11.3, wall=43893
2023-05-26 11:34:57 - progress_bar.py[line:272] - INFO: epoch 014:    893 / 1732 loss=2.217, loss_v1=0, loss_v2=0, nll_loss=0.999, ntokens=1009.8, nsentences=32, sample_size=1009.8, sample_size_v1=0, sample_size_v2=0, ppl=2, wps=543.6, ups=0.54, wpb=1009.8, bsz=32, num_updates=23370, lr=1.75603e-05, gnorm=5.082, clip=100, loss_scale=128, train_wall=19, gb_free=11.1, wall=43911
2023-05-26 11:35:15 - progress_bar.py[line:272] - INFO: epoch 014:    903 / 1732 loss=2.204, loss_v1=0, loss_v2=0, nll_loss=0.983, ntokens=1049.7, nsentences=32, sample_size=1049.7, sample_size_v1=0, sample_size_v2=0, ppl=1.98, wps=566, ups=0.54, wpb=1049.7, bsz=32, num_updates=23380, lr=1.75542e-05, gnorm=4.768, clip=100, loss_scale=128, train_wall=19, gb_free=11.5, wall=43930
2023-05-26 11:35:34 - progress_bar.py[line:272] - INFO: epoch 014:    913 / 1732 loss=2.292, loss_v1=0, loss_v2=0, nll_loss=1.083, ntokens=930.6, nsentences=32, sample_size=930.6, sample_size_v1=0, sample_size_v2=0, ppl=2.12, wps=502.9, ups=0.54, wpb=930.6, bsz=32, num_updates=23390, lr=1.75481e-05, gnorm=5.409, clip=100, loss_scale=128, train_wall=18, gb_free=11, wall=43948
2023-05-26 11:35:52 - progress_bar.py[line:272] - INFO: epoch 014:    923 / 1732 loss=2.229, loss_v1=0, loss_v2=0, nll_loss=1.012, ntokens=1023.3, nsentences=32, sample_size=1023.3, sample_size_v1=0, sample_size_v2=0, ppl=2.02, wps=548.8, ups=0.54, wpb=1023.3, bsz=32, num_updates=23400, lr=1.75419e-05, gnorm=4.752, clip=100, loss_scale=128, train_wall=19, gb_free=11.1, wall=43967
2023-05-26 11:36:11 - progress_bar.py[line:272] - INFO: epoch 014:    933 / 1732 loss=2.241, loss_v1=0, loss_v2=0, nll_loss=1.026, ntokens=1034.6, nsentences=32, sample_size=1034.6, sample_size_v1=0, sample_size_v2=0, ppl=2.04, wps=552.6, ups=0.53, wpb=1034.6, bsz=32, num_updates=23410, lr=1.75358e-05, gnorm=5.248, clip=100, loss_scale=128, train_wall=19, gb_free=11.1, wall=43986
2023-05-26 11:36:30 - progress_bar.py[line:272] - INFO: epoch 014:    943 / 1732 loss=2.267, loss_v1=0, loss_v2=0, nll_loss=1.056, ntokens=1054.1, nsentences=32, sample_size=1054.1, sample_size_v1=0, sample_size_v2=0, ppl=2.08, wps=561.2, ups=0.53, wpb=1054.1, bsz=32, num_updates=23420, lr=1.75296e-05, gnorm=5.004, clip=100, loss_scale=128, train_wall=19, gb_free=11.3, wall=44004
2023-05-26 11:36:49 - progress_bar.py[line:272] - INFO: epoch 014:    953 / 1732 loss=2.251, loss_v1=0, loss_v2=0, nll_loss=1.036, ntokens=1032.2, nsentences=32, sample_size=1032.2, sample_size_v1=0, sample_size_v2=0, ppl=2.05, wps=549.8, ups=0.53, wpb=1032.2, bsz=32, num_updates=23430, lr=1.75235e-05, gnorm=5.246, clip=100, loss_scale=128, train_wall=19, gb_free=10.9, wall=44023
2023-05-26 11:37:07 - progress_bar.py[line:272] - INFO: epoch 014:    963 / 1732 loss=2.262, loss_v1=0, loss_v2=0, nll_loss=1.049, ntokens=1069.2, nsentences=32, sample_size=1069.2, sample_size_v1=0, sample_size_v2=0, ppl=2.07, wps=570, ups=0.53, wpb=1069.2, bsz=32, num_updates=23440, lr=1.75174e-05, gnorm=5.109, clip=100, loss_scale=128, train_wall=19, gb_free=11.2, wall=44042
2023-05-26 11:37:26 - progress_bar.py[line:272] - INFO: epoch 014:    973 / 1732 loss=2.256, loss_v1=0, loss_v2=0, nll_loss=1.043, ntokens=1034.1, nsentences=32, sample_size=1034.1, sample_size_v1=0, sample_size_v2=0, ppl=2.06, wps=549.9, ups=0.53, wpb=1034.1, bsz=32, num_updates=23450, lr=1.75112e-05, gnorm=4.939, clip=100, loss_scale=128, train_wall=19, gb_free=11.2, wall=44061
2023-05-26 11:37:45 - progress_bar.py[line:272] - INFO: epoch 014:    983 / 1732 loss=2.25, loss_v1=0, loss_v2=0, nll_loss=1.034, ntokens=1026.6, nsentences=32, sample_size=1026.6, sample_size_v1=0, sample_size_v2=0, ppl=2.05, wps=543.3, ups=0.53, wpb=1026.6, bsz=32, num_updates=23460, lr=1.75051e-05, gnorm=4.866, clip=100, loss_scale=128, train_wall=19, gb_free=11.2, wall=44080
2023-05-26 11:38:04 - progress_bar.py[line:272] - INFO: epoch 014:    993 / 1732 loss=2.265, loss_v1=0, loss_v2=0, nll_loss=1.052, ntokens=1041.8, nsentences=32, sample_size=1041.8, sample_size_v1=0, sample_size_v2=0, ppl=2.07, wps=554.9, ups=0.53, wpb=1041.8, bsz=32, num_updates=23470, lr=1.74989e-05, gnorm=4.955, clip=100, loss_scale=128, train_wall=19, gb_free=11.4, wall=44098
2023-05-26 11:38:15 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 128.0
2023-05-26 11:38:24 - progress_bar.py[line:272] - INFO: epoch 014:   1004 / 1732 loss=2.242, loss_v1=0, loss_v2=0, nll_loss=1.026, ntokens=1002.2, nsentences=32, sample_size=1002.2, sample_size_v1=0, sample_size_v2=0, ppl=2.04, wps=489.2, ups=0.49, wpb=1002.2, bsz=32, num_updates=23480, lr=1.74928e-05, gnorm=5.612, clip=100, loss_scale=128, train_wall=20, gb_free=11.8, wall=44119
2023-05-26 11:38:43 - progress_bar.py[line:272] - INFO: epoch 014:   1014 / 1732 loss=2.246, loss_v1=0, loss_v2=0, nll_loss=1.03, ntokens=997.1, nsentences=32, sample_size=997.1, sample_size_v1=0, sample_size_v2=0, ppl=2.04, wps=535.9, ups=0.54, wpb=997.1, bsz=32, num_updates=23490, lr=1.74866e-05, gnorm=5.272, clip=100, loss_scale=128, train_wall=19, gb_free=11.4, wall=44138
2023-05-26 11:39:02 - progress_bar.py[line:272] - INFO: epoch 014:   1024 / 1732 loss=2.244, loss_v1=0, loss_v2=0, nll_loss=1.029, ntokens=1086.7, nsentences=32, sample_size=1086.7, sample_size_v1=0, sample_size_v2=0, ppl=2.04, wps=578.2, ups=0.53, wpb=1086.7, bsz=32, num_updates=23500, lr=1.74805e-05, gnorm=4.851, clip=100, loss_scale=128, train_wall=19, gb_free=11.2, wall=44156
2023-05-26 11:39:21 - progress_bar.py[line:272] - INFO: epoch 014:   1034 / 1732 loss=2.247, loss_v1=0, loss_v2=0, nll_loss=1.031, ntokens=1103.2, nsentences=32, sample_size=1103.2, sample_size_v1=0, sample_size_v2=0, ppl=2.04, wps=582.7, ups=0.53, wpb=1103.2, bsz=32, num_updates=23510, lr=1.74744e-05, gnorm=4.916, clip=100, loss_scale=128, train_wall=19, gb_free=10.8, wall=44175
2023-05-26 11:39:39 - progress_bar.py[line:272] - INFO: epoch 014:   1044 / 1732 loss=2.243, loss_v1=0, loss_v2=0, nll_loss=1.027, ntokens=1052.8, nsentences=32, sample_size=1052.8, sample_size_v1=0, sample_size_v2=0, ppl=2.04, wps=559.7, ups=0.53, wpb=1052.8, bsz=32, num_updates=23520, lr=1.74682e-05, gnorm=4.878, clip=100, loss_scale=128, train_wall=19, gb_free=11.2, wall=44194
2023-05-26 11:39:58 - progress_bar.py[line:272] - INFO: epoch 014:   1054 / 1732 loss=2.272, loss_v1=0, loss_v2=0, nll_loss=1.061, ntokens=1068, nsentences=32, sample_size=1068, sample_size_v1=0, sample_size_v2=0, ppl=2.09, wps=572.9, ups=0.54, wpb=1068, bsz=32, num_updates=23530, lr=1.74621e-05, gnorm=5.404, clip=100, loss_scale=128, train_wall=19, gb_free=10, wall=44213
2023-05-26 11:40:17 - progress_bar.py[line:272] - INFO: epoch 014:   1064 / 1732 loss=2.241, loss_v1=0, loss_v2=0, nll_loss=1.026, ntokens=1024.1, nsentences=32, sample_size=1024.1, sample_size_v1=0, sample_size_v2=0, ppl=2.04, wps=547.2, ups=0.53, wpb=1024.1, bsz=32, num_updates=23540, lr=1.74559e-05, gnorm=4.748, clip=100, loss_scale=128, train_wall=19, gb_free=11.6, wall=44231
2023-05-26 11:40:36 - progress_bar.py[line:272] - INFO: epoch 014:   1074 / 1732 loss=2.243, loss_v1=0, loss_v2=0, nll_loss=1.027, ntokens=1002.8, nsentences=32, sample_size=1002.8, sample_size_v1=0, sample_size_v2=0, ppl=2.04, wps=533.2, ups=0.53, wpb=1002.8, bsz=32, num_updates=23550, lr=1.74498e-05, gnorm=5.293, clip=100, loss_scale=128, train_wall=19, gb_free=11.3, wall=44250
2023-05-26 11:40:55 - progress_bar.py[line:272] - INFO: epoch 014:   1084 / 1732 loss=2.26, loss_v1=0, loss_v2=0, nll_loss=1.047, ntokens=1060.4, nsentences=32, sample_size=1060.4, sample_size_v1=0, sample_size_v2=0, ppl=2.07, wps=558.4, ups=0.53, wpb=1060.4, bsz=32, num_updates=23560, lr=1.74436e-05, gnorm=5.289, clip=100, loss_scale=128, train_wall=19, gb_free=10.3, wall=44269
2023-05-26 11:41:13 - progress_bar.py[line:272] - INFO: epoch 014:   1094 / 1732 loss=2.25, loss_v1=0, loss_v2=0, nll_loss=1.035, ntokens=1050.5, nsentences=32, sample_size=1050.5, sample_size_v1=0, sample_size_v2=0, ppl=2.05, wps=561.4, ups=0.53, wpb=1050.5, bsz=32, num_updates=23570, lr=1.74375e-05, gnorm=5.142, clip=100, loss_scale=128, train_wall=19, gb_free=10.8, wall=44288
2023-05-26 11:41:32 - progress_bar.py[line:272] - INFO: epoch 014:   1104 / 1732 loss=2.253, loss_v1=0, loss_v2=0, nll_loss=1.038, ntokens=1042.3, nsentences=32, sample_size=1042.3, sample_size_v1=0, sample_size_v2=0, ppl=2.05, wps=555.2, ups=0.53, wpb=1042.3, bsz=32, num_updates=23580, lr=1.74314e-05, gnorm=5.229, clip=100, loss_scale=128, train_wall=19, gb_free=11.2, wall=44307
2023-05-26 11:41:51 - progress_bar.py[line:272] - INFO: epoch 014:   1114 / 1732 loss=2.247, loss_v1=0, loss_v2=0, nll_loss=1.03, ntokens=1000.7, nsentences=32, sample_size=1000.7, sample_size_v1=0, sample_size_v2=0, ppl=2.04, wps=532.5, ups=0.53, wpb=1000.7, bsz=32, num_updates=23590, lr=1.74252e-05, gnorm=5.066, clip=100, loss_scale=128, train_wall=19, gb_free=11.3, wall=44326
2023-05-26 11:42:10 - progress_bar.py[line:272] - INFO: epoch 014:   1124 / 1732 loss=2.235, loss_v1=0, loss_v2=0, nll_loss=1.018, ntokens=989.1, nsentences=32, sample_size=989.1, sample_size_v1=0, sample_size_v2=0, ppl=2.03, wps=525.9, ups=0.53, wpb=989.1, bsz=32, num_updates=23600, lr=1.74191e-05, gnorm=5.293, clip=100, loss_scale=128, train_wall=19, gb_free=10.8, wall=44344
2023-05-26 11:42:28 - progress_bar.py[line:272] - INFO: epoch 014:   1134 / 1732 loss=2.242, loss_v1=0, loss_v2=0, nll_loss=1.028, ntokens=968.8, nsentences=32, sample_size=968.8, sample_size_v1=0, sample_size_v2=0, ppl=2.04, wps=517.5, ups=0.53, wpb=968.8, bsz=32, num_updates=23610, lr=1.74129e-05, gnorm=5.321, clip=100, loss_scale=128, train_wall=19, gb_free=11.4, wall=44363
2023-05-26 11:42:47 - progress_bar.py[line:272] - INFO: epoch 014:   1144 / 1732 loss=2.237, loss_v1=0, loss_v2=0, nll_loss=1.02, ntokens=1034.3, nsentences=32, sample_size=1034.3, sample_size_v1=0, sample_size_v2=0, ppl=2.03, wps=551.2, ups=0.53, wpb=1034.3, bsz=32, num_updates=23620, lr=1.74068e-05, gnorm=5.171, clip=100, loss_scale=128, train_wall=19, gb_free=11.6, wall=44382
2023-05-26 11:43:06 - progress_bar.py[line:272] - INFO: epoch 014:   1154 / 1732 loss=2.236, loss_v1=0, loss_v2=0, nll_loss=1.022, ntokens=1025.8, nsentences=32, sample_size=1025.8, sample_size_v1=0, sample_size_v2=0, ppl=2.03, wps=545.9, ups=0.53, wpb=1025.8, bsz=32, num_updates=23630, lr=1.74007e-05, gnorm=4.956, clip=100, loss_scale=128, train_wall=19, gb_free=10.3, wall=44401
2023-05-26 11:43:25 - progress_bar.py[line:272] - INFO: epoch 014:   1164 / 1732 loss=2.212, loss_v1=0, loss_v2=0, nll_loss=0.995, ntokens=1008, nsentences=32, sample_size=1008, sample_size_v1=0, sample_size_v2=0, ppl=1.99, wps=536.8, ups=0.53, wpb=1008, bsz=32, num_updates=23640, lr=1.73945e-05, gnorm=4.843, clip=100, loss_scale=128, train_wall=19, gb_free=11.5, wall=44419
2023-05-26 11:43:44 - progress_bar.py[line:272] - INFO: epoch 014:   1174 / 1732 loss=2.239, loss_v1=0, loss_v2=0, nll_loss=1.022, ntokens=1081.1, nsentences=32, sample_size=1081.1, sample_size_v1=0, sample_size_v2=0, ppl=2.03, wps=574.8, ups=0.53, wpb=1081.1, bsz=32, num_updates=23650, lr=1.73884e-05, gnorm=4.828, clip=100, loss_scale=128, train_wall=19, gb_free=11, wall=44438
2023-05-26 11:44:02 - progress_bar.py[line:272] - INFO: epoch 014:   1184 / 1732 loss=2.219, loss_v1=0, loss_v2=0, nll_loss=1, ntokens=962, nsentences=32, sample_size=962, sample_size_v1=0, sample_size_v2=0, ppl=2, wps=514.4, ups=0.53, wpb=962, bsz=32, num_updates=23660, lr=1.73822e-05, gnorm=5.155, clip=100, loss_scale=128, train_wall=19, gb_free=11.7, wall=44457
2023-05-26 11:44:21 - progress_bar.py[line:272] - INFO: epoch 014:   1194 / 1732 loss=2.245, loss_v1=0, loss_v2=0, nll_loss=1.031, ntokens=1042.6, nsentences=32, sample_size=1042.6, sample_size_v1=0, sample_size_v2=0, ppl=2.04, wps=556.4, ups=0.53, wpb=1042.6, bsz=32, num_updates=23670, lr=1.73761e-05, gnorm=5.164, clip=100, loss_scale=128, train_wall=19, gb_free=11.5, wall=44476
2023-05-26 11:44:40 - progress_bar.py[line:272] - INFO: epoch 014:   1204 / 1732 loss=2.214, loss_v1=0, loss_v2=0, nll_loss=0.994, ntokens=1150.2, nsentences=32, sample_size=1150.2, sample_size_v1=0, sample_size_v2=0, ppl=1.99, wps=606.3, ups=0.53, wpb=1150.2, bsz=32, num_updates=23680, lr=1.73699e-05, gnorm=4.612, clip=100, loss_scale=128, train_wall=19, gb_free=11.3, wall=44495
2023-05-26 11:44:59 - progress_bar.py[line:272] - INFO: epoch 014:   1214 / 1732 loss=2.239, loss_v1=0, loss_v2=0, nll_loss=1.023, ntokens=996.3, nsentences=32, sample_size=996.3, sample_size_v1=0, sample_size_v2=0, ppl=2.03, wps=531.4, ups=0.53, wpb=996.3, bsz=32, num_updates=23690, lr=1.73638e-05, gnorm=4.975, clip=100, loss_scale=128, train_wall=19, gb_free=11.7, wall=44513
2023-05-26 11:45:18 - progress_bar.py[line:272] - INFO: epoch 014:   1224 / 1732 loss=2.263, loss_v1=0, loss_v2=0, nll_loss=1.051, ntokens=1056.3, nsentences=32, sample_size=1056.3, sample_size_v1=0, sample_size_v2=0, ppl=2.07, wps=562, ups=0.53, wpb=1056.3, bsz=32, num_updates=23700, lr=1.73577e-05, gnorm=5.437, clip=100, loss_scale=128, train_wall=19, gb_free=11.5, wall=44532
2023-05-26 11:45:36 - progress_bar.py[line:272] - INFO: epoch 014:   1234 / 1732 loss=2.23, loss_v1=0, loss_v2=0, nll_loss=1.011, ntokens=1012.2, nsentences=32, sample_size=1012.2, sample_size_v1=0, sample_size_v2=0, ppl=2.02, wps=541.4, ups=0.53, wpb=1012.2, bsz=32, num_updates=23710, lr=1.73515e-05, gnorm=5.169, clip=100, loss_scale=128, train_wall=19, gb_free=11.6, wall=44551
2023-05-26 11:45:55 - progress_bar.py[line:272] - INFO: epoch 014:   1244 / 1732 loss=2.191, loss_v1=0, loss_v2=0, nll_loss=0.97, ntokens=1090.2, nsentences=32, sample_size=1090.2, sample_size_v1=0, sample_size_v2=0, ppl=1.96, wps=579.5, ups=0.53, wpb=1090.2, bsz=32, num_updates=23720, lr=1.73454e-05, gnorm=5.015, clip=100, loss_scale=128, train_wall=19, gb_free=11.4, wall=44570
2023-05-26 11:46:14 - progress_bar.py[line:272] - INFO: epoch 014:   1254 / 1732 loss=2.204, loss_v1=0, loss_v2=0, nll_loss=0.985, ntokens=1076, nsentences=32, sample_size=1076, sample_size_v1=0, sample_size_v2=0, ppl=1.98, wps=571.1, ups=0.53, wpb=1076, bsz=32, num_updates=23730, lr=1.73392e-05, gnorm=4.849, clip=100, loss_scale=128, train_wall=19, gb_free=11.6, wall=44589
2023-05-26 11:46:33 - progress_bar.py[line:272] - INFO: epoch 014:   1264 / 1732 loss=2.244, loss_v1=0, loss_v2=0, nll_loss=1.03, ntokens=1095.2, nsentences=32, sample_size=1095.2, sample_size_v1=0, sample_size_v2=0, ppl=2.04, wps=580.6, ups=0.53, wpb=1095.2, bsz=32, num_updates=23740, lr=1.73331e-05, gnorm=4.852, clip=100, loss_scale=128, train_wall=19, gb_free=10.7, wall=44607
2023-05-26 11:46:52 - progress_bar.py[line:272] - INFO: epoch 014:   1274 / 1732 loss=2.243, loss_v1=0, loss_v2=0, nll_loss=1.028, ntokens=1014.1, nsentences=32, sample_size=1014.1, sample_size_v1=0, sample_size_v2=0, ppl=2.04, wps=541, ups=0.53, wpb=1014.1, bsz=32, num_updates=23750, lr=1.73269e-05, gnorm=4.855, clip=100, loss_scale=128, train_wall=19, gb_free=11, wall=44626
2023-05-26 11:47:10 - progress_bar.py[line:272] - INFO: epoch 014:   1284 / 1732 loss=2.233, loss_v1=0, loss_v2=0, nll_loss=1.016, ntokens=1057.3, nsentences=32, sample_size=1057.3, sample_size_v1=0, sample_size_v2=0, ppl=2.02, wps=558.5, ups=0.53, wpb=1057.3, bsz=32, num_updates=23760, lr=1.73208e-05, gnorm=5.068, clip=100, loss_scale=128, train_wall=19, gb_free=11.5, wall=44645
2023-05-26 11:47:29 - progress_bar.py[line:272] - INFO: epoch 014:   1294 / 1732 loss=2.229, loss_v1=0, loss_v2=0, nll_loss=1.01, ntokens=1109.4, nsentences=32, sample_size=1109.4, sample_size_v1=0, sample_size_v2=0, ppl=2.01, wps=587.6, ups=0.53, wpb=1109.4, bsz=32, num_updates=23770, lr=1.73147e-05, gnorm=4.334, clip=100, loss_scale=128, train_wall=19, gb_free=11.5, wall=44664
2023-05-26 11:47:48 - progress_bar.py[line:272] - INFO: epoch 014:   1304 / 1732 loss=2.256, loss_v1=0, loss_v2=0, nll_loss=1.043, ntokens=1090.1, nsentences=32, sample_size=1090.1, sample_size_v1=0, sample_size_v2=0, ppl=2.06, wps=577.4, ups=0.53, wpb=1090.1, bsz=32, num_updates=23780, lr=1.73085e-05, gnorm=4.79, clip=100, loss_scale=128, train_wall=19, gb_free=10.7, wall=44683
2023-05-26 11:48:07 - progress_bar.py[line:272] - INFO: epoch 014:   1314 / 1732 loss=2.259, loss_v1=0, loss_v2=0, nll_loss=1.046, ntokens=1051.4, nsentences=32, sample_size=1051.4, sample_size_v1=0, sample_size_v2=0, ppl=2.07, wps=554.3, ups=0.53, wpb=1051.4, bsz=32, num_updates=23790, lr=1.73024e-05, gnorm=5.348, clip=100, loss_scale=128, train_wall=19, gb_free=11, wall=44702
2023-05-26 11:48:26 - progress_bar.py[line:272] - INFO: epoch 014:   1324 / 1732 loss=2.21, loss_v1=0, loss_v2=0, nll_loss=0.99, ntokens=1117, nsentences=32, sample_size=1117, sample_size_v1=0, sample_size_v2=0, ppl=1.99, wps=590.8, ups=0.53, wpb=1117, bsz=32, num_updates=23800, lr=1.72962e-05, gnorm=4.574, clip=100, loss_scale=128, train_wall=19, gb_free=11.4, wall=44721
2023-05-26 11:48:45 - progress_bar.py[line:272] - INFO: epoch 014:   1334 / 1732 loss=2.208, loss_v1=0, loss_v2=0, nll_loss=0.988, ntokens=1097.8, nsentences=32, sample_size=1097.8, sample_size_v1=0, sample_size_v2=0, ppl=1.98, wps=583.7, ups=0.53, wpb=1097.8, bsz=32, num_updates=23810, lr=1.72901e-05, gnorm=4.773, clip=100, loss_scale=128, train_wall=19, gb_free=11.4, wall=44740
2023-05-26 11:49:04 - progress_bar.py[line:272] - INFO: epoch 014:   1344 / 1732 loss=2.217, loss_v1=0, loss_v2=0, nll_loss=0.998, ntokens=1201.2, nsentences=32, sample_size=1201.2, sample_size_v1=0, sample_size_v2=0, ppl=2, wps=632.2, ups=0.53, wpb=1201.2, bsz=32, num_updates=23820, lr=1.7284e-05, gnorm=5.021, clip=100, loss_scale=128, train_wall=19, gb_free=10.9, wall=44759
2023-05-26 11:49:23 - progress_bar.py[line:272] - INFO: epoch 014:   1354 / 1732 loss=2.216, loss_v1=0, loss_v2=0, nll_loss=0.998, ntokens=1101.2, nsentences=32, sample_size=1101.2, sample_size_v1=0, sample_size_v2=0, ppl=2, wps=582, ups=0.53, wpb=1101.2, bsz=32, num_updates=23830, lr=1.72778e-05, gnorm=4.879, clip=100, loss_scale=128, train_wall=19, gb_free=11.5, wall=44777
2023-05-26 11:49:42 - progress_bar.py[line:272] - INFO: epoch 014:   1364 / 1732 loss=2.208, loss_v1=0, loss_v2=0, nll_loss=0.986, ntokens=1115.3, nsentences=32, sample_size=1115.3, sample_size_v1=0, sample_size_v2=0, ppl=1.98, wps=589, ups=0.53, wpb=1115.3, bsz=32, num_updates=23840, lr=1.72717e-05, gnorm=5.111, clip=100, loss_scale=128, train_wall=19, gb_free=10.9, wall=44796
2023-05-26 11:50:01 - progress_bar.py[line:272] - INFO: epoch 014:   1374 / 1732 loss=2.257, loss_v1=0, loss_v2=0, nll_loss=1.044, ntokens=1075.1, nsentences=32, sample_size=1075.1, sample_size_v1=0, sample_size_v2=0, ppl=2.06, wps=572.7, ups=0.53, wpb=1075.1, bsz=32, num_updates=23850, lr=1.72655e-05, gnorm=5.448, clip=100, loss_scale=128, train_wall=19, gb_free=11.6, wall=44815
2023-05-26 11:50:19 - progress_bar.py[line:272] - INFO: epoch 014:   1384 / 1732 loss=2.242, loss_v1=0, loss_v2=0, nll_loss=1.027, ntokens=1167.1, nsentences=32, sample_size=1167.1, sample_size_v1=0, sample_size_v2=0, ppl=2.04, wps=618.6, ups=0.53, wpb=1167.1, bsz=32, num_updates=23860, lr=1.72594e-05, gnorm=5.069, clip=100, loss_scale=128, train_wall=19, gb_free=10.8, wall=44834
2023-05-26 11:50:38 - progress_bar.py[line:272] - INFO: epoch 014:   1394 / 1732 loss=2.239, loss_v1=0, loss_v2=0, nll_loss=1.024, ntokens=1039.3, nsentences=32, sample_size=1039.3, sample_size_v1=0, sample_size_v2=0, ppl=2.03, wps=555.1, ups=0.53, wpb=1039.3, bsz=32, num_updates=23870, lr=1.72532e-05, gnorm=5.263, clip=100, loss_scale=128, train_wall=19, gb_free=10.6, wall=44853
2023-05-26 11:50:57 - progress_bar.py[line:272] - INFO: epoch 014:   1404 / 1732 loss=2.223, loss_v1=0, loss_v2=0, nll_loss=1.005, ntokens=1161.9, nsentences=32, sample_size=1161.9, sample_size_v1=0, sample_size_v2=0, ppl=2.01, wps=615, ups=0.53, wpb=1161.9, bsz=32, num_updates=23880, lr=1.72471e-05, gnorm=5.052, clip=100, loss_scale=128, train_wall=19, gb_free=10.2, wall=44872
2023-05-26 11:51:16 - progress_bar.py[line:272] - INFO: epoch 014:   1414 / 1732 loss=2.257, loss_v1=0, loss_v2=0, nll_loss=1.043, ntokens=1276, nsentences=32, sample_size=1276, sample_size_v1=0, sample_size_v2=0, ppl=2.06, wps=671.6, ups=0.53, wpb=1276, bsz=32, num_updates=23890, lr=1.7241e-05, gnorm=4.819, clip=100, loss_scale=128, train_wall=19, gb_free=10.6, wall=44891
2023-05-26 11:51:35 - progress_bar.py[line:272] - INFO: epoch 014:   1424 / 1732 loss=2.227, loss_v1=0, loss_v2=0, nll_loss=1.01, ntokens=1261.9, nsentences=32, sample_size=1261.9, sample_size_v1=0, sample_size_v2=0, ppl=2.01, wps=657.4, ups=0.52, wpb=1261.9, bsz=32, num_updates=23900, lr=1.72348e-05, gnorm=4.488, clip=100, loss_scale=128, train_wall=19, gb_free=10.6, wall=44910
2023-05-26 11:51:54 - progress_bar.py[line:272] - INFO: epoch 014:   1434 / 1732 loss=2.225, loss_v1=0, loss_v2=0, nll_loss=1.009, ntokens=1196.2, nsentences=32, sample_size=1196.2, sample_size_v1=0, sample_size_v2=0, ppl=2.01, wps=634.8, ups=0.53, wpb=1196.2, bsz=32, num_updates=23910, lr=1.72287e-05, gnorm=4.88, clip=100, loss_scale=128, train_wall=19, gb_free=11.1, wall=44929
2023-05-26 11:52:13 - progress_bar.py[line:272] - INFO: epoch 014:   1444 / 1732 loss=2.232, loss_v1=0, loss_v2=0, nll_loss=1.018, ntokens=1129.1, nsentences=32, sample_size=1129.1, sample_size_v1=0, sample_size_v2=0, ppl=2.02, wps=597.3, ups=0.53, wpb=1129.1, bsz=32, num_updates=23920, lr=1.72225e-05, gnorm=4.787, clip=100, loss_scale=128, train_wall=19, gb_free=10.6, wall=44948
2023-05-26 11:52:32 - progress_bar.py[line:272] - INFO: epoch 014:   1454 / 1732 loss=2.237, loss_v1=0, loss_v2=0, nll_loss=1.02, ntokens=1122, nsentences=32, sample_size=1122, sample_size_v1=0, sample_size_v2=0, ppl=2.03, wps=597.7, ups=0.53, wpb=1122, bsz=32, num_updates=23930, lr=1.72164e-05, gnorm=5.444, clip=100, loss_scale=128, train_wall=19, gb_free=10.8, wall=44966
2023-05-26 11:52:51 - progress_bar.py[line:272] - INFO: epoch 014:   1464 / 1732 loss=2.214, loss_v1=0, loss_v2=0, nll_loss=0.994, ntokens=1182.3, nsentences=32, sample_size=1182.3, sample_size_v1=0, sample_size_v2=0, ppl=1.99, wps=621.8, ups=0.53, wpb=1182.3, bsz=32, num_updates=23940, lr=1.72102e-05, gnorm=5.068, clip=100, loss_scale=128, train_wall=19, gb_free=11.2, wall=44985
2023-05-26 11:53:10 - progress_bar.py[line:272] - INFO: epoch 014:   1474 / 1732 loss=2.225, loss_v1=0, loss_v2=0, nll_loss=1.007, ntokens=1095.3, nsentences=32, sample_size=1095.3, sample_size_v1=0, sample_size_v2=0, ppl=2.01, wps=582.6, ups=0.53, wpb=1095.3, bsz=32, num_updates=23950, lr=1.72041e-05, gnorm=5.262, clip=100, loss_scale=128, train_wall=19, gb_free=11.3, wall=45004
2023-05-26 11:53:28 - progress_bar.py[line:272] - INFO: epoch 014:   1484 / 1732 loss=2.251, loss_v1=0, loss_v2=0, nll_loss=1.037, ntokens=1096.5, nsentences=32, sample_size=1096.5, sample_size_v1=0, sample_size_v2=0, ppl=2.05, wps=583, ups=0.53, wpb=1096.5, bsz=32, num_updates=23960, lr=1.7198e-05, gnorm=5.264, clip=100, loss_scale=128, train_wall=19, gb_free=10.6, wall=45023
2023-05-26 11:53:47 - progress_bar.py[line:272] - INFO: epoch 014:   1494 / 1732 loss=2.223, loss_v1=0, loss_v2=0, nll_loss=1.005, ntokens=1106.4, nsentences=32, sample_size=1106.4, sample_size_v1=0, sample_size_v2=0, ppl=2.01, wps=585.3, ups=0.53, wpb=1106.4, bsz=32, num_updates=23970, lr=1.71918e-05, gnorm=5.053, clip=100, loss_scale=128, train_wall=19, gb_free=11, wall=45042
2023-05-26 11:54:06 - progress_bar.py[line:272] - INFO: epoch 014:   1504 / 1732 loss=2.186, loss_v1=0, loss_v2=0, nll_loss=0.964, ntokens=1153.1, nsentences=32, sample_size=1153.1, sample_size_v1=0, sample_size_v2=0, ppl=1.95, wps=609.8, ups=0.53, wpb=1153.1, bsz=32, num_updates=23980, lr=1.71857e-05, gnorm=4.772, clip=100, loss_scale=128, train_wall=19, gb_free=10.9, wall=45061
2023-05-26 11:54:21 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 128.0
2023-05-26 11:54:27 - progress_bar.py[line:272] - INFO: epoch 014:   1515 / 1732 loss=2.229, loss_v1=0, loss_v2=0, nll_loss=1.013, ntokens=1031.1, nsentences=32, sample_size=1031.1, sample_size_v1=0, sample_size_v2=0, ppl=2.02, wps=501.9, ups=0.49, wpb=1031.1, bsz=32, num_updates=23990, lr=1.71795e-05, gnorm=5.604, clip=100, loss_scale=128, train_wall=21, gb_free=11.1, wall=45081
2023-05-26 11:54:45 - progress_bar.py[line:272] - INFO: epoch 014:   1525 / 1732 loss=2.27, loss_v1=0, loss_v2=0, nll_loss=1.058, ntokens=1040.6, nsentences=32, sample_size=1040.6, sample_size_v1=0, sample_size_v2=0, ppl=2.08, wps=555.7, ups=0.53, wpb=1040.6, bsz=32, num_updates=24000, lr=1.71734e-05, gnorm=5.826, clip=100, loss_scale=128, train_wall=19, gb_free=11, wall=45100
2023-05-26 11:55:04 - progress_bar.py[line:272] - INFO: epoch 014:   1535 / 1732 loss=2.236, loss_v1=0, loss_v2=0, nll_loss=1.02, ntokens=1087.5, nsentences=32, sample_size=1087.5, sample_size_v1=0, sample_size_v2=0, ppl=2.03, wps=572.9, ups=0.53, wpb=1087.5, bsz=32, num_updates=24010, lr=1.71673e-05, gnorm=5.44, clip=100, loss_scale=128, train_wall=19, gb_free=10.8, wall=45119
2023-05-26 11:55:23 - progress_bar.py[line:272] - INFO: epoch 014:   1545 / 1732 loss=2.197, loss_v1=0, loss_v2=0, nll_loss=0.976, ntokens=1079.7, nsentences=32, sample_size=1079.7, sample_size_v1=0, sample_size_v2=0, ppl=1.97, wps=569.5, ups=0.53, wpb=1079.7, bsz=32, num_updates=24020, lr=1.71611e-05, gnorm=5.359, clip=100, loss_scale=128, train_wall=19, gb_free=11.5, wall=45138
2023-05-26 11:55:42 - progress_bar.py[line:272] - INFO: epoch 014:   1555 / 1732 loss=2.199, loss_v1=0, loss_v2=0, nll_loss=0.979, ntokens=1057.3, nsentences=32, sample_size=1057.3, sample_size_v1=0, sample_size_v2=0, ppl=1.97, wps=563.9, ups=0.53, wpb=1057.3, bsz=32, num_updates=24030, lr=1.7155e-05, gnorm=5.041, clip=100, loss_scale=128, train_wall=19, gb_free=11.2, wall=45157
2023-05-26 11:56:01 - progress_bar.py[line:272] - INFO: epoch 014:   1565 / 1732 loss=2.241, loss_v1=0, loss_v2=0, nll_loss=1.026, ntokens=1124.1, nsentences=32, sample_size=1124.1, sample_size_v1=0, sample_size_v2=0, ppl=2.04, wps=596, ups=0.53, wpb=1124.1, bsz=32, num_updates=24040, lr=1.71488e-05, gnorm=4.868, clip=100, loss_scale=128, train_wall=19, gb_free=10.6, wall=45176
2023-05-26 11:56:20 - progress_bar.py[line:272] - INFO: epoch 014:   1575 / 1732 loss=2.239, loss_v1=0, loss_v2=0, nll_loss=1.022, ntokens=1025.1, nsentences=32, sample_size=1025.1, sample_size_v1=0, sample_size_v2=0, ppl=2.03, wps=544.1, ups=0.53, wpb=1025.1, bsz=32, num_updates=24050, lr=1.71427e-05, gnorm=5.702, clip=100, loss_scale=128, train_wall=19, gb_free=11.7, wall=45195
2023-05-26 11:56:39 - progress_bar.py[line:272] - INFO: epoch 014:   1585 / 1732 loss=2.238, loss_v1=0, loss_v2=0, nll_loss=1.023, ntokens=1049.1, nsentences=32, sample_size=1049.1, sample_size_v1=0, sample_size_v2=0, ppl=2.03, wps=556.3, ups=0.53, wpb=1049.1, bsz=32, num_updates=24060, lr=1.71365e-05, gnorm=5.238, clip=100, loss_scale=128, train_wall=19, gb_free=10.6, wall=45213
2023-05-26 11:56:58 - progress_bar.py[line:272] - INFO: epoch 014:   1595 / 1732 loss=2.207, loss_v1=0, loss_v2=0, nll_loss=0.987, ntokens=1072.1, nsentences=32, sample_size=1072.1, sample_size_v1=0, sample_size_v2=0, ppl=1.98, wps=568.9, ups=0.53, wpb=1072.1, bsz=32, num_updates=24070, lr=1.71304e-05, gnorm=5.204, clip=100, loss_scale=128, train_wall=19, gb_free=11, wall=45232
2023-05-26 11:57:16 - progress_bar.py[line:272] - INFO: epoch 014:   1605 / 1732 loss=2.211, loss_v1=0, loss_v2=0, nll_loss=0.993, ntokens=1099, nsentences=32, sample_size=1099, sample_size_v1=0, sample_size_v2=0, ppl=1.99, wps=583.8, ups=0.53, wpb=1099, bsz=32, num_updates=24080, lr=1.71243e-05, gnorm=5.075, clip=100, loss_scale=128, train_wall=19, gb_free=11.2, wall=45251
2023-05-26 11:57:36 - progress_bar.py[line:272] - INFO: epoch 014:   1615 / 1732 loss=2.19, loss_v1=0, loss_v2=0, nll_loss=0.968, ntokens=1176.8, nsentences=32, sample_size=1176.8, sample_size_v1=0, sample_size_v2=0, ppl=1.96, wps=617.5, ups=0.52, wpb=1176.8, bsz=32, num_updates=24090, lr=1.71181e-05, gnorm=4.736, clip=100, loss_scale=128, train_wall=19, gb_free=11.4, wall=45270
2023-05-26 11:57:54 - progress_bar.py[line:272] - INFO: epoch 014:   1625 / 1732 loss=2.235, loss_v1=0, loss_v2=0, nll_loss=1.019, ntokens=1075.4, nsentences=32, sample_size=1075.4, sample_size_v1=0, sample_size_v2=0, ppl=2.03, wps=568.8, ups=0.53, wpb=1075.4, bsz=32, num_updates=24100, lr=1.7112e-05, gnorm=5.52, clip=100, loss_scale=128, train_wall=19, gb_free=10.6, wall=45289
2023-05-26 11:58:13 - progress_bar.py[line:272] - INFO: epoch 014:   1635 / 1732 loss=2.195, loss_v1=0, loss_v2=0, nll_loss=0.975, ntokens=1182.6, nsentences=32, sample_size=1182.6, sample_size_v1=0, sample_size_v2=0, ppl=1.97, wps=624.8, ups=0.53, wpb=1182.6, bsz=32, num_updates=24110, lr=1.71058e-05, gnorm=4.833, clip=100, loss_scale=128, train_wall=19, gb_free=10.6, wall=45308
2023-05-26 11:58:32 - progress_bar.py[line:272] - INFO: epoch 014:   1645 / 1732 loss=2.2, loss_v1=0, loss_v2=0, nll_loss=0.98, ntokens=1274.6, nsentences=32, sample_size=1274.6, sample_size_v1=0, sample_size_v2=0, ppl=1.97, wps=669.7, ups=0.53, wpb=1274.6, bsz=32, num_updates=24120, lr=1.70997e-05, gnorm=4.725, clip=100, loss_scale=128, train_wall=19, gb_free=11, wall=45327
2023-05-26 11:58:51 - progress_bar.py[line:272] - INFO: epoch 014:   1655 / 1732 loss=2.23, loss_v1=0, loss_v2=0, nll_loss=1.013, ntokens=951.7, nsentences=32, sample_size=951.7, sample_size_v1=0, sample_size_v2=0, ppl=2.02, wps=510.2, ups=0.54, wpb=951.7, bsz=32, num_updates=24130, lr=1.70935e-05, gnorm=5.936, clip=100, loss_scale=128, train_wall=19, gb_free=11.2, wall=45346
2023-05-26 11:59:10 - progress_bar.py[line:272] - INFO: epoch 014:   1665 / 1732 loss=2.246, loss_v1=0, loss_v2=0, nll_loss=1.031, ntokens=1028.1, nsentences=32, sample_size=1028.1, sample_size_v1=0, sample_size_v2=0, ppl=2.04, wps=546.1, ups=0.53, wpb=1028.1, bsz=32, num_updates=24140, lr=1.70874e-05, gnorm=5.508, clip=100, loss_scale=128, train_wall=19, gb_free=11, wall=45365
2023-05-26 11:59:29 - progress_bar.py[line:272] - INFO: epoch 014:   1675 / 1732 loss=2.192, loss_v1=0, loss_v2=0, nll_loss=0.97, ntokens=1102.6, nsentences=32, sample_size=1102.6, sample_size_v1=0, sample_size_v2=0, ppl=1.96, wps=585.3, ups=0.53, wpb=1102.6, bsz=32, num_updates=24150, lr=1.70813e-05, gnorm=5.195, clip=100, loss_scale=128, train_wall=19, gb_free=9.9, wall=45383
2023-05-26 11:59:48 - progress_bar.py[line:272] - INFO: epoch 014:   1685 / 1732 loss=2.193, loss_v1=0, loss_v2=0, nll_loss=0.971, ntokens=1141.1, nsentences=32, sample_size=1141.1, sample_size_v1=0, sample_size_v2=0, ppl=1.96, wps=602.4, ups=0.53, wpb=1141.1, bsz=32, num_updates=24160, lr=1.70751e-05, gnorm=4.735, clip=100, loss_scale=128, train_wall=19, gb_free=11.4, wall=45402
2023-05-26 12:00:07 - progress_bar.py[line:272] - INFO: epoch 014:   1695 / 1732 loss=2.218, loss_v1=0, loss_v2=0, nll_loss=0.999, ntokens=1274.5, nsentences=32, sample_size=1274.5, sample_size_v1=0, sample_size_v2=0, ppl=2, wps=660.8, ups=0.52, wpb=1274.5, bsz=32, num_updates=24170, lr=1.7069e-05, gnorm=4.57, clip=100, loss_scale=128, train_wall=19, gb_free=11.2, wall=45422
2023-05-26 12:00:26 - progress_bar.py[line:272] - INFO: epoch 014:   1705 / 1732 loss=2.222, loss_v1=0, loss_v2=0, nll_loss=1.005, ntokens=1217, nsentences=32, sample_size=1217, sample_size_v1=0, sample_size_v2=0, ppl=2.01, wps=638.3, ups=0.52, wpb=1217, bsz=32, num_updates=24180, lr=1.70628e-05, gnorm=4.868, clip=100, loss_scale=128, train_wall=19, gb_free=10.8, wall=45441
2023-05-26 12:00:45 - progress_bar.py[line:272] - INFO: epoch 014:   1715 / 1732 loss=2.203, loss_v1=0, loss_v2=0, nll_loss=0.982, ntokens=1196, nsentences=32, sample_size=1196, sample_size_v1=0, sample_size_v2=0, ppl=1.98, wps=631.4, ups=0.53, wpb=1196, bsz=32, num_updates=24190, lr=1.70567e-05, gnorm=4.738, clip=100, loss_scale=128, train_wall=19, gb_free=10.8, wall=45460
2023-05-26 12:01:04 - progress_bar.py[line:272] - INFO: epoch 014:   1725 / 1732 loss=2.217, loss_v1=0, loss_v2=0, nll_loss=0.999, ntokens=1108.9, nsentences=32, sample_size=1108.9, sample_size_v1=0, sample_size_v2=0, ppl=2, wps=585, ups=0.53, wpb=1108.9, bsz=32, num_updates=24200, lr=1.70505e-05, gnorm=5.098, clip=100, loss_scale=128, train_wall=19, gb_free=11.3, wall=45479
2023-05-26 12:01:16 - train.py[line:332] - INFO: end of epoch 14 (average epoch stats below)
2023-05-26 12:01:16 - progress_bar.py[line:282] - INFO: epoch 014 | loss 2.234 | loss_v1 0 | loss_v2 0 | nll_loss 1.018 | ntokens 1051.61 | nsentences 31.986 | sample_size 1051.61 | sample_size_v1 0 | sample_size_v2 0 | ppl 2.02 | wps 559.8 | ups 0.53 | wpb 1051.6 | bsz 32 | num_updates 24207 | lr 1.70463e-05 | gnorm 4.846 | clip 100 | loss_scale 128 | train_wall 3240 | gb_free 11.7 | wall 45490
2023-05-26 12:01:16 - trainer.py[line:639] - INFO: loading train data for epoch 15
local datafile ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 0 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 0 finished initializing row_count and line_idx-to-offset mapping
file ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 0 row count 55400 total row count 55400
slice_id 0 seek offset 0
2023-05-26 12:01:18 - trainer.py[line:703] - INFO: begin training epoch 15
2023-05-26 12:01:18 - train.py[line:305] - INFO: Start iterating over samples
2023-05-26 12:01:24 - progress_bar.py[line:272] - INFO: epoch 015:      3 / 1732 loss=2.248, loss_v1=0, loss_v2=0, nll_loss=1.034, ntokens=1127.6, nsentences=29.6, sample_size=1127.6, sample_size_v1=0, sample_size_v2=0, ppl=2.05, wps=569, ups=0.5, wpb=1127.6, bsz=29.6, num_updates=24210, lr=1.70444e-05, gnorm=5.128, clip=100, loss_scale=128, train_wall=18, gb_free=11, wall=45498
2023-05-26 12:01:43 - progress_bar.py[line:272] - INFO: epoch 015:     13 / 1732 loss=2.193, loss_v1=0, loss_v2=0, nll_loss=0.97, ntokens=1037.7, nsentences=32, sample_size=1037.7, sample_size_v1=0, sample_size_v2=0, ppl=1.96, wps=550.7, ups=0.53, wpb=1037.7, bsz=32, num_updates=24220, lr=1.70383e-05, gnorm=5.524, clip=100, loss_scale=128, train_wall=19, gb_free=11, wall=45517
2023-05-26 12:02:01 - progress_bar.py[line:272] - INFO: epoch 015:     23 / 1732 loss=2.135, loss_v1=0, loss_v2=0, nll_loss=0.908, ntokens=1082, nsentences=32, sample_size=1082, sample_size_v1=0, sample_size_v2=0, ppl=1.88, wps=572.8, ups=0.53, wpb=1082, bsz=32, num_updates=24230, lr=1.70321e-05, gnorm=5.185, clip=100, loss_scale=128, train_wall=19, gb_free=11.4, wall=45536
2023-05-26 12:02:20 - progress_bar.py[line:272] - INFO: epoch 015:     33 / 1732 loss=2.114, loss_v1=0, loss_v2=0, nll_loss=0.884, ntokens=1032.3, nsentences=32, sample_size=1032.3, sample_size_v1=0, sample_size_v2=0, ppl=1.85, wps=545.2, ups=0.53, wpb=1032.3, bsz=32, num_updates=24240, lr=1.7026e-05, gnorm=4.826, clip=100, loss_scale=128, train_wall=19, gb_free=10.2, wall=45555
2023-05-26 12:02:39 - progress_bar.py[line:272] - INFO: epoch 015:     43 / 1732 loss=2.045, loss_v1=0, loss_v2=0, nll_loss=0.808, ntokens=1156.8, nsentences=32, sample_size=1156.8, sample_size_v1=0, sample_size_v2=0, ppl=1.75, wps=610.6, ups=0.53, wpb=1156.8, bsz=32, num_updates=24250, lr=1.70198e-05, gnorm=4.608, clip=100, loss_scale=128, train_wall=19, gb_free=11, wall=45574
2023-05-26 12:02:58 - progress_bar.py[line:272] - INFO: epoch 015:     53 / 1732 loss=2.088, loss_v1=0, loss_v2=0, nll_loss=0.855, ntokens=1016.6, nsentences=32, sample_size=1016.6, sample_size_v1=0, sample_size_v2=0, ppl=1.81, wps=539.1, ups=0.53, wpb=1016.6, bsz=32, num_updates=24260, lr=1.70137e-05, gnorm=4.895, clip=100, loss_scale=128, train_wall=19, gb_free=11.4, wall=45593
2023-05-26 12:03:17 - progress_bar.py[line:272] - INFO: epoch 015:     63 / 1732 loss=1.92, loss_v1=0, loss_v2=0, nll_loss=0.668, ntokens=1239.4, nsentences=32, sample_size=1239.4, sample_size_v1=0, sample_size_v2=0, ppl=1.59, wps=650.8, ups=0.53, wpb=1239.4, bsz=32, num_updates=24270, lr=1.70076e-05, gnorm=4.189, clip=100, loss_scale=128, train_wall=19, gb_free=10.3, wall=45612
2023-05-26 12:03:37 - progress_bar.py[line:272] - INFO: epoch 015:     73 / 1732 loss=2.012, loss_v1=0, loss_v2=0, nll_loss=0.77, ntokens=1389.6, nsentences=32, sample_size=1389.6, sample_size_v1=0, sample_size_v2=0, ppl=1.71, wps=714, ups=0.51, wpb=1389.6, bsz=32, num_updates=24280, lr=1.70014e-05, gnorm=3.361, clip=100, loss_scale=128, train_wall=19, gb_free=10, wall=45631
2023-05-26 12:03:56 - progress_bar.py[line:272] - INFO: epoch 015:     83 / 1732 loss=2.056, loss_v1=0, loss_v2=0, nll_loss=0.819, ntokens=1166.3, nsentences=32, sample_size=1166.3, sample_size_v1=0, sample_size_v2=0, ppl=1.76, wps=607.8, ups=0.52, wpb=1166.3, bsz=32, num_updates=24290, lr=1.69953e-05, gnorm=5.115, clip=100, loss_scale=128, train_wall=19, gb_free=10.2, wall=45651
2023-05-26 12:04:15 - progress_bar.py[line:272] - INFO: epoch 015:     93 / 1732 loss=2.029, loss_v1=0, loss_v2=0, nll_loss=0.788, ntokens=1099.1, nsentences=32, sample_size=1099.1, sample_size_v1=0, sample_size_v2=0, ppl=1.73, wps=577.1, ups=0.53, wpb=1099.1, bsz=32, num_updates=24300, lr=1.69891e-05, gnorm=4.606, clip=100, loss_scale=128, train_wall=19, gb_free=11, wall=45670
2023-05-26 12:04:34 - progress_bar.py[line:272] - INFO: epoch 015:    103 / 1732 loss=2.164, loss_v1=0, loss_v2=0, nll_loss=0.944, ntokens=976, nsentences=32, sample_size=976, sample_size_v1=0, sample_size_v2=0, ppl=1.92, wps=520.7, ups=0.53, wpb=976, bsz=32, num_updates=24310, lr=1.6983e-05, gnorm=5.153, clip=100, loss_scale=128, train_wall=19, gb_free=11.5, wall=45688
2023-05-26 12:04:53 - progress_bar.py[line:272] - INFO: epoch 015:    113 / 1732 loss=2.238, loss_v1=0, loss_v2=0, nll_loss=1.022, ntokens=1030.9, nsentences=32, sample_size=1030.9, sample_size_v1=0, sample_size_v2=0, ppl=2.03, wps=544.3, ups=0.53, wpb=1030.9, bsz=32, num_updates=24320, lr=1.69768e-05, gnorm=5.501, clip=100, loss_scale=128, train_wall=19, gb_free=10.8, wall=45707
2023-05-26 12:05:12 - progress_bar.py[line:272] - INFO: epoch 015:    123 / 1732 loss=2.224, loss_v1=0, loss_v2=0, nll_loss=1.005, ntokens=1142.2, nsentences=32, sample_size=1142.2, sample_size_v1=0, sample_size_v2=0, ppl=2.01, wps=595.5, ups=0.52, wpb=1142.2, bsz=32, num_updates=24330, lr=1.69707e-05, gnorm=5.429, clip=100, loss_scale=128, train_wall=19, gb_free=10.7, wall=45727
2023-05-26 12:05:31 - progress_bar.py[line:272] - INFO: epoch 015:    133 / 1732 loss=2.173, loss_v1=0, loss_v2=0, nll_loss=0.949, ntokens=1207.4, nsentences=32, sample_size=1207.4, sample_size_v1=0, sample_size_v2=0, ppl=1.93, wps=629.9, ups=0.52, wpb=1207.4, bsz=32, num_updates=24340, lr=1.69646e-05, gnorm=4.904, clip=100, loss_scale=128, train_wall=19, gb_free=10.8, wall=45746
2023-05-26 12:05:50 - progress_bar.py[line:272] - INFO: epoch 015:    143 / 1732 loss=2.157, loss_v1=0, loss_v2=0, nll_loss=0.931, ntokens=1226.6, nsentences=32, sample_size=1226.6, sample_size_v1=0, sample_size_v2=0, ppl=1.91, wps=636.9, ups=0.52, wpb=1226.6, bsz=32, num_updates=24350, lr=1.69584e-05, gnorm=4.885, clip=100, loss_scale=128, train_wall=19, gb_free=10.2, wall=45765
2023-05-26 12:06:10 - progress_bar.py[line:272] - INFO: epoch 015:    153 / 1732 loss=2.158, loss_v1=0, loss_v2=0, nll_loss=0.934, ntokens=1152.6, nsentences=32, sample_size=1152.6, sample_size_v1=0, sample_size_v2=0, ppl=1.91, wps=599.4, ups=0.52, wpb=1152.6, bsz=32, num_updates=24360, lr=1.69523e-05, gnorm=4.665, clip=100, loss_scale=128, train_wall=19, gb_free=10.3, wall=45784
2023-05-26 12:06:28 - progress_bar.py[line:272] - INFO: epoch 015:    163 / 1732 loss=2.165, loss_v1=0, loss_v2=0, nll_loss=0.941, ntokens=1079.7, nsentences=32, sample_size=1079.7, sample_size_v1=0, sample_size_v2=0, ppl=1.92, wps=569.5, ups=0.53, wpb=1079.7, bsz=32, num_updates=24370, lr=1.69461e-05, gnorm=5.455, clip=100, loss_scale=128, train_wall=19, gb_free=11.5, wall=45803
2023-05-26 12:06:47 - progress_bar.py[line:272] - INFO: epoch 015:    173 / 1732 loss=2.169, loss_v1=0, loss_v2=0, nll_loss=0.945, ntokens=936.5, nsentences=32, sample_size=936.5, sample_size_v1=0, sample_size_v2=0, ppl=1.92, wps=496.5, ups=0.53, wpb=936.5, bsz=32, num_updates=24380, lr=1.694e-05, gnorm=5.885, clip=100, loss_scale=128, train_wall=19, gb_free=10.7, wall=45822
2023-05-26 12:07:06 - progress_bar.py[line:272] - INFO: epoch 015:    183 / 1732 loss=2.132, loss_v1=0, loss_v2=0, nll_loss=0.904, ntokens=1184.7, nsentences=32, sample_size=1184.7, sample_size_v1=0, sample_size_v2=0, ppl=1.87, wps=620.3, ups=0.52, wpb=1184.7, bsz=32, num_updates=24390, lr=1.69338e-05, gnorm=4.523, clip=100, loss_scale=128, train_wall=19, gb_free=11.3, wall=45841
2023-05-26 12:07:26 - progress_bar.py[line:272] - INFO: epoch 015:    193 / 1732 loss=2.143, loss_v1=0, loss_v2=0, nll_loss=0.916, ntokens=1122.8, nsentences=32, sample_size=1122.8, sample_size_v1=0, sample_size_v2=0, ppl=1.89, wps=589.1, ups=0.52, wpb=1122.8, bsz=32, num_updates=24400, lr=1.69277e-05, gnorm=4.802, clip=100, loss_scale=128, train_wall=19, gb_free=11.2, wall=45860
2023-05-26 12:07:44 - progress_bar.py[line:272] - INFO: epoch 015:    203 / 1732 loss=2.224, loss_v1=0, loss_v2=0, nll_loss=1.006, ntokens=1086.7, nsentences=32, sample_size=1086.7, sample_size_v1=0, sample_size_v2=0, ppl=2.01, wps=577.4, ups=0.53, wpb=1086.7, bsz=32, num_updates=24410, lr=1.69216e-05, gnorm=5.253, clip=100, loss_scale=128, train_wall=19, gb_free=11.3, wall=45879
2023-05-26 12:08:03 - progress_bar.py[line:272] - INFO: epoch 015:    213 / 1732 loss=2.237, loss_v1=0, loss_v2=0, nll_loss=1.022, ntokens=1044.9, nsentences=32, sample_size=1044.9, sample_size_v1=0, sample_size_v2=0, ppl=2.03, wps=558.9, ups=0.53, wpb=1044.9, bsz=32, num_updates=24420, lr=1.69154e-05, gnorm=5.233, clip=100, loss_scale=128, train_wall=19, gb_free=11.2, wall=45898
2023-05-26 12:08:22 - progress_bar.py[line:272] - INFO: epoch 015:    223 / 1732 loss=2.243, loss_v1=0, loss_v2=0, nll_loss=1.028, ntokens=1134.6, nsentences=32, sample_size=1134.6, sample_size_v1=0, sample_size_v2=0, ppl=2.04, wps=606.6, ups=0.53, wpb=1134.6, bsz=32, num_updates=24430, lr=1.69093e-05, gnorm=5.202, clip=100, loss_scale=128, train_wall=19, gb_free=11.3, wall=45916
2023-05-26 12:08:40 - progress_bar.py[line:272] - INFO: epoch 015:    233 / 1732 loss=2.273, loss_v1=0, loss_v2=0, nll_loss=1.061, ntokens=1078.6, nsentences=32, sample_size=1078.6, sample_size_v1=0, sample_size_v2=0, ppl=2.09, wps=578.3, ups=0.54, wpb=1078.6, bsz=32, num_updates=24440, lr=1.69031e-05, gnorm=4.99, clip=100, loss_scale=128, train_wall=19, gb_free=11.5, wall=45935
2023-05-26 12:08:59 - progress_bar.py[line:272] - INFO: epoch 015:    243 / 1732 loss=2.254, loss_v1=0, loss_v2=0, nll_loss=1.039, ntokens=1123.3, nsentences=32, sample_size=1123.3, sample_size_v1=0, sample_size_v2=0, ppl=2.06, wps=596.2, ups=0.53, wpb=1123.3, bsz=32, num_updates=24450, lr=1.6897e-05, gnorm=4.684, clip=100, loss_scale=128, train_wall=19, gb_free=11.5, wall=45954
2023-05-26 12:09:18 - progress_bar.py[line:272] - INFO: epoch 015:    253 / 1732 loss=2.264, loss_v1=0, loss_v2=0, nll_loss=1.053, ntokens=1167.4, nsentences=32, sample_size=1167.4, sample_size_v1=0, sample_size_v2=0, ppl=2.07, wps=620.2, ups=0.53, wpb=1167.4, bsz=32, num_updates=24460, lr=1.68909e-05, gnorm=4.781, clip=100, loss_scale=128, train_wall=19, gb_free=10.8, wall=45973
2023-05-26 12:09:37 - progress_bar.py[line:272] - INFO: epoch 015:    263 / 1732 loss=2.251, loss_v1=0, loss_v2=0, nll_loss=1.037, ntokens=1123.9, nsentences=32, sample_size=1123.9, sample_size_v1=0, sample_size_v2=0, ppl=2.05, wps=600.8, ups=0.53, wpb=1123.9, bsz=32, num_updates=24470, lr=1.68847e-05, gnorm=5.182, clip=100, loss_scale=128, train_wall=19, gb_free=10.8, wall=45991
2023-05-26 12:09:56 - progress_bar.py[line:272] - INFO: epoch 015:    273 / 1732 loss=2.245, loss_v1=0, loss_v2=0, nll_loss=1.028, ntokens=1154.8, nsentences=32, sample_size=1154.8, sample_size_v1=0, sample_size_v2=0, ppl=2.04, wps=613.3, ups=0.53, wpb=1154.8, bsz=32, num_updates=24480, lr=1.68786e-05, gnorm=4.871, clip=100, loss_scale=128, train_wall=19, gb_free=11, wall=46010
2023-05-26 12:10:15 - progress_bar.py[line:272] - INFO: epoch 015:    283 / 1732 loss=2.265, loss_v1=0, loss_v2=0, nll_loss=1.051, ntokens=1146.7, nsentences=32, sample_size=1146.7, sample_size_v1=0, sample_size_v2=0, ppl=2.07, wps=606.2, ups=0.53, wpb=1146.7, bsz=32, num_updates=24490, lr=1.68724e-05, gnorm=4.884, clip=100, loss_scale=128, train_wall=19, gb_free=11.2, wall=46029
2023-05-26 12:10:33 - progress_bar.py[line:272] - INFO: epoch 015:    293 / 1732 loss=2.229, loss_v1=0, loss_v2=0, nll_loss=1.014, ntokens=1122.6, nsentences=32, sample_size=1122.6, sample_size_v1=0, sample_size_v2=0, ppl=2.02, wps=598.5, ups=0.53, wpb=1122.6, bsz=32, num_updates=24500, lr=1.68663e-05, gnorm=4.637, clip=100, loss_scale=256, train_wall=19, gb_free=10.3, wall=46048
2023-05-26 12:10:35 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 128.0
2023-05-26 12:10:54 - progress_bar.py[line:272] - INFO: epoch 015:    304 / 1732 loss=2.243, loss_v1=0, loss_v2=0, nll_loss=1.03, ntokens=1100.1, nsentences=32, sample_size=1100.1, sample_size_v1=0, sample_size_v2=0, ppl=2.04, wps=535.5, ups=0.49, wpb=1100.1, bsz=32, num_updates=24510, lr=1.68601e-05, gnorm=5.11, clip=100, loss_scale=128, train_wall=21, gb_free=11.4, wall=46069
2023-05-26 12:11:12 - progress_bar.py[line:272] - INFO: epoch 015:    314 / 1732 loss=2.251, loss_v1=0, loss_v2=0, nll_loss=1.037, ntokens=1016.6, nsentences=32, sample_size=1016.6, sample_size_v1=0, sample_size_v2=0, ppl=2.05, wps=547, ups=0.54, wpb=1016.6, bsz=32, num_updates=24520, lr=1.6854e-05, gnorm=5.753, clip=100, loss_scale=128, train_wall=19, gb_free=11.9, wall=46087
2023-05-26 12:11:31 - progress_bar.py[line:272] - INFO: epoch 015:    324 / 1732 loss=2.278, loss_v1=0, loss_v2=0, nll_loss=1.064, ntokens=1018.7, nsentences=32, sample_size=1018.7, sample_size_v1=0, sample_size_v2=0, ppl=2.09, wps=546.8, ups=0.54, wpb=1018.7, bsz=32, num_updates=24530, lr=1.68479e-05, gnorm=5.766, clip=100, loss_scale=128, train_wall=19, gb_free=11.3, wall=46106
2023-05-26 12:11:50 - progress_bar.py[line:272] - INFO: epoch 015:    334 / 1732 loss=2.272, loss_v1=0, loss_v2=0, nll_loss=1.062, ntokens=1018.9, nsentences=32, sample_size=1018.9, sample_size_v1=0, sample_size_v2=0, ppl=2.09, wps=548.1, ups=0.54, wpb=1018.9, bsz=32, num_updates=24540, lr=1.68417e-05, gnorm=5.655, clip=100, loss_scale=128, train_wall=19, gb_free=11.7, wall=46124
2023-05-26 12:12:08 - progress_bar.py[line:272] - INFO: epoch 015:    344 / 1732 loss=2.227, loss_v1=0, loss_v2=0, nll_loss=1.009, ntokens=921, nsentences=32, sample_size=921, sample_size_v1=0, sample_size_v2=0, ppl=2.01, wps=497.3, ups=0.54, wpb=921, bsz=32, num_updates=24550, lr=1.68356e-05, gnorm=5.783, clip=100, loss_scale=128, train_wall=18, gb_free=11.4, wall=46143
2023-05-26 12:12:27 - progress_bar.py[line:272] - INFO: epoch 015:    354 / 1732 loss=2.251, loss_v1=0, loss_v2=0, nll_loss=1.037, ntokens=961.9, nsentences=32, sample_size=961.9, sample_size_v1=0, sample_size_v2=0, ppl=2.05, wps=518.3, ups=0.54, wpb=961.9, bsz=32, num_updates=24560, lr=1.68294e-05, gnorm=5.226, clip=100, loss_scale=128, train_wall=19, gb_free=11.3, wall=46161
2023-05-26 12:12:45 - progress_bar.py[line:272] - INFO: epoch 015:    364 / 1732 loss=2.292, loss_v1=0, loss_v2=0, nll_loss=1.081, ntokens=927.9, nsentences=32, sample_size=927.9, sample_size_v1=0, sample_size_v2=0, ppl=2.12, wps=501.7, ups=0.54, wpb=927.9, bsz=32, num_updates=24570, lr=1.68233e-05, gnorm=6.279, clip=100, loss_scale=128, train_wall=18, gb_free=11.8, wall=46180
2023-05-26 12:13:04 - progress_bar.py[line:272] - INFO: epoch 015:    374 / 1732 loss=2.27, loss_v1=0, loss_v2=0, nll_loss=1.056, ntokens=1000.4, nsentences=32, sample_size=1000.4, sample_size_v1=0, sample_size_v2=0, ppl=2.08, wps=538.2, ups=0.54, wpb=1000.4, bsz=32, num_updates=24580, lr=1.68171e-05, gnorm=5.754, clip=100, loss_scale=128, train_wall=19, gb_free=11.5, wall=46198
2023-05-26 12:13:22 - progress_bar.py[line:272] - INFO: epoch 015:    384 / 1732 loss=2.275, loss_v1=0, loss_v2=0, nll_loss=1.063, ntokens=1084.8, nsentences=32, sample_size=1084.8, sample_size_v1=0, sample_size_v2=0, ppl=2.09, wps=584.6, ups=0.54, wpb=1084.8, bsz=32, num_updates=24590, lr=1.6811e-05, gnorm=5.508, clip=100, loss_scale=128, train_wall=19, gb_free=10.9, wall=46217
2023-05-26 12:13:41 - progress_bar.py[line:272] - INFO: epoch 015:    394 / 1732 loss=2.276, loss_v1=0, loss_v2=0, nll_loss=1.063, ntokens=950.6, nsentences=32, sample_size=950.6, sample_size_v1=0, sample_size_v2=0, ppl=2.09, wps=513.6, ups=0.54, wpb=950.6, bsz=32, num_updates=24600, lr=1.68049e-05, gnorm=5.725, clip=100, loss_scale=128, train_wall=18, gb_free=11.7, wall=46236
2023-05-26 12:14:00 - progress_bar.py[line:272] - INFO: epoch 015:    404 / 1732 loss=2.23, loss_v1=0, loss_v2=0, nll_loss=1.013, ntokens=1060.5, nsentences=32, sample_size=1060.5, sample_size_v1=0, sample_size_v2=0, ppl=2.02, wps=568, ups=0.54, wpb=1060.5, bsz=32, num_updates=24610, lr=1.67987e-05, gnorm=5.376, clip=100, loss_scale=128, train_wall=19, gb_free=11.1, wall=46254
2023-05-26 12:14:18 - progress_bar.py[line:272] - INFO: epoch 015:    414 / 1732 loss=2.231, loss_v1=0, loss_v2=0, nll_loss=1.015, ntokens=1066.1, nsentences=32, sample_size=1066.1, sample_size_v1=0, sample_size_v2=0, ppl=2.02, wps=572.7, ups=0.54, wpb=1066.1, bsz=32, num_updates=24620, lr=1.67926e-05, gnorm=5.083, clip=100, loss_scale=128, train_wall=19, gb_free=9.9, wall=46273
2023-05-26 12:14:37 - progress_bar.py[line:272] - INFO: epoch 015:    424 / 1732 loss=2.206, loss_v1=0, loss_v2=0, nll_loss=0.987, ntokens=992.6, nsentences=32, sample_size=992.6, sample_size_v1=0, sample_size_v2=0, ppl=1.98, wps=534.1, ups=0.54, wpb=992.6, bsz=32, num_updates=24630, lr=1.67864e-05, gnorm=5.988, clip=100, loss_scale=128, train_wall=19, gb_free=11.7, wall=46291
2023-05-26 12:14:55 - progress_bar.py[line:272] - INFO: epoch 015:    434 / 1732 loss=2.245, loss_v1=0, loss_v2=0, nll_loss=1.028, ntokens=1018.1, nsentences=32, sample_size=1018.1, sample_size_v1=0, sample_size_v2=0, ppl=2.04, wps=547.5, ups=0.54, wpb=1018.1, bsz=32, num_updates=24640, lr=1.67803e-05, gnorm=5.77, clip=100, loss_scale=128, train_wall=19, gb_free=11.8, wall=46310
2023-05-26 12:15:14 - progress_bar.py[line:272] - INFO: epoch 015:    444 / 1732 loss=2.259, loss_v1=0, loss_v2=0, nll_loss=1.045, ntokens=952.1, nsentences=32, sample_size=952.1, sample_size_v1=0, sample_size_v2=0, ppl=2.06, wps=514.3, ups=0.54, wpb=952.1, bsz=32, num_updates=24650, lr=1.67742e-05, gnorm=5.396, clip=100, loss_scale=128, train_wall=18, gb_free=11.7, wall=46329
2023-05-26 12:15:32 - progress_bar.py[line:272] - INFO: epoch 015:    454 / 1732 loss=2.257, loss_v1=0, loss_v2=0, nll_loss=1.044, ntokens=919.5, nsentences=32, sample_size=919.5, sample_size_v1=0, sample_size_v2=0, ppl=2.06, wps=496.6, ups=0.54, wpb=919.5, bsz=32, num_updates=24660, lr=1.6768e-05, gnorm=5.603, clip=100, loss_scale=128, train_wall=18, gb_free=11.4, wall=46347
2023-05-26 12:15:51 - progress_bar.py[line:272] - INFO: epoch 015:    464 / 1732 loss=2.276, loss_v1=0, loss_v2=0, nll_loss=1.065, ntokens=1076.9, nsentences=32, sample_size=1076.9, sample_size_v1=0, sample_size_v2=0, ppl=2.09, wps=577.2, ups=0.54, wpb=1076.9, bsz=32, num_updates=24670, lr=1.67619e-05, gnorm=5.638, clip=100, loss_scale=128, train_wall=19, gb_free=11.7, wall=46366
2023-05-26 12:16:10 - progress_bar.py[line:272] - INFO: epoch 015:    474 / 1732 loss=2.269, loss_v1=0, loss_v2=0, nll_loss=1.056, ntokens=1067.6, nsentences=32, sample_size=1067.6, sample_size_v1=0, sample_size_v2=0, ppl=2.08, wps=569.9, ups=0.53, wpb=1067.6, bsz=32, num_updates=24680, lr=1.67557e-05, gnorm=5.445, clip=100, loss_scale=128, train_wall=19, gb_free=11.8, wall=46384
2023-05-26 12:16:28 - progress_bar.py[line:272] - INFO: epoch 015:    484 / 1732 loss=2.257, loss_v1=0, loss_v2=0, nll_loss=1.042, ntokens=966.8, nsentences=32, sample_size=966.8, sample_size_v1=0, sample_size_v2=0, ppl=2.06, wps=522, ups=0.54, wpb=966.8, bsz=32, num_updates=24690, lr=1.67496e-05, gnorm=6.004, clip=100, loss_scale=128, train_wall=18, gb_free=11.6, wall=46403
2023-05-26 12:16:47 - progress_bar.py[line:272] - INFO: epoch 015:    494 / 1732 loss=2.246, loss_v1=0, loss_v2=0, nll_loss=1.031, ntokens=937.9, nsentences=32, sample_size=937.9, sample_size_v1=0, sample_size_v2=0, ppl=2.04, wps=505.1, ups=0.54, wpb=937.9, bsz=32, num_updates=24700, lr=1.67434e-05, gnorm=5.485, clip=100, loss_scale=128, train_wall=19, gb_free=11.3, wall=46422
2023-05-26 12:17:05 - progress_bar.py[line:272] - INFO: epoch 015:    504 / 1732 loss=2.262, loss_v1=0, loss_v2=0, nll_loss=1.05, ntokens=981, nsentences=32, sample_size=981, sample_size_v1=0, sample_size_v2=0, ppl=2.07, wps=533.5, ups=0.54, wpb=981, bsz=32, num_updates=24710, lr=1.67373e-05, gnorm=6.181, clip=100, loss_scale=128, train_wall=18, gb_free=11.4, wall=46440
2023-05-26 12:17:24 - progress_bar.py[line:272] - INFO: epoch 015:    514 / 1732 loss=2.277, loss_v1=0, loss_v2=0, nll_loss=1.065, ntokens=1052.2, nsentences=32, sample_size=1052.2, sample_size_v1=0, sample_size_v2=0, ppl=2.09, wps=565.9, ups=0.54, wpb=1052.2, bsz=32, num_updates=24720, lr=1.67312e-05, gnorm=5.431, clip=100, loss_scale=128, train_wall=19, gb_free=11.7, wall=46459
2023-05-26 12:17:42 - progress_bar.py[line:272] - INFO: epoch 015:    524 / 1732 loss=2.235, loss_v1=0, loss_v2=0, nll_loss=1.018, ntokens=980.8, nsentences=32, sample_size=980.8, sample_size_v1=0, sample_size_v2=0, ppl=2.03, wps=530.8, ups=0.54, wpb=980.8, bsz=32, num_updates=24730, lr=1.6725e-05, gnorm=5.562, clip=100, loss_scale=128, train_wall=18, gb_free=11.6, wall=46477
2023-05-26 12:18:01 - progress_bar.py[line:272] - INFO: epoch 015:    534 / 1732 loss=2.249, loss_v1=0, loss_v2=0, nll_loss=1.034, ntokens=944.9, nsentences=32, sample_size=944.9, sample_size_v1=0, sample_size_v2=0, ppl=2.05, wps=510.2, ups=0.54, wpb=944.9, bsz=32, num_updates=24740, lr=1.67189e-05, gnorm=5.773, clip=100, loss_scale=128, train_wall=18, gb_free=11.5, wall=46496
2023-05-26 12:18:19 - progress_bar.py[line:272] - INFO: epoch 015:    544 / 1732 loss=2.258, loss_v1=0, loss_v2=0, nll_loss=1.045, ntokens=998.9, nsentences=32, sample_size=998.9, sample_size_v1=0, sample_size_v2=0, ppl=2.06, wps=539.2, ups=0.54, wpb=998.9, bsz=32, num_updates=24750, lr=1.67127e-05, gnorm=5.839, clip=100, loss_scale=128, train_wall=18, gb_free=11.5, wall=46514
2023-05-26 12:18:38 - progress_bar.py[line:272] - INFO: epoch 015:    554 / 1732 loss=2.29, loss_v1=0, loss_v2=0, nll_loss=1.081, ntokens=1026.7, nsentences=32, sample_size=1026.7, sample_size_v1=0, sample_size_v2=0, ppl=2.11, wps=553, ups=0.54, wpb=1026.7, bsz=32, num_updates=24760, lr=1.67066e-05, gnorm=5.884, clip=100, loss_scale=128, train_wall=19, gb_free=11.3, wall=46533
2023-05-26 12:18:57 - progress_bar.py[line:272] - INFO: epoch 015:    564 / 1732 loss=2.277, loss_v1=0, loss_v2=0, nll_loss=1.065, ntokens=1028.3, nsentences=32, sample_size=1028.3, sample_size_v1=0, sample_size_v2=0, ppl=2.09, wps=552.4, ups=0.54, wpb=1028.3, bsz=32, num_updates=24770, lr=1.67004e-05, gnorm=5.656, clip=100, loss_scale=128, train_wall=19, gb_free=11, wall=46551
2023-05-26 12:19:15 - progress_bar.py[line:272] - INFO: epoch 015:    574 / 1732 loss=2.269, loss_v1=0, loss_v2=0, nll_loss=1.056, ntokens=1015.5, nsentences=32, sample_size=1015.5, sample_size_v1=0, sample_size_v2=0, ppl=2.08, wps=542.1, ups=0.53, wpb=1015.5, bsz=32, num_updates=24780, lr=1.66943e-05, gnorm=6.248, clip=100, loss_scale=128, train_wall=19, gb_free=11.3, wall=46570
2023-05-26 12:19:34 - progress_bar.py[line:272] - INFO: epoch 015:    584 / 1732 loss=2.27, loss_v1=0, loss_v2=0, nll_loss=1.057, ntokens=991.8, nsentences=32, sample_size=991.8, sample_size_v1=0, sample_size_v2=0, ppl=2.08, wps=531, ups=0.54, wpb=991.8, bsz=32, num_updates=24790, lr=1.66882e-05, gnorm=5.793, clip=100, loss_scale=128, train_wall=19, gb_free=10.8, wall=46589
2023-05-26 12:19:53 - progress_bar.py[line:272] - INFO: epoch 015:    594 / 1732 loss=2.225, loss_v1=0, loss_v2=0, nll_loss=1.008, ntokens=957.2, nsentences=32, sample_size=957.2, sample_size_v1=0, sample_size_v2=0, ppl=2.01, wps=513.7, ups=0.54, wpb=957.2, bsz=32, num_updates=24800, lr=1.6682e-05, gnorm=5.885, clip=100, loss_scale=128, train_wall=19, gb_free=11, wall=46607
2023-05-26 12:20:11 - progress_bar.py[line:272] - INFO: epoch 015:    604 / 1732 loss=2.229, loss_v1=0, loss_v2=0, nll_loss=1.013, ntokens=888.6, nsentences=32, sample_size=888.6, sample_size_v1=0, sample_size_v2=0, ppl=2.02, wps=482.4, ups=0.54, wpb=888.6, bsz=32, num_updates=24810, lr=1.66759e-05, gnorm=5.954, clip=100, loss_scale=128, train_wall=18, gb_free=11.3, wall=46626
2023-05-26 12:20:30 - progress_bar.py[line:272] - INFO: epoch 015:    614 / 1732 loss=2.27, loss_v1=0, loss_v2=0, nll_loss=1.06, ntokens=891, nsentences=32, sample_size=891, sample_size_v1=0, sample_size_v2=0, ppl=2.08, wps=481.9, ups=0.54, wpb=891, bsz=32, num_updates=24820, lr=1.66697e-05, gnorm=6.373, clip=100, loss_scale=128, train_wall=18, gb_free=11.6, wall=46644
2023-05-26 12:20:48 - progress_bar.py[line:272] - INFO: epoch 015:    624 / 1732 loss=2.268, loss_v1=0, loss_v2=0, nll_loss=1.054, ntokens=899.1, nsentences=32, sample_size=899.1, sample_size_v1=0, sample_size_v2=0, ppl=2.08, wps=488.6, ups=0.54, wpb=899.1, bsz=32, num_updates=24830, lr=1.66636e-05, gnorm=6.379, clip=100, loss_scale=128, train_wall=18, gb_free=11.9, wall=46663
2023-05-26 12:21:06 - progress_bar.py[line:272] - INFO: epoch 015:    634 / 1732 loss=2.257, loss_v1=0, loss_v2=0, nll_loss=1.042, ntokens=904.7, nsentences=32, sample_size=904.7, sample_size_v1=0, sample_size_v2=0, ppl=2.06, wps=491.5, ups=0.54, wpb=904.7, bsz=32, num_updates=24840, lr=1.66575e-05, gnorm=6.465, clip=100, loss_scale=128, train_wall=18, gb_free=11.9, wall=46681
2023-05-26 12:21:25 - progress_bar.py[line:272] - INFO: epoch 015:    644 / 1732 loss=2.267, loss_v1=0, loss_v2=0, nll_loss=1.056, ntokens=979.3, nsentences=32, sample_size=979.3, sample_size_v1=0, sample_size_v2=0, ppl=2.08, wps=528.8, ups=0.54, wpb=979.3, bsz=32, num_updates=24850, lr=1.66513e-05, gnorm=6.288, clip=100, loss_scale=128, train_wall=18, gb_free=11.7, wall=46700
2023-05-26 12:21:43 - progress_bar.py[line:272] - INFO: epoch 015:    654 / 1732 loss=2.254, loss_v1=0, loss_v2=0, nll_loss=1.04, ntokens=909.5, nsentences=32, sample_size=909.5, sample_size_v1=0, sample_size_v2=0, ppl=2.06, wps=497, ups=0.55, wpb=909.5, bsz=32, num_updates=24860, lr=1.66452e-05, gnorm=6.33, clip=100, loss_scale=128, train_wall=18, gb_free=11.4, wall=46718
2023-05-26 12:22:02 - progress_bar.py[line:272] - INFO: epoch 015:    664 / 1732 loss=2.252, loss_v1=0, loss_v2=0, nll_loss=1.037, ntokens=889.3, nsentences=32, sample_size=889.3, sample_size_v1=0, sample_size_v2=0, ppl=2.05, wps=484.4, ups=0.54, wpb=889.3, bsz=32, num_updates=24870, lr=1.6639e-05, gnorm=6.554, clip=100, loss_scale=128, train_wall=18, gb_free=11.7, wall=46736
2023-05-26 12:22:20 - progress_bar.py[line:272] - INFO: epoch 015:    674 / 1732 loss=2.282, loss_v1=0, loss_v2=0, nll_loss=1.072, ntokens=964.6, nsentences=32, sample_size=964.6, sample_size_v1=0, sample_size_v2=0, ppl=2.1, wps=520.1, ups=0.54, wpb=964.6, bsz=32, num_updates=24880, lr=1.66329e-05, gnorm=6.144, clip=100, loss_scale=128, train_wall=19, gb_free=11.5, wall=46755
2023-05-26 12:22:39 - progress_bar.py[line:272] - INFO: epoch 015:    684 / 1732 loss=2.258, loss_v1=0, loss_v2=0, nll_loss=1.042, ntokens=968.6, nsentences=32, sample_size=968.6, sample_size_v1=0, sample_size_v2=0, ppl=2.06, wps=524.8, ups=0.54, wpb=968.6, bsz=32, num_updates=24890, lr=1.66267e-05, gnorm=6.218, clip=100, loss_scale=128, train_wall=18, gb_free=11.9, wall=46773
2023-05-26 12:22:50 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2023-05-26 12:22:59 - progress_bar.py[line:272] - INFO: epoch 015:    695 / 1732 loss=2.266, loss_v1=0, loss_v2=0, nll_loss=1.053, ntokens=977.6, nsentences=32, sample_size=977.6, sample_size_v1=0, sample_size_v2=0, ppl=2.08, wps=477.7, ups=0.49, wpb=977.6, bsz=32, num_updates=24900, lr=1.66206e-05, gnorm=6.117, clip=100, loss_scale=64, train_wall=20, gb_free=10.5, wall=46794
2023-05-26 12:23:18 - progress_bar.py[line:272] - INFO: epoch 015:    705 / 1732 loss=2.226, loss_v1=0, loss_v2=0, nll_loss=1.01, ntokens=925.6, nsentences=32, sample_size=925.6, sample_size_v1=0, sample_size_v2=0, ppl=2.01, wps=501.1, ups=0.54, wpb=925.6, bsz=32, num_updates=24910, lr=1.66145e-05, gnorm=6.167, clip=100, loss_scale=64, train_wall=18, gb_free=11.8, wall=46812
2023-05-26 12:23:36 - progress_bar.py[line:272] - INFO: epoch 015:    715 / 1732 loss=2.265, loss_v1=0, loss_v2=0, nll_loss=1.053, ntokens=890.5, nsentences=32, sample_size=890.5, sample_size_v1=0, sample_size_v2=0, ppl=2.07, wps=483, ups=0.54, wpb=890.5, bsz=32, num_updates=24920, lr=1.66083e-05, gnorm=6.679, clip=100, loss_scale=64, train_wall=18, gb_free=11.7, wall=46831
2023-05-26 12:23:54 - progress_bar.py[line:272] - INFO: epoch 015:    725 / 1732 loss=2.219, loss_v1=0, loss_v2=0, nll_loss=1.001, ntokens=904.8, nsentences=32, sample_size=904.8, sample_size_v1=0, sample_size_v2=0, ppl=2, wps=491.3, ups=0.54, wpb=904.8, bsz=32, num_updates=24930, lr=1.66022e-05, gnorm=6.41, clip=100, loss_scale=64, train_wall=18, gb_free=11.5, wall=46849
2023-05-26 12:24:13 - progress_bar.py[line:272] - INFO: epoch 015:    735 / 1732 loss=2.252, loss_v1=0, loss_v2=0, nll_loss=1.038, ntokens=965.8, nsentences=32, sample_size=965.8, sample_size_v1=0, sample_size_v2=0, ppl=2.05, wps=523.7, ups=0.54, wpb=965.8, bsz=32, num_updates=24940, lr=1.6596e-05, gnorm=6.084, clip=100, loss_scale=64, train_wall=18, gb_free=11.6, wall=46868
2023-05-26 12:24:31 - progress_bar.py[line:272] - INFO: epoch 015:    745 / 1732 loss=2.229, loss_v1=0, loss_v2=0, nll_loss=1.012, ntokens=978.3, nsentences=32, sample_size=978.3, sample_size_v1=0, sample_size_v2=0, ppl=2.02, wps=527.8, ups=0.54, wpb=978.3, bsz=32, num_updates=24950, lr=1.65899e-05, gnorm=6.073, clip=100, loss_scale=64, train_wall=19, gb_free=11.1, wall=46886
2023-05-26 12:24:50 - progress_bar.py[line:272] - INFO: epoch 015:    755 / 1732 loss=2.242, loss_v1=0, loss_v2=0, nll_loss=1.026, ntokens=975.4, nsentences=32, sample_size=975.4, sample_size_v1=0, sample_size_v2=0, ppl=2.04, wps=525.4, ups=0.54, wpb=975.4, bsz=32, num_updates=24960, lr=1.65837e-05, gnorm=5.96, clip=100, loss_scale=64, train_wall=19, gb_free=11.7, wall=46905
2023-05-26 12:25:08 - progress_bar.py[line:272] - INFO: epoch 015:    765 / 1732 loss=2.238, loss_v1=0, loss_v2=0, nll_loss=1.021, ntokens=948.8, nsentences=32, sample_size=948.8, sample_size_v1=0, sample_size_v2=0, ppl=2.03, wps=514.9, ups=0.54, wpb=948.8, bsz=32, num_updates=24970, lr=1.65776e-05, gnorm=5.768, clip=100, loss_scale=64, train_wall=18, gb_free=10.9, wall=46923
2023-05-26 12:25:27 - progress_bar.py[line:272] - INFO: epoch 015:    775 / 1732 loss=2.241, loss_v1=0, loss_v2=0, nll_loss=1.027, ntokens=1002.4, nsentences=32, sample_size=1002.4, sample_size_v1=0, sample_size_v2=0, ppl=2.04, wps=541.7, ups=0.54, wpb=1002.4, bsz=32, num_updates=24980, lr=1.65715e-05, gnorm=6.324, clip=100, loss_scale=64, train_wall=18, gb_free=11.5, wall=46942
2023-05-26 12:25:45 - progress_bar.py[line:272] - INFO: epoch 015:    785 / 1732 loss=2.242, loss_v1=0, loss_v2=0, nll_loss=1.027, ntokens=1003.9, nsentences=32, sample_size=1003.9, sample_size_v1=0, sample_size_v2=0, ppl=2.04, wps=540.9, ups=0.54, wpb=1003.9, bsz=32, num_updates=24990, lr=1.65653e-05, gnorm=5.762, clip=100, loss_scale=64, train_wall=19, gb_free=11.2, wall=46960
2023-05-26 12:26:04 - progress_bar.py[line:272] - INFO: epoch 015:    795 / 1732 loss=2.26, loss_v1=0, loss_v2=0, nll_loss=1.048, ntokens=1051.8, nsentences=32, sample_size=1051.8, sample_size_v1=0, sample_size_v2=0, ppl=2.07, wps=568.1, ups=0.54, wpb=1051.8, bsz=32, num_updates=25000, lr=1.65592e-05, gnorm=6.455, clip=100, loss_scale=64, train_wall=18, gb_free=11.1, wall=46979
2023-05-26 12:26:22 - progress_bar.py[line:272] - INFO: epoch 015:    805 / 1732 loss=2.25, loss_v1=0, loss_v2=0, nll_loss=1.034, ntokens=913, nsentences=32, sample_size=913, sample_size_v1=0, sample_size_v2=0, ppl=2.05, wps=493.5, ups=0.54, wpb=913, bsz=32, num_updates=25010, lr=1.6553e-05, gnorm=6.896, clip=100, loss_scale=64, train_wall=18, gb_free=11.1, wall=46997
2023-05-26 12:26:41 - progress_bar.py[line:272] - INFO: epoch 015:    815 / 1732 loss=2.243, loss_v1=0, loss_v2=0, nll_loss=1.029, ntokens=936.3, nsentences=32, sample_size=936.3, sample_size_v1=0, sample_size_v2=0, ppl=2.04, wps=506.4, ups=0.54, wpb=936.3, bsz=32, num_updates=25020, lr=1.65469e-05, gnorm=6.341, clip=100, loss_scale=64, train_wall=18, gb_free=11.7, wall=47016
2023-05-26 12:27:00 - progress_bar.py[line:272] - INFO: epoch 015:    825 / 1732 loss=2.251, loss_v1=0, loss_v2=0, nll_loss=1.036, ntokens=931.3, nsentences=32, sample_size=931.3, sample_size_v1=0, sample_size_v2=0, ppl=2.05, wps=501, ups=0.54, wpb=931.3, bsz=32, num_updates=25030, lr=1.65408e-05, gnorm=6.71, clip=100, loss_scale=64, train_wall=19, gb_free=12, wall=47034
2023-05-26 12:27:18 - progress_bar.py[line:272] - INFO: epoch 015:    835 / 1732 loss=2.248, loss_v1=0, loss_v2=0, nll_loss=1.033, ntokens=897.4, nsentences=32, sample_size=897.4, sample_size_v1=0, sample_size_v2=0, ppl=2.05, wps=489.5, ups=0.55, wpb=897.4, bsz=32, num_updates=25040, lr=1.65346e-05, gnorm=6.542, clip=100, loss_scale=64, train_wall=18, gb_free=11.6, wall=47053
2023-05-26 12:27:36 - progress_bar.py[line:272] - INFO: epoch 015:    845 / 1732 loss=2.234, loss_v1=0, loss_v2=0, nll_loss=1.017, ntokens=987.4, nsentences=32, sample_size=987.4, sample_size_v1=0, sample_size_v2=0, ppl=2.02, wps=536.3, ups=0.54, wpb=987.4, bsz=32, num_updates=25050, lr=1.65285e-05, gnorm=6.043, clip=100, loss_scale=64, train_wall=18, gb_free=11.2, wall=47071
2023-05-26 12:27:55 - progress_bar.py[line:272] - INFO: epoch 015:    855 / 1732 loss=2.241, loss_v1=0, loss_v2=0, nll_loss=1.025, ntokens=952, nsentences=32, sample_size=952, sample_size_v1=0, sample_size_v2=0, ppl=2.04, wps=514.7, ups=0.54, wpb=952, bsz=32, num_updates=25060, lr=1.65223e-05, gnorm=6.373, clip=100, loss_scale=64, train_wall=18, gb_free=11.8, wall=47089
2023-05-26 12:28:13 - progress_bar.py[line:272] - INFO: epoch 015:    865 / 1732 loss=2.251, loss_v1=0, loss_v2=0, nll_loss=1.039, ntokens=968.1, nsentences=32, sample_size=968.1, sample_size_v1=0, sample_size_v2=0, ppl=2.06, wps=522.6, ups=0.54, wpb=968.1, bsz=32, num_updates=25070, lr=1.65162e-05, gnorm=6.167, clip=100, loss_scale=64, train_wall=18, gb_free=11.5, wall=47108
2023-05-26 12:28:32 - progress_bar.py[line:272] - INFO: epoch 015:    875 / 1732 loss=2.217, loss_v1=0, loss_v2=0, nll_loss=1, ntokens=985.7, nsentences=32, sample_size=985.7, sample_size_v1=0, sample_size_v2=0, ppl=2, wps=531.9, ups=0.54, wpb=985.7, bsz=32, num_updates=25080, lr=1.651e-05, gnorm=5.917, clip=100, loss_scale=64, train_wall=19, gb_free=11.4, wall=47127
2023-05-26 12:28:50 - progress_bar.py[line:272] - INFO: epoch 015:    885 / 1732 loss=2.2, loss_v1=0, loss_v2=0, nll_loss=0.979, ntokens=961.4, nsentences=32, sample_size=961.4, sample_size_v1=0, sample_size_v2=0, ppl=1.97, wps=518.4, ups=0.54, wpb=961.4, bsz=32, num_updates=25090, lr=1.65039e-05, gnorm=6.175, clip=100, loss_scale=64, train_wall=19, gb_free=11.4, wall=47145
2023-05-26 12:29:09 - progress_bar.py[line:272] - INFO: epoch 015:    895 / 1732 loss=2.194, loss_v1=0, loss_v2=0, nll_loss=0.972, ntokens=1031.3, nsentences=32, sample_size=1031.3, sample_size_v1=0, sample_size_v2=0, ppl=1.96, wps=554.9, ups=0.54, wpb=1031.3, bsz=32, num_updates=25100, lr=1.64978e-05, gnorm=5.653, clip=100, loss_scale=64, train_wall=19, gb_free=11.7, wall=47164
2023-05-26 12:29:28 - progress_bar.py[line:272] - INFO: epoch 015:    905 / 1732 loss=2.196, loss_v1=0, loss_v2=0, nll_loss=0.974, ntokens=1040.4, nsentences=32, sample_size=1040.4, sample_size_v1=0, sample_size_v2=0, ppl=1.96, wps=555.3, ups=0.53, wpb=1040.4, bsz=32, num_updates=25110, lr=1.64916e-05, gnorm=5.599, clip=100, loss_scale=64, train_wall=19, gb_free=11.1, wall=47182
2023-05-26 12:29:46 - progress_bar.py[line:272] - INFO: epoch 015:    915 / 1732 loss=2.269, loss_v1=0, loss_v2=0, nll_loss=1.058, ntokens=937.6, nsentences=32, sample_size=937.6, sample_size_v1=0, sample_size_v2=0, ppl=2.08, wps=507.9, ups=0.54, wpb=937.6, bsz=32, num_updates=25120, lr=1.64855e-05, gnorm=6.79, clip=100, loss_scale=64, train_wall=18, gb_free=12, wall=47201
2023-05-26 12:30:05 - progress_bar.py[line:272] - INFO: epoch 015:    925 / 1732 loss=2.209, loss_v1=0, loss_v2=0, nll_loss=0.991, ntokens=1005.1, nsentences=32, sample_size=1005.1, sample_size_v1=0, sample_size_v2=0, ppl=1.99, wps=535.2, ups=0.53, wpb=1005.1, bsz=32, num_updates=25130, lr=1.64793e-05, gnorm=5.991, clip=100, loss_scale=64, train_wall=19, gb_free=11.8, wall=47220
2023-05-26 12:30:24 - progress_bar.py[line:272] - INFO: epoch 015:    935 / 1732 loss=2.235, loss_v1=0, loss_v2=0, nll_loss=1.018, ntokens=1058.5, nsentences=32, sample_size=1058.5, sample_size_v1=0, sample_size_v2=0, ppl=2.03, wps=564.5, ups=0.53, wpb=1058.5, bsz=32, num_updates=25140, lr=1.64732e-05, gnorm=6.176, clip=100, loss_scale=64, train_wall=19, gb_free=11.3, wall=47238
2023-05-26 12:30:43 - progress_bar.py[line:272] - INFO: epoch 015:    945 / 1732 loss=2.26, loss_v1=0, loss_v2=0, nll_loss=1.048, ntokens=1055.4, nsentences=32, sample_size=1055.4, sample_size_v1=0, sample_size_v2=0, ppl=2.07, wps=560.6, ups=0.53, wpb=1055.4, bsz=32, num_updates=25150, lr=1.6467e-05, gnorm=6.033, clip=100, loss_scale=64, train_wall=19, gb_free=11.2, wall=47257
2023-05-26 12:31:01 - progress_bar.py[line:272] - INFO: epoch 015:    955 / 1732 loss=2.234, loss_v1=0, loss_v2=0, nll_loss=1.016, ntokens=1040.2, nsentences=32, sample_size=1040.2, sample_size_v1=0, sample_size_v2=0, ppl=2.02, wps=554.6, ups=0.53, wpb=1040.2, bsz=32, num_updates=25160, lr=1.64609e-05, gnorm=5.92, clip=100, loss_scale=64, train_wall=19, gb_free=11.4, wall=47276
2023-05-26 12:31:20 - progress_bar.py[line:272] - INFO: epoch 015:    965 / 1732 loss=2.247, loss_v1=0, loss_v2=0, nll_loss=1.031, ntokens=1047.7, nsentences=32, sample_size=1047.7, sample_size_v1=0, sample_size_v2=0, ppl=2.04, wps=557.1, ups=0.53, wpb=1047.7, bsz=32, num_updates=25170, lr=1.64548e-05, gnorm=6.143, clip=100, loss_scale=64, train_wall=19, gb_free=11.4, wall=47295
2023-05-26 12:31:39 - progress_bar.py[line:272] - INFO: epoch 015:    975 / 1732 loss=2.226, loss_v1=0, loss_v2=0, nll_loss=1.009, ntokens=1038, nsentences=32, sample_size=1038, sample_size_v1=0, sample_size_v2=0, ppl=2.01, wps=551.7, ups=0.53, wpb=1038, bsz=32, num_updates=25180, lr=1.64486e-05, gnorm=6.048, clip=100, loss_scale=64, train_wall=19, gb_free=11.6, wall=47314
2023-05-26 12:31:58 - progress_bar.py[line:272] - INFO: epoch 015:    985 / 1732 loss=2.237, loss_v1=0, loss_v2=0, nll_loss=1.021, ntokens=1034.6, nsentences=32, sample_size=1034.6, sample_size_v1=0, sample_size_v2=0, ppl=2.03, wps=547.7, ups=0.53, wpb=1034.6, bsz=32, num_updates=25190, lr=1.64425e-05, gnorm=5.769, clip=100, loss_scale=64, train_wall=19, gb_free=11.6, wall=47333
2023-05-26 12:32:17 - progress_bar.py[line:272] - INFO: epoch 015:    995 / 1732 loss=2.231, loss_v1=0, loss_v2=0, nll_loss=1.013, ntokens=1048.7, nsentences=32, sample_size=1048.7, sample_size_v1=0, sample_size_v2=0, ppl=2.02, wps=559.2, ups=0.53, wpb=1048.7, bsz=32, num_updates=25200, lr=1.64363e-05, gnorm=6.261, clip=100, loss_scale=64, train_wall=19, gb_free=10.6, wall=47351
2023-05-26 12:32:35 - progress_bar.py[line:272] - INFO: epoch 015:   1005 / 1732 loss=2.238, loss_v1=0, loss_v2=0, nll_loss=1.021, ntokens=981.9, nsentences=32, sample_size=981.9, sample_size_v1=0, sample_size_v2=0, ppl=2.03, wps=525.7, ups=0.54, wpb=981.9, bsz=32, num_updates=25210, lr=1.64302e-05, gnorm=6.58, clip=100, loss_scale=64, train_wall=19, gb_free=11.5, wall=47370
2023-05-26 12:32:54 - progress_bar.py[line:272] - INFO: epoch 015:   1015 / 1732 loss=2.238, loss_v1=0, loss_v2=0, nll_loss=1.023, ntokens=996.6, nsentences=32, sample_size=996.6, sample_size_v1=0, sample_size_v2=0, ppl=2.03, wps=534.7, ups=0.54, wpb=996.6, bsz=32, num_updates=25220, lr=1.64241e-05, gnorm=6.169, clip=100, loss_scale=64, train_wall=19, gb_free=11.7, wall=47389
2023-05-26 12:33:13 - progress_bar.py[line:272] - INFO: epoch 015:   1025 / 1732 loss=2.221, loss_v1=0, loss_v2=0, nll_loss=1.003, ntokens=1087.5, nsentences=32, sample_size=1087.5, sample_size_v1=0, sample_size_v2=0, ppl=2, wps=574.1, ups=0.53, wpb=1087.5, bsz=32, num_updates=25230, lr=1.64179e-05, gnorm=6.148, clip=100, loss_scale=64, train_wall=19, gb_free=10.8, wall=47408
2023-05-26 12:33:32 - progress_bar.py[line:272] - INFO: epoch 015:   1035 / 1732 loss=2.233, loss_v1=0, loss_v2=0, nll_loss=1.016, ntokens=1118.6, nsentences=32, sample_size=1118.6, sample_size_v1=0, sample_size_v2=0, ppl=2.02, wps=593.7, ups=0.53, wpb=1118.6, bsz=32, num_updates=25240, lr=1.64118e-05, gnorm=6.258, clip=100, loss_scale=64, train_wall=19, gb_free=11.4, wall=47426
2023-05-26 12:33:51 - progress_bar.py[line:272] - INFO: epoch 015:   1045 / 1732 loss=2.233, loss_v1=0, loss_v2=0, nll_loss=1.015, ntokens=1030.7, nsentences=32, sample_size=1030.7, sample_size_v1=0, sample_size_v2=0, ppl=2.02, wps=548.1, ups=0.53, wpb=1030.7, bsz=32, num_updates=25250, lr=1.64056e-05, gnorm=6.237, clip=100, loss_scale=64, train_wall=19, gb_free=11.6, wall=47445
2023-05-26 12:34:09 - progress_bar.py[line:272] - INFO: epoch 015:   1055 / 1732 loss=2.239, loss_v1=0, loss_v2=0, nll_loss=1.024, ntokens=1077.2, nsentences=32, sample_size=1077.2, sample_size_v1=0, sample_size_v2=0, ppl=2.03, wps=575.3, ups=0.53, wpb=1077.2, bsz=32, num_updates=25260, lr=1.63995e-05, gnorm=6.655, clip=100, loss_scale=64, train_wall=19, gb_free=11.1, wall=47464
2023-05-26 12:34:28 - progress_bar.py[line:272] - INFO: epoch 015:   1065 / 1732 loss=2.224, loss_v1=0, loss_v2=0, nll_loss=1.007, ntokens=1021, nsentences=32, sample_size=1021, sample_size_v1=0, sample_size_v2=0, ppl=2.01, wps=545.2, ups=0.53, wpb=1021, bsz=32, num_updates=25270, lr=1.63933e-05, gnorm=6.496, clip=100, loss_scale=64, train_wall=19, gb_free=11.3, wall=47483
2023-05-26 12:34:47 - progress_bar.py[line:272] - INFO: epoch 015:   1075 / 1732 loss=2.227, loss_v1=0, loss_v2=0, nll_loss=1.01, ntokens=1007.9, nsentences=32, sample_size=1007.9, sample_size_v1=0, sample_size_v2=0, ppl=2.01, wps=535.9, ups=0.53, wpb=1007.9, bsz=32, num_updates=25280, lr=1.63872e-05, gnorm=5.811, clip=100, loss_scale=64, train_wall=19, gb_free=10.9, wall=47501
2023-05-26 12:35:06 - progress_bar.py[line:272] - INFO: epoch 015:   1085 / 1732 loss=2.242, loss_v1=0, loss_v2=0, nll_loss=1.027, ntokens=1052.2, nsentences=32, sample_size=1052.2, sample_size_v1=0, sample_size_v2=0, ppl=2.04, wps=557.7, ups=0.53, wpb=1052.2, bsz=32, num_updates=25290, lr=1.63811e-05, gnorm=6.337, clip=100, loss_scale=64, train_wall=19, gb_free=11.7, wall=47520
2023-05-26 12:35:24 - progress_bar.py[line:272] - INFO: epoch 015:   1095 / 1732 loss=2.249, loss_v1=0, loss_v2=0, nll_loss=1.034, ntokens=1070, nsentences=32, sample_size=1070, sample_size_v1=0, sample_size_v2=0, ppl=2.05, wps=570.2, ups=0.53, wpb=1070, bsz=32, num_updates=25300, lr=1.63749e-05, gnorm=6.246, clip=100, loss_scale=64, train_wall=19, gb_free=11.4, wall=47539
2023-05-26 12:35:43 - progress_bar.py[line:272] - INFO: epoch 015:   1105 / 1732 loss=2.216, loss_v1=0, loss_v2=0, nll_loss=0.997, ntokens=1032.4, nsentences=32, sample_size=1032.4, sample_size_v1=0, sample_size_v2=0, ppl=2, wps=550.1, ups=0.53, wpb=1032.4, bsz=32, num_updates=25310, lr=1.63688e-05, gnorm=5.981, clip=100, loss_scale=64, train_wall=19, gb_free=11.5, wall=47558
2023-05-26 12:36:02 - progress_bar.py[line:272] - INFO: epoch 015:   1115 / 1732 loss=2.238, loss_v1=0, loss_v2=0, nll_loss=1.02, ntokens=979.5, nsentences=32, sample_size=979.5, sample_size_v1=0, sample_size_v2=0, ppl=2.03, wps=523.9, ups=0.53, wpb=979.5, bsz=32, num_updates=25320, lr=1.63626e-05, gnorm=6.429, clip=100, loss_scale=64, train_wall=19, gb_free=11.2, wall=47577
2023-05-26 12:36:21 - progress_bar.py[line:272] - INFO: epoch 015:   1125 / 1732 loss=2.216, loss_v1=0, loss_v2=0, nll_loss=0.997, ntokens=994.1, nsentences=32, sample_size=994.1, sample_size_v1=0, sample_size_v2=0, ppl=2, wps=529.1, ups=0.53, wpb=994.1, bsz=32, num_updates=25330, lr=1.63565e-05, gnorm=6.397, clip=100, loss_scale=64, train_wall=19, gb_free=10.9, wall=47595
2023-05-26 12:36:39 - progress_bar.py[line:272] - INFO: epoch 015:   1135 / 1732 loss=2.226, loss_v1=0, loss_v2=0, nll_loss=1.01, ntokens=998.2, nsentences=32, sample_size=998.2, sample_size_v1=0, sample_size_v2=0, ppl=2.01, wps=533.4, ups=0.53, wpb=998.2, bsz=32, num_updates=25340, lr=1.63503e-05, gnorm=6.266, clip=100, loss_scale=64, train_wall=19, gb_free=11.3, wall=47614
2023-05-26 12:36:58 - progress_bar.py[line:272] - INFO: epoch 015:   1145 / 1732 loss=2.227, loss_v1=0, loss_v2=0, nll_loss=1.011, ntokens=1012.1, nsentences=32, sample_size=1012.1, sample_size_v1=0, sample_size_v2=0, ppl=2.02, wps=539.4, ups=0.53, wpb=1012.1, bsz=32, num_updates=25350, lr=1.63442e-05, gnorm=6.232, clip=100, loss_scale=64, train_wall=19, gb_free=10.8, wall=47633
2023-05-26 12:37:17 - progress_bar.py[line:272] - INFO: epoch 015:   1155 / 1732 loss=2.199, loss_v1=0, loss_v2=0, nll_loss=0.979, ntokens=1037.8, nsentences=32, sample_size=1037.8, sample_size_v1=0, sample_size_v2=0, ppl=1.97, wps=553.7, ups=0.53, wpb=1037.8, bsz=32, num_updates=25360, lr=1.63381e-05, gnorm=6.121, clip=100, loss_scale=64, train_wall=19, gb_free=11.5, wall=47652
2023-05-26 12:37:36 - progress_bar.py[line:272] - INFO: epoch 015:   1165 / 1732 loss=2.204, loss_v1=0, loss_v2=0, nll_loss=0.985, ntokens=1000.9, nsentences=32, sample_size=1000.9, sample_size_v1=0, sample_size_v2=0, ppl=1.98, wps=532.8, ups=0.53, wpb=1000.9, bsz=32, num_updates=25370, lr=1.63319e-05, gnorm=6.149, clip=100, loss_scale=64, train_wall=19, gb_free=11.1, wall=47670
2023-05-26 12:37:54 - progress_bar.py[line:272] - INFO: epoch 015:   1175 / 1732 loss=2.21, loss_v1=0, loss_v2=0, nll_loss=0.99, ntokens=1076.2, nsentences=32, sample_size=1076.2, sample_size_v1=0, sample_size_v2=0, ppl=1.99, wps=573.6, ups=0.53, wpb=1076.2, bsz=32, num_updates=25380, lr=1.63258e-05, gnorm=5.655, clip=100, loss_scale=64, train_wall=19, gb_free=11, wall=47689
2023-05-26 12:38:13 - progress_bar.py[line:272] - INFO: epoch 015:   1185 / 1732 loss=2.209, loss_v1=0, loss_v2=0, nll_loss=0.989, ntokens=957.5, nsentences=32, sample_size=957.5, sample_size_v1=0, sample_size_v2=0, ppl=1.98, wps=512.3, ups=0.54, wpb=957.5, bsz=32, num_updates=25390, lr=1.63196e-05, gnorm=6.494, clip=100, loss_scale=64, train_wall=19, gb_free=11.6, wall=47708
2023-05-26 12:38:32 - progress_bar.py[line:272] - INFO: epoch 015:   1195 / 1732 loss=2.236, loss_v1=0, loss_v2=0, nll_loss=1.022, ntokens=1058.2, nsentences=32, sample_size=1058.2, sample_size_v1=0, sample_size_v2=0, ppl=2.03, wps=563.9, ups=0.53, wpb=1058.2, bsz=32, num_updates=25400, lr=1.63135e-05, gnorm=6.27, clip=100, loss_scale=64, train_wall=19, gb_free=11.4, wall=47727
2023-05-26 12:38:51 - progress_bar.py[line:272] - INFO: epoch 015:   1205 / 1732 loss=2.199, loss_v1=0, loss_v2=0, nll_loss=0.977, ntokens=1142.5, nsentences=32, sample_size=1142.5, sample_size_v1=0, sample_size_v2=0, ppl=1.97, wps=601.7, ups=0.53, wpb=1142.5, bsz=32, num_updates=25410, lr=1.63074e-05, gnorm=5.604, clip=100, loss_scale=128, train_wall=19, gb_free=11.1, wall=47746
2023-05-26 12:39:10 - progress_bar.py[line:272] - INFO: epoch 015:   1215 / 1732 loss=2.225, loss_v1=0, loss_v2=0, nll_loss=1.008, ntokens=998.9, nsentences=32, sample_size=998.9, sample_size_v1=0, sample_size_v2=0, ppl=2.01, wps=534.4, ups=0.54, wpb=998.9, bsz=32, num_updates=25420, lr=1.63012e-05, gnorm=6.075, clip=100, loss_scale=128, train_wall=19, gb_free=11.7, wall=47764
2023-05-26 12:39:28 - progress_bar.py[line:272] - INFO: epoch 015:   1225 / 1732 loss=2.239, loss_v1=0, loss_v2=0, nll_loss=1.024, ntokens=1043.3, nsentences=32, sample_size=1043.3, sample_size_v1=0, sample_size_v2=0, ppl=2.03, wps=553.8, ups=0.53, wpb=1043.3, bsz=32, num_updates=25430, lr=1.62951e-05, gnorm=6.237, clip=100, loss_scale=128, train_wall=19, gb_free=11.8, wall=47783
2023-05-26 12:39:47 - progress_bar.py[line:272] - INFO: epoch 015:   1235 / 1732 loss=2.209, loss_v1=0, loss_v2=0, nll_loss=0.989, ntokens=1038.1, nsentences=32, sample_size=1038.1, sample_size_v1=0, sample_size_v2=0, ppl=1.98, wps=553.6, ups=0.53, wpb=1038.1, bsz=32, num_updates=25440, lr=1.62889e-05, gnorm=6.098, clip=100, loss_scale=128, train_wall=19, gb_free=10.4, wall=47802
2023-05-26 12:40:06 - progress_bar.py[line:272] - INFO: epoch 015:   1245 / 1732 loss=2.168, loss_v1=0, loss_v2=0, nll_loss=0.943, ntokens=1088.5, nsentences=32, sample_size=1088.5, sample_size_v1=0, sample_size_v2=0, ppl=1.92, wps=577.7, ups=0.53, wpb=1088.5, bsz=32, num_updates=25450, lr=1.62828e-05, gnorm=5.838, clip=100, loss_scale=128, train_wall=19, gb_free=11, wall=47821
2023-05-26 12:40:25 - progress_bar.py[line:272] - INFO: epoch 015:   1255 / 1732 loss=2.19, loss_v1=0, loss_v2=0, nll_loss=0.97, ntokens=1068.9, nsentences=32, sample_size=1068.9, sample_size_v1=0, sample_size_v2=0, ppl=1.96, wps=568.8, ups=0.53, wpb=1068.9, bsz=32, num_updates=25460, lr=1.62766e-05, gnorm=5.753, clip=100, loss_scale=128, train_wall=19, gb_free=11.4, wall=47840
2023-05-26 12:40:27 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2023-05-26 12:40:46 - progress_bar.py[line:272] - INFO: epoch 015:   1266 / 1732 loss=2.222, loss_v1=0, loss_v2=0, nll_loss=1.005, ntokens=1048.7, nsentences=32, sample_size=1048.7, sample_size_v1=0, sample_size_v2=0, ppl=2.01, wps=508.7, ups=0.49, wpb=1048.7, bsz=32, num_updates=25470, lr=1.62705e-05, gnorm=6.122, clip=100, loss_scale=64, train_wall=21, gb_free=11.5, wall=47860
2023-05-26 12:41:04 - progress_bar.py[line:272] - INFO: epoch 015:   1276 / 1732 loss=2.217, loss_v1=0, loss_v2=0, nll_loss=1, ntokens=1075.2, nsentences=32, sample_size=1075.2, sample_size_v1=0, sample_size_v2=0, ppl=2, wps=569.9, ups=0.53, wpb=1075.2, bsz=32, num_updates=25480, lr=1.62644e-05, gnorm=5.473, clip=100, loss_scale=64, train_wall=19, gb_free=11, wall=47879
2023-05-26 12:41:23 - progress_bar.py[line:272] - INFO: epoch 015:   1286 / 1732 loss=2.222, loss_v1=0, loss_v2=0, nll_loss=1.003, ntokens=1038.1, nsentences=32, sample_size=1038.1, sample_size_v1=0, sample_size_v2=0, ppl=2, wps=551.3, ups=0.53, wpb=1038.1, bsz=32, num_updates=25490, lr=1.62582e-05, gnorm=5.96, clip=100, loss_scale=64, train_wall=19, gb_free=11.6, wall=47898
2023-05-26 12:41:42 - progress_bar.py[line:272] - INFO: epoch 015:   1296 / 1732 loss=2.197, loss_v1=0, loss_v2=0, nll_loss=0.975, ntokens=1121.3, nsentences=32, sample_size=1121.3, sample_size_v1=0, sample_size_v2=0, ppl=1.97, wps=593.9, ups=0.53, wpb=1121.3, bsz=32, num_updates=25500, lr=1.62521e-05, gnorm=5.538, clip=100, loss_scale=64, train_wall=19, gb_free=11.6, wall=47917
2023-05-26 12:42:01 - progress_bar.py[line:272] - INFO: epoch 015:   1306 / 1732 loss=2.246, loss_v1=0, loss_v2=0, nll_loss=1.031, ntokens=1091, nsentences=32, sample_size=1091, sample_size_v1=0, sample_size_v2=0, ppl=2.04, wps=575.6, ups=0.53, wpb=1091, bsz=32, num_updates=25510, lr=1.62459e-05, gnorm=5.903, clip=100, loss_scale=64, train_wall=19, gb_free=10.8, wall=47936
2023-05-26 12:42:20 - progress_bar.py[line:272] - INFO: epoch 015:   1316 / 1732 loss=2.225, loss_v1=0, loss_v2=0, nll_loss=1.008, ntokens=1049.3, nsentences=32, sample_size=1049.3, sample_size_v1=0, sample_size_v2=0, ppl=2.01, wps=555.2, ups=0.53, wpb=1049.3, bsz=32, num_updates=25520, lr=1.62398e-05, gnorm=6.243, clip=100, loss_scale=64, train_wall=19, gb_free=11.3, wall=47955
2023-05-26 12:42:39 - progress_bar.py[line:272] - INFO: epoch 015:   1326 / 1732 loss=2.196, loss_v1=0, loss_v2=0, nll_loss=0.975, ntokens=1110.6, nsentences=32, sample_size=1110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.97, wps=586.6, ups=0.53, wpb=1110.6, bsz=32, num_updates=25530, lr=1.62336e-05, gnorm=5.713, clip=100, loss_scale=64, train_wall=19, gb_free=11.5, wall=47974
2023-05-26 12:42:58 - progress_bar.py[line:272] - INFO: epoch 015:   1336 / 1732 loss=2.197, loss_v1=0, loss_v2=0, nll_loss=0.976, ntokens=1122.3, nsentences=32, sample_size=1122.3, sample_size_v1=0, sample_size_v2=0, ppl=1.97, wps=596.4, ups=0.53, wpb=1122.3, bsz=32, num_updates=25540, lr=1.62275e-05, gnorm=6.104, clip=100, loss_scale=64, train_wall=19, gb_free=10.9, wall=47992
2023-05-26 12:43:17 - progress_bar.py[line:272] - INFO: epoch 015:   1346 / 1732 loss=2.207, loss_v1=0, loss_v2=0, nll_loss=0.987, ntokens=1171.7, nsentences=32, sample_size=1171.7, sample_size_v1=0, sample_size_v2=0, ppl=1.98, wps=616.5, ups=0.53, wpb=1171.7, bsz=32, num_updates=25550, lr=1.62214e-05, gnorm=6.292, clip=100, loss_scale=64, train_wall=19, gb_free=11, wall=48011
2023-05-26 12:43:36 - progress_bar.py[line:272] - INFO: epoch 015:   1356 / 1732 loss=2.191, loss_v1=0, loss_v2=0, nll_loss=0.97, ntokens=1137.3, nsentences=32, sample_size=1137.3, sample_size_v1=0, sample_size_v2=0, ppl=1.96, wps=600.9, ups=0.53, wpb=1137.3, bsz=32, num_updates=25560, lr=1.62152e-05, gnorm=5.681, clip=100, loss_scale=64, train_wall=19, gb_free=11.4, wall=48030
2023-05-26 12:43:55 - progress_bar.py[line:272] - INFO: epoch 015:   1366 / 1732 loss=2.207, loss_v1=0, loss_v2=0, nll_loss=0.986, ntokens=1081.4, nsentences=32, sample_size=1081.4, sample_size_v1=0, sample_size_v2=0, ppl=1.98, wps=573.6, ups=0.53, wpb=1081.4, bsz=32, num_updates=25570, lr=1.62091e-05, gnorm=6.125, clip=100, loss_scale=64, train_wall=19, gb_free=11.4, wall=48049
2023-05-26 12:44:13 - progress_bar.py[line:272] - INFO: epoch 015:   1376 / 1732 loss=2.25, loss_v1=0, loss_v2=0, nll_loss=1.034, ntokens=1111.5, nsentences=32, sample_size=1111.5, sample_size_v1=0, sample_size_v2=0, ppl=2.05, wps=591.1, ups=0.53, wpb=1111.5, bsz=32, num_updates=25580, lr=1.62029e-05, gnorm=6.215, clip=100, loss_scale=64, train_wall=19, gb_free=11.1, wall=48068
2023-05-26 12:44:32 - progress_bar.py[line:272] - INFO: epoch 015:   1386 / 1732 loss=2.213, loss_v1=0, loss_v2=0, nll_loss=0.996, ntokens=1153.3, nsentences=32, sample_size=1153.3, sample_size_v1=0, sample_size_v2=0, ppl=1.99, wps=613.2, ups=0.53, wpb=1153.3, bsz=32, num_updates=25590, lr=1.61968e-05, gnorm=5.897, clip=100, loss_scale=64, train_wall=19, gb_free=11.7, wall=48087
2023-05-26 12:44:51 - progress_bar.py[line:272] - INFO: epoch 015:   1396 / 1732 loss=2.207, loss_v1=0, loss_v2=0, nll_loss=0.988, ntokens=1044.6, nsentences=32, sample_size=1044.6, sample_size_v1=0, sample_size_v2=0, ppl=1.98, wps=555.2, ups=0.53, wpb=1044.6, bsz=32, num_updates=25600, lr=1.61907e-05, gnorm=6.321, clip=100, loss_scale=64, train_wall=19, gb_free=11.3, wall=48106
2023-05-26 12:45:10 - progress_bar.py[line:272] - INFO: epoch 015:   1406 / 1732 loss=2.223, loss_v1=0, loss_v2=0, nll_loss=1.004, ntokens=1163.8, nsentences=32, sample_size=1163.8, sample_size_v1=0, sample_size_v2=0, ppl=2.01, wps=616, ups=0.53, wpb=1163.8, bsz=32, num_updates=25610, lr=1.61845e-05, gnorm=6.014, clip=100, loss_scale=64, train_wall=19, gb_free=11.5, wall=48125
2023-05-26 12:45:29 - progress_bar.py[line:272] - INFO: epoch 015:   1416 / 1732 loss=2.24, loss_v1=0, loss_v2=0, nll_loss=1.024, ntokens=1281, nsentences=32, sample_size=1281, sample_size_v1=0, sample_size_v2=0, ppl=2.03, wps=673, ups=0.53, wpb=1281, bsz=32, num_updates=25620, lr=1.61784e-05, gnorm=5.672, clip=100, loss_scale=64, train_wall=19, gb_free=10.6, wall=48144
2023-05-26 12:45:48 - progress_bar.py[line:272] - INFO: epoch 015:   1426 / 1732 loss=2.2, loss_v1=0, loss_v2=0, nll_loss=0.98, ntokens=1225.6, nsentences=32, sample_size=1225.6, sample_size_v1=0, sample_size_v2=0, ppl=1.97, wps=640.5, ups=0.52, wpb=1225.6, bsz=32, num_updates=25630, lr=1.61722e-05, gnorm=5.665, clip=100, loss_scale=64, train_wall=19, gb_free=10.6, wall=48163
2023-05-26 12:46:07 - progress_bar.py[line:272] - INFO: epoch 015:   1436 / 1732 loss=2.212, loss_v1=0, loss_v2=0, nll_loss=0.994, ntokens=1219.4, nsentences=32, sample_size=1219.4, sample_size_v1=0, sample_size_v2=0, ppl=1.99, wps=646.6, ups=0.53, wpb=1219.4, bsz=32, num_updates=25640, lr=1.61661e-05, gnorm=5.542, clip=100, loss_scale=64, train_wall=19, gb_free=10.9, wall=48182
2023-05-26 12:46:26 - progress_bar.py[line:272] - INFO: epoch 015:   1446 / 1732 loss=2.227, loss_v1=0, loss_v2=0, nll_loss=1.011, ntokens=1113.8, nsentences=32, sample_size=1113.8, sample_size_v1=0, sample_size_v2=0, ppl=2.01, wps=590.6, ups=0.53, wpb=1113.8, bsz=32, num_updates=25650, lr=1.61599e-05, gnorm=5.749, clip=100, loss_scale=64, train_wall=19, gb_free=11.2, wall=48200
2023-05-26 12:46:45 - progress_bar.py[line:272] - INFO: epoch 015:   1456 / 1732 loss=2.23, loss_v1=0, loss_v2=0, nll_loss=1.013, ntokens=1106.5, nsentences=32, sample_size=1106.5, sample_size_v1=0, sample_size_v2=0, ppl=2.02, wps=585.8, ups=0.53, wpb=1106.5, bsz=32, num_updates=25660, lr=1.61538e-05, gnorm=6.112, clip=100, loss_scale=64, train_wall=19, gb_free=11.1, wall=48219
2023-05-26 12:47:04 - progress_bar.py[line:272] - INFO: epoch 015:   1466 / 1732 loss=2.177, loss_v1=0, loss_v2=0, nll_loss=0.954, ntokens=1200.2, nsentences=32, sample_size=1200.2, sample_size_v1=0, sample_size_v2=0, ppl=1.94, wps=630.6, ups=0.53, wpb=1200.2, bsz=32, num_updates=25670, lr=1.61477e-05, gnorm=5.881, clip=100, loss_scale=64, train_wall=19, gb_free=11.2, wall=48238
2023-05-26 12:47:22 - progress_bar.py[line:272] - INFO: epoch 015:   1476 / 1732 loss=2.225, loss_v1=0, loss_v2=0, nll_loss=1.007, ntokens=1071.6, nsentences=32, sample_size=1071.6, sample_size_v1=0, sample_size_v2=0, ppl=2.01, wps=569.9, ups=0.53, wpb=1071.6, bsz=32, num_updates=25680, lr=1.61415e-05, gnorm=6.72, clip=100, loss_scale=64, train_wall=19, gb_free=11.4, wall=48257
2023-05-26 12:47:41 - progress_bar.py[line:272] - INFO: epoch 015:   1486 / 1732 loss=2.228, loss_v1=0, loss_v2=0, nll_loss=1.01, ntokens=1132, nsentences=32, sample_size=1132, sample_size_v1=0, sample_size_v2=0, ppl=2.01, wps=600.3, ups=0.53, wpb=1132, bsz=32, num_updates=25690, lr=1.61354e-05, gnorm=6.219, clip=100, loss_scale=64, train_wall=19, gb_free=10.6, wall=48276
2023-05-26 12:48:00 - progress_bar.py[line:272] - INFO: epoch 015:   1496 / 1732 loss=2.201, loss_v1=0, loss_v2=0, nll_loss=0.98, ntokens=1113.1, nsentences=32, sample_size=1113.1, sample_size_v1=0, sample_size_v2=0, ppl=1.97, wps=588.6, ups=0.53, wpb=1113.1, bsz=32, num_updates=25700, lr=1.61292e-05, gnorm=5.985, clip=100, loss_scale=64, train_wall=19, gb_free=10.9, wall=48295
2023-05-26 12:48:19 - progress_bar.py[line:272] - INFO: epoch 015:   1506 / 1732 loss=2.168, loss_v1=0, loss_v2=0, nll_loss=0.945, ntokens=1117, nsentences=32, sample_size=1117, sample_size_v1=0, sample_size_v2=0, ppl=1.93, wps=594.1, ups=0.53, wpb=1117, bsz=32, num_updates=25710, lr=1.61231e-05, gnorm=6.367, clip=100, loss_scale=64, train_wall=19, gb_free=11.4, wall=48314
2023-05-26 12:48:38 - progress_bar.py[line:272] - INFO: epoch 015:   1516 / 1732 loss=2.224, loss_v1=0, loss_v2=0, nll_loss=1.008, ntokens=1043.6, nsentences=32, sample_size=1043.6, sample_size_v1=0, sample_size_v2=0, ppl=2.01, wps=556.6, ups=0.53, wpb=1043.6, bsz=32, num_updates=25720, lr=1.61169e-05, gnorm=6.404, clip=100, loss_scale=64, train_wall=19, gb_free=11.3, wall=48332
2023-05-26 12:48:57 - progress_bar.py[line:272] - INFO: epoch 015:   1526 / 1732 loss=2.256, loss_v1=0, loss_v2=0, nll_loss=1.042, ntokens=1063.1, nsentences=32, sample_size=1063.1, sample_size_v1=0, sample_size_v2=0, ppl=2.06, wps=564.8, ups=0.53, wpb=1063.1, bsz=32, num_updates=25730, lr=1.61108e-05, gnorm=6.584, clip=100, loss_scale=64, train_wall=19, gb_free=11.2, wall=48351
2023-05-26 12:49:16 - progress_bar.py[line:272] - INFO: epoch 015:   1536 / 1732 loss=2.219, loss_v1=0, loss_v2=0, nll_loss=1.001, ntokens=1073.8, nsentences=32, sample_size=1073.8, sample_size_v1=0, sample_size_v2=0, ppl=2, wps=567.1, ups=0.53, wpb=1073.8, bsz=32, num_updates=25740, lr=1.61047e-05, gnorm=6.3, clip=100, loss_scale=64, train_wall=19, gb_free=11.2, wall=48370
2023-05-26 12:49:34 - progress_bar.py[line:272] - INFO: epoch 015:   1546 / 1732 loss=2.183, loss_v1=0, loss_v2=0, nll_loss=0.959, ntokens=1068.6, nsentences=32, sample_size=1068.6, sample_size_v1=0, sample_size_v2=0, ppl=1.94, wps=568.1, ups=0.53, wpb=1068.6, bsz=32, num_updates=25750, lr=1.60985e-05, gnorm=6.51, clip=100, loss_scale=64, train_wall=19, gb_free=11.2, wall=48389
2023-05-26 12:49:53 - progress_bar.py[line:272] - INFO: epoch 015:   1556 / 1732 loss=2.193, loss_v1=0, loss_v2=0, nll_loss=0.973, ntokens=1070.8, nsentences=32, sample_size=1070.8, sample_size_v1=0, sample_size_v2=0, ppl=1.96, wps=571.5, ups=0.53, wpb=1070.8, bsz=32, num_updates=25760, lr=1.60924e-05, gnorm=5.984, clip=100, loss_scale=64, train_wall=19, gb_free=11.3, wall=48408
2023-05-26 12:50:12 - progress_bar.py[line:272] - INFO: epoch 015:   1566 / 1732 loss=2.226, loss_v1=0, loss_v2=0, nll_loss=1.01, ntokens=1097.4, nsentences=32, sample_size=1097.4, sample_size_v1=0, sample_size_v2=0, ppl=2.01, wps=584.5, ups=0.53, wpb=1097.4, bsz=32, num_updates=25770, lr=1.60862e-05, gnorm=5.78, clip=100, loss_scale=64, train_wall=19, gb_free=11.6, wall=48427
2023-05-26 12:50:31 - progress_bar.py[line:272] - INFO: epoch 015:   1576 / 1732 loss=2.233, loss_v1=0, loss_v2=0, nll_loss=1.017, ntokens=1019.9, nsentences=32, sample_size=1019.9, sample_size_v1=0, sample_size_v2=0, ppl=2.02, wps=541.1, ups=0.53, wpb=1019.9, bsz=32, num_updates=25780, lr=1.60801e-05, gnorm=6.705, clip=100, loss_scale=64, train_wall=19, gb_free=11.5, wall=48445
2023-05-26 12:50:50 - progress_bar.py[line:272] - INFO: epoch 015:   1586 / 1732 loss=2.222, loss_v1=0, loss_v2=0, nll_loss=1.005, ntokens=1060.6, nsentences=32, sample_size=1060.6, sample_size_v1=0, sample_size_v2=0, ppl=2.01, wps=559.6, ups=0.53, wpb=1060.6, bsz=32, num_updates=25790, lr=1.6074e-05, gnorm=6.277, clip=100, loss_scale=64, train_wall=19, gb_free=11.1, wall=48464
2023-05-26 12:51:09 - progress_bar.py[line:272] - INFO: epoch 015:   1596 / 1732 loss=2.179, loss_v1=0, loss_v2=0, nll_loss=0.955, ntokens=1073.8, nsentences=32, sample_size=1073.8, sample_size_v1=0, sample_size_v2=0, ppl=1.94, wps=570.3, ups=0.53, wpb=1073.8, bsz=32, num_updates=25800, lr=1.60678e-05, gnorm=6.03, clip=100, loss_scale=64, train_wall=19, gb_free=11.2, wall=48483
2023-05-26 12:51:27 - progress_bar.py[line:272] - INFO: epoch 015:   1606 / 1732 loss=2.205, loss_v1=0, loss_v2=0, nll_loss=0.986, ntokens=1124, nsentences=32, sample_size=1124, sample_size_v1=0, sample_size_v2=0, ppl=1.98, wps=595.5, ups=0.53, wpb=1124, bsz=32, num_updates=25810, lr=1.60617e-05, gnorm=6.238, clip=100, loss_scale=64, train_wall=19, gb_free=11, wall=48502
2023-05-26 12:51:46 - progress_bar.py[line:272] - INFO: epoch 015:   1616 / 1732 loss=2.175, loss_v1=0, loss_v2=0, nll_loss=0.952, ntokens=1154.1, nsentences=32, sample_size=1154.1, sample_size_v1=0, sample_size_v2=0, ppl=1.93, wps=607.6, ups=0.53, wpb=1154.1, bsz=32, num_updates=25820, lr=1.60555e-05, gnorm=5.941, clip=100, loss_scale=64, train_wall=19, gb_free=11.5, wall=48521
2023-05-26 12:52:05 - progress_bar.py[line:272] - INFO: epoch 015:   1626 / 1732 loss=2.211, loss_v1=0, loss_v2=0, nll_loss=0.991, ntokens=1109.2, nsentences=32, sample_size=1109.2, sample_size_v1=0, sample_size_v2=0, ppl=1.99, wps=584.3, ups=0.53, wpb=1109.2, bsz=32, num_updates=25830, lr=1.60494e-05, gnorm=6.515, clip=100, loss_scale=64, train_wall=19, gb_free=10.9, wall=48540
2023-05-26 12:52:24 - progress_bar.py[line:272] - INFO: epoch 015:   1636 / 1732 loss=2.179, loss_v1=0, loss_v2=0, nll_loss=0.956, ntokens=1146, nsentences=32, sample_size=1146, sample_size_v1=0, sample_size_v2=0, ppl=1.94, wps=609.9, ups=0.53, wpb=1146, bsz=32, num_updates=25840, lr=1.60432e-05, gnorm=5.779, clip=100, loss_scale=64, train_wall=19, gb_free=11.8, wall=48559
2023-05-26 12:52:43 - progress_bar.py[line:272] - INFO: epoch 015:   1646 / 1732 loss=2.18, loss_v1=0, loss_v2=0, nll_loss=0.957, ntokens=1290.2, nsentences=32, sample_size=1290.2, sample_size_v1=0, sample_size_v2=0, ppl=1.94, wps=673.9, ups=0.52, wpb=1290.2, bsz=32, num_updates=25850, lr=1.60371e-05, gnorm=5.663, clip=100, loss_scale=64, train_wall=19, gb_free=11, wall=48578
2023-05-26 12:53:02 - progress_bar.py[line:272] - INFO: epoch 015:   1656 / 1732 loss=2.228, loss_v1=0, loss_v2=0, nll_loss=1.012, ntokens=952.5, nsentences=32, sample_size=952.5, sample_size_v1=0, sample_size_v2=0, ppl=2.02, wps=510.9, ups=0.54, wpb=952.5, bsz=32, num_updates=25860, lr=1.6031e-05, gnorm=7.352, clip=100, loss_scale=64, train_wall=19, gb_free=11.3, wall=48597
2023-05-26 12:53:21 - progress_bar.py[line:272] - INFO: epoch 015:   1666 / 1732 loss=2.224, loss_v1=0, loss_v2=0, nll_loss=1.007, ntokens=1015, nsentences=32, sample_size=1015, sample_size_v1=0, sample_size_v2=0, ppl=2.01, wps=537.5, ups=0.53, wpb=1015, bsz=32, num_updates=25870, lr=1.60248e-05, gnorm=6.613, clip=100, loss_scale=64, train_wall=19, gb_free=11.4, wall=48616
2023-05-26 12:53:40 - progress_bar.py[line:272] - INFO: epoch 015:   1676 / 1732 loss=2.178, loss_v1=0, loss_v2=0, nll_loss=0.955, ntokens=1119.1, nsentences=32, sample_size=1119.1, sample_size_v1=0, sample_size_v2=0, ppl=1.94, wps=594.7, ups=0.53, wpb=1119.1, bsz=32, num_updates=25880, lr=1.60187e-05, gnorm=6.531, clip=100, loss_scale=64, train_wall=19, gb_free=11.1, wall=48634
2023-05-26 12:53:59 - progress_bar.py[line:272] - INFO: epoch 015:   1686 / 1732 loss=2.166, loss_v1=0, loss_v2=0, nll_loss=0.94, ntokens=1151.6, nsentences=32, sample_size=1151.6, sample_size_v1=0, sample_size_v2=0, ppl=1.92, wps=608, ups=0.53, wpb=1151.6, bsz=32, num_updates=25890, lr=1.60125e-05, gnorm=5.808, clip=100, loss_scale=64, train_wall=19, gb_free=10.7, wall=48653
2023-05-26 12:54:18 - progress_bar.py[line:272] - INFO: epoch 015:   1696 / 1732 loss=2.204, loss_v1=0, loss_v2=0, nll_loss=0.984, ntokens=1284.6, nsentences=32, sample_size=1284.6, sample_size_v1=0, sample_size_v2=0, ppl=1.98, wps=665.7, ups=0.52, wpb=1284.6, bsz=32, num_updates=25900, lr=1.60064e-05, gnorm=5.787, clip=100, loss_scale=64, train_wall=19, gb_free=10.6, wall=48673
2023-05-26 12:54:37 - progress_bar.py[line:272] - INFO: epoch 015:   1706 / 1732 loss=2.208, loss_v1=0, loss_v2=0, nll_loss=0.989, ntokens=1193.5, nsentences=32, sample_size=1193.5, sample_size_v1=0, sample_size_v2=0, ppl=1.98, wps=626.4, ups=0.52, wpb=1193.5, bsz=32, num_updates=25910, lr=1.60002e-05, gnorm=5.884, clip=100, loss_scale=64, train_wall=19, gb_free=10.8, wall=48692
2023-05-26 12:54:56 - progress_bar.py[line:272] - INFO: epoch 015:   1716 / 1732 loss=2.19, loss_v1=0, loss_v2=0, nll_loss=0.968, ntokens=1213.9, nsentences=32, sample_size=1213.9, sample_size_v1=0, sample_size_v2=0, ppl=1.96, wps=636.7, ups=0.52, wpb=1213.9, bsz=32, num_updates=25920, lr=1.59941e-05, gnorm=5.488, clip=100, loss_scale=64, train_wall=19, gb_free=10.5, wall=48711
2023-05-26 12:55:15 - progress_bar.py[line:272] - INFO: epoch 015:   1726 / 1732 loss=2.209, loss_v1=0, loss_v2=0, nll_loss=0.99, ntokens=1112.1, nsentences=32, sample_size=1112.1, sample_size_v1=0, sample_size_v2=0, ppl=1.99, wps=588.6, ups=0.53, wpb=1112.1, bsz=32, num_updates=25930, lr=1.5988e-05, gnorm=6.261, clip=100, loss_scale=64, train_wall=19, gb_free=11.1, wall=48730
2023-05-26 12:55:25 - train.py[line:332] - INFO: end of epoch 15 (average epoch stats below)
2023-05-26 12:55:25 - progress_bar.py[line:282] - INFO: epoch 015 | loss 2.218 | loss_v1 0 | loss_v2 0 | nll_loss 0.999 | ntokens 1051.41 | nsentences 31.986 | sample_size 1051.41 | sample_size_v1 0 | sample_size_v2 0 | ppl 2 | wps 559.5 | ups 0.53 | wpb 1051.4 | bsz 32 | num_updates 25936 | lr 1.59843e-05 | gnorm 5.862 | clip 100 | loss_scale 64 | train_wall 3241 | gb_free 11.7 | wall 48740
2023-05-26 12:55:25 - trainer.py[line:639] - INFO: loading train data for epoch 16
local datafile ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 0 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 0 finished initializing row_count and line_idx-to-offset mapping
file ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 0 row count 55400 total row count 55400
slice_id 0 seek offset 0
2023-05-26 12:55:27 - trainer.py[line:703] - INFO: begin training epoch 16
2023-05-26 12:55:27 - train.py[line:305] - INFO: Start iterating over samples
2023-05-26 12:55:35 - progress_bar.py[line:272] - INFO: epoch 016:      4 / 1732 loss=2.215, loss_v1=0, loss_v2=0, nll_loss=0.994, ntokens=1098.7, nsentences=29.6, sample_size=1098.7, sample_size_v1=0, sample_size_v2=0, ppl=1.99, wps=551.6, ups=0.5, wpb=1098.7, bsz=29.6, num_updates=25940, lr=1.59818e-05, gnorm=6.177, clip=100, loss_scale=64, train_wall=18, gb_free=10.8, wall=48750
2023-05-26 12:55:54 - progress_bar.py[line:272] - INFO: epoch 016:     14 / 1732 loss=2.173, loss_v1=0, loss_v2=0, nll_loss=0.949, ntokens=1064.2, nsentences=32, sample_size=1064.2, sample_size_v1=0, sample_size_v2=0, ppl=1.93, wps=564.8, ups=0.53, wpb=1064.2, bsz=32, num_updates=25950, lr=1.59757e-05, gnorm=7.09, clip=100, loss_scale=64, train_wall=19, gb_free=11.1, wall=48768
2023-05-26 12:56:13 - progress_bar.py[line:272] - INFO: epoch 016:     24 / 1732 loss=2.131, loss_v1=0, loss_v2=0, nll_loss=0.903, ntokens=1038.3, nsentences=32, sample_size=1038.3, sample_size_v1=0, sample_size_v2=0, ppl=1.87, wps=549.8, ups=0.53, wpb=1038.3, bsz=32, num_updates=25960, lr=1.59695e-05, gnorm=6.745, clip=100, loss_scale=64, train_wall=19, gb_free=11.3, wall=48787
2023-05-26 12:56:32 - progress_bar.py[line:272] - INFO: epoch 016:     34 / 1732 loss=2.076, loss_v1=0, loss_v2=0, nll_loss=0.841, ntokens=1072.7, nsentences=32, sample_size=1072.7, sample_size_v1=0, sample_size_v2=0, ppl=1.79, wps=565.9, ups=0.53, wpb=1072.7, bsz=32, num_updates=25970, lr=1.59634e-05, gnorm=5.624, clip=100, loss_scale=64, train_wall=19, gb_free=11.1, wall=48806
2023-05-26 12:56:50 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2023-05-26 12:56:52 - progress_bar.py[line:272] - INFO: epoch 016:     45 / 1732 loss=2.044, loss_v1=0, loss_v2=0, nll_loss=0.807, ntokens=1117.7, nsentences=32, sample_size=1117.7, sample_size_v1=0, sample_size_v2=0, ppl=1.75, wps=538, ups=0.48, wpb=1117.7, bsz=32, num_updates=25980, lr=1.59573e-05, gnorm=5.73, clip=100, loss_scale=64, train_wall=21, gb_free=10.6, wall=48827
2023-05-26 12:57:11 - progress_bar.py[line:272] - INFO: epoch 016:     55 / 1732 loss=2.016, loss_v1=0, loss_v2=0, nll_loss=0.776, ntokens=1058.4, nsentences=32, sample_size=1058.4, sample_size_v1=0, sample_size_v2=0, ppl=1.71, wps=560.9, ups=0.53, wpb=1058.4, bsz=32, num_updates=25990, lr=1.59511e-05, gnorm=5.298, clip=100, loss_scale=64, train_wall=19, gb_free=10.9, wall=48846
2023-05-26 12:57:30 - progress_bar.py[line:272] - INFO: epoch 016:     65 / 1732 loss=1.919, loss_v1=0, loss_v2=0, nll_loss=0.666, ntokens=1260.1, nsentences=32, sample_size=1260.1, sample_size_v1=0, sample_size_v2=0, ppl=1.59, wps=659.9, ups=0.52, wpb=1260.1, bsz=32, num_updates=26000, lr=1.5945e-05, gnorm=4.84, clip=100, loss_scale=64, train_wall=19, gb_free=10.5, wall=48865
2023-05-26 12:57:50 - progress_bar.py[line:272] - INFO: epoch 016:     75 / 1732 loss=2.003, loss_v1=0, loss_v2=0, nll_loss=0.76, ntokens=1372.4, nsentences=32, sample_size=1372.4, sample_size_v1=0, sample_size_v2=0, ppl=1.69, wps=703, ups=0.51, wpb=1372.4, bsz=32, num_updates=26010, lr=1.59388e-05, gnorm=4.387, clip=100, loss_scale=64, train_wall=19, gb_free=10.5, wall=48885
2023-05-26 12:58:09 - progress_bar.py[line:272] - INFO: epoch 016:     85 / 1732 loss=2.061, loss_v1=0, loss_v2=0, nll_loss=0.825, ntokens=1112.6, nsentences=32, sample_size=1112.6, sample_size_v1=0, sample_size_v2=0, ppl=1.77, wps=581.1, ups=0.52, wpb=1112.6, bsz=32, num_updates=26020, lr=1.59327e-05, gnorm=5.857, clip=100, loss_scale=64, train_wall=19, gb_free=11.4, wall=48904
2023-05-26 12:58:28 - progress_bar.py[line:272] - INFO: epoch 016:     95 / 1732 loss=2.033, loss_v1=0, loss_v2=0, nll_loss=0.792, ntokens=1092.3, nsentences=32, sample_size=1092.3, sample_size_v1=0, sample_size_v2=0, ppl=1.73, wps=577.4, ups=0.53, wpb=1092.3, bsz=32, num_updates=26030, lr=1.59265e-05, gnorm=5.933, clip=100, loss_scale=64, train_wall=19, gb_free=11.6, wall=48923
2023-05-26 12:58:47 - progress_bar.py[line:272] - INFO: epoch 016:    105 / 1732 loss=2.153, loss_v1=0, loss_v2=0, nll_loss=0.93, ntokens=995.3, nsentences=32, sample_size=995.3, sample_size_v1=0, sample_size_v2=0, ppl=1.91, wps=529.5, ups=0.53, wpb=995.3, bsz=32, num_updates=26040, lr=1.59204e-05, gnorm=6.416, clip=100, loss_scale=64, train_wall=19, gb_free=11.1, wall=48941
2023-05-26 12:59:06 - progress_bar.py[line:272] - INFO: epoch 016:    115 / 1732 loss=2.242, loss_v1=0, loss_v2=0, nll_loss=1.028, ntokens=1032.5, nsentences=32, sample_size=1032.5, sample_size_v1=0, sample_size_v2=0, ppl=2.04, wps=543.5, ups=0.53, wpb=1032.5, bsz=32, num_updates=26050, lr=1.59143e-05, gnorm=6.558, clip=100, loss_scale=64, train_wall=19, gb_free=11.1, wall=48960
2023-05-26 12:59:25 - progress_bar.py[line:272] - INFO: epoch 016:    125 / 1732 loss=2.194, loss_v1=0, loss_v2=0, nll_loss=0.972, ntokens=1181.7, nsentences=32, sample_size=1181.7, sample_size_v1=0, sample_size_v2=0, ppl=1.96, wps=613.7, ups=0.52, wpb=1181.7, bsz=32, num_updates=26060, lr=1.59081e-05, gnorm=6.314, clip=100, loss_scale=64, train_wall=19, gb_free=10.4, wall=48980
2023-05-26 12:59:44 - progress_bar.py[line:272] - INFO: epoch 016:    135 / 1732 loss=2.17, loss_v1=0, loss_v2=0, nll_loss=0.944, ntokens=1179.6, nsentences=32, sample_size=1179.6, sample_size_v1=0, sample_size_v2=0, ppl=1.92, wps=619.3, ups=0.53, wpb=1179.6, bsz=32, num_updates=26070, lr=1.5902e-05, gnorm=6.368, clip=100, loss_scale=64, train_wall=19, gb_free=11.4, wall=48999
2023-05-26 13:00:03 - progress_bar.py[line:272] - INFO: epoch 016:    145 / 1732 loss=2.129, loss_v1=0, loss_v2=0, nll_loss=0.898, ntokens=1246.8, nsentences=32, sample_size=1246.8, sample_size_v1=0, sample_size_v2=0, ppl=1.86, wps=644.8, ups=0.52, wpb=1246.8, bsz=32, num_updates=26080, lr=1.58958e-05, gnorm=5.488, clip=100, loss_scale=64, train_wall=19, gb_free=11, wall=49018
2023-05-26 13:00:23 - progress_bar.py[line:272] - INFO: epoch 016:    155 / 1732 loss=2.153, loss_v1=0, loss_v2=0, nll_loss=0.93, ntokens=1151.6, nsentences=32, sample_size=1151.6, sample_size_v1=0, sample_size_v2=0, ppl=1.9, wps=598.7, ups=0.52, wpb=1151.6, bsz=32, num_updates=26090, lr=1.58897e-05, gnorm=5.857, clip=100, loss_scale=64, train_wall=19, gb_free=10.8, wall=49037
2023-05-26 13:00:42 - progress_bar.py[line:272] - INFO: epoch 016:    165 / 1732 loss=2.131, loss_v1=0, loss_v2=0, nll_loss=0.904, ntokens=1062.3, nsentences=32, sample_size=1062.3, sample_size_v1=0, sample_size_v2=0, ppl=1.87, wps=562.5, ups=0.53, wpb=1062.3, bsz=32, num_updates=26100, lr=1.58835e-05, gnorm=6.909, clip=100, loss_scale=64, train_wall=19, gb_free=11.3, wall=49056
2023-05-26 13:01:01 - progress_bar.py[line:272] - INFO: epoch 016:    175 / 1732 loss=2.161, loss_v1=0, loss_v2=0, nll_loss=0.936, ntokens=958.4, nsentences=32, sample_size=958.4, sample_size_v1=0, sample_size_v2=0, ppl=1.91, wps=503.4, ups=0.53, wpb=958.4, bsz=32, num_updates=26110, lr=1.58774e-05, gnorm=6.803, clip=100, loss_scale=64, train_wall=19, gb_free=10.7, wall=49075
2023-05-26 13:01:20 - progress_bar.py[line:272] - INFO: epoch 016:    185 / 1732 loss=2.11, loss_v1=0, loss_v2=0, nll_loss=0.879, ntokens=1173.4, nsentences=32, sample_size=1173.4, sample_size_v1=0, sample_size_v2=0, ppl=1.84, wps=613.4, ups=0.52, wpb=1173.4, bsz=32, num_updates=26120, lr=1.58713e-05, gnorm=5.794, clip=100, loss_scale=64, train_wall=19, gb_free=9.8, wall=49094
2023-05-26 13:01:39 - progress_bar.py[line:272] - INFO: epoch 016:    195 / 1732 loss=2.152, loss_v1=0, loss_v2=0, nll_loss=0.926, ntokens=1144.6, nsentences=32, sample_size=1144.6, sample_size_v1=0, sample_size_v2=0, ppl=1.9, wps=601.3, ups=0.53, wpb=1144.6, bsz=32, num_updates=26130, lr=1.58651e-05, gnorm=5.985, clip=100, loss_scale=64, train_wall=19, gb_free=10.6, wall=49113
2023-05-26 13:01:57 - progress_bar.py[line:272] - INFO: epoch 016:    205 / 1732 loss=2.204, loss_v1=0, loss_v2=0, nll_loss=0.986, ntokens=1021.8, nsentences=32, sample_size=1021.8, sample_size_v1=0, sample_size_v2=0, ppl=1.98, wps=547, ups=0.54, wpb=1021.8, bsz=32, num_updates=26140, lr=1.5859e-05, gnorm=6.865, clip=100, loss_scale=64, train_wall=19, gb_free=11.7, wall=49132
2023-05-26 13:02:16 - progress_bar.py[line:272] - INFO: epoch 016:    215 / 1732 loss=2.233, loss_v1=0, loss_v2=0, nll_loss=1.015, ntokens=1094.3, nsentences=32, sample_size=1094.3, sample_size_v1=0, sample_size_v2=0, ppl=2.02, wps=584.7, ups=0.53, wpb=1094.3, bsz=32, num_updates=26150, lr=1.58528e-05, gnorm=5.794, clip=100, loss_scale=64, train_wall=19, gb_free=11.5, wall=49151
2023-05-26 13:02:35 - progress_bar.py[line:272] - INFO: epoch 016:    225 / 1732 loss=2.213, loss_v1=0, loss_v2=0, nll_loss=0.993, ntokens=1095.2, nsentences=32, sample_size=1095.2, sample_size_v1=0, sample_size_v2=0, ppl=1.99, wps=585.6, ups=0.53, wpb=1095.2, bsz=32, num_updates=26160, lr=1.58467e-05, gnorm=6.134, clip=100, loss_scale=64, train_wall=19, gb_free=10.9, wall=49170
2023-05-26 13:02:54 - progress_bar.py[line:272] - INFO: epoch 016:    235 / 1732 loss=2.268, loss_v1=0, loss_v2=0, nll_loss=1.055, ntokens=1090, nsentences=32, sample_size=1090, sample_size_v1=0, sample_size_v2=0, ppl=2.08, wps=583.4, ups=0.54, wpb=1090, bsz=32, num_updates=26170, lr=1.58406e-05, gnorm=6.2, clip=100, loss_scale=64, train_wall=19, gb_free=11.2, wall=49188
2023-05-26 13:03:12 - progress_bar.py[line:272] - INFO: epoch 016:    245 / 1732 loss=2.236, loss_v1=0, loss_v2=0, nll_loss=1.019, ntokens=1178.2, nsentences=32, sample_size=1178.2, sample_size_v1=0, sample_size_v2=0, ppl=2.03, wps=625.1, ups=0.53, wpb=1178.2, bsz=32, num_updates=26180, lr=1.58344e-05, gnorm=6.067, clip=100, loss_scale=64, train_wall=19, gb_free=10.8, wall=49207
2023-05-26 13:03:31 - progress_bar.py[line:272] - INFO: epoch 016:    255 / 1732 loss=2.237, loss_v1=0, loss_v2=0, nll_loss=1.023, ntokens=1128.2, nsentences=32, sample_size=1128.2, sample_size_v1=0, sample_size_v2=0, ppl=2.03, wps=602.5, ups=0.53, wpb=1128.2, bsz=32, num_updates=26190, lr=1.58283e-05, gnorm=6.423, clip=100, loss_scale=64, train_wall=19, gb_free=11.8, wall=49226
2023-05-26 13:03:50 - progress_bar.py[line:272] - INFO: epoch 016:    265 / 1732 loss=2.228, loss_v1=0, loss_v2=0, nll_loss=1.011, ntokens=1148, nsentences=32, sample_size=1148, sample_size_v1=0, sample_size_v2=0, ppl=2.02, wps=612.7, ups=0.53, wpb=1148, bsz=32, num_updates=26200, lr=1.58221e-05, gnorm=5.994, clip=100, loss_scale=64, train_wall=19, gb_free=11.3, wall=49245
2023-05-26 13:04:09 - progress_bar.py[line:272] - INFO: epoch 016:    275 / 1732 loss=2.233, loss_v1=0, loss_v2=0, nll_loss=1.015, ntokens=1140.3, nsentences=32, sample_size=1140.3, sample_size_v1=0, sample_size_v2=0, ppl=2.02, wps=604.5, ups=0.53, wpb=1140.3, bsz=32, num_updates=26210, lr=1.5816e-05, gnorm=6.044, clip=100, loss_scale=64, train_wall=19, gb_free=11.4, wall=49263
2023-05-26 13:04:28 - progress_bar.py[line:272] - INFO: epoch 016:    285 / 1732 loss=2.243, loss_v1=0, loss_v2=0, nll_loss=1.026, ntokens=1154.4, nsentences=32, sample_size=1154.4, sample_size_v1=0, sample_size_v2=0, ppl=2.04, wps=611.9, ups=0.53, wpb=1154.4, bsz=32, num_updates=26220, lr=1.58098e-05, gnorm=6.155, clip=100, loss_scale=64, train_wall=19, gb_free=10.3, wall=49282
2023-05-26 13:04:46 - progress_bar.py[line:272] - INFO: epoch 016:    295 / 1732 loss=2.221, loss_v1=0, loss_v2=0, nll_loss=1.005, ntokens=1115.8, nsentences=32, sample_size=1115.8, sample_size_v1=0, sample_size_v2=0, ppl=2.01, wps=594.6, ups=0.53, wpb=1115.8, bsz=32, num_updates=26230, lr=1.58037e-05, gnorm=6.107, clip=100, loss_scale=64, train_wall=19, gb_free=11.4, wall=49301
2023-05-26 13:05:05 - progress_bar.py[line:272] - INFO: epoch 016:    305 / 1732 loss=2.219, loss_v1=0, loss_v2=0, nll_loss=1.002, ntokens=1102.2, nsentences=32, sample_size=1102.2, sample_size_v1=0, sample_size_v2=0, ppl=2, wps=588.1, ups=0.53, wpb=1102.2, bsz=32, num_updates=26240, lr=1.57976e-05, gnorm=6.337, clip=100, loss_scale=64, train_wall=19, gb_free=11, wall=49320
2023-05-26 13:05:24 - progress_bar.py[line:272] - INFO: epoch 016:    315 / 1732 loss=2.237, loss_v1=0, loss_v2=0, nll_loss=1.02, ntokens=1020.3, nsentences=32, sample_size=1020.3, sample_size_v1=0, sample_size_v2=0, ppl=2.03, wps=548.9, ups=0.54, wpb=1020.3, bsz=32, num_updates=26250, lr=1.57914e-05, gnorm=6.514, clip=100, loss_scale=64, train_wall=19, gb_free=11.5, wall=49338
2023-05-26 13:05:42 - progress_bar.py[line:272] - INFO: epoch 016:    325 / 1732 loss=2.248, loss_v1=0, loss_v2=0, nll_loss=1.032, ntokens=1011.9, nsentences=32, sample_size=1011.9, sample_size_v1=0, sample_size_v2=0, ppl=2.05, wps=543, ups=0.54, wpb=1011.9, bsz=32, num_updates=26260, lr=1.57853e-05, gnorm=7.457, clip=100, loss_scale=64, train_wall=19, gb_free=11.7, wall=49357
2023-05-26 13:06:01 - progress_bar.py[line:272] - INFO: epoch 016:    335 / 1732 loss=2.262, loss_v1=0, loss_v2=0, nll_loss=1.049, ntokens=1020.9, nsentences=32, sample_size=1020.9, sample_size_v1=0, sample_size_v2=0, ppl=2.07, wps=550.1, ups=0.54, wpb=1020.9, bsz=32, num_updates=26270, lr=1.57791e-05, gnorm=6.864, clip=100, loss_scale=64, train_wall=19, gb_free=11.8, wall=49376
2023-05-26 13:06:19 - progress_bar.py[line:272] - INFO: epoch 016:    345 / 1732 loss=2.196, loss_v1=0, loss_v2=0, nll_loss=0.976, ntokens=903.9, nsentences=32, sample_size=903.9, sample_size_v1=0, sample_size_v2=0, ppl=1.97, wps=488.7, ups=0.54, wpb=903.9, bsz=32, num_updates=26280, lr=1.5773e-05, gnorm=6.956, clip=100, loss_scale=64, train_wall=18, gb_free=11.6, wall=49394
2023-05-26 13:06:38 - progress_bar.py[line:272] - INFO: epoch 016:    355 / 1732 loss=2.237, loss_v1=0, loss_v2=0, nll_loss=1.023, ntokens=961.9, nsentences=32, sample_size=961.9, sample_size_v1=0, sample_size_v2=0, ppl=2.03, wps=518.8, ups=0.54, wpb=961.9, bsz=32, num_updates=26290, lr=1.57668e-05, gnorm=7.221, clip=100, loss_scale=64, train_wall=19, gb_free=11.8, wall=49413
2023-05-26 13:06:56 - progress_bar.py[line:272] - INFO: epoch 016:    365 / 1732 loss=2.272, loss_v1=0, loss_v2=0, nll_loss=1.06, ntokens=955.9, nsentences=32, sample_size=955.9, sample_size_v1=0, sample_size_v2=0, ppl=2.09, wps=516, ups=0.54, wpb=955.9, bsz=32, num_updates=26300, lr=1.57607e-05, gnorm=7.212, clip=100, loss_scale=64, train_wall=18, gb_free=11, wall=49431
2023-05-26 13:07:15 - progress_bar.py[line:272] - INFO: epoch 016:    375 / 1732 loss=2.257, loss_v1=0, loss_v2=0, nll_loss=1.042, ntokens=987.5, nsentences=32, sample_size=987.5, sample_size_v1=0, sample_size_v2=0, ppl=2.06, wps=534.7, ups=0.54, wpb=987.5, bsz=32, num_updates=26310, lr=1.57546e-05, gnorm=7.433, clip=100, loss_scale=64, train_wall=18, gb_free=11.6, wall=49450
2023-05-26 13:07:34 - progress_bar.py[line:272] - INFO: epoch 016:    385 / 1732 loss=2.257, loss_v1=0, loss_v2=0, nll_loss=1.043, ntokens=1084.2, nsentences=32, sample_size=1084.2, sample_size_v1=0, sample_size_v2=0, ppl=2.06, wps=582.2, ups=0.54, wpb=1084.2, bsz=32, num_updates=26320, lr=1.57484e-05, gnorm=6.597, clip=100, loss_scale=64, train_wall=19, gb_free=11.6, wall=49468
2023-05-26 13:07:52 - progress_bar.py[line:272] - INFO: epoch 016:    395 / 1732 loss=2.254, loss_v1=0, loss_v2=0, nll_loss=1.04, ntokens=924.7, nsentences=32, sample_size=924.7, sample_size_v1=0, sample_size_v2=0, ppl=2.06, wps=501.4, ups=0.54, wpb=924.7, bsz=32, num_updates=26330, lr=1.57423e-05, gnorm=7.257, clip=100, loss_scale=64, train_wall=18, gb_free=11.6, wall=49487
2023-05-26 13:08:11 - progress_bar.py[line:272] - INFO: epoch 016:    405 / 1732 loss=2.213, loss_v1=0, loss_v2=0, nll_loss=0.993, ntokens=1086.5, nsentences=32, sample_size=1086.5, sample_size_v1=0, sample_size_v2=0, ppl=1.99, wps=581.7, ups=0.54, wpb=1086.5, bsz=32, num_updates=26340, lr=1.57361e-05, gnorm=6.574, clip=100, loss_scale=64, train_wall=19, gb_free=11.8, wall=49505
2023-05-26 13:08:29 - progress_bar.py[line:272] - INFO: epoch 016:    415 / 1732 loss=2.219, loss_v1=0, loss_v2=0, nll_loss=1.001, ntokens=1059.1, nsentences=32, sample_size=1059.1, sample_size_v1=0, sample_size_v2=0, ppl=2, wps=568.4, ups=0.54, wpb=1059.1, bsz=32, num_updates=26350, lr=1.573e-05, gnorm=6.564, clip=100, loss_scale=64, train_wall=19, gb_free=11.9, wall=49524
2023-05-26 13:08:48 - progress_bar.py[line:272] - INFO: epoch 016:    425 / 1732 loss=2.189, loss_v1=0, loss_v2=0, nll_loss=0.968, ntokens=994.5, nsentences=32, sample_size=994.5, sample_size_v1=0, sample_size_v2=0, ppl=1.96, wps=534.5, ups=0.54, wpb=994.5, bsz=32, num_updates=26360, lr=1.57238e-05, gnorm=6.908, clip=100, loss_scale=64, train_wall=19, gb_free=11.6, wall=49543
2023-05-26 13:09:07 - progress_bar.py[line:272] - INFO: epoch 016:    435 / 1732 loss=2.238, loss_v1=0, loss_v2=0, nll_loss=1.021, ntokens=1024.5, nsentences=32, sample_size=1024.5, sample_size_v1=0, sample_size_v2=0, ppl=2.03, wps=552.2, ups=0.54, wpb=1024.5, bsz=32, num_updates=26370, lr=1.57177e-05, gnorm=6.361, clip=100, loss_scale=64, train_wall=19, gb_free=11.8, wall=49561
2023-05-26 13:09:25 - progress_bar.py[line:272] - INFO: epoch 016:    445 / 1732 loss=2.242, loss_v1=0, loss_v2=0, nll_loss=1.026, ntokens=956.5, nsentences=32, sample_size=956.5, sample_size_v1=0, sample_size_v2=0, ppl=2.04, wps=516.3, ups=0.54, wpb=956.5, bsz=32, num_updates=26380, lr=1.57116e-05, gnorm=6.713, clip=100, loss_scale=64, train_wall=18, gb_free=11, wall=49580
2023-05-26 13:09:44 - progress_bar.py[line:272] - INFO: epoch 016:    455 / 1732 loss=2.239, loss_v1=0, loss_v2=0, nll_loss=1.023, ntokens=932.1, nsentences=32, sample_size=932.1, sample_size_v1=0, sample_size_v2=0, ppl=2.03, wps=504.4, ups=0.54, wpb=932.1, bsz=32, num_updates=26390, lr=1.57054e-05, gnorm=6.509, clip=100, loss_scale=64, train_wall=18, gb_free=11.5, wall=49598
2023-05-26 13:10:02 - progress_bar.py[line:272] - INFO: epoch 016:    465 / 1732 loss=2.269, loss_v1=0, loss_v2=0, nll_loss=1.057, ntokens=1058.7, nsentences=32, sample_size=1058.7, sample_size_v1=0, sample_size_v2=0, ppl=2.08, wps=566.7, ups=0.54, wpb=1058.7, bsz=32, num_updates=26400, lr=1.56993e-05, gnorm=6.56, clip=100, loss_scale=64, train_wall=19, gb_free=11.1, wall=49617
2023-05-26 13:10:21 - progress_bar.py[line:272] - INFO: epoch 016:    475 / 1732 loss=2.265, loss_v1=0, loss_v2=0, nll_loss=1.051, ntokens=1061.8, nsentences=32, sample_size=1061.8, sample_size_v1=0, sample_size_v2=0, ppl=2.07, wps=566.4, ups=0.53, wpb=1061.8, bsz=32, num_updates=26410, lr=1.56931e-05, gnorm=7.12, clip=100, loss_scale=64, train_wall=19, gb_free=11.4, wall=49636
2023-05-26 13:10:39 - progress_bar.py[line:272] - INFO: epoch 016:    485 / 1732 loss=2.232, loss_v1=0, loss_v2=0, nll_loss=1.014, ntokens=980.2, nsentences=32, sample_size=980.2, sample_size_v1=0, sample_size_v2=0, ppl=2.02, wps=530.6, ups=0.54, wpb=980.2, bsz=32, num_updates=26420, lr=1.5687e-05, gnorm=7.097, clip=100, loss_scale=64, train_wall=18, gb_free=11.2, wall=49654
2023-05-26 13:10:58 - progress_bar.py[line:272] - INFO: epoch 016:    495 / 1732 loss=2.226, loss_v1=0, loss_v2=0, nll_loss=1.009, ntokens=928.7, nsentences=32, sample_size=928.7, sample_size_v1=0, sample_size_v2=0, ppl=2.01, wps=500.4, ups=0.54, wpb=928.7, bsz=32, num_updates=26430, lr=1.56809e-05, gnorm=7.105, clip=100, loss_scale=64, train_wall=19, gb_free=12, wall=49673
2023-05-26 13:11:16 - progress_bar.py[line:272] - INFO: epoch 016:    505 / 1732 loss=2.25, loss_v1=0, loss_v2=0, nll_loss=1.037, ntokens=974.8, nsentences=32, sample_size=974.8, sample_size_v1=0, sample_size_v2=0, ppl=2.05, wps=529.2, ups=0.54, wpb=974.8, bsz=32, num_updates=26440, lr=1.56747e-05, gnorm=7.649, clip=100, loss_scale=64, train_wall=18, gb_free=11.5, wall=49691
2023-05-26 13:11:35 - progress_bar.py[line:272] - INFO: epoch 016:    515 / 1732 loss=2.24, loss_v1=0, loss_v2=0, nll_loss=1.025, ntokens=1073.1, nsentences=32, sample_size=1073.1, sample_size_v1=0, sample_size_v2=0, ppl=2.03, wps=577.2, ups=0.54, wpb=1073.1, bsz=32, num_updates=26450, lr=1.56686e-05, gnorm=5.923, clip=100, loss_scale=64, train_wall=19, gb_free=11.2, wall=49710
2023-05-26 13:11:53 - progress_bar.py[line:272] - INFO: epoch 016:    525 / 1732 loss=2.232, loss_v1=0, loss_v2=0, nll_loss=1.014, ntokens=955.6, nsentences=32, sample_size=955.6, sample_size_v1=0, sample_size_v2=0, ppl=2.02, wps=518.4, ups=0.54, wpb=955.6, bsz=32, num_updates=26460, lr=1.56624e-05, gnorm=7.239, clip=100, loss_scale=64, train_wall=18, gb_free=11.7, wall=49728
2023-05-26 13:12:12 - progress_bar.py[line:272] - INFO: epoch 016:    535 / 1732 loss=2.233, loss_v1=0, loss_v2=0, nll_loss=1.016, ntokens=948.7, nsentences=32, sample_size=948.7, sample_size_v1=0, sample_size_v2=0, ppl=2.02, wps=514.2, ups=0.54, wpb=948.7, bsz=32, num_updates=26470, lr=1.56563e-05, gnorm=7.318, clip=100, loss_scale=64, train_wall=18, gb_free=11.3, wall=49747
2023-05-26 13:12:30 - progress_bar.py[line:272] - INFO: epoch 016:    545 / 1732 loss=2.241, loss_v1=0, loss_v2=0, nll_loss=1.026, ntokens=1010, nsentences=32, sample_size=1010, sample_size_v1=0, sample_size_v2=0, ppl=2.04, wps=544.3, ups=0.54, wpb=1010, bsz=32, num_updates=26480, lr=1.56501e-05, gnorm=6.834, clip=100, loss_scale=64, train_wall=19, gb_free=11.1, wall=49765
2023-05-26 13:12:49 - progress_bar.py[line:272] - INFO: epoch 016:    555 / 1732 loss=2.274, loss_v1=0, loss_v2=0, nll_loss=1.062, ntokens=1039.8, nsentences=32, sample_size=1039.8, sample_size_v1=0, sample_size_v2=0, ppl=2.09, wps=561.5, ups=0.54, wpb=1039.8, bsz=32, num_updates=26490, lr=1.5644e-05, gnorm=6.53, clip=100, loss_scale=64, train_wall=18, gb_free=11.3, wall=49784
2023-05-26 13:13:08 - progress_bar.py[line:272] - INFO: epoch 016:    565 / 1732 loss=2.254, loss_v1=0, loss_v2=0, nll_loss=1.039, ntokens=1014, nsentences=32, sample_size=1014, sample_size_v1=0, sample_size_v2=0, ppl=2.05, wps=544.8, ups=0.54, wpb=1014, bsz=32, num_updates=26500, lr=1.56379e-05, gnorm=7.236, clip=100, loss_scale=128, train_wall=19, gb_free=11.2, wall=49802
2023-05-26 13:13:26 - progress_bar.py[line:272] - INFO: epoch 016:    575 / 1732 loss=2.25, loss_v1=0, loss_v2=0, nll_loss=1.034, ntokens=1007.3, nsentences=32, sample_size=1007.3, sample_size_v1=0, sample_size_v2=0, ppl=2.05, wps=539, ups=0.54, wpb=1007.3, bsz=32, num_updates=26510, lr=1.56317e-05, gnorm=7.288, clip=100, loss_scale=128, train_wall=19, gb_free=11.5, wall=49821
2023-05-26 13:13:45 - progress_bar.py[line:272] - INFO: epoch 016:    585 / 1732 loss=2.254, loss_v1=0, loss_v2=0, nll_loss=1.04, ntokens=980.6, nsentences=32, sample_size=980.6, sample_size_v1=0, sample_size_v2=0, ppl=2.06, wps=524.7, ups=0.54, wpb=980.6, bsz=32, num_updates=26520, lr=1.56256e-05, gnorm=6.987, clip=100, loss_scale=128, train_wall=19, gb_free=11.6, wall=49840
2023-05-26 13:14:04 - progress_bar.py[line:272] - INFO: epoch 016:    595 / 1732 loss=2.207, loss_v1=0, loss_v2=0, nll_loss=0.988, ntokens=961.9, nsentences=32, sample_size=961.9, sample_size_v1=0, sample_size_v2=0, ppl=1.98, wps=516.9, ups=0.54, wpb=961.9, bsz=32, num_updates=26530, lr=1.56194e-05, gnorm=6.916, clip=100, loss_scale=128, train_wall=19, gb_free=11.6, wall=49858
2023-05-26 13:14:22 - progress_bar.py[line:272] - INFO: epoch 016:    605 / 1732 loss=2.215, loss_v1=0, loss_v2=0, nll_loss=0.998, ntokens=879.8, nsentences=32, sample_size=879.8, sample_size_v1=0, sample_size_v2=0, ppl=2, wps=477.7, ups=0.54, wpb=879.8, bsz=32, num_updates=26540, lr=1.56133e-05, gnorm=7.502, clip=100, loss_scale=128, train_wall=18, gb_free=12, wall=49877
2023-05-26 13:14:41 - progress_bar.py[line:272] - INFO: epoch 016:    615 / 1732 loss=2.25, loss_v1=0, loss_v2=0, nll_loss=1.037, ntokens=903.1, nsentences=32, sample_size=903.1, sample_size_v1=0, sample_size_v2=0, ppl=2.05, wps=487.7, ups=0.54, wpb=903.1, bsz=32, num_updates=26550, lr=1.56071e-05, gnorm=7.822, clip=100, loss_scale=128, train_wall=18, gb_free=11.7, wall=49895
2023-05-26 13:14:51 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2023-05-26 13:15:01 - progress_bar.py[line:272] - INFO: epoch 016:    626 / 1732 loss=2.239, loss_v1=0, loss_v2=0, nll_loss=1.022, ntokens=906.2, nsentences=32, sample_size=906.2, sample_size_v1=0, sample_size_v2=0, ppl=2.03, wps=449.5, ups=0.5, wpb=906.2, bsz=32, num_updates=26560, lr=1.5601e-05, gnorm=7.475, clip=100, loss_scale=64, train_wall=20, gb_free=11.6, wall=49915
2023-05-26 13:15:19 - progress_bar.py[line:272] - INFO: epoch 016:    636 / 1732 loss=2.253, loss_v1=0, loss_v2=0, nll_loss=1.038, ntokens=899.7, nsentences=32, sample_size=899.7, sample_size_v1=0, sample_size_v2=0, ppl=2.05, wps=489.1, ups=0.54, wpb=899.7, bsz=32, num_updates=26570, lr=1.55949e-05, gnorm=8.039, clip=100, loss_scale=64, train_wall=18, gb_free=11.4, wall=49934
2023-05-26 13:15:38 - progress_bar.py[line:272] - INFO: epoch 016:    646 / 1732 loss=2.241, loss_v1=0, loss_v2=0, nll_loss=1.025, ntokens=1003.9, nsentences=32, sample_size=1003.9, sample_size_v1=0, sample_size_v2=0, ppl=2.04, wps=543.4, ups=0.54, wpb=1003.9, bsz=32, num_updates=26580, lr=1.55887e-05, gnorm=7.533, clip=100, loss_scale=64, train_wall=18, gb_free=12, wall=49952
2023-05-26 13:15:56 - progress_bar.py[line:272] - INFO: epoch 016:    656 / 1732 loss=2.234, loss_v1=0, loss_v2=0, nll_loss=1.018, ntokens=882.2, nsentences=32, sample_size=882.2, sample_size_v1=0, sample_size_v2=0, ppl=2.03, wps=481.4, ups=0.55, wpb=882.2, bsz=32, num_updates=26590, lr=1.55826e-05, gnorm=7.183, clip=100, loss_scale=64, train_wall=18, gb_free=11.9, wall=49971
2023-05-26 13:16:14 - progress_bar.py[line:272] - INFO: epoch 016:    666 / 1732 loss=2.234, loss_v1=0, loss_v2=0, nll_loss=1.018, ntokens=902.8, nsentences=32, sample_size=902.8, sample_size_v1=0, sample_size_v2=0, ppl=2.03, wps=491.4, ups=0.54, wpb=902.8, bsz=32, num_updates=26600, lr=1.55764e-05, gnorm=7.557, clip=100, loss_scale=64, train_wall=18, gb_free=11.2, wall=49989
2023-05-26 13:16:33 - progress_bar.py[line:272] - INFO: epoch 016:    676 / 1732 loss=2.266, loss_v1=0, loss_v2=0, nll_loss=1.054, ntokens=976.1, nsentences=32, sample_size=976.1, sample_size_v1=0, sample_size_v2=0, ppl=2.08, wps=525.9, ups=0.54, wpb=976.1, bsz=32, num_updates=26610, lr=1.55703e-05, gnorm=7.545, clip=100, loss_scale=64, train_wall=19, gb_free=11.4, wall=50008
2023-05-26 13:16:51 - progress_bar.py[line:272] - INFO: epoch 016:    686 / 1732 loss=2.24, loss_v1=0, loss_v2=0, nll_loss=1.022, ntokens=963.6, nsentences=32, sample_size=963.6, sample_size_v1=0, sample_size_v2=0, ppl=2.03, wps=521.2, ups=0.54, wpb=963.6, bsz=32, num_updates=26620, lr=1.55642e-05, gnorm=7.053, clip=100, loss_scale=64, train_wall=18, gb_free=11.2, wall=50026
2023-05-26 13:17:10 - progress_bar.py[line:272] - INFO: epoch 016:    696 / 1732 loss=2.26, loss_v1=0, loss_v2=0, nll_loss=1.047, ntokens=982.5, nsentences=32, sample_size=982.5, sample_size_v1=0, sample_size_v2=0, ppl=2.07, wps=526.8, ups=0.54, wpb=982.5, bsz=32, num_updates=26630, lr=1.5558e-05, gnorm=7.077, clip=100, loss_scale=64, train_wall=19, gb_free=11.7, wall=50045
2023-05-26 13:17:28 - progress_bar.py[line:272] - INFO: epoch 016:    706 / 1732 loss=2.222, loss_v1=0, loss_v2=0, nll_loss=1.005, ntokens=918.4, nsentences=32, sample_size=918.4, sample_size_v1=0, sample_size_v2=0, ppl=2.01, wps=498.5, ups=0.54, wpb=918.4, bsz=32, num_updates=26640, lr=1.55519e-05, gnorm=7.487, clip=100, loss_scale=64, train_wall=18, gb_free=11.8, wall=50063
2023-05-26 13:17:47 - progress_bar.py[line:272] - INFO: epoch 016:    716 / 1732 loss=2.227, loss_v1=0, loss_v2=0, nll_loss=1.009, ntokens=886.1, nsentences=32, sample_size=886.1, sample_size_v1=0, sample_size_v2=0, ppl=2.01, wps=482.6, ups=0.54, wpb=886.1, bsz=32, num_updates=26650, lr=1.55457e-05, gnorm=7.678, clip=100, loss_scale=64, train_wall=18, gb_free=11.7, wall=50081
2023-05-26 13:18:05 - progress_bar.py[line:272] - INFO: epoch 016:    726 / 1732 loss=2.206, loss_v1=0, loss_v2=0, nll_loss=0.987, ntokens=913.6, nsentences=32, sample_size=913.6, sample_size_v1=0, sample_size_v2=0, ppl=1.98, wps=494.9, ups=0.54, wpb=913.6, bsz=32, num_updates=26660, lr=1.55396e-05, gnorm=7.848, clip=100, loss_scale=64, train_wall=18, gb_free=11.1, wall=50100
2023-05-26 13:18:24 - progress_bar.py[line:272] - INFO: epoch 016:    736 / 1732 loss=2.234, loss_v1=0, loss_v2=0, nll_loss=1.02, ntokens=979.7, nsentences=32, sample_size=979.7, sample_size_v1=0, sample_size_v2=0, ppl=2.03, wps=531.5, ups=0.54, wpb=979.7, bsz=32, num_updates=26670, lr=1.55334e-05, gnorm=7.607, clip=100, loss_scale=64, train_wall=18, gb_free=11.8, wall=50118
2023-05-26 13:18:42 - progress_bar.py[line:272] - INFO: epoch 016:    746 / 1732 loss=2.215, loss_v1=0, loss_v2=0, nll_loss=0.997, ntokens=974.7, nsentences=32, sample_size=974.7, sample_size_v1=0, sample_size_v2=0, ppl=2, wps=523.9, ups=0.54, wpb=974.7, bsz=32, num_updates=26680, lr=1.55273e-05, gnorm=7.225, clip=100, loss_scale=64, train_wall=19, gb_free=11.5, wall=50137
2023-05-26 13:19:01 - progress_bar.py[line:272] - INFO: epoch 016:    756 / 1732 loss=2.214, loss_v1=0, loss_v2=0, nll_loss=0.994, ntokens=977.2, nsentences=32, sample_size=977.2, sample_size_v1=0, sample_size_v2=0, ppl=1.99, wps=528.6, ups=0.54, wpb=977.2, bsz=32, num_updates=26690, lr=1.55212e-05, gnorm=6.891, clip=100, loss_scale=64, train_wall=18, gb_free=11.2, wall=50155
2023-05-26 13:19:19 - progress_bar.py[line:272] - INFO: epoch 016:    766 / 1732 loss=2.22, loss_v1=0, loss_v2=0, nll_loss=1.001, ntokens=933.3, nsentences=32, sample_size=933.3, sample_size_v1=0, sample_size_v2=0, ppl=2, wps=505.9, ups=0.54, wpb=933.3, bsz=32, num_updates=26700, lr=1.5515e-05, gnorm=7.533, clip=100, loss_scale=64, train_wall=18, gb_free=11.6, wall=50174
2023-05-26 13:19:38 - progress_bar.py[line:272] - INFO: epoch 016:    776 / 1732 loss=2.221, loss_v1=0, loss_v2=0, nll_loss=1.005, ntokens=1027.3, nsentences=32, sample_size=1027.3, sample_size_v1=0, sample_size_v2=0, ppl=2.01, wps=553.9, ups=0.54, wpb=1027.3, bsz=32, num_updates=26710, lr=1.55089e-05, gnorm=7.284, clip=100, loss_scale=64, train_wall=19, gb_free=11.3, wall=50192
2023-05-26 13:19:56 - progress_bar.py[line:272] - INFO: epoch 016:    786 / 1732 loss=2.237, loss_v1=0, loss_v2=0, nll_loss=1.021, ntokens=1013.1, nsentences=32, sample_size=1013.1, sample_size_v1=0, sample_size_v2=0, ppl=2.03, wps=545.8, ups=0.54, wpb=1013.1, bsz=32, num_updates=26720, lr=1.55027e-05, gnorm=7.402, clip=100, loss_scale=64, train_wall=19, gb_free=11.9, wall=50211
2023-05-26 13:20:15 - progress_bar.py[line:272] - INFO: epoch 016:    796 / 1732 loss=2.236, loss_v1=0, loss_v2=0, nll_loss=1.019, ntokens=1030.3, nsentences=32, sample_size=1030.3, sample_size_v1=0, sample_size_v2=0, ppl=2.03, wps=556.2, ups=0.54, wpb=1030.3, bsz=32, num_updates=26730, lr=1.54966e-05, gnorm=7.811, clip=100, loss_scale=64, train_wall=18, gb_free=11.2, wall=50230
2023-05-26 13:20:33 - progress_bar.py[line:272] - INFO: epoch 016:    806 / 1732 loss=2.231, loss_v1=0, loss_v2=0, nll_loss=1.015, ntokens=912.3, nsentences=32, sample_size=912.3, sample_size_v1=0, sample_size_v2=0, ppl=2.02, wps=494.8, ups=0.54, wpb=912.3, bsz=32, num_updates=26740, lr=1.54904e-05, gnorm=8.436, clip=100, loss_scale=64, train_wall=18, gb_free=11.8, wall=50248
2023-05-26 13:20:52 - progress_bar.py[line:272] - INFO: epoch 016:    816 / 1732 loss=2.236, loss_v1=0, loss_v2=0, nll_loss=1.02, ntokens=920, nsentences=32, sample_size=920, sample_size_v1=0, sample_size_v2=0, ppl=2.03, wps=498, ups=0.54, wpb=920, bsz=32, num_updates=26750, lr=1.54843e-05, gnorm=8.597, clip=100, loss_scale=64, train_wall=18, gb_free=11, wall=50266
2023-05-26 13:21:10 - progress_bar.py[line:272] - INFO: epoch 016:    826 / 1732 loss=2.228, loss_v1=0, loss_v2=0, nll_loss=1.01, ntokens=944.4, nsentences=32, sample_size=944.4, sample_size_v1=0, sample_size_v2=0, ppl=2.01, wps=509.7, ups=0.54, wpb=944.4, bsz=32, num_updates=26760, lr=1.54782e-05, gnorm=7.242, clip=100, loss_scale=64, train_wall=19, gb_free=11.6, wall=50285
2023-05-26 13:21:29 - progress_bar.py[line:272] - INFO: epoch 016:    836 / 1732 loss=2.236, loss_v1=0, loss_v2=0, nll_loss=1.02, ntokens=894, nsentences=32, sample_size=894, sample_size_v1=0, sample_size_v2=0, ppl=2.03, wps=488.8, ups=0.55, wpb=894, bsz=32, num_updates=26770, lr=1.5472e-05, gnorm=8.189, clip=100, loss_scale=64, train_wall=18, gb_free=11.8, wall=50303
2023-05-26 13:21:47 - progress_bar.py[line:272] - INFO: epoch 016:    846 / 1732 loss=2.217, loss_v1=0, loss_v2=0, nll_loss=1, ntokens=995.1, nsentences=32, sample_size=995.1, sample_size_v1=0, sample_size_v2=0, ppl=2, wps=541.3, ups=0.54, wpb=995.1, bsz=32, num_updates=26780, lr=1.54659e-05, gnorm=7.474, clip=100, loss_scale=64, train_wall=18, gb_free=11.6, wall=50322
2023-05-26 13:22:06 - progress_bar.py[line:272] - INFO: epoch 016:    856 / 1732 loss=2.22, loss_v1=0, loss_v2=0, nll_loss=1.002, ntokens=944.9, nsentences=32, sample_size=944.9, sample_size_v1=0, sample_size_v2=0, ppl=2, wps=511.2, ups=0.54, wpb=944.9, bsz=32, num_updates=26790, lr=1.54597e-05, gnorm=7.527, clip=100, loss_scale=64, train_wall=18, gb_free=11.6, wall=50340
2023-05-26 13:22:24 - progress_bar.py[line:272] - INFO: epoch 016:    866 / 1732 loss=2.24, loss_v1=0, loss_v2=0, nll_loss=1.026, ntokens=954.3, nsentences=32, sample_size=954.3, sample_size_v1=0, sample_size_v2=0, ppl=2.04, wps=516, ups=0.54, wpb=954.3, bsz=32, num_updates=26800, lr=1.54536e-05, gnorm=8.464, clip=100, loss_scale=64, train_wall=18, gb_free=11.3, wall=50359
2023-05-26 13:22:43 - progress_bar.py[line:272] - INFO: epoch 016:    876 / 1732 loss=2.189, loss_v1=0, loss_v2=0, nll_loss=0.969, ntokens=1023, nsentences=32, sample_size=1023, sample_size_v1=0, sample_size_v2=0, ppl=1.96, wps=550.9, ups=0.54, wpb=1023, bsz=32, num_updates=26810, lr=1.54475e-05, gnorm=7.321, clip=100, loss_scale=64, train_wall=19, gb_free=11.4, wall=50377
2023-05-26 13:23:01 - progress_bar.py[line:272] - INFO: epoch 016:    886 / 1732 loss=2.174, loss_v1=0, loss_v2=0, nll_loss=0.951, ntokens=963.8, nsentences=32, sample_size=963.8, sample_size_v1=0, sample_size_v2=0, ppl=1.93, wps=519, ups=0.54, wpb=963.8, bsz=32, num_updates=26820, lr=1.54413e-05, gnorm=7.458, clip=100, loss_scale=64, train_wall=19, gb_free=11, wall=50396
2023-05-26 13:23:20 - progress_bar.py[line:272] - INFO: epoch 016:    896 / 1732 loss=2.179, loss_v1=0, loss_v2=0, nll_loss=0.956, ntokens=1021.4, nsentences=32, sample_size=1021.4, sample_size_v1=0, sample_size_v2=0, ppl=1.94, wps=551.8, ups=0.54, wpb=1021.4, bsz=32, num_updates=26830, lr=1.54352e-05, gnorm=7.477, clip=100, loss_scale=64, train_wall=18, gb_free=11.5, wall=50414
2023-05-26 13:23:38 - progress_bar.py[line:272] - INFO: epoch 016:    906 / 1732 loss=2.188, loss_v1=0, loss_v2=0, nll_loss=0.965, ntokens=1030.5, nsentences=32, sample_size=1030.5, sample_size_v1=0, sample_size_v2=0, ppl=1.95, wps=554.4, ups=0.54, wpb=1030.5, bsz=32, num_updates=26840, lr=1.5429e-05, gnorm=7.063, clip=100, loss_scale=64, train_wall=19, gb_free=10.6, wall=50433
2023-05-26 13:23:57 - progress_bar.py[line:272] - INFO: epoch 016:    916 / 1732 loss=2.247, loss_v1=0, loss_v2=0, nll_loss=1.031, ntokens=932.7, nsentences=32, sample_size=932.7, sample_size_v1=0, sample_size_v2=0, ppl=2.04, wps=505.6, ups=0.54, wpb=932.7, bsz=32, num_updates=26850, lr=1.54229e-05, gnorm=8.425, clip=100, loss_scale=64, train_wall=18, gb_free=11.3, wall=50451
2023-05-26 13:24:15 - progress_bar.py[line:272] - INFO: epoch 016:    926 / 1732 loss=2.204, loss_v1=0, loss_v2=0, nll_loss=0.984, ntokens=1024.6, nsentences=32, sample_size=1024.6, sample_size_v1=0, sample_size_v2=0, ppl=1.98, wps=549, ups=0.54, wpb=1024.6, bsz=32, num_updates=26860, lr=1.54167e-05, gnorm=6.898, clip=100, loss_scale=64, train_wall=19, gb_free=11.3, wall=50470
2023-05-26 13:24:34 - progress_bar.py[line:272] - INFO: epoch 016:    936 / 1732 loss=2.209, loss_v1=0, loss_v2=0, nll_loss=0.99, ntokens=1056.9, nsentences=32, sample_size=1056.9, sample_size_v1=0, sample_size_v2=0, ppl=1.99, wps=564.5, ups=0.53, wpb=1056.9, bsz=32, num_updates=26870, lr=1.54106e-05, gnorm=7.462, clip=100, loss_scale=64, train_wall=19, gb_free=11.5, wall=50489
2023-05-26 13:24:53 - progress_bar.py[line:272] - INFO: epoch 016:    946 / 1732 loss=2.24, loss_v1=0, loss_v2=0, nll_loss=1.024, ntokens=1053.9, nsentences=32, sample_size=1053.9, sample_size_v1=0, sample_size_v2=0, ppl=2.03, wps=557.5, ups=0.53, wpb=1053.9, bsz=32, num_updates=26880, lr=1.54045e-05, gnorm=7.801, clip=100, loss_scale=64, train_wall=19, gb_free=11.2, wall=50508
2023-05-26 13:25:12 - progress_bar.py[line:272] - INFO: epoch 016:    956 / 1732 loss=2.218, loss_v1=0, loss_v2=0, nll_loss=0.999, ntokens=1038.8, nsentences=32, sample_size=1038.8, sample_size_v1=0, sample_size_v2=0, ppl=2, wps=555.5, ups=0.53, wpb=1038.8, bsz=32, num_updates=26890, lr=1.53983e-05, gnorm=7.585, clip=100, loss_scale=64, train_wall=19, gb_free=11.2, wall=50526
2023-05-26 13:25:30 - progress_bar.py[line:272] - INFO: epoch 016:    966 / 1732 loss=2.231, loss_v1=0, loss_v2=0, nll_loss=1.015, ntokens=1045.2, nsentences=32, sample_size=1045.2, sample_size_v1=0, sample_size_v2=0, ppl=2.02, wps=556.9, ups=0.53, wpb=1045.2, bsz=32, num_updates=26900, lr=1.53922e-05, gnorm=8.568, clip=100, loss_scale=64, train_wall=19, gb_free=11.5, wall=50545
2023-05-26 13:25:49 - progress_bar.py[line:272] - INFO: epoch 016:    976 / 1732 loss=2.209, loss_v1=0, loss_v2=0, nll_loss=0.989, ntokens=1030.4, nsentences=32, sample_size=1030.4, sample_size_v1=0, sample_size_v2=0, ppl=1.98, wps=548.4, ups=0.53, wpb=1030.4, bsz=32, num_updates=26910, lr=1.5386e-05, gnorm=7.382, clip=100, loss_scale=64, train_wall=19, gb_free=11.7, wall=50564
2023-05-26 13:26:08 - progress_bar.py[line:272] - INFO: epoch 016:    986 / 1732 loss=2.219, loss_v1=0, loss_v2=0, nll_loss=1.001, ntokens=1042.1, nsentences=32, sample_size=1042.1, sample_size_v1=0, sample_size_v2=0, ppl=2, wps=550.7, ups=0.53, wpb=1042.1, bsz=32, num_updates=26920, lr=1.53799e-05, gnorm=6.554, clip=100, loss_scale=64, train_wall=19, gb_free=10.8, wall=50583
2023-05-26 13:26:27 - progress_bar.py[line:272] - INFO: epoch 016:    996 / 1732 loss=2.223, loss_v1=0, loss_v2=0, nll_loss=1.005, ntokens=1036.4, nsentences=32, sample_size=1036.4, sample_size_v1=0, sample_size_v2=0, ppl=2.01, wps=552.9, ups=0.53, wpb=1036.4, bsz=32, num_updates=26930, lr=1.53737e-05, gnorm=7.56, clip=100, loss_scale=64, train_wall=19, gb_free=11.7, wall=50602
2023-05-26 13:26:46 - progress_bar.py[line:272] - INFO: epoch 016:   1006 / 1732 loss=2.213, loss_v1=0, loss_v2=0, nll_loss=0.992, ntokens=1007.9, nsentences=32, sample_size=1007.9, sample_size_v1=0, sample_size_v2=0, ppl=1.99, wps=540.7, ups=0.54, wpb=1007.9, bsz=32, num_updates=26940, lr=1.53676e-05, gnorm=8.194, clip=100, loss_scale=64, train_wall=19, gb_free=11.5, wall=50620
2023-05-26 13:27:04 - progress_bar.py[line:272] - INFO: epoch 016:   1016 / 1732 loss=2.218, loss_v1=0, loss_v2=0, nll_loss=0.997, ntokens=979.4, nsentences=32, sample_size=979.4, sample_size_v1=0, sample_size_v2=0, ppl=2, wps=527.9, ups=0.54, wpb=979.4, bsz=32, num_updates=26950, lr=1.53615e-05, gnorm=7.375, clip=100, loss_scale=64, train_wall=19, gb_free=11.6, wall=50639
2023-05-26 13:27:23 - progress_bar.py[line:272] - INFO: epoch 016:   1026 / 1732 loss=2.221, loss_v1=0, loss_v2=0, nll_loss=1.005, ntokens=1095, nsentences=32, sample_size=1095, sample_size_v1=0, sample_size_v2=0, ppl=2.01, wps=580.1, ups=0.53, wpb=1095, bsz=32, num_updates=26960, lr=1.53553e-05, gnorm=7.176, clip=100, loss_scale=64, train_wall=19, gb_free=11.3, wall=50658
2023-05-26 13:27:42 - progress_bar.py[line:272] - INFO: epoch 016:   1036 / 1732 loss=2.202, loss_v1=0, loss_v2=0, nll_loss=0.982, ntokens=1118.5, nsentences=32, sample_size=1118.5, sample_size_v1=0, sample_size_v2=0, ppl=1.98, wps=592.2, ups=0.53, wpb=1118.5, bsz=32, num_updates=26970, lr=1.53492e-05, gnorm=7.345, clip=100, loss_scale=64, train_wall=19, gb_free=11.2, wall=50677
2023-05-26 13:28:01 - progress_bar.py[line:272] - INFO: epoch 016:   1046 / 1732 loss=2.211, loss_v1=0, loss_v2=0, nll_loss=0.991, ntokens=1013.5, nsentences=32, sample_size=1013.5, sample_size_v1=0, sample_size_v2=0, ppl=1.99, wps=540, ups=0.53, wpb=1013.5, bsz=32, num_updates=26980, lr=1.5343e-05, gnorm=7.527, clip=100, loss_scale=64, train_wall=19, gb_free=11.7, wall=50695
2023-05-26 13:28:19 - progress_bar.py[line:272] - INFO: epoch 016:   1056 / 1732 loss=2.224, loss_v1=0, loss_v2=0, nll_loss=1.008, ntokens=1086.8, nsentences=32, sample_size=1086.8, sample_size_v1=0, sample_size_v2=0, ppl=2.01, wps=580.3, ups=0.53, wpb=1086.8, bsz=32, num_updates=26990, lr=1.53369e-05, gnorm=7.705, clip=100, loss_scale=64, train_wall=19, gb_free=11.2, wall=50714
2023-05-26 13:28:38 - progress_bar.py[line:272] - INFO: epoch 016:   1066 / 1732 loss=2.203, loss_v1=0, loss_v2=0, nll_loss=0.984, ntokens=1024.1, nsentences=32, sample_size=1024.1, sample_size_v1=0, sample_size_v2=0, ppl=1.98, wps=546.9, ups=0.53, wpb=1024.1, bsz=32, num_updates=27000, lr=1.53308e-05, gnorm=7.275, clip=100, loss_scale=64, train_wall=19, gb_free=11.2, wall=50733
2023-05-26 13:28:57 - progress_bar.py[line:272] - INFO: epoch 016:   1076 / 1732 loss=2.232, loss_v1=0, loss_v2=0, nll_loss=1.015, ntokens=1000.2, nsentences=32, sample_size=1000.2, sample_size_v1=0, sample_size_v2=0, ppl=2.02, wps=530.8, ups=0.53, wpb=1000.2, bsz=32, num_updates=27010, lr=1.53246e-05, gnorm=7.763, clip=100, loss_scale=64, train_wall=19, gb_free=11.5, wall=50752
2023-05-26 13:29:16 - progress_bar.py[line:272] - INFO: epoch 016:   1086 / 1732 loss=2.212, loss_v1=0, loss_v2=0, nll_loss=0.994, ntokens=1073.8, nsentences=32, sample_size=1073.8, sample_size_v1=0, sample_size_v2=0, ppl=1.99, wps=568.3, ups=0.53, wpb=1073.8, bsz=32, num_updates=27020, lr=1.53185e-05, gnorm=7.412, clip=100, loss_scale=64, train_wall=19, gb_free=11.2, wall=50771
2023-05-26 13:29:35 - progress_bar.py[line:272] - INFO: epoch 016:   1096 / 1732 loss=2.225, loss_v1=0, loss_v2=0, nll_loss=1.008, ntokens=1044.2, nsentences=32, sample_size=1044.2, sample_size_v1=0, sample_size_v2=0, ppl=2.01, wps=557, ups=0.53, wpb=1044.2, bsz=32, num_updates=27030, lr=1.53123e-05, gnorm=7.279, clip=100, loss_scale=64, train_wall=19, gb_free=11, wall=50789
2023-05-26 13:29:53 - progress_bar.py[line:272] - INFO: epoch 016:   1106 / 1732 loss=2.204, loss_v1=0, loss_v2=0, nll_loss=0.982, ntokens=1073, nsentences=32, sample_size=1073, sample_size_v1=0, sample_size_v2=0, ppl=1.98, wps=569.5, ups=0.53, wpb=1073, bsz=32, num_updates=27040, lr=1.53062e-05, gnorm=6.938, clip=100, loss_scale=64, train_wall=19, gb_free=11.2, wall=50808
2023-05-26 13:30:12 - progress_bar.py[line:272] - INFO: epoch 016:   1116 / 1732 loss=2.218, loss_v1=0, loss_v2=0, nll_loss=0.999, ntokens=936.7, nsentences=32, sample_size=936.7, sample_size_v1=0, sample_size_v2=0, ppl=2, wps=500.4, ups=0.53, wpb=936.7, bsz=32, num_updates=27050, lr=1.53e-05, gnorm=8.043, clip=100, loss_scale=64, train_wall=19, gb_free=11.1, wall=50827
2023-05-26 13:30:31 - progress_bar.py[line:272] - INFO: epoch 016:   1126 / 1732 loss=2.197, loss_v1=0, loss_v2=0, nll_loss=0.976, ntokens=1021, nsentences=32, sample_size=1021, sample_size_v1=0, sample_size_v2=0, ppl=1.97, wps=542.7, ups=0.53, wpb=1021, bsz=32, num_updates=27060, lr=1.52939e-05, gnorm=7.715, clip=100, loss_scale=64, train_wall=19, gb_free=10.9, wall=50846
2023-05-26 13:30:50 - progress_bar.py[line:272] - INFO: epoch 016:   1136 / 1732 loss=2.212, loss_v1=0, loss_v2=0, nll_loss=0.995, ntokens=969.6, nsentences=32, sample_size=969.6, sample_size_v1=0, sample_size_v2=0, ppl=1.99, wps=517.4, ups=0.53, wpb=969.6, bsz=32, num_updates=27070, lr=1.52878e-05, gnorm=7.728, clip=100, loss_scale=128, train_wall=19, gb_free=11.7, wall=50864
2023-05-26 13:30:55 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2023-05-26 13:31:10 - progress_bar.py[line:272] - INFO: epoch 016:   1147 / 1732 loss=2.204, loss_v1=0, loss_v2=0, nll_loss=0.984, ntokens=1020.9, nsentences=32, sample_size=1020.9, sample_size_v1=0, sample_size_v2=0, ppl=1.98, wps=496.3, ups=0.49, wpb=1020.9, bsz=32, num_updates=27080, lr=1.52816e-05, gnorm=7.703, clip=100, loss_scale=64, train_wall=21, gb_free=11.3, wall=50885
2023-05-26 13:31:29 - progress_bar.py[line:272] - INFO: epoch 016:   1157 / 1732 loss=2.185, loss_v1=0, loss_v2=0, nll_loss=0.963, ntokens=1000.6, nsentences=32, sample_size=1000.6, sample_size_v1=0, sample_size_v2=0, ppl=1.95, wps=535.9, ups=0.54, wpb=1000.6, bsz=32, num_updates=27090, lr=1.52755e-05, gnorm=7.904, clip=100, loss_scale=64, train_wall=19, gb_free=11.7, wall=50904
2023-05-26 13:31:48 - progress_bar.py[line:272] - INFO: epoch 016:   1167 / 1732 loss=2.205, loss_v1=0, loss_v2=0, nll_loss=0.986, ntokens=1036.7, nsentences=32, sample_size=1036.7, sample_size_v1=0, sample_size_v2=0, ppl=1.98, wps=551.5, ups=0.53, wpb=1036.7, bsz=32, num_updates=27100, lr=1.52693e-05, gnorm=7.688, clip=100, loss_scale=64, train_wall=19, gb_free=11.4, wall=50922
2023-05-26 13:32:07 - progress_bar.py[line:272] - INFO: epoch 016:   1177 / 1732 loss=2.186, loss_v1=0, loss_v2=0, nll_loss=0.963, ntokens=1069.6, nsentences=32, sample_size=1069.6, sample_size_v1=0, sample_size_v2=0, ppl=1.95, wps=569.8, ups=0.53, wpb=1069.6, bsz=32, num_updates=27110, lr=1.52632e-05, gnorm=7.519, clip=100, loss_scale=64, train_wall=19, gb_free=11.7, wall=50941
2023-05-26 13:32:25 - progress_bar.py[line:272] - INFO: epoch 016:   1187 / 1732 loss=2.189, loss_v1=0, loss_v2=0, nll_loss=0.968, ntokens=953.6, nsentences=32, sample_size=953.6, sample_size_v1=0, sample_size_v2=0, ppl=1.96, wps=511.4, ups=0.54, wpb=953.6, bsz=32, num_updates=27120, lr=1.5257e-05, gnorm=7.869, clip=100, loss_scale=64, train_wall=19, gb_free=11.9, wall=50960
2023-05-26 13:32:44 - progress_bar.py[line:272] - INFO: epoch 016:   1197 / 1732 loss=2.211, loss_v1=0, loss_v2=0, nll_loss=0.993, ntokens=1116.1, nsentences=32, sample_size=1116.1, sample_size_v1=0, sample_size_v2=0, ppl=1.99, wps=592, ups=0.53, wpb=1116.1, bsz=32, num_updates=27130, lr=1.52509e-05, gnorm=8.383, clip=100, loss_scale=64, train_wall=19, gb_free=10.4, wall=50979
2023-05-26 13:33:03 - progress_bar.py[line:272] - INFO: epoch 016:   1207 / 1732 loss=2.181, loss_v1=0, loss_v2=0, nll_loss=0.958, ntokens=1096.1, nsentences=32, sample_size=1096.1, sample_size_v1=0, sample_size_v2=0, ppl=1.94, wps=580.1, ups=0.53, wpb=1096.1, bsz=32, num_updates=27140, lr=1.52448e-05, gnorm=7.072, clip=100, loss_scale=64, train_wall=19, gb_free=11.1, wall=50998
2023-05-26 13:33:22 - progress_bar.py[line:272] - INFO: epoch 016:   1217 / 1732 loss=2.222, loss_v1=0, loss_v2=0, nll_loss=1.004, ntokens=1014.3, nsentences=32, sample_size=1014.3, sample_size_v1=0, sample_size_v2=0, ppl=2.01, wps=541.7, ups=0.53, wpb=1014.3, bsz=32, num_updates=27150, lr=1.52386e-05, gnorm=7.602, clip=100, loss_scale=64, train_wall=19, gb_free=11.4, wall=51016
2023-05-26 13:33:40 - progress_bar.py[line:272] - INFO: epoch 016:   1227 / 1732 loss=2.224, loss_v1=0, loss_v2=0, nll_loss=1.006, ntokens=1027.4, nsentences=32, sample_size=1027.4, sample_size_v1=0, sample_size_v2=0, ppl=2.01, wps=548, ups=0.53, wpb=1027.4, bsz=32, num_updates=27160, lr=1.52325e-05, gnorm=7.786, clip=100, loss_scale=64, train_wall=19, gb_free=11.8, wall=51035
2023-05-26 13:33:59 - progress_bar.py[line:272] - INFO: epoch 016:   1237 / 1732 loss=2.181, loss_v1=0, loss_v2=0, nll_loss=0.957, ntokens=1040.4, nsentences=32, sample_size=1040.4, sample_size_v1=0, sample_size_v2=0, ppl=1.94, wps=554.9, ups=0.53, wpb=1040.4, bsz=32, num_updates=27170, lr=1.52263e-05, gnorm=6.969, clip=100, loss_scale=64, train_wall=19, gb_free=11.4, wall=51054
2023-05-26 13:34:18 - progress_bar.py[line:272] - INFO: epoch 016:   1247 / 1732 loss=2.159, loss_v1=0, loss_v2=0, nll_loss=0.935, ntokens=1124.4, nsentences=32, sample_size=1124.4, sample_size_v1=0, sample_size_v2=0, ppl=1.91, wps=595.9, ups=0.53, wpb=1124.4, bsz=32, num_updates=27180, lr=1.52202e-05, gnorm=7.141, clip=100, loss_scale=64, train_wall=19, gb_free=11.6, wall=51073
2023-05-26 13:34:37 - progress_bar.py[line:272] - INFO: epoch 016:   1257 / 1732 loss=2.175, loss_v1=0, loss_v2=0, nll_loss=0.953, ntokens=1053.7, nsentences=32, sample_size=1053.7, sample_size_v1=0, sample_size_v2=0, ppl=1.94, wps=561.3, ups=0.53, wpb=1053.7, bsz=32, num_updates=27190, lr=1.52141e-05, gnorm=7.616, clip=100, loss_scale=64, train_wall=19, gb_free=11.2, wall=51092
2023-05-26 13:34:56 - progress_bar.py[line:272] - INFO: epoch 016:   1267 / 1732 loss=2.201, loss_v1=0, loss_v2=0, nll_loss=0.982, ntokens=1037.3, nsentences=32, sample_size=1037.3, sample_size_v1=0, sample_size_v2=0, ppl=1.98, wps=551, ups=0.53, wpb=1037.3, bsz=32, num_updates=27200, lr=1.52079e-05, gnorm=7.34, clip=100, loss_scale=64, train_wall=19, gb_free=11.3, wall=51110
2023-05-26 13:35:15 - progress_bar.py[line:272] - INFO: epoch 016:   1277 / 1732 loss=2.205, loss_v1=0, loss_v2=0, nll_loss=0.985, ntokens=1060.8, nsentences=32, sample_size=1060.8, sample_size_v1=0, sample_size_v2=0, ppl=1.98, wps=563, ups=0.53, wpb=1060.8, bsz=32, num_updates=27210, lr=1.52018e-05, gnorm=7.416, clip=100, loss_scale=64, train_wall=19, gb_free=10.9, wall=51129
2023-05-26 13:35:33 - progress_bar.py[line:272] - INFO: epoch 016:   1287 / 1732 loss=2.194, loss_v1=0, loss_v2=0, nll_loss=0.971, ntokens=1057.7, nsentences=32, sample_size=1057.7, sample_size_v1=0, sample_size_v2=0, ppl=1.96, wps=561.4, ups=0.53, wpb=1057.7, bsz=32, num_updates=27220, lr=1.51956e-05, gnorm=7.383, clip=100, loss_scale=64, train_wall=19, gb_free=11.1, wall=51148
2023-05-26 13:35:52 - progress_bar.py[line:272] - INFO: epoch 016:   1297 / 1732 loss=2.193, loss_v1=0, loss_v2=0, nll_loss=0.971, ntokens=1105.1, nsentences=32, sample_size=1105.1, sample_size_v1=0, sample_size_v2=0, ppl=1.96, wps=585.8, ups=0.53, wpb=1105.1, bsz=32, num_updates=27230, lr=1.51895e-05, gnorm=6.553, clip=100, loss_scale=64, train_wall=19, gb_free=11.5, wall=51167
2023-05-26 13:36:11 - progress_bar.py[line:272] - INFO: epoch 016:   1307 / 1732 loss=2.23, loss_v1=0, loss_v2=0, nll_loss=1.013, ntokens=1096.7, nsentences=32, sample_size=1096.7, sample_size_v1=0, sample_size_v2=0, ppl=2.02, wps=577.2, ups=0.53, wpb=1096.7, bsz=32, num_updates=27240, lr=1.51833e-05, gnorm=7.211, clip=100, loss_scale=64, train_wall=19, gb_free=11.5, wall=51186
2023-05-26 13:36:30 - progress_bar.py[line:272] - INFO: epoch 016:   1317 / 1732 loss=2.211, loss_v1=0, loss_v2=0, nll_loss=0.994, ntokens=1048.7, nsentences=32, sample_size=1048.7, sample_size_v1=0, sample_size_v2=0, ppl=1.99, wps=550.7, ups=0.53, wpb=1048.7, bsz=32, num_updates=27250, lr=1.51772e-05, gnorm=7.458, clip=100, loss_scale=64, train_wall=19, gb_free=11.6, wall=51205
2023-05-26 13:36:49 - progress_bar.py[line:272] - INFO: epoch 016:   1327 / 1732 loss=2.182, loss_v1=0, loss_v2=0, nll_loss=0.961, ntokens=1124.5, nsentences=32, sample_size=1124.5, sample_size_v1=0, sample_size_v2=0, ppl=1.95, wps=594.5, ups=0.53, wpb=1124.5, bsz=32, num_updates=27260, lr=1.51711e-05, gnorm=7.457, clip=100, loss_scale=64, train_wall=19, gb_free=11.3, wall=51224
2023-05-26 13:37:08 - progress_bar.py[line:272] - INFO: epoch 016:   1337 / 1732 loss=2.178, loss_v1=0, loss_v2=0, nll_loss=0.954, ntokens=1126.2, nsentences=32, sample_size=1126.2, sample_size_v1=0, sample_size_v2=0, ppl=1.94, wps=597.3, ups=0.53, wpb=1126.2, bsz=32, num_updates=27270, lr=1.51649e-05, gnorm=7.42, clip=100, loss_scale=64, train_wall=19, gb_free=11.2, wall=51243
2023-05-26 13:37:27 - progress_bar.py[line:272] - INFO: epoch 016:   1347 / 1732 loss=2.197, loss_v1=0, loss_v2=0, nll_loss=0.976, ntokens=1159.1, nsentences=32, sample_size=1159.1, sample_size_v1=0, sample_size_v2=0, ppl=1.97, wps=611.6, ups=0.53, wpb=1159.1, bsz=32, num_updates=27280, lr=1.51588e-05, gnorm=7.579, clip=100, loss_scale=64, train_wall=19, gb_free=11.5, wall=51262
2023-05-26 13:37:46 - progress_bar.py[line:272] - INFO: epoch 016:   1357 / 1732 loss=2.164, loss_v1=0, loss_v2=0, nll_loss=0.94, ntokens=1146.3, nsentences=32, sample_size=1146.3, sample_size_v1=0, sample_size_v2=0, ppl=1.92, wps=604.9, ups=0.53, wpb=1146.3, bsz=32, num_updates=27290, lr=1.51526e-05, gnorm=6.795, clip=100, loss_scale=64, train_wall=19, gb_free=10.9, wall=51281
2023-05-26 13:38:05 - progress_bar.py[line:272] - INFO: epoch 016:   1367 / 1732 loss=2.194, loss_v1=0, loss_v2=0, nll_loss=0.972, ntokens=1081.6, nsentences=32, sample_size=1081.6, sample_size_v1=0, sample_size_v2=0, ppl=1.96, wps=572.7, ups=0.53, wpb=1081.6, bsz=32, num_updates=27300, lr=1.51465e-05, gnorm=7.614, clip=100, loss_scale=64, train_wall=19, gb_free=11, wall=51300
2023-05-26 13:38:24 - progress_bar.py[line:272] - INFO: epoch 016:   1377 / 1732 loss=2.228, loss_v1=0, loss_v2=0, nll_loss=1.009, ntokens=1107.3, nsentences=32, sample_size=1107.3, sample_size_v1=0, sample_size_v2=0, ppl=2.01, wps=589.1, ups=0.53, wpb=1107.3, bsz=32, num_updates=27310, lr=1.51403e-05, gnorm=7.632, clip=100, loss_scale=64, train_wall=19, gb_free=11.5, wall=51318
2023-05-26 13:38:42 - progress_bar.py[line:272] - INFO: epoch 016:   1387 / 1732 loss=2.19, loss_v1=0, loss_v2=0, nll_loss=0.969, ntokens=1152.6, nsentences=32, sample_size=1152.6, sample_size_v1=0, sample_size_v2=0, ppl=1.96, wps=613.4, ups=0.53, wpb=1152.6, bsz=32, num_updates=27320, lr=1.51342e-05, gnorm=6.89, clip=100, loss_scale=64, train_wall=19, gb_free=11.5, wall=51337
2023-05-26 13:39:01 - progress_bar.py[line:272] - INFO: epoch 016:   1397 / 1732 loss=2.195, loss_v1=0, loss_v2=0, nll_loss=0.975, ntokens=1066.5, nsentences=32, sample_size=1066.5, sample_size_v1=0, sample_size_v2=0, ppl=1.97, wps=566.3, ups=0.53, wpb=1066.5, bsz=32, num_updates=27330, lr=1.51281e-05, gnorm=7.371, clip=100, loss_scale=64, train_wall=19, gb_free=11.4, wall=51356
2023-05-26 13:39:20 - progress_bar.py[line:272] - INFO: epoch 016:   1407 / 1732 loss=2.21, loss_v1=0, loss_v2=0, nll_loss=0.991, ntokens=1152.8, nsentences=32, sample_size=1152.8, sample_size_v1=0, sample_size_v2=0, ppl=1.99, wps=611.3, ups=0.53, wpb=1152.8, bsz=32, num_updates=27340, lr=1.51219e-05, gnorm=7.459, clip=100, loss_scale=64, train_wall=19, gb_free=11.4, wall=51375
2023-05-26 13:39:39 - progress_bar.py[line:272] - INFO: epoch 016:   1417 / 1732 loss=2.223, loss_v1=0, loss_v2=0, nll_loss=1.005, ntokens=1290.7, nsentences=32, sample_size=1290.7, sample_size_v1=0, sample_size_v2=0, ppl=2.01, wps=678.3, ups=0.53, wpb=1290.7, bsz=32, num_updates=27350, lr=1.51158e-05, gnorm=7.144, clip=100, loss_scale=64, train_wall=19, gb_free=10.9, wall=51394
2023-05-26 13:39:58 - progress_bar.py[line:272] - INFO: epoch 016:   1427 / 1732 loss=2.19, loss_v1=0, loss_v2=0, nll_loss=0.967, ntokens=1220.7, nsentences=32, sample_size=1220.7, sample_size_v1=0, sample_size_v2=0, ppl=1.96, wps=640.9, ups=0.53, wpb=1220.7, bsz=32, num_updates=27360, lr=1.51096e-05, gnorm=6.955, clip=100, loss_scale=64, train_wall=19, gb_free=11.6, wall=51413
2023-05-26 13:40:17 - progress_bar.py[line:272] - INFO: epoch 016:   1437 / 1732 loss=2.195, loss_v1=0, loss_v2=0, nll_loss=0.976, ntokens=1217.2, nsentences=32, sample_size=1217.2, sample_size_v1=0, sample_size_v2=0, ppl=1.97, wps=642.8, ups=0.53, wpb=1217.2, bsz=32, num_updates=27370, lr=1.51035e-05, gnorm=6.944, clip=100, loss_scale=64, train_wall=19, gb_free=9.6, wall=51432
2023-05-26 13:40:36 - progress_bar.py[line:272] - INFO: epoch 016:   1447 / 1732 loss=2.193, loss_v1=0, loss_v2=0, nll_loss=0.972, ntokens=1115.7, nsentences=32, sample_size=1115.7, sample_size_v1=0, sample_size_v2=0, ppl=1.96, wps=593.7, ups=0.53, wpb=1115.7, bsz=32, num_updates=27380, lr=1.50974e-05, gnorm=7.433, clip=100, loss_scale=64, train_wall=19, gb_free=11.6, wall=51451
2023-05-26 13:40:55 - progress_bar.py[line:272] - INFO: epoch 016:   1457 / 1732 loss=2.213, loss_v1=0, loss_v2=0, nll_loss=0.994, ntokens=1111.8, nsentences=32, sample_size=1111.8, sample_size_v1=0, sample_size_v2=0, ppl=1.99, wps=587.6, ups=0.53, wpb=1111.8, bsz=32, num_updates=27390, lr=1.50912e-05, gnorm=7.848, clip=100, loss_scale=64, train_wall=19, gb_free=10.6, wall=51470
2023-05-26 13:41:14 - progress_bar.py[line:272] - INFO: epoch 016:   1467 / 1732 loss=2.163, loss_v1=0, loss_v2=0, nll_loss=0.938, ntokens=1202.5, nsentences=32, sample_size=1202.5, sample_size_v1=0, sample_size_v2=0, ppl=1.92, wps=632.9, ups=0.53, wpb=1202.5, bsz=32, num_updates=27400, lr=1.50851e-05, gnorm=7.118, clip=100, loss_scale=64, train_wall=19, gb_free=11.3, wall=51489
2023-05-26 13:41:33 - progress_bar.py[line:272] - INFO: epoch 016:   1477 / 1732 loss=2.212, loss_v1=0, loss_v2=0, nll_loss=0.993, ntokens=1052.1, nsentences=32, sample_size=1052.1, sample_size_v1=0, sample_size_v2=0, ppl=1.99, wps=559.5, ups=0.53, wpb=1052.1, bsz=32, num_updates=27410, lr=1.50789e-05, gnorm=8.392, clip=100, loss_scale=64, train_wall=19, gb_free=10.7, wall=51507
2023-05-26 13:41:52 - progress_bar.py[line:272] - INFO: epoch 016:   1487 / 1732 loss=2.211, loss_v1=0, loss_v2=0, nll_loss=0.991, ntokens=1147.5, nsentences=32, sample_size=1147.5, sample_size_v1=0, sample_size_v2=0, ppl=1.99, wps=607.6, ups=0.53, wpb=1147.5, bsz=32, num_updates=27420, lr=1.50728e-05, gnorm=7.134, clip=100, loss_scale=64, train_wall=19, gb_free=10.8, wall=51526
2023-05-26 13:42:10 - progress_bar.py[line:272] - INFO: epoch 016:   1497 / 1732 loss=2.192, loss_v1=0, loss_v2=0, nll_loss=0.97, ntokens=1083.9, nsentences=32, sample_size=1083.9, sample_size_v1=0, sample_size_v2=0, ppl=1.96, wps=574.8, ups=0.53, wpb=1083.9, bsz=32, num_updates=27430, lr=1.50666e-05, gnorm=7.773, clip=100, loss_scale=64, train_wall=19, gb_free=11.5, wall=51545
2023-05-26 13:42:29 - progress_bar.py[line:272] - INFO: epoch 016:   1507 / 1732 loss=2.149, loss_v1=0, loss_v2=0, nll_loss=0.923, ntokens=1112.5, nsentences=32, sample_size=1112.5, sample_size_v1=0, sample_size_v2=0, ppl=1.9, wps=590.4, ups=0.53, wpb=1112.5, bsz=32, num_updates=27440, lr=1.50605e-05, gnorm=7.503, clip=100, loss_scale=64, train_wall=19, gb_free=11.5, wall=51564
2023-05-26 13:42:48 - progress_bar.py[line:272] - INFO: epoch 016:   1517 / 1732 loss=2.218, loss_v1=0, loss_v2=0, nll_loss=1.001, ntokens=1063, nsentences=32, sample_size=1063, sample_size_v1=0, sample_size_v2=0, ppl=2, wps=566.7, ups=0.53, wpb=1063, bsz=32, num_updates=27450, lr=1.50544e-05, gnorm=8.004, clip=100, loss_scale=64, train_wall=19, gb_free=10.7, wall=51583
2023-05-26 13:43:07 - progress_bar.py[line:272] - INFO: epoch 016:   1527 / 1732 loss=2.23, loss_v1=0, loss_v2=0, nll_loss=1.015, ntokens=1062.3, nsentences=32, sample_size=1062.3, sample_size_v1=0, sample_size_v2=0, ppl=2.02, wps=565.8, ups=0.53, wpb=1062.3, bsz=32, num_updates=27460, lr=1.50482e-05, gnorm=8.097, clip=100, loss_scale=64, train_wall=19, gb_free=11.1, wall=51602
2023-05-26 13:43:26 - progress_bar.py[line:272] - INFO: epoch 016:   1537 / 1732 loss=2.198, loss_v1=0, loss_v2=0, nll_loss=0.978, ntokens=1067, nsentences=32, sample_size=1067, sample_size_v1=0, sample_size_v2=0, ppl=1.97, wps=562.9, ups=0.53, wpb=1067, bsz=32, num_updates=27470, lr=1.50421e-05, gnorm=7.923, clip=100, loss_scale=64, train_wall=19, gb_free=11, wall=51621
2023-05-26 13:43:45 - progress_bar.py[line:272] - INFO: epoch 016:   1547 / 1732 loss=2.178, loss_v1=0, loss_v2=0, nll_loss=0.954, ntokens=1093.5, nsentences=32, sample_size=1093.5, sample_size_v1=0, sample_size_v2=0, ppl=1.94, wps=580.6, ups=0.53, wpb=1093.5, bsz=32, num_updates=27480, lr=1.50359e-05, gnorm=8.046, clip=100, loss_scale=64, train_wall=19, gb_free=11.2, wall=51639
2023-05-26 13:44:03 - progress_bar.py[line:272] - INFO: epoch 016:   1557 / 1732 loss=2.168, loss_v1=0, loss_v2=0, nll_loss=0.943, ntokens=1051.1, nsentences=32, sample_size=1051.1, sample_size_v1=0, sample_size_v2=0, ppl=1.92, wps=560.5, ups=0.53, wpb=1051.1, bsz=32, num_updates=27490, lr=1.50298e-05, gnorm=7.155, clip=100, loss_scale=64, train_wall=19, gb_free=11.2, wall=51658
2023-05-26 13:44:22 - progress_bar.py[line:272] - INFO: epoch 016:   1567 / 1732 loss=2.211, loss_v1=0, loss_v2=0, nll_loss=0.992, ntokens=1097.1, nsentences=32, sample_size=1097.1, sample_size_v1=0, sample_size_v2=0, ppl=1.99, wps=581.6, ups=0.53, wpb=1097.1, bsz=32, num_updates=27500, lr=1.50236e-05, gnorm=7.67, clip=100, loss_scale=64, train_wall=19, gb_free=10.6, wall=51677
2023-05-26 13:44:41 - progress_bar.py[line:272] - INFO: epoch 016:   1577 / 1732 loss=2.215, loss_v1=0, loss_v2=0, nll_loss=0.996, ntokens=1002.1, nsentences=32, sample_size=1002.1, sample_size_v1=0, sample_size_v2=0, ppl=1.99, wps=533.8, ups=0.53, wpb=1002.1, bsz=32, num_updates=27510, lr=1.50175e-05, gnorm=8.697, clip=100, loss_scale=64, train_wall=19, gb_free=11.8, wall=51696
2023-05-26 13:45:00 - progress_bar.py[line:272] - INFO: epoch 016:   1587 / 1732 loss=2.202, loss_v1=0, loss_v2=0, nll_loss=0.983, ntokens=1081.3, nsentences=32, sample_size=1081.3, sample_size_v1=0, sample_size_v2=0, ppl=1.98, wps=570.2, ups=0.53, wpb=1081.3, bsz=32, num_updates=27520, lr=1.50114e-05, gnorm=7.359, clip=100, loss_scale=64, train_wall=19, gb_free=10.8, wall=51715
2023-05-26 13:45:19 - progress_bar.py[line:272] - INFO: epoch 016:   1597 / 1732 loss=2.172, loss_v1=0, loss_v2=0, nll_loss=0.949, ntokens=1084.4, nsentences=32, sample_size=1084.4, sample_size_v1=0, sample_size_v2=0, ppl=1.93, wps=576, ups=0.53, wpb=1084.4, bsz=32, num_updates=27530, lr=1.50052e-05, gnorm=8.108, clip=100, loss_scale=64, train_wall=19, gb_free=10.9, wall=51734
2023-05-26 13:45:38 - progress_bar.py[line:272] - INFO: epoch 016:   1607 / 1732 loss=2.176, loss_v1=0, loss_v2=0, nll_loss=0.953, ntokens=1122.8, nsentences=32, sample_size=1122.8, sample_size_v1=0, sample_size_v2=0, ppl=1.94, wps=594.4, ups=0.53, wpb=1122.8, bsz=32, num_updates=27540, lr=1.49991e-05, gnorm=7.162, clip=100, loss_scale=64, train_wall=19, gb_free=10.9, wall=51752
2023-05-26 13:45:57 - progress_bar.py[line:272] - INFO: epoch 016:   1617 / 1732 loss=2.168, loss_v1=0, loss_v2=0, nll_loss=0.945, ntokens=1114.5, nsentences=32, sample_size=1114.5, sample_size_v1=0, sample_size_v2=0, ppl=1.92, wps=587.4, ups=0.53, wpb=1114.5, bsz=32, num_updates=27550, lr=1.49929e-05, gnorm=7.724, clip=100, loss_scale=64, train_wall=19, gb_free=11.3, wall=51771
2023-05-26 13:46:16 - progress_bar.py[line:272] - INFO: epoch 016:   1627 / 1732 loss=2.194, loss_v1=0, loss_v2=0, nll_loss=0.972, ntokens=1162.3, nsentences=32, sample_size=1162.3, sample_size_v1=0, sample_size_v2=0, ppl=1.96, wps=611.8, ups=0.53, wpb=1162.3, bsz=32, num_updates=27560, lr=1.49868e-05, gnorm=7.573, clip=100, loss_scale=64, train_wall=19, gb_free=11.2, wall=51790
2023-05-26 13:46:35 - progress_bar.py[line:272] - INFO: epoch 016:   1637 / 1732 loss=2.159, loss_v1=0, loss_v2=0, nll_loss=0.933, ntokens=1115.7, nsentences=32, sample_size=1115.7, sample_size_v1=0, sample_size_v2=0, ppl=1.91, wps=593.7, ups=0.53, wpb=1115.7, bsz=32, num_updates=27570, lr=1.49807e-05, gnorm=7.566, clip=100, loss_scale=64, train_wall=19, gb_free=11.3, wall=51809
2023-05-26 13:46:54 - progress_bar.py[line:272] - INFO: epoch 016:   1647 / 1732 loss=2.168, loss_v1=0, loss_v2=0, nll_loss=0.944, ntokens=1285, nsentences=32, sample_size=1285, sample_size_v1=0, sample_size_v2=0, ppl=1.92, wps=672.8, ups=0.52, wpb=1285, bsz=32, num_updates=27580, lr=1.49745e-05, gnorm=7.175, clip=100, loss_scale=64, train_wall=19, gb_free=11.1, wall=51828
2023-05-26 13:47:05 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2023-05-26 13:47:14 - progress_bar.py[line:272] - INFO: epoch 016:   1658 / 1732 loss=2.211, loss_v1=0, loss_v2=0, nll_loss=0.993, ntokens=974.4, nsentences=32, sample_size=974.4, sample_size_v1=0, sample_size_v2=0, ppl=1.99, wps=474.5, ups=0.49, wpb=974.4, bsz=32, num_updates=27590, lr=1.49684e-05, gnorm=9.032, clip=100, loss_scale=64, train_wall=20, gb_free=11.1, wall=51849
2023-05-26 13:47:33 - progress_bar.py[line:272] - INFO: epoch 016:   1668 / 1732 loss=2.196, loss_v1=0, loss_v2=0, nll_loss=0.974, ntokens=1011.3, nsentences=32, sample_size=1011.3, sample_size_v1=0, sample_size_v2=0, ppl=1.96, wps=538.4, ups=0.53, wpb=1011.3, bsz=32, num_updates=27600, lr=1.49622e-05, gnorm=8.389, clip=100, loss_scale=64, train_wall=19, gb_free=11.6, wall=51868
2023-05-26 13:47:52 - progress_bar.py[line:272] - INFO: epoch 016:   1678 / 1732 loss=2.151, loss_v1=0, loss_v2=0, nll_loss=0.924, ntokens=1161.5, nsentences=32, sample_size=1161.5, sample_size_v1=0, sample_size_v2=0, ppl=1.9, wps=613.9, ups=0.53, wpb=1161.5, bsz=32, num_updates=27610, lr=1.49561e-05, gnorm=7.343, clip=100, loss_scale=64, train_wall=19, gb_free=11.1, wall=51887
2023-05-26 13:48:11 - progress_bar.py[line:272] - INFO: epoch 016:   1688 / 1732 loss=2.189, loss_v1=0, loss_v2=0, nll_loss=0.967, ntokens=1174.7, nsentences=32, sample_size=1174.7, sample_size_v1=0, sample_size_v2=0, ppl=1.95, wps=616.7, ups=0.52, wpb=1174.7, bsz=32, num_updates=27620, lr=1.49499e-05, gnorm=7.747, clip=100, loss_scale=64, train_wall=19, gb_free=10, wall=51906
2023-05-26 13:48:30 - progress_bar.py[line:272] - INFO: epoch 016:   1698 / 1732 loss=2.169, loss_v1=0, loss_v2=0, nll_loss=0.945, ntokens=1304.9, nsentences=32, sample_size=1304.9, sample_size_v1=0, sample_size_v2=0, ppl=1.92, wps=676.5, ups=0.52, wpb=1304.9, bsz=32, num_updates=27630, lr=1.49438e-05, gnorm=6.669, clip=100, loss_scale=64, train_wall=19, gb_free=11.2, wall=51925
2023-05-26 13:48:49 - progress_bar.py[line:272] - INFO: epoch 016:   1708 / 1732 loss=2.201, loss_v1=0, loss_v2=0, nll_loss=0.979, ntokens=1174.9, nsentences=32, sample_size=1174.9, sample_size_v1=0, sample_size_v2=0, ppl=1.97, wps=619.5, ups=0.53, wpb=1174.9, bsz=32, num_updates=27640, lr=1.49377e-05, gnorm=7.551, clip=100, loss_scale=64, train_wall=19, gb_free=10.8, wall=51944
2023-05-26 13:49:08 - progress_bar.py[line:272] - INFO: epoch 016:   1718 / 1732 loss=2.166, loss_v1=0, loss_v2=0, nll_loss=0.941, ntokens=1181.2, nsentences=32, sample_size=1181.2, sample_size_v1=0, sample_size_v2=0, ppl=1.92, wps=621.6, ups=0.53, wpb=1181.2, bsz=32, num_updates=27650, lr=1.49315e-05, gnorm=7.43, clip=100, loss_scale=64, train_wall=19, gb_free=11, wall=51963
2023-05-26 13:49:27 - progress_bar.py[line:272] - INFO: epoch 016:   1728 / 1732 loss=2.213, loss_v1=0, loss_v2=0, nll_loss=0.994, ntokens=1093.2, nsentences=32, sample_size=1093.2, sample_size_v1=0, sample_size_v2=0, ppl=1.99, wps=578.9, ups=0.53, wpb=1093.2, bsz=32, num_updates=27660, lr=1.49254e-05, gnorm=8.296, clip=100, loss_scale=64, train_wall=19, gb_free=11, wall=51982
2023-05-26 13:49:33 - checkpoint_utils.py[line:64] - INFO: Preparing to save checkpoint for epoch 16 @ 27664 updates
2023-05-26 13:49:33 - trainer.py[line:431] - INFO: Saving checkpoint to ../../checkpoints/OFA/sgcls_checkpoints/_30_3e-5_512_base_nosrcbbox/checkpoint16.pt
2023-05-26 13:49:36 - trainer.py[line:441] - INFO: Finished saving checkpoint to ../../checkpoints/OFA/sgcls_checkpoints/_30_3e-5_512_base_nosrcbbox/checkpoint16.pt
2023-05-26 13:49:39 - checkpoint_utils.py[line:133] - INFO: Saved checkpoint ../../checkpoints/OFA/sgcls_checkpoints/_30_3e-5_512_base_nosrcbbox/checkpoint16.pt (epoch 16 @ 27664 updates, score None) (writing took 5.416722820140421 seconds)
2023-05-26 13:49:39 - train.py[line:332] - INFO: end of epoch 16 (average epoch stats below)
2023-05-26 13:49:39 - progress_bar.py[line:282] - INFO: epoch 016 | loss 2.201 | loss_v1 0 | loss_v2 0 | nll_loss 0.981 | ntokens 1051.84 | nsentences 31.986 | sample_size 1051.84 | sample_size_v1 0 | sample_size_v2 0 | ppl 1.97 | wps 558.6 | ups 0.53 | wpb 1051.8 | bsz 32 | num_updates 27664 | lr 1.49229e-05 | gnorm 7.193 | clip 100 | loss_scale 64 | train_wall 3240 | gb_free 11.7 | wall 51993
2023-05-26 13:49:39 - trainer.py[line:639] - INFO: loading train data for epoch 17
local datafile ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 0 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 0 finished initializing row_count and line_idx-to-offset mapping
file ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 0 row count 55400 total row count 55400
slice_id 0 seek offset 0
2023-05-26 13:49:41 - trainer.py[line:703] - INFO: begin training epoch 17
2023-05-26 13:49:41 - train.py[line:305] - INFO: Start iterating over samples
2023-05-26 13:49:52 - progress_bar.py[line:272] - INFO: epoch 017:      6 / 1732 loss=2.183, loss_v1=0, loss_v2=0, nll_loss=0.959, ntokens=1082.4, nsentences=29.6, sample_size=1082.4, sample_size_v1=0, sample_size_v2=0, ppl=1.94, wps=428.9, ups=0.4, wpb=1082.4, bsz=29.6, num_updates=27670, lr=1.49192e-05, gnorm=7.763, clip=100, loss_scale=64, train_wall=18, gb_free=11.2, wall=52007
2023-05-26 13:50:11 - progress_bar.py[line:272] - INFO: epoch 017:     16 / 1732 loss=2.151, loss_v1=0, loss_v2=0, nll_loss=0.924, ntokens=1099.3, nsentences=32, sample_size=1099.3, sample_size_v1=0, sample_size_v2=0, ppl=1.9, wps=582.9, ups=0.53, wpb=1099.3, bsz=32, num_updates=27680, lr=1.49131e-05, gnorm=8.455, clip=100, loss_scale=64, train_wall=19, gb_free=11.2, wall=52026
2023-05-26 13:50:30 - progress_bar.py[line:272] - INFO: epoch 017:     26 / 1732 loss=2.142, loss_v1=0, loss_v2=0, nll_loss=0.915, ntokens=973, nsentences=32, sample_size=973, sample_size_v1=0, sample_size_v2=0, ppl=1.89, wps=517.3, ups=0.53, wpb=973, bsz=32, num_updates=27690, lr=1.49069e-05, gnorm=9.481, clip=100, loss_scale=64, train_wall=19, gb_free=11.5, wall=52045
2023-05-26 13:50:49 - progress_bar.py[line:272] - INFO: epoch 017:     36 / 1732 loss=2.038, loss_v1=0, loss_v2=0, nll_loss=0.799, ntokens=1153.4, nsentences=32, sample_size=1153.4, sample_size_v1=0, sample_size_v2=0, ppl=1.74, wps=606.7, ups=0.53, wpb=1153.4, bsz=32, num_updates=27700, lr=1.49008e-05, gnorm=7.649, clip=100, loss_scale=64, train_wall=19, gb_free=10.4, wall=52064
2023-05-26 13:51:08 - progress_bar.py[line:272] - INFO: epoch 017:     46 / 1732 loss=2.033, loss_v1=0, loss_v2=0, nll_loss=0.796, ntokens=1066.8, nsentences=32, sample_size=1066.8, sample_size_v1=0, sample_size_v2=0, ppl=1.74, wps=566.3, ups=0.53, wpb=1066.8, bsz=32, num_updates=27710, lr=1.48947e-05, gnorm=7.769, clip=100, loss_scale=64, train_wall=19, gb_free=11.6, wall=52083
2023-05-26 13:51:27 - progress_bar.py[line:272] - INFO: epoch 017:     56 / 1732 loss=1.993, loss_v1=0, loss_v2=0, nll_loss=0.749, ntokens=1077, nsentences=32, sample_size=1077, sample_size_v1=0, sample_size_v2=0, ppl=1.68, wps=569.9, ups=0.53, wpb=1077, bsz=32, num_updates=27720, lr=1.48885e-05, gnorm=7.151, clip=100, loss_scale=64, train_wall=19, gb_free=11.5, wall=52101
2023-05-26 13:51:46 - progress_bar.py[line:272] - INFO: epoch 017:     66 / 1732 loss=1.898, loss_v1=0, loss_v2=0, nll_loss=0.643, ntokens=1294.5, nsentences=32, sample_size=1294.5, sample_size_v1=0, sample_size_v2=0, ppl=1.56, wps=673.2, ups=0.52, wpb=1294.5, bsz=32, num_updates=27730, lr=1.48824e-05, gnorm=5.799, clip=100, loss_scale=64, train_wall=19, gb_free=10.5, wall=52121
2023-05-26 13:52:06 - progress_bar.py[line:272] - INFO: epoch 017:     76 / 1732 loss=1.988, loss_v1=0, loss_v2=0, nll_loss=0.743, ntokens=1343.5, nsentences=32, sample_size=1343.5, sample_size_v1=0, sample_size_v2=0, ppl=1.67, wps=687.7, ups=0.51, wpb=1343.5, bsz=32, num_updates=27740, lr=1.48762e-05, gnorm=5.431, clip=100, loss_scale=64, train_wall=20, gb_free=10.1, wall=52140
2023-05-26 13:52:25 - progress_bar.py[line:272] - INFO: epoch 017:     86 / 1732 loss=2.048, loss_v1=0, loss_v2=0, nll_loss=0.81, ntokens=1107.4, nsentences=32, sample_size=1107.4, sample_size_v1=0, sample_size_v2=0, ppl=1.75, wps=578.7, ups=0.52, wpb=1107.4, bsz=32, num_updates=27750, lr=1.48701e-05, gnorm=7.444, clip=100, loss_scale=64, train_wall=19, gb_free=10.8, wall=52159
2023-05-26 13:52:44 - progress_bar.py[line:272] - INFO: epoch 017:     96 / 1732 loss=2.029, loss_v1=0, loss_v2=0, nll_loss=0.789, ntokens=1069.5, nsentences=32, sample_size=1069.5, sample_size_v1=0, sample_size_v2=0, ppl=1.73, wps=564.4, ups=0.53, wpb=1069.5, bsz=32, num_updates=27760, lr=1.4864e-05, gnorm=7.319, clip=100, loss_scale=64, train_wall=19, gb_free=10.4, wall=52178
2023-05-26 13:53:02 - progress_bar.py[line:272] - INFO: epoch 017:    106 / 1732 loss=2.146, loss_v1=0, loss_v2=0, nll_loss=0.922, ntokens=998.2, nsentences=32, sample_size=998.2, sample_size_v1=0, sample_size_v2=0, ppl=1.89, wps=530.4, ups=0.53, wpb=998.2, bsz=32, num_updates=27770, lr=1.48578e-05, gnorm=7.934, clip=100, loss_scale=64, train_wall=19, gb_free=10.4, wall=52197
2023-05-26 13:53:21 - progress_bar.py[line:272] - INFO: epoch 017:    116 / 1732 loss=2.23, loss_v1=0, loss_v2=0, nll_loss=1.014, ntokens=1049.3, nsentences=32, sample_size=1049.3, sample_size_v1=0, sample_size_v2=0, ppl=2.02, wps=552.9, ups=0.53, wpb=1049.3, bsz=32, num_updates=27780, lr=1.48517e-05, gnorm=7.865, clip=100, loss_scale=64, train_wall=19, gb_free=10.5, wall=52216
2023-05-26 13:53:41 - progress_bar.py[line:272] - INFO: epoch 017:    126 / 1732 loss=2.169, loss_v1=0, loss_v2=0, nll_loss=0.944, ntokens=1187.5, nsentences=32, sample_size=1187.5, sample_size_v1=0, sample_size_v2=0, ppl=1.92, wps=616.8, ups=0.52, wpb=1187.5, bsz=32, num_updates=27790, lr=1.48455e-05, gnorm=7.854, clip=100, loss_scale=64, train_wall=19, gb_free=10.9, wall=52235
2023-05-26 13:54:00 - progress_bar.py[line:272] - INFO: epoch 017:    136 / 1732 loss=2.157, loss_v1=0, loss_v2=0, nll_loss=0.931, ntokens=1228, nsentences=32, sample_size=1228, sample_size_v1=0, sample_size_v2=0, ppl=1.91, wps=642.3, ups=0.52, wpb=1228, bsz=32, num_updates=27800, lr=1.48394e-05, gnorm=7.527, clip=100, loss_scale=64, train_wall=19, gb_free=10.4, wall=52254
2023-05-26 13:54:19 - progress_bar.py[line:272] - INFO: epoch 017:    146 / 1732 loss=2.107, loss_v1=0, loss_v2=0, nll_loss=0.875, ntokens=1192.9, nsentences=32, sample_size=1192.9, sample_size_v1=0, sample_size_v2=0, ppl=1.83, wps=618, ups=0.52, wpb=1192.9, bsz=32, num_updates=27810, lr=1.48332e-05, gnorm=7.091, clip=100, loss_scale=64, train_wall=19, gb_free=10.6, wall=52274
2023-05-26 13:54:38 - progress_bar.py[line:272] - INFO: epoch 017:    156 / 1732 loss=2.148, loss_v1=0, loss_v2=0, nll_loss=0.923, ntokens=1174.3, nsentences=32, sample_size=1174.3, sample_size_v1=0, sample_size_v2=0, ppl=1.9, wps=608.7, ups=0.52, wpb=1174.3, bsz=32, num_updates=27820, lr=1.48271e-05, gnorm=7.858, clip=100, loss_scale=64, train_wall=19, gb_free=11.1, wall=52293
2023-05-26 13:54:57 - progress_bar.py[line:272] - INFO: epoch 017:    166 / 1732 loss=2.125, loss_v1=0, loss_v2=0, nll_loss=0.897, ntokens=1039.2, nsentences=32, sample_size=1039.2, sample_size_v1=0, sample_size_v2=0, ppl=1.86, wps=548.4, ups=0.53, wpb=1039.2, bsz=32, num_updates=27830, lr=1.4821e-05, gnorm=8.391, clip=100, loss_scale=64, train_wall=19, gb_free=10.5, wall=52312
2023-05-26 13:55:16 - progress_bar.py[line:272] - INFO: epoch 017:    176 / 1732 loss=2.142, loss_v1=0, loss_v2=0, nll_loss=0.915, ntokens=982.6, nsentences=32, sample_size=982.6, sample_size_v1=0, sample_size_v2=0, ppl=1.88, wps=520.1, ups=0.53, wpb=982.6, bsz=32, num_updates=27840, lr=1.48148e-05, gnorm=8.818, clip=100, loss_scale=64, train_wall=19, gb_free=11, wall=52331
2023-05-26 13:55:35 - progress_bar.py[line:272] - INFO: epoch 017:    186 / 1732 loss=2.084, loss_v1=0, loss_v2=0, nll_loss=0.85, ntokens=1142, nsentences=32, sample_size=1142, sample_size_v1=0, sample_size_v2=0, ppl=1.8, wps=597.4, ups=0.52, wpb=1142, bsz=32, num_updates=27850, lr=1.48087e-05, gnorm=7.292, clip=100, loss_scale=64, train_wall=19, gb_free=11.1, wall=52350
2023-05-26 13:55:54 - progress_bar.py[line:272] - INFO: epoch 017:    196 / 1732 loss=2.141, loss_v1=0, loss_v2=0, nll_loss=0.913, ntokens=1152.2, nsentences=32, sample_size=1152.2, sample_size_v1=0, sample_size_v2=0, ppl=1.88, wps=605.5, ups=0.53, wpb=1152.2, bsz=32, num_updates=27860, lr=1.48025e-05, gnorm=7.851, clip=100, loss_scale=64, train_wall=19, gb_free=11, wall=52369
2023-05-26 13:56:13 - progress_bar.py[line:272] - INFO: epoch 017:    206 / 1732 loss=2.2, loss_v1=0, loss_v2=0, nll_loss=0.98, ntokens=995.3, nsentences=32, sample_size=995.3, sample_size_v1=0, sample_size_v2=0, ppl=1.97, wps=534.7, ups=0.54, wpb=995.3, bsz=32, num_updates=27870, lr=1.47964e-05, gnorm=8.697, clip=100, loss_scale=64, train_wall=19, gb_free=11.3, wall=52388
2023-05-26 13:56:32 - progress_bar.py[line:272] - INFO: epoch 017:    216 / 1732 loss=2.215, loss_v1=0, loss_v2=0, nll_loss=0.996, ntokens=1119.9, nsentences=32, sample_size=1119.9, sample_size_v1=0, sample_size_v2=0, ppl=1.99, wps=595.9, ups=0.53, wpb=1119.9, bsz=32, num_updates=27880, lr=1.47902e-05, gnorm=8.001, clip=100, loss_scale=64, train_wall=19, gb_free=11.2, wall=52407
2023-05-26 13:56:51 - progress_bar.py[line:272] - INFO: epoch 017:    226 / 1732 loss=2.199, loss_v1=0, loss_v2=0, nll_loss=0.979, ntokens=1111.6, nsentences=32, sample_size=1111.6, sample_size_v1=0, sample_size_v2=0, ppl=1.97, wps=593.5, ups=0.53, wpb=1111.6, bsz=32, num_updates=27890, lr=1.47841e-05, gnorm=7.446, clip=100, loss_scale=64, train_wall=19, gb_free=11.4, wall=52425
2023-05-26 13:57:09 - progress_bar.py[line:272] - INFO: epoch 017:    236 / 1732 loss=2.253, loss_v1=0, loss_v2=0, nll_loss=1.039, ntokens=1076.5, nsentences=32, sample_size=1076.5, sample_size_v1=0, sample_size_v2=0, ppl=2.05, wps=575.6, ups=0.53, wpb=1076.5, bsz=32, num_updates=27900, lr=1.4778e-05, gnorm=7.824, clip=100, loss_scale=64, train_wall=19, gb_free=11.4, wall=52444
2023-05-26 13:57:28 - progress_bar.py[line:272] - INFO: epoch 017:    246 / 1732 loss=2.221, loss_v1=0, loss_v2=0, nll_loss=1.002, ntokens=1166.2, nsentences=32, sample_size=1166.2, sample_size_v1=0, sample_size_v2=0, ppl=2, wps=620.2, ups=0.53, wpb=1166.2, bsz=32, num_updates=27910, lr=1.47718e-05, gnorm=7.221, clip=100, loss_scale=64, train_wall=19, gb_free=11.6, wall=52463
2023-05-26 13:57:47 - progress_bar.py[line:272] - INFO: epoch 017:    256 / 1732 loss=2.217, loss_v1=0, loss_v2=0, nll_loss=1.001, ntokens=1137.6, nsentences=32, sample_size=1137.6, sample_size_v1=0, sample_size_v2=0, ppl=2, wps=606.7, ups=0.53, wpb=1137.6, bsz=32, num_updates=27920, lr=1.47657e-05, gnorm=7.316, clip=100, loss_scale=64, train_wall=19, gb_free=11.4, wall=52482
2023-05-26 13:58:06 - progress_bar.py[line:272] - INFO: epoch 017:    266 / 1732 loss=2.215, loss_v1=0, loss_v2=0, nll_loss=0.997, ntokens=1142, nsentences=32, sample_size=1142, sample_size_v1=0, sample_size_v2=0, ppl=2, wps=607.7, ups=0.53, wpb=1142, bsz=32, num_updates=27930, lr=1.47595e-05, gnorm=6.933, clip=100, loss_scale=64, train_wall=19, gb_free=10.9, wall=52500
2023-05-26 13:58:25 - progress_bar.py[line:272] - INFO: epoch 017:    276 / 1732 loss=2.221, loss_v1=0, loss_v2=0, nll_loss=1.001, ntokens=1142.5, nsentences=32, sample_size=1142.5, sample_size_v1=0, sample_size_v2=0, ppl=2, wps=605, ups=0.53, wpb=1142.5, bsz=32, num_updates=27940, lr=1.47534e-05, gnorm=8.056, clip=100, loss_scale=64, train_wall=19, gb_free=10.8, wall=52519
2023-05-26 13:58:43 - progress_bar.py[line:272] - INFO: epoch 017:    286 / 1732 loss=2.211, loss_v1=0, loss_v2=0, nll_loss=0.989, ntokens=1155.8, nsentences=32, sample_size=1155.8, sample_size_v1=0, sample_size_v2=0, ppl=1.98, wps=612.8, ups=0.53, wpb=1155.8, bsz=32, num_updates=27950, lr=1.47473e-05, gnorm=7.727, clip=100, loss_scale=64, train_wall=19, gb_free=11.2, wall=52538
2023-05-26 13:59:02 - progress_bar.py[line:272] - INFO: epoch 017:    296 / 1732 loss=2.205, loss_v1=0, loss_v2=0, nll_loss=0.986, ntokens=1134.4, nsentences=32, sample_size=1134.4, sample_size_v1=0, sample_size_v2=0, ppl=1.98, wps=604.4, ups=0.53, wpb=1134.4, bsz=32, num_updates=27960, lr=1.47411e-05, gnorm=7.061, clip=100, loss_scale=64, train_wall=19, gb_free=11, wall=52557
2023-05-26 13:59:21 - progress_bar.py[line:272] - INFO: epoch 017:    306 / 1732 loss=2.198, loss_v1=0, loss_v2=0, nll_loss=0.981, ntokens=1078.8, nsentences=32, sample_size=1078.8, sample_size_v1=0, sample_size_v2=0, ppl=1.97, wps=577.7, ups=0.54, wpb=1078.8, bsz=32, num_updates=27970, lr=1.4735e-05, gnorm=7.721, clip=100, loss_scale=64, train_wall=19, gb_free=10.9, wall=52576
2023-05-26 13:59:39 - progress_bar.py[line:272] - INFO: epoch 017:    316 / 1732 loss=2.231, loss_v1=0, loss_v2=0, nll_loss=1.013, ntokens=1033.6, nsentences=32, sample_size=1033.6, sample_size_v1=0, sample_size_v2=0, ppl=2.02, wps=554.2, ups=0.54, wpb=1033.6, bsz=32, num_updates=27980, lr=1.47288e-05, gnorm=8.158, clip=100, loss_scale=64, train_wall=19, gb_free=10.8, wall=52594
2023-05-26 13:59:58 - progress_bar.py[line:272] - INFO: epoch 017:    326 / 1732 loss=2.245, loss_v1=0, loss_v2=0, nll_loss=1.028, ntokens=1006.1, nsentences=32, sample_size=1006.1, sample_size_v1=0, sample_size_v2=0, ppl=2.04, wps=540.3, ups=0.54, wpb=1006.1, bsz=32, num_updates=27990, lr=1.47227e-05, gnorm=8.675, clip=100, loss_scale=64, train_wall=19, gb_free=11.6, wall=52613
2023-05-26 14:00:17 - progress_bar.py[line:272] - INFO: epoch 017:    336 / 1732 loss=2.229, loss_v1=0, loss_v2=0, nll_loss=1.012, ntokens=1005.9, nsentences=32, sample_size=1005.9, sample_size_v1=0, sample_size_v2=0, ppl=2.02, wps=543.4, ups=0.54, wpb=1005.9, bsz=32, num_updates=28000, lr=1.47165e-05, gnorm=8.183, clip=100, loss_scale=64, train_wall=18, gb_free=11.4, wall=52631
2023-05-26 14:00:35 - progress_bar.py[line:272] - INFO: epoch 017:    346 / 1732 loss=2.193, loss_v1=0, loss_v2=0, nll_loss=0.972, ntokens=909.3, nsentences=32, sample_size=909.3, sample_size_v1=0, sample_size_v2=0, ppl=1.96, wps=490.6, ups=0.54, wpb=909.3, bsz=32, num_updates=28010, lr=1.47104e-05, gnorm=9.156, clip=100, loss_scale=64, train_wall=19, gb_free=11.3, wall=52650
2023-05-26 14:00:54 - progress_bar.py[line:272] - INFO: epoch 017:    356 / 1732 loss=2.232, loss_v1=0, loss_v2=0, nll_loss=1.015, ntokens=955.2, nsentences=32, sample_size=955.2, sample_size_v1=0, sample_size_v2=0, ppl=2.02, wps=516.7, ups=0.54, wpb=955.2, bsz=32, num_updates=28020, lr=1.47043e-05, gnorm=8.256, clip=100, loss_scale=64, train_wall=18, gb_free=11.4, wall=52668
2023-05-26 14:01:12 - progress_bar.py[line:272] - INFO: epoch 017:    366 / 1732 loss=2.245, loss_v1=0, loss_v2=0, nll_loss=1.03, ntokens=951.9, nsentences=32, sample_size=951.9, sample_size_v1=0, sample_size_v2=0, ppl=2.04, wps=513.6, ups=0.54, wpb=951.9, bsz=32, num_updates=28030, lr=1.46981e-05, gnorm=9.027, clip=100, loss_scale=64, train_wall=19, gb_free=11.5, wall=52687
2023-05-26 14:01:31 - progress_bar.py[line:272] - INFO: epoch 017:    376 / 1732 loss=2.244, loss_v1=0, loss_v2=0, nll_loss=1.027, ntokens=1015.4, nsentences=32, sample_size=1015.4, sample_size_v1=0, sample_size_v2=0, ppl=2.04, wps=547.7, ups=0.54, wpb=1015.4, bsz=32, num_updates=28040, lr=1.4692e-05, gnorm=8.225, clip=100, loss_scale=64, train_wall=19, gb_free=11.4, wall=52705
2023-05-26 14:01:49 - progress_bar.py[line:272] - INFO: epoch 017:    386 / 1732 loss=2.237, loss_v1=0, loss_v2=0, nll_loss=1.02, ntokens=1063.1, nsentences=32, sample_size=1063.1, sample_size_v1=0, sample_size_v2=0, ppl=2.03, wps=571.5, ups=0.54, wpb=1063.1, bsz=32, num_updates=28050, lr=1.46858e-05, gnorm=8.515, clip=100, loss_scale=64, train_wall=19, gb_free=11.4, wall=52724
2023-05-26 14:02:08 - progress_bar.py[line:272] - INFO: epoch 017:    396 / 1732 loss=2.228, loss_v1=0, loss_v2=0, nll_loss=1.011, ntokens=950.2, nsentences=32, sample_size=950.2, sample_size_v1=0, sample_size_v2=0, ppl=2.02, wps=513.4, ups=0.54, wpb=950.2, bsz=32, num_updates=28060, lr=1.46797e-05, gnorm=9.186, clip=100, loss_scale=64, train_wall=18, gb_free=11.3, wall=52743
2023-05-26 14:02:26 - progress_bar.py[line:272] - INFO: epoch 017:    406 / 1732 loss=2.209, loss_v1=0, loss_v2=0, nll_loss=0.989, ntokens=1066.6, nsentences=32, sample_size=1066.6, sample_size_v1=0, sample_size_v2=0, ppl=1.99, wps=572.9, ups=0.54, wpb=1066.6, bsz=32, num_updates=28070, lr=1.46735e-05, gnorm=8.134, clip=100, loss_scale=64, train_wall=19, gb_free=11.2, wall=52761
2023-05-26 14:02:45 - progress_bar.py[line:272] - INFO: epoch 017:    416 / 1732 loss=2.196, loss_v1=0, loss_v2=0, nll_loss=0.975, ntokens=1055.1, nsentences=32, sample_size=1055.1, sample_size_v1=0, sample_size_v2=0, ppl=1.97, wps=565.1, ups=0.54, wpb=1055.1, bsz=32, num_updates=28080, lr=1.46674e-05, gnorm=8.182, clip=100, loss_scale=64, train_wall=19, gb_free=11.5, wall=52780
2023-05-26 14:03:04 - progress_bar.py[line:272] - INFO: epoch 017:    426 / 1732 loss=2.183, loss_v1=0, loss_v2=0, nll_loss=0.961, ntokens=988.1, nsentences=32, sample_size=988.1, sample_size_v1=0, sample_size_v2=0, ppl=1.95, wps=531.6, ups=0.54, wpb=988.1, bsz=32, num_updates=28090, lr=1.46613e-05, gnorm=8.313, clip=100, loss_scale=64, train_wall=19, gb_free=11, wall=52798
2023-05-26 14:03:22 - progress_bar.py[line:272] - INFO: epoch 017:    436 / 1732 loss=2.216, loss_v1=0, loss_v2=0, nll_loss=0.998, ntokens=1044.5, nsentences=32, sample_size=1044.5, sample_size_v1=0, sample_size_v2=0, ppl=2, wps=560.5, ups=0.54, wpb=1044.5, bsz=32, num_updates=28100, lr=1.46551e-05, gnorm=7.946, clip=100, loss_scale=128, train_wall=19, gb_free=11.1, wall=52817
2023-05-26 14:03:24 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2023-05-26 14:03:43 - progress_bar.py[line:272] - INFO: epoch 017:    447 / 1732 loss=2.22, loss_v1=0, loss_v2=0, nll_loss=1.002, ntokens=949, nsentences=32, sample_size=949, sample_size_v1=0, sample_size_v2=0, ppl=2, wps=466.6, ups=0.49, wpb=949, bsz=32, num_updates=28110, lr=1.4649e-05, gnorm=8.342, clip=100, loss_scale=64, train_wall=20, gb_free=10.9, wall=52837
2023-05-26 14:04:01 - progress_bar.py[line:272] - INFO: epoch 017:    457 / 1732 loss=2.224, loss_v1=0, loss_v2=0, nll_loss=1.008, ntokens=959.4, nsentences=32, sample_size=959.4, sample_size_v1=0, sample_size_v2=0, ppl=2.01, wps=518.7, ups=0.54, wpb=959.4, bsz=32, num_updates=28120, lr=1.46428e-05, gnorm=8.356, clip=100, loss_scale=64, train_wall=18, gb_free=10.6, wall=52856
2023-05-26 14:04:20 - progress_bar.py[line:272] - INFO: epoch 017:    467 / 1732 loss=2.245, loss_v1=0, loss_v2=0, nll_loss=1.03, ntokens=1054.7, nsentences=32, sample_size=1054.7, sample_size_v1=0, sample_size_v2=0, ppl=2.04, wps=563.2, ups=0.53, wpb=1054.7, bsz=32, num_updates=28130, lr=1.46367e-05, gnorm=8.266, clip=100, loss_scale=64, train_wall=19, gb_free=11.3, wall=52875
2023-05-26 14:04:39 - progress_bar.py[line:272] - INFO: epoch 017:    477 / 1732 loss=2.242, loss_v1=0, loss_v2=0, nll_loss=1.025, ntokens=1051.9, nsentences=32, sample_size=1051.9, sample_size_v1=0, sample_size_v2=0, ppl=2.03, wps=563.1, ups=0.54, wpb=1051.9, bsz=32, num_updates=28140, lr=1.46306e-05, gnorm=8.744, clip=100, loss_scale=64, train_wall=19, gb_free=11.6, wall=52893
2023-05-26 14:04:57 - progress_bar.py[line:272] - INFO: epoch 017:    487 / 1732 loss=2.209, loss_v1=0, loss_v2=0, nll_loss=0.988, ntokens=936.6, nsentences=32, sample_size=936.6, sample_size_v1=0, sample_size_v2=0, ppl=1.98, wps=505.8, ups=0.54, wpb=936.6, bsz=32, num_updates=28150, lr=1.46244e-05, gnorm=8.724, clip=100, loss_scale=64, train_wall=18, gb_free=12.1, wall=52912
2023-05-26 14:05:16 - progress_bar.py[line:272] - INFO: epoch 017:    497 / 1732 loss=2.207, loss_v1=0, loss_v2=0, nll_loss=0.988, ntokens=954.7, nsentences=32, sample_size=954.7, sample_size_v1=0, sample_size_v2=0, ppl=1.98, wps=515.4, ups=0.54, wpb=954.7, bsz=32, num_updates=28160, lr=1.46183e-05, gnorm=8.501, clip=100, loss_scale=64, train_wall=18, gb_free=10.9, wall=52930
2023-05-26 14:05:34 - progress_bar.py[line:272] - INFO: epoch 017:    507 / 1732 loss=2.236, loss_v1=0, loss_v2=0, nll_loss=1.021, ntokens=1006.3, nsentences=32, sample_size=1006.3, sample_size_v1=0, sample_size_v2=0, ppl=2.03, wps=543.3, ups=0.54, wpb=1006.3, bsz=32, num_updates=28170, lr=1.46121e-05, gnorm=8.864, clip=100, loss_scale=64, train_wall=18, gb_free=11.3, wall=52949
2023-05-26 14:05:53 - progress_bar.py[line:272] - INFO: epoch 017:    517 / 1732 loss=2.219, loss_v1=0, loss_v2=0, nll_loss=1.002, ntokens=1047.1, nsentences=32, sample_size=1047.1, sample_size_v1=0, sample_size_v2=0, ppl=2, wps=564.8, ups=0.54, wpb=1047.1, bsz=32, num_updates=28180, lr=1.4606e-05, gnorm=8.093, clip=100, loss_scale=64, train_wall=19, gb_free=11.6, wall=52967
2023-05-26 14:06:11 - progress_bar.py[line:272] - INFO: epoch 017:    527 / 1732 loss=2.219, loss_v1=0, loss_v2=0, nll_loss=1.001, ntokens=940.9, nsentences=32, sample_size=940.9, sample_size_v1=0, sample_size_v2=0, ppl=2, wps=509.8, ups=0.54, wpb=940.9, bsz=32, num_updates=28190, lr=1.45998e-05, gnorm=8.498, clip=100, loss_scale=64, train_wall=18, gb_free=11.6, wall=52986
2023-05-26 14:06:30 - progress_bar.py[line:272] - INFO: epoch 017:    537 / 1732 loss=2.209, loss_v1=0, loss_v2=0, nll_loss=0.99, ntokens=964.7, nsentences=32, sample_size=964.7, sample_size_v1=0, sample_size_v2=0, ppl=1.99, wps=521.5, ups=0.54, wpb=964.7, bsz=32, num_updates=28200, lr=1.45937e-05, gnorm=8.618, clip=100, loss_scale=64, train_wall=18, gb_free=11.9, wall=53004
2023-05-26 14:06:48 - progress_bar.py[line:272] - INFO: epoch 017:    547 / 1732 loss=2.233, loss_v1=0, loss_v2=0, nll_loss=1.017, ntokens=1033.6, nsentences=32, sample_size=1033.6, sample_size_v1=0, sample_size_v2=0, ppl=2.02, wps=556.1, ups=0.54, wpb=1033.6, bsz=32, num_updates=28210, lr=1.45876e-05, gnorm=8.611, clip=100, loss_scale=64, train_wall=19, gb_free=11.7, wall=53023
2023-05-26 14:07:07 - progress_bar.py[line:272] - INFO: epoch 017:    557 / 1732 loss=2.255, loss_v1=0, loss_v2=0, nll_loss=1.041, ntokens=1010.2, nsentences=32, sample_size=1010.2, sample_size_v1=0, sample_size_v2=0, ppl=2.06, wps=544.1, ups=0.54, wpb=1010.2, bsz=32, num_updates=28220, lr=1.45814e-05, gnorm=8.586, clip=100, loss_scale=64, train_wall=19, gb_free=11.8, wall=53042
2023-05-26 14:07:25 - progress_bar.py[line:272] - INFO: epoch 017:    567 / 1732 loss=2.249, loss_v1=0, loss_v2=0, nll_loss=1.033, ntokens=1004.9, nsentences=32, sample_size=1004.9, sample_size_v1=0, sample_size_v2=0, ppl=2.05, wps=540.1, ups=0.54, wpb=1004.9, bsz=32, num_updates=28230, lr=1.45753e-05, gnorm=9.022, clip=100, loss_scale=64, train_wall=19, gb_free=11.7, wall=53060
2023-05-26 14:07:44 - progress_bar.py[line:272] - INFO: epoch 017:    577 / 1732 loss=2.226, loss_v1=0, loss_v2=0, nll_loss=1.008, ntokens=1011.7, nsentences=32, sample_size=1011.7, sample_size_v1=0, sample_size_v2=0, ppl=2.01, wps=540.9, ups=0.53, wpb=1011.7, bsz=32, num_updates=28240, lr=1.45691e-05, gnorm=8.627, clip=100, loss_scale=64, train_wall=19, gb_free=11.6, wall=53079
2023-05-26 14:08:03 - progress_bar.py[line:272] - INFO: epoch 017:    587 / 1732 loss=2.237, loss_v1=0, loss_v2=0, nll_loss=1.02, ntokens=962.2, nsentences=32, sample_size=962.2, sample_size_v1=0, sample_size_v2=0, ppl=2.03, wps=510.8, ups=0.53, wpb=962.2, bsz=32, num_updates=28250, lr=1.4563e-05, gnorm=9.696, clip=100, loss_scale=64, train_wall=19, gb_free=12, wall=53098
2023-05-26 14:08:22 - progress_bar.py[line:272] - INFO: epoch 017:    597 / 1732 loss=2.182, loss_v1=0, loss_v2=0, nll_loss=0.96, ntokens=975.4, nsentences=32, sample_size=975.4, sample_size_v1=0, sample_size_v2=0, ppl=1.94, wps=522, ups=0.54, wpb=975.4, bsz=32, num_updates=28260, lr=1.45568e-05, gnorm=7.753, clip=100, loss_scale=64, train_wall=19, gb_free=11.7, wall=53116
2023-05-26 14:08:40 - progress_bar.py[line:272] - INFO: epoch 017:    607 / 1732 loss=2.227, loss_v1=0, loss_v2=0, nll_loss=1.011, ntokens=882.8, nsentences=32, sample_size=882.8, sample_size_v1=0, sample_size_v2=0, ppl=2.02, wps=479.6, ups=0.54, wpb=882.8, bsz=32, num_updates=28270, lr=1.45507e-05, gnorm=9.333, clip=100, loss_scale=64, train_wall=18, gb_free=11.3, wall=53135
2023-05-26 14:08:59 - progress_bar.py[line:272] - INFO: epoch 017:    617 / 1732 loss=2.228, loss_v1=0, loss_v2=0, nll_loss=1.011, ntokens=866.1, nsentences=32, sample_size=866.1, sample_size_v1=0, sample_size_v2=0, ppl=2.02, wps=470.1, ups=0.54, wpb=866.1, bsz=32, num_updates=28280, lr=1.45446e-05, gnorm=9.832, clip=100, loss_scale=64, train_wall=18, gb_free=11.5, wall=53153
2023-05-26 14:09:17 - progress_bar.py[line:272] - INFO: epoch 017:    627 / 1732 loss=2.219, loss_v1=0, loss_v2=0, nll_loss=1, ntokens=930.6, nsentences=32, sample_size=930.6, sample_size_v1=0, sample_size_v2=0, ppl=2, wps=505.5, ups=0.54, wpb=930.6, bsz=32, num_updates=28290, lr=1.45384e-05, gnorm=9.141, clip=100, loss_scale=64, train_wall=18, gb_free=11.9, wall=53172
2023-05-26 14:09:35 - progress_bar.py[line:272] - INFO: epoch 017:    637 / 1732 loss=2.238, loss_v1=0, loss_v2=0, nll_loss=1.022, ntokens=914.3, nsentences=32, sample_size=914.3, sample_size_v1=0, sample_size_v2=0, ppl=2.03, wps=496.9, ups=0.54, wpb=914.3, bsz=32, num_updates=28300, lr=1.45323e-05, gnorm=9.638, clip=100, loss_scale=64, train_wall=18, gb_free=11.6, wall=53190
2023-05-26 14:09:54 - progress_bar.py[line:272] - INFO: epoch 017:    647 / 1732 loss=2.222, loss_v1=0, loss_v2=0, nll_loss=1.004, ntokens=980.8, nsentences=32, sample_size=980.8, sample_size_v1=0, sample_size_v2=0, ppl=2.01, wps=530.9, ups=0.54, wpb=980.8, bsz=32, num_updates=28310, lr=1.45261e-05, gnorm=8.819, clip=100, loss_scale=64, train_wall=18, gb_free=11.8, wall=53209
2023-05-26 14:10:12 - progress_bar.py[line:272] - INFO: epoch 017:    657 / 1732 loss=2.216, loss_v1=0, loss_v2=0, nll_loss=0.998, ntokens=894.4, nsentences=32, sample_size=894.4, sample_size_v1=0, sample_size_v2=0, ppl=2, wps=489.1, ups=0.55, wpb=894.4, bsz=32, num_updates=28320, lr=1.452e-05, gnorm=8.672, clip=100, loss_scale=64, train_wall=18, gb_free=11.8, wall=53227
2023-05-26 14:10:31 - progress_bar.py[line:272] - INFO: epoch 017:    667 / 1732 loss=2.205, loss_v1=0, loss_v2=0, nll_loss=0.986, ntokens=903.9, nsentences=32, sample_size=903.9, sample_size_v1=0, sample_size_v2=0, ppl=1.98, wps=490.9, ups=0.54, wpb=903.9, bsz=32, num_updates=28330, lr=1.45139e-05, gnorm=9.414, clip=100, loss_scale=64, train_wall=18, gb_free=11.5, wall=53245
2023-05-26 14:10:49 - progress_bar.py[line:272] - INFO: epoch 017:    677 / 1732 loss=2.237, loss_v1=0, loss_v2=0, nll_loss=1.021, ntokens=985.3, nsentences=32, sample_size=985.3, sample_size_v1=0, sample_size_v2=0, ppl=2.03, wps=531.2, ups=0.54, wpb=985.3, bsz=32, num_updates=28340, lr=1.45077e-05, gnorm=8.981, clip=100, loss_scale=64, train_wall=19, gb_free=11.8, wall=53264
2023-05-26 14:11:08 - progress_bar.py[line:272] - INFO: epoch 017:    687 / 1732 loss=2.237, loss_v1=0, loss_v2=0, nll_loss=1.021, ntokens=943.2, nsentences=32, sample_size=943.2, sample_size_v1=0, sample_size_v2=0, ppl=2.03, wps=511.5, ups=0.54, wpb=943.2, bsz=32, num_updates=28350, lr=1.45016e-05, gnorm=9.383, clip=100, loss_scale=64, train_wall=18, gb_free=11.9, wall=53282
2023-05-26 14:11:26 - progress_bar.py[line:272] - INFO: epoch 017:    697 / 1732 loss=2.23, loss_v1=0, loss_v2=0, nll_loss=1.012, ntokens=1005.6, nsentences=32, sample_size=1005.6, sample_size_v1=0, sample_size_v2=0, ppl=2.02, wps=538.7, ups=0.54, wpb=1005.6, bsz=32, num_updates=28360, lr=1.44954e-05, gnorm=8.937, clip=100, loss_scale=64, train_wall=19, gb_free=10.9, wall=53301
2023-05-26 14:11:45 - progress_bar.py[line:272] - INFO: epoch 017:    707 / 1732 loss=2.204, loss_v1=0, loss_v2=0, nll_loss=0.984, ntokens=903.4, nsentences=32, sample_size=903.4, sample_size_v1=0, sample_size_v2=0, ppl=1.98, wps=491.3, ups=0.54, wpb=903.4, bsz=32, num_updates=28370, lr=1.44893e-05, gnorm=8.058, clip=100, loss_scale=64, train_wall=18, gb_free=11.6, wall=53319
2023-05-26 14:12:03 - progress_bar.py[line:272] - INFO: epoch 017:    717 / 1732 loss=2.21, loss_v1=0, loss_v2=0, nll_loss=0.991, ntokens=882.7, nsentences=32, sample_size=882.7, sample_size_v1=0, sample_size_v2=0, ppl=1.99, wps=479.8, ups=0.54, wpb=882.7, bsz=32, num_updates=28380, lr=1.44831e-05, gnorm=9.215, clip=100, loss_scale=64, train_wall=18, gb_free=11.6, wall=53338
2023-05-26 14:12:21 - progress_bar.py[line:272] - INFO: epoch 017:    727 / 1732 loss=2.195, loss_v1=0, loss_v2=0, nll_loss=0.975, ntokens=909.8, nsentences=32, sample_size=909.8, sample_size_v1=0, sample_size_v2=0, ppl=1.97, wps=492.9, ups=0.54, wpb=909.8, bsz=32, num_updates=28390, lr=1.4477e-05, gnorm=9.312, clip=100, loss_scale=64, train_wall=18, gb_free=11.9, wall=53356
2023-05-26 14:12:40 - progress_bar.py[line:272] - INFO: epoch 017:    737 / 1732 loss=2.213, loss_v1=0, loss_v2=0, nll_loss=0.996, ntokens=998.8, nsentences=32, sample_size=998.8, sample_size_v1=0, sample_size_v2=0, ppl=2, wps=541.1, ups=0.54, wpb=998.8, bsz=32, num_updates=28400, lr=1.44709e-05, gnorm=9.052, clip=100, loss_scale=64, train_wall=18, gb_free=11.5, wall=53375
2023-05-26 14:12:59 - progress_bar.py[line:272] - INFO: epoch 017:    747 / 1732 loss=2.201, loss_v1=0, loss_v2=0, nll_loss=0.981, ntokens=980.5, nsentences=32, sample_size=980.5, sample_size_v1=0, sample_size_v2=0, ppl=1.97, wps=527.5, ups=0.54, wpb=980.5, bsz=32, num_updates=28410, lr=1.44647e-05, gnorm=9.085, clip=100, loss_scale=64, train_wall=19, gb_free=11.3, wall=53393
2023-05-26 14:13:17 - progress_bar.py[line:272] - INFO: epoch 017:    757 / 1732 loss=2.199, loss_v1=0, loss_v2=0, nll_loss=0.978, ntokens=949.2, nsentences=32, sample_size=949.2, sample_size_v1=0, sample_size_v2=0, ppl=1.97, wps=514.1, ups=0.54, wpb=949.2, bsz=32, num_updates=28420, lr=1.44586e-05, gnorm=8.96, clip=100, loss_scale=64, train_wall=18, gb_free=11.6, wall=53412
2023-05-26 14:13:35 - progress_bar.py[line:272] - INFO: epoch 017:    767 / 1732 loss=2.207, loss_v1=0, loss_v2=0, nll_loss=0.987, ntokens=941.7, nsentences=32, sample_size=941.7, sample_size_v1=0, sample_size_v2=0, ppl=1.98, wps=509.7, ups=0.54, wpb=941.7, bsz=32, num_updates=28430, lr=1.44524e-05, gnorm=9.515, clip=100, loss_scale=64, train_wall=18, gb_free=11.9, wall=53430
2023-05-26 14:13:54 - progress_bar.py[line:272] - INFO: epoch 017:    777 / 1732 loss=2.205, loss_v1=0, loss_v2=0, nll_loss=0.986, ntokens=1028.6, nsentences=32, sample_size=1028.6, sample_size_v1=0, sample_size_v2=0, ppl=1.98, wps=553.9, ups=0.54, wpb=1028.6, bsz=32, num_updates=28440, lr=1.44463e-05, gnorm=8.522, clip=100, loss_scale=64, train_wall=19, gb_free=11.8, wall=53449
2023-05-26 14:14:13 - progress_bar.py[line:272] - INFO: epoch 017:    787 / 1732 loss=2.224, loss_v1=0, loss_v2=0, nll_loss=1.007, ntokens=1016.6, nsentences=32, sample_size=1016.6, sample_size_v1=0, sample_size_v2=0, ppl=2.01, wps=550, ups=0.54, wpb=1016.6, bsz=32, num_updates=28450, lr=1.44401e-05, gnorm=9.062, clip=100, loss_scale=64, train_wall=18, gb_free=11.3, wall=53467
2023-05-26 14:14:31 - progress_bar.py[line:272] - INFO: epoch 017:    797 / 1732 loss=2.225, loss_v1=0, loss_v2=0, nll_loss=1.007, ntokens=1038, nsentences=32, sample_size=1038, sample_size_v1=0, sample_size_v2=0, ppl=2.01, wps=559.7, ups=0.54, wpb=1038, bsz=32, num_updates=28460, lr=1.4434e-05, gnorm=8.957, clip=100, loss_scale=64, train_wall=19, gb_free=11.6, wall=53486
2023-05-26 14:14:50 - progress_bar.py[line:272] - INFO: epoch 017:    807 / 1732 loss=2.209, loss_v1=0, loss_v2=0, nll_loss=0.988, ntokens=915, nsentences=32, sample_size=915, sample_size_v1=0, sample_size_v2=0, ppl=1.98, wps=496.2, ups=0.54, wpb=915, bsz=32, num_updates=28470, lr=1.44279e-05, gnorm=10.135, clip=100, loss_scale=64, train_wall=18, gb_free=11.4, wall=53504
2023-05-26 14:15:08 - progress_bar.py[line:272] - INFO: epoch 017:    817 / 1732 loss=2.223, loss_v1=0, loss_v2=0, nll_loss=1.006, ntokens=917.4, nsentences=32, sample_size=917.4, sample_size_v1=0, sample_size_v2=0, ppl=2.01, wps=496.9, ups=0.54, wpb=917.4, bsz=32, num_updates=28480, lr=1.44217e-05, gnorm=10.031, clip=100, loss_scale=64, train_wall=18, gb_free=11.7, wall=53523
2023-05-26 14:15:26 - progress_bar.py[line:272] - INFO: epoch 017:    827 / 1732 loss=2.212, loss_v1=0, loss_v2=0, nll_loss=0.993, ntokens=930.6, nsentences=32, sample_size=930.6, sample_size_v1=0, sample_size_v2=0, ppl=1.99, wps=503.3, ups=0.54, wpb=930.6, bsz=32, num_updates=28490, lr=1.44156e-05, gnorm=9.213, clip=100, loss_scale=64, train_wall=18, gb_free=11.7, wall=53541
2023-05-26 14:15:45 - progress_bar.py[line:272] - INFO: epoch 017:    837 / 1732 loss=2.219, loss_v1=0, loss_v2=0, nll_loss=1.001, ntokens=894.5, nsentences=32, sample_size=894.5, sample_size_v1=0, sample_size_v2=0, ppl=2, wps=487.6, ups=0.55, wpb=894.5, bsz=32, num_updates=28500, lr=1.44094e-05, gnorm=10.149, clip=100, loss_scale=64, train_wall=18, gb_free=11.7, wall=53560
2023-05-26 14:16:03 - progress_bar.py[line:272] - INFO: epoch 017:    847 / 1732 loss=2.204, loss_v1=0, loss_v2=0, nll_loss=0.984, ntokens=1012.6, nsentences=32, sample_size=1012.6, sample_size_v1=0, sample_size_v2=0, ppl=1.98, wps=547.6, ups=0.54, wpb=1012.6, bsz=32, num_updates=28510, lr=1.44033e-05, gnorm=9.039, clip=100, loss_scale=64, train_wall=18, gb_free=10.6, wall=53578
2023-05-26 14:16:22 - progress_bar.py[line:272] - INFO: epoch 017:    857 / 1732 loss=2.211, loss_v1=0, loss_v2=0, nll_loss=0.993, ntokens=920, nsentences=32, sample_size=920, sample_size_v1=0, sample_size_v2=0, ppl=1.99, wps=499.9, ups=0.54, wpb=920, bsz=32, num_updates=28520, lr=1.43972e-05, gnorm=9.966, clip=100, loss_scale=64, train_wall=18, gb_free=11.7, wall=53596
2023-05-26 14:16:40 - progress_bar.py[line:272] - INFO: epoch 017:    867 / 1732 loss=2.222, loss_v1=0, loss_v2=0, nll_loss=1.006, ntokens=979.9, nsentences=32, sample_size=979.9, sample_size_v1=0, sample_size_v2=0, ppl=2.01, wps=529.7, ups=0.54, wpb=979.9, bsz=32, num_updates=28530, lr=1.4391e-05, gnorm=9.289, clip=100, loss_scale=64, train_wall=18, gb_free=11.3, wall=53615
2023-05-26 14:16:59 - progress_bar.py[line:272] - INFO: epoch 017:    877 / 1732 loss=2.158, loss_v1=0, loss_v2=0, nll_loss=0.933, ntokens=994.5, nsentences=32, sample_size=994.5, sample_size_v1=0, sample_size_v2=0, ppl=1.91, wps=534.5, ups=0.54, wpb=994.5, bsz=32, num_updates=28540, lr=1.43849e-05, gnorm=8.312, clip=100, loss_scale=64, train_wall=19, gb_free=11.7, wall=53634
2023-05-26 14:17:17 - progress_bar.py[line:272] - INFO: epoch 017:    887 / 1732 loss=2.17, loss_v1=0, loss_v2=0, nll_loss=0.947, ntokens=982, nsentences=32, sample_size=982, sample_size_v1=0, sample_size_v2=0, ppl=1.93, wps=527.7, ups=0.54, wpb=982, bsz=32, num_updates=28550, lr=1.43787e-05, gnorm=8.954, clip=100, loss_scale=64, train_wall=19, gb_free=11.2, wall=53652
2023-05-26 14:17:36 - progress_bar.py[line:272] - INFO: epoch 017:    897 / 1732 loss=2.159, loss_v1=0, loss_v2=0, nll_loss=0.934, ntokens=1034.6, nsentences=32, sample_size=1034.6, sample_size_v1=0, sample_size_v2=0, ppl=1.91, wps=557.5, ups=0.54, wpb=1034.6, bsz=32, num_updates=28560, lr=1.43726e-05, gnorm=8.364, clip=100, loss_scale=64, train_wall=19, gb_free=11.5, wall=53671
2023-05-26 14:17:55 - progress_bar.py[line:272] - INFO: epoch 017:    907 / 1732 loss=2.167, loss_v1=0, loss_v2=0, nll_loss=0.942, ntokens=1016.8, nsentences=32, sample_size=1016.8, sample_size_v1=0, sample_size_v2=0, ppl=1.92, wps=547.9, ups=0.54, wpb=1016.8, bsz=32, num_updates=28570, lr=1.43664e-05, gnorm=9.011, clip=100, loss_scale=64, train_wall=19, gb_free=11.6, wall=53689
2023-05-26 14:18:13 - progress_bar.py[line:272] - INFO: epoch 017:    917 / 1732 loss=2.246, loss_v1=0, loss_v2=0, nll_loss=1.031, ntokens=936.4, nsentences=32, sample_size=936.4, sample_size_v1=0, sample_size_v2=0, ppl=2.04, wps=506.4, ups=0.54, wpb=936.4, bsz=32, num_updates=28580, lr=1.43603e-05, gnorm=9.755, clip=100, loss_scale=64, train_wall=18, gb_free=11.8, wall=53708
2023-05-26 14:18:32 - progress_bar.py[line:272] - INFO: epoch 017:    927 / 1732 loss=2.181, loss_v1=0, loss_v2=0, nll_loss=0.959, ntokens=1039.7, nsentences=32, sample_size=1039.7, sample_size_v1=0, sample_size_v2=0, ppl=1.94, wps=556.7, ups=0.54, wpb=1039.7, bsz=32, num_updates=28590, lr=1.43542e-05, gnorm=8.764, clip=100, loss_scale=64, train_wall=19, gb_free=11.5, wall=53726
2023-05-26 14:18:51 - progress_bar.py[line:272] - INFO: epoch 017:    937 / 1732 loss=2.199, loss_v1=0, loss_v2=0, nll_loss=0.98, ntokens=1061.1, nsentences=32, sample_size=1061.1, sample_size_v1=0, sample_size_v2=0, ppl=1.97, wps=564.2, ups=0.53, wpb=1061.1, bsz=32, num_updates=28600, lr=1.4348e-05, gnorm=9.24, clip=100, loss_scale=64, train_wall=19, gb_free=11.5, wall=53745
2023-05-26 14:19:09 - progress_bar.py[line:272] - INFO: epoch 017:    947 / 1732 loss=2.214, loss_v1=0, loss_v2=0, nll_loss=0.996, ntokens=1042.4, nsentences=32, sample_size=1042.4, sample_size_v1=0, sample_size_v2=0, ppl=1.99, wps=553.2, ups=0.53, wpb=1042.4, bsz=32, num_updates=28610, lr=1.43419e-05, gnorm=9.416, clip=100, loss_scale=64, train_wall=19, gb_free=11.2, wall=53764
2023-05-26 14:19:21 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2023-05-26 14:19:30 - progress_bar.py[line:272] - INFO: epoch 017:    958 / 1732 loss=2.189, loss_v1=0, loss_v2=0, nll_loss=0.964, ntokens=1041.2, nsentences=32, sample_size=1041.2, sample_size_v1=0, sample_size_v2=0, ppl=1.95, wps=506.9, ups=0.49, wpb=1041.2, bsz=32, num_updates=28620, lr=1.43357e-05, gnorm=9.007, clip=100, loss_scale=64, train_wall=21, gb_free=11.3, wall=53785
2023-05-26 14:19:49 - progress_bar.py[line:272] - INFO: epoch 017:    968 / 1732 loss=2.227, loss_v1=0, loss_v2=0, nll_loss=1.01, ntokens=1015.7, nsentences=32, sample_size=1015.7, sample_size_v1=0, sample_size_v2=0, ppl=2.01, wps=543.5, ups=0.54, wpb=1015.7, bsz=32, num_updates=28630, lr=1.43296e-05, gnorm=9.594, clip=100, loss_scale=64, train_wall=19, gb_free=11.6, wall=53803
2023-05-26 14:20:08 - progress_bar.py[line:272] - INFO: epoch 017:    978 / 1732 loss=2.194, loss_v1=0, loss_v2=0, nll_loss=0.973, ntokens=1036.8, nsentences=32, sample_size=1036.8, sample_size_v1=0, sample_size_v2=0, ppl=1.96, wps=548.4, ups=0.53, wpb=1036.8, bsz=32, num_updates=28640, lr=1.43234e-05, gnorm=8.596, clip=100, loss_scale=64, train_wall=19, gb_free=11.5, wall=53822
2023-05-26 14:20:26 - progress_bar.py[line:272] - INFO: epoch 017:    988 / 1732 loss=2.195, loss_v1=0, loss_v2=0, nll_loss=0.974, ntokens=1050.5, nsentences=32, sample_size=1050.5, sample_size_v1=0, sample_size_v2=0, ppl=1.96, wps=555.7, ups=0.53, wpb=1050.5, bsz=32, num_updates=28650, lr=1.43173e-05, gnorm=8.443, clip=100, loss_scale=64, train_wall=19, gb_free=10.7, wall=53841
2023-05-26 14:20:45 - progress_bar.py[line:272] - INFO: epoch 017:    998 / 1732 loss=2.206, loss_v1=0, loss_v2=0, nll_loss=0.985, ntokens=1000, nsentences=32, sample_size=1000, sample_size_v1=0, sample_size_v2=0, ppl=1.98, wps=535.6, ups=0.54, wpb=1000, bsz=32, num_updates=28660, lr=1.43112e-05, gnorm=9.77, clip=100, loss_scale=64, train_wall=19, gb_free=10.8, wall=53860
2023-05-26 14:21:04 - progress_bar.py[line:272] - INFO: epoch 017:   1008 / 1732 loss=2.205, loss_v1=0, loss_v2=0, nll_loss=0.984, ntokens=1026.8, nsentences=32, sample_size=1026.8, sample_size_v1=0, sample_size_v2=0, ppl=1.98, wps=548.1, ups=0.53, wpb=1026.8, bsz=32, num_updates=28670, lr=1.4305e-05, gnorm=9.859, clip=100, loss_scale=64, train_wall=19, gb_free=10.4, wall=53879
2023-05-26 14:21:23 - progress_bar.py[line:272] - INFO: epoch 017:   1018 / 1732 loss=2.178, loss_v1=0, loss_v2=0, nll_loss=0.954, ntokens=1036.8, nsentences=32, sample_size=1036.8, sample_size_v1=0, sample_size_v2=0, ppl=1.94, wps=555.7, ups=0.54, wpb=1036.8, bsz=32, num_updates=28680, lr=1.42989e-05, gnorm=8.67, clip=100, loss_scale=64, train_wall=19, gb_free=11.3, wall=53897
2023-05-26 14:21:41 - progress_bar.py[line:272] - INFO: epoch 017:   1028 / 1732 loss=2.212, loss_v1=0, loss_v2=0, nll_loss=0.992, ntokens=1060.8, nsentences=32, sample_size=1060.8, sample_size_v1=0, sample_size_v2=0, ppl=1.99, wps=561.7, ups=0.53, wpb=1060.8, bsz=32, num_updates=28690, lr=1.42927e-05, gnorm=9.177, clip=100, loss_scale=64, train_wall=19, gb_free=10.3, wall=53916
2023-05-26 14:22:00 - progress_bar.py[line:272] - INFO: epoch 017:   1038 / 1732 loss=2.203, loss_v1=0, loss_v2=0, nll_loss=0.983, ntokens=1110, nsentences=32, sample_size=1110, sample_size_v1=0, sample_size_v2=0, ppl=1.98, wps=588.8, ups=0.53, wpb=1110, bsz=32, num_updates=28700, lr=1.42866e-05, gnorm=8.643, clip=100, loss_scale=64, train_wall=19, gb_free=11.7, wall=53935
2023-05-26 14:22:19 - progress_bar.py[line:272] - INFO: epoch 017:   1048 / 1732 loss=2.188, loss_v1=0, loss_v2=0, nll_loss=0.965, ntokens=1025.8, nsentences=32, sample_size=1025.8, sample_size_v1=0, sample_size_v2=0, ppl=1.95, wps=546.9, ups=0.53, wpb=1025.8, bsz=32, num_updates=28710, lr=1.42804e-05, gnorm=9.214, clip=100, loss_scale=64, train_wall=19, gb_free=11.4, wall=53954
2023-05-26 14:22:38 - progress_bar.py[line:272] - INFO: epoch 017:   1058 / 1732 loss=2.201, loss_v1=0, loss_v2=0, nll_loss=0.982, ntokens=1082.8, nsentences=32, sample_size=1082.8, sample_size_v1=0, sample_size_v2=0, ppl=1.97, wps=576.6, ups=0.53, wpb=1082.8, bsz=32, num_updates=28720, lr=1.42743e-05, gnorm=8.58, clip=100, loss_scale=64, train_wall=19, gb_free=11.8, wall=53973
2023-05-26 14:22:57 - progress_bar.py[line:272] - INFO: epoch 017:   1068 / 1732 loss=2.194, loss_v1=0, loss_v2=0, nll_loss=0.973, ntokens=1002.9, nsentences=32, sample_size=1002.9, sample_size_v1=0, sample_size_v2=0, ppl=1.96, wps=537.1, ups=0.54, wpb=1002.9, bsz=32, num_updates=28730, lr=1.42682e-05, gnorm=9.212, clip=100, loss_scale=64, train_wall=19, gb_free=11.7, wall=53991
2023-05-26 14:23:15 - progress_bar.py[line:272] - INFO: epoch 017:   1078 / 1732 loss=2.213, loss_v1=0, loss_v2=0, nll_loss=0.994, ntokens=1000.2, nsentences=32, sample_size=1000.2, sample_size_v1=0, sample_size_v2=0, ppl=1.99, wps=531.2, ups=0.53, wpb=1000.2, bsz=32, num_updates=28740, lr=1.4262e-05, gnorm=9.949, clip=100, loss_scale=64, train_wall=19, gb_free=11.5, wall=54010
2023-05-26 14:23:34 - progress_bar.py[line:272] - INFO: epoch 017:   1088 / 1732 loss=2.192, loss_v1=0, loss_v2=0, nll_loss=0.97, ntokens=1078.6, nsentences=32, sample_size=1078.6, sample_size_v1=0, sample_size_v2=0, ppl=1.96, wps=570.4, ups=0.53, wpb=1078.6, bsz=32, num_updates=28750, lr=1.42559e-05, gnorm=9.314, clip=100, loss_scale=64, train_wall=19, gb_free=11.4, wall=54029
2023-05-26 14:23:53 - progress_bar.py[line:272] - INFO: epoch 017:   1098 / 1732 loss=2.213, loss_v1=0, loss_v2=0, nll_loss=0.994, ntokens=1045.6, nsentences=32, sample_size=1045.6, sample_size_v1=0, sample_size_v2=0, ppl=1.99, wps=557.4, ups=0.53, wpb=1045.6, bsz=32, num_updates=28760, lr=1.42497e-05, gnorm=9.508, clip=100, loss_scale=64, train_wall=19, gb_free=10.8, wall=54048
2023-05-26 14:24:12 - progress_bar.py[line:272] - INFO: epoch 017:   1108 / 1732 loss=2.193, loss_v1=0, loss_v2=0, nll_loss=0.971, ntokens=1058.8, nsentences=32, sample_size=1058.8, sample_size_v1=0, sample_size_v2=0, ppl=1.96, wps=562.2, ups=0.53, wpb=1058.8, bsz=32, num_updates=28770, lr=1.42436e-05, gnorm=8.467, clip=100, loss_scale=64, train_wall=19, gb_free=11.6, wall=54067
2023-05-26 14:24:31 - progress_bar.py[line:272] - INFO: epoch 017:   1118 / 1732 loss=2.199, loss_v1=0, loss_v2=0, nll_loss=0.978, ntokens=944.7, nsentences=32, sample_size=944.7, sample_size_v1=0, sample_size_v2=0, ppl=1.97, wps=504.5, ups=0.53, wpb=944.7, bsz=32, num_updates=28780, lr=1.42375e-05, gnorm=9.972, clip=100, loss_scale=64, train_wall=19, gb_free=11.2, wall=54085
2023-05-26 14:24:49 - progress_bar.py[line:272] - INFO: epoch 017:   1128 / 1732 loss=2.195, loss_v1=0, loss_v2=0, nll_loss=0.974, ntokens=1025.9, nsentences=32, sample_size=1025.9, sample_size_v1=0, sample_size_v2=0, ppl=1.96, wps=545.1, ups=0.53, wpb=1025.9, bsz=32, num_updates=28790, lr=1.42313e-05, gnorm=9.48, clip=100, loss_scale=64, train_wall=19, gb_free=10.7, wall=54104
2023-05-26 14:25:08 - progress_bar.py[line:272] - INFO: epoch 017:   1138 / 1732 loss=2.188, loss_v1=0, loss_v2=0, nll_loss=0.967, ntokens=989.2, nsentences=32, sample_size=989.2, sample_size_v1=0, sample_size_v2=0, ppl=1.95, wps=528.5, ups=0.53, wpb=989.2, bsz=32, num_updates=28800, lr=1.42252e-05, gnorm=9.568, clip=100, loss_scale=64, train_wall=19, gb_free=11.6, wall=54123
2023-05-26 14:25:27 - progress_bar.py[line:272] - INFO: epoch 017:   1148 / 1732 loss=2.196, loss_v1=0, loss_v2=0, nll_loss=0.974, ntokens=1007.7, nsentences=32, sample_size=1007.7, sample_size_v1=0, sample_size_v2=0, ppl=1.96, wps=538.6, ups=0.53, wpb=1007.7, bsz=32, num_updates=28810, lr=1.4219e-05, gnorm=9.535, clip=100, loss_scale=64, train_wall=19, gb_free=11.5, wall=54142
2023-05-26 14:25:46 - progress_bar.py[line:272] - INFO: epoch 017:   1158 / 1732 loss=2.17, loss_v1=0, loss_v2=0, nll_loss=0.947, ntokens=1016, nsentences=32, sample_size=1016, sample_size_v1=0, sample_size_v2=0, ppl=1.93, wps=540.8, ups=0.53, wpb=1016, bsz=32, num_updates=28820, lr=1.42129e-05, gnorm=9.562, clip=100, loss_scale=64, train_wall=19, gb_free=10.8, wall=54160
2023-05-26 14:26:04 - progress_bar.py[line:272] - INFO: epoch 017:   1168 / 1732 loss=2.182, loss_v1=0, loss_v2=0, nll_loss=0.96, ntokens=1020.6, nsentences=32, sample_size=1020.6, sample_size_v1=0, sample_size_v2=0, ppl=1.95, wps=543, ups=0.53, wpb=1020.6, bsz=32, num_updates=28830, lr=1.42067e-05, gnorm=8.622, clip=100, loss_scale=64, train_wall=19, gb_free=10.9, wall=54179
2023-05-26 14:26:23 - progress_bar.py[line:272] - INFO: epoch 017:   1178 / 1732 loss=2.168, loss_v1=0, loss_v2=0, nll_loss=0.943, ntokens=1067, nsentences=32, sample_size=1067, sample_size_v1=0, sample_size_v2=0, ppl=1.92, wps=568.2, ups=0.53, wpb=1067, bsz=32, num_updates=28840, lr=1.42006e-05, gnorm=8.764, clip=100, loss_scale=64, train_wall=19, gb_free=11.6, wall=54198
2023-05-26 14:26:42 - progress_bar.py[line:272] - INFO: epoch 017:   1188 / 1732 loss=2.18, loss_v1=0, loss_v2=0, nll_loss=0.957, ntokens=963.5, nsentences=32, sample_size=963.5, sample_size_v1=0, sample_size_v2=0, ppl=1.94, wps=515.4, ups=0.53, wpb=963.5, bsz=32, num_updates=28850, lr=1.41945e-05, gnorm=8.89, clip=100, loss_scale=64, train_wall=19, gb_free=11.1, wall=54217
2023-05-26 14:27:01 - progress_bar.py[line:272] - INFO: epoch 017:   1198 / 1732 loss=2.186, loss_v1=0, loss_v2=0, nll_loss=0.963, ntokens=1123.7, nsentences=32, sample_size=1123.7, sample_size_v1=0, sample_size_v2=0, ppl=1.95, wps=594.8, ups=0.53, wpb=1123.7, bsz=32, num_updates=28860, lr=1.41883e-05, gnorm=9.042, clip=100, loss_scale=64, train_wall=19, gb_free=11.2, wall=54235
2023-05-26 14:27:20 - progress_bar.py[line:272] - INFO: epoch 017:   1208 / 1732 loss=2.166, loss_v1=0, loss_v2=0, nll_loss=0.942, ntokens=1088.9, nsentences=32, sample_size=1088.9, sample_size_v1=0, sample_size_v2=0, ppl=1.92, wps=574.5, ups=0.53, wpb=1088.9, bsz=32, num_updates=28870, lr=1.41822e-05, gnorm=8.767, clip=100, loss_scale=64, train_wall=19, gb_free=10.6, wall=54254
2023-05-26 14:27:38 - progress_bar.py[line:272] - INFO: epoch 017:   1218 / 1732 loss=2.208, loss_v1=0, loss_v2=0, nll_loss=0.989, ntokens=1016, nsentences=32, sample_size=1016, sample_size_v1=0, sample_size_v2=0, ppl=1.98, wps=543, ups=0.53, wpb=1016, bsz=32, num_updates=28880, lr=1.4176e-05, gnorm=9.594, clip=100, loss_scale=64, train_wall=19, gb_free=11.6, wall=54273
2023-05-26 14:27:57 - progress_bar.py[line:272] - INFO: epoch 017:   1228 / 1732 loss=2.194, loss_v1=0, loss_v2=0, nll_loss=0.973, ntokens=1018.6, nsentences=32, sample_size=1018.6, sample_size_v1=0, sample_size_v2=0, ppl=1.96, wps=542.5, ups=0.53, wpb=1018.6, bsz=32, num_updates=28890, lr=1.41699e-05, gnorm=9.963, clip=100, loss_scale=64, train_wall=19, gb_free=11.5, wall=54292
2023-05-26 14:28:16 - progress_bar.py[line:272] - INFO: epoch 017:   1238 / 1732 loss=2.162, loss_v1=0, loss_v2=0, nll_loss=0.937, ntokens=1070.1, nsentences=32, sample_size=1070.1, sample_size_v1=0, sample_size_v2=0, ppl=1.91, wps=568.6, ups=0.53, wpb=1070.1, bsz=32, num_updates=28900, lr=1.41637e-05, gnorm=8.764, clip=100, loss_scale=64, train_wall=19, gb_free=11.2, wall=54311
2023-05-26 14:28:35 - progress_bar.py[line:272] - INFO: epoch 017:   1248 / 1732 loss=2.147, loss_v1=0, loss_v2=0, nll_loss=0.92, ntokens=1083.3, nsentences=32, sample_size=1083.3, sample_size_v1=0, sample_size_v2=0, ppl=1.89, wps=575.6, ups=0.53, wpb=1083.3, bsz=32, num_updates=28910, lr=1.41576e-05, gnorm=8.4, clip=100, loss_scale=64, train_wall=19, gb_free=11.3, wall=54330
2023-05-26 14:28:54 - progress_bar.py[line:272] - INFO: epoch 017:   1258 / 1732 loss=2.162, loss_v1=0, loss_v2=0, nll_loss=0.937, ntokens=1058.8, nsentences=32, sample_size=1058.8, sample_size_v1=0, sample_size_v2=0, ppl=1.91, wps=563.4, ups=0.53, wpb=1058.8, bsz=32, num_updates=28920, lr=1.41515e-05, gnorm=9.534, clip=100, loss_scale=64, train_wall=19, gb_free=11.1, wall=54348
2023-05-26 14:29:12 - progress_bar.py[line:272] - INFO: epoch 017:   1268 / 1732 loss=2.187, loss_v1=0, loss_v2=0, nll_loss=0.967, ntokens=1040.1, nsentences=32, sample_size=1040.1, sample_size_v1=0, sample_size_v2=0, ppl=1.95, wps=554.2, ups=0.53, wpb=1040.1, bsz=32, num_updates=28930, lr=1.41453e-05, gnorm=9.205, clip=100, loss_scale=64, train_wall=19, gb_free=11.4, wall=54367
2023-05-26 14:29:31 - progress_bar.py[line:272] - INFO: epoch 017:   1278 / 1732 loss=2.195, loss_v1=0, loss_v2=0, nll_loss=0.973, ntokens=1064.5, nsentences=32, sample_size=1064.5, sample_size_v1=0, sample_size_v2=0, ppl=1.96, wps=563.8, ups=0.53, wpb=1064.5, bsz=32, num_updates=28940, lr=1.41392e-05, gnorm=8.412, clip=100, loss_scale=64, train_wall=19, gb_free=11.4, wall=54386
2023-05-26 14:29:50 - progress_bar.py[line:272] - INFO: epoch 017:   1288 / 1732 loss=2.169, loss_v1=0, loss_v2=0, nll_loss=0.944, ntokens=1074.2, nsentences=32, sample_size=1074.2, sample_size_v1=0, sample_size_v2=0, ppl=1.92, wps=569.8, ups=0.53, wpb=1074.2, bsz=32, num_updates=28950, lr=1.4133e-05, gnorm=8.512, clip=100, loss_scale=64, train_wall=19, gb_free=10, wall=54405
2023-05-26 14:30:09 - progress_bar.py[line:272] - INFO: epoch 017:   1298 / 1732 loss=2.177, loss_v1=0, loss_v2=0, nll_loss=0.954, ntokens=1104.5, nsentences=32, sample_size=1104.5, sample_size_v1=0, sample_size_v2=0, ppl=1.94, wps=584.8, ups=0.53, wpb=1104.5, bsz=32, num_updates=28960, lr=1.41269e-05, gnorm=8.663, clip=100, loss_scale=64, train_wall=19, gb_free=11.1, wall=54424
2023-05-26 14:30:28 - progress_bar.py[line:272] - INFO: epoch 017:   1308 / 1732 loss=2.216, loss_v1=0, loss_v2=0, nll_loss=0.998, ntokens=1079.8, nsentences=32, sample_size=1079.8, sample_size_v1=0, sample_size_v2=0, ppl=2, wps=568.4, ups=0.53, wpb=1079.8, bsz=32, num_updates=28970, lr=1.41208e-05, gnorm=9.134, clip=100, loss_scale=64, train_wall=19, gb_free=10.5, wall=54443
2023-05-26 14:30:47 - progress_bar.py[line:272] - INFO: epoch 017:   1318 / 1732 loss=2.188, loss_v1=0, loss_v2=0, nll_loss=0.967, ntokens=1085.2, nsentences=32, sample_size=1085.2, sample_size_v1=0, sample_size_v2=0, ppl=1.96, wps=574.2, ups=0.53, wpb=1085.2, bsz=32, num_updates=28980, lr=1.41146e-05, gnorm=8.942, clip=100, loss_scale=64, train_wall=19, gb_free=10.9, wall=54462
2023-05-26 14:31:06 - progress_bar.py[line:272] - INFO: epoch 017:   1328 / 1732 loss=2.153, loss_v1=0, loss_v2=0, nll_loss=0.928, ntokens=1103.2, nsentences=32, sample_size=1103.2, sample_size_v1=0, sample_size_v2=0, ppl=1.9, wps=581.6, ups=0.53, wpb=1103.2, bsz=32, num_updates=28990, lr=1.41085e-05, gnorm=8.809, clip=100, loss_scale=64, train_wall=19, gb_free=11, wall=54481
2023-05-26 14:31:25 - progress_bar.py[line:272] - INFO: epoch 017:   1338 / 1732 loss=2.174, loss_v1=0, loss_v2=0, nll_loss=0.95, ntokens=1116.2, nsentences=32, sample_size=1116.2, sample_size_v1=0, sample_size_v2=0, ppl=1.93, wps=592.5, ups=0.53, wpb=1116.2, bsz=32, num_updates=29000, lr=1.41023e-05, gnorm=8.916, clip=100, loss_scale=64, train_wall=19, gb_free=10.6, wall=54499
2023-05-26 14:31:44 - progress_bar.py[line:272] - INFO: epoch 017:   1348 / 1732 loss=2.175, loss_v1=0, loss_v2=0, nll_loss=0.952, ntokens=1187.2, nsentences=32, sample_size=1187.2, sample_size_v1=0, sample_size_v2=0, ppl=1.93, wps=624.7, ups=0.53, wpb=1187.2, bsz=32, num_updates=29010, lr=1.40962e-05, gnorm=8.114, clip=100, loss_scale=64, train_wall=19, gb_free=10.7, wall=54518
2023-05-26 14:32:03 - progress_bar.py[line:272] - INFO: epoch 017:   1358 / 1732 loss=2.156, loss_v1=0, loss_v2=0, nll_loss=0.931, ntokens=1099, nsentences=32, sample_size=1099, sample_size_v1=0, sample_size_v2=0, ppl=1.91, wps=581.8, ups=0.53, wpb=1099, bsz=32, num_updates=29020, lr=1.409e-05, gnorm=8.722, clip=100, loss_scale=64, train_wall=19, gb_free=11.3, wall=54537
2023-05-26 14:32:22 - progress_bar.py[line:272] - INFO: epoch 017:   1368 / 1732 loss=2.189, loss_v1=0, loss_v2=0, nll_loss=0.966, ntokens=1106.4, nsentences=32, sample_size=1106.4, sample_size_v1=0, sample_size_v2=0, ppl=1.95, wps=584.8, ups=0.53, wpb=1106.4, bsz=32, num_updates=29030, lr=1.40839e-05, gnorm=9.601, clip=100, loss_scale=64, train_wall=19, gb_free=11.3, wall=54556
2023-05-26 14:32:40 - progress_bar.py[line:272] - INFO: epoch 017:   1378 / 1732 loss=2.197, loss_v1=0, loss_v2=0, nll_loss=0.976, ntokens=1104.2, nsentences=32, sample_size=1104.2, sample_size_v1=0, sample_size_v2=0, ppl=1.97, wps=587.6, ups=0.53, wpb=1104.2, bsz=32, num_updates=29040, lr=1.40778e-05, gnorm=9.191, clip=100, loss_scale=64, train_wall=19, gb_free=11.3, wall=54575
2023-05-26 14:32:59 - progress_bar.py[line:272] - INFO: epoch 017:   1388 / 1732 loss=2.186, loss_v1=0, loss_v2=0, nll_loss=0.963, ntokens=1131.9, nsentences=32, sample_size=1131.9, sample_size_v1=0, sample_size_v2=0, ppl=1.95, wps=603.3, ups=0.53, wpb=1131.9, bsz=32, num_updates=29050, lr=1.40716e-05, gnorm=8.553, clip=100, loss_scale=64, train_wall=19, gb_free=11.5, wall=54594
2023-05-26 14:33:18 - progress_bar.py[line:272] - INFO: epoch 017:   1398 / 1732 loss=2.17, loss_v1=0, loss_v2=0, nll_loss=0.947, ntokens=1097.3, nsentences=32, sample_size=1097.3, sample_size_v1=0, sample_size_v2=0, ppl=1.93, wps=581.8, ups=0.53, wpb=1097.3, bsz=32, num_updates=29060, lr=1.40655e-05, gnorm=8.797, clip=100, loss_scale=64, train_wall=19, gb_free=11.3, wall=54613
2023-05-26 14:33:37 - progress_bar.py[line:272] - INFO: epoch 017:   1408 / 1732 loss=2.197, loss_v1=0, loss_v2=0, nll_loss=0.976, ntokens=1161.5, nsentences=32, sample_size=1161.5, sample_size_v1=0, sample_size_v2=0, ppl=1.97, wps=614.7, ups=0.53, wpb=1161.5, bsz=32, num_updates=29070, lr=1.40593e-05, gnorm=9.194, clip=100, loss_scale=64, train_wall=19, gb_free=11.3, wall=54632
2023-05-26 14:33:56 - progress_bar.py[line:272] - INFO: epoch 017:   1418 / 1732 loss=2.209, loss_v1=0, loss_v2=0, nll_loss=0.99, ntokens=1285.2, nsentences=32, sample_size=1285.2, sample_size_v1=0, sample_size_v2=0, ppl=1.99, wps=674.5, ups=0.52, wpb=1285.2, bsz=32, num_updates=29080, lr=1.40532e-05, gnorm=9.165, clip=100, loss_scale=64, train_wall=19, gb_free=10.7, wall=54651
2023-05-26 14:34:15 - progress_bar.py[line:272] - INFO: epoch 017:   1428 / 1732 loss=2.172, loss_v1=0, loss_v2=0, nll_loss=0.947, ntokens=1229.6, nsentences=32, sample_size=1229.6, sample_size_v1=0, sample_size_v2=0, ppl=1.93, wps=646.1, ups=0.53, wpb=1229.6, bsz=32, num_updates=29090, lr=1.4047e-05, gnorm=9.121, clip=100, loss_scale=64, train_wall=19, gb_free=11.4, wall=54670
2023-05-26 14:34:34 - progress_bar.py[line:272] - INFO: epoch 017:   1438 / 1732 loss=2.178, loss_v1=0, loss_v2=0, nll_loss=0.956, ntokens=1179.5, nsentences=32, sample_size=1179.5, sample_size_v1=0, sample_size_v2=0, ppl=1.94, wps=621.9, ups=0.53, wpb=1179.5, bsz=32, num_updates=29100, lr=1.40409e-05, gnorm=8.124, clip=100, loss_scale=64, train_wall=19, gb_free=11.6, wall=54689
2023-05-26 14:34:53 - progress_bar.py[line:272] - INFO: epoch 017:   1448 / 1732 loss=2.179, loss_v1=0, loss_v2=0, nll_loss=0.957, ntokens=1120.7, nsentences=32, sample_size=1120.7, sample_size_v1=0, sample_size_v2=0, ppl=1.94, wps=595.4, ups=0.53, wpb=1120.7, bsz=32, num_updates=29110, lr=1.40348e-05, gnorm=8.723, clip=100, loss_scale=64, train_wall=19, gb_free=11.4, wall=54708
2023-05-26 14:35:12 - progress_bar.py[line:272] - INFO: epoch 017:   1458 / 1732 loss=2.177, loss_v1=0, loss_v2=0, nll_loss=0.954, ntokens=1151.7, nsentences=32, sample_size=1151.7, sample_size_v1=0, sample_size_v2=0, ppl=1.94, wps=608.4, ups=0.53, wpb=1151.7, bsz=32, num_updates=29120, lr=1.40286e-05, gnorm=9.055, clip=100, loss_scale=64, train_wall=19, gb_free=10.8, wall=54726
2023-05-26 14:35:29 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2023-05-26 14:35:33 - progress_bar.py[line:272] - INFO: epoch 017:   1469 / 1732 loss=2.168, loss_v1=0, loss_v2=0, nll_loss=0.943, ntokens=1171.1, nsentences=32, sample_size=1171.1, sample_size_v1=0, sample_size_v2=0, ppl=1.92, wps=563.8, ups=0.48, wpb=1171.1, bsz=32, num_updates=29130, lr=1.40225e-05, gnorm=8.435, clip=100, loss_scale=64, train_wall=21, gb_free=11.3, wall=54747
2023-05-26 14:35:51 - progress_bar.py[line:272] - INFO: epoch 017:   1479 / 1732 loss=2.196, loss_v1=0, loss_v2=0, nll_loss=0.976, ntokens=1029.5, nsentences=32, sample_size=1029.5, sample_size_v1=0, sample_size_v2=0, ppl=1.97, wps=546.5, ups=0.53, wpb=1029.5, bsz=32, num_updates=29140, lr=1.40163e-05, gnorm=10.448, clip=100, loss_scale=64, train_wall=19, gb_free=11.1, wall=54766
2023-05-26 14:36:10 - progress_bar.py[line:272] - INFO: epoch 017:   1489 / 1732 loss=2.192, loss_v1=0, loss_v2=0, nll_loss=0.971, ntokens=1147, nsentences=32, sample_size=1147, sample_size_v1=0, sample_size_v2=0, ppl=1.96, wps=605.3, ups=0.53, wpb=1147, bsz=32, num_updates=29150, lr=1.40102e-05, gnorm=9.074, clip=100, loss_scale=64, train_wall=19, gb_free=11.3, wall=54785
2023-05-26 14:36:29 - progress_bar.py[line:272] - INFO: epoch 017:   1499 / 1732 loss=2.169, loss_v1=0, loss_v2=0, nll_loss=0.943, ntokens=1095.4, nsentences=32, sample_size=1095.4, sample_size_v1=0, sample_size_v2=0, ppl=1.92, wps=582.9, ups=0.53, wpb=1095.4, bsz=32, num_updates=29160, lr=1.40041e-05, gnorm=9.016, clip=100, loss_scale=64, train_wall=19, gb_free=10.8, wall=54804
2023-05-26 14:36:48 - progress_bar.py[line:272] - INFO: epoch 017:   1509 / 1732 loss=2.145, loss_v1=0, loss_v2=0, nll_loss=0.918, ntokens=1114.3, nsentences=32, sample_size=1114.3, sample_size_v1=0, sample_size_v2=0, ppl=1.89, wps=592.7, ups=0.53, wpb=1114.3, bsz=32, num_updates=29170, lr=1.39979e-05, gnorm=9.509, clip=100, loss_scale=64, train_wall=19, gb_free=11.4, wall=54823
2023-05-26 14:37:07 - progress_bar.py[line:272] - INFO: epoch 017:   1519 / 1732 loss=2.206, loss_v1=0, loss_v2=0, nll_loss=0.986, ntokens=1050.9, nsentences=32, sample_size=1050.9, sample_size_v1=0, sample_size_v2=0, ppl=1.98, wps=559.8, ups=0.53, wpb=1050.9, bsz=32, num_updates=29180, lr=1.39918e-05, gnorm=9.727, clip=100, loss_scale=64, train_wall=19, gb_free=11.4, wall=54841
2023-05-26 14:37:26 - progress_bar.py[line:272] - INFO: epoch 017:   1529 / 1732 loss=2.21, loss_v1=0, loss_v2=0, nll_loss=0.991, ntokens=1056.3, nsentences=32, sample_size=1056.3, sample_size_v1=0, sample_size_v2=0, ppl=1.99, wps=562.8, ups=0.53, wpb=1056.3, bsz=32, num_updates=29190, lr=1.39856e-05, gnorm=10.479, clip=100, loss_scale=64, train_wall=19, gb_free=10.8, wall=54860
2023-05-26 14:37:44 - progress_bar.py[line:272] - INFO: epoch 017:   1539 / 1732 loss=2.184, loss_v1=0, loss_v2=0, nll_loss=0.962, ntokens=1083.3, nsentences=32, sample_size=1083.3, sample_size_v1=0, sample_size_v2=0, ppl=1.95, wps=571.2, ups=0.53, wpb=1083.3, bsz=32, num_updates=29200, lr=1.39795e-05, gnorm=9.232, clip=100, loss_scale=64, train_wall=19, gb_free=11, wall=54879
2023-05-26 14:38:03 - progress_bar.py[line:272] - INFO: epoch 017:   1549 / 1732 loss=2.151, loss_v1=0, loss_v2=0, nll_loss=0.925, ntokens=1075, nsentences=32, sample_size=1075, sample_size_v1=0, sample_size_v2=0, ppl=1.9, wps=571.5, ups=0.53, wpb=1075, bsz=32, num_updates=29210, lr=1.39733e-05, gnorm=9.215, clip=100, loss_scale=64, train_wall=19, gb_free=11.4, wall=54898
2023-05-26 14:38:22 - progress_bar.py[line:272] - INFO: epoch 017:   1559 / 1732 loss=2.157, loss_v1=0, loss_v2=0, nll_loss=0.934, ntokens=1092, nsentences=32, sample_size=1092, sample_size_v1=0, sample_size_v2=0, ppl=1.91, wps=580.5, ups=0.53, wpb=1092, bsz=32, num_updates=29220, lr=1.39672e-05, gnorm=9.179, clip=100, loss_scale=64, train_wall=19, gb_free=11.3, wall=54917
2023-05-26 14:38:41 - progress_bar.py[line:272] - INFO: epoch 017:   1569 / 1732 loss=2.204, loss_v1=0, loss_v2=0, nll_loss=0.984, ntokens=1059.1, nsentences=32, sample_size=1059.1, sample_size_v1=0, sample_size_v2=0, ppl=1.98, wps=561.1, ups=0.53, wpb=1059.1, bsz=32, num_updates=29230, lr=1.39611e-05, gnorm=9.231, clip=100, loss_scale=64, train_wall=19, gb_free=10.7, wall=54936
2023-05-26 14:39:00 - progress_bar.py[line:272] - INFO: epoch 017:   1579 / 1732 loss=2.187, loss_v1=0, loss_v2=0, nll_loss=0.965, ntokens=1008.7, nsentences=32, sample_size=1008.7, sample_size_v1=0, sample_size_v2=0, ppl=1.95, wps=537.7, ups=0.53, wpb=1008.7, bsz=32, num_updates=29240, lr=1.39549e-05, gnorm=10.035, clip=100, loss_scale=64, train_wall=19, gb_free=11.2, wall=54954
2023-05-26 14:39:19 - progress_bar.py[line:272] - INFO: epoch 017:   1589 / 1732 loss=2.187, loss_v1=0, loss_v2=0, nll_loss=0.965, ntokens=1092.2, nsentences=32, sample_size=1092.2, sample_size_v1=0, sample_size_v2=0, ppl=1.95, wps=577.8, ups=0.53, wpb=1092.2, bsz=32, num_updates=29250, lr=1.39488e-05, gnorm=9.238, clip=100, loss_scale=64, train_wall=19, gb_free=11.4, wall=54973
2023-05-26 14:39:37 - progress_bar.py[line:272] - INFO: epoch 017:   1599 / 1732 loss=2.156, loss_v1=0, loss_v2=0, nll_loss=0.93, ntokens=1061.1, nsentences=32, sample_size=1061.1, sample_size_v1=0, sample_size_v2=0, ppl=1.91, wps=563.8, ups=0.53, wpb=1061.1, bsz=32, num_updates=29260, lr=1.39426e-05, gnorm=9.448, clip=100, loss_scale=64, train_wall=19, gb_free=11.3, wall=54992
2023-05-26 14:39:56 - progress_bar.py[line:272] - INFO: epoch 017:   1609 / 1732 loss=2.154, loss_v1=0, loss_v2=0, nll_loss=0.929, ntokens=1155.5, nsentences=32, sample_size=1155.5, sample_size_v1=0, sample_size_v2=0, ppl=1.9, wps=608.6, ups=0.53, wpb=1155.5, bsz=32, num_updates=29270, lr=1.39365e-05, gnorm=9.256, clip=100, loss_scale=64, train_wall=19, gb_free=10.9, wall=55011
2023-05-26 14:40:15 - progress_bar.py[line:272] - INFO: epoch 017:   1619 / 1732 loss=2.144, loss_v1=0, loss_v2=0, nll_loss=0.917, ntokens=1123.8, nsentences=32, sample_size=1123.8, sample_size_v1=0, sample_size_v2=0, ppl=1.89, wps=593, ups=0.53, wpb=1123.8, bsz=32, num_updates=29280, lr=1.39303e-05, gnorm=8.748, clip=100, loss_scale=64, train_wall=19, gb_free=10.9, wall=55030
2023-05-26 14:40:34 - progress_bar.py[line:272] - INFO: epoch 017:   1629 / 1732 loss=2.178, loss_v1=0, loss_v2=0, nll_loss=0.954, ntokens=1172.3, nsentences=32, sample_size=1172.3, sample_size_v1=0, sample_size_v2=0, ppl=1.94, wps=615.3, ups=0.52, wpb=1172.3, bsz=32, num_updates=29290, lr=1.39242e-05, gnorm=9.326, clip=100, loss_scale=64, train_wall=19, gb_free=11.2, wall=55049
2023-05-26 14:40:53 - progress_bar.py[line:272] - INFO: epoch 017:   1639 / 1732 loss=2.153, loss_v1=0, loss_v2=0, nll_loss=0.927, ntokens=1139.8, nsentences=32, sample_size=1139.8, sample_size_v1=0, sample_size_v2=0, ppl=1.9, wps=607.7, ups=0.53, wpb=1139.8, bsz=32, num_updates=29300, lr=1.39181e-05, gnorm=9.597, clip=100, loss_scale=64, train_wall=19, gb_free=10.8, wall=55068
2023-05-26 14:41:12 - progress_bar.py[line:272] - INFO: epoch 017:   1649 / 1732 loss=2.158, loss_v1=0, loss_v2=0, nll_loss=0.932, ntokens=1200.9, nsentences=32, sample_size=1200.9, sample_size_v1=0, sample_size_v2=0, ppl=1.91, wps=631.4, ups=0.53, wpb=1200.9, bsz=32, num_updates=29310, lr=1.39119e-05, gnorm=9.038, clip=100, loss_scale=64, train_wall=19, gb_free=11.3, wall=55087
2023-05-26 14:41:31 - progress_bar.py[line:272] - INFO: epoch 017:   1659 / 1732 loss=2.205, loss_v1=0, loss_v2=0, nll_loss=0.986, ntokens=965.2, nsentences=32, sample_size=965.2, sample_size_v1=0, sample_size_v2=0, ppl=1.98, wps=515.5, ups=0.53, wpb=965.2, bsz=32, num_updates=29320, lr=1.39058e-05, gnorm=10.847, clip=100, loss_scale=64, train_wall=19, gb_free=11.1, wall=55106
2023-05-26 14:41:50 - progress_bar.py[line:272] - INFO: epoch 017:   1669 / 1732 loss=2.166, loss_v1=0, loss_v2=0, nll_loss=0.941, ntokens=1018.2, nsentences=32, sample_size=1018.2, sample_size_v1=0, sample_size_v2=0, ppl=1.92, wps=543.3, ups=0.53, wpb=1018.2, bsz=32, num_updates=29330, lr=1.38996e-05, gnorm=9.505, clip=100, loss_scale=64, train_wall=19, gb_free=11.8, wall=55124
2023-05-26 14:42:09 - progress_bar.py[line:272] - INFO: epoch 017:   1679 / 1732 loss=2.139, loss_v1=0, loss_v2=0, nll_loss=0.911, ntokens=1155.9, nsentences=32, sample_size=1155.9, sample_size_v1=0, sample_size_v2=0, ppl=1.88, wps=607.2, ups=0.53, wpb=1155.9, bsz=32, num_updates=29340, lr=1.38935e-05, gnorm=9.038, clip=100, loss_scale=64, train_wall=19, gb_free=10.8, wall=55143
2023-05-26 14:42:28 - progress_bar.py[line:272] - INFO: epoch 017:   1689 / 1732 loss=2.171, loss_v1=0, loss_v2=0, nll_loss=0.947, ntokens=1198.6, nsentences=32, sample_size=1198.6, sample_size_v1=0, sample_size_v2=0, ppl=1.93, wps=629.3, ups=0.53, wpb=1198.6, bsz=32, num_updates=29350, lr=1.38874e-05, gnorm=8.993, clip=100, loss_scale=64, train_wall=19, gb_free=10.4, wall=55162
2023-05-26 14:42:47 - progress_bar.py[line:272] - INFO: epoch 017:   1699 / 1732 loss=2.155, loss_v1=0, loss_v2=0, nll_loss=0.93, ntokens=1300, nsentences=32, sample_size=1300, sample_size_v1=0, sample_size_v2=0, ppl=1.9, wps=676, ups=0.52, wpb=1300, bsz=32, num_updates=29360, lr=1.38812e-05, gnorm=7.813, clip=100, loss_scale=64, train_wall=19, gb_free=11.1, wall=55182
2023-05-26 14:43:06 - progress_bar.py[line:272] - INFO: epoch 017:   1709 / 1732 loss=2.19, loss_v1=0, loss_v2=0, nll_loss=0.967, ntokens=1178.3, nsentences=32, sample_size=1178.3, sample_size_v1=0, sample_size_v2=0, ppl=1.96, wps=622.4, ups=0.53, wpb=1178.3, bsz=32, num_updates=29370, lr=1.38751e-05, gnorm=9.448, clip=100, loss_scale=64, train_wall=19, gb_free=11.3, wall=55201
2023-05-26 14:43:25 - progress_bar.py[line:272] - INFO: epoch 017:   1719 / 1732 loss=2.148, loss_v1=0, loss_v2=0, nll_loss=0.921, ntokens=1171.3, nsentences=32, sample_size=1171.3, sample_size_v1=0, sample_size_v2=0, ppl=1.89, wps=609, ups=0.52, wpb=1171.3, bsz=32, num_updates=29380, lr=1.38689e-05, gnorm=8.693, clip=100, loss_scale=64, train_wall=19, gb_free=10.9, wall=55220
2023-05-26 14:43:44 - progress_bar.py[line:272] - INFO: epoch 017:   1729 / 1732 loss=2.192, loss_v1=0, loss_v2=0, nll_loss=0.971, ntokens=1095.7, nsentences=32, sample_size=1095.7, sample_size_v1=0, sample_size_v2=0, ppl=1.96, wps=579.8, ups=0.53, wpb=1095.7, bsz=32, num_updates=29390, lr=1.38628e-05, gnorm=9.901, clip=100, loss_scale=64, train_wall=19, gb_free=10.8, wall=55239
2023-05-26 14:43:48 - train.py[line:332] - INFO: end of epoch 17 (average epoch stats below)
2023-05-26 14:43:48 - progress_bar.py[line:282] - INFO: epoch 017 | loss 2.185 | loss_v1 0 | loss_v2 0 | nll_loss 0.963 | ntokens 1051.48 | nsentences 31.986 | sample_size 1051.48 | sample_size_v1 0 | sample_size_v2 0 | ppl 1.95 | wps 559.4 | ups 0.53 | wpb 1051.5 | bsz 32 | num_updates 29393 | lr 1.38609e-05 | gnorm 8.787 | clip 100 | loss_scale 64 | train_wall 3242 | gb_free 11.7 | wall 55243
2023-05-26 14:43:48 - trainer.py[line:639] - INFO: loading train data for epoch 18
local datafile ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 0 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 0 finished initializing row_count and line_idx-to-offset mapping
file ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 0 row count 55400 total row count 55400
slice_id 0 seek offset 0
2023-05-26 14:43:50 - trainer.py[line:703] - INFO: begin training epoch 18
2023-05-26 14:43:50 - train.py[line:305] - INFO: Start iterating over samples
2023-05-26 14:44:04 - progress_bar.py[line:272] - INFO: epoch 018:      7 / 1732 loss=2.148, loss_v1=0, loss_v2=0, nll_loss=0.921, ntokens=1093.3, nsentences=29.6, sample_size=1093.3, sample_size_v1=0, sample_size_v2=0, ppl=1.89, wps=550.4, ups=0.5, wpb=1093.3, bsz=29.6, num_updates=29400, lr=1.38566e-05, gnorm=9.857, clip=100, loss_scale=64, train_wall=18, gb_free=11.2, wall=55259
2023-05-26 14:44:23 - progress_bar.py[line:272] - INFO: epoch 018:     17 / 1732 loss=2.141, loss_v1=0, loss_v2=0, nll_loss=0.913, ntokens=1095.7, nsentences=32, sample_size=1095.7, sample_size_v1=0, sample_size_v2=0, ppl=1.88, wps=580.2, ups=0.53, wpb=1095.7, bsz=32, num_updates=29410, lr=1.38505e-05, gnorm=11.123, clip=100, loss_scale=64, train_wall=19, gb_free=11, wall=55278
2023-05-26 14:44:42 - progress_bar.py[line:272] - INFO: epoch 018:     27 / 1732 loss=2.15, loss_v1=0, loss_v2=0, nll_loss=0.925, ntokens=954.5, nsentences=32, sample_size=954.5, sample_size_v1=0, sample_size_v2=0, ppl=1.9, wps=507.8, ups=0.53, wpb=954.5, bsz=32, num_updates=29420, lr=1.38444e-05, gnorm=10.852, clip=100, loss_scale=64, train_wall=19, gb_free=10.7, wall=55296
2023-05-26 14:45:01 - progress_bar.py[line:272] - INFO: epoch 018:     37 / 1732 loss=2.014, loss_v1=0, loss_v2=0, nll_loss=0.773, ntokens=1179.3, nsentences=32, sample_size=1179.3, sample_size_v1=0, sample_size_v2=0, ppl=1.71, wps=619.7, ups=0.53, wpb=1179.3, bsz=32, num_updates=29430, lr=1.38382e-05, gnorm=8.194, clip=100, loss_scale=64, train_wall=19, gb_free=10.9, wall=55315
2023-05-26 14:45:20 - progress_bar.py[line:272] - INFO: epoch 018:     47 / 1732 loss=2.035, loss_v1=0, loss_v2=0, nll_loss=0.797, ntokens=1055.1, nsentences=32, sample_size=1055.1, sample_size_v1=0, sample_size_v2=0, ppl=1.74, wps=560, ups=0.53, wpb=1055.1, bsz=32, num_updates=29440, lr=1.38321e-05, gnorm=8.862, clip=100, loss_scale=64, train_wall=19, gb_free=10.8, wall=55334
2023-05-26 14:45:38 - progress_bar.py[line:272] - INFO: epoch 018:     57 / 1732 loss=1.961, loss_v1=0, loss_v2=0, nll_loss=0.713, ntokens=1048.7, nsentences=32, sample_size=1048.7, sample_size_v1=0, sample_size_v2=0, ppl=1.64, wps=559.2, ups=0.53, wpb=1048.7, bsz=32, num_updates=29450, lr=1.38259e-05, gnorm=8.976, clip=100, loss_scale=64, train_wall=19, gb_free=11.2, wall=55353
2023-05-26 14:45:58 - progress_bar.py[line:272] - INFO: epoch 018:     67 / 1732 loss=1.89, loss_v1=0, loss_v2=0, nll_loss=0.634, ntokens=1356.1, nsentences=32, sample_size=1356.1, sample_size_v1=0, sample_size_v2=0, ppl=1.55, wps=700.4, ups=0.52, wpb=1356.1, bsz=32, num_updates=29460, lr=1.38198e-05, gnorm=6.504, clip=100, loss_scale=64, train_wall=19, gb_free=10.3, wall=55372
2023-05-26 14:46:17 - progress_bar.py[line:272] - INFO: epoch 018:     77 / 1732 loss=1.973, loss_v1=0, loss_v2=0, nll_loss=0.728, ntokens=1273.9, nsentences=32, sample_size=1273.9, sample_size_v1=0, sample_size_v2=0, ppl=1.66, wps=657.4, ups=0.52, wpb=1273.9, bsz=32, num_updates=29470, lr=1.38136e-05, gnorm=7.05, clip=100, loss_scale=64, train_wall=19, gb_free=11.1, wall=55392
2023-05-26 14:46:36 - progress_bar.py[line:272] - INFO: epoch 018:     87 / 1732 loss=2.047, loss_v1=0, loss_v2=0, nll_loss=0.809, ntokens=1141.2, nsentences=32, sample_size=1141.2, sample_size_v1=0, sample_size_v2=0, ppl=1.75, wps=595.7, ups=0.52, wpb=1141.2, bsz=32, num_updates=29480, lr=1.38075e-05, gnorm=9.014, clip=100, loss_scale=64, train_wall=19, gb_free=10.6, wall=55411
2023-05-26 14:46:55 - progress_bar.py[line:272] - INFO: epoch 018:     97 / 1732 loss=2.02, loss_v1=0, loss_v2=0, nll_loss=0.778, ntokens=1080.1, nsentences=32, sample_size=1080.1, sample_size_v1=0, sample_size_v2=0, ppl=1.72, wps=570.3, ups=0.53, wpb=1080.1, bsz=32, num_updates=29490, lr=1.38014e-05, gnorm=8.909, clip=100, loss_scale=64, train_wall=19, gb_free=10.1, wall=55430
2023-05-26 14:47:14 - progress_bar.py[line:272] - INFO: epoch 018:    107 / 1732 loss=2.135, loss_v1=0, loss_v2=0, nll_loss=0.91, ntokens=981.4, nsentences=32, sample_size=981.4, sample_size_v1=0, sample_size_v2=0, ppl=1.88, wps=523.8, ups=0.53, wpb=981.4, bsz=32, num_updates=29500, lr=1.37952e-05, gnorm=9.568, clip=100, loss_scale=64, train_wall=19, gb_free=11, wall=55449
2023-05-26 14:47:33 - progress_bar.py[line:272] - INFO: epoch 018:    117 / 1732 loss=2.209, loss_v1=0, loss_v2=0, nll_loss=0.991, ntokens=1060.7, nsentences=32, sample_size=1060.7, sample_size_v1=0, sample_size_v2=0, ppl=1.99, wps=559.3, ups=0.53, wpb=1060.7, bsz=32, num_updates=29510, lr=1.37891e-05, gnorm=10.343, clip=100, loss_scale=64, train_wall=19, gb_free=10.6, wall=55468
2023-05-26 14:47:52 - progress_bar.py[line:272] - INFO: epoch 018:    127 / 1732 loss=2.161, loss_v1=0, loss_v2=0, nll_loss=0.936, ntokens=1185.5, nsentences=32, sample_size=1185.5, sample_size_v1=0, sample_size_v2=0, ppl=1.91, wps=617.3, ups=0.52, wpb=1185.5, bsz=32, num_updates=29520, lr=1.37829e-05, gnorm=9.678, clip=100, loss_scale=64, train_wall=19, gb_free=11.1, wall=55487
2023-05-26 14:48:07 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2023-05-26 14:48:13 - progress_bar.py[line:272] - INFO: epoch 018:    138 / 1732 loss=2.134, loss_v1=0, loss_v2=0, nll_loss=0.905, ntokens=1226.4, nsentences=32, sample_size=1226.4, sample_size_v1=0, sample_size_v2=0, ppl=1.87, wps=584.4, ups=0.48, wpb=1226.4, bsz=32, num_updates=29530, lr=1.37768e-05, gnorm=8.497, clip=100, loss_scale=32, train_wall=21, gb_free=11, wall=55508
2023-05-26 14:48:32 - progress_bar.py[line:272] - INFO: epoch 018:    148 / 1732 loss=2.088, loss_v1=0, loss_v2=0, nll_loss=0.853, ntokens=1210.4, nsentences=32, sample_size=1210.4, sample_size_v1=0, sample_size_v2=0, ppl=1.81, wps=625.9, ups=0.52, wpb=1210.4, bsz=32, num_updates=29540, lr=1.37707e-05, gnorm=8.453, clip=100, loss_scale=32, train_wall=19, gb_free=10.6, wall=55527
2023-05-26 14:48:52 - progress_bar.py[line:272] - INFO: epoch 018:    158 / 1732 loss=2.141, loss_v1=0, loss_v2=0, nll_loss=0.915, ntokens=1139, nsentences=32, sample_size=1139, sample_size_v1=0, sample_size_v2=0, ppl=1.89, wps=592.1, ups=0.52, wpb=1139, bsz=32, num_updates=29550, lr=1.37645e-05, gnorm=9.667, clip=100, loss_scale=32, train_wall=19, gb_free=11.2, wall=55546
2023-05-26 14:49:11 - progress_bar.py[line:272] - INFO: epoch 018:    168 / 1732 loss=2.118, loss_v1=0, loss_v2=0, nll_loss=0.89, ntokens=1015.2, nsentences=32, sample_size=1015.2, sample_size_v1=0, sample_size_v2=0, ppl=1.85, wps=537.5, ups=0.53, wpb=1015.2, bsz=32, num_updates=29560, lr=1.37584e-05, gnorm=10.325, clip=100, loss_scale=32, train_wall=19, gb_free=11.4, wall=55565
2023-05-26 14:49:29 - progress_bar.py[line:272] - INFO: epoch 018:    178 / 1732 loss=2.112, loss_v1=0, loss_v2=0, nll_loss=0.881, ntokens=1025.5, nsentences=32, sample_size=1025.5, sample_size_v1=0, sample_size_v2=0, ppl=1.84, wps=543.4, ups=0.53, wpb=1025.5, bsz=32, num_updates=29570, lr=1.37522e-05, gnorm=10.871, clip=100, loss_scale=32, train_wall=19, gb_free=11, wall=55584
2023-05-26 14:49:48 - progress_bar.py[line:272] - INFO: epoch 018:    188 / 1732 loss=2.082, loss_v1=0, loss_v2=0, nll_loss=0.847, ntokens=1150.5, nsentences=32, sample_size=1150.5, sample_size_v1=0, sample_size_v2=0, ppl=1.8, wps=603.3, ups=0.52, wpb=1150.5, bsz=32, num_updates=29580, lr=1.37461e-05, gnorm=9.669, clip=100, loss_scale=32, train_wall=19, gb_free=11.1, wall=55603
2023-05-26 14:50:08 - progress_bar.py[line:272] - INFO: epoch 018:    198 / 1732 loss=2.136, loss_v1=0, loss_v2=0, nll_loss=0.908, ntokens=1142.2, nsentences=32, sample_size=1142.2, sample_size_v1=0, sample_size_v2=0, ppl=1.88, wps=600.6, ups=0.53, wpb=1142.2, bsz=32, num_updates=29590, lr=1.37399e-05, gnorm=9.449, clip=100, loss_scale=32, train_wall=19, gb_free=11, wall=55622
2023-05-26 14:50:26 - progress_bar.py[line:272] - INFO: epoch 018:    208 / 1732 loss=2.195, loss_v1=0, loss_v2=0, nll_loss=0.974, ntokens=961.8, nsentences=32, sample_size=961.8, sample_size_v1=0, sample_size_v2=0, ppl=1.96, wps=519.1, ups=0.54, wpb=961.8, bsz=32, num_updates=29600, lr=1.37338e-05, gnorm=9.98, clip=100, loss_scale=32, train_wall=19, gb_free=11.1, wall=55641
2023-05-26 14:50:45 - progress_bar.py[line:272] - INFO: epoch 018:    218 / 1732 loss=2.201, loss_v1=0, loss_v2=0, nll_loss=0.981, ntokens=1149.2, nsentences=32, sample_size=1149.2, sample_size_v1=0, sample_size_v2=0, ppl=1.97, wps=613.5, ups=0.53, wpb=1149.2, bsz=32, num_updates=29610, lr=1.37277e-05, gnorm=8.811, clip=100, loss_scale=32, train_wall=19, gb_free=11.5, wall=55659
2023-05-26 14:51:04 - progress_bar.py[line:272] - INFO: epoch 018:    228 / 1732 loss=2.191, loss_v1=0, loss_v2=0, nll_loss=0.97, ntokens=1111.8, nsentences=32, sample_size=1111.8, sample_size_v1=0, sample_size_v2=0, ppl=1.96, wps=593.7, ups=0.53, wpb=1111.8, bsz=32, num_updates=29620, lr=1.37215e-05, gnorm=9.131, clip=100, loss_scale=32, train_wall=19, gb_free=11.6, wall=55678
2023-05-26 14:51:22 - progress_bar.py[line:272] - INFO: epoch 018:    238 / 1732 loss=2.235, loss_v1=0, loss_v2=0, nll_loss=1.017, ntokens=1085.4, nsentences=32, sample_size=1085.4, sample_size_v1=0, sample_size_v2=0, ppl=2.02, wps=580.3, ups=0.53, wpb=1085.4, bsz=32, num_updates=29630, lr=1.37154e-05, gnorm=8.943, clip=100, loss_scale=32, train_wall=19, gb_free=11.5, wall=55697
2023-05-26 14:51:41 - progress_bar.py[line:272] - INFO: epoch 018:    248 / 1732 loss=2.191, loss_v1=0, loss_v2=0, nll_loss=0.969, ntokens=1171.6, nsentences=32, sample_size=1171.6, sample_size_v1=0, sample_size_v2=0, ppl=1.96, wps=623.3, ups=0.53, wpb=1171.6, bsz=32, num_updates=29640, lr=1.37092e-05, gnorm=8.445, clip=100, loss_scale=32, train_wall=19, gb_free=11.3, wall=55716
2023-05-26 14:52:00 - progress_bar.py[line:272] - INFO: epoch 018:    258 / 1732 loss=2.22, loss_v1=0, loss_v2=0, nll_loss=1.005, ntokens=1118, nsentences=32, sample_size=1118, sample_size_v1=0, sample_size_v2=0, ppl=2.01, wps=596.7, ups=0.53, wpb=1118, bsz=32, num_updates=29650, lr=1.37031e-05, gnorm=9.208, clip=100, loss_scale=32, train_wall=19, gb_free=11.4, wall=55734
2023-05-26 14:52:19 - progress_bar.py[line:272] - INFO: epoch 018:    268 / 1732 loss=2.186, loss_v1=0, loss_v2=0, nll_loss=0.965, ntokens=1160.8, nsentences=32, sample_size=1160.8, sample_size_v1=0, sample_size_v2=0, ppl=1.95, wps=617.8, ups=0.53, wpb=1160.8, bsz=32, num_updates=29660, lr=1.36969e-05, gnorm=8.352, clip=100, loss_scale=32, train_wall=19, gb_free=11.6, wall=55753
2023-05-26 14:52:37 - progress_bar.py[line:272] - INFO: epoch 018:    278 / 1732 loss=2.214, loss_v1=0, loss_v2=0, nll_loss=0.993, ntokens=1136.9, nsentences=32, sample_size=1136.9, sample_size_v1=0, sample_size_v2=0, ppl=1.99, wps=602.5, ups=0.53, wpb=1136.9, bsz=32, num_updates=29670, lr=1.36908e-05, gnorm=9.564, clip=100, loss_scale=32, train_wall=19, gb_free=11.3, wall=55772
2023-05-26 14:52:56 - progress_bar.py[line:272] - INFO: epoch 018:    288 / 1732 loss=2.176, loss_v1=0, loss_v2=0, nll_loss=0.951, ntokens=1173.3, nsentences=32, sample_size=1173.3, sample_size_v1=0, sample_size_v2=0, ppl=1.93, wps=621, ups=0.53, wpb=1173.3, bsz=32, num_updates=29680, lr=1.36847e-05, gnorm=8.27, clip=100, loss_scale=32, train_wall=19, gb_free=11.2, wall=55791
2023-05-26 14:53:15 - progress_bar.py[line:272] - INFO: epoch 018:    298 / 1732 loss=2.196, loss_v1=0, loss_v2=0, nll_loss=0.976, ntokens=1074.2, nsentences=32, sample_size=1074.2, sample_size_v1=0, sample_size_v2=0, ppl=1.97, wps=575, ups=0.54, wpb=1074.2, bsz=32, num_updates=29690, lr=1.36785e-05, gnorm=8.905, clip=100, loss_scale=32, train_wall=19, gb_free=11.8, wall=55810
2023-05-26 14:53:34 - progress_bar.py[line:272] - INFO: epoch 018:    308 / 1732 loss=2.185, loss_v1=0, loss_v2=0, nll_loss=0.966, ntokens=1090.6, nsentences=32, sample_size=1090.6, sample_size_v1=0, sample_size_v2=0, ppl=1.95, wps=583.4, ups=0.53, wpb=1090.6, bsz=32, num_updates=29700, lr=1.36724e-05, gnorm=9.218, clip=100, loss_scale=32, train_wall=19, gb_free=11.7, wall=55828
2023-05-26 14:53:52 - progress_bar.py[line:272] - INFO: epoch 018:    318 / 1732 loss=2.212, loss_v1=0, loss_v2=0, nll_loss=0.993, ntokens=1026, nsentences=32, sample_size=1026, sample_size_v1=0, sample_size_v2=0, ppl=1.99, wps=550.9, ups=0.54, wpb=1026, bsz=32, num_updates=29710, lr=1.36662e-05, gnorm=10.083, clip=100, loss_scale=32, train_wall=19, gb_free=11.3, wall=55847
2023-05-26 14:54:11 - progress_bar.py[line:272] - INFO: epoch 018:    328 / 1732 loss=2.239, loss_v1=0, loss_v2=0, nll_loss=1.022, ntokens=1009.5, nsentences=32, sample_size=1009.5, sample_size_v1=0, sample_size_v2=0, ppl=2.03, wps=543.7, ups=0.54, wpb=1009.5, bsz=32, num_updates=29720, lr=1.36601e-05, gnorm=10.171, clip=100, loss_scale=32, train_wall=19, gb_free=11.7, wall=55866
2023-05-26 14:54:29 - progress_bar.py[line:272] - INFO: epoch 018:    338 / 1732 loss=2.194, loss_v1=0, loss_v2=0, nll_loss=0.973, ntokens=991.1, nsentences=32, sample_size=991.1, sample_size_v1=0, sample_size_v2=0, ppl=1.96, wps=533.3, ups=0.54, wpb=991.1, bsz=32, num_updates=29730, lr=1.3654e-05, gnorm=9.95, clip=100, loss_scale=32, train_wall=19, gb_free=11.7, wall=55884
2023-05-26 14:54:48 - progress_bar.py[line:272] - INFO: epoch 018:    348 / 1732 loss=2.184, loss_v1=0, loss_v2=0, nll_loss=0.962, ntokens=913.6, nsentences=32, sample_size=913.6, sample_size_v1=0, sample_size_v2=0, ppl=1.95, wps=494.9, ups=0.54, wpb=913.6, bsz=32, num_updates=29740, lr=1.36478e-05, gnorm=10.269, clip=100, loss_scale=32, train_wall=18, gb_free=11.6, wall=55903
2023-05-26 14:55:06 - progress_bar.py[line:272] - INFO: epoch 018:    358 / 1732 loss=2.226, loss_v1=0, loss_v2=0, nll_loss=1.01, ntokens=943, nsentences=32, sample_size=943, sample_size_v1=0, sample_size_v2=0, ppl=2.01, wps=510.7, ups=0.54, wpb=943, bsz=32, num_updates=29750, lr=1.36417e-05, gnorm=10.626, clip=100, loss_scale=32, train_wall=18, gb_free=11.9, wall=55921
2023-05-26 14:55:25 - progress_bar.py[line:272] - INFO: epoch 018:    368 / 1732 loss=2.216, loss_v1=0, loss_v2=0, nll_loss=0.998, ntokens=960.6, nsentences=32, sample_size=960.6, sample_size_v1=0, sample_size_v2=0, ppl=2, wps=518.3, ups=0.54, wpb=960.6, bsz=32, num_updates=29760, lr=1.36355e-05, gnorm=10.719, clip=100, loss_scale=32, train_wall=19, gb_free=11.5, wall=55940
2023-05-26 14:55:44 - progress_bar.py[line:272] - INFO: epoch 018:    378 / 1732 loss=2.232, loss_v1=0, loss_v2=0, nll_loss=1.015, ntokens=1043.2, nsentences=32, sample_size=1043.2, sample_size_v1=0, sample_size_v2=0, ppl=2.02, wps=562.4, ups=0.54, wpb=1043.2, bsz=32, num_updates=29770, lr=1.36294e-05, gnorm=10.462, clip=100, loss_scale=32, train_wall=19, gb_free=11.8, wall=55958
2023-05-26 14:56:02 - progress_bar.py[line:272] - INFO: epoch 018:    388 / 1732 loss=2.205, loss_v1=0, loss_v2=0, nll_loss=0.985, ntokens=1053.2, nsentences=32, sample_size=1053.2, sample_size_v1=0, sample_size_v2=0, ppl=1.98, wps=566.7, ups=0.54, wpb=1053.2, bsz=32, num_updates=29780, lr=1.36232e-05, gnorm=9.447, clip=100, loss_scale=32, train_wall=19, gb_free=11.1, wall=55977
2023-05-26 14:56:21 - progress_bar.py[line:272] - INFO: epoch 018:    398 / 1732 loss=2.221, loss_v1=0, loss_v2=0, nll_loss=1.002, ntokens=977.4, nsentences=32, sample_size=977.4, sample_size_v1=0, sample_size_v2=0, ppl=2, wps=528.3, ups=0.54, wpb=977.4, bsz=32, num_updates=29790, lr=1.36171e-05, gnorm=10.354, clip=100, loss_scale=32, train_wall=18, gb_free=10.9, wall=55995
2023-05-26 14:56:39 - progress_bar.py[line:272] - INFO: epoch 018:    408 / 1732 loss=2.2, loss_v1=0, loss_v2=0, nll_loss=0.98, ntokens=1058.6, nsentences=32, sample_size=1058.6, sample_size_v1=0, sample_size_v2=0, ppl=1.97, wps=568, ups=0.54, wpb=1058.6, bsz=32, num_updates=29800, lr=1.3611e-05, gnorm=9.678, clip=100, loss_scale=32, train_wall=19, gb_free=11.5, wall=56014
2023-05-26 14:56:58 - progress_bar.py[line:272] - INFO: epoch 018:    418 / 1732 loss=2.158, loss_v1=0, loss_v2=0, nll_loss=0.933, ntokens=1021.6, nsentences=32, sample_size=1021.6, sample_size_v1=0, sample_size_v2=0, ppl=1.91, wps=549.5, ups=0.54, wpb=1021.6, bsz=32, num_updates=29810, lr=1.36048e-05, gnorm=9.713, clip=100, loss_scale=32, train_wall=19, gb_free=11, wall=56033
2023-05-26 14:57:16 - progress_bar.py[line:272] - INFO: epoch 018:    428 / 1732 loss=2.174, loss_v1=0, loss_v2=0, nll_loss=0.951, ntokens=1016.5, nsentences=32, sample_size=1016.5, sample_size_v1=0, sample_size_v2=0, ppl=1.93, wps=546.3, ups=0.54, wpb=1016.5, bsz=32, num_updates=29820, lr=1.35987e-05, gnorm=10.181, clip=100, loss_scale=32, train_wall=19, gb_free=11.2, wall=56051
2023-05-26 14:57:35 - progress_bar.py[line:272] - INFO: epoch 018:    438 / 1732 loss=2.2, loss_v1=0, loss_v2=0, nll_loss=0.979, ntokens=1018.5, nsentences=32, sample_size=1018.5, sample_size_v1=0, sample_size_v2=0, ppl=1.97, wps=549.4, ups=0.54, wpb=1018.5, bsz=32, num_updates=29830, lr=1.35925e-05, gnorm=9.537, clip=100, loss_scale=32, train_wall=19, gb_free=11.7, wall=56070
2023-05-26 14:57:54 - progress_bar.py[line:272] - INFO: epoch 018:    448 / 1732 loss=2.209, loss_v1=0, loss_v2=0, nll_loss=0.989, ntokens=946.6, nsentences=32, sample_size=946.6, sample_size_v1=0, sample_size_v2=0, ppl=1.99, wps=509.9, ups=0.54, wpb=946.6, bsz=32, num_updates=29840, lr=1.35864e-05, gnorm=10.391, clip=100, loss_scale=32, train_wall=19, gb_free=11.5, wall=56088
2023-05-26 14:58:12 - progress_bar.py[line:272] - INFO: epoch 018:    458 / 1732 loss=2.212, loss_v1=0, loss_v2=0, nll_loss=0.994, ntokens=971.2, nsentences=32, sample_size=971.2, sample_size_v1=0, sample_size_v2=0, ppl=1.99, wps=526, ups=0.54, wpb=971.2, bsz=32, num_updates=29850, lr=1.35802e-05, gnorm=10.824, clip=100, loss_scale=32, train_wall=18, gb_free=11.8, wall=56107
2023-05-26 14:58:31 - progress_bar.py[line:272] - INFO: epoch 018:    468 / 1732 loss=2.223, loss_v1=0, loss_v2=0, nll_loss=1.005, ntokens=1064.3, nsentences=32, sample_size=1064.3, sample_size_v1=0, sample_size_v2=0, ppl=2.01, wps=567.5, ups=0.53, wpb=1064.3, bsz=32, num_updates=29860, lr=1.35741e-05, gnorm=9.78, clip=100, loss_scale=32, train_wall=19, gb_free=11.3, wall=56125
2023-05-26 14:58:49 - progress_bar.py[line:272] - INFO: epoch 018:    478 / 1732 loss=2.246, loss_v1=0, loss_v2=0, nll_loss=1.03, ntokens=1027.7, nsentences=32, sample_size=1027.7, sample_size_v1=0, sample_size_v2=0, ppl=2.04, wps=551.4, ups=0.54, wpb=1027.7, bsz=32, num_updates=29870, lr=1.3568e-05, gnorm=11.298, clip=100, loss_scale=32, train_wall=19, gb_free=11.7, wall=56144
2023-05-26 14:59:08 - progress_bar.py[line:272] - INFO: epoch 018:    488 / 1732 loss=2.178, loss_v1=0, loss_v2=0, nll_loss=0.953, ntokens=925.6, nsentences=32, sample_size=925.6, sample_size_v1=0, sample_size_v2=0, ppl=1.94, wps=501.1, ups=0.54, wpb=925.6, bsz=32, num_updates=29880, lr=1.35618e-05, gnorm=10.839, clip=100, loss_scale=32, train_wall=18, gb_free=12, wall=56163
2023-05-26 14:59:26 - progress_bar.py[line:272] - INFO: epoch 018:    498 / 1732 loss=2.19, loss_v1=0, loss_v2=0, nll_loss=0.969, ntokens=952.7, nsentences=32, sample_size=952.7, sample_size_v1=0, sample_size_v2=0, ppl=1.96, wps=514.4, ups=0.54, wpb=952.7, bsz=32, num_updates=29890, lr=1.35557e-05, gnorm=10.543, clip=100, loss_scale=32, train_wall=18, gb_free=12.1, wall=56181
2023-05-26 14:59:45 - progress_bar.py[line:272] - INFO: epoch 018:    508 / 1732 loss=2.222, loss_v1=0, loss_v2=0, nll_loss=1.005, ntokens=1034.3, nsentences=32, sample_size=1034.3, sample_size_v1=0, sample_size_v2=0, ppl=2.01, wps=558.3, ups=0.54, wpb=1034.3, bsz=32, num_updates=29900, lr=1.35495e-05, gnorm=11.006, clip=100, loss_scale=32, train_wall=18, gb_free=11.7, wall=56200
2023-05-26 15:00:03 - progress_bar.py[line:272] - INFO: epoch 018:    518 / 1732 loss=2.195, loss_v1=0, loss_v2=0, nll_loss=0.975, ntokens=1032.2, nsentences=32, sample_size=1032.2, sample_size_v1=0, sample_size_v2=0, ppl=1.97, wps=558.1, ups=0.54, wpb=1032.2, bsz=32, num_updates=29910, lr=1.35434e-05, gnorm=9.792, clip=100, loss_scale=32, train_wall=18, gb_free=11.7, wall=56218
2023-05-26 15:00:22 - progress_bar.py[line:272] - INFO: epoch 018:    528 / 1732 loss=2.204, loss_v1=0, loss_v2=0, nll_loss=0.982, ntokens=941.1, nsentences=32, sample_size=941.1, sample_size_v1=0, sample_size_v2=0, ppl=1.98, wps=510.9, ups=0.54, wpb=941.1, bsz=32, num_updates=29920, lr=1.35373e-05, gnorm=11.243, clip=100, loss_scale=32, train_wall=18, gb_free=11.9, wall=56237
2023-05-26 15:00:40 - progress_bar.py[line:272] - INFO: epoch 018:    538 / 1732 loss=2.196, loss_v1=0, loss_v2=0, nll_loss=0.974, ntokens=972.3, nsentences=32, sample_size=972.3, sample_size_v1=0, sample_size_v2=0, ppl=1.96, wps=526.2, ups=0.54, wpb=972.3, bsz=32, num_updates=29930, lr=1.35311e-05, gnorm=9.569, clip=100, loss_scale=32, train_wall=18, gb_free=11.2, wall=56255
2023-05-26 15:00:59 - progress_bar.py[line:272] - INFO: epoch 018:    548 / 1732 loss=2.224, loss_v1=0, loss_v2=0, nll_loss=1.007, ntokens=1027.8, nsentences=32, sample_size=1027.8, sample_size_v1=0, sample_size_v2=0, ppl=2.01, wps=552, ups=0.54, wpb=1027.8, bsz=32, num_updates=29940, lr=1.3525e-05, gnorm=10.683, clip=100, loss_scale=32, train_wall=19, gb_free=11.6, wall=56274
2023-05-26 15:01:18 - progress_bar.py[line:272] - INFO: epoch 018:    558 / 1732 loss=2.235, loss_v1=0, loss_v2=0, nll_loss=1.02, ntokens=1021.9, nsentences=32, sample_size=1021.9, sample_size_v1=0, sample_size_v2=0, ppl=2.03, wps=551.7, ups=0.54, wpb=1021.9, bsz=32, num_updates=29950, lr=1.35188e-05, gnorm=10.702, clip=100, loss_scale=32, train_wall=18, gb_free=10.9, wall=56292
2023-05-26 15:01:36 - progress_bar.py[line:272] - INFO: epoch 018:    568 / 1732 loss=2.232, loss_v1=0, loss_v2=0, nll_loss=1.015, ntokens=1014.9, nsentences=32, sample_size=1014.9, sample_size_v1=0, sample_size_v2=0, ppl=2.02, wps=545, ups=0.54, wpb=1014.9, bsz=32, num_updates=29960, lr=1.35127e-05, gnorm=11.191, clip=100, loss_scale=32, train_wall=19, gb_free=11.1, wall=56311
2023-05-26 15:01:55 - progress_bar.py[line:272] - INFO: epoch 018:    578 / 1732 loss=2.217, loss_v1=0, loss_v2=0, nll_loss=0.998, ntokens=991.4, nsentences=32, sample_size=991.4, sample_size_v1=0, sample_size_v2=0, ppl=2, wps=531.4, ups=0.54, wpb=991.4, bsz=32, num_updates=29970, lr=1.35065e-05, gnorm=11.071, clip=100, loss_scale=32, train_wall=19, gb_free=11.2, wall=56329
2023-05-26 15:02:13 - progress_bar.py[line:272] - INFO: epoch 018:    588 / 1732 loss=2.209, loss_v1=0, loss_v2=0, nll_loss=0.988, ntokens=965.9, nsentences=32, sample_size=965.9, sample_size_v1=0, sample_size_v2=0, ppl=1.98, wps=517.4, ups=0.54, wpb=965.9, bsz=32, num_updates=29980, lr=1.35004e-05, gnorm=11.311, clip=100, loss_scale=32, train_wall=19, gb_free=11.6, wall=56348
2023-05-26 15:02:32 - progress_bar.py[line:272] - INFO: epoch 018:    598 / 1732 loss=2.166, loss_v1=0, loss_v2=0, nll_loss=0.942, ntokens=957.4, nsentences=32, sample_size=957.4, sample_size_v1=0, sample_size_v2=0, ppl=1.92, wps=514.9, ups=0.54, wpb=957.4, bsz=32, num_updates=29990, lr=1.34943e-05, gnorm=9.945, clip=100, loss_scale=32, train_wall=19, gb_free=11.9, wall=56367
2023-05-26 15:02:50 - progress_bar.py[line:272] - INFO: epoch 018:    608 / 1732 loss=2.198, loss_v1=0, loss_v2=0, nll_loss=0.979, ntokens=893.5, nsentences=32, sample_size=893.5, sample_size_v1=0, sample_size_v2=0, ppl=1.97, wps=485.4, ups=0.54, wpb=893.5, bsz=32, num_updates=30000, lr=1.34881e-05, gnorm=11.457, clip=100, loss_scale=32, train_wall=18, gb_free=11.1, wall=56385
2023-05-26 15:03:09 - progress_bar.py[line:272] - INFO: epoch 018:    618 / 1732 loss=2.22, loss_v1=0, loss_v2=0, nll_loss=1.002, ntokens=860.2, nsentences=32, sample_size=860.2, sample_size_v1=0, sample_size_v2=0, ppl=2, wps=467, ups=0.54, wpb=860.2, bsz=32, num_updates=30010, lr=1.3482e-05, gnorm=11.357, clip=100, loss_scale=32, train_wall=18, gb_free=11.7, wall=56404
2023-05-26 15:03:27 - progress_bar.py[line:272] - INFO: epoch 018:    628 / 1732 loss=2.203, loss_v1=0, loss_v2=0, nll_loss=0.982, ntokens=929, nsentences=32, sample_size=929, sample_size_v1=0, sample_size_v2=0, ppl=1.97, wps=505.6, ups=0.54, wpb=929, bsz=32, num_updates=30020, lr=1.34758e-05, gnorm=11.293, clip=100, loss_scale=32, train_wall=18, gb_free=11.7, wall=56422
2023-05-26 15:03:46 - progress_bar.py[line:272] - INFO: epoch 018:    638 / 1732 loss=2.221, loss_v1=0, loss_v2=0, nll_loss=1.003, ntokens=921.3, nsentences=32, sample_size=921.3, sample_size_v1=0, sample_size_v2=0, ppl=2, wps=500.3, ups=0.54, wpb=921.3, bsz=32, num_updates=30030, lr=1.34697e-05, gnorm=11.148, clip=100, loss_scale=32, train_wall=18, gb_free=11.8, wall=56440
2023-05-26 15:04:04 - progress_bar.py[line:272] - INFO: epoch 018:    648 / 1732 loss=2.21, loss_v1=0, loss_v2=0, nll_loss=0.991, ntokens=983.5, nsentences=32, sample_size=983.5, sample_size_v1=0, sample_size_v2=0, ppl=1.99, wps=532, ups=0.54, wpb=983.5, bsz=32, num_updates=30040, lr=1.34635e-05, gnorm=11.039, clip=100, loss_scale=64, train_wall=18, gb_free=11.5, wall=56459
2023-05-26 15:04:23 - progress_bar.py[line:272] - INFO: epoch 018:    658 / 1732 loss=2.197, loss_v1=0, loss_v2=0, nll_loss=0.977, ntokens=892.2, nsentences=32, sample_size=892.2, sample_size_v1=0, sample_size_v2=0, ppl=1.97, wps=487.1, ups=0.55, wpb=892.2, bsz=32, num_updates=30050, lr=1.34574e-05, gnorm=9.918, clip=100, loss_scale=64, train_wall=18, gb_free=11.4, wall=56477
2023-05-26 15:04:41 - progress_bar.py[line:272] - INFO: epoch 018:    668 / 1732 loss=2.197, loss_v1=0, loss_v2=0, nll_loss=0.978, ntokens=910, nsentences=32, sample_size=910, sample_size_v1=0, sample_size_v2=0, ppl=1.97, wps=494.9, ups=0.54, wpb=910, bsz=32, num_updates=30060, lr=1.34513e-05, gnorm=11.02, clip=100, loss_scale=64, train_wall=18, gb_free=11.1, wall=56496
2023-05-26 15:04:59 - progress_bar.py[line:272] - INFO: epoch 018:    678 / 1732 loss=2.231, loss_v1=0, loss_v2=0, nll_loss=1.016, ntokens=980.2, nsentences=32, sample_size=980.2, sample_size_v1=0, sample_size_v2=0, ppl=2.02, wps=528.8, ups=0.54, wpb=980.2, bsz=32, num_updates=30070, lr=1.34451e-05, gnorm=10.661, clip=100, loss_scale=64, train_wall=19, gb_free=11.8, wall=56514
2023-05-26 15:05:18 - progress_bar.py[line:272] - INFO: epoch 018:    688 / 1732 loss=2.213, loss_v1=0, loss_v2=0, nll_loss=0.993, ntokens=942, nsentences=32, sample_size=942, sample_size_v1=0, sample_size_v2=0, ppl=1.99, wps=510.1, ups=0.54, wpb=942, bsz=32, num_updates=30080, lr=1.3439e-05, gnorm=11.375, clip=100, loss_scale=64, train_wall=18, gb_free=11.8, wall=56533
2023-05-26 15:05:37 - progress_bar.py[line:272] - INFO: epoch 018:    698 / 1732 loss=2.201, loss_v1=0, loss_v2=0, nll_loss=0.98, ntokens=1001.9, nsentences=32, sample_size=1001.9, sample_size_v1=0, sample_size_v2=0, ppl=1.97, wps=537, ups=0.54, wpb=1001.9, bsz=32, num_updates=30090, lr=1.34328e-05, gnorm=10.737, clip=100, loss_scale=64, train_wall=19, gb_free=11.7, wall=56551
2023-05-26 15:05:55 - progress_bar.py[line:272] - INFO: epoch 018:    708 / 1732 loss=2.187, loss_v1=0, loss_v2=0, nll_loss=0.965, ntokens=907.1, nsentences=32, sample_size=907.1, sample_size_v1=0, sample_size_v2=0, ppl=1.95, wps=492.6, ups=0.54, wpb=907.1, bsz=32, num_updates=30100, lr=1.34267e-05, gnorm=11.126, clip=100, loss_scale=64, train_wall=18, gb_free=11.7, wall=56570
2023-05-26 15:06:13 - progress_bar.py[line:272] - INFO: epoch 018:    718 / 1732 loss=2.191, loss_v1=0, loss_v2=0, nll_loss=0.97, ntokens=882, nsentences=32, sample_size=882, sample_size_v1=0, sample_size_v2=0, ppl=1.96, wps=479.9, ups=0.54, wpb=882, bsz=32, num_updates=30110, lr=1.34206e-05, gnorm=10.668, clip=100, loss_scale=64, train_wall=18, gb_free=12, wall=56588
2023-05-26 15:06:32 - progress_bar.py[line:272] - INFO: epoch 018:    728 / 1732 loss=2.179, loss_v1=0, loss_v2=0, nll_loss=0.957, ntokens=917.5, nsentences=32, sample_size=917.5, sample_size_v1=0, sample_size_v2=0, ppl=1.94, wps=496.3, ups=0.54, wpb=917.5, bsz=32, num_updates=30120, lr=1.34144e-05, gnorm=10.965, clip=100, loss_scale=64, train_wall=18, gb_free=11.5, wall=56607
2023-05-26 15:06:50 - progress_bar.py[line:272] - INFO: epoch 018:    738 / 1732 loss=2.202, loss_v1=0, loss_v2=0, nll_loss=0.984, ntokens=991.8, nsentences=32, sample_size=991.8, sample_size_v1=0, sample_size_v2=0, ppl=1.98, wps=538.6, ups=0.54, wpb=991.8, bsz=32, num_updates=30130, lr=1.34083e-05, gnorm=10.646, clip=100, loss_scale=64, train_wall=18, gb_free=11.6, wall=56625
2023-05-26 15:07:09 - progress_bar.py[line:272] - INFO: epoch 018:    748 / 1732 loss=2.198, loss_v1=0, loss_v2=0, nll_loss=0.977, ntokens=986.3, nsentences=32, sample_size=986.3, sample_size_v1=0, sample_size_v2=0, ppl=1.97, wps=530.4, ups=0.54, wpb=986.3, bsz=32, num_updates=30140, lr=1.34021e-05, gnorm=10.973, clip=100, loss_scale=64, train_wall=19, gb_free=11.6, wall=56644
2023-05-26 15:07:27 - progress_bar.py[line:272] - INFO: epoch 018:    758 / 1732 loss=2.171, loss_v1=0, loss_v2=0, nll_loss=0.946, ntokens=946.6, nsentences=32, sample_size=946.6, sample_size_v1=0, sample_size_v2=0, ppl=1.93, wps=513, ups=0.54, wpb=946.6, bsz=32, num_updates=30150, lr=1.3396e-05, gnorm=10.413, clip=100, loss_scale=64, train_wall=18, gb_free=11.4, wall=56662
2023-05-26 15:07:46 - progress_bar.py[line:272] - INFO: epoch 018:    768 / 1732 loss=2.192, loss_v1=0, loss_v2=0, nll_loss=0.971, ntokens=947.6, nsentences=32, sample_size=947.6, sample_size_v1=0, sample_size_v2=0, ppl=1.96, wps=514.2, ups=0.54, wpb=947.6, bsz=32, num_updates=30160, lr=1.33898e-05, gnorm=11.093, clip=100, loss_scale=64, train_wall=18, gb_free=11.3, wall=56680
2023-05-26 15:08:04 - progress_bar.py[line:272] - INFO: epoch 018:    778 / 1732 loss=2.19, loss_v1=0, loss_v2=0, nll_loss=0.97, ntokens=1017.6, nsentences=32, sample_size=1017.6, sample_size_v1=0, sample_size_v2=0, ppl=1.96, wps=549.8, ups=0.54, wpb=1017.6, bsz=32, num_updates=30170, lr=1.33837e-05, gnorm=10.186, clip=100, loss_scale=64, train_wall=18, gb_free=12, wall=56699
2023-05-26 15:08:23 - progress_bar.py[line:272] - INFO: epoch 018:    788 / 1732 loss=2.206, loss_v1=0, loss_v2=0, nll_loss=0.985, ntokens=1010.8, nsentences=32, sample_size=1010.8, sample_size_v1=0, sample_size_v2=0, ppl=1.98, wps=546.2, ups=0.54, wpb=1010.8, bsz=32, num_updates=30180, lr=1.33776e-05, gnorm=10.794, clip=100, loss_scale=64, train_wall=18, gb_free=11.3, wall=56717
2023-05-26 15:08:30 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2023-05-26 15:08:43 - progress_bar.py[line:272] - INFO: epoch 018:    799 / 1732 loss=2.21, loss_v1=0, loss_v2=0, nll_loss=0.989, ntokens=1042.1, nsentences=32, sample_size=1042.1, sample_size_v1=0, sample_size_v2=0, ppl=1.99, wps=514.2, ups=0.49, wpb=1042.1, bsz=32, num_updates=30190, lr=1.33714e-05, gnorm=11.347, clip=100, loss_scale=32, train_wall=20, gb_free=11.4, wall=56738
2023-05-26 15:09:02 - progress_bar.py[line:272] - INFO: epoch 018:    809 / 1732 loss=2.199, loss_v1=0, loss_v2=0, nll_loss=0.978, ntokens=922.8, nsentences=32, sample_size=922.8, sample_size_v1=0, sample_size_v2=0, ppl=1.97, wps=499.7, ups=0.54, wpb=922.8, bsz=32, num_updates=30200, lr=1.33653e-05, gnorm=11.595, clip=100, loss_scale=32, train_wall=18, gb_free=11.7, wall=56756
2023-05-26 15:09:20 - progress_bar.py[line:272] - INFO: epoch 018:    819 / 1732 loss=2.209, loss_v1=0, loss_v2=0, nll_loss=0.991, ntokens=909.6, nsentences=32, sample_size=909.6, sample_size_v1=0, sample_size_v2=0, ppl=1.99, wps=492.3, ups=0.54, wpb=909.6, bsz=32, num_updates=30210, lr=1.33591e-05, gnorm=11.908, clip=100, loss_scale=32, train_wall=18, gb_free=11.8, wall=56775
2023-05-26 15:09:39 - progress_bar.py[line:272] - INFO: epoch 018:    829 / 1732 loss=2.182, loss_v1=0, loss_v2=0, nll_loss=0.959, ntokens=917.4, nsentences=32, sample_size=917.4, sample_size_v1=0, sample_size_v2=0, ppl=1.94, wps=495.9, ups=0.54, wpb=917.4, bsz=32, num_updates=30220, lr=1.3353e-05, gnorm=11.538, clip=100, loss_scale=32, train_wall=18, gb_free=11.8, wall=56793
2023-05-26 15:09:57 - progress_bar.py[line:272] - INFO: epoch 018:    839 / 1732 loss=2.204, loss_v1=0, loss_v2=0, nll_loss=0.984, ntokens=902.5, nsentences=32, sample_size=902.5, sample_size_v1=0, sample_size_v2=0, ppl=1.98, wps=493.1, ups=0.55, wpb=902.5, bsz=32, num_updates=30230, lr=1.33468e-05, gnorm=11.676, clip=100, loss_scale=32, train_wall=18, gb_free=11.8, wall=56811
2023-05-26 15:10:15 - progress_bar.py[line:272] - INFO: epoch 018:    849 / 1732 loss=2.198, loss_v1=0, loss_v2=0, nll_loss=0.978, ntokens=1036.8, nsentences=32, sample_size=1036.8, sample_size_v1=0, sample_size_v2=0, ppl=1.97, wps=559, ups=0.54, wpb=1036.8, bsz=32, num_updates=30240, lr=1.33407e-05, gnorm=11.028, clip=100, loss_scale=32, train_wall=19, gb_free=11.4, wall=56830
2023-05-26 15:10:34 - progress_bar.py[line:272] - INFO: epoch 018:    859 / 1732 loss=2.185, loss_v1=0, loss_v2=0, nll_loss=0.963, ntokens=930.3, nsentences=32, sample_size=930.3, sample_size_v1=0, sample_size_v2=0, ppl=1.95, wps=505, ups=0.54, wpb=930.3, bsz=32, num_updates=30250, lr=1.33346e-05, gnorm=11.548, clip=100, loss_scale=32, train_wall=18, gb_free=11.4, wall=56848
2023-05-26 15:10:52 - progress_bar.py[line:272] - INFO: epoch 018:    869 / 1732 loss=2.208, loss_v1=0, loss_v2=0, nll_loss=0.99, ntokens=962.2, nsentences=32, sample_size=962.2, sample_size_v1=0, sample_size_v2=0, ppl=1.99, wps=520.8, ups=0.54, wpb=962.2, bsz=32, num_updates=30260, lr=1.33284e-05, gnorm=11.698, clip=100, loss_scale=32, train_wall=18, gb_free=11.6, wall=56867
2023-05-26 15:11:11 - progress_bar.py[line:272] - INFO: epoch 018:    879 / 1732 loss=2.136, loss_v1=0, loss_v2=0, nll_loss=0.909, ntokens=1001.9, nsentences=32, sample_size=1001.9, sample_size_v1=0, sample_size_v2=0, ppl=1.88, wps=539.8, ups=0.54, wpb=1001.9, bsz=32, num_updates=30270, lr=1.33223e-05, gnorm=10.433, clip=100, loss_scale=32, train_wall=19, gb_free=11.7, wall=56886
2023-05-26 15:11:29 - progress_bar.py[line:272] - INFO: epoch 018:    889 / 1732 loss=2.137, loss_v1=0, loss_v2=0, nll_loss=0.911, ntokens=975.7, nsentences=32, sample_size=975.7, sample_size_v1=0, sample_size_v2=0, ppl=1.88, wps=526.5, ups=0.54, wpb=975.7, bsz=32, num_updates=30280, lr=1.33161e-05, gnorm=10.392, clip=100, loss_scale=32, train_wall=19, gb_free=11.6, wall=56904
2023-05-26 15:11:48 - progress_bar.py[line:272] - INFO: epoch 018:    899 / 1732 loss=2.144, loss_v1=0, loss_v2=0, nll_loss=0.917, ntokens=1055.9, nsentences=32, sample_size=1055.9, sample_size_v1=0, sample_size_v2=0, ppl=1.89, wps=567.4, ups=0.54, wpb=1055.9, bsz=32, num_updates=30290, lr=1.331e-05, gnorm=10.526, clip=100, loss_scale=32, train_wall=19, gb_free=11.1, wall=56923
2023-05-26 15:12:07 - progress_bar.py[line:272] - INFO: epoch 018:    909 / 1732 loss=2.173, loss_v1=0, loss_v2=0, nll_loss=0.949, ntokens=975.2, nsentences=32, sample_size=975.2, sample_size_v1=0, sample_size_v2=0, ppl=1.93, wps=527.1, ups=0.54, wpb=975.2, bsz=32, num_updates=30300, lr=1.33039e-05, gnorm=10.531, clip=100, loss_scale=32, train_wall=18, gb_free=11.8, wall=56941
2023-05-26 15:12:25 - progress_bar.py[line:272] - INFO: epoch 018:    919 / 1732 loss=2.211, loss_v1=0, loss_v2=0, nll_loss=0.992, ntokens=988.7, nsentences=32, sample_size=988.7, sample_size_v1=0, sample_size_v2=0, ppl=1.99, wps=532, ups=0.54, wpb=988.7, bsz=32, num_updates=30310, lr=1.32977e-05, gnorm=11.495, clip=100, loss_scale=32, train_wall=19, gb_free=11, wall=56960
2023-05-26 15:12:44 - progress_bar.py[line:272] - INFO: epoch 018:    929 / 1732 loss=2.167, loss_v1=0, loss_v2=0, nll_loss=0.942, ntokens=1019.8, nsentences=32, sample_size=1019.8, sample_size_v1=0, sample_size_v2=0, ppl=1.92, wps=546.6, ups=0.54, wpb=1019.8, bsz=32, num_updates=30320, lr=1.32916e-05, gnorm=10.86, clip=100, loss_scale=32, train_wall=19, gb_free=10.9, wall=56978
2023-05-26 15:13:03 - progress_bar.py[line:272] - INFO: epoch 018:    939 / 1732 loss=2.193, loss_v1=0, loss_v2=0, nll_loss=0.973, ntokens=1047.7, nsentences=32, sample_size=1047.7, sample_size_v1=0, sample_size_v2=0, ppl=1.96, wps=552.5, ups=0.53, wpb=1047.7, bsz=32, num_updates=30330, lr=1.32854e-05, gnorm=11.094, clip=100, loss_scale=32, train_wall=19, gb_free=11.2, wall=56997
2023-05-26 15:13:22 - progress_bar.py[line:272] - INFO: epoch 018:    949 / 1732 loss=2.193, loss_v1=0, loss_v2=0, nll_loss=0.974, ntokens=1037.9, nsentences=32, sample_size=1037.9, sample_size_v1=0, sample_size_v2=0, ppl=1.96, wps=552.4, ups=0.53, wpb=1037.9, bsz=32, num_updates=30340, lr=1.32793e-05, gnorm=11.01, clip=100, loss_scale=32, train_wall=19, gb_free=11.3, wall=57016
2023-05-26 15:13:40 - progress_bar.py[line:272] - INFO: epoch 018:    959 / 1732 loss=2.182, loss_v1=0, loss_v2=0, nll_loss=0.958, ntokens=1070.6, nsentences=32, sample_size=1070.6, sample_size_v1=0, sample_size_v2=0, ppl=1.94, wps=570.2, ups=0.53, wpb=1070.6, bsz=32, num_updates=30350, lr=1.32731e-05, gnorm=10.87, clip=100, loss_scale=32, train_wall=19, gb_free=11.2, wall=57035
2023-05-26 15:13:59 - progress_bar.py[line:272] - INFO: epoch 018:    969 / 1732 loss=2.21, loss_v1=0, loss_v2=0, nll_loss=0.99, ntokens=1025.9, nsentences=32, sample_size=1025.9, sample_size_v1=0, sample_size_v2=0, ppl=1.99, wps=549, ups=0.54, wpb=1025.9, bsz=32, num_updates=30360, lr=1.3267e-05, gnorm=11.573, clip=100, loss_scale=32, train_wall=19, gb_free=11.3, wall=57054
2023-05-26 15:14:18 - progress_bar.py[line:272] - INFO: epoch 018:    979 / 1732 loss=2.174, loss_v1=0, loss_v2=0, nll_loss=0.951, ntokens=1025.3, nsentences=32, sample_size=1025.3, sample_size_v1=0, sample_size_v2=0, ppl=1.93, wps=543.7, ups=0.53, wpb=1025.3, bsz=32, num_updates=30370, lr=1.32609e-05, gnorm=10.484, clip=100, loss_scale=32, train_wall=19, gb_free=11, wall=57073
2023-05-26 15:14:37 - progress_bar.py[line:272] - INFO: epoch 018:    989 / 1732 loss=2.181, loss_v1=0, loss_v2=0, nll_loss=0.959, ntokens=1057.2, nsentences=32, sample_size=1057.2, sample_size_v1=0, sample_size_v2=0, ppl=1.94, wps=560.2, ups=0.53, wpb=1057.2, bsz=32, num_updates=30380, lr=1.32547e-05, gnorm=10.256, clip=100, loss_scale=32, train_wall=19, gb_free=11.1, wall=57091
2023-05-26 15:14:55 - progress_bar.py[line:272] - INFO: epoch 018:    999 / 1732 loss=2.185, loss_v1=0, loss_v2=0, nll_loss=0.962, ntokens=989.7, nsentences=32, sample_size=989.7, sample_size_v1=0, sample_size_v2=0, ppl=1.95, wps=531.2, ups=0.54, wpb=989.7, bsz=32, num_updates=30390, lr=1.32486e-05, gnorm=11.143, clip=100, loss_scale=32, train_wall=19, gb_free=11.8, wall=57110
2023-05-26 15:15:14 - progress_bar.py[line:272] - INFO: epoch 018:   1009 / 1732 loss=2.194, loss_v1=0, loss_v2=0, nll_loss=0.973, ntokens=1040.9, nsentences=32, sample_size=1040.9, sample_size_v1=0, sample_size_v2=0, ppl=1.96, wps=556.4, ups=0.53, wpb=1040.9, bsz=32, num_updates=30400, lr=1.32424e-05, gnorm=11.947, clip=100, loss_scale=32, train_wall=19, gb_free=10.8, wall=57129
2023-05-26 15:15:33 - progress_bar.py[line:272] - INFO: epoch 018:   1019 / 1732 loss=2.162, loss_v1=0, loss_v2=0, nll_loss=0.938, ntokens=1021.6, nsentences=32, sample_size=1021.6, sample_size_v1=0, sample_size_v2=0, ppl=1.92, wps=547.4, ups=0.54, wpb=1021.6, bsz=32, num_updates=30410, lr=1.32363e-05, gnorm=10.768, clip=100, loss_scale=32, train_wall=19, gb_free=11.3, wall=57147
2023-05-26 15:15:52 - progress_bar.py[line:272] - INFO: epoch 018:   1029 / 1732 loss=2.184, loss_v1=0, loss_v2=0, nll_loss=0.961, ntokens=1092, nsentences=32, sample_size=1092, sample_size_v1=0, sample_size_v2=0, ppl=1.95, wps=573.8, ups=0.53, wpb=1092, bsz=32, num_updates=30420, lr=1.32301e-05, gnorm=10.637, clip=100, loss_scale=32, train_wall=19, gb_free=10.6, wall=57166
2023-05-26 15:16:11 - progress_bar.py[line:272] - INFO: epoch 018:   1039 / 1732 loss=2.196, loss_v1=0, loss_v2=0, nll_loss=0.975, ntokens=1077.1, nsentences=32, sample_size=1077.1, sample_size_v1=0, sample_size_v2=0, ppl=1.97, wps=573.3, ups=0.53, wpb=1077.1, bsz=32, num_updates=30430, lr=1.3224e-05, gnorm=11.255, clip=100, loss_scale=32, train_wall=19, gb_free=10.9, wall=57185
2023-05-26 15:16:29 - progress_bar.py[line:272] - INFO: epoch 018:   1049 / 1732 loss=2.175, loss_v1=0, loss_v2=0, nll_loss=0.952, ntokens=1018.7, nsentences=32, sample_size=1018.7, sample_size_v1=0, sample_size_v2=0, ppl=1.93, wps=544.1, ups=0.53, wpb=1018.7, bsz=32, num_updates=30440, lr=1.32179e-05, gnorm=11.915, clip=100, loss_scale=32, train_wall=19, gb_free=11.5, wall=57204
2023-05-26 15:16:48 - progress_bar.py[line:272] - INFO: epoch 018:   1059 / 1732 loss=2.183, loss_v1=0, loss_v2=0, nll_loss=0.961, ntokens=1090.9, nsentences=32, sample_size=1090.9, sample_size_v1=0, sample_size_v2=0, ppl=1.95, wps=580, ups=0.53, wpb=1090.9, bsz=32, num_updates=30450, lr=1.32117e-05, gnorm=10.244, clip=100, loss_scale=32, train_wall=19, gb_free=11.5, wall=57223
2023-05-26 15:17:07 - progress_bar.py[line:272] - INFO: epoch 018:   1069 / 1732 loss=2.174, loss_v1=0, loss_v2=0, nll_loss=0.952, ntokens=979.2, nsentences=32, sample_size=979.2, sample_size_v1=0, sample_size_v2=0, ppl=1.93, wps=524.4, ups=0.54, wpb=979.2, bsz=32, num_updates=30460, lr=1.32056e-05, gnorm=11.857, clip=100, loss_scale=32, train_wall=19, gb_free=11.3, wall=57241
2023-05-26 15:17:26 - progress_bar.py[line:272] - INFO: epoch 018:   1079 / 1732 loss=2.196, loss_v1=0, loss_v2=0, nll_loss=0.976, ntokens=1044.7, nsentences=32, sample_size=1044.7, sample_size_v1=0, sample_size_v2=0, ppl=1.97, wps=554.1, ups=0.53, wpb=1044.7, bsz=32, num_updates=30470, lr=1.31994e-05, gnorm=11.791, clip=100, loss_scale=32, train_wall=19, gb_free=11, wall=57260
2023-05-26 15:17:45 - progress_bar.py[line:272] - INFO: epoch 018:   1089 / 1732 loss=2.181, loss_v1=0, loss_v2=0, nll_loss=0.958, ntokens=1065.4, nsentences=32, sample_size=1065.4, sample_size_v1=0, sample_size_v2=0, ppl=1.94, wps=562.6, ups=0.53, wpb=1065.4, bsz=32, num_updates=30480, lr=1.31933e-05, gnorm=11.472, clip=100, loss_scale=32, train_wall=19, gb_free=11.4, wall=57279
2023-05-26 15:18:03 - progress_bar.py[line:272] - INFO: epoch 018:   1099 / 1732 loss=2.19, loss_v1=0, loss_v2=0, nll_loss=0.968, ntokens=1034.8, nsentences=32, sample_size=1034.8, sample_size_v1=0, sample_size_v2=0, ppl=1.96, wps=552.1, ups=0.53, wpb=1034.8, bsz=32, num_updates=30490, lr=1.31872e-05, gnorm=11.001, clip=100, loss_scale=32, train_wall=19, gb_free=10.5, wall=57298
2023-05-26 15:18:22 - progress_bar.py[line:272] - INFO: epoch 018:   1109 / 1732 loss=2.179, loss_v1=0, loss_v2=0, nll_loss=0.955, ntokens=1058.4, nsentences=32, sample_size=1058.4, sample_size_v1=0, sample_size_v2=0, ppl=1.94, wps=561.7, ups=0.53, wpb=1058.4, bsz=32, num_updates=30500, lr=1.3181e-05, gnorm=10.863, clip=100, loss_scale=32, train_wall=19, gb_free=10.4, wall=57317
2023-05-26 15:18:41 - progress_bar.py[line:272] - INFO: epoch 018:   1119 / 1732 loss=2.178, loss_v1=0, loss_v2=0, nll_loss=0.955, ntokens=966, nsentences=32, sample_size=966, sample_size_v1=0, sample_size_v2=0, ppl=1.94, wps=513.1, ups=0.53, wpb=966, bsz=32, num_updates=30510, lr=1.31749e-05, gnorm=11.111, clip=100, loss_scale=32, train_wall=19, gb_free=10.9, wall=57336
2023-05-26 15:19:00 - progress_bar.py[line:272] - INFO: epoch 018:   1129 / 1732 loss=2.173, loss_v1=0, loss_v2=0, nll_loss=0.949, ntokens=1007.5, nsentences=32, sample_size=1007.5, sample_size_v1=0, sample_size_v2=0, ppl=1.93, wps=537.3, ups=0.53, wpb=1007.5, bsz=32, num_updates=30520, lr=1.31687e-05, gnorm=10.786, clip=100, loss_scale=32, train_wall=19, gb_free=11.4, wall=57354
2023-05-26 15:19:18 - progress_bar.py[line:272] - INFO: epoch 018:   1139 / 1732 loss=2.183, loss_v1=0, loss_v2=0, nll_loss=0.96, ntokens=999.7, nsentences=32, sample_size=999.7, sample_size_v1=0, sample_size_v2=0, ppl=1.95, wps=535, ups=0.54, wpb=999.7, bsz=32, num_updates=30530, lr=1.31626e-05, gnorm=11.225, clip=100, loss_scale=32, train_wall=19, gb_free=11.1, wall=57373
2023-05-26 15:19:37 - progress_bar.py[line:272] - INFO: epoch 018:   1149 / 1732 loss=2.164, loss_v1=0, loss_v2=0, nll_loss=0.94, ntokens=999, nsentences=32, sample_size=999, sample_size_v1=0, sample_size_v2=0, ppl=1.92, wps=533.6, ups=0.53, wpb=999, bsz=32, num_updates=30540, lr=1.31564e-05, gnorm=11.051, clip=100, loss_scale=32, train_wall=19, gb_free=11.4, wall=57392
2023-05-26 15:19:56 - progress_bar.py[line:272] - INFO: epoch 018:   1159 / 1732 loss=2.156, loss_v1=0, loss_v2=0, nll_loss=0.932, ntokens=1014.2, nsentences=32, sample_size=1014.2, sample_size_v1=0, sample_size_v2=0, ppl=1.91, wps=539.9, ups=0.53, wpb=1014.2, bsz=32, num_updates=30550, lr=1.31503e-05, gnorm=11.289, clip=100, loss_scale=32, train_wall=19, gb_free=11.5, wall=57411
2023-05-26 15:20:15 - progress_bar.py[line:272] - INFO: epoch 018:   1169 / 1732 loss=2.153, loss_v1=0, loss_v2=0, nll_loss=0.928, ntokens=1031, nsentences=32, sample_size=1031, sample_size_v1=0, sample_size_v2=0, ppl=1.9, wps=548.7, ups=0.53, wpb=1031, bsz=32, num_updates=30560, lr=1.31442e-05, gnorm=10.429, clip=100, loss_scale=32, train_wall=19, gb_free=11.1, wall=57429
2023-05-26 15:20:33 - progress_bar.py[line:272] - INFO: epoch 018:   1179 / 1732 loss=2.158, loss_v1=0, loss_v2=0, nll_loss=0.933, ntokens=1057.9, nsentences=32, sample_size=1057.9, sample_size_v1=0, sample_size_v2=0, ppl=1.91, wps=566, ups=0.54, wpb=1057.9, bsz=32, num_updates=30570, lr=1.3138e-05, gnorm=11.445, clip=100, loss_scale=32, train_wall=19, gb_free=11.6, wall=57448
2023-05-26 15:20:52 - progress_bar.py[line:272] - INFO: epoch 018:   1189 / 1732 loss=2.166, loss_v1=0, loss_v2=0, nll_loss=0.942, ntokens=993.6, nsentences=32, sample_size=993.6, sample_size_v1=0, sample_size_v2=0, ppl=1.92, wps=529.5, ups=0.53, wpb=993.6, bsz=32, num_updates=30580, lr=1.31319e-05, gnorm=11.222, clip=100, loss_scale=32, train_wall=19, gb_free=11, wall=57467
2023-05-26 15:21:11 - progress_bar.py[line:272] - INFO: epoch 018:   1199 / 1732 loss=2.164, loss_v1=0, loss_v2=0, nll_loss=0.939, ntokens=1103.9, nsentences=32, sample_size=1103.9, sample_size_v1=0, sample_size_v2=0, ppl=1.92, wps=586, ups=0.53, wpb=1103.9, bsz=32, num_updates=30590, lr=1.31257e-05, gnorm=11.193, clip=100, loss_scale=32, train_wall=19, gb_free=10.8, wall=57486
2023-05-26 15:21:30 - progress_bar.py[line:272] - INFO: epoch 018:   1209 / 1732 loss=2.157, loss_v1=0, loss_v2=0, nll_loss=0.932, ntokens=1079.5, nsentences=32, sample_size=1079.5, sample_size_v1=0, sample_size_v2=0, ppl=1.91, wps=571.6, ups=0.53, wpb=1079.5, bsz=32, num_updates=30600, lr=1.31196e-05, gnorm=10.159, clip=100, loss_scale=32, train_wall=19, gb_free=11.2, wall=57505
2023-05-26 15:21:49 - progress_bar.py[line:272] - INFO: epoch 018:   1219 / 1732 loss=2.211, loss_v1=0, loss_v2=0, nll_loss=0.992, ntokens=1009.3, nsentences=32, sample_size=1009.3, sample_size_v1=0, sample_size_v2=0, ppl=1.99, wps=539.6, ups=0.53, wpb=1009.3, bsz=32, num_updates=30610, lr=1.31134e-05, gnorm=11.805, clip=100, loss_scale=32, train_wall=19, gb_free=11.3, wall=57523
2023-05-26 15:22:07 - progress_bar.py[line:272] - INFO: epoch 018:   1229 / 1732 loss=2.171, loss_v1=0, loss_v2=0, nll_loss=0.947, ntokens=1052.5, nsentences=32, sample_size=1052.5, sample_size_v1=0, sample_size_v2=0, ppl=1.93, wps=560.6, ups=0.53, wpb=1052.5, bsz=32, num_updates=30620, lr=1.31073e-05, gnorm=11.328, clip=100, loss_scale=32, train_wall=19, gb_free=11.1, wall=57542
2023-05-26 15:22:26 - progress_bar.py[line:272] - INFO: epoch 018:   1239 / 1732 loss=2.14, loss_v1=0, loss_v2=0, nll_loss=0.912, ntokens=1065.1, nsentences=32, sample_size=1065.1, sample_size_v1=0, sample_size_v2=0, ppl=1.88, wps=565.7, ups=0.53, wpb=1065.1, bsz=32, num_updates=30630, lr=1.31012e-05, gnorm=10.637, clip=100, loss_scale=32, train_wall=19, gb_free=10.7, wall=57561
2023-05-26 15:22:45 - progress_bar.py[line:272] - INFO: epoch 018:   1249 / 1732 loss=2.139, loss_v1=0, loss_v2=0, nll_loss=0.911, ntokens=1065.4, nsentences=32, sample_size=1065.4, sample_size_v1=0, sample_size_v2=0, ppl=1.88, wps=566, ups=0.53, wpb=1065.4, bsz=32, num_updates=30640, lr=1.3095e-05, gnorm=11.14, clip=100, loss_scale=32, train_wall=19, gb_free=11.5, wall=57580
2023-05-26 15:23:04 - progress_bar.py[line:272] - INFO: epoch 018:   1259 / 1732 loss=2.163, loss_v1=0, loss_v2=0, nll_loss=0.939, ntokens=1045.9, nsentences=32, sample_size=1045.9, sample_size_v1=0, sample_size_v2=0, ppl=1.92, wps=557.2, ups=0.53, wpb=1045.9, bsz=32, num_updates=30650, lr=1.30889e-05, gnorm=11.138, clip=100, loss_scale=32, train_wall=19, gb_free=11.5, wall=57599
2023-05-26 15:23:23 - progress_bar.py[line:272] - INFO: epoch 018:   1269 / 1732 loss=2.177, loss_v1=0, loss_v2=0, nll_loss=0.955, ntokens=1069.2, nsentences=32, sample_size=1069.2, sample_size_v1=0, sample_size_v2=0, ppl=1.94, wps=568.3, ups=0.53, wpb=1069.2, bsz=32, num_updates=30660, lr=1.30827e-05, gnorm=10.605, clip=100, loss_scale=32, train_wall=19, gb_free=11.4, wall=57617
2023-05-26 15:23:42 - progress_bar.py[line:272] - INFO: epoch 018:   1279 / 1732 loss=2.163, loss_v1=0, loss_v2=0, nll_loss=0.938, ntokens=1067, nsentences=32, sample_size=1067, sample_size_v1=0, sample_size_v2=0, ppl=1.92, wps=565.2, ups=0.53, wpb=1067, bsz=32, num_updates=30670, lr=1.30766e-05, gnorm=9.867, clip=100, loss_scale=32, train_wall=19, gb_free=10.9, wall=57636
2023-05-26 15:24:00 - progress_bar.py[line:272] - INFO: epoch 018:   1289 / 1732 loss=2.151, loss_v1=0, loss_v2=0, nll_loss=0.923, ntokens=1071, nsentences=32, sample_size=1071, sample_size_v1=0, sample_size_v2=0, ppl=1.9, wps=565.2, ups=0.53, wpb=1071, bsz=32, num_updates=30680, lr=1.30705e-05, gnorm=9.981, clip=100, loss_scale=32, train_wall=19, gb_free=10.4, wall=57655
2023-05-26 15:24:19 - progress_bar.py[line:272] - INFO: epoch 018:   1299 / 1732 loss=2.161, loss_v1=0, loss_v2=0, nll_loss=0.937, ntokens=1078.1, nsentences=32, sample_size=1078.1, sample_size_v1=0, sample_size_v2=0, ppl=1.91, wps=574.9, ups=0.53, wpb=1078.1, bsz=32, num_updates=30690, lr=1.30643e-05, gnorm=10.366, clip=100, loss_scale=32, train_wall=19, gb_free=11.4, wall=57674
2023-05-26 15:24:38 - progress_bar.py[line:272] - INFO: epoch 018:   1309 / 1732 loss=2.208, loss_v1=0, loss_v2=0, nll_loss=0.989, ntokens=1085.2, nsentences=32, sample_size=1085.2, sample_size_v1=0, sample_size_v2=0, ppl=1.98, wps=570.4, ups=0.53, wpb=1085.2, bsz=32, num_updates=30700, lr=1.30582e-05, gnorm=10.503, clip=100, loss_scale=64, train_wall=19, gb_free=10.9, wall=57693
2023-05-26 15:24:57 - progress_bar.py[line:272] - INFO: epoch 018:   1319 / 1732 loss=2.167, loss_v1=0, loss_v2=0, nll_loss=0.942, ntokens=1092.6, nsentences=32, sample_size=1092.6, sample_size_v1=0, sample_size_v2=0, ppl=1.92, wps=578.6, ups=0.53, wpb=1092.6, bsz=32, num_updates=30710, lr=1.3052e-05, gnorm=10.154, clip=100, loss_scale=64, train_wall=19, gb_free=10.9, wall=57712
2023-05-26 15:25:16 - progress_bar.py[line:272] - INFO: epoch 018:   1329 / 1732 loss=2.137, loss_v1=0, loss_v2=0, nll_loss=0.91, ntokens=1106.3, nsentences=32, sample_size=1106.3, sample_size_v1=0, sample_size_v2=0, ppl=1.88, wps=583.7, ups=0.53, wpb=1106.3, bsz=32, num_updates=30720, lr=1.30459e-05, gnorm=10.327, clip=100, loss_scale=64, train_wall=19, gb_free=11.3, wall=57731
2023-05-26 15:25:29 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2023-05-26 15:25:37 - progress_bar.py[line:272] - INFO: epoch 018:   1340 / 1732 loss=2.157, loss_v1=0, loss_v2=0, nll_loss=0.93, ntokens=1129.9, nsentences=32, sample_size=1129.9, sample_size_v1=0, sample_size_v2=0, ppl=1.91, wps=545.9, ups=0.48, wpb=1129.9, bsz=32, num_updates=30730, lr=1.30397e-05, gnorm=10.658, clip=100, loss_scale=32, train_wall=21, gb_free=11.2, wall=57751
2023-05-26 15:25:56 - progress_bar.py[line:272] - INFO: epoch 018:   1350 / 1732 loss=2.159, loss_v1=0, loss_v2=0, nll_loss=0.934, ntokens=1168.9, nsentences=32, sample_size=1168.9, sample_size_v1=0, sample_size_v2=0, ppl=1.91, wps=616.5, ups=0.53, wpb=1168.9, bsz=32, num_updates=30740, lr=1.30336e-05, gnorm=10.076, clip=100, loss_scale=32, train_wall=19, gb_free=11.2, wall=57770
2023-05-26 15:26:15 - progress_bar.py[line:272] - INFO: epoch 018:   1360 / 1732 loss=2.137, loss_v1=0, loss_v2=0, nll_loss=0.909, ntokens=1107.8, nsentences=32, sample_size=1107.8, sample_size_v1=0, sample_size_v2=0, ppl=1.88, wps=584.2, ups=0.53, wpb=1107.8, bsz=32, num_updates=30750, lr=1.30275e-05, gnorm=10.562, clip=100, loss_scale=32, train_wall=19, gb_free=10.8, wall=57789
2023-05-26 15:26:34 - progress_bar.py[line:272] - INFO: epoch 018:   1370 / 1732 loss=2.176, loss_v1=0, loss_v2=0, nll_loss=0.951, ntokens=1111.1, nsentences=32, sample_size=1111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.93, wps=589, ups=0.53, wpb=1111.1, bsz=32, num_updates=30760, lr=1.30213e-05, gnorm=11.422, clip=100, loss_scale=32, train_wall=19, gb_free=11.1, wall=57808
2023-05-26 15:26:52 - progress_bar.py[line:272] - INFO: epoch 018:   1380 / 1732 loss=2.189, loss_v1=0, loss_v2=0, nll_loss=0.966, ntokens=1113.4, nsentences=32, sample_size=1113.4, sample_size_v1=0, sample_size_v2=0, ppl=1.95, wps=593.2, ups=0.53, wpb=1113.4, bsz=32, num_updates=30770, lr=1.30152e-05, gnorm=11.355, clip=100, loss_scale=32, train_wall=19, gb_free=10.5, wall=57827
2023-05-26 15:27:11 - progress_bar.py[line:272] - INFO: epoch 018:   1390 / 1732 loss=2.176, loss_v1=0, loss_v2=0, nll_loss=0.952, ntokens=1104, nsentences=32, sample_size=1104, sample_size_v1=0, sample_size_v2=0, ppl=1.93, wps=590.1, ups=0.53, wpb=1104, bsz=32, num_updates=30780, lr=1.3009e-05, gnorm=10.424, clip=100, loss_scale=32, train_wall=19, gb_free=11.3, wall=57846
2023-05-26 15:27:30 - progress_bar.py[line:272] - INFO: epoch 018:   1400 / 1732 loss=2.143, loss_v1=0, loss_v2=0, nll_loss=0.917, ntokens=1114.6, nsentences=32, sample_size=1114.6, sample_size_v1=0, sample_size_v2=0, ppl=1.89, wps=590.3, ups=0.53, wpb=1114.6, bsz=32, num_updates=30790, lr=1.30029e-05, gnorm=11.213, clip=100, loss_scale=32, train_wall=19, gb_free=11.1, wall=57865
2023-05-26 15:27:49 - progress_bar.py[line:272] - INFO: epoch 018:   1410 / 1732 loss=2.204, loss_v1=0, loss_v2=0, nll_loss=0.983, ntokens=1192.3, nsentences=32, sample_size=1192.3, sample_size_v1=0, sample_size_v2=0, ppl=1.98, wps=631.8, ups=0.53, wpb=1192.3, bsz=32, num_updates=30800, lr=1.29967e-05, gnorm=11.023, clip=100, loss_scale=32, train_wall=19, gb_free=10.9, wall=57884
2023-05-26 15:28:08 - progress_bar.py[line:272] - INFO: epoch 018:   1420 / 1732 loss=2.191, loss_v1=0, loss_v2=0, nll_loss=0.969, ntokens=1265.6, nsentences=32, sample_size=1265.6, sample_size_v1=0, sample_size_v2=0, ppl=1.96, wps=660.1, ups=0.52, wpb=1265.6, bsz=32, num_updates=30810, lr=1.29906e-05, gnorm=10.12, clip=100, loss_scale=32, train_wall=19, gb_free=11.1, wall=57903
2023-05-26 15:28:27 - progress_bar.py[line:272] - INFO: epoch 018:   1430 / 1732 loss=2.155, loss_v1=0, loss_v2=0, nll_loss=0.929, ntokens=1231, nsentences=32, sample_size=1231, sample_size_v1=0, sample_size_v2=0, ppl=1.9, wps=647.1, ups=0.53, wpb=1231, bsz=32, num_updates=30820, lr=1.29845e-05, gnorm=9.913, clip=100, loss_scale=32, train_wall=19, gb_free=10.2, wall=57922
2023-05-26 15:28:46 - progress_bar.py[line:272] - INFO: epoch 018:   1440 / 1732 loss=2.172, loss_v1=0, loss_v2=0, nll_loss=0.949, ntokens=1169.2, nsentences=32, sample_size=1169.2, sample_size_v1=0, sample_size_v2=0, ppl=1.93, wps=619.8, ups=0.53, wpb=1169.2, bsz=32, num_updates=30830, lr=1.29783e-05, gnorm=10.981, clip=100, loss_scale=32, train_wall=19, gb_free=11.3, wall=57941
2023-05-26 15:29:05 - progress_bar.py[line:272] - INFO: epoch 018:   1450 / 1732 loss=2.16, loss_v1=0, loss_v2=0, nll_loss=0.935, ntokens=1100.3, nsentences=32, sample_size=1100.3, sample_size_v1=0, sample_size_v2=0, ppl=1.91, wps=583.9, ups=0.53, wpb=1100.3, bsz=32, num_updates=30840, lr=1.29722e-05, gnorm=10.332, clip=100, loss_scale=32, train_wall=19, gb_free=11, wall=57959
2023-05-26 15:29:24 - progress_bar.py[line:272] - INFO: epoch 018:   1460 / 1732 loss=2.162, loss_v1=0, loss_v2=0, nll_loss=0.938, ntokens=1171.4, nsentences=32, sample_size=1171.4, sample_size_v1=0, sample_size_v2=0, ppl=1.92, wps=619.1, ups=0.53, wpb=1171.4, bsz=32, num_updates=30850, lr=1.2966e-05, gnorm=10.535, clip=100, loss_scale=32, train_wall=19, gb_free=11.1, wall=57978
2023-05-26 15:29:43 - progress_bar.py[line:272] - INFO: epoch 018:   1470 / 1732 loss=2.155, loss_v1=0, loss_v2=0, nll_loss=0.929, ntokens=1176.9, nsentences=32, sample_size=1176.9, sample_size_v1=0, sample_size_v2=0, ppl=1.9, wps=619.5, ups=0.53, wpb=1176.9, bsz=32, num_updates=30860, lr=1.29599e-05, gnorm=10.724, clip=100, loss_scale=32, train_wall=19, gb_free=9.8, wall=57997
2023-05-26 15:30:01 - progress_bar.py[line:272] - INFO: epoch 018:   1480 / 1732 loss=2.178, loss_v1=0, loss_v2=0, nll_loss=0.956, ntokens=1035.6, nsentences=32, sample_size=1035.6, sample_size_v1=0, sample_size_v2=0, ppl=1.94, wps=553.1, ups=0.53, wpb=1035.6, bsz=32, num_updates=30870, lr=1.29537e-05, gnorm=12.591, clip=100, loss_scale=32, train_wall=19, gb_free=11.3, wall=58016
2023-05-26 15:30:20 - progress_bar.py[line:272] - INFO: epoch 018:   1490 / 1732 loss=2.173, loss_v1=0, loss_v2=0, nll_loss=0.95, ntokens=1129.4, nsentences=32, sample_size=1129.4, sample_size_v1=0, sample_size_v2=0, ppl=1.93, wps=597.6, ups=0.53, wpb=1129.4, bsz=32, num_updates=30880, lr=1.29476e-05, gnorm=11.113, clip=100, loss_scale=32, train_wall=19, gb_free=11.4, wall=58035
2023-05-26 15:30:39 - progress_bar.py[line:272] - INFO: epoch 018:   1500 / 1732 loss=2.146, loss_v1=0, loss_v2=0, nll_loss=0.918, ntokens=1104.6, nsentences=32, sample_size=1104.6, sample_size_v1=0, sample_size_v2=0, ppl=1.89, wps=587.1, ups=0.53, wpb=1104.6, bsz=32, num_updates=30890, lr=1.29415e-05, gnorm=11.059, clip=100, loss_scale=32, train_wall=19, gb_free=11.2, wall=58054
2023-05-26 15:30:58 - progress_bar.py[line:272] - INFO: epoch 018:   1510 / 1732 loss=2.143, loss_v1=0, loss_v2=0, nll_loss=0.915, ntokens=1117.2, nsentences=32, sample_size=1117.2, sample_size_v1=0, sample_size_v2=0, ppl=1.88, wps=594.4, ups=0.53, wpb=1117.2, bsz=32, num_updates=30900, lr=1.29353e-05, gnorm=11.002, clip=100, loss_scale=32, train_wall=19, gb_free=11, wall=58073
2023-05-26 15:31:17 - progress_bar.py[line:272] - INFO: epoch 018:   1520 / 1732 loss=2.187, loss_v1=0, loss_v2=0, nll_loss=0.966, ntokens=1039.7, nsentences=32, sample_size=1039.7, sample_size_v1=0, sample_size_v2=0, ppl=1.95, wps=554.6, ups=0.53, wpb=1039.7, bsz=32, num_updates=30910, lr=1.29292e-05, gnorm=11.757, clip=100, loss_scale=32, train_wall=19, gb_free=11.5, wall=58091
2023-05-26 15:31:36 - progress_bar.py[line:272] - INFO: epoch 018:   1530 / 1732 loss=2.201, loss_v1=0, loss_v2=0, nll_loss=0.982, ntokens=1056.8, nsentences=32, sample_size=1056.8, sample_size_v1=0, sample_size_v2=0, ppl=1.97, wps=561.1, ups=0.53, wpb=1056.8, bsz=32, num_updates=30920, lr=1.2923e-05, gnorm=12.612, clip=100, loss_scale=32, train_wall=19, gb_free=10.6, wall=58110
2023-05-26 15:31:54 - progress_bar.py[line:272] - INFO: epoch 018:   1540 / 1732 loss=2.156, loss_v1=0, loss_v2=0, nll_loss=0.929, ntokens=1106.8, nsentences=32, sample_size=1106.8, sample_size_v1=0, sample_size_v2=0, ppl=1.9, wps=584.9, ups=0.53, wpb=1106.8, bsz=32, num_updates=30930, lr=1.29169e-05, gnorm=10.823, clip=100, loss_scale=32, train_wall=19, gb_free=10.9, wall=58129
2023-05-26 15:32:13 - progress_bar.py[line:272] - INFO: epoch 018:   1550 / 1732 loss=2.144, loss_v1=0, loss_v2=0, nll_loss=0.916, ntokens=1063.7, nsentences=32, sample_size=1063.7, sample_size_v1=0, sample_size_v2=0, ppl=1.89, wps=566.1, ups=0.53, wpb=1063.7, bsz=32, num_updates=30940, lr=1.29108e-05, gnorm=10.377, clip=100, loss_scale=32, train_wall=19, gb_free=10.8, wall=58148
2023-05-26 15:32:32 - progress_bar.py[line:272] - INFO: epoch 018:   1560 / 1732 loss=2.147, loss_v1=0, loss_v2=0, nll_loss=0.922, ntokens=1090.1, nsentences=32, sample_size=1090.1, sample_size_v1=0, sample_size_v2=0, ppl=1.89, wps=581.2, ups=0.53, wpb=1090.1, bsz=32, num_updates=30950, lr=1.29046e-05, gnorm=11.098, clip=100, loss_scale=32, train_wall=19, gb_free=10.4, wall=58167
2023-05-26 15:32:51 - progress_bar.py[line:272] - INFO: epoch 018:   1570 / 1732 loss=2.194, loss_v1=0, loss_v2=0, nll_loss=0.974, ntokens=1073.5, nsentences=32, sample_size=1073.5, sample_size_v1=0, sample_size_v2=0, ppl=1.96, wps=569.9, ups=0.53, wpb=1073.5, bsz=32, num_updates=30960, lr=1.28985e-05, gnorm=12.119, clip=100, loss_scale=32, train_wall=19, gb_free=11.1, wall=58186
2023-05-26 15:33:10 - progress_bar.py[line:272] - INFO: epoch 018:   1580 / 1732 loss=2.17, loss_v1=0, loss_v2=0, nll_loss=0.946, ntokens=980.3, nsentences=32, sample_size=980.3, sample_size_v1=0, sample_size_v2=0, ppl=1.93, wps=523.9, ups=0.53, wpb=980.3, bsz=32, num_updates=30970, lr=1.28923e-05, gnorm=12.261, clip=100, loss_scale=32, train_wall=19, gb_free=11.6, wall=58204
2023-05-26 15:33:28 - progress_bar.py[line:272] - INFO: epoch 018:   1590 / 1732 loss=2.16, loss_v1=0, loss_v2=0, nll_loss=0.935, ntokens=1103, nsentences=32, sample_size=1103, sample_size_v1=0, sample_size_v2=0, ppl=1.91, wps=583.4, ups=0.53, wpb=1103, bsz=32, num_updates=30980, lr=1.28862e-05, gnorm=10.481, clip=100, loss_scale=32, train_wall=19, gb_free=10.6, wall=58223
2023-05-26 15:33:47 - progress_bar.py[line:272] - INFO: epoch 018:   1600 / 1732 loss=2.143, loss_v1=0, loss_v2=0, nll_loss=0.916, ntokens=1067.6, nsentences=32, sample_size=1067.6, sample_size_v1=0, sample_size_v2=0, ppl=1.89, wps=568.8, ups=0.53, wpb=1067.6, bsz=32, num_updates=30990, lr=1.288e-05, gnorm=10.97, clip=100, loss_scale=32, train_wall=19, gb_free=11, wall=58242
2023-05-26 15:34:06 - progress_bar.py[line:272] - INFO: epoch 018:   1610 / 1732 loss=2.139, loss_v1=0, loss_v2=0, nll_loss=0.912, ntokens=1149.4, nsentences=32, sample_size=1149.4, sample_size_v1=0, sample_size_v2=0, ppl=1.88, wps=605.8, ups=0.53, wpb=1149.4, bsz=32, num_updates=31000, lr=1.28739e-05, gnorm=10.281, clip=100, loss_scale=32, train_wall=19, gb_free=11.2, wall=58261
2023-05-26 15:34:25 - progress_bar.py[line:272] - INFO: epoch 018:   1620 / 1732 loss=2.131, loss_v1=0, loss_v2=0, nll_loss=0.903, ntokens=1143.9, nsentences=32, sample_size=1143.9, sample_size_v1=0, sample_size_v2=0, ppl=1.87, wps=603.5, ups=0.53, wpb=1143.9, bsz=32, num_updates=31010, lr=1.28678e-05, gnorm=10.975, clip=100, loss_scale=32, train_wall=19, gb_free=10.5, wall=58280
2023-05-26 15:34:44 - progress_bar.py[line:272] - INFO: epoch 018:   1630 / 1732 loss=2.155, loss_v1=0, loss_v2=0, nll_loss=0.929, ntokens=1148.8, nsentences=32, sample_size=1148.8, sample_size_v1=0, sample_size_v2=0, ppl=1.9, wps=606.8, ups=0.53, wpb=1148.8, bsz=32, num_updates=31020, lr=1.28616e-05, gnorm=11.097, clip=100, loss_scale=32, train_wall=19, gb_free=11.1, wall=58299
2023-05-26 15:35:03 - progress_bar.py[line:272] - INFO: epoch 018:   1640 / 1732 loss=2.142, loss_v1=0, loss_v2=0, nll_loss=0.914, ntokens=1148.2, nsentences=32, sample_size=1148.2, sample_size_v1=0, sample_size_v2=0, ppl=1.88, wps=611.2, ups=0.53, wpb=1148.2, bsz=32, num_updates=31030, lr=1.28555e-05, gnorm=10.672, clip=100, loss_scale=32, train_wall=19, gb_free=11, wall=58318
2023-05-26 15:35:22 - progress_bar.py[line:272] - INFO: epoch 018:   1650 / 1732 loss=2.151, loss_v1=0, loss_v2=0, nll_loss=0.926, ntokens=1158.7, nsentences=32, sample_size=1158.7, sample_size_v1=0, sample_size_v2=0, ppl=1.9, wps=611.4, ups=0.53, wpb=1158.7, bsz=32, num_updates=31040, lr=1.28493e-05, gnorm=11.232, clip=100, loss_scale=32, train_wall=19, gb_free=11.7, wall=58337
2023-05-26 15:35:41 - progress_bar.py[line:272] - INFO: epoch 018:   1660 / 1732 loss=2.178, loss_v1=0, loss_v2=0, nll_loss=0.956, ntokens=997.6, nsentences=32, sample_size=997.6, sample_size_v1=0, sample_size_v2=0, ppl=1.94, wps=532.4, ups=0.53, wpb=997.6, bsz=32, num_updates=31050, lr=1.28432e-05, gnorm=12.51, clip=100, loss_scale=32, train_wall=19, gb_free=11.3, wall=58355
2023-05-26 15:35:59 - progress_bar.py[line:272] - INFO: epoch 018:   1670 / 1732 loss=2.157, loss_v1=0, loss_v2=0, nll_loss=0.932, ntokens=1015.8, nsentences=32, sample_size=1015.8, sample_size_v1=0, sample_size_v2=0, ppl=1.91, wps=542.7, ups=0.53, wpb=1015.8, bsz=32, num_updates=31060, lr=1.2837e-05, gnorm=11.616, clip=100, loss_scale=32, train_wall=19, gb_free=11.4, wall=58374
2023-05-26 15:36:18 - progress_bar.py[line:272] - INFO: epoch 018:   1680 / 1732 loss=2.122, loss_v1=0, loss_v2=0, nll_loss=0.892, ntokens=1181.3, nsentences=32, sample_size=1181.3, sample_size_v1=0, sample_size_v2=0, ppl=1.86, wps=619, ups=0.52, wpb=1181.3, bsz=32, num_updates=31070, lr=1.28309e-05, gnorm=10.832, clip=100, loss_scale=32, train_wall=19, gb_free=11.1, wall=58393
2023-05-26 15:36:37 - progress_bar.py[line:272] - INFO: epoch 018:   1690 / 1732 loss=2.149, loss_v1=0, loss_v2=0, nll_loss=0.922, ntokens=1198.5, nsentences=32, sample_size=1198.5, sample_size_v1=0, sample_size_v2=0, ppl=1.89, wps=628.5, ups=0.52, wpb=1198.5, bsz=32, num_updates=31080, lr=1.28248e-05, gnorm=10.644, clip=100, loss_scale=32, train_wall=19, gb_free=10.8, wall=58412
2023-05-26 15:36:57 - progress_bar.py[line:272] - INFO: epoch 018:   1700 / 1732 loss=2.151, loss_v1=0, loss_v2=0, nll_loss=0.924, ntokens=1281, nsentences=32, sample_size=1281, sample_size_v1=0, sample_size_v2=0, ppl=1.9, wps=669.4, ups=0.52, wpb=1281, bsz=32, num_updates=31090, lr=1.28186e-05, gnorm=9.45, clip=100, loss_scale=32, train_wall=19, gb_free=11.4, wall=58431
2023-05-26 15:37:16 - progress_bar.py[line:272] - INFO: epoch 018:   1710 / 1732 loss=2.173, loss_v1=0, loss_v2=0, nll_loss=0.949, ntokens=1170.9, nsentences=32, sample_size=1170.9, sample_size_v1=0, sample_size_v2=0, ppl=1.93, wps=618.2, ups=0.53, wpb=1170.9, bsz=32, num_updates=31100, lr=1.28125e-05, gnorm=11.384, clip=100, loss_scale=32, train_wall=19, gb_free=10.2, wall=58450
2023-05-26 15:37:35 - progress_bar.py[line:272] - INFO: epoch 018:   1720 / 1732 loss=2.138, loss_v1=0, loss_v2=0, nll_loss=0.911, ntokens=1171, nsentences=32, sample_size=1171, sample_size_v1=0, sample_size_v2=0, ppl=1.88, wps=616.4, ups=0.53, wpb=1171, bsz=32, num_updates=31110, lr=1.28063e-05, gnorm=10.673, clip=100, loss_scale=32, train_wall=19, gb_free=11.3, wall=58469
2023-05-26 15:37:53 - progress_bar.py[line:272] - INFO: epoch 018:   1730 / 1732 loss=2.189, loss_v1=0, loss_v2=0, nll_loss=0.968, ntokens=1126.4, nsentences=32, sample_size=1126.4, sample_size_v1=0, sample_size_v2=0, ppl=1.96, wps=595.5, ups=0.53, wpb=1126.4, bsz=32, num_updates=31120, lr=1.28002e-05, gnorm=11.201, clip=100, loss_scale=32, train_wall=19, gb_free=11.2, wall=58488
2023-05-26 15:37:56 - train.py[line:332] - INFO: end of epoch 18 (average epoch stats below)
2023-05-26 15:37:56 - progress_bar.py[line:282] - INFO: epoch 018 | loss 2.17 | loss_v1 0 | loss_v2 0 | nll_loss 0.946 | ntokens 1051.54 | nsentences 31.986 | sample_size 1051.54 | sample_size_v1 0 | sample_size_v2 0 | ppl 1.93 | wps 559.9 | ups 0.53 | wpb 1051.5 | bsz 32 | num_updates 31122 | lr 1.2799e-05 | gnorm 10.567 | clip 100 | loss_scale 32 | train_wall 3239 | gb_free 11.7 | wall 58491
2023-05-26 15:37:56 - trainer.py[line:639] - INFO: loading train data for epoch 19
local datafile ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 0 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 0 finished initializing row_count and line_idx-to-offset mapping
file ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 0 row count 55400 total row count 55400
slice_id 0 seek offset 0
2023-05-26 15:37:58 - trainer.py[line:703] - INFO: begin training epoch 19
2023-05-26 15:37:58 - train.py[line:305] - INFO: Start iterating over samples
2023-05-26 15:38:13 - progress_bar.py[line:272] - INFO: epoch 019:      8 / 1732 loss=2.128, loss_v1=0, loss_v2=0, nll_loss=0.899, ntokens=1080.1, nsentences=29.6, sample_size=1080.1, sample_size_v1=0, sample_size_v2=0, ppl=1.86, wps=543.9, ups=0.5, wpb=1080.1, bsz=29.6, num_updates=31130, lr=1.27941e-05, gnorm=12.469, clip=100, loss_scale=32, train_wall=18, gb_free=10.3, wall=58508
2023-05-26 15:38:32 - progress_bar.py[line:272] - INFO: epoch 019:     18 / 1732 loss=2.109, loss_v1=0, loss_v2=0, nll_loss=0.877, ntokens=1071.6, nsentences=32, sample_size=1071.6, sample_size_v1=0, sample_size_v2=0, ppl=1.84, wps=567.3, ups=0.53, wpb=1071.6, bsz=32, num_updates=31140, lr=1.27879e-05, gnorm=14.736, clip=100, loss_scale=32, train_wall=19, gb_free=11.1, wall=58527
2023-05-26 15:38:51 - progress_bar.py[line:272] - INFO: epoch 019:     28 / 1732 loss=2.142, loss_v1=0, loss_v2=0, nll_loss=0.916, ntokens=959.8, nsentences=32, sample_size=959.8, sample_size_v1=0, sample_size_v2=0, ppl=1.89, wps=511.3, ups=0.53, wpb=959.8, bsz=32, num_updates=31150, lr=1.27818e-05, gnorm=13.723, clip=100, loss_scale=32, train_wall=19, gb_free=11.3, wall=58546
2023-05-26 15:39:10 - progress_bar.py[line:272] - INFO: epoch 019:     38 / 1732 loss=1.996, loss_v1=0, loss_v2=0, nll_loss=0.752, ntokens=1177.1, nsentences=32, sample_size=1177.1, sample_size_v1=0, sample_size_v2=0, ppl=1.68, wps=616.9, ups=0.52, wpb=1177.1, bsz=32, num_updates=31160, lr=1.27756e-05, gnorm=10.948, clip=100, loss_scale=32, train_wall=19, gb_free=11.3, wall=58565
2023-05-26 15:39:29 - progress_bar.py[line:272] - INFO: epoch 019:     48 / 1732 loss=2.031, loss_v1=0, loss_v2=0, nll_loss=0.793, ntokens=1064.2, nsentences=32, sample_size=1064.2, sample_size_v1=0, sample_size_v2=0, ppl=1.73, wps=563.1, ups=0.53, wpb=1064.2, bsz=32, num_updates=31170, lr=1.27695e-05, gnorm=11.737, clip=100, loss_scale=32, train_wall=19, gb_free=10.8, wall=58584
2023-05-26 15:39:48 - progress_bar.py[line:272] - INFO: epoch 019:     58 / 1732 loss=1.928, loss_v1=0, loss_v2=0, nll_loss=0.677, ntokens=1039.9, nsentences=32, sample_size=1039.9, sample_size_v1=0, sample_size_v2=0, ppl=1.6, wps=556.3, ups=0.53, wpb=1039.9, bsz=32, num_updates=31180, lr=1.27633e-05, gnorm=10.34, clip=100, loss_scale=32, train_wall=19, gb_free=11.6, wall=58602
2023-05-26 15:40:07 - progress_bar.py[line:272] - INFO: epoch 019:     68 / 1732 loss=1.89, loss_v1=0, loss_v2=0, nll_loss=0.633, ntokens=1401.1, nsentences=32, sample_size=1401.1, sample_size_v1=0, sample_size_v2=0, ppl=1.55, wps=717.5, ups=0.51, wpb=1401.1, bsz=32, num_updates=31190, lr=1.27572e-05, gnorm=7.51, clip=100, loss_scale=32, train_wall=19, gb_free=10, wall=58622
2023-05-26 15:40:27 - progress_bar.py[line:272] - INFO: epoch 019:     78 / 1732 loss=1.965, loss_v1=0, loss_v2=0, nll_loss=0.718, ntokens=1268.8, nsentences=32, sample_size=1268.8, sample_size_v1=0, sample_size_v2=0, ppl=1.65, wps=656.3, ups=0.52, wpb=1268.8, bsz=32, num_updates=31200, lr=1.27511e-05, gnorm=8.807, clip=100, loss_scale=32, train_wall=19, gb_free=9.9, wall=58641
2023-05-26 15:40:46 - progress_bar.py[line:272] - INFO: epoch 019:     88 / 1732 loss=2.032, loss_v1=0, loss_v2=0, nll_loss=0.793, ntokens=1100.2, nsentences=32, sample_size=1100.2, sample_size_v1=0, sample_size_v2=0, ppl=1.73, wps=575, ups=0.52, wpb=1100.2, bsz=32, num_updates=31210, lr=1.27449e-05, gnorm=11.583, clip=100, loss_scale=32, train_wall=19, gb_free=11, wall=58660
2023-05-26 15:41:05 - progress_bar.py[line:272] - INFO: epoch 019:     98 / 1732 loss=2.002, loss_v1=0, loss_v2=0, nll_loss=0.758, ntokens=1080.6, nsentences=32, sample_size=1080.6, sample_size_v1=0, sample_size_v2=0, ppl=1.69, wps=571.4, ups=0.53, wpb=1080.6, bsz=32, num_updates=31220, lr=1.27388e-05, gnorm=11.283, clip=100, loss_scale=32, train_wall=19, gb_free=11.3, wall=58679
2023-05-26 15:41:23 - progress_bar.py[line:272] - INFO: epoch 019:    108 / 1732 loss=2.15, loss_v1=0, loss_v2=0, nll_loss=0.928, ntokens=978.3, nsentences=32, sample_size=978.3, sample_size_v1=0, sample_size_v2=0, ppl=1.9, wps=523.1, ups=0.53, wpb=978.3, bsz=32, num_updates=31230, lr=1.27326e-05, gnorm=12.827, clip=100, loss_scale=32, train_wall=19, gb_free=11.7, wall=58698
2023-05-26 15:41:42 - progress_bar.py[line:272] - INFO: epoch 019:    118 / 1732 loss=2.175, loss_v1=0, loss_v2=0, nll_loss=0.953, ntokens=1087, nsentences=32, sample_size=1087, sample_size_v1=0, sample_size_v2=0, ppl=1.94, wps=571.9, ups=0.53, wpb=1087, bsz=32, num_updates=31240, lr=1.27265e-05, gnorm=11.974, clip=100, loss_scale=64, train_wall=19, gb_free=10.9, wall=58717
2023-05-26 15:42:02 - progress_bar.py[line:272] - INFO: epoch 019:    128 / 1732 loss=2.153, loss_v1=0, loss_v2=0, nll_loss=0.927, ntokens=1177.5, nsentences=32, sample_size=1177.5, sample_size_v1=0, sample_size_v2=0, ppl=1.9, wps=612.3, ups=0.52, wpb=1177.5, bsz=32, num_updates=31250, lr=1.27203e-05, gnorm=11.093, clip=100, loss_scale=64, train_wall=19, gb_free=11.4, wall=58736
2023-05-26 15:42:21 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2023-05-26 15:42:23 - progress_bar.py[line:272] - INFO: epoch 019:    139 / 1732 loss=2.121, loss_v1=0, loss_v2=0, nll_loss=0.891, ntokens=1241.6, nsentences=32, sample_size=1241.6, sample_size_v1=0, sample_size_v2=0, ppl=1.85, wps=591.2, ups=0.48, wpb=1241.6, bsz=32, num_updates=31260, lr=1.27142e-05, gnorm=10.63, clip=100, loss_scale=32, train_wall=21, gb_free=10.3, wall=58757
2023-05-26 15:42:42 - progress_bar.py[line:272] - INFO: epoch 019:    149 / 1732 loss=2.079, loss_v1=0, loss_v2=0, nll_loss=0.842, ntokens=1177.5, nsentences=32, sample_size=1177.5, sample_size_v1=0, sample_size_v2=0, ppl=1.79, wps=609.8, ups=0.52, wpb=1177.5, bsz=32, num_updates=31270, lr=1.27081e-05, gnorm=10.962, clip=100, loss_scale=32, train_wall=19, gb_free=10.3, wall=58777
2023-05-26 15:43:01 - progress_bar.py[line:272] - INFO: epoch 019:    159 / 1732 loss=2.125, loss_v1=0, loss_v2=0, nll_loss=0.896, ntokens=1139.9, nsentences=32, sample_size=1139.9, sample_size_v1=0, sample_size_v2=0, ppl=1.86, wps=594.5, ups=0.52, wpb=1139.9, bsz=32, num_updates=31280, lr=1.27019e-05, gnorm=11.487, clip=100, loss_scale=32, train_wall=19, gb_free=11.5, wall=58796
2023-05-26 15:43:20 - progress_bar.py[line:272] - INFO: epoch 019:    169 / 1732 loss=2.114, loss_v1=0, loss_v2=0, nll_loss=0.885, ntokens=986.6, nsentences=32, sample_size=986.6, sample_size_v1=0, sample_size_v2=0, ppl=1.85, wps=523.3, ups=0.53, wpb=986.6, bsz=32, num_updates=31290, lr=1.26958e-05, gnorm=12.252, clip=100, loss_scale=32, train_wall=19, gb_free=11.4, wall=58815
2023-05-26 15:43:39 - progress_bar.py[line:272] - INFO: epoch 019:    179 / 1732 loss=2.094, loss_v1=0, loss_v2=0, nll_loss=0.86, ntokens=1076.1, nsentences=32, sample_size=1076.1, sample_size_v1=0, sample_size_v2=0, ppl=1.82, wps=566.5, ups=0.53, wpb=1076.1, bsz=32, num_updates=31300, lr=1.26896e-05, gnorm=12.222, clip=100, loss_scale=32, train_wall=19, gb_free=10.6, wall=58834
2023-05-26 15:43:58 - progress_bar.py[line:272] - INFO: epoch 019:    189 / 1732 loss=2.079, loss_v1=0, loss_v2=0, nll_loss=0.843, ntokens=1120.4, nsentences=32, sample_size=1120.4, sample_size_v1=0, sample_size_v2=0, ppl=1.79, wps=588.2, ups=0.53, wpb=1120.4, bsz=32, num_updates=31310, lr=1.26835e-05, gnorm=11.487, clip=100, loss_scale=32, train_wall=19, gb_free=11.7, wall=58853
2023-05-26 15:44:17 - progress_bar.py[line:272] - INFO: epoch 019:    199 / 1732 loss=2.123, loss_v1=0, loss_v2=0, nll_loss=0.894, ntokens=1141, nsentences=32, sample_size=1141, sample_size_v1=0, sample_size_v2=0, ppl=1.86, wps=603, ups=0.53, wpb=1141, bsz=32, num_updates=31320, lr=1.26774e-05, gnorm=11.504, clip=100, loss_scale=32, train_wall=19, gb_free=11.6, wall=58872
2023-05-26 15:44:36 - progress_bar.py[line:272] - INFO: epoch 019:    209 / 1732 loss=2.187, loss_v1=0, loss_v2=0, nll_loss=0.966, ntokens=970.7, nsentences=32, sample_size=970.7, sample_size_v1=0, sample_size_v2=0, ppl=1.95, wps=520.9, ups=0.54, wpb=970.7, bsz=32, num_updates=31330, lr=1.26712e-05, gnorm=12.698, clip=100, loss_scale=32, train_wall=19, gb_free=10.3, wall=58890
2023-05-26 15:44:54 - progress_bar.py[line:272] - INFO: epoch 019:    219 / 1732 loss=2.19, loss_v1=0, loss_v2=0, nll_loss=0.969, ntokens=1152.7, nsentences=32, sample_size=1152.7, sample_size_v1=0, sample_size_v2=0, ppl=1.96, wps=615.7, ups=0.53, wpb=1152.7, bsz=32, num_updates=31340, lr=1.26651e-05, gnorm=11.238, clip=100, loss_scale=32, train_wall=19, gb_free=11.3, wall=58909
2023-05-26 15:45:13 - progress_bar.py[line:272] - INFO: epoch 019:    229 / 1732 loss=2.169, loss_v1=0, loss_v2=0, nll_loss=0.945, ntokens=1096.1, nsentences=32, sample_size=1096.1, sample_size_v1=0, sample_size_v2=0, ppl=1.93, wps=586, ups=0.53, wpb=1096.1, bsz=32, num_updates=31350, lr=1.26589e-05, gnorm=10.64, clip=100, loss_scale=32, train_wall=19, gb_free=11.7, wall=58928
2023-05-26 15:45:32 - progress_bar.py[line:272] - INFO: epoch 019:    239 / 1732 loss=2.215, loss_v1=0, loss_v2=0, nll_loss=0.996, ntokens=1117, nsentences=32, sample_size=1117, sample_size_v1=0, sample_size_v2=0, ppl=1.99, wps=595.7, ups=0.53, wpb=1117, bsz=32, num_updates=31360, lr=1.26528e-05, gnorm=10.526, clip=100, loss_scale=32, train_wall=19, gb_free=10.8, wall=58946
2023-05-26 15:45:51 - progress_bar.py[line:272] - INFO: epoch 019:    249 / 1732 loss=2.176, loss_v1=0, loss_v2=0, nll_loss=0.952, ntokens=1165.4, nsentences=32, sample_size=1165.4, sample_size_v1=0, sample_size_v2=0, ppl=1.93, wps=618.1, ups=0.53, wpb=1165.4, bsz=32, num_updates=31370, lr=1.26466e-05, gnorm=10.303, clip=100, loss_scale=32, train_wall=19, gb_free=11.3, wall=58965
2023-05-26 15:46:09 - progress_bar.py[line:272] - INFO: epoch 019:    259 / 1732 loss=2.188, loss_v1=0, loss_v2=0, nll_loss=0.968, ntokens=1119.2, nsentences=32, sample_size=1119.2, sample_size_v1=0, sample_size_v2=0, ppl=1.96, wps=595.3, ups=0.53, wpb=1119.2, bsz=32, num_updates=31380, lr=1.26405e-05, gnorm=10.963, clip=100, loss_scale=32, train_wall=19, gb_free=11.2, wall=58984
2023-05-26 15:46:28 - progress_bar.py[line:272] - INFO: epoch 019:    269 / 1732 loss=2.176, loss_v1=0, loss_v2=0, nll_loss=0.954, ntokens=1154.8, nsentences=32, sample_size=1154.8, sample_size_v1=0, sample_size_v2=0, ppl=1.94, wps=609.2, ups=0.53, wpb=1154.8, bsz=32, num_updates=31390, lr=1.26344e-05, gnorm=10.767, clip=100, loss_scale=32, train_wall=19, gb_free=11.1, wall=59003
2023-05-26 15:46:47 - progress_bar.py[line:272] - INFO: epoch 019:    279 / 1732 loss=2.196, loss_v1=0, loss_v2=0, nll_loss=0.975, ntokens=1151.7, nsentences=32, sample_size=1151.7, sample_size_v1=0, sample_size_v2=0, ppl=1.97, wps=609.5, ups=0.53, wpb=1151.7, bsz=32, num_updates=31400, lr=1.26282e-05, gnorm=11.336, clip=100, loss_scale=32, train_wall=19, gb_free=10.9, wall=59022
2023-05-26 15:47:06 - progress_bar.py[line:272] - INFO: epoch 019:    289 / 1732 loss=2.162, loss_v1=0, loss_v2=0, nll_loss=0.935, ntokens=1147.9, nsentences=32, sample_size=1147.9, sample_size_v1=0, sample_size_v2=0, ppl=1.91, wps=609.4, ups=0.53, wpb=1147.9, bsz=32, num_updates=31410, lr=1.26221e-05, gnorm=10.363, clip=100, loss_scale=32, train_wall=19, gb_free=11.8, wall=59041
2023-05-26 15:47:25 - progress_bar.py[line:272] - INFO: epoch 019:    299 / 1732 loss=2.171, loss_v1=0, loss_v2=0, nll_loss=0.948, ntokens=1105.2, nsentences=32, sample_size=1105.2, sample_size_v1=0, sample_size_v2=0, ppl=1.93, wps=590.4, ups=0.53, wpb=1105.2, bsz=32, num_updates=31420, lr=1.26159e-05, gnorm=10.651, clip=100, loss_scale=32, train_wall=19, gb_free=11.1, wall=59059
2023-05-26 15:47:44 - progress_bar.py[line:272] - INFO: epoch 019:    309 / 1732 loss=2.173, loss_v1=0, loss_v2=0, nll_loss=0.953, ntokens=1071, nsentences=32, sample_size=1071, sample_size_v1=0, sample_size_v2=0, ppl=1.94, wps=572.2, ups=0.53, wpb=1071, bsz=32, num_updates=31430, lr=1.26098e-05, gnorm=11.704, clip=100, loss_scale=32, train_wall=19, gb_free=11.3, wall=59078
2023-05-26 15:48:02 - progress_bar.py[line:272] - INFO: epoch 019:    319 / 1732 loss=2.202, loss_v1=0, loss_v2=0, nll_loss=0.983, ntokens=1020.8, nsentences=32, sample_size=1020.8, sample_size_v1=0, sample_size_v2=0, ppl=1.98, wps=548.6, ups=0.54, wpb=1020.8, bsz=32, num_updates=31440, lr=1.26036e-05, gnorm=11.582, clip=100, loss_scale=32, train_wall=19, gb_free=11.7, wall=59097
2023-05-26 15:48:21 - progress_bar.py[line:272] - INFO: epoch 019:    329 / 1732 loss=2.215, loss_v1=0, loss_v2=0, nll_loss=0.996, ntokens=1025.4, nsentences=32, sample_size=1025.4, sample_size_v1=0, sample_size_v2=0, ppl=1.99, wps=550.6, ups=0.54, wpb=1025.4, bsz=32, num_updates=31450, lr=1.25975e-05, gnorm=12.242, clip=100, loss_scale=32, train_wall=19, gb_free=11.3, wall=59115
2023-05-26 15:48:39 - progress_bar.py[line:272] - INFO: epoch 019:    339 / 1732 loss=2.168, loss_v1=0, loss_v2=0, nll_loss=0.944, ntokens=950.6, nsentences=32, sample_size=950.6, sample_size_v1=0, sample_size_v2=0, ppl=1.92, wps=512.6, ups=0.54, wpb=950.6, bsz=32, num_updates=31460, lr=1.25914e-05, gnorm=12.168, clip=100, loss_scale=32, train_wall=19, gb_free=11.7, wall=59134
2023-05-26 15:48:58 - progress_bar.py[line:272] - INFO: epoch 019:    349 / 1732 loss=2.172, loss_v1=0, loss_v2=0, nll_loss=0.95, ntokens=919.8, nsentences=32, sample_size=919.8, sample_size_v1=0, sample_size_v2=0, ppl=1.93, wps=497.2, ups=0.54, wpb=919.8, bsz=32, num_updates=31470, lr=1.25852e-05, gnorm=13.156, clip=100, loss_scale=32, train_wall=18, gb_free=11.9, wall=59152
2023-05-26 15:49:16 - progress_bar.py[line:272] - INFO: epoch 019:    359 / 1732 loss=2.207, loss_v1=0, loss_v2=0, nll_loss=0.988, ntokens=933.3, nsentences=32, sample_size=933.3, sample_size_v1=0, sample_size_v2=0, ppl=1.98, wps=504.7, ups=0.54, wpb=933.3, bsz=32, num_updates=31480, lr=1.25791e-05, gnorm=13.832, clip=100, loss_scale=32, train_wall=18, gb_free=11.2, wall=59171
2023-05-26 15:49:35 - progress_bar.py[line:272] - INFO: epoch 019:    369 / 1732 loss=2.206, loss_v1=0, loss_v2=0, nll_loss=0.986, ntokens=971.1, nsentences=32, sample_size=971.1, sample_size_v1=0, sample_size_v2=0, ppl=1.98, wps=523.5, ups=0.54, wpb=971.1, bsz=32, num_updates=31490, lr=1.25729e-05, gnorm=12.716, clip=100, loss_scale=32, train_wall=19, gb_free=11.5, wall=59190
2023-05-26 15:49:53 - progress_bar.py[line:272] - INFO: epoch 019:    379 / 1732 loss=2.216, loss_v1=0, loss_v2=0, nll_loss=0.998, ntokens=1075.7, nsentences=32, sample_size=1075.7, sample_size_v1=0, sample_size_v2=0, ppl=2, wps=579.6, ups=0.54, wpb=1075.7, bsz=32, num_updates=31500, lr=1.25668e-05, gnorm=12.01, clip=100, loss_scale=32, train_wall=19, gb_free=11, wall=59208
2023-05-26 15:50:12 - progress_bar.py[line:272] - INFO: epoch 019:    389 / 1732 loss=2.195, loss_v1=0, loss_v2=0, nll_loss=0.973, ntokens=1027.5, nsentences=32, sample_size=1027.5, sample_size_v1=0, sample_size_v2=0, ppl=1.96, wps=552.5, ups=0.54, wpb=1027.5, bsz=32, num_updates=31510, lr=1.25607e-05, gnorm=12.346, clip=100, loss_scale=32, train_wall=19, gb_free=11.6, wall=59227
2023-05-26 15:50:31 - progress_bar.py[line:272] - INFO: epoch 019:    399 / 1732 loss=2.191, loss_v1=0, loss_v2=0, nll_loss=0.969, ntokens=981.4, nsentences=32, sample_size=981.4, sample_size_v1=0, sample_size_v2=0, ppl=1.96, wps=528.2, ups=0.54, wpb=981.4, bsz=32, num_updates=31520, lr=1.25545e-05, gnorm=11.909, clip=100, loss_scale=32, train_wall=19, gb_free=11.4, wall=59245
2023-05-26 15:50:49 - progress_bar.py[line:272] - INFO: epoch 019:    409 / 1732 loss=2.186, loss_v1=0, loss_v2=0, nll_loss=0.964, ntokens=1066.6, nsentences=32, sample_size=1066.6, sample_size_v1=0, sample_size_v2=0, ppl=1.95, wps=571.5, ups=0.54, wpb=1066.6, bsz=32, num_updates=31530, lr=1.25484e-05, gnorm=12.126, clip=100, loss_scale=32, train_wall=19, gb_free=11.5, wall=59264
2023-05-26 15:51:08 - progress_bar.py[line:272] - INFO: epoch 019:    419 / 1732 loss=2.15, loss_v1=0, loss_v2=0, nll_loss=0.924, ntokens=1023.6, nsentences=32, sample_size=1023.6, sample_size_v1=0, sample_size_v2=0, ppl=1.9, wps=550.8, ups=0.54, wpb=1023.6, bsz=32, num_updates=31540, lr=1.25422e-05, gnorm=11.713, clip=100, loss_scale=32, train_wall=19, gb_free=11.2, wall=59283
2023-05-26 15:51:27 - progress_bar.py[line:272] - INFO: epoch 019:    429 / 1732 loss=2.15, loss_v1=0, loss_v2=0, nll_loss=0.923, ntokens=1011.5, nsentences=32, sample_size=1011.5, sample_size_v1=0, sample_size_v2=0, ppl=1.9, wps=543.1, ups=0.54, wpb=1011.5, bsz=32, num_updates=31550, lr=1.25361e-05, gnorm=11.843, clip=100, loss_scale=32, train_wall=19, gb_free=11.6, wall=59301
2023-05-26 15:51:45 - progress_bar.py[line:272] - INFO: epoch 019:    439 / 1732 loss=2.188, loss_v1=0, loss_v2=0, nll_loss=0.965, ntokens=1024.1, nsentences=32, sample_size=1024.1, sample_size_v1=0, sample_size_v2=0, ppl=1.95, wps=549.6, ups=0.54, wpb=1024.1, bsz=32, num_updates=31560, lr=1.25299e-05, gnorm=12.431, clip=100, loss_scale=32, train_wall=19, gb_free=10.8, wall=59320
2023-05-26 15:52:04 - progress_bar.py[line:272] - INFO: epoch 019:    449 / 1732 loss=2.196, loss_v1=0, loss_v2=0, nll_loss=0.975, ntokens=917.8, nsentences=32, sample_size=917.8, sample_size_v1=0, sample_size_v2=0, ppl=1.97, wps=493.8, ups=0.54, wpb=917.8, bsz=32, num_updates=31570, lr=1.25238e-05, gnorm=11.779, clip=100, loss_scale=32, train_wall=19, gb_free=11.3, wall=59338
2023-05-26 15:52:22 - progress_bar.py[line:272] - INFO: epoch 019:    459 / 1732 loss=2.198, loss_v1=0, loss_v2=0, nll_loss=0.979, ntokens=1003.6, nsentences=32, sample_size=1003.6, sample_size_v1=0, sample_size_v2=0, ppl=1.97, wps=541.3, ups=0.54, wpb=1003.6, bsz=32, num_updates=31580, lr=1.25177e-05, gnorm=12.25, clip=100, loss_scale=32, train_wall=19, gb_free=11.6, wall=59357
2023-05-26 15:52:41 - progress_bar.py[line:272] - INFO: epoch 019:    469 / 1732 loss=2.202, loss_v1=0, loss_v2=0, nll_loss=0.982, ntokens=1054.5, nsentences=32, sample_size=1054.5, sample_size_v1=0, sample_size_v2=0, ppl=1.98, wps=561.5, ups=0.53, wpb=1054.5, bsz=32, num_updates=31590, lr=1.25115e-05, gnorm=12.946, clip=100, loss_scale=32, train_wall=19, gb_free=10.6, wall=59376
2023-05-26 15:53:00 - progress_bar.py[line:272] - INFO: epoch 019:    479 / 1732 loss=2.224, loss_v1=0, loss_v2=0, nll_loss=1.007, ntokens=1034.5, nsentences=32, sample_size=1034.5, sample_size_v1=0, sample_size_v2=0, ppl=2.01, wps=556.3, ups=0.54, wpb=1034.5, bsz=32, num_updates=31600, lr=1.25054e-05, gnorm=12.948, clip=100, loss_scale=32, train_wall=19, gb_free=11.6, wall=59394
2023-05-26 15:53:18 - progress_bar.py[line:272] - INFO: epoch 019:    489 / 1732 loss=2.169, loss_v1=0, loss_v2=0, nll_loss=0.943, ntokens=912, nsentences=32, sample_size=912, sample_size_v1=0, sample_size_v2=0, ppl=1.92, wps=492.5, ups=0.54, wpb=912, bsz=32, num_updates=31610, lr=1.24992e-05, gnorm=13.109, clip=100, loss_scale=32, train_wall=18, gb_free=11.6, wall=59413
2023-05-26 15:53:37 - progress_bar.py[line:272] - INFO: epoch 019:    499 / 1732 loss=2.18, loss_v1=0, loss_v2=0, nll_loss=0.957, ntokens=957.3, nsentences=32, sample_size=957.3, sample_size_v1=0, sample_size_v2=0, ppl=1.94, wps=517.2, ups=0.54, wpb=957.3, bsz=32, num_updates=31620, lr=1.24931e-05, gnorm=13.232, clip=100, loss_scale=32, train_wall=18, gb_free=11.4, wall=59431
2023-05-26 15:53:55 - progress_bar.py[line:272] - INFO: epoch 019:    509 / 1732 loss=2.202, loss_v1=0, loss_v2=0, nll_loss=0.982, ntokens=1025.1, nsentences=32, sample_size=1025.1, sample_size_v1=0, sample_size_v2=0, ppl=1.98, wps=552.3, ups=0.54, wpb=1025.1, bsz=32, num_updates=31630, lr=1.24869e-05, gnorm=13.382, clip=100, loss_scale=32, train_wall=19, gb_free=11.7, wall=59450
2023-05-26 15:54:14 - progress_bar.py[line:272] - INFO: epoch 019:    519 / 1732 loss=2.174, loss_v1=0, loss_v2=0, nll_loss=0.952, ntokens=1029.2, nsentences=32, sample_size=1029.2, sample_size_v1=0, sample_size_v2=0, ppl=1.93, wps=555.4, ups=0.54, wpb=1029.2, bsz=32, num_updates=31640, lr=1.24808e-05, gnorm=11.67, clip=100, loss_scale=32, train_wall=18, gb_free=11.9, wall=59468
2023-05-26 15:54:32 - progress_bar.py[line:272] - INFO: epoch 019:    529 / 1732 loss=2.194, loss_v1=0, loss_v2=0, nll_loss=0.973, ntokens=945, nsentences=32, sample_size=945, sample_size_v1=0, sample_size_v2=0, ppl=1.96, wps=512, ups=0.54, wpb=945, bsz=32, num_updates=31650, lr=1.24747e-05, gnorm=12.942, clip=100, loss_scale=32, train_wall=18, gb_free=11.5, wall=59487
2023-05-26 15:54:51 - progress_bar.py[line:272] - INFO: epoch 019:    539 / 1732 loss=2.18, loss_v1=0, loss_v2=0, nll_loss=0.957, ntokens=990.9, nsentences=32, sample_size=990.9, sample_size_v1=0, sample_size_v2=0, ppl=1.94, wps=535.4, ups=0.54, wpb=990.9, bsz=32, num_updates=31660, lr=1.24685e-05, gnorm=12.464, clip=100, loss_scale=32, train_wall=18, gb_free=11.4, wall=59505
2023-05-26 15:55:09 - progress_bar.py[line:272] - INFO: epoch 019:    549 / 1732 loss=2.213, loss_v1=0, loss_v2=0, nll_loss=0.994, ntokens=1038.3, nsentences=32, sample_size=1038.3, sample_size_v1=0, sample_size_v2=0, ppl=1.99, wps=557.8, ups=0.54, wpb=1038.3, bsz=32, num_updates=31670, lr=1.24624e-05, gnorm=12.312, clip=100, loss_scale=32, train_wall=19, gb_free=11.5, wall=59524
2023-05-26 15:55:28 - progress_bar.py[line:272] - INFO: epoch 019:    559 / 1732 loss=2.204, loss_v1=0, loss_v2=0, nll_loss=0.983, ntokens=1016.1, nsentences=32, sample_size=1016.1, sample_size_v1=0, sample_size_v2=0, ppl=1.98, wps=545.5, ups=0.54, wpb=1016.1, bsz=32, num_updates=31680, lr=1.24562e-05, gnorm=12.371, clip=100, loss_scale=32, train_wall=19, gb_free=11, wall=59543
2023-05-26 15:55:47 - progress_bar.py[line:272] - INFO: epoch 019:    569 / 1732 loss=2.232, loss_v1=0, loss_v2=0, nll_loss=1.015, ntokens=1004.9, nsentences=32, sample_size=1004.9, sample_size_v1=0, sample_size_v2=0, ppl=2.02, wps=538.3, ups=0.54, wpb=1004.9, bsz=32, num_updates=31690, lr=1.24501e-05, gnorm=13.473, clip=100, loss_scale=32, train_wall=19, gb_free=11.2, wall=59561
2023-05-26 15:56:05 - progress_bar.py[line:272] - INFO: epoch 019:    579 / 1732 loss=2.19, loss_v1=0, loss_v2=0, nll_loss=0.968, ntokens=1003.1, nsentences=32, sample_size=1003.1, sample_size_v1=0, sample_size_v2=0, ppl=1.96, wps=535, ups=0.53, wpb=1003.1, bsz=32, num_updates=31700, lr=1.2444e-05, gnorm=12.006, clip=100, loss_scale=32, train_wall=19, gb_free=11, wall=59580
2023-05-26 15:56:24 - progress_bar.py[line:272] - INFO: epoch 019:    589 / 1732 loss=2.196, loss_v1=0, loss_v2=0, nll_loss=0.975, ntokens=951.2, nsentences=32, sample_size=951.2, sample_size_v1=0, sample_size_v2=0, ppl=1.97, wps=508.5, ups=0.53, wpb=951.2, bsz=32, num_updates=31710, lr=1.24378e-05, gnorm=12.526, clip=100, loss_scale=32, train_wall=19, gb_free=10.7, wall=59599
2023-05-26 15:56:43 - progress_bar.py[line:272] - INFO: epoch 019:    599 / 1732 loss=2.14, loss_v1=0, loss_v2=0, nll_loss=0.914, ntokens=935, nsentences=32, sample_size=935, sample_size_v1=0, sample_size_v2=0, ppl=1.88, wps=502.4, ups=0.54, wpb=935, bsz=32, num_updates=31720, lr=1.24317e-05, gnorm=11.654, clip=100, loss_scale=32, train_wall=19, gb_free=12.1, wall=59617
2023-05-26 15:57:01 - progress_bar.py[line:272] - INFO: epoch 019:    609 / 1732 loss=2.186, loss_v1=0, loss_v2=0, nll_loss=0.967, ntokens=917.6, nsentences=32, sample_size=917.6, sample_size_v1=0, sample_size_v2=0, ppl=1.95, wps=495.5, ups=0.54, wpb=917.6, bsz=32, num_updates=31730, lr=1.24255e-05, gnorm=13.887, clip=100, loss_scale=32, train_wall=18, gb_free=10.5, wall=59636
2023-05-26 15:57:20 - progress_bar.py[line:272] - INFO: epoch 019:    619 / 1732 loss=2.207, loss_v1=0, loss_v2=0, nll_loss=0.988, ntokens=845.1, nsentences=32, sample_size=845.1, sample_size_v1=0, sample_size_v2=0, ppl=1.98, wps=460.2, ups=0.54, wpb=845.1, bsz=32, num_updates=31740, lr=1.24194e-05, gnorm=14.228, clip=100, loss_scale=32, train_wall=18, gb_free=11.7, wall=59654
2023-05-26 15:57:38 - progress_bar.py[line:272] - INFO: epoch 019:    629 / 1732 loss=2.169, loss_v1=0, loss_v2=0, nll_loss=0.944, ntokens=934.9, nsentences=32, sample_size=934.9, sample_size_v1=0, sample_size_v2=0, ppl=1.92, wps=507.5, ups=0.54, wpb=934.9, bsz=32, num_updates=31750, lr=1.24132e-05, gnorm=12.859, clip=100, loss_scale=32, train_wall=18, gb_free=11.9, wall=59673
2023-05-26 15:57:57 - progress_bar.py[line:272] - INFO: epoch 019:    639 / 1732 loss=2.201, loss_v1=0, loss_v2=0, nll_loss=0.98, ntokens=925.6, nsentences=32, sample_size=925.6, sample_size_v1=0, sample_size_v2=0, ppl=1.97, wps=500.9, ups=0.54, wpb=925.6, bsz=32, num_updates=31760, lr=1.24071e-05, gnorm=13.423, clip=100, loss_scale=32, train_wall=18, gb_free=11.4, wall=59691
2023-05-26 15:58:15 - progress_bar.py[line:272] - INFO: epoch 019:    649 / 1732 loss=2.187, loss_v1=0, loss_v2=0, nll_loss=0.966, ntokens=987, nsentences=32, sample_size=987, sample_size_v1=0, sample_size_v2=0, ppl=1.95, wps=534.3, ups=0.54, wpb=987, bsz=32, num_updates=31770, lr=1.2401e-05, gnorm=12.653, clip=100, loss_scale=32, train_wall=18, gb_free=11.4, wall=59710
2023-05-26 15:58:20 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2023-05-26 15:58:35 - progress_bar.py[line:272] - INFO: epoch 019:    660 / 1732 loss=2.183, loss_v1=0, loss_v2=0, nll_loss=0.962, ntokens=886.2, nsentences=32, sample_size=886.2, sample_size_v1=0, sample_size_v2=0, ppl=1.95, wps=440.8, ups=0.5, wpb=886.2, bsz=32, num_updates=31780, lr=1.23948e-05, gnorm=13.716, clip=100, loss_scale=32, train_wall=20, gb_free=11.9, wall=59730
2023-05-26 15:58:54 - progress_bar.py[line:272] - INFO: epoch 019:    670 / 1732 loss=2.202, loss_v1=0, loss_v2=0, nll_loss=0.983, ntokens=914.5, nsentences=32, sample_size=914.5, sample_size_v1=0, sample_size_v2=0, ppl=1.98, wps=495.4, ups=0.54, wpb=914.5, bsz=32, num_updates=31790, lr=1.23887e-05, gnorm=14.166, clip=100, loss_scale=32, train_wall=18, gb_free=11.4, wall=59748
2023-05-26 15:59:12 - progress_bar.py[line:272] - INFO: epoch 019:    680 / 1732 loss=2.201, loss_v1=0, loss_v2=0, nll_loss=0.981, ntokens=998, nsentences=32, sample_size=998, sample_size_v1=0, sample_size_v2=0, ppl=1.97, wps=537.9, ups=0.54, wpb=998, bsz=32, num_updates=31800, lr=1.23825e-05, gnorm=13.702, clip=100, loss_scale=32, train_wall=19, gb_free=11.2, wall=59767
2023-05-26 15:59:31 - progress_bar.py[line:272] - INFO: epoch 019:    690 / 1732 loss=2.203, loss_v1=0, loss_v2=0, nll_loss=0.982, ntokens=956.7, nsentences=32, sample_size=956.7, sample_size_v1=0, sample_size_v2=0, ppl=1.98, wps=514, ups=0.54, wpb=956.7, bsz=32, num_updates=31810, lr=1.23764e-05, gnorm=13.059, clip=100, loss_scale=32, train_wall=19, gb_free=10.6, wall=59785
2023-05-26 15:59:49 - progress_bar.py[line:272] - INFO: epoch 019:    700 / 1732 loss=2.168, loss_v1=0, loss_v2=0, nll_loss=0.944, ntokens=979.4, nsentences=32, sample_size=979.4, sample_size_v1=0, sample_size_v2=0, ppl=1.92, wps=528, ups=0.54, wpb=979.4, bsz=32, num_updates=31820, lr=1.23702e-05, gnorm=13.252, clip=100, loss_scale=32, train_wall=19, gb_free=11.7, wall=59804
2023-05-26 16:00:08 - progress_bar.py[line:272] - INFO: epoch 019:    710 / 1732 loss=2.179, loss_v1=0, loss_v2=0, nll_loss=0.957, ntokens=915.1, nsentences=32, sample_size=915.1, sample_size_v1=0, sample_size_v2=0, ppl=1.94, wps=494.6, ups=0.54, wpb=915.1, bsz=32, num_updates=31830, lr=1.23641e-05, gnorm=12.467, clip=100, loss_scale=32, train_wall=18, gb_free=11.6, wall=59823
2023-05-26 16:00:26 - progress_bar.py[line:272] - INFO: epoch 019:    720 / 1732 loss=2.173, loss_v1=0, loss_v2=0, nll_loss=0.95, ntokens=848.7, nsentences=32, sample_size=848.7, sample_size_v1=0, sample_size_v2=0, ppl=1.93, wps=462, ups=0.54, wpb=848.7, bsz=32, num_updates=31840, lr=1.2358e-05, gnorm=13.408, clip=100, loss_scale=32, train_wall=18, gb_free=10.9, wall=59841
2023-05-26 16:00:45 - progress_bar.py[line:272] - INFO: epoch 019:    730 / 1732 loss=2.167, loss_v1=0, loss_v2=0, nll_loss=0.943, ntokens=943.7, nsentences=32, sample_size=943.7, sample_size_v1=0, sample_size_v2=0, ppl=1.92, wps=510.8, ups=0.54, wpb=943.7, bsz=32, num_updates=31850, lr=1.23518e-05, gnorm=12.658, clip=100, loss_scale=32, train_wall=18, gb_free=11.9, wall=59859
2023-05-26 16:01:03 - progress_bar.py[line:272] - INFO: epoch 019:    740 / 1732 loss=2.18, loss_v1=0, loss_v2=0, nll_loss=0.958, ntokens=1007.2, nsentences=32, sample_size=1007.2, sample_size_v1=0, sample_size_v2=0, ppl=1.94, wps=543.5, ups=0.54, wpb=1007.2, bsz=32, num_updates=31860, lr=1.23457e-05, gnorm=12.527, clip=100, loss_scale=32, train_wall=19, gb_free=11.4, wall=59878
2023-05-26 16:01:22 - progress_bar.py[line:272] - INFO: epoch 019:    750 / 1732 loss=2.17, loss_v1=0, loss_v2=0, nll_loss=0.946, ntokens=970.2, nsentences=32, sample_size=970.2, sample_size_v1=0, sample_size_v2=0, ppl=1.93, wps=522, ups=0.54, wpb=970.2, bsz=32, num_updates=31870, lr=1.23395e-05, gnorm=14.014, clip=100, loss_scale=32, train_wall=19, gb_free=11.7, wall=59896
2023-05-26 16:01:40 - progress_bar.py[line:272] - INFO: epoch 019:    760 / 1732 loss=2.159, loss_v1=0, loss_v2=0, nll_loss=0.933, ntokens=974, nsentences=32, sample_size=974, sample_size_v1=0, sample_size_v2=0, ppl=1.91, wps=525.9, ups=0.54, wpb=974, bsz=32, num_updates=31880, lr=1.23334e-05, gnorm=13.335, clip=100, loss_scale=32, train_wall=18, gb_free=11.3, wall=59915
2023-05-26 16:01:59 - progress_bar.py[line:272] - INFO: epoch 019:    770 / 1732 loss=2.172, loss_v1=0, loss_v2=0, nll_loss=0.949, ntokens=922.1, nsentences=32, sample_size=922.1, sample_size_v1=0, sample_size_v2=0, ppl=1.93, wps=500.9, ups=0.54, wpb=922.1, bsz=32, num_updates=31890, lr=1.23273e-05, gnorm=13.571, clip=100, loss_scale=32, train_wall=18, gb_free=11.8, wall=59933
2023-05-26 16:02:17 - progress_bar.py[line:272] - INFO: epoch 019:    780 / 1732 loss=2.17, loss_v1=0, loss_v2=0, nll_loss=0.947, ntokens=1056.6, nsentences=32, sample_size=1056.6, sample_size_v1=0, sample_size_v2=0, ppl=1.93, wps=567.7, ups=0.54, wpb=1056.6, bsz=32, num_updates=31900, lr=1.23211e-05, gnorm=11.74, clip=100, loss_scale=32, train_wall=19, gb_free=11.3, wall=59952
2023-05-26 16:02:36 - progress_bar.py[line:272] - INFO: epoch 019:    790 / 1732 loss=2.189, loss_v1=0, loss_v2=0, nll_loss=0.967, ntokens=1011.9, nsentences=32, sample_size=1011.9, sample_size_v1=0, sample_size_v2=0, ppl=1.96, wps=546.8, ups=0.54, wpb=1011.9, bsz=32, num_updates=31910, lr=1.2315e-05, gnorm=12.946, clip=100, loss_scale=32, train_wall=18, gb_free=10.9, wall=59971
2023-05-26 16:02:54 - progress_bar.py[line:272] - INFO: epoch 019:    800 / 1732 loss=2.197, loss_v1=0, loss_v2=0, nll_loss=0.975, ntokens=1000.1, nsentences=32, sample_size=1000.1, sample_size_v1=0, sample_size_v2=0, ppl=1.97, wps=540.2, ups=0.54, wpb=1000.1, bsz=32, num_updates=31920, lr=1.23088e-05, gnorm=13.533, clip=100, loss_scale=32, train_wall=18, gb_free=11.8, wall=59989
2023-05-26 16:03:13 - progress_bar.py[line:272] - INFO: epoch 019:    810 / 1732 loss=2.184, loss_v1=0, loss_v2=0, nll_loss=0.961, ntokens=918.3, nsentences=32, sample_size=918.3, sample_size_v1=0, sample_size_v2=0, ppl=1.95, wps=496.9, ups=0.54, wpb=918.3, bsz=32, num_updates=31930, lr=1.23027e-05, gnorm=13.344, clip=100, loss_scale=32, train_wall=18, gb_free=11.5, wall=60008
2023-05-26 16:03:31 - progress_bar.py[line:272] - INFO: epoch 019:    820 / 1732 loss=2.187, loss_v1=0, loss_v2=0, nll_loss=0.966, ntokens=912.3, nsentences=32, sample_size=912.3, sample_size_v1=0, sample_size_v2=0, ppl=1.95, wps=491.8, ups=0.54, wpb=912.3, bsz=32, num_updates=31940, lr=1.22965e-05, gnorm=14.528, clip=100, loss_scale=32, train_wall=19, gb_free=11.6, wall=60026
2023-05-26 16:03:50 - progress_bar.py[line:272] - INFO: epoch 019:    830 / 1732 loss=2.167, loss_v1=0, loss_v2=0, nll_loss=0.943, ntokens=919.5, nsentences=32, sample_size=919.5, sample_size_v1=0, sample_size_v2=0, ppl=1.92, wps=497.4, ups=0.54, wpb=919.5, bsz=32, num_updates=31950, lr=1.22904e-05, gnorm=14.589, clip=100, loss_scale=32, train_wall=18, gb_free=11.7, wall=60045
2023-05-26 16:04:08 - progress_bar.py[line:272] - INFO: epoch 019:    840 / 1732 loss=2.186, loss_v1=0, loss_v2=0, nll_loss=0.964, ntokens=917.9, nsentences=32, sample_size=917.9, sample_size_v1=0, sample_size_v2=0, ppl=1.95, wps=499, ups=0.54, wpb=917.9, bsz=32, num_updates=31960, lr=1.22843e-05, gnorm=13.347, clip=100, loss_scale=32, train_wall=18, gb_free=11.2, wall=60063
2023-05-26 16:04:27 - progress_bar.py[line:272] - INFO: epoch 019:    850 / 1732 loss=2.191, loss_v1=0, loss_v2=0, nll_loss=0.969, ntokens=1015.3, nsentences=32, sample_size=1015.3, sample_size_v1=0, sample_size_v2=0, ppl=1.96, wps=548.7, ups=0.54, wpb=1015.3, bsz=32, num_updates=31970, lr=1.22781e-05, gnorm=13.2, clip=100, loss_scale=32, train_wall=18, gb_free=11.6, wall=60081
2023-05-26 16:04:45 - progress_bar.py[line:272] - INFO: epoch 019:    860 / 1732 loss=2.162, loss_v1=0, loss_v2=0, nll_loss=0.938, ntokens=930.1, nsentences=32, sample_size=930.1, sample_size_v1=0, sample_size_v2=0, ppl=1.92, wps=503.3, ups=0.54, wpb=930.1, bsz=32, num_updates=31980, lr=1.2272e-05, gnorm=13.153, clip=100, loss_scale=32, train_wall=18, gb_free=11.7, wall=60100
2023-05-26 16:05:04 - progress_bar.py[line:272] - INFO: epoch 019:    870 / 1732 loss=2.18, loss_v1=0, loss_v2=0, nll_loss=0.959, ntokens=970.4, nsentences=32, sample_size=970.4, sample_size_v1=0, sample_size_v2=0, ppl=1.94, wps=524.7, ups=0.54, wpb=970.4, bsz=32, num_updates=31990, lr=1.22658e-05, gnorm=14.001, clip=100, loss_scale=32, train_wall=18, gb_free=11.6, wall=60118
2023-05-26 16:05:22 - progress_bar.py[line:272] - INFO: epoch 019:    880 / 1732 loss=2.133, loss_v1=0, loss_v2=0, nll_loss=0.906, ntokens=1004.9, nsentences=32, sample_size=1004.9, sample_size_v1=0, sample_size_v2=0, ppl=1.87, wps=538.4, ups=0.54, wpb=1004.9, bsz=32, num_updates=32000, lr=1.22597e-05, gnorm=12.422, clip=100, loss_scale=32, train_wall=19, gb_free=11.1, wall=60137
2023-05-26 16:05:41 - progress_bar.py[line:272] - INFO: epoch 019:    890 / 1732 loss=2.114, loss_v1=0, loss_v2=0, nll_loss=0.884, ntokens=986.6, nsentences=32, sample_size=986.6, sample_size_v1=0, sample_size_v2=0, ppl=1.85, wps=531.6, ups=0.54, wpb=986.6, bsz=32, num_updates=32010, lr=1.22535e-05, gnorm=11.608, clip=100, loss_scale=32, train_wall=19, gb_free=11.2, wall=60156
2023-05-26 16:06:00 - progress_bar.py[line:272] - INFO: epoch 019:    900 / 1732 loss=2.123, loss_v1=0, loss_v2=0, nll_loss=0.893, ntokens=1043.1, nsentences=32, sample_size=1043.1, sample_size_v1=0, sample_size_v2=0, ppl=1.86, wps=560.6, ups=0.54, wpb=1043.1, bsz=32, num_updates=32020, lr=1.22474e-05, gnorm=12.508, clip=100, loss_scale=32, train_wall=19, gb_free=11.8, wall=60174
2023-05-26 16:06:18 - progress_bar.py[line:272] - INFO: epoch 019:    910 / 1732 loss=2.157, loss_v1=0, loss_v2=0, nll_loss=0.932, ntokens=976.1, nsentences=32, sample_size=976.1, sample_size_v1=0, sample_size_v2=0, ppl=1.91, wps=526, ups=0.54, wpb=976.1, bsz=32, num_updates=32030, lr=1.22413e-05, gnorm=12.712, clip=100, loss_scale=32, train_wall=19, gb_free=11.5, wall=60193
2023-05-26 16:06:37 - progress_bar.py[line:272] - INFO: epoch 019:    920 / 1732 loss=2.192, loss_v1=0, loss_v2=0, nll_loss=0.972, ntokens=983.5, nsentences=32, sample_size=983.5, sample_size_v1=0, sample_size_v2=0, ppl=1.96, wps=528.6, ups=0.54, wpb=983.5, bsz=32, num_updates=32040, lr=1.22351e-05, gnorm=14.408, clip=100, loss_scale=32, train_wall=19, gb_free=11.7, wall=60211
2023-05-26 16:06:56 - progress_bar.py[line:272] - INFO: epoch 019:    930 / 1732 loss=2.156, loss_v1=0, loss_v2=0, nll_loss=0.93, ntokens=1038.6, nsentences=32, sample_size=1038.6, sample_size_v1=0, sample_size_v2=0, ppl=1.91, wps=554.5, ups=0.53, wpb=1038.6, bsz=32, num_updates=32050, lr=1.2229e-05, gnorm=12.253, clip=100, loss_scale=32, train_wall=19, gb_free=11.7, wall=60230
2023-05-26 16:07:14 - progress_bar.py[line:272] - INFO: epoch 019:    940 / 1732 loss=2.164, loss_v1=0, loss_v2=0, nll_loss=0.94, ntokens=1043.2, nsentences=32, sample_size=1043.2, sample_size_v1=0, sample_size_v2=0, ppl=1.92, wps=553, ups=0.53, wpb=1043.2, bsz=32, num_updates=32060, lr=1.22228e-05, gnorm=12.303, clip=100, loss_scale=32, train_wall=19, gb_free=10.9, wall=60249
2023-05-26 16:07:33 - progress_bar.py[line:272] - INFO: epoch 019:    950 / 1732 loss=2.18, loss_v1=0, loss_v2=0, nll_loss=0.958, ntokens=1038.6, nsentences=32, sample_size=1038.6, sample_size_v1=0, sample_size_v2=0, ppl=1.94, wps=553.5, ups=0.53, wpb=1038.6, bsz=32, num_updates=32070, lr=1.22167e-05, gnorm=13.635, clip=100, loss_scale=32, train_wall=19, gb_free=11.6, wall=60268
2023-05-26 16:07:52 - progress_bar.py[line:272] - INFO: epoch 019:    960 / 1732 loss=2.172, loss_v1=0, loss_v2=0, nll_loss=0.948, ntokens=1044.3, nsentences=32, sample_size=1044.3, sample_size_v1=0, sample_size_v2=0, ppl=1.93, wps=555.3, ups=0.53, wpb=1044.3, bsz=32, num_updates=32080, lr=1.22106e-05, gnorm=12.809, clip=100, loss_scale=32, train_wall=19, gb_free=11.4, wall=60287
2023-05-26 16:08:11 - progress_bar.py[line:272] - INFO: epoch 019:    970 / 1732 loss=2.195, loss_v1=0, loss_v2=0, nll_loss=0.974, ntokens=1054.8, nsentences=32, sample_size=1054.8, sample_size_v1=0, sample_size_v2=0, ppl=1.96, wps=563.4, ups=0.53, wpb=1054.8, bsz=32, num_updates=32090, lr=1.22044e-05, gnorm=13.551, clip=100, loss_scale=32, train_wall=19, gb_free=11.5, wall=60305
2023-05-26 16:08:30 - progress_bar.py[line:272] - INFO: epoch 019:    980 / 1732 loss=2.16, loss_v1=0, loss_v2=0, nll_loss=0.934, ntokens=1012, nsentences=32, sample_size=1012, sample_size_v1=0, sample_size_v2=0, ppl=1.91, wps=535, ups=0.53, wpb=1012, bsz=32, num_updates=32100, lr=1.21983e-05, gnorm=12.492, clip=100, loss_scale=32, train_wall=19, gb_free=11.5, wall=60324
2023-05-26 16:08:49 - progress_bar.py[line:272] - INFO: epoch 019:    990 / 1732 loss=2.179, loss_v1=0, loss_v2=0, nll_loss=0.957, ntokens=1049.1, nsentences=32, sample_size=1049.1, sample_size_v1=0, sample_size_v2=0, ppl=1.94, wps=555.1, ups=0.53, wpb=1049.1, bsz=32, num_updates=32110, lr=1.21921e-05, gnorm=11.928, clip=100, loss_scale=32, train_wall=19, gb_free=11.4, wall=60343
2023-05-26 16:09:07 - progress_bar.py[line:272] - INFO: epoch 019:   1000 / 1732 loss=2.163, loss_v1=0, loss_v2=0, nll_loss=0.937, ntokens=1015.5, nsentences=32, sample_size=1015.5, sample_size_v1=0, sample_size_v2=0, ppl=1.91, wps=544.1, ups=0.54, wpb=1015.5, bsz=32, num_updates=32120, lr=1.2186e-05, gnorm=13.025, clip=100, loss_scale=32, train_wall=19, gb_free=11.7, wall=60362
2023-05-26 16:09:26 - progress_bar.py[line:272] - INFO: epoch 019:   1010 / 1732 loss=2.183, loss_v1=0, loss_v2=0, nll_loss=0.96, ntokens=1013.4, nsentences=32, sample_size=1013.4, sample_size_v1=0, sample_size_v2=0, ppl=1.94, wps=539.3, ups=0.53, wpb=1013.4, bsz=32, num_updates=32130, lr=1.21798e-05, gnorm=13.451, clip=100, loss_scale=32, train_wall=19, gb_free=11.7, wall=60381
2023-05-26 16:09:45 - progress_bar.py[line:272] - INFO: epoch 019:   1020 / 1732 loss=2.149, loss_v1=0, loss_v2=0, nll_loss=0.922, ntokens=1035.8, nsentences=32, sample_size=1035.8, sample_size_v1=0, sample_size_v2=0, ppl=1.89, wps=553.4, ups=0.53, wpb=1035.8, bsz=32, num_updates=32140, lr=1.21737e-05, gnorm=13.055, clip=100, loss_scale=32, train_wall=19, gb_free=11.3, wall=60399
2023-05-26 16:10:04 - progress_bar.py[line:272] - INFO: epoch 019:   1030 / 1732 loss=2.177, loss_v1=0, loss_v2=0, nll_loss=0.954, ntokens=1101.6, nsentences=32, sample_size=1101.6, sample_size_v1=0, sample_size_v2=0, ppl=1.94, wps=579.8, ups=0.53, wpb=1101.6, bsz=32, num_updates=32150, lr=1.21676e-05, gnorm=13.413, clip=100, loss_scale=32, train_wall=19, gb_free=11.2, wall=60418
2023-05-26 16:10:23 - progress_bar.py[line:272] - INFO: epoch 019:   1040 / 1732 loss=2.168, loss_v1=0, loss_v2=0, nll_loss=0.944, ntokens=1070.8, nsentences=32, sample_size=1070.8, sample_size_v1=0, sample_size_v2=0, ppl=1.92, wps=568.7, ups=0.53, wpb=1070.8, bsz=32, num_updates=32160, lr=1.21614e-05, gnorm=13.308, clip=100, loss_scale=32, train_wall=19, gb_free=10.8, wall=60437
2023-05-26 16:10:41 - progress_bar.py[line:272] - INFO: epoch 019:   1050 / 1732 loss=2.176, loss_v1=0, loss_v2=0, nll_loss=0.953, ntokens=1039.3, nsentences=32, sample_size=1039.3, sample_size_v1=0, sample_size_v2=0, ppl=1.94, wps=555.8, ups=0.53, wpb=1039.3, bsz=32, num_updates=32170, lr=1.21553e-05, gnorm=14.211, clip=100, loss_scale=32, train_wall=19, gb_free=11.4, wall=60456
2023-05-26 16:11:00 - progress_bar.py[line:272] - INFO: epoch 019:   1060 / 1732 loss=2.166, loss_v1=0, loss_v2=0, nll_loss=0.942, ntokens=1066.3, nsentences=32, sample_size=1066.3, sample_size_v1=0, sample_size_v2=0, ppl=1.92, wps=567.9, ups=0.53, wpb=1066.3, bsz=32, num_updates=32180, lr=1.21491e-05, gnorm=13.046, clip=100, loss_scale=32, train_wall=19, gb_free=10.9, wall=60475
2023-05-26 16:11:19 - progress_bar.py[line:272] - INFO: epoch 019:   1070 / 1732 loss=2.161, loss_v1=0, loss_v2=0, nll_loss=0.936, ntokens=985.6, nsentences=32, sample_size=985.6, sample_size_v1=0, sample_size_v2=0, ppl=1.91, wps=526.8, ups=0.53, wpb=985.6, bsz=32, num_updates=32190, lr=1.2143e-05, gnorm=13.267, clip=100, loss_scale=32, train_wall=19, gb_free=10.9, wall=60493
2023-05-26 16:11:38 - progress_bar.py[line:272] - INFO: epoch 019:   1080 / 1732 loss=2.184, loss_v1=0, loss_v2=0, nll_loss=0.962, ntokens=1039.6, nsentences=32, sample_size=1039.6, sample_size_v1=0, sample_size_v2=0, ppl=1.95, wps=550, ups=0.53, wpb=1039.6, bsz=32, num_updates=32200, lr=1.21368e-05, gnorm=14.069, clip=100, loss_scale=32, train_wall=19, gb_free=11.1, wall=60512
2023-05-26 16:11:57 - progress_bar.py[line:272] - INFO: epoch 019:   1090 / 1732 loss=2.169, loss_v1=0, loss_v2=0, nll_loss=0.945, ntokens=1074, nsentences=32, sample_size=1074, sample_size_v1=0, sample_size_v2=0, ppl=1.93, wps=568, ups=0.53, wpb=1074, bsz=32, num_updates=32210, lr=1.21307e-05, gnorm=12.756, clip=100, loss_scale=32, train_wall=19, gb_free=11.2, wall=60531
2023-05-26 16:12:15 - progress_bar.py[line:272] - INFO: epoch 019:   1100 / 1732 loss=2.175, loss_v1=0, loss_v2=0, nll_loss=0.952, ntokens=1032, nsentences=32, sample_size=1032, sample_size_v1=0, sample_size_v2=0, ppl=1.94, wps=550.7, ups=0.53, wpb=1032, bsz=32, num_updates=32220, lr=1.21246e-05, gnorm=13.045, clip=100, loss_scale=32, train_wall=19, gb_free=11.5, wall=60550
2023-05-26 16:12:34 - progress_bar.py[line:272] - INFO: epoch 019:   1110 / 1732 loss=2.167, loss_v1=0, loss_v2=0, nll_loss=0.94, ntokens=1053.3, nsentences=32, sample_size=1053.3, sample_size_v1=0, sample_size_v2=0, ppl=1.92, wps=557.7, ups=0.53, wpb=1053.3, bsz=32, num_updates=32230, lr=1.21184e-05, gnorm=13.59, clip=100, loss_scale=32, train_wall=19, gb_free=11.4, wall=60569
2023-05-26 16:12:53 - progress_bar.py[line:272] - INFO: epoch 019:   1120 / 1732 loss=2.17, loss_v1=0, loss_v2=0, nll_loss=0.945, ntokens=958.1, nsentences=32, sample_size=958.1, sample_size_v1=0, sample_size_v2=0, ppl=1.92, wps=508.9, ups=0.53, wpb=958.1, bsz=32, num_updates=32240, lr=1.21123e-05, gnorm=15.248, clip=100, loss_scale=32, train_wall=19, gb_free=11.5, wall=60588
2023-05-26 16:13:12 - progress_bar.py[line:272] - INFO: epoch 019:   1130 / 1732 loss=2.155, loss_v1=0, loss_v2=0, nll_loss=0.931, ntokens=1008.8, nsentences=32, sample_size=1008.8, sample_size_v1=0, sample_size_v2=0, ppl=1.91, wps=536.9, ups=0.53, wpb=1008.8, bsz=32, num_updates=32250, lr=1.21061e-05, gnorm=12.35, clip=100, loss_scale=32, train_wall=19, gb_free=11.5, wall=60606
2023-05-26 16:13:31 - progress_bar.py[line:272] - INFO: epoch 019:   1140 / 1732 loss=2.168, loss_v1=0, loss_v2=0, nll_loss=0.944, ntokens=1003.3, nsentences=32, sample_size=1003.3, sample_size_v1=0, sample_size_v2=0, ppl=1.92, wps=537.1, ups=0.54, wpb=1003.3, bsz=32, num_updates=32260, lr=1.21e-05, gnorm=13.228, clip=100, loss_scale=32, train_wall=19, gb_free=11.7, wall=60625
2023-05-26 16:13:49 - progress_bar.py[line:272] - INFO: epoch 019:   1150 / 1732 loss=2.148, loss_v1=0, loss_v2=0, nll_loss=0.922, ntokens=1020.4, nsentences=32, sample_size=1020.4, sample_size_v1=0, sample_size_v2=0, ppl=1.89, wps=544.4, ups=0.53, wpb=1020.4, bsz=32, num_updates=32270, lr=1.20939e-05, gnorm=12.654, clip=100, loss_scale=32, train_wall=19, gb_free=11.6, wall=60644
2023-05-26 16:14:08 - progress_bar.py[line:272] - INFO: epoch 019:   1160 / 1732 loss=2.142, loss_v1=0, loss_v2=0, nll_loss=0.915, ntokens=995, nsentences=32, sample_size=995, sample_size_v1=0, sample_size_v2=0, ppl=1.89, wps=528.3, ups=0.53, wpb=995, bsz=32, num_updates=32280, lr=1.20877e-05, gnorm=14.154, clip=100, loss_scale=32, train_wall=19, gb_free=11.3, wall=60663
2023-05-26 16:14:27 - progress_bar.py[line:272] - INFO: epoch 019:   1170 / 1732 loss=2.137, loss_v1=0, loss_v2=0, nll_loss=0.91, ntokens=1051.7, nsentences=32, sample_size=1051.7, sample_size_v1=0, sample_size_v2=0, ppl=1.88, wps=557.2, ups=0.53, wpb=1051.7, bsz=32, num_updates=32290, lr=1.20816e-05, gnorm=12.848, clip=100, loss_scale=64, train_wall=19, gb_free=11, wall=60682
2023-05-26 16:14:46 - progress_bar.py[line:272] - INFO: epoch 019:   1180 / 1732 loss=2.138, loss_v1=0, loss_v2=0, nll_loss=0.91, ntokens=1021, nsentences=32, sample_size=1021, sample_size_v1=0, sample_size_v2=0, ppl=1.88, wps=547.2, ups=0.54, wpb=1021, bsz=32, num_updates=32300, lr=1.20754e-05, gnorm=12.75, clip=100, loss_scale=64, train_wall=19, gb_free=11.6, wall=60700
2023-05-26 16:15:04 - progress_bar.py[line:272] - INFO: epoch 019:   1190 / 1732 loss=2.153, loss_v1=0, loss_v2=0, nll_loss=0.926, ntokens=996.9, nsentences=32, sample_size=996.9, sample_size_v1=0, sample_size_v2=0, ppl=1.9, wps=530, ups=0.53, wpb=996.9, bsz=32, num_updates=32310, lr=1.20693e-05, gnorm=12.898, clip=100, loss_scale=64, train_wall=19, gb_free=11.2, wall=60719
2023-05-26 16:15:23 - progress_bar.py[line:272] - INFO: epoch 019:   1200 / 1732 loss=2.159, loss_v1=0, loss_v2=0, nll_loss=0.933, ntokens=1118, nsentences=32, sample_size=1118, sample_size_v1=0, sample_size_v2=0, ppl=1.91, wps=591, ups=0.53, wpb=1118, bsz=32, num_updates=32320, lr=1.20631e-05, gnorm=12.276, clip=100, loss_scale=64, train_wall=19, gb_free=11.3, wall=60738
2023-05-26 16:15:42 - progress_bar.py[line:272] - INFO: epoch 019:   1210 / 1732 loss=2.132, loss_v1=0, loss_v2=0, nll_loss=0.903, ntokens=1074.7, nsentences=32, sample_size=1074.7, sample_size_v1=0, sample_size_v2=0, ppl=1.87, wps=566.2, ups=0.53, wpb=1074.7, bsz=32, num_updates=32330, lr=1.2057e-05, gnorm=12.67, clip=100, loss_scale=64, train_wall=19, gb_free=11.3, wall=60757
2023-05-26 16:16:01 - progress_bar.py[line:272] - INFO: epoch 019:   1220 / 1732 loss=2.196, loss_v1=0, loss_v2=0, nll_loss=0.975, ntokens=1018.6, nsentences=32, sample_size=1018.6, sample_size_v1=0, sample_size_v2=0, ppl=1.97, wps=543.9, ups=0.53, wpb=1018.6, bsz=32, num_updates=32340, lr=1.20509e-05, gnorm=13.438, clip=100, loss_scale=64, train_wall=19, gb_free=11.4, wall=60776
2023-05-26 16:16:18 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2023-05-26 16:16:22 - progress_bar.py[line:272] - INFO: epoch 019:   1231 / 1732 loss=2.145, loss_v1=0, loss_v2=0, nll_loss=0.919, ntokens=1003.6, nsentences=32, sample_size=1003.6, sample_size_v1=0, sample_size_v2=0, ppl=1.89, wps=488, ups=0.49, wpb=1003.6, bsz=32, num_updates=32350, lr=1.20447e-05, gnorm=13, clip=100, loss_scale=32, train_wall=21, gb_free=11.4, wall=60796
2023-05-26 16:16:41 - progress_bar.py[line:272] - INFO: epoch 019:   1241 / 1732 loss=2.124, loss_v1=0, loss_v2=0, nll_loss=0.896, ntokens=1099, nsentences=32, sample_size=1099, sample_size_v1=0, sample_size_v2=0, ppl=1.86, wps=581.2, ups=0.53, wpb=1099, bsz=32, num_updates=32360, lr=1.20386e-05, gnorm=12.885, clip=100, loss_scale=32, train_wall=19, gb_free=11.7, wall=60815
2023-05-26 16:16:59 - progress_bar.py[line:272] - INFO: epoch 019:   1251 / 1732 loss=2.134, loss_v1=0, loss_v2=0, nll_loss=0.906, ntokens=1063.8, nsentences=32, sample_size=1063.8, sample_size_v1=0, sample_size_v2=0, ppl=1.87, wps=564.6, ups=0.53, wpb=1063.8, bsz=32, num_updates=32370, lr=1.20324e-05, gnorm=12.243, clip=100, loss_scale=32, train_wall=19, gb_free=11.2, wall=60834
2023-05-26 16:17:18 - progress_bar.py[line:272] - INFO: epoch 019:   1261 / 1732 loss=2.148, loss_v1=0, loss_v2=0, nll_loss=0.923, ntokens=1068.4, nsentences=32, sample_size=1068.4, sample_size_v1=0, sample_size_v2=0, ppl=1.9, wps=566.3, ups=0.53, wpb=1068.4, bsz=32, num_updates=32380, lr=1.20263e-05, gnorm=13.575, clip=100, loss_scale=32, train_wall=19, gb_free=11, wall=60853
2023-05-26 16:17:37 - progress_bar.py[line:272] - INFO: epoch 019:   1271 / 1732 loss=2.162, loss_v1=0, loss_v2=0, nll_loss=0.938, ntokens=1028.5, nsentences=32, sample_size=1028.5, sample_size_v1=0, sample_size_v2=0, ppl=1.92, wps=549.1, ups=0.53, wpb=1028.5, bsz=32, num_updates=32390, lr=1.20201e-05, gnorm=12.236, clip=100, loss_scale=32, train_wall=19, gb_free=11.8, wall=60872
2023-05-26 16:17:56 - progress_bar.py[line:272] - INFO: epoch 019:   1281 / 1732 loss=2.133, loss_v1=0, loss_v2=0, nll_loss=0.905, ntokens=1068.6, nsentences=32, sample_size=1068.6, sample_size_v1=0, sample_size_v2=0, ppl=1.87, wps=563.6, ups=0.53, wpb=1068.6, bsz=32, num_updates=32400, lr=1.2014e-05, gnorm=11.795, clip=100, loss_scale=32, train_wall=19, gb_free=11.3, wall=60891
2023-05-26 16:18:15 - progress_bar.py[line:272] - INFO: epoch 019:   1291 / 1732 loss=2.141, loss_v1=0, loss_v2=0, nll_loss=0.913, ntokens=1084.2, nsentences=32, sample_size=1084.2, sample_size_v1=0, sample_size_v2=0, ppl=1.88, wps=573.4, ups=0.53, wpb=1084.2, bsz=32, num_updates=32410, lr=1.20079e-05, gnorm=12.664, clip=100, loss_scale=32, train_wall=19, gb_free=11.5, wall=60910
2023-05-26 16:18:34 - progress_bar.py[line:272] - INFO: epoch 019:   1301 / 1732 loss=2.153, loss_v1=0, loss_v2=0, nll_loss=0.928, ntokens=1090.9, nsentences=32, sample_size=1090.9, sample_size_v1=0, sample_size_v2=0, ppl=1.9, wps=580.4, ups=0.53, wpb=1090.9, bsz=32, num_updates=32420, lr=1.20017e-05, gnorm=12.396, clip=100, loss_scale=32, train_wall=19, gb_free=11.3, wall=60928
2023-05-26 16:18:53 - progress_bar.py[line:272] - INFO: epoch 019:   1311 / 1732 loss=2.189, loss_v1=0, loss_v2=0, nll_loss=0.967, ntokens=1079.3, nsentences=32, sample_size=1079.3, sample_size_v1=0, sample_size_v2=0, ppl=1.95, wps=564.9, ups=0.52, wpb=1079.3, bsz=32, num_updates=32430, lr=1.19956e-05, gnorm=12.397, clip=100, loss_scale=32, train_wall=19, gb_free=10.9, wall=60947
2023-05-26 16:19:12 - progress_bar.py[line:272] - INFO: epoch 019:   1321 / 1732 loss=2.15, loss_v1=0, loss_v2=0, nll_loss=0.926, ntokens=1098.3, nsentences=32, sample_size=1098.3, sample_size_v1=0, sample_size_v2=0, ppl=1.9, wps=580.6, ups=0.53, wpb=1098.3, bsz=32, num_updates=32440, lr=1.19894e-05, gnorm=12.266, clip=100, loss_scale=32, train_wall=19, gb_free=9.2, wall=60966
2023-05-26 16:19:31 - progress_bar.py[line:272] - INFO: epoch 019:   1331 / 1732 loss=2.124, loss_v1=0, loss_v2=0, nll_loss=0.896, ntokens=1102.8, nsentences=32, sample_size=1102.8, sample_size_v1=0, sample_size_v2=0, ppl=1.86, wps=584.1, ups=0.53, wpb=1102.8, bsz=32, num_updates=32450, lr=1.19833e-05, gnorm=12.577, clip=100, loss_scale=32, train_wall=19, gb_free=11.3, wall=60985
2023-05-26 16:19:50 - progress_bar.py[line:272] - INFO: epoch 019:   1341 / 1732 loss=2.147, loss_v1=0, loss_v2=0, nll_loss=0.92, ntokens=1167.8, nsentences=32, sample_size=1167.8, sample_size_v1=0, sample_size_v2=0, ppl=1.89, wps=616, ups=0.53, wpb=1167.8, bsz=32, num_updates=32460, lr=1.19772e-05, gnorm=12.159, clip=100, loss_scale=32, train_wall=19, gb_free=10.9, wall=61004
2023-05-26 16:20:09 - progress_bar.py[line:272] - INFO: epoch 019:   1351 / 1732 loss=2.148, loss_v1=0, loss_v2=0, nll_loss=0.921, ntokens=1137.2, nsentences=32, sample_size=1137.2, sample_size_v1=0, sample_size_v2=0, ppl=1.89, wps=599.6, ups=0.53, wpb=1137.2, bsz=32, num_updates=32470, lr=1.1971e-05, gnorm=12.107, clip=100, loss_scale=32, train_wall=19, gb_free=11, wall=61023
2023-05-26 16:20:28 - progress_bar.py[line:272] - INFO: epoch 019:   1361 / 1732 loss=2.117, loss_v1=0, loss_v2=0, nll_loss=0.887, ntokens=1107.4, nsentences=32, sample_size=1107.4, sample_size_v1=0, sample_size_v2=0, ppl=1.85, wps=583.7, ups=0.53, wpb=1107.4, bsz=32, num_updates=32480, lr=1.19649e-05, gnorm=12.489, clip=100, loss_scale=32, train_wall=19, gb_free=11.3, wall=61042
2023-05-26 16:20:46 - progress_bar.py[line:272] - INFO: epoch 019:   1371 / 1732 loss=2.159, loss_v1=0, loss_v2=0, nll_loss=0.933, ntokens=1105.1, nsentences=32, sample_size=1105.1, sample_size_v1=0, sample_size_v2=0, ppl=1.91, wps=585.2, ups=0.53, wpb=1105.1, bsz=32, num_updates=32490, lr=1.19587e-05, gnorm=13.345, clip=100, loss_scale=32, train_wall=19, gb_free=11.6, wall=61061
2023-05-26 16:21:05 - progress_bar.py[line:272] - INFO: epoch 019:   1381 / 1732 loss=2.178, loss_v1=0, loss_v2=0, nll_loss=0.954, ntokens=1138.6, nsentences=32, sample_size=1138.6, sample_size_v1=0, sample_size_v2=0, ppl=1.94, wps=604.4, ups=0.53, wpb=1138.6, bsz=32, num_updates=32500, lr=1.19526e-05, gnorm=13.06, clip=100, loss_scale=32, train_wall=19, gb_free=11.3, wall=61080
2023-05-26 16:21:24 - progress_bar.py[line:272] - INFO: epoch 019:   1391 / 1732 loss=2.162, loss_v1=0, loss_v2=0, nll_loss=0.937, ntokens=1079.9, nsentences=32, sample_size=1079.9, sample_size_v1=0, sample_size_v2=0, ppl=1.91, wps=577.7, ups=0.53, wpb=1079.9, bsz=32, num_updates=32510, lr=1.19464e-05, gnorm=12.563, clip=100, loss_scale=32, train_wall=19, gb_free=10.9, wall=61099
2023-05-26 16:21:43 - progress_bar.py[line:272] - INFO: epoch 019:   1401 / 1732 loss=2.128, loss_v1=0, loss_v2=0, nll_loss=0.901, ntokens=1107.2, nsentences=32, sample_size=1107.2, sample_size_v1=0, sample_size_v2=0, ppl=1.87, wps=586.2, ups=0.53, wpb=1107.2, bsz=32, num_updates=32520, lr=1.19403e-05, gnorm=12.472, clip=100, loss_scale=32, train_wall=19, gb_free=11.7, wall=61117
2023-05-26 16:22:02 - progress_bar.py[line:272] - INFO: epoch 019:   1411 / 1732 loss=2.176, loss_v1=0, loss_v2=0, nll_loss=0.953, ntokens=1229.2, nsentences=32, sample_size=1229.2, sample_size_v1=0, sample_size_v2=0, ppl=1.94, wps=647.4, ups=0.53, wpb=1229.2, bsz=32, num_updates=32530, lr=1.19342e-05, gnorm=11.971, clip=100, loss_scale=32, train_wall=19, gb_free=10.9, wall=61136
2023-05-26 16:22:21 - progress_bar.py[line:272] - INFO: epoch 019:   1421 / 1732 loss=2.183, loss_v1=0, loss_v2=0, nll_loss=0.96, ntokens=1255.1, nsentences=32, sample_size=1255.1, sample_size_v1=0, sample_size_v2=0, ppl=1.94, wps=654.7, ups=0.52, wpb=1255.1, bsz=32, num_updates=32540, lr=1.1928e-05, gnorm=11.802, clip=100, loss_scale=32, train_wall=19, gb_free=9.9, wall=61156
2023-05-26 16:22:40 - progress_bar.py[line:272] - INFO: epoch 019:   1431 / 1732 loss=2.148, loss_v1=0, loss_v2=0, nll_loss=0.92, ntokens=1244.5, nsentences=32, sample_size=1244.5, sample_size_v1=0, sample_size_v2=0, ppl=1.89, wps=656.8, ups=0.53, wpb=1244.5, bsz=32, num_updates=32550, lr=1.19219e-05, gnorm=12.065, clip=100, loss_scale=32, train_wall=19, gb_free=10.7, wall=61175
2023-05-26 16:22:59 - progress_bar.py[line:272] - INFO: epoch 019:   1441 / 1732 loss=2.162, loss_v1=0, loss_v2=0, nll_loss=0.938, ntokens=1138.5, nsentences=32, sample_size=1138.5, sample_size_v1=0, sample_size_v2=0, ppl=1.92, wps=603.7, ups=0.53, wpb=1138.5, bsz=32, num_updates=32560, lr=1.19157e-05, gnorm=12.119, clip=100, loss_scale=32, train_wall=19, gb_free=11.1, wall=61193
2023-05-26 16:23:18 - progress_bar.py[line:272] - INFO: epoch 019:   1451 / 1732 loss=2.151, loss_v1=0, loss_v2=0, nll_loss=0.925, ntokens=1144.4, nsentences=32, sample_size=1144.4, sample_size_v1=0, sample_size_v2=0, ppl=1.9, wps=602.8, ups=0.53, wpb=1144.4, bsz=32, num_updates=32570, lr=1.19096e-05, gnorm=12.806, clip=100, loss_scale=32, train_wall=19, gb_free=10.8, wall=61212
2023-05-26 16:23:37 - progress_bar.py[line:272] - INFO: epoch 019:   1461 / 1732 loss=2.152, loss_v1=0, loss_v2=0, nll_loss=0.925, ntokens=1149.6, nsentences=32, sample_size=1149.6, sample_size_v1=0, sample_size_v2=0, ppl=1.9, wps=608.5, ups=0.53, wpb=1149.6, bsz=32, num_updates=32580, lr=1.19034e-05, gnorm=12.68, clip=100, loss_scale=32, train_wall=19, gb_free=10.9, wall=61231
2023-05-26 16:23:56 - progress_bar.py[line:272] - INFO: epoch 019:   1471 / 1732 loss=2.138, loss_v1=0, loss_v2=0, nll_loss=0.911, ntokens=1162.5, nsentences=32, sample_size=1162.5, sample_size_v1=0, sample_size_v2=0, ppl=1.88, wps=603.7, ups=0.52, wpb=1162.5, bsz=32, num_updates=32590, lr=1.18973e-05, gnorm=13.997, clip=100, loss_scale=32, train_wall=19, gb_free=11.7, wall=61251
2023-05-26 16:24:15 - progress_bar.py[line:272] - INFO: epoch 019:   1481 / 1732 loss=2.167, loss_v1=0, loss_v2=0, nll_loss=0.944, ntokens=1033.9, nsentences=32, sample_size=1033.9, sample_size_v1=0, sample_size_v2=0, ppl=1.92, wps=551.9, ups=0.53, wpb=1033.9, bsz=32, num_updates=32600, lr=1.18912e-05, gnorm=13.691, clip=100, loss_scale=32, train_wall=19, gb_free=11, wall=61269
2023-05-26 16:24:34 - progress_bar.py[line:272] - INFO: epoch 019:   1491 / 1732 loss=2.157, loss_v1=0, loss_v2=0, nll_loss=0.93, ntokens=1139.7, nsentences=32, sample_size=1139.7, sample_size_v1=0, sample_size_v2=0, ppl=1.91, wps=600.1, ups=0.53, wpb=1139.7, bsz=32, num_updates=32610, lr=1.1885e-05, gnorm=13.287, clip=100, loss_scale=32, train_wall=19, gb_free=11.3, wall=61288
2023-05-26 16:24:53 - progress_bar.py[line:272] - INFO: epoch 019:   1501 / 1732 loss=2.122, loss_v1=0, loss_v2=0, nll_loss=0.89, ntokens=1132.8, nsentences=32, sample_size=1132.8, sample_size_v1=0, sample_size_v2=0, ppl=1.85, wps=598.2, ups=0.53, wpb=1132.8, bsz=32, num_updates=32620, lr=1.18789e-05, gnorm=14.389, clip=100, loss_scale=32, train_wall=19, gb_free=10.6, wall=61307
2023-05-26 16:25:11 - progress_bar.py[line:272] - INFO: epoch 019:   1511 / 1732 loss=2.146, loss_v1=0, loss_v2=0, nll_loss=0.919, ntokens=1056, nsentences=32, sample_size=1056, sample_size_v1=0, sample_size_v2=0, ppl=1.89, wps=563.4, ups=0.53, wpb=1056, bsz=32, num_updates=32630, lr=1.18727e-05, gnorm=13.596, clip=100, loss_scale=32, train_wall=19, gb_free=10.8, wall=61326
2023-05-26 16:25:30 - progress_bar.py[line:272] - INFO: epoch 019:   1521 / 1732 loss=2.185, loss_v1=0, loss_v2=0, nll_loss=0.963, ntokens=1046.7, nsentences=32, sample_size=1046.7, sample_size_v1=0, sample_size_v2=0, ppl=1.95, wps=557, ups=0.53, wpb=1046.7, bsz=32, num_updates=32640, lr=1.18666e-05, gnorm=14.947, clip=100, loss_scale=32, train_wall=19, gb_free=11.6, wall=61345
2023-05-26 16:25:49 - progress_bar.py[line:272] - INFO: epoch 019:   1531 / 1732 loss=2.174, loss_v1=0, loss_v2=0, nll_loss=0.952, ntokens=1056, nsentences=32, sample_size=1056, sample_size_v1=0, sample_size_v2=0, ppl=1.93, wps=559.6, ups=0.53, wpb=1056, bsz=32, num_updates=32650, lr=1.18605e-05, gnorm=14.35, clip=100, loss_scale=32, train_wall=19, gb_free=10.7, wall=61364
2023-05-26 16:26:08 - progress_bar.py[line:272] - INFO: epoch 019:   1541 / 1732 loss=2.144, loss_v1=0, loss_v2=0, nll_loss=0.917, ntokens=1105.6, nsentences=32, sample_size=1105.6, sample_size_v1=0, sample_size_v2=0, ppl=1.89, wps=582.2, ups=0.53, wpb=1105.6, bsz=32, num_updates=32660, lr=1.18543e-05, gnorm=12.669, clip=100, loss_scale=32, train_wall=19, gb_free=11.4, wall=61383
2023-05-26 16:26:27 - progress_bar.py[line:272] - INFO: epoch 019:   1551 / 1732 loss=2.126, loss_v1=0, loss_v2=0, nll_loss=0.896, ntokens=1073.3, nsentences=32, sample_size=1073.3, sample_size_v1=0, sample_size_v2=0, ppl=1.86, wps=569.8, ups=0.53, wpb=1073.3, bsz=32, num_updates=32670, lr=1.18482e-05, gnorm=13.269, clip=100, loss_scale=32, train_wall=19, gb_free=11.3, wall=61402
2023-05-26 16:26:46 - progress_bar.py[line:272] - INFO: epoch 019:   1561 / 1732 loss=2.133, loss_v1=0, loss_v2=0, nll_loss=0.905, ntokens=1091.5, nsentences=32, sample_size=1091.5, sample_size_v1=0, sample_size_v2=0, ppl=1.87, wps=580.3, ups=0.53, wpb=1091.5, bsz=32, num_updates=32680, lr=1.1842e-05, gnorm=12.593, clip=100, loss_scale=32, train_wall=19, gb_free=11.4, wall=61420
2023-05-26 16:27:05 - progress_bar.py[line:272] - INFO: epoch 019:   1571 / 1732 loss=2.169, loss_v1=0, loss_v2=0, nll_loss=0.946, ntokens=1079.7, nsentences=32, sample_size=1079.7, sample_size_v1=0, sample_size_v2=0, ppl=1.93, wps=571, ups=0.53, wpb=1079.7, bsz=32, num_updates=32690, lr=1.18359e-05, gnorm=13.57, clip=100, loss_scale=32, train_wall=19, gb_free=10.6, wall=61439
2023-05-26 16:27:23 - progress_bar.py[line:272] - INFO: epoch 019:   1581 / 1732 loss=2.17, loss_v1=0, loss_v2=0, nll_loss=0.947, ntokens=984.8, nsentences=32, sample_size=984.8, sample_size_v1=0, sample_size_v2=0, ppl=1.93, wps=524.5, ups=0.53, wpb=984.8, bsz=32, num_updates=32700, lr=1.18297e-05, gnorm=15.473, clip=100, loss_scale=32, train_wall=19, gb_free=10.9, wall=61458
2023-05-26 16:27:42 - progress_bar.py[line:272] - INFO: epoch 019:   1591 / 1732 loss=2.14, loss_v1=0, loss_v2=0, nll_loss=0.913, ntokens=1097.4, nsentences=32, sample_size=1097.4, sample_size_v1=0, sample_size_v2=0, ppl=1.88, wps=580.1, ups=0.53, wpb=1097.4, bsz=32, num_updates=32710, lr=1.18236e-05, gnorm=12.794, clip=100, loss_scale=32, train_wall=19, gb_free=11.1, wall=61477
2023-05-26 16:28:01 - progress_bar.py[line:272] - INFO: epoch 019:   1601 / 1732 loss=2.128, loss_v1=0, loss_v2=0, nll_loss=0.899, ntokens=1085.9, nsentences=32, sample_size=1085.9, sample_size_v1=0, sample_size_v2=0, ppl=1.86, wps=578.2, ups=0.53, wpb=1085.9, bsz=32, num_updates=32720, lr=1.18175e-05, gnorm=12.687, clip=100, loss_scale=32, train_wall=19, gb_free=11.5, wall=61496
2023-05-26 16:28:20 - progress_bar.py[line:272] - INFO: epoch 019:   1611 / 1732 loss=2.128, loss_v1=0, loss_v2=0, nll_loss=0.9, ntokens=1158.1, nsentences=32, sample_size=1158.1, sample_size_v1=0, sample_size_v2=0, ppl=1.87, wps=607.6, ups=0.52, wpb=1158.1, bsz=32, num_updates=32730, lr=1.18113e-05, gnorm=13.216, clip=100, loss_scale=32, train_wall=19, gb_free=11, wall=61515
2023-05-26 16:28:39 - progress_bar.py[line:272] - INFO: epoch 019:   1621 / 1732 loss=2.132, loss_v1=0, loss_v2=0, nll_loss=0.904, ntokens=1113.1, nsentences=32, sample_size=1113.1, sample_size_v1=0, sample_size_v2=0, ppl=1.87, wps=586, ups=0.53, wpb=1113.1, bsz=32, num_updates=32740, lr=1.18052e-05, gnorm=13.665, clip=100, loss_scale=32, train_wall=19, gb_free=11.2, wall=61534
2023-05-26 16:28:58 - progress_bar.py[line:272] - INFO: epoch 019:   1631 / 1732 loss=2.141, loss_v1=0, loss_v2=0, nll_loss=0.913, ntokens=1151.4, nsentences=32, sample_size=1151.4, sample_size_v1=0, sample_size_v2=0, ppl=1.88, wps=607.9, ups=0.53, wpb=1151.4, bsz=32, num_updates=32750, lr=1.1799e-05, gnorm=13.253, clip=100, loss_scale=32, train_wall=19, gb_free=11.2, wall=61553
2023-05-26 16:29:17 - progress_bar.py[line:272] - INFO: epoch 019:   1641 / 1732 loss=2.128, loss_v1=0, loss_v2=0, nll_loss=0.898, ntokens=1178.1, nsentences=32, sample_size=1178.1, sample_size_v1=0, sample_size_v2=0, ppl=1.86, wps=622.3, ups=0.53, wpb=1178.1, bsz=32, num_updates=32760, lr=1.17929e-05, gnorm=11.942, clip=100, loss_scale=32, train_wall=19, gb_free=10.1, wall=61572
2023-05-26 16:29:36 - progress_bar.py[line:272] - INFO: epoch 019:   1651 / 1732 loss=2.141, loss_v1=0, loss_v2=0, nll_loss=0.914, ntokens=1103.6, nsentences=32, sample_size=1103.6, sample_size_v1=0, sample_size_v2=0, ppl=1.88, wps=586.7, ups=0.53, wpb=1103.6, bsz=32, num_updates=32770, lr=1.17867e-05, gnorm=14.198, clip=100, loss_scale=32, train_wall=19, gb_free=12, wall=61591
2023-05-26 16:29:55 - progress_bar.py[line:272] - INFO: epoch 019:   1661 / 1732 loss=2.171, loss_v1=0, loss_v2=0, nll_loss=0.949, ntokens=1033.5, nsentences=32, sample_size=1033.5, sample_size_v1=0, sample_size_v2=0, ppl=1.93, wps=547.6, ups=0.53, wpb=1033.5, bsz=32, num_updates=32780, lr=1.17806e-05, gnorm=14.776, clip=100, loss_scale=32, train_wall=19, gb_free=10.8, wall=61609
2023-05-26 16:30:13 - progress_bar.py[line:272] - INFO: epoch 019:   1671 / 1732 loss=2.139, loss_v1=0, loss_v2=0, nll_loss=0.91, ntokens=998, nsentences=32, sample_size=998, sample_size_v1=0, sample_size_v2=0, ppl=1.88, wps=533.7, ups=0.53, wpb=998, bsz=32, num_updates=32790, lr=1.17745e-05, gnorm=13.029, clip=100, loss_scale=32, train_wall=19, gb_free=11.2, wall=61628
2023-05-26 16:30:32 - progress_bar.py[line:272] - INFO: epoch 019:   1681 / 1732 loss=2.117, loss_v1=0, loss_v2=0, nll_loss=0.887, ntokens=1185.3, nsentences=32, sample_size=1185.3, sample_size_v1=0, sample_size_v2=0, ppl=1.85, wps=621.8, ups=0.52, wpb=1185.3, bsz=32, num_updates=32800, lr=1.17683e-05, gnorm=11.855, clip=100, loss_scale=32, train_wall=19, gb_free=11.4, wall=61647
2023-05-26 16:30:52 - progress_bar.py[line:272] - INFO: epoch 019:   1691 / 1732 loss=2.127, loss_v1=0, loss_v2=0, nll_loss=0.899, ntokens=1205.4, nsentences=32, sample_size=1205.4, sample_size_v1=0, sample_size_v2=0, ppl=1.86, wps=629.3, ups=0.52, wpb=1205.4, bsz=32, num_updates=32810, lr=1.17622e-05, gnorm=11.815, clip=100, loss_scale=32, train_wall=19, gb_free=10.6, wall=61666
2023-05-26 16:31:11 - progress_bar.py[line:272] - INFO: epoch 019:   1701 / 1732 loss=2.146, loss_v1=0, loss_v2=0, nll_loss=0.92, ntokens=1274, nsentences=32, sample_size=1274, sample_size_v1=0, sample_size_v2=0, ppl=1.89, wps=663, ups=0.52, wpb=1274, bsz=32, num_updates=32820, lr=1.1756e-05, gnorm=12.27, clip=100, loss_scale=32, train_wall=19, gb_free=11.3, wall=61686
2023-05-26 16:31:30 - progress_bar.py[line:272] - INFO: epoch 019:   1711 / 1732 loss=2.158, loss_v1=0, loss_v2=0, nll_loss=0.931, ntokens=1171.2, nsentences=32, sample_size=1171.2, sample_size_v1=0, sample_size_v2=0, ppl=1.91, wps=616.3, ups=0.53, wpb=1171.2, bsz=32, num_updates=32830, lr=1.17499e-05, gnorm=13.565, clip=100, loss_scale=32, train_wall=19, gb_free=11.4, wall=61705
2023-05-26 16:31:49 - progress_bar.py[line:272] - INFO: epoch 019:   1721 / 1732 loss=2.12, loss_v1=0, loss_v2=0, nll_loss=0.891, ntokens=1173.7, nsentences=32, sample_size=1173.7, sample_size_v1=0, sample_size_v2=0, ppl=1.85, wps=616.1, ups=0.52, wpb=1173.7, bsz=32, num_updates=32840, lr=1.17438e-05, gnorm=11.379, clip=100, loss_scale=32, train_wall=19, gb_free=10.8, wall=61724
2023-05-26 16:32:08 - progress_bar.py[line:272] - INFO: epoch 019:   1731 / 1732 loss=2.189, loss_v1=0, loss_v2=0, nll_loss=0.968, ntokens=1135.4, nsentences=32, sample_size=1135.4, sample_size_v1=0, sample_size_v2=0, ppl=1.96, wps=599.9, ups=0.53, wpb=1135.4, bsz=32, num_updates=32850, lr=1.17376e-05, gnorm=13.333, clip=100, loss_scale=32, train_wall=19, gb_free=11.2, wall=61743
2023-05-26 16:32:08 - train.py[line:332] - INFO: end of epoch 19 (average epoch stats below)
2023-05-26 16:32:08 - progress_bar.py[line:282] - INFO: epoch 019 | loss 2.155 | loss_v1 0 | loss_v2 0 | nll_loss 0.929 | ntokens 1051.59 | nsentences 31.986 | sample_size 1051.59 | sample_size_v1 0 | sample_size_v2 0 | ppl 1.9 | wps 559 | ups 0.53 | wpb 1051.6 | bsz 32 | num_updates 32851 | lr 1.1737e-05 | gnorm 12.661 | clip 100 | loss_scale 32 | train_wall 3244 | gb_free 11.7 | wall 61743
2023-05-26 16:32:08 - trainer.py[line:639] - INFO: loading train data for epoch 20
local datafile ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 0 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 0 finished initializing row_count and line_idx-to-offset mapping
file ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 0 row count 55400 total row count 55400
slice_id 0 seek offset 0
2023-05-26 16:32:10 - trainer.py[line:703] - INFO: begin training epoch 20
2023-05-26 16:32:10 - train.py[line:305] - INFO: Start iterating over samples
2023-05-26 16:32:28 - progress_bar.py[line:272] - INFO: epoch 020:      9 / 1732 loss=2.125, loss_v1=0, loss_v2=0, nll_loss=0.894, ntokens=1061, nsentences=29.6, sample_size=1061, sample_size_v1=0, sample_size_v2=0, ppl=1.86, wps=535.9, ups=0.51, wpb=1061, bsz=29.6, num_updates=32860, lr=1.17315e-05, gnorm=16.093, clip=100, loss_scale=64, train_wall=18, gb_free=11, wall=61762
2023-05-26 16:32:30 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2023-05-26 16:32:48 - progress_bar.py[line:272] - INFO: epoch 020:     20 / 1732 loss=2.083, loss_v1=0, loss_v2=0, nll_loss=0.847, ntokens=1079.2, nsentences=32, sample_size=1079.2, sample_size_v1=0, sample_size_v2=0, ppl=1.8, wps=520.5, ups=0.48, wpb=1079.2, bsz=32, num_updates=32870, lr=1.17253e-05, gnorm=15.562, clip=100, loss_scale=32, train_wall=21, gb_free=11.4, wall=61783
2023-05-26 16:33:07 - progress_bar.py[line:272] - INFO: epoch 020:     30 / 1732 loss=2.098, loss_v1=0, loss_v2=0, nll_loss=0.865, ntokens=962.6, nsentences=32, sample_size=962.6, sample_size_v1=0, sample_size_v2=0, ppl=1.82, wps=512.6, ups=0.53, wpb=962.6, bsz=32, num_updates=32880, lr=1.17192e-05, gnorm=15.523, clip=100, loss_scale=32, train_wall=19, gb_free=11.3, wall=61802
2023-05-26 16:33:26 - progress_bar.py[line:272] - INFO: epoch 020:     40 / 1732 loss=1.975, loss_v1=0, loss_v2=0, nll_loss=0.728, ntokens=1211.6, nsentences=32, sample_size=1211.6, sample_size_v1=0, sample_size_v2=0, ppl=1.66, wps=632.6, ups=0.52, wpb=1211.6, bsz=32, num_updates=32890, lr=1.1713e-05, gnorm=11.766, clip=100, loss_scale=32, train_wall=19, gb_free=11.3, wall=61821
2023-05-26 16:33:45 - progress_bar.py[line:272] - INFO: epoch 020:     50 / 1732 loss=2.036, loss_v1=0, loss_v2=0, nll_loss=0.799, ntokens=1054.8, nsentences=32, sample_size=1054.8, sample_size_v1=0, sample_size_v2=0, ppl=1.74, wps=558, ups=0.53, wpb=1054.8, bsz=32, num_updates=32900, lr=1.17069e-05, gnorm=12.465, clip=100, loss_scale=32, train_wall=19, gb_free=11.1, wall=61840
2023-05-26 16:34:04 - progress_bar.py[line:272] - INFO: epoch 020:     60 / 1732 loss=1.892, loss_v1=0, loss_v2=0, nll_loss=0.638, ntokens=1049.9, nsentences=32, sample_size=1049.9, sample_size_v1=0, sample_size_v2=0, ppl=1.56, wps=561.6, ups=0.53, wpb=1049.9, bsz=32, num_updates=32910, lr=1.17008e-05, gnorm=12.807, clip=100, loss_scale=32, train_wall=19, gb_free=10.3, wall=61859
2023-05-26 16:34:23 - progress_bar.py[line:272] - INFO: epoch 020:     70 / 1732 loss=1.918, loss_v1=0, loss_v2=0, nll_loss=0.663, ntokens=1412, nsentences=32, sample_size=1412, sample_size_v1=0, sample_size_v2=0, ppl=1.58, wps=722.2, ups=0.51, wpb=1412, bsz=32, num_updates=32920, lr=1.16946e-05, gnorm=9.115, clip=100, loss_scale=32, train_wall=20, gb_free=10.8, wall=61878
2023-05-26 16:34:43 - progress_bar.py[line:272] - INFO: epoch 020:     80 / 1732 loss=1.948, loss_v1=0, loss_v2=0, nll_loss=0.699, ntokens=1259.9, nsentences=32, sample_size=1259.9, sample_size_v1=0, sample_size_v2=0, ppl=1.62, wps=647.3, ups=0.51, wpb=1259.9, bsz=32, num_updates=32930, lr=1.16885e-05, gnorm=10.183, clip=100, loss_scale=32, train_wall=19, gb_free=10.6, wall=61898
2023-05-26 16:35:02 - progress_bar.py[line:272] - INFO: epoch 020:     90 / 1732 loss=2.024, loss_v1=0, loss_v2=0, nll_loss=0.782, ntokens=1086.9, nsentences=32, sample_size=1086.9, sample_size_v1=0, sample_size_v2=0, ppl=1.72, wps=568.5, ups=0.52, wpb=1086.9, bsz=32, num_updates=32940, lr=1.16823e-05, gnorm=12.469, clip=100, loss_scale=32, train_wall=19, gb_free=11, wall=61917
2023-05-26 16:35:21 - progress_bar.py[line:272] - INFO: epoch 020:    100 / 1732 loss=2.011, loss_v1=0, loss_v2=0, nll_loss=0.769, ntokens=1024.5, nsentences=32, sample_size=1024.5, sample_size_v1=0, sample_size_v2=0, ppl=1.7, wps=544.6, ups=0.53, wpb=1024.5, bsz=32, num_updates=32950, lr=1.16762e-05, gnorm=14.454, clip=100, loss_scale=32, train_wall=19, gb_free=10.9, wall=61936
2023-05-26 16:35:40 - progress_bar.py[line:272] - INFO: epoch 020:    110 / 1732 loss=2.147, loss_v1=0, loss_v2=0, nll_loss=0.923, ntokens=1011.2, nsentences=32, sample_size=1011.2, sample_size_v1=0, sample_size_v2=0, ppl=1.9, wps=537.4, ups=0.53, wpb=1011.2, bsz=32, num_updates=32960, lr=1.167e-05, gnorm=15.657, clip=100, loss_scale=32, train_wall=19, gb_free=11, wall=61954
2023-05-26 16:35:59 - progress_bar.py[line:272] - INFO: epoch 020:    120 / 1732 loss=2.145, loss_v1=0, loss_v2=0, nll_loss=0.919, ntokens=1124.3, nsentences=32, sample_size=1124.3, sample_size_v1=0, sample_size_v2=0, ppl=1.89, wps=586.8, ups=0.52, wpb=1124.3, bsz=32, num_updates=32970, lr=1.16639e-05, gnorm=13.286, clip=100, loss_scale=32, train_wall=19, gb_free=10.6, wall=61974
2023-05-26 16:36:18 - progress_bar.py[line:272] - INFO: epoch 020:    130 / 1732 loss=2.127, loss_v1=0, loss_v2=0, nll_loss=0.898, ntokens=1171.7, nsentences=32, sample_size=1171.7, sample_size_v1=0, sample_size_v2=0, ppl=1.86, wps=608.8, ups=0.52, wpb=1171.7, bsz=32, num_updates=32980, lr=1.16578e-05, gnorm=13.505, clip=100, loss_scale=32, train_wall=19, gb_free=10.2, wall=61993
2023-05-26 16:36:37 - progress_bar.py[line:272] - INFO: epoch 020:    140 / 1732 loss=2.103, loss_v1=0, loss_v2=0, nll_loss=0.87, ntokens=1245, nsentences=32, sample_size=1245, sample_size_v1=0, sample_size_v2=0, ppl=1.83, wps=649.1, ups=0.52, wpb=1245, bsz=32, num_updates=32990, lr=1.16516e-05, gnorm=13.645, clip=100, loss_scale=32, train_wall=19, gb_free=10.2, wall=62012
2023-05-26 16:36:57 - progress_bar.py[line:272] - INFO: epoch 020:    150 / 1732 loss=2.067, loss_v1=0, loss_v2=0, nll_loss=0.83, ntokens=1172.1, nsentences=32, sample_size=1172.1, sample_size_v1=0, sample_size_v2=0, ppl=1.78, wps=608.1, ups=0.52, wpb=1172.1, bsz=32, num_updates=33000, lr=1.16455e-05, gnorm=12.742, clip=100, loss_scale=32, train_wall=19, gb_free=11, wall=62031
2023-05-26 16:37:16 - progress_bar.py[line:272] - INFO: epoch 020:    160 / 1732 loss=2.106, loss_v1=0, loss_v2=0, nll_loss=0.876, ntokens=1127.8, nsentences=32, sample_size=1127.8, sample_size_v1=0, sample_size_v2=0, ppl=1.84, wps=589.5, ups=0.52, wpb=1127.8, bsz=32, num_updates=33010, lr=1.16393e-05, gnorm=14.355, clip=100, loss_scale=32, train_wall=19, gb_free=10.9, wall=62050
2023-05-26 16:37:35 - progress_bar.py[line:272] - INFO: epoch 020:    170 / 1732 loss=2.099, loss_v1=0, loss_v2=0, nll_loss=0.868, ntokens=965.3, nsentences=32, sample_size=965.3, sample_size_v1=0, sample_size_v2=0, ppl=1.82, wps=511.4, ups=0.53, wpb=965.3, bsz=32, num_updates=33020, lr=1.16332e-05, gnorm=15.786, clip=100, loss_scale=32, train_wall=19, gb_free=11.4, wall=62069
2023-05-26 16:37:54 - progress_bar.py[line:272] - INFO: epoch 020:    180 / 1732 loss=2.073, loss_v1=0, loss_v2=0, nll_loss=0.838, ntokens=1102.7, nsentences=32, sample_size=1102.7, sample_size_v1=0, sample_size_v2=0, ppl=1.79, wps=578.2, ups=0.52, wpb=1102.7, bsz=32, num_updates=33030, lr=1.1627e-05, gnorm=13.513, clip=100, loss_scale=32, train_wall=19, gb_free=10.9, wall=62088
2023-05-26 16:38:13 - progress_bar.py[line:272] - INFO: epoch 020:    190 / 1732 loss=2.078, loss_v1=0, loss_v2=0, nll_loss=0.843, ntokens=1120.1, nsentences=32, sample_size=1120.1, sample_size_v1=0, sample_size_v2=0, ppl=1.79, wps=587.7, ups=0.52, wpb=1120.1, bsz=32, num_updates=33040, lr=1.16209e-05, gnorm=14.249, clip=100, loss_scale=32, train_wall=19, gb_free=10.7, wall=62107
2023-05-26 16:38:32 - progress_bar.py[line:272] - INFO: epoch 020:    200 / 1732 loss=2.116, loss_v1=0, loss_v2=0, nll_loss=0.885, ntokens=1100.1, nsentences=32, sample_size=1100.1, sample_size_v1=0, sample_size_v2=0, ppl=1.85, wps=582.9, ups=0.53, wpb=1100.1, bsz=32, num_updates=33050, lr=1.16148e-05, gnorm=14.292, clip=100, loss_scale=32, train_wall=19, gb_free=11.7, wall=62126
2023-05-26 16:38:50 - progress_bar.py[line:272] - INFO: epoch 020:    210 / 1732 loss=2.165, loss_v1=0, loss_v2=0, nll_loss=0.941, ntokens=1012.9, nsentences=32, sample_size=1012.9, sample_size_v1=0, sample_size_v2=0, ppl=1.92, wps=541.9, ups=0.53, wpb=1012.9, bsz=32, num_updates=33060, lr=1.16086e-05, gnorm=13.619, clip=100, loss_scale=32, train_wall=19, gb_free=11.3, wall=62145
2023-05-26 16:39:09 - progress_bar.py[line:272] - INFO: epoch 020:    220 / 1732 loss=2.169, loss_v1=0, loss_v2=0, nll_loss=0.946, ntokens=1142.1, nsentences=32, sample_size=1142.1, sample_size_v1=0, sample_size_v2=0, ppl=1.93, wps=610.5, ups=0.53, wpb=1142.1, bsz=32, num_updates=33070, lr=1.16025e-05, gnorm=13.16, clip=100, loss_scale=32, train_wall=19, gb_free=11.2, wall=62164
2023-05-26 16:39:28 - progress_bar.py[line:272] - INFO: epoch 020:    230 / 1732 loss=2.167, loss_v1=0, loss_v2=0, nll_loss=0.944, ntokens=1099.8, nsentences=32, sample_size=1099.8, sample_size_v1=0, sample_size_v2=0, ppl=1.92, wps=587.6, ups=0.53, wpb=1099.8, bsz=32, num_updates=33080, lr=1.15963e-05, gnorm=12.388, clip=100, loss_scale=32, train_wall=19, gb_free=11, wall=62182
2023-05-26 16:39:47 - progress_bar.py[line:272] - INFO: epoch 020:    240 / 1732 loss=2.181, loss_v1=0, loss_v2=0, nll_loss=0.958, ntokens=1111.4, nsentences=32, sample_size=1111.4, sample_size_v1=0, sample_size_v2=0, ppl=1.94, wps=591.9, ups=0.53, wpb=1111.4, bsz=32, num_updates=33090, lr=1.15902e-05, gnorm=12.926, clip=100, loss_scale=32, train_wall=19, gb_free=10.9, wall=62201
2023-05-26 16:40:05 - progress_bar.py[line:272] - INFO: epoch 020:    250 / 1732 loss=2.172, loss_v1=0, loss_v2=0, nll_loss=0.948, ntokens=1170.4, nsentences=32, sample_size=1170.4, sample_size_v1=0, sample_size_v2=0, ppl=1.93, wps=619.9, ups=0.53, wpb=1170.4, bsz=32, num_updates=33100, lr=1.15841e-05, gnorm=12.909, clip=100, loss_scale=32, train_wall=19, gb_free=11.1, wall=62220
2023-05-26 16:40:24 - progress_bar.py[line:272] - INFO: epoch 020:    260 / 1732 loss=2.19, loss_v1=0, loss_v2=0, nll_loss=0.969, ntokens=1120.1, nsentences=32, sample_size=1120.1, sample_size_v1=0, sample_size_v2=0, ppl=1.96, wps=597.3, ups=0.53, wpb=1120.1, bsz=32, num_updates=33110, lr=1.15779e-05, gnorm=13.093, clip=100, loss_scale=32, train_wall=19, gb_free=11.5, wall=62239
2023-05-26 16:40:43 - progress_bar.py[line:272] - INFO: epoch 020:    270 / 1732 loss=2.155, loss_v1=0, loss_v2=0, nll_loss=0.93, ntokens=1146.7, nsentences=32, sample_size=1146.7, sample_size_v1=0, sample_size_v2=0, ppl=1.91, wps=608.9, ups=0.53, wpb=1146.7, bsz=32, num_updates=33120, lr=1.15718e-05, gnorm=11.427, clip=100, loss_scale=32, train_wall=19, gb_free=10.9, wall=62258
2023-05-26 16:41:02 - progress_bar.py[line:272] - INFO: epoch 020:    280 / 1732 loss=2.187, loss_v1=0, loss_v2=0, nll_loss=0.964, ntokens=1171.6, nsentences=32, sample_size=1171.6, sample_size_v1=0, sample_size_v2=0, ppl=1.95, wps=618.4, ups=0.53, wpb=1171.6, bsz=32, num_updates=33130, lr=1.15656e-05, gnorm=12.98, clip=100, loss_scale=32, train_wall=19, gb_free=11, wall=62277
2023-05-26 16:41:21 - progress_bar.py[line:272] - INFO: epoch 020:    290 / 1732 loss=2.143, loss_v1=0, loss_v2=0, nll_loss=0.914, ntokens=1121.4, nsentences=32, sample_size=1121.4, sample_size_v1=0, sample_size_v2=0, ppl=1.88, wps=597.2, ups=0.53, wpb=1121.4, bsz=32, num_updates=33140, lr=1.15595e-05, gnorm=12.55, clip=100, loss_scale=32, train_wall=19, gb_free=11.8, wall=62295
2023-05-26 16:41:40 - progress_bar.py[line:272] - INFO: epoch 020:    300 / 1732 loss=2.16, loss_v1=0, loss_v2=0, nll_loss=0.936, ntokens=1116.4, nsentences=32, sample_size=1116.4, sample_size_v1=0, sample_size_v2=0, ppl=1.91, wps=592.9, ups=0.53, wpb=1116.4, bsz=32, num_updates=33150, lr=1.15533e-05, gnorm=13.199, clip=100, loss_scale=32, train_wall=19, gb_free=10.6, wall=62314
2023-05-26 16:41:58 - progress_bar.py[line:272] - INFO: epoch 020:    310 / 1732 loss=2.153, loss_v1=0, loss_v2=0, nll_loss=0.93, ntokens=1069.4, nsentences=32, sample_size=1069.4, sample_size_v1=0, sample_size_v2=0, ppl=1.91, wps=571.2, ups=0.53, wpb=1069.4, bsz=32, num_updates=33160, lr=1.15472e-05, gnorm=13.845, clip=100, loss_scale=32, train_wall=19, gb_free=10.8, wall=62333
2023-05-26 16:42:17 - progress_bar.py[line:272] - INFO: epoch 020:    320 / 1732 loss=2.193, loss_v1=0, loss_v2=0, nll_loss=0.972, ntokens=1013.1, nsentences=32, sample_size=1013.1, sample_size_v1=0, sample_size_v2=0, ppl=1.96, wps=545.1, ups=0.54, wpb=1013.1, bsz=32, num_updates=33170, lr=1.15411e-05, gnorm=13.535, clip=100, loss_scale=32, train_wall=19, gb_free=11.3, wall=62352
2023-05-26 16:42:36 - progress_bar.py[line:272] - INFO: epoch 020:    330 / 1732 loss=2.206, loss_v1=0, loss_v2=0, nll_loss=0.987, ntokens=1024.4, nsentences=32, sample_size=1024.4, sample_size_v1=0, sample_size_v2=0, ppl=1.98, wps=550.3, ups=0.54, wpb=1024.4, bsz=32, num_updates=33180, lr=1.15349e-05, gnorm=14.02, clip=100, loss_scale=32, train_wall=19, gb_free=11.1, wall=62370
2023-05-26 16:42:54 - progress_bar.py[line:272] - INFO: epoch 020:    340 / 1732 loss=2.146, loss_v1=0, loss_v2=0, nll_loss=0.92, ntokens=959.9, nsentences=32, sample_size=959.9, sample_size_v1=0, sample_size_v2=0, ppl=1.89, wps=517.5, ups=0.54, wpb=959.9, bsz=32, num_updates=33190, lr=1.15288e-05, gnorm=13.515, clip=100, loss_scale=32, train_wall=19, gb_free=11.4, wall=62389
2023-05-26 16:43:13 - progress_bar.py[line:272] - INFO: epoch 020:    350 / 1732 loss=2.158, loss_v1=0, loss_v2=0, nll_loss=0.934, ntokens=909.7, nsentences=32, sample_size=909.7, sample_size_v1=0, sample_size_v2=0, ppl=1.91, wps=491.6, ups=0.54, wpb=909.7, bsz=32, num_updates=33200, lr=1.15226e-05, gnorm=15.274, clip=100, loss_scale=32, train_wall=18, gb_free=11.7, wall=62407
2023-05-26 16:43:31 - progress_bar.py[line:272] - INFO: epoch 020:    360 / 1732 loss=2.196, loss_v1=0, loss_v2=0, nll_loss=0.976, ntokens=938.9, nsentences=32, sample_size=938.9, sample_size_v1=0, sample_size_v2=0, ppl=1.97, wps=506.2, ups=0.54, wpb=938.9, bsz=32, num_updates=33210, lr=1.15165e-05, gnorm=15.344, clip=100, loss_scale=32, train_wall=19, gb_free=11.6, wall=62426
2023-05-26 16:43:50 - progress_bar.py[line:272] - INFO: epoch 020:    370 / 1732 loss=2.195, loss_v1=0, loss_v2=0, nll_loss=0.973, ntokens=953.9, nsentences=32, sample_size=953.9, sample_size_v1=0, sample_size_v2=0, ppl=1.96, wps=514.6, ups=0.54, wpb=953.9, bsz=32, num_updates=33220, lr=1.15103e-05, gnorm=16.543, clip=100, loss_scale=32, train_wall=19, gb_free=12, wall=62444
2023-05-26 16:44:08 - progress_bar.py[line:272] - INFO: epoch 020:    380 / 1732 loss=2.192, loss_v1=0, loss_v2=0, nll_loss=0.971, ntokens=1091.6, nsentences=32, sample_size=1091.6, sample_size_v1=0, sample_size_v2=0, ppl=1.96, wps=586, ups=0.54, wpb=1091.6, bsz=32, num_updates=33230, lr=1.15042e-05, gnorm=13.687, clip=100, loss_scale=32, train_wall=19, gb_free=11.7, wall=62463
2023-05-26 16:44:27 - progress_bar.py[line:272] - INFO: epoch 020:    390 / 1732 loss=2.186, loss_v1=0, loss_v2=0, nll_loss=0.964, ntokens=1027.2, nsentences=32, sample_size=1027.2, sample_size_v1=0, sample_size_v2=0, ppl=1.95, wps=550.6, ups=0.54, wpb=1027.2, bsz=32, num_updates=33240, lr=1.14981e-05, gnorm=13.432, clip=100, loss_scale=32, train_wall=19, gb_free=11.5, wall=62482
2023-05-26 16:44:46 - progress_bar.py[line:272] - INFO: epoch 020:    400 / 1732 loss=2.174, loss_v1=0, loss_v2=0, nll_loss=0.95, ntokens=977.7, nsentences=32, sample_size=977.7, sample_size_v1=0, sample_size_v2=0, ppl=1.93, wps=527.1, ups=0.54, wpb=977.7, bsz=32, num_updates=33250, lr=1.14919e-05, gnorm=14.568, clip=100, loss_scale=32, train_wall=19, gb_free=11.4, wall=62500
2023-05-26 16:45:04 - progress_bar.py[line:272] - INFO: epoch 020:    410 / 1732 loss=2.168, loss_v1=0, loss_v2=0, nll_loss=0.943, ntokens=1069.8, nsentences=32, sample_size=1069.8, sample_size_v1=0, sample_size_v2=0, ppl=1.92, wps=572.3, ups=0.53, wpb=1069.8, bsz=32, num_updates=33260, lr=1.14858e-05, gnorm=13.984, clip=100, loss_scale=32, train_wall=19, gb_free=11.5, wall=62519
2023-05-26 16:45:23 - progress_bar.py[line:272] - INFO: epoch 020:    420 / 1732 loss=2.135, loss_v1=0, loss_v2=0, nll_loss=0.908, ntokens=1036.4, nsentences=32, sample_size=1036.4, sample_size_v1=0, sample_size_v2=0, ppl=1.88, wps=554.7, ups=0.54, wpb=1036.4, bsz=32, num_updates=33270, lr=1.14796e-05, gnorm=14.49, clip=100, loss_scale=32, train_wall=19, gb_free=10.7, wall=62538
2023-05-26 16:45:42 - progress_bar.py[line:272] - INFO: epoch 020:    430 / 1732 loss=2.142, loss_v1=0, loss_v2=0, nll_loss=0.916, ntokens=1013.2, nsentences=32, sample_size=1013.2, sample_size_v1=0, sample_size_v2=0, ppl=1.89, wps=544.1, ups=0.54, wpb=1013.2, bsz=32, num_updates=33280, lr=1.14735e-05, gnorm=14.311, clip=100, loss_scale=32, train_wall=19, gb_free=11.1, wall=62556
2023-05-26 16:46:00 - progress_bar.py[line:272] - INFO: epoch 020:    440 / 1732 loss=2.173, loss_v1=0, loss_v2=0, nll_loss=0.949, ntokens=989.2, nsentences=32, sample_size=989.2, sample_size_v1=0, sample_size_v2=0, ppl=1.93, wps=532.1, ups=0.54, wpb=989.2, bsz=32, num_updates=33290, lr=1.14674e-05, gnorm=14.116, clip=100, loss_scale=32, train_wall=19, gb_free=11.7, wall=62575
2023-05-26 16:46:19 - progress_bar.py[line:272] - INFO: epoch 020:    450 / 1732 loss=2.171, loss_v1=0, loss_v2=0, nll_loss=0.947, ntokens=915.3, nsentences=32, sample_size=915.3, sample_size_v1=0, sample_size_v2=0, ppl=1.93, wps=493.4, ups=0.54, wpb=915.3, bsz=32, num_updates=33300, lr=1.14612e-05, gnorm=14.634, clip=100, loss_scale=32, train_wall=19, gb_free=11.8, wall=62593
2023-05-26 16:46:37 - progress_bar.py[line:272] - INFO: epoch 020:    460 / 1732 loss=2.193, loss_v1=0, loss_v2=0, nll_loss=0.973, ntokens=1040.5, nsentences=32, sample_size=1040.5, sample_size_v1=0, sample_size_v2=0, ppl=1.96, wps=559.2, ups=0.54, wpb=1040.5, bsz=32, num_updates=33310, lr=1.14551e-05, gnorm=14.179, clip=100, loss_scale=32, train_wall=19, gb_free=11.3, wall=62612
2023-05-26 16:46:56 - progress_bar.py[line:272] - INFO: epoch 020:    470 / 1732 loss=2.196, loss_v1=0, loss_v2=0, nll_loss=0.974, ntokens=1036.3, nsentences=32, sample_size=1036.3, sample_size_v1=0, sample_size_v2=0, ppl=1.96, wps=552.7, ups=0.53, wpb=1036.3, bsz=32, num_updates=33320, lr=1.14489e-05, gnorm=13.966, clip=100, loss_scale=32, train_wall=19, gb_free=11.8, wall=62631
2023-05-26 16:47:15 - progress_bar.py[line:272] - INFO: epoch 020:    480 / 1732 loss=2.202, loss_v1=0, loss_v2=0, nll_loss=0.981, ntokens=1040.5, nsentences=32, sample_size=1040.5, sample_size_v1=0, sample_size_v2=0, ppl=1.97, wps=558.7, ups=0.54, wpb=1040.5, bsz=32, num_updates=33330, lr=1.14428e-05, gnorm=14.386, clip=100, loss_scale=32, train_wall=19, gb_free=9.9, wall=62649
2023-05-26 16:47:33 - progress_bar.py[line:272] - INFO: epoch 020:    490 / 1732 loss=2.169, loss_v1=0, loss_v2=0, nll_loss=0.943, ntokens=919.9, nsentences=32, sample_size=919.9, sample_size_v1=0, sample_size_v2=0, ppl=1.92, wps=496.9, ups=0.54, wpb=919.9, bsz=32, num_updates=33340, lr=1.14366e-05, gnorm=14.738, clip=100, loss_scale=32, train_wall=18, gb_free=10.5, wall=62668
2023-05-26 16:47:52 - progress_bar.py[line:272] - INFO: epoch 020:    500 / 1732 loss=2.165, loss_v1=0, loss_v2=0, nll_loss=0.94, ntokens=950.8, nsentences=32, sample_size=950.8, sample_size_v1=0, sample_size_v2=0, ppl=1.92, wps=514.9, ups=0.54, wpb=950.8, bsz=32, num_updates=33350, lr=1.14305e-05, gnorm=15.738, clip=100, loss_scale=32, train_wall=18, gb_free=11.5, wall=62686
2023-05-26 16:48:10 - progress_bar.py[line:272] - INFO: epoch 020:    510 / 1732 loss=2.215, loss_v1=0, loss_v2=0, nll_loss=0.996, ntokens=1039.6, nsentences=32, sample_size=1039.6, sample_size_v1=0, sample_size_v2=0, ppl=1.99, wps=560.3, ups=0.54, wpb=1039.6, bsz=32, num_updates=33360, lr=1.14244e-05, gnorm=15.184, clip=100, loss_scale=32, train_wall=19, gb_free=10.9, wall=62705
2023-05-26 16:48:29 - progress_bar.py[line:272] - INFO: epoch 020:    520 / 1732 loss=2.149, loss_v1=0, loss_v2=0, nll_loss=0.923, ntokens=1010.1, nsentences=32, sample_size=1010.1, sample_size_v1=0, sample_size_v2=0, ppl=1.9, wps=546.5, ups=0.54, wpb=1010.1, bsz=32, num_updates=33370, lr=1.14182e-05, gnorm=13.648, clip=100, loss_scale=32, train_wall=18, gb_free=11.7, wall=62723
2023-05-26 16:48:34 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2023-05-26 16:48:49 - progress_bar.py[line:272] - INFO: epoch 020:    531 / 1732 loss=2.173, loss_v1=0, loss_v2=0, nll_loss=0.951, ntokens=933, nsentences=32, sample_size=933, sample_size_v1=0, sample_size_v2=0, ppl=1.93, wps=460.9, ups=0.49, wpb=933, bsz=32, num_updates=33380, lr=1.14121e-05, gnorm=14.691, clip=100, loss_scale=32, train_wall=20, gb_free=11.6, wall=62744
2023-05-26 16:49:07 - progress_bar.py[line:272] - INFO: epoch 020:    541 / 1732 loss=2.171, loss_v1=0, loss_v2=0, nll_loss=0.947, ntokens=994.8, nsentences=32, sample_size=994.8, sample_size_v1=0, sample_size_v2=0, ppl=1.93, wps=538.3, ups=0.54, wpb=994.8, bsz=32, num_updates=33390, lr=1.14059e-05, gnorm=15.569, clip=100, loss_scale=32, train_wall=18, gb_free=12, wall=62762
2023-05-26 16:49:26 - progress_bar.py[line:272] - INFO: epoch 020:    551 / 1732 loss=2.19, loss_v1=0, loss_v2=0, nll_loss=0.969, ntokens=1021.9, nsentences=32, sample_size=1021.9, sample_size_v1=0, sample_size_v2=0, ppl=1.96, wps=548.9, ups=0.54, wpb=1021.9, bsz=32, num_updates=33400, lr=1.13998e-05, gnorm=15.518, clip=100, loss_scale=32, train_wall=19, gb_free=11.3, wall=62781
2023-05-26 16:49:45 - progress_bar.py[line:272] - INFO: epoch 020:    561 / 1732 loss=2.2, loss_v1=0, loss_v2=0, nll_loss=0.98, ntokens=1030.9, nsentences=32, sample_size=1030.9, sample_size_v1=0, sample_size_v2=0, ppl=1.97, wps=554.2, ups=0.54, wpb=1030.9, bsz=32, num_updates=33410, lr=1.13936e-05, gnorm=14.224, clip=100, loss_scale=32, train_wall=19, gb_free=11.3, wall=62799
2023-05-26 16:50:03 - progress_bar.py[line:272] - INFO: epoch 020:    571 / 1732 loss=2.208, loss_v1=0, loss_v2=0, nll_loss=0.988, ntokens=990.9, nsentences=32, sample_size=990.9, sample_size_v1=0, sample_size_v2=0, ppl=1.98, wps=532.1, ups=0.54, wpb=990.9, bsz=32, num_updates=33420, lr=1.13875e-05, gnorm=14.65, clip=100, loss_scale=32, train_wall=19, gb_free=11.8, wall=62818
2023-05-26 16:50:22 - progress_bar.py[line:272] - INFO: epoch 020:    581 / 1732 loss=2.176, loss_v1=0, loss_v2=0, nll_loss=0.953, ntokens=1021.6, nsentences=32, sample_size=1021.6, sample_size_v1=0, sample_size_v2=0, ppl=1.94, wps=544.4, ups=0.53, wpb=1021.6, bsz=32, num_updates=33430, lr=1.13814e-05, gnorm=13.901, clip=100, loss_scale=32, train_wall=19, gb_free=10.7, wall=62837
2023-05-26 16:50:41 - progress_bar.py[line:272] - INFO: epoch 020:    591 / 1732 loss=2.163, loss_v1=0, loss_v2=0, nll_loss=0.939, ntokens=934.4, nsentences=32, sample_size=934.4, sample_size_v1=0, sample_size_v2=0, ppl=1.92, wps=501.6, ups=0.54, wpb=934.4, bsz=32, num_updates=33440, lr=1.13752e-05, gnorm=16.221, clip=100, loss_scale=32, train_wall=19, gb_free=10.7, wall=62855
2023-05-26 16:50:59 - progress_bar.py[line:272] - INFO: epoch 020:    601 / 1732 loss=2.139, loss_v1=0, loss_v2=0, nll_loss=0.912, ntokens=941.2, nsentences=32, sample_size=941.2, sample_size_v1=0, sample_size_v2=0, ppl=1.88, wps=507.1, ups=0.54, wpb=941.2, bsz=32, num_updates=33450, lr=1.13691e-05, gnorm=14.461, clip=100, loss_scale=32, train_wall=19, gb_free=11.6, wall=62874
2023-05-26 16:51:18 - progress_bar.py[line:272] - INFO: epoch 020:    611 / 1732 loss=2.169, loss_v1=0, loss_v2=0, nll_loss=0.946, ntokens=911.9, nsentences=32, sample_size=911.9, sample_size_v1=0, sample_size_v2=0, ppl=1.93, wps=494, ups=0.54, wpb=911.9, bsz=32, num_updates=33460, lr=1.13629e-05, gnorm=16.059, clip=100, loss_scale=32, train_wall=18, gb_free=11.7, wall=62892
2023-05-26 16:51:36 - progress_bar.py[line:272] - INFO: epoch 020:    621 / 1732 loss=2.19, loss_v1=0, loss_v2=0, nll_loss=0.97, ntokens=845.9, nsentences=32, sample_size=845.9, sample_size_v1=0, sample_size_v2=0, ppl=1.96, wps=460.7, ups=0.54, wpb=845.9, bsz=32, num_updates=33470, lr=1.13568e-05, gnorm=17.346, clip=100, loss_scale=32, train_wall=18, gb_free=12, wall=62911
2023-05-26 16:51:55 - progress_bar.py[line:272] - INFO: epoch 020:    631 / 1732 loss=2.157, loss_v1=0, loss_v2=0, nll_loss=0.932, ntokens=949.2, nsentences=32, sample_size=949.2, sample_size_v1=0, sample_size_v2=0, ppl=1.91, wps=513.5, ups=0.54, wpb=949.2, bsz=32, num_updates=33480, lr=1.13507e-05, gnorm=14.526, clip=100, loss_scale=32, train_wall=18, gb_free=11.2, wall=62929
2023-05-26 16:52:13 - progress_bar.py[line:272] - INFO: epoch 020:    641 / 1732 loss=2.192, loss_v1=0, loss_v2=0, nll_loss=0.97, ntokens=915.8, nsentences=32, sample_size=915.8, sample_size_v1=0, sample_size_v2=0, ppl=1.96, wps=491.3, ups=0.54, wpb=915.8, bsz=32, num_updates=33490, lr=1.13445e-05, gnorm=15.657, clip=100, loss_scale=32, train_wall=19, gb_free=11.8, wall=62948
2023-05-26 16:52:32 - progress_bar.py[line:272] - INFO: epoch 020:    651 / 1732 loss=2.165, loss_v1=0, loss_v2=0, nll_loss=0.941, ntokens=990.2, nsentences=32, sample_size=990.2, sample_size_v1=0, sample_size_v2=0, ppl=1.92, wps=537.7, ups=0.54, wpb=990.2, bsz=32, num_updates=33500, lr=1.13384e-05, gnorm=13.742, clip=100, loss_scale=32, train_wall=18, gb_free=11.7, wall=62966
2023-05-26 16:52:50 - progress_bar.py[line:272] - INFO: epoch 020:    661 / 1732 loss=2.171, loss_v1=0, loss_v2=0, nll_loss=0.947, ntokens=863.9, nsentences=32, sample_size=863.9, sample_size_v1=0, sample_size_v2=0, ppl=1.93, wps=473, ups=0.55, wpb=863.9, bsz=32, num_updates=33510, lr=1.13322e-05, gnorm=15.544, clip=100, loss_scale=32, train_wall=18, gb_free=11.5, wall=62985
2023-05-26 16:53:08 - progress_bar.py[line:272] - INFO: epoch 020:    671 / 1732 loss=2.184, loss_v1=0, loss_v2=0, nll_loss=0.962, ntokens=943.7, nsentences=32, sample_size=943.7, sample_size_v1=0, sample_size_v2=0, ppl=1.95, wps=509.4, ups=0.54, wpb=943.7, bsz=32, num_updates=33520, lr=1.13261e-05, gnorm=15.576, clip=100, loss_scale=32, train_wall=18, gb_free=11.4, wall=63003
2023-05-26 16:53:27 - progress_bar.py[line:272] - INFO: epoch 020:    681 / 1732 loss=2.182, loss_v1=0, loss_v2=0, nll_loss=0.961, ntokens=972.8, nsentences=32, sample_size=972.8, sample_size_v1=0, sample_size_v2=0, ppl=1.95, wps=526, ups=0.54, wpb=972.8, bsz=32, num_updates=33530, lr=1.13199e-05, gnorm=14.991, clip=100, loss_scale=32, train_wall=18, gb_free=11, wall=63022
2023-05-26 16:53:46 - progress_bar.py[line:272] - INFO: epoch 020:    691 / 1732 loss=2.185, loss_v1=0, loss_v2=0, nll_loss=0.962, ntokens=949, nsentences=32, sample_size=949, sample_size_v1=0, sample_size_v2=0, ppl=1.95, wps=510.5, ups=0.54, wpb=949, bsz=32, num_updates=33540, lr=1.13138e-05, gnorm=15.909, clip=100, loss_scale=32, train_wall=19, gb_free=11.8, wall=63040
2023-05-26 16:54:04 - progress_bar.py[line:272] - INFO: epoch 020:    701 / 1732 loss=2.15, loss_v1=0, loss_v2=0, nll_loss=0.922, ntokens=988.7, nsentences=32, sample_size=988.7, sample_size_v1=0, sample_size_v2=0, ppl=1.9, wps=532.7, ups=0.54, wpb=988.7, bsz=32, num_updates=33550, lr=1.13077e-05, gnorm=14.76, clip=100, loss_scale=32, train_wall=19, gb_free=11.8, wall=63059
2023-05-26 16:54:23 - progress_bar.py[line:272] - INFO: epoch 020:    711 / 1732 loss=2.178, loss_v1=0, loss_v2=0, nll_loss=0.956, ntokens=913.9, nsentences=32, sample_size=913.9, sample_size_v1=0, sample_size_v2=0, ppl=1.94, wps=495, ups=0.54, wpb=913.9, bsz=32, num_updates=33560, lr=1.13015e-05, gnorm=15.252, clip=100, loss_scale=32, train_wall=18, gb_free=11.6, wall=63077
2023-05-26 16:54:41 - progress_bar.py[line:272] - INFO: epoch 020:    721 / 1732 loss=2.142, loss_v1=0, loss_v2=0, nll_loss=0.914, ntokens=854.5, nsentences=32, sample_size=854.5, sample_size_v1=0, sample_size_v2=0, ppl=1.88, wps=465.3, ups=0.54, wpb=854.5, bsz=32, num_updates=33570, lr=1.12954e-05, gnorm=15.826, clip=100, loss_scale=32, train_wall=18, gb_free=11.4, wall=63096
2023-05-26 16:54:59 - progress_bar.py[line:272] - INFO: epoch 020:    731 / 1732 loss=2.161, loss_v1=0, loss_v2=0, nll_loss=0.936, ntokens=932.8, nsentences=32, sample_size=932.8, sample_size_v1=0, sample_size_v2=0, ppl=1.91, wps=505.1, ups=0.54, wpb=932.8, bsz=32, num_updates=33580, lr=1.12892e-05, gnorm=14.607, clip=100, loss_scale=32, train_wall=18, gb_free=11.6, wall=63114
2023-05-26 16:55:18 - progress_bar.py[line:272] - INFO: epoch 020:    741 / 1732 loss=2.159, loss_v1=0, loss_v2=0, nll_loss=0.934, ntokens=1003.7, nsentences=32, sample_size=1003.7, sample_size_v1=0, sample_size_v2=0, ppl=1.91, wps=541.3, ups=0.54, wpb=1003.7, bsz=32, num_updates=33590, lr=1.12831e-05, gnorm=13.774, clip=100, loss_scale=32, train_wall=19, gb_free=11.4, wall=63133
2023-05-26 16:55:37 - progress_bar.py[line:272] - INFO: epoch 020:    751 / 1732 loss=2.156, loss_v1=0, loss_v2=0, nll_loss=0.931, ntokens=975.7, nsentences=32, sample_size=975.7, sample_size_v1=0, sample_size_v2=0, ppl=1.91, wps=523.5, ups=0.54, wpb=975.7, bsz=32, num_updates=33600, lr=1.12769e-05, gnorm=14.893, clip=100, loss_scale=32, train_wall=19, gb_free=11, wall=63151
2023-05-26 16:55:55 - progress_bar.py[line:272] - INFO: epoch 020:    761 / 1732 loss=2.143, loss_v1=0, loss_v2=0, nll_loss=0.916, ntokens=974.2, nsentences=32, sample_size=974.2, sample_size_v1=0, sample_size_v2=0, ppl=1.89, wps=526.8, ups=0.54, wpb=974.2, bsz=32, num_updates=33610, lr=1.12708e-05, gnorm=14.707, clip=100, loss_scale=32, train_wall=18, gb_free=11.5, wall=63170
2023-05-26 16:56:13 - progress_bar.py[line:272] - INFO: epoch 020:    771 / 1732 loss=2.164, loss_v1=0, loss_v2=0, nll_loss=0.94, ntokens=924.9, nsentences=32, sample_size=924.9, sample_size_v1=0, sample_size_v2=0, ppl=1.92, wps=502.4, ups=0.54, wpb=924.9, bsz=32, num_updates=33620, lr=1.12647e-05, gnorm=15.517, clip=100, loss_scale=32, train_wall=18, gb_free=11.7, wall=63188
2023-05-26 16:56:32 - progress_bar.py[line:272] - INFO: epoch 020:    781 / 1732 loss=2.161, loss_v1=0, loss_v2=0, nll_loss=0.936, ntokens=1053.4, nsentences=32, sample_size=1053.4, sample_size_v1=0, sample_size_v2=0, ppl=1.91, wps=566.9, ups=0.54, wpb=1053.4, bsz=32, num_updates=33630, lr=1.12585e-05, gnorm=13.767, clip=100, loss_scale=32, train_wall=19, gb_free=11.7, wall=63207
2023-05-26 16:56:51 - progress_bar.py[line:272] - INFO: epoch 020:    791 / 1732 loss=2.182, loss_v1=0, loss_v2=0, nll_loss=0.959, ntokens=1022, nsentences=32, sample_size=1022, sample_size_v1=0, sample_size_v2=0, ppl=1.94, wps=552.4, ups=0.54, wpb=1022, bsz=32, num_updates=33640, lr=1.12524e-05, gnorm=14.969, clip=100, loss_scale=32, train_wall=18, gb_free=11.4, wall=63225
2023-05-26 16:57:09 - progress_bar.py[line:272] - INFO: epoch 020:    801 / 1732 loss=2.174, loss_v1=0, loss_v2=0, nll_loss=0.949, ntokens=984.3, nsentences=32, sample_size=984.3, sample_size_v1=0, sample_size_v2=0, ppl=1.93, wps=532.4, ups=0.54, wpb=984.3, bsz=32, num_updates=33650, lr=1.12462e-05, gnorm=14.901, clip=100, loss_scale=32, train_wall=18, gb_free=11.1, wall=63244
2023-05-26 16:57:28 - progress_bar.py[line:272] - INFO: epoch 020:    811 / 1732 loss=2.164, loss_v1=0, loss_v2=0, nll_loss=0.939, ntokens=931.4, nsentences=32, sample_size=931.4, sample_size_v1=0, sample_size_v2=0, ppl=1.92, wps=502.4, ups=0.54, wpb=931.4, bsz=32, num_updates=33660, lr=1.12401e-05, gnorm=16.637, clip=100, loss_scale=32, train_wall=19, gb_free=11.4, wall=63262
2023-05-26 16:57:46 - progress_bar.py[line:272] - INFO: epoch 020:    821 / 1732 loss=2.178, loss_v1=0, loss_v2=0, nll_loss=0.957, ntokens=915.1, nsentences=32, sample_size=915.1, sample_size_v1=0, sample_size_v2=0, ppl=1.94, wps=493.8, ups=0.54, wpb=915.1, bsz=32, num_updates=33670, lr=1.1234e-05, gnorm=15.432, clip=100, loss_scale=32, train_wall=18, gb_free=10.2, wall=63281
2023-05-26 16:58:05 - progress_bar.py[line:272] - INFO: epoch 020:    831 / 1732 loss=2.158, loss_v1=0, loss_v2=0, nll_loss=0.933, ntokens=914.9, nsentences=32, sample_size=914.9, sample_size_v1=0, sample_size_v2=0, ppl=1.91, wps=495.7, ups=0.54, wpb=914.9, bsz=32, num_updates=33680, lr=1.12278e-05, gnorm=16.066, clip=100, loss_scale=32, train_wall=18, gb_free=11.6, wall=63299
2023-05-26 16:58:23 - progress_bar.py[line:272] - INFO: epoch 020:    841 / 1732 loss=2.167, loss_v1=0, loss_v2=0, nll_loss=0.943, ntokens=933, nsentences=32, sample_size=933, sample_size_v1=0, sample_size_v2=0, ppl=1.92, wps=507.5, ups=0.54, wpb=933, bsz=32, num_updates=33690, lr=1.12217e-05, gnorm=16.569, clip=100, loss_scale=32, train_wall=18, gb_free=11.7, wall=63318
2023-05-26 16:58:41 - progress_bar.py[line:272] - INFO: epoch 020:    851 / 1732 loss=2.171, loss_v1=0, loss_v2=0, nll_loss=0.946, ntokens=1005.2, nsentences=32, sample_size=1005.2, sample_size_v1=0, sample_size_v2=0, ppl=1.93, wps=543.4, ups=0.54, wpb=1005.2, bsz=32, num_updates=33700, lr=1.12155e-05, gnorm=15.533, clip=100, loss_scale=32, train_wall=18, gb_free=11.4, wall=63336
2023-05-26 16:59:00 - progress_bar.py[line:272] - INFO: epoch 020:    861 / 1732 loss=2.147, loss_v1=0, loss_v2=0, nll_loss=0.922, ntokens=942.6, nsentences=32, sample_size=942.6, sample_size_v1=0, sample_size_v2=0, ppl=1.89, wps=509.4, ups=0.54, wpb=942.6, bsz=32, num_updates=33710, lr=1.12094e-05, gnorm=15.109, clip=100, loss_scale=32, train_wall=18, gb_free=11.3, wall=63355
2023-05-26 16:59:18 - progress_bar.py[line:272] - INFO: epoch 020:    871 / 1732 loss=2.165, loss_v1=0, loss_v2=0, nll_loss=0.943, ntokens=962.7, nsentences=32, sample_size=962.7, sample_size_v1=0, sample_size_v2=0, ppl=1.92, wps=522, ups=0.54, wpb=962.7, bsz=32, num_updates=33720, lr=1.12032e-05, gnorm=15.558, clip=100, loss_scale=32, train_wall=18, gb_free=11.8, wall=63373
2023-05-26 16:59:37 - progress_bar.py[line:272] - INFO: epoch 020:    881 / 1732 loss=2.124, loss_v1=0, loss_v2=0, nll_loss=0.896, ntokens=988.4, nsentences=32, sample_size=988.4, sample_size_v1=0, sample_size_v2=0, ppl=1.86, wps=531.4, ups=0.54, wpb=988.4, bsz=32, num_updates=33730, lr=1.11971e-05, gnorm=14.465, clip=100, loss_scale=32, train_wall=19, gb_free=12.1, wall=63392
2023-05-26 16:59:56 - progress_bar.py[line:272] - INFO: epoch 020:    891 / 1732 loss=2.108, loss_v1=0, loss_v2=0, nll_loss=0.878, ntokens=1001.4, nsentences=32, sample_size=1001.4, sample_size_v1=0, sample_size_v2=0, ppl=1.84, wps=539, ups=0.54, wpb=1001.4, bsz=32, num_updates=33740, lr=1.1191e-05, gnorm=13.429, clip=100, loss_scale=32, train_wall=19, gb_free=11.4, wall=63410
2023-05-26 17:00:14 - progress_bar.py[line:272] - INFO: epoch 020:    901 / 1732 loss=2.105, loss_v1=0, loss_v2=0, nll_loss=0.873, ntokens=1032.4, nsentences=32, sample_size=1032.4, sample_size_v1=0, sample_size_v2=0, ppl=1.83, wps=555.5, ups=0.54, wpb=1032.4, bsz=32, num_updates=33750, lr=1.11848e-05, gnorm=14.921, clip=100, loss_scale=32, train_wall=19, gb_free=11.7, wall=63429
2023-05-26 17:00:33 - progress_bar.py[line:272] - INFO: epoch 020:    911 / 1732 loss=2.153, loss_v1=0, loss_v2=0, nll_loss=0.927, ntokens=960.1, nsentences=32, sample_size=960.1, sample_size_v1=0, sample_size_v2=0, ppl=1.9, wps=518.6, ups=0.54, wpb=960.1, bsz=32, num_updates=33760, lr=1.11787e-05, gnorm=15.781, clip=100, loss_scale=32, train_wall=18, gb_free=12, wall=63447
2023-05-26 17:00:51 - progress_bar.py[line:272] - INFO: epoch 020:    921 / 1732 loss=2.166, loss_v1=0, loss_v2=0, nll_loss=0.942, ntokens=986.3, nsentences=32, sample_size=986.3, sample_size_v1=0, sample_size_v2=0, ppl=1.92, wps=530, ups=0.54, wpb=986.3, bsz=32, num_updates=33770, lr=1.11725e-05, gnorm=15.791, clip=100, loss_scale=32, train_wall=19, gb_free=11.4, wall=63466
2023-05-26 17:01:10 - progress_bar.py[line:272] - INFO: epoch 020:    931 / 1732 loss=2.147, loss_v1=0, loss_v2=0, nll_loss=0.92, ntokens=1050.4, nsentences=32, sample_size=1050.4, sample_size_v1=0, sample_size_v2=0, ppl=1.89, wps=559.8, ups=0.53, wpb=1050.4, bsz=32, num_updates=33780, lr=1.11664e-05, gnorm=15.772, clip=100, loss_scale=32, train_wall=19, gb_free=11.5, wall=63485
2023-05-26 17:01:29 - progress_bar.py[line:272] - INFO: epoch 020:    941 / 1732 loss=2.147, loss_v1=0, loss_v2=0, nll_loss=0.92, ntokens=1052.3, nsentences=32, sample_size=1052.3, sample_size_v1=0, sample_size_v2=0, ppl=1.89, wps=558.6, ups=0.53, wpb=1052.3, bsz=32, num_updates=33790, lr=1.11602e-05, gnorm=15.546, clip=100, loss_scale=32, train_wall=19, gb_free=10.1, wall=63504
2023-05-26 17:01:48 - progress_bar.py[line:272] - INFO: epoch 020:    951 / 1732 loss=2.173, loss_v1=0, loss_v2=0, nll_loss=0.95, ntokens=1037.8, nsentences=32, sample_size=1037.8, sample_size_v1=0, sample_size_v2=0, ppl=1.93, wps=552.8, ups=0.53, wpb=1037.8, bsz=32, num_updates=33800, lr=1.11541e-05, gnorm=16.085, clip=100, loss_scale=32, train_wall=19, gb_free=11.1, wall=63522
2023-05-26 17:02:07 - progress_bar.py[line:272] - INFO: epoch 020:    961 / 1732 loss=2.154, loss_v1=0, loss_v2=0, nll_loss=0.929, ntokens=1067.9, nsentences=32, sample_size=1067.9, sample_size_v1=0, sample_size_v2=0, ppl=1.9, wps=568.5, ups=0.53, wpb=1067.9, bsz=32, num_updates=33810, lr=1.1148e-05, gnorm=14.009, clip=100, loss_scale=32, train_wall=19, gb_free=11.3, wall=63541
2023-05-26 17:02:25 - progress_bar.py[line:272] - INFO: epoch 020:    971 / 1732 loss=2.178, loss_v1=0, loss_v2=0, nll_loss=0.956, ntokens=1026.9, nsentences=32, sample_size=1026.9, sample_size_v1=0, sample_size_v2=0, ppl=1.94, wps=547.4, ups=0.53, wpb=1026.9, bsz=32, num_updates=33820, lr=1.11418e-05, gnorm=17.61, clip=100, loss_scale=32, train_wall=19, gb_free=10.3, wall=63560
2023-05-26 17:02:44 - progress_bar.py[line:272] - INFO: epoch 020:    981 / 1732 loss=2.145, loss_v1=0, loss_v2=0, nll_loss=0.918, ntokens=1016.8, nsentences=32, sample_size=1016.8, sample_size_v1=0, sample_size_v2=0, ppl=1.89, wps=538.7, ups=0.53, wpb=1016.8, bsz=32, num_updates=33830, lr=1.11357e-05, gnorm=14.983, clip=100, loss_scale=32, train_wall=19, gb_free=11.1, wall=63579
2023-05-26 17:03:03 - progress_bar.py[line:272] - INFO: epoch 020:    991 / 1732 loss=2.168, loss_v1=0, loss_v2=0, nll_loss=0.944, ntokens=1042.2, nsentences=32, sample_size=1042.2, sample_size_v1=0, sample_size_v2=0, ppl=1.92, wps=553.4, ups=0.53, wpb=1042.2, bsz=32, num_updates=33840, lr=1.11295e-05, gnorm=15.479, clip=100, loss_scale=32, train_wall=19, gb_free=11.4, wall=63598
2023-05-26 17:03:22 - progress_bar.py[line:272] - INFO: epoch 020:   1001 / 1732 loss=2.15, loss_v1=0, loss_v2=0, nll_loss=0.922, ntokens=1019, nsentences=32, sample_size=1019, sample_size_v1=0, sample_size_v2=0, ppl=1.9, wps=546.4, ups=0.54, wpb=1019, bsz=32, num_updates=33850, lr=1.11234e-05, gnorm=15.868, clip=100, loss_scale=32, train_wall=19, gb_free=11.3, wall=63616
2023-05-26 17:03:40 - progress_bar.py[line:272] - INFO: epoch 020:   1011 / 1732 loss=2.161, loss_v1=0, loss_v2=0, nll_loss=0.935, ntokens=995.8, nsentences=32, sample_size=995.8, sample_size_v1=0, sample_size_v2=0, ppl=1.91, wps=532.5, ups=0.53, wpb=995.8, bsz=32, num_updates=33860, lr=1.11173e-05, gnorm=15.781, clip=100, loss_scale=32, train_wall=19, gb_free=11.5, wall=63635
2023-05-26 17:03:59 - progress_bar.py[line:272] - INFO: epoch 020:   1021 / 1732 loss=2.14, loss_v1=0, loss_v2=0, nll_loss=0.913, ntokens=1050, nsentences=32, sample_size=1050, sample_size_v1=0, sample_size_v2=0, ppl=1.88, wps=558.4, ups=0.53, wpb=1050, bsz=32, num_updates=33870, lr=1.11111e-05, gnorm=15.789, clip=100, loss_scale=32, train_wall=19, gb_free=10.5, wall=63654
2023-05-26 17:04:18 - progress_bar.py[line:272] - INFO: epoch 020:   1031 / 1732 loss=2.162, loss_v1=0, loss_v2=0, nll_loss=0.935, ntokens=1125.6, nsentences=32, sample_size=1125.6, sample_size_v1=0, sample_size_v2=0, ppl=1.91, wps=593.1, ups=0.53, wpb=1125.6, bsz=32, num_updates=33880, lr=1.1105e-05, gnorm=14.579, clip=100, loss_scale=32, train_wall=19, gb_free=11.1, wall=63673
2023-05-26 17:04:29 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2023-05-26 17:04:39 - progress_bar.py[line:272] - INFO: epoch 020:   1042 / 1732 loss=2.145, loss_v1=0, loss_v2=0, nll_loss=0.916, ntokens=1065.3, nsentences=32, sample_size=1065.3, sample_size_v1=0, sample_size_v2=0, ppl=1.89, wps=515.3, ups=0.48, wpb=1065.3, bsz=32, num_updates=33890, lr=1.10988e-05, gnorm=15.063, clip=100, loss_scale=32, train_wall=21, gb_free=10.8, wall=63693
2023-05-26 17:04:58 - progress_bar.py[line:272] - INFO: epoch 020:   1052 / 1732 loss=2.168, loss_v1=0, loss_v2=0, nll_loss=0.945, ntokens=1041, nsentences=32, sample_size=1041, sample_size_v1=0, sample_size_v2=0, ppl=1.93, wps=557.3, ups=0.54, wpb=1041, bsz=32, num_updates=33900, lr=1.10927e-05, gnorm=16.75, clip=100, loss_scale=32, train_wall=19, gb_free=11.2, wall=63712
2023-05-26 17:05:16 - progress_bar.py[line:272] - INFO: epoch 020:   1062 / 1732 loss=2.142, loss_v1=0, loss_v2=0, nll_loss=0.914, ntokens=1046.1, nsentences=32, sample_size=1046.1, sample_size_v1=0, sample_size_v2=0, ppl=1.88, wps=556.4, ups=0.53, wpb=1046.1, bsz=32, num_updates=33910, lr=1.10865e-05, gnorm=15.33, clip=100, loss_scale=32, train_wall=19, gb_free=11.1, wall=63731
2023-05-26 17:05:35 - progress_bar.py[line:272] - INFO: epoch 020:   1072 / 1732 loss=2.152, loss_v1=0, loss_v2=0, nll_loss=0.927, ntokens=994.4, nsentences=32, sample_size=994.4, sample_size_v1=0, sample_size_v2=0, ppl=1.9, wps=529.9, ups=0.53, wpb=994.4, bsz=32, num_updates=33920, lr=1.10804e-05, gnorm=15.291, clip=100, loss_scale=32, train_wall=19, gb_free=11.5, wall=63750
2023-05-26 17:05:54 - progress_bar.py[line:272] - INFO: epoch 020:   1082 / 1732 loss=2.171, loss_v1=0, loss_v2=0, nll_loss=0.947, ntokens=1041.7, nsentences=32, sample_size=1041.7, sample_size_v1=0, sample_size_v2=0, ppl=1.93, wps=550.7, ups=0.53, wpb=1041.7, bsz=32, num_updates=33930, lr=1.10743e-05, gnorm=16.442, clip=100, loss_scale=32, train_wall=19, gb_free=11.2, wall=63769
2023-05-26 17:06:13 - progress_bar.py[line:272] - INFO: epoch 020:   1092 / 1732 loss=2.156, loss_v1=0, loss_v2=0, nll_loss=0.93, ntokens=1060.8, nsentences=32, sample_size=1060.8, sample_size_v1=0, sample_size_v2=0, ppl=1.91, wps=561.6, ups=0.53, wpb=1060.8, bsz=32, num_updates=33940, lr=1.10681e-05, gnorm=15.927, clip=100, loss_scale=32, train_wall=19, gb_free=11.6, wall=63788
2023-05-26 17:06:32 - progress_bar.py[line:272] - INFO: epoch 020:   1102 / 1732 loss=2.158, loss_v1=0, loss_v2=0, nll_loss=0.932, ntokens=1049.1, nsentences=32, sample_size=1049.1, sample_size_v1=0, sample_size_v2=0, ppl=1.91, wps=558.3, ups=0.53, wpb=1049.1, bsz=32, num_updates=33950, lr=1.1062e-05, gnorm=15.858, clip=100, loss_scale=32, train_wall=19, gb_free=10.5, wall=63806
2023-05-26 17:06:51 - progress_bar.py[line:272] - INFO: epoch 020:   1112 / 1732 loss=2.148, loss_v1=0, loss_v2=0, nll_loss=0.921, ntokens=1025.7, nsentences=32, sample_size=1025.7, sample_size_v1=0, sample_size_v2=0, ppl=1.89, wps=545.2, ups=0.53, wpb=1025.7, bsz=32, num_updates=33960, lr=1.10558e-05, gnorm=16.181, clip=100, loss_scale=32, train_wall=19, gb_free=11.3, wall=63825
2023-05-26 17:07:09 - progress_bar.py[line:272] - INFO: epoch 020:   1122 / 1732 loss=2.142, loss_v1=0, loss_v2=0, nll_loss=0.913, ntokens=976.1, nsentences=32, sample_size=976.1, sample_size_v1=0, sample_size_v2=0, ppl=1.88, wps=520.3, ups=0.53, wpb=976.1, bsz=32, num_updates=33970, lr=1.10497e-05, gnorm=15.742, clip=100, loss_scale=32, train_wall=19, gb_free=11.3, wall=63844
2023-05-26 17:07:28 - progress_bar.py[line:272] - INFO: epoch 020:   1132 / 1732 loss=2.15, loss_v1=0, loss_v2=0, nll_loss=0.923, ntokens=969.4, nsentences=32, sample_size=969.4, sample_size_v1=0, sample_size_v2=0, ppl=1.9, wps=515.5, ups=0.53, wpb=969.4, bsz=32, num_updates=33980, lr=1.10435e-05, gnorm=16.454, clip=100, loss_scale=32, train_wall=19, gb_free=11.7, wall=63863
2023-05-26 17:07:47 - progress_bar.py[line:272] - INFO: epoch 020:   1142 / 1732 loss=2.148, loss_v1=0, loss_v2=0, nll_loss=0.921, ntokens=1032.5, nsentences=32, sample_size=1032.5, sample_size_v1=0, sample_size_v2=0, ppl=1.89, wps=549.9, ups=0.53, wpb=1032.5, bsz=32, num_updates=33990, lr=1.10374e-05, gnorm=15.497, clip=100, loss_scale=32, train_wall=19, gb_free=11.1, wall=63882
2023-05-26 17:08:06 - progress_bar.py[line:272] - INFO: epoch 020:   1152 / 1732 loss=2.127, loss_v1=0, loss_v2=0, nll_loss=0.899, ntokens=1026.9, nsentences=32, sample_size=1026.9, sample_size_v1=0, sample_size_v2=0, ppl=1.86, wps=547.9, ups=0.53, wpb=1026.9, bsz=32, num_updates=34000, lr=1.10313e-05, gnorm=14.484, clip=100, loss_scale=32, train_wall=19, gb_free=11.4, wall=63900
2023-05-26 17:08:24 - progress_bar.py[line:272] - INFO: epoch 020:   1162 / 1732 loss=2.128, loss_v1=0, loss_v2=0, nll_loss=0.901, ntokens=1008.4, nsentences=32, sample_size=1008.4, sample_size_v1=0, sample_size_v2=0, ppl=1.87, wps=535.3, ups=0.53, wpb=1008.4, bsz=32, num_updates=34010, lr=1.10251e-05, gnorm=16.354, clip=100, loss_scale=32, train_wall=19, gb_free=11.3, wall=63919
2023-05-26 17:08:43 - progress_bar.py[line:272] - INFO: epoch 020:   1172 / 1732 loss=2.146, loss_v1=0, loss_v2=0, nll_loss=0.92, ntokens=1048.6, nsentences=32, sample_size=1048.6, sample_size_v1=0, sample_size_v2=0, ppl=1.89, wps=557.6, ups=0.53, wpb=1048.6, bsz=32, num_updates=34020, lr=1.1019e-05, gnorm=15.644, clip=100, loss_scale=32, train_wall=19, gb_free=10.8, wall=63938
2023-05-26 17:09:02 - progress_bar.py[line:272] - INFO: epoch 020:   1182 / 1732 loss=2.116, loss_v1=0, loss_v2=0, nll_loss=0.885, ntokens=1018.1, nsentences=32, sample_size=1018.1, sample_size_v1=0, sample_size_v2=0, ppl=1.85, wps=544.6, ups=0.53, wpb=1018.1, bsz=32, num_updates=34030, lr=1.10128e-05, gnorm=15.646, clip=100, loss_scale=32, train_wall=19, gb_free=11.4, wall=63957
2023-05-26 17:09:21 - progress_bar.py[line:272] - INFO: epoch 020:   1192 / 1732 loss=2.158, loss_v1=0, loss_v2=0, nll_loss=0.934, ntokens=1011.4, nsentences=32, sample_size=1011.4, sample_size_v1=0, sample_size_v2=0, ppl=1.91, wps=540.2, ups=0.53, wpb=1011.4, bsz=32, num_updates=34040, lr=1.10067e-05, gnorm=14.672, clip=100, loss_scale=32, train_wall=19, gb_free=11.4, wall=63975
2023-05-26 17:09:40 - progress_bar.py[line:272] - INFO: epoch 020:   1202 / 1732 loss=2.121, loss_v1=0, loss_v2=0, nll_loss=0.891, ntokens=1128.3, nsentences=32, sample_size=1128.3, sample_size_v1=0, sample_size_v2=0, ppl=1.85, wps=597.4, ups=0.53, wpb=1128.3, bsz=32, num_updates=34050, lr=1.10006e-05, gnorm=14.602, clip=100, loss_scale=32, train_wall=19, gb_free=11.1, wall=63994
2023-05-26 17:09:58 - progress_bar.py[line:272] - INFO: epoch 020:   1212 / 1732 loss=2.137, loss_v1=0, loss_v2=0, nll_loss=0.909, ntokens=1031.6, nsentences=32, sample_size=1031.6, sample_size_v1=0, sample_size_v2=0, ppl=1.88, wps=547, ups=0.53, wpb=1031.6, bsz=32, num_updates=34060, lr=1.09944e-05, gnorm=14.366, clip=100, loss_scale=32, train_wall=19, gb_free=10.9, wall=64013
2023-05-26 17:10:17 - progress_bar.py[line:272] - INFO: epoch 020:   1222 / 1732 loss=2.175, loss_v1=0, loss_v2=0, nll_loss=0.953, ntokens=1024, nsentences=32, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=1.94, wps=546.7, ups=0.53, wpb=1024, bsz=32, num_updates=34070, lr=1.09883e-05, gnorm=16.289, clip=100, loss_scale=32, train_wall=19, gb_free=10.8, wall=64032
2023-05-26 17:10:36 - progress_bar.py[line:272] - INFO: epoch 020:   1232 / 1732 loss=2.126, loss_v1=0, loss_v2=0, nll_loss=0.897, ntokens=1035.1, nsentences=32, sample_size=1035.1, sample_size_v1=0, sample_size_v2=0, ppl=1.86, wps=550.8, ups=0.53, wpb=1035.1, bsz=32, num_updates=34080, lr=1.09821e-05, gnorm=15.006, clip=100, loss_scale=32, train_wall=19, gb_free=11.4, wall=64051
2023-05-26 17:10:55 - progress_bar.py[line:272] - INFO: epoch 020:   1242 / 1732 loss=2.101, loss_v1=0, loss_v2=0, nll_loss=0.869, ntokens=1078.3, nsentences=32, sample_size=1078.3, sample_size_v1=0, sample_size_v2=0, ppl=1.83, wps=570.8, ups=0.53, wpb=1078.3, bsz=32, num_updates=34090, lr=1.0976e-05, gnorm=15.163, clip=100, loss_scale=32, train_wall=19, gb_free=11.4, wall=64070
2023-05-26 17:11:14 - progress_bar.py[line:272] - INFO: epoch 020:   1252 / 1732 loss=2.113, loss_v1=0, loss_v2=0, nll_loss=0.883, ntokens=1106.3, nsentences=32, sample_size=1106.3, sample_size_v1=0, sample_size_v2=0, ppl=1.84, wps=583.9, ups=0.53, wpb=1106.3, bsz=32, num_updates=34100, lr=1.09698e-05, gnorm=15.65, clip=100, loss_scale=32, train_wall=19, gb_free=10.9, wall=64088
2023-05-26 17:11:33 - progress_bar.py[line:272] - INFO: epoch 020:   1262 / 1732 loss=2.141, loss_v1=0, loss_v2=0, nll_loss=0.916, ntokens=1064, nsentences=32, sample_size=1064, sample_size_v1=0, sample_size_v2=0, ppl=1.89, wps=564.7, ups=0.53, wpb=1064, bsz=32, num_updates=34110, lr=1.09637e-05, gnorm=15.16, clip=100, loss_scale=32, train_wall=19, gb_free=10.9, wall=64107
2023-05-26 17:11:51 - progress_bar.py[line:272] - INFO: epoch 020:   1272 / 1732 loss=2.145, loss_v1=0, loss_v2=0, nll_loss=0.92, ntokens=1010.3, nsentences=32, sample_size=1010.3, sample_size_v1=0, sample_size_v2=0, ppl=1.89, wps=539.5, ups=0.53, wpb=1010.3, bsz=32, num_updates=34120, lr=1.09576e-05, gnorm=14.331, clip=100, loss_scale=32, train_wall=19, gb_free=10.9, wall=64126
2023-05-26 17:12:10 - progress_bar.py[line:272] - INFO: epoch 020:   1282 / 1732 loss=2.126, loss_v1=0, loss_v2=0, nll_loss=0.897, ntokens=1073.6, nsentences=32, sample_size=1073.6, sample_size_v1=0, sample_size_v2=0, ppl=1.86, wps=564.2, ups=0.53, wpb=1073.6, bsz=32, num_updates=34130, lr=1.09514e-05, gnorm=14.11, clip=100, loss_scale=32, train_wall=19, gb_free=10.4, wall=64145
2023-05-26 17:12:29 - progress_bar.py[line:272] - INFO: epoch 020:   1292 / 1732 loss=2.125, loss_v1=0, loss_v2=0, nll_loss=0.893, ntokens=1095.2, nsentences=32, sample_size=1095.2, sample_size_v1=0, sample_size_v2=0, ppl=1.86, wps=579.9, ups=0.53, wpb=1095.2, bsz=32, num_updates=34140, lr=1.09453e-05, gnorm=13.53, clip=100, loss_scale=32, train_wall=19, gb_free=10.7, wall=64164
2023-05-26 17:12:48 - progress_bar.py[line:272] - INFO: epoch 020:   1302 / 1732 loss=2.141, loss_v1=0, loss_v2=0, nll_loss=0.914, ntokens=1099.5, nsentences=32, sample_size=1099.5, sample_size_v1=0, sample_size_v2=0, ppl=1.88, wps=583.2, ups=0.53, wpb=1099.5, bsz=32, num_updates=34150, lr=1.09391e-05, gnorm=13.728, clip=100, loss_scale=32, train_wall=19, gb_free=10.4, wall=64183
2023-05-26 17:13:07 - progress_bar.py[line:272] - INFO: epoch 020:   1312 / 1732 loss=2.173, loss_v1=0, loss_v2=0, nll_loss=0.949, ntokens=1055.4, nsentences=32, sample_size=1055.4, sample_size_v1=0, sample_size_v2=0, ppl=1.93, wps=554.2, ups=0.53, wpb=1055.4, bsz=32, num_updates=34160, lr=1.0933e-05, gnorm=15.948, clip=100, loss_scale=32, train_wall=19, gb_free=11.4, wall=64202
2023-05-26 17:13:26 - progress_bar.py[line:272] - INFO: epoch 020:   1322 / 1732 loss=2.13, loss_v1=0, loss_v2=0, nll_loss=0.901, ntokens=1120.6, nsentences=32, sample_size=1120.6, sample_size_v1=0, sample_size_v2=0, ppl=1.87, wps=591.1, ups=0.53, wpb=1120.6, bsz=32, num_updates=34170, lr=1.09268e-05, gnorm=14.062, clip=100, loss_scale=32, train_wall=19, gb_free=10.6, wall=64221
2023-05-26 17:13:45 - progress_bar.py[line:272] - INFO: epoch 020:   1332 / 1732 loss=2.102, loss_v1=0, loss_v2=0, nll_loss=0.871, ntokens=1081, nsentences=32, sample_size=1081, sample_size_v1=0, sample_size_v2=0, ppl=1.83, wps=572.7, ups=0.53, wpb=1081, bsz=32, num_updates=34180, lr=1.09207e-05, gnorm=13.285, clip=100, loss_scale=32, train_wall=19, gb_free=11.1, wall=64240
2023-05-26 17:14:04 - progress_bar.py[line:272] - INFO: epoch 020:   1342 / 1732 loss=2.135, loss_v1=0, loss_v2=0, nll_loss=0.908, ntokens=1183.5, nsentences=32, sample_size=1183.5, sample_size_v1=0, sample_size_v2=0, ppl=1.88, wps=622.8, ups=0.53, wpb=1183.5, bsz=32, num_updates=34190, lr=1.09146e-05, gnorm=14.826, clip=100, loss_scale=32, train_wall=19, gb_free=10.4, wall=64259
2023-05-26 17:14:23 - progress_bar.py[line:272] - INFO: epoch 020:   1352 / 1732 loss=2.132, loss_v1=0, loss_v2=0, nll_loss=0.903, ntokens=1129.4, nsentences=32, sample_size=1129.4, sample_size_v1=0, sample_size_v2=0, ppl=1.87, wps=595.4, ups=0.53, wpb=1129.4, bsz=32, num_updates=34200, lr=1.09084e-05, gnorm=13.34, clip=100, loss_scale=32, train_wall=19, gb_free=11, wall=64278
2023-05-26 17:14:42 - progress_bar.py[line:272] - INFO: epoch 020:   1362 / 1732 loss=2.111, loss_v1=0, loss_v2=0, nll_loss=0.88, ntokens=1092.5, nsentences=32, sample_size=1092.5, sample_size_v1=0, sample_size_v2=0, ppl=1.84, wps=576.4, ups=0.53, wpb=1092.5, bsz=32, num_updates=34210, lr=1.09023e-05, gnorm=14.756, clip=100, loss_scale=32, train_wall=19, gb_free=10.3, wall=64297
2023-05-26 17:15:01 - progress_bar.py[line:272] - INFO: epoch 020:   1372 / 1732 loss=2.146, loss_v1=0, loss_v2=0, nll_loss=0.919, ntokens=1098.3, nsentences=32, sample_size=1098.3, sample_size_v1=0, sample_size_v2=0, ppl=1.89, wps=584.5, ups=0.53, wpb=1098.3, bsz=32, num_updates=34220, lr=1.08961e-05, gnorm=15.938, clip=100, loss_scale=32, train_wall=19, gb_free=11.6, wall=64315
2023-05-26 17:15:20 - progress_bar.py[line:272] - INFO: epoch 020:   1382 / 1732 loss=2.159, loss_v1=0, loss_v2=0, nll_loss=0.932, ntokens=1160, nsentences=32, sample_size=1160, sample_size_v1=0, sample_size_v2=0, ppl=1.91, wps=614.6, ups=0.53, wpb=1160, bsz=32, num_updates=34230, lr=1.089e-05, gnorm=14.995, clip=100, loss_scale=32, train_wall=19, gb_free=10.9, wall=64334
2023-05-26 17:15:38 - progress_bar.py[line:272] - INFO: epoch 020:   1392 / 1732 loss=2.148, loss_v1=0, loss_v2=0, nll_loss=0.92, ntokens=1049.4, nsentences=32, sample_size=1049.4, sample_size_v1=0, sample_size_v2=0, ppl=1.89, wps=562.2, ups=0.54, wpb=1049.4, bsz=32, num_updates=34240, lr=1.08839e-05, gnorm=14.138, clip=100, loss_scale=32, train_wall=19, gb_free=11.2, wall=64353
2023-05-26 17:15:57 - progress_bar.py[line:272] - INFO: epoch 020:   1402 / 1732 loss=2.127, loss_v1=0, loss_v2=0, nll_loss=0.899, ntokens=1133.7, nsentences=32, sample_size=1133.7, sample_size_v1=0, sample_size_v2=0, ppl=1.86, wps=599.1, ups=0.53, wpb=1133.7, bsz=32, num_updates=34250, lr=1.08777e-05, gnorm=14.412, clip=100, loss_scale=32, train_wall=19, gb_free=10.2, wall=64372
2023-05-26 17:16:16 - progress_bar.py[line:272] - INFO: epoch 020:   1412 / 1732 loss=2.172, loss_v1=0, loss_v2=0, nll_loss=0.949, ntokens=1246.7, nsentences=32, sample_size=1246.7, sample_size_v1=0, sample_size_v2=0, ppl=1.93, wps=658.4, ups=0.53, wpb=1246.7, bsz=32, num_updates=34260, lr=1.08716e-05, gnorm=14.646, clip=100, loss_scale=32, train_wall=19, gb_free=10.8, wall=64391
2023-05-26 17:16:35 - progress_bar.py[line:272] - INFO: epoch 020:   1422 / 1732 loss=2.159, loss_v1=0, loss_v2=0, nll_loss=0.934, ntokens=1259.2, nsentences=32, sample_size=1259.2, sample_size_v1=0, sample_size_v2=0, ppl=1.91, wps=656.5, ups=0.52, wpb=1259.2, bsz=32, num_updates=34270, lr=1.08654e-05, gnorm=13.268, clip=100, loss_scale=32, train_wall=19, gb_free=10.7, wall=64410
2023-05-26 17:16:54 - progress_bar.py[line:272] - INFO: epoch 020:   1432 / 1732 loss=2.134, loss_v1=0, loss_v2=0, nll_loss=0.905, ntokens=1215.6, nsentences=32, sample_size=1215.6, sample_size_v1=0, sample_size_v2=0, ppl=1.87, wps=641, ups=0.53, wpb=1215.6, bsz=32, num_updates=34280, lr=1.08593e-05, gnorm=13.61, clip=100, loss_scale=32, train_wall=19, gb_free=11.2, wall=64429
2023-05-26 17:17:13 - progress_bar.py[line:272] - INFO: epoch 020:   1442 / 1732 loss=2.139, loss_v1=0, loss_v2=0, nll_loss=0.912, ntokens=1136.6, nsentences=32, sample_size=1136.6, sample_size_v1=0, sample_size_v2=0, ppl=1.88, wps=602.1, ups=0.53, wpb=1136.6, bsz=32, num_updates=34290, lr=1.08531e-05, gnorm=14.279, clip=100, loss_scale=32, train_wall=19, gb_free=11.2, wall=64448
2023-05-26 17:17:32 - progress_bar.py[line:272] - INFO: epoch 020:   1452 / 1732 loss=2.148, loss_v1=0, loss_v2=0, nll_loss=0.922, ntokens=1140.1, nsentences=32, sample_size=1140.1, sample_size_v1=0, sample_size_v2=0, ppl=1.89, wps=605, ups=0.53, wpb=1140.1, bsz=32, num_updates=34300, lr=1.0847e-05, gnorm=14.66, clip=100, loss_scale=32, train_wall=19, gb_free=11.7, wall=64467
2023-05-26 17:17:51 - progress_bar.py[line:272] - INFO: epoch 020:   1462 / 1732 loss=2.124, loss_v1=0, loss_v2=0, nll_loss=0.894, ntokens=1170.3, nsentences=32, sample_size=1170.3, sample_size_v1=0, sample_size_v2=0, ppl=1.86, wps=616.6, ups=0.53, wpb=1170.3, bsz=32, num_updates=34310, lr=1.08409e-05, gnorm=13.784, clip=100, loss_scale=32, train_wall=19, gb_free=10.6, wall=64486
2023-05-26 17:18:10 - progress_bar.py[line:272] - INFO: epoch 020:   1472 / 1732 loss=2.128, loss_v1=0, loss_v2=0, nll_loss=0.9, ntokens=1139, nsentences=32, sample_size=1139, sample_size_v1=0, sample_size_v2=0, ppl=1.87, wps=601.2, ups=0.53, wpb=1139, bsz=32, num_updates=34320, lr=1.08347e-05, gnorm=15.637, clip=100, loss_scale=32, train_wall=19, gb_free=11.7, wall=64505
2023-05-26 17:18:29 - progress_bar.py[line:272] - INFO: epoch 020:   1482 / 1732 loss=2.162, loss_v1=0, loss_v2=0, nll_loss=0.938, ntokens=1051.3, nsentences=32, sample_size=1051.3, sample_size_v1=0, sample_size_v2=0, ppl=1.92, wps=558.9, ups=0.53, wpb=1051.3, bsz=32, num_updates=34330, lr=1.08286e-05, gnorm=15.912, clip=100, loss_scale=32, train_wall=19, gb_free=10.6, wall=64523
2023-05-26 17:18:48 - progress_bar.py[line:272] - INFO: epoch 020:   1492 / 1732 loss=2.142, loss_v1=0, loss_v2=0, nll_loss=0.913, ntokens=1143, nsentences=32, sample_size=1143, sample_size_v1=0, sample_size_v2=0, ppl=1.88, wps=604.3, ups=0.53, wpb=1143, bsz=32, num_updates=34340, lr=1.08224e-05, gnorm=14.533, clip=100, loss_scale=32, train_wall=19, gb_free=11.5, wall=64542
2023-05-26 17:19:07 - progress_bar.py[line:272] - INFO: epoch 020:   1502 / 1732 loss=2.111, loss_v1=0, loss_v2=0, nll_loss=0.879, ntokens=1131.9, nsentences=32, sample_size=1131.9, sample_size_v1=0, sample_size_v2=0, ppl=1.84, wps=597.2, ups=0.53, wpb=1131.9, bsz=32, num_updates=34350, lr=1.08163e-05, gnorm=14.707, clip=100, loss_scale=32, train_wall=19, gb_free=10.3, wall=64561
2023-05-26 17:19:25 - progress_bar.py[line:272] - INFO: epoch 020:   1512 / 1732 loss=2.144, loss_v1=0, loss_v2=0, nll_loss=0.917, ntokens=1058.6, nsentences=32, sample_size=1058.6, sample_size_v1=0, sample_size_v2=0, ppl=1.89, wps=565.3, ups=0.53, wpb=1058.6, bsz=32, num_updates=34360, lr=1.08101e-05, gnorm=16.95, clip=100, loss_scale=32, train_wall=19, gb_free=10.8, wall=64580
2023-05-26 17:19:44 - progress_bar.py[line:272] - INFO: epoch 020:   1522 / 1732 loss=2.167, loss_v1=0, loss_v2=0, nll_loss=0.943, ntokens=1011, nsentences=32, sample_size=1011, sample_size_v1=0, sample_size_v2=0, ppl=1.92, wps=540.3, ups=0.53, wpb=1011, bsz=32, num_updates=34370, lr=1.0804e-05, gnorm=16.947, clip=100, loss_scale=32, train_wall=19, gb_free=11.8, wall=64599
2023-05-26 17:20:03 - progress_bar.py[line:272] - INFO: epoch 020:   1532 / 1732 loss=2.168, loss_v1=0, loss_v2=0, nll_loss=0.945, ntokens=1075.4, nsentences=32, sample_size=1075.4, sample_size_v1=0, sample_size_v2=0, ppl=1.92, wps=566.7, ups=0.53, wpb=1075.4, bsz=32, num_updates=34380, lr=1.07979e-05, gnorm=16.631, clip=100, loss_scale=32, train_wall=19, gb_free=10.7, wall=64618
2023-05-26 17:20:22 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2023-05-26 17:20:24 - progress_bar.py[line:272] - INFO: epoch 020:   1543 / 1732 loss=2.126, loss_v1=0, loss_v2=0, nll_loss=0.896, ntokens=1124.6, nsentences=32, sample_size=1124.6, sample_size_v1=0, sample_size_v2=0, ppl=1.86, wps=541.3, ups=0.48, wpb=1124.6, bsz=32, num_updates=34390, lr=1.07917e-05, gnorm=15.314, clip=100, loss_scale=16, train_wall=21, gb_free=10.9, wall=64639
2023-05-26 17:20:43 - progress_bar.py[line:272] - INFO: epoch 020:   1553 / 1732 loss=2.113, loss_v1=0, loss_v2=0, nll_loss=0.883, ntokens=1034.9, nsentences=32, sample_size=1034.9, sample_size_v1=0, sample_size_v2=0, ppl=1.84, wps=551.3, ups=0.53, wpb=1034.9, bsz=32, num_updates=34400, lr=1.07856e-05, gnorm=16.839, clip=100, loss_scale=16, train_wall=19, gb_free=11.3, wall=64657
2023-05-26 17:21:02 - progress_bar.py[line:272] - INFO: epoch 020:   1563 / 1732 loss=2.126, loss_v1=0, loss_v2=0, nll_loss=0.898, ntokens=1130.9, nsentences=32, sample_size=1130.9, sample_size_v1=0, sample_size_v2=0, ppl=1.86, wps=598.2, ups=0.53, wpb=1130.9, bsz=32, num_updates=34410, lr=1.07794e-05, gnorm=14.034, clip=100, loss_scale=16, train_wall=19, gb_free=11.7, wall=64676
2023-05-26 17:21:21 - progress_bar.py[line:272] - INFO: epoch 020:   1573 / 1732 loss=2.161, loss_v1=0, loss_v2=0, nll_loss=0.937, ntokens=1064.8, nsentences=32, sample_size=1064.8, sample_size_v1=0, sample_size_v2=0, ppl=1.92, wps=562.4, ups=0.53, wpb=1064.8, bsz=32, num_updates=34420, lr=1.07733e-05, gnorm=17.293, clip=100, loss_scale=16, train_wall=19, gb_free=10.8, wall=64695
2023-05-26 17:21:39 - progress_bar.py[line:272] - INFO: epoch 020:   1583 / 1732 loss=2.156, loss_v1=0, loss_v2=0, nll_loss=0.931, ntokens=1007.5, nsentences=32, sample_size=1007.5, sample_size_v1=0, sample_size_v2=0, ppl=1.91, wps=536.1, ups=0.53, wpb=1007.5, bsz=32, num_updates=34430, lr=1.07672e-05, gnorm=17.098, clip=100, loss_scale=16, train_wall=19, gb_free=11.3, wall=64714
2023-05-26 17:21:58 - progress_bar.py[line:272] - INFO: epoch 020:   1593 / 1732 loss=2.114, loss_v1=0, loss_v2=0, nll_loss=0.883, ntokens=1081.3, nsentences=32, sample_size=1081.3, sample_size_v1=0, sample_size_v2=0, ppl=1.84, wps=573.4, ups=0.53, wpb=1081.3, bsz=32, num_updates=34440, lr=1.0761e-05, gnorm=14.748, clip=100, loss_scale=16, train_wall=19, gb_free=11.6, wall=64733
2023-05-26 17:22:17 - progress_bar.py[line:272] - INFO: epoch 020:   1603 / 1732 loss=2.112, loss_v1=0, loss_v2=0, nll_loss=0.881, ntokens=1092.4, nsentences=32, sample_size=1092.4, sample_size_v1=0, sample_size_v2=0, ppl=1.84, wps=580, ups=0.53, wpb=1092.4, bsz=32, num_updates=34450, lr=1.07549e-05, gnorm=15.633, clip=100, loss_scale=16, train_wall=19, gb_free=11.7, wall=64752
2023-05-26 17:22:36 - progress_bar.py[line:272] - INFO: epoch 020:   1613 / 1732 loss=2.108, loss_v1=0, loss_v2=0, nll_loss=0.877, ntokens=1153.1, nsentences=32, sample_size=1153.1, sample_size_v1=0, sample_size_v2=0, ppl=1.84, wps=606.1, ups=0.53, wpb=1153.1, bsz=32, num_updates=34460, lr=1.07487e-05, gnorm=15.139, clip=100, loss_scale=16, train_wall=19, gb_free=10.7, wall=64771
2023-05-26 17:22:55 - progress_bar.py[line:272] - INFO: epoch 020:   1623 / 1732 loss=2.127, loss_v1=0, loss_v2=0, nll_loss=0.899, ntokens=1098.4, nsentences=32, sample_size=1098.4, sample_size_v1=0, sample_size_v2=0, ppl=1.87, wps=581, ups=0.53, wpb=1098.4, bsz=32, num_updates=34470, lr=1.07426e-05, gnorm=15.085, clip=100, loss_scale=16, train_wall=19, gb_free=10.9, wall=64790
2023-05-26 17:23:14 - progress_bar.py[line:272] - INFO: epoch 020:   1633 / 1732 loss=2.123, loss_v1=0, loss_v2=0, nll_loss=0.894, ntokens=1178.3, nsentences=32, sample_size=1178.3, sample_size_v1=0, sample_size_v2=0, ppl=1.86, wps=623.1, ups=0.53, wpb=1178.3, bsz=32, num_updates=34480, lr=1.07364e-05, gnorm=15.115, clip=100, loss_scale=16, train_wall=19, gb_free=11.5, wall=64809
2023-05-26 17:23:33 - progress_bar.py[line:272] - INFO: epoch 020:   1643 / 1732 loss=2.124, loss_v1=0, loss_v2=0, nll_loss=0.893, ntokens=1238.2, nsentences=32, sample_size=1238.2, sample_size_v1=0, sample_size_v2=0, ppl=1.86, wps=652.4, ups=0.53, wpb=1238.2, bsz=32, num_updates=34490, lr=1.07303e-05, gnorm=15.073, clip=100, loss_scale=16, train_wall=19, gb_free=11.3, wall=64828
2023-05-26 17:23:52 - progress_bar.py[line:272] - INFO: epoch 020:   1653 / 1732 loss=2.145, loss_v1=0, loss_v2=0, nll_loss=0.917, ntokens=993.8, nsentences=32, sample_size=993.8, sample_size_v1=0, sample_size_v2=0, ppl=1.89, wps=530.3, ups=0.53, wpb=993.8, bsz=32, num_updates=34500, lr=1.07242e-05, gnorm=17.257, clip=100, loss_scale=16, train_wall=19, gb_free=11.6, wall=64846
2023-05-26 17:24:11 - progress_bar.py[line:272] - INFO: epoch 020:   1663 / 1732 loss=2.153, loss_v1=0, loss_v2=0, nll_loss=0.927, ntokens=1051.4, nsentences=32, sample_size=1051.4, sample_size_v1=0, sample_size_v2=0, ppl=1.9, wps=556.6, ups=0.53, wpb=1051.4, bsz=32, num_updates=34510, lr=1.0718e-05, gnorm=17.203, clip=100, loss_scale=16, train_wall=19, gb_free=11.1, wall=64865
2023-05-26 17:24:29 - progress_bar.py[line:272] - INFO: epoch 020:   1673 / 1732 loss=2.109, loss_v1=0, loss_v2=0, nll_loss=0.878, ntokens=1033, nsentences=32, sample_size=1033, sample_size_v1=0, sample_size_v2=0, ppl=1.84, wps=551.6, ups=0.53, wpb=1033, bsz=32, num_updates=34520, lr=1.07119e-05, gnorm=15.813, clip=100, loss_scale=16, train_wall=19, gb_free=10.8, wall=64884
2023-05-26 17:24:48 - progress_bar.py[line:272] - INFO: epoch 020:   1683 / 1732 loss=2.103, loss_v1=0, loss_v2=0, nll_loss=0.871, ntokens=1168.8, nsentences=32, sample_size=1168.8, sample_size_v1=0, sample_size_v2=0, ppl=1.83, wps=614, ups=0.53, wpb=1168.8, bsz=32, num_updates=34530, lr=1.07057e-05, gnorm=13.525, clip=100, loss_scale=16, train_wall=19, gb_free=11.2, wall=64903
2023-05-26 17:25:07 - progress_bar.py[line:272] - INFO: epoch 020:   1693 / 1732 loss=2.117, loss_v1=0, loss_v2=0, nll_loss=0.887, ntokens=1251.1, nsentences=32, sample_size=1251.1, sample_size_v1=0, sample_size_v2=0, ppl=1.85, wps=651.1, ups=0.52, wpb=1251.1, bsz=32, num_updates=34540, lr=1.06996e-05, gnorm=14.17, clip=100, loss_scale=16, train_wall=19, gb_free=11.1, wall=64922
2023-05-26 17:25:27 - progress_bar.py[line:272] - INFO: epoch 020:   1703 / 1732 loss=2.146, loss_v1=0, loss_v2=0, nll_loss=0.919, ntokens=1247.1, nsentences=32, sample_size=1247.1, sample_size_v1=0, sample_size_v2=0, ppl=1.89, wps=650.5, ups=0.52, wpb=1247.1, bsz=32, num_updates=34550, lr=1.06934e-05, gnorm=13.618, clip=100, loss_scale=16, train_wall=19, gb_free=11.2, wall=64941
2023-05-26 17:25:46 - progress_bar.py[line:272] - INFO: epoch 020:   1713 / 1732 loss=2.131, loss_v1=0, loss_v2=0, nll_loss=0.902, ntokens=1176.1, nsentences=32, sample_size=1176.1, sample_size_v1=0, sample_size_v2=0, ppl=1.87, wps=620, ups=0.53, wpb=1176.1, bsz=32, num_updates=34560, lr=1.06873e-05, gnorm=13.83, clip=100, loss_scale=16, train_wall=19, gb_free=9.2, wall=64960
2023-05-26 17:26:05 - progress_bar.py[line:272] - INFO: epoch 020:   1723 / 1732 loss=2.119, loss_v1=0, loss_v2=0, nll_loss=0.89, ntokens=1147.2, nsentences=32, sample_size=1147.2, sample_size_v1=0, sample_size_v2=0, ppl=1.85, wps=600.5, ups=0.52, wpb=1147.2, bsz=32, num_updates=34570, lr=1.06812e-05, gnorm=14.003, clip=100, loss_scale=16, train_wall=19, gb_free=10.3, wall=64979
2023-05-26 17:26:20 - checkpoint_utils.py[line:64] - INFO: Preparing to save checkpoint for epoch 20 @ 34579 updates
2023-05-26 17:26:20 - trainer.py[line:431] - INFO: Saving checkpoint to ../../checkpoints/OFA/sgcls_checkpoints/_30_3e-5_512_base_nosrcbbox/checkpoint20.pt
2023-05-26 17:26:23 - trainer.py[line:441] - INFO: Finished saving checkpoint to ../../checkpoints/OFA/sgcls_checkpoints/_30_3e-5_512_base_nosrcbbox/checkpoint20.pt
2023-05-26 17:26:26 - checkpoint_utils.py[line:133] - INFO: Saved checkpoint ../../checkpoints/OFA/sgcls_checkpoints/_30_3e-5_512_base_nosrcbbox/checkpoint20.pt (epoch 20 @ 34579 updates, score None) (writing took 5.387405207846314 seconds)
2023-05-26 17:26:26 - train.py[line:332] - INFO: end of epoch 20 (average epoch stats below)
2023-05-26 17:26:26 - progress_bar.py[line:282] - INFO: epoch 020 | loss 2.141 | loss_v1 0 | loss_v2 0 | nll_loss 0.914 | ntokens 1051.6 | nsentences 31.986 | sample_size 1051.6 | sample_size_v1 0 | sample_size_v2 0 | ppl 1.88 | wps 557.9 | ups 0.53 | wpb 1051.6 | bsz 32 | num_updates 34579 | lr 1.06756e-05 | gnorm 14.77 | clip 100 | loss_scale 16 | train_wall 3244 | gb_free 11.7 | wall 65000
2023-05-26 17:26:26 - trainer.py[line:639] - INFO: loading train data for epoch 21
local datafile ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 0 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 0 finished initializing row_count and line_idx-to-offset mapping
file ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 0 row count 55400 total row count 55400
slice_id 0 seek offset 0
2023-05-26 17:26:28 - trainer.py[line:703] - INFO: begin training epoch 21
2023-05-26 17:26:28 - train.py[line:305] - INFO: Start iterating over samples
2023-05-26 17:26:30 - progress_bar.py[line:272] - INFO: epoch 021:      1 / 1732 loss=2.181, loss_v1=0, loss_v2=0, nll_loss=0.959, ntokens=1067.2, nsentences=29.6, sample_size=1067.2, sample_size_v1=0, sample_size_v2=0, ppl=1.94, wps=427.2, ups=0.4, wpb=1067.2, bsz=29.6, num_updates=34580, lr=1.0675e-05, gnorm=15.198, clip=100, loss_scale=16, train_wall=18, gb_free=11.4, wall=65004
2023-05-26 17:26:49 - progress_bar.py[line:272] - INFO: epoch 021:     11 / 1732 loss=2.112, loss_v1=0, loss_v2=0, nll_loss=0.881, ntokens=1109.8, nsentences=32, sample_size=1109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.84, wps=579.4, ups=0.52, wpb=1109.8, bsz=32, num_updates=34590, lr=1.06689e-05, gnorm=19.186, clip=100, loss_scale=16, train_wall=19, gb_free=11.4, wall=65024
2023-05-26 17:27:08 - progress_bar.py[line:272] - INFO: epoch 021:     21 / 1732 loss=2.063, loss_v1=0, loss_v2=0, nll_loss=0.825, ntokens=1106.8, nsentences=32, sample_size=1106.8, sample_size_v1=0, sample_size_v2=0, ppl=1.77, wps=587.3, ups=0.53, wpb=1106.8, bsz=32, num_updates=34600, lr=1.06627e-05, gnorm=17.736, clip=100, loss_scale=16, train_wall=19, gb_free=11.2, wall=65042
2023-05-26 17:27:27 - progress_bar.py[line:272] - INFO: epoch 021:     31 / 1732 loss=2.068, loss_v1=0, loss_v2=0, nll_loss=0.831, ntokens=958.4, nsentences=32, sample_size=958.4, sample_size_v1=0, sample_size_v2=0, ppl=1.78, wps=508.9, ups=0.53, wpb=958.4, bsz=32, num_updates=34610, lr=1.06566e-05, gnorm=18.31, clip=100, loss_scale=16, train_wall=19, gb_free=11.1, wall=65061
2023-05-26 17:27:46 - progress_bar.py[line:272] - INFO: epoch 021:     41 / 1732 loss=1.974, loss_v1=0, loss_v2=0, nll_loss=0.727, ntokens=1207.2, nsentences=32, sample_size=1207.2, sample_size_v1=0, sample_size_v2=0, ppl=1.65, wps=629.9, ups=0.52, wpb=1207.2, bsz=32, num_updates=34620, lr=1.06505e-05, gnorm=14.98, clip=100, loss_scale=16, train_wall=19, gb_free=10.9, wall=65080
2023-05-26 17:28:05 - progress_bar.py[line:272] - INFO: epoch 021:     51 / 1732 loss=2.029, loss_v1=0, loss_v2=0, nll_loss=0.791, ntokens=1028.6, nsentences=32, sample_size=1028.6, sample_size_v1=0, sample_size_v2=0, ppl=1.73, wps=545.4, ups=0.53, wpb=1028.6, bsz=32, num_updates=34630, lr=1.06443e-05, gnorm=17.527, clip=100, loss_scale=16, train_wall=19, gb_free=11.2, wall=65099
2023-05-26 17:28:23 - progress_bar.py[line:272] - INFO: epoch 021:     61 / 1732 loss=1.869, loss_v1=0, loss_v2=0, nll_loss=0.613, ntokens=1123.9, nsentences=32, sample_size=1123.9, sample_size_v1=0, sample_size_v2=0, ppl=1.53, wps=596.3, ups=0.53, wpb=1123.9, bsz=32, num_updates=34640, lr=1.06382e-05, gnorm=14.225, clip=100, loss_scale=16, train_wall=19, gb_free=10.1, wall=65118
2023-05-26 17:28:43 - progress_bar.py[line:272] - INFO: epoch 021:     71 / 1732 loss=1.921, loss_v1=0, loss_v2=0, nll_loss=0.669, ntokens=1363.4, nsentences=32, sample_size=1363.4, sample_size_v1=0, sample_size_v2=0, ppl=1.59, wps=699, ups=0.51, wpb=1363.4, bsz=32, num_updates=34650, lr=1.0632e-05, gnorm=11.242, clip=100, loss_scale=16, train_wall=19, gb_free=10.1, wall=65138
2023-05-26 17:29:02 - progress_bar.py[line:272] - INFO: epoch 021:     81 / 1732 loss=1.949, loss_v1=0, loss_v2=0, nll_loss=0.699, ntokens=1263, nsentences=32, sample_size=1263, sample_size_v1=0, sample_size_v2=0, ppl=1.62, wps=651.5, ups=0.52, wpb=1263, bsz=32, num_updates=34660, lr=1.06259e-05, gnorm=12.222, clip=100, loss_scale=16, train_wall=19, gb_free=11.3, wall=65157
2023-05-26 17:29:21 - progress_bar.py[line:272] - INFO: epoch 021:     91 / 1732 loss=2.002, loss_v1=0, loss_v2=0, nll_loss=0.758, ntokens=1062.5, nsentences=32, sample_size=1062.5, sample_size_v1=0, sample_size_v2=0, ppl=1.69, wps=557.3, ups=0.52, wpb=1062.5, bsz=32, num_updates=34670, lr=1.06197e-05, gnorm=14.576, clip=100, loss_scale=16, train_wall=19, gb_free=11.4, wall=65176
2023-05-26 17:29:40 - progress_bar.py[line:272] - INFO: epoch 021:    101 / 1732 loss=2.005, loss_v1=0, loss_v2=0, nll_loss=0.762, ntokens=1023.5, nsentences=32, sample_size=1023.5, sample_size_v1=0, sample_size_v2=0, ppl=1.7, wps=545.5, ups=0.53, wpb=1023.5, bsz=32, num_updates=34680, lr=1.06136e-05, gnorm=14.958, clip=100, loss_scale=16, train_wall=19, gb_free=11, wall=65195
2023-05-26 17:29:59 - progress_bar.py[line:272] - INFO: epoch 021:    111 / 1732 loss=2.139, loss_v1=0, loss_v2=0, nll_loss=0.914, ntokens=1034.7, nsentences=32, sample_size=1034.7, sample_size_v1=0, sample_size_v2=0, ppl=1.88, wps=549.2, ups=0.53, wpb=1034.7, bsz=32, num_updates=34690, lr=1.06075e-05, gnorm=17.804, clip=100, loss_scale=16, train_wall=19, gb_free=11.2, wall=65214
2023-05-26 17:30:18 - progress_bar.py[line:272] - INFO: epoch 021:    121 / 1732 loss=2.127, loss_v1=0, loss_v2=0, nll_loss=0.899, ntokens=1114.4, nsentences=32, sample_size=1114.4, sample_size_v1=0, sample_size_v2=0, ppl=1.86, wps=580.7, ups=0.52, wpb=1114.4, bsz=32, num_updates=34700, lr=1.06013e-05, gnorm=17.272, clip=100, loss_scale=16, train_wall=19, gb_free=11.4, wall=65233
2023-05-26 17:30:37 - progress_bar.py[line:272] - INFO: epoch 021:    131 / 1732 loss=2.112, loss_v1=0, loss_v2=0, nll_loss=0.882, ntokens=1176.2, nsentences=32, sample_size=1176.2, sample_size_v1=0, sample_size_v2=0, ppl=1.84, wps=612, ups=0.52, wpb=1176.2, bsz=32, num_updates=34710, lr=1.05952e-05, gnorm=15.789, clip=100, loss_scale=16, train_wall=19, gb_free=11.2, wall=65252
2023-05-26 17:30:57 - progress_bar.py[line:272] - INFO: epoch 021:    141 / 1732 loss=2.08, loss_v1=0, loss_v2=0, nll_loss=0.845, ntokens=1252.9, nsentences=32, sample_size=1252.9, sample_size_v1=0, sample_size_v2=0, ppl=1.8, wps=652.4, ups=0.52, wpb=1252.9, bsz=32, num_updates=34720, lr=1.0589e-05, gnorm=15.032, clip=100, loss_scale=16, train_wall=19, gb_free=11.2, wall=65271
2023-05-26 17:31:16 - progress_bar.py[line:272] - INFO: epoch 021:    151 / 1732 loss=2.06, loss_v1=0, loss_v2=0, nll_loss=0.822, ntokens=1168.3, nsentences=32, sample_size=1168.3, sample_size_v1=0, sample_size_v2=0, ppl=1.77, wps=605, ups=0.52, wpb=1168.3, bsz=32, num_updates=34730, lr=1.05829e-05, gnorm=14.74, clip=100, loss_scale=16, train_wall=19, gb_free=9.9, wall=65291
2023-05-26 17:31:35 - progress_bar.py[line:272] - INFO: epoch 021:    161 / 1732 loss=2.097, loss_v1=0, loss_v2=0, nll_loss=0.866, ntokens=1106.1, nsentences=32, sample_size=1106.1, sample_size_v1=0, sample_size_v2=0, ppl=1.82, wps=579.5, ups=0.52, wpb=1106.1, bsz=32, num_updates=34740, lr=1.05767e-05, gnorm=18, clip=100, loss_scale=16, train_wall=19, gb_free=11.3, wall=65310
2023-05-26 17:31:54 - progress_bar.py[line:272] - INFO: epoch 021:    171 / 1732 loss=2.098, loss_v1=0, loss_v2=0, nll_loss=0.866, ntokens=969.4, nsentences=32, sample_size=969.4, sample_size_v1=0, sample_size_v2=0, ppl=1.82, wps=514.4, ups=0.53, wpb=969.4, bsz=32, num_updates=34750, lr=1.05706e-05, gnorm=17.942, clip=100, loss_scale=16, train_wall=19, gb_free=11.3, wall=65329
2023-05-26 17:32:13 - progress_bar.py[line:272] - INFO: epoch 021:    181 / 1732 loss=2.059, loss_v1=0, loss_v2=0, nll_loss=0.822, ntokens=1122.2, nsentences=32, sample_size=1122.2, sample_size_v1=0, sample_size_v2=0, ppl=1.77, wps=589.2, ups=0.53, wpb=1122.2, bsz=32, num_updates=34760, lr=1.05645e-05, gnorm=16.084, clip=100, loss_scale=16, train_wall=19, gb_free=11.1, wall=65348
2023-05-26 17:32:32 - progress_bar.py[line:272] - INFO: epoch 021:    191 / 1732 loss=2.064, loss_v1=0, loss_v2=0, nll_loss=0.828, ntokens=1130.1, nsentences=32, sample_size=1130.1, sample_size_v1=0, sample_size_v2=0, ppl=1.77, wps=591, ups=0.52, wpb=1130.1, bsz=32, num_updates=34770, lr=1.05583e-05, gnorm=16.13, clip=100, loss_scale=16, train_wall=19, gb_free=10.9, wall=65367
2023-05-26 17:32:51 - progress_bar.py[line:272] - INFO: epoch 021:    201 / 1732 loss=2.115, loss_v1=0, loss_v2=0, nll_loss=0.884, ntokens=1092.1, nsentences=32, sample_size=1092.1, sample_size_v1=0, sample_size_v2=0, ppl=1.85, wps=578.4, ups=0.53, wpb=1092.1, bsz=32, num_updates=34780, lr=1.05522e-05, gnorm=15.596, clip=100, loss_scale=16, train_wall=19, gb_free=11.3, wall=65386
2023-05-26 17:33:10 - progress_bar.py[line:272] - INFO: epoch 021:    211 / 1732 loss=2.147, loss_v1=0, loss_v2=0, nll_loss=0.922, ntokens=1010.6, nsentences=32, sample_size=1010.6, sample_size_v1=0, sample_size_v2=0, ppl=1.89, wps=538.6, ups=0.53, wpb=1010.6, bsz=32, num_updates=34790, lr=1.0546e-05, gnorm=14.728, clip=100, loss_scale=16, train_wall=19, gb_free=11, wall=65404
2023-05-26 17:33:28 - progress_bar.py[line:272] - INFO: epoch 021:    221 / 1732 loss=2.164, loss_v1=0, loss_v2=0, nll_loss=0.94, ntokens=1140.8, nsentences=32, sample_size=1140.8, sample_size_v1=0, sample_size_v2=0, ppl=1.92, wps=609.3, ups=0.53, wpb=1140.8, bsz=32, num_updates=34800, lr=1.05399e-05, gnorm=15.192, clip=100, loss_scale=16, train_wall=19, gb_free=10.6, wall=65423
2023-05-26 17:33:47 - progress_bar.py[line:272] - INFO: epoch 021:    231 / 1732 loss=2.152, loss_v1=0, loss_v2=0, nll_loss=0.926, ntokens=1093.8, nsentences=32, sample_size=1093.8, sample_size_v1=0, sample_size_v2=0, ppl=1.9, wps=584.2, ups=0.53, wpb=1093.8, bsz=32, num_updates=34810, lr=1.05338e-05, gnorm=14.25, clip=100, loss_scale=16, train_wall=19, gb_free=11.6, wall=65442
2023-05-26 17:34:06 - progress_bar.py[line:272] - INFO: epoch 021:    241 / 1732 loss=2.181, loss_v1=0, loss_v2=0, nll_loss=0.957, ntokens=1114.7, nsentences=32, sample_size=1114.7, sample_size_v1=0, sample_size_v2=0, ppl=1.94, wps=594.3, ups=0.53, wpb=1114.7, bsz=32, num_updates=34820, lr=1.05276e-05, gnorm=15.213, clip=100, loss_scale=16, train_wall=19, gb_free=11.6, wall=65461
2023-05-26 17:34:25 - progress_bar.py[line:272] - INFO: epoch 021:    251 / 1732 loss=2.149, loss_v1=0, loss_v2=0, nll_loss=0.923, ntokens=1172.1, nsentences=32, sample_size=1172.1, sample_size_v1=0, sample_size_v2=0, ppl=1.9, wps=620.6, ups=0.53, wpb=1172.1, bsz=32, num_updates=34830, lr=1.05215e-05, gnorm=13.987, clip=100, loss_scale=16, train_wall=19, gb_free=11.6, wall=65480
2023-05-26 17:34:44 - progress_bar.py[line:272] - INFO: epoch 021:    261 / 1732 loss=2.174, loss_v1=0, loss_v2=0, nll_loss=0.952, ntokens=1139.9, nsentences=32, sample_size=1139.9, sample_size_v1=0, sample_size_v2=0, ppl=1.93, wps=610, ups=0.54, wpb=1139.9, bsz=32, num_updates=34840, lr=1.05153e-05, gnorm=14.534, clip=100, loss_scale=16, train_wall=19, gb_free=11.1, wall=65498
2023-05-26 17:35:02 - progress_bar.py[line:272] - INFO: epoch 021:    271 / 1732 loss=2.139, loss_v1=0, loss_v2=0, nll_loss=0.912, ntokens=1145.3, nsentences=32, sample_size=1145.3, sample_size_v1=0, sample_size_v2=0, ppl=1.88, wps=606.9, ups=0.53, wpb=1145.3, bsz=32, num_updates=34850, lr=1.05092e-05, gnorm=13.82, clip=100, loss_scale=16, train_wall=19, gb_free=11.2, wall=65517
2023-05-26 17:35:21 - progress_bar.py[line:272] - INFO: epoch 021:    281 / 1732 loss=2.182, loss_v1=0, loss_v2=0, nll_loss=0.961, ntokens=1149.7, nsentences=32, sample_size=1149.7, sample_size_v1=0, sample_size_v2=0, ppl=1.95, wps=608.4, ups=0.53, wpb=1149.7, bsz=32, num_updates=34860, lr=1.0503e-05, gnorm=15.938, clip=100, loss_scale=16, train_wall=19, gb_free=11.7, wall=65536
2023-05-26 17:35:40 - progress_bar.py[line:272] - INFO: epoch 021:    291 / 1732 loss=2.135, loss_v1=0, loss_v2=0, nll_loss=0.906, ntokens=1130.5, nsentences=32, sample_size=1130.5, sample_size_v1=0, sample_size_v2=0, ppl=1.87, wps=602.1, ups=0.53, wpb=1130.5, bsz=32, num_updates=34870, lr=1.04969e-05, gnorm=13.474, clip=100, loss_scale=16, train_wall=19, gb_free=11.3, wall=65555
2023-05-26 17:35:59 - progress_bar.py[line:272] - INFO: epoch 021:    301 / 1732 loss=2.147, loss_v1=0, loss_v2=0, nll_loss=0.921, ntokens=1109.1, nsentences=32, sample_size=1109.1, sample_size_v1=0, sample_size_v2=0, ppl=1.89, wps=591, ups=0.53, wpb=1109.1, bsz=32, num_updates=34880, lr=1.04908e-05, gnorm=14.964, clip=100, loss_scale=16, train_wall=19, gb_free=11.5, wall=65574
2023-05-26 17:36:18 - progress_bar.py[line:272] - INFO: epoch 021:    311 / 1732 loss=2.137, loss_v1=0, loss_v2=0, nll_loss=0.911, ntokens=1067.3, nsentences=32, sample_size=1067.3, sample_size_v1=0, sample_size_v2=0, ppl=1.88, wps=570.8, ups=0.53, wpb=1067.3, bsz=32, num_updates=34890, lr=1.04846e-05, gnorm=16.377, clip=100, loss_scale=16, train_wall=19, gb_free=11.5, wall=65592
2023-05-26 17:36:36 - progress_bar.py[line:272] - INFO: epoch 021:    321 / 1732 loss=2.179, loss_v1=0, loss_v2=0, nll_loss=0.957, ntokens=1001.7, nsentences=32, sample_size=1001.7, sample_size_v1=0, sample_size_v2=0, ppl=1.94, wps=539, ups=0.54, wpb=1001.7, bsz=32, num_updates=34900, lr=1.04785e-05, gnorm=16.507, clip=100, loss_scale=16, train_wall=19, gb_free=11.8, wall=65611
2023-05-26 17:36:55 - progress_bar.py[line:272] - INFO: epoch 021:    331 / 1732 loss=2.176, loss_v1=0, loss_v2=0, nll_loss=0.954, ntokens=1019.4, nsentences=32, sample_size=1019.4, sample_size_v1=0, sample_size_v2=0, ppl=1.94, wps=547.5, ups=0.54, wpb=1019.4, bsz=32, num_updates=34910, lr=1.04723e-05, gnorm=16.857, clip=100, loss_scale=32, train_wall=19, gb_free=11.9, wall=65629
2023-05-26 17:37:13 - progress_bar.py[line:272] - INFO: epoch 021:    341 / 1732 loss=2.135, loss_v1=0, loss_v2=0, nll_loss=0.908, ntokens=952.2, nsentences=32, sample_size=952.2, sample_size_v1=0, sample_size_v2=0, ppl=1.88, wps=513.5, ups=0.54, wpb=952.2, bsz=32, num_updates=34920, lr=1.04662e-05, gnorm=16.55, clip=100, loss_scale=32, train_wall=19, gb_free=11.4, wall=65648
2023-05-26 17:37:32 - progress_bar.py[line:272] - INFO: epoch 021:    351 / 1732 loss=2.142, loss_v1=0, loss_v2=0, nll_loss=0.916, ntokens=941.5, nsentences=32, sample_size=941.5, sample_size_v1=0, sample_size_v2=0, ppl=1.89, wps=508.9, ups=0.54, wpb=941.5, bsz=32, num_updates=34930, lr=1.046e-05, gnorm=15.545, clip=100, loss_scale=32, train_wall=18, gb_free=11.5, wall=65666
2023-05-26 17:37:50 - progress_bar.py[line:272] - INFO: epoch 021:    361 / 1732 loss=2.181, loss_v1=0, loss_v2=0, nll_loss=0.959, ntokens=925.7, nsentences=32, sample_size=925.7, sample_size_v1=0, sample_size_v2=0, ppl=1.94, wps=500.1, ups=0.54, wpb=925.7, bsz=32, num_updates=34940, lr=1.04539e-05, gnorm=17.822, clip=100, loss_scale=32, train_wall=18, gb_free=11.5, wall=65685
2023-05-26 17:38:09 - progress_bar.py[line:272] - INFO: epoch 021:    371 / 1732 loss=2.169, loss_v1=0, loss_v2=0, nll_loss=0.946, ntokens=989.1, nsentences=32, sample_size=989.1, sample_size_v1=0, sample_size_v2=0, ppl=1.93, wps=531.9, ups=0.54, wpb=989.1, bsz=32, num_updates=34950, lr=1.04478e-05, gnorm=16.954, clip=100, loss_scale=32, train_wall=19, gb_free=11, wall=65704
2023-05-26 17:38:28 - progress_bar.py[line:272] - INFO: epoch 021:    381 / 1732 loss=2.183, loss_v1=0, loss_v2=0, nll_loss=0.961, ntokens=1071.8, nsentences=32, sample_size=1071.8, sample_size_v1=0, sample_size_v2=0, ppl=1.95, wps=576.7, ups=0.54, wpb=1071.8, bsz=32, num_updates=34960, lr=1.04416e-05, gnorm=16.778, clip=100, loss_scale=32, train_wall=19, gb_free=11.3, wall=65722
2023-05-26 17:38:46 - progress_bar.py[line:272] - INFO: epoch 021:    391 / 1732 loss=2.149, loss_v1=0, loss_v2=0, nll_loss=0.922, ntokens=986, nsentences=32, sample_size=986, sample_size_v1=0, sample_size_v2=0, ppl=1.9, wps=529, ups=0.54, wpb=986, bsz=32, num_updates=34970, lr=1.04355e-05, gnorm=16.812, clip=100, loss_scale=32, train_wall=19, gb_free=11.6, wall=65741
2023-05-26 17:39:05 - progress_bar.py[line:272] - INFO: epoch 021:    401 / 1732 loss=2.156, loss_v1=0, loss_v2=0, nll_loss=0.931, ntokens=999.1, nsentences=32, sample_size=999.1, sample_size_v1=0, sample_size_v2=0, ppl=1.91, wps=538.2, ups=0.54, wpb=999.1, bsz=32, num_updates=34980, lr=1.04293e-05, gnorm=17.305, clip=100, loss_scale=32, train_wall=19, gb_free=11.3, wall=65759
2023-05-26 17:39:23 - progress_bar.py[line:272] - INFO: epoch 021:    411 / 1732 loss=2.154, loss_v1=0, loss_v2=0, nll_loss=0.928, ntokens=1079.4, nsentences=32, sample_size=1079.4, sample_size_v1=0, sample_size_v2=0, ppl=1.9, wps=578.1, ups=0.54, wpb=1079.4, bsz=32, num_updates=34990, lr=1.04232e-05, gnorm=15.901, clip=100, loss_scale=32, train_wall=19, gb_free=11.5, wall=65778
2023-05-26 17:39:42 - progress_bar.py[line:272] - INFO: epoch 021:    421 / 1732 loss=2.128, loss_v1=0, loss_v2=0, nll_loss=0.898, ntokens=1019, nsentences=32, sample_size=1019, sample_size_v1=0, sample_size_v2=0, ppl=1.86, wps=545.9, ups=0.54, wpb=1019, bsz=32, num_updates=35000, lr=1.04171e-05, gnorm=16.894, clip=100, loss_scale=32, train_wall=19, gb_free=11.3, wall=65797
2023-05-26 17:40:01 - progress_bar.py[line:272] - INFO: epoch 021:    431 / 1732 loss=2.134, loss_v1=0, loss_v2=0, nll_loss=0.907, ntokens=1019.7, nsentences=32, sample_size=1019.7, sample_size_v1=0, sample_size_v2=0, ppl=1.88, wps=548, ups=0.54, wpb=1019.7, bsz=32, num_updates=35010, lr=1.04109e-05, gnorm=17.477, clip=100, loss_scale=32, train_wall=19, gb_free=11.3, wall=65815
2023-05-26 17:40:19 - progress_bar.py[line:272] - INFO: epoch 021:    441 / 1732 loss=2.16, loss_v1=0, loss_v2=0, nll_loss=0.936, ntokens=990.4, nsentences=32, sample_size=990.4, sample_size_v1=0, sample_size_v2=0, ppl=1.91, wps=533.8, ups=0.54, wpb=990.4, bsz=32, num_updates=35020, lr=1.04048e-05, gnorm=16.656, clip=100, loss_scale=32, train_wall=19, gb_free=11.9, wall=65834
2023-05-26 17:40:38 - progress_bar.py[line:272] - INFO: epoch 021:    451 / 1732 loss=2.152, loss_v1=0, loss_v2=0, nll_loss=0.926, ntokens=920.2, nsentences=32, sample_size=920.2, sample_size_v1=0, sample_size_v2=0, ppl=1.9, wps=495.6, ups=0.54, wpb=920.2, bsz=32, num_updates=35030, lr=1.03986e-05, gnorm=15.68, clip=100, loss_scale=32, train_wall=19, gb_free=10.9, wall=65852
2023-05-26 17:40:56 - progress_bar.py[line:272] - INFO: epoch 021:    461 / 1732 loss=2.189, loss_v1=0, loss_v2=0, nll_loss=0.968, ntokens=1038.5, nsentences=32, sample_size=1038.5, sample_size_v1=0, sample_size_v2=0, ppl=1.96, wps=557.8, ups=0.54, wpb=1038.5, bsz=32, num_updates=35040, lr=1.03925e-05, gnorm=16.694, clip=100, loss_scale=32, train_wall=19, gb_free=11.2, wall=65871
2023-05-26 17:41:15 - progress_bar.py[line:272] - INFO: epoch 021:    471 / 1732 loss=2.174, loss_v1=0, loss_v2=0, nll_loss=0.95, ntokens=1039.4, nsentences=32, sample_size=1039.4, sample_size_v1=0, sample_size_v2=0, ppl=1.93, wps=555.6, ups=0.53, wpb=1039.4, bsz=32, num_updates=35050, lr=1.03863e-05, gnorm=16.56, clip=100, loss_scale=32, train_wall=19, gb_free=11.7, wall=65890
2023-05-26 17:41:34 - progress_bar.py[line:272] - INFO: epoch 021:    481 / 1732 loss=2.183, loss_v1=0, loss_v2=0, nll_loss=0.961, ntokens=1025, nsentences=32, sample_size=1025, sample_size_v1=0, sample_size_v2=0, ppl=1.95, wps=550.9, ups=0.54, wpb=1025, bsz=32, num_updates=35060, lr=1.03802e-05, gnorm=16.458, clip=100, loss_scale=32, train_wall=19, gb_free=11.8, wall=65908
2023-05-26 17:41:52 - progress_bar.py[line:272] - INFO: epoch 021:    491 / 1732 loss=2.153, loss_v1=0, loss_v2=0, nll_loss=0.925, ntokens=939.5, nsentences=32, sample_size=939.5, sample_size_v1=0, sample_size_v2=0, ppl=1.9, wps=506.8, ups=0.54, wpb=939.5, bsz=32, num_updates=35070, lr=1.03741e-05, gnorm=17.517, clip=100, loss_scale=32, train_wall=19, gb_free=10.8, wall=65927
2023-05-26 17:42:11 - progress_bar.py[line:272] - INFO: epoch 021:    501 / 1732 loss=2.149, loss_v1=0, loss_v2=0, nll_loss=0.922, ntokens=938, nsentences=32, sample_size=938, sample_size_v1=0, sample_size_v2=0, ppl=1.89, wps=508.2, ups=0.54, wpb=938, bsz=32, num_updates=35080, lr=1.03679e-05, gnorm=19.009, clip=100, loss_scale=32, train_wall=18, gb_free=11.6, wall=65945
2023-05-26 17:42:29 - progress_bar.py[line:272] - INFO: epoch 021:    511 / 1732 loss=2.198, loss_v1=0, loss_v2=0, nll_loss=0.977, ntokens=1040.7, nsentences=32, sample_size=1040.7, sample_size_v1=0, sample_size_v2=0, ppl=1.97, wps=560.2, ups=0.54, wpb=1040.7, bsz=32, num_updates=35090, lr=1.03618e-05, gnorm=17.859, clip=100, loss_scale=32, train_wall=19, gb_free=12, wall=65964
2023-05-26 17:42:48 - progress_bar.py[line:272] - INFO: epoch 021:    521 / 1732 loss=2.132, loss_v1=0, loss_v2=0, nll_loss=0.905, ntokens=1020.1, nsentences=32, sample_size=1020.1, sample_size_v1=0, sample_size_v2=0, ppl=1.87, wps=551.8, ups=0.54, wpb=1020.1, bsz=32, num_updates=35100, lr=1.03556e-05, gnorm=16.866, clip=100, loss_scale=32, train_wall=18, gb_free=11.6, wall=65983
2023-05-26 17:43:06 - progress_bar.py[line:272] - INFO: epoch 021:    531 / 1732 loss=2.172, loss_v1=0, loss_v2=0, nll_loss=0.949, ntokens=931.7, nsentences=32, sample_size=931.7, sample_size_v1=0, sample_size_v2=0, ppl=1.93, wps=503.2, ups=0.54, wpb=931.7, bsz=32, num_updates=35110, lr=1.03495e-05, gnorm=18.795, clip=100, loss_scale=32, train_wall=18, gb_free=11.6, wall=66001
2023-05-26 17:43:25 - progress_bar.py[line:272] - INFO: epoch 021:    541 / 1732 loss=2.163, loss_v1=0, loss_v2=0, nll_loss=0.938, ntokens=994.8, nsentences=32, sample_size=994.8, sample_size_v1=0, sample_size_v2=0, ppl=1.92, wps=538.3, ups=0.54, wpb=994.8, bsz=32, num_updates=35120, lr=1.03433e-05, gnorm=17.399, clip=100, loss_scale=32, train_wall=18, gb_free=12, wall=66020
2023-05-26 17:43:44 - progress_bar.py[line:272] - INFO: epoch 021:    551 / 1732 loss=2.185, loss_v1=0, loss_v2=0, nll_loss=0.964, ntokens=1021.9, nsentences=32, sample_size=1021.9, sample_size_v1=0, sample_size_v2=0, ppl=1.95, wps=547.4, ups=0.54, wpb=1021.9, bsz=32, num_updates=35130, lr=1.03372e-05, gnorm=17.164, clip=100, loss_scale=32, train_wall=19, gb_free=11.3, wall=66038
2023-05-26 17:44:02 - progress_bar.py[line:272] - INFO: epoch 021:    561 / 1732 loss=2.183, loss_v1=0, loss_v2=0, nll_loss=0.961, ntokens=1030.9, nsentences=32, sample_size=1030.9, sample_size_v1=0, sample_size_v2=0, ppl=1.95, wps=552.7, ups=0.54, wpb=1030.9, bsz=32, num_updates=35140, lr=1.03311e-05, gnorm=17.19, clip=100, loss_scale=32, train_wall=19, gb_free=11.3, wall=66057
2023-05-26 17:44:21 - progress_bar.py[line:272] - INFO: epoch 021:    571 / 1732 loss=2.196, loss_v1=0, loss_v2=0, nll_loss=0.975, ntokens=990.9, nsentences=32, sample_size=990.9, sample_size_v1=0, sample_size_v2=0, ppl=1.97, wps=532.1, ups=0.54, wpb=990.9, bsz=32, num_updates=35150, lr=1.03249e-05, gnorm=17.67, clip=100, loss_scale=32, train_wall=19, gb_free=11.8, wall=66075
2023-05-26 17:44:40 - progress_bar.py[line:272] - INFO: epoch 021:    581 / 1732 loss=2.165, loss_v1=0, loss_v2=0, nll_loss=0.941, ntokens=1021.6, nsentences=32, sample_size=1021.6, sample_size_v1=0, sample_size_v2=0, ppl=1.92, wps=543.5, ups=0.53, wpb=1021.6, bsz=32, num_updates=35160, lr=1.03188e-05, gnorm=16.337, clip=100, loss_scale=32, train_wall=19, gb_free=10.7, wall=66094
2023-05-26 17:44:58 - progress_bar.py[line:272] - INFO: epoch 021:    591 / 1732 loss=2.157, loss_v1=0, loss_v2=0, nll_loss=0.931, ntokens=934.4, nsentences=32, sample_size=934.4, sample_size_v1=0, sample_size_v2=0, ppl=1.91, wps=501, ups=0.54, wpb=934.4, bsz=32, num_updates=35170, lr=1.03126e-05, gnorm=18.288, clip=100, loss_scale=32, train_wall=19, gb_free=10.7, wall=66113
2023-05-26 17:45:17 - progress_bar.py[line:272] - INFO: epoch 021:    601 / 1732 loss=2.125, loss_v1=0, loss_v2=0, nll_loss=0.896, ntokens=941.2, nsentences=32, sample_size=941.2, sample_size_v1=0, sample_size_v2=0, ppl=1.86, wps=506.4, ups=0.54, wpb=941.2, bsz=32, num_updates=35180, lr=1.03065e-05, gnorm=15.93, clip=100, loss_scale=32, train_wall=19, gb_free=11.6, wall=66132
2023-05-26 17:45:35 - progress_bar.py[line:272] - INFO: epoch 021:    611 / 1732 loss=2.157, loss_v1=0, loss_v2=0, nll_loss=0.933, ntokens=911.9, nsentences=32, sample_size=911.9, sample_size_v1=0, sample_size_v2=0, ppl=1.91, wps=493.3, ups=0.54, wpb=911.9, bsz=32, num_updates=35190, lr=1.03004e-05, gnorm=19.144, clip=100, loss_scale=32, train_wall=18, gb_free=11.7, wall=66150
2023-05-26 17:45:54 - progress_bar.py[line:272] - INFO: epoch 021:    621 / 1732 loss=2.177, loss_v1=0, loss_v2=0, nll_loss=0.954, ntokens=845.9, nsentences=32, sample_size=845.9, sample_size_v1=0, sample_size_v2=0, ppl=1.94, wps=461, ups=0.54, wpb=845.9, bsz=32, num_updates=35200, lr=1.02942e-05, gnorm=18.811, clip=100, loss_scale=32, train_wall=18, gb_free=12, wall=66168
2023-05-26 17:46:12 - progress_bar.py[line:272] - INFO: epoch 021:    631 / 1732 loss=2.143, loss_v1=0, loss_v2=0, nll_loss=0.915, ntokens=949.2, nsentences=32, sample_size=949.2, sample_size_v1=0, sample_size_v2=0, ppl=1.89, wps=513.8, ups=0.54, wpb=949.2, bsz=32, num_updates=35210, lr=1.02881e-05, gnorm=17.644, clip=100, loss_scale=32, train_wall=18, gb_free=11.2, wall=66187
2023-05-26 17:46:31 - progress_bar.py[line:272] - INFO: epoch 021:    641 / 1732 loss=2.179, loss_v1=0, loss_v2=0, nll_loss=0.957, ntokens=915.8, nsentences=32, sample_size=915.8, sample_size_v1=0, sample_size_v2=0, ppl=1.94, wps=496, ups=0.54, wpb=915.8, bsz=32, num_updates=35220, lr=1.02819e-05, gnorm=18.891, clip=100, loss_scale=32, train_wall=18, gb_free=11.8, wall=66205
2023-05-26 17:46:49 - progress_bar.py[line:272] - INFO: epoch 021:    651 / 1732 loss=2.149, loss_v1=0, loss_v2=0, nll_loss=0.924, ntokens=990.2, nsentences=32, sample_size=990.2, sample_size_v1=0, sample_size_v2=0, ppl=1.9, wps=537, ups=0.54, wpb=990.2, bsz=32, num_updates=35230, lr=1.02758e-05, gnorm=16.299, clip=100, loss_scale=32, train_wall=18, gb_free=11.7, wall=66224
2023-05-26 17:47:07 - progress_bar.py[line:272] - INFO: epoch 021:    661 / 1732 loss=2.151, loss_v1=0, loss_v2=0, nll_loss=0.926, ntokens=863.9, nsentences=32, sample_size=863.9, sample_size_v1=0, sample_size_v2=0, ppl=1.9, wps=471.4, ups=0.55, wpb=863.9, bsz=32, num_updates=35240, lr=1.02696e-05, gnorm=18.198, clip=100, loss_scale=32, train_wall=18, gb_free=11.5, wall=66242
2023-05-26 17:47:26 - progress_bar.py[line:272] - INFO: epoch 021:    671 / 1732 loss=2.173, loss_v1=0, loss_v2=0, nll_loss=0.95, ntokens=943.7, nsentences=32, sample_size=943.7, sample_size_v1=0, sample_size_v2=0, ppl=1.93, wps=508.9, ups=0.54, wpb=943.7, bsz=32, num_updates=35250, lr=1.02635e-05, gnorm=16.76, clip=100, loss_scale=32, train_wall=19, gb_free=11.4, wall=66261
2023-05-26 17:47:44 - progress_bar.py[line:272] - INFO: epoch 021:    681 / 1732 loss=2.166, loss_v1=0, loss_v2=0, nll_loss=0.941, ntokens=972.8, nsentences=32, sample_size=972.8, sample_size_v1=0, sample_size_v2=0, ppl=1.92, wps=526.7, ups=0.54, wpb=972.8, bsz=32, num_updates=35260, lr=1.02574e-05, gnorm=16.951, clip=100, loss_scale=32, train_wall=18, gb_free=11, wall=66279
2023-05-26 17:48:03 - progress_bar.py[line:272] - INFO: epoch 021:    691 / 1732 loss=2.168, loss_v1=0, loss_v2=0, nll_loss=0.944, ntokens=949, nsentences=32, sample_size=949, sample_size_v1=0, sample_size_v2=0, ppl=1.92, wps=510.2, ups=0.54, wpb=949, bsz=32, num_updates=35270, lr=1.02512e-05, gnorm=17.542, clip=100, loss_scale=32, train_wall=19, gb_free=11.8, wall=66298
2023-05-26 17:48:22 - progress_bar.py[line:272] - INFO: epoch 021:    701 / 1732 loss=2.132, loss_v1=0, loss_v2=0, nll_loss=0.903, ntokens=988.7, nsentences=32, sample_size=988.7, sample_size_v1=0, sample_size_v2=0, ppl=1.87, wps=532.2, ups=0.54, wpb=988.7, bsz=32, num_updates=35280, lr=1.02451e-05, gnorm=16.746, clip=100, loss_scale=32, train_wall=19, gb_free=11.8, wall=66316
2023-05-26 17:48:40 - progress_bar.py[line:272] - INFO: epoch 021:    711 / 1732 loss=2.156, loss_v1=0, loss_v2=0, nll_loss=0.931, ntokens=913.9, nsentences=32, sample_size=913.9, sample_size_v1=0, sample_size_v2=0, ppl=1.91, wps=494.7, ups=0.54, wpb=913.9, bsz=32, num_updates=35290, lr=1.02389e-05, gnorm=16.903, clip=100, loss_scale=32, train_wall=18, gb_free=11.6, wall=66335
2023-05-26 17:48:58 - progress_bar.py[line:272] - INFO: epoch 021:    721 / 1732 loss=2.126, loss_v1=0, loss_v2=0, nll_loss=0.896, ntokens=854.5, nsentences=32, sample_size=854.5, sample_size_v1=0, sample_size_v2=0, ppl=1.86, wps=464.9, ups=0.54, wpb=854.5, bsz=32, num_updates=35300, lr=1.02328e-05, gnorm=17.687, clip=100, loss_scale=32, train_wall=18, gb_free=11.4, wall=66353
2023-05-26 17:49:17 - progress_bar.py[line:272] - INFO: epoch 021:    731 / 1732 loss=2.148, loss_v1=0, loss_v2=0, nll_loss=0.923, ntokens=932.8, nsentences=32, sample_size=932.8, sample_size_v1=0, sample_size_v2=0, ppl=1.9, wps=504.4, ups=0.54, wpb=932.8, bsz=32, num_updates=35310, lr=1.02266e-05, gnorm=17.379, clip=100, loss_scale=32, train_wall=18, gb_free=11.6, wall=66372
2023-05-26 17:49:36 - progress_bar.py[line:272] - INFO: epoch 021:    741 / 1732 loss=2.142, loss_v1=0, loss_v2=0, nll_loss=0.915, ntokens=1003.7, nsentences=32, sample_size=1003.7, sample_size_v1=0, sample_size_v2=0, ppl=1.89, wps=541.5, ups=0.54, wpb=1003.7, bsz=32, num_updates=35320, lr=1.02205e-05, gnorm=17.081, clip=100, loss_scale=32, train_wall=19, gb_free=11.4, wall=66390
2023-05-26 17:49:54 - progress_bar.py[line:272] - INFO: epoch 021:    751 / 1732 loss=2.142, loss_v1=0, loss_v2=0, nll_loss=0.915, ntokens=975.7, nsentences=32, sample_size=975.7, sample_size_v1=0, sample_size_v2=0, ppl=1.89, wps=524.1, ups=0.54, wpb=975.7, bsz=32, num_updates=35330, lr=1.02144e-05, gnorm=17.453, clip=100, loss_scale=32, train_wall=19, gb_free=11, wall=66409
2023-05-26 17:50:13 - progress_bar.py[line:272] - INFO: epoch 021:    761 / 1732 loss=2.132, loss_v1=0, loss_v2=0, nll_loss=0.903, ntokens=974.2, nsentences=32, sample_size=974.2, sample_size_v1=0, sample_size_v2=0, ppl=1.87, wps=526.2, ups=0.54, wpb=974.2, bsz=32, num_updates=35340, lr=1.02082e-05, gnorm=18.013, clip=100, loss_scale=32, train_wall=18, gb_free=11.5, wall=66427
2023-05-26 17:50:31 - progress_bar.py[line:272] - INFO: epoch 021:    771 / 1732 loss=2.144, loss_v1=0, loss_v2=0, nll_loss=0.918, ntokens=924.9, nsentences=32, sample_size=924.9, sample_size_v1=0, sample_size_v2=0, ppl=1.89, wps=501.7, ups=0.54, wpb=924.9, bsz=32, num_updates=35350, lr=1.02021e-05, gnorm=17.918, clip=100, loss_scale=32, train_wall=18, gb_free=11.7, wall=66446
2023-05-26 17:50:50 - progress_bar.py[line:272] - INFO: epoch 021:    781 / 1732 loss=2.138, loss_v1=0, loss_v2=0, nll_loss=0.911, ntokens=1053.4, nsentences=32, sample_size=1053.4, sample_size_v1=0, sample_size_v2=0, ppl=1.88, wps=566.5, ups=0.54, wpb=1053.4, bsz=32, num_updates=35360, lr=1.01959e-05, gnorm=15.297, clip=100, loss_scale=32, train_wall=19, gb_free=11.7, wall=66464
2023-05-26 17:51:08 - progress_bar.py[line:272] - INFO: epoch 021:    791 / 1732 loss=2.173, loss_v1=0, loss_v2=0, nll_loss=0.95, ntokens=1022, nsentences=32, sample_size=1022, sample_size_v1=0, sample_size_v2=0, ppl=1.93, wps=552.6, ups=0.54, wpb=1022, bsz=32, num_updates=35370, lr=1.01898e-05, gnorm=18.147, clip=100, loss_scale=32, train_wall=18, gb_free=11.4, wall=66483
2023-05-26 17:51:27 - progress_bar.py[line:272] - INFO: epoch 021:    801 / 1732 loss=2.158, loss_v1=0, loss_v2=0, nll_loss=0.931, ntokens=984.3, nsentences=32, sample_size=984.3, sample_size_v1=0, sample_size_v2=0, ppl=1.91, wps=531.3, ups=0.54, wpb=984.3, bsz=32, num_updates=35380, lr=1.01836e-05, gnorm=17.054, clip=100, loss_scale=32, train_wall=18, gb_free=11.1, wall=66501
2023-05-26 17:51:45 - progress_bar.py[line:272] - INFO: epoch 021:    811 / 1732 loss=2.153, loss_v1=0, loss_v2=0, nll_loss=0.927, ntokens=931.4, nsentences=32, sample_size=931.4, sample_size_v1=0, sample_size_v2=0, ppl=1.9, wps=504.4, ups=0.54, wpb=931.4, bsz=32, num_updates=35390, lr=1.01775e-05, gnorm=19.731, clip=100, loss_scale=32, train_wall=18, gb_free=11.4, wall=66520
2023-05-26 17:52:04 - progress_bar.py[line:272] - INFO: epoch 021:    821 / 1732 loss=2.159, loss_v1=0, loss_v2=0, nll_loss=0.933, ntokens=915.1, nsentences=32, sample_size=915.1, sample_size_v1=0, sample_size_v2=0, ppl=1.91, wps=493.8, ups=0.54, wpb=915.1, bsz=32, num_updates=35400, lr=1.01714e-05, gnorm=18.965, clip=100, loss_scale=32, train_wall=19, gb_free=10.2, wall=66538
2023-05-26 17:52:22 - progress_bar.py[line:272] - INFO: epoch 021:    831 / 1732 loss=2.141, loss_v1=0, loss_v2=0, nll_loss=0.914, ntokens=914.9, nsentences=32, sample_size=914.9, sample_size_v1=0, sample_size_v2=0, ppl=1.88, wps=496.5, ups=0.54, wpb=914.9, bsz=32, num_updates=35410, lr=1.01652e-05, gnorm=17.547, clip=100, loss_scale=32, train_wall=18, gb_free=11.6, wall=66557
2023-05-26 17:52:33 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2023-05-26 17:52:42 - progress_bar.py[line:272] - INFO: epoch 021:    842 / 1732 loss=2.148, loss_v1=0, loss_v2=0, nll_loss=0.921, ntokens=954.8, nsentences=32, sample_size=954.8, sample_size_v1=0, sample_size_v2=0, ppl=1.89, wps=472.9, ups=0.5, wpb=954.8, bsz=32, num_updates=35420, lr=1.01591e-05, gnorm=17.385, clip=100, loss_scale=32, train_wall=20, gb_free=11.4, wall=66577
2023-05-26 17:53:01 - progress_bar.py[line:272] - INFO: epoch 021:    852 / 1732 loss=2.161, loss_v1=0, loss_v2=0, nll_loss=0.935, ntokens=997.8, nsentences=32, sample_size=997.8, sample_size_v1=0, sample_size_v2=0, ppl=1.91, wps=538.3, ups=0.54, wpb=997.8, bsz=32, num_updates=35430, lr=1.01529e-05, gnorm=17.078, clip=100, loss_scale=32, train_wall=19, gb_free=11.8, wall=66596
2023-05-26 17:53:19 - progress_bar.py[line:272] - INFO: epoch 021:    862 / 1732 loss=2.133, loss_v1=0, loss_v2=0, nll_loss=0.906, ntokens=931.8, nsentences=32, sample_size=931.8, sample_size_v1=0, sample_size_v2=0, ppl=1.87, wps=503.2, ups=0.54, wpb=931.8, bsz=32, num_updates=35440, lr=1.01468e-05, gnorm=18.193, clip=100, loss_scale=32, train_wall=18, gb_free=11, wall=66614
2023-05-26 17:53:38 - progress_bar.py[line:272] - INFO: epoch 021:    872 / 1732 loss=2.143, loss_v1=0, loss_v2=0, nll_loss=0.918, ntokens=965, nsentences=32, sample_size=965, sample_size_v1=0, sample_size_v2=0, ppl=1.89, wps=521.7, ups=0.54, wpb=965, bsz=32, num_updates=35450, lr=1.01407e-05, gnorm=17.183, clip=100, loss_scale=32, train_wall=18, gb_free=11.6, wall=66633
2023-05-26 17:53:57 - progress_bar.py[line:272] - INFO: epoch 021:    882 / 1732 loss=2.104, loss_v1=0, loss_v2=0, nll_loss=0.872, ntokens=987.7, nsentences=32, sample_size=987.7, sample_size_v1=0, sample_size_v2=0, ppl=1.83, wps=531, ups=0.54, wpb=987.7, bsz=32, num_updates=35460, lr=1.01345e-05, gnorm=17.161, clip=100, loss_scale=32, train_wall=19, gb_free=11.3, wall=66651
2023-05-26 17:54:15 - progress_bar.py[line:272] - INFO: epoch 021:    892 / 1732 loss=2.093, loss_v1=0, loss_v2=0, nll_loss=0.861, ntokens=1003.5, nsentences=32, sample_size=1003.5, sample_size_v1=0, sample_size_v2=0, ppl=1.82, wps=538.6, ups=0.54, wpb=1003.5, bsz=32, num_updates=35470, lr=1.01284e-05, gnorm=16.919, clip=100, loss_scale=32, train_wall=19, gb_free=11.1, wall=66670
2023-05-26 17:54:34 - progress_bar.py[line:272] - INFO: epoch 021:    902 / 1732 loss=2.099, loss_v1=0, loss_v2=0, nll_loss=0.867, ntokens=1046.1, nsentences=32, sample_size=1046.1, sample_size_v1=0, sample_size_v2=0, ppl=1.82, wps=562.6, ups=0.54, wpb=1046.1, bsz=32, num_updates=35480, lr=1.01222e-05, gnorm=16.251, clip=100, loss_scale=32, train_wall=19, gb_free=11.2, wall=66688
2023-05-26 17:54:52 - progress_bar.py[line:272] - INFO: epoch 021:    912 / 1732 loss=2.157, loss_v1=0, loss_v2=0, nll_loss=0.931, ntokens=948.6, nsentences=32, sample_size=948.6, sample_size_v1=0, sample_size_v2=0, ppl=1.91, wps=513, ups=0.54, wpb=948.6, bsz=32, num_updates=35490, lr=1.01161e-05, gnorm=19.383, clip=100, loss_scale=32, train_wall=18, gb_free=11, wall=66707
2023-05-26 17:55:11 - progress_bar.py[line:272] - INFO: epoch 021:    922 / 1732 loss=2.139, loss_v1=0, loss_v2=0, nll_loss=0.912, ntokens=1004.6, nsentences=32, sample_size=1004.6, sample_size_v1=0, sample_size_v2=0, ppl=1.88, wps=538.4, ups=0.54, wpb=1004.6, bsz=32, num_updates=35500, lr=1.01099e-05, gnorm=17.684, clip=100, loss_scale=32, train_wall=19, gb_free=11.3, wall=66726
2023-05-26 17:55:30 - progress_bar.py[line:272] - INFO: epoch 021:    932 / 1732 loss=2.139, loss_v1=0, loss_v2=0, nll_loss=0.911, ntokens=1036.8, nsentences=32, sample_size=1036.8, sample_size_v1=0, sample_size_v2=0, ppl=1.88, wps=552.3, ups=0.53, wpb=1036.8, bsz=32, num_updates=35510, lr=1.01038e-05, gnorm=18.577, clip=100, loss_scale=32, train_wall=19, gb_free=10.9, wall=66744
2023-05-26 17:55:49 - progress_bar.py[line:272] - INFO: epoch 021:    942 / 1732 loss=2.148, loss_v1=0, loss_v2=0, nll_loss=0.922, ntokens=1063.3, nsentences=32, sample_size=1063.3, sample_size_v1=0, sample_size_v2=0, ppl=1.89, wps=564.5, ups=0.53, wpb=1063.3, bsz=32, num_updates=35520, lr=1.00977e-05, gnorm=18.939, clip=100, loss_scale=32, train_wall=19, gb_free=11.5, wall=66763
2023-05-26 17:56:07 - progress_bar.py[line:272] - INFO: epoch 021:    952 / 1732 loss=2.152, loss_v1=0, loss_v2=0, nll_loss=0.927, ntokens=1011.4, nsentences=32, sample_size=1011.4, sample_size_v1=0, sample_size_v2=0, ppl=1.9, wps=538.6, ups=0.53, wpb=1011.4, bsz=32, num_updates=35530, lr=1.00915e-05, gnorm=18.783, clip=100, loss_scale=32, train_wall=19, gb_free=11.5, wall=66782
2023-05-26 17:56:26 - progress_bar.py[line:272] - INFO: epoch 021:    962 / 1732 loss=2.154, loss_v1=0, loss_v2=0, nll_loss=0.929, ntokens=1071.4, nsentences=32, sample_size=1071.4, sample_size_v1=0, sample_size_v2=0, ppl=1.9, wps=570, ups=0.53, wpb=1071.4, bsz=32, num_updates=35540, lr=1.00854e-05, gnorm=16.622, clip=100, loss_scale=32, train_wall=19, gb_free=11.8, wall=66801
2023-05-26 17:56:45 - progress_bar.py[line:272] - INFO: epoch 021:    972 / 1732 loss=2.154, loss_v1=0, loss_v2=0, nll_loss=0.928, ntokens=1038.3, nsentences=32, sample_size=1038.3, sample_size_v1=0, sample_size_v2=0, ppl=1.9, wps=551.8, ups=0.53, wpb=1038.3, bsz=32, num_updates=35550, lr=1.00792e-05, gnorm=17.127, clip=100, loss_scale=32, train_wall=19, gb_free=10.7, wall=66820
2023-05-26 17:57:04 - progress_bar.py[line:272] - INFO: epoch 021:    982 / 1732 loss=2.135, loss_v1=0, loss_v2=0, nll_loss=0.907, ntokens=1035.4, nsentences=32, sample_size=1035.4, sample_size_v1=0, sample_size_v2=0, ppl=1.88, wps=548.8, ups=0.53, wpb=1035.4, bsz=32, num_updates=35560, lr=1.00731e-05, gnorm=16.155, clip=100, loss_scale=32, train_wall=19, gb_free=11.3, wall=66838
2023-05-26 17:57:23 - progress_bar.py[line:272] - INFO: epoch 021:    992 / 1732 loss=2.164, loss_v1=0, loss_v2=0, nll_loss=0.939, ntokens=1026.6, nsentences=32, sample_size=1026.6, sample_size_v1=0, sample_size_v2=0, ppl=1.92, wps=540, ups=0.53, wpb=1026.6, bsz=32, num_updates=35570, lr=1.00669e-05, gnorm=18.153, clip=100, loss_scale=32, train_wall=19, gb_free=11.4, wall=66857
2023-05-26 17:57:41 - progress_bar.py[line:272] - INFO: epoch 021:   1002 / 1732 loss=2.134, loss_v1=0, loss_v2=0, nll_loss=0.905, ntokens=1023.8, nsentences=32, sample_size=1023.8, sample_size_v1=0, sample_size_v2=0, ppl=1.87, wps=547.9, ups=0.54, wpb=1023.8, bsz=32, num_updates=35580, lr=1.00608e-05, gnorm=19.401, clip=100, loss_scale=32, train_wall=19, gb_free=11, wall=66876
2023-05-26 17:58:00 - progress_bar.py[line:272] - INFO: epoch 021:   1012 / 1732 loss=2.148, loss_v1=0, loss_v2=0, nll_loss=0.92, ntokens=987.2, nsentences=32, sample_size=987.2, sample_size_v1=0, sample_size_v2=0, ppl=1.89, wps=529.6, ups=0.54, wpb=987.2, bsz=32, num_updates=35590, lr=1.00547e-05, gnorm=17.313, clip=100, loss_scale=32, train_wall=19, gb_free=11.3, wall=66895
2023-05-26 17:58:19 - progress_bar.py[line:272] - INFO: epoch 021:   1022 / 1732 loss=2.132, loss_v1=0, loss_v2=0, nll_loss=0.904, ntokens=1063.7, nsentences=32, sample_size=1063.7, sample_size_v1=0, sample_size_v2=0, ppl=1.87, wps=566.5, ups=0.53, wpb=1063.7, bsz=32, num_updates=35600, lr=1.00485e-05, gnorm=16.539, clip=100, loss_scale=32, train_wall=19, gb_free=10.7, wall=66914
2023-05-26 17:58:38 - progress_bar.py[line:272] - INFO: epoch 021:   1032 / 1732 loss=2.143, loss_v1=0, loss_v2=0, nll_loss=0.915, ntokens=1117.6, nsentences=32, sample_size=1117.6, sample_size_v1=0, sample_size_v2=0, ppl=1.89, wps=588.8, ups=0.53, wpb=1117.6, bsz=32, num_updates=35610, lr=1.00424e-05, gnorm=15.917, clip=100, loss_scale=32, train_wall=19, gb_free=11.5, wall=66933
2023-05-26 17:58:57 - progress_bar.py[line:272] - INFO: epoch 021:   1042 / 1732 loss=2.148, loss_v1=0, loss_v2=0, nll_loss=0.921, ntokens=1067.2, nsentences=32, sample_size=1067.2, sample_size_v1=0, sample_size_v2=0, ppl=1.89, wps=565.4, ups=0.53, wpb=1067.2, bsz=32, num_updates=35620, lr=1.00362e-05, gnorm=16.928, clip=100, loss_scale=32, train_wall=19, gb_free=10.8, wall=66951
2023-05-26 17:59:15 - progress_bar.py[line:272] - INFO: epoch 021:   1052 / 1732 loss=2.157, loss_v1=0, loss_v2=0, nll_loss=0.932, ntokens=1041, nsentences=32, sample_size=1041, sample_size_v1=0, sample_size_v2=0, ppl=1.91, wps=557.9, ups=0.54, wpb=1041, bsz=32, num_updates=35630, lr=1.00301e-05, gnorm=19.074, clip=100, loss_scale=32, train_wall=19, gb_free=11.2, wall=66970
2023-05-26 17:59:34 - progress_bar.py[line:272] - INFO: epoch 021:   1062 / 1732 loss=2.134, loss_v1=0, loss_v2=0, nll_loss=0.905, ntokens=1046.1, nsentences=32, sample_size=1046.1, sample_size_v1=0, sample_size_v2=0, ppl=1.87, wps=557.5, ups=0.53, wpb=1046.1, bsz=32, num_updates=35640, lr=1.0024e-05, gnorm=17.649, clip=100, loss_scale=32, train_wall=19, gb_free=11.1, wall=66989
2023-05-26 17:59:53 - progress_bar.py[line:272] - INFO: epoch 021:   1072 / 1732 loss=2.134, loss_v1=0, loss_v2=0, nll_loss=0.906, ntokens=994.4, nsentences=32, sample_size=994.4, sample_size_v1=0, sample_size_v2=0, ppl=1.87, wps=529.9, ups=0.53, wpb=994.4, bsz=32, num_updates=35650, lr=1.00178e-05, gnorm=18.372, clip=100, loss_scale=32, train_wall=19, gb_free=11.5, wall=67008
2023-05-26 18:00:12 - progress_bar.py[line:272] - INFO: epoch 021:   1082 / 1732 loss=2.162, loss_v1=0, loss_v2=0, nll_loss=0.937, ntokens=1041.7, nsentences=32, sample_size=1041.7, sample_size_v1=0, sample_size_v2=0, ppl=1.91, wps=550.8, ups=0.53, wpb=1041.7, bsz=32, num_updates=35660, lr=1.00117e-05, gnorm=19.601, clip=100, loss_scale=32, train_wall=19, gb_free=11.2, wall=67027
2023-05-26 18:00:31 - progress_bar.py[line:272] - INFO: epoch 021:   1092 / 1732 loss=2.142, loss_v1=0, loss_v2=0, nll_loss=0.916, ntokens=1060.8, nsentences=32, sample_size=1060.8, sample_size_v1=0, sample_size_v2=0, ppl=1.89, wps=561.9, ups=0.53, wpb=1060.8, bsz=32, num_updates=35670, lr=1.00055e-05, gnorm=17.857, clip=100, loss_scale=32, train_wall=19, gb_free=11.6, wall=67045
2023-05-26 18:00:50 - progress_bar.py[line:272] - INFO: epoch 021:   1102 / 1732 loss=2.151, loss_v1=0, loss_v2=0, nll_loss=0.925, ntokens=1049.1, nsentences=32, sample_size=1049.1, sample_size_v1=0, sample_size_v2=0, ppl=1.9, wps=558.3, ups=0.53, wpb=1049.1, bsz=32, num_updates=35680, lr=9.99939e-06, gnorm=17.217, clip=100, loss_scale=32, train_wall=19, gb_free=10.5, wall=67064
2023-05-26 18:01:08 - progress_bar.py[line:272] - INFO: epoch 021:   1112 / 1732 loss=2.135, loss_v1=0, loss_v2=0, nll_loss=0.906, ntokens=1025.7, nsentences=32, sample_size=1025.7, sample_size_v1=0, sample_size_v2=0, ppl=1.87, wps=545, ups=0.53, wpb=1025.7, bsz=32, num_updates=35690, lr=9.99324e-06, gnorm=18.541, clip=100, loss_scale=32, train_wall=19, gb_free=11.3, wall=67083
2023-05-26 18:01:27 - progress_bar.py[line:272] - INFO: epoch 021:   1122 / 1732 loss=2.131, loss_v1=0, loss_v2=0, nll_loss=0.9, ntokens=976.1, nsentences=32, sample_size=976.1, sample_size_v1=0, sample_size_v2=0, ppl=1.87, wps=519.1, ups=0.53, wpb=976.1, bsz=32, num_updates=35700, lr=9.9871e-06, gnorm=19.816, clip=100, loss_scale=32, train_wall=19, gb_free=11.3, wall=67102
2023-05-26 18:01:46 - progress_bar.py[line:272] - INFO: epoch 021:   1132 / 1732 loss=2.142, loss_v1=0, loss_v2=0, nll_loss=0.915, ntokens=969.4, nsentences=32, sample_size=969.4, sample_size_v1=0, sample_size_v2=0, ppl=1.89, wps=515.5, ups=0.53, wpb=969.4, bsz=32, num_updates=35710, lr=9.98096e-06, gnorm=19.568, clip=100, loss_scale=32, train_wall=19, gb_free=11.7, wall=67121
2023-05-26 18:02:05 - progress_bar.py[line:272] - INFO: epoch 021:   1142 / 1732 loss=2.135, loss_v1=0, loss_v2=0, nll_loss=0.906, ntokens=1032.5, nsentences=32, sample_size=1032.5, sample_size_v1=0, sample_size_v2=0, ppl=1.87, wps=548.8, ups=0.53, wpb=1032.5, bsz=32, num_updates=35720, lr=9.97482e-06, gnorm=18.564, clip=100, loss_scale=32, train_wall=19, gb_free=11.1, wall=67139
2023-05-26 18:02:24 - progress_bar.py[line:272] - INFO: epoch 021:   1152 / 1732 loss=2.116, loss_v1=0, loss_v2=0, nll_loss=0.886, ntokens=1026.9, nsentences=32, sample_size=1026.9, sample_size_v1=0, sample_size_v2=0, ppl=1.85, wps=548.6, ups=0.53, wpb=1026.9, bsz=32, num_updates=35730, lr=9.96868e-06, gnorm=16.558, clip=100, loss_scale=32, train_wall=19, gb_free=11.4, wall=67158
2023-05-26 18:02:42 - progress_bar.py[line:272] - INFO: epoch 021:   1162 / 1732 loss=2.113, loss_v1=0, loss_v2=0, nll_loss=0.883, ntokens=1008.4, nsentences=32, sample_size=1008.4, sample_size_v1=0, sample_size_v2=0, ppl=1.84, wps=535.8, ups=0.53, wpb=1008.4, bsz=32, num_updates=35740, lr=9.96253e-06, gnorm=18.126, clip=100, loss_scale=32, train_wall=19, gb_free=11.3, wall=67177
2023-05-26 18:03:01 - progress_bar.py[line:272] - INFO: epoch 021:   1172 / 1732 loss=2.132, loss_v1=0, loss_v2=0, nll_loss=0.904, ntokens=1048.6, nsentences=32, sample_size=1048.6, sample_size_v1=0, sample_size_v2=0, ppl=1.87, wps=556.7, ups=0.53, wpb=1048.6, bsz=32, num_updates=35750, lr=9.95639e-06, gnorm=17.472, clip=100, loss_scale=32, train_wall=19, gb_free=10.8, wall=67196
2023-05-26 18:03:20 - progress_bar.py[line:272] - INFO: epoch 021:   1182 / 1732 loss=2.106, loss_v1=0, loss_v2=0, nll_loss=0.874, ntokens=1018.1, nsentences=32, sample_size=1018.1, sample_size_v1=0, sample_size_v2=0, ppl=1.83, wps=544.5, ups=0.53, wpb=1018.1, bsz=32, num_updates=35760, lr=9.95025e-06, gnorm=18.388, clip=100, loss_scale=32, train_wall=19, gb_free=11.4, wall=67215
2023-05-26 18:03:39 - progress_bar.py[line:272] - INFO: epoch 021:   1192 / 1732 loss=2.143, loss_v1=0, loss_v2=0, nll_loss=0.917, ntokens=1011.4, nsentences=32, sample_size=1011.4, sample_size_v1=0, sample_size_v2=0, ppl=1.89, wps=539.4, ups=0.53, wpb=1011.4, bsz=32, num_updates=35770, lr=9.94411e-06, gnorm=17.736, clip=100, loss_scale=32, train_wall=19, gb_free=11.4, wall=67233
2023-05-26 18:03:58 - progress_bar.py[line:272] - INFO: epoch 021:   1202 / 1732 loss=2.102, loss_v1=0, loss_v2=0, nll_loss=0.869, ntokens=1128.3, nsentences=32, sample_size=1128.3, sample_size_v1=0, sample_size_v2=0, ppl=1.83, wps=597.9, ups=0.53, wpb=1128.3, bsz=32, num_updates=35780, lr=9.93796e-06, gnorm=16.132, clip=100, loss_scale=32, train_wall=19, gb_free=11.1, wall=67252
2023-05-26 18:04:16 - progress_bar.py[line:272] - INFO: epoch 021:   1212 / 1732 loss=2.124, loss_v1=0, loss_v2=0, nll_loss=0.894, ntokens=1031.6, nsentences=32, sample_size=1031.6, sample_size_v1=0, sample_size_v2=0, ppl=1.86, wps=545.5, ups=0.53, wpb=1031.6, bsz=32, num_updates=35790, lr=9.93182e-06, gnorm=17.483, clip=100, loss_scale=32, train_wall=19, gb_free=10.9, wall=67271
2023-05-26 18:04:35 - progress_bar.py[line:272] - INFO: epoch 021:   1222 / 1732 loss=2.157, loss_v1=0, loss_v2=0, nll_loss=0.933, ntokens=1024, nsentences=32, sample_size=1024, sample_size_v1=0, sample_size_v2=0, ppl=1.91, wps=545.8, ups=0.53, wpb=1024, bsz=32, num_updates=35800, lr=9.92568e-06, gnorm=17.725, clip=100, loss_scale=32, train_wall=19, gb_free=10.8, wall=67290
2023-05-26 18:04:54 - progress_bar.py[line:272] - INFO: epoch 021:   1232 / 1732 loss=2.114, loss_v1=0, loss_v2=0, nll_loss=0.884, ntokens=1035.1, nsentences=32, sample_size=1035.1, sample_size_v1=0, sample_size_v2=0, ppl=1.85, wps=551.9, ups=0.53, wpb=1035.1, bsz=32, num_updates=35810, lr=9.91954e-06, gnorm=17.232, clip=100, loss_scale=32, train_wall=19, gb_free=11.4, wall=67309
2023-05-26 18:05:13 - progress_bar.py[line:272] - INFO: epoch 021:   1242 / 1732 loss=2.1, loss_v1=0, loss_v2=0, nll_loss=0.868, ntokens=1078.3, nsentences=32, sample_size=1078.3, sample_size_v1=0, sample_size_v2=0, ppl=1.83, wps=570.7, ups=0.53, wpb=1078.3, bsz=32, num_updates=35820, lr=9.9134e-06, gnorm=17.955, clip=100, loss_scale=32, train_wall=19, gb_free=11.4, wall=67328
2023-05-26 18:05:32 - progress_bar.py[line:272] - INFO: epoch 021:   1252 / 1732 loss=2.106, loss_v1=0, loss_v2=0, nll_loss=0.875, ntokens=1106.3, nsentences=32, sample_size=1106.3, sample_size_v1=0, sample_size_v2=0, ppl=1.83, wps=585.6, ups=0.53, wpb=1106.3, bsz=32, num_updates=35830, lr=9.90725e-06, gnorm=16.597, clip=100, loss_scale=32, train_wall=19, gb_free=10.9, wall=67346
2023-05-26 18:05:51 - progress_bar.py[line:272] - INFO: epoch 021:   1262 / 1732 loss=2.133, loss_v1=0, loss_v2=0, nll_loss=0.906, ntokens=1064, nsentences=32, sample_size=1064, sample_size_v1=0, sample_size_v2=0, ppl=1.87, wps=564.9, ups=0.53, wpb=1064, bsz=32, num_updates=35840, lr=9.90111e-06, gnorm=17.855, clip=100, loss_scale=32, train_wall=19, gb_free=10.9, wall=67365
2023-05-26 18:06:09 - progress_bar.py[line:272] - INFO: epoch 021:   1272 / 1732 loss=2.13, loss_v1=0, loss_v2=0, nll_loss=0.903, ntokens=1010.3, nsentences=32, sample_size=1010.3, sample_size_v1=0, sample_size_v2=0, ppl=1.87, wps=538.9, ups=0.53, wpb=1010.3, bsz=32, num_updates=35850, lr=9.89497e-06, gnorm=17.529, clip=100, loss_scale=32, train_wall=19, gb_free=10.9, wall=67384
2023-05-26 18:06:28 - progress_bar.py[line:272] - INFO: epoch 021:   1282 / 1732 loss=2.103, loss_v1=0, loss_v2=0, nll_loss=0.871, ntokens=1073.6, nsentences=32, sample_size=1073.6, sample_size_v1=0, sample_size_v2=0, ppl=1.83, wps=566.3, ups=0.53, wpb=1073.6, bsz=32, num_updates=35860, lr=9.88883e-06, gnorm=16.652, clip=100, loss_scale=32, train_wall=19, gb_free=10.4, wall=67403
2023-05-26 18:06:47 - progress_bar.py[line:272] - INFO: epoch 021:   1292 / 1732 loss=2.108, loss_v1=0, loss_v2=0, nll_loss=0.876, ntokens=1095.2, nsentences=32, sample_size=1095.2, sample_size_v1=0, sample_size_v2=0, ppl=1.84, wps=579.9, ups=0.53, wpb=1095.2, bsz=32, num_updates=35870, lr=9.88269e-06, gnorm=16.712, clip=100, loss_scale=32, train_wall=19, gb_free=10.7, wall=67422
2023-05-26 18:07:06 - progress_bar.py[line:272] - INFO: epoch 021:   1302 / 1732 loss=2.13, loss_v1=0, loss_v2=0, nll_loss=0.902, ntokens=1099.5, nsentences=32, sample_size=1099.5, sample_size_v1=0, sample_size_v2=0, ppl=1.87, wps=582.2, ups=0.53, wpb=1099.5, bsz=32, num_updates=35880, lr=9.87654e-06, gnorm=15.669, clip=100, loss_scale=32, train_wall=19, gb_free=10.4, wall=67441
2023-05-26 18:07:25 - progress_bar.py[line:272] - INFO: epoch 021:   1312 / 1732 loss=2.164, loss_v1=0, loss_v2=0, nll_loss=0.94, ntokens=1055.4, nsentences=32, sample_size=1055.4, sample_size_v1=0, sample_size_v2=0, ppl=1.92, wps=553.2, ups=0.52, wpb=1055.4, bsz=32, num_updates=35890, lr=9.8704e-06, gnorm=17.054, clip=100, loss_scale=32, train_wall=19, gb_free=11.4, wall=67460
2023-05-26 18:07:44 - progress_bar.py[line:272] - INFO: epoch 021:   1322 / 1732 loss=2.12, loss_v1=0, loss_v2=0, nll_loss=0.892, ntokens=1120.6, nsentences=32, sample_size=1120.6, sample_size_v1=0, sample_size_v2=0, ppl=1.86, wps=590.8, ups=0.53, wpb=1120.6, bsz=32, num_updates=35900, lr=9.86426e-06, gnorm=15.826, clip=100, loss_scale=32, train_wall=19, gb_free=10.6, wall=67479
2023-05-26 18:08:03 - progress_bar.py[line:272] - INFO: epoch 021:   1332 / 1732 loss=2.094, loss_v1=0, loss_v2=0, nll_loss=0.861, ntokens=1081, nsentences=32, sample_size=1081, sample_size_v1=0, sample_size_v2=0, ppl=1.82, wps=573.3, ups=0.53, wpb=1081, bsz=32, num_updates=35910, lr=9.85812e-06, gnorm=16.566, clip=100, loss_scale=32, train_wall=19, gb_free=11.1, wall=67498
2023-05-26 18:08:22 - progress_bar.py[line:272] - INFO: epoch 021:   1342 / 1732 loss=2.125, loss_v1=0, loss_v2=0, nll_loss=0.895, ntokens=1183.5, nsentences=32, sample_size=1183.5, sample_size_v1=0, sample_size_v2=0, ppl=1.86, wps=623.5, ups=0.53, wpb=1183.5, bsz=32, num_updates=35920, lr=9.85197e-06, gnorm=16.935, clip=100, loss_scale=32, train_wall=19, gb_free=10.4, wall=67517
2023-05-26 18:08:41 - progress_bar.py[line:272] - INFO: epoch 021:   1352 / 1732 loss=2.118, loss_v1=0, loss_v2=0, nll_loss=0.887, ntokens=1129.4, nsentences=32, sample_size=1129.4, sample_size_v1=0, sample_size_v2=0, ppl=1.85, wps=595.9, ups=0.53, wpb=1129.4, bsz=32, num_updates=35930, lr=9.84583e-06, gnorm=16.379, clip=100, loss_scale=64, train_wall=19, gb_free=11, wall=67536
2023-05-26 18:08:47 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2023-05-26 18:09:02 - progress_bar.py[line:272] - INFO: epoch 021:   1363 / 1732 loss=2.102, loss_v1=0, loss_v2=0, nll_loss=0.869, ntokens=1073.3, nsentences=32, sample_size=1073.3, sample_size_v1=0, sample_size_v2=0, ppl=1.83, wps=517.1, ups=0.48, wpb=1073.3, bsz=32, num_updates=35940, lr=9.83969e-06, gnorm=16.576, clip=100, loss_scale=32, train_wall=21, gb_free=11.8, wall=67556
2023-05-26 18:09:21 - progress_bar.py[line:272] - INFO: epoch 021:   1373 / 1732 loss=2.139, loss_v1=0, loss_v2=0, nll_loss=0.912, ntokens=1114.2, nsentences=32, sample_size=1114.2, sample_size_v1=0, sample_size_v2=0, ppl=1.88, wps=592.1, ups=0.53, wpb=1114.2, bsz=32, num_updates=35950, lr=9.83355e-06, gnorm=16.523, clip=100, loss_scale=32, train_wall=19, gb_free=11.3, wall=67575
2023-05-26 18:09:26 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2023-05-26 18:09:41 - progress_bar.py[line:272] - INFO: epoch 021:   1384 / 1732 loss=2.131, loss_v1=0, loss_v2=0, nll_loss=0.901, ntokens=1113, nsentences=32, sample_size=1113, sample_size_v1=0, sample_size_v2=0, ppl=1.87, wps=537.5, ups=0.48, wpb=1113, bsz=32, num_updates=35960, lr=9.82741e-06, gnorm=17.323, clip=100, loss_scale=16, train_wall=21, gb_free=10.8, wall=67596
2023-05-26 18:10:00 - progress_bar.py[line:272] - INFO: epoch 021:   1394 / 1732 loss=2.128, loss_v1=0, loss_v2=0, nll_loss=0.897, ntokens=1039.3, nsentences=32, sample_size=1039.3, sample_size_v1=0, sample_size_v2=0, ppl=1.86, wps=554.1, ups=0.53, wpb=1039.3, bsz=32, num_updates=35970, lr=9.82126e-06, gnorm=16.649, clip=100, loss_scale=16, train_wall=19, gb_free=10.6, wall=67615
2023-05-26 18:10:19 - progress_bar.py[line:272] - INFO: epoch 021:   1404 / 1732 loss=2.124, loss_v1=0, loss_v2=0, nll_loss=0.896, ntokens=1161.9, nsentences=32, sample_size=1161.9, sample_size_v1=0, sample_size_v2=0, ppl=1.86, wps=613.7, ups=0.53, wpb=1161.9, bsz=32, num_updates=35980, lr=9.81512e-06, gnorm=16.516, clip=100, loss_scale=16, train_wall=19, gb_free=10.2, wall=67634
2023-05-26 18:10:38 - progress_bar.py[line:272] - INFO: epoch 021:   1414 / 1732 loss=2.167, loss_v1=0, loss_v2=0, nll_loss=0.942, ntokens=1276, nsentences=32, sample_size=1276, sample_size_v1=0, sample_size_v2=0, ppl=1.92, wps=671.6, ups=0.53, wpb=1276, bsz=32, num_updates=35990, lr=9.80898e-06, gnorm=16.562, clip=100, loss_scale=16, train_wall=19, gb_free=10.6, wall=67653
2023-05-26 18:10:57 - progress_bar.py[line:272] - INFO: epoch 021:   1424 / 1732 loss=2.13, loss_v1=0, loss_v2=0, nll_loss=0.901, ntokens=1261.9, nsentences=32, sample_size=1261.9, sample_size_v1=0, sample_size_v2=0, ppl=1.87, wps=658.2, ups=0.52, wpb=1261.9, bsz=32, num_updates=36000, lr=9.80284e-06, gnorm=14.804, clip=100, loss_scale=16, train_wall=19, gb_free=10.6, wall=67672
2023-05-26 18:11:16 - progress_bar.py[line:272] - INFO: epoch 021:   1434 / 1732 loss=2.128, loss_v1=0, loss_v2=0, nll_loss=0.9, ntokens=1196.2, nsentences=32, sample_size=1196.2, sample_size_v1=0, sample_size_v2=0, ppl=1.87, wps=633.4, ups=0.53, wpb=1196.2, bsz=32, num_updates=36010, lr=9.7967e-06, gnorm=16.668, clip=100, loss_scale=16, train_wall=19, gb_free=11.1, wall=67691
2023-05-26 18:11:35 - progress_bar.py[line:272] - INFO: epoch 021:   1444 / 1732 loss=2.125, loss_v1=0, loss_v2=0, nll_loss=0.896, ntokens=1129.1, nsentences=32, sample_size=1129.1, sample_size_v1=0, sample_size_v2=0, ppl=1.86, wps=596.3, ups=0.53, wpb=1129.1, bsz=32, num_updates=36020, lr=9.79055e-06, gnorm=15.632, clip=100, loss_scale=16, train_wall=19, gb_free=10.6, wall=67710
2023-05-26 18:11:54 - progress_bar.py[line:272] - INFO: epoch 021:   1454 / 1732 loss=2.139, loss_v1=0, loss_v2=0, nll_loss=0.911, ntokens=1122, nsentences=32, sample_size=1122, sample_size_v1=0, sample_size_v2=0, ppl=1.88, wps=595.5, ups=0.53, wpb=1122, bsz=32, num_updates=36030, lr=9.78441e-06, gnorm=17.142, clip=100, loss_scale=16, train_wall=19, gb_free=10.8, wall=67728
2023-05-26 18:12:13 - progress_bar.py[line:272] - INFO: epoch 021:   1464 / 1732 loss=2.118, loss_v1=0, loss_v2=0, nll_loss=0.888, ntokens=1182.3, nsentences=32, sample_size=1182.3, sample_size_v1=0, sample_size_v2=0, ppl=1.85, wps=621.4, ups=0.53, wpb=1182.3, bsz=32, num_updates=36040, lr=9.77827e-06, gnorm=18.589, clip=100, loss_scale=16, train_wall=19, gb_free=11.2, wall=67748
2023-05-26 18:12:32 - progress_bar.py[line:272] - INFO: epoch 021:   1474 / 1732 loss=2.121, loss_v1=0, loss_v2=0, nll_loss=0.892, ntokens=1095.3, nsentences=32, sample_size=1095.3, sample_size_v1=0, sample_size_v2=0, ppl=1.86, wps=581.4, ups=0.53, wpb=1095.3, bsz=32, num_updates=36050, lr=9.77213e-06, gnorm=17.829, clip=100, loss_scale=16, train_wall=19, gb_free=11.3, wall=67766
2023-05-26 18:12:51 - progress_bar.py[line:272] - INFO: epoch 021:   1484 / 1732 loss=2.151, loss_v1=0, loss_v2=0, nll_loss=0.925, ntokens=1096.5, nsentences=32, sample_size=1096.5, sample_size_v1=0, sample_size_v2=0, ppl=1.9, wps=582.2, ups=0.53, wpb=1096.5, bsz=32, num_updates=36060, lr=9.76598e-06, gnorm=16.604, clip=100, loss_scale=16, train_wall=19, gb_free=10.6, wall=67785
2023-05-26 18:13:09 - progress_bar.py[line:272] - INFO: epoch 021:   1494 / 1732 loss=2.118, loss_v1=0, loss_v2=0, nll_loss=0.888, ntokens=1106.4, nsentences=32, sample_size=1106.4, sample_size_v1=0, sample_size_v2=0, ppl=1.85, wps=584.6, ups=0.53, wpb=1106.4, bsz=32, num_updates=36070, lr=9.75984e-06, gnorm=15.756, clip=100, loss_scale=16, train_wall=19, gb_free=11, wall=67804
2023-05-26 18:13:28 - progress_bar.py[line:272] - INFO: epoch 021:   1504 / 1732 loss=2.097, loss_v1=0, loss_v2=0, nll_loss=0.865, ntokens=1153.1, nsentences=32, sample_size=1153.1, sample_size_v1=0, sample_size_v2=0, ppl=1.82, wps=610.4, ups=0.53, wpb=1153.1, bsz=32, num_updates=36080, lr=9.7537e-06, gnorm=15.827, clip=100, loss_scale=16, train_wall=19, gb_free=10.9, wall=67823
2023-05-26 18:13:47 - progress_bar.py[line:272] - INFO: epoch 021:   1514 / 1732 loss=2.135, loss_v1=0, loss_v2=0, nll_loss=0.907, ntokens=1041.2, nsentences=32, sample_size=1041.2, sample_size_v1=0, sample_size_v2=0, ppl=1.88, wps=555.9, ups=0.53, wpb=1041.2, bsz=32, num_updates=36090, lr=9.74756e-06, gnorm=19.081, clip=100, loss_scale=16, train_wall=19, gb_free=11.7, wall=67842
2023-05-26 18:14:06 - progress_bar.py[line:272] - INFO: epoch 021:   1524 / 1732 loss=2.169, loss_v1=0, loss_v2=0, nll_loss=0.945, ntokens=1034.8, nsentences=32, sample_size=1034.8, sample_size_v1=0, sample_size_v2=0, ppl=1.92, wps=551.5, ups=0.53, wpb=1034.8, bsz=32, num_updates=36100, lr=9.74142e-06, gnorm=18.755, clip=100, loss_scale=16, train_wall=19, gb_free=10.5, wall=67861
2023-05-26 18:14:25 - progress_bar.py[line:272] - INFO: epoch 021:   1534 / 1732 loss=2.149, loss_v1=0, loss_v2=0, nll_loss=0.922, ntokens=1092.4, nsentences=32, sample_size=1092.4, sample_size_v1=0, sample_size_v2=0, ppl=1.9, wps=576.1, ups=0.53, wpb=1092.4, bsz=32, num_updates=36110, lr=9.73527e-06, gnorm=18.957, clip=100, loss_scale=16, train_wall=19, gb_free=11, wall=67879
2023-05-26 18:14:44 - progress_bar.py[line:272] - INFO: epoch 021:   1544 / 1732 loss=2.115, loss_v1=0, loss_v2=0, nll_loss=0.884, ntokens=1091.8, nsentences=32, sample_size=1091.8, sample_size_v1=0, sample_size_v2=0, ppl=1.85, wps=578.1, ups=0.53, wpb=1091.8, bsz=32, num_updates=36120, lr=9.72913e-06, gnorm=16.791, clip=100, loss_scale=16, train_wall=19, gb_free=11.5, wall=67898
2023-05-26 18:15:03 - progress_bar.py[line:272] - INFO: epoch 021:   1554 / 1732 loss=2.101, loss_v1=0, loss_v2=0, nll_loss=0.87, ntokens=1040, nsentences=32, sample_size=1040, sample_size_v1=0, sample_size_v2=0, ppl=1.83, wps=551.9, ups=0.53, wpb=1040, bsz=32, num_updates=36130, lr=9.72299e-06, gnorm=16.878, clip=100, loss_scale=16, train_wall=19, gb_free=11.4, wall=67917
2023-05-26 18:15:21 - progress_bar.py[line:272] - INFO: epoch 021:   1564 / 1732 loss=2.128, loss_v1=0, loss_v2=0, nll_loss=0.9, ntokens=1120.2, nsentences=32, sample_size=1120.2, sample_size_v1=0, sample_size_v2=0, ppl=1.87, wps=593.8, ups=0.53, wpb=1120.2, bsz=32, num_updates=36140, lr=9.71685e-06, gnorm=18.053, clip=100, loss_scale=16, train_wall=19, gb_free=11.6, wall=67936
2023-05-26 18:15:40 - progress_bar.py[line:272] - INFO: epoch 021:   1574 / 1732 loss=2.147, loss_v1=0, loss_v2=0, nll_loss=0.92, ntokens=1055.9, nsentences=32, sample_size=1055.9, sample_size_v1=0, sample_size_v2=0, ppl=1.89, wps=558.7, ups=0.53, wpb=1055.9, bsz=32, num_updates=36150, lr=9.71071e-06, gnorm=18.631, clip=100, loss_scale=16, train_wall=19, gb_free=11.2, wall=67955
2023-05-26 18:15:59 - progress_bar.py[line:272] - INFO: epoch 021:   1584 / 1732 loss=2.137, loss_v1=0, loss_v2=0, nll_loss=0.91, ntokens=1026.8, nsentences=32, sample_size=1026.8, sample_size_v1=0, sample_size_v2=0, ppl=1.88, wps=545.9, ups=0.53, wpb=1026.8, bsz=32, num_updates=36160, lr=9.70456e-06, gnorm=17.228, clip=100, loss_scale=16, train_wall=19, gb_free=10.8, wall=67974
2023-05-26 18:16:18 - progress_bar.py[line:272] - INFO: epoch 021:   1594 / 1732 loss=2.105, loss_v1=0, loss_v2=0, nll_loss=0.873, ntokens=1068.7, nsentences=32, sample_size=1068.7, sample_size_v1=0, sample_size_v2=0, ppl=1.83, wps=566.1, ups=0.53, wpb=1068.7, bsz=32, num_updates=36170, lr=9.69842e-06, gnorm=16.755, clip=100, loss_scale=16, train_wall=19, gb_free=11.3, wall=67993
2023-05-26 18:16:37 - progress_bar.py[line:272] - INFO: epoch 021:   1604 / 1732 loss=2.111, loss_v1=0, loss_v2=0, nll_loss=0.881, ntokens=1089, nsentences=32, sample_size=1089, sample_size_v1=0, sample_size_v2=0, ppl=1.84, wps=576.4, ups=0.53, wpb=1089, bsz=32, num_updates=36180, lr=9.69228e-06, gnorm=17.045, clip=100, loss_scale=16, train_wall=19, gb_free=10.8, wall=68012
2023-05-26 18:16:56 - progress_bar.py[line:272] - INFO: epoch 021:   1614 / 1732 loss=2.095, loss_v1=0, loss_v2=0, nll_loss=0.862, ntokens=1186.1, nsentences=32, sample_size=1186.1, sample_size_v1=0, sample_size_v2=0, ppl=1.82, wps=621.2, ups=0.52, wpb=1186.1, bsz=32, num_updates=36190, lr=9.68614e-06, gnorm=16.906, clip=100, loss_scale=16, train_wall=19, gb_free=10.9, wall=68031
2023-05-26 18:17:15 - progress_bar.py[line:272] - INFO: epoch 021:   1624 / 1732 loss=2.128, loss_v1=0, loss_v2=0, nll_loss=0.898, ntokens=1074.1, nsentences=32, sample_size=1074.1, sample_size_v1=0, sample_size_v2=0, ppl=1.86, wps=568.5, ups=0.53, wpb=1074.1, bsz=32, num_updates=36200, lr=9.68e-06, gnorm=17.559, clip=100, loss_scale=16, train_wall=19, gb_free=11.6, wall=68050
2023-05-26 18:17:34 - progress_bar.py[line:272] - INFO: epoch 021:   1634 / 1732 loss=2.102, loss_v1=0, loss_v2=0, nll_loss=0.871, ntokens=1178.9, nsentences=32, sample_size=1178.9, sample_size_v1=0, sample_size_v2=0, ppl=1.83, wps=623.3, ups=0.53, wpb=1178.9, bsz=32, num_updates=36210, lr=9.67385e-06, gnorm=17.071, clip=100, loss_scale=16, train_wall=19, gb_free=11.5, wall=68068
2023-05-26 18:17:53 - progress_bar.py[line:272] - INFO: epoch 021:   1644 / 1732 loss=2.108, loss_v1=0, loss_v2=0, nll_loss=0.875, ntokens=1265.1, nsentences=32, sample_size=1265.1, sample_size_v1=0, sample_size_v2=0, ppl=1.83, wps=664.2, ups=0.53, wpb=1265.1, bsz=32, num_updates=36220, lr=9.66771e-06, gnorm=16.218, clip=100, loss_scale=16, train_wall=19, gb_free=10.9, wall=68088
2023-05-26 18:18:12 - progress_bar.py[line:272] - INFO: epoch 021:   1654 / 1732 loss=2.135, loss_v1=0, loss_v2=0, nll_loss=0.907, ntokens=974.9, nsentences=32, sample_size=974.9, sample_size_v1=0, sample_size_v2=0, ppl=1.87, wps=520.7, ups=0.53, wpb=974.9, bsz=32, num_updates=36230, lr=9.66157e-06, gnorm=17.309, clip=100, loss_scale=16, train_wall=19, gb_free=11.5, wall=68106
2023-05-26 18:18:30 - progress_bar.py[line:272] - INFO: epoch 021:   1664 / 1732 loss=2.14, loss_v1=0, loss_v2=0, nll_loss=0.913, ntokens=1041.8, nsentences=32, sample_size=1041.8, sample_size_v1=0, sample_size_v2=0, ppl=1.88, wps=552.6, ups=0.53, wpb=1041.8, bsz=32, num_updates=36240, lr=9.65543e-06, gnorm=19.034, clip=100, loss_scale=16, train_wall=19, gb_free=11.1, wall=68125
2023-05-26 18:18:49 - progress_bar.py[line:272] - INFO: epoch 021:   1674 / 1732 loss=2.102, loss_v1=0, loss_v2=0, nll_loss=0.87, ntokens=1052.3, nsentences=32, sample_size=1052.3, sample_size_v1=0, sample_size_v2=0, ppl=1.83, wps=561.9, ups=0.53, wpb=1052.3, bsz=32, num_updates=36250, lr=9.64928e-06, gnorm=19.26, clip=100, loss_scale=16, train_wall=19, gb_free=11.3, wall=68144
2023-05-26 18:19:08 - progress_bar.py[line:272] - INFO: epoch 021:   1684 / 1732 loss=2.083, loss_v1=0, loss_v2=0, nll_loss=0.848, ntokens=1169.1, nsentences=32, sample_size=1169.1, sample_size_v1=0, sample_size_v2=0, ppl=1.8, wps=613.6, ups=0.52, wpb=1169.1, bsz=32, num_updates=36260, lr=9.64314e-06, gnorm=15.152, clip=100, loss_scale=16, train_wall=19, gb_free=11.5, wall=68163
2023-05-26 18:19:28 - progress_bar.py[line:272] - INFO: epoch 021:   1694 / 1732 loss=2.116, loss_v1=0, loss_v2=0, nll_loss=0.885, ntokens=1257.3, nsentences=32, sample_size=1257.3, sample_size_v1=0, sample_size_v2=0, ppl=1.85, wps=652.9, ups=0.52, wpb=1257.3, bsz=32, num_updates=36270, lr=9.637e-06, gnorm=15.359, clip=100, loss_scale=16, train_wall=19, gb_free=10.1, wall=68182
2023-05-26 18:19:47 - progress_bar.py[line:272] - INFO: epoch 021:   1704 / 1732 loss=2.126, loss_v1=0, loss_v2=0, nll_loss=0.896, ntokens=1232.6, nsentences=32, sample_size=1232.6, sample_size_v1=0, sample_size_v2=0, ppl=1.86, wps=646.6, ups=0.52, wpb=1232.6, bsz=32, num_updates=36280, lr=9.63086e-06, gnorm=15.459, clip=100, loss_scale=16, train_wall=19, gb_free=11.3, wall=68201
2023-05-26 18:20:06 - progress_bar.py[line:272] - INFO: epoch 021:   1714 / 1732 loss=2.123, loss_v1=0, loss_v2=0, nll_loss=0.894, ntokens=1181.2, nsentences=32, sample_size=1181.2, sample_size_v1=0, sample_size_v2=0, ppl=1.86, wps=620, ups=0.52, wpb=1181.2, bsz=32, num_updates=36290, lr=9.62472e-06, gnorm=16.858, clip=100, loss_scale=16, train_wall=19, gb_free=11.2, wall=68220
2023-05-26 18:20:25 - progress_bar.py[line:272] - INFO: epoch 021:   1724 / 1732 loss=2.107, loss_v1=0, loss_v2=0, nll_loss=0.877, ntokens=1135.1, nsentences=32, sample_size=1135.1, sample_size_v1=0, sample_size_v2=0, ppl=1.84, wps=595.7, ups=0.52, wpb=1135.1, bsz=32, num_updates=36300, lr=9.61857e-06, gnorm=15.911, clip=100, loss_scale=16, train_wall=19, gb_free=11.7, wall=68239
2023-05-26 18:20:38 - train.py[line:332] - INFO: end of epoch 21 (average epoch stats below)
2023-05-26 18:20:38 - progress_bar.py[line:282] - INFO: epoch 021 | loss 2.129 | loss_v1 0 | loss_v2 0 | nll_loss 0.9 | ntokens 1051.4 | nsentences 31.986 | sample_size 1051.4 | sample_size_v1 0 | sample_size_v2 0 | ppl 1.87 | wps 558.9 | ups 0.53 | wpb 1051.4 | bsz 32 | num_updates 36308 | lr 9.61366e-06 | gnorm 16.994 | clip 100 | loss_scale 16 | train_wall 3245 | gb_free 11.7 | wall 68253
2023-05-26 18:20:38 - trainer.py[line:639] - INFO: loading train data for epoch 22
local datafile ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 0 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 0 finished initializing row_count and line_idx-to-offset mapping
file ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 0 row count 55400 total row count 55400
slice_id 0 seek offset 0
2023-05-26 18:20:40 - trainer.py[line:703] - INFO: begin training epoch 22
2023-05-26 18:20:40 - train.py[line:305] - INFO: Start iterating over samples
2023-05-26 18:20:44 - progress_bar.py[line:272] - INFO: epoch 022:      2 / 1732 loss=2.17, loss_v1=0, loss_v2=0, nll_loss=0.946, ntokens=1104.4, nsentences=29.6, sample_size=1104.4, sample_size_v1=0, sample_size_v2=0, ppl=1.93, wps=558.9, ups=0.51, wpb=1104.4, bsz=29.6, num_updates=36310, lr=9.61243e-06, gnorm=17.11, clip=100, loss_scale=16, train_wall=18, gb_free=10.9, wall=68259
2023-05-26 18:21:03 - progress_bar.py[line:272] - INFO: epoch 022:     12 / 1732 loss=2.1, loss_v1=0, loss_v2=0, nll_loss=0.867, ntokens=1057.9, nsentences=32, sample_size=1057.9, sample_size_v1=0, sample_size_v2=0, ppl=1.82, wps=558.4, ups=0.53, wpb=1057.9, bsz=32, num_updates=36320, lr=9.60629e-06, gnorm=21.496, clip=100, loss_scale=16, train_wall=19, gb_free=11.6, wall=68278
2023-05-26 18:21:22 - progress_bar.py[line:272] - INFO: epoch 022:     22 / 1732 loss=2.052, loss_v1=0, loss_v2=0, nll_loss=0.813, ntokens=1106.7, nsentences=32, sample_size=1106.7, sample_size_v1=0, sample_size_v2=0, ppl=1.76, wps=586.8, ups=0.53, wpb=1106.7, bsz=32, num_updates=36330, lr=9.60015e-06, gnorm=19.756, clip=100, loss_scale=16, train_wall=19, gb_free=11.4, wall=68297
2023-05-26 18:21:41 - progress_bar.py[line:272] - INFO: epoch 022:     32 / 1732 loss=2.056, loss_v1=0, loss_v2=0, nll_loss=0.818, ntokens=985.4, nsentences=32, sample_size=985.4, sample_size_v1=0, sample_size_v2=0, ppl=1.76, wps=522, ups=0.53, wpb=985.4, bsz=32, num_updates=36340, lr=9.59401e-06, gnorm=20.735, clip=100, loss_scale=16, train_wall=19, gb_free=10.5, wall=68316
2023-05-26 18:22:00 - progress_bar.py[line:272] - INFO: epoch 022:     42 / 1732 loss=1.959, loss_v1=0, loss_v2=0, nll_loss=0.709, ntokens=1168.8, nsentences=32, sample_size=1168.8, sample_size_v1=0, sample_size_v2=0, ppl=1.64, wps=615.1, ups=0.53, wpb=1168.8, bsz=32, num_updates=36350, lr=9.58786e-06, gnorm=16.662, clip=100, loss_scale=16, train_wall=19, gb_free=11.9, wall=68335
2023-05-26 18:22:19 - progress_bar.py[line:272] - INFO: epoch 022:     52 / 1732 loss=2.007, loss_v1=0, loss_v2=0, nll_loss=0.766, ntokens=1030.1, nsentences=32, sample_size=1030.1, sample_size_v1=0, sample_size_v2=0, ppl=1.7, wps=544.9, ups=0.53, wpb=1030.1, bsz=32, num_updates=36360, lr=9.58172e-06, gnorm=20.581, clip=100, loss_scale=16, train_wall=19, gb_free=11.7, wall=68354
2023-05-26 18:22:38 - progress_bar.py[line:272] - INFO: epoch 022:     62 / 1732 loss=1.858, loss_v1=0, loss_v2=0, nll_loss=0.598, ntokens=1192.6, nsentences=32, sample_size=1192.6, sample_size_v1=0, sample_size_v2=0, ppl=1.51, wps=628.5, ups=0.53, wpb=1192.6, bsz=32, num_updates=36370, lr=9.57558e-06, gnorm=15.544, clip=100, loss_scale=16, train_wall=19, gb_free=10.7, wall=68373
2023-05-26 18:22:58 - progress_bar.py[line:272] - INFO: epoch 022:     72 / 1732 loss=1.926, loss_v1=0, loss_v2=0, nll_loss=0.675, ntokens=1389.6, nsentences=32, sample_size=1389.6, sample_size_v1=0, sample_size_v2=0, ppl=1.6, wps=711.4, ups=0.51, wpb=1389.6, bsz=32, num_updates=36380, lr=9.56944e-06, gnorm=11.177, clip=100, loss_scale=16, train_wall=19, gb_free=10.7, wall=68392
2023-05-26 18:23:17 - progress_bar.py[line:272] - INFO: epoch 022:     82 / 1732 loss=1.953, loss_v1=0, loss_v2=0, nll_loss=0.705, ntokens=1199, nsentences=32, sample_size=1199, sample_size_v1=0, sample_size_v2=0, ppl=1.63, wps=622.5, ups=0.52, wpb=1199, bsz=32, num_updates=36390, lr=9.56329e-06, gnorm=13.709, clip=100, loss_scale=16, train_wall=19, gb_free=10.8, wall=68412
2023-05-26 18:23:36 - progress_bar.py[line:272] - INFO: epoch 022:     92 / 1732 loss=1.961, loss_v1=0, loss_v2=0, nll_loss=0.711, ntokens=1081.9, nsentences=32, sample_size=1081.9, sample_size_v1=0, sample_size_v2=0, ppl=1.64, wps=566.6, ups=0.52, wpb=1081.9, bsz=32, num_updates=36400, lr=9.55715e-06, gnorm=16.041, clip=100, loss_scale=16, train_wall=19, gb_free=11.1, wall=68431
2023-05-26 18:23:55 - progress_bar.py[line:272] - INFO: epoch 022:    102 / 1732 loss=2.018, loss_v1=0, loss_v2=0, nll_loss=0.776, ntokens=1017.7, nsentences=32, sample_size=1017.7, sample_size_v1=0, sample_size_v2=0, ppl=1.71, wps=541.1, ups=0.53, wpb=1017.7, bsz=32, num_updates=36410, lr=9.55101e-06, gnorm=18.773, clip=100, loss_scale=16, train_wall=19, gb_free=11, wall=68449
2023-05-26 18:24:14 - progress_bar.py[line:272] - INFO: epoch 022:    112 / 1732 loss=2.146, loss_v1=0, loss_v2=0, nll_loss=0.921, ntokens=1026.3, nsentences=32, sample_size=1026.3, sample_size_v1=0, sample_size_v2=0, ppl=1.89, wps=544, ups=0.53, wpb=1026.3, bsz=32, num_updates=36420, lr=9.54487e-06, gnorm=20.232, clip=100, loss_scale=16, train_wall=19, gb_free=10.2, wall=68468
2023-05-26 18:24:33 - progress_bar.py[line:272] - INFO: epoch 022:    122 / 1732 loss=2.124, loss_v1=0, loss_v2=0, nll_loss=0.895, ntokens=1103.7, nsentences=32, sample_size=1103.7, sample_size_v1=0, sample_size_v2=0, ppl=1.86, wps=576.1, ups=0.52, wpb=1103.7, bsz=32, num_updates=36430, lr=9.53873e-06, gnorm=19.053, clip=100, loss_scale=16, train_wall=19, gb_free=10.8, wall=68487
2023-05-26 18:24:52 - progress_bar.py[line:272] - INFO: epoch 022:    132 / 1732 loss=2.096, loss_v1=0, loss_v2=0, nll_loss=0.863, ntokens=1224.5, nsentences=32, sample_size=1224.5, sample_size_v1=0, sample_size_v2=0, ppl=1.82, wps=636.6, ups=0.52, wpb=1224.5, bsz=32, num_updates=36440, lr=9.53258e-06, gnorm=16.941, clip=100, loss_scale=16, train_wall=19, gb_free=10.7, wall=68507
2023-05-26 18:25:11 - progress_bar.py[line:272] - INFO: epoch 022:    142 / 1732 loss=2.071, loss_v1=0, loss_v2=0, nll_loss=0.834, ntokens=1223.2, nsentences=32, sample_size=1223.2, sample_size_v1=0, sample_size_v2=0, ppl=1.78, wps=636.6, ups=0.52, wpb=1223.2, bsz=32, num_updates=36450, lr=9.52644e-06, gnorm=17.279, clip=100, loss_scale=16, train_wall=19, gb_free=10.8, wall=68526
2023-05-26 18:25:30 - progress_bar.py[line:272] - INFO: epoch 022:    152 / 1732 loss=2.061, loss_v1=0, loss_v2=0, nll_loss=0.823, ntokens=1158.5, nsentences=32, sample_size=1158.5, sample_size_v1=0, sample_size_v2=0, ppl=1.77, wps=602.4, ups=0.52, wpb=1158.5, bsz=32, num_updates=36460, lr=9.5203e-06, gnorm=18.128, clip=100, loss_scale=16, train_wall=19, gb_free=10.7, wall=68545
2023-05-26 18:25:50 - progress_bar.py[line:272] - INFO: epoch 022:    162 / 1732 loss=2.081, loss_v1=0, loss_v2=0, nll_loss=0.847, ntokens=1101.3, nsentences=32, sample_size=1101.3, sample_size_v1=0, sample_size_v2=0, ppl=1.8, wps=578.1, ups=0.52, wpb=1101.3, bsz=32, num_updates=36470, lr=9.51416e-06, gnorm=19.425, clip=100, loss_scale=32, train_wall=19, gb_free=11, wall=68564
2023-05-26 18:26:08 - progress_bar.py[line:272] - INFO: epoch 022:    172 / 1732 loss=2.099, loss_v1=0, loss_v2=0, nll_loss=0.869, ntokens=937.9, nsentences=32, sample_size=937.9, sample_size_v1=0, sample_size_v2=0, ppl=1.83, wps=498.7, ups=0.53, wpb=937.9, bsz=32, num_updates=36480, lr=9.50802e-06, gnorm=21.048, clip=100, loss_scale=32, train_wall=19, gb_free=11.2, wall=68583
2023-05-26 18:26:27 - progress_bar.py[line:272] - INFO: epoch 022:    182 / 1732 loss=2.048, loss_v1=0, loss_v2=0, nll_loss=0.81, ntokens=1177.8, nsentences=32, sample_size=1177.8, sample_size_v1=0, sample_size_v2=0, ppl=1.75, wps=614.8, ups=0.52, wpb=1177.8, bsz=32, num_updates=36490, lr=9.50187e-06, gnorm=18.15, clip=100, loss_scale=32, train_wall=19, gb_free=10.6, wall=68602
2023-05-26 18:26:47 - progress_bar.py[line:272] - INFO: epoch 022:    192 / 1732 loss=2.046, loss_v1=0, loss_v2=0, nll_loss=0.808, ntokens=1116, nsentences=32, sample_size=1116, sample_size_v1=0, sample_size_v2=0, ppl=1.75, wps=585.7, ups=0.52, wpb=1116, bsz=32, num_updates=36500, lr=9.49573e-06, gnorm=17.706, clip=100, loss_scale=32, train_wall=19, gb_free=10.6, wall=68621
2023-05-26 18:27:05 - progress_bar.py[line:272] - INFO: epoch 022:    202 / 1732 loss=2.112, loss_v1=0, loss_v2=0, nll_loss=0.881, ntokens=1088.7, nsentences=32, sample_size=1088.7, sample_size_v1=0, sample_size_v2=0, ppl=1.84, wps=576.7, ups=0.53, wpb=1088.7, bsz=32, num_updates=36510, lr=9.48959e-06, gnorm=17.198, clip=100, loss_scale=32, train_wall=19, gb_free=10.7, wall=68640
2023-05-26 18:27:24 - progress_bar.py[line:272] - INFO: epoch 022:    212 / 1732 loss=2.13, loss_v1=0, loss_v2=0, nll_loss=0.903, ntokens=1014.1, nsentences=32, sample_size=1014.1, sample_size_v1=0, sample_size_v2=0, ppl=1.87, wps=542.7, ups=0.54, wpb=1014.1, bsz=32, num_updates=36520, lr=9.48345e-06, gnorm=17.014, clip=100, loss_scale=32, train_wall=19, gb_free=11, wall=68659
2023-05-26 18:27:43 - progress_bar.py[line:272] - INFO: epoch 022:    222 / 1732 loss=2.157, loss_v1=0, loss_v2=0, nll_loss=0.933, ntokens=1144.1, nsentences=32, sample_size=1144.1, sample_size_v1=0, sample_size_v2=0, ppl=1.91, wps=610.7, ups=0.53, wpb=1144.1, bsz=32, num_updates=36530, lr=9.4773e-06, gnorm=16.969, clip=100, loss_scale=32, train_wall=19, gb_free=10.8, wall=68678
2023-05-26 18:28:02 - progress_bar.py[line:272] - INFO: epoch 022:    232 / 1732 loss=2.147, loss_v1=0, loss_v2=0, nll_loss=0.921, ntokens=1097.8, nsentences=32, sample_size=1097.8, sample_size_v1=0, sample_size_v2=0, ppl=1.89, wps=586.5, ups=0.53, wpb=1097.8, bsz=32, num_updates=36540, lr=9.47116e-06, gnorm=16.695, clip=100, loss_scale=32, train_wall=19, gb_free=11.3, wall=68696
2023-05-26 18:28:20 - progress_bar.py[line:272] - INFO: epoch 022:    242 / 1732 loss=2.141, loss_v1=0, loss_v2=0, nll_loss=0.912, ntokens=1115.1, nsentences=32, sample_size=1115.1, sample_size_v1=0, sample_size_v2=0, ppl=1.88, wps=592.3, ups=0.53, wpb=1115.1, bsz=32, num_updates=36550, lr=9.46502e-06, gnorm=15.944, clip=100, loss_scale=32, train_wall=19, gb_free=10.8, wall=68715
2023-05-26 18:28:39 - progress_bar.py[line:272] - INFO: epoch 022:    252 / 1732 loss=2.159, loss_v1=0, loss_v2=0, nll_loss=0.933, ntokens=1167.7, nsentences=32, sample_size=1167.7, sample_size_v1=0, sample_size_v2=0, ppl=1.91, wps=619.2, ups=0.53, wpb=1167.7, bsz=32, num_updates=36560, lr=9.45888e-06, gnorm=16.38, clip=100, loss_scale=32, train_wall=19, gb_free=11.5, wall=68734
2023-05-26 18:28:58 - progress_bar.py[line:272] - INFO: epoch 022:    262 / 1732 loss=2.16, loss_v1=0, loss_v2=0, nll_loss=0.936, ntokens=1134.1, nsentences=32, sample_size=1134.1, sample_size_v1=0, sample_size_v2=0, ppl=1.91, wps=604.4, ups=0.53, wpb=1134.1, bsz=32, num_updates=36570, lr=9.45274e-06, gnorm=16.093, clip=100, loss_scale=32, train_wall=19, gb_free=11.3, wall=68753
2023-05-26 18:29:17 - progress_bar.py[line:272] - INFO: epoch 022:    272 / 1732 loss=2.126, loss_v1=0, loss_v2=0, nll_loss=0.897, ntokens=1139, nsentences=32, sample_size=1139, sample_size_v1=0, sample_size_v2=0, ppl=1.86, wps=606, ups=0.53, wpb=1139, bsz=32, num_updates=36580, lr=9.44659e-06, gnorm=17.921, clip=100, loss_scale=32, train_wall=19, gb_free=11.6, wall=68772
2023-05-26 18:29:36 - progress_bar.py[line:272] - INFO: epoch 022:    282 / 1732 loss=2.164, loss_v1=0, loss_v2=0, nll_loss=0.94, ntokens=1161.5, nsentences=32, sample_size=1161.5, sample_size_v1=0, sample_size_v2=0, ppl=1.92, wps=613.2, ups=0.53, wpb=1161.5, bsz=32, num_updates=36590, lr=9.44045e-06, gnorm=16.348, clip=100, loss_scale=32, train_wall=19, gb_free=10.7, wall=68790
2023-05-26 18:29:55 - progress_bar.py[line:272] - INFO: epoch 022:    292 / 1732 loss=2.123, loss_v1=0, loss_v2=0, nll_loss=0.893, ntokens=1114.9, nsentences=32, sample_size=1114.9, sample_size_v1=0, sample_size_v2=0, ppl=1.86, wps=592.2, ups=0.53, wpb=1114.9, bsz=32, num_updates=36600, lr=9.43431e-06, gnorm=17.149, clip=100, loss_scale=32, train_wall=19, gb_free=11.2, wall=68809
2023-05-26 18:30:13 - progress_bar.py[line:272] - INFO: epoch 022:    302 / 1732 loss=2.129, loss_v1=0, loss_v2=0, nll_loss=0.9, ntokens=1109.4, nsentences=32, sample_size=1109.4, sample_size_v1=0, sample_size_v2=0, ppl=1.87, wps=592, ups=0.53, wpb=1109.4, bsz=32, num_updates=36610, lr=9.42817e-06, gnorm=16.167, clip=100, loss_scale=32, train_wall=19, gb_free=11.5, wall=68828
2023-05-26 18:30:32 - progress_bar.py[line:272] - INFO: epoch 022:    312 / 1732 loss=2.139, loss_v1=0, loss_v2=0, nll_loss=0.912, ntokens=1061.9, nsentences=32, sample_size=1061.9, sample_size_v1=0, sample_size_v2=0, ppl=1.88, wps=566.6, ups=0.53, wpb=1061.9, bsz=32, num_updates=36620, lr=9.42203e-06, gnorm=17.83, clip=100, loss_scale=32, train_wall=19, gb_free=11.5, wall=68847
2023-05-26 18:30:51 - progress_bar.py[line:272] - INFO: epoch 022:    322 / 1732 loss=2.172, loss_v1=0, loss_v2=0, nll_loss=0.949, ntokens=1000.1, nsentences=32, sample_size=1000.1, sample_size_v1=0, sample_size_v2=0, ppl=1.93, wps=537.6, ups=0.54, wpb=1000.1, bsz=32, num_updates=36630, lr=9.41588e-06, gnorm=18.854, clip=100, loss_scale=32, train_wall=19, gb_free=11.3, wall=68865
2023-05-26 18:31:09 - progress_bar.py[line:272] - INFO: epoch 022:    332 / 1732 loss=2.169, loss_v1=0, loss_v2=0, nll_loss=0.946, ntokens=1031.9, nsentences=32, sample_size=1031.9, sample_size_v1=0, sample_size_v2=0, ppl=1.93, wps=551, ups=0.53, wpb=1031.9, bsz=32, num_updates=36640, lr=9.40974e-06, gnorm=19.054, clip=100, loss_scale=32, train_wall=19, gb_free=11.2, wall=68884
2023-05-26 18:31:28 - progress_bar.py[line:272] - INFO: epoch 022:    342 / 1732 loss=2.115, loss_v1=0, loss_v2=0, nll_loss=0.885, ntokens=926.6, nsentences=32, sample_size=926.6, sample_size_v1=0, sample_size_v2=0, ppl=1.85, wps=500.7, ups=0.54, wpb=926.6, bsz=32, num_updates=36650, lr=9.4036e-06, gnorm=17.298, clip=100, loss_scale=32, train_wall=18, gb_free=11.8, wall=68903
2023-05-26 18:31:46 - progress_bar.py[line:272] - INFO: epoch 022:    352 / 1732 loss=2.134, loss_v1=0, loss_v2=0, nll_loss=0.907, ntokens=952.9, nsentences=32, sample_size=952.9, sample_size_v1=0, sample_size_v2=0, ppl=1.88, wps=514, ups=0.54, wpb=952.9, bsz=32, num_updates=36660, lr=9.39746e-06, gnorm=19.417, clip=100, loss_scale=32, train_wall=19, gb_free=11.8, wall=68921
2023-05-26 18:32:05 - progress_bar.py[line:272] - INFO: epoch 022:    362 / 1732 loss=2.172, loss_v1=0, loss_v2=0, nll_loss=0.951, ntokens=940.7, nsentences=32, sample_size=940.7, sample_size_v1=0, sample_size_v2=0, ppl=1.93, wps=506.5, ups=0.54, wpb=940.7, bsz=32, num_updates=36670, lr=9.39132e-06, gnorm=20.978, clip=100, loss_scale=32, train_wall=19, gb_free=11.6, wall=68940
2023-05-26 18:32:24 - progress_bar.py[line:272] - INFO: epoch 022:    372 / 1732 loss=2.156, loss_v1=0, loss_v2=0, nll_loss=0.932, ntokens=975.5, nsentences=32, sample_size=975.5, sample_size_v1=0, sample_size_v2=0, ppl=1.91, wps=519.3, ups=0.53, wpb=975.5, bsz=32, num_updates=36680, lr=9.38517e-06, gnorm=19.14, clip=100, loss_scale=32, train_wall=19, gb_free=11.7, wall=68959
2023-05-26 18:32:42 - progress_bar.py[line:272] - INFO: epoch 022:    382 / 1732 loss=2.171, loss_v1=0, loss_v2=0, nll_loss=0.948, ntokens=1062, nsentences=32, sample_size=1062, sample_size_v1=0, sample_size_v2=0, ppl=1.93, wps=571.6, ups=0.54, wpb=1062, bsz=32, num_updates=36690, lr=9.37903e-06, gnorm=18.782, clip=100, loss_scale=32, train_wall=19, gb_free=11.2, wall=68977
2023-05-26 18:33:01 - progress_bar.py[line:272] - INFO: epoch 022:    392 / 1732 loss=2.153, loss_v1=0, loss_v2=0, nll_loss=0.926, ntokens=1004.1, nsentences=32, sample_size=1004.1, sample_size_v1=0, sample_size_v2=0, ppl=1.9, wps=541.1, ups=0.54, wpb=1004.1, bsz=32, num_updates=36700, lr=9.37289e-06, gnorm=19.077, clip=100, loss_scale=32, train_wall=19, gb_free=11.8, wall=68996
2023-05-26 18:33:20 - progress_bar.py[line:272] - INFO: epoch 022:    402 / 1732 loss=2.141, loss_v1=0, loss_v2=0, nll_loss=0.913, ntokens=1005.2, nsentences=32, sample_size=1005.2, sample_size_v1=0, sample_size_v2=0, ppl=1.88, wps=540, ups=0.54, wpb=1005.2, bsz=32, num_updates=36710, lr=9.36675e-06, gnorm=19.085, clip=100, loss_scale=32, train_wall=19, gb_free=11.3, wall=69014
2023-05-26 18:33:38 - progress_bar.py[line:272] - INFO: epoch 022:    412 / 1732 loss=2.145, loss_v1=0, loss_v2=0, nll_loss=0.917, ntokens=1091.2, nsentences=32, sample_size=1091.2, sample_size_v1=0, sample_size_v2=0, ppl=1.89, wps=584.9, ups=0.54, wpb=1091.2, bsz=32, num_updates=36720, lr=9.3606e-06, gnorm=19.062, clip=100, loss_scale=32, train_wall=19, gb_free=11.3, wall=69033
2023-05-26 18:33:57 - progress_bar.py[line:272] - INFO: epoch 022:    422 / 1732 loss=2.116, loss_v1=0, loss_v2=0, nll_loss=0.884, ntokens=1011.2, nsentences=32, sample_size=1011.2, sample_size_v1=0, sample_size_v2=0, ppl=1.85, wps=541.5, ups=0.54, wpb=1011.2, bsz=32, num_updates=36730, lr=9.35446e-06, gnorm=18.85, clip=100, loss_scale=32, train_wall=19, gb_free=11.3, wall=69052
2023-05-26 18:34:16 - progress_bar.py[line:272] - INFO: epoch 022:    432 / 1732 loss=2.129, loss_v1=0, loss_v2=0, nll_loss=0.899, ntokens=1006.8, nsentences=32, sample_size=1006.8, sample_size_v1=0, sample_size_v2=0, ppl=1.87, wps=541.4, ups=0.54, wpb=1006.8, bsz=32, num_updates=36740, lr=9.34832e-06, gnorm=18.487, clip=100, loss_scale=32, train_wall=19, gb_free=11.7, wall=69070
2023-05-26 18:34:34 - progress_bar.py[line:272] - INFO: epoch 022:    442 / 1732 loss=2.15, loss_v1=0, loss_v2=0, nll_loss=0.924, ntokens=979.7, nsentences=32, sample_size=979.7, sample_size_v1=0, sample_size_v2=0, ppl=1.9, wps=527.3, ups=0.54, wpb=979.7, bsz=32, num_updates=36750, lr=9.34218e-06, gnorm=20.361, clip=100, loss_scale=32, train_wall=19, gb_free=11, wall=69089
2023-05-26 18:34:53 - progress_bar.py[line:272] - INFO: epoch 022:    452 / 1732 loss=2.139, loss_v1=0, loss_v2=0, nll_loss=0.911, ntokens=913.2, nsentences=32, sample_size=913.2, sample_size_v1=0, sample_size_v2=0, ppl=1.88, wps=492.6, ups=0.54, wpb=913.2, bsz=32, num_updates=36760, lr=9.33604e-06, gnorm=19.316, clip=100, loss_scale=32, train_wall=19, gb_free=11.9, wall=69107
2023-05-26 18:35:11 - progress_bar.py[line:272] - INFO: epoch 022:    462 / 1732 loss=2.177, loss_v1=0, loss_v2=0, nll_loss=0.956, ntokens=1070.3, nsentences=32, sample_size=1070.3, sample_size_v1=0, sample_size_v2=0, ppl=1.94, wps=575.5, ups=0.54, wpb=1070.3, bsz=32, num_updates=36770, lr=9.32989e-06, gnorm=16.946, clip=100, loss_scale=32, train_wall=19, gb_free=11, wall=69126
2023-05-26 18:35:30 - progress_bar.py[line:272] - INFO: epoch 022:    472 / 1732 loss=2.17, loss_v1=0, loss_v2=0, nll_loss=0.946, ntokens=1036.2, nsentences=32, sample_size=1036.2, sample_size_v1=0, sample_size_v2=0, ppl=1.93, wps=553, ups=0.53, wpb=1036.2, bsz=32, num_updates=36780, lr=9.32375e-06, gnorm=18.446, clip=100, loss_scale=32, train_wall=19, gb_free=11.1, wall=69145
2023-05-26 18:35:49 - progress_bar.py[line:272] - INFO: epoch 022:    482 / 1732 loss=2.155, loss_v1=0, loss_v2=0, nll_loss=0.929, ntokens=990.8, nsentences=32, sample_size=990.8, sample_size_v1=0, sample_size_v2=0, ppl=1.9, wps=534.2, ups=0.54, wpb=990.8, bsz=32, num_updates=36790, lr=9.31761e-06, gnorm=18.924, clip=100, loss_scale=32, train_wall=19, gb_free=11.9, wall=69163
2023-05-26 18:36:07 - progress_bar.py[line:272] - INFO: epoch 022:    492 / 1732 loss=2.138, loss_v1=0, loss_v2=0, nll_loss=0.908, ntokens=948.5, nsentences=32, sample_size=948.5, sample_size_v1=0, sample_size_v2=0, ppl=1.88, wps=509.1, ups=0.54, wpb=948.5, bsz=32, num_updates=36800, lr=9.31147e-06, gnorm=17.84, clip=100, loss_scale=32, train_wall=19, gb_free=11.2, wall=69182
2023-05-26 18:36:20 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2023-05-26 18:36:27 - progress_bar.py[line:272] - INFO: epoch 022:    503 / 1732 loss=2.16, loss_v1=0, loss_v2=0, nll_loss=0.934, ntokens=968.6, nsentences=32, sample_size=968.6, sample_size_v1=0, sample_size_v2=0, ppl=1.91, wps=479.4, ups=0.49, wpb=968.6, bsz=32, num_updates=36810, lr=9.30533e-06, gnorm=20.522, clip=100, loss_scale=16, train_wall=20, gb_free=11.8, wall=69202
2023-05-26 18:36:46 - progress_bar.py[line:272] - INFO: epoch 022:    513 / 1732 loss=2.176, loss_v1=0, loss_v2=0, nll_loss=0.953, ntokens=1035, nsentences=32, sample_size=1035, sample_size_v1=0, sample_size_v2=0, ppl=1.94, wps=557.1, ups=0.54, wpb=1035, bsz=32, num_updates=36820, lr=9.29918e-06, gnorm=18.554, clip=100, loss_scale=16, train_wall=19, gb_free=11.7, wall=69221
2023-05-26 18:37:04 - progress_bar.py[line:272] - INFO: epoch 022:    523 / 1732 loss=2.14, loss_v1=0, loss_v2=0, nll_loss=0.913, ntokens=997.6, nsentences=32, sample_size=997.6, sample_size_v1=0, sample_size_v2=0, ppl=1.88, wps=540.4, ups=0.54, wpb=997.6, bsz=32, num_updates=36830, lr=9.29304e-06, gnorm=20.172, clip=100, loss_scale=16, train_wall=18, gb_free=11.8, wall=69239
2023-05-26 18:37:23 - progress_bar.py[line:272] - INFO: epoch 022:    533 / 1732 loss=2.136, loss_v1=0, loss_v2=0, nll_loss=0.909, ntokens=935, nsentences=32, sample_size=935, sample_size_v1=0, sample_size_v2=0, ppl=1.88, wps=506.7, ups=0.54, wpb=935, bsz=32, num_updates=36840, lr=9.2869e-06, gnorm=18.771, clip=100, loss_scale=16, train_wall=18, gb_free=11.8, wall=69258
2023-05-26 18:37:41 - progress_bar.py[line:272] - INFO: epoch 022:    543 / 1732 loss=2.153, loss_v1=0, loss_v2=0, nll_loss=0.928, ntokens=1003.8, nsentences=32, sample_size=1003.8, sample_size_v1=0, sample_size_v2=0, ppl=1.9, wps=540.9, ups=0.54, wpb=1003.8, bsz=32, num_updates=36850, lr=9.28076e-06, gnorm=20.054, clip=100, loss_scale=16, train_wall=19, gb_free=11.3, wall=69276
2023-05-26 18:38:00 - progress_bar.py[line:272] - INFO: epoch 022:    553 / 1732 loss=2.18, loss_v1=0, loss_v2=0, nll_loss=0.958, ntokens=1017.4, nsentences=32, sample_size=1017.4, sample_size_v1=0, sample_size_v2=0, ppl=1.94, wps=546.8, ups=0.54, wpb=1017.4, bsz=32, num_updates=36860, lr=9.27461e-06, gnorm=19.856, clip=100, loss_scale=16, train_wall=19, gb_free=11.8, wall=69295
2023-05-26 18:38:19 - progress_bar.py[line:272] - INFO: epoch 022:    563 / 1732 loss=2.174, loss_v1=0, loss_v2=0, nll_loss=0.951, ntokens=1008.2, nsentences=32, sample_size=1008.2, sample_size_v1=0, sample_size_v2=0, ppl=1.93, wps=543, ups=0.54, wpb=1008.2, bsz=32, num_updates=36870, lr=9.26847e-06, gnorm=20.854, clip=100, loss_scale=16, train_wall=19, gb_free=12, wall=69313
2023-05-26 18:38:37 - progress_bar.py[line:272] - INFO: epoch 022:    573 / 1732 loss=2.17, loss_v1=0, loss_v2=0, nll_loss=0.946, ntokens=1041.3, nsentences=32, sample_size=1041.3, sample_size_v1=0, sample_size_v2=0, ppl=1.93, wps=556, ups=0.53, wpb=1041.3, bsz=32, num_updates=36880, lr=9.26233e-06, gnorm=17.354, clip=100, loss_scale=16, train_wall=19, gb_free=11, wall=69332
2023-05-26 18:38:56 - progress_bar.py[line:272] - INFO: epoch 022:    583 / 1732 loss=2.169, loss_v1=0, loss_v2=0, nll_loss=0.944, ntokens=981.7, nsentences=32, sample_size=981.7, sample_size_v1=0, sample_size_v2=0, ppl=1.92, wps=525, ups=0.53, wpb=981.7, bsz=32, num_updates=36890, lr=9.25619e-06, gnorm=20.61, clip=100, loss_scale=16, train_wall=19, gb_free=11.8, wall=69351
2023-05-26 18:39:15 - progress_bar.py[line:272] - INFO: epoch 022:    593 / 1732 loss=2.121, loss_v1=0, loss_v2=0, nll_loss=0.89, ntokens=957.4, nsentences=32, sample_size=957.4, sample_size_v1=0, sample_size_v2=0, ppl=1.85, wps=512.8, ups=0.54, wpb=957.4, bsz=32, num_updates=36900, lr=9.25005e-06, gnorm=19.059, clip=100, loss_scale=16, train_wall=19, gb_free=11.7, wall=69369
2023-05-26 18:39:33 - progress_bar.py[line:272] - INFO: epoch 022:    603 / 1732 loss=2.12, loss_v1=0, loss_v2=0, nll_loss=0.89, ntokens=911.2, nsentences=32, sample_size=911.2, sample_size_v1=0, sample_size_v2=0, ppl=1.85, wps=493.2, ups=0.54, wpb=911.2, bsz=32, num_updates=36910, lr=9.2439e-06, gnorm=17.814, clip=100, loss_scale=16, train_wall=18, gb_free=11.8, wall=69388
2023-05-26 18:39:52 - progress_bar.py[line:272] - INFO: epoch 022:    613 / 1732 loss=2.15, loss_v1=0, loss_v2=0, nll_loss=0.925, ntokens=893.3, nsentences=32, sample_size=893.3, sample_size_v1=0, sample_size_v2=0, ppl=1.9, wps=482.3, ups=0.54, wpb=893.3, bsz=32, num_updates=36920, lr=9.23776e-06, gnorm=21.008, clip=100, loss_scale=16, train_wall=18, gb_free=11.7, wall=69406
2023-05-26 18:40:10 - progress_bar.py[line:272] - INFO: epoch 022:    623 / 1732 loss=2.153, loss_v1=0, loss_v2=0, nll_loss=0.929, ntokens=887.2, nsentences=32, sample_size=887.2, sample_size_v1=0, sample_size_v2=0, ppl=1.9, wps=481.9, ups=0.54, wpb=887.2, bsz=32, num_updates=36930, lr=9.23162e-06, gnorm=20.245, clip=100, loss_scale=16, train_wall=18, gb_free=11.1, wall=69425
2023-05-26 18:40:29 - progress_bar.py[line:272] - INFO: epoch 022:    633 / 1732 loss=2.139, loss_v1=0, loss_v2=0, nll_loss=0.912, ntokens=925, nsentences=32, sample_size=925, sample_size_v1=0, sample_size_v2=0, ppl=1.88, wps=501, ups=0.54, wpb=925, bsz=32, num_updates=36940, lr=9.22548e-06, gnorm=19.88, clip=100, loss_scale=16, train_wall=18, gb_free=11.6, wall=69443
2023-05-26 18:40:47 - progress_bar.py[line:272] - INFO: epoch 022:    643 / 1732 loss=2.168, loss_v1=0, loss_v2=0, nll_loss=0.945, ntokens=963.8, nsentences=32, sample_size=963.8, sample_size_v1=0, sample_size_v2=0, ppl=1.93, wps=521.5, ups=0.54, wpb=963.8, bsz=32, num_updates=36950, lr=9.21934e-06, gnorm=21.317, clip=100, loss_scale=16, train_wall=18, gb_free=11.8, wall=69462
2023-05-26 18:41:05 - progress_bar.py[line:272] - INFO: epoch 022:    653 / 1732 loss=2.138, loss_v1=0, loss_v2=0, nll_loss=0.91, ntokens=928, nsentences=32, sample_size=928, sample_size_v1=0, sample_size_v2=0, ppl=1.88, wps=505.7, ups=0.54, wpb=928, bsz=32, num_updates=36960, lr=9.21319e-06, gnorm=18.922, clip=100, loss_scale=16, train_wall=18, gb_free=11.9, wall=69480
2023-05-26 18:41:24 - progress_bar.py[line:272] - INFO: epoch 022:    663 / 1732 loss=2.133, loss_v1=0, loss_v2=0, nll_loss=0.906, ntokens=882.9, nsentences=32, sample_size=882.9, sample_size_v1=0, sample_size_v2=0, ppl=1.87, wps=478.3, ups=0.54, wpb=882.9, bsz=32, num_updates=36970, lr=9.20705e-06, gnorm=22.703, clip=100, loss_scale=16, train_wall=18, gb_free=11.5, wall=69499
2023-05-26 18:41:43 - progress_bar.py[line:272] - INFO: epoch 022:    673 / 1732 loss=2.173, loss_v1=0, loss_v2=0, nll_loss=0.95, ntokens=954.3, nsentences=32, sample_size=954.3, sample_size_v1=0, sample_size_v2=0, ppl=1.93, wps=514.7, ups=0.54, wpb=954.3, bsz=32, num_updates=36980, lr=9.20091e-06, gnorm=21.072, clip=100, loss_scale=16, train_wall=19, gb_free=11.8, wall=69517
2023-05-26 18:42:01 - progress_bar.py[line:272] - INFO: epoch 022:    683 / 1732 loss=2.134, loss_v1=0, loss_v2=0, nll_loss=0.907, ntokens=960.5, nsentences=32, sample_size=960.5, sample_size_v1=0, sample_size_v2=0, ppl=1.87, wps=519, ups=0.54, wpb=960.5, bsz=32, num_updates=36990, lr=9.19477e-06, gnorm=17.838, clip=100, loss_scale=16, train_wall=18, gb_free=11.9, wall=69536
2023-05-26 18:42:20 - progress_bar.py[line:272] - INFO: epoch 022:    693 / 1732 loss=2.17, loss_v1=0, loss_v2=0, nll_loss=0.947, ntokens=962.9, nsentences=32, sample_size=962.9, sample_size_v1=0, sample_size_v2=0, ppl=1.93, wps=518, ups=0.54, wpb=962.9, bsz=32, num_updates=37000, lr=9.18862e-06, gnorm=19.769, clip=100, loss_scale=16, train_wall=19, gb_free=11.2, wall=69554
2023-05-26 18:42:38 - progress_bar.py[line:272] - INFO: epoch 022:    703 / 1732 loss=2.116, loss_v1=0, loss_v2=0, nll_loss=0.885, ntokens=972.9, nsentences=32, sample_size=972.9, sample_size_v1=0, sample_size_v2=0, ppl=1.85, wps=523.7, ups=0.54, wpb=972.9, bsz=32, num_updates=37010, lr=9.18248e-06, gnorm=18.963, clip=100, loss_scale=16, train_wall=19, gb_free=11.6, wall=69573
2023-05-26 18:42:57 - progress_bar.py[line:272] - INFO: epoch 022:    713 / 1732 loss=2.15, loss_v1=0, loss_v2=0, nll_loss=0.925, ntokens=898.6, nsentences=32, sample_size=898.6, sample_size_v1=0, sample_size_v2=0, ppl=1.9, wps=487, ups=0.54, wpb=898.6, bsz=32, num_updates=37020, lr=9.17634e-06, gnorm=20.642, clip=100, loss_scale=16, train_wall=18, gb_free=11.8, wall=69591
2023-05-26 18:43:15 - progress_bar.py[line:272] - INFO: epoch 022:    723 / 1732 loss=2.11, loss_v1=0, loss_v2=0, nll_loss=0.878, ntokens=877.5, nsentences=32, sample_size=877.5, sample_size_v1=0, sample_size_v2=0, ppl=1.84, wps=476.1, ups=0.54, wpb=877.5, bsz=32, num_updates=37030, lr=9.1702e-06, gnorm=20.897, clip=100, loss_scale=16, train_wall=18, gb_free=12, wall=69610
2023-05-26 18:43:34 - progress_bar.py[line:272] - INFO: epoch 022:    733 / 1732 loss=2.134, loss_v1=0, loss_v2=0, nll_loss=0.906, ntokens=959.6, nsentences=32, sample_size=959.6, sample_size_v1=0, sample_size_v2=0, ppl=1.87, wps=519.4, ups=0.54, wpb=959.6, bsz=32, num_updates=37040, lr=9.16406e-06, gnorm=18.952, clip=100, loss_scale=16, train_wall=18, gb_free=11, wall=69628
2023-05-26 18:43:52 - progress_bar.py[line:272] - INFO: epoch 022:    743 / 1732 loss=2.129, loss_v1=0, loss_v2=0, nll_loss=0.9, ntokens=991.8, nsentences=32, sample_size=991.8, sample_size_v1=0, sample_size_v2=0, ppl=1.87, wps=536.5, ups=0.54, wpb=991.8, bsz=32, num_updates=37050, lr=9.15791e-06, gnorm=19.545, clip=100, loss_scale=16, train_wall=18, gb_free=11.4, wall=69647
2023-05-26 18:44:11 - progress_bar.py[line:272] - INFO: epoch 022:    753 / 1732 loss=2.133, loss_v1=0, loss_v2=0, nll_loss=0.906, ntokens=968.6, nsentences=32, sample_size=968.6, sample_size_v1=0, sample_size_v2=0, ppl=1.87, wps=521.5, ups=0.54, wpb=968.6, bsz=32, num_updates=37060, lr=9.15177e-06, gnorm=20.779, clip=100, loss_scale=16, train_wall=19, gb_free=11.5, wall=69665
2023-05-26 18:44:29 - progress_bar.py[line:272] - INFO: epoch 022:    763 / 1732 loss=2.129, loss_v1=0, loss_v2=0, nll_loss=0.9, ntokens=964, nsentences=32, sample_size=964, sample_size_v1=0, sample_size_v2=0, ppl=1.87, wps=521.5, ups=0.54, wpb=964, bsz=32, num_updates=37070, lr=9.14563e-06, gnorm=22.034, clip=100, loss_scale=16, train_wall=18, gb_free=11.6, wall=69684
2023-05-26 18:44:48 - progress_bar.py[line:272] - INFO: epoch 022:    773 / 1732 loss=2.136, loss_v1=0, loss_v2=0, nll_loss=0.91, ntokens=971.7, nsentences=32, sample_size=971.7, sample_size_v1=0, sample_size_v2=0, ppl=1.88, wps=524.9, ups=0.54, wpb=971.7, bsz=32, num_updates=37080, lr=9.13949e-06, gnorm=18.968, clip=100, loss_scale=16, train_wall=18, gb_free=11.5, wall=69702
2023-05-26 18:45:06 - progress_bar.py[line:272] - INFO: epoch 022:    783 / 1732 loss=2.126, loss_v1=0, loss_v2=0, nll_loss=0.897, ntokens=1008.4, nsentences=32, sample_size=1008.4, sample_size_v1=0, sample_size_v2=0, ppl=1.86, wps=544.4, ups=0.54, wpb=1008.4, bsz=32, num_updates=37090, lr=9.13335e-06, gnorm=18.892, clip=100, loss_scale=16, train_wall=18, gb_free=11.2, wall=69721
2023-05-26 18:45:25 - progress_bar.py[line:272] - INFO: epoch 022:    793 / 1732 loss=2.153, loss_v1=0, loss_v2=0, nll_loss=0.929, ntokens=1034.6, nsentences=32, sample_size=1034.6, sample_size_v1=0, sample_size_v2=0, ppl=1.9, wps=558.1, ups=0.54, wpb=1034.6, bsz=32, num_updates=37100, lr=9.1272e-06, gnorm=20.198, clip=100, loss_scale=16, train_wall=19, gb_free=11.4, wall=69739
2023-05-26 18:45:43 - progress_bar.py[line:272] - INFO: epoch 022:    803 / 1732 loss=2.15, loss_v1=0, loss_v2=0, nll_loss=0.922, ntokens=964.4, nsentences=32, sample_size=964.4, sample_size_v1=0, sample_size_v2=0, ppl=1.89, wps=521.2, ups=0.54, wpb=964.4, bsz=32, num_updates=37110, lr=9.12106e-06, gnorm=19.764, clip=100, loss_scale=16, train_wall=18, gb_free=10.9, wall=69758
2023-05-26 18:46:02 - progress_bar.py[line:272] - INFO: epoch 022:    813 / 1732 loss=2.148, loss_v1=0, loss_v2=0, nll_loss=0.92, ntokens=940.9, nsentences=32, sample_size=940.9, sample_size_v1=0, sample_size_v2=0, ppl=1.89, wps=507.9, ups=0.54, wpb=940.9, bsz=32, num_updates=37120, lr=9.11492e-06, gnorm=20.486, clip=100, loss_scale=16, train_wall=18, gb_free=10.8, wall=69776
2023-05-26 18:46:20 - progress_bar.py[line:272] - INFO: epoch 022:    823 / 1732 loss=2.143, loss_v1=0, loss_v2=0, nll_loss=0.916, ntokens=915.1, nsentences=32, sample_size=915.1, sample_size_v1=0, sample_size_v2=0, ppl=1.89, wps=493.7, ups=0.54, wpb=915.1, bsz=32, num_updates=37130, lr=9.10878e-06, gnorm=22.374, clip=100, loss_scale=16, train_wall=19, gb_free=11.5, wall=69795
2023-05-26 18:46:39 - progress_bar.py[line:272] - INFO: epoch 022:    833 / 1732 loss=2.137, loss_v1=0, loss_v2=0, nll_loss=0.909, ntokens=907.5, nsentences=32, sample_size=907.5, sample_size_v1=0, sample_size_v2=0, ppl=1.88, wps=493.7, ups=0.54, wpb=907.5, bsz=32, num_updates=37140, lr=9.10263e-06, gnorm=20.31, clip=100, loss_scale=16, train_wall=18, gb_free=11.8, wall=69813
2023-05-26 18:46:57 - progress_bar.py[line:272] - INFO: epoch 022:    843 / 1732 loss=2.128, loss_v1=0, loss_v2=0, nll_loss=0.899, ntokens=950.7, nsentences=32, sample_size=950.7, sample_size_v1=0, sample_size_v2=0, ppl=1.86, wps=517, ups=0.54, wpb=950.7, bsz=32, num_updates=37150, lr=9.09649e-06, gnorm=20.959, clip=100, loss_scale=16, train_wall=18, gb_free=11.8, wall=69832
2023-05-26 18:47:16 - progress_bar.py[line:272] - INFO: epoch 022:    853 / 1732 loss=2.144, loss_v1=0, loss_v2=0, nll_loss=0.916, ntokens=1006.3, nsentences=32, sample_size=1006.3, sample_size_v1=0, sample_size_v2=0, ppl=1.89, wps=540.8, ups=0.54, wpb=1006.3, bsz=32, num_updates=37160, lr=9.09035e-06, gnorm=18.366, clip=100, loss_scale=16, train_wall=19, gb_free=11.1, wall=69850
2023-05-26 18:47:34 - progress_bar.py[line:272] - INFO: epoch 022:    863 / 1732 loss=2.136, loss_v1=0, loss_v2=0, nll_loss=0.909, ntokens=933.3, nsentences=32, sample_size=933.3, sample_size_v1=0, sample_size_v2=0, ppl=1.88, wps=504.1, ups=0.54, wpb=933.3, bsz=32, num_updates=37170, lr=9.08421e-06, gnorm=20.222, clip=100, loss_scale=16, train_wall=18, gb_free=11.4, wall=69869
2023-05-26 18:47:53 - progress_bar.py[line:272] - INFO: epoch 022:    873 / 1732 loss=2.125, loss_v1=0, loss_v2=0, nll_loss=0.898, ntokens=966.4, nsentences=32, sample_size=966.4, sample_size_v1=0, sample_size_v2=0, ppl=1.86, wps=522.4, ups=0.54, wpb=966.4, bsz=32, num_updates=37180, lr=9.07807e-06, gnorm=20.859, clip=100, loss_scale=16, train_wall=18, gb_free=11.3, wall=69887
2023-05-26 18:48:11 - progress_bar.py[line:272] - INFO: epoch 022:    883 / 1732 loss=2.079, loss_v1=0, loss_v2=0, nll_loss=0.845, ntokens=985.5, nsentences=32, sample_size=985.5, sample_size_v1=0, sample_size_v2=0, ppl=1.8, wps=529, ups=0.54, wpb=985.5, bsz=32, num_updates=37190, lr=9.07192e-06, gnorm=19.679, clip=100, loss_scale=16, train_wall=19, gb_free=11.3, wall=69906
2023-05-26 18:48:30 - progress_bar.py[line:272] - INFO: epoch 022:    893 / 1732 loss=2.094, loss_v1=0, loss_v2=0, nll_loss=0.862, ntokens=1009.8, nsentences=32, sample_size=1009.8, sample_size_v1=0, sample_size_v2=0, ppl=1.82, wps=542.3, ups=0.54, wpb=1009.8, bsz=32, num_updates=37200, lr=9.06578e-06, gnorm=18.88, clip=100, loss_scale=16, train_wall=19, gb_free=11.1, wall=69925
2023-05-26 18:48:49 - progress_bar.py[line:272] - INFO: epoch 022:    903 / 1732 loss=2.09, loss_v1=0, loss_v2=0, nll_loss=0.858, ntokens=1049.7, nsentences=32, sample_size=1049.7, sample_size_v1=0, sample_size_v2=0, ppl=1.81, wps=563.8, ups=0.54, wpb=1049.7, bsz=32, num_updates=37210, lr=9.05964e-06, gnorm=19.799, clip=100, loss_scale=16, train_wall=19, gb_free=11.5, wall=69943
2023-05-26 18:49:07 - progress_bar.py[line:272] - INFO: epoch 022:    913 / 1732 loss=2.168, loss_v1=0, loss_v2=0, nll_loss=0.944, ntokens=930.6, nsentences=32, sample_size=930.6, sample_size_v1=0, sample_size_v2=0, ppl=1.92, wps=503.7, ups=0.54, wpb=930.6, bsz=32, num_updates=37220, lr=9.0535e-06, gnorm=22.015, clip=100, loss_scale=16, train_wall=18, gb_free=11, wall=69962
2023-05-26 18:49:26 - progress_bar.py[line:272] - INFO: epoch 022:    923 / 1732 loss=2.108, loss_v1=0, loss_v2=0, nll_loss=0.876, ntokens=1023.3, nsentences=32, sample_size=1023.3, sample_size_v1=0, sample_size_v2=0, ppl=1.84, wps=548, ups=0.54, wpb=1023.3, bsz=32, num_updates=37230, lr=9.04736e-06, gnorm=19.843, clip=100, loss_scale=16, train_wall=19, gb_free=11.1, wall=69980
2023-05-26 18:49:44 - progress_bar.py[line:272] - INFO: epoch 022:    933 / 1732 loss=2.128, loss_v1=0, loss_v2=0, nll_loss=0.899, ntokens=1034.6, nsentences=32, sample_size=1034.6, sample_size_v1=0, sample_size_v2=0, ppl=1.86, wps=551.6, ups=0.53, wpb=1034.6, bsz=32, num_updates=37240, lr=9.04121e-06, gnorm=20.459, clip=100, loss_scale=16, train_wall=19, gb_free=11.1, wall=69999
2023-05-26 18:50:03 - progress_bar.py[line:272] - INFO: epoch 022:    943 / 1732 loss=2.152, loss_v1=0, loss_v2=0, nll_loss=0.926, ntokens=1054.1, nsentences=32, sample_size=1054.1, sample_size_v1=0, sample_size_v2=0, ppl=1.9, wps=560.1, ups=0.53, wpb=1054.1, bsz=32, num_updates=37250, lr=9.03507e-06, gnorm=20.18, clip=100, loss_scale=16, train_wall=19, gb_free=11.3, wall=70018
2023-05-26 18:50:22 - progress_bar.py[line:272] - INFO: epoch 022:    953 / 1732 loss=2.14, loss_v1=0, loss_v2=0, nll_loss=0.914, ntokens=1032.2, nsentences=32, sample_size=1032.2, sample_size_v1=0, sample_size_v2=0, ppl=1.88, wps=549.7, ups=0.53, wpb=1032.2, bsz=32, num_updates=37260, lr=9.02893e-06, gnorm=20.666, clip=100, loss_scale=16, train_wall=19, gb_free=10.9, wall=70037
2023-05-26 18:50:41 - progress_bar.py[line:272] - INFO: epoch 022:    963 / 1732 loss=2.149, loss_v1=0, loss_v2=0, nll_loss=0.924, ntokens=1069.2, nsentences=32, sample_size=1069.2, sample_size_v1=0, sample_size_v2=0, ppl=1.9, wps=569.1, ups=0.53, wpb=1069.2, bsz=32, num_updates=37270, lr=9.02279e-06, gnorm=21.832, clip=100, loss_scale=16, train_wall=19, gb_free=11.2, wall=70056
2023-05-26 18:51:00 - progress_bar.py[line:272] - INFO: epoch 022:    973 / 1732 loss=2.131, loss_v1=0, loss_v2=0, nll_loss=0.903, ntokens=1034.1, nsentences=32, sample_size=1034.1, sample_size_v1=0, sample_size_v2=0, ppl=1.87, wps=548.7, ups=0.53, wpb=1034.1, bsz=32, num_updates=37280, lr=9.01665e-06, gnorm=20.761, clip=100, loss_scale=16, train_wall=19, gb_free=11.2, wall=70074
2023-05-26 18:51:19 - progress_bar.py[line:272] - INFO: epoch 022:    983 / 1732 loss=2.13, loss_v1=0, loss_v2=0, nll_loss=0.901, ntokens=1026.6, nsentences=32, sample_size=1026.6, sample_size_v1=0, sample_size_v2=0, ppl=1.87, wps=544.3, ups=0.53, wpb=1026.6, bsz=32, num_updates=37290, lr=9.0105e-06, gnorm=19.01, clip=100, loss_scale=16, train_wall=19, gb_free=11.2, wall=70093
2023-05-26 18:51:37 - progress_bar.py[line:272] - INFO: epoch 022:    993 / 1732 loss=2.149, loss_v1=0, loss_v2=0, nll_loss=0.923, ntokens=1041.8, nsentences=32, sample_size=1041.8, sample_size_v1=0, sample_size_v2=0, ppl=1.9, wps=554.1, ups=0.53, wpb=1041.8, bsz=32, num_updates=37300, lr=9.00436e-06, gnorm=22.935, clip=100, loss_scale=16, train_wall=19, gb_free=11.4, wall=70112
2023-05-26 18:51:56 - progress_bar.py[line:272] - INFO: epoch 022:   1003 / 1732 loss=2.131, loss_v1=0, loss_v2=0, nll_loss=0.902, ntokens=1018, nsentences=32, sample_size=1018, sample_size_v1=0, sample_size_v2=0, ppl=1.87, wps=545.3, ups=0.54, wpb=1018, bsz=32, num_updates=37310, lr=8.99822e-06, gnorm=19.186, clip=100, loss_scale=16, train_wall=19, gb_free=11.2, wall=70131
2023-05-26 18:52:15 - progress_bar.py[line:272] - INFO: epoch 022:   1013 / 1732 loss=2.125, loss_v1=0, loss_v2=0, nll_loss=0.895, ntokens=965, nsentences=32, sample_size=965, sample_size_v1=0, sample_size_v2=0, ppl=1.86, wps=518.3, ups=0.54, wpb=965, bsz=32, num_updates=37320, lr=8.99208e-06, gnorm=19.642, clip=100, loss_scale=32, train_wall=19, gb_free=11.9, wall=70149
2023-05-26 18:52:34 - progress_bar.py[line:272] - INFO: epoch 022:   1023 / 1732 loss=2.122, loss_v1=0, loss_v2=0, nll_loss=0.893, ntokens=1087.1, nsentences=32, sample_size=1087.1, sample_size_v1=0, sample_size_v2=0, ppl=1.86, wps=575.3, ups=0.53, wpb=1087.1, bsz=32, num_updates=37330, lr=8.98593e-06, gnorm=19.636, clip=100, loss_scale=32, train_wall=19, gb_free=11, wall=70168
2023-05-26 18:52:53 - progress_bar.py[line:272] - INFO: epoch 022:   1033 / 1732 loss=2.132, loss_v1=0, loss_v2=0, nll_loss=0.902, ntokens=1100.3, nsentences=32, sample_size=1100.3, sample_size_v1=0, sample_size_v2=0, ppl=1.87, wps=581.2, ups=0.53, wpb=1100.3, bsz=32, num_updates=37340, lr=8.97979e-06, gnorm=18.065, clip=100, loss_scale=32, train_wall=19, gb_free=11.7, wall=70187
2023-05-26 18:53:11 - progress_bar.py[line:272] - INFO: epoch 022:   1043 / 1732 loss=2.128, loss_v1=0, loss_v2=0, nll_loss=0.899, ntokens=1068.2, nsentences=32, sample_size=1068.2, sample_size_v1=0, sample_size_v2=0, ppl=1.87, wps=565.3, ups=0.53, wpb=1068.2, bsz=32, num_updates=37350, lr=8.97365e-06, gnorm=19.374, clip=100, loss_scale=32, train_wall=19, gb_free=11.2, wall=70206
2023-05-26 18:53:30 - progress_bar.py[line:272] - INFO: epoch 022:   1053 / 1732 loss=2.142, loss_v1=0, loss_v2=0, nll_loss=0.915, ntokens=1062.8, nsentences=32, sample_size=1062.8, sample_size_v1=0, sample_size_v2=0, ppl=1.89, wps=569.9, ups=0.54, wpb=1062.8, bsz=32, num_updates=37360, lr=8.96751e-06, gnorm=21.023, clip=100, loss_scale=32, train_wall=19, gb_free=11.5, wall=70225
2023-05-26 18:53:49 - progress_bar.py[line:272] - INFO: epoch 022:   1063 / 1732 loss=2.121, loss_v1=0, loss_v2=0, nll_loss=0.89, ntokens=1030.9, nsentences=32, sample_size=1030.9, sample_size_v1=0, sample_size_v2=0, ppl=1.85, wps=548.6, ups=0.53, wpb=1030.9, bsz=32, num_updates=37370, lr=8.96137e-06, gnorm=20.464, clip=100, loss_scale=32, train_wall=19, gb_free=11.1, wall=70244
2023-05-26 18:54:08 - progress_bar.py[line:272] - INFO: epoch 022:   1073 / 1732 loss=2.138, loss_v1=0, loss_v2=0, nll_loss=0.911, ntokens=999.3, nsentences=32, sample_size=999.3, sample_size_v1=0, sample_size_v2=0, ppl=1.88, wps=532.3, ups=0.53, wpb=999.3, bsz=32, num_updates=37380, lr=8.95522e-06, gnorm=21.043, clip=100, loss_scale=32, train_wall=19, gb_free=11.3, wall=70262
2023-05-26 18:54:27 - progress_bar.py[line:272] - INFO: epoch 022:   1083 / 1732 loss=2.151, loss_v1=0, loss_v2=0, nll_loss=0.926, ntokens=1054.9, nsentences=32, sample_size=1054.9, sample_size_v1=0, sample_size_v2=0, ppl=1.9, wps=556.6, ups=0.53, wpb=1054.9, bsz=32, num_updates=37390, lr=8.94908e-06, gnorm=21.211, clip=100, loss_scale=32, train_wall=19, gb_free=10.5, wall=70281
2023-05-26 18:54:45 - progress_bar.py[line:272] - INFO: epoch 022:   1093 / 1732 loss=2.132, loss_v1=0, loss_v2=0, nll_loss=0.904, ntokens=1060.6, nsentences=32, sample_size=1060.6, sample_size_v1=0, sample_size_v2=0, ppl=1.87, wps=562.9, ups=0.53, wpb=1060.6, bsz=32, num_updates=37400, lr=8.94294e-06, gnorm=20.066, clip=100, loss_scale=32, train_wall=19, gb_free=11.1, wall=70300
2023-05-26 18:55:04 - progress_bar.py[line:272] - INFO: epoch 022:   1103 / 1732 loss=2.142, loss_v1=0, loss_v2=0, nll_loss=0.915, ntokens=1039.1, nsentences=32, sample_size=1039.1, sample_size_v1=0, sample_size_v2=0, ppl=1.89, wps=554.5, ups=0.53, wpb=1039.1, bsz=32, num_updates=37410, lr=8.9368e-06, gnorm=21.352, clip=100, loss_scale=32, train_wall=19, gb_free=11.7, wall=70319
2023-05-26 18:55:23 - progress_bar.py[line:272] - INFO: epoch 022:   1113 / 1732 loss=2.132, loss_v1=0, loss_v2=0, nll_loss=0.903, ntokens=1008.5, nsentences=32, sample_size=1008.5, sample_size_v1=0, sample_size_v2=0, ppl=1.87, wps=536.8, ups=0.53, wpb=1008.5, bsz=32, num_updates=37420, lr=8.93066e-06, gnorm=20.175, clip=100, loss_scale=32, train_wall=19, gb_free=11.4, wall=70338
2023-05-26 18:55:42 - progress_bar.py[line:272] - INFO: epoch 022:   1123 / 1732 loss=2.119, loss_v1=0, loss_v2=0, nll_loss=0.888, ntokens=976.6, nsentences=32, sample_size=976.6, sample_size_v1=0, sample_size_v2=0, ppl=1.85, wps=517.9, ups=0.53, wpb=976.6, bsz=32, num_updates=37430, lr=8.92451e-06, gnorm=22.01, clip=100, loss_scale=32, train_wall=19, gb_free=10.8, wall=70357
2023-05-26 18:56:01 - progress_bar.py[line:272] - INFO: epoch 022:   1133 / 1732 loss=2.127, loss_v1=0, loss_v2=0, nll_loss=0.898, ntokens=965.2, nsentences=32, sample_size=965.2, sample_size_v1=0, sample_size_v2=0, ppl=1.86, wps=515.4, ups=0.53, wpb=965.2, bsz=32, num_updates=37440, lr=8.91837e-06, gnorm=22.153, clip=100, loss_scale=32, train_wall=19, gb_free=10.6, wall=70375
2023-05-26 18:56:19 - progress_bar.py[line:272] - INFO: epoch 022:   1143 / 1732 loss=2.128, loss_v1=0, loss_v2=0, nll_loss=0.899, ntokens=1060.3, nsentences=32, sample_size=1060.3, sample_size_v1=0, sample_size_v2=0, ppl=1.86, wps=565.2, ups=0.53, wpb=1060.3, bsz=32, num_updates=37450, lr=8.91223e-06, gnorm=20.012, clip=100, loss_scale=32, train_wall=19, gb_free=11.1, wall=70394
2023-05-26 18:56:38 - progress_bar.py[line:272] - INFO: epoch 022:   1153 / 1732 loss=2.108, loss_v1=0, loss_v2=0, nll_loss=0.877, ntokens=1009.1, nsentences=32, sample_size=1009.1, sample_size_v1=0, sample_size_v2=0, ppl=1.84, wps=539.6, ups=0.53, wpb=1009.1, bsz=32, num_updates=37460, lr=8.90609e-06, gnorm=19.271, clip=100, loss_scale=32, train_wall=19, gb_free=11.7, wall=70413
2023-05-26 18:56:57 - progress_bar.py[line:272] - INFO: epoch 022:   1163 / 1732 loss=2.106, loss_v1=0, loss_v2=0, nll_loss=0.876, ntokens=999.2, nsentences=32, sample_size=999.2, sample_size_v1=0, sample_size_v2=0, ppl=1.84, wps=530.7, ups=0.53, wpb=999.2, bsz=32, num_updates=37470, lr=8.89994e-06, gnorm=19.975, clip=100, loss_scale=32, train_wall=19, gb_free=11.2, wall=70432
2023-05-26 18:57:06 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2023-05-26 18:57:17 - progress_bar.py[line:272] - INFO: epoch 022:   1174 / 1732 loss=2.125, loss_v1=0, loss_v2=0, nll_loss=0.896, ntokens=1088.7, nsentences=32, sample_size=1088.7, sample_size_v1=0, sample_size_v2=0, ppl=1.86, wps=528.3, ups=0.49, wpb=1088.7, bsz=32, num_updates=37480, lr=8.8938e-06, gnorm=18.367, clip=100, loss_scale=16, train_wall=21, gb_free=11, wall=70452
2023-05-26 18:57:36 - progress_bar.py[line:272] - INFO: epoch 022:   1184 / 1732 loss=2.093, loss_v1=0, loss_v2=0, nll_loss=0.86, ntokens=962, nsentences=32, sample_size=962, sample_size_v1=0, sample_size_v2=0, ppl=1.82, wps=515.1, ups=0.54, wpb=962, bsz=32, num_updates=37490, lr=8.88766e-06, gnorm=18.649, clip=100, loss_scale=16, train_wall=19, gb_free=11.7, wall=70471
2023-05-26 18:57:55 - progress_bar.py[line:272] - INFO: epoch 022:   1194 / 1732 loss=2.122, loss_v1=0, loss_v2=0, nll_loss=0.892, ntokens=1042.6, nsentences=32, sample_size=1042.6, sample_size_v1=0, sample_size_v2=0, ppl=1.86, wps=555.8, ups=0.53, wpb=1042.6, bsz=32, num_updates=37500, lr=8.88152e-06, gnorm=18.562, clip=100, loss_scale=16, train_wall=19, gb_free=11.5, wall=70490
2023-05-26 18:58:14 - progress_bar.py[line:272] - INFO: epoch 022:   1204 / 1732 loss=2.094, loss_v1=0, loss_v2=0, nll_loss=0.86, ntokens=1150.2, nsentences=32, sample_size=1150.2, sample_size_v1=0, sample_size_v2=0, ppl=1.81, wps=606, ups=0.53, wpb=1150.2, bsz=32, num_updates=37510, lr=8.87538e-06, gnorm=16.818, clip=100, loss_scale=16, train_wall=19, gb_free=11.3, wall=70509
2023-05-26 18:58:33 - progress_bar.py[line:272] - INFO: epoch 022:   1214 / 1732 loss=2.115, loss_v1=0, loss_v2=0, nll_loss=0.884, ntokens=996.3, nsentences=32, sample_size=996.3, sample_size_v1=0, sample_size_v2=0, ppl=1.85, wps=532, ups=0.53, wpb=996.3, bsz=32, num_updates=37520, lr=8.86923e-06, gnorm=20.981, clip=100, loss_scale=16, train_wall=19, gb_free=11.7, wall=70527
2023-05-26 18:58:51 - progress_bar.py[line:272] - INFO: epoch 022:   1224 / 1732 loss=2.146, loss_v1=0, loss_v2=0, nll_loss=0.92, ntokens=1056.3, nsentences=32, sample_size=1056.3, sample_size_v1=0, sample_size_v2=0, ppl=1.89, wps=562.6, ups=0.53, wpb=1056.3, bsz=32, num_updates=37530, lr=8.86309e-06, gnorm=19.399, clip=100, loss_scale=16, train_wall=19, gb_free=11.5, wall=70546
2023-05-26 18:59:10 - progress_bar.py[line:272] - INFO: epoch 022:   1234 / 1732 loss=2.111, loss_v1=0, loss_v2=0, nll_loss=0.879, ntokens=1012.2, nsentences=32, sample_size=1012.2, sample_size_v1=0, sample_size_v2=0, ppl=1.84, wps=541.7, ups=0.54, wpb=1012.2, bsz=32, num_updates=37540, lr=8.85695e-06, gnorm=19.877, clip=100, loss_scale=16, train_wall=19, gb_free=11.6, wall=70565
2023-05-26 18:59:29 - progress_bar.py[line:272] - INFO: epoch 022:   1244 / 1732 loss=2.073, loss_v1=0, loss_v2=0, nll_loss=0.838, ntokens=1090.2, nsentences=32, sample_size=1090.2, sample_size_v1=0, sample_size_v2=0, ppl=1.79, wps=578.8, ups=0.53, wpb=1090.2, bsz=32, num_updates=37550, lr=8.85081e-06, gnorm=17.603, clip=100, loss_scale=16, train_wall=19, gb_free=11.4, wall=70584
2023-05-26 18:59:48 - progress_bar.py[line:272] - INFO: epoch 022:   1254 / 1732 loss=2.089, loss_v1=0, loss_v2=0, nll_loss=0.856, ntokens=1076, nsentences=32, sample_size=1076, sample_size_v1=0, sample_size_v2=0, ppl=1.81, wps=570.9, ups=0.53, wpb=1076, bsz=32, num_updates=37560, lr=8.84467e-06, gnorm=17.761, clip=100, loss_scale=16, train_wall=19, gb_free=11.6, wall=70602
2023-05-26 19:00:07 - progress_bar.py[line:272] - INFO: epoch 022:   1264 / 1732 loss=2.127, loss_v1=0, loss_v2=0, nll_loss=0.899, ntokens=1095.2, nsentences=32, sample_size=1095.2, sample_size_v1=0, sample_size_v2=0, ppl=1.86, wps=579.3, ups=0.53, wpb=1095.2, bsz=32, num_updates=37570, lr=8.83852e-06, gnorm=20.613, clip=100, loss_scale=16, train_wall=19, gb_free=10.7, wall=70621
2023-05-26 19:00:25 - progress_bar.py[line:272] - INFO: epoch 022:   1274 / 1732 loss=2.11, loss_v1=0, loss_v2=0, nll_loss=0.88, ntokens=1014.1, nsentences=32, sample_size=1014.1, sample_size_v1=0, sample_size_v2=0, ppl=1.84, wps=541.4, ups=0.53, wpb=1014.1, bsz=32, num_updates=37580, lr=8.83238e-06, gnorm=19.11, clip=100, loss_scale=16, train_wall=19, gb_free=11, wall=70640
2023-05-26 19:00:44 - progress_bar.py[line:272] - INFO: epoch 022:   1284 / 1732 loss=2.104, loss_v1=0, loss_v2=0, nll_loss=0.872, ntokens=1057.3, nsentences=32, sample_size=1057.3, sample_size_v1=0, sample_size_v2=0, ppl=1.83, wps=559.7, ups=0.53, wpb=1057.3, bsz=32, num_updates=37590, lr=8.82624e-06, gnorm=20.475, clip=100, loss_scale=16, train_wall=19, gb_free=11.5, wall=70659
2023-05-26 19:01:03 - progress_bar.py[line:272] - INFO: epoch 022:   1294 / 1732 loss=2.099, loss_v1=0, loss_v2=0, nll_loss=0.866, ntokens=1109.4, nsentences=32, sample_size=1109.4, sample_size_v1=0, sample_size_v2=0, ppl=1.82, wps=587.9, ups=0.53, wpb=1109.4, bsz=32, num_updates=37600, lr=8.8201e-06, gnorm=18.225, clip=100, loss_scale=16, train_wall=19, gb_free=11.5, wall=70678
2023-05-26 19:01:22 - progress_bar.py[line:272] - INFO: epoch 022:   1304 / 1732 loss=2.133, loss_v1=0, loss_v2=0, nll_loss=0.904, ntokens=1090.1, nsentences=32, sample_size=1090.1, sample_size_v1=0, sample_size_v2=0, ppl=1.87, wps=577.6, ups=0.53, wpb=1090.1, bsz=32, num_updates=37610, lr=8.81395e-06, gnorm=18.428, clip=100, loss_scale=16, train_wall=19, gb_free=10.7, wall=70697
2023-05-26 19:01:41 - progress_bar.py[line:272] - INFO: epoch 022:   1314 / 1732 loss=2.131, loss_v1=0, loss_v2=0, nll_loss=0.903, ntokens=1051.4, nsentences=32, sample_size=1051.4, sample_size_v1=0, sample_size_v2=0, ppl=1.87, wps=554.4, ups=0.53, wpb=1051.4, bsz=32, num_updates=37620, lr=8.80781e-06, gnorm=18.051, clip=100, loss_scale=16, train_wall=19, gb_free=11, wall=70716
2023-05-26 19:02:00 - progress_bar.py[line:272] - INFO: epoch 022:   1324 / 1732 loss=2.092, loss_v1=0, loss_v2=0, nll_loss=0.859, ntokens=1117, nsentences=32, sample_size=1117, sample_size_v1=0, sample_size_v2=0, ppl=1.81, wps=590.9, ups=0.53, wpb=1117, bsz=32, num_updates=37630, lr=8.80167e-06, gnorm=17.214, clip=100, loss_scale=16, train_wall=19, gb_free=11.4, wall=70735
2023-05-26 19:02:19 - progress_bar.py[line:272] - INFO: epoch 022:   1334 / 1732 loss=2.091, loss_v1=0, loss_v2=0, nll_loss=0.859, ntokens=1097.8, nsentences=32, sample_size=1097.8, sample_size_v1=0, sample_size_v2=0, ppl=1.81, wps=583.3, ups=0.53, wpb=1097.8, bsz=32, num_updates=37640, lr=8.79553e-06, gnorm=16.904, clip=100, loss_scale=16, train_wall=19, gb_free=11.4, wall=70753
2023-05-26 19:02:38 - progress_bar.py[line:272] - INFO: epoch 022:   1344 / 1732 loss=2.114, loss_v1=0, loss_v2=0, nll_loss=0.884, ntokens=1201.2, nsentences=32, sample_size=1201.2, sample_size_v1=0, sample_size_v2=0, ppl=1.84, wps=631.2, ups=0.53, wpb=1201.2, bsz=32, num_updates=37650, lr=8.78939e-06, gnorm=20.744, clip=100, loss_scale=16, train_wall=19, gb_free=10.9, wall=70772
2023-05-26 19:02:57 - progress_bar.py[line:272] - INFO: epoch 022:   1354 / 1732 loss=2.1, loss_v1=0, loss_v2=0, nll_loss=0.868, ntokens=1101.2, nsentences=32, sample_size=1101.2, sample_size_v1=0, sample_size_v2=0, ppl=1.83, wps=583, ups=0.53, wpb=1101.2, bsz=32, num_updates=37660, lr=8.78324e-06, gnorm=18.276, clip=100, loss_scale=16, train_wall=19, gb_free=11.5, wall=70791
2023-05-26 19:03:16 - progress_bar.py[line:272] - INFO: epoch 022:   1364 / 1732 loss=2.104, loss_v1=0, loss_v2=0, nll_loss=0.872, ntokens=1115.3, nsentences=32, sample_size=1115.3, sample_size_v1=0, sample_size_v2=0, ppl=1.83, wps=588.1, ups=0.53, wpb=1115.3, bsz=32, num_updates=37670, lr=8.7771e-06, gnorm=17.729, clip=100, loss_scale=16, train_wall=19, gb_free=10.9, wall=70810
2023-05-26 19:03:34 - progress_bar.py[line:272] - INFO: epoch 022:   1374 / 1732 loss=2.134, loss_v1=0, loss_v2=0, nll_loss=0.906, ntokens=1075.1, nsentences=32, sample_size=1075.1, sample_size_v1=0, sample_size_v2=0, ppl=1.87, wps=572.9, ups=0.53, wpb=1075.1, bsz=32, num_updates=37680, lr=8.77096e-06, gnorm=19.23, clip=100, loss_scale=16, train_wall=19, gb_free=11.6, wall=70829
2023-05-26 19:03:53 - progress_bar.py[line:272] - INFO: epoch 022:   1384 / 1732 loss=2.136, loss_v1=0, loss_v2=0, nll_loss=0.907, ntokens=1167.1, nsentences=32, sample_size=1167.1, sample_size_v1=0, sample_size_v2=0, ppl=1.87, wps=617.1, ups=0.53, wpb=1167.1, bsz=32, num_updates=37690, lr=8.76482e-06, gnorm=19.762, clip=100, loss_scale=16, train_wall=19, gb_free=10.8, wall=70848
2023-05-26 19:04:12 - progress_bar.py[line:272] - INFO: epoch 022:   1394 / 1732 loss=2.118, loss_v1=0, loss_v2=0, nll_loss=0.887, ntokens=1039.3, nsentences=32, sample_size=1039.3, sample_size_v1=0, sample_size_v2=0, ppl=1.85, wps=555.3, ups=0.53, wpb=1039.3, bsz=32, num_updates=37700, lr=8.75868e-06, gnorm=20.746, clip=100, loss_scale=16, train_wall=19, gb_free=10.6, wall=70867
2023-05-26 19:04:31 - progress_bar.py[line:272] - INFO: epoch 022:   1404 / 1732 loss=2.107, loss_v1=0, loss_v2=0, nll_loss=0.875, ntokens=1161.9, nsentences=32, sample_size=1161.9, sample_size_v1=0, sample_size_v2=0, ppl=1.83, wps=615.4, ups=0.53, wpb=1161.9, bsz=32, num_updates=37710, lr=8.75253e-06, gnorm=17.552, clip=100, loss_scale=16, train_wall=19, gb_free=10.2, wall=70886
2023-05-26 19:04:50 - progress_bar.py[line:272] - INFO: epoch 022:   1414 / 1732 loss=2.161, loss_v1=0, loss_v2=0, nll_loss=0.936, ntokens=1276, nsentences=32, sample_size=1276, sample_size_v1=0, sample_size_v2=0, ppl=1.91, wps=672, ups=0.53, wpb=1276, bsz=32, num_updates=37720, lr=8.74639e-06, gnorm=19.043, clip=100, loss_scale=16, train_wall=19, gb_free=10.6, wall=70905
2023-05-26 19:05:09 - progress_bar.py[line:272] - INFO: epoch 022:   1424 / 1732 loss=2.122, loss_v1=0, loss_v2=0, nll_loss=0.891, ntokens=1261.9, nsentences=32, sample_size=1261.9, sample_size_v1=0, sample_size_v2=0, ppl=1.85, wps=658.6, ups=0.52, wpb=1261.9, bsz=32, num_updates=37730, lr=8.74025e-06, gnorm=16.974, clip=100, loss_scale=16, train_wall=19, gb_free=10.6, wall=70924
2023-05-26 19:05:28 - progress_bar.py[line:272] - INFO: epoch 022:   1434 / 1732 loss=2.123, loss_v1=0, loss_v2=0, nll_loss=0.893, ntokens=1196.2, nsentences=32, sample_size=1196.2, sample_size_v1=0, sample_size_v2=0, ppl=1.86, wps=633.6, ups=0.53, wpb=1196.2, bsz=32, num_updates=37740, lr=8.73411e-06, gnorm=17.575, clip=100, loss_scale=16, train_wall=19, gb_free=11.1, wall=70943
2023-05-26 19:05:47 - progress_bar.py[line:272] - INFO: epoch 022:   1444 / 1732 loss=2.114, loss_v1=0, loss_v2=0, nll_loss=0.884, ntokens=1129.1, nsentences=32, sample_size=1129.1, sample_size_v1=0, sample_size_v2=0, ppl=1.85, wps=596.4, ups=0.53, wpb=1129.1, bsz=32, num_updates=37750, lr=8.72797e-06, gnorm=17.301, clip=100, loss_scale=16, train_wall=19, gb_free=10.6, wall=70962
2023-05-26 19:06:06 - progress_bar.py[line:272] - INFO: epoch 022:   1454 / 1732 loss=2.126, loss_v1=0, loss_v2=0, nll_loss=0.896, ntokens=1122, nsentences=32, sample_size=1122, sample_size_v1=0, sample_size_v2=0, ppl=1.86, wps=596.9, ups=0.53, wpb=1122, bsz=32, num_updates=37760, lr=8.72182e-06, gnorm=19.2, clip=100, loss_scale=16, train_wall=19, gb_free=10.8, wall=70980
2023-05-26 19:06:25 - progress_bar.py[line:272] - INFO: epoch 022:   1464 / 1732 loss=2.107, loss_v1=0, loss_v2=0, nll_loss=0.876, ntokens=1182.3, nsentences=32, sample_size=1182.3, sample_size_v1=0, sample_size_v2=0, ppl=1.83, wps=621.8, ups=0.53, wpb=1182.3, bsz=32, num_updates=37770, lr=8.71568e-06, gnorm=17.834, clip=100, loss_scale=16, train_wall=19, gb_free=11.2, wall=70999
2023-05-26 19:06:44 - progress_bar.py[line:272] - INFO: epoch 022:   1474 / 1732 loss=2.116, loss_v1=0, loss_v2=0, nll_loss=0.887, ntokens=1095.3, nsentences=32, sample_size=1095.3, sample_size_v1=0, sample_size_v2=0, ppl=1.85, wps=582.4, ups=0.53, wpb=1095.3, bsz=32, num_updates=37780, lr=8.70954e-06, gnorm=20.096, clip=100, loss_scale=16, train_wall=19, gb_free=11.3, wall=71018
2023-05-26 19:07:02 - progress_bar.py[line:272] - INFO: epoch 022:   1484 / 1732 loss=2.144, loss_v1=0, loss_v2=0, nll_loss=0.917, ntokens=1096.5, nsentences=32, sample_size=1096.5, sample_size_v1=0, sample_size_v2=0, ppl=1.89, wps=582.4, ups=0.53, wpb=1096.5, bsz=32, num_updates=37790, lr=8.7034e-06, gnorm=19.873, clip=100, loss_scale=16, train_wall=19, gb_free=10.6, wall=71037
2023-05-26 19:07:21 - progress_bar.py[line:272] - INFO: epoch 022:   1494 / 1732 loss=2.112, loss_v1=0, loss_v2=0, nll_loss=0.88, ntokens=1106.4, nsentences=32, sample_size=1106.4, sample_size_v1=0, sample_size_v2=0, ppl=1.84, wps=584.7, ups=0.53, wpb=1106.4, bsz=32, num_updates=37800, lr=8.69725e-06, gnorm=19.815, clip=100, loss_scale=16, train_wall=19, gb_free=11, wall=71056
2023-05-26 19:07:40 - progress_bar.py[line:272] - INFO: epoch 022:   1504 / 1732 loss=2.087, loss_v1=0, loss_v2=0, nll_loss=0.852, ntokens=1153.1, nsentences=32, sample_size=1153.1, sample_size_v1=0, sample_size_v2=0, ppl=1.8, wps=610.2, ups=0.53, wpb=1153.1, bsz=32, num_updates=37810, lr=8.69111e-06, gnorm=19.573, clip=100, loss_scale=16, train_wall=19, gb_free=10.9, wall=71075
2023-05-26 19:07:59 - progress_bar.py[line:272] - INFO: epoch 022:   1514 / 1732 loss=2.126, loss_v1=0, loss_v2=0, nll_loss=0.896, ntokens=1041.2, nsentences=32, sample_size=1041.2, sample_size_v1=0, sample_size_v2=0, ppl=1.86, wps=556.2, ups=0.53, wpb=1041.2, bsz=32, num_updates=37820, lr=8.68497e-06, gnorm=20.016, clip=100, loss_scale=16, train_wall=19, gb_free=11.7, wall=71094
2023-05-26 19:08:18 - progress_bar.py[line:272] - INFO: epoch 022:   1524 / 1732 loss=2.152, loss_v1=0, loss_v2=0, nll_loss=0.927, ntokens=1034.8, nsentences=32, sample_size=1034.8, sample_size_v1=0, sample_size_v2=0, ppl=1.9, wps=552.5, ups=0.53, wpb=1034.8, bsz=32, num_updates=37830, lr=8.67883e-06, gnorm=20.905, clip=100, loss_scale=16, train_wall=19, gb_free=10.5, wall=71112
2023-05-26 19:08:37 - progress_bar.py[line:272] - INFO: epoch 022:   1534 / 1732 loss=2.133, loss_v1=0, loss_v2=0, nll_loss=0.907, ntokens=1092.4, nsentences=32, sample_size=1092.4, sample_size_v1=0, sample_size_v2=0, ppl=1.87, wps=576.3, ups=0.53, wpb=1092.4, bsz=32, num_updates=37840, lr=8.67269e-06, gnorm=21.039, clip=100, loss_scale=16, train_wall=19, gb_free=11, wall=71131
2023-05-26 19:08:56 - progress_bar.py[line:272] - INFO: epoch 022:   1544 / 1732 loss=2.104, loss_v1=0, loss_v2=0, nll_loss=0.872, ntokens=1091.8, nsentences=32, sample_size=1091.8, sample_size_v1=0, sample_size_v2=0, ppl=1.83, wps=578.6, ups=0.53, wpb=1091.8, bsz=32, num_updates=37850, lr=8.66654e-06, gnorm=20.708, clip=100, loss_scale=16, train_wall=19, gb_free=11.5, wall=71150
2023-05-26 19:09:14 - progress_bar.py[line:272] - INFO: epoch 022:   1554 / 1732 loss=2.096, loss_v1=0, loss_v2=0, nll_loss=0.863, ntokens=1040, nsentences=32, sample_size=1040, sample_size_v1=0, sample_size_v2=0, ppl=1.82, wps=552.6, ups=0.53, wpb=1040, bsz=32, num_updates=37860, lr=8.6604e-06, gnorm=19.927, clip=100, loss_scale=16, train_wall=19, gb_free=11.4, wall=71169
2023-05-26 19:09:33 - progress_bar.py[line:272] - INFO: epoch 022:   1564 / 1732 loss=2.123, loss_v1=0, loss_v2=0, nll_loss=0.894, ntokens=1120.2, nsentences=32, sample_size=1120.2, sample_size_v1=0, sample_size_v2=0, ppl=1.86, wps=595.2, ups=0.53, wpb=1120.2, bsz=32, num_updates=37870, lr=8.65426e-06, gnorm=19.702, clip=100, loss_scale=16, train_wall=19, gb_free=11.6, wall=71188
2023-05-26 19:09:52 - progress_bar.py[line:272] - INFO: epoch 022:   1574 / 1732 loss=2.135, loss_v1=0, loss_v2=0, nll_loss=0.906, ntokens=1055.9, nsentences=32, sample_size=1055.9, sample_size_v1=0, sample_size_v2=0, ppl=1.87, wps=559, ups=0.53, wpb=1055.9, bsz=32, num_updates=37880, lr=8.64812e-06, gnorm=21.234, clip=100, loss_scale=16, train_wall=19, gb_free=11.2, wall=71207
2023-05-26 19:10:11 - progress_bar.py[line:272] - INFO: epoch 022:   1584 / 1732 loss=2.13, loss_v1=0, loss_v2=0, nll_loss=0.902, ntokens=1026.8, nsentences=32, sample_size=1026.8, sample_size_v1=0, sample_size_v2=0, ppl=1.87, wps=546.2, ups=0.53, wpb=1026.8, bsz=32, num_updates=37890, lr=8.64198e-06, gnorm=20.85, clip=100, loss_scale=16, train_wall=19, gb_free=10.8, wall=71226
2023-05-26 19:10:30 - progress_bar.py[line:272] - INFO: epoch 022:   1594 / 1732 loss=2.098, loss_v1=0, loss_v2=0, nll_loss=0.866, ntokens=1068.7, nsentences=32, sample_size=1068.7, sample_size_v1=0, sample_size_v2=0, ppl=1.82, wps=565.9, ups=0.53, wpb=1068.7, bsz=32, num_updates=37900, lr=8.63583e-06, gnorm=18.386, clip=100, loss_scale=16, train_wall=19, gb_free=11.3, wall=71244
2023-05-26 19:10:49 - progress_bar.py[line:272] - INFO: epoch 022:   1604 / 1732 loss=2.097, loss_v1=0, loss_v2=0, nll_loss=0.864, ntokens=1089, nsentences=32, sample_size=1089, sample_size_v1=0, sample_size_v2=0, ppl=1.82, wps=577.8, ups=0.53, wpb=1089, bsz=32, num_updates=37910, lr=8.62969e-06, gnorm=17.921, clip=100, loss_scale=16, train_wall=19, gb_free=10.8, wall=71263
2023-05-26 19:11:08 - progress_bar.py[line:272] - INFO: epoch 022:   1614 / 1732 loss=2.092, loss_v1=0, loss_v2=0, nll_loss=0.859, ntokens=1186.1, nsentences=32, sample_size=1186.1, sample_size_v1=0, sample_size_v2=0, ppl=1.81, wps=622.6, ups=0.52, wpb=1186.1, bsz=32, num_updates=37920, lr=8.62355e-06, gnorm=19.789, clip=100, loss_scale=16, train_wall=19, gb_free=10.9, wall=71282
2023-05-26 19:11:27 - progress_bar.py[line:272] - INFO: epoch 022:   1624 / 1732 loss=2.121, loss_v1=0, loss_v2=0, nll_loss=0.892, ntokens=1074.1, nsentences=32, sample_size=1074.1, sample_size_v1=0, sample_size_v2=0, ppl=1.86, wps=568, ups=0.53, wpb=1074.1, bsz=32, num_updates=37930, lr=8.61741e-06, gnorm=18.446, clip=100, loss_scale=16, train_wall=19, gb_free=11.6, wall=71301
2023-05-26 19:11:45 - progress_bar.py[line:272] - INFO: epoch 022:   1634 / 1732 loss=2.098, loss_v1=0, loss_v2=0, nll_loss=0.865, ntokens=1178.9, nsentences=32, sample_size=1178.9, sample_size_v1=0, sample_size_v2=0, ppl=1.82, wps=624, ups=0.53, wpb=1178.9, bsz=32, num_updates=37940, lr=8.61126e-06, gnorm=18.554, clip=100, loss_scale=16, train_wall=19, gb_free=11.5, wall=71320
2023-05-26 19:12:05 - progress_bar.py[line:272] - INFO: epoch 022:   1644 / 1732 loss=2.101, loss_v1=0, loss_v2=0, nll_loss=0.868, ntokens=1265.1, nsentences=32, sample_size=1265.1, sample_size_v1=0, sample_size_v2=0, ppl=1.83, wps=664.9, ups=0.53, wpb=1265.1, bsz=32, num_updates=37950, lr=8.60512e-06, gnorm=18.476, clip=100, loss_scale=16, train_wall=19, gb_free=10.9, wall=71339
2023-05-26 19:12:23 - progress_bar.py[line:272] - INFO: epoch 022:   1654 / 1732 loss=2.126, loss_v1=0, loss_v2=0, nll_loss=0.896, ntokens=974.9, nsentences=32, sample_size=974.9, sample_size_v1=0, sample_size_v2=0, ppl=1.86, wps=520.5, ups=0.53, wpb=974.9, bsz=32, num_updates=37960, lr=8.59898e-06, gnorm=18.906, clip=100, loss_scale=16, train_wall=19, gb_free=11.5, wall=71358
2023-05-26 19:12:42 - progress_bar.py[line:272] - INFO: epoch 022:   1664 / 1732 loss=2.131, loss_v1=0, loss_v2=0, nll_loss=0.903, ntokens=1041.8, nsentences=32, sample_size=1041.8, sample_size_v1=0, sample_size_v2=0, ppl=1.87, wps=551.3, ups=0.53, wpb=1041.8, bsz=32, num_updates=37970, lr=8.59284e-06, gnorm=20.471, clip=100, loss_scale=16, train_wall=19, gb_free=11.1, wall=71377
2023-05-26 19:13:01 - progress_bar.py[line:272] - INFO: epoch 022:   1674 / 1732 loss=2.095, loss_v1=0, loss_v2=0, nll_loss=0.862, ntokens=1052.3, nsentences=32, sample_size=1052.3, sample_size_v1=0, sample_size_v2=0, ppl=1.82, wps=561.5, ups=0.53, wpb=1052.3, bsz=32, num_updates=37980, lr=8.5867e-06, gnorm=20.418, clip=100, loss_scale=16, train_wall=19, gb_free=11.3, wall=71396
2023-05-26 19:13:20 - progress_bar.py[line:272] - INFO: epoch 022:   1684 / 1732 loss=2.075, loss_v1=0, loss_v2=0, nll_loss=0.839, ntokens=1169.1, nsentences=32, sample_size=1169.1, sample_size_v1=0, sample_size_v2=0, ppl=1.79, wps=614.9, ups=0.53, wpb=1169.1, bsz=32, num_updates=37990, lr=8.58055e-06, gnorm=18.394, clip=100, loss_scale=32, train_wall=19, gb_free=11.5, wall=71415
2023-05-26 19:13:39 - progress_bar.py[line:272] - INFO: epoch 022:   1694 / 1732 loss=2.109, loss_v1=0, loss_v2=0, nll_loss=0.879, ntokens=1257.3, nsentences=32, sample_size=1257.3, sample_size_v1=0, sample_size_v2=0, ppl=1.84, wps=648.3, ups=0.52, wpb=1257.3, bsz=32, num_updates=38000, lr=8.57441e-06, gnorm=17.438, clip=100, loss_scale=32, train_wall=19, gb_free=10.1, wall=71434
2023-05-26 19:13:58 - progress_bar.py[line:272] - INFO: epoch 022:   1704 / 1732 loss=2.123, loss_v1=0, loss_v2=0, nll_loss=0.894, ntokens=1232.6, nsentences=32, sample_size=1232.6, sample_size_v1=0, sample_size_v2=0, ppl=1.86, wps=647.8, ups=0.53, wpb=1232.6, bsz=32, num_updates=38010, lr=8.56827e-06, gnorm=18.151, clip=100, loss_scale=32, train_wall=19, gb_free=11.3, wall=71453
2023-05-26 19:14:17 - progress_bar.py[line:272] - INFO: epoch 022:   1714 / 1732 loss=2.112, loss_v1=0, loss_v2=0, nll_loss=0.88, ntokens=1181.2, nsentences=32, sample_size=1181.2, sample_size_v1=0, sample_size_v2=0, ppl=1.84, wps=622.9, ups=0.53, wpb=1181.2, bsz=32, num_updates=38020, lr=8.56213e-06, gnorm=19.452, clip=100, loss_scale=32, train_wall=19, gb_free=11.2, wall=71472
2023-05-26 19:14:36 - progress_bar.py[line:272] - INFO: epoch 022:   1724 / 1732 loss=2.101, loss_v1=0, loss_v2=0, nll_loss=0.869, ntokens=1135.1, nsentences=32, sample_size=1135.1, sample_size_v1=0, sample_size_v2=0, ppl=1.83, wps=598.4, ups=0.53, wpb=1135.1, bsz=32, num_updates=38030, lr=8.55599e-06, gnorm=18.533, clip=100, loss_scale=32, train_wall=19, gb_free=11.7, wall=71491
2023-05-26 19:14:50 - train.py[line:332] - INFO: end of epoch 22 (average epoch stats below)
2023-05-26 19:14:50 - progress_bar.py[line:282] - INFO: epoch 022 | loss 2.118 | loss_v1 0 | loss_v2 0 | nll_loss 0.889 | ntokens 1051.67 | nsentences 31.986 | sample_size 1051.67 | sample_size_v1 0 | sample_size_v2 0 | ppl 1.85 | wps 559.5 | ups 0.53 | wpb 1051.7 | bsz 32 | num_updates 38038 | lr 8.55107e-06 | gnorm 19.185 | clip 100 | loss_scale 32 | train_wall 3243 | gb_free 11.7 | wall 71505
2023-05-26 19:14:50 - trainer.py[line:639] - INFO: loading train data for epoch 23
local datafile ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 0 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 0 finished initializing row_count and line_idx-to-offset mapping
file ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 0 row count 55400 total row count 55400
slice_id 0 seek offset 0
2023-05-26 19:14:52 - trainer.py[line:703] - INFO: begin training epoch 23
2023-05-26 19:14:52 - train.py[line:305] - INFO: Start iterating over samples
2023-05-26 19:14:56 - progress_bar.py[line:272] - INFO: epoch 023:      2 / 1732 loss=2.16, loss_v1=0, loss_v2=0, nll_loss=0.935, ntokens=1104.4, nsentences=29.6, sample_size=1104.4, sample_size_v1=0, sample_size_v2=0, ppl=1.91, wps=563.4, ups=0.51, wpb=1104.4, bsz=29.6, num_updates=38040, lr=8.54984e-06, gnorm=19.15, clip=100, loss_scale=32, train_wall=18, gb_free=10.9, wall=71511
2023-05-26 19:15:00 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2023-05-26 19:15:17 - progress_bar.py[line:272] - INFO: epoch 023:     13 / 1732 loss=2.093, loss_v1=0, loss_v2=0, nll_loss=0.86, ntokens=1056.4, nsentences=32, sample_size=1056.4, sample_size_v1=0, sample_size_v2=0, ppl=1.81, wps=509.4, ups=0.48, wpb=1056.4, bsz=32, num_updates=38050, lr=8.5437e-06, gnorm=25.379, clip=100, loss_scale=16, train_wall=21, gb_free=11, wall=71531
2023-05-26 19:15:35 - progress_bar.py[line:272] - INFO: epoch 023:     23 / 1732 loss=2.052, loss_v1=0, loss_v2=0, nll_loss=0.813, ntokens=1082, nsentences=32, sample_size=1082, sample_size_v1=0, sample_size_v2=0, ppl=1.76, wps=574.1, ups=0.53, wpb=1082, bsz=32, num_updates=38060, lr=8.53756e-06, gnorm=22.967, clip=100, loss_scale=16, train_wall=19, gb_free=11.4, wall=71550
2023-05-26 19:15:54 - progress_bar.py[line:272] - INFO: epoch 023:     33 / 1732 loss=2.024, loss_v1=0, loss_v2=0, nll_loss=0.781, ntokens=1032.3, nsentences=32, sample_size=1032.3, sample_size_v1=0, sample_size_v2=0, ppl=1.72, wps=545.2, ups=0.53, wpb=1032.3, bsz=32, num_updates=38070, lr=8.53142e-06, gnorm=20.178, clip=100, loss_scale=16, train_wall=19, gb_free=10.2, wall=71569
2023-05-26 19:16:13 - progress_bar.py[line:272] - INFO: epoch 023:     43 / 1732 loss=1.958, loss_v1=0, loss_v2=0, nll_loss=0.71, ntokens=1156.8, nsentences=32, sample_size=1156.8, sample_size_v1=0, sample_size_v2=0, ppl=1.64, wps=610.6, ups=0.53, wpb=1156.8, bsz=32, num_updates=38080, lr=8.52527e-06, gnorm=19.498, clip=100, loss_scale=16, train_wall=19, gb_free=11, wall=71588
2023-05-26 19:16:32 - progress_bar.py[line:272] - INFO: epoch 023:     53 / 1732 loss=2.004, loss_v1=0, loss_v2=0, nll_loss=0.762, ntokens=1016.6, nsentences=32, sample_size=1016.6, sample_size_v1=0, sample_size_v2=0, ppl=1.7, wps=538, ups=0.53, wpb=1016.6, bsz=32, num_updates=38090, lr=8.51913e-06, gnorm=20.786, clip=100, loss_scale=16, train_wall=19, gb_free=11.4, wall=71607
2023-05-26 19:16:51 - progress_bar.py[line:272] - INFO: epoch 023:     63 / 1732 loss=1.852, loss_v1=0, loss_v2=0, nll_loss=0.592, ntokens=1239.4, nsentences=32, sample_size=1239.4, sample_size_v1=0, sample_size_v2=0, ppl=1.51, wps=650, ups=0.52, wpb=1239.4, bsz=32, num_updates=38100, lr=8.51299e-06, gnorm=17.312, clip=100, loss_scale=16, train_wall=19, gb_free=10.3, wall=71626
2023-05-26 19:17:11 - progress_bar.py[line:272] - INFO: epoch 023:     73 / 1732 loss=1.922, loss_v1=0, loss_v2=0, nll_loss=0.67, ntokens=1389.6, nsentences=32, sample_size=1389.6, sample_size_v1=0, sample_size_v2=0, ppl=1.59, wps=713.3, ups=0.51, wpb=1389.6, bsz=32, num_updates=38110, lr=8.50685e-06, gnorm=13.328, clip=100, loss_scale=16, train_wall=19, gb_free=10, wall=71645
2023-05-26 19:17:30 - progress_bar.py[line:272] - INFO: epoch 023:     83 / 1732 loss=1.952, loss_v1=0, loss_v2=0, nll_loss=0.704, ntokens=1166.3, nsentences=32, sample_size=1166.3, sample_size_v1=0, sample_size_v2=0, ppl=1.63, wps=606.6, ups=0.52, wpb=1166.3, bsz=32, num_updates=38120, lr=8.50071e-06, gnorm=15, clip=100, loss_scale=16, train_wall=19, gb_free=10.2, wall=71665
2023-05-26 19:17:49 - progress_bar.py[line:272] - INFO: epoch 023:     93 / 1732 loss=1.935, loss_v1=0, loss_v2=0, nll_loss=0.684, ntokens=1099.1, nsentences=32, sample_size=1099.1, sample_size_v1=0, sample_size_v2=0, ppl=1.61, wps=578.2, ups=0.53, wpb=1099.1, bsz=32, num_updates=38130, lr=8.49456e-06, gnorm=16.376, clip=100, loss_scale=16, train_wall=19, gb_free=11, wall=71684
2023-05-26 19:18:08 - progress_bar.py[line:272] - INFO: epoch 023:    103 / 1732 loss=2.048, loss_v1=0, loss_v2=0, nll_loss=0.809, ntokens=976, nsentences=32, sample_size=976, sample_size_v1=0, sample_size_v2=0, ppl=1.75, wps=520.9, ups=0.53, wpb=976, bsz=32, num_updates=38140, lr=8.48842e-06, gnorm=20.942, clip=100, loss_scale=16, train_wall=19, gb_free=11.5, wall=71702
2023-05-26 19:18:27 - progress_bar.py[line:272] - INFO: epoch 023:    113 / 1732 loss=2.128, loss_v1=0, loss_v2=0, nll_loss=0.899, ntokens=1030.9, nsentences=32, sample_size=1030.9, sample_size_v1=0, sample_size_v2=0, ppl=1.87, wps=545.1, ups=0.53, wpb=1030.9, bsz=32, num_updates=38150, lr=8.48228e-06, gnorm=21.551, clip=100, loss_scale=16, train_wall=19, gb_free=10.8, wall=71721
2023-05-26 19:18:46 - progress_bar.py[line:272] - INFO: epoch 023:    123 / 1732 loss=2.114, loss_v1=0, loss_v2=0, nll_loss=0.885, ntokens=1142.2, nsentences=32, sample_size=1142.2, sample_size_v1=0, sample_size_v2=0, ppl=1.85, wps=594.6, ups=0.52, wpb=1142.2, bsz=32, num_updates=38160, lr=8.47614e-06, gnorm=20.399, clip=100, loss_scale=16, train_wall=19, gb_free=10.7, wall=71741
2023-05-26 19:19:05 - progress_bar.py[line:272] - INFO: epoch 023:    133 / 1732 loss=2.08, loss_v1=0, loss_v2=0, nll_loss=0.845, ntokens=1207.4, nsentences=32, sample_size=1207.4, sample_size_v1=0, sample_size_v2=0, ppl=1.8, wps=629.7, ups=0.52, wpb=1207.4, bsz=32, num_updates=38170, lr=8.47e-06, gnorm=19.636, clip=100, loss_scale=16, train_wall=19, gb_free=10.8, wall=71760
2023-05-26 19:19:24 - progress_bar.py[line:272] - INFO: epoch 023:    143 / 1732 loss=2.068, loss_v1=0, loss_v2=0, nll_loss=0.832, ntokens=1226.6, nsentences=32, sample_size=1226.6, sample_size_v1=0, sample_size_v2=0, ppl=1.78, wps=638.2, ups=0.52, wpb=1226.6, bsz=32, num_updates=38180, lr=8.46385e-06, gnorm=19.529, clip=100, loss_scale=16, train_wall=19, gb_free=10.2, wall=71779
2023-05-26 19:19:44 - progress_bar.py[line:272] - INFO: epoch 023:    153 / 1732 loss=2.06, loss_v1=0, loss_v2=0, nll_loss=0.823, ntokens=1152.6, nsentences=32, sample_size=1152.6, sample_size_v1=0, sample_size_v2=0, ppl=1.77, wps=598.4, ups=0.52, wpb=1152.6, bsz=32, num_updates=38190, lr=8.45771e-06, gnorm=19.182, clip=100, loss_scale=16, train_wall=19, gb_free=10.3, wall=71798
2023-05-26 19:20:03 - progress_bar.py[line:272] - INFO: epoch 023:    163 / 1732 loss=2.071, loss_v1=0, loss_v2=0, nll_loss=0.835, ntokens=1079.7, nsentences=32, sample_size=1079.7, sample_size_v1=0, sample_size_v2=0, ppl=1.78, wps=569.7, ups=0.53, wpb=1079.7, bsz=32, num_updates=38200, lr=8.45157e-06, gnorm=23.516, clip=100, loss_scale=16, train_wall=19, gb_free=11.5, wall=71817
2023-05-26 19:20:21 - progress_bar.py[line:272] - INFO: epoch 023:    173 / 1732 loss=2.072, loss_v1=0, loss_v2=0, nll_loss=0.837, ntokens=936.5, nsentences=32, sample_size=936.5, sample_size_v1=0, sample_size_v2=0, ppl=1.79, wps=496.9, ups=0.53, wpb=936.5, bsz=32, num_updates=38210, lr=8.44543e-06, gnorm=23.914, clip=100, loss_scale=16, train_wall=19, gb_free=10.7, wall=71836
2023-05-26 19:20:40 - progress_bar.py[line:272] - INFO: epoch 023:    183 / 1732 loss=2.048, loss_v1=0, loss_v2=0, nll_loss=0.81, ntokens=1184.7, nsentences=32, sample_size=1184.7, sample_size_v1=0, sample_size_v2=0, ppl=1.75, wps=620.9, ups=0.52, wpb=1184.7, bsz=32, num_updates=38220, lr=8.43929e-06, gnorm=19.634, clip=100, loss_scale=16, train_wall=19, gb_free=11.3, wall=71855
2023-05-26 19:21:00 - progress_bar.py[line:272] - INFO: epoch 023:    193 / 1732 loss=2.048, loss_v1=0, loss_v2=0, nll_loss=0.809, ntokens=1122.8, nsentences=32, sample_size=1122.8, sample_size_v1=0, sample_size_v2=0, ppl=1.75, wps=589.5, ups=0.53, wpb=1122.8, bsz=32, num_updates=38230, lr=8.43314e-06, gnorm=21.11, clip=100, loss_scale=16, train_wall=19, gb_free=11.2, wall=71874
2023-05-26 19:21:18 - progress_bar.py[line:272] - INFO: epoch 023:    203 / 1732 loss=2.108, loss_v1=0, loss_v2=0, nll_loss=0.876, ntokens=1086.7, nsentences=32, sample_size=1086.7, sample_size_v1=0, sample_size_v2=0, ppl=1.84, wps=578, ups=0.53, wpb=1086.7, bsz=32, num_updates=38240, lr=8.427e-06, gnorm=19.516, clip=100, loss_scale=16, train_wall=19, gb_free=11.3, wall=71893
2023-05-26 19:21:37 - progress_bar.py[line:272] - INFO: epoch 023:    213 / 1732 loss=2.108, loss_v1=0, loss_v2=0, nll_loss=0.877, ntokens=1044.9, nsentences=32, sample_size=1044.9, sample_size_v1=0, sample_size_v2=0, ppl=1.84, wps=557.2, ups=0.53, wpb=1044.9, bsz=32, num_updates=38250, lr=8.42086e-06, gnorm=19.68, clip=100, loss_scale=16, train_wall=19, gb_free=11.2, wall=71912
2023-05-26 19:21:56 - progress_bar.py[line:272] - INFO: epoch 023:    223 / 1732 loss=2.142, loss_v1=0, loss_v2=0, nll_loss=0.917, ntokens=1134.6, nsentences=32, sample_size=1134.6, sample_size_v1=0, sample_size_v2=0, ppl=1.89, wps=605.4, ups=0.53, wpb=1134.6, bsz=32, num_updates=38260, lr=8.41472e-06, gnorm=19.413, clip=100, loss_scale=16, train_wall=19, gb_free=11.3, wall=71930
2023-05-26 19:22:14 - progress_bar.py[line:272] - INFO: epoch 023:    233 / 1732 loss=2.152, loss_v1=0, loss_v2=0, nll_loss=0.927, ntokens=1078.6, nsentences=32, sample_size=1078.6, sample_size_v1=0, sample_size_v2=0, ppl=1.9, wps=578.4, ups=0.54, wpb=1078.6, bsz=32, num_updates=38270, lr=8.40857e-06, gnorm=19.519, clip=100, loss_scale=16, train_wall=19, gb_free=11.5, wall=71949
2023-05-26 19:22:33 - progress_bar.py[line:272] - INFO: epoch 023:    243 / 1732 loss=2.141, loss_v1=0, loss_v2=0, nll_loss=0.912, ntokens=1123.3, nsentences=32, sample_size=1123.3, sample_size_v1=0, sample_size_v2=0, ppl=1.88, wps=597.2, ups=0.53, wpb=1123.3, bsz=32, num_updates=38280, lr=8.40243e-06, gnorm=16.584, clip=100, loss_scale=16, train_wall=19, gb_free=11.5, wall=71968
2023-05-26 19:22:52 - progress_bar.py[line:272] - INFO: epoch 023:    253 / 1732 loss=2.151, loss_v1=0, loss_v2=0, nll_loss=0.925, ntokens=1167.4, nsentences=32, sample_size=1167.4, sample_size_v1=0, sample_size_v2=0, ppl=1.9, wps=621.4, ups=0.53, wpb=1167.4, bsz=32, num_updates=38290, lr=8.39629e-06, gnorm=19.09, clip=100, loss_scale=16, train_wall=19, gb_free=10.8, wall=71987
2023-05-26 19:23:11 - progress_bar.py[line:272] - INFO: epoch 023:    263 / 1732 loss=2.132, loss_v1=0, loss_v2=0, nll_loss=0.903, ntokens=1123.9, nsentences=32, sample_size=1123.9, sample_size_v1=0, sample_size_v2=0, ppl=1.87, wps=601.8, ups=0.54, wpb=1123.9, bsz=32, num_updates=38300, lr=8.39015e-06, gnorm=16.782, clip=100, loss_scale=16, train_wall=19, gb_free=10.8, wall=72005
2023-05-26 19:23:30 - progress_bar.py[line:272] - INFO: epoch 023:    273 / 1732 loss=2.128, loss_v1=0, loss_v2=0, nll_loss=0.9, ntokens=1154.8, nsentences=32, sample_size=1154.8, sample_size_v1=0, sample_size_v2=0, ppl=1.87, wps=613.3, ups=0.53, wpb=1154.8, bsz=32, num_updates=38310, lr=8.38401e-06, gnorm=17.266, clip=100, loss_scale=16, train_wall=19, gb_free=11, wall=72024
2023-05-26 19:23:49 - progress_bar.py[line:272] - INFO: epoch 023:    283 / 1732 loss=2.159, loss_v1=0, loss_v2=0, nll_loss=0.934, ntokens=1146.7, nsentences=32, sample_size=1146.7, sample_size_v1=0, sample_size_v2=0, ppl=1.91, wps=606.7, ups=0.53, wpb=1146.7, bsz=32, num_updates=38320, lr=8.37786e-06, gnorm=17.854, clip=100, loss_scale=16, train_wall=19, gb_free=11.2, wall=72043
2023-05-26 19:24:07 - progress_bar.py[line:272] - INFO: epoch 023:    293 / 1732 loss=2.117, loss_v1=0, loss_v2=0, nll_loss=0.887, ntokens=1122.6, nsentences=32, sample_size=1122.6, sample_size_v1=0, sample_size_v2=0, ppl=1.85, wps=599.3, ups=0.53, wpb=1122.6, bsz=32, num_updates=38330, lr=8.37172e-06, gnorm=18.283, clip=100, loss_scale=16, train_wall=19, gb_free=10.3, wall=72062
2023-05-26 19:24:26 - progress_bar.py[line:272] - INFO: epoch 023:    303 / 1732 loss=2.121, loss_v1=0, loss_v2=0, nll_loss=0.891, ntokens=1117.4, nsentences=32, sample_size=1117.4, sample_size_v1=0, sample_size_v2=0, ppl=1.86, wps=597.4, ups=0.53, wpb=1117.4, bsz=32, num_updates=38340, lr=8.36558e-06, gnorm=21.101, clip=100, loss_scale=16, train_wall=19, gb_free=11.1, wall=72081
2023-05-26 19:24:45 - progress_bar.py[line:272] - INFO: epoch 023:    313 / 1732 loss=2.133, loss_v1=0, loss_v2=0, nll_loss=0.906, ntokens=1045.5, nsentences=32, sample_size=1045.5, sample_size_v1=0, sample_size_v2=0, ppl=1.87, wps=560.2, ups=0.54, wpb=1045.5, bsz=32, num_updates=38350, lr=8.35944e-06, gnorm=19.276, clip=100, loss_scale=16, train_wall=19, gb_free=11.7, wall=72099
2023-05-26 19:25:03 - progress_bar.py[line:272] - INFO: epoch 023:    323 / 1732 loss=2.152, loss_v1=0, loss_v2=0, nll_loss=0.927, ntokens=1005.7, nsentences=32, sample_size=1005.7, sample_size_v1=0, sample_size_v2=0, ppl=1.9, wps=541.2, ups=0.54, wpb=1005.7, bsz=32, num_updates=38360, lr=8.3533e-06, gnorm=19.912, clip=100, loss_scale=16, train_wall=19, gb_free=11.2, wall=72118
2023-05-26 19:25:22 - progress_bar.py[line:272] - INFO: epoch 023:    333 / 1732 loss=2.16, loss_v1=0, loss_v2=0, nll_loss=0.936, ntokens=1019.2, nsentences=32, sample_size=1019.2, sample_size_v1=0, sample_size_v2=0, ppl=1.91, wps=549.6, ups=0.54, wpb=1019.2, bsz=32, num_updates=38370, lr=8.34715e-06, gnorm=20.641, clip=100, loss_scale=16, train_wall=19, gb_free=11.3, wall=72136
2023-05-26 19:25:40 - progress_bar.py[line:272] - INFO: epoch 023:    343 / 1732 loss=2.105, loss_v1=0, loss_v2=0, nll_loss=0.874, ntokens=919.2, nsentences=32, sample_size=919.2, sample_size_v1=0, sample_size_v2=0, ppl=1.83, wps=498.1, ups=0.54, wpb=919.2, bsz=32, num_updates=38380, lr=8.34101e-06, gnorm=20.483, clip=100, loss_scale=16, train_wall=18, gb_free=11.8, wall=72155
2023-05-26 19:25:59 - progress_bar.py[line:272] - INFO: epoch 023:    353 / 1732 loss=2.133, loss_v1=0, loss_v2=0, nll_loss=0.906, ntokens=968.9, nsentences=32, sample_size=968.9, sample_size_v1=0, sample_size_v2=0, ppl=1.87, wps=522.1, ups=0.54, wpb=968.9, bsz=32, num_updates=38390, lr=8.33487e-06, gnorm=20.187, clip=100, loss_scale=16, train_wall=19, gb_free=10.6, wall=72173
2023-05-26 19:26:17 - progress_bar.py[line:272] - INFO: epoch 023:    363 / 1732 loss=2.171, loss_v1=0, loss_v2=0, nll_loss=0.949, ntokens=932.1, nsentences=32, sample_size=932.1, sample_size_v1=0, sample_size_v2=0, ppl=1.93, wps=503.5, ups=0.54, wpb=932.1, bsz=32, num_updates=38400, lr=8.32873e-06, gnorm=22.512, clip=100, loss_scale=16, train_wall=18, gb_free=11.5, wall=72192
2023-05-26 19:26:36 - progress_bar.py[line:272] - INFO: epoch 023:    373 / 1732 loss=2.142, loss_v1=0, loss_v2=0, nll_loss=0.916, ntokens=967.4, nsentences=32, sample_size=967.4, sample_size_v1=0, sample_size_v2=0, ppl=1.89, wps=522.3, ups=0.54, wpb=967.4, bsz=32, num_updates=38410, lr=8.32258e-06, gnorm=22.272, clip=100, loss_scale=16, train_wall=18, gb_free=11.8, wall=72210
2023-05-26 19:26:54 - progress_bar.py[line:272] - INFO: epoch 023:    383 / 1732 loss=2.166, loss_v1=0, loss_v2=0, nll_loss=0.941, ntokens=1070.5, nsentences=32, sample_size=1070.5, sample_size_v1=0, sample_size_v2=0, ppl=1.92, wps=577.8, ups=0.54, wpb=1070.5, bsz=32, num_updates=38420, lr=8.31644e-06, gnorm=19.895, clip=100, loss_scale=16, train_wall=18, gb_free=11.4, wall=72229
2023-05-26 19:27:13 - progress_bar.py[line:272] - INFO: epoch 023:    393 / 1732 loss=2.147, loss_v1=0, loss_v2=0, nll_loss=0.92, ntokens=990.3, nsentences=32, sample_size=990.3, sample_size_v1=0, sample_size_v2=0, ppl=1.89, wps=532.8, ups=0.54, wpb=990.3, bsz=32, num_updates=38430, lr=8.3103e-06, gnorm=20.93, clip=100, loss_scale=16, train_wall=19, gb_free=11.6, wall=72248
2023-05-26 19:27:32 - progress_bar.py[line:272] - INFO: epoch 023:    403 / 1732 loss=2.127, loss_v1=0, loss_v2=0, nll_loss=0.897, ntokens=1045, nsentences=32, sample_size=1045, sample_size_v1=0, sample_size_v2=0, ppl=1.86, wps=561.8, ups=0.54, wpb=1045, bsz=32, num_updates=38440, lr=8.30416e-06, gnorm=20.069, clip=100, loss_scale=16, train_wall=19, gb_free=11.2, wall=72266
2023-05-26 19:27:50 - progress_bar.py[line:272] - INFO: epoch 023:    413 / 1732 loss=2.129, loss_v1=0, loss_v2=0, nll_loss=0.9, ntokens=1078.5, nsentences=32, sample_size=1078.5, sample_size_v1=0, sample_size_v2=0, ppl=1.87, wps=578.5, ups=0.54, wpb=1078.5, bsz=32, num_updates=38450, lr=8.29802e-06, gnorm=19.127, clip=100, loss_scale=16, train_wall=19, gb_free=11.3, wall=72285
2023-05-26 19:28:09 - progress_bar.py[line:272] - INFO: epoch 023:    423 / 1732 loss=2.085, loss_v1=0, loss_v2=0, nll_loss=0.851, ntokens=985.4, nsentences=32, sample_size=985.4, sample_size_v1=0, sample_size_v2=0, ppl=1.8, wps=529.3, ups=0.54, wpb=985.4, bsz=32, num_updates=38460, lr=8.29187e-06, gnorm=19.186, clip=100, loss_scale=16, train_wall=19, gb_free=11.2, wall=72303
2023-05-26 19:28:27 - progress_bar.py[line:272] - INFO: epoch 023:    433 / 1732 loss=2.119, loss_v1=0, loss_v2=0, nll_loss=0.89, ntokens=1024.2, nsentences=32, sample_size=1024.2, sample_size_v1=0, sample_size_v2=0, ppl=1.85, wps=551.3, ups=0.54, wpb=1024.2, bsz=32, num_updates=38470, lr=8.28573e-06, gnorm=21.092, clip=100, loss_scale=16, train_wall=19, gb_free=11.6, wall=72322
2023-05-26 19:28:46 - progress_bar.py[line:272] - INFO: epoch 023:    443 / 1732 loss=2.151, loss_v1=0, loss_v2=0, nll_loss=0.925, ntokens=966.7, nsentences=32, sample_size=966.7, sample_size_v1=0, sample_size_v2=0, ppl=1.9, wps=521.1, ups=0.54, wpb=966.7, bsz=32, num_updates=38480, lr=8.27959e-06, gnorm=21.226, clip=100, loss_scale=16, train_wall=19, gb_free=11.7, wall=72341
2023-05-26 19:29:04 - progress_bar.py[line:272] - INFO: epoch 023:    453 / 1732 loss=2.124, loss_v1=0, loss_v2=0, nll_loss=0.894, ntokens=911.8, nsentences=32, sample_size=911.8, sample_size_v1=0, sample_size_v2=0, ppl=1.86, wps=492.8, ups=0.54, wpb=911.8, bsz=32, num_updates=38490, lr=8.27345e-06, gnorm=20.769, clip=100, loss_scale=16, train_wall=18, gb_free=11.6, wall=72359
2023-05-26 19:29:23 - progress_bar.py[line:272] - INFO: epoch 023:    463 / 1732 loss=2.173, loss_v1=0, loss_v2=0, nll_loss=0.949, ntokens=1072.4, nsentences=32, sample_size=1072.4, sample_size_v1=0, sample_size_v2=0, ppl=1.93, wps=576.6, ups=0.54, wpb=1072.4, bsz=32, num_updates=38500, lr=8.26731e-06, gnorm=20.656, clip=100, loss_scale=16, train_wall=19, gb_free=11.1, wall=72378
2023-05-26 19:29:42 - progress_bar.py[line:272] - INFO: epoch 023:    473 / 1732 loss=2.157, loss_v1=0, loss_v2=0, nll_loss=0.931, ntokens=1059.2, nsentences=32, sample_size=1059.2, sample_size_v1=0, sample_size_v2=0, ppl=1.91, wps=564, ups=0.53, wpb=1059.2, bsz=32, num_updates=38510, lr=8.26116e-06, gnorm=19.002, clip=100, loss_scale=16, train_wall=19, gb_free=10.5, wall=72396
2023-05-26 19:30:00 - progress_bar.py[line:272] - INFO: epoch 023:    483 / 1732 loss=2.14, loss_v1=0, loss_v2=0, nll_loss=0.913, ntokens=966.6, nsentences=32, sample_size=966.6, sample_size_v1=0, sample_size_v2=0, ppl=1.88, wps=523.2, ups=0.54, wpb=966.6, bsz=32, num_updates=38520, lr=8.25502e-06, gnorm=21.243, clip=100, loss_scale=16, train_wall=18, gb_free=11.7, wall=72415
2023-05-26 19:30:19 - progress_bar.py[line:272] - INFO: epoch 023:    493 / 1732 loss=2.128, loss_v1=0, loss_v2=0, nll_loss=0.897, ntokens=940.2, nsentences=32, sample_size=940.2, sample_size_v1=0, sample_size_v2=0, ppl=1.86, wps=505.4, ups=0.54, wpb=940.2, bsz=32, num_updates=38530, lr=8.24888e-06, gnorm=20.421, clip=100, loss_scale=16, train_wall=19, gb_free=11.8, wall=72434
2023-05-26 19:30:37 - progress_bar.py[line:272] - INFO: epoch 023:    503 / 1732 loss=2.153, loss_v1=0, loss_v2=0, nll_loss=0.927, ntokens=988.6, nsentences=32, sample_size=988.6, sample_size_v1=0, sample_size_v2=0, ppl=1.9, wps=536.8, ups=0.54, wpb=988.6, bsz=32, num_updates=38540, lr=8.24274e-06, gnorm=24.485, clip=100, loss_scale=16, train_wall=18, gb_free=11.8, wall=72452
2023-05-26 19:30:56 - progress_bar.py[line:272] - INFO: epoch 023:    513 / 1732 loss=2.166, loss_v1=0, loss_v2=0, nll_loss=0.941, ntokens=1035, nsentences=32, sample_size=1035, sample_size_v1=0, sample_size_v2=0, ppl=1.92, wps=558.1, ups=0.54, wpb=1035, bsz=32, num_updates=38550, lr=8.23659e-06, gnorm=20.854, clip=100, loss_scale=16, train_wall=19, gb_free=11.7, wall=72471
2023-05-26 19:31:14 - progress_bar.py[line:272] - INFO: epoch 023:    523 / 1732 loss=2.131, loss_v1=0, loss_v2=0, nll_loss=0.902, ntokens=997.6, nsentences=32, sample_size=997.6, sample_size_v1=0, sample_size_v2=0, ppl=1.87, wps=540.8, ups=0.54, wpb=997.6, bsz=32, num_updates=38560, lr=8.23045e-06, gnorm=21.583, clip=100, loss_scale=32, train_wall=18, gb_free=11.8, wall=72489
2023-05-26 19:31:33 - progress_bar.py[line:272] - INFO: epoch 023:    533 / 1732 loss=2.128, loss_v1=0, loss_v2=0, nll_loss=0.9, ntokens=935, nsentences=32, sample_size=935, sample_size_v1=0, sample_size_v2=0, ppl=1.87, wps=506.4, ups=0.54, wpb=935, bsz=32, num_updates=38570, lr=8.22431e-06, gnorm=23.294, clip=100, loss_scale=32, train_wall=18, gb_free=11.8, wall=72507
2023-05-26 19:31:51 - progress_bar.py[line:272] - INFO: epoch 023:    543 / 1732 loss=2.156, loss_v1=0, loss_v2=0, nll_loss=0.931, ntokens=1003.8, nsentences=32, sample_size=1003.8, sample_size_v1=0, sample_size_v2=0, ppl=1.91, wps=542.4, ups=0.54, wpb=1003.8, bsz=32, num_updates=38580, lr=8.21817e-06, gnorm=22.797, clip=100, loss_scale=32, train_wall=18, gb_free=11.3, wall=72526
2023-05-26 19:32:10 - progress_bar.py[line:272] - INFO: epoch 023:    553 / 1732 loss=2.175, loss_v1=0, loss_v2=0, nll_loss=0.952, ntokens=1017.4, nsentences=32, sample_size=1017.4, sample_size_v1=0, sample_size_v2=0, ppl=1.93, wps=548, ups=0.54, wpb=1017.4, bsz=32, num_updates=38590, lr=8.21203e-06, gnorm=22.905, clip=100, loss_scale=32, train_wall=19, gb_free=11.8, wall=72545
2023-05-26 19:32:28 - progress_bar.py[line:272] - INFO: epoch 023:    563 / 1732 loss=2.168, loss_v1=0, loss_v2=0, nll_loss=0.943, ntokens=1008.2, nsentences=32, sample_size=1008.2, sample_size_v1=0, sample_size_v2=0, ppl=1.92, wps=543.2, ups=0.54, wpb=1008.2, bsz=32, num_updates=38600, lr=8.20588e-06, gnorm=22.145, clip=100, loss_scale=32, train_wall=19, gb_free=12, wall=72563
2023-05-26 19:32:47 - progress_bar.py[line:272] - INFO: epoch 023:    573 / 1732 loss=2.165, loss_v1=0, loss_v2=0, nll_loss=0.94, ntokens=1041.3, nsentences=32, sample_size=1041.3, sample_size_v1=0, sample_size_v2=0, ppl=1.92, wps=555, ups=0.53, wpb=1041.3, bsz=32, num_updates=38610, lr=8.19974e-06, gnorm=22.884, clip=100, loss_scale=32, train_wall=19, gb_free=11, wall=72582
2023-05-26 19:33:06 - progress_bar.py[line:272] - INFO: epoch 023:    583 / 1732 loss=2.154, loss_v1=0, loss_v2=0, nll_loss=0.929, ntokens=981.7, nsentences=32, sample_size=981.7, sample_size_v1=0, sample_size_v2=0, ppl=1.9, wps=525.7, ups=0.54, wpb=981.7, bsz=32, num_updates=38620, lr=8.1936e-06, gnorm=22.206, clip=100, loss_scale=32, train_wall=19, gb_free=11.8, wall=72601
2023-05-26 19:33:25 - progress_bar.py[line:272] - INFO: epoch 023:    593 / 1732 loss=2.111, loss_v1=0, loss_v2=0, nll_loss=0.879, ntokens=957.4, nsentences=32, sample_size=957.4, sample_size_v1=0, sample_size_v2=0, ppl=1.84, wps=512.9, ups=0.54, wpb=957.4, bsz=32, num_updates=38630, lr=8.18746e-06, gnorm=21.573, clip=100, loss_scale=32, train_wall=19, gb_free=11.7, wall=72619
2023-05-26 19:33:43 - progress_bar.py[line:272] - INFO: epoch 023:    603 / 1732 loss=2.109, loss_v1=0, loss_v2=0, nll_loss=0.877, ntokens=911.2, nsentences=32, sample_size=911.2, sample_size_v1=0, sample_size_v2=0, ppl=1.84, wps=494.1, ups=0.54, wpb=911.2, bsz=32, num_updates=38640, lr=8.18132e-06, gnorm=21.823, clip=100, loss_scale=32, train_wall=18, gb_free=11.8, wall=72638
2023-05-26 19:34:01 - progress_bar.py[line:272] - INFO: epoch 023:    613 / 1732 loss=2.14, loss_v1=0, loss_v2=0, nll_loss=0.913, ntokens=893.3, nsentences=32, sample_size=893.3, sample_size_v1=0, sample_size_v2=0, ppl=1.88, wps=482.9, ups=0.54, wpb=893.3, bsz=32, num_updates=38650, lr=8.17517e-06, gnorm=24.161, clip=100, loss_scale=32, train_wall=18, gb_free=11.7, wall=72656
2023-05-26 19:34:20 - progress_bar.py[line:272] - INFO: epoch 023:    623 / 1732 loss=2.144, loss_v1=0, loss_v2=0, nll_loss=0.918, ntokens=887.2, nsentences=32, sample_size=887.2, sample_size_v1=0, sample_size_v2=0, ppl=1.89, wps=482.2, ups=0.54, wpb=887.2, bsz=32, num_updates=38660, lr=8.16903e-06, gnorm=22.751, clip=100, loss_scale=32, train_wall=18, gb_free=11.1, wall=72675
2023-05-26 19:34:38 - progress_bar.py[line:272] - INFO: epoch 023:    633 / 1732 loss=2.131, loss_v1=0, loss_v2=0, nll_loss=0.902, ntokens=925, nsentences=32, sample_size=925, sample_size_v1=0, sample_size_v2=0, ppl=1.87, wps=502.9, ups=0.54, wpb=925, bsz=32, num_updates=38670, lr=8.16289e-06, gnorm=21.788, clip=100, loss_scale=32, train_wall=18, gb_free=11.6, wall=72693
2023-05-26 19:34:57 - progress_bar.py[line:272] - INFO: epoch 023:    643 / 1732 loss=2.159, loss_v1=0, loss_v2=0, nll_loss=0.933, ntokens=963.8, nsentences=32, sample_size=963.8, sample_size_v1=0, sample_size_v2=0, ppl=1.91, wps=522.5, ups=0.54, wpb=963.8, bsz=32, num_updates=38680, lr=8.15675e-06, gnorm=22.748, clip=100, loss_scale=32, train_wall=18, gb_free=11.8, wall=72711
2023-05-26 19:35:15 - progress_bar.py[line:272] - INFO: epoch 023:    653 / 1732 loss=2.128, loss_v1=0, loss_v2=0, nll_loss=0.9, ntokens=928, nsentences=32, sample_size=928, sample_size_v1=0, sample_size_v2=0, ppl=1.87, wps=505.5, ups=0.54, wpb=928, bsz=32, num_updates=38690, lr=8.1506e-06, gnorm=21.192, clip=100, loss_scale=32, train_wall=18, gb_free=11.9, wall=72730
2023-05-26 19:35:33 - progress_bar.py[line:272] - INFO: epoch 023:    663 / 1732 loss=2.133, loss_v1=0, loss_v2=0, nll_loss=0.905, ntokens=882.9, nsentences=32, sample_size=882.9, sample_size_v1=0, sample_size_v2=0, ppl=1.87, wps=481, ups=0.54, wpb=882.9, bsz=32, num_updates=38700, lr=8.14446e-06, gnorm=24.583, clip=100, loss_scale=32, train_wall=18, gb_free=11.5, wall=72748
2023-05-26 19:35:52 - progress_bar.py[line:272] - INFO: epoch 023:    673 / 1732 loss=2.166, loss_v1=0, loss_v2=0, nll_loss=0.942, ntokens=954.3, nsentences=32, sample_size=954.3, sample_size_v1=0, sample_size_v2=0, ppl=1.92, wps=515.2, ups=0.54, wpb=954.3, bsz=32, num_updates=38710, lr=8.13832e-06, gnorm=22.691, clip=100, loss_scale=32, train_wall=18, gb_free=11.8, wall=72767
2023-05-26 19:36:11 - progress_bar.py[line:272] - INFO: epoch 023:    683 / 1732 loss=2.122, loss_v1=0, loss_v2=0, nll_loss=0.892, ntokens=960.5, nsentences=32, sample_size=960.5, sample_size_v1=0, sample_size_v2=0, ppl=1.86, wps=519, ups=0.54, wpb=960.5, bsz=32, num_updates=38720, lr=8.13218e-06, gnorm=20.59, clip=100, loss_scale=32, train_wall=18, gb_free=11.9, wall=72785
2023-05-26 19:36:29 - progress_bar.py[line:272] - INFO: epoch 023:    693 / 1732 loss=2.151, loss_v1=0, loss_v2=0, nll_loss=0.925, ntokens=962.9, nsentences=32, sample_size=962.9, sample_size_v1=0, sample_size_v2=0, ppl=1.9, wps=518.7, ups=0.54, wpb=962.9, bsz=32, num_updates=38730, lr=8.12604e-06, gnorm=22.657, clip=100, loss_scale=32, train_wall=19, gb_free=11.2, wall=72804
2023-05-26 19:36:48 - progress_bar.py[line:272] - INFO: epoch 023:    703 / 1732 loss=2.099, loss_v1=0, loss_v2=0, nll_loss=0.867, ntokens=972.9, nsentences=32, sample_size=972.9, sample_size_v1=0, sample_size_v2=0, ppl=1.82, wps=524.6, ups=0.54, wpb=972.9, bsz=32, num_updates=38740, lr=8.11989e-06, gnorm=18.944, clip=100, loss_scale=32, train_wall=19, gb_free=11.6, wall=72822
2023-05-26 19:37:06 - progress_bar.py[line:272] - INFO: epoch 023:    713 / 1732 loss=2.143, loss_v1=0, loss_v2=0, nll_loss=0.917, ntokens=898.6, nsentences=32, sample_size=898.6, sample_size_v1=0, sample_size_v2=0, ppl=1.89, wps=488.6, ups=0.54, wpb=898.6, bsz=32, num_updates=38750, lr=8.11375e-06, gnorm=22.357, clip=100, loss_scale=32, train_wall=18, gb_free=11.8, wall=72841
2023-05-26 19:37:24 - progress_bar.py[line:272] - INFO: epoch 023:    723 / 1732 loss=2.098, loss_v1=0, loss_v2=0, nll_loss=0.865, ntokens=877.5, nsentences=32, sample_size=877.5, sample_size_v1=0, sample_size_v2=0, ppl=1.82, wps=476.4, ups=0.54, wpb=877.5, bsz=32, num_updates=38760, lr=8.10761e-06, gnorm=20.861, clip=100, loss_scale=32, train_wall=18, gb_free=12, wall=72859
2023-05-26 19:37:43 - progress_bar.py[line:272] - INFO: epoch 023:    733 / 1732 loss=2.124, loss_v1=0, loss_v2=0, nll_loss=0.895, ntokens=959.6, nsentences=32, sample_size=959.6, sample_size_v1=0, sample_size_v2=0, ppl=1.86, wps=519.9, ups=0.54, wpb=959.6, bsz=32, num_updates=38770, lr=8.10147e-06, gnorm=19.394, clip=100, loss_scale=32, train_wall=18, gb_free=11, wall=72878
2023-05-26 19:38:01 - progress_bar.py[line:272] - INFO: epoch 023:    743 / 1732 loss=2.127, loss_v1=0, loss_v2=0, nll_loss=0.897, ntokens=991.8, nsentences=32, sample_size=991.8, sample_size_v1=0, sample_size_v2=0, ppl=1.86, wps=537.3, ups=0.54, wpb=991.8, bsz=32, num_updates=38780, lr=8.09533e-06, gnorm=22.327, clip=100, loss_scale=32, train_wall=18, gb_free=11.4, wall=72896
2023-05-26 19:38:20 - progress_bar.py[line:272] - INFO: epoch 023:    753 / 1732 loss=2.126, loss_v1=0, loss_v2=0, nll_loss=0.898, ntokens=968.6, nsentences=32, sample_size=968.6, sample_size_v1=0, sample_size_v2=0, ppl=1.86, wps=522.1, ups=0.54, wpb=968.6, bsz=32, num_updates=38790, lr=8.08918e-06, gnorm=20.802, clip=100, loss_scale=32, train_wall=19, gb_free=11.5, wall=72915
2023-05-26 19:38:38 - progress_bar.py[line:272] - INFO: epoch 023:    763 / 1732 loss=2.126, loss_v1=0, loss_v2=0, nll_loss=0.898, ntokens=964, nsentences=32, sample_size=964, sample_size_v1=0, sample_size_v2=0, ppl=1.86, wps=521.9, ups=0.54, wpb=964, bsz=32, num_updates=38800, lr=8.08304e-06, gnorm=22.052, clip=100, loss_scale=32, train_wall=18, gb_free=11.6, wall=72933
2023-05-26 19:38:57 - progress_bar.py[line:272] - INFO: epoch 023:    773 / 1732 loss=2.13, loss_v1=0, loss_v2=0, nll_loss=0.902, ntokens=971.7, nsentences=32, sample_size=971.7, sample_size_v1=0, sample_size_v2=0, ppl=1.87, wps=525.6, ups=0.54, wpb=971.7, bsz=32, num_updates=38810, lr=8.0769e-06, gnorm=23.032, clip=100, loss_scale=32, train_wall=18, gb_free=11.5, wall=72952
2023-05-26 19:39:15 - progress_bar.py[line:272] - INFO: epoch 023:    783 / 1732 loss=2.113, loss_v1=0, loss_v2=0, nll_loss=0.883, ntokens=1008.4, nsentences=32, sample_size=1008.4, sample_size_v1=0, sample_size_v2=0, ppl=1.84, wps=545.6, ups=0.54, wpb=1008.4, bsz=32, num_updates=38820, lr=8.07076e-06, gnorm=20.052, clip=100, loss_scale=32, train_wall=18, gb_free=11.2, wall=72970
2023-05-26 19:39:34 - progress_bar.py[line:272] - INFO: epoch 023:    793 / 1732 loss=2.148, loss_v1=0, loss_v2=0, nll_loss=0.922, ntokens=1034.6, nsentences=32, sample_size=1034.6, sample_size_v1=0, sample_size_v2=0, ppl=1.89, wps=559.1, ups=0.54, wpb=1034.6, bsz=32, num_updates=38830, lr=8.06462e-06, gnorm=22.538, clip=100, loss_scale=32, train_wall=18, gb_free=11.4, wall=72989
2023-05-26 19:39:52 - progress_bar.py[line:272] - INFO: epoch 023:    803 / 1732 loss=2.141, loss_v1=0, loss_v2=0, nll_loss=0.914, ntokens=964.4, nsentences=32, sample_size=964.4, sample_size_v1=0, sample_size_v2=0, ppl=1.88, wps=521.2, ups=0.54, wpb=964.4, bsz=32, num_updates=38840, lr=8.05847e-06, gnorm=21.663, clip=100, loss_scale=32, train_wall=18, gb_free=10.9, wall=73007
2023-05-26 19:40:11 - progress_bar.py[line:272] - INFO: epoch 023:    813 / 1732 loss=2.139, loss_v1=0, loss_v2=0, nll_loss=0.911, ntokens=940.9, nsentences=32, sample_size=940.9, sample_size_v1=0, sample_size_v2=0, ppl=1.88, wps=509.6, ups=0.54, wpb=940.9, bsz=32, num_updates=38850, lr=8.05233e-06, gnorm=22.885, clip=100, loss_scale=32, train_wall=18, gb_free=10.8, wall=73026
2023-05-26 19:40:29 - progress_bar.py[line:272] - INFO: epoch 023:    823 / 1732 loss=2.132, loss_v1=0, loss_v2=0, nll_loss=0.904, ntokens=915.1, nsentences=32, sample_size=915.1, sample_size_v1=0, sample_size_v2=0, ppl=1.87, wps=494.7, ups=0.54, wpb=915.1, bsz=32, num_updates=38860, lr=8.04619e-06, gnorm=22.145, clip=100, loss_scale=32, train_wall=18, gb_free=11.5, wall=73044
2023-05-26 19:40:48 - progress_bar.py[line:272] - INFO: epoch 023:    833 / 1732 loss=2.132, loss_v1=0, loss_v2=0, nll_loss=0.904, ntokens=907.5, nsentences=32, sample_size=907.5, sample_size_v1=0, sample_size_v2=0, ppl=1.87, wps=493.5, ups=0.54, wpb=907.5, bsz=32, num_updates=38870, lr=8.04005e-06, gnorm=22.404, clip=100, loss_scale=32, train_wall=18, gb_free=11.8, wall=73062
2023-05-26 19:41:06 - progress_bar.py[line:272] - INFO: epoch 023:    843 / 1732 loss=2.116, loss_v1=0, loss_v2=0, nll_loss=0.886, ntokens=950.7, nsentences=32, sample_size=950.7, sample_size_v1=0, sample_size_v2=0, ppl=1.85, wps=517.3, ups=0.54, wpb=950.7, bsz=32, num_updates=38880, lr=8.0339e-06, gnorm=21.681, clip=100, loss_scale=32, train_wall=18, gb_free=11.8, wall=73081
2023-05-26 19:41:25 - progress_bar.py[line:272] - INFO: epoch 023:    853 / 1732 loss=2.136, loss_v1=0, loss_v2=0, nll_loss=0.908, ntokens=1006.3, nsentences=32, sample_size=1006.3, sample_size_v1=0, sample_size_v2=0, ppl=1.88, wps=542, ups=0.54, wpb=1006.3, bsz=32, num_updates=38890, lr=8.02776e-06, gnorm=21.346, clip=100, loss_scale=32, train_wall=19, gb_free=11.1, wall=73099
2023-05-26 19:41:43 - progress_bar.py[line:272] - INFO: epoch 023:    863 / 1732 loss=2.125, loss_v1=0, loss_v2=0, nll_loss=0.896, ntokens=933.3, nsentences=32, sample_size=933.3, sample_size_v1=0, sample_size_v2=0, ppl=1.86, wps=504, ups=0.54, wpb=933.3, bsz=32, num_updates=38900, lr=8.02162e-06, gnorm=23.262, clip=100, loss_scale=32, train_wall=18, gb_free=11.4, wall=73118
2023-05-26 19:42:02 - progress_bar.py[line:272] - INFO: epoch 023:    873 / 1732 loss=2.119, loss_v1=0, loss_v2=0, nll_loss=0.891, ntokens=966.4, nsentences=32, sample_size=966.4, sample_size_v1=0, sample_size_v2=0, ppl=1.85, wps=523, ups=0.54, wpb=966.4, bsz=32, num_updates=38910, lr=8.01548e-06, gnorm=23.186, clip=100, loss_scale=32, train_wall=18, gb_free=11.3, wall=73136
2023-05-26 19:42:20 - progress_bar.py[line:272] - INFO: epoch 023:    883 / 1732 loss=2.072, loss_v1=0, loss_v2=0, nll_loss=0.837, ntokens=985.5, nsentences=32, sample_size=985.5, sample_size_v1=0, sample_size_v2=0, ppl=1.79, wps=528.4, ups=0.54, wpb=985.5, bsz=32, num_updates=38920, lr=8.00934e-06, gnorm=21.83, clip=100, loss_scale=32, train_wall=19, gb_free=11.3, wall=73155
2023-05-26 19:42:39 - progress_bar.py[line:272] - INFO: epoch 023:    893 / 1732 loss=2.08, loss_v1=0, loss_v2=0, nll_loss=0.846, ntokens=1009.8, nsentences=32, sample_size=1009.8, sample_size_v1=0, sample_size_v2=0, ppl=1.8, wps=543, ups=0.54, wpb=1009.8, bsz=32, num_updates=38930, lr=8.00319e-06, gnorm=21.958, clip=100, loss_scale=32, train_wall=19, gb_free=11.1, wall=73174
2023-05-26 19:42:58 - progress_bar.py[line:272] - INFO: epoch 023:    903 / 1732 loss=2.087, loss_v1=0, loss_v2=0, nll_loss=0.854, ntokens=1049.7, nsentences=32, sample_size=1049.7, sample_size_v1=0, sample_size_v2=0, ppl=1.81, wps=565.5, ups=0.54, wpb=1049.7, bsz=32, num_updates=38940, lr=7.99705e-06, gnorm=21.039, clip=100, loss_scale=32, train_wall=19, gb_free=11.5, wall=73192
2023-05-26 19:43:16 - progress_bar.py[line:272] - INFO: epoch 023:    913 / 1732 loss=2.159, loss_v1=0, loss_v2=0, nll_loss=0.934, ntokens=930.6, nsentences=32, sample_size=930.6, sample_size_v1=0, sample_size_v2=0, ppl=1.91, wps=503.7, ups=0.54, wpb=930.6, bsz=32, num_updates=38950, lr=7.99091e-06, gnorm=23.914, clip=100, loss_scale=32, train_wall=18, gb_free=11, wall=73211
2023-05-26 19:43:35 - progress_bar.py[line:272] - INFO: epoch 023:    923 / 1732 loss=2.101, loss_v1=0, loss_v2=0, nll_loss=0.869, ntokens=1023.3, nsentences=32, sample_size=1023.3, sample_size_v1=0, sample_size_v2=0, ppl=1.83, wps=549.3, ups=0.54, wpb=1023.3, bsz=32, num_updates=38960, lr=7.98477e-06, gnorm=19.12, clip=100, loss_scale=32, train_wall=19, gb_free=11.1, wall=73229
2023-05-26 19:43:53 - progress_bar.py[line:272] - INFO: epoch 023:    933 / 1732 loss=2.125, loss_v1=0, loss_v2=0, nll_loss=0.895, ntokens=1034.6, nsentences=32, sample_size=1034.6, sample_size_v1=0, sample_size_v2=0, ppl=1.86, wps=552.8, ups=0.53, wpb=1034.6, bsz=32, num_updates=38970, lr=7.97863e-06, gnorm=24.083, clip=100, loss_scale=32, train_wall=19, gb_free=11.1, wall=73248
2023-05-26 19:44:12 - progress_bar.py[line:272] - INFO: epoch 023:    943 / 1732 loss=2.139, loss_v1=0, loss_v2=0, nll_loss=0.911, ntokens=1054.1, nsentences=32, sample_size=1054.1, sample_size_v1=0, sample_size_v2=0, ppl=1.88, wps=560.7, ups=0.53, wpb=1054.1, bsz=32, num_updates=38980, lr=7.97248e-06, gnorm=21.498, clip=100, loss_scale=32, train_wall=19, gb_free=11.3, wall=73267
2023-05-26 19:44:14 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2023-05-26 19:44:33 - progress_bar.py[line:272] - INFO: epoch 023:    954 / 1732 loss=2.124, loss_v1=0, loss_v2=0, nll_loss=0.895, ntokens=1041, nsentences=32, sample_size=1041, sample_size_v1=0, sample_size_v2=0, ppl=1.86, wps=505.7, ups=0.49, wpb=1041, bsz=32, num_updates=38990, lr=7.96634e-06, gnorm=21.933, clip=100, loss_scale=16, train_wall=21, gb_free=10.9, wall=73287
2023-05-26 19:44:52 - progress_bar.py[line:272] - INFO: epoch 023:    964 / 1732 loss=2.146, loss_v1=0, loss_v2=0, nll_loss=0.919, ntokens=1053, nsentences=32, sample_size=1053, sample_size_v1=0, sample_size_v2=0, ppl=1.89, wps=556.3, ups=0.53, wpb=1053, bsz=32, num_updates=39000, lr=7.9602e-06, gnorm=22.026, clip=100, loss_scale=16, train_wall=19, gb_free=11.4, wall=73306
2023-05-26 19:45:10 - progress_bar.py[line:272] - INFO: epoch 023:    974 / 1732 loss=2.115, loss_v1=0, loss_v2=0, nll_loss=0.885, ntokens=1051.9, nsentences=32, sample_size=1051.9, sample_size_v1=0, sample_size_v2=0, ppl=1.85, wps=558.5, ups=0.53, wpb=1051.9, bsz=32, num_updates=39010, lr=7.95406e-06, gnorm=20.753, clip=100, loss_scale=16, train_wall=19, gb_free=11.4, wall=73325
2023-05-26 19:45:29 - progress_bar.py[line:272] - INFO: epoch 023:    984 / 1732 loss=2.125, loss_v1=0, loss_v2=0, nll_loss=0.897, ntokens=1029.3, nsentences=32, sample_size=1029.3, sample_size_v1=0, sample_size_v2=0, ppl=1.86, wps=545.4, ups=0.53, wpb=1029.3, bsz=32, num_updates=39020, lr=7.94791e-06, gnorm=18.619, clip=100, loss_scale=16, train_wall=19, gb_free=10.9, wall=73344
2023-05-26 19:45:48 - progress_bar.py[line:272] - INFO: epoch 023:    994 / 1732 loss=2.135, loss_v1=0, loss_v2=0, nll_loss=0.907, ntokens=1030.4, nsentences=32, sample_size=1030.4, sample_size_v1=0, sample_size_v2=0, ppl=1.88, wps=549.9, ups=0.53, wpb=1030.4, bsz=32, num_updates=39030, lr=7.94177e-06, gnorm=23.249, clip=100, loss_scale=16, train_wall=19, gb_free=11.4, wall=73363
2023-05-26 19:46:07 - progress_bar.py[line:272] - INFO: epoch 023:   1004 / 1732 loss=2.126, loss_v1=0, loss_v2=0, nll_loss=0.896, ntokens=995.4, nsentences=32, sample_size=995.4, sample_size_v1=0, sample_size_v2=0, ppl=1.86, wps=533.5, ups=0.54, wpb=995.4, bsz=32, num_updates=39040, lr=7.93563e-06, gnorm=24.535, clip=100, loss_scale=16, train_wall=19, gb_free=11.8, wall=73381
2023-05-26 19:46:25 - progress_bar.py[line:272] - INFO: epoch 023:   1014 / 1732 loss=2.124, loss_v1=0, loss_v2=0, nll_loss=0.893, ntokens=997.1, nsentences=32, sample_size=997.1, sample_size_v1=0, sample_size_v2=0, ppl=1.86, wps=535.8, ups=0.54, wpb=997.1, bsz=32, num_updates=39050, lr=7.92949e-06, gnorm=21.197, clip=100, loss_scale=16, train_wall=19, gb_free=11.4, wall=73400
2023-05-26 19:46:44 - progress_bar.py[line:272] - INFO: epoch 023:   1024 / 1732 loss=2.119, loss_v1=0, loss_v2=0, nll_loss=0.889, ntokens=1086.7, nsentences=32, sample_size=1086.7, sample_size_v1=0, sample_size_v2=0, ppl=1.85, wps=577.4, ups=0.53, wpb=1086.7, bsz=32, num_updates=39060, lr=7.92335e-06, gnorm=20.608, clip=100, loss_scale=16, train_wall=19, gb_free=11.2, wall=73419
2023-05-26 19:47:03 - progress_bar.py[line:272] - INFO: epoch 023:   1034 / 1732 loss=2.12, loss_v1=0, loss_v2=0, nll_loss=0.889, ntokens=1103.2, nsentences=32, sample_size=1103.2, sample_size_v1=0, sample_size_v2=0, ppl=1.85, wps=583.4, ups=0.53, wpb=1103.2, bsz=32, num_updates=39070, lr=7.9172e-06, gnorm=19.953, clip=100, loss_scale=16, train_wall=19, gb_free=10.8, wall=73438
2023-05-26 19:47:22 - progress_bar.py[line:272] - INFO: epoch 023:   1044 / 1732 loss=2.121, loss_v1=0, loss_v2=0, nll_loss=0.891, ntokens=1052.8, nsentences=32, sample_size=1052.8, sample_size_v1=0, sample_size_v2=0, ppl=1.85, wps=558.7, ups=0.53, wpb=1052.8, bsz=32, num_updates=39080, lr=7.91106e-06, gnorm=22.306, clip=100, loss_scale=16, train_wall=19, gb_free=11.2, wall=73457
2023-05-26 19:47:41 - progress_bar.py[line:272] - INFO: epoch 023:   1054 / 1732 loss=2.151, loss_v1=0, loss_v2=0, nll_loss=0.926, ntokens=1068, nsentences=32, sample_size=1068, sample_size_v1=0, sample_size_v2=0, ppl=1.9, wps=572, ups=0.54, wpb=1068, bsz=32, num_updates=39090, lr=7.90492e-06, gnorm=24.228, clip=100, loss_scale=16, train_wall=19, gb_free=10, wall=73475
2023-05-26 19:47:59 - progress_bar.py[line:272] - INFO: epoch 023:   1064 / 1732 loss=2.116, loss_v1=0, loss_v2=0, nll_loss=0.885, ntokens=1024.1, nsentences=32, sample_size=1024.1, sample_size_v1=0, sample_size_v2=0, ppl=1.85, wps=547, ups=0.53, wpb=1024.1, bsz=32, num_updates=39100, lr=7.89878e-06, gnorm=21.255, clip=100, loss_scale=16, train_wall=19, gb_free=11.6, wall=73494
2023-05-26 19:48:18 - progress_bar.py[line:272] - INFO: epoch 023:   1074 / 1732 loss=2.114, loss_v1=0, loss_v2=0, nll_loss=0.882, ntokens=1002.8, nsentences=32, sample_size=1002.8, sample_size_v1=0, sample_size_v2=0, ppl=1.84, wps=535, ups=0.53, wpb=1002.8, bsz=32, num_updates=39110, lr=7.89264e-06, gnorm=21.453, clip=100, loss_scale=16, train_wall=19, gb_free=11.3, wall=73513
2023-05-26 19:48:37 - progress_bar.py[line:272] - INFO: epoch 023:   1084 / 1732 loss=2.143, loss_v1=0, loss_v2=0, nll_loss=0.915, ntokens=1060.4, nsentences=32, sample_size=1060.4, sample_size_v1=0, sample_size_v2=0, ppl=1.89, wps=558.1, ups=0.53, wpb=1060.4, bsz=32, num_updates=39120, lr=7.88649e-06, gnorm=21.588, clip=100, loss_scale=16, train_wall=19, gb_free=10.3, wall=73532
2023-05-26 19:48:56 - progress_bar.py[line:272] - INFO: epoch 023:   1094 / 1732 loss=2.133, loss_v1=0, loss_v2=0, nll_loss=0.906, ntokens=1050.5, nsentences=32, sample_size=1050.5, sample_size_v1=0, sample_size_v2=0, ppl=1.87, wps=560.2, ups=0.53, wpb=1050.5, bsz=32, num_updates=39130, lr=7.88035e-06, gnorm=21.533, clip=100, loss_scale=16, train_wall=19, gb_free=10.8, wall=73551
2023-05-26 19:49:15 - progress_bar.py[line:272] - INFO: epoch 023:   1104 / 1732 loss=2.123, loss_v1=0, loss_v2=0, nll_loss=0.894, ntokens=1042.3, nsentences=32, sample_size=1042.3, sample_size_v1=0, sample_size_v2=0, ppl=1.86, wps=553.8, ups=0.53, wpb=1042.3, bsz=32, num_updates=39140, lr=7.87421e-06, gnorm=21.714, clip=100, loss_scale=16, train_wall=19, gb_free=11.2, wall=73569
2023-05-26 19:49:33 - progress_bar.py[line:272] - INFO: epoch 023:   1114 / 1732 loss=2.126, loss_v1=0, loss_v2=0, nll_loss=0.897, ntokens=1000.7, nsentences=32, sample_size=1000.7, sample_size_v1=0, sample_size_v2=0, ppl=1.86, wps=533.7, ups=0.53, wpb=1000.7, bsz=32, num_updates=39150, lr=7.86807e-06, gnorm=24.499, clip=100, loss_scale=16, train_wall=19, gb_free=11.3, wall=73588
2023-05-26 19:49:52 - progress_bar.py[line:272] - INFO: epoch 023:   1124 / 1732 loss=2.11, loss_v1=0, loss_v2=0, nll_loss=0.878, ntokens=989.1, nsentences=32, sample_size=989.1, sample_size_v1=0, sample_size_v2=0, ppl=1.84, wps=525.6, ups=0.53, wpb=989.1, bsz=32, num_updates=39160, lr=7.86192e-06, gnorm=22.768, clip=100, loss_scale=16, train_wall=19, gb_free=10.8, wall=73607
2023-05-26 19:50:11 - progress_bar.py[line:272] - INFO: epoch 023:   1134 / 1732 loss=2.122, loss_v1=0, loss_v2=0, nll_loss=0.892, ntokens=968.8, nsentences=32, sample_size=968.8, sample_size_v1=0, sample_size_v2=0, ppl=1.86, wps=518.3, ups=0.54, wpb=968.8, bsz=32, num_updates=39170, lr=7.85578e-06, gnorm=22.677, clip=100, loss_scale=16, train_wall=19, gb_free=11.4, wall=73626
2023-05-26 19:50:30 - progress_bar.py[line:272] - INFO: epoch 023:   1144 / 1732 loss=2.115, loss_v1=0, loss_v2=0, nll_loss=0.883, ntokens=1034.3, nsentences=32, sample_size=1034.3, sample_size_v1=0, sample_size_v2=0, ppl=1.84, wps=552.8, ups=0.53, wpb=1034.3, bsz=32, num_updates=39180, lr=7.84964e-06, gnorm=21.085, clip=100, loss_scale=16, train_wall=19, gb_free=11.6, wall=73644
2023-05-26 19:50:48 - progress_bar.py[line:272] - INFO: epoch 023:   1154 / 1732 loss=2.11, loss_v1=0, loss_v2=0, nll_loss=0.88, ntokens=1025.8, nsentences=32, sample_size=1025.8, sample_size_v1=0, sample_size_v2=0, ppl=1.84, wps=546.6, ups=0.53, wpb=1025.8, bsz=32, num_updates=39190, lr=7.8435e-06, gnorm=20.743, clip=100, loss_scale=16, train_wall=19, gb_free=10.3, wall=73663
2023-05-26 19:51:07 - progress_bar.py[line:272] - INFO: epoch 023:   1164 / 1732 loss=2.09, loss_v1=0, loss_v2=0, nll_loss=0.858, ntokens=1008, nsentences=32, sample_size=1008, sample_size_v1=0, sample_size_v2=0, ppl=1.81, wps=537.1, ups=0.53, wpb=1008, bsz=32, num_updates=39200, lr=7.83736e-06, gnorm=22.083, clip=100, loss_scale=16, train_wall=19, gb_free=11.5, wall=73682
2023-05-26 19:51:26 - progress_bar.py[line:272] - INFO: epoch 023:   1174 / 1732 loss=2.118, loss_v1=0, loss_v2=0, nll_loss=0.888, ntokens=1081.1, nsentences=32, sample_size=1081.1, sample_size_v1=0, sample_size_v2=0, ppl=1.85, wps=575, ups=0.53, wpb=1081.1, bsz=32, num_updates=39210, lr=7.83121e-06, gnorm=21.969, clip=100, loss_scale=16, train_wall=19, gb_free=11, wall=73701
2023-05-26 19:51:45 - progress_bar.py[line:272] - INFO: epoch 023:   1184 / 1732 loss=2.087, loss_v1=0, loss_v2=0, nll_loss=0.854, ntokens=962, nsentences=32, sample_size=962, sample_size_v1=0, sample_size_v2=0, ppl=1.81, wps=516, ups=0.54, wpb=962, bsz=32, num_updates=39220, lr=7.82507e-06, gnorm=23.399, clip=100, loss_scale=16, train_wall=19, gb_free=11.7, wall=73719
2023-05-26 19:52:03 - progress_bar.py[line:272] - INFO: epoch 023:   1194 / 1732 loss=2.114, loss_v1=0, loss_v2=0, nll_loss=0.884, ntokens=1042.6, nsentences=32, sample_size=1042.6, sample_size_v1=0, sample_size_v2=0, ppl=1.85, wps=556.5, ups=0.53, wpb=1042.6, bsz=32, num_updates=39230, lr=7.81893e-06, gnorm=21.962, clip=100, loss_scale=16, train_wall=19, gb_free=11.5, wall=73738
2023-05-26 19:52:22 - progress_bar.py[line:272] - INFO: epoch 023:   1204 / 1732 loss=2.083, loss_v1=0, loss_v2=0, nll_loss=0.849, ntokens=1150.2, nsentences=32, sample_size=1150.2, sample_size_v1=0, sample_size_v2=0, ppl=1.8, wps=605.1, ups=0.53, wpb=1150.2, bsz=32, num_updates=39240, lr=7.81279e-06, gnorm=18.379, clip=100, loss_scale=16, train_wall=19, gb_free=11.3, wall=73757
2023-05-26 19:52:41 - progress_bar.py[line:272] - INFO: epoch 023:   1214 / 1732 loss=2.106, loss_v1=0, loss_v2=0, nll_loss=0.875, ntokens=996.3, nsentences=32, sample_size=996.3, sample_size_v1=0, sample_size_v2=0, ppl=1.83, wps=531.3, ups=0.53, wpb=996.3, bsz=32, num_updates=39250, lr=7.80665e-06, gnorm=20.452, clip=100, loss_scale=16, train_wall=19, gb_free=11.7, wall=73776
2023-05-26 19:53:00 - progress_bar.py[line:272] - INFO: epoch 023:   1224 / 1732 loss=2.138, loss_v1=0, loss_v2=0, nll_loss=0.912, ntokens=1056.3, nsentences=32, sample_size=1056.3, sample_size_v1=0, sample_size_v2=0, ppl=1.88, wps=561.7, ups=0.53, wpb=1056.3, bsz=32, num_updates=39260, lr=7.8005e-06, gnorm=22.183, clip=100, loss_scale=16, train_wall=19, gb_free=11.5, wall=73795
2023-05-26 19:53:19 - progress_bar.py[line:272] - INFO: epoch 023:   1234 / 1732 loss=2.102, loss_v1=0, loss_v2=0, nll_loss=0.868, ntokens=1012.2, nsentences=32, sample_size=1012.2, sample_size_v1=0, sample_size_v2=0, ppl=1.83, wps=541.8, ups=0.54, wpb=1012.2, bsz=32, num_updates=39270, lr=7.79436e-06, gnorm=21.003, clip=100, loss_scale=16, train_wall=19, gb_free=11.6, wall=73813
2023-05-26 19:53:37 - progress_bar.py[line:272] - INFO: epoch 023:   1244 / 1732 loss=2.073, loss_v1=0, loss_v2=0, nll_loss=0.837, ntokens=1090.2, nsentences=32, sample_size=1090.2, sample_size_v1=0, sample_size_v2=0, ppl=1.79, wps=579.7, ups=0.53, wpb=1090.2, bsz=32, num_updates=39280, lr=7.78822e-06, gnorm=20.797, clip=100, loss_scale=16, train_wall=19, gb_free=11.4, wall=73832
2023-05-26 19:53:56 - progress_bar.py[line:272] - INFO: epoch 023:   1254 / 1732 loss=2.088, loss_v1=0, loss_v2=0, nll_loss=0.854, ntokens=1076, nsentences=32, sample_size=1076, sample_size_v1=0, sample_size_v2=0, ppl=1.81, wps=570.9, ups=0.53, wpb=1076, bsz=32, num_updates=39290, lr=7.78208e-06, gnorm=20.262, clip=100, loss_scale=16, train_wall=19, gb_free=11.6, wall=73851
2023-05-26 19:54:15 - progress_bar.py[line:272] - INFO: epoch 023:   1264 / 1732 loss=2.12, loss_v1=0, loss_v2=0, nll_loss=0.892, ntokens=1095.2, nsentences=32, sample_size=1095.2, sample_size_v1=0, sample_size_v2=0, ppl=1.86, wps=579.9, ups=0.53, wpb=1095.2, bsz=32, num_updates=39300, lr=7.77594e-06, gnorm=19.503, clip=100, loss_scale=16, train_wall=19, gb_free=10.7, wall=73870
2023-05-26 19:54:34 - progress_bar.py[line:272] - INFO: epoch 023:   1274 / 1732 loss=2.109, loss_v1=0, loss_v2=0, nll_loss=0.879, ntokens=1014.1, nsentences=32, sample_size=1014.1, sample_size_v1=0, sample_size_v2=0, ppl=1.84, wps=541.9, ups=0.53, wpb=1014.1, bsz=32, num_updates=39310, lr=7.76979e-06, gnorm=21.494, clip=100, loss_scale=16, train_wall=19, gb_free=11, wall=73889
2023-05-26 19:54:53 - progress_bar.py[line:272] - INFO: epoch 023:   1284 / 1732 loss=2.094, loss_v1=0, loss_v2=0, nll_loss=0.862, ntokens=1057.3, nsentences=32, sample_size=1057.3, sample_size_v1=0, sample_size_v2=0, ppl=1.82, wps=558.6, ups=0.53, wpb=1057.3, bsz=32, num_updates=39320, lr=7.76365e-06, gnorm=20.673, clip=100, loss_scale=16, train_wall=19, gb_free=11.5, wall=73908
2023-05-26 19:55:12 - progress_bar.py[line:272] - INFO: epoch 023:   1294 / 1732 loss=2.093, loss_v1=0, loss_v2=0, nll_loss=0.859, ntokens=1109.4, nsentences=32, sample_size=1109.4, sample_size_v1=0, sample_size_v2=0, ppl=1.81, wps=587.5, ups=0.53, wpb=1109.4, bsz=32, num_updates=39330, lr=7.75751e-06, gnorm=18.698, clip=100, loss_scale=16, train_wall=19, gb_free=11.5, wall=73926
2023-05-26 19:55:31 - progress_bar.py[line:272] - INFO: epoch 023:   1304 / 1732 loss=2.127, loss_v1=0, loss_v2=0, nll_loss=0.898, ntokens=1090.1, nsentences=32, sample_size=1090.1, sample_size_v1=0, sample_size_v2=0, ppl=1.86, wps=577.3, ups=0.53, wpb=1090.1, bsz=32, num_updates=39340, lr=7.75137e-06, gnorm=20.407, clip=100, loss_scale=16, train_wall=19, gb_free=10.7, wall=73945
2023-05-26 19:55:50 - progress_bar.py[line:272] - INFO: epoch 023:   1314 / 1732 loss=2.128, loss_v1=0, loss_v2=0, nll_loss=0.9, ntokens=1051.4, nsentences=32, sample_size=1051.4, sample_size_v1=0, sample_size_v2=0, ppl=1.87, wps=553.9, ups=0.53, wpb=1051.4, bsz=32, num_updates=39350, lr=7.74522e-06, gnorm=19.647, clip=100, loss_scale=16, train_wall=19, gb_free=11, wall=73964
2023-05-26 19:56:09 - progress_bar.py[line:272] - INFO: epoch 023:   1324 / 1732 loss=2.089, loss_v1=0, loss_v2=0, nll_loss=0.856, ntokens=1117, nsentences=32, sample_size=1117, sample_size_v1=0, sample_size_v2=0, ppl=1.81, wps=590.2, ups=0.53, wpb=1117, bsz=32, num_updates=39360, lr=7.73908e-06, gnorm=17.484, clip=100, loss_scale=16, train_wall=19, gb_free=11.4, wall=73983
2023-05-26 19:56:27 - progress_bar.py[line:272] - INFO: epoch 023:   1334 / 1732 loss=2.084, loss_v1=0, loss_v2=0, nll_loss=0.85, ntokens=1097.8, nsentences=32, sample_size=1097.8, sample_size_v1=0, sample_size_v2=0, ppl=1.8, wps=583.2, ups=0.53, wpb=1097.8, bsz=32, num_updates=39370, lr=7.73294e-06, gnorm=19.348, clip=100, loss_scale=16, train_wall=19, gb_free=11.4, wall=74002
2023-05-26 19:56:46 - progress_bar.py[line:272] - INFO: epoch 023:   1344 / 1732 loss=2.105, loss_v1=0, loss_v2=0, nll_loss=0.874, ntokens=1201.2, nsentences=32, sample_size=1201.2, sample_size_v1=0, sample_size_v2=0, ppl=1.83, wps=630.3, ups=0.52, wpb=1201.2, bsz=32, num_updates=39380, lr=7.7268e-06, gnorm=20.586, clip=100, loss_scale=16, train_wall=19, gb_free=10.9, wall=74021
2023-05-26 19:57:05 - progress_bar.py[line:272] - INFO: epoch 023:   1354 / 1732 loss=2.095, loss_v1=0, loss_v2=0, nll_loss=0.862, ntokens=1101.2, nsentences=32, sample_size=1101.2, sample_size_v1=0, sample_size_v2=0, ppl=1.82, wps=582.3, ups=0.53, wpb=1101.2, bsz=32, num_updates=39390, lr=7.72066e-06, gnorm=20.675, clip=100, loss_scale=16, train_wall=19, gb_free=11.5, wall=74040
2023-05-26 19:57:24 - progress_bar.py[line:272] - INFO: epoch 023:   1364 / 1732 loss=2.091, loss_v1=0, loss_v2=0, nll_loss=0.858, ntokens=1115.3, nsentences=32, sample_size=1115.3, sample_size_v1=0, sample_size_v2=0, ppl=1.81, wps=587.9, ups=0.53, wpb=1115.3, bsz=32, num_updates=39400, lr=7.71451e-06, gnorm=19.978, clip=100, loss_scale=16, train_wall=19, gb_free=10.9, wall=74059
2023-05-26 19:57:43 - progress_bar.py[line:272] - INFO: epoch 023:   1374 / 1732 loss=2.13, loss_v1=0, loss_v2=0, nll_loss=0.903, ntokens=1075.1, nsentences=32, sample_size=1075.1, sample_size_v1=0, sample_size_v2=0, ppl=1.87, wps=573.2, ups=0.53, wpb=1075.1, bsz=32, num_updates=39410, lr=7.70837e-06, gnorm=21.574, clip=100, loss_scale=16, train_wall=19, gb_free=11.6, wall=74078
2023-05-26 19:58:02 - progress_bar.py[line:272] - INFO: epoch 023:   1384 / 1732 loss=2.126, loss_v1=0, loss_v2=0, nll_loss=0.895, ntokens=1167.1, nsentences=32, sample_size=1167.1, sample_size_v1=0, sample_size_v2=0, ppl=1.86, wps=618.6, ups=0.53, wpb=1167.1, bsz=32, num_updates=39420, lr=7.70223e-06, gnorm=19.26, clip=100, loss_scale=16, train_wall=19, gb_free=10.8, wall=74097
2023-05-26 19:58:21 - progress_bar.py[line:272] - INFO: epoch 023:   1394 / 1732 loss=2.112, loss_v1=0, loss_v2=0, nll_loss=0.88, ntokens=1039.3, nsentences=32, sample_size=1039.3, sample_size_v1=0, sample_size_v2=0, ppl=1.84, wps=554.8, ups=0.53, wpb=1039.3, bsz=32, num_updates=39430, lr=7.69609e-06, gnorm=21.396, clip=100, loss_scale=16, train_wall=19, gb_free=10.6, wall=74115
2023-05-26 19:58:40 - progress_bar.py[line:272] - INFO: epoch 023:   1404 / 1732 loss=2.107, loss_v1=0, loss_v2=0, nll_loss=0.875, ntokens=1161.9, nsentences=32, sample_size=1161.9, sample_size_v1=0, sample_size_v2=0, ppl=1.83, wps=613.5, ups=0.53, wpb=1161.9, bsz=32, num_updates=39440, lr=7.68995e-06, gnorm=18.015, clip=100, loss_scale=16, train_wall=19, gb_free=10.2, wall=74134
2023-05-26 19:58:59 - progress_bar.py[line:272] - INFO: epoch 023:   1414 / 1732 loss=2.155, loss_v1=0, loss_v2=0, nll_loss=0.93, ntokens=1276, nsentences=32, sample_size=1276, sample_size_v1=0, sample_size_v2=0, ppl=1.91, wps=672.5, ups=0.53, wpb=1276, bsz=32, num_updates=39450, lr=7.6838e-06, gnorm=20.7, clip=100, loss_scale=16, train_wall=19, gb_free=10.6, wall=74153
2023-05-26 19:59:18 - progress_bar.py[line:272] - INFO: epoch 023:   1424 / 1732 loss=2.113, loss_v1=0, loss_v2=0, nll_loss=0.882, ntokens=1261.9, nsentences=32, sample_size=1261.9, sample_size_v1=0, sample_size_v2=0, ppl=1.84, wps=658.1, ups=0.52, wpb=1261.9, bsz=32, num_updates=39460, lr=7.67766e-06, gnorm=19.043, clip=100, loss_scale=16, train_wall=19, gb_free=10.6, wall=74172
2023-05-26 19:59:37 - progress_bar.py[line:272] - INFO: epoch 023:   1434 / 1732 loss=2.116, loss_v1=0, loss_v2=0, nll_loss=0.886, ntokens=1196.2, nsentences=32, sample_size=1196.2, sample_size_v1=0, sample_size_v2=0, ppl=1.85, wps=633.8, ups=0.53, wpb=1196.2, bsz=32, num_updates=39470, lr=7.67152e-06, gnorm=19.386, clip=100, loss_scale=16, train_wall=19, gb_free=11.1, wall=74191
2023-05-26 19:59:56 - progress_bar.py[line:272] - INFO: epoch 023:   1444 / 1732 loss=2.108, loss_v1=0, loss_v2=0, nll_loss=0.877, ntokens=1129.1, nsentences=32, sample_size=1129.1, sample_size_v1=0, sample_size_v2=0, ppl=1.84, wps=597.2, ups=0.53, wpb=1129.1, bsz=32, num_updates=39480, lr=7.66538e-06, gnorm=19.327, clip=100, loss_scale=16, train_wall=19, gb_free=10.6, wall=74210
2023-05-26 20:00:14 - progress_bar.py[line:272] - INFO: epoch 023:   1454 / 1732 loss=2.123, loss_v1=0, loss_v2=0, nll_loss=0.893, ntokens=1122, nsentences=32, sample_size=1122, sample_size_v1=0, sample_size_v2=0, ppl=1.86, wps=596.1, ups=0.53, wpb=1122, bsz=32, num_updates=39490, lr=7.65923e-06, gnorm=21.498, clip=100, loss_scale=16, train_wall=19, gb_free=10.8, wall=74229
2023-05-26 20:00:33 - progress_bar.py[line:272] - INFO: epoch 023:   1464 / 1732 loss=2.105, loss_v1=0, loss_v2=0, nll_loss=0.873, ntokens=1182.3, nsentences=32, sample_size=1182.3, sample_size_v1=0, sample_size_v2=0, ppl=1.83, wps=622.9, ups=0.53, wpb=1182.3, bsz=32, num_updates=39500, lr=7.65309e-06, gnorm=20.271, clip=100, loss_scale=32, train_wall=19, gb_free=11.2, wall=74248
2023-05-26 20:00:52 - progress_bar.py[line:272] - INFO: epoch 023:   1474 / 1732 loss=2.109, loss_v1=0, loss_v2=0, nll_loss=0.877, ntokens=1095.3, nsentences=32, sample_size=1095.3, sample_size_v1=0, sample_size_v2=0, ppl=1.84, wps=581.4, ups=0.53, wpb=1095.3, bsz=32, num_updates=39510, lr=7.64695e-06, gnorm=21.59, clip=100, loss_scale=32, train_wall=19, gb_free=11.3, wall=74267
2023-05-26 20:01:11 - progress_bar.py[line:272] - INFO: epoch 023:   1484 / 1732 loss=2.147, loss_v1=0, loss_v2=0, nll_loss=0.921, ntokens=1096.5, nsentences=32, sample_size=1096.5, sample_size_v1=0, sample_size_v2=0, ppl=1.89, wps=581.2, ups=0.53, wpb=1096.5, bsz=32, num_updates=39520, lr=7.64081e-06, gnorm=21.085, clip=100, loss_scale=32, train_wall=19, gb_free=10.6, wall=74286
2023-05-26 20:01:30 - progress_bar.py[line:272] - INFO: epoch 023:   1494 / 1732 loss=2.109, loss_v1=0, loss_v2=0, nll_loss=0.878, ntokens=1106.4, nsentences=32, sample_size=1106.4, sample_size_v1=0, sample_size_v2=0, ppl=1.84, wps=584.9, ups=0.53, wpb=1106.4, bsz=32, num_updates=39530, lr=7.63467e-06, gnorm=19.59, clip=100, loss_scale=32, train_wall=19, gb_free=11, wall=74305
2023-05-26 20:01:49 - progress_bar.py[line:272] - INFO: epoch 023:   1504 / 1732 loss=2.09, loss_v1=0, loss_v2=0, nll_loss=0.855, ntokens=1153.1, nsentences=32, sample_size=1153.1, sample_size_v1=0, sample_size_v2=0, ppl=1.81, wps=610.5, ups=0.53, wpb=1153.1, bsz=32, num_updates=39540, lr=7.62852e-06, gnorm=19.553, clip=100, loss_scale=32, train_wall=19, gb_free=10.9, wall=74324
2023-05-26 20:02:08 - progress_bar.py[line:272] - INFO: epoch 023:   1514 / 1732 loss=2.125, loss_v1=0, loss_v2=0, nll_loss=0.895, ntokens=1041.2, nsentences=32, sample_size=1041.2, sample_size_v1=0, sample_size_v2=0, ppl=1.86, wps=556.5, ups=0.53, wpb=1041.2, bsz=32, num_updates=39550, lr=7.62238e-06, gnorm=23.446, clip=100, loss_scale=32, train_wall=19, gb_free=11.7, wall=74342
2023-05-26 20:02:26 - progress_bar.py[line:272] - INFO: epoch 023:   1524 / 1732 loss=2.146, loss_v1=0, loss_v2=0, nll_loss=0.92, ntokens=1034.8, nsentences=32, sample_size=1034.8, sample_size_v1=0, sample_size_v2=0, ppl=1.89, wps=551.4, ups=0.53, wpb=1034.8, bsz=32, num_updates=39560, lr=7.61624e-06, gnorm=21.597, clip=100, loss_scale=32, train_wall=19, gb_free=10.5, wall=74361
2023-05-26 20:02:45 - progress_bar.py[line:272] - INFO: epoch 023:   1534 / 1732 loss=2.135, loss_v1=0, loss_v2=0, nll_loss=0.907, ntokens=1092.4, nsentences=32, sample_size=1092.4, sample_size_v1=0, sample_size_v2=0, ppl=1.87, wps=575.9, ups=0.53, wpb=1092.4, bsz=32, num_updates=39570, lr=7.6101e-06, gnorm=21.462, clip=100, loss_scale=32, train_wall=19, gb_free=11, wall=74380
2023-05-26 20:03:00 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2023-05-26 20:03:06 - progress_bar.py[line:272] - INFO: epoch 023:   1545 / 1732 loss=2.087, loss_v1=0, loss_v2=0, nll_loss=0.852, ntokens=1079, nsentences=32, sample_size=1079, sample_size_v1=0, sample_size_v2=0, ppl=1.81, wps=522.7, ups=0.48, wpb=1079, bsz=32, num_updates=39580, lr=7.60396e-06, gnorm=19.975, clip=100, loss_scale=16, train_wall=21, gb_free=11.5, wall=74401
2023-05-26 20:03:25 - progress_bar.py[line:272] - INFO: epoch 023:   1555 / 1732 loss=2.087, loss_v1=0, loss_v2=0, nll_loss=0.853, ntokens=1057.3, nsentences=32, sample_size=1057.3, sample_size_v1=0, sample_size_v2=0, ppl=1.81, wps=564.3, ups=0.53, wpb=1057.3, bsz=32, num_updates=39590, lr=7.59781e-06, gnorm=22.249, clip=100, loss_scale=16, train_wall=19, gb_free=11.2, wall=74419
2023-05-26 20:03:44 - progress_bar.py[line:272] - INFO: epoch 023:   1565 / 1732 loss=2.133, loss_v1=0, loss_v2=0, nll_loss=0.905, ntokens=1124.1, nsentences=32, sample_size=1124.1, sample_size_v1=0, sample_size_v2=0, ppl=1.87, wps=595.3, ups=0.53, wpb=1124.1, bsz=32, num_updates=39600, lr=7.59167e-06, gnorm=22.062, clip=100, loss_scale=16, train_wall=19, gb_free=10.6, wall=74438
2023-05-26 20:04:03 - progress_bar.py[line:272] - INFO: epoch 023:   1575 / 1732 loss=2.121, loss_v1=0, loss_v2=0, nll_loss=0.892, ntokens=1025.1, nsentences=32, sample_size=1025.1, sample_size_v1=0, sample_size_v2=0, ppl=1.86, wps=542.7, ups=0.53, wpb=1025.1, bsz=32, num_updates=39610, lr=7.58553e-06, gnorm=22.273, clip=100, loss_scale=16, train_wall=19, gb_free=11.7, wall=74457
2023-05-26 20:04:21 - progress_bar.py[line:272] - INFO: epoch 023:   1585 / 1732 loss=2.112, loss_v1=0, loss_v2=0, nll_loss=0.881, ntokens=1049.1, nsentences=32, sample_size=1049.1, sample_size_v1=0, sample_size_v2=0, ppl=1.84, wps=555.8, ups=0.53, wpb=1049.1, bsz=32, num_updates=39620, lr=7.57939e-06, gnorm=20.988, clip=100, loss_scale=16, train_wall=19, gb_free=10.6, wall=74476
2023-05-26 20:04:40 - progress_bar.py[line:272] - INFO: epoch 023:   1595 / 1732 loss=2.089, loss_v1=0, loss_v2=0, nll_loss=0.855, ntokens=1072.1, nsentences=32, sample_size=1072.1, sample_size_v1=0, sample_size_v2=0, ppl=1.81, wps=570.1, ups=0.53, wpb=1072.1, bsz=32, num_updates=39630, lr=7.57324e-06, gnorm=18.897, clip=100, loss_scale=16, train_wall=19, gb_free=11, wall=74495
2023-05-26 20:04:59 - progress_bar.py[line:272] - INFO: epoch 023:   1605 / 1732 loss=2.096, loss_v1=0, loss_v2=0, nll_loss=0.862, ntokens=1099, nsentences=32, sample_size=1099, sample_size_v1=0, sample_size_v2=0, ppl=1.82, wps=583.8, ups=0.53, wpb=1099, bsz=32, num_updates=39640, lr=7.5671e-06, gnorm=18.879, clip=100, loss_scale=16, train_wall=19, gb_free=11.2, wall=74514
2023-05-26 20:05:18 - progress_bar.py[line:272] - INFO: epoch 023:   1615 / 1732 loss=2.082, loss_v1=0, loss_v2=0, nll_loss=0.849, ntokens=1176.8, nsentences=32, sample_size=1176.8, sample_size_v1=0, sample_size_v2=0, ppl=1.8, wps=618.7, ups=0.53, wpb=1176.8, bsz=32, num_updates=39650, lr=7.56096e-06, gnorm=19.682, clip=100, loss_scale=16, train_wall=19, gb_free=11.4, wall=74533
2023-05-26 20:05:37 - progress_bar.py[line:272] - INFO: epoch 023:   1625 / 1732 loss=2.119, loss_v1=0, loss_v2=0, nll_loss=0.888, ntokens=1075.4, nsentences=32, sample_size=1075.4, sample_size_v1=0, sample_size_v2=0, ppl=1.85, wps=568.1, ups=0.53, wpb=1075.4, bsz=32, num_updates=39660, lr=7.55482e-06, gnorm=21.6, clip=100, loss_scale=16, train_wall=19, gb_free=10.6, wall=74552
2023-05-26 20:05:56 - progress_bar.py[line:272] - INFO: epoch 023:   1635 / 1732 loss=2.089, loss_v1=0, loss_v2=0, nll_loss=0.855, ntokens=1182.6, nsentences=32, sample_size=1182.6, sample_size_v1=0, sample_size_v2=0, ppl=1.81, wps=626.2, ups=0.53, wpb=1182.6, bsz=32, num_updates=39670, lr=7.54868e-06, gnorm=19.264, clip=100, loss_scale=16, train_wall=19, gb_free=10.6, wall=74571
2023-05-26 20:06:15 - progress_bar.py[line:272] - INFO: epoch 023:   1645 / 1732 loss=2.096, loss_v1=0, loss_v2=0, nll_loss=0.861, ntokens=1274.6, nsentences=32, sample_size=1274.6, sample_size_v1=0, sample_size_v2=0, ppl=1.82, wps=668.9, ups=0.52, wpb=1274.6, bsz=32, num_updates=39680, lr=7.54253e-06, gnorm=19.065, clip=100, loss_scale=16, train_wall=19, gb_free=11, wall=74590
2023-05-26 20:06:34 - progress_bar.py[line:272] - INFO: epoch 023:   1655 / 1732 loss=2.108, loss_v1=0, loss_v2=0, nll_loss=0.877, ntokens=951.7, nsentences=32, sample_size=951.7, sample_size_v1=0, sample_size_v2=0, ppl=1.84, wps=509.9, ups=0.54, wpb=951.7, bsz=32, num_updates=39690, lr=7.53639e-06, gnorm=20.412, clip=100, loss_scale=16, train_wall=19, gb_free=11.2, wall=74608
2023-05-26 20:06:53 - progress_bar.py[line:272] - INFO: epoch 023:   1665 / 1732 loss=2.125, loss_v1=0, loss_v2=0, nll_loss=0.897, ntokens=1028.1, nsentences=32, sample_size=1028.1, sample_size_v1=0, sample_size_v2=0, ppl=1.86, wps=545.5, ups=0.53, wpb=1028.1, bsz=32, num_updates=39700, lr=7.53025e-06, gnorm=20.496, clip=100, loss_scale=16, train_wall=19, gb_free=11, wall=74627
2023-05-26 20:07:11 - progress_bar.py[line:272] - INFO: epoch 023:   1675 / 1732 loss=2.079, loss_v1=0, loss_v2=0, nll_loss=0.845, ntokens=1102.6, nsentences=32, sample_size=1102.6, sample_size_v1=0, sample_size_v2=0, ppl=1.8, wps=585.9, ups=0.53, wpb=1102.6, bsz=32, num_updates=39710, lr=7.52411e-06, gnorm=21.065, clip=100, loss_scale=16, train_wall=19, gb_free=9.9, wall=74646
2023-05-26 20:07:30 - progress_bar.py[line:272] - INFO: epoch 023:   1685 / 1732 loss=2.082, loss_v1=0, loss_v2=0, nll_loss=0.847, ntokens=1141.1, nsentences=32, sample_size=1141.1, sample_size_v1=0, sample_size_v2=0, ppl=1.8, wps=601.8, ups=0.53, wpb=1141.1, bsz=32, num_updates=39720, lr=7.51797e-06, gnorm=19.459, clip=100, loss_scale=16, train_wall=19, gb_free=11.4, wall=74665
2023-05-26 20:07:50 - progress_bar.py[line:272] - INFO: epoch 023:   1695 / 1732 loss=2.115, loss_v1=0, loss_v2=0, nll_loss=0.885, ntokens=1274.5, nsentences=32, sample_size=1274.5, sample_size_v1=0, sample_size_v2=0, ppl=1.85, wps=661.8, ups=0.52, wpb=1274.5, bsz=32, num_updates=39730, lr=7.51182e-06, gnorm=18.318, clip=100, loss_scale=16, train_wall=19, gb_free=11.2, wall=74684
2023-05-26 20:08:09 - progress_bar.py[line:272] - INFO: epoch 023:   1705 / 1732 loss=2.112, loss_v1=0, loss_v2=0, nll_loss=0.881, ntokens=1217, nsentences=32, sample_size=1217, sample_size_v1=0, sample_size_v2=0, ppl=1.84, wps=638.3, ups=0.52, wpb=1217, bsz=32, num_updates=39740, lr=7.50568e-06, gnorm=19.274, clip=100, loss_scale=16, train_wall=19, gb_free=10.8, wall=74703
2023-05-26 20:08:28 - progress_bar.py[line:272] - INFO: epoch 023:   1715 / 1732 loss=2.095, loss_v1=0, loss_v2=0, nll_loss=0.861, ntokens=1196, nsentences=32, sample_size=1196, sample_size_v1=0, sample_size_v2=0, ppl=1.82, wps=630.5, ups=0.53, wpb=1196, bsz=32, num_updates=39750, lr=7.49954e-06, gnorm=17.86, clip=100, loss_scale=16, train_wall=19, gb_free=10.8, wall=74722
2023-05-26 20:08:47 - progress_bar.py[line:272] - INFO: epoch 023:   1725 / 1732 loss=2.098, loss_v1=0, loss_v2=0, nll_loss=0.866, ntokens=1108.9, nsentences=32, sample_size=1108.9, sample_size_v1=0, sample_size_v2=0, ppl=1.82, wps=585.3, ups=0.53, wpb=1108.9, bsz=32, num_updates=39760, lr=7.4934e-06, gnorm=18.4, clip=100, loss_scale=16, train_wall=19, gb_free=11.3, wall=74741
2023-05-26 20:08:58 - train.py[line:332] - INFO: end of epoch 23 (average epoch stats below)
2023-05-26 20:08:58 - progress_bar.py[line:282] - INFO: epoch 023 | loss 2.111 | loss_v1 0 | loss_v2 0 | nll_loss 0.88 | ntokens 1051.61 | nsentences 31.986 | sample_size 1051.61 | sample_size_v1 0 | sample_size_v2 0 | ppl 1.84 | wps 559.7 | ups 0.53 | wpb 1051.6 | bsz 32 | num_updates 39767 | lr 7.4891e-06 | gnorm 20.851 | clip 100 | loss_scale 16 | train_wall 3241 | gb_free 11.7 | wall 74753
2023-05-26 20:08:58 - trainer.py[line:639] - INFO: loading train data for epoch 24
local datafile ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 0 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 0 finished initializing row_count and line_idx-to-offset mapping
file ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 0 row count 55400 total row count 55400
slice_id 0 seek offset 0
2023-05-26 20:09:00 - trainer.py[line:703] - INFO: begin training epoch 24
2023-05-26 20:09:00 - train.py[line:305] - INFO: Start iterating over samples
2023-05-26 20:09:06 - progress_bar.py[line:272] - INFO: epoch 024:      3 / 1732 loss=2.142, loss_v1=0, loss_v2=0, nll_loss=0.915, ntokens=1127.6, nsentences=29.6, sample_size=1127.6, sample_size_v1=0, sample_size_v2=0, ppl=1.89, wps=574, ups=0.51, wpb=1127.6, bsz=29.6, num_updates=39770, lr=7.48726e-06, gnorm=21.086, clip=100, loss_scale=16, train_wall=18, gb_free=11, wall=74761
2023-05-26 20:09:25 - progress_bar.py[line:272] - INFO: epoch 024:     13 / 1732 loss=2.109, loss_v1=0, loss_v2=0, nll_loss=0.877, ntokens=1037.7, nsentences=32, sample_size=1037.7, sample_size_v1=0, sample_size_v2=0, ppl=1.84, wps=549.7, ups=0.53, wpb=1037.7, bsz=32, num_updates=39780, lr=7.48111e-06, gnorm=26.579, clip=100, loss_scale=16, train_wall=19, gb_free=11, wall=74780
2023-05-26 20:09:44 - progress_bar.py[line:272] - INFO: epoch 024:     23 / 1732 loss=2.047, loss_v1=0, loss_v2=0, nll_loss=0.807, ntokens=1082, nsentences=32, sample_size=1082, sample_size_v1=0, sample_size_v2=0, ppl=1.75, wps=574.2, ups=0.53, wpb=1082, bsz=32, num_updates=39790, lr=7.47497e-06, gnorm=23.364, clip=100, loss_scale=16, train_wall=19, gb_free=11.4, wall=74799
2023-05-26 20:10:03 - progress_bar.py[line:272] - INFO: epoch 024:     33 / 1732 loss=2.016, loss_v1=0, loss_v2=0, nll_loss=0.772, ntokens=1032.3, nsentences=32, sample_size=1032.3, sample_size_v1=0, sample_size_v2=0, ppl=1.71, wps=545.4, ups=0.53, wpb=1032.3, bsz=32, num_updates=39800, lr=7.46883e-06, gnorm=20.627, clip=100, loss_scale=16, train_wall=19, gb_free=10.2, wall=74818
2023-05-26 20:10:22 - progress_bar.py[line:272] - INFO: epoch 024:     43 / 1732 loss=1.955, loss_v1=0, loss_v2=0, nll_loss=0.705, ntokens=1156.8, nsentences=32, sample_size=1156.8, sample_size_v1=0, sample_size_v2=0, ppl=1.63, wps=610.8, ups=0.53, wpb=1156.8, bsz=32, num_updates=39810, lr=7.46269e-06, gnorm=20.426, clip=100, loss_scale=16, train_wall=19, gb_free=11, wall=74836
2023-05-26 20:10:41 - progress_bar.py[line:272] - INFO: epoch 024:     53 / 1732 loss=1.997, loss_v1=0, loss_v2=0, nll_loss=0.754, ntokens=1016.6, nsentences=32, sample_size=1016.6, sample_size_v1=0, sample_size_v2=0, ppl=1.69, wps=539.2, ups=0.53, wpb=1016.6, bsz=32, num_updates=39820, lr=7.45654e-06, gnorm=23.541, clip=100, loss_scale=16, train_wall=19, gb_free=11.4, wall=74855
2023-05-26 20:11:00 - progress_bar.py[line:272] - INFO: epoch 024:     63 / 1732 loss=1.844, loss_v1=0, loss_v2=0, nll_loss=0.583, ntokens=1239.4, nsentences=32, sample_size=1239.4, sample_size_v1=0, sample_size_v2=0, ppl=1.5, wps=652.1, ups=0.53, wpb=1239.4, bsz=32, num_updates=39830, lr=7.4504e-06, gnorm=18.819, clip=100, loss_scale=16, train_wall=19, gb_free=10.3, wall=74874
2023-05-26 20:11:19 - progress_bar.py[line:272] - INFO: epoch 024:     73 / 1732 loss=1.921, loss_v1=0, loss_v2=0, nll_loss=0.67, ntokens=1389.6, nsentences=32, sample_size=1389.6, sample_size_v1=0, sample_size_v2=0, ppl=1.59, wps=714.2, ups=0.51, wpb=1389.6, bsz=32, num_updates=39840, lr=7.44426e-06, gnorm=14.114, clip=100, loss_scale=16, train_wall=19, gb_free=10, wall=74894
2023-05-26 20:11:38 - progress_bar.py[line:272] - INFO: epoch 024:     83 / 1732 loss=1.947, loss_v1=0, loss_v2=0, nll_loss=0.699, ntokens=1166.3, nsentences=32, sample_size=1166.3, sample_size_v1=0, sample_size_v2=0, ppl=1.62, wps=607.2, ups=0.52, wpb=1166.3, bsz=32, num_updates=39850, lr=7.43812e-06, gnorm=16.915, clip=100, loss_scale=16, train_wall=19, gb_free=10.2, wall=74913
2023-05-26 20:11:57 - progress_bar.py[line:272] - INFO: epoch 024:     93 / 1732 loss=1.925, loss_v1=0, loss_v2=0, nll_loss=0.672, ntokens=1099.1, nsentences=32, sample_size=1099.1, sample_size_v1=0, sample_size_v2=0, ppl=1.59, wps=578.1, ups=0.53, wpb=1099.1, bsz=32, num_updates=39860, lr=7.43198e-06, gnorm=17.843, clip=100, loss_scale=16, train_wall=19, gb_free=11, wall=74932
2023-05-26 20:12:16 - progress_bar.py[line:272] - INFO: epoch 024:    103 / 1732 loss=2.043, loss_v1=0, loss_v2=0, nll_loss=0.805, ntokens=976, nsentences=32, sample_size=976, sample_size_v1=0, sample_size_v2=0, ppl=1.75, wps=521.5, ups=0.53, wpb=976, bsz=32, num_updates=39870, lr=7.42583e-06, gnorm=20.684, clip=100, loss_scale=16, train_wall=19, gb_free=11.5, wall=74951
2023-05-26 20:12:35 - progress_bar.py[line:272] - INFO: epoch 024:    113 / 1732 loss=2.124, loss_v1=0, loss_v2=0, nll_loss=0.894, ntokens=1030.9, nsentences=32, sample_size=1030.9, sample_size_v1=0, sample_size_v2=0, ppl=1.86, wps=544.9, ups=0.53, wpb=1030.9, bsz=32, num_updates=39880, lr=7.41969e-06, gnorm=24.484, clip=100, loss_scale=16, train_wall=19, gb_free=10.8, wall=74970
2023-05-26 20:12:54 - progress_bar.py[line:272] - INFO: epoch 024:    123 / 1732 loss=2.11, loss_v1=0, loss_v2=0, nll_loss=0.879, ntokens=1142.2, nsentences=32, sample_size=1142.2, sample_size_v1=0, sample_size_v2=0, ppl=1.84, wps=595.4, ups=0.52, wpb=1142.2, bsz=32, num_updates=39890, lr=7.41355e-06, gnorm=21.16, clip=100, loss_scale=16, train_wall=19, gb_free=10.7, wall=74989
2023-05-26 20:13:13 - progress_bar.py[line:272] - INFO: epoch 024:    133 / 1732 loss=2.076, loss_v1=0, loss_v2=0, nll_loss=0.841, ntokens=1207.4, nsentences=32, sample_size=1207.4, sample_size_v1=0, sample_size_v2=0, ppl=1.79, wps=630.2, ups=0.52, wpb=1207.4, bsz=32, num_updates=39900, lr=7.40741e-06, gnorm=22.86, clip=100, loss_scale=16, train_wall=19, gb_free=10.8, wall=75008
2023-05-26 20:13:33 - progress_bar.py[line:272] - INFO: epoch 024:    143 / 1732 loss=2.057, loss_v1=0, loss_v2=0, nll_loss=0.819, ntokens=1226.6, nsentences=32, sample_size=1226.6, sample_size_v1=0, sample_size_v2=0, ppl=1.76, wps=639, ups=0.52, wpb=1226.6, bsz=32, num_updates=39910, lr=7.40127e-06, gnorm=19.576, clip=100, loss_scale=16, train_wall=19, gb_free=10.2, wall=75027
2023-05-26 20:13:52 - progress_bar.py[line:272] - INFO: epoch 024:    153 / 1732 loss=2.054, loss_v1=0, loss_v2=0, nll_loss=0.816, ntokens=1152.6, nsentences=32, sample_size=1152.6, sample_size_v1=0, sample_size_v2=0, ppl=1.76, wps=599.6, ups=0.52, wpb=1152.6, bsz=32, num_updates=39920, lr=7.39512e-06, gnorm=20.554, clip=100, loss_scale=16, train_wall=19, gb_free=10.3, wall=75046
2023-05-26 20:14:11 - progress_bar.py[line:272] - INFO: epoch 024:    163 / 1732 loss=2.063, loss_v1=0, loss_v2=0, nll_loss=0.827, ntokens=1079.7, nsentences=32, sample_size=1079.7, sample_size_v1=0, sample_size_v2=0, ppl=1.77, wps=569.6, ups=0.53, wpb=1079.7, bsz=32, num_updates=39930, lr=7.38898e-06, gnorm=24.128, clip=100, loss_scale=16, train_wall=19, gb_free=11.5, wall=75065
2023-05-26 20:14:30 - progress_bar.py[line:272] - INFO: epoch 024:    173 / 1732 loss=2.071, loss_v1=0, loss_v2=0, nll_loss=0.836, ntokens=936.5, nsentences=32, sample_size=936.5, sample_size_v1=0, sample_size_v2=0, ppl=1.78, wps=497.5, ups=0.53, wpb=936.5, bsz=32, num_updates=39940, lr=7.38284e-06, gnorm=24.837, clip=100, loss_scale=16, train_wall=19, gb_free=10.7, wall=75084
2023-05-26 20:14:49 - progress_bar.py[line:272] - INFO: epoch 024:    183 / 1732 loss=2.038, loss_v1=0, loss_v2=0, nll_loss=0.799, ntokens=1184.7, nsentences=32, sample_size=1184.7, sample_size_v1=0, sample_size_v2=0, ppl=1.74, wps=620.8, ups=0.52, wpb=1184.7, bsz=32, num_updates=39950, lr=7.3767e-06, gnorm=17.623, clip=100, loss_scale=16, train_wall=19, gb_free=11.3, wall=75103
2023-05-26 20:15:08 - progress_bar.py[line:272] - INFO: epoch 024:    193 / 1732 loss=2.045, loss_v1=0, loss_v2=0, nll_loss=0.806, ntokens=1122.8, nsentences=32, sample_size=1122.8, sample_size_v1=0, sample_size_v2=0, ppl=1.75, wps=589.5, ups=0.53, wpb=1122.8, bsz=32, num_updates=39960, lr=7.37055e-06, gnorm=20.423, clip=100, loss_scale=16, train_wall=19, gb_free=11.2, wall=75122
2023-05-26 20:15:26 - progress_bar.py[line:272] - INFO: epoch 024:    203 / 1732 loss=2.101, loss_v1=0, loss_v2=0, nll_loss=0.87, ntokens=1086.7, nsentences=32, sample_size=1086.7, sample_size_v1=0, sample_size_v2=0, ppl=1.83, wps=578.6, ups=0.53, wpb=1086.7, bsz=32, num_updates=39970, lr=7.36441e-06, gnorm=20.657, clip=100, loss_scale=16, train_wall=19, gb_free=11.3, wall=75141
2023-05-26 20:15:45 - progress_bar.py[line:272] - INFO: epoch 024:    213 / 1732 loss=2.104, loss_v1=0, loss_v2=0, nll_loss=0.873, ntokens=1044.9, nsentences=32, sample_size=1044.9, sample_size_v1=0, sample_size_v2=0, ppl=1.83, wps=558.5, ups=0.53, wpb=1044.9, bsz=32, num_updates=39980, lr=7.35827e-06, gnorm=19.549, clip=100, loss_scale=16, train_wall=19, gb_free=11.2, wall=75160
2023-05-26 20:16:04 - progress_bar.py[line:272] - INFO: epoch 024:    223 / 1732 loss=2.129, loss_v1=0, loss_v2=0, nll_loss=0.901, ntokens=1134.6, nsentences=32, sample_size=1134.6, sample_size_v1=0, sample_size_v2=0, ppl=1.87, wps=606.8, ups=0.53, wpb=1134.6, bsz=32, num_updates=39990, lr=7.35213e-06, gnorm=18.913, clip=100, loss_scale=16, train_wall=19, gb_free=11.3, wall=75179
2023-05-26 20:16:23 - progress_bar.py[line:272] - INFO: epoch 024:    233 / 1732 loss=2.145, loss_v1=0, loss_v2=0, nll_loss=0.918, ntokens=1078.6, nsentences=32, sample_size=1078.6, sample_size_v1=0, sample_size_v2=0, ppl=1.89, wps=579, ups=0.54, wpb=1078.6, bsz=32, num_updates=40000, lr=7.34599e-06, gnorm=19.964, clip=100, loss_scale=16, train_wall=19, gb_free=11.5, wall=75197
2023-05-26 20:16:41 - progress_bar.py[line:272] - INFO: epoch 024:    243 / 1732 loss=2.131, loss_v1=0, loss_v2=0, nll_loss=0.901, ntokens=1123.3, nsentences=32, sample_size=1123.3, sample_size_v1=0, sample_size_v2=0, ppl=1.87, wps=596.7, ups=0.53, wpb=1123.3, bsz=32, num_updates=40010, lr=7.33984e-06, gnorm=18.825, clip=100, loss_scale=16, train_wall=19, gb_free=11.5, wall=75216
2023-05-26 20:17:00 - progress_bar.py[line:272] - INFO: epoch 024:    253 / 1732 loss=2.142, loss_v1=0, loss_v2=0, nll_loss=0.914, ntokens=1167.4, nsentences=32, sample_size=1167.4, sample_size_v1=0, sample_size_v2=0, ppl=1.88, wps=620.9, ups=0.53, wpb=1167.4, bsz=32, num_updates=40020, lr=7.3337e-06, gnorm=18.984, clip=100, loss_scale=16, train_wall=19, gb_free=10.8, wall=75235
2023-05-26 20:17:19 - progress_bar.py[line:272] - INFO: epoch 024:    263 / 1732 loss=2.122, loss_v1=0, loss_v2=0, nll_loss=0.893, ntokens=1123.9, nsentences=32, sample_size=1123.9, sample_size_v1=0, sample_size_v2=0, ppl=1.86, wps=601.1, ups=0.53, wpb=1123.9, bsz=32, num_updates=40030, lr=7.32756e-06, gnorm=19.607, clip=100, loss_scale=16, train_wall=19, gb_free=10.8, wall=75254
2023-05-26 20:17:38 - progress_bar.py[line:272] - INFO: epoch 024:    273 / 1732 loss=2.122, loss_v1=0, loss_v2=0, nll_loss=0.893, ntokens=1154.8, nsentences=32, sample_size=1154.8, sample_size_v1=0, sample_size_v2=0, ppl=1.86, wps=612.9, ups=0.53, wpb=1154.8, bsz=32, num_updates=40040, lr=7.32142e-06, gnorm=18.408, clip=100, loss_scale=16, train_wall=19, gb_free=11, wall=75272
2023-05-26 20:17:57 - progress_bar.py[line:272] - INFO: epoch 024:    283 / 1732 loss=2.152, loss_v1=0, loss_v2=0, nll_loss=0.927, ntokens=1146.7, nsentences=32, sample_size=1146.7, sample_size_v1=0, sample_size_v2=0, ppl=1.9, wps=605.4, ups=0.53, wpb=1146.7, bsz=32, num_updates=40050, lr=7.31528e-06, gnorm=19.35, clip=100, loss_scale=16, train_wall=19, gb_free=11.2, wall=75291
2023-05-26 20:18:15 - progress_bar.py[line:272] - INFO: epoch 024:    293 / 1732 loss=2.106, loss_v1=0, loss_v2=0, nll_loss=0.875, ntokens=1122.6, nsentences=32, sample_size=1122.6, sample_size_v1=0, sample_size_v2=0, ppl=1.83, wps=598.5, ups=0.53, wpb=1122.6, bsz=32, num_updates=40060, lr=7.30913e-06, gnorm=19.317, clip=100, loss_scale=16, train_wall=19, gb_free=10.3, wall=75310
2023-05-26 20:18:34 - progress_bar.py[line:272] - INFO: epoch 024:    303 / 1732 loss=2.114, loss_v1=0, loss_v2=0, nll_loss=0.884, ntokens=1117.4, nsentences=32, sample_size=1117.4, sample_size_v1=0, sample_size_v2=0, ppl=1.84, wps=597.5, ups=0.53, wpb=1117.4, bsz=32, num_updates=40070, lr=7.30299e-06, gnorm=23.269, clip=100, loss_scale=16, train_wall=19, gb_free=11.1, wall=75329
2023-05-26 20:18:53 - progress_bar.py[line:272] - INFO: epoch 024:    313 / 1732 loss=2.127, loss_v1=0, loss_v2=0, nll_loss=0.899, ntokens=1045.5, nsentences=32, sample_size=1045.5, sample_size_v1=0, sample_size_v2=0, ppl=1.86, wps=559.4, ups=0.54, wpb=1045.5, bsz=32, num_updates=40080, lr=7.29685e-06, gnorm=21.345, clip=100, loss_scale=16, train_wall=19, gb_free=11.7, wall=75347
2023-05-26 20:19:11 - progress_bar.py[line:272] - INFO: epoch 024:    323 / 1732 loss=2.149, loss_v1=0, loss_v2=0, nll_loss=0.924, ntokens=1005.7, nsentences=32, sample_size=1005.7, sample_size_v1=0, sample_size_v2=0, ppl=1.9, wps=541.2, ups=0.54, wpb=1005.7, bsz=32, num_updates=40090, lr=7.29071e-06, gnorm=21.327, clip=100, loss_scale=32, train_wall=19, gb_free=11.2, wall=75366
2023-05-26 20:19:30 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2023-05-26 20:19:32 - progress_bar.py[line:272] - INFO: epoch 024:    334 / 1732 loss=2.149, loss_v1=0, loss_v2=0, nll_loss=0.924, ntokens=1017, nsentences=32, sample_size=1017, sample_size_v1=0, sample_size_v2=0, ppl=1.9, wps=499.2, ups=0.49, wpb=1017, bsz=32, num_updates=40100, lr=7.28456e-06, gnorm=22.287, clip=100, loss_scale=16, train_wall=20, gb_free=11.3, wall=75386
2023-05-26 20:19:50 - progress_bar.py[line:272] - INFO: epoch 024:    344 / 1732 loss=2.094, loss_v1=0, loss_v2=0, nll_loss=0.861, ntokens=921, nsentences=32, sample_size=921, sample_size_v1=0, sample_size_v2=0, ppl=1.82, wps=497.2, ups=0.54, wpb=921, bsz=32, num_updates=40110, lr=7.27842e-06, gnorm=23.284, clip=100, loss_scale=16, train_wall=18, gb_free=11.4, wall=75405
2023-05-26 20:20:09 - progress_bar.py[line:272] - INFO: epoch 024:    354 / 1732 loss=2.115, loss_v1=0, loss_v2=0, nll_loss=0.885, ntokens=961.9, nsentences=32, sample_size=961.9, sample_size_v1=0, sample_size_v2=0, ppl=1.85, wps=518.3, ups=0.54, wpb=961.9, bsz=32, num_updates=40120, lr=7.27228e-06, gnorm=20.473, clip=100, loss_scale=16, train_wall=19, gb_free=11.3, wall=75424
2023-05-26 20:20:27 - progress_bar.py[line:272] - INFO: epoch 024:    364 / 1732 loss=2.162, loss_v1=0, loss_v2=0, nll_loss=0.938, ntokens=927.9, nsentences=32, sample_size=927.9, sample_size_v1=0, sample_size_v2=0, ppl=1.92, wps=502.6, ups=0.54, wpb=927.9, bsz=32, num_updates=40130, lr=7.26614e-06, gnorm=24.263, clip=100, loss_scale=16, train_wall=18, gb_free=11.8, wall=75442
2023-05-26 20:20:46 - progress_bar.py[line:272] - INFO: epoch 024:    374 / 1732 loss=2.144, loss_v1=0, loss_v2=0, nll_loss=0.918, ntokens=1000.4, nsentences=32, sample_size=1000.4, sample_size_v1=0, sample_size_v2=0, ppl=1.89, wps=539, ups=0.54, wpb=1000.4, bsz=32, num_updates=40140, lr=7.26e-06, gnorm=22.824, clip=100, loss_scale=16, train_wall=19, gb_free=11.5, wall=75461
2023-05-26 20:21:04 - progress_bar.py[line:272] - INFO: epoch 024:    384 / 1732 loss=2.146, loss_v1=0, loss_v2=0, nll_loss=0.92, ntokens=1084.8, nsentences=32, sample_size=1084.8, sample_size_v1=0, sample_size_v2=0, ppl=1.89, wps=584.1, ups=0.54, wpb=1084.8, bsz=32, num_updates=40150, lr=7.25385e-06, gnorm=22.923, clip=100, loss_scale=16, train_wall=19, gb_free=10.9, wall=75479
2023-05-26 20:21:23 - progress_bar.py[line:272] - INFO: epoch 024:    394 / 1732 loss=2.144, loss_v1=0, loss_v2=0, nll_loss=0.917, ntokens=950.6, nsentences=32, sample_size=950.6, sample_size_v1=0, sample_size_v2=0, ppl=1.89, wps=514.3, ups=0.54, wpb=950.6, bsz=32, num_updates=40160, lr=7.24771e-06, gnorm=23.764, clip=100, loss_scale=16, train_wall=18, gb_free=11.7, wall=75498
2023-05-26 20:21:42 - progress_bar.py[line:272] - INFO: epoch 024:    404 / 1732 loss=2.107, loss_v1=0, loss_v2=0, nll_loss=0.875, ntokens=1060.5, nsentences=32, sample_size=1060.5, sample_size_v1=0, sample_size_v2=0, ppl=1.83, wps=567.3, ups=0.53, wpb=1060.5, bsz=32, num_updates=40170, lr=7.24157e-06, gnorm=20.238, clip=100, loss_scale=16, train_wall=19, gb_free=11.1, wall=75516
2023-05-26 20:22:00 - progress_bar.py[line:272] - INFO: epoch 024:    414 / 1732 loss=2.12, loss_v1=0, loss_v2=0, nll_loss=0.889, ntokens=1066.1, nsentences=32, sample_size=1066.1, sample_size_v1=0, sample_size_v2=0, ppl=1.85, wps=572.1, ups=0.54, wpb=1066.1, bsz=32, num_updates=40180, lr=7.23543e-06, gnorm=21.029, clip=100, loss_scale=16, train_wall=19, gb_free=9.9, wall=75535
2023-05-26 20:22:19 - progress_bar.py[line:272] - INFO: epoch 024:    424 / 1732 loss=2.084, loss_v1=0, loss_v2=0, nll_loss=0.85, ntokens=992.6, nsentences=32, sample_size=992.6, sample_size_v1=0, sample_size_v2=0, ppl=1.8, wps=534.2, ups=0.54, wpb=992.6, bsz=32, num_updates=40190, lr=7.22929e-06, gnorm=22.08, clip=100, loss_scale=16, train_wall=19, gb_free=11.7, wall=75554
2023-05-26 20:22:37 - progress_bar.py[line:272] - INFO: epoch 024:    434 / 1732 loss=2.129, loss_v1=0, loss_v2=0, nll_loss=0.9, ntokens=1018.1, nsentences=32, sample_size=1018.1, sample_size_v1=0, sample_size_v2=0, ppl=1.87, wps=548.3, ups=0.54, wpb=1018.1, bsz=32, num_updates=40200, lr=7.22314e-06, gnorm=22.037, clip=100, loss_scale=16, train_wall=19, gb_free=11.8, wall=75572
2023-05-26 20:22:56 - progress_bar.py[line:272] - INFO: epoch 024:    444 / 1732 loss=2.136, loss_v1=0, loss_v2=0, nll_loss=0.909, ntokens=952.1, nsentences=32, sample_size=952.1, sample_size_v1=0, sample_size_v2=0, ppl=1.88, wps=514, ups=0.54, wpb=952.1, bsz=32, num_updates=40210, lr=7.217e-06, gnorm=22.12, clip=100, loss_scale=16, train_wall=18, gb_free=11.7, wall=75591
2023-05-26 20:23:14 - progress_bar.py[line:272] - INFO: epoch 024:    454 / 1732 loss=2.128, loss_v1=0, loss_v2=0, nll_loss=0.899, ntokens=919.5, nsentences=32, sample_size=919.5, sample_size_v1=0, sample_size_v2=0, ppl=1.86, wps=496.9, ups=0.54, wpb=919.5, bsz=32, num_updates=40220, lr=7.21086e-06, gnorm=24.471, clip=100, loss_scale=16, train_wall=18, gb_free=11.4, wall=75609
2023-05-26 20:23:33 - progress_bar.py[line:272] - INFO: epoch 024:    464 / 1732 loss=2.163, loss_v1=0, loss_v2=0, nll_loss=0.939, ntokens=1076.9, nsentences=32, sample_size=1076.9, sample_size_v1=0, sample_size_v2=0, ppl=1.92, wps=576.6, ups=0.54, wpb=1076.9, bsz=32, num_updates=40230, lr=7.20472e-06, gnorm=22.256, clip=100, loss_scale=16, train_wall=19, gb_free=11.7, wall=75628
2023-05-26 20:23:52 - progress_bar.py[line:272] - INFO: epoch 024:    474 / 1732 loss=2.155, loss_v1=0, loss_v2=0, nll_loss=0.929, ntokens=1067.6, nsentences=32, sample_size=1067.6, sample_size_v1=0, sample_size_v2=0, ppl=1.9, wps=568.9, ups=0.53, wpb=1067.6, bsz=32, num_updates=40240, lr=7.19858e-06, gnorm=23.248, clip=100, loss_scale=16, train_wall=19, gb_free=11.8, wall=75647
2023-05-26 20:24:10 - progress_bar.py[line:272] - INFO: epoch 024:    484 / 1732 loss=2.135, loss_v1=0, loss_v2=0, nll_loss=0.907, ntokens=966.8, nsentences=32, sample_size=966.8, sample_size_v1=0, sample_size_v2=0, ppl=1.88, wps=522.4, ups=0.54, wpb=966.8, bsz=32, num_updates=40250, lr=7.19243e-06, gnorm=24.107, clip=100, loss_scale=16, train_wall=18, gb_free=11.6, wall=75665
2023-05-26 20:24:29 - progress_bar.py[line:272] - INFO: epoch 024:    494 / 1732 loss=2.114, loss_v1=0, loss_v2=0, nll_loss=0.882, ntokens=937.9, nsentences=32, sample_size=937.9, sample_size_v1=0, sample_size_v2=0, ppl=1.84, wps=505.1, ups=0.54, wpb=937.9, bsz=32, num_updates=40260, lr=7.18629e-06, gnorm=21.324, clip=100, loss_scale=16, train_wall=19, gb_free=11.3, wall=75684
2023-05-26 20:24:47 - progress_bar.py[line:272] - INFO: epoch 024:    504 / 1732 loss=2.148, loss_v1=0, loss_v2=0, nll_loss=0.922, ntokens=981, nsentences=32, sample_size=981, sample_size_v1=0, sample_size_v2=0, ppl=1.89, wps=533.5, ups=0.54, wpb=981, bsz=32, num_updates=40270, lr=7.18015e-06, gnorm=23.499, clip=100, loss_scale=16, train_wall=18, gb_free=11.4, wall=75702
2023-05-26 20:25:06 - progress_bar.py[line:272] - INFO: epoch 024:    514 / 1732 loss=2.161, loss_v1=0, loss_v2=0, nll_loss=0.936, ntokens=1052.2, nsentences=32, sample_size=1052.2, sample_size_v1=0, sample_size_v2=0, ppl=1.91, wps=567, ups=0.54, wpb=1052.2, bsz=32, num_updates=40280, lr=7.17401e-06, gnorm=21.449, clip=100, loss_scale=16, train_wall=19, gb_free=11.7, wall=75721
2023-05-26 20:25:24 - progress_bar.py[line:272] - INFO: epoch 024:    524 / 1732 loss=2.123, loss_v1=0, loss_v2=0, nll_loss=0.894, ntokens=980.8, nsentences=32, sample_size=980.8, sample_size_v1=0, sample_size_v2=0, ppl=1.86, wps=531.5, ups=0.54, wpb=980.8, bsz=32, num_updates=40290, lr=7.16786e-06, gnorm=24.221, clip=100, loss_scale=16, train_wall=18, gb_free=11.6, wall=75739
2023-05-26 20:25:43 - progress_bar.py[line:272] - INFO: epoch 024:    534 / 1732 loss=2.139, loss_v1=0, loss_v2=0, nll_loss=0.911, ntokens=944.9, nsentences=32, sample_size=944.9, sample_size_v1=0, sample_size_v2=0, ppl=1.88, wps=511.9, ups=0.54, wpb=944.9, bsz=32, num_updates=40300, lr=7.16172e-06, gnorm=22.768, clip=100, loss_scale=16, train_wall=18, gb_free=11.5, wall=75758
2023-05-26 20:26:01 - progress_bar.py[line:272] - INFO: epoch 024:    544 / 1732 loss=2.148, loss_v1=0, loss_v2=0, nll_loss=0.922, ntokens=998.9, nsentences=32, sample_size=998.9, sample_size_v1=0, sample_size_v2=0, ppl=1.89, wps=538.9, ups=0.54, wpb=998.9, bsz=32, num_updates=40310, lr=7.15558e-06, gnorm=22.506, clip=100, loss_scale=16, train_wall=19, gb_free=11.5, wall=75776
2023-05-26 20:26:20 - progress_bar.py[line:272] - INFO: epoch 024:    554 / 1732 loss=2.172, loss_v1=0, loss_v2=0, nll_loss=0.949, ntokens=1026.7, nsentences=32, sample_size=1026.7, sample_size_v1=0, sample_size_v2=0, ppl=1.93, wps=553.9, ups=0.54, wpb=1026.7, bsz=32, num_updates=40320, lr=7.14944e-06, gnorm=23.222, clip=100, loss_scale=16, train_wall=19, gb_free=11.3, wall=75795
2023-05-26 20:26:39 - progress_bar.py[line:272] - INFO: epoch 024:    564 / 1732 loss=2.168, loss_v1=0, loss_v2=0, nll_loss=0.943, ntokens=1028.3, nsentences=32, sample_size=1028.3, sample_size_v1=0, sample_size_v2=0, ppl=1.92, wps=553.2, ups=0.54, wpb=1028.3, bsz=32, num_updates=40330, lr=7.1433e-06, gnorm=23.564, clip=100, loss_scale=16, train_wall=19, gb_free=11, wall=75813
2023-05-26 20:26:57 - progress_bar.py[line:272] - INFO: epoch 024:    574 / 1732 loss=2.154, loss_v1=0, loss_v2=0, nll_loss=0.928, ntokens=1015.5, nsentences=32, sample_size=1015.5, sample_size_v1=0, sample_size_v2=0, ppl=1.9, wps=537.1, ups=0.53, wpb=1015.5, bsz=32, num_updates=40340, lr=7.13715e-06, gnorm=23.513, clip=100, loss_scale=16, train_wall=19, gb_free=11.3, wall=75832
2023-05-26 20:27:16 - progress_bar.py[line:272] - INFO: epoch 024:    584 / 1732 loss=2.156, loss_v1=0, loss_v2=0, nll_loss=0.931, ntokens=991.8, nsentences=32, sample_size=991.8, sample_size_v1=0, sample_size_v2=0, ppl=1.91, wps=531.6, ups=0.54, wpb=991.8, bsz=32, num_updates=40350, lr=7.13101e-06, gnorm=22.292, clip=100, loss_scale=16, train_wall=19, gb_free=10.8, wall=75851
2023-05-26 20:27:35 - progress_bar.py[line:272] - INFO: epoch 024:    594 / 1732 loss=2.102, loss_v1=0, loss_v2=0, nll_loss=0.868, ntokens=957.2, nsentences=32, sample_size=957.2, sample_size_v1=0, sample_size_v2=0, ppl=1.83, wps=513.4, ups=0.54, wpb=957.2, bsz=32, num_updates=40360, lr=7.12487e-06, gnorm=20.438, clip=100, loss_scale=16, train_wall=19, gb_free=11, wall=75869
2023-05-26 20:27:53 - progress_bar.py[line:272] - INFO: epoch 024:    604 / 1732 loss=2.11, loss_v1=0, loss_v2=0, nll_loss=0.879, ntokens=888.6, nsentences=32, sample_size=888.6, sample_size_v1=0, sample_size_v2=0, ppl=1.84, wps=482.1, ups=0.54, wpb=888.6, bsz=32, num_updates=40370, lr=7.11873e-06, gnorm=23.142, clip=100, loss_scale=16, train_wall=18, gb_free=11.3, wall=75888
2023-05-26 20:28:12 - progress_bar.py[line:272] - INFO: epoch 024:    614 / 1732 loss=2.147, loss_v1=0, loss_v2=0, nll_loss=0.921, ntokens=891, nsentences=32, sample_size=891, sample_size_v1=0, sample_size_v2=0, ppl=1.89, wps=482.4, ups=0.54, wpb=891, bsz=32, num_updates=40380, lr=7.11259e-06, gnorm=25.142, clip=100, loss_scale=16, train_wall=18, gb_free=11.6, wall=75906
2023-05-26 20:28:30 - progress_bar.py[line:272] - INFO: epoch 024:    624 / 1732 loss=2.141, loss_v1=0, loss_v2=0, nll_loss=0.915, ntokens=899.1, nsentences=32, sample_size=899.1, sample_size_v1=0, sample_size_v2=0, ppl=1.89, wps=489.5, ups=0.54, wpb=899.1, bsz=32, num_updates=40390, lr=7.10644e-06, gnorm=25.253, clip=100, loss_scale=16, train_wall=18, gb_free=11.9, wall=75925
2023-05-26 20:28:48 - progress_bar.py[line:272] - INFO: epoch 024:    634 / 1732 loss=2.126, loss_v1=0, loss_v2=0, nll_loss=0.897, ntokens=904.7, nsentences=32, sample_size=904.7, sample_size_v1=0, sample_size_v2=0, ppl=1.86, wps=492.1, ups=0.54, wpb=904.7, bsz=32, num_updates=40400, lr=7.1003e-06, gnorm=24.244, clip=100, loss_scale=16, train_wall=18, gb_free=11.9, wall=75943
2023-05-26 20:29:07 - progress_bar.py[line:272] - INFO: epoch 024:    644 / 1732 loss=2.142, loss_v1=0, loss_v2=0, nll_loss=0.915, ntokens=979.3, nsentences=32, sample_size=979.3, sample_size_v1=0, sample_size_v2=0, ppl=1.89, wps=529.4, ups=0.54, wpb=979.3, bsz=32, num_updates=40410, lr=7.09416e-06, gnorm=22.09, clip=100, loss_scale=16, train_wall=18, gb_free=11.7, wall=75962
2023-05-26 20:29:25 - progress_bar.py[line:272] - INFO: epoch 024:    654 / 1732 loss=2.125, loss_v1=0, loss_v2=0, nll_loss=0.896, ntokens=909.5, nsentences=32, sample_size=909.5, sample_size_v1=0, sample_size_v2=0, ppl=1.86, wps=497.2, ups=0.55, wpb=909.5, bsz=32, num_updates=40420, lr=7.08802e-06, gnorm=22.588, clip=100, loss_scale=16, train_wall=18, gb_free=11.4, wall=75980
2023-05-26 20:29:44 - progress_bar.py[line:272] - INFO: epoch 024:    664 / 1732 loss=2.125, loss_v1=0, loss_v2=0, nll_loss=0.897, ntokens=889.3, nsentences=32, sample_size=889.3, sample_size_v1=0, sample_size_v2=0, ppl=1.86, wps=484.5, ups=0.54, wpb=889.3, bsz=32, num_updates=40430, lr=7.08187e-06, gnorm=24.899, clip=100, loss_scale=16, train_wall=18, gb_free=11.7, wall=75998
2023-05-26 20:30:02 - progress_bar.py[line:272] - INFO: epoch 024:    674 / 1732 loss=2.154, loss_v1=0, loss_v2=0, nll_loss=0.928, ntokens=964.6, nsentences=32, sample_size=964.6, sample_size_v1=0, sample_size_v2=0, ppl=1.9, wps=521.4, ups=0.54, wpb=964.6, bsz=32, num_updates=40440, lr=7.07573e-06, gnorm=24.241, clip=100, loss_scale=16, train_wall=18, gb_free=11.5, wall=76017
2023-05-26 20:30:21 - progress_bar.py[line:272] - INFO: epoch 024:    684 / 1732 loss=2.127, loss_v1=0, loss_v2=0, nll_loss=0.898, ntokens=968.6, nsentences=32, sample_size=968.6, sample_size_v1=0, sample_size_v2=0, ppl=1.86, wps=524.8, ups=0.54, wpb=968.6, bsz=32, num_updates=40450, lr=7.06959e-06, gnorm=22.662, clip=100, loss_scale=16, train_wall=18, gb_free=11.9, wall=76035
2023-05-26 20:30:39 - progress_bar.py[line:272] - INFO: epoch 024:    694 / 1732 loss=2.144, loss_v1=0, loss_v2=0, nll_loss=0.917, ntokens=975.2, nsentences=32, sample_size=975.2, sample_size_v1=0, sample_size_v2=0, ppl=1.89, wps=524, ups=0.54, wpb=975.2, bsz=32, num_updates=40460, lr=7.06345e-06, gnorm=25.614, clip=100, loss_scale=16, train_wall=19, gb_free=11, wall=76054
2023-05-26 20:30:58 - progress_bar.py[line:272] - INFO: epoch 024:    704 / 1732 loss=2.089, loss_v1=0, loss_v2=0, nll_loss=0.855, ntokens=954.2, nsentences=32, sample_size=954.2, sample_size_v1=0, sample_size_v2=0, ppl=1.81, wps=516.1, ups=0.54, wpb=954.2, bsz=32, num_updates=40470, lr=7.05731e-06, gnorm=20.935, clip=100, loss_scale=16, train_wall=18, gb_free=11.8, wall=76072
2023-05-26 20:31:16 - progress_bar.py[line:272] - INFO: epoch 024:    714 / 1732 loss=2.148, loss_v1=0, loss_v2=0, nll_loss=0.923, ntokens=885.5, nsentences=32, sample_size=885.5, sample_size_v1=0, sample_size_v2=0, ppl=1.9, wps=481.5, ups=0.54, wpb=885.5, bsz=32, num_updates=40480, lr=7.05116e-06, gnorm=23.81, clip=100, loss_scale=16, train_wall=18, gb_free=11.3, wall=76091
2023-05-26 20:31:34 - progress_bar.py[line:272] - INFO: epoch 024:    724 / 1732 loss=2.08, loss_v1=0, loss_v2=0, nll_loss=0.846, ntokens=897.8, nsentences=32, sample_size=897.8, sample_size_v1=0, sample_size_v2=0, ppl=1.8, wps=488.1, ups=0.54, wpb=897.8, bsz=32, num_updates=40490, lr=7.04502e-06, gnorm=20.926, clip=100, loss_scale=16, train_wall=18, gb_free=11.7, wall=76109
2023-05-26 20:31:53 - progress_bar.py[line:272] - INFO: epoch 024:    734 / 1732 loss=2.125, loss_v1=0, loss_v2=0, nll_loss=0.896, ntokens=952.3, nsentences=32, sample_size=952.3, sample_size_v1=0, sample_size_v2=0, ppl=1.86, wps=514.8, ups=0.54, wpb=952.3, bsz=32, num_updates=40500, lr=7.03888e-06, gnorm=24.159, clip=100, loss_scale=16, train_wall=18, gb_free=11.6, wall=76128
2023-05-26 20:32:11 - progress_bar.py[line:272] - INFO: epoch 024:    744 / 1732 loss=2.115, loss_v1=0, loss_v2=0, nll_loss=0.884, ntokens=999.9, nsentences=32, sample_size=999.9, sample_size_v1=0, sample_size_v2=0, ppl=1.85, wps=539.4, ups=0.54, wpb=999.9, bsz=32, num_updates=40510, lr=7.03274e-06, gnorm=22.263, clip=100, loss_scale=16, train_wall=19, gb_free=11, wall=76146
2023-05-26 20:32:30 - progress_bar.py[line:272] - INFO: epoch 024:    754 / 1732 loss=2.117, loss_v1=0, loss_v2=0, nll_loss=0.886, ntokens=976.3, nsentences=32, sample_size=976.3, sample_size_v1=0, sample_size_v2=0, ppl=1.85, wps=526.3, ups=0.54, wpb=976.3, bsz=32, num_updates=40520, lr=7.0266e-06, gnorm=22.128, clip=100, loss_scale=16, train_wall=19, gb_free=11.5, wall=76165
2023-05-26 20:32:48 - progress_bar.py[line:272] - INFO: epoch 024:    764 / 1732 loss=2.132, loss_v1=0, loss_v2=0, nll_loss=0.904, ntokens=943.8, nsentences=32, sample_size=943.8, sample_size_v1=0, sample_size_v2=0, ppl=1.87, wps=513.8, ups=0.54, wpb=943.8, bsz=32, num_updates=40530, lr=7.02045e-06, gnorm=24.655, clip=100, loss_scale=16, train_wall=18, gb_free=11.8, wall=76183
2023-05-26 20:33:07 - progress_bar.py[line:272] - INFO: epoch 024:    774 / 1732 loss=2.117, loss_v1=0, loss_v2=0, nll_loss=0.888, ntokens=1000.5, nsentences=32, sample_size=1000.5, sample_size_v1=0, sample_size_v2=0, ppl=1.85, wps=540.5, ups=0.54, wpb=1000.5, bsz=32, num_updates=40540, lr=7.01431e-06, gnorm=24.227, clip=100, loss_scale=16, train_wall=18, gb_free=11.4, wall=76202
2023-05-26 20:33:25 - progress_bar.py[line:272] - INFO: epoch 024:    784 / 1732 loss=2.122, loss_v1=0, loss_v2=0, nll_loss=0.893, ntokens=1008.3, nsentences=32, sample_size=1008.3, sample_size_v1=0, sample_size_v2=0, ppl=1.86, wps=545.6, ups=0.54, wpb=1008.3, bsz=32, num_updates=40550, lr=7.00817e-06, gnorm=23.206, clip=100, loss_scale=16, train_wall=18, gb_free=11.3, wall=76220
2023-05-26 20:33:44 - progress_bar.py[line:272] - INFO: epoch 024:    794 / 1732 loss=2.145, loss_v1=0, loss_v2=0, nll_loss=0.919, ntokens=1024.7, nsentences=32, sample_size=1024.7, sample_size_v1=0, sample_size_v2=0, ppl=1.89, wps=554.5, ups=0.54, wpb=1024.7, bsz=32, num_updates=40560, lr=7.00203e-06, gnorm=25.389, clip=100, loss_scale=16, train_wall=18, gb_free=11.7, wall=76239
2023-05-26 20:34:02 - progress_bar.py[line:272] - INFO: epoch 024:    804 / 1732 loss=2.139, loss_v1=0, loss_v2=0, nll_loss=0.911, ntokens=947.8, nsentences=32, sample_size=947.8, sample_size_v1=0, sample_size_v2=0, ppl=1.88, wps=513.3, ups=0.54, wpb=947.8, bsz=32, num_updates=40570, lr=6.99588e-06, gnorm=26.073, clip=100, loss_scale=16, train_wall=18, gb_free=11.6, wall=76257
2023-05-26 20:34:21 - progress_bar.py[line:272] - INFO: epoch 024:    814 / 1732 loss=2.142, loss_v1=0, loss_v2=0, nll_loss=0.915, ntokens=938.1, nsentences=32, sample_size=938.1, sample_size_v1=0, sample_size_v2=0, ppl=1.89, wps=506.6, ups=0.54, wpb=938.1, bsz=32, num_updates=40580, lr=6.98974e-06, gnorm=26.27, clip=100, loss_scale=16, train_wall=18, gb_free=11.8, wall=76276
2023-05-26 20:34:39 - progress_bar.py[line:272] - INFO: epoch 024:    824 / 1732 loss=2.132, loss_v1=0, loss_v2=0, nll_loss=0.903, ntokens=923.7, nsentences=32, sample_size=923.7, sample_size_v1=0, sample_size_v2=0, ppl=1.87, wps=497.7, ups=0.54, wpb=923.7, bsz=32, num_updates=40590, lr=6.9836e-06, gnorm=24.661, clip=100, loss_scale=16, train_wall=19, gb_free=11.1, wall=76294
2023-05-26 20:34:58 - progress_bar.py[line:272] - INFO: epoch 024:    834 / 1732 loss=2.14, loss_v1=0, loss_v2=0, nll_loss=0.912, ntokens=890.1, nsentences=32, sample_size=890.1, sample_size_v1=0, sample_size_v2=0, ppl=1.88, wps=486.5, ups=0.55, wpb=890.1, bsz=32, num_updates=40600, lr=6.97746e-06, gnorm=26.375, clip=100, loss_scale=16, train_wall=18, gb_free=11.9, wall=76312
2023-05-26 20:35:16 - progress_bar.py[line:272] - INFO: epoch 024:    844 / 1732 loss=2.124, loss_v1=0, loss_v2=0, nll_loss=0.894, ntokens=972.2, nsentences=32, sample_size=972.2, sample_size_v1=0, sample_size_v2=0, ppl=1.86, wps=528.9, ups=0.54, wpb=972.2, bsz=32, num_updates=40610, lr=6.97132e-06, gnorm=25.211, clip=100, loss_scale=16, train_wall=18, gb_free=11.5, wall=76331
2023-05-26 20:35:35 - progress_bar.py[line:272] - INFO: epoch 024:    854 / 1732 loss=2.124, loss_v1=0, loss_v2=0, nll_loss=0.893, ntokens=976.8, nsentences=32, sample_size=976.8, sample_size_v1=0, sample_size_v2=0, ppl=1.86, wps=528.1, ups=0.54, wpb=976.8, bsz=32, num_updates=40620, lr=6.96517e-06, gnorm=22.744, clip=100, loss_scale=32, train_wall=18, gb_free=11.5, wall=76349
2023-05-26 20:35:53 - progress_bar.py[line:272] - INFO: epoch 024:    864 / 1732 loss=2.129, loss_v1=0, loss_v2=0, nll_loss=0.901, ntokens=958.7, nsentences=32, sample_size=958.7, sample_size_v1=0, sample_size_v2=0, ppl=1.87, wps=519, ups=0.54, wpb=958.7, bsz=32, num_updates=40630, lr=6.95903e-06, gnorm=22.334, clip=100, loss_scale=32, train_wall=18, gb_free=11.4, wall=76368
2023-05-26 20:36:12 - progress_bar.py[line:272] - INFO: epoch 024:    874 / 1732 loss=2.105, loss_v1=0, loss_v2=0, nll_loss=0.874, ntokens=975.5, nsentences=32, sample_size=975.5, sample_size_v1=0, sample_size_v2=0, ppl=1.83, wps=527.1, ups=0.54, wpb=975.5, bsz=32, num_updates=40640, lr=6.95289e-06, gnorm=24.276, clip=100, loss_scale=32, train_wall=18, gb_free=11, wall=76386
2023-05-26 20:36:30 - progress_bar.py[line:272] - INFO: epoch 024:    884 / 1732 loss=2.064, loss_v1=0, loss_v2=0, nll_loss=0.828, ntokens=977.6, nsentences=32, sample_size=977.6, sample_size_v1=0, sample_size_v2=0, ppl=1.77, wps=526.3, ups=0.54, wpb=977.6, bsz=32, num_updates=40650, lr=6.94675e-06, gnorm=21.915, clip=100, loss_scale=32, train_wall=19, gb_free=11.3, wall=76405
2023-05-26 20:36:49 - progress_bar.py[line:272] - INFO: epoch 024:    894 / 1732 loss=2.08, loss_v1=0, loss_v2=0, nll_loss=0.847, ntokens=1010, nsentences=32, sample_size=1010, sample_size_v1=0, sample_size_v2=0, ppl=1.8, wps=544.1, ups=0.54, wpb=1010, bsz=32, num_updates=40660, lr=6.94061e-06, gnorm=20.919, clip=100, loss_scale=32, train_wall=19, gb_free=10.9, wall=76423
2023-05-26 20:37:07 - progress_bar.py[line:272] - INFO: epoch 024:    904 / 1732 loss=2.085, loss_v1=0, loss_v2=0, nll_loss=0.852, ntokens=1055.2, nsentences=32, sample_size=1055.2, sample_size_v1=0, sample_size_v2=0, ppl=1.8, wps=568.7, ups=0.54, wpb=1055.2, bsz=32, num_updates=40670, lr=6.93446e-06, gnorm=21.334, clip=100, loss_scale=32, train_wall=19, gb_free=11.5, wall=76442
2023-05-26 20:37:22 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2023-05-26 20:37:28 - progress_bar.py[line:272] - INFO: epoch 024:    915 / 1732 loss=2.133, loss_v1=0, loss_v2=0, nll_loss=0.906, ntokens=935.3, nsentences=32, sample_size=935.3, sample_size_v1=0, sample_size_v2=0, ppl=1.87, wps=462.3, ups=0.49, wpb=935.3, bsz=32, num_updates=40680, lr=6.92832e-06, gnorm=25.178, clip=100, loss_scale=16, train_wall=20, gb_free=12, wall=76462
2023-05-26 20:37:46 - progress_bar.py[line:272] - INFO: epoch 024:    925 / 1732 loss=2.098, loss_v1=0, loss_v2=0, nll_loss=0.865, ntokens=1005.1, nsentences=32, sample_size=1005.1, sample_size_v1=0, sample_size_v2=0, ppl=1.82, wps=537.2, ups=0.53, wpb=1005.1, bsz=32, num_updates=40690, lr=6.92218e-06, gnorm=22.859, clip=100, loss_scale=16, train_wall=19, gb_free=11.8, wall=76481
2023-05-26 20:38:05 - progress_bar.py[line:272] - INFO: epoch 024:    935 / 1732 loss=2.126, loss_v1=0, loss_v2=0, nll_loss=0.896, ntokens=1058.5, nsentences=32, sample_size=1058.5, sample_size_v1=0, sample_size_v2=0, ppl=1.86, wps=565.7, ups=0.53, wpb=1058.5, bsz=32, num_updates=40700, lr=6.91604e-06, gnorm=22.856, clip=100, loss_scale=16, train_wall=19, gb_free=11.3, wall=76500
2023-05-26 20:38:24 - progress_bar.py[line:272] - INFO: epoch 024:    945 / 1732 loss=2.153, loss_v1=0, loss_v2=0, nll_loss=0.926, ntokens=1055.4, nsentences=32, sample_size=1055.4, sample_size_v1=0, sample_size_v2=0, ppl=1.9, wps=560.2, ups=0.53, wpb=1055.4, bsz=32, num_updates=40710, lr=6.90989e-06, gnorm=23.403, clip=100, loss_scale=16, train_wall=19, gb_free=11.2, wall=76519
2023-05-26 20:38:43 - progress_bar.py[line:272] - INFO: epoch 024:    955 / 1732 loss=2.128, loss_v1=0, loss_v2=0, nll_loss=0.9, ntokens=1040.2, nsentences=32, sample_size=1040.2, sample_size_v1=0, sample_size_v2=0, ppl=1.87, wps=554.8, ups=0.53, wpb=1040.2, bsz=32, num_updates=40720, lr=6.90375e-06, gnorm=23.977, clip=100, loss_scale=16, train_wall=19, gb_free=11.4, wall=76537
2023-05-26 20:39:01 - progress_bar.py[line:272] - INFO: epoch 024:    965 / 1732 loss=2.141, loss_v1=0, loss_v2=0, nll_loss=0.915, ntokens=1047.7, nsentences=32, sample_size=1047.7, sample_size_v1=0, sample_size_v2=0, ppl=1.89, wps=558.5, ups=0.53, wpb=1047.7, bsz=32, num_updates=40730, lr=6.89761e-06, gnorm=24.253, clip=100, loss_scale=16, train_wall=19, gb_free=11.4, wall=76556
2023-05-26 20:39:20 - progress_bar.py[line:272] - INFO: epoch 024:    975 / 1732 loss=2.109, loss_v1=0, loss_v2=0, nll_loss=0.877, ntokens=1038, nsentences=32, sample_size=1038, sample_size_v1=0, sample_size_v2=0, ppl=1.84, wps=550.9, ups=0.53, wpb=1038, bsz=32, num_updates=40740, lr=6.89147e-06, gnorm=23.867, clip=100, loss_scale=16, train_wall=19, gb_free=11.6, wall=76575
2023-05-26 20:39:39 - progress_bar.py[line:272] - INFO: epoch 024:    985 / 1732 loss=2.123, loss_v1=0, loss_v2=0, nll_loss=0.895, ntokens=1034.6, nsentences=32, sample_size=1034.6, sample_size_v1=0, sample_size_v2=0, ppl=1.86, wps=549.1, ups=0.53, wpb=1034.6, bsz=32, num_updates=40750, lr=6.88533e-06, gnorm=20.844, clip=100, loss_scale=16, train_wall=19, gb_free=11.6, wall=76594
2023-05-26 20:39:58 - progress_bar.py[line:272] - INFO: epoch 024:    995 / 1732 loss=2.124, loss_v1=0, loss_v2=0, nll_loss=0.894, ntokens=1048.7, nsentences=32, sample_size=1048.7, sample_size_v1=0, sample_size_v2=0, ppl=1.86, wps=559.1, ups=0.53, wpb=1048.7, bsz=32, num_updates=40760, lr=6.87918e-06, gnorm=21.249, clip=100, loss_scale=16, train_wall=19, gb_free=10.6, wall=76612
2023-05-26 20:40:16 - progress_bar.py[line:272] - INFO: epoch 024:   1005 / 1732 loss=2.125, loss_v1=0, loss_v2=0, nll_loss=0.894, ntokens=981.9, nsentences=32, sample_size=981.9, sample_size_v1=0, sample_size_v2=0, ppl=1.86, wps=526.9, ups=0.54, wpb=981.9, bsz=32, num_updates=40770, lr=6.87304e-06, gnorm=24.489, clip=100, loss_scale=16, train_wall=19, gb_free=11.5, wall=76631
2023-05-26 20:40:35 - progress_bar.py[line:272] - INFO: epoch 024:   1015 / 1732 loss=2.118, loss_v1=0, loss_v2=0, nll_loss=0.887, ntokens=996.6, nsentences=32, sample_size=996.6, sample_size_v1=0, sample_size_v2=0, ppl=1.85, wps=535.8, ups=0.54, wpb=996.6, bsz=32, num_updates=40780, lr=6.8669e-06, gnorm=21.594, clip=100, loss_scale=16, train_wall=19, gb_free=11.7, wall=76650
2023-05-26 20:40:54 - progress_bar.py[line:272] - INFO: epoch 024:   1025 / 1732 loss=2.115, loss_v1=0, loss_v2=0, nll_loss=0.884, ntokens=1087.5, nsentences=32, sample_size=1087.5, sample_size_v1=0, sample_size_v2=0, ppl=1.85, wps=574.2, ups=0.53, wpb=1087.5, bsz=32, num_updates=40790, lr=6.86076e-06, gnorm=21.332, clip=100, loss_scale=16, train_wall=19, gb_free=10.8, wall=76669
2023-05-26 20:41:13 - progress_bar.py[line:272] - INFO: epoch 024:   1035 / 1732 loss=2.118, loss_v1=0, loss_v2=0, nll_loss=0.887, ntokens=1118.6, nsentences=32, sample_size=1118.6, sample_size_v1=0, sample_size_v2=0, ppl=1.85, wps=593.6, ups=0.53, wpb=1118.6, bsz=32, num_updates=40800, lr=6.85462e-06, gnorm=19.855, clip=100, loss_scale=16, train_wall=19, gb_free=11.4, wall=76688
2023-05-26 20:41:32 - progress_bar.py[line:272] - INFO: epoch 024:   1045 / 1732 loss=2.123, loss_v1=0, loss_v2=0, nll_loss=0.894, ntokens=1030.7, nsentences=32, sample_size=1030.7, sample_size_v1=0, sample_size_v2=0, ppl=1.86, wps=548.1, ups=0.53, wpb=1030.7, bsz=32, num_updates=40810, lr=6.84847e-06, gnorm=23.665, clip=100, loss_scale=16, train_wall=19, gb_free=11.6, wall=76706
2023-05-26 20:41:50 - progress_bar.py[line:272] - INFO: epoch 024:   1055 / 1732 loss=2.137, loss_v1=0, loss_v2=0, nll_loss=0.909, ntokens=1077.2, nsentences=32, sample_size=1077.2, sample_size_v1=0, sample_size_v2=0, ppl=1.88, wps=576.4, ups=0.54, wpb=1077.2, bsz=32, num_updates=40820, lr=6.84233e-06, gnorm=24.252, clip=100, loss_scale=16, train_wall=19, gb_free=11.1, wall=76725
2023-05-26 20:42:09 - progress_bar.py[line:272] - INFO: epoch 024:   1065 / 1732 loss=2.119, loss_v1=0, loss_v2=0, nll_loss=0.888, ntokens=1021, nsentences=32, sample_size=1021, sample_size_v1=0, sample_size_v2=0, ppl=1.85, wps=544.8, ups=0.53, wpb=1021, bsz=32, num_updates=40830, lr=6.83619e-06, gnorm=22.128, clip=100, loss_scale=16, train_wall=19, gb_free=11.3, wall=76744
2023-05-26 20:42:28 - progress_bar.py[line:272] - INFO: epoch 024:   1075 / 1732 loss=2.116, loss_v1=0, loss_v2=0, nll_loss=0.886, ntokens=1007.9, nsentences=32, sample_size=1007.9, sample_size_v1=0, sample_size_v2=0, ppl=1.85, wps=535.6, ups=0.53, wpb=1007.9, bsz=32, num_updates=40840, lr=6.83005e-06, gnorm=21.783, clip=100, loss_scale=16, train_wall=19, gb_free=10.9, wall=76763
2023-05-26 20:42:47 - progress_bar.py[line:272] - INFO: epoch 024:   1085 / 1732 loss=2.136, loss_v1=0, loss_v2=0, nll_loss=0.909, ntokens=1052.2, nsentences=32, sample_size=1052.2, sample_size_v1=0, sample_size_v2=0, ppl=1.88, wps=557.7, ups=0.53, wpb=1052.2, bsz=32, num_updates=40850, lr=6.82391e-06, gnorm=22.748, clip=100, loss_scale=16, train_wall=19, gb_free=11.7, wall=76781
2023-05-26 20:43:06 - progress_bar.py[line:272] - INFO: epoch 024:   1095 / 1732 loss=2.141, loss_v1=0, loss_v2=0, nll_loss=0.913, ntokens=1070, nsentences=32, sample_size=1070, sample_size_v1=0, sample_size_v2=0, ppl=1.88, wps=567.9, ups=0.53, wpb=1070, bsz=32, num_updates=40860, lr=6.81776e-06, gnorm=21.857, clip=100, loss_scale=16, train_wall=19, gb_free=11.4, wall=76800
2023-05-26 20:43:24 - progress_bar.py[line:272] - INFO: epoch 024:   1105 / 1732 loss=2.106, loss_v1=0, loss_v2=0, nll_loss=0.875, ntokens=1032.4, nsentences=32, sample_size=1032.4, sample_size_v1=0, sample_size_v2=0, ppl=1.83, wps=549.6, ups=0.53, wpb=1032.4, bsz=32, num_updates=40870, lr=6.81162e-06, gnorm=22.022, clip=100, loss_scale=16, train_wall=19, gb_free=11.5, wall=76819
2023-05-26 20:43:43 - progress_bar.py[line:272] - INFO: epoch 024:   1115 / 1732 loss=2.133, loss_v1=0, loss_v2=0, nll_loss=0.905, ntokens=979.5, nsentences=32, sample_size=979.5, sample_size_v1=0, sample_size_v2=0, ppl=1.87, wps=523.2, ups=0.53, wpb=979.5, bsz=32, num_updates=40880, lr=6.80548e-06, gnorm=24.468, clip=100, loss_scale=16, train_wall=19, gb_free=11.2, wall=76838
2023-05-26 20:44:02 - progress_bar.py[line:272] - INFO: epoch 024:   1125 / 1732 loss=2.119, loss_v1=0, loss_v2=0, nll_loss=0.888, ntokens=994.1, nsentences=32, sample_size=994.1, sample_size_v1=0, sample_size_v2=0, ppl=1.85, wps=528.9, ups=0.53, wpb=994.1, bsz=32, num_updates=40890, lr=6.79934e-06, gnorm=24.974, clip=100, loss_scale=16, train_wall=19, gb_free=10.9, wall=76857
2023-05-26 20:44:21 - progress_bar.py[line:272] - INFO: epoch 024:   1135 / 1732 loss=2.118, loss_v1=0, loss_v2=0, nll_loss=0.887, ntokens=998.2, nsentences=32, sample_size=998.2, sample_size_v1=0, sample_size_v2=0, ppl=1.85, wps=533.3, ups=0.53, wpb=998.2, bsz=32, num_updates=40900, lr=6.79319e-06, gnorm=23.879, clip=100, loss_scale=16, train_wall=19, gb_free=11.3, wall=76875
2023-05-26 20:44:39 - progress_bar.py[line:272] - INFO: epoch 024:   1145 / 1732 loss=2.119, loss_v1=0, loss_v2=0, nll_loss=0.888, ntokens=1012.1, nsentences=32, sample_size=1012.1, sample_size_v1=0, sample_size_v2=0, ppl=1.85, wps=540.9, ups=0.53, wpb=1012.1, bsz=32, num_updates=40910, lr=6.78705e-06, gnorm=23.013, clip=100, loss_scale=16, train_wall=19, gb_free=10.8, wall=76894
2023-05-26 20:44:58 - progress_bar.py[line:272] - INFO: epoch 024:   1155 / 1732 loss=2.096, loss_v1=0, loss_v2=0, nll_loss=0.863, ntokens=1037.8, nsentences=32, sample_size=1037.8, sample_size_v1=0, sample_size_v2=0, ppl=1.82, wps=552.8, ups=0.53, wpb=1037.8, bsz=32, num_updates=40920, lr=6.78091e-06, gnorm=21.555, clip=100, loss_scale=16, train_wall=19, gb_free=11.5, wall=76913
2023-05-26 20:45:17 - progress_bar.py[line:272] - INFO: epoch 024:   1165 / 1732 loss=2.096, loss_v1=0, loss_v2=0, nll_loss=0.863, ntokens=1000.9, nsentences=32, sample_size=1000.9, sample_size_v1=0, sample_size_v2=0, ppl=1.82, wps=533.2, ups=0.53, wpb=1000.9, bsz=32, num_updates=40930, lr=6.77477e-06, gnorm=22.07, clip=100, loss_scale=16, train_wall=19, gb_free=11.1, wall=76932
2023-05-26 20:45:36 - progress_bar.py[line:272] - INFO: epoch 024:   1175 / 1732 loss=2.118, loss_v1=0, loss_v2=0, nll_loss=0.888, ntokens=1076.2, nsentences=32, sample_size=1076.2, sample_size_v1=0, sample_size_v2=0, ppl=1.85, wps=573.6, ups=0.53, wpb=1076.2, bsz=32, num_updates=40940, lr=6.76863e-06, gnorm=22.995, clip=100, loss_scale=16, train_wall=19, gb_free=11, wall=76950
2023-05-26 20:45:54 - progress_bar.py[line:272] - INFO: epoch 024:   1185 / 1732 loss=2.103, loss_v1=0, loss_v2=0, nll_loss=0.871, ntokens=957.5, nsentences=32, sample_size=957.5, sample_size_v1=0, sample_size_v2=0, ppl=1.83, wps=512.4, ups=0.54, wpb=957.5, bsz=32, num_updates=40950, lr=6.76248e-06, gnorm=23.875, clip=100, loss_scale=16, train_wall=19, gb_free=11.6, wall=76969
2023-05-26 20:46:13 - progress_bar.py[line:272] - INFO: epoch 024:   1195 / 1732 loss=2.127, loss_v1=0, loss_v2=0, nll_loss=0.898, ntokens=1058.2, nsentences=32, sample_size=1058.2, sample_size_v1=0, sample_size_v2=0, ppl=1.86, wps=564.4, ups=0.53, wpb=1058.2, bsz=32, num_updates=40960, lr=6.75634e-06, gnorm=22.107, clip=100, loss_scale=16, train_wall=19, gb_free=11.4, wall=76988
2023-05-26 20:46:32 - progress_bar.py[line:272] - INFO: epoch 024:   1205 / 1732 loss=2.093, loss_v1=0, loss_v2=0, nll_loss=0.859, ntokens=1142.5, nsentences=32, sample_size=1142.5, sample_size_v1=0, sample_size_v2=0, ppl=1.81, wps=602.4, ups=0.53, wpb=1142.5, bsz=32, num_updates=40970, lr=6.7502e-06, gnorm=20.313, clip=100, loss_scale=16, train_wall=19, gb_free=11.1, wall=77007
2023-05-26 20:46:51 - progress_bar.py[line:272] - INFO: epoch 024:   1215 / 1732 loss=2.114, loss_v1=0, loss_v2=0, nll_loss=0.883, ntokens=998.9, nsentences=32, sample_size=998.9, sample_size_v1=0, sample_size_v2=0, ppl=1.84, wps=534.2, ups=0.53, wpb=998.9, bsz=32, num_updates=40980, lr=6.74406e-06, gnorm=21.596, clip=100, loss_scale=16, train_wall=19, gb_free=11.7, wall=77025
2023-05-26 20:47:10 - progress_bar.py[line:272] - INFO: epoch 024:   1225 / 1732 loss=2.127, loss_v1=0, loss_v2=0, nll_loss=0.898, ntokens=1043.3, nsentences=32, sample_size=1043.3, sample_size_v1=0, sample_size_v2=0, ppl=1.86, wps=555.2, ups=0.53, wpb=1043.3, bsz=32, num_updates=40990, lr=6.73792e-06, gnorm=20.292, clip=100, loss_scale=16, train_wall=19, gb_free=11.8, wall=77044
2023-05-26 20:47:28 - progress_bar.py[line:272] - INFO: epoch 024:   1235 / 1732 loss=2.092, loss_v1=0, loss_v2=0, nll_loss=0.858, ntokens=1038.1, nsentences=32, sample_size=1038.1, sample_size_v1=0, sample_size_v2=0, ppl=1.81, wps=553.7, ups=0.53, wpb=1038.1, bsz=32, num_updates=41000, lr=6.73177e-06, gnorm=20.59, clip=100, loss_scale=16, train_wall=19, gb_free=10.4, wall=77063
2023-05-26 20:47:47 - progress_bar.py[line:272] - INFO: epoch 024:   1245 / 1732 loss=2.063, loss_v1=0, loss_v2=0, nll_loss=0.827, ntokens=1088.5, nsentences=32, sample_size=1088.5, sample_size_v1=0, sample_size_v2=0, ppl=1.77, wps=578.3, ups=0.53, wpb=1088.5, bsz=32, num_updates=41010, lr=6.72563e-06, gnorm=20.346, clip=100, loss_scale=16, train_wall=19, gb_free=11, wall=77082
2023-05-26 20:48:06 - progress_bar.py[line:272] - INFO: epoch 024:   1255 / 1732 loss=2.087, loss_v1=0, loss_v2=0, nll_loss=0.853, ntokens=1068.9, nsentences=32, sample_size=1068.9, sample_size_v1=0, sample_size_v2=0, ppl=1.81, wps=567.9, ups=0.53, wpb=1068.9, bsz=32, num_updates=41020, lr=6.71949e-06, gnorm=21.676, clip=100, loss_scale=16, train_wall=19, gb_free=11.4, wall=77101
2023-05-26 20:48:25 - progress_bar.py[line:272] - INFO: epoch 024:   1265 / 1732 loss=2.118, loss_v1=0, loss_v2=0, nll_loss=0.889, ntokens=1072.6, nsentences=32, sample_size=1072.6, sample_size_v1=0, sample_size_v2=0, ppl=1.85, wps=570, ups=0.53, wpb=1072.6, bsz=32, num_updates=41030, lr=6.71335e-06, gnorm=19.377, clip=100, loss_scale=16, train_wall=19, gb_free=12, wall=77119
2023-05-26 20:48:44 - progress_bar.py[line:272] - INFO: epoch 024:   1275 / 1732 loss=2.099, loss_v1=0, loss_v2=0, nll_loss=0.868, ntokens=1036.2, nsentences=32, sample_size=1036.2, sample_size_v1=0, sample_size_v2=0, ppl=1.82, wps=551.7, ups=0.53, wpb=1036.2, bsz=32, num_updates=41040, lr=6.7072e-06, gnorm=20.759, clip=100, loss_scale=16, train_wall=19, gb_free=11.3, wall=77138
2023-05-26 20:49:03 - progress_bar.py[line:272] - INFO: epoch 024:   1285 / 1732 loss=2.099, loss_v1=0, loss_v2=0, nll_loss=0.867, ntokens=1069.5, nsentences=32, sample_size=1069.5, sample_size_v1=0, sample_size_v2=0, ppl=1.82, wps=565.6, ups=0.53, wpb=1069.5, bsz=32, num_updates=41050, lr=6.70106e-06, gnorm=22.216, clip=100, loss_scale=16, train_wall=19, gb_free=11.4, wall=77157
2023-05-26 20:49:21 - progress_bar.py[line:272] - INFO: epoch 024:   1295 / 1732 loss=2.087, loss_v1=0, loss_v2=0, nll_loss=0.853, ntokens=1106.6, nsentences=32, sample_size=1106.6, sample_size_v1=0, sample_size_v2=0, ppl=1.81, wps=585, ups=0.53, wpb=1106.6, bsz=32, num_updates=41060, lr=6.69492e-06, gnorm=20.252, clip=100, loss_scale=16, train_wall=19, gb_free=10.6, wall=77176
2023-05-26 20:49:40 - progress_bar.py[line:272] - INFO: epoch 024:   1305 / 1732 loss=2.124, loss_v1=0, loss_v2=0, nll_loss=0.894, ntokens=1087.8, nsentences=32, sample_size=1087.8, sample_size_v1=0, sample_size_v2=0, ppl=1.86, wps=575.6, ups=0.53, wpb=1087.8, bsz=32, num_updates=41070, lr=6.68878e-06, gnorm=21.349, clip=100, loss_scale=16, train_wall=19, gb_free=10.8, wall=77195
2023-05-26 20:49:59 - progress_bar.py[line:272] - INFO: epoch 024:   1315 / 1732 loss=2.112, loss_v1=0, loss_v2=0, nll_loss=0.881, ntokens=1038.9, nsentences=32, sample_size=1038.9, sample_size_v1=0, sample_size_v2=0, ppl=1.84, wps=547, ups=0.53, wpb=1038.9, bsz=32, num_updates=41080, lr=6.68264e-06, gnorm=21.322, clip=100, loss_scale=16, train_wall=19, gb_free=11.2, wall=77214
2023-05-26 20:50:18 - progress_bar.py[line:272] - INFO: epoch 024:   1325 / 1732 loss=2.078, loss_v1=0, loss_v2=0, nll_loss=0.843, ntokens=1136.1, nsentences=32, sample_size=1136.1, sample_size_v1=0, sample_size_v2=0, ppl=1.79, wps=600.1, ups=0.53, wpb=1136.1, bsz=32, num_updates=41090, lr=6.67649e-06, gnorm=18.591, clip=100, loss_scale=16, train_wall=19, gb_free=10.6, wall=77233
2023-05-26 20:50:37 - progress_bar.py[line:272] - INFO: epoch 024:   1335 / 1732 loss=2.078, loss_v1=0, loss_v2=0, nll_loss=0.844, ntokens=1103.3, nsentences=32, sample_size=1103.3, sample_size_v1=0, sample_size_v2=0, ppl=1.79, wps=587.5, ups=0.53, wpb=1103.3, bsz=32, num_updates=41100, lr=6.67035e-06, gnorm=18.347, clip=100, loss_scale=16, train_wall=19, gb_free=10.3, wall=77252
2023-05-26 20:50:56 - progress_bar.py[line:272] - INFO: epoch 024:   1345 / 1732 loss=2.104, loss_v1=0, loss_v2=0, nll_loss=0.873, ntokens=1182.5, nsentences=32, sample_size=1182.5, sample_size_v1=0, sample_size_v2=0, ppl=1.83, wps=621.1, ups=0.53, wpb=1182.5, bsz=32, num_updates=41110, lr=6.66421e-06, gnorm=20.375, clip=100, loss_scale=16, train_wall=19, gb_free=11.1, wall=77271
2023-05-26 20:51:15 - progress_bar.py[line:272] - INFO: epoch 024:   1355 / 1732 loss=2.082, loss_v1=0, loss_v2=0, nll_loss=0.848, ntokens=1122.3, nsentences=32, sample_size=1122.3, sample_size_v1=0, sample_size_v2=0, ppl=1.8, wps=593.8, ups=0.53, wpb=1122.3, bsz=32, num_updates=41120, lr=6.65807e-06, gnorm=20.712, clip=100, loss_scale=16, train_wall=19, gb_free=11.3, wall=77290
2023-05-26 20:51:34 - progress_bar.py[line:272] - INFO: epoch 024:   1365 / 1732 loss=2.094, loss_v1=0, loss_v2=0, nll_loss=0.861, ntokens=1083.1, nsentences=32, sample_size=1083.1, sample_size_v1=0, sample_size_v2=0, ppl=1.82, wps=573, ups=0.53, wpb=1083.1, bsz=32, num_updates=41130, lr=6.65193e-06, gnorm=20.88, clip=100, loss_scale=16, train_wall=19, gb_free=11.6, wall=77309
2023-05-26 20:51:53 - progress_bar.py[line:272] - INFO: epoch 024:   1375 / 1732 loss=2.126, loss_v1=0, loss_v2=0, nll_loss=0.898, ntokens=1095.5, nsentences=32, sample_size=1095.5, sample_size_v1=0, sample_size_v2=0, ppl=1.86, wps=582.5, ups=0.53, wpb=1095.5, bsz=32, num_updates=41140, lr=6.64578e-06, gnorm=20.907, clip=100, loss_scale=16, train_wall=19, gb_free=11.3, wall=77327
2023-05-26 20:52:12 - progress_bar.py[line:272] - INFO: epoch 024:   1385 / 1732 loss=2.119, loss_v1=0, loss_v2=0, nll_loss=0.888, ntokens=1167.7, nsentences=32, sample_size=1167.7, sample_size_v1=0, sample_size_v2=0, ppl=1.85, wps=617.4, ups=0.53, wpb=1167.7, bsz=32, num_updates=41150, lr=6.63964e-06, gnorm=22.565, clip=100, loss_scale=16, train_wall=19, gb_free=11.1, wall=77346
2023-05-26 20:52:30 - progress_bar.py[line:272] - INFO: epoch 024:   1395 / 1732 loss=2.107, loss_v1=0, loss_v2=0, nll_loss=0.875, ntokens=1051.3, nsentences=32, sample_size=1051.3, sample_size_v1=0, sample_size_v2=0, ppl=1.83, wps=561.5, ups=0.53, wpb=1051.3, bsz=32, num_updates=41160, lr=6.6335e-06, gnorm=24.621, clip=100, loss_scale=16, train_wall=19, gb_free=11.1, wall=77365
2023-05-26 20:52:49 - progress_bar.py[line:272] - INFO: epoch 024:   1405 / 1732 loss=2.108, loss_v1=0, loss_v2=0, nll_loss=0.875, ntokens=1161.5, nsentences=32, sample_size=1161.5, sample_size_v1=0, sample_size_v2=0, ppl=1.83, wps=614.4, ups=0.53, wpb=1161.5, bsz=32, num_updates=41170, lr=6.62736e-06, gnorm=19.448, clip=100, loss_scale=16, train_wall=19, gb_free=11, wall=77384
2023-05-26 20:53:08 - progress_bar.py[line:272] - INFO: epoch 024:   1415 / 1732 loss=2.154, loss_v1=0, loss_v2=0, nll_loss=0.927, ntokens=1285.3, nsentences=32, sample_size=1285.3, sample_size_v1=0, sample_size_v2=0, ppl=1.9, wps=675.1, ups=0.53, wpb=1285.3, bsz=32, num_updates=41180, lr=6.62121e-06, gnorm=19.309, clip=100, loss_scale=16, train_wall=19, gb_free=10.7, wall=77403
2023-05-26 20:53:27 - progress_bar.py[line:272] - INFO: epoch 024:   1425 / 1732 loss=2.11, loss_v1=0, loss_v2=0, nll_loss=0.878, ntokens=1231.8, nsentences=32, sample_size=1231.8, sample_size_v1=0, sample_size_v2=0, ppl=1.84, wps=643.6, ups=0.52, wpb=1231.8, bsz=32, num_updates=41190, lr=6.61507e-06, gnorm=20.628, clip=100, loss_scale=32, train_wall=19, gb_free=10, wall=77422
2023-05-26 20:53:46 - progress_bar.py[line:272] - INFO: epoch 024:   1435 / 1732 loss=2.109, loss_v1=0, loss_v2=0, nll_loss=0.878, ntokens=1210.6, nsentences=32, sample_size=1210.6, sample_size_v1=0, sample_size_v2=0, ppl=1.84, wps=641.4, ups=0.53, wpb=1210.6, bsz=32, num_updates=41200, lr=6.60893e-06, gnorm=19.66, clip=100, loss_scale=32, train_wall=19, gb_free=11.3, wall=77441
2023-05-26 20:54:05 - progress_bar.py[line:272] - INFO: epoch 024:   1445 / 1732 loss=2.107, loss_v1=0, loss_v2=0, nll_loss=0.877, ntokens=1117.4, nsentences=32, sample_size=1117.4, sample_size_v1=0, sample_size_v2=0, ppl=1.84, wps=591.4, ups=0.53, wpb=1117.4, bsz=32, num_updates=41210, lr=6.60279e-06, gnorm=20.325, clip=100, loss_scale=32, train_wall=19, gb_free=11.3, wall=77460
2023-05-26 20:54:24 - progress_bar.py[line:272] - INFO: epoch 024:   1455 / 1732 loss=2.131, loss_v1=0, loss_v2=0, nll_loss=0.902, ntokens=1125.4, nsentences=32, sample_size=1125.4, sample_size_v1=0, sample_size_v2=0, ppl=1.87, wps=597.8, ups=0.53, wpb=1125.4, bsz=32, num_updates=41220, lr=6.59665e-06, gnorm=21.865, clip=100, loss_scale=32, train_wall=19, gb_free=11.1, wall=77479
2023-05-26 20:54:43 - progress_bar.py[line:272] - INFO: epoch 024:   1465 / 1732 loss=2.085, loss_v1=0, loss_v2=0, nll_loss=0.85, ntokens=1185.4, nsentences=32, sample_size=1185.4, sample_size_v1=0, sample_size_v2=0, ppl=1.8, wps=624.6, ups=0.53, wpb=1185.4, bsz=32, num_updates=41230, lr=6.5905e-06, gnorm=19.79, clip=100, loss_scale=32, train_wall=19, gb_free=11.2, wall=77498
2023-05-26 20:55:02 - progress_bar.py[line:272] - INFO: epoch 024:   1475 / 1732 loss=2.106, loss_v1=0, loss_v2=0, nll_loss=0.875, ntokens=1082.9, nsentences=32, sample_size=1082.9, sample_size_v1=0, sample_size_v2=0, ppl=1.83, wps=576.8, ups=0.53, wpb=1082.9, bsz=32, num_updates=41240, lr=6.58436e-06, gnorm=21.225, clip=100, loss_scale=32, train_wall=19, gb_free=11, wall=77516
2023-05-26 20:55:21 - progress_bar.py[line:272] - INFO: epoch 024:   1485 / 1732 loss=2.136, loss_v1=0, loss_v2=0, nll_loss=0.908, ntokens=1103.4, nsentences=32, sample_size=1103.4, sample_size_v1=0, sample_size_v2=0, ppl=1.88, wps=585.1, ups=0.53, wpb=1103.4, bsz=32, num_updates=41250, lr=6.57822e-06, gnorm=21.895, clip=100, loss_scale=32, train_wall=19, gb_free=10.6, wall=77535
2023-05-26 20:55:40 - progress_bar.py[line:272] - INFO: epoch 024:   1495 / 1732 loss=2.107, loss_v1=0, loss_v2=0, nll_loss=0.875, ntokens=1111.1, nsentences=32, sample_size=1111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.83, wps=586.9, ups=0.53, wpb=1111.1, bsz=32, num_updates=41260, lr=6.57208e-06, gnorm=21.799, clip=100, loss_scale=32, train_wall=19, gb_free=10.5, wall=77554
2023-05-26 20:55:58 - progress_bar.py[line:272] - INFO: epoch 024:   1505 / 1732 loss=2.077, loss_v1=0, loss_v2=0, nll_loss=0.841, ntokens=1137.1, nsentences=32, sample_size=1137.1, sample_size_v1=0, sample_size_v2=0, ppl=1.79, wps=603.1, ups=0.53, wpb=1137.1, bsz=32, num_updates=41270, lr=6.56594e-06, gnorm=20.006, clip=100, loss_scale=32, train_wall=19, gb_free=11.7, wall=77573
2023-05-26 20:56:17 - progress_bar.py[line:272] - INFO: epoch 024:   1515 / 1732 loss=2.125, loss_v1=0, loss_v2=0, nll_loss=0.897, ntokens=1046.4, nsentences=32, sample_size=1046.4, sample_size_v1=0, sample_size_v2=0, ppl=1.86, wps=558.8, ups=0.53, wpb=1046.4, bsz=32, num_updates=41280, lr=6.55979e-06, gnorm=23.582, clip=100, loss_scale=32, train_wall=19, gb_free=11.1, wall=77592
2023-05-26 20:56:36 - progress_bar.py[line:272] - INFO: epoch 024:   1525 / 1732 loss=2.154, loss_v1=0, loss_v2=0, nll_loss=0.928, ntokens=1040.6, nsentences=32, sample_size=1040.6, sample_size_v1=0, sample_size_v2=0, ppl=1.9, wps=555, ups=0.53, wpb=1040.6, bsz=32, num_updates=41290, lr=6.55365e-06, gnorm=21.582, clip=100, loss_scale=32, train_wall=19, gb_free=11, wall=77611
2023-05-26 20:56:55 - progress_bar.py[line:272] - INFO: epoch 024:   1535 / 1732 loss=2.125, loss_v1=0, loss_v2=0, nll_loss=0.896, ntokens=1087.5, nsentences=32, sample_size=1087.5, sample_size_v1=0, sample_size_v2=0, ppl=1.86, wps=572.5, ups=0.53, wpb=1087.5, bsz=32, num_updates=41300, lr=6.54751e-06, gnorm=23.684, clip=100, loss_scale=32, train_wall=19, gb_free=10.8, wall=77630
2023-05-26 20:57:08 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2023-05-26 20:57:16 - progress_bar.py[line:272] - INFO: epoch 024:   1546 / 1732 loss=2.083, loss_v1=0, loss_v2=0, nll_loss=0.849, ntokens=1074.9, nsentences=32, sample_size=1074.9, sample_size_v1=0, sample_size_v2=0, ppl=1.8, wps=521.6, ups=0.49, wpb=1074.9, bsz=32, num_updates=41310, lr=6.54137e-06, gnorm=21.408, clip=100, loss_scale=16, train_wall=21, gb_free=11.2, wall=77650
2023-05-26 20:57:34 - progress_bar.py[line:272] - INFO: epoch 024:   1556 / 1732 loss=2.094, loss_v1=0, loss_v2=0, nll_loss=0.861, ntokens=1070.8, nsentences=32, sample_size=1070.8, sample_size_v1=0, sample_size_v2=0, ppl=1.82, wps=570.5, ups=0.53, wpb=1070.8, bsz=32, num_updates=41320, lr=6.53523e-06, gnorm=21.376, clip=100, loss_scale=16, train_wall=19, gb_free=11.3, wall=77669
2023-05-26 20:57:53 - progress_bar.py[line:272] - INFO: epoch 024:   1566 / 1732 loss=2.132, loss_v1=0, loss_v2=0, nll_loss=0.904, ntokens=1097.4, nsentences=32, sample_size=1097.4, sample_size_v1=0, sample_size_v2=0, ppl=1.87, wps=584.3, ups=0.53, wpb=1097.4, bsz=32, num_updates=41330, lr=6.52908e-06, gnorm=21.044, clip=100, loss_scale=16, train_wall=19, gb_free=11.6, wall=77688
2023-05-26 20:58:12 - progress_bar.py[line:272] - INFO: epoch 024:   1576 / 1732 loss=2.128, loss_v1=0, loss_v2=0, nll_loss=0.899, ntokens=1019.9, nsentences=32, sample_size=1019.9, sample_size_v1=0, sample_size_v2=0, ppl=1.86, wps=537.3, ups=0.53, wpb=1019.9, bsz=32, num_updates=41340, lr=6.52294e-06, gnorm=23.238, clip=100, loss_scale=16, train_wall=19, gb_free=11.5, wall=77707
2023-05-26 20:58:31 - progress_bar.py[line:272] - INFO: epoch 024:   1586 / 1732 loss=2.112, loss_v1=0, loss_v2=0, nll_loss=0.881, ntokens=1060.6, nsentences=32, sample_size=1060.6, sample_size_v1=0, sample_size_v2=0, ppl=1.84, wps=560.8, ups=0.53, wpb=1060.6, bsz=32, num_updates=41350, lr=6.5168e-06, gnorm=21.842, clip=100, loss_scale=16, train_wall=19, gb_free=11.1, wall=77726
2023-05-26 20:58:50 - progress_bar.py[line:272] - INFO: epoch 024:   1596 / 1732 loss=2.083, loss_v1=0, loss_v2=0, nll_loss=0.848, ntokens=1073.8, nsentences=32, sample_size=1073.8, sample_size_v1=0, sample_size_v2=0, ppl=1.8, wps=570.9, ups=0.53, wpb=1073.8, bsz=32, num_updates=41360, lr=6.51066e-06, gnorm=20.35, clip=100, loss_scale=16, train_wall=19, gb_free=11.2, wall=77744
2023-05-26 20:59:09 - progress_bar.py[line:272] - INFO: epoch 024:   1606 / 1732 loss=2.104, loss_v1=0, loss_v2=0, nll_loss=0.872, ntokens=1124, nsentences=32, sample_size=1124, sample_size_v1=0, sample_size_v2=0, ppl=1.83, wps=595.2, ups=0.53, wpb=1124, bsz=32, num_updates=41370, lr=6.50451e-06, gnorm=19.716, clip=100, loss_scale=16, train_wall=19, gb_free=11, wall=77763
2023-05-26 20:59:28 - progress_bar.py[line:272] - INFO: epoch 024:   1616 / 1732 loss=2.081, loss_v1=0, loss_v2=0, nll_loss=0.847, ntokens=1154.1, nsentences=32, sample_size=1154.1, sample_size_v1=0, sample_size_v2=0, ppl=1.8, wps=607.1, ups=0.53, wpb=1154.1, bsz=32, num_updates=41380, lr=6.49837e-06, gnorm=19.6, clip=100, loss_scale=16, train_wall=19, gb_free=11.5, wall=77782
2023-05-26 20:59:47 - progress_bar.py[line:272] - INFO: epoch 024:   1626 / 1732 loss=2.109, loss_v1=0, loss_v2=0, nll_loss=0.879, ntokens=1109.2, nsentences=32, sample_size=1109.2, sample_size_v1=0, sample_size_v2=0, ppl=1.84, wps=584.7, ups=0.53, wpb=1109.2, bsz=32, num_updates=41390, lr=6.49223e-06, gnorm=21.283, clip=100, loss_scale=16, train_wall=19, gb_free=10.9, wall=77801
2023-05-26 21:00:06 - progress_bar.py[line:272] - INFO: epoch 024:   1636 / 1732 loss=2.086, loss_v1=0, loss_v2=0, nll_loss=0.852, ntokens=1146, nsentences=32, sample_size=1146, sample_size_v1=0, sample_size_v2=0, ppl=1.81, wps=609.1, ups=0.53, wpb=1146, bsz=32, num_updates=41400, lr=6.48609e-06, gnorm=20.548, clip=100, loss_scale=16, train_wall=19, gb_free=11.8, wall=77820
2023-05-26 21:00:25 - progress_bar.py[line:272] - INFO: epoch 024:   1646 / 1732 loss=2.092, loss_v1=0, loss_v2=0, nll_loss=0.858, ntokens=1290.2, nsentences=32, sample_size=1290.2, sample_size_v1=0, sample_size_v2=0, ppl=1.81, wps=675, ups=0.52, wpb=1290.2, bsz=32, num_updates=41410, lr=6.47995e-06, gnorm=18.906, clip=100, loss_scale=16, train_wall=19, gb_free=11, wall=77839
2023-05-26 21:00:43 - progress_bar.py[line:272] - INFO: epoch 024:   1656 / 1732 loss=2.114, loss_v1=0, loss_v2=0, nll_loss=0.884, ntokens=952.5, nsentences=32, sample_size=952.5, sample_size_v1=0, sample_size_v2=0, ppl=1.85, wps=510.2, ups=0.54, wpb=952.5, bsz=32, num_updates=41420, lr=6.4738e-06, gnorm=21.786, clip=100, loss_scale=16, train_wall=19, gb_free=11.3, wall=77858
2023-05-26 21:01:02 - progress_bar.py[line:272] - INFO: epoch 024:   1666 / 1732 loss=2.109, loss_v1=0, loss_v2=0, nll_loss=0.877, ntokens=1015, nsentences=32, sample_size=1015, sample_size_v1=0, sample_size_v2=0, ppl=1.84, wps=538.2, ups=0.53, wpb=1015, bsz=32, num_updates=41430, lr=6.46766e-06, gnorm=20.152, clip=100, loss_scale=16, train_wall=19, gb_free=11.4, wall=77877
2023-05-26 21:01:21 - progress_bar.py[line:272] - INFO: epoch 024:   1676 / 1732 loss=2.078, loss_v1=0, loss_v2=0, nll_loss=0.842, ntokens=1119.1, nsentences=32, sample_size=1119.1, sample_size_v1=0, sample_size_v2=0, ppl=1.79, wps=594, ups=0.53, wpb=1119.1, bsz=32, num_updates=41440, lr=6.46152e-06, gnorm=20.417, clip=100, loss_scale=16, train_wall=19, gb_free=11.1, wall=77896
2023-05-26 21:01:40 - progress_bar.py[line:272] - INFO: epoch 024:   1686 / 1732 loss=2.071, loss_v1=0, loss_v2=0, nll_loss=0.834, ntokens=1151.6, nsentences=32, sample_size=1151.6, sample_size_v1=0, sample_size_v2=0, ppl=1.78, wps=606.7, ups=0.53, wpb=1151.6, bsz=32, num_updates=41450, lr=6.45538e-06, gnorm=20.015, clip=100, loss_scale=16, train_wall=19, gb_free=10.7, wall=77915
2023-05-26 21:01:59 - progress_bar.py[line:272] - INFO: epoch 024:   1696 / 1732 loss=2.107, loss_v1=0, loss_v2=0, nll_loss=0.875, ntokens=1284.6, nsentences=32, sample_size=1284.6, sample_size_v1=0, sample_size_v2=0, ppl=1.83, wps=666.7, ups=0.52, wpb=1284.6, bsz=32, num_updates=41460, lr=6.44924e-06, gnorm=18.649, clip=100, loss_scale=16, train_wall=19, gb_free=10.6, wall=77934
2023-05-26 21:02:18 - progress_bar.py[line:272] - INFO: epoch 024:   1706 / 1732 loss=2.108, loss_v1=0, loss_v2=0, nll_loss=0.877, ntokens=1193.5, nsentences=32, sample_size=1193.5, sample_size_v1=0, sample_size_v2=0, ppl=1.84, wps=626.8, ups=0.53, wpb=1193.5, bsz=32, num_updates=41470, lr=6.44309e-06, gnorm=17.936, clip=100, loss_scale=16, train_wall=19, gb_free=10.8, wall=77953
2023-05-26 21:02:37 - progress_bar.py[line:272] - INFO: epoch 024:   1716 / 1732 loss=2.088, loss_v1=0, loss_v2=0, nll_loss=0.854, ntokens=1213.9, nsentences=32, sample_size=1213.9, sample_size_v1=0, sample_size_v2=0, ppl=1.81, wps=638.6, ups=0.53, wpb=1213.9, bsz=32, num_updates=41480, lr=6.43695e-06, gnorm=17.291, clip=100, loss_scale=16, train_wall=19, gb_free=10.5, wall=77972
2023-05-26 21:02:56 - progress_bar.py[line:272] - INFO: epoch 024:   1726 / 1732 loss=2.101, loss_v1=0, loss_v2=0, nll_loss=0.869, ntokens=1112.1, nsentences=32, sample_size=1112.1, sample_size_v1=0, sample_size_v2=0, ppl=1.83, wps=589.5, ups=0.53, wpb=1112.1, bsz=32, num_updates=41490, lr=6.43081e-06, gnorm=19.66, clip=100, loss_scale=16, train_wall=19, gb_free=11.1, wall=77991
2023-05-26 21:03:06 - checkpoint_utils.py[line:64] - INFO: Preparing to save checkpoint for epoch 24 @ 41496 updates
2023-05-26 21:03:06 - trainer.py[line:431] - INFO: Saving checkpoint to ../../checkpoints/OFA/sgcls_checkpoints/_30_3e-5_512_base_nosrcbbox/checkpoint24.pt
2023-05-26 21:03:09 - trainer.py[line:441] - INFO: Finished saving checkpoint to ../../checkpoints/OFA/sgcls_checkpoints/_30_3e-5_512_base_nosrcbbox/checkpoint24.pt
2023-05-26 21:03:13 - checkpoint_utils.py[line:133] - INFO: Saved checkpoint ../../checkpoints/OFA/sgcls_checkpoints/_30_3e-5_512_base_nosrcbbox/checkpoint24.pt (epoch 24 @ 41496 updates, score None) (writing took 7.295175441075116 seconds)
2023-05-26 21:03:13 - train.py[line:332] - INFO: end of epoch 24 (average epoch stats below)
2023-05-26 21:03:13 - progress_bar.py[line:282] - INFO: epoch 024 | loss 2.107 | loss_v1 0 | loss_v2 0 | nll_loss 0.875 | ntokens 1051.7 | nsentences 31.986 | sample_size 1051.7 | sample_size_v1 0 | sample_size_v2 0 | ppl 1.83 | wps 558.6 | ups 0.53 | wpb 1051.7 | bsz 32 | num_updates 41496 | lr 6.42712e-06 | gnorm 21.881 | clip 100 | loss_scale 16 | train_wall 3240 | gb_free 11.7 | wall 78008
2023-05-26 21:03:13 - trainer.py[line:639] - INFO: loading train data for epoch 25
local datafile ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 0 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 0 finished initializing row_count and line_idx-to-offset mapping
file ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 0 row count 55400 total row count 55400
slice_id 0 seek offset 0
2023-05-26 21:03:15 - trainer.py[line:703] - INFO: begin training epoch 25
2023-05-26 21:03:15 - train.py[line:305] - INFO: Start iterating over samples
2023-05-26 21:03:23 - progress_bar.py[line:272] - INFO: epoch 025:      4 / 1732 loss=2.121, loss_v1=0, loss_v2=0, nll_loss=0.891, ntokens=1098.7, nsentences=29.6, sample_size=1098.7, sample_size_v1=0, sample_size_v2=0, ppl=1.85, wps=405, ups=0.37, wpb=1098.7, bsz=29.6, num_updates=41500, lr=6.42467e-06, gnorm=24.054, clip=100, loss_scale=16, train_wall=18, gb_free=10.8, wall=78018
2023-05-26 21:03:42 - progress_bar.py[line:272] - INFO: epoch 025:     14 / 1732 loss=2.097, loss_v1=0, loss_v2=0, nll_loss=0.864, ntokens=1064.2, nsentences=32, sample_size=1064.2, sample_size_v1=0, sample_size_v2=0, ppl=1.82, wps=564.9, ups=0.53, wpb=1064.2, bsz=32, num_updates=41510, lr=6.41852e-06, gnorm=27.435, clip=100, loss_scale=16, train_wall=19, gb_free=11.1, wall=78037
2023-05-26 21:04:01 - progress_bar.py[line:272] - INFO: epoch 025:     24 / 1732 loss=2.048, loss_v1=0, loss_v2=0, nll_loss=0.808, ntokens=1038.3, nsentences=32, sample_size=1038.3, sample_size_v1=0, sample_size_v2=0, ppl=1.75, wps=551.2, ups=0.53, wpb=1038.3, bsz=32, num_updates=41520, lr=6.41238e-06, gnorm=23.34, clip=100, loss_scale=16, train_wall=19, gb_free=11.3, wall=78056
2023-05-26 21:04:20 - progress_bar.py[line:272] - INFO: epoch 025:     34 / 1732 loss=1.989, loss_v1=0, loss_v2=0, nll_loss=0.742, ntokens=1072.7, nsentences=32, sample_size=1072.7, sample_size_v1=0, sample_size_v2=0, ppl=1.67, wps=567.2, ups=0.53, wpb=1072.7, bsz=32, num_updates=41530, lr=6.40624e-06, gnorm=21.658, clip=100, loss_scale=16, train_wall=19, gb_free=11.1, wall=78075
2023-05-26 21:04:39 - progress_bar.py[line:272] - INFO: epoch 025:     44 / 1732 loss=1.963, loss_v1=0, loss_v2=0, nll_loss=0.714, ntokens=1134, nsentences=32, sample_size=1134, sample_size_v1=0, sample_size_v2=0, ppl=1.64, wps=600, ups=0.53, wpb=1134, bsz=32, num_updates=41540, lr=6.4001e-06, gnorm=19.971, clip=100, loss_scale=16, train_wall=19, gb_free=10.9, wall=78093
2023-05-26 21:04:58 - progress_bar.py[line:272] - INFO: epoch 025:     54 / 1732 loss=1.97, loss_v1=0, loss_v2=0, nll_loss=0.722, ntokens=1025.8, nsentences=32, sample_size=1025.8, sample_size_v1=0, sample_size_v2=0, ppl=1.65, wps=543.2, ups=0.53, wpb=1025.8, bsz=32, num_updates=41550, lr=6.39396e-06, gnorm=22.85, clip=100, loss_scale=16, train_wall=19, gb_free=11.2, wall=78112
2023-05-26 21:05:17 - progress_bar.py[line:272] - INFO: epoch 025:     64 / 1732 loss=1.85, loss_v1=0, loss_v2=0, nll_loss=0.588, ntokens=1253.8, nsentences=32, sample_size=1253.8, sample_size_v1=0, sample_size_v2=0, ppl=1.5, wps=657.8, ups=0.52, wpb=1253.8, bsz=32, num_updates=41560, lr=6.38781e-06, gnorm=19.068, clip=100, loss_scale=16, train_wall=19, gb_free=10.7, wall=78131
2023-05-26 21:05:36 - progress_bar.py[line:272] - INFO: epoch 025:     74 / 1732 loss=1.914, loss_v1=0, loss_v2=0, nll_loss=0.661, ntokens=1358.9, nsentences=32, sample_size=1358.9, sample_size_v1=0, sample_size_v2=0, ppl=1.58, wps=696.8, ups=0.51, wpb=1358.9, bsz=32, num_updates=41570, lr=6.38167e-06, gnorm=14.608, clip=100, loss_scale=16, train_wall=19, gb_free=10.3, wall=78151
2023-05-26 21:05:56 - progress_bar.py[line:272] - INFO: epoch 025:     84 / 1732 loss=1.943, loss_v1=0, loss_v2=0, nll_loss=0.695, ntokens=1166.6, nsentences=32, sample_size=1166.6, sample_size_v1=0, sample_size_v2=0, ppl=1.62, wps=607.2, ups=0.52, wpb=1166.6, bsz=32, num_updates=41580, lr=6.37553e-06, gnorm=18.013, clip=100, loss_scale=16, train_wall=19, gb_free=10.5, wall=78170
2023-05-26 21:06:14 - progress_bar.py[line:272] - INFO: epoch 025:     94 / 1732 loss=1.928, loss_v1=0, loss_v2=0, nll_loss=0.677, ntokens=1099.4, nsentences=32, sample_size=1099.4, sample_size_v1=0, sample_size_v2=0, ppl=1.6, wps=579.8, ups=0.53, wpb=1099.4, bsz=32, num_updates=41590, lr=6.36939e-06, gnorm=19.355, clip=100, loss_scale=16, train_wall=19, gb_free=11.6, wall=78189
2023-05-26 21:06:33 - progress_bar.py[line:272] - INFO: epoch 025:    104 / 1732 loss=2.045, loss_v1=0, loss_v2=0, nll_loss=0.807, ntokens=968, nsentences=32, sample_size=968, sample_size_v1=0, sample_size_v2=0, ppl=1.75, wps=516.9, ups=0.53, wpb=968, bsz=32, num_updates=41600, lr=6.36325e-06, gnorm=20.71, clip=100, loss_scale=16, train_wall=19, gb_free=11.3, wall=78208
2023-05-26 21:06:52 - progress_bar.py[line:272] - INFO: epoch 025:    114 / 1732 loss=2.135, loss_v1=0, loss_v2=0, nll_loss=0.908, ntokens=1043.8, nsentences=32, sample_size=1043.8, sample_size_v1=0, sample_size_v2=0, ppl=1.88, wps=550.3, ups=0.53, wpb=1043.8, bsz=32, num_updates=41610, lr=6.3571e-06, gnorm=22.358, clip=100, loss_scale=16, train_wall=19, gb_free=11.4, wall=78227
2023-05-26 21:07:11 - progress_bar.py[line:272] - INFO: epoch 025:    124 / 1732 loss=2.103, loss_v1=0, loss_v2=0, nll_loss=0.871, ntokens=1156.9, nsentences=32, sample_size=1156.9, sample_size_v1=0, sample_size_v2=0, ppl=1.83, wps=603.1, ups=0.52, wpb=1156.9, bsz=32, num_updates=41620, lr=6.35096e-06, gnorm=23.585, clip=100, loss_scale=16, train_wall=19, gb_free=10.8, wall=78246
2023-05-26 21:07:30 - progress_bar.py[line:272] - INFO: epoch 025:    134 / 1732 loss=2.071, loss_v1=0, loss_v2=0, nll_loss=0.835, ntokens=1187.1, nsentences=32, sample_size=1187.1, sample_size_v1=0, sample_size_v2=0, ppl=1.78, wps=620.5, ups=0.52, wpb=1187.1, bsz=32, num_updates=41630, lr=6.34482e-06, gnorm=22.74, clip=100, loss_scale=16, train_wall=19, gb_free=11.4, wall=78265
2023-05-26 21:07:50 - progress_bar.py[line:272] - INFO: epoch 025:    144 / 1732 loss=2.059, loss_v1=0, loss_v2=0, nll_loss=0.822, ntokens=1239.8, nsentences=32, sample_size=1239.8, sample_size_v1=0, sample_size_v2=0, ppl=1.77, wps=643.1, ups=0.52, wpb=1239.8, bsz=32, num_updates=41640, lr=6.33868e-06, gnorm=20.558, clip=100, loss_scale=16, train_wall=19, gb_free=10.5, wall=78284
2023-05-26 21:08:09 - progress_bar.py[line:272] - INFO: epoch 025:    154 / 1732 loss=2.051, loss_v1=0, loss_v2=0, nll_loss=0.814, ntokens=1177.9, nsentences=32, sample_size=1177.9, sample_size_v1=0, sample_size_v2=0, ppl=1.76, wps=611.8, ups=0.52, wpb=1177.9, bsz=32, num_updates=41650, lr=6.33253e-06, gnorm=20.955, clip=100, loss_scale=16, train_wall=19, gb_free=10.5, wall=78304
2023-05-26 21:08:28 - progress_bar.py[line:272] - INFO: epoch 025:    164 / 1732 loss=2.053, loss_v1=0, loss_v2=0, nll_loss=0.816, ntokens=1064.5, nsentences=32, sample_size=1064.5, sample_size_v1=0, sample_size_v2=0, ppl=1.76, wps=561, ups=0.53, wpb=1064.5, bsz=32, num_updates=41660, lr=6.32639e-06, gnorm=24.796, clip=100, loss_scale=16, train_wall=19, gb_free=10.2, wall=78323
2023-05-26 21:08:47 - progress_bar.py[line:272] - INFO: epoch 025:    174 / 1732 loss=2.062, loss_v1=0, loss_v2=0, nll_loss=0.826, ntokens=918.2, nsentences=32, sample_size=918.2, sample_size_v1=0, sample_size_v2=0, ppl=1.77, wps=489, ups=0.53, wpb=918.2, bsz=32, num_updates=41670, lr=6.32025e-06, gnorm=27.172, clip=100, loss_scale=16, train_wall=19, gb_free=11.3, wall=78341
2023-05-26 21:09:06 - progress_bar.py[line:272] - INFO: epoch 025:    184 / 1732 loss=2.036, loss_v1=0, loss_v2=0, nll_loss=0.797, ntokens=1196.7, nsentences=32, sample_size=1196.7, sample_size_v1=0, sample_size_v2=0, ppl=1.74, wps=626.5, ups=0.52, wpb=1196.7, bsz=32, num_updates=41680, lr=6.31411e-06, gnorm=19.338, clip=100, loss_scale=16, train_wall=19, gb_free=11.2, wall=78361
2023-05-26 21:09:25 - progress_bar.py[line:272] - INFO: epoch 025:    194 / 1732 loss=2.048, loss_v1=0, loss_v2=0, nll_loss=0.809, ntokens=1132.8, nsentences=32, sample_size=1132.8, sample_size_v1=0, sample_size_v2=0, ppl=1.75, wps=593.2, ups=0.52, wpb=1132.8, bsz=32, num_updates=41690, lr=6.30797e-06, gnorm=21.471, clip=100, loss_scale=16, train_wall=19, gb_free=10.8, wall=78380
2023-05-26 21:09:44 - progress_bar.py[line:272] - INFO: epoch 025:    204 / 1732 loss=2.095, loss_v1=0, loss_v2=0, nll_loss=0.862, ntokens=1052.4, nsentences=32, sample_size=1052.4, sample_size_v1=0, sample_size_v2=0, ppl=1.82, wps=561.8, ups=0.53, wpb=1052.4, bsz=32, num_updates=41700, lr=6.30182e-06, gnorm=22.616, clip=100, loss_scale=16, train_wall=19, gb_free=11.1, wall=78398
2023-05-26 21:10:03 - progress_bar.py[line:272] - INFO: epoch 025:    214 / 1732 loss=2.117, loss_v1=0, loss_v2=0, nll_loss=0.887, ntokens=1074.9, nsentences=32, sample_size=1074.9, sample_size_v1=0, sample_size_v2=0, ppl=1.85, wps=572.2, ups=0.53, wpb=1074.9, bsz=32, num_updates=41710, lr=6.29568e-06, gnorm=20.547, clip=100, loss_scale=16, train_wall=19, gb_free=11.2, wall=78417
2023-05-26 21:10:21 - progress_bar.py[line:272] - INFO: epoch 025:    224 / 1732 loss=2.11, loss_v1=0, loss_v2=0, nll_loss=0.88, ntokens=1100.1, nsentences=32, sample_size=1100.1, sample_size_v1=0, sample_size_v2=0, ppl=1.84, wps=589.4, ups=0.54, wpb=1100.1, bsz=32, num_updates=41720, lr=6.28954e-06, gnorm=19.525, clip=100, loss_scale=16, train_wall=19, gb_free=11.3, wall=78436
2023-05-26 21:10:40 - progress_bar.py[line:272] - INFO: epoch 025:    234 / 1732 loss=2.145, loss_v1=0, loss_v2=0, nll_loss=0.919, ntokens=1090.7, nsentences=32, sample_size=1090.7, sample_size_v1=0, sample_size_v2=0, ppl=1.89, wps=584.1, ups=0.54, wpb=1090.7, bsz=32, num_updates=41730, lr=6.2834e-06, gnorm=19.873, clip=100, loss_scale=16, train_wall=19, gb_free=11.3, wall=78455
2023-05-26 21:10:59 - progress_bar.py[line:272] - INFO: epoch 025:    244 / 1732 loss=2.132, loss_v1=0, loss_v2=0, nll_loss=0.904, ntokens=1157.9, nsentences=32, sample_size=1157.9, sample_size_v1=0, sample_size_v2=0, ppl=1.87, wps=615, ups=0.53, wpb=1157.9, bsz=32, num_updates=41740, lr=6.27726e-06, gnorm=19.726, clip=100, loss_scale=16, train_wall=19, gb_free=10.7, wall=78473
2023-05-26 21:11:17 - progress_bar.py[line:272] - INFO: epoch 025:    254 / 1732 loss=2.132, loss_v1=0, loss_v2=0, nll_loss=0.904, ntokens=1151.4, nsentences=32, sample_size=1151.4, sample_size_v1=0, sample_size_v2=0, ppl=1.87, wps=612.7, ups=0.53, wpb=1151.4, bsz=32, num_updates=41750, lr=6.27111e-06, gnorm=20.961, clip=100, loss_scale=16, train_wall=19, gb_free=11.2, wall=78492
2023-05-26 21:11:36 - progress_bar.py[line:272] - INFO: epoch 025:    264 / 1732 loss=2.114, loss_v1=0, loss_v2=0, nll_loss=0.884, ntokens=1137.5, nsentences=32, sample_size=1137.5, sample_size_v1=0, sample_size_v2=0, ppl=1.84, wps=607.1, ups=0.53, wpb=1137.5, bsz=32, num_updates=41760, lr=6.26497e-06, gnorm=19.284, clip=100, loss_scale=16, train_wall=19, gb_free=10.7, wall=78511
2023-05-26 21:11:55 - progress_bar.py[line:272] - INFO: epoch 025:    274 / 1732 loss=2.116, loss_v1=0, loss_v2=0, nll_loss=0.886, ntokens=1136.4, nsentences=32, sample_size=1136.4, sample_size_v1=0, sample_size_v2=0, ppl=1.85, wps=602.2, ups=0.53, wpb=1136.4, bsz=32, num_updates=41770, lr=6.25883e-06, gnorm=19.993, clip=100, loss_scale=16, train_wall=19, gb_free=9.5, wall=78530
2023-05-26 21:12:14 - progress_bar.py[line:272] - INFO: epoch 025:    284 / 1732 loss=2.142, loss_v1=0, loss_v2=0, nll_loss=0.915, ntokens=1138.6, nsentences=32, sample_size=1138.6, sample_size_v1=0, sample_size_v2=0, ppl=1.89, wps=604.8, ups=0.53, wpb=1138.6, bsz=32, num_updates=41780, lr=6.25269e-06, gnorm=20.22, clip=100, loss_scale=16, train_wall=19, gb_free=11.2, wall=78549
2023-05-26 21:12:33 - progress_bar.py[line:272] - INFO: epoch 025:    294 / 1732 loss=2.104, loss_v1=0, loss_v2=0, nll_loss=0.872, ntokens=1144.7, nsentences=32, sample_size=1144.7, sample_size_v1=0, sample_size_v2=0, ppl=1.83, wps=609.2, ups=0.53, wpb=1144.7, bsz=32, num_updates=41790, lr=6.24655e-06, gnorm=20.42, clip=100, loss_scale=16, train_wall=19, gb_free=11.3, wall=78567
2023-05-26 21:12:51 - progress_bar.py[line:272] - INFO: epoch 025:    304 / 1732 loss=2.12, loss_v1=0, loss_v2=0, nll_loss=0.891, ntokens=1100.1, nsentences=32, sample_size=1100.1, sample_size_v1=0, sample_size_v2=0, ppl=1.85, wps=587.8, ups=0.53, wpb=1100.1, bsz=32, num_updates=41800, lr=6.2404e-06, gnorm=22.31, clip=100, loss_scale=16, train_wall=19, gb_free=11.4, wall=78586
2023-05-26 21:13:10 - progress_bar.py[line:272] - INFO: epoch 025:    314 / 1732 loss=2.126, loss_v1=0, loss_v2=0, nll_loss=0.898, ntokens=1016.6, nsentences=32, sample_size=1016.6, sample_size_v1=0, sample_size_v2=0, ppl=1.86, wps=546.3, ups=0.54, wpb=1016.6, bsz=32, num_updates=41810, lr=6.23426e-06, gnorm=22.155, clip=100, loss_scale=16, train_wall=19, gb_free=11.9, wall=78605
2023-05-26 21:13:29 - progress_bar.py[line:272] - INFO: epoch 025:    324 / 1732 loss=2.14, loss_v1=0, loss_v2=0, nll_loss=0.912, ntokens=1018.7, nsentences=32, sample_size=1018.7, sample_size_v1=0, sample_size_v2=0, ppl=1.88, wps=546.9, ups=0.54, wpb=1018.7, bsz=32, num_updates=41820, lr=6.22812e-06, gnorm=23.38, clip=100, loss_scale=32, train_wall=19, gb_free=11.3, wall=78623
2023-05-26 21:13:47 - progress_bar.py[line:272] - INFO: epoch 025:    334 / 1732 loss=2.148, loss_v1=0, loss_v2=0, nll_loss=0.922, ntokens=1018.9, nsentences=32, sample_size=1018.9, sample_size_v1=0, sample_size_v2=0, ppl=1.89, wps=549, ups=0.54, wpb=1018.9, bsz=32, num_updates=41830, lr=6.22198e-06, gnorm=23.458, clip=100, loss_scale=32, train_wall=19, gb_free=11.7, wall=78642
2023-05-26 21:14:06 - progress_bar.py[line:272] - INFO: epoch 025:    344 / 1732 loss=2.089, loss_v1=0, loss_v2=0, nll_loss=0.856, ntokens=921, nsentences=32, sample_size=921, sample_size_v1=0, sample_size_v2=0, ppl=1.81, wps=497.8, ups=0.54, wpb=921, bsz=32, num_updates=41840, lr=6.21583e-06, gnorm=23.717, clip=100, loss_scale=32, train_wall=18, gb_free=11.4, wall=78660
2023-05-26 21:14:24 - progress_bar.py[line:272] - INFO: epoch 025:    354 / 1732 loss=2.11, loss_v1=0, loss_v2=0, nll_loss=0.88, ntokens=961.9, nsentences=32, sample_size=961.9, sample_size_v1=0, sample_size_v2=0, ppl=1.84, wps=518.2, ups=0.54, wpb=961.9, bsz=32, num_updates=41850, lr=6.20969e-06, gnorm=20.901, clip=100, loss_scale=32, train_wall=19, gb_free=11.3, wall=78679
2023-05-26 21:14:43 - progress_bar.py[line:272] - INFO: epoch 025:    364 / 1732 loss=2.155, loss_v1=0, loss_v2=0, nll_loss=0.931, ntokens=927.9, nsentences=32, sample_size=927.9, sample_size_v1=0, sample_size_v2=0, ppl=1.91, wps=502.2, ups=0.54, wpb=927.9, bsz=32, num_updates=41860, lr=6.20355e-06, gnorm=24.598, clip=100, loss_scale=32, train_wall=18, gb_free=11.8, wall=78697
2023-05-26 21:15:01 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2023-05-26 21:15:03 - progress_bar.py[line:272] - INFO: epoch 025:    375 / 1732 loss=2.125, loss_v1=0, loss_v2=0, nll_loss=0.897, ntokens=985.5, nsentences=32, sample_size=985.5, sample_size_v1=0, sample_size_v2=0, ppl=1.86, wps=484.5, ups=0.49, wpb=985.5, bsz=32, num_updates=41870, lr=6.19741e-06, gnorm=22.616, clip=100, loss_scale=16, train_wall=20, gb_free=11.5, wall=78718
2023-05-26 21:15:22 - progress_bar.py[line:272] - INFO: epoch 025:    385 / 1732 loss=2.147, loss_v1=0, loss_v2=0, nll_loss=0.921, ntokens=1084.2, nsentences=32, sample_size=1084.2, sample_size_v1=0, sample_size_v2=0, ppl=1.89, wps=582.8, ups=0.54, wpb=1084.2, bsz=32, num_updates=41880, lr=6.19127e-06, gnorm=22.609, clip=100, loss_scale=16, train_wall=19, gb_free=11.6, wall=78736
2023-05-26 21:15:40 - progress_bar.py[line:272] - INFO: epoch 025:    395 / 1732 loss=2.144, loss_v1=0, loss_v2=0, nll_loss=0.918, ntokens=924.7, nsentences=32, sample_size=924.7, sample_size_v1=0, sample_size_v2=0, ppl=1.89, wps=501.3, ups=0.54, wpb=924.7, bsz=32, num_updates=41890, lr=6.18512e-06, gnorm=25.254, clip=100, loss_scale=16, train_wall=18, gb_free=11.6, wall=78755
2023-05-26 21:15:59 - progress_bar.py[line:272] - INFO: epoch 025:    405 / 1732 loss=2.107, loss_v1=0, loss_v2=0, nll_loss=0.875, ntokens=1086.5, nsentences=32, sample_size=1086.5, sample_size_v1=0, sample_size_v2=0, ppl=1.83, wps=582.2, ups=0.54, wpb=1086.5, bsz=32, num_updates=41900, lr=6.17898e-06, gnorm=21.767, clip=100, loss_scale=16, train_wall=19, gb_free=11.8, wall=78774
2023-05-26 21:16:18 - progress_bar.py[line:272] - INFO: epoch 025:    415 / 1732 loss=2.109, loss_v1=0, loss_v2=0, nll_loss=0.878, ntokens=1059.1, nsentences=32, sample_size=1059.1, sample_size_v1=0, sample_size_v2=0, ppl=1.84, wps=566.7, ups=0.54, wpb=1059.1, bsz=32, num_updates=41910, lr=6.17284e-06, gnorm=22.005, clip=100, loss_scale=16, train_wall=19, gb_free=11.9, wall=78792
2023-05-26 21:16:36 - progress_bar.py[line:272] - INFO: epoch 025:    425 / 1732 loss=2.081, loss_v1=0, loss_v2=0, nll_loss=0.847, ntokens=994.5, nsentences=32, sample_size=994.5, sample_size_v1=0, sample_size_v2=0, ppl=1.8, wps=534.1, ups=0.54, wpb=994.5, bsz=32, num_updates=41920, lr=6.1667e-06, gnorm=23.358, clip=100, loss_scale=16, train_wall=19, gb_free=11.6, wall=78811
2023-05-26 21:16:55 - progress_bar.py[line:272] - INFO: epoch 025:    435 / 1732 loss=2.132, loss_v1=0, loss_v2=0, nll_loss=0.904, ntokens=1024.5, nsentences=32, sample_size=1024.5, sample_size_v1=0, sample_size_v2=0, ppl=1.87, wps=552.6, ups=0.54, wpb=1024.5, bsz=32, num_updates=41930, lr=6.16056e-06, gnorm=21.15, clip=100, loss_scale=16, train_wall=19, gb_free=11.8, wall=78829
2023-05-26 21:17:13 - progress_bar.py[line:272] - INFO: epoch 025:    445 / 1732 loss=2.129, loss_v1=0, loss_v2=0, nll_loss=0.9, ntokens=956.5, nsentences=32, sample_size=956.5, sample_size_v1=0, sample_size_v2=0, ppl=1.87, wps=514.9, ups=0.54, wpb=956.5, bsz=32, num_updates=41940, lr=6.15441e-06, gnorm=23.395, clip=100, loss_scale=16, train_wall=19, gb_free=11, wall=78848
2023-05-26 21:17:32 - progress_bar.py[line:272] - INFO: epoch 025:    455 / 1732 loss=2.127, loss_v1=0, loss_v2=0, nll_loss=0.897, ntokens=932.1, nsentences=32, sample_size=932.1, sample_size_v1=0, sample_size_v2=0, ppl=1.86, wps=504.3, ups=0.54, wpb=932.1, bsz=32, num_updates=41950, lr=6.14827e-06, gnorm=23.437, clip=100, loss_scale=16, train_wall=18, gb_free=11.5, wall=78866
2023-05-26 21:17:50 - progress_bar.py[line:272] - INFO: epoch 025:    465 / 1732 loss=2.161, loss_v1=0, loss_v2=0, nll_loss=0.936, ntokens=1058.7, nsentences=32, sample_size=1058.7, sample_size_v1=0, sample_size_v2=0, ppl=1.91, wps=567.8, ups=0.54, wpb=1058.7, bsz=32, num_updates=41960, lr=6.14213e-06, gnorm=21.974, clip=100, loss_scale=16, train_wall=19, gb_free=11.1, wall=78885
2023-05-26 21:18:09 - progress_bar.py[line:272] - INFO: epoch 025:    475 / 1732 loss=2.161, loss_v1=0, loss_v2=0, nll_loss=0.936, ntokens=1061.8, nsentences=32, sample_size=1061.8, sample_size_v1=0, sample_size_v2=0, ppl=1.91, wps=566.6, ups=0.53, wpb=1061.8, bsz=32, num_updates=41970, lr=6.13599e-06, gnorm=22.972, clip=100, loss_scale=16, train_wall=19, gb_free=11.4, wall=78904
2023-05-26 21:18:28 - progress_bar.py[line:272] - INFO: epoch 025:    485 / 1732 loss=2.123, loss_v1=0, loss_v2=0, nll_loss=0.893, ntokens=980.2, nsentences=32, sample_size=980.2, sample_size_v1=0, sample_size_v2=0, ppl=1.86, wps=528.8, ups=0.54, wpb=980.2, bsz=32, num_updates=41980, lr=6.12984e-06, gnorm=21.952, clip=100, loss_scale=16, train_wall=19, gb_free=11.2, wall=78922
2023-05-26 21:18:46 - progress_bar.py[line:272] - INFO: epoch 025:    495 / 1732 loss=2.106, loss_v1=0, loss_v2=0, nll_loss=0.874, ntokens=928.7, nsentences=32, sample_size=928.7, sample_size_v1=0, sample_size_v2=0, ppl=1.83, wps=502.1, ups=0.54, wpb=928.7, bsz=32, num_updates=41990, lr=6.1237e-06, gnorm=22.437, clip=100, loss_scale=16, train_wall=18, gb_free=12, wall=78941
2023-05-26 21:19:05 - progress_bar.py[line:272] - INFO: epoch 025:    505 / 1732 loss=2.153, loss_v1=0, loss_v2=0, nll_loss=0.927, ntokens=974.8, nsentences=32, sample_size=974.8, sample_size_v1=0, sample_size_v2=0, ppl=1.9, wps=530, ups=0.54, wpb=974.8, bsz=32, num_updates=42000, lr=6.11756e-06, gnorm=24.828, clip=100, loss_scale=16, train_wall=18, gb_free=11.5, wall=78959
2023-05-26 21:19:23 - progress_bar.py[line:272] - INFO: epoch 025:    515 / 1732 loss=2.145, loss_v1=0, loss_v2=0, nll_loss=0.918, ntokens=1073.1, nsentences=32, sample_size=1073.1, sample_size_v1=0, sample_size_v2=0, ppl=1.89, wps=577.2, ups=0.54, wpb=1073.1, bsz=32, num_updates=42010, lr=6.11142e-06, gnorm=22.124, clip=100, loss_scale=16, train_wall=19, gb_free=11.2, wall=78978
2023-05-26 21:19:42 - progress_bar.py[line:272] - INFO: epoch 025:    525 / 1732 loss=2.129, loss_v1=0, loss_v2=0, nll_loss=0.9, ntokens=955.6, nsentences=32, sample_size=955.6, sample_size_v1=0, sample_size_v2=0, ppl=1.87, wps=518.1, ups=0.54, wpb=955.6, bsz=32, num_updates=42020, lr=6.10528e-06, gnorm=23.575, clip=100, loss_scale=16, train_wall=18, gb_free=11.7, wall=78996
2023-05-26 21:20:00 - progress_bar.py[line:272] - INFO: epoch 025:    535 / 1732 loss=2.139, loss_v1=0, loss_v2=0, nll_loss=0.91, ntokens=948.7, nsentences=32, sample_size=948.7, sample_size_v1=0, sample_size_v2=0, ppl=1.88, wps=514.9, ups=0.54, wpb=948.7, bsz=32, num_updates=42030, lr=6.09913e-06, gnorm=24.724, clip=100, loss_scale=16, train_wall=18, gb_free=11.3, wall=79015
2023-05-26 21:20:19 - progress_bar.py[line:272] - INFO: epoch 025:    545 / 1732 loss=2.149, loss_v1=0, loss_v2=0, nll_loss=0.923, ntokens=1010, nsentences=32, sample_size=1010, sample_size_v1=0, sample_size_v2=0, ppl=1.9, wps=544.9, ups=0.54, wpb=1010, bsz=32, num_updates=42040, lr=6.09299e-06, gnorm=23.74, clip=100, loss_scale=16, train_wall=19, gb_free=11.1, wall=79033
2023-05-26 21:20:37 - progress_bar.py[line:272] - INFO: epoch 025:    555 / 1732 loss=2.171, loss_v1=0, loss_v2=0, nll_loss=0.948, ntokens=1039.8, nsentences=32, sample_size=1039.8, sample_size_v1=0, sample_size_v2=0, ppl=1.93, wps=560.2, ups=0.54, wpb=1039.8, bsz=32, num_updates=42050, lr=6.08685e-06, gnorm=23.545, clip=100, loss_scale=16, train_wall=19, gb_free=11.3, wall=79052
2023-05-26 21:20:56 - progress_bar.py[line:272] - INFO: epoch 025:    565 / 1732 loss=2.161, loss_v1=0, loss_v2=0, nll_loss=0.937, ntokens=1014, nsentences=32, sample_size=1014, sample_size_v1=0, sample_size_v2=0, ppl=1.91, wps=544.7, ups=0.54, wpb=1014, bsz=32, num_updates=42060, lr=6.08071e-06, gnorm=24.588, clip=100, loss_scale=16, train_wall=19, gb_free=11.2, wall=79070
2023-05-26 21:21:15 - progress_bar.py[line:272] - INFO: epoch 025:    575 / 1732 loss=2.157, loss_v1=0, loss_v2=0, nll_loss=0.931, ntokens=1007.3, nsentences=32, sample_size=1007.3, sample_size_v1=0, sample_size_v2=0, ppl=1.91, wps=538.9, ups=0.54, wpb=1007.3, bsz=32, num_updates=42070, lr=6.07457e-06, gnorm=24.628, clip=100, loss_scale=16, train_wall=19, gb_free=11.5, wall=79089
2023-05-26 21:21:33 - progress_bar.py[line:272] - INFO: epoch 025:    585 / 1732 loss=2.155, loss_v1=0, loss_v2=0, nll_loss=0.929, ntokens=980.6, nsentences=32, sample_size=980.6, sample_size_v1=0, sample_size_v2=0, ppl=1.9, wps=524.3, ups=0.53, wpb=980.6, bsz=32, num_updates=42080, lr=6.06842e-06, gnorm=23.861, clip=100, loss_scale=16, train_wall=19, gb_free=11.6, wall=79108
2023-05-26 21:21:52 - progress_bar.py[line:272] - INFO: epoch 025:    595 / 1732 loss=2.102, loss_v1=0, loss_v2=0, nll_loss=0.869, ntokens=961.9, nsentences=32, sample_size=961.9, sample_size_v1=0, sample_size_v2=0, ppl=1.83, wps=516.6, ups=0.54, wpb=961.9, bsz=32, num_updates=42090, lr=6.06228e-06, gnorm=21.983, clip=100, loss_scale=16, train_wall=19, gb_free=11.6, wall=79127
2023-05-26 21:22:10 - progress_bar.py[line:272] - INFO: epoch 025:    605 / 1732 loss=2.107, loss_v1=0, loss_v2=0, nll_loss=0.875, ntokens=879.8, nsentences=32, sample_size=879.8, sample_size_v1=0, sample_size_v2=0, ppl=1.83, wps=479.4, ups=0.54, wpb=879.8, bsz=32, num_updates=42100, lr=6.05614e-06, gnorm=23.074, clip=100, loss_scale=16, train_wall=18, gb_free=12, wall=79145
2023-05-26 21:22:29 - progress_bar.py[line:272] - INFO: epoch 025:    615 / 1732 loss=2.142, loss_v1=0, loss_v2=0, nll_loss=0.915, ntokens=903.1, nsentences=32, sample_size=903.1, sample_size_v1=0, sample_size_v2=0, ppl=1.89, wps=488, ups=0.54, wpb=903.1, bsz=32, num_updates=42110, lr=6.05e-06, gnorm=23.754, clip=100, loss_scale=16, train_wall=18, gb_free=11.7, wall=79163
2023-05-26 21:22:47 - progress_bar.py[line:272] - INFO: epoch 025:    625 / 1732 loss=2.133, loss_v1=0, loss_v2=0, nll_loss=0.905, ntokens=898.6, nsentences=32, sample_size=898.6, sample_size_v1=0, sample_size_v2=0, ppl=1.87, wps=488.5, ups=0.54, wpb=898.6, bsz=32, num_updates=42120, lr=6.04385e-06, gnorm=23.236, clip=100, loss_scale=16, train_wall=18, gb_free=11.4, wall=79182
2023-05-26 21:23:05 - progress_bar.py[line:272] - INFO: epoch 025:    635 / 1732 loss=2.136, loss_v1=0, loss_v2=0, nll_loss=0.908, ntokens=897.1, nsentences=32, sample_size=897.1, sample_size_v1=0, sample_size_v2=0, ppl=1.88, wps=489.2, ups=0.55, wpb=897.1, bsz=32, num_updates=42130, lr=6.03771e-06, gnorm=24.556, clip=100, loss_scale=16, train_wall=18, gb_free=11.8, wall=79200
2023-05-26 21:23:24 - progress_bar.py[line:272] - INFO: epoch 025:    645 / 1732 loss=2.131, loss_v1=0, loss_v2=0, nll_loss=0.902, ntokens=1010.4, nsentences=32, sample_size=1010.4, sample_size_v1=0, sample_size_v2=0, ppl=1.87, wps=544.7, ups=0.54, wpb=1010.4, bsz=32, num_updates=42140, lr=6.03157e-06, gnorm=22.899, clip=100, loss_scale=16, train_wall=19, gb_free=11.8, wall=79219
2023-05-26 21:23:42 - progress_bar.py[line:272] - INFO: epoch 025:    655 / 1732 loss=2.111, loss_v1=0, loss_v2=0, nll_loss=0.882, ntokens=879.8, nsentences=32, sample_size=879.8, sample_size_v1=0, sample_size_v2=0, ppl=1.84, wps=482, ups=0.55, wpb=879.8, bsz=32, num_updates=42150, lr=6.02543e-06, gnorm=23.953, clip=100, loss_scale=16, train_wall=18, gb_free=11.8, wall=79237
2023-05-26 21:24:01 - progress_bar.py[line:272] - INFO: epoch 025:    665 / 1732 loss=2.124, loss_v1=0, loss_v2=0, nll_loss=0.895, ntokens=893.8, nsentences=32, sample_size=893.8, sample_size_v1=0, sample_size_v2=0, ppl=1.86, wps=487, ups=0.54, wpb=893.8, bsz=32, num_updates=42160, lr=6.01929e-06, gnorm=25.091, clip=100, loss_scale=16, train_wall=18, gb_free=12, wall=79255
2023-05-26 21:24:19 - progress_bar.py[line:272] - INFO: epoch 025:    675 / 1732 loss=2.142, loss_v1=0, loss_v2=0, nll_loss=0.915, ntokens=961.9, nsentences=32, sample_size=961.9, sample_size_v1=0, sample_size_v2=0, ppl=1.89, wps=518.3, ups=0.54, wpb=961.9, bsz=32, num_updates=42170, lr=6.01314e-06, gnorm=23.081, clip=100, loss_scale=16, train_wall=19, gb_free=10.9, wall=79274
2023-05-26 21:24:38 - progress_bar.py[line:272] - INFO: epoch 025:    685 / 1732 loss=2.127, loss_v1=0, loss_v2=0, nll_loss=0.898, ntokens=961.5, nsentences=32, sample_size=961.5, sample_size_v1=0, sample_size_v2=0, ppl=1.86, wps=521.5, ups=0.54, wpb=961.5, bsz=32, num_updates=42180, lr=6.007e-06, gnorm=22.295, clip=100, loss_scale=16, train_wall=18, gb_free=11.5, wall=79292
2023-05-26 21:24:56 - progress_bar.py[line:272] - INFO: epoch 025:    695 / 1732 loss=2.139, loss_v1=0, loss_v2=0, nll_loss=0.912, ntokens=1007.2, nsentences=32, sample_size=1007.2, sample_size_v1=0, sample_size_v2=0, ppl=1.88, wps=538.4, ups=0.53, wpb=1007.2, bsz=32, num_updates=42190, lr=6.00086e-06, gnorm=24.388, clip=100, loss_scale=16, train_wall=19, gb_free=10.5, wall=79311
2023-05-26 21:25:15 - progress_bar.py[line:272] - INFO: epoch 025:    705 / 1732 loss=2.092, loss_v1=0, loss_v2=0, nll_loss=0.859, ntokens=925.6, nsentences=32, sample_size=925.6, sample_size_v1=0, sample_size_v2=0, ppl=1.81, wps=502.7, ups=0.54, wpb=925.6, bsz=32, num_updates=42200, lr=5.99472e-06, gnorm=23.294, clip=100, loss_scale=16, train_wall=18, gb_free=11.8, wall=79329
2023-05-26 21:25:33 - progress_bar.py[line:272] - INFO: epoch 025:    715 / 1732 loss=2.125, loss_v1=0, loss_v2=0, nll_loss=0.895, ntokens=890.5, nsentences=32, sample_size=890.5, sample_size_v1=0, sample_size_v2=0, ppl=1.86, wps=483, ups=0.54, wpb=890.5, bsz=32, num_updates=42210, lr=5.98858e-06, gnorm=24.888, clip=100, loss_scale=16, train_wall=18, gb_free=11.7, wall=79348
2023-05-26 21:25:52 - progress_bar.py[line:272] - INFO: epoch 025:    725 / 1732 loss=2.084, loss_v1=0, loss_v2=0, nll_loss=0.851, ntokens=904.8, nsentences=32, sample_size=904.8, sample_size_v1=0, sample_size_v2=0, ppl=1.8, wps=486.6, ups=0.54, wpb=904.8, bsz=32, num_updates=42220, lr=5.98243e-06, gnorm=22.81, clip=100, loss_scale=16, train_wall=19, gb_free=11.5, wall=79366
2023-05-26 21:26:10 - progress_bar.py[line:272] - INFO: epoch 025:    735 / 1732 loss=2.121, loss_v1=0, loss_v2=0, nll_loss=0.891, ntokens=965.8, nsentences=32, sample_size=965.8, sample_size_v1=0, sample_size_v2=0, ppl=1.85, wps=523.7, ups=0.54, wpb=965.8, bsz=32, num_updates=42230, lr=5.97629e-06, gnorm=22.389, clip=100, loss_scale=16, train_wall=18, gb_free=11.6, wall=79385
2023-05-26 21:26:29 - progress_bar.py[line:272] - INFO: epoch 025:    745 / 1732 loss=2.1, loss_v1=0, loss_v2=0, nll_loss=0.867, ntokens=978.3, nsentences=32, sample_size=978.3, sample_size_v1=0, sample_size_v2=0, ppl=1.82, wps=528, ups=0.54, wpb=978.3, bsz=32, num_updates=42240, lr=5.97015e-06, gnorm=21.425, clip=100, loss_scale=16, train_wall=18, gb_free=11.1, wall=79403
2023-05-26 21:26:47 - progress_bar.py[line:272] - INFO: epoch 025:    755 / 1732 loss=2.109, loss_v1=0, loss_v2=0, nll_loss=0.878, ntokens=975.4, nsentences=32, sample_size=975.4, sample_size_v1=0, sample_size_v2=0, ppl=1.84, wps=526.5, ups=0.54, wpb=975.4, bsz=32, num_updates=42250, lr=5.96401e-06, gnorm=23.106, clip=100, loss_scale=16, train_wall=18, gb_free=11.7, wall=79422
2023-05-26 21:27:06 - progress_bar.py[line:272] - INFO: epoch 025:    765 / 1732 loss=2.12, loss_v1=0, loss_v2=0, nll_loss=0.891, ntokens=948.8, nsentences=32, sample_size=948.8, sample_size_v1=0, sample_size_v2=0, ppl=1.85, wps=515.6, ups=0.54, wpb=948.8, bsz=32, num_updates=42260, lr=5.95786e-06, gnorm=23.884, clip=100, loss_scale=16, train_wall=18, gb_free=10.9, wall=79440
2023-05-26 21:27:24 - progress_bar.py[line:272] - INFO: epoch 025:    775 / 1732 loss=2.123, loss_v1=0, loss_v2=0, nll_loss=0.894, ntokens=1002.4, nsentences=32, sample_size=1002.4, sample_size_v1=0, sample_size_v2=0, ppl=1.86, wps=541.6, ups=0.54, wpb=1002.4, bsz=32, num_updates=42270, lr=5.95172e-06, gnorm=25.042, clip=100, loss_scale=16, train_wall=18, gb_free=11.5, wall=79459
2023-05-26 21:27:43 - progress_bar.py[line:272] - INFO: epoch 025:    785 / 1732 loss=2.13, loss_v1=0, loss_v2=0, nll_loss=0.902, ntokens=1003.9, nsentences=32, sample_size=1003.9, sample_size_v1=0, sample_size_v2=0, ppl=1.87, wps=542.3, ups=0.54, wpb=1003.9, bsz=32, num_updates=42280, lr=5.94558e-06, gnorm=25.352, clip=100, loss_scale=16, train_wall=18, gb_free=11.2, wall=79477
2023-05-26 21:28:01 - progress_bar.py[line:272] - INFO: epoch 025:    795 / 1732 loss=2.154, loss_v1=0, loss_v2=0, nll_loss=0.927, ntokens=1051.8, nsentences=32, sample_size=1051.8, sample_size_v1=0, sample_size_v2=0, ppl=1.9, wps=567.8, ups=0.54, wpb=1051.8, bsz=32, num_updates=42290, lr=5.93944e-06, gnorm=23.883, clip=100, loss_scale=16, train_wall=18, gb_free=11.1, wall=79496
2023-05-26 21:28:20 - progress_bar.py[line:272] - INFO: epoch 025:    805 / 1732 loss=2.141, loss_v1=0, loss_v2=0, nll_loss=0.912, ntokens=913, nsentences=32, sample_size=913, sample_size_v1=0, sample_size_v2=0, ppl=1.88, wps=494.5, ups=0.54, wpb=913, bsz=32, num_updates=42300, lr=5.9333e-06, gnorm=25.109, clip=100, loss_scale=16, train_wall=18, gb_free=11.1, wall=79514
2023-05-26 21:28:38 - progress_bar.py[line:272] - INFO: epoch 025:    815 / 1732 loss=2.134, loss_v1=0, loss_v2=0, nll_loss=0.907, ntokens=936.3, nsentences=32, sample_size=936.3, sample_size_v1=0, sample_size_v2=0, ppl=1.88, wps=506.7, ups=0.54, wpb=936.3, bsz=32, num_updates=42310, lr=5.92715e-06, gnorm=25.462, clip=100, loss_scale=16, train_wall=18, gb_free=11.7, wall=79533
2023-05-26 21:28:57 - progress_bar.py[line:272] - INFO: epoch 025:    825 / 1732 loss=2.128, loss_v1=0, loss_v2=0, nll_loss=0.899, ntokens=931.3, nsentences=32, sample_size=931.3, sample_size_v1=0, sample_size_v2=0, ppl=1.86, wps=502.9, ups=0.54, wpb=931.3, bsz=32, num_updates=42320, lr=5.92101e-06, gnorm=23.752, clip=100, loss_scale=16, train_wall=18, gb_free=12, wall=79551
2023-05-26 21:29:15 - progress_bar.py[line:272] - INFO: epoch 025:    835 / 1732 loss=2.129, loss_v1=0, loss_v2=0, nll_loss=0.901, ntokens=897.4, nsentences=32, sample_size=897.4, sample_size_v1=0, sample_size_v2=0, ppl=1.87, wps=490.5, ups=0.55, wpb=897.4, bsz=32, num_updates=42330, lr=5.91487e-06, gnorm=24.787, clip=100, loss_scale=16, train_wall=18, gb_free=11.6, wall=79570
2023-05-26 21:29:33 - progress_bar.py[line:272] - INFO: epoch 025:    845 / 1732 loss=2.12, loss_v1=0, loss_v2=0, nll_loss=0.891, ntokens=987.4, nsentences=32, sample_size=987.4, sample_size_v1=0, sample_size_v2=0, ppl=1.85, wps=536.5, ups=0.54, wpb=987.4, bsz=32, num_updates=42340, lr=5.90873e-06, gnorm=23.935, clip=100, loss_scale=16, train_wall=18, gb_free=11.2, wall=79588
2023-05-26 21:29:52 - progress_bar.py[line:272] - INFO: epoch 025:    855 / 1732 loss=2.126, loss_v1=0, loss_v2=0, nll_loss=0.896, ntokens=952, nsentences=32, sample_size=952, sample_size_v1=0, sample_size_v2=0, ppl=1.86, wps=515.4, ups=0.54, wpb=952, bsz=32, num_updates=42350, lr=5.90259e-06, gnorm=23.923, clip=100, loss_scale=16, train_wall=18, gb_free=11.8, wall=79607
2023-05-26 21:30:10 - progress_bar.py[line:272] - INFO: epoch 025:    865 / 1732 loss=2.131, loss_v1=0, loss_v2=0, nll_loss=0.903, ntokens=968.1, nsentences=32, sample_size=968.1, sample_size_v1=0, sample_size_v2=0, ppl=1.87, wps=522.7, ups=0.54, wpb=968.1, bsz=32, num_updates=42360, lr=5.89644e-06, gnorm=25.367, clip=100, loss_scale=16, train_wall=18, gb_free=11.5, wall=79625
2023-05-26 21:30:29 - progress_bar.py[line:272] - INFO: epoch 025:    875 / 1732 loss=2.102, loss_v1=0, loss_v2=0, nll_loss=0.87, ntokens=985.7, nsentences=32, sample_size=985.7, sample_size_v1=0, sample_size_v2=0, ppl=1.83, wps=532.4, ups=0.54, wpb=985.7, bsz=32, num_updates=42370, lr=5.8903e-06, gnorm=22.64, clip=100, loss_scale=16, train_wall=18, gb_free=11.4, wall=79644
2023-05-26 21:30:47 - progress_bar.py[line:272] - INFO: epoch 025:    885 / 1732 loss=2.066, loss_v1=0, loss_v2=0, nll_loss=0.83, ntokens=961.4, nsentences=32, sample_size=961.4, sample_size_v1=0, sample_size_v2=0, ppl=1.78, wps=518.7, ups=0.54, wpb=961.4, bsz=32, num_updates=42380, lr=5.88416e-06, gnorm=22.804, clip=100, loss_scale=16, train_wall=19, gb_free=11.4, wall=79662
2023-05-26 21:31:06 - progress_bar.py[line:272] - INFO: epoch 025:    895 / 1732 loss=2.081, loss_v1=0, loss_v2=0, nll_loss=0.848, ntokens=1031.3, nsentences=32, sample_size=1031.3, sample_size_v1=0, sample_size_v2=0, ppl=1.8, wps=555.7, ups=0.54, wpb=1031.3, bsz=32, num_updates=42390, lr=5.87802e-06, gnorm=22.465, clip=100, loss_scale=32, train_wall=19, gb_free=11.7, wall=79681
2023-05-26 21:31:25 - progress_bar.py[line:272] - INFO: epoch 025:    905 / 1732 loss=2.075, loss_v1=0, loss_v2=0, nll_loss=0.84, ntokens=1040.4, nsentences=32, sample_size=1040.4, sample_size_v1=0, sample_size_v2=0, ppl=1.79, wps=560.8, ups=0.54, wpb=1040.4, bsz=32, num_updates=42400, lr=5.87188e-06, gnorm=21.831, clip=100, loss_scale=32, train_wall=19, gb_free=11.1, wall=79699
2023-05-26 21:31:43 - progress_bar.py[line:272] - INFO: epoch 025:    915 / 1732 loss=2.143, loss_v1=0, loss_v2=0, nll_loss=0.916, ntokens=937.6, nsentences=32, sample_size=937.6, sample_size_v1=0, sample_size_v2=0, ppl=1.89, wps=508.5, ups=0.54, wpb=937.6, bsz=32, num_updates=42410, lr=5.86573e-06, gnorm=25.337, clip=100, loss_scale=32, train_wall=18, gb_free=12, wall=79718
2023-05-26 21:32:02 - progress_bar.py[line:272] - INFO: epoch 025:    925 / 1732 loss=2.092, loss_v1=0, loss_v2=0, nll_loss=0.859, ntokens=1005.1, nsentences=32, sample_size=1005.1, sample_size_v1=0, sample_size_v2=0, ppl=1.81, wps=537.6, ups=0.53, wpb=1005.1, bsz=32, num_updates=42420, lr=5.85959e-06, gnorm=22.045, clip=100, loss_scale=32, train_wall=19, gb_free=11.8, wall=79736
2023-05-26 21:32:20 - progress_bar.py[line:272] - INFO: epoch 025:    935 / 1732 loss=2.115, loss_v1=0, loss_v2=0, nll_loss=0.884, ntokens=1058.5, nsentences=32, sample_size=1058.5, sample_size_v1=0, sample_size_v2=0, ppl=1.85, wps=565.7, ups=0.53, wpb=1058.5, bsz=32, num_updates=42430, lr=5.85345e-06, gnorm=24.738, clip=100, loss_scale=32, train_wall=19, gb_free=11.3, wall=79755
2023-05-26 21:32:39 - progress_bar.py[line:272] - INFO: epoch 025:    945 / 1732 loss=2.146, loss_v1=0, loss_v2=0, nll_loss=0.919, ntokens=1055.4, nsentences=32, sample_size=1055.4, sample_size_v1=0, sample_size_v2=0, ppl=1.89, wps=559.6, ups=0.53, wpb=1055.4, bsz=32, num_updates=42440, lr=5.84731e-06, gnorm=25.544, clip=100, loss_scale=32, train_wall=19, gb_free=11.2, wall=79774
2023-05-26 21:32:58 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2023-05-26 21:33:00 - progress_bar.py[line:272] - INFO: epoch 025:    956 / 1732 loss=2.112, loss_v1=0, loss_v2=0, nll_loss=0.882, ntokens=1037.7, nsentences=32, sample_size=1037.7, sample_size_v1=0, sample_size_v2=0, ppl=1.84, wps=506.1, ups=0.49, wpb=1037.7, bsz=32, num_updates=42450, lr=5.84116e-06, gnorm=22.13, clip=100, loss_scale=16, train_wall=20, gb_free=11.2, wall=79794
2023-05-26 21:33:19 - progress_bar.py[line:272] - INFO: epoch 025:    966 / 1732 loss=2.139, loss_v1=0, loss_v2=0, nll_loss=0.912, ntokens=1045.2, nsentences=32, sample_size=1045.2, sample_size_v1=0, sample_size_v2=0, ppl=1.88, wps=557.1, ups=0.53, wpb=1045.2, bsz=32, num_updates=42460, lr=5.83502e-06, gnorm=23.915, clip=100, loss_scale=16, train_wall=19, gb_free=11.5, wall=79813
2023-05-26 21:33:37 - progress_bar.py[line:272] - INFO: epoch 025:    976 / 1732 loss=2.108, loss_v1=0, loss_v2=0, nll_loss=0.877, ntokens=1030.4, nsentences=32, sample_size=1030.4, sample_size_v1=0, sample_size_v2=0, ppl=1.84, wps=548.1, ups=0.53, wpb=1030.4, bsz=32, num_updates=42470, lr=5.82888e-06, gnorm=22.703, clip=100, loss_scale=16, train_wall=19, gb_free=11.7, wall=79832
2023-05-26 21:33:56 - progress_bar.py[line:272] - INFO: epoch 025:    986 / 1732 loss=2.118, loss_v1=0, loss_v2=0, nll_loss=0.889, ntokens=1042.1, nsentences=32, sample_size=1042.1, sample_size_v1=0, sample_size_v2=0, ppl=1.85, wps=551.4, ups=0.53, wpb=1042.1, bsz=32, num_updates=42480, lr=5.82274e-06, gnorm=22.616, clip=100, loss_scale=16, train_wall=19, gb_free=10.8, wall=79851
2023-05-26 21:34:15 - progress_bar.py[line:272] - INFO: epoch 025:    996 / 1732 loss=2.126, loss_v1=0, loss_v2=0, nll_loss=0.896, ntokens=1036.4, nsentences=32, sample_size=1036.4, sample_size_v1=0, sample_size_v2=0, ppl=1.86, wps=553.5, ups=0.53, wpb=1036.4, bsz=32, num_updates=42490, lr=5.8166e-06, gnorm=24.029, clip=100, loss_scale=16, train_wall=19, gb_free=11.7, wall=79870
2023-05-26 21:34:34 - progress_bar.py[line:272] - INFO: epoch 025:   1006 / 1732 loss=2.117, loss_v1=0, loss_v2=0, nll_loss=0.887, ntokens=1007.9, nsentences=32, sample_size=1007.9, sample_size_v1=0, sample_size_v2=0, ppl=1.85, wps=539.7, ups=0.54, wpb=1007.9, bsz=32, num_updates=42500, lr=5.81045e-06, gnorm=22.835, clip=100, loss_scale=16, train_wall=19, gb_free=11.5, wall=79888
2023-05-26 21:34:52 - progress_bar.py[line:272] - INFO: epoch 025:   1016 / 1732 loss=2.112, loss_v1=0, loss_v2=0, nll_loss=0.88, ntokens=979.4, nsentences=32, sample_size=979.4, sample_size_v1=0, sample_size_v2=0, ppl=1.84, wps=526.4, ups=0.54, wpb=979.4, bsz=32, num_updates=42510, lr=5.80431e-06, gnorm=20.822, clip=100, loss_scale=16, train_wall=19, gb_free=11.6, wall=79907
2023-05-26 21:35:11 - progress_bar.py[line:272] - INFO: epoch 025:   1026 / 1732 loss=2.124, loss_v1=0, loss_v2=0, nll_loss=0.894, ntokens=1095, nsentences=32, sample_size=1095, sample_size_v1=0, sample_size_v2=0, ppl=1.86, wps=579.1, ups=0.53, wpb=1095, bsz=32, num_updates=42520, lr=5.79817e-06, gnorm=21.805, clip=100, loss_scale=16, train_wall=19, gb_free=11.3, wall=79926
2023-05-26 21:35:30 - progress_bar.py[line:272] - INFO: epoch 025:   1036 / 1732 loss=2.097, loss_v1=0, loss_v2=0, nll_loss=0.863, ntokens=1118.5, nsentences=32, sample_size=1118.5, sample_size_v1=0, sample_size_v2=0, ppl=1.82, wps=592, ups=0.53, wpb=1118.5, bsz=32, num_updates=42530, lr=5.79203e-06, gnorm=21.699, clip=100, loss_scale=16, train_wall=19, gb_free=11.2, wall=79945
2023-05-26 21:35:49 - progress_bar.py[line:272] - INFO: epoch 025:   1046 / 1732 loss=2.122, loss_v1=0, loss_v2=0, nll_loss=0.892, ntokens=1013.5, nsentences=32, sample_size=1013.5, sample_size_v1=0, sample_size_v2=0, ppl=1.86, wps=540.2, ups=0.53, wpb=1013.5, bsz=32, num_updates=42540, lr=5.78589e-06, gnorm=22.675, clip=100, loss_scale=16, train_wall=19, gb_free=11.7, wall=79964
2023-05-26 21:36:08 - progress_bar.py[line:272] - INFO: epoch 025:   1056 / 1732 loss=2.128, loss_v1=0, loss_v2=0, nll_loss=0.899, ntokens=1086.8, nsentences=32, sample_size=1086.8, sample_size_v1=0, sample_size_v2=0, ppl=1.87, wps=580.1, ups=0.53, wpb=1086.8, bsz=32, num_updates=42550, lr=5.77974e-06, gnorm=22.842, clip=100, loss_scale=16, train_wall=19, gb_free=11.2, wall=79982
2023-05-26 21:36:26 - progress_bar.py[line:272] - INFO: epoch 025:   1066 / 1732 loss=2.112, loss_v1=0, loss_v2=0, nll_loss=0.881, ntokens=1024.1, nsentences=32, sample_size=1024.1, sample_size_v1=0, sample_size_v2=0, ppl=1.84, wps=547.7, ups=0.53, wpb=1024.1, bsz=32, num_updates=42560, lr=5.7736e-06, gnorm=21.822, clip=100, loss_scale=16, train_wall=19, gb_free=11.2, wall=80001
2023-05-26 21:36:45 - progress_bar.py[line:272] - INFO: epoch 025:   1076 / 1732 loss=2.138, loss_v1=0, loss_v2=0, nll_loss=0.91, ntokens=1000.2, nsentences=32, sample_size=1000.2, sample_size_v1=0, sample_size_v2=0, ppl=1.88, wps=530.2, ups=0.53, wpb=1000.2, bsz=32, num_updates=42570, lr=5.76746e-06, gnorm=25.458, clip=100, loss_scale=16, train_wall=19, gb_free=11.5, wall=80020
2023-05-26 21:37:04 - progress_bar.py[line:272] - INFO: epoch 025:   1086 / 1732 loss=2.118, loss_v1=0, loss_v2=0, nll_loss=0.887, ntokens=1073.8, nsentences=32, sample_size=1073.8, sample_size_v1=0, sample_size_v2=0, ppl=1.85, wps=568.4, ups=0.53, wpb=1073.8, bsz=32, num_updates=42580, lr=5.76132e-06, gnorm=20.433, clip=100, loss_scale=16, train_wall=19, gb_free=11.2, wall=80039
2023-05-26 21:37:23 - progress_bar.py[line:272] - INFO: epoch 025:   1096 / 1732 loss=2.133, loss_v1=0, loss_v2=0, nll_loss=0.904, ntokens=1044.2, nsentences=32, sample_size=1044.2, sample_size_v1=0, sample_size_v2=0, ppl=1.87, wps=556.6, ups=0.53, wpb=1044.2, bsz=32, num_updates=42590, lr=5.75517e-06, gnorm=21.559, clip=100, loss_scale=16, train_wall=19, gb_free=11, wall=80058
2023-05-26 21:37:42 - progress_bar.py[line:272] - INFO: epoch 025:   1106 / 1732 loss=2.108, loss_v1=0, loss_v2=0, nll_loss=0.876, ntokens=1073, nsentences=32, sample_size=1073, sample_size_v1=0, sample_size_v2=0, ppl=1.84, wps=569.7, ups=0.53, wpb=1073, bsz=32, num_updates=42600, lr=5.74903e-06, gnorm=21.99, clip=100, loss_scale=16, train_wall=19, gb_free=11.2, wall=80076
2023-05-26 21:38:00 - progress_bar.py[line:272] - INFO: epoch 025:   1116 / 1732 loss=2.133, loss_v1=0, loss_v2=0, nll_loss=0.904, ntokens=936.7, nsentences=32, sample_size=936.7, sample_size_v1=0, sample_size_v2=0, ppl=1.87, wps=500.8, ups=0.53, wpb=936.7, bsz=32, num_updates=42610, lr=5.74289e-06, gnorm=24.791, clip=100, loss_scale=16, train_wall=19, gb_free=11.1, wall=80095
2023-05-26 21:38:19 - progress_bar.py[line:272] - INFO: epoch 025:   1126 / 1732 loss=2.116, loss_v1=0, loss_v2=0, nll_loss=0.885, ntokens=1021, nsentences=32, sample_size=1021, sample_size_v1=0, sample_size_v2=0, ppl=1.85, wps=543.6, ups=0.53, wpb=1021, bsz=32, num_updates=42620, lr=5.73675e-06, gnorm=23.829, clip=100, loss_scale=16, train_wall=19, gb_free=10.9, wall=80114
2023-05-26 21:38:38 - progress_bar.py[line:272] - INFO: epoch 025:   1136 / 1732 loss=2.11, loss_v1=0, loss_v2=0, nll_loss=0.878, ntokens=969.6, nsentences=32, sample_size=969.6, sample_size_v1=0, sample_size_v2=0, ppl=1.84, wps=519.2, ups=0.54, wpb=969.6, bsz=32, num_updates=42630, lr=5.73061e-06, gnorm=23.263, clip=100, loss_scale=16, train_wall=19, gb_free=11.7, wall=80133
2023-05-26 21:38:57 - progress_bar.py[line:272] - INFO: epoch 025:   1146 / 1732 loss=2.116, loss_v1=0, loss_v2=0, nll_loss=0.884, ntokens=1029.8, nsentences=32, sample_size=1029.8, sample_size_v1=0, sample_size_v2=0, ppl=1.85, wps=548.9, ups=0.53, wpb=1029.8, bsz=32, num_updates=42640, lr=5.72446e-06, gnorm=22.863, clip=100, loss_scale=16, train_wall=19, gb_free=11.4, wall=80151
2023-05-26 21:39:15 - progress_bar.py[line:272] - INFO: epoch 025:   1156 / 1732 loss=2.099, loss_v1=0, loss_v2=0, nll_loss=0.866, ntokens=1017, nsentences=32, sample_size=1017, sample_size_v1=0, sample_size_v2=0, ppl=1.82, wps=542.3, ups=0.53, wpb=1017, bsz=32, num_updates=42650, lr=5.71832e-06, gnorm=22.113, clip=100, loss_scale=16, train_wall=19, gb_free=10.6, wall=80170
2023-05-26 21:39:34 - progress_bar.py[line:272] - INFO: epoch 025:   1166 / 1732 loss=2.099, loss_v1=0, loss_v2=0, nll_loss=0.867, ntokens=1020.6, nsentences=32, sample_size=1020.6, sample_size_v1=0, sample_size_v2=0, ppl=1.82, wps=544.3, ups=0.53, wpb=1020.6, bsz=32, num_updates=42660, lr=5.71218e-06, gnorm=22.328, clip=100, loss_scale=16, train_wall=19, gb_free=11.5, wall=80189
2023-05-26 21:39:53 - progress_bar.py[line:272] - INFO: epoch 025:   1176 / 1732 loss=2.103, loss_v1=0, loss_v2=0, nll_loss=0.871, ntokens=1064.1, nsentences=32, sample_size=1064.1, sample_size_v1=0, sample_size_v2=0, ppl=1.83, wps=567.7, ups=0.53, wpb=1064.1, bsz=32, num_updates=42670, lr=5.70604e-06, gnorm=21.48, clip=100, loss_scale=16, train_wall=19, gb_free=11.1, wall=80208
2023-05-26 21:40:12 - progress_bar.py[line:272] - INFO: epoch 025:   1186 / 1732 loss=2.097, loss_v1=0, loss_v2=0, nll_loss=0.865, ntokens=966.7, nsentences=32, sample_size=966.7, sample_size_v1=0, sample_size_v2=0, ppl=1.82, wps=517.7, ups=0.54, wpb=966.7, bsz=32, num_updates=42680, lr=5.6999e-06, gnorm=24.152, clip=100, loss_scale=16, train_wall=19, gb_free=11.6, wall=80226
2023-05-26 21:40:30 - progress_bar.py[line:272] - INFO: epoch 025:   1196 / 1732 loss=2.114, loss_v1=0, loss_v2=0, nll_loss=0.884, ntokens=1072.1, nsentences=32, sample_size=1072.1, sample_size_v1=0, sample_size_v2=0, ppl=1.85, wps=570.9, ups=0.53, wpb=1072.1, bsz=32, num_updates=42690, lr=5.69375e-06, gnorm=21.311, clip=100, loss_scale=16, train_wall=19, gb_free=11.2, wall=80245
2023-05-26 21:40:49 - progress_bar.py[line:272] - INFO: epoch 025:   1206 / 1732 loss=2.092, loss_v1=0, loss_v2=0, nll_loss=0.859, ntokens=1115.4, nsentences=32, sample_size=1115.4, sample_size_v1=0, sample_size_v2=0, ppl=1.81, wps=589.5, ups=0.53, wpb=1115.4, bsz=32, num_updates=42700, lr=5.68761e-06, gnorm=21.13, clip=100, loss_scale=16, train_wall=19, gb_free=11.8, wall=80264
2023-05-26 21:41:08 - progress_bar.py[line:272] - INFO: epoch 025:   1216 / 1732 loss=2.118, loss_v1=0, loss_v2=0, nll_loss=0.887, ntokens=1038.1, nsentences=32, sample_size=1038.1, sample_size_v1=0, sample_size_v2=0, ppl=1.85, wps=553.7, ups=0.53, wpb=1038.1, bsz=32, num_updates=42710, lr=5.68147e-06, gnorm=20.507, clip=100, loss_scale=16, train_wall=19, gb_free=10.9, wall=80283
2023-05-26 21:41:27 - progress_bar.py[line:272] - INFO: epoch 025:   1226 / 1732 loss=2.126, loss_v1=0, loss_v2=0, nll_loss=0.896, ntokens=1020.3, nsentences=32, sample_size=1020.3, sample_size_v1=0, sample_size_v2=0, ppl=1.86, wps=542.8, ups=0.53, wpb=1020.3, bsz=32, num_updates=42720, lr=5.67533e-06, gnorm=22.861, clip=100, loss_scale=16, train_wall=19, gb_free=11.4, wall=80301
2023-05-26 21:41:46 - progress_bar.py[line:272] - INFO: epoch 025:   1236 / 1732 loss=2.092, loss_v1=0, loss_v2=0, nll_loss=0.859, ntokens=1034, nsentences=32, sample_size=1034, sample_size_v1=0, sample_size_v2=0, ppl=1.81, wps=552.9, ups=0.53, wpb=1034, bsz=32, num_updates=42730, lr=5.66918e-06, gnorm=20.313, clip=100, loss_scale=16, train_wall=19, gb_free=11, wall=80320
2023-05-26 21:42:04 - progress_bar.py[line:272] - INFO: epoch 025:   1246 / 1732 loss=2.062, loss_v1=0, loss_v2=0, nll_loss=0.825, ntokens=1109.3, nsentences=32, sample_size=1109.3, sample_size_v1=0, sample_size_v2=0, ppl=1.77, wps=588.3, ups=0.53, wpb=1109.3, bsz=32, num_updates=42740, lr=5.66304e-06, gnorm=20.961, clip=100, loss_scale=16, train_wall=19, gb_free=10.7, wall=80339
2023-05-26 21:42:23 - progress_bar.py[line:272] - INFO: epoch 025:   1256 / 1732 loss=2.101, loss_v1=0, loss_v2=0, nll_loss=0.869, ntokens=1060.4, nsentences=32, sample_size=1060.4, sample_size_v1=0, sample_size_v2=0, ppl=1.83, wps=566.2, ups=0.53, wpb=1060.4, bsz=32, num_updates=42750, lr=5.6569e-06, gnorm=21.427, clip=100, loss_scale=16, train_wall=19, gb_free=11.2, wall=80358
2023-05-26 21:42:42 - progress_bar.py[line:272] - INFO: epoch 025:   1266 / 1732 loss=2.107, loss_v1=0, loss_v2=0, nll_loss=0.875, ntokens=1048.7, nsentences=32, sample_size=1048.7, sample_size_v1=0, sample_size_v2=0, ppl=1.83, wps=555.8, ups=0.53, wpb=1048.7, bsz=32, num_updates=42760, lr=5.65076e-06, gnorm=21.601, clip=100, loss_scale=16, train_wall=19, gb_free=11.5, wall=80377
2023-05-26 21:43:01 - progress_bar.py[line:272] - INFO: epoch 025:   1276 / 1732 loss=2.091, loss_v1=0, loss_v2=0, nll_loss=0.859, ntokens=1075.2, nsentences=32, sample_size=1075.2, sample_size_v1=0, sample_size_v2=0, ppl=1.81, wps=569, ups=0.53, wpb=1075.2, bsz=32, num_updates=42770, lr=5.64462e-06, gnorm=18.633, clip=100, loss_scale=16, train_wall=19, gb_free=11, wall=80396
2023-05-26 21:43:20 - progress_bar.py[line:272] - INFO: epoch 025:   1286 / 1732 loss=2.092, loss_v1=0, loss_v2=0, nll_loss=0.859, ntokens=1038.1, nsentences=32, sample_size=1038.1, sample_size_v1=0, sample_size_v2=0, ppl=1.81, wps=550.9, ups=0.53, wpb=1038.1, bsz=32, num_updates=42780, lr=5.63847e-06, gnorm=20.17, clip=100, loss_scale=16, train_wall=19, gb_free=11.6, wall=80414
2023-05-26 21:43:39 - progress_bar.py[line:272] - INFO: epoch 025:   1296 / 1732 loss=2.081, loss_v1=0, loss_v2=0, nll_loss=0.847, ntokens=1121.3, nsentences=32, sample_size=1121.3, sample_size_v1=0, sample_size_v2=0, ppl=1.8, wps=593.3, ups=0.53, wpb=1121.3, bsz=32, num_updates=42790, lr=5.63233e-06, gnorm=19.461, clip=100, loss_scale=16, train_wall=19, gb_free=11.6, wall=80433
2023-05-26 21:43:58 - progress_bar.py[line:272] - INFO: epoch 025:   1306 / 1732 loss=2.125, loss_v1=0, loss_v2=0, nll_loss=0.895, ntokens=1091, nsentences=32, sample_size=1091, sample_size_v1=0, sample_size_v2=0, ppl=1.86, wps=575.8, ups=0.53, wpb=1091, bsz=32, num_updates=42800, lr=5.62619e-06, gnorm=21.085, clip=100, loss_scale=16, train_wall=19, gb_free=10.8, wall=80452
2023-05-26 21:44:17 - progress_bar.py[line:272] - INFO: epoch 025:   1316 / 1732 loss=2.105, loss_v1=0, loss_v2=0, nll_loss=0.872, ntokens=1049.3, nsentences=32, sample_size=1049.3, sample_size_v1=0, sample_size_v2=0, ppl=1.83, wps=554.7, ups=0.53, wpb=1049.3, bsz=32, num_updates=42810, lr=5.62005e-06, gnorm=20.462, clip=100, loss_scale=16, train_wall=19, gb_free=11.3, wall=80471
2023-05-26 21:44:35 - progress_bar.py[line:272] - INFO: epoch 025:   1326 / 1732 loss=2.078, loss_v1=0, loss_v2=0, nll_loss=0.845, ntokens=1110.6, nsentences=32, sample_size=1110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.8, wps=587.3, ups=0.53, wpb=1110.6, bsz=32, num_updates=42820, lr=5.61391e-06, gnorm=20.233, clip=100, loss_scale=16, train_wall=19, gb_free=11.5, wall=80490
2023-05-26 21:44:54 - progress_bar.py[line:272] - INFO: epoch 025:   1336 / 1732 loss=2.084, loss_v1=0, loss_v2=0, nll_loss=0.85, ntokens=1122.3, nsentences=32, sample_size=1122.3, sample_size_v1=0, sample_size_v2=0, ppl=1.8, wps=596.2, ups=0.53, wpb=1122.3, bsz=32, num_updates=42830, lr=5.60776e-06, gnorm=19.356, clip=100, loss_scale=16, train_wall=19, gb_free=10.9, wall=80509
2023-05-26 21:45:13 - progress_bar.py[line:272] - INFO: epoch 025:   1346 / 1732 loss=2.099, loss_v1=0, loss_v2=0, nll_loss=0.868, ntokens=1171.7, nsentences=32, sample_size=1171.7, sample_size_v1=0, sample_size_v2=0, ppl=1.82, wps=617.9, ups=0.53, wpb=1171.7, bsz=32, num_updates=42840, lr=5.60162e-06, gnorm=20.491, clip=100, loss_scale=16, train_wall=19, gb_free=11, wall=80528
2023-05-26 21:45:32 - progress_bar.py[line:272] - INFO: epoch 025:   1356 / 1732 loss=2.083, loss_v1=0, loss_v2=0, nll_loss=0.85, ntokens=1137.3, nsentences=32, sample_size=1137.3, sample_size_v1=0, sample_size_v2=0, ppl=1.8, wps=601.1, ups=0.53, wpb=1137.3, bsz=32, num_updates=42850, lr=5.59548e-06, gnorm=19.404, clip=100, loss_scale=16, train_wall=19, gb_free=11.4, wall=80547
2023-05-26 21:45:51 - progress_bar.py[line:272] - INFO: epoch 025:   1366 / 1732 loss=2.097, loss_v1=0, loss_v2=0, nll_loss=0.864, ntokens=1081.4, nsentences=32, sample_size=1081.4, sample_size_v1=0, sample_size_v2=0, ppl=1.82, wps=573, ups=0.53, wpb=1081.4, bsz=32, num_updates=42860, lr=5.58934e-06, gnorm=20.862, clip=100, loss_scale=16, train_wall=19, gb_free=11.4, wall=80566
2023-05-26 21:46:10 - progress_bar.py[line:272] - INFO: epoch 025:   1376 / 1732 loss=2.136, loss_v1=0, loss_v2=0, nll_loss=0.908, ntokens=1111.5, nsentences=32, sample_size=1111.5, sample_size_v1=0, sample_size_v2=0, ppl=1.88, wps=590.2, ups=0.53, wpb=1111.5, bsz=32, num_updates=42870, lr=5.5832e-06, gnorm=21.741, clip=100, loss_scale=16, train_wall=19, gb_free=11.1, wall=80585
2023-05-26 21:46:29 - progress_bar.py[line:272] - INFO: epoch 025:   1386 / 1732 loss=2.114, loss_v1=0, loss_v2=0, nll_loss=0.883, ntokens=1153.3, nsentences=32, sample_size=1153.3, sample_size_v1=0, sample_size_v2=0, ppl=1.84, wps=612.8, ups=0.53, wpb=1153.3, bsz=32, num_updates=42880, lr=5.57705e-06, gnorm=21.396, clip=100, loss_scale=16, train_wall=19, gb_free=11.7, wall=80603
2023-05-26 21:46:47 - progress_bar.py[line:272] - INFO: epoch 025:   1396 / 1732 loss=2.094, loss_v1=0, loss_v2=0, nll_loss=0.86, ntokens=1044.6, nsentences=32, sample_size=1044.6, sample_size_v1=0, sample_size_v2=0, ppl=1.81, wps=556.2, ups=0.53, wpb=1044.6, bsz=32, num_updates=42890, lr=5.57091e-06, gnorm=21.671, clip=100, loss_scale=16, train_wall=19, gb_free=11.3, wall=80622
2023-05-26 21:47:06 - progress_bar.py[line:272] - INFO: epoch 025:   1406 / 1732 loss=2.122, loss_v1=0, loss_v2=0, nll_loss=0.892, ntokens=1163.8, nsentences=32, sample_size=1163.8, sample_size_v1=0, sample_size_v2=0, ppl=1.86, wps=616.4, ups=0.53, wpb=1163.8, bsz=32, num_updates=42900, lr=5.56477e-06, gnorm=22.049, clip=100, loss_scale=16, train_wall=19, gb_free=11.5, wall=80641
2023-05-26 21:47:25 - progress_bar.py[line:272] - INFO: epoch 025:   1416 / 1732 loss=2.145, loss_v1=0, loss_v2=0, nll_loss=0.918, ntokens=1281, nsentences=32, sample_size=1281, sample_size_v1=0, sample_size_v2=0, ppl=1.89, wps=673.2, ups=0.53, wpb=1281, bsz=32, num_updates=42910, lr=5.55863e-06, gnorm=19.055, clip=100, loss_scale=16, train_wall=19, gb_free=10.6, wall=80660
2023-05-26 21:47:45 - progress_bar.py[line:272] - INFO: epoch 025:   1426 / 1732 loss=2.105, loss_v1=0, loss_v2=0, nll_loss=0.871, ntokens=1225.6, nsentences=32, sample_size=1225.6, sample_size_v1=0, sample_size_v2=0, ppl=1.83, wps=640.6, ups=0.52, wpb=1225.6, bsz=32, num_updates=42920, lr=5.55248e-06, gnorm=18.262, clip=100, loss_scale=16, train_wall=19, gb_free=10.6, wall=80679
2023-05-26 21:48:03 - progress_bar.py[line:272] - INFO: epoch 025:   1436 / 1732 loss=2.117, loss_v1=0, loss_v2=0, nll_loss=0.887, ntokens=1219.4, nsentences=32, sample_size=1219.4, sample_size_v1=0, sample_size_v2=0, ppl=1.85, wps=647.2, ups=0.53, wpb=1219.4, bsz=32, num_updates=42930, lr=5.54634e-06, gnorm=21.059, clip=100, loss_scale=16, train_wall=19, gb_free=10.9, wall=80698
2023-05-26 21:48:22 - progress_bar.py[line:272] - INFO: epoch 025:   1446 / 1732 loss=2.116, loss_v1=0, loss_v2=0, nll_loss=0.886, ntokens=1113.8, nsentences=32, sample_size=1113.8, sample_size_v1=0, sample_size_v2=0, ppl=1.85, wps=589.4, ups=0.53, wpb=1113.8, bsz=32, num_updates=42940, lr=5.5402e-06, gnorm=19.466, clip=100, loss_scale=16, train_wall=19, gb_free=11.2, wall=80717
2023-05-26 21:48:41 - progress_bar.py[line:272] - INFO: epoch 025:   1456 / 1732 loss=2.124, loss_v1=0, loss_v2=0, nll_loss=0.894, ntokens=1106.5, nsentences=32, sample_size=1106.5, sample_size_v1=0, sample_size_v2=0, ppl=1.86, wps=586.8, ups=0.53, wpb=1106.5, bsz=32, num_updates=42950, lr=5.53406e-06, gnorm=22.568, clip=100, loss_scale=16, train_wall=19, gb_free=11.1, wall=80736
2023-05-26 21:49:00 - progress_bar.py[line:272] - INFO: epoch 025:   1466 / 1732 loss=2.078, loss_v1=0, loss_v2=0, nll_loss=0.841, ntokens=1200.2, nsentences=32, sample_size=1200.2, sample_size_v1=0, sample_size_v2=0, ppl=1.79, wps=632.2, ups=0.53, wpb=1200.2, bsz=32, num_updates=42960, lr=5.52792e-06, gnorm=18.782, clip=100, loss_scale=16, train_wall=19, gb_free=11.2, wall=80755
2023-05-26 21:49:19 - progress_bar.py[line:272] - INFO: epoch 025:   1476 / 1732 loss=2.118, loss_v1=0, loss_v2=0, nll_loss=0.887, ntokens=1071.6, nsentences=32, sample_size=1071.6, sample_size_v1=0, sample_size_v2=0, ppl=1.85, wps=570, ups=0.53, wpb=1071.6, bsz=32, num_updates=42970, lr=5.52177e-06, gnorm=21.381, clip=100, loss_scale=32, train_wall=19, gb_free=11.4, wall=80774
2023-05-26 21:49:38 - progress_bar.py[line:272] - INFO: epoch 025:   1486 / 1732 loss=2.125, loss_v1=0, loss_v2=0, nll_loss=0.896, ntokens=1132, nsentences=32, sample_size=1132, sample_size_v1=0, sample_size_v2=0, ppl=1.86, wps=600.5, ups=0.53, wpb=1132, bsz=32, num_updates=42980, lr=5.51563e-06, gnorm=21.152, clip=100, loss_scale=32, train_wall=19, gb_free=10.6, wall=80792
2023-05-26 21:49:57 - progress_bar.py[line:272] - INFO: epoch 025:   1496 / 1732 loss=2.109, loss_v1=0, loss_v2=0, nll_loss=0.877, ntokens=1113.1, nsentences=32, sample_size=1113.1, sample_size_v1=0, sample_size_v2=0, ppl=1.84, wps=589.3, ups=0.53, wpb=1113.1, bsz=32, num_updates=42990, lr=5.50949e-06, gnorm=21.416, clip=100, loss_scale=32, train_wall=19, gb_free=10.9, wall=80811
2023-05-26 21:50:15 - progress_bar.py[line:272] - INFO: epoch 025:   1506 / 1732 loss=2.078, loss_v1=0, loss_v2=0, nll_loss=0.841, ntokens=1117, nsentences=32, sample_size=1117, sample_size_v1=0, sample_size_v2=0, ppl=1.79, wps=595.3, ups=0.53, wpb=1117, bsz=32, num_updates=43000, lr=5.50335e-06, gnorm=21.147, clip=100, loss_scale=32, train_wall=19, gb_free=11.4, wall=80830
2023-05-26 21:50:34 - progress_bar.py[line:272] - INFO: epoch 025:   1516 / 1732 loss=2.124, loss_v1=0, loss_v2=0, nll_loss=0.895, ntokens=1043.6, nsentences=32, sample_size=1043.6, sample_size_v1=0, sample_size_v2=0, ppl=1.86, wps=556.3, ups=0.53, wpb=1043.6, bsz=32, num_updates=43010, lr=5.49721e-06, gnorm=22.378, clip=100, loss_scale=32, train_wall=19, gb_free=11.3, wall=80849
2023-05-26 21:50:53 - progress_bar.py[line:272] - INFO: epoch 025:   1526 / 1732 loss=2.155, loss_v1=0, loss_v2=0, nll_loss=0.93, ntokens=1063.1, nsentences=32, sample_size=1063.1, sample_size_v1=0, sample_size_v2=0, ppl=1.91, wps=565.4, ups=0.53, wpb=1063.1, bsz=32, num_updates=43020, lr=5.49106e-06, gnorm=21.45, clip=100, loss_scale=32, train_wall=19, gb_free=11.2, wall=80868
2023-05-26 21:51:12 - progress_bar.py[line:272] - INFO: epoch 025:   1536 / 1732 loss=2.112, loss_v1=0, loss_v2=0, nll_loss=0.881, ntokens=1073.8, nsentences=32, sample_size=1073.8, sample_size_v1=0, sample_size_v2=0, ppl=1.84, wps=567.9, ups=0.53, wpb=1073.8, bsz=32, num_updates=43030, lr=5.48492e-06, gnorm=21.198, clip=100, loss_scale=32, train_wall=19, gb_free=11.2, wall=80887
2023-05-26 21:51:23 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2023-05-26 21:51:33 - progress_bar.py[line:272] - INFO: epoch 025:   1547 / 1732 loss=2.082, loss_v1=0, loss_v2=0, nll_loss=0.846, ntokens=1087, nsentences=32, sample_size=1087, sample_size_v1=0, sample_size_v2=0, ppl=1.8, wps=526.8, ups=0.48, wpb=1087, bsz=32, num_updates=43040, lr=5.47878e-06, gnorm=19.624, clip=100, loss_scale=16, train_wall=21, gb_free=11.2, wall=80907
2023-05-26 21:51:51 - progress_bar.py[line:272] - INFO: epoch 025:   1557 / 1732 loss=2.079, loss_v1=0, loss_v2=0, nll_loss=0.844, ntokens=1051.1, nsentences=32, sample_size=1051.1, sample_size_v1=0, sample_size_v2=0, ppl=1.79, wps=561, ups=0.53, wpb=1051.1, bsz=32, num_updates=43050, lr=5.47264e-06, gnorm=20.748, clip=100, loss_scale=16, train_wall=19, gb_free=11.2, wall=80926
2023-05-26 21:52:10 - progress_bar.py[line:272] - INFO: epoch 025:   1567 / 1732 loss=2.137, loss_v1=0, loss_v2=0, nll_loss=0.909, ntokens=1097.1, nsentences=32, sample_size=1097.1, sample_size_v1=0, sample_size_v2=0, ppl=1.88, wps=582.2, ups=0.53, wpb=1097.1, bsz=32, num_updates=43060, lr=5.46649e-06, gnorm=21.179, clip=100, loss_scale=16, train_wall=19, gb_free=10.6, wall=80945
2023-05-26 21:52:29 - progress_bar.py[line:272] - INFO: epoch 025:   1577 / 1732 loss=2.122, loss_v1=0, loss_v2=0, nll_loss=0.892, ntokens=1002.1, nsentences=32, sample_size=1002.1, sample_size_v1=0, sample_size_v2=0, ppl=1.86, wps=534.4, ups=0.53, wpb=1002.1, bsz=32, num_updates=43070, lr=5.46035e-06, gnorm=23.469, clip=100, loss_scale=16, train_wall=19, gb_free=11.8, wall=80964
2023-05-26 21:52:48 - progress_bar.py[line:272] - INFO: epoch 025:   1587 / 1732 loss=2.105, loss_v1=0, loss_v2=0, nll_loss=0.874, ntokens=1081.3, nsentences=32, sample_size=1081.3, sample_size_v1=0, sample_size_v2=0, ppl=1.83, wps=570.8, ups=0.53, wpb=1081.3, bsz=32, num_updates=43080, lr=5.45421e-06, gnorm=20.671, clip=100, loss_scale=16, train_wall=19, gb_free=10.8, wall=80982
2023-05-26 21:53:07 - progress_bar.py[line:272] - INFO: epoch 025:   1597 / 1732 loss=2.079, loss_v1=0, loss_v2=0, nll_loss=0.843, ntokens=1084.4, nsentences=32, sample_size=1084.4, sample_size_v1=0, sample_size_v2=0, ppl=1.79, wps=576.8, ups=0.53, wpb=1084.4, bsz=32, num_updates=43090, lr=5.44807e-06, gnorm=21.167, clip=100, loss_scale=16, train_wall=19, gb_free=10.9, wall=81001
2023-05-26 21:53:26 - progress_bar.py[line:272] - INFO: epoch 025:   1607 / 1732 loss=2.087, loss_v1=0, loss_v2=0, nll_loss=0.853, ntokens=1122.8, nsentences=32, sample_size=1122.8, sample_size_v1=0, sample_size_v2=0, ppl=1.81, wps=595, ups=0.53, wpb=1122.8, bsz=32, num_updates=43100, lr=5.44193e-06, gnorm=19.954, clip=100, loss_scale=16, train_wall=19, gb_free=10.9, wall=81020
2023-05-26 21:53:44 - progress_bar.py[line:272] - INFO: epoch 025:   1617 / 1732 loss=2.082, loss_v1=0, loss_v2=0, nll_loss=0.847, ntokens=1114.5, nsentences=32, sample_size=1114.5, sample_size_v1=0, sample_size_v2=0, ppl=1.8, wps=587.7, ups=0.53, wpb=1114.5, bsz=32, num_updates=43110, lr=5.43578e-06, gnorm=20.992, clip=100, loss_scale=16, train_wall=19, gb_free=11.3, wall=81039
2023-05-26 21:54:03 - progress_bar.py[line:272] - INFO: epoch 025:   1627 / 1732 loss=2.105, loss_v1=0, loss_v2=0, nll_loss=0.874, ntokens=1162.3, nsentences=32, sample_size=1162.3, sample_size_v1=0, sample_size_v2=0, ppl=1.83, wps=612.8, ups=0.53, wpb=1162.3, bsz=32, num_updates=43120, lr=5.42964e-06, gnorm=19.922, clip=100, loss_scale=16, train_wall=19, gb_free=11.2, wall=81058
2023-05-26 21:54:22 - progress_bar.py[line:272] - INFO: epoch 025:   1637 / 1732 loss=2.077, loss_v1=0, loss_v2=0, nll_loss=0.843, ntokens=1115.7, nsentences=32, sample_size=1115.7, sample_size_v1=0, sample_size_v2=0, ppl=1.79, wps=594.2, ups=0.53, wpb=1115.7, bsz=32, num_updates=43130, lr=5.4235e-06, gnorm=21.305, clip=100, loss_scale=16, train_wall=19, gb_free=11.3, wall=81077
2023-05-26 21:54:41 - progress_bar.py[line:272] - INFO: epoch 025:   1647 / 1732 loss=2.088, loss_v1=0, loss_v2=0, nll_loss=0.853, ntokens=1285, nsentences=32, sample_size=1285, sample_size_v1=0, sample_size_v2=0, ppl=1.81, wps=671.9, ups=0.52, wpb=1285, bsz=32, num_updates=43140, lr=5.41736e-06, gnorm=18.99, clip=100, loss_scale=16, train_wall=19, gb_free=11.1, wall=81096
2023-05-26 21:55:00 - progress_bar.py[line:272] - INFO: epoch 025:   1657 / 1732 loss=2.122, loss_v1=0, loss_v2=0, nll_loss=0.893, ntokens=952, nsentences=32, sample_size=952, sample_size_v1=0, sample_size_v2=0, ppl=1.86, wps=509.9, ups=0.54, wpb=952, bsz=32, num_updates=43150, lr=5.41122e-06, gnorm=22.727, clip=100, loss_scale=16, train_wall=19, gb_free=11.3, wall=81115
2023-05-26 21:55:19 - progress_bar.py[line:272] - INFO: epoch 025:   1667 / 1732 loss=2.099, loss_v1=0, loss_v2=0, nll_loss=0.866, ntokens=1028.1, nsentences=32, sample_size=1028.1, sample_size_v1=0, sample_size_v2=0, ppl=1.82, wps=546, ups=0.53, wpb=1028.1, bsz=32, num_updates=43160, lr=5.40507e-06, gnorm=20.431, clip=100, loss_scale=16, train_wall=19, gb_free=11.4, wall=81134
2023-05-26 21:55:38 - progress_bar.py[line:272] - INFO: epoch 025:   1677 / 1732 loss=2.075, loss_v1=0, loss_v2=0, nll_loss=0.84, ntokens=1135.4, nsentences=32, sample_size=1135.4, sample_size_v1=0, sample_size_v2=0, ppl=1.79, wps=602.8, ups=0.53, wpb=1135.4, bsz=32, num_updates=43170, lr=5.39893e-06, gnorm=19.801, clip=100, loss_scale=16, train_wall=19, gb_free=10.5, wall=81152
2023-05-26 21:55:57 - progress_bar.py[line:272] - INFO: epoch 025:   1687 / 1732 loss=2.091, loss_v1=0, loss_v2=0, nll_loss=0.856, ntokens=1154.5, nsentences=32, sample_size=1154.5, sample_size_v1=0, sample_size_v2=0, ppl=1.81, wps=609, ups=0.53, wpb=1154.5, bsz=32, num_updates=43180, lr=5.39279e-06, gnorm=20.988, clip=100, loss_scale=16, train_wall=19, gb_free=10, wall=81171
2023-05-26 21:56:16 - progress_bar.py[line:272] - INFO: epoch 025:   1697 / 1732 loss=2.09, loss_v1=0, loss_v2=0, nll_loss=0.856, ntokens=1302.5, nsentences=32, sample_size=1302.5, sample_size_v1=0, sample_size_v2=0, ppl=1.81, wps=673.7, ups=0.52, wpb=1302.5, bsz=32, num_updates=43190, lr=5.38665e-06, gnorm=18.619, clip=100, loss_scale=16, train_wall=19, gb_free=10.7, wall=81191
2023-05-26 21:56:35 - progress_bar.py[line:272] - INFO: epoch 025:   1707 / 1732 loss=2.108, loss_v1=0, loss_v2=0, nll_loss=0.878, ntokens=1171.1, nsentences=32, sample_size=1171.1, sample_size_v1=0, sample_size_v2=0, ppl=1.84, wps=617.7, ups=0.53, wpb=1171.1, bsz=32, num_updates=43200, lr=5.3805e-06, gnorm=19.952, clip=100, loss_scale=16, train_wall=19, gb_free=11.7, wall=81210
2023-05-26 21:56:54 - progress_bar.py[line:272] - INFO: epoch 025:   1717 / 1732 loss=2.094, loss_v1=0, loss_v2=0, nll_loss=0.861, ntokens=1206.1, nsentences=32, sample_size=1206.1, sample_size_v1=0, sample_size_v2=0, ppl=1.82, wps=634, ups=0.53, wpb=1206.1, bsz=32, num_updates=43210, lr=5.37436e-06, gnorm=19.217, clip=100, loss_scale=16, train_wall=19, gb_free=11.2, wall=81229
2023-05-26 21:57:13 - progress_bar.py[line:272] - INFO: epoch 025:   1727 / 1732 loss=2.103, loss_v1=0, loss_v2=0, nll_loss=0.871, ntokens=1102.3, nsentences=32, sample_size=1102.3, sample_size_v1=0, sample_size_v2=0, ppl=1.83, wps=582.6, ups=0.53, wpb=1102.3, bsz=32, num_updates=43220, lr=5.36822e-06, gnorm=19.981, clip=100, loss_scale=16, train_wall=19, gb_free=11.2, wall=81248
2023-05-26 21:57:21 - train.py[line:332] - INFO: end of epoch 25 (average epoch stats below)
2023-05-26 21:57:21 - progress_bar.py[line:282] - INFO: epoch 025 | loss 2.104 | loss_v1 0 | loss_v2 0 | nll_loss 0.872 | ntokens 1051.51 | nsentences 31.986 | sample_size 1051.51 | sample_size_v1 0 | sample_size_v2 0 | ppl 1.83 | wps 559.8 | ups 0.53 | wpb 1051.5 | bsz 32 | num_updates 43225 | lr 5.36515e-06 | gnorm 22.087 | clip 100 | loss_scale 16 | train_wall 3240 | gb_free 11.7 | wall 81256
2023-05-26 21:57:21 - trainer.py[line:639] - INFO: loading train data for epoch 26
local datafile ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 0 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 0 finished initializing row_count and line_idx-to-offset mapping
file ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 0 row count 55400 total row count 55400
slice_id 0 seek offset 0
2023-05-26 21:57:23 - trainer.py[line:703] - INFO: begin training epoch 26
2023-05-26 21:57:23 - train.py[line:305] - INFO: Start iterating over samples
2023-05-26 21:57:33 - progress_bar.py[line:272] - INFO: epoch 026:      5 / 1732 loss=2.104, loss_v1=0, loss_v2=0, nll_loss=0.871, ntokens=1084.5, nsentences=29.6, sample_size=1084.5, sample_size_v1=0, sample_size_v2=0, ppl=1.83, wps=548.9, ups=0.51, wpb=1084.5, bsz=29.6, num_updates=43230, lr=5.36208e-06, gnorm=22.182, clip=100, loss_scale=16, train_wall=18, gb_free=11.2, wall=81267
2023-05-26 21:57:52 - progress_bar.py[line:272] - INFO: epoch 026:     15 / 1732 loss=2.105, loss_v1=0, loss_v2=0, nll_loss=0.873, ntokens=1089.9, nsentences=32, sample_size=1089.9, sample_size_v1=0, sample_size_v2=0, ppl=1.83, wps=578.1, ups=0.53, wpb=1089.9, bsz=32, num_updates=43240, lr=5.35594e-06, gnorm=25.638, clip=100, loss_scale=16, train_wall=19, gb_free=11, wall=81286
2023-05-26 21:58:10 - progress_bar.py[line:272] - INFO: epoch 026:     25 / 1732 loss=2.055, loss_v1=0, loss_v2=0, nll_loss=0.816, ntokens=998.7, nsentences=32, sample_size=998.7, sample_size_v1=0, sample_size_v2=0, ppl=1.76, wps=530.9, ups=0.53, wpb=998.7, bsz=32, num_updates=43250, lr=5.34979e-06, gnorm=26.633, clip=100, loss_scale=16, train_wall=19, gb_free=11.6, wall=81305
2023-05-26 21:58:29 - progress_bar.py[line:272] - INFO: epoch 026:     35 / 1732 loss=1.981, loss_v1=0, loss_v2=0, nll_loss=0.733, ntokens=1115.2, nsentences=32, sample_size=1115.2, sample_size_v1=0, sample_size_v2=0, ppl=1.66, wps=588, ups=0.53, wpb=1115.2, bsz=32, num_updates=43260, lr=5.34365e-06, gnorm=20.369, clip=100, loss_scale=16, train_wall=19, gb_free=11, wall=81324
2023-05-26 21:58:48 - progress_bar.py[line:272] - INFO: epoch 026:     45 / 1732 loss=1.971, loss_v1=0, loss_v2=0, nll_loss=0.722, ntokens=1103.9, nsentences=32, sample_size=1103.9, sample_size_v1=0, sample_size_v2=0, ppl=1.65, wps=584.8, ups=0.53, wpb=1103.9, bsz=32, num_updates=43270, lr=5.33751e-06, gnorm=21.36, clip=100, loss_scale=16, train_wall=19, gb_free=10.6, wall=81343
2023-05-26 21:59:07 - progress_bar.py[line:272] - INFO: epoch 026:     55 / 1732 loss=1.937, loss_v1=0, loss_v2=0, nll_loss=0.685, ntokens=1058.4, nsentences=32, sample_size=1058.4, sample_size_v1=0, sample_size_v2=0, ppl=1.61, wps=561.7, ups=0.53, wpb=1058.4, bsz=32, num_updates=43280, lr=5.33137e-06, gnorm=20.594, clip=100, loss_scale=16, train_wall=19, gb_free=10.9, wall=81362
2023-05-26 21:59:26 - progress_bar.py[line:272] - INFO: epoch 026:     65 / 1732 loss=1.849, loss_v1=0, loss_v2=0, nll_loss=0.586, ntokens=1260.1, nsentences=32, sample_size=1260.1, sample_size_v1=0, sample_size_v2=0, ppl=1.5, wps=659.2, ups=0.52, wpb=1260.1, bsz=32, num_updates=43290, lr=5.32523e-06, gnorm=18.284, clip=100, loss_scale=16, train_wall=19, gb_free=10.5, wall=81381
2023-05-26 21:59:46 - progress_bar.py[line:272] - INFO: epoch 026:     75 / 1732 loss=1.918, loss_v1=0, loss_v2=0, nll_loss=0.665, ntokens=1372.4, nsentences=32, sample_size=1372.4, sample_size_v1=0, sample_size_v2=0, ppl=1.59, wps=702.4, ups=0.51, wpb=1372.4, bsz=32, num_updates=43300, lr=5.31908e-06, gnorm=17.377, clip=100, loss_scale=16, train_wall=20, gb_free=10.5, wall=81400
2023-05-26 22:00:05 - progress_bar.py[line:272] - INFO: epoch 026:     85 / 1732 loss=1.951, loss_v1=0, loss_v2=0, nll_loss=0.703, ntokens=1112.6, nsentences=32, sample_size=1112.6, sample_size_v1=0, sample_size_v2=0, ppl=1.63, wps=580.4, ups=0.52, wpb=1112.6, bsz=32, num_updates=43310, lr=5.31294e-06, gnorm=17.571, clip=100, loss_scale=16, train_wall=19, gb_free=11.4, wall=81420
2023-05-26 22:00:24 - progress_bar.py[line:272] - INFO: epoch 026:     95 / 1732 loss=1.938, loss_v1=0, loss_v2=0, nll_loss=0.689, ntokens=1092.3, nsentences=32, sample_size=1092.3, sample_size_v1=0, sample_size_v2=0, ppl=1.61, wps=576.8, ups=0.53, wpb=1092.3, bsz=32, num_updates=43320, lr=5.3068e-06, gnorm=20.78, clip=100, loss_scale=16, train_wall=19, gb_free=11.6, wall=81438
2023-05-26 22:00:43 - progress_bar.py[line:272] - INFO: epoch 026:    105 / 1732 loss=2.039, loss_v1=0, loss_v2=0, nll_loss=0.801, ntokens=995.3, nsentences=32, sample_size=995.3, sample_size_v1=0, sample_size_v2=0, ppl=1.74, wps=529, ups=0.53, wpb=995.3, bsz=32, num_updates=43330, lr=5.30066e-06, gnorm=20.556, clip=100, loss_scale=16, train_wall=19, gb_free=11.1, wall=81457
2023-05-26 22:01:02 - progress_bar.py[line:272] - INFO: epoch 026:    115 / 1732 loss=2.141, loss_v1=0, loss_v2=0, nll_loss=0.914, ntokens=1032.5, nsentences=32, sample_size=1032.5, sample_size_v1=0, sample_size_v2=0, ppl=1.88, wps=544.1, ups=0.53, wpb=1032.5, bsz=32, num_updates=43340, lr=5.29452e-06, gnorm=23.35, clip=100, loss_scale=16, train_wall=19, gb_free=11.1, wall=81476
2023-05-26 22:01:21 - progress_bar.py[line:272] - INFO: epoch 026:    125 / 1732 loss=2.101, loss_v1=0, loss_v2=0, nll_loss=0.868, ntokens=1181.7, nsentences=32, sample_size=1181.7, sample_size_v1=0, sample_size_v2=0, ppl=1.83, wps=614, ups=0.52, wpb=1181.7, bsz=32, num_updates=43350, lr=5.28837e-06, gnorm=23.423, clip=100, loss_scale=16, train_wall=19, gb_free=10.4, wall=81496
2023-05-26 22:01:40 - progress_bar.py[line:272] - INFO: epoch 026:    135 / 1732 loss=2.083, loss_v1=0, loss_v2=0, nll_loss=0.848, ntokens=1179.6, nsentences=32, sample_size=1179.6, sample_size_v1=0, sample_size_v2=0, ppl=1.8, wps=618.9, ups=0.52, wpb=1179.6, bsz=32, num_updates=43360, lr=5.28223e-06, gnorm=23.887, clip=100, loss_scale=16, train_wall=19, gb_free=11.4, wall=81515
2023-05-26 22:01:59 - progress_bar.py[line:272] - INFO: epoch 026:    145 / 1732 loss=2.046, loss_v1=0, loss_v2=0, nll_loss=0.806, ntokens=1246.8, nsentences=32, sample_size=1246.8, sample_size_v1=0, sample_size_v2=0, ppl=1.75, wps=644.7, ups=0.52, wpb=1246.8, bsz=32, num_updates=43370, lr=5.27609e-06, gnorm=21.945, clip=100, loss_scale=16, train_wall=19, gb_free=11, wall=81534
2023-05-26 22:02:19 - progress_bar.py[line:272] - INFO: epoch 026:    155 / 1732 loss=2.072, loss_v1=0, loss_v2=0, nll_loss=0.836, ntokens=1151.6, nsentences=32, sample_size=1151.6, sample_size_v1=0, sample_size_v2=0, ppl=1.79, wps=597.6, ups=0.52, wpb=1151.6, bsz=32, num_updates=43380, lr=5.26995e-06, gnorm=23.903, clip=100, loss_scale=16, train_wall=19, gb_free=10.8, wall=81553
2023-05-26 22:02:37 - progress_bar.py[line:272] - INFO: epoch 026:    165 / 1732 loss=2.055, loss_v1=0, loss_v2=0, nll_loss=0.818, ntokens=1062.3, nsentences=32, sample_size=1062.3, sample_size_v1=0, sample_size_v2=0, ppl=1.76, wps=561.2, ups=0.53, wpb=1062.3, bsz=32, num_updates=43390, lr=5.2638e-06, gnorm=26.315, clip=100, loss_scale=16, train_wall=19, gb_free=11.3, wall=81572
2023-05-26 22:02:57 - progress_bar.py[line:272] - INFO: epoch 026:    175 / 1732 loss=2.076, loss_v1=0, loss_v2=0, nll_loss=0.841, ntokens=958.4, nsentences=32, sample_size=958.4, sample_size_v1=0, sample_size_v2=0, ppl=1.79, wps=503.1, ups=0.52, wpb=958.4, bsz=32, num_updates=43400, lr=5.25766e-06, gnorm=25.932, clip=100, loss_scale=16, train_wall=19, gb_free=10.7, wall=81591
2023-05-26 22:03:16 - progress_bar.py[line:272] - INFO: epoch 026:    185 / 1732 loss=2.027, loss_v1=0, loss_v2=0, nll_loss=0.787, ntokens=1173.4, nsentences=32, sample_size=1173.4, sample_size_v1=0, sample_size_v2=0, ppl=1.73, wps=612.8, ups=0.52, wpb=1173.4, bsz=32, num_updates=43410, lr=5.25152e-06, gnorm=20.74, clip=100, loss_scale=16, train_wall=19, gb_free=9.8, wall=81610
2023-05-26 22:03:35 - progress_bar.py[line:272] - INFO: epoch 026:    195 / 1732 loss=2.057, loss_v1=0, loss_v2=0, nll_loss=0.819, ntokens=1144.6, nsentences=32, sample_size=1144.6, sample_size_v1=0, sample_size_v2=0, ppl=1.76, wps=601, ups=0.53, wpb=1144.6, bsz=32, num_updates=43420, lr=5.24538e-06, gnorm=20.906, clip=100, loss_scale=16, train_wall=19, gb_free=10.6, wall=81629
2023-05-26 22:03:53 - progress_bar.py[line:272] - INFO: epoch 026:    205 / 1732 loss=2.085, loss_v1=0, loss_v2=0, nll_loss=0.852, ntokens=1021.8, nsentences=32, sample_size=1021.8, sample_size_v1=0, sample_size_v2=0, ppl=1.8, wps=547, ups=0.54, wpb=1021.8, bsz=32, num_updates=43430, lr=5.23924e-06, gnorm=22.701, clip=100, loss_scale=16, train_wall=19, gb_free=11.7, wall=81648
2023-05-26 22:04:12 - progress_bar.py[line:272] - INFO: epoch 026:    215 / 1732 loss=2.119, loss_v1=0, loss_v2=0, nll_loss=0.889, ntokens=1094.3, nsentences=32, sample_size=1094.3, sample_size_v1=0, sample_size_v2=0, ppl=1.85, wps=583.1, ups=0.53, wpb=1094.3, bsz=32, num_updates=43440, lr=5.23309e-06, gnorm=20.761, clip=100, loss_scale=16, train_wall=19, gb_free=11.5, wall=81667
2023-05-26 22:04:31 - progress_bar.py[line:272] - INFO: epoch 026:    225 / 1732 loss=2.103, loss_v1=0, loss_v2=0, nll_loss=0.873, ntokens=1095.2, nsentences=32, sample_size=1095.2, sample_size_v1=0, sample_size_v2=0, ppl=1.83, wps=584.3, ups=0.53, wpb=1095.2, bsz=32, num_updates=43450, lr=5.22695e-06, gnorm=19.101, clip=100, loss_scale=16, train_wall=19, gb_free=10.9, wall=81686
2023-05-26 22:04:50 - progress_bar.py[line:272] - INFO: epoch 026:    235 / 1732 loss=2.153, loss_v1=0, loss_v2=0, nll_loss=0.928, ntokens=1090, nsentences=32, sample_size=1090, sample_size_v1=0, sample_size_v2=0, ppl=1.9, wps=584.2, ups=0.54, wpb=1090, bsz=32, num_updates=43460, lr=5.22081e-06, gnorm=20.427, clip=100, loss_scale=16, train_wall=19, gb_free=11.2, wall=81704
2023-05-26 22:05:08 - progress_bar.py[line:272] - INFO: epoch 026:    245 / 1732 loss=2.131, loss_v1=0, loss_v2=0, nll_loss=0.902, ntokens=1178.2, nsentences=32, sample_size=1178.2, sample_size_v1=0, sample_size_v2=0, ppl=1.87, wps=625.7, ups=0.53, wpb=1178.2, bsz=32, num_updates=43470, lr=5.21467e-06, gnorm=19.897, clip=100, loss_scale=16, train_wall=19, gb_free=10.8, wall=81723
2023-05-26 22:05:27 - progress_bar.py[line:272] - INFO: epoch 026:    255 / 1732 loss=2.128, loss_v1=0, loss_v2=0, nll_loss=0.899, ntokens=1128.2, nsentences=32, sample_size=1128.2, sample_size_v1=0, sample_size_v2=0, ppl=1.86, wps=602.2, ups=0.53, wpb=1128.2, bsz=32, num_updates=43480, lr=5.20853e-06, gnorm=20.001, clip=100, loss_scale=16, train_wall=19, gb_free=11.8, wall=81742
2023-05-26 22:05:46 - progress_bar.py[line:272] - INFO: epoch 026:    265 / 1732 loss=2.113, loss_v1=0, loss_v2=0, nll_loss=0.882, ntokens=1148, nsentences=32, sample_size=1148, sample_size_v1=0, sample_size_v2=0, ppl=1.84, wps=611.3, ups=0.53, wpb=1148, bsz=32, num_updates=43490, lr=5.20238e-06, gnorm=19.244, clip=100, loss_scale=16, train_wall=19, gb_free=11.3, wall=81761
2023-05-26 22:06:05 - progress_bar.py[line:272] - INFO: epoch 026:    275 / 1732 loss=2.12, loss_v1=0, loss_v2=0, nll_loss=0.89, ntokens=1140.3, nsentences=32, sample_size=1140.3, sample_size_v1=0, sample_size_v2=0, ppl=1.85, wps=604.1, ups=0.53, wpb=1140.3, bsz=32, num_updates=43500, lr=5.19624e-06, gnorm=20.084, clip=100, loss_scale=16, train_wall=19, gb_free=11.4, wall=81779
2023-05-26 22:06:24 - progress_bar.py[line:272] - INFO: epoch 026:    285 / 1732 loss=2.134, loss_v1=0, loss_v2=0, nll_loss=0.907, ntokens=1154.4, nsentences=32, sample_size=1154.4, sample_size_v1=0, sample_size_v2=0, ppl=1.87, wps=611.7, ups=0.53, wpb=1154.4, bsz=32, num_updates=43510, lr=5.1901e-06, gnorm=19.703, clip=100, loss_scale=16, train_wall=19, gb_free=10.3, wall=81798
2023-05-26 22:06:42 - progress_bar.py[line:272] - INFO: epoch 026:    295 / 1732 loss=2.114, loss_v1=0, loss_v2=0, nll_loss=0.884, ntokens=1115.8, nsentences=32, sample_size=1115.8, sample_size_v1=0, sample_size_v2=0, ppl=1.85, wps=595.5, ups=0.53, wpb=1115.8, bsz=32, num_updates=43520, lr=5.18396e-06, gnorm=20.238, clip=100, loss_scale=16, train_wall=19, gb_free=11.4, wall=81817
2023-05-26 22:07:01 - progress_bar.py[line:272] - INFO: epoch 026:    305 / 1732 loss=2.111, loss_v1=0, loss_v2=0, nll_loss=0.88, ntokens=1102.2, nsentences=32, sample_size=1102.2, sample_size_v1=0, sample_size_v2=0, ppl=1.84, wps=588.1, ups=0.53, wpb=1102.2, bsz=32, num_updates=43530, lr=5.17781e-06, gnorm=21.537, clip=100, loss_scale=16, train_wall=19, gb_free=11, wall=81836
2023-05-26 22:07:20 - progress_bar.py[line:272] - INFO: epoch 026:    315 / 1732 loss=2.13, loss_v1=0, loss_v2=0, nll_loss=0.902, ntokens=1020.3, nsentences=32, sample_size=1020.3, sample_size_v1=0, sample_size_v2=0, ppl=1.87, wps=549.9, ups=0.54, wpb=1020.3, bsz=32, num_updates=43540, lr=5.17167e-06, gnorm=22.7, clip=100, loss_scale=16, train_wall=19, gb_free=11.5, wall=81854
2023-05-26 22:07:38 - progress_bar.py[line:272] - INFO: epoch 026:    325 / 1732 loss=2.145, loss_v1=0, loss_v2=0, nll_loss=0.919, ntokens=1011.9, nsentences=32, sample_size=1011.9, sample_size_v1=0, sample_size_v2=0, ppl=1.89, wps=543.6, ups=0.54, wpb=1011.9, bsz=32, num_updates=43550, lr=5.16553e-06, gnorm=22.541, clip=100, loss_scale=32, train_wall=19, gb_free=11.7, wall=81873
2023-05-26 22:07:57 - progress_bar.py[line:272] - INFO: epoch 026:    335 / 1732 loss=2.156, loss_v1=0, loss_v2=0, nll_loss=0.932, ntokens=1020.9, nsentences=32, sample_size=1020.9, sample_size_v1=0, sample_size_v2=0, ppl=1.91, wps=549.1, ups=0.54, wpb=1020.9, bsz=32, num_updates=43560, lr=5.15939e-06, gnorm=26.65, clip=100, loss_scale=32, train_wall=19, gb_free=11.8, wall=81892
2023-05-26 22:08:14 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2023-05-26 22:08:17 - progress_bar.py[line:272] - INFO: epoch 026:    346 / 1732 loss=2.083, loss_v1=0, loss_v2=0, nll_loss=0.849, ntokens=907, nsentences=32, sample_size=907, sample_size_v1=0, sample_size_v2=0, ppl=1.8, wps=446.6, ups=0.49, wpb=907, bsz=32, num_updates=43570, lr=5.15325e-06, gnorm=22.92, clip=100, loss_scale=16, train_wall=20, gb_free=11.3, wall=81912
2023-05-26 22:08:36 - progress_bar.py[line:272] - INFO: epoch 026:    356 / 1732 loss=2.126, loss_v1=0, loss_v2=0, nll_loss=0.897, ntokens=955.2, nsentences=32, sample_size=955.2, sample_size_v1=0, sample_size_v2=0, ppl=1.86, wps=515.9, ups=0.54, wpb=955.2, bsz=32, num_updates=43580, lr=5.1471e-06, gnorm=23.787, clip=100, loss_scale=16, train_wall=18, gb_free=11.4, wall=81930
2023-05-26 22:08:54 - progress_bar.py[line:272] - INFO: epoch 026:    366 / 1732 loss=2.14, loss_v1=0, loss_v2=0, nll_loss=0.914, ntokens=951.9, nsentences=32, sample_size=951.9, sample_size_v1=0, sample_size_v2=0, ppl=1.88, wps=513.4, ups=0.54, wpb=951.9, bsz=32, num_updates=43590, lr=5.14096e-06, gnorm=24.064, clip=100, loss_scale=16, train_wall=19, gb_free=11.5, wall=81949
2023-05-26 22:09:13 - progress_bar.py[line:272] - INFO: epoch 026:    376 / 1732 loss=2.138, loss_v1=0, loss_v2=0, nll_loss=0.912, ntokens=1015.4, nsentences=32, sample_size=1015.4, sample_size_v1=0, sample_size_v2=0, ppl=1.88, wps=546.7, ups=0.54, wpb=1015.4, bsz=32, num_updates=43600, lr=5.13482e-06, gnorm=20.873, clip=100, loss_scale=16, train_wall=19, gb_free=11.4, wall=81968
2023-05-26 22:09:32 - progress_bar.py[line:272] - INFO: epoch 026:    386 / 1732 loss=2.145, loss_v1=0, loss_v2=0, nll_loss=0.92, ntokens=1063.1, nsentences=32, sample_size=1063.1, sample_size_v1=0, sample_size_v2=0, ppl=1.89, wps=572, ups=0.54, wpb=1063.1, bsz=32, num_updates=43610, lr=5.12868e-06, gnorm=21.655, clip=100, loss_scale=16, train_wall=19, gb_free=11.4, wall=81986
2023-05-26 22:09:50 - progress_bar.py[line:272] - INFO: epoch 026:    396 / 1732 loss=2.133, loss_v1=0, loss_v2=0, nll_loss=0.905, ntokens=950.2, nsentences=32, sample_size=950.2, sample_size_v1=0, sample_size_v2=0, ppl=1.87, wps=513.7, ups=0.54, wpb=950.2, bsz=32, num_updates=43620, lr=5.12254e-06, gnorm=25.686, clip=100, loss_scale=16, train_wall=18, gb_free=11.3, wall=82005
2023-05-26 22:10:09 - progress_bar.py[line:272] - INFO: epoch 026:    406 / 1732 loss=2.112, loss_v1=0, loss_v2=0, nll_loss=0.881, ntokens=1066.6, nsentences=32, sample_size=1066.6, sample_size_v1=0, sample_size_v2=0, ppl=1.84, wps=570, ups=0.53, wpb=1066.6, bsz=32, num_updates=43630, lr=5.11639e-06, gnorm=21.32, clip=100, loss_scale=16, train_wall=19, gb_free=11.2, wall=82023
2023-05-26 22:10:27 - progress_bar.py[line:272] - INFO: epoch 026:    416 / 1732 loss=2.113, loss_v1=0, loss_v2=0, nll_loss=0.882, ntokens=1055.1, nsentences=32, sample_size=1055.1, sample_size_v1=0, sample_size_v2=0, ppl=1.84, wps=564.7, ups=0.54, wpb=1055.1, bsz=32, num_updates=43640, lr=5.11025e-06, gnorm=22.05, clip=100, loss_scale=16, train_wall=19, gb_free=11.5, wall=82042
2023-05-26 22:10:46 - progress_bar.py[line:272] - INFO: epoch 026:    426 / 1732 loss=2.093, loss_v1=0, loss_v2=0, nll_loss=0.861, ntokens=988.1, nsentences=32, sample_size=988.1, sample_size_v1=0, sample_size_v2=0, ppl=1.82, wps=531, ups=0.54, wpb=988.1, bsz=32, num_updates=43650, lr=5.10411e-06, gnorm=23.218, clip=100, loss_scale=16, train_wall=19, gb_free=11, wall=82061
2023-05-26 22:11:05 - progress_bar.py[line:272] - INFO: epoch 026:    436 / 1732 loss=2.128, loss_v1=0, loss_v2=0, nll_loss=0.899, ntokens=1044.5, nsentences=32, sample_size=1044.5, sample_size_v1=0, sample_size_v2=0, ppl=1.87, wps=561.1, ups=0.54, wpb=1044.5, bsz=32, num_updates=43660, lr=5.09797e-06, gnorm=21.714, clip=100, loss_scale=16, train_wall=19, gb_free=11.1, wall=82079
2023-05-26 22:11:23 - progress_bar.py[line:272] - INFO: epoch 026:    446 / 1732 loss=2.128, loss_v1=0, loss_v2=0, nll_loss=0.898, ntokens=952.9, nsentences=32, sample_size=952.9, sample_size_v1=0, sample_size_v2=0, ppl=1.86, wps=512.5, ups=0.54, wpb=952.9, bsz=32, num_updates=43670, lr=5.09182e-06, gnorm=24.537, clip=100, loss_scale=16, train_wall=19, gb_free=10.9, wall=82098
2023-05-26 22:11:42 - progress_bar.py[line:272] - INFO: epoch 026:    456 / 1732 loss=2.133, loss_v1=0, loss_v2=0, nll_loss=0.905, ntokens=925.5, nsentences=32, sample_size=925.5, sample_size_v1=0, sample_size_v2=0, ppl=1.87, wps=500.8, ups=0.54, wpb=925.5, bsz=32, num_updates=43680, lr=5.08568e-06, gnorm=23.637, clip=100, loss_scale=16, train_wall=18, gb_free=11.6, wall=82116
2023-05-26 22:12:00 - progress_bar.py[line:272] - INFO: epoch 026:    466 / 1732 loss=2.152, loss_v1=0, loss_v2=0, nll_loss=0.926, ntokens=1063.6, nsentences=32, sample_size=1063.6, sample_size_v1=0, sample_size_v2=0, ppl=1.9, wps=566.8, ups=0.53, wpb=1063.6, bsz=32, num_updates=43690, lr=5.07954e-06, gnorm=21.83, clip=100, loss_scale=16, train_wall=19, gb_free=11.4, wall=82135
2023-05-26 22:12:19 - progress_bar.py[line:272] - INFO: epoch 026:    476 / 1732 loss=2.172, loss_v1=0, loss_v2=0, nll_loss=0.948, ntokens=1057.9, nsentences=32, sample_size=1057.9, sample_size_v1=0, sample_size_v2=0, ppl=1.93, wps=563.9, ups=0.53, wpb=1057.9, bsz=32, num_updates=43700, lr=5.0734e-06, gnorm=22.417, clip=100, loss_scale=16, train_wall=19, gb_free=11.3, wall=82154
2023-05-26 22:12:38 - progress_bar.py[line:272] - INFO: epoch 026:    486 / 1732 loss=2.119, loss_v1=0, loss_v2=0, nll_loss=0.889, ntokens=966.1, nsentences=32, sample_size=966.1, sample_size_v1=0, sample_size_v2=0, ppl=1.85, wps=520.2, ups=0.54, wpb=966.1, bsz=32, num_updates=43710, lr=5.06726e-06, gnorm=20.845, clip=100, loss_scale=16, train_wall=19, gb_free=11.3, wall=82172
2023-05-26 22:12:56 - progress_bar.py[line:272] - INFO: epoch 026:    496 / 1732 loss=2.11, loss_v1=0, loss_v2=0, nll_loss=0.877, ntokens=932.2, nsentences=32, sample_size=932.2, sample_size_v1=0, sample_size_v2=0, ppl=1.84, wps=504.2, ups=0.54, wpb=932.2, bsz=32, num_updates=43720, lr=5.06111e-06, gnorm=23.675, clip=100, loss_scale=16, train_wall=18, gb_free=11.7, wall=82191
2023-05-26 22:13:15 - progress_bar.py[line:272] - INFO: epoch 026:    506 / 1732 loss=2.156, loss_v1=0, loss_v2=0, nll_loss=0.93, ntokens=994.9, nsentences=32, sample_size=994.9, sample_size_v1=0, sample_size_v2=0, ppl=1.91, wps=538.3, ups=0.54, wpb=994.9, bsz=32, num_updates=43730, lr=5.05497e-06, gnorm=22.923, clip=100, loss_scale=16, train_wall=18, gb_free=11.5, wall=82209
2023-05-26 22:13:33 - progress_bar.py[line:272] - INFO: epoch 026:    516 / 1732 loss=2.143, loss_v1=0, loss_v2=0, nll_loss=0.915, ntokens=1062.8, nsentences=32, sample_size=1062.8, sample_size_v1=0, sample_size_v2=0, ppl=1.89, wps=570.9, ups=0.54, wpb=1062.8, bsz=32, num_updates=43740, lr=5.04883e-06, gnorm=21.13, clip=100, loss_scale=16, train_wall=19, gb_free=11.6, wall=82228
2023-05-26 22:13:52 - progress_bar.py[line:272] - INFO: epoch 026:    526 / 1732 loss=2.133, loss_v1=0, loss_v2=0, nll_loss=0.905, ntokens=946.7, nsentences=32, sample_size=946.7, sample_size_v1=0, sample_size_v2=0, ppl=1.87, wps=511.5, ups=0.54, wpb=946.7, bsz=32, num_updates=43750, lr=5.04269e-06, gnorm=23.507, clip=100, loss_scale=16, train_wall=18, gb_free=11.6, wall=82247
2023-05-26 22:14:10 - progress_bar.py[line:272] - INFO: epoch 026:    536 / 1732 loss=2.135, loss_v1=0, loss_v2=0, nll_loss=0.906, ntokens=955.9, nsentences=32, sample_size=955.9, sample_size_v1=0, sample_size_v2=0, ppl=1.87, wps=516.9, ups=0.54, wpb=955.9, bsz=32, num_updates=43760, lr=5.03655e-06, gnorm=24.733, clip=100, loss_scale=16, train_wall=18, gb_free=11.9, wall=82265
2023-05-26 22:14:29 - progress_bar.py[line:272] - INFO: epoch 026:    546 / 1732 loss=2.157, loss_v1=0, loss_v2=0, nll_loss=0.932, ntokens=1026.2, nsentences=32, sample_size=1026.2, sample_size_v1=0, sample_size_v2=0, ppl=1.91, wps=551.7, ups=0.54, wpb=1026.2, bsz=32, num_updates=43770, lr=5.0304e-06, gnorm=21.686, clip=100, loss_scale=16, train_wall=19, gb_free=11.3, wall=82284
2023-05-26 22:14:48 - progress_bar.py[line:272] - INFO: epoch 026:    556 / 1732 loss=2.176, loss_v1=0, loss_v2=0, nll_loss=0.953, ntokens=1007.9, nsentences=32, sample_size=1007.9, sample_size_v1=0, sample_size_v2=0, ppl=1.94, wps=543, ups=0.54, wpb=1007.9, bsz=32, num_updates=43780, lr=5.02426e-06, gnorm=23.012, clip=100, loss_scale=16, train_wall=19, gb_free=11.1, wall=82302
2023-05-26 22:15:06 - progress_bar.py[line:272] - INFO: epoch 026:    566 / 1732 loss=2.173, loss_v1=0, loss_v2=0, nll_loss=0.95, ntokens=1034.4, nsentences=32, sample_size=1034.4, sample_size_v1=0, sample_size_v2=0, ppl=1.93, wps=555.1, ups=0.54, wpb=1034.4, bsz=32, num_updates=43790, lr=5.01812e-06, gnorm=22.343, clip=100, loss_scale=16, train_wall=19, gb_free=10.6, wall=82321
2023-05-26 22:15:25 - progress_bar.py[line:272] - INFO: epoch 026:    576 / 1732 loss=2.152, loss_v1=0, loss_v2=0, nll_loss=0.925, ntokens=1004.8, nsentences=32, sample_size=1004.8, sample_size_v1=0, sample_size_v2=0, ppl=1.9, wps=537, ups=0.53, wpb=1004.8, bsz=32, num_updates=43800, lr=5.01198e-06, gnorm=23.496, clip=100, loss_scale=16, train_wall=19, gb_free=11.3, wall=82340
2023-05-26 22:15:44 - progress_bar.py[line:272] - INFO: epoch 026:    586 / 1732 loss=2.163, loss_v1=0, loss_v2=0, nll_loss=0.937, ntokens=978.1, nsentences=32, sample_size=978.1, sample_size_v1=0, sample_size_v2=0, ppl=1.92, wps=522.4, ups=0.53, wpb=978.1, bsz=32, num_updates=43810, lr=5.00584e-06, gnorm=23.482, clip=100, loss_scale=16, train_wall=19, gb_free=11.3, wall=82358
2023-05-26 22:16:02 - progress_bar.py[line:272] - INFO: epoch 026:    596 / 1732 loss=2.112, loss_v1=0, loss_v2=0, nll_loss=0.88, ntokens=953.1, nsentences=32, sample_size=953.1, sample_size_v1=0, sample_size_v2=0, ppl=1.84, wps=510.7, ups=0.54, wpb=953.1, bsz=32, num_updates=43820, lr=4.99969e-06, gnorm=23.518, clip=100, loss_scale=16, train_wall=19, gb_free=11.4, wall=82377
2023-05-26 22:16:21 - progress_bar.py[line:272] - INFO: epoch 026:    606 / 1732 loss=2.126, loss_v1=0, loss_v2=0, nll_loss=0.897, ntokens=871.6, nsentences=32, sample_size=871.6, sample_size_v1=0, sample_size_v2=0, ppl=1.86, wps=473.9, ups=0.54, wpb=871.6, bsz=32, num_updates=43830, lr=4.99355e-06, gnorm=22.923, clip=100, loss_scale=16, train_wall=18, gb_free=11.8, wall=82395
2023-05-26 22:16:39 - progress_bar.py[line:272] - INFO: epoch 026:    616 / 1732 loss=2.146, loss_v1=0, loss_v2=0, nll_loss=0.919, ntokens=889.6, nsentences=32, sample_size=889.6, sample_size_v1=0, sample_size_v2=0, ppl=1.89, wps=481.6, ups=0.54, wpb=889.6, bsz=32, num_updates=43840, lr=4.98741e-06, gnorm=24.948, clip=100, loss_scale=16, train_wall=18, gb_free=12.1, wall=82414
2023-05-26 22:16:58 - progress_bar.py[line:272] - INFO: epoch 026:    626 / 1732 loss=2.13, loss_v1=0, loss_v2=0, nll_loss=0.901, ntokens=922.9, nsentences=32, sample_size=922.9, sample_size_v1=0, sample_size_v2=0, ppl=1.87, wps=499.3, ups=0.54, wpb=922.9, bsz=32, num_updates=43850, lr=4.98127e-06, gnorm=22.388, clip=100, loss_scale=16, train_wall=18, gb_free=11.6, wall=82432
2023-05-26 22:17:16 - progress_bar.py[line:272] - INFO: epoch 026:    636 / 1732 loss=2.147, loss_v1=0, loss_v2=0, nll_loss=0.92, ntokens=899.7, nsentences=32, sample_size=899.7, sample_size_v1=0, sample_size_v2=0, ppl=1.89, wps=488.5, ups=0.54, wpb=899.7, bsz=32, num_updates=43860, lr=4.97512e-06, gnorm=23.722, clip=100, loss_scale=16, train_wall=18, gb_free=11.4, wall=82451
2023-05-26 22:17:35 - progress_bar.py[line:272] - INFO: epoch 026:    646 / 1732 loss=2.14, loss_v1=0, loss_v2=0, nll_loss=0.912, ntokens=1003.9, nsentences=32, sample_size=1003.9, sample_size_v1=0, sample_size_v2=0, ppl=1.88, wps=543, ups=0.54, wpb=1003.9, bsz=32, num_updates=43870, lr=4.96898e-06, gnorm=22.096, clip=100, loss_scale=16, train_wall=18, gb_free=12, wall=82469
2023-05-26 22:17:53 - progress_bar.py[line:272] - INFO: epoch 026:    656 / 1732 loss=2.12, loss_v1=0, loss_v2=0, nll_loss=0.89, ntokens=882.2, nsentences=32, sample_size=882.2, sample_size_v1=0, sample_size_v2=0, ppl=1.85, wps=481.2, ups=0.55, wpb=882.2, bsz=32, num_updates=43880, lr=4.96284e-06, gnorm=25.261, clip=100, loss_scale=16, train_wall=18, gb_free=11.9, wall=82488
2023-05-26 22:18:11 - progress_bar.py[line:272] - INFO: epoch 026:    666 / 1732 loss=2.129, loss_v1=0, loss_v2=0, nll_loss=0.9, ntokens=902.8, nsentences=32, sample_size=902.8, sample_size_v1=0, sample_size_v2=0, ppl=1.87, wps=490.8, ups=0.54, wpb=902.8, bsz=32, num_updates=43890, lr=4.9567e-06, gnorm=23.711, clip=100, loss_scale=16, train_wall=18, gb_free=11.2, wall=82506
2023-05-26 22:18:30 - progress_bar.py[line:272] - INFO: epoch 026:    676 / 1732 loss=2.157, loss_v1=0, loss_v2=0, nll_loss=0.932, ntokens=976.1, nsentences=32, sample_size=976.1, sample_size_v1=0, sample_size_v2=0, ppl=1.91, wps=526.3, ups=0.54, wpb=976.1, bsz=32, num_updates=43900, lr=4.95056e-06, gnorm=21.885, clip=100, loss_scale=16, train_wall=19, gb_free=11.4, wall=82525
2023-05-26 22:18:48 - progress_bar.py[line:272] - INFO: epoch 026:    686 / 1732 loss=2.138, loss_v1=0, loss_v2=0, nll_loss=0.911, ntokens=963.6, nsentences=32, sample_size=963.6, sample_size_v1=0, sample_size_v2=0, ppl=1.88, wps=521.5, ups=0.54, wpb=963.6, bsz=32, num_updates=43910, lr=4.94441e-06, gnorm=22.875, clip=100, loss_scale=16, train_wall=18, gb_free=11.2, wall=82543
2023-05-26 22:19:07 - progress_bar.py[line:272] - INFO: epoch 026:    696 / 1732 loss=2.148, loss_v1=0, loss_v2=0, nll_loss=0.921, ntokens=982.5, nsentences=32, sample_size=982.5, sample_size_v1=0, sample_size_v2=0, ppl=1.89, wps=527.6, ups=0.54, wpb=982.5, bsz=32, num_updates=43920, lr=4.93827e-06, gnorm=23.367, clip=100, loss_scale=16, train_wall=19, gb_free=11.7, wall=82562
2023-05-26 22:19:25 - progress_bar.py[line:272] - INFO: epoch 026:    706 / 1732 loss=2.112, loss_v1=0, loss_v2=0, nll_loss=0.88, ntokens=918.4, nsentences=32, sample_size=918.4, sample_size_v1=0, sample_size_v2=0, ppl=1.84, wps=497.1, ups=0.54, wpb=918.4, bsz=32, num_updates=43930, lr=4.93213e-06, gnorm=22.641, clip=100, loss_scale=16, train_wall=18, gb_free=11.8, wall=82580
2023-05-26 22:19:44 - progress_bar.py[line:272] - INFO: epoch 026:    716 / 1732 loss=2.113, loss_v1=0, loss_v2=0, nll_loss=0.882, ntokens=886.1, nsentences=32, sample_size=886.1, sample_size_v1=0, sample_size_v2=0, ppl=1.84, wps=480.9, ups=0.54, wpb=886.1, bsz=32, num_updates=43940, lr=4.92599e-06, gnorm=23.162, clip=100, loss_scale=16, train_wall=18, gb_free=11.7, wall=82599
2023-05-26 22:20:02 - progress_bar.py[line:272] - INFO: epoch 026:    726 / 1732 loss=2.085, loss_v1=0, loss_v2=0, nll_loss=0.851, ntokens=913.6, nsentences=32, sample_size=913.6, sample_size_v1=0, sample_size_v2=0, ppl=1.8, wps=494.2, ups=0.54, wpb=913.6, bsz=32, num_updates=43950, lr=4.91985e-06, gnorm=23.231, clip=100, loss_scale=16, train_wall=18, gb_free=11.1, wall=82617
2023-05-26 22:20:21 - progress_bar.py[line:272] - INFO: epoch 026:    736 / 1732 loss=2.121, loss_v1=0, loss_v2=0, nll_loss=0.891, ntokens=979.7, nsentences=32, sample_size=979.7, sample_size_v1=0, sample_size_v2=0, ppl=1.86, wps=530.1, ups=0.54, wpb=979.7, bsz=32, num_updates=43960, lr=4.9137e-06, gnorm=21.778, clip=100, loss_scale=16, train_wall=18, gb_free=11.8, wall=82636
2023-05-26 22:20:39 - progress_bar.py[line:272] - INFO: epoch 026:    746 / 1732 loss=2.103, loss_v1=0, loss_v2=0, nll_loss=0.87, ntokens=974.7, nsentences=32, sample_size=974.7, sample_size_v1=0, sample_size_v2=0, ppl=1.83, wps=524.3, ups=0.54, wpb=974.7, bsz=32, num_updates=43970, lr=4.90756e-06, gnorm=21.21, clip=100, loss_scale=16, train_wall=19, gb_free=11.5, wall=82654
2023-05-26 22:20:58 - progress_bar.py[line:272] - INFO: epoch 026:    756 / 1732 loss=2.11, loss_v1=0, loss_v2=0, nll_loss=0.879, ntokens=977.2, nsentences=32, sample_size=977.2, sample_size_v1=0, sample_size_v2=0, ppl=1.84, wps=527.4, ups=0.54, wpb=977.2, bsz=32, num_updates=43980, lr=4.90142e-06, gnorm=20.138, clip=100, loss_scale=16, train_wall=18, gb_free=11.2, wall=82673
2023-05-26 22:21:17 - progress_bar.py[line:272] - INFO: epoch 026:    766 / 1732 loss=2.124, loss_v1=0, loss_v2=0, nll_loss=0.895, ntokens=933.3, nsentences=32, sample_size=933.3, sample_size_v1=0, sample_size_v2=0, ppl=1.86, wps=504, ups=0.54, wpb=933.3, bsz=32, num_updates=43990, lr=4.89528e-06, gnorm=22.637, clip=100, loss_scale=16, train_wall=18, gb_free=11.6, wall=82691
2023-05-26 22:21:35 - progress_bar.py[line:272] - INFO: epoch 026:    776 / 1732 loss=2.119, loss_v1=0, loss_v2=0, nll_loss=0.89, ntokens=1027.3, nsentences=32, sample_size=1027.3, sample_size_v1=0, sample_size_v2=0, ppl=1.85, wps=553.5, ups=0.54, wpb=1027.3, bsz=32, num_updates=44000, lr=4.88913e-06, gnorm=22.968, clip=100, loss_scale=16, train_wall=19, gb_free=11.3, wall=82710
2023-05-26 22:21:54 - progress_bar.py[line:272] - INFO: epoch 026:    786 / 1732 loss=2.141, loss_v1=0, loss_v2=0, nll_loss=0.914, ntokens=1013.1, nsentences=32, sample_size=1013.1, sample_size_v1=0, sample_size_v2=0, ppl=1.88, wps=547.6, ups=0.54, wpb=1013.1, bsz=32, num_updates=44010, lr=4.88299e-06, gnorm=23.163, clip=100, loss_scale=16, train_wall=18, gb_free=11.9, wall=82728
2023-05-26 22:22:12 - progress_bar.py[line:272] - INFO: epoch 026:    796 / 1732 loss=2.142, loss_v1=0, loss_v2=0, nll_loss=0.916, ntokens=1030.3, nsentences=32, sample_size=1030.3, sample_size_v1=0, sample_size_v2=0, ppl=1.89, wps=556.5, ups=0.54, wpb=1030.3, bsz=32, num_updates=44020, lr=4.87685e-06, gnorm=22.693, clip=100, loss_scale=16, train_wall=18, gb_free=11.2, wall=82747
2023-05-26 22:22:31 - progress_bar.py[line:272] - INFO: epoch 026:    806 / 1732 loss=2.135, loss_v1=0, loss_v2=0, nll_loss=0.905, ntokens=912.3, nsentences=32, sample_size=912.3, sample_size_v1=0, sample_size_v2=0, ppl=1.87, wps=494.6, ups=0.54, wpb=912.3, bsz=32, num_updates=44030, lr=4.87071e-06, gnorm=24.443, clip=100, loss_scale=16, train_wall=18, gb_free=11.8, wall=82765
2023-05-26 22:22:49 - progress_bar.py[line:272] - INFO: epoch 026:    816 / 1732 loss=2.142, loss_v1=0, loss_v2=0, nll_loss=0.915, ntokens=920, nsentences=32, sample_size=920, sample_size_v1=0, sample_size_v2=0, ppl=1.89, wps=495.7, ups=0.54, wpb=920, bsz=32, num_updates=44040, lr=4.86457e-06, gnorm=25.979, clip=100, loss_scale=16, train_wall=19, gb_free=11, wall=82784
2023-05-26 22:23:08 - progress_bar.py[line:272] - INFO: epoch 026:    826 / 1732 loss=2.127, loss_v1=0, loss_v2=0, nll_loss=0.897, ntokens=944.4, nsentences=32, sample_size=944.4, sample_size_v1=0, sample_size_v2=0, ppl=1.86, wps=507.2, ups=0.54, wpb=944.4, bsz=32, num_updates=44050, lr=4.85842e-06, gnorm=22.717, clip=100, loss_scale=16, train_wall=19, gb_free=11.6, wall=82802
2023-05-26 22:23:26 - progress_bar.py[line:272] - INFO: epoch 026:    836 / 1732 loss=2.134, loss_v1=0, loss_v2=0, nll_loss=0.906, ntokens=894, nsentences=32, sample_size=894, sample_size_v1=0, sample_size_v2=0, ppl=1.87, wps=487.1, ups=0.54, wpb=894, bsz=32, num_updates=44060, lr=4.85228e-06, gnorm=24.478, clip=100, loss_scale=16, train_wall=18, gb_free=11.8, wall=82821
2023-05-26 22:23:45 - progress_bar.py[line:272] - INFO: epoch 026:    846 / 1732 loss=2.122, loss_v1=0, loss_v2=0, nll_loss=0.892, ntokens=995.1, nsentences=32, sample_size=995.1, sample_size_v1=0, sample_size_v2=0, ppl=1.86, wps=539.5, ups=0.54, wpb=995.1, bsz=32, num_updates=44070, lr=4.84614e-06, gnorm=21.906, clip=100, loss_scale=16, train_wall=18, gb_free=11.6, wall=82839
2023-05-26 22:24:03 - progress_bar.py[line:272] - INFO: epoch 026:    856 / 1732 loss=2.114, loss_v1=0, loss_v2=0, nll_loss=0.883, ntokens=944.9, nsentences=32, sample_size=944.9, sample_size_v1=0, sample_size_v2=0, ppl=1.84, wps=510.2, ups=0.54, wpb=944.9, bsz=32, num_updates=44080, lr=4.84e-06, gnorm=23.627, clip=100, loss_scale=32, train_wall=18, gb_free=11.6, wall=82858
2023-05-26 22:24:22 - progress_bar.py[line:272] - INFO: epoch 026:    866 / 1732 loss=2.142, loss_v1=0, loss_v2=0, nll_loss=0.916, ntokens=954.3, nsentences=32, sample_size=954.3, sample_size_v1=0, sample_size_v2=0, ppl=1.89, wps=514.9, ups=0.54, wpb=954.3, bsz=32, num_updates=44090, lr=4.83386e-06, gnorm=23.409, clip=100, loss_scale=32, train_wall=19, gb_free=11.3, wall=82876
2023-05-26 22:24:40 - progress_bar.py[line:272] - INFO: epoch 026:    876 / 1732 loss=2.09, loss_v1=0, loss_v2=0, nll_loss=0.857, ntokens=1023, nsentences=32, sample_size=1023, sample_size_v1=0, sample_size_v2=0, ppl=1.81, wps=550.6, ups=0.54, wpb=1023, bsz=32, num_updates=44100, lr=4.82771e-06, gnorm=21.503, clip=100, loss_scale=32, train_wall=19, gb_free=11.4, wall=82895
2023-05-26 22:24:59 - progress_bar.py[line:272] - INFO: epoch 026:    886 / 1732 loss=2.07, loss_v1=0, loss_v2=0, nll_loss=0.835, ntokens=963.8, nsentences=32, sample_size=963.8, sample_size_v1=0, sample_size_v2=0, ppl=1.78, wps=518, ups=0.54, wpb=963.8, bsz=32, num_updates=44110, lr=4.82157e-06, gnorm=22.996, clip=100, loss_scale=32, train_wall=19, gb_free=11, wall=82913
2023-05-26 22:25:17 - progress_bar.py[line:272] - INFO: epoch 026:    896 / 1732 loss=2.083, loss_v1=0, loss_v2=0, nll_loss=0.85, ntokens=1021.4, nsentences=32, sample_size=1021.4, sample_size_v1=0, sample_size_v2=0, ppl=1.8, wps=550.3, ups=0.54, wpb=1021.4, bsz=32, num_updates=44120, lr=4.81543e-06, gnorm=22.449, clip=100, loss_scale=32, train_wall=19, gb_free=11.5, wall=82932
2023-05-26 22:25:36 - progress_bar.py[line:272] - INFO: epoch 026:    906 / 1732 loss=2.095, loss_v1=0, loss_v2=0, nll_loss=0.863, ntokens=1030.5, nsentences=32, sample_size=1030.5, sample_size_v1=0, sample_size_v2=0, ppl=1.82, wps=553.5, ups=0.54, wpb=1030.5, bsz=32, num_updates=44130, lr=4.80929e-06, gnorm=22.463, clip=100, loss_scale=32, train_wall=19, gb_free=10.6, wall=82951
2023-05-26 22:25:54 - progress_bar.py[line:272] - INFO: epoch 026:    916 / 1732 loss=2.144, loss_v1=0, loss_v2=0, nll_loss=0.917, ntokens=932.7, nsentences=32, sample_size=932.7, sample_size_v1=0, sample_size_v2=0, ppl=1.89, wps=504.5, ups=0.54, wpb=932.7, bsz=32, num_updates=44140, lr=4.80314e-06, gnorm=24.336, clip=100, loss_scale=32, train_wall=18, gb_free=11.3, wall=82969
2023-05-26 22:26:13 - progress_bar.py[line:272] - INFO: epoch 026:    926 / 1732 loss=2.11, loss_v1=0, loss_v2=0, nll_loss=0.878, ntokens=1024.6, nsentences=32, sample_size=1024.6, sample_size_v1=0, sample_size_v2=0, ppl=1.84, wps=548.7, ups=0.54, wpb=1024.6, bsz=32, num_updates=44150, lr=4.797e-06, gnorm=22.847, clip=100, loss_scale=32, train_wall=19, gb_free=11.3, wall=82988
2023-05-26 22:26:32 - progress_bar.py[line:272] - INFO: epoch 026:    936 / 1732 loss=2.121, loss_v1=0, loss_v2=0, nll_loss=0.891, ntokens=1056.9, nsentences=32, sample_size=1056.9, sample_size_v1=0, sample_size_v2=0, ppl=1.85, wps=564.2, ups=0.53, wpb=1056.9, bsz=32, num_updates=44160, lr=4.79086e-06, gnorm=23.105, clip=100, loss_scale=32, train_wall=19, gb_free=11.5, wall=83007
2023-05-26 22:26:51 - progress_bar.py[line:272] - INFO: epoch 026:    946 / 1732 loss=2.152, loss_v1=0, loss_v2=0, nll_loss=0.926, ntokens=1053.9, nsentences=32, sample_size=1053.9, sample_size_v1=0, sample_size_v2=0, ppl=1.9, wps=559.1, ups=0.53, wpb=1053.9, bsz=32, num_updates=44170, lr=4.78472e-06, gnorm=23.561, clip=100, loss_scale=32, train_wall=19, gb_free=11.2, wall=83025
2023-05-26 22:27:09 - progress_bar.py[line:272] - INFO: epoch 026:    956 / 1732 loss=2.127, loss_v1=0, loss_v2=0, nll_loss=0.897, ntokens=1038.8, nsentences=32, sample_size=1038.8, sample_size_v1=0, sample_size_v2=0, ppl=1.86, wps=555.4, ups=0.53, wpb=1038.8, bsz=32, num_updates=44180, lr=4.77858e-06, gnorm=21.373, clip=100, loss_scale=32, train_wall=19, gb_free=11.2, wall=83044
2023-05-26 22:27:28 - progress_bar.py[line:272] - INFO: epoch 026:    966 / 1732 loss=2.145, loss_v1=0, loss_v2=0, nll_loss=0.918, ntokens=1045.2, nsentences=32, sample_size=1045.2, sample_size_v1=0, sample_size_v2=0, ppl=1.89, wps=556.3, ups=0.53, wpb=1045.2, bsz=32, num_updates=44190, lr=4.77243e-06, gnorm=22.755, clip=100, loss_scale=32, train_wall=19, gb_free=11.5, wall=83063
2023-05-26 22:27:47 - progress_bar.py[line:272] - INFO: epoch 026:    976 / 1732 loss=2.106, loss_v1=0, loss_v2=0, nll_loss=0.875, ntokens=1030.4, nsentences=32, sample_size=1030.4, sample_size_v1=0, sample_size_v2=0, ppl=1.83, wps=547.1, ups=0.53, wpb=1030.4, bsz=32, num_updates=44200, lr=4.76629e-06, gnorm=21.854, clip=100, loss_scale=32, train_wall=19, gb_free=11.7, wall=83082
2023-05-26 22:28:06 - progress_bar.py[line:272] - INFO: epoch 026:    986 / 1732 loss=2.126, loss_v1=0, loss_v2=0, nll_loss=0.899, ntokens=1042.1, nsentences=32, sample_size=1042.1, sample_size_v1=0, sample_size_v2=0, ppl=1.86, wps=551.8, ups=0.53, wpb=1042.1, bsz=32, num_updates=44210, lr=4.76015e-06, gnorm=22.069, clip=100, loss_scale=32, train_wall=19, gb_free=10.8, wall=83101
2023-05-26 22:28:25 - progress_bar.py[line:272] - INFO: epoch 026:    996 / 1732 loss=2.132, loss_v1=0, loss_v2=0, nll_loss=0.903, ntokens=1036.4, nsentences=32, sample_size=1036.4, sample_size_v1=0, sample_size_v2=0, ppl=1.87, wps=554.2, ups=0.53, wpb=1036.4, bsz=32, num_updates=44220, lr=4.75401e-06, gnorm=22.685, clip=100, loss_scale=32, train_wall=19, gb_free=11.7, wall=83119
2023-05-26 22:28:34 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2023-05-26 22:28:45 - progress_bar.py[line:272] - INFO: epoch 026:   1007 / 1732 loss=2.118, loss_v1=0, loss_v2=0, nll_loss=0.889, ntokens=1005.5, nsentences=32, sample_size=1005.5, sample_size_v1=0, sample_size_v2=0, ppl=1.85, wps=491.2, ups=0.49, wpb=1005.5, bsz=32, num_updates=44230, lr=4.74787e-06, gnorm=22, clip=100, loss_scale=16, train_wall=20, gb_free=11.3, wall=83140
2023-05-26 22:29:04 - progress_bar.py[line:272] - INFO: epoch 026:   1017 / 1732 loss=2.106, loss_v1=0, loss_v2=0, nll_loss=0.873, ntokens=1024.8, nsentences=32, sample_size=1024.8, sample_size_v1=0, sample_size_v2=0, ppl=1.83, wps=548.9, ups=0.54, wpb=1024.8, bsz=32, num_updates=44240, lr=4.74172e-06, gnorm=20.98, clip=100, loss_scale=16, train_wall=19, gb_free=10.5, wall=83159
2023-05-26 22:29:23 - progress_bar.py[line:272] - INFO: epoch 026:   1027 / 1732 loss=2.137, loss_v1=0, loss_v2=0, nll_loss=0.909, ntokens=1051.5, nsentences=32, sample_size=1051.5, sample_size_v1=0, sample_size_v2=0, ppl=1.88, wps=558.5, ups=0.53, wpb=1051.5, bsz=32, num_updates=44250, lr=4.73558e-06, gnorm=20.44, clip=100, loss_scale=16, train_wall=19, gb_free=11.3, wall=83177
2023-05-26 22:29:42 - progress_bar.py[line:272] - INFO: epoch 026:   1037 / 1732 loss=2.109, loss_v1=0, loss_v2=0, nll_loss=0.876, ntokens=1129.2, nsentences=32, sample_size=1129.2, sample_size_v1=0, sample_size_v2=0, ppl=1.84, wps=596.7, ups=0.53, wpb=1129.2, bsz=32, num_updates=44260, lr=4.72944e-06, gnorm=20.491, clip=100, loss_scale=16, train_wall=19, gb_free=11.5, wall=83196
2023-05-26 22:30:00 - progress_bar.py[line:272] - INFO: epoch 026:   1047 / 1732 loss=2.115, loss_v1=0, loss_v2=0, nll_loss=0.883, ntokens=1024.6, nsentences=32, sample_size=1024.6, sample_size_v1=0, sample_size_v2=0, ppl=1.84, wps=545.8, ups=0.53, wpb=1024.6, bsz=32, num_updates=44270, lr=4.7233e-06, gnorm=22.613, clip=100, loss_scale=16, train_wall=19, gb_free=11.5, wall=83215
2023-05-26 22:30:19 - progress_bar.py[line:272] - INFO: epoch 026:   1057 / 1732 loss=2.139, loss_v1=0, loss_v2=0, nll_loss=0.911, ntokens=1089.7, nsentences=32, sample_size=1089.7, sample_size_v1=0, sample_size_v2=0, ppl=1.88, wps=580.1, ups=0.53, wpb=1089.7, bsz=32, num_updates=44280, lr=4.71715e-06, gnorm=22.053, clip=100, loss_scale=16, train_wall=19, gb_free=10.5, wall=83234
2023-05-26 22:30:38 - progress_bar.py[line:272] - INFO: epoch 026:   1067 / 1732 loss=2.107, loss_v1=0, loss_v2=0, nll_loss=0.874, ntokens=1006.5, nsentences=32, sample_size=1006.5, sample_size_v1=0, sample_size_v2=0, ppl=1.83, wps=539.1, ups=0.54, wpb=1006.5, bsz=32, num_updates=44290, lr=4.71101e-06, gnorm=20.646, clip=100, loss_scale=16, train_wall=19, gb_free=11.4, wall=83253
2023-05-26 22:30:57 - progress_bar.py[line:272] - INFO: epoch 026:   1077 / 1732 loss=2.133, loss_v1=0, loss_v2=0, nll_loss=0.905, ntokens=990.3, nsentences=32, sample_size=990.3, sample_size_v1=0, sample_size_v2=0, ppl=1.87, wps=526.1, ups=0.53, wpb=990.3, bsz=32, num_updates=44300, lr=4.70487e-06, gnorm=22.68, clip=100, loss_scale=16, train_wall=19, gb_free=11.8, wall=83271
2023-05-26 22:31:16 - progress_bar.py[line:272] - INFO: epoch 026:   1087 / 1732 loss=2.119, loss_v1=0, loss_v2=0, nll_loss=0.888, ntokens=1071.1, nsentences=32, sample_size=1071.1, sample_size_v1=0, sample_size_v2=0, ppl=1.85, wps=566, ups=0.53, wpb=1071.1, bsz=32, num_updates=44310, lr=4.69873e-06, gnorm=21.26, clip=100, loss_scale=16, train_wall=19, gb_free=11.8, wall=83290
2023-05-26 22:31:34 - progress_bar.py[line:272] - INFO: epoch 026:   1097 / 1732 loss=2.126, loss_v1=0, loss_v2=0, nll_loss=0.897, ntokens=1042.6, nsentences=32, sample_size=1042.6, sample_size_v1=0, sample_size_v2=0, ppl=1.86, wps=556.7, ups=0.53, wpb=1042.6, bsz=32, num_updates=44320, lr=4.69259e-06, gnorm=22.016, clip=100, loss_scale=16, train_wall=19, gb_free=11.9, wall=83309
2023-05-26 22:31:53 - progress_bar.py[line:272] - INFO: epoch 026:   1107 / 1732 loss=2.123, loss_v1=0, loss_v2=0, nll_loss=0.893, ntokens=1075.5, nsentences=32, sample_size=1075.5, sample_size_v1=0, sample_size_v2=0, ppl=1.86, wps=570.9, ups=0.53, wpb=1075.5, bsz=32, num_updates=44330, lr=4.68644e-06, gnorm=20.688, clip=100, loss_scale=16, train_wall=19, gb_free=11, wall=83328
2023-05-26 22:32:12 - progress_bar.py[line:272] - INFO: epoch 026:   1117 / 1732 loss=2.12, loss_v1=0, loss_v2=0, nll_loss=0.89, ntokens=943.9, nsentences=32, sample_size=943.9, sample_size_v1=0, sample_size_v2=0, ppl=1.85, wps=504, ups=0.53, wpb=943.9, bsz=32, num_updates=44340, lr=4.6803e-06, gnorm=22.839, clip=100, loss_scale=16, train_wall=19, gb_free=11.3, wall=83347
2023-05-26 22:32:31 - progress_bar.py[line:272] - INFO: epoch 026:   1127 / 1732 loss=2.113, loss_v1=0, loss_v2=0, nll_loss=0.881, ntokens=1022.2, nsentences=32, sample_size=1022.2, sample_size_v1=0, sample_size_v2=0, ppl=1.84, wps=543.9, ups=0.53, wpb=1022.2, bsz=32, num_updates=44350, lr=4.67416e-06, gnorm=22.081, clip=100, loss_scale=16, train_wall=19, gb_free=10.8, wall=83365
2023-05-26 22:32:49 - progress_bar.py[line:272] - INFO: epoch 026:   1137 / 1732 loss=2.11, loss_v1=0, loss_v2=0, nll_loss=0.878, ntokens=987.1, nsentences=32, sample_size=987.1, sample_size_v1=0, sample_size_v2=0, ppl=1.84, wps=527.2, ups=0.53, wpb=987.1, bsz=32, num_updates=44360, lr=4.66802e-06, gnorm=22.86, clip=100, loss_scale=16, train_wall=19, gb_free=10.8, wall=83384
2023-05-26 22:33:08 - progress_bar.py[line:272] - INFO: epoch 026:   1147 / 1732 loss=2.119, loss_v1=0, loss_v2=0, nll_loss=0.887, ntokens=1007.7, nsentences=32, sample_size=1007.7, sample_size_v1=0, sample_size_v2=0, ppl=1.85, wps=538.5, ups=0.53, wpb=1007.7, bsz=32, num_updates=44370, lr=4.66188e-06, gnorm=20.756, clip=100, loss_scale=16, train_wall=19, gb_free=11.3, wall=83403
2023-05-26 22:33:27 - progress_bar.py[line:272] - INFO: epoch 026:   1157 / 1732 loss=2.092, loss_v1=0, loss_v2=0, nll_loss=0.858, ntokens=1000.6, nsentences=32, sample_size=1000.6, sample_size_v1=0, sample_size_v2=0, ppl=1.81, wps=535, ups=0.53, wpb=1000.6, bsz=32, num_updates=44380, lr=4.65573e-06, gnorm=23.222, clip=100, loss_scale=16, train_wall=19, gb_free=11.7, wall=83422
2023-05-26 22:33:46 - progress_bar.py[line:272] - INFO: epoch 026:   1167 / 1732 loss=2.108, loss_v1=0, loss_v2=0, nll_loss=0.877, ntokens=1036.7, nsentences=32, sample_size=1036.7, sample_size_v1=0, sample_size_v2=0, ppl=1.84, wps=551, ups=0.53, wpb=1036.7, bsz=32, num_updates=44390, lr=4.64959e-06, gnorm=23.058, clip=100, loss_scale=16, train_wall=19, gb_free=11.4, wall=83440
2023-05-26 22:34:04 - progress_bar.py[line:272] - INFO: epoch 026:   1177 / 1732 loss=2.099, loss_v1=0, loss_v2=0, nll_loss=0.866, ntokens=1069.6, nsentences=32, sample_size=1069.6, sample_size_v1=0, sample_size_v2=0, ppl=1.82, wps=570.4, ups=0.53, wpb=1069.6, bsz=32, num_updates=44400, lr=4.64345e-06, gnorm=21.544, clip=100, loss_scale=16, train_wall=19, gb_free=11.7, wall=83459
2023-05-26 22:34:23 - progress_bar.py[line:272] - INFO: epoch 026:   1187 / 1732 loss=2.104, loss_v1=0, loss_v2=0, nll_loss=0.872, ntokens=953.6, nsentences=32, sample_size=953.6, sample_size_v1=0, sample_size_v2=0, ppl=1.83, wps=511.3, ups=0.54, wpb=953.6, bsz=32, num_updates=44410, lr=4.63731e-06, gnorm=23.484, clip=100, loss_scale=16, train_wall=19, gb_free=11.9, wall=83478
2023-05-26 22:34:42 - progress_bar.py[line:272] - INFO: epoch 026:   1197 / 1732 loss=2.123, loss_v1=0, loss_v2=0, nll_loss=0.893, ntokens=1116.1, nsentences=32, sample_size=1116.1, sample_size_v1=0, sample_size_v2=0, ppl=1.86, wps=591.6, ups=0.53, wpb=1116.1, bsz=32, num_updates=44420, lr=4.63117e-06, gnorm=23.15, clip=100, loss_scale=16, train_wall=19, gb_free=10.4, wall=83497
2023-05-26 22:35:01 - progress_bar.py[line:272] - INFO: epoch 026:   1207 / 1732 loss=2.101, loss_v1=0, loss_v2=0, nll_loss=0.87, ntokens=1096.1, nsentences=32, sample_size=1096.1, sample_size_v1=0, sample_size_v2=0, ppl=1.83, wps=580.6, ups=0.53, wpb=1096.1, bsz=32, num_updates=44430, lr=4.62502e-06, gnorm=21.197, clip=100, loss_scale=16, train_wall=19, gb_free=11.1, wall=83515
2023-05-26 22:35:20 - progress_bar.py[line:272] - INFO: epoch 026:   1217 / 1732 loss=2.121, loss_v1=0, loss_v2=0, nll_loss=0.891, ntokens=1014.3, nsentences=32, sample_size=1014.3, sample_size_v1=0, sample_size_v2=0, ppl=1.85, wps=541.4, ups=0.53, wpb=1014.3, bsz=32, num_updates=44440, lr=4.61888e-06, gnorm=22.098, clip=100, loss_scale=16, train_wall=19, gb_free=11.4, wall=83534
2023-05-26 22:35:38 - progress_bar.py[line:272] - INFO: epoch 026:   1227 / 1732 loss=2.142, loss_v1=0, loss_v2=0, nll_loss=0.914, ntokens=1027.4, nsentences=32, sample_size=1027.4, sample_size_v1=0, sample_size_v2=0, ppl=1.88, wps=547.7, ups=0.53, wpb=1027.4, bsz=32, num_updates=44450, lr=4.61274e-06, gnorm=22.65, clip=100, loss_scale=16, train_wall=19, gb_free=11.8, wall=83553
2023-05-26 22:35:57 - progress_bar.py[line:272] - INFO: epoch 026:   1237 / 1732 loss=2.09, loss_v1=0, loss_v2=0, nll_loss=0.855, ntokens=1040.4, nsentences=32, sample_size=1040.4, sample_size_v1=0, sample_size_v2=0, ppl=1.81, wps=553.3, ups=0.53, wpb=1040.4, bsz=32, num_updates=44460, lr=4.6066e-06, gnorm=20.492, clip=100, loss_scale=16, train_wall=19, gb_free=11.4, wall=83572
2023-05-26 22:36:16 - progress_bar.py[line:272] - INFO: epoch 026:   1247 / 1732 loss=2.075, loss_v1=0, loss_v2=0, nll_loss=0.839, ntokens=1124.4, nsentences=32, sample_size=1124.4, sample_size_v1=0, sample_size_v2=0, ppl=1.79, wps=596.3, ups=0.53, wpb=1124.4, bsz=32, num_updates=44470, lr=4.60045e-06, gnorm=20.457, clip=100, loss_scale=16, train_wall=19, gb_free=11.6, wall=83591
2023-05-26 22:36:35 - progress_bar.py[line:272] - INFO: epoch 026:   1257 / 1732 loss=2.092, loss_v1=0, loss_v2=0, nll_loss=0.857, ntokens=1053.7, nsentences=32, sample_size=1053.7, sample_size_v1=0, sample_size_v2=0, ppl=1.81, wps=561.9, ups=0.53, wpb=1053.7, bsz=32, num_updates=44480, lr=4.59431e-06, gnorm=21.191, clip=100, loss_scale=16, train_wall=19, gb_free=11.2, wall=83609
2023-05-26 22:36:54 - progress_bar.py[line:272] - INFO: epoch 026:   1267 / 1732 loss=2.111, loss_v1=0, loss_v2=0, nll_loss=0.88, ntokens=1037.3, nsentences=32, sample_size=1037.3, sample_size_v1=0, sample_size_v2=0, ppl=1.84, wps=549.1, ups=0.53, wpb=1037.3, bsz=32, num_updates=44490, lr=4.58817e-06, gnorm=19.435, clip=100, loss_scale=16, train_wall=19, gb_free=11.3, wall=83628
2023-05-26 22:37:13 - progress_bar.py[line:272] - INFO: epoch 026:   1277 / 1732 loss=2.104, loss_v1=0, loss_v2=0, nll_loss=0.872, ntokens=1060.8, nsentences=32, sample_size=1060.8, sample_size_v1=0, sample_size_v2=0, ppl=1.83, wps=562, ups=0.53, wpb=1060.8, bsz=32, num_updates=44500, lr=4.58203e-06, gnorm=19.809, clip=100, loss_scale=16, train_wall=19, gb_free=10.9, wall=83647
2023-05-26 22:37:31 - progress_bar.py[line:272] - INFO: epoch 026:   1287 / 1732 loss=2.094, loss_v1=0, loss_v2=0, nll_loss=0.86, ntokens=1057.7, nsentences=32, sample_size=1057.7, sample_size_v1=0, sample_size_v2=0, ppl=1.82, wps=562.4, ups=0.53, wpb=1057.7, bsz=32, num_updates=44510, lr=4.57589e-06, gnorm=21.09, clip=100, loss_scale=16, train_wall=19, gb_free=11.1, wall=83666
2023-05-26 22:37:50 - progress_bar.py[line:272] - INFO: epoch 026:   1297 / 1732 loss=2.094, loss_v1=0, loss_v2=0, nll_loss=0.86, ntokens=1105.1, nsentences=32, sample_size=1105.1, sample_size_v1=0, sample_size_v2=0, ppl=1.82, wps=586.4, ups=0.53, wpb=1105.1, bsz=32, num_updates=44520, lr=4.56974e-06, gnorm=19.847, clip=100, loss_scale=16, train_wall=19, gb_free=11.5, wall=83685
2023-05-26 22:38:09 - progress_bar.py[line:272] - INFO: epoch 026:   1307 / 1732 loss=2.14, loss_v1=0, loss_v2=0, nll_loss=0.912, ntokens=1096.7, nsentences=32, sample_size=1096.7, sample_size_v1=0, sample_size_v2=0, ppl=1.88, wps=577.1, ups=0.53, wpb=1096.7, bsz=32, num_updates=44530, lr=4.5636e-06, gnorm=21.186, clip=100, loss_scale=16, train_wall=19, gb_free=11.5, wall=83704
2023-05-26 22:38:28 - progress_bar.py[line:272] - INFO: epoch 026:   1317 / 1732 loss=2.115, loss_v1=0, loss_v2=0, nll_loss=0.884, ntokens=1048.7, nsentences=32, sample_size=1048.7, sample_size_v1=0, sample_size_v2=0, ppl=1.85, wps=554.7, ups=0.53, wpb=1048.7, bsz=32, num_updates=44540, lr=4.55746e-06, gnorm=22.45, clip=100, loss_scale=16, train_wall=19, gb_free=11.6, wall=83723
2023-05-26 22:38:47 - progress_bar.py[line:272] - INFO: epoch 026:   1327 / 1732 loss=2.089, loss_v1=0, loss_v2=0, nll_loss=0.855, ntokens=1124.5, nsentences=32, sample_size=1124.5, sample_size_v1=0, sample_size_v2=0, ppl=1.81, wps=593.5, ups=0.53, wpb=1124.5, bsz=32, num_updates=44550, lr=4.55132e-06, gnorm=20.766, clip=100, loss_scale=16, train_wall=19, gb_free=11.3, wall=83742
2023-05-26 22:39:06 - progress_bar.py[line:272] - INFO: epoch 026:   1337 / 1732 loss=2.088, loss_v1=0, loss_v2=0, nll_loss=0.854, ntokens=1126.2, nsentences=32, sample_size=1126.2, sample_size_v1=0, sample_size_v2=0, ppl=1.81, wps=592.4, ups=0.53, wpb=1126.2, bsz=32, num_updates=44560, lr=4.54518e-06, gnorm=19.644, clip=100, loss_scale=16, train_wall=19, gb_free=11.2, wall=83761
2023-05-26 22:39:25 - progress_bar.py[line:272] - INFO: epoch 026:   1347 / 1732 loss=2.107, loss_v1=0, loss_v2=0, nll_loss=0.877, ntokens=1159.1, nsentences=32, sample_size=1159.1, sample_size_v1=0, sample_size_v2=0, ppl=1.84, wps=609.6, ups=0.53, wpb=1159.1, bsz=32, num_updates=44570, lr=4.53903e-06, gnorm=19.143, clip=100, loss_scale=16, train_wall=19, gb_free=11.5, wall=83780
2023-05-26 22:39:44 - progress_bar.py[line:272] - INFO: epoch 026:   1357 / 1732 loss=2.081, loss_v1=0, loss_v2=0, nll_loss=0.847, ntokens=1146.3, nsentences=32, sample_size=1146.3, sample_size_v1=0, sample_size_v2=0, ppl=1.8, wps=604.2, ups=0.53, wpb=1146.3, bsz=32, num_updates=44580, lr=4.53289e-06, gnorm=19.791, clip=100, loss_scale=16, train_wall=19, gb_free=10.9, wall=83799
2023-05-26 22:40:03 - progress_bar.py[line:272] - INFO: epoch 026:   1367 / 1732 loss=2.103, loss_v1=0, loss_v2=0, nll_loss=0.872, ntokens=1081.6, nsentences=32, sample_size=1081.6, sample_size_v1=0, sample_size_v2=0, ppl=1.83, wps=572.4, ups=0.53, wpb=1081.6, bsz=32, num_updates=44590, lr=4.52675e-06, gnorm=19.285, clip=100, loss_scale=16, train_wall=19, gb_free=11, wall=83818
2023-05-26 22:40:22 - progress_bar.py[line:272] - INFO: epoch 026:   1377 / 1732 loss=2.15, loss_v1=0, loss_v2=0, nll_loss=0.924, ntokens=1107.3, nsentences=32, sample_size=1107.3, sample_size_v1=0, sample_size_v2=0, ppl=1.9, wps=590.3, ups=0.53, wpb=1107.3, bsz=32, num_updates=44600, lr=4.52061e-06, gnorm=21.519, clip=100, loss_scale=16, train_wall=19, gb_free=11.5, wall=83836
2023-05-26 22:40:40 - progress_bar.py[line:272] - INFO: epoch 026:   1387 / 1732 loss=2.105, loss_v1=0, loss_v2=0, nll_loss=0.872, ntokens=1152.6, nsentences=32, sample_size=1152.6, sample_size_v1=0, sample_size_v2=0, ppl=1.83, wps=613.6, ups=0.53, wpb=1152.6, bsz=32, num_updates=44610, lr=4.51446e-06, gnorm=19.098, clip=100, loss_scale=16, train_wall=19, gb_free=11.5, wall=83855
2023-05-26 22:40:59 - progress_bar.py[line:272] - INFO: epoch 026:   1397 / 1732 loss=2.103, loss_v1=0, loss_v2=0, nll_loss=0.871, ntokens=1066.5, nsentences=32, sample_size=1066.5, sample_size_v1=0, sample_size_v2=0, ppl=1.83, wps=567.3, ups=0.53, wpb=1066.5, bsz=32, num_updates=44620, lr=4.50832e-06, gnorm=21.16, clip=100, loss_scale=16, train_wall=19, gb_free=11.4, wall=83874
2023-05-26 22:41:18 - progress_bar.py[line:272] - INFO: epoch 026:   1407 / 1732 loss=2.13, loss_v1=0, loss_v2=0, nll_loss=0.901, ntokens=1152.8, nsentences=32, sample_size=1152.8, sample_size_v1=0, sample_size_v2=0, ppl=1.87, wps=611.5, ups=0.53, wpb=1152.8, bsz=32, num_updates=44630, lr=4.50218e-06, gnorm=19.68, clip=100, loss_scale=16, train_wall=19, gb_free=11.4, wall=83893
2023-05-26 22:41:37 - progress_bar.py[line:272] - INFO: epoch 026:   1417 / 1732 loss=2.154, loss_v1=0, loss_v2=0, nll_loss=0.927, ntokens=1290.7, nsentences=32, sample_size=1290.7, sample_size_v1=0, sample_size_v2=0, ppl=1.9, wps=677.3, ups=0.52, wpb=1290.7, bsz=32, num_updates=44640, lr=4.49604e-06, gnorm=18.504, clip=100, loss_scale=16, train_wall=19, gb_free=10.9, wall=83912
2023-05-26 22:41:56 - progress_bar.py[line:272] - INFO: epoch 026:   1427 / 1732 loss=2.107, loss_v1=0, loss_v2=0, nll_loss=0.873, ntokens=1220.7, nsentences=32, sample_size=1220.7, sample_size_v1=0, sample_size_v2=0, ppl=1.83, wps=640.1, ups=0.52, wpb=1220.7, bsz=32, num_updates=44650, lr=4.4899e-06, gnorm=17.774, clip=100, loss_scale=16, train_wall=19, gb_free=11.6, wall=83931
2023-05-26 22:42:15 - progress_bar.py[line:272] - INFO: epoch 026:   1437 / 1732 loss=2.12, loss_v1=0, loss_v2=0, nll_loss=0.889, ntokens=1217.2, nsentences=32, sample_size=1217.2, sample_size_v1=0, sample_size_v2=0, ppl=1.85, wps=642.9, ups=0.53, wpb=1217.2, bsz=32, num_updates=44660, lr=4.48375e-06, gnorm=18.892, clip=100, loss_scale=16, train_wall=19, gb_free=9.6, wall=83950
2023-05-26 22:42:34 - progress_bar.py[line:272] - INFO: epoch 026:   1447 / 1732 loss=2.111, loss_v1=0, loss_v2=0, nll_loss=0.88, ntokens=1115.7, nsentences=32, sample_size=1115.7, sample_size_v1=0, sample_size_v2=0, ppl=1.84, wps=593.1, ups=0.53, wpb=1115.7, bsz=32, num_updates=44670, lr=4.47761e-06, gnorm=19.199, clip=100, loss_scale=16, train_wall=19, gb_free=11.6, wall=83969
2023-05-26 22:42:53 - progress_bar.py[line:272] - INFO: epoch 026:   1457 / 1732 loss=2.143, loss_v1=0, loss_v2=0, nll_loss=0.915, ntokens=1111.8, nsentences=32, sample_size=1111.8, sample_size_v1=0, sample_size_v2=0, ppl=1.89, wps=588.4, ups=0.53, wpb=1111.8, bsz=32, num_updates=44680, lr=4.47147e-06, gnorm=20.918, clip=100, loss_scale=16, train_wall=19, gb_free=10.6, wall=83988
2023-05-26 22:43:12 - progress_bar.py[line:272] - INFO: epoch 026:   1467 / 1732 loss=2.087, loss_v1=0, loss_v2=0, nll_loss=0.852, ntokens=1202.5, nsentences=32, sample_size=1202.5, sample_size_v1=0, sample_size_v2=0, ppl=1.81, wps=632.8, ups=0.53, wpb=1202.5, bsz=32, num_updates=44690, lr=4.46533e-06, gnorm=18.594, clip=100, loss_scale=16, train_wall=19, gb_free=11.3, wall=84007
2023-05-26 22:43:31 - progress_bar.py[line:272] - INFO: epoch 026:   1477 / 1732 loss=2.125, loss_v1=0, loss_v2=0, nll_loss=0.895, ntokens=1052.1, nsentences=32, sample_size=1052.1, sample_size_v1=0, sample_size_v2=0, ppl=1.86, wps=559.7, ups=0.53, wpb=1052.1, bsz=32, num_updates=44700, lr=4.45919e-06, gnorm=22.676, clip=100, loss_scale=16, train_wall=19, gb_free=10.7, wall=84025
2023-05-26 22:43:50 - progress_bar.py[line:272] - INFO: epoch 026:   1487 / 1732 loss=2.133, loss_v1=0, loss_v2=0, nll_loss=0.905, ntokens=1147.5, nsentences=32, sample_size=1147.5, sample_size_v1=0, sample_size_v2=0, ppl=1.87, wps=608.6, ups=0.53, wpb=1147.5, bsz=32, num_updates=44710, lr=4.45304e-06, gnorm=18.628, clip=100, loss_scale=16, train_wall=19, gb_free=10.8, wall=84044
2023-05-26 22:44:08 - progress_bar.py[line:272] - INFO: epoch 026:   1497 / 1732 loss=2.108, loss_v1=0, loss_v2=0, nll_loss=0.876, ntokens=1083.9, nsentences=32, sample_size=1083.9, sample_size_v1=0, sample_size_v2=0, ppl=1.83, wps=574.6, ups=0.53, wpb=1083.9, bsz=32, num_updates=44720, lr=4.4469e-06, gnorm=20.589, clip=100, loss_scale=16, train_wall=19, gb_free=11.5, wall=84063
2023-05-26 22:44:27 - progress_bar.py[line:272] - INFO: epoch 026:   1507 / 1732 loss=2.073, loss_v1=0, loss_v2=0, nll_loss=0.837, ntokens=1112.5, nsentences=32, sample_size=1112.5, sample_size_v1=0, sample_size_v2=0, ppl=1.79, wps=591.2, ups=0.53, wpb=1112.5, bsz=32, num_updates=44730, lr=4.44076e-06, gnorm=19.255, clip=100, loss_scale=16, train_wall=19, gb_free=11.5, wall=84082
2023-05-26 22:44:46 - progress_bar.py[line:272] - INFO: epoch 026:   1517 / 1732 loss=2.146, loss_v1=0, loss_v2=0, nll_loss=0.92, ntokens=1063, nsentences=32, sample_size=1063, sample_size_v1=0, sample_size_v2=0, ppl=1.89, wps=565, ups=0.53, wpb=1063, bsz=32, num_updates=44740, lr=4.43462e-06, gnorm=20.666, clip=100, loss_scale=32, train_wall=19, gb_free=10.7, wall=84101
2023-05-26 22:45:01 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2023-05-26 22:45:07 - progress_bar.py[line:272] - INFO: epoch 026:   1528 / 1732 loss=2.148, loss_v1=0, loss_v2=0, nll_loss=0.922, ntokens=1038.7, nsentences=32, sample_size=1038.7, sample_size_v1=0, sample_size_v2=0, ppl=1.89, wps=505.1, ups=0.49, wpb=1038.7, bsz=32, num_updates=44750, lr=4.42847e-06, gnorm=21.748, clip=100, loss_scale=16, train_wall=21, gb_free=11.6, wall=84121
2023-05-26 22:45:26 - progress_bar.py[line:272] - INFO: epoch 026:   1538 / 1732 loss=2.107, loss_v1=0, loss_v2=0, nll_loss=0.875, ntokens=1094, nsentences=32, sample_size=1094, sample_size_v1=0, sample_size_v2=0, ppl=1.83, wps=577.3, ups=0.53, wpb=1094, bsz=32, num_updates=44760, lr=4.42233e-06, gnorm=19.258, clip=100, loss_scale=16, train_wall=19, gb_free=11, wall=84140
2023-05-26 22:45:44 - progress_bar.py[line:272] - INFO: epoch 026:   1548 / 1732 loss=2.097, loss_v1=0, loss_v2=0, nll_loss=0.862, ntokens=1084.2, nsentences=32, sample_size=1084.2, sample_size_v1=0, sample_size_v2=0, ppl=1.82, wps=576.5, ups=0.53, wpb=1084.2, bsz=32, num_updates=44770, lr=4.41619e-06, gnorm=21.099, clip=100, loss_scale=16, train_wall=19, gb_free=11.4, wall=84159
2023-05-26 22:46:03 - progress_bar.py[line:272] - INFO: epoch 026:   1558 / 1732 loss=2.078, loss_v1=0, loss_v2=0, nll_loss=0.842, ntokens=1077.4, nsentences=32, sample_size=1077.4, sample_size_v1=0, sample_size_v2=0, ppl=1.79, wps=572.5, ups=0.53, wpb=1077.4, bsz=32, num_updates=44780, lr=4.41005e-06, gnorm=19.797, clip=100, loss_scale=16, train_wall=19, gb_free=10.8, wall=84178
2023-05-26 22:46:22 - progress_bar.py[line:272] - INFO: epoch 026:   1568 / 1732 loss=2.142, loss_v1=0, loss_v2=0, nll_loss=0.915, ntokens=1072.3, nsentences=32, sample_size=1072.3, sample_size_v1=0, sample_size_v2=0, ppl=1.89, wps=569.9, ups=0.53, wpb=1072.3, bsz=32, num_updates=44790, lr=4.40391e-06, gnorm=18.943, clip=100, loss_scale=16, train_wall=19, gb_free=10.5, wall=84197
2023-05-26 22:46:41 - progress_bar.py[line:272] - INFO: epoch 026:   1578 / 1732 loss=2.119, loss_v1=0, loss_v2=0, nll_loss=0.889, ntokens=1004.7, nsentences=32, sample_size=1004.7, sample_size_v1=0, sample_size_v2=0, ppl=1.85, wps=535.9, ups=0.53, wpb=1004.7, bsz=32, num_updates=44800, lr=4.39776e-06, gnorm=23.18, clip=100, loss_scale=16, train_wall=19, gb_free=11.2, wall=84216
2023-05-26 22:47:00 - progress_bar.py[line:272] - INFO: epoch 026:   1588 / 1732 loss=2.101, loss_v1=0, loss_v2=0, nll_loss=0.869, ntokens=1078.3, nsentences=32, sample_size=1078.3, sample_size_v1=0, sample_size_v2=0, ppl=1.83, wps=569.8, ups=0.53, wpb=1078.3, bsz=32, num_updates=44810, lr=4.39162e-06, gnorm=19.547, clip=100, loss_scale=16, train_wall=19, gb_free=11.4, wall=84234
2023-05-26 22:47:19 - progress_bar.py[line:272] - INFO: epoch 026:   1598 / 1732 loss=2.098, loss_v1=0, loss_v2=0, nll_loss=0.864, ntokens=1079.8, nsentences=32, sample_size=1079.8, sample_size_v1=0, sample_size_v2=0, ppl=1.82, wps=574.4, ups=0.53, wpb=1079.8, bsz=32, num_updates=44820, lr=4.38548e-06, gnorm=19.951, clip=100, loss_scale=16, train_wall=19, gb_free=11.5, wall=84253
2023-05-26 22:47:38 - progress_bar.py[line:272] - INFO: epoch 026:   1608 / 1732 loss=2.096, loss_v1=0, loss_v2=0, nll_loss=0.863, ntokens=1140.6, nsentences=32, sample_size=1140.6, sample_size_v1=0, sample_size_v2=0, ppl=1.82, wps=601.9, ups=0.53, wpb=1140.6, bsz=32, num_updates=44830, lr=4.37934e-06, gnorm=18.677, clip=100, loss_scale=16, train_wall=19, gb_free=11, wall=84272
2023-05-26 22:47:56 - progress_bar.py[line:272] - INFO: epoch 026:   1618 / 1732 loss=2.083, loss_v1=0, loss_v2=0, nll_loss=0.849, ntokens=1124.7, nsentences=32, sample_size=1124.7, sample_size_v1=0, sample_size_v2=0, ppl=1.8, wps=593.1, ups=0.53, wpb=1124.7, bsz=32, num_updates=44840, lr=4.3732e-06, gnorm=20.705, clip=100, loss_scale=16, train_wall=19, gb_free=11, wall=84291
2023-05-26 22:48:15 - progress_bar.py[line:272] - INFO: epoch 026:   1628 / 1732 loss=2.109, loss_v1=0, loss_v2=0, nll_loss=0.878, ntokens=1158.7, nsentences=32, sample_size=1158.7, sample_size_v1=0, sample_size_v2=0, ppl=1.84, wps=609.5, ups=0.53, wpb=1158.7, bsz=32, num_updates=44850, lr=4.36705e-06, gnorm=21.114, clip=100, loss_scale=16, train_wall=19, gb_free=10.6, wall=84310
2023-05-26 22:48:34 - progress_bar.py[line:272] - INFO: epoch 026:   1638 / 1732 loss=2.092, loss_v1=0, loss_v2=0, nll_loss=0.858, ntokens=1131.3, nsentences=32, sample_size=1131.3, sample_size_v1=0, sample_size_v2=0, ppl=1.81, wps=602.9, ups=0.53, wpb=1131.3, bsz=32, num_updates=44860, lr=4.36091e-06, gnorm=21.124, clip=100, loss_scale=16, train_wall=19, gb_free=11, wall=84329
2023-05-26 22:48:53 - progress_bar.py[line:272] - INFO: epoch 026:   1648 / 1732 loss=2.097, loss_v1=0, loss_v2=0, nll_loss=0.863, ntokens=1231.9, nsentences=32, sample_size=1231.9, sample_size_v1=0, sample_size_v2=0, ppl=1.82, wps=648.4, ups=0.53, wpb=1231.9, bsz=32, num_updates=44870, lr=4.35477e-06, gnorm=18.279, clip=100, loss_scale=16, train_wall=19, gb_free=11.6, wall=84348
2023-05-26 22:49:12 - progress_bar.py[line:272] - INFO: epoch 026:   1658 / 1732 loss=2.131, loss_v1=0, loss_v2=0, nll_loss=0.903, ntokens=971, nsentences=32, sample_size=971, sample_size_v1=0, sample_size_v2=0, ppl=1.87, wps=518, ups=0.53, wpb=971, bsz=32, num_updates=44880, lr=4.34863e-06, gnorm=22.301, clip=100, loss_scale=16, train_wall=19, gb_free=11.1, wall=84367
2023-05-26 22:49:31 - progress_bar.py[line:272] - INFO: epoch 026:   1668 / 1732 loss=2.107, loss_v1=0, loss_v2=0, nll_loss=0.875, ntokens=1011.3, nsentences=32, sample_size=1011.3, sample_size_v1=0, sample_size_v2=0, ppl=1.83, wps=538.6, ups=0.53, wpb=1011.3, bsz=32, num_updates=44890, lr=4.34249e-06, gnorm=19.795, clip=100, loss_scale=16, train_wall=19, gb_free=11.6, wall=84385
2023-05-26 22:49:50 - progress_bar.py[line:272] - INFO: epoch 026:   1678 / 1732 loss=2.072, loss_v1=0, loss_v2=0, nll_loss=0.836, ntokens=1161.5, nsentences=32, sample_size=1161.5, sample_size_v1=0, sample_size_v2=0, ppl=1.78, wps=613, ups=0.53, wpb=1161.5, bsz=32, num_updates=44900, lr=4.33634e-06, gnorm=17.998, clip=100, loss_scale=16, train_wall=19, gb_free=11.1, wall=84404
2023-05-26 22:50:09 - progress_bar.py[line:272] - INFO: epoch 026:   1688 / 1732 loss=2.112, loss_v1=0, loss_v2=0, nll_loss=0.881, ntokens=1174.7, nsentences=32, sample_size=1174.7, sample_size_v1=0, sample_size_v2=0, ppl=1.84, wps=617.4, ups=0.53, wpb=1174.7, bsz=32, num_updates=44910, lr=4.3302e-06, gnorm=20.393, clip=100, loss_scale=16, train_wall=19, gb_free=10, wall=84423
2023-05-26 22:50:28 - progress_bar.py[line:272] - INFO: epoch 026:   1698 / 1732 loss=2.094, loss_v1=0, loss_v2=0, nll_loss=0.861, ntokens=1304.9, nsentences=32, sample_size=1304.9, sample_size_v1=0, sample_size_v2=0, ppl=1.82, wps=676.2, ups=0.52, wpb=1304.9, bsz=32, num_updates=44920, lr=4.32406e-06, gnorm=16.761, clip=100, loss_scale=16, train_wall=19, gb_free=11.2, wall=84443
2023-05-26 22:50:47 - progress_bar.py[line:272] - INFO: epoch 026:   1708 / 1732 loss=2.126, loss_v1=0, loss_v2=0, nll_loss=0.896, ntokens=1174.9, nsentences=32, sample_size=1174.9, sample_size_v1=0, sample_size_v2=0, ppl=1.86, wps=619.1, ups=0.53, wpb=1174.9, bsz=32, num_updates=44930, lr=4.31792e-06, gnorm=19.1, clip=100, loss_scale=16, train_wall=19, gb_free=10.8, wall=84462
2023-05-26 22:51:06 - progress_bar.py[line:272] - INFO: epoch 026:   1718 / 1732 loss=2.088, loss_v1=0, loss_v2=0, nll_loss=0.853, ntokens=1181.2, nsentences=32, sample_size=1181.2, sample_size_v1=0, sample_size_v2=0, ppl=1.81, wps=620.3, ups=0.53, wpb=1181.2, bsz=32, num_updates=44940, lr=4.31177e-06, gnorm=17.09, clip=100, loss_scale=16, train_wall=19, gb_free=11, wall=84481
2023-05-26 22:51:25 - progress_bar.py[line:272] - INFO: epoch 026:   1728 / 1732 loss=2.128, loss_v1=0, loss_v2=0, nll_loss=0.899, ntokens=1093.2, nsentences=32, sample_size=1093.2, sample_size_v1=0, sample_size_v2=0, ppl=1.87, wps=578.8, ups=0.53, wpb=1093.2, bsz=32, num_updates=44950, lr=4.30563e-06, gnorm=19.186, clip=100, loss_scale=16, train_wall=19, gb_free=11, wall=84500
2023-05-26 22:51:31 - train.py[line:332] - INFO: end of epoch 26 (average epoch stats below)
2023-05-26 22:51:31 - progress_bar.py[line:282] - INFO: epoch 026 | loss 2.107 | loss_v1 0 | loss_v2 0 | nll_loss 0.876 | ntokens 1051.67 | nsentences 31.986 | sample_size 1051.67 | sample_size_v1 0 | sample_size_v2 0 | ppl 1.84 | wps 559.5 | ups 0.53 | wpb 1051.7 | bsz 32 | num_updates 44954 | lr 4.30318e-06 | gnorm 21.687 | clip 100 | loss_scale 16 | train_wall 3242 | gb_free 11.7 | wall 84506
2023-05-26 22:51:31 - trainer.py[line:639] - INFO: loading train data for epoch 27
local datafile ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 0 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 0 finished initializing row_count and line_idx-to-offset mapping
file ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 0 row count 55400 total row count 55400
slice_id 0 seek offset 0
2023-05-26 22:51:33 - trainer.py[line:703] - INFO: begin training epoch 27
2023-05-26 22:51:33 - train.py[line:305] - INFO: Start iterating over samples
2023-05-26 22:51:45 - progress_bar.py[line:272] - INFO: epoch 027:      6 / 1732 loss=2.108, loss_v1=0, loss_v2=0, nll_loss=0.876, ntokens=1082.4, nsentences=29.6, sample_size=1082.4, sample_size_v1=0, sample_size_v2=0, ppl=1.84, wps=547.4, ups=0.51, wpb=1082.4, bsz=29.6, num_updates=44960, lr=4.29949e-06, gnorm=22.37, clip=100, loss_scale=16, train_wall=18, gb_free=11.2, wall=84519
2023-05-26 22:52:04 - progress_bar.py[line:272] - INFO: epoch 027:     16 / 1732 loss=2.109, loss_v1=0, loss_v2=0, nll_loss=0.879, ntokens=1099.3, nsentences=32, sample_size=1099.3, sample_size_v1=0, sample_size_v2=0, ppl=1.84, wps=582.6, ups=0.53, wpb=1099.3, bsz=32, num_updates=44970, lr=4.29335e-06, gnorm=25.085, clip=100, loss_scale=16, train_wall=19, gb_free=11.2, wall=84538
2023-05-26 22:52:22 - progress_bar.py[line:272] - INFO: epoch 027:     26 / 1732 loss=2.078, loss_v1=0, loss_v2=0, nll_loss=0.842, ntokens=973, nsentences=32, sample_size=973, sample_size_v1=0, sample_size_v2=0, ppl=1.79, wps=517.8, ups=0.53, wpb=973, bsz=32, num_updates=44980, lr=4.28721e-06, gnorm=24.729, clip=100, loss_scale=16, train_wall=19, gb_free=11.5, wall=84557
2023-05-26 22:52:41 - progress_bar.py[line:272] - INFO: epoch 027:     36 / 1732 loss=1.981, loss_v1=0, loss_v2=0, nll_loss=0.733, ntokens=1153.4, nsentences=32, sample_size=1153.4, sample_size_v1=0, sample_size_v2=0, ppl=1.66, wps=607.5, ups=0.53, wpb=1153.4, bsz=32, num_updates=44990, lr=4.28106e-06, gnorm=19.35, clip=100, loss_scale=16, train_wall=19, gb_free=10.4, wall=84576
2023-05-26 22:53:00 - progress_bar.py[line:272] - INFO: epoch 027:     46 / 1732 loss=1.978, loss_v1=0, loss_v2=0, nll_loss=0.729, ntokens=1066.8, nsentences=32, sample_size=1066.8, sample_size_v1=0, sample_size_v2=0, ppl=1.66, wps=566.4, ups=0.53, wpb=1066.8, bsz=32, num_updates=45000, lr=4.27492e-06, gnorm=20.688, clip=100, loss_scale=16, train_wall=19, gb_free=11.6, wall=84595
2023-05-26 22:53:19 - progress_bar.py[line:272] - INFO: epoch 027:     56 / 1732 loss=1.937, loss_v1=0, loss_v2=0, nll_loss=0.684, ntokens=1077, nsentences=32, sample_size=1077, sample_size_v1=0, sample_size_v2=0, ppl=1.61, wps=571.9, ups=0.53, wpb=1077, bsz=32, num_updates=45010, lr=4.26878e-06, gnorm=21.127, clip=100, loss_scale=16, train_wall=19, gb_free=11.5, wall=84614
2023-05-26 22:53:38 - progress_bar.py[line:272] - INFO: epoch 027:     66 / 1732 loss=1.842, loss_v1=0, loss_v2=0, nll_loss=0.577, ntokens=1294.5, nsentences=32, sample_size=1294.5, sample_size_v1=0, sample_size_v2=0, ppl=1.49, wps=674.9, ups=0.52, wpb=1294.5, bsz=32, num_updates=45020, lr=4.26264e-06, gnorm=15.508, clip=100, loss_scale=16, train_wall=19, gb_free=10.5, wall=84633
2023-05-26 22:53:58 - progress_bar.py[line:272] - INFO: epoch 027:     76 / 1732 loss=1.918, loss_v1=0, loss_v2=0, nll_loss=0.664, ntokens=1343.5, nsentences=32, sample_size=1343.5, sample_size_v1=0, sample_size_v2=0, ppl=1.58, wps=687.7, ups=0.51, wpb=1343.5, bsz=32, num_updates=45030, lr=4.2565e-06, gnorm=13.462, clip=100, loss_scale=16, train_wall=20, gb_free=10.1, wall=84652
2023-05-26 22:54:17 - progress_bar.py[line:272] - INFO: epoch 027:     86 / 1732 loss=1.964, loss_v1=0, loss_v2=0, nll_loss=0.716, ntokens=1107.4, nsentences=32, sample_size=1107.4, sample_size_v1=0, sample_size_v2=0, ppl=1.64, wps=581, ups=0.52, wpb=1107.4, bsz=32, num_updates=45040, lr=4.25035e-06, gnorm=17.702, clip=100, loss_scale=16, train_wall=19, gb_free=10.8, wall=84672
2023-05-26 22:54:36 - progress_bar.py[line:272] - INFO: epoch 027:     96 / 1732 loss=1.967, loss_v1=0, loss_v2=0, nll_loss=0.722, ntokens=1069.5, nsentences=32, sample_size=1069.5, sample_size_v1=0, sample_size_v2=0, ppl=1.65, wps=564.8, ups=0.53, wpb=1069.5, bsz=32, num_updates=45050, lr=4.24421e-06, gnorm=20.014, clip=100, loss_scale=16, train_wall=19, gb_free=10.4, wall=84690
2023-05-26 22:54:55 - progress_bar.py[line:272] - INFO: epoch 027:    106 / 1732 loss=2.058, loss_v1=0, loss_v2=0, nll_loss=0.823, ntokens=998.2, nsentences=32, sample_size=998.2, sample_size_v1=0, sample_size_v2=0, ppl=1.77, wps=532.3, ups=0.53, wpb=998.2, bsz=32, num_updates=45060, lr=4.23807e-06, gnorm=21.499, clip=100, loss_scale=16, train_wall=19, gb_free=10.4, wall=84709
2023-05-26 22:55:14 - progress_bar.py[line:272] - INFO: epoch 027:    116 / 1732 loss=2.152, loss_v1=0, loss_v2=0, nll_loss=0.928, ntokens=1049.3, nsentences=32, sample_size=1049.3, sample_size_v1=0, sample_size_v2=0, ppl=1.9, wps=552.9, ups=0.53, wpb=1049.3, bsz=32, num_updates=45070, lr=4.23193e-06, gnorm=22.838, clip=100, loss_scale=16, train_wall=19, gb_free=10.5, wall=84728
2023-05-26 22:55:33 - progress_bar.py[line:272] - INFO: epoch 027:    126 / 1732 loss=2.109, loss_v1=0, loss_v2=0, nll_loss=0.879, ntokens=1187.5, nsentences=32, sample_size=1187.5, sample_size_v1=0, sample_size_v2=0, ppl=1.84, wps=616.4, ups=0.52, wpb=1187.5, bsz=32, num_updates=45080, lr=4.22578e-06, gnorm=19.873, clip=100, loss_scale=16, train_wall=19, gb_free=10.9, wall=84747
2023-05-26 22:55:52 - progress_bar.py[line:272] - INFO: epoch 027:    136 / 1732 loss=2.094, loss_v1=0, loss_v2=0, nll_loss=0.86, ntokens=1228, nsentences=32, sample_size=1228, sample_size_v1=0, sample_size_v2=0, ppl=1.82, wps=643.7, ups=0.52, wpb=1228, bsz=32, num_updates=45090, lr=4.21964e-06, gnorm=19.466, clip=100, loss_scale=16, train_wall=19, gb_free=10.4, wall=84767
2023-05-26 22:56:11 - progress_bar.py[line:272] - INFO: epoch 027:    146 / 1732 loss=2.048, loss_v1=0, loss_v2=0, nll_loss=0.808, ntokens=1192.9, nsentences=32, sample_size=1192.9, sample_size_v1=0, sample_size_v2=0, ppl=1.75, wps=619.8, ups=0.52, wpb=1192.9, bsz=32, num_updates=45100, lr=4.2135e-06, gnorm=19.924, clip=100, loss_scale=16, train_wall=19, gb_free=10.6, wall=84786
2023-05-26 22:56:30 - progress_bar.py[line:272] - INFO: epoch 027:    156 / 1732 loss=2.09, loss_v1=0, loss_v2=0, nll_loss=0.856, ntokens=1174.3, nsentences=32, sample_size=1174.3, sample_size_v1=0, sample_size_v2=0, ppl=1.81, wps=610, ups=0.52, wpb=1174.3, bsz=32, num_updates=45110, lr=4.20736e-06, gnorm=20.841, clip=100, loss_scale=16, train_wall=19, gb_free=11.1, wall=84805
2023-05-26 22:56:49 - progress_bar.py[line:272] - INFO: epoch 027:    166 / 1732 loss=2.07, loss_v1=0, loss_v2=0, nll_loss=0.834, ntokens=1039.2, nsentences=32, sample_size=1039.2, sample_size_v1=0, sample_size_v2=0, ppl=1.78, wps=550.3, ups=0.53, wpb=1039.2, bsz=32, num_updates=45120, lr=4.20122e-06, gnorm=24.381, clip=100, loss_scale=16, train_wall=19, gb_free=10.5, wall=84824
2023-05-26 22:57:08 - progress_bar.py[line:272] - INFO: epoch 027:    176 / 1732 loss=2.081, loss_v1=0, loss_v2=0, nll_loss=0.846, ntokens=982.6, nsentences=32, sample_size=982.6, sample_size_v1=0, sample_size_v2=0, ppl=1.8, wps=520.5, ups=0.53, wpb=982.6, bsz=32, num_updates=45130, lr=4.19507e-06, gnorm=23.693, clip=100, loss_scale=16, train_wall=19, gb_free=11, wall=84843
2023-05-26 22:57:27 - progress_bar.py[line:272] - INFO: epoch 027:    186 / 1732 loss=2.032, loss_v1=0, loss_v2=0, nll_loss=0.792, ntokens=1142, nsentences=32, sample_size=1142, sample_size_v1=0, sample_size_v2=0, ppl=1.73, wps=597.4, ups=0.52, wpb=1142, bsz=32, num_updates=45140, lr=4.18893e-06, gnorm=21.223, clip=100, loss_scale=16, train_wall=19, gb_free=11.1, wall=84862
2023-05-26 22:57:46 - progress_bar.py[line:272] - INFO: epoch 027:    196 / 1732 loss=2.07, loss_v1=0, loss_v2=0, nll_loss=0.834, ntokens=1152.2, nsentences=32, sample_size=1152.2, sample_size_v1=0, sample_size_v2=0, ppl=1.78, wps=605.1, ups=0.53, wpb=1152.2, bsz=32, num_updates=45150, lr=4.18279e-06, gnorm=21.015, clip=100, loss_scale=16, train_wall=19, gb_free=11, wall=84881
2023-05-26 22:58:05 - progress_bar.py[line:272] - INFO: epoch 027:    206 / 1732 loss=2.111, loss_v1=0, loss_v2=0, nll_loss=0.88, ntokens=995.3, nsentences=32, sample_size=995.3, sample_size_v1=0, sample_size_v2=0, ppl=1.84, wps=534.6, ups=0.54, wpb=995.3, bsz=32, num_updates=45160, lr=4.17665e-06, gnorm=20.662, clip=100, loss_scale=16, train_wall=19, gb_free=11.3, wall=84900
2023-05-26 22:58:24 - progress_bar.py[line:272] - INFO: epoch 027:    216 / 1732 loss=2.144, loss_v1=0, loss_v2=0, nll_loss=0.918, ntokens=1119.9, nsentences=32, sample_size=1119.9, sample_size_v1=0, sample_size_v2=0, ppl=1.89, wps=596.3, ups=0.53, wpb=1119.9, bsz=32, num_updates=45170, lr=4.17051e-06, gnorm=20.746, clip=100, loss_scale=16, train_wall=19, gb_free=11.2, wall=84918
2023-05-26 22:58:42 - progress_bar.py[line:272] - INFO: epoch 027:    226 / 1732 loss=2.116, loss_v1=0, loss_v2=0, nll_loss=0.887, ntokens=1111.6, nsentences=32, sample_size=1111.6, sample_size_v1=0, sample_size_v2=0, ppl=1.85, wps=595.6, ups=0.54, wpb=1111.6, bsz=32, num_updates=45180, lr=4.16436e-06, gnorm=18.625, clip=100, loss_scale=16, train_wall=19, gb_free=11.4, wall=84937
2023-05-26 22:59:01 - progress_bar.py[line:272] - INFO: epoch 027:    236 / 1732 loss=2.176, loss_v1=0, loss_v2=0, nll_loss=0.954, ntokens=1076.5, nsentences=32, sample_size=1076.5, sample_size_v1=0, sample_size_v2=0, ppl=1.94, wps=576.4, ups=0.54, wpb=1076.5, bsz=32, num_updates=45190, lr=4.15822e-06, gnorm=19.229, clip=100, loss_scale=16, train_wall=19, gb_free=11.4, wall=84956
2023-05-26 22:59:20 - progress_bar.py[line:272] - INFO: epoch 027:    246 / 1732 loss=2.15, loss_v1=0, loss_v2=0, nll_loss=0.924, ntokens=1166.2, nsentences=32, sample_size=1166.2, sample_size_v1=0, sample_size_v2=0, ppl=1.9, wps=619.3, ups=0.53, wpb=1166.2, bsz=32, num_updates=45200, lr=4.15208e-06, gnorm=18.891, clip=100, loss_scale=16, train_wall=19, gb_free=11.6, wall=84975
2023-05-26 22:59:39 - progress_bar.py[line:272] - INFO: epoch 027:    256 / 1732 loss=2.142, loss_v1=0, loss_v2=0, nll_loss=0.915, ntokens=1137.6, nsentences=32, sample_size=1137.6, sample_size_v1=0, sample_size_v2=0, ppl=1.89, wps=606, ups=0.53, wpb=1137.6, bsz=32, num_updates=45210, lr=4.14594e-06, gnorm=19.176, clip=100, loss_scale=16, train_wall=19, gb_free=11.4, wall=84993
2023-05-26 22:59:57 - progress_bar.py[line:272] - INFO: epoch 027:    266 / 1732 loss=2.136, loss_v1=0, loss_v2=0, nll_loss=0.908, ntokens=1142, nsentences=32, sample_size=1142, sample_size_v1=0, sample_size_v2=0, ppl=1.88, wps=608.5, ups=0.53, wpb=1142, bsz=32, num_updates=45220, lr=4.13979e-06, gnorm=18.963, clip=100, loss_scale=16, train_wall=19, gb_free=10.9, wall=85012
2023-05-26 23:00:16 - progress_bar.py[line:272] - INFO: epoch 027:    276 / 1732 loss=2.147, loss_v1=0, loss_v2=0, nll_loss=0.92, ntokens=1142.5, nsentences=32, sample_size=1142.5, sample_size_v1=0, sample_size_v2=0, ppl=1.89, wps=606.8, ups=0.53, wpb=1142.5, bsz=32, num_updates=45230, lr=4.13365e-06, gnorm=18.679, clip=100, loss_scale=16, train_wall=19, gb_free=10.8, wall=85031
2023-05-26 23:00:35 - progress_bar.py[line:272] - INFO: epoch 027:    286 / 1732 loss=2.148, loss_v1=0, loss_v2=0, nll_loss=0.92, ntokens=1155.8, nsentences=32, sample_size=1155.8, sample_size_v1=0, sample_size_v2=0, ppl=1.89, wps=613.7, ups=0.53, wpb=1155.8, bsz=32, num_updates=45240, lr=4.12751e-06, gnorm=17.822, clip=100, loss_scale=16, train_wall=19, gb_free=11.2, wall=85050
2023-05-26 23:00:54 - progress_bar.py[line:272] - INFO: epoch 027:    296 / 1732 loss=2.138, loss_v1=0, loss_v2=0, nll_loss=0.909, ntokens=1134.4, nsentences=32, sample_size=1134.4, sample_size_v1=0, sample_size_v2=0, ppl=1.88, wps=604.4, ups=0.53, wpb=1134.4, bsz=32, num_updates=45250, lr=4.12137e-06, gnorm=18.896, clip=100, loss_scale=16, train_wall=19, gb_free=11, wall=85069
2023-05-26 23:01:13 - progress_bar.py[line:272] - INFO: epoch 027:    306 / 1732 loss=2.123, loss_v1=0, loss_v2=0, nll_loss=0.893, ntokens=1078.8, nsentences=32, sample_size=1078.8, sample_size_v1=0, sample_size_v2=0, ppl=1.86, wps=577.3, ups=0.54, wpb=1078.8, bsz=32, num_updates=45260, lr=4.11523e-06, gnorm=19.002, clip=100, loss_scale=32, train_wall=19, gb_free=10.9, wall=85087
2023-05-26 23:01:31 - progress_bar.py[line:272] - INFO: epoch 027:    316 / 1732 loss=2.16, loss_v1=0, loss_v2=0, nll_loss=0.935, ntokens=1033.6, nsentences=32, sample_size=1033.6, sample_size_v1=0, sample_size_v2=0, ppl=1.91, wps=555.2, ups=0.54, wpb=1033.6, bsz=32, num_updates=45270, lr=4.10908e-06, gnorm=22.732, clip=100, loss_scale=32, train_wall=19, gb_free=10.8, wall=85106
2023-05-26 23:01:50 - progress_bar.py[line:272] - INFO: epoch 027:    326 / 1732 loss=2.17, loss_v1=0, loss_v2=0, nll_loss=0.946, ntokens=1006.1, nsentences=32, sample_size=1006.1, sample_size_v1=0, sample_size_v2=0, ppl=1.93, wps=541.9, ups=0.54, wpb=1006.1, bsz=32, num_updates=45280, lr=4.10294e-06, gnorm=22.56, clip=100, loss_scale=32, train_wall=19, gb_free=11.6, wall=85124
2023-05-26 23:02:08 - progress_bar.py[line:272] - INFO: epoch 027:    336 / 1732 loss=2.159, loss_v1=0, loss_v2=0, nll_loss=0.933, ntokens=1005.9, nsentences=32, sample_size=1005.9, sample_size_v1=0, sample_size_v2=0, ppl=1.91, wps=543.8, ups=0.54, wpb=1005.9, bsz=32, num_updates=45290, lr=4.0968e-06, gnorm=20.543, clip=100, loss_scale=32, train_wall=18, gb_free=11.4, wall=85143
2023-05-26 23:02:27 - progress_bar.py[line:272] - INFO: epoch 027:    346 / 1732 loss=2.121, loss_v1=0, loss_v2=0, nll_loss=0.89, ntokens=909.3, nsentences=32, sample_size=909.3, sample_size_v1=0, sample_size_v2=0, ppl=1.85, wps=491.2, ups=0.54, wpb=909.3, bsz=32, num_updates=45300, lr=4.09066e-06, gnorm=22.064, clip=100, loss_scale=32, train_wall=18, gb_free=11.3, wall=85161
2023-05-26 23:02:45 - progress_bar.py[line:272] - INFO: epoch 027:    356 / 1732 loss=2.157, loss_v1=0, loss_v2=0, nll_loss=0.931, ntokens=955.2, nsentences=32, sample_size=955.2, sample_size_v1=0, sample_size_v2=0, ppl=1.91, wps=517.4, ups=0.54, wpb=955.2, bsz=32, num_updates=45310, lr=4.08452e-06, gnorm=23.051, clip=100, loss_scale=32, train_wall=18, gb_free=11.4, wall=85180
2023-05-26 23:03:04 - progress_bar.py[line:272] - INFO: epoch 027:    366 / 1732 loss=2.17, loss_v1=0, loss_v2=0, nll_loss=0.946, ntokens=951.9, nsentences=32, sample_size=951.9, sample_size_v1=0, sample_size_v2=0, ppl=1.93, wps=514.2, ups=0.54, wpb=951.9, bsz=32, num_updates=45320, lr=4.07837e-06, gnorm=23.12, clip=100, loss_scale=32, train_wall=18, gb_free=11.5, wall=85198
2023-05-26 23:03:22 - progress_bar.py[line:272] - INFO: epoch 027:    376 / 1732 loss=2.171, loss_v1=0, loss_v2=0, nll_loss=0.947, ntokens=1015.4, nsentences=32, sample_size=1015.4, sample_size_v1=0, sample_size_v2=0, ppl=1.93, wps=548.6, ups=0.54, wpb=1015.4, bsz=32, num_updates=45330, lr=4.07223e-06, gnorm=22.246, clip=100, loss_scale=32, train_wall=18, gb_free=11.4, wall=85217
2023-05-26 23:03:41 - progress_bar.py[line:272] - INFO: epoch 027:    386 / 1732 loss=2.166, loss_v1=0, loss_v2=0, nll_loss=0.942, ntokens=1063.1, nsentences=32, sample_size=1063.1, sample_size_v1=0, sample_size_v2=0, ppl=1.92, wps=572.8, ups=0.54, wpb=1063.1, bsz=32, num_updates=45340, lr=4.06609e-06, gnorm=20.556, clip=100, loss_scale=32, train_wall=19, gb_free=11.4, wall=85236
2023-05-26 23:03:59 - progress_bar.py[line:272] - INFO: epoch 027:    396 / 1732 loss=2.15, loss_v1=0, loss_v2=0, nll_loss=0.924, ntokens=950.2, nsentences=32, sample_size=950.2, sample_size_v1=0, sample_size_v2=0, ppl=1.9, wps=513.8, ups=0.54, wpb=950.2, bsz=32, num_updates=45350, lr=4.05995e-06, gnorm=22.304, clip=100, loss_scale=32, train_wall=18, gb_free=11.3, wall=85254
2023-05-26 23:04:18 - progress_bar.py[line:272] - INFO: epoch 027:    406 / 1732 loss=2.123, loss_v1=0, loss_v2=0, nll_loss=0.893, ntokens=1066.6, nsentences=32, sample_size=1066.6, sample_size_v1=0, sample_size_v2=0, ppl=1.86, wps=572.2, ups=0.54, wpb=1066.6, bsz=32, num_updates=45360, lr=4.05381e-06, gnorm=18.972, clip=100, loss_scale=32, train_wall=19, gb_free=11.2, wall=85273
2023-05-26 23:04:33 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2023-05-26 23:04:38 - progress_bar.py[line:272] - INFO: epoch 027:    417 / 1732 loss=2.117, loss_v1=0, loss_v2=0, nll_loss=0.887, ntokens=1056.4, nsentences=32, sample_size=1056.4, sample_size_v1=0, sample_size_v2=0, ppl=1.85, wps=517.2, ups=0.49, wpb=1056.4, bsz=32, num_updates=45370, lr=4.04766e-06, gnorm=19.843, clip=100, loss_scale=16, train_wall=20, gb_free=11.6, wall=85293
2023-05-26 23:04:57 - progress_bar.py[line:272] - INFO: epoch 027:    427 / 1732 loss=2.119, loss_v1=0, loss_v2=0, nll_loss=0.888, ntokens=993.5, nsentences=32, sample_size=993.5, sample_size_v1=0, sample_size_v2=0, ppl=1.85, wps=534.8, ups=0.54, wpb=993.5, bsz=32, num_updates=45380, lr=4.04152e-06, gnorm=21.095, clip=100, loss_scale=16, train_wall=19, gb_free=11.2, wall=85312
2023-05-26 23:05:16 - progress_bar.py[line:272] - INFO: epoch 027:    437 / 1732 loss=2.14, loss_v1=0, loss_v2=0, nll_loss=0.911, ntokens=1035.6, nsentences=32, sample_size=1035.6, sample_size_v1=0, sample_size_v2=0, ppl=1.88, wps=558.1, ups=0.54, wpb=1035.6, bsz=32, num_updates=45390, lr=4.03538e-06, gnorm=19.526, clip=100, loss_scale=16, train_wall=19, gb_free=12, wall=85330
2023-05-26 23:05:34 - progress_bar.py[line:272] - INFO: epoch 027:    447 / 1732 loss=2.134, loss_v1=0, loss_v2=0, nll_loss=0.906, ntokens=949, nsentences=32, sample_size=949, sample_size_v1=0, sample_size_v2=0, ppl=1.87, wps=509.2, ups=0.54, wpb=949, bsz=32, num_updates=45400, lr=4.02924e-06, gnorm=19.962, clip=100, loss_scale=16, train_wall=19, gb_free=10.9, wall=85349
2023-05-26 23:05:53 - progress_bar.py[line:272] - INFO: epoch 027:    457 / 1732 loss=2.147, loss_v1=0, loss_v2=0, nll_loss=0.92, ntokens=959.4, nsentences=32, sample_size=959.4, sample_size_v1=0, sample_size_v2=0, ppl=1.89, wps=518.8, ups=0.54, wpb=959.4, bsz=32, num_updates=45410, lr=4.02309e-06, gnorm=21.036, clip=100, loss_scale=16, train_wall=18, gb_free=10.6, wall=85367
2023-05-26 23:06:11 - progress_bar.py[line:272] - INFO: epoch 027:    467 / 1732 loss=2.165, loss_v1=0, loss_v2=0, nll_loss=0.941, ntokens=1054.7, nsentences=32, sample_size=1054.7, sample_size_v1=0, sample_size_v2=0, ppl=1.92, wps=564.3, ups=0.54, wpb=1054.7, bsz=32, num_updates=45420, lr=4.01695e-06, gnorm=20.304, clip=100, loss_scale=16, train_wall=19, gb_free=11.3, wall=85386
2023-05-26 23:06:30 - progress_bar.py[line:272] - INFO: epoch 027:    477 / 1732 loss=2.175, loss_v1=0, loss_v2=0, nll_loss=0.951, ntokens=1051.9, nsentences=32, sample_size=1051.9, sample_size_v1=0, sample_size_v2=0, ppl=1.93, wps=562.2, ups=0.53, wpb=1051.9, bsz=32, num_updates=45430, lr=4.01081e-06, gnorm=22.279, clip=100, loss_scale=16, train_wall=19, gb_free=11.6, wall=85405
2023-05-26 23:06:49 - progress_bar.py[line:272] - INFO: epoch 027:    487 / 1732 loss=2.128, loss_v1=0, loss_v2=0, nll_loss=0.899, ntokens=936.6, nsentences=32, sample_size=936.6, sample_size_v1=0, sample_size_v2=0, ppl=1.86, wps=505.9, ups=0.54, wpb=936.6, bsz=32, num_updates=45440, lr=4.00467e-06, gnorm=21.047, clip=100, loss_scale=16, train_wall=18, gb_free=12.1, wall=85423
2023-05-26 23:07:07 - progress_bar.py[line:272] - INFO: epoch 027:    497 / 1732 loss=2.135, loss_v1=0, loss_v2=0, nll_loss=0.907, ntokens=954.7, nsentences=32, sample_size=954.7, sample_size_v1=0, sample_size_v2=0, ppl=1.87, wps=515.1, ups=0.54, wpb=954.7, bsz=32, num_updates=45450, lr=3.99853e-06, gnorm=21.878, clip=100, loss_scale=16, train_wall=19, gb_free=10.9, wall=85442
2023-05-26 23:07:26 - progress_bar.py[line:272] - INFO: epoch 027:    507 / 1732 loss=2.167, loss_v1=0, loss_v2=0, nll_loss=0.942, ntokens=1006.3, nsentences=32, sample_size=1006.3, sample_size_v1=0, sample_size_v2=0, ppl=1.92, wps=545.1, ups=0.54, wpb=1006.3, bsz=32, num_updates=45460, lr=3.99238e-06, gnorm=21.901, clip=100, loss_scale=16, train_wall=18, gb_free=11.3, wall=85460
2023-05-26 23:07:44 - progress_bar.py[line:272] - INFO: epoch 027:    517 / 1732 loss=2.14, loss_v1=0, loss_v2=0, nll_loss=0.911, ntokens=1047.1, nsentences=32, sample_size=1047.1, sample_size_v1=0, sample_size_v2=0, ppl=1.88, wps=565.8, ups=0.54, wpb=1047.1, bsz=32, num_updates=45470, lr=3.98624e-06, gnorm=18.637, clip=100, loss_scale=16, train_wall=18, gb_free=11.6, wall=85479
2023-05-26 23:08:03 - progress_bar.py[line:272] - INFO: epoch 027:    527 / 1732 loss=2.151, loss_v1=0, loss_v2=0, nll_loss=0.924, ntokens=940.9, nsentences=32, sample_size=940.9, sample_size_v1=0, sample_size_v2=0, ppl=1.9, wps=509.6, ups=0.54, wpb=940.9, bsz=32, num_updates=45480, lr=3.9801e-06, gnorm=22.25, clip=100, loss_scale=16, train_wall=18, gb_free=11.6, wall=85497
2023-05-26 23:08:21 - progress_bar.py[line:272] - INFO: epoch 027:    537 / 1732 loss=2.144, loss_v1=0, loss_v2=0, nll_loss=0.917, ntokens=964.7, nsentences=32, sample_size=964.7, sample_size_v1=0, sample_size_v2=0, ppl=1.89, wps=523, ups=0.54, wpb=964.7, bsz=32, num_updates=45490, lr=3.97396e-06, gnorm=20.482, clip=100, loss_scale=16, train_wall=18, gb_free=11.9, wall=85516
2023-05-26 23:08:40 - progress_bar.py[line:272] - INFO: epoch 027:    547 / 1732 loss=2.171, loss_v1=0, loss_v2=0, nll_loss=0.946, ntokens=1033.6, nsentences=32, sample_size=1033.6, sample_size_v1=0, sample_size_v2=0, ppl=1.93, wps=555.4, ups=0.54, wpb=1033.6, bsz=32, num_updates=45500, lr=3.96782e-06, gnorm=21.349, clip=100, loss_scale=16, train_wall=19, gb_free=11.7, wall=85534
2023-05-26 23:08:58 - progress_bar.py[line:272] - INFO: epoch 027:    557 / 1732 loss=2.177, loss_v1=0, loss_v2=0, nll_loss=0.954, ntokens=1010.2, nsentences=32, sample_size=1010.2, sample_size_v1=0, sample_size_v2=0, ppl=1.94, wps=544.5, ups=0.54, wpb=1010.2, bsz=32, num_updates=45510, lr=3.96167e-06, gnorm=21.339, clip=100, loss_scale=16, train_wall=19, gb_free=11.8, wall=85553
2023-05-26 23:09:17 - progress_bar.py[line:272] - INFO: epoch 027:    567 / 1732 loss=2.18, loss_v1=0, loss_v2=0, nll_loss=0.957, ntokens=1004.9, nsentences=32, sample_size=1004.9, sample_size_v1=0, sample_size_v2=0, ppl=1.94, wps=539.6, ups=0.54, wpb=1004.9, bsz=32, num_updates=45520, lr=3.95553e-06, gnorm=22.834, clip=100, loss_scale=16, train_wall=19, gb_free=11.7, wall=85572
2023-05-26 23:09:36 - progress_bar.py[line:272] - INFO: epoch 027:    577 / 1732 loss=2.155, loss_v1=0, loss_v2=0, nll_loss=0.929, ntokens=1011.7, nsentences=32, sample_size=1011.7, sample_size_v1=0, sample_size_v2=0, ppl=1.9, wps=541.3, ups=0.54, wpb=1011.7, bsz=32, num_updates=45530, lr=3.94939e-06, gnorm=20.819, clip=100, loss_scale=16, train_wall=19, gb_free=11.6, wall=85590
2023-05-26 23:09:54 - progress_bar.py[line:272] - INFO: epoch 027:    587 / 1732 loss=2.166, loss_v1=0, loss_v2=0, nll_loss=0.94, ntokens=962.2, nsentences=32, sample_size=962.2, sample_size_v1=0, sample_size_v2=0, ppl=1.92, wps=516, ups=0.54, wpb=962.2, bsz=32, num_updates=45540, lr=3.94325e-06, gnorm=22.098, clip=100, loss_scale=16, train_wall=19, gb_free=12, wall=85609
2023-05-26 23:10:13 - progress_bar.py[line:272] - INFO: epoch 027:    597 / 1732 loss=2.11, loss_v1=0, loss_v2=0, nll_loss=0.879, ntokens=975.4, nsentences=32, sample_size=975.4, sample_size_v1=0, sample_size_v2=0, ppl=1.84, wps=522.7, ups=0.54, wpb=975.4, bsz=32, num_updates=45550, lr=3.9371e-06, gnorm=19.552, clip=100, loss_scale=16, train_wall=19, gb_free=11.7, wall=85628
2023-05-26 23:10:31 - progress_bar.py[line:272] - INFO: epoch 027:    607 / 1732 loss=2.15, loss_v1=0, loss_v2=0, nll_loss=0.923, ntokens=882.8, nsentences=32, sample_size=882.8, sample_size_v1=0, sample_size_v2=0, ppl=1.9, wps=475.7, ups=0.54, wpb=882.8, bsz=32, num_updates=45560, lr=3.93096e-06, gnorm=22.533, clip=100, loss_scale=16, train_wall=19, gb_free=11.3, wall=85646
2023-05-26 23:10:50 - progress_bar.py[line:272] - INFO: epoch 027:    617 / 1732 loss=2.155, loss_v1=0, loss_v2=0, nll_loss=0.93, ntokens=866.1, nsentences=32, sample_size=866.1, sample_size_v1=0, sample_size_v2=0, ppl=1.9, wps=469.1, ups=0.54, wpb=866.1, bsz=32, num_updates=45570, lr=3.92482e-06, gnorm=24.178, clip=100, loss_scale=16, train_wall=18, gb_free=11.5, wall=85665
2023-05-26 23:11:08 - progress_bar.py[line:272] - INFO: epoch 027:    627 / 1732 loss=2.139, loss_v1=0, loss_v2=0, nll_loss=0.911, ntokens=930.6, nsentences=32, sample_size=930.6, sample_size_v1=0, sample_size_v2=0, ppl=1.88, wps=505.4, ups=0.54, wpb=930.6, bsz=32, num_updates=45580, lr=3.91868e-06, gnorm=21.425, clip=100, loss_scale=16, train_wall=18, gb_free=11.9, wall=85683
2023-05-26 23:11:27 - progress_bar.py[line:272] - INFO: epoch 027:    637 / 1732 loss=2.164, loss_v1=0, loss_v2=0, nll_loss=0.939, ntokens=914.3, nsentences=32, sample_size=914.3, sample_size_v1=0, sample_size_v2=0, ppl=1.92, wps=497, ups=0.54, wpb=914.3, bsz=32, num_updates=45590, lr=3.91254e-06, gnorm=22.163, clip=100, loss_scale=16, train_wall=18, gb_free=11.6, wall=85701
2023-05-26 23:11:45 - progress_bar.py[line:272] - INFO: epoch 027:    647 / 1732 loss=2.149, loss_v1=0, loss_v2=0, nll_loss=0.922, ntokens=980.8, nsentences=32, sample_size=980.8, sample_size_v1=0, sample_size_v2=0, ppl=1.89, wps=530.4, ups=0.54, wpb=980.8, bsz=32, num_updates=45600, lr=3.90639e-06, gnorm=21.944, clip=100, loss_scale=16, train_wall=18, gb_free=11.8, wall=85720
2023-05-26 23:12:04 - progress_bar.py[line:272] - INFO: epoch 027:    657 / 1732 loss=2.149, loss_v1=0, loss_v2=0, nll_loss=0.923, ntokens=894.4, nsentences=32, sample_size=894.4, sample_size_v1=0, sample_size_v2=0, ppl=1.9, wps=488.8, ups=0.55, wpb=894.4, bsz=32, num_updates=45610, lr=3.90025e-06, gnorm=22.815, clip=100, loss_scale=16, train_wall=18, gb_free=11.8, wall=85738
2023-05-26 23:12:22 - progress_bar.py[line:272] - INFO: epoch 027:    667 / 1732 loss=2.142, loss_v1=0, loss_v2=0, nll_loss=0.915, ntokens=903.9, nsentences=32, sample_size=903.9, sample_size_v1=0, sample_size_v2=0, ppl=1.89, wps=491.3, ups=0.54, wpb=903.9, bsz=32, num_updates=45620, lr=3.89411e-06, gnorm=22.635, clip=100, loss_scale=16, train_wall=18, gb_free=11.5, wall=85757
2023-05-26 23:12:40 - progress_bar.py[line:272] - INFO: epoch 027:    677 / 1732 loss=2.172, loss_v1=0, loss_v2=0, nll_loss=0.948, ntokens=985.3, nsentences=32, sample_size=985.3, sample_size_v1=0, sample_size_v2=0, ppl=1.93, wps=531.9, ups=0.54, wpb=985.3, bsz=32, num_updates=45630, lr=3.88797e-06, gnorm=22.127, clip=100, loss_scale=16, train_wall=18, gb_free=11.8, wall=85775
2023-05-26 23:12:59 - progress_bar.py[line:272] - INFO: epoch 027:    687 / 1732 loss=2.156, loss_v1=0, loss_v2=0, nll_loss=0.93, ntokens=943.2, nsentences=32, sample_size=943.2, sample_size_v1=0, sample_size_v2=0, ppl=1.91, wps=510.8, ups=0.54, wpb=943.2, bsz=32, num_updates=45640, lr=3.88183e-06, gnorm=23.065, clip=100, loss_scale=16, train_wall=18, gb_free=11.9, wall=85794
2023-05-26 23:13:18 - progress_bar.py[line:272] - INFO: epoch 027:    697 / 1732 loss=2.151, loss_v1=0, loss_v2=0, nll_loss=0.924, ntokens=1005.6, nsentences=32, sample_size=1005.6, sample_size_v1=0, sample_size_v2=0, ppl=1.9, wps=538.2, ups=0.54, wpb=1005.6, bsz=32, num_updates=45650, lr=3.87568e-06, gnorm=20.556, clip=100, loss_scale=16, train_wall=19, gb_free=10.9, wall=85812
2023-05-26 23:13:36 - progress_bar.py[line:272] - INFO: epoch 027:    707 / 1732 loss=2.121, loss_v1=0, loss_v2=0, nll_loss=0.891, ntokens=903.4, nsentences=32, sample_size=903.4, sample_size_v1=0, sample_size_v2=0, ppl=1.85, wps=491.1, ups=0.54, wpb=903.4, bsz=32, num_updates=45660, lr=3.86954e-06, gnorm=21.71, clip=100, loss_scale=16, train_wall=18, gb_free=11.6, wall=85831
2023-05-26 23:13:54 - progress_bar.py[line:272] - INFO: epoch 027:    717 / 1732 loss=2.131, loss_v1=0, loss_v2=0, nll_loss=0.902, ntokens=882.7, nsentences=32, sample_size=882.7, sample_size_v1=0, sample_size_v2=0, ppl=1.87, wps=479.5, ups=0.54, wpb=882.7, bsz=32, num_updates=45670, lr=3.8634e-06, gnorm=21.571, clip=100, loss_scale=16, train_wall=18, gb_free=11.6, wall=85849
2023-05-26 23:14:13 - progress_bar.py[line:272] - INFO: epoch 027:    727 / 1732 loss=2.116, loss_v1=0, loss_v2=0, nll_loss=0.885, ntokens=909.8, nsentences=32, sample_size=909.8, sample_size_v1=0, sample_size_v2=0, ppl=1.85, wps=493.3, ups=0.54, wpb=909.8, bsz=32, num_updates=45680, lr=3.85726e-06, gnorm=21.698, clip=100, loss_scale=16, train_wall=18, gb_free=11.9, wall=85868
2023-05-26 23:14:31 - progress_bar.py[line:272] - INFO: epoch 027:    737 / 1732 loss=2.135, loss_v1=0, loss_v2=0, nll_loss=0.906, ntokens=998.8, nsentences=32, sample_size=998.8, sample_size_v1=0, sample_size_v2=0, ppl=1.87, wps=541.9, ups=0.54, wpb=998.8, bsz=32, num_updates=45690, lr=3.85111e-06, gnorm=19.659, clip=100, loss_scale=16, train_wall=18, gb_free=11.5, wall=85886
2023-05-26 23:14:50 - progress_bar.py[line:272] - INFO: epoch 027:    747 / 1732 loss=2.117, loss_v1=0, loss_v2=0, nll_loss=0.885, ntokens=980.5, nsentences=32, sample_size=980.5, sample_size_v1=0, sample_size_v2=0, ppl=1.85, wps=526.2, ups=0.54, wpb=980.5, bsz=32, num_updates=45700, lr=3.84497e-06, gnorm=20.237, clip=100, loss_scale=16, train_wall=19, gb_free=11.3, wall=85905
2023-05-26 23:15:08 - progress_bar.py[line:272] - INFO: epoch 027:    757 / 1732 loss=2.129, loss_v1=0, loss_v2=0, nll_loss=0.899, ntokens=949.2, nsentences=32, sample_size=949.2, sample_size_v1=0, sample_size_v2=0, ppl=1.87, wps=514.2, ups=0.54, wpb=949.2, bsz=32, num_updates=45710, lr=3.83883e-06, gnorm=20.219, clip=100, loss_scale=16, train_wall=18, gb_free=11.6, wall=85923
2023-05-26 23:15:27 - progress_bar.py[line:272] - INFO: epoch 027:    767 / 1732 loss=2.137, loss_v1=0, loss_v2=0, nll_loss=0.909, ntokens=941.7, nsentences=32, sample_size=941.7, sample_size_v1=0, sample_size_v2=0, ppl=1.88, wps=511.2, ups=0.54, wpb=941.7, bsz=32, num_updates=45720, lr=3.83269e-06, gnorm=20.569, clip=100, loss_scale=16, train_wall=18, gb_free=11.9, wall=85941
2023-05-26 23:15:45 - progress_bar.py[line:272] - INFO: epoch 027:    777 / 1732 loss=2.135, loss_v1=0, loss_v2=0, nll_loss=0.908, ntokens=1028.6, nsentences=32, sample_size=1028.6, sample_size_v1=0, sample_size_v2=0, ppl=1.88, wps=554.3, ups=0.54, wpb=1028.6, bsz=32, num_updates=45730, lr=3.82655e-06, gnorm=20.927, clip=100, loss_scale=16, train_wall=19, gb_free=11.8, wall=85960
2023-05-26 23:16:04 - progress_bar.py[line:272] - INFO: epoch 027:    787 / 1732 loss=2.154, loss_v1=0, loss_v2=0, nll_loss=0.927, ntokens=1016.6, nsentences=32, sample_size=1016.6, sample_size_v1=0, sample_size_v2=0, ppl=1.9, wps=550.5, ups=0.54, wpb=1016.6, bsz=32, num_updates=45740, lr=3.8204e-06, gnorm=21.49, clip=100, loss_scale=16, train_wall=18, gb_free=11.3, wall=85979
2023-05-26 23:16:22 - progress_bar.py[line:272] - INFO: epoch 027:    797 / 1732 loss=2.158, loss_v1=0, loss_v2=0, nll_loss=0.933, ntokens=1038, nsentences=32, sample_size=1038, sample_size_v1=0, sample_size_v2=0, ppl=1.91, wps=560.4, ups=0.54, wpb=1038, bsz=32, num_updates=45750, lr=3.81426e-06, gnorm=21.009, clip=100, loss_scale=16, train_wall=18, gb_free=11.6, wall=85997
2023-05-26 23:16:41 - progress_bar.py[line:272] - INFO: epoch 027:    807 / 1732 loss=2.14, loss_v1=0, loss_v2=0, nll_loss=0.911, ntokens=915, nsentences=32, sample_size=915, sample_size_v1=0, sample_size_v2=0, ppl=1.88, wps=497.2, ups=0.54, wpb=915, bsz=32, num_updates=45760, lr=3.80812e-06, gnorm=21.651, clip=100, loss_scale=16, train_wall=18, gb_free=11.4, wall=86015
2023-05-26 23:16:59 - progress_bar.py[line:272] - INFO: epoch 027:    817 / 1732 loss=2.157, loss_v1=0, loss_v2=0, nll_loss=0.933, ntokens=917.4, nsentences=32, sample_size=917.4, sample_size_v1=0, sample_size_v2=0, ppl=1.91, wps=495.9, ups=0.54, wpb=917.4, bsz=32, num_updates=45770, lr=3.80198e-06, gnorm=23.08, clip=100, loss_scale=16, train_wall=18, gb_free=11.7, wall=86034
2023-05-26 23:17:18 - progress_bar.py[line:272] - INFO: epoch 027:    827 / 1732 loss=2.143, loss_v1=0, loss_v2=0, nll_loss=0.915, ntokens=930.6, nsentences=32, sample_size=930.6, sample_size_v1=0, sample_size_v2=0, ppl=1.89, wps=502.7, ups=0.54, wpb=930.6, bsz=32, num_updates=45780, lr=3.79584e-06, gnorm=22.802, clip=100, loss_scale=16, train_wall=18, gb_free=11.7, wall=86052
2023-05-26 23:17:36 - progress_bar.py[line:272] - INFO: epoch 027:    837 / 1732 loss=2.149, loss_v1=0, loss_v2=0, nll_loss=0.922, ntokens=894.5, nsentences=32, sample_size=894.5, sample_size_v1=0, sample_size_v2=0, ppl=1.89, wps=487.3, ups=0.54, wpb=894.5, bsz=32, num_updates=45790, lr=3.78969e-06, gnorm=21.958, clip=100, loss_scale=16, train_wall=18, gb_free=11.7, wall=86071
2023-05-26 23:17:55 - progress_bar.py[line:272] - INFO: epoch 027:    847 / 1732 loss=2.132, loss_v1=0, loss_v2=0, nll_loss=0.902, ntokens=1012.6, nsentences=32, sample_size=1012.6, sample_size_v1=0, sample_size_v2=0, ppl=1.87, wps=547.7, ups=0.54, wpb=1012.6, bsz=32, num_updates=45800, lr=3.78355e-06, gnorm=21.119, clip=100, loss_scale=16, train_wall=18, gb_free=10.6, wall=86089
2023-05-26 23:18:13 - progress_bar.py[line:272] - INFO: epoch 027:    857 / 1732 loss=2.13, loss_v1=0, loss_v2=0, nll_loss=0.9, ntokens=920, nsentences=32, sample_size=920, sample_size_v1=0, sample_size_v2=0, ppl=1.87, wps=498.4, ups=0.54, wpb=920, bsz=32, num_updates=45810, lr=3.77741e-06, gnorm=21.98, clip=100, loss_scale=16, train_wall=18, gb_free=11.7, wall=86108
2023-05-26 23:18:32 - progress_bar.py[line:272] - INFO: epoch 027:    867 / 1732 loss=2.15, loss_v1=0, loss_v2=0, nll_loss=0.924, ntokens=979.9, nsentences=32, sample_size=979.9, sample_size_v1=0, sample_size_v2=0, ppl=1.9, wps=530, ups=0.54, wpb=979.9, bsz=32, num_updates=45820, lr=3.77127e-06, gnorm=20.766, clip=100, loss_scale=16, train_wall=18, gb_free=11.3, wall=86126
2023-05-26 23:18:50 - progress_bar.py[line:272] - INFO: epoch 027:    877 / 1732 loss=2.085, loss_v1=0, loss_v2=0, nll_loss=0.851, ntokens=994.5, nsentences=32, sample_size=994.5, sample_size_v1=0, sample_size_v2=0, ppl=1.8, wps=535.6, ups=0.54, wpb=994.5, bsz=32, num_updates=45830, lr=3.76512e-06, gnorm=19.588, clip=100, loss_scale=16, train_wall=19, gb_free=11.7, wall=86145
2023-05-26 23:19:09 - progress_bar.py[line:272] - INFO: epoch 027:    887 / 1732 loss=2.099, loss_v1=0, loss_v2=0, nll_loss=0.867, ntokens=982, nsentences=32, sample_size=982, sample_size_v1=0, sample_size_v2=0, ppl=1.82, wps=528, ups=0.54, wpb=982, bsz=32, num_updates=45840, lr=3.75898e-06, gnorm=21.912, clip=100, loss_scale=16, train_wall=19, gb_free=11.2, wall=86163
2023-05-26 23:19:27 - progress_bar.py[line:272] - INFO: epoch 027:    897 / 1732 loss=2.089, loss_v1=0, loss_v2=0, nll_loss=0.856, ntokens=1034.6, nsentences=32, sample_size=1034.6, sample_size_v1=0, sample_size_v2=0, ppl=1.81, wps=557.9, ups=0.54, wpb=1034.6, bsz=32, num_updates=45850, lr=3.75284e-06, gnorm=19.964, clip=100, loss_scale=16, train_wall=19, gb_free=11.5, wall=86182
2023-05-26 23:19:46 - progress_bar.py[line:272] - INFO: epoch 027:    907 / 1732 loss=2.102, loss_v1=0, loss_v2=0, nll_loss=0.87, ntokens=1016.8, nsentences=32, sample_size=1016.8, sample_size_v1=0, sample_size_v2=0, ppl=1.83, wps=547.4, ups=0.54, wpb=1016.8, bsz=32, num_updates=45860, lr=3.7467e-06, gnorm=18.092, clip=100, loss_scale=16, train_wall=19, gb_free=11.6, wall=86201
2023-05-26 23:20:04 - progress_bar.py[line:272] - INFO: epoch 027:    917 / 1732 loss=2.18, loss_v1=0, loss_v2=0, nll_loss=0.958, ntokens=936.4, nsentences=32, sample_size=936.4, sample_size_v1=0, sample_size_v2=0, ppl=1.94, wps=507.3, ups=0.54, wpb=936.4, bsz=32, num_updates=45870, lr=3.74056e-06, gnorm=23.694, clip=100, loss_scale=16, train_wall=18, gb_free=11.8, wall=86219
2023-05-26 23:20:23 - progress_bar.py[line:272] - INFO: epoch 027:    927 / 1732 loss=2.113, loss_v1=0, loss_v2=0, nll_loss=0.883, ntokens=1039.7, nsentences=32, sample_size=1039.7, sample_size_v1=0, sample_size_v2=0, ppl=1.84, wps=556.7, ups=0.54, wpb=1039.7, bsz=32, num_updates=45880, lr=3.73441e-06, gnorm=20.249, clip=100, loss_scale=32, train_wall=19, gb_free=11.5, wall=86238
2023-05-26 23:20:42 - progress_bar.py[line:272] - INFO: epoch 027:    937 / 1732 loss=2.139, loss_v1=0, loss_v2=0, nll_loss=0.91, ntokens=1061.1, nsentences=32, sample_size=1061.1, sample_size_v1=0, sample_size_v2=0, ppl=1.88, wps=565.3, ups=0.53, wpb=1061.1, bsz=32, num_updates=45890, lr=3.72827e-06, gnorm=20.323, clip=100, loss_scale=32, train_wall=19, gb_free=11.5, wall=86256
2023-05-26 23:21:01 - progress_bar.py[line:272] - INFO: epoch 027:    947 / 1732 loss=2.155, loss_v1=0, loss_v2=0, nll_loss=0.93, ntokens=1042.4, nsentences=32, sample_size=1042.4, sample_size_v1=0, sample_size_v2=0, ppl=1.91, wps=552.8, ups=0.53, wpb=1042.4, bsz=32, num_updates=45900, lr=3.72213e-06, gnorm=21.574, clip=100, loss_scale=32, train_wall=19, gb_free=11.2, wall=86275
2023-05-26 23:21:19 - progress_bar.py[line:272] - INFO: epoch 027:    957 / 1732 loss=2.143, loss_v1=0, loss_v2=0, nll_loss=0.917, ntokens=1046.8, nsentences=32, sample_size=1046.8, sample_size_v1=0, sample_size_v2=0, ppl=1.89, wps=558.9, ups=0.53, wpb=1046.8, bsz=32, num_updates=45910, lr=3.71599e-06, gnorm=19.941, clip=100, loss_scale=32, train_wall=19, gb_free=11.1, wall=86294
2023-05-26 23:21:38 - progress_bar.py[line:272] - INFO: epoch 027:    967 / 1732 loss=2.147, loss_v1=0, loss_v2=0, nll_loss=0.92, ntokens=1036.4, nsentences=32, sample_size=1036.4, sample_size_v1=0, sample_size_v2=0, ppl=1.89, wps=553.5, ups=0.53, wpb=1036.4, bsz=32, num_updates=45920, lr=3.70985e-06, gnorm=21.545, clip=100, loss_scale=32, train_wall=19, gb_free=11.3, wall=86313
2023-05-26 23:21:57 - progress_bar.py[line:272] - INFO: epoch 027:    977 / 1732 loss=2.112, loss_v1=0, loss_v2=0, nll_loss=0.881, ntokens=1035.2, nsentences=32, sample_size=1035.2, sample_size_v1=0, sample_size_v2=0, ppl=1.84, wps=548.8, ups=0.53, wpb=1035.2, bsz=32, num_updates=45930, lr=3.7037e-06, gnorm=19.053, clip=100, loss_scale=32, train_wall=19, gb_free=10.4, wall=86332
2023-05-26 23:22:16 - progress_bar.py[line:272] - INFO: epoch 027:    987 / 1732 loss=2.127, loss_v1=0, loss_v2=0, nll_loss=0.899, ntokens=1020.1, nsentences=32, sample_size=1020.1, sample_size_v1=0, sample_size_v2=0, ppl=1.86, wps=541, ups=0.53, wpb=1020.1, bsz=32, num_updates=45940, lr=3.69756e-06, gnorm=20.186, clip=100, loss_scale=32, train_wall=19, gb_free=11.3, wall=86351
2023-05-26 23:22:35 - progress_bar.py[line:272] - INFO: epoch 027:    997 / 1732 loss=2.133, loss_v1=0, loss_v2=0, nll_loss=0.903, ntokens=1032.4, nsentences=32, sample_size=1032.4, sample_size_v1=0, sample_size_v2=0, ppl=1.87, wps=552.4, ups=0.54, wpb=1032.4, bsz=32, num_updates=45950, lr=3.69142e-06, gnorm=20.19, clip=100, loss_scale=32, train_wall=19, gb_free=11.7, wall=86369
2023-05-26 23:22:53 - progress_bar.py[line:272] - INFO: epoch 027:   1007 / 1732 loss=2.123, loss_v1=0, loss_v2=0, nll_loss=0.894, ntokens=1018.9, nsentences=32, sample_size=1018.9, sample_size_v1=0, sample_size_v2=0, ppl=1.86, wps=545.9, ups=0.54, wpb=1018.9, bsz=32, num_updates=45960, lr=3.68528e-06, gnorm=21.226, clip=100, loss_scale=32, train_wall=19, gb_free=11.3, wall=86388
2023-05-26 23:23:12 - progress_bar.py[line:272] - INFO: epoch 027:   1017 / 1732 loss=2.11, loss_v1=0, loss_v2=0, nll_loss=0.878, ntokens=1024.8, nsentences=32, sample_size=1024.8, sample_size_v1=0, sample_size_v2=0, ppl=1.84, wps=549.4, ups=0.54, wpb=1024.8, bsz=32, num_updates=45970, lr=3.67914e-06, gnorm=18.726, clip=100, loss_scale=32, train_wall=19, gb_free=10.5, wall=86407
2023-05-26 23:23:31 - progress_bar.py[line:272] - INFO: epoch 027:   1027 / 1732 loss=2.151, loss_v1=0, loss_v2=0, nll_loss=0.925, ntokens=1051.5, nsentences=32, sample_size=1051.5, sample_size_v1=0, sample_size_v2=0, ppl=1.9, wps=558.9, ups=0.53, wpb=1051.5, bsz=32, num_updates=45980, lr=3.67299e-06, gnorm=19.412, clip=100, loss_scale=32, train_wall=19, gb_free=11.3, wall=86425
2023-05-26 23:23:50 - progress_bar.py[line:272] - INFO: epoch 027:   1037 / 1732 loss=2.115, loss_v1=0, loss_v2=0, nll_loss=0.883, ntokens=1129.2, nsentences=32, sample_size=1129.2, sample_size_v1=0, sample_size_v2=0, ppl=1.84, wps=596.8, ups=0.53, wpb=1129.2, bsz=32, num_updates=45990, lr=3.66685e-06, gnorm=18.537, clip=100, loss_scale=32, train_wall=19, gb_free=11.5, wall=86444
2023-05-26 23:24:08 - progress_bar.py[line:272] - INFO: epoch 027:   1047 / 1732 loss=2.131, loss_v1=0, loss_v2=0, nll_loss=0.901, ntokens=1024.6, nsentences=32, sample_size=1024.6, sample_size_v1=0, sample_size_v2=0, ppl=1.87, wps=546.6, ups=0.53, wpb=1024.6, bsz=32, num_updates=46000, lr=3.66071e-06, gnorm=20.438, clip=100, loss_scale=32, train_wall=19, gb_free=11.5, wall=86463
2023-05-26 23:24:27 - progress_bar.py[line:272] - INFO: epoch 027:   1057 / 1732 loss=2.14, loss_v1=0, loss_v2=0, nll_loss=0.912, ntokens=1089.7, nsentences=32, sample_size=1089.7, sample_size_v1=0, sample_size_v2=0, ppl=1.88, wps=580.5, ups=0.53, wpb=1089.7, bsz=32, num_updates=46010, lr=3.65457e-06, gnorm=19.499, clip=100, loss_scale=32, train_wall=19, gb_free=10.5, wall=86482
2023-05-26 23:24:46 - progress_bar.py[line:272] - INFO: epoch 027:   1067 / 1732 loss=2.116, loss_v1=0, loss_v2=0, nll_loss=0.884, ntokens=1006.5, nsentences=32, sample_size=1006.5, sample_size_v1=0, sample_size_v2=0, ppl=1.84, wps=539.3, ups=0.54, wpb=1006.5, bsz=32, num_updates=46020, lr=3.64842e-06, gnorm=19.105, clip=100, loss_scale=32, train_wall=19, gb_free=11.4, wall=86500
2023-05-26 23:25:05 - progress_bar.py[line:272] - INFO: epoch 027:   1077 / 1732 loss=2.149, loss_v1=0, loss_v2=0, nll_loss=0.922, ntokens=990.3, nsentences=32, sample_size=990.3, sample_size_v1=0, sample_size_v2=0, ppl=1.89, wps=525.8, ups=0.53, wpb=990.3, bsz=32, num_updates=46030, lr=3.64228e-06, gnorm=22.453, clip=100, loss_scale=32, train_wall=19, gb_free=11.8, wall=86519
2023-05-26 23:25:24 - progress_bar.py[line:272] - INFO: epoch 027:   1087 / 1732 loss=2.137, loss_v1=0, loss_v2=0, nll_loss=0.909, ntokens=1071.1, nsentences=32, sample_size=1071.1, sample_size_v1=0, sample_size_v2=0, ppl=1.88, wps=567.5, ups=0.53, wpb=1071.1, bsz=32, num_updates=46040, lr=3.63614e-06, gnorm=19.762, clip=100, loss_scale=32, train_wall=19, gb_free=11.8, wall=86538
2023-05-26 23:25:42 - progress_bar.py[line:272] - INFO: epoch 027:   1097 / 1732 loss=2.14, loss_v1=0, loss_v2=0, nll_loss=0.911, ntokens=1042.6, nsentences=32, sample_size=1042.6, sample_size_v1=0, sample_size_v2=0, ppl=1.88, wps=556.7, ups=0.53, wpb=1042.6, bsz=32, num_updates=46050, lr=3.63e-06, gnorm=20.251, clip=100, loss_scale=32, train_wall=19, gb_free=11.9, wall=86557
2023-05-26 23:26:01 - progress_bar.py[line:272] - INFO: epoch 027:   1107 / 1732 loss=2.127, loss_v1=0, loss_v2=0, nll_loss=0.896, ntokens=1075.5, nsentences=32, sample_size=1075.5, sample_size_v1=0, sample_size_v2=0, ppl=1.86, wps=570.1, ups=0.53, wpb=1075.5, bsz=32, num_updates=46060, lr=3.62386e-06, gnorm=18.959, clip=100, loss_scale=32, train_wall=19, gb_free=11, wall=86576
2023-05-26 23:26:20 - progress_bar.py[line:272] - INFO: epoch 027:   1117 / 1732 loss=2.13, loss_v1=0, loss_v2=0, nll_loss=0.902, ntokens=943.9, nsentences=32, sample_size=943.9, sample_size_v1=0, sample_size_v2=0, ppl=1.87, wps=503.8, ups=0.53, wpb=943.9, bsz=32, num_updates=46070, lr=3.61771e-06, gnorm=21.952, clip=100, loss_scale=32, train_wall=19, gb_free=11.3, wall=86595
2023-05-26 23:26:29 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2023-05-26 23:26:40 - progress_bar.py[line:272] - INFO: epoch 027:   1128 / 1732 loss=2.131, loss_v1=0, loss_v2=0, nll_loss=0.902, ntokens=1010.8, nsentences=32, sample_size=1010.8, sample_size_v1=0, sample_size_v2=0, ppl=1.87, wps=490, ups=0.48, wpb=1010.8, bsz=32, num_updates=46080, lr=3.61157e-06, gnorm=20.015, clip=100, loss_scale=16, train_wall=21, gb_free=10.7, wall=86615
2023-05-26 23:26:59 - progress_bar.py[line:272] - INFO: epoch 027:   1138 / 1732 loss=2.115, loss_v1=0, loss_v2=0, nll_loss=0.884, ntokens=989.2, nsentences=32, sample_size=989.2, sample_size_v1=0, sample_size_v2=0, ppl=1.84, wps=529.2, ups=0.54, wpb=989.2, bsz=32, num_updates=46090, lr=3.60543e-06, gnorm=21.079, clip=100, loss_scale=16, train_wall=19, gb_free=11.6, wall=86634
2023-05-26 23:27:18 - progress_bar.py[line:272] - INFO: epoch 027:   1148 / 1732 loss=2.125, loss_v1=0, loss_v2=0, nll_loss=0.894, ntokens=1007.7, nsentences=32, sample_size=1007.7, sample_size_v1=0, sample_size_v2=0, ppl=1.86, wps=538.6, ups=0.53, wpb=1007.7, bsz=32, num_updates=46100, lr=3.59929e-06, gnorm=20.531, clip=100, loss_scale=16, train_wall=19, gb_free=11.5, wall=86653
2023-05-26 23:27:37 - progress_bar.py[line:272] - INFO: epoch 027:   1158 / 1732 loss=2.101, loss_v1=0, loss_v2=0, nll_loss=0.868, ntokens=1016, nsentences=32, sample_size=1016, sample_size_v1=0, sample_size_v2=0, ppl=1.82, wps=541, ups=0.53, wpb=1016, bsz=32, num_updates=46110, lr=3.59315e-06, gnorm=20.092, clip=100, loss_scale=16, train_wall=19, gb_free=10.8, wall=86671
2023-05-26 23:27:55 - progress_bar.py[line:272] - INFO: epoch 027:   1168 / 1732 loss=2.119, loss_v1=0, loss_v2=0, nll_loss=0.889, ntokens=1020.6, nsentences=32, sample_size=1020.6, sample_size_v1=0, sample_size_v2=0, ppl=1.85, wps=543.7, ups=0.53, wpb=1020.6, bsz=32, num_updates=46120, lr=3.587e-06, gnorm=21.209, clip=100, loss_scale=16, train_wall=19, gb_free=10.9, wall=86690
2023-05-26 23:28:14 - progress_bar.py[line:272] - INFO: epoch 027:   1178 / 1732 loss=2.112, loss_v1=0, loss_v2=0, nll_loss=0.88, ntokens=1067, nsentences=32, sample_size=1067, sample_size_v1=0, sample_size_v2=0, ppl=1.84, wps=569.1, ups=0.53, wpb=1067, bsz=32, num_updates=46130, lr=3.58086e-06, gnorm=20.202, clip=100, loss_scale=16, train_wall=19, gb_free=11.6, wall=86709
2023-05-26 23:28:33 - progress_bar.py[line:272] - INFO: epoch 027:   1188 / 1732 loss=2.108, loss_v1=0, loss_v2=0, nll_loss=0.877, ntokens=963.5, nsentences=32, sample_size=963.5, sample_size_v1=0, sample_size_v2=0, ppl=1.84, wps=515.4, ups=0.53, wpb=963.5, bsz=32, num_updates=46140, lr=3.57472e-06, gnorm=20.302, clip=100, loss_scale=16, train_wall=19, gb_free=11.1, wall=86728
2023-05-26 23:28:52 - progress_bar.py[line:272] - INFO: epoch 027:   1198 / 1732 loss=2.118, loss_v1=0, loss_v2=0, nll_loss=0.887, ntokens=1123.7, nsentences=32, sample_size=1123.7, sample_size_v1=0, sample_size_v2=0, ppl=1.85, wps=596.5, ups=0.53, wpb=1123.7, bsz=32, num_updates=46150, lr=3.56858e-06, gnorm=18.013, clip=100, loss_scale=16, train_wall=19, gb_free=11.2, wall=86746
2023-05-26 23:29:11 - progress_bar.py[line:272] - INFO: epoch 027:   1208 / 1732 loss=2.099, loss_v1=0, loss_v2=0, nll_loss=0.866, ntokens=1088.9, nsentences=32, sample_size=1088.9, sample_size_v1=0, sample_size_v2=0, ppl=1.82, wps=575.4, ups=0.53, wpb=1088.9, bsz=32, num_updates=46160, lr=3.56243e-06, gnorm=19.599, clip=100, loss_scale=16, train_wall=19, gb_free=10.6, wall=86765
2023-05-26 23:29:29 - progress_bar.py[line:272] - INFO: epoch 027:   1218 / 1732 loss=2.143, loss_v1=0, loss_v2=0, nll_loss=0.916, ntokens=1016, nsentences=32, sample_size=1016, sample_size_v1=0, sample_size_v2=0, ppl=1.89, wps=543.7, ups=0.54, wpb=1016, bsz=32, num_updates=46170, lr=3.55629e-06, gnorm=20.786, clip=100, loss_scale=16, train_wall=19, gb_free=11.6, wall=86784
2023-05-26 23:29:48 - progress_bar.py[line:272] - INFO: epoch 027:   1228 / 1732 loss=2.132, loss_v1=0, loss_v2=0, nll_loss=0.903, ntokens=1018.6, nsentences=32, sample_size=1018.6, sample_size_v1=0, sample_size_v2=0, ppl=1.87, wps=544.1, ups=0.53, wpb=1018.6, bsz=32, num_updates=46180, lr=3.55015e-06, gnorm=20.133, clip=100, loss_scale=16, train_wall=19, gb_free=11.5, wall=86803
2023-05-26 23:30:07 - progress_bar.py[line:272] - INFO: epoch 027:   1238 / 1732 loss=2.093, loss_v1=0, loss_v2=0, nll_loss=0.86, ntokens=1070.1, nsentences=32, sample_size=1070.1, sample_size_v1=0, sample_size_v2=0, ppl=1.81, wps=567.5, ups=0.53, wpb=1070.1, bsz=32, num_updates=46190, lr=3.54401e-06, gnorm=19.064, clip=100, loss_scale=16, train_wall=19, gb_free=11.2, wall=86822
2023-05-26 23:30:26 - progress_bar.py[line:272] - INFO: epoch 027:   1248 / 1732 loss=2.085, loss_v1=0, loss_v2=0, nll_loss=0.85, ntokens=1083.3, nsentences=32, sample_size=1083.3, sample_size_v1=0, sample_size_v2=0, ppl=1.8, wps=574.6, ups=0.53, wpb=1083.3, bsz=32, num_updates=46200, lr=3.53787e-06, gnorm=18.168, clip=100, loss_scale=16, train_wall=19, gb_free=11.3, wall=86840
2023-05-26 23:30:45 - progress_bar.py[line:272] - INFO: epoch 027:   1258 / 1732 loss=2.103, loss_v1=0, loss_v2=0, nll_loss=0.87, ntokens=1058.8, nsentences=32, sample_size=1058.8, sample_size_v1=0, sample_size_v2=0, ppl=1.83, wps=563.6, ups=0.53, wpb=1058.8, bsz=32, num_updates=46210, lr=3.53172e-06, gnorm=18.638, clip=100, loss_scale=16, train_wall=19, gb_free=11.1, wall=86859
2023-05-26 23:31:03 - progress_bar.py[line:272] - INFO: epoch 027:   1268 / 1732 loss=2.121, loss_v1=0, loss_v2=0, nll_loss=0.892, ntokens=1040.1, nsentences=32, sample_size=1040.1, sample_size_v1=0, sample_size_v2=0, ppl=1.86, wps=553.6, ups=0.53, wpb=1040.1, bsz=32, num_updates=46220, lr=3.52558e-06, gnorm=18.819, clip=100, loss_scale=16, train_wall=19, gb_free=11.4, wall=86878
2023-05-26 23:31:22 - progress_bar.py[line:272] - INFO: epoch 027:   1278 / 1732 loss=2.118, loss_v1=0, loss_v2=0, nll_loss=0.888, ntokens=1064.5, nsentences=32, sample_size=1064.5, sample_size_v1=0, sample_size_v2=0, ppl=1.85, wps=563.2, ups=0.53, wpb=1064.5, bsz=32, num_updates=46230, lr=3.51944e-06, gnorm=19.347, clip=100, loss_scale=16, train_wall=19, gb_free=11.4, wall=86897
2023-05-26 23:31:41 - progress_bar.py[line:272] - INFO: epoch 027:   1288 / 1732 loss=2.101, loss_v1=0, loss_v2=0, nll_loss=0.868, ntokens=1074.2, nsentences=32, sample_size=1074.2, sample_size_v1=0, sample_size_v2=0, ppl=1.82, wps=568.8, ups=0.53, wpb=1074.2, bsz=32, num_updates=46240, lr=3.5133e-06, gnorm=18.202, clip=100, loss_scale=16, train_wall=19, gb_free=10, wall=86916
2023-05-26 23:32:00 - progress_bar.py[line:272] - INFO: epoch 027:   1298 / 1732 loss=2.112, loss_v1=0, loss_v2=0, nll_loss=0.88, ntokens=1104.5, nsentences=32, sample_size=1104.5, sample_size_v1=0, sample_size_v2=0, ppl=1.84, wps=587.2, ups=0.53, wpb=1104.5, bsz=32, num_updates=46250, lr=3.50716e-06, gnorm=18.405, clip=100, loss_scale=16, train_wall=19, gb_free=11.1, wall=86935
2023-05-26 23:32:19 - progress_bar.py[line:272] - INFO: epoch 027:   1308 / 1732 loss=2.143, loss_v1=0, loss_v2=0, nll_loss=0.915, ntokens=1079.8, nsentences=32, sample_size=1079.8, sample_size_v1=0, sample_size_v2=0, ppl=1.89, wps=569.2, ups=0.53, wpb=1079.8, bsz=32, num_updates=46260, lr=3.50101e-06, gnorm=20.15, clip=100, loss_scale=16, train_wall=19, gb_free=10.5, wall=86954
2023-05-26 23:32:38 - progress_bar.py[line:272] - INFO: epoch 027:   1318 / 1732 loss=2.117, loss_v1=0, loss_v2=0, nll_loss=0.887, ntokens=1085.2, nsentences=32, sample_size=1085.2, sample_size_v1=0, sample_size_v2=0, ppl=1.85, wps=574.1, ups=0.53, wpb=1085.2, bsz=32, num_updates=46270, lr=3.49487e-06, gnorm=19.673, clip=100, loss_scale=16, train_wall=19, gb_free=10.9, wall=86973
2023-05-26 23:32:57 - progress_bar.py[line:272] - INFO: epoch 027:   1328 / 1732 loss=2.087, loss_v1=0, loss_v2=0, nll_loss=0.854, ntokens=1103.2, nsentences=32, sample_size=1103.2, sample_size_v1=0, sample_size_v2=0, ppl=1.81, wps=581.7, ups=0.53, wpb=1103.2, bsz=32, num_updates=46280, lr=3.48873e-06, gnorm=18.648, clip=100, loss_scale=16, train_wall=19, gb_free=11, wall=86992
2023-05-26 23:33:16 - progress_bar.py[line:272] - INFO: epoch 027:   1338 / 1732 loss=2.113, loss_v1=0, loss_v2=0, nll_loss=0.882, ntokens=1116.2, nsentences=32, sample_size=1116.2, sample_size_v1=0, sample_size_v2=0, ppl=1.84, wps=592.6, ups=0.53, wpb=1116.2, bsz=32, num_updates=46290, lr=3.48259e-06, gnorm=19.115, clip=100, loss_scale=16, train_wall=19, gb_free=10.6, wall=87010
2023-05-26 23:33:35 - progress_bar.py[line:272] - INFO: epoch 027:   1348 / 1732 loss=2.112, loss_v1=0, loss_v2=0, nll_loss=0.882, ntokens=1187.2, nsentences=32, sample_size=1187.2, sample_size_v1=0, sample_size_v2=0, ppl=1.84, wps=623.8, ups=0.53, wpb=1187.2, bsz=32, num_updates=46300, lr=3.47644e-06, gnorm=18.967, clip=100, loss_scale=16, train_wall=19, gb_free=10.7, wall=87029
2023-05-26 23:33:54 - progress_bar.py[line:272] - INFO: epoch 027:   1358 / 1732 loss=2.094, loss_v1=0, loss_v2=0, nll_loss=0.862, ntokens=1099, nsentences=32, sample_size=1099, sample_size_v1=0, sample_size_v2=0, ppl=1.82, wps=581.1, ups=0.53, wpb=1099, bsz=32, num_updates=46310, lr=3.4703e-06, gnorm=18.967, clip=100, loss_scale=16, train_wall=19, gb_free=11.3, wall=87048
2023-05-26 23:34:13 - progress_bar.py[line:272] - INFO: epoch 027:   1368 / 1732 loss=2.117, loss_v1=0, loss_v2=0, nll_loss=0.887, ntokens=1106.4, nsentences=32, sample_size=1106.4, sample_size_v1=0, sample_size_v2=0, ppl=1.85, wps=585.3, ups=0.53, wpb=1106.4, bsz=32, num_updates=46320, lr=3.46416e-06, gnorm=19.993, clip=100, loss_scale=16, train_wall=19, gb_free=11.3, wall=87067
2023-05-26 23:34:31 - progress_bar.py[line:272] - INFO: epoch 027:   1378 / 1732 loss=2.144, loss_v1=0, loss_v2=0, nll_loss=0.917, ntokens=1104.2, nsentences=32, sample_size=1104.2, sample_size_v1=0, sample_size_v2=0, ppl=1.89, wps=587.7, ups=0.53, wpb=1104.2, bsz=32, num_updates=46330, lr=3.45802e-06, gnorm=20.867, clip=100, loss_scale=16, train_wall=19, gb_free=11.3, wall=87086
2023-05-26 23:34:50 - progress_bar.py[line:272] - INFO: epoch 027:   1388 / 1732 loss=2.133, loss_v1=0, loss_v2=0, nll_loss=0.904, ntokens=1131.9, nsentences=32, sample_size=1131.9, sample_size_v1=0, sample_size_v2=0, ppl=1.87, wps=603.8, ups=0.53, wpb=1131.9, bsz=32, num_updates=46340, lr=3.45188e-06, gnorm=19.143, clip=100, loss_scale=16, train_wall=19, gb_free=11.5, wall=87105
2023-05-26 23:35:09 - progress_bar.py[line:272] - INFO: epoch 027:   1398 / 1732 loss=2.105, loss_v1=0, loss_v2=0, nll_loss=0.872, ntokens=1097.3, nsentences=32, sample_size=1097.3, sample_size_v1=0, sample_size_v2=0, ppl=1.83, wps=581.5, ups=0.53, wpb=1097.3, bsz=32, num_updates=46350, lr=3.44573e-06, gnorm=19.387, clip=100, loss_scale=16, train_wall=19, gb_free=11.3, wall=87124
2023-05-26 23:35:28 - progress_bar.py[line:272] - INFO: epoch 027:   1408 / 1732 loss=2.141, loss_v1=0, loss_v2=0, nll_loss=0.913, ntokens=1161.5, nsentences=32, sample_size=1161.5, sample_size_v1=0, sample_size_v2=0, ppl=1.88, wps=616.7, ups=0.53, wpb=1161.5, bsz=32, num_updates=46360, lr=3.43959e-06, gnorm=18.113, clip=100, loss_scale=16, train_wall=19, gb_free=11.3, wall=87142
2023-05-26 23:35:47 - progress_bar.py[line:272] - INFO: epoch 027:   1418 / 1732 loss=2.153, loss_v1=0, loss_v2=0, nll_loss=0.928, ntokens=1285.2, nsentences=32, sample_size=1285.2, sample_size_v1=0, sample_size_v2=0, ppl=1.9, wps=674.3, ups=0.52, wpb=1285.2, bsz=32, num_updates=46370, lr=3.43345e-06, gnorm=17.79, clip=100, loss_scale=16, train_wall=19, gb_free=10.7, wall=87162
2023-05-26 23:36:06 - progress_bar.py[line:272] - INFO: epoch 027:   1428 / 1732 loss=2.116, loss_v1=0, loss_v2=0, nll_loss=0.884, ntokens=1229.6, nsentences=32, sample_size=1229.6, sample_size_v1=0, sample_size_v2=0, ppl=1.85, wps=646.2, ups=0.53, wpb=1229.6, bsz=32, num_updates=46380, lr=3.42731e-06, gnorm=17.849, clip=100, loss_scale=16, train_wall=19, gb_free=11.4, wall=87181
2023-05-26 23:36:25 - progress_bar.py[line:272] - INFO: epoch 027:   1438 / 1732 loss=2.12, loss_v1=0, loss_v2=0, nll_loss=0.889, ntokens=1179.5, nsentences=32, sample_size=1179.5, sample_size_v1=0, sample_size_v2=0, ppl=1.85, wps=623.7, ups=0.53, wpb=1179.5, bsz=32, num_updates=46390, lr=3.42117e-06, gnorm=17.832, clip=100, loss_scale=16, train_wall=19, gb_free=11.6, wall=87199
2023-05-26 23:36:44 - progress_bar.py[line:272] - INFO: epoch 027:   1448 / 1732 loss=2.127, loss_v1=0, loss_v2=0, nll_loss=0.897, ntokens=1120.7, nsentences=32, sample_size=1120.7, sample_size_v1=0, sample_size_v2=0, ppl=1.86, wps=596.3, ups=0.53, wpb=1120.7, bsz=32, num_updates=46400, lr=3.41502e-06, gnorm=18.283, clip=100, loss_scale=16, train_wall=19, gb_free=11.4, wall=87218
2023-05-26 23:37:03 - progress_bar.py[line:272] - INFO: epoch 027:   1458 / 1732 loss=2.124, loss_v1=0, loss_v2=0, nll_loss=0.893, ntokens=1151.7, nsentences=32, sample_size=1151.7, sample_size_v1=0, sample_size_v2=0, ppl=1.86, wps=607, ups=0.53, wpb=1151.7, bsz=32, num_updates=46410, lr=3.40888e-06, gnorm=19.814, clip=100, loss_scale=16, train_wall=19, gb_free=10.8, wall=87237
2023-05-26 23:37:22 - progress_bar.py[line:272] - INFO: epoch 027:   1468 / 1732 loss=2.099, loss_v1=0, loss_v2=0, nll_loss=0.865, ntokens=1195.8, nsentences=32, sample_size=1195.8, sample_size_v1=0, sample_size_v2=0, ppl=1.82, wps=630.5, ups=0.53, wpb=1195.8, bsz=32, num_updates=46420, lr=3.40274e-06, gnorm=17.142, clip=100, loss_scale=16, train_wall=19, gb_free=10.6, wall=87256
2023-05-26 23:37:41 - progress_bar.py[line:272] - INFO: epoch 027:   1478 / 1732 loss=2.133, loss_v1=0, loss_v2=0, nll_loss=0.903, ntokens=1019.5, nsentences=32, sample_size=1019.5, sample_size_v1=0, sample_size_v2=0, ppl=1.87, wps=534.4, ups=0.52, wpb=1019.5, bsz=32, num_updates=46430, lr=3.3966e-06, gnorm=20.884, clip=100, loss_scale=16, train_wall=19, gb_free=11.4, wall=87275
2023-05-26 23:38:00 - progress_bar.py[line:272] - INFO: epoch 027:   1488 / 1732 loss=2.129, loss_v1=0, loss_v2=0, nll_loss=0.899, ntokens=1151.5, nsentences=32, sample_size=1151.5, sample_size_v1=0, sample_size_v2=0, ppl=1.86, wps=600.5, ups=0.52, wpb=1151.5, bsz=32, num_updates=46440, lr=3.39046e-06, gnorm=18.708, clip=100, loss_scale=16, train_wall=19, gb_free=10.7, wall=87294
2023-05-26 23:38:19 - progress_bar.py[line:272] - INFO: epoch 027:   1498 / 1732 loss=2.116, loss_v1=0, loss_v2=0, nll_loss=0.885, ntokens=1078, nsentences=32, sample_size=1078, sample_size_v1=0, sample_size_v2=0, ppl=1.85, wps=558.8, ups=0.52, wpb=1078, bsz=32, num_updates=46450, lr=3.38431e-06, gnorm=18.591, clip=100, loss_scale=16, train_wall=19, gb_free=11.4, wall=87314
2023-05-26 23:38:38 - progress_bar.py[line:272] - INFO: epoch 027:   1508 / 1732 loss=2.083, loss_v1=0, loss_v2=0, nll_loss=0.848, ntokens=1107.9, nsentences=32, sample_size=1107.9, sample_size_v1=0, sample_size_v2=0, ppl=1.8, wps=588.9, ups=0.53, wpb=1107.9, bsz=32, num_updates=46460, lr=3.37817e-06, gnorm=17.726, clip=100, loss_scale=16, train_wall=19, gb_free=11.3, wall=87333
2023-05-26 23:38:57 - progress_bar.py[line:272] - INFO: epoch 027:   1518 / 1732 loss=2.143, loss_v1=0, loss_v2=0, nll_loss=0.915, ntokens=1079, nsentences=32, sample_size=1079, sample_size_v1=0, sample_size_v2=0, ppl=1.89, wps=573.9, ups=0.53, wpb=1079, bsz=32, num_updates=46470, lr=3.37203e-06, gnorm=19.697, clip=100, loss_scale=16, train_wall=19, gb_free=11.1, wall=87351
2023-05-26 23:39:15 - progress_bar.py[line:272] - INFO: epoch 027:   1528 / 1732 loss=2.168, loss_v1=0, loss_v2=0, nll_loss=0.944, ntokens=1041.5, nsentences=32, sample_size=1041.5, sample_size_v1=0, sample_size_v2=0, ppl=1.92, wps=555.5, ups=0.53, wpb=1041.5, bsz=32, num_updates=46480, lr=3.36589e-06, gnorm=19.886, clip=100, loss_scale=16, train_wall=19, gb_free=11.6, wall=87370
2023-05-26 23:39:35 - progress_bar.py[line:272] - INFO: epoch 027:   1538 / 1732 loss=2.113, loss_v1=0, loss_v2=0, nll_loss=0.881, ntokens=1094, nsentences=32, sample_size=1094, sample_size_v1=0, sample_size_v2=0, ppl=1.84, wps=556.7, ups=0.51, wpb=1094, bsz=32, num_updates=46490, lr=3.35974e-06, gnorm=18.997, clip=100, loss_scale=16, train_wall=20, gb_free=11, wall=87390
2023-05-26 23:39:54 - progress_bar.py[line:272] - INFO: epoch 027:   1548 / 1732 loss=2.105, loss_v1=0, loss_v2=0, nll_loss=0.872, ntokens=1084.2, nsentences=32, sample_size=1084.2, sample_size_v1=0, sample_size_v2=0, ppl=1.83, wps=565.1, ups=0.52, wpb=1084.2, bsz=32, num_updates=46500, lr=3.3536e-06, gnorm=19.113, clip=100, loss_scale=16, train_wall=19, gb_free=11.4, wall=87409
2023-05-26 23:40:13 - progress_bar.py[line:272] - INFO: epoch 027:   1558 / 1732 loss=2.085, loss_v1=0, loss_v2=0, nll_loss=0.85, ntokens=1077.4, nsentences=32, sample_size=1077.4, sample_size_v1=0, sample_size_v2=0, ppl=1.8, wps=569.1, ups=0.53, wpb=1077.4, bsz=32, num_updates=46510, lr=3.34746e-06, gnorm=18.283, clip=100, loss_scale=16, train_wall=19, gb_free=10.8, wall=87428
2023-05-26 23:40:32 - progress_bar.py[line:272] - INFO: epoch 027:   1568 / 1732 loss=2.149, loss_v1=0, loss_v2=0, nll_loss=0.922, ntokens=1072.3, nsentences=32, sample_size=1072.3, sample_size_v1=0, sample_size_v2=0, ppl=1.9, wps=569.8, ups=0.53, wpb=1072.3, bsz=32, num_updates=46520, lr=3.34132e-06, gnorm=18.804, clip=100, loss_scale=16, train_wall=19, gb_free=10.5, wall=87447
2023-05-26 23:40:51 - progress_bar.py[line:272] - INFO: epoch 027:   1578 / 1732 loss=2.128, loss_v1=0, loss_v2=0, nll_loss=0.898, ntokens=1004.7, nsentences=32, sample_size=1004.7, sample_size_v1=0, sample_size_v2=0, ppl=1.86, wps=535.5, ups=0.53, wpb=1004.7, bsz=32, num_updates=46530, lr=3.33518e-06, gnorm=20.856, clip=100, loss_scale=16, train_wall=19, gb_free=11.2, wall=87466
2023-05-26 23:41:10 - progress_bar.py[line:272] - INFO: epoch 027:   1588 / 1732 loss=2.114, loss_v1=0, loss_v2=0, nll_loss=0.883, ntokens=1078.3, nsentences=32, sample_size=1078.3, sample_size_v1=0, sample_size_v2=0, ppl=1.84, wps=570.4, ups=0.53, wpb=1078.3, bsz=32, num_updates=46540, lr=3.32903e-06, gnorm=21.048, clip=100, loss_scale=16, train_wall=19, gb_free=11.4, wall=87484
2023-05-26 23:41:29 - progress_bar.py[line:272] - INFO: epoch 027:   1598 / 1732 loss=2.105, loss_v1=0, loss_v2=0, nll_loss=0.873, ntokens=1079.8, nsentences=32, sample_size=1079.8, sample_size_v1=0, sample_size_v2=0, ppl=1.83, wps=574.5, ups=0.53, wpb=1079.8, bsz=32, num_updates=46550, lr=3.32289e-06, gnorm=18.348, clip=100, loss_scale=16, train_wall=19, gb_free=11.5, wall=87503
2023-05-26 23:41:47 - progress_bar.py[line:272] - INFO: epoch 027:   1608 / 1732 loss=2.107, loss_v1=0, loss_v2=0, nll_loss=0.874, ntokens=1140.6, nsentences=32, sample_size=1140.6, sample_size_v1=0, sample_size_v2=0, ppl=1.83, wps=602.1, ups=0.53, wpb=1140.6, bsz=32, num_updates=46560, lr=3.31675e-06, gnorm=18.639, clip=100, loss_scale=16, train_wall=19, gb_free=11, wall=87522
2023-05-26 23:42:06 - progress_bar.py[line:272] - INFO: epoch 027:   1618 / 1732 loss=2.095, loss_v1=0, loss_v2=0, nll_loss=0.862, ntokens=1124.7, nsentences=32, sample_size=1124.7, sample_size_v1=0, sample_size_v2=0, ppl=1.82, wps=592.8, ups=0.53, wpb=1124.7, bsz=32, num_updates=46570, lr=3.31061e-06, gnorm=18.204, clip=100, loss_scale=16, train_wall=19, gb_free=11, wall=87541
2023-05-26 23:42:26 - progress_bar.py[line:272] - INFO: epoch 027:   1628 / 1732 loss=2.12, loss_v1=0, loss_v2=0, nll_loss=0.889, ntokens=1158.7, nsentences=32, sample_size=1158.7, sample_size_v1=0, sample_size_v2=0, ppl=1.85, wps=599.8, ups=0.52, wpb=1158.7, bsz=32, num_updates=46580, lr=3.30447e-06, gnorm=18.126, clip=100, loss_scale=16, train_wall=19, gb_free=10.6, wall=87560
2023-05-26 23:42:45 - progress_bar.py[line:272] - INFO: epoch 027:   1638 / 1732 loss=2.097, loss_v1=0, loss_v2=0, nll_loss=0.865, ntokens=1131.3, nsentences=32, sample_size=1131.3, sample_size_v1=0, sample_size_v2=0, ppl=1.82, wps=599.7, ups=0.53, wpb=1131.3, bsz=32, num_updates=46590, lr=3.29832e-06, gnorm=18.721, clip=100, loss_scale=32, train_wall=19, gb_free=11, wall=87579
2023-05-26 23:43:04 - progress_bar.py[line:272] - INFO: epoch 027:   1648 / 1732 loss=2.105, loss_v1=0, loss_v2=0, nll_loss=0.872, ntokens=1231.9, nsentences=32, sample_size=1231.9, sample_size_v1=0, sample_size_v2=0, ppl=1.83, wps=635.5, ups=0.52, wpb=1231.9, bsz=32, num_updates=46600, lr=3.29218e-06, gnorm=16.915, clip=100, loss_scale=32, train_wall=19, gb_free=11.6, wall=87599
2023-05-26 23:43:23 - progress_bar.py[line:272] - INFO: epoch 027:   1658 / 1732 loss=2.143, loss_v1=0, loss_v2=0, nll_loss=0.916, ntokens=971, nsentences=32, sample_size=971, sample_size_v1=0, sample_size_v2=0, ppl=1.89, wps=517.9, ups=0.53, wpb=971, bsz=32, num_updates=46610, lr=3.28604e-06, gnorm=21.258, clip=100, loss_scale=32, train_wall=19, gb_free=11.1, wall=87617
2023-05-26 23:43:42 - progress_bar.py[line:272] - INFO: epoch 027:   1668 / 1732 loss=2.114, loss_v1=0, loss_v2=0, nll_loss=0.883, ntokens=1011.3, nsentences=32, sample_size=1011.3, sample_size_v1=0, sample_size_v2=0, ppl=1.84, wps=538.2, ups=0.53, wpb=1011.3, bsz=32, num_updates=46620, lr=3.2799e-06, gnorm=20.086, clip=100, loss_scale=32, train_wall=19, gb_free=11.6, wall=87636
2023-05-26 23:44:01 - progress_bar.py[line:272] - INFO: epoch 027:   1678 / 1732 loss=2.076, loss_v1=0, loss_v2=0, nll_loss=0.84, ntokens=1161.5, nsentences=32, sample_size=1161.5, sample_size_v1=0, sample_size_v2=0, ppl=1.79, wps=613.7, ups=0.53, wpb=1161.5, bsz=32, num_updates=46630, lr=3.27375e-06, gnorm=16.334, clip=100, loss_scale=32, train_wall=19, gb_free=11.1, wall=87655
2023-05-26 23:44:20 - progress_bar.py[line:272] - INFO: epoch 027:   1688 / 1732 loss=2.116, loss_v1=0, loss_v2=0, nll_loss=0.884, ntokens=1174.7, nsentences=32, sample_size=1174.7, sample_size_v1=0, sample_size_v2=0, ppl=1.85, wps=617.7, ups=0.53, wpb=1174.7, bsz=32, num_updates=46640, lr=3.26761e-06, gnorm=18.427, clip=100, loss_scale=32, train_wall=19, gb_free=10, wall=87674
2023-05-26 23:44:40 - progress_bar.py[line:272] - INFO: epoch 027:   1698 / 1732 loss=2.099, loss_v1=0, loss_v2=0, nll_loss=0.867, ntokens=1304.9, nsentences=32, sample_size=1304.9, sample_size_v1=0, sample_size_v2=0, ppl=1.82, wps=652.7, ups=0.5, wpb=1304.9, bsz=32, num_updates=46650, lr=3.26147e-06, gnorm=16.549, clip=100, loss_scale=32, train_wall=20, gb_free=11.2, wall=87694
2023-05-26 23:44:59 - progress_bar.py[line:272] - INFO: epoch 027:   1708 / 1732 loss=2.127, loss_v1=0, loss_v2=0, nll_loss=0.897, ntokens=1174.9, nsentences=32, sample_size=1174.9, sample_size_v1=0, sample_size_v2=0, ppl=1.86, wps=619.7, ups=0.53, wpb=1174.9, bsz=32, num_updates=46660, lr=3.25533e-06, gnorm=18.599, clip=100, loss_scale=32, train_wall=19, gb_free=10.8, wall=87713
2023-05-26 23:45:18 - progress_bar.py[line:272] - INFO: epoch 027:   1718 / 1732 loss=2.092, loss_v1=0, loss_v2=0, nll_loss=0.858, ntokens=1181.2, nsentences=32, sample_size=1181.2, sample_size_v1=0, sample_size_v2=0, ppl=1.81, wps=621.4, ups=0.53, wpb=1181.2, bsz=32, num_updates=46670, lr=3.24919e-06, gnorm=17.038, clip=100, loss_scale=32, train_wall=19, gb_free=11, wall=87732
2023-05-26 23:45:36 - progress_bar.py[line:272] - INFO: epoch 027:   1728 / 1732 loss=2.129, loss_v1=0, loss_v2=0, nll_loss=0.899, ntokens=1093.2, nsentences=32, sample_size=1093.2, sample_size_v1=0, sample_size_v2=0, ppl=1.87, wps=577.2, ups=0.53, wpb=1093.2, bsz=32, num_updates=46680, lr=3.24304e-06, gnorm=17.23, clip=100, loss_scale=32, train_wall=19, gb_free=11, wall=87751
2023-05-26 23:45:43 - train.py[line:332] - INFO: end of epoch 27 (average epoch stats below)
2023-05-26 23:45:43 - progress_bar.py[line:282] - INFO: epoch 027 | loss 2.118 | loss_v1 0 | loss_v2 0 | nll_loss 0.888 | ntokens 1051.63 | nsentences 31.986 | sample_size 1051.63 | sample_size_v1 0 | sample_size_v2 0 | ppl 1.85 | wps 559.5 | ups 0.53 | wpb 1051.6 | bsz 32 | num_updates 46684 | lr 3.24059e-06 | gnorm 20.204 | clip 100 | loss_scale 32 | train_wall 3244 | gb_free 11.7 | wall 87757
2023-05-26 23:45:43 - trainer.py[line:639] - INFO: loading train data for epoch 28
local datafile ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 0 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 0 finished initializing row_count and line_idx-to-offset mapping
file ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 0 row count 55400 total row count 55400
slice_id 0 seek offset 0
2023-05-26 23:45:45 - trainer.py[line:703] - INFO: begin training epoch 28
2023-05-26 23:45:45 - train.py[line:305] - INFO: Start iterating over samples
2023-05-26 23:45:56 - progress_bar.py[line:272] - INFO: epoch 028:      6 / 1732 loss=2.11, loss_v1=0, loss_v2=0, nll_loss=0.879, ntokens=1082.4, nsentences=29.6, sample_size=1082.4, sample_size_v1=0, sample_size_v2=0, ppl=1.84, wps=546.8, ups=0.51, wpb=1082.4, bsz=29.6, num_updates=46690, lr=3.2369e-06, gnorm=19.405, clip=100, loss_scale=32, train_wall=18, gb_free=11.2, wall=87771
2023-05-26 23:46:15 - progress_bar.py[line:272] - INFO: epoch 028:     16 / 1732 loss=2.104, loss_v1=0, loss_v2=0, nll_loss=0.872, ntokens=1099.3, nsentences=32, sample_size=1099.3, sample_size_v1=0, sample_size_v2=0, ppl=1.83, wps=582.3, ups=0.53, wpb=1099.3, bsz=32, num_updates=46700, lr=3.23076e-06, gnorm=21.679, clip=100, loss_scale=32, train_wall=19, gb_free=11.2, wall=87790
2023-05-26 23:46:34 - progress_bar.py[line:272] - INFO: epoch 028:     26 / 1732 loss=2.086, loss_v1=0, loss_v2=0, nll_loss=0.851, ntokens=973, nsentences=32, sample_size=973, sample_size_v1=0, sample_size_v2=0, ppl=1.8, wps=516.3, ups=0.53, wpb=973, bsz=32, num_updates=46710, lr=3.22462e-06, gnorm=24.486, clip=100, loss_scale=32, train_wall=19, gb_free=11.5, wall=87809
2023-05-26 23:46:53 - progress_bar.py[line:272] - INFO: epoch 028:     36 / 1732 loss=1.984, loss_v1=0, loss_v2=0, nll_loss=0.737, ntokens=1153.4, nsentences=32, sample_size=1153.4, sample_size_v1=0, sample_size_v2=0, ppl=1.67, wps=606.9, ups=0.53, wpb=1153.4, bsz=32, num_updates=46720, lr=3.21848e-06, gnorm=18.5, clip=100, loss_scale=32, train_wall=19, gb_free=10.4, wall=87828
2023-05-26 23:47:12 - progress_bar.py[line:272] - INFO: epoch 028:     46 / 1732 loss=1.978, loss_v1=0, loss_v2=0, nll_loss=0.729, ntokens=1066.8, nsentences=32, sample_size=1066.8, sample_size_v1=0, sample_size_v2=0, ppl=1.66, wps=566.3, ups=0.53, wpb=1066.8, bsz=32, num_updates=46730, lr=3.21233e-06, gnorm=19.665, clip=100, loss_scale=32, train_wall=19, gb_free=11.6, wall=87847
2023-05-26 23:47:31 - progress_bar.py[line:272] - INFO: epoch 028:     56 / 1732 loss=1.941, loss_v1=0, loss_v2=0, nll_loss=0.688, ntokens=1077, nsentences=32, sample_size=1077, sample_size_v1=0, sample_size_v2=0, ppl=1.61, wps=569.8, ups=0.53, wpb=1077, bsz=32, num_updates=46740, lr=3.20619e-06, gnorm=20.785, clip=100, loss_scale=32, train_wall=19, gb_free=11.5, wall=87865
2023-05-26 23:47:50 - progress_bar.py[line:272] - INFO: epoch 028:     66 / 1732 loss=1.843, loss_v1=0, loss_v2=0, nll_loss=0.578, ntokens=1294.5, nsentences=32, sample_size=1294.5, sample_size_v1=0, sample_size_v2=0, ppl=1.49, wps=673.5, ups=0.52, wpb=1294.5, bsz=32, num_updates=46750, lr=3.20005e-06, gnorm=14.992, clip=100, loss_scale=32, train_wall=19, gb_free=10.5, wall=87885
2023-05-26 23:48:10 - progress_bar.py[line:272] - INFO: epoch 028:     76 / 1732 loss=1.916, loss_v1=0, loss_v2=0, nll_loss=0.661, ntokens=1343.5, nsentences=32, sample_size=1343.5, sample_size_v1=0, sample_size_v2=0, ppl=1.58, wps=686.7, ups=0.51, wpb=1343.5, bsz=32, num_updates=46760, lr=3.19391e-06, gnorm=14.686, clip=100, loss_scale=32, train_wall=20, gb_free=10.1, wall=87904
2023-05-26 23:48:29 - progress_bar.py[line:272] - INFO: epoch 028:     86 / 1732 loss=1.962, loss_v1=0, loss_v2=0, nll_loss=0.713, ntokens=1107.4, nsentences=32, sample_size=1107.4, sample_size_v1=0, sample_size_v2=0, ppl=1.64, wps=578.6, ups=0.52, wpb=1107.4, bsz=32, num_updates=46770, lr=3.18776e-06, gnorm=16.421, clip=100, loss_scale=32, train_wall=19, gb_free=10.8, wall=87923
2023-05-26 23:48:48 - progress_bar.py[line:272] - INFO: epoch 028:     96 / 1732 loss=1.958, loss_v1=0, loss_v2=0, nll_loss=0.71, ntokens=1069.5, nsentences=32, sample_size=1069.5, sample_size_v1=0, sample_size_v2=0, ppl=1.64, wps=563.7, ups=0.53, wpb=1069.5, bsz=32, num_updates=46780, lr=3.18162e-06, gnorm=19.55, clip=100, loss_scale=32, train_wall=19, gb_free=10.4, wall=87942
2023-05-26 23:49:06 - progress_bar.py[line:272] - INFO: epoch 028:    106 / 1732 loss=2.058, loss_v1=0, loss_v2=0, nll_loss=0.821, ntokens=998.2, nsentences=32, sample_size=998.2, sample_size_v1=0, sample_size_v2=0, ppl=1.77, wps=529.9, ups=0.53, wpb=998.2, bsz=32, num_updates=46790, lr=3.17548e-06, gnorm=20.685, clip=100, loss_scale=32, train_wall=19, gb_free=10.4, wall=87961
2023-05-26 23:49:26 - progress_bar.py[line:272] - INFO: epoch 028:    116 / 1732 loss=2.155, loss_v1=0, loss_v2=0, nll_loss=0.931, ntokens=1049.3, nsentences=32, sample_size=1049.3, sample_size_v1=0, sample_size_v2=0, ppl=1.91, wps=552.3, ups=0.53, wpb=1049.3, bsz=32, num_updates=46800, lr=3.16934e-06, gnorm=21.337, clip=100, loss_scale=32, train_wall=19, gb_free=10.5, wall=87980
2023-05-26 23:49:45 - progress_bar.py[line:272] - INFO: epoch 028:    126 / 1732 loss=2.101, loss_v1=0, loss_v2=0, nll_loss=0.869, ntokens=1187.5, nsentences=32, sample_size=1187.5, sample_size_v1=0, sample_size_v2=0, ppl=1.83, wps=616.2, ups=0.52, wpb=1187.5, bsz=32, num_updates=46810, lr=3.1632e-06, gnorm=20.926, clip=100, loss_scale=32, train_wall=19, gb_free=10.9, wall=87999
2023-05-26 23:50:04 - progress_bar.py[line:272] - INFO: epoch 028:    136 / 1732 loss=2.095, loss_v1=0, loss_v2=0, nll_loss=0.863, ntokens=1228, nsentences=32, sample_size=1228, sample_size_v1=0, sample_size_v2=0, ppl=1.82, wps=641.2, ups=0.52, wpb=1228, bsz=32, num_updates=46820, lr=3.15705e-06, gnorm=17.809, clip=100, loss_scale=32, train_wall=19, gb_free=10.4, wall=88019
2023-05-26 23:50:08 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2023-05-26 23:50:25 - progress_bar.py[line:272] - INFO: epoch 028:    147 / 1732 loss=2.042, loss_v1=0, loss_v2=0, nll_loss=0.803, ntokens=1200.5, nsentences=32, sample_size=1200.5, sample_size_v1=0, sample_size_v2=0, ppl=1.75, wps=566.9, ups=0.47, wpb=1200.5, bsz=32, num_updates=46830, lr=3.15091e-06, gnorm=18.271, clip=100, loss_scale=16, train_wall=21, gb_free=10.9, wall=88040
2023-05-26 23:50:44 - progress_bar.py[line:272] - INFO: epoch 028:    157 / 1732 loss=2.088, loss_v1=0, loss_v2=0, nll_loss=0.855, ntokens=1172.8, nsentences=32, sample_size=1172.8, sample_size_v1=0, sample_size_v2=0, ppl=1.81, wps=608.1, ups=0.52, wpb=1172.8, bsz=32, num_updates=46840, lr=3.14477e-06, gnorm=19.285, clip=100, loss_scale=16, train_wall=19, gb_free=11.1, wall=88059
2023-05-26 23:51:03 - progress_bar.py[line:272] - INFO: epoch 028:    167 / 1732 loss=2.063, loss_v1=0, loss_v2=0, nll_loss=0.827, ntokens=1009.5, nsentences=32, sample_size=1009.5, sample_size_v1=0, sample_size_v2=0, ppl=1.77, wps=533, ups=0.53, wpb=1009.5, bsz=32, num_updates=46850, lr=3.13863e-06, gnorm=22.225, clip=100, loss_scale=16, train_wall=19, gb_free=10.3, wall=88078
2023-05-26 23:51:22 - progress_bar.py[line:272] - INFO: epoch 028:    177 / 1732 loss=2.072, loss_v1=0, loss_v2=0, nll_loss=0.836, ntokens=994.5, nsentences=32, sample_size=994.5, sample_size_v1=0, sample_size_v2=0, ppl=1.78, wps=527.4, ups=0.53, wpb=994.5, bsz=32, num_updates=46860, lr=3.13249e-06, gnorm=22.867, clip=100, loss_scale=16, train_wall=19, gb_free=10.8, wall=88097
2023-05-26 23:51:41 - progress_bar.py[line:272] - INFO: epoch 028:    187 / 1732 loss=2.033, loss_v1=0, loss_v2=0, nll_loss=0.793, ntokens=1141.8, nsentences=32, sample_size=1141.8, sample_size_v1=0, sample_size_v2=0, ppl=1.73, wps=597, ups=0.52, wpb=1141.8, bsz=32, num_updates=46870, lr=3.12634e-06, gnorm=18.825, clip=100, loss_scale=16, train_wall=19, gb_free=10.5, wall=88116
2023-05-26 23:52:00 - progress_bar.py[line:272] - INFO: epoch 028:    197 / 1732 loss=2.078, loss_v1=0, loss_v2=0, nll_loss=0.843, ntokens=1173.2, nsentences=32, sample_size=1173.2, sample_size_v1=0, sample_size_v2=0, ppl=1.79, wps=616.1, ups=0.53, wpb=1173.2, bsz=32, num_updates=46880, lr=3.1202e-06, gnorm=19.42, clip=100, loss_scale=16, train_wall=19, gb_free=11.4, wall=88135
2023-05-26 23:52:19 - progress_bar.py[line:272] - INFO: epoch 028:    207 / 1732 loss=2.121, loss_v1=0, loss_v2=0, nll_loss=0.891, ntokens=957.1, nsentences=32, sample_size=957.1, sample_size_v1=0, sample_size_v2=0, ppl=1.85, wps=514.3, ups=0.54, wpb=957.1, bsz=32, num_updates=46890, lr=3.11406e-06, gnorm=20.524, clip=100, loss_scale=16, train_wall=19, gb_free=10.7, wall=88154
2023-05-26 23:52:38 - progress_bar.py[line:272] - INFO: epoch 028:    217 / 1732 loss=2.151, loss_v1=0, loss_v2=0, nll_loss=0.924, ntokens=1157.1, nsentences=32, sample_size=1157.1, sample_size_v1=0, sample_size_v2=0, ppl=1.9, wps=614.7, ups=0.53, wpb=1157.1, bsz=32, num_updates=46900, lr=3.10792e-06, gnorm=17.693, clip=100, loss_scale=16, train_wall=19, gb_free=11.2, wall=88172
2023-05-26 23:52:57 - progress_bar.py[line:272] - INFO: epoch 028:    227 / 1732 loss=2.125, loss_v1=0, loss_v2=0, nll_loss=0.898, ntokens=1106.8, nsentences=32, sample_size=1106.8, sample_size_v1=0, sample_size_v2=0, ppl=1.86, wps=590.3, ups=0.53, wpb=1106.8, bsz=32, num_updates=46910, lr=3.10178e-06, gnorm=18.792, clip=100, loss_scale=16, train_wall=19, gb_free=10.9, wall=88191
2023-05-26 23:53:15 - progress_bar.py[line:272] - INFO: epoch 028:    237 / 1732 loss=2.182, loss_v1=0, loss_v2=0, nll_loss=0.96, ntokens=1060.1, nsentences=32, sample_size=1060.1, sample_size_v1=0, sample_size_v2=0, ppl=1.95, wps=566.8, ups=0.53, wpb=1060.1, bsz=32, num_updates=46920, lr=3.09563e-06, gnorm=18.886, clip=100, loss_scale=16, train_wall=19, gb_free=10.7, wall=88210
2023-05-26 23:53:34 - progress_bar.py[line:272] - INFO: epoch 028:    247 / 1732 loss=2.148, loss_v1=0, loss_v2=0, nll_loss=0.921, ntokens=1188.4, nsentences=32, sample_size=1188.4, sample_size_v1=0, sample_size_v2=0, ppl=1.89, wps=630.1, ups=0.53, wpb=1188.4, bsz=32, num_updates=46930, lr=3.08949e-06, gnorm=17.549, clip=100, loss_scale=16, train_wall=19, gb_free=10.9, wall=88229
2023-05-26 23:53:53 - progress_bar.py[line:272] - INFO: epoch 028:    257 / 1732 loss=2.141, loss_v1=0, loss_v2=0, nll_loss=0.914, ntokens=1118.5, nsentences=32, sample_size=1118.5, sample_size_v1=0, sample_size_v2=0, ppl=1.88, wps=596.3, ups=0.53, wpb=1118.5, bsz=32, num_updates=46940, lr=3.08335e-06, gnorm=16.799, clip=100, loss_scale=16, train_wall=19, gb_free=11.2, wall=88248
2023-05-26 23:54:12 - progress_bar.py[line:272] - INFO: epoch 028:    267 / 1732 loss=2.135, loss_v1=0, loss_v2=0, nll_loss=0.906, ntokens=1162.2, nsentences=32, sample_size=1162.2, sample_size_v1=0, sample_size_v2=0, ppl=1.87, wps=616.7, ups=0.53, wpb=1162.2, bsz=32, num_updates=46950, lr=3.07721e-06, gnorm=17.443, clip=100, loss_scale=16, train_wall=19, gb_free=11.2, wall=88266
2023-05-26 23:54:31 - progress_bar.py[line:272] - INFO: epoch 028:    277 / 1732 loss=2.158, loss_v1=0, loss_v2=0, nll_loss=0.933, ntokens=1137.3, nsentences=32, sample_size=1137.3, sample_size_v1=0, sample_size_v2=0, ppl=1.91, wps=601.9, ups=0.53, wpb=1137.3, bsz=32, num_updates=46960, lr=3.07106e-06, gnorm=19.282, clip=100, loss_scale=16, train_wall=19, gb_free=11.3, wall=88285
2023-05-26 23:54:50 - progress_bar.py[line:272] - INFO: epoch 028:    287 / 1732 loss=2.133, loss_v1=0, loss_v2=0, nll_loss=0.905, ntokens=1149.1, nsentences=32, sample_size=1149.1, sample_size_v1=0, sample_size_v2=0, ppl=1.87, wps=607.9, ups=0.53, wpb=1149.1, bsz=32, num_updates=46970, lr=3.06492e-06, gnorm=17.432, clip=100, loss_scale=16, train_wall=19, gb_free=10.6, wall=88304
2023-05-26 23:55:08 - progress_bar.py[line:272] - INFO: epoch 028:    297 / 1732 loss=2.152, loss_v1=0, loss_v2=0, nll_loss=0.926, ntokens=1120.1, nsentences=32, sample_size=1120.1, sample_size_v1=0, sample_size_v2=0, ppl=1.9, wps=596.7, ups=0.53, wpb=1120.1, bsz=32, num_updates=46980, lr=3.05878e-06, gnorm=20.321, clip=100, loss_scale=16, train_wall=19, gb_free=10.9, wall=88323
2023-05-26 23:55:27 - progress_bar.py[line:272] - INFO: epoch 028:    307 / 1732 loss=2.133, loss_v1=0, loss_v2=0, nll_loss=0.906, ntokens=1063.6, nsentences=32, sample_size=1063.6, sample_size_v1=0, sample_size_v2=0, ppl=1.87, wps=569, ups=0.53, wpb=1063.6, bsz=32, num_updates=46990, lr=3.05264e-06, gnorm=18.885, clip=100, loss_scale=16, train_wall=19, gb_free=11.5, wall=88342
2023-05-26 23:55:46 - progress_bar.py[line:272] - INFO: epoch 028:    317 / 1732 loss=2.159, loss_v1=0, loss_v2=0, nll_loss=0.933, ntokens=1045.4, nsentences=32, sample_size=1045.4, sample_size_v1=0, sample_size_v2=0, ppl=1.91, wps=560.5, ups=0.54, wpb=1045.4, bsz=32, num_updates=47000, lr=3.0465e-06, gnorm=20.034, clip=100, loss_scale=16, train_wall=19, gb_free=11.5, wall=88360
2023-05-26 23:56:04 - progress_bar.py[line:272] - INFO: epoch 028:    327 / 1732 loss=2.18, loss_v1=0, loss_v2=0, nll_loss=0.957, ntokens=1029.3, nsentences=32, sample_size=1029.3, sample_size_v1=0, sample_size_v2=0, ppl=1.94, wps=552.3, ups=0.54, wpb=1029.3, bsz=32, num_updates=47010, lr=3.04035e-06, gnorm=20.454, clip=100, loss_scale=16, train_wall=19, gb_free=11.4, wall=88379
2023-05-26 23:56:23 - progress_bar.py[line:272] - INFO: epoch 028:    337 / 1732 loss=2.143, loss_v1=0, loss_v2=0, nll_loss=0.915, ntokens=970.5, nsentences=32, sample_size=970.5, sample_size_v1=0, sample_size_v2=0, ppl=1.89, wps=522.1, ups=0.54, wpb=970.5, bsz=32, num_updates=47020, lr=3.03421e-06, gnorm=18.755, clip=100, loss_scale=16, train_wall=19, gb_free=10.6, wall=88398
2023-05-26 23:56:41 - progress_bar.py[line:272] - INFO: epoch 028:    347 / 1732 loss=2.124, loss_v1=0, loss_v2=0, nll_loss=0.894, ntokens=913.7, nsentences=32, sample_size=913.7, sample_size_v1=0, sample_size_v2=0, ppl=1.86, wps=492.9, ups=0.54, wpb=913.7, bsz=32, num_updates=47030, lr=3.02807e-06, gnorm=20.565, clip=100, loss_scale=16, train_wall=19, gb_free=11.8, wall=88416
2023-05-26 23:57:00 - progress_bar.py[line:272] - INFO: epoch 028:    357 / 1732 loss=2.164, loss_v1=0, loss_v2=0, nll_loss=0.94, ntokens=948.3, nsentences=32, sample_size=948.3, sample_size_v1=0, sample_size_v2=0, ppl=1.92, wps=511, ups=0.54, wpb=948.3, bsz=32, num_updates=47040, lr=3.02193e-06, gnorm=20.828, clip=100, loss_scale=16, train_wall=19, gb_free=11.8, wall=88435
2023-05-26 23:57:19 - progress_bar.py[line:272] - INFO: epoch 028:    367 / 1732 loss=2.173, loss_v1=0, loss_v2=0, nll_loss=0.949, ntokens=952.5, nsentences=32, sample_size=952.5, sample_size_v1=0, sample_size_v2=0, ppl=1.93, wps=513.7, ups=0.54, wpb=952.5, bsz=32, num_updates=47050, lr=3.01579e-06, gnorm=21.268, clip=100, loss_scale=16, train_wall=19, gb_free=11.7, wall=88453
2023-05-26 23:57:37 - progress_bar.py[line:272] - INFO: epoch 028:    377 / 1732 loss=2.172, loss_v1=0, loss_v2=0, nll_loss=0.948, ntokens=1056.5, nsentences=32, sample_size=1056.5, sample_size_v1=0, sample_size_v2=0, ppl=1.93, wps=567.9, ups=0.54, wpb=1056.5, bsz=32, num_updates=47060, lr=3.00964e-06, gnorm=20.238, clip=100, loss_scale=16, train_wall=19, gb_free=11.1, wall=88472
2023-05-26 23:57:56 - progress_bar.py[line:272] - INFO: epoch 028:    387 / 1732 loss=2.17, loss_v1=0, loss_v2=0, nll_loss=0.946, ntokens=1047.4, nsentences=32, sample_size=1047.4, sample_size_v1=0, sample_size_v2=0, ppl=1.93, wps=562.1, ups=0.54, wpb=1047.4, bsz=32, num_updates=47070, lr=3.0035e-06, gnorm=19.082, clip=100, loss_scale=16, train_wall=19, gb_free=11.6, wall=88490
2023-05-26 23:58:14 - progress_bar.py[line:272] - INFO: epoch 028:    397 / 1732 loss=2.149, loss_v1=0, loss_v2=0, nll_loss=0.922, ntokens=958, nsentences=32, sample_size=958, sample_size_v1=0, sample_size_v2=0, ppl=1.9, wps=516.8, ups=0.54, wpb=958, bsz=32, num_updates=47080, lr=2.99736e-06, gnorm=22.25, clip=100, loss_scale=16, train_wall=19, gb_free=11.4, wall=88509
2023-05-26 23:58:33 - progress_bar.py[line:272] - INFO: epoch 028:    407 / 1732 loss=2.141, loss_v1=0, loss_v2=0, nll_loss=0.915, ntokens=1072.2, nsentences=32, sample_size=1072.2, sample_size_v1=0, sample_size_v2=0, ppl=1.88, wps=574, ups=0.54, wpb=1072.2, bsz=32, num_updates=47090, lr=2.99122e-06, gnorm=18.854, clip=100, loss_scale=16, train_wall=19, gb_free=11.1, wall=88528
2023-05-26 23:58:52 - progress_bar.py[line:272] - INFO: epoch 028:    417 / 1732 loss=2.116, loss_v1=0, loss_v2=0, nll_loss=0.885, ntokens=1027.3, nsentences=32, sample_size=1027.3, sample_size_v1=0, sample_size_v2=0, ppl=1.85, wps=550.6, ups=0.54, wpb=1027.3, bsz=32, num_updates=47100, lr=2.98507e-06, gnorm=19.904, clip=100, loss_scale=16, train_wall=19, gb_free=11.6, wall=88546
2023-05-26 23:59:10 - progress_bar.py[line:272] - INFO: epoch 028:    427 / 1732 loss=2.118, loss_v1=0, loss_v2=0, nll_loss=0.886, ntokens=993.5, nsentences=32, sample_size=993.5, sample_size_v1=0, sample_size_v2=0, ppl=1.85, wps=534, ups=0.54, wpb=993.5, bsz=32, num_updates=47110, lr=2.97893e-06, gnorm=21.273, clip=100, loss_scale=16, train_wall=19, gb_free=11.2, wall=88565
2023-05-26 23:59:29 - progress_bar.py[line:272] - INFO: epoch 028:    437 / 1732 loss=2.139, loss_v1=0, loss_v2=0, nll_loss=0.91, ntokens=1035.6, nsentences=32, sample_size=1035.6, sample_size_v1=0, sample_size_v2=0, ppl=1.88, wps=556.9, ups=0.54, wpb=1035.6, bsz=32, num_updates=47120, lr=2.97279e-06, gnorm=19.708, clip=100, loss_scale=16, train_wall=19, gb_free=12, wall=88584
2023-05-26 23:59:48 - progress_bar.py[line:272] - INFO: epoch 028:    447 / 1732 loss=2.142, loss_v1=0, loss_v2=0, nll_loss=0.915, ntokens=949, nsentences=32, sample_size=949, sample_size_v1=0, sample_size_v2=0, ppl=1.89, wps=509.7, ups=0.54, wpb=949, bsz=32, num_updates=47130, lr=2.96665e-06, gnorm=19.152, clip=100, loss_scale=16, train_wall=19, gb_free=10.9, wall=88602
2023-05-27 00:00:06 - progress_bar.py[line:272] - INFO: epoch 028:    457 / 1732 loss=2.151, loss_v1=0, loss_v2=0, nll_loss=0.924, ntokens=959.4, nsentences=32, sample_size=959.4, sample_size_v1=0, sample_size_v2=0, ppl=1.9, wps=516.7, ups=0.54, wpb=959.4, bsz=32, num_updates=47140, lr=2.96051e-06, gnorm=18.995, clip=100, loss_scale=16, train_wall=19, gb_free=10.6, wall=88621
2023-05-27 00:00:25 - progress_bar.py[line:272] - INFO: epoch 028:    467 / 1732 loss=2.172, loss_v1=0, loss_v2=0, nll_loss=0.948, ntokens=1054.7, nsentences=32, sample_size=1054.7, sample_size_v1=0, sample_size_v2=0, ppl=1.93, wps=562.8, ups=0.53, wpb=1054.7, bsz=32, num_updates=47150, lr=2.95436e-06, gnorm=20.271, clip=100, loss_scale=16, train_wall=19, gb_free=11.3, wall=88640
2023-05-27 00:00:44 - progress_bar.py[line:272] - INFO: epoch 028:    477 / 1732 loss=2.176, loss_v1=0, loss_v2=0, nll_loss=0.953, ntokens=1051.9, nsentences=32, sample_size=1051.9, sample_size_v1=0, sample_size_v2=0, ppl=1.94, wps=562, ups=0.53, wpb=1051.9, bsz=32, num_updates=47160, lr=2.94822e-06, gnorm=21.079, clip=100, loss_scale=16, train_wall=19, gb_free=11.6, wall=88658
2023-05-27 00:01:02 - progress_bar.py[line:272] - INFO: epoch 028:    487 / 1732 loss=2.137, loss_v1=0, loss_v2=0, nll_loss=0.908, ntokens=936.6, nsentences=32, sample_size=936.6, sample_size_v1=0, sample_size_v2=0, ppl=1.88, wps=506.8, ups=0.54, wpb=936.6, bsz=32, num_updates=47170, lr=2.94208e-06, gnorm=20.923, clip=100, loss_scale=16, train_wall=18, gb_free=12.1, wall=88677
2023-05-27 00:01:21 - progress_bar.py[line:272] - INFO: epoch 028:    497 / 1732 loss=2.132, loss_v1=0, loss_v2=0, nll_loss=0.903, ntokens=954.7, nsentences=32, sample_size=954.7, sample_size_v1=0, sample_size_v2=0, ppl=1.87, wps=513.4, ups=0.54, wpb=954.7, bsz=32, num_updates=47180, lr=2.93594e-06, gnorm=19.314, clip=100, loss_scale=16, train_wall=19, gb_free=10.9, wall=88695
2023-05-27 00:01:39 - progress_bar.py[line:272] - INFO: epoch 028:    507 / 1732 loss=2.179, loss_v1=0, loss_v2=0, nll_loss=0.956, ntokens=1006.3, nsentences=32, sample_size=1006.3, sample_size_v1=0, sample_size_v2=0, ppl=1.94, wps=544, ups=0.54, wpb=1006.3, bsz=32, num_updates=47190, lr=2.9298e-06, gnorm=21.461, clip=100, loss_scale=16, train_wall=18, gb_free=11.3, wall=88714
2023-05-27 00:01:58 - progress_bar.py[line:272] - INFO: epoch 028:    517 / 1732 loss=2.152, loss_v1=0, loss_v2=0, nll_loss=0.926, ntokens=1047.1, nsentences=32, sample_size=1047.1, sample_size_v1=0, sample_size_v2=0, ppl=1.9, wps=563.3, ups=0.54, wpb=1047.1, bsz=32, num_updates=47200, lr=2.92365e-06, gnorm=17.27, clip=100, loss_scale=16, train_wall=19, gb_free=11.6, wall=88732
2023-05-27 00:02:16 - progress_bar.py[line:272] - INFO: epoch 028:    527 / 1732 loss=2.153, loss_v1=0, loss_v2=0, nll_loss=0.926, ntokens=940.9, nsentences=32, sample_size=940.9, sample_size_v1=0, sample_size_v2=0, ppl=1.9, wps=509.3, ups=0.54, wpb=940.9, bsz=32, num_updates=47210, lr=2.91751e-06, gnorm=22.314, clip=100, loss_scale=16, train_wall=18, gb_free=11.6, wall=88751
2023-05-27 00:02:35 - progress_bar.py[line:272] - INFO: epoch 028:    537 / 1732 loss=2.147, loss_v1=0, loss_v2=0, nll_loss=0.92, ntokens=964.7, nsentences=32, sample_size=964.7, sample_size_v1=0, sample_size_v2=0, ppl=1.89, wps=521.5, ups=0.54, wpb=964.7, bsz=32, num_updates=47220, lr=2.91137e-06, gnorm=19.315, clip=100, loss_scale=16, train_wall=18, gb_free=11.9, wall=88769
2023-05-27 00:02:53 - progress_bar.py[line:272] - INFO: epoch 028:    547 / 1732 loss=2.172, loss_v1=0, loss_v2=0, nll_loss=0.947, ntokens=1033.6, nsentences=32, sample_size=1033.6, sample_size_v1=0, sample_size_v2=0, ppl=1.93, wps=555.2, ups=0.54, wpb=1033.6, bsz=32, num_updates=47230, lr=2.90523e-06, gnorm=19.214, clip=100, loss_scale=16, train_wall=19, gb_free=11.7, wall=88788
2023-05-27 00:03:12 - progress_bar.py[line:272] - INFO: epoch 028:    557 / 1732 loss=2.184, loss_v1=0, loss_v2=0, nll_loss=0.962, ntokens=1010.2, nsentences=32, sample_size=1010.2, sample_size_v1=0, sample_size_v2=0, ppl=1.95, wps=544.2, ups=0.54, wpb=1010.2, bsz=32, num_updates=47240, lr=2.89908e-06, gnorm=20.496, clip=100, loss_scale=16, train_wall=19, gb_free=11.8, wall=88807
2023-05-27 00:03:31 - progress_bar.py[line:272] - INFO: epoch 028:    567 / 1732 loss=2.184, loss_v1=0, loss_v2=0, nll_loss=0.962, ntokens=1004.9, nsentences=32, sample_size=1004.9, sample_size_v1=0, sample_size_v2=0, ppl=1.95, wps=539.6, ups=0.54, wpb=1004.9, bsz=32, num_updates=47250, lr=2.89294e-06, gnorm=21.193, clip=100, loss_scale=16, train_wall=19, gb_free=11.7, wall=88825
2023-05-27 00:03:49 - progress_bar.py[line:272] - INFO: epoch 028:    577 / 1732 loss=2.168, loss_v1=0, loss_v2=0, nll_loss=0.944, ntokens=1011.7, nsentences=32, sample_size=1011.7, sample_size_v1=0, sample_size_v2=0, ppl=1.92, wps=539, ups=0.53, wpb=1011.7, bsz=32, num_updates=47260, lr=2.8868e-06, gnorm=21.682, clip=100, loss_scale=16, train_wall=19, gb_free=11.6, wall=88844
2023-05-27 00:04:08 - progress_bar.py[line:272] - INFO: epoch 028:    587 / 1732 loss=2.167, loss_v1=0, loss_v2=0, nll_loss=0.942, ntokens=962.2, nsentences=32, sample_size=962.2, sample_size_v1=0, sample_size_v2=0, ppl=1.92, wps=515.3, ups=0.54, wpb=962.2, bsz=32, num_updates=47270, lr=2.88066e-06, gnorm=20.816, clip=100, loss_scale=16, train_wall=19, gb_free=12, wall=88863
2023-05-27 00:04:27 - progress_bar.py[line:272] - INFO: epoch 028:    597 / 1732 loss=2.114, loss_v1=0, loss_v2=0, nll_loss=0.883, ntokens=975.4, nsentences=32, sample_size=975.4, sample_size_v1=0, sample_size_v2=0, ppl=1.84, wps=521.8, ups=0.53, wpb=975.4, bsz=32, num_updates=47280, lr=2.87452e-06, gnorm=20.472, clip=100, loss_scale=16, train_wall=19, gb_free=11.7, wall=88881
2023-05-27 00:04:45 - progress_bar.py[line:272] - INFO: epoch 028:    607 / 1732 loss=2.157, loss_v1=0, loss_v2=0, nll_loss=0.931, ntokens=882.8, nsentences=32, sample_size=882.8, sample_size_v1=0, sample_size_v2=0, ppl=1.91, wps=479.7, ups=0.54, wpb=882.8, bsz=32, num_updates=47290, lr=2.86837e-06, gnorm=20.888, clip=100, loss_scale=16, train_wall=18, gb_free=11.3, wall=88900
2023-05-27 00:05:04 - progress_bar.py[line:272] - INFO: epoch 028:    617 / 1732 loss=2.163, loss_v1=0, loss_v2=0, nll_loss=0.938, ntokens=866.1, nsentences=32, sample_size=866.1, sample_size_v1=0, sample_size_v2=0, ppl=1.92, wps=469.4, ups=0.54, wpb=866.1, bsz=32, num_updates=47300, lr=2.86223e-06, gnorm=21.844, clip=100, loss_scale=16, train_wall=18, gb_free=11.5, wall=88918
2023-05-27 00:05:22 - progress_bar.py[line:272] - INFO: epoch 028:    627 / 1732 loss=2.144, loss_v1=0, loss_v2=0, nll_loss=0.916, ntokens=930.6, nsentences=32, sample_size=930.6, sample_size_v1=0, sample_size_v2=0, ppl=1.89, wps=504.6, ups=0.54, wpb=930.6, bsz=32, num_updates=47310, lr=2.85609e-06, gnorm=20.951, clip=100, loss_scale=16, train_wall=18, gb_free=11.9, wall=88937
2023-05-27 00:05:40 - progress_bar.py[line:272] - INFO: epoch 028:    637 / 1732 loss=2.175, loss_v1=0, loss_v2=0, nll_loss=0.95, ntokens=914.3, nsentences=32, sample_size=914.3, sample_size_v1=0, sample_size_v2=0, ppl=1.93, wps=496, ups=0.54, wpb=914.3, bsz=32, num_updates=47320, lr=2.84995e-06, gnorm=22.91, clip=100, loss_scale=16, train_wall=18, gb_free=11.6, wall=88955
2023-05-27 00:05:59 - progress_bar.py[line:272] - INFO: epoch 028:    647 / 1732 loss=2.154, loss_v1=0, loss_v2=0, nll_loss=0.927, ntokens=980.8, nsentences=32, sample_size=980.8, sample_size_v1=0, sample_size_v2=0, ppl=1.9, wps=529.4, ups=0.54, wpb=980.8, bsz=32, num_updates=47330, lr=2.84381e-06, gnorm=19.927, clip=100, loss_scale=16, train_wall=18, gb_free=11.8, wall=88974
2023-05-27 00:06:17 - progress_bar.py[line:272] - INFO: epoch 028:    657 / 1732 loss=2.158, loss_v1=0, loss_v2=0, nll_loss=0.933, ntokens=894.4, nsentences=32, sample_size=894.4, sample_size_v1=0, sample_size_v2=0, ppl=1.91, wps=489.4, ups=0.55, wpb=894.4, bsz=32, num_updates=47340, lr=2.83766e-06, gnorm=20.61, clip=100, loss_scale=32, train_wall=18, gb_free=11.8, wall=88992
2023-05-27 00:06:36 - progress_bar.py[line:272] - INFO: epoch 028:    667 / 1732 loss=2.146, loss_v1=0, loss_v2=0, nll_loss=0.919, ntokens=903.9, nsentences=32, sample_size=903.9, sample_size_v1=0, sample_size_v2=0, ppl=1.89, wps=489.4, ups=0.54, wpb=903.9, bsz=32, num_updates=47350, lr=2.83152e-06, gnorm=22.045, clip=100, loss_scale=32, train_wall=18, gb_free=11.5, wall=89010
2023-05-27 00:06:54 - progress_bar.py[line:272] - INFO: epoch 028:    677 / 1732 loss=2.165, loss_v1=0, loss_v2=0, nll_loss=0.939, ntokens=985.3, nsentences=32, sample_size=985.3, sample_size_v1=0, sample_size_v2=0, ppl=1.92, wps=530.7, ups=0.54, wpb=985.3, bsz=32, num_updates=47360, lr=2.82538e-06, gnorm=19.83, clip=100, loss_scale=32, train_wall=19, gb_free=11.8, wall=89029
2023-05-27 00:07:13 - progress_bar.py[line:272] - INFO: epoch 028:    687 / 1732 loss=2.164, loss_v1=0, loss_v2=0, nll_loss=0.939, ntokens=943.2, nsentences=32, sample_size=943.2, sample_size_v1=0, sample_size_v2=0, ppl=1.92, wps=510.2, ups=0.54, wpb=943.2, bsz=32, num_updates=47370, lr=2.81924e-06, gnorm=21.007, clip=100, loss_scale=32, train_wall=18, gb_free=11.9, wall=89047
2023-05-27 00:07:31 - progress_bar.py[line:272] - INFO: epoch 028:    697 / 1732 loss=2.164, loss_v1=0, loss_v2=0, nll_loss=0.938, ntokens=1005.6, nsentences=32, sample_size=1005.6, sample_size_v1=0, sample_size_v2=0, ppl=1.92, wps=537.5, ups=0.53, wpb=1005.6, bsz=32, num_updates=47380, lr=2.8131e-06, gnorm=20.816, clip=100, loss_scale=32, train_wall=19, gb_free=10.9, wall=89066
2023-05-27 00:07:50 - progress_bar.py[line:272] - INFO: epoch 028:    707 / 1732 loss=2.133, loss_v1=0, loss_v2=0, nll_loss=0.904, ntokens=903.4, nsentences=32, sample_size=903.4, sample_size_v1=0, sample_size_v2=0, ppl=1.87, wps=489.1, ups=0.54, wpb=903.4, bsz=32, num_updates=47390, lr=2.80695e-06, gnorm=21.701, clip=100, loss_scale=32, train_wall=18, gb_free=11.6, wall=89085
2023-05-27 00:08:08 - progress_bar.py[line:272] - INFO: epoch 028:    717 / 1732 loss=2.128, loss_v1=0, loss_v2=0, nll_loss=0.899, ntokens=882.7, nsentences=32, sample_size=882.7, sample_size_v1=0, sample_size_v2=0, ppl=1.86, wps=479.5, ups=0.54, wpb=882.7, bsz=32, num_updates=47400, lr=2.80081e-06, gnorm=21.237, clip=100, loss_scale=32, train_wall=18, gb_free=11.6, wall=89103
2023-05-27 00:08:27 - progress_bar.py[line:272] - INFO: epoch 028:    727 / 1732 loss=2.122, loss_v1=0, loss_v2=0, nll_loss=0.892, ntokens=909.8, nsentences=32, sample_size=909.8, sample_size_v1=0, sample_size_v2=0, ppl=1.86, wps=492.4, ups=0.54, wpb=909.8, bsz=32, num_updates=47410, lr=2.79467e-06, gnorm=20.627, clip=100, loss_scale=32, train_wall=18, gb_free=11.9, wall=89122
2023-05-27 00:08:45 - progress_bar.py[line:272] - INFO: epoch 028:    737 / 1732 loss=2.145, loss_v1=0, loss_v2=0, nll_loss=0.917, ntokens=998.8, nsentences=32, sample_size=998.8, sample_size_v1=0, sample_size_v2=0, ppl=1.89, wps=539.4, ups=0.54, wpb=998.8, bsz=32, num_updates=47420, lr=2.78853e-06, gnorm=19.964, clip=100, loss_scale=32, train_wall=18, gb_free=11.5, wall=89140
2023-05-27 00:09:04 - progress_bar.py[line:272] - INFO: epoch 028:    747 / 1732 loss=2.13, loss_v1=0, loss_v2=0, nll_loss=0.9, ntokens=980.5, nsentences=32, sample_size=980.5, sample_size_v1=0, sample_size_v2=0, ppl=1.87, wps=526.9, ups=0.54, wpb=980.5, bsz=32, num_updates=47430, lr=2.78238e-06, gnorm=19.095, clip=100, loss_scale=32, train_wall=19, gb_free=11.3, wall=89159
2023-05-27 00:09:22 - progress_bar.py[line:272] - INFO: epoch 028:    757 / 1732 loss=2.131, loss_v1=0, loss_v2=0, nll_loss=0.901, ntokens=949.2, nsentences=32, sample_size=949.2, sample_size_v1=0, sample_size_v2=0, ppl=1.87, wps=514.8, ups=0.54, wpb=949.2, bsz=32, num_updates=47440, lr=2.77624e-06, gnorm=19.957, clip=100, loss_scale=32, train_wall=18, gb_free=11.6, wall=89177
2023-05-27 00:09:41 - progress_bar.py[line:272] - INFO: epoch 028:    767 / 1732 loss=2.142, loss_v1=0, loss_v2=0, nll_loss=0.914, ntokens=941.7, nsentences=32, sample_size=941.7, sample_size_v1=0, sample_size_v2=0, ppl=1.88, wps=510, ups=0.54, wpb=941.7, bsz=32, num_updates=47450, lr=2.7701e-06, gnorm=20.247, clip=100, loss_scale=32, train_wall=18, gb_free=11.9, wall=89196
2023-05-27 00:09:59 - progress_bar.py[line:272] - INFO: epoch 028:    777 / 1732 loss=2.138, loss_v1=0, loss_v2=0, nll_loss=0.911, ntokens=1028.6, nsentences=32, sample_size=1028.6, sample_size_v1=0, sample_size_v2=0, ppl=1.88, wps=553, ups=0.54, wpb=1028.6, bsz=32, num_updates=47460, lr=2.76396e-06, gnorm=19.28, clip=100, loss_scale=32, train_wall=19, gb_free=11.8, wall=89214
2023-05-27 00:10:18 - progress_bar.py[line:272] - INFO: epoch 028:    787 / 1732 loss=2.152, loss_v1=0, loss_v2=0, nll_loss=0.925, ntokens=1016.6, nsentences=32, sample_size=1016.6, sample_size_v1=0, sample_size_v2=0, ppl=1.9, wps=549.3, ups=0.54, wpb=1016.6, bsz=32, num_updates=47470, lr=2.75782e-06, gnorm=19.299, clip=100, loss_scale=32, train_wall=18, gb_free=11.3, wall=89233
2023-05-27 00:10:37 - progress_bar.py[line:272] - INFO: epoch 028:    797 / 1732 loss=2.164, loss_v1=0, loss_v2=0, nll_loss=0.941, ntokens=1038, nsentences=32, sample_size=1038, sample_size_v1=0, sample_size_v2=0, ppl=1.92, wps=558.8, ups=0.54, wpb=1038, bsz=32, num_updates=47480, lr=2.75167e-06, gnorm=19.946, clip=100, loss_scale=32, train_wall=19, gb_free=11.6, wall=89251
2023-05-27 00:10:55 - progress_bar.py[line:272] - INFO: epoch 028:    807 / 1732 loss=2.142, loss_v1=0, loss_v2=0, nll_loss=0.913, ntokens=915, nsentences=32, sample_size=915, sample_size_v1=0, sample_size_v2=0, ppl=1.88, wps=494.8, ups=0.54, wpb=915, bsz=32, num_updates=47490, lr=2.74553e-06, gnorm=21.37, clip=100, loss_scale=32, train_wall=18, gb_free=11.4, wall=89270
2023-05-27 00:11:14 - progress_bar.py[line:272] - INFO: epoch 028:    817 / 1732 loss=2.155, loss_v1=0, loss_v2=0, nll_loss=0.928, ntokens=917.4, nsentences=32, sample_size=917.4, sample_size_v1=0, sample_size_v2=0, ppl=1.9, wps=495.2, ups=0.54, wpb=917.4, bsz=32, num_updates=47500, lr=2.73939e-06, gnorm=22.616, clip=100, loss_scale=32, train_wall=18, gb_free=11.7, wall=89288
2023-05-27 00:11:32 - progress_bar.py[line:272] - INFO: epoch 028:    827 / 1732 loss=2.14, loss_v1=0, loss_v2=0, nll_loss=0.912, ntokens=930.6, nsentences=32, sample_size=930.6, sample_size_v1=0, sample_size_v2=0, ppl=1.88, wps=502.2, ups=0.54, wpb=930.6, bsz=32, num_updates=47510, lr=2.73325e-06, gnorm=20.676, clip=100, loss_scale=32, train_wall=18, gb_free=11.7, wall=89307
2023-05-27 00:11:50 - progress_bar.py[line:272] - INFO: epoch 028:    837 / 1732 loss=2.154, loss_v1=0, loss_v2=0, nll_loss=0.928, ntokens=894.5, nsentences=32, sample_size=894.5, sample_size_v1=0, sample_size_v2=0, ppl=1.9, wps=488.1, ups=0.55, wpb=894.5, bsz=32, num_updates=47520, lr=2.72711e-06, gnorm=23.383, clip=100, loss_scale=32, train_wall=18, gb_free=11.7, wall=89325
2023-05-27 00:12:09 - progress_bar.py[line:272] - INFO: epoch 028:    847 / 1732 loss=2.138, loss_v1=0, loss_v2=0, nll_loss=0.909, ntokens=1012.6, nsentences=32, sample_size=1012.6, sample_size_v1=0, sample_size_v2=0, ppl=1.88, wps=547.1, ups=0.54, wpb=1012.6, bsz=32, num_updates=47530, lr=2.72096e-06, gnorm=20.338, clip=100, loss_scale=32, train_wall=18, gb_free=10.6, wall=89344
2023-05-27 00:12:27 - progress_bar.py[line:272] - INFO: epoch 028:    857 / 1732 loss=2.136, loss_v1=0, loss_v2=0, nll_loss=0.906, ntokens=920, nsentences=32, sample_size=920, sample_size_v1=0, sample_size_v2=0, ppl=1.87, wps=497.7, ups=0.54, wpb=920, bsz=32, num_updates=47540, lr=2.71482e-06, gnorm=21.069, clip=100, loss_scale=32, train_wall=18, gb_free=11.7, wall=89362
2023-05-27 00:12:46 - progress_bar.py[line:272] - INFO: epoch 028:    867 / 1732 loss=2.156, loss_v1=0, loss_v2=0, nll_loss=0.931, ntokens=979.9, nsentences=32, sample_size=979.9, sample_size_v1=0, sample_size_v2=0, ppl=1.91, wps=529.9, ups=0.54, wpb=979.9, bsz=32, num_updates=47550, lr=2.70868e-06, gnorm=20.688, clip=100, loss_scale=32, train_wall=18, gb_free=11.3, wall=89381
2023-05-27 00:13:05 - progress_bar.py[line:272] - INFO: epoch 028:    877 / 1732 loss=2.091, loss_v1=0, loss_v2=0, nll_loss=0.857, ntokens=994.5, nsentences=32, sample_size=994.5, sample_size_v1=0, sample_size_v2=0, ppl=1.81, wps=535.3, ups=0.54, wpb=994.5, bsz=32, num_updates=47560, lr=2.70254e-06, gnorm=19.449, clip=100, loss_scale=32, train_wall=19, gb_free=11.7, wall=89399
2023-05-27 00:13:23 - progress_bar.py[line:272] - INFO: epoch 028:    887 / 1732 loss=2.109, loss_v1=0, loss_v2=0, nll_loss=0.877, ntokens=982, nsentences=32, sample_size=982, sample_size_v1=0, sample_size_v2=0, ppl=1.84, wps=526.8, ups=0.54, wpb=982, bsz=32, num_updates=47570, lr=2.69639e-06, gnorm=20.309, clip=100, loss_scale=32, train_wall=19, gb_free=11.2, wall=89418
2023-05-27 00:13:42 - progress_bar.py[line:272] - INFO: epoch 028:    897 / 1732 loss=2.093, loss_v1=0, loss_v2=0, nll_loss=0.86, ntokens=1034.6, nsentences=32, sample_size=1034.6, sample_size_v1=0, sample_size_v2=0, ppl=1.81, wps=555.6, ups=0.54, wpb=1034.6, bsz=32, num_updates=47580, lr=2.69025e-06, gnorm=19.902, clip=100, loss_scale=32, train_wall=19, gb_free=11.5, wall=89436
2023-05-27 00:14:00 - progress_bar.py[line:272] - INFO: epoch 028:    907 / 1732 loss=2.1, loss_v1=0, loss_v2=0, nll_loss=0.867, ntokens=1016.8, nsentences=32, sample_size=1016.8, sample_size_v1=0, sample_size_v2=0, ppl=1.82, wps=546.7, ups=0.54, wpb=1016.8, bsz=32, num_updates=47590, lr=2.68411e-06, gnorm=18.944, clip=100, loss_scale=32, train_wall=19, gb_free=11.6, wall=89455
2023-05-27 00:14:19 - progress_bar.py[line:272] - INFO: epoch 028:    917 / 1732 loss=2.185, loss_v1=0, loss_v2=0, nll_loss=0.964, ntokens=936.4, nsentences=32, sample_size=936.4, sample_size_v1=0, sample_size_v2=0, ppl=1.95, wps=506.7, ups=0.54, wpb=936.4, bsz=32, num_updates=47600, lr=2.67797e-06, gnorm=21.072, clip=100, loss_scale=32, train_wall=18, gb_free=11.8, wall=89474
2023-05-27 00:14:38 - progress_bar.py[line:272] - INFO: epoch 028:    927 / 1732 loss=2.113, loss_v1=0, loss_v2=0, nll_loss=0.882, ntokens=1039.7, nsentences=32, sample_size=1039.7, sample_size_v1=0, sample_size_v2=0, ppl=1.84, wps=555.8, ups=0.53, wpb=1039.7, bsz=32, num_updates=47610, lr=2.67183e-06, gnorm=20.193, clip=100, loss_scale=32, train_wall=19, gb_free=11.5, wall=89492
2023-05-27 00:14:56 - progress_bar.py[line:272] - INFO: epoch 028:    937 / 1732 loss=2.148, loss_v1=0, loss_v2=0, nll_loss=0.92, ntokens=1061.1, nsentences=32, sample_size=1061.1, sample_size_v1=0, sample_size_v2=0, ppl=1.89, wps=563.3, ups=0.53, wpb=1061.1, bsz=32, num_updates=47620, lr=2.66568e-06, gnorm=19.493, clip=100, loss_scale=32, train_wall=19, gb_free=11.5, wall=89511
2023-05-27 00:15:15 - progress_bar.py[line:272] - INFO: epoch 028:    947 / 1732 loss=2.157, loss_v1=0, loss_v2=0, nll_loss=0.931, ntokens=1042.4, nsentences=32, sample_size=1042.4, sample_size_v1=0, sample_size_v2=0, ppl=1.91, wps=552.2, ups=0.53, wpb=1042.4, bsz=32, num_updates=47630, lr=2.65954e-06, gnorm=21.405, clip=100, loss_scale=32, train_wall=19, gb_free=11.2, wall=89530
2023-05-27 00:15:34 - progress_bar.py[line:272] - INFO: epoch 028:    957 / 1732 loss=2.144, loss_v1=0, loss_v2=0, nll_loss=0.916, ntokens=1046.8, nsentences=32, sample_size=1046.8, sample_size_v1=0, sample_size_v2=0, ppl=1.89, wps=558.5, ups=0.53, wpb=1046.8, bsz=32, num_updates=47640, lr=2.6534e-06, gnorm=19.4, clip=100, loss_scale=32, train_wall=19, gb_free=11.1, wall=89549
2023-05-27 00:15:53 - progress_bar.py[line:272] - INFO: epoch 028:    967 / 1732 loss=2.148, loss_v1=0, loss_v2=0, nll_loss=0.922, ntokens=1036.4, nsentences=32, sample_size=1036.4, sample_size_v1=0, sample_size_v2=0, ppl=1.89, wps=553.2, ups=0.53, wpb=1036.4, bsz=32, num_updates=47650, lr=2.64726e-06, gnorm=21.343, clip=100, loss_scale=32, train_wall=19, gb_free=11.3, wall=89567
2023-05-27 00:16:12 - progress_bar.py[line:272] - INFO: epoch 028:    977 / 1732 loss=2.117, loss_v1=0, loss_v2=0, nll_loss=0.886, ntokens=1035.2, nsentences=32, sample_size=1035.2, sample_size_v1=0, sample_size_v2=0, ppl=1.85, wps=547.7, ups=0.53, wpb=1035.2, bsz=32, num_updates=47660, lr=2.64112e-06, gnorm=18.727, clip=100, loss_scale=32, train_wall=19, gb_free=10.4, wall=89586
2023-05-27 00:16:31 - progress_bar.py[line:272] - INFO: epoch 028:    987 / 1732 loss=2.131, loss_v1=0, loss_v2=0, nll_loss=0.903, ntokens=1020.1, nsentences=32, sample_size=1020.1, sample_size_v1=0, sample_size_v2=0, ppl=1.87, wps=539.8, ups=0.53, wpb=1020.1, bsz=32, num_updates=47670, lr=2.63497e-06, gnorm=18.432, clip=100, loss_scale=32, train_wall=19, gb_free=11.3, wall=89605
2023-05-27 00:16:49 - progress_bar.py[line:272] - INFO: epoch 028:    997 / 1732 loss=2.133, loss_v1=0, loss_v2=0, nll_loss=0.904, ntokens=1032.4, nsentences=32, sample_size=1032.4, sample_size_v1=0, sample_size_v2=0, ppl=1.87, wps=551.4, ups=0.53, wpb=1032.4, bsz=32, num_updates=47680, lr=2.62883e-06, gnorm=20.176, clip=100, loss_scale=32, train_wall=19, gb_free=11.7, wall=89624
2023-05-27 00:17:08 - progress_bar.py[line:272] - INFO: epoch 028:   1007 / 1732 loss=2.132, loss_v1=0, loss_v2=0, nll_loss=0.903, ntokens=1018.9, nsentences=32, sample_size=1018.9, sample_size_v1=0, sample_size_v2=0, ppl=1.87, wps=544.3, ups=0.53, wpb=1018.9, bsz=32, num_updates=47690, lr=2.62269e-06, gnorm=19.484, clip=100, loss_scale=32, train_wall=19, gb_free=11.3, wall=89643
2023-05-27 00:17:27 - progress_bar.py[line:272] - INFO: epoch 028:   1017 / 1732 loss=2.115, loss_v1=0, loss_v2=0, nll_loss=0.882, ntokens=1024.8, nsentences=32, sample_size=1024.8, sample_size_v1=0, sample_size_v2=0, ppl=1.84, wps=548.4, ups=0.54, wpb=1024.8, bsz=32, num_updates=47700, lr=2.61655e-06, gnorm=19.04, clip=100, loss_scale=32, train_wall=19, gb_free=10.5, wall=89661
2023-05-27 00:17:46 - progress_bar.py[line:272] - INFO: epoch 028:   1027 / 1732 loss=2.151, loss_v1=0, loss_v2=0, nll_loss=0.923, ntokens=1051.5, nsentences=32, sample_size=1051.5, sample_size_v1=0, sample_size_v2=0, ppl=1.9, wps=557.1, ups=0.53, wpb=1051.5, bsz=32, num_updates=47710, lr=2.6104e-06, gnorm=20.066, clip=100, loss_scale=32, train_wall=19, gb_free=11.3, wall=89680
2023-05-27 00:17:53 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2023-05-27 00:18:06 - progress_bar.py[line:272] - INFO: epoch 028:   1038 / 1732 loss=2.12, loss_v1=0, loss_v2=0, nll_loss=0.89, ntokens=1112, nsentences=32, sample_size=1112, sample_size_v1=0, sample_size_v2=0, ppl=1.85, wps=535.4, ups=0.48, wpb=1112, bsz=32, num_updates=47720, lr=2.60426e-06, gnorm=17.596, clip=100, loss_scale=16, train_wall=21, gb_free=11.7, wall=89701
2023-05-27 00:18:25 - progress_bar.py[line:272] - INFO: epoch 028:   1048 / 1732 loss=2.119, loss_v1=0, loss_v2=0, nll_loss=0.888, ntokens=1025.8, nsentences=32, sample_size=1025.8, sample_size_v1=0, sample_size_v2=0, ppl=1.85, wps=545.8, ups=0.53, wpb=1025.8, bsz=32, num_updates=47730, lr=2.59812e-06, gnorm=19.864, clip=100, loss_scale=16, train_wall=19, gb_free=11.4, wall=89720
2023-05-27 00:18:44 - progress_bar.py[line:272] - INFO: epoch 028:   1058 / 1732 loss=2.131, loss_v1=0, loss_v2=0, nll_loss=0.902, ntokens=1082.8, nsentences=32, sample_size=1082.8, sample_size_v1=0, sample_size_v2=0, ppl=1.87, wps=577.2, ups=0.53, wpb=1082.8, bsz=32, num_updates=47740, lr=2.59198e-06, gnorm=17.999, clip=100, loss_scale=16, train_wall=19, gb_free=11.8, wall=89739
2023-05-27 00:19:03 - progress_bar.py[line:272] - INFO: epoch 028:   1068 / 1732 loss=2.121, loss_v1=0, loss_v2=0, nll_loss=0.89, ntokens=1002.9, nsentences=32, sample_size=1002.9, sample_size_v1=0, sample_size_v2=0, ppl=1.85, wps=536.6, ups=0.54, wpb=1002.9, bsz=32, num_updates=47750, lr=2.58584e-06, gnorm=17.816, clip=100, loss_scale=16, train_wall=19, gb_free=11.7, wall=89757
2023-05-27 00:19:22 - progress_bar.py[line:272] - INFO: epoch 028:   1078 / 1732 loss=2.146, loss_v1=0, loss_v2=0, nll_loss=0.919, ntokens=1000.2, nsentences=32, sample_size=1000.2, sample_size_v1=0, sample_size_v2=0, ppl=1.89, wps=530.7, ups=0.53, wpb=1000.2, bsz=32, num_updates=47760, lr=2.57969e-06, gnorm=19.686, clip=100, loss_scale=16, train_wall=19, gb_free=11.5, wall=89776
2023-05-27 00:19:40 - progress_bar.py[line:272] - INFO: epoch 028:   1088 / 1732 loss=2.122, loss_v1=0, loss_v2=0, nll_loss=0.891, ntokens=1078.6, nsentences=32, sample_size=1078.6, sample_size_v1=0, sample_size_v2=0, ppl=1.85, wps=569.6, ups=0.53, wpb=1078.6, bsz=32, num_updates=47770, lr=2.57355e-06, gnorm=19.002, clip=100, loss_scale=16, train_wall=19, gb_free=11.4, wall=89795
2023-05-27 00:19:59 - progress_bar.py[line:272] - INFO: epoch 028:   1098 / 1732 loss=2.144, loss_v1=0, loss_v2=0, nll_loss=0.916, ntokens=1045.6, nsentences=32, sample_size=1045.6, sample_size_v1=0, sample_size_v2=0, ppl=1.89, wps=551.9, ups=0.53, wpb=1045.6, bsz=32, num_updates=47780, lr=2.56741e-06, gnorm=19.48, clip=100, loss_scale=16, train_wall=19, gb_free=10.8, wall=89814
2023-05-27 00:20:18 - progress_bar.py[line:272] - INFO: epoch 028:   1108 / 1732 loss=2.127, loss_v1=0, loss_v2=0, nll_loss=0.898, ntokens=1058.8, nsentences=32, sample_size=1058.8, sample_size_v1=0, sample_size_v2=0, ppl=1.86, wps=561.5, ups=0.53, wpb=1058.8, bsz=32, num_updates=47790, lr=2.56127e-06, gnorm=18.127, clip=100, loss_scale=16, train_wall=19, gb_free=11.6, wall=89833
2023-05-27 00:20:37 - progress_bar.py[line:272] - INFO: epoch 028:   1118 / 1732 loss=2.134, loss_v1=0, loss_v2=0, nll_loss=0.905, ntokens=944.7, nsentences=32, sample_size=944.7, sample_size_v1=0, sample_size_v2=0, ppl=1.87, wps=502.5, ups=0.53, wpb=944.7, bsz=32, num_updates=47800, lr=2.55513e-06, gnorm=20.171, clip=100, loss_scale=16, train_wall=19, gb_free=11.2, wall=89852
2023-05-27 00:20:56 - progress_bar.py[line:272] - INFO: epoch 028:   1128 / 1732 loss=2.128, loss_v1=0, loss_v2=0, nll_loss=0.899, ntokens=1025.9, nsentences=32, sample_size=1025.9, sample_size_v1=0, sample_size_v2=0, ppl=1.86, wps=544.6, ups=0.53, wpb=1025.9, bsz=32, num_updates=47810, lr=2.54898e-06, gnorm=19.856, clip=100, loss_scale=16, train_wall=19, gb_free=10.7, wall=89871
2023-05-27 00:21:15 - progress_bar.py[line:272] - INFO: epoch 028:   1138 / 1732 loss=2.122, loss_v1=0, loss_v2=0, nll_loss=0.89, ntokens=989.2, nsentences=32, sample_size=989.2, sample_size_v1=0, sample_size_v2=0, ppl=1.85, wps=528.1, ups=0.53, wpb=989.2, bsz=32, num_updates=47820, lr=2.54284e-06, gnorm=21.004, clip=100, loss_scale=16, train_wall=19, gb_free=11.6, wall=89889
2023-05-27 00:21:33 - progress_bar.py[line:272] - INFO: epoch 028:   1148 / 1732 loss=2.13, loss_v1=0, loss_v2=0, nll_loss=0.901, ntokens=1007.7, nsentences=32, sample_size=1007.7, sample_size_v1=0, sample_size_v2=0, ppl=1.87, wps=537.7, ups=0.53, wpb=1007.7, bsz=32, num_updates=47830, lr=2.5367e-06, gnorm=19.584, clip=100, loss_scale=16, train_wall=19, gb_free=11.5, wall=89908
2023-05-27 00:21:52 - progress_bar.py[line:272] - INFO: epoch 028:   1158 / 1732 loss=2.104, loss_v1=0, loss_v2=0, nll_loss=0.871, ntokens=1016, nsentences=32, sample_size=1016, sample_size_v1=0, sample_size_v2=0, ppl=1.83, wps=540.6, ups=0.53, wpb=1016, bsz=32, num_updates=47840, lr=2.53056e-06, gnorm=18.559, clip=100, loss_scale=16, train_wall=19, gb_free=10.8, wall=89927
2023-05-27 00:22:11 - progress_bar.py[line:272] - INFO: epoch 028:   1168 / 1732 loss=2.118, loss_v1=0, loss_v2=0, nll_loss=0.886, ntokens=1020.6, nsentences=32, sample_size=1020.6, sample_size_v1=0, sample_size_v2=0, ppl=1.85, wps=543.9, ups=0.53, wpb=1020.6, bsz=32, num_updates=47850, lr=2.52441e-06, gnorm=19.17, clip=100, loss_scale=16, train_wall=19, gb_free=10.9, wall=89946
2023-05-27 00:22:30 - progress_bar.py[line:272] - INFO: epoch 028:   1178 / 1732 loss=2.109, loss_v1=0, loss_v2=0, nll_loss=0.877, ntokens=1067, nsentences=32, sample_size=1067, sample_size_v1=0, sample_size_v2=0, ppl=1.84, wps=568.2, ups=0.53, wpb=1067, bsz=32, num_updates=47860, lr=2.51827e-06, gnorm=19.702, clip=100, loss_scale=16, train_wall=19, gb_free=11.6, wall=89964
2023-05-27 00:22:48 - progress_bar.py[line:272] - INFO: epoch 028:   1188 / 1732 loss=2.111, loss_v1=0, loss_v2=0, nll_loss=0.879, ntokens=963.5, nsentences=32, sample_size=963.5, sample_size_v1=0, sample_size_v2=0, ppl=1.84, wps=514.9, ups=0.53, wpb=963.5, bsz=32, num_updates=47870, lr=2.51213e-06, gnorm=21.657, clip=100, loss_scale=16, train_wall=19, gb_free=11.1, wall=89983
2023-05-27 00:23:07 - progress_bar.py[line:272] - INFO: epoch 028:   1198 / 1732 loss=2.117, loss_v1=0, loss_v2=0, nll_loss=0.887, ntokens=1123.7, nsentences=32, sample_size=1123.7, sample_size_v1=0, sample_size_v2=0, ppl=1.85, wps=595.1, ups=0.53, wpb=1123.7, bsz=32, num_updates=47880, lr=2.50599e-06, gnorm=18.99, clip=100, loss_scale=16, train_wall=19, gb_free=11.2, wall=90002
2023-05-27 00:23:26 - progress_bar.py[line:272] - INFO: epoch 028:   1208 / 1732 loss=2.097, loss_v1=0, loss_v2=0, nll_loss=0.863, ntokens=1088.9, nsentences=32, sample_size=1088.9, sample_size_v1=0, sample_size_v2=0, ppl=1.82, wps=571.7, ups=0.53, wpb=1088.9, bsz=32, num_updates=47890, lr=2.49985e-06, gnorm=19.384, clip=100, loss_scale=16, train_wall=19, gb_free=10.6, wall=90021
2023-05-27 00:23:45 - progress_bar.py[line:272] - INFO: epoch 028:   1218 / 1732 loss=2.143, loss_v1=0, loss_v2=0, nll_loss=0.915, ntokens=1016, nsentences=32, sample_size=1016, sample_size_v1=0, sample_size_v2=0, ppl=1.89, wps=542, ups=0.53, wpb=1016, bsz=32, num_updates=47900, lr=2.4937e-06, gnorm=19.47, clip=100, loss_scale=16, train_wall=19, gb_free=11.6, wall=90040
2023-05-27 00:24:04 - progress_bar.py[line:272] - INFO: epoch 028:   1228 / 1732 loss=2.129, loss_v1=0, loss_v2=0, nll_loss=0.899, ntokens=1018.6, nsentences=32, sample_size=1018.6, sample_size_v1=0, sample_size_v2=0, ppl=1.87, wps=543.3, ups=0.53, wpb=1018.6, bsz=32, num_updates=47910, lr=2.48756e-06, gnorm=21.106, clip=100, loss_scale=16, train_wall=19, gb_free=11.5, wall=90059
2023-05-27 00:24:23 - progress_bar.py[line:272] - INFO: epoch 028:   1238 / 1732 loss=2.099, loss_v1=0, loss_v2=0, nll_loss=0.867, ntokens=1070.1, nsentences=32, sample_size=1070.1, sample_size_v1=0, sample_size_v2=0, ppl=1.82, wps=566, ups=0.53, wpb=1070.1, bsz=32, num_updates=47920, lr=2.48142e-06, gnorm=19.155, clip=100, loss_scale=16, train_wall=19, gb_free=11.2, wall=90077
2023-05-27 00:24:42 - progress_bar.py[line:272] - INFO: epoch 028:   1248 / 1732 loss=2.085, loss_v1=0, loss_v2=0, nll_loss=0.849, ntokens=1083.3, nsentences=32, sample_size=1083.3, sample_size_v1=0, sample_size_v2=0, ppl=1.8, wps=573, ups=0.53, wpb=1083.3, bsz=32, num_updates=47930, lr=2.47528e-06, gnorm=17.949, clip=100, loss_scale=16, train_wall=19, gb_free=11.3, wall=90096
2023-05-27 00:25:01 - progress_bar.py[line:272] - INFO: epoch 028:   1258 / 1732 loss=2.102, loss_v1=0, loss_v2=0, nll_loss=0.868, ntokens=1058.8, nsentences=32, sample_size=1058.8, sample_size_v1=0, sample_size_v2=0, ppl=1.83, wps=562.9, ups=0.53, wpb=1058.8, bsz=32, num_updates=47940, lr=2.46914e-06, gnorm=19.645, clip=100, loss_scale=16, train_wall=19, gb_free=11.1, wall=90115
2023-05-27 00:25:19 - progress_bar.py[line:272] - INFO: epoch 028:   1268 / 1732 loss=2.121, loss_v1=0, loss_v2=0, nll_loss=0.892, ntokens=1040.1, nsentences=32, sample_size=1040.1, sample_size_v1=0, sample_size_v2=0, ppl=1.86, wps=551.7, ups=0.53, wpb=1040.1, bsz=32, num_updates=47950, lr=2.46299e-06, gnorm=19.593, clip=100, loss_scale=16, train_wall=19, gb_free=11.4, wall=90134
2023-05-27 00:25:38 - progress_bar.py[line:272] - INFO: epoch 028:   1278 / 1732 loss=2.117, loss_v1=0, loss_v2=0, nll_loss=0.886, ntokens=1064.5, nsentences=32, sample_size=1064.5, sample_size_v1=0, sample_size_v2=0, ppl=1.85, wps=562.4, ups=0.53, wpb=1064.5, bsz=32, num_updates=47960, lr=2.45685e-06, gnorm=17.445, clip=100, loss_scale=16, train_wall=19, gb_free=11.4, wall=90153
2023-05-27 00:25:57 - progress_bar.py[line:272] - INFO: epoch 028:   1288 / 1732 loss=2.097, loss_v1=0, loss_v2=0, nll_loss=0.863, ntokens=1074.2, nsentences=32, sample_size=1074.2, sample_size_v1=0, sample_size_v2=0, ppl=1.82, wps=568.4, ups=0.53, wpb=1074.2, bsz=32, num_updates=47970, lr=2.45071e-06, gnorm=18.569, clip=100, loss_scale=16, train_wall=19, gb_free=10, wall=90172
2023-05-27 00:26:16 - progress_bar.py[line:272] - INFO: epoch 028:   1298 / 1732 loss=2.109, loss_v1=0, loss_v2=0, nll_loss=0.877, ntokens=1104.5, nsentences=32, sample_size=1104.5, sample_size_v1=0, sample_size_v2=0, ppl=1.84, wps=583, ups=0.53, wpb=1104.5, bsz=32, num_updates=47980, lr=2.44457e-06, gnorm=17.877, clip=100, loss_scale=16, train_wall=19, gb_free=11.1, wall=90191
2023-05-27 00:26:35 - progress_bar.py[line:272] - INFO: epoch 028:   1308 / 1732 loss=2.152, loss_v1=0, loss_v2=0, nll_loss=0.924, ntokens=1079.8, nsentences=32, sample_size=1079.8, sample_size_v1=0, sample_size_v2=0, ppl=1.9, wps=567.5, ups=0.53, wpb=1079.8, bsz=32, num_updates=47990, lr=2.43843e-06, gnorm=20.241, clip=100, loss_scale=16, train_wall=19, gb_free=10.5, wall=90210
2023-05-27 00:26:54 - progress_bar.py[line:272] - INFO: epoch 028:   1318 / 1732 loss=2.115, loss_v1=0, loss_v2=0, nll_loss=0.884, ntokens=1085.2, nsentences=32, sample_size=1085.2, sample_size_v1=0, sample_size_v2=0, ppl=1.85, wps=573.7, ups=0.53, wpb=1085.2, bsz=32, num_updates=48000, lr=2.43228e-06, gnorm=19.207, clip=100, loss_scale=16, train_wall=19, gb_free=10.9, wall=90229
2023-05-27 00:27:13 - progress_bar.py[line:272] - INFO: epoch 028:   1328 / 1732 loss=2.087, loss_v1=0, loss_v2=0, nll_loss=0.853, ntokens=1103.2, nsentences=32, sample_size=1103.2, sample_size_v1=0, sample_size_v2=0, ppl=1.81, wps=581.3, ups=0.53, wpb=1103.2, bsz=32, num_updates=48010, lr=2.42614e-06, gnorm=18.381, clip=100, loss_scale=16, train_wall=19, gb_free=11, wall=90248
2023-05-27 00:27:32 - progress_bar.py[line:272] - INFO: epoch 028:   1338 / 1732 loss=2.111, loss_v1=0, loss_v2=0, nll_loss=0.88, ntokens=1116.2, nsentences=32, sample_size=1116.2, sample_size_v1=0, sample_size_v2=0, ppl=1.84, wps=591.1, ups=0.53, wpb=1116.2, bsz=32, num_updates=48020, lr=2.42e-06, gnorm=18.958, clip=100, loss_scale=16, train_wall=19, gb_free=10.6, wall=90267
2023-05-27 00:27:51 - progress_bar.py[line:272] - INFO: epoch 028:   1348 / 1732 loss=2.114, loss_v1=0, loss_v2=0, nll_loss=0.883, ntokens=1187.2, nsentences=32, sample_size=1187.2, sample_size_v1=0, sample_size_v2=0, ppl=1.84, wps=623.7, ups=0.53, wpb=1187.2, bsz=32, num_updates=48030, lr=2.41386e-06, gnorm=18.203, clip=100, loss_scale=16, train_wall=19, gb_free=10.7, wall=90286
2023-05-27 00:28:10 - progress_bar.py[line:272] - INFO: epoch 028:   1358 / 1732 loss=2.103, loss_v1=0, loss_v2=0, nll_loss=0.872, ntokens=1099, nsentences=32, sample_size=1099, sample_size_v1=0, sample_size_v2=0, ppl=1.83, wps=580.9, ups=0.53, wpb=1099, bsz=32, num_updates=48040, lr=2.40771e-06, gnorm=19.141, clip=100, loss_scale=16, train_wall=19, gb_free=11.3, wall=90305
2023-05-27 00:28:29 - progress_bar.py[line:272] - INFO: epoch 028:   1368 / 1732 loss=2.126, loss_v1=0, loss_v2=0, nll_loss=0.897, ntokens=1106.4, nsentences=32, sample_size=1106.4, sample_size_v1=0, sample_size_v2=0, ppl=1.86, wps=584.2, ups=0.53, wpb=1106.4, bsz=32, num_updates=48050, lr=2.40157e-06, gnorm=19.562, clip=100, loss_scale=16, train_wall=19, gb_free=11.3, wall=90324
2023-05-27 00:28:48 - progress_bar.py[line:272] - INFO: epoch 028:   1378 / 1732 loss=2.147, loss_v1=0, loss_v2=0, nll_loss=0.92, ntokens=1104.2, nsentences=32, sample_size=1104.2, sample_size_v1=0, sample_size_v2=0, ppl=1.89, wps=586.9, ups=0.53, wpb=1104.2, bsz=32, num_updates=48060, lr=2.39543e-06, gnorm=17.96, clip=100, loss_scale=16, train_wall=19, gb_free=11.3, wall=90342
2023-05-27 00:29:07 - progress_bar.py[line:272] - INFO: epoch 028:   1388 / 1732 loss=2.129, loss_v1=0, loss_v2=0, nll_loss=0.9, ntokens=1131.9, nsentences=32, sample_size=1131.9, sample_size_v1=0, sample_size_v2=0, ppl=1.87, wps=601.7, ups=0.53, wpb=1131.9, bsz=32, num_updates=48070, lr=2.38929e-06, gnorm=17.908, clip=100, loss_scale=16, train_wall=19, gb_free=11.5, wall=90361
2023-05-27 00:29:25 - progress_bar.py[line:272] - INFO: epoch 028:   1398 / 1732 loss=2.101, loss_v1=0, loss_v2=0, nll_loss=0.868, ntokens=1097.3, nsentences=32, sample_size=1097.3, sample_size_v1=0, sample_size_v2=0, ppl=1.82, wps=581.3, ups=0.53, wpb=1097.3, bsz=32, num_updates=48080, lr=2.38315e-06, gnorm=18.529, clip=100, loss_scale=16, train_wall=19, gb_free=11.3, wall=90380
2023-05-27 00:29:44 - progress_bar.py[line:272] - INFO: epoch 028:   1408 / 1732 loss=2.144, loss_v1=0, loss_v2=0, nll_loss=0.917, ntokens=1161.5, nsentences=32, sample_size=1161.5, sample_size_v1=0, sample_size_v2=0, ppl=1.89, wps=615.1, ups=0.53, wpb=1161.5, bsz=32, num_updates=48090, lr=2.377e-06, gnorm=18.869, clip=100, loss_scale=16, train_wall=19, gb_free=11.3, wall=90399
2023-05-27 00:30:03 - progress_bar.py[line:272] - INFO: epoch 028:   1418 / 1732 loss=2.159, loss_v1=0, loss_v2=0, nll_loss=0.935, ntokens=1285.2, nsentences=32, sample_size=1285.2, sample_size_v1=0, sample_size_v2=0, ppl=1.91, wps=670.9, ups=0.52, wpb=1285.2, bsz=32, num_updates=48100, lr=2.37086e-06, gnorm=17.343, clip=100, loss_scale=16, train_wall=19, gb_free=10.7, wall=90418
2023-05-27 00:30:22 - progress_bar.py[line:272] - INFO: epoch 028:   1428 / 1732 loss=2.12, loss_v1=0, loss_v2=0, nll_loss=0.891, ntokens=1229.6, nsentences=32, sample_size=1229.6, sample_size_v1=0, sample_size_v2=0, ppl=1.85, wps=646.3, ups=0.53, wpb=1229.6, bsz=32, num_updates=48110, lr=2.36472e-06, gnorm=17.57, clip=100, loss_scale=16, train_wall=19, gb_free=11.4, wall=90437
2023-05-27 00:30:41 - progress_bar.py[line:272] - INFO: epoch 028:   1438 / 1732 loss=2.12, loss_v1=0, loss_v2=0, nll_loss=0.89, ntokens=1179.5, nsentences=32, sample_size=1179.5, sample_size_v1=0, sample_size_v2=0, ppl=1.85, wps=622.2, ups=0.53, wpb=1179.5, bsz=32, num_updates=48120, lr=2.35858e-06, gnorm=17.424, clip=100, loss_scale=16, train_wall=19, gb_free=11.6, wall=90456
2023-05-27 00:31:00 - progress_bar.py[line:272] - INFO: epoch 028:   1448 / 1732 loss=2.122, loss_v1=0, loss_v2=0, nll_loss=0.893, ntokens=1120.7, nsentences=32, sample_size=1120.7, sample_size_v1=0, sample_size_v2=0, ppl=1.86, wps=595.1, ups=0.53, wpb=1120.7, bsz=32, num_updates=48130, lr=2.35244e-06, gnorm=16.822, clip=100, loss_scale=16, train_wall=19, gb_free=11.4, wall=90475
2023-05-27 00:31:20 - progress_bar.py[line:272] - INFO: epoch 028:   1458 / 1732 loss=2.123, loss_v1=0, loss_v2=0, nll_loss=0.892, ntokens=1151.7, nsentences=32, sample_size=1151.7, sample_size_v1=0, sample_size_v2=0, ppl=1.86, wps=598.4, ups=0.52, wpb=1151.7, bsz=32, num_updates=48140, lr=2.34629e-06, gnorm=19.165, clip=100, loss_scale=16, train_wall=19, gb_free=10.8, wall=90494
2023-05-27 00:31:39 - progress_bar.py[line:272] - INFO: epoch 028:   1468 / 1732 loss=2.102, loss_v1=0, loss_v2=0, nll_loss=0.869, ntokens=1195.8, nsentences=32, sample_size=1195.8, sample_size_v1=0, sample_size_v2=0, ppl=1.83, wps=624.2, ups=0.52, wpb=1195.8, bsz=32, num_updates=48150, lr=2.34015e-06, gnorm=17.994, clip=100, loss_scale=16, train_wall=19, gb_free=10.6, wall=90513
2023-05-27 00:31:57 - progress_bar.py[line:272] - INFO: epoch 028:   1478 / 1732 loss=2.143, loss_v1=0, loss_v2=0, nll_loss=0.915, ntokens=1019.5, nsentences=32, sample_size=1019.5, sample_size_v1=0, sample_size_v2=0, ppl=1.89, wps=543, ups=0.53, wpb=1019.5, bsz=32, num_updates=48160, lr=2.33401e-06, gnorm=20.402, clip=100, loss_scale=16, train_wall=19, gb_free=11.4, wall=90532
2023-05-27 00:32:16 - progress_bar.py[line:272] - INFO: epoch 028:   1488 / 1732 loss=2.134, loss_v1=0, loss_v2=0, nll_loss=0.905, ntokens=1151.5, nsentences=32, sample_size=1151.5, sample_size_v1=0, sample_size_v2=0, ppl=1.87, wps=608.6, ups=0.53, wpb=1151.5, bsz=32, num_updates=48170, lr=2.32787e-06, gnorm=19.029, clip=100, loss_scale=16, train_wall=19, gb_free=10.7, wall=90551
2023-05-27 00:32:35 - progress_bar.py[line:272] - INFO: epoch 028:   1498 / 1732 loss=2.121, loss_v1=0, loss_v2=0, nll_loss=0.89, ntokens=1078, nsentences=32, sample_size=1078, sample_size_v1=0, sample_size_v2=0, ppl=1.85, wps=572.3, ups=0.53, wpb=1078, bsz=32, num_updates=48180, lr=2.32172e-06, gnorm=17.654, clip=100, loss_scale=16, train_wall=19, gb_free=11.4, wall=90570
2023-05-27 00:32:54 - progress_bar.py[line:272] - INFO: epoch 028:   1508 / 1732 loss=2.089, loss_v1=0, loss_v2=0, nll_loss=0.856, ntokens=1107.9, nsentences=32, sample_size=1107.9, sample_size_v1=0, sample_size_v2=0, ppl=1.81, wps=588, ups=0.53, wpb=1107.9, bsz=32, num_updates=48190, lr=2.31558e-06, gnorm=19.2, clip=100, loss_scale=16, train_wall=19, gb_free=11.3, wall=90589
2023-05-27 00:33:13 - progress_bar.py[line:272] - INFO: epoch 028:   1518 / 1732 loss=2.153, loss_v1=0, loss_v2=0, nll_loss=0.927, ntokens=1079, nsentences=32, sample_size=1079, sample_size_v1=0, sample_size_v2=0, ppl=1.9, wps=573.3, ups=0.53, wpb=1079, bsz=32, num_updates=48200, lr=2.30944e-06, gnorm=18.534, clip=100, loss_scale=16, train_wall=19, gb_free=11.1, wall=90608
2023-05-27 00:33:32 - progress_bar.py[line:272] - INFO: epoch 028:   1528 / 1732 loss=2.164, loss_v1=0, loss_v2=0, nll_loss=0.939, ntokens=1041.5, nsentences=32, sample_size=1041.5, sample_size_v1=0, sample_size_v2=0, ppl=1.92, wps=554.5, ups=0.53, wpb=1041.5, bsz=32, num_updates=48210, lr=2.3033e-06, gnorm=19.539, clip=100, loss_scale=16, train_wall=19, gb_free=11.6, wall=90626
2023-05-27 00:33:51 - progress_bar.py[line:272] - INFO: epoch 028:   1538 / 1732 loss=2.126, loss_v1=0, loss_v2=0, nll_loss=0.897, ntokens=1094, nsentences=32, sample_size=1094, sample_size_v1=0, sample_size_v2=0, ppl=1.86, wps=576.6, ups=0.53, wpb=1094, bsz=32, num_updates=48220, lr=2.29716e-06, gnorm=17.782, clip=100, loss_scale=16, train_wall=19, gb_free=11, wall=90645
2023-05-27 00:34:10 - progress_bar.py[line:272] - INFO: epoch 028:   1548 / 1732 loss=2.103, loss_v1=0, loss_v2=0, nll_loss=0.87, ntokens=1084.2, nsentences=32, sample_size=1084.2, sample_size_v1=0, sample_size_v2=0, ppl=1.83, wps=575.7, ups=0.53, wpb=1084.2, bsz=32, num_updates=48230, lr=2.29101e-06, gnorm=18.635, clip=100, loss_scale=32, train_wall=19, gb_free=11.4, wall=90664
2023-05-27 00:34:28 - progress_bar.py[line:272] - INFO: epoch 028:   1558 / 1732 loss=2.093, loss_v1=0, loss_v2=0, nll_loss=0.86, ntokens=1077.4, nsentences=32, sample_size=1077.4, sample_size_v1=0, sample_size_v2=0, ppl=1.82, wps=572.1, ups=0.53, wpb=1077.4, bsz=32, num_updates=48240, lr=2.28487e-06, gnorm=17.184, clip=100, loss_scale=32, train_wall=19, gb_free=10.8, wall=90683
2023-05-27 00:34:47 - progress_bar.py[line:272] - INFO: epoch 028:   1568 / 1732 loss=2.155, loss_v1=0, loss_v2=0, nll_loss=0.929, ntokens=1072.3, nsentences=32, sample_size=1072.3, sample_size_v1=0, sample_size_v2=0, ppl=1.9, wps=568.8, ups=0.53, wpb=1072.3, bsz=32, num_updates=48250, lr=2.27873e-06, gnorm=18.918, clip=100, loss_scale=32, train_wall=19, gb_free=10.5, wall=90702
2023-05-27 00:35:06 - progress_bar.py[line:272] - INFO: epoch 028:   1578 / 1732 loss=2.135, loss_v1=0, loss_v2=0, nll_loss=0.906, ntokens=1004.7, nsentences=32, sample_size=1004.7, sample_size_v1=0, sample_size_v2=0, ppl=1.87, wps=534.6, ups=0.53, wpb=1004.7, bsz=32, num_updates=48260, lr=2.27259e-06, gnorm=19.344, clip=100, loss_scale=32, train_wall=19, gb_free=11.2, wall=90721
2023-05-27 00:35:25 - progress_bar.py[line:272] - INFO: epoch 028:   1588 / 1732 loss=2.119, loss_v1=0, loss_v2=0, nll_loss=0.889, ntokens=1078.3, nsentences=32, sample_size=1078.3, sample_size_v1=0, sample_size_v2=0, ppl=1.85, wps=569, ups=0.53, wpb=1078.3, bsz=32, num_updates=48270, lr=2.26645e-06, gnorm=18.739, clip=100, loss_scale=32, train_wall=19, gb_free=11.4, wall=90740
2023-05-27 00:35:44 - progress_bar.py[line:272] - INFO: epoch 028:   1598 / 1732 loss=2.107, loss_v1=0, loss_v2=0, nll_loss=0.875, ntokens=1079.8, nsentences=32, sample_size=1079.8, sample_size_v1=0, sample_size_v2=0, ppl=1.83, wps=573.7, ups=0.53, wpb=1079.8, bsz=32, num_updates=48280, lr=2.2603e-06, gnorm=19.063, clip=100, loss_scale=32, train_wall=19, gb_free=11.5, wall=90758
2023-05-27 00:36:03 - progress_bar.py[line:272] - INFO: epoch 028:   1608 / 1732 loss=2.11, loss_v1=0, loss_v2=0, nll_loss=0.878, ntokens=1140.6, nsentences=32, sample_size=1140.6, sample_size_v1=0, sample_size_v2=0, ppl=1.84, wps=602.1, ups=0.53, wpb=1140.6, bsz=32, num_updates=48290, lr=2.25416e-06, gnorm=17.943, clip=100, loss_scale=32, train_wall=19, gb_free=11, wall=90777
2023-05-27 00:36:22 - progress_bar.py[line:272] - INFO: epoch 028:   1618 / 1732 loss=2.095, loss_v1=0, loss_v2=0, nll_loss=0.862, ntokens=1124.7, nsentences=32, sample_size=1124.7, sample_size_v1=0, sample_size_v2=0, ppl=1.82, wps=593, ups=0.53, wpb=1124.7, bsz=32, num_updates=48300, lr=2.24802e-06, gnorm=17.865, clip=100, loss_scale=32, train_wall=19, gb_free=11, wall=90796
2023-05-27 00:36:41 - progress_bar.py[line:272] - INFO: epoch 028:   1628 / 1732 loss=2.125, loss_v1=0, loss_v2=0, nll_loss=0.896, ntokens=1158.7, nsentences=32, sample_size=1158.7, sample_size_v1=0, sample_size_v2=0, ppl=1.86, wps=609.5, ups=0.53, wpb=1158.7, bsz=32, num_updates=48310, lr=2.24188e-06, gnorm=18.932, clip=100, loss_scale=32, train_wall=19, gb_free=10.6, wall=90815
2023-05-27 00:36:59 - progress_bar.py[line:272] - INFO: epoch 028:   1638 / 1732 loss=2.103, loss_v1=0, loss_v2=0, nll_loss=0.871, ntokens=1131.3, nsentences=32, sample_size=1131.3, sample_size_v1=0, sample_size_v2=0, ppl=1.83, wps=601.8, ups=0.53, wpb=1131.3, bsz=32, num_updates=48320, lr=2.23573e-06, gnorm=19.022, clip=100, loss_scale=32, train_wall=19, gb_free=11, wall=90834
2023-05-27 00:37:19 - progress_bar.py[line:272] - INFO: epoch 028:   1648 / 1732 loss=2.111, loss_v1=0, loss_v2=0, nll_loss=0.879, ntokens=1231.9, nsentences=32, sample_size=1231.9, sample_size_v1=0, sample_size_v2=0, ppl=1.84, wps=645.5, ups=0.52, wpb=1231.9, bsz=32, num_updates=48330, lr=2.22959e-06, gnorm=17.639, clip=100, loss_scale=32, train_wall=19, gb_free=11.6, wall=90853
2023-05-27 00:37:37 - progress_bar.py[line:272] - INFO: epoch 028:   1658 / 1732 loss=2.144, loss_v1=0, loss_v2=0, nll_loss=0.916, ntokens=971, nsentences=32, sample_size=971, sample_size_v1=0, sample_size_v2=0, ppl=1.89, wps=517.1, ups=0.53, wpb=971, bsz=32, num_updates=48340, lr=2.22345e-06, gnorm=20.528, clip=100, loss_scale=32, train_wall=19, gb_free=11.1, wall=90872
2023-05-27 00:37:56 - progress_bar.py[line:272] - INFO: epoch 028:   1668 / 1732 loss=2.122, loss_v1=0, loss_v2=0, nll_loss=0.892, ntokens=1011.3, nsentences=32, sample_size=1011.3, sample_size_v1=0, sample_size_v2=0, ppl=1.86, wps=538.5, ups=0.53, wpb=1011.3, bsz=32, num_updates=48350, lr=2.21731e-06, gnorm=19.298, clip=100, loss_scale=32, train_wall=19, gb_free=11.6, wall=90891
2023-05-27 00:38:15 - progress_bar.py[line:272] - INFO: epoch 028:   1678 / 1732 loss=2.076, loss_v1=0, loss_v2=0, nll_loss=0.84, ntokens=1161.5, nsentences=32, sample_size=1161.5, sample_size_v1=0, sample_size_v2=0, ppl=1.79, wps=611, ups=0.53, wpb=1161.5, bsz=32, num_updates=48360, lr=2.21117e-06, gnorm=16.36, clip=100, loss_scale=32, train_wall=19, gb_free=11.1, wall=90910
2023-05-27 00:38:34 - progress_bar.py[line:272] - INFO: epoch 028:   1688 / 1732 loss=2.122, loss_v1=0, loss_v2=0, nll_loss=0.891, ntokens=1174.7, nsentences=32, sample_size=1174.7, sample_size_v1=0, sample_size_v2=0, ppl=1.86, wps=617.8, ups=0.53, wpb=1174.7, bsz=32, num_updates=48370, lr=2.20502e-06, gnorm=17.576, clip=100, loss_scale=32, train_wall=19, gb_free=10, wall=90929
2023-05-27 00:38:53 - progress_bar.py[line:272] - INFO: epoch 028:   1698 / 1732 loss=2.101, loss_v1=0, loss_v2=0, nll_loss=0.868, ntokens=1304.9, nsentences=32, sample_size=1304.9, sample_size_v1=0, sample_size_v2=0, ppl=1.83, wps=677.6, ups=0.52, wpb=1304.9, bsz=32, num_updates=48380, lr=2.19888e-06, gnorm=16.516, clip=100, loss_scale=32, train_wall=19, gb_free=11.2, wall=90948
2023-05-27 00:39:12 - progress_bar.py[line:272] - INFO: epoch 028:   1708 / 1732 loss=2.128, loss_v1=0, loss_v2=0, nll_loss=0.898, ntokens=1174.9, nsentences=32, sample_size=1174.9, sample_size_v1=0, sample_size_v2=0, ppl=1.86, wps=618.8, ups=0.53, wpb=1174.9, bsz=32, num_updates=48390, lr=2.19274e-06, gnorm=18.718, clip=100, loss_scale=32, train_wall=19, gb_free=10.8, wall=90967
2023-05-27 00:39:31 - progress_bar.py[line:272] - INFO: epoch 028:   1718 / 1732 loss=2.095, loss_v1=0, loss_v2=0, nll_loss=0.861, ntokens=1181.2, nsentences=32, sample_size=1181.2, sample_size_v1=0, sample_size_v2=0, ppl=1.82, wps=620.1, ups=0.53, wpb=1181.2, bsz=32, num_updates=48400, lr=2.1866e-06, gnorm=16.652, clip=100, loss_scale=32, train_wall=19, gb_free=11, wall=90986
2023-05-27 00:39:50 - progress_bar.py[line:272] - INFO: epoch 028:   1728 / 1732 loss=2.133, loss_v1=0, loss_v2=0, nll_loss=0.905, ntokens=1093.2, nsentences=32, sample_size=1093.2, sample_size_v1=0, sample_size_v2=0, ppl=1.87, wps=577.4, ups=0.53, wpb=1093.2, bsz=32, num_updates=48410, lr=2.18046e-06, gnorm=19.242, clip=100, loss_scale=32, train_wall=19, gb_free=11, wall=91005
2023-05-27 00:39:57 - checkpoint_utils.py[line:64] - INFO: Preparing to save checkpoint for epoch 28 @ 48414 updates
2023-05-27 00:39:57 - trainer.py[line:431] - INFO: Saving checkpoint to ../../checkpoints/OFA/sgcls_checkpoints/_30_3e-5_512_base_nosrcbbox/checkpoint28.pt
2023-05-27 00:40:00 - trainer.py[line:441] - INFO: Finished saving checkpoint to ../../checkpoints/OFA/sgcls_checkpoints/_30_3e-5_512_base_nosrcbbox/checkpoint28.pt
2023-05-27 00:40:04 - checkpoint_utils.py[line:133] - INFO: Saved checkpoint ../../checkpoints/OFA/sgcls_checkpoints/_30_3e-5_512_base_nosrcbbox/checkpoint28.pt (epoch 28 @ 48414 updates, score None) (writing took 7.51382901519537 seconds)
2023-05-27 00:40:04 - train.py[line:332] - INFO: end of epoch 28 (average epoch stats below)
2023-05-27 00:40:04 - progress_bar.py[line:282] - INFO: epoch 028 | loss 2.121 | loss_v1 0 | loss_v2 0 | nll_loss 0.89 | ntokens 1051.46 | nsentences 31.986 | sample_size 1051.46 | sample_size_v1 0 | sample_size_v2 0 | ppl 1.85 | wps 557.7 | ups 0.53 | wpb 1051.5 | bsz 32 | num_updates 48414 | lr 2.178e-06 | gnorm 19.498 | clip 100 | loss_scale 32 | train_wall 3246 | gb_free 11.7 | wall 91019
2023-05-27 00:40:04 - trainer.py[line:639] - INFO: loading train data for epoch 29
local datafile ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 0 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 0 finished initializing row_count and line_idx-to-offset mapping
file ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 0 row count 55400 total row count 55400
slice_id 0 seek offset 0
2023-05-27 00:40:06 - trainer.py[line:703] - INFO: begin training epoch 29
2023-05-27 00:40:06 - train.py[line:305] - INFO: Start iterating over samples
2023-05-27 00:40:18 - progress_bar.py[line:272] - INFO: epoch 029:      6 / 1732 loss=2.112, loss_v1=0, loss_v2=0, nll_loss=0.88, ntokens=1082.4, nsentences=29.6, sample_size=1082.4, sample_size_v1=0, sample_size_v2=0, ppl=1.84, wps=393, ups=0.36, wpb=1082.4, bsz=29.6, num_updates=48420, lr=2.17431e-06, gnorm=18.066, clip=100, loss_scale=32, train_wall=18, gb_free=11.2, wall=91033
2023-05-27 00:40:26 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2023-05-27 00:40:39 - progress_bar.py[line:272] - INFO: epoch 029:     17 / 1732 loss=2.077, loss_v1=0, loss_v2=0, nll_loss=0.841, ntokens=1116, nsentences=32, sample_size=1116, sample_size_v1=0, sample_size_v2=0, ppl=1.79, wps=538.8, ups=0.48, wpb=1116, bsz=32, num_updates=48430, lr=2.16817e-06, gnorm=20.866, clip=100, loss_scale=16, train_wall=21, gb_free=11, wall=91053
2023-05-27 00:40:58 - progress_bar.py[line:272] - INFO: epoch 029:     27 / 1732 loss=2.097, loss_v1=0, loss_v2=0, nll_loss=0.864, ntokens=954.5, nsentences=32, sample_size=954.5, sample_size_v1=0, sample_size_v2=0, ppl=1.82, wps=506.4, ups=0.53, wpb=954.5, bsz=32, num_updates=48440, lr=2.16203e-06, gnorm=24.181, clip=100, loss_scale=16, train_wall=19, gb_free=10.7, wall=91072
2023-05-27 00:41:17 - progress_bar.py[line:272] - INFO: epoch 029:     37 / 1732 loss=1.98, loss_v1=0, loss_v2=0, nll_loss=0.733, ntokens=1179.3, nsentences=32, sample_size=1179.3, sample_size_v1=0, sample_size_v2=0, ppl=1.66, wps=619.8, ups=0.53, wpb=1179.3, bsz=32, num_updates=48450, lr=2.15589e-06, gnorm=19.373, clip=100, loss_scale=16, train_wall=19, gb_free=10.9, wall=91091
2023-05-27 00:41:35 - progress_bar.py[line:272] - INFO: epoch 029:     47 / 1732 loss=1.993, loss_v1=0, loss_v2=0, nll_loss=0.747, ntokens=1055.1, nsentences=32, sample_size=1055.1, sample_size_v1=0, sample_size_v2=0, ppl=1.68, wps=560, ups=0.53, wpb=1055.1, bsz=32, num_updates=48460, lr=2.14975e-06, gnorm=19.459, clip=100, loss_scale=16, train_wall=19, gb_free=10.8, wall=91110
2023-05-27 00:41:54 - progress_bar.py[line:272] - INFO: epoch 029:     57 / 1732 loss=1.925, loss_v1=0, loss_v2=0, nll_loss=0.67, ntokens=1048.7, nsentences=32, sample_size=1048.7, sample_size_v1=0, sample_size_v2=0, ppl=1.59, wps=557.7, ups=0.53, wpb=1048.7, bsz=32, num_updates=48470, lr=2.1436e-06, gnorm=20.789, clip=100, loss_scale=16, train_wall=19, gb_free=11.2, wall=91129
2023-05-27 00:42:14 - progress_bar.py[line:272] - INFO: epoch 029:     67 / 1732 loss=1.852, loss_v1=0, loss_v2=0, nll_loss=0.587, ntokens=1356.1, nsentences=32, sample_size=1356.1, sample_size_v1=0, sample_size_v2=0, ppl=1.5, wps=701.5, ups=0.52, wpb=1356.1, bsz=32, num_updates=48480, lr=2.13746e-06, gnorm=14.66, clip=100, loss_scale=16, train_wall=19, gb_free=10.3, wall=91148
2023-05-27 00:42:33 - progress_bar.py[line:272] - INFO: epoch 029:     77 / 1732 loss=1.923, loss_v1=0, loss_v2=0, nll_loss=0.668, ntokens=1273.9, nsentences=32, sample_size=1273.9, sample_size_v1=0, sample_size_v2=0, ppl=1.59, wps=656.7, ups=0.52, wpb=1273.9, bsz=32, num_updates=48490, lr=2.13132e-06, gnorm=14.803, clip=100, loss_scale=16, train_wall=19, gb_free=11.1, wall=91168
2023-05-27 00:42:52 - progress_bar.py[line:272] - INFO: epoch 029:     87 / 1732 loss=1.983, loss_v1=0, loss_v2=0, nll_loss=0.737, ntokens=1141.2, nsentences=32, sample_size=1141.2, sample_size_v1=0, sample_size_v2=0, ppl=1.67, wps=594, ups=0.52, wpb=1141.2, bsz=32, num_updates=48500, lr=2.12518e-06, gnorm=16.939, clip=100, loss_scale=16, train_wall=19, gb_free=10.6, wall=91187
2023-05-27 00:43:11 - progress_bar.py[line:272] - INFO: epoch 029:     97 / 1732 loss=1.963, loss_v1=0, loss_v2=0, nll_loss=0.713, ntokens=1080.1, nsentences=32, sample_size=1080.1, sample_size_v1=0, sample_size_v2=0, ppl=1.64, wps=570.2, ups=0.53, wpb=1080.1, bsz=32, num_updates=48510, lr=2.11903e-06, gnorm=18.598, clip=100, loss_scale=16, train_wall=19, gb_free=10.1, wall=91206
2023-05-27 00:43:30 - progress_bar.py[line:272] - INFO: epoch 029:    107 / 1732 loss=2.062, loss_v1=0, loss_v2=0, nll_loss=0.824, ntokens=981.4, nsentences=32, sample_size=981.4, sample_size_v1=0, sample_size_v2=0, ppl=1.77, wps=523.1, ups=0.53, wpb=981.4, bsz=32, num_updates=48520, lr=2.11289e-06, gnorm=20.127, clip=100, loss_scale=16, train_wall=19, gb_free=11, wall=91225
2023-05-27 00:43:49 - progress_bar.py[line:272] - INFO: epoch 029:    117 / 1732 loss=2.153, loss_v1=0, loss_v2=0, nll_loss=0.927, ntokens=1060.7, nsentences=32, sample_size=1060.7, sample_size_v1=0, sample_size_v2=0, ppl=1.9, wps=558.7, ups=0.53, wpb=1060.7, bsz=32, num_updates=48530, lr=2.10675e-06, gnorm=21.54, clip=100, loss_scale=16, train_wall=19, gb_free=10.6, wall=91244
2023-05-27 00:44:08 - progress_bar.py[line:272] - INFO: epoch 029:    127 / 1732 loss=2.119, loss_v1=0, loss_v2=0, nll_loss=0.889, ntokens=1185.5, nsentences=32, sample_size=1185.5, sample_size_v1=0, sample_size_v2=0, ppl=1.85, wps=615.9, ups=0.52, wpb=1185.5, bsz=32, num_updates=48540, lr=2.10061e-06, gnorm=20.347, clip=100, loss_scale=16, train_wall=19, gb_free=11.1, wall=91263
2023-05-27 00:44:27 - progress_bar.py[line:272] - INFO: epoch 029:    137 / 1732 loss=2.089, loss_v1=0, loss_v2=0, nll_loss=0.856, ntokens=1222.2, nsentences=32, sample_size=1222.2, sample_size_v1=0, sample_size_v2=0, ppl=1.81, wps=639.7, ups=0.52, wpb=1222.2, bsz=32, num_updates=48550, lr=2.09447e-06, gnorm=19.167, clip=100, loss_scale=16, train_wall=19, gb_free=11, wall=91282
2023-05-27 00:44:47 - progress_bar.py[line:272] - INFO: epoch 029:    147 / 1732 loss=2.044, loss_v1=0, loss_v2=0, nll_loss=0.805, ntokens=1207.1, nsentences=32, sample_size=1207.1, sample_size_v1=0, sample_size_v2=0, ppl=1.75, wps=624.5, ups=0.52, wpb=1207.1, bsz=32, num_updates=48560, lr=2.08832e-06, gnorm=17.812, clip=100, loss_scale=16, train_wall=19, gb_free=10.9, wall=91301
2023-05-27 00:45:06 - progress_bar.py[line:272] - INFO: epoch 029:    157 / 1732 loss=2.093, loss_v1=0, loss_v2=0, nll_loss=0.861, ntokens=1172.8, nsentences=32, sample_size=1172.8, sample_size_v1=0, sample_size_v2=0, ppl=1.82, wps=607.6, ups=0.52, wpb=1172.8, bsz=32, num_updates=48570, lr=2.08218e-06, gnorm=18.714, clip=100, loss_scale=16, train_wall=19, gb_free=11.1, wall=91321
2023-05-27 00:45:25 - progress_bar.py[line:272] - INFO: epoch 029:    167 / 1732 loss=2.073, loss_v1=0, loss_v2=0, nll_loss=0.838, ntokens=1009.5, nsentences=32, sample_size=1009.5, sample_size_v1=0, sample_size_v2=0, ppl=1.79, wps=533.2, ups=0.53, wpb=1009.5, bsz=32, num_updates=48580, lr=2.07604e-06, gnorm=23.275, clip=100, loss_scale=16, train_wall=19, gb_free=10.3, wall=91339
2023-05-27 00:45:44 - progress_bar.py[line:272] - INFO: epoch 029:    177 / 1732 loss=2.083, loss_v1=0, loss_v2=0, nll_loss=0.848, ntokens=994.5, nsentences=32, sample_size=994.5, sample_size_v1=0, sample_size_v2=0, ppl=1.8, wps=527.1, ups=0.53, wpb=994.5, bsz=32, num_updates=48590, lr=2.0699e-06, gnorm=23.23, clip=100, loss_scale=16, train_wall=19, gb_free=10.8, wall=91358
2023-05-27 00:46:03 - progress_bar.py[line:272] - INFO: epoch 029:    187 / 1732 loss=2.033, loss_v1=0, loss_v2=0, nll_loss=0.793, ntokens=1141.8, nsentences=32, sample_size=1141.8, sample_size_v1=0, sample_size_v2=0, ppl=1.73, wps=596.6, ups=0.52, wpb=1141.8, bsz=32, num_updates=48600, lr=2.06376e-06, gnorm=18.499, clip=100, loss_scale=16, train_wall=19, gb_free=10.5, wall=91377
2023-05-27 00:46:22 - progress_bar.py[line:272] - INFO: epoch 029:    197 / 1732 loss=2.085, loss_v1=0, loss_v2=0, nll_loss=0.851, ntokens=1173.2, nsentences=32, sample_size=1173.2, sample_size_v1=0, sample_size_v2=0, ppl=1.8, wps=616.6, ups=0.53, wpb=1173.2, bsz=32, num_updates=48610, lr=2.05761e-06, gnorm=18.324, clip=100, loss_scale=16, train_wall=19, gb_free=11.4, wall=91397
2023-05-27 00:46:40 - progress_bar.py[line:272] - INFO: epoch 029:    207 / 1732 loss=2.118, loss_v1=0, loss_v2=0, nll_loss=0.888, ntokens=957.1, nsentences=32, sample_size=957.1, sample_size_v1=0, sample_size_v2=0, ppl=1.85, wps=514.4, ups=0.54, wpb=957.1, bsz=32, num_updates=48620, lr=2.05147e-06, gnorm=21.551, clip=100, loss_scale=16, train_wall=19, gb_free=10.7, wall=91415
2023-05-27 00:46:59 - progress_bar.py[line:272] - INFO: epoch 029:    217 / 1732 loss=2.148, loss_v1=0, loss_v2=0, nll_loss=0.921, ntokens=1157.1, nsentences=32, sample_size=1157.1, sample_size_v1=0, sample_size_v2=0, ppl=1.89, wps=615.4, ups=0.53, wpb=1157.1, bsz=32, num_updates=48630, lr=2.04533e-06, gnorm=17.638, clip=100, loss_scale=16, train_wall=19, gb_free=11.2, wall=91434
2023-05-27 00:47:18 - progress_bar.py[line:272] - INFO: epoch 029:    227 / 1732 loss=2.121, loss_v1=0, loss_v2=0, nll_loss=0.892, ntokens=1106.8, nsentences=32, sample_size=1106.8, sample_size_v1=0, sample_size_v2=0, ppl=1.86, wps=590.1, ups=0.53, wpb=1106.8, bsz=32, num_updates=48640, lr=2.03919e-06, gnorm=16.896, clip=100, loss_scale=16, train_wall=19, gb_free=10.9, wall=91453
2023-05-27 00:47:37 - progress_bar.py[line:272] - INFO: epoch 029:    237 / 1732 loss=2.185, loss_v1=0, loss_v2=0, nll_loss=0.964, ntokens=1060.1, nsentences=32, sample_size=1060.1, sample_size_v1=0, sample_size_v2=0, ppl=1.95, wps=567.1, ups=0.53, wpb=1060.1, bsz=32, num_updates=48650, lr=2.03304e-06, gnorm=18.292, clip=100, loss_scale=16, train_wall=19, gb_free=10.7, wall=91471
2023-05-27 00:47:56 - progress_bar.py[line:272] - INFO: epoch 029:    247 / 1732 loss=2.149, loss_v1=0, loss_v2=0, nll_loss=0.922, ntokens=1188.4, nsentences=32, sample_size=1188.4, sample_size_v1=0, sample_size_v2=0, ppl=1.9, wps=629.4, ups=0.53, wpb=1188.4, bsz=32, num_updates=48660, lr=2.0269e-06, gnorm=18.443, clip=100, loss_scale=16, train_wall=19, gb_free=10.9, wall=91490
2023-05-27 00:48:14 - progress_bar.py[line:272] - INFO: epoch 029:    257 / 1732 loss=2.145, loss_v1=0, loss_v2=0, nll_loss=0.918, ntokens=1118.5, nsentences=32, sample_size=1118.5, sample_size_v1=0, sample_size_v2=0, ppl=1.89, wps=595.1, ups=0.53, wpb=1118.5, bsz=32, num_updates=48670, lr=2.02076e-06, gnorm=18.393, clip=100, loss_scale=16, train_wall=19, gb_free=11.2, wall=91509
2023-05-27 00:48:33 - progress_bar.py[line:272] - INFO: epoch 029:    267 / 1732 loss=2.133, loss_v1=0, loss_v2=0, nll_loss=0.904, ntokens=1162.2, nsentences=32, sample_size=1162.2, sample_size_v1=0, sample_size_v2=0, ppl=1.87, wps=618.3, ups=0.53, wpb=1162.2, bsz=32, num_updates=48680, lr=2.01462e-06, gnorm=15.318, clip=100, loss_scale=16, train_wall=19, gb_free=11.2, wall=91528
2023-05-27 00:48:52 - progress_bar.py[line:272] - INFO: epoch 029:    277 / 1732 loss=2.158, loss_v1=0, loss_v2=0, nll_loss=0.933, ntokens=1137.3, nsentences=32, sample_size=1137.3, sample_size_v1=0, sample_size_v2=0, ppl=1.91, wps=601.8, ups=0.53, wpb=1137.3, bsz=32, num_updates=48690, lr=2.00848e-06, gnorm=17.86, clip=100, loss_scale=16, train_wall=19, gb_free=11.3, wall=91547
2023-05-27 00:49:11 - progress_bar.py[line:272] - INFO: epoch 029:    287 / 1732 loss=2.132, loss_v1=0, loss_v2=0, nll_loss=0.904, ntokens=1149.1, nsentences=32, sample_size=1149.1, sample_size_v1=0, sample_size_v2=0, ppl=1.87, wps=605.4, ups=0.53, wpb=1149.1, bsz=32, num_updates=48700, lr=2.00233e-06, gnorm=16.535, clip=100, loss_scale=16, train_wall=19, gb_free=10.6, wall=91566
2023-05-27 00:49:30 - progress_bar.py[line:272] - INFO: epoch 029:    297 / 1732 loss=2.152, loss_v1=0, loss_v2=0, nll_loss=0.925, ntokens=1120.1, nsentences=32, sample_size=1120.1, sample_size_v1=0, sample_size_v2=0, ppl=1.9, wps=596.9, ups=0.53, wpb=1120.1, bsz=32, num_updates=48710, lr=1.99619e-06, gnorm=16.959, clip=100, loss_scale=16, train_wall=19, gb_free=10.9, wall=91585
2023-05-27 00:49:49 - progress_bar.py[line:272] - INFO: epoch 029:    307 / 1732 loss=2.133, loss_v1=0, loss_v2=0, nll_loss=0.905, ntokens=1063.6, nsentences=32, sample_size=1063.6, sample_size_v1=0, sample_size_v2=0, ppl=1.87, wps=567.7, ups=0.53, wpb=1063.6, bsz=32, num_updates=48720, lr=1.99005e-06, gnorm=19.14, clip=100, loss_scale=16, train_wall=19, gb_free=11.5, wall=91603
2023-05-27 00:50:07 - progress_bar.py[line:272] - INFO: epoch 029:    317 / 1732 loss=2.157, loss_v1=0, loss_v2=0, nll_loss=0.931, ntokens=1045.4, nsentences=32, sample_size=1045.4, sample_size_v1=0, sample_size_v2=0, ppl=1.91, wps=560.8, ups=0.54, wpb=1045.4, bsz=32, num_updates=48730, lr=1.98391e-06, gnorm=19.693, clip=100, loss_scale=16, train_wall=19, gb_free=11.5, wall=91622
2023-05-27 00:50:26 - progress_bar.py[line:272] - INFO: epoch 029:    327 / 1732 loss=2.177, loss_v1=0, loss_v2=0, nll_loss=0.954, ntokens=1029.3, nsentences=32, sample_size=1029.3, sample_size_v1=0, sample_size_v2=0, ppl=1.94, wps=553.2, ups=0.54, wpb=1029.3, bsz=32, num_updates=48740, lr=1.97777e-06, gnorm=19.104, clip=100, loss_scale=16, train_wall=19, gb_free=11.4, wall=91641
2023-05-27 00:50:44 - progress_bar.py[line:272] - INFO: epoch 029:    337 / 1732 loss=2.146, loss_v1=0, loss_v2=0, nll_loss=0.919, ntokens=970.5, nsentences=32, sample_size=970.5, sample_size_v1=0, sample_size_v2=0, ppl=1.89, wps=523.4, ups=0.54, wpb=970.5, bsz=32, num_updates=48750, lr=1.97162e-06, gnorm=19.623, clip=100, loss_scale=16, train_wall=19, gb_free=10.6, wall=91659
2023-05-27 00:51:03 - progress_bar.py[line:272] - INFO: epoch 029:    347 / 1732 loss=2.131, loss_v1=0, loss_v2=0, nll_loss=0.902, ntokens=913.7, nsentences=32, sample_size=913.7, sample_size_v1=0, sample_size_v2=0, ppl=1.87, wps=494.5, ups=0.54, wpb=913.7, bsz=32, num_updates=48760, lr=1.96548e-06, gnorm=20.705, clip=100, loss_scale=16, train_wall=18, gb_free=11.8, wall=91678
2023-05-27 00:51:21 - progress_bar.py[line:272] - INFO: epoch 029:    357 / 1732 loss=2.165, loss_v1=0, loss_v2=0, nll_loss=0.941, ntokens=948.3, nsentences=32, sample_size=948.3, sample_size_v1=0, sample_size_v2=0, ppl=1.92, wps=512.1, ups=0.54, wpb=948.3, bsz=32, num_updates=48770, lr=1.95934e-06, gnorm=20.56, clip=100, loss_scale=16, train_wall=18, gb_free=11.8, wall=91696
2023-05-27 00:51:40 - progress_bar.py[line:272] - INFO: epoch 029:    367 / 1732 loss=2.176, loss_v1=0, loss_v2=0, nll_loss=0.953, ntokens=952.5, nsentences=32, sample_size=952.5, sample_size_v1=0, sample_size_v2=0, ppl=1.94, wps=514.9, ups=0.54, wpb=952.5, bsz=32, num_updates=48780, lr=1.9532e-06, gnorm=20.652, clip=100, loss_scale=16, train_wall=18, gb_free=11.7, wall=91715
2023-05-27 00:51:58 - progress_bar.py[line:272] - INFO: epoch 029:    377 / 1732 loss=2.171, loss_v1=0, loss_v2=0, nll_loss=0.947, ntokens=1056.5, nsentences=32, sample_size=1056.5, sample_size_v1=0, sample_size_v2=0, ppl=1.93, wps=569, ups=0.54, wpb=1056.5, bsz=32, num_updates=48790, lr=1.94705e-06, gnorm=19.336, clip=100, loss_scale=16, train_wall=19, gb_free=11.1, wall=91733
2023-05-27 00:52:17 - progress_bar.py[line:272] - INFO: epoch 029:    387 / 1732 loss=2.177, loss_v1=0, loss_v2=0, nll_loss=0.955, ntokens=1047.4, nsentences=32, sample_size=1047.4, sample_size_v1=0, sample_size_v2=0, ppl=1.94, wps=562.7, ups=0.54, wpb=1047.4, bsz=32, num_updates=48800, lr=1.94091e-06, gnorm=18.426, clip=100, loss_scale=16, train_wall=19, gb_free=11.6, wall=91752
2023-05-27 00:52:36 - progress_bar.py[line:272] - INFO: epoch 029:    397 / 1732 loss=2.153, loss_v1=0, loss_v2=0, nll_loss=0.927, ntokens=958, nsentences=32, sample_size=958, sample_size_v1=0, sample_size_v2=0, ppl=1.9, wps=518.1, ups=0.54, wpb=958, bsz=32, num_updates=48810, lr=1.93477e-06, gnorm=20.32, clip=100, loss_scale=16, train_wall=18, gb_free=11.4, wall=91770
2023-05-27 00:52:54 - progress_bar.py[line:272] - INFO: epoch 029:    407 / 1732 loss=2.141, loss_v1=0, loss_v2=0, nll_loss=0.914, ntokens=1072.2, nsentences=32, sample_size=1072.2, sample_size_v1=0, sample_size_v2=0, ppl=1.88, wps=573.4, ups=0.53, wpb=1072.2, bsz=32, num_updates=48820, lr=1.92863e-06, gnorm=18.295, clip=100, loss_scale=16, train_wall=19, gb_free=11.1, wall=91789
2023-05-27 00:53:13 - progress_bar.py[line:272] - INFO: epoch 029:    417 / 1732 loss=2.123, loss_v1=0, loss_v2=0, nll_loss=0.894, ntokens=1027.3, nsentences=32, sample_size=1027.3, sample_size_v1=0, sample_size_v2=0, ppl=1.86, wps=545.8, ups=0.53, wpb=1027.3, bsz=32, num_updates=48830, lr=1.92249e-06, gnorm=20.095, clip=100, loss_scale=16, train_wall=19, gb_free=11.6, wall=91808
2023-05-27 00:53:32 - progress_bar.py[line:272] - INFO: epoch 029:    427 / 1732 loss=2.127, loss_v1=0, loss_v2=0, nll_loss=0.898, ntokens=993.5, nsentences=32, sample_size=993.5, sample_size_v1=0, sample_size_v2=0, ppl=1.86, wps=534.2, ups=0.54, wpb=993.5, bsz=32, num_updates=48840, lr=1.91634e-06, gnorm=20.113, clip=100, loss_scale=16, train_wall=19, gb_free=11.2, wall=91826
2023-05-27 00:53:50 - progress_bar.py[line:272] - INFO: epoch 029:    437 / 1732 loss=2.146, loss_v1=0, loss_v2=0, nll_loss=0.919, ntokens=1035.6, nsentences=32, sample_size=1035.6, sample_size_v1=0, sample_size_v2=0, ppl=1.89, wps=557.5, ups=0.54, wpb=1035.6, bsz=32, num_updates=48850, lr=1.9102e-06, gnorm=19.873, clip=100, loss_scale=16, train_wall=19, gb_free=12, wall=91845
2023-05-27 00:54:09 - progress_bar.py[line:272] - INFO: epoch 029:    447 / 1732 loss=2.144, loss_v1=0, loss_v2=0, nll_loss=0.916, ntokens=949, nsentences=32, sample_size=949, sample_size_v1=0, sample_size_v2=0, ppl=1.89, wps=511.9, ups=0.54, wpb=949, bsz=32, num_updates=48860, lr=1.90406e-06, gnorm=19.334, clip=100, loss_scale=16, train_wall=19, gb_free=10.9, wall=91864
2023-05-27 00:54:27 - progress_bar.py[line:272] - INFO: epoch 029:    457 / 1732 loss=2.149, loss_v1=0, loss_v2=0, nll_loss=0.922, ntokens=959.4, nsentences=32, sample_size=959.4, sample_size_v1=0, sample_size_v2=0, ppl=1.9, wps=517.5, ups=0.54, wpb=959.4, bsz=32, num_updates=48870, lr=1.89792e-06, gnorm=18.3, clip=100, loss_scale=16, train_wall=19, gb_free=10.6, wall=91882
2023-05-27 00:54:46 - progress_bar.py[line:272] - INFO: epoch 029:    467 / 1732 loss=2.176, loss_v1=0, loss_v2=0, nll_loss=0.953, ntokens=1054.7, nsentences=32, sample_size=1054.7, sample_size_v1=0, sample_size_v2=0, ppl=1.94, wps=562.8, ups=0.53, wpb=1054.7, bsz=32, num_updates=48880, lr=1.89178e-06, gnorm=20.368, clip=100, loss_scale=16, train_wall=19, gb_free=11.3, wall=91901
2023-05-27 00:55:05 - progress_bar.py[line:272] - INFO: epoch 029:    477 / 1732 loss=2.185, loss_v1=0, loss_v2=0, nll_loss=0.963, ntokens=1051.9, nsentences=32, sample_size=1051.9, sample_size_v1=0, sample_size_v2=0, ppl=1.95, wps=562.5, ups=0.53, wpb=1051.9, bsz=32, num_updates=48890, lr=1.88563e-06, gnorm=19.993, clip=100, loss_scale=16, train_wall=19, gb_free=11.6, wall=91919
2023-05-27 00:55:23 - progress_bar.py[line:272] - INFO: epoch 029:    487 / 1732 loss=2.136, loss_v1=0, loss_v2=0, nll_loss=0.909, ntokens=936.6, nsentences=32, sample_size=936.6, sample_size_v1=0, sample_size_v2=0, ppl=1.88, wps=505.8, ups=0.54, wpb=936.6, bsz=32, num_updates=48900, lr=1.87949e-06, gnorm=19.285, clip=100, loss_scale=16, train_wall=18, gb_free=12.1, wall=91938
2023-05-27 00:55:42 - progress_bar.py[line:272] - INFO: epoch 029:    497 / 1732 loss=2.137, loss_v1=0, loss_v2=0, nll_loss=0.909, ntokens=954.7, nsentences=32, sample_size=954.7, sample_size_v1=0, sample_size_v2=0, ppl=1.88, wps=514.5, ups=0.54, wpb=954.7, bsz=32, num_updates=48910, lr=1.87335e-06, gnorm=19.734, clip=100, loss_scale=16, train_wall=19, gb_free=10.9, wall=91957
2023-05-27 00:56:00 - progress_bar.py[line:272] - INFO: epoch 029:    507 / 1732 loss=2.178, loss_v1=0, loss_v2=0, nll_loss=0.955, ntokens=1006.3, nsentences=32, sample_size=1006.3, sample_size_v1=0, sample_size_v2=0, ppl=1.94, wps=545.1, ups=0.54, wpb=1006.3, bsz=32, num_updates=48920, lr=1.86721e-06, gnorm=20.593, clip=100, loss_scale=16, train_wall=18, gb_free=11.3, wall=91975
2023-05-27 00:56:19 - progress_bar.py[line:272] - INFO: epoch 029:    517 / 1732 loss=2.152, loss_v1=0, loss_v2=0, nll_loss=0.926, ntokens=1047.1, nsentences=32, sample_size=1047.1, sample_size_v1=0, sample_size_v2=0, ppl=1.9, wps=564.6, ups=0.54, wpb=1047.1, bsz=32, num_updates=48930, lr=1.86107e-06, gnorm=19.035, clip=100, loss_scale=16, train_wall=19, gb_free=11.6, wall=91994
2023-05-27 00:56:37 - progress_bar.py[line:272] - INFO: epoch 029:    527 / 1732 loss=2.156, loss_v1=0, loss_v2=0, nll_loss=0.93, ntokens=940.9, nsentences=32, sample_size=940.9, sample_size_v1=0, sample_size_v2=0, ppl=1.91, wps=509.5, ups=0.54, wpb=940.9, bsz=32, num_updates=48940, lr=1.85492e-06, gnorm=20.134, clip=100, loss_scale=32, train_wall=18, gb_free=11.6, wall=92012
2023-05-27 00:56:56 - progress_bar.py[line:272] - INFO: epoch 029:    537 / 1732 loss=2.143, loss_v1=0, loss_v2=0, nll_loss=0.915, ntokens=964.7, nsentences=32, sample_size=964.7, sample_size_v1=0, sample_size_v2=0, ppl=1.89, wps=522, ups=0.54, wpb=964.7, bsz=32, num_updates=48950, lr=1.84878e-06, gnorm=20.304, clip=100, loss_scale=32, train_wall=18, gb_free=11.9, wall=92031
2023-05-27 00:57:14 - progress_bar.py[line:272] - INFO: epoch 029:    547 / 1732 loss=2.172, loss_v1=0, loss_v2=0, nll_loss=0.948, ntokens=1033.6, nsentences=32, sample_size=1033.6, sample_size_v1=0, sample_size_v2=0, ppl=1.93, wps=557.2, ups=0.54, wpb=1033.6, bsz=32, num_updates=48960, lr=1.84264e-06, gnorm=19.042, clip=100, loss_scale=32, train_wall=19, gb_free=11.7, wall=92049
2023-05-27 00:57:33 - progress_bar.py[line:272] - INFO: epoch 029:    557 / 1732 loss=2.185, loss_v1=0, loss_v2=0, nll_loss=0.963, ntokens=1010.2, nsentences=32, sample_size=1010.2, sample_size_v1=0, sample_size_v2=0, ppl=1.95, wps=544.8, ups=0.54, wpb=1010.2, bsz=32, num_updates=48970, lr=1.8365e-06, gnorm=19.695, clip=100, loss_scale=32, train_wall=19, gb_free=11.8, wall=92068
2023-05-27 00:57:52 - progress_bar.py[line:272] - INFO: epoch 029:    567 / 1732 loss=2.19, loss_v1=0, loss_v2=0, nll_loss=0.968, ntokens=1004.9, nsentences=32, sample_size=1004.9, sample_size_v1=0, sample_size_v2=0, ppl=1.96, wps=540, ups=0.54, wpb=1004.9, bsz=32, num_updates=48980, lr=1.83035e-06, gnorm=21.098, clip=100, loss_scale=32, train_wall=19, gb_free=11.7, wall=92086
2023-05-27 00:58:10 - progress_bar.py[line:272] - INFO: epoch 029:    577 / 1732 loss=2.165, loss_v1=0, loss_v2=0, nll_loss=0.94, ntokens=1011.7, nsentences=32, sample_size=1011.7, sample_size_v1=0, sample_size_v2=0, ppl=1.92, wps=540.1, ups=0.53, wpb=1011.7, bsz=32, num_updates=48990, lr=1.82421e-06, gnorm=20.804, clip=100, loss_scale=32, train_wall=19, gb_free=11.6, wall=92105
2023-05-27 00:58:29 - progress_bar.py[line:272] - INFO: epoch 029:    587 / 1732 loss=2.175, loss_v1=0, loss_v2=0, nll_loss=0.951, ntokens=962.2, nsentences=32, sample_size=962.2, sample_size_v1=0, sample_size_v2=0, ppl=1.93, wps=515.6, ups=0.54, wpb=962.2, bsz=32, num_updates=49000, lr=1.81807e-06, gnorm=20.761, clip=100, loss_scale=32, train_wall=19, gb_free=12, wall=92124
2023-05-27 00:58:48 - progress_bar.py[line:272] - INFO: epoch 029:    597 / 1732 loss=2.112, loss_v1=0, loss_v2=0, nll_loss=0.88, ntokens=975.4, nsentences=32, sample_size=975.4, sample_size_v1=0, sample_size_v2=0, ppl=1.84, wps=523.4, ups=0.54, wpb=975.4, bsz=32, num_updates=49010, lr=1.81193e-06, gnorm=19.257, clip=100, loss_scale=32, train_wall=19, gb_free=11.7, wall=92142
2023-05-27 00:59:06 - progress_bar.py[line:272] - INFO: epoch 029:    607 / 1732 loss=2.157, loss_v1=0, loss_v2=0, nll_loss=0.931, ntokens=882.8, nsentences=32, sample_size=882.8, sample_size_v1=0, sample_size_v2=0, ppl=1.91, wps=478.4, ups=0.54, wpb=882.8, bsz=32, num_updates=49020, lr=1.80579e-06, gnorm=21.159, clip=100, loss_scale=32, train_wall=18, gb_free=11.3, wall=92161
2023-05-27 00:59:25 - progress_bar.py[line:272] - INFO: epoch 029:    617 / 1732 loss=2.164, loss_v1=0, loss_v2=0, nll_loss=0.939, ntokens=866.1, nsentences=32, sample_size=866.1, sample_size_v1=0, sample_size_v2=0, ppl=1.92, wps=470.2, ups=0.54, wpb=866.1, bsz=32, num_updates=49030, lr=1.79964e-06, gnorm=19.861, clip=100, loss_scale=32, train_wall=18, gb_free=11.5, wall=92179
2023-05-27 00:59:43 - progress_bar.py[line:272] - INFO: epoch 029:    627 / 1732 loss=2.15, loss_v1=0, loss_v2=0, nll_loss=0.923, ntokens=930.6, nsentences=32, sample_size=930.6, sample_size_v1=0, sample_size_v2=0, ppl=1.9, wps=505.9, ups=0.54, wpb=930.6, bsz=32, num_updates=49040, lr=1.7935e-06, gnorm=20.33, clip=100, loss_scale=32, train_wall=18, gb_free=11.9, wall=92198
2023-05-27 01:00:01 - progress_bar.py[line:272] - INFO: epoch 029:    637 / 1732 loss=2.174, loss_v1=0, loss_v2=0, nll_loss=0.95, ntokens=914.3, nsentences=32, sample_size=914.3, sample_size_v1=0, sample_size_v2=0, ppl=1.93, wps=496.9, ups=0.54, wpb=914.3, bsz=32, num_updates=49050, lr=1.78736e-06, gnorm=21.311, clip=100, loss_scale=32, train_wall=18, gb_free=11.6, wall=92216
2023-05-27 01:00:20 - progress_bar.py[line:272] - INFO: epoch 029:    647 / 1732 loss=2.157, loss_v1=0, loss_v2=0, nll_loss=0.931, ntokens=980.8, nsentences=32, sample_size=980.8, sample_size_v1=0, sample_size_v2=0, ppl=1.91, wps=530, ups=0.54, wpb=980.8, bsz=32, num_updates=49060, lr=1.78122e-06, gnorm=21, clip=100, loss_scale=32, train_wall=18, gb_free=11.8, wall=92234
2023-05-27 01:00:38 - progress_bar.py[line:272] - INFO: epoch 029:    657 / 1732 loss=2.153, loss_v1=0, loss_v2=0, nll_loss=0.928, ntokens=894.4, nsentences=32, sample_size=894.4, sample_size_v1=0, sample_size_v2=0, ppl=1.9, wps=487.8, ups=0.55, wpb=894.4, bsz=32, num_updates=49070, lr=1.77508e-06, gnorm=21.378, clip=100, loss_scale=32, train_wall=18, gb_free=11.8, wall=92253
2023-05-27 01:00:57 - progress_bar.py[line:272] - INFO: epoch 029:    667 / 1732 loss=2.144, loss_v1=0, loss_v2=0, nll_loss=0.917, ntokens=903.9, nsentences=32, sample_size=903.9, sample_size_v1=0, sample_size_v2=0, ppl=1.89, wps=492, ups=0.54, wpb=903.9, bsz=32, num_updates=49080, lr=1.76893e-06, gnorm=21.637, clip=100, loss_scale=32, train_wall=18, gb_free=11.5, wall=92271
2023-05-27 01:01:15 - progress_bar.py[line:272] - INFO: epoch 029:    677 / 1732 loss=2.167, loss_v1=0, loss_v2=0, nll_loss=0.942, ntokens=985.3, nsentences=32, sample_size=985.3, sample_size_v1=0, sample_size_v2=0, ppl=1.92, wps=531.6, ups=0.54, wpb=985.3, bsz=32, num_updates=49090, lr=1.76279e-06, gnorm=20.981, clip=100, loss_scale=32, train_wall=19, gb_free=11.8, wall=92290
2023-05-27 01:01:34 - progress_bar.py[line:272] - INFO: epoch 029:    687 / 1732 loss=2.167, loss_v1=0, loss_v2=0, nll_loss=0.942, ntokens=943.2, nsentences=32, sample_size=943.2, sample_size_v1=0, sample_size_v2=0, ppl=1.92, wps=511.1, ups=0.54, wpb=943.2, bsz=32, num_updates=49100, lr=1.75665e-06, gnorm=22.461, clip=100, loss_scale=32, train_wall=18, gb_free=11.9, wall=92308
2023-05-27 01:01:52 - progress_bar.py[line:272] - INFO: epoch 029:    697 / 1732 loss=2.163, loss_v1=0, loss_v2=0, nll_loss=0.937, ntokens=1005.6, nsentences=32, sample_size=1005.6, sample_size_v1=0, sample_size_v2=0, ppl=1.92, wps=536.8, ups=0.53, wpb=1005.6, bsz=32, num_updates=49110, lr=1.75051e-06, gnorm=21.158, clip=100, loss_scale=32, train_wall=19, gb_free=10.9, wall=92327
2023-05-27 01:02:11 - progress_bar.py[line:272] - INFO: epoch 029:    707 / 1732 loss=2.139, loss_v1=0, loss_v2=0, nll_loss=0.911, ntokens=903.4, nsentences=32, sample_size=903.4, sample_size_v1=0, sample_size_v2=0, ppl=1.88, wps=490.9, ups=0.54, wpb=903.4, bsz=32, num_updates=49120, lr=1.74436e-06, gnorm=19.95, clip=100, loss_scale=32, train_wall=18, gb_free=11.6, wall=92345
2023-05-27 01:02:29 - progress_bar.py[line:272] - INFO: epoch 029:    717 / 1732 loss=2.134, loss_v1=0, loss_v2=0, nll_loss=0.905, ntokens=882.7, nsentences=32, sample_size=882.7, sample_size_v1=0, sample_size_v2=0, ppl=1.87, wps=478.2, ups=0.54, wpb=882.7, bsz=32, num_updates=49130, lr=1.73822e-06, gnorm=21.527, clip=100, loss_scale=32, train_wall=18, gb_free=11.6, wall=92364
2023-05-27 01:02:48 - progress_bar.py[line:272] - INFO: epoch 029:    727 / 1732 loss=2.123, loss_v1=0, loss_v2=0, nll_loss=0.893, ntokens=909.8, nsentences=32, sample_size=909.8, sample_size_v1=0, sample_size_v2=0, ppl=1.86, wps=492.8, ups=0.54, wpb=909.8, bsz=32, num_updates=49140, lr=1.73208e-06, gnorm=20.332, clip=100, loss_scale=32, train_wall=18, gb_free=11.9, wall=92382
2023-05-27 01:03:06 - progress_bar.py[line:272] - INFO: epoch 029:    737 / 1732 loss=2.148, loss_v1=0, loss_v2=0, nll_loss=0.92, ntokens=998.8, nsentences=32, sample_size=998.8, sample_size_v1=0, sample_size_v2=0, ppl=1.89, wps=540.5, ups=0.54, wpb=998.8, bsz=32, num_updates=49150, lr=1.72594e-06, gnorm=18.908, clip=100, loss_scale=32, train_wall=18, gb_free=11.5, wall=92401
2023-05-27 01:03:25 - progress_bar.py[line:272] - INFO: epoch 029:    747 / 1732 loss=2.129, loss_v1=0, loss_v2=0, nll_loss=0.899, ntokens=980.5, nsentences=32, sample_size=980.5, sample_size_v1=0, sample_size_v2=0, ppl=1.87, wps=526.9, ups=0.54, wpb=980.5, bsz=32, num_updates=49160, lr=1.7198e-06, gnorm=18.733, clip=100, loss_scale=32, train_wall=19, gb_free=11.3, wall=92419
2023-05-27 01:03:43 - progress_bar.py[line:272] - INFO: epoch 029:    757 / 1732 loss=2.14, loss_v1=0, loss_v2=0, nll_loss=0.912, ntokens=949.2, nsentences=32, sample_size=949.2, sample_size_v1=0, sample_size_v2=0, ppl=1.88, wps=514.2, ups=0.54, wpb=949.2, bsz=32, num_updates=49170, lr=1.71365e-06, gnorm=19.102, clip=100, loss_scale=32, train_wall=18, gb_free=11.6, wall=92438
2023-05-27 01:04:02 - progress_bar.py[line:272] - INFO: epoch 029:    767 / 1732 loss=2.138, loss_v1=0, loss_v2=0, nll_loss=0.91, ntokens=941.7, nsentences=32, sample_size=941.7, sample_size_v1=0, sample_size_v2=0, ppl=1.88, wps=510.6, ups=0.54, wpb=941.7, bsz=32, num_updates=49180, lr=1.70751e-06, gnorm=19.362, clip=100, loss_scale=32, train_wall=18, gb_free=11.9, wall=92456
2023-05-27 01:04:20 - progress_bar.py[line:272] - INFO: epoch 029:    777 / 1732 loss=2.139, loss_v1=0, loss_v2=0, nll_loss=0.911, ntokens=1028.6, nsentences=32, sample_size=1028.6, sample_size_v1=0, sample_size_v2=0, ppl=1.88, wps=554.1, ups=0.54, wpb=1028.6, bsz=32, num_updates=49190, lr=1.70137e-06, gnorm=20.374, clip=100, loss_scale=32, train_wall=19, gb_free=11.8, wall=92475
2023-05-27 01:04:39 - progress_bar.py[line:272] - INFO: epoch 029:    787 / 1732 loss=2.157, loss_v1=0, loss_v2=0, nll_loss=0.932, ntokens=1016.6, nsentences=32, sample_size=1016.6, sample_size_v1=0, sample_size_v2=0, ppl=1.91, wps=550, ups=0.54, wpb=1016.6, bsz=32, num_updates=49200, lr=1.69523e-06, gnorm=21.731, clip=100, loss_scale=32, train_wall=18, gb_free=11.3, wall=92493
2023-05-27 01:04:57 - progress_bar.py[line:272] - INFO: epoch 029:    797 / 1732 loss=2.163, loss_v1=0, loss_v2=0, nll_loss=0.938, ntokens=1038, nsentences=32, sample_size=1038, sample_size_v1=0, sample_size_v2=0, ppl=1.92, wps=559.7, ups=0.54, wpb=1038, bsz=32, num_updates=49210, lr=1.68909e-06, gnorm=19.575, clip=100, loss_scale=32, train_wall=19, gb_free=11.6, wall=92512
2023-05-27 01:05:16 - progress_bar.py[line:272] - INFO: epoch 029:    807 / 1732 loss=2.145, loss_v1=0, loss_v2=0, nll_loss=0.917, ntokens=915, nsentences=32, sample_size=915, sample_size_v1=0, sample_size_v2=0, ppl=1.89, wps=496.2, ups=0.54, wpb=915, bsz=32, num_updates=49220, lr=1.68294e-06, gnorm=19.501, clip=100, loss_scale=32, train_wall=18, gb_free=11.4, wall=92530
2023-05-27 01:05:34 - progress_bar.py[line:272] - INFO: epoch 029:    817 / 1732 loss=2.159, loss_v1=0, loss_v2=0, nll_loss=0.933, ntokens=917.4, nsentences=32, sample_size=917.4, sample_size_v1=0, sample_size_v2=0, ppl=1.91, wps=496, ups=0.54, wpb=917.4, bsz=32, num_updates=49230, lr=1.6768e-06, gnorm=22.19, clip=100, loss_scale=32, train_wall=18, gb_free=11.7, wall=92549
2023-05-27 01:05:53 - progress_bar.py[line:272] - INFO: epoch 029:    827 / 1732 loss=2.138, loss_v1=0, loss_v2=0, nll_loss=0.909, ntokens=930.6, nsentences=32, sample_size=930.6, sample_size_v1=0, sample_size_v2=0, ppl=1.88, wps=502.4, ups=0.54, wpb=930.6, bsz=32, num_updates=49240, lr=1.67066e-06, gnorm=19.747, clip=100, loss_scale=32, train_wall=18, gb_free=11.7, wall=92567
2023-05-27 01:06:11 - progress_bar.py[line:272] - INFO: epoch 029:    837 / 1732 loss=2.155, loss_v1=0, loss_v2=0, nll_loss=0.929, ntokens=894.5, nsentences=32, sample_size=894.5, sample_size_v1=0, sample_size_v2=0, ppl=1.9, wps=487.1, ups=0.54, wpb=894.5, bsz=32, num_updates=49250, lr=1.66452e-06, gnorm=23.001, clip=100, loss_scale=32, train_wall=18, gb_free=11.7, wall=92586
2023-05-27 01:06:30 - progress_bar.py[line:272] - INFO: epoch 029:    847 / 1732 loss=2.136, loss_v1=0, loss_v2=0, nll_loss=0.907, ntokens=1012.6, nsentences=32, sample_size=1012.6, sample_size_v1=0, sample_size_v2=0, ppl=1.88, wps=547.8, ups=0.54, wpb=1012.6, bsz=32, num_updates=49260, lr=1.65837e-06, gnorm=19.145, clip=100, loss_scale=32, train_wall=18, gb_free=10.6, wall=92604
2023-05-27 01:06:48 - progress_bar.py[line:272] - INFO: epoch 029:    857 / 1732 loss=2.141, loss_v1=0, loss_v2=0, nll_loss=0.913, ntokens=920, nsentences=32, sample_size=920, sample_size_v1=0, sample_size_v2=0, ppl=1.88, wps=499.3, ups=0.54, wpb=920, bsz=32, num_updates=49270, lr=1.65223e-06, gnorm=21.217, clip=100, loss_scale=32, train_wall=18, gb_free=11.7, wall=92623
2023-05-27 01:07:06 - progress_bar.py[line:272] - INFO: epoch 029:    867 / 1732 loss=2.149, loss_v1=0, loss_v2=0, nll_loss=0.922, ntokens=979.9, nsentences=32, sample_size=979.9, sample_size_v1=0, sample_size_v2=0, ppl=1.89, wps=529.7, ups=0.54, wpb=979.9, bsz=32, num_updates=49280, lr=1.64609e-06, gnorm=20.127, clip=100, loss_scale=32, train_wall=18, gb_free=11.3, wall=92641
2023-05-27 01:07:25 - progress_bar.py[line:272] - INFO: epoch 029:    877 / 1732 loss=2.091, loss_v1=0, loss_v2=0, nll_loss=0.856, ntokens=994.5, nsentences=32, sample_size=994.5, sample_size_v1=0, sample_size_v2=0, ppl=1.81, wps=535.6, ups=0.54, wpb=994.5, bsz=32, num_updates=49290, lr=1.63995e-06, gnorm=18.365, clip=100, loss_scale=32, train_wall=19, gb_free=11.7, wall=92660
2023-05-27 01:07:44 - progress_bar.py[line:272] - INFO: epoch 029:    887 / 1732 loss=2.1, loss_v1=0, loss_v2=0, nll_loss=0.867, ntokens=982, nsentences=32, sample_size=982, sample_size_v1=0, sample_size_v2=0, ppl=1.82, wps=527.8, ups=0.54, wpb=982, bsz=32, num_updates=49300, lr=1.63381e-06, gnorm=19.778, clip=100, loss_scale=32, train_wall=19, gb_free=11.2, wall=92678
2023-05-27 01:08:02 - progress_bar.py[line:272] - INFO: epoch 029:    897 / 1732 loss=2.093, loss_v1=0, loss_v2=0, nll_loss=0.859, ntokens=1034.6, nsentences=32, sample_size=1034.6, sample_size_v1=0, sample_size_v2=0, ppl=1.81, wps=558, ups=0.54, wpb=1034.6, bsz=32, num_updates=49310, lr=1.62766e-06, gnorm=18.662, clip=100, loss_scale=32, train_wall=19, gb_free=11.5, wall=92697
2023-05-27 01:08:21 - progress_bar.py[line:272] - INFO: epoch 029:    907 / 1732 loss=2.105, loss_v1=0, loss_v2=0, nll_loss=0.873, ntokens=1016.8, nsentences=32, sample_size=1016.8, sample_size_v1=0, sample_size_v2=0, ppl=1.83, wps=547.5, ups=0.54, wpb=1016.8, bsz=32, num_updates=49320, lr=1.62152e-06, gnorm=17.344, clip=100, loss_scale=32, train_wall=19, gb_free=11.6, wall=92715
2023-05-27 01:08:39 - progress_bar.py[line:272] - INFO: epoch 029:    917 / 1732 loss=2.18, loss_v1=0, loss_v2=0, nll_loss=0.958, ntokens=936.4, nsentences=32, sample_size=936.4, sample_size_v1=0, sample_size_v2=0, ppl=1.94, wps=507.2, ups=0.54, wpb=936.4, bsz=32, num_updates=49330, lr=1.61538e-06, gnorm=21.593, clip=100, loss_scale=32, train_wall=18, gb_free=11.8, wall=92734
2023-05-27 01:08:58 - progress_bar.py[line:272] - INFO: epoch 029:    927 / 1732 loss=2.112, loss_v1=0, loss_v2=0, nll_loss=0.881, ntokens=1039.7, nsentences=32, sample_size=1039.7, sample_size_v1=0, sample_size_v2=0, ppl=1.84, wps=556.1, ups=0.53, wpb=1039.7, bsz=32, num_updates=49340, lr=1.60924e-06, gnorm=17.937, clip=100, loss_scale=32, train_wall=19, gb_free=11.5, wall=92753
2023-05-27 01:09:17 - progress_bar.py[line:272] - INFO: epoch 029:    937 / 1732 loss=2.149, loss_v1=0, loss_v2=0, nll_loss=0.922, ntokens=1061.1, nsentences=32, sample_size=1061.1, sample_size_v1=0, sample_size_v2=0, ppl=1.89, wps=564.9, ups=0.53, wpb=1061.1, bsz=32, num_updates=49350, lr=1.6031e-06, gnorm=19.067, clip=100, loss_scale=32, train_wall=19, gb_free=11.5, wall=92771
2023-05-27 01:09:36 - progress_bar.py[line:272] - INFO: epoch 029:    947 / 1732 loss=2.157, loss_v1=0, loss_v2=0, nll_loss=0.932, ntokens=1042.4, nsentences=32, sample_size=1042.4, sample_size_v1=0, sample_size_v2=0, ppl=1.91, wps=553.3, ups=0.53, wpb=1042.4, bsz=32, num_updates=49360, lr=1.59695e-06, gnorm=20.766, clip=100, loss_scale=32, train_wall=19, gb_free=11.2, wall=92790
2023-05-27 01:09:54 - progress_bar.py[line:272] - INFO: epoch 029:    957 / 1732 loss=2.149, loss_v1=0, loss_v2=0, nll_loss=0.922, ntokens=1046.8, nsentences=32, sample_size=1046.8, sample_size_v1=0, sample_size_v2=0, ppl=1.89, wps=558.3, ups=0.53, wpb=1046.8, bsz=32, num_updates=49370, lr=1.59081e-06, gnorm=19.353, clip=100, loss_scale=32, train_wall=19, gb_free=11.1, wall=92809
2023-05-27 01:10:13 - progress_bar.py[line:272] - INFO: epoch 029:    967 / 1732 loss=2.153, loss_v1=0, loss_v2=0, nll_loss=0.927, ntokens=1036.4, nsentences=32, sample_size=1036.4, sample_size_v1=0, sample_size_v2=0, ppl=1.9, wps=553.9, ups=0.53, wpb=1036.4, bsz=32, num_updates=49380, lr=1.58467e-06, gnorm=20.826, clip=100, loss_scale=32, train_wall=19, gb_free=11.3, wall=92828
2023-05-27 01:10:32 - progress_bar.py[line:272] - INFO: epoch 029:    977 / 1732 loss=2.118, loss_v1=0, loss_v2=0, nll_loss=0.887, ntokens=1035.2, nsentences=32, sample_size=1035.2, sample_size_v1=0, sample_size_v2=0, ppl=1.85, wps=547.8, ups=0.53, wpb=1035.2, bsz=32, num_updates=49390, lr=1.57853e-06, gnorm=18.061, clip=100, loss_scale=32, train_wall=19, gb_free=10.4, wall=92847
2023-05-27 01:10:51 - progress_bar.py[line:272] - INFO: epoch 029:    987 / 1732 loss=2.126, loss_v1=0, loss_v2=0, nll_loss=0.897, ntokens=1020.1, nsentences=32, sample_size=1020.1, sample_size_v1=0, sample_size_v2=0, ppl=1.86, wps=540.1, ups=0.53, wpb=1020.1, bsz=32, num_updates=49400, lr=1.57238e-06, gnorm=16.982, clip=100, loss_scale=32, train_wall=19, gb_free=11.3, wall=92865
2023-05-27 01:11:10 - progress_bar.py[line:272] - INFO: epoch 029:    997 / 1732 loss=2.135, loss_v1=0, loss_v2=0, nll_loss=0.907, ntokens=1032.4, nsentences=32, sample_size=1032.4, sample_size_v1=0, sample_size_v2=0, ppl=1.87, wps=551.6, ups=0.53, wpb=1032.4, bsz=32, num_updates=49410, lr=1.56624e-06, gnorm=19.093, clip=100, loss_scale=32, train_wall=19, gb_free=11.7, wall=92884
2023-05-27 01:11:28 - progress_bar.py[line:272] - INFO: epoch 029:   1007 / 1732 loss=2.138, loss_v1=0, loss_v2=0, nll_loss=0.91, ntokens=1018.9, nsentences=32, sample_size=1018.9, sample_size_v1=0, sample_size_v2=0, ppl=1.88, wps=545.2, ups=0.54, wpb=1018.9, bsz=32, num_updates=49420, lr=1.5601e-06, gnorm=19.425, clip=100, loss_scale=32, train_wall=19, gb_free=11.3, wall=92903
2023-05-27 01:11:47 - progress_bar.py[line:272] - INFO: epoch 029:   1017 / 1732 loss=2.117, loss_v1=0, loss_v2=0, nll_loss=0.885, ntokens=1024.8, nsentences=32, sample_size=1024.8, sample_size_v1=0, sample_size_v2=0, ppl=1.85, wps=548.6, ups=0.54, wpb=1024.8, bsz=32, num_updates=49430, lr=1.55396e-06, gnorm=18.81, clip=100, loss_scale=32, train_wall=19, gb_free=10.5, wall=92922
2023-05-27 01:12:06 - progress_bar.py[line:272] - INFO: epoch 029:   1027 / 1732 loss=2.155, loss_v1=0, loss_v2=0, nll_loss=0.929, ntokens=1051.5, nsentences=32, sample_size=1051.5, sample_size_v1=0, sample_size_v2=0, ppl=1.9, wps=558.2, ups=0.53, wpb=1051.5, bsz=32, num_updates=49440, lr=1.54782e-06, gnorm=19.44, clip=100, loss_scale=32, train_wall=19, gb_free=11.3, wall=92940
2023-05-27 01:12:25 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2023-05-27 01:12:26 - progress_bar.py[line:272] - INFO: epoch 029:   1038 / 1732 loss=2.131, loss_v1=0, loss_v2=0, nll_loss=0.902, ntokens=1122.4, nsentences=32, sample_size=1122.4, sample_size_v1=0, sample_size_v2=0, ppl=1.87, wps=541.9, ups=0.48, wpb=1122.4, bsz=32, num_updates=49450, lr=1.54167e-06, gnorm=18.375, clip=100, loss_scale=32, train_wall=21, gb_free=11.5, wall=92961
2023-05-27 01:12:45 - progress_bar.py[line:272] - INFO: epoch 029:   1048 / 1732 loss=2.122, loss_v1=0, loss_v2=0, nll_loss=0.892, ntokens=1025.8, nsentences=32, sample_size=1025.8, sample_size_v1=0, sample_size_v2=0, ppl=1.86, wps=546.3, ups=0.53, wpb=1025.8, bsz=32, num_updates=49460, lr=1.53553e-06, gnorm=18.819, clip=100, loss_scale=32, train_wall=19, gb_free=11.4, wall=92980
2023-05-27 01:13:04 - progress_bar.py[line:272] - INFO: epoch 029:   1058 / 1732 loss=2.137, loss_v1=0, loss_v2=0, nll_loss=0.908, ntokens=1082.8, nsentences=32, sample_size=1082.8, sample_size_v1=0, sample_size_v2=0, ppl=1.88, wps=576.4, ups=0.53, wpb=1082.8, bsz=32, num_updates=49470, lr=1.52939e-06, gnorm=17.708, clip=100, loss_scale=32, train_wall=19, gb_free=11.8, wall=92999
2023-05-27 01:13:23 - progress_bar.py[line:272] - INFO: epoch 029:   1068 / 1732 loss=2.13, loss_v1=0, loss_v2=0, nll_loss=0.899, ntokens=1002.9, nsentences=32, sample_size=1002.9, sample_size_v1=0, sample_size_v2=0, ppl=1.87, wps=537.1, ups=0.54, wpb=1002.9, bsz=32, num_updates=49480, lr=1.52325e-06, gnorm=19.505, clip=100, loss_scale=32, train_wall=19, gb_free=11.7, wall=93017
2023-05-27 01:13:42 - progress_bar.py[line:272] - INFO: epoch 029:   1078 / 1732 loss=2.152, loss_v1=0, loss_v2=0, nll_loss=0.926, ntokens=1000.2, nsentences=32, sample_size=1000.2, sample_size_v1=0, sample_size_v2=0, ppl=1.9, wps=531, ups=0.53, wpb=1000.2, bsz=32, num_updates=49490, lr=1.51711e-06, gnorm=21.171, clip=100, loss_scale=32, train_wall=19, gb_free=11.5, wall=93036
2023-05-27 01:14:00 - progress_bar.py[line:272] - INFO: epoch 029:   1088 / 1732 loss=2.121, loss_v1=0, loss_v2=0, nll_loss=0.89, ntokens=1078.6, nsentences=32, sample_size=1078.6, sample_size_v1=0, sample_size_v2=0, ppl=1.85, wps=570.4, ups=0.53, wpb=1078.6, bsz=32, num_updates=49500, lr=1.51096e-06, gnorm=18.124, clip=100, loss_scale=32, train_wall=19, gb_free=11.4, wall=93055
2023-05-27 01:14:19 - progress_bar.py[line:272] - INFO: epoch 029:   1098 / 1732 loss=2.146, loss_v1=0, loss_v2=0, nll_loss=0.919, ntokens=1045.6, nsentences=32, sample_size=1045.6, sample_size_v1=0, sample_size_v2=0, ppl=1.89, wps=558.1, ups=0.53, wpb=1045.6, bsz=32, num_updates=49510, lr=1.50482e-06, gnorm=19.281, clip=100, loss_scale=32, train_wall=19, gb_free=10.8, wall=93074
2023-05-27 01:14:38 - progress_bar.py[line:272] - INFO: epoch 029:   1108 / 1732 loss=2.13, loss_v1=0, loss_v2=0, nll_loss=0.902, ntokens=1058.8, nsentences=32, sample_size=1058.8, sample_size_v1=0, sample_size_v2=0, ppl=1.87, wps=562.3, ups=0.53, wpb=1058.8, bsz=32, num_updates=49520, lr=1.49868e-06, gnorm=18.141, clip=100, loss_scale=32, train_wall=19, gb_free=11.6, wall=93093
2023-05-27 01:14:57 - progress_bar.py[line:272] - INFO: epoch 029:   1118 / 1732 loss=2.135, loss_v1=0, loss_v2=0, nll_loss=0.907, ntokens=944.7, nsentences=32, sample_size=944.7, sample_size_v1=0, sample_size_v2=0, ppl=1.87, wps=504.3, ups=0.53, wpb=944.7, bsz=32, num_updates=49530, lr=1.49254e-06, gnorm=19.54, clip=100, loss_scale=32, train_wall=19, gb_free=11.2, wall=93111
2023-05-27 01:15:16 - progress_bar.py[line:272] - INFO: epoch 029:   1128 / 1732 loss=2.129, loss_v1=0, loss_v2=0, nll_loss=0.899, ntokens=1025.9, nsentences=32, sample_size=1025.9, sample_size_v1=0, sample_size_v2=0, ppl=1.86, wps=544.6, ups=0.53, wpb=1025.9, bsz=32, num_updates=49540, lr=1.4864e-06, gnorm=20.41, clip=100, loss_scale=32, train_wall=19, gb_free=10.7, wall=93130
2023-05-27 01:15:34 - progress_bar.py[line:272] - INFO: epoch 029:   1138 / 1732 loss=2.123, loss_v1=0, loss_v2=0, nll_loss=0.893, ntokens=989.2, nsentences=32, sample_size=989.2, sample_size_v1=0, sample_size_v2=0, ppl=1.86, wps=528.9, ups=0.53, wpb=989.2, bsz=32, num_updates=49550, lr=1.48025e-06, gnorm=19.407, clip=100, loss_scale=32, train_wall=19, gb_free=11.6, wall=93149
2023-05-27 01:15:53 - progress_bar.py[line:272] - INFO: epoch 029:   1148 / 1732 loss=2.118, loss_v1=0, loss_v2=0, nll_loss=0.887, ntokens=1007.7, nsentences=32, sample_size=1007.7, sample_size_v1=0, sample_size_v2=0, ppl=1.85, wps=538.8, ups=0.53, wpb=1007.7, bsz=32, num_updates=49560, lr=1.47411e-06, gnorm=18.908, clip=100, loss_scale=32, train_wall=19, gb_free=11.5, wall=93168
2023-05-27 01:16:12 - progress_bar.py[line:272] - INFO: epoch 029:   1158 / 1732 loss=2.103, loss_v1=0, loss_v2=0, nll_loss=0.87, ntokens=1016, nsentences=32, sample_size=1016, sample_size_v1=0, sample_size_v2=0, ppl=1.83, wps=541, ups=0.53, wpb=1016, bsz=32, num_updates=49570, lr=1.46797e-06, gnorm=18.286, clip=100, loss_scale=32, train_wall=19, gb_free=10.8, wall=93186
2023-05-27 01:16:31 - progress_bar.py[line:272] - INFO: epoch 029:   1168 / 1732 loss=2.108, loss_v1=0, loss_v2=0, nll_loss=0.876, ntokens=1020.6, nsentences=32, sample_size=1020.6, sample_size_v1=0, sample_size_v2=0, ppl=1.84, wps=544.3, ups=0.53, wpb=1020.6, bsz=32, num_updates=49580, lr=1.46183e-06, gnorm=18.49, clip=100, loss_scale=32, train_wall=19, gb_free=10.9, wall=93205
2023-05-27 01:16:49 - progress_bar.py[line:272] - INFO: epoch 029:   1178 / 1732 loss=2.11, loss_v1=0, loss_v2=0, nll_loss=0.877, ntokens=1067, nsentences=32, sample_size=1067, sample_size_v1=0, sample_size_v2=0, ppl=1.84, wps=568.2, ups=0.53, wpb=1067, bsz=32, num_updates=49590, lr=1.45568e-06, gnorm=18.944, clip=100, loss_scale=32, train_wall=19, gb_free=11.6, wall=93224
2023-05-27 01:17:08 - progress_bar.py[line:272] - INFO: epoch 029:   1188 / 1732 loss=2.113, loss_v1=0, loss_v2=0, nll_loss=0.882, ntokens=963.5, nsentences=32, sample_size=963.5, sample_size_v1=0, sample_size_v2=0, ppl=1.84, wps=515.9, ups=0.54, wpb=963.5, bsz=32, num_updates=49600, lr=1.44954e-06, gnorm=19.065, clip=100, loss_scale=32, train_wall=19, gb_free=11.1, wall=93243
2023-05-27 01:17:27 - progress_bar.py[line:272] - INFO: epoch 029:   1198 / 1732 loss=2.116, loss_v1=0, loss_v2=0, nll_loss=0.885, ntokens=1123.7, nsentences=32, sample_size=1123.7, sample_size_v1=0, sample_size_v2=0, ppl=1.85, wps=595.8, ups=0.53, wpb=1123.7, bsz=32, num_updates=49610, lr=1.4434e-06, gnorm=18.879, clip=100, loss_scale=32, train_wall=19, gb_free=11.2, wall=93262
2023-05-27 01:17:46 - progress_bar.py[line:272] - INFO: epoch 029:   1208 / 1732 loss=2.098, loss_v1=0, loss_v2=0, nll_loss=0.865, ntokens=1088.9, nsentences=32, sample_size=1088.9, sample_size_v1=0, sample_size_v2=0, ppl=1.82, wps=574.3, ups=0.53, wpb=1088.9, bsz=32, num_updates=49620, lr=1.43726e-06, gnorm=17.615, clip=100, loss_scale=32, train_wall=19, gb_free=10.6, wall=93281
2023-05-27 01:18:05 - progress_bar.py[line:272] - INFO: epoch 029:   1218 / 1732 loss=2.139, loss_v1=0, loss_v2=0, nll_loss=0.911, ntokens=1016, nsentences=32, sample_size=1016, sample_size_v1=0, sample_size_v2=0, ppl=1.88, wps=541.7, ups=0.53, wpb=1016, bsz=32, num_updates=49630, lr=1.43112e-06, gnorm=19.199, clip=100, loss_scale=32, train_wall=19, gb_free=11.6, wall=93299
2023-05-27 01:18:23 - progress_bar.py[line:272] - INFO: epoch 029:   1228 / 1732 loss=2.137, loss_v1=0, loss_v2=0, nll_loss=0.909, ntokens=1018.6, nsentences=32, sample_size=1018.6, sample_size_v1=0, sample_size_v2=0, ppl=1.88, wps=542.9, ups=0.53, wpb=1018.6, bsz=32, num_updates=49640, lr=1.42497e-06, gnorm=19.318, clip=100, loss_scale=32, train_wall=19, gb_free=11.5, wall=93318
2023-05-27 01:18:42 - progress_bar.py[line:272] - INFO: epoch 029:   1238 / 1732 loss=2.088, loss_v1=0, loss_v2=0, nll_loss=0.853, ntokens=1070.1, nsentences=32, sample_size=1070.1, sample_size_v1=0, sample_size_v2=0, ppl=1.81, wps=568.2, ups=0.53, wpb=1070.1, bsz=32, num_updates=49650, lr=1.41883e-06, gnorm=17.861, clip=100, loss_scale=32, train_wall=19, gb_free=11.2, wall=93337
2023-05-27 01:19:01 - progress_bar.py[line:272] - INFO: epoch 029:   1248 / 1732 loss=2.086, loss_v1=0, loss_v2=0, nll_loss=0.851, ntokens=1083.3, nsentences=32, sample_size=1083.3, sample_size_v1=0, sample_size_v2=0, ppl=1.8, wps=575.2, ups=0.53, wpb=1083.3, bsz=32, num_updates=49660, lr=1.41269e-06, gnorm=18.998, clip=100, loss_scale=32, train_wall=19, gb_free=11.3, wall=93356
2023-05-27 01:19:20 - progress_bar.py[line:272] - INFO: epoch 029:   1258 / 1732 loss=2.096, loss_v1=0, loss_v2=0, nll_loss=0.863, ntokens=1058.8, nsentences=32, sample_size=1058.8, sample_size_v1=0, sample_size_v2=0, ppl=1.82, wps=562.5, ups=0.53, wpb=1058.8, bsz=32, num_updates=49670, lr=1.40655e-06, gnorm=19.575, clip=100, loss_scale=32, train_wall=19, gb_free=11.1, wall=93375
2023-05-27 01:19:39 - progress_bar.py[line:272] - INFO: epoch 029:   1268 / 1732 loss=2.116, loss_v1=0, loss_v2=0, nll_loss=0.887, ntokens=1040.1, nsentences=32, sample_size=1040.1, sample_size_v1=0, sample_size_v2=0, ppl=1.85, wps=553.3, ups=0.53, wpb=1040.1, bsz=32, num_updates=49680, lr=1.40041e-06, gnorm=19.227, clip=100, loss_scale=32, train_wall=19, gb_free=11.4, wall=93393
2023-05-27 01:19:58 - progress_bar.py[line:272] - INFO: epoch 029:   1278 / 1732 loss=2.112, loss_v1=0, loss_v2=0, nll_loss=0.881, ntokens=1064.5, nsentences=32, sample_size=1064.5, sample_size_v1=0, sample_size_v2=0, ppl=1.84, wps=563.6, ups=0.53, wpb=1064.5, bsz=32, num_updates=49690, lr=1.39426e-06, gnorm=17.601, clip=100, loss_scale=32, train_wall=19, gb_free=11.4, wall=93412
2023-05-27 01:20:16 - progress_bar.py[line:272] - INFO: epoch 029:   1288 / 1732 loss=2.101, loss_v1=0, loss_v2=0, nll_loss=0.868, ntokens=1074.2, nsentences=32, sample_size=1074.2, sample_size_v1=0, sample_size_v2=0, ppl=1.82, wps=568.4, ups=0.53, wpb=1074.2, bsz=32, num_updates=49700, lr=1.38812e-06, gnorm=17.405, clip=100, loss_scale=32, train_wall=19, gb_free=10, wall=93431
2023-05-27 01:20:35 - progress_bar.py[line:272] - INFO: epoch 029:   1298 / 1732 loss=2.108, loss_v1=0, loss_v2=0, nll_loss=0.876, ntokens=1104.5, nsentences=32, sample_size=1104.5, sample_size_v1=0, sample_size_v2=0, ppl=1.83, wps=584.9, ups=0.53, wpb=1104.5, bsz=32, num_updates=49710, lr=1.38198e-06, gnorm=19.85, clip=100, loss_scale=32, train_wall=19, gb_free=11.1, wall=93450
2023-05-27 01:20:54 - progress_bar.py[line:272] - INFO: epoch 029:   1308 / 1732 loss=2.149, loss_v1=0, loss_v2=0, nll_loss=0.921, ntokens=1079.8, nsentences=32, sample_size=1079.8, sample_size_v1=0, sample_size_v2=0, ppl=1.89, wps=569.3, ups=0.53, wpb=1079.8, bsz=32, num_updates=49720, lr=1.37584e-06, gnorm=19.616, clip=100, loss_scale=32, train_wall=19, gb_free=10.5, wall=93469
2023-05-27 01:21:13 - progress_bar.py[line:272] - INFO: epoch 029:   1318 / 1732 loss=2.117, loss_v1=0, loss_v2=0, nll_loss=0.886, ntokens=1085.2, nsentences=32, sample_size=1085.2, sample_size_v1=0, sample_size_v2=0, ppl=1.85, wps=575.1, ups=0.53, wpb=1085.2, bsz=32, num_updates=49730, lr=1.36969e-06, gnorm=17.963, clip=100, loss_scale=32, train_wall=19, gb_free=10.9, wall=93488
2023-05-27 01:21:32 - progress_bar.py[line:272] - INFO: epoch 029:   1328 / 1732 loss=2.085, loss_v1=0, loss_v2=0, nll_loss=0.85, ntokens=1103.2, nsentences=32, sample_size=1103.2, sample_size_v1=0, sample_size_v2=0, ppl=1.8, wps=582.1, ups=0.53, wpb=1103.2, bsz=32, num_updates=49740, lr=1.36355e-06, gnorm=18.129, clip=100, loss_scale=32, train_wall=19, gb_free=11, wall=93507
2023-05-27 01:21:51 - progress_bar.py[line:272] - INFO: epoch 029:   1338 / 1732 loss=2.114, loss_v1=0, loss_v2=0, nll_loss=0.882, ntokens=1116.2, nsentences=32, sample_size=1116.2, sample_size_v1=0, sample_size_v2=0, ppl=1.84, wps=589.8, ups=0.53, wpb=1116.2, bsz=32, num_updates=49750, lr=1.35741e-06, gnorm=19.011, clip=100, loss_scale=32, train_wall=19, gb_free=10.6, wall=93526
2023-05-27 01:22:10 - progress_bar.py[line:272] - INFO: epoch 029:   1348 / 1732 loss=2.117, loss_v1=0, loss_v2=0, nll_loss=0.887, ntokens=1187.2, nsentences=32, sample_size=1187.2, sample_size_v1=0, sample_size_v2=0, ppl=1.85, wps=623.7, ups=0.53, wpb=1187.2, bsz=32, num_updates=49760, lr=1.35127e-06, gnorm=17.83, clip=100, loss_scale=32, train_wall=19, gb_free=10.7, wall=93545
2023-05-27 01:22:29 - progress_bar.py[line:272] - INFO: epoch 029:   1358 / 1732 loss=2.101, loss_v1=0, loss_v2=0, nll_loss=0.868, ntokens=1099, nsentences=32, sample_size=1099, sample_size_v1=0, sample_size_v2=0, ppl=1.83, wps=581, ups=0.53, wpb=1099, bsz=32, num_updates=49770, lr=1.34513e-06, gnorm=17.52, clip=100, loss_scale=32, train_wall=19, gb_free=11.3, wall=93564
2023-05-27 01:22:48 - progress_bar.py[line:272] - INFO: epoch 029:   1368 / 1732 loss=2.122, loss_v1=0, loss_v2=0, nll_loss=0.893, ntokens=1106.4, nsentences=32, sample_size=1106.4, sample_size_v1=0, sample_size_v2=0, ppl=1.86, wps=584.8, ups=0.53, wpb=1106.4, bsz=32, num_updates=49780, lr=1.33898e-06, gnorm=18.378, clip=100, loss_scale=32, train_wall=19, gb_free=11.3, wall=93583
2023-05-27 01:23:07 - progress_bar.py[line:272] - INFO: epoch 029:   1378 / 1732 loss=2.143, loss_v1=0, loss_v2=0, nll_loss=0.917, ntokens=1104.2, nsentences=32, sample_size=1104.2, sample_size_v1=0, sample_size_v2=0, ppl=1.89, wps=587.7, ups=0.53, wpb=1104.2, bsz=32, num_updates=49790, lr=1.33284e-06, gnorm=19.723, clip=100, loss_scale=32, train_wall=19, gb_free=11.3, wall=93601
2023-05-27 01:23:26 - progress_bar.py[line:272] - INFO: epoch 029:   1388 / 1732 loss=2.127, loss_v1=0, loss_v2=0, nll_loss=0.897, ntokens=1131.9, nsentences=32, sample_size=1131.9, sample_size_v1=0, sample_size_v2=0, ppl=1.86, wps=602.4, ups=0.53, wpb=1131.9, bsz=32, num_updates=49800, lr=1.3267e-06, gnorm=17.316, clip=100, loss_scale=32, train_wall=19, gb_free=11.5, wall=93620
2023-05-27 01:23:44 - progress_bar.py[line:272] - INFO: epoch 029:   1398 / 1732 loss=2.11, loss_v1=0, loss_v2=0, nll_loss=0.879, ntokens=1097.3, nsentences=32, sample_size=1097.3, sample_size_v1=0, sample_size_v2=0, ppl=1.84, wps=582.3, ups=0.53, wpb=1097.3, bsz=32, num_updates=49810, lr=1.32056e-06, gnorm=17.758, clip=100, loss_scale=32, train_wall=19, gb_free=11.3, wall=93639
2023-05-27 01:24:03 - progress_bar.py[line:272] - INFO: epoch 029:   1408 / 1732 loss=2.141, loss_v1=0, loss_v2=0, nll_loss=0.914, ntokens=1161.5, nsentences=32, sample_size=1161.5, sample_size_v1=0, sample_size_v2=0, ppl=1.88, wps=615.2, ups=0.53, wpb=1161.5, bsz=32, num_updates=49820, lr=1.31442e-06, gnorm=18.43, clip=100, loss_scale=32, train_wall=19, gb_free=11.3, wall=93658
2023-05-27 01:24:22 - progress_bar.py[line:272] - INFO: epoch 029:   1418 / 1732 loss=2.152, loss_v1=0, loss_v2=0, nll_loss=0.926, ntokens=1285.2, nsentences=32, sample_size=1285.2, sample_size_v1=0, sample_size_v2=0, ppl=1.9, wps=674.3, ups=0.52, wpb=1285.2, bsz=32, num_updates=49830, lr=1.30827e-06, gnorm=16.27, clip=100, loss_scale=32, train_wall=19, gb_free=10.7, wall=93677
2023-05-27 01:24:41 - progress_bar.py[line:272] - INFO: epoch 029:   1428 / 1732 loss=2.117, loss_v1=0, loss_v2=0, nll_loss=0.885, ntokens=1229.6, nsentences=32, sample_size=1229.6, sample_size_v1=0, sample_size_v2=0, ppl=1.85, wps=645.7, ups=0.53, wpb=1229.6, bsz=32, num_updates=49840, lr=1.30213e-06, gnorm=17.552, clip=100, loss_scale=32, train_wall=19, gb_free=11.4, wall=93696
2023-05-27 01:25:00 - progress_bar.py[line:272] - INFO: epoch 029:   1438 / 1732 loss=2.119, loss_v1=0, loss_v2=0, nll_loss=0.888, ntokens=1179.5, nsentences=32, sample_size=1179.5, sample_size_v1=0, sample_size_v2=0, ppl=1.85, wps=624.4, ups=0.53, wpb=1179.5, bsz=32, num_updates=49850, lr=1.29599e-06, gnorm=17.155, clip=100, loss_scale=32, train_wall=19, gb_free=11.6, wall=93715
2023-05-27 01:25:19 - progress_bar.py[line:272] - INFO: epoch 029:   1448 / 1732 loss=2.12, loss_v1=0, loss_v2=0, nll_loss=0.889, ntokens=1120.7, nsentences=32, sample_size=1120.7, sample_size_v1=0, sample_size_v2=0, ppl=1.85, wps=596.1, ups=0.53, wpb=1120.7, bsz=32, num_updates=49860, lr=1.28985e-06, gnorm=16.956, clip=100, loss_scale=32, train_wall=19, gb_free=11.4, wall=93734
2023-05-27 01:25:38 - progress_bar.py[line:272] - INFO: epoch 029:   1458 / 1732 loss=2.13, loss_v1=0, loss_v2=0, nll_loss=0.899, ntokens=1151.7, nsentences=32, sample_size=1151.7, sample_size_v1=0, sample_size_v2=0, ppl=1.87, wps=602.4, ups=0.52, wpb=1151.7, bsz=32, num_updates=49870, lr=1.2837e-06, gnorm=19.27, clip=100, loss_scale=32, train_wall=19, gb_free=10.8, wall=93753
2023-05-27 01:25:57 - progress_bar.py[line:272] - INFO: epoch 029:   1468 / 1732 loss=2.099, loss_v1=0, loss_v2=0, nll_loss=0.866, ntokens=1195.8, nsentences=32, sample_size=1195.8, sample_size_v1=0, sample_size_v2=0, ppl=1.82, wps=630.1, ups=0.53, wpb=1195.8, bsz=32, num_updates=49880, lr=1.27756e-06, gnorm=16.854, clip=100, loss_scale=32, train_wall=19, gb_free=10.6, wall=93772
2023-05-27 01:26:16 - progress_bar.py[line:272] - INFO: epoch 029:   1478 / 1732 loss=2.142, loss_v1=0, loss_v2=0, nll_loss=0.914, ntokens=1019.5, nsentences=32, sample_size=1019.5, sample_size_v1=0, sample_size_v2=0, ppl=1.88, wps=543, ups=0.53, wpb=1019.5, bsz=32, num_updates=49890, lr=1.27142e-06, gnorm=20.812, clip=100, loss_scale=32, train_wall=19, gb_free=11.4, wall=93791
2023-05-27 01:26:35 - progress_bar.py[line:272] - INFO: epoch 029:   1488 / 1732 loss=2.13, loss_v1=0, loss_v2=0, nll_loss=0.901, ntokens=1151.5, nsentences=32, sample_size=1151.5, sample_size_v1=0, sample_size_v2=0, ppl=1.87, wps=609.3, ups=0.53, wpb=1151.5, bsz=32, num_updates=49900, lr=1.26528e-06, gnorm=16.265, clip=100, loss_scale=32, train_wall=19, gb_free=10.7, wall=93810
2023-05-27 01:26:54 - progress_bar.py[line:272] - INFO: epoch 029:   1498 / 1732 loss=2.115, loss_v1=0, loss_v2=0, nll_loss=0.883, ntokens=1078, nsentences=32, sample_size=1078, sample_size_v1=0, sample_size_v2=0, ppl=1.84, wps=571.6, ups=0.53, wpb=1078, bsz=32, num_updates=49910, lr=1.25914e-06, gnorm=17.944, clip=100, loss_scale=32, train_wall=19, gb_free=11.4, wall=93828
2023-05-27 01:27:13 - progress_bar.py[line:272] - INFO: epoch 029:   1508 / 1732 loss=2.091, loss_v1=0, loss_v2=0, nll_loss=0.858, ntokens=1107.9, nsentences=32, sample_size=1107.9, sample_size_v1=0, sample_size_v2=0, ppl=1.81, wps=588.5, ups=0.53, wpb=1107.9, bsz=32, num_updates=49920, lr=1.25299e-06, gnorm=18.764, clip=100, loss_scale=32, train_wall=19, gb_free=11.3, wall=93847
2023-05-27 01:27:31 - progress_bar.py[line:272] - INFO: epoch 029:   1518 / 1732 loss=2.15, loss_v1=0, loss_v2=0, nll_loss=0.923, ntokens=1079, nsentences=32, sample_size=1079, sample_size_v1=0, sample_size_v2=0, ppl=1.9, wps=573.2, ups=0.53, wpb=1079, bsz=32, num_updates=49930, lr=1.24685e-06, gnorm=18.729, clip=100, loss_scale=32, train_wall=19, gb_free=11.1, wall=93866
2023-05-27 01:27:50 - progress_bar.py[line:272] - INFO: epoch 029:   1528 / 1732 loss=2.167, loss_v1=0, loss_v2=0, nll_loss=0.943, ntokens=1041.5, nsentences=32, sample_size=1041.5, sample_size_v1=0, sample_size_v2=0, ppl=1.92, wps=555.8, ups=0.53, wpb=1041.5, bsz=32, num_updates=49940, lr=1.24071e-06, gnorm=19.109, clip=100, loss_scale=32, train_wall=19, gb_free=11.6, wall=93885
2023-05-27 01:28:09 - progress_bar.py[line:272] - INFO: epoch 029:   1538 / 1732 loss=2.12, loss_v1=0, loss_v2=0, nll_loss=0.889, ntokens=1094, nsentences=32, sample_size=1094, sample_size_v1=0, sample_size_v2=0, ppl=1.85, wps=575.2, ups=0.53, wpb=1094, bsz=32, num_updates=49950, lr=1.23457e-06, gnorm=18.021, clip=100, loss_scale=32, train_wall=19, gb_free=11, wall=93904
2023-05-27 01:28:28 - progress_bar.py[line:272] - INFO: epoch 029:   1548 / 1732 loss=2.108, loss_v1=0, loss_v2=0, nll_loss=0.877, ntokens=1084.2, nsentences=32, sample_size=1084.2, sample_size_v1=0, sample_size_v2=0, ppl=1.84, wps=576.4, ups=0.53, wpb=1084.2, bsz=32, num_updates=49960, lr=1.22843e-06, gnorm=19.491, clip=100, loss_scale=32, train_wall=19, gb_free=11.4, wall=93923
2023-05-27 01:28:35 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2023-05-27 01:28:49 - progress_bar.py[line:272] - INFO: epoch 029:   1559 / 1732 loss=2.1, loss_v1=0, loss_v2=0, nll_loss=0.868, ntokens=1097.1, nsentences=32, sample_size=1097.1, sample_size_v1=0, sample_size_v2=0, ppl=1.83, wps=531.5, ups=0.48, wpb=1097.1, bsz=32, num_updates=49970, lr=1.22228e-06, gnorm=17.043, clip=100, loss_scale=32, train_wall=21, gb_free=11.3, wall=93943
2023-05-27 01:29:08 - progress_bar.py[line:272] - INFO: epoch 029:   1569 / 1732 loss=2.149, loss_v1=0, loss_v2=0, nll_loss=0.922, ntokens=1059.1, nsentences=32, sample_size=1059.1, sample_size_v1=0, sample_size_v2=0, ppl=1.89, wps=561.4, ups=0.53, wpb=1059.1, bsz=32, num_updates=49980, lr=1.21614e-06, gnorm=18.787, clip=100, loss_scale=32, train_wall=19, gb_free=10.7, wall=93962
2023-05-27 01:29:26 - progress_bar.py[line:272] - INFO: epoch 029:   1579 / 1732 loss=2.129, loss_v1=0, loss_v2=0, nll_loss=0.9, ntokens=1008.7, nsentences=32, sample_size=1008.7, sample_size_v1=0, sample_size_v2=0, ppl=1.87, wps=537.5, ups=0.53, wpb=1008.7, bsz=32, num_updates=49990, lr=1.21e-06, gnorm=19.777, clip=100, loss_scale=32, train_wall=19, gb_free=11.2, wall=93981
2023-05-27 01:29:45 - progress_bar.py[line:272] - INFO: epoch 029:   1589 / 1732 loss=2.128, loss_v1=0, loss_v2=0, nll_loss=0.899, ntokens=1092.2, nsentences=32, sample_size=1092.2, sample_size_v1=0, sample_size_v2=0, ppl=1.86, wps=578.6, ups=0.53, wpb=1092.2, bsz=32, num_updates=50000, lr=1.20386e-06, gnorm=17.962, clip=100, loss_scale=32, train_wall=19, gb_free=11.4, wall=94000
2023-05-27 01:30:04 - progress_bar.py[line:272] - INFO: epoch 029:   1599 / 1732 loss=2.101, loss_v1=0, loss_v2=0, nll_loss=0.868, ntokens=1061.1, nsentences=32, sample_size=1061.1, sample_size_v1=0, sample_size_v2=0, ppl=1.82, wps=564.8, ups=0.53, wpb=1061.1, bsz=32, num_updates=50010, lr=1.19772e-06, gnorm=18.335, clip=100, loss_scale=32, train_wall=19, gb_free=11.3, wall=94019
2023-05-27 01:30:23 - progress_bar.py[line:272] - INFO: epoch 029:   1609 / 1732 loss=2.104, loss_v1=0, loss_v2=0, nll_loss=0.871, ntokens=1155.5, nsentences=32, sample_size=1155.5, sample_size_v1=0, sample_size_v2=0, ppl=1.83, wps=608.5, ups=0.53, wpb=1155.5, bsz=32, num_updates=50020, lr=1.19157e-06, gnorm=17.751, clip=100, loss_scale=32, train_wall=19, gb_free=10.9, wall=94038
2023-05-27 01:30:42 - progress_bar.py[line:272] - INFO: epoch 029:   1619 / 1732 loss=2.09, loss_v1=0, loss_v2=0, nll_loss=0.856, ntokens=1123.8, nsentences=32, sample_size=1123.8, sample_size_v1=0, sample_size_v2=0, ppl=1.81, wps=593.1, ups=0.53, wpb=1123.8, bsz=32, num_updates=50030, lr=1.18543e-06, gnorm=17.648, clip=100, loss_scale=32, train_wall=19, gb_free=10.9, wall=94057
2023-05-27 01:31:01 - progress_bar.py[line:272] - INFO: epoch 029:   1629 / 1732 loss=2.134, loss_v1=0, loss_v2=0, nll_loss=0.905, ntokens=1172.3, nsentences=32, sample_size=1172.3, sample_size_v1=0, sample_size_v2=0, ppl=1.87, wps=616.6, ups=0.53, wpb=1172.3, bsz=32, num_updates=50040, lr=1.17929e-06, gnorm=18.71, clip=100, loss_scale=32, train_wall=19, gb_free=11.2, wall=94076
2023-05-27 01:31:20 - progress_bar.py[line:272] - INFO: epoch 029:   1639 / 1732 loss=2.105, loss_v1=0, loss_v2=0, nll_loss=0.872, ntokens=1139.8, nsentences=32, sample_size=1139.8, sample_size_v1=0, sample_size_v2=0, ppl=1.83, wps=606.3, ups=0.53, wpb=1139.8, bsz=32, num_updates=50050, lr=1.17315e-06, gnorm=19.168, clip=100, loss_scale=32, train_wall=19, gb_free=10.8, wall=94094
2023-05-27 01:31:39 - progress_bar.py[line:272] - INFO: epoch 029:   1649 / 1732 loss=2.11, loss_v1=0, loss_v2=0, nll_loss=0.877, ntokens=1200.9, nsentences=32, sample_size=1200.9, sample_size_v1=0, sample_size_v2=0, ppl=1.84, wps=631.2, ups=0.53, wpb=1200.9, bsz=32, num_updates=50060, lr=1.167e-06, gnorm=17.007, clip=100, loss_scale=32, train_wall=19, gb_free=11.3, wall=94113
2023-05-27 01:31:57 - progress_bar.py[line:272] - INFO: epoch 029:   1659 / 1732 loss=2.143, loss_v1=0, loss_v2=0, nll_loss=0.914, ntokens=965.2, nsentences=32, sample_size=965.2, sample_size_v1=0, sample_size_v2=0, ppl=1.88, wps=514.9, ups=0.53, wpb=965.2, bsz=32, num_updates=50070, lr=1.16086e-06, gnorm=21.485, clip=100, loss_scale=32, train_wall=19, gb_free=11.1, wall=94132
2023-05-27 01:32:16 - progress_bar.py[line:272] - INFO: epoch 029:   1669 / 1732 loss=2.114, loss_v1=0, loss_v2=0, nll_loss=0.883, ntokens=1018.2, nsentences=32, sample_size=1018.2, sample_size_v1=0, sample_size_v2=0, ppl=1.84, wps=543.8, ups=0.53, wpb=1018.2, bsz=32, num_updates=50080, lr=1.15472e-06, gnorm=17.909, clip=100, loss_scale=32, train_wall=19, gb_free=11.8, wall=94151
2023-05-27 01:32:35 - progress_bar.py[line:272] - INFO: epoch 029:   1679 / 1732 loss=2.084, loss_v1=0, loss_v2=0, nll_loss=0.849, ntokens=1155.9, nsentences=32, sample_size=1155.9, sample_size_v1=0, sample_size_v2=0, ppl=1.8, wps=606.9, ups=0.53, wpb=1155.9, bsz=32, num_updates=50090, lr=1.14858e-06, gnorm=17.526, clip=100, loss_scale=32, train_wall=19, gb_free=10.8, wall=94170
2023-05-27 01:32:54 - progress_bar.py[line:272] - INFO: epoch 029:   1689 / 1732 loss=2.118, loss_v1=0, loss_v2=0, nll_loss=0.887, ntokens=1198.6, nsentences=32, sample_size=1198.6, sample_size_v1=0, sample_size_v2=0, ppl=1.85, wps=628.1, ups=0.52, wpb=1198.6, bsz=32, num_updates=50100, lr=1.14244e-06, gnorm=16.569, clip=100, loss_scale=32, train_wall=19, gb_free=10.4, wall=94189
2023-05-27 01:33:14 - progress_bar.py[line:272] - INFO: epoch 029:   1699 / 1732 loss=2.102, loss_v1=0, loss_v2=0, nll_loss=0.87, ntokens=1300, nsentences=32, sample_size=1300, sample_size_v1=0, sample_size_v2=0, ppl=1.83, wps=674.9, ups=0.52, wpb=1300, bsz=32, num_updates=50110, lr=1.13629e-06, gnorm=15.532, clip=100, loss_scale=32, train_wall=19, gb_free=11.1, wall=94208
2023-05-27 01:33:33 - progress_bar.py[line:272] - INFO: epoch 029:   1709 / 1732 loss=2.132, loss_v1=0, loss_v2=0, nll_loss=0.902, ntokens=1178.3, nsentences=32, sample_size=1178.3, sample_size_v1=0, sample_size_v2=0, ppl=1.87, wps=622.1, ups=0.53, wpb=1178.3, bsz=32, num_updates=50120, lr=1.13015e-06, gnorm=17.466, clip=100, loss_scale=32, train_wall=19, gb_free=11.3, wall=94227
2023-05-27 01:33:52 - progress_bar.py[line:272] - INFO: epoch 029:   1719 / 1732 loss=2.096, loss_v1=0, loss_v2=0, nll_loss=0.862, ntokens=1171.3, nsentences=32, sample_size=1171.3, sample_size_v1=0, sample_size_v2=0, ppl=1.82, wps=613.6, ups=0.52, wpb=1171.3, bsz=32, num_updates=50130, lr=1.12401e-06, gnorm=15.88, clip=100, loss_scale=32, train_wall=19, gb_free=10.9, wall=94246
2023-05-27 01:34:11 - progress_bar.py[line:272] - INFO: epoch 029:   1729 / 1732 loss=2.139, loss_v1=0, loss_v2=0, nll_loss=0.912, ntokens=1095.7, nsentences=32, sample_size=1095.7, sample_size_v1=0, sample_size_v2=0, ppl=1.88, wps=578.8, ups=0.53, wpb=1095.7, bsz=32, num_updates=50140, lr=1.11787e-06, gnorm=18.567, clip=100, loss_scale=32, train_wall=19, gb_free=10.8, wall=94265
2023-05-27 01:34:15 - train.py[line:332] - INFO: end of epoch 29 (average epoch stats below)
2023-05-27 01:34:15 - progress_bar.py[line:282] - INFO: epoch 029 | loss 2.122 | loss_v1 0 | loss_v2 0 | nll_loss 0.891 | ntokens 1051.67 | nsentences 31.986 | sample_size 1051.67 | sample_size_v1 0 | sample_size_v2 0 | ppl 1.85 | wps 559.4 | ups 0.53 | wpb 1051.7 | bsz 32 | num_updates 50143 | lr 1.11602e-06 | gnorm 19.135 | clip 100 | loss_scale 32 | train_wall 3242 | gb_free 11.7 | wall 94270
2023-05-27 01:34:15 - trainer.py[line:639] - INFO: loading train data for epoch 30
local datafile ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 0 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 0 finished initializing row_count and line_idx-to-offset mapping
file ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 0 row count 55400 total row count 55400
slice_id 0 seek offset 0
2023-05-27 01:34:17 - trainer.py[line:703] - INFO: begin training epoch 30
2023-05-27 01:34:17 - train.py[line:305] - INFO: Start iterating over samples
2023-05-27 01:34:30 - progress_bar.py[line:272] - INFO: epoch 030:      7 / 1732 loss=2.098, loss_v1=0, loss_v2=0, nll_loss=0.865, ntokens=1093.3, nsentences=29.6, sample_size=1093.3, sample_size_v1=0, sample_size_v2=0, ppl=1.82, wps=551.7, ups=0.5, wpb=1093.3, bsz=29.6, num_updates=50150, lr=1.11173e-06, gnorm=19.303, clip=100, loss_scale=32, train_wall=18, gb_free=11.2, wall=94285
2023-05-27 01:34:49 - progress_bar.py[line:272] - INFO: epoch 030:     17 / 1732 loss=2.109, loss_v1=0, loss_v2=0, nll_loss=0.878, ntokens=1095.7, nsentences=32, sample_size=1095.7, sample_size_v1=0, sample_size_v2=0, ppl=1.84, wps=578.7, ups=0.53, wpb=1095.7, bsz=32, num_updates=50160, lr=1.10558e-06, gnorm=22.615, clip=100, loss_scale=32, train_wall=19, gb_free=11, wall=94304
2023-05-27 01:35:08 - progress_bar.py[line:272] - INFO: epoch 030:     27 / 1732 loss=2.11, loss_v1=0, loss_v2=0, nll_loss=0.878, ntokens=954.5, nsentences=32, sample_size=954.5, sample_size_v1=0, sample_size_v2=0, ppl=1.84, wps=506.6, ups=0.53, wpb=954.5, bsz=32, num_updates=50170, lr=1.09944e-06, gnorm=24.658, clip=100, loss_scale=32, train_wall=19, gb_free=10.7, wall=94323
2023-05-27 01:35:27 - progress_bar.py[line:272] - INFO: epoch 030:     37 / 1732 loss=1.988, loss_v1=0, loss_v2=0, nll_loss=0.742, ntokens=1179.3, nsentences=32, sample_size=1179.3, sample_size_v1=0, sample_size_v2=0, ppl=1.67, wps=618.2, ups=0.52, wpb=1179.3, bsz=32, num_updates=50180, lr=1.0933e-06, gnorm=18.74, clip=100, loss_scale=32, train_wall=19, gb_free=10.9, wall=94342
2023-05-27 01:35:46 - progress_bar.py[line:272] - INFO: epoch 030:     47 / 1732 loss=1.998, loss_v1=0, loss_v2=0, nll_loss=0.753, ntokens=1055.1, nsentences=32, sample_size=1055.1, sample_size_v1=0, sample_size_v2=0, ppl=1.69, wps=558.1, ups=0.53, wpb=1055.1, bsz=32, num_updates=50190, lr=1.08716e-06, gnorm=21.864, clip=100, loss_scale=32, train_wall=19, gb_free=10.8, wall=94361
2023-05-27 01:36:05 - progress_bar.py[line:272] - INFO: epoch 030:     57 / 1732 loss=1.938, loss_v1=0, loss_v2=0, nll_loss=0.686, ntokens=1048.7, nsentences=32, sample_size=1048.7, sample_size_v1=0, sample_size_v2=0, ppl=1.61, wps=557.1, ups=0.53, wpb=1048.7, bsz=32, num_updates=50200, lr=1.08101e-06, gnorm=23.675, clip=100, loss_scale=32, train_wall=19, gb_free=11.2, wall=94380
2023-05-27 01:36:24 - progress_bar.py[line:272] - INFO: epoch 030:     67 / 1732 loss=1.871, loss_v1=0, loss_v2=0, nll_loss=0.61, ntokens=1356.1, nsentences=32, sample_size=1356.1, sample_size_v1=0, sample_size_v2=0, ppl=1.53, wps=700.7, ups=0.52, wpb=1356.1, bsz=32, num_updates=50210, lr=1.07487e-06, gnorm=18.27, clip=100, loss_scale=32, train_wall=19, gb_free=10.3, wall=94399
2023-05-27 01:36:44 - progress_bar.py[line:272] - INFO: epoch 030:     77 / 1732 loss=1.936, loss_v1=0, loss_v2=0, nll_loss=0.683, ntokens=1273.9, nsentences=32, sample_size=1273.9, sample_size_v1=0, sample_size_v2=0, ppl=1.61, wps=655, ups=0.51, wpb=1273.9, bsz=32, num_updates=50220, lr=1.06873e-06, gnorm=15.941, clip=100, loss_scale=32, train_wall=19, gb_free=11.1, wall=94418
2023-05-27 01:37:03 - progress_bar.py[line:272] - INFO: epoch 030:     87 / 1732 loss=1.991, loss_v1=0, loss_v2=0, nll_loss=0.745, ntokens=1141.2, nsentences=32, sample_size=1141.2, sample_size_v1=0, sample_size_v2=0, ppl=1.68, wps=592.8, ups=0.52, wpb=1141.2, bsz=32, num_updates=50230, lr=1.06259e-06, gnorm=18.789, clip=100, loss_scale=32, train_wall=19, gb_free=10.6, wall=94438
2023-05-27 01:37:22 - progress_bar.py[line:272] - INFO: epoch 030:     97 / 1732 loss=1.969, loss_v1=0, loss_v2=0, nll_loss=0.721, ntokens=1080.1, nsentences=32, sample_size=1080.1, sample_size_v1=0, sample_size_v2=0, ppl=1.65, wps=568.7, ups=0.53, wpb=1080.1, bsz=32, num_updates=50240, lr=1.05645e-06, gnorm=20.121, clip=100, loss_scale=32, train_wall=19, gb_free=10.1, wall=94457
2023-05-27 01:37:41 - progress_bar.py[line:272] - INFO: epoch 030:    107 / 1732 loss=2.061, loss_v1=0, loss_v2=0, nll_loss=0.822, ntokens=981.4, nsentences=32, sample_size=981.4, sample_size_v1=0, sample_size_v2=0, ppl=1.77, wps=522.7, ups=0.53, wpb=981.4, bsz=32, num_updates=50250, lr=1.0503e-06, gnorm=21.378, clip=100, loss_scale=32, train_wall=19, gb_free=11, wall=94476
2023-05-27 01:38:00 - progress_bar.py[line:272] - INFO: epoch 030:    117 / 1732 loss=2.146, loss_v1=0, loss_v2=0, nll_loss=0.919, ntokens=1060.7, nsentences=32, sample_size=1060.7, sample_size_v1=0, sample_size_v2=0, ppl=1.89, wps=557.5, ups=0.53, wpb=1060.7, bsz=32, num_updates=50260, lr=1.04416e-06, gnorm=21.569, clip=100, loss_scale=32, train_wall=19, gb_free=10.6, wall=94495
2023-05-27 01:38:19 - progress_bar.py[line:272] - INFO: epoch 030:    127 / 1732 loss=2.108, loss_v1=0, loss_v2=0, nll_loss=0.876, ntokens=1185.5, nsentences=32, sample_size=1185.5, sample_size_v1=0, sample_size_v2=0, ppl=1.83, wps=615.5, ups=0.52, wpb=1185.5, bsz=32, num_updates=50270, lr=1.03802e-06, gnorm=19.123, clip=100, loss_scale=32, train_wall=19, gb_free=11.1, wall=94514
2023-05-27 01:38:38 - progress_bar.py[line:272] - INFO: epoch 030:    137 / 1732 loss=2.091, loss_v1=0, loss_v2=0, nll_loss=0.857, ntokens=1222.2, nsentences=32, sample_size=1222.2, sample_size_v1=0, sample_size_v2=0, ppl=1.81, wps=639.5, ups=0.52, wpb=1222.2, bsz=32, num_updates=50280, lr=1.03188e-06, gnorm=17.989, clip=100, loss_scale=32, train_wall=19, gb_free=11, wall=94533
2023-05-27 01:38:58 - progress_bar.py[line:272] - INFO: epoch 030:    147 / 1732 loss=2.049, loss_v1=0, loss_v2=0, nll_loss=0.809, ntokens=1207.1, nsentences=32, sample_size=1207.1, sample_size_v1=0, sample_size_v2=0, ppl=1.75, wps=624.3, ups=0.52, wpb=1207.1, bsz=32, num_updates=50290, lr=1.02574e-06, gnorm=18.181, clip=100, loss_scale=32, train_wall=19, gb_free=10.9, wall=94552
2023-05-27 01:39:17 - progress_bar.py[line:272] - INFO: epoch 030:    157 / 1732 loss=2.094, loss_v1=0, loss_v2=0, nll_loss=0.861, ntokens=1172.8, nsentences=32, sample_size=1172.8, sample_size_v1=0, sample_size_v2=0, ppl=1.82, wps=607.7, ups=0.52, wpb=1172.8, bsz=32, num_updates=50300, lr=1.01959e-06, gnorm=19.983, clip=100, loss_scale=32, train_wall=19, gb_free=11.1, wall=94572
2023-05-27 01:39:36 - progress_bar.py[line:272] - INFO: epoch 030:    167 / 1732 loss=2.077, loss_v1=0, loss_v2=0, nll_loss=0.842, ntokens=1009.5, nsentences=32, sample_size=1009.5, sample_size_v1=0, sample_size_v2=0, ppl=1.79, wps=532.2, ups=0.53, wpb=1009.5, bsz=32, num_updates=50310, lr=1.01345e-06, gnorm=22.588, clip=100, loss_scale=32, train_wall=19, gb_free=10.3, wall=94591
2023-05-27 01:39:55 - progress_bar.py[line:272] - INFO: epoch 030:    177 / 1732 loss=2.088, loss_v1=0, loss_v2=0, nll_loss=0.854, ntokens=994.5, nsentences=32, sample_size=994.5, sample_size_v1=0, sample_size_v2=0, ppl=1.81, wps=526.9, ups=0.53, wpb=994.5, bsz=32, num_updates=50320, lr=1.00731e-06, gnorm=24.086, clip=100, loss_scale=32, train_wall=19, gb_free=10.8, wall=94609
2023-05-27 01:40:14 - progress_bar.py[line:272] - INFO: epoch 030:    187 / 1732 loss=2.041, loss_v1=0, loss_v2=0, nll_loss=0.802, ntokens=1141.8, nsentences=32, sample_size=1141.8, sample_size_v1=0, sample_size_v2=0, ppl=1.74, wps=596.8, ups=0.52, wpb=1141.8, bsz=32, num_updates=50330, lr=1.00117e-06, gnorm=19.701, clip=100, loss_scale=32, train_wall=19, gb_free=10.5, wall=94629
2023-05-27 01:40:33 - progress_bar.py[line:272] - INFO: epoch 030:    197 / 1732 loss=2.087, loss_v1=0, loss_v2=0, nll_loss=0.852, ntokens=1173.2, nsentences=32, sample_size=1173.2, sample_size_v1=0, sample_size_v2=0, ppl=1.81, wps=616.6, ups=0.53, wpb=1173.2, bsz=32, num_updates=50340, lr=9.95025e-07, gnorm=19.351, clip=100, loss_scale=32, train_wall=19, gb_free=11.4, wall=94648
2023-05-27 01:40:52 - progress_bar.py[line:272] - INFO: epoch 030:    207 / 1732 loss=2.119, loss_v1=0, loss_v2=0, nll_loss=0.888, ntokens=957.1, nsentences=32, sample_size=957.1, sample_size_v1=0, sample_size_v2=0, ppl=1.85, wps=514.6, ups=0.54, wpb=957.1, bsz=32, num_updates=50350, lr=9.88883e-07, gnorm=21.44, clip=100, loss_scale=32, train_wall=19, gb_free=10.7, wall=94666
2023-05-27 01:41:10 - progress_bar.py[line:272] - INFO: epoch 030:    217 / 1732 loss=2.15, loss_v1=0, loss_v2=0, nll_loss=0.922, ntokens=1157.1, nsentences=32, sample_size=1157.1, sample_size_v1=0, sample_size_v2=0, ppl=1.9, wps=614.3, ups=0.53, wpb=1157.1, bsz=32, num_updates=50360, lr=9.82741e-07, gnorm=16.695, clip=100, loss_scale=32, train_wall=19, gb_free=11.2, wall=94685
2023-05-27 01:41:29 - progress_bar.py[line:272] - INFO: epoch 030:    227 / 1732 loss=2.118, loss_v1=0, loss_v2=0, nll_loss=0.888, ntokens=1106.8, nsentences=32, sample_size=1106.8, sample_size_v1=0, sample_size_v2=0, ppl=1.85, wps=589.1, ups=0.53, wpb=1106.8, bsz=32, num_updates=50370, lr=9.76598e-07, gnorm=17.035, clip=100, loss_scale=32, train_wall=19, gb_free=10.9, wall=94704
2023-05-27 01:41:48 - progress_bar.py[line:272] - INFO: epoch 030:    237 / 1732 loss=2.184, loss_v1=0, loss_v2=0, nll_loss=0.962, ntokens=1060.1, nsentences=32, sample_size=1060.1, sample_size_v1=0, sample_size_v2=0, ppl=1.95, wps=565.9, ups=0.53, wpb=1060.1, bsz=32, num_updates=50380, lr=9.70456e-07, gnorm=18.004, clip=100, loss_scale=32, train_wall=19, gb_free=10.7, wall=94723
2023-05-27 01:42:07 - progress_bar.py[line:272] - INFO: epoch 030:    247 / 1732 loss=2.153, loss_v1=0, loss_v2=0, nll_loss=0.927, ntokens=1188.4, nsentences=32, sample_size=1188.4, sample_size_v1=0, sample_size_v2=0, ppl=1.9, wps=630.4, ups=0.53, wpb=1188.4, bsz=32, num_updates=50390, lr=9.64314e-07, gnorm=16.46, clip=100, loss_scale=32, train_wall=19, gb_free=10.9, wall=94741
2023-05-27 01:42:26 - progress_bar.py[line:272] - INFO: epoch 030:    257 / 1732 loss=2.147, loss_v1=0, loss_v2=0, nll_loss=0.92, ntokens=1118.5, nsentences=32, sample_size=1118.5, sample_size_v1=0, sample_size_v2=0, ppl=1.89, wps=595.6, ups=0.53, wpb=1118.5, bsz=32, num_updates=50400, lr=9.58172e-07, gnorm=17.424, clip=100, loss_scale=32, train_wall=19, gb_free=11.2, wall=94760
2023-05-27 01:42:44 - progress_bar.py[line:272] - INFO: epoch 030:    267 / 1732 loss=2.132, loss_v1=0, loss_v2=0, nll_loss=0.903, ntokens=1162.2, nsentences=32, sample_size=1162.2, sample_size_v1=0, sample_size_v2=0, ppl=1.87, wps=617.5, ups=0.53, wpb=1162.2, bsz=32, num_updates=50410, lr=9.5203e-07, gnorm=16.618, clip=100, loss_scale=32, train_wall=19, gb_free=11.2, wall=94779
2023-05-27 01:43:03 - progress_bar.py[line:272] - INFO: epoch 030:    277 / 1732 loss=2.16, loss_v1=0, loss_v2=0, nll_loss=0.935, ntokens=1137.3, nsentences=32, sample_size=1137.3, sample_size_v1=0, sample_size_v2=0, ppl=1.91, wps=602.3, ups=0.53, wpb=1137.3, bsz=32, num_updates=50420, lr=9.45888e-07, gnorm=18.836, clip=100, loss_scale=32, train_wall=19, gb_free=11.3, wall=94798
2023-05-27 01:43:22 - progress_bar.py[line:272] - INFO: epoch 030:    287 / 1732 loss=2.13, loss_v1=0, loss_v2=0, nll_loss=0.901, ntokens=1149.1, nsentences=32, sample_size=1149.1, sample_size_v1=0, sample_size_v2=0, ppl=1.87, wps=608.6, ups=0.53, wpb=1149.1, bsz=32, num_updates=50430, lr=9.39746e-07, gnorm=16.046, clip=100, loss_scale=32, train_wall=19, gb_free=10.6, wall=94817
2023-05-27 01:43:41 - progress_bar.py[line:272] - INFO: epoch 030:    297 / 1732 loss=2.15, loss_v1=0, loss_v2=0, nll_loss=0.923, ntokens=1120.1, nsentences=32, sample_size=1120.1, sample_size_v1=0, sample_size_v2=0, ppl=1.9, wps=597.7, ups=0.53, wpb=1120.1, bsz=32, num_updates=50440, lr=9.33604e-07, gnorm=17.243, clip=100, loss_scale=32, train_wall=19, gb_free=10.9, wall=94836
2023-05-27 01:44:00 - progress_bar.py[line:272] - INFO: epoch 030:    307 / 1732 loss=2.138, loss_v1=0, loss_v2=0, nll_loss=0.91, ntokens=1063.6, nsentences=32, sample_size=1063.6, sample_size_v1=0, sample_size_v2=0, ppl=1.88, wps=569.3, ups=0.54, wpb=1063.6, bsz=32, num_updates=50450, lr=9.27461e-07, gnorm=19.263, clip=100, loss_scale=32, train_wall=19, gb_free=11.5, wall=94854
2023-05-27 01:44:18 - progress_bar.py[line:272] - INFO: epoch 030:    317 / 1732 loss=2.16, loss_v1=0, loss_v2=0, nll_loss=0.935, ntokens=1045.4, nsentences=32, sample_size=1045.4, sample_size_v1=0, sample_size_v2=0, ppl=1.91, wps=560.2, ups=0.54, wpb=1045.4, bsz=32, num_updates=50460, lr=9.21319e-07, gnorm=20.43, clip=100, loss_scale=32, train_wall=19, gb_free=11.5, wall=94873
2023-05-27 01:44:37 - progress_bar.py[line:272] - INFO: epoch 030:    327 / 1732 loss=2.181, loss_v1=0, loss_v2=0, nll_loss=0.957, ntokens=1029.3, nsentences=32, sample_size=1029.3, sample_size_v1=0, sample_size_v2=0, ppl=1.94, wps=552.3, ups=0.54, wpb=1029.3, bsz=32, num_updates=50470, lr=9.15177e-07, gnorm=18.576, clip=100, loss_scale=32, train_wall=19, gb_free=11.4, wall=94892
2023-05-27 01:44:48 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2023-05-27 01:44:57 - progress_bar.py[line:272] - INFO: epoch 030:    338 / 1732 loss=2.143, loss_v1=0, loss_v2=0, nll_loss=0.914, ntokens=972, nsentences=32, sample_size=972, sample_size_v1=0, sample_size_v2=0, ppl=1.88, wps=478.5, ups=0.49, wpb=972, bsz=32, num_updates=50480, lr=9.09035e-07, gnorm=19.335, clip=100, loss_scale=32, train_wall=20, gb_free=11.7, wall=94912
2023-05-27 01:45:16 - progress_bar.py[line:272] - INFO: epoch 030:    348 / 1732 loss=2.129, loss_v1=0, loss_v2=0, nll_loss=0.9, ntokens=913.6, nsentences=32, sample_size=913.6, sample_size_v1=0, sample_size_v2=0, ppl=1.87, wps=493.2, ups=0.54, wpb=913.6, bsz=32, num_updates=50490, lr=9.02893e-07, gnorm=22.47, clip=100, loss_scale=32, train_wall=18, gb_free=11.6, wall=94930
2023-05-27 01:45:34 - progress_bar.py[line:272] - INFO: epoch 030:    358 / 1732 loss=2.178, loss_v1=0, loss_v2=0, nll_loss=0.955, ntokens=943, nsentences=32, sample_size=943, sample_size_v1=0, sample_size_v2=0, ppl=1.94, wps=508.9, ups=0.54, wpb=943, bsz=32, num_updates=50500, lr=8.96751e-07, gnorm=20.102, clip=100, loss_scale=32, train_wall=18, gb_free=11.9, wall=94949
2023-05-27 01:45:53 - progress_bar.py[line:272] - INFO: epoch 030:    368 / 1732 loss=2.171, loss_v1=0, loss_v2=0, nll_loss=0.947, ntokens=960.6, nsentences=32, sample_size=960.6, sample_size_v1=0, sample_size_v2=0, ppl=1.93, wps=517.8, ups=0.54, wpb=960.6, bsz=32, num_updates=50510, lr=8.90609e-07, gnorm=19.631, clip=100, loss_scale=32, train_wall=19, gb_free=11.5, wall=94967
2023-05-27 01:46:11 - progress_bar.py[line:272] - INFO: epoch 030:    378 / 1732 loss=2.183, loss_v1=0, loss_v2=0, nll_loss=0.961, ntokens=1043.2, nsentences=32, sample_size=1043.2, sample_size_v1=0, sample_size_v2=0, ppl=1.95, wps=561.8, ups=0.54, wpb=1043.2, bsz=32, num_updates=50520, lr=8.84467e-07, gnorm=19.942, clip=100, loss_scale=32, train_wall=19, gb_free=11.8, wall=94986
2023-05-27 01:46:30 - progress_bar.py[line:272] - INFO: epoch 030:    388 / 1732 loss=2.162, loss_v1=0, loss_v2=0, nll_loss=0.937, ntokens=1053.2, nsentences=32, sample_size=1053.2, sample_size_v1=0, sample_size_v2=0, ppl=1.91, wps=565.3, ups=0.54, wpb=1053.2, bsz=32, num_updates=50530, lr=8.78324e-07, gnorm=18.149, clip=100, loss_scale=32, train_wall=19, gb_free=11.1, wall=95005
2023-05-27 01:46:49 - progress_bar.py[line:272] - INFO: epoch 030:    398 / 1732 loss=2.162, loss_v1=0, loss_v2=0, nll_loss=0.937, ntokens=977.4, nsentences=32, sample_size=977.4, sample_size_v1=0, sample_size_v2=0, ppl=1.92, wps=527.4, ups=0.54, wpb=977.4, bsz=32, num_updates=50540, lr=8.72182e-07, gnorm=20.65, clip=100, loss_scale=32, train_wall=19, gb_free=10.9, wall=95023
2023-05-27 01:47:07 - progress_bar.py[line:272] - INFO: epoch 030:    408 / 1732 loss=2.152, loss_v1=0, loss_v2=0, nll_loss=0.926, ntokens=1058.6, nsentences=32, sample_size=1058.6, sample_size_v1=0, sample_size_v2=0, ppl=1.9, wps=567.8, ups=0.54, wpb=1058.6, bsz=32, num_updates=50550, lr=8.6604e-07, gnorm=18.534, clip=100, loss_scale=32, train_wall=19, gb_free=11.5, wall=95042
2023-05-27 01:47:26 - progress_bar.py[line:272] - INFO: epoch 030:    418 / 1732 loss=2.105, loss_v1=0, loss_v2=0, nll_loss=0.872, ntokens=1021.6, nsentences=32, sample_size=1021.6, sample_size_v1=0, sample_size_v2=0, ppl=1.83, wps=547.1, ups=0.54, wpb=1021.6, bsz=32, num_updates=50560, lr=8.59898e-07, gnorm=19.584, clip=100, loss_scale=32, train_wall=19, gb_free=11, wall=95061
2023-05-27 01:47:28 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2023-05-27 01:47:46 - progress_bar.py[line:272] - INFO: epoch 030:    429 / 1732 loss=2.118, loss_v1=0, loss_v2=0, nll_loss=0.888, ntokens=1011.5, nsentences=32, sample_size=1011.5, sample_size_v1=0, sample_size_v2=0, ppl=1.85, wps=494.5, ups=0.49, wpb=1011.5, bsz=32, num_updates=50570, lr=8.53756e-07, gnorm=20.886, clip=100, loss_scale=16, train_wall=20, gb_free=11.6, wall=95081
2023-05-27 01:48:05 - progress_bar.py[line:272] - INFO: epoch 030:    439 / 1732 loss=2.156, loss_v1=0, loss_v2=0, nll_loss=0.931, ntokens=1024.1, nsentences=32, sample_size=1024.1, sample_size_v1=0, sample_size_v2=0, ppl=1.91, wps=550.7, ups=0.54, wpb=1024.1, bsz=32, num_updates=50580, lr=8.47614e-07, gnorm=20.127, clip=100, loss_scale=16, train_wall=19, gb_free=10.8, wall=95100
2023-05-27 01:48:24 - progress_bar.py[line:272] - INFO: epoch 030:    449 / 1732 loss=2.149, loss_v1=0, loss_v2=0, nll_loss=0.922, ntokens=917.8, nsentences=32, sample_size=917.8, sample_size_v1=0, sample_size_v2=0, ppl=1.89, wps=493.5, ups=0.54, wpb=917.8, bsz=32, num_updates=50590, lr=8.41472e-07, gnorm=19.448, clip=100, loss_scale=16, train_wall=19, gb_free=11.3, wall=95118
2023-05-27 01:48:42 - progress_bar.py[line:272] - INFO: epoch 030:    459 / 1732 loss=2.157, loss_v1=0, loss_v2=0, nll_loss=0.932, ntokens=1003.6, nsentences=32, sample_size=1003.6, sample_size_v1=0, sample_size_v2=0, ppl=1.91, wps=541.2, ups=0.54, wpb=1003.6, bsz=32, num_updates=50600, lr=8.3533e-07, gnorm=18.716, clip=100, loss_scale=16, train_wall=19, gb_free=11.6, wall=95137
2023-05-27 01:49:01 - progress_bar.py[line:272] - INFO: epoch 030:    469 / 1732 loss=2.168, loss_v1=0, loss_v2=0, nll_loss=0.943, ntokens=1054.5, nsentences=32, sample_size=1054.5, sample_size_v1=0, sample_size_v2=0, ppl=1.92, wps=562.3, ups=0.53, wpb=1054.5, bsz=32, num_updates=50610, lr=8.29187e-07, gnorm=19.277, clip=100, loss_scale=16, train_wall=19, gb_free=10.6, wall=95155
2023-05-27 01:49:19 - progress_bar.py[line:272] - INFO: epoch 030:    479 / 1732 loss=2.187, loss_v1=0, loss_v2=0, nll_loss=0.966, ntokens=1034.5, nsentences=32, sample_size=1034.5, sample_size_v1=0, sample_size_v2=0, ppl=1.95, wps=556.1, ups=0.54, wpb=1034.5, bsz=32, num_updates=50620, lr=8.23045e-07, gnorm=20.815, clip=100, loss_scale=16, train_wall=19, gb_free=11.6, wall=95174
2023-05-27 01:49:38 - progress_bar.py[line:272] - INFO: epoch 030:    489 / 1732 loss=2.131, loss_v1=0, loss_v2=0, nll_loss=0.902, ntokens=912, nsentences=32, sample_size=912, sample_size_v1=0, sample_size_v2=0, ppl=1.87, wps=492.3, ups=0.54, wpb=912, bsz=32, num_updates=50630, lr=8.16903e-07, gnorm=20.214, clip=100, loss_scale=16, train_wall=18, gb_free=11.6, wall=95193
2023-05-27 01:49:56 - progress_bar.py[line:272] - INFO: epoch 030:    499 / 1732 loss=2.142, loss_v1=0, loss_v2=0, nll_loss=0.915, ntokens=957.3, nsentences=32, sample_size=957.3, sample_size_v1=0, sample_size_v2=0, ppl=1.88, wps=518, ups=0.54, wpb=957.3, bsz=32, num_updates=50640, lr=8.10761e-07, gnorm=21.631, clip=100, loss_scale=16, train_wall=18, gb_free=11.4, wall=95211
2023-05-27 01:50:15 - progress_bar.py[line:272] - INFO: epoch 030:    509 / 1732 loss=2.178, loss_v1=0, loss_v2=0, nll_loss=0.954, ntokens=1025.1, nsentences=32, sample_size=1025.1, sample_size_v1=0, sample_size_v2=0, ppl=1.94, wps=553, ups=0.54, wpb=1025.1, bsz=32, num_updates=50650, lr=8.04619e-07, gnorm=20.128, clip=100, loss_scale=16, train_wall=19, gb_free=11.7, wall=95230
2023-05-27 01:50:33 - progress_bar.py[line:272] - INFO: epoch 030:    519 / 1732 loss=2.144, loss_v1=0, loss_v2=0, nll_loss=0.917, ntokens=1029.2, nsentences=32, sample_size=1029.2, sample_size_v1=0, sample_size_v2=0, ppl=1.89, wps=556.6, ups=0.54, wpb=1029.2, bsz=32, num_updates=50660, lr=7.98477e-07, gnorm=18.18, clip=100, loss_scale=16, train_wall=18, gb_free=11.9, wall=95248
2023-05-27 01:50:52 - progress_bar.py[line:272] - INFO: epoch 030:    529 / 1732 loss=2.168, loss_v1=0, loss_v2=0, nll_loss=0.944, ntokens=945, nsentences=32, sample_size=945, sample_size_v1=0, sample_size_v2=0, ppl=1.92, wps=512.6, ups=0.54, wpb=945, bsz=32, num_updates=50670, lr=7.92335e-07, gnorm=22.235, clip=100, loss_scale=16, train_wall=18, gb_free=11.5, wall=95267
2023-05-27 01:51:10 - progress_bar.py[line:272] - INFO: epoch 030:    539 / 1732 loss=2.149, loss_v1=0, loss_v2=0, nll_loss=0.921, ntokens=990.9, nsentences=32, sample_size=990.9, sample_size_v1=0, sample_size_v2=0, ppl=1.89, wps=535.3, ups=0.54, wpb=990.9, bsz=32, num_updates=50680, lr=7.86192e-07, gnorm=19.127, clip=100, loss_scale=16, train_wall=18, gb_free=11.4, wall=95285
2023-05-27 01:51:29 - progress_bar.py[line:272] - INFO: epoch 030:    549 / 1732 loss=2.177, loss_v1=0, loss_v2=0, nll_loss=0.955, ntokens=1038.3, nsentences=32, sample_size=1038.3, sample_size_v1=0, sample_size_v2=0, ppl=1.94, wps=559.2, ups=0.54, wpb=1038.3, bsz=32, num_updates=50690, lr=7.8005e-07, gnorm=18.69, clip=100, loss_scale=16, train_wall=19, gb_free=11.5, wall=95304
2023-05-27 01:51:48 - progress_bar.py[line:272] - INFO: epoch 030:    559 / 1732 loss=2.171, loss_v1=0, loss_v2=0, nll_loss=0.947, ntokens=1016.1, nsentences=32, sample_size=1016.1, sample_size_v1=0, sample_size_v2=0, ppl=1.93, wps=546.2, ups=0.54, wpb=1016.1, bsz=32, num_updates=50700, lr=7.73908e-07, gnorm=20.183, clip=100, loss_scale=16, train_wall=19, gb_free=11, wall=95322
2023-05-27 01:52:06 - progress_bar.py[line:272] - INFO: epoch 030:    569 / 1732 loss=2.198, loss_v1=0, loss_v2=0, nll_loss=0.976, ntokens=1004.9, nsentences=32, sample_size=1004.9, sample_size_v1=0, sample_size_v2=0, ppl=1.97, wps=538, ups=0.54, wpb=1004.9, bsz=32, num_updates=50710, lr=7.67766e-07, gnorm=20.486, clip=100, loss_scale=16, train_wall=19, gb_free=11.2, wall=95341
2023-05-27 01:52:25 - progress_bar.py[line:272] - INFO: epoch 030:    579 / 1732 loss=2.153, loss_v1=0, loss_v2=0, nll_loss=0.927, ntokens=1003.1, nsentences=32, sample_size=1003.1, sample_size_v1=0, sample_size_v2=0, ppl=1.9, wps=537.3, ups=0.54, wpb=1003.1, bsz=32, num_updates=50720, lr=7.61624e-07, gnorm=19.288, clip=100, loss_scale=16, train_wall=19, gb_free=11, wall=95360
2023-05-27 01:52:44 - progress_bar.py[line:272] - INFO: epoch 030:    589 / 1732 loss=2.161, loss_v1=0, loss_v2=0, nll_loss=0.936, ntokens=951.2, nsentences=32, sample_size=951.2, sample_size_v1=0, sample_size_v2=0, ppl=1.91, wps=510.6, ups=0.54, wpb=951.2, bsz=32, num_updates=50730, lr=7.55482e-07, gnorm=21.719, clip=100, loss_scale=16, train_wall=19, gb_free=10.7, wall=95378
2023-05-27 01:53:02 - progress_bar.py[line:272] - INFO: epoch 030:    599 / 1732 loss=2.113, loss_v1=0, loss_v2=0, nll_loss=0.881, ntokens=935, nsentences=32, sample_size=935, sample_size_v1=0, sample_size_v2=0, ppl=1.84, wps=504.7, ups=0.54, wpb=935, bsz=32, num_updates=50740, lr=7.4934e-07, gnorm=18.909, clip=100, loss_scale=16, train_wall=18, gb_free=12.1, wall=95397
2023-05-27 01:53:21 - progress_bar.py[line:272] - INFO: epoch 030:    609 / 1732 loss=2.157, loss_v1=0, loss_v2=0, nll_loss=0.931, ntokens=917.6, nsentences=32, sample_size=917.6, sample_size_v1=0, sample_size_v2=0, ppl=1.91, wps=496, ups=0.54, wpb=917.6, bsz=32, num_updates=50750, lr=7.43198e-07, gnorm=20.43, clip=100, loss_scale=16, train_wall=18, gb_free=10.5, wall=95415
2023-05-27 01:53:39 - progress_bar.py[line:272] - INFO: epoch 030:    619 / 1732 loss=2.173, loss_v1=0, loss_v2=0, nll_loss=0.949, ntokens=845.1, nsentences=32, sample_size=845.1, sample_size_v1=0, sample_size_v2=0, ppl=1.93, wps=459.9, ups=0.54, wpb=845.1, bsz=32, num_updates=50760, lr=7.37055e-07, gnorm=22.541, clip=100, loss_scale=16, train_wall=18, gb_free=11.7, wall=95434
2023-05-27 01:53:57 - progress_bar.py[line:272] - INFO: epoch 030:    629 / 1732 loss=2.136, loss_v1=0, loss_v2=0, nll_loss=0.907, ntokens=934.9, nsentences=32, sample_size=934.9, sample_size_v1=0, sample_size_v2=0, ppl=1.88, wps=507.7, ups=0.54, wpb=934.9, bsz=32, num_updates=50770, lr=7.30913e-07, gnorm=20.557, clip=100, loss_scale=16, train_wall=18, gb_free=11.9, wall=95452
2023-05-27 01:54:16 - progress_bar.py[line:272] - INFO: epoch 030:    639 / 1732 loss=2.172, loss_v1=0, loss_v2=0, nll_loss=0.95, ntokens=925.6, nsentences=32, sample_size=925.6, sample_size_v1=0, sample_size_v2=0, ppl=1.93, wps=500.5, ups=0.54, wpb=925.6, bsz=32, num_updates=50780, lr=7.24771e-07, gnorm=21.357, clip=100, loss_scale=16, train_wall=18, gb_free=11.4, wall=95471
2023-05-27 01:54:34 - progress_bar.py[line:272] - INFO: epoch 030:    649 / 1732 loss=2.15, loss_v1=0, loss_v2=0, nll_loss=0.923, ntokens=987, nsentences=32, sample_size=987, sample_size_v1=0, sample_size_v2=0, ppl=1.9, wps=535.3, ups=0.54, wpb=987, bsz=32, num_updates=50790, lr=7.18629e-07, gnorm=20.248, clip=100, loss_scale=16, train_wall=18, gb_free=11.4, wall=95489
2023-05-27 01:54:53 - progress_bar.py[line:272] - INFO: epoch 030:    659 / 1732 loss=2.153, loss_v1=0, loss_v2=0, nll_loss=0.928, ntokens=871.8, nsentences=32, sample_size=871.8, sample_size_v1=0, sample_size_v2=0, ppl=1.9, wps=476.6, ups=0.55, wpb=871.8, bsz=32, num_updates=50800, lr=7.12487e-07, gnorm=21.495, clip=100, loss_scale=16, train_wall=18, gb_free=12.1, wall=95507
2023-05-27 01:55:11 - progress_bar.py[line:272] - INFO: epoch 030:    669 / 1732 loss=2.16, loss_v1=0, loss_v2=0, nll_loss=0.936, ntokens=918, nsentences=32, sample_size=918, sample_size_v1=0, sample_size_v2=0, ppl=1.91, wps=495.6, ups=0.54, wpb=918, bsz=32, num_updates=50810, lr=7.06345e-07, gnorm=20.725, clip=100, loss_scale=16, train_wall=18, gb_free=11.4, wall=95526
2023-05-27 01:55:30 - progress_bar.py[line:272] - INFO: epoch 030:    679 / 1732 loss=2.183, loss_v1=0, loss_v2=0, nll_loss=0.961, ntokens=982.1, nsentences=32, sample_size=982.1, sample_size_v1=0, sample_size_v2=0, ppl=1.95, wps=530.8, ups=0.54, wpb=982.1, bsz=32, num_updates=50820, lr=7.00203e-07, gnorm=21.247, clip=100, loss_scale=16, train_wall=18, gb_free=11.8, wall=95544
2023-05-27 01:55:48 - progress_bar.py[line:272] - INFO: epoch 030:    689 / 1732 loss=2.162, loss_v1=0, loss_v2=0, nll_loss=0.937, ntokens=949.7, nsentences=32, sample_size=949.7, sample_size_v1=0, sample_size_v2=0, ppl=1.91, wps=513.7, ups=0.54, wpb=949.7, bsz=32, num_updates=50830, lr=6.94061e-07, gnorm=19.817, clip=100, loss_scale=16, train_wall=18, gb_free=10.7, wall=95563
2023-05-27 01:56:07 - progress_bar.py[line:272] - INFO: epoch 030:    699 / 1732 loss=2.146, loss_v1=0, loss_v2=0, nll_loss=0.919, ntokens=981.3, nsentences=32, sample_size=981.3, sample_size_v1=0, sample_size_v2=0, ppl=1.89, wps=525.8, ups=0.54, wpb=981.3, bsz=32, num_updates=50840, lr=6.87918e-07, gnorm=19.985, clip=100, loss_scale=16, train_wall=19, gb_free=11.6, wall=95582
2023-05-27 01:56:25 - progress_bar.py[line:272] - INFO: epoch 030:    709 / 1732 loss=2.135, loss_v1=0, loss_v2=0, nll_loss=0.907, ntokens=928.2, nsentences=32, sample_size=928.2, sample_size_v1=0, sample_size_v2=0, ppl=1.88, wps=504.2, ups=0.54, wpb=928.2, bsz=32, num_updates=50850, lr=6.81776e-07, gnorm=19.585, clip=100, loss_scale=16, train_wall=18, gb_free=11.1, wall=95600
2023-05-27 01:56:44 - progress_bar.py[line:272] - INFO: epoch 030:    719 / 1732 loss=2.138, loss_v1=0, loss_v2=0, nll_loss=0.91, ntokens=863.5, nsentences=32, sample_size=863.5, sample_size_v1=0, sample_size_v2=0, ppl=1.88, wps=470.1, ups=0.54, wpb=863.5, bsz=32, num_updates=50860, lr=6.75634e-07, gnorm=21.499, clip=100, loss_scale=16, train_wall=18, gb_free=12, wall=95618
2023-05-27 01:57:02 - progress_bar.py[line:272] - INFO: epoch 030:    729 / 1732 loss=2.127, loss_v1=0, loss_v2=0, nll_loss=0.898, ntokens=920.7, nsentences=32, sample_size=920.7, sample_size_v1=0, sample_size_v2=0, ppl=1.86, wps=497.5, ups=0.54, wpb=920.7, bsz=32, num_updates=50870, lr=6.69492e-07, gnorm=20.585, clip=100, loss_scale=16, train_wall=18, gb_free=11.8, wall=95637
2023-05-27 01:57:21 - progress_bar.py[line:272] - INFO: epoch 030:    739 / 1732 loss=2.142, loss_v1=0, loss_v2=0, nll_loss=0.913, ntokens=1016.5, nsentences=32, sample_size=1016.5, sample_size_v1=0, sample_size_v2=0, ppl=1.88, wps=551.1, ups=0.54, wpb=1016.5, bsz=32, num_updates=50880, lr=6.6335e-07, gnorm=19.93, clip=100, loss_scale=16, train_wall=18, gb_free=11.5, wall=95655
2023-05-27 01:57:39 - progress_bar.py[line:272] - INFO: epoch 030:    749 / 1732 loss=2.134, loss_v1=0, loss_v2=0, nll_loss=0.904, ntokens=964.9, nsentences=32, sample_size=964.9, sample_size_v1=0, sample_size_v2=0, ppl=1.87, wps=518.3, ups=0.54, wpb=964.9, bsz=32, num_updates=50890, lr=6.57208e-07, gnorm=18.934, clip=100, loss_scale=16, train_wall=19, gb_free=11.6, wall=95674
2023-05-27 01:57:58 - progress_bar.py[line:272] - INFO: epoch 030:    759 / 1732 loss=2.124, loss_v1=0, loss_v2=0, nll_loss=0.893, ntokens=966.4, nsentences=32, sample_size=966.4, sample_size_v1=0, sample_size_v2=0, ppl=1.86, wps=522.9, ups=0.54, wpb=966.4, bsz=32, num_updates=50900, lr=6.51066e-07, gnorm=18.264, clip=100, loss_scale=16, train_wall=18, gb_free=11.5, wall=95692
2023-05-27 01:58:16 - progress_bar.py[line:272] - INFO: epoch 030:    769 / 1732 loss=2.155, loss_v1=0, loss_v2=0, nll_loss=0.929, ntokens=931.4, nsentences=32, sample_size=931.4, sample_size_v1=0, sample_size_v2=0, ppl=1.9, wps=504, ups=0.54, wpb=931.4, bsz=32, num_updates=50910, lr=6.44924e-07, gnorm=19.19, clip=100, loss_scale=16, train_wall=18, gb_free=11.9, wall=95711
2023-05-27 01:58:35 - progress_bar.py[line:272] - INFO: epoch 030:    779 / 1732 loss=2.145, loss_v1=0, loss_v2=0, nll_loss=0.917, ntokens=1031.1, nsentences=32, sample_size=1031.1, sample_size_v1=0, sample_size_v2=0, ppl=1.89, wps=556.3, ups=0.54, wpb=1031.1, bsz=32, num_updates=50920, lr=6.38781e-07, gnorm=18.279, clip=100, loss_scale=16, train_wall=19, gb_free=11.3, wall=95729
2023-05-27 01:58:53 - progress_bar.py[line:272] - INFO: epoch 030:    789 / 1732 loss=2.152, loss_v1=0, loss_v2=0, nll_loss=0.926, ntokens=1004.1, nsentences=32, sample_size=1004.1, sample_size_v1=0, sample_size_v2=0, ppl=1.9, wps=543.2, ups=0.54, wpb=1004.1, bsz=32, num_updates=50930, lr=6.32639e-07, gnorm=20.623, clip=100, loss_scale=16, train_wall=18, gb_free=11.9, wall=95748
2023-05-27 01:59:12 - progress_bar.py[line:272] - INFO: epoch 030:    799 / 1732 loss=2.166, loss_v1=0, loss_v2=0, nll_loss=0.942, ntokens=1038.9, nsentences=32, sample_size=1038.9, sample_size_v1=0, sample_size_v2=0, ppl=1.92, wps=560.9, ups=0.54, wpb=1038.9, bsz=32, num_updates=50940, lr=6.26497e-07, gnorm=18.668, clip=100, loss_scale=16, train_wall=18, gb_free=11.4, wall=95766
2023-05-27 01:59:30 - progress_bar.py[line:272] - INFO: epoch 030:    809 / 1732 loss=2.154, loss_v1=0, loss_v2=0, nll_loss=0.926, ntokens=922.8, nsentences=32, sample_size=922.8, sample_size_v1=0, sample_size_v2=0, ppl=1.9, wps=499.9, ups=0.54, wpb=922.8, bsz=32, num_updates=50950, lr=6.20355e-07, gnorm=20.766, clip=100, loss_scale=16, train_wall=18, gb_free=11.7, wall=95785
2023-05-27 01:59:49 - progress_bar.py[line:272] - INFO: epoch 030:    819 / 1732 loss=2.157, loss_v1=0, loss_v2=0, nll_loss=0.931, ntokens=909.6, nsentences=32, sample_size=909.6, sample_size_v1=0, sample_size_v2=0, ppl=1.91, wps=491.4, ups=0.54, wpb=909.6, bsz=32, num_updates=50960, lr=6.14213e-07, gnorm=21.857, clip=100, loss_scale=16, train_wall=18, gb_free=11.8, wall=95803
2023-05-27 02:00:07 - progress_bar.py[line:272] - INFO: epoch 030:    829 / 1732 loss=2.133, loss_v1=0, loss_v2=0, nll_loss=0.903, ntokens=917.4, nsentences=32, sample_size=917.4, sample_size_v1=0, sample_size_v2=0, ppl=1.87, wps=496, ups=0.54, wpb=917.4, bsz=32, num_updates=50970, lr=6.08071e-07, gnorm=19.818, clip=100, loss_scale=16, train_wall=18, gb_free=11.8, wall=95822
2023-05-27 02:00:26 - progress_bar.py[line:272] - INFO: epoch 030:    839 / 1732 loss=2.156, loss_v1=0, loss_v2=0, nll_loss=0.93, ntokens=902.5, nsentences=32, sample_size=902.5, sample_size_v1=0, sample_size_v2=0, ppl=1.91, wps=492, ups=0.55, wpb=902.5, bsz=32, num_updates=50980, lr=6.01929e-07, gnorm=20.359, clip=100, loss_scale=16, train_wall=18, gb_free=11.8, wall=95840
2023-05-27 02:00:44 - progress_bar.py[line:272] - INFO: epoch 030:    849 / 1732 loss=2.155, loss_v1=0, loss_v2=0, nll_loss=0.93, ntokens=1036.8, nsentences=32, sample_size=1036.8, sample_size_v1=0, sample_size_v2=0, ppl=1.91, wps=559.5, ups=0.54, wpb=1036.8, bsz=32, num_updates=50990, lr=5.95786e-07, gnorm=20.042, clip=100, loss_scale=16, train_wall=18, gb_free=11.4, wall=95859
2023-05-27 02:01:03 - progress_bar.py[line:272] - INFO: epoch 030:    859 / 1732 loss=2.124, loss_v1=0, loss_v2=0, nll_loss=0.893, ntokens=930.3, nsentences=32, sample_size=930.3, sample_size_v1=0, sample_size_v2=0, ppl=1.86, wps=505.3, ups=0.54, wpb=930.3, bsz=32, num_updates=51000, lr=5.89644e-07, gnorm=19.747, clip=100, loss_scale=16, train_wall=18, gb_free=11.4, wall=95877
2023-05-27 02:01:21 - progress_bar.py[line:272] - INFO: epoch 030:    869 / 1732 loss=2.157, loss_v1=0, loss_v2=0, nll_loss=0.931, ntokens=962.2, nsentences=32, sample_size=962.2, sample_size_v1=0, sample_size_v2=0, ppl=1.91, wps=520.5, ups=0.54, wpb=962.2, bsz=32, num_updates=51010, lr=5.83502e-07, gnorm=20.289, clip=100, loss_scale=16, train_wall=18, gb_free=11.6, wall=95896
2023-05-27 02:01:40 - progress_bar.py[line:272] - INFO: epoch 030:    879 / 1732 loss=2.092, loss_v1=0, loss_v2=0, nll_loss=0.858, ntokens=1001.9, nsentences=32, sample_size=1001.9, sample_size_v1=0, sample_size_v2=0, ppl=1.81, wps=539.6, ups=0.54, wpb=1001.9, bsz=32, num_updates=51020, lr=5.7736e-07, gnorm=18.128, clip=100, loss_scale=16, train_wall=19, gb_free=11.7, wall=95914
2023-05-27 02:01:58 - progress_bar.py[line:272] - INFO: epoch 030:    889 / 1732 loss=2.083, loss_v1=0, loss_v2=0, nll_loss=0.848, ntokens=975.7, nsentences=32, sample_size=975.7, sample_size_v1=0, sample_size_v2=0, ppl=1.8, wps=525.4, ups=0.54, wpb=975.7, bsz=32, num_updates=51030, lr=5.71218e-07, gnorm=17.947, clip=100, loss_scale=16, train_wall=19, gb_free=11.6, wall=95933
2023-05-27 02:02:17 - progress_bar.py[line:272] - INFO: epoch 030:    899 / 1732 loss=2.095, loss_v1=0, loss_v2=0, nll_loss=0.862, ntokens=1055.9, nsentences=32, sample_size=1055.9, sample_size_v1=0, sample_size_v2=0, ppl=1.82, wps=567.8, ups=0.54, wpb=1055.9, bsz=32, num_updates=51040, lr=5.65076e-07, gnorm=19.7, clip=100, loss_scale=16, train_wall=19, gb_free=11.1, wall=95951
2023-05-27 02:02:35 - progress_bar.py[line:272] - INFO: epoch 030:    909 / 1732 loss=2.123, loss_v1=0, loss_v2=0, nll_loss=0.893, ntokens=975.2, nsentences=32, sample_size=975.2, sample_size_v1=0, sample_size_v2=0, ppl=1.86, wps=527.4, ups=0.54, wpb=975.2, bsz=32, num_updates=51050, lr=5.58934e-07, gnorm=19.243, clip=100, loss_scale=16, train_wall=18, gb_free=11.8, wall=95970
2023-05-27 02:02:54 - progress_bar.py[line:272] - INFO: epoch 030:    919 / 1732 loss=2.159, loss_v1=0, loss_v2=0, nll_loss=0.934, ntokens=988.7, nsentences=32, sample_size=988.7, sample_size_v1=0, sample_size_v2=0, ppl=1.91, wps=532.2, ups=0.54, wpb=988.7, bsz=32, num_updates=51060, lr=5.52792e-07, gnorm=19.36, clip=100, loss_scale=16, train_wall=19, gb_free=11, wall=95988
2023-05-27 02:03:12 - progress_bar.py[line:272] - INFO: epoch 030:    929 / 1732 loss=2.118, loss_v1=0, loss_v2=0, nll_loss=0.887, ntokens=1019.8, nsentences=32, sample_size=1019.8, sample_size_v1=0, sample_size_v2=0, ppl=1.85, wps=546.7, ups=0.54, wpb=1019.8, bsz=32, num_updates=51070, lr=5.46649e-07, gnorm=18.683, clip=100, loss_scale=16, train_wall=19, gb_free=10.9, wall=96007
2023-05-27 02:03:31 - progress_bar.py[line:272] - INFO: epoch 030:    939 / 1732 loss=2.151, loss_v1=0, loss_v2=0, nll_loss=0.925, ntokens=1047.7, nsentences=32, sample_size=1047.7, sample_size_v1=0, sample_size_v2=0, ppl=1.9, wps=556.2, ups=0.53, wpb=1047.7, bsz=32, num_updates=51080, lr=5.40507e-07, gnorm=20.61, clip=100, loss_scale=32, train_wall=19, gb_free=11.2, wall=96026
2023-05-27 02:03:50 - progress_bar.py[line:272] - INFO: epoch 030:    949 / 1732 loss=2.147, loss_v1=0, loss_v2=0, nll_loss=0.921, ntokens=1037.9, nsentences=32, sample_size=1037.9, sample_size_v1=0, sample_size_v2=0, ppl=1.89, wps=552.8, ups=0.53, wpb=1037.9, bsz=32, num_updates=51090, lr=5.34365e-07, gnorm=20.6, clip=100, loss_scale=32, train_wall=19, gb_free=11.3, wall=96045
2023-05-27 02:04:09 - progress_bar.py[line:272] - INFO: epoch 030:    959 / 1732 loss=2.135, loss_v1=0, loss_v2=0, nll_loss=0.906, ntokens=1070.6, nsentences=32, sample_size=1070.6, sample_size_v1=0, sample_size_v2=0, ppl=1.87, wps=570.4, ups=0.53, wpb=1070.6, bsz=32, num_updates=51100, lr=5.28223e-07, gnorm=17.278, clip=100, loss_scale=32, train_wall=19, gb_free=11.2, wall=96064
2023-05-27 02:04:28 - progress_bar.py[line:272] - INFO: epoch 030:    969 / 1732 loss=2.17, loss_v1=0, loss_v2=0, nll_loss=0.947, ntokens=1025.9, nsentences=32, sample_size=1025.9, sample_size_v1=0, sample_size_v2=0, ppl=1.93, wps=547.5, ups=0.53, wpb=1025.9, bsz=32, num_updates=51110, lr=5.22081e-07, gnorm=20.618, clip=100, loss_scale=32, train_wall=19, gb_free=11.3, wall=96082
2023-05-27 02:04:46 - progress_bar.py[line:272] - INFO: epoch 030:    979 / 1732 loss=2.118, loss_v1=0, loss_v2=0, nll_loss=0.887, ntokens=1025.3, nsentences=32, sample_size=1025.3, sample_size_v1=0, sample_size_v2=0, ppl=1.85, wps=543.5, ups=0.53, wpb=1025.3, bsz=32, num_updates=51120, lr=5.15939e-07, gnorm=18.704, clip=100, loss_scale=32, train_wall=19, gb_free=11, wall=96101
2023-05-27 02:05:05 - progress_bar.py[line:272] - INFO: epoch 030:    989 / 1732 loss=2.137, loss_v1=0, loss_v2=0, nll_loss=0.909, ntokens=1057.2, nsentences=32, sample_size=1057.2, sample_size_v1=0, sample_size_v2=0, ppl=1.88, wps=559.2, ups=0.53, wpb=1057.2, bsz=32, num_updates=51130, lr=5.09797e-07, gnorm=17.72, clip=100, loss_scale=32, train_wall=19, gb_free=11.1, wall=96120
2023-05-27 02:05:24 - progress_bar.py[line:272] - INFO: epoch 030:    999 / 1732 loss=2.137, loss_v1=0, loss_v2=0, nll_loss=0.909, ntokens=989.7, nsentences=32, sample_size=989.7, sample_size_v1=0, sample_size_v2=0, ppl=1.88, wps=530.8, ups=0.54, wpb=989.7, bsz=32, num_updates=51140, lr=5.03655e-07, gnorm=19.442, clip=100, loss_scale=32, train_wall=19, gb_free=11.8, wall=96139
2023-05-27 02:05:43 - progress_bar.py[line:272] - INFO: epoch 030:   1009 / 1732 loss=2.138, loss_v1=0, loss_v2=0, nll_loss=0.91, ntokens=1040.9, nsentences=32, sample_size=1040.9, sample_size_v1=0, sample_size_v2=0, ppl=1.88, wps=555.7, ups=0.53, wpb=1040.9, bsz=32, num_updates=51150, lr=4.97512e-07, gnorm=19.251, clip=100, loss_scale=32, train_wall=19, gb_free=10.8, wall=96157
2023-05-27 02:06:01 - progress_bar.py[line:272] - INFO: epoch 030:   1019 / 1732 loss=2.113, loss_v1=0, loss_v2=0, nll_loss=0.882, ntokens=1021.6, nsentences=32, sample_size=1021.6, sample_size_v1=0, sample_size_v2=0, ppl=1.84, wps=548.3, ups=0.54, wpb=1021.6, bsz=32, num_updates=51160, lr=4.9137e-07, gnorm=18.946, clip=100, loss_scale=32, train_wall=19, gb_free=11.3, wall=96176
2023-05-27 02:06:21 - progress_bar.py[line:272] - INFO: epoch 030:   1029 / 1732 loss=2.134, loss_v1=0, loss_v2=0, nll_loss=0.905, ntokens=1092, nsentences=32, sample_size=1092, sample_size_v1=0, sample_size_v2=0, ppl=1.87, wps=570.4, ups=0.52, wpb=1092, bsz=32, num_updates=51170, lr=4.85228e-07, gnorm=18.321, clip=100, loss_scale=32, train_wall=19, gb_free=10.6, wall=96195
2023-05-27 02:06:39 - progress_bar.py[line:272] - INFO: epoch 030:   1039 / 1732 loss=2.144, loss_v1=0, loss_v2=0, nll_loss=0.917, ntokens=1077.1, nsentences=32, sample_size=1077.1, sample_size_v1=0, sample_size_v2=0, ppl=1.89, wps=573.8, ups=0.53, wpb=1077.1, bsz=32, num_updates=51180, lr=4.79086e-07, gnorm=19.575, clip=100, loss_scale=32, train_wall=19, gb_free=10.9, wall=96214
2023-05-27 02:06:58 - progress_bar.py[line:272] - INFO: epoch 030:   1049 / 1732 loss=2.133, loss_v1=0, loss_v2=0, nll_loss=0.905, ntokens=1018.7, nsentences=32, sample_size=1018.7, sample_size_v1=0, sample_size_v2=0, ppl=1.87, wps=544.4, ups=0.53, wpb=1018.7, bsz=32, num_updates=51190, lr=4.72944e-07, gnorm=20.373, clip=100, loss_scale=32, train_wall=19, gb_free=11.5, wall=96233
2023-05-27 02:07:17 - progress_bar.py[line:272] - INFO: epoch 030:   1059 / 1732 loss=2.134, loss_v1=0, loss_v2=0, nll_loss=0.906, ntokens=1090.9, nsentences=32, sample_size=1090.9, sample_size_v1=0, sample_size_v2=0, ppl=1.87, wps=581.6, ups=0.53, wpb=1090.9, bsz=32, num_updates=51200, lr=4.66802e-07, gnorm=17.283, clip=100, loss_scale=32, train_wall=19, gb_free=11.5, wall=96251
2023-05-27 02:07:35 - progress_bar.py[line:272] - INFO: epoch 030:   1069 / 1732 loss=2.123, loss_v1=0, loss_v2=0, nll_loss=0.892, ntokens=979.2, nsentences=32, sample_size=979.2, sample_size_v1=0, sample_size_v2=0, ppl=1.86, wps=524.6, ups=0.54, wpb=979.2, bsz=32, num_updates=51210, lr=4.6066e-07, gnorm=19.376, clip=100, loss_scale=32, train_wall=19, gb_free=11.3, wall=96270
2023-05-27 02:07:54 - progress_bar.py[line:272] - INFO: epoch 030:   1079 / 1732 loss=2.148, loss_v1=0, loss_v2=0, nll_loss=0.921, ntokens=1044.7, nsentences=32, sample_size=1044.7, sample_size_v1=0, sample_size_v2=0, ppl=1.89, wps=553.3, ups=0.53, wpb=1044.7, bsz=32, num_updates=51220, lr=4.54518e-07, gnorm=19.723, clip=100, loss_scale=32, train_wall=19, gb_free=11, wall=96289
2023-05-27 02:08:13 - progress_bar.py[line:272] - INFO: epoch 030:   1089 / 1732 loss=2.125, loss_v1=0, loss_v2=0, nll_loss=0.894, ntokens=1065.4, nsentences=32, sample_size=1065.4, sample_size_v1=0, sample_size_v2=0, ppl=1.86, wps=562.9, ups=0.53, wpb=1065.4, bsz=32, num_updates=51230, lr=4.48375e-07, gnorm=17.919, clip=100, loss_scale=32, train_wall=19, gb_free=11.4, wall=96308
2023-05-27 02:08:32 - progress_bar.py[line:272] - INFO: epoch 030:   1099 / 1732 loss=2.139, loss_v1=0, loss_v2=0, nll_loss=0.911, ntokens=1034.8, nsentences=32, sample_size=1034.8, sample_size_v1=0, sample_size_v2=0, ppl=1.88, wps=552.4, ups=0.53, wpb=1034.8, bsz=32, num_updates=51240, lr=4.42233e-07, gnorm=19.849, clip=100, loss_scale=32, train_wall=19, gb_free=10.5, wall=96327
2023-05-27 02:08:51 - progress_bar.py[line:272] - INFO: epoch 030:   1109 / 1732 loss=2.133, loss_v1=0, loss_v2=0, nll_loss=0.904, ntokens=1058.4, nsentences=32, sample_size=1058.4, sample_size_v1=0, sample_size_v2=0, ppl=1.87, wps=561.1, ups=0.53, wpb=1058.4, bsz=32, num_updates=51250, lr=4.36091e-07, gnorm=18.117, clip=100, loss_scale=32, train_wall=19, gb_free=10.4, wall=96346
2023-05-27 02:09:10 - progress_bar.py[line:272] - INFO: epoch 030:   1119 / 1732 loss=2.135, loss_v1=0, loss_v2=0, nll_loss=0.906, ntokens=966, nsentences=32, sample_size=966, sample_size_v1=0, sample_size_v2=0, ppl=1.87, wps=514, ups=0.53, wpb=966, bsz=32, num_updates=51260, lr=4.29949e-07, gnorm=19.581, clip=100, loss_scale=32, train_wall=19, gb_free=10.9, wall=96364
2023-05-27 02:09:28 - progress_bar.py[line:272] - INFO: epoch 030:   1129 / 1732 loss=2.13, loss_v1=0, loss_v2=0, nll_loss=0.9, ntokens=1007.5, nsentences=32, sample_size=1007.5, sample_size_v1=0, sample_size_v2=0, ppl=1.87, wps=536.3, ups=0.53, wpb=1007.5, bsz=32, num_updates=51270, lr=4.23807e-07, gnorm=19.17, clip=100, loss_scale=32, train_wall=19, gb_free=11.4, wall=96383
2023-05-27 02:09:47 - progress_bar.py[line:272] - INFO: epoch 030:   1139 / 1732 loss=2.126, loss_v1=0, loss_v2=0, nll_loss=0.896, ntokens=999.7, nsentences=32, sample_size=999.7, sample_size_v1=0, sample_size_v2=0, ppl=1.86, wps=534.1, ups=0.53, wpb=999.7, bsz=32, num_updates=51280, lr=4.17665e-07, gnorm=19.355, clip=100, loss_scale=32, train_wall=19, gb_free=11.1, wall=96402
2023-05-27 02:10:06 - progress_bar.py[line:272] - INFO: epoch 030:   1149 / 1732 loss=2.106, loss_v1=0, loss_v2=0, nll_loss=0.873, ntokens=999, nsentences=32, sample_size=999, sample_size_v1=0, sample_size_v2=0, ppl=1.83, wps=533.3, ups=0.53, wpb=999, bsz=32, num_updates=51290, lr=4.11523e-07, gnorm=16.973, clip=100, loss_scale=32, train_wall=19, gb_free=11.4, wall=96421
2023-05-27 02:10:25 - progress_bar.py[line:272] - INFO: epoch 030:   1159 / 1732 loss=2.102, loss_v1=0, loss_v2=0, nll_loss=0.869, ntokens=1014.2, nsentences=32, sample_size=1014.2, sample_size_v1=0, sample_size_v2=0, ppl=1.83, wps=539.4, ups=0.53, wpb=1014.2, bsz=32, num_updates=51300, lr=4.05381e-07, gnorm=17.731, clip=100, loss_scale=32, train_wall=19, gb_free=11.5, wall=96439
2023-05-27 02:10:44 - progress_bar.py[line:272] - INFO: epoch 030:   1169 / 1732 loss=2.103, loss_v1=0, loss_v2=0, nll_loss=0.871, ntokens=1031, nsentences=32, sample_size=1031, sample_size_v1=0, sample_size_v2=0, ppl=1.83, wps=549.6, ups=0.53, wpb=1031, bsz=32, num_updates=51310, lr=3.99238e-07, gnorm=17.427, clip=100, loss_scale=32, train_wall=19, gb_free=11.1, wall=96458
2023-05-27 02:11:02 - progress_bar.py[line:272] - INFO: epoch 030:   1179 / 1732 loss=2.108, loss_v1=0, loss_v2=0, nll_loss=0.875, ntokens=1057.9, nsentences=32, sample_size=1057.9, sample_size_v1=0, sample_size_v2=0, ppl=1.83, wps=564.1, ups=0.53, wpb=1057.9, bsz=32, num_updates=51320, lr=3.93096e-07, gnorm=19.688, clip=100, loss_scale=32, train_wall=19, gb_free=11.6, wall=96477
2023-05-27 02:11:21 - progress_bar.py[line:272] - INFO: epoch 030:   1189 / 1732 loss=2.108, loss_v1=0, loss_v2=0, nll_loss=0.876, ntokens=993.6, nsentences=32, sample_size=993.6, sample_size_v1=0, sample_size_v2=0, ppl=1.84, wps=529.2, ups=0.53, wpb=993.6, bsz=32, num_updates=51330, lr=3.86954e-07, gnorm=17.698, clip=100, loss_scale=32, train_wall=19, gb_free=11, wall=96496
2023-05-27 02:11:40 - progress_bar.py[line:272] - INFO: epoch 030:   1199 / 1732 loss=2.111, loss_v1=0, loss_v2=0, nll_loss=0.878, ntokens=1103.9, nsentences=32, sample_size=1103.9, sample_size_v1=0, sample_size_v2=0, ppl=1.84, wps=585.6, ups=0.53, wpb=1103.9, bsz=32, num_updates=51340, lr=3.80812e-07, gnorm=19.389, clip=100, loss_scale=32, train_wall=19, gb_free=10.8, wall=96515
2023-05-27 02:11:59 - progress_bar.py[line:272] - INFO: epoch 030:   1209 / 1732 loss=2.105, loss_v1=0, loss_v2=0, nll_loss=0.873, ntokens=1079.5, nsentences=32, sample_size=1079.5, sample_size_v1=0, sample_size_v2=0, ppl=1.83, wps=570.5, ups=0.53, wpb=1079.5, bsz=32, num_updates=51350, lr=3.7467e-07, gnorm=17.726, clip=100, loss_scale=32, train_wall=19, gb_free=11.2, wall=96533
2023-05-27 02:12:18 - progress_bar.py[line:272] - INFO: epoch 030:   1219 / 1732 loss=2.153, loss_v1=0, loss_v2=0, nll_loss=0.926, ntokens=1009.3, nsentences=32, sample_size=1009.3, sample_size_v1=0, sample_size_v2=0, ppl=1.9, wps=540.3, ups=0.54, wpb=1009.3, bsz=32, num_updates=51360, lr=3.68528e-07, gnorm=18.814, clip=100, loss_scale=32, train_wall=19, gb_free=11.3, wall=96552
2023-05-27 02:12:36 - progress_bar.py[line:272] - INFO: epoch 030:   1229 / 1732 loss=2.121, loss_v1=0, loss_v2=0, nll_loss=0.891, ntokens=1052.5, nsentences=32, sample_size=1052.5, sample_size_v1=0, sample_size_v2=0, ppl=1.86, wps=560.6, ups=0.53, wpb=1052.5, bsz=32, num_updates=51370, lr=3.62386e-07, gnorm=17.61, clip=100, loss_scale=32, train_wall=19, gb_free=11.1, wall=96571
2023-05-27 02:12:55 - progress_bar.py[line:272] - INFO: epoch 030:   1239 / 1732 loss=2.084, loss_v1=0, loss_v2=0, nll_loss=0.849, ntokens=1065.1, nsentences=32, sample_size=1065.1, sample_size_v1=0, sample_size_v2=0, ppl=1.8, wps=565.5, ups=0.53, wpb=1065.1, bsz=32, num_updates=51380, lr=3.56243e-07, gnorm=16.255, clip=100, loss_scale=32, train_wall=19, gb_free=10.7, wall=96590
2023-05-27 02:13:14 - progress_bar.py[line:272] - INFO: epoch 030:   1249 / 1732 loss=2.086, loss_v1=0, loss_v2=0, nll_loss=0.851, ntokens=1065.4, nsentences=32, sample_size=1065.4, sample_size_v1=0, sample_size_v2=0, ppl=1.8, wps=564.8, ups=0.53, wpb=1065.4, bsz=32, num_updates=51390, lr=3.50101e-07, gnorm=19.211, clip=100, loss_scale=32, train_wall=19, gb_free=11.5, wall=96609
2023-05-27 02:13:33 - progress_bar.py[line:272] - INFO: epoch 030:   1259 / 1732 loss=2.106, loss_v1=0, loss_v2=0, nll_loss=0.874, ntokens=1045.9, nsentences=32, sample_size=1045.9, sample_size_v1=0, sample_size_v2=0, ppl=1.83, wps=556.4, ups=0.53, wpb=1045.9, bsz=32, num_updates=51400, lr=3.43959e-07, gnorm=19.436, clip=100, loss_scale=32, train_wall=19, gb_free=11.5, wall=96627
2023-05-27 02:13:52 - progress_bar.py[line:272] - INFO: epoch 030:   1269 / 1732 loss=2.114, loss_v1=0, loss_v2=0, nll_loss=0.883, ntokens=1069.2, nsentences=32, sample_size=1069.2, sample_size_v1=0, sample_size_v2=0, ppl=1.84, wps=569, ups=0.53, wpb=1069.2, bsz=32, num_updates=51410, lr=3.37817e-07, gnorm=18.08, clip=100, loss_scale=32, train_wall=19, gb_free=11.4, wall=96646
2023-05-27 02:14:10 - progress_bar.py[line:272] - INFO: epoch 030:   1279 / 1732 loss=2.098, loss_v1=0, loss_v2=0, nll_loss=0.865, ntokens=1067, nsentences=32, sample_size=1067, sample_size_v1=0, sample_size_v2=0, ppl=1.82, wps=565, ups=0.53, wpb=1067, bsz=32, num_updates=51420, lr=3.31675e-07, gnorm=16.913, clip=100, loss_scale=32, train_wall=19, gb_free=10.9, wall=96665
2023-05-27 02:14:29 - progress_bar.py[line:272] - INFO: epoch 030:   1289 / 1732 loss=2.098, loss_v1=0, loss_v2=0, nll_loss=0.864, ntokens=1071, nsentences=32, sample_size=1071, sample_size_v1=0, sample_size_v2=0, ppl=1.82, wps=565.2, ups=0.53, wpb=1071, bsz=32, num_updates=51430, lr=3.25533e-07, gnorm=17.545, clip=100, loss_scale=32, train_wall=19, gb_free=10.4, wall=96684
2023-05-27 02:14:48 - progress_bar.py[line:272] - INFO: epoch 030:   1299 / 1732 loss=2.107, loss_v1=0, loss_v2=0, nll_loss=0.875, ntokens=1078.1, nsentences=32, sample_size=1078.1, sample_size_v1=0, sample_size_v2=0, ppl=1.83, wps=573.8, ups=0.53, wpb=1078.1, bsz=32, num_updates=51440, lr=3.19391e-07, gnorm=18.203, clip=100, loss_scale=32, train_wall=19, gb_free=11.4, wall=96703
2023-05-27 02:15:07 - progress_bar.py[line:272] - INFO: epoch 030:   1309 / 1732 loss=2.152, loss_v1=0, loss_v2=0, nll_loss=0.925, ntokens=1085.2, nsentences=32, sample_size=1085.2, sample_size_v1=0, sample_size_v2=0, ppl=1.9, wps=570.6, ups=0.53, wpb=1085.2, bsz=32, num_updates=51450, lr=3.13249e-07, gnorm=18.736, clip=100, loss_scale=32, train_wall=19, gb_free=10.9, wall=96722
2023-05-27 02:15:26 - progress_bar.py[line:272] - INFO: epoch 030:   1319 / 1732 loss=2.112, loss_v1=0, loss_v2=0, nll_loss=0.88, ntokens=1092.6, nsentences=32, sample_size=1092.6, sample_size_v1=0, sample_size_v2=0, ppl=1.84, wps=579.3, ups=0.53, wpb=1092.6, bsz=32, num_updates=51460, lr=3.07106e-07, gnorm=19.172, clip=100, loss_scale=32, train_wall=19, gb_free=10.9, wall=96741
2023-05-27 02:15:45 - progress_bar.py[line:272] - INFO: epoch 030:   1329 / 1732 loss=2.091, loss_v1=0, loss_v2=0, nll_loss=0.858, ntokens=1106.3, nsentences=32, sample_size=1106.3, sample_size_v1=0, sample_size_v2=0, ppl=1.81, wps=583.3, ups=0.53, wpb=1106.3, bsz=32, num_updates=51470, lr=3.00964e-07, gnorm=17.056, clip=100, loss_scale=32, train_wall=19, gb_free=11.3, wall=96760
2023-05-27 02:16:04 - progress_bar.py[line:272] - INFO: epoch 030:   1339 / 1732 loss=2.114, loss_v1=0, loss_v2=0, nll_loss=0.883, ntokens=1120.5, nsentences=32, sample_size=1120.5, sample_size_v1=0, sample_size_v2=0, ppl=1.84, wps=593, ups=0.53, wpb=1120.5, bsz=32, num_updates=51480, lr=2.94822e-07, gnorm=18.311, clip=100, loss_scale=32, train_wall=19, gb_free=11, wall=96779
2023-05-27 02:16:23 - progress_bar.py[line:272] - INFO: epoch 030:   1349 / 1732 loss=2.116, loss_v1=0, loss_v2=0, nll_loss=0.886, ntokens=1187.2, nsentences=32, sample_size=1187.2, sample_size_v1=0, sample_size_v2=0, ppl=1.85, wps=624.9, ups=0.53, wpb=1187.2, bsz=32, num_updates=51490, lr=2.8868e-07, gnorm=16.85, clip=100, loss_scale=32, train_wall=19, gb_free=11.3, wall=96798
2023-05-27 02:16:42 - progress_bar.py[line:272] - INFO: epoch 030:   1359 / 1732 loss=2.089, loss_v1=0, loss_v2=0, nll_loss=0.854, ntokens=1104.5, nsentences=32, sample_size=1104.5, sample_size_v1=0, sample_size_v2=0, ppl=1.81, wps=583.6, ups=0.53, wpb=1104.5, bsz=32, num_updates=51500, lr=2.82538e-07, gnorm=16.679, clip=100, loss_scale=32, train_wall=19, gb_free=11.2, wall=96817
2023-05-27 02:17:01 - progress_bar.py[line:272] - INFO: epoch 030:   1369 / 1732 loss=2.13, loss_v1=0, loss_v2=0, nll_loss=0.901, ntokens=1096, nsentences=32, sample_size=1096, sample_size_v1=0, sample_size_v2=0, ppl=1.87, wps=579.5, ups=0.53, wpb=1096, bsz=32, num_updates=51510, lr=2.76396e-07, gnorm=18.402, clip=100, loss_scale=32, train_wall=19, gb_free=11.2, wall=96835
2023-05-27 02:17:20 - progress_bar.py[line:272] - INFO: epoch 030:   1379 / 1732 loss=2.15, loss_v1=0, loss_v2=0, nll_loss=0.923, ntokens=1115.7, nsentences=32, sample_size=1115.7, sample_size_v1=0, sample_size_v2=0, ppl=1.9, wps=595.8, ups=0.53, wpb=1115.7, bsz=32, num_updates=51520, lr=2.70254e-07, gnorm=16.888, clip=100, loss_scale=32, train_wall=19, gb_free=11.4, wall=96854
2023-05-27 02:17:38 - progress_bar.py[line:272] - INFO: epoch 030:   1389 / 1732 loss=2.126, loss_v1=0, loss_v2=0, nll_loss=0.896, ntokens=1122.1, nsentences=32, sample_size=1122.1, sample_size_v1=0, sample_size_v2=0, ppl=1.86, wps=598.3, ups=0.53, wpb=1122.1, bsz=32, num_updates=51530, lr=2.64112e-07, gnorm=18.571, clip=100, loss_scale=32, train_wall=19, gb_free=11.5, wall=96873
2023-05-27 02:17:57 - progress_bar.py[line:272] - INFO: epoch 030:   1399 / 1732 loss=2.097, loss_v1=0, loss_v2=0, nll_loss=0.864, ntokens=1113, nsentences=32, sample_size=1113, sample_size_v1=0, sample_size_v2=0, ppl=1.82, wps=588.8, ups=0.53, wpb=1113, bsz=32, num_updates=51540, lr=2.57969e-07, gnorm=17.528, clip=100, loss_scale=32, train_wall=19, gb_free=11.1, wall=96892
2023-05-27 02:18:16 - progress_bar.py[line:272] - INFO: epoch 030:   1409 / 1732 loss=2.15, loss_v1=0, loss_v2=0, nll_loss=0.924, ntokens=1156.6, nsentences=32, sample_size=1156.6, sample_size_v1=0, sample_size_v2=0, ppl=1.9, wps=611.6, ups=0.53, wpb=1156.6, bsz=32, num_updates=51550, lr=2.51827e-07, gnorm=19.022, clip=100, loss_scale=32, train_wall=19, gb_free=11.1, wall=96911
2023-05-27 02:18:35 - progress_bar.py[line:272] - INFO: epoch 030:   1419 / 1732 loss=2.151, loss_v1=0, loss_v2=0, nll_loss=0.925, ntokens=1290.6, nsentences=32, sample_size=1290.6, sample_size_v1=0, sample_size_v2=0, ppl=1.9, wps=674.6, ups=0.52, wpb=1290.6, bsz=32, num_updates=51560, lr=2.45685e-07, gnorm=16.085, clip=100, loss_scale=32, train_wall=19, gb_free=10.5, wall=96930
2023-05-27 02:18:54 - progress_bar.py[line:272] - INFO: epoch 030:   1429 / 1732 loss=2.112, loss_v1=0, loss_v2=0, nll_loss=0.88, ntokens=1226.2, nsentences=32, sample_size=1226.2, sample_size_v1=0, sample_size_v2=0, ppl=1.84, wps=646.4, ups=0.53, wpb=1226.2, bsz=32, num_updates=51570, lr=2.39543e-07, gnorm=16.36, clip=100, loss_scale=32, train_wall=19, gb_free=11.2, wall=96949
2023-05-27 02:19:13 - progress_bar.py[line:272] - INFO: epoch 030:   1439 / 1732 loss=2.113, loss_v1=0, loss_v2=0, nll_loss=0.882, ntokens=1192.7, nsentences=32, sample_size=1192.7, sample_size_v1=0, sample_size_v2=0, ppl=1.84, wps=628.5, ups=0.53, wpb=1192.7, bsz=32, num_updates=51580, lr=2.33401e-07, gnorm=16.271, clip=100, loss_scale=32, train_wall=19, gb_free=11, wall=96968
2023-05-27 02:19:23 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2023-05-27 02:19:34 - progress_bar.py[line:272] - INFO: epoch 030:   1450 / 1732 loss=2.116, loss_v1=0, loss_v2=0, nll_loss=0.884, ntokens=1087.9, nsentences=32, sample_size=1087.9, sample_size_v1=0, sample_size_v2=0, ppl=1.85, wps=526.6, ups=0.48, wpb=1087.9, bsz=32, num_updates=51590, lr=2.27259e-07, gnorm=16.794, clip=100, loss_scale=32, train_wall=21, gb_free=11, wall=96989
2023-05-27 02:19:53 - progress_bar.py[line:272] - INFO: epoch 030:   1460 / 1732 loss=2.125, loss_v1=0, loss_v2=0, nll_loss=0.894, ntokens=1171.4, nsentences=32, sample_size=1171.4, sample_size_v1=0, sample_size_v2=0, ppl=1.86, wps=618.7, ups=0.53, wpb=1171.4, bsz=32, num_updates=51600, lr=2.21117e-07, gnorm=18.411, clip=100, loss_scale=32, train_wall=19, gb_free=11.1, wall=97007
2023-05-27 02:20:12 - progress_bar.py[line:272] - INFO: epoch 030:   1470 / 1732 loss=2.109, loss_v1=0, loss_v2=0, nll_loss=0.877, ntokens=1176.9, nsentences=32, sample_size=1176.9, sample_size_v1=0, sample_size_v2=0, ppl=1.84, wps=619.3, ups=0.53, wpb=1176.9, bsz=32, num_updates=51610, lr=2.14975e-07, gnorm=18.796, clip=100, loss_scale=32, train_wall=19, gb_free=9.8, wall=97026
2023-05-27 02:20:31 - progress_bar.py[line:272] - INFO: epoch 030:   1480 / 1732 loss=2.134, loss_v1=0, loss_v2=0, nll_loss=0.905, ntokens=1035.6, nsentences=32, sample_size=1035.6, sample_size_v1=0, sample_size_v2=0, ppl=1.87, wps=553.7, ups=0.53, wpb=1035.6, bsz=32, num_updates=51620, lr=2.08832e-07, gnorm=19.276, clip=100, loss_scale=32, train_wall=19, gb_free=11.3, wall=97045
2023-05-27 02:20:49 - progress_bar.py[line:272] - INFO: epoch 030:   1490 / 1732 loss=2.135, loss_v1=0, loss_v2=0, nll_loss=0.907, ntokens=1129.4, nsentences=32, sample_size=1129.4, sample_size_v1=0, sample_size_v2=0, ppl=1.87, wps=596.4, ups=0.53, wpb=1129.4, bsz=32, num_updates=51630, lr=2.0269e-07, gnorm=17.568, clip=100, loss_scale=32, train_wall=19, gb_free=11.4, wall=97064
2023-05-27 02:21:08 - progress_bar.py[line:272] - INFO: epoch 030:   1500 / 1732 loss=2.11, loss_v1=0, loss_v2=0, nll_loss=0.879, ntokens=1104.6, nsentences=32, sample_size=1104.6, sample_size_v1=0, sample_size_v2=0, ppl=1.84, wps=585.4, ups=0.53, wpb=1104.6, bsz=32, num_updates=51640, lr=1.96548e-07, gnorm=18.36, clip=100, loss_scale=32, train_wall=19, gb_free=11.2, wall=97083
2023-05-27 02:21:27 - progress_bar.py[line:272] - INFO: epoch 030:   1510 / 1732 loss=2.102, loss_v1=0, loss_v2=0, nll_loss=0.869, ntokens=1117.2, nsentences=32, sample_size=1117.2, sample_size_v1=0, sample_size_v2=0, ppl=1.83, wps=594.8, ups=0.53, wpb=1117.2, bsz=32, num_updates=51650, lr=1.90406e-07, gnorm=17.03, clip=100, loss_scale=32, train_wall=19, gb_free=11, wall=97102
2023-05-27 02:21:46 - progress_bar.py[line:272] - INFO: epoch 030:   1520 / 1732 loss=2.148, loss_v1=0, loss_v2=0, nll_loss=0.921, ntokens=1039.7, nsentences=32, sample_size=1039.7, sample_size_v1=0, sample_size_v2=0, ppl=1.89, wps=553.6, ups=0.53, wpb=1039.7, bsz=32, num_updates=51660, lr=1.84264e-07, gnorm=19.421, clip=100, loss_scale=32, train_wall=19, gb_free=11.5, wall=97121
2023-05-27 02:22:05 - progress_bar.py[line:272] - INFO: epoch 030:   1530 / 1732 loss=2.154, loss_v1=0, loss_v2=0, nll_loss=0.928, ntokens=1056.8, nsentences=32, sample_size=1056.8, sample_size_v1=0, sample_size_v2=0, ppl=1.9, wps=561.4, ups=0.53, wpb=1056.8, bsz=32, num_updates=51670, lr=1.78122e-07, gnorm=18.721, clip=100, loss_scale=32, train_wall=19, gb_free=10.6, wall=97139
2023-05-27 02:22:24 - progress_bar.py[line:272] - INFO: epoch 030:   1540 / 1732 loss=2.115, loss_v1=0, loss_v2=0, nll_loss=0.884, ntokens=1106.8, nsentences=32, sample_size=1106.8, sample_size_v1=0, sample_size_v2=0, ppl=1.85, wps=583.3, ups=0.53, wpb=1106.8, bsz=32, num_updates=51680, lr=1.7198e-07, gnorm=19.284, clip=100, loss_scale=32, train_wall=19, gb_free=10.9, wall=97158
2023-05-27 02:22:43 - progress_bar.py[line:272] - INFO: epoch 030:   1550 / 1732 loss=2.112, loss_v1=0, loss_v2=0, nll_loss=0.881, ntokens=1063.7, nsentences=32, sample_size=1063.7, sample_size_v1=0, sample_size_v2=0, ppl=1.84, wps=564.8, ups=0.53, wpb=1063.7, bsz=32, num_updates=51690, lr=1.65837e-07, gnorm=18.902, clip=100, loss_scale=32, train_wall=19, gb_free=10.8, wall=97177
2023-05-27 02:23:01 - progress_bar.py[line:272] - INFO: epoch 030:   1560 / 1732 loss=2.108, loss_v1=0, loss_v2=0, nll_loss=0.877, ntokens=1090.1, nsentences=32, sample_size=1090.1, sample_size_v1=0, sample_size_v2=0, ppl=1.84, wps=579.8, ups=0.53, wpb=1090.1, bsz=32, num_updates=51700, lr=1.59695e-07, gnorm=17.883, clip=100, loss_scale=32, train_wall=19, gb_free=10.4, wall=97196
2023-05-27 02:23:20 - progress_bar.py[line:272] - INFO: epoch 030:   1570 / 1732 loss=2.146, loss_v1=0, loss_v2=0, nll_loss=0.918, ntokens=1073.5, nsentences=32, sample_size=1073.5, sample_size_v1=0, sample_size_v2=0, ppl=1.89, wps=569.1, ups=0.53, wpb=1073.5, bsz=32, num_updates=51710, lr=1.53553e-07, gnorm=17.869, clip=100, loss_scale=32, train_wall=19, gb_free=11.1, wall=97215
2023-05-27 02:23:39 - progress_bar.py[line:272] - INFO: epoch 030:   1580 / 1732 loss=2.129, loss_v1=0, loss_v2=0, nll_loss=0.899, ntokens=980.3, nsentences=32, sample_size=980.3, sample_size_v1=0, sample_size_v2=0, ppl=1.86, wps=523.1, ups=0.53, wpb=980.3, bsz=32, num_updates=51720, lr=1.47411e-07, gnorm=20.416, clip=100, loss_scale=32, train_wall=19, gb_free=11.6, wall=97234
2023-05-27 02:23:58 - progress_bar.py[line:272] - INFO: epoch 030:   1590 / 1732 loss=2.121, loss_v1=0, loss_v2=0, nll_loss=0.891, ntokens=1103, nsentences=32, sample_size=1103, sample_size_v1=0, sample_size_v2=0, ppl=1.85, wps=582.2, ups=0.53, wpb=1103, bsz=32, num_updates=51730, lr=1.41269e-07, gnorm=18.595, clip=100, loss_scale=32, train_wall=19, gb_free=10.6, wall=97253
2023-05-27 02:24:17 - progress_bar.py[line:272] - INFO: epoch 030:   1600 / 1732 loss=2.102, loss_v1=0, loss_v2=0, nll_loss=0.869, ntokens=1067.6, nsentences=32, sample_size=1067.6, sample_size_v1=0, sample_size_v2=0, ppl=1.83, wps=567.7, ups=0.53, wpb=1067.6, bsz=32, num_updates=51740, lr=1.35127e-07, gnorm=18.483, clip=100, loss_scale=32, train_wall=19, gb_free=11, wall=97271
2023-05-27 02:24:36 - progress_bar.py[line:272] - INFO: epoch 030:   1610 / 1732 loss=2.104, loss_v1=0, loss_v2=0, nll_loss=0.871, ntokens=1149.4, nsentences=32, sample_size=1149.4, sample_size_v1=0, sample_size_v2=0, ppl=1.83, wps=605, ups=0.53, wpb=1149.4, bsz=32, num_updates=51750, lr=1.28985e-07, gnorm=17.767, clip=100, loss_scale=32, train_wall=19, gb_free=11.2, wall=97290
2023-05-27 02:24:55 - progress_bar.py[line:272] - INFO: epoch 030:   1620 / 1732 loss=2.095, loss_v1=0, loss_v2=0, nll_loss=0.862, ntokens=1143.9, nsentences=32, sample_size=1143.9, sample_size_v1=0, sample_size_v2=0, ppl=1.82, wps=601.7, ups=0.53, wpb=1143.9, bsz=32, num_updates=51760, lr=1.22843e-07, gnorm=18.287, clip=100, loss_scale=32, train_wall=19, gb_free=10.5, wall=97309
2023-05-27 02:25:14 - progress_bar.py[line:272] - INFO: epoch 030:   1630 / 1732 loss=2.129, loss_v1=0, loss_v2=0, nll_loss=0.9, ntokens=1148.8, nsentences=32, sample_size=1148.8, sample_size_v1=0, sample_size_v2=0, ppl=1.87, wps=606.3, ups=0.53, wpb=1148.8, bsz=32, num_updates=51770, lr=1.167e-07, gnorm=18.473, clip=100, loss_scale=32, train_wall=19, gb_free=11.1, wall=97328
2023-05-27 02:25:33 - progress_bar.py[line:272] - INFO: epoch 030:   1640 / 1732 loss=2.106, loss_v1=0, loss_v2=0, nll_loss=0.874, ntokens=1148.2, nsentences=32, sample_size=1148.2, sample_size_v1=0, sample_size_v2=0, ppl=1.83, wps=610.8, ups=0.53, wpb=1148.2, bsz=32, num_updates=51780, lr=1.10558e-07, gnorm=18.557, clip=100, loss_scale=32, train_wall=19, gb_free=11, wall=97347
2023-05-27 02:25:51 - progress_bar.py[line:272] - INFO: epoch 030:   1650 / 1732 loss=2.115, loss_v1=0, loss_v2=0, nll_loss=0.884, ntokens=1158.7, nsentences=32, sample_size=1158.7, sample_size_v1=0, sample_size_v2=0, ppl=1.85, wps=610.7, ups=0.53, wpb=1158.7, bsz=32, num_updates=51790, lr=1.04416e-07, gnorm=19.503, clip=100, loss_scale=32, train_wall=19, gb_free=11.7, wall=97366
2023-05-27 02:26:10 - progress_bar.py[line:272] - INFO: epoch 030:   1660 / 1732 loss=2.142, loss_v1=0, loss_v2=0, nll_loss=0.914, ntokens=997.6, nsentences=32, sample_size=997.6, sample_size_v1=0, sample_size_v2=0, ppl=1.88, wps=531.3, ups=0.53, wpb=997.6, bsz=32, num_updates=51800, lr=9.82741e-08, gnorm=19.573, clip=100, loss_scale=32, train_wall=19, gb_free=11.3, wall=97385
2023-05-27 02:26:29 - progress_bar.py[line:272] - INFO: epoch 030:   1670 / 1732 loss=2.114, loss_v1=0, loss_v2=0, nll_loss=0.883, ntokens=1015.8, nsentences=32, sample_size=1015.8, sample_size_v1=0, sample_size_v2=0, ppl=1.84, wps=542.1, ups=0.53, wpb=1015.8, bsz=32, num_updates=51810, lr=9.21319e-08, gnorm=18.235, clip=100, loss_scale=32, train_wall=19, gb_free=11.4, wall=97404
2023-05-27 02:26:48 - progress_bar.py[line:272] - INFO: epoch 030:   1680 / 1732 loss=2.084, loss_v1=0, loss_v2=0, nll_loss=0.85, ntokens=1181.3, nsentences=32, sample_size=1181.3, sample_size_v1=0, sample_size_v2=0, ppl=1.8, wps=619.1, ups=0.52, wpb=1181.3, bsz=32, num_updates=51820, lr=8.59898e-08, gnorm=17.14, clip=100, loss_scale=32, train_wall=19, gb_free=11.1, wall=97423
2023-05-27 02:27:07 - progress_bar.py[line:272] - INFO: epoch 030:   1690 / 1732 loss=2.112, loss_v1=0, loss_v2=0, nll_loss=0.88, ntokens=1198.5, nsentences=32, sample_size=1198.5, sample_size_v1=0, sample_size_v2=0, ppl=1.84, wps=626.8, ups=0.52, wpb=1198.5, bsz=32, num_updates=51830, lr=7.98477e-08, gnorm=16.946, clip=100, loss_scale=32, train_wall=19, gb_free=10.8, wall=97442
2023-05-27 02:27:26 - progress_bar.py[line:272] - INFO: epoch 030:   1700 / 1732 loss=2.108, loss_v1=0, loss_v2=0, nll_loss=0.875, ntokens=1281, nsentences=32, sample_size=1281, sample_size_v1=0, sample_size_v2=0, ppl=1.83, wps=666.7, ups=0.52, wpb=1281, bsz=32, num_updates=51840, lr=7.37055e-08, gnorm=15.228, clip=100, loss_scale=32, train_wall=19, gb_free=11.4, wall=97461
2023-05-27 02:27:45 - progress_bar.py[line:272] - INFO: epoch 030:   1710 / 1732 loss=2.132, loss_v1=0, loss_v2=0, nll_loss=0.902, ntokens=1170.9, nsentences=32, sample_size=1170.9, sample_size_v1=0, sample_size_v2=0, ppl=1.87, wps=618, ups=0.53, wpb=1170.9, bsz=32, num_updates=51850, lr=6.75634e-08, gnorm=17.724, clip=100, loss_scale=32, train_wall=19, gb_free=10.2, wall=97480
2023-05-27 02:28:04 - progress_bar.py[line:272] - INFO: epoch 030:   1720 / 1732 loss=2.105, loss_v1=0, loss_v2=0, nll_loss=0.873, ntokens=1171, nsentences=32, sample_size=1171, sample_size_v1=0, sample_size_v2=0, ppl=1.83, wps=616.5, ups=0.53, wpb=1171, bsz=32, num_updates=51860, lr=6.14213e-08, gnorm=16.648, clip=100, loss_scale=32, train_wall=19, gb_free=11.3, wall=97499
2023-05-27 02:28:23 - progress_bar.py[line:272] - INFO: epoch 030:   1730 / 1732 loss=2.145, loss_v1=0, loss_v2=0, nll_loss=0.917, ntokens=1126.4, nsentences=32, sample_size=1126.4, sample_size_v1=0, sample_size_v2=0, ppl=1.89, wps=595.7, ups=0.53, wpb=1126.4, bsz=32, num_updates=51870, lr=5.52792e-08, gnorm=17.584, clip=100, loss_scale=32, train_wall=19, gb_free=11.2, wall=97518
2023-05-27 02:28:26 - train.py[line:445] - INFO: begin validation on "valid" subset
slice_id 0 seek offset 0
slice_id 0 seek offset 0
/home/zcai75/Github/OFA/fairseq/fairseq/search.py:140: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  beams_buf = indices_buf // vocab_size
/home/zcai75/Github/OFA_forked/models/sequence_generator.py:705: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  unfin_idx = bbsz_idx // beam_size
2343729 <sub> train<pred> on<obj> track<sub> window<pred> on<obj> train<sub> window<pred> on<obj> train<sub> window<pred> on<obj> train<sub> window<pred> on<obj> train<sub> door<pred> on<obj> train ['<sub> windshield<pred> on<obj> train<sub> window<pred> on<obj> train<sub> train<pred> has<obj> window<sub> house<pred> near<obj> train<sub> tree<pred> near<obj> house']
2023-05-27 02:28:37 - progress_bar.py[line:272] - INFO: epoch 030 | valid on 'valid' subset:     11 / 2860 loss=2.439, loss_v1=0, loss_v2=0, nll_loss=1.221, ntokens=293, nsentences=8, sample_size=293, sample_size_v1=0, sample_size_v2=0
2023-05-27 02:28:47 - progress_bar.py[line:272] - INFO: epoch 030 | valid on 'valid' subset:     21 / 2860 loss=2.209, loss_v1=0, loss_v2=0, nll_loss=0.969, ntokens=308, nsentences=8, sample_size=308, sample_size_v1=0, sample_size_v2=0
2023-05-27 02:28:57 - progress_bar.py[line:272] - INFO: epoch 030 | valid on 'valid' subset:     31 / 2860 loss=2.293, loss_v1=0, loss_v2=0, nll_loss=1.055, ntokens=299, nsentences=8, sample_size=299, sample_size_v1=0, sample_size_v2=0
2023-05-27 02:29:07 - progress_bar.py[line:272] - INFO: epoch 030 | valid on 'valid' subset:     41 / 2860 loss=2.504, loss_v1=0, loss_v2=0, nll_loss=1.299, ntokens=331, nsentences=8, sample_size=331, sample_size_v1=0, sample_size_v2=0
2343237 <sub> person<pred> wearing<obj> pant<pred> wearing<obj> jacket<pred> wearing<obj> helmet<pred> wearing<obj> jacket<pred> wearing<obj> pant<sub> person<pred> wearing<obj> jacket<sub> snow<pred> on<obj> hill ['<sub> man<pred> above<obj> skateboard<pred> wearing<obj> shoe<pred> wearing<obj> sock<pred> wearing<obj> shirt<sub> person<pred> standing on<obj> skateboard<pred> has<obj> head<sub> skateboard<pred> for<obj> shoe<sub> leg<pred> of<obj> person<sub> leg<pred> of<obj> person<sub> head<pred> of<obj> person']
2023-05-27 02:29:16 - progress_bar.py[line:272] - INFO: epoch 030 | valid on 'valid' subset:     51 / 2860 loss=2.235, loss_v1=0, loss_v2=0, nll_loss=0.996, ntokens=375, nsentences=8, sample_size=375, sample_size_v1=0, sample_size_v2=0
2023-05-27 02:29:26 - progress_bar.py[line:272] - INFO: epoch 030 | valid on 'valid' subset:     61 / 2860 loss=2.456, loss_v1=0, loss_v2=0, nll_loss=1.246, ntokens=292, nsentences=8, sample_size=292, sample_size_v1=0, sample_size_v2=0
2023-05-27 02:29:36 - progress_bar.py[line:272] - INFO: epoch 030 | valid on 'valid' subset:     71 / 2860 loss=2.319, loss_v1=0, loss_v2=0, nll_loss=1.087, ntokens=384, nsentences=8, sample_size=384, sample_size_v1=0, sample_size_v2=0
2023-05-27 02:29:45 - progress_bar.py[line:272] - INFO: epoch 030 | valid on 'valid' subset:     81 / 2860 loss=2.207, loss_v1=0, loss_v2=0, nll_loss=0.964, ntokens=355, nsentences=8, sample_size=355, sample_size_v1=0, sample_size_v2=0
2023-05-27 02:29:55 - progress_bar.py[line:272] - INFO: epoch 030 | valid on 'valid' subset:     91 / 2860 loss=2.298, loss_v1=0, loss_v2=0, nll_loss=1.058, ntokens=438, nsentences=8, sample_size=438, sample_size_v1=0, sample_size_v2=0
2342714 <sub> bird<pred> on<obj> rock<sub> bird<pred> on<obj> rock<sub> bird<pred> on<obj> rock<sub> bird<pred> on<obj> rock ['<sub> head<pred> of<obj> sheep<sub> head<pred> of<obj> sheep<sub> head<pred> of<obj> sheep<sub> head<pred> of<obj> sheep<sub> head<pred> of<obj> sheep']
2023-05-27 02:30:05 - progress_bar.py[line:272] - INFO: epoch 030 | valid on 'valid' subset:    101 / 2860 loss=2.307, loss_v1=0, loss_v2=0, nll_loss=1.072, ntokens=408, nsentences=8, sample_size=408, sample_size_v1=0, sample_size_v2=0
2023-05-27 02:30:15 - progress_bar.py[line:272] - INFO: epoch 030 | valid on 'valid' subset:    111 / 2860 loss=2.52, loss_v1=0, loss_v2=0, nll_loss=1.313, ntokens=347, nsentences=8, sample_size=347, sample_size_v1=0, sample_size_v2=0
2023-05-27 02:30:26 - progress_bar.py[line:272] - INFO: epoch 030 | valid on 'valid' subset:    121 / 2860 loss=2.232, loss_v1=0, loss_v2=0, nll_loss=0.993, ntokens=352, nsentences=8, sample_size=352, sample_size_v1=0, sample_size_v2=0
2023-05-27 02:30:35 - progress_bar.py[line:272] - INFO: epoch 030 | valid on 'valid' subset:    131 / 2860 loss=2.489, loss_v1=0, loss_v2=0, nll_loss=1.279, ntokens=247, nsentences=8, sample_size=247, sample_size_v1=0, sample_size_v2=0
2023-05-27 02:30:45 - progress_bar.py[line:272] - INFO: epoch 030 | valid on 'valid' subset:    141 / 2860 loss=2.42, loss_v1=0, loss_v2=0, nll_loss=1.202, ntokens=246, nsentences=8, sample_size=246, sample_size_v1=0, sample_size_v2=0
2342212 <sub> leg<pred> of<obj> horse<sub> leg<pred> of<obj> horse<sub> leg<pred> of<obj> horse<sub> leg<pred> of<obj> horse<sub> leg<pred> of<obj> horse<sub> leg<pred> of<obj> horse<sub> leg<pred> of<obj> horse<sub> leg<pred> of<obj> horse<sub> leg<pred> of<obj> horse<sub> leg<pred> of<obj> horse ['<sub> kid<pred> near<obj> bike<sub> sign<pred> near<obj> building<sub> man<pred> on<obj> street<sub> bike<pred> has<obj> tire<pred> near<obj> stand<pred> parked on<obj> street<sub> people<pred> under<obj> umbrella<pred> walking on<obj> street<sub> boy<pred> near<obj> bike<sub> man<pred> wears<obj> shirt<pred> wears<obj> short<sub> woman<pred> wearing<obj> shirt<sub> person<pred> wearing<obj> shirt']
2023-05-27 02:30:56 - progress_bar.py[line:272] - INFO: epoch 030 | valid on 'valid' subset:    151 / 2860 loss=2.495, loss_v1=0, loss_v2=0, nll_loss=1.282, ntokens=433, nsentences=8, sample_size=433, sample_size_v1=0, sample_size_v2=0
2023-05-27 02:31:05 - progress_bar.py[line:272] - INFO: epoch 030 | valid on 'valid' subset:    161 / 2860 loss=2.433, loss_v1=0, loss_v2=0, nll_loss=1.217, ntokens=346, nsentences=8, sample_size=346, sample_size_v1=0, sample_size_v2=0
2023-05-27 02:31:15 - progress_bar.py[line:272] - INFO: epoch 030 | valid on 'valid' subset:    171 / 2860 loss=2.771, loss_v1=0, loss_v2=0, nll_loss=1.589, ntokens=274, nsentences=8, sample_size=274, sample_size_v1=0, sample_size_v2=0
2023-05-27 02:31:26 - progress_bar.py[line:272] - INFO: epoch 030 | valid on 'valid' subset:    181 / 2860 loss=2.431, loss_v1=0, loss_v2=0, nll_loss=1.212, ntokens=258, nsentences=8, sample_size=258, sample_size_v1=0, sample_size_v2=0
2023-05-27 02:31:36 - progress_bar.py[line:272] - INFO: epoch 030 | valid on 'valid' subset:    191 / 2860 loss=2.252, loss_v1=0, loss_v2=0, nll_loss=1.004, ntokens=218, nsentences=8, sample_size=218, sample_size_v1=0, sample_size_v2=0
2341718 <sub> flower<pred> in<obj> vase<sub> flower<pred> in<obj> vase<sub> vase<pred> with<obj> flower<pred> with<obj> flower<sub> vase<pred> with<obj> flower ['<sub> bird<pred> on<obj> bike<sub> wire<pred> on<obj> bike']
2023-05-27 02:31:46 - progress_bar.py[line:272] - INFO: epoch 030 | valid on 'valid' subset:    201 / 2860 loss=2.376, loss_v1=0, loss_v2=0, nll_loss=1.155, ntokens=265, nsentences=8, sample_size=265, sample_size_v1=0, sample_size_v2=0
2023-05-27 02:31:56 - progress_bar.py[line:272] - INFO: epoch 030 | valid on 'valid' subset:    211 / 2860 loss=2.428, loss_v1=0, loss_v2=0, nll_loss=1.22, ntokens=211, nsentences=8, sample_size=211, sample_size_v1=0, sample_size_v2=0
2023-05-27 02:32:06 - progress_bar.py[line:272] - INFO: epoch 030 | valid on 'valid' subset:    221 / 2860 loss=2.35, loss_v1=0, loss_v2=0, nll_loss=1.122, ntokens=394, nsentences=8, sample_size=394, sample_size_v1=0, sample_size_v2=0
2023-05-27 02:32:17 - progress_bar.py[line:272] - INFO: epoch 030 | valid on 'valid' subset:    231 / 2860 loss=2.409, loss_v1=0, loss_v2=0, nll_loss=1.187, ntokens=231, nsentences=8, sample_size=231, sample_size_v1=0, sample_size_v2=0
2023-05-27 02:32:27 - progress_bar.py[line:272] - INFO: epoch 030 | valid on 'valid' subset:    241 / 2860 loss=2.38, loss_v1=0, loss_v2=0, nll_loss=1.158, ntokens=267, nsentences=8, sample_size=267, sample_size_v1=0, sample_size_v2=0
2341172 <sub> man<pred> wearing<obj> short<pred> wearing<obj> shirt<pred> wearing<obj> sneaker<pred> wearing<obj> sneaker<pred> wearing<obj> sneaker ['<sub> dog<pred> has<obj> ear<pred> has<obj> ear<pred> has<obj> leg<sub> person<pred> has<obj> pant']
2023-05-27 02:32:36 - progress_bar.py[line:272] - INFO: epoch 030 | valid on 'valid' subset:    251 / 2860 loss=2.338, loss_v1=0, loss_v2=0, nll_loss=1.11, ntokens=340, nsentences=8, sample_size=340, sample_size_v1=0, sample_size_v2=0
2023-05-27 02:32:45 - progress_bar.py[line:272] - INFO: epoch 030 | valid on 'valid' subset:    261 / 2860 loss=2.318, loss_v1=0, loss_v2=0, nll_loss=1.083, ntokens=209, nsentences=8, sample_size=209, sample_size_v1=0, sample_size_v2=0
2023-05-27 02:32:54 - progress_bar.py[line:272] - INFO: epoch 030 | valid on 'valid' subset:    271 / 2860 loss=2.428, loss_v1=0, loss_v2=0, nll_loss=1.214, ntokens=234, nsentences=8, sample_size=234, sample_size_v1=0, sample_size_v2=0
2023-05-27 02:33:03 - progress_bar.py[line:272] - INFO: epoch 030 | valid on 'valid' subset:    281 / 2860 loss=2.311, loss_v1=0, loss_v2=0, nll_loss=1.076, ntokens=171, nsentences=8, sample_size=171, sample_size_v1=0, sample_size_v2=0
2023-05-27 02:33:13 - progress_bar.py[line:272] - INFO: epoch 030 | valid on 'valid' subset:    291 / 2860 loss=2.284, loss_v1=0, loss_v2=0, nll_loss=1.05, ntokens=318, nsentences=8, sample_size=318, sample_size_v1=0, sample_size_v2=0
2340556 <sub> man<pred> wearing<obj> shirt<sub> man<pred> wearing<obj> shirt<sub> man<pred> wearing<obj> shirt<sub> man<pred> wearing<obj> shirt<sub> man<pred> wearing<obj> shirt<sub> man<pred> wearing<obj> shirt ['<sub> person<pred> holding<obj> jacket<pred> wearing<obj> shirt<pred> wearing<obj> pant<pred> wearing<obj> shoe<sub> woman<pred> carrying<obj> bag<pred> wearing<obj> pant<sub> person<pred> holding<obj> bag<sub> wheel<pred> on<obj> airplane<sub> guy<pred> wearing<obj> short<sub> guy<pred> wearing<obj> shirt<pred> wearing<obj> pant']
2023-05-27 02:33:23 - progress_bar.py[line:272] - INFO: epoch 030 | valid on 'valid' subset:    301 / 2860 loss=2.589, loss_v1=0, loss_v2=0, nll_loss=1.385, ntokens=313, nsentences=8, sample_size=313, sample_size_v1=0, sample_size_v2=0
2023-05-27 02:33:33 - progress_bar.py[line:272] - INFO: epoch 030 | valid on 'valid' subset:    311 / 2860 loss=2.295, loss_v1=0, loss_v2=0, nll_loss=1.054, ntokens=316, nsentences=8, sample_size=316, sample_size_v1=0, sample_size_v2=0
2023-05-27 02:33:43 - progress_bar.py[line:272] - INFO: epoch 030 | valid on 'valid' subset:    321 / 2860 loss=2.442, loss_v1=0, loss_v2=0, nll_loss=1.223, ntokens=222, nsentences=8, sample_size=222, sample_size_v1=0, sample_size_v2=0
2023-05-27 02:33:53 - progress_bar.py[line:272] - INFO: epoch 030 | valid on 'valid' subset:    331 / 2860 loss=2.496, loss_v1=0, loss_v2=0, nll_loss=1.288, ntokens=272, nsentences=8, sample_size=272, sample_size_v1=0, sample_size_v2=0
2023-05-27 02:34:03 - progress_bar.py[line:272] - INFO: epoch 030 | valid on 'valid' subset:    341 / 2860 loss=2.31, loss_v1=0, loss_v2=0, nll_loss=1.077, ntokens=236, nsentences=8, sample_size=236, sample_size_v1=0, sample_size_v2=0
2339847 <sub> food<pred> on<obj> plate<sub> food<pred> on<obj> plate<sub> food<pred> on<obj> plate<sub> food<pred> on<obj> plate<sub> food<pred> on<obj> plate<sub> food<pred> on<obj> plate<sub> food<pred> on<obj> plate<sub> food<pred> on<obj> plate<sub> food<pred> on<obj> plate<sub> food<pred> on<obj> plate<sub> food<pred> on<obj> plate<sub> food<pred> on<obj> plate<sub> food<pred> on<obj> plate ['<sub> hand<pred> on<obj> laptop<sub> laptop<pred> has<obj> screen<sub> book<pred> on<obj> table<sub> book<pred> on<obj> table<sub> screen<pred> has<obj> laptop<sub> shirt<pred> of<obj> person']
2023-05-27 02:34:13 - progress_bar.py[line:272] - INFO: epoch 030 | valid on 'valid' subset:    351 / 2860 loss=2.597, loss_v1=0, loss_v2=0, nll_loss=1.399, ntokens=271, nsentences=8, sample_size=271, sample_size_v1=0, sample_size_v2=0
2023-05-27 02:34:22 - progress_bar.py[line:272] - INFO: epoch 030 | valid on 'valid' subset:    361 / 2860 loss=2.325, loss_v1=0, loss_v2=0, nll_loss=1.095, ntokens=274, nsentences=8, sample_size=274, sample_size_v1=0, sample_size_v2=0
2023-05-27 02:34:32 - progress_bar.py[line:272] - INFO: epoch 030 | valid on 'valid' subset:    371 / 2860 loss=2.364, loss_v1=0, loss_v2=0, nll_loss=1.145, ntokens=245, nsentences=8, sample_size=245, sample_size_v1=0, sample_size_v2=0
2023-05-27 02:34:42 - progress_bar.py[line:272] - INFO: epoch 030 | valid on 'valid' subset:    381 / 2860 loss=2.484, loss_v1=0, loss_v2=0, nll_loss=1.275, ntokens=228, nsentences=8, sample_size=228, sample_size_v1=0, sample_size_v2=0
2023-05-27 02:34:51 - progress_bar.py[line:272] - INFO: epoch 030 | valid on 'valid' subset:    391 / 2860 loss=2.301, loss_v1=0, loss_v2=0, nll_loss=1.068, ntokens=260, nsentences=8, sample_size=260, sample_size_v1=0, sample_size_v2=0
2339141 <sub> man<pred> wearing<obj> hat<pred> wearing<obj> shirt<pred> wearing<obj> short<pred> wearing<obj> shoe<pred> wearing<obj> shoe<pred> wearing<obj> shoe<sub> man<pred> wearing<obj> shirt<pred> wearing<obj> short<sub> man<pred> wearing<obj> shirt<sub> man<pred> wearing<obj> short<sub> hat<pred> on<obj> head ['<sub> man<pred> wearing<obj> short<pred> wearing<obj> hat<pred> wearing<obj> shirt<sub> hat<pred> on<obj> man<sub> leaf<pred> on<obj> tree']
2023-05-27 02:35:01 - progress_bar.py[line:272] - INFO: epoch 030 | valid on 'valid' subset:    401 / 2860 loss=2.485, loss_v1=0, loss_v2=0, nll_loss=1.274, ntokens=258, nsentences=8, sample_size=258, sample_size_v1=0, sample_size_v2=0
2023-05-27 02:35:10 - progress_bar.py[line:272] - INFO: epoch 030 | valid on 'valid' subset:    411 / 2860 loss=2.488, loss_v1=0, loss_v2=0, nll_loss=1.275, ntokens=195, nsentences=8, sample_size=195, sample_size_v1=0, sample_size_v2=0
2023-05-27 02:35:19 - progress_bar.py[line:272] - INFO: epoch 030 | valid on 'valid' subset:    421 / 2860 loss=2.355, loss_v1=0, loss_v2=0, nll_loss=1.126, ntokens=155, nsentences=8, sample_size=155, sample_size_v1=0, sample_size_v2=0
2023-05-27 02:35:29 - progress_bar.py[line:272] - INFO: epoch 030 | valid on 'valid' subset:    431 / 2860 loss=2.256, loss_v1=0, loss_v2=0, nll_loss=1.008, ntokens=255, nsentences=8, sample_size=255, sample_size_v1=0, sample_size_v2=0
2023-05-27 02:35:37 - progress_bar.py[line:272] - INFO: epoch 030 | valid on 'valid' subset:    441 / 2860 loss=2.382, loss_v1=0, loss_v2=0, nll_loss=1.161, ntokens=260, nsentences=8, sample_size=260, sample_size_v1=0, sample_size_v2=0
2338457 <sub> bed<pred> in<obj> room<sub> pillow<pred> on<obj> bed<sub> pillow<pred> on<obj> bed ['<sub> towel<pred> on<obj> bed<sub> bed<pred> in<obj> room<sub> bed<pred> in<obj> room<sub> table<pred> near<obj> bed']
2023-05-27 02:35:46 - progress_bar.py[line:272] - INFO: epoch 030 | valid on 'valid' subset:    451 / 2860 loss=2.551, loss_v1=0, loss_v2=0, nll_loss=1.347, ntokens=199, nsentences=8, sample_size=199, sample_size_v1=0, sample_size_v2=0
2023-05-27 02:35:54 - progress_bar.py[line:272] - INFO: epoch 030 | valid on 'valid' subset:    461 / 2860 loss=2.406, loss_v1=0, loss_v2=0, nll_loss=1.186, ntokens=239, nsentences=8, sample_size=239, sample_size_v1=0, sample_size_v2=0
2023-05-27 02:36:04 - progress_bar.py[line:272] - INFO: epoch 030 | valid on 'valid' subset:    471 / 2860 loss=2.396, loss_v1=0, loss_v2=0, nll_loss=1.169, ntokens=231, nsentences=8, sample_size=231, sample_size_v1=0, sample_size_v2=0
2023-05-27 02:36:13 - progress_bar.py[line:272] - INFO: epoch 030 | valid on 'valid' subset:    481 / 2860 loss=2.458, loss_v1=0, loss_v2=0, nll_loss=1.241, ntokens=282, nsentences=8, sample_size=282, sample_size_v1=0, sample_size_v2=0
2023-05-27 02:36:23 - progress_bar.py[line:272] - INFO: epoch 030 | valid on 'valid' subset:    491 / 2860 loss=2.364, loss_v1=0, loss_v2=0, nll_loss=1.15, ntokens=327, nsentences=8, sample_size=327, sample_size_v1=0, sample_size_v2=0
2337758 <sub> man<pred> wearing<obj> tie<pred> wearing<obj> shirt<pred> wearing<obj> glass<pred> wearing<obj> shirt<pred> has<obj> face<sub> woman<pred> has<obj> hair<pred> wearing<obj> shirt<pred> has<obj> hand<pred> has<obj> hand<sub> glass<pred> on<obj> face<pred> on<obj> face<sub> face<pred> on<obj> man<sub> face<pred> on<obj> man<sub> face<pred> on<obj> man<sub> face<pred> on<obj> man<sub> face<pred> on<obj> man ['<sub> man<pred> at<obj> table<pred> on<obj> glass<pred> in<obj> shirt<sub> woman<pred> wearing<obj> shirt<sub> man<pred> wearing<obj> glass<pred> wearing<obj> shirt<sub> woman<pred> with<obj> hair<sub> man<pred> wearing<obj> shirt<sub> person<pred> wearing<obj> shirt<sub> head<pred> of<obj> person']
2023-05-27 02:36:33 - progress_bar.py[line:272] - INFO: epoch 030 | valid on 'valid' subset:    501 / 2860 loss=2.219, loss_v1=0, loss_v2=0, nll_loss=0.979, ntokens=305, nsentences=8, sample_size=305, sample_size_v1=0, sample_size_v2=0
2023-05-27 02:36:42 - progress_bar.py[line:272] - INFO: epoch 030 | valid on 'valid' subset:    511 / 2860 loss=2.609, loss_v1=0, loss_v2=0, nll_loss=1.406, ntokens=242, nsentences=8, sample_size=242, sample_size_v1=0, sample_size_v2=0
2023-05-27 02:36:51 - progress_bar.py[line:272] - INFO: epoch 030 | valid on 'valid' subset:    521 / 2860 loss=2.403, loss_v1=0, loss_v2=0, nll_loss=1.182, ntokens=286, nsentences=8, sample_size=286, sample_size_v1=0, sample_size_v2=0
2023-05-27 02:37:01 - progress_bar.py[line:272] - INFO: epoch 030 | valid on 'valid' subset:    531 / 2860 loss=2.319, loss_v1=0, loss_v2=0, nll_loss=1.081, ntokens=292, nsentences=8, sample_size=292, sample_size_v1=0, sample_size_v2=0
2023-05-27 02:37:10 - progress_bar.py[line:272] - INFO: epoch 030 | valid on 'valid' subset:    541 / 2860 loss=2.582, loss_v1=0, loss_v2=0, nll_loss=1.384, ntokens=215, nsentences=8, sample_size=215, sample_size_v1=0, sample_size_v2=0
2337075 <sub> man<pred> wearing<obj> shirt<pred> wearing<obj> glass<pred> has<obj> hair<sub> man<pred> wearing<obj> shirt<pred> wearing<obj> jean<sub> man<pred> wearing<obj> shirt<pred> wearing<obj> jean<sub> woman<pred> wearing<obj> shirt<pred> has<obj> hair<sub> glass<pred> on<obj> face<sub> woman<pred> wearing<obj> shirt ['<sub> banana<pred> on<obj> head<sub> banana<pred> on<obj> head<sub> man<pred> wearing<obj> shirt<sub> men<pred> wearing<obj> banana<sub> banana<pred> on<obj> head<sub> face<pred> of<obj> man<sub> face<pred> of<obj> person<sub> hand<pred> of<obj> person<sub> man<pred> holding<obj> food<sub> logo<pred> in<obj> shirt<sub> hand<pred> of<obj> man<sub> hand<pred> of<obj> man']
2023-05-27 02:37:20 - progress_bar.py[line:272] - INFO: epoch 030 | valid on 'valid' subset:    551 / 2860 loss=2.445, loss_v1=0, loss_v2=0, nll_loss=1.231, ntokens=309, nsentences=8, sample_size=309, sample_size_v1=0, sample_size_v2=0
2023-05-27 02:37:29 - progress_bar.py[line:272] - INFO: epoch 030 | valid on 'valid' subset:    561 / 2860 loss=2.401, loss_v1=0, loss_v2=0, nll_loss=1.183, ntokens=250, nsentences=8, sample_size=250, sample_size_v1=0, sample_size_v2=0
2023-05-27 02:37:38 - progress_bar.py[line:272] - INFO: epoch 030 | valid on 'valid' subset:    571 / 2860 loss=2.609, loss_v1=0, loss_v2=0, nll_loss=1.405, ntokens=219, nsentences=8, sample_size=219, sample_size_v1=0, sample_size_v2=0
2023-05-27 02:37:48 - progress_bar.py[line:272] - INFO: epoch 030 | valid on 'valid' subset:    581 / 2860 loss=2.276, loss_v1=0, loss_v2=0, nll_loss=1.04, ntokens=286, nsentences=8, sample_size=286, sample_size_v1=0, sample_size_v2=0
2023-05-27 02:37:58 - progress_bar.py[line:272] - INFO: epoch 030 | valid on 'valid' subset:    591 / 2860 loss=2.283, loss_v1=0, loss_v2=0, nll_loss=1.044, ntokens=321, nsentences=8, sample_size=321, sample_size_v1=0, sample_size_v2=0
2336515 <sub> man<pred> wearing<obj> shirt<pred> wearing<obj> short<pred> wearing<obj> sock<pred> wearing<obj> sock<pred> wearing<obj> sock<pred> wearing<obj> sock<pred> wearing<obj> sock<pred> wearing<obj> sock<sub> man<pred> wearing<obj> short<pred> wearing<obj> shirt<pred> wearing<obj> sock<pred> wearing<obj> sock<pred> wearing<obj> sock<pred> wearing<obj> sock<sub> man<pred> wearing<obj> sock<pred> wearing<obj> sock<pred> wearing<obj> sock<pred> wearing<obj> sock<pred> wearing<obj> sock<pred> wearing<obj> short ['<sub> man<pred> wearing<obj> shoe<pred> in<obj> shirt<pred> wearing<obj> short<pred> has<obj> hair<sub> shoe<pred> of<obj> man<sub> leg<pred> on<obj> man<sub> leg<pred> on<obj> man<sub> arm<pred> on<obj> man<sub> arm<pred> on<obj> person']
2023-05-27 02:38:08 - progress_bar.py[line:272] - INFO: epoch 030 | valid on 'valid' subset:    601 / 2860 loss=2.328, loss_v1=0, loss_v2=0, nll_loss=1.095, ntokens=261, nsentences=8, sample_size=261, sample_size_v1=0, sample_size_v2=0
2023-05-27 02:38:17 - progress_bar.py[line:272] - INFO: epoch 030 | valid on 'valid' subset:    611 / 2860 loss=2.285, loss_v1=0, loss_v2=0, nll_loss=1.051, ntokens=332, nsentences=8, sample_size=332, sample_size_v1=0, sample_size_v2=0
2023-05-27 02:38:26 - progress_bar.py[line:272] - INFO: epoch 030 | valid on 'valid' subset:    621 / 2860 loss=2.405, loss_v1=0, loss_v2=0, nll_loss=1.181, ntokens=448, nsentences=8, sample_size=448, sample_size_v1=0, sample_size_v2=0
2023-05-27 02:38:36 - progress_bar.py[line:272] - INFO: epoch 030 | valid on 'valid' subset:    631 / 2860 loss=2.333, loss_v1=0, loss_v2=0, nll_loss=1.106, ntokens=278, nsentences=8, sample_size=278, sample_size_v1=0, sample_size_v2=0
2023-05-27 02:38:46 - progress_bar.py[line:272] - INFO: epoch 030 | valid on 'valid' subset:    641 / 2860 loss=2.408, loss_v1=0, loss_v2=0, nll_loss=1.183, ntokens=329, nsentences=8, sample_size=329, sample_size_v1=0, sample_size_v2=0
2335972 <sub> leg<pred> of<obj> zebra<sub> leg<pred> of<obj> zebra<sub> leg<pred> of<obj> zebra<sub> leg<pred> of<obj> zebra<sub> leg<pred> of<obj> zebra<sub> leg<pred> of<obj> zebra<sub> leg<pred> of<obj> zebra ['<sub> animal<pred> on<obj> rock<pred> on<obj> rock<sub> giraffe<pred> has<obj> leg<sub> zebra<pred> has<obj> eye']
2023-05-27 02:38:56 - progress_bar.py[line:272] - INFO: epoch 030 | valid on 'valid' subset:    651 / 2860 loss=2.513, loss_v1=0, loss_v2=0, nll_loss=1.306, ntokens=324, nsentences=8, sample_size=324, sample_size_v1=0, sample_size_v2=0
2023-05-27 02:39:06 - progress_bar.py[line:272] - INFO: epoch 030 | valid on 'valid' subset:    661 / 2860 loss=2.353, loss_v1=0, loss_v2=0, nll_loss=1.126, ntokens=311, nsentences=8, sample_size=311, sample_size_v1=0, sample_size_v2=0
2023-05-27 02:39:17 - progress_bar.py[line:272] - INFO: epoch 030 | valid on 'valid' subset:    671 / 2860 loss=2.529, loss_v1=0, loss_v2=0, nll_loss=1.323, ntokens=320, nsentences=8, sample_size=320, sample_size_v1=0, sample_size_v2=0
2023-05-27 02:39:27 - progress_bar.py[line:272] - INFO: epoch 030 | valid on 'valid' subset:    681 / 2860 loss=2.216, loss_v1=0, loss_v2=0, nll_loss=0.975, ntokens=224, nsentences=8, sample_size=224, sample_size_v1=0, sample_size_v2=0
2023-05-27 02:39:37 - progress_bar.py[line:272] - INFO: epoch 030 | valid on 'valid' subset:    691 / 2860 loss=2.324, loss_v1=0, loss_v2=0, nll_loss=1.096, ntokens=282, nsentences=8, sample_size=282, sample_size_v1=0, sample_size_v2=0
2335409 <sub> boy<pred> on<obj> skateboard<pred> wearing<obj> shirt<pred> wearing<obj> jean<pred> has<obj> hair<sub> skateboard<pred> under<obj> boy<sub> building<pred> behind<obj> boy<sub> tree<pred> behind<obj> building<sub> tree<pred> behind<obj> building<sub> building<pred> behind<obj> boy ['<sub> head<pred> of<obj> man<sub> leg<pred> of<obj> man<sub> man<pred> wearing<obj> jacket<pred> on<obj> skateboard<pred> wearing<obj> shirt']
2023-05-27 02:39:46 - progress_bar.py[line:272] - INFO: epoch 030 | valid on 'valid' subset:    701 / 2860 loss=2.392, loss_v1=0, loss_v2=0, nll_loss=1.163, ntokens=289, nsentences=8, sample_size=289, sample_size_v1=0, sample_size_v2=0
2023-05-27 02:39:56 - progress_bar.py[line:272] - INFO: epoch 030 | valid on 'valid' subset:    711 / 2860 loss=2.624, loss_v1=0, loss_v2=0, nll_loss=1.433, ntokens=281, nsentences=8, sample_size=281, sample_size_v1=0, sample_size_v2=0
2023-05-27 02:40:05 - progress_bar.py[line:272] - INFO: epoch 030 | valid on 'valid' subset:    721 / 2860 loss=2.375, loss_v1=0, loss_v2=0, nll_loss=1.148, ntokens=215, nsentences=8, sample_size=215, sample_size_v1=0, sample_size_v2=0
2023-05-27 02:40:15 - progress_bar.py[line:272] - INFO: epoch 030 | valid on 'valid' subset:    731 / 2860 loss=2.24, loss_v1=0, loss_v2=0, nll_loss=0.999, ntokens=421, nsentences=8, sample_size=421, sample_size_v1=0, sample_size_v2=0
2023-05-27 02:40:24 - progress_bar.py[line:272] - INFO: epoch 030 | valid on 'valid' subset:    741 / 2860 loss=2.214, loss_v1=0, loss_v2=0, nll_loss=0.968, ntokens=347, nsentences=8, sample_size=347, sample_size_v1=0, sample_size_v2=0
2334815 <sub> woman<pred> holding<obj> cup<pred> holding<obj> cup<pred> holding<obj> cup<pred> holding<obj> cup<pred> holding<obj> cup<pred> holding<obj> cup<pred> holding<obj> cup<pred> holding<obj> cup<pred> holding<obj> cup<sub> cup<pred> in<obj> hand<sub> cup<pred> in<obj> hand<sub> cup<pred> in<obj> hand<sub> cup<pred> in<obj> hand<sub> cup<pred> in<obj> hand ['<sub> leg<pred> of<obj> person<sub> leg<pred> of<obj> person<sub> leg<pred> of<obj> person<sub> leg<pred> of<obj> person<sub> leg<pred> of<obj> woman<sub> person<pred> in<obj> house']
2023-05-27 02:40:35 - progress_bar.py[line:272] - INFO: epoch 030 | valid on 'valid' subset:    751 / 2860 loss=2.32, loss_v1=0, loss_v2=0, nll_loss=1.089, ntokens=184, nsentences=8, sample_size=184, sample_size_v1=0, sample_size_v2=0
2023-05-27 02:40:45 - progress_bar.py[line:272] - INFO: epoch 030 | valid on 'valid' subset:    761 / 2860 loss=2.455, loss_v1=0, loss_v2=0, nll_loss=1.235, ntokens=193, nsentences=8, sample_size=193, sample_size_v1=0, sample_size_v2=0
2023-05-27 02:40:54 - progress_bar.py[line:272] - INFO: epoch 030 | valid on 'valid' subset:    771 / 2860 loss=2.365, loss_v1=0, loss_v2=0, nll_loss=1.138, ntokens=371, nsentences=8, sample_size=371, sample_size_v1=0, sample_size_v2=0
2023-05-27 02:41:04 - progress_bar.py[line:272] - INFO: epoch 030 | valid on 'valid' subset:    781 / 2860 loss=2.385, loss_v1=0, loss_v2=0, nll_loss=1.163, ntokens=252, nsentences=8, sample_size=252, sample_size_v1=0, sample_size_v2=0
2023-05-27 02:41:13 - progress_bar.py[line:272] - INFO: epoch 030 | valid on 'valid' subset:    791 / 2860 loss=2.425, loss_v1=0, loss_v2=0, nll_loss=1.202, ntokens=319, nsentences=8, sample_size=319, sample_size_v1=0, sample_size_v2=0
2334234 <sub> box<pred> on<obj> shelf<sub> box<pred> on<obj> shelf<sub> box<pred> on<obj> shelf<sub> box<pred> on<obj> shelf<sub> box<pred> on<obj> shelf<sub> box<pred> on<obj> shelf<sub> box<pred> on<obj> shelf<sub> box<pred> on<obj> shelf<sub> box<pred> on<obj> shelf<sub> box<pred> on<obj> shelf ['<sub> person<pred> using<obj> laptop<pred> sitting on<obj> chair<sub> arm<pred> on<obj> chair<sub> woman<pred> with<obj> laptop<sub> woman<pred> on<obj> screen']
2023-05-27 02:41:23 - progress_bar.py[line:272] - INFO: epoch 030 | valid on 'valid' subset:    801 / 2860 loss=2.315, loss_v1=0, loss_v2=0, nll_loss=1.078, ntokens=244, nsentences=8, sample_size=244, sample_size_v1=0, sample_size_v2=0
2023-05-27 02:41:33 - progress_bar.py[line:272] - INFO: epoch 030 | valid on 'valid' subset:    811 / 2860 loss=2.16, loss_v1=0, loss_v2=0, nll_loss=0.913, ntokens=239, nsentences=8, sample_size=239, sample_size_v1=0, sample_size_v2=0
2023-05-27 02:41:42 - progress_bar.py[line:272] - INFO: epoch 030 | valid on 'valid' subset:    821 / 2860 loss=2.429, loss_v1=0, loss_v2=0, nll_loss=1.216, ntokens=336, nsentences=8, sample_size=336, sample_size_v1=0, sample_size_v2=0
2023-05-27 02:41:52 - progress_bar.py[line:272] - INFO: epoch 030 | valid on 'valid' subset:    831 / 2860 loss=2.393, loss_v1=0, loss_v2=0, nll_loss=1.171, ntokens=302, nsentences=8, sample_size=302, sample_size_v1=0, sample_size_v2=0
2023-05-27 02:42:02 - progress_bar.py[line:272] - INFO: epoch 030 | valid on 'valid' subset:    841 / 2860 loss=2.404, loss_v1=0, loss_v2=0, nll_loss=1.187, ntokens=252, nsentences=8, sample_size=252, sample_size_v1=0, sample_size_v2=0
2333632 <sub> man<pred> in<obj> shirt<sub> man<pred> in<obj> shirt<sub> man<pred> in<obj> shirt ['<sub> shirt<pred> on<obj> man<sub> person<pred> in<obj> stand<sub> woman<pred> holding<obj> racket<sub> man<pred> wearing<obj> shirt']
2023-05-27 02:42:11 - progress_bar.py[line:272] - INFO: epoch 030 | valid on 'valid' subset:    851 / 2860 loss=2.403, loss_v1=0, loss_v2=0, nll_loss=1.183, ntokens=270, nsentences=8, sample_size=270, sample_size_v1=0, sample_size_v2=0
2023-05-27 02:42:21 - progress_bar.py[line:272] - INFO: epoch 030 | valid on 'valid' subset:    861 / 2860 loss=2.378, loss_v1=0, loss_v2=0, nll_loss=1.151, ntokens=274, nsentences=8, sample_size=274, sample_size_v1=0, sample_size_v2=0
2023-05-27 02:42:30 - progress_bar.py[line:272] - INFO: epoch 030 | valid on 'valid' subset:    871 / 2860 loss=2.442, loss_v1=0, loss_v2=0, nll_loss=1.217, ntokens=386, nsentences=8, sample_size=386, sample_size_v1=0, sample_size_v2=0
2023-05-27 02:42:40 - progress_bar.py[line:272] - INFO: epoch 030 | valid on 'valid' subset:    881 / 2860 loss=2.263, loss_v1=0, loss_v2=0, nll_loss=1.02, ntokens=289, nsentences=8, sample_size=289, sample_size_v1=0, sample_size_v2=0
2023-05-27 02:42:50 - progress_bar.py[line:272] - INFO: epoch 030 | valid on 'valid' subset:    891 / 2860 loss=2.492, loss_v1=0, loss_v2=0, nll_loss=1.283, ntokens=210, nsentences=8, sample_size=210, sample_size_v1=0, sample_size_v2=0
2333035 <sub> child<pred> on<obj> ski<sub> child<pred> on<obj> ski<sub> child<pred> on<obj> ski<sub> child<pred> on<obj> ski<sub> child<pred> on<obj> ski<sub> child<pred> on<obj> ski<sub> child<pred> on<obj> ski ['<sub> tree<pred> near<obj> street<sub> sign<pred> on<obj> pole<sub> man<pred> wears<obj> shirt<sub> man<pred> has<obj> head<sub> man<pred> has<obj> arm<pred> has<obj> leg<pred> with<obj> hat']
2023-05-27 02:42:59 - progress_bar.py[line:272] - INFO: epoch 030 | valid on 'valid' subset:    901 / 2860 loss=2.451, loss_v1=0, loss_v2=0, nll_loss=1.238, ntokens=267, nsentences=8, sample_size=267, sample_size_v1=0, sample_size_v2=0
2023-05-27 02:43:08 - progress_bar.py[line:272] - INFO: epoch 030 | valid on 'valid' subset:    911 / 2860 loss=2.371, loss_v1=0, loss_v2=0, nll_loss=1.153, ntokens=203, nsentences=8, sample_size=203, sample_size_v1=0, sample_size_v2=0
2023-05-27 02:43:17 - progress_bar.py[line:272] - INFO: epoch 030 | valid on 'valid' subset:    921 / 2860 loss=2.572, loss_v1=0, loss_v2=0, nll_loss=1.369, ntokens=170, nsentences=8, sample_size=170, sample_size_v1=0, sample_size_v2=0
2023-05-27 02:43:25 - progress_bar.py[line:272] - INFO: epoch 030 | valid on 'valid' subset:    931 / 2860 loss=2.246, loss_v1=0, loss_v2=0, nll_loss=1.005, ntokens=195, nsentences=8, sample_size=195, sample_size_v1=0, sample_size_v2=0
2023-05-27 02:43:33 - progress_bar.py[line:272] - INFO: epoch 030 | valid on 'valid' subset:    941 / 2860 loss=2.293, loss_v1=0, loss_v2=0, nll_loss=1.057, ntokens=331, nsentences=8, sample_size=331, sample_size_v1=0, sample_size_v2=0
2332329 <sub> person<pred> on<obj> beach<sub> person<pred> on<obj> beach<sub> person<pred> on<obj> beach ['<sub> kite<pred> lying on<obj> beach<sub> kite<pred> lying on<obj> beach<sub> kite<pred> lying on<obj> beach<sub> kite<pred> lying on<obj> beach<sub> kite<pred> lying on<obj> beach']
2023-05-27 02:43:42 - progress_bar.py[line:272] - INFO: epoch 030 | valid on 'valid' subset:    951 / 2860 loss=2.432, loss_v1=0, loss_v2=0, nll_loss=1.208, ntokens=250, nsentences=8, sample_size=250, sample_size_v1=0, sample_size_v2=0
2023-05-27 02:43:51 - progress_bar.py[line:272] - INFO: epoch 030 | valid on 'valid' subset:    961 / 2860 loss=2.446, loss_v1=0, loss_v2=0, nll_loss=1.23, ntokens=203, nsentences=8, sample_size=203, sample_size_v1=0, sample_size_v2=0
2023-05-27 02:43:59 - progress_bar.py[line:272] - INFO: epoch 030 | valid on 'valid' subset:    971 / 2860 loss=2.578, loss_v1=0, loss_v2=0, nll_loss=1.372, ntokens=137, nsentences=8, sample_size=137, sample_size_v1=0, sample_size_v2=0
2023-05-27 02:44:08 - progress_bar.py[line:272] - INFO: epoch 030 | valid on 'valid' subset:    981 / 2860 loss=2.54, loss_v1=0, loss_v2=0, nll_loss=1.332, ntokens=193, nsentences=8, sample_size=193, sample_size_v1=0, sample_size_v2=0
2023-05-27 02:44:16 - progress_bar.py[line:272] - INFO: epoch 030 | valid on 'valid' subset:    991 / 2860 loss=2.306, loss_v1=0, loss_v2=0, nll_loss=1.077, ntokens=163, nsentences=8, sample_size=163, sample_size_v1=0, sample_size_v2=0
2331507 <sub> pillow<pred> on<obj> bed<sub> pillow<pred> on<obj> bed<sub> pillow<pred> on<obj> bed<sub> pillow<pred> on<obj> bed<sub> pillow<pred> on<obj> bed<sub> pillow<pred> on<obj> bed<sub> pillow<pred> on<obj> bed<sub> pillow<pred> on<obj> bed<sub> lamp<pred> on<obj> table<sub> table<pred> near<obj> bed ['<sub> drawer<pred> to<obj> desk<sub> bed<pred> in<obj> room<sub> bed<pred> in<obj> room<sub> lamp<pred> on<obj> desk<sub> chair<pred> at<obj> desk']
2023-05-27 02:44:24 - progress_bar.py[line:272] - INFO: epoch 030 | valid on 'valid' subset:   1001 / 2860 loss=2.333, loss_v1=0, loss_v2=0, nll_loss=1.099, ntokens=210, nsentences=8, sample_size=210, sample_size_v1=0, sample_size_v2=0
2023-05-27 02:44:33 - progress_bar.py[line:272] - INFO: epoch 030 | valid on 'valid' subset:   1011 / 2860 loss=2.45, loss_v1=0, loss_v2=0, nll_loss=1.232, ntokens=251, nsentences=8, sample_size=251, sample_size_v1=0, sample_size_v2=0
2023-05-27 02:44:40 - progress_bar.py[line:272] - INFO: epoch 030 | valid on 'valid' subset:   1021 / 2860 loss=2.408, loss_v1=0, loss_v2=0, nll_loss=1.193, ntokens=183, nsentences=8, sample_size=183, sample_size_v1=0, sample_size_v2=0
2023-05-27 02:44:50 - progress_bar.py[line:272] - INFO: epoch 030 | valid on 'valid' subset:   1031 / 2860 loss=2.556, loss_v1=0, loss_v2=0, nll_loss=1.355, ntokens=242, nsentences=8, sample_size=242, sample_size_v1=0, sample_size_v2=0
2023-05-27 02:44:58 - progress_bar.py[line:272] - INFO: epoch 030 | valid on 'valid' subset:   1041 / 2860 loss=2.368, loss_v1=0, loss_v2=0, nll_loss=1.14, ntokens=262, nsentences=8, sample_size=262, sample_size_v1=0, sample_size_v2=0
2330749 <sub> umbrella<pred> on<obj> beach<sub> umbrella<pred> on<obj> beach<sub> umbrella<pred> on<obj> beach<sub> umbrella<pred> on<obj> beach<sub> umbrella<pred> on<obj> beach<sub> umbrella<pred> on<obj> beach<sub> umbrella<pred> on<obj> beach<sub> umbrella<pred> on<obj> beach<sub> umbrella<pred> on<obj> beach<sub> umbrella<pred> on<obj> beach<sub> umbrella<pred> on<obj> beach ['<sub> window<pred> of<obj> building<sub> window<pred> on<obj> building<sub> window<pred> on<obj> building<sub> window<pred> on<obj> building<sub> window<pred> of<obj> building<sub> window<pred> of<obj> building<sub> window<pred> on<obj> building<sub> sign<pred> on<obj> pole<sub> window<pred> on<obj> building<sub> window<pred> on<obj> building<sub> window<pred> on<obj> building<sub> window<pred> on<obj> building<sub> building<pred> has<obj> window<sub> window<pred> on<obj> building']
2023-05-27 02:45:07 - progress_bar.py[line:272] - INFO: epoch 030 | valid on 'valid' subset:   1051 / 2860 loss=2.263, loss_v1=0, loss_v2=0, nll_loss=1.024, ntokens=298, nsentences=8, sample_size=298, sample_size_v1=0, sample_size_v2=0
2023-05-27 02:45:15 - progress_bar.py[line:272] - INFO: epoch 030 | valid on 'valid' subset:   1061 / 2860 loss=2.24, loss_v1=0, loss_v2=0, nll_loss=0.99, ntokens=224, nsentences=8, sample_size=224, sample_size_v1=0, sample_size_v2=0
2023-05-27 02:45:23 - progress_bar.py[line:272] - INFO: epoch 030 | valid on 'valid' subset:   1071 / 2860 loss=2.33, loss_v1=0, loss_v2=0, nll_loss=1.1, ntokens=153, nsentences=8, sample_size=153, sample_size_v1=0, sample_size_v2=0
2023-05-27 02:45:32 - progress_bar.py[line:272] - INFO: epoch 030 | valid on 'valid' subset:   1081 / 2860 loss=2.235, loss_v1=0, loss_v2=0, nll_loss=0.993, ntokens=324, nsentences=8, sample_size=324, sample_size_v1=0, sample_size_v2=0
2023-05-27 02:45:42 - progress_bar.py[line:272] - INFO: epoch 030 | valid on 'valid' subset:   1091 / 2860 loss=2.232, loss_v1=0, loss_v2=0, nll_loss=0.99, ntokens=198, nsentences=8, sample_size=198, sample_size_v1=0, sample_size_v2=0
2330046 <sub> sign<pred> on<obj> pole<sub> car<pred> on<obj> street ['<sub> car<pred> on<obj> street<sub> car<pred> on<obj> street']
2023-05-27 02:45:50 - progress_bar.py[line:272] - INFO: epoch 030 | valid on 'valid' subset:   1101 / 2860 loss=2.527, loss_v1=0, loss_v2=0, nll_loss=1.323, ntokens=205, nsentences=8, sample_size=205, sample_size_v1=0, sample_size_v2=0
2023-05-27 02:45:59 - progress_bar.py[line:272] - INFO: epoch 030 | valid on 'valid' subset:   1111 / 2860 loss=2.615, loss_v1=0, loss_v2=0, nll_loss=1.421, ntokens=147, nsentences=8, sample_size=147, sample_size_v1=0, sample_size_v2=0
2023-05-27 02:46:07 - progress_bar.py[line:272] - INFO: epoch 030 | valid on 'valid' subset:   1121 / 2860 loss=2.518, loss_v1=0, loss_v2=0, nll_loss=1.307, ntokens=229, nsentences=8, sample_size=229, sample_size_v1=0, sample_size_v2=0
2023-05-27 02:46:16 - progress_bar.py[line:272] - INFO: epoch 030 | valid on 'valid' subset:   1131 / 2860 loss=2.432, loss_v1=0, loss_v2=0, nll_loss=1.214, ntokens=325, nsentences=8, sample_size=325, sample_size_v1=0, sample_size_v2=0
2023-05-27 02:46:24 - progress_bar.py[line:272] - INFO: epoch 030 | valid on 'valid' subset:   1141 / 2860 loss=2.345, loss_v1=0, loss_v2=0, nll_loss=1.116, ntokens=242, nsentences=8, sample_size=242, sample_size_v1=0, sample_size_v2=0
2329338 <sub> vase<pred> on<obj> table<sub> flower<pred> in<obj> vase<sub> flower<pred> in<obj> vase<sub> flower<pred> in<obj> vase<sub> vase<pred> on<obj> table<sub> leaf<pred> in<obj> vase<sub> leaf<pred> in<obj> vase<sub> leaf<pred> in<obj> vase ['<sub> vase<pred> of<obj> flower<pred> on<obj> table<sub> flower<pred> in<obj> vase<sub> flower<pred> in<obj> vase<sub> flower<pred> in<obj> vase']
2023-05-27 02:46:33 - progress_bar.py[line:272] - INFO: epoch 030 | valid on 'valid' subset:   1151 / 2860 loss=2.294, loss_v1=0, loss_v2=0, nll_loss=1.057, ntokens=332, nsentences=8, sample_size=332, sample_size_v1=0, sample_size_v2=0
2023-05-27 02:46:41 - progress_bar.py[line:272] - INFO: epoch 030 | valid on 'valid' subset:   1161 / 2860 loss=2.441, loss_v1=0, loss_v2=0, nll_loss=1.231, ntokens=186, nsentences=8, sample_size=186, sample_size_v1=0, sample_size_v2=0
2023-05-27 02:46:51 - progress_bar.py[line:272] - INFO: epoch 030 | valid on 'valid' subset:   1171 / 2860 loss=2.362, loss_v1=0, loss_v2=0, nll_loss=1.134, ntokens=390, nsentences=8, sample_size=390, sample_size_v1=0, sample_size_v2=0
2023-05-27 02:47:01 - progress_bar.py[line:272] - INFO: epoch 030 | valid on 'valid' subset:   1181 / 2860 loss=2.355, loss_v1=0, loss_v2=0, nll_loss=1.119, ntokens=308, nsentences=8, sample_size=308, sample_size_v1=0, sample_size_v2=0
2023-05-27 02:47:10 - progress_bar.py[line:272] - INFO: epoch 030 | valid on 'valid' subset:   1191 / 2860 loss=2.499, loss_v1=0, loss_v2=0, nll_loss=1.29, ntokens=379, nsentences=8, sample_size=379, sample_size_v1=0, sample_size_v2=0
2328738 <sub> head<pred> of<obj> horse<sub> leg<pred> of<obj> horse<sub> leg<pred> of<obj> horse<sub> leg<pred> of<obj> horse<sub> leg<pred> of<obj> horse<sub> leg<pred> of<obj> horse<sub> leg<pred> of<obj> horse<sub> horse<pred> has<obj> leg<pred> has<obj> leg<pred> has<obj> leg<pred> has<obj> leg<pred> has<obj> leg<pred> has<obj> leg<pred> has<obj> leg<sub> horse<pred> has<obj> leg<pred> has<obj> leg<pred> has<obj> leg<pred> has<obj> leg ['<sub> trunk<pred> on<obj> elephant<sub> person<pred> wearing<obj> hat<sub> person<pred> wearing<obj> shirt<sub> person<pred> riding<obj> elephant<sub> head<pred> of<obj> elephant<sub> head<pred> of<obj> elephant<sub> eye<pred> of<obj> elephant<sub> elephant<pred> has<obj> trunk<sub> mouth<pred> of<obj> elephant<sub> leg<pred> of<obj> elephant']
2023-05-27 02:47:20 - progress_bar.py[line:272] - INFO: epoch 030 | valid on 'valid' subset:   1201 / 2860 loss=2.499, loss_v1=0, loss_v2=0, nll_loss=1.292, ntokens=334, nsentences=8, sample_size=334, sample_size_v1=0, sample_size_v2=0
2023-05-27 02:47:29 - progress_bar.py[line:272] - INFO: epoch 030 | valid on 'valid' subset:   1211 / 2860 loss=2.494, loss_v1=0, loss_v2=0, nll_loss=1.28, ntokens=179, nsentences=8, sample_size=179, sample_size_v1=0, sample_size_v2=0
2023-05-27 02:47:39 - progress_bar.py[line:272] - INFO: epoch 030 | valid on 'valid' subset:   1221 / 2860 loss=2.289, loss_v1=0, loss_v2=0, nll_loss=1.055, ntokens=454, nsentences=8, sample_size=454, sample_size_v1=0, sample_size_v2=0
2023-05-27 02:47:49 - progress_bar.py[line:272] - INFO: epoch 030 | valid on 'valid' subset:   1231 / 2860 loss=2.387, loss_v1=0, loss_v2=0, nll_loss=1.168, ntokens=334, nsentences=8, sample_size=334, sample_size_v1=0, sample_size_v2=0
2023-05-27 02:47:58 - progress_bar.py[line:272] - INFO: epoch 030 | valid on 'valid' subset:   1241 / 2860 loss=2.378, loss_v1=0, loss_v2=0, nll_loss=1.151, ntokens=257, nsentences=8, sample_size=257, sample_size_v1=0, sample_size_v2=0
2328121 <sub> pizza<pred> on<obj> plate<pred> on<obj> table<sub> glass<pred> on<obj> table<sub> plate<pred> on<obj> table<sub> plate<pred> on<obj> table<sub> glass<pred> on<obj> table ['<sub> food<pred> sitting on<obj> table<sub> leaf<pred> on<obj> table<sub> food<pred> sitting on<obj> plate<sub> food<pred> sitting on<obj> table']
2023-05-27 02:48:09 - progress_bar.py[line:272] - INFO: epoch 030 | valid on 'valid' subset:   1251 / 2860 loss=2.428, loss_v1=0, loss_v2=0, nll_loss=1.205, ntokens=285, nsentences=8, sample_size=285, sample_size_v1=0, sample_size_v2=0
2023-05-27 02:48:18 - progress_bar.py[line:272] - INFO: epoch 030 | valid on 'valid' subset:   1261 / 2860 loss=2.288, loss_v1=0, loss_v2=0, nll_loss=1.055, ntokens=233, nsentences=8, sample_size=233, sample_size_v1=0, sample_size_v2=0
2023-05-27 02:48:27 - progress_bar.py[line:272] - INFO: epoch 030 | valid on 'valid' subset:   1271 / 2860 loss=2.347, loss_v1=0, loss_v2=0, nll_loss=1.113, ntokens=231, nsentences=8, sample_size=231, sample_size_v1=0, sample_size_v2=0
2023-05-27 02:48:36 - progress_bar.py[line:272] - INFO: epoch 030 | valid on 'valid' subset:   1281 / 2860 loss=2.439, loss_v1=0, loss_v2=0, nll_loss=1.22, ntokens=225, nsentences=8, sample_size=225, sample_size_v1=0, sample_size_v2=0
2023-05-27 02:48:46 - progress_bar.py[line:272] - INFO: epoch 030 | valid on 'valid' subset:   1291 / 2860 loss=2.441, loss_v1=0, loss_v2=0, nll_loss=1.228, ntokens=215, nsentences=8, sample_size=215, sample_size_v1=0, sample_size_v2=0
2327533 <sub> eye<pred> on<obj> cat<sub> ear<pred> on<obj> cat<sub> ear<pred> on<obj> cat<sub> ear<pred> on<obj> cat<sub> ear<pred> on<obj> cat ['<sub> tail<pred> of<obj> cat<sub> neck<pred> of<obj> cat<sub> ear<pred> of<obj> cat']
2023-05-27 02:48:57 - progress_bar.py[line:272] - INFO: epoch 030 | valid on 'valid' subset:   1301 / 2860 loss=2.351, loss_v1=0, loss_v2=0, nll_loss=1.119, ntokens=339, nsentences=8, sample_size=339, sample_size_v1=0, sample_size_v2=0
2023-05-27 02:49:06 - progress_bar.py[line:272] - INFO: epoch 030 | valid on 'valid' subset:   1311 / 2860 loss=2.264, loss_v1=0, loss_v2=0, nll_loss=1.025, ntokens=455, nsentences=8, sample_size=455, sample_size_v1=0, sample_size_v2=0
2023-05-27 02:49:15 - progress_bar.py[line:272] - INFO: epoch 030 | valid on 'valid' subset:   1321 / 2860 loss=2.419, loss_v1=0, loss_v2=0, nll_loss=1.201, ntokens=237, nsentences=8, sample_size=237, sample_size_v1=0, sample_size_v2=0
2023-05-27 02:49:25 - progress_bar.py[line:272] - INFO: epoch 030 | valid on 'valid' subset:   1331 / 2860 loss=2.574, loss_v1=0, loss_v2=0, nll_loss=1.373, ntokens=231, nsentences=8, sample_size=231, sample_size_v1=0, sample_size_v2=0
2023-05-27 02:49:34 - progress_bar.py[line:272] - INFO: epoch 030 | valid on 'valid' subset:   1341 / 2860 loss=2.364, loss_v1=0, loss_v2=0, nll_loss=1.127, ntokens=254, nsentences=8, sample_size=254, sample_size_v1=0, sample_size_v2=0
2326906 <sub> leg<pred> of<obj> dog<sub> leg<pred> of<obj> dog<sub> leg<pred> of<obj> dog<sub> leg<pred> of<obj> dog<sub> head<pred> of<obj> dog<sub> dog<pred> has<obj> tail<pred> has<obj> ear<pred> has<obj> ear<sub> door<pred> behind<obj> dog ['<sub> handle<pred> on<obj> cabinet<pred> on<obj> cabinet<pred> on<obj> door<sub> leg<pred> of<obj> chair<sub> door<pred> with<obj> handle']
2023-05-27 02:49:42 - progress_bar.py[line:272] - INFO: epoch 030 | valid on 'valid' subset:   1351 / 2860 loss=2.663, loss_v1=0, loss_v2=0, nll_loss=1.464, ntokens=215, nsentences=8, sample_size=215, sample_size_v1=0, sample_size_v2=0
2023-05-27 02:49:52 - progress_bar.py[line:272] - INFO: epoch 030 | valid on 'valid' subset:   1361 / 2860 loss=2.487, loss_v1=0, loss_v2=0, nll_loss=1.273, ntokens=263, nsentences=8, sample_size=263, sample_size_v1=0, sample_size_v2=0
2023-05-27 02:50:01 - progress_bar.py[line:272] - INFO: epoch 030 | valid on 'valid' subset:   1371 / 2860 loss=2.372, loss_v1=0, loss_v2=0, nll_loss=1.14, ntokens=217, nsentences=8, sample_size=217, sample_size_v1=0, sample_size_v2=0
2023-05-27 02:50:11 - progress_bar.py[line:272] - INFO: epoch 030 | valid on 'valid' subset:   1381 / 2860 loss=2.396, loss_v1=0, loss_v2=0, nll_loss=1.173, ntokens=258, nsentences=8, sample_size=258, sample_size_v1=0, sample_size_v2=0
2023-05-27 02:50:21 - progress_bar.py[line:272] - INFO: epoch 030 | valid on 'valid' subset:   1391 / 2860 loss=2.464, loss_v1=0, loss_v2=0, nll_loss=1.254, ntokens=218, nsentences=8, sample_size=218, sample_size_v1=0, sample_size_v2=0
2326324 <sub> window<pred> on<obj> building<sub> window<pred> on<obj> building<sub> window<pred> on<obj> building<pred> on<obj> building<sub> window<pred> on<obj> building<sub> window<pred> on<obj> building<sub> window<pred> on<obj> building<sub> window<pred> on<obj> building<sub> window<pred> on<obj> building<sub> window<pred> on<obj> building<sub> window<pred> on<obj> building<sub> window<pred> on<obj> building<sub> window<pred> on<obj> building<sub> window<pred> on<obj> building ['<sub> plant<pred> in<obj> pot<sub> shoe<pred> of<obj> man<sub> shoe<pred> of<obj> man<sub> umbrella<pred> of<obj> man<sub> man<pred> has<obj> leg<pred> wears<obj> glass<pred> wearing<obj> shoe<pred> wearing<obj> pant<pred> wearing<obj> jacket<pred> with<obj> umbrella<pred> holding<obj> umbrella<sub> leg<pred> of<obj> man<sub> jacket<pred> of<obj> man<sub> glass<pred> of<obj> man<sub> shirt<pred> of<obj> man<sub> door<pred> behind<obj> man<pred> with<obj> window<sub> plant<pred> hanging from<obj> pot']
2023-05-27 02:50:31 - progress_bar.py[line:272] - INFO: epoch 030 | valid on 'valid' subset:   1401 / 2860 loss=2.506, loss_v1=0, loss_v2=0, nll_loss=1.301, ntokens=312, nsentences=8, sample_size=312, sample_size_v1=0, sample_size_v2=0
2023-05-27 02:50:41 - progress_bar.py[line:272] - INFO: epoch 030 | valid on 'valid' subset:   1411 / 2860 loss=2.286, loss_v1=0, loss_v2=0, nll_loss=1.05, ntokens=346, nsentences=8, sample_size=346, sample_size_v1=0, sample_size_v2=0
2023-05-27 02:50:52 - progress_bar.py[line:272] - INFO: epoch 030 | valid on 'valid' subset:   1421 / 2860 loss=2.369, loss_v1=0, loss_v2=0, nll_loss=1.141, ntokens=444, nsentences=8, sample_size=444, sample_size_v1=0, sample_size_v2=0
2023-05-27 02:51:02 - progress_bar.py[line:272] - INFO: epoch 030 | valid on 'valid' subset:   1431 / 2860 loss=2.485, loss_v1=0, loss_v2=0, nll_loss=1.267, ntokens=323, nsentences=8, sample_size=323, sample_size_v1=0, sample_size_v2=0
2023-05-27 02:51:12 - progress_bar.py[line:272] - INFO: epoch 030 | valid on 'valid' subset:   1441 / 2860 loss=2.532, loss_v1=0, loss_v2=0, nll_loss=1.323, ntokens=280, nsentences=8, sample_size=280, sample_size_v1=0, sample_size_v2=0
2325736 <sub> man<pred> wearing<obj> shirt<sub> man<pred> wearing<obj> shirt<sub> man<pred> wearing<obj> shirt ['<sub> man<pred> wearing<obj> shoe<pred> wearing<obj> short<pred> in<obj> shirt']
2023-05-27 02:51:21 - progress_bar.py[line:272] - INFO: epoch 030 | valid on 'valid' subset:   1451 / 2860 loss=2.364, loss_v1=0, loss_v2=0, nll_loss=1.137, ntokens=280, nsentences=8, sample_size=280, sample_size_v1=0, sample_size_v2=0
2023-05-27 02:51:30 - progress_bar.py[line:272] - INFO: epoch 030 | valid on 'valid' subset:   1461 / 2860 loss=2.585, loss_v1=0, loss_v2=0, nll_loss=1.387, ntokens=318, nsentences=8, sample_size=318, sample_size_v1=0, sample_size_v2=0
2023-05-27 02:51:40 - progress_bar.py[line:272] - INFO: epoch 030 | valid on 'valid' subset:   1471 / 2860 loss=2.261, loss_v1=0, loss_v2=0, nll_loss=1.027, ntokens=213, nsentences=8, sample_size=213, sample_size_v1=0, sample_size_v2=0
2023-05-27 02:51:49 - progress_bar.py[line:272] - INFO: epoch 030 | valid on 'valid' subset:   1481 / 2860 loss=2.301, loss_v1=0, loss_v2=0, nll_loss=1.065, ntokens=244, nsentences=8, sample_size=244, sample_size_v1=0, sample_size_v2=0
2023-05-27 02:51:59 - progress_bar.py[line:272] - INFO: epoch 030 | valid on 'valid' subset:   1491 / 2860 loss=2.497, loss_v1=0, loss_v2=0, nll_loss=1.289, ntokens=292, nsentences=8, sample_size=292, sample_size_v1=0, sample_size_v2=0
2325142 <sub> man<pred> on<obj> surfboard<pred> on<obj> surfboard<sub> man<pred> on<obj> surfboard ['<sub> person<pred> on<obj> surfboard<sub> person<pred> laying on<obj> surfboard']
2023-05-27 02:52:08 - progress_bar.py[line:272] - INFO: epoch 030 | valid on 'valid' subset:   1501 / 2860 loss=2.367, loss_v1=0, loss_v2=0, nll_loss=1.139, ntokens=216, nsentences=8, sample_size=216, sample_size_v1=0, sample_size_v2=0
2023-05-27 02:52:20 - progress_bar.py[line:272] - INFO: epoch 030 | valid on 'valid' subset:   1511 / 2860 loss=2.396, loss_v1=0, loss_v2=0, nll_loss=1.172, ntokens=336, nsentences=8, sample_size=336, sample_size_v1=0, sample_size_v2=0
2023-05-27 02:52:30 - progress_bar.py[line:272] - INFO: epoch 030 | valid on 'valid' subset:   1521 / 2860 loss=2.409, loss_v1=0, loss_v2=0, nll_loss=1.183, ntokens=302, nsentences=8, sample_size=302, sample_size_v1=0, sample_size_v2=0
2023-05-27 02:52:39 - progress_bar.py[line:272] - INFO: epoch 030 | valid on 'valid' subset:   1531 / 2860 loss=2.262, loss_v1=0, loss_v2=0, nll_loss=1.021, ntokens=399, nsentences=8, sample_size=399, sample_size_v1=0, sample_size_v2=0
2023-05-27 02:52:51 - progress_bar.py[line:272] - INFO: epoch 030 | valid on 'valid' subset:   1541 / 2860 loss=2.444, loss_v1=0, loss_v2=0, nll_loss=1.23, ntokens=329, nsentences=8, sample_size=329, sample_size_v1=0, sample_size_v2=0
2324565 <sub> woman<pred> wearing<obj> shoe<pred> wearing<obj> shoe<pred> holding<obj> racket ['<sub> man<pred> wearing<obj> shoe<pred> wearing<obj> shoe<pred> wearing<obj> sock<sub> player<pred> wearing<obj> shirt<sub> shoe<pred> wearing<obj> shoe']
2023-05-27 02:53:00 - progress_bar.py[line:272] - INFO: epoch 030 | valid on 'valid' subset:   1551 / 2860 loss=2.314, loss_v1=0, loss_v2=0, nll_loss=1.089, ntokens=310, nsentences=8, sample_size=310, sample_size_v1=0, sample_size_v2=0
2023-05-27 02:53:10 - progress_bar.py[line:272] - INFO: epoch 030 | valid on 'valid' subset:   1561 / 2860 loss=2.413, loss_v1=0, loss_v2=0, nll_loss=1.195, ntokens=362, nsentences=8, sample_size=362, sample_size_v1=0, sample_size_v2=0
2023-05-27 02:53:20 - progress_bar.py[line:272] - INFO: epoch 030 | valid on 'valid' subset:   1571 / 2860 loss=2.453, loss_v1=0, loss_v2=0, nll_loss=1.242, ntokens=314, nsentences=8, sample_size=314, sample_size_v1=0, sample_size_v2=0
2023-05-27 02:53:30 - progress_bar.py[line:272] - INFO: epoch 030 | valid on 'valid' subset:   1581 / 2860 loss=2.617, loss_v1=0, loss_v2=0, nll_loss=1.417, ntokens=244, nsentences=8, sample_size=244, sample_size_v1=0, sample_size_v2=0
2023-05-27 02:53:40 - progress_bar.py[line:272] - INFO: epoch 030 | valid on 'valid' subset:   1591 / 2860 loss=2.494, loss_v1=0, loss_v2=0, nll_loss=1.285, ntokens=280, nsentences=8, sample_size=280, sample_size_v1=0, sample_size_v2=0
2323992 <sub> girl<pred> sitting on<obj> bench<sub> girl<pred> sitting on<obj> bench<sub> girl<pred> sitting on<obj> bench<sub> girl<pred> sitting on<obj> bench<sub> girl<pred> sitting on<obj> bench<sub> girl<pred> sitting on<obj> bench<sub> girl<pred> sitting on<obj> bench<sub> girl<pred> sitting on<obj> bench<sub> girl<pred> sitting on<obj> bench<sub> girl<pred> sitting on<obj> bench ['<sub> boy<pred> wearing<obj> shoe<pred> wearing<obj> jean<sub> woman<pred> wearing<obj> shoe<pred> has<obj> head<pred> has<obj> arm<pred> has<obj> arm<pred> has<obj> leg<sub> person<pred> wearing<obj> hat<sub> people<pred> on<obj> bench<sub> cap<pred> on<obj> head<sub> hand<pred> attached to<obj> person<sub> arm<pred> attached to<obj> bench']
2023-05-27 02:53:50 - progress_bar.py[line:272] - INFO: epoch 030 | valid on 'valid' subset:   1601 / 2860 loss=2.6, loss_v1=0, loss_v2=0, nll_loss=1.407, ntokens=284, nsentences=8, sample_size=284, sample_size_v1=0, sample_size_v2=0
2023-05-27 02:53:58 - progress_bar.py[line:272] - INFO: epoch 030 | valid on 'valid' subset:   1611 / 2860 loss=2.551, loss_v1=0, loss_v2=0, nll_loss=1.343, ntokens=201, nsentences=8, sample_size=201, sample_size_v1=0, sample_size_v2=0
2023-05-27 02:54:07 - progress_bar.py[line:272] - INFO: epoch 030 | valid on 'valid' subset:   1621 / 2860 loss=2.404, loss_v1=0, loss_v2=0, nll_loss=1.187, ntokens=258, nsentences=8, sample_size=258, sample_size_v1=0, sample_size_v2=0
2023-05-27 02:54:18 - progress_bar.py[line:272] - INFO: epoch 030 | valid on 'valid' subset:   1631 / 2860 loss=2.492, loss_v1=0, loss_v2=0, nll_loss=1.276, ntokens=250, nsentences=8, sample_size=250, sample_size_v1=0, sample_size_v2=0
2023-05-27 02:54:27 - progress_bar.py[line:272] - INFO: epoch 030 | valid on 'valid' subset:   1641 / 2860 loss=2.458, loss_v1=0, loss_v2=0, nll_loss=1.245, ntokens=288, nsentences=8, sample_size=288, sample_size_v1=0, sample_size_v2=0
2323417 <sub> person<pred> on<obj> surfboard<pred> on<obj> surfboard<sub> man<pred> on<obj> surfboard<sub> person<pred> on<obj> surfboard<sub> person<pred> on<obj> surfboard ['<sub> letter<pred> on<obj> plane<sub> letter<pred> on<obj> plane<sub> tail<pred> on<obj> plane<sub> engine<pred> under<obj> wing<sub> engine<pred> under<obj> wing']
2023-05-27 02:54:37 - progress_bar.py[line:272] - INFO: epoch 030 | valid on 'valid' subset:   1651 / 2860 loss=2.305, loss_v1=0, loss_v2=0, nll_loss=1.073, ntokens=257, nsentences=8, sample_size=257, sample_size_v1=0, sample_size_v2=0
2023-05-27 02:54:47 - progress_bar.py[line:272] - INFO: epoch 030 | valid on 'valid' subset:   1661 / 2860 loss=2.198, loss_v1=0, loss_v2=0, nll_loss=0.953, ntokens=246, nsentences=8, sample_size=246, sample_size_v1=0, sample_size_v2=0
2023-05-27 02:54:57 - progress_bar.py[line:272] - INFO: epoch 030 | valid on 'valid' subset:   1671 / 2860 loss=2.263, loss_v1=0, loss_v2=0, nll_loss=1.027, ntokens=296, nsentences=8, sample_size=296, sample_size_v1=0, sample_size_v2=0
2023-05-27 02:55:06 - progress_bar.py[line:272] - INFO: epoch 030 | valid on 'valid' subset:   1681 / 2860 loss=2.398, loss_v1=0, loss_v2=0, nll_loss=1.177, ntokens=247, nsentences=8, sample_size=247, sample_size_v1=0, sample_size_v2=0
2023-05-27 02:55:15 - progress_bar.py[line:272] - INFO: epoch 030 | valid on 'valid' subset:   1691 / 2860 loss=2.373, loss_v1=0, loss_v2=0, nll_loss=1.148, ntokens=252, nsentences=8, sample_size=252, sample_size_v1=0, sample_size_v2=0
2322823 <sub> head<pred> of<obj> giraffe<sub> leg<pred> of<obj> giraffe<sub> leg<pred> of<obj> giraffe<sub> leg<pred> of<obj> giraffe<sub> leg<pred> of<obj> giraffe ['<sub> flag<pred> on<obj> pole<sub> woman<pred> wearing<obj> boat<pred> wearing<obj> shirt<pred> riding<obj> horse']
2023-05-27 02:55:24 - progress_bar.py[line:272] - INFO: epoch 030 | valid on 'valid' subset:   1701 / 2860 loss=2.289, loss_v1=0, loss_v2=0, nll_loss=1.064, ntokens=282, nsentences=8, sample_size=282, sample_size_v1=0, sample_size_v2=0
2023-05-27 02:55:33 - progress_bar.py[line:272] - INFO: epoch 030 | valid on 'valid' subset:   1711 / 2860 loss=2.473, loss_v1=0, loss_v2=0, nll_loss=1.257, ntokens=268, nsentences=8, sample_size=268, sample_size_v1=0, sample_size_v2=0
2023-05-27 02:55:43 - progress_bar.py[line:272] - INFO: epoch 030 | valid on 'valid' subset:   1721 / 2860 loss=2.298, loss_v1=0, loss_v2=0, nll_loss=1.064, ntokens=418, nsentences=8, sample_size=418, sample_size_v1=0, sample_size_v2=0
2023-05-27 02:55:52 - progress_bar.py[line:272] - INFO: epoch 030 | valid on 'valid' subset:   1731 / 2860 loss=2.375, loss_v1=0, loss_v2=0, nll_loss=1.15, ntokens=251, nsentences=8, sample_size=251, sample_size_v1=0, sample_size_v2=0
2023-05-27 02:56:01 - progress_bar.py[line:272] - INFO: epoch 030 | valid on 'valid' subset:   1741 / 2860 loss=2.37, loss_v1=0, loss_v2=0, nll_loss=1.143, ntokens=267, nsentences=8, sample_size=267, sample_size_v1=0, sample_size_v2=0
2322253 <sub> nose<pred> of<obj> man<sub> eye<pred> of<obj> man<sub> eye<pred> of<obj> man<sub> eye<pred> of<obj> man<sub> eye<pred> of<obj> man<sub> eye<pred> of<obj> man<sub> nose<pred> of<obj> man<sub> mouth<pred> of<obj> man<sub> ear<pred> of<obj> man<sub> ear<pred> of<obj> man<sub> mouth<pred> of<obj> man<sub> hair<pred> of<obj> man<sub> eye<pred> of<obj> man<sub> ear<pred> of<obj> man<sub> man<pred> wearing<obj> shirt ['<sub> person<pred> wearing<obj> hat<pred> wearing<obj> shirt<sub> person<pred> wearing<obj> shirt<pred> carrying<obj> coat<pred> has<obj> bag<sub> shelf<pred> behind<obj> man<sub> man<pred> has<obj> hair<pred> has<obj> shirt<sub> eye<pred> of<obj> man']
2023-05-27 02:56:11 - progress_bar.py[line:272] - INFO: epoch 030 | valid on 'valid' subset:   1751 / 2860 loss=2.587, loss_v1=0, loss_v2=0, nll_loss=1.391, ntokens=262, nsentences=8, sample_size=262, sample_size_v1=0, sample_size_v2=0
2023-05-27 02:56:20 - progress_bar.py[line:272] - INFO: epoch 030 | valid on 'valid' subset:   1761 / 2860 loss=2.434, loss_v1=0, loss_v2=0, nll_loss=1.212, ntokens=235, nsentences=8, sample_size=235, sample_size_v1=0, sample_size_v2=0
2023-05-27 02:56:29 - progress_bar.py[line:272] - INFO: epoch 030 | valid on 'valid' subset:   1771 / 2860 loss=2.409, loss_v1=0, loss_v2=0, nll_loss=1.188, ntokens=237, nsentences=8, sample_size=237, sample_size_v1=0, sample_size_v2=0
2023-05-27 02:56:39 - progress_bar.py[line:272] - INFO: epoch 030 | valid on 'valid' subset:   1781 / 2860 loss=2.364, loss_v1=0, loss_v2=0, nll_loss=1.139, ntokens=283, nsentences=8, sample_size=283, sample_size_v1=0, sample_size_v2=0
2023-05-27 02:56:48 - progress_bar.py[line:272] - INFO: epoch 030 | valid on 'valid' subset:   1791 / 2860 loss=2.511, loss_v1=0, loss_v2=0, nll_loss=1.303, ntokens=288, nsentences=8, sample_size=288, sample_size_v1=0, sample_size_v2=0
2321694 <sub> man<pred> on<obj> elephant<pred> wearing<obj> hat<pred> wearing<obj> shirt<pred> wearing<obj> pant<sub> elephant<pred> has<obj> trunk<pred> has<obj> ear<pred> has<obj> ear<pred> has<obj> leg<pred> has<obj> leg<pred> has<obj> leg<pred> has<obj> leg<pred> has<obj> leg<pred> has<obj> leg<sub> elephant<pred> has<obj> leg<pred> has<obj> leg<pred> has<obj> leg ['<sub> people<pred> on<obj> seat<sub> woman<pred> sitting on<obj> elephant<sub> trunk<pred> of<obj> elephant<sub> eye<pred> of<obj> elephant<sub> ear<pred> of<obj> elephant<sub> man<pred> sitting on<obj> elephant<sub> eye<pred> on<obj> elephant<sub> leaf<pred> in<obj> tree']
2023-05-27 02:56:58 - progress_bar.py[line:272] - INFO: epoch 030 | valid on 'valid' subset:   1801 / 2860 loss=2.356, loss_v1=0, loss_v2=0, nll_loss=1.124, ntokens=240, nsentences=8, sample_size=240, sample_size_v1=0, sample_size_v2=0
2023-05-27 02:57:07 - progress_bar.py[line:272] - INFO: epoch 030 | valid on 'valid' subset:   1811 / 2860 loss=2.148, loss_v1=0, loss_v2=0, nll_loss=0.901, ntokens=282, nsentences=8, sample_size=282, sample_size_v1=0, sample_size_v2=0
2023-05-27 02:57:17 - progress_bar.py[line:272] - INFO: epoch 030 | valid on 'valid' subset:   1821 / 2860 loss=2.232, loss_v1=0, loss_v2=0, nll_loss=0.992, ntokens=378, nsentences=8, sample_size=378, sample_size_v1=0, sample_size_v2=0
2023-05-27 02:57:28 - progress_bar.py[line:272] - INFO: epoch 030 | valid on 'valid' subset:   1831 / 2860 loss=2.358, loss_v1=0, loss_v2=0, nll_loss=1.123, ntokens=383, nsentences=8, sample_size=383, sample_size_v1=0, sample_size_v2=0
2023-05-27 02:57:38 - progress_bar.py[line:272] - INFO: epoch 030 | valid on 'valid' subset:   1841 / 2860 loss=2.372, loss_v1=0, loss_v2=0, nll_loss=1.152, ntokens=260, nsentences=8, sample_size=260, sample_size_v1=0, sample_size_v2=0
2321117 <sub> leaf<pred> on<obj> tree<sub> leaf<pred> on<obj> tree<sub> leaf<pred> on<obj> tree<sub> leaf<pred> on<obj> tree<sub> leaf<pred> on<obj> tree<sub> leaf<pred> on<obj> tree<sub> leaf<pred> on<obj> tree<sub> leaf<pred> on<obj> tree<sub> leaf<pred> on<obj> tree<sub> leaf<pred> on<obj> tree ['<sub> man<pred> wearing<obj> short<pred> wearing<obj> hat<sub> woman<pred> wearing<obj> shirt<pred> wearing<obj> sneaker<sub> man<pred> at<obj> fence<pred> wearing<obj> shirt<sub> shirt<pred> on<obj> player<sub> short<pred> on<obj> player<sub> lady<pred> at<obj> fence<sub> sneaker<pred> on<obj> man<sub> man<pred> holding<obj> racket']
2023-05-27 02:57:47 - progress_bar.py[line:272] - INFO: epoch 030 | valid on 'valid' subset:   1851 / 2860 loss=2.506, loss_v1=0, loss_v2=0, nll_loss=1.297, ntokens=305, nsentences=8, sample_size=305, sample_size_v1=0, sample_size_v2=0
2023-05-27 02:57:57 - progress_bar.py[line:272] - INFO: epoch 030 | valid on 'valid' subset:   1861 / 2860 loss=2.209, loss_v1=0, loss_v2=0, nll_loss=0.96, ntokens=271, nsentences=8, sample_size=271, sample_size_v1=0, sample_size_v2=0
2023-05-27 02:58:07 - progress_bar.py[line:272] - INFO: epoch 030 | valid on 'valid' subset:   1871 / 2860 loss=2.465, loss_v1=0, loss_v2=0, nll_loss=1.25, ntokens=263, nsentences=8, sample_size=263, sample_size_v1=0, sample_size_v2=0
2023-05-27 02:58:16 - progress_bar.py[line:272] - INFO: epoch 030 | valid on 'valid' subset:   1881 / 2860 loss=2.629, loss_v1=0, loss_v2=0, nll_loss=1.434, ntokens=422, nsentences=8, sample_size=422, sample_size_v1=0, sample_size_v2=0
2023-05-27 02:58:27 - progress_bar.py[line:272] - INFO: epoch 030 | valid on 'valid' subset:   1891 / 2860 loss=2.473, loss_v1=0, loss_v2=0, nll_loss=1.256, ntokens=379, nsentences=8, sample_size=379, sample_size_v1=0, sample_size_v2=0
2320545 <sub> leaf<pred> of<obj> plant<sub> leaf<pred> of<obj> plant<sub> leaf<pred> of<obj> plant<sub> leaf<pred> of<obj> plant<sub> leaf<pred> of<obj> plant<sub> leaf<pred> of<obj> plant ['<sub> bird<pred> with<obj> head<pred> on<obj> branch<sub> bird<pred> with<obj> head<sub> bird<pred> with<obj> wing<pred> on<obj> branch<sub> bird<pred> with<obj> wing<pred> on<obj> branch<sub> tail<pred> of<obj> bird<sub> bird<pred> sitting on<obj> branch<sub> bird<pred> on<obj> branch<sub> bird<pred> on<obj> branch<sub> bird<pred> sitting on<obj> branch']
2023-05-27 02:58:38 - progress_bar.py[line:272] - INFO: epoch 030 | valid on 'valid' subset:   1901 / 2860 loss=2.451, loss_v1=0, loss_v2=0, nll_loss=1.237, ntokens=411, nsentences=8, sample_size=411, sample_size_v1=0, sample_size_v2=0
2023-05-27 02:58:49 - progress_bar.py[line:272] - INFO: epoch 030 | valid on 'valid' subset:   1911 / 2860 loss=2.21, loss_v1=0, loss_v2=0, nll_loss=0.968, ntokens=279, nsentences=8, sample_size=279, sample_size_v1=0, sample_size_v2=0
2023-05-27 02:59:00 - progress_bar.py[line:272] - INFO: epoch 030 | valid on 'valid' subset:   1921 / 2860 loss=2.23, loss_v1=0, loss_v2=0, nll_loss=0.993, ntokens=490, nsentences=8, sample_size=490, sample_size_v1=0, sample_size_v2=0
2023-05-27 02:59:11 - progress_bar.py[line:272] - INFO: epoch 030 | valid on 'valid' subset:   1931 / 2860 loss=2.323, loss_v1=0, loss_v2=0, nll_loss=1.099, ntokens=340, nsentences=8, sample_size=340, sample_size_v1=0, sample_size_v2=0
2023-05-27 02:59:22 - progress_bar.py[line:272] - INFO: epoch 030 | valid on 'valid' subset:   1941 / 2860 loss=2.619, loss_v1=0, loss_v2=0, nll_loss=1.422, ntokens=347, nsentences=8, sample_size=347, sample_size_v1=0, sample_size_v2=0
2319990 <sub> plane<pred> has<obj> tail<pred> has<obj> wing<pred> has<obj> engine ['<sub> engine<pred> on<obj> plane<sub> engine<pred> on<obj> plane']
2023-05-27 02:59:32 - progress_bar.py[line:272] - INFO: epoch 030 | valid on 'valid' subset:   1951 / 2860 loss=2.275, loss_v1=0, loss_v2=0, nll_loss=1.039, ntokens=311, nsentences=8, sample_size=311, sample_size_v1=0, sample_size_v2=0
2023-05-27 02:59:43 - progress_bar.py[line:272] - INFO: epoch 030 | valid on 'valid' subset:   1961 / 2860 loss=2.45, loss_v1=0, loss_v2=0, nll_loss=1.234, ntokens=345, nsentences=8, sample_size=345, sample_size_v1=0, sample_size_v2=0
2023-05-27 02:59:52 - progress_bar.py[line:272] - INFO: epoch 030 | valid on 'valid' subset:   1971 / 2860 loss=2.429, loss_v1=0, loss_v2=0, nll_loss=1.211, ntokens=220, nsentences=8, sample_size=220, sample_size_v1=0, sample_size_v2=0
2023-05-27 03:00:03 - progress_bar.py[line:272] - INFO: epoch 030 | valid on 'valid' subset:   1981 / 2860 loss=2.469, loss_v1=0, loss_v2=0, nll_loss=1.254, ntokens=412, nsentences=8, sample_size=412, sample_size_v1=0, sample_size_v2=0
2023-05-27 03:00:13 - progress_bar.py[line:272] - INFO: epoch 030 | valid on 'valid' subset:   1991 / 2860 loss=2.348, loss_v1=0, loss_v2=0, nll_loss=1.117, ntokens=152, nsentences=8, sample_size=152, sample_size_v1=0, sample_size_v2=0
2319454 <sub> pillow<pred> on<obj> bed<sub> pillow<pred> on<obj> bed<sub> pillow<pred> on<obj> bed<sub> pillow<pred> on<obj> bed<sub> pillow<pred> on<obj> bed<sub> pillow<pred> on<obj> bed ['<sub> bear<pred> has<obj> head<sub> leg<pred> of<obj> bear<sub> leg<pred> of<obj> bear<sub> leg<pred> of<obj> bear<sub> ear<pred> of<obj> bear<sub> eye<pred> of<obj> bear<sub> head<pred> of<obj> bear']
2023-05-27 03:00:23 - progress_bar.py[line:272] - INFO: epoch 030 | valid on 'valid' subset:   2001 / 2860 loss=2.235, loss_v1=0, loss_v2=0, nll_loss=0.993, ntokens=245, nsentences=8, sample_size=245, sample_size_v1=0, sample_size_v2=0
2023-05-27 03:00:33 - progress_bar.py[line:272] - INFO: epoch 030 | valid on 'valid' subset:   2011 / 2860 loss=2.305, loss_v1=0, loss_v2=0, nll_loss=1.074, ntokens=416, nsentences=8, sample_size=416, sample_size_v1=0, sample_size_v2=0
2023-05-27 03:00:43 - progress_bar.py[line:272] - INFO: epoch 030 | valid on 'valid' subset:   2021 / 2860 loss=2.275, loss_v1=0, loss_v2=0, nll_loss=1.034, ntokens=246, nsentences=8, sample_size=246, sample_size_v1=0, sample_size_v2=0
2023-05-27 03:00:53 - progress_bar.py[line:272] - INFO: epoch 030 | valid on 'valid' subset:   2031 / 2860 loss=2.26, loss_v1=0, loss_v2=0, nll_loss=1.021, ntokens=245, nsentences=8, sample_size=245, sample_size_v1=0, sample_size_v2=0
2023-05-27 03:01:03 - progress_bar.py[line:272] - INFO: epoch 030 | valid on 'valid' subset:   2041 / 2860 loss=2.564, loss_v1=0, loss_v2=0, nll_loss=1.361, ntokens=333, nsentences=8, sample_size=333, sample_size_v1=0, sample_size_v2=0
2318906 <sub> head<pred> of<obj> child<sub> hand<pred> of<obj> child<sub> hand<pred> of<obj> child<sub> arm<pred> of<obj> child<sub> arm<pred> of<obj> child<sub> arm<pred> of<obj> child<sub> arm<pred> of<obj> child<sub> arm<pred> of<obj> child<sub> arm<pred> of<obj> child<sub> arm<pred> of<obj> child<sub> arm<pred> of<obj> child<sub> arm<pred> of<obj> child<sub> arm<pred> of<obj> child<sub> arm<pred> of<obj> child<sub> arm<pred> of<obj> child ['<sub> food<pred> on<obj> plate<sub> pizza<pred> on<obj> food<sub> pant<pred> on<obj> man<sub> hand<pred> of<obj> man<pred> with<obj> shirt<pred> near<obj> plate<sub> man<pred> has<obj> arm<pred> has<obj> nose<pred> wearing<obj> shirt<pred> holding<obj> plate<pred> eating<obj> food<sub> person<pred> has<obj> finger<sub> leg<pred> of<obj> man<sub> leg<pred> of<obj> man<sub> man<pred> wearing<obj> jacket<sub> hair<pred> on<obj> man<sub> towel<pred> on<obj> man']
2023-05-27 03:01:14 - progress_bar.py[line:272] - INFO: epoch 030 | valid on 'valid' subset:   2051 / 2860 loss=2.479, loss_v1=0, loss_v2=0, nll_loss=1.269, ntokens=431, nsentences=8, sample_size=431, sample_size_v1=0, sample_size_v2=0
2023-05-27 03:01:25 - progress_bar.py[line:272] - INFO: epoch 030 | valid on 'valid' subset:   2061 / 2860 loss=2.375, loss_v1=0, loss_v2=0, nll_loss=1.154, ntokens=289, nsentences=8, sample_size=289, sample_size_v1=0, sample_size_v2=0
2023-05-27 03:01:35 - progress_bar.py[line:272] - INFO: epoch 030 | valid on 'valid' subset:   2071 / 2860 loss=2.459, loss_v1=0, loss_v2=0, nll_loss=1.245, ntokens=366, nsentences=8, sample_size=366, sample_size_v1=0, sample_size_v2=0
2023-05-27 03:01:44 - progress_bar.py[line:272] - INFO: epoch 030 | valid on 'valid' subset:   2081 / 2860 loss=2.349, loss_v1=0, loss_v2=0, nll_loss=1.114, ntokens=273, nsentences=8, sample_size=273, sample_size_v1=0, sample_size_v2=0
2023-05-27 03:01:55 - progress_bar.py[line:272] - INFO: epoch 030 | valid on 'valid' subset:   2091 / 2860 loss=2.338, loss_v1=0, loss_v2=0, nll_loss=1.106, ntokens=341, nsentences=8, sample_size=341, sample_size_v1=0, sample_size_v2=0
2318364 <sub> cow<pred> on<obj> hill<sub> head<pred> of<obj> cow<sub> leg<pred> of<obj> cow<sub> leg<pred> of<obj> cow ['<sub> dog<pred> on<obj> beach<pred> has<obj> leg<pred> has<obj> leg<pred> has<obj> ear<pred> has<obj> ear']
2023-05-27 03:02:04 - progress_bar.py[line:272] - INFO: epoch 030 | valid on 'valid' subset:   2101 / 2860 loss=2.263, loss_v1=0, loss_v2=0, nll_loss=1.018, ntokens=303, nsentences=8, sample_size=303, sample_size_v1=0, sample_size_v2=0
2023-05-27 03:02:15 - progress_bar.py[line:272] - INFO: epoch 030 | valid on 'valid' subset:   2111 / 2860 loss=2.383, loss_v1=0, loss_v2=0, nll_loss=1.155, ntokens=254, nsentences=8, sample_size=254, sample_size_v1=0, sample_size_v2=0
2023-05-27 03:02:24 - progress_bar.py[line:272] - INFO: epoch 030 | valid on 'valid' subset:   2121 / 2860 loss=2.412, loss_v1=0, loss_v2=0, nll_loss=1.191, ntokens=352, nsentences=8, sample_size=352, sample_size_v1=0, sample_size_v2=0
2023-05-27 03:02:35 - progress_bar.py[line:272] - INFO: epoch 030 | valid on 'valid' subset:   2131 / 2860 loss=2.432, loss_v1=0, loss_v2=0, nll_loss=1.214, ntokens=337, nsentences=8, sample_size=337, sample_size_v1=0, sample_size_v2=0
2023-05-27 03:02:45 - progress_bar.py[line:272] - INFO: epoch 030 | valid on 'valid' subset:   2141 / 2860 loss=2.639, loss_v1=0, loss_v2=0, nll_loss=1.446, ntokens=259, nsentences=8, sample_size=259, sample_size_v1=0, sample_size_v2=0
2317864 <sub> people<pred> walking on<obj> sidewalk<sub> car<pred> on<obj> street<sub> car<pred> on<obj> street<sub> car<pred> on<obj> street<sub> car<pred> on<obj> street<sub> car<pred> on<obj> street ['<sub> bird<pred> standing on<obj> boat<sub> bird<pred> on<obj> boat<pred> on<obj> boat<sub> bird<pred> standing on<obj> boat<sub> bird<pred> standing on<obj> boat<sub> roof<pred> on<obj> building<sub> bird<pred> in<obj> boat<sub> bird<pred> on<obj> boat']
2023-05-27 03:02:55 - progress_bar.py[line:272] - INFO: epoch 030 | valid on 'valid' subset:   2151 / 2860 loss=2.372, loss_v1=0, loss_v2=0, nll_loss=1.15, ntokens=419, nsentences=8, sample_size=419, sample_size_v1=0, sample_size_v2=0
2023-05-27 03:03:06 - progress_bar.py[line:272] - INFO: epoch 030 | valid on 'valid' subset:   2161 / 2860 loss=2.365, loss_v1=0, loss_v2=0, nll_loss=1.137, ntokens=309, nsentences=8, sample_size=309, sample_size_v1=0, sample_size_v2=0
2023-05-27 03:03:16 - progress_bar.py[line:272] - INFO: epoch 030 | valid on 'valid' subset:   2171 / 2860 loss=2.324, loss_v1=0, loss_v2=0, nll_loss=1.095, ntokens=228, nsentences=8, sample_size=228, sample_size_v1=0, sample_size_v2=0
2023-05-27 03:03:27 - progress_bar.py[line:272] - INFO: epoch 030 | valid on 'valid' subset:   2181 / 2860 loss=2.164, loss_v1=0, loss_v2=0, nll_loss=0.917, ntokens=290, nsentences=8, sample_size=290, sample_size_v1=0, sample_size_v2=0
2023-05-27 03:03:37 - progress_bar.py[line:272] - INFO: epoch 030 | valid on 'valid' subset:   2191 / 2860 loss=2.507, loss_v1=0, loss_v2=0, nll_loss=1.295, ntokens=368, nsentences=8, sample_size=368, sample_size_v1=0, sample_size_v2=0
2317347 <sub> pizza<pred> on<obj> plate<sub> plate<pred> on<obj> table ['<sub> pizza<pred> above<obj> plate']
2023-05-27 03:03:47 - progress_bar.py[line:272] - INFO: epoch 030 | valid on 'valid' subset:   2201 / 2860 loss=2.332, loss_v1=0, loss_v2=0, nll_loss=1.1, ntokens=257, nsentences=8, sample_size=257, sample_size_v1=0, sample_size_v2=0
2023-05-27 03:03:58 - progress_bar.py[line:272] - INFO: epoch 030 | valid on 'valid' subset:   2211 / 2860 loss=2.408, loss_v1=0, loss_v2=0, nll_loss=1.188, ntokens=341, nsentences=8, sample_size=341, sample_size_v1=0, sample_size_v2=0
2023-05-27 03:04:09 - progress_bar.py[line:272] - INFO: epoch 030 | valid on 'valid' subset:   2221 / 2860 loss=2.385, loss_v1=0, loss_v2=0, nll_loss=1.161, ntokens=294, nsentences=8, sample_size=294, sample_size_v1=0, sample_size_v2=0
2023-05-27 03:04:20 - progress_bar.py[line:272] - INFO: epoch 030 | valid on 'valid' subset:   2231 / 2860 loss=2.377, loss_v1=0, loss_v2=0, nll_loss=1.154, ntokens=342, nsentences=8, sample_size=342, sample_size_v1=0, sample_size_v2=0
2023-05-27 03:04:30 - progress_bar.py[line:272] - INFO: epoch 030 | valid on 'valid' subset:   2241 / 2860 loss=2.357, loss_v1=0, loss_v2=0, nll_loss=1.124, ntokens=329, nsentences=8, sample_size=329, sample_size_v1=0, sample_size_v2=0
2316840 <sub> tree<pred> covered in<obj> snow<sub> tree<pred> covered in<obj> snow<sub> tree<pred> covered in<obj> snow<sub> tree<pred> covered in<obj> snow<sub> tree<pred> covered in<obj> snow<sub> tree<pred> covered in<obj> snow<sub> tree<pred> covered in<obj> snow<sub> tree<pred> covered in<obj> snow<sub> tree<pred> covered in<obj> snow<sub> tree<pred> covered in<obj> snow<sub> tree<pred> covered in<obj> snow<sub> tree<pred> covered in<obj> snow<sub> tree<pred> covered in<obj> snow<sub> tree<pred> covered in<obj> snow<sub> tree ['<sub> man<pred> in<obj> snow<sub> man<pred> in<obj> snow<pred> wearing<obj> jacket<sub> man<pred> in<obj> snow<sub> man<pred> wearing<obj> jacket<sub> guy<pred> in<obj> snow<sub> snow<pred> in<obj> tree<pred> on<obj> snow<pred> in<obj> tree<pred> in<obj> tree<pred> in<obj> tree<pred> in<obj> tree<pred> in<obj> tree<sub> guy<pred> wearing<obj> jacket<sub> man<pred> in<obj> snow<pred> in<obj> jacket<sub> man<pred> sitting on<obj> snow<sub> tree<pred> behind<obj> man<sub> people<pred> on<obj> snow']
2023-05-27 03:04:41 - progress_bar.py[line:272] - INFO: epoch 030 | valid on 'valid' subset:   2251 / 2860 loss=2.467, loss_v1=0, loss_v2=0, nll_loss=1.253, ntokens=500, nsentences=8, sample_size=500, sample_size_v1=0, sample_size_v2=0
2023-05-27 03:04:51 - progress_bar.py[line:272] - INFO: epoch 030 | valid on 'valid' subset:   2261 / 2860 loss=2.352, loss_v1=0, loss_v2=0, nll_loss=1.129, ntokens=249, nsentences=8, sample_size=249, sample_size_v1=0, sample_size_v2=0
2023-05-27 03:05:01 - progress_bar.py[line:272] - INFO: epoch 030 | valid on 'valid' subset:   2271 / 2860 loss=2.398, loss_v1=0, loss_v2=0, nll_loss=1.172, ntokens=186, nsentences=8, sample_size=186, sample_size_v1=0, sample_size_v2=0
2023-05-27 03:05:11 - progress_bar.py[line:272] - INFO: epoch 030 | valid on 'valid' subset:   2281 / 2860 loss=2.315, loss_v1=0, loss_v2=0, nll_loss=1.084, ntokens=341, nsentences=8, sample_size=341, sample_size_v1=0, sample_size_v2=0
2023-05-27 03:05:21 - progress_bar.py[line:272] - INFO: epoch 030 | valid on 'valid' subset:   2291 / 2860 loss=2.281, loss_v1=0, loss_v2=0, nll_loss=1.045, ntokens=379, nsentences=8, sample_size=379, sample_size_v1=0, sample_size_v2=0
2316330 <sub> woman<pred> sitting on<obj> bench<pred> has<obj> hair<pred> wearing<obj> shirt<pred> has<obj> hair<sub> bike<pred> has<obj> tire<pred> has<obj> tire<pred> has<obj> tire<pred> has<obj> tire<pred> has<obj> tire ['<sub> cat<pred> laying on<obj> laptop<sub> laptop<pred> on<obj> man<pred> has<obj> screen']
2023-05-27 03:05:31 - progress_bar.py[line:272] - INFO: epoch 030 | valid on 'valid' subset:   2301 / 2860 loss=2.271, loss_v1=0, loss_v2=0, nll_loss=1.029, ntokens=252, nsentences=8, sample_size=252, sample_size_v1=0, sample_size_v2=0
2023-05-27 03:05:40 - progress_bar.py[line:272] - INFO: epoch 030 | valid on 'valid' subset:   2311 / 2860 loss=2.297, loss_v1=0, loss_v2=0, nll_loss=1.066, ntokens=290, nsentences=8, sample_size=290, sample_size_v1=0, sample_size_v2=0
2023-05-27 03:05:50 - progress_bar.py[line:272] - INFO: epoch 030 | valid on 'valid' subset:   2321 / 2860 loss=2.467, loss_v1=0, loss_v2=0, nll_loss=1.249, ntokens=217, nsentences=8, sample_size=217, sample_size_v1=0, sample_size_v2=0
2023-05-27 03:06:00 - progress_bar.py[line:272] - INFO: epoch 030 | valid on 'valid' subset:   2331 / 2860 loss=2.365, loss_v1=0, loss_v2=0, nll_loss=1.139, ntokens=331, nsentences=8, sample_size=331, sample_size_v1=0, sample_size_v2=0
2023-05-27 03:06:09 - progress_bar.py[line:272] - INFO: epoch 030 | valid on 'valid' subset:   2341 / 2860 loss=2.216, loss_v1=0, loss_v2=0, nll_loss=0.978, ntokens=264, nsentences=8, sample_size=264, sample_size_v1=0, sample_size_v2=0
2315767 <sub> man<pred> wearing<obj> jacket<sub> man<pred> wearing<obj> jacket<sub> man<pred> wearing<obj> jacket ['<sub> man<pred> with<obj> hat<sub> man<pred> in<obj> shirt']
2023-05-27 03:06:20 - progress_bar.py[line:272] - INFO: epoch 030 | valid on 'valid' subset:   2351 / 2860 loss=2.182, loss_v1=0, loss_v2=0, nll_loss=0.93, ntokens=175, nsentences=8, sample_size=175, sample_size_v1=0, sample_size_v2=0
2023-05-27 03:06:30 - progress_bar.py[line:272] - INFO: epoch 030 | valid on 'valid' subset:   2361 / 2860 loss=2.514, loss_v1=0, loss_v2=0, nll_loss=1.303, ntokens=323, nsentences=8, sample_size=323, sample_size_v1=0, sample_size_v2=0
2023-05-27 03:06:39 - progress_bar.py[line:272] - INFO: epoch 030 | valid on 'valid' subset:   2371 / 2860 loss=2.286, loss_v1=0, loss_v2=0, nll_loss=1.05, ntokens=381, nsentences=8, sample_size=381, sample_size_v1=0, sample_size_v2=0
2023-05-27 03:06:49 - progress_bar.py[line:272] - INFO: epoch 030 | valid on 'valid' subset:   2381 / 2860 loss=2.524, loss_v1=0, loss_v2=0, nll_loss=1.326, ntokens=273, nsentences=8, sample_size=273, sample_size_v1=0, sample_size_v2=0
2023-05-27 03:06:58 - progress_bar.py[line:272] - INFO: epoch 030 | valid on 'valid' subset:   2391 / 2860 loss=2.542, loss_v1=0, loss_v2=0, nll_loss=1.332, ntokens=171, nsentences=8, sample_size=171, sample_size_v1=0, sample_size_v2=0
2414817 <sub> hand<pred> of<obj> person<sub> hand<pred> of<obj> person<sub> finger<pred> of<obj> person<sub> finger<pred> of<obj> person ['<sub> person<pred> wears<obj> glove<pred> wears<obj> glove<pred> wears<obj> pant<pred> wears<obj> jacket']
2023-05-27 03:07:07 - progress_bar.py[line:272] - INFO: epoch 030 | valid on 'valid' subset:   2401 / 2860 loss=2.225, loss_v1=0, loss_v2=0, nll_loss=0.973, ntokens=283, nsentences=8, sample_size=283, sample_size_v1=0, sample_size_v2=0
2023-05-27 03:07:15 - progress_bar.py[line:272] - INFO: epoch 030 | valid on 'valid' subset:   2411 / 2860 loss=2.443, loss_v1=0, loss_v2=0, nll_loss=1.222, ntokens=196, nsentences=8, sample_size=196, sample_size_v1=0, sample_size_v2=0
2023-05-27 03:07:25 - progress_bar.py[line:272] - INFO: epoch 030 | valid on 'valid' subset:   2421 / 2860 loss=2.351, loss_v1=0, loss_v2=0, nll_loss=1.12, ntokens=279, nsentences=8, sample_size=279, sample_size_v1=0, sample_size_v2=0
2023-05-27 03:07:35 - progress_bar.py[line:272] - INFO: epoch 030 | valid on 'valid' subset:   2431 / 2860 loss=2.55, loss_v1=0, loss_v2=0, nll_loss=1.348, ntokens=223, nsentences=8, sample_size=223, sample_size_v1=0, sample_size_v2=0
2023-05-27 03:07:44 - progress_bar.py[line:272] - INFO: epoch 030 | valid on 'valid' subset:   2441 / 2860 loss=2.268, loss_v1=0, loss_v2=0, nll_loss=1.029, ntokens=249, nsentences=8, sample_size=249, sample_size_v1=0, sample_size_v2=0
2414004 <sub> tire<pred> on<obj> motorcycle<sub> tire<pred> on<obj> motorcycle<sub> tire<pred> on<obj> motorcycle<sub> tire<pred> on<obj> motorcycle ['<sub> train<pred> has<obj> wheel<pred> has<obj> wheel<pred> has<obj> wheel<pred> has<obj> wheel<pred> has<obj> wheel<sub> wheel<pred> on<obj> track<sub> wheel<pred> on<obj> track<sub> wheel<pred> on<obj> track<sub> wheel<pred> on<obj> track']
2023-05-27 03:07:52 - progress_bar.py[line:272] - INFO: epoch 030 | valid on 'valid' subset:   2451 / 2860 loss=2.187, loss_v1=0, loss_v2=0, nll_loss=0.942, ntokens=234, nsentences=8, sample_size=234, sample_size_v1=0, sample_size_v2=0
2023-05-27 03:08:01 - progress_bar.py[line:272] - INFO: epoch 030 | valid on 'valid' subset:   2461 / 2860 loss=2.344, loss_v1=0, loss_v2=0, nll_loss=1.118, ntokens=274, nsentences=8, sample_size=274, sample_size_v1=0, sample_size_v2=0
2023-05-27 03:08:09 - progress_bar.py[line:272] - INFO: epoch 030 | valid on 'valid' subset:   2471 / 2860 loss=2.036, loss_v1=0, loss_v2=0, nll_loss=0.77, ntokens=204, nsentences=8, sample_size=204, sample_size_v1=0, sample_size_v2=0
2023-05-27 03:08:17 - progress_bar.py[line:272] - INFO: epoch 030 | valid on 'valid' subset:   2481 / 2860 loss=2.417, loss_v1=0, loss_v2=0, nll_loss=1.208, ntokens=184, nsentences=8, sample_size=184, sample_size_v1=0, sample_size_v2=0
2023-05-27 03:08:25 - progress_bar.py[line:272] - INFO: epoch 030 | valid on 'valid' subset:   2491 / 2860 loss=2.509, loss_v1=0, loss_v2=0, nll_loss=1.298, ntokens=274, nsentences=8, sample_size=274, sample_size_v1=0, sample_size_v2=0
2413235 <sub> woman<pred> has<obj> head<pred> has<obj> arm<pred> has<obj> hand ['<sub> woman<pred> wears<obj> coat<pred> has<obj> hair<pred> has<obj> arm<pred> has<obj> head']
2023-05-27 03:08:35 - progress_bar.py[line:272] - INFO: epoch 030 | valid on 'valid' subset:   2501 / 2860 loss=2.59, loss_v1=0, loss_v2=0, nll_loss=1.384, ntokens=315, nsentences=8, sample_size=315, sample_size_v1=0, sample_size_v2=0
2023-05-27 03:08:45 - progress_bar.py[line:272] - INFO: epoch 030 | valid on 'valid' subset:   2511 / 2860 loss=2.51, loss_v1=0, loss_v2=0, nll_loss=1.307, ntokens=255, nsentences=8, sample_size=255, sample_size_v1=0, sample_size_v2=0
2023-05-27 03:08:55 - progress_bar.py[line:272] - INFO: epoch 030 | valid on 'valid' subset:   2521 / 2860 loss=2.662, loss_v1=0, loss_v2=0, nll_loss=1.469, ntokens=192, nsentences=8, sample_size=192, sample_size_v1=0, sample_size_v2=0
2023-05-27 03:09:05 - progress_bar.py[line:272] - INFO: epoch 030 | valid on 'valid' subset:   2531 / 2860 loss=2.541, loss_v1=0, loss_v2=0, nll_loss=1.334, ntokens=322, nsentences=8, sample_size=322, sample_size_v1=0, sample_size_v2=0
2023-05-27 03:09:14 - progress_bar.py[line:272] - INFO: epoch 030 | valid on 'valid' subset:   2541 / 2860 loss=2.59, loss_v1=0, loss_v2=0, nll_loss=1.391, ntokens=268, nsentences=8, sample_size=268, sample_size_v1=0, sample_size_v2=0
2412598 <sub> book<pred> on<obj> desk<sub> book<pred> on<obj> desk<sub> book<pred> on<obj> desk<sub> book<pred> on<obj> desk<sub> book<pred> on<obj> desk<sub> book<pred> on<obj> desk<sub> book<pred> on<obj> desk<sub> book<pred> on<obj> desk<sub> book<pred> on<obj> desk<sub> book<pred> on<obj> desk<sub> book<pred> on<obj> desk<sub> book<pred> on<obj> desk<sub> paper<pred> on<obj> desk<sub> paper<pred> on<obj> desk<sub> paper<pred> on<obj> desk ['<sub> laptop<pred> on<obj> table<pred> on<obj> desk<sub> laptop<pred> on<obj> table<sub> window<pred> behind<obj> screen<pred> behind<obj> screen']
2023-05-27 03:09:25 - progress_bar.py[line:272] - INFO: epoch 030 | valid on 'valid' subset:   2551 / 2860 loss=2.619, loss_v1=0, loss_v2=0, nll_loss=1.423, ntokens=242, nsentences=8, sample_size=242, sample_size_v1=0, sample_size_v2=0
2023-05-27 03:09:34 - progress_bar.py[line:272] - INFO: epoch 030 | valid on 'valid' subset:   2561 / 2860 loss=2.528, loss_v1=0, loss_v2=0, nll_loss=1.318, ntokens=299, nsentences=8, sample_size=299, sample_size_v1=0, sample_size_v2=0
2023-05-27 03:09:44 - progress_bar.py[line:272] - INFO: epoch 030 | valid on 'valid' subset:   2571 / 2860 loss=2.348, loss_v1=0, loss_v2=0, nll_loss=1.121, ntokens=304, nsentences=8, sample_size=304, sample_size_v1=0, sample_size_v2=0
2023-05-27 03:09:53 - progress_bar.py[line:272] - INFO: epoch 030 | valid on 'valid' subset:   2581 / 2860 loss=2.461, loss_v1=0, loss_v2=0, nll_loss=1.246, ntokens=250, nsentences=8, sample_size=250, sample_size_v1=0, sample_size_v2=0
2023-05-27 03:10:03 - progress_bar.py[line:272] - INFO: epoch 030 | valid on 'valid' subset:   2591 / 2860 loss=2.211, loss_v1=0, loss_v2=0, nll_loss=0.966, ntokens=367, nsentences=8, sample_size=367, sample_size_v1=0, sample_size_v2=0
2411912 <sub> window<pred> on<obj> building<sub> window<pred> on<obj> building<sub> window<pred> on<obj> building<sub> window<pred> on<obj> building ['<sub> sign<pred> on<obj> pole<sub> tree<pred> behind<obj> fence<sub> pole<pred> with<obj> sign']
2023-05-27 03:10:12 - progress_bar.py[line:272] - INFO: epoch 030 | valid on 'valid' subset:   2601 / 2860 loss=2.461, loss_v1=0, loss_v2=0, nll_loss=1.242, ntokens=305, nsentences=8, sample_size=305, sample_size_v1=0, sample_size_v2=0
2023-05-27 03:10:21 - progress_bar.py[line:272] - INFO: epoch 030 | valid on 'valid' subset:   2611 / 2860 loss=2.579, loss_v1=0, loss_v2=0, nll_loss=1.379, ntokens=241, nsentences=8, sample_size=241, sample_size_v1=0, sample_size_v2=0
2023-05-27 03:10:31 - progress_bar.py[line:272] - INFO: epoch 030 | valid on 'valid' subset:   2621 / 2860 loss=2.674, loss_v1=0, loss_v2=0, nll_loss=1.484, ntokens=204, nsentences=8, sample_size=204, sample_size_v1=0, sample_size_v2=0
2023-05-27 03:10:41 - progress_bar.py[line:272] - INFO: epoch 030 | valid on 'valid' subset:   2631 / 2860 loss=2.695, loss_v1=0, loss_v2=0, nll_loss=1.509, ntokens=364, nsentences=8, sample_size=364, sample_size_v1=0, sample_size_v2=0
2023-05-27 03:10:51 - progress_bar.py[line:272] - INFO: epoch 030 | valid on 'valid' subset:   2641 / 2860 loss=2.361, loss_v1=0, loss_v2=0, nll_loss=1.133, ntokens=281, nsentences=8, sample_size=281, sample_size_v1=0, sample_size_v2=0
2415403 <sub> food<pred> on<obj> plate<sub> plate<pred> of<obj> food ['<sub> cat<pred> near<obj> basket<sub> paw<pred> on<obj> cat']
2023-05-27 03:11:00 - progress_bar.py[line:272] - INFO: epoch 030 | valid on 'valid' subset:   2651 / 2860 loss=2.524, loss_v1=0, loss_v2=0, nll_loss=1.32, ntokens=363, nsentences=8, sample_size=363, sample_size_v1=0, sample_size_v2=0
2023-05-27 03:11:10 - progress_bar.py[line:272] - INFO: epoch 030 | valid on 'valid' subset:   2661 / 2860 loss=2.434, loss_v1=0, loss_v2=0, nll_loss=1.218, ntokens=325, nsentences=8, sample_size=325, sample_size_v1=0, sample_size_v2=0
2023-05-27 03:11:19 - progress_bar.py[line:272] - INFO: epoch 030 | valid on 'valid' subset:   2671 / 2860 loss=2.113, loss_v1=0, loss_v2=0, nll_loss=0.86, ntokens=250, nsentences=8, sample_size=250, sample_size_v1=0, sample_size_v2=0
2023-05-27 03:11:28 - progress_bar.py[line:272] - INFO: epoch 030 | valid on 'valid' subset:   2681 / 2860 loss=2.317, loss_v1=0, loss_v2=0, nll_loss=1.089, ntokens=244, nsentences=8, sample_size=244, sample_size_v1=0, sample_size_v2=0
2023-05-27 03:11:37 - progress_bar.py[line:272] - INFO: epoch 030 | valid on 'valid' subset:   2691 / 2860 loss=2.423, loss_v1=0, loss_v2=0, nll_loss=1.205, ntokens=213, nsentences=8, sample_size=213, sample_size_v1=0, sample_size_v2=0
2416036 <sub> tree<pred> behind<obj> fence<sub> tree<pred> behind<obj> fence<sub> tree<pred> behind<obj> fence<sub> tree<pred> behind<obj> fence<sub> tree<pred> behind<obj> fence<sub> tree<pred> behind<obj> fence<sub> tree<pred> behind<obj> fence<sub> cow<pred> behind<obj> fence<sub> cow<pred> behind<obj> fence<sub> cow<pred> behind<obj> fence<sub> cow<pred> behind<obj> fence ['<sub> tail<pred> belonging to<obj> giraffe<sub> neck<pred> belonging to<obj> giraffe<sub> neck<pred> belonging to<obj> giraffe<sub> giraffe<pred> has<obj> tail<sub> head<pred> of<obj> giraffe<sub> window<pred> on<obj> building']
2023-05-27 03:11:46 - progress_bar.py[line:272] - INFO: epoch 030 | valid on 'valid' subset:   2701 / 2860 loss=2.521, loss_v1=0, loss_v2=0, nll_loss=1.312, ntokens=239, nsentences=8, sample_size=239, sample_size_v1=0, sample_size_v2=0
2023-05-27 03:11:56 - progress_bar.py[line:272] - INFO: epoch 030 | valid on 'valid' subset:   2711 / 2860 loss=2.258, loss_v1=0, loss_v2=0, nll_loss=1.017, ntokens=246, nsentences=8, sample_size=246, sample_size_v1=0, sample_size_v2=0
2023-05-27 03:12:06 - progress_bar.py[line:272] - INFO: epoch 030 | valid on 'valid' subset:   2721 / 2860 loss=2.38, loss_v1=0, loss_v2=0, nll_loss=1.155, ntokens=169, nsentences=8, sample_size=169, sample_size_v1=0, sample_size_v2=0
2023-05-27 03:12:16 - progress_bar.py[line:272] - INFO: epoch 030 | valid on 'valid' subset:   2731 / 2860 loss=2.234, loss_v1=0, loss_v2=0, nll_loss=0.998, ntokens=337, nsentences=8, sample_size=337, sample_size_v1=0, sample_size_v2=0
2023-05-27 03:12:25 - progress_bar.py[line:272] - INFO: epoch 030 | valid on 'valid' subset:   2741 / 2860 loss=2.31, loss_v1=0, loss_v2=0, nll_loss=1.075, ntokens=211, nsentences=8, sample_size=211, sample_size_v1=0, sample_size_v2=0
2416633 <sub> vase<pred> on<obj> table<sub> flower<pred> in<obj> vase ['<sub> screen<pred> on<obj> phone<sub> phone<pred> on<obj> table<sub> phone<pred> on<obj> table']
2023-05-27 03:12:35 - progress_bar.py[line:272] - INFO: epoch 030 | valid on 'valid' subset:   2751 / 2860 loss=2.438, loss_v1=0, loss_v2=0, nll_loss=1.217, ntokens=241, nsentences=8, sample_size=241, sample_size_v1=0, sample_size_v2=0
2023-05-27 03:12:44 - progress_bar.py[line:272] - INFO: epoch 030 | valid on 'valid' subset:   2761 / 2860 loss=2.436, loss_v1=0, loss_v2=0, nll_loss=1.216, ntokens=249, nsentences=8, sample_size=249, sample_size_v1=0, sample_size_v2=0
2023-05-27 03:12:52 - progress_bar.py[line:272] - INFO: epoch 030 | valid on 'valid' subset:   2771 / 2860 loss=2.251, loss_v1=0, loss_v2=0, nll_loss=1.015, ntokens=290, nsentences=8, sample_size=290, sample_size_v1=0, sample_size_v2=0
2023-05-27 03:13:01 - progress_bar.py[line:272] - INFO: epoch 030 | valid on 'valid' subset:   2781 / 2860 loss=2.479, loss_v1=0, loss_v2=0, nll_loss=1.262, ntokens=145, nsentences=8, sample_size=145, sample_size_v1=0, sample_size_v2=0
2023-05-27 03:13:09 - progress_bar.py[line:272] - INFO: epoch 030 | valid on 'valid' subset:   2791 / 2860 loss=2.465, loss_v1=0, loss_v2=0, nll_loss=1.252, ntokens=306, nsentences=8, sample_size=306, sample_size_v1=0, sample_size_v2=0
2417277 <sub> head<pred> of<obj> zebra<sub> ear<pred> of<obj> zebra<sub> ear<pred> of<obj> zebra<sub> ear<pred> of<obj> zebra ['<sub> fence<pred> behind<obj> giraffe<sub> ear<pred> of<obj> giraffe']
2023-05-27 03:13:19 - progress_bar.py[line:272] - INFO: epoch 030 | valid on 'valid' subset:   2801 / 2860 loss=2.301, loss_v1=0, loss_v2=0, nll_loss=1.066, ntokens=249, nsentences=8, sample_size=249, sample_size_v1=0, sample_size_v2=0
2023-05-27 03:13:28 - progress_bar.py[line:272] - INFO: epoch 030 | valid on 'valid' subset:   2811 / 2860 loss=2.253, loss_v1=0, loss_v2=0, nll_loss=1.008, ntokens=243, nsentences=8, sample_size=243, sample_size_v1=0, sample_size_v2=0
2023-05-27 03:13:38 - progress_bar.py[line:272] - INFO: epoch 030 | valid on 'valid' subset:   2821 / 2860 loss=2.59, loss_v1=0, loss_v2=0, nll_loss=1.384, ntokens=321, nsentences=8, sample_size=321, sample_size_v1=0, sample_size_v2=0
2023-05-27 03:13:48 - progress_bar.py[line:272] - INFO: epoch 030 | valid on 'valid' subset:   2831 / 2860 loss=2.511, loss_v1=0, loss_v2=0, nll_loss=1.297, ntokens=218, nsentences=8, sample_size=218, sample_size_v1=0, sample_size_v2=0
2023-05-27 03:13:58 - progress_bar.py[line:272] - INFO: epoch 030 | valid on 'valid' subset:   2841 / 2860 loss=2.473, loss_v1=0, loss_v2=0, nll_loss=1.26, ntokens=224, nsentences=8, sample_size=224, sample_size_v1=0, sample_size_v2=0
2417871 <sub> man<pred> wearing<obj> tie<pred> wearing<obj> shirt<pred> has<obj> hair<pred> has<obj> ear<pred> has<obj> ear<pred> has<obj> eye<pred> has<obj> nose<pred> has<obj> mouth<pred> has<obj> hair<pred> has<obj> ear<pred> has<obj> ear<pred> has<obj> face<pred> has<obj> nose<pred> has<obj> mouth<pred> has<obj> hair<pred> wearing<obj> shirt<pred> has<obj> face<sub> tie<pred> on<obj> neck<sub> shirt<pred> has<obj> logo<sub> tie<pred> on<obj> shirt<sub> tie<pred> on<obj> shirt ['<sub> woman<pred> has<obj> hair<sub> man<pred> has<obj> hair<pred> has<obj> head<pred> wearing<obj> shirt<sub> cap<pred> above<obj> head<sub> shirt<pred> has<obj> logo<sub> man<pred> has<obj> hand<pred> has<obj> ear<sub> man<pred> in<obj> cap']
2023-05-27 03:14:06 - progress_bar.py[line:272] - INFO: epoch 030 | valid on 'valid' subset:   2851 / 2860 loss=2.602, loss_v1=0, loss_v2=0, nll_loss=1.398, ntokens=218, nsentences=8, sample_size=218, sample_size_v1=0, sample_size_v2=0
2023-05-27 03:14:14 - progress_bar.py[line:282] - INFO: epoch 030 | valid on 'valid' subset | loss 2.388 | loss_v1 0 | loss_v2 0 | nll_loss 1.165 | ntokens 286.856 | nsentences 8 | sample_size 286.856 | sample_size_v1 0 | sample_size_v2 0 | ppl 2.24 | wps 298.5 | wpb 286.9 | bsz 8 | num_updates 51872
2023-05-27 03:14:14 - train.py[line:332] - INFO: end of epoch 30 (average epoch stats below)
2023-05-27 03:14:14 - progress_bar.py[line:282] - INFO: epoch 030 | loss 2.122 | loss_v1 0 | loss_v2 0 | nll_loss 0.892 | ntokens 1051.61 | nsentences 31.986 | sample_size 1051.61 | sample_size_v1 0 | sample_size_v2 0 | ppl 1.86 | wps 303.1 | ups 0.29 | wpb 1051.6 | bsz 32 | num_updates 51872 | lr 5.40507e-08 | gnorm 19.109 | clip 100 | loss_scale 32 | train_wall 3243 | gb_free 11.7 | wall 100269
2023-05-27 03:14:14 - trainer.py[line:639] - INFO: loading train data for epoch 31
local datafile ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 0 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 0 finished initializing row_count and line_idx-to-offset mapping
file ../../dataset/OFA_data/sgcls/vg_train_full.tsv slice_id 0 row count 55400 total row count 55400
slice_id 0 seek offset 0
2023-05-27 03:14:16 - train.py[line:214] - INFO: done training in 100269.1 seconds
2023-05-27 03:14:16 - distributed_c10d.py[line:228] - INFO: Added key: store_based_barrier_key:2 to store for rank: 0
2023-05-27 03:14:16 - distributed_c10d.py[line:262] - INFO: Rank 0: Completed store-based barrier for key:store_based_barrier_key:2 with 1 nodes.
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                  train/bsz ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:                 train/clip ██▁▁█▁▁▁▁▁████████████████████
wandb:              train/gb_free ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:                train/gnorm ▂▁▁▁▁▁▁▁▁▁▂▂▂▂▂▃▃▄▅▆▆▇████▇▇▇▇
wandb:                 train/loss █▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:           train/loss_scale ▄█▄▄▄▃▄▄▄▃▃▃▃▃▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:              train/loss_v1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:              train/loss_v2 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:                   train/lr ▅██▇▇▇▇▇▆▆▆▅▅▅▅▅▄▄▄▄▃▃▃▃▂▂▂▁▁▁
wandb:             train/nll_loss █▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:           train/nsentences ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:              train/ntokens ▁▄▃▃▆▄█▇▅▄▃▆▂▅▂█▃▄▅▅▂▆▅▆▃▆▅▃▆▅
wandb:                  train/ppl █▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:          train/sample_size ▁▄▃▃▆▄█▇▅▄▃▆▂▅▂█▃▄▅▅▂▆▅▆▃▆▅▃▆▅
wandb:       train/sample_size_v1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       train/sample_size_v2 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:           train/train_wall ▅▂▄▁▂▃▄▃▅▄▄▄▅▄▅▄▅▃▇▇▇▆▅▄▄▅▇█▅▆
wandb:                  train/ups █████████████████████████████▁
wandb:                 train/wall ▁▁▁▂▂▂▂▃▃▃▃▄▄▄▄▅▅▅▅▅▆▆▆▆▇▇▇▇██
wandb:                  train/wpb ▁▅▄▄▇▄██▅▄▄▇▂▅▂█▄▄▅▅▂▇▅▇▄▇▅▄▇▅
wandb:                  train/wps █████████████████████████████▁
wandb:            train_inner/bsz ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:           train_inner/clip ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:        train_inner/gb_free ▆▅█▅▆▅▆▇▇▇▆▇█▇▇▇▆▇▇█▆▆▅▇▆▆▁▆▅▇▆▇▆▇▆▅█▆▇▇
wandb:          train_inner/gnorm ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▂▂▂▂▂▃▃▃▄▅▅▅▆▇█▇█▇▇█▇▇▆▇▅
wandb:           train_inner/loss █▃▂▂▂▂▂▂▂▁▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     train_inner/loss_scale ▂▄██▄▄▄▄▄▄▃▄▃▃▃▃▃▃▃▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:        train_inner/loss_v1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:        train_inner/loss_v2 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:             train_inner/lr ▂▅███▇▇▇▇▇▇▆▆▆▆▆▅▅▅▅▅▄▄▄▄▄▃▃▃▃▃▃▂▂▂▂▂▁▁▁
wandb:       train_inner/nll_loss █▂▂▂▂▂▂▂▂▁▂▂▂▂▂▂▂▂▁▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     train_inner/nsentences ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:        train_inner/ntokens ▂▅▆▄▃▅▆▃▂▄▅▂▃▆▄▁▂▃▆▂▄▂▄▅▃▃▆▄▂▁█▄▂▅▃▃▂▅▅█
wandb:            train_inner/ppl █▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:    train_inner/sample_size ▂▅▆▄▃▅▆▃▂▄▅▂▃▆▄▁▂▃▆▂▄▂▄▅▃▃▆▄▂▁█▄▂▅▃▃▂▅▅█
wandb: train_inner/sample_size_v1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: train_inner/sample_size_v2 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     train_inner/train_wall ▁▃▃▃▃▃▃▃▁▃▃▃▁▃▃▁▃▃▃▃▃▁▃▃▃▃▃▃▁▁▃▃▁▃▃█▃▃▃▃
wandb:            train_inner/ups █▆▇▇█▆▇▇█▇▇██▇▇██▇▇█▇█▇▇██▇▇██▆▇█▇▇▁█▇▇▆
wandb:           train_inner/wall ▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███
wandb:            train_inner/wpb ▂▅▆▄▃▅▆▃▂▄▅▂▃▆▄▁▂▃▆▂▄▂▄▅▃▃▆▄▂▁█▄▂▅▃▃▂▅▅█
wandb:            train_inner/wps ▂▅▆▄▃▄▆▄▃▄▅▂▃▆▄▁▃▃▆▂▄▂▄▅▃▃▆▄▂▂█▄▂▅▃▁▃▅▅█
wandb:                  valid/bsz ▁
wandb:                 valid/loss ▁
wandb:              valid/loss_v1 ▁
wandb:              valid/loss_v2 ▁
wandb:             valid/nll_loss ▁
wandb:           valid/nsentences ▁
wandb:              valid/ntokens ▁
wandb:                  valid/ppl ▁
wandb:          valid/sample_size ▁
wandb:       valid/sample_size_v1 ▁
wandb:       valid/sample_size_v2 ▁
wandb:                  valid/wpb ▁
wandb:                  valid/wps ▁
wandb: 
wandb: Run summary:
wandb:                  train/bsz 32.0
wandb:                 train/clip 100.0
wandb:              train/gb_free 11.7
wandb:                train/gnorm 19.109
wandb:                 train/loss 2.122
wandb:           train/loss_scale 32.0
wandb:              train/loss_v1 0.0
wandb:              train/loss_v2 0.0
wandb:                   train/lr 0.0
wandb:             train/nll_loss 0.892
wandb:           train/nsentences 31.986
wandb:              train/ntokens 1051.607
wandb:                  train/ppl 1.86
wandb:          train/sample_size 1051.607
wandb:       train/sample_size_v1 0.0
wandb:       train/sample_size_v2 0.0
wandb:           train/train_wall 3243.0
wandb:                  train/ups 0.29
wandb:                 train/wall 100269.0
wandb:                  train/wpb 1051.6
wandb:                  train/wps 303.1
wandb:            train_inner/bsz 32.0
wandb:           train_inner/clip 100.0
wandb:        train_inner/gb_free 11.2
wandb:          train_inner/gnorm 17.584
wandb:           train_inner/loss 2.145
wandb:     train_inner/loss_scale 32.0
wandb:        train_inner/loss_v1 0.0
wandb:        train_inner/loss_v2 0.0
wandb:             train_inner/lr 0.0
wandb:       train_inner/nll_loss 0.917
wandb:     train_inner/nsentences 32.0
wandb:        train_inner/ntokens 1126.4
wandb:            train_inner/ppl 1.89
wandb:    train_inner/sample_size 1126.4
wandb: train_inner/sample_size_v1 0.0
wandb: train_inner/sample_size_v2 0.0
wandb:     train_inner/train_wall 19.0
wandb:            train_inner/ups 0.53
wandb:           train_inner/wall 97518.0
wandb:            train_inner/wpb 1126.4
wandb:            train_inner/wps 595.7
wandb:                  valid/bsz 8.0
wandb:                 valid/loss 2.388
wandb:              valid/loss_v1 0.0
wandb:              valid/loss_v2 0.0
wandb:             valid/nll_loss 1.165
wandb:           valid/nsentences 8.0
wandb:              valid/ntokens 286.856
wandb:                  valid/ppl 2.24
wandb:          valid/sample_size 286.856
wandb:       valid/sample_size_v1 0.0
wandb:       valid/sample_size_v2 0.0
wandb:                  valid/wpb 286.9
wandb:                  valid/wps 298.5
wandb: 
wandb: 🚀 View run _30_3e-5_512_base_nosrcbbox at: https://wandb.ai/jackcai1206/OFA-VG/runs/kx739tj6
wandb: Synced 6 W&B file(s), 0 media file(s), 2 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230525_232308-kx739tj6/logs
/data/hulab/zcai75/anaconda3/envs/vilt/lib/python3.8/site-packages/torch/distributed/launch.py:178: FutureWarning: The module torch.distributed.launch is deprecated
and will be removed in future. Use torchrun.
Note that --use_env is set by default in torchrun.
If your script expects `--local_rank` argument to be set, please
change it to read from `os.environ['LOCAL_RANK']` instead. See 
https://pytorch.org/docs/stable/distributed.html#launch-utility for 
further instructions

  warnings.warn(

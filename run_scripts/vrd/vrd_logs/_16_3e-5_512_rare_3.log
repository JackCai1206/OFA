/data/hulab/zcai75/anaconda3/envs/vilt/lib/python3.8/site-packages/torch/distributed/launch.py:178: FutureWarning: The module torch.distributed.launch is deprecated
and will be removed in future. Use torchrun.
Note that --use_env is set by default in torchrun.
If your script expects `--local_rank` argument to be set, please
change it to read from `os.environ['LOCAL_RANK']` instead. See 
https://pytorch.org/docs/stable/distributed.html#launch-utility for 
further instructions

  warnings.warn(
WARNING:torch.distributed.run:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
2023-06-27 02:13:16 - utils.py[line:255] - INFO: distributed init (rank 1): env://
2023-06-27 02:13:16 - utils.py[line:261] - INFO: Start init
2023-06-27 02:13:16 - distributed_c10d.py[line:228] - INFO: Added key: store_based_barrier_key:1 to store for rank: 1
2023-06-27 02:13:16 - utils.py[line:255] - INFO: distributed init (rank 2): env://
2023-06-27 02:13:16 - utils.py[line:261] - INFO: Start init
2023-06-27 02:13:16 - distributed_c10d.py[line:228] - INFO: Added key: store_based_barrier_key:1 to store for rank: 2
2023-06-27 02:13:16 - utils.py[line:255] - INFO: distributed init (rank 3): env://
2023-06-27 02:13:16 - utils.py[line:261] - INFO: Start init
2023-06-27 02:13:16 - distributed_c10d.py[line:228] - INFO: Added key: store_based_barrier_key:1 to store for rank: 3
2023-06-27 02:13:16 - utils.py[line:255] - INFO: distributed init (rank 0): env://
2023-06-27 02:13:16 - utils.py[line:261] - INFO: Start init
2023-06-27 02:13:16 - distributed_c10d.py[line:228] - INFO: Added key: store_based_barrier_key:1 to store for rank: 0
2023-06-27 02:13:16 - distributed_c10d.py[line:262] - INFO: Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 4 nodes.
2023-06-27 02:13:16 - utils.py[line:271] - INFO: initialized host AMD4RTX3090GPU14 as rank 0
single-machine distributed training is initialized.
2023-06-27 02:13:16 - distributed_c10d.py[line:262] - INFO: Rank 2: Completed store-based barrier for key:store_based_barrier_key:1 with 4 nodes.
2023-06-27 02:13:16 - utils.py[line:271] - INFO: initialized host AMD4RTX3090GPU14 as rank 2
single-machine distributed training is initialized.
2023-06-27 02:13:16 - distributed_c10d.py[line:262] - INFO: Rank 1: Completed store-based barrier for key:store_based_barrier_key:1 with 4 nodes.
2023-06-27 02:13:16 - utils.py[line:271] - INFO: initialized host AMD4RTX3090GPU14 as rank 1
single-machine distributed training is initialized.
2023-06-27 02:13:16 - distributed_c10d.py[line:262] - INFO: Rank 3: Completed store-based barrier for key:store_based_barrier_key:1 with 4 nodes.
2023-06-27 02:13:16 - utils.py[line:271] - INFO: initialized host AMD4RTX3090GPU14 as rank 3
single-machine distributed training is initialized.
2023-06-27 02:13:17 - train.py[line:77] - INFO: {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 10, 'log_format': 'simple', 'log_file': None, 'tensorboard_logdir': './tensorboard/_16_3e-5_512', 'wandb_project': 'OFA-VG', 'azureml_logging': False, 'seed': 1, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': 512, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': '../../ofa_module', 'empty_cache_freq': 0, 'all_gather_list_size': 2097152, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 4, 'distributed_num_procs': 4, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': 'env://', 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': True, 'ddp_backend': 'pytorch_ddp', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': True, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_algorithm': 'LocalSGD', 'localsgd_frequency': 3, 'nprocs_per_node': 4, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False}, 'dataset': {'_name': None, 'num_workers': 0, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': None, 'batch_size': 10, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 10, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': 7, 'disable_validation': False, 'max_tokens_valid': None, 'batch_size_valid': 10, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0}, 'optimization': {'_name': None, 'max_epoch': 16, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 1.0, 'sentence_avg': False, 'update_freq': [4], 'lr': [3e-05], 'stop_min_lr': -1.0, 'use_bmuf': False}, 'checkpoint': {'_name': None, 'save_dir': '../../checkpoints/OFA/vrd_checkpoints/_16_3e-5_512_rare_3', 'restore_file': '../../checkpoints/ofa_base.pt', 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 2, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': 1, 'no_save': False, 'no_epoch_checkpoints': False, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': True, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1, 'use_ema_weights_to_init_param': False, 'use_latest_weights_to_init_ema': False}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 4}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': Namespace(_name='ofa_base', activation_fn='gelu', adam_betas='(0.9,0.999)', adam_eps=1e-08, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, add_type_embedding=True, all_gather_list_size=2097152, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, arch='ofa_base', attention_dropout=0.0, attn_scale_factor=2, azureml_logging=False, batch_size=10, batch_size_valid=10, best_checkpoint_metric='loss', bf16=False, bitfit=False, bpe=None, bpe_dir='../../utils/BPE', broadcast_buffers=False, bucket_cap_mb=25, checkpoint_shard_count=1, checkpoint_suffix='', clip_norm=1.0, code_dict_size=8192, code_image_size=128, code_layernorm_embedding=True, combine_valid_subsets=None, constraint_range=None, cpu=False, cpu_offload=False, criterion='adjust_label_smoothed_cross_entropy', cross_self_attention=False, curriculum=0, data='../../dataset/OFA_data/vrd/vg_train_full.tsv,../../dataset/OFA_data/vrd/vg_val_full.tsv', data_buffer_size=10, dataset_impl=None, ddp_backend='pytorch_ddp', ddp_comm_hook='none', decoder_attention_heads=12, decoder_drop_path_rate=0.1, decoder_embed_dim=768, decoder_embed_path=None, decoder_ffn_embed_dim=3072, decoder_input_dim=768, decoder_layerdrop=0, decoder_layers=6, decoder_layers_to_keep=None, decoder_learned_pos=True, decoder_normalize_before=True, decoder_output_dim=768, device_id=0, disable_entangle=True, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_num_procs=4, distributed_port=-1, distributed_rank=0, distributed_world_size=4, drop_worst_after=0, drop_worst_ratio=0.0, dropout=0.1, ema_decay=0.9999, ema_fp32=False, ema_seed_model=None, ema_start_update=0, ema_update_freq=1, empty_cache_freq=0, encoder_attention_heads=12, encoder_drop_path_rate=0.1, encoder_embed_dim=768, encoder_embed_path=None, encoder_ffn_embed_dim=3072, encoder_layerdrop=0, encoder_layers=6, encoder_layers_to_keep=None, encoder_learned_pos=True, encoder_normalize_before=True, end_learning_rate=0.0, entangle_position_embedding=False, eos=2, eval_args='{"beam":5,"max_len_a":0,"max_len_b":200}', eval_print_samples=False, fast_stat_sync=False, find_unused_parameters=True, finetune_from_model=None, fix_batches_to_gpus=False, fixed_validation_seed=7, force_anneal=None, fp16=True, fp16_adam_stats=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=512, fp32_reduce_scatter=False, freeze_decoder_embedding=False, freeze_encoder_embedding=False, gen_subset='test', gradient_as_bucket_view=False, heartbeat_timeout=-1, ignore_eos=False, ignore_prefix_size=0, ignore_unused_valid_subsets=False, image_bucket_size=42, imagenet_default_mean_and_std=False, keep_best_checkpoints=1, keep_interval_updates=-1, keep_interval_updates_pattern=-1, keep_last_epochs=-1, label_smoothing=0.1, layernorm_embedding=True, load_checkpoint_on_all_dp_ranks=False, localsgd_frequency=3, log_file=None, log_format='simple', log_interval=10, lr=[3e-05], lr_scheduler='polynomial_decay', max_epoch=16, max_source_positions=1024, max_src_length=100, max_target_positions=1024, max_tgt_length=100, max_tokens=None, max_tokens_valid=None, max_update=0, max_valid_steps=None, maximize_best_checkpoint_metric=True, memory_efficient_bf16=False, memory_efficient_fp16=False, min_loss_scale=0.0001, min_params_to_wrap=100000000, model_parallel_size=1, no_cross_attention=False, no_epoch_checkpoints=False, no_last_checkpoints=False, no_progress_bar=False, no_reshard_after_forward=False, no_save=False, no_save_optimizer_state=False, no_scale_embedding=True, no_seed_provided=False, no_token_positional_embeddings=False, nprocs_per_node=4, num_bins=1000, num_shards=1, num_workers=0, on_cpu_convert_precision=False, optimizer='adam', optimizer_overrides='{}', orig_patch_image_size=256, pad=1, patch_image_size=512, patch_layernorm_embedding=True, patience=-1, pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, plasma_path='/tmp/plasma', pooler_activation_fn='tanh', pooler_classifier='mlp', pooler_dropout=0.0, power=1.0, profile=False, quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, quantization_config_path=None, reg_alpha=1.0, relu_dropout=0.0, report_accuracy=False, required_batch_size_multiple=8, required_seq_len_multiple=1, reset_dataloader=False, reset_logging=False, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, resnet_drop_path_rate=0.0, resnet_type='resnet101', restore_file='../../checkpoints/ofa_base.pt', sample_patch_num=196, save_dir='../../checkpoints/OFA/vrd_checkpoints/_16_3e-5_512_rare_3', save_interval=2, save_interval_updates=0, scale_attn=True, scale_fc=True, scale_heads=True, scale_resids=False, scoring='bleu', seed=1, selected_cols=None, sentence_avg=False, shard_id=0, share_all_embeddings=True, share_decoder_input_output_embed=True, simul_type=None, skip_invalid_size_inputs_valid_test=False, slowmo_algorithm='LocalSGD', slowmo_momentum=None, stop_min_lr=-1.0, stop_time_hours=0, store_ema=False, suppress_crashes=False, sync_bn=False, task='vrd', tensorboard_logdir='./tensorboard/_16_3e-5_512', threshold_loss_scale=None, token_bucket_size=256, tokenizer=None, total_num_update=1000000, tpu=False, train_subset='train', unk=3, update_freq=[4], use_bmuf=False, use_ema_weights_to_init_param=False, use_latest_weights_to_init_ema=False, use_old_adam=False, use_plasma_view=False, use_rdrop=False, use_sharded_state=False, user_dir='../../ofa_module', valid_subset='valid', validate_after_updates=0, validate_interval=10, validate_interval_updates=0, vg_json_dir=None, wandb_project='OFA-VG', warmup_ratio=0.06, warmup_updates=0, weight_decay=0.01, write_checkpoints_asynchronously=False, zero_sharding='none'), 'task': {'_name': 'vrd', 'data': '../../dataset/OFA_data/vrd/vg_train_full.tsv,../../dataset/OFA_data/vrd/vg_val_full.tsv', 'selected_cols': None, 'bpe': None, 'bpe_dir': '../../utils/BPE', 'max_source_positions': 1024, 'max_target_positions': 1024, 'max_src_length': 100, 'max_tgt_length': 100, 'code_dict_size': 8192, 'patch_image_size': 512, 'orig_patch_image_size': 256, 'num_bins': 1000, 'imagenet_default_mean_and_std': False, 'constraint_range': None, 'eval_args': '{"beam":5,"max_len_a":0,"max_len_b":200}', 'eval_print_samples': False, 'vg_json_dir': None}, 'criterion': {'_name': 'adjust_label_smoothed_cross_entropy', 'label_smoothing': 0.1, 'report_accuracy': False, 'ignore_prefix_size': 0, 'ignore_eos': False, 'sentence_avg': False, 'drop_worst_ratio': 0.0, 'drop_worst_after': 0, 'use_rdrop': False, 'reg_alpha': 1.0, 'sample_patch_num': 196, 'constraint_range': None}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9,0.999)', 'adam_eps': 1e-08, 'weight_decay': 0.01, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': False, 'lr': [3e-05]}, 'lr_scheduler': {'_name': 'polynomial_decay', 'warmup_updates': 0, 'warmup_ratio': 0.06, 'force_anneal': None, 'end_learning_rate': 0.0, 'power': 1.0, 'total_num_update': 1000000.0, 'lr': [3e-05]}, 'scoring': {'_name': 'bleu', 'pad': 1, 'eos': 2, 'unk': 3}, 'bpe': None, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}, 'simul_type': None}
2023-06-27 02:13:17 - vrd.py[line:84] - INFO: vrd setup: source dictionary: 51268 types
2023-06-27 02:13:17 - vrd.py[line:85] - INFO: vrd setup: target dictionary: 51268 types
/data/hulab/zcai75/anaconda3/envs/vilt/lib/python3.8/site-packages/torch/functional.py:478: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at  ../aten/src/ATen/native/TensorShape.cpp:2894.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/data/hulab/zcai75/anaconda3/envs/vilt/lib/python3.8/site-packages/torch/functional.py:478: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at  ../aten/src/ATen/native/TensorShape.cpp:2894.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/data/hulab/zcai75/anaconda3/envs/vilt/lib/python3.8/site-packages/torch/functional.py:478: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at  ../aten/src/ATen/native/TensorShape.cpp:2894.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/data/hulab/zcai75/anaconda3/envs/vilt/lib/python3.8/site-packages/torch/functional.py:478: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at  ../aten/src/ATen/native/TensorShape.cpp:2894.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
2023-06-27 02:13:19 - train.py[line:110] - INFO: OFAModel(
  (encoder): TransformerEncoder(
    (encoder_dropout): Dropout(p=0.2, inplace=False)
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(51268, 768, padding_idx=1)
    (layernorm_embedding): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (type_embedding): Embedding(2, 768)
    (embed_images): ResNet(
      (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)
      (layer1): Sequential(
        (0): Bottleneck(
          (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (downsample): Sequential(
            (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (drop_path): Identity()
        )
        (1): Bottleneck(
          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (2): Bottleneck(
          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
      )
      (layer2): Sequential(
        (0): Bottleneck(
          (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (downsample): Sequential(
            (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
            (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (drop_path): Identity()
        )
        (1): Bottleneck(
          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (2): Bottleneck(
          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (3): Bottleneck(
          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
      )
      (layer3): Sequential(
        (0): Bottleneck(
          (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (downsample): Sequential(
            (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)
            (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (drop_path): Identity()
        )
        (1): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (2): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (3): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (4): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (5): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (6): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (7): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (8): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (9): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (10): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (11): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (12): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (13): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (14): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (15): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (16): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (17): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (18): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (19): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (20): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (21): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (22): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
      )
    )
    (image_proj): Linear(in_features=1024, out_features=768, bias=True)
    (patch_layernorm_embedding): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (embed_positions): Embedding(1026, 768)
    (embed_image_positions): Embedding(1765, 768)
    (pos_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (image_pos_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (pos_q_linear): Linear(in_features=768, out_features=768, bias=True)
    (pos_k_linear): Linear(in_features=768, out_features=768, bias=True)
    (layers): ModuleList(
      (0): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): Identity()
      )
      (1): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(p=0.019999999552965164)
      )
      (2): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(p=0.03999999910593033)
      )
      (3): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(p=0.06000000238418579)
      )
      (4): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(p=0.07999999821186066)
      )
      (5): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(p=0.10000000149011612)
      )
    )
    (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (token_rel_pos_table_list): ModuleList(
      (0): Embedding(511, 12)
      (1): Embedding(511, 12)
      (2): Embedding(511, 12)
      (3): Embedding(511, 12)
      (4): Embedding(511, 12)
      (5): Embedding(511, 12)
    )
    (image_rel_pos_table_list): ModuleList(
      (0): Embedding(6892, 12)
      (1): Embedding(6892, 12)
      (2): Embedding(6892, 12)
      (3): Embedding(6892, 12)
      (4): Embedding(6892, 12)
      (5): Embedding(6892, 12)
    )
  )
  (decoder): TransformerDecoder(
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(51268, 768, padding_idx=1)
    (layernorm_embedding): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (embed_positions): Embedding(1026, 768)
    (embed_image_positions): Embedding(1765, 768)
    (pos_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (image_pos_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (self_pos_q_linear): Linear(in_features=768, out_features=768, bias=True)
    (self_pos_k_linear): Linear(in_features=768, out_features=768, bias=True)
    (cross_pos_q_linear): Linear(in_features=768, out_features=768, bias=True)
    (cross_pos_k_linear): Linear(in_features=768, out_features=768, bias=True)
    (code_layernorm_embedding): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (layers): ModuleList(
      (0): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (cross_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): Identity()
      )
      (1): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (cross_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(p=0.019999999552965164)
      )
      (2): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (cross_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(p=0.03999999910593033)
      )
      (3): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (cross_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(p=0.06000000238418579)
      )
      (4): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (cross_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(p=0.07999999821186066)
      )
      (5): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (cross_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(p=0.10000000149011612)
      )
    )
    (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (output_projection): Linear(in_features=768, out_features=51268, bias=False)
    (token_rel_pos_table_list): ModuleList(
      (0): Embedding(511, 12)
      (1): Embedding(511, 12)
      (2): Embedding(511, 12)
      (3): Embedding(511, 12)
      (4): Embedding(511, 12)
      (5): Embedding(511, 12)
    )
    (image_rel_pos_table_list): ModuleList(
      (0): Embedding(6892, 12)
      (1): Embedding(6892, 12)
      (2): Embedding(6892, 12)
      (3): Embedding(6892, 12)
      (4): Embedding(6892, 12)
      (5): Embedding(6892, 12)
    )
  )
  (classification_heads): ModuleDict()
)
2023-06-27 02:13:19 - train.py[line:111] - INFO: task: VRDTask
2023-06-27 02:13:19 - train.py[line:112] - INFO: model: OFAModel
2023-06-27 02:13:19 - train.py[line:113] - INFO: criterion: AdjustLabelSmoothedCrossEntropyCriterion
2023-06-27 02:13:19 - train.py[line:114] - INFO: num. shared model params: 175,949,384 (num. trained: 175,949,384)
2023-06-27 02:13:19 - train.py[line:121] - INFO: num. expert model params: 0 (num. trained: 0)
local datafile ../../dataset/OFA_data/vrd/vg_val_full.tsv slice_id 0 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../dataset/OFA_data/vrd/vg_val_full.tsv slice_id 3 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../dataset/OFA_data/vrd/vg_val_full.tsv slice_id 2 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../dataset/OFA_data/vrd/vg_val_full.tsv slice_id 1 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../dataset/OFA_data/vrd/vg_val_full.tsv slice_id 0 finished initializing row_count and line_idx-to-offset mapping
local datafile ../../dataset/OFA_data/vrd/vg_val_full.tsv slice_id 3 finished initializing row_count and line_idx-to-offset mapping
file ../../dataset/OFA_data/vrd/vg_val_full.tsv slice_id 0 row count 48187 total row count 192746
file ../../dataset/OFA_data/vrd/vg_val_full.tsv slice_id 3 row count 48186 total row count 192746
/data/hulab/zcai75/anaconda3/envs/vilt/lib/python3.8/site-packages/torchvision/transforms/transforms.py:332: UserWarning: Argument 'interpolation' of type int is deprecated since 0.13 and will be removed in 0.15. Please use InterpolationMode enum.
  warnings.warn(
/data/hulab/zcai75/anaconda3/envs/vilt/lib/python3.8/site-packages/torchvision/transforms/transforms.py:332: UserWarning: Argument 'interpolation' of type int is deprecated since 0.13 and will be removed in 0.15. Please use InterpolationMode enum.
  warnings.warn(
local datafile ../../dataset/OFA_data/vrd/vg_val_full.tsv slice_id 2 finished initializing row_count and line_idx-to-offset mapping
file ../../dataset/OFA_data/vrd/vg_val_full.tsv slice_id 2 row count 48186 total row count 192746
/data/hulab/zcai75/anaconda3/envs/vilt/lib/python3.8/site-packages/torchvision/transforms/transforms.py:332: UserWarning: Argument 'interpolation' of type int is deprecated since 0.13 and will be removed in 0.15. Please use InterpolationMode enum.
  warnings.warn(
local datafile ../../dataset/OFA_data/vrd/vg_val_full.tsv slice_id 1 finished initializing row_count and line_idx-to-offset mapping
file ../../dataset/OFA_data/vrd/vg_val_full.tsv slice_id 1 row count 48187 total row count 192746
/data/hulab/zcai75/anaconda3/envs/vilt/lib/python3.8/site-packages/torchvision/transforms/transforms.py:332: UserWarning: Argument 'interpolation' of type int is deprecated since 0.13 and will be removed in 0.15. Please use InterpolationMode enum.
  warnings.warn(
2023-06-27 02:13:20 - distributed_c10d.py[line:228] - INFO: Added key: store_based_barrier_key:2 to store for rank: 0
2023-06-27 02:13:20 - distributed_c10d.py[line:262] - INFO: Rank 0: Completed store-based barrier for key:store_based_barrier_key:2 with 4 nodes.
2023-06-27 02:13:20 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_tokens.weight <- decoder.embed_tokens.weight
2023-06-27 02:13:20 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_tokens.weight <- decoder.output_projection.weight
2023-06-27 02:13:20 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer1.0.conv1.bias
2023-06-27 02:13:20 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer1.0.conv2.bias
2023-06-27 02:13:20 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer1.0.conv3.bias
2023-06-27 02:13:20 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer1.0.downsample.0.bias
2023-06-27 02:13:20 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer1.1.conv1.bias
2023-06-27 02:13:20 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer1.1.conv2.bias
2023-06-27 02:13:20 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer1.1.conv3.bias
2023-06-27 02:13:20 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer1.2.conv1.bias
2023-06-27 02:13:20 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer1.2.conv2.bias
2023-06-27 02:13:20 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer1.2.conv3.bias
2023-06-27 02:13:20 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.0.conv1.bias
2023-06-27 02:13:20 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.0.conv2.bias
2023-06-27 02:13:20 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.0.conv3.bias
2023-06-27 02:13:20 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.0.downsample.0.bias
2023-06-27 02:13:20 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.1.conv1.bias
2023-06-27 02:13:20 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.1.conv2.bias
2023-06-27 02:13:20 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.1.conv3.bias
2023-06-27 02:13:20 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.2.conv1.bias
2023-06-27 02:13:20 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.2.conv2.bias
2023-06-27 02:13:20 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.2.conv3.bias
2023-06-27 02:13:20 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.3.conv1.bias
2023-06-27 02:13:20 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.3.conv2.bias
2023-06-27 02:13:20 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.3.conv3.bias
2023-06-27 02:13:20 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.0.conv1.bias
2023-06-27 02:13:20 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.0.conv2.bias
2023-06-27 02:13:20 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.0.conv3.bias
2023-06-27 02:13:20 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.0.downsample.0.bias
2023-06-27 02:13:20 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.1.conv1.bias
2023-06-27 02:13:20 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.1.conv2.bias
2023-06-27 02:13:20 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.1.conv3.bias
2023-06-27 02:13:20 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.2.conv1.bias
2023-06-27 02:13:20 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.2.conv2.bias
2023-06-27 02:13:20 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.2.conv3.bias
2023-06-27 02:13:20 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.3.conv1.bias
2023-06-27 02:13:20 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.3.conv2.bias
2023-06-27 02:13:20 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.3.conv3.bias
2023-06-27 02:13:20 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.4.conv1.bias
2023-06-27 02:13:20 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.4.conv2.bias
2023-06-27 02:13:20 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.4.conv3.bias
2023-06-27 02:13:20 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.5.conv1.bias
2023-06-27 02:13:20 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.5.conv2.bias
2023-06-27 02:13:20 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.5.conv3.bias
2023-06-27 02:13:20 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.6.conv1.bias
2023-06-27 02:13:20 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.6.conv2.bias
2023-06-27 02:13:20 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.6.conv3.bias
2023-06-27 02:13:20 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.7.conv1.bias
2023-06-27 02:13:20 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.7.conv2.bias
2023-06-27 02:13:20 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.7.conv3.bias
2023-06-27 02:13:20 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.8.conv1.bias
2023-06-27 02:13:20 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.8.conv2.bias
2023-06-27 02:13:20 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.8.conv3.bias
2023-06-27 02:13:20 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.9.conv1.bias
2023-06-27 02:13:20 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.9.conv2.bias
2023-06-27 02:13:20 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.9.conv3.bias
2023-06-27 02:13:20 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.10.conv1.bias
2023-06-27 02:13:20 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.10.conv2.bias
2023-06-27 02:13:20 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.10.conv3.bias
2023-06-27 02:13:20 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.11.conv1.bias
2023-06-27 02:13:20 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.11.conv2.bias
2023-06-27 02:13:20 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.11.conv3.bias
2023-06-27 02:13:20 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.12.conv1.bias
2023-06-27 02:13:20 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.12.conv2.bias
2023-06-27 02:13:20 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.12.conv3.bias
2023-06-27 02:13:20 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.13.conv1.bias
2023-06-27 02:13:20 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.13.conv2.bias
2023-06-27 02:13:20 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.13.conv3.bias
2023-06-27 02:13:20 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.14.conv1.bias
2023-06-27 02:13:20 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.14.conv2.bias
2023-06-27 02:13:20 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.14.conv3.bias
2023-06-27 02:13:20 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.15.conv1.bias
2023-06-27 02:13:20 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.15.conv2.bias
2023-06-27 02:13:20 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.15.conv3.bias
2023-06-27 02:13:20 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.16.conv1.bias
2023-06-27 02:13:20 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.16.conv2.bias
2023-06-27 02:13:20 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.16.conv3.bias
2023-06-27 02:13:20 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.17.conv1.bias
2023-06-27 02:13:20 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.17.conv2.bias
2023-06-27 02:13:20 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.17.conv3.bias
2023-06-27 02:13:20 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.18.conv1.bias
2023-06-27 02:13:20 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.18.conv2.bias
2023-06-27 02:13:20 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.18.conv3.bias
2023-06-27 02:13:20 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.19.conv1.bias
2023-06-27 02:13:20 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.19.conv2.bias
2023-06-27 02:13:20 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.19.conv3.bias
2023-06-27 02:13:20 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.20.conv1.bias
2023-06-27 02:13:20 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.20.conv2.bias
2023-06-27 02:13:20 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.20.conv3.bias
2023-06-27 02:13:20 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.21.conv1.bias
2023-06-27 02:13:20 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.21.conv2.bias
2023-06-27 02:13:20 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.21.conv3.bias
2023-06-27 02:13:20 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.22.conv1.bias
2023-06-27 02:13:20 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.22.conv2.bias
2023-06-27 02:13:20 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.22.conv3.bias
2023-06-27 02:13:20 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- decoder.output_projection.bias
2023-06-27 02:13:20 - utils.py[line:759] - INFO: ***********************CUDA enviroments for all 4 workers***********************
2023-06-27 02:13:20 - utils.py[line:761] - INFO: rank   0: capabilities =  8.6  ; total memory = 23.688 GB ; name = NVIDIA GeForce RTX 3090 Ti              
2023-06-27 02:13:20 - utils.py[line:761] - INFO: rank   1: capabilities =  8.6  ; total memory = 23.688 GB ; name = NVIDIA GeForce RTX 3090 Ti              
2023-06-27 02:13:20 - utils.py[line:761] - INFO: rank   2: capabilities =  8.6  ; total memory = 23.688 GB ; name = NVIDIA GeForce RTX 3090 Ti              
2023-06-27 02:13:20 - utils.py[line:761] - INFO: rank   3: capabilities =  8.6  ; total memory = 23.688 GB ; name = NVIDIA GeForce RTX 3090 Ti              
2023-06-27 02:13:20 - utils.py[line:767] - INFO: ***********************CUDA enviroments for all 4 workers***********************
2023-06-27 02:13:20 - train.py[line:152] - INFO: training on 4 devices (GPUs/TPUs)
2023-06-27 02:13:20 - train.py[line:157] - INFO: max tokens per device = None and max sentences per device = 10
2023-06-27 02:13:20 - trainer.py[line:458] - INFO: Preparing to load checkpoint ../../checkpoints/ofa_base.pt
local datafile ../../dataset/OFA_data/vrd/vg_train_full.tsv slice_id 2 begin to initialize row_count and line_idx-to-offset mapping
2023-06-27 02:13:20 - trainer.py[line:624] - INFO: No existing checkpoint found ../../checkpoints/ofa_base.pt
2023-06-27 02:13:20 - trainer.py[line:639] - INFO: loading train data for epoch 1
local datafile ../../dataset/OFA_data/vrd/vg_train_full.tsv slice_id 1 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../dataset/OFA_data/vrd/vg_train_full.tsv slice_id 3 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../dataset/OFA_data/vrd/vg_train_full.tsv slice_id 0 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../dataset/OFA_data/vrd/vg_train_full.tsv slice_id 2 finished initializing row_count and line_idx-to-offset mapping
file ../../dataset/OFA_data/vrd/vg_train_full.tsv slice_id 2 row count 105470 total row count 421879
local datafile ../../dataset/OFA_data/vrd/vg_train_full.tsv slice_id 1 finished initializing row_count and line_idx-to-offset mapping
file ../../dataset/OFA_data/vrd/vg_train_full.tsv slice_id 1 row count 105470 total row count 421879
local datafile ../../dataset/OFA_data/vrd/vg_train_full.tsv slice_id 0 finished initializing row_count and line_idx-to-offset mapping
file ../../dataset/OFA_data/vrd/vg_train_full.tsv slice_id 0 row count 105470 total row count 421879
local datafile ../../dataset/OFA_data/vrd/vg_train_full.tsv slice_id 3 finished initializing row_count and line_idx-to-offset mapping
file ../../dataset/OFA_data/vrd/vg_train_full.tsv slice_id 3 row count 105469 total row count 421879
slice_id 1 seek offset 105470
slice_id 2 seek offset 210940
slice_id 3 seek offset 316410
Total steps 42192, warmup steps 2531, warmup_factor 0.0003951007506914263
Total steps 42192, warmup steps 2531, warmup_factor 0.0003951007506914263
Total steps 42192, warmup steps 2531, warmup_factor 0.0003951007506914263
slice_id 0 seek offset 0
Total steps 42192, warmup steps 2531, warmup_factor 0.0003951007506914263
wandb: Currently logged in as: jackcai1206. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /home/zcai75/Github/OFA_forked/run_scripts/vrd/wandb/run-20230627_021321-hw2w0fcg
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run _16_3e-5_512_rare_3
wandb:  View project at https://wandb.ai/jackcai1206/OFA-VG
wandb:  View run at https://wandb.ai/jackcai1206/OFA-VG/runs/hw2w0fcg
2023-06-27 02:13:27 - trainer.py[line:703] - INFO: begin training epoch 1
2023-06-27 02:13:27 - train.py[line:305] - INFO: Start iterating over samples
2023-06-27 02:13:50 - progress_bar.py[line:272] - INFO: epoch 001:     10 / 2637 loss=11.042, loss_v1=0, loss_v2=0, nll_loss=11.047, ntokens=1253.7, nsentences=160, sample_size=1253.7, sample_size_v1=0, sample_size_v2=0, ppl=2115.93, wps=605.8, ups=0.48, wpb=1253.7, bsz=160, num_updates=10, lr=1.1853e-07, gnorm=20.703, clip=100, loss_scale=128, train_wall=23, gb_free=8.9, wall=30
2023-06-27 02:14:11 - progress_bar.py[line:272] - INFO: epoch 001:     20 / 2637 loss=11.013, loss_v1=0, loss_v2=0, nll_loss=11.015, ntokens=1263.4, nsentences=160, sample_size=1263.4, sample_size_v1=0, sample_size_v2=0, ppl=2069.51, wps=609.5, ups=0.48, wpb=1263.4, bsz=160, num_updates=20, lr=2.3706e-07, gnorm=20.996, clip=100, loss_scale=128, train_wall=21, gb_free=8.9, wall=51
2023-06-27 02:14:31 - progress_bar.py[line:272] - INFO: epoch 001:     30 / 2637 loss=10.885, loss_v1=0, loss_v2=0, nll_loss=10.872, ntokens=1256.1, nsentences=160, sample_size=1256.1, sample_size_v1=0, sample_size_v2=0, ppl=1874.28, wps=602.6, ups=0.48, wpb=1256.1, bsz=160, num_updates=30, lr=3.55591e-07, gnorm=20.72, clip=100, loss_scale=128, train_wall=21, gb_free=8.9, wall=72
2023-06-27 02:14:52 - progress_bar.py[line:272] - INFO: epoch 001:     40 / 2637 loss=10.576, loss_v1=0, loss_v2=0, nll_loss=10.529, ntokens=1262.9, nsentences=160, sample_size=1262.9, sample_size_v1=0, sample_size_v2=0, ppl=1477.88, wps=606.7, ups=0.48, wpb=1262.9, bsz=160, num_updates=40, lr=4.74121e-07, gnorm=19.854, clip=100, loss_scale=128, train_wall=21, gb_free=8.9, wall=93
2023-06-27 02:15:13 - progress_bar.py[line:272] - INFO: epoch 001:     50 / 2637 loss=10.106, loss_v1=0, loss_v2=0, nll_loss=10.006, ntokens=1239.3, nsentences=160, sample_size=1239.3, sample_size_v1=0, sample_size_v2=0, ppl=1028.6, wps=595.1, ups=0.48, wpb=1239.3, bsz=160, num_updates=50, lr=5.92651e-07, gnorm=18.015, clip=100, loss_scale=128, train_wall=21, gb_free=8.9, wall=113
2023-06-27 02:15:34 - progress_bar.py[line:272] - INFO: epoch 001:     60 / 2637 loss=9.658, loss_v1=0, loss_v2=0, nll_loss=9.509, ntokens=1245.7, nsentences=160, sample_size=1245.7, sample_size_v1=0, sample_size_v2=0, ppl=728.64, wps=597.9, ups=0.48, wpb=1245.7, bsz=160, num_updates=60, lr=7.11181e-07, gnorm=16.097, clip=100, loss_scale=128, train_wall=21, gb_free=8.9, wall=134
2023-06-27 02:15:55 - progress_bar.py[line:272] - INFO: epoch 001:     70 / 2637 loss=9.176, loss_v1=0, loss_v2=0, nll_loss=8.973, ntokens=1256.8, nsentences=160, sample_size=1256.8, sample_size_v1=0, sample_size_v2=0, ppl=502.63, wps=602.8, ups=0.48, wpb=1256.8, bsz=160, num_updates=70, lr=8.29712e-07, gnorm=13.667, clip=100, loss_scale=128, train_wall=21, gb_free=8.9, wall=155
2023-06-27 02:16:16 - progress_bar.py[line:272] - INFO: epoch 001:     80 / 2637 loss=8.784, loss_v1=0, loss_v2=0, nll_loss=8.537, ntokens=1246.8, nsentences=160, sample_size=1246.8, sample_size_v1=0, sample_size_v2=0, ppl=371.55, wps=598, ups=0.48, wpb=1246.8, bsz=160, num_updates=80, lr=9.48242e-07, gnorm=11.93, clip=100, loss_scale=128, train_wall=21, gb_free=8.9, wall=176
2023-06-27 02:16:37 - progress_bar.py[line:272] - INFO: epoch 001:     90 / 2637 loss=8.369, loss_v1=0, loss_v2=0, nll_loss=8.076, ntokens=1257.7, nsentences=160, sample_size=1257.7, sample_size_v1=0, sample_size_v2=0, ppl=269.84, wps=602.9, ups=0.48, wpb=1257.7, bsz=160, num_updates=90, lr=1.06677e-06, gnorm=10.524, clip=100, loss_scale=128, train_wall=21, gb_free=8.9, wall=197
2023-06-27 02:16:57 - progress_bar.py[line:272] - INFO: epoch 001:    100 / 2637 loss=7.974, loss_v1=0, loss_v2=0, nll_loss=7.637, ntokens=1253.2, nsentences=160, sample_size=1253.2, sample_size_v1=0, sample_size_v2=0, ppl=198.99, wps=601.1, ups=0.48, wpb=1253.2, bsz=160, num_updates=100, lr=1.1853e-06, gnorm=9.396, clip=100, loss_scale=128, train_wall=21, gb_free=8.9, wall=218
2023-06-27 02:17:18 - progress_bar.py[line:272] - INFO: epoch 001:    110 / 2637 loss=7.627, loss_v1=0, loss_v2=0, nll_loss=7.25, ntokens=1243, nsentences=160, sample_size=1243, sample_size_v1=0, sample_size_v2=0, ppl=152.17, wps=596.4, ups=0.48, wpb=1243, bsz=160, num_updates=110, lr=1.30383e-06, gnorm=8.792, clip=100, loss_scale=128, train_wall=21, gb_free=8.9, wall=239
2023-06-27 02:17:39 - progress_bar.py[line:272] - INFO: epoch 001:    120 / 2637 loss=7.348, loss_v1=0, loss_v2=0, nll_loss=6.939, ntokens=1253.5, nsentences=160, sample_size=1253.5, sample_size_v1=0, sample_size_v2=0, ppl=122.73, wps=602.8, ups=0.48, wpb=1253.5, bsz=160, num_updates=120, lr=1.42236e-06, gnorm=8.226, clip=100, loss_scale=128, train_wall=21, gb_free=8.9, wall=259
2023-06-27 02:18:00 - progress_bar.py[line:272] - INFO: epoch 001:    130 / 2637 loss=7.107, loss_v1=0, loss_v2=0, nll_loss=6.67, ntokens=1234.1, nsentences=160, sample_size=1234.1, sample_size_v1=0, sample_size_v2=0, ppl=101.84, wps=592.8, ups=0.48, wpb=1234.1, bsz=160, num_updates=130, lr=1.54089e-06, gnorm=7.86, clip=100, loss_scale=128, train_wall=21, gb_free=8.9, wall=280
2023-06-27 02:18:21 - progress_bar.py[line:272] - INFO: epoch 001:    140 / 2637 loss=6.878, loss_v1=0, loss_v2=0, nll_loss=6.415, ntokens=1248.9, nsentences=160, sample_size=1248.9, sample_size_v1=0, sample_size_v2=0, ppl=85.35, wps=599.5, ups=0.48, wpb=1248.9, bsz=160, num_updates=140, lr=1.65942e-06, gnorm=7.66, clip=100, loss_scale=128, train_wall=21, gb_free=8.9, wall=301
2023-06-27 02:18:42 - progress_bar.py[line:272] - INFO: epoch 001:    150 / 2637 loss=6.691, loss_v1=0, loss_v2=0, nll_loss=6.206, ntokens=1250, nsentences=160, sample_size=1250, sample_size_v1=0, sample_size_v2=0, ppl=73.83, wps=600, ups=0.48, wpb=1250, bsz=160, num_updates=150, lr=1.77795e-06, gnorm=7.436, clip=100, loss_scale=128, train_wall=21, gb_free=8.9, wall=322
2023-06-27 02:19:02 - progress_bar.py[line:272] - INFO: epoch 001:    160 / 2637 loss=6.479, loss_v1=0, loss_v2=0, nll_loss=5.969, ntokens=1245.8, nsentences=160, sample_size=1245.8, sample_size_v1=0, sample_size_v2=0, ppl=62.64, wps=598.7, ups=0.48, wpb=1245.8, bsz=160, num_updates=160, lr=1.89648e-06, gnorm=7.186, clip=100, loss_scale=128, train_wall=21, gb_free=8.9, wall=343
2023-06-27 02:19:23 - progress_bar.py[line:272] - INFO: epoch 001:    170 / 2637 loss=6.255, loss_v1=0, loss_v2=0, nll_loss=5.718, ntokens=1240.5, nsentences=160, sample_size=1240.5, sample_size_v1=0, sample_size_v2=0, ppl=52.64, wps=596.1, ups=0.48, wpb=1240.5, bsz=160, num_updates=170, lr=2.01501e-06, gnorm=6.926, clip=100, loss_scale=128, train_wall=21, gb_free=8.9, wall=363
2023-06-27 02:19:44 - progress_bar.py[line:272] - INFO: epoch 001:    180 / 2637 loss=6.067, loss_v1=0, loss_v2=0, nll_loss=5.507, ntokens=1240.9, nsentences=160, sample_size=1240.9, sample_size_v1=0, sample_size_v2=0, ppl=45.47, wps=595.7, ups=0.48, wpb=1240.9, bsz=160, num_updates=180, lr=2.13354e-06, gnorm=6.714, clip=100, loss_scale=128, train_wall=21, gb_free=8.9, wall=384
2023-06-27 02:20:05 - progress_bar.py[line:272] - INFO: epoch 001:    190 / 2637 loss=5.875, loss_v1=0, loss_v2=0, nll_loss=5.289, ntokens=1238.7, nsentences=160, sample_size=1238.7, sample_size_v1=0, sample_size_v2=0, ppl=39.1, wps=595.2, ups=0.48, wpb=1238.7, bsz=160, num_updates=190, lr=2.25207e-06, gnorm=6.346, clip=100, loss_scale=128, train_wall=21, gb_free=8.9, wall=405
2023-06-27 02:20:26 - progress_bar.py[line:272] - INFO: epoch 001:    200 / 2637 loss=5.673, loss_v1=0, loss_v2=0, nll_loss=5.06, ntokens=1239.4, nsentences=160, sample_size=1239.4, sample_size_v1=0, sample_size_v2=0, ppl=33.36, wps=595, ups=0.48, wpb=1239.4, bsz=160, num_updates=200, lr=2.3706e-06, gnorm=5.992, clip=100, loss_scale=128, train_wall=21, gb_free=8.9, wall=426
2023-06-27 02:20:46 - progress_bar.py[line:272] - INFO: epoch 001:    210 / 2637 loss=5.444, loss_v1=0, loss_v2=0, nll_loss=4.801, ntokens=1249.1, nsentences=160, sample_size=1249.1, sample_size_v1=0, sample_size_v2=0, ppl=27.88, wps=600.2, ups=0.48, wpb=1249.1, bsz=160, num_updates=210, lr=2.48913e-06, gnorm=5.616, clip=100, loss_scale=128, train_wall=21, gb_free=8.9, wall=447
2023-06-27 02:21:07 - progress_bar.py[line:272] - INFO: epoch 001:    220 / 2637 loss=5.195, loss_v1=0, loss_v2=0, nll_loss=4.516, ntokens=1220.4, nsentences=160, sample_size=1220.4, sample_size_v1=0, sample_size_v2=0, ppl=22.88, wps=586.3, ups=0.48, wpb=1220.4, bsz=160, num_updates=220, lr=2.60766e-06, gnorm=5.218, clip=100, loss_scale=128, train_wall=21, gb_free=8.9, wall=468
2023-06-27 02:21:28 - progress_bar.py[line:272] - INFO: epoch 001:    230 / 2637 loss=5.082, loss_v1=0, loss_v2=0, nll_loss=4.383, ntokens=1257.7, nsentences=160, sample_size=1257.7, sample_size_v1=0, sample_size_v2=0, ppl=20.87, wps=604.5, ups=0.48, wpb=1257.7, bsz=160, num_updates=230, lr=2.7262e-06, gnorm=4.776, clip=100, loss_scale=128, train_wall=21, gb_free=8.9, wall=488
2023-06-27 02:21:49 - progress_bar.py[line:272] - INFO: epoch 001:    240 / 2637 loss=4.876, loss_v1=0, loss_v2=0, nll_loss=4.145, ntokens=1248.9, nsentences=160, sample_size=1248.9, sample_size_v1=0, sample_size_v2=0, ppl=17.69, wps=599.9, ups=0.48, wpb=1248.9, bsz=160, num_updates=240, lr=2.84473e-06, gnorm=4.27, clip=100, loss_scale=128, train_wall=21, gb_free=8.9, wall=509
2023-06-27 02:22:10 - progress_bar.py[line:272] - INFO: epoch 001:    250 / 2637 loss=4.753, loss_v1=0, loss_v2=0, nll_loss=3.999, ntokens=1263.2, nsentences=160, sample_size=1263.2, sample_size_v1=0, sample_size_v2=0, ppl=15.99, wps=606.7, ups=0.48, wpb=1263.2, bsz=160, num_updates=250, lr=2.96326e-06, gnorm=3.923, clip=100, loss_scale=128, train_wall=21, gb_free=8.9, wall=530
2023-06-27 02:22:31 - progress_bar.py[line:272] - INFO: epoch 001:    260 / 2637 loss=4.551, loss_v1=0, loss_v2=0, nll_loss=3.762, ntokens=1246.9, nsentences=160, sample_size=1246.9, sample_size_v1=0, sample_size_v2=0, ppl=13.56, wps=598.9, ups=0.48, wpb=1246.9, bsz=160, num_updates=260, lr=3.08179e-06, gnorm=3.626, clip=100, loss_scale=128, train_wall=21, gb_free=8.9, wall=551
2023-06-27 02:22:51 - progress_bar.py[line:272] - INFO: epoch 001:    270 / 2637 loss=4.477, loss_v1=0, loss_v2=0, nll_loss=3.672, ntokens=1249.6, nsentences=160, sample_size=1249.6, sample_size_v1=0, sample_size_v2=0, ppl=12.75, wps=600.5, ups=0.48, wpb=1249.6, bsz=160, num_updates=270, lr=3.20032e-06, gnorm=3.227, clip=100, loss_scale=128, train_wall=21, gb_free=8.9, wall=572
2023-06-27 02:23:12 - progress_bar.py[line:272] - INFO: epoch 001:    280 / 2637 loss=4.452, loss_v1=0, loss_v2=0, nll_loss=3.634, ntokens=1254, nsentences=160, sample_size=1254, sample_size_v1=0, sample_size_v2=0, ppl=12.42, wps=602.6, ups=0.48, wpb=1254, bsz=160, num_updates=280, lr=3.31885e-06, gnorm=3.011, clip=100, loss_scale=128, train_wall=21, gb_free=8.9, wall=592
2023-06-27 02:23:33 - progress_bar.py[line:272] - INFO: epoch 001:    290 / 2637 loss=4.293, loss_v1=0, loss_v2=0, nll_loss=3.45, ntokens=1243.8, nsentences=160, sample_size=1243.8, sample_size_v1=0, sample_size_v2=0, ppl=10.93, wps=597.7, ups=0.48, wpb=1243.8, bsz=160, num_updates=290, lr=3.43738e-06, gnorm=2.911, clip=100, loss_scale=128, train_wall=21, gb_free=8.9, wall=613
2023-06-27 02:23:54 - progress_bar.py[line:272] - INFO: epoch 001:    300 / 2637 loss=4.261, loss_v1=0, loss_v2=0, nll_loss=3.41, ntokens=1234.2, nsentences=160, sample_size=1234.2, sample_size_v1=0, sample_size_v2=0, ppl=10.63, wps=593.3, ups=0.48, wpb=1234.2, bsz=160, num_updates=300, lr=3.55591e-06, gnorm=2.666, clip=100, loss_scale=128, train_wall=21, gb_free=8.9, wall=634
2023-06-27 02:24:15 - progress_bar.py[line:272] - INFO: epoch 001:    310 / 2637 loss=4.113, loss_v1=0, loss_v2=0, nll_loss=3.239, ntokens=1235.4, nsentences=160, sample_size=1235.4, sample_size_v1=0, sample_size_v2=0, ppl=9.44, wps=593.6, ups=0.48, wpb=1235.4, bsz=160, num_updates=310, lr=3.67444e-06, gnorm=2.644, clip=100, loss_scale=128, train_wall=21, gb_free=8.9, wall=655
2023-06-27 02:24:35 - progress_bar.py[line:272] - INFO: epoch 001:    320 / 2637 loss=4.049, loss_v1=0, loss_v2=0, nll_loss=3.164, ntokens=1237.8, nsentences=160, sample_size=1237.8, sample_size_v1=0, sample_size_v2=0, ppl=8.96, wps=595.2, ups=0.48, wpb=1237.8, bsz=160, num_updates=320, lr=3.79297e-06, gnorm=2.496, clip=100, loss_scale=128, train_wall=21, gb_free=8.9, wall=676
2023-06-27 02:24:56 - progress_bar.py[line:272] - INFO: epoch 001:    330 / 2637 loss=4.065, loss_v1=0, loss_v2=0, nll_loss=3.179, ntokens=1262.9, nsentences=160, sample_size=1262.9, sample_size_v1=0, sample_size_v2=0, ppl=9.05, wps=606.8, ups=0.48, wpb=1262.9, bsz=160, num_updates=330, lr=3.9115e-06, gnorm=2.482, clip=100, loss_scale=128, train_wall=21, gb_free=8.9, wall=697
2023-06-27 02:25:17 - progress_bar.py[line:272] - INFO: epoch 001:    340 / 2637 loss=3.92, loss_v1=0, loss_v2=0, nll_loss=3.014, ntokens=1234.4, nsentences=160, sample_size=1234.4, sample_size_v1=0, sample_size_v2=0, ppl=8.08, wps=593.5, ups=0.48, wpb=1234.4, bsz=160, num_updates=340, lr=4.03003e-06, gnorm=2.404, clip=100, loss_scale=128, train_wall=21, gb_free=8.9, wall=717
2023-06-27 02:25:38 - progress_bar.py[line:272] - INFO: epoch 001:    350 / 2637 loss=3.972, loss_v1=0, loss_v2=0, nll_loss=3.071, ntokens=1259.5, nsentences=160, sample_size=1259.5, sample_size_v1=0, sample_size_v2=0, ppl=8.4, wps=604.5, ups=0.48, wpb=1259.5, bsz=160, num_updates=350, lr=4.14856e-06, gnorm=2.286, clip=100, loss_scale=128, train_wall=21, gb_free=8.9, wall=738
2023-06-27 02:25:59 - progress_bar.py[line:272] - INFO: epoch 001:    360 / 2637 loss=3.871, loss_v1=0, loss_v2=0, nll_loss=2.953, ntokens=1250, nsentences=160, sample_size=1250, sample_size_v1=0, sample_size_v2=0, ppl=7.74, wps=598.3, ups=0.48, wpb=1250, bsz=160, num_updates=360, lr=4.26709e-06, gnorm=2.131, clip=100, loss_scale=128, train_wall=21, gb_free=8.9, wall=759
2023-06-27 02:26:20 - progress_bar.py[line:272] - INFO: epoch 001:    370 / 2637 loss=3.759, loss_v1=0, loss_v2=0, nll_loss=2.827, ntokens=1252.7, nsentences=160, sample_size=1252.7, sample_size_v1=0, sample_size_v2=0, ppl=7.09, wps=600.6, ups=0.48, wpb=1252.7, bsz=160, num_updates=370, lr=4.38562e-06, gnorm=2.157, clip=100, loss_scale=128, train_wall=21, gb_free=8.9, wall=780
2023-06-27 02:26:40 - progress_bar.py[line:272] - INFO: epoch 001:    380 / 2637 loss=3.782, loss_v1=0, loss_v2=0, nll_loss=2.85, ntokens=1247.4, nsentences=160, sample_size=1247.4, sample_size_v1=0, sample_size_v2=0, ppl=7.21, wps=598, ups=0.48, wpb=1247.4, bsz=160, num_updates=380, lr=4.50415e-06, gnorm=2.106, clip=100, loss_scale=128, train_wall=21, gb_free=8.9, wall=801
2023-06-27 02:27:01 - progress_bar.py[line:272] - INFO: epoch 001:    390 / 2637 loss=3.723, loss_v1=0, loss_v2=0, nll_loss=2.781, ntokens=1233.4, nsentences=160, sample_size=1233.4, sample_size_v1=0, sample_size_v2=0, ppl=6.87, wps=591.1, ups=0.48, wpb=1233.4, bsz=160, num_updates=390, lr=4.62268e-06, gnorm=2.004, clip=100, loss_scale=128, train_wall=21, gb_free=8.9, wall=822
2023-06-27 02:27:22 - progress_bar.py[line:272] - INFO: epoch 001:    400 / 2637 loss=3.692, loss_v1=0, loss_v2=0, nll_loss=2.746, ntokens=1251.7, nsentences=160, sample_size=1251.7, sample_size_v1=0, sample_size_v2=0, ppl=6.71, wps=600.2, ups=0.48, wpb=1251.7, bsz=160, num_updates=400, lr=4.74121e-06, gnorm=2.018, clip=100, loss_scale=128, train_wall=21, gb_free=8.9, wall=842
2023-06-27 02:27:43 - progress_bar.py[line:272] - INFO: epoch 001:    410 / 2637 loss=3.611, loss_v1=0, loss_v2=0, nll_loss=2.651, ntokens=1237.4, nsentences=160, sample_size=1237.4, sample_size_v1=0, sample_size_v2=0, ppl=6.28, wps=593.2, ups=0.48, wpb=1237.4, bsz=160, num_updates=410, lr=4.85974e-06, gnorm=1.917, clip=100, loss_scale=128, train_wall=21, gb_free=8.9, wall=863
2023-06-27 02:28:04 - progress_bar.py[line:272] - INFO: epoch 001:    420 / 2637 loss=3.6, loss_v1=0, loss_v2=0, nll_loss=2.639, ntokens=1269.3, nsentences=160, sample_size=1269.3, sample_size_v1=0, sample_size_v2=0, ppl=6.23, wps=608.9, ups=0.48, wpb=1269.3, bsz=160, num_updates=420, lr=4.97827e-06, gnorm=1.871, clip=100, loss_scale=128, train_wall=21, gb_free=8.9, wall=884
2023-06-27 02:28:25 - progress_bar.py[line:272] - INFO: epoch 001:    430 / 2637 loss=3.565, loss_v1=0, loss_v2=0, nll_loss=2.595, ntokens=1241.8, nsentences=160, sample_size=1241.8, sample_size_v1=0, sample_size_v2=0, ppl=6.04, wps=595.8, ups=0.48, wpb=1241.8, bsz=160, num_updates=430, lr=5.0968e-06, gnorm=1.896, clip=100, loss_scale=128, train_wall=21, gb_free=8.9, wall=905
2023-06-27 02:28:46 - progress_bar.py[line:272] - INFO: epoch 001:    440 / 2637 loss=3.609, loss_v1=0, loss_v2=0, nll_loss=2.647, ntokens=1251.6, nsentences=160, sample_size=1251.6, sample_size_v1=0, sample_size_v2=0, ppl=6.26, wps=599.6, ups=0.48, wpb=1251.6, bsz=160, num_updates=440, lr=5.21533e-06, gnorm=1.827, clip=100, loss_scale=128, train_wall=21, gb_free=8.9, wall=926
2023-06-27 02:29:06 - progress_bar.py[line:272] - INFO: epoch 001:    450 / 2637 loss=3.529, loss_v1=0, loss_v2=0, nll_loss=2.551, ntokens=1241.5, nsentences=160, sample_size=1241.5, sample_size_v1=0, sample_size_v2=0, ppl=5.86, wps=595.5, ups=0.48, wpb=1241.5, bsz=160, num_updates=450, lr=5.33386e-06, gnorm=1.802, clip=100, loss_scale=128, train_wall=21, gb_free=8.9, wall=947
2023-06-27 02:29:27 - progress_bar.py[line:272] - INFO: epoch 001:    460 / 2637 loss=3.516, loss_v1=0, loss_v2=0, nll_loss=2.54, ntokens=1269.3, nsentences=160, sample_size=1269.3, sample_size_v1=0, sample_size_v2=0, ppl=5.82, wps=608.7, ups=0.48, wpb=1269.3, bsz=160, num_updates=460, lr=5.45239e-06, gnorm=1.715, clip=100, loss_scale=128, train_wall=21, gb_free=8.9, wall=968
2023-06-27 02:29:48 - progress_bar.py[line:272] - INFO: epoch 001:    470 / 2637 loss=3.523, loss_v1=0, loss_v2=0, nll_loss=2.543, ntokens=1243.9, nsentences=160, sample_size=1243.9, sample_size_v1=0, sample_size_v2=0, ppl=5.83, wps=597.3, ups=0.48, wpb=1243.9, bsz=160, num_updates=470, lr=5.57092e-06, gnorm=1.7, clip=100, loss_scale=128, train_wall=21, gb_free=8.9, wall=988
2023-06-27 02:30:09 - progress_bar.py[line:272] - INFO: epoch 001:    480 / 2637 loss=3.535, loss_v1=0, loss_v2=0, nll_loss=2.562, ntokens=1261.4, nsentences=160, sample_size=1261.4, sample_size_v1=0, sample_size_v2=0, ppl=5.91, wps=605.6, ups=0.48, wpb=1261.4, bsz=160, num_updates=480, lr=5.68945e-06, gnorm=1.769, clip=100, loss_scale=128, train_wall=21, gb_free=8.9, wall=1009
2023-06-27 02:30:30 - progress_bar.py[line:272] - INFO: epoch 001:    490 / 2637 loss=3.461, loss_v1=0, loss_v2=0, nll_loss=2.474, ntokens=1258.5, nsentences=160, sample_size=1258.5, sample_size_v1=0, sample_size_v2=0, ppl=5.56, wps=604, ups=0.48, wpb=1258.5, bsz=160, num_updates=490, lr=5.80798e-06, gnorm=1.664, clip=100, loss_scale=128, train_wall=21, gb_free=8.9, wall=1030
2023-06-27 02:30:51 - progress_bar.py[line:272] - INFO: epoch 001:    500 / 2637 loss=3.448, loss_v1=0, loss_v2=0, nll_loss=2.458, ntokens=1270.7, nsentences=160, sample_size=1270.7, sample_size_v1=0, sample_size_v2=0, ppl=5.5, wps=610.2, ups=0.48, wpb=1270.7, bsz=160, num_updates=500, lr=5.92651e-06, gnorm=1.643, clip=100, loss_scale=128, train_wall=21, gb_free=8.9, wall=1051
2023-06-27 02:31:12 - progress_bar.py[line:272] - INFO: epoch 001:    510 / 2637 loss=3.386, loss_v1=0, loss_v2=0, nll_loss=2.387, ntokens=1257.7, nsentences=160, sample_size=1257.7, sample_size_v1=0, sample_size_v2=0, ppl=5.23, wps=603.9, ups=0.48, wpb=1257.7, bsz=160, num_updates=510, lr=6.04504e-06, gnorm=1.675, clip=100, loss_scale=128, train_wall=21, gb_free=8.9, wall=1072
2023-06-27 02:31:32 - progress_bar.py[line:272] - INFO: epoch 001:    520 / 2637 loss=3.407, loss_v1=0, loss_v2=0, nll_loss=2.409, ntokens=1246.3, nsentences=160, sample_size=1246.3, sample_size_v1=0, sample_size_v2=0, ppl=5.31, wps=598.9, ups=0.48, wpb=1246.3, bsz=160, num_updates=520, lr=6.16357e-06, gnorm=1.547, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=1093
2023-06-27 02:31:53 - progress_bar.py[line:272] - INFO: epoch 001:    530 / 2637 loss=3.335, loss_v1=0, loss_v2=0, nll_loss=2.332, ntokens=1244.4, nsentences=160, sample_size=1244.4, sample_size_v1=0, sample_size_v2=0, ppl=5.03, wps=596.8, ups=0.48, wpb=1244.4, bsz=160, num_updates=530, lr=6.2821e-06, gnorm=1.611, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=1113
2023-06-27 02:32:14 - progress_bar.py[line:272] - INFO: epoch 001:    540 / 2637 loss=3.358, loss_v1=0, loss_v2=0, nll_loss=2.354, ntokens=1257.5, nsentences=160, sample_size=1257.5, sample_size_v1=0, sample_size_v2=0, ppl=5.11, wps=602.9, ups=0.48, wpb=1257.5, bsz=160, num_updates=540, lr=6.40063e-06, gnorm=1.589, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=1134
2023-06-27 02:32:35 - progress_bar.py[line:272] - INFO: epoch 001:    550 / 2637 loss=3.312, loss_v1=0, loss_v2=0, nll_loss=2.302, ntokens=1262.4, nsentences=160, sample_size=1262.4, sample_size_v1=0, sample_size_v2=0, ppl=4.93, wps=603.8, ups=0.48, wpb=1262.4, bsz=160, num_updates=550, lr=6.51916e-06, gnorm=1.539, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=1155
2023-06-27 02:32:56 - progress_bar.py[line:272] - INFO: epoch 001:    560 / 2637 loss=3.331, loss_v1=0, loss_v2=0, nll_loss=2.321, ntokens=1265.7, nsentences=160, sample_size=1265.7, sample_size_v1=0, sample_size_v2=0, ppl=5, wps=606, ups=0.48, wpb=1265.7, bsz=160, num_updates=560, lr=6.63769e-06, gnorm=1.462, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=1176
2023-06-27 02:33:17 - progress_bar.py[line:272] - INFO: epoch 001:    570 / 2637 loss=3.278, loss_v1=0, loss_v2=0, nll_loss=2.263, ntokens=1243.5, nsentences=160, sample_size=1243.5, sample_size_v1=0, sample_size_v2=0, ppl=4.8, wps=596.4, ups=0.48, wpb=1243.5, bsz=160, num_updates=570, lr=6.75622e-06, gnorm=1.444, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=1197
2023-06-27 02:33:38 - progress_bar.py[line:272] - INFO: epoch 001:    580 / 2637 loss=3.209, loss_v1=0, loss_v2=0, nll_loss=2.188, ntokens=1249.8, nsentences=160, sample_size=1249.8, sample_size_v1=0, sample_size_v2=0, ppl=4.56, wps=600.4, ups=0.48, wpb=1249.8, bsz=160, num_updates=580, lr=6.87475e-06, gnorm=1.408, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=1218
2023-06-27 02:33:58 - progress_bar.py[line:272] - INFO: epoch 001:    590 / 2637 loss=3.242, loss_v1=0, loss_v2=0, nll_loss=2.22, ntokens=1258.7, nsentences=160, sample_size=1258.7, sample_size_v1=0, sample_size_v2=0, ppl=4.66, wps=603.7, ups=0.48, wpb=1258.7, bsz=160, num_updates=590, lr=6.99328e-06, gnorm=1.517, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=1239
2023-06-27 02:34:19 - progress_bar.py[line:272] - INFO: epoch 001:    600 / 2637 loss=3.219, loss_v1=0, loss_v2=0, nll_loss=2.196, ntokens=1271.6, nsentences=160, sample_size=1271.6, sample_size_v1=0, sample_size_v2=0, ppl=4.58, wps=609.5, ups=0.48, wpb=1271.6, bsz=160, num_updates=600, lr=7.11181e-06, gnorm=1.567, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=1260
2023-06-27 02:34:40 - progress_bar.py[line:272] - INFO: epoch 001:    610 / 2637 loss=3.188, loss_v1=0, loss_v2=0, nll_loss=2.161, ntokens=1252, nsentences=160, sample_size=1252, sample_size_v1=0, sample_size_v2=0, ppl=4.47, wps=601.4, ups=0.48, wpb=1252, bsz=160, num_updates=610, lr=7.23034e-06, gnorm=1.407, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=1280
2023-06-27 02:35:01 - progress_bar.py[line:272] - INFO: epoch 001:    620 / 2637 loss=3.108, loss_v1=0, loss_v2=0, nll_loss=2.071, ntokens=1262.1, nsentences=160, sample_size=1262.1, sample_size_v1=0, sample_size_v2=0, ppl=4.2, wps=605.7, ups=0.48, wpb=1262.1, bsz=160, num_updates=620, lr=7.34887e-06, gnorm=1.361, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=1301
2023-06-27 02:35:22 - progress_bar.py[line:272] - INFO: epoch 001:    630 / 2637 loss=3.103, loss_v1=0, loss_v2=0, nll_loss=2.059, ntokens=1240.3, nsentences=160, sample_size=1240.3, sample_size_v1=0, sample_size_v2=0, ppl=4.17, wps=594.8, ups=0.48, wpb=1240.3, bsz=160, num_updates=630, lr=7.4674e-06, gnorm=1.358, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=1322
2023-06-27 02:35:43 - progress_bar.py[line:272] - INFO: epoch 001:    640 / 2637 loss=3.031, loss_v1=0, loss_v2=0, nll_loss=1.982, ntokens=1271.1, nsentences=160, sample_size=1271.1, sample_size_v1=0, sample_size_v2=0, ppl=3.95, wps=609.7, ups=0.48, wpb=1271.1, bsz=160, num_updates=640, lr=7.58593e-06, gnorm=1.437, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=1343
2023-06-27 02:36:03 - progress_bar.py[line:272] - INFO: epoch 001:    650 / 2637 loss=3.037, loss_v1=0, loss_v2=0, nll_loss=1.986, ntokens=1241.9, nsentences=160, sample_size=1241.9, sample_size_v1=0, sample_size_v2=0, ppl=3.96, wps=595.6, ups=0.48, wpb=1241.9, bsz=160, num_updates=650, lr=7.70446e-06, gnorm=1.53, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=1364
2023-06-27 02:36:24 - progress_bar.py[line:272] - INFO: epoch 001:    660 / 2637 loss=3.081, loss_v1=0, loss_v2=0, nll_loss=2.034, ntokens=1249.1, nsentences=160, sample_size=1249.1, sample_size_v1=0, sample_size_v2=0, ppl=4.09, wps=599.6, ups=0.48, wpb=1249.1, bsz=160, num_updates=660, lr=7.82299e-06, gnorm=1.43, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=1385
2023-06-27 02:36:45 - progress_bar.py[line:272] - INFO: epoch 001:    670 / 2637 loss=2.994, loss_v1=0, loss_v2=0, nll_loss=1.936, ntokens=1256.3, nsentences=160, sample_size=1256.3, sample_size_v1=0, sample_size_v2=0, ppl=3.83, wps=602.6, ups=0.48, wpb=1256.3, bsz=160, num_updates=670, lr=7.94153e-06, gnorm=1.267, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=1405
2023-06-27 02:37:06 - progress_bar.py[line:272] - INFO: epoch 001:    680 / 2637 loss=2.976, loss_v1=0, loss_v2=0, nll_loss=1.907, ntokens=1275.1, nsentences=160, sample_size=1275.1, sample_size_v1=0, sample_size_v2=0, ppl=3.75, wps=611.6, ups=0.48, wpb=1275.1, bsz=160, num_updates=680, lr=8.06006e-06, gnorm=1.2, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=1426
2023-06-27 02:37:27 - progress_bar.py[line:272] - INFO: epoch 001:    690 / 2637 loss=2.979, loss_v1=0, loss_v2=0, nll_loss=1.915, ntokens=1278.7, nsentences=160, sample_size=1278.7, sample_size_v1=0, sample_size_v2=0, ppl=3.77, wps=613.4, ups=0.48, wpb=1278.7, bsz=160, num_updates=690, lr=8.17859e-06, gnorm=1.242, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=1447
2023-06-27 02:37:48 - progress_bar.py[line:272] - INFO: epoch 001:    700 / 2637 loss=2.932, loss_v1=0, loss_v2=0, nll_loss=1.857, ntokens=1249.3, nsentences=160, sample_size=1249.3, sample_size_v1=0, sample_size_v2=0, ppl=3.62, wps=598.3, ups=0.48, wpb=1249.3, bsz=160, num_updates=700, lr=8.29712e-06, gnorm=1.373, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=1468
2023-06-27 02:38:09 - progress_bar.py[line:272] - INFO: epoch 001:    710 / 2637 loss=2.93, loss_v1=0, loss_v2=0, nll_loss=1.857, ntokens=1274.7, nsentences=160, sample_size=1274.7, sample_size_v1=0, sample_size_v2=0, ppl=3.62, wps=610.3, ups=0.48, wpb=1274.7, bsz=160, num_updates=710, lr=8.41565e-06, gnorm=1.268, clip=90, loss_scale=256, train_wall=21, gb_free=8.9, wall=1489
2023-06-27 02:38:29 - progress_bar.py[line:272] - INFO: epoch 001:    720 / 2637 loss=2.873, loss_v1=0, loss_v2=0, nll_loss=1.791, ntokens=1242.5, nsentences=160, sample_size=1242.5, sample_size_v1=0, sample_size_v2=0, ppl=3.46, wps=595.5, ups=0.48, wpb=1242.5, bsz=160, num_updates=720, lr=8.53418e-06, gnorm=1.156, clip=90, loss_scale=256, train_wall=21, gb_free=8.9, wall=1510
2023-06-27 02:38:50 - progress_bar.py[line:272] - INFO: epoch 001:    730 / 2637 loss=2.912, loss_v1=0, loss_v2=0, nll_loss=1.832, ntokens=1264.6, nsentences=160, sample_size=1264.6, sample_size_v1=0, sample_size_v2=0, ppl=3.56, wps=606.3, ups=0.48, wpb=1264.6, bsz=160, num_updates=730, lr=8.65271e-06, gnorm=1.208, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=1531
2023-06-27 02:39:11 - progress_bar.py[line:272] - INFO: epoch 001:    740 / 2637 loss=2.866, loss_v1=0, loss_v2=0, nll_loss=1.781, ntokens=1257.1, nsentences=160, sample_size=1257.1, sample_size_v1=0, sample_size_v2=0, ppl=3.44, wps=602.6, ups=0.48, wpb=1257.1, bsz=160, num_updates=740, lr=8.77124e-06, gnorm=1.134, clip=90, loss_scale=256, train_wall=21, gb_free=8.9, wall=1551
2023-06-27 02:39:32 - progress_bar.py[line:272] - INFO: epoch 001:    750 / 2637 loss=2.87, loss_v1=0, loss_v2=0, nll_loss=1.783, ntokens=1266.4, nsentences=160, sample_size=1266.4, sample_size_v1=0, sample_size_v2=0, ppl=3.44, wps=607, ups=0.48, wpb=1266.4, bsz=160, num_updates=750, lr=8.88977e-06, gnorm=1.183, clip=80, loss_scale=256, train_wall=21, gb_free=8.9, wall=1572
2023-06-27 02:39:53 - progress_bar.py[line:272] - INFO: epoch 001:    760 / 2637 loss=2.799, loss_v1=0, loss_v2=0, nll_loss=1.702, ntokens=1269.8, nsentences=160, sample_size=1269.8, sample_size_v1=0, sample_size_v2=0, ppl=3.25, wps=608.5, ups=0.48, wpb=1269.8, bsz=160, num_updates=760, lr=9.0083e-06, gnorm=1.162, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=1593
2023-06-27 02:40:14 - progress_bar.py[line:272] - INFO: epoch 001:    770 / 2637 loss=2.798, loss_v1=0, loss_v2=0, nll_loss=1.696, ntokens=1254.1, nsentences=160, sample_size=1254.1, sample_size_v1=0, sample_size_v2=0, ppl=3.24, wps=600.6, ups=0.48, wpb=1254.1, bsz=160, num_updates=770, lr=9.12683e-06, gnorm=1.041, clip=80, loss_scale=256, train_wall=21, gb_free=8.9, wall=1614
2023-06-27 02:40:35 - progress_bar.py[line:272] - INFO: epoch 001:    780 / 2637 loss=2.767, loss_v1=0, loss_v2=0, nll_loss=1.661, ntokens=1252.3, nsentences=160, sample_size=1252.3, sample_size_v1=0, sample_size_v2=0, ppl=3.16, wps=600.1, ups=0.48, wpb=1252.3, bsz=160, num_updates=780, lr=9.24536e-06, gnorm=1.073, clip=80, loss_scale=256, train_wall=21, gb_free=8.9, wall=1635
2023-06-27 02:40:56 - progress_bar.py[line:272] - INFO: epoch 001:    790 / 2637 loss=2.761, loss_v1=0, loss_v2=0, nll_loss=1.652, ntokens=1265.2, nsentences=160, sample_size=1265.2, sample_size_v1=0, sample_size_v2=0, ppl=3.14, wps=606.5, ups=0.48, wpb=1265.2, bsz=160, num_updates=790, lr=9.36389e-06, gnorm=1.149, clip=80, loss_scale=256, train_wall=21, gb_free=8.9, wall=1656
2023-06-27 02:41:16 - progress_bar.py[line:272] - INFO: epoch 001:    800 / 2637 loss=2.733, loss_v1=0, loss_v2=0, nll_loss=1.622, ntokens=1256.8, nsentences=160, sample_size=1256.8, sample_size_v1=0, sample_size_v2=0, ppl=3.08, wps=603.6, ups=0.48, wpb=1256.8, bsz=160, num_updates=800, lr=9.48242e-06, gnorm=1.109, clip=70, loss_scale=256, train_wall=21, gb_free=8.9, wall=1677
2023-06-27 02:41:37 - progress_bar.py[line:272] - INFO: epoch 001:    810 / 2637 loss=2.709, loss_v1=0, loss_v2=0, nll_loss=1.591, ntokens=1233.3, nsentences=160, sample_size=1233.3, sample_size_v1=0, sample_size_v2=0, ppl=3.01, wps=592.1, ups=0.48, wpb=1233.3, bsz=160, num_updates=810, lr=9.60095e-06, gnorm=1.12, clip=70, loss_scale=256, train_wall=21, gb_free=8.9, wall=1698
2023-06-27 02:41:58 - progress_bar.py[line:272] - INFO: epoch 001:    820 / 2637 loss=2.717, loss_v1=0, loss_v2=0, nll_loss=1.6, ntokens=1273.5, nsentences=160, sample_size=1273.5, sample_size_v1=0, sample_size_v2=0, ppl=3.03, wps=611.1, ups=0.48, wpb=1273.5, bsz=160, num_updates=820, lr=9.71948e-06, gnorm=1.409, clip=90, loss_scale=256, train_wall=21, gb_free=8.9, wall=1718
2023-06-27 02:42:19 - progress_bar.py[line:272] - INFO: epoch 001:    830 / 2637 loss=2.758, loss_v1=0, loss_v2=0, nll_loss=1.642, ntokens=1247.3, nsentences=160, sample_size=1247.3, sample_size_v1=0, sample_size_v2=0, ppl=3.12, wps=598.9, ups=0.48, wpb=1247.3, bsz=160, num_updates=830, lr=9.83801e-06, gnorm=1.159, clip=80, loss_scale=256, train_wall=21, gb_free=8.9, wall=1739
2023-06-27 02:42:40 - progress_bar.py[line:272] - INFO: epoch 001:    840 / 2637 loss=2.691, loss_v1=0, loss_v2=0, nll_loss=1.573, ntokens=1276.6, nsentences=160, sample_size=1276.6, sample_size_v1=0, sample_size_v2=0, ppl=2.97, wps=612, ups=0.48, wpb=1276.6, bsz=160, num_updates=840, lr=9.95654e-06, gnorm=1.058, clip=80, loss_scale=256, train_wall=21, gb_free=8.9, wall=1760
2023-06-27 02:43:01 - progress_bar.py[line:272] - INFO: epoch 001:    850 / 2637 loss=2.713, loss_v1=0, loss_v2=0, nll_loss=1.59, ntokens=1244.8, nsentences=160, sample_size=1244.8, sample_size_v1=0, sample_size_v2=0, ppl=3.01, wps=596.4, ups=0.48, wpb=1244.8, bsz=160, num_updates=850, lr=1.00751e-05, gnorm=1.059, clip=80, loss_scale=256, train_wall=21, gb_free=8.9, wall=1781
2023-06-27 02:43:22 - progress_bar.py[line:272] - INFO: epoch 001:    860 / 2637 loss=2.681, loss_v1=0, loss_v2=0, nll_loss=1.555, ntokens=1241.4, nsentences=160, sample_size=1241.4, sample_size_v1=0, sample_size_v2=0, ppl=2.94, wps=594.8, ups=0.48, wpb=1241.4, bsz=160, num_updates=860, lr=1.01936e-05, gnorm=1.054, clip=70, loss_scale=256, train_wall=21, gb_free=8.9, wall=1802
2023-06-27 02:43:42 - progress_bar.py[line:272] - INFO: epoch 001:    870 / 2637 loss=2.668, loss_v1=0, loss_v2=0, nll_loss=1.537, ntokens=1230.6, nsentences=160, sample_size=1230.6, sample_size_v1=0, sample_size_v2=0, ppl=2.9, wps=589.2, ups=0.48, wpb=1230.6, bsz=160, num_updates=870, lr=1.03121e-05, gnorm=1.114, clip=80, loss_scale=256, train_wall=21, gb_free=8.9, wall=1823
2023-06-27 02:44:03 - progress_bar.py[line:272] - INFO: epoch 001:    880 / 2637 loss=2.659, loss_v1=0, loss_v2=0, nll_loss=1.526, ntokens=1266.6, nsentences=160, sample_size=1266.6, sample_size_v1=0, sample_size_v2=0, ppl=2.88, wps=606.5, ups=0.48, wpb=1266.6, bsz=160, num_updates=880, lr=1.04307e-05, gnorm=1.13, clip=80, loss_scale=256, train_wall=21, gb_free=8.9, wall=1844
2023-06-27 02:44:24 - progress_bar.py[line:272] - INFO: epoch 001:    890 / 2637 loss=2.656, loss_v1=0, loss_v2=0, nll_loss=1.521, ntokens=1248.5, nsentences=160, sample_size=1248.5, sample_size_v1=0, sample_size_v2=0, ppl=2.87, wps=598.3, ups=0.48, wpb=1248.5, bsz=160, num_updates=890, lr=1.05492e-05, gnorm=1.234, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=1864
2023-06-27 02:44:45 - progress_bar.py[line:272] - INFO: epoch 001:    900 / 2637 loss=2.638, loss_v1=0, loss_v2=0, nll_loss=1.502, ntokens=1264.9, nsentences=160, sample_size=1264.9, sample_size_v1=0, sample_size_v2=0, ppl=2.83, wps=606.1, ups=0.48, wpb=1264.9, bsz=160, num_updates=900, lr=1.06677e-05, gnorm=1.08, clip=80, loss_scale=256, train_wall=21, gb_free=8.9, wall=1885
2023-06-27 02:45:06 - progress_bar.py[line:272] - INFO: epoch 001:    910 / 2637 loss=2.621, loss_v1=0, loss_v2=0, nll_loss=1.482, ntokens=1241.5, nsentences=160, sample_size=1241.5, sample_size_v1=0, sample_size_v2=0, ppl=2.79, wps=594.9, ups=0.48, wpb=1241.5, bsz=160, num_updates=910, lr=1.07863e-05, gnorm=1.072, clip=60, loss_scale=256, train_wall=21, gb_free=8.9, wall=1906
2023-06-27 02:45:27 - progress_bar.py[line:272] - INFO: epoch 001:    920 / 2637 loss=2.661, loss_v1=0, loss_v2=0, nll_loss=1.523, ntokens=1253, nsentences=160, sample_size=1253, sample_size_v1=0, sample_size_v2=0, ppl=2.87, wps=600.2, ups=0.48, wpb=1253, bsz=160, num_updates=920, lr=1.09048e-05, gnorm=1.224, clip=90, loss_scale=256, train_wall=21, gb_free=8.9, wall=1927
2023-06-27 02:45:48 - progress_bar.py[line:272] - INFO: epoch 001:    930 / 2637 loss=2.613, loss_v1=0, loss_v2=0, nll_loss=1.472, ntokens=1260.3, nsentences=160, sample_size=1260.3, sample_size_v1=0, sample_size_v2=0, ppl=2.77, wps=604.1, ups=0.48, wpb=1260.3, bsz=160, num_updates=930, lr=1.10233e-05, gnorm=1.184, clip=90, loss_scale=256, train_wall=21, gb_free=8.9, wall=1948
2023-06-27 02:46:09 - progress_bar.py[line:272] - INFO: epoch 001:    940 / 2637 loss=2.649, loss_v1=0, loss_v2=0, nll_loss=1.507, ntokens=1257.4, nsentences=160, sample_size=1257.4, sample_size_v1=0, sample_size_v2=0, ppl=2.84, wps=602.2, ups=0.48, wpb=1257.4, bsz=160, num_updates=940, lr=1.11418e-05, gnorm=1.075, clip=80, loss_scale=256, train_wall=21, gb_free=8.9, wall=1969
2023-06-27 02:46:29 - progress_bar.py[line:272] - INFO: epoch 001:    950 / 2637 loss=2.618, loss_v1=0, loss_v2=0, nll_loss=1.472, ntokens=1241.7, nsentences=160, sample_size=1241.7, sample_size_v1=0, sample_size_v2=0, ppl=2.77, wps=595.3, ups=0.48, wpb=1241.7, bsz=160, num_updates=950, lr=1.12604e-05, gnorm=1.187, clip=80, loss_scale=256, train_wall=21, gb_free=8.9, wall=1990
2023-06-27 02:46:50 - progress_bar.py[line:272] - INFO: epoch 001:    960 / 2637 loss=2.63, loss_v1=0, loss_v2=0, nll_loss=1.488, ntokens=1252.2, nsentences=160, sample_size=1252.2, sample_size_v1=0, sample_size_v2=0, ppl=2.81, wps=600.3, ups=0.48, wpb=1252.2, bsz=160, num_updates=960, lr=1.13789e-05, gnorm=1.062, clip=70, loss_scale=256, train_wall=21, gb_free=8.9, wall=2011
2023-06-27 02:47:11 - progress_bar.py[line:272] - INFO: epoch 001:    970 / 2637 loss=2.604, loss_v1=0, loss_v2=0, nll_loss=1.457, ntokens=1232.7, nsentences=160, sample_size=1232.7, sample_size_v1=0, sample_size_v2=0, ppl=2.75, wps=592.2, ups=0.48, wpb=1232.7, bsz=160, num_updates=970, lr=1.14974e-05, gnorm=1.101, clip=70, loss_scale=256, train_wall=21, gb_free=8.9, wall=2031
2023-06-27 02:47:32 - progress_bar.py[line:272] - INFO: epoch 001:    980 / 2637 loss=2.603, loss_v1=0, loss_v2=0, nll_loss=1.455, ntokens=1247.4, nsentences=160, sample_size=1247.4, sample_size_v1=0, sample_size_v2=0, ppl=2.74, wps=599.3, ups=0.48, wpb=1247.4, bsz=160, num_updates=980, lr=1.1616e-05, gnorm=1.119, clip=80, loss_scale=256, train_wall=21, gb_free=8.9, wall=2052
2023-06-27 02:47:53 - progress_bar.py[line:272] - INFO: epoch 001:    990 / 2637 loss=2.597, loss_v1=0, loss_v2=0, nll_loss=1.448, ntokens=1244.6, nsentences=160, sample_size=1244.6, sample_size_v1=0, sample_size_v2=0, ppl=2.73, wps=597.2, ups=0.48, wpb=1244.6, bsz=160, num_updates=990, lr=1.17345e-05, gnorm=1.141, clip=80, loss_scale=256, train_wall=21, gb_free=8.9, wall=2073
2023-06-27 02:48:14 - progress_bar.py[line:272] - INFO: epoch 001:   1000 / 2637 loss=2.597, loss_v1=0, loss_v2=0, nll_loss=1.447, ntokens=1247.6, nsentences=160, sample_size=1247.6, sample_size_v1=0, sample_size_v2=0, ppl=2.73, wps=599.3, ups=0.48, wpb=1247.6, bsz=160, num_updates=1000, lr=1.1853e-05, gnorm=1.142, clip=90, loss_scale=256, train_wall=21, gb_free=8.9, wall=2094
2023-06-27 02:48:34 - progress_bar.py[line:272] - INFO: epoch 001:   1010 / 2637 loss=2.596, loss_v1=0, loss_v2=0, nll_loss=1.445, ntokens=1241.1, nsentences=160, sample_size=1241.1, sample_size_v1=0, sample_size_v2=0, ppl=2.72, wps=596, ups=0.48, wpb=1241.1, bsz=160, num_updates=1010, lr=1.19716e-05, gnorm=1.139, clip=70, loss_scale=256, train_wall=21, gb_free=8.9, wall=2115
2023-06-27 02:48:55 - progress_bar.py[line:272] - INFO: epoch 001:   1020 / 2637 loss=2.617, loss_v1=0, loss_v2=0, nll_loss=1.469, ntokens=1241.8, nsentences=160, sample_size=1241.8, sample_size_v1=0, sample_size_v2=0, ppl=2.77, wps=596, ups=0.48, wpb=1241.8, bsz=160, num_updates=1020, lr=1.20901e-05, gnorm=1.097, clip=90, loss_scale=256, train_wall=21, gb_free=8.9, wall=2136
2023-06-27 02:49:16 - progress_bar.py[line:272] - INFO: epoch 001:   1030 / 2637 loss=2.589, loss_v1=0, loss_v2=0, nll_loss=1.436, ntokens=1254.3, nsentences=160, sample_size=1254.3, sample_size_v1=0, sample_size_v2=0, ppl=2.7, wps=602.2, ups=0.48, wpb=1254.3, bsz=160, num_updates=1030, lr=1.22086e-05, gnorm=1.197, clip=90, loss_scale=512, train_wall=21, gb_free=8.9, wall=2156
2023-06-27 02:49:37 - progress_bar.py[line:272] - INFO: epoch 001:   1040 / 2637 loss=2.583, loss_v1=0, loss_v2=0, nll_loss=1.43, ntokens=1243.1, nsentences=160, sample_size=1243.1, sample_size_v1=0, sample_size_v2=0, ppl=2.69, wps=595.6, ups=0.48, wpb=1243.1, bsz=160, num_updates=1040, lr=1.23271e-05, gnorm=1.081, clip=60, loss_scale=512, train_wall=21, gb_free=8.9, wall=2177
2023-06-27 02:49:58 - progress_bar.py[line:272] - INFO: epoch 001:   1050 / 2637 loss=2.587, loss_v1=0, loss_v2=0, nll_loss=1.435, ntokens=1267.6, nsentences=160, sample_size=1267.6, sample_size_v1=0, sample_size_v2=0, ppl=2.7, wps=607.4, ups=0.48, wpb=1267.6, bsz=160, num_updates=1050, lr=1.24457e-05, gnorm=1.142, clip=60, loss_scale=512, train_wall=21, gb_free=8.9, wall=2198
2023-06-27 02:50:19 - progress_bar.py[line:272] - INFO: epoch 001:   1060 / 2637 loss=2.572, loss_v1=0, loss_v2=0, nll_loss=1.415, ntokens=1246.2, nsentences=160, sample_size=1246.2, sample_size_v1=0, sample_size_v2=0, ppl=2.67, wps=597.8, ups=0.48, wpb=1246.2, bsz=160, num_updates=1060, lr=1.25642e-05, gnorm=1.092, clip=80, loss_scale=512, train_wall=21, gb_free=8.9, wall=2219
2023-06-27 02:50:40 - progress_bar.py[line:272] - INFO: epoch 001:   1070 / 2637 loss=2.561, loss_v1=0, loss_v2=0, nll_loss=1.4, ntokens=1232.4, nsentences=160, sample_size=1232.4, sample_size_v1=0, sample_size_v2=0, ppl=2.64, wps=590.2, ups=0.48, wpb=1232.4, bsz=160, num_updates=1070, lr=1.26827e-05, gnorm=1.036, clip=50, loss_scale=512, train_wall=21, gb_free=8.9, wall=2240
2023-06-27 02:51:00 - progress_bar.py[line:272] - INFO: epoch 001:   1080 / 2637 loss=2.546, loss_v1=0, loss_v2=0, nll_loss=1.385, ntokens=1230.2, nsentences=160, sample_size=1230.2, sample_size_v1=0, sample_size_v2=0, ppl=2.61, wps=589.9, ups=0.48, wpb=1230.2, bsz=160, num_updates=1080, lr=1.28013e-05, gnorm=1.067, clip=80, loss_scale=512, train_wall=21, gb_free=8.9, wall=2261
2023-06-27 02:51:21 - progress_bar.py[line:272] - INFO: epoch 001:   1090 / 2637 loss=2.56, loss_v1=0, loss_v2=0, nll_loss=1.398, ntokens=1272.6, nsentences=160, sample_size=1272.6, sample_size_v1=0, sample_size_v2=0, ppl=2.64, wps=610.7, ups=0.48, wpb=1272.6, bsz=160, num_updates=1090, lr=1.29198e-05, gnorm=1.097, clip=70, loss_scale=512, train_wall=21, gb_free=8.9, wall=2282
2023-06-27 02:51:42 - progress_bar.py[line:272] - INFO: epoch 001:   1100 / 2637 loss=2.549, loss_v1=0, loss_v2=0, nll_loss=1.388, ntokens=1236.7, nsentences=160, sample_size=1236.7, sample_size_v1=0, sample_size_v2=0, ppl=2.62, wps=592.9, ups=0.48, wpb=1236.7, bsz=160, num_updates=1100, lr=1.30383e-05, gnorm=1.106, clip=70, loss_scale=512, train_wall=21, gb_free=8.9, wall=2302
2023-06-27 02:52:03 - progress_bar.py[line:272] - INFO: epoch 001:   1110 / 2637 loss=2.545, loss_v1=0, loss_v2=0, nll_loss=1.381, ntokens=1230.6, nsentences=160, sample_size=1230.6, sample_size_v1=0, sample_size_v2=0, ppl=2.61, wps=591.1, ups=0.48, wpb=1230.6, bsz=160, num_updates=1110, lr=1.31569e-05, gnorm=1.021, clip=50, loss_scale=512, train_wall=21, gb_free=8.9, wall=2323
2023-06-27 02:52:24 - progress_bar.py[line:272] - INFO: epoch 001:   1120 / 2637 loss=2.56, loss_v1=0, loss_v2=0, nll_loss=1.398, ntokens=1239.4, nsentences=160, sample_size=1239.4, sample_size_v1=0, sample_size_v2=0, ppl=2.63, wps=595, ups=0.48, wpb=1239.4, bsz=160, num_updates=1120, lr=1.32754e-05, gnorm=1.142, clip=90, loss_scale=512, train_wall=21, gb_free=8.9, wall=2344
2023-06-27 02:52:45 - progress_bar.py[line:272] - INFO: epoch 001:   1130 / 2637 loss=2.553, loss_v1=0, loss_v2=0, nll_loss=1.393, ntokens=1240.7, nsentences=160, sample_size=1240.7, sample_size_v1=0, sample_size_v2=0, ppl=2.63, wps=596.1, ups=0.48, wpb=1240.7, bsz=160, num_updates=1130, lr=1.33939e-05, gnorm=1.004, clip=40, loss_scale=512, train_wall=21, gb_free=8.9, wall=2365
2023-06-27 02:53:05 - progress_bar.py[line:272] - INFO: epoch 001:   1140 / 2637 loss=2.547, loss_v1=0, loss_v2=0, nll_loss=1.382, ntokens=1263.5, nsentences=160, sample_size=1263.5, sample_size_v1=0, sample_size_v2=0, ppl=2.61, wps=606.9, ups=0.48, wpb=1263.5, bsz=160, num_updates=1140, lr=1.35124e-05, gnorm=1.112, clip=90, loss_scale=512, train_wall=21, gb_free=8.7, wall=2386
2023-06-27 02:53:26 - progress_bar.py[line:272] - INFO: epoch 001:   1150 / 2637 loss=2.558, loss_v1=0, loss_v2=0, nll_loss=1.395, ntokens=1258.6, nsentences=160, sample_size=1258.6, sample_size_v1=0, sample_size_v2=0, ppl=2.63, wps=605.2, ups=0.48, wpb=1258.6, bsz=160, num_updates=1150, lr=1.3631e-05, gnorm=1.132, clip=80, loss_scale=512, train_wall=21, gb_free=8.9, wall=2406
2023-06-27 02:53:47 - progress_bar.py[line:272] - INFO: epoch 001:   1160 / 2637 loss=2.555, loss_v1=0, loss_v2=0, nll_loss=1.39, ntokens=1243.6, nsentences=160, sample_size=1243.6, sample_size_v1=0, sample_size_v2=0, ppl=2.62, wps=597.2, ups=0.48, wpb=1243.6, bsz=160, num_updates=1160, lr=1.37495e-05, gnorm=1.118, clip=80, loss_scale=512, train_wall=21, gb_free=8.9, wall=2427
2023-06-27 02:54:08 - progress_bar.py[line:272] - INFO: epoch 001:   1170 / 2637 loss=2.537, loss_v1=0, loss_v2=0, nll_loss=1.37, ntokens=1244, nsentences=160, sample_size=1244, sample_size_v1=0, sample_size_v2=0, ppl=2.59, wps=597.1, ups=0.48, wpb=1244, bsz=160, num_updates=1170, lr=1.3868e-05, gnorm=1.202, clip=90, loss_scale=512, train_wall=21, gb_free=8.9, wall=2448
2023-06-27 02:54:29 - progress_bar.py[line:272] - INFO: epoch 001:   1180 / 2637 loss=2.551, loss_v1=0, loss_v2=0, nll_loss=1.387, ntokens=1252.2, nsentences=160, sample_size=1252.2, sample_size_v1=0, sample_size_v2=0, ppl=2.61, wps=600, ups=0.48, wpb=1252.2, bsz=160, num_updates=1180, lr=1.39866e-05, gnorm=1.133, clip=90, loss_scale=512, train_wall=21, gb_free=8.9, wall=2469
2023-06-27 02:54:50 - progress_bar.py[line:272] - INFO: epoch 001:   1190 / 2637 loss=2.528, loss_v1=0, loss_v2=0, nll_loss=1.36, ntokens=1252.3, nsentences=160, sample_size=1252.3, sample_size_v1=0, sample_size_v2=0, ppl=2.57, wps=600.7, ups=0.48, wpb=1252.3, bsz=160, num_updates=1190, lr=1.41051e-05, gnorm=1.026, clip=60, loss_scale=512, train_wall=21, gb_free=8.9, wall=2490
2023-06-27 02:55:10 - progress_bar.py[line:272] - INFO: epoch 001:   1200 / 2637 loss=2.535, loss_v1=0, loss_v2=0, nll_loss=1.371, ntokens=1257.8, nsentences=160, sample_size=1257.8, sample_size_v1=0, sample_size_v2=0, ppl=2.59, wps=604.4, ups=0.48, wpb=1257.8, bsz=160, num_updates=1200, lr=1.42236e-05, gnorm=1.097, clip=60, loss_scale=512, train_wall=21, gb_free=8.9, wall=2511
2023-06-27 02:55:31 - progress_bar.py[line:272] - INFO: epoch 001:   1210 / 2637 loss=2.533, loss_v1=0, loss_v2=0, nll_loss=1.359, ntokens=1245.8, nsentences=160, sample_size=1245.8, sample_size_v1=0, sample_size_v2=0, ppl=2.56, wps=598.6, ups=0.48, wpb=1245.8, bsz=160, num_updates=1210, lr=1.43422e-05, gnorm=1.064, clip=30, loss_scale=512, train_wall=21, gb_free=8.9, wall=2531
2023-06-27 02:55:52 - progress_bar.py[line:272] - INFO: epoch 001:   1220 / 2637 loss=2.511, loss_v1=0, loss_v2=0, nll_loss=1.342, ntokens=1265.3, nsentences=160, sample_size=1265.3, sample_size_v1=0, sample_size_v2=0, ppl=2.54, wps=607.7, ups=0.48, wpb=1265.3, bsz=160, num_updates=1220, lr=1.44607e-05, gnorm=1.081, clip=70, loss_scale=512, train_wall=21, gb_free=8.9, wall=2552
2023-06-27 02:56:13 - progress_bar.py[line:272] - INFO: epoch 001:   1230 / 2637 loss=2.537, loss_v1=0, loss_v2=0, nll_loss=1.365, ntokens=1227.6, nsentences=160, sample_size=1227.6, sample_size_v1=0, sample_size_v2=0, ppl=2.58, wps=589.4, ups=0.48, wpb=1227.6, bsz=160, num_updates=1230, lr=1.45792e-05, gnorm=1.081, clip=80, loss_scale=512, train_wall=21, gb_free=8.9, wall=2573
2023-06-27 02:56:34 - progress_bar.py[line:272] - INFO: epoch 001:   1240 / 2637 loss=2.531, loss_v1=0, loss_v2=0, nll_loss=1.364, ntokens=1238.1, nsentences=160, sample_size=1238.1, sample_size_v1=0, sample_size_v2=0, ppl=2.57, wps=594.2, ups=0.48, wpb=1238.1, bsz=160, num_updates=1240, lr=1.46977e-05, gnorm=1.089, clip=60, loss_scale=512, train_wall=21, gb_free=8.9, wall=2594
2023-06-27 02:56:55 - progress_bar.py[line:272] - INFO: epoch 001:   1250 / 2637 loss=2.492, loss_v1=0, loss_v2=0, nll_loss=1.322, ntokens=1238.7, nsentences=160, sample_size=1238.7, sample_size_v1=0, sample_size_v2=0, ppl=2.5, wps=594.5, ups=0.48, wpb=1238.7, bsz=160, num_updates=1250, lr=1.48163e-05, gnorm=1.049, clip=80, loss_scale=512, train_wall=21, gb_free=8.9, wall=2615
2023-06-27 02:57:16 - progress_bar.py[line:272] - INFO: epoch 001:   1260 / 2637 loss=2.523, loss_v1=0, loss_v2=0, nll_loss=1.349, ntokens=1233.6, nsentences=160, sample_size=1233.6, sample_size_v1=0, sample_size_v2=0, ppl=2.55, wps=586.2, ups=0.48, wpb=1233.6, bsz=160, num_updates=1260, lr=1.49348e-05, gnorm=1.088, clip=70, loss_scale=512, train_wall=21, gb_free=8.9, wall=2636
2023-06-27 02:57:36 - progress_bar.py[line:272] - INFO: epoch 001:   1270 / 2637 loss=2.526, loss_v1=0, loss_v2=0, nll_loss=1.356, ntokens=1264.5, nsentences=160, sample_size=1264.5, sample_size_v1=0, sample_size_v2=0, ppl=2.56, wps=607.7, ups=0.48, wpb=1264.5, bsz=160, num_updates=1270, lr=1.50533e-05, gnorm=1.128, clip=80, loss_scale=512, train_wall=21, gb_free=8.9, wall=2657
2023-06-27 02:57:57 - progress_bar.py[line:272] - INFO: epoch 001:   1280 / 2637 loss=2.529, loss_v1=0, loss_v2=0, nll_loss=1.358, ntokens=1239.3, nsentences=160, sample_size=1239.3, sample_size_v1=0, sample_size_v2=0, ppl=2.56, wps=595.7, ups=0.48, wpb=1239.3, bsz=160, num_updates=1280, lr=1.51719e-05, gnorm=1.105, clip=80, loss_scale=512, train_wall=21, gb_free=8.9, wall=2677
2023-06-27 02:58:18 - progress_bar.py[line:272] - INFO: epoch 001:   1290 / 2637 loss=2.526, loss_v1=0, loss_v2=0, nll_loss=1.353, ntokens=1251, nsentences=160, sample_size=1251, sample_size_v1=0, sample_size_v2=0, ppl=2.55, wps=600.1, ups=0.48, wpb=1251, bsz=160, num_updates=1290, lr=1.52904e-05, gnorm=1.121, clip=80, loss_scale=512, train_wall=21, gb_free=8.9, wall=2698
2023-06-27 02:58:39 - progress_bar.py[line:272] - INFO: epoch 001:   1300 / 2637 loss=2.496, loss_v1=0, loss_v2=0, nll_loss=1.325, ntokens=1243.8, nsentences=160, sample_size=1243.8, sample_size_v1=0, sample_size_v2=0, ppl=2.51, wps=595.7, ups=0.48, wpb=1243.8, bsz=160, num_updates=1300, lr=1.54089e-05, gnorm=1.01, clip=50, loss_scale=512, train_wall=21, gb_free=8.9, wall=2719
2023-06-27 02:59:00 - progress_bar.py[line:272] - INFO: epoch 001:   1310 / 2637 loss=2.503, loss_v1=0, loss_v2=0, nll_loss=1.33, ntokens=1245.5, nsentences=160, sample_size=1245.5, sample_size_v1=0, sample_size_v2=0, ppl=2.51, wps=597.3, ups=0.48, wpb=1245.5, bsz=160, num_updates=1310, lr=1.55275e-05, gnorm=1.014, clip=60, loss_scale=512, train_wall=21, gb_free=8.9, wall=2740
2023-06-27 02:59:21 - progress_bar.py[line:272] - INFO: epoch 001:   1320 / 2637 loss=2.52, loss_v1=0, loss_v2=0, nll_loss=1.346, ntokens=1238.6, nsentences=160, sample_size=1238.6, sample_size_v1=0, sample_size_v2=0, ppl=2.54, wps=592.8, ups=0.48, wpb=1238.6, bsz=160, num_updates=1320, lr=1.5646e-05, gnorm=1.095, clip=80, loss_scale=512, train_wall=21, gb_free=8.9, wall=2761
2023-06-27 02:59:42 - progress_bar.py[line:272] - INFO: epoch 001:   1330 / 2637 loss=2.503, loss_v1=0, loss_v2=0, nll_loss=1.33, ntokens=1228.2, nsentences=160, sample_size=1228.2, sample_size_v1=0, sample_size_v2=0, ppl=2.51, wps=589.7, ups=0.48, wpb=1228.2, bsz=160, num_updates=1330, lr=1.57645e-05, gnorm=1.053, clip=60, loss_scale=512, train_wall=21, gb_free=8.9, wall=2782
2023-06-27 03:00:02 - progress_bar.py[line:272] - INFO: epoch 001:   1340 / 2637 loss=2.512, loss_v1=0, loss_v2=0, nll_loss=1.338, ntokens=1227.7, nsentences=159.9, sample_size=1227.7, sample_size_v1=0, sample_size_v2=0, ppl=2.53, wps=589.3, ups=0.48, wpb=1227.7, bsz=159.9, num_updates=1340, lr=1.58831e-05, gnorm=1.09, clip=80, loss_scale=512, train_wall=21, gb_free=8.9, wall=2803
2023-06-27 03:00:23 - progress_bar.py[line:272] - INFO: epoch 001:   1350 / 2637 loss=2.498, loss_v1=0, loss_v2=0, nll_loss=1.323, ntokens=1230.7, nsentences=160, sample_size=1230.7, sample_size_v1=0, sample_size_v2=0, ppl=2.5, wps=590.3, ups=0.48, wpb=1230.7, bsz=160, num_updates=1350, lr=1.60016e-05, gnorm=1.125, clip=90, loss_scale=512, train_wall=21, gb_free=8.9, wall=2824
2023-06-27 03:00:44 - progress_bar.py[line:272] - INFO: epoch 001:   1360 / 2637 loss=2.529, loss_v1=0, loss_v2=0, nll_loss=1.356, ntokens=1243.9, nsentences=160, sample_size=1243.9, sample_size_v1=0, sample_size_v2=0, ppl=2.56, wps=591, ups=0.48, wpb=1243.9, bsz=160, num_updates=1360, lr=1.61201e-05, gnorm=1.249, clip=100, loss_scale=512, train_wall=21, gb_free=8.9, wall=2845
2023-06-27 03:01:05 - progress_bar.py[line:272] - INFO: epoch 001:   1370 / 2637 loss=2.52, loss_v1=0, loss_v2=0, nll_loss=1.347, ntokens=1229.3, nsentences=160, sample_size=1229.3, sample_size_v1=0, sample_size_v2=0, ppl=2.54, wps=590.3, ups=0.48, wpb=1229.3, bsz=160, num_updates=1370, lr=1.62386e-05, gnorm=1.24, clip=100, loss_scale=512, train_wall=21, gb_free=8.9, wall=2865
2023-06-27 03:01:26 - progress_bar.py[line:272] - INFO: epoch 001:   1380 / 2637 loss=2.533, loss_v1=0, loss_v2=0, nll_loss=1.363, ntokens=1235.9, nsentences=160, sample_size=1235.9, sample_size_v1=0, sample_size_v2=0, ppl=2.57, wps=592.6, ups=0.48, wpb=1235.9, bsz=160, num_updates=1380, lr=1.63572e-05, gnorm=1.154, clip=80, loss_scale=512, train_wall=21, gb_free=8.9, wall=2886
2023-06-27 03:01:47 - progress_bar.py[line:272] - INFO: epoch 001:   1390 / 2637 loss=2.52, loss_v1=0, loss_v2=0, nll_loss=1.346, ntokens=1275.3, nsentences=160, sample_size=1275.3, sample_size_v1=0, sample_size_v2=0, ppl=2.54, wps=611.3, ups=0.48, wpb=1275.3, bsz=160, num_updates=1390, lr=1.64757e-05, gnorm=1.122, clip=90, loss_scale=512, train_wall=21, gb_free=8.9, wall=2907
2023-06-27 03:02:08 - progress_bar.py[line:272] - INFO: epoch 001:   1400 / 2637 loss=2.51, loss_v1=0, loss_v2=0, nll_loss=1.338, ntokens=1273.2, nsentences=160, sample_size=1273.2, sample_size_v1=0, sample_size_v2=0, ppl=2.53, wps=610.2, ups=0.48, wpb=1273.2, bsz=160, num_updates=1400, lr=1.65942e-05, gnorm=1.119, clip=80, loss_scale=512, train_wall=21, gb_free=8.9, wall=2928
2023-06-27 03:02:29 - progress_bar.py[line:272] - INFO: epoch 001:   1410 / 2637 loss=2.497, loss_v1=0, loss_v2=0, nll_loss=1.321, ntokens=1275.4, nsentences=160, sample_size=1275.4, sample_size_v1=0, sample_size_v2=0, ppl=2.5, wps=611.6, ups=0.48, wpb=1275.4, bsz=160, num_updates=1410, lr=1.67128e-05, gnorm=1.156, clip=90, loss_scale=512, train_wall=21, gb_free=8.9, wall=2949
2023-06-27 03:02:49 - progress_bar.py[line:272] - INFO: epoch 001:   1420 / 2637 loss=2.492, loss_v1=0, loss_v2=0, nll_loss=1.314, ntokens=1272.4, nsentences=160, sample_size=1272.4, sample_size_v1=0, sample_size_v2=0, ppl=2.49, wps=610.4, ups=0.48, wpb=1272.4, bsz=160, num_updates=1420, lr=1.68313e-05, gnorm=1.023, clip=60, loss_scale=512, train_wall=21, gb_free=8.9, wall=2970
2023-06-27 03:03:10 - progress_bar.py[line:272] - INFO: epoch 001:   1430 / 2637 loss=2.496, loss_v1=0, loss_v2=0, nll_loss=1.32, ntokens=1272.3, nsentences=160, sample_size=1272.3, sample_size_v1=0, sample_size_v2=0, ppl=2.5, wps=609.4, ups=0.48, wpb=1272.3, bsz=160, num_updates=1430, lr=1.69498e-05, gnorm=1.052, clip=40, loss_scale=512, train_wall=21, gb_free=8.9, wall=2991
2023-06-27 03:03:31 - progress_bar.py[line:272] - INFO: epoch 001:   1440 / 2637 loss=2.505, loss_v1=0, loss_v2=0, nll_loss=1.33, ntokens=1272, nsentences=160, sample_size=1272, sample_size_v1=0, sample_size_v2=0, ppl=2.51, wps=607.8, ups=0.48, wpb=1272, bsz=160, num_updates=1440, lr=1.70684e-05, gnorm=1.068, clip=60, loss_scale=512, train_wall=21, gb_free=8.9, wall=3011
2023-06-27 03:03:52 - progress_bar.py[line:272] - INFO: epoch 001:   1450 / 2637 loss=2.496, loss_v1=0, loss_v2=0, nll_loss=1.318, ntokens=1289.9, nsentences=160, sample_size=1289.9, sample_size_v1=0, sample_size_v2=0, ppl=2.49, wps=617.8, ups=0.48, wpb=1289.9, bsz=160, num_updates=1450, lr=1.71869e-05, gnorm=1.112, clip=80, loss_scale=512, train_wall=21, gb_free=8.9, wall=3032
2023-06-27 03:04:13 - progress_bar.py[line:272] - INFO: epoch 001:   1460 / 2637 loss=2.505, loss_v1=0, loss_v2=0, nll_loss=1.327, ntokens=1287.4, nsentences=160, sample_size=1287.4, sample_size_v1=0, sample_size_v2=0, ppl=2.51, wps=616.5, ups=0.48, wpb=1287.4, bsz=160, num_updates=1460, lr=1.73054e-05, gnorm=1.12, clip=50, loss_scale=512, train_wall=21, gb_free=8.9, wall=3053
2023-06-27 03:04:34 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 256.0
2023-06-27 03:04:36 - progress_bar.py[line:272] - INFO: epoch 001:   1471 / 2637 loss=2.5, loss_v1=0, loss_v2=0, nll_loss=1.326, ntokens=1253.3, nsentences=160, sample_size=1253.3, sample_size_v1=0, sample_size_v2=0, ppl=2.51, wps=547.2, ups=0.44, wpb=1253.3, bsz=160, num_updates=1470, lr=1.74239e-05, gnorm=1.114, clip=80, loss_scale=256, train_wall=23, gb_free=8.9, wall=3076
2023-06-27 03:04:57 - progress_bar.py[line:272] - INFO: epoch 001:   1481 / 2637 loss=2.496, loss_v1=0, loss_v2=0, nll_loss=1.318, ntokens=1272.2, nsentences=160, sample_size=1272.2, sample_size_v1=0, sample_size_v2=0, ppl=2.49, wps=611.4, ups=0.48, wpb=1272.2, bsz=160, num_updates=1480, lr=1.75425e-05, gnorm=1.162, clip=90, loss_scale=256, train_wall=21, gb_free=8.9, wall=3097
2023-06-27 03:05:18 - progress_bar.py[line:272] - INFO: epoch 001:   1491 / 2637 loss=2.51, loss_v1=0, loss_v2=0, nll_loss=1.338, ntokens=1287.7, nsentences=160, sample_size=1287.7, sample_size_v1=0, sample_size_v2=0, ppl=2.53, wps=618.6, ups=0.48, wpb=1287.7, bsz=160, num_updates=1490, lr=1.7661e-05, gnorm=1.22, clip=90, loss_scale=256, train_wall=21, gb_free=8.9, wall=3118
2023-06-27 03:05:38 - progress_bar.py[line:272] - INFO: epoch 001:   1501 / 2637 loss=2.478, loss_v1=0, loss_v2=0, nll_loss=1.294, ntokens=1282.7, nsentences=160, sample_size=1282.7, sample_size_v1=0, sample_size_v2=0, ppl=2.45, wps=616.4, ups=0.48, wpb=1282.7, bsz=160, num_updates=1500, lr=1.77795e-05, gnorm=1.074, clip=60, loss_scale=256, train_wall=21, gb_free=8.9, wall=3139
2023-06-27 03:05:59 - progress_bar.py[line:272] - INFO: epoch 001:   1511 / 2637 loss=2.508, loss_v1=0, loss_v2=0, nll_loss=1.331, ntokens=1283.7, nsentences=160, sample_size=1283.7, sample_size_v1=0, sample_size_v2=0, ppl=2.52, wps=615.1, ups=0.48, wpb=1283.7, bsz=160, num_updates=1510, lr=1.78981e-05, gnorm=1.159, clip=70, loss_scale=256, train_wall=21, gb_free=8.9, wall=3159
2023-06-27 03:06:20 - progress_bar.py[line:272] - INFO: epoch 001:   1521 / 2637 loss=2.496, loss_v1=0, loss_v2=0, nll_loss=1.321, ntokens=1262.4, nsentences=160, sample_size=1262.4, sample_size_v1=0, sample_size_v2=0, ppl=2.5, wps=604.4, ups=0.48, wpb=1262.4, bsz=160, num_updates=1520, lr=1.80166e-05, gnorm=1.135, clip=90, loss_scale=256, train_wall=21, gb_free=8.9, wall=3180
2023-06-27 03:06:41 - progress_bar.py[line:272] - INFO: epoch 001:   1531 / 2637 loss=2.523, loss_v1=0, loss_v2=0, nll_loss=1.346, ntokens=1254.7, nsentences=160, sample_size=1254.7, sample_size_v1=0, sample_size_v2=0, ppl=2.54, wps=600.7, ups=0.48, wpb=1254.7, bsz=160, num_updates=1530, lr=1.81351e-05, gnorm=1.269, clip=90, loss_scale=256, train_wall=21, gb_free=8.9, wall=3201
2023-06-27 03:07:02 - progress_bar.py[line:272] - INFO: epoch 001:   1541 / 2637 loss=2.526, loss_v1=0, loss_v2=0, nll_loss=1.351, ntokens=1266.8, nsentences=160, sample_size=1266.8, sample_size_v1=0, sample_size_v2=0, ppl=2.55, wps=607.3, ups=0.48, wpb=1266.8, bsz=160, num_updates=1540, lr=1.82537e-05, gnorm=1.19, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=3222
2023-06-27 03:07:23 - progress_bar.py[line:272] - INFO: epoch 001:   1551 / 2637 loss=2.503, loss_v1=0, loss_v2=0, nll_loss=1.329, ntokens=1277.2, nsentences=160, sample_size=1277.2, sample_size_v1=0, sample_size_v2=0, ppl=2.51, wps=612.8, ups=0.48, wpb=1277.2, bsz=160, num_updates=1550, lr=1.83722e-05, gnorm=1.101, clip=70, loss_scale=256, train_wall=21, gb_free=8.9, wall=3243
2023-06-27 03:07:44 - progress_bar.py[line:272] - INFO: epoch 001:   1561 / 2637 loss=2.479, loss_v1=0, loss_v2=0, nll_loss=1.299, ntokens=1276.8, nsentences=160, sample_size=1276.8, sample_size_v1=0, sample_size_v2=0, ppl=2.46, wps=611.7, ups=0.48, wpb=1276.8, bsz=160, num_updates=1560, lr=1.84907e-05, gnorm=1.118, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=3264
2023-06-27 03:08:04 - progress_bar.py[line:272] - INFO: epoch 001:   1571 / 2637 loss=2.484, loss_v1=0, loss_v2=0, nll_loss=1.306, ntokens=1256, nsentences=160, sample_size=1256, sample_size_v1=0, sample_size_v2=0, ppl=2.47, wps=602.1, ups=0.48, wpb=1256, bsz=160, num_updates=1570, lr=1.86092e-05, gnorm=1.123, clip=80, loss_scale=256, train_wall=21, gb_free=8.9, wall=3285
2023-06-27 03:08:25 - progress_bar.py[line:272] - INFO: epoch 001:   1581 / 2637 loss=2.483, loss_v1=0, loss_v2=0, nll_loss=1.3, ntokens=1269.9, nsentences=160, sample_size=1269.9, sample_size_v1=0, sample_size_v2=0, ppl=2.46, wps=608, ups=0.48, wpb=1269.9, bsz=160, num_updates=1580, lr=1.87278e-05, gnorm=1.182, clip=90, loss_scale=256, train_wall=21, gb_free=8.9, wall=3306
2023-06-27 03:08:46 - progress_bar.py[line:272] - INFO: epoch 001:   1591 / 2637 loss=2.484, loss_v1=0, loss_v2=0, nll_loss=1.305, ntokens=1268.6, nsentences=160, sample_size=1268.6, sample_size_v1=0, sample_size_v2=0, ppl=2.47, wps=607, ups=0.48, wpb=1268.6, bsz=160, num_updates=1590, lr=1.88463e-05, gnorm=1.094, clip=90, loss_scale=256, train_wall=21, gb_free=8.9, wall=3327
2023-06-27 03:09:07 - progress_bar.py[line:272] - INFO: epoch 001:   1601 / 2637 loss=2.494, loss_v1=0, loss_v2=0, nll_loss=1.316, ntokens=1271.2, nsentences=160, sample_size=1271.2, sample_size_v1=0, sample_size_v2=0, ppl=2.49, wps=608.7, ups=0.48, wpb=1271.2, bsz=160, num_updates=1600, lr=1.89648e-05, gnorm=1.113, clip=70, loss_scale=256, train_wall=21, gb_free=8.9, wall=3347
2023-06-27 03:09:28 - progress_bar.py[line:272] - INFO: epoch 001:   1611 / 2637 loss=2.51, loss_v1=0, loss_v2=0, nll_loss=1.331, ntokens=1268, nsentences=160, sample_size=1268, sample_size_v1=0, sample_size_v2=0, ppl=2.52, wps=607.4, ups=0.48, wpb=1268, bsz=160, num_updates=1610, lr=1.90834e-05, gnorm=1.045, clip=80, loss_scale=256, train_wall=21, gb_free=8.9, wall=3368
2023-06-27 03:09:49 - progress_bar.py[line:272] - INFO: epoch 001:   1621 / 2637 loss=2.512, loss_v1=0, loss_v2=0, nll_loss=1.338, ntokens=1257.8, nsentences=160, sample_size=1257.8, sample_size_v1=0, sample_size_v2=0, ppl=2.53, wps=603.6, ups=0.48, wpb=1257.8, bsz=160, num_updates=1620, lr=1.92019e-05, gnorm=1.085, clip=90, loss_scale=256, train_wall=21, gb_free=8.9, wall=3389
2023-06-27 03:10:10 - progress_bar.py[line:272] - INFO: epoch 001:   1631 / 2637 loss=2.484, loss_v1=0, loss_v2=0, nll_loss=1.306, ntokens=1267.2, nsentences=160, sample_size=1267.2, sample_size_v1=0, sample_size_v2=0, ppl=2.47, wps=607.7, ups=0.48, wpb=1267.2, bsz=160, num_updates=1630, lr=1.93204e-05, gnorm=1.109, clip=80, loss_scale=256, train_wall=21, gb_free=8.9, wall=3410
2023-06-27 03:10:31 - progress_bar.py[line:272] - INFO: epoch 001:   1641 / 2637 loss=2.492, loss_v1=0, loss_v2=0, nll_loss=1.313, ntokens=1265.7, nsentences=160, sample_size=1265.7, sample_size_v1=0, sample_size_v2=0, ppl=2.49, wps=608.3, ups=0.48, wpb=1265.7, bsz=160, num_updates=1640, lr=1.9439e-05, gnorm=1.22, clip=70, loss_scale=256, train_wall=21, gb_free=8.9, wall=3431
2023-06-27 03:10:51 - progress_bar.py[line:272] - INFO: epoch 001:   1651 / 2637 loss=2.47, loss_v1=0, loss_v2=0, nll_loss=1.288, ntokens=1257.2, nsentences=160, sample_size=1257.2, sample_size_v1=0, sample_size_v2=0, ppl=2.44, wps=604, ups=0.48, wpb=1257.2, bsz=160, num_updates=1650, lr=1.95575e-05, gnorm=1.308, clip=90, loss_scale=256, train_wall=21, gb_free=8.9, wall=3452
2023-06-27 03:11:12 - progress_bar.py[line:272] - INFO: epoch 001:   1661 / 2637 loss=2.5, loss_v1=0, loss_v2=0, nll_loss=1.321, ntokens=1275.7, nsentences=160, sample_size=1275.7, sample_size_v1=0, sample_size_v2=0, ppl=2.5, wps=612.5, ups=0.48, wpb=1275.7, bsz=160, num_updates=1660, lr=1.9676e-05, gnorm=1.233, clip=90, loss_scale=256, train_wall=21, gb_free=8.9, wall=3472
2023-06-27 03:11:33 - progress_bar.py[line:272] - INFO: epoch 001:   1671 / 2637 loss=2.48, loss_v1=0, loss_v2=0, nll_loss=1.301, ntokens=1257.1, nsentences=160, sample_size=1257.1, sample_size_v1=0, sample_size_v2=0, ppl=2.46, wps=603.8, ups=0.48, wpb=1257.1, bsz=160, num_updates=1670, lr=1.97945e-05, gnorm=1.274, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=3493
2023-06-27 03:11:54 - progress_bar.py[line:272] - INFO: epoch 001:   1681 / 2637 loss=2.485, loss_v1=0, loss_v2=0, nll_loss=1.306, ntokens=1264.5, nsentences=160, sample_size=1264.5, sample_size_v1=0, sample_size_v2=0, ppl=2.47, wps=607.3, ups=0.48, wpb=1264.5, bsz=160, num_updates=1680, lr=1.99131e-05, gnorm=1.284, clip=90, loss_scale=256, train_wall=21, gb_free=8.9, wall=3514
2023-06-27 03:12:15 - progress_bar.py[line:272] - INFO: epoch 001:   1691 / 2637 loss=2.465, loss_v1=0, loss_v2=0, nll_loss=1.283, ntokens=1285.4, nsentences=160, sample_size=1285.4, sample_size_v1=0, sample_size_v2=0, ppl=2.43, wps=617.1, ups=0.48, wpb=1285.4, bsz=160, num_updates=1690, lr=2.00316e-05, gnorm=1.498, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=3535
2023-06-27 03:12:35 - progress_bar.py[line:272] - INFO: epoch 001:   1701 / 2637 loss=2.481, loss_v1=0, loss_v2=0, nll_loss=1.299, ntokens=1278, nsentences=160, sample_size=1278, sample_size_v1=0, sample_size_v2=0, ppl=2.46, wps=613.4, ups=0.48, wpb=1278, bsz=160, num_updates=1700, lr=2.01501e-05, gnorm=1.25, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=3556
2023-06-27 03:12:56 - progress_bar.py[line:272] - INFO: epoch 001:   1711 / 2637 loss=2.48, loss_v1=0, loss_v2=0, nll_loss=1.299, ntokens=1273.1, nsentences=160, sample_size=1273.1, sample_size_v1=0, sample_size_v2=0, ppl=2.46, wps=611.6, ups=0.48, wpb=1273.1, bsz=160, num_updates=1710, lr=2.02687e-05, gnorm=1.299, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=3577
2023-06-27 03:13:17 - progress_bar.py[line:272] - INFO: epoch 001:   1721 / 2637 loss=2.485, loss_v1=0, loss_v2=0, nll_loss=1.308, ntokens=1279.1, nsentences=160, sample_size=1279.1, sample_size_v1=0, sample_size_v2=0, ppl=2.48, wps=613.8, ups=0.48, wpb=1279.1, bsz=160, num_updates=1720, lr=2.03872e-05, gnorm=1.305, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=3597
2023-06-27 03:13:38 - progress_bar.py[line:272] - INFO: epoch 001:   1731 / 2637 loss=2.48, loss_v1=0, loss_v2=0, nll_loss=1.295, ntokens=1263.2, nsentences=160, sample_size=1263.2, sample_size_v1=0, sample_size_v2=0, ppl=2.45, wps=607.3, ups=0.48, wpb=1263.2, bsz=160, num_updates=1730, lr=2.05057e-05, gnorm=1.36, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=3618
2023-06-27 03:13:59 - progress_bar.py[line:272] - INFO: epoch 001:   1741 / 2637 loss=2.465, loss_v1=0, loss_v2=0, nll_loss=1.285, ntokens=1279.9, nsentences=160, sample_size=1279.9, sample_size_v1=0, sample_size_v2=0, ppl=2.44, wps=614.5, ups=0.48, wpb=1279.9, bsz=160, num_updates=1740, lr=2.06243e-05, gnorm=1.408, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=3639
2023-06-27 03:14:11 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 128.0
2023-06-27 03:14:22 - progress_bar.py[line:272] - INFO: epoch 001:   1752 / 2637 loss=2.479, loss_v1=0, loss_v2=0, nll_loss=1.297, ntokens=1258.3, nsentences=160, sample_size=1258.3, sample_size_v1=0, sample_size_v2=0, ppl=2.46, wps=549.8, ups=0.44, wpb=1258.3, bsz=160, num_updates=1750, lr=2.07428e-05, gnorm=1.37, clip=100, loss_scale=128, train_wall=23, gb_free=8.9, wall=3662
2023-06-27 03:14:43 - progress_bar.py[line:272] - INFO: epoch 001:   1762 / 2637 loss=2.457, loss_v1=0, loss_v2=0, nll_loss=1.273, ntokens=1287.3, nsentences=160, sample_size=1287.3, sample_size_v1=0, sample_size_v2=0, ppl=2.42, wps=617.8, ups=0.48, wpb=1287.3, bsz=160, num_updates=1760, lr=2.08613e-05, gnorm=1.354, clip=100, loss_scale=128, train_wall=21, gb_free=8.9, wall=3683
2023-06-27 03:15:03 - progress_bar.py[line:272] - INFO: epoch 001:   1772 / 2637 loss=2.509, loss_v1=0, loss_v2=0, nll_loss=1.332, ntokens=1263.4, nsentences=160, sample_size=1263.4, sample_size_v1=0, sample_size_v2=0, ppl=2.52, wps=606.9, ups=0.48, wpb=1263.4, bsz=160, num_updates=1770, lr=2.09798e-05, gnorm=1.545, clip=100, loss_scale=128, train_wall=21, gb_free=8.9, wall=3704
2023-06-27 03:15:24 - progress_bar.py[line:272] - INFO: epoch 001:   1782 / 2637 loss=2.47, loss_v1=0, loss_v2=0, nll_loss=1.287, ntokens=1285.7, nsentences=160, sample_size=1285.7, sample_size_v1=0, sample_size_v2=0, ppl=2.44, wps=616.9, ups=0.48, wpb=1285.7, bsz=160, num_updates=1780, lr=2.10984e-05, gnorm=1.471, clip=100, loss_scale=128, train_wall=21, gb_free=8.9, wall=3724
2023-06-27 03:15:45 - progress_bar.py[line:272] - INFO: epoch 001:   1792 / 2637 loss=2.469, loss_v1=0, loss_v2=0, nll_loss=1.285, ntokens=1286.5, nsentences=160, sample_size=1286.5, sample_size_v1=0, sample_size_v2=0, ppl=2.44, wps=617.6, ups=0.48, wpb=1286.5, bsz=160, num_updates=1790, lr=2.12169e-05, gnorm=1.406, clip=90, loss_scale=128, train_wall=21, gb_free=8.9, wall=3745
2023-06-27 03:16:06 - progress_bar.py[line:272] - INFO: epoch 001:   1802 / 2637 loss=2.488, loss_v1=0, loss_v2=0, nll_loss=1.307, ntokens=1266, nsentences=160, sample_size=1266, sample_size_v1=0, sample_size_v2=0, ppl=2.47, wps=607.8, ups=0.48, wpb=1266, bsz=160, num_updates=1800, lr=2.13354e-05, gnorm=1.424, clip=100, loss_scale=128, train_wall=21, gb_free=8.9, wall=3766
2023-06-27 03:16:27 - progress_bar.py[line:272] - INFO: epoch 001:   1812 / 2637 loss=2.445, loss_v1=0, loss_v2=0, nll_loss=1.26, ntokens=1280.7, nsentences=160, sample_size=1280.7, sample_size_v1=0, sample_size_v2=0, ppl=2.39, wps=615.3, ups=0.48, wpb=1280.7, bsz=160, num_updates=1810, lr=2.1454e-05, gnorm=1.347, clip=100, loss_scale=128, train_wall=21, gb_free=8.9, wall=3787
2023-06-27 03:16:47 - progress_bar.py[line:272] - INFO: epoch 001:   1822 / 2637 loss=2.479, loss_v1=0, loss_v2=0, nll_loss=1.3, ntokens=1260.2, nsentences=160, sample_size=1260.2, sample_size_v1=0, sample_size_v2=0, ppl=2.46, wps=605.4, ups=0.48, wpb=1260.2, bsz=160, num_updates=1820, lr=2.15725e-05, gnorm=1.598, clip=100, loss_scale=128, train_wall=21, gb_free=8.9, wall=3808
2023-06-27 03:17:08 - progress_bar.py[line:272] - INFO: epoch 001:   1832 / 2637 loss=2.439, loss_v1=0, loss_v2=0, nll_loss=1.25, ntokens=1279, nsentences=160, sample_size=1279, sample_size_v1=0, sample_size_v2=0, ppl=2.38, wps=614.8, ups=0.48, wpb=1279, bsz=160, num_updates=1830, lr=2.1691e-05, gnorm=1.553, clip=100, loss_scale=128, train_wall=21, gb_free=8.9, wall=3829
2023-06-27 03:17:29 - progress_bar.py[line:272] - INFO: epoch 001:   1842 / 2637 loss=2.44, loss_v1=0, loss_v2=0, nll_loss=1.255, ntokens=1303, nsentences=160, sample_size=1303, sample_size_v1=0, sample_size_v2=0, ppl=2.39, wps=625.4, ups=0.48, wpb=1303, bsz=160, num_updates=1840, lr=2.18096e-05, gnorm=1.326, clip=100, loss_scale=128, train_wall=21, gb_free=8.9, wall=3849
2023-06-27 03:17:50 - progress_bar.py[line:272] - INFO: epoch 001:   1852 / 2637 loss=2.454, loss_v1=0, loss_v2=0, nll_loss=1.268, ntokens=1263.6, nsentences=160, sample_size=1263.6, sample_size_v1=0, sample_size_v2=0, ppl=2.41, wps=607.1, ups=0.48, wpb=1263.6, bsz=160, num_updates=1850, lr=2.19281e-05, gnorm=1.33, clip=100, loss_scale=128, train_wall=21, gb_free=8.9, wall=3870
2023-06-27 03:18:11 - progress_bar.py[line:272] - INFO: epoch 001:   1862 / 2637 loss=2.462, loss_v1=0, loss_v2=0, nll_loss=1.28, ntokens=1280.1, nsentences=160, sample_size=1280.1, sample_size_v1=0, sample_size_v2=0, ppl=2.43, wps=614.3, ups=0.48, wpb=1280.1, bsz=160, num_updates=1860, lr=2.20466e-05, gnorm=1.4, clip=100, loss_scale=128, train_wall=21, gb_free=8.9, wall=3891
2023-06-27 03:18:32 - progress_bar.py[line:272] - INFO: epoch 001:   1872 / 2637 loss=2.459, loss_v1=0, loss_v2=0, nll_loss=1.275, ntokens=1257.7, nsentences=160, sample_size=1257.7, sample_size_v1=0, sample_size_v2=0, ppl=2.42, wps=603.8, ups=0.48, wpb=1257.7, bsz=160, num_updates=1870, lr=2.21652e-05, gnorm=1.568, clip=100, loss_scale=128, train_wall=21, gb_free=8.9, wall=3912
2023-06-27 03:18:52 - progress_bar.py[line:272] - INFO: epoch 001:   1882 / 2637 loss=2.416, loss_v1=0, loss_v2=0, nll_loss=1.225, ntokens=1290.3, nsentences=160, sample_size=1290.3, sample_size_v1=0, sample_size_v2=0, ppl=2.34, wps=618.7, ups=0.48, wpb=1290.3, bsz=160, num_updates=1880, lr=2.22837e-05, gnorm=1.265, clip=100, loss_scale=128, train_wall=21, gb_free=8.9, wall=3933
2023-06-27 03:19:13 - progress_bar.py[line:272] - INFO: epoch 001:   1892 / 2637 loss=2.455, loss_v1=0, loss_v2=0, nll_loss=1.272, ntokens=1273.7, nsentences=160, sample_size=1273.7, sample_size_v1=0, sample_size_v2=0, ppl=2.41, wps=611.1, ups=0.48, wpb=1273.7, bsz=160, num_updates=1890, lr=2.24022e-05, gnorm=1.522, clip=100, loss_scale=128, train_wall=21, gb_free=8.9, wall=3954
2023-06-27 03:19:34 - progress_bar.py[line:272] - INFO: epoch 001:   1902 / 2637 loss=2.459, loss_v1=0, loss_v2=0, nll_loss=1.274, ntokens=1288.1, nsentences=160, sample_size=1288.1, sample_size_v1=0, sample_size_v2=0, ppl=2.42, wps=618.1, ups=0.48, wpb=1288.1, bsz=160, num_updates=1900, lr=2.25207e-05, gnorm=1.496, clip=100, loss_scale=128, train_wall=21, gb_free=8.9, wall=3974
2023-06-27 03:19:55 - progress_bar.py[line:272] - INFO: epoch 001:   1912 / 2637 loss=2.445, loss_v1=0, loss_v2=0, nll_loss=1.26, ntokens=1258.7, nsentences=160, sample_size=1258.7, sample_size_v1=0, sample_size_v2=0, ppl=2.4, wps=604.4, ups=0.48, wpb=1258.7, bsz=160, num_updates=1910, lr=2.26393e-05, gnorm=1.57, clip=100, loss_scale=128, train_wall=21, gb_free=8.9, wall=3995
2023-06-27 03:20:16 - progress_bar.py[line:272] - INFO: epoch 001:   1922 / 2637 loss=2.463, loss_v1=0, loss_v2=0, nll_loss=1.281, ntokens=1276.9, nsentences=160, sample_size=1276.9, sample_size_v1=0, sample_size_v2=0, ppl=2.43, wps=610.6, ups=0.48, wpb=1276.9, bsz=160, num_updates=1920, lr=2.27578e-05, gnorm=1.386, clip=100, loss_scale=128, train_wall=21, gb_free=8.9, wall=4016
2023-06-27 03:20:37 - progress_bar.py[line:272] - INFO: epoch 001:   1932 / 2637 loss=2.475, loss_v1=0, loss_v2=0, nll_loss=1.29, ntokens=1252.8, nsentences=160, sample_size=1252.8, sample_size_v1=0, sample_size_v2=0, ppl=2.45, wps=599.9, ups=0.48, wpb=1252.8, bsz=160, num_updates=1930, lr=2.28763e-05, gnorm=1.814, clip=100, loss_scale=128, train_wall=21, gb_free=8.9, wall=4037
2023-06-27 03:20:58 - progress_bar.py[line:272] - INFO: epoch 001:   1942 / 2637 loss=2.44, loss_v1=0, loss_v2=0, nll_loss=1.254, ntokens=1295.9, nsentences=160, sample_size=1295.9, sample_size_v1=0, sample_size_v2=0, ppl=2.38, wps=620.6, ups=0.48, wpb=1295.9, bsz=160, num_updates=1940, lr=2.29949e-05, gnorm=1.538, clip=100, loss_scale=128, train_wall=21, gb_free=8.9, wall=4058
2023-06-27 03:21:19 - progress_bar.py[line:272] - INFO: epoch 001:   1952 / 2637 loss=2.47, loss_v1=0, loss_v2=0, nll_loss=1.285, ntokens=1288, nsentences=160, sample_size=1288, sample_size_v1=0, sample_size_v2=0, ppl=2.44, wps=618.2, ups=0.48, wpb=1288, bsz=160, num_updates=1950, lr=2.31134e-05, gnorm=1.534, clip=100, loss_scale=128, train_wall=21, gb_free=8.9, wall=4079
2023-06-27 03:21:39 - progress_bar.py[line:272] - INFO: epoch 001:   1962 / 2637 loss=2.457, loss_v1=0, loss_v2=0, nll_loss=1.273, ntokens=1266.2, nsentences=160, sample_size=1266.2, sample_size_v1=0, sample_size_v2=0, ppl=2.42, wps=608.5, ups=0.48, wpb=1266.2, bsz=160, num_updates=1960, lr=2.32319e-05, gnorm=1.799, clip=100, loss_scale=128, train_wall=21, gb_free=8.9, wall=4100
2023-06-27 03:22:00 - progress_bar.py[line:272] - INFO: epoch 001:   1972 / 2637 loss=2.479, loss_v1=0, loss_v2=0, nll_loss=1.294, ntokens=1268.3, nsentences=160, sample_size=1268.3, sample_size_v1=0, sample_size_v2=0, ppl=2.45, wps=608.9, ups=0.48, wpb=1268.3, bsz=160, num_updates=1970, lr=2.33505e-05, gnorm=1.79, clip=100, loss_scale=128, train_wall=21, gb_free=8.9, wall=4120
2023-06-27 03:22:21 - progress_bar.py[line:272] - INFO: epoch 001:   1982 / 2637 loss=2.504, loss_v1=0, loss_v2=0, nll_loss=1.324, ntokens=1278.2, nsentences=160, sample_size=1278.2, sample_size_v1=0, sample_size_v2=0, ppl=2.5, wps=614, ups=0.48, wpb=1278.2, bsz=160, num_updates=1980, lr=2.3469e-05, gnorm=1.881, clip=100, loss_scale=128, train_wall=21, gb_free=8.9, wall=4141
2023-06-27 03:22:42 - progress_bar.py[line:272] - INFO: epoch 001:   1992 / 2637 loss=2.442, loss_v1=0, loss_v2=0, nll_loss=1.256, ntokens=1293.9, nsentences=160, sample_size=1293.9, sample_size_v1=0, sample_size_v2=0, ppl=2.39, wps=621.3, ups=0.48, wpb=1293.9, bsz=160, num_updates=1990, lr=2.35875e-05, gnorm=1.483, clip=100, loss_scale=128, train_wall=21, gb_free=8.9, wall=4162
2023-06-27 03:23:03 - progress_bar.py[line:272] - INFO: epoch 001:   2002 / 2637 loss=2.462, loss_v1=0, loss_v2=0, nll_loss=1.278, ntokens=1270.4, nsentences=160, sample_size=1270.4, sample_size_v1=0, sample_size_v2=0, ppl=2.42, wps=609.7, ups=0.48, wpb=1270.4, bsz=160, num_updates=2000, lr=2.3706e-05, gnorm=1.717, clip=100, loss_scale=128, train_wall=21, gb_free=8.9, wall=4183
2023-06-27 03:23:23 - progress_bar.py[line:272] - INFO: epoch 001:   2012 / 2637 loss=2.461, loss_v1=0, loss_v2=0, nll_loss=1.275, ntokens=1274.3, nsentences=160, sample_size=1274.3, sample_size_v1=0, sample_size_v2=0, ppl=2.42, wps=612.1, ups=0.48, wpb=1274.3, bsz=160, num_updates=2010, lr=2.38246e-05, gnorm=1.611, clip=100, loss_scale=128, train_wall=21, gb_free=8.9, wall=4204
2023-06-27 03:23:44 - progress_bar.py[line:272] - INFO: epoch 001:   2022 / 2637 loss=2.447, loss_v1=0, loss_v2=0, nll_loss=1.261, ntokens=1304, nsentences=160, sample_size=1304, sample_size_v1=0, sample_size_v2=0, ppl=2.4, wps=626.1, ups=0.48, wpb=1304, bsz=160, num_updates=2020, lr=2.39431e-05, gnorm=1.44, clip=100, loss_scale=128, train_wall=21, gb_free=8.9, wall=4225
2023-06-27 03:24:05 - progress_bar.py[line:272] - INFO: epoch 001:   2032 / 2637 loss=2.451, loss_v1=0, loss_v2=0, nll_loss=1.266, ntokens=1251.8, nsentences=160, sample_size=1251.8, sample_size_v1=0, sample_size_v2=0, ppl=2.4, wps=600.8, ups=0.48, wpb=1251.8, bsz=160, num_updates=2030, lr=2.40616e-05, gnorm=1.854, clip=100, loss_scale=128, train_wall=21, gb_free=8.9, wall=4245
2023-06-27 03:24:26 - progress_bar.py[line:272] - INFO: epoch 001:   2042 / 2637 loss=2.416, loss_v1=0, loss_v2=0, nll_loss=1.227, ntokens=1284, nsentences=160, sample_size=1284, sample_size_v1=0, sample_size_v2=0, ppl=2.34, wps=616.8, ups=0.48, wpb=1284, bsz=160, num_updates=2040, lr=2.41802e-05, gnorm=1.452, clip=100, loss_scale=128, train_wall=21, gb_free=8.9, wall=4266
2023-06-27 03:24:47 - progress_bar.py[line:272] - INFO: epoch 001:   2052 / 2637 loss=2.44, loss_v1=0, loss_v2=0, nll_loss=1.249, ntokens=1280.4, nsentences=160, sample_size=1280.4, sample_size_v1=0, sample_size_v2=0, ppl=2.38, wps=614.9, ups=0.48, wpb=1280.4, bsz=160, num_updates=2050, lr=2.42987e-05, gnorm=1.618, clip=100, loss_scale=128, train_wall=21, gb_free=8.9, wall=4287
2023-06-27 03:25:08 - progress_bar.py[line:272] - INFO: epoch 001:   2062 / 2637 loss=2.434, loss_v1=0, loss_v2=0, nll_loss=1.252, ntokens=1250.5, nsentences=160, sample_size=1250.5, sample_size_v1=0, sample_size_v2=0, ppl=2.38, wps=600.5, ups=0.48, wpb=1250.5, bsz=160, num_updates=2060, lr=2.44172e-05, gnorm=1.797, clip=100, loss_scale=128, train_wall=21, gb_free=8.9, wall=4308
2023-06-27 03:25:28 - progress_bar.py[line:272] - INFO: epoch 001:   2072 / 2637 loss=2.455, loss_v1=0, loss_v2=0, nll_loss=1.263, ntokens=1259.1, nsentences=160, sample_size=1259.1, sample_size_v1=0, sample_size_v2=0, ppl=2.4, wps=604.5, ups=0.48, wpb=1259.1, bsz=160, num_updates=2070, lr=2.45358e-05, gnorm=1.844, clip=100, loss_scale=128, train_wall=21, gb_free=8.9, wall=4329
2023-06-27 03:25:49 - progress_bar.py[line:272] - INFO: epoch 001:   2082 / 2637 loss=2.454, loss_v1=0, loss_v2=0, nll_loss=1.268, ntokens=1257.6, nsentences=160, sample_size=1257.6, sample_size_v1=0, sample_size_v2=0, ppl=2.41, wps=604.1, ups=0.48, wpb=1257.6, bsz=160, num_updates=2080, lr=2.46543e-05, gnorm=1.381, clip=100, loss_scale=128, train_wall=21, gb_free=8.9, wall=4350
2023-06-27 03:26:10 - progress_bar.py[line:272] - INFO: epoch 001:   2092 / 2637 loss=2.447, loss_v1=0, loss_v2=0, nll_loss=1.263, ntokens=1267.4, nsentences=160, sample_size=1267.4, sample_size_v1=0, sample_size_v2=0, ppl=2.4, wps=608.8, ups=0.48, wpb=1267.4, bsz=160, num_updates=2090, lr=2.47728e-05, gnorm=1.848, clip=100, loss_scale=128, train_wall=21, gb_free=8.9, wall=4370
2023-06-27 03:26:31 - progress_bar.py[line:272] - INFO: epoch 001:   2102 / 2637 loss=2.44, loss_v1=0, loss_v2=0, nll_loss=1.252, ntokens=1248.7, nsentences=160, sample_size=1248.7, sample_size_v1=0, sample_size_v2=0, ppl=2.38, wps=600.1, ups=0.48, wpb=1248.7, bsz=160, num_updates=2100, lr=2.48913e-05, gnorm=1.692, clip=100, loss_scale=128, train_wall=21, gb_free=8.9, wall=4391
2023-06-27 03:26:52 - progress_bar.py[line:272] - INFO: epoch 001:   2112 / 2637 loss=2.456, loss_v1=0, loss_v2=0, nll_loss=1.27, ntokens=1264.9, nsentences=160, sample_size=1264.9, sample_size_v1=0, sample_size_v2=0, ppl=2.41, wps=607.4, ups=0.48, wpb=1264.9, bsz=160, num_updates=2110, lr=2.50099e-05, gnorm=1.504, clip=100, loss_scale=128, train_wall=21, gb_free=8.9, wall=4412
2023-06-27 03:27:13 - progress_bar.py[line:272] - INFO: epoch 001:   2122 / 2637 loss=2.455, loss_v1=0, loss_v2=0, nll_loss=1.273, ntokens=1260.7, nsentences=160, sample_size=1260.7, sample_size_v1=0, sample_size_v2=0, ppl=2.42, wps=605.7, ups=0.48, wpb=1260.7, bsz=160, num_updates=2120, lr=2.51284e-05, gnorm=1.768, clip=100, loss_scale=128, train_wall=21, gb_free=8.9, wall=4433
2023-06-27 03:27:33 - progress_bar.py[line:272] - INFO: epoch 001:   2132 / 2637 loss=2.464, loss_v1=0, loss_v2=0, nll_loss=1.279, ntokens=1257.2, nsentences=160, sample_size=1257.2, sample_size_v1=0, sample_size_v2=0, ppl=2.43, wps=603.4, ups=0.48, wpb=1257.2, bsz=160, num_updates=2130, lr=2.52469e-05, gnorm=1.756, clip=100, loss_scale=128, train_wall=21, gb_free=8.9, wall=4454
2023-06-27 03:27:54 - progress_bar.py[line:272] - INFO: epoch 001:   2142 / 2637 loss=2.435, loss_v1=0, loss_v2=0, nll_loss=1.249, ntokens=1261.5, nsentences=160, sample_size=1261.5, sample_size_v1=0, sample_size_v2=0, ppl=2.38, wps=605.5, ups=0.48, wpb=1261.5, bsz=160, num_updates=2140, lr=2.53655e-05, gnorm=1.745, clip=100, loss_scale=128, train_wall=21, gb_free=8.9, wall=4475
2023-06-27 03:28:15 - progress_bar.py[line:272] - INFO: epoch 001:   2152 / 2637 loss=2.433, loss_v1=0, loss_v2=0, nll_loss=1.244, ntokens=1263.1, nsentences=160, sample_size=1263.1, sample_size_v1=0, sample_size_v2=0, ppl=2.37, wps=604.9, ups=0.48, wpb=1263.1, bsz=160, num_updates=2150, lr=2.5484e-05, gnorm=1.671, clip=100, loss_scale=128, train_wall=21, gb_free=8.9, wall=4495
2023-06-27 03:28:36 - progress_bar.py[line:272] - INFO: epoch 001:   2162 / 2637 loss=2.442, loss_v1=0, loss_v2=0, nll_loss=1.255, ntokens=1260.5, nsentences=160, sample_size=1260.5, sample_size_v1=0, sample_size_v2=0, ppl=2.39, wps=604, ups=0.48, wpb=1260.5, bsz=160, num_updates=2160, lr=2.56025e-05, gnorm=1.73, clip=100, loss_scale=128, train_wall=21, gb_free=8.9, wall=4516
2023-06-27 03:28:57 - progress_bar.py[line:272] - INFO: epoch 001:   2172 / 2637 loss=2.434, loss_v1=0, loss_v2=0, nll_loss=1.244, ntokens=1269, nsentences=160, sample_size=1269, sample_size_v1=0, sample_size_v2=0, ppl=2.37, wps=608.1, ups=0.48, wpb=1269, bsz=160, num_updates=2170, lr=2.57211e-05, gnorm=1.721, clip=100, loss_scale=128, train_wall=21, gb_free=8.9, wall=4537
2023-06-27 03:29:18 - progress_bar.py[line:272] - INFO: epoch 001:   2182 / 2637 loss=2.436, loss_v1=0, loss_v2=0, nll_loss=1.249, ntokens=1258.6, nsentences=160, sample_size=1258.6, sample_size_v1=0, sample_size_v2=0, ppl=2.38, wps=603.4, ups=0.48, wpb=1258.6, bsz=160, num_updates=2180, lr=2.58396e-05, gnorm=1.989, clip=100, loss_scale=128, train_wall=21, gb_free=8.9, wall=4558
2023-06-27 03:29:39 - progress_bar.py[line:272] - INFO: epoch 001:   2192 / 2637 loss=2.439, loss_v1=0, loss_v2=0, nll_loss=1.252, ntokens=1272.6, nsentences=160, sample_size=1272.6, sample_size_v1=0, sample_size_v2=0, ppl=2.38, wps=610.1, ups=0.48, wpb=1272.6, bsz=160, num_updates=2190, lr=2.59581e-05, gnorm=2.14, clip=100, loss_scale=128, train_wall=21, gb_free=8.9, wall=4579
2023-06-27 03:29:59 - progress_bar.py[line:272] - INFO: epoch 001:   2202 / 2637 loss=2.427, loss_v1=0, loss_v2=0, nll_loss=1.234, ntokens=1268.9, nsentences=160, sample_size=1268.9, sample_size_v1=0, sample_size_v2=0, ppl=2.35, wps=608.5, ups=0.48, wpb=1268.9, bsz=160, num_updates=2200, lr=2.60766e-05, gnorm=1.955, clip=100, loss_scale=128, train_wall=21, gb_free=8.9, wall=4600
2023-06-27 03:30:20 - progress_bar.py[line:272] - INFO: epoch 001:   2212 / 2637 loss=2.408, loss_v1=0, loss_v2=0, nll_loss=1.218, ntokens=1266.9, nsentences=160, sample_size=1266.9, sample_size_v1=0, sample_size_v2=0, ppl=2.33, wps=606.7, ups=0.48, wpb=1266.9, bsz=160, num_updates=2210, lr=2.61952e-05, gnorm=2.089, clip=100, loss_scale=128, train_wall=21, gb_free=8.9, wall=4621
2023-06-27 03:30:41 - progress_bar.py[line:272] - INFO: epoch 001:   2222 / 2637 loss=2.442, loss_v1=0, loss_v2=0, nll_loss=1.252, ntokens=1260.1, nsentences=160, sample_size=1260.1, sample_size_v1=0, sample_size_v2=0, ppl=2.38, wps=603.8, ups=0.48, wpb=1260.1, bsz=160, num_updates=2220, lr=2.63137e-05, gnorm=2.742, clip=100, loss_scale=128, train_wall=21, gb_free=8.9, wall=4641
2023-06-27 03:31:02 - progress_bar.py[line:272] - INFO: epoch 001:   2232 / 2637 loss=2.445, loss_v1=0, loss_v2=0, nll_loss=1.259, ntokens=1274.3, nsentences=160, sample_size=1274.3, sample_size_v1=0, sample_size_v2=0, ppl=2.39, wps=611.2, ups=0.48, wpb=1274.3, bsz=160, num_updates=2230, lr=2.64322e-05, gnorm=2.203, clip=100, loss_scale=128, train_wall=21, gb_free=8.9, wall=4662
2023-06-27 03:31:23 - progress_bar.py[line:272] - INFO: epoch 001:   2242 / 2637 loss=2.42, loss_v1=0, loss_v2=0, nll_loss=1.229, ntokens=1265.5, nsentences=160, sample_size=1265.5, sample_size_v1=0, sample_size_v2=0, ppl=2.34, wps=607.1, ups=0.48, wpb=1265.5, bsz=160, num_updates=2240, lr=2.65508e-05, gnorm=2.224, clip=100, loss_scale=128, train_wall=21, gb_free=8.9, wall=4683
2023-06-27 03:31:44 - progress_bar.py[line:272] - INFO: epoch 001:   2252 / 2637 loss=2.436, loss_v1=0, loss_v2=0, nll_loss=1.247, ntokens=1246.2, nsentences=160, sample_size=1246.2, sample_size_v1=0, sample_size_v2=0, ppl=2.37, wps=598.3, ups=0.48, wpb=1246.2, bsz=160, num_updates=2250, lr=2.66693e-05, gnorm=2.393, clip=100, loss_scale=128, train_wall=21, gb_free=8.9, wall=4704
2023-06-27 03:32:05 - progress_bar.py[line:272] - INFO: epoch 001:   2262 / 2637 loss=2.419, loss_v1=0, loss_v2=0, nll_loss=1.229, ntokens=1264.7, nsentences=160, sample_size=1264.7, sample_size_v1=0, sample_size_v2=0, ppl=2.34, wps=606.9, ups=0.48, wpb=1264.7, bsz=160, num_updates=2260, lr=2.67878e-05, gnorm=2.007, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=4725
2023-06-27 03:32:25 - progress_bar.py[line:272] - INFO: epoch 001:   2272 / 2637 loss=2.433, loss_v1=0, loss_v2=0, nll_loss=1.247, ntokens=1283.8, nsentences=160, sample_size=1283.8, sample_size_v1=0, sample_size_v2=0, ppl=2.37, wps=616, ups=0.48, wpb=1283.8, bsz=160, num_updates=2270, lr=2.69064e-05, gnorm=2.058, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=4746
2023-06-27 03:32:46 - progress_bar.py[line:272] - INFO: epoch 001:   2282 / 2637 loss=2.447, loss_v1=0, loss_v2=0, nll_loss=1.259, ntokens=1261.8, nsentences=160, sample_size=1261.8, sample_size_v1=0, sample_size_v2=0, ppl=2.39, wps=605.5, ups=0.48, wpb=1261.8, bsz=160, num_updates=2280, lr=2.70249e-05, gnorm=2.137, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=4767
2023-06-27 03:33:07 - progress_bar.py[line:272] - INFO: epoch 001:   2292 / 2637 loss=2.421, loss_v1=0, loss_v2=0, nll_loss=1.232, ntokens=1268.7, nsentences=160, sample_size=1268.7, sample_size_v1=0, sample_size_v2=0, ppl=2.35, wps=608.1, ups=0.48, wpb=1268.7, bsz=160, num_updates=2290, lr=2.71434e-05, gnorm=2.118, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=4787
2023-06-27 03:33:28 - progress_bar.py[line:272] - INFO: epoch 001:   2302 / 2637 loss=2.463, loss_v1=0, loss_v2=0, nll_loss=1.276, ntokens=1267.5, nsentences=160, sample_size=1267.5, sample_size_v1=0, sample_size_v2=0, ppl=2.42, wps=608.1, ups=0.48, wpb=1267.5, bsz=160, num_updates=2300, lr=2.7262e-05, gnorm=2.158, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=4808
2023-06-27 03:33:49 - progress_bar.py[line:272] - INFO: epoch 001:   2312 / 2637 loss=2.411, loss_v1=0, loss_v2=0, nll_loss=1.221, ntokens=1271.1, nsentences=160, sample_size=1271.1, sample_size_v1=0, sample_size_v2=0, ppl=2.33, wps=609.4, ups=0.48, wpb=1271.1, bsz=160, num_updates=2310, lr=2.73805e-05, gnorm=2.319, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=4829
2023-06-27 03:34:10 - progress_bar.py[line:272] - INFO: epoch 001:   2322 / 2637 loss=2.426, loss_v1=0, loss_v2=0, nll_loss=1.236, ntokens=1265.6, nsentences=160, sample_size=1265.6, sample_size_v1=0, sample_size_v2=0, ppl=2.35, wps=606.8, ups=0.48, wpb=1265.6, bsz=160, num_updates=2320, lr=2.7499e-05, gnorm=2.559, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=4850
2023-06-27 03:34:31 - progress_bar.py[line:272] - INFO: epoch 001:   2332 / 2637 loss=2.448, loss_v1=0, loss_v2=0, nll_loss=1.263, ntokens=1242.7, nsentences=160, sample_size=1242.7, sample_size_v1=0, sample_size_v2=0, ppl=2.4, wps=596.2, ups=0.48, wpb=1242.7, bsz=160, num_updates=2330, lr=2.76175e-05, gnorm=2.149, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=4871
2023-06-27 03:34:51 - progress_bar.py[line:272] - INFO: epoch 001:   2342 / 2637 loss=2.432, loss_v1=0, loss_v2=0, nll_loss=1.24, ntokens=1260.3, nsentences=160, sample_size=1260.3, sample_size_v1=0, sample_size_v2=0, ppl=2.36, wps=604.4, ups=0.48, wpb=1260.3, bsz=160, num_updates=2340, lr=2.77361e-05, gnorm=2.381, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=4892
2023-06-27 03:35:12 - progress_bar.py[line:272] - INFO: epoch 001:   2352 / 2637 loss=2.408, loss_v1=0, loss_v2=0, nll_loss=1.217, ntokens=1263.3, nsentences=160, sample_size=1263.3, sample_size_v1=0, sample_size_v2=0, ppl=2.32, wps=605.7, ups=0.48, wpb=1263.3, bsz=160, num_updates=2350, lr=2.78546e-05, gnorm=1.75, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=4913
2023-06-27 03:35:33 - progress_bar.py[line:272] - INFO: epoch 001:   2362 / 2637 loss=2.447, loss_v1=0, loss_v2=0, nll_loss=1.26, ntokens=1275.9, nsentences=160, sample_size=1275.9, sample_size_v1=0, sample_size_v2=0, ppl=2.4, wps=612.6, ups=0.48, wpb=1275.9, bsz=160, num_updates=2360, lr=2.79731e-05, gnorm=2.075, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=4933
2023-06-27 03:35:54 - progress_bar.py[line:272] - INFO: epoch 001:   2372 / 2637 loss=2.431, loss_v1=0, loss_v2=0, nll_loss=1.241, ntokens=1277.1, nsentences=160, sample_size=1277.1, sample_size_v1=0, sample_size_v2=0, ppl=2.36, wps=613.5, ups=0.48, wpb=1277.1, bsz=160, num_updates=2370, lr=2.80917e-05, gnorm=2.146, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=4954
2023-06-27 03:36:15 - progress_bar.py[line:272] - INFO: epoch 001:   2382 / 2637 loss=2.434, loss_v1=0, loss_v2=0, nll_loss=1.244, ntokens=1272.4, nsentences=160, sample_size=1272.4, sample_size_v1=0, sample_size_v2=0, ppl=2.37, wps=610.6, ups=0.48, wpb=1272.4, bsz=160, num_updates=2380, lr=2.82102e-05, gnorm=2.104, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=4975
2023-06-27 03:36:36 - progress_bar.py[line:272] - INFO: epoch 001:   2392 / 2637 loss=2.451, loss_v1=0, loss_v2=0, nll_loss=1.265, ntokens=1289.7, nsentences=160, sample_size=1289.7, sample_size_v1=0, sample_size_v2=0, ppl=2.4, wps=619.1, ups=0.48, wpb=1289.7, bsz=160, num_updates=2390, lr=2.83287e-05, gnorm=1.803, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=4996
2023-06-27 03:36:56 - progress_bar.py[line:272] - INFO: epoch 001:   2402 / 2637 loss=2.467, loss_v1=0, loss_v2=0, nll_loss=1.282, ntokens=1270.1, nsentences=160, sample_size=1270.1, sample_size_v1=0, sample_size_v2=0, ppl=2.43, wps=609.8, ups=0.48, wpb=1270.1, bsz=160, num_updates=2400, lr=2.84473e-05, gnorm=2.404, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=5017
2023-06-27 03:37:17 - progress_bar.py[line:272] - INFO: epoch 001:   2412 / 2637 loss=2.441, loss_v1=0, loss_v2=0, nll_loss=1.253, ntokens=1291.6, nsentences=160, sample_size=1291.6, sample_size_v1=0, sample_size_v2=0, ppl=2.38, wps=620.5, ups=0.48, wpb=1291.6, bsz=160, num_updates=2410, lr=2.85658e-05, gnorm=2.322, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=5038
2023-06-27 03:37:38 - progress_bar.py[line:272] - INFO: epoch 001:   2422 / 2637 loss=2.408, loss_v1=0, loss_v2=0, nll_loss=1.219, ntokens=1258, nsentences=160, sample_size=1258, sample_size_v1=0, sample_size_v2=0, ppl=2.33, wps=604.1, ups=0.48, wpb=1258, bsz=160, num_updates=2420, lr=2.86843e-05, gnorm=2.135, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=5058
2023-06-27 03:37:59 - progress_bar.py[line:272] - INFO: epoch 001:   2432 / 2637 loss=2.427, loss_v1=0, loss_v2=0, nll_loss=1.236, ntokens=1281.6, nsentences=160, sample_size=1281.6, sample_size_v1=0, sample_size_v2=0, ppl=2.36, wps=614.6, ups=0.48, wpb=1281.6, bsz=160, num_updates=2430, lr=2.88028e-05, gnorm=2.338, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=5079
2023-06-27 03:38:20 - progress_bar.py[line:272] - INFO: epoch 001:   2442 / 2637 loss=2.443, loss_v1=0, loss_v2=0, nll_loss=1.254, ntokens=1279, nsentences=160, sample_size=1279, sample_size_v1=0, sample_size_v2=0, ppl=2.38, wps=613.8, ups=0.48, wpb=1279, bsz=160, num_updates=2440, lr=2.89214e-05, gnorm=2.479, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=5100
2023-06-27 03:38:41 - progress_bar.py[line:272] - INFO: epoch 001:   2452 / 2637 loss=2.425, loss_v1=0, loss_v2=0, nll_loss=1.235, ntokens=1274.6, nsentences=160, sample_size=1274.6, sample_size_v1=0, sample_size_v2=0, ppl=2.35, wps=611.4, ups=0.48, wpb=1274.6, bsz=160, num_updates=2450, lr=2.90399e-05, gnorm=2.149, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=5121
2023-06-27 03:39:01 - progress_bar.py[line:272] - INFO: epoch 001:   2462 / 2637 loss=2.41, loss_v1=0, loss_v2=0, nll_loss=1.215, ntokens=1273.9, nsentences=160, sample_size=1273.9, sample_size_v1=0, sample_size_v2=0, ppl=2.32, wps=610.8, ups=0.48, wpb=1273.9, bsz=160, num_updates=2460, lr=2.91584e-05, gnorm=1.921, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=5142
2023-06-27 03:39:22 - progress_bar.py[line:272] - INFO: epoch 001:   2472 / 2637 loss=2.419, loss_v1=0, loss_v2=0, nll_loss=1.23, ntokens=1284.8, nsentences=160, sample_size=1284.8, sample_size_v1=0, sample_size_v2=0, ppl=2.35, wps=614.9, ups=0.48, wpb=1284.8, bsz=160, num_updates=2470, lr=2.9277e-05, gnorm=1.907, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=5163
2023-06-27 03:39:43 - progress_bar.py[line:272] - INFO: epoch 001:   2482 / 2637 loss=2.438, loss_v1=0, loss_v2=0, nll_loss=1.25, ntokens=1289.4, nsentences=160, sample_size=1289.4, sample_size_v1=0, sample_size_v2=0, ppl=2.38, wps=618.1, ups=0.48, wpb=1289.4, bsz=160, num_updates=2480, lr=2.93955e-05, gnorm=1.999, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=5184
2023-06-27 03:39:47 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 128.0
2023-06-27 03:40:06 - progress_bar.py[line:272] - INFO: epoch 001:   2493 / 2637 loss=2.424, loss_v1=0, loss_v2=0, nll_loss=1.231, ntokens=1275.1, nsentences=160, sample_size=1275.1, sample_size_v1=0, sample_size_v2=0, ppl=2.35, wps=556.5, ups=0.44, wpb=1275.1, bsz=160, num_updates=2490, lr=2.9514e-05, gnorm=2.308, clip=100, loss_scale=128, train_wall=23, gb_free=8.9, wall=5206
2023-06-27 03:40:27 - progress_bar.py[line:272] - INFO: epoch 001:   2503 / 2637 loss=2.417, loss_v1=0, loss_v2=0, nll_loss=1.227, ntokens=1281.6, nsentences=160, sample_size=1281.6, sample_size_v1=0, sample_size_v2=0, ppl=2.34, wps=614.2, ups=0.48, wpb=1281.6, bsz=160, num_updates=2500, lr=2.96326e-05, gnorm=1.9, clip=100, loss_scale=128, train_wall=21, gb_free=8.9, wall=5227
2023-06-27 03:40:48 - progress_bar.py[line:272] - INFO: epoch 001:   2513 / 2637 loss=2.425, loss_v1=0, loss_v2=0, nll_loss=1.234, ntokens=1271.4, nsentences=160, sample_size=1271.4, sample_size_v1=0, sample_size_v2=0, ppl=2.35, wps=609.2, ups=0.48, wpb=1271.4, bsz=160, num_updates=2510, lr=2.97511e-05, gnorm=2.061, clip=100, loss_scale=128, train_wall=21, gb_free=8.9, wall=5248
2023-06-27 03:41:09 - progress_bar.py[line:272] - INFO: epoch 001:   2523 / 2637 loss=2.424, loss_v1=0, loss_v2=0, nll_loss=1.234, ntokens=1277, nsentences=160, sample_size=1277, sample_size_v1=0, sample_size_v2=0, ppl=2.35, wps=612.4, ups=0.48, wpb=1277, bsz=160, num_updates=2520, lr=2.98696e-05, gnorm=2.561, clip=100, loss_scale=128, train_wall=21, gb_free=8.9, wall=5269
2023-06-27 03:41:30 - progress_bar.py[line:272] - INFO: epoch 001:   2533 / 2637 loss=2.421, loss_v1=0, loss_v2=0, nll_loss=1.228, ntokens=1268.5, nsentences=160, sample_size=1268.5, sample_size_v1=0, sample_size_v2=0, ppl=2.34, wps=608.8, ups=0.48, wpb=1268.5, bsz=160, num_updates=2530, lr=2.99881e-05, gnorm=2.351, clip=100, loss_scale=128, train_wall=21, gb_free=8.9, wall=5290
2023-06-27 03:41:50 - progress_bar.py[line:272] - INFO: epoch 001:   2543 / 2637 loss=2.404, loss_v1=0, loss_v2=0, nll_loss=1.21, ntokens=1263.5, nsentences=160, sample_size=1263.5, sample_size_v1=0, sample_size_v2=0, ppl=2.31, wps=606.2, ups=0.48, wpb=1263.5, bsz=160, num_updates=2540, lr=2.99932e-05, gnorm=2.31, clip=100, loss_scale=128, train_wall=21, gb_free=8.9, wall=5311
2023-06-27 03:42:11 - progress_bar.py[line:272] - INFO: epoch 001:   2553 / 2637 loss=2.416, loss_v1=0, loss_v2=0, nll_loss=1.224, ntokens=1269.5, nsentences=160, sample_size=1269.5, sample_size_v1=0, sample_size_v2=0, ppl=2.34, wps=609.2, ups=0.48, wpb=1269.5, bsz=160, num_updates=2550, lr=2.99856e-05, gnorm=2.335, clip=100, loss_scale=128, train_wall=21, gb_free=8.9, wall=5332
2023-06-27 03:42:32 - progress_bar.py[line:272] - INFO: epoch 001:   2563 / 2637 loss=2.429, loss_v1=0, loss_v2=0, nll_loss=1.24, ntokens=1266.2, nsentences=160, sample_size=1266.2, sample_size_v1=0, sample_size_v2=0, ppl=2.36, wps=607.6, ups=0.48, wpb=1266.2, bsz=160, num_updates=2560, lr=2.99781e-05, gnorm=2.299, clip=100, loss_scale=128, train_wall=21, gb_free=8.9, wall=5352
2023-06-27 03:42:53 - progress_bar.py[line:272] - INFO: epoch 001:   2573 / 2637 loss=2.415, loss_v1=0, loss_v2=0, nll_loss=1.225, ntokens=1262.1, nsentences=160, sample_size=1262.1, sample_size_v1=0, sample_size_v2=0, ppl=2.34, wps=605.7, ups=0.48, wpb=1262.1, bsz=160, num_updates=2570, lr=2.99705e-05, gnorm=2.104, clip=100, loss_scale=128, train_wall=21, gb_free=8.8, wall=5373
2023-06-27 03:43:14 - progress_bar.py[line:272] - INFO: epoch 001:   2583 / 2637 loss=2.427, loss_v1=0, loss_v2=0, nll_loss=1.236, ntokens=1264.3, nsentences=160, sample_size=1264.3, sample_size_v1=0, sample_size_v2=0, ppl=2.36, wps=607, ups=0.48, wpb=1264.3, bsz=160, num_updates=2580, lr=2.99629e-05, gnorm=2.982, clip=100, loss_scale=128, train_wall=21, gb_free=8.9, wall=5394
2023-06-27 03:43:35 - progress_bar.py[line:272] - INFO: epoch 001:   2593 / 2637 loss=2.414, loss_v1=0, loss_v2=0, nll_loss=1.223, ntokens=1284.2, nsentences=160, sample_size=1284.2, sample_size_v1=0, sample_size_v2=0, ppl=2.33, wps=615.5, ups=0.48, wpb=1284.2, bsz=160, num_updates=2590, lr=2.99554e-05, gnorm=2.373, clip=100, loss_scale=128, train_wall=21, gb_free=8.9, wall=5415
2023-06-27 03:43:56 - progress_bar.py[line:272] - INFO: epoch 001:   2603 / 2637 loss=2.417, loss_v1=0, loss_v2=0, nll_loss=1.225, ntokens=1283.6, nsentences=160, sample_size=1283.6, sample_size_v1=0, sample_size_v2=0, ppl=2.34, wps=615, ups=0.48, wpb=1283.6, bsz=160, num_updates=2600, lr=2.99478e-05, gnorm=2.733, clip=100, loss_scale=128, train_wall=21, gb_free=8.9, wall=5436
2023-06-27 03:44:16 - progress_bar.py[line:272] - INFO: epoch 001:   2613 / 2637 loss=2.419, loss_v1=0, loss_v2=0, nll_loss=1.228, ntokens=1270.2, nsentences=160, sample_size=1270.2, sample_size_v1=0, sample_size_v2=0, ppl=2.34, wps=609.6, ups=0.48, wpb=1270.2, bsz=160, num_updates=2610, lr=2.99402e-05, gnorm=2.553, clip=100, loss_scale=128, train_wall=21, gb_free=8.9, wall=5457
2023-06-27 03:44:37 - progress_bar.py[line:272] - INFO: epoch 001:   2623 / 2637 loss=2.411, loss_v1=0, loss_v2=0, nll_loss=1.222, ntokens=1262.3, nsentences=160, sample_size=1262.3, sample_size_v1=0, sample_size_v2=0, ppl=2.33, wps=605.8, ups=0.48, wpb=1262.3, bsz=160, num_updates=2620, lr=2.99327e-05, gnorm=3.506, clip=100, loss_scale=128, train_wall=21, gb_free=8.9, wall=5478
2023-06-27 03:44:58 - progress_bar.py[line:272] - INFO: epoch 001:   2633 / 2637 loss=2.417, loss_v1=0, loss_v2=0, nll_loss=1.223, ntokens=1289.9, nsentences=160, sample_size=1289.9, sample_size_v1=0, sample_size_v2=0, ppl=2.34, wps=618.7, ups=0.48, wpb=1289.9, bsz=160, num_updates=2630, lr=2.99251e-05, gnorm=2.725, clip=100, loss_scale=128, train_wall=21, gb_free=8.9, wall=5498
2023-06-27 03:45:06 - train.py[line:332] - INFO: end of epoch 1 (average epoch stats below)
local datafile ../../dataset/OFA_data/vrd/vg_train_full.tsv slice_id 2 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../dataset/OFA_data/vrd/vg_train_full.tsv slice_id 1 begin to initialize row_count and line_idx-to-offset mappinglocal datafile ../../dataset/OFA_data/vrd/vg_train_full.tsv slice_id 3 begin to initialize row_count and line_idx-to-offset mapping

2023-06-27 03:45:06 - progress_bar.py[line:282] - INFO: epoch 001 | loss 3.164 | loss_v1 0 | loss_v2 0 | nll_loss 2.1 | ntokens 1259.93 | nsentences 159.984 | sample_size 1259.93 | sample_size_v1 0 | sample_size_v2 0 | ppl 4.29 | wps 603.7 | ups 0.48 | wpb 1259.9 | bsz 160 | num_updates 2634 | lr 2.99221e-05 | gnorm 2.414 | clip 91.8 | loss_scale 128 | train_wall 5490 | gb_free 8.9 | wall 5506
2023-06-27 03:45:06 - trainer.py[line:639] - INFO: loading train data for epoch 2
local datafile ../../dataset/OFA_data/vrd/vg_train_full.tsv slice_id 0 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../dataset/OFA_data/vrd/vg_train_full.tsv slice_id 2 finished initializing row_count and line_idx-to-offset mapping
file ../../dataset/OFA_data/vrd/vg_train_full.tsv slice_id 2 row count 105470 total row count 421879
local datafile ../../dataset/OFA_data/vrd/vg_train_full.tsv slice_id 3 finished initializing row_count and line_idx-to-offset mapping
file ../../dataset/OFA_data/vrd/vg_train_full.tsv slice_id 3 row count 105469 total row count 421879
local datafile ../../dataset/OFA_data/vrd/vg_train_full.tsv slice_id 1 finished initializing row_count and line_idx-to-offset mapping
file ../../dataset/OFA_data/vrd/vg_train_full.tsv slice_id 1 row count 105470 total row count 421879
local datafile ../../dataset/OFA_data/vrd/vg_train_full.tsv slice_id 0 finished initializing row_count and line_idx-to-offset mapping
file ../../dataset/OFA_data/vrd/vg_train_full.tsv slice_id 0 row count 105470 total row count 421879
/data/hulab/zcai75/anaconda3/envs/vilt/lib/python3.8/site-packages/torchvision/transforms/transforms.py:332: UserWarning: Argument 'interpolation' of type int is deprecated since 0.13 and will be removed in 0.15. Please use InterpolationMode enum.
  warnings.warn(
slice_id 2 seek offset 210940
slice_id 3 seek offset 316410
slice_id 1 seek offset 105470
slice_id 0 seek offset 0
2023-06-27 03:45:06 - trainer.py[line:703] - INFO: begin training epoch 2
2023-06-27 03:45:06 - train.py[line:305] - INFO: Start iterating over samples
2023-06-27 03:45:19 - progress_bar.py[line:272] - INFO: epoch 002:      6 / 2637 loss=2.436, loss_v1=0, loss_v2=0, nll_loss=1.248, ntokens=1222.5, nsentences=156, sample_size=1222.5, sample_size_v1=0, sample_size_v2=0, ppl=2.38, wps=583.2, ups=0.48, wpb=1222.5, bsz=156, num_updates=2640, lr=2.99176e-05, gnorm=3.025, clip=100, loss_scale=128, train_wall=20, gb_free=8.9, wall=5519
2023-06-27 03:45:40 - progress_bar.py[line:272] - INFO: epoch 002:     16 / 2637 loss=2.4, loss_v1=0, loss_v2=0, nll_loss=1.205, ntokens=1249.4, nsentences=160, sample_size=1249.4, sample_size_v1=0, sample_size_v2=0, ppl=2.31, wps=600.7, ups=0.48, wpb=1249.4, bsz=160, num_updates=2650, lr=2.991e-05, gnorm=2.757, clip=100, loss_scale=128, train_wall=21, gb_free=8.9, wall=5540
2023-06-27 03:46:01 - progress_bar.py[line:272] - INFO: epoch 002:     26 / 2637 loss=2.395, loss_v1=0, loss_v2=0, nll_loss=1.204, ntokens=1268.8, nsentences=160, sample_size=1268.8, sample_size_v1=0, sample_size_v2=0, ppl=2.3, wps=609.7, ups=0.48, wpb=1268.8, bsz=160, num_updates=2660, lr=2.99024e-05, gnorm=3.017, clip=100, loss_scale=128, train_wall=21, gb_free=8.9, wall=5561
2023-06-27 03:46:21 - progress_bar.py[line:272] - INFO: epoch 002:     36 / 2637 loss=2.39, loss_v1=0, loss_v2=0, nll_loss=1.194, ntokens=1256.8, nsentences=160, sample_size=1256.8, sample_size_v1=0, sample_size_v2=0, ppl=2.29, wps=603.8, ups=0.48, wpb=1256.8, bsz=160, num_updates=2670, lr=2.98949e-05, gnorm=2.893, clip=100, loss_scale=128, train_wall=21, gb_free=8.9, wall=5582
2023-06-27 03:46:42 - progress_bar.py[line:272] - INFO: epoch 002:     46 / 2637 loss=2.4, loss_v1=0, loss_v2=0, nll_loss=1.206, ntokens=1253.4, nsentences=160, sample_size=1253.4, sample_size_v1=0, sample_size_v2=0, ppl=2.31, wps=602.1, ups=0.48, wpb=1253.4, bsz=160, num_updates=2680, lr=2.98873e-05, gnorm=2.707, clip=100, loss_scale=128, train_wall=21, gb_free=8.9, wall=5603
2023-06-27 03:47:03 - progress_bar.py[line:272] - INFO: epoch 002:     56 / 2637 loss=2.402, loss_v1=0, loss_v2=0, nll_loss=1.21, ntokens=1243.4, nsentences=160, sample_size=1243.4, sample_size_v1=0, sample_size_v2=0, ppl=2.31, wps=597.2, ups=0.48, wpb=1243.4, bsz=160, num_updates=2690, lr=2.98797e-05, gnorm=2.99, clip=100, loss_scale=128, train_wall=21, gb_free=8.9, wall=5623
2023-06-27 03:47:24 - progress_bar.py[line:272] - INFO: epoch 002:     66 / 2637 loss=2.424, loss_v1=0, loss_v2=0, nll_loss=1.233, ntokens=1252.6, nsentences=160, sample_size=1252.6, sample_size_v1=0, sample_size_v2=0, ppl=2.35, wps=600.6, ups=0.48, wpb=1252.6, bsz=160, num_updates=2700, lr=2.98722e-05, gnorm=3.499, clip=100, loss_scale=128, train_wall=21, gb_free=8.9, wall=5644
2023-06-27 03:47:45 - progress_bar.py[line:272] - INFO: epoch 002:     76 / 2637 loss=2.409, loss_v1=0, loss_v2=0, nll_loss=1.219, ntokens=1243.2, nsentences=160, sample_size=1243.2, sample_size_v1=0, sample_size_v2=0, ppl=2.33, wps=596, ups=0.48, wpb=1243.2, bsz=160, num_updates=2710, lr=2.98646e-05, gnorm=3.978, clip=100, loss_scale=128, train_wall=21, gb_free=8.9, wall=5665
2023-06-27 03:48:06 - progress_bar.py[line:272] - INFO: epoch 002:     86 / 2637 loss=2.42, loss_v1=0, loss_v2=0, nll_loss=1.226, ntokens=1256.9, nsentences=160, sample_size=1256.9, sample_size_v1=0, sample_size_v2=0, ppl=2.34, wps=602.4, ups=0.48, wpb=1256.9, bsz=160, num_updates=2720, lr=2.9857e-05, gnorm=3.371, clip=100, loss_scale=128, train_wall=21, gb_free=8.9, wall=5686
2023-06-27 03:48:27 - progress_bar.py[line:272] - INFO: epoch 002:     96 / 2637 loss=2.394, loss_v1=0, loss_v2=0, nll_loss=1.202, ntokens=1252, nsentences=160, sample_size=1252, sample_size_v1=0, sample_size_v2=0, ppl=2.3, wps=600.4, ups=0.48, wpb=1252, bsz=160, num_updates=2730, lr=2.98495e-05, gnorm=3.942, clip=100, loss_scale=128, train_wall=21, gb_free=8.9, wall=5707
2023-06-27 03:48:35 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2023-06-27 03:48:50 - progress_bar.py[line:272] - INFO: epoch 002:    107 / 2637 loss=2.402, loss_v1=0, loss_v2=0, nll_loss=1.206, ntokens=1242.3, nsentences=160, sample_size=1242.3, sample_size_v1=0, sample_size_v2=0, ppl=2.31, wps=542, ups=0.44, wpb=1242.3, bsz=160, num_updates=2740, lr=2.98419e-05, gnorm=3.335, clip=100, loss_scale=64, train_wall=23, gb_free=8.9, wall=5730
2023-06-27 03:49:10 - progress_bar.py[line:272] - INFO: epoch 002:    117 / 2637 loss=2.371, loss_v1=0, loss_v2=0, nll_loss=1.176, ntokens=1249.1, nsentences=160, sample_size=1249.1, sample_size_v1=0, sample_size_v2=0, ppl=2.26, wps=598.5, ups=0.48, wpb=1249.1, bsz=160, num_updates=2750, lr=2.98343e-05, gnorm=3.025, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=5751
2023-06-27 03:49:31 - progress_bar.py[line:272] - INFO: epoch 002:    127 / 2637 loss=2.39, loss_v1=0, loss_v2=0, nll_loss=1.197, ntokens=1237, nsentences=160, sample_size=1237, sample_size_v1=0, sample_size_v2=0, ppl=2.29, wps=592.9, ups=0.48, wpb=1237, bsz=160, num_updates=2760, lr=2.98268e-05, gnorm=3.108, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=5772
2023-06-27 03:49:52 - progress_bar.py[line:272] - INFO: epoch 002:    137 / 2637 loss=2.408, loss_v1=0, loss_v2=0, nll_loss=1.214, ntokens=1256.9, nsentences=160, sample_size=1256.9, sample_size_v1=0, sample_size_v2=0, ppl=2.32, wps=602.6, ups=0.48, wpb=1256.9, bsz=160, num_updates=2770, lr=2.98192e-05, gnorm=2.79, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=5792
2023-06-27 03:50:13 - progress_bar.py[line:272] - INFO: epoch 002:    147 / 2637 loss=2.413, loss_v1=0, loss_v2=0, nll_loss=1.219, ntokens=1251.5, nsentences=160, sample_size=1251.5, sample_size_v1=0, sample_size_v2=0, ppl=2.33, wps=599.6, ups=0.48, wpb=1251.5, bsz=160, num_updates=2780, lr=2.98117e-05, gnorm=3.143, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=5813
2023-06-27 03:50:34 - progress_bar.py[line:272] - INFO: epoch 002:    157 / 2637 loss=2.439, loss_v1=0, loss_v2=0, nll_loss=1.251, ntokens=1240.4, nsentences=160, sample_size=1240.4, sample_size_v1=0, sample_size_v2=0, ppl=2.38, wps=594.3, ups=0.48, wpb=1240.4, bsz=160, num_updates=2790, lr=2.98041e-05, gnorm=2.999, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=5834
2023-06-27 03:50:55 - progress_bar.py[line:272] - INFO: epoch 002:    167 / 2637 loss=2.428, loss_v1=0, loss_v2=0, nll_loss=1.236, ntokens=1239.7, nsentences=160, sample_size=1239.7, sample_size_v1=0, sample_size_v2=0, ppl=2.36, wps=595.1, ups=0.48, wpb=1239.7, bsz=160, num_updates=2800, lr=2.97965e-05, gnorm=2.77, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=5855
2023-06-27 03:51:16 - progress_bar.py[line:272] - INFO: epoch 002:    177 / 2637 loss=2.399, loss_v1=0, loss_v2=0, nll_loss=1.206, ntokens=1239.6, nsentences=160, sample_size=1239.6, sample_size_v1=0, sample_size_v2=0, ppl=2.31, wps=594.9, ups=0.48, wpb=1239.6, bsz=160, num_updates=2810, lr=2.9789e-05, gnorm=2.779, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=5876
2023-06-27 03:51:36 - progress_bar.py[line:272] - INFO: epoch 002:    187 / 2637 loss=2.392, loss_v1=0, loss_v2=0, nll_loss=1.197, ntokens=1242.2, nsentences=160, sample_size=1242.2, sample_size_v1=0, sample_size_v2=0, ppl=2.29, wps=596.3, ups=0.48, wpb=1242.2, bsz=160, num_updates=2820, lr=2.97814e-05, gnorm=3.044, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=5897
2023-06-27 03:51:57 - progress_bar.py[line:272] - INFO: epoch 002:    197 / 2637 loss=2.395, loss_v1=0, loss_v2=0, nll_loss=1.203, ntokens=1234.8, nsentences=160, sample_size=1234.8, sample_size_v1=0, sample_size_v2=0, ppl=2.3, wps=593.3, ups=0.48, wpb=1234.8, bsz=160, num_updates=2830, lr=2.97738e-05, gnorm=3.032, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=5917
2023-06-27 03:52:18 - progress_bar.py[line:272] - INFO: epoch 002:    207 / 2637 loss=2.365, loss_v1=0, loss_v2=0, nll_loss=1.166, ntokens=1257.2, nsentences=160, sample_size=1257.2, sample_size_v1=0, sample_size_v2=0, ppl=2.24, wps=603.7, ups=0.48, wpb=1257.2, bsz=160, num_updates=2840, lr=2.97663e-05, gnorm=3.031, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=5938
2023-06-27 03:52:39 - progress_bar.py[line:272] - INFO: epoch 002:    217 / 2637 loss=2.356, loss_v1=0, loss_v2=0, nll_loss=1.16, ntokens=1225.9, nsentences=160, sample_size=1225.9, sample_size_v1=0, sample_size_v2=0, ppl=2.23, wps=588.2, ups=0.48, wpb=1225.9, bsz=160, num_updates=2850, lr=2.97587e-05, gnorm=3.584, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=5959
2023-06-27 03:53:00 - progress_bar.py[line:272] - INFO: epoch 002:    227 / 2637 loss=2.394, loss_v1=0, loss_v2=0, nll_loss=1.199, ntokens=1245.1, nsentences=160, sample_size=1245.1, sample_size_v1=0, sample_size_v2=0, ppl=2.3, wps=597.9, ups=0.48, wpb=1245.1, bsz=160, num_updates=2860, lr=2.97511e-05, gnorm=3.549, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=5980
2023-06-27 03:53:21 - progress_bar.py[line:272] - INFO: epoch 002:    237 / 2637 loss=2.395, loss_v1=0, loss_v2=0, nll_loss=1.203, ntokens=1250.9, nsentences=160, sample_size=1250.9, sample_size_v1=0, sample_size_v2=0, ppl=2.3, wps=601.2, ups=0.48, wpb=1250.9, bsz=160, num_updates=2870, lr=2.97436e-05, gnorm=3.291, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=6001
2023-06-27 03:53:41 - progress_bar.py[line:272] - INFO: epoch 002:    247 / 2637 loss=2.367, loss_v1=0, loss_v2=0, nll_loss=1.167, ntokens=1266.8, nsentences=160, sample_size=1266.8, sample_size_v1=0, sample_size_v2=0, ppl=2.25, wps=609.4, ups=0.48, wpb=1266.8, bsz=160, num_updates=2880, lr=2.9736e-05, gnorm=3.398, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=6022
2023-06-27 03:54:02 - progress_bar.py[line:272] - INFO: epoch 002:    257 / 2637 loss=2.377, loss_v1=0, loss_v2=0, nll_loss=1.181, ntokens=1234.5, nsentences=160, sample_size=1234.5, sample_size_v1=0, sample_size_v2=0, ppl=2.27, wps=593.6, ups=0.48, wpb=1234.5, bsz=160, num_updates=2890, lr=2.97284e-05, gnorm=4.31, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=6042
2023-06-27 03:54:23 - progress_bar.py[line:272] - INFO: epoch 002:    267 / 2637 loss=2.383, loss_v1=0, loss_v2=0, nll_loss=1.186, ntokens=1256.2, nsentences=160, sample_size=1256.2, sample_size_v1=0, sample_size_v2=0, ppl=2.28, wps=604.3, ups=0.48, wpb=1256.2, bsz=160, num_updates=2900, lr=2.97209e-05, gnorm=3.737, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=6063
2023-06-27 03:54:44 - progress_bar.py[line:272] - INFO: epoch 002:    277 / 2637 loss=2.414, loss_v1=0, loss_v2=0, nll_loss=1.221, ntokens=1254.7, nsentences=160, sample_size=1254.7, sample_size_v1=0, sample_size_v2=0, ppl=2.33, wps=602.9, ups=0.48, wpb=1254.7, bsz=160, num_updates=2910, lr=2.97133e-05, gnorm=4.385, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=6084
2023-06-27 03:55:04 - progress_bar.py[line:272] - INFO: epoch 002:    287 / 2637 loss=2.401, loss_v1=0, loss_v2=0, nll_loss=1.207, ntokens=1248.8, nsentences=160, sample_size=1248.8, sample_size_v1=0, sample_size_v2=0, ppl=2.31, wps=600.7, ups=0.48, wpb=1248.8, bsz=160, num_updates=2920, lr=2.97058e-05, gnorm=3.022, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=6105
2023-06-27 03:55:25 - progress_bar.py[line:272] - INFO: epoch 002:    297 / 2637 loss=2.417, loss_v1=0, loss_v2=0, nll_loss=1.228, ntokens=1235, nsentences=160, sample_size=1235, sample_size_v1=0, sample_size_v2=0, ppl=2.34, wps=593.7, ups=0.48, wpb=1235, bsz=160, num_updates=2930, lr=2.96982e-05, gnorm=3.491, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=6126
2023-06-27 03:55:46 - progress_bar.py[line:272] - INFO: epoch 002:    307 / 2637 loss=2.386, loss_v1=0, loss_v2=0, nll_loss=1.19, ntokens=1226.3, nsentences=160, sample_size=1226.3, sample_size_v1=0, sample_size_v2=0, ppl=2.28, wps=589.5, ups=0.48, wpb=1226.3, bsz=160, num_updates=2940, lr=2.96906e-05, gnorm=3.618, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=6146
2023-06-27 03:56:07 - progress_bar.py[line:272] - INFO: epoch 002:    317 / 2637 loss=2.372, loss_v1=0, loss_v2=0, nll_loss=1.176, ntokens=1245.9, nsentences=160, sample_size=1245.9, sample_size_v1=0, sample_size_v2=0, ppl=2.26, wps=599, ups=0.48, wpb=1245.9, bsz=160, num_updates=2950, lr=2.96831e-05, gnorm=3.75, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=6167
2023-06-27 03:56:28 - progress_bar.py[line:272] - INFO: epoch 002:    327 / 2637 loss=2.383, loss_v1=0, loss_v2=0, nll_loss=1.188, ntokens=1259.2, nsentences=160, sample_size=1259.2, sample_size_v1=0, sample_size_v2=0, ppl=2.28, wps=604.6, ups=0.48, wpb=1259.2, bsz=160, num_updates=2960, lr=2.96755e-05, gnorm=3.84, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=6188
2023-06-27 03:56:49 - progress_bar.py[line:272] - INFO: epoch 002:    337 / 2637 loss=2.373, loss_v1=0, loss_v2=0, nll_loss=1.178, ntokens=1228.6, nsentences=160, sample_size=1228.6, sample_size_v1=0, sample_size_v2=0, ppl=2.26, wps=589.7, ups=0.48, wpb=1228.6, bsz=160, num_updates=2970, lr=2.96679e-05, gnorm=3.965, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=6209
2023-06-27 03:57:09 - progress_bar.py[line:272] - INFO: epoch 002:    347 / 2637 loss=2.389, loss_v1=0, loss_v2=0, nll_loss=1.191, ntokens=1265.9, nsentences=160, sample_size=1265.9, sample_size_v1=0, sample_size_v2=0, ppl=2.28, wps=608, ups=0.48, wpb=1265.9, bsz=160, num_updates=2980, lr=2.96604e-05, gnorm=3.202, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=6230
2023-06-27 03:57:30 - progress_bar.py[line:272] - INFO: epoch 002:    357 / 2637 loss=2.364, loss_v1=0, loss_v2=0, nll_loss=1.165, ntokens=1248.7, nsentences=160, sample_size=1248.7, sample_size_v1=0, sample_size_v2=0, ppl=2.24, wps=599.6, ups=0.48, wpb=1248.7, bsz=160, num_updates=2990, lr=2.96528e-05, gnorm=3.574, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=6251
2023-06-27 03:57:51 - progress_bar.py[line:272] - INFO: epoch 002:    367 / 2637 loss=2.345, loss_v1=0, loss_v2=0, nll_loss=1.147, ntokens=1255.9, nsentences=160, sample_size=1255.9, sample_size_v1=0, sample_size_v2=0, ppl=2.21, wps=602.1, ups=0.48, wpb=1255.9, bsz=160, num_updates=3000, lr=2.96452e-05, gnorm=4.024, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=6271
2023-06-27 03:58:12 - progress_bar.py[line:272] - INFO: epoch 002:    377 / 2637 loss=2.345, loss_v1=0, loss_v2=0, nll_loss=1.142, ntokens=1244.8, nsentences=160, sample_size=1244.8, sample_size_v1=0, sample_size_v2=0, ppl=2.21, wps=596.6, ups=0.48, wpb=1244.8, bsz=160, num_updates=3010, lr=2.96377e-05, gnorm=3.901, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=6292
2023-06-27 03:58:33 - progress_bar.py[line:272] - INFO: epoch 002:    387 / 2637 loss=2.355, loss_v1=0, loss_v2=0, nll_loss=1.156, ntokens=1235.4, nsentences=160, sample_size=1235.4, sample_size_v1=0, sample_size_v2=0, ppl=2.23, wps=592.7, ups=0.48, wpb=1235.4, bsz=160, num_updates=3020, lr=2.96301e-05, gnorm=4.655, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=6313
2023-06-27 03:58:54 - progress_bar.py[line:272] - INFO: epoch 002:    397 / 2637 loss=2.331, loss_v1=0, loss_v2=0, nll_loss=1.129, ntokens=1246.5, nsentences=160, sample_size=1246.5, sample_size_v1=0, sample_size_v2=0, ppl=2.19, wps=597.6, ups=0.48, wpb=1246.5, bsz=160, num_updates=3030, lr=2.96226e-05, gnorm=3.933, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=6334
2023-06-27 03:59:15 - progress_bar.py[line:272] - INFO: epoch 002:    407 / 2637 loss=2.342, loss_v1=0, loss_v2=0, nll_loss=1.14, ntokens=1246.2, nsentences=160, sample_size=1246.2, sample_size_v1=0, sample_size_v2=0, ppl=2.2, wps=597.6, ups=0.48, wpb=1246.2, bsz=160, num_updates=3040, lr=2.9615e-05, gnorm=4.867, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=6355
2023-06-27 03:59:35 - progress_bar.py[line:272] - INFO: epoch 002:    417 / 2637 loss=2.336, loss_v1=0, loss_v2=0, nll_loss=1.136, ntokens=1264.7, nsentences=160, sample_size=1264.7, sample_size_v1=0, sample_size_v2=0, ppl=2.2, wps=605.7, ups=0.48, wpb=1264.7, bsz=160, num_updates=3050, lr=2.96074e-05, gnorm=5.707, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=6376
2023-06-27 03:59:56 - progress_bar.py[line:272] - INFO: epoch 002:    427 / 2637 loss=2.339, loss_v1=0, loss_v2=0, nll_loss=1.136, ntokens=1240.5, nsentences=160, sample_size=1240.5, sample_size_v1=0, sample_size_v2=0, ppl=2.2, wps=594.9, ups=0.48, wpb=1240.5, bsz=160, num_updates=3060, lr=2.95999e-05, gnorm=4.265, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=6397
2023-06-27 04:00:17 - progress_bar.py[line:272] - INFO: epoch 002:    437 / 2637 loss=2.363, loss_v1=0, loss_v2=0, nll_loss=1.167, ntokens=1257.1, nsentences=160, sample_size=1257.1, sample_size_v1=0, sample_size_v2=0, ppl=2.25, wps=602.7, ups=0.48, wpb=1257.1, bsz=160, num_updates=3070, lr=2.95923e-05, gnorm=4.583, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=6417
2023-06-27 04:00:38 - progress_bar.py[line:272] - INFO: epoch 002:    447 / 2637 loss=2.343, loss_v1=0, loss_v2=0, nll_loss=1.14, ntokens=1238.7, nsentences=160, sample_size=1238.7, sample_size_v1=0, sample_size_v2=0, ppl=2.2, wps=594.9, ups=0.48, wpb=1238.7, bsz=160, num_updates=3080, lr=2.95847e-05, gnorm=4.377, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=6438
2023-06-27 04:00:59 - progress_bar.py[line:272] - INFO: epoch 002:    457 / 2637 loss=2.357, loss_v1=0, loss_v2=0, nll_loss=1.162, ntokens=1252.4, nsentences=160, sample_size=1252.4, sample_size_v1=0, sample_size_v2=0, ppl=2.24, wps=601.9, ups=0.48, wpb=1252.4, bsz=160, num_updates=3090, lr=2.95772e-05, gnorm=4.275, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=6459
2023-06-27 04:01:20 - progress_bar.py[line:272] - INFO: epoch 002:    467 / 2637 loss=2.35, loss_v1=0, loss_v2=0, nll_loss=1.149, ntokens=1254, nsentences=160, sample_size=1254, sample_size_v1=0, sample_size_v2=0, ppl=2.22, wps=601.8, ups=0.48, wpb=1254, bsz=160, num_updates=3100, lr=2.95696e-05, gnorm=5.085, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=6480
2023-06-27 04:01:40 - progress_bar.py[line:272] - INFO: epoch 002:    477 / 2637 loss=2.393, loss_v1=0, loss_v2=0, nll_loss=1.197, ntokens=1263.2, nsentences=160, sample_size=1263.2, sample_size_v1=0, sample_size_v2=0, ppl=2.29, wps=605.9, ups=0.48, wpb=1263.2, bsz=160, num_updates=3110, lr=2.9562e-05, gnorm=4.613, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=6501
2023-06-27 04:02:01 - progress_bar.py[line:272] - INFO: epoch 002:    487 / 2637 loss=2.372, loss_v1=0, loss_v2=0, nll_loss=1.175, ntokens=1262.1, nsentences=160, sample_size=1262.1, sample_size_v1=0, sample_size_v2=0, ppl=2.26, wps=604.8, ups=0.48, wpb=1262.1, bsz=160, num_updates=3120, lr=2.95545e-05, gnorm=4.212, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=6522
2023-06-27 04:02:22 - progress_bar.py[line:272] - INFO: epoch 002:    497 / 2637 loss=2.375, loss_v1=0, loss_v2=0, nll_loss=1.178, ntokens=1267.9, nsentences=160, sample_size=1267.9, sample_size_v1=0, sample_size_v2=0, ppl=2.26, wps=608.3, ups=0.48, wpb=1267.9, bsz=160, num_updates=3130, lr=2.95469e-05, gnorm=5.237, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=6542
2023-06-27 04:02:43 - progress_bar.py[line:272] - INFO: epoch 002:    507 / 2637 loss=2.384, loss_v1=0, loss_v2=0, nll_loss=1.188, ntokens=1258.9, nsentences=160, sample_size=1258.9, sample_size_v1=0, sample_size_v2=0, ppl=2.28, wps=603.4, ups=0.48, wpb=1258.9, bsz=160, num_updates=3140, lr=2.95393e-05, gnorm=5.509, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=6563
2023-06-27 04:03:04 - progress_bar.py[line:272] - INFO: epoch 002:    517 / 2637 loss=2.407, loss_v1=0, loss_v2=0, nll_loss=1.213, ntokens=1243.3, nsentences=160, sample_size=1243.3, sample_size_v1=0, sample_size_v2=0, ppl=2.32, wps=596, ups=0.48, wpb=1243.3, bsz=160, num_updates=3150, lr=2.95318e-05, gnorm=5.106, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=6584
2023-06-27 04:03:25 - progress_bar.py[line:272] - INFO: epoch 002:    527 / 2637 loss=2.345, loss_v1=0, loss_v2=0, nll_loss=1.145, ntokens=1240.4, nsentences=160, sample_size=1240.4, sample_size_v1=0, sample_size_v2=0, ppl=2.21, wps=594.7, ups=0.48, wpb=1240.4, bsz=160, num_updates=3160, lr=2.95242e-05, gnorm=4.408, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=6605
2023-06-27 04:03:46 - progress_bar.py[line:272] - INFO: epoch 002:    537 / 2637 loss=2.407, loss_v1=0, loss_v2=0, nll_loss=1.216, ntokens=1261.8, nsentences=160, sample_size=1261.8, sample_size_v1=0, sample_size_v2=0, ppl=2.32, wps=605.1, ups=0.48, wpb=1261.8, bsz=160, num_updates=3170, lr=2.95167e-05, gnorm=4.317, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=6626
2023-06-27 04:04:07 - progress_bar.py[line:272] - INFO: epoch 002:    547 / 2637 loss=2.378, loss_v1=0, loss_v2=0, nll_loss=1.179, ntokens=1263.9, nsentences=160, sample_size=1263.9, sample_size_v1=0, sample_size_v2=0, ppl=2.26, wps=605.1, ups=0.48, wpb=1263.9, bsz=160, num_updates=3180, lr=2.95091e-05, gnorm=4.388, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=6647
2023-06-27 04:04:27 - progress_bar.py[line:272] - INFO: epoch 002:    557 / 2637 loss=2.397, loss_v1=0, loss_v2=0, nll_loss=1.202, ntokens=1255.3, nsentences=160, sample_size=1255.3, sample_size_v1=0, sample_size_v2=0, ppl=2.3, wps=601.8, ups=0.48, wpb=1255.3, bsz=160, num_updates=3190, lr=2.95015e-05, gnorm=4.512, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=6668
2023-06-27 04:04:48 - progress_bar.py[line:272] - INFO: epoch 002:    567 / 2637 loss=2.411, loss_v1=0, loss_v2=0, nll_loss=1.221, ntokens=1254.3, nsentences=160, sample_size=1254.3, sample_size_v1=0, sample_size_v2=0, ppl=2.33, wps=600.9, ups=0.48, wpb=1254.3, bsz=160, num_updates=3200, lr=2.9494e-05, gnorm=3.746, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=6689
2023-06-27 04:05:09 - progress_bar.py[line:272] - INFO: epoch 002:    577 / 2637 loss=2.397, loss_v1=0, loss_v2=0, nll_loss=1.199, ntokens=1258.5, nsentences=160, sample_size=1258.5, sample_size_v1=0, sample_size_v2=0, ppl=2.3, wps=603.6, ups=0.48, wpb=1258.5, bsz=160, num_updates=3210, lr=2.94864e-05, gnorm=4.805, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=6709
2023-06-27 04:05:30 - progress_bar.py[line:272] - INFO: epoch 002:    587 / 2637 loss=2.408, loss_v1=0, loss_v2=0, nll_loss=1.216, ntokens=1247.7, nsentences=160, sample_size=1247.7, sample_size_v1=0, sample_size_v2=0, ppl=2.32, wps=598.3, ups=0.48, wpb=1247.7, bsz=160, num_updates=3220, lr=2.94788e-05, gnorm=4.204, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=6730
2023-06-27 04:05:51 - progress_bar.py[line:272] - INFO: epoch 002:    597 / 2637 loss=2.388, loss_v1=0, loss_v2=0, nll_loss=1.196, ntokens=1262.9, nsentences=160, sample_size=1262.9, sample_size_v1=0, sample_size_v2=0, ppl=2.29, wps=605.4, ups=0.48, wpb=1262.9, bsz=160, num_updates=3230, lr=2.94713e-05, gnorm=3.905, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=6751
2023-06-27 04:06:12 - progress_bar.py[line:272] - INFO: epoch 002:    607 / 2637 loss=2.392, loss_v1=0, loss_v2=0, nll_loss=1.195, ntokens=1259.7, nsentences=160, sample_size=1259.7, sample_size_v1=0, sample_size_v2=0, ppl=2.29, wps=604.5, ups=0.48, wpb=1259.7, bsz=160, num_updates=3240, lr=2.94637e-05, gnorm=4.206, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=6772
2023-06-27 04:06:33 - progress_bar.py[line:272] - INFO: epoch 002:    617 / 2637 loss=2.388, loss_v1=0, loss_v2=0, nll_loss=1.192, ntokens=1271.4, nsentences=160, sample_size=1271.4, sample_size_v1=0, sample_size_v2=0, ppl=2.28, wps=609.9, ups=0.48, wpb=1271.4, bsz=160, num_updates=3250, lr=2.94561e-05, gnorm=3.984, clip=100, loss_scale=128, train_wall=21, gb_free=8.9, wall=6793
2023-06-27 04:06:53 - progress_bar.py[line:272] - INFO: epoch 002:    627 / 2637 loss=2.383, loss_v1=0, loss_v2=0, nll_loss=1.189, ntokens=1235.6, nsentences=160, sample_size=1235.6, sample_size_v1=0, sample_size_v2=0, ppl=2.28, wps=591.9, ups=0.48, wpb=1235.6, bsz=160, num_updates=3260, lr=2.94486e-05, gnorm=4.133, clip=100, loss_scale=128, train_wall=21, gb_free=8.9, wall=6814
2023-06-27 04:07:14 - progress_bar.py[line:272] - INFO: epoch 002:    637 / 2637 loss=2.376, loss_v1=0, loss_v2=0, nll_loss=1.177, ntokens=1267.1, nsentences=160, sample_size=1267.1, sample_size_v1=0, sample_size_v2=0, ppl=2.26, wps=607.3, ups=0.48, wpb=1267.1, bsz=160, num_updates=3270, lr=2.9441e-05, gnorm=4.473, clip=100, loss_scale=128, train_wall=21, gb_free=8.9, wall=6835
2023-06-27 04:07:35 - progress_bar.py[line:272] - INFO: epoch 002:    647 / 2637 loss=2.369, loss_v1=0, loss_v2=0, nll_loss=1.174, ntokens=1244.2, nsentences=160, sample_size=1244.2, sample_size_v1=0, sample_size_v2=0, ppl=2.26, wps=597, ups=0.48, wpb=1244.2, bsz=160, num_updates=3280, lr=2.94334e-05, gnorm=4.512, clip=100, loss_scale=128, train_wall=21, gb_free=8.9, wall=6855
2023-06-27 04:07:56 - progress_bar.py[line:272] - INFO: epoch 002:    657 / 2637 loss=2.407, loss_v1=0, loss_v2=0, nll_loss=1.215, ntokens=1245.6, nsentences=160, sample_size=1245.6, sample_size_v1=0, sample_size_v2=0, ppl=2.32, wps=596.9, ups=0.48, wpb=1245.6, bsz=160, num_updates=3290, lr=2.94259e-05, gnorm=3.66, clip=100, loss_scale=128, train_wall=21, gb_free=8.9, wall=6876
2023-06-27 04:08:17 - progress_bar.py[line:272] - INFO: epoch 002:    667 / 2637 loss=2.394, loss_v1=0, loss_v2=0, nll_loss=1.198, ntokens=1261.1, nsentences=160, sample_size=1261.1, sample_size_v1=0, sample_size_v2=0, ppl=2.29, wps=604.9, ups=0.48, wpb=1261.1, bsz=160, num_updates=3300, lr=2.94183e-05, gnorm=4.095, clip=100, loss_scale=128, train_wall=21, gb_free=8.9, wall=6897
2023-06-27 04:08:38 - progress_bar.py[line:272] - INFO: epoch 002:    677 / 2637 loss=2.382, loss_v1=0, loss_v2=0, nll_loss=1.186, ntokens=1260.4, nsentences=160, sample_size=1260.4, sample_size_v1=0, sample_size_v2=0, ppl=2.28, wps=603.6, ups=0.48, wpb=1260.4, bsz=160, num_updates=3310, lr=2.94108e-05, gnorm=4.044, clip=100, loss_scale=128, train_wall=21, gb_free=8.9, wall=6918
2023-06-27 04:08:59 - progress_bar.py[line:272] - INFO: epoch 002:    687 / 2637 loss=2.393, loss_v1=0, loss_v2=0, nll_loss=1.196, ntokens=1293.3, nsentences=160, sample_size=1293.3, sample_size_v1=0, sample_size_v2=0, ppl=2.29, wps=619.4, ups=0.48, wpb=1293.3, bsz=160, num_updates=3320, lr=2.94032e-05, gnorm=4.024, clip=100, loss_scale=128, train_wall=21, gb_free=8.9, wall=6939
2023-06-27 04:09:19 - progress_bar.py[line:272] - INFO: epoch 002:    697 / 2637 loss=2.411, loss_v1=0, loss_v2=0, nll_loss=1.218, ntokens=1244, nsentences=160, sample_size=1244, sample_size_v1=0, sample_size_v2=0, ppl=2.33, wps=596, ups=0.48, wpb=1244, bsz=160, num_updates=3330, lr=2.93956e-05, gnorm=3.993, clip=100, loss_scale=128, train_wall=21, gb_free=8.9, wall=6960
2023-06-27 04:09:40 - progress_bar.py[line:272] - INFO: epoch 002:    707 / 2637 loss=2.393, loss_v1=0, loss_v2=0, nll_loss=1.199, ntokens=1268.9, nsentences=160, sample_size=1268.9, sample_size_v1=0, sample_size_v2=0, ppl=2.3, wps=608.7, ups=0.48, wpb=1268.9, bsz=160, num_updates=3340, lr=2.93881e-05, gnorm=3.472, clip=100, loss_scale=128, train_wall=21, gb_free=8.9, wall=6981
2023-06-27 04:10:01 - progress_bar.py[line:272] - INFO: epoch 002:    717 / 2637 loss=2.4, loss_v1=0, loss_v2=0, nll_loss=1.204, ntokens=1256.1, nsentences=160, sample_size=1256.1, sample_size_v1=0, sample_size_v2=0, ppl=2.3, wps=602.7, ups=0.48, wpb=1256.1, bsz=160, num_updates=3350, lr=2.93805e-05, gnorm=3.088, clip=100, loss_scale=128, train_wall=21, gb_free=8.9, wall=7001
2023-06-27 04:10:22 - progress_bar.py[line:272] - INFO: epoch 002:    727 / 2637 loss=2.407, loss_v1=0, loss_v2=0, nll_loss=1.214, ntokens=1262.3, nsentences=160, sample_size=1262.3, sample_size_v1=0, sample_size_v2=0, ppl=2.32, wps=605.3, ups=0.48, wpb=1262.3, bsz=160, num_updates=3360, lr=2.93729e-05, gnorm=3.484, clip=100, loss_scale=128, train_wall=21, gb_free=8.9, wall=7022
2023-06-27 04:10:39 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2023-06-27 04:10:45 - progress_bar.py[line:272] - INFO: epoch 002:    738 / 2637 loss=2.39, loss_v1=0, loss_v2=0, nll_loss=1.195, ntokens=1255.7, nsentences=160, sample_size=1255.7, sample_size_v1=0, sample_size_v2=0, ppl=2.29, wps=547.7, ups=0.44, wpb=1255.7, bsz=160, num_updates=3370, lr=2.93654e-05, gnorm=3.433, clip=100, loss_scale=64, train_wall=23, gb_free=8.9, wall=7045
2023-06-27 04:11:06 - progress_bar.py[line:272] - INFO: epoch 002:    748 / 2637 loss=2.409, loss_v1=0, loss_v2=0, nll_loss=1.22, ntokens=1269.4, nsentences=160, sample_size=1269.4, sample_size_v1=0, sample_size_v2=0, ppl=2.33, wps=609.1, ups=0.48, wpb=1269.4, bsz=160, num_updates=3380, lr=2.93578e-05, gnorm=3.465, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=7066
2023-06-27 04:11:27 - progress_bar.py[line:272] - INFO: epoch 002:    758 / 2637 loss=2.384, loss_v1=0, loss_v2=0, nll_loss=1.186, ntokens=1264.7, nsentences=160, sample_size=1264.7, sample_size_v1=0, sample_size_v2=0, ppl=2.27, wps=607.1, ups=0.48, wpb=1264.7, bsz=160, num_updates=3390, lr=2.93502e-05, gnorm=3.502, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=7087
2023-06-27 04:11:47 - progress_bar.py[line:272] - INFO: epoch 002:    768 / 2637 loss=2.388, loss_v1=0, loss_v2=0, nll_loss=1.194, ntokens=1252.8, nsentences=160, sample_size=1252.8, sample_size_v1=0, sample_size_v2=0, ppl=2.29, wps=601.7, ups=0.48, wpb=1252.8, bsz=160, num_updates=3400, lr=2.93427e-05, gnorm=3.563, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=7108
2023-06-27 04:12:08 - progress_bar.py[line:272] - INFO: epoch 002:    778 / 2637 loss=2.385, loss_v1=0, loss_v2=0, nll_loss=1.186, ntokens=1257.7, nsentences=160, sample_size=1257.7, sample_size_v1=0, sample_size_v2=0, ppl=2.28, wps=604.2, ups=0.48, wpb=1257.7, bsz=160, num_updates=3410, lr=2.93351e-05, gnorm=3.551, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=7129
2023-06-27 04:12:29 - progress_bar.py[line:272] - INFO: epoch 002:    788 / 2637 loss=2.376, loss_v1=0, loss_v2=0, nll_loss=1.182, ntokens=1258.9, nsentences=160, sample_size=1258.9, sample_size_v1=0, sample_size_v2=0, ppl=2.27, wps=603.6, ups=0.48, wpb=1258.9, bsz=160, num_updates=3420, lr=2.93276e-05, gnorm=3.887, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=7149
2023-06-27 04:12:50 - progress_bar.py[line:272] - INFO: epoch 002:    798 / 2637 loss=2.395, loss_v1=0, loss_v2=0, nll_loss=1.197, ntokens=1256.7, nsentences=160, sample_size=1256.7, sample_size_v1=0, sample_size_v2=0, ppl=2.29, wps=602.4, ups=0.48, wpb=1256.7, bsz=160, num_updates=3430, lr=2.932e-05, gnorm=3.716, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=7170
2023-06-27 04:13:11 - progress_bar.py[line:272] - INFO: epoch 002:    808 / 2637 loss=2.362, loss_v1=0, loss_v2=0, nll_loss=1.165, ntokens=1243.4, nsentences=160, sample_size=1243.4, sample_size_v1=0, sample_size_v2=0, ppl=2.24, wps=596.3, ups=0.48, wpb=1243.4, bsz=160, num_updates=3440, lr=2.93124e-05, gnorm=4.185, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=7191
2023-06-27 04:13:32 - progress_bar.py[line:272] - INFO: epoch 002:    818 / 2637 loss=2.371, loss_v1=0, loss_v2=0, nll_loss=1.172, ntokens=1267.1, nsentences=160, sample_size=1267.1, sample_size_v1=0, sample_size_v2=0, ppl=2.25, wps=608.2, ups=0.48, wpb=1267.1, bsz=160, num_updates=3450, lr=2.93049e-05, gnorm=5.012, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=7212
2023-06-27 04:13:53 - progress_bar.py[line:272] - INFO: epoch 002:    828 / 2637 loss=2.421, loss_v1=0, loss_v2=0, nll_loss=1.23, ntokens=1251, nsentences=160, sample_size=1251, sample_size_v1=0, sample_size_v2=0, ppl=2.35, wps=600.8, ups=0.48, wpb=1251, bsz=160, num_updates=3460, lr=2.92973e-05, gnorm=4.793, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=7233
2023-06-27 04:14:13 - progress_bar.py[line:272] - INFO: epoch 002:    838 / 2637 loss=2.374, loss_v1=0, loss_v2=0, nll_loss=1.176, ntokens=1267.4, nsentences=160, sample_size=1267.4, sample_size_v1=0, sample_size_v2=0, ppl=2.26, wps=608.7, ups=0.48, wpb=1267.4, bsz=160, num_updates=3470, lr=2.92897e-05, gnorm=3.885, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=7254
2023-06-27 04:14:34 - progress_bar.py[line:272] - INFO: epoch 002:    848 / 2637 loss=2.387, loss_v1=0, loss_v2=0, nll_loss=1.192, ntokens=1256.7, nsentences=160, sample_size=1256.7, sample_size_v1=0, sample_size_v2=0, ppl=2.29, wps=603.6, ups=0.48, wpb=1256.7, bsz=160, num_updates=3480, lr=2.92822e-05, gnorm=4.226, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=7274
2023-06-27 04:14:55 - progress_bar.py[line:272] - INFO: epoch 002:    858 / 2637 loss=2.388, loss_v1=0, loss_v2=0, nll_loss=1.193, ntokens=1236.8, nsentences=160, sample_size=1236.8, sample_size_v1=0, sample_size_v2=0, ppl=2.29, wps=594.2, ups=0.48, wpb=1236.8, bsz=160, num_updates=3490, lr=2.92746e-05, gnorm=3.811, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=7295
2023-06-27 04:15:16 - progress_bar.py[line:272] - INFO: epoch 002:    868 / 2637 loss=2.39, loss_v1=0, loss_v2=0, nll_loss=1.194, ntokens=1230.8, nsentences=160, sample_size=1230.8, sample_size_v1=0, sample_size_v2=0, ppl=2.29, wps=591.5, ups=0.48, wpb=1230.8, bsz=160, num_updates=3500, lr=2.9267e-05, gnorm=3.88, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=7316
2023-06-27 04:15:37 - progress_bar.py[line:272] - INFO: epoch 002:    878 / 2637 loss=2.378, loss_v1=0, loss_v2=0, nll_loss=1.178, ntokens=1263.6, nsentences=160, sample_size=1263.6, sample_size_v1=0, sample_size_v2=0, ppl=2.26, wps=606.9, ups=0.48, wpb=1263.6, bsz=160, num_updates=3510, lr=2.92595e-05, gnorm=4.131, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=7337
2023-06-27 04:15:57 - progress_bar.py[line:272] - INFO: epoch 002:    888 / 2637 loss=2.375, loss_v1=0, loss_v2=0, nll_loss=1.18, ntokens=1251.1, nsentences=160, sample_size=1251.1, sample_size_v1=0, sample_size_v2=0, ppl=2.27, wps=600.7, ups=0.48, wpb=1251.1, bsz=160, num_updates=3520, lr=2.92519e-05, gnorm=4.525, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=7358
2023-06-27 04:16:18 - progress_bar.py[line:272] - INFO: epoch 002:    898 / 2637 loss=2.361, loss_v1=0, loss_v2=0, nll_loss=1.164, ntokens=1258.7, nsentences=160, sample_size=1258.7, sample_size_v1=0, sample_size_v2=0, ppl=2.24, wps=603.1, ups=0.48, wpb=1258.7, bsz=160, num_updates=3530, lr=2.92443e-05, gnorm=4.515, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=7379
2023-06-27 04:16:39 - progress_bar.py[line:272] - INFO: epoch 002:    908 / 2637 loss=2.37, loss_v1=0, loss_v2=0, nll_loss=1.172, ntokens=1246.2, nsentences=160, sample_size=1246.2, sample_size_v1=0, sample_size_v2=0, ppl=2.25, wps=597.5, ups=0.48, wpb=1246.2, bsz=160, num_updates=3540, lr=2.92368e-05, gnorm=4.352, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=7399
2023-06-27 04:17:00 - progress_bar.py[line:272] - INFO: epoch 002:    918 / 2637 loss=2.373, loss_v1=0, loss_v2=0, nll_loss=1.176, ntokens=1252.7, nsentences=160, sample_size=1252.7, sample_size_v1=0, sample_size_v2=0, ppl=2.26, wps=600.8, ups=0.48, wpb=1252.7, bsz=160, num_updates=3550, lr=2.92292e-05, gnorm=4.69, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=7420
2023-06-27 04:17:21 - progress_bar.py[line:272] - INFO: epoch 002:    928 / 2637 loss=2.391, loss_v1=0, loss_v2=0, nll_loss=1.193, ntokens=1257.3, nsentences=160, sample_size=1257.3, sample_size_v1=0, sample_size_v2=0, ppl=2.29, wps=603.9, ups=0.48, wpb=1257.3, bsz=160, num_updates=3560, lr=2.92217e-05, gnorm=4.055, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=7441
2023-06-27 04:17:42 - progress_bar.py[line:272] - INFO: epoch 002:    938 / 2637 loss=2.372, loss_v1=0, loss_v2=0, nll_loss=1.176, ntokens=1259.9, nsentences=160, sample_size=1259.9, sample_size_v1=0, sample_size_v2=0, ppl=2.26, wps=604.4, ups=0.48, wpb=1259.9, bsz=160, num_updates=3570, lr=2.92141e-05, gnorm=4.412, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=7462
2023-06-27 04:18:03 - progress_bar.py[line:272] - INFO: epoch 002:    948 / 2637 loss=2.391, loss_v1=0, loss_v2=0, nll_loss=1.192, ntokens=1240.8, nsentences=160, sample_size=1240.8, sample_size_v1=0, sample_size_v2=0, ppl=2.29, wps=594.9, ups=0.48, wpb=1240.8, bsz=160, num_updates=3580, lr=2.92065e-05, gnorm=4.133, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=7483
2023-06-27 04:18:23 - progress_bar.py[line:272] - INFO: epoch 002:    958 / 2637 loss=2.403, loss_v1=0, loss_v2=0, nll_loss=1.211, ntokens=1250.5, nsentences=160, sample_size=1250.5, sample_size_v1=0, sample_size_v2=0, ppl=2.31, wps=600.6, ups=0.48, wpb=1250.5, bsz=160, num_updates=3590, lr=2.9199e-05, gnorm=4.986, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=7504
2023-06-27 04:18:44 - progress_bar.py[line:272] - INFO: epoch 002:    968 / 2637 loss=2.362, loss_v1=0, loss_v2=0, nll_loss=1.164, ntokens=1237.8, nsentences=160, sample_size=1237.8, sample_size_v1=0, sample_size_v2=0, ppl=2.24, wps=594.8, ups=0.48, wpb=1237.8, bsz=160, num_updates=3600, lr=2.91914e-05, gnorm=4.436, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=7525
2023-06-27 04:19:05 - progress_bar.py[line:272] - INFO: epoch 002:    978 / 2637 loss=2.372, loss_v1=0, loss_v2=0, nll_loss=1.176, ntokens=1251.6, nsentences=160, sample_size=1251.6, sample_size_v1=0, sample_size_v2=0, ppl=2.26, wps=601.1, ups=0.48, wpb=1251.6, bsz=160, num_updates=3610, lr=2.91838e-05, gnorm=4.782, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=7545
2023-06-27 04:19:26 - progress_bar.py[line:272] - INFO: epoch 002:    988 / 2637 loss=2.378, loss_v1=0, loss_v2=0, nll_loss=1.18, ntokens=1238.1, nsentences=160, sample_size=1238.1, sample_size_v1=0, sample_size_v2=0, ppl=2.27, wps=594.1, ups=0.48, wpb=1238.1, bsz=160, num_updates=3620, lr=2.91763e-05, gnorm=4.166, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=7566
2023-06-27 04:19:47 - progress_bar.py[line:272] - INFO: epoch 002:    998 / 2637 loss=2.377, loss_v1=0, loss_v2=0, nll_loss=1.181, ntokens=1254.3, nsentences=160, sample_size=1254.3, sample_size_v1=0, sample_size_v2=0, ppl=2.27, wps=602.3, ups=0.48, wpb=1254.3, bsz=160, num_updates=3630, lr=2.91687e-05, gnorm=4.44, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=7587
2023-06-27 04:20:08 - progress_bar.py[line:272] - INFO: epoch 002:   1008 / 2637 loss=2.366, loss_v1=0, loss_v2=0, nll_loss=1.168, ntokens=1241.6, nsentences=160, sample_size=1241.6, sample_size_v1=0, sample_size_v2=0, ppl=2.25, wps=596.4, ups=0.48, wpb=1241.6, bsz=160, num_updates=3640, lr=2.91611e-05, gnorm=4.015, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=7608
2023-06-27 04:20:28 - progress_bar.py[line:272] - INFO: epoch 002:   1018 / 2637 loss=2.392, loss_v1=0, loss_v2=0, nll_loss=1.194, ntokens=1238.8, nsentences=160, sample_size=1238.8, sample_size_v1=0, sample_size_v2=0, ppl=2.29, wps=594.8, ups=0.48, wpb=1238.8, bsz=160, num_updates=3650, lr=2.91536e-05, gnorm=4.44, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=7629
2023-06-27 04:20:49 - progress_bar.py[line:272] - INFO: epoch 002:   1028 / 2637 loss=2.388, loss_v1=0, loss_v2=0, nll_loss=1.191, ntokens=1258.7, nsentences=160, sample_size=1258.7, sample_size_v1=0, sample_size_v2=0, ppl=2.28, wps=603.8, ups=0.48, wpb=1258.7, bsz=160, num_updates=3660, lr=2.9146e-05, gnorm=4.415, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=7650
2023-06-27 04:21:10 - progress_bar.py[line:272] - INFO: epoch 002:   1038 / 2637 loss=2.372, loss_v1=0, loss_v2=0, nll_loss=1.177, ntokens=1243.1, nsentences=160, sample_size=1243.1, sample_size_v1=0, sample_size_v2=0, ppl=2.26, wps=596.1, ups=0.48, wpb=1243.1, bsz=160, num_updates=3670, lr=2.91384e-05, gnorm=4.607, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=7670
2023-06-27 04:21:31 - progress_bar.py[line:272] - INFO: epoch 002:   1048 / 2637 loss=2.368, loss_v1=0, loss_v2=0, nll_loss=1.169, ntokens=1259.7, nsentences=160, sample_size=1259.7, sample_size_v1=0, sample_size_v2=0, ppl=2.25, wps=603.8, ups=0.48, wpb=1259.7, bsz=160, num_updates=3680, lr=2.91309e-05, gnorm=4.331, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=7691
2023-06-27 04:21:52 - progress_bar.py[line:272] - INFO: epoch 002:   1058 / 2637 loss=2.382, loss_v1=0, loss_v2=0, nll_loss=1.186, ntokens=1245.4, nsentences=160, sample_size=1245.4, sample_size_v1=0, sample_size_v2=0, ppl=2.28, wps=598, ups=0.48, wpb=1245.4, bsz=160, num_updates=3690, lr=2.91233e-05, gnorm=4.054, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=7712
2023-06-27 04:22:13 - progress_bar.py[line:272] - INFO: epoch 002:   1068 / 2637 loss=2.373, loss_v1=0, loss_v2=0, nll_loss=1.175, ntokens=1232.3, nsentences=160, sample_size=1232.3, sample_size_v1=0, sample_size_v2=0, ppl=2.26, wps=592.4, ups=0.48, wpb=1232.3, bsz=160, num_updates=3700, lr=2.91158e-05, gnorm=3.413, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=7733
2023-06-27 04:22:33 - progress_bar.py[line:272] - INFO: epoch 002:   1078 / 2637 loss=2.351, loss_v1=0, loss_v2=0, nll_loss=1.15, ntokens=1238.8, nsentences=160, sample_size=1238.8, sample_size_v1=0, sample_size_v2=0, ppl=2.22, wps=595.2, ups=0.48, wpb=1238.8, bsz=160, num_updates=3710, lr=2.91082e-05, gnorm=3.776, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=7754
2023-06-27 04:22:54 - progress_bar.py[line:272] - INFO: epoch 002:   1088 / 2637 loss=2.368, loss_v1=0, loss_v2=0, nll_loss=1.171, ntokens=1267.3, nsentences=160, sample_size=1267.3, sample_size_v1=0, sample_size_v2=0, ppl=2.25, wps=606.6, ups=0.48, wpb=1267.3, bsz=160, num_updates=3720, lr=2.91006e-05, gnorm=3.468, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=7775
2023-06-27 04:23:15 - progress_bar.py[line:272] - INFO: epoch 002:   1098 / 2637 loss=2.371, loss_v1=0, loss_v2=0, nll_loss=1.174, ntokens=1235.1, nsentences=160, sample_size=1235.1, sample_size_v1=0, sample_size_v2=0, ppl=2.26, wps=592.3, ups=0.48, wpb=1235.1, bsz=160, num_updates=3730, lr=2.90931e-05, gnorm=3.665, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=7795
2023-06-27 04:23:36 - progress_bar.py[line:272] - INFO: epoch 002:   1108 / 2637 loss=2.377, loss_v1=0, loss_v2=0, nll_loss=1.18, ntokens=1229.9, nsentences=160, sample_size=1229.9, sample_size_v1=0, sample_size_v2=0, ppl=2.27, wps=589.9, ups=0.48, wpb=1229.9, bsz=160, num_updates=3740, lr=2.90855e-05, gnorm=4.073, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=7816
2023-06-27 04:23:57 - progress_bar.py[line:272] - INFO: epoch 002:   1118 / 2637 loss=2.369, loss_v1=0, loss_v2=0, nll_loss=1.171, ntokens=1245.9, nsentences=160, sample_size=1245.9, sample_size_v1=0, sample_size_v2=0, ppl=2.25, wps=597.3, ups=0.48, wpb=1245.9, bsz=160, num_updates=3750, lr=2.90779e-05, gnorm=4.033, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=7837
2023-06-27 04:24:18 - progress_bar.py[line:272] - INFO: epoch 002:   1128 / 2637 loss=2.374, loss_v1=0, loss_v2=0, nll_loss=1.175, ntokens=1236, nsentences=160, sample_size=1236, sample_size_v1=0, sample_size_v2=0, ppl=2.26, wps=592.6, ups=0.48, wpb=1236, bsz=160, num_updates=3760, lr=2.90704e-05, gnorm=3.611, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=7858
2023-06-27 04:24:39 - progress_bar.py[line:272] - INFO: epoch 002:   1138 / 2637 loss=2.378, loss_v1=0, loss_v2=0, nll_loss=1.183, ntokens=1257.2, nsentences=160, sample_size=1257.2, sample_size_v1=0, sample_size_v2=0, ppl=2.27, wps=603.1, ups=0.48, wpb=1257.2, bsz=160, num_updates=3770, lr=2.90628e-05, gnorm=4.317, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=7879
2023-06-27 04:24:59 - progress_bar.py[line:272] - INFO: epoch 002:   1148 / 2637 loss=2.363, loss_v1=0, loss_v2=0, nll_loss=1.165, ntokens=1270.1, nsentences=160, sample_size=1270.1, sample_size_v1=0, sample_size_v2=0, ppl=2.24, wps=608.5, ups=0.48, wpb=1270.1, bsz=160, num_updates=3780, lr=2.90552e-05, gnorm=4.905, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=7900
2023-06-27 04:25:20 - progress_bar.py[line:272] - INFO: epoch 002:   1158 / 2637 loss=2.391, loss_v1=0, loss_v2=0, nll_loss=1.196, ntokens=1235.5, nsentences=160, sample_size=1235.5, sample_size_v1=0, sample_size_v2=0, ppl=2.29, wps=593.9, ups=0.48, wpb=1235.5, bsz=160, num_updates=3790, lr=2.90477e-05, gnorm=3.928, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=7921
2023-06-27 04:25:41 - progress_bar.py[line:272] - INFO: epoch 002:   1168 / 2637 loss=2.364, loss_v1=0, loss_v2=0, nll_loss=1.166, ntokens=1246.6, nsentences=160, sample_size=1246.6, sample_size_v1=0, sample_size_v2=0, ppl=2.24, wps=599, ups=0.48, wpb=1246.6, bsz=160, num_updates=3800, lr=2.90401e-05, gnorm=4.562, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=7941
2023-06-27 04:26:02 - progress_bar.py[line:272] - INFO: epoch 002:   1178 / 2637 loss=2.375, loss_v1=0, loss_v2=0, nll_loss=1.179, ntokens=1247, nsentences=160, sample_size=1247, sample_size_v1=0, sample_size_v2=0, ppl=2.26, wps=597.9, ups=0.48, wpb=1247, bsz=160, num_updates=3810, lr=2.90326e-05, gnorm=4.799, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=7962
2023-06-27 04:26:23 - progress_bar.py[line:272] - INFO: epoch 002:   1188 / 2637 loss=2.369, loss_v1=0, loss_v2=0, nll_loss=1.172, ntokens=1255.4, nsentences=160, sample_size=1255.4, sample_size_v1=0, sample_size_v2=0, ppl=2.25, wps=602.3, ups=0.48, wpb=1255.4, bsz=160, num_updates=3820, lr=2.9025e-05, gnorm=4.165, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=7983
2023-06-27 04:26:44 - progress_bar.py[line:272] - INFO: epoch 002:   1198 / 2637 loss=2.388, loss_v1=0, loss_v2=0, nll_loss=1.19, ntokens=1258.7, nsentences=160, sample_size=1258.7, sample_size_v1=0, sample_size_v2=0, ppl=2.28, wps=603.9, ups=0.48, wpb=1258.7, bsz=160, num_updates=3830, lr=2.90174e-05, gnorm=4.484, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=8004
2023-06-27 04:27:04 - progress_bar.py[line:272] - INFO: epoch 002:   1208 / 2637 loss=2.371, loss_v1=0, loss_v2=0, nll_loss=1.175, ntokens=1250.1, nsentences=160, sample_size=1250.1, sample_size_v1=0, sample_size_v2=0, ppl=2.26, wps=600.6, ups=0.48, wpb=1250.1, bsz=160, num_updates=3840, lr=2.90099e-05, gnorm=4.081, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=8025
2023-06-27 04:27:25 - progress_bar.py[line:272] - INFO: epoch 002:   1218 / 2637 loss=2.368, loss_v1=0, loss_v2=0, nll_loss=1.171, ntokens=1264.2, nsentences=160, sample_size=1264.2, sample_size_v1=0, sample_size_v2=0, ppl=2.25, wps=607.1, ups=0.48, wpb=1264.2, bsz=160, num_updates=3850, lr=2.90023e-05, gnorm=3.874, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=8046
2023-06-27 04:27:46 - progress_bar.py[line:272] - INFO: epoch 002:   1228 / 2637 loss=2.383, loss_v1=0, loss_v2=0, nll_loss=1.183, ntokens=1237.1, nsentences=160, sample_size=1237.1, sample_size_v1=0, sample_size_v2=0, ppl=2.27, wps=594.8, ups=0.48, wpb=1237.1, bsz=160, num_updates=3860, lr=2.89947e-05, gnorm=3.68, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=8066
2023-06-27 04:28:07 - progress_bar.py[line:272] - INFO: epoch 002:   1238 / 2637 loss=2.37, loss_v1=0, loss_v2=0, nll_loss=1.174, ntokens=1231, nsentences=160, sample_size=1231, sample_size_v1=0, sample_size_v2=0, ppl=2.26, wps=592, ups=0.48, wpb=1231, bsz=160, num_updates=3870, lr=2.89872e-05, gnorm=3.603, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=8087
2023-06-27 04:28:28 - progress_bar.py[line:272] - INFO: epoch 002:   1248 / 2637 loss=2.359, loss_v1=0, loss_v2=0, nll_loss=1.158, ntokens=1234.6, nsentences=160, sample_size=1234.6, sample_size_v1=0, sample_size_v2=0, ppl=2.23, wps=592.8, ups=0.48, wpb=1234.6, bsz=160, num_updates=3880, lr=2.89796e-05, gnorm=3.825, clip=100, loss_scale=128, train_wall=21, gb_free=8.9, wall=8108
2023-06-27 04:28:49 - progress_bar.py[line:272] - INFO: epoch 002:   1258 / 2637 loss=2.393, loss_v1=0, loss_v2=0, nll_loss=1.2, ntokens=1240.5, nsentences=160, sample_size=1240.5, sample_size_v1=0, sample_size_v2=0, ppl=2.3, wps=595.8, ups=0.48, wpb=1240.5, bsz=160, num_updates=3890, lr=2.8972e-05, gnorm=4.48, clip=100, loss_scale=128, train_wall=21, gb_free=8.9, wall=8129
2023-06-27 04:29:09 - progress_bar.py[line:272] - INFO: epoch 002:   1268 / 2637 loss=2.364, loss_v1=0, loss_v2=0, nll_loss=1.163, ntokens=1256.1, nsentences=160, sample_size=1256.1, sample_size_v1=0, sample_size_v2=0, ppl=2.24, wps=602.8, ups=0.48, wpb=1256.1, bsz=160, num_updates=3900, lr=2.89645e-05, gnorm=3.481, clip=100, loss_scale=128, train_wall=21, gb_free=8.9, wall=8150
2023-06-27 04:29:30 - progress_bar.py[line:272] - INFO: epoch 002:   1278 / 2637 loss=2.397, loss_v1=0, loss_v2=0, nll_loss=1.202, ntokens=1242.9, nsentences=160, sample_size=1242.9, sample_size_v1=0, sample_size_v2=0, ppl=2.3, wps=596, ups=0.48, wpb=1242.9, bsz=160, num_updates=3910, lr=2.89569e-05, gnorm=3.547, clip=100, loss_scale=128, train_wall=21, gb_free=8.9, wall=8171
2023-06-27 04:29:51 - progress_bar.py[line:272] - INFO: epoch 002:   1288 / 2637 loss=2.385, loss_v1=0, loss_v2=0, nll_loss=1.191, ntokens=1251.9, nsentences=160, sample_size=1251.9, sample_size_v1=0, sample_size_v2=0, ppl=2.28, wps=600.6, ups=0.48, wpb=1251.9, bsz=160, num_updates=3920, lr=2.89493e-05, gnorm=4.203, clip=100, loss_scale=128, train_wall=21, gb_free=8.9, wall=8191
2023-06-27 04:30:12 - progress_bar.py[line:272] - INFO: epoch 002:   1298 / 2637 loss=2.37, loss_v1=0, loss_v2=0, nll_loss=1.171, ntokens=1234.9, nsentences=160, sample_size=1234.9, sample_size_v1=0, sample_size_v2=0, ppl=2.25, wps=592.3, ups=0.48, wpb=1234.9, bsz=160, num_updates=3930, lr=2.89418e-05, gnorm=4.066, clip=100, loss_scale=128, train_wall=21, gb_free=8.9, wall=8212
2023-06-27 04:30:33 - progress_bar.py[line:272] - INFO: epoch 002:   1308 / 2637 loss=2.367, loss_v1=0, loss_v2=0, nll_loss=1.172, ntokens=1251.8, nsentences=160, sample_size=1251.8, sample_size_v1=0, sample_size_v2=0, ppl=2.25, wps=600.5, ups=0.48, wpb=1251.8, bsz=160, num_updates=3940, lr=2.89342e-05, gnorm=3.856, clip=100, loss_scale=128, train_wall=21, gb_free=8.9, wall=8233
2023-06-27 04:30:54 - progress_bar.py[line:272] - INFO: epoch 002:   1318 / 2637 loss=2.375, loss_v1=0, loss_v2=0, nll_loss=1.176, ntokens=1241.4, nsentences=160, sample_size=1241.4, sample_size_v1=0, sample_size_v2=0, ppl=2.26, wps=596.3, ups=0.48, wpb=1241.4, bsz=160, num_updates=3950, lr=2.89267e-05, gnorm=4.214, clip=100, loss_scale=128, train_wall=21, gb_free=8.9, wall=8254
2023-06-27 04:31:10 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2023-06-27 04:31:16 - progress_bar.py[line:272] - INFO: epoch 002:   1329 / 2637 loss=2.363, loss_v1=0, loss_v2=0, nll_loss=1.167, ntokens=1222.5, nsentences=160, sample_size=1222.5, sample_size_v1=0, sample_size_v2=0, ppl=2.25, wps=534.8, ups=0.44, wpb=1222.5, bsz=160, num_updates=3960, lr=2.89191e-05, gnorm=4.538, clip=100, loss_scale=64, train_wall=23, gb_free=8.9, wall=8277
2023-06-27 04:31:37 - progress_bar.py[line:272] - INFO: epoch 002:   1339 / 2637 loss=2.374, loss_v1=0, loss_v2=0, nll_loss=1.173, ntokens=1231.1, nsentences=160, sample_size=1231.1, sample_size_v1=0, sample_size_v2=0, ppl=2.25, wps=591.6, ups=0.48, wpb=1231.1, bsz=160, num_updates=3970, lr=2.89115e-05, gnorm=4.942, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=8298
2023-06-27 04:31:58 - progress_bar.py[line:272] - INFO: epoch 002:   1349 / 2637 loss=2.382, loss_v1=0, loss_v2=0, nll_loss=1.186, ntokens=1224.1, nsentences=160, sample_size=1224.1, sample_size_v1=0, sample_size_v2=0, ppl=2.28, wps=588.6, ups=0.48, wpb=1224.1, bsz=160, num_updates=3980, lr=2.8904e-05, gnorm=5.214, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=8318
2023-06-27 04:32:19 - progress_bar.py[line:272] - INFO: epoch 002:   1359 / 2637 loss=2.384, loss_v1=0, loss_v2=0, nll_loss=1.185, ntokens=1247.8, nsentences=160, sample_size=1247.8, sample_size_v1=0, sample_size_v2=0, ppl=2.27, wps=599.9, ups=0.48, wpb=1247.8, bsz=160, num_updates=3990, lr=2.88964e-05, gnorm=4.809, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=8339
2023-06-27 04:32:40 - progress_bar.py[line:272] - INFO: epoch 002:   1369 / 2637 loss=2.407, loss_v1=0, loss_v2=0, nll_loss=1.215, ntokens=1233.5, nsentences=160, sample_size=1233.5, sample_size_v1=0, sample_size_v2=0, ppl=2.32, wps=593.1, ups=0.48, wpb=1233.5, bsz=160, num_updates=4000, lr=2.88888e-05, gnorm=5.151, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=8360
2023-06-27 04:33:00 - progress_bar.py[line:272] - INFO: epoch 002:   1379 / 2637 loss=2.388, loss_v1=0, loss_v2=0, nll_loss=1.192, ntokens=1228.8, nsentences=160, sample_size=1228.8, sample_size_v1=0, sample_size_v2=0, ppl=2.29, wps=590.7, ups=0.48, wpb=1228.8, bsz=160, num_updates=4010, lr=2.88813e-05, gnorm=4.545, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=8381
2023-06-27 04:33:21 - progress_bar.py[line:272] - INFO: epoch 002:   1389 / 2637 loss=2.389, loss_v1=0, loss_v2=0, nll_loss=1.195, ntokens=1273.1, nsentences=160, sample_size=1273.1, sample_size_v1=0, sample_size_v2=0, ppl=2.29, wps=611.9, ups=0.48, wpb=1273.1, bsz=160, num_updates=4020, lr=2.88737e-05, gnorm=5.585, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=8402
2023-06-27 04:33:42 - progress_bar.py[line:272] - INFO: epoch 002:   1399 / 2637 loss=2.379, loss_v1=0, loss_v2=0, nll_loss=1.185, ntokens=1274.1, nsentences=160, sample_size=1274.1, sample_size_v1=0, sample_size_v2=0, ppl=2.27, wps=611.5, ups=0.48, wpb=1274.1, bsz=160, num_updates=4030, lr=2.88661e-05, gnorm=4.35, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=8422
2023-06-27 04:34:03 - progress_bar.py[line:272] - INFO: epoch 002:   1409 / 2637 loss=2.379, loss_v1=0, loss_v2=0, nll_loss=1.18, ntokens=1271.6, nsentences=160, sample_size=1271.6, sample_size_v1=0, sample_size_v2=0, ppl=2.27, wps=610.6, ups=0.48, wpb=1271.6, bsz=160, num_updates=4040, lr=2.88586e-05, gnorm=4.475, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=8443
2023-06-27 04:34:24 - progress_bar.py[line:272] - INFO: epoch 002:   1419 / 2637 loss=2.379, loss_v1=0, loss_v2=0, nll_loss=1.183, ntokens=1268.9, nsentences=160, sample_size=1268.9, sample_size_v1=0, sample_size_v2=0, ppl=2.27, wps=609.1, ups=0.48, wpb=1268.9, bsz=160, num_updates=4050, lr=2.8851e-05, gnorm=4.259, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=8464
2023-06-27 04:34:45 - progress_bar.py[line:272] - INFO: epoch 002:   1429 / 2637 loss=2.366, loss_v1=0, loss_v2=0, nll_loss=1.167, ntokens=1283.5, nsentences=160, sample_size=1283.5, sample_size_v1=0, sample_size_v2=0, ppl=2.25, wps=615.7, ups=0.48, wpb=1283.5, bsz=160, num_updates=4060, lr=2.88434e-05, gnorm=4.689, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=8485
2023-06-27 04:35:05 - progress_bar.py[line:272] - INFO: epoch 002:   1439 / 2637 loss=2.374, loss_v1=0, loss_v2=0, nll_loss=1.178, ntokens=1267, nsentences=160, sample_size=1267, sample_size_v1=0, sample_size_v2=0, ppl=2.26, wps=608.6, ups=0.48, wpb=1267, bsz=160, num_updates=4070, lr=2.88359e-05, gnorm=5.428, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=8506
2023-06-27 04:35:26 - progress_bar.py[line:272] - INFO: epoch 002:   1449 / 2637 loss=2.378, loss_v1=0, loss_v2=0, nll_loss=1.179, ntokens=1287.5, nsentences=160, sample_size=1287.5, sample_size_v1=0, sample_size_v2=0, ppl=2.26, wps=618.4, ups=0.48, wpb=1287.5, bsz=160, num_updates=4080, lr=2.88283e-05, gnorm=4.988, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=8527
2023-06-27 04:35:47 - progress_bar.py[line:272] - INFO: epoch 002:   1459 / 2637 loss=2.39, loss_v1=0, loss_v2=0, nll_loss=1.195, ntokens=1286, nsentences=160, sample_size=1286, sample_size_v1=0, sample_size_v2=0, ppl=2.29, wps=617.7, ups=0.48, wpb=1286, bsz=160, num_updates=4090, lr=2.88208e-05, gnorm=4.441, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=8547
2023-06-27 04:36:08 - progress_bar.py[line:272] - INFO: epoch 002:   1469 / 2637 loss=2.377, loss_v1=0, loss_v2=0, nll_loss=1.178, ntokens=1261.8, nsentences=160, sample_size=1261.8, sample_size_v1=0, sample_size_v2=0, ppl=2.26, wps=605.8, ups=0.48, wpb=1261.8, bsz=160, num_updates=4100, lr=2.88132e-05, gnorm=4.58, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=8568
2023-06-27 04:36:29 - progress_bar.py[line:272] - INFO: epoch 002:   1479 / 2637 loss=2.366, loss_v1=0, loss_v2=0, nll_loss=1.17, ntokens=1272.4, nsentences=160, sample_size=1272.4, sample_size_v1=0, sample_size_v2=0, ppl=2.25, wps=611.4, ups=0.48, wpb=1272.4, bsz=160, num_updates=4110, lr=2.88056e-05, gnorm=5.1, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=8589
2023-06-27 04:36:50 - progress_bar.py[line:272] - INFO: epoch 002:   1489 / 2637 loss=2.385, loss_v1=0, loss_v2=0, nll_loss=1.189, ntokens=1285.9, nsentences=160, sample_size=1285.9, sample_size_v1=0, sample_size_v2=0, ppl=2.28, wps=617.2, ups=0.48, wpb=1285.9, bsz=160, num_updates=4120, lr=2.87981e-05, gnorm=4.162, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=8610
2023-06-27 04:37:10 - progress_bar.py[line:272] - INFO: epoch 002:   1499 / 2637 loss=2.384, loss_v1=0, loss_v2=0, nll_loss=1.189, ntokens=1287.4, nsentences=160, sample_size=1287.4, sample_size_v1=0, sample_size_v2=0, ppl=2.28, wps=618, ups=0.48, wpb=1287.4, bsz=160, num_updates=4130, lr=2.87905e-05, gnorm=4.625, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=8631
2023-06-27 04:37:31 - progress_bar.py[line:272] - INFO: epoch 002:   1509 / 2637 loss=2.4, loss_v1=0, loss_v2=0, nll_loss=1.203, ntokens=1281.1, nsentences=160, sample_size=1281.1, sample_size_v1=0, sample_size_v2=0, ppl=2.3, wps=615, ups=0.48, wpb=1281.1, bsz=160, num_updates=4140, lr=2.87829e-05, gnorm=4.812, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=8652
2023-06-27 04:37:52 - progress_bar.py[line:272] - INFO: epoch 002:   1519 / 2637 loss=2.376, loss_v1=0, loss_v2=0, nll_loss=1.18, ntokens=1266.3, nsentences=160, sample_size=1266.3, sample_size_v1=0, sample_size_v2=0, ppl=2.27, wps=607.1, ups=0.48, wpb=1266.3, bsz=160, num_updates=4150, lr=2.87754e-05, gnorm=4.467, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=8672
2023-06-27 04:38:13 - progress_bar.py[line:272] - INFO: epoch 002:   1529 / 2637 loss=2.411, loss_v1=0, loss_v2=0, nll_loss=1.215, ntokens=1257.9, nsentences=160, sample_size=1257.9, sample_size_v1=0, sample_size_v2=0, ppl=2.32, wps=602.9, ups=0.48, wpb=1257.9, bsz=160, num_updates=4160, lr=2.87678e-05, gnorm=4.51, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=8693
2023-06-27 04:38:34 - progress_bar.py[line:272] - INFO: epoch 002:   1539 / 2637 loss=2.395, loss_v1=0, loss_v2=0, nll_loss=1.204, ntokens=1265.4, nsentences=160, sample_size=1265.4, sample_size_v1=0, sample_size_v2=0, ppl=2.3, wps=606.9, ups=0.48, wpb=1265.4, bsz=160, num_updates=4170, lr=2.87602e-05, gnorm=4.278, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=8714
2023-06-27 04:38:55 - progress_bar.py[line:272] - INFO: epoch 002:   1549 / 2637 loss=2.407, loss_v1=0, loss_v2=0, nll_loss=1.21, ntokens=1265, nsentences=160, sample_size=1265, sample_size_v1=0, sample_size_v2=0, ppl=2.31, wps=607.3, ups=0.48, wpb=1265, bsz=160, num_updates=4180, lr=2.87527e-05, gnorm=4.742, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=8735
2023-06-27 04:39:16 - progress_bar.py[line:272] - INFO: epoch 002:   1559 / 2637 loss=2.392, loss_v1=0, loss_v2=0, nll_loss=1.199, ntokens=1276.7, nsentences=160, sample_size=1276.7, sample_size_v1=0, sample_size_v2=0, ppl=2.3, wps=612.9, ups=0.48, wpb=1276.7, bsz=160, num_updates=4190, lr=2.87451e-05, gnorm=4.305, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=8756
2023-06-27 04:39:36 - progress_bar.py[line:272] - INFO: epoch 002:   1569 / 2637 loss=2.369, loss_v1=0, loss_v2=0, nll_loss=1.168, ntokens=1265, nsentences=160, sample_size=1265, sample_size_v1=0, sample_size_v2=0, ppl=2.25, wps=607.4, ups=0.48, wpb=1265, bsz=160, num_updates=4200, lr=2.87376e-05, gnorm=3.906, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=8777
2023-06-27 04:39:57 - progress_bar.py[line:272] - INFO: epoch 002:   1579 / 2637 loss=2.366, loss_v1=0, loss_v2=0, nll_loss=1.168, ntokens=1270.9, nsentences=160, sample_size=1270.9, sample_size_v1=0, sample_size_v2=0, ppl=2.25, wps=609.6, ups=0.48, wpb=1270.9, bsz=160, num_updates=4210, lr=2.873e-05, gnorm=4.874, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=8797
2023-06-27 04:40:18 - progress_bar.py[line:272] - INFO: epoch 002:   1589 / 2637 loss=2.393, loss_v1=0, loss_v2=0, nll_loss=1.197, ntokens=1267.3, nsentences=160, sample_size=1267.3, sample_size_v1=0, sample_size_v2=0, ppl=2.29, wps=608.4, ups=0.48, wpb=1267.3, bsz=160, num_updates=4220, lr=2.87224e-05, gnorm=4.819, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=8818
2023-06-27 04:40:39 - progress_bar.py[line:272] - INFO: epoch 002:   1599 / 2637 loss=2.388, loss_v1=0, loss_v2=0, nll_loss=1.194, ntokens=1270.2, nsentences=160, sample_size=1270.2, sample_size_v1=0, sample_size_v2=0, ppl=2.29, wps=609.2, ups=0.48, wpb=1270.2, bsz=160, num_updates=4230, lr=2.87149e-05, gnorm=4.581, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=8839
2023-06-27 04:41:00 - progress_bar.py[line:272] - INFO: epoch 002:   1609 / 2637 loss=2.399, loss_v1=0, loss_v2=0, nll_loss=1.204, ntokens=1256.2, nsentences=160, sample_size=1256.2, sample_size_v1=0, sample_size_v2=0, ppl=2.3, wps=603, ups=0.48, wpb=1256.2, bsz=160, num_updates=4240, lr=2.87073e-05, gnorm=4.231, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=8860
2023-06-27 04:41:21 - progress_bar.py[line:272] - INFO: epoch 002:   1619 / 2637 loss=2.402, loss_v1=0, loss_v2=0, nll_loss=1.209, ntokens=1266, nsentences=160, sample_size=1266, sample_size_v1=0, sample_size_v2=0, ppl=2.31, wps=602.1, ups=0.48, wpb=1266, bsz=160, num_updates=4250, lr=2.86997e-05, gnorm=4.536, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=8881
2023-06-27 04:41:42 - progress_bar.py[line:272] - INFO: epoch 002:   1629 / 2637 loss=2.39, loss_v1=0, loss_v2=0, nll_loss=1.193, ntokens=1268.1, nsentences=160, sample_size=1268.1, sample_size_v1=0, sample_size_v2=0, ppl=2.29, wps=608.8, ups=0.48, wpb=1268.1, bsz=160, num_updates=4260, lr=2.86922e-05, gnorm=4.57, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=8902
2023-06-27 04:42:02 - progress_bar.py[line:272] - INFO: epoch 002:   1639 / 2637 loss=2.38, loss_v1=0, loss_v2=0, nll_loss=1.185, ntokens=1262.3, nsentences=160, sample_size=1262.3, sample_size_v1=0, sample_size_v2=0, ppl=2.27, wps=605.9, ups=0.48, wpb=1262.3, bsz=160, num_updates=4270, lr=2.86846e-05, gnorm=4.465, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=8923
2023-06-27 04:42:23 - progress_bar.py[line:272] - INFO: epoch 002:   1649 / 2637 loss=2.375, loss_v1=0, loss_v2=0, nll_loss=1.177, ntokens=1264.7, nsentences=160, sample_size=1264.7, sample_size_v1=0, sample_size_v2=0, ppl=2.26, wps=607.6, ups=0.48, wpb=1264.7, bsz=160, num_updates=4280, lr=2.8677e-05, gnorm=4.924, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=8944
2023-06-27 04:42:44 - progress_bar.py[line:272] - INFO: epoch 002:   1659 / 2637 loss=2.408, loss_v1=0, loss_v2=0, nll_loss=1.213, ntokens=1279.5, nsentences=160, sample_size=1279.5, sample_size_v1=0, sample_size_v2=0, ppl=2.32, wps=613.7, ups=0.48, wpb=1279.5, bsz=160, num_updates=4290, lr=2.86695e-05, gnorm=4.288, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=8964
2023-06-27 04:43:05 - progress_bar.py[line:272] - INFO: epoch 002:   1669 / 2637 loss=2.374, loss_v1=0, loss_v2=0, nll_loss=1.176, ntokens=1252.8, nsentences=160, sample_size=1252.8, sample_size_v1=0, sample_size_v2=0, ppl=2.26, wps=601.9, ups=0.48, wpb=1252.8, bsz=160, num_updates=4300, lr=2.86619e-05, gnorm=4.691, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=8985
2023-06-27 04:43:26 - progress_bar.py[line:272] - INFO: epoch 002:   1679 / 2637 loss=2.386, loss_v1=0, loss_v2=0, nll_loss=1.192, ntokens=1265.6, nsentences=160, sample_size=1265.6, sample_size_v1=0, sample_size_v2=0, ppl=2.28, wps=607.5, ups=0.48, wpb=1265.6, bsz=160, num_updates=4310, lr=2.86543e-05, gnorm=4.714, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=9006
2023-06-27 04:43:47 - progress_bar.py[line:272] - INFO: epoch 002:   1689 / 2637 loss=2.365, loss_v1=0, loss_v2=0, nll_loss=1.167, ntokens=1280.5, nsentences=160, sample_size=1280.5, sample_size_v1=0, sample_size_v2=0, ppl=2.25, wps=614.2, ups=0.48, wpb=1280.5, bsz=160, num_updates=4320, lr=2.86468e-05, gnorm=5.241, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=9027
2023-06-27 04:44:07 - progress_bar.py[line:272] - INFO: epoch 002:   1699 / 2637 loss=2.394, loss_v1=0, loss_v2=0, nll_loss=1.2, ntokens=1268.5, nsentences=160, sample_size=1268.5, sample_size_v1=0, sample_size_v2=0, ppl=2.3, wps=609.1, ups=0.48, wpb=1268.5, bsz=160, num_updates=4330, lr=2.86392e-05, gnorm=4.941, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=9048
2023-06-27 04:44:28 - progress_bar.py[line:272] - INFO: epoch 002:   1709 / 2637 loss=2.355, loss_v1=0, loss_v2=0, nll_loss=1.154, ntokens=1284.3, nsentences=160, sample_size=1284.3, sample_size_v1=0, sample_size_v2=0, ppl=2.23, wps=616.1, ups=0.48, wpb=1284.3, bsz=160, num_updates=4340, lr=2.86317e-05, gnorm=4.936, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=9069
2023-06-27 04:44:49 - progress_bar.py[line:272] - INFO: epoch 002:   1719 / 2637 loss=2.4, loss_v1=0, loss_v2=0, nll_loss=1.208, ntokens=1269.8, nsentences=160, sample_size=1269.8, sample_size_v1=0, sample_size_v2=0, ppl=2.31, wps=608.8, ups=0.48, wpb=1269.8, bsz=160, num_updates=4350, lr=2.86241e-05, gnorm=5.378, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=9089
2023-06-27 04:45:10 - progress_bar.py[line:272] - INFO: epoch 002:   1729 / 2637 loss=2.379, loss_v1=0, loss_v2=0, nll_loss=1.18, ntokens=1278.8, nsentences=160, sample_size=1278.8, sample_size_v1=0, sample_size_v2=0, ppl=2.27, wps=613.9, ups=0.48, wpb=1278.8, bsz=160, num_updates=4360, lr=2.86165e-05, gnorm=4.991, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=9110
2023-06-27 04:45:31 - progress_bar.py[line:272] - INFO: epoch 002:   1739 / 2637 loss=2.367, loss_v1=0, loss_v2=0, nll_loss=1.17, ntokens=1273, nsentences=160, sample_size=1273, sample_size_v1=0, sample_size_v2=0, ppl=2.25, wps=611.2, ups=0.48, wpb=1273, bsz=160, num_updates=4370, lr=2.8609e-05, gnorm=4.818, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=9131
2023-06-27 04:45:52 - progress_bar.py[line:272] - INFO: epoch 002:   1749 / 2637 loss=2.4, loss_v1=0, loss_v2=0, nll_loss=1.203, ntokens=1265.2, nsentences=160, sample_size=1265.2, sample_size_v1=0, sample_size_v2=0, ppl=2.3, wps=601.7, ups=0.48, wpb=1265.2, bsz=160, num_updates=4380, lr=2.86014e-05, gnorm=4.838, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=9152
2023-06-27 04:46:13 - progress_bar.py[line:272] - INFO: epoch 002:   1759 / 2637 loss=2.364, loss_v1=0, loss_v2=0, nll_loss=1.165, ntokens=1275.8, nsentences=160, sample_size=1275.8, sample_size_v1=0, sample_size_v2=0, ppl=2.24, wps=612.2, ups=0.48, wpb=1275.8, bsz=160, num_updates=4390, lr=2.85938e-05, gnorm=4.933, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=9173
2023-06-27 04:46:34 - progress_bar.py[line:272] - INFO: epoch 002:   1769 / 2637 loss=2.393, loss_v1=0, loss_v2=0, nll_loss=1.198, ntokens=1274.3, nsentences=160, sample_size=1274.3, sample_size_v1=0, sample_size_v2=0, ppl=2.29, wps=612.2, ups=0.48, wpb=1274.3, bsz=160, num_updates=4400, lr=2.85863e-05, gnorm=5.068, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=9194
2023-06-27 04:46:54 - progress_bar.py[line:272] - INFO: epoch 002:   1779 / 2637 loss=2.371, loss_v1=0, loss_v2=0, nll_loss=1.175, ntokens=1273.7, nsentences=160, sample_size=1273.7, sample_size_v1=0, sample_size_v2=0, ppl=2.26, wps=611.7, ups=0.48, wpb=1273.7, bsz=160, num_updates=4410, lr=2.85787e-05, gnorm=5.626, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=9215
2023-06-27 04:47:15 - progress_bar.py[line:272] - INFO: epoch 002:   1789 / 2637 loss=2.383, loss_v1=0, loss_v2=0, nll_loss=1.185, ntokens=1299.8, nsentences=160, sample_size=1299.8, sample_size_v1=0, sample_size_v2=0, ppl=2.27, wps=623.9, ups=0.48, wpb=1299.8, bsz=160, num_updates=4420, lr=2.85711e-05, gnorm=5.637, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=9235
2023-06-27 04:47:36 - progress_bar.py[line:272] - INFO: epoch 002:   1799 / 2637 loss=2.405, loss_v1=0, loss_v2=0, nll_loss=1.211, ntokens=1258.4, nsentences=160, sample_size=1258.4, sample_size_v1=0, sample_size_v2=0, ppl=2.31, wps=604.3, ups=0.48, wpb=1258.4, bsz=160, num_updates=4430, lr=2.85636e-05, gnorm=4.57, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=9256
2023-06-27 04:47:57 - progress_bar.py[line:272] - INFO: epoch 002:   1809 / 2637 loss=2.37, loss_v1=0, loss_v2=0, nll_loss=1.17, ntokens=1286.7, nsentences=160, sample_size=1286.7, sample_size_v1=0, sample_size_v2=0, ppl=2.25, wps=616.4, ups=0.48, wpb=1286.7, bsz=160, num_updates=4440, lr=2.8556e-05, gnorm=4.788, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=9277
2023-06-27 04:48:18 - progress_bar.py[line:272] - INFO: epoch 002:   1819 / 2637 loss=2.381, loss_v1=0, loss_v2=0, nll_loss=1.187, ntokens=1255.7, nsentences=160, sample_size=1255.7, sample_size_v1=0, sample_size_v2=0, ppl=2.28, wps=602.4, ups=0.48, wpb=1255.7, bsz=160, num_updates=4450, lr=2.85484e-05, gnorm=5.169, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=9298
2023-06-27 04:48:39 - progress_bar.py[line:272] - INFO: epoch 002:   1829 / 2637 loss=2.376, loss_v1=0, loss_v2=0, nll_loss=1.179, ntokens=1271.7, nsentences=160, sample_size=1271.7, sample_size_v1=0, sample_size_v2=0, ppl=2.26, wps=609.8, ups=0.48, wpb=1271.7, bsz=160, num_updates=4460, lr=2.85409e-05, gnorm=4.882, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=9319
2023-06-27 04:48:59 - progress_bar.py[line:272] - INFO: epoch 002:   1839 / 2637 loss=2.362, loss_v1=0, loss_v2=0, nll_loss=1.161, ntokens=1306, nsentences=160, sample_size=1306, sample_size_v1=0, sample_size_v2=0, ppl=2.24, wps=625.7, ups=0.48, wpb=1306, bsz=160, num_updates=4470, lr=2.85333e-05, gnorm=4.733, clip=100, loss_scale=128, train_wall=21, gb_free=8.9, wall=9340
2023-06-27 04:49:20 - progress_bar.py[line:272] - INFO: epoch 002:   1849 / 2637 loss=2.372, loss_v1=0, loss_v2=0, nll_loss=1.175, ntokens=1278.2, nsentences=160, sample_size=1278.2, sample_size_v1=0, sample_size_v2=0, ppl=2.26, wps=612.8, ups=0.48, wpb=1278.2, bsz=160, num_updates=4480, lr=2.85258e-05, gnorm=4.313, clip=100, loss_scale=128, train_wall=21, gb_free=8.9, wall=9361
2023-06-27 04:49:41 - progress_bar.py[line:272] - INFO: epoch 002:   1859 / 2637 loss=2.371, loss_v1=0, loss_v2=0, nll_loss=1.173, ntokens=1262.6, nsentences=160, sample_size=1262.6, sample_size_v1=0, sample_size_v2=0, ppl=2.26, wps=604.7, ups=0.48, wpb=1262.6, bsz=160, num_updates=4490, lr=2.85182e-05, gnorm=4.518, clip=100, loss_scale=128, train_wall=21, gb_free=8.9, wall=9381
2023-06-27 04:50:02 - progress_bar.py[line:272] - INFO: epoch 002:   1869 / 2637 loss=2.377, loss_v1=0, loss_v2=0, nll_loss=1.179, ntokens=1270.3, nsentences=160, sample_size=1270.3, sample_size_v1=0, sample_size_v2=0, ppl=2.26, wps=609, ups=0.48, wpb=1270.3, bsz=160, num_updates=4500, lr=2.85106e-05, gnorm=4.639, clip=100, loss_scale=128, train_wall=21, gb_free=8.9, wall=9402
2023-06-27 04:50:23 - progress_bar.py[line:272] - INFO: epoch 002:   1879 / 2637 loss=2.359, loss_v1=0, loss_v2=0, nll_loss=1.16, ntokens=1284.3, nsentences=160, sample_size=1284.3, sample_size_v1=0, sample_size_v2=0, ppl=2.23, wps=615.3, ups=0.48, wpb=1284.3, bsz=160, num_updates=4510, lr=2.85031e-05, gnorm=4.707, clip=100, loss_scale=128, train_wall=21, gb_free=8.9, wall=9423
2023-06-27 04:50:44 - progress_bar.py[line:272] - INFO: epoch 002:   1889 / 2637 loss=2.362, loss_v1=0, loss_v2=0, nll_loss=1.161, ntokens=1264.7, nsentences=160, sample_size=1264.7, sample_size_v1=0, sample_size_v2=0, ppl=2.24, wps=605.8, ups=0.48, wpb=1264.7, bsz=160, num_updates=4520, lr=2.84955e-05, gnorm=4.546, clip=100, loss_scale=128, train_wall=21, gb_free=8.9, wall=9444
2023-06-27 04:51:05 - progress_bar.py[line:272] - INFO: epoch 002:   1899 / 2637 loss=2.367, loss_v1=0, loss_v2=0, nll_loss=1.168, ntokens=1292.3, nsentences=160, sample_size=1292.3, sample_size_v1=0, sample_size_v2=0, ppl=2.25, wps=619.3, ups=0.48, wpb=1292.3, bsz=160, num_updates=4530, lr=2.84879e-05, gnorm=5.402, clip=100, loss_scale=128, train_wall=21, gb_free=8.9, wall=9465
2023-06-27 04:51:26 - progress_bar.py[line:272] - INFO: epoch 002:   1909 / 2637 loss=2.366, loss_v1=0, loss_v2=0, nll_loss=1.168, ntokens=1261, nsentences=160, sample_size=1261, sample_size_v1=0, sample_size_v2=0, ppl=2.25, wps=604.3, ups=0.48, wpb=1261, bsz=160, num_updates=4540, lr=2.84804e-05, gnorm=5.533, clip=100, loss_scale=128, train_wall=21, gb_free=8.9, wall=9486
2023-06-27 04:51:46 - progress_bar.py[line:272] - INFO: epoch 002:   1919 / 2637 loss=2.36, loss_v1=0, loss_v2=0, nll_loss=1.161, ntokens=1276.7, nsentences=160, sample_size=1276.7, sample_size_v1=0, sample_size_v2=0, ppl=2.24, wps=611.4, ups=0.48, wpb=1276.7, bsz=160, num_updates=4550, lr=2.84728e-05, gnorm=4.693, clip=100, loss_scale=128, train_wall=21, gb_free=8.9, wall=9507
2023-06-27 04:52:07 - progress_bar.py[line:272] - INFO: epoch 002:   1929 / 2637 loss=2.403, loss_v1=0, loss_v2=0, nll_loss=1.206, ntokens=1268.1, nsentences=160, sample_size=1268.1, sample_size_v1=0, sample_size_v2=0, ppl=2.31, wps=607, ups=0.48, wpb=1268.1, bsz=160, num_updates=4560, lr=2.84652e-05, gnorm=5.293, clip=100, loss_scale=128, train_wall=21, gb_free=8.9, wall=9528
2023-06-27 04:52:20 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2023-06-27 04:52:30 - progress_bar.py[line:272] - INFO: epoch 002:   1940 / 2637 loss=2.371, loss_v1=0, loss_v2=0, nll_loss=1.175, ntokens=1275.2, nsentences=160, sample_size=1275.2, sample_size_v1=0, sample_size_v2=0, ppl=2.26, wps=555.6, ups=0.44, wpb=1275.2, bsz=160, num_updates=4570, lr=2.84577e-05, gnorm=6.052, clip=100, loss_scale=64, train_wall=23, gb_free=8.9, wall=9551
2023-06-27 04:52:41 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2023-06-27 04:52:53 - progress_bar.py[line:272] - INFO: epoch 002:   1951 / 2637 loss=2.391, loss_v1=0, loss_v2=0, nll_loss=1.195, ntokens=1288.8, nsentences=160, sample_size=1288.8, sample_size_v1=0, sample_size_v2=0, ppl=2.29, wps=562.3, ups=0.44, wpb=1288.8, bsz=160, num_updates=4580, lr=2.84501e-05, gnorm=5.057, clip=100, loss_scale=32, train_wall=23, gb_free=8.9, wall=9574
2023-06-27 04:53:14 - progress_bar.py[line:272] - INFO: epoch 002:   1961 / 2637 loss=2.373, loss_v1=0, loss_v2=0, nll_loss=1.175, ntokens=1269.6, nsentences=160, sample_size=1269.6, sample_size_v1=0, sample_size_v2=0, ppl=2.26, wps=609.4, ups=0.48, wpb=1269.6, bsz=160, num_updates=4590, lr=2.84426e-05, gnorm=4.779, clip=100, loss_scale=32, train_wall=21, gb_free=8.9, wall=9594
2023-06-27 04:53:35 - progress_bar.py[line:272] - INFO: epoch 002:   1971 / 2637 loss=2.396, loss_v1=0, loss_v2=0, nll_loss=1.201, ntokens=1265.5, nsentences=160, sample_size=1265.5, sample_size_v1=0, sample_size_v2=0, ppl=2.3, wps=607.5, ups=0.48, wpb=1265.5, bsz=160, num_updates=4600, lr=2.8435e-05, gnorm=5.059, clip=100, loss_scale=32, train_wall=21, gb_free=8.9, wall=9615
2023-06-27 04:53:56 - progress_bar.py[line:272] - INFO: epoch 002:   1981 / 2637 loss=2.415, loss_v1=0, loss_v2=0, nll_loss=1.22, ntokens=1278.9, nsentences=160, sample_size=1278.9, sample_size_v1=0, sample_size_v2=0, ppl=2.33, wps=614.2, ups=0.48, wpb=1278.9, bsz=160, num_updates=4610, lr=2.84274e-05, gnorm=5.852, clip=100, loss_scale=32, train_wall=21, gb_free=8.9, wall=9636
2023-06-27 04:54:17 - progress_bar.py[line:272] - INFO: epoch 002:   1991 / 2637 loss=2.36, loss_v1=0, loss_v2=0, nll_loss=1.165, ntokens=1299.7, nsentences=160, sample_size=1299.7, sample_size_v1=0, sample_size_v2=0, ppl=2.24, wps=624, ups=0.48, wpb=1299.7, bsz=160, num_updates=4620, lr=2.84199e-05, gnorm=5.197, clip=100, loss_scale=32, train_wall=21, gb_free=8.9, wall=9657
2023-06-27 04:54:37 - progress_bar.py[line:272] - INFO: epoch 002:   2001 / 2637 loss=2.389, loss_v1=0, loss_v2=0, nll_loss=1.191, ntokens=1273.2, nsentences=160, sample_size=1273.2, sample_size_v1=0, sample_size_v2=0, ppl=2.28, wps=611.3, ups=0.48, wpb=1273.2, bsz=160, num_updates=4630, lr=2.84123e-05, gnorm=4.995, clip=100, loss_scale=32, train_wall=21, gb_free=8.9, wall=9678
2023-06-27 04:54:58 - progress_bar.py[line:272] - INFO: epoch 002:   2011 / 2637 loss=2.374, loss_v1=0, loss_v2=0, nll_loss=1.178, ntokens=1266.3, nsentences=160, sample_size=1266.3, sample_size_v1=0, sample_size_v2=0, ppl=2.26, wps=608, ups=0.48, wpb=1266.3, bsz=160, num_updates=4640, lr=2.84047e-05, gnorm=5.594, clip=100, loss_scale=32, train_wall=21, gb_free=8.9, wall=9699
2023-06-27 04:55:19 - progress_bar.py[line:272] - INFO: epoch 002:   2021 / 2637 loss=2.373, loss_v1=0, loss_v2=0, nll_loss=1.175, ntokens=1305.4, nsentences=160, sample_size=1305.4, sample_size_v1=0, sample_size_v2=0, ppl=2.26, wps=626.6, ups=0.48, wpb=1305.4, bsz=160, num_updates=4650, lr=2.83972e-05, gnorm=5.134, clip=100, loss_scale=32, train_wall=21, gb_free=8.9, wall=9719
2023-06-27 04:55:40 - progress_bar.py[line:272] - INFO: epoch 002:   2031 / 2637 loss=2.36, loss_v1=0, loss_v2=0, nll_loss=1.162, ntokens=1259.7, nsentences=160, sample_size=1259.7, sample_size_v1=0, sample_size_v2=0, ppl=2.24, wps=604.6, ups=0.48, wpb=1259.7, bsz=160, num_updates=4660, lr=2.83896e-05, gnorm=5.531, clip=100, loss_scale=32, train_wall=21, gb_free=8.9, wall=9740
2023-06-27 04:56:01 - progress_bar.py[line:272] - INFO: epoch 002:   2041 / 2637 loss=2.344, loss_v1=0, loss_v2=0, nll_loss=1.141, ntokens=1280.3, nsentences=160, sample_size=1280.3, sample_size_v1=0, sample_size_v2=0, ppl=2.21, wps=614.5, ups=0.48, wpb=1280.3, bsz=160, num_updates=4670, lr=2.8382e-05, gnorm=5.97, clip=100, loss_scale=32, train_wall=21, gb_free=8.9, wall=9761
2023-06-27 04:56:22 - progress_bar.py[line:272] - INFO: epoch 002:   2051 / 2637 loss=2.366, loss_v1=0, loss_v2=0, nll_loss=1.169, ntokens=1271.3, nsentences=160, sample_size=1271.3, sample_size_v1=0, sample_size_v2=0, ppl=2.25, wps=609.8, ups=0.48, wpb=1271.3, bsz=160, num_updates=4680, lr=2.83745e-05, gnorm=5.235, clip=100, loss_scale=32, train_wall=21, gb_free=8.9, wall=9782
2023-06-27 04:56:42 - progress_bar.py[line:272] - INFO: epoch 002:   2061 / 2637 loss=2.357, loss_v1=0, loss_v2=0, nll_loss=1.158, ntokens=1263.4, nsentences=160, sample_size=1263.4, sample_size_v1=0, sample_size_v2=0, ppl=2.23, wps=605.3, ups=0.48, wpb=1263.4, bsz=160, num_updates=4690, lr=2.83669e-05, gnorm=5.695, clip=100, loss_scale=32, train_wall=21, gb_free=8.9, wall=9803
2023-06-27 04:57:03 - progress_bar.py[line:272] - INFO: epoch 002:   2071 / 2637 loss=2.392, loss_v1=0, loss_v2=0, nll_loss=1.197, ntokens=1252.8, nsentences=160, sample_size=1252.8, sample_size_v1=0, sample_size_v2=0, ppl=2.29, wps=599.8, ups=0.48, wpb=1252.8, bsz=160, num_updates=4700, lr=2.83593e-05, gnorm=6.2, clip=100, loss_scale=32, train_wall=21, gb_free=8.9, wall=9824
2023-06-27 04:57:24 - progress_bar.py[line:272] - INFO: epoch 002:   2081 / 2637 loss=2.376, loss_v1=0, loss_v2=0, nll_loss=1.176, ntokens=1261.6, nsentences=160, sample_size=1261.6, sample_size_v1=0, sample_size_v2=0, ppl=2.26, wps=603.9, ups=0.48, wpb=1261.6, bsz=160, num_updates=4710, lr=2.83518e-05, gnorm=5.171, clip=100, loss_scale=32, train_wall=21, gb_free=8.9, wall=9845
2023-06-27 04:57:45 - progress_bar.py[line:272] - INFO: epoch 002:   2091 / 2637 loss=2.371, loss_v1=0, loss_v2=0, nll_loss=1.173, ntokens=1260.9, nsentences=160, sample_size=1260.9, sample_size_v1=0, sample_size_v2=0, ppl=2.25, wps=603.6, ups=0.48, wpb=1260.9, bsz=160, num_updates=4720, lr=2.83442e-05, gnorm=5.15, clip=100, loss_scale=32, train_wall=21, gb_free=8.9, wall=9865
2023-06-27 04:58:06 - progress_bar.py[line:272] - INFO: epoch 002:   2101 / 2637 loss=2.364, loss_v1=0, loss_v2=0, nll_loss=1.168, ntokens=1253.7, nsentences=160, sample_size=1253.7, sample_size_v1=0, sample_size_v2=0, ppl=2.25, wps=601.1, ups=0.48, wpb=1253.7, bsz=160, num_updates=4730, lr=2.83367e-05, gnorm=5.99, clip=100, loss_scale=32, train_wall=21, gb_free=8.9, wall=9886
2023-06-27 04:58:27 - progress_bar.py[line:272] - INFO: epoch 002:   2111 / 2637 loss=2.391, loss_v1=0, loss_v2=0, nll_loss=1.195, ntokens=1257.9, nsentences=160, sample_size=1257.9, sample_size_v1=0, sample_size_v2=0, ppl=2.29, wps=603.2, ups=0.48, wpb=1257.9, bsz=160, num_updates=4740, lr=2.83291e-05, gnorm=5.502, clip=100, loss_scale=32, train_wall=21, gb_free=8.9, wall=9907
2023-06-27 04:58:48 - progress_bar.py[line:272] - INFO: epoch 002:   2121 / 2637 loss=2.364, loss_v1=0, loss_v2=0, nll_loss=1.165, ntokens=1267, nsentences=160, sample_size=1267, sample_size_v1=0, sample_size_v2=0, ppl=2.24, wps=607.8, ups=0.48, wpb=1267, bsz=160, num_updates=4750, lr=2.83215e-05, gnorm=5.25, clip=100, loss_scale=32, train_wall=21, gb_free=8.9, wall=9928
2023-06-27 04:59:09 - progress_bar.py[line:272] - INFO: epoch 002:   2131 / 2637 loss=2.385, loss_v1=0, loss_v2=0, nll_loss=1.19, ntokens=1251.7, nsentences=160, sample_size=1251.7, sample_size_v1=0, sample_size_v2=0, ppl=2.28, wps=600.3, ups=0.48, wpb=1251.7, bsz=160, num_updates=4760, lr=2.8314e-05, gnorm=5.305, clip=100, loss_scale=32, train_wall=21, gb_free=8.9, wall=9949
2023-06-27 04:59:29 - progress_bar.py[line:272] - INFO: epoch 002:   2141 / 2637 loss=2.369, loss_v1=0, loss_v2=0, nll_loss=1.17, ntokens=1264.3, nsentences=160, sample_size=1264.3, sample_size_v1=0, sample_size_v2=0, ppl=2.25, wps=607.4, ups=0.48, wpb=1264.3, bsz=160, num_updates=4770, lr=2.83064e-05, gnorm=5.122, clip=100, loss_scale=32, train_wall=21, gb_free=8.9, wall=9970
2023-06-27 04:59:50 - progress_bar.py[line:272] - INFO: epoch 002:   2151 / 2637 loss=2.372, loss_v1=0, loss_v2=0, nll_loss=1.174, ntokens=1268.6, nsentences=160, sample_size=1268.6, sample_size_v1=0, sample_size_v2=0, ppl=2.26, wps=608.8, ups=0.48, wpb=1268.6, bsz=160, num_updates=4780, lr=2.82988e-05, gnorm=5.205, clip=100, loss_scale=32, train_wall=21, gb_free=8.9, wall=9991
2023-06-27 05:00:11 - progress_bar.py[line:272] - INFO: epoch 002:   2161 / 2637 loss=2.366, loss_v1=0, loss_v2=0, nll_loss=1.17, ntokens=1256.5, nsentences=160, sample_size=1256.5, sample_size_v1=0, sample_size_v2=0, ppl=2.25, wps=603.3, ups=0.48, wpb=1256.5, bsz=160, num_updates=4790, lr=2.82913e-05, gnorm=5.515, clip=100, loss_scale=32, train_wall=21, gb_free=8.9, wall=10011
2023-06-27 05:00:32 - progress_bar.py[line:272] - INFO: epoch 002:   2171 / 2637 loss=2.364, loss_v1=0, loss_v2=0, nll_loss=1.164, ntokens=1271.3, nsentences=160, sample_size=1271.3, sample_size_v1=0, sample_size_v2=0, ppl=2.24, wps=610.2, ups=0.48, wpb=1271.3, bsz=160, num_updates=4800, lr=2.82837e-05, gnorm=5.04, clip=100, loss_scale=32, train_wall=21, gb_free=8.9, wall=10032
2023-06-27 05:00:53 - progress_bar.py[line:272] - INFO: epoch 002:   2181 / 2637 loss=2.367, loss_v1=0, loss_v2=0, nll_loss=1.17, ntokens=1257.6, nsentences=160, sample_size=1257.6, sample_size_v1=0, sample_size_v2=0, ppl=2.25, wps=603.3, ups=0.48, wpb=1257.6, bsz=160, num_updates=4810, lr=2.82761e-05, gnorm=5.12, clip=100, loss_scale=32, train_wall=21, gb_free=8.9, wall=10053
2023-06-27 05:01:14 - progress_bar.py[line:272] - INFO: epoch 002:   2191 / 2637 loss=2.377, loss_v1=0, loss_v2=0, nll_loss=1.181, ntokens=1272.9, nsentences=160, sample_size=1272.9, sample_size_v1=0, sample_size_v2=0, ppl=2.27, wps=610.8, ups=0.48, wpb=1272.9, bsz=160, num_updates=4820, lr=2.82686e-05, gnorm=4.919, clip=100, loss_scale=32, train_wall=21, gb_free=8.9, wall=10074
2023-06-27 05:01:34 - progress_bar.py[line:272] - INFO: epoch 002:   2201 / 2637 loss=2.356, loss_v1=0, loss_v2=0, nll_loss=1.155, ntokens=1265.3, nsentences=160, sample_size=1265.3, sample_size_v1=0, sample_size_v2=0, ppl=2.23, wps=607.1, ups=0.48, wpb=1265.3, bsz=160, num_updates=4830, lr=2.8261e-05, gnorm=5.894, clip=100, loss_scale=32, train_wall=21, gb_free=8.9, wall=10095
2023-06-27 05:01:55 - progress_bar.py[line:272] - INFO: epoch 002:   2211 / 2637 loss=2.342, loss_v1=0, loss_v2=0, nll_loss=1.14, ntokens=1267, nsentences=160, sample_size=1267, sample_size_v1=0, sample_size_v2=0, ppl=2.2, wps=608.2, ups=0.48, wpb=1267, bsz=160, num_updates=4840, lr=2.82534e-05, gnorm=5.024, clip=100, loss_scale=32, train_wall=21, gb_free=8.9, wall=10116
2023-06-27 05:02:16 - progress_bar.py[line:272] - INFO: epoch 002:   2221 / 2637 loss=2.372, loss_v1=0, loss_v2=0, nll_loss=1.174, ntokens=1263.4, nsentences=160, sample_size=1263.4, sample_size_v1=0, sample_size_v2=0, ppl=2.26, wps=606.4, ups=0.48, wpb=1263.4, bsz=160, num_updates=4850, lr=2.82459e-05, gnorm=5.4, clip=100, loss_scale=32, train_wall=21, gb_free=8.9, wall=10136
2023-06-27 05:02:37 - progress_bar.py[line:272] - INFO: epoch 002:   2231 / 2637 loss=2.368, loss_v1=0, loss_v2=0, nll_loss=1.17, ntokens=1269.8, nsentences=160, sample_size=1269.8, sample_size_v1=0, sample_size_v2=0, ppl=2.25, wps=609.6, ups=0.48, wpb=1269.8, bsz=160, num_updates=4860, lr=2.82383e-05, gnorm=4.907, clip=100, loss_scale=32, train_wall=21, gb_free=8.9, wall=10157
2023-06-27 05:02:58 - progress_bar.py[line:272] - INFO: epoch 002:   2241 / 2637 loss=2.366, loss_v1=0, loss_v2=0, nll_loss=1.168, ntokens=1266.7, nsentences=160, sample_size=1266.7, sample_size_v1=0, sample_size_v2=0, ppl=2.25, wps=607.9, ups=0.48, wpb=1266.7, bsz=160, num_updates=4870, lr=2.82308e-05, gnorm=4.513, clip=100, loss_scale=32, train_wall=21, gb_free=8.9, wall=10178
2023-06-27 05:03:19 - progress_bar.py[line:272] - INFO: epoch 002:   2251 / 2637 loss=2.365, loss_v1=0, loss_v2=0, nll_loss=1.164, ntokens=1250.5, nsentences=160, sample_size=1250.5, sample_size_v1=0, sample_size_v2=0, ppl=2.24, wps=599.9, ups=0.48, wpb=1250.5, bsz=160, num_updates=4880, lr=2.82232e-05, gnorm=4.705, clip=100, loss_scale=32, train_wall=21, gb_free=8.9, wall=10199
2023-06-27 05:03:39 - progress_bar.py[line:272] - INFO: epoch 002:   2261 / 2637 loss=2.362, loss_v1=0, loss_v2=0, nll_loss=1.163, ntokens=1257.2, nsentences=160, sample_size=1257.2, sample_size_v1=0, sample_size_v2=0, ppl=2.24, wps=603.8, ups=0.48, wpb=1257.2, bsz=160, num_updates=4890, lr=2.82156e-05, gnorm=5.215, clip=100, loss_scale=32, train_wall=21, gb_free=8.9, wall=10220
2023-06-27 05:04:00 - progress_bar.py[line:272] - INFO: epoch 002:   2271 / 2637 loss=2.364, loss_v1=0, loss_v2=0, nll_loss=1.166, ntokens=1285.6, nsentences=159.9, sample_size=1285.6, sample_size_v1=0, sample_size_v2=0, ppl=2.24, wps=616.9, ups=0.48, wpb=1285.6, bsz=159.9, num_updates=4900, lr=2.82081e-05, gnorm=4.51, clip=100, loss_scale=32, train_wall=21, gb_free=8.9, wall=10241
2023-06-27 05:04:21 - progress_bar.py[line:272] - INFO: epoch 002:   2281 / 2637 loss=2.375, loss_v1=0, loss_v2=0, nll_loss=1.18, ntokens=1267.5, nsentences=160, sample_size=1267.5, sample_size_v1=0, sample_size_v2=0, ppl=2.27, wps=608.7, ups=0.48, wpb=1267.5, bsz=160, num_updates=4910, lr=2.82005e-05, gnorm=4.34, clip=100, loss_scale=32, train_wall=21, gb_free=8.9, wall=10261
2023-06-27 05:04:42 - progress_bar.py[line:272] - INFO: epoch 002:   2291 / 2637 loss=2.357, loss_v1=0, loss_v2=0, nll_loss=1.155, ntokens=1264.7, nsentences=160, sample_size=1264.7, sample_size_v1=0, sample_size_v2=0, ppl=2.23, wps=607.6, ups=0.48, wpb=1264.7, bsz=160, num_updates=4920, lr=2.81929e-05, gnorm=4.342, clip=100, loss_scale=32, train_wall=21, gb_free=8.9, wall=10282
2023-06-27 05:05:03 - progress_bar.py[line:272] - INFO: epoch 002:   2301 / 2637 loss=2.395, loss_v1=0, loss_v2=0, nll_loss=1.2, ntokens=1272, nsentences=160, sample_size=1272, sample_size_v1=0, sample_size_v2=0, ppl=2.3, wps=610.8, ups=0.48, wpb=1272, bsz=160, num_updates=4930, lr=2.81854e-05, gnorm=4.143, clip=100, loss_scale=32, train_wall=21, gb_free=8.9, wall=10303
2023-06-27 05:05:24 - progress_bar.py[line:272] - INFO: epoch 002:   2311 / 2637 loss=2.362, loss_v1=0, loss_v2=0, nll_loss=1.162, ntokens=1265.8, nsentences=160, sample_size=1265.8, sample_size_v1=0, sample_size_v2=0, ppl=2.24, wps=608.2, ups=0.48, wpb=1265.8, bsz=160, num_updates=4940, lr=2.81778e-05, gnorm=5.012, clip=100, loss_scale=32, train_wall=21, gb_free=8.9, wall=10324
2023-06-27 05:05:44 - progress_bar.py[line:272] - INFO: epoch 002:   2321 / 2637 loss=2.371, loss_v1=0, loss_v2=0, nll_loss=1.174, ntokens=1265.7, nsentences=160, sample_size=1265.7, sample_size_v1=0, sample_size_v2=0, ppl=2.26, wps=607.3, ups=0.48, wpb=1265.7, bsz=160, num_updates=4950, lr=2.81702e-05, gnorm=4.326, clip=100, loss_scale=32, train_wall=21, gb_free=8.9, wall=10345
2023-06-27 05:06:05 - progress_bar.py[line:272] - INFO: epoch 002:   2331 / 2637 loss=2.404, loss_v1=0, loss_v2=0, nll_loss=1.209, ntokens=1249.5, nsentences=160, sample_size=1249.5, sample_size_v1=0, sample_size_v2=0, ppl=2.31, wps=600, ups=0.48, wpb=1249.5, bsz=160, num_updates=4960, lr=2.81627e-05, gnorm=5.2, clip=100, loss_scale=32, train_wall=21, gb_free=8.9, wall=10366
2023-06-27 05:06:26 - progress_bar.py[line:272] - INFO: epoch 002:   2341 / 2637 loss=2.38, loss_v1=0, loss_v2=0, nll_loss=1.181, ntokens=1253.8, nsentences=160, sample_size=1253.8, sample_size_v1=0, sample_size_v2=0, ppl=2.27, wps=602.1, ups=0.48, wpb=1253.8, bsz=160, num_updates=4970, lr=2.81551e-05, gnorm=4.37, clip=100, loss_scale=32, train_wall=21, gb_free=8.9, wall=10386
2023-06-27 05:06:47 - progress_bar.py[line:272] - INFO: epoch 002:   2351 / 2637 loss=2.359, loss_v1=0, loss_v2=0, nll_loss=1.159, ntokens=1260, nsentences=160, sample_size=1260, sample_size_v1=0, sample_size_v2=0, ppl=2.23, wps=605.2, ups=0.48, wpb=1260, bsz=160, num_updates=4980, lr=2.81476e-05, gnorm=4.011, clip=100, loss_scale=32, train_wall=21, gb_free=8.9, wall=10407
2023-06-27 05:07:08 - progress_bar.py[line:272] - INFO: epoch 002:   2361 / 2637 loss=2.388, loss_v1=0, loss_v2=0, nll_loss=1.192, ntokens=1279.1, nsentences=160, sample_size=1279.1, sample_size_v1=0, sample_size_v2=0, ppl=2.29, wps=614, ups=0.48, wpb=1279.1, bsz=160, num_updates=4990, lr=2.814e-05, gnorm=3.437, clip=100, loss_scale=32, train_wall=21, gb_free=8.9, wall=10428
2023-06-27 05:07:29 - progress_bar.py[line:272] - INFO: epoch 002:   2371 / 2637 loss=2.373, loss_v1=0, loss_v2=0, nll_loss=1.175, ntokens=1276.1, nsentences=160, sample_size=1276.1, sample_size_v1=0, sample_size_v2=0, ppl=2.26, wps=612.8, ups=0.48, wpb=1276.1, bsz=160, num_updates=5000, lr=2.81324e-05, gnorm=4.098, clip=100, loss_scale=32, train_wall=21, gb_free=8.9, wall=10449
2023-06-27 05:07:49 - progress_bar.py[line:272] - INFO: epoch 002:   2381 / 2637 loss=2.365, loss_v1=0, loss_v2=0, nll_loss=1.166, ntokens=1278.3, nsentences=160, sample_size=1278.3, sample_size_v1=0, sample_size_v2=0, ppl=2.24, wps=614.2, ups=0.48, wpb=1278.3, bsz=160, num_updates=5010, lr=2.81249e-05, gnorm=4.152, clip=100, loss_scale=32, train_wall=21, gb_free=8.9, wall=10470
2023-06-27 05:08:10 - progress_bar.py[line:272] - INFO: epoch 002:   2391 / 2637 loss=2.382, loss_v1=0, loss_v2=0, nll_loss=1.186, ntokens=1282, nsentences=160, sample_size=1282, sample_size_v1=0, sample_size_v2=0, ppl=2.28, wps=615.7, ups=0.48, wpb=1282, bsz=160, num_updates=5020, lr=2.81173e-05, gnorm=4.353, clip=100, loss_scale=32, train_wall=21, gb_free=8.9, wall=10491
2023-06-27 05:08:31 - progress_bar.py[line:272] - INFO: epoch 002:   2401 / 2637 loss=2.39, loss_v1=0, loss_v2=0, nll_loss=1.194, ntokens=1277.4, nsentences=160, sample_size=1277.4, sample_size_v1=0, sample_size_v2=0, ppl=2.29, wps=613.5, ups=0.48, wpb=1277.4, bsz=160, num_updates=5030, lr=2.81097e-05, gnorm=4.966, clip=100, loss_scale=32, train_wall=21, gb_free=8.9, wall=10511
2023-06-27 05:08:52 - progress_bar.py[line:272] - INFO: epoch 002:   2411 / 2637 loss=2.385, loss_v1=0, loss_v2=0, nll_loss=1.187, ntokens=1286.4, nsentences=160, sample_size=1286.4, sample_size_v1=0, sample_size_v2=0, ppl=2.28, wps=618, ups=0.48, wpb=1286.4, bsz=160, num_updates=5040, lr=2.81022e-05, gnorm=5.291, clip=100, loss_scale=32, train_wall=21, gb_free=8.9, wall=10532
2023-06-27 05:09:13 - progress_bar.py[line:272] - INFO: epoch 002:   2421 / 2637 loss=2.363, loss_v1=0, loss_v2=0, nll_loss=1.167, ntokens=1260, nsentences=160, sample_size=1260, sample_size_v1=0, sample_size_v2=0, ppl=2.25, wps=604.8, ups=0.48, wpb=1260, bsz=160, num_updates=5050, lr=2.80946e-05, gnorm=5.064, clip=100, loss_scale=32, train_wall=21, gb_free=8.9, wall=10553
2023-06-27 05:09:34 - progress_bar.py[line:272] - INFO: epoch 002:   2431 / 2637 loss=2.379, loss_v1=0, loss_v2=0, nll_loss=1.181, ntokens=1276.8, nsentences=160, sample_size=1276.8, sample_size_v1=0, sample_size_v2=0, ppl=2.27, wps=613.8, ups=0.48, wpb=1276.8, bsz=160, num_updates=5060, lr=2.8087e-05, gnorm=4.676, clip=100, loss_scale=32, train_wall=21, gb_free=8.9, wall=10574
2023-06-27 05:09:54 - progress_bar.py[line:272] - INFO: epoch 002:   2441 / 2637 loss=2.372, loss_v1=0, loss_v2=0, nll_loss=1.174, ntokens=1282.8, nsentences=160, sample_size=1282.8, sample_size_v1=0, sample_size_v2=0, ppl=2.26, wps=616.1, ups=0.48, wpb=1282.8, bsz=160, num_updates=5070, lr=2.80795e-05, gnorm=3.746, clip=100, loss_scale=32, train_wall=21, gb_free=8.9, wall=10595
2023-06-27 05:10:15 - progress_bar.py[line:272] - INFO: epoch 002:   2451 / 2637 loss=2.384, loss_v1=0, loss_v2=0, nll_loss=1.186, ntokens=1275.4, nsentences=160, sample_size=1275.4, sample_size_v1=0, sample_size_v2=0, ppl=2.28, wps=612.5, ups=0.48, wpb=1275.4, bsz=160, num_updates=5080, lr=2.80719e-05, gnorm=4.777, clip=100, loss_scale=32, train_wall=21, gb_free=8.9, wall=10615
2023-06-27 05:10:36 - progress_bar.py[line:272] - INFO: epoch 002:   2461 / 2637 loss=2.352, loss_v1=0, loss_v2=0, nll_loss=1.152, ntokens=1276.9, nsentences=160, sample_size=1276.9, sample_size_v1=0, sample_size_v2=0, ppl=2.22, wps=612.3, ups=0.48, wpb=1276.9, bsz=160, num_updates=5090, lr=2.80643e-05, gnorm=4.965, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=10636
2023-06-27 05:10:57 - progress_bar.py[line:272] - INFO: epoch 002:   2471 / 2637 loss=2.353, loss_v1=0, loss_v2=0, nll_loss=1.153, ntokens=1279.3, nsentences=160, sample_size=1279.3, sample_size_v1=0, sample_size_v2=0, ppl=2.22, wps=612.7, ups=0.48, wpb=1279.3, bsz=160, num_updates=5100, lr=2.80568e-05, gnorm=4.213, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=10657
2023-06-27 05:11:18 - progress_bar.py[line:272] - INFO: epoch 002:   2481 / 2637 loss=2.375, loss_v1=0, loss_v2=0, nll_loss=1.175, ntokens=1294.4, nsentences=160, sample_size=1294.4, sample_size_v1=0, sample_size_v2=0, ppl=2.26, wps=620.4, ups=0.48, wpb=1294.4, bsz=160, num_updates=5110, lr=2.80492e-05, gnorm=4.866, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=10678
2023-06-27 05:11:39 - progress_bar.py[line:272] - INFO: epoch 002:   2491 / 2637 loss=2.382, loss_v1=0, loss_v2=0, nll_loss=1.187, ntokens=1265.6, nsentences=160, sample_size=1265.6, sample_size_v1=0, sample_size_v2=0, ppl=2.28, wps=606.6, ups=0.48, wpb=1265.6, bsz=160, num_updates=5120, lr=2.80417e-05, gnorm=4.621, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=10699
2023-06-27 05:12:00 - progress_bar.py[line:272] - INFO: epoch 002:   2501 / 2637 loss=2.358, loss_v1=0, loss_v2=0, nll_loss=1.157, ntokens=1282.9, nsentences=160, sample_size=1282.9, sample_size_v1=0, sample_size_v2=0, ppl=2.23, wps=614.1, ups=0.48, wpb=1282.9, bsz=160, num_updates=5130, lr=2.80341e-05, gnorm=4.069, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=10720
2023-06-27 05:12:20 - progress_bar.py[line:272] - INFO: epoch 002:   2511 / 2637 loss=2.361, loss_v1=0, loss_v2=0, nll_loss=1.162, ntokens=1281, nsentences=160, sample_size=1281, sample_size_v1=0, sample_size_v2=0, ppl=2.24, wps=614.1, ups=0.48, wpb=1281, bsz=160, num_updates=5140, lr=2.80265e-05, gnorm=4.275, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=10741
2023-06-27 05:12:41 - progress_bar.py[line:272] - INFO: epoch 002:   2521 / 2637 loss=2.358, loss_v1=0, loss_v2=0, nll_loss=1.161, ntokens=1276, nsentences=160, sample_size=1276, sample_size_v1=0, sample_size_v2=0, ppl=2.24, wps=611.7, ups=0.48, wpb=1276, bsz=160, num_updates=5150, lr=2.8019e-05, gnorm=3.974, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=10762
2023-06-27 05:13:02 - progress_bar.py[line:272] - INFO: epoch 002:   2531 / 2637 loss=2.377, loss_v1=0, loss_v2=0, nll_loss=1.175, ntokens=1259.1, nsentences=160, sample_size=1259.1, sample_size_v1=0, sample_size_v2=0, ppl=2.26, wps=602, ups=0.48, wpb=1259.1, bsz=160, num_updates=5160, lr=2.80114e-05, gnorm=4.963, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=10782
2023-06-27 05:13:23 - progress_bar.py[line:272] - INFO: epoch 002:   2541 / 2637 loss=2.345, loss_v1=0, loss_v2=0, nll_loss=1.144, ntokens=1278.4, nsentences=160, sample_size=1278.4, sample_size_v1=0, sample_size_v2=0, ppl=2.21, wps=613, ups=0.48, wpb=1278.4, bsz=160, num_updates=5170, lr=2.80038e-05, gnorm=4.148, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=10803
2023-06-27 05:13:44 - progress_bar.py[line:272] - INFO: epoch 002:   2551 / 2637 loss=2.356, loss_v1=0, loss_v2=0, nll_loss=1.155, ntokens=1260.2, nsentences=160, sample_size=1260.2, sample_size_v1=0, sample_size_v2=0, ppl=2.23, wps=604.2, ups=0.48, wpb=1260.2, bsz=160, num_updates=5180, lr=2.79963e-05, gnorm=4.36, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=10824
2023-06-27 05:14:05 - progress_bar.py[line:272] - INFO: epoch 002:   2561 / 2637 loss=2.36, loss_v1=0, loss_v2=0, nll_loss=1.161, ntokens=1278.4, nsentences=160, sample_size=1278.4, sample_size_v1=0, sample_size_v2=0, ppl=2.24, wps=612.5, ups=0.48, wpb=1278.4, bsz=160, num_updates=5190, lr=2.79887e-05, gnorm=4.554, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=10845
2023-06-27 05:14:26 - progress_bar.py[line:272] - INFO: epoch 002:   2571 / 2637 loss=2.372, loss_v1=0, loss_v2=0, nll_loss=1.174, ntokens=1250.6, nsentences=160, sample_size=1250.6, sample_size_v1=0, sample_size_v2=0, ppl=2.26, wps=599.1, ups=0.48, wpb=1250.6, bsz=160, num_updates=5200, lr=2.79811e-05, gnorm=4.756, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=10866
2023-06-27 05:14:47 - progress_bar.py[line:272] - INFO: epoch 002:   2581 / 2637 loss=2.365, loss_v1=0, loss_v2=0, nll_loss=1.168, ntokens=1265.3, nsentences=160, sample_size=1265.3, sample_size_v1=0, sample_size_v2=0, ppl=2.25, wps=605.7, ups=0.48, wpb=1265.3, bsz=160, num_updates=5210, lr=2.79736e-05, gnorm=5.581, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=10887
2023-06-27 05:15:07 - progress_bar.py[line:272] - INFO: epoch 002:   2591 / 2637 loss=2.366, loss_v1=0, loss_v2=0, nll_loss=1.165, ntokens=1290.1, nsentences=160, sample_size=1290.1, sample_size_v1=0, sample_size_v2=0, ppl=2.24, wps=617.5, ups=0.48, wpb=1290.1, bsz=160, num_updates=5220, lr=2.7966e-05, gnorm=4.521, clip=100, loss_scale=64, train_wall=21, gb_free=8.7, wall=10908
2023-06-27 05:15:28 - progress_bar.py[line:272] - INFO: epoch 002:   2601 / 2637 loss=2.366, loss_v1=0, loss_v2=0, nll_loss=1.169, ntokens=1273.4, nsentences=160, sample_size=1273.4, sample_size_v1=0, sample_size_v2=0, ppl=2.25, wps=610.4, ups=0.48, wpb=1273.4, bsz=160, num_updates=5230, lr=2.79584e-05, gnorm=4.509, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=10929
2023-06-27 05:15:49 - progress_bar.py[line:272] - INFO: epoch 002:   2611 / 2637 loss=2.358, loss_v1=0, loss_v2=0, nll_loss=1.157, ntokens=1270, nsentences=160, sample_size=1270, sample_size_v1=0, sample_size_v2=0, ppl=2.23, wps=606.3, ups=0.48, wpb=1270, bsz=160, num_updates=5240, lr=2.79509e-05, gnorm=4.135, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=10950
2023-06-27 05:16:10 - progress_bar.py[line:272] - INFO: epoch 002:   2621 / 2637 loss=2.341, loss_v1=0, loss_v2=0, nll_loss=1.141, ntokens=1268.8, nsentences=160, sample_size=1268.8, sample_size_v1=0, sample_size_v2=0, ppl=2.21, wps=607.5, ups=0.48, wpb=1268.8, bsz=160, num_updates=5250, lr=2.79433e-05, gnorm=4.203, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=10970
2023-06-27 05:16:31 - progress_bar.py[line:272] - INFO: epoch 002:   2631 / 2637 loss=2.373, loss_v1=0, loss_v2=0, nll_loss=1.173, ntokens=1289.4, nsentences=160, sample_size=1289.4, sample_size_v1=0, sample_size_v2=0, ppl=2.26, wps=617.2, ups=0.48, wpb=1289.4, bsz=160, num_updates=5260, lr=2.79358e-05, gnorm=4.892, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=10991
2023-06-27 05:16:43 - checkpoint_utils.py[line:64] - INFO: Preparing to save checkpoint for epoch 2 @ 5266 updates
local datafile ../../dataset/OFA_data/vrd/vg_train_full.tsv slice_id 1 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../dataset/OFA_data/vrd/vg_train_full.tsv slice_id 2 begin to initialize row_count and line_idx-to-offset mapping
2023-06-27 05:16:43 - trainer.py[line:431] - INFO: Saving checkpoint to ../../checkpoints/OFA/vrd_checkpoints/_16_3e-5_512_rare_3/checkpoint2.pt
local datafile ../../dataset/OFA_data/vrd/vg_train_full.tsv slice_id 3 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../dataset/OFA_data/vrd/vg_train_full.tsv slice_id 2 finished initializing row_count and line_idx-to-offset mapping
file ../../dataset/OFA_data/vrd/vg_train_full.tsv slice_id 2 row count 105470 total row count 421879
local datafile ../../dataset/OFA_data/vrd/vg_train_full.tsv slice_id 3 finished initializing row_count and line_idx-to-offset mapping
file ../../dataset/OFA_data/vrd/vg_train_full.tsv slice_id 3 row count 105469 total row count 421879
local datafile ../../dataset/OFA_data/vrd/vg_train_full.tsv slice_id 1 finished initializing row_count and line_idx-to-offset mapping
file ../../dataset/OFA_data/vrd/vg_train_full.tsv slice_id 1 row count 105470 total row count 421879
slice_id 1 seek offset 105470
slice_id 2 seek offset 210940
slice_id 3 seek offset 316410
2023-06-27 05:16:46 - trainer.py[line:441] - INFO: Finished saving checkpoint to ../../checkpoints/OFA/vrd_checkpoints/_16_3e-5_512_rare_3/checkpoint2.pt
2023-06-27 05:16:48 - checkpoint_utils.py[line:133] - INFO: Saved checkpoint ../../checkpoints/OFA/vrd_checkpoints/_16_3e-5_512_rare_3/checkpoint2.pt (epoch 2 @ 5266 updates, score None) (writing took 4.776012120768428 seconds)
2023-06-27 05:16:48 - train.py[line:332] - INFO: end of epoch 2 (average epoch stats below)
2023-06-27 05:16:48 - progress_bar.py[line:282] - INFO: epoch 002 | loss 2.379 | loss_v1 0 | loss_v2 0 | nll_loss 1.182 | ntokens 1259.92 | nsentences 159.984 | sample_size 1259.92 | sample_size_v1 0 | sample_size_v2 0 | ppl 2.27 | wps 602.7 | ups 0.48 | wpb 1259.9 | bsz 160 | num_updates 5266 | lr 2.79312e-05 | gnorm 4.397 | clip 100 | loss_scale 64 | train_wall 5488 | gb_free 8.9 | wall 11008
2023-06-27 05:16:48 - trainer.py[line:639] - INFO: loading train data for epoch 3
local datafile ../../dataset/OFA_data/vrd/vg_train_full.tsv slice_id 0 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../dataset/OFA_data/vrd/vg_train_full.tsv slice_id 0 finished initializing row_count and line_idx-to-offset mapping
file ../../dataset/OFA_data/vrd/vg_train_full.tsv slice_id 0 row count 105470 total row count 421879
slice_id 0 seek offset 0
2023-06-27 05:16:48 - trainer.py[line:703] - INFO: begin training epoch 3
2023-06-27 05:16:48 - train.py[line:305] - INFO: Start iterating over samples
2023-06-27 05:16:57 - progress_bar.py[line:272] - INFO: epoch 003:      4 / 2637 loss=2.384, loss_v1=0, loss_v2=0, nll_loss=1.187, ntokens=1221.4, nsentences=156, sample_size=1221.4, sample_size_v1=0, sample_size_v2=0, ppl=2.28, wps=475.4, ups=0.39, wpb=1221.4, bsz=156, num_updates=5270, lr=2.79282e-05, gnorm=4.751, clip=100, loss_scale=64, train_wall=20, gb_free=8.9, wall=11017
2023-06-27 05:17:18 - progress_bar.py[line:272] - INFO: epoch 003:     14 / 2637 loss=2.342, loss_v1=0, loss_v2=0, nll_loss=1.139, ntokens=1262.8, nsentences=160, sample_size=1262.8, sample_size_v1=0, sample_size_v2=0, ppl=2.2, wps=605, ups=0.48, wpb=1262.8, bsz=160, num_updates=5280, lr=2.79206e-05, gnorm=5.285, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=11038
2023-06-27 05:17:38 - progress_bar.py[line:272] - INFO: epoch 003:     24 / 2637 loss=2.342, loss_v1=0, loss_v2=0, nll_loss=1.141, ntokens=1258.5, nsentences=160, sample_size=1258.5, sample_size_v1=0, sample_size_v2=0, ppl=2.21, wps=603.5, ups=0.48, wpb=1258.5, bsz=160, num_updates=5290, lr=2.79131e-05, gnorm=5.176, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=11059
2023-06-27 05:17:59 - progress_bar.py[line:272] - INFO: epoch 003:     34 / 2637 loss=2.333, loss_v1=0, loss_v2=0, nll_loss=1.131, ntokens=1252.2, nsentences=160, sample_size=1252.2, sample_size_v1=0, sample_size_v2=0, ppl=2.19, wps=599.6, ups=0.48, wpb=1252.2, bsz=160, num_updates=5300, lr=2.79055e-05, gnorm=4.953, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=11080
2023-06-27 05:18:20 - progress_bar.py[line:272] - INFO: epoch 003:     44 / 2637 loss=2.351, loss_v1=0, loss_v2=0, nll_loss=1.149, ntokens=1258.8, nsentences=160, sample_size=1258.8, sample_size_v1=0, sample_size_v2=0, ppl=2.22, wps=604.2, ups=0.48, wpb=1258.8, bsz=160, num_updates=5310, lr=2.78979e-05, gnorm=4.301, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=11100
2023-06-27 05:18:41 - progress_bar.py[line:272] - INFO: epoch 003:     54 / 2637 loss=2.352, loss_v1=0, loss_v2=0, nll_loss=1.152, ntokens=1243.5, nsentences=160, sample_size=1243.5, sample_size_v1=0, sample_size_v2=0, ppl=2.22, wps=597.4, ups=0.48, wpb=1243.5, bsz=160, num_updates=5320, lr=2.78904e-05, gnorm=4.139, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=11121
2023-06-27 05:19:02 - progress_bar.py[line:272] - INFO: epoch 003:     64 / 2637 loss=2.367, loss_v1=0, loss_v2=0, nll_loss=1.17, ntokens=1248.2, nsentences=160, sample_size=1248.2, sample_size_v1=0, sample_size_v2=0, ppl=2.25, wps=599.3, ups=0.48, wpb=1248.2, bsz=160, num_updates=5330, lr=2.78828e-05, gnorm=4.665, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=11142
2023-06-27 05:19:23 - progress_bar.py[line:272] - INFO: epoch 003:     74 / 2637 loss=2.352, loss_v1=0, loss_v2=0, nll_loss=1.151, ntokens=1244, nsentences=160, sample_size=1244, sample_size_v1=0, sample_size_v2=0, ppl=2.22, wps=598.1, ups=0.48, wpb=1244, bsz=160, num_updates=5340, lr=2.78752e-05, gnorm=4.888, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=11163
2023-06-27 05:19:43 - progress_bar.py[line:272] - INFO: epoch 003:     84 / 2637 loss=2.366, loss_v1=0, loss_v2=0, nll_loss=1.166, ntokens=1257.8, nsentences=160, sample_size=1257.8, sample_size_v1=0, sample_size_v2=0, ppl=2.24, wps=604.5, ups=0.48, wpb=1257.8, bsz=160, num_updates=5350, lr=2.78677e-05, gnorm=4.71, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=11184
2023-06-27 05:20:04 - progress_bar.py[line:272] - INFO: epoch 003:     94 / 2637 loss=2.345, loss_v1=0, loss_v2=0, nll_loss=1.145, ntokens=1249.6, nsentences=160, sample_size=1249.6, sample_size_v1=0, sample_size_v2=0, ppl=2.21, wps=600.9, ups=0.48, wpb=1249.6, bsz=160, num_updates=5360, lr=2.78601e-05, gnorm=5.224, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=11205
2023-06-27 05:20:25 - progress_bar.py[line:272] - INFO: epoch 003:    104 / 2637 loss=2.356, loss_v1=0, loss_v2=0, nll_loss=1.154, ntokens=1248.5, nsentences=160, sample_size=1248.5, sample_size_v1=0, sample_size_v2=0, ppl=2.23, wps=600, ups=0.48, wpb=1248.5, bsz=160, num_updates=5370, lr=2.78526e-05, gnorm=5.319, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=11225
2023-06-27 05:20:46 - progress_bar.py[line:272] - INFO: epoch 003:    114 / 2637 loss=2.327, loss_v1=0, loss_v2=0, nll_loss=1.124, ntokens=1247.3, nsentences=160, sample_size=1247.3, sample_size_v1=0, sample_size_v2=0, ppl=2.18, wps=599.2, ups=0.48, wpb=1247.3, bsz=160, num_updates=5380, lr=2.7845e-05, gnorm=3.85, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=11246
2023-06-27 05:21:07 - progress_bar.py[line:272] - INFO: epoch 003:    124 / 2637 loss=2.345, loss_v1=0, loss_v2=0, nll_loss=1.145, ntokens=1241, nsentences=160, sample_size=1241, sample_size_v1=0, sample_size_v2=0, ppl=2.21, wps=596.1, ups=0.48, wpb=1241, bsz=160, num_updates=5390, lr=2.78374e-05, gnorm=4.134, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=11267
2023-06-27 05:21:28 - progress_bar.py[line:272] - INFO: epoch 003:    134 / 2637 loss=2.363, loss_v1=0, loss_v2=0, nll_loss=1.163, ntokens=1253.9, nsentences=160, sample_size=1253.9, sample_size_v1=0, sample_size_v2=0, ppl=2.24, wps=600.7, ups=0.48, wpb=1253.9, bsz=160, num_updates=5400, lr=2.78299e-05, gnorm=4.491, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=11288
2023-06-27 05:21:48 - progress_bar.py[line:272] - INFO: epoch 003:    144 / 2637 loss=2.366, loss_v1=0, loss_v2=0, nll_loss=1.164, ntokens=1252.5, nsentences=160, sample_size=1252.5, sample_size_v1=0, sample_size_v2=0, ppl=2.24, wps=599.9, ups=0.48, wpb=1252.5, bsz=160, num_updates=5410, lr=2.78223e-05, gnorm=4.326, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=11309
2023-06-27 05:22:09 - progress_bar.py[line:272] - INFO: epoch 003:    154 / 2637 loss=2.379, loss_v1=0, loss_v2=0, nll_loss=1.18, ntokens=1249.4, nsentences=160, sample_size=1249.4, sample_size_v1=0, sample_size_v2=0, ppl=2.27, wps=599.1, ups=0.48, wpb=1249.4, bsz=160, num_updates=5420, lr=2.78147e-05, gnorm=4.833, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=11330
2023-06-27 05:22:30 - progress_bar.py[line:272] - INFO: epoch 003:    164 / 2637 loss=2.368, loss_v1=0, loss_v2=0, nll_loss=1.172, ntokens=1234.2, nsentences=160, sample_size=1234.2, sample_size_v1=0, sample_size_v2=0, ppl=2.25, wps=591.5, ups=0.48, wpb=1234.2, bsz=160, num_updates=5430, lr=2.78072e-05, gnorm=4.18, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=11350
2023-06-27 05:22:51 - progress_bar.py[line:272] - INFO: epoch 003:    174 / 2637 loss=2.352, loss_v1=0, loss_v2=0, nll_loss=1.153, ntokens=1243, nsentences=160, sample_size=1243, sample_size_v1=0, sample_size_v2=0, ppl=2.22, wps=596.1, ups=0.48, wpb=1243, bsz=160, num_updates=5440, lr=2.77996e-05, gnorm=4.225, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=11371
2023-06-27 05:23:12 - progress_bar.py[line:272] - INFO: epoch 003:    184 / 2637 loss=2.342, loss_v1=0, loss_v2=0, nll_loss=1.141, ntokens=1238, nsentences=160, sample_size=1238, sample_size_v1=0, sample_size_v2=0, ppl=2.21, wps=593.2, ups=0.48, wpb=1238, bsz=160, num_updates=5450, lr=2.7792e-05, gnorm=4.516, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=11392
2023-06-27 05:23:33 - progress_bar.py[line:272] - INFO: epoch 003:    194 / 2637 loss=2.346, loss_v1=0, loss_v2=0, nll_loss=1.143, ntokens=1230.4, nsentences=160, sample_size=1230.4, sample_size_v1=0, sample_size_v2=0, ppl=2.21, wps=589.8, ups=0.48, wpb=1230.4, bsz=160, num_updates=5460, lr=2.77845e-05, gnorm=4.725, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=11413
2023-06-27 05:23:54 - progress_bar.py[line:272] - INFO: epoch 003:    204 / 2637 loss=2.329, loss_v1=0, loss_v2=0, nll_loss=1.125, ntokens=1257.8, nsentences=160, sample_size=1257.8, sample_size_v1=0, sample_size_v2=0, ppl=2.18, wps=602.9, ups=0.48, wpb=1257.8, bsz=160, num_updates=5470, lr=2.77769e-05, gnorm=4.906, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=11434
2023-06-27 05:24:15 - progress_bar.py[line:272] - INFO: epoch 003:    214 / 2637 loss=2.296, loss_v1=0, loss_v2=0, nll_loss=1.09, ntokens=1233.1, nsentences=160, sample_size=1233.1, sample_size_v1=0, sample_size_v2=0, ppl=2.13, wps=591, ups=0.48, wpb=1233.1, bsz=160, num_updates=5480, lr=2.77693e-05, gnorm=5.086, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=11455
2023-06-27 05:24:35 - progress_bar.py[line:272] - INFO: epoch 003:    224 / 2637 loss=2.343, loss_v1=0, loss_v2=0, nll_loss=1.143, ntokens=1231.9, nsentences=160, sample_size=1231.9, sample_size_v1=0, sample_size_v2=0, ppl=2.21, wps=588.9, ups=0.48, wpb=1231.9, bsz=160, num_updates=5490, lr=2.77618e-05, gnorm=5.161, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=11476
2023-06-27 05:24:56 - progress_bar.py[line:272] - INFO: epoch 003:    234 / 2637 loss=2.346, loss_v1=0, loss_v2=0, nll_loss=1.147, ntokens=1261.3, nsentences=160, sample_size=1261.3, sample_size_v1=0, sample_size_v2=0, ppl=2.21, wps=604.6, ups=0.48, wpb=1261.3, bsz=160, num_updates=5500, lr=2.77542e-05, gnorm=5.097, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=11497
2023-06-27 05:25:17 - progress_bar.py[line:272] - INFO: epoch 003:    244 / 2637 loss=2.314, loss_v1=0, loss_v2=0, nll_loss=1.108, ntokens=1248.6, nsentences=160, sample_size=1248.6, sample_size_v1=0, sample_size_v2=0, ppl=2.16, wps=599.3, ups=0.48, wpb=1248.6, bsz=160, num_updates=5510, lr=2.77467e-05, gnorm=4.426, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=11517
2023-06-27 05:25:38 - progress_bar.py[line:272] - INFO: epoch 003:    254 / 2637 loss=2.345, loss_v1=0, loss_v2=0, nll_loss=1.144, ntokens=1258.6, nsentences=160, sample_size=1258.6, sample_size_v1=0, sample_size_v2=0, ppl=2.21, wps=604.8, ups=0.48, wpb=1258.6, bsz=160, num_updates=5520, lr=2.77391e-05, gnorm=5.268, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=11538
2023-06-27 05:25:59 - progress_bar.py[line:272] - INFO: epoch 003:    264 / 2637 loss=2.33, loss_v1=0, loss_v2=0, nll_loss=1.127, ntokens=1246.7, nsentences=160, sample_size=1246.7, sample_size_v1=0, sample_size_v2=0, ppl=2.18, wps=598.1, ups=0.48, wpb=1246.7, bsz=160, num_updates=5530, lr=2.77315e-05, gnorm=5.28, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=11559
2023-06-27 05:26:20 - progress_bar.py[line:272] - INFO: epoch 003:    274 / 2637 loss=2.358, loss_v1=0, loss_v2=0, nll_loss=1.155, ntokens=1255.2, nsentences=160, sample_size=1255.2, sample_size_v1=0, sample_size_v2=0, ppl=2.23, wps=602.2, ups=0.48, wpb=1255.2, bsz=160, num_updates=5540, lr=2.7724e-05, gnorm=5.689, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=11580
2023-06-27 05:26:40 - progress_bar.py[line:272] - INFO: epoch 003:    284 / 2637 loss=2.351, loss_v1=0, loss_v2=0, nll_loss=1.153, ntokens=1245.7, nsentences=160, sample_size=1245.7, sample_size_v1=0, sample_size_v2=0, ppl=2.22, wps=598.2, ups=0.48, wpb=1245.7, bsz=160, num_updates=5550, lr=2.77164e-05, gnorm=4.871, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=11601
2023-06-27 05:27:01 - progress_bar.py[line:272] - INFO: epoch 003:    294 / 2637 loss=2.37, loss_v1=0, loss_v2=0, nll_loss=1.169, ntokens=1236, nsentences=160, sample_size=1236, sample_size_v1=0, sample_size_v2=0, ppl=2.25, wps=593.2, ups=0.48, wpb=1236, bsz=160, num_updates=5560, lr=2.77088e-05, gnorm=4.9, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=11622
2023-06-27 05:27:22 - progress_bar.py[line:272] - INFO: epoch 003:    304 / 2637 loss=2.357, loss_v1=0, loss_v2=0, nll_loss=1.158, ntokens=1238, nsentences=160, sample_size=1238, sample_size_v1=0, sample_size_v2=0, ppl=2.23, wps=594.6, ups=0.48, wpb=1238, bsz=160, num_updates=5570, lr=2.77013e-05, gnorm=4.664, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=11642
2023-06-27 05:27:43 - progress_bar.py[line:272] - INFO: epoch 003:    314 / 2637 loss=2.316, loss_v1=0, loss_v2=0, nll_loss=1.11, ntokens=1240.7, nsentences=160, sample_size=1240.7, sample_size_v1=0, sample_size_v2=0, ppl=2.16, wps=596.2, ups=0.48, wpb=1240.7, bsz=160, num_updates=5580, lr=2.76937e-05, gnorm=5.305, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=11663
2023-06-27 05:28:04 - progress_bar.py[line:272] - INFO: epoch 003:    324 / 2637 loss=2.336, loss_v1=0, loss_v2=0, nll_loss=1.137, ntokens=1247.6, nsentences=160, sample_size=1247.6, sample_size_v1=0, sample_size_v2=0, ppl=2.2, wps=599.7, ups=0.48, wpb=1247.6, bsz=160, num_updates=5590, lr=2.76861e-05, gnorm=5.343, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=11684
2023-06-27 05:28:25 - progress_bar.py[line:272] - INFO: epoch 003:    334 / 2637 loss=2.331, loss_v1=0, loss_v2=0, nll_loss=1.128, ntokens=1244, nsentences=160, sample_size=1244, sample_size_v1=0, sample_size_v2=0, ppl=2.19, wps=597.6, ups=0.48, wpb=1244, bsz=160, num_updates=5600, lr=2.76786e-05, gnorm=5.32, clip=100, loss_scale=128, train_wall=21, gb_free=8.9, wall=11705
2023-06-27 05:28:45 - progress_bar.py[line:272] - INFO: epoch 003:    344 / 2637 loss=2.337, loss_v1=0, loss_v2=0, nll_loss=1.133, ntokens=1241.8, nsentences=160, sample_size=1241.8, sample_size_v1=0, sample_size_v2=0, ppl=2.19, wps=597.1, ups=0.48, wpb=1241.8, bsz=160, num_updates=5610, lr=2.7671e-05, gnorm=4.72, clip=100, loss_scale=128, train_wall=21, gb_free=8.9, wall=11726
2023-06-27 05:29:06 - progress_bar.py[line:272] - INFO: epoch 003:    354 / 2637 loss=2.337, loss_v1=0, loss_v2=0, nll_loss=1.134, ntokens=1260.6, nsentences=160, sample_size=1260.6, sample_size_v1=0, sample_size_v2=0, ppl=2.19, wps=606.3, ups=0.48, wpb=1260.6, bsz=160, num_updates=5620, lr=2.76634e-05, gnorm=4.376, clip=100, loss_scale=128, train_wall=21, gb_free=8.9, wall=11746
2023-06-27 05:29:27 - progress_bar.py[line:272] - INFO: epoch 003:    364 / 2637 loss=2.304, loss_v1=0, loss_v2=0, nll_loss=1.097, ntokens=1260.3, nsentences=160, sample_size=1260.3, sample_size_v1=0, sample_size_v2=0, ppl=2.14, wps=606.5, ups=0.48, wpb=1260.3, bsz=160, num_updates=5630, lr=2.76559e-05, gnorm=4.784, clip=100, loss_scale=128, train_wall=21, gb_free=8.9, wall=11767
2023-06-27 05:29:48 - progress_bar.py[line:272] - INFO: epoch 003:    374 / 2637 loss=2.317, loss_v1=0, loss_v2=0, nll_loss=1.111, ntokens=1242.4, nsentences=160, sample_size=1242.4, sample_size_v1=0, sample_size_v2=0, ppl=2.16, wps=594.5, ups=0.48, wpb=1242.4, bsz=160, num_updates=5640, lr=2.76483e-05, gnorm=4.75, clip=100, loss_scale=128, train_wall=21, gb_free=8.9, wall=11788
2023-06-27 05:29:52 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2023-06-27 05:30:11 - progress_bar.py[line:272] - INFO: epoch 003:    385 / 2637 loss=2.299, loss_v1=0, loss_v2=0, nll_loss=1.094, ntokens=1249.8, nsentences=160, sample_size=1249.8, sample_size_v1=0, sample_size_v2=0, ppl=2.13, wps=543.5, ups=0.43, wpb=1249.8, bsz=160, num_updates=5650, lr=2.76408e-05, gnorm=5.177, clip=100, loss_scale=64, train_wall=23, gb_free=8.9, wall=11811
2023-06-27 05:30:32 - progress_bar.py[line:272] - INFO: epoch 003:    395 / 2637 loss=2.303, loss_v1=0, loss_v2=0, nll_loss=1.098, ntokens=1241.1, nsentences=160, sample_size=1241.1, sample_size_v1=0, sample_size_v2=0, ppl=2.14, wps=594.7, ups=0.48, wpb=1241.1, bsz=160, num_updates=5660, lr=2.76332e-05, gnorm=5.442, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=11832
2023-06-27 05:30:53 - progress_bar.py[line:272] - INFO: epoch 003:    405 / 2637 loss=2.293, loss_v1=0, loss_v2=0, nll_loss=1.085, ntokens=1248.5, nsentences=160, sample_size=1248.5, sample_size_v1=0, sample_size_v2=0, ppl=2.12, wps=599.2, ups=0.48, wpb=1248.5, bsz=160, num_updates=5670, lr=2.76256e-05, gnorm=6.06, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=11853
2023-06-27 05:31:13 - progress_bar.py[line:272] - INFO: epoch 003:    415 / 2637 loss=2.294, loss_v1=0, loss_v2=0, nll_loss=1.09, ntokens=1245.7, nsentences=160, sample_size=1245.7, sample_size_v1=0, sample_size_v2=0, ppl=2.13, wps=597.5, ups=0.48, wpb=1245.7, bsz=160, num_updates=5680, lr=2.76181e-05, gnorm=6.76, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=11874
2023-06-27 05:31:34 - progress_bar.py[line:272] - INFO: epoch 003:    425 / 2637 loss=2.301, loss_v1=0, loss_v2=0, nll_loss=1.09, ntokens=1243.3, nsentences=160, sample_size=1243.3, sample_size_v1=0, sample_size_v2=0, ppl=2.13, wps=595.7, ups=0.48, wpb=1243.3, bsz=160, num_updates=5690, lr=2.76105e-05, gnorm=4.928, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=11895
2023-06-27 05:31:55 - progress_bar.py[line:272] - INFO: epoch 003:    435 / 2637 loss=2.323, loss_v1=0, loss_v2=0, nll_loss=1.119, ntokens=1259.4, nsentences=160, sample_size=1259.4, sample_size_v1=0, sample_size_v2=0, ppl=2.17, wps=603.9, ups=0.48, wpb=1259.4, bsz=160, num_updates=5700, lr=2.76029e-05, gnorm=4.214, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=11915
2023-06-27 05:32:16 - progress_bar.py[line:272] - INFO: epoch 003:    445 / 2637 loss=2.3, loss_v1=0, loss_v2=0, nll_loss=1.095, ntokens=1252.9, nsentences=160, sample_size=1252.9, sample_size_v1=0, sample_size_v2=0, ppl=2.14, wps=601, ups=0.48, wpb=1252.9, bsz=160, num_updates=5710, lr=2.75954e-05, gnorm=4.443, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=11936
2023-06-27 05:32:37 - progress_bar.py[line:272] - INFO: epoch 003:    455 / 2637 loss=2.31, loss_v1=0, loss_v2=0, nll_loss=1.106, ntokens=1242.3, nsentences=160, sample_size=1242.3, sample_size_v1=0, sample_size_v2=0, ppl=2.15, wps=595.7, ups=0.48, wpb=1242.3, bsz=160, num_updates=5720, lr=2.75878e-05, gnorm=5.379, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=11957
2023-06-27 05:32:58 - progress_bar.py[line:272] - INFO: epoch 003:    465 / 2637 loss=2.312, loss_v1=0, loss_v2=0, nll_loss=1.106, ntokens=1263.1, nsentences=160, sample_size=1263.1, sample_size_v1=0, sample_size_v2=0, ppl=2.15, wps=605.8, ups=0.48, wpb=1263.1, bsz=160, num_updates=5730, lr=2.75802e-05, gnorm=4.604, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=11978
2023-06-27 05:33:19 - progress_bar.py[line:272] - INFO: epoch 003:    475 / 2637 loss=2.351, loss_v1=0, loss_v2=0, nll_loss=1.151, ntokens=1255.8, nsentences=160, sample_size=1255.8, sample_size_v1=0, sample_size_v2=0, ppl=2.22, wps=601.8, ups=0.48, wpb=1255.8, bsz=160, num_updates=5740, lr=2.75727e-05, gnorm=4.981, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=11999
2023-06-27 05:33:39 - progress_bar.py[line:272] - INFO: epoch 003:    485 / 2637 loss=2.32, loss_v1=0, loss_v2=0, nll_loss=1.117, ntokens=1260.9, nsentences=160, sample_size=1260.9, sample_size_v1=0, sample_size_v2=0, ppl=2.17, wps=604.1, ups=0.48, wpb=1260.9, bsz=160, num_updates=5750, lr=2.75651e-05, gnorm=4.315, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=12020
2023-06-27 05:34:00 - progress_bar.py[line:272] - INFO: epoch 003:    495 / 2637 loss=2.338, loss_v1=0, loss_v2=0, nll_loss=1.136, ntokens=1257.5, nsentences=160, sample_size=1257.5, sample_size_v1=0, sample_size_v2=0, ppl=2.2, wps=602.2, ups=0.48, wpb=1257.5, bsz=160, num_updates=5760, lr=2.75576e-05, gnorm=5.228, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=12041
2023-06-27 05:34:21 - progress_bar.py[line:272] - INFO: epoch 003:    505 / 2637 loss=2.361, loss_v1=0, loss_v2=0, nll_loss=1.16, ntokens=1267.9, nsentences=160, sample_size=1267.9, sample_size_v1=0, sample_size_v2=0, ppl=2.23, wps=607.2, ups=0.48, wpb=1267.9, bsz=160, num_updates=5770, lr=2.755e-05, gnorm=5.048, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=12062
2023-06-27 05:34:42 - progress_bar.py[line:272] - INFO: epoch 003:    515 / 2637 loss=2.349, loss_v1=0, loss_v2=0, nll_loss=1.147, ntokens=1250.6, nsentences=160, sample_size=1250.6, sample_size_v1=0, sample_size_v2=0, ppl=2.21, wps=599.1, ups=0.48, wpb=1250.6, bsz=160, num_updates=5780, lr=2.75424e-05, gnorm=5.555, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=12082
2023-06-27 05:35:03 - progress_bar.py[line:272] - INFO: epoch 003:    525 / 2637 loss=2.314, loss_v1=0, loss_v2=0, nll_loss=1.109, ntokens=1238.6, nsentences=160, sample_size=1238.6, sample_size_v1=0, sample_size_v2=0, ppl=2.16, wps=594.3, ups=0.48, wpb=1238.6, bsz=160, num_updates=5790, lr=2.75349e-05, gnorm=4.998, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=12103
2023-06-27 05:35:24 - progress_bar.py[line:272] - INFO: epoch 003:    535 / 2637 loss=2.348, loss_v1=0, loss_v2=0, nll_loss=1.148, ntokens=1257.1, nsentences=160, sample_size=1257.1, sample_size_v1=0, sample_size_v2=0, ppl=2.22, wps=602.7, ups=0.48, wpb=1257.1, bsz=160, num_updates=5800, lr=2.75273e-05, gnorm=4.798, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=12124
2023-06-27 05:35:45 - progress_bar.py[line:272] - INFO: epoch 003:    545 / 2637 loss=2.359, loss_v1=0, loss_v2=0, nll_loss=1.158, ntokens=1256.8, nsentences=160, sample_size=1256.8, sample_size_v1=0, sample_size_v2=0, ppl=2.23, wps=603.4, ups=0.48, wpb=1256.8, bsz=160, num_updates=5810, lr=2.75197e-05, gnorm=5.104, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=12145
2023-06-27 05:36:05 - progress_bar.py[line:272] - INFO: epoch 003:    555 / 2637 loss=2.333, loss_v1=0, loss_v2=0, nll_loss=1.129, ntokens=1265.3, nsentences=160, sample_size=1265.3, sample_size_v1=0, sample_size_v2=0, ppl=2.19, wps=607.2, ups=0.48, wpb=1265.3, bsz=160, num_updates=5820, lr=2.75122e-05, gnorm=5.258, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=12166
2023-06-27 05:36:26 - progress_bar.py[line:272] - INFO: epoch 003:    565 / 2637 loss=2.362, loss_v1=0, loss_v2=0, nll_loss=1.165, ntokens=1255.6, nsentences=160, sample_size=1255.6, sample_size_v1=0, sample_size_v2=0, ppl=2.24, wps=602.9, ups=0.48, wpb=1255.6, bsz=160, num_updates=5830, lr=2.75046e-05, gnorm=5.002, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=12187
2023-06-27 05:36:47 - progress_bar.py[line:272] - INFO: epoch 003:    575 / 2637 loss=2.366, loss_v1=0, loss_v2=0, nll_loss=1.166, ntokens=1256, nsentences=160, sample_size=1256, sample_size_v1=0, sample_size_v2=0, ppl=2.24, wps=603, ups=0.48, wpb=1256, bsz=160, num_updates=5840, lr=2.7497e-05, gnorm=6.176, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=12207
2023-06-27 05:37:08 - progress_bar.py[line:272] - INFO: epoch 003:    585 / 2637 loss=2.369, loss_v1=0, loss_v2=0, nll_loss=1.17, ntokens=1243.6, nsentences=160, sample_size=1243.6, sample_size_v1=0, sample_size_v2=0, ppl=2.25, wps=597.5, ups=0.48, wpb=1243.6, bsz=160, num_updates=5850, lr=2.74895e-05, gnorm=4.929, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=12228
2023-06-27 05:37:29 - progress_bar.py[line:272] - INFO: epoch 003:    595 / 2637 loss=2.334, loss_v1=0, loss_v2=0, nll_loss=1.133, ntokens=1273.6, nsentences=160, sample_size=1273.6, sample_size_v1=0, sample_size_v2=0, ppl=2.19, wps=611.8, ups=0.48, wpb=1273.6, bsz=160, num_updates=5860, lr=2.74819e-05, gnorm=3.91, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=12249
2023-06-27 05:37:50 - progress_bar.py[line:272] - INFO: epoch 003:    605 / 2637 loss=2.354, loss_v1=0, loss_v2=0, nll_loss=1.153, ntokens=1249.7, nsentences=160, sample_size=1249.7, sample_size_v1=0, sample_size_v2=0, ppl=2.22, wps=599.8, ups=0.48, wpb=1249.7, bsz=160, num_updates=5870, lr=2.74743e-05, gnorm=4.69, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=12270
2023-06-27 05:38:10 - progress_bar.py[line:272] - INFO: epoch 003:    615 / 2637 loss=2.355, loss_v1=0, loss_v2=0, nll_loss=1.154, ntokens=1269, nsentences=160, sample_size=1269, sample_size_v1=0, sample_size_v2=0, ppl=2.23, wps=609.5, ups=0.48, wpb=1269, bsz=160, num_updates=5880, lr=2.74668e-05, gnorm=5.034, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=12291
2023-06-27 05:38:31 - progress_bar.py[line:272] - INFO: epoch 003:    625 / 2637 loss=2.346, loss_v1=0, loss_v2=0, nll_loss=1.146, ntokens=1243.1, nsentences=160, sample_size=1243.1, sample_size_v1=0, sample_size_v2=0, ppl=2.21, wps=596.8, ups=0.48, wpb=1243.1, bsz=160, num_updates=5890, lr=2.74592e-05, gnorm=4.301, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=12312
2023-06-27 05:38:52 - progress_bar.py[line:272] - INFO: epoch 003:    635 / 2637 loss=2.338, loss_v1=0, loss_v2=0, nll_loss=1.137, ntokens=1258.2, nsentences=160, sample_size=1258.2, sample_size_v1=0, sample_size_v2=0, ppl=2.2, wps=604.4, ups=0.48, wpb=1258.2, bsz=160, num_updates=5900, lr=2.74517e-05, gnorm=4.584, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=12332
2023-06-27 05:39:13 - progress_bar.py[line:272] - INFO: epoch 003:    645 / 2637 loss=2.311, loss_v1=0, loss_v2=0, nll_loss=1.107, ntokens=1259.1, nsentences=160, sample_size=1259.1, sample_size_v1=0, sample_size_v2=0, ppl=2.15, wps=604.3, ups=0.48, wpb=1259.1, bsz=160, num_updates=5910, lr=2.74441e-05, gnorm=5.227, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=12353
2023-06-27 05:39:34 - progress_bar.py[line:272] - INFO: epoch 003:    655 / 2637 loss=2.375, loss_v1=0, loss_v2=0, nll_loss=1.178, ntokens=1238.3, nsentences=160, sample_size=1238.3, sample_size_v1=0, sample_size_v2=0, ppl=2.26, wps=594.9, ups=0.48, wpb=1238.3, bsz=160, num_updates=5920, lr=2.74365e-05, gnorm=6.075, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=12374
2023-06-27 05:39:55 - progress_bar.py[line:272] - INFO: epoch 003:    665 / 2637 loss=2.369, loss_v1=0, loss_v2=0, nll_loss=1.169, ntokens=1265.3, nsentences=160, sample_size=1265.3, sample_size_v1=0, sample_size_v2=0, ppl=2.25, wps=607.8, ups=0.48, wpb=1265.3, bsz=160, num_updates=5930, lr=2.7429e-05, gnorm=4.664, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=12395
2023-06-27 05:40:15 - progress_bar.py[line:272] - INFO: epoch 003:    675 / 2637 loss=2.332, loss_v1=0, loss_v2=0, nll_loss=1.128, ntokens=1253.6, nsentences=160, sample_size=1253.6, sample_size_v1=0, sample_size_v2=0, ppl=2.18, wps=602.2, ups=0.48, wpb=1253.6, bsz=160, num_updates=5940, lr=2.74214e-05, gnorm=4.363, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=12416
2023-06-27 05:40:36 - progress_bar.py[line:272] - INFO: epoch 003:    685 / 2637 loss=2.354, loss_v1=0, loss_v2=0, nll_loss=1.155, ntokens=1286.5, nsentences=160, sample_size=1286.5, sample_size_v1=0, sample_size_v2=0, ppl=2.23, wps=617.5, ups=0.48, wpb=1286.5, bsz=160, num_updates=5950, lr=2.74138e-05, gnorm=4.13, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=12437
2023-06-27 05:40:57 - progress_bar.py[line:272] - INFO: epoch 003:    695 / 2637 loss=2.365, loss_v1=0, loss_v2=0, nll_loss=1.163, ntokens=1256, nsentences=160, sample_size=1256, sample_size_v1=0, sample_size_v2=0, ppl=2.24, wps=601.8, ups=0.48, wpb=1256, bsz=160, num_updates=5960, lr=2.74063e-05, gnorm=4.119, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=12457
2023-06-27 05:41:18 - progress_bar.py[line:272] - INFO: epoch 003:    705 / 2637 loss=2.339, loss_v1=0, loss_v2=0, nll_loss=1.139, ntokens=1269.5, nsentences=160, sample_size=1269.5, sample_size_v1=0, sample_size_v2=0, ppl=2.2, wps=607.9, ups=0.48, wpb=1269.5, bsz=160, num_updates=5970, lr=2.73987e-05, gnorm=3.937, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=12478
2023-06-27 05:41:39 - progress_bar.py[line:272] - INFO: epoch 003:    715 / 2637 loss=2.364, loss_v1=0, loss_v2=0, nll_loss=1.163, ntokens=1253.2, nsentences=160, sample_size=1253.2, sample_size_v1=0, sample_size_v2=0, ppl=2.24, wps=599.5, ups=0.48, wpb=1253.2, bsz=160, num_updates=5980, lr=2.73911e-05, gnorm=4.138, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=12499
2023-06-27 05:42:00 - progress_bar.py[line:272] - INFO: epoch 003:    725 / 2637 loss=2.357, loss_v1=0, loss_v2=0, nll_loss=1.158, ntokens=1254.7, nsentences=160, sample_size=1254.7, sample_size_v1=0, sample_size_v2=0, ppl=2.23, wps=601.1, ups=0.48, wpb=1254.7, bsz=160, num_updates=5990, lr=2.73836e-05, gnorm=4.364, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=12520
2023-06-27 05:42:21 - progress_bar.py[line:272] - INFO: epoch 003:    735 / 2637 loss=2.35, loss_v1=0, loss_v2=0, nll_loss=1.15, ntokens=1264.3, nsentences=160, sample_size=1264.3, sample_size_v1=0, sample_size_v2=0, ppl=2.22, wps=605.1, ups=0.48, wpb=1264.3, bsz=160, num_updates=6000, lr=2.7376e-05, gnorm=4.09, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=12541
2023-06-27 05:42:42 - progress_bar.py[line:272] - INFO: epoch 003:    745 / 2637 loss=2.364, loss_v1=0, loss_v2=0, nll_loss=1.167, ntokens=1269, nsentences=160, sample_size=1269, sample_size_v1=0, sample_size_v2=0, ppl=2.25, wps=608, ups=0.48, wpb=1269, bsz=160, num_updates=6010, lr=2.73684e-05, gnorm=4.82, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=12562
2023-06-27 05:43:02 - progress_bar.py[line:272] - INFO: epoch 003:    755 / 2637 loss=2.356, loss_v1=0, loss_v2=0, nll_loss=1.155, ntokens=1260.9, nsentences=160, sample_size=1260.9, sample_size_v1=0, sample_size_v2=0, ppl=2.23, wps=603.8, ups=0.48, wpb=1260.9, bsz=160, num_updates=6020, lr=2.73609e-05, gnorm=4.841, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=12583
2023-06-27 05:43:23 - progress_bar.py[line:272] - INFO: epoch 003:    765 / 2637 loss=2.338, loss_v1=0, loss_v2=0, nll_loss=1.134, ntokens=1252.1, nsentences=160, sample_size=1252.1, sample_size_v1=0, sample_size_v2=0, ppl=2.2, wps=600.3, ups=0.48, wpb=1252.1, bsz=160, num_updates=6030, lr=2.73533e-05, gnorm=4.744, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=12604
2023-06-27 05:43:44 - progress_bar.py[line:272] - INFO: epoch 003:    775 / 2637 loss=2.361, loss_v1=0, loss_v2=0, nll_loss=1.162, ntokens=1260.8, nsentences=160, sample_size=1260.8, sample_size_v1=0, sample_size_v2=0, ppl=2.24, wps=604.6, ups=0.48, wpb=1260.8, bsz=160, num_updates=6040, lr=2.73458e-05, gnorm=4.458, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=12624
2023-06-27 05:44:05 - progress_bar.py[line:272] - INFO: epoch 003:    785 / 2637 loss=2.338, loss_v1=0, loss_v2=0, nll_loss=1.137, ntokens=1257.5, nsentences=160, sample_size=1257.5, sample_size_v1=0, sample_size_v2=0, ppl=2.2, wps=604.1, ups=0.48, wpb=1257.5, bsz=160, num_updates=6050, lr=2.73382e-05, gnorm=5.615, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=12645
2023-06-27 05:44:26 - progress_bar.py[line:272] - INFO: epoch 003:    795 / 2637 loss=2.352, loss_v1=0, loss_v2=0, nll_loss=1.149, ntokens=1256.6, nsentences=160, sample_size=1256.6, sample_size_v1=0, sample_size_v2=0, ppl=2.22, wps=603, ups=0.48, wpb=1256.6, bsz=160, num_updates=6060, lr=2.73306e-05, gnorm=5.278, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=12666
2023-06-27 05:44:47 - progress_bar.py[line:272] - INFO: epoch 003:    805 / 2637 loss=2.335, loss_v1=0, loss_v2=0, nll_loss=1.132, ntokens=1252.2, nsentences=160, sample_size=1252.2, sample_size_v1=0, sample_size_v2=0, ppl=2.19, wps=601.5, ups=0.48, wpb=1252.2, bsz=160, num_updates=6070, lr=2.73231e-05, gnorm=4.352, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=12687
2023-06-27 05:45:07 - progress_bar.py[line:272] - INFO: epoch 003:    815 / 2637 loss=2.325, loss_v1=0, loss_v2=0, nll_loss=1.12, ntokens=1260.6, nsentences=160, sample_size=1260.6, sample_size_v1=0, sample_size_v2=0, ppl=2.17, wps=605.7, ups=0.48, wpb=1260.6, bsz=160, num_updates=6080, lr=2.73155e-05, gnorm=6.314, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=12708
2023-06-27 05:45:28 - progress_bar.py[line:272] - INFO: epoch 003:    825 / 2637 loss=2.359, loss_v1=0, loss_v2=0, nll_loss=1.161, ntokens=1254.3, nsentences=160, sample_size=1254.3, sample_size_v1=0, sample_size_v2=0, ppl=2.24, wps=602.4, ups=0.48, wpb=1254.3, bsz=160, num_updates=6090, lr=2.73079e-05, gnorm=5.292, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=12729
2023-06-27 05:45:49 - progress_bar.py[line:272] - INFO: epoch 003:    835 / 2637 loss=2.358, loss_v1=0, loss_v2=0, nll_loss=1.158, ntokens=1256.8, nsentences=160, sample_size=1256.8, sample_size_v1=0, sample_size_v2=0, ppl=2.23, wps=603.4, ups=0.48, wpb=1256.8, bsz=160, num_updates=6100, lr=2.73004e-05, gnorm=4.343, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=12749
2023-06-27 05:46:10 - progress_bar.py[line:272] - INFO: epoch 003:    845 / 2637 loss=2.34, loss_v1=0, loss_v2=0, nll_loss=1.139, ntokens=1261.9, nsentences=160, sample_size=1261.9, sample_size_v1=0, sample_size_v2=0, ppl=2.2, wps=605, ups=0.48, wpb=1261.9, bsz=160, num_updates=6110, lr=2.72928e-05, gnorm=5.25, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=12770
2023-06-27 05:46:31 - progress_bar.py[line:272] - INFO: epoch 003:    855 / 2637 loss=2.348, loss_v1=0, loss_v2=0, nll_loss=1.148, ntokens=1243.1, nsentences=160, sample_size=1243.1, sample_size_v1=0, sample_size_v2=0, ppl=2.22, wps=597.2, ups=0.48, wpb=1243.1, bsz=160, num_updates=6120, lr=2.72852e-05, gnorm=5.673, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=12791
2023-06-27 05:46:52 - progress_bar.py[line:272] - INFO: epoch 003:    865 / 2637 loss=2.35, loss_v1=0, loss_v2=0, nll_loss=1.148, ntokens=1236.6, nsentences=160, sample_size=1236.6, sample_size_v1=0, sample_size_v2=0, ppl=2.22, wps=593.4, ups=0.48, wpb=1236.6, bsz=160, num_updates=6130, lr=2.72777e-05, gnorm=4.697, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=12812
2023-06-27 05:47:12 - progress_bar.py[line:272] - INFO: epoch 003:    875 / 2637 loss=2.345, loss_v1=0, loss_v2=0, nll_loss=1.143, ntokens=1253.7, nsentences=160, sample_size=1253.7, sample_size_v1=0, sample_size_v2=0, ppl=2.21, wps=601.6, ups=0.48, wpb=1253.7, bsz=160, num_updates=6140, lr=2.72701e-05, gnorm=5.507, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=12833
2023-06-27 05:47:33 - progress_bar.py[line:272] - INFO: epoch 003:    885 / 2637 loss=2.341, loss_v1=0, loss_v2=0, nll_loss=1.139, ntokens=1252.5, nsentences=160, sample_size=1252.5, sample_size_v1=0, sample_size_v2=0, ppl=2.2, wps=600.9, ups=0.48, wpb=1252.5, bsz=160, num_updates=6150, lr=2.72626e-05, gnorm=4.864, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=12854
2023-06-27 05:47:54 - progress_bar.py[line:272] - INFO: epoch 003:    895 / 2637 loss=2.331, loss_v1=0, loss_v2=0, nll_loss=1.129, ntokens=1255.5, nsentences=160, sample_size=1255.5, sample_size_v1=0, sample_size_v2=0, ppl=2.19, wps=602.6, ups=0.48, wpb=1255.5, bsz=160, num_updates=6160, lr=2.7255e-05, gnorm=5.226, clip=100, loss_scale=128, train_wall=21, gb_free=8.9, wall=12874
2023-06-27 05:48:15 - progress_bar.py[line:272] - INFO: epoch 003:    905 / 2637 loss=2.332, loss_v1=0, loss_v2=0, nll_loss=1.129, ntokens=1252.4, nsentences=160, sample_size=1252.4, sample_size_v1=0, sample_size_v2=0, ppl=2.19, wps=601.4, ups=0.48, wpb=1252.4, bsz=160, num_updates=6170, lr=2.72474e-05, gnorm=5.052, clip=100, loss_scale=128, train_wall=21, gb_free=8.9, wall=12895
2023-06-27 05:48:34 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2023-06-27 05:48:38 - progress_bar.py[line:272] - INFO: epoch 003:    916 / 2637 loss=2.319, loss_v1=0, loss_v2=0, nll_loss=1.116, ntokens=1245.7, nsentences=160, sample_size=1245.7, sample_size_v1=0, sample_size_v2=0, ppl=2.17, wps=544.2, ups=0.44, wpb=1245.7, bsz=160, num_updates=6180, lr=2.72399e-05, gnorm=4.981, clip=100, loss_scale=64, train_wall=23, gb_free=8.9, wall=12918
2023-06-27 05:48:59 - progress_bar.py[line:272] - INFO: epoch 003:    926 / 2637 loss=2.366, loss_v1=0, loss_v2=0, nll_loss=1.166, ntokens=1247.2, nsentences=160, sample_size=1247.2, sample_size_v1=0, sample_size_v2=0, ppl=2.24, wps=598.7, ups=0.48, wpb=1247.2, bsz=160, num_updates=6190, lr=2.72323e-05, gnorm=5.594, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=12939
2023-06-27 05:49:20 - progress_bar.py[line:272] - INFO: epoch 003:    936 / 2637 loss=2.332, loss_v1=0, loss_v2=0, nll_loss=1.129, ntokens=1271.2, nsentences=160, sample_size=1271.2, sample_size_v1=0, sample_size_v2=0, ppl=2.19, wps=609.1, ups=0.48, wpb=1271.2, bsz=160, num_updates=6200, lr=2.72247e-05, gnorm=5.172, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=12960
2023-06-27 05:49:40 - progress_bar.py[line:272] - INFO: epoch 003:    946 / 2637 loss=2.365, loss_v1=0, loss_v2=0, nll_loss=1.165, ntokens=1240.4, nsentences=160, sample_size=1240.4, sample_size_v1=0, sample_size_v2=0, ppl=2.24, wps=594.8, ups=0.48, wpb=1240.4, bsz=160, num_updates=6210, lr=2.72172e-05, gnorm=5.425, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=12981
2023-06-27 05:50:01 - progress_bar.py[line:272] - INFO: epoch 003:    956 / 2637 loss=2.351, loss_v1=0, loss_v2=0, nll_loss=1.151, ntokens=1254.2, nsentences=160, sample_size=1254.2, sample_size_v1=0, sample_size_v2=0, ppl=2.22, wps=601.3, ups=0.48, wpb=1254.2, bsz=160, num_updates=6220, lr=2.72096e-05, gnorm=5.414, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=13002
2023-06-27 05:50:22 - progress_bar.py[line:272] - INFO: epoch 003:    966 / 2637 loss=2.34, loss_v1=0, loss_v2=0, nll_loss=1.139, ntokens=1239.9, nsentences=160, sample_size=1239.9, sample_size_v1=0, sample_size_v2=0, ppl=2.2, wps=594.6, ups=0.48, wpb=1239.9, bsz=160, num_updates=6230, lr=2.7202e-05, gnorm=5.129, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=13022
2023-06-27 05:50:43 - progress_bar.py[line:272] - INFO: epoch 003:    976 / 2637 loss=2.299, loss_v1=0, loss_v2=0, nll_loss=1.094, ntokens=1245.2, nsentences=160, sample_size=1245.2, sample_size_v1=0, sample_size_v2=0, ppl=2.13, wps=596.9, ups=0.48, wpb=1245.2, bsz=160, num_updates=6240, lr=2.71945e-05, gnorm=4.683, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=13043
2023-06-27 05:51:04 - progress_bar.py[line:272] - INFO: epoch 003:    986 / 2637 loss=2.36, loss_v1=0, loss_v2=0, nll_loss=1.158, ntokens=1230.6, nsentences=160, sample_size=1230.6, sample_size_v1=0, sample_size_v2=0, ppl=2.23, wps=590, ups=0.48, wpb=1230.6, bsz=160, num_updates=6250, lr=2.71869e-05, gnorm=4.723, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=13064
2023-06-27 05:51:25 - progress_bar.py[line:272] - INFO: epoch 003:    996 / 2637 loss=2.327, loss_v1=0, loss_v2=0, nll_loss=1.123, ntokens=1256.3, nsentences=160, sample_size=1256.3, sample_size_v1=0, sample_size_v2=0, ppl=2.18, wps=602.3, ups=0.48, wpb=1256.3, bsz=160, num_updates=6260, lr=2.71793e-05, gnorm=5.034, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=13085
2023-06-27 05:51:46 - progress_bar.py[line:272] - INFO: epoch 003:   1006 / 2637 loss=2.347, loss_v1=0, loss_v2=0, nll_loss=1.149, ntokens=1245.3, nsentences=160, sample_size=1245.3, sample_size_v1=0, sample_size_v2=0, ppl=2.22, wps=597.4, ups=0.48, wpb=1245.3, bsz=160, num_updates=6270, lr=2.71718e-05, gnorm=5.323, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=13106
2023-06-27 05:52:06 - progress_bar.py[line:272] - INFO: epoch 003:   1016 / 2637 loss=2.353, loss_v1=0, loss_v2=0, nll_loss=1.15, ntokens=1228.7, nsentences=160, sample_size=1228.7, sample_size_v1=0, sample_size_v2=0, ppl=2.22, wps=590, ups=0.48, wpb=1228.7, bsz=160, num_updates=6280, lr=2.71642e-05, gnorm=6.001, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=13127
2023-06-27 05:52:27 - progress_bar.py[line:272] - INFO: epoch 003:   1026 / 2637 loss=2.333, loss_v1=0, loss_v2=0, nll_loss=1.129, ntokens=1261, nsentences=160, sample_size=1261, sample_size_v1=0, sample_size_v2=0, ppl=2.19, wps=604.5, ups=0.48, wpb=1261, bsz=160, num_updates=6290, lr=2.71567e-05, gnorm=4.653, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=13148
2023-06-27 05:52:48 - progress_bar.py[line:272] - INFO: epoch 003:   1036 / 2637 loss=2.338, loss_v1=0, loss_v2=0, nll_loss=1.137, ntokens=1254.2, nsentences=160, sample_size=1254.2, sample_size_v1=0, sample_size_v2=0, ppl=2.2, wps=601.1, ups=0.48, wpb=1254.2, bsz=160, num_updates=6300, lr=2.71491e-05, gnorm=4.981, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=13168
2023-06-27 05:53:09 - progress_bar.py[line:272] - INFO: epoch 003:   1046 / 2637 loss=2.335, loss_v1=0, loss_v2=0, nll_loss=1.133, ntokens=1247.9, nsentences=160, sample_size=1247.9, sample_size_v1=0, sample_size_v2=0, ppl=2.19, wps=599.8, ups=0.48, wpb=1247.9, bsz=160, num_updates=6310, lr=2.71415e-05, gnorm=4.328, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=13189
2023-06-27 05:53:30 - progress_bar.py[line:272] - INFO: epoch 003:   1056 / 2637 loss=2.334, loss_v1=0, loss_v2=0, nll_loss=1.131, ntokens=1257.4, nsentences=160, sample_size=1257.4, sample_size_v1=0, sample_size_v2=0, ppl=2.19, wps=603.2, ups=0.48, wpb=1257.4, bsz=160, num_updates=6320, lr=2.7134e-05, gnorm=4.753, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=13210
2023-06-27 05:53:51 - progress_bar.py[line:272] - INFO: epoch 003:   1066 / 2637 loss=2.337, loss_v1=0, loss_v2=0, nll_loss=1.135, ntokens=1227.3, nsentences=160, sample_size=1227.3, sample_size_v1=0, sample_size_v2=0, ppl=2.2, wps=589.7, ups=0.48, wpb=1227.3, bsz=160, num_updates=6330, lr=2.71264e-05, gnorm=4.187, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=13231
2023-06-27 05:54:11 - progress_bar.py[line:272] - INFO: epoch 003:   1076 / 2637 loss=2.328, loss_v1=0, loss_v2=0, nll_loss=1.124, ntokens=1234.8, nsentences=160, sample_size=1234.8, sample_size_v1=0, sample_size_v2=0, ppl=2.18, wps=593.2, ups=0.48, wpb=1234.8, bsz=160, num_updates=6340, lr=2.71188e-05, gnorm=4.571, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=13252
2023-06-27 05:54:32 - progress_bar.py[line:272] - INFO: epoch 003:   1086 / 2637 loss=2.342, loss_v1=0, loss_v2=0, nll_loss=1.141, ntokens=1269.8, nsentences=160, sample_size=1269.8, sample_size_v1=0, sample_size_v2=0, ppl=2.21, wps=609.5, ups=0.48, wpb=1269.8, bsz=160, num_updates=6350, lr=2.71113e-05, gnorm=4.32, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=13273
2023-06-27 05:54:53 - progress_bar.py[line:272] - INFO: epoch 003:   1096 / 2637 loss=2.337, loss_v1=0, loss_v2=0, nll_loss=1.135, ntokens=1241.1, nsentences=160, sample_size=1241.1, sample_size_v1=0, sample_size_v2=0, ppl=2.2, wps=595.4, ups=0.48, wpb=1241.1, bsz=160, num_updates=6360, lr=2.71037e-05, gnorm=4.804, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=13293
2023-06-27 05:55:14 - progress_bar.py[line:272] - INFO: epoch 003:   1106 / 2637 loss=2.333, loss_v1=0, loss_v2=0, nll_loss=1.13, ntokens=1233.4, nsentences=160, sample_size=1233.4, sample_size_v1=0, sample_size_v2=0, ppl=2.19, wps=592.7, ups=0.48, wpb=1233.4, bsz=160, num_updates=6370, lr=2.70961e-05, gnorm=4.619, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=13314
2023-06-27 05:55:35 - progress_bar.py[line:272] - INFO: epoch 003:   1116 / 2637 loss=2.333, loss_v1=0, loss_v2=0, nll_loss=1.13, ntokens=1235.5, nsentences=160, sample_size=1235.5, sample_size_v1=0, sample_size_v2=0, ppl=2.19, wps=592.6, ups=0.48, wpb=1235.5, bsz=160, num_updates=6380, lr=2.70886e-05, gnorm=4.522, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=13335
2023-06-27 05:55:56 - progress_bar.py[line:272] - INFO: epoch 003:   1126 / 2637 loss=2.335, loss_v1=0, loss_v2=0, nll_loss=1.131, ntokens=1243.4, nsentences=160, sample_size=1243.4, sample_size_v1=0, sample_size_v2=0, ppl=2.19, wps=597, ups=0.48, wpb=1243.4, bsz=160, num_updates=6390, lr=2.7081e-05, gnorm=4.426, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=13356
2023-06-27 05:56:16 - progress_bar.py[line:272] - INFO: epoch 003:   1136 / 2637 loss=2.34, loss_v1=0, loss_v2=0, nll_loss=1.14, ntokens=1245.7, nsentences=160, sample_size=1245.7, sample_size_v1=0, sample_size_v2=0, ppl=2.2, wps=598.4, ups=0.48, wpb=1245.7, bsz=160, num_updates=6400, lr=2.70734e-05, gnorm=4.904, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=13377
2023-06-27 05:56:37 - progress_bar.py[line:272] - INFO: epoch 003:   1146 / 2637 loss=2.331, loss_v1=0, loss_v2=0, nll_loss=1.13, ntokens=1270.4, nsentences=160, sample_size=1270.4, sample_size_v1=0, sample_size_v2=0, ppl=2.19, wps=609.4, ups=0.48, wpb=1270.4, bsz=160, num_updates=6410, lr=2.70659e-05, gnorm=5.619, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=13398
2023-06-27 05:56:58 - progress_bar.py[line:272] - INFO: epoch 003:   1156 / 2637 loss=2.356, loss_v1=0, loss_v2=0, nll_loss=1.155, ntokens=1237, nsentences=160, sample_size=1237, sample_size_v1=0, sample_size_v2=0, ppl=2.23, wps=594.4, ups=0.48, wpb=1237, bsz=160, num_updates=6420, lr=2.70583e-05, gnorm=4.467, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=13418
2023-06-27 05:57:19 - progress_bar.py[line:272] - INFO: epoch 003:   1166 / 2637 loss=2.328, loss_v1=0, loss_v2=0, nll_loss=1.125, ntokens=1252.7, nsentences=160, sample_size=1252.7, sample_size_v1=0, sample_size_v2=0, ppl=2.18, wps=601.1, ups=0.48, wpb=1252.7, bsz=160, num_updates=6430, lr=2.70508e-05, gnorm=4.667, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=13439
2023-06-27 05:57:40 - progress_bar.py[line:272] - INFO: epoch 003:   1176 / 2637 loss=2.334, loss_v1=0, loss_v2=0, nll_loss=1.133, ntokens=1241.2, nsentences=160, sample_size=1241.2, sample_size_v1=0, sample_size_v2=0, ppl=2.19, wps=595.3, ups=0.48, wpb=1241.2, bsz=160, num_updates=6440, lr=2.70432e-05, gnorm=4.597, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=13460
2023-06-27 05:58:01 - progress_bar.py[line:272] - INFO: epoch 003:   1186 / 2637 loss=2.319, loss_v1=0, loss_v2=0, nll_loss=1.116, ntokens=1260, nsentences=160, sample_size=1260, sample_size_v1=0, sample_size_v2=0, ppl=2.17, wps=603.8, ups=0.48, wpb=1260, bsz=160, num_updates=6450, lr=2.70356e-05, gnorm=5.063, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=13481
2023-06-27 05:58:22 - progress_bar.py[line:272] - INFO: epoch 003:   1196 / 2637 loss=2.354, loss_v1=0, loss_v2=0, nll_loss=1.152, ntokens=1256.9, nsentences=160, sample_size=1256.9, sample_size_v1=0, sample_size_v2=0, ppl=2.22, wps=603.1, ups=0.48, wpb=1256.9, bsz=160, num_updates=6460, lr=2.70281e-05, gnorm=5.229, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=13502
2023-06-27 05:58:42 - progress_bar.py[line:272] - INFO: epoch 003:   1206 / 2637 loss=2.34, loss_v1=0, loss_v2=0, nll_loss=1.141, ntokens=1246.1, nsentences=160, sample_size=1246.1, sample_size_v1=0, sample_size_v2=0, ppl=2.21, wps=597.5, ups=0.48, wpb=1246.1, bsz=160, num_updates=6470, lr=2.70205e-05, gnorm=5.021, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=13523
2023-06-27 05:59:03 - progress_bar.py[line:272] - INFO: epoch 003:   1216 / 2637 loss=2.338, loss_v1=0, loss_v2=0, nll_loss=1.134, ntokens=1259.3, nsentences=160, sample_size=1259.3, sample_size_v1=0, sample_size_v2=0, ppl=2.19, wps=603.9, ups=0.48, wpb=1259.3, bsz=160, num_updates=6480, lr=2.70129e-05, gnorm=5.369, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=13544
2023-06-27 05:59:24 - progress_bar.py[line:272] - INFO: epoch 003:   1226 / 2637 loss=2.335, loss_v1=0, loss_v2=0, nll_loss=1.133, ntokens=1251.8, nsentences=160, sample_size=1251.8, sample_size_v1=0, sample_size_v2=0, ppl=2.19, wps=600.3, ups=0.48, wpb=1251.8, bsz=160, num_updates=6490, lr=2.70054e-05, gnorm=5.019, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=13564
2023-06-27 05:59:45 - progress_bar.py[line:272] - INFO: epoch 003:   1236 / 2637 loss=2.337, loss_v1=0, loss_v2=0, nll_loss=1.134, ntokens=1227.3, nsentences=160, sample_size=1227.3, sample_size_v1=0, sample_size_v2=0, ppl=2.19, wps=588.2, ups=0.48, wpb=1227.3, bsz=160, num_updates=6500, lr=2.69978e-05, gnorm=4.061, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=13585
2023-06-27 06:00:06 - progress_bar.py[line:272] - INFO: epoch 003:   1246 / 2637 loss=2.332, loss_v1=0, loss_v2=0, nll_loss=1.129, ntokens=1233.2, nsentences=160, sample_size=1233.2, sample_size_v1=0, sample_size_v2=0, ppl=2.19, wps=591.5, ups=0.48, wpb=1233.2, bsz=160, num_updates=6510, lr=2.69902e-05, gnorm=4.552, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=13606
2023-06-27 06:00:27 - progress_bar.py[line:272] - INFO: epoch 003:   1256 / 2637 loss=2.337, loss_v1=0, loss_v2=0, nll_loss=1.135, ntokens=1242.1, nsentences=160, sample_size=1242.1, sample_size_v1=0, sample_size_v2=0, ppl=2.2, wps=595.4, ups=0.48, wpb=1242.1, bsz=160, num_updates=6520, lr=2.69827e-05, gnorm=4.126, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=13627
2023-06-27 06:00:48 - progress_bar.py[line:272] - INFO: epoch 003:   1266 / 2637 loss=2.344, loss_v1=0, loss_v2=0, nll_loss=1.141, ntokens=1254, nsentences=160, sample_size=1254, sample_size_v1=0, sample_size_v2=0, ppl=2.21, wps=601.2, ups=0.48, wpb=1254, bsz=160, num_updates=6530, lr=2.69751e-05, gnorm=4.824, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=13648
2023-06-27 06:01:08 - progress_bar.py[line:272] - INFO: epoch 003:   1276 / 2637 loss=2.369, loss_v1=0, loss_v2=0, nll_loss=1.169, ntokens=1247.1, nsentences=160, sample_size=1247.1, sample_size_v1=0, sample_size_v2=0, ppl=2.25, wps=597.9, ups=0.48, wpb=1247.1, bsz=160, num_updates=6540, lr=2.69675e-05, gnorm=3.989, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=13669
2023-06-27 06:01:29 - progress_bar.py[line:272] - INFO: epoch 003:   1286 / 2637 loss=2.33, loss_v1=0, loss_v2=0, nll_loss=1.128, ntokens=1249.8, nsentences=160, sample_size=1249.8, sample_size_v1=0, sample_size_v2=0, ppl=2.19, wps=598.9, ups=0.48, wpb=1249.8, bsz=160, num_updates=6550, lr=2.696e-05, gnorm=4.082, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=13690
2023-06-27 06:01:50 - progress_bar.py[line:272] - INFO: epoch 003:   1296 / 2637 loss=2.347, loss_v1=0, loss_v2=0, nll_loss=1.145, ntokens=1238.2, nsentences=160, sample_size=1238.2, sample_size_v1=0, sample_size_v2=0, ppl=2.21, wps=593.4, ups=0.48, wpb=1238.2, bsz=160, num_updates=6560, lr=2.69524e-05, gnorm=4.102, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=13710
2023-06-27 06:02:11 - progress_bar.py[line:272] - INFO: epoch 003:   1306 / 2637 loss=2.336, loss_v1=0, loss_v2=0, nll_loss=1.133, ntokens=1253.5, nsentences=160, sample_size=1253.5, sample_size_v1=0, sample_size_v2=0, ppl=2.19, wps=600.1, ups=0.48, wpb=1253.5, bsz=160, num_updates=6570, lr=2.69449e-05, gnorm=4.871, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=13731
2023-06-27 06:02:32 - progress_bar.py[line:272] - INFO: epoch 003:   1316 / 2637 loss=2.332, loss_v1=0, loss_v2=0, nll_loss=1.129, ntokens=1233.8, nsentences=160, sample_size=1233.8, sample_size_v1=0, sample_size_v2=0, ppl=2.19, wps=591.8, ups=0.48, wpb=1233.8, bsz=160, num_updates=6580, lr=2.69373e-05, gnorm=4.975, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=13752
2023-06-27 06:02:53 - progress_bar.py[line:272] - INFO: epoch 003:   1326 / 2637 loss=2.327, loss_v1=0, loss_v2=0, nll_loss=1.126, ntokens=1235, nsentences=160, sample_size=1235, sample_size_v1=0, sample_size_v2=0, ppl=2.18, wps=591.9, ups=0.48, wpb=1235, bsz=160, num_updates=6590, lr=2.69297e-05, gnorm=5.261, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=13773
2023-06-27 06:03:14 - progress_bar.py[line:272] - INFO: epoch 003:   1336 / 2637 loss=2.345, loss_v1=0, loss_v2=0, nll_loss=1.141, ntokens=1231.3, nsentences=160, sample_size=1231.3, sample_size_v1=0, sample_size_v2=0, ppl=2.21, wps=590.3, ups=0.48, wpb=1231.3, bsz=160, num_updates=6600, lr=2.69222e-05, gnorm=5.497, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=13794
2023-06-27 06:03:35 - progress_bar.py[line:272] - INFO: epoch 003:   1346 / 2637 loss=2.347, loss_v1=0, loss_v2=0, nll_loss=1.147, ntokens=1225.3, nsentences=160, sample_size=1225.3, sample_size_v1=0, sample_size_v2=0, ppl=2.21, wps=587.8, ups=0.48, wpb=1225.3, bsz=160, num_updates=6610, lr=2.69146e-05, gnorm=5.741, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=13815
2023-06-27 06:03:55 - progress_bar.py[line:272] - INFO: epoch 003:   1356 / 2637 loss=2.333, loss_v1=0, loss_v2=0, nll_loss=1.128, ntokens=1241.8, nsentences=160, sample_size=1241.8, sample_size_v1=0, sample_size_v2=0, ppl=2.19, wps=595.8, ups=0.48, wpb=1241.8, bsz=160, num_updates=6620, lr=2.6907e-05, gnorm=5.053, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=13836
2023-06-27 06:04:16 - progress_bar.py[line:272] - INFO: epoch 003:   1366 / 2637 loss=2.359, loss_v1=0, loss_v2=0, nll_loss=1.16, ntokens=1234.5, nsentences=160, sample_size=1234.5, sample_size_v1=0, sample_size_v2=0, ppl=2.23, wps=591.9, ups=0.48, wpb=1234.5, bsz=160, num_updates=6630, lr=2.68995e-05, gnorm=5.777, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=13857
2023-06-27 06:04:37 - progress_bar.py[line:272] - INFO: epoch 003:   1376 / 2637 loss=2.366, loss_v1=0, loss_v2=0, nll_loss=1.168, ntokens=1235.8, nsentences=160, sample_size=1235.8, sample_size_v1=0, sample_size_v2=0, ppl=2.25, wps=592.3, ups=0.48, wpb=1235.8, bsz=160, num_updates=6640, lr=2.68919e-05, gnorm=5.445, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=13877
2023-06-27 06:04:58 - progress_bar.py[line:272] - INFO: epoch 003:   1386 / 2637 loss=2.344, loss_v1=0, loss_v2=0, nll_loss=1.144, ntokens=1257.9, nsentences=160, sample_size=1257.9, sample_size_v1=0, sample_size_v2=0, ppl=2.21, wps=602.6, ups=0.48, wpb=1257.9, bsz=160, num_updates=6650, lr=2.68843e-05, gnorm=5.395, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=13898
2023-06-27 06:05:19 - progress_bar.py[line:272] - INFO: epoch 003:   1396 / 2637 loss=2.343, loss_v1=0, loss_v2=0, nll_loss=1.143, ntokens=1273.1, nsentences=160, sample_size=1273.1, sample_size_v1=0, sample_size_v2=0, ppl=2.21, wps=609.8, ups=0.48, wpb=1273.1, bsz=160, num_updates=6660, lr=2.68768e-05, gnorm=5.126, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=13919
2023-06-27 06:05:40 - progress_bar.py[line:272] - INFO: epoch 003:   1406 / 2637 loss=2.346, loss_v1=0, loss_v2=0, nll_loss=1.144, ntokens=1272.1, nsentences=160, sample_size=1272.1, sample_size_v1=0, sample_size_v2=0, ppl=2.21, wps=609.8, ups=0.48, wpb=1272.1, bsz=160, num_updates=6670, lr=2.68692e-05, gnorm=4.439, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=13940
2023-06-27 06:06:01 - progress_bar.py[line:272] - INFO: epoch 003:   1416 / 2637 loss=2.348, loss_v1=0, loss_v2=0, nll_loss=1.146, ntokens=1265, nsentences=160, sample_size=1265, sample_size_v1=0, sample_size_v2=0, ppl=2.21, wps=606.2, ups=0.48, wpb=1265, bsz=160, num_updates=6680, lr=2.68617e-05, gnorm=4.291, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=13961
2023-06-27 06:06:21 - progress_bar.py[line:272] - INFO: epoch 003:   1426 / 2637 loss=2.333, loss_v1=0, loss_v2=0, nll_loss=1.131, ntokens=1282.7, nsentences=160, sample_size=1282.7, sample_size_v1=0, sample_size_v2=0, ppl=2.19, wps=614.6, ups=0.48, wpb=1282.7, bsz=160, num_updates=6690, lr=2.68541e-05, gnorm=4.701, clip=100, loss_scale=128, train_wall=21, gb_free=8.9, wall=13982
2023-06-27 06:06:42 - progress_bar.py[line:272] - INFO: epoch 003:   1436 / 2637 loss=2.335, loss_v1=0, loss_v2=0, nll_loss=1.134, ntokens=1268.9, nsentences=160, sample_size=1268.9, sample_size_v1=0, sample_size_v2=0, ppl=2.19, wps=608.5, ups=0.48, wpb=1268.9, bsz=160, num_updates=6700, lr=2.68465e-05, gnorm=5.453, clip=100, loss_scale=128, train_wall=21, gb_free=8.9, wall=14003
2023-06-27 06:06:49 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2023-06-27 06:07:05 - progress_bar.py[line:272] - INFO: epoch 003:   1447 / 2637 loss=2.341, loss_v1=0, loss_v2=0, nll_loss=1.138, ntokens=1288.9, nsentences=160, sample_size=1288.9, sample_size_v1=0, sample_size_v2=0, ppl=2.2, wps=561.9, ups=0.44, wpb=1288.9, bsz=160, num_updates=6710, lr=2.6839e-05, gnorm=4.513, clip=100, loss_scale=64, train_wall=23, gb_free=8.9, wall=14026
2023-06-27 06:07:26 - progress_bar.py[line:272] - INFO: epoch 003:   1457 / 2637 loss=2.347, loss_v1=0, loss_v2=0, nll_loss=1.147, ntokens=1279.5, nsentences=160, sample_size=1279.5, sample_size_v1=0, sample_size_v2=0, ppl=2.21, wps=613, ups=0.48, wpb=1279.5, bsz=160, num_updates=6720, lr=2.68314e-05, gnorm=5.173, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=14046
2023-06-27 06:07:47 - progress_bar.py[line:272] - INFO: epoch 003:   1467 / 2637 loss=2.345, loss_v1=0, loss_v2=0, nll_loss=1.142, ntokens=1277.1, nsentences=160, sample_size=1277.1, sample_size_v1=0, sample_size_v2=0, ppl=2.21, wps=612.3, ups=0.48, wpb=1277.1, bsz=160, num_updates=6730, lr=2.68238e-05, gnorm=4.2, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=14067
2023-06-27 06:08:08 - progress_bar.py[line:272] - INFO: epoch 003:   1477 / 2637 loss=2.345, loss_v1=0, loss_v2=0, nll_loss=1.144, ntokens=1268.6, nsentences=160, sample_size=1268.6, sample_size_v1=0, sample_size_v2=0, ppl=2.21, wps=607.7, ups=0.48, wpb=1268.6, bsz=160, num_updates=6740, lr=2.68163e-05, gnorm=4.615, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=14088
2023-06-27 06:08:29 - progress_bar.py[line:272] - INFO: epoch 003:   1487 / 2637 loss=2.357, loss_v1=0, loss_v2=0, nll_loss=1.16, ntokens=1277.2, nsentences=160, sample_size=1277.2, sample_size_v1=0, sample_size_v2=0, ppl=2.23, wps=611.3, ups=0.48, wpb=1277.2, bsz=160, num_updates=6750, lr=2.68087e-05, gnorm=4.637, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=14109
2023-06-27 06:08:50 - progress_bar.py[line:272] - INFO: epoch 003:   1497 / 2637 loss=2.34, loss_v1=0, loss_v2=0, nll_loss=1.139, ntokens=1293.8, nsentences=160, sample_size=1293.8, sample_size_v1=0, sample_size_v2=0, ppl=2.2, wps=620, ups=0.48, wpb=1293.8, bsz=160, num_updates=6760, lr=2.68011e-05, gnorm=4.341, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=14130
2023-06-27 06:09:11 - progress_bar.py[line:272] - INFO: epoch 003:   1507 / 2637 loss=2.359, loss_v1=0, loss_v2=0, nll_loss=1.159, ntokens=1274.5, nsentences=160, sample_size=1274.5, sample_size_v1=0, sample_size_v2=0, ppl=2.23, wps=610.8, ups=0.48, wpb=1274.5, bsz=160, num_updates=6770, lr=2.67936e-05, gnorm=4.834, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=14151
2023-06-27 06:09:31 - progress_bar.py[line:272] - INFO: epoch 003:   1517 / 2637 loss=2.346, loss_v1=0, loss_v2=0, nll_loss=1.145, ntokens=1265.8, nsentences=160, sample_size=1265.8, sample_size_v1=0, sample_size_v2=0, ppl=2.21, wps=606.6, ups=0.48, wpb=1265.8, bsz=160, num_updates=6780, lr=2.6786e-05, gnorm=4.622, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=14172
2023-06-27 06:09:52 - progress_bar.py[line:272] - INFO: epoch 003:   1527 / 2637 loss=2.374, loss_v1=0, loss_v2=0, nll_loss=1.175, ntokens=1266.1, nsentences=160, sample_size=1266.1, sample_size_v1=0, sample_size_v2=0, ppl=2.26, wps=606.6, ups=0.48, wpb=1266.1, bsz=160, num_updates=6790, lr=2.67784e-05, gnorm=4.45, clip=100, loss_scale=64, train_wall=21, gb_free=8.8, wall=14193
2023-06-27 06:10:13 - progress_bar.py[line:272] - INFO: epoch 003:   1537 / 2637 loss=2.36, loss_v1=0, loss_v2=0, nll_loss=1.162, ntokens=1264.8, nsentences=160, sample_size=1264.8, sample_size_v1=0, sample_size_v2=0, ppl=2.24, wps=606.1, ups=0.48, wpb=1264.8, bsz=160, num_updates=6800, lr=2.67709e-05, gnorm=4.224, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=14213
2023-06-27 06:10:34 - progress_bar.py[line:272] - INFO: epoch 003:   1547 / 2637 loss=2.365, loss_v1=0, loss_v2=0, nll_loss=1.166, ntokens=1268.9, nsentences=160, sample_size=1268.9, sample_size_v1=0, sample_size_v2=0, ppl=2.24, wps=609.4, ups=0.48, wpb=1268.9, bsz=160, num_updates=6810, lr=2.67633e-05, gnorm=4.378, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=14234
2023-06-27 06:10:55 - progress_bar.py[line:272] - INFO: epoch 003:   1557 / 2637 loss=2.363, loss_v1=0, loss_v2=0, nll_loss=1.165, ntokens=1276.2, nsentences=160, sample_size=1276.2, sample_size_v1=0, sample_size_v2=0, ppl=2.24, wps=612.5, ups=0.48, wpb=1276.2, bsz=160, num_updates=6820, lr=2.67558e-05, gnorm=4.521, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=14255
2023-06-27 06:11:16 - progress_bar.py[line:272] - INFO: epoch 003:   1567 / 2637 loss=2.337, loss_v1=0, loss_v2=0, nll_loss=1.133, ntokens=1263.8, nsentences=160, sample_size=1263.8, sample_size_v1=0, sample_size_v2=0, ppl=2.19, wps=606, ups=0.48, wpb=1263.8, bsz=160, num_updates=6830, lr=2.67482e-05, gnorm=4.428, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=14276
2023-06-27 06:11:37 - progress_bar.py[line:272] - INFO: epoch 003:   1577 / 2637 loss=2.336, loss_v1=0, loss_v2=0, nll_loss=1.133, ntokens=1268.3, nsentences=160, sample_size=1268.3, sample_size_v1=0, sample_size_v2=0, ppl=2.19, wps=608.5, ups=0.48, wpb=1268.3, bsz=160, num_updates=6840, lr=2.67406e-05, gnorm=4.333, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=14297
2023-06-27 06:11:57 - progress_bar.py[line:272] - INFO: epoch 003:   1587 / 2637 loss=2.357, loss_v1=0, loss_v2=0, nll_loss=1.155, ntokens=1268.2, nsentences=160, sample_size=1268.2, sample_size_v1=0, sample_size_v2=0, ppl=2.23, wps=608.1, ups=0.48, wpb=1268.2, bsz=160, num_updates=6850, lr=2.67331e-05, gnorm=4.332, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=14318
2023-06-27 06:12:18 - progress_bar.py[line:272] - INFO: epoch 003:   1597 / 2637 loss=2.353, loss_v1=0, loss_v2=0, nll_loss=1.154, ntokens=1271.7, nsentences=160, sample_size=1271.7, sample_size_v1=0, sample_size_v2=0, ppl=2.23, wps=610.3, ups=0.48, wpb=1271.7, bsz=160, num_updates=6860, lr=2.67255e-05, gnorm=4.515, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=14338
2023-06-27 06:12:39 - progress_bar.py[line:272] - INFO: epoch 003:   1607 / 2637 loss=2.37, loss_v1=0, loss_v2=0, nll_loss=1.172, ntokens=1256.6, nsentences=160, sample_size=1256.6, sample_size_v1=0, sample_size_v2=0, ppl=2.25, wps=602.3, ups=0.48, wpb=1256.6, bsz=160, num_updates=6870, lr=2.67179e-05, gnorm=4.41, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=14359
2023-06-27 06:13:00 - progress_bar.py[line:272] - INFO: epoch 003:   1617 / 2637 loss=2.354, loss_v1=0, loss_v2=0, nll_loss=1.155, ntokens=1265, nsentences=160, sample_size=1265, sample_size_v1=0, sample_size_v2=0, ppl=2.23, wps=607.2, ups=0.48, wpb=1265, bsz=160, num_updates=6880, lr=2.67104e-05, gnorm=4.589, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=14380
2023-06-27 06:13:21 - progress_bar.py[line:272] - INFO: epoch 003:   1627 / 2637 loss=2.38, loss_v1=0, loss_v2=0, nll_loss=1.181, ntokens=1263.6, nsentences=160, sample_size=1263.6, sample_size_v1=0, sample_size_v2=0, ppl=2.27, wps=606.7, ups=0.48, wpb=1263.6, bsz=160, num_updates=6890, lr=2.67028e-05, gnorm=4.92, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=14401
2023-06-27 06:13:42 - progress_bar.py[line:272] - INFO: epoch 003:   1637 / 2637 loss=2.333, loss_v1=0, loss_v2=0, nll_loss=1.13, ntokens=1267.7, nsentences=159.9, sample_size=1267.7, sample_size_v1=0, sample_size_v2=0, ppl=2.19, wps=608.6, ups=0.48, wpb=1267.7, bsz=159.9, num_updates=6900, lr=2.66952e-05, gnorm=4.495, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=14422
2023-06-27 06:14:02 - progress_bar.py[line:272] - INFO: epoch 003:   1647 / 2637 loss=2.345, loss_v1=0, loss_v2=0, nll_loss=1.145, ntokens=1267.2, nsentences=160, sample_size=1267.2, sample_size_v1=0, sample_size_v2=0, ppl=2.21, wps=608.1, ups=0.48, wpb=1267.2, bsz=160, num_updates=6910, lr=2.66877e-05, gnorm=4.555, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=14443
2023-06-27 06:14:23 - progress_bar.py[line:272] - INFO: epoch 003:   1657 / 2637 loss=2.382, loss_v1=0, loss_v2=0, nll_loss=1.183, ntokens=1258.2, nsentences=160, sample_size=1258.2, sample_size_v1=0, sample_size_v2=0, ppl=2.27, wps=603.5, ups=0.48, wpb=1258.2, bsz=160, num_updates=6920, lr=2.66801e-05, gnorm=5.267, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=14464
2023-06-27 06:14:44 - progress_bar.py[line:272] - INFO: epoch 003:   1667 / 2637 loss=2.346, loss_v1=0, loss_v2=0, nll_loss=1.146, ntokens=1274.2, nsentences=160, sample_size=1274.2, sample_size_v1=0, sample_size_v2=0, ppl=2.21, wps=610.7, ups=0.48, wpb=1274.2, bsz=160, num_updates=6930, lr=2.66725e-05, gnorm=5.323, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=14484
2023-06-27 06:15:05 - progress_bar.py[line:272] - INFO: epoch 003:   1677 / 2637 loss=2.342, loss_v1=0, loss_v2=0, nll_loss=1.139, ntokens=1258.9, nsentences=160, sample_size=1258.9, sample_size_v1=0, sample_size_v2=0, ppl=2.2, wps=603, ups=0.48, wpb=1258.9, bsz=160, num_updates=6940, lr=2.6665e-05, gnorm=4.842, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=14505
2023-06-27 06:15:26 - progress_bar.py[line:272] - INFO: epoch 003:   1687 / 2637 loss=2.34, loss_v1=0, loss_v2=0, nll_loss=1.138, ntokens=1274.4, nsentences=160, sample_size=1274.4, sample_size_v1=0, sample_size_v2=0, ppl=2.2, wps=610.6, ups=0.48, wpb=1274.4, bsz=160, num_updates=6950, lr=2.66574e-05, gnorm=5.408, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=14526
2023-06-27 06:15:47 - progress_bar.py[line:272] - INFO: epoch 003:   1697 / 2637 loss=2.352, loss_v1=0, loss_v2=0, nll_loss=1.152, ntokens=1272.3, nsentences=160, sample_size=1272.3, sample_size_v1=0, sample_size_v2=0, ppl=2.22, wps=610.2, ups=0.48, wpb=1272.3, bsz=160, num_updates=6960, lr=2.66499e-05, gnorm=4.928, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=14547
2023-06-27 06:16:08 - progress_bar.py[line:272] - INFO: epoch 003:   1707 / 2637 loss=2.33, loss_v1=0, loss_v2=0, nll_loss=1.125, ntokens=1280.9, nsentences=160, sample_size=1280.9, sample_size_v1=0, sample_size_v2=0, ppl=2.18, wps=614.6, ups=0.48, wpb=1280.9, bsz=160, num_updates=6970, lr=2.66423e-05, gnorm=5.485, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=14568
2023-06-27 06:16:29 - progress_bar.py[line:272] - INFO: epoch 003:   1717 / 2637 loss=2.35, loss_v1=0, loss_v2=0, nll_loss=1.15, ntokens=1275.8, nsentences=160, sample_size=1275.8, sample_size_v1=0, sample_size_v2=0, ppl=2.22, wps=610.3, ups=0.48, wpb=1275.8, bsz=160, num_updates=6980, lr=2.66347e-05, gnorm=5.534, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=14589
2023-06-27 06:16:49 - progress_bar.py[line:272] - INFO: epoch 003:   1727 / 2637 loss=2.353, loss_v1=0, loss_v2=0, nll_loss=1.153, ntokens=1281.8, nsentences=160, sample_size=1281.8, sample_size_v1=0, sample_size_v2=0, ppl=2.22, wps=614.5, ups=0.48, wpb=1281.8, bsz=160, num_updates=6990, lr=2.66272e-05, gnorm=5.109, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=14610
2023-06-27 06:17:10 - progress_bar.py[line:272] - INFO: epoch 003:   1737 / 2637 loss=2.338, loss_v1=0, loss_v2=0, nll_loss=1.137, ntokens=1257.3, nsentences=160, sample_size=1257.3, sample_size_v1=0, sample_size_v2=0, ppl=2.2, wps=603.1, ups=0.48, wpb=1257.3, bsz=160, num_updates=7000, lr=2.66196e-05, gnorm=4.887, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=14630
2023-06-27 06:17:31 - progress_bar.py[line:272] - INFO: epoch 003:   1747 / 2637 loss=2.37, loss_v1=0, loss_v2=0, nll_loss=1.17, ntokens=1282.9, nsentences=160, sample_size=1282.9, sample_size_v1=0, sample_size_v2=0, ppl=2.25, wps=615.1, ups=0.48, wpb=1282.9, bsz=160, num_updates=7010, lr=2.6612e-05, gnorm=5.136, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=14651
2023-06-27 06:17:52 - progress_bar.py[line:272] - INFO: epoch 003:   1757 / 2637 loss=2.336, loss_v1=0, loss_v2=0, nll_loss=1.133, ntokens=1262.5, nsentences=160, sample_size=1262.5, sample_size_v1=0, sample_size_v2=0, ppl=2.19, wps=605.3, ups=0.48, wpb=1262.5, bsz=160, num_updates=7020, lr=2.66045e-05, gnorm=4.665, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=14672
2023-06-27 06:18:13 - progress_bar.py[line:272] - INFO: epoch 003:   1767 / 2637 loss=2.348, loss_v1=0, loss_v2=0, nll_loss=1.146, ntokens=1279.2, nsentences=160, sample_size=1279.2, sample_size_v1=0, sample_size_v2=0, ppl=2.21, wps=612.8, ups=0.48, wpb=1279.2, bsz=160, num_updates=7030, lr=2.65969e-05, gnorm=4.328, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=14693
2023-06-27 06:18:34 - progress_bar.py[line:272] - INFO: epoch 003:   1777 / 2637 loss=2.345, loss_v1=0, loss_v2=0, nll_loss=1.146, ntokens=1269.1, nsentences=160, sample_size=1269.1, sample_size_v1=0, sample_size_v2=0, ppl=2.21, wps=606.1, ups=0.48, wpb=1269.1, bsz=160, num_updates=7040, lr=2.65893e-05, gnorm=5.465, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=14714
2023-06-27 06:18:55 - progress_bar.py[line:272] - INFO: epoch 003:   1787 / 2637 loss=2.346, loss_v1=0, loss_v2=0, nll_loss=1.145, ntokens=1305, nsentences=160, sample_size=1305, sample_size_v1=0, sample_size_v2=0, ppl=2.21, wps=625.1, ups=0.48, wpb=1305, bsz=160, num_updates=7050, lr=2.65818e-05, gnorm=4.851, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=14735
2023-06-27 06:19:16 - progress_bar.py[line:272] - INFO: epoch 003:   1797 / 2637 loss=2.378, loss_v1=0, loss_v2=0, nll_loss=1.179, ntokens=1263.7, nsentences=160, sample_size=1263.7, sample_size_v1=0, sample_size_v2=0, ppl=2.26, wps=605.6, ups=0.48, wpb=1263.7, bsz=160, num_updates=7060, lr=2.65742e-05, gnorm=5.191, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=14756
2023-06-27 06:19:36 - progress_bar.py[line:272] - INFO: epoch 003:   1807 / 2637 loss=2.34, loss_v1=0, loss_v2=0, nll_loss=1.138, ntokens=1277.9, nsentences=160, sample_size=1277.9, sample_size_v1=0, sample_size_v2=0, ppl=2.2, wps=611.9, ups=0.48, wpb=1277.9, bsz=160, num_updates=7070, lr=2.65667e-05, gnorm=5.286, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=14777
2023-06-27 06:19:57 - progress_bar.py[line:272] - INFO: epoch 003:   1817 / 2637 loss=2.329, loss_v1=0, loss_v2=0, nll_loss=1.128, ntokens=1261.7, nsentences=160, sample_size=1261.7, sample_size_v1=0, sample_size_v2=0, ppl=2.18, wps=604.6, ups=0.48, wpb=1261.7, bsz=160, num_updates=7080, lr=2.65591e-05, gnorm=5.278, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=14798
2023-06-27 06:20:18 - progress_bar.py[line:272] - INFO: epoch 003:   1827 / 2637 loss=2.341, loss_v1=0, loss_v2=0, nll_loss=1.14, ntokens=1271.1, nsentences=160, sample_size=1271.1, sample_size_v1=0, sample_size_v2=0, ppl=2.2, wps=608.9, ups=0.48, wpb=1271.1, bsz=160, num_updates=7090, lr=2.65515e-05, gnorm=5.537, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=14818
2023-06-27 06:20:39 - progress_bar.py[line:272] - INFO: epoch 003:   1837 / 2637 loss=2.334, loss_v1=0, loss_v2=0, nll_loss=1.129, ntokens=1295.5, nsentences=160, sample_size=1295.5, sample_size_v1=0, sample_size_v2=0, ppl=2.19, wps=620.7, ups=0.48, wpb=1295.5, bsz=160, num_updates=7100, lr=2.6544e-05, gnorm=4.909, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=14839
2023-06-27 06:21:00 - progress_bar.py[line:272] - INFO: epoch 003:   1847 / 2637 loss=2.326, loss_v1=0, loss_v2=0, nll_loss=1.125, ntokens=1288.7, nsentences=160, sample_size=1288.7, sample_size_v1=0, sample_size_v2=0, ppl=2.18, wps=617.8, ups=0.48, wpb=1288.7, bsz=160, num_updates=7110, lr=2.65364e-05, gnorm=5.456, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=14860
2023-06-27 06:21:21 - progress_bar.py[line:272] - INFO: epoch 003:   1857 / 2637 loss=2.344, loss_v1=0, loss_v2=0, nll_loss=1.142, ntokens=1259, nsentences=160, sample_size=1259, sample_size_v1=0, sample_size_v2=0, ppl=2.21, wps=603.5, ups=0.48, wpb=1259, bsz=160, num_updates=7120, lr=2.65288e-05, gnorm=5.359, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=14881
2023-06-27 06:21:42 - progress_bar.py[line:272] - INFO: epoch 003:   1867 / 2637 loss=2.33, loss_v1=0, loss_v2=0, nll_loss=1.126, ntokens=1273.1, nsentences=160, sample_size=1273.1, sample_size_v1=0, sample_size_v2=0, ppl=2.18, wps=610.4, ups=0.48, wpb=1273.1, bsz=160, num_updates=7130, lr=2.65213e-05, gnorm=5.277, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=14902
2023-06-27 06:22:02 - progress_bar.py[line:272] - INFO: epoch 003:   1877 / 2637 loss=2.344, loss_v1=0, loss_v2=0, nll_loss=1.143, ntokens=1275.1, nsentences=160, sample_size=1275.1, sample_size_v1=0, sample_size_v2=0, ppl=2.21, wps=612, ups=0.48, wpb=1275.1, bsz=160, num_updates=7140, lr=2.65137e-05, gnorm=5.654, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=14923
2023-06-27 06:22:23 - progress_bar.py[line:272] - INFO: epoch 003:   1887 / 2637 loss=2.311, loss_v1=0, loss_v2=0, nll_loss=1.104, ntokens=1276.2, nsentences=160, sample_size=1276.2, sample_size_v1=0, sample_size_v2=0, ppl=2.15, wps=612, ups=0.48, wpb=1276.2, bsz=160, num_updates=7150, lr=2.65061e-05, gnorm=4.873, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=14944
2023-06-27 06:22:44 - progress_bar.py[line:272] - INFO: epoch 003:   1897 / 2637 loss=2.333, loss_v1=0, loss_v2=0, nll_loss=1.13, ntokens=1287.8, nsentences=160, sample_size=1287.8, sample_size_v1=0, sample_size_v2=0, ppl=2.19, wps=617.5, ups=0.48, wpb=1287.8, bsz=160, num_updates=7160, lr=2.64986e-05, gnorm=4.903, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=14964
2023-06-27 06:23:05 - progress_bar.py[line:272] - INFO: epoch 003:   1907 / 2637 loss=2.338, loss_v1=0, loss_v2=0, nll_loss=1.137, ntokens=1269.9, nsentences=160, sample_size=1269.9, sample_size_v1=0, sample_size_v2=0, ppl=2.2, wps=608.8, ups=0.48, wpb=1269.9, bsz=160, num_updates=7170, lr=2.6491e-05, gnorm=5.221, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=14985
2023-06-27 06:23:26 - progress_bar.py[line:272] - INFO: epoch 003:   1917 / 2637 loss=2.317, loss_v1=0, loss_v2=0, nll_loss=1.113, ntokens=1273.7, nsentences=160, sample_size=1273.7, sample_size_v1=0, sample_size_v2=0, ppl=2.16, wps=610.8, ups=0.48, wpb=1273.7, bsz=160, num_updates=7180, lr=2.64834e-05, gnorm=4.803, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=15006
2023-06-27 06:23:47 - progress_bar.py[line:272] - INFO: epoch 003:   1927 / 2637 loss=2.376, loss_v1=0, loss_v2=0, nll_loss=1.177, ntokens=1269.2, nsentences=160, sample_size=1269.2, sample_size_v1=0, sample_size_v2=0, ppl=2.26, wps=602.6, ups=0.47, wpb=1269.2, bsz=160, num_updates=7190, lr=2.64759e-05, gnorm=5.234, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=15027
2023-06-27 06:24:08 - progress_bar.py[line:272] - INFO: epoch 003:   1937 / 2637 loss=2.345, loss_v1=0, loss_v2=0, nll_loss=1.144, ntokens=1271.1, nsentences=160, sample_size=1271.1, sample_size_v1=0, sample_size_v2=0, ppl=2.21, wps=608.5, ups=0.48, wpb=1271.1, bsz=160, num_updates=7200, lr=2.64683e-05, gnorm=5.968, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=15048
2023-06-27 06:24:29 - progress_bar.py[line:272] - INFO: epoch 003:   1947 / 2637 loss=2.338, loss_v1=0, loss_v2=0, nll_loss=1.137, ntokens=1290.6, nsentences=160, sample_size=1290.6, sample_size_v1=0, sample_size_v2=0, ppl=2.2, wps=618, ups=0.48, wpb=1290.6, bsz=160, num_updates=7210, lr=2.64608e-05, gnorm=4.72, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=15069
2023-06-27 06:24:50 - progress_bar.py[line:272] - INFO: epoch 003:   1957 / 2637 loss=2.352, loss_v1=0, loss_v2=0, nll_loss=1.15, ntokens=1276.3, nsentences=160, sample_size=1276.3, sample_size_v1=0, sample_size_v2=0, ppl=2.22, wps=611.6, ups=0.48, wpb=1276.3, bsz=160, num_updates=7220, lr=2.64532e-05, gnorm=4.952, clip=100, loss_scale=128, train_wall=21, gb_free=8.9, wall=15090
2023-06-27 06:25:10 - progress_bar.py[line:272] - INFO: epoch 003:   1967 / 2637 loss=2.35, loss_v1=0, loss_v2=0, nll_loss=1.15, ntokens=1259.8, nsentences=160, sample_size=1259.8, sample_size_v1=0, sample_size_v2=0, ppl=2.22, wps=603.7, ups=0.48, wpb=1259.8, bsz=160, num_updates=7230, lr=2.64456e-05, gnorm=5.142, clip=100, loss_scale=128, train_wall=21, gb_free=8.9, wall=15111
2023-06-27 06:25:31 - progress_bar.py[line:272] - INFO: epoch 003:   1977 / 2637 loss=2.387, loss_v1=0, loss_v2=0, nll_loss=1.189, ntokens=1275.5, nsentences=160, sample_size=1275.5, sample_size_v1=0, sample_size_v2=0, ppl=2.28, wps=611.8, ups=0.48, wpb=1275.5, bsz=160, num_updates=7240, lr=2.64381e-05, gnorm=5.299, clip=100, loss_scale=128, train_wall=21, gb_free=8.9, wall=15132
2023-06-27 06:25:52 - progress_bar.py[line:272] - INFO: epoch 003:   1987 / 2637 loss=2.331, loss_v1=0, loss_v2=0, nll_loss=1.13, ntokens=1301, nsentences=160, sample_size=1301, sample_size_v1=0, sample_size_v2=0, ppl=2.19, wps=623.7, ups=0.48, wpb=1301, bsz=160, num_updates=7250, lr=2.64305e-05, gnorm=4.803, clip=100, loss_scale=128, train_wall=21, gb_free=8.9, wall=15152
2023-06-27 06:26:13 - progress_bar.py[line:272] - INFO: epoch 003:   1997 / 2637 loss=2.358, loss_v1=0, loss_v2=0, nll_loss=1.158, ntokens=1284, nsentences=160, sample_size=1284, sample_size_v1=0, sample_size_v2=0, ppl=2.23, wps=615.4, ups=0.48, wpb=1284, bsz=160, num_updates=7260, lr=2.64229e-05, gnorm=4.975, clip=100, loss_scale=128, train_wall=21, gb_free=8.9, wall=15173
2023-06-27 06:26:34 - progress_bar.py[line:272] - INFO: epoch 003:   2007 / 2637 loss=2.339, loss_v1=0, loss_v2=0, nll_loss=1.136, ntokens=1245.8, nsentences=160, sample_size=1245.8, sample_size_v1=0, sample_size_v2=0, ppl=2.2, wps=597.1, ups=0.48, wpb=1245.8, bsz=160, num_updates=7270, lr=2.64154e-05, gnorm=4.493, clip=100, loss_scale=128, train_wall=21, gb_free=8.9, wall=15194
2023-06-27 06:26:55 - progress_bar.py[line:272] - INFO: epoch 003:   2017 / 2637 loss=2.341, loss_v1=0, loss_v2=0, nll_loss=1.139, ntokens=1303.1, nsentences=160, sample_size=1303.1, sample_size_v1=0, sample_size_v2=0, ppl=2.2, wps=624.4, ups=0.48, wpb=1303.1, bsz=160, num_updates=7280, lr=2.64078e-05, gnorm=4.786, clip=100, loss_scale=128, train_wall=21, gb_free=8.9, wall=15215
2023-06-27 06:27:16 - progress_bar.py[line:272] - INFO: epoch 003:   2027 / 2637 loss=2.319, loss_v1=0, loss_v2=0, nll_loss=1.116, ntokens=1276.5, nsentences=160, sample_size=1276.5, sample_size_v1=0, sample_size_v2=0, ppl=2.17, wps=610.6, ups=0.48, wpb=1276.5, bsz=160, num_updates=7290, lr=2.64002e-05, gnorm=5.726, clip=100, loss_scale=128, train_wall=21, gb_free=8.9, wall=15236
2023-06-27 06:27:20 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2023-06-27 06:27:39 - progress_bar.py[line:272] - INFO: epoch 003:   2038 / 2637 loss=2.322, loss_v1=0, loss_v2=0, nll_loss=1.117, ntokens=1283.1, nsentences=160, sample_size=1283.1, sample_size_v1=0, sample_size_v2=0, ppl=2.17, wps=559.7, ups=0.44, wpb=1283.1, bsz=160, num_updates=7300, lr=2.63927e-05, gnorm=5.13, clip=100, loss_scale=64, train_wall=23, gb_free=8.9, wall=15259
2023-06-27 06:27:41 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2023-06-27 06:28:02 - progress_bar.py[line:272] - INFO: epoch 003:   2049 / 2637 loss=2.317, loss_v1=0, loss_v2=0, nll_loss=1.11, ntokens=1274.2, nsentences=160, sample_size=1274.2, sample_size_v1=0, sample_size_v2=0, ppl=2.16, wps=556.2, ups=0.44, wpb=1274.2, bsz=160, num_updates=7310, lr=2.63851e-05, gnorm=4.614, clip=100, loss_scale=32, train_wall=23, gb_free=8.9, wall=15282
2023-06-27 06:28:22 - progress_bar.py[line:272] - INFO: epoch 003:   2059 / 2637 loss=2.34, loss_v1=0, loss_v2=0, nll_loss=1.139, ntokens=1258.9, nsentences=160, sample_size=1258.9, sample_size_v1=0, sample_size_v2=0, ppl=2.2, wps=603.5, ups=0.48, wpb=1258.9, bsz=160, num_updates=7320, lr=2.63775e-05, gnorm=5.854, clip=100, loss_scale=32, train_wall=21, gb_free=8.9, wall=15303
2023-06-27 06:28:43 - progress_bar.py[line:272] - INFO: epoch 003:   2069 / 2637 loss=2.347, loss_v1=0, loss_v2=0, nll_loss=1.147, ntokens=1260.6, nsentences=160, sample_size=1260.6, sample_size_v1=0, sample_size_v2=0, ppl=2.21, wps=604.3, ups=0.48, wpb=1260.6, bsz=160, num_updates=7330, lr=2.637e-05, gnorm=6.061, clip=100, loss_scale=32, train_wall=21, gb_free=8.9, wall=15324
2023-06-27 06:29:04 - progress_bar.py[line:272] - INFO: epoch 003:   2079 / 2637 loss=2.354, loss_v1=0, loss_v2=0, nll_loss=1.153, ntokens=1260, nsentences=160, sample_size=1260, sample_size_v1=0, sample_size_v2=0, ppl=2.22, wps=604, ups=0.48, wpb=1260, bsz=160, num_updates=7340, lr=2.63624e-05, gnorm=5.033, clip=100, loss_scale=32, train_wall=21, gb_free=8.9, wall=15344
2023-06-27 06:29:25 - progress_bar.py[line:272] - INFO: epoch 003:   2089 / 2637 loss=2.348, loss_v1=0, loss_v2=0, nll_loss=1.146, ntokens=1246.3, nsentences=160, sample_size=1246.3, sample_size_v1=0, sample_size_v2=0, ppl=2.21, wps=597, ups=0.48, wpb=1246.3, bsz=160, num_updates=7350, lr=2.63549e-05, gnorm=4.806, clip=100, loss_scale=32, train_wall=21, gb_free=8.9, wall=15365
2023-06-27 06:29:46 - progress_bar.py[line:272] - INFO: epoch 003:   2099 / 2637 loss=2.333, loss_v1=0, loss_v2=0, nll_loss=1.132, ntokens=1266.4, nsentences=160, sample_size=1266.4, sample_size_v1=0, sample_size_v2=0, ppl=2.19, wps=607, ups=0.48, wpb=1266.4, bsz=160, num_updates=7360, lr=2.63473e-05, gnorm=5.303, clip=100, loss_scale=32, train_wall=21, gb_free=8.9, wall=15386
2023-06-27 06:30:07 - progress_bar.py[line:272] - INFO: epoch 003:   2109 / 2637 loss=2.36, loss_v1=0, loss_v2=0, nll_loss=1.161, ntokens=1251.7, nsentences=160, sample_size=1251.7, sample_size_v1=0, sample_size_v2=0, ppl=2.24, wps=600.4, ups=0.48, wpb=1251.7, bsz=160, num_updates=7370, lr=2.63397e-05, gnorm=4.783, clip=100, loss_scale=32, train_wall=21, gb_free=8.9, wall=15407
2023-06-27 06:30:28 - progress_bar.py[line:272] - INFO: epoch 003:   2119 / 2637 loss=2.332, loss_v1=0, loss_v2=0, nll_loss=1.129, ntokens=1268.6, nsentences=160, sample_size=1268.6, sample_size_v1=0, sample_size_v2=0, ppl=2.19, wps=608.8, ups=0.48, wpb=1268.6, bsz=160, num_updates=7380, lr=2.63322e-05, gnorm=4.497, clip=100, loss_scale=32, train_wall=21, gb_free=8.9, wall=15428
2023-06-27 06:30:48 - progress_bar.py[line:272] - INFO: epoch 003:   2129 / 2637 loss=2.354, loss_v1=0, loss_v2=0, nll_loss=1.156, ntokens=1254.2, nsentences=160, sample_size=1254.2, sample_size_v1=0, sample_size_v2=0, ppl=2.23, wps=602.2, ups=0.48, wpb=1254.2, bsz=160, num_updates=7390, lr=2.63246e-05, gnorm=4.11, clip=100, loss_scale=32, train_wall=21, gb_free=8.9, wall=15449
2023-06-27 06:31:09 - progress_bar.py[line:272] - INFO: epoch 003:   2139 / 2637 loss=2.338, loss_v1=0, loss_v2=0, nll_loss=1.136, ntokens=1256.1, nsentences=160, sample_size=1256.1, sample_size_v1=0, sample_size_v2=0, ppl=2.2, wps=603.3, ups=0.48, wpb=1256.1, bsz=160, num_updates=7400, lr=2.6317e-05, gnorm=4.498, clip=100, loss_scale=32, train_wall=21, gb_free=8.9, wall=15470
2023-06-27 06:31:30 - progress_bar.py[line:272] - INFO: epoch 003:   2149 / 2637 loss=2.349, loss_v1=0, loss_v2=0, nll_loss=1.149, ntokens=1268.1, nsentences=160, sample_size=1268.1, sample_size_v1=0, sample_size_v2=0, ppl=2.22, wps=602.2, ups=0.47, wpb=1268.1, bsz=160, num_updates=7410, lr=2.63095e-05, gnorm=4.629, clip=100, loss_scale=32, train_wall=21, gb_free=8.9, wall=15491
2023-06-27 06:31:51 - progress_bar.py[line:272] - INFO: epoch 003:   2159 / 2637 loss=2.331, loss_v1=0, loss_v2=0, nll_loss=1.13, ntokens=1255.5, nsentences=160, sample_size=1255.5, sample_size_v1=0, sample_size_v2=0, ppl=2.19, wps=602.4, ups=0.48, wpb=1255.5, bsz=160, num_updates=7420, lr=2.63019e-05, gnorm=4.087, clip=100, loss_scale=32, train_wall=21, gb_free=8.9, wall=15511
2023-06-27 06:32:12 - progress_bar.py[line:272] - INFO: epoch 003:   2169 / 2637 loss=2.338, loss_v1=0, loss_v2=0, nll_loss=1.133, ntokens=1278.2, nsentences=160, sample_size=1278.2, sample_size_v1=0, sample_size_v2=0, ppl=2.19, wps=613.4, ups=0.48, wpb=1278.2, bsz=160, num_updates=7430, lr=2.62943e-05, gnorm=4.031, clip=100, loss_scale=32, train_wall=21, gb_free=8.9, wall=15532
2023-06-27 06:32:33 - progress_bar.py[line:272] - INFO: epoch 003:   2179 / 2637 loss=2.335, loss_v1=0, loss_v2=0, nll_loss=1.134, ntokens=1262.2, nsentences=160, sample_size=1262.2, sample_size_v1=0, sample_size_v2=0, ppl=2.2, wps=605.8, ups=0.48, wpb=1262.2, bsz=160, num_updates=7440, lr=2.62868e-05, gnorm=4.752, clip=100, loss_scale=32, train_wall=21, gb_free=8.9, wall=15553
2023-06-27 06:32:54 - progress_bar.py[line:272] - INFO: epoch 003:   2189 / 2637 loss=2.341, loss_v1=0, loss_v2=0, nll_loss=1.14, ntokens=1271, nsentences=160, sample_size=1271, sample_size_v1=0, sample_size_v2=0, ppl=2.2, wps=610.3, ups=0.48, wpb=1271, bsz=160, num_updates=7450, lr=2.62792e-05, gnorm=4.419, clip=100, loss_scale=32, train_wall=21, gb_free=8.9, wall=15574
2023-06-27 06:33:14 - progress_bar.py[line:272] - INFO: epoch 003:   2199 / 2637 loss=2.33, loss_v1=0, loss_v2=0, nll_loss=1.127, ntokens=1261.3, nsentences=160, sample_size=1261.3, sample_size_v1=0, sample_size_v2=0, ppl=2.18, wps=606.1, ups=0.48, wpb=1261.3, bsz=160, num_updates=7460, lr=2.62717e-05, gnorm=4.889, clip=100, loss_scale=32, train_wall=21, gb_free=8.9, wall=15595
2023-06-27 06:33:35 - progress_bar.py[line:272] - INFO: epoch 003:   2209 / 2637 loss=2.311, loss_v1=0, loss_v2=0, nll_loss=1.104, ntokens=1270.2, nsentences=160, sample_size=1270.2, sample_size_v1=0, sample_size_v2=0, ppl=2.15, wps=610.4, ups=0.48, wpb=1270.2, bsz=160, num_updates=7470, lr=2.62641e-05, gnorm=4.616, clip=100, loss_scale=32, train_wall=21, gb_free=8.9, wall=15616
2023-06-27 06:33:56 - progress_bar.py[line:272] - INFO: epoch 003:   2219 / 2637 loss=2.331, loss_v1=0, loss_v2=0, nll_loss=1.128, ntokens=1260.3, nsentences=160, sample_size=1260.3, sample_size_v1=0, sample_size_v2=0, ppl=2.19, wps=605.5, ups=0.48, wpb=1260.3, bsz=160, num_updates=7480, lr=2.62565e-05, gnorm=4.635, clip=100, loss_scale=32, train_wall=21, gb_free=8.9, wall=15636
2023-06-27 06:34:17 - progress_bar.py[line:272] - INFO: epoch 003:   2229 / 2637 loss=2.343, loss_v1=0, loss_v2=0, nll_loss=1.142, ntokens=1268.5, nsentences=160, sample_size=1268.5, sample_size_v1=0, sample_size_v2=0, ppl=2.21, wps=609.3, ups=0.48, wpb=1268.5, bsz=160, num_updates=7490, lr=2.6249e-05, gnorm=4.515, clip=100, loss_scale=32, train_wall=21, gb_free=8.9, wall=15657
2023-06-27 06:34:38 - progress_bar.py[line:272] - INFO: epoch 003:   2239 / 2637 loss=2.341, loss_v1=0, loss_v2=0, nll_loss=1.139, ntokens=1269.9, nsentences=160, sample_size=1269.9, sample_size_v1=0, sample_size_v2=0, ppl=2.2, wps=610.1, ups=0.48, wpb=1269.9, bsz=160, num_updates=7500, lr=2.62414e-05, gnorm=4.285, clip=100, loss_scale=32, train_wall=21, gb_free=8.9, wall=15678
2023-06-27 06:34:59 - progress_bar.py[line:272] - INFO: epoch 003:   2249 / 2637 loss=2.333, loss_v1=0, loss_v2=0, nll_loss=1.13, ntokens=1253.2, nsentences=160, sample_size=1253.2, sample_size_v1=0, sample_size_v2=0, ppl=2.19, wps=602.4, ups=0.48, wpb=1253.2, bsz=160, num_updates=7510, lr=2.62338e-05, gnorm=4.686, clip=100, loss_scale=32, train_wall=21, gb_free=8.9, wall=15699
2023-06-27 06:35:19 - progress_bar.py[line:272] - INFO: epoch 003:   2259 / 2637 loss=2.33, loss_v1=0, loss_v2=0, nll_loss=1.125, ntokens=1257.3, nsentences=160, sample_size=1257.3, sample_size_v1=0, sample_size_v2=0, ppl=2.18, wps=603.9, ups=0.48, wpb=1257.3, bsz=160, num_updates=7520, lr=2.62263e-05, gnorm=4.32, clip=100, loss_scale=32, train_wall=21, gb_free=8.9, wall=15720
2023-06-27 06:35:40 - progress_bar.py[line:272] - INFO: epoch 003:   2269 / 2637 loss=2.324, loss_v1=0, loss_v2=0, nll_loss=1.121, ntokens=1283.8, nsentences=160, sample_size=1283.8, sample_size_v1=0, sample_size_v2=0, ppl=2.18, wps=616.2, ups=0.48, wpb=1283.8, bsz=160, num_updates=7530, lr=2.62187e-05, gnorm=4.954, clip=100, loss_scale=32, train_wall=21, gb_free=8.9, wall=15740
2023-06-27 06:36:01 - progress_bar.py[line:272] - INFO: epoch 003:   2279 / 2637 loss=2.36, loss_v1=0, loss_v2=0, nll_loss=1.163, ntokens=1270, nsentences=160, sample_size=1270, sample_size_v1=0, sample_size_v2=0, ppl=2.24, wps=609.8, ups=0.48, wpb=1270, bsz=160, num_updates=7540, lr=2.62111e-05, gnorm=4.281, clip=100, loss_scale=32, train_wall=21, gb_free=8.9, wall=15761
2023-06-27 06:36:22 - progress_bar.py[line:272] - INFO: epoch 003:   2289 / 2637 loss=2.324, loss_v1=0, loss_v2=0, nll_loss=1.119, ntokens=1258.9, nsentences=160, sample_size=1258.9, sample_size_v1=0, sample_size_v2=0, ppl=2.17, wps=604.4, ups=0.48, wpb=1258.9, bsz=160, num_updates=7550, lr=2.62036e-05, gnorm=4.843, clip=100, loss_scale=32, train_wall=21, gb_free=8.9, wall=15782
2023-06-27 06:36:43 - progress_bar.py[line:272] - INFO: epoch 003:   2299 / 2637 loss=2.355, loss_v1=0, loss_v2=0, nll_loss=1.155, ntokens=1277.6, nsentences=160, sample_size=1277.6, sample_size_v1=0, sample_size_v2=0, ppl=2.23, wps=613.1, ups=0.48, wpb=1277.6, bsz=160, num_updates=7560, lr=2.6196e-05, gnorm=3.737, clip=100, loss_scale=32, train_wall=21, gb_free=8.9, wall=15803
2023-06-27 06:37:04 - progress_bar.py[line:272] - INFO: epoch 003:   2309 / 2637 loss=2.346, loss_v1=0, loss_v2=0, nll_loss=1.144, ntokens=1256.5, nsentences=160, sample_size=1256.5, sample_size_v1=0, sample_size_v2=0, ppl=2.21, wps=602.9, ups=0.48, wpb=1256.5, bsz=160, num_updates=7570, lr=2.61884e-05, gnorm=5.014, clip=100, loss_scale=32, train_wall=21, gb_free=8.9, wall=15824
2023-06-27 06:37:24 - progress_bar.py[line:272] - INFO: epoch 003:   2319 / 2637 loss=2.332, loss_v1=0, loss_v2=0, nll_loss=1.129, ntokens=1265.5, nsentences=160, sample_size=1265.5, sample_size_v1=0, sample_size_v2=0, ppl=2.19, wps=607.6, ups=0.48, wpb=1265.5, bsz=160, num_updates=7580, lr=2.61809e-05, gnorm=4.128, clip=100, loss_scale=32, train_wall=21, gb_free=8.9, wall=15845
2023-06-27 06:37:45 - progress_bar.py[line:272] - INFO: epoch 003:   2329 / 2637 loss=2.35, loss_v1=0, loss_v2=0, nll_loss=1.149, ntokens=1260, nsentences=160, sample_size=1260, sample_size_v1=0, sample_size_v2=0, ppl=2.22, wps=605, ups=0.48, wpb=1260, bsz=160, num_updates=7590, lr=2.61733e-05, gnorm=4.777, clip=100, loss_scale=32, train_wall=21, gb_free=8.9, wall=15865
2023-06-27 06:38:06 - progress_bar.py[line:272] - INFO: epoch 003:   2339 / 2637 loss=2.343, loss_v1=0, loss_v2=0, nll_loss=1.141, ntokens=1243.1, nsentences=160, sample_size=1243.1, sample_size_v1=0, sample_size_v2=0, ppl=2.21, wps=597.2, ups=0.48, wpb=1243.1, bsz=160, num_updates=7600, lr=2.61658e-05, gnorm=4.782, clip=100, loss_scale=32, train_wall=21, gb_free=8.9, wall=15886
2023-06-27 06:38:27 - progress_bar.py[line:272] - INFO: epoch 003:   2349 / 2637 loss=2.346, loss_v1=0, loss_v2=0, nll_loss=1.144, ntokens=1273.9, nsentences=160, sample_size=1273.9, sample_size_v1=0, sample_size_v2=0, ppl=2.21, wps=611.6, ups=0.48, wpb=1273.9, bsz=160, num_updates=7610, lr=2.61582e-05, gnorm=4.702, clip=100, loss_scale=32, train_wall=21, gb_free=8.9, wall=15907
2023-06-27 06:38:48 - progress_bar.py[line:272] - INFO: epoch 003:   2359 / 2637 loss=2.349, loss_v1=0, loss_v2=0, nll_loss=1.148, ntokens=1269.3, nsentences=160, sample_size=1269.3, sample_size_v1=0, sample_size_v2=0, ppl=2.22, wps=608, ups=0.48, wpb=1269.3, bsz=160, num_updates=7620, lr=2.61506e-05, gnorm=3.922, clip=100, loss_scale=32, train_wall=21, gb_free=8.9, wall=15928
2023-06-27 06:39:09 - progress_bar.py[line:272] - INFO: epoch 003:   2369 / 2637 loss=2.339, loss_v1=0, loss_v2=0, nll_loss=1.136, ntokens=1277.3, nsentences=160, sample_size=1277.3, sample_size_v1=0, sample_size_v2=0, ppl=2.2, wps=612, ups=0.48, wpb=1277.3, bsz=160, num_updates=7630, lr=2.61431e-05, gnorm=4.418, clip=100, loss_scale=32, train_wall=21, gb_free=8.9, wall=15949
2023-06-27 06:39:29 - progress_bar.py[line:272] - INFO: epoch 003:   2379 / 2637 loss=2.322, loss_v1=0, loss_v2=0, nll_loss=1.121, ntokens=1275.8, nsentences=160, sample_size=1275.8, sample_size_v1=0, sample_size_v2=0, ppl=2.17, wps=611.9, ups=0.48, wpb=1275.8, bsz=160, num_updates=7640, lr=2.61355e-05, gnorm=4.132, clip=100, loss_scale=32, train_wall=21, gb_free=8.9, wall=15970
2023-06-27 06:39:50 - progress_bar.py[line:272] - INFO: epoch 003:   2389 / 2637 loss=2.352, loss_v1=0, loss_v2=0, nll_loss=1.149, ntokens=1281, nsentences=160, sample_size=1281, sample_size_v1=0, sample_size_v2=0, ppl=2.22, wps=613.8, ups=0.48, wpb=1281, bsz=160, num_updates=7650, lr=2.61279e-05, gnorm=4.536, clip=100, loss_scale=32, train_wall=21, gb_free=8.9, wall=15991
2023-06-27 06:40:11 - progress_bar.py[line:272] - INFO: epoch 003:   2399 / 2637 loss=2.346, loss_v1=0, loss_v2=0, nll_loss=1.147, ntokens=1287.6, nsentences=160, sample_size=1287.6, sample_size_v1=0, sample_size_v2=0, ppl=2.21, wps=617.5, ups=0.48, wpb=1287.6, bsz=160, num_updates=7660, lr=2.61204e-05, gnorm=5.205, clip=100, loss_scale=32, train_wall=21, gb_free=8.9, wall=16011
2023-06-27 06:40:32 - progress_bar.py[line:272] - INFO: epoch 003:   2409 / 2637 loss=2.362, loss_v1=0, loss_v2=0, nll_loss=1.161, ntokens=1278.5, nsentences=160, sample_size=1278.5, sample_size_v1=0, sample_size_v2=0, ppl=2.24, wps=612.9, ups=0.48, wpb=1278.5, bsz=160, num_updates=7670, lr=2.61128e-05, gnorm=4.992, clip=100, loss_scale=32, train_wall=21, gb_free=8.9, wall=16032
2023-06-27 06:40:53 - progress_bar.py[line:272] - INFO: epoch 003:   2419 / 2637 loss=2.339, loss_v1=0, loss_v2=0, nll_loss=1.138, ntokens=1273.8, nsentences=160, sample_size=1273.8, sample_size_v1=0, sample_size_v2=0, ppl=2.2, wps=610.2, ups=0.48, wpb=1273.8, bsz=160, num_updates=7680, lr=2.61052e-05, gnorm=4.984, clip=100, loss_scale=32, train_wall=21, gb_free=8.9, wall=16053
2023-06-27 06:41:14 - progress_bar.py[line:272] - INFO: epoch 003:   2429 / 2637 loss=2.337, loss_v1=0, loss_v2=0, nll_loss=1.135, ntokens=1262.9, nsentences=160, sample_size=1262.9, sample_size_v1=0, sample_size_v2=0, ppl=2.2, wps=606.4, ups=0.48, wpb=1262.9, bsz=160, num_updates=7690, lr=2.60977e-05, gnorm=4.54, clip=100, loss_scale=32, train_wall=21, gb_free=8.9, wall=16074
2023-06-27 06:41:35 - progress_bar.py[line:272] - INFO: epoch 003:   2439 / 2637 loss=2.356, loss_v1=0, loss_v2=0, nll_loss=1.156, ntokens=1281.8, nsentences=160, sample_size=1281.8, sample_size_v1=0, sample_size_v2=0, ppl=2.23, wps=615.4, ups=0.48, wpb=1281.8, bsz=160, num_updates=7700, lr=2.60901e-05, gnorm=4.364, clip=100, loss_scale=32, train_wall=21, gb_free=8.9, wall=16095
2023-06-27 06:41:55 - progress_bar.py[line:272] - INFO: epoch 003:   2449 / 2637 loss=2.362, loss_v1=0, loss_v2=0, nll_loss=1.162, ntokens=1277, nsentences=160, sample_size=1277, sample_size_v1=0, sample_size_v2=0, ppl=2.24, wps=613.1, ups=0.48, wpb=1277, bsz=160, num_updates=7710, lr=2.60825e-05, gnorm=4.935, clip=100, loss_scale=32, train_wall=21, gb_free=8.9, wall=16116
2023-06-27 06:42:16 - progress_bar.py[line:272] - INFO: epoch 003:   2459 / 2637 loss=2.326, loss_v1=0, loss_v2=0, nll_loss=1.122, ntokens=1283.9, nsentences=160, sample_size=1283.9, sample_size_v1=0, sample_size_v2=0, ppl=2.18, wps=615.9, ups=0.48, wpb=1283.9, bsz=160, num_updates=7720, lr=2.6075e-05, gnorm=4.468, clip=100, loss_scale=32, train_wall=21, gb_free=8.9, wall=16137
2023-06-27 06:42:37 - progress_bar.py[line:272] - INFO: epoch 003:   2469 / 2637 loss=2.312, loss_v1=0, loss_v2=0, nll_loss=1.107, ntokens=1269.2, nsentences=160, sample_size=1269.2, sample_size_v1=0, sample_size_v2=0, ppl=2.15, wps=609.2, ups=0.48, wpb=1269.2, bsz=160, num_updates=7730, lr=2.60674e-05, gnorm=4.2, clip=100, loss_scale=32, train_wall=21, gb_free=8.9, wall=16157
2023-06-27 06:42:58 - progress_bar.py[line:272] - INFO: epoch 003:   2479 / 2637 loss=2.347, loss_v1=0, loss_v2=0, nll_loss=1.145, ntokens=1295, nsentences=160, sample_size=1295, sample_size_v1=0, sample_size_v2=0, ppl=2.21, wps=621.9, ups=0.48, wpb=1295, bsz=160, num_updates=7740, lr=2.60599e-05, gnorm=4.421, clip=100, loss_scale=32, train_wall=21, gb_free=8.9, wall=16178
2023-06-27 06:43:19 - progress_bar.py[line:272] - INFO: epoch 003:   2489 / 2637 loss=2.335, loss_v1=0, loss_v2=0, nll_loss=1.134, ntokens=1266.9, nsentences=160, sample_size=1266.9, sample_size_v1=0, sample_size_v2=0, ppl=2.2, wps=608.1, ups=0.48, wpb=1266.9, bsz=160, num_updates=7750, lr=2.60523e-05, gnorm=5.123, clip=100, loss_scale=32, train_wall=21, gb_free=8.9, wall=16199
2023-06-27 06:43:40 - progress_bar.py[line:272] - INFO: epoch 003:   2499 / 2637 loss=2.344, loss_v1=0, loss_v2=0, nll_loss=1.142, ntokens=1288.4, nsentences=160, sample_size=1288.4, sample_size_v1=0, sample_size_v2=0, ppl=2.21, wps=618.3, ups=0.48, wpb=1288.4, bsz=160, num_updates=7760, lr=2.60447e-05, gnorm=3.982, clip=100, loss_scale=32, train_wall=21, gb_free=8.9, wall=16220
2023-06-27 06:44:00 - progress_bar.py[line:272] - INFO: epoch 003:   2509 / 2637 loss=2.334, loss_v1=0, loss_v2=0, nll_loss=1.132, ntokens=1277, nsentences=160, sample_size=1277, sample_size_v1=0, sample_size_v2=0, ppl=2.19, wps=613.4, ups=0.48, wpb=1277, bsz=160, num_updates=7770, lr=2.60372e-05, gnorm=4.081, clip=100, loss_scale=32, train_wall=21, gb_free=8.9, wall=16241
2023-06-27 06:44:21 - progress_bar.py[line:272] - INFO: epoch 003:   2519 / 2637 loss=2.326, loss_v1=0, loss_v2=0, nll_loss=1.123, ntokens=1278, nsentences=160, sample_size=1278, sample_size_v1=0, sample_size_v2=0, ppl=2.18, wps=613.6, ups=0.48, wpb=1278, bsz=160, num_updates=7780, lr=2.60296e-05, gnorm=3.9, clip=100, loss_scale=32, train_wall=21, gb_free=8.9, wall=16262
2023-06-27 06:44:42 - progress_bar.py[line:272] - INFO: epoch 003:   2529 / 2637 loss=2.328, loss_v1=0, loss_v2=0, nll_loss=1.123, ntokens=1258, nsentences=160, sample_size=1258, sample_size_v1=0, sample_size_v2=0, ppl=2.18, wps=603.2, ups=0.48, wpb=1258, bsz=160, num_updates=7790, lr=2.6022e-05, gnorm=4.352, clip=100, loss_scale=32, train_wall=21, gb_free=8.9, wall=16282
2023-06-27 06:45:03 - progress_bar.py[line:272] - INFO: epoch 003:   2539 / 2637 loss=2.322, loss_v1=0, loss_v2=0, nll_loss=1.118, ntokens=1274.3, nsentences=160, sample_size=1274.3, sample_size_v1=0, sample_size_v2=0, ppl=2.17, wps=609.7, ups=0.48, wpb=1274.3, bsz=160, num_updates=7800, lr=2.60145e-05, gnorm=4.198, clip=100, loss_scale=32, train_wall=21, gb_free=8.9, wall=16303
2023-06-27 06:45:24 - progress_bar.py[line:272] - INFO: epoch 003:   2549 / 2637 loss=2.336, loss_v1=0, loss_v2=0, nll_loss=1.133, ntokens=1258.7, nsentences=160, sample_size=1258.7, sample_size_v1=0, sample_size_v2=0, ppl=2.19, wps=603.2, ups=0.48, wpb=1258.7, bsz=160, num_updates=7810, lr=2.60069e-05, gnorm=4.9, clip=100, loss_scale=32, train_wall=21, gb_free=8.9, wall=16324
2023-06-27 06:45:45 - progress_bar.py[line:272] - INFO: epoch 003:   2559 / 2637 loss=2.323, loss_v1=0, loss_v2=0, nll_loss=1.12, ntokens=1284.2, nsentences=160, sample_size=1284.2, sample_size_v1=0, sample_size_v2=0, ppl=2.17, wps=615.1, ups=0.48, wpb=1284.2, bsz=160, num_updates=7820, lr=2.59993e-05, gnorm=4.625, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=16345
2023-06-27 06:46:06 - progress_bar.py[line:272] - INFO: epoch 003:   2569 / 2637 loss=2.345, loss_v1=0, loss_v2=0, nll_loss=1.145, ntokens=1256.1, nsentences=160, sample_size=1256.1, sample_size_v1=0, sample_size_v2=0, ppl=2.21, wps=601.9, ups=0.48, wpb=1256.1, bsz=160, num_updates=7830, lr=2.59918e-05, gnorm=4.116, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=16366
2023-06-27 06:46:27 - progress_bar.py[line:272] - INFO: epoch 003:   2579 / 2637 loss=2.325, loss_v1=0, loss_v2=0, nll_loss=1.122, ntokens=1256.2, nsentences=160, sample_size=1256.2, sample_size_v1=0, sample_size_v2=0, ppl=2.18, wps=601.4, ups=0.48, wpb=1256.2, bsz=160, num_updates=7840, lr=2.59842e-05, gnorm=4.853, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=16387
2023-06-27 06:46:47 - progress_bar.py[line:272] - INFO: epoch 003:   2589 / 2637 loss=2.346, loss_v1=0, loss_v2=0, nll_loss=1.144, ntokens=1286.8, nsentences=160, sample_size=1286.8, sample_size_v1=0, sample_size_v2=0, ppl=2.21, wps=616.5, ups=0.48, wpb=1286.8, bsz=160, num_updates=7850, lr=2.59767e-05, gnorm=5.038, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=16408
2023-06-27 06:47:08 - progress_bar.py[line:272] - INFO: epoch 003:   2599 / 2637 loss=2.337, loss_v1=0, loss_v2=0, nll_loss=1.135, ntokens=1277.5, nsentences=160, sample_size=1277.5, sample_size_v1=0, sample_size_v2=0, ppl=2.2, wps=611.6, ups=0.48, wpb=1277.5, bsz=160, num_updates=7860, lr=2.59691e-05, gnorm=4.553, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=16429
2023-06-27 06:47:29 - progress_bar.py[line:272] - INFO: epoch 003:   2609 / 2637 loss=2.325, loss_v1=0, loss_v2=0, nll_loss=1.121, ntokens=1273.9, nsentences=160, sample_size=1273.9, sample_size_v1=0, sample_size_v2=0, ppl=2.17, wps=609.8, ups=0.48, wpb=1273.9, bsz=160, num_updates=7870, lr=2.59615e-05, gnorm=4.278, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=16449
2023-06-27 06:47:50 - progress_bar.py[line:272] - INFO: epoch 003:   2619 / 2637 loss=2.31, loss_v1=0, loss_v2=0, nll_loss=1.104, ntokens=1266.1, nsentences=160, sample_size=1266.1, sample_size_v1=0, sample_size_v2=0, ppl=2.15, wps=606.6, ups=0.48, wpb=1266.1, bsz=160, num_updates=7880, lr=2.5954e-05, gnorm=4.175, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=16470
2023-06-27 06:48:11 - progress_bar.py[line:272] - INFO: epoch 003:   2629 / 2637 loss=2.338, loss_v1=0, loss_v2=0, nll_loss=1.136, ntokens=1283.5, nsentences=160, sample_size=1283.5, sample_size_v1=0, sample_size_v2=0, ppl=2.2, wps=614.8, ups=0.48, wpb=1283.5, bsz=160, num_updates=7890, lr=2.59464e-05, gnorm=4.687, clip=100, loss_scale=64, train_wall=21, gb_free=8.8, wall=16491
2023-06-27 06:48:27 - train.py[line:332] - INFO: end of epoch 3 (average epoch stats below)
local datafile ../../dataset/OFA_data/vrd/vg_train_full.tsv slice_id 1 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../dataset/OFA_data/vrd/vg_train_full.tsv slice_id 3 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../dataset/OFA_data/vrd/vg_train_full.tsv slice_id 2 begin to initialize row_count and line_idx-to-offset mapping
2023-06-27 06:48:27 - progress_bar.py[line:282] - INFO: epoch 003 | loss 2.342 | loss_v1 0 | loss_v2 0 | nll_loss 1.14 | ntokens 1259.95 | nsentences 159.984 | sample_size 1259.95 | sample_size_v1 0 | sample_size_v2 0 | ppl 2.2 | wps 603 | ups 0.48 | wpb 1260 | bsz 160 | num_updates 7898 | lr 2.59403e-05 | gnorm 4.828 | clip 100 | loss_scale 64 | train_wall 5490 | gb_free 8.9 | wall 16507
2023-06-27 06:48:27 - trainer.py[line:639] - INFO: loading train data for epoch 4
local datafile ../../dataset/OFA_data/vrd/vg_train_full.tsv slice_id 0 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../dataset/OFA_data/vrd/vg_train_full.tsv slice_id 3 finished initializing row_count and line_idx-to-offset mapping
file ../../dataset/OFA_data/vrd/vg_train_full.tsv slice_id 3 row count 105469 total row count 421879
local datafile ../../dataset/OFA_data/vrd/vg_train_full.tsv slice_id 2 finished initializing row_count and line_idx-to-offset mapping
file ../../dataset/OFA_data/vrd/vg_train_full.tsv slice_id 2 row count 105470 total row count 421879
local datafile ../../dataset/OFA_data/vrd/vg_train_full.tsv slice_id 1 finished initializing row_count and line_idx-to-offset mapping
file ../../dataset/OFA_data/vrd/vg_train_full.tsv slice_id 1 row count 105470 total row count 421879
local datafile ../../dataset/OFA_data/vrd/vg_train_full.tsv slice_id 0 finished initializing row_count and line_idx-to-offset mapping
file ../../dataset/OFA_data/vrd/vg_train_full.tsv slice_id 0 row count 105470 total row count 421879
slice_id 3 seek offset 316410
slice_id 1 seek offset 105470
slice_id 2 seek offset 210940
slice_id 0 seek offset 0
2023-06-27 06:48:27 - trainer.py[line:703] - INFO: begin training epoch 4
2023-06-27 06:48:27 - train.py[line:305] - INFO: Start iterating over samples
2023-06-27 06:48:32 - progress_bar.py[line:272] - INFO: epoch 004:      2 / 2637 loss=2.343, loss_v1=0, loss_v2=0, nll_loss=1.142, ntokens=1229.3, nsentences=156, sample_size=1229.3, sample_size_v1=0, sample_size_v2=0, ppl=2.21, wps=586.4, ups=0.48, wpb=1229.3, bsz=156, num_updates=7900, lr=2.59388e-05, gnorm=4.506, clip=100, loss_scale=64, train_wall=20, gb_free=8.9, wall=16512
2023-06-27 06:48:53 - progress_bar.py[line:272] - INFO: epoch 004:     12 / 2637 loss=2.318, loss_v1=0, loss_v2=0, nll_loss=1.112, ntokens=1252.7, nsentences=160, sample_size=1252.7, sample_size_v1=0, sample_size_v2=0, ppl=2.16, wps=601, ups=0.48, wpb=1252.7, bsz=160, num_updates=7910, lr=2.59313e-05, gnorm=4.456, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=16533
2023-06-27 06:49:14 - progress_bar.py[line:272] - INFO: epoch 004:     22 / 2637 loss=2.316, loss_v1=0, loss_v2=0, nll_loss=1.111, ntokens=1264.8, nsentences=160, sample_size=1264.8, sample_size_v1=0, sample_size_v2=0, ppl=2.16, wps=607.5, ups=0.48, wpb=1264.8, bsz=160, num_updates=7920, lr=2.59237e-05, gnorm=5.098, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=16554
2023-06-27 06:49:34 - progress_bar.py[line:272] - INFO: epoch 004:     32 / 2637 loss=2.318, loss_v1=0, loss_v2=0, nll_loss=1.114, ntokens=1254.1, nsentences=160, sample_size=1254.1, sample_size_v1=0, sample_size_v2=0, ppl=2.16, wps=602, ups=0.48, wpb=1254.1, bsz=160, num_updates=7930, lr=2.59161e-05, gnorm=4.771, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=16575
2023-06-27 06:49:55 - progress_bar.py[line:272] - INFO: epoch 004:     42 / 2637 loss=2.312, loss_v1=0, loss_v2=0, nll_loss=1.107, ntokens=1268.5, nsentences=160, sample_size=1268.5, sample_size_v1=0, sample_size_v2=0, ppl=2.15, wps=609.3, ups=0.48, wpb=1268.5, bsz=160, num_updates=7940, lr=2.59086e-05, gnorm=4.786, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=16596
2023-06-27 06:50:16 - progress_bar.py[line:272] - INFO: epoch 004:     52 / 2637 loss=2.318, loss_v1=0, loss_v2=0, nll_loss=1.113, ntokens=1236.2, nsentences=160, sample_size=1236.2, sample_size_v1=0, sample_size_v2=0, ppl=2.16, wps=594.2, ups=0.48, wpb=1236.2, bsz=160, num_updates=7950, lr=2.5901e-05, gnorm=4.082, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=16616
2023-06-27 06:50:37 - progress_bar.py[line:272] - INFO: epoch 004:     62 / 2637 loss=2.337, loss_v1=0, loss_v2=0, nll_loss=1.137, ntokens=1246.6, nsentences=160, sample_size=1246.6, sample_size_v1=0, sample_size_v2=0, ppl=2.2, wps=598.5, ups=0.48, wpb=1246.6, bsz=160, num_updates=7960, lr=2.58934e-05, gnorm=4.202, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=16637
2023-06-27 06:50:58 - progress_bar.py[line:272] - INFO: epoch 004:     72 / 2637 loss=2.329, loss_v1=0, loss_v2=0, nll_loss=1.127, ntokens=1256.2, nsentences=160, sample_size=1256.2, sample_size_v1=0, sample_size_v2=0, ppl=2.18, wps=602.8, ups=0.48, wpb=1256.2, bsz=160, num_updates=7970, lr=2.58859e-05, gnorm=5.066, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=16658
2023-06-27 06:51:19 - progress_bar.py[line:272] - INFO: epoch 004:     82 / 2637 loss=2.343, loss_v1=0, loss_v2=0, nll_loss=1.139, ntokens=1250.5, nsentences=160, sample_size=1250.5, sample_size_v1=0, sample_size_v2=0, ppl=2.2, wps=599.9, ups=0.48, wpb=1250.5, bsz=160, num_updates=7980, lr=2.58783e-05, gnorm=4.298, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=16679
2023-06-27 06:51:39 - progress_bar.py[line:272] - INFO: epoch 004:     92 / 2637 loss=2.325, loss_v1=0, loss_v2=0, nll_loss=1.122, ntokens=1252.2, nsentences=160, sample_size=1252.2, sample_size_v1=0, sample_size_v2=0, ppl=2.18, wps=600.5, ups=0.48, wpb=1252.2, bsz=160, num_updates=7990, lr=2.58708e-05, gnorm=4.488, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=16700
2023-06-27 06:52:00 - progress_bar.py[line:272] - INFO: epoch 004:    102 / 2637 loss=2.311, loss_v1=0, loss_v2=0, nll_loss=1.105, ntokens=1250.4, nsentences=160, sample_size=1250.4, sample_size_v1=0, sample_size_v2=0, ppl=2.15, wps=599.3, ups=0.48, wpb=1250.4, bsz=160, num_updates=8000, lr=2.58632e-05, gnorm=4.595, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=16721
2023-06-27 06:52:21 - progress_bar.py[line:272] - INFO: epoch 004:    112 / 2637 loss=2.315, loss_v1=0, loss_v2=0, nll_loss=1.11, ntokens=1246.8, nsentences=160, sample_size=1246.8, sample_size_v1=0, sample_size_v2=0, ppl=2.16, wps=598.2, ups=0.48, wpb=1246.8, bsz=160, num_updates=8010, lr=2.58556e-05, gnorm=4.364, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=16741
2023-06-27 06:52:42 - progress_bar.py[line:272] - INFO: epoch 004:    122 / 2637 loss=2.309, loss_v1=0, loss_v2=0, nll_loss=1.103, ntokens=1247.7, nsentences=160, sample_size=1247.7, sample_size_v1=0, sample_size_v2=0, ppl=2.15, wps=598.8, ups=0.48, wpb=1247.7, bsz=160, num_updates=8020, lr=2.58481e-05, gnorm=4.098, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=16762
2023-06-27 06:53:03 - progress_bar.py[line:272] - INFO: epoch 004:    132 / 2637 loss=2.327, loss_v1=0, loss_v2=0, nll_loss=1.124, ntokens=1246.9, nsentences=160, sample_size=1246.9, sample_size_v1=0, sample_size_v2=0, ppl=2.18, wps=598.1, ups=0.48, wpb=1246.9, bsz=160, num_updates=8030, lr=2.58405e-05, gnorm=4.824, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=16783
2023-06-27 06:53:24 - progress_bar.py[line:272] - INFO: epoch 004:    142 / 2637 loss=2.335, loss_v1=0, loss_v2=0, nll_loss=1.131, ntokens=1242.2, nsentences=160, sample_size=1242.2, sample_size_v1=0, sample_size_v2=0, ppl=2.19, wps=595.2, ups=0.48, wpb=1242.2, bsz=160, num_updates=8040, lr=2.58329e-05, gnorm=4.073, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=16804
2023-06-27 06:53:45 - progress_bar.py[line:272] - INFO: epoch 004:    152 / 2637 loss=2.353, loss_v1=0, loss_v2=0, nll_loss=1.151, ntokens=1250.3, nsentences=160, sample_size=1250.3, sample_size_v1=0, sample_size_v2=0, ppl=2.22, wps=599.2, ups=0.48, wpb=1250.3, bsz=160, num_updates=8050, lr=2.58254e-05, gnorm=4.917, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=16825
2023-06-27 06:54:05 - progress_bar.py[line:272] - INFO: epoch 004:    162 / 2637 loss=2.344, loss_v1=0, loss_v2=0, nll_loss=1.145, ntokens=1240.2, nsentences=160, sample_size=1240.2, sample_size_v1=0, sample_size_v2=0, ppl=2.21, wps=594.7, ups=0.48, wpb=1240.2, bsz=160, num_updates=8060, lr=2.58178e-05, gnorm=4.033, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=16846
2023-06-27 06:54:26 - progress_bar.py[line:272] - INFO: epoch 004:    172 / 2637 loss=2.338, loss_v1=0, loss_v2=0, nll_loss=1.135, ntokens=1245.7, nsentences=160, sample_size=1245.7, sample_size_v1=0, sample_size_v2=0, ppl=2.2, wps=597.5, ups=0.48, wpb=1245.7, bsz=160, num_updates=8070, lr=2.58102e-05, gnorm=4.148, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=16867
2023-06-27 06:54:47 - progress_bar.py[line:272] - INFO: epoch 004:    182 / 2637 loss=2.318, loss_v1=0, loss_v2=0, nll_loss=1.113, ntokens=1243.8, nsentences=160, sample_size=1243.8, sample_size_v1=0, sample_size_v2=0, ppl=2.16, wps=595.4, ups=0.48, wpb=1243.8, bsz=160, num_updates=8080, lr=2.58027e-05, gnorm=4.614, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=16887
2023-06-27 06:55:08 - progress_bar.py[line:272] - INFO: epoch 004:    192 / 2637 loss=2.312, loss_v1=0, loss_v2=0, nll_loss=1.106, ntokens=1226.6, nsentences=160, sample_size=1226.6, sample_size_v1=0, sample_size_v2=0, ppl=2.15, wps=587.1, ups=0.48, wpb=1226.6, bsz=160, num_updates=8090, lr=2.57951e-05, gnorm=4.582, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=16908
2023-06-27 06:55:29 - progress_bar.py[line:272] - INFO: epoch 004:    202 / 2637 loss=2.3, loss_v1=0, loss_v2=0, nll_loss=1.093, ntokens=1253.9, nsentences=160, sample_size=1253.9, sample_size_v1=0, sample_size_v2=0, ppl=2.13, wps=600.8, ups=0.48, wpb=1253.9, bsz=160, num_updates=8100, lr=2.57875e-05, gnorm=4.22, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=16929
2023-06-27 06:55:50 - progress_bar.py[line:272] - INFO: epoch 004:    212 / 2637 loss=2.275, loss_v1=0, loss_v2=0, nll_loss=1.065, ntokens=1237, nsentences=160, sample_size=1237, sample_size_v1=0, sample_size_v2=0, ppl=2.09, wps=592.7, ups=0.48, wpb=1237, bsz=160, num_updates=8110, lr=2.578e-05, gnorm=4.112, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=16950
2023-06-27 06:56:11 - progress_bar.py[line:272] - INFO: epoch 004:    222 / 2637 loss=2.296, loss_v1=0, loss_v2=0, nll_loss=1.09, ntokens=1227, nsentences=160, sample_size=1227, sample_size_v1=0, sample_size_v2=0, ppl=2.13, wps=589.7, ups=0.48, wpb=1227, bsz=160, num_updates=8120, lr=2.57724e-05, gnorm=4.505, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=16971
2023-06-27 06:56:31 - progress_bar.py[line:272] - INFO: epoch 004:    232 / 2637 loss=2.323, loss_v1=0, loss_v2=0, nll_loss=1.121, ntokens=1259.4, nsentences=160, sample_size=1259.4, sample_size_v1=0, sample_size_v2=0, ppl=2.17, wps=605.2, ups=0.48, wpb=1259.4, bsz=160, num_updates=8130, lr=2.57649e-05, gnorm=5.061, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=16992
2023-06-27 06:56:52 - progress_bar.py[line:272] - INFO: epoch 004:    242 / 2637 loss=2.289, loss_v1=0, loss_v2=0, nll_loss=1.081, ntokens=1251.2, nsentences=160, sample_size=1251.2, sample_size_v1=0, sample_size_v2=0, ppl=2.12, wps=601, ups=0.48, wpb=1251.2, bsz=160, num_updates=8140, lr=2.57573e-05, gnorm=4.51, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=17013
2023-06-27 06:57:13 - progress_bar.py[line:272] - INFO: epoch 004:    252 / 2637 loss=2.31, loss_v1=0, loss_v2=0, nll_loss=1.105, ntokens=1259.8, nsentences=160, sample_size=1259.8, sample_size_v1=0, sample_size_v2=0, ppl=2.15, wps=605.2, ups=0.48, wpb=1259.8, bsz=160, num_updates=8150, lr=2.57497e-05, gnorm=4.682, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=17033
2023-06-27 06:57:34 - progress_bar.py[line:272] - INFO: epoch 004:    262 / 2637 loss=2.297, loss_v1=0, loss_v2=0, nll_loss=1.09, ntokens=1245.6, nsentences=160, sample_size=1245.6, sample_size_v1=0, sample_size_v2=0, ppl=2.13, wps=598.6, ups=0.48, wpb=1245.6, bsz=160, num_updates=8160, lr=2.57422e-05, gnorm=4.643, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=17054
2023-06-27 06:57:55 - progress_bar.py[line:272] - INFO: epoch 004:    272 / 2637 loss=2.326, loss_v1=0, loss_v2=0, nll_loss=1.121, ntokens=1248.4, nsentences=160, sample_size=1248.4, sample_size_v1=0, sample_size_v2=0, ppl=2.17, wps=599.7, ups=0.48, wpb=1248.4, bsz=160, num_updates=8170, lr=2.57346e-05, gnorm=4.845, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=17075
2023-06-27 06:58:16 - progress_bar.py[line:272] - INFO: epoch 004:    282 / 2637 loss=2.324, loss_v1=0, loss_v2=0, nll_loss=1.122, ntokens=1249.2, nsentences=160, sample_size=1249.2, sample_size_v1=0, sample_size_v2=0, ppl=2.18, wps=600.4, ups=0.48, wpb=1249.2, bsz=160, num_updates=8180, lr=2.5727e-05, gnorm=4.136, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=17096
2023-06-27 06:58:36 - progress_bar.py[line:272] - INFO: epoch 004:    292 / 2637 loss=2.334, loss_v1=0, loss_v2=0, nll_loss=1.131, ntokens=1244.4, nsentences=160, sample_size=1244.4, sample_size_v1=0, sample_size_v2=0, ppl=2.19, wps=598.5, ups=0.48, wpb=1244.4, bsz=160, num_updates=8190, lr=2.57195e-05, gnorm=4.876, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=17117
2023-06-27 06:58:57 - progress_bar.py[line:272] - INFO: epoch 004:    302 / 2637 loss=2.332, loss_v1=0, loss_v2=0, nll_loss=1.129, ntokens=1233.7, nsentences=160, sample_size=1233.7, sample_size_v1=0, sample_size_v2=0, ppl=2.19, wps=591.9, ups=0.48, wpb=1233.7, bsz=160, num_updates=8200, lr=2.57119e-05, gnorm=3.74, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=17137
2023-06-27 06:59:18 - progress_bar.py[line:272] - INFO: epoch 004:    312 / 2637 loss=2.299, loss_v1=0, loss_v2=0, nll_loss=1.091, ntokens=1236.3, nsentences=160, sample_size=1236.3, sample_size_v1=0, sample_size_v2=0, ppl=2.13, wps=592.1, ups=0.48, wpb=1236.3, bsz=160, num_updates=8210, lr=2.57043e-05, gnorm=4.63, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=17158
2023-06-27 06:59:39 - progress_bar.py[line:272] - INFO: epoch 004:    322 / 2637 loss=2.307, loss_v1=0, loss_v2=0, nll_loss=1.103, ntokens=1242.8, nsentences=160, sample_size=1242.8, sample_size_v1=0, sample_size_v2=0, ppl=2.15, wps=594.9, ups=0.48, wpb=1242.8, bsz=160, num_updates=8220, lr=2.56968e-05, gnorm=5.129, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=17179
2023-06-27 07:00:00 - progress_bar.py[line:272] - INFO: epoch 004:    332 / 2637 loss=2.292, loss_v1=0, loss_v2=0, nll_loss=1.086, ntokens=1262.9, nsentences=160, sample_size=1262.9, sample_size_v1=0, sample_size_v2=0, ppl=2.12, wps=604.7, ups=0.48, wpb=1262.9, bsz=160, num_updates=8230, lr=2.56892e-05, gnorm=5.119, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=17200
2023-06-27 07:00:21 - progress_bar.py[line:272] - INFO: epoch 004:    342 / 2637 loss=2.293, loss_v1=0, loss_v2=0, nll_loss=1.084, ntokens=1229.1, nsentences=160, sample_size=1229.1, sample_size_v1=0, sample_size_v2=0, ppl=2.12, wps=589.2, ups=0.48, wpb=1229.1, bsz=160, num_updates=8240, lr=2.56817e-05, gnorm=4.801, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=17221
2023-06-27 07:00:42 - progress_bar.py[line:272] - INFO: epoch 004:    352 / 2637 loss=2.33, loss_v1=0, loss_v2=0, nll_loss=1.126, ntokens=1262.3, nsentences=160, sample_size=1262.3, sample_size_v1=0, sample_size_v2=0, ppl=2.18, wps=604.9, ups=0.48, wpb=1262.3, bsz=160, num_updates=8250, lr=2.56741e-05, gnorm=4.806, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=17242
2023-06-27 07:01:02 - progress_bar.py[line:272] - INFO: epoch 004:    362 / 2637 loss=2.283, loss_v1=0, loss_v2=0, nll_loss=1.074, ntokens=1253.5, nsentences=160, sample_size=1253.5, sample_size_v1=0, sample_size_v2=0, ppl=2.11, wps=600.5, ups=0.48, wpb=1253.5, bsz=160, num_updates=8260, lr=2.56665e-05, gnorm=5.411, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=17263
2023-06-27 07:01:23 - progress_bar.py[line:272] - INFO: epoch 004:    372 / 2637 loss=2.278, loss_v1=0, loss_v2=0, nll_loss=1.067, ntokens=1247.5, nsentences=160, sample_size=1247.5, sample_size_v1=0, sample_size_v2=0, ppl=2.1, wps=597.6, ups=0.48, wpb=1247.5, bsz=160, num_updates=8270, lr=2.5659e-05, gnorm=4.591, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=17284
2023-06-27 07:01:44 - progress_bar.py[line:272] - INFO: epoch 004:    382 / 2637 loss=2.275, loss_v1=0, loss_v2=0, nll_loss=1.068, ntokens=1247.6, nsentences=160, sample_size=1247.6, sample_size_v1=0, sample_size_v2=0, ppl=2.1, wps=597.8, ups=0.48, wpb=1247.6, bsz=160, num_updates=8280, lr=2.56514e-05, gnorm=5.213, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=17305
2023-06-27 07:02:05 - progress_bar.py[line:272] - INFO: epoch 004:    392 / 2637 loss=2.282, loss_v1=0, loss_v2=0, nll_loss=1.073, ntokens=1234, nsentences=160, sample_size=1234, sample_size_v1=0, sample_size_v2=0, ppl=2.1, wps=591.3, ups=0.48, wpb=1234, bsz=160, num_updates=8290, lr=2.56438e-05, gnorm=5.125, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=17325
2023-06-27 07:02:26 - progress_bar.py[line:272] - INFO: epoch 004:    402 / 2637 loss=2.265, loss_v1=0, loss_v2=0, nll_loss=1.055, ntokens=1254.6, nsentences=160, sample_size=1254.6, sample_size_v1=0, sample_size_v2=0, ppl=2.08, wps=600.9, ups=0.48, wpb=1254.6, bsz=160, num_updates=8300, lr=2.56363e-05, gnorm=4.985, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=17346
2023-06-27 07:02:47 - progress_bar.py[line:272] - INFO: epoch 004:    412 / 2637 loss=2.257, loss_v1=0, loss_v2=0, nll_loss=1.047, ntokens=1242.7, nsentences=160, sample_size=1242.7, sample_size_v1=0, sample_size_v2=0, ppl=2.07, wps=595.1, ups=0.48, wpb=1242.7, bsz=160, num_updates=8310, lr=2.56287e-05, gnorm=5.084, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=17367
2023-06-27 07:03:08 - progress_bar.py[line:272] - INFO: epoch 004:    422 / 2637 loss=2.283, loss_v1=0, loss_v2=0, nll_loss=1.071, ntokens=1255.6, nsentences=160, sample_size=1255.6, sample_size_v1=0, sample_size_v2=0, ppl=2.1, wps=601.6, ups=0.48, wpb=1255.6, bsz=160, num_updates=8320, lr=2.56211e-05, gnorm=5.121, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=17388
2023-06-27 07:03:29 - progress_bar.py[line:272] - INFO: epoch 004:    432 / 2637 loss=2.276, loss_v1=0, loss_v2=0, nll_loss=1.066, ntokens=1257.4, nsentences=160, sample_size=1257.4, sample_size_v1=0, sample_size_v2=0, ppl=2.09, wps=602.5, ups=0.48, wpb=1257.4, bsz=160, num_updates=8330, lr=2.56136e-05, gnorm=4.173, clip=100, loss_scale=128, train_wall=21, gb_free=8.9, wall=17409
2023-06-27 07:03:50 - progress_bar.py[line:272] - INFO: epoch 004:    442 / 2637 loss=2.285, loss_v1=0, loss_v2=0, nll_loss=1.077, ntokens=1246.2, nsentences=160, sample_size=1246.2, sample_size_v1=0, sample_size_v2=0, ppl=2.11, wps=596.8, ups=0.48, wpb=1246.2, bsz=160, num_updates=8340, lr=2.5606e-05, gnorm=4.247, clip=100, loss_scale=128, train_wall=21, gb_free=8.9, wall=17430
2023-06-27 07:04:10 - progress_bar.py[line:272] - INFO: epoch 004:    452 / 2637 loss=2.271, loss_v1=0, loss_v2=0, nll_loss=1.063, ntokens=1241.5, nsentences=160, sample_size=1241.5, sample_size_v1=0, sample_size_v2=0, ppl=2.09, wps=595, ups=0.48, wpb=1241.5, bsz=160, num_updates=8350, lr=2.55984e-05, gnorm=4.531, clip=100, loss_scale=128, train_wall=21, gb_free=8.9, wall=17451
2023-06-27 07:04:31 - progress_bar.py[line:272] - INFO: epoch 004:    462 / 2637 loss=2.297, loss_v1=0, loss_v2=0, nll_loss=1.091, ntokens=1274.3, nsentences=160, sample_size=1274.3, sample_size_v1=0, sample_size_v2=0, ppl=2.13, wps=610.6, ups=0.48, wpb=1274.3, bsz=160, num_updates=8360, lr=2.55909e-05, gnorm=4.797, clip=100, loss_scale=128, train_wall=21, gb_free=8.9, wall=17472
2023-06-27 07:04:52 - progress_bar.py[line:272] - INFO: epoch 004:    472 / 2637 loss=2.299, loss_v1=0, loss_v2=0, nll_loss=1.091, ntokens=1245.3, nsentences=160, sample_size=1245.3, sample_size_v1=0, sample_size_v2=0, ppl=2.13, wps=596.6, ups=0.48, wpb=1245.3, bsz=160, num_updates=8370, lr=2.55833e-05, gnorm=4.981, clip=100, loss_scale=128, train_wall=21, gb_free=8.9, wall=17492
2023-06-27 07:05:13 - progress_bar.py[line:272] - INFO: epoch 004:    482 / 2637 loss=2.3, loss_v1=0, loss_v2=0, nll_loss=1.095, ntokens=1259.3, nsentences=160, sample_size=1259.3, sample_size_v1=0, sample_size_v2=0, ppl=2.14, wps=603, ups=0.48, wpb=1259.3, bsz=160, num_updates=8380, lr=2.55758e-05, gnorm=4.498, clip=100, loss_scale=128, train_wall=21, gb_free=8.9, wall=17513
2023-06-27 07:05:34 - progress_bar.py[line:272] - INFO: epoch 004:    492 / 2637 loss=2.3, loss_v1=0, loss_v2=0, nll_loss=1.095, ntokens=1257.6, nsentences=160, sample_size=1257.6, sample_size_v1=0, sample_size_v2=0, ppl=2.14, wps=602.9, ups=0.48, wpb=1257.6, bsz=160, num_updates=8390, lr=2.55682e-05, gnorm=4.397, clip=100, loss_scale=128, train_wall=21, gb_free=8.9, wall=17534
2023-06-27 07:05:55 - progress_bar.py[line:272] - INFO: epoch 004:    502 / 2637 loss=2.315, loss_v1=0, loss_v2=0, nll_loss=1.109, ntokens=1266, nsentences=160, sample_size=1266, sample_size_v1=0, sample_size_v2=0, ppl=2.16, wps=606.9, ups=0.48, wpb=1266, bsz=160, num_updates=8400, lr=2.55606e-05, gnorm=4.503, clip=100, loss_scale=128, train_wall=21, gb_free=8.9, wall=17555
2023-06-27 07:06:16 - progress_bar.py[line:272] - INFO: epoch 004:    512 / 2637 loss=2.319, loss_v1=0, loss_v2=0, nll_loss=1.113, ntokens=1256.1, nsentences=160, sample_size=1256.1, sample_size_v1=0, sample_size_v2=0, ppl=2.16, wps=601.5, ups=0.48, wpb=1256.1, bsz=160, num_updates=8410, lr=2.55531e-05, gnorm=4.453, clip=100, loss_scale=128, train_wall=21, gb_free=8.9, wall=17576
2023-06-27 07:06:34 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2023-06-27 07:06:39 - progress_bar.py[line:272] - INFO: epoch 004:    523 / 2637 loss=2.315, loss_v1=0, loss_v2=0, nll_loss=1.111, ntokens=1239.9, nsentences=160, sample_size=1239.9, sample_size_v1=0, sample_size_v2=0, ppl=2.16, wps=541.1, ups=0.44, wpb=1239.9, bsz=160, num_updates=8420, lr=2.55455e-05, gnorm=5.133, clip=100, loss_scale=64, train_wall=23, gb_free=8.9, wall=17599
2023-06-27 07:06:59 - progress_bar.py[line:272] - INFO: epoch 004:    533 / 2637 loss=2.285, loss_v1=0, loss_v2=0, nll_loss=1.077, ntokens=1247.6, nsentences=160, sample_size=1247.6, sample_size_v1=0, sample_size_v2=0, ppl=2.11, wps=598.3, ups=0.48, wpb=1247.6, bsz=160, num_updates=8430, lr=2.55379e-05, gnorm=4.473, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=17620
2023-06-27 07:07:20 - progress_bar.py[line:272] - INFO: epoch 004:    543 / 2637 loss=2.347, loss_v1=0, loss_v2=0, nll_loss=1.146, ntokens=1266.7, nsentences=160, sample_size=1266.7, sample_size_v1=0, sample_size_v2=0, ppl=2.21, wps=607.2, ups=0.48, wpb=1266.7, bsz=160, num_updates=8440, lr=2.55304e-05, gnorm=5.179, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=17641
2023-06-27 07:07:41 - progress_bar.py[line:272] - INFO: epoch 004:    553 / 2637 loss=2.301, loss_v1=0, loss_v2=0, nll_loss=1.094, ntokens=1268.1, nsentences=160, sample_size=1268.1, sample_size_v1=0, sample_size_v2=0, ppl=2.13, wps=609.5, ups=0.48, wpb=1268.1, bsz=160, num_updates=8450, lr=2.55228e-05, gnorm=5.064, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=17661
2023-06-27 07:08:02 - progress_bar.py[line:272] - INFO: epoch 004:    563 / 2637 loss=2.327, loss_v1=0, loss_v2=0, nll_loss=1.125, ntokens=1249.7, nsentences=160, sample_size=1249.7, sample_size_v1=0, sample_size_v2=0, ppl=2.18, wps=600.2, ups=0.48, wpb=1249.7, bsz=160, num_updates=8460, lr=2.55152e-05, gnorm=5.075, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=17682
2023-06-27 07:08:23 - progress_bar.py[line:272] - INFO: epoch 004:    573 / 2637 loss=2.343, loss_v1=0, loss_v2=0, nll_loss=1.143, ntokens=1256.6, nsentences=160, sample_size=1256.6, sample_size_v1=0, sample_size_v2=0, ppl=2.21, wps=603.6, ups=0.48, wpb=1256.6, bsz=160, num_updates=8470, lr=2.55077e-05, gnorm=5.726, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=17703
2023-06-27 07:08:44 - progress_bar.py[line:272] - INFO: epoch 004:    583 / 2637 loss=2.334, loss_v1=0, loss_v2=0, nll_loss=1.131, ntokens=1243.9, nsentences=160, sample_size=1243.9, sample_size_v1=0, sample_size_v2=0, ppl=2.19, wps=597.8, ups=0.48, wpb=1243.9, bsz=160, num_updates=8480, lr=2.55001e-05, gnorm=4.37, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=17724
2023-06-27 07:09:04 - progress_bar.py[line:272] - INFO: epoch 004:    593 / 2637 loss=2.297, loss_v1=0, loss_v2=0, nll_loss=1.091, ntokens=1268.3, nsentences=160, sample_size=1268.3, sample_size_v1=0, sample_size_v2=0, ppl=2.13, wps=609.1, ups=0.48, wpb=1268.3, bsz=160, num_updates=8490, lr=2.54925e-05, gnorm=4.08, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=17745
2023-06-27 07:09:25 - progress_bar.py[line:272] - INFO: epoch 004:    603 / 2637 loss=2.323, loss_v1=0, loss_v2=0, nll_loss=1.119, ntokens=1254, nsentences=160, sample_size=1254, sample_size_v1=0, sample_size_v2=0, ppl=2.17, wps=602.7, ups=0.48, wpb=1254, bsz=160, num_updates=8500, lr=2.5485e-05, gnorm=5.24, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=17765
2023-06-27 07:09:46 - progress_bar.py[line:272] - INFO: epoch 004:    613 / 2637 loss=2.331, loss_v1=0, loss_v2=0, nll_loss=1.127, ntokens=1270.6, nsentences=160, sample_size=1270.6, sample_size_v1=0, sample_size_v2=0, ppl=2.18, wps=611, ups=0.48, wpb=1270.6, bsz=160, num_updates=8510, lr=2.54774e-05, gnorm=5.142, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=17786
2023-06-27 07:10:07 - progress_bar.py[line:272] - INFO: epoch 004:    623 / 2637 loss=2.306, loss_v1=0, loss_v2=0, nll_loss=1.099, ntokens=1243.1, nsentences=160, sample_size=1243.1, sample_size_v1=0, sample_size_v2=0, ppl=2.14, wps=597.1, ups=0.48, wpb=1243.1, bsz=160, num_updates=8520, lr=2.54699e-05, gnorm=4.014, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=17807
2023-06-27 07:10:28 - progress_bar.py[line:272] - INFO: epoch 004:    633 / 2637 loss=2.321, loss_v1=0, loss_v2=0, nll_loss=1.118, ntokens=1250.5, nsentences=160, sample_size=1250.5, sample_size_v1=0, sample_size_v2=0, ppl=2.17, wps=600.7, ups=0.48, wpb=1250.5, bsz=160, num_updates=8530, lr=2.54623e-05, gnorm=4.702, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=17828
2023-06-27 07:10:48 - progress_bar.py[line:272] - INFO: epoch 004:    643 / 2637 loss=2.276, loss_v1=0, loss_v2=0, nll_loss=1.068, ntokens=1260.1, nsentences=160, sample_size=1260.1, sample_size_v1=0, sample_size_v2=0, ppl=2.1, wps=605.2, ups=0.48, wpb=1260.1, bsz=160, num_updates=8540, lr=2.54547e-05, gnorm=4.635, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=17849
2023-06-27 07:11:09 - progress_bar.py[line:272] - INFO: epoch 004:    653 / 2637 loss=2.326, loss_v1=0, loss_v2=0, nll_loss=1.124, ntokens=1246.2, nsentences=160, sample_size=1246.2, sample_size_v1=0, sample_size_v2=0, ppl=2.18, wps=599.1, ups=0.48, wpb=1246.2, bsz=160, num_updates=8550, lr=2.54472e-05, gnorm=5.29, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=17870
2023-06-27 07:11:30 - progress_bar.py[line:272] - INFO: epoch 004:    663 / 2637 loss=2.328, loss_v1=0, loss_v2=0, nll_loss=1.124, ntokens=1256.1, nsentences=160, sample_size=1256.1, sample_size_v1=0, sample_size_v2=0, ppl=2.18, wps=603.5, ups=0.48, wpb=1256.1, bsz=160, num_updates=8560, lr=2.54396e-05, gnorm=5.064, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=17890
2023-06-27 07:11:51 - progress_bar.py[line:272] - INFO: epoch 004:    673 / 2637 loss=2.308, loss_v1=0, loss_v2=0, nll_loss=1.102, ntokens=1251, nsentences=160, sample_size=1251, sample_size_v1=0, sample_size_v2=0, ppl=2.15, wps=600.6, ups=0.48, wpb=1251, bsz=160, num_updates=8570, lr=2.5432e-05, gnorm=4.398, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=17911
2023-06-27 07:12:12 - progress_bar.py[line:272] - INFO: epoch 004:    683 / 2637 loss=2.319, loss_v1=0, loss_v2=0, nll_loss=1.114, ntokens=1289.5, nsentences=160, sample_size=1289.5, sample_size_v1=0, sample_size_v2=0, ppl=2.17, wps=619.1, ups=0.48, wpb=1289.5, bsz=160, num_updates=8580, lr=2.54245e-05, gnorm=4.429, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=17932
2023-06-27 07:12:33 - progress_bar.py[line:272] - INFO: epoch 004:    693 / 2637 loss=2.328, loss_v1=0, loss_v2=0, nll_loss=1.124, ntokens=1270.7, nsentences=160, sample_size=1270.7, sample_size_v1=0, sample_size_v2=0, ppl=2.18, wps=610.3, ups=0.48, wpb=1270.7, bsz=160, num_updates=8590, lr=2.54169e-05, gnorm=4.685, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=17953
2023-06-27 07:12:53 - progress_bar.py[line:272] - INFO: epoch 004:    703 / 2637 loss=2.306, loss_v1=0, loss_v2=0, nll_loss=1.1, ntokens=1256.4, nsentences=160, sample_size=1256.4, sample_size_v1=0, sample_size_v2=0, ppl=2.14, wps=603.3, ups=0.48, wpb=1256.4, bsz=160, num_updates=8600, lr=2.54093e-05, gnorm=4.451, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=17974
2023-06-27 07:13:14 - progress_bar.py[line:272] - INFO: epoch 004:    713 / 2637 loss=2.319, loss_v1=0, loss_v2=0, nll_loss=1.113, ntokens=1257.3, nsentences=160, sample_size=1257.3, sample_size_v1=0, sample_size_v2=0, ppl=2.16, wps=603.6, ups=0.48, wpb=1257.3, bsz=160, num_updates=8610, lr=2.54018e-05, gnorm=4.651, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=17994
2023-06-27 07:13:35 - progress_bar.py[line:272] - INFO: epoch 004:    723 / 2637 loss=2.32, loss_v1=0, loss_v2=0, nll_loss=1.115, ntokens=1245.7, nsentences=160, sample_size=1245.7, sample_size_v1=0, sample_size_v2=0, ppl=2.17, wps=598.4, ups=0.48, wpb=1245.7, bsz=160, num_updates=8620, lr=2.53942e-05, gnorm=4.28, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=18015
2023-06-27 07:13:56 - progress_bar.py[line:272] - INFO: epoch 004:    733 / 2637 loss=2.309, loss_v1=0, loss_v2=0, nll_loss=1.106, ntokens=1273.3, nsentences=160, sample_size=1273.3, sample_size_v1=0, sample_size_v2=0, ppl=2.15, wps=612.1, ups=0.48, wpb=1273.3, bsz=160, num_updates=8630, lr=2.53867e-05, gnorm=4.157, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=18036
2023-06-27 07:14:17 - progress_bar.py[line:272] - INFO: epoch 004:    743 / 2637 loss=2.327, loss_v1=0, loss_v2=0, nll_loss=1.124, ntokens=1263, nsentences=160, sample_size=1263, sample_size_v1=0, sample_size_v2=0, ppl=2.18, wps=606.6, ups=0.48, wpb=1263, bsz=160, num_updates=8640, lr=2.53791e-05, gnorm=4.465, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=18057
2023-06-27 07:14:37 - progress_bar.py[line:272] - INFO: epoch 004:    753 / 2637 loss=2.332, loss_v1=0, loss_v2=0, nll_loss=1.13, ntokens=1261.7, nsentences=160, sample_size=1261.7, sample_size_v1=0, sample_size_v2=0, ppl=2.19, wps=605.8, ups=0.48, wpb=1261.7, bsz=160, num_updates=8650, lr=2.53715e-05, gnorm=4.409, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=18078
2023-06-27 07:14:58 - progress_bar.py[line:272] - INFO: epoch 004:    763 / 2637 loss=2.302, loss_v1=0, loss_v2=0, nll_loss=1.094, ntokens=1261, nsentences=160, sample_size=1261, sample_size_v1=0, sample_size_v2=0, ppl=2.13, wps=605.9, ups=0.48, wpb=1261, bsz=160, num_updates=8660, lr=2.5364e-05, gnorm=4.39, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=18099
2023-06-27 07:15:19 - progress_bar.py[line:272] - INFO: epoch 004:    773 / 2637 loss=2.32, loss_v1=0, loss_v2=0, nll_loss=1.116, ntokens=1253.2, nsentences=160, sample_size=1253.2, sample_size_v1=0, sample_size_v2=0, ppl=2.17, wps=602.3, ups=0.48, wpb=1253.2, bsz=160, num_updates=8670, lr=2.53564e-05, gnorm=4.13, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=18119
2023-06-27 07:15:40 - progress_bar.py[line:272] - INFO: epoch 004:    783 / 2637 loss=2.305, loss_v1=0, loss_v2=0, nll_loss=1.1, ntokens=1262.7, nsentences=160, sample_size=1262.7, sample_size_v1=0, sample_size_v2=0, ppl=2.14, wps=606.1, ups=0.48, wpb=1262.7, bsz=160, num_updates=8680, lr=2.53488e-05, gnorm=5.026, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=18140
2023-06-27 07:16:01 - progress_bar.py[line:272] - INFO: epoch 004:    793 / 2637 loss=2.325, loss_v1=0, loss_v2=0, nll_loss=1.122, ntokens=1257.6, nsentences=160, sample_size=1257.6, sample_size_v1=0, sample_size_v2=0, ppl=2.18, wps=603.3, ups=0.48, wpb=1257.6, bsz=160, num_updates=8690, lr=2.53413e-05, gnorm=4.77, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=18161
2023-06-27 07:16:22 - progress_bar.py[line:272] - INFO: epoch 004:    803 / 2637 loss=2.301, loss_v1=0, loss_v2=0, nll_loss=1.093, ntokens=1252.9, nsentences=160, sample_size=1252.9, sample_size_v1=0, sample_size_v2=0, ppl=2.13, wps=601.3, ups=0.48, wpb=1252.9, bsz=160, num_updates=8700, lr=2.53337e-05, gnorm=4.558, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=18182
2023-06-27 07:16:42 - progress_bar.py[line:272] - INFO: epoch 004:    813 / 2637 loss=2.293, loss_v1=0, loss_v2=0, nll_loss=1.085, ntokens=1237.8, nsentences=160, sample_size=1237.8, sample_size_v1=0, sample_size_v2=0, ppl=2.12, wps=594.9, ups=0.48, wpb=1237.8, bsz=160, num_updates=8710, lr=2.53261e-05, gnorm=4.629, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=18203
2023-06-27 07:17:03 - progress_bar.py[line:272] - INFO: epoch 004:    823 / 2637 loss=2.301, loss_v1=0, loss_v2=0, nll_loss=1.095, ntokens=1277.3, nsentences=160, sample_size=1277.3, sample_size_v1=0, sample_size_v2=0, ppl=2.14, wps=612.2, ups=0.48, wpb=1277.3, bsz=160, num_updates=8720, lr=2.53186e-05, gnorm=5.659, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=18224
2023-06-27 07:17:24 - progress_bar.py[line:272] - INFO: epoch 004:    833 / 2637 loss=2.335, loss_v1=0, loss_v2=0, nll_loss=1.135, ntokens=1252.2, nsentences=160, sample_size=1252.2, sample_size_v1=0, sample_size_v2=0, ppl=2.2, wps=600.1, ups=0.48, wpb=1252.2, bsz=160, num_updates=8730, lr=2.5311e-05, gnorm=4.366, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=18244
2023-06-27 07:17:45 - progress_bar.py[line:272] - INFO: epoch 004:    843 / 2637 loss=2.303, loss_v1=0, loss_v2=0, nll_loss=1.095, ntokens=1269.6, nsentences=160, sample_size=1269.6, sample_size_v1=0, sample_size_v2=0, ppl=2.14, wps=608.4, ups=0.48, wpb=1269.6, bsz=160, num_updates=8740, lr=2.53034e-05, gnorm=4.797, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=18265
2023-06-27 07:18:06 - progress_bar.py[line:272] - INFO: epoch 004:    853 / 2637 loss=2.317, loss_v1=0, loss_v2=0, nll_loss=1.114, ntokens=1237.3, nsentences=160, sample_size=1237.3, sample_size_v1=0, sample_size_v2=0, ppl=2.16, wps=592.5, ups=0.48, wpb=1237.3, bsz=160, num_updates=8750, lr=2.52959e-05, gnorm=5.48, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=18286
2023-06-27 07:18:27 - progress_bar.py[line:272] - INFO: epoch 004:    863 / 2637 loss=2.307, loss_v1=0, loss_v2=0, nll_loss=1.1, ntokens=1244.5, nsentences=160, sample_size=1244.5, sample_size_v1=0, sample_size_v2=0, ppl=2.14, wps=597.4, ups=0.48, wpb=1244.5, bsz=160, num_updates=8760, lr=2.52883e-05, gnorm=4.375, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=18307
2023-06-27 07:18:48 - progress_bar.py[line:272] - INFO: epoch 004:    873 / 2637 loss=2.319, loss_v1=0, loss_v2=0, nll_loss=1.114, ntokens=1239.1, nsentences=160, sample_size=1239.1, sample_size_v1=0, sample_size_v2=0, ppl=2.16, wps=595.3, ups=0.48, wpb=1239.1, bsz=160, num_updates=8770, lr=2.52808e-05, gnorm=5.139, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=18328
2023-06-27 07:19:08 - progress_bar.py[line:272] - INFO: epoch 004:    883 / 2637 loss=2.31, loss_v1=0, loss_v2=0, nll_loss=1.102, ntokens=1263.7, nsentences=160, sample_size=1263.7, sample_size_v1=0, sample_size_v2=0, ppl=2.15, wps=606.7, ups=0.48, wpb=1263.7, bsz=160, num_updates=8780, lr=2.52732e-05, gnorm=4.953, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=18349
2023-06-27 07:19:29 - progress_bar.py[line:272] - INFO: epoch 004:    893 / 2637 loss=2.288, loss_v1=0, loss_v2=0, nll_loss=1.082, ntokens=1251.8, nsentences=160, sample_size=1251.8, sample_size_v1=0, sample_size_v2=0, ppl=2.12, wps=601, ups=0.48, wpb=1251.8, bsz=160, num_updates=8790, lr=2.52656e-05, gnorm=4.808, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=18370
2023-06-27 07:19:50 - progress_bar.py[line:272] - INFO: epoch 004:    903 / 2637 loss=2.3, loss_v1=0, loss_v2=0, nll_loss=1.094, ntokens=1249.7, nsentences=160, sample_size=1249.7, sample_size_v1=0, sample_size_v2=0, ppl=2.13, wps=599.6, ups=0.48, wpb=1249.7, bsz=160, num_updates=8800, lr=2.52581e-05, gnorm=4.689, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=18390
2023-06-27 07:20:11 - progress_bar.py[line:272] - INFO: epoch 004:    913 / 2637 loss=2.274, loss_v1=0, loss_v2=0, nll_loss=1.066, ntokens=1255.6, nsentences=160, sample_size=1255.6, sample_size_v1=0, sample_size_v2=0, ppl=2.09, wps=601.9, ups=0.48, wpb=1255.6, bsz=160, num_updates=8810, lr=2.52505e-05, gnorm=4.61, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=18411
2023-06-27 07:20:32 - progress_bar.py[line:272] - INFO: epoch 004:    923 / 2637 loss=2.308, loss_v1=0, loss_v2=0, nll_loss=1.103, ntokens=1246.3, nsentences=160, sample_size=1246.3, sample_size_v1=0, sample_size_v2=0, ppl=2.15, wps=597.5, ups=0.48, wpb=1246.3, bsz=160, num_updates=8820, lr=2.52429e-05, gnorm=4.702, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=18432
2023-06-27 07:20:53 - progress_bar.py[line:272] - INFO: epoch 004:    933 / 2637 loss=2.292, loss_v1=0, loss_v2=0, nll_loss=1.082, ntokens=1265.8, nsentences=160, sample_size=1265.8, sample_size_v1=0, sample_size_v2=0, ppl=2.12, wps=607, ups=0.48, wpb=1265.8, bsz=160, num_updates=8830, lr=2.52354e-05, gnorm=4.88, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=18453
2023-06-27 07:21:14 - progress_bar.py[line:272] - INFO: epoch 004:    943 / 2637 loss=2.32, loss_v1=0, loss_v2=0, nll_loss=1.117, ntokens=1247.8, nsentences=160, sample_size=1247.8, sample_size_v1=0, sample_size_v2=0, ppl=2.17, wps=597.2, ups=0.48, wpb=1247.8, bsz=160, num_updates=8840, lr=2.52278e-05, gnorm=4.93, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=18474
2023-06-27 07:21:34 - progress_bar.py[line:272] - INFO: epoch 004:    953 / 2637 loss=2.328, loss_v1=0, loss_v2=0, nll_loss=1.124, ntokens=1253.4, nsentences=160, sample_size=1253.4, sample_size_v1=0, sample_size_v2=0, ppl=2.18, wps=601.4, ups=0.48, wpb=1253.4, bsz=160, num_updates=8850, lr=2.52202e-05, gnorm=4.175, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=18495
2023-06-27 07:21:55 - progress_bar.py[line:272] - INFO: epoch 004:    963 / 2637 loss=2.313, loss_v1=0, loss_v2=0, nll_loss=1.109, ntokens=1240.5, nsentences=160, sample_size=1240.5, sample_size_v1=0, sample_size_v2=0, ppl=2.16, wps=595.2, ups=0.48, wpb=1240.5, bsz=160, num_updates=8860, lr=2.52127e-05, gnorm=4.975, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=18516
2023-06-27 07:22:16 - progress_bar.py[line:272] - INFO: epoch 004:    973 / 2637 loss=2.276, loss_v1=0, loss_v2=0, nll_loss=1.067, ntokens=1246.6, nsentences=160, sample_size=1246.6, sample_size_v1=0, sample_size_v2=0, ppl=2.1, wps=598, ups=0.48, wpb=1246.6, bsz=160, num_updates=8870, lr=2.52051e-05, gnorm=4.2, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=18536
2023-06-27 07:22:37 - progress_bar.py[line:272] - INFO: epoch 004:    983 / 2637 loss=2.326, loss_v1=0, loss_v2=0, nll_loss=1.121, ntokens=1236.1, nsentences=160, sample_size=1236.1, sample_size_v1=0, sample_size_v2=0, ppl=2.17, wps=592.6, ups=0.48, wpb=1236.1, bsz=160, num_updates=8880, lr=2.51975e-05, gnorm=4.83, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=18557
2023-06-27 07:22:58 - progress_bar.py[line:272] - INFO: epoch 004:    993 / 2637 loss=2.288, loss_v1=0, loss_v2=0, nll_loss=1.08, ntokens=1246, nsentences=160, sample_size=1246, sample_size_v1=0, sample_size_v2=0, ppl=2.11, wps=598.3, ups=0.48, wpb=1246, bsz=160, num_updates=8890, lr=2.519e-05, gnorm=4.029, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=18578
2023-06-27 07:23:19 - progress_bar.py[line:272] - INFO: epoch 004:   1003 / 2637 loss=2.296, loss_v1=0, loss_v2=0, nll_loss=1.092, ntokens=1241.6, nsentences=160, sample_size=1241.6, sample_size_v1=0, sample_size_v2=0, ppl=2.13, wps=594.7, ups=0.48, wpb=1241.6, bsz=160, num_updates=8900, lr=2.51824e-05, gnorm=4.654, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=18599
2023-06-27 07:23:40 - progress_bar.py[line:272] - INFO: epoch 004:   1013 / 2637 loss=2.311, loss_v1=0, loss_v2=0, nll_loss=1.105, ntokens=1240.6, nsentences=160, sample_size=1240.6, sample_size_v1=0, sample_size_v2=0, ppl=2.15, wps=595.4, ups=0.48, wpb=1240.6, bsz=160, num_updates=8910, lr=2.51749e-05, gnorm=6.004, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=18620
2023-06-27 07:24:00 - progress_bar.py[line:272] - INFO: epoch 004:   1023 / 2637 loss=2.299, loss_v1=0, loss_v2=0, nll_loss=1.092, ntokens=1241.4, nsentences=160, sample_size=1241.4, sample_size_v1=0, sample_size_v2=0, ppl=2.13, wps=595.3, ups=0.48, wpb=1241.4, bsz=160, num_updates=8920, lr=2.51673e-05, gnorm=4.764, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=18641
2023-06-27 07:24:21 - progress_bar.py[line:272] - INFO: epoch 004:   1033 / 2637 loss=2.293, loss_v1=0, loss_v2=0, nll_loss=1.084, ntokens=1268.5, nsentences=160, sample_size=1268.5, sample_size_v1=0, sample_size_v2=0, ppl=2.12, wps=608.2, ups=0.48, wpb=1268.5, bsz=160, num_updates=8930, lr=2.51597e-05, gnorm=5.246, clip=100, loss_scale=128, train_wall=21, gb_free=8.9, wall=18662
2023-06-27 07:24:42 - progress_bar.py[line:272] - INFO: epoch 004:   1043 / 2637 loss=2.301, loss_v1=0, loss_v2=0, nll_loss=1.096, ntokens=1238.4, nsentences=160, sample_size=1238.4, sample_size_v1=0, sample_size_v2=0, ppl=2.14, wps=593.9, ups=0.48, wpb=1238.4, bsz=160, num_updates=8940, lr=2.51522e-05, gnorm=4.818, clip=100, loss_scale=128, train_wall=21, gb_free=8.9, wall=18682
2023-06-27 07:25:03 - progress_bar.py[line:272] - INFO: epoch 004:   1053 / 2637 loss=2.285, loss_v1=0, loss_v2=0, nll_loss=1.077, ntokens=1261.5, nsentences=160, sample_size=1261.5, sample_size_v1=0, sample_size_v2=0, ppl=2.11, wps=604.5, ups=0.48, wpb=1261.5, bsz=160, num_updates=8950, lr=2.51446e-05, gnorm=4.686, clip=100, loss_scale=128, train_wall=21, gb_free=8.9, wall=18703
2023-06-27 07:25:24 - progress_bar.py[line:272] - INFO: epoch 004:   1063 / 2637 loss=2.312, loss_v1=0, loss_v2=0, nll_loss=1.107, ntokens=1238.5, nsentences=160, sample_size=1238.5, sample_size_v1=0, sample_size_v2=0, ppl=2.15, wps=593.9, ups=0.48, wpb=1238.5, bsz=160, num_updates=8960, lr=2.5137e-05, gnorm=4.109, clip=100, loss_scale=128, train_wall=21, gb_free=8.9, wall=18724
2023-06-27 07:25:45 - progress_bar.py[line:272] - INFO: epoch 004:   1073 / 2637 loss=2.288, loss_v1=0, loss_v2=0, nll_loss=1.08, ntokens=1235.8, nsentences=160, sample_size=1235.8, sample_size_v1=0, sample_size_v2=0, ppl=2.11, wps=592.6, ups=0.48, wpb=1235.8, bsz=160, num_updates=8970, lr=2.51295e-05, gnorm=4.342, clip=100, loss_scale=128, train_wall=21, gb_free=8.9, wall=18745
2023-06-27 07:26:06 - progress_bar.py[line:272] - INFO: epoch 004:   1083 / 2637 loss=2.293, loss_v1=0, loss_v2=0, nll_loss=1.087, ntokens=1253.3, nsentences=160, sample_size=1253.3, sample_size_v1=0, sample_size_v2=0, ppl=2.12, wps=600.7, ups=0.48, wpb=1253.3, bsz=160, num_updates=8980, lr=2.51219e-05, gnorm=4.241, clip=100, loss_scale=128, train_wall=21, gb_free=8.9, wall=18766
2023-06-27 07:26:26 - progress_bar.py[line:272] - INFO: epoch 004:   1093 / 2637 loss=2.305, loss_v1=0, loss_v2=0, nll_loss=1.099, ntokens=1247.9, nsentences=160, sample_size=1247.9, sample_size_v1=0, sample_size_v2=0, ppl=2.14, wps=598.3, ups=0.48, wpb=1247.9, bsz=160, num_updates=8990, lr=2.51143e-05, gnorm=4.751, clip=100, loss_scale=128, train_wall=21, gb_free=8.9, wall=18787
2023-06-27 07:26:47 - progress_bar.py[line:272] - INFO: epoch 004:   1103 / 2637 loss=2.292, loss_v1=0, loss_v2=0, nll_loss=1.085, ntokens=1240.6, nsentences=160, sample_size=1240.6, sample_size_v1=0, sample_size_v2=0, ppl=2.12, wps=594.9, ups=0.48, wpb=1240.6, bsz=160, num_updates=9000, lr=2.51068e-05, gnorm=4.775, clip=100, loss_scale=128, train_wall=21, gb_free=8.9, wall=18808
2023-06-27 07:27:08 - progress_bar.py[line:272] - INFO: epoch 004:   1113 / 2637 loss=2.286, loss_v1=0, loss_v2=0, nll_loss=1.077, ntokens=1226.7, nsentences=160, sample_size=1226.7, sample_size_v1=0, sample_size_v2=0, ppl=2.11, wps=588.1, ups=0.48, wpb=1226.7, bsz=160, num_updates=9010, lr=2.50992e-05, gnorm=4.336, clip=100, loss_scale=128, train_wall=21, gb_free=8.9, wall=18828
2023-06-27 07:27:29 - progress_bar.py[line:272] - INFO: epoch 004:   1123 / 2637 loss=2.308, loss_v1=0, loss_v2=0, nll_loss=1.102, ntokens=1248.3, nsentences=160, sample_size=1248.3, sample_size_v1=0, sample_size_v2=0, ppl=2.15, wps=599.1, ups=0.48, wpb=1248.3, bsz=160, num_updates=9020, lr=2.50917e-05, gnorm=4.903, clip=100, loss_scale=128, train_wall=21, gb_free=8.9, wall=18849
2023-06-27 07:27:50 - progress_bar.py[line:272] - INFO: epoch 004:   1133 / 2637 loss=2.293, loss_v1=0, loss_v2=0, nll_loss=1.086, ntokens=1244.6, nsentences=160, sample_size=1244.6, sample_size_v1=0, sample_size_v2=0, ppl=2.12, wps=597, ups=0.48, wpb=1244.6, bsz=160, num_updates=9030, lr=2.50841e-05, gnorm=4.567, clip=100, loss_scale=128, train_wall=21, gb_free=8.9, wall=18870
2023-06-27 07:27:56 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2023-06-27 07:28:13 - progress_bar.py[line:272] - INFO: epoch 004:   1144 / 2637 loss=2.285, loss_v1=0, loss_v2=0, nll_loss=1.078, ntokens=1266.7, nsentences=160, sample_size=1266.7, sample_size_v1=0, sample_size_v2=0, ppl=2.11, wps=552.6, ups=0.44, wpb=1266.7, bsz=160, num_updates=9040, lr=2.50765e-05, gnorm=5.22, clip=100, loss_scale=64, train_wall=23, gb_free=8.9, wall=18893
2023-06-27 07:28:34 - progress_bar.py[line:272] - INFO: epoch 004:   1154 / 2637 loss=2.308, loss_v1=0, loss_v2=0, nll_loss=1.102, ntokens=1246.9, nsentences=160, sample_size=1246.9, sample_size_v1=0, sample_size_v2=0, ppl=2.15, wps=597.8, ups=0.48, wpb=1246.9, bsz=160, num_updates=9050, lr=2.5069e-05, gnorm=4.377, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=18914
2023-06-27 07:28:54 - progress_bar.py[line:272] - INFO: epoch 004:   1164 / 2637 loss=2.296, loss_v1=0, loss_v2=0, nll_loss=1.089, ntokens=1243.6, nsentences=160, sample_size=1243.6, sample_size_v1=0, sample_size_v2=0, ppl=2.13, wps=596.2, ups=0.48, wpb=1243.6, bsz=160, num_updates=9060, lr=2.50614e-05, gnorm=4.507, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=18935
2023-06-27 07:29:15 - progress_bar.py[line:272] - INFO: epoch 004:   1174 / 2637 loss=2.293, loss_v1=0, loss_v2=0, nll_loss=1.086, ntokens=1244.9, nsentences=160, sample_size=1244.9, sample_size_v1=0, sample_size_v2=0, ppl=2.12, wps=597.6, ups=0.48, wpb=1244.9, bsz=160, num_updates=9070, lr=2.50538e-05, gnorm=5.046, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=18956
2023-06-27 07:29:36 - progress_bar.py[line:272] - INFO: epoch 004:   1184 / 2637 loss=2.273, loss_v1=0, loss_v2=0, nll_loss=1.063, ntokens=1254.7, nsentences=160, sample_size=1254.7, sample_size_v1=0, sample_size_v2=0, ppl=2.09, wps=602.2, ups=0.48, wpb=1254.7, bsz=160, num_updates=9080, lr=2.50463e-05, gnorm=5.092, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=18976
2023-06-27 07:29:57 - progress_bar.py[line:272] - INFO: epoch 004:   1194 / 2637 loss=2.309, loss_v1=0, loss_v2=0, nll_loss=1.103, ntokens=1255.2, nsentences=160, sample_size=1255.2, sample_size_v1=0, sample_size_v2=0, ppl=2.15, wps=602.4, ups=0.48, wpb=1255.2, bsz=160, num_updates=9090, lr=2.50387e-05, gnorm=4.489, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=18997
2023-06-27 07:30:18 - progress_bar.py[line:272] - INFO: epoch 004:   1204 / 2637 loss=2.299, loss_v1=0, loss_v2=0, nll_loss=1.095, ntokens=1255.2, nsentences=160, sample_size=1255.2, sample_size_v1=0, sample_size_v2=0, ppl=2.14, wps=601.7, ups=0.48, wpb=1255.2, bsz=160, num_updates=9100, lr=2.50311e-05, gnorm=4.856, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=19018
2023-06-27 07:30:39 - progress_bar.py[line:272] - INFO: epoch 004:   1214 / 2637 loss=2.299, loss_v1=0, loss_v2=0, nll_loss=1.092, ntokens=1249, nsentences=160, sample_size=1249, sample_size_v1=0, sample_size_v2=0, ppl=2.13, wps=598.8, ups=0.48, wpb=1249, bsz=160, num_updates=9110, lr=2.50236e-05, gnorm=4.858, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=19039
2023-06-27 07:31:00 - progress_bar.py[line:272] - INFO: epoch 004:   1224 / 2637 loss=2.293, loss_v1=0, loss_v2=0, nll_loss=1.085, ntokens=1259.6, nsentences=160, sample_size=1259.6, sample_size_v1=0, sample_size_v2=0, ppl=2.12, wps=604.2, ups=0.48, wpb=1259.6, bsz=160, num_updates=9120, lr=2.5016e-05, gnorm=4.49, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=19060
2023-06-27 07:31:20 - progress_bar.py[line:272] - INFO: epoch 004:   1234 / 2637 loss=2.29, loss_v1=0, loss_v2=0, nll_loss=1.082, ntokens=1227.6, nsentences=160, sample_size=1227.6, sample_size_v1=0, sample_size_v2=0, ppl=2.12, wps=589, ups=0.48, wpb=1227.6, bsz=160, num_updates=9130, lr=2.50084e-05, gnorm=4.295, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=19081
2023-06-27 07:31:41 - progress_bar.py[line:272] - INFO: epoch 004:   1244 / 2637 loss=2.288, loss_v1=0, loss_v2=0, nll_loss=1.079, ntokens=1234.2, nsentences=160, sample_size=1234.2, sample_size_v1=0, sample_size_v2=0, ppl=2.11, wps=591.7, ups=0.48, wpb=1234.2, bsz=160, num_updates=9140, lr=2.50009e-05, gnorm=4.393, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=19102
2023-06-27 07:32:02 - progress_bar.py[line:272] - INFO: epoch 004:   1254 / 2637 loss=2.284, loss_v1=0, loss_v2=0, nll_loss=1.076, ntokens=1243.8, nsentences=160, sample_size=1243.8, sample_size_v1=0, sample_size_v2=0, ppl=2.11, wps=596, ups=0.48, wpb=1243.8, bsz=160, num_updates=9150, lr=2.49933e-05, gnorm=4.308, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=19122
2023-06-27 07:32:23 - progress_bar.py[line:272] - INFO: epoch 004:   1264 / 2637 loss=2.298, loss_v1=0, loss_v2=0, nll_loss=1.092, ntokens=1247.2, nsentences=160, sample_size=1247.2, sample_size_v1=0, sample_size_v2=0, ppl=2.13, wps=598.3, ups=0.48, wpb=1247.2, bsz=160, num_updates=9160, lr=2.49858e-05, gnorm=4.273, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=19143
2023-06-27 07:32:44 - progress_bar.py[line:272] - INFO: epoch 004:   1274 / 2637 loss=2.311, loss_v1=0, loss_v2=0, nll_loss=1.105, ntokens=1256.8, nsentences=160, sample_size=1256.8, sample_size_v1=0, sample_size_v2=0, ppl=2.15, wps=602.7, ups=0.48, wpb=1256.8, bsz=160, num_updates=9170, lr=2.49782e-05, gnorm=3.909, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=19164
2023-06-27 07:33:05 - progress_bar.py[line:272] - INFO: epoch 004:   1284 / 2637 loss=2.292, loss_v1=0, loss_v2=0, nll_loss=1.084, ntokens=1241.1, nsentences=160, sample_size=1241.1, sample_size_v1=0, sample_size_v2=0, ppl=2.12, wps=595.1, ups=0.48, wpb=1241.1, bsz=160, num_updates=9180, lr=2.49706e-05, gnorm=4.617, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=19185
2023-06-27 07:33:26 - progress_bar.py[line:272] - INFO: epoch 004:   1294 / 2637 loss=2.29, loss_v1=0, loss_v2=0, nll_loss=1.084, ntokens=1237.1, nsentences=160, sample_size=1237.1, sample_size_v1=0, sample_size_v2=0, ppl=2.12, wps=593.5, ups=0.48, wpb=1237.1, bsz=160, num_updates=9190, lr=2.49631e-05, gnorm=4.188, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=19206
2023-06-27 07:33:46 - progress_bar.py[line:272] - INFO: epoch 004:   1304 / 2637 loss=2.288, loss_v1=0, loss_v2=0, nll_loss=1.078, ntokens=1252.8, nsentences=160, sample_size=1252.8, sample_size_v1=0, sample_size_v2=0, ppl=2.11, wps=601, ups=0.48, wpb=1252.8, bsz=160, num_updates=9200, lr=2.49555e-05, gnorm=4.919, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=19227
2023-06-27 07:34:07 - progress_bar.py[line:272] - INFO: epoch 004:   1314 / 2637 loss=2.278, loss_v1=0, loss_v2=0, nll_loss=1.069, ntokens=1234.9, nsentences=160, sample_size=1234.9, sample_size_v1=0, sample_size_v2=0, ppl=2.1, wps=592.4, ups=0.48, wpb=1234.9, bsz=160, num_updates=9210, lr=2.49479e-05, gnorm=4.758, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=19248
2023-06-27 07:34:28 - progress_bar.py[line:272] - INFO: epoch 004:   1324 / 2637 loss=2.285, loss_v1=0, loss_v2=0, nll_loss=1.077, ntokens=1233.8, nsentences=160, sample_size=1233.8, sample_size_v1=0, sample_size_v2=0, ppl=2.11, wps=591.6, ups=0.48, wpb=1233.8, bsz=160, num_updates=9220, lr=2.49404e-05, gnorm=5.109, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=19268
2023-06-27 07:34:49 - progress_bar.py[line:272] - INFO: epoch 004:   1334 / 2637 loss=2.295, loss_v1=0, loss_v2=0, nll_loss=1.087, ntokens=1240.1, nsentences=160, sample_size=1240.1, sample_size_v1=0, sample_size_v2=0, ppl=2.12, wps=594.6, ups=0.48, wpb=1240.1, bsz=160, num_updates=9230, lr=2.49328e-05, gnorm=5.382, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=19289
2023-06-27 07:35:10 - progress_bar.py[line:272] - INFO: epoch 004:   1344 / 2637 loss=2.297, loss_v1=0, loss_v2=0, nll_loss=1.092, ntokens=1224.2, nsentences=160, sample_size=1224.2, sample_size_v1=0, sample_size_v2=0, ppl=2.13, wps=587.2, ups=0.48, wpb=1224.2, bsz=160, num_updates=9240, lr=2.49252e-05, gnorm=5.68, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=19310
2023-06-27 07:35:31 - progress_bar.py[line:272] - INFO: epoch 004:   1354 / 2637 loss=2.283, loss_v1=0, loss_v2=0, nll_loss=1.073, ntokens=1234.4, nsentences=160, sample_size=1234.4, sample_size_v1=0, sample_size_v2=0, ppl=2.1, wps=591.7, ups=0.48, wpb=1234.4, bsz=160, num_updates=9250, lr=2.49177e-05, gnorm=4.707, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=19331
2023-06-27 07:35:52 - progress_bar.py[line:272] - INFO: epoch 004:   1364 / 2637 loss=2.301, loss_v1=0, loss_v2=0, nll_loss=1.095, ntokens=1238.2, nsentences=160, sample_size=1238.2, sample_size_v1=0, sample_size_v2=0, ppl=2.14, wps=593.6, ups=0.48, wpb=1238.2, bsz=160, num_updates=9260, lr=2.49101e-05, gnorm=4.835, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=19352
2023-06-27 07:36:12 - progress_bar.py[line:272] - INFO: epoch 004:   1374 / 2637 loss=2.325, loss_v1=0, loss_v2=0, nll_loss=1.122, ntokens=1232.1, nsentences=160, sample_size=1232.1, sample_size_v1=0, sample_size_v2=0, ppl=2.18, wps=590.8, ups=0.48, wpb=1232.1, bsz=160, num_updates=9270, lr=2.49025e-05, gnorm=5.338, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=19373
2023-06-27 07:36:33 - progress_bar.py[line:272] - INFO: epoch 004:   1384 / 2637 loss=2.292, loss_v1=0, loss_v2=0, nll_loss=1.086, ntokens=1250.4, nsentences=160, sample_size=1250.4, sample_size_v1=0, sample_size_v2=0, ppl=2.12, wps=598.3, ups=0.48, wpb=1250.4, bsz=160, num_updates=9280, lr=2.4895e-05, gnorm=5.201, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=19394
2023-06-27 07:36:54 - progress_bar.py[line:272] - INFO: epoch 004:   1394 / 2637 loss=2.279, loss_v1=0, loss_v2=0, nll_loss=1.071, ntokens=1281.1, nsentences=160, sample_size=1281.1, sample_size_v1=0, sample_size_v2=0, ppl=2.1, wps=613.2, ups=0.48, wpb=1281.1, bsz=160, num_updates=9290, lr=2.48874e-05, gnorm=4.767, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=19415
2023-06-27 07:37:15 - progress_bar.py[line:272] - INFO: epoch 004:   1404 / 2637 loss=2.294, loss_v1=0, loss_v2=0, nll_loss=1.086, ntokens=1265.5, nsentences=160, sample_size=1265.5, sample_size_v1=0, sample_size_v2=0, ppl=2.12, wps=606.4, ups=0.48, wpb=1265.5, bsz=160, num_updates=9300, lr=2.48799e-05, gnorm=4.35, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=19435
2023-06-27 07:37:36 - progress_bar.py[line:272] - INFO: epoch 004:   1414 / 2637 loss=2.291, loss_v1=0, loss_v2=0, nll_loss=1.081, ntokens=1268.9, nsentences=160, sample_size=1268.9, sample_size_v1=0, sample_size_v2=0, ppl=2.12, wps=607.6, ups=0.48, wpb=1268.9, bsz=160, num_updates=9310, lr=2.48723e-05, gnorm=4.279, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=19456
2023-06-27 07:37:57 - progress_bar.py[line:272] - INFO: epoch 004:   1424 / 2637 loss=2.293, loss_v1=0, loss_v2=0, nll_loss=1.086, ntokens=1279.5, nsentences=160, sample_size=1279.5, sample_size_v1=0, sample_size_v2=0, ppl=2.12, wps=612.3, ups=0.48, wpb=1279.5, bsz=160, num_updates=9320, lr=2.48647e-05, gnorm=4.089, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=19477
2023-06-27 07:38:18 - progress_bar.py[line:272] - INFO: epoch 004:   1434 / 2637 loss=2.274, loss_v1=0, loss_v2=0, nll_loss=1.067, ntokens=1275.1, nsentences=160, sample_size=1275.1, sample_size_v1=0, sample_size_v2=0, ppl=2.09, wps=610.4, ups=0.48, wpb=1275.1, bsz=160, num_updates=9330, lr=2.48572e-05, gnorm=4.51, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=19498
2023-06-27 07:38:39 - progress_bar.py[line:272] - INFO: epoch 004:   1444 / 2637 loss=2.278, loss_v1=0, loss_v2=0, nll_loss=1.07, ntokens=1284.7, nsentences=160, sample_size=1284.7, sample_size_v1=0, sample_size_v2=0, ppl=2.1, wps=615.4, ups=0.48, wpb=1284.7, bsz=160, num_updates=9340, lr=2.48496e-05, gnorm=4.798, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=19519
2023-06-27 07:39:00 - progress_bar.py[line:272] - INFO: epoch 004:   1454 / 2637 loss=2.298, loss_v1=0, loss_v2=0, nll_loss=1.089, ntokens=1279.9, nsentences=160, sample_size=1279.9, sample_size_v1=0, sample_size_v2=0, ppl=2.13, wps=612.6, ups=0.48, wpb=1279.9, bsz=160, num_updates=9350, lr=2.4842e-05, gnorm=4.832, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=19540
2023-06-27 07:39:20 - progress_bar.py[line:272] - INFO: epoch 004:   1464 / 2637 loss=2.304, loss_v1=0, loss_v2=0, nll_loss=1.097, ntokens=1277.3, nsentences=160, sample_size=1277.3, sample_size_v1=0, sample_size_v2=0, ppl=2.14, wps=611.6, ups=0.48, wpb=1277.3, bsz=160, num_updates=9360, lr=2.48345e-05, gnorm=4.095, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=19561
2023-06-27 07:39:41 - progress_bar.py[line:272] - INFO: epoch 004:   1474 / 2637 loss=2.284, loss_v1=0, loss_v2=0, nll_loss=1.077, ntokens=1266.6, nsentences=160, sample_size=1266.6, sample_size_v1=0, sample_size_v2=0, ppl=2.11, wps=606.7, ups=0.48, wpb=1266.6, bsz=160, num_updates=9370, lr=2.48269e-05, gnorm=4.516, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=19582
2023-06-27 07:40:02 - progress_bar.py[line:272] - INFO: epoch 004:   1484 / 2637 loss=2.297, loss_v1=0, loss_v2=0, nll_loss=1.091, ntokens=1271.2, nsentences=160, sample_size=1271.2, sample_size_v1=0, sample_size_v2=0, ppl=2.13, wps=609, ups=0.48, wpb=1271.2, bsz=160, num_updates=9380, lr=2.48193e-05, gnorm=4.673, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=19602
2023-06-27 07:40:23 - progress_bar.py[line:272] - INFO: epoch 004:   1494 / 2637 loss=2.291, loss_v1=0, loss_v2=0, nll_loss=1.085, ntokens=1299.7, nsentences=160, sample_size=1299.7, sample_size_v1=0, sample_size_v2=0, ppl=2.12, wps=623.9, ups=0.48, wpb=1299.7, bsz=160, num_updates=9390, lr=2.48118e-05, gnorm=3.943, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=19623
2023-06-27 07:40:44 - progress_bar.py[line:272] - INFO: epoch 004:   1504 / 2637 loss=2.282, loss_v1=0, loss_v2=0, nll_loss=1.073, ntokens=1266.6, nsentences=160, sample_size=1266.6, sample_size_v1=0, sample_size_v2=0, ppl=2.1, wps=607.6, ups=0.48, wpb=1266.6, bsz=160, num_updates=9400, lr=2.48042e-05, gnorm=4.912, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=19644
2023-06-27 07:41:05 - progress_bar.py[line:272] - INFO: epoch 004:   1514 / 2637 loss=2.299, loss_v1=0, loss_v2=0, nll_loss=1.092, ntokens=1281.2, nsentences=160, sample_size=1281.2, sample_size_v1=0, sample_size_v2=0, ppl=2.13, wps=614, ups=0.48, wpb=1281.2, bsz=160, num_updates=9410, lr=2.47967e-05, gnorm=5.317, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=19665
2023-06-27 07:41:26 - progress_bar.py[line:272] - INFO: epoch 004:   1524 / 2637 loss=2.314, loss_v1=0, loss_v2=0, nll_loss=1.109, ntokens=1259.6, nsentences=160, sample_size=1259.6, sample_size_v1=0, sample_size_v2=0, ppl=2.16, wps=603.4, ups=0.48, wpb=1259.6, bsz=160, num_updates=9420, lr=2.47891e-05, gnorm=4.505, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=19686
2023-06-27 07:41:47 - progress_bar.py[line:272] - INFO: epoch 004:   1534 / 2637 loss=2.302, loss_v1=0, loss_v2=0, nll_loss=1.095, ntokens=1264.3, nsentences=160, sample_size=1264.3, sample_size_v1=0, sample_size_v2=0, ppl=2.14, wps=604.9, ups=0.48, wpb=1264.3, bsz=160, num_updates=9430, lr=2.47815e-05, gnorm=4.572, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=19707
2023-06-27 07:42:07 - progress_bar.py[line:272] - INFO: epoch 004:   1544 / 2637 loss=2.299, loss_v1=0, loss_v2=0, nll_loss=1.093, ntokens=1259.7, nsentences=160, sample_size=1259.7, sample_size_v1=0, sample_size_v2=0, ppl=2.13, wps=603.5, ups=0.48, wpb=1259.7, bsz=160, num_updates=9440, lr=2.4774e-05, gnorm=3.936, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=19728
2023-06-27 07:42:28 - progress_bar.py[line:272] - INFO: epoch 004:   1554 / 2637 loss=2.318, loss_v1=0, loss_v2=0, nll_loss=1.114, ntokens=1280.3, nsentences=160, sample_size=1280.3, sample_size_v1=0, sample_size_v2=0, ppl=2.16, wps=612.8, ups=0.48, wpb=1280.3, bsz=160, num_updates=9450, lr=2.47664e-05, gnorm=4.077, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=19749
2023-06-27 07:42:49 - progress_bar.py[line:272] - INFO: epoch 004:   1564 / 2637 loss=2.283, loss_v1=0, loss_v2=0, nll_loss=1.073, ntokens=1271.4, nsentences=160, sample_size=1271.4, sample_size_v1=0, sample_size_v2=0, ppl=2.1, wps=609, ups=0.48, wpb=1271.4, bsz=160, num_updates=9460, lr=2.47588e-05, gnorm=4.665, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=19769
2023-06-27 07:43:10 - progress_bar.py[line:272] - INFO: epoch 004:   1574 / 2637 loss=2.289, loss_v1=0, loss_v2=0, nll_loss=1.08, ntokens=1258.2, nsentences=160, sample_size=1258.2, sample_size_v1=0, sample_size_v2=0, ppl=2.11, wps=603.1, ups=0.48, wpb=1258.2, bsz=160, num_updates=9470, lr=2.47513e-05, gnorm=4.293, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=19790
2023-06-27 07:43:31 - progress_bar.py[line:272] - INFO: epoch 004:   1584 / 2637 loss=2.298, loss_v1=0, loss_v2=0, nll_loss=1.091, ntokens=1276.7, nsentences=160, sample_size=1276.7, sample_size_v1=0, sample_size_v2=0, ppl=2.13, wps=611.5, ups=0.48, wpb=1276.7, bsz=160, num_updates=9480, lr=2.47437e-05, gnorm=4.87, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=19811
2023-06-27 07:43:52 - progress_bar.py[line:272] - INFO: epoch 004:   1594 / 2637 loss=2.283, loss_v1=0, loss_v2=0, nll_loss=1.075, ntokens=1263, nsentences=160, sample_size=1263, sample_size_v1=0, sample_size_v2=0, ppl=2.11, wps=604.7, ups=0.48, wpb=1263, bsz=160, num_updates=9490, lr=2.47361e-05, gnorm=4.471, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=19832
2023-06-27 07:44:13 - progress_bar.py[line:272] - INFO: epoch 004:   1604 / 2637 loss=2.296, loss_v1=0, loss_v2=0, nll_loss=1.091, ntokens=1270.5, nsentences=160, sample_size=1270.5, sample_size_v1=0, sample_size_v2=0, ppl=2.13, wps=608.1, ups=0.48, wpb=1270.5, bsz=160, num_updates=9500, lr=2.47286e-05, gnorm=4.291, clip=100, loss_scale=64, train_wall=21, gb_free=8.7, wall=19853
2023-06-27 07:44:34 - progress_bar.py[line:272] - INFO: epoch 004:   1614 / 2637 loss=2.313, loss_v1=0, loss_v2=0, nll_loss=1.109, ntokens=1262.8, nsentences=160, sample_size=1262.8, sample_size_v1=0, sample_size_v2=0, ppl=2.16, wps=604.9, ups=0.48, wpb=1262.8, bsz=160, num_updates=9510, lr=2.4721e-05, gnorm=4.21, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=19874
2023-06-27 07:44:54 - progress_bar.py[line:272] - INFO: epoch 004:   1624 / 2637 loss=2.31, loss_v1=0, loss_v2=0, nll_loss=1.104, ntokens=1256, nsentences=160, sample_size=1256, sample_size_v1=0, sample_size_v2=0, ppl=2.15, wps=601.8, ups=0.48, wpb=1256, bsz=160, num_updates=9520, lr=2.47134e-05, gnorm=4.352, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=19895
2023-06-27 07:45:15 - progress_bar.py[line:272] - INFO: epoch 004:   1634 / 2637 loss=2.272, loss_v1=0, loss_v2=0, nll_loss=1.063, ntokens=1271.8, nsentences=160, sample_size=1271.8, sample_size_v1=0, sample_size_v2=0, ppl=2.09, wps=609.6, ups=0.48, wpb=1271.8, bsz=160, num_updates=9530, lr=2.47059e-05, gnorm=4.27, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=19916
2023-06-27 07:45:36 - progress_bar.py[line:272] - INFO: epoch 004:   1644 / 2637 loss=2.28, loss_v1=0, loss_v2=0, nll_loss=1.073, ntokens=1266.9, nsentences=160, sample_size=1266.9, sample_size_v1=0, sample_size_v2=0, ppl=2.1, wps=607.1, ups=0.48, wpb=1266.9, bsz=160, num_updates=9540, lr=2.46983e-05, gnorm=3.912, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=19936
2023-06-27 07:45:57 - progress_bar.py[line:272] - INFO: epoch 004:   1654 / 2637 loss=2.305, loss_v1=0, loss_v2=0, nll_loss=1.1, ntokens=1257.9, nsentences=160, sample_size=1257.9, sample_size_v1=0, sample_size_v2=0, ppl=2.14, wps=601.9, ups=0.48, wpb=1257.9, bsz=160, num_updates=9550, lr=2.46908e-05, gnorm=4.753, clip=100, loss_scale=128, train_wall=21, gb_free=8.9, wall=19957
2023-06-27 07:46:18 - progress_bar.py[line:272] - INFO: epoch 004:   1664 / 2637 loss=2.294, loss_v1=0, loss_v2=0, nll_loss=1.086, ntokens=1281, nsentences=160, sample_size=1281, sample_size_v1=0, sample_size_v2=0, ppl=2.12, wps=613.5, ups=0.48, wpb=1281, bsz=160, num_updates=9560, lr=2.46832e-05, gnorm=4.168, clip=100, loss_scale=128, train_wall=21, gb_free=8.9, wall=19978
2023-06-27 07:46:39 - progress_bar.py[line:272] - INFO: epoch 004:   1674 / 2637 loss=2.291, loss_v1=0, loss_v2=0, nll_loss=1.082, ntokens=1250.7, nsentences=160, sample_size=1250.7, sample_size_v1=0, sample_size_v2=0, ppl=2.12, wps=599.3, ups=0.48, wpb=1250.7, bsz=160, num_updates=9570, lr=2.46756e-05, gnorm=4.644, clip=100, loss_scale=128, train_wall=21, gb_free=8.9, wall=19999
2023-06-27 07:47:00 - progress_bar.py[line:272] - INFO: epoch 004:   1684 / 2637 loss=2.278, loss_v1=0, loss_v2=0, nll_loss=1.071, ntokens=1272.8, nsentences=160, sample_size=1272.8, sample_size_v1=0, sample_size_v2=0, ppl=2.1, wps=609.9, ups=0.48, wpb=1272.8, bsz=160, num_updates=9580, lr=2.46681e-05, gnorm=4.632, clip=100, loss_scale=128, train_wall=21, gb_free=8.9, wall=20020
2023-06-27 07:47:21 - progress_bar.py[line:272] - INFO: epoch 004:   1694 / 2637 loss=2.271, loss_v1=0, loss_v2=0, nll_loss=1.061, ntokens=1279.1, nsentences=159.9, sample_size=1279.1, sample_size_v1=0, sample_size_v2=0, ppl=2.09, wps=613.2, ups=0.48, wpb=1279.1, bsz=159.9, num_updates=9590, lr=2.46605e-05, gnorm=4.736, clip=100, loss_scale=128, train_wall=21, gb_free=8.9, wall=20041
2023-06-27 07:47:41 - progress_bar.py[line:272] - INFO: epoch 004:   1704 / 2637 loss=2.271, loss_v1=0, loss_v2=0, nll_loss=1.062, ntokens=1277.1, nsentences=160, sample_size=1277.1, sample_size_v1=0, sample_size_v2=0, ppl=2.09, wps=611.3, ups=0.48, wpb=1277.1, bsz=160, num_updates=9600, lr=2.46529e-05, gnorm=4.922, clip=100, loss_scale=128, train_wall=21, gb_free=8.9, wall=20062
2023-06-27 07:47:50 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2023-06-27 07:48:04 - progress_bar.py[line:272] - INFO: epoch 004:   1715 / 2637 loss=2.288, loss_v1=0, loss_v2=0, nll_loss=1.08, ntokens=1280, nsentences=160, sample_size=1280, sample_size_v1=0, sample_size_v2=0, ppl=2.11, wps=557.5, ups=0.44, wpb=1280, bsz=160, num_updates=9610, lr=2.46454e-05, gnorm=4.582, clip=100, loss_scale=64, train_wall=23, gb_free=8.9, wall=20085
2023-06-27 07:48:25 - progress_bar.py[line:272] - INFO: epoch 004:   1725 / 2637 loss=2.292, loss_v1=0, loss_v2=0, nll_loss=1.086, ntokens=1277.4, nsentences=160, sample_size=1277.4, sample_size_v1=0, sample_size_v2=0, ppl=2.12, wps=611.2, ups=0.48, wpb=1277.4, bsz=160, num_updates=9620, lr=2.46378e-05, gnorm=5.142, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=20106
2023-06-27 07:48:46 - progress_bar.py[line:272] - INFO: epoch 004:   1735 / 2637 loss=2.279, loss_v1=0, loss_v2=0, nll_loss=1.071, ntokens=1255.9, nsentences=160, sample_size=1255.9, sample_size_v1=0, sample_size_v2=0, ppl=2.1, wps=601.3, ups=0.48, wpb=1255.9, bsz=160, num_updates=9630, lr=2.46302e-05, gnorm=4.987, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=20127
2023-06-27 07:49:07 - progress_bar.py[line:272] - INFO: epoch 004:   1745 / 2637 loss=2.276, loss_v1=0, loss_v2=0, nll_loss=1.066, ntokens=1276.8, nsentences=160, sample_size=1276.8, sample_size_v1=0, sample_size_v2=0, ppl=2.09, wps=612.2, ups=0.48, wpb=1276.8, bsz=160, num_updates=9640, lr=2.46227e-05, gnorm=5.091, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=20147
2023-06-27 07:49:28 - progress_bar.py[line:272] - INFO: epoch 004:   1755 / 2637 loss=2.282, loss_v1=0, loss_v2=0, nll_loss=1.072, ntokens=1269.7, nsentences=160, sample_size=1269.7, sample_size_v1=0, sample_size_v2=0, ppl=2.1, wps=608.5, ups=0.48, wpb=1269.7, bsz=160, num_updates=9650, lr=2.46151e-05, gnorm=4.921, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=20168
2023-06-27 07:49:49 - progress_bar.py[line:272] - INFO: epoch 004:   1765 / 2637 loss=2.29, loss_v1=0, loss_v2=0, nll_loss=1.081, ntokens=1281.2, nsentences=160, sample_size=1281.2, sample_size_v1=0, sample_size_v2=0, ppl=2.12, wps=613.9, ups=0.48, wpb=1281.2, bsz=160, num_updates=9660, lr=2.46075e-05, gnorm=4.575, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=20189
2023-06-27 07:50:10 - progress_bar.py[line:272] - INFO: epoch 004:   1775 / 2637 loss=2.289, loss_v1=0, loss_v2=0, nll_loss=1.083, ntokens=1263.6, nsentences=160, sample_size=1263.6, sample_size_v1=0, sample_size_v2=0, ppl=2.12, wps=605.4, ups=0.48, wpb=1263.6, bsz=160, num_updates=9670, lr=2.46e-05, gnorm=4.864, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=20210
2023-06-27 07:50:31 - progress_bar.py[line:272] - INFO: epoch 004:   1785 / 2637 loss=2.281, loss_v1=0, loss_v2=0, nll_loss=1.072, ntokens=1300.1, nsentences=160, sample_size=1300.1, sample_size_v1=0, sample_size_v2=0, ppl=2.1, wps=622.4, ups=0.48, wpb=1300.1, bsz=160, num_updates=9680, lr=2.45924e-05, gnorm=4.986, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=20231
2023-06-27 07:50:52 - progress_bar.py[line:272] - INFO: epoch 004:   1795 / 2637 loss=2.305, loss_v1=0, loss_v2=0, nll_loss=1.099, ntokens=1266.7, nsentences=160, sample_size=1266.7, sample_size_v1=0, sample_size_v2=0, ppl=2.14, wps=606.3, ups=0.48, wpb=1266.7, bsz=160, num_updates=9690, lr=2.45849e-05, gnorm=4.771, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=20252
2023-06-27 07:51:12 - progress_bar.py[line:272] - INFO: epoch 004:   1805 / 2637 loss=2.284, loss_v1=0, loss_v2=0, nll_loss=1.076, ntokens=1279.1, nsentences=160, sample_size=1279.1, sample_size_v1=0, sample_size_v2=0, ppl=2.11, wps=612.9, ups=0.48, wpb=1279.1, bsz=160, num_updates=9700, lr=2.45773e-05, gnorm=4.787, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=20273
2023-06-27 07:51:33 - progress_bar.py[line:272] - INFO: epoch 004:   1815 / 2637 loss=2.266, loss_v1=0, loss_v2=0, nll_loss=1.057, ntokens=1267, nsentences=160, sample_size=1267, sample_size_v1=0, sample_size_v2=0, ppl=2.08, wps=606.9, ups=0.48, wpb=1267, bsz=160, num_updates=9710, lr=2.45697e-05, gnorm=4.84, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=20294
2023-06-27 07:51:54 - progress_bar.py[line:272] - INFO: epoch 004:   1825 / 2637 loss=2.282, loss_v1=0, loss_v2=0, nll_loss=1.074, ntokens=1253.2, nsentences=160, sample_size=1253.2, sample_size_v1=0, sample_size_v2=0, ppl=2.1, wps=600.9, ups=0.48, wpb=1253.2, bsz=160, num_updates=9720, lr=2.45622e-05, gnorm=5.104, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=20314
2023-06-27 07:52:15 - progress_bar.py[line:272] - INFO: epoch 004:   1835 / 2637 loss=2.251, loss_v1=0, loss_v2=0, nll_loss=1.039, ntokens=1307.2, nsentences=160, sample_size=1307.2, sample_size_v1=0, sample_size_v2=0, ppl=2.05, wps=626.4, ups=0.48, wpb=1307.2, bsz=160, num_updates=9730, lr=2.45546e-05, gnorm=4.348, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=20335
2023-06-27 07:52:36 - progress_bar.py[line:272] - INFO: epoch 004:   1845 / 2637 loss=2.276, loss_v1=0, loss_v2=0, nll_loss=1.067, ntokens=1291.2, nsentences=160, sample_size=1291.2, sample_size_v1=0, sample_size_v2=0, ppl=2.1, wps=618.9, ups=0.48, wpb=1291.2, bsz=160, num_updates=9740, lr=2.4547e-05, gnorm=5.645, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=20356
2023-06-27 07:52:57 - progress_bar.py[line:272] - INFO: epoch 004:   1855 / 2637 loss=2.282, loss_v1=0, loss_v2=0, nll_loss=1.075, ntokens=1260.5, nsentences=160, sample_size=1260.5, sample_size_v1=0, sample_size_v2=0, ppl=2.11, wps=603.2, ups=0.48, wpb=1260.5, bsz=160, num_updates=9750, lr=2.45395e-05, gnorm=4.754, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=20377
2023-06-27 07:53:18 - progress_bar.py[line:272] - INFO: epoch 004:   1865 / 2637 loss=2.261, loss_v1=0, loss_v2=0, nll_loss=1.049, ntokens=1276.8, nsentences=160, sample_size=1276.8, sample_size_v1=0, sample_size_v2=0, ppl=2.07, wps=611.9, ups=0.48, wpb=1276.8, bsz=160, num_updates=9760, lr=2.45319e-05, gnorm=4.799, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=20398
2023-06-27 07:53:38 - progress_bar.py[line:272] - INFO: epoch 004:   1875 / 2637 loss=2.285, loss_v1=0, loss_v2=0, nll_loss=1.077, ntokens=1265.3, nsentences=160, sample_size=1265.3, sample_size_v1=0, sample_size_v2=0, ppl=2.11, wps=606.7, ups=0.48, wpb=1265.3, bsz=160, num_updates=9770, lr=2.45243e-05, gnorm=5.123, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=20419
2023-06-27 07:53:59 - progress_bar.py[line:272] - INFO: epoch 004:   1885 / 2637 loss=2.255, loss_v1=0, loss_v2=0, nll_loss=1.042, ntokens=1283, nsentences=160, sample_size=1283, sample_size_v1=0, sample_size_v2=0, ppl=2.06, wps=614.6, ups=0.48, wpb=1283, bsz=160, num_updates=9780, lr=2.45168e-05, gnorm=3.986, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=20440
2023-06-27 07:54:20 - progress_bar.py[line:272] - INFO: epoch 004:   1895 / 2637 loss=2.249, loss_v1=0, loss_v2=0, nll_loss=1.037, ntokens=1286.8, nsentences=160, sample_size=1286.8, sample_size_v1=0, sample_size_v2=0, ppl=2.05, wps=615.8, ups=0.48, wpb=1286.8, bsz=160, num_updates=9790, lr=2.45092e-05, gnorm=5.175, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=20461
2023-06-27 07:54:41 - progress_bar.py[line:272] - INFO: epoch 004:   1905 / 2637 loss=2.287, loss_v1=0, loss_v2=0, nll_loss=1.079, ntokens=1274.8, nsentences=160, sample_size=1274.8, sample_size_v1=0, sample_size_v2=0, ppl=2.11, wps=610.8, ups=0.48, wpb=1274.8, bsz=160, num_updates=9800, lr=2.45017e-05, gnorm=4.934, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=20481
2023-06-27 07:55:02 - progress_bar.py[line:272] - INFO: epoch 004:   1915 / 2637 loss=2.247, loss_v1=0, loss_v2=0, nll_loss=1.036, ntokens=1262.6, nsentences=160, sample_size=1262.6, sample_size_v1=0, sample_size_v2=0, ppl=2.05, wps=605.5, ups=0.48, wpb=1262.6, bsz=160, num_updates=9810, lr=2.44941e-05, gnorm=4.829, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=20502
2023-06-27 07:55:23 - progress_bar.py[line:272] - INFO: epoch 004:   1925 / 2637 loss=2.299, loss_v1=0, loss_v2=0, nll_loss=1.092, ntokens=1277.2, nsentences=160, sample_size=1277.2, sample_size_v1=0, sample_size_v2=0, ppl=2.13, wps=612.3, ups=0.48, wpb=1277.2, bsz=160, num_updates=9820, lr=2.44865e-05, gnorm=4.89, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=20523
2023-06-27 07:55:44 - progress_bar.py[line:272] - INFO: epoch 004:   1935 / 2637 loss=2.271, loss_v1=0, loss_v2=0, nll_loss=1.06, ntokens=1258.9, nsentences=160, sample_size=1258.9, sample_size_v1=0, sample_size_v2=0, ppl=2.08, wps=603.5, ups=0.48, wpb=1258.9, bsz=160, num_updates=9830, lr=2.4479e-05, gnorm=5.662, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=20544
2023-06-27 07:56:05 - progress_bar.py[line:272] - INFO: epoch 004:   1945 / 2637 loss=2.273, loss_v1=0, loss_v2=0, nll_loss=1.064, ntokens=1296.6, nsentences=160, sample_size=1296.6, sample_size_v1=0, sample_size_v2=0, ppl=2.09, wps=621.5, ups=0.48, wpb=1296.6, bsz=160, num_updates=9840, lr=2.44714e-05, gnorm=5.232, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=20565
2023-06-27 07:56:25 - progress_bar.py[line:272] - INFO: epoch 004:   1955 / 2637 loss=2.281, loss_v1=0, loss_v2=0, nll_loss=1.074, ntokens=1281.5, nsentences=160, sample_size=1281.5, sample_size_v1=0, sample_size_v2=0, ppl=2.1, wps=614.1, ups=0.48, wpb=1281.5, bsz=160, num_updates=9850, lr=2.44638e-05, gnorm=5.567, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=20586
2023-06-27 07:56:46 - progress_bar.py[line:272] - INFO: epoch 004:   1965 / 2637 loss=2.274, loss_v1=0, loss_v2=0, nll_loss=1.062, ntokens=1261.3, nsentences=160, sample_size=1261.3, sample_size_v1=0, sample_size_v2=0, ppl=2.09, wps=604.5, ups=0.48, wpb=1261.3, bsz=160, num_updates=9860, lr=2.44563e-05, gnorm=4.82, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=20607
2023-06-27 07:57:07 - progress_bar.py[line:272] - INFO: epoch 004:   1975 / 2637 loss=2.32, loss_v1=0, loss_v2=0, nll_loss=1.115, ntokens=1266.3, nsentences=160, sample_size=1266.3, sample_size_v1=0, sample_size_v2=0, ppl=2.17, wps=606.3, ups=0.48, wpb=1266.3, bsz=160, num_updates=9870, lr=2.44487e-05, gnorm=5.145, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=20627
2023-06-27 07:57:28 - progress_bar.py[line:272] - INFO: epoch 004:   1985 / 2637 loss=2.265, loss_v1=0, loss_v2=0, nll_loss=1.055, ntokens=1299.3, nsentences=160, sample_size=1299.3, sample_size_v1=0, sample_size_v2=0, ppl=2.08, wps=622.9, ups=0.48, wpb=1299.3, bsz=160, num_updates=9880, lr=2.44411e-05, gnorm=4.556, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=20648
2023-06-27 07:57:49 - progress_bar.py[line:272] - INFO: epoch 004:   1995 / 2637 loss=2.273, loss_v1=0, loss_v2=0, nll_loss=1.065, ntokens=1281.8, nsentences=160, sample_size=1281.8, sample_size_v1=0, sample_size_v2=0, ppl=2.09, wps=615, ups=0.48, wpb=1281.8, bsz=160, num_updates=9890, lr=2.44336e-05, gnorm=4.741, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=20669
2023-06-27 07:58:10 - progress_bar.py[line:272] - INFO: epoch 004:   2005 / 2637 loss=2.272, loss_v1=0, loss_v2=0, nll_loss=1.061, ntokens=1260.9, nsentences=160, sample_size=1260.9, sample_size_v1=0, sample_size_v2=0, ppl=2.09, wps=603.8, ups=0.48, wpb=1260.9, bsz=160, num_updates=9900, lr=2.4426e-05, gnorm=4.802, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=20690
2023-06-27 07:58:31 - progress_bar.py[line:272] - INFO: epoch 004:   2015 / 2637 loss=2.285, loss_v1=0, loss_v2=0, nll_loss=1.077, ntokens=1287.5, nsentences=160, sample_size=1287.5, sample_size_v1=0, sample_size_v2=0, ppl=2.11, wps=617.1, ups=0.48, wpb=1287.5, bsz=160, num_updates=9910, lr=2.44184e-05, gnorm=4.654, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=20711
2023-06-27 07:58:52 - progress_bar.py[line:272] - INFO: epoch 004:   2025 / 2637 loss=2.241, loss_v1=0, loss_v2=0, nll_loss=1.03, ntokens=1287.6, nsentences=160, sample_size=1287.6, sample_size_v1=0, sample_size_v2=0, ppl=2.04, wps=617.5, ups=0.48, wpb=1287.6, bsz=160, num_updates=9920, lr=2.44109e-05, gnorm=5.214, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=20732
2023-06-27 07:59:12 - progress_bar.py[line:272] - INFO: epoch 004:   2035 / 2637 loss=2.27, loss_v1=0, loss_v2=0, nll_loss=1.06, ntokens=1267, nsentences=160, sample_size=1267, sample_size_v1=0, sample_size_v2=0, ppl=2.08, wps=607.2, ups=0.48, wpb=1267, bsz=160, num_updates=9930, lr=2.44033e-05, gnorm=4.9, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=20753
2023-06-27 07:59:33 - progress_bar.py[line:272] - INFO: epoch 004:   2045 / 2637 loss=2.224, loss_v1=0, loss_v2=0, nll_loss=1.008, ntokens=1279, nsentences=160, sample_size=1279, sample_size_v1=0, sample_size_v2=0, ppl=2.01, wps=613.9, ups=0.48, wpb=1279, bsz=160, num_updates=9940, lr=2.43958e-05, gnorm=4.367, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=20774
2023-06-27 07:59:54 - progress_bar.py[line:272] - INFO: epoch 004:   2055 / 2637 loss=2.266, loss_v1=0, loss_v2=0, nll_loss=1.056, ntokens=1281.5, nsentences=160, sample_size=1281.5, sample_size_v1=0, sample_size_v2=0, ppl=2.08, wps=615.3, ups=0.48, wpb=1281.5, bsz=160, num_updates=9950, lr=2.43882e-05, gnorm=4.722, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=20794
2023-06-27 08:00:15 - progress_bar.py[line:272] - INFO: epoch 004:   2065 / 2637 loss=2.276, loss_v1=0, loss_v2=0, nll_loss=1.07, ntokens=1245.9, nsentences=160, sample_size=1245.9, sample_size_v1=0, sample_size_v2=0, ppl=2.1, wps=597.6, ups=0.48, wpb=1245.9, bsz=160, num_updates=9960, lr=2.43806e-05, gnorm=6.27, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=20815
2023-06-27 08:00:36 - progress_bar.py[line:272] - INFO: epoch 004:   2075 / 2637 loss=2.274, loss_v1=0, loss_v2=0, nll_loss=1.063, ntokens=1261.5, nsentences=160, sample_size=1261.5, sample_size_v1=0, sample_size_v2=0, ppl=2.09, wps=605.6, ups=0.48, wpb=1261.5, bsz=160, num_updates=9970, lr=2.43731e-05, gnorm=5.815, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=20836
2023-06-27 08:00:57 - progress_bar.py[line:272] - INFO: epoch 004:   2085 / 2637 loss=2.285, loss_v1=0, loss_v2=0, nll_loss=1.078, ntokens=1251.3, nsentences=160, sample_size=1251.3, sample_size_v1=0, sample_size_v2=0, ppl=2.11, wps=600.4, ups=0.48, wpb=1251.3, bsz=160, num_updates=9980, lr=2.43655e-05, gnorm=4.543, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=20857
2023-06-27 08:01:17 - progress_bar.py[line:272] - INFO: epoch 004:   2095 / 2637 loss=2.264, loss_v1=0, loss_v2=0, nll_loss=1.054, ntokens=1271.9, nsentences=160, sample_size=1271.9, sample_size_v1=0, sample_size_v2=0, ppl=2.08, wps=611, ups=0.48, wpb=1271.9, bsz=160, num_updates=9990, lr=2.43579e-05, gnorm=5.627, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=20878
2023-06-27 08:01:38 - progress_bar.py[line:272] - INFO: epoch 004:   2105 / 2637 loss=2.268, loss_v1=0, loss_v2=0, nll_loss=1.06, ntokens=1247.6, nsentences=160, sample_size=1247.6, sample_size_v1=0, sample_size_v2=0, ppl=2.09, wps=598.9, ups=0.48, wpb=1247.6, bsz=160, num_updates=10000, lr=2.43504e-05, gnorm=4.825, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=20899
2023-06-27 08:01:59 - progress_bar.py[line:272] - INFO: epoch 004:   2115 / 2637 loss=2.274, loss_v1=0, loss_v2=0, nll_loss=1.065, ntokens=1271.5, nsentences=160, sample_size=1271.5, sample_size_v1=0, sample_size_v2=0, ppl=2.09, wps=609.7, ups=0.48, wpb=1271.5, bsz=160, num_updates=10010, lr=2.43428e-05, gnorm=4.333, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=20919
2023-06-27 08:02:20 - progress_bar.py[line:272] - INFO: epoch 004:   2125 / 2637 loss=2.282, loss_v1=0, loss_v2=0, nll_loss=1.073, ntokens=1249.4, nsentences=160, sample_size=1249.4, sample_size_v1=0, sample_size_v2=0, ppl=2.1, wps=598.5, ups=0.48, wpb=1249.4, bsz=160, num_updates=10020, lr=2.43352e-05, gnorm=4.787, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=20940
2023-06-27 08:02:41 - progress_bar.py[line:272] - INFO: epoch 004:   2135 / 2637 loss=2.27, loss_v1=0, loss_v2=0, nll_loss=1.06, ntokens=1257.4, nsentences=160, sample_size=1257.4, sample_size_v1=0, sample_size_v2=0, ppl=2.08, wps=601.8, ups=0.48, wpb=1257.4, bsz=160, num_updates=10030, lr=2.43277e-05, gnorm=4.563, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=20961
2023-06-27 08:03:02 - progress_bar.py[line:272] - INFO: epoch 004:   2145 / 2637 loss=2.258, loss_v1=0, loss_v2=0, nll_loss=1.047, ntokens=1265.2, nsentences=160, sample_size=1265.2, sample_size_v1=0, sample_size_v2=0, ppl=2.07, wps=605.5, ups=0.48, wpb=1265.2, bsz=160, num_updates=10040, lr=2.43201e-05, gnorm=4.437, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=20982
2023-06-27 08:03:23 - progress_bar.py[line:272] - INFO: epoch 004:   2155 / 2637 loss=2.272, loss_v1=0, loss_v2=0, nll_loss=1.062, ntokens=1259.2, nsentences=160, sample_size=1259.2, sample_size_v1=0, sample_size_v2=0, ppl=2.09, wps=603, ups=0.48, wpb=1259.2, bsz=160, num_updates=10050, lr=2.43125e-05, gnorm=5.129, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=21003
2023-06-27 08:03:44 - progress_bar.py[line:272] - INFO: epoch 004:   2165 / 2637 loss=2.266, loss_v1=0, loss_v2=0, nll_loss=1.058, ntokens=1270.9, nsentences=160, sample_size=1270.9, sample_size_v1=0, sample_size_v2=0, ppl=2.08, wps=608.5, ups=0.48, wpb=1270.9, bsz=160, num_updates=10060, lr=2.4305e-05, gnorm=4.266, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=21024
2023-06-27 08:04:04 - progress_bar.py[line:272] - INFO: epoch 004:   2175 / 2637 loss=2.255, loss_v1=0, loss_v2=0, nll_loss=1.043, ntokens=1264.4, nsentences=160, sample_size=1264.4, sample_size_v1=0, sample_size_v2=0, ppl=2.06, wps=605.2, ups=0.48, wpb=1264.4, bsz=160, num_updates=10070, lr=2.42974e-05, gnorm=4.765, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=21045
2023-06-27 08:04:25 - progress_bar.py[line:272] - INFO: epoch 004:   2185 / 2637 loss=2.263, loss_v1=0, loss_v2=0, nll_loss=1.051, ntokens=1263.5, nsentences=160, sample_size=1263.5, sample_size_v1=0, sample_size_v2=0, ppl=2.07, wps=604.8, ups=0.48, wpb=1263.5, bsz=160, num_updates=10080, lr=2.42899e-05, gnorm=4.845, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=21066
2023-06-27 08:04:46 - progress_bar.py[line:272] - INFO: epoch 004:   2195 / 2637 loss=2.247, loss_v1=0, loss_v2=0, nll_loss=1.036, ntokens=1260.6, nsentences=160, sample_size=1260.6, sample_size_v1=0, sample_size_v2=0, ppl=2.05, wps=604, ups=0.48, wpb=1260.6, bsz=160, num_updates=10090, lr=2.42823e-05, gnorm=4.774, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=21087
2023-06-27 08:05:07 - progress_bar.py[line:272] - INFO: epoch 004:   2205 / 2637 loss=2.241, loss_v1=0, loss_v2=0, nll_loss=1.027, ntokens=1290.5, nsentences=160, sample_size=1290.5, sample_size_v1=0, sample_size_v2=0, ppl=2.04, wps=617.8, ups=0.48, wpb=1290.5, bsz=160, num_updates=10100, lr=2.42747e-05, gnorm=4.551, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=21107
2023-06-27 08:05:28 - progress_bar.py[line:272] - INFO: epoch 004:   2215 / 2637 loss=2.24, loss_v1=0, loss_v2=0, nll_loss=1.026, ntokens=1259, nsentences=160, sample_size=1259, sample_size_v1=0, sample_size_v2=0, ppl=2.04, wps=603.5, ups=0.48, wpb=1259, bsz=160, num_updates=10110, lr=2.42672e-05, gnorm=5.259, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=21128
2023-06-27 08:05:49 - progress_bar.py[line:272] - INFO: epoch 004:   2225 / 2637 loss=2.254, loss_v1=0, loss_v2=0, nll_loss=1.042, ntokens=1251.6, nsentences=160, sample_size=1251.6, sample_size_v1=0, sample_size_v2=0, ppl=2.06, wps=600.4, ups=0.48, wpb=1251.6, bsz=160, num_updates=10120, lr=2.42596e-05, gnorm=4.983, clip=100, loss_scale=128, train_wall=21, gb_free=8.9, wall=21149
2023-06-27 08:05:59 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2023-06-27 08:06:12 - progress_bar.py[line:272] - INFO: epoch 004:   2236 / 2637 loss=2.281, loss_v1=0, loss_v2=0, nll_loss=1.074, ntokens=1284.7, nsentences=160, sample_size=1284.7, sample_size_v1=0, sample_size_v2=0, ppl=2.1, wps=560.4, ups=0.44, wpb=1284.7, bsz=160, num_updates=10130, lr=2.4252e-05, gnorm=4.533, clip=100, loss_scale=64, train_wall=23, gb_free=8.9, wall=21172
2023-06-27 08:06:33 - progress_bar.py[line:272] - INFO: epoch 004:   2246 / 2637 loss=2.233, loss_v1=0, loss_v2=0, nll_loss=1.02, ntokens=1247.1, nsentences=160, sample_size=1247.1, sample_size_v1=0, sample_size_v2=0, ppl=2.03, wps=598.1, ups=0.48, wpb=1247.1, bsz=160, num_updates=10140, lr=2.42445e-05, gnorm=4.604, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=21193
2023-06-27 08:06:54 - progress_bar.py[line:272] - INFO: epoch 004:   2256 / 2637 loss=2.274, loss_v1=0, loss_v2=0, nll_loss=1.062, ntokens=1262.5, nsentences=160, sample_size=1262.5, sample_size_v1=0, sample_size_v2=0, ppl=2.09, wps=604.2, ups=0.48, wpb=1262.5, bsz=160, num_updates=10150, lr=2.42369e-05, gnorm=4.3, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=21214
2023-06-27 08:07:14 - progress_bar.py[line:272] - INFO: epoch 004:   2266 / 2637 loss=2.237, loss_v1=0, loss_v2=0, nll_loss=1.025, ntokens=1266, nsentences=160, sample_size=1266, sample_size_v1=0, sample_size_v2=0, ppl=2.03, wps=605.9, ups=0.48, wpb=1266, bsz=160, num_updates=10160, lr=2.42293e-05, gnorm=4.921, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=21235
2023-06-27 08:07:35 - progress_bar.py[line:272] - INFO: epoch 004:   2276 / 2637 loss=2.263, loss_v1=0, loss_v2=0, nll_loss=1.053, ntokens=1272.9, nsentences=160, sample_size=1272.9, sample_size_v1=0, sample_size_v2=0, ppl=2.07, wps=609.9, ups=0.48, wpb=1272.9, bsz=160, num_updates=10170, lr=2.42218e-05, gnorm=4.299, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=21256
2023-06-27 08:07:56 - progress_bar.py[line:272] - INFO: epoch 004:   2286 / 2637 loss=2.255, loss_v1=0, loss_v2=0, nll_loss=1.046, ntokens=1260.2, nsentences=160, sample_size=1260.2, sample_size_v1=0, sample_size_v2=0, ppl=2.06, wps=603.7, ups=0.48, wpb=1260.2, bsz=160, num_updates=10180, lr=2.42142e-05, gnorm=4.911, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=21276
2023-06-27 08:08:17 - progress_bar.py[line:272] - INFO: epoch 004:   2296 / 2637 loss=2.256, loss_v1=0, loss_v2=0, nll_loss=1.044, ntokens=1286.9, nsentences=160, sample_size=1286.9, sample_size_v1=0, sample_size_v2=0, ppl=2.06, wps=615.9, ups=0.48, wpb=1286.9, bsz=160, num_updates=10190, lr=2.42067e-05, gnorm=4.457, clip=100, loss_scale=64, train_wall=21, gb_free=8.7, wall=21297
2023-06-27 08:08:38 - progress_bar.py[line:272] - INFO: epoch 004:   2306 / 2637 loss=2.279, loss_v1=0, loss_v2=0, nll_loss=1.071, ntokens=1263.3, nsentences=160, sample_size=1263.3, sample_size_v1=0, sample_size_v2=0, ppl=2.1, wps=598.9, ups=0.47, wpb=1263.3, bsz=160, num_updates=10200, lr=2.41991e-05, gnorm=5.041, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=21318
2023-06-27 08:08:59 - progress_bar.py[line:272] - INFO: epoch 004:   2316 / 2637 loss=2.243, loss_v1=0, loss_v2=0, nll_loss=1.029, ntokens=1251.6, nsentences=160, sample_size=1251.6, sample_size_v1=0, sample_size_v2=0, ppl=2.04, wps=599.7, ups=0.48, wpb=1251.6, bsz=160, num_updates=10210, lr=2.41915e-05, gnorm=4.649, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=21339
2023-06-27 08:09:20 - progress_bar.py[line:272] - INFO: epoch 004:   2326 / 2637 loss=2.258, loss_v1=0, loss_v2=0, nll_loss=1.048, ntokens=1272.8, nsentences=160, sample_size=1272.8, sample_size_v1=0, sample_size_v2=0, ppl=2.07, wps=609.9, ups=0.48, wpb=1272.8, bsz=160, num_updates=10220, lr=2.4184e-05, gnorm=4.46, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=21360
2023-06-27 08:09:41 - progress_bar.py[line:272] - INFO: epoch 004:   2336 / 2637 loss=2.27, loss_v1=0, loss_v2=0, nll_loss=1.06, ntokens=1234, nsentences=160, sample_size=1234, sample_size_v1=0, sample_size_v2=0, ppl=2.09, wps=591, ups=0.48, wpb=1234, bsz=160, num_updates=10230, lr=2.41764e-05, gnorm=5.951, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=21381
2023-06-27 08:10:02 - progress_bar.py[line:272] - INFO: epoch 004:   2346 / 2637 loss=2.26, loss_v1=0, loss_v2=0, nll_loss=1.048, ntokens=1265.2, nsentences=160, sample_size=1265.2, sample_size_v1=0, sample_size_v2=0, ppl=2.07, wps=606.8, ups=0.48, wpb=1265.2, bsz=160, num_updates=10240, lr=2.41688e-05, gnorm=4.632, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=21402
2023-06-27 08:10:23 - progress_bar.py[line:272] - INFO: epoch 004:   2356 / 2637 loss=2.249, loss_v1=0, loss_v2=0, nll_loss=1.035, ntokens=1278.5, nsentences=160, sample_size=1278.5, sample_size_v1=0, sample_size_v2=0, ppl=2.05, wps=612.5, ups=0.48, wpb=1278.5, bsz=160, num_updates=10250, lr=2.41613e-05, gnorm=4.981, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=21423
2023-06-27 08:10:43 - progress_bar.py[line:272] - INFO: epoch 004:   2366 / 2637 loss=2.25, loss_v1=0, loss_v2=0, nll_loss=1.038, ntokens=1269.8, nsentences=160, sample_size=1269.8, sample_size_v1=0, sample_size_v2=0, ppl=2.05, wps=609.6, ups=0.48, wpb=1269.8, bsz=160, num_updates=10260, lr=2.41537e-05, gnorm=4.891, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=21444
2023-06-27 08:11:04 - progress_bar.py[line:272] - INFO: epoch 004:   2376 / 2637 loss=2.254, loss_v1=0, loss_v2=0, nll_loss=1.042, ntokens=1274.9, nsentences=160, sample_size=1274.9, sample_size_v1=0, sample_size_v2=0, ppl=2.06, wps=611.4, ups=0.48, wpb=1274.9, bsz=160, num_updates=10270, lr=2.41461e-05, gnorm=4.852, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=21464
2023-06-27 08:11:25 - progress_bar.py[line:272] - INFO: epoch 004:   2386 / 2637 loss=2.26, loss_v1=0, loss_v2=0, nll_loss=1.05, ntokens=1283.4, nsentences=160, sample_size=1283.4, sample_size_v1=0, sample_size_v2=0, ppl=2.07, wps=613.9, ups=0.48, wpb=1283.4, bsz=160, num_updates=10280, lr=2.41386e-05, gnorm=4.772, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=21485
2023-06-27 08:11:46 - progress_bar.py[line:272] - INFO: epoch 004:   2396 / 2637 loss=2.262, loss_v1=0, loss_v2=0, nll_loss=1.052, ntokens=1286.9, nsentences=160, sample_size=1286.9, sample_size_v1=0, sample_size_v2=0, ppl=2.07, wps=616.2, ups=0.48, wpb=1286.9, bsz=160, num_updates=10290, lr=2.4131e-05, gnorm=4.921, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=21506
2023-06-27 08:12:07 - progress_bar.py[line:272] - INFO: epoch 004:   2406 / 2637 loss=2.279, loss_v1=0, loss_v2=0, nll_loss=1.07, ntokens=1273.4, nsentences=160, sample_size=1273.4, sample_size_v1=0, sample_size_v2=0, ppl=2.1, wps=609.9, ups=0.48, wpb=1273.4, bsz=160, num_updates=10300, lr=2.41234e-05, gnorm=5.712, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=21527
2023-06-27 08:12:28 - progress_bar.py[line:272] - INFO: epoch 004:   2416 / 2637 loss=2.265, loss_v1=0, loss_v2=0, nll_loss=1.054, ntokens=1279.9, nsentences=160, sample_size=1279.9, sample_size_v1=0, sample_size_v2=0, ppl=2.08, wps=612.7, ups=0.48, wpb=1279.9, bsz=160, num_updates=10310, lr=2.41159e-05, gnorm=4.756, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=21548
2023-06-27 08:12:49 - progress_bar.py[line:272] - INFO: epoch 004:   2426 / 2637 loss=2.251, loss_v1=0, loss_v2=0, nll_loss=1.039, ntokens=1261.5, nsentences=160, sample_size=1261.5, sample_size_v1=0, sample_size_v2=0, ppl=2.06, wps=603.9, ups=0.48, wpb=1261.5, bsz=160, num_updates=10320, lr=2.41083e-05, gnorm=5.332, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=21569
2023-06-27 08:13:10 - progress_bar.py[line:272] - INFO: epoch 004:   2436 / 2637 loss=2.26, loss_v1=0, loss_v2=0, nll_loss=1.049, ntokens=1289.3, nsentences=160, sample_size=1289.3, sample_size_v1=0, sample_size_v2=0, ppl=2.07, wps=617.5, ups=0.48, wpb=1289.3, bsz=160, num_updates=10330, lr=2.41008e-05, gnorm=5.118, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=21590
2023-06-27 08:13:30 - progress_bar.py[line:272] - INFO: epoch 004:   2446 / 2637 loss=2.279, loss_v1=0, loss_v2=0, nll_loss=1.07, ntokens=1265.3, nsentences=160, sample_size=1265.3, sample_size_v1=0, sample_size_v2=0, ppl=2.1, wps=606.3, ups=0.48, wpb=1265.3, bsz=160, num_updates=10340, lr=2.40932e-05, gnorm=5.374, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=21611
2023-06-27 08:13:51 - progress_bar.py[line:272] - INFO: epoch 004:   2456 / 2637 loss=2.242, loss_v1=0, loss_v2=0, nll_loss=1.029, ntokens=1281.8, nsentences=160, sample_size=1281.8, sample_size_v1=0, sample_size_v2=0, ppl=2.04, wps=614.2, ups=0.48, wpb=1281.8, bsz=160, num_updates=10350, lr=2.40856e-05, gnorm=4.703, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=21632
2023-06-27 08:14:12 - progress_bar.py[line:272] - INFO: epoch 004:   2466 / 2637 loss=2.232, loss_v1=0, loss_v2=0, nll_loss=1.019, ntokens=1272.9, nsentences=160, sample_size=1272.9, sample_size_v1=0, sample_size_v2=0, ppl=2.03, wps=608.9, ups=0.48, wpb=1272.9, bsz=160, num_updates=10360, lr=2.40781e-05, gnorm=4.913, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=21652
2023-06-27 08:14:33 - progress_bar.py[line:272] - INFO: epoch 004:   2476 / 2637 loss=2.241, loss_v1=0, loss_v2=0, nll_loss=1.027, ntokens=1303.9, nsentences=160, sample_size=1303.9, sample_size_v1=0, sample_size_v2=0, ppl=2.04, wps=624.8, ups=0.48, wpb=1303.9, bsz=160, num_updates=10370, lr=2.40705e-05, gnorm=4.726, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=21673
2023-06-27 08:14:54 - progress_bar.py[line:272] - INFO: epoch 004:   2486 / 2637 loss=2.266, loss_v1=0, loss_v2=0, nll_loss=1.057, ntokens=1272.3, nsentences=160, sample_size=1272.3, sample_size_v1=0, sample_size_v2=0, ppl=2.08, wps=609.6, ups=0.48, wpb=1272.3, bsz=160, num_updates=10380, lr=2.40629e-05, gnorm=5.156, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=21694
2023-06-27 08:14:56 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2023-06-27 08:15:17 - progress_bar.py[line:272] - INFO: epoch 004:   2497 / 2637 loss=2.252, loss_v1=0, loss_v2=0, nll_loss=1.041, ntokens=1284.1, nsentences=160, sample_size=1284.1, sample_size_v1=0, sample_size_v2=0, ppl=2.06, wps=560.1, ups=0.44, wpb=1284.1, bsz=160, num_updates=10390, lr=2.40554e-05, gnorm=4.653, clip=100, loss_scale=32, train_wall=23, gb_free=8.9, wall=21717
2023-06-27 08:15:38 - progress_bar.py[line:272] - INFO: epoch 004:   2507 / 2637 loss=2.261, loss_v1=0, loss_v2=0, nll_loss=1.051, ntokens=1270.7, nsentences=160, sample_size=1270.7, sample_size_v1=0, sample_size_v2=0, ppl=2.07, wps=608.8, ups=0.48, wpb=1270.7, bsz=160, num_updates=10400, lr=2.40478e-05, gnorm=4.564, clip=100, loss_scale=32, train_wall=21, gb_free=8.9, wall=21738
2023-06-27 08:15:59 - progress_bar.py[line:272] - INFO: epoch 004:   2517 / 2637 loss=2.238, loss_v1=0, loss_v2=0, nll_loss=1.022, ntokens=1275.9, nsentences=160, sample_size=1275.9, sample_size_v1=0, sample_size_v2=0, ppl=2.03, wps=611.7, ups=0.48, wpb=1275.9, bsz=160, num_updates=10410, lr=2.40402e-05, gnorm=4.081, clip=100, loss_scale=32, train_wall=21, gb_free=8.9, wall=21759
2023-06-27 08:16:19 - progress_bar.py[line:272] - INFO: epoch 004:   2527 / 2637 loss=2.244, loss_v1=0, loss_v2=0, nll_loss=1.033, ntokens=1268.2, nsentences=160, sample_size=1268.2, sample_size_v1=0, sample_size_v2=0, ppl=2.05, wps=608.3, ups=0.48, wpb=1268.2, bsz=160, num_updates=10420, lr=2.40327e-05, gnorm=4.565, clip=100, loss_scale=32, train_wall=21, gb_free=8.9, wall=21780
2023-06-27 08:16:40 - progress_bar.py[line:272] - INFO: epoch 004:   2537 / 2637 loss=2.238, loss_v1=0, loss_v2=0, nll_loss=1.024, ntokens=1273.9, nsentences=160, sample_size=1273.9, sample_size_v1=0, sample_size_v2=0, ppl=2.03, wps=611.2, ups=0.48, wpb=1273.9, bsz=160, num_updates=10430, lr=2.40251e-05, gnorm=4.637, clip=100, loss_scale=32, train_wall=21, gb_free=8.9, wall=21801
2023-06-27 08:17:01 - progress_bar.py[line:272] - INFO: epoch 004:   2547 / 2637 loss=2.238, loss_v1=0, loss_v2=0, nll_loss=1.025, ntokens=1257.9, nsentences=160, sample_size=1257.9, sample_size_v1=0, sample_size_v2=0, ppl=2.03, wps=597.7, ups=0.48, wpb=1257.9, bsz=160, num_updates=10440, lr=2.40175e-05, gnorm=5.032, clip=100, loss_scale=32, train_wall=21, gb_free=8.9, wall=21822
2023-06-27 08:17:22 - progress_bar.py[line:272] - INFO: epoch 004:   2557 / 2637 loss=2.241, loss_v1=0, loss_v2=0, nll_loss=1.028, ntokens=1277.5, nsentences=160, sample_size=1277.5, sample_size_v1=0, sample_size_v2=0, ppl=2.04, wps=612.1, ups=0.48, wpb=1277.5, bsz=160, num_updates=10450, lr=2.401e-05, gnorm=4.664, clip=100, loss_scale=32, train_wall=21, gb_free=8.9, wall=21843
2023-06-27 08:17:43 - progress_bar.py[line:272] - INFO: epoch 004:   2567 / 2637 loss=2.253, loss_v1=0, loss_v2=0, nll_loss=1.044, ntokens=1260.1, nsentences=160, sample_size=1260.1, sample_size_v1=0, sample_size_v2=0, ppl=2.06, wps=604.1, ups=0.48, wpb=1260.1, bsz=160, num_updates=10460, lr=2.40024e-05, gnorm=4.509, clip=100, loss_scale=32, train_wall=21, gb_free=8.9, wall=21863
2023-06-27 08:18:04 - progress_bar.py[line:272] - INFO: epoch 004:   2577 / 2637 loss=2.232, loss_v1=0, loss_v2=0, nll_loss=1.017, ntokens=1252.2, nsentences=160, sample_size=1252.2, sample_size_v1=0, sample_size_v2=0, ppl=2.02, wps=599.9, ups=0.48, wpb=1252.2, bsz=160, num_updates=10470, lr=2.39949e-05, gnorm=4.732, clip=100, loss_scale=32, train_wall=21, gb_free=8.9, wall=21884
2023-06-27 08:18:25 - progress_bar.py[line:272] - INFO: epoch 004:   2587 / 2637 loss=2.263, loss_v1=0, loss_v2=0, nll_loss=1.053, ntokens=1281.4, nsentences=160, sample_size=1281.4, sample_size_v1=0, sample_size_v2=0, ppl=2.07, wps=614.4, ups=0.48, wpb=1281.4, bsz=160, num_updates=10480, lr=2.39873e-05, gnorm=4.694, clip=100, loss_scale=32, train_wall=21, gb_free=8.9, wall=21905
2023-06-27 08:18:46 - progress_bar.py[line:272] - INFO: epoch 004:   2597 / 2637 loss=2.232, loss_v1=0, loss_v2=0, nll_loss=1.019, ntokens=1277.6, nsentences=160, sample_size=1277.6, sample_size_v1=0, sample_size_v2=0, ppl=2.03, wps=612.3, ups=0.48, wpb=1277.6, bsz=160, num_updates=10490, lr=2.39797e-05, gnorm=4.108, clip=100, loss_scale=32, train_wall=21, gb_free=8.9, wall=21926
2023-06-27 08:19:07 - progress_bar.py[line:272] - INFO: epoch 004:   2607 / 2637 loss=2.235, loss_v1=0, loss_v2=0, nll_loss=1.021, ntokens=1283.1, nsentences=160, sample_size=1283.1, sample_size_v1=0, sample_size_v2=0, ppl=2.03, wps=615.3, ups=0.48, wpb=1283.1, bsz=160, num_updates=10500, lr=2.39722e-05, gnorm=4.382, clip=100, loss_scale=32, train_wall=21, gb_free=8.9, wall=21947
2023-06-27 08:19:27 - progress_bar.py[line:272] - INFO: epoch 004:   2617 / 2637 loss=2.222, loss_v1=0, loss_v2=0, nll_loss=1.005, ntokens=1261.8, nsentences=160, sample_size=1261.8, sample_size_v1=0, sample_size_v2=0, ppl=2.01, wps=605.3, ups=0.48, wpb=1261.8, bsz=160, num_updates=10510, lr=2.39646e-05, gnorm=4.46, clip=100, loss_scale=32, train_wall=21, gb_free=8.9, wall=21968
2023-06-27 08:19:48 - progress_bar.py[line:272] - INFO: epoch 004:   2627 / 2637 loss=2.24, loss_v1=0, loss_v2=0, nll_loss=1.028, ntokens=1282.9, nsentences=160, sample_size=1282.9, sample_size_v1=0, sample_size_v2=0, ppl=2.04, wps=614.7, ups=0.48, wpb=1282.9, bsz=160, num_updates=10520, lr=2.3957e-05, gnorm=5.3, clip=100, loss_scale=32, train_wall=21, gb_free=8.9, wall=21989
local datafile ../../dataset/OFA_data/vrd/vg_train_full.tsv slice_id 1 begin to initialize row_count and line_idx-to-offset mappinglocal datafile ../../dataset/OFA_data/vrd/vg_train_full.tsv slice_id 3 begin to initialize row_count and line_idx-to-offset mapping

local datafile ../../dataset/OFA_data/vrd/vg_train_full.tsv slice_id 2 begin to initialize row_count and line_idx-to-offset mapping
2023-06-27 08:20:09 - progress_bar.py[line:272] - INFO: epoch 004:   2637 / 2637 loss=2.258, loss_v1=0, loss_v2=0, nll_loss=1.047, ntokens=1236.4, nsentences=156, sample_size=1236.4, sample_size_v1=0, sample_size_v2=0, ppl=2.07, wps=608.2, ups=0.49, wpb=1236.4, bsz=156, num_updates=10530, lr=2.39495e-05, gnorm=4.993, clip=100, loss_scale=32, train_wall=20, gb_free=8.9, wall=22009
2023-06-27 08:20:09 - checkpoint_utils.py[line:64] - INFO: Preparing to save checkpoint for epoch 4 @ 10530 updates
2023-06-27 08:20:09 - trainer.py[line:431] - INFO: Saving checkpoint to ../../checkpoints/OFA/vrd_checkpoints/_16_3e-5_512_rare_3/checkpoint4.pt
local datafile ../../dataset/OFA_data/vrd/vg_train_full.tsv slice_id 2 finished initializing row_count and line_idx-to-offset mapping
file ../../dataset/OFA_data/vrd/vg_train_full.tsv slice_id 2 row count 105470 total row count 421879
local datafile ../../dataset/OFA_data/vrd/vg_train_full.tsv slice_id 3 finished initializing row_count and line_idx-to-offset mapping
file ../../dataset/OFA_data/vrd/vg_train_full.tsv slice_id 3 row count 105469 total row count 421879
local datafile ../../dataset/OFA_data/vrd/vg_train_full.tsv slice_id 1 finished initializing row_count and line_idx-to-offset mapping
file ../../dataset/OFA_data/vrd/vg_train_full.tsv slice_id 1 row count 105470 total row count 421879
slice_id 3 seek offset 316410
slice_id 1 seek offset 105470slice_id 2 seek offset 210940

2023-06-27 08:20:12 - trainer.py[line:441] - INFO: Finished saving checkpoint to ../../checkpoints/OFA/vrd_checkpoints/_16_3e-5_512_rare_3/checkpoint4.pt
2023-06-27 08:20:15 - checkpoint_utils.py[line:133] - INFO: Saved checkpoint ../../checkpoints/OFA/vrd_checkpoints/_16_3e-5_512_rare_3/checkpoint4.pt (epoch 4 @ 10530 updates, score None) (writing took 6.005709934048355 seconds)
2023-06-27 08:20:15 - train.py[line:332] - INFO: end of epoch 4 (average epoch stats below)
2023-06-27 08:20:15 - progress_bar.py[line:282] - INFO: epoch 004 | loss 2.289 | loss_v1 0 | loss_v2 0 | nll_loss 1.081 | ntokens 1259.93 | nsentences 159.984 | sample_size 1259.93 | sample_size_v1 0 | sample_size_v2 0 | ppl 2.12 | wps 602.1 | ups 0.48 | wpb 1259.9 | bsz 160 | num_updates 10530 | lr 2.39495e-05 | gnorm 4.721 | clip 100 | loss_scale 32 | train_wall 5492 | gb_free 8.9 | wall 22015
2023-06-27 08:20:15 - trainer.py[line:639] - INFO: loading train data for epoch 5
local datafile ../../dataset/OFA_data/vrd/vg_train_full.tsv slice_id 0 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../dataset/OFA_data/vrd/vg_train_full.tsv slice_id 0 finished initializing row_count and line_idx-to-offset mapping
file ../../dataset/OFA_data/vrd/vg_train_full.tsv slice_id 0 row count 105470 total row count 421879
slice_id 0 seek offset 0
2023-06-27 08:20:15 - trainer.py[line:703] - INFO: begin training epoch 5
2023-06-27 08:20:15 - train.py[line:305] - INFO: Start iterating over samples
2023-06-27 08:20:36 - progress_bar.py[line:272] - INFO: epoch 005:     10 / 2637 loss=2.246, loss_v1=0, loss_v2=0, nll_loss=1.033, ntokens=1253.7, nsentences=160, sample_size=1253.7, sample_size_v1=0, sample_size_v2=0, ppl=2.05, wps=456.9, ups=0.36, wpb=1253.7, bsz=160, num_updates=10540, lr=2.39419e-05, gnorm=4.569, clip=100, loss_scale=32, train_wall=21, gb_free=8.9, wall=22036
2023-06-27 08:20:57 - progress_bar.py[line:272] - INFO: epoch 005:     20 / 2637 loss=2.209, loss_v1=0, loss_v2=0, nll_loss=0.989, ntokens=1263.4, nsentences=160, sample_size=1263.4, sample_size_v1=0, sample_size_v2=0, ppl=1.99, wps=607.1, ups=0.48, wpb=1263.4, bsz=160, num_updates=10550, lr=2.39343e-05, gnorm=4.909, clip=100, loss_scale=32, train_wall=21, gb_free=8.9, wall=22057
2023-06-27 08:21:18 - progress_bar.py[line:272] - INFO: epoch 005:     30 / 2637 loss=2.223, loss_v1=0, loss_v2=0, nll_loss=1.01, ntokens=1256.1, nsentences=160, sample_size=1256.1, sample_size_v1=0, sample_size_v2=0, ppl=2.01, wps=603.5, ups=0.48, wpb=1256.1, bsz=160, num_updates=10560, lr=2.39268e-05, gnorm=4.691, clip=100, loss_scale=32, train_wall=21, gb_free=8.9, wall=22078
2023-06-27 08:21:39 - progress_bar.py[line:272] - INFO: epoch 005:     40 / 2637 loss=2.248, loss_v1=0, loss_v2=0, nll_loss=1.034, ntokens=1262.9, nsentences=160, sample_size=1262.9, sample_size_v1=0, sample_size_v2=0, ppl=2.05, wps=606.9, ups=0.48, wpb=1262.9, bsz=160, num_updates=10570, lr=2.39192e-05, gnorm=4.889, clip=100, loss_scale=32, train_wall=21, gb_free=8.9, wall=22099
2023-06-27 08:21:59 - progress_bar.py[line:272] - INFO: epoch 005:     50 / 2637 loss=2.211, loss_v1=0, loss_v2=0, nll_loss=0.995, ntokens=1238.6, nsentences=159.9, sample_size=1238.6, sample_size_v1=0, sample_size_v2=0, ppl=1.99, wps=595.1, ups=0.48, wpb=1238.6, bsz=159.9, num_updates=10580, lr=2.39117e-05, gnorm=4.308, clip=100, loss_scale=32, train_wall=21, gb_free=8.9, wall=22120
2023-06-27 08:22:20 - progress_bar.py[line:272] - INFO: epoch 005:     60 / 2637 loss=2.237, loss_v1=0, loss_v2=0, nll_loss=1.024, ntokens=1245.7, nsentences=160, sample_size=1245.7, sample_size_v1=0, sample_size_v2=0, ppl=2.03, wps=598.6, ups=0.48, wpb=1245.7, bsz=160, num_updates=10590, lr=2.39041e-05, gnorm=4.084, clip=100, loss_scale=32, train_wall=21, gb_free=8.9, wall=22140
2023-06-27 08:22:41 - progress_bar.py[line:272] - INFO: epoch 005:     70 / 2637 loss=2.253, loss_v1=0, loss_v2=0, nll_loss=1.043, ntokens=1256.8, nsentences=160, sample_size=1256.8, sample_size_v1=0, sample_size_v2=0, ppl=2.06, wps=604.1, ups=0.48, wpb=1256.8, bsz=160, num_updates=10600, lr=2.38965e-05, gnorm=4.584, clip=100, loss_scale=32, train_wall=21, gb_free=8.9, wall=22161
2023-06-27 08:23:02 - progress_bar.py[line:272] - INFO: epoch 005:     80 / 2637 loss=2.246, loss_v1=0, loss_v2=0, nll_loss=1.032, ntokens=1246.8, nsentences=160, sample_size=1246.8, sample_size_v1=0, sample_size_v2=0, ppl=2.05, wps=598.8, ups=0.48, wpb=1246.8, bsz=160, num_updates=10610, lr=2.3889e-05, gnorm=4.646, clip=100, loss_scale=32, train_wall=21, gb_free=8.9, wall=22182
2023-06-27 08:23:23 - progress_bar.py[line:272] - INFO: epoch 005:     90 / 2637 loss=2.231, loss_v1=0, loss_v2=0, nll_loss=1.016, ntokens=1257.7, nsentences=160, sample_size=1257.7, sample_size_v1=0, sample_size_v2=0, ppl=2.02, wps=603.4, ups=0.48, wpb=1257.7, bsz=160, num_updates=10620, lr=2.38814e-05, gnorm=4.673, clip=100, loss_scale=32, train_wall=21, gb_free=8.9, wall=22203
2023-06-27 08:23:43 - progress_bar.py[line:272] - INFO: epoch 005:    100 / 2637 loss=2.224, loss_v1=0, loss_v2=0, nll_loss=1.01, ntokens=1253.2, nsentences=160, sample_size=1253.2, sample_size_v1=0, sample_size_v2=0, ppl=2.01, wps=600.9, ups=0.48, wpb=1253.2, bsz=160, num_updates=10630, lr=2.38738e-05, gnorm=5.07, clip=100, loss_scale=32, train_wall=21, gb_free=8.9, wall=22224
2023-06-27 08:24:04 - progress_bar.py[line:272] - INFO: epoch 005:    110 / 2637 loss=2.228, loss_v1=0, loss_v2=0, nll_loss=1.013, ntokens=1243, nsentences=160, sample_size=1243, sample_size_v1=0, sample_size_v2=0, ppl=2.02, wps=595.1, ups=0.48, wpb=1243, bsz=160, num_updates=10640, lr=2.38663e-05, gnorm=5.169, clip=100, loss_scale=32, train_wall=21, gb_free=8.9, wall=22245
2023-06-27 08:24:25 - progress_bar.py[line:272] - INFO: epoch 005:    120 / 2637 loss=2.206, loss_v1=0, loss_v2=0, nll_loss=0.989, ntokens=1253.5, nsentences=160, sample_size=1253.5, sample_size_v1=0, sample_size_v2=0, ppl=1.98, wps=601.3, ups=0.48, wpb=1253.5, bsz=160, num_updates=10650, lr=2.38587e-05, gnorm=4.78, clip=100, loss_scale=32, train_wall=21, gb_free=8.9, wall=22266
2023-06-27 08:24:46 - progress_bar.py[line:272] - INFO: epoch 005:    130 / 2637 loss=2.229, loss_v1=0, loss_v2=0, nll_loss=1.014, ntokens=1234.1, nsentences=160, sample_size=1234.1, sample_size_v1=0, sample_size_v2=0, ppl=2.02, wps=592.3, ups=0.48, wpb=1234.1, bsz=160, num_updates=10660, lr=2.38511e-05, gnorm=5.06, clip=100, loss_scale=32, train_wall=21, gb_free=8.9, wall=22286
2023-06-27 08:25:07 - progress_bar.py[line:272] - INFO: epoch 005:    140 / 2637 loss=2.248, loss_v1=0, loss_v2=0, nll_loss=1.035, ntokens=1248.9, nsentences=160, sample_size=1248.9, sample_size_v1=0, sample_size_v2=0, ppl=2.05, wps=599.7, ups=0.48, wpb=1248.9, bsz=160, num_updates=10670, lr=2.38436e-05, gnorm=4.542, clip=100, loss_scale=32, train_wall=21, gb_free=8.9, wall=22307
2023-06-27 08:25:28 - progress_bar.py[line:272] - INFO: epoch 005:    150 / 2637 loss=2.264, loss_v1=0, loss_v2=0, nll_loss=1.052, ntokens=1250, nsentences=160, sample_size=1250, sample_size_v1=0, sample_size_v2=0, ppl=2.07, wps=600.4, ups=0.48, wpb=1250, bsz=160, num_updates=10680, lr=2.3836e-05, gnorm=5.268, clip=100, loss_scale=32, train_wall=21, gb_free=8.9, wall=22328
2023-06-27 08:25:49 - progress_bar.py[line:272] - INFO: epoch 005:    160 / 2637 loss=2.262, loss_v1=0, loss_v2=0, nll_loss=1.053, ntokens=1245.7, nsentences=160, sample_size=1245.7, sample_size_v1=0, sample_size_v2=0, ppl=2.07, wps=598.2, ups=0.48, wpb=1245.7, bsz=160, num_updates=10690, lr=2.38284e-05, gnorm=4.616, clip=100, loss_scale=32, train_wall=21, gb_free=8.9, wall=22349
2023-06-27 08:26:09 - progress_bar.py[line:272] - INFO: epoch 005:    170 / 2637 loss=2.251, loss_v1=0, loss_v2=0, nll_loss=1.04, ntokens=1240.6, nsentences=160, sample_size=1240.6, sample_size_v1=0, sample_size_v2=0, ppl=2.06, wps=595.8, ups=0.48, wpb=1240.6, bsz=160, num_updates=10700, lr=2.38209e-05, gnorm=4.494, clip=100, loss_scale=32, train_wall=21, gb_free=8.9, wall=22370
2023-06-27 08:26:30 - progress_bar.py[line:272] - INFO: epoch 005:    180 / 2637 loss=2.212, loss_v1=0, loss_v2=0, nll_loss=0.996, ntokens=1240.9, nsentences=160, sample_size=1240.9, sample_size_v1=0, sample_size_v2=0, ppl=2, wps=595.8, ups=0.48, wpb=1240.9, bsz=160, num_updates=10710, lr=2.38133e-05, gnorm=4.412, clip=100, loss_scale=32, train_wall=21, gb_free=8.9, wall=22390
2023-06-27 08:26:51 - progress_bar.py[line:272] - INFO: epoch 005:    190 / 2637 loss=2.213, loss_v1=0, loss_v2=0, nll_loss=0.995, ntokens=1238.7, nsentences=160, sample_size=1238.7, sample_size_v1=0, sample_size_v2=0, ppl=1.99, wps=594.9, ups=0.48, wpb=1238.7, bsz=160, num_updates=10720, lr=2.38058e-05, gnorm=5.475, clip=100, loss_scale=32, train_wall=21, gb_free=8.9, wall=22411
2023-06-27 08:27:12 - progress_bar.py[line:272] - INFO: epoch 005:    200 / 2637 loss=2.206, loss_v1=0, loss_v2=0, nll_loss=0.989, ntokens=1239.4, nsentences=160, sample_size=1239.4, sample_size_v1=0, sample_size_v2=0, ppl=1.99, wps=595.4, ups=0.48, wpb=1239.4, bsz=160, num_updates=10730, lr=2.37982e-05, gnorm=5.11, clip=100, loss_scale=32, train_wall=21, gb_free=8.9, wall=22432
2023-06-27 08:27:33 - progress_bar.py[line:272] - INFO: epoch 005:    210 / 2637 loss=2.199, loss_v1=0, loss_v2=0, nll_loss=0.981, ntokens=1249.1, nsentences=160, sample_size=1249.1, sample_size_v1=0, sample_size_v2=0, ppl=1.97, wps=599.3, ups=0.48, wpb=1249.1, bsz=160, num_updates=10740, lr=2.37906e-05, gnorm=4.605, clip=100, loss_scale=32, train_wall=21, gb_free=8.9, wall=22453
2023-06-27 08:27:54 - progress_bar.py[line:272] - INFO: epoch 005:    220 / 2637 loss=2.184, loss_v1=0, loss_v2=0, nll_loss=0.965, ntokens=1220.4, nsentences=160, sample_size=1220.4, sample_size_v1=0, sample_size_v2=0, ppl=1.95, wps=586, ups=0.48, wpb=1220.4, bsz=160, num_updates=10750, lr=2.37831e-05, gnorm=5.037, clip=100, loss_scale=32, train_wall=21, gb_free=8.9, wall=22474
2023-06-27 08:28:14 - progress_bar.py[line:272] - INFO: epoch 005:    230 / 2637 loss=2.217, loss_v1=0, loss_v2=0, nll_loss=1.003, ntokens=1257.7, nsentences=160, sample_size=1257.7, sample_size_v1=0, sample_size_v2=0, ppl=2, wps=603.2, ups=0.48, wpb=1257.7, bsz=160, num_updates=10760, lr=2.37755e-05, gnorm=5.004, clip=100, loss_scale=32, train_wall=21, gb_free=8.9, wall=22495
2023-06-27 08:28:35 - progress_bar.py[line:272] - INFO: epoch 005:    240 / 2637 loss=2.204, loss_v1=0, loss_v2=0, nll_loss=0.987, ntokens=1248.9, nsentences=160, sample_size=1248.9, sample_size_v1=0, sample_size_v2=0, ppl=1.98, wps=598.8, ups=0.48, wpb=1248.9, bsz=160, num_updates=10770, lr=2.37679e-05, gnorm=4.539, clip=100, loss_scale=32, train_wall=21, gb_free=8.9, wall=22516
2023-06-27 08:28:56 - progress_bar.py[line:272] - INFO: epoch 005:    250 / 2637 loss=2.209, loss_v1=0, loss_v2=0, nll_loss=0.993, ntokens=1263.2, nsentences=160, sample_size=1263.2, sample_size_v1=0, sample_size_v2=0, ppl=1.99, wps=605.9, ups=0.48, wpb=1263.2, bsz=160, num_updates=10780, lr=2.37604e-05, gnorm=5.301, clip=100, loss_scale=32, train_wall=21, gb_free=8.9, wall=22536
2023-06-27 08:29:17 - progress_bar.py[line:272] - INFO: epoch 005:    260 / 2637 loss=2.195, loss_v1=0, loss_v2=0, nll_loss=0.978, ntokens=1246.9, nsentences=160, sample_size=1246.9, sample_size_v1=0, sample_size_v2=0, ppl=1.97, wps=598.9, ups=0.48, wpb=1246.9, bsz=160, num_updates=10790, lr=2.37528e-05, gnorm=4.961, clip=100, loss_scale=32, train_wall=21, gb_free=8.9, wall=22557
2023-06-27 08:29:38 - progress_bar.py[line:272] - INFO: epoch 005:    270 / 2637 loss=2.225, loss_v1=0, loss_v2=0, nll_loss=1.008, ntokens=1249.6, nsentences=160, sample_size=1249.6, sample_size_v1=0, sample_size_v2=0, ppl=2.01, wps=599.5, ups=0.48, wpb=1249.6, bsz=160, num_updates=10800, lr=2.37452e-05, gnorm=6.08, clip=100, loss_scale=32, train_wall=21, gb_free=8.9, wall=22578
2023-06-27 08:29:59 - progress_bar.py[line:272] - INFO: epoch 005:    280 / 2637 loss=2.248, loss_v1=0, loss_v2=0, nll_loss=1.037, ntokens=1254, nsentences=160, sample_size=1254, sample_size_v1=0, sample_size_v2=0, ppl=2.05, wps=601.6, ups=0.48, wpb=1254, bsz=160, num_updates=10810, lr=2.37377e-05, gnorm=4.585, clip=100, loss_scale=32, train_wall=21, gb_free=8.9, wall=22599
2023-06-27 08:30:19 - progress_bar.py[line:272] - INFO: epoch 005:    290 / 2637 loss=2.228, loss_v1=0, loss_v2=0, nll_loss=1.013, ntokens=1243.8, nsentences=160, sample_size=1243.8, sample_size_v1=0, sample_size_v2=0, ppl=2.02, wps=596.7, ups=0.48, wpb=1243.8, bsz=160, num_updates=10820, lr=2.37301e-05, gnorm=4.888, clip=100, loss_scale=32, train_wall=21, gb_free=8.9, wall=22620
2023-06-27 08:30:40 - progress_bar.py[line:272] - INFO: epoch 005:    300 / 2637 loss=2.217, loss_v1=0, loss_v2=0, nll_loss=1, ntokens=1234.2, nsentences=160, sample_size=1234.2, sample_size_v1=0, sample_size_v2=0, ppl=2, wps=591.6, ups=0.48, wpb=1234.2, bsz=160, num_updates=10830, lr=2.37225e-05, gnorm=4.798, clip=100, loss_scale=32, train_wall=21, gb_free=8.9, wall=22641
2023-06-27 08:31:01 - progress_bar.py[line:272] - INFO: epoch 005:    310 / 2637 loss=2.207, loss_v1=0, loss_v2=0, nll_loss=0.987, ntokens=1235.4, nsentences=160, sample_size=1235.4, sample_size_v1=0, sample_size_v2=0, ppl=1.98, wps=592.6, ups=0.48, wpb=1235.4, bsz=160, num_updates=10840, lr=2.3715e-05, gnorm=4.977, clip=100, loss_scale=32, train_wall=21, gb_free=8.9, wall=22661
2023-06-27 08:31:22 - progress_bar.py[line:272] - INFO: epoch 005:    320 / 2637 loss=2.195, loss_v1=0, loss_v2=0, nll_loss=0.978, ntokens=1237.8, nsentences=160, sample_size=1237.8, sample_size_v1=0, sample_size_v2=0, ppl=1.97, wps=593.4, ups=0.48, wpb=1237.8, bsz=160, num_updates=10850, lr=2.37074e-05, gnorm=4.848, clip=100, loss_scale=32, train_wall=21, gb_free=8.9, wall=22682
2023-06-27 08:31:43 - progress_bar.py[line:272] - INFO: epoch 005:    330 / 2637 loss=2.216, loss_v1=0, loss_v2=0, nll_loss=1.002, ntokens=1262.9, nsentences=160, sample_size=1262.9, sample_size_v1=0, sample_size_v2=0, ppl=2, wps=605.2, ups=0.48, wpb=1262.9, bsz=160, num_updates=10860, lr=2.36999e-05, gnorm=4.984, clip=100, loss_scale=32, train_wall=21, gb_free=8.9, wall=22703
2023-06-27 08:32:04 - progress_bar.py[line:272] - INFO: epoch 005:    340 / 2637 loss=2.189, loss_v1=0, loss_v2=0, nll_loss=0.969, ntokens=1234, nsentences=160, sample_size=1234, sample_size_v1=0, sample_size_v2=0, ppl=1.96, wps=591.4, ups=0.48, wpb=1234, bsz=160, num_updates=10870, lr=2.36923e-05, gnorm=4.813, clip=100, loss_scale=32, train_wall=21, gb_free=8.9, wall=22724
2023-06-27 08:32:25 - progress_bar.py[line:272] - INFO: epoch 005:    350 / 2637 loss=2.245, loss_v1=0, loss_v2=0, nll_loss=1.03, ntokens=1259.9, nsentences=160, sample_size=1259.9, sample_size_v1=0, sample_size_v2=0, ppl=2.04, wps=603.9, ups=0.48, wpb=1259.9, bsz=160, num_updates=10880, lr=2.36847e-05, gnorm=5.081, clip=100, loss_scale=32, train_wall=21, gb_free=8.9, wall=22745
2023-06-27 08:32:45 - progress_bar.py[line:272] - INFO: epoch 005:    360 / 2637 loss=2.195, loss_v1=0, loss_v2=0, nll_loss=0.977, ntokens=1249.6, nsentences=160, sample_size=1249.6, sample_size_v1=0, sample_size_v2=0, ppl=1.97, wps=599.1, ups=0.48, wpb=1249.6, bsz=160, num_updates=10890, lr=2.36772e-05, gnorm=4.605, clip=100, loss_scale=32, train_wall=21, gb_free=8.9, wall=22766
2023-06-27 08:33:06 - progress_bar.py[line:272] - INFO: epoch 005:    370 / 2637 loss=2.18, loss_v1=0, loss_v2=0, nll_loss=0.959, ntokens=1253.1, nsentences=160, sample_size=1253.1, sample_size_v1=0, sample_size_v2=0, ppl=1.94, wps=601, ups=0.48, wpb=1253.1, bsz=160, num_updates=10900, lr=2.36696e-05, gnorm=4.788, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=22787
2023-06-27 08:33:27 - progress_bar.py[line:272] - INFO: epoch 005:    380 / 2637 loss=2.178, loss_v1=0, loss_v2=0, nll_loss=0.959, ntokens=1247.4, nsentences=160, sample_size=1247.4, sample_size_v1=0, sample_size_v2=0, ppl=1.94, wps=598.2, ups=0.48, wpb=1247.4, bsz=160, num_updates=10910, lr=2.3662e-05, gnorm=5.334, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=22807
2023-06-27 08:33:48 - progress_bar.py[line:272] - INFO: epoch 005:    390 / 2637 loss=2.168, loss_v1=0, loss_v2=0, nll_loss=0.947, ntokens=1233.4, nsentences=160, sample_size=1233.4, sample_size_v1=0, sample_size_v2=0, ppl=1.93, wps=591.2, ups=0.48, wpb=1233.4, bsz=160, num_updates=10920, lr=2.36545e-05, gnorm=5.088, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=22828
2023-06-27 08:34:09 - progress_bar.py[line:272] - INFO: epoch 005:    400 / 2637 loss=2.167, loss_v1=0, loss_v2=0, nll_loss=0.945, ntokens=1251.7, nsentences=160, sample_size=1251.7, sample_size_v1=0, sample_size_v2=0, ppl=1.92, wps=600.1, ups=0.48, wpb=1251.7, bsz=160, num_updates=10930, lr=2.36469e-05, gnorm=4.988, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=22849
2023-06-27 08:34:30 - progress_bar.py[line:272] - INFO: epoch 005:    410 / 2637 loss=2.171, loss_v1=0, loss_v2=0, nll_loss=0.949, ntokens=1237.4, nsentences=160, sample_size=1237.4, sample_size_v1=0, sample_size_v2=0, ppl=1.93, wps=593.2, ups=0.48, wpb=1237.4, bsz=160, num_updates=10940, lr=2.36393e-05, gnorm=5.437, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=22870
2023-06-27 08:34:51 - progress_bar.py[line:272] - INFO: epoch 005:    420 / 2637 loss=2.178, loss_v1=0, loss_v2=0, nll_loss=0.957, ntokens=1269.3, nsentences=160, sample_size=1269.3, sample_size_v1=0, sample_size_v2=0, ppl=1.94, wps=608.1, ups=0.48, wpb=1269.3, bsz=160, num_updates=10950, lr=2.36318e-05, gnorm=5.128, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=22891
2023-06-27 08:35:12 - progress_bar.py[line:272] - INFO: epoch 005:    430 / 2637 loss=2.165, loss_v1=0, loss_v2=0, nll_loss=0.942, ntokens=1241.8, nsentences=160, sample_size=1241.8, sample_size_v1=0, sample_size_v2=0, ppl=1.92, wps=595, ups=0.48, wpb=1241.8, bsz=160, num_updates=10960, lr=2.36242e-05, gnorm=4.878, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=22912
2023-06-27 08:35:32 - progress_bar.py[line:272] - INFO: epoch 005:    440 / 2637 loss=2.175, loss_v1=0, loss_v2=0, nll_loss=0.954, ntokens=1251.6, nsentences=160, sample_size=1251.6, sample_size_v1=0, sample_size_v2=0, ppl=1.94, wps=599.9, ups=0.48, wpb=1251.6, bsz=160, num_updates=10970, lr=2.36167e-05, gnorm=4.439, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=22933
2023-06-27 08:35:53 - progress_bar.py[line:272] - INFO: epoch 005:    450 / 2637 loss=2.182, loss_v1=0, loss_v2=0, nll_loss=0.962, ntokens=1241.5, nsentences=160, sample_size=1241.5, sample_size_v1=0, sample_size_v2=0, ppl=1.95, wps=595.6, ups=0.48, wpb=1241.5, bsz=160, num_updates=10980, lr=2.36091e-05, gnorm=4.95, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=22954
2023-06-27 08:36:14 - progress_bar.py[line:272] - INFO: epoch 005:    460 / 2637 loss=2.184, loss_v1=0, loss_v2=0, nll_loss=0.966, ntokens=1269.3, nsentences=160, sample_size=1269.3, sample_size_v1=0, sample_size_v2=0, ppl=1.95, wps=610, ups=0.48, wpb=1269.3, bsz=160, num_updates=10990, lr=2.36015e-05, gnorm=5.566, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=22974
2023-06-27 08:36:35 - progress_bar.py[line:272] - INFO: epoch 005:    470 / 2637 loss=2.189, loss_v1=0, loss_v2=0, nll_loss=0.969, ntokens=1243.9, nsentences=160, sample_size=1243.9, sample_size_v1=0, sample_size_v2=0, ppl=1.96, wps=598.1, ups=0.48, wpb=1243.9, bsz=160, num_updates=11000, lr=2.3594e-05, gnorm=5.454, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=22995
2023-06-27 08:36:56 - progress_bar.py[line:272] - INFO: epoch 005:    480 / 2637 loss=2.206, loss_v1=0, loss_v2=0, nll_loss=0.989, ntokens=1261.4, nsentences=160, sample_size=1261.4, sample_size_v1=0, sample_size_v2=0, ppl=1.98, wps=606.1, ups=0.48, wpb=1261.4, bsz=160, num_updates=11010, lr=2.35864e-05, gnorm=5.604, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=23016
2023-06-27 08:37:17 - progress_bar.py[line:272] - INFO: epoch 005:    490 / 2637 loss=2.184, loss_v1=0, loss_v2=0, nll_loss=0.966, ntokens=1258.5, nsentences=160, sample_size=1258.5, sample_size_v1=0, sample_size_v2=0, ppl=1.95, wps=603, ups=0.48, wpb=1258.5, bsz=160, num_updates=11020, lr=2.35788e-05, gnorm=4.701, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=23037
2023-06-27 08:37:37 - progress_bar.py[line:272] - INFO: epoch 005:    500 / 2637 loss=2.213, loss_v1=0, loss_v2=0, nll_loss=0.998, ntokens=1270.7, nsentences=160, sample_size=1270.7, sample_size_v1=0, sample_size_v2=0, ppl=2, wps=608.8, ups=0.48, wpb=1270.7, bsz=160, num_updates=11030, lr=2.35713e-05, gnorm=4.981, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=23058
2023-06-27 08:37:58 - progress_bar.py[line:272] - INFO: epoch 005:    510 / 2637 loss=2.22, loss_v1=0, loss_v2=0, nll_loss=1.001, ntokens=1257.7, nsentences=160, sample_size=1257.7, sample_size_v1=0, sample_size_v2=0, ppl=2, wps=602.3, ups=0.48, wpb=1257.7, bsz=160, num_updates=11040, lr=2.35637e-05, gnorm=5.041, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=23079
2023-06-27 08:38:19 - progress_bar.py[line:272] - INFO: epoch 005:    520 / 2637 loss=2.241, loss_v1=0, loss_v2=0, nll_loss=1.027, ntokens=1246.3, nsentences=160, sample_size=1246.3, sample_size_v1=0, sample_size_v2=0, ppl=2.04, wps=597.4, ups=0.48, wpb=1246.3, bsz=160, num_updates=11050, lr=2.35561e-05, gnorm=4.992, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=23099
2023-06-27 08:38:40 - progress_bar.py[line:272] - INFO: epoch 005:    530 / 2637 loss=2.178, loss_v1=0, loss_v2=0, nll_loss=0.959, ntokens=1244.4, nsentences=160, sample_size=1244.4, sample_size_v1=0, sample_size_v2=0, ppl=1.94, wps=597, ups=0.48, wpb=1244.4, bsz=160, num_updates=11060, lr=2.35486e-05, gnorm=5.072, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=23120
2023-06-27 08:39:01 - progress_bar.py[line:272] - INFO: epoch 005:    540 / 2637 loss=2.263, loss_v1=0, loss_v2=0, nll_loss=1.052, ntokens=1257.5, nsentences=160, sample_size=1257.5, sample_size_v1=0, sample_size_v2=0, ppl=2.07, wps=602.6, ups=0.48, wpb=1257.5, bsz=160, num_updates=11070, lr=2.3541e-05, gnorm=5.942, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=23141
2023-06-27 08:39:22 - progress_bar.py[line:272] - INFO: epoch 005:    550 / 2637 loss=2.222, loss_v1=0, loss_v2=0, nll_loss=1.007, ntokens=1262.4, nsentences=160, sample_size=1262.4, sample_size_v1=0, sample_size_v2=0, ppl=2.01, wps=605.8, ups=0.48, wpb=1262.4, bsz=160, num_updates=11080, lr=2.35334e-05, gnorm=5.741, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=23162
2023-06-27 08:39:43 - progress_bar.py[line:272] - INFO: epoch 005:    560 / 2637 loss=2.237, loss_v1=0, loss_v2=0, nll_loss=1.02, ntokens=1265.7, nsentences=160, sample_size=1265.7, sample_size_v1=0, sample_size_v2=0, ppl=2.03, wps=608, ups=0.48, wpb=1265.7, bsz=160, num_updates=11090, lr=2.35259e-05, gnorm=5.527, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=23183
2023-06-27 08:40:03 - progress_bar.py[line:272] - INFO: epoch 005:    570 / 2637 loss=2.238, loss_v1=0, loss_v2=0, nll_loss=1.027, ntokens=1243.5, nsentences=160, sample_size=1243.5, sample_size_v1=0, sample_size_v2=0, ppl=2.04, wps=597, ups=0.48, wpb=1243.5, bsz=160, num_updates=11100, lr=2.35183e-05, gnorm=5.519, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=23204
2023-06-27 08:40:24 - progress_bar.py[line:272] - INFO: epoch 005:    580 / 2637 loss=2.243, loss_v1=0, loss_v2=0, nll_loss=1.03, ntokens=1249.8, nsentences=160, sample_size=1249.8, sample_size_v1=0, sample_size_v2=0, ppl=2.04, wps=599.8, ups=0.48, wpb=1249.8, bsz=160, num_updates=11110, lr=2.35108e-05, gnorm=5.749, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=23225
2023-06-27 08:40:45 - progress_bar.py[line:272] - INFO: epoch 005:    590 / 2637 loss=2.228, loss_v1=0, loss_v2=0, nll_loss=1.014, ntokens=1258.7, nsentences=160, sample_size=1258.7, sample_size_v1=0, sample_size_v2=0, ppl=2.02, wps=603.6, ups=0.48, wpb=1258.7, bsz=160, num_updates=11120, lr=2.35032e-05, gnorm=4.663, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=23245
2023-06-27 08:41:06 - progress_bar.py[line:272] - INFO: epoch 005:    600 / 2637 loss=2.226, loss_v1=0, loss_v2=0, nll_loss=1.01, ntokens=1271.6, nsentences=160, sample_size=1271.6, sample_size_v1=0, sample_size_v2=0, ppl=2.01, wps=609.8, ups=0.48, wpb=1271.6, bsz=160, num_updates=11130, lr=2.34956e-05, gnorm=5.423, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=23266
2023-06-27 08:41:27 - progress_bar.py[line:272] - INFO: epoch 005:    610 / 2637 loss=2.246, loss_v1=0, loss_v2=0, nll_loss=1.034, ntokens=1252, nsentences=160, sample_size=1252, sample_size_v1=0, sample_size_v2=0, ppl=2.05, wps=601.1, ups=0.48, wpb=1252, bsz=160, num_updates=11140, lr=2.34881e-05, gnorm=5.51, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=23287
2023-06-27 08:41:48 - progress_bar.py[line:272] - INFO: epoch 005:    620 / 2637 loss=2.215, loss_v1=0, loss_v2=0, nll_loss=0.997, ntokens=1262.1, nsentences=160, sample_size=1262.1, sample_size_v1=0, sample_size_v2=0, ppl=2, wps=604.8, ups=0.48, wpb=1262.1, bsz=160, num_updates=11150, lr=2.34805e-05, gnorm=4.467, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=23308
2023-06-27 08:42:09 - progress_bar.py[line:272] - INFO: epoch 005:    630 / 2637 loss=2.219, loss_v1=0, loss_v2=0, nll_loss=1.005, ntokens=1240.3, nsentences=160, sample_size=1240.3, sample_size_v1=0, sample_size_v2=0, ppl=2.01, wps=594.7, ups=0.48, wpb=1240.3, bsz=160, num_updates=11160, lr=2.34729e-05, gnorm=5.375, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=23329
2023-06-27 08:42:29 - progress_bar.py[line:272] - INFO: epoch 005:    640 / 2637 loss=2.188, loss_v1=0, loss_v2=0, nll_loss=0.969, ntokens=1271.1, nsentences=160, sample_size=1271.1, sample_size_v1=0, sample_size_v2=0, ppl=1.96, wps=609.1, ups=0.48, wpb=1271.1, bsz=160, num_updates=11170, lr=2.34654e-05, gnorm=4.589, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=23350
2023-06-27 08:42:50 - progress_bar.py[line:272] - INFO: epoch 005:    650 / 2637 loss=2.229, loss_v1=0, loss_v2=0, nll_loss=1.016, ntokens=1241.3, nsentences=160, sample_size=1241.3, sample_size_v1=0, sample_size_v2=0, ppl=2.02, wps=595.6, ups=0.48, wpb=1241.3, bsz=160, num_updates=11180, lr=2.34578e-05, gnorm=5.378, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=23371
2023-06-27 08:43:11 - progress_bar.py[line:272] - INFO: epoch 005:    660 / 2637 loss=2.25, loss_v1=0, loss_v2=0, nll_loss=1.038, ntokens=1249.7, nsentences=160, sample_size=1249.7, sample_size_v1=0, sample_size_v2=0, ppl=2.05, wps=599.3, ups=0.48, wpb=1249.7, bsz=160, num_updates=11190, lr=2.34502e-05, gnorm=5.426, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=23391
2023-06-27 08:43:32 - progress_bar.py[line:272] - INFO: epoch 005:    670 / 2637 loss=2.211, loss_v1=0, loss_v2=0, nll_loss=0.993, ntokens=1256.1, nsentences=160, sample_size=1256.1, sample_size_v1=0, sample_size_v2=0, ppl=1.99, wps=601.6, ups=0.48, wpb=1256.1, bsz=160, num_updates=11200, lr=2.34427e-05, gnorm=4.509, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=23412
2023-06-27 08:43:53 - progress_bar.py[line:272] - INFO: epoch 005:    680 / 2637 loss=2.221, loss_v1=0, loss_v2=0, nll_loss=1.006, ntokens=1275.3, nsentences=160, sample_size=1275.3, sample_size_v1=0, sample_size_v2=0, ppl=2.01, wps=609.7, ups=0.48, wpb=1275.3, bsz=160, num_updates=11210, lr=2.34351e-05, gnorm=4.51, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=23433
2023-06-27 08:44:14 - progress_bar.py[line:272] - INFO: epoch 005:    690 / 2637 loss=2.239, loss_v1=0, loss_v2=0, nll_loss=1.026, ntokens=1278.7, nsentences=160, sample_size=1278.7, sample_size_v1=0, sample_size_v2=0, ppl=2.04, wps=613.2, ups=0.48, wpb=1278.7, bsz=160, num_updates=11220, lr=2.34275e-05, gnorm=4.514, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=23454
2023-06-27 08:44:35 - progress_bar.py[line:272] - INFO: epoch 005:    700 / 2637 loss=2.206, loss_v1=0, loss_v2=0, nll_loss=0.989, ntokens=1249.3, nsentences=160, sample_size=1249.3, sample_size_v1=0, sample_size_v2=0, ppl=1.98, wps=599.3, ups=0.48, wpb=1249.3, bsz=160, num_updates=11230, lr=2.342e-05, gnorm=4.449, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=23475
2023-06-27 08:44:55 - progress_bar.py[line:272] - INFO: epoch 005:    710 / 2637 loss=2.232, loss_v1=0, loss_v2=0, nll_loss=1.018, ntokens=1274.6, nsentences=160, sample_size=1274.6, sample_size_v1=0, sample_size_v2=0, ppl=2.02, wps=611.5, ups=0.48, wpb=1274.6, bsz=160, num_updates=11240, lr=2.34124e-05, gnorm=5.22, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=23496
2023-06-27 08:45:16 - progress_bar.py[line:272] - INFO: epoch 005:    720 / 2637 loss=2.215, loss_v1=0, loss_v2=0, nll_loss=1, ntokens=1241.4, nsentences=160, sample_size=1241.4, sample_size_v1=0, sample_size_v2=0, ppl=2, wps=595.4, ups=0.48, wpb=1241.4, bsz=160, num_updates=11250, lr=2.34049e-05, gnorm=4.62, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=23517
2023-06-27 08:45:37 - progress_bar.py[line:272] - INFO: epoch 005:    730 / 2637 loss=2.239, loss_v1=0, loss_v2=0, nll_loss=1.026, ntokens=1265.8, nsentences=160, sample_size=1265.8, sample_size_v1=0, sample_size_v2=0, ppl=2.04, wps=608.5, ups=0.48, wpb=1265.8, bsz=160, num_updates=11260, lr=2.33973e-05, gnorm=4.742, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=23537
2023-06-27 08:45:58 - progress_bar.py[line:272] - INFO: epoch 005:    740 / 2637 loss=2.217, loss_v1=0, loss_v2=0, nll_loss=1.002, ntokens=1257.1, nsentences=160, sample_size=1257.1, sample_size_v1=0, sample_size_v2=0, ppl=2, wps=604, ups=0.48, wpb=1257.1, bsz=160, num_updates=11270, lr=2.33897e-05, gnorm=4.463, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=23558
2023-06-27 08:46:19 - progress_bar.py[line:272] - INFO: epoch 005:    750 / 2637 loss=2.241, loss_v1=0, loss_v2=0, nll_loss=1.027, ntokens=1266.4, nsentences=160, sample_size=1266.4, sample_size_v1=0, sample_size_v2=0, ppl=2.04, wps=608.4, ups=0.48, wpb=1266.4, bsz=160, num_updates=11280, lr=2.33822e-05, gnorm=4.929, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=23579
2023-06-27 08:46:40 - progress_bar.py[line:272] - INFO: epoch 005:    760 / 2637 loss=2.225, loss_v1=0, loss_v2=0, nll_loss=1.011, ntokens=1269.8, nsentences=160, sample_size=1269.8, sample_size_v1=0, sample_size_v2=0, ppl=2.01, wps=609.7, ups=0.48, wpb=1269.8, bsz=160, num_updates=11290, lr=2.33746e-05, gnorm=4.916, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=23600
2023-06-27 08:47:00 - progress_bar.py[line:272] - INFO: epoch 005:    770 / 2637 loss=2.219, loss_v1=0, loss_v2=0, nll_loss=1.003, ntokens=1254.1, nsentences=160, sample_size=1254.1, sample_size_v1=0, sample_size_v2=0, ppl=2, wps=602.9, ups=0.48, wpb=1254.1, bsz=160, num_updates=11300, lr=2.3367e-05, gnorm=4.577, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=23621
2023-06-27 08:47:21 - progress_bar.py[line:272] - INFO: epoch 005:    780 / 2637 loss=2.219, loss_v1=0, loss_v2=0, nll_loss=1.004, ntokens=1252.3, nsentences=160, sample_size=1252.3, sample_size_v1=0, sample_size_v2=0, ppl=2.01, wps=601.1, ups=0.48, wpb=1252.3, bsz=160, num_updates=11310, lr=2.33595e-05, gnorm=4.585, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=23641
2023-06-27 08:47:42 - progress_bar.py[line:272] - INFO: epoch 005:    790 / 2637 loss=2.232, loss_v1=0, loss_v2=0, nll_loss=1.017, ntokens=1265.2, nsentences=160, sample_size=1265.2, sample_size_v1=0, sample_size_v2=0, ppl=2.02, wps=606.9, ups=0.48, wpb=1265.2, bsz=160, num_updates=11320, lr=2.33519e-05, gnorm=5.314, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=23662
2023-06-27 08:48:03 - progress_bar.py[line:272] - INFO: epoch 005:    800 / 2637 loss=2.207, loss_v1=0, loss_v2=0, nll_loss=0.989, ntokens=1256.7, nsentences=160, sample_size=1256.7, sample_size_v1=0, sample_size_v2=0, ppl=1.99, wps=603.6, ups=0.48, wpb=1256.7, bsz=160, num_updates=11330, lr=2.33443e-05, gnorm=4.557, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=23683
2023-06-27 08:48:24 - progress_bar.py[line:272] - INFO: epoch 005:    810 / 2637 loss=2.219, loss_v1=0, loss_v2=0, nll_loss=1.003, ntokens=1233.4, nsentences=160, sample_size=1233.4, sample_size_v1=0, sample_size_v2=0, ppl=2, wps=591.7, ups=0.48, wpb=1233.4, bsz=160, num_updates=11340, lr=2.33368e-05, gnorm=4.998, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=23704
2023-06-27 08:48:45 - progress_bar.py[line:272] - INFO: epoch 005:    820 / 2637 loss=2.197, loss_v1=0, loss_v2=0, nll_loss=0.98, ntokens=1273.5, nsentences=160, sample_size=1273.5, sample_size_v1=0, sample_size_v2=0, ppl=1.97, wps=610.6, ups=0.48, wpb=1273.5, bsz=160, num_updates=11350, lr=2.33292e-05, gnorm=5.72, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=23725
2023-06-27 08:49:05 - progress_bar.py[line:272] - INFO: epoch 005:    830 / 2637 loss=2.265, loss_v1=0, loss_v2=0, nll_loss=1.056, ntokens=1247.3, nsentences=160, sample_size=1247.3, sample_size_v1=0, sample_size_v2=0, ppl=2.08, wps=597.7, ups=0.48, wpb=1247.3, bsz=160, num_updates=11360, lr=2.33217e-05, gnorm=4.38, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=23746
2023-06-27 08:49:26 - progress_bar.py[line:272] - INFO: epoch 005:    840 / 2637 loss=2.212, loss_v1=0, loss_v2=0, nll_loss=0.995, ntokens=1276.6, nsentences=160, sample_size=1276.6, sample_size_v1=0, sample_size_v2=0, ppl=1.99, wps=611.5, ups=0.48, wpb=1276.6, bsz=160, num_updates=11370, lr=2.33141e-05, gnorm=4.3, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=23767
2023-06-27 08:49:47 - progress_bar.py[line:272] - INFO: epoch 005:    850 / 2637 loss=2.22, loss_v1=0, loss_v2=0, nll_loss=1.004, ntokens=1244.8, nsentences=160, sample_size=1244.8, sample_size_v1=0, sample_size_v2=0, ppl=2.01, wps=596.7, ups=0.48, wpb=1244.8, bsz=160, num_updates=11380, lr=2.33065e-05, gnorm=5.164, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=23787
2023-06-27 08:50:08 - progress_bar.py[line:272] - INFO: epoch 005:    860 / 2637 loss=2.22, loss_v1=0, loss_v2=0, nll_loss=1.005, ntokens=1241.4, nsentences=160, sample_size=1241.4, sample_size_v1=0, sample_size_v2=0, ppl=2.01, wps=594.8, ups=0.48, wpb=1241.4, bsz=160, num_updates=11390, lr=2.3299e-05, gnorm=4.488, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=23808
2023-06-27 08:50:29 - progress_bar.py[line:272] - INFO: epoch 005:    870 / 2637 loss=2.22, loss_v1=0, loss_v2=0, nll_loss=1.005, ntokens=1230.6, nsentences=160, sample_size=1230.6, sample_size_v1=0, sample_size_v2=0, ppl=2.01, wps=590.3, ups=0.48, wpb=1230.6, bsz=160, num_updates=11400, lr=2.32914e-05, gnorm=5.229, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=23829
2023-06-27 08:50:50 - progress_bar.py[line:272] - INFO: epoch 005:    880 / 2637 loss=2.224, loss_v1=0, loss_v2=0, nll_loss=1.009, ntokens=1266.6, nsentences=160, sample_size=1266.6, sample_size_v1=0, sample_size_v2=0, ppl=2.01, wps=606.8, ups=0.48, wpb=1266.6, bsz=160, num_updates=11410, lr=2.32838e-05, gnorm=4.884, clip=100, loss_scale=128, train_wall=21, gb_free=8.9, wall=23850
2023-06-27 08:50:52 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2023-06-27 08:51:13 - progress_bar.py[line:272] - INFO: epoch 005:    891 / 2637 loss=2.188, loss_v1=0, loss_v2=0, nll_loss=0.968, ntokens=1252.5, nsentences=160, sample_size=1252.5, sample_size_v1=0, sample_size_v2=0, ppl=1.96, wps=546.7, ups=0.44, wpb=1252.5, bsz=160, num_updates=11420, lr=2.32763e-05, gnorm=4.618, clip=100, loss_scale=64, train_wall=23, gb_free=8.9, wall=23873
2023-06-27 08:51:34 - progress_bar.py[line:272] - INFO: epoch 005:    901 / 2637 loss=2.21, loss_v1=0, loss_v2=0, nll_loss=0.994, ntokens=1253.9, nsentences=160, sample_size=1253.9, sample_size_v1=0, sample_size_v2=0, ppl=1.99, wps=602.2, ups=0.48, wpb=1253.9, bsz=160, num_updates=11430, lr=2.32687e-05, gnorm=4.863, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=23894
2023-06-27 08:51:54 - progress_bar.py[line:272] - INFO: epoch 005:    911 / 2637 loss=2.193, loss_v1=0, loss_v2=0, nll_loss=0.976, ntokens=1244.8, nsentences=160, sample_size=1244.8, sample_size_v1=0, sample_size_v2=0, ppl=1.97, wps=598.2, ups=0.48, wpb=1244.8, bsz=160, num_updates=11440, lr=2.32611e-05, gnorm=4.715, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=23915
2023-06-27 08:52:15 - progress_bar.py[line:272] - INFO: epoch 005:    921 / 2637 loss=2.205, loss_v1=0, loss_v2=0, nll_loss=0.989, ntokens=1254.5, nsentences=160, sample_size=1254.5, sample_size_v1=0, sample_size_v2=0, ppl=1.98, wps=602.3, ups=0.48, wpb=1254.5, bsz=160, num_updates=11450, lr=2.32536e-05, gnorm=4.885, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=23935
2023-06-27 08:52:36 - progress_bar.py[line:272] - INFO: epoch 005:    931 / 2637 loss=2.202, loss_v1=0, loss_v2=0, nll_loss=0.983, ntokens=1262.5, nsentences=160, sample_size=1262.5, sample_size_v1=0, sample_size_v2=0, ppl=1.98, wps=606.7, ups=0.48, wpb=1262.5, bsz=160, num_updates=11460, lr=2.3246e-05, gnorm=4.694, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=23956
2023-06-27 08:52:57 - progress_bar.py[line:272] - INFO: epoch 005:    941 / 2637 loss=2.229, loss_v1=0, loss_v2=0, nll_loss=1.014, ntokens=1255.5, nsentences=160, sample_size=1255.5, sample_size_v1=0, sample_size_v2=0, ppl=2.02, wps=601.5, ups=0.48, wpb=1255.5, bsz=160, num_updates=11470, lr=2.32384e-05, gnorm=4.944, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=23977
2023-06-27 08:53:18 - progress_bar.py[line:272] - INFO: epoch 005:    951 / 2637 loss=2.24, loss_v1=0, loss_v2=0, nll_loss=1.026, ntokens=1242.7, nsentences=160, sample_size=1242.7, sample_size_v1=0, sample_size_v2=0, ppl=2.04, wps=595.4, ups=0.48, wpb=1242.7, bsz=160, num_updates=11480, lr=2.32309e-05, gnorm=4.65, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=23998
2023-06-27 08:53:39 - progress_bar.py[line:272] - INFO: epoch 005:    961 / 2637 loss=2.235, loss_v1=0, loss_v2=0, nll_loss=1.024, ntokens=1248.4, nsentences=160, sample_size=1248.4, sample_size_v1=0, sample_size_v2=0, ppl=2.03, wps=598.4, ups=0.48, wpb=1248.4, bsz=160, num_updates=11490, lr=2.32233e-05, gnorm=5.031, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=24019
2023-06-27 08:54:00 - progress_bar.py[line:272] - INFO: epoch 005:    971 / 2637 loss=2.194, loss_v1=0, loss_v2=0, nll_loss=0.976, ntokens=1236.8, nsentences=160, sample_size=1236.8, sample_size_v1=0, sample_size_v2=0, ppl=1.97, wps=590.8, ups=0.48, wpb=1236.8, bsz=160, num_updates=11500, lr=2.32158e-05, gnorm=4.59, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=24040
2023-06-27 08:54:20 - progress_bar.py[line:272] - INFO: epoch 005:    981 / 2637 loss=2.222, loss_v1=0, loss_v2=0, nll_loss=1.005, ntokens=1247.4, nsentences=160, sample_size=1247.4, sample_size_v1=0, sample_size_v2=0, ppl=2.01, wps=598.1, ups=0.48, wpb=1247.4, bsz=160, num_updates=11510, lr=2.32082e-05, gnorm=4.584, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=24061
2023-06-27 08:54:41 - progress_bar.py[line:272] - INFO: epoch 005:    991 / 2637 loss=2.204, loss_v1=0, loss_v2=0, nll_loss=0.987, ntokens=1241.4, nsentences=160, sample_size=1241.4, sample_size_v1=0, sample_size_v2=0, ppl=1.98, wps=595.1, ups=0.48, wpb=1241.4, bsz=160, num_updates=11520, lr=2.32006e-05, gnorm=4.448, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=24082
2023-06-27 08:55:02 - progress_bar.py[line:272] - INFO: epoch 005:   1001 / 2637 loss=2.209, loss_v1=0, loss_v2=0, nll_loss=0.992, ntokens=1245.6, nsentences=160, sample_size=1245.6, sample_size_v1=0, sample_size_v2=0, ppl=1.99, wps=597.4, ups=0.48, wpb=1245.6, bsz=160, num_updates=11530, lr=2.31931e-05, gnorm=5.075, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=24102
2023-06-27 08:55:23 - progress_bar.py[line:272] - INFO: epoch 005:   1011 / 2637 loss=2.197, loss_v1=0, loss_v2=0, nll_loss=0.981, ntokens=1241.3, nsentences=160, sample_size=1241.3, sample_size_v1=0, sample_size_v2=0, ppl=1.97, wps=595.6, ups=0.48, wpb=1241.3, bsz=160, num_updates=11540, lr=2.31855e-05, gnorm=5.552, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=24123
2023-06-27 08:55:44 - progress_bar.py[line:272] - INFO: epoch 005:   1021 / 2637 loss=2.198, loss_v1=0, loss_v2=0, nll_loss=0.979, ntokens=1246.4, nsentences=160, sample_size=1246.4, sample_size_v1=0, sample_size_v2=0, ppl=1.97, wps=597.7, ups=0.48, wpb=1246.4, bsz=160, num_updates=11550, lr=2.31779e-05, gnorm=4.872, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=24144
2023-06-27 08:56:05 - progress_bar.py[line:272] - INFO: epoch 005:   1031 / 2637 loss=2.203, loss_v1=0, loss_v2=0, nll_loss=0.985, ntokens=1254.7, nsentences=160, sample_size=1254.7, sample_size_v1=0, sample_size_v2=0, ppl=1.98, wps=601.7, ups=0.48, wpb=1254.7, bsz=160, num_updates=11560, lr=2.31704e-05, gnorm=4.747, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=24165
2023-06-27 08:56:26 - progress_bar.py[line:272] - INFO: epoch 005:   1041 / 2637 loss=2.214, loss_v1=0, loss_v2=0, nll_loss=0.997, ntokens=1239.6, nsentences=160, sample_size=1239.6, sample_size_v1=0, sample_size_v2=0, ppl=2, wps=594.6, ups=0.48, wpb=1239.6, bsz=160, num_updates=11570, lr=2.31628e-05, gnorm=4.839, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=24186
2023-06-27 08:56:46 - progress_bar.py[line:272] - INFO: epoch 005:   1051 / 2637 loss=2.193, loss_v1=0, loss_v2=0, nll_loss=0.976, ntokens=1269.4, nsentences=160, sample_size=1269.4, sample_size_v1=0, sample_size_v2=0, ppl=1.97, wps=608.6, ups=0.48, wpb=1269.4, bsz=160, num_updates=11580, lr=2.31552e-05, gnorm=5.285, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=24207
2023-06-27 08:57:07 - progress_bar.py[line:272] - INFO: epoch 005:   1061 / 2637 loss=2.223, loss_v1=0, loss_v2=0, nll_loss=1.008, ntokens=1243.7, nsentences=160, sample_size=1243.7, sample_size_v1=0, sample_size_v2=0, ppl=2.01, wps=596.3, ups=0.48, wpb=1243.7, bsz=160, num_updates=11590, lr=2.31477e-05, gnorm=4.736, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=24228
2023-06-27 08:57:28 - progress_bar.py[line:272] - INFO: epoch 005:   1071 / 2637 loss=2.203, loss_v1=0, loss_v2=0, nll_loss=0.985, ntokens=1231.8, nsentences=160, sample_size=1231.8, sample_size_v1=0, sample_size_v2=0, ppl=1.98, wps=591, ups=0.48, wpb=1231.8, bsz=160, num_updates=11600, lr=2.31401e-05, gnorm=4.571, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=24248
2023-06-27 08:57:49 - progress_bar.py[line:272] - INFO: epoch 005:   1081 / 2637 loss=2.207, loss_v1=0, loss_v2=0, nll_loss=0.989, ntokens=1236.5, nsentences=160, sample_size=1236.5, sample_size_v1=0, sample_size_v2=0, ppl=1.99, wps=593.9, ups=0.48, wpb=1236.5, bsz=160, num_updates=11610, lr=2.31325e-05, gnorm=4.503, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=24269
2023-06-27 08:58:10 - progress_bar.py[line:272] - INFO: epoch 005:   1091 / 2637 loss=2.211, loss_v1=0, loss_v2=0, nll_loss=0.996, ntokens=1270.9, nsentences=160, sample_size=1270.9, sample_size_v1=0, sample_size_v2=0, ppl=1.99, wps=610.2, ups=0.48, wpb=1270.9, bsz=160, num_updates=11620, lr=2.3125e-05, gnorm=4.748, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=24290
2023-06-27 08:58:31 - progress_bar.py[line:272] - INFO: epoch 005:   1101 / 2637 loss=2.192, loss_v1=0, loss_v2=0, nll_loss=0.974, ntokens=1234.7, nsentences=160, sample_size=1234.7, sample_size_v1=0, sample_size_v2=0, ppl=1.96, wps=592.2, ups=0.48, wpb=1234.7, bsz=160, num_updates=11630, lr=2.31174e-05, gnorm=4.738, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=24311
2023-06-27 08:58:51 - progress_bar.py[line:272] - INFO: epoch 005:   1111 / 2637 loss=2.218, loss_v1=0, loss_v2=0, nll_loss=1.001, ntokens=1232.4, nsentences=160, sample_size=1232.4, sample_size_v1=0, sample_size_v2=0, ppl=2, wps=590.9, ups=0.48, wpb=1232.4, bsz=160, num_updates=11640, lr=2.31099e-05, gnorm=4.712, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=24332
2023-06-27 08:59:12 - progress_bar.py[line:272] - INFO: epoch 005:   1121 / 2637 loss=2.207, loss_v1=0, loss_v2=0, nll_loss=0.988, ntokens=1236.8, nsentences=160, sample_size=1236.8, sample_size_v1=0, sample_size_v2=0, ppl=1.98, wps=593.4, ups=0.48, wpb=1236.8, bsz=160, num_updates=11650, lr=2.31023e-05, gnorm=4.842, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=24353
2023-06-27 08:59:33 - progress_bar.py[line:272] - INFO: epoch 005:   1131 / 2637 loss=2.207, loss_v1=0, loss_v2=0, nll_loss=0.99, ntokens=1241.8, nsentences=160, sample_size=1241.8, sample_size_v1=0, sample_size_v2=0, ppl=1.99, wps=595.6, ups=0.48, wpb=1241.8, bsz=160, num_updates=11660, lr=2.30947e-05, gnorm=4.969, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=24373
2023-06-27 08:59:54 - progress_bar.py[line:272] - INFO: epoch 005:   1141 / 2637 loss=2.193, loss_v1=0, loss_v2=0, nll_loss=0.975, ntokens=1264.9, nsentences=160, sample_size=1264.9, sample_size_v1=0, sample_size_v2=0, ppl=1.97, wps=607.1, ups=0.48, wpb=1264.9, bsz=160, num_updates=11670, lr=2.30872e-05, gnorm=5.336, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=24394
2023-06-27 09:00:15 - progress_bar.py[line:272] - INFO: epoch 005:   1151 / 2637 loss=2.222, loss_v1=0, loss_v2=0, nll_loss=1.007, ntokens=1258.4, nsentences=160, sample_size=1258.4, sample_size_v1=0, sample_size_v2=0, ppl=2.01, wps=603.5, ups=0.48, wpb=1258.4, bsz=160, num_updates=11680, lr=2.30796e-05, gnorm=4.536, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=24415
2023-06-27 09:00:36 - progress_bar.py[line:272] - INFO: epoch 005:   1161 / 2637 loss=2.217, loss_v1=0, loss_v2=0, nll_loss=1, ntokens=1242.4, nsentences=160, sample_size=1242.4, sample_size_v1=0, sample_size_v2=0, ppl=2, wps=596.4, ups=0.48, wpb=1242.4, bsz=160, num_updates=11690, lr=2.3072e-05, gnorm=4.81, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=24436
2023-06-27 09:00:57 - progress_bar.py[line:272] - INFO: epoch 005:   1171 / 2637 loss=2.191, loss_v1=0, loss_v2=0, nll_loss=0.974, ntokens=1243.1, nsentences=160, sample_size=1243.1, sample_size_v1=0, sample_size_v2=0, ppl=1.96, wps=596.5, ups=0.48, wpb=1243.1, bsz=160, num_updates=11700, lr=2.30645e-05, gnorm=4.824, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=24457
2023-06-27 09:01:17 - progress_bar.py[line:272] - INFO: epoch 005:   1181 / 2637 loss=2.201, loss_v1=0, loss_v2=0, nll_loss=0.983, ntokens=1253.2, nsentences=160, sample_size=1253.2, sample_size_v1=0, sample_size_v2=0, ppl=1.98, wps=601.1, ups=0.48, wpb=1253.2, bsz=160, num_updates=11710, lr=2.30569e-05, gnorm=5.356, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=24478
2023-06-27 09:01:38 - progress_bar.py[line:272] - INFO: epoch 005:   1191 / 2637 loss=2.201, loss_v1=0, loss_v2=0, nll_loss=0.984, ntokens=1253.2, nsentences=160, sample_size=1253.2, sample_size_v1=0, sample_size_v2=0, ppl=1.98, wps=601.4, ups=0.48, wpb=1253.2, bsz=160, num_updates=11720, lr=2.30493e-05, gnorm=4.714, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=24499
2023-06-27 09:01:59 - progress_bar.py[line:272] - INFO: epoch 005:   1201 / 2637 loss=2.213, loss_v1=0, loss_v2=0, nll_loss=0.998, ntokens=1259.1, nsentences=160, sample_size=1259.1, sample_size_v1=0, sample_size_v2=0, ppl=2, wps=604.9, ups=0.48, wpb=1259.1, bsz=160, num_updates=11730, lr=2.30418e-05, gnorm=5.168, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=24519
2023-06-27 09:02:20 - progress_bar.py[line:272] - INFO: epoch 005:   1211 / 2637 loss=2.21, loss_v1=0, loss_v2=0, nll_loss=0.995, ntokens=1247.9, nsentences=160, sample_size=1247.9, sample_size_v1=0, sample_size_v2=0, ppl=1.99, wps=599.7, ups=0.48, wpb=1247.9, bsz=160, num_updates=11740, lr=2.30342e-05, gnorm=5.292, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=24540
2023-06-27 09:02:41 - progress_bar.py[line:272] - INFO: epoch 005:   1221 / 2637 loss=2.195, loss_v1=0, loss_v2=0, nll_loss=0.975, ntokens=1264.1, nsentences=160, sample_size=1264.1, sample_size_v1=0, sample_size_v2=0, ppl=1.97, wps=607.3, ups=0.48, wpb=1264.1, bsz=160, num_updates=11750, lr=2.30267e-05, gnorm=5.184, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=24561
2023-06-27 09:03:01 - progress_bar.py[line:272] - INFO: epoch 005:   1231 / 2637 loss=2.216, loss_v1=0, loss_v2=0, nll_loss=1, ntokens=1222.6, nsentences=160, sample_size=1222.6, sample_size_v1=0, sample_size_v2=0, ppl=2, wps=587.7, ups=0.48, wpb=1222.6, bsz=160, num_updates=11760, lr=2.30191e-05, gnorm=4.722, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=24582
2023-06-27 09:03:22 - progress_bar.py[line:272] - INFO: epoch 005:   1241 / 2637 loss=2.22, loss_v1=0, loss_v2=0, nll_loss=1.003, ntokens=1240.8, nsentences=160, sample_size=1240.8, sample_size_v1=0, sample_size_v2=0, ppl=2, wps=596.3, ups=0.48, wpb=1240.8, bsz=160, num_updates=11770, lr=2.30115e-05, gnorm=5.273, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=24603
2023-06-27 09:03:43 - progress_bar.py[line:272] - INFO: epoch 005:   1251 / 2637 loss=2.194, loss_v1=0, loss_v2=0, nll_loss=0.977, ntokens=1240.9, nsentences=160, sample_size=1240.9, sample_size_v1=0, sample_size_v2=0, ppl=1.97, wps=596.5, ups=0.48, wpb=1240.9, bsz=160, num_updates=11780, lr=2.3004e-05, gnorm=5.128, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=24623
2023-06-27 09:04:04 - progress_bar.py[line:272] - INFO: epoch 005:   1261 / 2637 loss=2.213, loss_v1=0, loss_v2=0, nll_loss=0.998, ntokens=1233.3, nsentences=160, sample_size=1233.3, sample_size_v1=0, sample_size_v2=0, ppl=2, wps=592.5, ups=0.48, wpb=1233.3, bsz=160, num_updates=11790, lr=2.29964e-05, gnorm=4.683, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=24644
2023-06-27 09:04:25 - progress_bar.py[line:272] - INFO: epoch 005:   1271 / 2637 loss=2.193, loss_v1=0, loss_v2=0, nll_loss=0.975, ntokens=1268, nsentences=160, sample_size=1268, sample_size_v1=0, sample_size_v2=0, ppl=1.97, wps=609.6, ups=0.48, wpb=1268, bsz=160, num_updates=11800, lr=2.29888e-05, gnorm=4.407, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=24665
2023-06-27 09:04:46 - progress_bar.py[line:272] - INFO: epoch 005:   1281 / 2637 loss=2.218, loss_v1=0, loss_v2=0, nll_loss=1, ntokens=1231.8, nsentences=160, sample_size=1231.8, sample_size_v1=0, sample_size_v2=0, ppl=2, wps=592.3, ups=0.48, wpb=1231.8, bsz=160, num_updates=11810, lr=2.29813e-05, gnorm=5.041, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=24686
2023-06-27 09:05:06 - progress_bar.py[line:272] - INFO: epoch 005:   1291 / 2637 loss=2.21, loss_v1=0, loss_v2=0, nll_loss=0.994, ntokens=1257.3, nsentences=160, sample_size=1257.3, sample_size_v1=0, sample_size_v2=0, ppl=1.99, wps=604.2, ups=0.48, wpb=1257.3, bsz=160, num_updates=11820, lr=2.29737e-05, gnorm=4.662, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=24707
2023-06-27 09:05:27 - progress_bar.py[line:272] - INFO: epoch 005:   1301 / 2637 loss=2.203, loss_v1=0, loss_v2=0, nll_loss=0.985, ntokens=1243.9, nsentences=160, sample_size=1243.9, sample_size_v1=0, sample_size_v2=0, ppl=1.98, wps=597.8, ups=0.48, wpb=1243.9, bsz=160, num_updates=11830, lr=2.29661e-05, gnorm=5.17, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=24727
2023-06-27 09:05:48 - progress_bar.py[line:272] - INFO: epoch 005:   1311 / 2637 loss=2.193, loss_v1=0, loss_v2=0, nll_loss=0.975, ntokens=1237, nsentences=160, sample_size=1237, sample_size_v1=0, sample_size_v2=0, ppl=1.97, wps=594.4, ups=0.48, wpb=1237, bsz=160, num_updates=11840, lr=2.29586e-05, gnorm=4.809, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=24748
2023-06-27 09:06:09 - progress_bar.py[line:272] - INFO: epoch 005:   1321 / 2637 loss=2.212, loss_v1=0, loss_v2=0, nll_loss=0.993, ntokens=1239.4, nsentences=160, sample_size=1239.4, sample_size_v1=0, sample_size_v2=0, ppl=1.99, wps=595.5, ups=0.48, wpb=1239.4, bsz=160, num_updates=11850, lr=2.2951e-05, gnorm=5.293, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=24769
2023-06-27 09:06:30 - progress_bar.py[line:272] - INFO: epoch 005:   1331 / 2637 loss=2.206, loss_v1=0, loss_v2=0, nll_loss=0.989, ntokens=1230.8, nsentences=160, sample_size=1230.8, sample_size_v1=0, sample_size_v2=0, ppl=1.99, wps=591.3, ups=0.48, wpb=1230.8, bsz=160, num_updates=11860, lr=2.29434e-05, gnorm=5.049, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=24790
2023-06-27 09:06:50 - progress_bar.py[line:272] - INFO: epoch 005:   1341 / 2637 loss=2.207, loss_v1=0, loss_v2=0, nll_loss=0.989, ntokens=1230.8, nsentences=160, sample_size=1230.8, sample_size_v1=0, sample_size_v2=0, ppl=1.98, wps=590.2, ups=0.48, wpb=1230.8, bsz=160, num_updates=11870, lr=2.29359e-05, gnorm=5.706, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=24811
2023-06-27 09:07:11 - progress_bar.py[line:272] - INFO: epoch 005:   1351 / 2637 loss=2.212, loss_v1=0, loss_v2=0, nll_loss=0.996, ntokens=1235.4, nsentences=160, sample_size=1235.4, sample_size_v1=0, sample_size_v2=0, ppl=1.99, wps=592.2, ups=0.48, wpb=1235.4, bsz=160, num_updates=11880, lr=2.29283e-05, gnorm=5.021, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=24832
2023-06-27 09:07:32 - progress_bar.py[line:272] - INFO: epoch 005:   1361 / 2637 loss=2.222, loss_v1=0, loss_v2=0, nll_loss=1.005, ntokens=1232.5, nsentences=160, sample_size=1232.5, sample_size_v1=0, sample_size_v2=0, ppl=2.01, wps=591, ups=0.48, wpb=1232.5, bsz=160, num_updates=11890, lr=2.29208e-05, gnorm=4.997, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=24852
2023-06-27 09:07:53 - progress_bar.py[line:272] - INFO: epoch 005:   1371 / 2637 loss=2.232, loss_v1=0, loss_v2=0, nll_loss=1.02, ntokens=1235.3, nsentences=160, sample_size=1235.3, sample_size_v1=0, sample_size_v2=0, ppl=2.03, wps=592.6, ups=0.48, wpb=1235.3, bsz=160, num_updates=11900, lr=2.29132e-05, gnorm=5.628, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=24873
2023-06-27 09:08:14 - progress_bar.py[line:272] - INFO: epoch 005:   1381 / 2637 loss=2.212, loss_v1=0, loss_v2=0, nll_loss=0.996, ntokens=1239.3, nsentences=160, sample_size=1239.3, sample_size_v1=0, sample_size_v2=0, ppl=1.99, wps=594.3, ups=0.48, wpb=1239.3, bsz=160, num_updates=11910, lr=2.29056e-05, gnorm=5.156, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=24894
2023-06-27 09:08:35 - progress_bar.py[line:272] - INFO: epoch 005:   1391 / 2637 loss=2.202, loss_v1=0, loss_v2=0, nll_loss=0.985, ntokens=1271.8, nsentences=160, sample_size=1271.8, sample_size_v1=0, sample_size_v2=0, ppl=1.98, wps=609.1, ups=0.48, wpb=1271.8, bsz=160, num_updates=11920, lr=2.28981e-05, gnorm=4.694, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=24915
2023-06-27 09:08:56 - progress_bar.py[line:272] - INFO: epoch 005:   1401 / 2637 loss=2.201, loss_v1=0, loss_v2=0, nll_loss=0.983, ntokens=1276.5, nsentences=160, sample_size=1276.5, sample_size_v1=0, sample_size_v2=0, ppl=1.98, wps=611.6, ups=0.48, wpb=1276.5, bsz=160, num_updates=11930, lr=2.28905e-05, gnorm=4.803, clip=100, loss_scale=128, train_wall=21, gb_free=8.9, wall=24936
2023-06-27 09:09:17 - progress_bar.py[line:272] - INFO: epoch 005:   1411 / 2637 loss=2.221, loss_v1=0, loss_v2=0, nll_loss=1.004, ntokens=1270.6, nsentences=160, sample_size=1270.6, sample_size_v1=0, sample_size_v2=0, ppl=2.01, wps=608.9, ups=0.48, wpb=1270.6, bsz=160, num_updates=11940, lr=2.28829e-05, gnorm=4.55, clip=100, loss_scale=128, train_wall=21, gb_free=8.9, wall=24957
2023-06-27 09:09:37 - progress_bar.py[line:272] - INFO: epoch 005:   1421 / 2637 loss=2.216, loss_v1=0, loss_v2=0, nll_loss=0.999, ntokens=1273.7, nsentences=160, sample_size=1273.7, sample_size_v1=0, sample_size_v2=0, ppl=2, wps=610.4, ups=0.48, wpb=1273.7, bsz=160, num_updates=11950, lr=2.28754e-05, gnorm=4.843, clip=100, loss_scale=128, train_wall=21, gb_free=8.9, wall=24978
2023-06-27 09:09:58 - progress_bar.py[line:272] - INFO: epoch 005:   1431 / 2637 loss=2.191, loss_v1=0, loss_v2=0, nll_loss=0.973, ntokens=1272.8, nsentences=160, sample_size=1272.8, sample_size_v1=0, sample_size_v2=0, ppl=1.96, wps=609.8, ups=0.48, wpb=1272.8, bsz=160, num_updates=11960, lr=2.28678e-05, gnorm=4.526, clip=100, loss_scale=128, train_wall=21, gb_free=8.9, wall=24999
2023-06-27 09:10:19 - progress_bar.py[line:272] - INFO: epoch 005:   1441 / 2637 loss=2.201, loss_v1=0, loss_v2=0, nll_loss=0.984, ntokens=1280.3, nsentences=160, sample_size=1280.3, sample_size_v1=0, sample_size_v2=0, ppl=1.98, wps=613.3, ups=0.48, wpb=1280.3, bsz=160, num_updates=11970, lr=2.28602e-05, gnorm=4.315, clip=100, loss_scale=128, train_wall=21, gb_free=8.9, wall=25019
2023-06-27 09:10:40 - progress_bar.py[line:272] - INFO: epoch 005:   1451 / 2637 loss=2.224, loss_v1=0, loss_v2=0, nll_loss=1.007, ntokens=1287.3, nsentences=160, sample_size=1287.3, sample_size_v1=0, sample_size_v2=0, ppl=2.01, wps=617, ups=0.48, wpb=1287.3, bsz=160, num_updates=11980, lr=2.28527e-05, gnorm=4.733, clip=100, loss_scale=128, train_wall=21, gb_free=8.9, wall=25040
2023-06-27 09:11:01 - progress_bar.py[line:272] - INFO: epoch 005:   1461 / 2637 loss=2.219, loss_v1=0, loss_v2=0, nll_loss=1.003, ntokens=1286.3, nsentences=160, sample_size=1286.3, sample_size_v1=0, sample_size_v2=0, ppl=2, wps=614.6, ups=0.48, wpb=1286.3, bsz=160, num_updates=11990, lr=2.28451e-05, gnorm=4.297, clip=100, loss_scale=128, train_wall=21, gb_free=8.9, wall=25061
2023-06-27 09:11:22 - progress_bar.py[line:272] - INFO: epoch 005:   1471 / 2637 loss=2.215, loss_v1=0, loss_v2=0, nll_loss=1, ntokens=1253.2, nsentences=160, sample_size=1253.2, sample_size_v1=0, sample_size_v2=0, ppl=2, wps=600.3, ups=0.48, wpb=1253.2, bsz=160, num_updates=12000, lr=2.28375e-05, gnorm=4.661, clip=100, loss_scale=128, train_wall=21, gb_free=8.9, wall=25082
2023-06-27 09:11:43 - progress_bar.py[line:272] - INFO: epoch 005:   1481 / 2637 loss=2.21, loss_v1=0, loss_v2=0, nll_loss=0.994, ntokens=1272.2, nsentences=160, sample_size=1272.2, sample_size_v1=0, sample_size_v2=0, ppl=1.99, wps=609.2, ups=0.48, wpb=1272.2, bsz=160, num_updates=12010, lr=2.283e-05, gnorm=5.036, clip=100, loss_scale=128, train_wall=21, gb_free=8.9, wall=25103
2023-06-27 09:12:04 - progress_bar.py[line:272] - INFO: epoch 005:   1491 / 2637 loss=2.22, loss_v1=0, loss_v2=0, nll_loss=1.006, ntokens=1287.7, nsentences=160, sample_size=1287.7, sample_size_v1=0, sample_size_v2=0, ppl=2.01, wps=616.5, ups=0.48, wpb=1287.7, bsz=160, num_updates=12020, lr=2.28224e-05, gnorm=4.534, clip=100, loss_scale=128, train_wall=21, gb_free=8.9, wall=25124
2023-06-27 09:12:24 - progress_bar.py[line:272] - INFO: epoch 005:   1501 / 2637 loss=2.211, loss_v1=0, loss_v2=0, nll_loss=0.995, ntokens=1282.7, nsentences=160, sample_size=1282.7, sample_size_v1=0, sample_size_v2=0, ppl=1.99, wps=615.2, ups=0.48, wpb=1282.7, bsz=160, num_updates=12030, lr=2.28149e-05, gnorm=4.672, clip=100, loss_scale=128, train_wall=21, gb_free=8.9, wall=25145
2023-06-27 09:12:45 - progress_bar.py[line:272] - INFO: epoch 005:   1511 / 2637 loss=2.217, loss_v1=0, loss_v2=0, nll_loss=1.002, ntokens=1283.7, nsentences=160, sample_size=1283.7, sample_size_v1=0, sample_size_v2=0, ppl=2, wps=616.3, ups=0.48, wpb=1283.7, bsz=160, num_updates=12040, lr=2.28073e-05, gnorm=5.128, clip=100, loss_scale=128, train_wall=21, gb_free=8.9, wall=25166
2023-06-27 09:13:06 - progress_bar.py[line:272] - INFO: epoch 005:   1521 / 2637 loss=2.235, loss_v1=0, loss_v2=0, nll_loss=1.02, ntokens=1262.4, nsentences=160, sample_size=1262.4, sample_size_v1=0, sample_size_v2=0, ppl=2.03, wps=606.1, ups=0.48, wpb=1262.4, bsz=160, num_updates=12050, lr=2.27997e-05, gnorm=5, clip=100, loss_scale=128, train_wall=21, gb_free=8.9, wall=25186
2023-06-27 09:13:27 - progress_bar.py[line:272] - INFO: epoch 005:   1531 / 2637 loss=2.224, loss_v1=0, loss_v2=0, nll_loss=1.007, ntokens=1254.7, nsentences=160, sample_size=1254.7, sample_size_v1=0, sample_size_v2=0, ppl=2.01, wps=601.7, ups=0.48, wpb=1254.7, bsz=160, num_updates=12060, lr=2.27922e-05, gnorm=5.515, clip=100, loss_scale=128, train_wall=21, gb_free=8.9, wall=25207
2023-06-27 09:13:48 - progress_bar.py[line:272] - INFO: epoch 005:   1541 / 2637 loss=2.237, loss_v1=0, loss_v2=0, nll_loss=1.025, ntokens=1266.8, nsentences=160, sample_size=1266.8, sample_size_v1=0, sample_size_v2=0, ppl=2.04, wps=607.6, ups=0.48, wpb=1266.8, bsz=160, num_updates=12070, lr=2.27846e-05, gnorm=4.521, clip=100, loss_scale=128, train_wall=21, gb_free=8.9, wall=25228
2023-06-27 09:14:09 - progress_bar.py[line:272] - INFO: epoch 005:   1551 / 2637 loss=2.23, loss_v1=0, loss_v2=0, nll_loss=1.016, ntokens=1277.2, nsentences=160, sample_size=1277.2, sample_size_v1=0, sample_size_v2=0, ppl=2.02, wps=613.1, ups=0.48, wpb=1277.2, bsz=160, num_updates=12080, lr=2.2777e-05, gnorm=4.18, clip=100, loss_scale=128, train_wall=21, gb_free=8.9, wall=25249
2023-06-27 09:14:29 - progress_bar.py[line:272] - INFO: epoch 005:   1561 / 2637 loss=2.209, loss_v1=0, loss_v2=0, nll_loss=0.993, ntokens=1276.8, nsentences=160, sample_size=1276.8, sample_size_v1=0, sample_size_v2=0, ppl=1.99, wps=612.6, ups=0.48, wpb=1276.8, bsz=160, num_updates=12090, lr=2.27695e-05, gnorm=4.447, clip=100, loss_scale=128, train_wall=21, gb_free=8.9, wall=25270
2023-06-27 09:14:50 - progress_bar.py[line:272] - INFO: epoch 005:   1571 / 2637 loss=2.213, loss_v1=0, loss_v2=0, nll_loss=0.995, ntokens=1256, nsentences=160, sample_size=1256, sample_size_v1=0, sample_size_v2=0, ppl=1.99, wps=603.2, ups=0.48, wpb=1256, bsz=160, num_updates=12100, lr=2.27619e-05, gnorm=4.571, clip=100, loss_scale=128, train_wall=21, gb_free=8.9, wall=25291
2023-06-27 09:15:05 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2023-06-27 09:15:13 - progress_bar.py[line:272] - INFO: epoch 005:   1582 / 2637 loss=2.232, loss_v1=0, loss_v2=0, nll_loss=1.017, ntokens=1272.4, nsentences=160, sample_size=1272.4, sample_size_v1=0, sample_size_v2=0, ppl=2.02, wps=555, ups=0.44, wpb=1272.4, bsz=160, num_updates=12110, lr=2.27543e-05, gnorm=4.778, clip=100, loss_scale=64, train_wall=23, gb_free=8.9, wall=25314
2023-06-27 09:15:34 - progress_bar.py[line:272] - INFO: epoch 005:   1592 / 2637 loss=2.21, loss_v1=0, loss_v2=0, nll_loss=0.994, ntokens=1269.4, nsentences=160, sample_size=1269.4, sample_size_v1=0, sample_size_v2=0, ppl=1.99, wps=608.1, ups=0.48, wpb=1269.4, bsz=160, num_updates=12120, lr=2.27468e-05, gnorm=4.863, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=25334
2023-06-27 09:15:55 - progress_bar.py[line:272] - INFO: epoch 005:   1602 / 2637 loss=2.22, loss_v1=0, loss_v2=0, nll_loss=1.006, ntokens=1269.3, nsentences=160, sample_size=1269.3, sample_size_v1=0, sample_size_v2=0, ppl=2.01, wps=607.9, ups=0.48, wpb=1269.3, bsz=160, num_updates=12130, lr=2.27392e-05, gnorm=5.306, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=25355
2023-06-27 09:16:16 - progress_bar.py[line:272] - INFO: epoch 005:   1612 / 2637 loss=2.232, loss_v1=0, loss_v2=0, nll_loss=1.019, ntokens=1266.8, nsentences=160, sample_size=1266.8, sample_size_v1=0, sample_size_v2=0, ppl=2.03, wps=606.1, ups=0.48, wpb=1266.8, bsz=160, num_updates=12140, lr=2.27317e-05, gnorm=4.516, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=25376
2023-06-27 09:16:37 - progress_bar.py[line:272] - INFO: epoch 005:   1622 / 2637 loss=2.248, loss_v1=0, loss_v2=0, nll_loss=1.036, ntokens=1257.3, nsentences=160, sample_size=1257.3, sample_size_v1=0, sample_size_v2=0, ppl=2.05, wps=602.9, ups=0.48, wpb=1257.3, bsz=160, num_updates=12150, lr=2.27241e-05, gnorm=4.662, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=25397
2023-06-27 09:16:58 - progress_bar.py[line:272] - INFO: epoch 005:   1632 / 2637 loss=2.2, loss_v1=0, loss_v2=0, nll_loss=0.982, ntokens=1263.4, nsentences=160, sample_size=1263.4, sample_size_v1=0, sample_size_v2=0, ppl=1.97, wps=605.1, ups=0.48, wpb=1263.4, bsz=160, num_updates=12160, lr=2.27165e-05, gnorm=4.44, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=25418
2023-06-27 09:17:19 - progress_bar.py[line:272] - INFO: epoch 005:   1642 / 2637 loss=2.217, loss_v1=0, loss_v2=0, nll_loss=1.002, ntokens=1268.3, nsentences=160, sample_size=1268.3, sample_size_v1=0, sample_size_v2=0, ppl=2, wps=608.3, ups=0.48, wpb=1268.3, bsz=160, num_updates=12170, lr=2.2709e-05, gnorm=4.491, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=25439
2023-06-27 09:17:39 - progress_bar.py[line:272] - INFO: epoch 005:   1652 / 2637 loss=2.214, loss_v1=0, loss_v2=0, nll_loss=0.998, ntokens=1259.8, nsentences=160, sample_size=1259.8, sample_size_v1=0, sample_size_v2=0, ppl=2, wps=604.6, ups=0.48, wpb=1259.8, bsz=160, num_updates=12180, lr=2.27014e-05, gnorm=4.369, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=25460
2023-06-27 09:18:00 - progress_bar.py[line:272] - INFO: epoch 005:   1662 / 2637 loss=2.23, loss_v1=0, loss_v2=0, nll_loss=1.015, ntokens=1271.4, nsentences=160, sample_size=1271.4, sample_size_v1=0, sample_size_v2=0, ppl=2.02, wps=609.3, ups=0.48, wpb=1271.4, bsz=160, num_updates=12190, lr=2.26938e-05, gnorm=4.829, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=25480
2023-06-27 09:18:21 - progress_bar.py[line:272] - INFO: epoch 005:   1672 / 2637 loss=2.213, loss_v1=0, loss_v2=0, nll_loss=0.996, ntokens=1253.5, nsentences=160, sample_size=1253.5, sample_size_v1=0, sample_size_v2=0, ppl=1.99, wps=599.8, ups=0.48, wpb=1253.5, bsz=160, num_updates=12200, lr=2.26863e-05, gnorm=4.721, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=25501
2023-06-27 09:18:42 - progress_bar.py[line:272] - INFO: epoch 005:   1682 / 2637 loss=2.203, loss_v1=0, loss_v2=0, nll_loss=0.987, ntokens=1266.8, nsentences=160, sample_size=1266.8, sample_size_v1=0, sample_size_v2=0, ppl=1.98, wps=606.5, ups=0.48, wpb=1266.8, bsz=160, num_updates=12210, lr=2.26787e-05, gnorm=4.98, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=25522
2023-06-27 09:19:03 - progress_bar.py[line:272] - INFO: epoch 005:   1692 / 2637 loss=2.2, loss_v1=0, loss_v2=0, nll_loss=0.983, ntokens=1288.3, nsentences=160, sample_size=1288.3, sample_size_v1=0, sample_size_v2=0, ppl=1.98, wps=617.1, ups=0.48, wpb=1288.3, bsz=160, num_updates=12220, lr=2.26711e-05, gnorm=5.303, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=25543
2023-06-27 09:19:24 - progress_bar.py[line:272] - INFO: epoch 005:   1702 / 2637 loss=2.211, loss_v1=0, loss_v2=0, nll_loss=0.994, ntokens=1278.9, nsentences=160, sample_size=1278.9, sample_size_v1=0, sample_size_v2=0, ppl=1.99, wps=612.3, ups=0.48, wpb=1278.9, bsz=160, num_updates=12230, lr=2.26636e-05, gnorm=4.984, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=25564
2023-06-27 09:19:45 - progress_bar.py[line:272] - INFO: epoch 005:   1712 / 2637 loss=2.217, loss_v1=0, loss_v2=0, nll_loss=1.002, ntokens=1277.5, nsentences=160, sample_size=1277.5, sample_size_v1=0, sample_size_v2=0, ppl=2, wps=611.9, ups=0.48, wpb=1277.5, bsz=160, num_updates=12240, lr=2.2656e-05, gnorm=5.093, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=25585
2023-06-27 09:20:06 - progress_bar.py[line:272] - INFO: epoch 005:   1722 / 2637 loss=2.208, loss_v1=0, loss_v2=0, nll_loss=0.993, ntokens=1275.4, nsentences=160, sample_size=1275.4, sample_size_v1=0, sample_size_v2=0, ppl=1.99, wps=610.6, ups=0.48, wpb=1275.4, bsz=160, num_updates=12250, lr=2.26484e-05, gnorm=4.796, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=25606
2023-06-27 09:20:26 - progress_bar.py[line:272] - INFO: epoch 005:   1732 / 2637 loss=2.206, loss_v1=0, loss_v2=0, nll_loss=0.989, ntokens=1263.6, nsentences=160, sample_size=1263.6, sample_size_v1=0, sample_size_v2=0, ppl=1.99, wps=605.6, ups=0.48, wpb=1263.6, bsz=160, num_updates=12260, lr=2.26409e-05, gnorm=5.081, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=25627
2023-06-27 09:20:47 - progress_bar.py[line:272] - INFO: epoch 005:   1742 / 2637 loss=2.194, loss_v1=0, loss_v2=0, nll_loss=0.975, ntokens=1284.7, nsentences=160, sample_size=1284.7, sample_size_v1=0, sample_size_v2=0, ppl=1.97, wps=614.8, ups=0.48, wpb=1284.7, bsz=160, num_updates=12270, lr=2.26333e-05, gnorm=4.241, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=25648
2023-06-27 09:21:08 - progress_bar.py[line:272] - INFO: epoch 005:   1752 / 2637 loss=2.23, loss_v1=0, loss_v2=0, nll_loss=1.015, ntokens=1256.6, nsentences=160, sample_size=1256.6, sample_size_v1=0, sample_size_v2=0, ppl=2.02, wps=602, ups=0.48, wpb=1256.6, bsz=160, num_updates=12280, lr=2.26258e-05, gnorm=5.161, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=25668
2023-06-27 09:21:29 - progress_bar.py[line:272] - INFO: epoch 005:   1762 / 2637 loss=2.188, loss_v1=0, loss_v2=0, nll_loss=0.968, ntokens=1287.3, nsentences=160, sample_size=1287.3, sample_size_v1=0, sample_size_v2=0, ppl=1.96, wps=615.8, ups=0.48, wpb=1287.3, bsz=160, num_updates=12290, lr=2.26182e-05, gnorm=4.104, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=25689
2023-06-27 09:21:50 - progress_bar.py[line:272] - INFO: epoch 005:   1772 / 2637 loss=2.236, loss_v1=0, loss_v2=0, nll_loss=1.023, ntokens=1263.4, nsentences=160, sample_size=1263.4, sample_size_v1=0, sample_size_v2=0, ppl=2.03, wps=605, ups=0.48, wpb=1263.4, bsz=160, num_updates=12300, lr=2.26106e-05, gnorm=4.688, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=25710
2023-06-27 09:22:11 - progress_bar.py[line:272] - INFO: epoch 005:   1782 / 2637 loss=2.209, loss_v1=0, loss_v2=0, nll_loss=0.993, ntokens=1285.7, nsentences=160, sample_size=1285.7, sample_size_v1=0, sample_size_v2=0, ppl=1.99, wps=616.2, ups=0.48, wpb=1285.7, bsz=160, num_updates=12310, lr=2.26031e-05, gnorm=5.648, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=25731
2023-06-27 09:22:32 - progress_bar.py[line:272] - INFO: epoch 005:   1792 / 2637 loss=2.21, loss_v1=0, loss_v2=0, nll_loss=0.993, ntokens=1286.5, nsentences=160, sample_size=1286.5, sample_size_v1=0, sample_size_v2=0, ppl=1.99, wps=615.9, ups=0.48, wpb=1286.5, bsz=160, num_updates=12320, lr=2.25955e-05, gnorm=4.767, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=25752
2023-06-27 09:22:53 - progress_bar.py[line:272] - INFO: epoch 005:   1802 / 2637 loss=2.241, loss_v1=0, loss_v2=0, nll_loss=1.028, ntokens=1266, nsentences=160, sample_size=1266, sample_size_v1=0, sample_size_v2=0, ppl=2.04, wps=606.3, ups=0.48, wpb=1266, bsz=160, num_updates=12330, lr=2.25879e-05, gnorm=5.345, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=25773
2023-06-27 09:23:13 - progress_bar.py[line:272] - INFO: epoch 005:   1812 / 2637 loss=2.189, loss_v1=0, loss_v2=0, nll_loss=0.969, ntokens=1280.7, nsentences=160, sample_size=1280.7, sample_size_v1=0, sample_size_v2=0, ppl=1.96, wps=613.8, ups=0.48, wpb=1280.7, bsz=160, num_updates=12340, lr=2.25804e-05, gnorm=4.838, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=25794
2023-06-27 09:23:34 - progress_bar.py[line:272] - INFO: epoch 005:   1822 / 2637 loss=2.216, loss_v1=0, loss_v2=0, nll_loss=1.001, ntokens=1260.2, nsentences=160, sample_size=1260.2, sample_size_v1=0, sample_size_v2=0, ppl=2, wps=603.7, ups=0.48, wpb=1260.2, bsz=160, num_updates=12350, lr=2.25728e-05, gnorm=5.292, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=25815
2023-06-27 09:23:55 - progress_bar.py[line:272] - INFO: epoch 005:   1832 / 2637 loss=2.196, loss_v1=0, loss_v2=0, nll_loss=0.977, ntokens=1279, nsentences=160, sample_size=1279, sample_size_v1=0, sample_size_v2=0, ppl=1.97, wps=612.4, ups=0.48, wpb=1279, bsz=160, num_updates=12360, lr=2.25652e-05, gnorm=4.745, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=25836
2023-06-27 09:24:16 - progress_bar.py[line:272] - INFO: epoch 005:   1842 / 2637 loss=2.195, loss_v1=0, loss_v2=0, nll_loss=0.977, ntokens=1303, nsentences=160, sample_size=1303, sample_size_v1=0, sample_size_v2=0, ppl=1.97, wps=623.9, ups=0.48, wpb=1303, bsz=160, num_updates=12370, lr=2.25577e-05, gnorm=5.141, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=25856
2023-06-27 09:24:37 - progress_bar.py[line:272] - INFO: epoch 005:   1852 / 2637 loss=2.199, loss_v1=0, loss_v2=0, nll_loss=0.982, ntokens=1263.6, nsentences=160, sample_size=1263.6, sample_size_v1=0, sample_size_v2=0, ppl=1.97, wps=605.2, ups=0.48, wpb=1263.6, bsz=160, num_updates=12380, lr=2.25501e-05, gnorm=5.302, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=25877
2023-06-27 09:24:58 - progress_bar.py[line:272] - INFO: epoch 005:   1862 / 2637 loss=2.212, loss_v1=0, loss_v2=0, nll_loss=0.995, ntokens=1280.1, nsentences=160, sample_size=1280.1, sample_size_v1=0, sample_size_v2=0, ppl=1.99, wps=613.1, ups=0.48, wpb=1280.1, bsz=160, num_updates=12390, lr=2.25425e-05, gnorm=4.774, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=25898
2023-06-27 09:25:19 - progress_bar.py[line:272] - INFO: epoch 005:   1872 / 2637 loss=2.205, loss_v1=0, loss_v2=0, nll_loss=0.988, ntokens=1257.7, nsentences=160, sample_size=1257.7, sample_size_v1=0, sample_size_v2=0, ppl=1.98, wps=602.7, ups=0.48, wpb=1257.7, bsz=160, num_updates=12400, lr=2.2535e-05, gnorm=5.307, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=25919
2023-06-27 09:25:40 - progress_bar.py[line:272] - INFO: epoch 005:   1882 / 2637 loss=2.184, loss_v1=0, loss_v2=0, nll_loss=0.964, ntokens=1290.3, nsentences=160, sample_size=1290.3, sample_size_v1=0, sample_size_v2=0, ppl=1.95, wps=618.3, ups=0.48, wpb=1290.3, bsz=160, num_updates=12410, lr=2.25274e-05, gnorm=4.54, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=25940
2023-06-27 09:26:01 - progress_bar.py[line:272] - INFO: epoch 005:   1892 / 2637 loss=2.195, loss_v1=0, loss_v2=0, nll_loss=0.975, ntokens=1273.7, nsentences=160, sample_size=1273.7, sample_size_v1=0, sample_size_v2=0, ppl=1.97, wps=609.8, ups=0.48, wpb=1273.7, bsz=160, num_updates=12420, lr=2.25199e-05, gnorm=4.641, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=25961
2023-06-27 09:26:21 - progress_bar.py[line:272] - INFO: epoch 005:   1902 / 2637 loss=2.199, loss_v1=0, loss_v2=0, nll_loss=0.983, ntokens=1288.1, nsentences=160, sample_size=1288.1, sample_size_v1=0, sample_size_v2=0, ppl=1.98, wps=616.8, ups=0.48, wpb=1288.1, bsz=160, num_updates=12430, lr=2.25123e-05, gnorm=4.624, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=25982
2023-06-27 09:26:42 - progress_bar.py[line:272] - INFO: epoch 005:   1912 / 2637 loss=2.191, loss_v1=0, loss_v2=0, nll_loss=0.973, ntokens=1258.7, nsentences=160, sample_size=1258.7, sample_size_v1=0, sample_size_v2=0, ppl=1.96, wps=603.6, ups=0.48, wpb=1258.7, bsz=160, num_updates=12440, lr=2.25047e-05, gnorm=5.096, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=26003
2023-06-27 09:27:03 - progress_bar.py[line:272] - INFO: epoch 005:   1922 / 2637 loss=2.217, loss_v1=0, loss_v2=0, nll_loss=1.002, ntokens=1276.9, nsentences=160, sample_size=1276.9, sample_size_v1=0, sample_size_v2=0, ppl=2, wps=611.8, ups=0.48, wpb=1276.9, bsz=160, num_updates=12450, lr=2.24972e-05, gnorm=4.426, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=26023
2023-06-27 09:27:24 - progress_bar.py[line:272] - INFO: epoch 005:   1932 / 2637 loss=2.21, loss_v1=0, loss_v2=0, nll_loss=0.992, ntokens=1252.8, nsentences=160, sample_size=1252.8, sample_size_v1=0, sample_size_v2=0, ppl=1.99, wps=600, ups=0.48, wpb=1252.8, bsz=160, num_updates=12460, lr=2.24896e-05, gnorm=5.308, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=26044
2023-06-27 09:27:45 - progress_bar.py[line:272] - INFO: epoch 005:   1942 / 2637 loss=2.183, loss_v1=0, loss_v2=0, nll_loss=0.963, ntokens=1295.9, nsentences=160, sample_size=1295.9, sample_size_v1=0, sample_size_v2=0, ppl=1.95, wps=620.7, ups=0.48, wpb=1295.9, bsz=160, num_updates=12470, lr=2.2482e-05, gnorm=4.968, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=26065
2023-06-27 09:28:06 - progress_bar.py[line:272] - INFO: epoch 005:   1952 / 2637 loss=2.226, loss_v1=0, loss_v2=0, nll_loss=1.013, ntokens=1288, nsentences=160, sample_size=1288, sample_size_v1=0, sample_size_v2=0, ppl=2.02, wps=616.9, ups=0.48, wpb=1288, bsz=160, num_updates=12480, lr=2.24745e-05, gnorm=4.958, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=26086
2023-06-27 09:28:27 - progress_bar.py[line:272] - INFO: epoch 005:   1962 / 2637 loss=2.208, loss_v1=0, loss_v2=0, nll_loss=0.99, ntokens=1266.2, nsentences=160, sample_size=1266.2, sample_size_v1=0, sample_size_v2=0, ppl=1.99, wps=606.3, ups=0.48, wpb=1266.2, bsz=160, num_updates=12490, lr=2.24669e-05, gnorm=4.857, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=26107
2023-06-27 09:28:48 - progress_bar.py[line:272] - INFO: epoch 005:   1972 / 2637 loss=2.215, loss_v1=0, loss_v2=0, nll_loss=0.999, ntokens=1268.3, nsentences=160, sample_size=1268.3, sample_size_v1=0, sample_size_v2=0, ppl=2, wps=607.7, ups=0.48, wpb=1268.3, bsz=160, num_updates=12500, lr=2.24593e-05, gnorm=4.94, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=26128
2023-06-27 09:29:08 - progress_bar.py[line:272] - INFO: epoch 005:   1982 / 2637 loss=2.243, loss_v1=0, loss_v2=0, nll_loss=1.031, ntokens=1278.2, nsentences=160, sample_size=1278.2, sample_size_v1=0, sample_size_v2=0, ppl=2.04, wps=612.7, ups=0.48, wpb=1278.2, bsz=160, num_updates=12510, lr=2.24518e-05, gnorm=4.742, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=26149
2023-06-27 09:29:29 - progress_bar.py[line:272] - INFO: epoch 005:   1992 / 2637 loss=2.204, loss_v1=0, loss_v2=0, nll_loss=0.987, ntokens=1293.9, nsentences=160, sample_size=1293.9, sample_size_v1=0, sample_size_v2=0, ppl=1.98, wps=620.1, ups=0.48, wpb=1293.9, bsz=160, num_updates=12520, lr=2.24442e-05, gnorm=4.603, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=26170
2023-06-27 09:29:50 - progress_bar.py[line:272] - INFO: epoch 005:   2002 / 2637 loss=2.203, loss_v1=0, loss_v2=0, nll_loss=0.986, ntokens=1270.4, nsentences=160, sample_size=1270.4, sample_size_v1=0, sample_size_v2=0, ppl=1.98, wps=608.1, ups=0.48, wpb=1270.4, bsz=160, num_updates=12530, lr=2.24367e-05, gnorm=4.478, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=26190
2023-06-27 09:30:11 - progress_bar.py[line:272] - INFO: epoch 005:   2012 / 2637 loss=2.205, loss_v1=0, loss_v2=0, nll_loss=0.988, ntokens=1274.3, nsentences=160, sample_size=1274.3, sample_size_v1=0, sample_size_v2=0, ppl=1.98, wps=610.3, ups=0.48, wpb=1274.3, bsz=160, num_updates=12540, lr=2.24291e-05, gnorm=4.935, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=26211
2023-06-27 09:30:32 - progress_bar.py[line:272] - INFO: epoch 005:   2022 / 2637 loss=2.199, loss_v1=0, loss_v2=0, nll_loss=0.983, ntokens=1304, nsentences=160, sample_size=1304, sample_size_v1=0, sample_size_v2=0, ppl=1.98, wps=624.4, ups=0.48, wpb=1304, bsz=160, num_updates=12550, lr=2.24215e-05, gnorm=4.966, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=26232
2023-06-27 09:30:53 - progress_bar.py[line:272] - INFO: epoch 005:   2032 / 2637 loss=2.19, loss_v1=0, loss_v2=0, nll_loss=0.971, ntokens=1251.8, nsentences=160, sample_size=1251.8, sample_size_v1=0, sample_size_v2=0, ppl=1.96, wps=599.7, ups=0.48, wpb=1251.8, bsz=160, num_updates=12560, lr=2.2414e-05, gnorm=4.999, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=26253
2023-06-27 09:31:14 - progress_bar.py[line:272] - INFO: epoch 005:   2042 / 2637 loss=2.162, loss_v1=0, loss_v2=0, nll_loss=0.938, ntokens=1284, nsentences=160, sample_size=1284, sample_size_v1=0, sample_size_v2=0, ppl=1.92, wps=616, ups=0.48, wpb=1284, bsz=160, num_updates=12570, lr=2.24064e-05, gnorm=4.35, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=26274
2023-06-27 09:31:35 - progress_bar.py[line:272] - INFO: epoch 005:   2052 / 2637 loss=2.199, loss_v1=0, loss_v2=0, nll_loss=0.983, ntokens=1280.4, nsentences=160, sample_size=1280.4, sample_size_v1=0, sample_size_v2=0, ppl=1.98, wps=613.8, ups=0.48, wpb=1280.4, bsz=160, num_updates=12580, lr=2.23988e-05, gnorm=4.439, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=26295
2023-06-27 09:31:55 - progress_bar.py[line:272] - INFO: epoch 005:   2062 / 2637 loss=2.196, loss_v1=0, loss_v2=0, nll_loss=0.978, ntokens=1250.5, nsentences=160, sample_size=1250.5, sample_size_v1=0, sample_size_v2=0, ppl=1.97, wps=599.7, ups=0.48, wpb=1250.5, bsz=160, num_updates=12590, lr=2.23913e-05, gnorm=5.535, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=26316
2023-06-27 09:32:16 - progress_bar.py[line:272] - INFO: epoch 005:   2072 / 2637 loss=2.215, loss_v1=0, loss_v2=0, nll_loss=1, ntokens=1259.1, nsentences=160, sample_size=1259.1, sample_size_v1=0, sample_size_v2=0, ppl=2, wps=603.2, ups=0.48, wpb=1259.1, bsz=160, num_updates=12600, lr=2.23837e-05, gnorm=5.965, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=26337
2023-06-27 09:32:37 - progress_bar.py[line:272] - INFO: epoch 005:   2082 / 2637 loss=2.215, loss_v1=0, loss_v2=0, nll_loss=0.998, ntokens=1257.6, nsentences=160, sample_size=1257.6, sample_size_v1=0, sample_size_v2=0, ppl=2, wps=602.5, ups=0.48, wpb=1257.6, bsz=160, num_updates=12610, lr=2.23761e-05, gnorm=5.275, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=26357
2023-06-27 09:32:58 - progress_bar.py[line:272] - INFO: epoch 005:   2092 / 2637 loss=2.197, loss_v1=0, loss_v2=0, nll_loss=0.98, ntokens=1267.4, nsentences=160, sample_size=1267.4, sample_size_v1=0, sample_size_v2=0, ppl=1.97, wps=607.6, ups=0.48, wpb=1267.4, bsz=160, num_updates=12620, lr=2.23686e-05, gnorm=5.712, clip=100, loss_scale=128, train_wall=21, gb_free=8.9, wall=26378
2023-06-27 09:33:11 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2023-06-27 09:33:21 - progress_bar.py[line:272] - INFO: epoch 005:   2103 / 2637 loss=2.199, loss_v1=0, loss_v2=0, nll_loss=0.981, ntokens=1247.3, nsentences=160, sample_size=1247.3, sample_size_v1=0, sample_size_v2=0, ppl=1.97, wps=544.1, ups=0.44, wpb=1247.3, bsz=160, num_updates=12630, lr=2.2361e-05, gnorm=5.051, clip=100, loss_scale=64, train_wall=23, gb_free=8.9, wall=26401
2023-06-27 09:33:42 - progress_bar.py[line:272] - INFO: epoch 005:   2113 / 2637 loss=2.223, loss_v1=0, loss_v2=0, nll_loss=1.01, ntokens=1266.8, nsentences=160, sample_size=1266.8, sample_size_v1=0, sample_size_v2=0, ppl=2.01, wps=606.8, ups=0.48, wpb=1266.8, bsz=160, num_updates=12640, lr=2.23534e-05, gnorm=5.369, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=26422
2023-06-27 09:34:03 - progress_bar.py[line:272] - INFO: epoch 005:   2123 / 2637 loss=2.2, loss_v1=0, loss_v2=0, nll_loss=0.984, ntokens=1257.7, nsentences=160, sample_size=1257.7, sample_size_v1=0, sample_size_v2=0, ppl=1.98, wps=602.6, ups=0.48, wpb=1257.7, bsz=160, num_updates=12650, lr=2.23459e-05, gnorm=4.616, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=26443
2023-06-27 09:34:24 - progress_bar.py[line:272] - INFO: epoch 005:   2133 / 2637 loss=2.2, loss_v1=0, loss_v2=0, nll_loss=0.982, ntokens=1259.5, nsentences=160, sample_size=1259.5, sample_size_v1=0, sample_size_v2=0, ppl=1.98, wps=603.7, ups=0.48, wpb=1259.5, bsz=160, num_updates=12660, lr=2.23383e-05, gnorm=4.809, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=26464
2023-06-27 09:34:44 - progress_bar.py[line:272] - INFO: epoch 005:   2143 / 2637 loss=2.202, loss_v1=0, loss_v2=0, nll_loss=0.984, ntokens=1260.9, nsentences=160, sample_size=1260.9, sample_size_v1=0, sample_size_v2=0, ppl=1.98, wps=604.3, ups=0.48, wpb=1260.9, bsz=160, num_updates=12670, lr=2.23308e-05, gnorm=4.21, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=26485
2023-06-27 09:35:05 - progress_bar.py[line:272] - INFO: epoch 005:   2153 / 2637 loss=2.193, loss_v1=0, loss_v2=0, nll_loss=0.975, ntokens=1268.7, nsentences=160, sample_size=1268.7, sample_size_v1=0, sample_size_v2=0, ppl=1.97, wps=608.1, ups=0.48, wpb=1268.7, bsz=160, num_updates=12680, lr=2.23232e-05, gnorm=4.679, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=26506
2023-06-27 09:35:26 - progress_bar.py[line:272] - INFO: epoch 005:   2163 / 2637 loss=2.206, loss_v1=0, loss_v2=0, nll_loss=0.99, ntokens=1261, nsentences=160, sample_size=1261, sample_size_v1=0, sample_size_v2=0, ppl=1.99, wps=603.8, ups=0.48, wpb=1261, bsz=160, num_updates=12690, lr=2.23156e-05, gnorm=4.402, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=26526
2023-06-27 09:35:47 - progress_bar.py[line:272] - INFO: epoch 005:   2173 / 2637 loss=2.196, loss_v1=0, loss_v2=0, nll_loss=0.979, ntokens=1269.8, nsentences=160, sample_size=1269.8, sample_size_v1=0, sample_size_v2=0, ppl=1.97, wps=608.2, ups=0.48, wpb=1269.8, bsz=160, num_updates=12700, lr=2.23081e-05, gnorm=4.811, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=26547
2023-06-27 09:36:08 - progress_bar.py[line:272] - INFO: epoch 005:   2183 / 2637 loss=2.194, loss_v1=0, loss_v2=0, nll_loss=0.973, ntokens=1257.3, nsentences=160, sample_size=1257.3, sample_size_v1=0, sample_size_v2=0, ppl=1.96, wps=601, ups=0.48, wpb=1257.3, bsz=160, num_updates=12710, lr=2.23005e-05, gnorm=4.606, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=26568
2023-06-27 09:36:29 - progress_bar.py[line:272] - INFO: epoch 005:   2193 / 2637 loss=2.185, loss_v1=0, loss_v2=0, nll_loss=0.967, ntokens=1267.2, nsentences=160, sample_size=1267.2, sample_size_v1=0, sample_size_v2=0, ppl=1.95, wps=607, ups=0.48, wpb=1267.2, bsz=160, num_updates=12720, lr=2.22929e-05, gnorm=4.592, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=26589
2023-06-27 09:36:50 - progress_bar.py[line:272] - INFO: epoch 005:   2203 / 2637 loss=2.197, loss_v1=0, loss_v2=0, nll_loss=0.979, ntokens=1279.4, nsentences=160, sample_size=1279.4, sample_size_v1=0, sample_size_v2=0, ppl=1.97, wps=613.7, ups=0.48, wpb=1279.4, bsz=160, num_updates=12730, lr=2.22854e-05, gnorm=4.518, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=26610
2023-06-27 09:37:11 - progress_bar.py[line:272] - INFO: epoch 005:   2213 / 2637 loss=2.165, loss_v1=0, loss_v2=0, nll_loss=0.944, ntokens=1264, nsentences=160, sample_size=1264, sample_size_v1=0, sample_size_v2=0, ppl=1.92, wps=606.7, ups=0.48, wpb=1264, bsz=160, num_updates=12740, lr=2.22778e-05, gnorm=4.659, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=26631
2023-06-27 09:37:31 - progress_bar.py[line:272] - INFO: epoch 005:   2223 / 2637 loss=2.188, loss_v1=0, loss_v2=0, nll_loss=0.97, ntokens=1247.4, nsentences=160, sample_size=1247.4, sample_size_v1=0, sample_size_v2=0, ppl=1.96, wps=598.2, ups=0.48, wpb=1247.4, bsz=160, num_updates=12750, lr=2.22702e-05, gnorm=5.164, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=26652
2023-06-27 09:37:52 - progress_bar.py[line:272] - INFO: epoch 005:   2233 / 2637 loss=2.215, loss_v1=0, loss_v2=0, nll_loss=1, ntokens=1282.7, nsentences=160, sample_size=1282.7, sample_size_v1=0, sample_size_v2=0, ppl=2, wps=614.9, ups=0.48, wpb=1282.7, bsz=160, num_updates=12760, lr=2.22627e-05, gnorm=4.267, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=26673
2023-06-27 09:38:13 - progress_bar.py[line:272] - INFO: epoch 005:   2243 / 2637 loss=2.178, loss_v1=0, loss_v2=0, nll_loss=0.958, ntokens=1263.5, nsentences=160, sample_size=1263.5, sample_size_v1=0, sample_size_v2=0, ppl=1.94, wps=606.2, ups=0.48, wpb=1263.5, bsz=160, num_updates=12770, lr=2.22551e-05, gnorm=5.093, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=26693
2023-06-27 09:38:34 - progress_bar.py[line:272] - INFO: epoch 005:   2253 / 2637 loss=2.203, loss_v1=0, loss_v2=0, nll_loss=0.985, ntokens=1246.7, nsentences=160, sample_size=1246.7, sample_size_v1=0, sample_size_v2=0, ppl=1.98, wps=597.8, ups=0.48, wpb=1246.7, bsz=160, num_updates=12780, lr=2.22475e-05, gnorm=4.668, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=26714
2023-06-27 09:38:55 - progress_bar.py[line:272] - INFO: epoch 005:   2263 / 2637 loss=2.199, loss_v1=0, loss_v2=0, nll_loss=0.98, ntokens=1263.5, nsentences=160, sample_size=1263.5, sample_size_v1=0, sample_size_v2=0, ppl=1.97, wps=605.9, ups=0.48, wpb=1263.5, bsz=160, num_updates=12790, lr=2.224e-05, gnorm=4.737, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=26735
2023-06-27 09:39:16 - progress_bar.py[line:272] - INFO: epoch 005:   2273 / 2637 loss=2.175, loss_v1=0, loss_v2=0, nll_loss=0.956, ntokens=1285.6, nsentences=160, sample_size=1285.6, sample_size_v1=0, sample_size_v2=0, ppl=1.94, wps=617, ups=0.48, wpb=1285.6, bsz=160, num_updates=12800, lr=2.22324e-05, gnorm=4.279, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=26756
2023-06-27 09:39:37 - progress_bar.py[line:272] - INFO: epoch 005:   2283 / 2637 loss=2.215, loss_v1=0, loss_v2=0, nll_loss=1, ntokens=1256.4, nsentences=160, sample_size=1256.4, sample_size_v1=0, sample_size_v2=0, ppl=2, wps=602.7, ups=0.48, wpb=1256.4, bsz=160, num_updates=12810, lr=2.22249e-05, gnorm=5.104, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=26777
2023-06-27 09:39:57 - progress_bar.py[line:272] - INFO: epoch 005:   2293 / 2637 loss=2.195, loss_v1=0, loss_v2=0, nll_loss=0.976, ntokens=1278.4, nsentences=160, sample_size=1278.4, sample_size_v1=0, sample_size_v2=0, ppl=1.97, wps=612.6, ups=0.48, wpb=1278.4, bsz=160, num_updates=12820, lr=2.22173e-05, gnorm=4.522, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=26798
2023-06-27 09:40:18 - progress_bar.py[line:272] - INFO: epoch 005:   2303 / 2637 loss=2.236, loss_v1=0, loss_v2=0, nll_loss=1.021, ntokens=1270.1, nsentences=160, sample_size=1270.1, sample_size_v1=0, sample_size_v2=0, ppl=2.03, wps=608.5, ups=0.48, wpb=1270.1, bsz=160, num_updates=12830, lr=2.22097e-05, gnorm=4.908, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=26819
2023-06-27 09:40:39 - progress_bar.py[line:272] - INFO: epoch 005:   2313 / 2637 loss=2.188, loss_v1=0, loss_v2=0, nll_loss=0.968, ntokens=1263.9, nsentences=160, sample_size=1263.9, sample_size_v1=0, sample_size_v2=0, ppl=1.96, wps=606.2, ups=0.48, wpb=1263.9, bsz=160, num_updates=12840, lr=2.22022e-05, gnorm=4.663, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=26839
2023-06-27 09:41:00 - progress_bar.py[line:272] - INFO: epoch 005:   2323 / 2637 loss=2.194, loss_v1=0, loss_v2=0, nll_loss=0.975, ntokens=1263.9, nsentences=160, sample_size=1263.9, sample_size_v1=0, sample_size_v2=0, ppl=1.97, wps=605.5, ups=0.48, wpb=1263.9, bsz=160, num_updates=12850, lr=2.21946e-05, gnorm=4.366, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=26860
2023-06-27 09:41:21 - progress_bar.py[line:272] - INFO: epoch 005:   2333 / 2637 loss=2.218, loss_v1=0, loss_v2=0, nll_loss=1.004, ntokens=1242.1, nsentences=160, sample_size=1242.1, sample_size_v1=0, sample_size_v2=0, ppl=2.01, wps=595.1, ups=0.48, wpb=1242.1, bsz=160, num_updates=12860, lr=2.2187e-05, gnorm=5.401, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=26881
2023-06-27 09:41:42 - progress_bar.py[line:272] - INFO: epoch 005:   2343 / 2637 loss=2.209, loss_v1=0, loss_v2=0, nll_loss=0.993, ntokens=1260.7, nsentences=160, sample_size=1260.7, sample_size_v1=0, sample_size_v2=0, ppl=1.99, wps=604.2, ups=0.48, wpb=1260.7, bsz=160, num_updates=12870, lr=2.21795e-05, gnorm=4.541, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=26902
2023-06-27 09:42:03 - progress_bar.py[line:272] - INFO: epoch 005:   2353 / 2637 loss=2.182, loss_v1=0, loss_v2=0, nll_loss=0.96, ntokens=1268.5, nsentences=160, sample_size=1268.5, sample_size_v1=0, sample_size_v2=0, ppl=1.95, wps=607.3, ups=0.48, wpb=1268.5, bsz=160, num_updates=12880, lr=2.21719e-05, gnorm=5.025, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=26923
2023-06-27 09:42:24 - progress_bar.py[line:272] - INFO: epoch 005:   2363 / 2637 loss=2.204, loss_v1=0, loss_v2=0, nll_loss=0.988, ntokens=1273.3, nsentences=160, sample_size=1273.3, sample_size_v1=0, sample_size_v2=0, ppl=1.98, wps=610.3, ups=0.48, wpb=1273.3, bsz=160, num_updates=12890, lr=2.21643e-05, gnorm=4.498, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=26944
2023-06-27 09:42:44 - progress_bar.py[line:272] - INFO: epoch 005:   2373 / 2637 loss=2.195, loss_v1=0, loss_v2=0, nll_loss=0.976, ntokens=1281, nsentences=160, sample_size=1281, sample_size_v1=0, sample_size_v2=0, ppl=1.97, wps=613.3, ups=0.48, wpb=1281, bsz=160, num_updates=12900, lr=2.21568e-05, gnorm=4.568, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=26965
2023-06-27 09:43:05 - progress_bar.py[line:272] - INFO: epoch 005:   2383 / 2637 loss=2.191, loss_v1=0, loss_v2=0, nll_loss=0.975, ntokens=1271.9, nsentences=160, sample_size=1271.9, sample_size_v1=0, sample_size_v2=0, ppl=1.96, wps=609.4, ups=0.48, wpb=1271.9, bsz=160, num_updates=12910, lr=2.21492e-05, gnorm=4.74, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=26986
2023-06-27 09:43:26 - progress_bar.py[line:272] - INFO: epoch 005:   2393 / 2637 loss=2.217, loss_v1=0, loss_v2=0, nll_loss=1, ntokens=1289.1, nsentences=160, sample_size=1289.1, sample_size_v1=0, sample_size_v2=0, ppl=2, wps=617, ups=0.48, wpb=1289.1, bsz=160, num_updates=12920, lr=2.21417e-05, gnorm=4.384, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=27006
2023-06-27 09:43:47 - progress_bar.py[line:272] - INFO: epoch 005:   2403 / 2637 loss=2.223, loss_v1=0, loss_v2=0, nll_loss=1.008, ntokens=1267.5, nsentences=160, sample_size=1267.5, sample_size_v1=0, sample_size_v2=0, ppl=2.01, wps=607.2, ups=0.48, wpb=1267.5, bsz=160, num_updates=12930, lr=2.21341e-05, gnorm=4.736, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=27027
2023-06-27 09:44:08 - progress_bar.py[line:272] - INFO: epoch 005:   2413 / 2637 loss=2.202, loss_v1=0, loss_v2=0, nll_loss=0.984, ntokens=1294.2, nsentences=160, sample_size=1294.2, sample_size_v1=0, sample_size_v2=0, ppl=1.98, wps=620.1, ups=0.48, wpb=1294.2, bsz=160, num_updates=12940, lr=2.21265e-05, gnorm=4.52, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=27048
2023-06-27 09:44:29 - progress_bar.py[line:272] - INFO: epoch 005:   2423 / 2637 loss=2.191, loss_v1=0, loss_v2=0, nll_loss=0.973, ntokens=1257, nsentences=160, sample_size=1257, sample_size_v1=0, sample_size_v2=0, ppl=1.96, wps=602.5, ups=0.48, wpb=1257, bsz=160, num_updates=12950, lr=2.2119e-05, gnorm=4.893, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=27069
2023-06-27 09:44:50 - progress_bar.py[line:272] - INFO: epoch 005:   2433 / 2637 loss=2.2, loss_v1=0, loss_v2=0, nll_loss=0.983, ntokens=1281.8, nsentences=160, sample_size=1281.8, sample_size_v1=0, sample_size_v2=0, ppl=1.98, wps=614.1, ups=0.48, wpb=1281.8, bsz=160, num_updates=12960, lr=2.21114e-05, gnorm=4.886, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=27090
2023-06-27 09:45:11 - progress_bar.py[line:272] - INFO: epoch 005:   2443 / 2637 loss=2.221, loss_v1=0, loss_v2=0, nll_loss=1.005, ntokens=1280.7, nsentences=160, sample_size=1280.7, sample_size_v1=0, sample_size_v2=0, ppl=2.01, wps=613.4, ups=0.48, wpb=1280.7, bsz=160, num_updates=12970, lr=2.21038e-05, gnorm=5.14, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=27111
2023-06-27 09:45:31 - progress_bar.py[line:272] - INFO: epoch 005:   2453 / 2637 loss=2.202, loss_v1=0, loss_v2=0, nll_loss=0.984, ntokens=1272.4, nsentences=160, sample_size=1272.4, sample_size_v1=0, sample_size_v2=0, ppl=1.98, wps=610.1, ups=0.48, wpb=1272.4, bsz=160, num_updates=12980, lr=2.20963e-05, gnorm=4.907, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=27132
2023-06-27 09:45:52 - progress_bar.py[line:272] - INFO: epoch 005:   2463 / 2637 loss=2.178, loss_v1=0, loss_v2=0, nll_loss=0.958, ntokens=1273.8, nsentences=160, sample_size=1273.8, sample_size_v1=0, sample_size_v2=0, ppl=1.94, wps=610.7, ups=0.48, wpb=1273.8, bsz=160, num_updates=12990, lr=2.20887e-05, gnorm=4.223, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=27153
2023-06-27 09:46:13 - progress_bar.py[line:272] - INFO: epoch 005:   2473 / 2637 loss=2.193, loss_v1=0, loss_v2=0, nll_loss=0.976, ntokens=1286.1, nsentences=160, sample_size=1286.1, sample_size_v1=0, sample_size_v2=0, ppl=1.97, wps=616, ups=0.48, wpb=1286.1, bsz=160, num_updates=13000, lr=2.20811e-05, gnorm=4.214, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=27173
2023-06-27 09:46:34 - progress_bar.py[line:272] - INFO: epoch 005:   2483 / 2637 loss=2.196, loss_v1=0, loss_v2=0, nll_loss=0.979, ntokens=1291.6, nsentences=160, sample_size=1291.6, sample_size_v1=0, sample_size_v2=0, ppl=1.97, wps=619.1, ups=0.48, wpb=1291.6, bsz=160, num_updates=13010, lr=2.20736e-05, gnorm=4.66, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=27194
2023-06-27 09:46:55 - progress_bar.py[line:272] - INFO: epoch 005:   2493 / 2637 loss=2.201, loss_v1=0, loss_v2=0, nll_loss=0.984, ntokens=1270.6, nsentences=160, sample_size=1270.6, sample_size_v1=0, sample_size_v2=0, ppl=1.98, wps=608.8, ups=0.48, wpb=1270.6, bsz=160, num_updates=13020, lr=2.2066e-05, gnorm=4.949, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=27215
2023-06-27 09:47:16 - progress_bar.py[line:272] - INFO: epoch 005:   2503 / 2637 loss=2.199, loss_v1=0, loss_v2=0, nll_loss=0.979, ntokens=1281.6, nsentences=160, sample_size=1281.6, sample_size_v1=0, sample_size_v2=0, ppl=1.97, wps=613.7, ups=0.48, wpb=1281.6, bsz=160, num_updates=13030, lr=2.20584e-05, gnorm=4.132, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=27236
2023-06-27 09:47:37 - progress_bar.py[line:272] - INFO: epoch 005:   2513 / 2637 loss=2.185, loss_v1=0, loss_v2=0, nll_loss=0.967, ntokens=1271.4, nsentences=160, sample_size=1271.4, sample_size_v1=0, sample_size_v2=0, ppl=1.95, wps=609.4, ups=0.48, wpb=1271.4, bsz=160, num_updates=13040, lr=2.20509e-05, gnorm=4.546, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=27257
2023-06-27 09:47:58 - progress_bar.py[line:272] - INFO: epoch 005:   2523 / 2637 loss=2.194, loss_v1=0, loss_v2=0, nll_loss=0.976, ntokens=1277, nsentences=160, sample_size=1277, sample_size_v1=0, sample_size_v2=0, ppl=1.97, wps=611.3, ups=0.48, wpb=1277, bsz=160, num_updates=13050, lr=2.20433e-05, gnorm=3.778, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=27278
2023-06-27 09:48:18 - progress_bar.py[line:272] - INFO: epoch 005:   2533 / 2637 loss=2.192, loss_v1=0, loss_v2=0, nll_loss=0.974, ntokens=1268.5, nsentences=160, sample_size=1268.5, sample_size_v1=0, sample_size_v2=0, ppl=1.96, wps=608.1, ups=0.48, wpb=1268.5, bsz=160, num_updates=13060, lr=2.20358e-05, gnorm=4.259, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=27299
2023-06-27 09:48:39 - progress_bar.py[line:272] - INFO: epoch 005:   2543 / 2637 loss=2.175, loss_v1=0, loss_v2=0, nll_loss=0.953, ntokens=1263.5, nsentences=160, sample_size=1263.5, sample_size_v1=0, sample_size_v2=0, ppl=1.94, wps=605.9, ups=0.48, wpb=1263.5, bsz=160, num_updates=13070, lr=2.20282e-05, gnorm=4.38, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=27320
2023-06-27 09:49:00 - progress_bar.py[line:272] - INFO: epoch 005:   2553 / 2637 loss=2.192, loss_v1=0, loss_v2=0, nll_loss=0.974, ntokens=1269.5, nsentences=160, sample_size=1269.5, sample_size_v1=0, sample_size_v2=0, ppl=1.96, wps=608.3, ups=0.48, wpb=1269.5, bsz=160, num_updates=13080, lr=2.20206e-05, gnorm=4.854, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=27340
2023-06-27 09:49:21 - progress_bar.py[line:272] - INFO: epoch 005:   2563 / 2637 loss=2.197, loss_v1=0, loss_v2=0, nll_loss=0.98, ntokens=1266.2, nsentences=160, sample_size=1266.2, sample_size_v1=0, sample_size_v2=0, ppl=1.97, wps=606.3, ups=0.48, wpb=1266.2, bsz=160, num_updates=13090, lr=2.20131e-05, gnorm=4.172, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=27361
2023-06-27 09:49:42 - progress_bar.py[line:272] - INFO: epoch 005:   2573 / 2637 loss=2.177, loss_v1=0, loss_v2=0, nll_loss=0.958, ntokens=1262.1, nsentences=160, sample_size=1262.1, sample_size_v1=0, sample_size_v2=0, ppl=1.94, wps=603.7, ups=0.48, wpb=1262.1, bsz=160, num_updates=13100, lr=2.20055e-05, gnorm=4.218, clip=100, loss_scale=64, train_wall=21, gb_free=8.8, wall=27382
2023-06-27 09:50:03 - progress_bar.py[line:272] - INFO: epoch 005:   2583 / 2637 loss=2.193, loss_v1=0, loss_v2=0, nll_loss=0.976, ntokens=1264.3, nsentences=160, sample_size=1264.3, sample_size_v1=0, sample_size_v2=0, ppl=1.97, wps=605.1, ups=0.48, wpb=1264.3, bsz=160, num_updates=13110, lr=2.19979e-05, gnorm=4.63, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=27403
2023-06-27 09:50:24 - progress_bar.py[line:272] - INFO: epoch 005:   2593 / 2637 loss=2.177, loss_v1=0, loss_v2=0, nll_loss=0.955, ntokens=1284.2, nsentences=160, sample_size=1284.2, sample_size_v1=0, sample_size_v2=0, ppl=1.94, wps=613.7, ups=0.48, wpb=1284.2, bsz=160, num_updates=13120, lr=2.19904e-05, gnorm=4.402, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=27424
2023-06-27 09:50:45 - progress_bar.py[line:272] - INFO: epoch 005:   2603 / 2637 loss=2.188, loss_v1=0, loss_v2=0, nll_loss=0.97, ntokens=1283.6, nsentences=160, sample_size=1283.6, sample_size_v1=0, sample_size_v2=0, ppl=1.96, wps=615.7, ups=0.48, wpb=1283.6, bsz=160, num_updates=13130, lr=2.19828e-05, gnorm=4.762, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=27445
2023-06-27 09:51:05 - progress_bar.py[line:272] - INFO: epoch 005:   2613 / 2637 loss=2.2, loss_v1=0, loss_v2=0, nll_loss=0.98, ntokens=1270.2, nsentences=160, sample_size=1270.2, sample_size_v1=0, sample_size_v2=0, ppl=1.97, wps=609.4, ups=0.48, wpb=1270.2, bsz=160, num_updates=13140, lr=2.19752e-05, gnorm=4.202, clip=100, loss_scale=128, train_wall=21, gb_free=8.9, wall=27466
2023-06-27 09:51:26 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2023-06-27 09:51:29 - progress_bar.py[line:272] - INFO: epoch 005:   2624 / 2637 loss=2.154, loss_v1=0, loss_v2=0, nll_loss=0.93, ntokens=1268.3, nsentences=160, sample_size=1268.3, sample_size_v1=0, sample_size_v2=0, ppl=1.91, wps=549.6, ups=0.43, wpb=1268.3, bsz=160, num_updates=13150, lr=2.19677e-05, gnorm=4.219, clip=100, loss_scale=64, train_wall=23, gb_free=8.9, wall=27489
2023-06-27 09:51:49 - progress_bar.py[line:272] - INFO: epoch 005:   2634 / 2637 loss=2.197, loss_v1=0, loss_v2=0, nll_loss=0.979, ntokens=1286.3, nsentences=160, sample_size=1286.3, sample_size_v1=0, sample_size_v2=0, ppl=1.97, wps=617.2, ups=0.48, wpb=1286.3, bsz=160, num_updates=13160, lr=2.19601e-05, gnorm=4.68, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=27510
2023-06-27 09:51:55 - train.py[line:332] - INFO: end of epoch 5 (average epoch stats below)
local datafile ../../dataset/OFA_data/vrd/vg_train_full.tsv slice_id 1 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../dataset/OFA_data/vrd/vg_train_full.tsv slice_id 2 begin to initialize row_count and line_idx-to-offset mappinglocal datafile ../../dataset/OFA_data/vrd/vg_train_full.tsv slice_id 3 begin to initialize row_count and line_idx-to-offset mapping

2023-06-27 09:51:55 - progress_bar.py[line:282] - INFO: epoch 005 | loss 2.209 | loss_v1 0 | loss_v2 0 | nll_loss 0.993 | ntokens 1259.97 | nsentences 159.984 | sample_size 1259.97 | sample_size_v1 0 | sample_size_v2 0 | ppl 1.99 | wps 603.1 | ups 0.48 | wpb 1260 | bsz 160 | num_updates 13163 | lr 2.19578e-05 | gnorm 4.848 | clip 100 | loss_scale 64 | train_wall 5491 | gb_free 8.9 | wall 27515
2023-06-27 09:51:55 - trainer.py[line:639] - INFO: loading train data for epoch 6
local datafile ../../dataset/OFA_data/vrd/vg_train_full.tsv slice_id 0 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../dataset/OFA_data/vrd/vg_train_full.tsv slice_id 2 finished initializing row_count and line_idx-to-offset mapping
file ../../dataset/OFA_data/vrd/vg_train_full.tsv slice_id 2 row count 105470 total row count 421879
local datafile ../../dataset/OFA_data/vrd/vg_train_full.tsv slice_id 3 finished initializing row_count and line_idx-to-offset mapping
file ../../dataset/OFA_data/vrd/vg_train_full.tsv slice_id 3 row count 105469 total row count 421879
local datafile ../../dataset/OFA_data/vrd/vg_train_full.tsv slice_id 1 finished initializing row_count and line_idx-to-offset mapping
file ../../dataset/OFA_data/vrd/vg_train_full.tsv slice_id 1 row count 105470 total row count 421879
local datafile ../../dataset/OFA_data/vrd/vg_train_full.tsv slice_id 0 finished initializing row_count and line_idx-to-offset mapping
file ../../dataset/OFA_data/vrd/vg_train_full.tsv slice_id 0 row count 105470 total row count 421879
slice_id 3 seek offset 316410
slice_id 2 seek offset 210940
slice_id 1 seek offset 105470
slice_id 0 seek offset 0
2023-06-27 09:51:55 - trainer.py[line:703] - INFO: begin training epoch 6
2023-06-27 09:51:55 - train.py[line:305] - INFO: Start iterating over samples
2023-06-27 09:52:10 - progress_bar.py[line:272] - INFO: epoch 006:      7 / 2637 loss=2.199, loss_v1=0, loss_v2=0, nll_loss=0.981, ntokens=1221.7, nsentences=156, sample_size=1221.7, sample_size_v1=0, sample_size_v2=0, ppl=1.97, wps=584.5, ups=0.48, wpb=1221.7, bsz=156, num_updates=13170, lr=2.19525e-05, gnorm=4.327, clip=100, loss_scale=64, train_wall=20, gb_free=8.9, wall=27531
2023-06-27 09:52:31 - progress_bar.py[line:272] - INFO: epoch 006:     17 / 2637 loss=2.173, loss_v1=0, loss_v2=0, nll_loss=0.95, ntokens=1249.4, nsentences=160, sample_size=1249.4, sample_size_v1=0, sample_size_v2=0, ppl=1.93, wps=600.2, ups=0.48, wpb=1249.4, bsz=160, num_updates=13180, lr=2.1945e-05, gnorm=4.53, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=27551
2023-06-27 09:52:52 - progress_bar.py[line:272] - INFO: epoch 006:     27 / 2637 loss=2.165, loss_v1=0, loss_v2=0, nll_loss=0.944, ntokens=1265.3, nsentences=160, sample_size=1265.3, sample_size_v1=0, sample_size_v2=0, ppl=1.92, wps=608.2, ups=0.48, wpb=1265.3, bsz=160, num_updates=13190, lr=2.19374e-05, gnorm=4.381, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=27572
2023-06-27 09:53:13 - progress_bar.py[line:272] - INFO: epoch 006:     37 / 2637 loss=2.185, loss_v1=0, loss_v2=0, nll_loss=0.966, ntokens=1260.8, nsentences=160, sample_size=1260.8, sample_size_v1=0, sample_size_v2=0, ppl=1.95, wps=606.1, ups=0.48, wpb=1260.8, bsz=160, num_updates=13200, lr=2.19299e-05, gnorm=4.812, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=27593
2023-06-27 09:53:34 - progress_bar.py[line:272] - INFO: epoch 006:     47 / 2637 loss=2.184, loss_v1=0, loss_v2=0, nll_loss=0.964, ntokens=1254.2, nsentences=160, sample_size=1254.2, sample_size_v1=0, sample_size_v2=0, ppl=1.95, wps=602.9, ups=0.48, wpb=1254.2, bsz=160, num_updates=13210, lr=2.19223e-05, gnorm=4.616, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=27614
2023-06-27 09:53:54 - progress_bar.py[line:272] - INFO: epoch 006:     57 / 2637 loss=2.186, loss_v1=0, loss_v2=0, nll_loss=0.967, ntokens=1237.7, nsentences=160, sample_size=1237.7, sample_size_v1=0, sample_size_v2=0, ppl=1.96, wps=594.5, ups=0.48, wpb=1237.7, bsz=160, num_updates=13220, lr=2.19147e-05, gnorm=4.112, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=27635
2023-06-27 09:54:15 - progress_bar.py[line:272] - INFO: epoch 006:     67 / 2637 loss=2.196, loss_v1=0, loss_v2=0, nll_loss=0.979, ntokens=1256.3, nsentences=160, sample_size=1256.3, sample_size_v1=0, sample_size_v2=0, ppl=1.97, wps=603.5, ups=0.48, wpb=1256.3, bsz=160, num_updates=13230, lr=2.19072e-05, gnorm=4.934, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=27655
2023-06-27 09:54:36 - progress_bar.py[line:272] - INFO: epoch 006:     77 / 2637 loss=2.198, loss_v1=0, loss_v2=0, nll_loss=0.979, ntokens=1247.3, nsentences=160, sample_size=1247.3, sample_size_v1=0, sample_size_v2=0, ppl=1.97, wps=599.6, ups=0.48, wpb=1247.3, bsz=160, num_updates=13240, lr=2.18996e-05, gnorm=4.284, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=27676
2023-06-27 09:54:57 - progress_bar.py[line:272] - INFO: epoch 006:     87 / 2637 loss=2.206, loss_v1=0, loss_v2=0, nll_loss=0.987, ntokens=1251.1, nsentences=160, sample_size=1251.1, sample_size_v1=0, sample_size_v2=0, ppl=1.98, wps=601.5, ups=0.48, wpb=1251.1, bsz=160, num_updates=13250, lr=2.1892e-05, gnorm=4.554, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=27697
2023-06-27 09:55:18 - progress_bar.py[line:272] - INFO: epoch 006:     97 / 2637 loss=2.162, loss_v1=0, loss_v2=0, nll_loss=0.941, ntokens=1255.1, nsentences=160, sample_size=1255.1, sample_size_v1=0, sample_size_v2=0, ppl=1.92, wps=603.6, ups=0.48, wpb=1255.1, bsz=160, num_updates=13260, lr=2.18845e-05, gnorm=4.165, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=27718
2023-06-27 09:55:38 - progress_bar.py[line:272] - INFO: epoch 006:    107 / 2637 loss=2.195, loss_v1=0, loss_v2=0, nll_loss=0.976, ntokens=1242.6, nsentences=160, sample_size=1242.6, sample_size_v1=0, sample_size_v2=0, ppl=1.97, wps=597.7, ups=0.48, wpb=1242.6, bsz=160, num_updates=13270, lr=2.18769e-05, gnorm=4.388, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=27739
2023-06-27 09:55:59 - progress_bar.py[line:272] - INFO: epoch 006:    117 / 2637 loss=2.157, loss_v1=0, loss_v2=0, nll_loss=0.935, ntokens=1249.1, nsentences=160, sample_size=1249.1, sample_size_v1=0, sample_size_v2=0, ppl=1.91, wps=600.8, ups=0.48, wpb=1249.1, bsz=160, num_updates=13280, lr=2.18693e-05, gnorm=4.482, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=27759
2023-06-27 09:56:20 - progress_bar.py[line:272] - INFO: epoch 006:    127 / 2637 loss=2.17, loss_v1=0, loss_v2=0, nll_loss=0.948, ntokens=1237, nsentences=160, sample_size=1237, sample_size_v1=0, sample_size_v2=0, ppl=1.93, wps=589.2, ups=0.48, wpb=1237, bsz=160, num_updates=13290, lr=2.18618e-05, gnorm=4.43, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=27780
2023-06-27 09:56:41 - progress_bar.py[line:272] - INFO: epoch 006:    137 / 2637 loss=2.203, loss_v1=0, loss_v2=0, nll_loss=0.986, ntokens=1256.9, nsentences=160, sample_size=1256.9, sample_size_v1=0, sample_size_v2=0, ppl=1.98, wps=603.6, ups=0.48, wpb=1256.9, bsz=160, num_updates=13300, lr=2.18542e-05, gnorm=4.578, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=27801
2023-06-27 09:57:02 - progress_bar.py[line:272] - INFO: epoch 006:    147 / 2637 loss=2.214, loss_v1=0, loss_v2=0, nll_loss=0.996, ntokens=1251.5, nsentences=160, sample_size=1251.5, sample_size_v1=0, sample_size_v2=0, ppl=2, wps=600.5, ups=0.48, wpb=1251.5, bsz=160, num_updates=13310, lr=2.18467e-05, gnorm=4.606, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=27822
2023-06-27 09:57:23 - progress_bar.py[line:272] - INFO: epoch 006:    157 / 2637 loss=2.214, loss_v1=0, loss_v2=0, nll_loss=0.999, ntokens=1240.4, nsentences=160, sample_size=1240.4, sample_size_v1=0, sample_size_v2=0, ppl=2, wps=595.1, ups=0.48, wpb=1240.4, bsz=160, num_updates=13320, lr=2.18391e-05, gnorm=4.681, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=27843
2023-06-27 09:57:44 - progress_bar.py[line:272] - INFO: epoch 006:    167 / 2637 loss=2.204, loss_v1=0, loss_v2=0, nll_loss=0.987, ntokens=1239.7, nsentences=160, sample_size=1239.7, sample_size_v1=0, sample_size_v2=0, ppl=1.98, wps=594.1, ups=0.48, wpb=1239.7, bsz=160, num_updates=13330, lr=2.18315e-05, gnorm=4.184, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=27864
2023-06-27 09:58:04 - progress_bar.py[line:272] - INFO: epoch 006:    177 / 2637 loss=2.165, loss_v1=0, loss_v2=0, nll_loss=0.944, ntokens=1239.6, nsentences=160, sample_size=1239.6, sample_size_v1=0, sample_size_v2=0, ppl=1.92, wps=594.7, ups=0.48, wpb=1239.6, bsz=160, num_updates=13340, lr=2.1824e-05, gnorm=4.412, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=27885
2023-06-27 09:58:25 - progress_bar.py[line:272] - INFO: epoch 006:    187 / 2637 loss=2.178, loss_v1=0, loss_v2=0, nll_loss=0.956, ntokens=1242.2, nsentences=160, sample_size=1242.2, sample_size_v1=0, sample_size_v2=0, ppl=1.94, wps=595.1, ups=0.48, wpb=1242.2, bsz=160, num_updates=13350, lr=2.18164e-05, gnorm=4.529, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=27906
2023-06-27 09:58:46 - progress_bar.py[line:272] - INFO: epoch 006:    197 / 2637 loss=2.168, loss_v1=0, loss_v2=0, nll_loss=0.947, ntokens=1234.8, nsentences=160, sample_size=1234.8, sample_size_v1=0, sample_size_v2=0, ppl=1.93, wps=592.6, ups=0.48, wpb=1234.8, bsz=160, num_updates=13360, lr=2.18088e-05, gnorm=4.87, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=27926
2023-06-27 09:59:07 - progress_bar.py[line:272] - INFO: epoch 006:    207 / 2637 loss=2.142, loss_v1=0, loss_v2=0, nll_loss=0.917, ntokens=1257.2, nsentences=160, sample_size=1257.2, sample_size_v1=0, sample_size_v2=0, ppl=1.89, wps=603.2, ups=0.48, wpb=1257.2, bsz=160, num_updates=13370, lr=2.18013e-05, gnorm=4.424, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=27947
2023-06-27 09:59:28 - progress_bar.py[line:272] - INFO: epoch 006:    217 / 2637 loss=2.135, loss_v1=0, loss_v2=0, nll_loss=0.909, ntokens=1225.9, nsentences=160, sample_size=1225.9, sample_size_v1=0, sample_size_v2=0, ppl=1.88, wps=588.3, ups=0.48, wpb=1225.9, bsz=160, num_updates=13380, lr=2.17937e-05, gnorm=4.225, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=27968
2023-06-27 09:59:49 - progress_bar.py[line:272] - INFO: epoch 006:    227 / 2637 loss=2.17, loss_v1=0, loss_v2=0, nll_loss=0.951, ntokens=1245.1, nsentences=160, sample_size=1245.1, sample_size_v1=0, sample_size_v2=0, ppl=1.93, wps=598.1, ups=0.48, wpb=1245.1, bsz=160, num_updates=13390, lr=2.17861e-05, gnorm=4.35, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=27989
2023-06-27 10:00:09 - progress_bar.py[line:272] - INFO: epoch 006:    237 / 2637 loss=2.157, loss_v1=0, loss_v2=0, nll_loss=0.937, ntokens=1250.9, nsentences=160, sample_size=1250.9, sample_size_v1=0, sample_size_v2=0, ppl=1.92, wps=600.6, ups=0.48, wpb=1250.9, bsz=160, num_updates=13400, lr=2.17786e-05, gnorm=4.742, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=28010
2023-06-27 10:00:30 - progress_bar.py[line:272] - INFO: epoch 006:    247 / 2637 loss=2.13, loss_v1=0, loss_v2=0, nll_loss=0.903, ntokens=1266.8, nsentences=160, sample_size=1266.8, sample_size_v1=0, sample_size_v2=0, ppl=1.87, wps=608.7, ups=0.48, wpb=1266.8, bsz=160, num_updates=13410, lr=2.1771e-05, gnorm=4.711, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=28031
2023-06-27 10:00:51 - progress_bar.py[line:272] - INFO: epoch 006:    257 / 2637 loss=2.179, loss_v1=0, loss_v2=0, nll_loss=0.959, ntokens=1234.5, nsentences=160, sample_size=1234.5, sample_size_v1=0, sample_size_v2=0, ppl=1.94, wps=592.6, ups=0.48, wpb=1234.5, bsz=160, num_updates=13420, lr=2.17634e-05, gnorm=4.356, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=28051
2023-06-27 10:01:12 - progress_bar.py[line:272] - INFO: epoch 006:    267 / 2637 loss=2.185, loss_v1=0, loss_v2=0, nll_loss=0.964, ntokens=1256.2, nsentences=160, sample_size=1256.2, sample_size_v1=0, sample_size_v2=0, ppl=1.95, wps=603.3, ups=0.48, wpb=1256.2, bsz=160, num_updates=13430, lr=2.17559e-05, gnorm=5.076, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=28072
2023-06-27 10:01:33 - progress_bar.py[line:272] - INFO: epoch 006:    277 / 2637 loss=2.183, loss_v1=0, loss_v2=0, nll_loss=0.964, ntokens=1254.7, nsentences=160, sample_size=1254.7, sample_size_v1=0, sample_size_v2=0, ppl=1.95, wps=603, ups=0.48, wpb=1254.7, bsz=160, num_updates=13440, lr=2.17483e-05, gnorm=5.074, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=28093
2023-06-27 10:01:54 - progress_bar.py[line:272] - INFO: epoch 006:    287 / 2637 loss=2.178, loss_v1=0, loss_v2=0, nll_loss=0.958, ntokens=1248.8, nsentences=160, sample_size=1248.8, sample_size_v1=0, sample_size_v2=0, ppl=1.94, wps=600.3, ups=0.48, wpb=1248.8, bsz=160, num_updates=13450, lr=2.17408e-05, gnorm=4.47, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=28114
2023-06-27 10:02:14 - progress_bar.py[line:272] - INFO: epoch 006:    297 / 2637 loss=2.185, loss_v1=0, loss_v2=0, nll_loss=0.965, ntokens=1235, nsentences=160, sample_size=1235, sample_size_v1=0, sample_size_v2=0, ppl=1.95, wps=593.4, ups=0.48, wpb=1235, bsz=160, num_updates=13460, lr=2.17332e-05, gnorm=4.818, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=28135
2023-06-27 10:02:35 - progress_bar.py[line:272] - INFO: epoch 006:    307 / 2637 loss=2.163, loss_v1=0, loss_v2=0, nll_loss=0.94, ntokens=1226.3, nsentences=160, sample_size=1226.3, sample_size_v1=0, sample_size_v2=0, ppl=1.92, wps=588.9, ups=0.48, wpb=1226.3, bsz=160, num_updates=13470, lr=2.17256e-05, gnorm=4.091, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=28155
2023-06-27 10:02:56 - progress_bar.py[line:272] - INFO: epoch 006:    317 / 2637 loss=2.153, loss_v1=0, loss_v2=0, nll_loss=0.927, ntokens=1245.9, nsentences=160, sample_size=1245.9, sample_size_v1=0, sample_size_v2=0, ppl=1.9, wps=598.4, ups=0.48, wpb=1245.9, bsz=160, num_updates=13480, lr=2.17181e-05, gnorm=4.216, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=28176
2023-06-27 10:03:17 - progress_bar.py[line:272] - INFO: epoch 006:    327 / 2637 loss=2.158, loss_v1=0, loss_v2=0, nll_loss=0.939, ntokens=1259.2, nsentences=160, sample_size=1259.2, sample_size_v1=0, sample_size_v2=0, ppl=1.92, wps=604.3, ups=0.48, wpb=1259.2, bsz=160, num_updates=13490, lr=2.17105e-05, gnorm=4.401, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=28197
2023-06-27 10:03:38 - progress_bar.py[line:272] - INFO: epoch 006:    337 / 2637 loss=2.169, loss_v1=0, loss_v2=0, nll_loss=0.948, ntokens=1228.6, nsentences=160, sample_size=1228.6, sample_size_v1=0, sample_size_v2=0, ppl=1.93, wps=589.5, ups=0.48, wpb=1228.6, bsz=160, num_updates=13500, lr=2.17029e-05, gnorm=4.685, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=28218
2023-06-27 10:03:59 - progress_bar.py[line:272] - INFO: epoch 006:    347 / 2637 loss=2.163, loss_v1=0, loss_v2=0, nll_loss=0.94, ntokens=1265.9, nsentences=160, sample_size=1265.9, sample_size_v1=0, sample_size_v2=0, ppl=1.92, wps=607.3, ups=0.48, wpb=1265.9, bsz=160, num_updates=13510, lr=2.16954e-05, gnorm=4.393, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=28239
2023-06-27 10:04:19 - progress_bar.py[line:272] - INFO: epoch 006:    357 / 2637 loss=2.169, loss_v1=0, loss_v2=0, nll_loss=0.946, ntokens=1248.7, nsentences=160, sample_size=1248.7, sample_size_v1=0, sample_size_v2=0, ppl=1.93, wps=599.2, ups=0.48, wpb=1248.7, bsz=160, num_updates=13520, lr=2.16878e-05, gnorm=4.524, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=28260
2023-06-27 10:04:40 - progress_bar.py[line:272] - INFO: epoch 006:    367 / 2637 loss=2.134, loss_v1=0, loss_v2=0, nll_loss=0.908, ntokens=1255.9, nsentences=160, sample_size=1255.9, sample_size_v1=0, sample_size_v2=0, ppl=1.88, wps=602.9, ups=0.48, wpb=1255.9, bsz=160, num_updates=13530, lr=2.16802e-05, gnorm=4.229, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=28281
2023-06-27 10:05:01 - progress_bar.py[line:272] - INFO: epoch 006:    377 / 2637 loss=2.126, loss_v1=0, loss_v2=0, nll_loss=0.899, ntokens=1244.8, nsentences=160, sample_size=1244.8, sample_size_v1=0, sample_size_v2=0, ppl=1.87, wps=597.8, ups=0.48, wpb=1244.8, bsz=160, num_updates=13540, lr=2.16727e-05, gnorm=4.386, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=28301
2023-06-27 10:05:22 - progress_bar.py[line:272] - INFO: epoch 006:    387 / 2637 loss=2.127, loss_v1=0, loss_v2=0, nll_loss=0.901, ntokens=1235.4, nsentences=160, sample_size=1235.4, sample_size_v1=0, sample_size_v2=0, ppl=1.87, wps=592.9, ups=0.48, wpb=1235.4, bsz=160, num_updates=13550, lr=2.16651e-05, gnorm=4.793, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=28322
2023-06-27 10:05:43 - progress_bar.py[line:272] - INFO: epoch 006:    397 / 2637 loss=2.116, loss_v1=0, loss_v2=0, nll_loss=0.89, ntokens=1246.5, nsentences=160, sample_size=1246.5, sample_size_v1=0, sample_size_v2=0, ppl=1.85, wps=598.4, ups=0.48, wpb=1246.5, bsz=160, num_updates=13560, lr=2.16575e-05, gnorm=5.293, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=28343
2023-06-27 10:06:04 - progress_bar.py[line:272] - INFO: epoch 006:    407 / 2637 loss=2.133, loss_v1=0, loss_v2=0, nll_loss=0.906, ntokens=1246.2, nsentences=160, sample_size=1246.2, sample_size_v1=0, sample_size_v2=0, ppl=1.87, wps=597.9, ups=0.48, wpb=1246.2, bsz=160, num_updates=13570, lr=2.165e-05, gnorm=5.636, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=28364
2023-06-27 10:06:24 - progress_bar.py[line:272] - INFO: epoch 006:    417 / 2637 loss=2.128, loss_v1=0, loss_v2=0, nll_loss=0.903, ntokens=1264.7, nsentences=160, sample_size=1264.7, sample_size_v1=0, sample_size_v2=0, ppl=1.87, wps=606.6, ups=0.48, wpb=1264.7, bsz=160, num_updates=13580, lr=2.16424e-05, gnorm=4.511, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=28385
2023-06-27 10:06:45 - progress_bar.py[line:272] - INFO: epoch 006:    427 / 2637 loss=2.136, loss_v1=0, loss_v2=0, nll_loss=0.909, ntokens=1240.5, nsentences=160, sample_size=1240.5, sample_size_v1=0, sample_size_v2=0, ppl=1.88, wps=594.4, ups=0.48, wpb=1240.5, bsz=160, num_updates=13590, lr=2.16349e-05, gnorm=4.838, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=28406
2023-06-27 10:07:06 - progress_bar.py[line:272] - INFO: epoch 006:    437 / 2637 loss=2.138, loss_v1=0, loss_v2=0, nll_loss=0.912, ntokens=1257.1, nsentences=160, sample_size=1257.1, sample_size_v1=0, sample_size_v2=0, ppl=1.88, wps=602.6, ups=0.48, wpb=1257.1, bsz=160, num_updates=13600, lr=2.16273e-05, gnorm=4.346, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=28426
2023-06-27 10:07:27 - progress_bar.py[line:272] - INFO: epoch 006:    447 / 2637 loss=2.131, loss_v1=0, loss_v2=0, nll_loss=0.907, ntokens=1238.7, nsentences=160, sample_size=1238.7, sample_size_v1=0, sample_size_v2=0, ppl=1.88, wps=593.3, ups=0.48, wpb=1238.7, bsz=160, num_updates=13610, lr=2.16197e-05, gnorm=4.484, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=28447
2023-06-27 10:07:48 - progress_bar.py[line:272] - INFO: epoch 006:    457 / 2637 loss=2.127, loss_v1=0, loss_v2=0, nll_loss=0.902, ntokens=1252.4, nsentences=160, sample_size=1252.4, sample_size_v1=0, sample_size_v2=0, ppl=1.87, wps=601, ups=0.48, wpb=1252.4, bsz=160, num_updates=13620, lr=2.16122e-05, gnorm=4.47, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=28468
2023-06-27 10:08:09 - progress_bar.py[line:272] - INFO: epoch 006:    467 / 2637 loss=2.129, loss_v1=0, loss_v2=0, nll_loss=0.902, ntokens=1254, nsentences=160, sample_size=1254, sample_size_v1=0, sample_size_v2=0, ppl=1.87, wps=600.8, ups=0.48, wpb=1254, bsz=160, num_updates=13630, lr=2.16046e-05, gnorm=4.395, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=28489
2023-06-27 10:08:30 - progress_bar.py[line:272] - INFO: epoch 006:    477 / 2637 loss=2.166, loss_v1=0, loss_v2=0, nll_loss=0.943, ntokens=1263.2, nsentences=160, sample_size=1263.2, sample_size_v1=0, sample_size_v2=0, ppl=1.92, wps=605.6, ups=0.48, wpb=1263.2, bsz=160, num_updates=13640, lr=2.1597e-05, gnorm=4.925, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=28510
2023-06-27 10:08:50 - progress_bar.py[line:272] - INFO: epoch 006:    487 / 2637 loss=2.135, loss_v1=0, loss_v2=0, nll_loss=0.912, ntokens=1262.1, nsentences=160, sample_size=1262.1, sample_size_v1=0, sample_size_v2=0, ppl=1.88, wps=605, ups=0.48, wpb=1262.1, bsz=160, num_updates=13650, lr=2.15895e-05, gnorm=4.064, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=28531
2023-06-27 10:09:11 - progress_bar.py[line:272] - INFO: epoch 006:    497 / 2637 loss=2.159, loss_v1=0, loss_v2=0, nll_loss=0.938, ntokens=1267.9, nsentences=160, sample_size=1267.9, sample_size_v1=0, sample_size_v2=0, ppl=1.92, wps=607.9, ups=0.48, wpb=1267.9, bsz=160, num_updates=13660, lr=2.15819e-05, gnorm=4.374, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=28552
2023-06-27 10:09:32 - progress_bar.py[line:272] - INFO: epoch 006:    507 / 2637 loss=2.167, loss_v1=0, loss_v2=0, nll_loss=0.943, ntokens=1258.9, nsentences=160, sample_size=1258.9, sample_size_v1=0, sample_size_v2=0, ppl=1.92, wps=603.1, ups=0.48, wpb=1258.9, bsz=160, num_updates=13670, lr=2.15743e-05, gnorm=4.284, clip=100, loss_scale=128, train_wall=21, gb_free=8.9, wall=28573
2023-06-27 10:09:53 - progress_bar.py[line:272] - INFO: epoch 006:    517 / 2637 loss=2.205, loss_v1=0, loss_v2=0, nll_loss=0.986, ntokens=1243.3, nsentences=160, sample_size=1243.3, sample_size_v1=0, sample_size_v2=0, ppl=1.98, wps=596.4, ups=0.48, wpb=1243.3, bsz=160, num_updates=13680, lr=2.15668e-05, gnorm=4.665, clip=100, loss_scale=128, train_wall=21, gb_free=8.9, wall=28593
2023-06-27 10:10:14 - progress_bar.py[line:272] - INFO: epoch 006:    527 / 2637 loss=2.141, loss_v1=0, loss_v2=0, nll_loss=0.918, ntokens=1240.4, nsentences=160, sample_size=1240.4, sample_size_v1=0, sample_size_v2=0, ppl=1.89, wps=595.1, ups=0.48, wpb=1240.4, bsz=160, num_updates=13690, lr=2.15592e-05, gnorm=4.467, clip=100, loss_scale=128, train_wall=21, gb_free=8.9, wall=28614
2023-06-27 10:10:22 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2023-06-27 10:10:37 - progress_bar.py[line:272] - INFO: epoch 006:    538 / 2637 loss=2.203, loss_v1=0, loss_v2=0, nll_loss=0.984, ntokens=1262.5, nsentences=160, sample_size=1262.5, sample_size_v1=0, sample_size_v2=0, ppl=1.98, wps=550.7, ups=0.44, wpb=1262.5, bsz=160, num_updates=13700, lr=2.15517e-05, gnorm=4.857, clip=100, loss_scale=64, train_wall=23, gb_free=8.9, wall=28637
2023-06-27 10:10:58 - progress_bar.py[line:272] - INFO: epoch 006:    548 / 2637 loss=2.187, loss_v1=0, loss_v2=0, nll_loss=0.969, ntokens=1266.7, nsentences=160, sample_size=1266.7, sample_size_v1=0, sample_size_v2=0, ppl=1.96, wps=607.7, ups=0.48, wpb=1266.7, bsz=160, num_updates=13710, lr=2.15441e-05, gnorm=5.44, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=28658
2023-06-27 10:11:19 - progress_bar.py[line:272] - INFO: epoch 006:    558 / 2637 loss=2.179, loss_v1=0, loss_v2=0, nll_loss=0.957, ntokens=1265.3, nsentences=160, sample_size=1265.3, sample_size_v1=0, sample_size_v2=0, ppl=1.94, wps=607.7, ups=0.48, wpb=1265.3, bsz=160, num_updates=13720, lr=2.15365e-05, gnorm=5.195, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=28679
2023-06-27 10:11:39 - progress_bar.py[line:272] - INFO: epoch 006:    568 / 2637 loss=2.2, loss_v1=0, loss_v2=0, nll_loss=0.985, ntokens=1243.7, nsentences=160, sample_size=1243.7, sample_size_v1=0, sample_size_v2=0, ppl=1.98, wps=596.9, ups=0.48, wpb=1243.7, bsz=160, num_updates=13730, lr=2.1529e-05, gnorm=5.036, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=28700
2023-06-27 10:12:00 - progress_bar.py[line:272] - INFO: epoch 006:    578 / 2637 loss=2.19, loss_v1=0, loss_v2=0, nll_loss=0.972, ntokens=1255.3, nsentences=160, sample_size=1255.3, sample_size_v1=0, sample_size_v2=0, ppl=1.96, wps=602.7, ups=0.48, wpb=1255.3, bsz=160, num_updates=13740, lr=2.15214e-05, gnorm=6.09, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=28720
2023-06-27 10:12:21 - progress_bar.py[line:272] - INFO: epoch 006:    588 / 2637 loss=2.198, loss_v1=0, loss_v2=0, nll_loss=0.979, ntokens=1253.8, nsentences=160, sample_size=1253.8, sample_size_v1=0, sample_size_v2=0, ppl=1.97, wps=601.4, ups=0.48, wpb=1253.8, bsz=160, num_updates=13750, lr=2.15138e-05, gnorm=4.843, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=28741
2023-06-27 10:12:42 - progress_bar.py[line:272] - INFO: epoch 006:    598 / 2637 loss=2.177, loss_v1=0, loss_v2=0, nll_loss=0.955, ntokens=1265.4, nsentences=160, sample_size=1265.4, sample_size_v1=0, sample_size_v2=0, ppl=1.94, wps=606.9, ups=0.48, wpb=1265.4, bsz=160, num_updates=13760, lr=2.15063e-05, gnorm=4.668, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=28762
2023-06-27 10:13:03 - progress_bar.py[line:272] - INFO: epoch 006:    608 / 2637 loss=2.184, loss_v1=0, loss_v2=0, nll_loss=0.965, ntokens=1258.6, nsentences=160, sample_size=1258.6, sample_size_v1=0, sample_size_v2=0, ppl=1.95, wps=603.8, ups=0.48, wpb=1258.6, bsz=160, num_updates=13770, lr=2.14987e-05, gnorm=4.847, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=28783
2023-06-27 10:13:24 - progress_bar.py[line:272] - INFO: epoch 006:    618 / 2637 loss=2.2, loss_v1=0, loss_v2=0, nll_loss=0.981, ntokens=1266.5, nsentences=160, sample_size=1266.5, sample_size_v1=0, sample_size_v2=0, ppl=1.97, wps=607.5, ups=0.48, wpb=1266.5, bsz=160, num_updates=13780, lr=2.14911e-05, gnorm=4.454, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=28804
2023-06-27 10:13:44 - progress_bar.py[line:272] - INFO: epoch 006:    628 / 2637 loss=2.167, loss_v1=0, loss_v2=0, nll_loss=0.945, ntokens=1232.1, nsentences=160, sample_size=1232.1, sample_size_v1=0, sample_size_v2=0, ppl=1.92, wps=589.8, ups=0.48, wpb=1232.1, bsz=160, num_updates=13790, lr=2.14836e-05, gnorm=4.395, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=28825
2023-06-27 10:14:05 - progress_bar.py[line:272] - INFO: epoch 006:    638 / 2637 loss=2.162, loss_v1=0, loss_v2=0, nll_loss=0.941, ntokens=1267.6, nsentences=160, sample_size=1267.6, sample_size_v1=0, sample_size_v2=0, ppl=1.92, wps=607.1, ups=0.48, wpb=1267.6, bsz=160, num_updates=13800, lr=2.1476e-05, gnorm=4.167, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=28846
2023-06-27 10:14:26 - progress_bar.py[line:272] - INFO: epoch 006:    648 / 2637 loss=2.176, loss_v1=0, loss_v2=0, nll_loss=0.957, ntokens=1247.5, nsentences=160, sample_size=1247.5, sample_size_v1=0, sample_size_v2=0, ppl=1.94, wps=597.6, ups=0.48, wpb=1247.5, bsz=160, num_updates=13810, lr=2.14684e-05, gnorm=5.051, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=28867
2023-06-27 10:14:47 - progress_bar.py[line:272] - INFO: epoch 006:    658 / 2637 loss=2.195, loss_v1=0, loss_v2=0, nll_loss=0.976, ntokens=1249.8, nsentences=160, sample_size=1249.8, sample_size_v1=0, sample_size_v2=0, ppl=1.97, wps=599.4, ups=0.48, wpb=1249.8, bsz=160, num_updates=13820, lr=2.14609e-05, gnorm=4.92, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=28887
2023-06-27 10:15:08 - progress_bar.py[line:272] - INFO: epoch 006:    668 / 2637 loss=2.172, loss_v1=0, loss_v2=0, nll_loss=0.952, ntokens=1259.1, nsentences=160, sample_size=1259.1, sample_size_v1=0, sample_size_v2=0, ppl=1.93, wps=603.7, ups=0.48, wpb=1259.1, bsz=160, num_updates=13830, lr=2.14533e-05, gnorm=4.748, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=28908
2023-06-27 10:15:29 - progress_bar.py[line:272] - INFO: epoch 006:    678 / 2637 loss=2.171, loss_v1=0, loss_v2=0, nll_loss=0.949, ntokens=1265.2, nsentences=160, sample_size=1265.2, sample_size_v1=0, sample_size_v2=0, ppl=1.93, wps=606.5, ups=0.48, wpb=1265.2, bsz=160, num_updates=13840, lr=2.14458e-05, gnorm=4.192, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=28929
2023-06-27 10:15:50 - progress_bar.py[line:272] - INFO: epoch 006:    688 / 2637 loss=2.193, loss_v1=0, loss_v2=0, nll_loss=0.976, ntokens=1289.3, nsentences=160, sample_size=1289.3, sample_size_v1=0, sample_size_v2=0, ppl=1.97, wps=618.4, ups=0.48, wpb=1289.3, bsz=160, num_updates=13850, lr=2.14382e-05, gnorm=4.698, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=28950
2023-06-27 10:16:11 - progress_bar.py[line:272] - INFO: epoch 006:    698 / 2637 loss=2.173, loss_v1=0, loss_v2=0, nll_loss=0.95, ntokens=1247.4, nsentences=160, sample_size=1247.4, sample_size_v1=0, sample_size_v2=0, ppl=1.93, wps=598.7, ups=0.48, wpb=1247.4, bsz=160, num_updates=13860, lr=2.14306e-05, gnorm=4.336, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=28971
2023-06-27 10:16:31 - progress_bar.py[line:272] - INFO: epoch 006:    708 / 2637 loss=2.195, loss_v1=0, loss_v2=0, nll_loss=0.977, ntokens=1266, nsentences=160, sample_size=1266, sample_size_v1=0, sample_size_v2=0, ppl=1.97, wps=608.2, ups=0.48, wpb=1266, bsz=160, num_updates=13870, lr=2.14231e-05, gnorm=4.373, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=28992
2023-06-27 10:16:52 - progress_bar.py[line:272] - INFO: epoch 006:    718 / 2637 loss=2.174, loss_v1=0, loss_v2=0, nll_loss=0.953, ntokens=1249.4, nsentences=160, sample_size=1249.4, sample_size_v1=0, sample_size_v2=0, ppl=1.94, wps=600.2, ups=0.48, wpb=1249.4, bsz=160, num_updates=13880, lr=2.14155e-05, gnorm=4.449, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=29012
2023-06-27 10:17:13 - progress_bar.py[line:272] - INFO: epoch 006:    728 / 2637 loss=2.176, loss_v1=0, loss_v2=0, nll_loss=0.955, ntokens=1267.1, nsentences=160, sample_size=1267.1, sample_size_v1=0, sample_size_v2=0, ppl=1.94, wps=608.3, ups=0.48, wpb=1267.1, bsz=160, num_updates=13890, lr=2.14079e-05, gnorm=4.091, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=29033
2023-06-27 10:17:34 - progress_bar.py[line:272] - INFO: epoch 006:    738 / 2637 loss=2.188, loss_v1=0, loss_v2=0, nll_loss=0.97, ntokens=1255.3, nsentences=160, sample_size=1255.3, sample_size_v1=0, sample_size_v2=0, ppl=1.96, wps=603.2, ups=0.48, wpb=1255.3, bsz=160, num_updates=13900, lr=2.14004e-05, gnorm=4.19, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=29054
2023-06-27 10:17:55 - progress_bar.py[line:272] - INFO: epoch 006:    748 / 2637 loss=2.202, loss_v1=0, loss_v2=0, nll_loss=0.984, ntokens=1269.4, nsentences=160, sample_size=1269.4, sample_size_v1=0, sample_size_v2=0, ppl=1.98, wps=609.7, ups=0.48, wpb=1269.4, bsz=160, num_updates=13910, lr=2.13928e-05, gnorm=4.513, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=29075
2023-06-27 10:18:15 - progress_bar.py[line:272] - INFO: epoch 006:    758 / 2637 loss=2.197, loss_v1=0, loss_v2=0, nll_loss=0.98, ntokens=1264.7, nsentences=160, sample_size=1264.7, sample_size_v1=0, sample_size_v2=0, ppl=1.97, wps=606.9, ups=0.48, wpb=1264.7, bsz=160, num_updates=13920, lr=2.13852e-05, gnorm=4.603, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=29096
2023-06-27 10:18:36 - progress_bar.py[line:272] - INFO: epoch 006:    768 / 2637 loss=2.166, loss_v1=0, loss_v2=0, nll_loss=0.943, ntokens=1252.8, nsentences=160, sample_size=1252.8, sample_size_v1=0, sample_size_v2=0, ppl=1.92, wps=601.1, ups=0.48, wpb=1252.8, bsz=160, num_updates=13930, lr=2.13777e-05, gnorm=4.022, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=29117
2023-06-27 10:18:57 - progress_bar.py[line:272] - INFO: epoch 006:    778 / 2637 loss=2.182, loss_v1=0, loss_v2=0, nll_loss=0.962, ntokens=1257.7, nsentences=160, sample_size=1257.7, sample_size_v1=0, sample_size_v2=0, ppl=1.95, wps=603.8, ups=0.48, wpb=1257.7, bsz=160, num_updates=13940, lr=2.13701e-05, gnorm=4.12, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=29137
2023-06-27 10:19:18 - progress_bar.py[line:272] - INFO: epoch 006:    788 / 2637 loss=2.179, loss_v1=0, loss_v2=0, nll_loss=0.959, ntokens=1258.9, nsentences=160, sample_size=1258.9, sample_size_v1=0, sample_size_v2=0, ppl=1.94, wps=604.6, ups=0.48, wpb=1258.9, bsz=160, num_updates=13950, lr=2.13625e-05, gnorm=4.68, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=29158
2023-06-27 10:19:39 - progress_bar.py[line:272] - INFO: epoch 006:    798 / 2637 loss=2.183, loss_v1=0, loss_v2=0, nll_loss=0.962, ntokens=1256.7, nsentences=160, sample_size=1256.7, sample_size_v1=0, sample_size_v2=0, ppl=1.95, wps=603.6, ups=0.48, wpb=1256.7, bsz=160, num_updates=13960, lr=2.1355e-05, gnorm=4.517, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=29179
2023-06-27 10:20:00 - progress_bar.py[line:272] - INFO: epoch 006:    808 / 2637 loss=2.169, loss_v1=0, loss_v2=0, nll_loss=0.947, ntokens=1243.4, nsentences=160, sample_size=1243.4, sample_size_v1=0, sample_size_v2=0, ppl=1.93, wps=597.2, ups=0.48, wpb=1243.4, bsz=160, num_updates=13970, lr=2.13474e-05, gnorm=4.985, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=29200
2023-06-27 10:20:20 - progress_bar.py[line:272] - INFO: epoch 006:    818 / 2637 loss=2.164, loss_v1=0, loss_v2=0, nll_loss=0.941, ntokens=1267.1, nsentences=160, sample_size=1267.1, sample_size_v1=0, sample_size_v2=0, ppl=1.92, wps=607.6, ups=0.48, wpb=1267.1, bsz=160, num_updates=13980, lr=2.13399e-05, gnorm=5.158, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=29221
2023-06-27 10:20:41 - progress_bar.py[line:272] - INFO: epoch 006:    828 / 2637 loss=2.203, loss_v1=0, loss_v2=0, nll_loss=0.988, ntokens=1251, nsentences=160, sample_size=1251, sample_size_v1=0, sample_size_v2=0, ppl=1.98, wps=600.1, ups=0.48, wpb=1251, bsz=160, num_updates=13990, lr=2.13323e-05, gnorm=4.938, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=29242
2023-06-27 10:21:02 - progress_bar.py[line:272] - INFO: epoch 006:    838 / 2637 loss=2.172, loss_v1=0, loss_v2=0, nll_loss=0.952, ntokens=1267.4, nsentences=160, sample_size=1267.4, sample_size_v1=0, sample_size_v2=0, ppl=1.93, wps=606.8, ups=0.48, wpb=1267.4, bsz=160, num_updates=14000, lr=2.13247e-05, gnorm=4.392, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=29263
2023-06-27 10:21:23 - progress_bar.py[line:272] - INFO: epoch 006:    848 / 2637 loss=2.189, loss_v1=0, loss_v2=0, nll_loss=0.969, ntokens=1256.7, nsentences=160, sample_size=1256.7, sample_size_v1=0, sample_size_v2=0, ppl=1.96, wps=601.8, ups=0.48, wpb=1256.7, bsz=160, num_updates=14010, lr=2.13172e-05, gnorm=5.149, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=29283
2023-06-27 10:21:44 - progress_bar.py[line:272] - INFO: epoch 006:    858 / 2637 loss=2.173, loss_v1=0, loss_v2=0, nll_loss=0.953, ntokens=1236.8, nsentences=160, sample_size=1236.8, sample_size_v1=0, sample_size_v2=0, ppl=1.94, wps=593, ups=0.48, wpb=1236.8, bsz=160, num_updates=14020, lr=2.13096e-05, gnorm=4.394, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=29304
2023-06-27 10:22:05 - progress_bar.py[line:272] - INFO: epoch 006:    868 / 2637 loss=2.183, loss_v1=0, loss_v2=0, nll_loss=0.962, ntokens=1230.8, nsentences=160, sample_size=1230.8, sample_size_v1=0, sample_size_v2=0, ppl=1.95, wps=590.2, ups=0.48, wpb=1230.8, bsz=160, num_updates=14030, lr=2.1302e-05, gnorm=4.61, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=29325
2023-06-27 10:22:26 - progress_bar.py[line:272] - INFO: epoch 006:    878 / 2637 loss=2.176, loss_v1=0, loss_v2=0, nll_loss=0.956, ntokens=1263.6, nsentences=160, sample_size=1263.6, sample_size_v1=0, sample_size_v2=0, ppl=1.94, wps=606, ups=0.48, wpb=1263.6, bsz=160, num_updates=14040, lr=2.12945e-05, gnorm=4.523, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=29346
2023-06-27 10:22:47 - progress_bar.py[line:272] - INFO: epoch 006:    888 / 2637 loss=2.162, loss_v1=0, loss_v2=0, nll_loss=0.939, ntokens=1251.1, nsentences=160, sample_size=1251.1, sample_size_v1=0, sample_size_v2=0, ppl=1.92, wps=600.1, ups=0.48, wpb=1251.1, bsz=160, num_updates=14050, lr=2.12869e-05, gnorm=4.5, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=29367
2023-06-27 10:23:07 - progress_bar.py[line:272] - INFO: epoch 006:    898 / 2637 loss=2.167, loss_v1=0, loss_v2=0, nll_loss=0.946, ntokens=1258.7, nsentences=160, sample_size=1258.7, sample_size_v1=0, sample_size_v2=0, ppl=1.93, wps=603.8, ups=0.48, wpb=1258.7, bsz=160, num_updates=14060, lr=2.12793e-05, gnorm=4.557, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=29388
2023-06-27 10:23:28 - progress_bar.py[line:272] - INFO: epoch 006:    908 / 2637 loss=2.165, loss_v1=0, loss_v2=0, nll_loss=0.943, ntokens=1246.2, nsentences=160, sample_size=1246.2, sample_size_v1=0, sample_size_v2=0, ppl=1.92, wps=598.6, ups=0.48, wpb=1246.2, bsz=160, num_updates=14070, lr=2.12718e-05, gnorm=4.776, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=29408
2023-06-27 10:23:49 - progress_bar.py[line:272] - INFO: epoch 006:    918 / 2637 loss=2.147, loss_v1=0, loss_v2=0, nll_loss=0.924, ntokens=1252.7, nsentences=160, sample_size=1252.7, sample_size_v1=0, sample_size_v2=0, ppl=1.9, wps=602.1, ups=0.48, wpb=1252.7, bsz=160, num_updates=14080, lr=2.12642e-05, gnorm=4.641, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=29429
2023-06-27 10:24:10 - progress_bar.py[line:272] - INFO: epoch 006:    928 / 2637 loss=2.188, loss_v1=0, loss_v2=0, nll_loss=0.97, ntokens=1257.3, nsentences=160, sample_size=1257.3, sample_size_v1=0, sample_size_v2=0, ppl=1.96, wps=604.3, ups=0.48, wpb=1257.3, bsz=160, num_updates=14090, lr=2.12567e-05, gnorm=5.197, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=29450
2023-06-27 10:24:31 - progress_bar.py[line:272] - INFO: epoch 006:    938 / 2637 loss=2.16, loss_v1=0, loss_v2=0, nll_loss=0.936, ntokens=1259.9, nsentences=160, sample_size=1259.9, sample_size_v1=0, sample_size_v2=0, ppl=1.91, wps=605.2, ups=0.48, wpb=1259.9, bsz=160, num_updates=14100, lr=2.12491e-05, gnorm=4.953, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=29471
2023-06-27 10:24:51 - progress_bar.py[line:272] - INFO: epoch 006:    948 / 2637 loss=2.189, loss_v1=0, loss_v2=0, nll_loss=0.968, ntokens=1240.8, nsentences=160, sample_size=1240.8, sample_size_v1=0, sample_size_v2=0, ppl=1.96, wps=596.5, ups=0.48, wpb=1240.8, bsz=160, num_updates=14110, lr=2.12415e-05, gnorm=4.448, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=29492
2023-06-27 10:25:12 - progress_bar.py[line:272] - INFO: epoch 006:    958 / 2637 loss=2.208, loss_v1=0, loss_v2=0, nll_loss=0.991, ntokens=1250.5, nsentences=160, sample_size=1250.5, sample_size_v1=0, sample_size_v2=0, ppl=1.99, wps=601.1, ups=0.48, wpb=1250.5, bsz=160, num_updates=14120, lr=2.1234e-05, gnorm=4.945, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=29513
2023-06-27 10:25:33 - progress_bar.py[line:272] - INFO: epoch 006:    968 / 2637 loss=2.152, loss_v1=0, loss_v2=0, nll_loss=0.931, ntokens=1237.8, nsentences=160, sample_size=1237.8, sample_size_v1=0, sample_size_v2=0, ppl=1.91, wps=595.3, ups=0.48, wpb=1237.8, bsz=160, num_updates=14130, lr=2.12264e-05, gnorm=4.273, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=29533
2023-06-27 10:25:54 - progress_bar.py[line:272] - INFO: epoch 006:    978 / 2637 loss=2.167, loss_v1=0, loss_v2=0, nll_loss=0.946, ntokens=1251.6, nsentences=160, sample_size=1251.6, sample_size_v1=0, sample_size_v2=0, ppl=1.93, wps=601.5, ups=0.48, wpb=1251.6, bsz=160, num_updates=14140, lr=2.12188e-05, gnorm=4.61, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=29554
2023-06-27 10:26:15 - progress_bar.py[line:272] - INFO: epoch 006:    988 / 2637 loss=2.182, loss_v1=0, loss_v2=0, nll_loss=0.961, ntokens=1238.1, nsentences=160, sample_size=1238.1, sample_size_v1=0, sample_size_v2=0, ppl=1.95, wps=594.6, ups=0.48, wpb=1238.1, bsz=160, num_updates=14150, lr=2.12113e-05, gnorm=4.836, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=29575
2023-06-27 10:26:36 - progress_bar.py[line:272] - INFO: epoch 006:    998 / 2637 loss=2.162, loss_v1=0, loss_v2=0, nll_loss=0.939, ntokens=1254.3, nsentences=160, sample_size=1254.3, sample_size_v1=0, sample_size_v2=0, ppl=1.92, wps=602.6, ups=0.48, wpb=1254.3, bsz=160, num_updates=14160, lr=2.12037e-05, gnorm=4.678, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=29596
2023-06-27 10:26:56 - progress_bar.py[line:272] - INFO: epoch 006:   1008 / 2637 loss=2.148, loss_v1=0, loss_v2=0, nll_loss=0.925, ntokens=1241.6, nsentences=160, sample_size=1241.6, sample_size_v1=0, sample_size_v2=0, ppl=1.9, wps=597, ups=0.48, wpb=1241.6, bsz=160, num_updates=14170, lr=2.11961e-05, gnorm=4.64, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=29617
2023-06-27 10:27:17 - progress_bar.py[line:272] - INFO: epoch 006:   1018 / 2637 loss=2.17, loss_v1=0, loss_v2=0, nll_loss=0.949, ntokens=1238.8, nsentences=160, sample_size=1238.8, sample_size_v1=0, sample_size_v2=0, ppl=1.93, wps=595.6, ups=0.48, wpb=1238.8, bsz=160, num_updates=14180, lr=2.11886e-05, gnorm=5.021, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=29637
2023-06-27 10:27:38 - progress_bar.py[line:272] - INFO: epoch 006:   1028 / 2637 loss=2.174, loss_v1=0, loss_v2=0, nll_loss=0.953, ntokens=1258.7, nsentences=160, sample_size=1258.7, sample_size_v1=0, sample_size_v2=0, ppl=1.94, wps=605.4, ups=0.48, wpb=1258.7, bsz=160, num_updates=14190, lr=2.1181e-05, gnorm=4.184, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=29658
2023-06-27 10:27:59 - progress_bar.py[line:272] - INFO: epoch 006:   1038 / 2637 loss=2.16, loss_v1=0, loss_v2=0, nll_loss=0.938, ntokens=1243.1, nsentences=160, sample_size=1243.1, sample_size_v1=0, sample_size_v2=0, ppl=1.92, wps=597.5, ups=0.48, wpb=1243.1, bsz=160, num_updates=14200, lr=2.11734e-05, gnorm=4.958, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=29679
2023-06-27 10:28:20 - progress_bar.py[line:272] - INFO: epoch 006:   1048 / 2637 loss=2.157, loss_v1=0, loss_v2=0, nll_loss=0.933, ntokens=1259.7, nsentences=160, sample_size=1259.7, sample_size_v1=0, sample_size_v2=0, ppl=1.91, wps=605.4, ups=0.48, wpb=1259.7, bsz=160, num_updates=14210, lr=2.11659e-05, gnorm=5.259, clip=100, loss_scale=128, train_wall=21, gb_free=8.9, wall=29700
2023-06-27 10:28:40 - progress_bar.py[line:272] - INFO: epoch 006:   1058 / 2637 loss=2.171, loss_v1=0, loss_v2=0, nll_loss=0.95, ntokens=1245.4, nsentences=160, sample_size=1245.4, sample_size_v1=0, sample_size_v2=0, ppl=1.93, wps=599, ups=0.48, wpb=1245.4, bsz=160, num_updates=14220, lr=2.11583e-05, gnorm=4.718, clip=100, loss_scale=128, train_wall=21, gb_free=8.9, wall=29721
2023-06-27 10:29:01 - progress_bar.py[line:272] - INFO: epoch 006:   1068 / 2637 loss=2.179, loss_v1=0, loss_v2=0, nll_loss=0.959, ntokens=1232.3, nsentences=160, sample_size=1232.3, sample_size_v1=0, sample_size_v2=0, ppl=1.94, wps=592, ups=0.48, wpb=1232.3, bsz=160, num_updates=14230, lr=2.11508e-05, gnorm=4.316, clip=100, loss_scale=128, train_wall=21, gb_free=8.9, wall=29741
2023-06-27 10:29:22 - progress_bar.py[line:272] - INFO: epoch 006:   1078 / 2637 loss=2.16, loss_v1=0, loss_v2=0, nll_loss=0.938, ntokens=1238.8, nsentences=160, sample_size=1238.8, sample_size_v1=0, sample_size_v2=0, ppl=1.92, wps=595.2, ups=0.48, wpb=1238.8, bsz=160, num_updates=14240, lr=2.11432e-05, gnorm=4.487, clip=100, loss_scale=128, train_wall=21, gb_free=8.9, wall=29762
2023-06-27 10:29:43 - progress_bar.py[line:272] - INFO: epoch 006:   1088 / 2637 loss=2.176, loss_v1=0, loss_v2=0, nll_loss=0.957, ntokens=1267.3, nsentences=160, sample_size=1267.3, sample_size_v1=0, sample_size_v2=0, ppl=1.94, wps=608.6, ups=0.48, wpb=1267.3, bsz=160, num_updates=14250, lr=2.11356e-05, gnorm=4.319, clip=100, loss_scale=128, train_wall=21, gb_free=8.9, wall=29783
2023-06-27 10:30:04 - progress_bar.py[line:272] - INFO: epoch 006:   1098 / 2637 loss=2.161, loss_v1=0, loss_v2=0, nll_loss=0.939, ntokens=1235.1, nsentences=160, sample_size=1235.1, sample_size_v1=0, sample_size_v2=0, ppl=1.92, wps=593.1, ups=0.48, wpb=1235.1, bsz=160, num_updates=14260, lr=2.11281e-05, gnorm=4.553, clip=100, loss_scale=128, train_wall=21, gb_free=8.9, wall=29804
2023-06-27 10:30:24 - progress_bar.py[line:272] - INFO: epoch 006:   1108 / 2637 loss=2.165, loss_v1=0, loss_v2=0, nll_loss=0.942, ntokens=1229.9, nsentences=160, sample_size=1229.9, sample_size_v1=0, sample_size_v2=0, ppl=1.92, wps=590.8, ups=0.48, wpb=1229.9, bsz=160, num_updates=14270, lr=2.11205e-05, gnorm=4.238, clip=100, loss_scale=128, train_wall=21, gb_free=8.9, wall=29825
2023-06-27 10:30:45 - progress_bar.py[line:272] - INFO: epoch 006:   1118 / 2637 loss=2.164, loss_v1=0, loss_v2=0, nll_loss=0.94, ntokens=1245.9, nsentences=160, sample_size=1245.9, sample_size_v1=0, sample_size_v2=0, ppl=1.92, wps=598.1, ups=0.48, wpb=1245.9, bsz=160, num_updates=14280, lr=2.11129e-05, gnorm=4.473, clip=100, loss_scale=128, train_wall=21, gb_free=8.9, wall=29846
2023-06-27 10:31:06 - progress_bar.py[line:272] - INFO: epoch 006:   1128 / 2637 loss=2.18, loss_v1=0, loss_v2=0, nll_loss=0.959, ntokens=1236, nsentences=160, sample_size=1236, sample_size_v1=0, sample_size_v2=0, ppl=1.94, wps=593, ups=0.48, wpb=1236, bsz=160, num_updates=14290, lr=2.11054e-05, gnorm=4.393, clip=100, loss_scale=128, train_wall=21, gb_free=8.9, wall=29866
2023-06-27 10:31:27 - progress_bar.py[line:272] - INFO: epoch 006:   1138 / 2637 loss=2.159, loss_v1=0, loss_v2=0, nll_loss=0.937, ntokens=1257.2, nsentences=160, sample_size=1257.2, sample_size_v1=0, sample_size_v2=0, ppl=1.91, wps=603.3, ups=0.48, wpb=1257.2, bsz=160, num_updates=14300, lr=2.10978e-05, gnorm=5.675, clip=100, loss_scale=128, train_wall=21, gb_free=8.9, wall=29887
2023-06-27 10:31:48 - progress_bar.py[line:272] - INFO: epoch 006:   1148 / 2637 loss=2.169, loss_v1=0, loss_v2=0, nll_loss=0.95, ntokens=1270.1, nsentences=160, sample_size=1270.1, sample_size_v1=0, sample_size_v2=0, ppl=1.93, wps=608.9, ups=0.48, wpb=1270.1, bsz=160, num_updates=14310, lr=2.10902e-05, gnorm=4.568, clip=100, loss_scale=128, train_wall=21, gb_free=8.9, wall=29908
2023-06-27 10:32:09 - progress_bar.py[line:272] - INFO: epoch 006:   1158 / 2637 loss=2.193, loss_v1=0, loss_v2=0, nll_loss=0.973, ntokens=1235.5, nsentences=160, sample_size=1235.5, sample_size_v1=0, sample_size_v2=0, ppl=1.96, wps=593, ups=0.48, wpb=1235.5, bsz=160, num_updates=14320, lr=2.10827e-05, gnorm=4.564, clip=100, loss_scale=128, train_wall=21, gb_free=8.9, wall=29929
2023-06-27 10:32:30 - progress_bar.py[line:272] - INFO: epoch 006:   1168 / 2637 loss=2.13, loss_v1=0, loss_v2=0, nll_loss=0.905, ntokens=1246.6, nsentences=160, sample_size=1246.6, sample_size_v1=0, sample_size_v2=0, ppl=1.87, wps=598.1, ups=0.48, wpb=1246.6, bsz=160, num_updates=14330, lr=2.10751e-05, gnorm=3.972, clip=100, loss_scale=128, train_wall=21, gb_free=8.9, wall=29950
2023-06-27 10:32:40 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2023-06-27 10:32:52 - progress_bar.py[line:272] - INFO: epoch 006:   1179 / 2637 loss=2.166, loss_v1=0, loss_v2=0, nll_loss=0.945, ntokens=1250.1, nsentences=160, sample_size=1250.1, sample_size_v1=0, sample_size_v2=0, ppl=1.92, wps=546, ups=0.44, wpb=1250.1, bsz=160, num_updates=14340, lr=2.10675e-05, gnorm=4.897, clip=100, loss_scale=64, train_wall=23, gb_free=8.9, wall=29973
2023-06-27 10:33:13 - progress_bar.py[line:272] - INFO: epoch 006:   1189 / 2637 loss=2.162, loss_v1=0, loss_v2=0, nll_loss=0.94, ntokens=1249.3, nsentences=160, sample_size=1249.3, sample_size_v1=0, sample_size_v2=0, ppl=1.92, wps=599.4, ups=0.48, wpb=1249.3, bsz=160, num_updates=14350, lr=2.106e-05, gnorm=4.191, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=29994
2023-06-27 10:33:34 - progress_bar.py[line:272] - INFO: epoch 006:   1199 / 2637 loss=2.177, loss_v1=0, loss_v2=0, nll_loss=0.956, ntokens=1265.8, nsentences=160, sample_size=1265.8, sample_size_v1=0, sample_size_v2=0, ppl=1.94, wps=607.3, ups=0.48, wpb=1265.8, bsz=160, num_updates=14360, lr=2.10524e-05, gnorm=4.945, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=30014
2023-06-27 10:33:55 - progress_bar.py[line:272] - INFO: epoch 006:   1209 / 2637 loss=2.171, loss_v1=0, loss_v2=0, nll_loss=0.952, ntokens=1243.1, nsentences=160, sample_size=1243.1, sample_size_v1=0, sample_size_v2=0, ppl=1.93, wps=596.1, ups=0.48, wpb=1243.1, bsz=160, num_updates=14370, lr=2.10449e-05, gnorm=5.045, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=30035
2023-06-27 10:34:16 - progress_bar.py[line:272] - INFO: epoch 006:   1219 / 2637 loss=2.161, loss_v1=0, loss_v2=0, nll_loss=0.938, ntokens=1268.3, nsentences=160, sample_size=1268.3, sample_size_v1=0, sample_size_v2=0, ppl=1.92, wps=607.8, ups=0.48, wpb=1268.3, bsz=160, num_updates=14380, lr=2.10373e-05, gnorm=4.408, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=30056
2023-06-27 10:34:37 - progress_bar.py[line:272] - INFO: epoch 006:   1229 / 2637 loss=2.179, loss_v1=0, loss_v2=0, nll_loss=0.958, ntokens=1228.6, nsentences=160, sample_size=1228.6, sample_size_v1=0, sample_size_v2=0, ppl=1.94, wps=589.9, ups=0.48, wpb=1228.6, bsz=160, num_updates=14390, lr=2.10297e-05, gnorm=4.875, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=30077
2023-06-27 10:34:57 - progress_bar.py[line:272] - INFO: epoch 006:   1239 / 2637 loss=2.169, loss_v1=0, loss_v2=0, nll_loss=0.946, ntokens=1237.1, nsentences=160, sample_size=1237.1, sample_size_v1=0, sample_size_v2=0, ppl=1.93, wps=594.3, ups=0.48, wpb=1237.1, bsz=160, num_updates=14400, lr=2.10222e-05, gnorm=4.455, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=30098
2023-06-27 10:35:18 - progress_bar.py[line:272] - INFO: epoch 006:   1249 / 2637 loss=2.16, loss_v1=0, loss_v2=0, nll_loss=0.939, ntokens=1233.9, nsentences=160, sample_size=1233.9, sample_size_v1=0, sample_size_v2=0, ppl=1.92, wps=592.7, ups=0.48, wpb=1233.9, bsz=160, num_updates=14410, lr=2.10146e-05, gnorm=4.448, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=30119
2023-06-27 10:35:39 - progress_bar.py[line:272] - INFO: epoch 006:   1259 / 2637 loss=2.176, loss_v1=0, loss_v2=0, nll_loss=0.957, ntokens=1235, nsentences=160, sample_size=1235, sample_size_v1=0, sample_size_v2=0, ppl=1.94, wps=593.3, ups=0.48, wpb=1235, bsz=160, num_updates=14420, lr=2.1007e-05, gnorm=4.282, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=30139
2023-06-27 10:36:00 - progress_bar.py[line:272] - INFO: epoch 006:   1269 / 2637 loss=2.159, loss_v1=0, loss_v2=0, nll_loss=0.937, ntokens=1265, nsentences=160, sample_size=1265, sample_size_v1=0, sample_size_v2=0, ppl=1.91, wps=607.9, ups=0.48, wpb=1265, bsz=160, num_updates=14430, lr=2.09995e-05, gnorm=4.309, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=30160
2023-06-27 10:36:21 - progress_bar.py[line:272] - INFO: epoch 006:   1279 / 2637 loss=2.185, loss_v1=0, loss_v2=0, nll_loss=0.965, ntokens=1240.9, nsentences=160, sample_size=1240.9, sample_size_v1=0, sample_size_v2=0, ppl=1.95, wps=596, ups=0.48, wpb=1240.9, bsz=160, num_updates=14440, lr=2.09919e-05, gnorm=4.675, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=30181
2023-06-27 10:36:42 - progress_bar.py[line:272] - INFO: epoch 006:   1289 / 2637 loss=2.17, loss_v1=0, loss_v2=0, nll_loss=0.949, ntokens=1249.4, nsentences=160, sample_size=1249.4, sample_size_v1=0, sample_size_v2=0, ppl=1.93, wps=600.4, ups=0.48, wpb=1249.4, bsz=160, num_updates=14450, lr=2.09843e-05, gnorm=4.529, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=30202
2023-06-27 10:37:02 - progress_bar.py[line:272] - INFO: epoch 006:   1299 / 2637 loss=2.168, loss_v1=0, loss_v2=0, nll_loss=0.946, ntokens=1239.7, nsentences=160, sample_size=1239.7, sample_size_v1=0, sample_size_v2=0, ppl=1.93, wps=596, ups=0.48, wpb=1239.7, bsz=160, num_updates=14460, lr=2.09768e-05, gnorm=4.813, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=30223
2023-06-27 10:37:23 - progress_bar.py[line:272] - INFO: epoch 006:   1309 / 2637 loss=2.17, loss_v1=0, loss_v2=0, nll_loss=0.949, ntokens=1250.3, nsentences=160, sample_size=1250.3, sample_size_v1=0, sample_size_v2=0, ppl=1.93, wps=600.6, ups=0.48, wpb=1250.3, bsz=160, num_updates=14470, lr=2.09692e-05, gnorm=4.408, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=30243
2023-06-27 10:37:44 - progress_bar.py[line:272] - INFO: epoch 006:   1319 / 2637 loss=2.172, loss_v1=0, loss_v2=0, nll_loss=0.949, ntokens=1241.2, nsentences=160, sample_size=1241.2, sample_size_v1=0, sample_size_v2=0, ppl=1.93, wps=596.3, ups=0.48, wpb=1241.2, bsz=160, num_updates=14480, lr=2.09616e-05, gnorm=4.335, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=30264
2023-06-27 10:38:05 - progress_bar.py[line:272] - INFO: epoch 006:   1329 / 2637 loss=2.157, loss_v1=0, loss_v2=0, nll_loss=0.935, ntokens=1226.5, nsentences=160, sample_size=1226.5, sample_size_v1=0, sample_size_v2=0, ppl=1.91, wps=588.4, ups=0.48, wpb=1226.5, bsz=160, num_updates=14490, lr=2.09541e-05, gnorm=4.642, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=30285
2023-06-27 10:38:26 - progress_bar.py[line:272] - INFO: epoch 006:   1339 / 2637 loss=2.173, loss_v1=0, loss_v2=0, nll_loss=0.952, ntokens=1231.1, nsentences=160, sample_size=1231.1, sample_size_v1=0, sample_size_v2=0, ppl=1.93, wps=591.2, ups=0.48, wpb=1231.1, bsz=160, num_updates=14500, lr=2.09465e-05, gnorm=5.231, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=30306
2023-06-27 10:38:47 - progress_bar.py[line:272] - INFO: epoch 006:   1349 / 2637 loss=2.175, loss_v1=0, loss_v2=0, nll_loss=0.957, ntokens=1224.1, nsentences=160, sample_size=1224.1, sample_size_v1=0, sample_size_v2=0, ppl=1.94, wps=587.7, ups=0.48, wpb=1224.1, bsz=160, num_updates=14510, lr=2.0939e-05, gnorm=4.589, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=30327
2023-06-27 10:39:07 - progress_bar.py[line:272] - INFO: epoch 006:   1359 / 2637 loss=2.173, loss_v1=0, loss_v2=0, nll_loss=0.949, ntokens=1247.8, nsentences=160, sample_size=1247.8, sample_size_v1=0, sample_size_v2=0, ppl=1.93, wps=599, ups=0.48, wpb=1247.8, bsz=160, num_updates=14520, lr=2.09314e-05, gnorm=4.437, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=30348
2023-06-27 10:39:28 - progress_bar.py[line:272] - INFO: epoch 006:   1369 / 2637 loss=2.197, loss_v1=0, loss_v2=0, nll_loss=0.981, ntokens=1233.5, nsentences=160, sample_size=1233.5, sample_size_v1=0, sample_size_v2=0, ppl=1.97, wps=592.3, ups=0.48, wpb=1233.5, bsz=160, num_updates=14530, lr=2.09238e-05, gnorm=5.297, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=30368
2023-06-27 10:39:49 - progress_bar.py[line:272] - INFO: epoch 006:   1379 / 2637 loss=2.164, loss_v1=0, loss_v2=0, nll_loss=0.943, ntokens=1228.8, nsentences=160, sample_size=1228.8, sample_size_v1=0, sample_size_v2=0, ppl=1.92, wps=590.4, ups=0.48, wpb=1228.8, bsz=160, num_updates=14540, lr=2.09163e-05, gnorm=4.708, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=30389
2023-06-27 10:40:10 - progress_bar.py[line:272] - INFO: epoch 006:   1389 / 2637 loss=2.167, loss_v1=0, loss_v2=0, nll_loss=0.946, ntokens=1273.1, nsentences=160, sample_size=1273.1, sample_size_v1=0, sample_size_v2=0, ppl=1.93, wps=611.5, ups=0.48, wpb=1273.1, bsz=160, num_updates=14550, lr=2.09087e-05, gnorm=4.201, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=30410
2023-06-27 10:40:31 - progress_bar.py[line:272] - INFO: epoch 006:   1399 / 2637 loss=2.159, loss_v1=0, loss_v2=0, nll_loss=0.938, ntokens=1274.1, nsentences=160, sample_size=1274.1, sample_size_v1=0, sample_size_v2=0, ppl=1.92, wps=611.7, ups=0.48, wpb=1274.1, bsz=160, num_updates=14560, lr=2.09011e-05, gnorm=4.636, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=30431
2023-06-27 10:40:51 - progress_bar.py[line:272] - INFO: epoch 006:   1409 / 2637 loss=2.183, loss_v1=0, loss_v2=0, nll_loss=0.963, ntokens=1271.6, nsentences=160, sample_size=1271.6, sample_size_v1=0, sample_size_v2=0, ppl=1.95, wps=610.1, ups=0.48, wpb=1271.6, bsz=160, num_updates=14570, lr=2.08936e-05, gnorm=4.526, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=30452
2023-06-27 10:41:12 - progress_bar.py[line:272] - INFO: epoch 006:   1419 / 2637 loss=2.179, loss_v1=0, loss_v2=0, nll_loss=0.956, ntokens=1268.9, nsentences=160, sample_size=1268.9, sample_size_v1=0, sample_size_v2=0, ppl=1.94, wps=609.4, ups=0.48, wpb=1268.9, bsz=160, num_updates=14580, lr=2.0886e-05, gnorm=4.824, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=30473
2023-06-27 10:41:33 - progress_bar.py[line:272] - INFO: epoch 006:   1429 / 2637 loss=2.154, loss_v1=0, loss_v2=0, nll_loss=0.931, ntokens=1283.5, nsentences=160, sample_size=1283.5, sample_size_v1=0, sample_size_v2=0, ppl=1.91, wps=616, ups=0.48, wpb=1283.5, bsz=160, num_updates=14590, lr=2.08784e-05, gnorm=4.125, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=30493
2023-06-27 10:41:54 - progress_bar.py[line:272] - INFO: epoch 006:   1439 / 2637 loss=2.168, loss_v1=0, loss_v2=0, nll_loss=0.947, ntokens=1267, nsentences=160, sample_size=1267, sample_size_v1=0, sample_size_v2=0, ppl=1.93, wps=608.7, ups=0.48, wpb=1267, bsz=160, num_updates=14600, lr=2.08709e-05, gnorm=4.1, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=30514
2023-06-27 10:42:15 - progress_bar.py[line:272] - INFO: epoch 006:   1449 / 2637 loss=2.187, loss_v1=0, loss_v2=0, nll_loss=0.968, ntokens=1287.5, nsentences=160, sample_size=1287.5, sample_size_v1=0, sample_size_v2=0, ppl=1.96, wps=618.3, ups=0.48, wpb=1287.5, bsz=160, num_updates=14610, lr=2.08633e-05, gnorm=4.641, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=30535
2023-06-27 10:42:36 - progress_bar.py[line:272] - INFO: epoch 006:   1459 / 2637 loss=2.187, loss_v1=0, loss_v2=0, nll_loss=0.966, ntokens=1286, nsentences=160, sample_size=1286, sample_size_v1=0, sample_size_v2=0, ppl=1.95, wps=617.3, ups=0.48, wpb=1286, bsz=160, num_updates=14620, lr=2.08558e-05, gnorm=4.428, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=30556
2023-06-27 10:42:56 - progress_bar.py[line:272] - INFO: epoch 006:   1469 / 2637 loss=2.168, loss_v1=0, loss_v2=0, nll_loss=0.947, ntokens=1261.8, nsentences=160, sample_size=1261.8, sample_size_v1=0, sample_size_v2=0, ppl=1.93, wps=605.8, ups=0.48, wpb=1261.8, bsz=160, num_updates=14630, lr=2.08482e-05, gnorm=4.27, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=30577
2023-06-27 10:43:17 - progress_bar.py[line:272] - INFO: epoch 006:   1479 / 2637 loss=2.166, loss_v1=0, loss_v2=0, nll_loss=0.945, ntokens=1272.4, nsentences=160, sample_size=1272.4, sample_size_v1=0, sample_size_v2=0, ppl=1.92, wps=610.6, ups=0.48, wpb=1272.4, bsz=160, num_updates=14640, lr=2.08406e-05, gnorm=4.828, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=30598
2023-06-27 10:43:38 - progress_bar.py[line:272] - INFO: epoch 006:   1489 / 2637 loss=2.188, loss_v1=0, loss_v2=0, nll_loss=0.971, ntokens=1285.9, nsentences=160, sample_size=1285.9, sample_size_v1=0, sample_size_v2=0, ppl=1.96, wps=617.5, ups=0.48, wpb=1285.9, bsz=160, num_updates=14650, lr=2.08331e-05, gnorm=4.63, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=30618
2023-06-27 10:43:59 - progress_bar.py[line:272] - INFO: epoch 006:   1499 / 2637 loss=2.184, loss_v1=0, loss_v2=0, nll_loss=0.966, ntokens=1287.4, nsentences=160, sample_size=1287.4, sample_size_v1=0, sample_size_v2=0, ppl=1.95, wps=617.9, ups=0.48, wpb=1287.4, bsz=160, num_updates=14660, lr=2.08255e-05, gnorm=4.301, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=30639
2023-06-27 10:44:20 - progress_bar.py[line:272] - INFO: epoch 006:   1509 / 2637 loss=2.18, loss_v1=0, loss_v2=0, nll_loss=0.959, ntokens=1281.1, nsentences=160, sample_size=1281.1, sample_size_v1=0, sample_size_v2=0, ppl=1.94, wps=615.3, ups=0.48, wpb=1281.1, bsz=160, num_updates=14670, lr=2.08179e-05, gnorm=4.998, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=30660
2023-06-27 10:44:41 - progress_bar.py[line:272] - INFO: epoch 006:   1519 / 2637 loss=2.178, loss_v1=0, loss_v2=0, nll_loss=0.958, ntokens=1266.3, nsentences=160, sample_size=1266.3, sample_size_v1=0, sample_size_v2=0, ppl=1.94, wps=608.1, ups=0.48, wpb=1266.3, bsz=160, num_updates=14680, lr=2.08104e-05, gnorm=4.927, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=30681
2023-06-27 10:45:01 - progress_bar.py[line:272] - INFO: epoch 006:   1529 / 2637 loss=2.2, loss_v1=0, loss_v2=0, nll_loss=0.98, ntokens=1257.9, nsentences=160, sample_size=1257.9, sample_size_v1=0, sample_size_v2=0, ppl=1.97, wps=603.5, ups=0.48, wpb=1257.9, bsz=160, num_updates=14690, lr=2.08028e-05, gnorm=5.077, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=30702
2023-06-27 10:45:22 - progress_bar.py[line:272] - INFO: epoch 006:   1539 / 2637 loss=2.182, loss_v1=0, loss_v2=0, nll_loss=0.963, ntokens=1265.4, nsentences=160, sample_size=1265.4, sample_size_v1=0, sample_size_v2=0, ppl=1.95, wps=607.1, ups=0.48, wpb=1265.4, bsz=160, num_updates=14700, lr=2.07952e-05, gnorm=4.383, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=30723
2023-06-27 10:45:43 - progress_bar.py[line:272] - INFO: epoch 006:   1549 / 2637 loss=2.193, loss_v1=0, loss_v2=0, nll_loss=0.974, ntokens=1265, nsentences=160, sample_size=1265, sample_size_v1=0, sample_size_v2=0, ppl=1.96, wps=607.1, ups=0.48, wpb=1265, bsz=160, num_updates=14710, lr=2.07877e-05, gnorm=3.907, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=30743
2023-06-27 10:46:04 - progress_bar.py[line:272] - INFO: epoch 006:   1559 / 2637 loss=2.187, loss_v1=0, loss_v2=0, nll_loss=0.969, ntokens=1276.7, nsentences=160, sample_size=1276.7, sample_size_v1=0, sample_size_v2=0, ppl=1.96, wps=613, ups=0.48, wpb=1276.7, bsz=160, num_updates=14720, lr=2.07801e-05, gnorm=4.531, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=30764
2023-06-27 10:46:25 - progress_bar.py[line:272] - INFO: epoch 006:   1569 / 2637 loss=2.168, loss_v1=0, loss_v2=0, nll_loss=0.945, ntokens=1265, nsentences=160, sample_size=1265, sample_size_v1=0, sample_size_v2=0, ppl=1.93, wps=607.8, ups=0.48, wpb=1265, bsz=160, num_updates=14730, lr=2.07725e-05, gnorm=4.497, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=30785
2023-06-27 10:46:46 - progress_bar.py[line:272] - INFO: epoch 006:   1579 / 2637 loss=2.178, loss_v1=0, loss_v2=0, nll_loss=0.957, ntokens=1270.9, nsentences=160, sample_size=1270.9, sample_size_v1=0, sample_size_v2=0, ppl=1.94, wps=610.1, ups=0.48, wpb=1270.9, bsz=160, num_updates=14740, lr=2.0765e-05, gnorm=4.449, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=30806
2023-06-27 10:47:06 - progress_bar.py[line:272] - INFO: epoch 006:   1589 / 2637 loss=2.183, loss_v1=0, loss_v2=0, nll_loss=0.962, ntokens=1267.3, nsentences=160, sample_size=1267.3, sample_size_v1=0, sample_size_v2=0, ppl=1.95, wps=608.2, ups=0.48, wpb=1267.3, bsz=160, num_updates=14750, lr=2.07574e-05, gnorm=5.007, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=30827
2023-06-27 10:47:27 - progress_bar.py[line:272] - INFO: epoch 006:   1599 / 2637 loss=2.187, loss_v1=0, loss_v2=0, nll_loss=0.97, ntokens=1270.2, nsentences=160, sample_size=1270.2, sample_size_v1=0, sample_size_v2=0, ppl=1.96, wps=609.5, ups=0.48, wpb=1270.2, bsz=160, num_updates=14760, lr=2.07499e-05, gnorm=5.06, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=30848
2023-06-27 10:47:48 - progress_bar.py[line:272] - INFO: epoch 006:   1609 / 2637 loss=2.194, loss_v1=0, loss_v2=0, nll_loss=0.976, ntokens=1256.2, nsentences=160, sample_size=1256.2, sample_size_v1=0, sample_size_v2=0, ppl=1.97, wps=603, ups=0.48, wpb=1256.2, bsz=160, num_updates=14770, lr=2.07423e-05, gnorm=4.463, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=30868
2023-06-27 10:48:09 - progress_bar.py[line:272] - INFO: epoch 006:   1619 / 2637 loss=2.202, loss_v1=0, loss_v2=0, nll_loss=0.985, ntokens=1266, nsentences=160, sample_size=1266, sample_size_v1=0, sample_size_v2=0, ppl=1.98, wps=607.7, ups=0.48, wpb=1266, bsz=160, num_updates=14780, lr=2.07347e-05, gnorm=3.993, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=30889
2023-06-27 10:48:30 - progress_bar.py[line:272] - INFO: epoch 006:   1629 / 2637 loss=2.184, loss_v1=0, loss_v2=0, nll_loss=0.963, ntokens=1268.1, nsentences=160, sample_size=1268.1, sample_size_v1=0, sample_size_v2=0, ppl=1.95, wps=609.2, ups=0.48, wpb=1268.1, bsz=160, num_updates=14790, lr=2.07272e-05, gnorm=4.704, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=30910
2023-06-27 10:48:51 - progress_bar.py[line:272] - INFO: epoch 006:   1639 / 2637 loss=2.174, loss_v1=0, loss_v2=0, nll_loss=0.953, ntokens=1262.3, nsentences=160, sample_size=1262.3, sample_size_v1=0, sample_size_v2=0, ppl=1.94, wps=606.4, ups=0.48, wpb=1262.3, bsz=160, num_updates=14800, lr=2.07196e-05, gnorm=4.214, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=30931
2023-06-27 10:49:11 - progress_bar.py[line:272] - INFO: epoch 006:   1649 / 2637 loss=2.18, loss_v1=0, loss_v2=0, nll_loss=0.961, ntokens=1264.7, nsentences=160, sample_size=1264.7, sample_size_v1=0, sample_size_v2=0, ppl=1.95, wps=607.7, ups=0.48, wpb=1264.7, bsz=160, num_updates=14810, lr=2.0712e-05, gnorm=4.846, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=30952
2023-06-27 10:49:32 - progress_bar.py[line:272] - INFO: epoch 006:   1659 / 2637 loss=2.205, loss_v1=0, loss_v2=0, nll_loss=0.988, ntokens=1279.5, nsentences=160, sample_size=1279.5, sample_size_v1=0, sample_size_v2=0, ppl=1.98, wps=614.4, ups=0.48, wpb=1279.5, bsz=160, num_updates=14820, lr=2.07045e-05, gnorm=4.634, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=30973
2023-06-27 10:49:53 - progress_bar.py[line:272] - INFO: epoch 006:   1669 / 2637 loss=2.166, loss_v1=0, loss_v2=0, nll_loss=0.944, ntokens=1252.8, nsentences=160, sample_size=1252.8, sample_size_v1=0, sample_size_v2=0, ppl=1.92, wps=602.1, ups=0.48, wpb=1252.8, bsz=160, num_updates=14830, lr=2.06969e-05, gnorm=4.689, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=30993
2023-06-27 10:50:14 - progress_bar.py[line:272] - INFO: epoch 006:   1679 / 2637 loss=2.177, loss_v1=0, loss_v2=0, nll_loss=0.956, ntokens=1265.6, nsentences=160, sample_size=1265.6, sample_size_v1=0, sample_size_v2=0, ppl=1.94, wps=608, ups=0.48, wpb=1265.6, bsz=160, num_updates=14840, lr=2.06893e-05, gnorm=4.691, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=31014
2023-06-27 10:50:35 - progress_bar.py[line:272] - INFO: epoch 006:   1689 / 2637 loss=2.158, loss_v1=0, loss_v2=0, nll_loss=0.936, ntokens=1280.5, nsentences=160, sample_size=1280.5, sample_size_v1=0, sample_size_v2=0, ppl=1.91, wps=614.8, ups=0.48, wpb=1280.5, bsz=160, num_updates=14850, lr=2.06818e-05, gnorm=4.91, clip=100, loss_scale=128, train_wall=21, gb_free=8.9, wall=31035
2023-06-27 10:50:56 - progress_bar.py[line:272] - INFO: epoch 006:   1699 / 2637 loss=2.189, loss_v1=0, loss_v2=0, nll_loss=0.97, ntokens=1268.5, nsentences=160, sample_size=1268.5, sample_size_v1=0, sample_size_v2=0, ppl=1.96, wps=609.7, ups=0.48, wpb=1268.5, bsz=160, num_updates=14860, lr=2.06742e-05, gnorm=4.589, clip=100, loss_scale=128, train_wall=21, gb_free=8.9, wall=31056
2023-06-27 10:51:14 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2023-06-27 10:51:18 - progress_bar.py[line:272] - INFO: epoch 006:   1710 / 2637 loss=2.163, loss_v1=0, loss_v2=0, nll_loss=0.941, ntokens=1280.9, nsentences=160, sample_size=1280.9, sample_size_v1=0, sample_size_v2=0, ppl=1.92, wps=558.6, ups=0.44, wpb=1280.9, bsz=160, num_updates=14870, lr=2.06666e-05, gnorm=4.648, clip=100, loss_scale=64, train_wall=23, gb_free=8.9, wall=31079
2023-06-27 10:51:39 - progress_bar.py[line:272] - INFO: epoch 006:   1720 / 2637 loss=2.184, loss_v1=0, loss_v2=0, nll_loss=0.967, ntokens=1274.5, nsentences=160, sample_size=1274.5, sample_size_v1=0, sample_size_v2=0, ppl=1.95, wps=610.6, ups=0.48, wpb=1274.5, bsz=160, num_updates=14880, lr=2.06591e-05, gnorm=4.621, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=31100
2023-06-27 10:52:00 - progress_bar.py[line:272] - INFO: epoch 006:   1730 / 2637 loss=2.176, loss_v1=0, loss_v2=0, nll_loss=0.957, ntokens=1274.8, nsentences=160, sample_size=1274.8, sample_size_v1=0, sample_size_v2=0, ppl=1.94, wps=611.4, ups=0.48, wpb=1274.8, bsz=160, num_updates=14890, lr=2.06515e-05, gnorm=4.649, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=31120
2023-06-27 10:52:21 - progress_bar.py[line:272] - INFO: epoch 006:   1740 / 2637 loss=2.156, loss_v1=0, loss_v2=0, nll_loss=0.935, ntokens=1275.5, nsentences=160, sample_size=1275.5, sample_size_v1=0, sample_size_v2=0, ppl=1.91, wps=611.4, ups=0.48, wpb=1275.5, bsz=160, num_updates=14900, lr=2.0644e-05, gnorm=4.241, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=31141
2023-06-27 10:52:42 - progress_bar.py[line:272] - INFO: epoch 006:   1750 / 2637 loss=2.205, loss_v1=0, loss_v2=0, nll_loss=0.986, ntokens=1265.2, nsentences=159.9, sample_size=1265.2, sample_size_v1=0, sample_size_v2=0, ppl=1.98, wps=607, ups=0.48, wpb=1265.2, bsz=159.9, num_updates=14910, lr=2.06364e-05, gnorm=4.69, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=31162
2023-06-27 10:53:03 - progress_bar.py[line:272] - INFO: epoch 006:   1760 / 2637 loss=2.142, loss_v1=0, loss_v2=0, nll_loss=0.916, ntokens=1274.8, nsentences=160, sample_size=1274.8, sample_size_v1=0, sample_size_v2=0, ppl=1.89, wps=611, ups=0.48, wpb=1274.8, bsz=160, num_updates=14920, lr=2.06288e-05, gnorm=3.955, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=31183
2023-06-27 10:53:24 - progress_bar.py[line:272] - INFO: epoch 006:   1770 / 2637 loss=2.201, loss_v1=0, loss_v2=0, nll_loss=0.983, ntokens=1271.4, nsentences=160, sample_size=1271.4, sample_size_v1=0, sample_size_v2=0, ppl=1.98, wps=609.7, ups=0.48, wpb=1271.4, bsz=160, num_updates=14930, lr=2.06213e-05, gnorm=4.179, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=31204
2023-06-27 10:53:45 - progress_bar.py[line:272] - INFO: epoch 006:   1780 / 2637 loss=2.167, loss_v1=0, loss_v2=0, nll_loss=0.946, ntokens=1274.6, nsentences=160, sample_size=1274.6, sample_size_v1=0, sample_size_v2=0, ppl=1.93, wps=610.5, ups=0.48, wpb=1274.6, bsz=160, num_updates=14940, lr=2.06137e-05, gnorm=4.909, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=31225
2023-06-27 10:54:05 - progress_bar.py[line:272] - INFO: epoch 006:   1790 / 2637 loss=2.166, loss_v1=0, loss_v2=0, nll_loss=0.944, ntokens=1295.7, nsentences=160, sample_size=1295.7, sample_size_v1=0, sample_size_v2=0, ppl=1.92, wps=620.4, ups=0.48, wpb=1295.7, bsz=160, num_updates=14950, lr=2.06061e-05, gnorm=4.301, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=31246
2023-06-27 10:54:26 - progress_bar.py[line:272] - INFO: epoch 006:   1800 / 2637 loss=2.21, loss_v1=0, loss_v2=0, nll_loss=0.994, ntokens=1260.5, nsentences=160, sample_size=1260.5, sample_size_v1=0, sample_size_v2=0, ppl=1.99, wps=603.8, ups=0.48, wpb=1260.5, bsz=160, num_updates=14960, lr=2.05986e-05, gnorm=5.073, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=31267
2023-06-27 10:54:47 - progress_bar.py[line:272] - INFO: epoch 006:   1810 / 2637 loss=2.163, loss_v1=0, loss_v2=0, nll_loss=0.941, ntokens=1284.9, nsentences=160, sample_size=1284.9, sample_size_v1=0, sample_size_v2=0, ppl=1.92, wps=615.7, ups=0.48, wpb=1284.9, bsz=160, num_updates=14970, lr=2.0591e-05, gnorm=4.399, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=31287
2023-06-27 10:55:08 - progress_bar.py[line:272] - INFO: epoch 006:   1820 / 2637 loss=2.171, loss_v1=0, loss_v2=0, nll_loss=0.95, ntokens=1262.5, nsentences=160, sample_size=1262.5, sample_size_v1=0, sample_size_v2=0, ppl=1.93, wps=605.3, ups=0.48, wpb=1262.5, bsz=160, num_updates=14980, lr=2.05834e-05, gnorm=4.521, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=31308
2023-06-27 10:55:29 - progress_bar.py[line:272] - INFO: epoch 006:   1830 / 2637 loss=2.169, loss_v1=0, loss_v2=0, nll_loss=0.949, ntokens=1272.8, nsentences=160, sample_size=1272.8, sample_size_v1=0, sample_size_v2=0, ppl=1.93, wps=610.4, ups=0.48, wpb=1272.8, bsz=160, num_updates=14990, lr=2.05759e-05, gnorm=4.941, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=31329
2023-06-27 10:55:50 - progress_bar.py[line:272] - INFO: epoch 006:   1840 / 2637 loss=2.168, loss_v1=0, loss_v2=0, nll_loss=0.945, ntokens=1302, nsentences=160, sample_size=1302, sample_size_v1=0, sample_size_v2=0, ppl=1.93, wps=623.8, ups=0.48, wpb=1302, bsz=160, num_updates=15000, lr=2.05683e-05, gnorm=4.75, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=31350
2023-06-27 10:56:11 - progress_bar.py[line:272] - INFO: epoch 006:   1850 / 2637 loss=2.176, loss_v1=0, loss_v2=0, nll_loss=0.955, ntokens=1275, nsentences=160, sample_size=1275, sample_size_v1=0, sample_size_v2=0, ppl=1.94, wps=610.8, ups=0.48, wpb=1275, bsz=160, num_updates=15010, lr=2.05608e-05, gnorm=4.991, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=31371
2023-06-27 10:56:32 - progress_bar.py[line:272] - INFO: epoch 006:   1860 / 2637 loss=2.166, loss_v1=0, loss_v2=0, nll_loss=0.944, ntokens=1266.5, nsentences=160, sample_size=1266.5, sample_size_v1=0, sample_size_v2=0, ppl=1.92, wps=606.6, ups=0.48, wpb=1266.5, bsz=160, num_updates=15020, lr=2.05532e-05, gnorm=4.162, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=31392
2023-06-27 10:56:52 - progress_bar.py[line:272] - INFO: epoch 006:   1870 / 2637 loss=2.179, loss_v1=0, loss_v2=0, nll_loss=0.959, ntokens=1265.1, nsentences=160, sample_size=1265.1, sample_size_v1=0, sample_size_v2=0, ppl=1.94, wps=606.3, ups=0.48, wpb=1265.1, bsz=160, num_updates=15030, lr=2.05456e-05, gnorm=5.081, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=31413
2023-06-27 10:57:13 - progress_bar.py[line:272] - INFO: epoch 006:   1880 / 2637 loss=2.159, loss_v1=0, loss_v2=0, nll_loss=0.937, ntokens=1289.1, nsentences=160, sample_size=1289.1, sample_size_v1=0, sample_size_v2=0, ppl=1.91, wps=617.6, ups=0.48, wpb=1289.1, bsz=160, num_updates=15040, lr=2.05381e-05, gnorm=4.187, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=31434
2023-06-27 10:57:34 - progress_bar.py[line:272] - INFO: epoch 006:   1890 / 2637 loss=2.137, loss_v1=0, loss_v2=0, nll_loss=0.91, ntokens=1267.7, nsentences=160, sample_size=1267.7, sample_size_v1=0, sample_size_v2=0, ppl=1.88, wps=608, ups=0.48, wpb=1267.7, bsz=160, num_updates=15050, lr=2.05305e-05, gnorm=4.25, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=31454
2023-06-27 10:57:55 - progress_bar.py[line:272] - INFO: epoch 006:   1900 / 2637 loss=2.165, loss_v1=0, loss_v2=0, nll_loss=0.944, ntokens=1293.1, nsentences=160, sample_size=1293.1, sample_size_v1=0, sample_size_v2=0, ppl=1.92, wps=619.8, ups=0.48, wpb=1293.1, bsz=160, num_updates=15060, lr=2.05229e-05, gnorm=4.178, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=31475
2023-06-27 10:58:16 - progress_bar.py[line:272] - INFO: epoch 006:   1910 / 2637 loss=2.158, loss_v1=0, loss_v2=0, nll_loss=0.937, ntokens=1254, nsentences=160, sample_size=1254, sample_size_v1=0, sample_size_v2=0, ppl=1.91, wps=600.9, ups=0.48, wpb=1254, bsz=160, num_updates=15070, lr=2.05154e-05, gnorm=4.964, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=31496
2023-06-27 10:58:37 - progress_bar.py[line:272] - INFO: epoch 006:   1920 / 2637 loss=2.165, loss_v1=0, loss_v2=0, nll_loss=0.944, ntokens=1281.1, nsentences=160, sample_size=1281.1, sample_size_v1=0, sample_size_v2=0, ppl=1.92, wps=614.1, ups=0.48, wpb=1281.1, bsz=160, num_updates=15080, lr=2.05078e-05, gnorm=4.262, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=31517
2023-06-27 10:58:58 - progress_bar.py[line:272] - INFO: epoch 006:   1930 / 2637 loss=2.184, loss_v1=0, loss_v2=0, nll_loss=0.963, ntokens=1260.1, nsentences=160, sample_size=1260.1, sample_size_v1=0, sample_size_v2=0, ppl=1.95, wps=603.5, ups=0.48, wpb=1260.1, bsz=160, num_updates=15090, lr=2.05002e-05, gnorm=4.655, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=31538
2023-06-27 10:59:18 - progress_bar.py[line:272] - INFO: epoch 006:   1940 / 2637 loss=2.15, loss_v1=0, loss_v2=0, nll_loss=0.925, ntokens=1285, nsentences=160, sample_size=1285, sample_size_v1=0, sample_size_v2=0, ppl=1.9, wps=615.7, ups=0.48, wpb=1285, bsz=160, num_updates=15100, lr=2.04927e-05, gnorm=4.543, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=31559
2023-06-27 10:59:39 - progress_bar.py[line:272] - INFO: epoch 006:   1950 / 2637 loss=2.195, loss_v1=0, loss_v2=0, nll_loss=0.978, ntokens=1283.4, nsentences=160, sample_size=1283.4, sample_size_v1=0, sample_size_v2=0, ppl=1.97, wps=614.9, ups=0.48, wpb=1283.4, bsz=160, num_updates=15110, lr=2.04851e-05, gnorm=4.618, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=31580
2023-06-27 11:00:00 - progress_bar.py[line:272] - INFO: epoch 006:   1960 / 2637 loss=2.171, loss_v1=0, loss_v2=0, nll_loss=0.95, ntokens=1269.9, nsentences=160, sample_size=1269.9, sample_size_v1=0, sample_size_v2=0, ppl=1.93, wps=609, ups=0.48, wpb=1269.9, bsz=160, num_updates=15120, lr=2.04775e-05, gnorm=4.628, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=31600
2023-06-27 11:00:21 - progress_bar.py[line:272] - INFO: epoch 006:   1970 / 2637 loss=2.185, loss_v1=0, loss_v2=0, nll_loss=0.964, ntokens=1270.6, nsentences=160, sample_size=1270.6, sample_size_v1=0, sample_size_v2=0, ppl=1.95, wps=608.4, ups=0.48, wpb=1270.6, bsz=160, num_updates=15130, lr=2.047e-05, gnorm=4.486, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=31621
2023-06-27 11:00:42 - progress_bar.py[line:272] - INFO: epoch 006:   1980 / 2637 loss=2.213, loss_v1=0, loss_v2=0, nll_loss=0.998, ntokens=1278.1, nsentences=160, sample_size=1278.1, sample_size_v1=0, sample_size_v2=0, ppl=2, wps=612.4, ups=0.48, wpb=1278.1, bsz=160, num_updates=15140, lr=2.04624e-05, gnorm=4.47, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=31642
2023-06-27 11:01:03 - progress_bar.py[line:272] - INFO: epoch 006:   1990 / 2637 loss=2.149, loss_v1=0, loss_v2=0, nll_loss=0.927, ntokens=1302.2, nsentences=160, sample_size=1302.2, sample_size_v1=0, sample_size_v2=0, ppl=1.9, wps=624.3, ups=0.48, wpb=1302.2, bsz=160, num_updates=15150, lr=2.04549e-05, gnorm=4.689, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=31663
2023-06-27 11:01:24 - progress_bar.py[line:272] - INFO: epoch 006:   2000 / 2637 loss=2.176, loss_v1=0, loss_v2=0, nll_loss=0.954, ntokens=1274.5, nsentences=160, sample_size=1274.5, sample_size_v1=0, sample_size_v2=0, ppl=1.94, wps=610.7, ups=0.48, wpb=1274.5, bsz=160, num_updates=15160, lr=2.04473e-05, gnorm=4.197, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=31684
2023-06-27 11:01:45 - progress_bar.py[line:272] - INFO: epoch 006:   2010 / 2637 loss=2.17, loss_v1=0, loss_v2=0, nll_loss=0.95, ntokens=1261, nsentences=160, sample_size=1261, sample_size_v1=0, sample_size_v2=0, ppl=1.93, wps=604.2, ups=0.48, wpb=1261, bsz=160, num_updates=15170, lr=2.04397e-05, gnorm=4.855, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=31705
2023-06-27 11:02:05 - progress_bar.py[line:272] - INFO: epoch 006:   2020 / 2637 loss=2.173, loss_v1=0, loss_v2=0, nll_loss=0.954, ntokens=1304.6, nsentences=160, sample_size=1304.6, sample_size_v1=0, sample_size_v2=0, ppl=1.94, wps=625.3, ups=0.48, wpb=1304.6, bsz=160, num_updates=15180, lr=2.04322e-05, gnorm=4.874, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=31726
2023-06-27 11:02:26 - progress_bar.py[line:272] - INFO: epoch 006:   2030 / 2637 loss=2.145, loss_v1=0, loss_v2=0, nll_loss=0.922, ntokens=1265.6, nsentences=160, sample_size=1265.6, sample_size_v1=0, sample_size_v2=0, ppl=1.89, wps=606.5, ups=0.48, wpb=1265.6, bsz=160, num_updates=15190, lr=2.04246e-05, gnorm=4.479, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=31747
2023-06-27 11:02:47 - progress_bar.py[line:272] - INFO: epoch 006:   2040 / 2637 loss=2.149, loss_v1=0, loss_v2=0, nll_loss=0.925, ntokens=1278.2, nsentences=160, sample_size=1278.2, sample_size_v1=0, sample_size_v2=0, ppl=1.9, wps=613.1, ups=0.48, wpb=1278.2, bsz=160, num_updates=15200, lr=2.0417e-05, gnorm=4.265, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=31767
2023-06-27 11:03:08 - progress_bar.py[line:272] - INFO: epoch 006:   2050 / 2637 loss=2.154, loss_v1=0, loss_v2=0, nll_loss=0.932, ntokens=1276.1, nsentences=160, sample_size=1276.1, sample_size_v1=0, sample_size_v2=0, ppl=1.91, wps=611.4, ups=0.48, wpb=1276.1, bsz=160, num_updates=15210, lr=2.04095e-05, gnorm=4.375, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=31788
2023-06-27 11:03:29 - progress_bar.py[line:272] - INFO: epoch 006:   2060 / 2637 loss=2.159, loss_v1=0, loss_v2=0, nll_loss=0.937, ntokens=1253.3, nsentences=160, sample_size=1253.3, sample_size_v1=0, sample_size_v2=0, ppl=1.91, wps=600.5, ups=0.48, wpb=1253.3, bsz=160, num_updates=15220, lr=2.04019e-05, gnorm=4.875, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=31809
2023-06-27 11:03:50 - progress_bar.py[line:272] - INFO: epoch 006:   2070 / 2637 loss=2.18, loss_v1=0, loss_v2=0, nll_loss=0.961, ntokens=1263.2, nsentences=160, sample_size=1263.2, sample_size_v1=0, sample_size_v2=0, ppl=1.95, wps=605.3, ups=0.48, wpb=1263.2, bsz=160, num_updates=15230, lr=2.03943e-05, gnorm=5.752, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=31830
2023-06-27 11:04:11 - progress_bar.py[line:272] - INFO: epoch 006:   2080 / 2637 loss=2.185, loss_v1=0, loss_v2=0, nll_loss=0.966, ntokens=1262.4, nsentences=160, sample_size=1262.4, sample_size_v1=0, sample_size_v2=0, ppl=1.95, wps=605, ups=0.48, wpb=1262.4, bsz=160, num_updates=15240, lr=2.03868e-05, gnorm=5.65, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=31851
2023-06-27 11:04:32 - progress_bar.py[line:272] - INFO: epoch 006:   2090 / 2637 loss=2.17, loss_v1=0, loss_v2=0, nll_loss=0.95, ntokens=1252.4, nsentences=160, sample_size=1252.4, sample_size_v1=0, sample_size_v2=0, ppl=1.93, wps=600.6, ups=0.48, wpb=1252.4, bsz=160, num_updates=15250, lr=2.03792e-05, gnorm=5.45, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=31872
2023-06-27 11:04:52 - progress_bar.py[line:272] - INFO: epoch 006:   2100 / 2637 loss=2.164, loss_v1=0, loss_v2=0, nll_loss=0.943, ntokens=1256.3, nsentences=160, sample_size=1256.3, sample_size_v1=0, sample_size_v2=0, ppl=1.92, wps=602.4, ups=0.48, wpb=1256.3, bsz=160, num_updates=15260, lr=2.03716e-05, gnorm=5.082, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=31893
2023-06-27 11:05:13 - progress_bar.py[line:272] - INFO: epoch 006:   2110 / 2637 loss=2.183, loss_v1=0, loss_v2=0, nll_loss=0.964, ntokens=1256.3, nsentences=160, sample_size=1256.3, sample_size_v1=0, sample_size_v2=0, ppl=1.95, wps=601.6, ups=0.48, wpb=1256.3, bsz=160, num_updates=15270, lr=2.03641e-05, gnorm=4.889, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=31914
2023-06-27 11:05:34 - progress_bar.py[line:272] - INFO: epoch 006:   2120 / 2637 loss=2.166, loss_v1=0, loss_v2=0, nll_loss=0.946, ntokens=1268, nsentences=160, sample_size=1268, sample_size_v1=0, sample_size_v2=0, ppl=1.93, wps=607.2, ups=0.48, wpb=1268, bsz=160, num_updates=15280, lr=2.03565e-05, gnorm=4.735, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=31934
2023-06-27 11:05:55 - progress_bar.py[line:272] - INFO: epoch 006:   2130 / 2637 loss=2.169, loss_v1=0, loss_v2=0, nll_loss=0.949, ntokens=1252.9, nsentences=160, sample_size=1252.9, sample_size_v1=0, sample_size_v2=0, ppl=1.93, wps=600.2, ups=0.48, wpb=1252.9, bsz=160, num_updates=15290, lr=2.0349e-05, gnorm=4.432, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=31955
2023-06-27 11:06:16 - progress_bar.py[line:272] - INFO: epoch 006:   2140 / 2637 loss=2.16, loss_v1=0, loss_v2=0, nll_loss=0.937, ntokens=1260.5, nsentences=160, sample_size=1260.5, sample_size_v1=0, sample_size_v2=0, ppl=1.91, wps=603.8, ups=0.48, wpb=1260.5, bsz=160, num_updates=15300, lr=2.03414e-05, gnorm=4.932, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=31976
2023-06-27 11:06:37 - progress_bar.py[line:272] - INFO: epoch 006:   2150 / 2637 loss=2.172, loss_v1=0, loss_v2=0, nll_loss=0.95, ntokens=1269.2, nsentences=160, sample_size=1269.2, sample_size_v1=0, sample_size_v2=0, ppl=1.93, wps=607.6, ups=0.48, wpb=1269.2, bsz=160, num_updates=15310, lr=2.03338e-05, gnorm=4.515, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=31997
2023-06-27 11:06:58 - progress_bar.py[line:272] - INFO: epoch 006:   2160 / 2637 loss=2.162, loss_v1=0, loss_v2=0, nll_loss=0.94, ntokens=1263.7, nsentences=160, sample_size=1263.7, sample_size_v1=0, sample_size_v2=0, ppl=1.92, wps=605.7, ups=0.48, wpb=1263.7, bsz=160, num_updates=15320, lr=2.03263e-05, gnorm=4.233, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=32018
2023-06-27 11:07:19 - progress_bar.py[line:272] - INFO: epoch 006:   2170 / 2637 loss=2.16, loss_v1=0, loss_v2=0, nll_loss=0.939, ntokens=1267, nsentences=160, sample_size=1267, sample_size_v1=0, sample_size_v2=0, ppl=1.92, wps=607.9, ups=0.48, wpb=1267, bsz=160, num_updates=15330, lr=2.03187e-05, gnorm=4.602, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=32039
2023-06-27 11:07:39 - progress_bar.py[line:272] - INFO: epoch 006:   2180 / 2637 loss=2.157, loss_v1=0, loss_v2=0, nll_loss=0.934, ntokens=1262.8, nsentences=160, sample_size=1262.8, sample_size_v1=0, sample_size_v2=0, ppl=1.91, wps=606, ups=0.48, wpb=1262.8, bsz=160, num_updates=15340, lr=2.03111e-05, gnorm=4.834, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=32060
2023-06-27 11:08:00 - progress_bar.py[line:272] - INFO: epoch 006:   2190 / 2637 loss=2.17, loss_v1=0, loss_v2=0, nll_loss=0.948, ntokens=1273.7, nsentences=160, sample_size=1273.7, sample_size_v1=0, sample_size_v2=0, ppl=1.93, wps=610, ups=0.48, wpb=1273.7, bsz=160, num_updates=15350, lr=2.03036e-05, gnorm=4.767, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=32081
2023-06-27 11:08:21 - progress_bar.py[line:272] - INFO: epoch 006:   2200 / 2637 loss=2.151, loss_v1=0, loss_v2=0, nll_loss=0.928, ntokens=1260.3, nsentences=160, sample_size=1260.3, sample_size_v1=0, sample_size_v2=0, ppl=1.9, wps=605.3, ups=0.48, wpb=1260.3, bsz=160, num_updates=15360, lr=2.0296e-05, gnorm=4.982, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=32101
2023-06-27 11:08:42 - progress_bar.py[line:272] - INFO: epoch 006:   2210 / 2637 loss=2.137, loss_v1=0, loss_v2=0, nll_loss=0.912, ntokens=1269.8, nsentences=160, sample_size=1269.8, sample_size_v1=0, sample_size_v2=0, ppl=1.88, wps=609.3, ups=0.48, wpb=1269.8, bsz=160, num_updates=15370, lr=2.02884e-05, gnorm=4.143, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=32122
2023-06-27 11:09:03 - progress_bar.py[line:272] - INFO: epoch 006:   2220 / 2637 loss=2.153, loss_v1=0, loss_v2=0, nll_loss=0.932, ntokens=1261.3, nsentences=160, sample_size=1261.3, sample_size_v1=0, sample_size_v2=0, ppl=1.91, wps=605.3, ups=0.48, wpb=1261.3, bsz=160, num_updates=15380, lr=2.02809e-05, gnorm=4.724, clip=100, loss_scale=128, train_wall=21, gb_free=8.9, wall=32143
2023-06-27 11:09:24 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2023-06-27 11:09:26 - progress_bar.py[line:272] - INFO: epoch 006:   2231 / 2637 loss=2.162, loss_v1=0, loss_v2=0, nll_loss=0.94, ntokens=1266.7, nsentences=160, sample_size=1266.7, sample_size_v1=0, sample_size_v2=0, ppl=1.92, wps=552.9, ups=0.44, wpb=1266.7, bsz=160, num_updates=15390, lr=2.02733e-05, gnorm=4.523, clip=100, loss_scale=64, train_wall=23, gb_free=8.9, wall=32166
2023-06-27 11:09:47 - progress_bar.py[line:272] - INFO: epoch 006:   2241 / 2637 loss=2.17, loss_v1=0, loss_v2=0, nll_loss=0.949, ntokens=1265.9, nsentences=160, sample_size=1265.9, sample_size_v1=0, sample_size_v2=0, ppl=1.93, wps=607.2, ups=0.48, wpb=1265.9, bsz=160, num_updates=15400, lr=2.02658e-05, gnorm=4.888, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=32187
2023-06-27 11:10:07 - progress_bar.py[line:272] - INFO: epoch 006:   2251 / 2637 loss=2.166, loss_v1=0, loss_v2=0, nll_loss=0.944, ntokens=1251.3, nsentences=160, sample_size=1251.3, sample_size_v1=0, sample_size_v2=0, ppl=1.92, wps=600.4, ups=0.48, wpb=1251.3, bsz=160, num_updates=15410, lr=2.02582e-05, gnorm=4.566, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=32208
2023-06-27 11:10:28 - progress_bar.py[line:272] - INFO: epoch 006:   2261 / 2637 loss=2.165, loss_v1=0, loss_v2=0, nll_loss=0.941, ntokens=1257.2, nsentences=160, sample_size=1257.2, sample_size_v1=0, sample_size_v2=0, ppl=1.92, wps=603.4, ups=0.48, wpb=1257.2, bsz=160, num_updates=15420, lr=2.02506e-05, gnorm=4.425, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=32228
2023-06-27 11:10:49 - progress_bar.py[line:272] - INFO: epoch 006:   2271 / 2637 loss=2.145, loss_v1=0, loss_v2=0, nll_loss=0.922, ntokens=1286.3, nsentences=160, sample_size=1286.3, sample_size_v1=0, sample_size_v2=0, ppl=1.89, wps=617.3, ups=0.48, wpb=1286.3, bsz=160, num_updates=15430, lr=2.02431e-05, gnorm=4.253, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=32249
2023-06-27 11:11:10 - progress_bar.py[line:272] - INFO: epoch 006:   2281 / 2637 loss=2.167, loss_v1=0, loss_v2=0, nll_loss=0.947, ntokens=1267.5, nsentences=160, sample_size=1267.5, sample_size_v1=0, sample_size_v2=0, ppl=1.93, wps=608.7, ups=0.48, wpb=1267.5, bsz=160, num_updates=15440, lr=2.02355e-05, gnorm=4.286, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=32270
2023-06-27 11:11:31 - progress_bar.py[line:272] - INFO: epoch 006:   2291 / 2637 loss=2.158, loss_v1=0, loss_v2=0, nll_loss=0.936, ntokens=1264.7, nsentences=160, sample_size=1264.7, sample_size_v1=0, sample_size_v2=0, ppl=1.91, wps=606.6, ups=0.48, wpb=1264.7, bsz=160, num_updates=15450, lr=2.02279e-05, gnorm=4.485, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=32291
2023-06-27 11:11:52 - progress_bar.py[line:272] - INFO: epoch 006:   2301 / 2637 loss=2.22, loss_v1=0, loss_v2=0, nll_loss=1.002, ntokens=1272, nsentences=160, sample_size=1272, sample_size_v1=0, sample_size_v2=0, ppl=2, wps=610, ups=0.48, wpb=1272, bsz=160, num_updates=15460, lr=2.02204e-05, gnorm=4.82, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=32312
2023-06-27 11:12:12 - progress_bar.py[line:272] - INFO: epoch 006:   2311 / 2637 loss=2.16, loss_v1=0, loss_v2=0, nll_loss=0.938, ntokens=1265.8, nsentences=160, sample_size=1265.8, sample_size_v1=0, sample_size_v2=0, ppl=1.92, wps=606.7, ups=0.48, wpb=1265.8, bsz=160, num_updates=15470, lr=2.02128e-05, gnorm=4.477, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=32333
2023-06-27 11:12:33 - progress_bar.py[line:272] - INFO: epoch 006:   2321 / 2637 loss=2.157, loss_v1=0, loss_v2=0, nll_loss=0.934, ntokens=1265.7, nsentences=160, sample_size=1265.7, sample_size_v1=0, sample_size_v2=0, ppl=1.91, wps=607, ups=0.48, wpb=1265.7, bsz=160, num_updates=15480, lr=2.02052e-05, gnorm=4.062, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=32354
2023-06-27 11:12:54 - progress_bar.py[line:272] - INFO: epoch 006:   2331 / 2637 loss=2.175, loss_v1=0, loss_v2=0, nll_loss=0.954, ntokens=1249.5, nsentences=160, sample_size=1249.5, sample_size_v1=0, sample_size_v2=0, ppl=1.94, wps=599, ups=0.48, wpb=1249.5, bsz=160, num_updates=15490, lr=2.01977e-05, gnorm=4.845, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=32374
2023-06-27 11:13:15 - progress_bar.py[line:272] - INFO: epoch 006:   2341 / 2637 loss=2.177, loss_v1=0, loss_v2=0, nll_loss=0.958, ntokens=1253.8, nsentences=160, sample_size=1253.8, sample_size_v1=0, sample_size_v2=0, ppl=1.94, wps=600.2, ups=0.48, wpb=1253.8, bsz=160, num_updates=15500, lr=2.01901e-05, gnorm=4.481, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=32395
2023-06-27 11:13:36 - progress_bar.py[line:272] - INFO: epoch 006:   2351 / 2637 loss=2.157, loss_v1=0, loss_v2=0, nll_loss=0.933, ntokens=1260, nsentences=160, sample_size=1260, sample_size_v1=0, sample_size_v2=0, ppl=1.91, wps=605.3, ups=0.48, wpb=1260, bsz=160, num_updates=15510, lr=2.01825e-05, gnorm=4.238, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=32416
2023-06-27 11:13:57 - progress_bar.py[line:272] - INFO: epoch 006:   2361 / 2637 loss=2.17, loss_v1=0, loss_v2=0, nll_loss=0.949, ntokens=1279.1, nsentences=160, sample_size=1279.1, sample_size_v1=0, sample_size_v2=0, ppl=1.93, wps=613.8, ups=0.48, wpb=1279.1, bsz=160, num_updates=15520, lr=2.0175e-05, gnorm=4.418, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=32437
2023-06-27 11:14:18 - progress_bar.py[line:272] - INFO: epoch 006:   2371 / 2637 loss=2.162, loss_v1=0, loss_v2=0, nll_loss=0.94, ntokens=1276.1, nsentences=160, sample_size=1276.1, sample_size_v1=0, sample_size_v2=0, ppl=1.92, wps=612.4, ups=0.48, wpb=1276.1, bsz=160, num_updates=15530, lr=2.01674e-05, gnorm=4.629, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=32458
2023-06-27 11:14:38 - progress_bar.py[line:272] - INFO: epoch 006:   2381 / 2637 loss=2.155, loss_v1=0, loss_v2=0, nll_loss=0.933, ntokens=1278.3, nsentences=160, sample_size=1278.3, sample_size_v1=0, sample_size_v2=0, ppl=1.91, wps=613, ups=0.48, wpb=1278.3, bsz=160, num_updates=15540, lr=2.01599e-05, gnorm=4.162, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=32479
2023-06-27 11:14:59 - progress_bar.py[line:272] - INFO: epoch 006:   2391 / 2637 loss=2.183, loss_v1=0, loss_v2=0, nll_loss=0.964, ntokens=1282, nsentences=160, sample_size=1282, sample_size_v1=0, sample_size_v2=0, ppl=1.95, wps=614.6, ups=0.48, wpb=1282, bsz=160, num_updates=15550, lr=2.01523e-05, gnorm=4.437, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=32500
2023-06-27 11:15:20 - progress_bar.py[line:272] - INFO: epoch 006:   2401 / 2637 loss=2.177, loss_v1=0, loss_v2=0, nll_loss=0.957, ntokens=1277.4, nsentences=160, sample_size=1277.4, sample_size_v1=0, sample_size_v2=0, ppl=1.94, wps=612.1, ups=0.48, wpb=1277.4, bsz=160, num_updates=15560, lr=2.01447e-05, gnorm=4.753, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=32520
2023-06-27 11:15:41 - progress_bar.py[line:272] - INFO: epoch 006:   2411 / 2637 loss=2.171, loss_v1=0, loss_v2=0, nll_loss=0.95, ntokens=1286.4, nsentences=160, sample_size=1286.4, sample_size_v1=0, sample_size_v2=0, ppl=1.93, wps=616.6, ups=0.48, wpb=1286.4, bsz=160, num_updates=15570, lr=2.01372e-05, gnorm=4.704, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=32541
2023-06-27 11:16:02 - progress_bar.py[line:272] - INFO: epoch 006:   2421 / 2637 loss=2.154, loss_v1=0, loss_v2=0, nll_loss=0.931, ntokens=1260, nsentences=160, sample_size=1260, sample_size_v1=0, sample_size_v2=0, ppl=1.91, wps=603.3, ups=0.48, wpb=1260, bsz=160, num_updates=15580, lr=2.01296e-05, gnorm=5.102, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=32562
2023-06-27 11:16:23 - progress_bar.py[line:272] - INFO: epoch 006:   2431 / 2637 loss=2.173, loss_v1=0, loss_v2=0, nll_loss=0.953, ntokens=1276.8, nsentences=160, sample_size=1276.8, sample_size_v1=0, sample_size_v2=0, ppl=1.94, wps=611.1, ups=0.48, wpb=1276.8, bsz=160, num_updates=15590, lr=2.0122e-05, gnorm=5.056, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=32583
2023-06-27 11:16:44 - progress_bar.py[line:272] - INFO: epoch 006:   2441 / 2637 loss=2.17, loss_v1=0, loss_v2=0, nll_loss=0.948, ntokens=1282.8, nsentences=160, sample_size=1282.8, sample_size_v1=0, sample_size_v2=0, ppl=1.93, wps=614.4, ups=0.48, wpb=1282.8, bsz=160, num_updates=15600, lr=2.01145e-05, gnorm=4.318, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=32604
2023-06-27 11:17:05 - progress_bar.py[line:272] - INFO: epoch 006:   2451 / 2637 loss=2.19, loss_v1=0, loss_v2=0, nll_loss=0.97, ntokens=1275.4, nsentences=160, sample_size=1275.4, sample_size_v1=0, sample_size_v2=0, ppl=1.96, wps=611.7, ups=0.48, wpb=1275.4, bsz=160, num_updates=15610, lr=2.01069e-05, gnorm=5.194, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=32625
2023-06-27 11:17:25 - progress_bar.py[line:272] - INFO: epoch 006:   2461 / 2637 loss=2.147, loss_v1=0, loss_v2=0, nll_loss=0.923, ntokens=1276.9, nsentences=160, sample_size=1276.9, sample_size_v1=0, sample_size_v2=0, ppl=1.9, wps=612.1, ups=0.48, wpb=1276.9, bsz=160, num_updates=15620, lr=2.00993e-05, gnorm=4.315, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=32646
2023-06-27 11:17:46 - progress_bar.py[line:272] - INFO: epoch 006:   2471 / 2637 loss=2.152, loss_v1=0, loss_v2=0, nll_loss=0.93, ntokens=1279.3, nsentences=160, sample_size=1279.3, sample_size_v1=0, sample_size_v2=0, ppl=1.91, wps=613.3, ups=0.48, wpb=1279.3, bsz=160, num_updates=15630, lr=2.00918e-05, gnorm=3.872, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=32667
2023-06-27 11:18:07 - progress_bar.py[line:272] - INFO: epoch 006:   2481 / 2637 loss=2.167, loss_v1=0, loss_v2=0, nll_loss=0.946, ntokens=1294.4, nsentences=160, sample_size=1294.4, sample_size_v1=0, sample_size_v2=0, ppl=1.93, wps=620.8, ups=0.48, wpb=1294.4, bsz=160, num_updates=15640, lr=2.00842e-05, gnorm=4.501, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=32687
2023-06-27 11:18:28 - progress_bar.py[line:272] - INFO: epoch 006:   2491 / 2637 loss=2.178, loss_v1=0, loss_v2=0, nll_loss=0.957, ntokens=1265.6, nsentences=160, sample_size=1265.6, sample_size_v1=0, sample_size_v2=0, ppl=1.94, wps=606.6, ups=0.48, wpb=1265.6, bsz=160, num_updates=15650, lr=2.00766e-05, gnorm=5.028, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=32708
2023-06-27 11:18:49 - progress_bar.py[line:272] - INFO: epoch 006:   2501 / 2637 loss=2.171, loss_v1=0, loss_v2=0, nll_loss=0.95, ntokens=1282.9, nsentences=160, sample_size=1282.9, sample_size_v1=0, sample_size_v2=0, ppl=1.93, wps=615.1, ups=0.48, wpb=1282.9, bsz=160, num_updates=15660, lr=2.00691e-05, gnorm=4.251, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=32729
2023-06-27 11:19:10 - progress_bar.py[line:272] - INFO: epoch 006:   2511 / 2637 loss=2.154, loss_v1=0, loss_v2=0, nll_loss=0.931, ntokens=1281, nsentences=160, sample_size=1281, sample_size_v1=0, sample_size_v2=0, ppl=1.91, wps=614.3, ups=0.48, wpb=1281, bsz=160, num_updates=15670, lr=2.00615e-05, gnorm=4.361, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=32750
2023-06-27 11:19:31 - progress_bar.py[line:272] - INFO: epoch 006:   2521 / 2637 loss=2.149, loss_v1=0, loss_v2=0, nll_loss=0.925, ntokens=1276, nsentences=160, sample_size=1276, sample_size_v1=0, sample_size_v2=0, ppl=1.9, wps=612.4, ups=0.48, wpb=1276, bsz=160, num_updates=15680, lr=2.0054e-05, gnorm=4.006, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=32771
2023-06-27 11:19:51 - progress_bar.py[line:272] - INFO: epoch 006:   2531 / 2637 loss=2.166, loss_v1=0, loss_v2=0, nll_loss=0.946, ntokens=1259.1, nsentences=160, sample_size=1259.1, sample_size_v1=0, sample_size_v2=0, ppl=1.93, wps=604.2, ups=0.48, wpb=1259.1, bsz=160, num_updates=15690, lr=2.00464e-05, gnorm=4.779, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=32792
2023-06-27 11:20:12 - progress_bar.py[line:272] - INFO: epoch 006:   2541 / 2637 loss=2.143, loss_v1=0, loss_v2=0, nll_loss=0.919, ntokens=1278.4, nsentences=160, sample_size=1278.4, sample_size_v1=0, sample_size_v2=0, ppl=1.89, wps=612.9, ups=0.48, wpb=1278.4, bsz=160, num_updates=15700, lr=2.00388e-05, gnorm=4.438, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=32813
2023-06-27 11:20:33 - progress_bar.py[line:272] - INFO: epoch 006:   2551 / 2637 loss=2.138, loss_v1=0, loss_v2=0, nll_loss=0.912, ntokens=1260.2, nsentences=160, sample_size=1260.2, sample_size_v1=0, sample_size_v2=0, ppl=1.88, wps=604, ups=0.48, wpb=1260.2, bsz=160, num_updates=15710, lr=2.00313e-05, gnorm=4.702, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=32833
2023-06-27 11:20:54 - progress_bar.py[line:272] - INFO: epoch 006:   2561 / 2637 loss=2.156, loss_v1=0, loss_v2=0, nll_loss=0.934, ntokens=1278.4, nsentences=160, sample_size=1278.4, sample_size_v1=0, sample_size_v2=0, ppl=1.91, wps=612.4, ups=0.48, wpb=1278.4, bsz=160, num_updates=15720, lr=2.00237e-05, gnorm=4.655, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=32854
2023-06-27 11:21:15 - progress_bar.py[line:272] - INFO: epoch 006:   2571 / 2637 loss=2.169, loss_v1=0, loss_v2=0, nll_loss=0.949, ntokens=1250.6, nsentences=160, sample_size=1250.6, sample_size_v1=0, sample_size_v2=0, ppl=1.93, wps=599.3, ups=0.48, wpb=1250.6, bsz=160, num_updates=15730, lr=2.00161e-05, gnorm=4.097, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=32875
2023-06-27 11:21:36 - progress_bar.py[line:272] - INFO: epoch 006:   2581 / 2637 loss=2.149, loss_v1=0, loss_v2=0, nll_loss=0.926, ntokens=1265.3, nsentences=160, sample_size=1265.3, sample_size_v1=0, sample_size_v2=0, ppl=1.9, wps=606, ups=0.48, wpb=1265.3, bsz=160, num_updates=15740, lr=2.00086e-05, gnorm=4.705, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=32896
2023-06-27 11:21:57 - progress_bar.py[line:272] - INFO: epoch 006:   2591 / 2637 loss=2.148, loss_v1=0, loss_v2=0, nll_loss=0.924, ntokens=1290.1, nsentences=160, sample_size=1290.1, sample_size_v1=0, sample_size_v2=0, ppl=1.9, wps=618, ups=0.48, wpb=1290.1, bsz=160, num_updates=15750, lr=2.0001e-05, gnorm=4.506, clip=100, loss_scale=64, train_wall=21, gb_free=8.7, wall=32917
2023-06-27 11:22:17 - progress_bar.py[line:272] - INFO: epoch 006:   2601 / 2637 loss=2.164, loss_v1=0, loss_v2=0, nll_loss=0.942, ntokens=1273.4, nsentences=160, sample_size=1273.4, sample_size_v1=0, sample_size_v2=0, ppl=1.92, wps=610.5, ups=0.48, wpb=1273.4, bsz=160, num_updates=15760, lr=1.99934e-05, gnorm=4.951, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=32938
2023-06-27 11:22:38 - progress_bar.py[line:272] - INFO: epoch 006:   2611 / 2637 loss=2.162, loss_v1=0, loss_v2=0, nll_loss=0.941, ntokens=1270, nsentences=160, sample_size=1270, sample_size_v1=0, sample_size_v2=0, ppl=1.92, wps=609.3, ups=0.48, wpb=1270, bsz=160, num_updates=15770, lr=1.99859e-05, gnorm=4.153, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=32959
2023-06-27 11:22:59 - progress_bar.py[line:272] - INFO: epoch 006:   2621 / 2637 loss=2.114, loss_v1=0, loss_v2=0, nll_loss=0.885, ntokens=1268.8, nsentences=160, sample_size=1268.8, sample_size_v1=0, sample_size_v2=0, ppl=1.85, wps=608.6, ups=0.48, wpb=1268.8, bsz=160, num_updates=15780, lr=1.99783e-05, gnorm=4.544, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=32979
2023-06-27 11:23:20 - progress_bar.py[line:272] - INFO: epoch 006:   2631 / 2637 loss=2.16, loss_v1=0, loss_v2=0, nll_loss=0.938, ntokens=1289.4, nsentences=160, sample_size=1289.4, sample_size_v1=0, sample_size_v2=0, ppl=1.92, wps=618.7, ups=0.48, wpb=1289.4, bsz=160, num_updates=15790, lr=1.99708e-05, gnorm=4.631, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=33000
2023-06-27 11:23:32 - checkpoint_utils.py[line:64] - INFO: Preparing to save checkpoint for epoch 6 @ 15796 updates
2023-06-27 11:23:32 - trainer.py[line:431] - INFO: Saving checkpoint to ../../checkpoints/OFA/vrd_checkpoints/_16_3e-5_512_rare_3/checkpoint6.pt
local datafile ../../dataset/OFA_data/vrd/vg_train_full.tsv slice_id 1 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../dataset/OFA_data/vrd/vg_train_full.tsv slice_id 2 begin to initialize row_count and line_idx-to-offset mappinglocal datafile ../../dataset/OFA_data/vrd/vg_train_full.tsv slice_id 3 begin to initialize row_count and line_idx-to-offset mapping

local datafile ../../dataset/OFA_data/vrd/vg_train_full.tsv slice_id 2 finished initializing row_count and line_idx-to-offset mapping
file ../../dataset/OFA_data/vrd/vg_train_full.tsv slice_id 2 row count 105470 total row count 421879
local datafile ../../dataset/OFA_data/vrd/vg_train_full.tsv slice_id 3 finished initializing row_count and line_idx-to-offset mapping
file ../../dataset/OFA_data/vrd/vg_train_full.tsv slice_id 3 row count 105469 total row count 421879
local datafile ../../dataset/OFA_data/vrd/vg_train_full.tsv slice_id 1 finished initializing row_count and line_idx-to-offset mapping
file ../../dataset/OFA_data/vrd/vg_train_full.tsv slice_id 1 row count 105470 total row count 421879
slice_id 3 seek offset 316410
slice_id 1 seek offset 105470
slice_id 2 seek offset 210940
2023-06-27 11:23:35 - trainer.py[line:441] - INFO: Finished saving checkpoint to ../../checkpoints/OFA/vrd_checkpoints/_16_3e-5_512_rare_3/checkpoint6.pt
2023-06-27 11:23:38 - checkpoint_utils.py[line:133] - INFO: Saved checkpoint ../../checkpoints/OFA/vrd_checkpoints/_16_3e-5_512_rare_3/checkpoint6.pt (epoch 6 @ 15796 updates, score None) (writing took 6.143107954412699 seconds)
2023-06-27 11:23:38 - train.py[line:332] - INFO: end of epoch 6 (average epoch stats below)
2023-06-27 11:23:38 - progress_bar.py[line:282] - INFO: epoch 006 | loss 2.17 | loss_v1 0 | loss_v2 0 | nll_loss 0.949 | ntokens 1259.96 | nsentences 159.984 | sample_size 1259.96 | sample_size_v1 0 | sample_size_v2 0 | ppl 1.93 | wps 602.8 | ups 0.48 | wpb 1260 | bsz 160 | num_updates 15796 | lr 1.99662e-05 | gnorm 4.602 | clip 100 | loss_scale 64 | train_wall 5488 | gb_free 8.9 | wall 33018
2023-06-27 11:23:38 - trainer.py[line:639] - INFO: loading train data for epoch 7
local datafile ../../dataset/OFA_data/vrd/vg_train_full.tsv slice_id 0 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../dataset/OFA_data/vrd/vg_train_full.tsv slice_id 0 finished initializing row_count and line_idx-to-offset mapping
file ../../dataset/OFA_data/vrd/vg_train_full.tsv slice_id 0 row count 105470 total row count 421879
slice_id 0 seek offset 0
2023-06-27 11:23:38 - trainer.py[line:703] - INFO: begin training epoch 7
2023-06-27 11:23:38 - train.py[line:305] - INFO: Start iterating over samples
2023-06-27 11:23:47 - progress_bar.py[line:272] - INFO: epoch 007:      4 / 2637 loss=2.185, loss_v1=0, loss_v2=0, nll_loss=0.966, ntokens=1221.4, nsentences=156, sample_size=1221.4, sample_size_v1=0, sample_size_v2=0, ppl=1.95, wps=451.3, ups=0.37, wpb=1221.4, bsz=156, num_updates=15800, lr=1.99632e-05, gnorm=4.799, clip=100, loss_scale=64, train_wall=20, gb_free=8.9, wall=33027
2023-06-27 11:24:08 - progress_bar.py[line:272] - INFO: epoch 007:     14 / 2637 loss=2.142, loss_v1=0, loss_v2=0, nll_loss=0.916, ntokens=1262.8, nsentences=160, sample_size=1262.8, sample_size_v1=0, sample_size_v2=0, ppl=1.89, wps=606.7, ups=0.48, wpb=1262.8, bsz=160, num_updates=15810, lr=1.99556e-05, gnorm=4.21, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=33048
2023-06-27 11:24:29 - progress_bar.py[line:272] - INFO: epoch 007:     24 / 2637 loss=2.139, loss_v1=0, loss_v2=0, nll_loss=0.912, ntokens=1258.5, nsentences=160, sample_size=1258.5, sample_size_v1=0, sample_size_v2=0, ppl=1.88, wps=604.1, ups=0.48, wpb=1258.5, bsz=160, num_updates=15820, lr=1.99481e-05, gnorm=4.55, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=33069
2023-06-27 11:24:50 - progress_bar.py[line:272] - INFO: epoch 007:     34 / 2637 loss=2.134, loss_v1=0, loss_v2=0, nll_loss=0.91, ntokens=1252.2, nsentences=160, sample_size=1252.2, sample_size_v1=0, sample_size_v2=0, ppl=1.88, wps=600.5, ups=0.48, wpb=1252.2, bsz=160, num_updates=15830, lr=1.99405e-05, gnorm=4.827, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=33090
2023-06-27 11:25:10 - progress_bar.py[line:272] - INFO: epoch 007:     44 / 2637 loss=2.159, loss_v1=0, loss_v2=0, nll_loss=0.936, ntokens=1258.8, nsentences=160, sample_size=1258.8, sample_size_v1=0, sample_size_v2=0, ppl=1.91, wps=604.2, ups=0.48, wpb=1258.8, bsz=160, num_updates=15840, lr=1.99329e-05, gnorm=4.895, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=33111
2023-06-27 11:25:31 - progress_bar.py[line:272] - INFO: epoch 007:     54 / 2637 loss=2.141, loss_v1=0, loss_v2=0, nll_loss=0.918, ntokens=1243.5, nsentences=160, sample_size=1243.5, sample_size_v1=0, sample_size_v2=0, ppl=1.89, wps=597.2, ups=0.48, wpb=1243.5, bsz=160, num_updates=15850, lr=1.99254e-05, gnorm=4.073, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=33132
2023-06-27 11:25:52 - progress_bar.py[line:272] - INFO: epoch 007:     64 / 2637 loss=2.17, loss_v1=0, loss_v2=0, nll_loss=0.95, ntokens=1248.2, nsentences=160, sample_size=1248.2, sample_size_v1=0, sample_size_v2=0, ppl=1.93, wps=599.2, ups=0.48, wpb=1248.2, bsz=160, num_updates=15860, lr=1.99178e-05, gnorm=4.789, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=33152
2023-06-27 11:26:13 - progress_bar.py[line:272] - INFO: epoch 007:     74 / 2637 loss=2.16, loss_v1=0, loss_v2=0, nll_loss=0.936, ntokens=1244, nsentences=160, sample_size=1244, sample_size_v1=0, sample_size_v2=0, ppl=1.91, wps=597.2, ups=0.48, wpb=1244, bsz=160, num_updates=15870, lr=1.99102e-05, gnorm=4.555, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=33173
2023-06-27 11:26:34 - progress_bar.py[line:272] - INFO: epoch 007:     84 / 2637 loss=2.172, loss_v1=0, loss_v2=0, nll_loss=0.949, ntokens=1257.8, nsentences=160, sample_size=1257.8, sample_size_v1=0, sample_size_v2=0, ppl=1.93, wps=604.3, ups=0.48, wpb=1257.8, bsz=160, num_updates=15880, lr=1.99027e-05, gnorm=4.586, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=33194
2023-06-27 11:26:55 - progress_bar.py[line:272] - INFO: epoch 007:     94 / 2637 loss=2.136, loss_v1=0, loss_v2=0, nll_loss=0.911, ntokens=1249.6, nsentences=160, sample_size=1249.6, sample_size_v1=0, sample_size_v2=0, ppl=1.88, wps=600.5, ups=0.48, wpb=1249.6, bsz=160, num_updates=15890, lr=1.98951e-05, gnorm=4.159, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=33215
2023-06-27 11:27:15 - progress_bar.py[line:272] - INFO: epoch 007:    104 / 2637 loss=2.151, loss_v1=0, loss_v2=0, nll_loss=0.93, ntokens=1248.5, nsentences=160, sample_size=1248.5, sample_size_v1=0, sample_size_v2=0, ppl=1.91, wps=599.5, ups=0.48, wpb=1248.5, bsz=160, num_updates=15900, lr=1.98875e-05, gnorm=4.514, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=33236
2023-06-27 11:27:36 - progress_bar.py[line:272] - INFO: epoch 007:    114 / 2637 loss=2.127, loss_v1=0, loss_v2=0, nll_loss=0.9, ntokens=1247.3, nsentences=160, sample_size=1247.3, sample_size_v1=0, sample_size_v2=0, ppl=1.87, wps=599.4, ups=0.48, wpb=1247.3, bsz=160, num_updates=15910, lr=1.988e-05, gnorm=4.537, clip=100, loss_scale=128, train_wall=21, gb_free=8.9, wall=33256
2023-06-27 11:27:57 - progress_bar.py[line:272] - INFO: epoch 007:    124 / 2637 loss=2.151, loss_v1=0, loss_v2=0, nll_loss=0.928, ntokens=1241, nsentences=160, sample_size=1241, sample_size_v1=0, sample_size_v2=0, ppl=1.9, wps=594.5, ups=0.48, wpb=1241, bsz=160, num_updates=15920, lr=1.98724e-05, gnorm=4.658, clip=100, loss_scale=128, train_wall=21, gb_free=8.9, wall=33277
2023-06-27 11:28:18 - progress_bar.py[line:272] - INFO: epoch 007:    134 / 2637 loss=2.156, loss_v1=0, loss_v2=0, nll_loss=0.934, ntokens=1253.9, nsentences=160, sample_size=1253.9, sample_size_v1=0, sample_size_v2=0, ppl=1.91, wps=600.5, ups=0.48, wpb=1253.9, bsz=160, num_updates=15930, lr=1.98649e-05, gnorm=4.625, clip=100, loss_scale=128, train_wall=21, gb_free=8.9, wall=33298
2023-06-27 11:28:39 - progress_bar.py[line:272] - INFO: epoch 007:    144 / 2637 loss=2.177, loss_v1=0, loss_v2=0, nll_loss=0.955, ntokens=1252.5, nsentences=160, sample_size=1252.5, sample_size_v1=0, sample_size_v2=0, ppl=1.94, wps=600, ups=0.48, wpb=1252.5, bsz=160, num_updates=15940, lr=1.98573e-05, gnorm=4.486, clip=100, loss_scale=128, train_wall=21, gb_free=8.9, wall=33319
2023-06-27 11:29:00 - progress_bar.py[line:272] - INFO: epoch 007:    154 / 2637 loss=2.179, loss_v1=0, loss_v2=0, nll_loss=0.959, ntokens=1249.4, nsentences=160, sample_size=1249.4, sample_size_v1=0, sample_size_v2=0, ppl=1.94, wps=599, ups=0.48, wpb=1249.4, bsz=160, num_updates=15950, lr=1.98497e-05, gnorm=4.635, clip=100, loss_scale=128, train_wall=21, gb_free=8.9, wall=33340
2023-06-27 11:29:21 - progress_bar.py[line:272] - INFO: epoch 007:    164 / 2637 loss=2.169, loss_v1=0, loss_v2=0, nll_loss=0.949, ntokens=1234.2, nsentences=160, sample_size=1234.2, sample_size_v1=0, sample_size_v2=0, ppl=1.93, wps=591.4, ups=0.48, wpb=1234.2, bsz=160, num_updates=15960, lr=1.98422e-05, gnorm=4.357, clip=100, loss_scale=128, train_wall=21, gb_free=8.9, wall=33361
2023-06-27 11:29:42 - progress_bar.py[line:272] - INFO: epoch 007:    174 / 2637 loss=2.153, loss_v1=0, loss_v2=0, nll_loss=0.929, ntokens=1243, nsentences=160, sample_size=1243, sample_size_v1=0, sample_size_v2=0, ppl=1.9, wps=590.7, ups=0.48, wpb=1243, bsz=160, num_updates=15970, lr=1.98346e-05, gnorm=4.417, clip=100, loss_scale=128, train_wall=21, gb_free=8.9, wall=33382
2023-06-27 11:30:02 - progress_bar.py[line:272] - INFO: epoch 007:    184 / 2637 loss=2.138, loss_v1=0, loss_v2=0, nll_loss=0.914, ntokens=1238, nsentences=160, sample_size=1238, sample_size_v1=0, sample_size_v2=0, ppl=1.88, wps=593.8, ups=0.48, wpb=1238, bsz=160, num_updates=15980, lr=1.9827e-05, gnorm=4.11, clip=100, loss_scale=128, train_wall=21, gb_free=8.9, wall=33403
2023-06-27 11:30:21 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2023-06-27 11:30:25 - progress_bar.py[line:272] - INFO: epoch 007:    195 / 2637 loss=2.124, loss_v1=0, loss_v2=0, nll_loss=0.897, ntokens=1233, nsentences=160, sample_size=1233, sample_size_v1=0, sample_size_v2=0, ppl=1.86, wps=538, ups=0.44, wpb=1233, bsz=160, num_updates=15990, lr=1.98195e-05, gnorm=4.569, clip=100, loss_scale=64, train_wall=23, gb_free=8.9, wall=33426
2023-06-27 11:30:46 - progress_bar.py[line:272] - INFO: epoch 007:    205 / 2637 loss=2.127, loss_v1=0, loss_v2=0, nll_loss=0.901, ntokens=1256.9, nsentences=160, sample_size=1256.9, sample_size_v1=0, sample_size_v2=0, ppl=1.87, wps=602.3, ups=0.48, wpb=1256.9, bsz=160, num_updates=16000, lr=1.98119e-05, gnorm=3.967, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=33447
2023-06-27 11:31:07 - progress_bar.py[line:272] - INFO: epoch 007:    215 / 2637 loss=2.101, loss_v1=0, loss_v2=0, nll_loss=0.872, ntokens=1237, nsentences=160, sample_size=1237, sample_size_v1=0, sample_size_v2=0, ppl=1.83, wps=592.8, ups=0.48, wpb=1237, bsz=160, num_updates=16010, lr=1.98043e-05, gnorm=4.255, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=33467
2023-06-27 11:31:28 - progress_bar.py[line:272] - INFO: epoch 007:    225 / 2637 loss=2.137, loss_v1=0, loss_v2=0, nll_loss=0.912, ntokens=1230.1, nsentences=160, sample_size=1230.1, sample_size_v1=0, sample_size_v2=0, ppl=1.88, wps=589.9, ups=0.48, wpb=1230.1, bsz=160, num_updates=16020, lr=1.97968e-05, gnorm=4.324, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=33488
2023-06-27 11:31:49 - progress_bar.py[line:272] - INFO: epoch 007:    235 / 2637 loss=2.125, loss_v1=0, loss_v2=0, nll_loss=0.901, ntokens=1256.2, nsentences=160, sample_size=1256.2, sample_size_v1=0, sample_size_v2=0, ppl=1.87, wps=602.4, ups=0.48, wpb=1256.2, bsz=160, num_updates=16030, lr=1.97892e-05, gnorm=4.611, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=33509
2023-06-27 11:32:10 - progress_bar.py[line:272] - INFO: epoch 007:    245 / 2637 loss=2.113, loss_v1=0, loss_v2=0, nll_loss=0.885, ntokens=1260.7, nsentences=160, sample_size=1260.7, sample_size_v1=0, sample_size_v2=0, ppl=1.85, wps=605.8, ups=0.48, wpb=1260.7, bsz=160, num_updates=16040, lr=1.97816e-05, gnorm=4.507, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=33530
2023-06-27 11:32:30 - progress_bar.py[line:272] - INFO: epoch 007:    255 / 2637 loss=2.148, loss_v1=0, loss_v2=0, nll_loss=0.924, ntokens=1248.7, nsentences=160, sample_size=1248.7, sample_size_v1=0, sample_size_v2=0, ppl=1.9, wps=599.8, ups=0.48, wpb=1248.7, bsz=160, num_updates=16050, lr=1.97741e-05, gnorm=4.428, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=33551
2023-06-27 11:32:51 - progress_bar.py[line:272] - INFO: epoch 007:    265 / 2637 loss=2.147, loss_v1=0, loss_v2=0, nll_loss=0.923, ntokens=1248.5, nsentences=160, sample_size=1248.5, sample_size_v1=0, sample_size_v2=0, ppl=1.9, wps=599.4, ups=0.48, wpb=1248.5, bsz=160, num_updates=16060, lr=1.97665e-05, gnorm=4.748, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=33572
2023-06-27 11:33:12 - progress_bar.py[line:272] - INFO: epoch 007:    275 / 2637 loss=2.161, loss_v1=0, loss_v2=0, nll_loss=0.938, ntokens=1255.9, nsentences=160, sample_size=1255.9, sample_size_v1=0, sample_size_v2=0, ppl=1.92, wps=603.6, ups=0.48, wpb=1255.9, bsz=160, num_updates=16070, lr=1.9759e-05, gnorm=4.753, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=33592
2023-06-27 11:33:33 - progress_bar.py[line:272] - INFO: epoch 007:    285 / 2637 loss=2.137, loss_v1=0, loss_v2=0, nll_loss=0.913, ntokens=1246, nsentences=160, sample_size=1246, sample_size_v1=0, sample_size_v2=0, ppl=1.88, wps=598.6, ups=0.48, wpb=1246, bsz=160, num_updates=16080, lr=1.97514e-05, gnorm=4.532, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=33613
2023-06-27 11:33:54 - progress_bar.py[line:272] - INFO: epoch 007:    295 / 2637 loss=2.163, loss_v1=0, loss_v2=0, nll_loss=0.94, ntokens=1235.2, nsentences=160, sample_size=1235.2, sample_size_v1=0, sample_size_v2=0, ppl=1.92, wps=591.4, ups=0.48, wpb=1235.2, bsz=160, num_updates=16090, lr=1.97438e-05, gnorm=4.487, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=33634
2023-06-27 11:34:15 - progress_bar.py[line:272] - INFO: epoch 007:    305 / 2637 loss=2.136, loss_v1=0, loss_v2=0, nll_loss=0.911, ntokens=1233.9, nsentences=160, sample_size=1233.9, sample_size_v1=0, sample_size_v2=0, ppl=1.88, wps=591.6, ups=0.48, wpb=1233.9, bsz=160, num_updates=16100, lr=1.97363e-05, gnorm=4.256, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=33655
2023-06-27 11:34:36 - progress_bar.py[line:272] - INFO: epoch 007:    315 / 2637 loss=2.106, loss_v1=0, loss_v2=0, nll_loss=0.875, ntokens=1243.5, nsentences=160, sample_size=1243.5, sample_size_v1=0, sample_size_v2=0, ppl=1.83, wps=596, ups=0.48, wpb=1243.5, bsz=160, num_updates=16110, lr=1.97287e-05, gnorm=4.161, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=33676
2023-06-27 11:34:56 - progress_bar.py[line:272] - INFO: epoch 007:    325 / 2637 loss=2.132, loss_v1=0, loss_v2=0, nll_loss=0.908, ntokens=1250.5, nsentences=160, sample_size=1250.5, sample_size_v1=0, sample_size_v2=0, ppl=1.88, wps=599.7, ups=0.48, wpb=1250.5, bsz=160, num_updates=16120, lr=1.97211e-05, gnorm=4.391, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=33697
2023-06-27 11:35:17 - progress_bar.py[line:272] - INFO: epoch 007:    335 / 2637 loss=2.134, loss_v1=0, loss_v2=0, nll_loss=0.912, ntokens=1240.2, nsentences=160, sample_size=1240.2, sample_size_v1=0, sample_size_v2=0, ppl=1.88, wps=594.4, ups=0.48, wpb=1240.2, bsz=160, num_updates=16130, lr=1.97136e-05, gnorm=4.259, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=33718
2023-06-27 11:35:38 - progress_bar.py[line:272] - INFO: epoch 007:    345 / 2637 loss=2.13, loss_v1=0, loss_v2=0, nll_loss=0.901, ntokens=1245.4, nsentences=160, sample_size=1245.4, sample_size_v1=0, sample_size_v2=0, ppl=1.87, wps=596.8, ups=0.48, wpb=1245.4, bsz=160, num_updates=16140, lr=1.9706e-05, gnorm=4.648, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=33738
2023-06-27 11:35:59 - progress_bar.py[line:272] - INFO: epoch 007:    355 / 2637 loss=2.135, loss_v1=0, loss_v2=0, nll_loss=0.91, ntokens=1260.8, nsentences=160, sample_size=1260.8, sample_size_v1=0, sample_size_v2=0, ppl=1.88, wps=604.3, ups=0.48, wpb=1260.8, bsz=160, num_updates=16150, lr=1.96984e-05, gnorm=4.537, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=33759
2023-06-27 11:36:20 - progress_bar.py[line:272] - INFO: epoch 007:    365 / 2637 loss=2.115, loss_v1=0, loss_v2=0, nll_loss=0.887, ntokens=1259.5, nsentences=160, sample_size=1259.5, sample_size_v1=0, sample_size_v2=0, ppl=1.85, wps=603.4, ups=0.48, wpb=1259.5, bsz=160, num_updates=16160, lr=1.96909e-05, gnorm=4.917, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=33780
2023-06-27 11:36:41 - progress_bar.py[line:272] - INFO: epoch 007:    375 / 2637 loss=2.09, loss_v1=0, loss_v2=0, nll_loss=0.859, ntokens=1244.3, nsentences=160, sample_size=1244.3, sample_size_v1=0, sample_size_v2=0, ppl=1.81, wps=597.2, ups=0.48, wpb=1244.3, bsz=160, num_updates=16170, lr=1.96833e-05, gnorm=4.254, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=33801
2023-06-27 11:37:02 - progress_bar.py[line:272] - INFO: epoch 007:    385 / 2637 loss=2.095, loss_v1=0, loss_v2=0, nll_loss=0.866, ntokens=1244.3, nsentences=160, sample_size=1244.3, sample_size_v1=0, sample_size_v2=0, ppl=1.82, wps=597.7, ups=0.48, wpb=1244.3, bsz=160, num_updates=16180, lr=1.96758e-05, gnorm=4.752, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=33822
2023-06-27 11:37:22 - progress_bar.py[line:272] - INFO: epoch 007:    395 / 2637 loss=2.095, loss_v1=0, loss_v2=0, nll_loss=0.867, ntokens=1241.1, nsentences=160, sample_size=1241.1, sample_size_v1=0, sample_size_v2=0, ppl=1.82, wps=595.7, ups=0.48, wpb=1241.1, bsz=160, num_updates=16190, lr=1.96682e-05, gnorm=5.175, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=33843
2023-06-27 11:37:43 - progress_bar.py[line:272] - INFO: epoch 007:    405 / 2637 loss=2.094, loss_v1=0, loss_v2=0, nll_loss=0.863, ntokens=1248.5, nsentences=160, sample_size=1248.5, sample_size_v1=0, sample_size_v2=0, ppl=1.82, wps=600, ups=0.48, wpb=1248.5, bsz=160, num_updates=16200, lr=1.96606e-05, gnorm=5.057, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=33863
2023-06-27 11:38:04 - progress_bar.py[line:272] - INFO: epoch 007:    415 / 2637 loss=2.088, loss_v1=0, loss_v2=0, nll_loss=0.859, ntokens=1245.7, nsentences=160, sample_size=1245.7, sample_size_v1=0, sample_size_v2=0, ppl=1.81, wps=598.6, ups=0.48, wpb=1245.7, bsz=160, num_updates=16210, lr=1.96531e-05, gnorm=4.99, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=33884
2023-06-27 11:38:25 - progress_bar.py[line:272] - INFO: epoch 007:    425 / 2637 loss=2.109, loss_v1=0, loss_v2=0, nll_loss=0.88, ntokens=1243.3, nsentences=160, sample_size=1243.3, sample_size_v1=0, sample_size_v2=0, ppl=1.84, wps=597.8, ups=0.48, wpb=1243.3, bsz=160, num_updates=16220, lr=1.96455e-05, gnorm=4.705, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=33905
2023-06-27 11:38:46 - progress_bar.py[line:272] - INFO: epoch 007:    435 / 2637 loss=2.112, loss_v1=0, loss_v2=0, nll_loss=0.883, ntokens=1259.4, nsentences=160, sample_size=1259.4, sample_size_v1=0, sample_size_v2=0, ppl=1.84, wps=605.5, ups=0.48, wpb=1259.4, bsz=160, num_updates=16230, lr=1.96379e-05, gnorm=4.248, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=33926
2023-06-27 11:39:06 - progress_bar.py[line:272] - INFO: epoch 007:    445 / 2637 loss=2.088, loss_v1=0, loss_v2=0, nll_loss=0.858, ntokens=1252.9, nsentences=160, sample_size=1252.9, sample_size_v1=0, sample_size_v2=0, ppl=1.81, wps=602.3, ups=0.48, wpb=1252.9, bsz=160, num_updates=16240, lr=1.96304e-05, gnorm=3.983, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=33947
2023-06-27 11:39:27 - progress_bar.py[line:272] - INFO: epoch 007:    455 / 2637 loss=2.098, loss_v1=0, loss_v2=0, nll_loss=0.87, ntokens=1242.3, nsentences=160, sample_size=1242.3, sample_size_v1=0, sample_size_v2=0, ppl=1.83, wps=597.1, ups=0.48, wpb=1242.3, bsz=160, num_updates=16250, lr=1.96228e-05, gnorm=4.607, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=33968
2023-06-27 11:39:48 - progress_bar.py[line:272] - INFO: epoch 007:    465 / 2637 loss=2.107, loss_v1=0, loss_v2=0, nll_loss=0.88, ntokens=1263.1, nsentences=160, sample_size=1263.1, sample_size_v1=0, sample_size_v2=0, ppl=1.84, wps=607, ups=0.48, wpb=1263.1, bsz=160, num_updates=16260, lr=1.96152e-05, gnorm=4.507, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=33988
2023-06-27 11:40:09 - progress_bar.py[line:272] - INFO: epoch 007:    475 / 2637 loss=2.137, loss_v1=0, loss_v2=0, nll_loss=0.912, ntokens=1255.8, nsentences=160, sample_size=1255.8, sample_size_v1=0, sample_size_v2=0, ppl=1.88, wps=602.7, ups=0.48, wpb=1255.8, bsz=160, num_updates=16270, lr=1.96077e-05, gnorm=4.673, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=34009
2023-06-27 11:40:30 - progress_bar.py[line:272] - INFO: epoch 007:    485 / 2637 loss=2.097, loss_v1=0, loss_v2=0, nll_loss=0.869, ntokens=1260.9, nsentences=160, sample_size=1260.9, sample_size_v1=0, sample_size_v2=0, ppl=1.83, wps=604.8, ups=0.48, wpb=1260.9, bsz=160, num_updates=16280, lr=1.96001e-05, gnorm=3.919, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=34030
2023-06-27 11:40:51 - progress_bar.py[line:272] - INFO: epoch 007:    495 / 2637 loss=2.115, loss_v1=0, loss_v2=0, nll_loss=0.889, ntokens=1257.5, nsentences=160, sample_size=1257.5, sample_size_v1=0, sample_size_v2=0, ppl=1.85, wps=603.9, ups=0.48, wpb=1257.5, bsz=160, num_updates=16290, lr=1.95925e-05, gnorm=4.925, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=34051
2023-06-27 11:41:11 - progress_bar.py[line:272] - INFO: epoch 007:    505 / 2637 loss=2.163, loss_v1=0, loss_v2=0, nll_loss=0.941, ntokens=1267.9, nsentences=160, sample_size=1267.9, sample_size_v1=0, sample_size_v2=0, ppl=1.92, wps=609.2, ups=0.48, wpb=1267.9, bsz=160, num_updates=16300, lr=1.9585e-05, gnorm=4.182, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=34072
2023-06-27 11:41:32 - progress_bar.py[line:272] - INFO: epoch 007:    515 / 2637 loss=2.148, loss_v1=0, loss_v2=0, nll_loss=0.922, ntokens=1250.6, nsentences=160, sample_size=1250.6, sample_size_v1=0, sample_size_v2=0, ppl=1.89, wps=600, ups=0.48, wpb=1250.6, bsz=160, num_updates=16310, lr=1.95774e-05, gnorm=4.366, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=34093
2023-06-27 11:41:53 - progress_bar.py[line:272] - INFO: epoch 007:    525 / 2637 loss=2.132, loss_v1=0, loss_v2=0, nll_loss=0.907, ntokens=1238.6, nsentences=160, sample_size=1238.6, sample_size_v1=0, sample_size_v2=0, ppl=1.88, wps=589.6, ups=0.48, wpb=1238.6, bsz=160, num_updates=16320, lr=1.95699e-05, gnorm=4.543, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=34114
2023-06-27 11:42:14 - progress_bar.py[line:272] - INFO: epoch 007:    535 / 2637 loss=2.152, loss_v1=0, loss_v2=0, nll_loss=0.929, ntokens=1257.1, nsentences=160, sample_size=1257.1, sample_size_v1=0, sample_size_v2=0, ppl=1.9, wps=603.8, ups=0.48, wpb=1257.1, bsz=160, num_updates=16330, lr=1.95623e-05, gnorm=4.699, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=34134
2023-06-27 11:42:35 - progress_bar.py[line:272] - INFO: epoch 007:    545 / 2637 loss=2.177, loss_v1=0, loss_v2=0, nll_loss=0.957, ntokens=1256.8, nsentences=160, sample_size=1256.8, sample_size_v1=0, sample_size_v2=0, ppl=1.94, wps=603.1, ups=0.48, wpb=1256.8, bsz=160, num_updates=16340, lr=1.95547e-05, gnorm=5.358, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=34155
2023-06-27 11:42:56 - progress_bar.py[line:272] - INFO: epoch 007:    555 / 2637 loss=2.149, loss_v1=0, loss_v2=0, nll_loss=0.925, ntokens=1265.3, nsentences=160, sample_size=1265.3, sample_size_v1=0, sample_size_v2=0, ppl=1.9, wps=607.8, ups=0.48, wpb=1265.3, bsz=160, num_updates=16350, lr=1.95472e-05, gnorm=5.253, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=34176
2023-06-27 11:43:17 - progress_bar.py[line:272] - INFO: epoch 007:    565 / 2637 loss=2.149, loss_v1=0, loss_v2=0, nll_loss=0.925, ntokens=1255.6, nsentences=160, sample_size=1255.6, sample_size_v1=0, sample_size_v2=0, ppl=1.9, wps=602.7, ups=0.48, wpb=1255.6, bsz=160, num_updates=16360, lr=1.95396e-05, gnorm=4.328, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=34197
2023-06-27 11:43:37 - progress_bar.py[line:272] - INFO: epoch 007:    575 / 2637 loss=2.158, loss_v1=0, loss_v2=0, nll_loss=0.937, ntokens=1256, nsentences=160, sample_size=1256, sample_size_v1=0, sample_size_v2=0, ppl=1.91, wps=603.3, ups=0.48, wpb=1256, bsz=160, num_updates=16370, lr=1.9532e-05, gnorm=5.035, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=34218
2023-06-27 11:43:58 - progress_bar.py[line:272] - INFO: epoch 007:    585 / 2637 loss=2.171, loss_v1=0, loss_v2=0, nll_loss=0.95, ntokens=1243.6, nsentences=160, sample_size=1243.6, sample_size_v1=0, sample_size_v2=0, ppl=1.93, wps=597.3, ups=0.48, wpb=1243.6, bsz=160, num_updates=16380, lr=1.95245e-05, gnorm=4.843, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=34239
2023-06-27 11:44:19 - progress_bar.py[line:272] - INFO: epoch 007:    595 / 2637 loss=2.135, loss_v1=0, loss_v2=0, nll_loss=0.909, ntokens=1273.6, nsentences=160, sample_size=1273.6, sample_size_v1=0, sample_size_v2=0, ppl=1.88, wps=611.9, ups=0.48, wpb=1273.6, bsz=160, num_updates=16390, lr=1.95169e-05, gnorm=4.405, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=34259
2023-06-27 11:44:40 - progress_bar.py[line:272] - INFO: epoch 007:    605 / 2637 loss=2.153, loss_v1=0, loss_v2=0, nll_loss=0.93, ntokens=1249.7, nsentences=160, sample_size=1249.7, sample_size_v1=0, sample_size_v2=0, ppl=1.9, wps=599.6, ups=0.48, wpb=1249.7, bsz=160, num_updates=16400, lr=1.95093e-05, gnorm=4.314, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=34280
2023-06-27 11:45:01 - progress_bar.py[line:272] - INFO: epoch 007:    615 / 2637 loss=2.171, loss_v1=0, loss_v2=0, nll_loss=0.95, ntokens=1269, nsentences=160, sample_size=1269, sample_size_v1=0, sample_size_v2=0, ppl=1.93, wps=608.4, ups=0.48, wpb=1269, bsz=160, num_updates=16410, lr=1.95018e-05, gnorm=4.912, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=34301
2023-06-27 11:45:22 - progress_bar.py[line:272] - INFO: epoch 007:    625 / 2637 loss=2.139, loss_v1=0, loss_v2=0, nll_loss=0.912, ntokens=1243.1, nsentences=160, sample_size=1243.1, sample_size_v1=0, sample_size_v2=0, ppl=1.88, wps=596, ups=0.48, wpb=1243.1, bsz=160, num_updates=16420, lr=1.94942e-05, gnorm=4.346, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=34322
2023-06-27 11:45:42 - progress_bar.py[line:272] - INFO: epoch 007:    635 / 2637 loss=2.145, loss_v1=0, loss_v2=0, nll_loss=0.922, ntokens=1258.2, nsentences=160, sample_size=1258.2, sample_size_v1=0, sample_size_v2=0, ppl=1.89, wps=603, ups=0.48, wpb=1258.2, bsz=160, num_updates=16430, lr=1.94866e-05, gnorm=4.211, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=34343
2023-06-27 11:46:03 - progress_bar.py[line:272] - INFO: epoch 007:    645 / 2637 loss=2.117, loss_v1=0, loss_v2=0, nll_loss=0.892, ntokens=1259.1, nsentences=160, sample_size=1259.1, sample_size_v1=0, sample_size_v2=0, ppl=1.86, wps=603.1, ups=0.48, wpb=1259.1, bsz=160, num_updates=16440, lr=1.94791e-05, gnorm=4.896, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=34364
2023-06-27 11:46:24 - progress_bar.py[line:272] - INFO: epoch 007:    655 / 2637 loss=2.166, loss_v1=0, loss_v2=0, nll_loss=0.945, ntokens=1238.3, nsentences=160, sample_size=1238.3, sample_size_v1=0, sample_size_v2=0, ppl=1.93, wps=593.9, ups=0.48, wpb=1238.3, bsz=160, num_updates=16450, lr=1.94715e-05, gnorm=5.437, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=34384
2023-06-27 11:46:45 - progress_bar.py[line:272] - INFO: epoch 007:    665 / 2637 loss=2.162, loss_v1=0, loss_v2=0, nll_loss=0.94, ntokens=1265.3, nsentences=160, sample_size=1265.3, sample_size_v1=0, sample_size_v2=0, ppl=1.92, wps=607.1, ups=0.48, wpb=1265.3, bsz=160, num_updates=16460, lr=1.9464e-05, gnorm=4.693, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=34405
2023-06-27 11:47:06 - progress_bar.py[line:272] - INFO: epoch 007:    675 / 2637 loss=2.12, loss_v1=0, loss_v2=0, nll_loss=0.894, ntokens=1253.6, nsentences=160, sample_size=1253.6, sample_size_v1=0, sample_size_v2=0, ppl=1.86, wps=599.9, ups=0.48, wpb=1253.6, bsz=160, num_updates=16470, lr=1.94564e-05, gnorm=4.065, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=34426
2023-06-27 11:47:27 - progress_bar.py[line:272] - INFO: epoch 007:    685 / 2637 loss=2.163, loss_v1=0, loss_v2=0, nll_loss=0.94, ntokens=1286.5, nsentences=160, sample_size=1286.5, sample_size_v1=0, sample_size_v2=0, ppl=1.92, wps=616.1, ups=0.48, wpb=1286.5, bsz=160, num_updates=16480, lr=1.94488e-05, gnorm=4.538, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=34447
2023-06-27 11:47:48 - progress_bar.py[line:272] - INFO: epoch 007:    695 / 2637 loss=2.15, loss_v1=0, loss_v2=0, nll_loss=0.927, ntokens=1256, nsentences=160, sample_size=1256, sample_size_v1=0, sample_size_v2=0, ppl=1.9, wps=602.2, ups=0.48, wpb=1256, bsz=160, num_updates=16490, lr=1.94413e-05, gnorm=4.477, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=34468
2023-06-27 11:48:09 - progress_bar.py[line:272] - INFO: epoch 007:    705 / 2637 loss=2.145, loss_v1=0, loss_v2=0, nll_loss=0.921, ntokens=1269.5, nsentences=160, sample_size=1269.5, sample_size_v1=0, sample_size_v2=0, ppl=1.89, wps=608.2, ups=0.48, wpb=1269.5, bsz=160, num_updates=16500, lr=1.94337e-05, gnorm=4.233, clip=100, loss_scale=128, train_wall=21, gb_free=8.9, wall=34489
2023-06-27 11:48:29 - progress_bar.py[line:272] - INFO: epoch 007:    715 / 2637 loss=2.163, loss_v1=0, loss_v2=0, nll_loss=0.939, ntokens=1253.2, nsentences=160, sample_size=1253.2, sample_size_v1=0, sample_size_v2=0, ppl=1.92, wps=599.8, ups=0.48, wpb=1253.2, bsz=160, num_updates=16510, lr=1.94261e-05, gnorm=4.202, clip=100, loss_scale=128, train_wall=21, gb_free=8.9, wall=34510
2023-06-27 11:48:50 - progress_bar.py[line:272] - INFO: epoch 007:    725 / 2637 loss=2.142, loss_v1=0, loss_v2=0, nll_loss=0.917, ntokens=1254.7, nsentences=160, sample_size=1254.7, sample_size_v1=0, sample_size_v2=0, ppl=1.89, wps=600.6, ups=0.48, wpb=1254.7, bsz=160, num_updates=16520, lr=1.94186e-05, gnorm=4.519, clip=100, loss_scale=128, train_wall=21, gb_free=8.9, wall=34531
2023-06-27 11:49:11 - progress_bar.py[line:272] - INFO: epoch 007:    735 / 2637 loss=2.153, loss_v1=0, loss_v2=0, nll_loss=0.932, ntokens=1264.3, nsentences=160, sample_size=1264.3, sample_size_v1=0, sample_size_v2=0, ppl=1.91, wps=606.6, ups=0.48, wpb=1264.3, bsz=160, num_updates=16530, lr=1.9411e-05, gnorm=4.001, clip=100, loss_scale=128, train_wall=21, gb_free=8.9, wall=34551
2023-06-27 11:49:32 - progress_bar.py[line:272] - INFO: epoch 007:    745 / 2637 loss=2.16, loss_v1=0, loss_v2=0, nll_loss=0.937, ntokens=1269, nsentences=160, sample_size=1269, sample_size_v1=0, sample_size_v2=0, ppl=1.91, wps=608.7, ups=0.48, wpb=1269, bsz=160, num_updates=16540, lr=1.94034e-05, gnorm=4.503, clip=100, loss_scale=128, train_wall=21, gb_free=8.9, wall=34572
2023-06-27 11:49:53 - progress_bar.py[line:272] - INFO: epoch 007:    755 / 2637 loss=2.178, loss_v1=0, loss_v2=0, nll_loss=0.959, ntokens=1260.9, nsentences=160, sample_size=1260.9, sample_size_v1=0, sample_size_v2=0, ppl=1.94, wps=605.8, ups=0.48, wpb=1260.9, bsz=160, num_updates=16550, lr=1.93959e-05, gnorm=4.929, clip=100, loss_scale=128, train_wall=21, gb_free=8.9, wall=34593
2023-06-27 11:50:14 - progress_bar.py[line:272] - INFO: epoch 007:    765 / 2637 loss=2.129, loss_v1=0, loss_v2=0, nll_loss=0.903, ntokens=1252.1, nsentences=160, sample_size=1252.1, sample_size_v1=0, sample_size_v2=0, ppl=1.87, wps=601.2, ups=0.48, wpb=1252.1, bsz=160, num_updates=16560, lr=1.93883e-05, gnorm=4.068, clip=100, loss_scale=128, train_wall=21, gb_free=8.9, wall=34614
2023-06-27 11:50:35 - progress_bar.py[line:272] - INFO: epoch 007:    775 / 2637 loss=2.163, loss_v1=0, loss_v2=0, nll_loss=0.94, ntokens=1260.8, nsentences=160, sample_size=1260.8, sample_size_v1=0, sample_size_v2=0, ppl=1.92, wps=605.6, ups=0.48, wpb=1260.8, bsz=160, num_updates=16570, lr=1.93808e-05, gnorm=3.676, clip=100, loss_scale=128, train_wall=21, gb_free=8.9, wall=34635
2023-06-27 11:50:55 - progress_bar.py[line:272] - INFO: epoch 007:    785 / 2637 loss=2.149, loss_v1=0, loss_v2=0, nll_loss=0.925, ntokens=1257.5, nsentences=160, sample_size=1257.5, sample_size_v1=0, sample_size_v2=0, ppl=1.9, wps=603.6, ups=0.48, wpb=1257.5, bsz=160, num_updates=16580, lr=1.93732e-05, gnorm=4.559, clip=100, loss_scale=128, train_wall=21, gb_free=8.9, wall=34656
2023-06-27 11:51:16 - progress_bar.py[line:272] - INFO: epoch 007:    795 / 2637 loss=2.155, loss_v1=0, loss_v2=0, nll_loss=0.931, ntokens=1256.6, nsentences=160, sample_size=1256.6, sample_size_v1=0, sample_size_v2=0, ppl=1.91, wps=603, ups=0.48, wpb=1256.6, bsz=160, num_updates=16590, lr=1.93656e-05, gnorm=4.42, clip=100, loss_scale=128, train_wall=21, gb_free=8.9, wall=34676
2023-06-27 11:51:37 - progress_bar.py[line:272] - INFO: epoch 007:    805 / 2637 loss=2.141, loss_v1=0, loss_v2=0, nll_loss=0.915, ntokens=1252.2, nsentences=160, sample_size=1252.2, sample_size_v1=0, sample_size_v2=0, ppl=1.89, wps=601.5, ups=0.48, wpb=1252.2, bsz=160, num_updates=16600, lr=1.93581e-05, gnorm=4.364, clip=100, loss_scale=128, train_wall=21, gb_free=8.9, wall=34697
2023-06-27 11:51:58 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2023-06-27 11:52:00 - progress_bar.py[line:272] - INFO: epoch 007:    816 / 2637 loss=2.141, loss_v1=0, loss_v2=0, nll_loss=0.916, ntokens=1256.9, nsentences=160, sample_size=1256.9, sample_size_v1=0, sample_size_v2=0, ppl=1.89, wps=549.1, ups=0.44, wpb=1256.9, bsz=160, num_updates=16610, lr=1.93505e-05, gnorm=5.005, clip=100, loss_scale=64, train_wall=23, gb_free=8.9, wall=34720
2023-06-27 11:52:21 - progress_bar.py[line:272] - INFO: epoch 007:    826 / 2637 loss=2.155, loss_v1=0, loss_v2=0, nll_loss=0.932, ntokens=1249.7, nsentences=160, sample_size=1249.7, sample_size_v1=0, sample_size_v2=0, ppl=1.91, wps=600, ups=0.48, wpb=1249.7, bsz=160, num_updates=16620, lr=1.93429e-05, gnorm=4.441, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=34741
2023-06-27 11:52:42 - progress_bar.py[line:272] - INFO: epoch 007:    836 / 2637 loss=2.168, loss_v1=0, loss_v2=0, nll_loss=0.948, ntokens=1260.5, nsentences=160, sample_size=1260.5, sample_size_v1=0, sample_size_v2=0, ppl=1.93, wps=604.8, ups=0.48, wpb=1260.5, bsz=160, num_updates=16630, lr=1.93354e-05, gnorm=4.409, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=34762
2023-06-27 11:53:02 - progress_bar.py[line:272] - INFO: epoch 007:    846 / 2637 loss=2.158, loss_v1=0, loss_v2=0, nll_loss=0.933, ntokens=1259.7, nsentences=160, sample_size=1259.7, sample_size_v1=0, sample_size_v2=0, ppl=1.91, wps=603.5, ups=0.48, wpb=1259.7, bsz=160, num_updates=16640, lr=1.93278e-05, gnorm=4.7, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=34783
2023-06-27 11:53:23 - progress_bar.py[line:272] - INFO: epoch 007:    856 / 2637 loss=2.151, loss_v1=0, loss_v2=0, nll_loss=0.928, ntokens=1239.6, nsentences=160, sample_size=1239.6, sample_size_v1=0, sample_size_v2=0, ppl=1.9, wps=594, ups=0.48, wpb=1239.6, bsz=160, num_updates=16650, lr=1.93202e-05, gnorm=4.33, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=34804
2023-06-27 11:53:44 - progress_bar.py[line:272] - INFO: epoch 007:    866 / 2637 loss=2.155, loss_v1=0, loss_v2=0, nll_loss=0.931, ntokens=1236.1, nsentences=160, sample_size=1236.1, sample_size_v1=0, sample_size_v2=0, ppl=1.91, wps=593, ups=0.48, wpb=1236.1, bsz=160, num_updates=16660, lr=1.93127e-05, gnorm=4.549, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=34824
2023-06-27 11:54:05 - progress_bar.py[line:272] - INFO: epoch 007:    876 / 2637 loss=2.15, loss_v1=0, loss_v2=0, nll_loss=0.926, ntokens=1255.4, nsentences=160, sample_size=1255.4, sample_size_v1=0, sample_size_v2=0, ppl=1.9, wps=601.9, ups=0.48, wpb=1255.4, bsz=160, num_updates=16670, lr=1.93051e-05, gnorm=4.575, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=34845
2023-06-27 11:54:26 - progress_bar.py[line:272] - INFO: epoch 007:    886 / 2637 loss=2.134, loss_v1=0, loss_v2=0, nll_loss=0.908, ntokens=1255.1, nsentences=160, sample_size=1255.1, sample_size_v1=0, sample_size_v2=0, ppl=1.88, wps=601.7, ups=0.48, wpb=1255.1, bsz=160, num_updates=16680, lr=1.92975e-05, gnorm=4.691, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=34866
2023-06-27 11:54:47 - progress_bar.py[line:272] - INFO: epoch 007:    896 / 2637 loss=2.137, loss_v1=0, loss_v2=0, nll_loss=0.913, ntokens=1250.4, nsentences=160, sample_size=1250.4, sample_size_v1=0, sample_size_v2=0, ppl=1.88, wps=599.3, ups=0.48, wpb=1250.4, bsz=160, num_updates=16690, lr=1.929e-05, gnorm=4.844, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=34887
2023-06-27 11:55:08 - progress_bar.py[line:272] - INFO: epoch 007:    906 / 2637 loss=2.133, loss_v1=0, loss_v2=0, nll_loss=0.908, ntokens=1253.1, nsentences=160, sample_size=1253.1, sample_size_v1=0, sample_size_v2=0, ppl=1.88, wps=600.9, ups=0.48, wpb=1253.1, bsz=160, num_updates=16700, lr=1.92824e-05, gnorm=4.883, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=34908
2023-06-27 11:55:29 - progress_bar.py[line:272] - INFO: epoch 007:    916 / 2637 loss=2.105, loss_v1=0, loss_v2=0, nll_loss=0.877, ntokens=1254.8, nsentences=160, sample_size=1254.8, sample_size_v1=0, sample_size_v2=0, ppl=1.84, wps=601.8, ups=0.48, wpb=1254.8, bsz=160, num_updates=16710, lr=1.92749e-05, gnorm=4.369, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=34929
2023-06-27 11:55:49 - progress_bar.py[line:272] - INFO: epoch 007:    926 / 2637 loss=2.174, loss_v1=0, loss_v2=0, nll_loss=0.956, ntokens=1247.2, nsentences=160, sample_size=1247.2, sample_size_v1=0, sample_size_v2=0, ppl=1.94, wps=598.1, ups=0.48, wpb=1247.2, bsz=160, num_updates=16720, lr=1.92673e-05, gnorm=4.818, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=34950
2023-06-27 11:56:10 - progress_bar.py[line:272] - INFO: epoch 007:    936 / 2637 loss=2.128, loss_v1=0, loss_v2=0, nll_loss=0.901, ntokens=1271.2, nsentences=160, sample_size=1271.2, sample_size_v1=0, sample_size_v2=0, ppl=1.87, wps=608.9, ups=0.48, wpb=1271.2, bsz=160, num_updates=16730, lr=1.92597e-05, gnorm=4.428, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=34971
2023-06-27 11:56:31 - progress_bar.py[line:272] - INFO: epoch 007:    946 / 2637 loss=2.171, loss_v1=0, loss_v2=0, nll_loss=0.948, ntokens=1240.4, nsentences=160, sample_size=1240.4, sample_size_v1=0, sample_size_v2=0, ppl=1.93, wps=594.7, ups=0.48, wpb=1240.4, bsz=160, num_updates=16740, lr=1.92522e-05, gnorm=5.092, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=34991
2023-06-27 11:56:52 - progress_bar.py[line:272] - INFO: epoch 007:    956 / 2637 loss=2.156, loss_v1=0, loss_v2=0, nll_loss=0.932, ntokens=1254.2, nsentences=160, sample_size=1254.2, sample_size_v1=0, sample_size_v2=0, ppl=1.91, wps=600.4, ups=0.48, wpb=1254.2, bsz=160, num_updates=16750, lr=1.92446e-05, gnorm=5.23, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=35012
2023-06-27 11:57:13 - progress_bar.py[line:272] - INFO: epoch 007:    966 / 2637 loss=2.141, loss_v1=0, loss_v2=0, nll_loss=0.919, ntokens=1239.9, nsentences=160, sample_size=1239.9, sample_size_v1=0, sample_size_v2=0, ppl=1.89, wps=594.7, ups=0.48, wpb=1239.9, bsz=160, num_updates=16760, lr=1.9237e-05, gnorm=4.92, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=35033
2023-06-27 11:57:34 - progress_bar.py[line:272] - INFO: epoch 007:    976 / 2637 loss=2.107, loss_v1=0, loss_v2=0, nll_loss=0.88, ntokens=1245.2, nsentences=160, sample_size=1245.2, sample_size_v1=0, sample_size_v2=0, ppl=1.84, wps=597.1, ups=0.48, wpb=1245.2, bsz=160, num_updates=16770, lr=1.92295e-05, gnorm=4.774, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=35054
2023-06-27 11:57:44 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2023-06-27 11:57:57 - progress_bar.py[line:272] - INFO: epoch 007:    987 / 2637 loss=2.166, loss_v1=0, loss_v2=0, nll_loss=0.943, ntokens=1232, nsentences=160, sample_size=1232, sample_size_v1=0, sample_size_v2=0, ppl=1.92, wps=536.8, ups=0.44, wpb=1232, bsz=160, num_updates=16780, lr=1.92219e-05, gnorm=4.812, clip=100, loss_scale=32, train_wall=23, gb_free=8.8, wall=35077
2023-06-27 11:58:18 - progress_bar.py[line:272] - INFO: epoch 007:    997 / 2637 loss=2.12, loss_v1=0, loss_v2=0, nll_loss=0.892, ntokens=1258.1, nsentences=160, sample_size=1258.1, sample_size_v1=0, sample_size_v2=0, ppl=1.86, wps=603.1, ups=0.48, wpb=1258.1, bsz=160, num_updates=16790, lr=1.92143e-05, gnorm=4.576, clip=100, loss_scale=32, train_wall=21, gb_free=8.9, wall=35098
2023-06-27 11:58:38 - progress_bar.py[line:272] - INFO: epoch 007:   1007 / 2637 loss=2.132, loss_v1=0, loss_v2=0, nll_loss=0.908, ntokens=1239.5, nsentences=160, sample_size=1239.5, sample_size_v1=0, sample_size_v2=0, ppl=1.88, wps=594.5, ups=0.48, wpb=1239.5, bsz=160, num_updates=16800, lr=1.92068e-05, gnorm=4.899, clip=100, loss_scale=32, train_wall=21, gb_free=8.9, wall=35119
2023-06-27 11:58:59 - progress_bar.py[line:272] - INFO: epoch 007:   1017 / 2637 loss=2.134, loss_v1=0, loss_v2=0, nll_loss=0.909, ntokens=1231.4, nsentences=160, sample_size=1231.4, sample_size_v1=0, sample_size_v2=0, ppl=1.88, wps=590.2, ups=0.48, wpb=1231.4, bsz=160, num_updates=16810, lr=1.91992e-05, gnorm=4.678, clip=100, loss_scale=32, train_wall=21, gb_free=8.9, wall=35140
2023-06-27 11:59:20 - progress_bar.py[line:272] - INFO: epoch 007:   1027 / 2637 loss=2.142, loss_v1=0, loss_v2=0, nll_loss=0.919, ntokens=1264.1, nsentences=160, sample_size=1264.1, sample_size_v1=0, sample_size_v2=0, ppl=1.89, wps=605.9, ups=0.48, wpb=1264.1, bsz=160, num_updates=16820, lr=1.91916e-05, gnorm=4.322, clip=100, loss_scale=32, train_wall=21, gb_free=8.9, wall=35160
2023-06-27 11:59:41 - progress_bar.py[line:272] - INFO: epoch 007:   1037 / 2637 loss=2.124, loss_v1=0, loss_v2=0, nll_loss=0.897, ntokens=1245.8, nsentences=160, sample_size=1245.8, sample_size_v1=0, sample_size_v2=0, ppl=1.86, wps=597.2, ups=0.48, wpb=1245.8, bsz=160, num_updates=16830, lr=1.91841e-05, gnorm=4.644, clip=100, loss_scale=32, train_wall=21, gb_free=8.9, wall=35181
2023-06-27 12:00:02 - progress_bar.py[line:272] - INFO: epoch 007:   1047 / 2637 loss=2.131, loss_v1=0, loss_v2=0, nll_loss=0.904, ntokens=1257, nsentences=160, sample_size=1257, sample_size_v1=0, sample_size_v2=0, ppl=1.87, wps=602.4, ups=0.48, wpb=1257, bsz=160, num_updates=16840, lr=1.91765e-05, gnorm=4.86, clip=100, loss_scale=32, train_wall=21, gb_free=8.9, wall=35202
2023-06-27 12:00:23 - progress_bar.py[line:272] - INFO: epoch 007:   1057 / 2637 loss=2.14, loss_v1=0, loss_v2=0, nll_loss=0.917, ntokens=1250.4, nsentences=160, sample_size=1250.4, sample_size_v1=0, sample_size_v2=0, ppl=1.89, wps=599.4, ups=0.48, wpb=1250.4, bsz=160, num_updates=16850, lr=1.9169e-05, gnorm=4.925, clip=100, loss_scale=32, train_wall=21, gb_free=8.9, wall=35223
2023-06-27 12:00:44 - progress_bar.py[line:272] - INFO: epoch 007:   1067 / 2637 loss=2.151, loss_v1=0, loss_v2=0, nll_loss=0.927, ntokens=1234.6, nsentences=160, sample_size=1234.6, sample_size_v1=0, sample_size_v2=0, ppl=1.9, wps=592, ups=0.48, wpb=1234.6, bsz=160, num_updates=16860, lr=1.91614e-05, gnorm=4.618, clip=100, loss_scale=32, train_wall=21, gb_free=8.9, wall=35244
2023-06-27 12:01:04 - progress_bar.py[line:272] - INFO: epoch 007:   1077 / 2637 loss=2.131, loss_v1=0, loss_v2=0, nll_loss=0.905, ntokens=1234.1, nsentences=160, sample_size=1234.1, sample_size_v1=0, sample_size_v2=0, ppl=1.87, wps=591.5, ups=0.48, wpb=1234.1, bsz=160, num_updates=16870, lr=1.91538e-05, gnorm=4.644, clip=100, loss_scale=32, train_wall=21, gb_free=8.9, wall=35265
2023-06-27 12:01:25 - progress_bar.py[line:272] - INFO: epoch 007:   1087 / 2637 loss=2.148, loss_v1=0, loss_v2=0, nll_loss=0.926, ntokens=1271, nsentences=160, sample_size=1271, sample_size_v1=0, sample_size_v2=0, ppl=1.9, wps=609.4, ups=0.48, wpb=1271, bsz=160, num_updates=16880, lr=1.91463e-05, gnorm=4.656, clip=100, loss_scale=32, train_wall=21, gb_free=8.9, wall=35286
2023-06-27 12:01:46 - progress_bar.py[line:272] - INFO: epoch 007:   1097 / 2637 loss=2.133, loss_v1=0, loss_v2=0, nll_loss=0.909, ntokens=1235.6, nsentences=160, sample_size=1235.6, sample_size_v1=0, sample_size_v2=0, ppl=1.88, wps=592.5, ups=0.48, wpb=1235.6, bsz=160, num_updates=16890, lr=1.91387e-05, gnorm=4.708, clip=100, loss_scale=32, train_wall=21, gb_free=8.9, wall=35306
2023-06-27 12:02:07 - progress_bar.py[line:272] - INFO: epoch 007:   1107 / 2637 loss=2.121, loss_v1=0, loss_v2=0, nll_loss=0.894, ntokens=1230.6, nsentences=160, sample_size=1230.6, sample_size_v1=0, sample_size_v2=0, ppl=1.86, wps=590, ups=0.48, wpb=1230.6, bsz=160, num_updates=16900, lr=1.91311e-05, gnorm=4.24, clip=100, loss_scale=32, train_wall=21, gb_free=8.9, wall=35327
2023-06-27 12:02:28 - progress_bar.py[line:272] - INFO: epoch 007:   1117 / 2637 loss=2.144, loss_v1=0, loss_v2=0, nll_loss=0.918, ntokens=1238.9, nsentences=160, sample_size=1238.9, sample_size_v1=0, sample_size_v2=0, ppl=1.89, wps=594.4, ups=0.48, wpb=1238.9, bsz=160, num_updates=16910, lr=1.91236e-05, gnorm=5.06, clip=100, loss_scale=32, train_wall=21, gb_free=8.9, wall=35348
2023-06-27 12:02:49 - progress_bar.py[line:272] - INFO: epoch 007:   1127 / 2637 loss=2.148, loss_v1=0, loss_v2=0, nll_loss=0.922, ntokens=1240.5, nsentences=160, sample_size=1240.5, sample_size_v1=0, sample_size_v2=0, ppl=1.9, wps=596, ups=0.48, wpb=1240.5, bsz=160, num_updates=16920, lr=1.9116e-05, gnorm=4.429, clip=100, loss_scale=32, train_wall=21, gb_free=8.9, wall=35369
2023-06-27 12:03:10 - progress_bar.py[line:272] - INFO: epoch 007:   1137 / 2637 loss=2.128, loss_v1=0, loss_v2=0, nll_loss=0.902, ntokens=1251.4, nsentences=160, sample_size=1251.4, sample_size_v1=0, sample_size_v2=0, ppl=1.87, wps=600.7, ups=0.48, wpb=1251.4, bsz=160, num_updates=16930, lr=1.91084e-05, gnorm=5.383, clip=100, loss_scale=32, train_wall=21, gb_free=8.9, wall=35390
2023-06-27 12:03:30 - progress_bar.py[line:272] - INFO: epoch 007:   1147 / 2637 loss=2.132, loss_v1=0, loss_v2=0, nll_loss=0.908, ntokens=1270, nsentences=160, sample_size=1270, sample_size_v1=0, sample_size_v2=0, ppl=1.88, wps=608.9, ups=0.48, wpb=1270, bsz=160, num_updates=16940, lr=1.91009e-05, gnorm=4.473, clip=100, loss_scale=32, train_wall=21, gb_free=8.9, wall=35411
2023-06-27 12:03:51 - progress_bar.py[line:272] - INFO: epoch 007:   1157 / 2637 loss=2.164, loss_v1=0, loss_v2=0, nll_loss=0.942, ntokens=1238.3, nsentences=160, sample_size=1238.3, sample_size_v1=0, sample_size_v2=0, ppl=1.92, wps=593.9, ups=0.48, wpb=1238.3, bsz=160, num_updates=16950, lr=1.90933e-05, gnorm=4.985, clip=100, loss_scale=32, train_wall=21, gb_free=8.9, wall=35432
2023-06-27 12:04:12 - progress_bar.py[line:272] - INFO: epoch 007:   1167 / 2637 loss=2.106, loss_v1=0, loss_v2=0, nll_loss=0.877, ntokens=1250.7, nsentences=160, sample_size=1250.7, sample_size_v1=0, sample_size_v2=0, ppl=1.84, wps=599.6, ups=0.48, wpb=1250.7, bsz=160, num_updates=16960, lr=1.90858e-05, gnorm=4.228, clip=100, loss_scale=32, train_wall=21, gb_free=8.9, wall=35452
2023-06-27 12:04:33 - progress_bar.py[line:272] - INFO: epoch 007:   1177 / 2637 loss=2.143, loss_v1=0, loss_v2=0, nll_loss=0.92, ntokens=1240.2, nsentences=160, sample_size=1240.2, sample_size_v1=0, sample_size_v2=0, ppl=1.89, wps=594, ups=0.48, wpb=1240.2, bsz=160, num_updates=16970, lr=1.90782e-05, gnorm=5.002, clip=100, loss_scale=32, train_wall=21, gb_free=8.9, wall=35473
2023-06-27 12:04:54 - progress_bar.py[line:272] - INFO: epoch 007:   1187 / 2637 loss=2.126, loss_v1=0, loss_v2=0, nll_loss=0.9, ntokens=1258.7, nsentences=160, sample_size=1258.7, sample_size_v1=0, sample_size_v2=0, ppl=1.87, wps=603.7, ups=0.48, wpb=1258.7, bsz=160, num_updates=16980, lr=1.90706e-05, gnorm=4.271, clip=100, loss_scale=32, train_wall=21, gb_free=8.9, wall=35494
2023-06-27 12:05:15 - progress_bar.py[line:272] - INFO: epoch 007:   1197 / 2637 loss=2.149, loss_v1=0, loss_v2=0, nll_loss=0.926, ntokens=1259.2, nsentences=160, sample_size=1259.2, sample_size_v1=0, sample_size_v2=0, ppl=1.9, wps=604.3, ups=0.48, wpb=1259.2, bsz=160, num_updates=16990, lr=1.90631e-05, gnorm=4.541, clip=100, loss_scale=32, train_wall=21, gb_free=8.9, wall=35515
2023-06-27 12:05:35 - progress_bar.py[line:272] - INFO: epoch 007:   1207 / 2637 loss=2.145, loss_v1=0, loss_v2=0, nll_loss=0.922, ntokens=1247.9, nsentences=160, sample_size=1247.9, sample_size_v1=0, sample_size_v2=0, ppl=1.9, wps=599.1, ups=0.48, wpb=1247.9, bsz=160, num_updates=17000, lr=1.90555e-05, gnorm=4.79, clip=100, loss_scale=32, train_wall=21, gb_free=8.9, wall=35536
2023-06-27 12:05:56 - progress_bar.py[line:272] - INFO: epoch 007:   1217 / 2637 loss=2.13, loss_v1=0, loss_v2=0, nll_loss=0.905, ntokens=1259.9, nsentences=160, sample_size=1259.9, sample_size_v1=0, sample_size_v2=0, ppl=1.87, wps=604.8, ups=0.48, wpb=1259.9, bsz=160, num_updates=17010, lr=1.90479e-05, gnorm=4.706, clip=100, loss_scale=32, train_wall=21, gb_free=8.9, wall=35557
2023-06-27 12:06:17 - progress_bar.py[line:272] - INFO: epoch 007:   1227 / 2637 loss=2.14, loss_v1=0, loss_v2=0, nll_loss=0.915, ntokens=1246.4, nsentences=160, sample_size=1246.4, sample_size_v1=0, sample_size_v2=0, ppl=1.88, wps=598.2, ups=0.48, wpb=1246.4, bsz=160, num_updates=17020, lr=1.90404e-05, gnorm=4.724, clip=100, loss_scale=32, train_wall=21, gb_free=8.9, wall=35577
2023-06-27 12:06:38 - progress_bar.py[line:272] - INFO: epoch 007:   1237 / 2637 loss=2.146, loss_v1=0, loss_v2=0, nll_loss=0.922, ntokens=1230.2, nsentences=160, sample_size=1230.2, sample_size_v1=0, sample_size_v2=0, ppl=1.89, wps=591, ups=0.48, wpb=1230.2, bsz=160, num_updates=17030, lr=1.90328e-05, gnorm=4.878, clip=100, loss_scale=32, train_wall=21, gb_free=8.9, wall=35598
2023-06-27 12:06:59 - progress_bar.py[line:272] - INFO: epoch 007:   1247 / 2637 loss=2.13, loss_v1=0, loss_v2=0, nll_loss=0.904, ntokens=1230.1, nsentences=160, sample_size=1230.1, sample_size_v1=0, sample_size_v2=0, ppl=1.87, wps=590.9, ups=0.48, wpb=1230.1, bsz=160, num_updates=17040, lr=1.90252e-05, gnorm=4.971, clip=100, loss_scale=32, train_wall=21, gb_free=8.9, wall=35619
2023-06-27 12:07:20 - progress_bar.py[line:272] - INFO: epoch 007:   1257 / 2637 loss=2.138, loss_v1=0, loss_v2=0, nll_loss=0.915, ntokens=1243.5, nsentences=160, sample_size=1243.5, sample_size_v1=0, sample_size_v2=0, ppl=1.89, wps=596.2, ups=0.48, wpb=1243.5, bsz=160, num_updates=17050, lr=1.90177e-05, gnorm=4.351, clip=100, loss_scale=32, train_wall=21, gb_free=8.9, wall=35640
2023-06-27 12:07:41 - progress_bar.py[line:272] - INFO: epoch 007:   1267 / 2637 loss=2.126, loss_v1=0, loss_v2=0, nll_loss=0.901, ntokens=1251.8, nsentences=160, sample_size=1251.8, sample_size_v1=0, sample_size_v2=0, ppl=1.87, wps=600.4, ups=0.48, wpb=1251.8, bsz=160, num_updates=17060, lr=1.90101e-05, gnorm=4.568, clip=100, loss_scale=32, train_wall=21, gb_free=8.9, wall=35661
2023-06-27 12:08:01 - progress_bar.py[line:272] - INFO: epoch 007:   1277 / 2637 loss=2.17, loss_v1=0, loss_v2=0, nll_loss=0.948, ntokens=1250.1, nsentences=160, sample_size=1250.1, sample_size_v1=0, sample_size_v2=0, ppl=1.93, wps=599.9, ups=0.48, wpb=1250.1, bsz=160, num_updates=17070, lr=1.90025e-05, gnorm=4.808, clip=100, loss_scale=32, train_wall=21, gb_free=8.9, wall=35682
2023-06-27 12:08:22 - progress_bar.py[line:272] - INFO: epoch 007:   1287 / 2637 loss=2.126, loss_v1=0, loss_v2=0, nll_loss=0.898, ntokens=1245.1, nsentences=160, sample_size=1245.1, sample_size_v1=0, sample_size_v2=0, ppl=1.86, wps=597.2, ups=0.48, wpb=1245.1, bsz=160, num_updates=17080, lr=1.8995e-05, gnorm=4.44, clip=100, loss_scale=32, train_wall=21, gb_free=8.9, wall=35702
2023-06-27 12:08:43 - progress_bar.py[line:272] - INFO: epoch 007:   1297 / 2637 loss=2.155, loss_v1=0, loss_v2=0, nll_loss=0.933, ntokens=1237.5, nsentences=160, sample_size=1237.5, sample_size_v1=0, sample_size_v2=0, ppl=1.91, wps=593.9, ups=0.48, wpb=1237.5, bsz=160, num_updates=17090, lr=1.89874e-05, gnorm=4.679, clip=100, loss_scale=32, train_wall=21, gb_free=8.9, wall=35723
2023-06-27 12:09:04 - progress_bar.py[line:272] - INFO: epoch 007:   1307 / 2637 loss=2.142, loss_v1=0, loss_v2=0, nll_loss=0.917, ntokens=1254.4, nsentences=160, sample_size=1254.4, sample_size_v1=0, sample_size_v2=0, ppl=1.89, wps=601.3, ups=0.48, wpb=1254.4, bsz=160, num_updates=17100, lr=1.89799e-05, gnorm=4.323, clip=100, loss_scale=32, train_wall=21, gb_free=8.9, wall=35744
2023-06-27 12:09:25 - progress_bar.py[line:272] - INFO: epoch 007:   1317 / 2637 loss=2.139, loss_v1=0, loss_v2=0, nll_loss=0.914, ntokens=1236.4, nsentences=160, sample_size=1236.4, sample_size_v1=0, sample_size_v2=0, ppl=1.88, wps=592.7, ups=0.48, wpb=1236.4, bsz=160, num_updates=17110, lr=1.89723e-05, gnorm=3.991, clip=100, loss_scale=32, train_wall=21, gb_free=8.9, wall=35765
2023-06-27 12:09:46 - progress_bar.py[line:272] - INFO: epoch 007:   1327 / 2637 loss=2.122, loss_v1=0, loss_v2=0, nll_loss=0.895, ntokens=1234.1, nsentences=160, sample_size=1234.1, sample_size_v1=0, sample_size_v2=0, ppl=1.86, wps=591.7, ups=0.48, wpb=1234.1, bsz=160, num_updates=17120, lr=1.89647e-05, gnorm=4.242, clip=100, loss_scale=32, train_wall=21, gb_free=8.9, wall=35786
2023-06-27 12:10:07 - progress_bar.py[line:272] - INFO: epoch 007:   1337 / 2637 loss=2.152, loss_v1=0, loss_v2=0, nll_loss=0.929, ntokens=1232.5, nsentences=160, sample_size=1232.5, sample_size_v1=0, sample_size_v2=0, ppl=1.9, wps=590.8, ups=0.48, wpb=1232.5, bsz=160, num_updates=17130, lr=1.89572e-05, gnorm=4.547, clip=100, loss_scale=32, train_wall=21, gb_free=8.9, wall=35807
2023-06-27 12:10:27 - progress_bar.py[line:272] - INFO: epoch 007:   1347 / 2637 loss=2.14, loss_v1=0, loss_v2=0, nll_loss=0.917, ntokens=1220.4, nsentences=160, sample_size=1220.4, sample_size_v1=0, sample_size_v2=0, ppl=1.89, wps=585, ups=0.48, wpb=1220.4, bsz=160, num_updates=17140, lr=1.89496e-05, gnorm=4.981, clip=100, loss_scale=32, train_wall=21, gb_free=8.9, wall=35828
2023-06-27 12:10:48 - progress_bar.py[line:272] - INFO: epoch 007:   1357 / 2637 loss=2.129, loss_v1=0, loss_v2=0, nll_loss=0.903, ntokens=1245, nsentences=160, sample_size=1245, sample_size_v1=0, sample_size_v2=0, ppl=1.87, wps=597, ups=0.48, wpb=1245, bsz=160, num_updates=17150, lr=1.8942e-05, gnorm=4.38, clip=100, loss_scale=32, train_wall=21, gb_free=8.9, wall=35849
2023-06-27 12:11:09 - progress_bar.py[line:272] - INFO: epoch 007:   1367 / 2637 loss=2.156, loss_v1=0, loss_v2=0, nll_loss=0.933, ntokens=1235.7, nsentences=160, sample_size=1235.7, sample_size_v1=0, sample_size_v2=0, ppl=1.91, wps=592.5, ups=0.48, wpb=1235.7, bsz=160, num_updates=17160, lr=1.89345e-05, gnorm=4.833, clip=100, loss_scale=32, train_wall=21, gb_free=8.9, wall=35869
2023-06-27 12:11:30 - progress_bar.py[line:272] - INFO: epoch 007:   1377 / 2637 loss=2.165, loss_v1=0, loss_v2=0, nll_loss=0.945, ntokens=1234.3, nsentences=160, sample_size=1234.3, sample_size_v1=0, sample_size_v2=0, ppl=1.92, wps=592.1, ups=0.48, wpb=1234.3, bsz=160, num_updates=17170, lr=1.89269e-05, gnorm=5.216, clip=100, loss_scale=32, train_wall=21, gb_free=8.9, wall=35890
2023-06-27 12:11:51 - progress_bar.py[line:272] - INFO: epoch 007:   1387 / 2637 loss=2.134, loss_v1=0, loss_v2=0, nll_loss=0.909, ntokens=1261.9, nsentences=160, sample_size=1261.9, sample_size_v1=0, sample_size_v2=0, ppl=1.88, wps=604.7, ups=0.48, wpb=1261.9, bsz=160, num_updates=17180, lr=1.89193e-05, gnorm=4.275, clip=100, loss_scale=32, train_wall=21, gb_free=8.9, wall=35911
2023-06-27 12:12:12 - progress_bar.py[line:272] - INFO: epoch 007:   1397 / 2637 loss=2.124, loss_v1=0, loss_v2=0, nll_loss=0.898, ntokens=1276.1, nsentences=160, sample_size=1276.1, sample_size_v1=0, sample_size_v2=0, ppl=1.86, wps=611, ups=0.48, wpb=1276.1, bsz=160, num_updates=17190, lr=1.89118e-05, gnorm=4.527, clip=100, loss_scale=32, train_wall=21, gb_free=8.9, wall=35932
2023-06-27 12:12:33 - progress_bar.py[line:272] - INFO: epoch 007:   1407 / 2637 loss=2.157, loss_v1=0, loss_v2=0, nll_loss=0.935, ntokens=1268.2, nsentences=160, sample_size=1268.2, sample_size_v1=0, sample_size_v2=0, ppl=1.91, wps=607.2, ups=0.48, wpb=1268.2, bsz=160, num_updates=17200, lr=1.89042e-05, gnorm=4.91, clip=100, loss_scale=32, train_wall=21, gb_free=8.9, wall=35953
2023-06-27 12:12:53 - progress_bar.py[line:272] - INFO: epoch 007:   1417 / 2637 loss=2.152, loss_v1=0, loss_v2=0, nll_loss=0.926, ntokens=1268, nsentences=160, sample_size=1268, sample_size_v1=0, sample_size_v2=0, ppl=1.9, wps=607.1, ups=0.48, wpb=1268, bsz=160, num_updates=17210, lr=1.88966e-05, gnorm=4.495, clip=100, loss_scale=32, train_wall=21, gb_free=8.9, wall=35974
2023-06-27 12:13:14 - progress_bar.py[line:272] - INFO: epoch 007:   1427 / 2637 loss=2.124, loss_v1=0, loss_v2=0, nll_loss=0.896, ntokens=1281.5, nsentences=160, sample_size=1281.5, sample_size_v1=0, sample_size_v2=0, ppl=1.86, wps=613.7, ups=0.48, wpb=1281.5, bsz=160, num_updates=17220, lr=1.88891e-05, gnorm=4.334, clip=100, loss_scale=32, train_wall=21, gb_free=8.9, wall=35995
2023-06-27 12:13:35 - progress_bar.py[line:272] - INFO: epoch 007:   1437 / 2637 loss=2.133, loss_v1=0, loss_v2=0, nll_loss=0.908, ntokens=1271.9, nsentences=160, sample_size=1271.9, sample_size_v1=0, sample_size_v2=0, ppl=1.88, wps=609.3, ups=0.48, wpb=1271.9, bsz=160, num_updates=17230, lr=1.88815e-05, gnorm=4.277, clip=100, loss_scale=32, train_wall=21, gb_free=8.9, wall=36016
2023-06-27 12:13:56 - progress_bar.py[line:272] - INFO: epoch 007:   1447 / 2637 loss=2.162, loss_v1=0, loss_v2=0, nll_loss=0.941, ntokens=1284.5, nsentences=160, sample_size=1284.5, sample_size_v1=0, sample_size_v2=0, ppl=1.92, wps=615.8, ups=0.48, wpb=1284.5, bsz=160, num_updates=17240, lr=1.8874e-05, gnorm=4.534, clip=100, loss_scale=32, train_wall=21, gb_free=8.9, wall=36036
2023-06-27 12:14:17 - progress_bar.py[line:272] - INFO: epoch 007:   1457 / 2637 loss=2.146, loss_v1=0, loss_v2=0, nll_loss=0.922, ntokens=1279.5, nsentences=160, sample_size=1279.5, sample_size_v1=0, sample_size_v2=0, ppl=1.89, wps=611.4, ups=0.48, wpb=1279.5, bsz=160, num_updates=17250, lr=1.88664e-05, gnorm=4.52, clip=100, loss_scale=32, train_wall=21, gb_free=8.9, wall=36057
2023-06-27 12:14:38 - progress_bar.py[line:272] - INFO: epoch 007:   1467 / 2637 loss=2.152, loss_v1=0, loss_v2=0, nll_loss=0.929, ntokens=1277.1, nsentences=160, sample_size=1277.1, sample_size_v1=0, sample_size_v2=0, ppl=1.9, wps=611.3, ups=0.48, wpb=1277.1, bsz=160, num_updates=17260, lr=1.88588e-05, gnorm=4.159, clip=100, loss_scale=32, train_wall=21, gb_free=8.9, wall=36078
2023-06-27 12:14:59 - progress_bar.py[line:272] - INFO: epoch 007:   1477 / 2637 loss=2.148, loss_v1=0, loss_v2=0, nll_loss=0.923, ntokens=1268.6, nsentences=160, sample_size=1268.6, sample_size_v1=0, sample_size_v2=0, ppl=1.9, wps=607.3, ups=0.48, wpb=1268.6, bsz=160, num_updates=17270, lr=1.88513e-05, gnorm=4.76, clip=100, loss_scale=32, train_wall=21, gb_free=8.9, wall=36099
2023-06-27 12:15:20 - progress_bar.py[line:272] - INFO: epoch 007:   1487 / 2637 loss=2.154, loss_v1=0, loss_v2=0, nll_loss=0.933, ntokens=1277.2, nsentences=160, sample_size=1277.2, sample_size_v1=0, sample_size_v2=0, ppl=1.91, wps=611.5, ups=0.48, wpb=1277.2, bsz=160, num_updates=17280, lr=1.88437e-05, gnorm=4.47, clip=100, loss_scale=32, train_wall=21, gb_free=8.9, wall=36120
2023-06-27 12:15:41 - progress_bar.py[line:272] - INFO: epoch 007:   1497 / 2637 loss=2.146, loss_v1=0, loss_v2=0, nll_loss=0.924, ntokens=1293.8, nsentences=160, sample_size=1293.8, sample_size_v1=0, sample_size_v2=0, ppl=1.9, wps=619.8, ups=0.48, wpb=1293.8, bsz=160, num_updates=17290, lr=1.88361e-05, gnorm=4.134, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=36141
2023-06-27 12:16:01 - progress_bar.py[line:272] - INFO: epoch 007:   1507 / 2637 loss=2.148, loss_v1=0, loss_v2=0, nll_loss=0.924, ntokens=1274.5, nsentences=160, sample_size=1274.5, sample_size_v1=0, sample_size_v2=0, ppl=1.9, wps=610.3, ups=0.48, wpb=1274.5, bsz=160, num_updates=17300, lr=1.88286e-05, gnorm=5.106, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=36162
2023-06-27 12:16:22 - progress_bar.py[line:272] - INFO: epoch 007:   1517 / 2637 loss=2.142, loss_v1=0, loss_v2=0, nll_loss=0.919, ntokens=1265.8, nsentences=160, sample_size=1265.8, sample_size_v1=0, sample_size_v2=0, ppl=1.89, wps=606, ups=0.48, wpb=1265.8, bsz=160, num_updates=17310, lr=1.8821e-05, gnorm=5.049, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=36183
2023-06-27 12:16:43 - progress_bar.py[line:272] - INFO: epoch 007:   1527 / 2637 loss=2.18, loss_v1=0, loss_v2=0, nll_loss=0.96, ntokens=1266.1, nsentences=160, sample_size=1266.1, sample_size_v1=0, sample_size_v2=0, ppl=1.95, wps=606, ups=0.48, wpb=1266.1, bsz=160, num_updates=17320, lr=1.88134e-05, gnorm=5.494, clip=100, loss_scale=64, train_wall=21, gb_free=8.8, wall=36204
2023-06-27 12:17:04 - progress_bar.py[line:272] - INFO: epoch 007:   1537 / 2637 loss=2.151, loss_v1=0, loss_v2=0, nll_loss=0.927, ntokens=1264.8, nsentences=160, sample_size=1264.8, sample_size_v1=0, sample_size_v2=0, ppl=1.9, wps=605.5, ups=0.48, wpb=1264.8, bsz=160, num_updates=17330, lr=1.88059e-05, gnorm=4.552, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=36224
2023-06-27 12:17:25 - progress_bar.py[line:272] - INFO: epoch 007:   1547 / 2637 loss=2.167, loss_v1=0, loss_v2=0, nll_loss=0.946, ntokens=1268.9, nsentences=160, sample_size=1268.9, sample_size_v1=0, sample_size_v2=0, ppl=1.93, wps=607.6, ups=0.48, wpb=1268.9, bsz=160, num_updates=17340, lr=1.87983e-05, gnorm=4.439, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=36245
2023-06-27 12:17:46 - progress_bar.py[line:272] - INFO: epoch 007:   1557 / 2637 loss=2.158, loss_v1=0, loss_v2=0, nll_loss=0.936, ntokens=1276.2, nsentences=160, sample_size=1276.2, sample_size_v1=0, sample_size_v2=0, ppl=1.91, wps=610.9, ups=0.48, wpb=1276.2, bsz=160, num_updates=17350, lr=1.87908e-05, gnorm=4.406, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=36266
2023-06-27 12:18:07 - progress_bar.py[line:272] - INFO: epoch 007:   1567 / 2637 loss=2.14, loss_v1=0, loss_v2=0, nll_loss=0.915, ntokens=1263.8, nsentences=160, sample_size=1263.8, sample_size_v1=0, sample_size_v2=0, ppl=1.89, wps=605.4, ups=0.48, wpb=1263.8, bsz=160, num_updates=17360, lr=1.87832e-05, gnorm=4.433, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=36287
2023-06-27 12:18:28 - progress_bar.py[line:272] - INFO: epoch 007:   1577 / 2637 loss=2.146, loss_v1=0, loss_v2=0, nll_loss=0.922, ntokens=1268.3, nsentences=160, sample_size=1268.3, sample_size_v1=0, sample_size_v2=0, ppl=1.9, wps=606.9, ups=0.48, wpb=1268.3, bsz=160, num_updates=17370, lr=1.87756e-05, gnorm=4.184, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=36308
2023-06-27 12:18:49 - progress_bar.py[line:272] - INFO: epoch 007:   1587 / 2637 loss=2.154, loss_v1=0, loss_v2=0, nll_loss=0.93, ntokens=1268.2, nsentences=160, sample_size=1268.2, sample_size_v1=0, sample_size_v2=0, ppl=1.91, wps=607.4, ups=0.48, wpb=1268.2, bsz=160, num_updates=17380, lr=1.87681e-05, gnorm=4.863, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=36329
2023-06-27 12:19:09 - progress_bar.py[line:272] - INFO: epoch 007:   1597 / 2637 loss=2.14, loss_v1=0, loss_v2=0, nll_loss=0.917, ntokens=1271.7, nsentences=160, sample_size=1271.7, sample_size_v1=0, sample_size_v2=0, ppl=1.89, wps=609.4, ups=0.48, wpb=1271.7, bsz=160, num_updates=17390, lr=1.87605e-05, gnorm=4.714, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=36350
2023-06-27 12:19:30 - progress_bar.py[line:272] - INFO: epoch 007:   1607 / 2637 loss=2.166, loss_v1=0, loss_v2=0, nll_loss=0.945, ntokens=1256.6, nsentences=160, sample_size=1256.6, sample_size_v1=0, sample_size_v2=0, ppl=1.93, wps=601.9, ups=0.48, wpb=1256.6, bsz=160, num_updates=17400, lr=1.87529e-05, gnorm=4.634, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=36371
2023-06-27 12:19:51 - progress_bar.py[line:272] - INFO: epoch 007:   1617 / 2637 loss=2.16, loss_v1=0, loss_v2=0, nll_loss=0.939, ntokens=1265, nsentences=160, sample_size=1265, sample_size_v1=0, sample_size_v2=0, ppl=1.92, wps=606.3, ups=0.48, wpb=1265, bsz=160, num_updates=17410, lr=1.87454e-05, gnorm=4.103, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=36392
2023-06-27 12:20:12 - progress_bar.py[line:272] - INFO: epoch 007:   1627 / 2637 loss=2.181, loss_v1=0, loss_v2=0, nll_loss=0.96, ntokens=1263.6, nsentences=160, sample_size=1263.6, sample_size_v1=0, sample_size_v2=0, ppl=1.95, wps=605.5, ups=0.48, wpb=1263.6, bsz=160, num_updates=17420, lr=1.87378e-05, gnorm=4.862, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=36412
2023-06-27 12:20:33 - progress_bar.py[line:272] - INFO: epoch 007:   1637 / 2637 loss=2.122, loss_v1=0, loss_v2=0, nll_loss=0.895, ntokens=1268.4, nsentences=160, sample_size=1268.4, sample_size_v1=0, sample_size_v2=0, ppl=1.86, wps=606.4, ups=0.48, wpb=1268.4, bsz=160, num_updates=17430, lr=1.87302e-05, gnorm=4.191, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=36433
2023-06-27 12:20:54 - progress_bar.py[line:272] - INFO: epoch 007:   1647 / 2637 loss=2.147, loss_v1=0, loss_v2=0, nll_loss=0.925, ntokens=1267.2, nsentences=160, sample_size=1267.2, sample_size_v1=0, sample_size_v2=0, ppl=1.9, wps=606.2, ups=0.48, wpb=1267.2, bsz=160, num_updates=17440, lr=1.87227e-05, gnorm=4.209, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=36454
2023-06-27 12:21:15 - progress_bar.py[line:272] - INFO: epoch 007:   1657 / 2637 loss=2.186, loss_v1=0, loss_v2=0, nll_loss=0.966, ntokens=1261.4, nsentences=160, sample_size=1261.4, sample_size_v1=0, sample_size_v2=0, ppl=1.95, wps=605.2, ups=0.48, wpb=1261.4, bsz=160, num_updates=17450, lr=1.87151e-05, gnorm=4.925, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=36475
2023-06-27 12:21:36 - progress_bar.py[line:272] - INFO: epoch 007:   1667 / 2637 loss=2.144, loss_v1=0, loss_v2=0, nll_loss=0.92, ntokens=1271, nsentences=160, sample_size=1271, sample_size_v1=0, sample_size_v2=0, ppl=1.89, wps=609.9, ups=0.48, wpb=1271, bsz=160, num_updates=17460, lr=1.87075e-05, gnorm=5.099, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=36496
2023-06-27 12:21:56 - progress_bar.py[line:272] - INFO: epoch 007:   1677 / 2637 loss=2.142, loss_v1=0, loss_v2=0, nll_loss=0.916, ntokens=1258.9, nsentences=160, sample_size=1258.9, sample_size_v1=0, sample_size_v2=0, ppl=1.89, wps=604.4, ups=0.48, wpb=1258.9, bsz=160, num_updates=17470, lr=1.87e-05, gnorm=4.468, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=36517
2023-06-27 12:22:17 - progress_bar.py[line:272] - INFO: epoch 007:   1687 / 2637 loss=2.141, loss_v1=0, loss_v2=0, nll_loss=0.916, ntokens=1274.4, nsentences=160, sample_size=1274.4, sample_size_v1=0, sample_size_v2=0, ppl=1.89, wps=611.5, ups=0.48, wpb=1274.4, bsz=160, num_updates=17480, lr=1.86924e-05, gnorm=4.358, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=36538
2023-06-27 12:22:38 - progress_bar.py[line:272] - INFO: epoch 007:   1697 / 2637 loss=2.151, loss_v1=0, loss_v2=0, nll_loss=0.928, ntokens=1272.3, nsentences=160, sample_size=1272.3, sample_size_v1=0, sample_size_v2=0, ppl=1.9, wps=610.8, ups=0.48, wpb=1272.3, bsz=160, num_updates=17490, lr=1.86849e-05, gnorm=4.335, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=36558
2023-06-27 12:22:59 - progress_bar.py[line:272] - INFO: epoch 007:   1707 / 2637 loss=2.134, loss_v1=0, loss_v2=0, nll_loss=0.908, ntokens=1282.2, nsentences=160, sample_size=1282.2, sample_size_v1=0, sample_size_v2=0, ppl=1.88, wps=615.3, ups=0.48, wpb=1282.2, bsz=160, num_updates=17500, lr=1.86773e-05, gnorm=4.374, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=36579
2023-06-27 12:23:20 - progress_bar.py[line:272] - INFO: epoch 007:   1717 / 2637 loss=2.156, loss_v1=0, loss_v2=0, nll_loss=0.934, ntokens=1274.5, nsentences=160, sample_size=1274.5, sample_size_v1=0, sample_size_v2=0, ppl=1.91, wps=611.6, ups=0.48, wpb=1274.5, bsz=160, num_updates=17510, lr=1.86697e-05, gnorm=4.854, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=36600
2023-06-27 12:23:41 - progress_bar.py[line:272] - INFO: epoch 007:   1727 / 2637 loss=2.156, loss_v1=0, loss_v2=0, nll_loss=0.935, ntokens=1281.8, nsentences=160, sample_size=1281.8, sample_size_v1=0, sample_size_v2=0, ppl=1.91, wps=615.5, ups=0.48, wpb=1281.8, bsz=160, num_updates=17520, lr=1.86622e-05, gnorm=4.846, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=36621
2023-06-27 12:24:01 - progress_bar.py[line:272] - INFO: epoch 007:   1737 / 2637 loss=2.122, loss_v1=0, loss_v2=0, nll_loss=0.896, ntokens=1257.4, nsentences=160, sample_size=1257.4, sample_size_v1=0, sample_size_v2=0, ppl=1.86, wps=603.7, ups=0.48, wpb=1257.4, bsz=160, num_updates=17530, lr=1.86546e-05, gnorm=4.252, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=36642
2023-06-27 12:24:22 - progress_bar.py[line:272] - INFO: epoch 007:   1747 / 2637 loss=2.175, loss_v1=0, loss_v2=0, nll_loss=0.954, ntokens=1283.2, nsentences=160, sample_size=1283.2, sample_size_v1=0, sample_size_v2=0, ppl=1.94, wps=615.9, ups=0.48, wpb=1283.2, bsz=160, num_updates=17540, lr=1.8647e-05, gnorm=4.68, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=36663
2023-06-27 12:24:43 - progress_bar.py[line:272] - INFO: epoch 007:   1757 / 2637 loss=2.136, loss_v1=0, loss_v2=0, nll_loss=0.908, ntokens=1262.1, nsentences=160, sample_size=1262.1, sample_size_v1=0, sample_size_v2=0, ppl=1.88, wps=606.1, ups=0.48, wpb=1262.1, bsz=160, num_updates=17550, lr=1.86395e-05, gnorm=4.2, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=36683
2023-06-27 12:25:04 - progress_bar.py[line:272] - INFO: epoch 007:   1767 / 2637 loss=2.146, loss_v1=0, loss_v2=0, nll_loss=0.92, ntokens=1279.2, nsentences=160, sample_size=1279.2, sample_size_v1=0, sample_size_v2=0, ppl=1.89, wps=613.6, ups=0.48, wpb=1279.2, bsz=160, num_updates=17560, lr=1.86319e-05, gnorm=3.742, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=36704
2023-06-27 12:25:25 - progress_bar.py[line:272] - INFO: epoch 007:   1777 / 2637 loss=2.134, loss_v1=0, loss_v2=0, nll_loss=0.909, ntokens=1269.1, nsentences=160, sample_size=1269.1, sample_size_v1=0, sample_size_v2=0, ppl=1.88, wps=609.2, ups=0.48, wpb=1269.1, bsz=160, num_updates=17570, lr=1.86243e-05, gnorm=4.801, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=36725
2023-06-27 12:25:46 - progress_bar.py[line:272] - INFO: epoch 007:   1787 / 2637 loss=2.149, loss_v1=0, loss_v2=0, nll_loss=0.926, ntokens=1305, nsentences=160, sample_size=1305, sample_size_v1=0, sample_size_v2=0, ppl=1.9, wps=626.8, ups=0.48, wpb=1305, bsz=160, num_updates=17580, lr=1.86168e-05, gnorm=4.227, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=36746
2023-06-27 12:26:06 - progress_bar.py[line:272] - INFO: epoch 007:   1797 / 2637 loss=2.186, loss_v1=0, loss_v2=0, nll_loss=0.967, ntokens=1263.7, nsentences=160, sample_size=1263.7, sample_size_v1=0, sample_size_v2=0, ppl=1.95, wps=606.4, ups=0.48, wpb=1263.7, bsz=160, num_updates=17590, lr=1.86092e-05, gnorm=4.977, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=36767
2023-06-27 12:26:27 - progress_bar.py[line:272] - INFO: epoch 007:   1807 / 2637 loss=2.135, loss_v1=0, loss_v2=0, nll_loss=0.911, ntokens=1277.9, nsentences=160, sample_size=1277.9, sample_size_v1=0, sample_size_v2=0, ppl=1.88, wps=613.2, ups=0.48, wpb=1277.9, bsz=160, num_updates=17600, lr=1.86016e-05, gnorm=4.379, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=36788
2023-06-27 12:26:48 - progress_bar.py[line:272] - INFO: epoch 007:   1817 / 2637 loss=2.137, loss_v1=0, loss_v2=0, nll_loss=0.911, ntokens=1261.7, nsentences=160, sample_size=1261.7, sample_size_v1=0, sample_size_v2=0, ppl=1.88, wps=605.9, ups=0.48, wpb=1261.7, bsz=160, num_updates=17610, lr=1.85941e-05, gnorm=4.39, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=36808
2023-06-27 12:27:09 - progress_bar.py[line:272] - INFO: epoch 007:   1827 / 2637 loss=2.14, loss_v1=0, loss_v2=0, nll_loss=0.917, ntokens=1271.1, nsentences=160, sample_size=1271.1, sample_size_v1=0, sample_size_v2=0, ppl=1.89, wps=609.8, ups=0.48, wpb=1271.1, bsz=160, num_updates=17620, lr=1.85865e-05, gnorm=4.763, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=36829
2023-06-27 12:27:30 - progress_bar.py[line:272] - INFO: epoch 007:   1837 / 2637 loss=2.135, loss_v1=0, loss_v2=0, nll_loss=0.91, ntokens=1295.6, nsentences=160, sample_size=1295.6, sample_size_v1=0, sample_size_v2=0, ppl=1.88, wps=621.4, ups=0.48, wpb=1295.6, bsz=160, num_updates=17630, lr=1.8579e-05, gnorm=4.43, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=36850
2023-06-27 12:27:51 - progress_bar.py[line:272] - INFO: epoch 007:   1847 / 2637 loss=2.139, loss_v1=0, loss_v2=0, nll_loss=0.913, ntokens=1288.6, nsentences=160, sample_size=1288.6, sample_size_v1=0, sample_size_v2=0, ppl=1.88, wps=619, ups=0.48, wpb=1288.6, bsz=160, num_updates=17640, lr=1.85714e-05, gnorm=4.681, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=36871
2023-06-27 12:28:12 - progress_bar.py[line:272] - INFO: epoch 007:   1857 / 2637 loss=2.144, loss_v1=0, loss_v2=0, nll_loss=0.92, ntokens=1259, nsentences=160, sample_size=1259, sample_size_v1=0, sample_size_v2=0, ppl=1.89, wps=604.5, ups=0.48, wpb=1259, bsz=160, num_updates=17650, lr=1.85638e-05, gnorm=4.207, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=36892
2023-06-27 12:28:32 - progress_bar.py[line:272] - INFO: epoch 007:   1867 / 2637 loss=2.137, loss_v1=0, loss_v2=0, nll_loss=0.912, ntokens=1273.1, nsentences=160, sample_size=1273.1, sample_size_v1=0, sample_size_v2=0, ppl=1.88, wps=610.6, ups=0.48, wpb=1273.1, bsz=160, num_updates=17660, lr=1.85563e-05, gnorm=4.871, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=36913
2023-06-27 12:28:53 - progress_bar.py[line:272] - INFO: epoch 007:   1877 / 2637 loss=2.148, loss_v1=0, loss_v2=0, nll_loss=0.924, ntokens=1275.1, nsentences=160, sample_size=1275.1, sample_size_v1=0, sample_size_v2=0, ppl=1.9, wps=611.4, ups=0.48, wpb=1275.1, bsz=160, num_updates=17670, lr=1.85487e-05, gnorm=4.324, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=36934
2023-06-27 12:29:14 - progress_bar.py[line:272] - INFO: epoch 007:   1887 / 2637 loss=2.111, loss_v1=0, loss_v2=0, nll_loss=0.882, ntokens=1276.3, nsentences=160, sample_size=1276.3, sample_size_v1=0, sample_size_v2=0, ppl=1.84, wps=611.1, ups=0.48, wpb=1276.3, bsz=160, num_updates=17680, lr=1.85411e-05, gnorm=4.078, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=36954
2023-06-27 12:29:35 - progress_bar.py[line:272] - INFO: epoch 007:   1897 / 2637 loss=2.128, loss_v1=0, loss_v2=0, nll_loss=0.901, ntokens=1287.7, nsentences=160, sample_size=1287.7, sample_size_v1=0, sample_size_v2=0, ppl=1.87, wps=616.8, ups=0.48, wpb=1287.7, bsz=160, num_updates=17690, lr=1.85336e-05, gnorm=4.324, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=36975
2023-06-27 12:29:56 - progress_bar.py[line:272] - INFO: epoch 007:   1907 / 2637 loss=2.131, loss_v1=0, loss_v2=0, nll_loss=0.907, ntokens=1269.9, nsentences=160, sample_size=1269.9, sample_size_v1=0, sample_size_v2=0, ppl=1.87, wps=609, ups=0.48, wpb=1269.9, bsz=160, num_updates=17700, lr=1.8526e-05, gnorm=4.735, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=36996
2023-06-27 12:30:17 - progress_bar.py[line:272] - INFO: epoch 007:   1917 / 2637 loss=2.118, loss_v1=0, loss_v2=0, nll_loss=0.893, ntokens=1273.8, nsentences=160, sample_size=1273.8, sample_size_v1=0, sample_size_v2=0, ppl=1.86, wps=610.2, ups=0.48, wpb=1273.8, bsz=160, num_updates=17710, lr=1.85184e-05, gnorm=4.401, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=37017
2023-06-27 12:30:38 - progress_bar.py[line:272] - INFO: epoch 007:   1927 / 2637 loss=2.173, loss_v1=0, loss_v2=0, nll_loss=0.953, ntokens=1269.1, nsentences=160, sample_size=1269.1, sample_size_v1=0, sample_size_v2=0, ppl=1.94, wps=608.3, ups=0.48, wpb=1269.1, bsz=160, num_updates=17720, lr=1.85109e-05, gnorm=4.434, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=37038
2023-06-27 12:30:58 - progress_bar.py[line:272] - INFO: epoch 007:   1937 / 2637 loss=2.127, loss_v1=0, loss_v2=0, nll_loss=0.899, ntokens=1271.1, nsentences=160, sample_size=1271.1, sample_size_v1=0, sample_size_v2=0, ppl=1.86, wps=609.1, ups=0.48, wpb=1271.1, bsz=160, num_updates=17730, lr=1.85033e-05, gnorm=4.688, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=37059
2023-06-27 12:31:19 - progress_bar.py[line:272] - INFO: epoch 007:   1947 / 2637 loss=2.141, loss_v1=0, loss_v2=0, nll_loss=0.916, ntokens=1290.6, nsentences=160, sample_size=1290.6, sample_size_v1=0, sample_size_v2=0, ppl=1.89, wps=618, ups=0.48, wpb=1290.6, bsz=160, num_updates=17740, lr=1.84958e-05, gnorm=4.201, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=37080
2023-06-27 12:31:40 - progress_bar.py[line:272] - INFO: epoch 007:   1957 / 2637 loss=2.152, loss_v1=0, loss_v2=0, nll_loss=0.93, ntokens=1276.3, nsentences=160, sample_size=1276.3, sample_size_v1=0, sample_size_v2=0, ppl=1.91, wps=611.7, ups=0.48, wpb=1276.3, bsz=160, num_updates=17750, lr=1.84882e-05, gnorm=4.931, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=37101
2023-06-27 12:32:01 - progress_bar.py[line:272] - INFO: epoch 007:   1967 / 2637 loss=2.153, loss_v1=0, loss_v2=0, nll_loss=0.928, ntokens=1259.8, nsentences=160, sample_size=1259.8, sample_size_v1=0, sample_size_v2=0, ppl=1.9, wps=604.1, ups=0.48, wpb=1259.8, bsz=160, num_updates=17760, lr=1.84806e-05, gnorm=4.794, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=37121
2023-06-27 12:32:22 - progress_bar.py[line:272] - INFO: epoch 007:   1977 / 2637 loss=2.176, loss_v1=0, loss_v2=0, nll_loss=0.955, ntokens=1275.5, nsentences=160, sample_size=1275.5, sample_size_v1=0, sample_size_v2=0, ppl=1.94, wps=611.2, ups=0.48, wpb=1275.5, bsz=160, num_updates=17770, lr=1.84731e-05, gnorm=4.767, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=37142
2023-06-27 12:32:43 - progress_bar.py[line:272] - INFO: epoch 007:   1987 / 2637 loss=2.134, loss_v1=0, loss_v2=0, nll_loss=0.91, ntokens=1301, nsentences=160, sample_size=1301, sample_size_v1=0, sample_size_v2=0, ppl=1.88, wps=623.5, ups=0.48, wpb=1301, bsz=160, num_updates=17780, lr=1.84655e-05, gnorm=4.329, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=37163
2023-06-27 12:33:04 - progress_bar.py[line:272] - INFO: epoch 007:   1997 / 2637 loss=2.159, loss_v1=0, loss_v2=0, nll_loss=0.936, ntokens=1284, nsentences=160, sample_size=1284, sample_size_v1=0, sample_size_v2=0, ppl=1.91, wps=615.3, ups=0.48, wpb=1284, bsz=160, num_updates=17790, lr=1.84579e-05, gnorm=4.161, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=37184
2023-06-27 12:33:25 - progress_bar.py[line:272] - INFO: epoch 007:   2007 / 2637 loss=2.142, loss_v1=0, loss_v2=0, nll_loss=0.917, ntokens=1245.8, nsentences=160, sample_size=1245.8, sample_size_v1=0, sample_size_v2=0, ppl=1.89, wps=597.2, ups=0.48, wpb=1245.8, bsz=160, num_updates=17800, lr=1.84504e-05, gnorm=4.262, clip=100, loss_scale=128, train_wall=21, gb_free=8.9, wall=37205
2023-06-27 12:33:45 - progress_bar.py[line:272] - INFO: epoch 007:   2017 / 2637 loss=2.144, loss_v1=0, loss_v2=0, nll_loss=0.92, ntokens=1303.1, nsentences=160, sample_size=1303.1, sample_size_v1=0, sample_size_v2=0, ppl=1.89, wps=624.8, ups=0.48, wpb=1303.1, bsz=160, num_updates=17810, lr=1.84428e-05, gnorm=4.239, clip=100, loss_scale=128, train_wall=21, gb_free=8.9, wall=37226
2023-06-27 12:34:06 - progress_bar.py[line:272] - INFO: epoch 007:   2027 / 2637 loss=2.115, loss_v1=0, loss_v2=0, nll_loss=0.889, ntokens=1276.5, nsentences=160, sample_size=1276.5, sample_size_v1=0, sample_size_v2=0, ppl=1.85, wps=612.3, ups=0.48, wpb=1276.5, bsz=160, num_updates=17820, lr=1.84352e-05, gnorm=4.058, clip=100, loss_scale=128, train_wall=21, gb_free=8.9, wall=37247
2023-06-27 12:34:27 - progress_bar.py[line:272] - INFO: epoch 007:   2037 / 2637 loss=2.14, loss_v1=0, loss_v2=0, nll_loss=0.915, ntokens=1279.2, nsentences=160, sample_size=1279.2, sample_size_v1=0, sample_size_v2=0, ppl=1.88, wps=612, ups=0.48, wpb=1279.2, bsz=160, num_updates=17830, lr=1.84277e-05, gnorm=4.071, clip=100, loss_scale=128, train_wall=21, gb_free=8.9, wall=37267
2023-06-27 12:34:48 - progress_bar.py[line:272] - INFO: epoch 007:   2047 / 2637 loss=2.112, loss_v1=0, loss_v2=0, nll_loss=0.884, ntokens=1276.2, nsentences=160, sample_size=1276.2, sample_size_v1=0, sample_size_v2=0, ppl=1.85, wps=612.1, ups=0.48, wpb=1276.2, bsz=160, num_updates=17840, lr=1.84201e-05, gnorm=4.02, clip=100, loss_scale=128, train_wall=21, gb_free=8.9, wall=37288
2023-06-27 12:35:09 - progress_bar.py[line:272] - INFO: epoch 007:   2057 / 2637 loss=2.151, loss_v1=0, loss_v2=0, nll_loss=0.929, ntokens=1267.3, nsentences=160, sample_size=1267.3, sample_size_v1=0, sample_size_v2=0, ppl=1.9, wps=607.4, ups=0.48, wpb=1267.3, bsz=160, num_updates=17850, lr=1.84125e-05, gnorm=4.35, clip=100, loss_scale=128, train_wall=21, gb_free=8.9, wall=37309
2023-06-27 12:35:30 - progress_bar.py[line:272] - INFO: epoch 007:   2067 / 2637 loss=2.145, loss_v1=0, loss_v2=0, nll_loss=0.921, ntokens=1252.3, nsentences=160, sample_size=1252.3, sample_size_v1=0, sample_size_v2=0, ppl=1.89, wps=600.4, ups=0.48, wpb=1252.3, bsz=160, num_updates=17860, lr=1.8405e-05, gnorm=4.882, clip=100, loss_scale=128, train_wall=21, gb_free=8.9, wall=37330
2023-06-27 12:35:51 - progress_bar.py[line:272] - INFO: epoch 007:   2077 / 2637 loss=2.154, loss_v1=0, loss_v2=0, nll_loss=0.931, ntokens=1263.7, nsentences=160, sample_size=1263.7, sample_size_v1=0, sample_size_v2=0, ppl=1.91, wps=605.9, ups=0.48, wpb=1263.7, bsz=160, num_updates=17870, lr=1.83974e-05, gnorm=4.983, clip=100, loss_scale=128, train_wall=21, gb_free=8.9, wall=37351
2023-06-27 12:36:11 - progress_bar.py[line:272] - INFO: epoch 007:   2087 / 2637 loss=2.155, loss_v1=0, loss_v2=0, nll_loss=0.932, ntokens=1247.2, nsentences=160, sample_size=1247.2, sample_size_v1=0, sample_size_v2=0, ppl=1.91, wps=598.3, ups=0.48, wpb=1247.2, bsz=160, num_updates=17880, lr=1.83899e-05, gnorm=4.492, clip=100, loss_scale=128, train_wall=21, gb_free=8.9, wall=37372
2023-06-27 12:36:18 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2023-06-27 12:36:34 - progress_bar.py[line:272] - INFO: epoch 007:   2098 / 2637 loss=2.138, loss_v1=0, loss_v2=0, nll_loss=0.913, ntokens=1263.6, nsentences=160, sample_size=1263.6, sample_size_v1=0, sample_size_v2=0, ppl=1.88, wps=551, ups=0.44, wpb=1263.6, bsz=160, num_updates=17890, lr=1.83823e-05, gnorm=4.748, clip=100, loss_scale=64, train_wall=23, gb_free=8.9, wall=37395
2023-06-27 12:36:55 - progress_bar.py[line:272] - INFO: epoch 007:   2108 / 2637 loss=2.169, loss_v1=0, loss_v2=0, nll_loss=0.947, ntokens=1250.4, nsentences=160, sample_size=1250.4, sample_size_v1=0, sample_size_v2=0, ppl=1.93, wps=598.4, ups=0.48, wpb=1250.4, bsz=160, num_updates=17900, lr=1.83747e-05, gnorm=4.957, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=37416
2023-06-27 12:37:16 - progress_bar.py[line:272] - INFO: epoch 007:   2118 / 2637 loss=2.127, loss_v1=0, loss_v2=0, nll_loss=0.903, ntokens=1266.6, nsentences=160, sample_size=1266.6, sample_size_v1=0, sample_size_v2=0, ppl=1.87, wps=606.6, ups=0.48, wpb=1266.6, bsz=160, num_updates=17910, lr=1.83672e-05, gnorm=4.383, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=37436
2023-06-27 12:37:37 - progress_bar.py[line:272] - INFO: epoch 007:   2128 / 2637 loss=2.146, loss_v1=0, loss_v2=0, nll_loss=0.923, ntokens=1252.8, nsentences=160, sample_size=1252.8, sample_size_v1=0, sample_size_v2=0, ppl=1.9, wps=600.4, ups=0.48, wpb=1252.8, bsz=160, num_updates=17920, lr=1.83596e-05, gnorm=4.322, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=37457
2023-06-27 12:37:58 - progress_bar.py[line:272] - INFO: epoch 007:   2138 / 2637 loss=2.141, loss_v1=0, loss_v2=0, nll_loss=0.917, ntokens=1260.1, nsentences=160, sample_size=1260.1, sample_size_v1=0, sample_size_v2=0, ppl=1.89, wps=604, ups=0.48, wpb=1260.1, bsz=160, num_updates=17930, lr=1.8352e-05, gnorm=4.741, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=37478
2023-06-27 12:38:19 - progress_bar.py[line:272] - INFO: epoch 007:   2148 / 2637 loss=2.137, loss_v1=0, loss_v2=0, nll_loss=0.911, ntokens=1264.7, nsentences=160, sample_size=1264.7, sample_size_v1=0, sample_size_v2=0, ppl=1.88, wps=606, ups=0.48, wpb=1264.7, bsz=160, num_updates=17940, lr=1.83445e-05, gnorm=4.257, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=37499
2023-06-27 12:38:40 - progress_bar.py[line:272] - INFO: epoch 007:   2158 / 2637 loss=2.147, loss_v1=0, loss_v2=0, nll_loss=0.923, ntokens=1258.7, nsentences=160, sample_size=1258.7, sample_size_v1=0, sample_size_v2=0, ppl=1.9, wps=603.6, ups=0.48, wpb=1258.7, bsz=160, num_updates=17950, lr=1.83369e-05, gnorm=4.352, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=37520
2023-06-27 12:39:01 - progress_bar.py[line:272] - INFO: epoch 007:   2168 / 2637 loss=2.135, loss_v1=0, loss_v2=0, nll_loss=0.91, ntokens=1274.1, nsentences=160, sample_size=1274.1, sample_size_v1=0, sample_size_v2=0, ppl=1.88, wps=609.8, ups=0.48, wpb=1274.1, bsz=160, num_updates=17960, lr=1.83293e-05, gnorm=4.193, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=37541
2023-06-27 12:39:21 - progress_bar.py[line:272] - INFO: epoch 007:   2178 / 2637 loss=2.127, loss_v1=0, loss_v2=0, nll_loss=0.902, ntokens=1265.9, nsentences=160, sample_size=1265.9, sample_size_v1=0, sample_size_v2=0, ppl=1.87, wps=605.6, ups=0.48, wpb=1265.9, bsz=160, num_updates=17970, lr=1.83218e-05, gnorm=4.807, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=37562
2023-06-27 12:39:42 - progress_bar.py[line:272] - INFO: epoch 007:   2188 / 2637 loss=2.138, loss_v1=0, loss_v2=0, nll_loss=0.914, ntokens=1265.4, nsentences=160, sample_size=1265.4, sample_size_v1=0, sample_size_v2=0, ppl=1.88, wps=606.4, ups=0.48, wpb=1265.4, bsz=160, num_updates=17980, lr=1.83142e-05, gnorm=4.798, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=37583
2023-06-27 12:40:03 - progress_bar.py[line:272] - INFO: epoch 007:   2198 / 2637 loss=2.131, loss_v1=0, loss_v2=0, nll_loss=0.905, ntokens=1264.4, nsentences=160, sample_size=1264.4, sample_size_v1=0, sample_size_v2=0, ppl=1.87, wps=605.7, ups=0.48, wpb=1264.4, bsz=160, num_updates=17990, lr=1.83066e-05, gnorm=4.48, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=37603
2023-06-27 12:40:24 - progress_bar.py[line:272] - INFO: epoch 007:   2208 / 2637 loss=2.117, loss_v1=0, loss_v2=0, nll_loss=0.89, ntokens=1273.1, nsentences=160, sample_size=1273.1, sample_size_v1=0, sample_size_v2=0, ppl=1.85, wps=609.9, ups=0.48, wpb=1273.1, bsz=160, num_updates=18000, lr=1.82991e-05, gnorm=4.036, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=37624
2023-06-27 12:40:45 - progress_bar.py[line:272] - INFO: epoch 007:   2218 / 2637 loss=2.112, loss_v1=0, loss_v2=0, nll_loss=0.887, ntokens=1255.2, nsentences=160, sample_size=1255.2, sample_size_v1=0, sample_size_v2=0, ppl=1.85, wps=601.7, ups=0.48, wpb=1255.2, bsz=160, num_updates=18010, lr=1.82915e-05, gnorm=4.323, clip=100, loss_scale=64, train_wall=21, gb_free=8.9, wall=37645
WARNING:torch.distributed.elastic.agent.server.api:Received 2 death signal, shutting down workers
WARNING:torch.distributed.elastic.multiprocessing.api:Sending process 937299 closing signal SIGINT
WARNING:torch.distributed.elastic.multiprocessing.api:Sending process 937300 closing signal SIGINT
WARNING:torch.distributed.elastic.multiprocessing.api:Sending process 937301 closing signal SIGINT
WARNING:torch.distributed.elastic.multiprocessing.api:Sending process 937302 closing signal SIGINT
Traceback (most recent call last):
  File "../../train.py", line 539, in <module>
    cli_main()
  File "../../train.py", line 532, in cli_main
    distributed_utils.call_main(cfg, main)
  File "/home/zcai75/Github/OFA/fairseq/fairseq/distributed/utils.py", line 374, in call_main
    distributed_main(cfg.distributed_training.device_id, main, cfg, kwargs)
  File "/home/zcai75/Github/OFA/fairseq/fairseq/distributed/utils.py", line 348, in distributed_main
    main(cfg, **kwargs)
  File "../../train.py", line 199, in main
    valid_losses, should_stop = train(cfg, trainer, task, epoch_itr)
  File "/data/hulab/zcai75/anaconda3/envs/vilt/lib/python3.8/contextlib.py", line 75, in inner
    return func(*args, **kwds)
  File "../../train.py", line 310, in train
    log_output = trainer.train_step(samples)
  File "/data/hulab/zcai75/anaconda3/envs/vilt/lib/python3.8/contextlib.py", line 75, in inner
    return func(*args, **kwds)
  File "/home/zcai75/Github/OFA_forked/trainer.py", line 773, in train_step
    loss, sample_size_i, logging_output = self.task.train_step(
  File "/home/zcai75/Github/OFA_forked/tasks/ofa_task.py", line 338, in train_step
    optimizer.backward(loss)
  File "/home/zcai75/Github/OFA/fairseq/fairseq/optim/fp16_optimizer.py", line 105, in backward
    loss.backward()
  File "/data/hulab/zcai75/anaconda3/envs/vilt/lib/python3.8/site-packages/torch/_tensor.py", line 396, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph, inputs=inputs)
  File "/data/hulab/zcai75/anaconda3/envs/vilt/lib/python3.8/site-packages/torch/autograd/__init__.py", line 173, in backward
    Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
KeyboardInterrupt
Traceback (most recent call last):
  File "../../train.py", line 539, in <module>
    cli_main()
  File "../../train.py", line 532, in cli_main
    distributed_utils.call_main(cfg, main)
  File "/home/zcai75/Github/OFA/fairseq/fairseq/distributed/utils.py", line 374, in call_main
    distributed_main(cfg.distributed_training.device_id, main, cfg, kwargs)
  File "/home/zcai75/Github/OFA/fairseq/fairseq/distributed/utils.py", line 348, in distributed_main
    main(cfg, **kwargs)
  File "../../train.py", line 199, in main
    valid_losses, should_stop = train(cfg, trainer, task, epoch_itr)
  File "/data/hulab/zcai75/anaconda3/envs/vilt/lib/python3.8/contextlib.py", line 75, in inner
    return func(*args, **kwds)
  File "../../train.py", line 310, in train
    log_output = trainer.train_step(samples)
  File "/data/hulab/zcai75/anaconda3/envs/vilt/lib/python3.8/contextlib.py", line 75, in inner
    return func(*args, **kwds)
  File "/home/zcai75/Github/OFA_forked/trainer.py", line 773, in train_step
    loss, sample_size_i, logging_output = self.task.train_step(
  File "/home/zcai75/Github/OFA_forked/tasks/ofa_task.py", line 338, in train_step
    optimizer.backward(loss)
  File "/home/zcai75/Github/OFA/fairseq/fairseq/optim/fp16_optimizer.py", line 105, in backward
    loss.backward()
  File "/data/hulab/zcai75/anaconda3/envs/vilt/lib/python3.8/site-packages/torch/_tensor.py", line 396, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph, inputs=inputs)
  File "/data/hulab/zcai75/anaconda3/envs/vilt/lib/python3.8/site-packages/torch/autograd/__init__.py", line 173, in backward
    Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
KeyboardInterrupt
Traceback (most recent call last):
  File "../../train.py", line 539, in <module>
    cli_main()
  File "../../train.py", line 532, in cli_main
    distributed_utils.call_main(cfg, main)
  File "/home/zcai75/Github/OFA/fairseq/fairseq/distributed/utils.py", line 374, in call_main
    distributed_main(cfg.distributed_training.device_id, main, cfg, kwargs)
  File "/home/zcai75/Github/OFA/fairseq/fairseq/distributed/utils.py", line 348, in distributed_main
    main(cfg, **kwargs)
  File "../../train.py", line 199, in main
    valid_losses, should_stop = train(cfg, trainer, task, epoch_itr)
  File "/data/hulab/zcai75/anaconda3/envs/vilt/lib/python3.8/contextlib.py", line 75, in inner
    return func(*args, **kwds)
  File "../../train.py", line 310, in train
    log_output = trainer.train_step(samples)
  File "/data/hulab/zcai75/anaconda3/envs/vilt/lib/python3.8/contextlib.py", line 75, in inner
    return func(*args, **kwds)
  File "/home/zcai75/Github/OFA_forked/trainer.py", line 773, in train_step
    loss, sample_size_i, logging_output = self.task.train_step(
  File "/home/zcai75/Github/OFA_forked/tasks/ofa_task.py", line 338, in train_step
    optimizer.backward(loss)
  File "/home/zcai75/Github/OFA/fairseq/fairseq/optim/fp16_optimizer.py", line 105, in backward
    loss.backward()
  File "/data/hulab/zcai75/anaconda3/envs/vilt/lib/python3.8/site-packages/torch/_tensor.py", line 396, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph, inputs=inputs)
  File "/data/hulab/zcai75/anaconda3/envs/vilt/lib/python3.8/site-packages/torch/autograd/__init__.py", line 173, in backward
    Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
KeyboardInterrupt
Traceback (most recent call last):
  File "../../train.py", line 539, in <module>
    cli_main()
  File "../../train.py", line 532, in cli_main
    distributed_utils.call_main(cfg, main)
  File "/home/zcai75/Github/OFA/fairseq/fairseq/distributed/utils.py", line 374, in call_main
    distributed_main(cfg.distributed_training.device_id, main, cfg, kwargs)
  File "/home/zcai75/Github/OFA/fairseq/fairseq/distributed/utils.py", line 348, in distributed_main
    main(cfg, **kwargs)
  File "../../train.py", line 199, in main
    valid_losses, should_stop = train(cfg, trainer, task, epoch_itr)
  File "/data/hulab/zcai75/anaconda3/envs/vilt/lib/python3.8/contextlib.py", line 75, in inner
    return func(*args, **kwds)
  File "../../train.py", line 310, in train
    log_output = trainer.train_step(samples)
  File "/data/hulab/zcai75/anaconda3/envs/vilt/lib/python3.8/contextlib.py", line 75, in inner
    return func(*args, **kwds)
  File "/home/zcai75/Github/OFA_forked/trainer.py", line 773, in train_step
    loss, sample_size_i, logging_output = self.task.train_step(
  File "/home/zcai75/Github/OFA_forked/tasks/ofa_task.py", line 338, in train_step
    optimizer.backward(loss)
  File "/home/zcai75/Github/OFA/fairseq/fairseq/optim/fp16_optimizer.py", line 105, in backward
    loss.backward()
  File "/data/hulab/zcai75/anaconda3/envs/vilt/lib/python3.8/site-packages/torch/_tensor.py", line 396, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph, inputs=inputs)
  File "/data/hulab/zcai75/anaconda3/envs/vilt/lib/python3.8/site-packages/torch/autograd/__init__.py", line 173, in backward
    Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
KeyboardInterrupt
wandb: Waiting for W&B process to finish... (failed 255). Press Control-C to abort syncing.
wandb: 
wandb: Run history:
wandb:                  train/bsz 
wandb:                 train/clip 
wandb:              train/gb_free 
wandb:                train/gnorm 
wandb:                 train/loss 
wandb:           train/loss_scale 
wandb:              train/loss_v1 
wandb:              train/loss_v2 
wandb:                   train/lr 
wandb:             train/nll_loss 
wandb:           train/nsentences 
wandb:              train/ntokens 
wandb:                  train/ppl 
wandb:          train/sample_size 
wandb:       train/sample_size_v1 
wandb:       train/sample_size_v2 
wandb:           train/train_wall 
wandb:                  train/ups 
wandb:                 train/wall 
wandb:                  train/wpb 
wandb:                  train/wps 
wandb:            train_inner/bsz 
wandb:           train_inner/clip 
wandb:        train_inner/gb_free 
wandb:          train_inner/gnorm 
wandb:           train_inner/loss 
wandb:     train_inner/loss_scale 
wandb:        train_inner/loss_v1 
wandb:        train_inner/loss_v2 
wandb:             train_inner/lr 
wandb:       train_inner/nll_loss 
wandb:     train_inner/nsentences 
wandb:        train_inner/ntokens 
wandb:            train_inner/ppl 
wandb:    train_inner/sample_size 
wandb: train_inner/sample_size_v1 
wandb: train_inner/sample_size_v2 
wandb:     train_inner/train_wall 
wandb:            train_inner/ups 
wandb:           train_inner/wall 
wandb:            train_inner/wpb 
wandb:            train_inner/wps 
wandb: 
wandb: Run summary:
wandb:                  train/bsz 160.0
wandb:                 train/clip 100.0
wandb:              train/gb_free 8.9
wandb:                train/gnorm 4.602
wandb:                 train/loss 2.17
wandb:           train/loss_scale 64.0
wandb:              train/loss_v1 0.0
wandb:              train/loss_v2 0.0
wandb:                   train/lr 2e-05
wandb:             train/nll_loss 0.949
wandb:           train/nsentences 159.984
wandb:              train/ntokens 1259.962
wandb:                  train/ppl 1.93
wandb:          train/sample_size 1259.962
wandb:       train/sample_size_v1 0.0
wandb:       train/sample_size_v2 0.0
wandb:           train/train_wall 5488.0
wandb:                  train/ups 0.48
wandb:                 train/wall 33018.0
wandb:                  train/wpb 1260.0
wandb:                  train/wps 602.8
wandb:            train_inner/bsz 160.0
wandb:           train_inner/clip 100.0
wandb:        train_inner/gb_free 8.9
wandb:          train_inner/gnorm 4.323
wandb:           train_inner/loss 2.112
wandb:     train_inner/loss_scale 64.0
wandb:        train_inner/loss_v1 0.0
wandb:        train_inner/loss_v2 0.0
wandb:             train_inner/lr 2e-05
wandb:       train_inner/nll_loss 0.887
wandb:     train_inner/nsentences 160.0
wandb:        train_inner/ntokens 1255.2
wandb:            train_inner/ppl 1.85
wandb:    train_inner/sample_size 1255.2
wandb: train_inner/sample_size_v1 0.0
wandb: train_inner/sample_size_v2 0.0
wandb:     train_inner/train_wall 21.0
wandb:            train_inner/ups 0.48
wandb:           train_inner/wall 37645.0
wandb:            train_inner/wpb 1255.2
wandb:            train_inner/wps 601.7
wandb: 
wandb:  View run _16_3e-5_512_rare_3 at: https://wandb.ai/jackcai1206/OFA-VG/runs/hw2w0fcg
wandb: Synced 6 W&B file(s), 0 media file(s), 2 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230627_021321-hw2w0fcg/logs
Traceback (most recent call last):
  File "/data/hulab/zcai75/anaconda3/envs/vilt/lib/python3.8/runpy.py", line 194, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File "/data/hulab/zcai75/anaconda3/envs/vilt/lib/python3.8/runpy.py", line 87, in _run_code
    exec(code, run_globals)
  File "/data/hulab/zcai75/anaconda3/envs/vilt/lib/python3.8/site-packages/torch/distributed/launch.py", line 193, in <module>
    main()
  File "/data/hulab/zcai75/anaconda3/envs/vilt/lib/python3.8/site-packages/torch/distributed/launch.py", line 189, in main
    launch(args)
  File "/data/hulab/zcai75/anaconda3/envs/vilt/lib/python3.8/site-packages/torch/distributed/launch.py", line 174, in launch
    run(args)
  File "/data/hulab/zcai75/anaconda3/envs/vilt/lib/python3.8/site-packages/torch/distributed/run.py", line 752, in run
    elastic_launch(
  File "/data/hulab/zcai75/anaconda3/envs/vilt/lib/python3.8/site-packages/torch/distributed/launcher/api.py", line 131, in __call__
    return launch_agent(self._config, self._entrypoint, list(args))
  File "/data/hulab/zcai75/anaconda3/envs/vilt/lib/python3.8/site-packages/torch/distributed/launcher/api.py", line 236, in launch_agent
    result = agent.run()
  File "/data/hulab/zcai75/anaconda3/envs/vilt/lib/python3.8/site-packages/torch/distributed/elastic/metrics/api.py", line 125, in wrapper
    result = f(*args, **kwargs)
  File "/data/hulab/zcai75/anaconda3/envs/vilt/lib/python3.8/site-packages/torch/distributed/elastic/agent/server/api.py", line 709, in run
    result = self._invoke_run(role)
  File "/data/hulab/zcai75/anaconda3/envs/vilt/lib/python3.8/site-packages/torch/distributed/elastic/agent/server/api.py", line 850, in _invoke_run
    time.sleep(monitor_interval)
  File "/data/hulab/zcai75/anaconda3/envs/vilt/lib/python3.8/site-packages/torch/distributed/elastic/multiprocessing/api.py", line 60, in _terminate_process_handler
    raise SignalException(f"Process {os.getpid()} got signal: {sigval}", sigval=sigval)
torch.distributed.elastic.multiprocessing.api.SignalException: Process 937255 got signal: 2

/data/hulab/zcai75/anaconda3/envs/vilt/lib/python3.8/site-packages/torch/distributed/launch.py:178: FutureWarning: The module torch.distributed.launch is deprecated
and will be removed in future. Use torchrun.
Note that --use_env is set by default in torchrun.
If your script expects `--local_rank` argument to be set, please
change it to read from `os.environ['LOCAL_RANK']` instead. See 
https://pytorch.org/docs/stable/distributed.html#launch-utility for 
further instructions

  warnings.warn(
WARNING:torch.distributed.run:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
2023-06-26 18:19:12 - utils.py[line:255] - INFO: distributed init (rank 0): env://
2023-06-26 18:19:12 - utils.py[line:261] - INFO: Start init
2023-06-26 18:19:12 - distributed_c10d.py[line:228] - INFO: Added key: store_based_barrier_key:1 to store for rank: 0
2023-06-26 18:19:12 - utils.py[line:255] - INFO: distributed init (rank 1): env://
2023-06-26 18:19:12 - utils.py[line:261] - INFO: Start init
2023-06-26 18:19:12 - distributed_c10d.py[line:228] - INFO: Added key: store_based_barrier_key:1 to store for rank: 1
2023-06-26 18:19:12 - utils.py[line:255] - INFO: distributed init (rank 2): env://
2023-06-26 18:19:12 - utils.py[line:261] - INFO: Start init
2023-06-26 18:19:12 - distributed_c10d.py[line:228] - INFO: Added key: store_based_barrier_key:1 to store for rank: 2
2023-06-26 18:19:12 - distributed_c10d.py[line:262] - INFO: Rank 2: Completed store-based barrier for key:store_based_barrier_key:1 with 3 nodes.
2023-06-26 18:19:12 - utils.py[line:271] - INFO: initialized host AMD4RTX3090GPU14 as rank 2
single-machine distributed training is initialized.
2023-06-26 18:19:12 - distributed_c10d.py[line:262] - INFO: Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 3 nodes.
2023-06-26 18:19:12 - utils.py[line:271] - INFO: initialized host AMD4RTX3090GPU14 as rank 0
single-machine distributed training is initialized.
2023-06-26 18:19:12 - distributed_c10d.py[line:262] - INFO: Rank 1: Completed store-based barrier for key:store_based_barrier_key:1 with 3 nodes.
2023-06-26 18:19:12 - utils.py[line:271] - INFO: initialized host AMD4RTX3090GPU14 as rank 1
single-machine distributed training is initialized.
2023-06-26 18:19:13 - train.py[line:77] - INFO: {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 10, 'log_format': 'simple', 'log_file': None, 'tensorboard_logdir': './tensorboard/_16_3e-5_512', 'wandb_project': 'OFA-VG', 'azureml_logging': False, 'seed': 1, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': 512, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': '../../ofa_module', 'empty_cache_freq': 0, 'all_gather_list_size': 2097152, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 3, 'distributed_num_procs': 3, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': 'env://', 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': True, 'ddp_backend': 'pytorch_ddp', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': True, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_algorithm': 'LocalSGD', 'localsgd_frequency': 3, 'nprocs_per_node': 3, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False}, 'dataset': {'_name': None, 'num_workers': 0, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': None, 'batch_size': 10, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 10, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': 7, 'disable_validation': False, 'max_tokens_valid': None, 'batch_size_valid': 10, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0}, 'optimization': {'_name': None, 'max_epoch': 16, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 1.0, 'sentence_avg': False, 'update_freq': [4], 'lr': [3e-05], 'stop_min_lr': -1.0, 'use_bmuf': False}, 'checkpoint': {'_name': None, 'save_dir': '../../checkpoints/OFA/vrd_checkpoints/_16_3e-5_512_rare_balanced_2', 'restore_file': '../../checkpoints/ofa_base.pt', 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 2, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': 1, 'no_save': False, 'no_epoch_checkpoints': False, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': True, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1, 'use_ema_weights_to_init_param': False, 'use_latest_weights_to_init_ema': False}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 3}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': Namespace(_name='ofa_base', activation_fn='gelu', adam_betas='(0.9,0.999)', adam_eps=1e-08, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, add_type_embedding=True, all_gather_list_size=2097152, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, arch='ofa_base', attention_dropout=0.0, attn_scale_factor=2, azureml_logging=False, batch_size=10, batch_size_valid=10, best_checkpoint_metric='loss', bf16=False, bitfit=False, bpe=None, bpe_dir='../../utils/BPE', broadcast_buffers=False, bucket_cap_mb=25, checkpoint_shard_count=1, checkpoint_suffix='', clip_norm=1.0, code_dict_size=8192, code_image_size=128, code_layernorm_embedding=True, combine_valid_subsets=None, constraint_range=None, cpu=False, cpu_offload=False, criterion='adjust_label_smoothed_cross_entropy', cross_self_attention=False, curriculum=0, data='../../dataset/OFA_data/vrd_balanced/vg_train_full.tsv,../../dataset/OFA_data/vrd_balanced/vg_val_full.tsv', data_buffer_size=10, dataset_impl=None, ddp_backend='pytorch_ddp', ddp_comm_hook='none', decoder_attention_heads=12, decoder_drop_path_rate=0.1, decoder_embed_dim=768, decoder_embed_path=None, decoder_ffn_embed_dim=3072, decoder_input_dim=768, decoder_layerdrop=0, decoder_layers=6, decoder_layers_to_keep=None, decoder_learned_pos=True, decoder_normalize_before=True, decoder_output_dim=768, device_id=0, disable_entangle=True, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_num_procs=3, distributed_port=-1, distributed_rank=0, distributed_world_size=3, drop_worst_after=0, drop_worst_ratio=0.0, dropout=0.1, ema_decay=0.9999, ema_fp32=False, ema_seed_model=None, ema_start_update=0, ema_update_freq=1, empty_cache_freq=0, encoder_attention_heads=12, encoder_drop_path_rate=0.1, encoder_embed_dim=768, encoder_embed_path=None, encoder_ffn_embed_dim=3072, encoder_layerdrop=0, encoder_layers=6, encoder_layers_to_keep=None, encoder_learned_pos=True, encoder_normalize_before=True, end_learning_rate=0.0, entangle_position_embedding=False, eos=2, eval_args='{"beam":5,"max_len_a":0,"max_len_b":200}', eval_print_samples=False, fast_stat_sync=False, find_unused_parameters=True, finetune_from_model=None, fix_batches_to_gpus=False, fixed_validation_seed=7, force_anneal=None, fp16=True, fp16_adam_stats=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=512, fp32_reduce_scatter=False, freeze_decoder_embedding=False, freeze_encoder_embedding=False, gen_subset='test', gradient_as_bucket_view=False, heartbeat_timeout=-1, ignore_eos=False, ignore_prefix_size=0, ignore_unused_valid_subsets=False, image_bucket_size=42, imagenet_default_mean_and_std=False, keep_best_checkpoints=1, keep_interval_updates=-1, keep_interval_updates_pattern=-1, keep_last_epochs=-1, label_smoothing=0.1, layernorm_embedding=True, load_checkpoint_on_all_dp_ranks=False, localsgd_frequency=3, log_file=None, log_format='simple', log_interval=10, lr=[3e-05], lr_scheduler='polynomial_decay', max_epoch=16, max_source_positions=1024, max_src_length=100, max_target_positions=1024, max_tgt_length=100, max_tokens=None, max_tokens_valid=None, max_update=0, max_valid_steps=None, maximize_best_checkpoint_metric=True, memory_efficient_bf16=False, memory_efficient_fp16=False, min_loss_scale=0.0001, min_params_to_wrap=100000000, model_parallel_size=1, no_cross_attention=False, no_epoch_checkpoints=False, no_last_checkpoints=False, no_progress_bar=False, no_reshard_after_forward=False, no_save=False, no_save_optimizer_state=False, no_scale_embedding=True, no_seed_provided=False, no_token_positional_embeddings=False, nprocs_per_node=3, num_bins=1000, num_shards=1, num_workers=0, on_cpu_convert_precision=False, optimizer='adam', optimizer_overrides='{}', orig_patch_image_size=256, pad=1, patch_image_size=512, patch_layernorm_embedding=True, patience=-1, pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, plasma_path='/tmp/plasma', pooler_activation_fn='tanh', pooler_classifier='mlp', pooler_dropout=0.0, power=1.0, profile=False, quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, quantization_config_path=None, reg_alpha=1.0, relu_dropout=0.0, report_accuracy=False, required_batch_size_multiple=8, required_seq_len_multiple=1, reset_dataloader=False, reset_logging=False, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, resnet_drop_path_rate=0.0, resnet_type='resnet101', restore_file='../../checkpoints/ofa_base.pt', sample_patch_num=196, save_dir='../../checkpoints/OFA/vrd_checkpoints/_16_3e-5_512_rare_balanced_2', save_interval=2, save_interval_updates=0, scale_attn=True, scale_fc=True, scale_heads=True, scale_resids=False, scoring='bleu', seed=1, selected_cols=None, sentence_avg=False, shard_id=0, share_all_embeddings=True, share_decoder_input_output_embed=True, simul_type=None, skip_invalid_size_inputs_valid_test=False, slowmo_algorithm='LocalSGD', slowmo_momentum=None, stop_min_lr=-1.0, stop_time_hours=0, store_ema=False, suppress_crashes=False, sync_bn=False, task='vrd', tensorboard_logdir='./tensorboard/_16_3e-5_512', threshold_loss_scale=None, token_bucket_size=256, tokenizer=None, total_num_update=1000000, tpu=False, train_subset='train', unk=3, update_freq=[4], use_bmuf=False, use_ema_weights_to_init_param=False, use_latest_weights_to_init_ema=False, use_old_adam=False, use_plasma_view=False, use_rdrop=False, use_sharded_state=False, user_dir='../../ofa_module', valid_subset='valid', validate_after_updates=0, validate_interval=10, validate_interval_updates=0, vg_json_dir=None, wandb_project='OFA-VG', warmup_ratio=0.06, warmup_updates=0, weight_decay=0.01, write_checkpoints_asynchronously=False, zero_sharding='none'), 'task': {'_name': 'vrd', 'data': '../../dataset/OFA_data/vrd_balanced/vg_train_full.tsv,../../dataset/OFA_data/vrd_balanced/vg_val_full.tsv', 'selected_cols': None, 'bpe': None, 'bpe_dir': '../../utils/BPE', 'max_source_positions': 1024, 'max_target_positions': 1024, 'max_src_length': 100, 'max_tgt_length': 100, 'code_dict_size': 8192, 'patch_image_size': 512, 'orig_patch_image_size': 256, 'num_bins': 1000, 'imagenet_default_mean_and_std': False, 'constraint_range': None, 'eval_args': '{"beam":5,"max_len_a":0,"max_len_b":200}', 'eval_print_samples': False, 'vg_json_dir': None}, 'criterion': {'_name': 'adjust_label_smoothed_cross_entropy', 'label_smoothing': 0.1, 'report_accuracy': False, 'ignore_prefix_size': 0, 'ignore_eos': False, 'sentence_avg': False, 'drop_worst_ratio': 0.0, 'drop_worst_after': 0, 'use_rdrop': False, 'reg_alpha': 1.0, 'sample_patch_num': 196, 'constraint_range': None}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9,0.999)', 'adam_eps': 1e-08, 'weight_decay': 0.01, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': False, 'lr': [3e-05]}, 'lr_scheduler': {'_name': 'polynomial_decay', 'warmup_updates': 0, 'warmup_ratio': 0.06, 'force_anneal': None, 'end_learning_rate': 0.0, 'power': 1.0, 'total_num_update': 1000000.0, 'lr': [3e-05]}, 'scoring': {'_name': 'bleu', 'pad': 1, 'eos': 2, 'unk': 3}, 'bpe': None, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}, 'simul_type': None}
2023-06-26 18:19:13 - vrd.py[line:84] - INFO: vrd setup: source dictionary: 51268 types
2023-06-26 18:19:13 - vrd.py[line:85] - INFO: vrd setup: target dictionary: 51268 types
/data/hulab/zcai75/anaconda3/envs/vilt/lib/python3.8/site-packages/torch/functional.py:478: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at  ../aten/src/ATen/native/TensorShape.cpp:2894.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/data/hulab/zcai75/anaconda3/envs/vilt/lib/python3.8/site-packages/torch/functional.py:478: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at  ../aten/src/ATen/native/TensorShape.cpp:2894.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/data/hulab/zcai75/anaconda3/envs/vilt/lib/python3.8/site-packages/torch/functional.py:478: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at  ../aten/src/ATen/native/TensorShape.cpp:2894.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
local datafile ../../dataset/OFA_data/vrd_balanced/vg_val_full.tsv slice_id 2 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../dataset/OFA_data/vrd_balanced/vg_val_full.tsv slice_id 1 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../dataset/OFA_data/vrd_balanced/vg_val_full.tsv slice_id 2 finished initializing row_count and line_idx-to-offset mapping
file ../../dataset/OFA_data/vrd_balanced/vg_val_full.tsv slice_id 2 row count 36214 total row count 108643
local datafile ../../dataset/OFA_data/vrd_balanced/vg_val_full.tsv slice_id 1 finished initializing row_count and line_idx-to-offset mapping
/data/hulab/zcai75/anaconda3/envs/vilt/lib/python3.8/site-packages/torchvision/transforms/transforms.py:332: UserWarning: Argument 'interpolation' of type int is deprecated since 0.13 and will be removed in 0.15. Please use InterpolationMode enum.
  warnings.warn(
file ../../dataset/OFA_data/vrd_balanced/vg_val_full.tsv slice_id 1 row count 36214 total row count 108643
/data/hulab/zcai75/anaconda3/envs/vilt/lib/python3.8/site-packages/torchvision/transforms/transforms.py:332: UserWarning: Argument 'interpolation' of type int is deprecated since 0.13 and will be removed in 0.15. Please use InterpolationMode enum.
  warnings.warn(
2023-06-26 18:19:15 - train.py[line:110] - INFO: OFAModel(
  (encoder): TransformerEncoder(
    (encoder_dropout): Dropout(p=0.2, inplace=False)
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(51268, 768, padding_idx=1)
    (layernorm_embedding): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (type_embedding): Embedding(2, 768)
    (embed_images): ResNet(
      (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)
      (layer1): Sequential(
        (0): Bottleneck(
          (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (downsample): Sequential(
            (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (drop_path): Identity()
        )
        (1): Bottleneck(
          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (2): Bottleneck(
          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
      )
      (layer2): Sequential(
        (0): Bottleneck(
          (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (downsample): Sequential(
            (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
            (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (drop_path): Identity()
        )
        (1): Bottleneck(
          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (2): Bottleneck(
          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (3): Bottleneck(
          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
      )
      (layer3): Sequential(
        (0): Bottleneck(
          (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (downsample): Sequential(
            (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)
            (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (drop_path): Identity()
        )
        (1): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (2): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (3): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (4): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (5): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (6): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (7): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (8): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (9): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (10): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (11): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (12): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (13): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (14): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (15): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (16): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (17): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (18): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (19): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (20): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (21): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (22): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
      )
    )
    (image_proj): Linear(in_features=1024, out_features=768, bias=True)
    (patch_layernorm_embedding): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (embed_positions): Embedding(1026, 768)
    (embed_image_positions): Embedding(1765, 768)
    (pos_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (image_pos_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (pos_q_linear): Linear(in_features=768, out_features=768, bias=True)
    (pos_k_linear): Linear(in_features=768, out_features=768, bias=True)
    (layers): ModuleList(
      (0): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): Identity()
      )
      (1): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(p=0.019999999552965164)
      )
      (2): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(p=0.03999999910593033)
      )
      (3): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(p=0.06000000238418579)
      )
      (4): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(p=0.07999999821186066)
      )
      (5): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(p=0.10000000149011612)
      )
    )
    (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (token_rel_pos_table_list): ModuleList(
      (0): Embedding(511, 12)
      (1): Embedding(511, 12)
      (2): Embedding(511, 12)
      (3): Embedding(511, 12)
      (4): Embedding(511, 12)
      (5): Embedding(511, 12)
    )
    (image_rel_pos_table_list): ModuleList(
      (0): Embedding(6892, 12)
      (1): Embedding(6892, 12)
      (2): Embedding(6892, 12)
      (3): Embedding(6892, 12)
      (4): Embedding(6892, 12)
      (5): Embedding(6892, 12)
    )
  )
  (decoder): TransformerDecoder(
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(51268, 768, padding_idx=1)
    (layernorm_embedding): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (embed_positions): Embedding(1026, 768)
    (embed_image_positions): Embedding(1765, 768)
    (pos_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (image_pos_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (self_pos_q_linear): Linear(in_features=768, out_features=768, bias=True)
    (self_pos_k_linear): Linear(in_features=768, out_features=768, bias=True)
    (cross_pos_q_linear): Linear(in_features=768, out_features=768, bias=True)
    (cross_pos_k_linear): Linear(in_features=768, out_features=768, bias=True)
    (code_layernorm_embedding): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (layers): ModuleList(
      (0): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (cross_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): Identity()
      )
      (1): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (cross_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(p=0.019999999552965164)
      )
      (2): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (cross_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(p=0.03999999910593033)
      )
      (3): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (cross_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(p=0.06000000238418579)
      )
      (4): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (cross_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(p=0.07999999821186066)
      )
      (5): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (cross_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(p=0.10000000149011612)
      )
    )
    (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (output_projection): Linear(in_features=768, out_features=51268, bias=False)
    (token_rel_pos_table_list): ModuleList(
      (0): Embedding(511, 12)
      (1): Embedding(511, 12)
      (2): Embedding(511, 12)
      (3): Embedding(511, 12)
      (4): Embedding(511, 12)
      (5): Embedding(511, 12)
    )
    (image_rel_pos_table_list): ModuleList(
      (0): Embedding(6892, 12)
      (1): Embedding(6892, 12)
      (2): Embedding(6892, 12)
      (3): Embedding(6892, 12)
      (4): Embedding(6892, 12)
      (5): Embedding(6892, 12)
    )
  )
  (classification_heads): ModuleDict()
)
2023-06-26 18:19:15 - train.py[line:111] - INFO: task: VRDTask
2023-06-26 18:19:15 - train.py[line:112] - INFO: model: OFAModel
2023-06-26 18:19:15 - train.py[line:113] - INFO: criterion: AdjustLabelSmoothedCrossEntropyCriterion
2023-06-26 18:19:15 - train.py[line:114] - INFO: num. shared model params: 175,949,384 (num. trained: 175,949,384)
2023-06-26 18:19:15 - train.py[line:121] - INFO: num. expert model params: 0 (num. trained: 0)
local datafile ../../dataset/OFA_data/vrd_balanced/vg_val_full.tsv slice_id 0 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../dataset/OFA_data/vrd_balanced/vg_val_full.tsv slice_id 0 finished initializing row_count and line_idx-to-offset mapping
file ../../dataset/OFA_data/vrd_balanced/vg_val_full.tsv slice_id 0 row count 36215 total row count 108643
/data/hulab/zcai75/anaconda3/envs/vilt/lib/python3.8/site-packages/torchvision/transforms/transforms.py:332: UserWarning: Argument 'interpolation' of type int is deprecated since 0.13 and will be removed in 0.15. Please use InterpolationMode enum.
  warnings.warn(
2023-06-26 18:19:16 - distributed_c10d.py[line:228] - INFO: Added key: store_based_barrier_key:2 to store for rank: 0
2023-06-26 18:19:16 - distributed_c10d.py[line:262] - INFO: Rank 0: Completed store-based barrier for key:store_based_barrier_key:2 with 3 nodes.
2023-06-26 18:19:16 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_tokens.weight <- decoder.embed_tokens.weight
2023-06-26 18:19:16 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_tokens.weight <- decoder.output_projection.weight
2023-06-26 18:19:16 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer1.0.conv1.bias
2023-06-26 18:19:16 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer1.0.conv2.bias
2023-06-26 18:19:16 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer1.0.conv3.bias
2023-06-26 18:19:16 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer1.0.downsample.0.bias
2023-06-26 18:19:16 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer1.1.conv1.bias
2023-06-26 18:19:16 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer1.1.conv2.bias
2023-06-26 18:19:16 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer1.1.conv3.bias
2023-06-26 18:19:16 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer1.2.conv1.bias
2023-06-26 18:19:16 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer1.2.conv2.bias
2023-06-26 18:19:16 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer1.2.conv3.bias
2023-06-26 18:19:16 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.0.conv1.bias
2023-06-26 18:19:16 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.0.conv2.bias
2023-06-26 18:19:16 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.0.conv3.bias
2023-06-26 18:19:16 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.0.downsample.0.bias
2023-06-26 18:19:16 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.1.conv1.bias
2023-06-26 18:19:16 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.1.conv2.bias
2023-06-26 18:19:16 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.1.conv3.bias
2023-06-26 18:19:16 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.2.conv1.bias
2023-06-26 18:19:16 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.2.conv2.bias
2023-06-26 18:19:16 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.2.conv3.bias
2023-06-26 18:19:16 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.3.conv1.bias
2023-06-26 18:19:16 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.3.conv2.bias
2023-06-26 18:19:16 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.3.conv3.bias
2023-06-26 18:19:16 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.0.conv1.bias
2023-06-26 18:19:16 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.0.conv2.bias
2023-06-26 18:19:16 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.0.conv3.bias
2023-06-26 18:19:16 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.0.downsample.0.bias
2023-06-26 18:19:16 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.1.conv1.bias
2023-06-26 18:19:16 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.1.conv2.bias
2023-06-26 18:19:16 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.1.conv3.bias
2023-06-26 18:19:16 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.2.conv1.bias
2023-06-26 18:19:16 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.2.conv2.bias
2023-06-26 18:19:16 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.2.conv3.bias
2023-06-26 18:19:16 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.3.conv1.bias
2023-06-26 18:19:16 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.3.conv2.bias
2023-06-26 18:19:16 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.3.conv3.bias
2023-06-26 18:19:16 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.4.conv1.bias
2023-06-26 18:19:16 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.4.conv2.bias
2023-06-26 18:19:16 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.4.conv3.bias
2023-06-26 18:19:16 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.5.conv1.bias
2023-06-26 18:19:16 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.5.conv2.bias
2023-06-26 18:19:16 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.5.conv3.bias
2023-06-26 18:19:16 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.6.conv1.bias
2023-06-26 18:19:16 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.6.conv2.bias
2023-06-26 18:19:16 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.6.conv3.bias
2023-06-26 18:19:16 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.7.conv1.bias
2023-06-26 18:19:16 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.7.conv2.bias
2023-06-26 18:19:16 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.7.conv3.bias
2023-06-26 18:19:16 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.8.conv1.bias
2023-06-26 18:19:16 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.8.conv2.bias
2023-06-26 18:19:16 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.8.conv3.bias
2023-06-26 18:19:16 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.9.conv1.bias
2023-06-26 18:19:16 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.9.conv2.bias
2023-06-26 18:19:16 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.9.conv3.bias
2023-06-26 18:19:16 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.10.conv1.bias
2023-06-26 18:19:16 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.10.conv2.bias
2023-06-26 18:19:16 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.10.conv3.bias
2023-06-26 18:19:16 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.11.conv1.bias
2023-06-26 18:19:16 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.11.conv2.bias
2023-06-26 18:19:16 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.11.conv3.bias
2023-06-26 18:19:16 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.12.conv1.bias
2023-06-26 18:19:16 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.12.conv2.bias
2023-06-26 18:19:16 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.12.conv3.bias
2023-06-26 18:19:16 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.13.conv1.bias
2023-06-26 18:19:16 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.13.conv2.bias
2023-06-26 18:19:16 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.13.conv3.bias
2023-06-26 18:19:16 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.14.conv1.bias
2023-06-26 18:19:16 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.14.conv2.bias
2023-06-26 18:19:16 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.14.conv3.bias
2023-06-26 18:19:16 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.15.conv1.bias
2023-06-26 18:19:16 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.15.conv2.bias
2023-06-26 18:19:16 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.15.conv3.bias
2023-06-26 18:19:16 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.16.conv1.bias
2023-06-26 18:19:16 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.16.conv2.bias
2023-06-26 18:19:16 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.16.conv3.bias
2023-06-26 18:19:16 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.17.conv1.bias
2023-06-26 18:19:16 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.17.conv2.bias
2023-06-26 18:19:16 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.17.conv3.bias
2023-06-26 18:19:16 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.18.conv1.bias
2023-06-26 18:19:16 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.18.conv2.bias
2023-06-26 18:19:16 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.18.conv3.bias
2023-06-26 18:19:16 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.19.conv1.bias
2023-06-26 18:19:16 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.19.conv2.bias
2023-06-26 18:19:16 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.19.conv3.bias
2023-06-26 18:19:16 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.20.conv1.bias
2023-06-26 18:19:16 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.20.conv2.bias
2023-06-26 18:19:16 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.20.conv3.bias
2023-06-26 18:19:16 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.21.conv1.bias
2023-06-26 18:19:16 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.21.conv2.bias
2023-06-26 18:19:16 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.21.conv3.bias
2023-06-26 18:19:16 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.22.conv1.bias
2023-06-26 18:19:16 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.22.conv2.bias
2023-06-26 18:19:16 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.22.conv3.bias
2023-06-26 18:19:16 - trainer.py[line:123] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- decoder.output_projection.bias
2023-06-26 18:19:16 - utils.py[line:759] - INFO: ***********************CUDA enviroments for all 3 workers***********************
2023-06-26 18:19:16 - utils.py[line:761] - INFO: rank   0: capabilities =  8.6  ; total memory = 23.688 GB ; name = NVIDIA GeForce RTX 3090 Ti              
2023-06-26 18:19:16 - utils.py[line:761] - INFO: rank   1: capabilities =  8.6  ; total memory = 23.688 GB ; name = NVIDIA GeForce RTX 3090 Ti              
2023-06-26 18:19:16 - utils.py[line:761] - INFO: rank   2: capabilities =  8.6  ; total memory = 23.688 GB ; name = NVIDIA GeForce RTX 3090 Ti              
2023-06-26 18:19:16 - utils.py[line:767] - INFO: ***********************CUDA enviroments for all 3 workers***********************
2023-06-26 18:19:16 - train.py[line:152] - INFO: training on 3 devices (GPUs/TPUs)
2023-06-26 18:19:16 - train.py[line:157] - INFO: max tokens per device = None and max sentences per device = 10
2023-06-26 18:19:16 - trainer.py[line:458] - INFO: Preparing to load checkpoint ../../checkpoints/ofa_base.pt
2023-06-26 18:19:16 - trainer.py[line:624] - INFO: No existing checkpoint found ../../checkpoints/ofa_base.pt
2023-06-26 18:19:16 - trainer.py[line:639] - INFO: loading train data for epoch 1
local datafile ../../dataset/OFA_data/vrd_balanced/vg_train_full.tsv slice_id 1 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../dataset/OFA_data/vrd_balanced/vg_train_full.tsv slice_id 2 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../dataset/OFA_data/vrd_balanced/vg_train_full.tsv slice_id 0 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../dataset/OFA_data/vrd_balanced/vg_train_full.tsv slice_id 1 finished initializing row_count and line_idx-to-offset mapping
file ../../dataset/OFA_data/vrd_balanced/vg_train_full.tsv slice_id 1 row count 148595 total row count 445785
local datafile ../../dataset/OFA_data/vrd_balanced/vg_train_full.tsv slice_id 0 finished initializing row_count and line_idx-to-offset mapping
file ../../dataset/OFA_data/vrd_balanced/vg_train_full.tsv slice_id 0 row count 148595 total row count 445785
local datafile ../../dataset/OFA_data/vrd_balanced/vg_train_full.tsv slice_id 2 finished initializing row_count and line_idx-to-offset mapping
file ../../dataset/OFA_data/vrd_balanced/vg_train_full.tsv slice_id 2 row count 148595 total row count 445785
slice_id 2 seek offset 297190
slice_id 0 seek offset 0
slice_id 1 seek offset 148595
Total steps 59440, warmup steps 3566, warmup_factor 0.00028042624789680314
Total steps 59440, warmup steps 3566, warmup_factor 0.00028042624789680314
Total steps 59440, warmup steps 3566, warmup_factor 0.00028042624789680314
wandb: Currently logged in as: jackcai1206. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.0
wandb: Run data is saved locally in /home/zcai75/Github/OFA_forked/run_scripts/vrd/wandb/run-20230626_181917-zb18sa9x
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run _16_3e-5_512_rare_balanced_2
wandb: ⭐️ View project at https://wandb.ai/jackcai1206/OFA-VG
wandb: 🚀 View run at https://wandb.ai/jackcai1206/OFA-VG/runs/zb18sa9x
2023-06-26 18:19:23 - trainer.py[line:703] - INFO: begin training epoch 1
2023-06-26 18:19:23 - train.py[line:305] - INFO: Start iterating over samples
2023-06-26 18:19:46 - progress_bar.py[line:272] - INFO: epoch 001:     10 / 3715 loss=11.085, loss_v1=0, loss_v2=0, nll_loss=11.094, ntokens=1087.3, nsentences=120, sample_size=1087.3, sample_size_v1=0, sample_size_v2=0, ppl=2186.43, wps=529.6, ups=0.48, wpb=1087.3, bsz=120, num_updates=10, lr=8.41279e-08, gnorm=17.941, clip=100, loss_scale=128, train_wall=22, gb_free=8.9, wall=30
2023-06-26 18:20:06 - progress_bar.py[line:272] - INFO: epoch 001:     20 / 3715 loss=11.083, loss_v1=0, loss_v2=0, nll_loss=11.092, ntokens=1074.9, nsentences=120, sample_size=1074.9, sample_size_v1=0, sample_size_v2=0, ppl=2183.46, wps=521.7, ups=0.49, wpb=1074.9, bsz=120, num_updates=20, lr=1.68256e-07, gnorm=18.202, clip=100, loss_scale=128, train_wall=21, gb_free=8.9, wall=51
2023-06-26 18:20:27 - progress_bar.py[line:272] - INFO: epoch 001:     30 / 3715 loss=11.029, loss_v1=0, loss_v2=0, nll_loss=11.032, ntokens=1091.6, nsentences=120, sample_size=1091.6, sample_size_v1=0, sample_size_v2=0, ppl=2093.81, wps=530.5, ups=0.49, wpb=1091.6, bsz=120, num_updates=30, lr=2.52384e-07, gnorm=18.128, clip=100, loss_scale=128, train_wall=21, gb_free=8.9, wall=71
2023-06-26 18:20:47 - progress_bar.py[line:272] - INFO: epoch 001:     40 / 3715 loss=10.848, loss_v1=0, loss_v2=0, nll_loss=10.831, ntokens=1092.4, nsentences=120, sample_size=1092.4, sample_size_v1=0, sample_size_v2=0, ppl=1821.7, wps=531.8, ups=0.49, wpb=1092.4, bsz=120, num_updates=40, lr=3.36511e-07, gnorm=17.751, clip=100, loss_scale=128, train_wall=21, gb_free=8.9, wall=92
2023-06-26 18:21:08 - progress_bar.py[line:272] - INFO: epoch 001:     50 / 3715 loss=10.544, loss_v1=0, loss_v2=0, nll_loss=10.494, ntokens=1082.6, nsentences=120, sample_size=1082.6, sample_size_v1=0, sample_size_v2=0, ppl=1441.91, wps=527.1, ups=0.49, wpb=1082.6, bsz=120, num_updates=50, lr=4.20639e-07, gnorm=17.135, clip=100, loss_scale=128, train_wall=21, gb_free=8.9, wall=112
2023-06-26 18:21:28 - progress_bar.py[line:272] - INFO: epoch 001:     60 / 3715 loss=10.213, loss_v1=0, loss_v2=0, nll_loss=10.125, ntokens=1073.3, nsentences=120, sample_size=1073.3, sample_size_v1=0, sample_size_v2=0, ppl=1116.9, wps=523.4, ups=0.49, wpb=1073.3, bsz=120, num_updates=60, lr=5.04767e-07, gnorm=15.884, clip=100, loss_scale=128, train_wall=20, gb_free=8.9, wall=133
2023-06-26 18:21:49 - progress_bar.py[line:272] - INFO: epoch 001:     70 / 3715 loss=9.847, loss_v1=0, loss_v2=0, nll_loss=9.719, ntokens=1080.3, nsentences=120, sample_size=1080.3, sample_size_v1=0, sample_size_v2=0, ppl=842.49, wps=525.5, ups=0.49, wpb=1080.3, bsz=120, num_updates=70, lr=5.88895e-07, gnorm=14.591, clip=100, loss_scale=128, train_wall=21, gb_free=8.9, wall=153
2023-06-26 18:22:10 - progress_bar.py[line:272] - INFO: epoch 001:     80 / 3715 loss=9.479, loss_v1=0, loss_v2=0, nll_loss=9.309, ntokens=1071, nsentences=120, sample_size=1071, sample_size_v1=0, sample_size_v2=0, ppl=634.5, wps=521.3, ups=0.49, wpb=1071, bsz=120, num_updates=80, lr=6.73023e-07, gnorm=12.553, clip=100, loss_scale=128, train_wall=21, gb_free=8.9, wall=174
2023-06-26 18:22:30 - progress_bar.py[line:272] - INFO: epoch 001:     90 / 3715 loss=9.172, loss_v1=0, loss_v2=0, nll_loss=8.969, ntokens=1089.7, nsentences=120, sample_size=1089.7, sample_size_v1=0, sample_size_v2=0, ppl=501.13, wps=530.4, ups=0.49, wpb=1089.7, bsz=120, num_updates=90, lr=7.57151e-07, gnorm=11.238, clip=100, loss_scale=128, train_wall=21, gb_free=8.9, wall=194
2023-06-26 18:22:51 - progress_bar.py[line:272] - INFO: epoch 001:    100 / 3715 loss=8.826, loss_v1=0, loss_v2=0, nll_loss=8.584, ntokens=1099.5, nsentences=120, sample_size=1099.5, sample_size_v1=0, sample_size_v2=0, ppl=383.73, wps=534.5, ups=0.49, wpb=1099.5, bsz=120, num_updates=100, lr=8.41279e-07, gnorm=10.189, clip=100, loss_scale=128, train_wall=21, gb_free=8.9, wall=215
2023-06-26 18:23:11 - progress_bar.py[line:272] - INFO: epoch 001:    110 / 3715 loss=8.528, loss_v1=0, loss_v2=0, nll_loss=8.252, ntokens=1094.3, nsentences=120, sample_size=1094.3, sample_size_v1=0, sample_size_v2=0, ppl=304.87, wps=531.9, ups=0.49, wpb=1094.3, bsz=120, num_updates=110, lr=9.25407e-07, gnorm=9.105, clip=100, loss_scale=128, train_wall=21, gb_free=8.9, wall=236
2023-06-26 18:23:32 - progress_bar.py[line:272] - INFO: epoch 001:    120 / 3715 loss=8.266, loss_v1=0, loss_v2=0, nll_loss=7.959, ntokens=1095, nsentences=120, sample_size=1095, sample_size_v1=0, sample_size_v2=0, ppl=248.86, wps=532.4, ups=0.49, wpb=1095, bsz=120, num_updates=120, lr=1.00953e-06, gnorm=8.296, clip=100, loss_scale=128, train_wall=21, gb_free=8.9, wall=256
2023-06-26 18:23:52 - progress_bar.py[line:272] - INFO: epoch 001:    130 / 3715 loss=8.034, loss_v1=0, loss_v2=0, nll_loss=7.701, ntokens=1075.3, nsentences=120, sample_size=1075.3, sample_size_v1=0, sample_size_v2=0, ppl=208.09, wps=523.5, ups=0.49, wpb=1075.3, bsz=120, num_updates=130, lr=1.09366e-06, gnorm=7.715, clip=100, loss_scale=128, train_wall=21, gb_free=8.9, wall=277
2023-06-26 18:24:13 - progress_bar.py[line:272] - INFO: epoch 001:    140 / 3715 loss=7.822, loss_v1=0, loss_v2=0, nll_loss=7.465, ntokens=1092.9, nsentences=120, sample_size=1092.9, sample_size_v1=0, sample_size_v2=0, ppl=176.63, wps=532.1, ups=0.49, wpb=1092.9, bsz=120, num_updates=140, lr=1.17779e-06, gnorm=7.379, clip=100, loss_scale=128, train_wall=21, gb_free=8.9, wall=297
2023-06-26 18:24:34 - progress_bar.py[line:272] - INFO: epoch 001:    150 / 3715 loss=7.642, loss_v1=0, loss_v2=0, nll_loss=7.264, ntokens=1077.7, nsentences=120, sample_size=1077.7, sample_size_v1=0, sample_size_v2=0, ppl=153.67, wps=523.2, ups=0.49, wpb=1077.7, bsz=120, num_updates=150, lr=1.26192e-06, gnorm=6.892, clip=100, loss_scale=128, train_wall=21, gb_free=8.9, wall=318
2023-06-26 18:24:54 - progress_bar.py[line:272] - INFO: epoch 001:    160 / 3715 loss=7.476, loss_v1=0, loss_v2=0, nll_loss=7.078, ntokens=1074.5, nsentences=120, sample_size=1074.5, sample_size_v1=0, sample_size_v2=0, ppl=135.07, wps=522.5, ups=0.49, wpb=1074.5, bsz=120, num_updates=160, lr=1.34605e-06, gnorm=6.76, clip=100, loss_scale=128, train_wall=21, gb_free=8.9, wall=338
2023-06-26 18:25:15 - progress_bar.py[line:272] - INFO: epoch 001:    170 / 3715 loss=7.332, loss_v1=0, loss_v2=0, nll_loss=6.916, ntokens=1091.3, nsentences=120, sample_size=1091.3, sample_size_v1=0, sample_size_v2=0, ppl=120.8, wps=530.6, ups=0.49, wpb=1091.3, bsz=120, num_updates=170, lr=1.43017e-06, gnorm=6.521, clip=100, loss_scale=128, train_wall=21, gb_free=8.9, wall=359
2023-06-26 18:25:35 - progress_bar.py[line:272] - INFO: epoch 001:    180 / 3715 loss=7.207, loss_v1=0, loss_v2=0, nll_loss=6.776, ntokens=1111.3, nsentences=120, sample_size=1111.3, sample_size_v1=0, sample_size_v2=0, ppl=109.62, wps=539.5, ups=0.49, wpb=1111.3, bsz=120, num_updates=180, lr=1.5143e-06, gnorm=6.176, clip=100, loss_scale=128, train_wall=21, gb_free=8.9, wall=380
2023-06-26 18:25:56 - progress_bar.py[line:272] - INFO: epoch 001:    190 / 3715 loss=7.021, loss_v1=0, loss_v2=0, nll_loss=6.568, ntokens=1076.4, nsentences=120, sample_size=1076.4, sample_size_v1=0, sample_size_v2=0, ppl=94.9, wps=523.3, ups=0.49, wpb=1076.4, bsz=120, num_updates=190, lr=1.59843e-06, gnorm=6.105, clip=100, loss_scale=128, train_wall=21, gb_free=8.9, wall=400
2023-06-26 18:26:16 - progress_bar.py[line:272] - INFO: epoch 001:    200 / 3715 loss=6.873, loss_v1=0, loss_v2=0, nll_loss=6.403, ntokens=1066.6, nsentences=120, sample_size=1066.6, sample_size_v1=0, sample_size_v2=0, ppl=84.61, wps=519.3, ups=0.49, wpb=1066.6, bsz=120, num_updates=200, lr=1.68256e-06, gnorm=5.885, clip=100, loss_scale=128, train_wall=21, gb_free=8.9, wall=421
2023-06-26 18:26:37 - progress_bar.py[line:272] - INFO: epoch 001:    210 / 3715 loss=6.709, loss_v1=0, loss_v2=0, nll_loss=6.218, ntokens=1067.4, nsentences=120, sample_size=1067.4, sample_size_v1=0, sample_size_v2=0, ppl=74.45, wps=519.7, ups=0.49, wpb=1067.4, bsz=120, num_updates=210, lr=1.76669e-06, gnorm=5.659, clip=100, loss_scale=128, train_wall=21, gb_free=8.9, wall=441
2023-06-26 18:26:57 - progress_bar.py[line:272] - INFO: epoch 001:    220 / 3715 loss=6.592, loss_v1=0, loss_v2=0, nll_loss=6.086, ntokens=1093.8, nsentences=120, sample_size=1093.8, sample_size_v1=0, sample_size_v2=0, ppl=67.91, wps=532.9, ups=0.49, wpb=1093.8, bsz=120, num_updates=220, lr=1.85081e-06, gnorm=5.324, clip=100, loss_scale=128, train_wall=20, gb_free=8.9, wall=462
2023-06-26 18:27:18 - progress_bar.py[line:272] - INFO: epoch 001:    230 / 3715 loss=6.433, loss_v1=0, loss_v2=0, nll_loss=5.905, ntokens=1076.7, nsentences=120, sample_size=1076.7, sample_size_v1=0, sample_size_v2=0, ppl=59.93, wps=524.2, ups=0.49, wpb=1076.7, bsz=120, num_updates=230, lr=1.93494e-06, gnorm=5.112, clip=100, loss_scale=128, train_wall=21, gb_free=8.9, wall=482
2023-06-26 18:27:39 - progress_bar.py[line:272] - INFO: epoch 001:    240 / 3715 loss=6.309, loss_v1=0, loss_v2=0, nll_loss=5.764, ntokens=1069.6, nsentences=120, sample_size=1069.6, sample_size_v1=0, sample_size_v2=0, ppl=54.36, wps=520.8, ups=0.49, wpb=1069.6, bsz=120, num_updates=240, lr=2.01907e-06, gnorm=4.891, clip=100, loss_scale=128, train_wall=21, gb_free=8.9, wall=503
2023-06-26 18:27:59 - progress_bar.py[line:272] - INFO: epoch 001:    250 / 3715 loss=6.194, loss_v1=0, loss_v2=0, nll_loss=5.633, ntokens=1091.1, nsentences=120, sample_size=1091.1, sample_size_v1=0, sample_size_v2=0, ppl=49.61, wps=531, ups=0.49, wpb=1091.1, bsz=120, num_updates=250, lr=2.1032e-06, gnorm=4.583, clip=100, loss_scale=128, train_wall=21, gb_free=8.9, wall=523
2023-06-26 18:28:20 - progress_bar.py[line:272] - INFO: epoch 001:    260 / 3715 loss=6.051, loss_v1=0, loss_v2=0, nll_loss=5.469, ntokens=1066.6, nsentences=120, sample_size=1066.6, sample_size_v1=0, sample_size_v2=0, ppl=44.29, wps=519, ups=0.49, wpb=1066.6, bsz=120, num_updates=260, lr=2.18732e-06, gnorm=4.378, clip=100, loss_scale=128, train_wall=21, gb_free=8.9, wall=544
2023-06-26 18:28:40 - progress_bar.py[line:272] - INFO: epoch 001:    270 / 3715 loss=5.938, loss_v1=0, loss_v2=0, nll_loss=5.34, ntokens=1091.8, nsentences=120, sample_size=1091.8, sample_size_v1=0, sample_size_v2=0, ppl=40.5, wps=530.2, ups=0.49, wpb=1091.8, bsz=120, num_updates=270, lr=2.27145e-06, gnorm=4.157, clip=100, loss_scale=128, train_wall=21, gb_free=8.9, wall=565
2023-06-26 18:29:01 - progress_bar.py[line:272] - INFO: epoch 001:    280 / 3715 loss=5.819, loss_v1=0, loss_v2=0, nll_loss=5.202, ntokens=1077.7, nsentences=120, sample_size=1077.7, sample_size_v1=0, sample_size_v2=0, ppl=36.82, wps=524.7, ups=0.49, wpb=1077.7, bsz=120, num_updates=280, lr=2.35558e-06, gnorm=4.035, clip=100, loss_scale=128, train_wall=21, gb_free=8.9, wall=585
2023-06-26 18:29:21 - progress_bar.py[line:272] - INFO: epoch 001:    290 / 3715 loss=5.679, loss_v1=0, loss_v2=0, nll_loss=5.042, ntokens=1082.8, nsentences=120, sample_size=1082.8, sample_size_v1=0, sample_size_v2=0, ppl=32.95, wps=526.7, ups=0.49, wpb=1082.8, bsz=120, num_updates=290, lr=2.43971e-06, gnorm=3.869, clip=100, loss_scale=128, train_wall=21, gb_free=8.9, wall=606
2023-06-26 18:29:42 - progress_bar.py[line:272] - INFO: epoch 001:    300 / 3715 loss=5.537, loss_v1=0, loss_v2=0, nll_loss=4.88, ntokens=1062.6, nsentences=120, sample_size=1062.6, sample_size_v1=0, sample_size_v2=0, ppl=29.45, wps=517.8, ups=0.49, wpb=1062.6, bsz=120, num_updates=300, lr=2.52384e-06, gnorm=3.62, clip=100, loss_scale=128, train_wall=20, gb_free=8.9, wall=626
2023-06-26 18:30:02 - progress_bar.py[line:272] - INFO: epoch 001:    310 / 3715 loss=5.523, loss_v1=0, loss_v2=0, nll_loss=4.862, ntokens=1102.4, nsentences=120, sample_size=1102.4, sample_size_v1=0, sample_size_v2=0, ppl=29.08, wps=536.5, ups=0.49, wpb=1102.4, bsz=120, num_updates=310, lr=2.60796e-06, gnorm=3.576, clip=100, loss_scale=128, train_wall=21, gb_free=8.9, wall=647
2023-06-26 18:30:23 - progress_bar.py[line:272] - INFO: epoch 001:    320 / 3715 loss=5.368, loss_v1=0, loss_v2=0, nll_loss=4.683, ntokens=1076.4, nsentences=120, sample_size=1076.4, sample_size_v1=0, sample_size_v2=0, ppl=25.69, wps=524.1, ups=0.49, wpb=1076.4, bsz=120, num_updates=320, lr=2.69209e-06, gnorm=3.348, clip=100, loss_scale=128, train_wall=21, gb_free=8.9, wall=667
2023-06-26 18:30:44 - progress_bar.py[line:272] - INFO: epoch 001:    330 / 3715 loss=5.281, loss_v1=0, loss_v2=0, nll_loss=4.584, ntokens=1100.7, nsentences=120, sample_size=1100.7, sample_size_v1=0, sample_size_v2=0, ppl=23.99, wps=535.7, ups=0.49, wpb=1100.7, bsz=120, num_updates=330, lr=2.77622e-06, gnorm=3.344, clip=100, loss_scale=128, train_wall=21, gb_free=8.9, wall=688
2023-06-26 18:31:04 - progress_bar.py[line:272] - INFO: epoch 001:    340 / 3715 loss=5.13, loss_v1=0, loss_v2=0, nll_loss=4.411, ntokens=1056.7, nsentences=120, sample_size=1056.7, sample_size_v1=0, sample_size_v2=0, ppl=21.27, wps=513.7, ups=0.49, wpb=1056.7, bsz=120, num_updates=340, lr=2.86035e-06, gnorm=3.141, clip=100, loss_scale=128, train_wall=21, gb_free=8.9, wall=708
2023-06-26 18:31:25 - progress_bar.py[line:272] - INFO: epoch 001:    350 / 3715 loss=5.126, loss_v1=0, loss_v2=0, nll_loss=4.405, ntokens=1093.9, nsentences=120, sample_size=1093.9, sample_size_v1=0, sample_size_v2=0, ppl=21.18, wps=531, ups=0.49, wpb=1093.9, bsz=120, num_updates=350, lr=2.94448e-06, gnorm=3.031, clip=100, loss_scale=128, train_wall=21, gb_free=8.9, wall=729
2023-06-26 18:31:45 - progress_bar.py[line:272] - INFO: epoch 001:    360 / 3715 loss=5.046, loss_v1=0, loss_v2=0, nll_loss=4.312, ntokens=1107.5, nsentences=120, sample_size=1107.5, sample_size_v1=0, sample_size_v2=0, ppl=19.86, wps=538.1, ups=0.49, wpb=1107.5, bsz=120, num_updates=360, lr=3.0286e-06, gnorm=3.071, clip=100, loss_scale=128, train_wall=21, gb_free=8.9, wall=750
2023-06-26 18:32:06 - progress_bar.py[line:272] - INFO: epoch 001:    370 / 3715 loss=4.986, loss_v1=0, loss_v2=0, nll_loss=4.241, ntokens=1093, nsentences=120, sample_size=1093, sample_size_v1=0, sample_size_v2=0, ppl=18.91, wps=531.5, ups=0.49, wpb=1093, bsz=120, num_updates=370, lr=3.11273e-06, gnorm=2.802, clip=100, loss_scale=128, train_wall=21, gb_free=8.9, wall=770
2023-06-26 18:32:26 - progress_bar.py[line:272] - INFO: epoch 001:    380 / 3715 loss=4.906, loss_v1=0, loss_v2=0, nll_loss=4.15, ntokens=1090.8, nsentences=120, sample_size=1090.8, sample_size_v1=0, sample_size_v2=0, ppl=17.75, wps=529.5, ups=0.49, wpb=1090.8, bsz=120, num_updates=380, lr=3.19686e-06, gnorm=2.77, clip=100, loss_scale=128, train_wall=21, gb_free=8.9, wall=791
2023-06-26 18:32:47 - progress_bar.py[line:272] - INFO: epoch 001:    390 / 3715 loss=4.816, loss_v1=0, loss_v2=0, nll_loss=4.045, ntokens=1080.8, nsentences=120, sample_size=1080.8, sample_size_v1=0, sample_size_v2=0, ppl=16.5, wps=525.3, ups=0.49, wpb=1080.8, bsz=120, num_updates=390, lr=3.28099e-06, gnorm=2.609, clip=100, loss_scale=128, train_wall=21, gb_free=8.9, wall=811
2023-06-26 18:33:08 - progress_bar.py[line:272] - INFO: epoch 001:    400 / 3715 loss=4.784, loss_v1=0, loss_v2=0, nll_loss=4.005, ntokens=1084.1, nsentences=120, sample_size=1084.1, sample_size_v1=0, sample_size_v2=0, ppl=16.06, wps=526.7, ups=0.49, wpb=1084.1, bsz=120, num_updates=400, lr=3.36511e-06, gnorm=2.485, clip=100, loss_scale=128, train_wall=21, gb_free=8.9, wall=832
2023-06-26 18:33:28 - progress_bar.py[line:272] - INFO: epoch 001:    410 / 3715 loss=4.707, loss_v1=0, loss_v2=0, nll_loss=3.917, ntokens=1062.4, nsentences=120, sample_size=1062.4, sample_size_v1=0, sample_size_v2=0, ppl=15.11, wps=516.1, ups=0.49, wpb=1062.4, bsz=120, num_updates=410, lr=3.44924e-06, gnorm=2.425, clip=100, loss_scale=128, train_wall=21, gb_free=8.9, wall=853
2023-06-26 18:33:49 - progress_bar.py[line:272] - INFO: epoch 001:    420 / 3715 loss=4.694, loss_v1=0, loss_v2=0, nll_loss=3.9, ntokens=1107.8, nsentences=120, sample_size=1107.8, sample_size_v1=0, sample_size_v2=0, ppl=14.93, wps=538.1, ups=0.49, wpb=1107.8, bsz=120, num_updates=420, lr=3.53337e-06, gnorm=2.497, clip=100, loss_scale=128, train_wall=21, gb_free=8.9, wall=873
2023-06-26 18:34:09 - progress_bar.py[line:272] - INFO: epoch 001:    430 / 3715 loss=4.623, loss_v1=0, loss_v2=0, nll_loss=3.817, ntokens=1075.5, nsentences=120, sample_size=1075.5, sample_size_v1=0, sample_size_v2=0, ppl=14.09, wps=523, ups=0.49, wpb=1075.5, bsz=120, num_updates=430, lr=3.6175e-06, gnorm=2.31, clip=100, loss_scale=128, train_wall=21, gb_free=8.9, wall=894
2023-06-26 18:34:30 - progress_bar.py[line:272] - INFO: epoch 001:    440 / 3715 loss=4.563, loss_v1=0, loss_v2=0, nll_loss=3.749, ntokens=1074.4, nsentences=120, sample_size=1074.4, sample_size_v1=0, sample_size_v2=0, ppl=13.44, wps=522.8, ups=0.49, wpb=1074.4, bsz=120, num_updates=440, lr=3.70163e-06, gnorm=2.258, clip=100, loss_scale=128, train_wall=21, gb_free=8.9, wall=914
2023-06-26 18:34:50 - progress_bar.py[line:272] - INFO: epoch 001:    450 / 3715 loss=4.526, loss_v1=0, loss_v2=0, nll_loss=3.706, ntokens=1112.3, nsentences=120, sample_size=1112.3, sample_size_v1=0, sample_size_v2=0, ppl=13.05, wps=541, ups=0.49, wpb=1112.3, bsz=120, num_updates=450, lr=3.78575e-06, gnorm=2.29, clip=100, loss_scale=128, train_wall=21, gb_free=8.9, wall=935
2023-06-26 18:35:11 - progress_bar.py[line:272] - INFO: epoch 001:    460 / 3715 loss=4.48, loss_v1=0, loss_v2=0, nll_loss=3.65, ntokens=1083.1, nsentences=120, sample_size=1083.1, sample_size_v1=0, sample_size_v2=0, ppl=12.55, wps=526.5, ups=0.49, wpb=1083.1, bsz=120, num_updates=460, lr=3.86988e-06, gnorm=2.139, clip=100, loss_scale=128, train_wall=21, gb_free=8.9, wall=955
2023-06-26 18:35:32 - progress_bar.py[line:272] - INFO: epoch 001:    470 / 3715 loss=4.435, loss_v1=0, loss_v2=0, nll_loss=3.597, ntokens=1056.1, nsentences=120, sample_size=1056.1, sample_size_v1=0, sample_size_v2=0, ppl=12.1, wps=513.9, ups=0.49, wpb=1056.1, bsz=120, num_updates=470, lr=3.95401e-06, gnorm=2.256, clip=100, loss_scale=128, train_wall=21, gb_free=8.9, wall=976
2023-06-26 18:35:52 - progress_bar.py[line:272] - INFO: epoch 001:    480 / 3715 loss=4.44, loss_v1=0, loss_v2=0, nll_loss=3.604, ntokens=1090.8, nsentences=120, sample_size=1090.8, sample_size_v1=0, sample_size_v2=0, ppl=12.16, wps=529.7, ups=0.49, wpb=1090.8, bsz=120, num_updates=480, lr=4.03814e-06, gnorm=2.161, clip=100, loss_scale=128, train_wall=21, gb_free=8.9, wall=997
2023-06-26 18:36:13 - progress_bar.py[line:272] - INFO: epoch 001:    490 / 3715 loss=4.387, loss_v1=0, loss_v2=0, nll_loss=3.543, ntokens=1085.8, nsentences=120, sample_size=1085.8, sample_size_v1=0, sample_size_v2=0, ppl=11.65, wps=527.4, ups=0.49, wpb=1085.8, bsz=120, num_updates=490, lr=4.12227e-06, gnorm=2.137, clip=100, loss_scale=128, train_wall=21, gb_free=8.9, wall=1017
2023-06-26 18:36:33 - progress_bar.py[line:272] - INFO: epoch 001:    500 / 3715 loss=4.327, loss_v1=0, loss_v2=0, nll_loss=3.475, ntokens=1089.2, nsentences=120, sample_size=1089.2, sample_size_v1=0, sample_size_v2=0, ppl=11.12, wps=529.7, ups=0.49, wpb=1089.2, bsz=120, num_updates=500, lr=4.20639e-06, gnorm=2.008, clip=100, loss_scale=128, train_wall=21, gb_free=8.9, wall=1038
2023-06-26 18:36:54 - progress_bar.py[line:272] - INFO: epoch 001:    510 / 3715 loss=4.273, loss_v1=0, loss_v2=0, nll_loss=3.412, ntokens=1103.2, nsentences=120, sample_size=1103.2, sample_size_v1=0, sample_size_v2=0, ppl=10.65, wps=535.9, ups=0.49, wpb=1103.2, bsz=120, num_updates=510, lr=4.29052e-06, gnorm=2.002, clip=100, loss_scale=128, train_wall=21, gb_free=8.9, wall=1058
2023-06-26 18:37:15 - progress_bar.py[line:272] - INFO: epoch 001:    520 / 3715 loss=4.258, loss_v1=0, loss_v2=0, nll_loss=3.394, ntokens=1065.6, nsentences=120, sample_size=1065.6, sample_size_v1=0, sample_size_v2=0, ppl=10.51, wps=517.7, ups=0.49, wpb=1065.6, bsz=120, num_updates=520, lr=4.37465e-06, gnorm=1.948, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=1079
2023-06-26 18:37:35 - progress_bar.py[line:272] - INFO: epoch 001:    530 / 3715 loss=4.221, loss_v1=0, loss_v2=0, nll_loss=3.355, ntokens=1095.5, nsentences=120, sample_size=1095.5, sample_size_v1=0, sample_size_v2=0, ppl=10.23, wps=532.2, ups=0.49, wpb=1095.5, bsz=120, num_updates=530, lr=4.45878e-06, gnorm=2.002, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=1099
2023-06-26 18:37:56 - progress_bar.py[line:272] - INFO: epoch 001:    540 / 3715 loss=4.151, loss_v1=0, loss_v2=0, nll_loss=3.273, ntokens=1063.8, nsentences=120, sample_size=1063.8, sample_size_v1=0, sample_size_v2=0, ppl=9.66, wps=517.3, ups=0.49, wpb=1063.8, bsz=120, num_updates=540, lr=4.54291e-06, gnorm=1.905, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=1120
2023-06-26 18:38:16 - progress_bar.py[line:272] - INFO: epoch 001:    550 / 3715 loss=4.141, loss_v1=0, loss_v2=0, nll_loss=3.262, ntokens=1080.8, nsentences=120, sample_size=1080.8, sample_size_v1=0, sample_size_v2=0, ppl=9.6, wps=525.5, ups=0.49, wpb=1080.8, bsz=120, num_updates=550, lr=4.62703e-06, gnorm=1.842, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=1141
2023-06-26 18:38:37 - progress_bar.py[line:272] - INFO: epoch 001:    560 / 3715 loss=4.076, loss_v1=0, loss_v2=0, nll_loss=3.186, ntokens=1067.3, nsentences=120, sample_size=1067.3, sample_size_v1=0, sample_size_v2=0, ppl=9.1, wps=518.7, ups=0.49, wpb=1067.3, bsz=120, num_updates=560, lr=4.71116e-06, gnorm=1.79, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=1161
2023-06-26 18:38:57 - progress_bar.py[line:272] - INFO: epoch 001:    570 / 3715 loss=4.083, loss_v1=0, loss_v2=0, nll_loss=3.194, ntokens=1074.6, nsentences=120, sample_size=1074.6, sample_size_v1=0, sample_size_v2=0, ppl=9.15, wps=522.5, ups=0.49, wpb=1074.6, bsz=120, num_updates=570, lr=4.79529e-06, gnorm=1.789, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=1182
2023-06-26 18:39:18 - progress_bar.py[line:272] - INFO: epoch 001:    580 / 3715 loss=4.04, loss_v1=0, loss_v2=0, nll_loss=3.146, ntokens=1073.3, nsentences=120, sample_size=1073.3, sample_size_v1=0, sample_size_v2=0, ppl=8.85, wps=521.7, ups=0.49, wpb=1073.3, bsz=120, num_updates=580, lr=4.87942e-06, gnorm=1.783, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=1202
2023-06-26 18:39:39 - progress_bar.py[line:272] - INFO: epoch 001:    590 / 3715 loss=4.003, loss_v1=0, loss_v2=0, nll_loss=3.104, ntokens=1078.6, nsentences=120, sample_size=1078.6, sample_size_v1=0, sample_size_v2=0, ppl=8.6, wps=523.8, ups=0.49, wpb=1078.6, bsz=120, num_updates=590, lr=4.96354e-06, gnorm=1.809, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=1223
2023-06-26 18:39:59 - progress_bar.py[line:272] - INFO: epoch 001:    600 / 3715 loss=3.974, loss_v1=0, loss_v2=0, nll_loss=3.069, ntokens=1098.7, nsentences=120, sample_size=1098.7, sample_size_v1=0, sample_size_v2=0, ppl=8.39, wps=533.5, ups=0.49, wpb=1098.7, bsz=120, num_updates=600, lr=5.04767e-06, gnorm=1.785, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=1244
2023-06-26 18:40:20 - progress_bar.py[line:272] - INFO: epoch 001:    610 / 3715 loss=3.913, loss_v1=0, loss_v2=0, nll_loss=3.002, ntokens=1098.6, nsentences=120, sample_size=1098.6, sample_size_v1=0, sample_size_v2=0, ppl=8.01, wps=534, ups=0.49, wpb=1098.6, bsz=120, num_updates=610, lr=5.1318e-06, gnorm=1.781, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=1264
2023-06-26 18:40:40 - progress_bar.py[line:272] - INFO: epoch 001:    620 / 3715 loss=3.891, loss_v1=0, loss_v2=0, nll_loss=2.975, ntokens=1067.2, nsentences=120, sample_size=1067.2, sample_size_v1=0, sample_size_v2=0, ppl=7.86, wps=519.7, ups=0.49, wpb=1067.2, bsz=120, num_updates=620, lr=5.21593e-06, gnorm=1.662, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=1285
2023-06-26 18:41:01 - progress_bar.py[line:272] - INFO: epoch 001:    630 / 3715 loss=3.853, loss_v1=0, loss_v2=0, nll_loss=2.933, ntokens=1076.4, nsentences=120, sample_size=1076.4, sample_size_v1=0, sample_size_v2=0, ppl=7.64, wps=523.9, ups=0.49, wpb=1076.4, bsz=120, num_updates=630, lr=5.30006e-06, gnorm=1.614, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=1305
2023-06-26 18:41:21 - progress_bar.py[line:272] - INFO: epoch 001:    640 / 3715 loss=3.811, loss_v1=0, loss_v2=0, nll_loss=2.883, ntokens=1077, nsentences=120, sample_size=1077, sample_size_v1=0, sample_size_v2=0, ppl=7.38, wps=523.5, ups=0.49, wpb=1077, bsz=120, num_updates=640, lr=5.38418e-06, gnorm=1.581, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=1326
2023-06-26 18:41:42 - progress_bar.py[line:272] - INFO: epoch 001:    650 / 3715 loss=3.807, loss_v1=0, loss_v2=0, nll_loss=2.878, ntokens=1076.5, nsentences=120, sample_size=1076.5, sample_size_v1=0, sample_size_v2=0, ppl=7.35, wps=523.9, ups=0.49, wpb=1076.5, bsz=120, num_updates=650, lr=5.46831e-06, gnorm=1.575, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=1346
2023-06-26 18:42:03 - progress_bar.py[line:272] - INFO: epoch 001:    660 / 3715 loss=3.73, loss_v1=0, loss_v2=0, nll_loss=2.79, ntokens=1059.2, nsentences=120, sample_size=1059.2, sample_size_v1=0, sample_size_v2=0, ppl=6.92, wps=514.9, ups=0.49, wpb=1059.2, bsz=120, num_updates=660, lr=5.55244e-06, gnorm=1.58, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=1367
2023-06-26 18:42:23 - progress_bar.py[line:272] - INFO: epoch 001:    670 / 3715 loss=3.722, loss_v1=0, loss_v2=0, nll_loss=2.781, ntokens=1078.2, nsentences=120, sample_size=1078.2, sample_size_v1=0, sample_size_v2=0, ppl=6.87, wps=524, ups=0.49, wpb=1078.2, bsz=120, num_updates=670, lr=5.63657e-06, gnorm=1.56, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=1387
2023-06-26 18:42:44 - progress_bar.py[line:272] - INFO: epoch 001:    680 / 3715 loss=3.668, loss_v1=0, loss_v2=0, nll_loss=2.718, ntokens=1078.9, nsentences=120, sample_size=1078.9, sample_size_v1=0, sample_size_v2=0, ppl=6.58, wps=524.2, ups=0.49, wpb=1078.9, bsz=120, num_updates=680, lr=5.7207e-06, gnorm=1.518, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=1408
2023-06-26 18:43:04 - progress_bar.py[line:272] - INFO: epoch 001:    690 / 3715 loss=3.639, loss_v1=0, loss_v2=0, nll_loss=2.687, ntokens=1080.3, nsentences=120, sample_size=1080.3, sample_size_v1=0, sample_size_v2=0, ppl=6.44, wps=524.9, ups=0.49, wpb=1080.3, bsz=120, num_updates=690, lr=5.80482e-06, gnorm=1.579, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=1429
2023-06-26 18:43:25 - progress_bar.py[line:272] - INFO: epoch 001:    700 / 3715 loss=3.621, loss_v1=0, loss_v2=0, nll_loss=2.664, ntokens=1070, nsentences=120, sample_size=1070, sample_size_v1=0, sample_size_v2=0, ppl=6.34, wps=519.6, ups=0.49, wpb=1070, bsz=120, num_updates=700, lr=5.88895e-06, gnorm=1.519, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=1449
2023-06-26 18:43:45 - progress_bar.py[line:272] - INFO: epoch 001:    710 / 3715 loss=3.567, loss_v1=0, loss_v2=0, nll_loss=2.603, ntokens=1099.3, nsentences=120, sample_size=1099.3, sample_size_v1=0, sample_size_v2=0, ppl=6.08, wps=535, ups=0.49, wpb=1099.3, bsz=120, num_updates=710, lr=5.97308e-06, gnorm=1.478, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=1470
2023-06-26 18:44:06 - progress_bar.py[line:272] - INFO: epoch 001:    720 / 3715 loss=3.556, loss_v1=0, loss_v2=0, nll_loss=2.588, ntokens=1092.5, nsentences=120, sample_size=1092.5, sample_size_v1=0, sample_size_v2=0, ppl=6.01, wps=531.8, ups=0.49, wpb=1092.5, bsz=120, num_updates=720, lr=6.05721e-06, gnorm=1.486, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=1490
2023-06-26 18:44:27 - progress_bar.py[line:272] - INFO: epoch 001:    730 / 3715 loss=3.534, loss_v1=0, loss_v2=0, nll_loss=2.564, ntokens=1069.8, nsentences=120, sample_size=1069.8, sample_size_v1=0, sample_size_v2=0, ppl=5.91, wps=519.4, ups=0.49, wpb=1069.8, bsz=120, num_updates=730, lr=6.14133e-06, gnorm=1.495, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=1511
2023-06-26 18:44:47 - progress_bar.py[line:272] - INFO: epoch 001:    740 / 3715 loss=3.485, loss_v1=0, loss_v2=0, nll_loss=2.506, ntokens=1083, nsentences=120, sample_size=1083, sample_size_v1=0, sample_size_v2=0, ppl=5.68, wps=526.7, ups=0.49, wpb=1083, bsz=120, num_updates=740, lr=6.22546e-06, gnorm=1.383, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=1532
2023-06-26 18:45:08 - progress_bar.py[line:272] - INFO: epoch 001:    750 / 3715 loss=3.449, loss_v1=0, loss_v2=0, nll_loss=2.463, ntokens=1077.9, nsentences=120, sample_size=1077.9, sample_size_v1=0, sample_size_v2=0, ppl=5.51, wps=523.8, ups=0.49, wpb=1077.9, bsz=120, num_updates=750, lr=6.30959e-06, gnorm=1.366, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=1552
2023-06-26 18:45:28 - progress_bar.py[line:272] - INFO: epoch 001:    760 / 3715 loss=3.451, loss_v1=0, loss_v2=0, nll_loss=2.467, ntokens=1095.3, nsentences=120, sample_size=1095.3, sample_size_v1=0, sample_size_v2=0, ppl=5.53, wps=532.3, ups=0.49, wpb=1095.3, bsz=120, num_updates=760, lr=6.39372e-06, gnorm=1.355, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=1573
2023-06-26 18:45:49 - progress_bar.py[line:272] - INFO: epoch 001:    770 / 3715 loss=3.397, loss_v1=0, loss_v2=0, nll_loss=2.404, ntokens=1061.4, nsentences=120, sample_size=1061.4, sample_size_v1=0, sample_size_v2=0, ppl=5.29, wps=515.9, ups=0.49, wpb=1061.4, bsz=120, num_updates=770, lr=6.47785e-06, gnorm=1.318, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=1593
2023-06-26 18:46:10 - progress_bar.py[line:272] - INFO: epoch 001:    780 / 3715 loss=3.371, loss_v1=0, loss_v2=0, nll_loss=2.371, ntokens=1068.9, nsentences=120, sample_size=1068.9, sample_size_v1=0, sample_size_v2=0, ppl=5.17, wps=518.9, ups=0.49, wpb=1068.9, bsz=120, num_updates=780, lr=6.56197e-06, gnorm=1.299, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=1614
2023-06-26 18:46:30 - progress_bar.py[line:272] - INFO: epoch 001:    790 / 3715 loss=3.319, loss_v1=0, loss_v2=0, nll_loss=2.313, ntokens=1083.4, nsentences=120, sample_size=1083.4, sample_size_v1=0, sample_size_v2=0, ppl=4.97, wps=526.5, ups=0.49, wpb=1083.4, bsz=120, num_updates=790, lr=6.6461e-06, gnorm=1.32, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=1634
2023-06-26 18:46:51 - progress_bar.py[line:272] - INFO: epoch 001:    800 / 3715 loss=3.338, loss_v1=0, loss_v2=0, nll_loss=2.334, ntokens=1078, nsentences=120, sample_size=1078, sample_size_v1=0, sample_size_v2=0, ppl=5.04, wps=523.6, ups=0.49, wpb=1078, bsz=120, num_updates=800, lr=6.73023e-06, gnorm=1.292, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=1655
2023-06-26 18:47:11 - progress_bar.py[line:272] - INFO: epoch 001:    810 / 3715 loss=3.299, loss_v1=0, loss_v2=0, nll_loss=2.289, ntokens=1098, nsentences=120, sample_size=1098, sample_size_v1=0, sample_size_v2=0, ppl=4.89, wps=533.5, ups=0.49, wpb=1098, bsz=120, num_updates=810, lr=6.81436e-06, gnorm=1.272, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=1676
2023-06-26 18:47:32 - progress_bar.py[line:272] - INFO: epoch 001:    820 / 3715 loss=3.288, loss_v1=0, loss_v2=0, nll_loss=2.273, ntokens=1107.6, nsentences=120, sample_size=1107.6, sample_size_v1=0, sample_size_v2=0, ppl=4.83, wps=538, ups=0.49, wpb=1107.6, bsz=120, num_updates=820, lr=6.89849e-06, gnorm=1.226, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=1696
2023-06-26 18:47:52 - progress_bar.py[line:272] - INFO: epoch 001:    830 / 3715 loss=3.25, loss_v1=0, loss_v2=0, nll_loss=2.231, ntokens=1100.2, nsentences=120, sample_size=1100.2, sample_size_v1=0, sample_size_v2=0, ppl=4.69, wps=534.8, ups=0.49, wpb=1100.2, bsz=120, num_updates=830, lr=6.98261e-06, gnorm=1.254, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=1717
2023-06-26 18:48:13 - progress_bar.py[line:272] - INFO: epoch 001:    840 / 3715 loss=3.226, loss_v1=0, loss_v2=0, nll_loss=2.198, ntokens=1091.1, nsentences=120, sample_size=1091.1, sample_size_v1=0, sample_size_v2=0, ppl=4.59, wps=530.3, ups=0.49, wpb=1091.1, bsz=120, num_updates=840, lr=7.06674e-06, gnorm=1.322, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=1737
2023-06-26 18:48:34 - progress_bar.py[line:272] - INFO: epoch 001:    850 / 3715 loss=3.184, loss_v1=0, loss_v2=0, nll_loss=2.153, ntokens=1088.9, nsentences=120, sample_size=1088.9, sample_size_v1=0, sample_size_v2=0, ppl=4.45, wps=529, ups=0.49, wpb=1088.9, bsz=120, num_updates=850, lr=7.15087e-06, gnorm=1.277, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=1758
2023-06-26 18:48:54 - progress_bar.py[line:272] - INFO: epoch 001:    860 / 3715 loss=3.164, loss_v1=0, loss_v2=0, nll_loss=2.128, ntokens=1090.1, nsentences=120, sample_size=1090.1, sample_size_v1=0, sample_size_v2=0, ppl=4.37, wps=530.2, ups=0.49, wpb=1090.1, bsz=120, num_updates=860, lr=7.235e-06, gnorm=1.212, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=1779
2023-06-26 18:49:15 - progress_bar.py[line:272] - INFO: epoch 001:    870 / 3715 loss=3.145, loss_v1=0, loss_v2=0, nll_loss=2.103, ntokens=1081.2, nsentences=120, sample_size=1081.2, sample_size_v1=0, sample_size_v2=0, ppl=4.3, wps=525.2, ups=0.49, wpb=1081.2, bsz=120, num_updates=870, lr=7.31913e-06, gnorm=1.179, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=1799
2023-06-26 18:49:35 - progress_bar.py[line:272] - INFO: epoch 001:    880 / 3715 loss=3.126, loss_v1=0, loss_v2=0, nll_loss=2.082, ntokens=1079.7, nsentences=120, sample_size=1079.7, sample_size_v1=0, sample_size_v2=0, ppl=4.23, wps=524.1, ups=0.49, wpb=1079.7, bsz=120, num_updates=880, lr=7.40325e-06, gnorm=1.227, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=1820
2023-06-26 18:49:56 - progress_bar.py[line:272] - INFO: epoch 001:    890 / 3715 loss=3.115, loss_v1=0, loss_v2=0, nll_loss=2.067, ntokens=1071, nsentences=120, sample_size=1071, sample_size_v1=0, sample_size_v2=0, ppl=4.19, wps=520.9, ups=0.49, wpb=1071, bsz=120, num_updates=890, lr=7.48738e-06, gnorm=1.267, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=1840
2023-06-26 18:50:17 - progress_bar.py[line:272] - INFO: epoch 001:    900 / 3715 loss=3.091, loss_v1=0, loss_v2=0, nll_loss=2.042, ntokens=1082.4, nsentences=120, sample_size=1082.4, sample_size_v1=0, sample_size_v2=0, ppl=4.12, wps=525.9, ups=0.49, wpb=1082.4, bsz=120, num_updates=900, lr=7.57151e-06, gnorm=1.168, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=1861
2023-06-26 18:50:37 - progress_bar.py[line:272] - INFO: epoch 001:    910 / 3715 loss=3.09, loss_v1=0, loss_v2=0, nll_loss=2.036, ntokens=1076.6, nsentences=120, sample_size=1076.6, sample_size_v1=0, sample_size_v2=0, ppl=4.1, wps=524, ups=0.49, wpb=1076.6, bsz=120, num_updates=910, lr=7.65564e-06, gnorm=1.151, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=1881
2023-06-26 18:50:58 - progress_bar.py[line:272] - INFO: epoch 001:    920 / 3715 loss=3.085, loss_v1=0, loss_v2=0, nll_loss=2.029, ntokens=1087.3, nsentences=120, sample_size=1087.3, sample_size_v1=0, sample_size_v2=0, ppl=4.08, wps=529.9, ups=0.49, wpb=1087.3, bsz=120, num_updates=920, lr=7.73976e-06, gnorm=1.185, clip=100, loss_scale=256, train_wall=20, gb_free=8.9, wall=1902
2023-06-26 18:51:18 - progress_bar.py[line:272] - INFO: epoch 001:    930 / 3715 loss=3.071, loss_v1=0, loss_v2=0, nll_loss=2.012, ntokens=1055.6, nsentences=120, sample_size=1055.6, sample_size_v1=0, sample_size_v2=0, ppl=4.03, wps=514.5, ups=0.49, wpb=1055.6, bsz=120, num_updates=930, lr=7.82389e-06, gnorm=1.184, clip=100, loss_scale=256, train_wall=20, gb_free=8.9, wall=1922
2023-06-26 18:51:39 - progress_bar.py[line:272] - INFO: epoch 001:    940 / 3715 loss=3.033, loss_v1=0, loss_v2=0, nll_loss=1.973, ntokens=1095.4, nsentences=120, sample_size=1095.4, sample_size_v1=0, sample_size_v2=0, ppl=3.92, wps=533, ups=0.49, wpb=1095.4, bsz=120, num_updates=940, lr=7.90802e-06, gnorm=1.229, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=1943
2023-06-26 18:51:59 - progress_bar.py[line:272] - INFO: epoch 001:    950 / 3715 loss=3.009, loss_v1=0, loss_v2=0, nll_loss=1.938, ntokens=1089, nsentences=120, sample_size=1089, sample_size_v1=0, sample_size_v2=0, ppl=3.83, wps=530.7, ups=0.49, wpb=1089, bsz=120, num_updates=950, lr=7.99215e-06, gnorm=1.138, clip=100, loss_scale=256, train_wall=20, gb_free=8.9, wall=1964
2023-06-26 18:52:20 - progress_bar.py[line:272] - INFO: epoch 001:    960 / 3715 loss=3, loss_v1=0, loss_v2=0, nll_loss=1.93, ntokens=1090.6, nsentences=120, sample_size=1090.6, sample_size_v1=0, sample_size_v2=0, ppl=3.81, wps=530.3, ups=0.49, wpb=1090.6, bsz=120, num_updates=960, lr=8.07628e-06, gnorm=1.2, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=1984
2023-06-26 18:52:40 - progress_bar.py[line:272] - INFO: epoch 001:    970 / 3715 loss=2.996, loss_v1=0, loss_v2=0, nll_loss=1.922, ntokens=1072.7, nsentences=120, sample_size=1072.7, sample_size_v1=0, sample_size_v2=0, ppl=3.79, wps=522.1, ups=0.49, wpb=1072.7, bsz=120, num_updates=970, lr=8.1604e-06, gnorm=1.202, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=2005
2023-06-26 18:53:01 - progress_bar.py[line:272] - INFO: epoch 001:    980 / 3715 loss=2.987, loss_v1=0, loss_v2=0, nll_loss=1.91, ntokens=1091.6, nsentences=120, sample_size=1091.6, sample_size_v1=0, sample_size_v2=0, ppl=3.76, wps=530.8, ups=0.49, wpb=1091.6, bsz=120, num_updates=980, lr=8.24453e-06, gnorm=1.282, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=2025
2023-06-26 18:53:21 - progress_bar.py[line:272] - INFO: epoch 001:    990 / 3715 loss=2.969, loss_v1=0, loss_v2=0, nll_loss=1.893, ntokens=1091.2, nsentences=120, sample_size=1091.2, sample_size_v1=0, sample_size_v2=0, ppl=3.71, wps=530.2, ups=0.49, wpb=1091.2, bsz=120, num_updates=990, lr=8.32866e-06, gnorm=1.222, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=2046
2023-06-26 18:53:42 - progress_bar.py[line:272] - INFO: epoch 001:   1000 / 3715 loss=2.947, loss_v1=0, loss_v2=0, nll_loss=1.861, ntokens=1077.8, nsentences=120, sample_size=1077.8, sample_size_v1=0, sample_size_v2=0, ppl=3.63, wps=524.3, ups=0.49, wpb=1077.8, bsz=120, num_updates=1000, lr=8.41279e-06, gnorm=1.18, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=2066
2023-06-26 18:54:03 - progress_bar.py[line:272] - INFO: epoch 001:   1010 / 3715 loss=2.936, loss_v1=0, loss_v2=0, nll_loss=1.852, ntokens=1078.2, nsentences=120, sample_size=1078.2, sample_size_v1=0, sample_size_v2=0, ppl=3.61, wps=524.8, ups=0.49, wpb=1078.2, bsz=120, num_updates=1010, lr=8.49692e-06, gnorm=1.246, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=2087
2023-06-26 18:54:23 - progress_bar.py[line:272] - INFO: epoch 001:   1020 / 3715 loss=2.939, loss_v1=0, loss_v2=0, nll_loss=1.852, ntokens=1080.3, nsentences=120, sample_size=1080.3, sample_size_v1=0, sample_size_v2=0, ppl=3.61, wps=526.1, ups=0.49, wpb=1080.3, bsz=120, num_updates=1020, lr=8.58104e-06, gnorm=1.275, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=2107
2023-06-26 18:54:44 - progress_bar.py[line:272] - INFO: epoch 001:   1030 / 3715 loss=2.913, loss_v1=0, loss_v2=0, nll_loss=1.822, ntokens=1074.2, nsentences=120, sample_size=1074.2, sample_size_v1=0, sample_size_v2=0, ppl=3.54, wps=523.1, ups=0.49, wpb=1074.2, bsz=120, num_updates=1030, lr=8.66517e-06, gnorm=1.28, clip=100, loss_scale=512, train_wall=21, gb_free=8.9, wall=2128
2023-06-26 18:55:04 - progress_bar.py[line:272] - INFO: epoch 001:   1040 / 3715 loss=2.914, loss_v1=0, loss_v2=0, nll_loss=1.819, ntokens=1071.1, nsentences=120, sample_size=1071.1, sample_size_v1=0, sample_size_v2=0, ppl=3.53, wps=520.9, ups=0.49, wpb=1071.1, bsz=120, num_updates=1040, lr=8.7493e-06, gnorm=1.191, clip=100, loss_scale=512, train_wall=21, gb_free=8.9, wall=2149
2023-06-26 18:55:25 - progress_bar.py[line:272] - INFO: epoch 001:   1050 / 3715 loss=2.928, loss_v1=0, loss_v2=0, nll_loss=1.837, ntokens=1078.4, nsentences=120, sample_size=1078.4, sample_size_v1=0, sample_size_v2=0, ppl=3.57, wps=525, ups=0.49, wpb=1078.4, bsz=120, num_updates=1050, lr=8.83343e-06, gnorm=1.259, clip=100, loss_scale=512, train_wall=21, gb_free=8.9, wall=2169
2023-06-26 18:55:45 - progress_bar.py[line:272] - INFO: epoch 001:   1060 / 3715 loss=2.898, loss_v1=0, loss_v2=0, nll_loss=1.805, ntokens=1081.6, nsentences=120, sample_size=1081.6, sample_size_v1=0, sample_size_v2=0, ppl=3.49, wps=526.5, ups=0.49, wpb=1081.6, bsz=120, num_updates=1060, lr=8.91755e-06, gnorm=1.15, clip=90, loss_scale=512, train_wall=21, gb_free=8.9, wall=2190
2023-06-26 18:56:06 - progress_bar.py[line:272] - INFO: epoch 001:   1070 / 3715 loss=2.886, loss_v1=0, loss_v2=0, nll_loss=1.785, ntokens=1084.1, nsentences=120, sample_size=1084.1, sample_size_v1=0, sample_size_v2=0, ppl=3.45, wps=527.4, ups=0.49, wpb=1084.1, bsz=120, num_updates=1070, lr=9.00168e-06, gnorm=1.174, clip=100, loss_scale=512, train_wall=21, gb_free=8.9, wall=2210
2023-06-26 18:56:26 - progress_bar.py[line:272] - INFO: epoch 001:   1080 / 3715 loss=2.869, loss_v1=0, loss_v2=0, nll_loss=1.77, ntokens=1100.4, nsentences=120, sample_size=1100.4, sample_size_v1=0, sample_size_v2=0, ppl=3.41, wps=535.7, ups=0.49, wpb=1100.4, bsz=120, num_updates=1080, lr=9.08581e-06, gnorm=1.223, clip=100, loss_scale=512, train_wall=21, gb_free=8.9, wall=2231
2023-06-26 18:56:47 - progress_bar.py[line:272] - INFO: epoch 001:   1090 / 3715 loss=2.853, loss_v1=0, loss_v2=0, nll_loss=1.747, ntokens=1077.2, nsentences=120, sample_size=1077.2, sample_size_v1=0, sample_size_v2=0, ppl=3.36, wps=524.6, ups=0.49, wpb=1077.2, bsz=120, num_updates=1090, lr=9.16994e-06, gnorm=1.318, clip=100, loss_scale=512, train_wall=21, gb_free=8.9, wall=2251
2023-06-26 18:57:07 - progress_bar.py[line:272] - INFO: epoch 001:   1100 / 3715 loss=2.863, loss_v1=0, loss_v2=0, nll_loss=1.759, ntokens=1051.3, nsentences=120, sample_size=1051.3, sample_size_v1=0, sample_size_v2=0, ppl=3.38, wps=512.2, ups=0.49, wpb=1051.3, bsz=120, num_updates=1100, lr=9.25407e-06, gnorm=1.35, clip=100, loss_scale=512, train_wall=20, gb_free=8.9, wall=2272
2023-06-26 18:57:28 - progress_bar.py[line:272] - INFO: epoch 001:   1110 / 3715 loss=2.849, loss_v1=0, loss_v2=0, nll_loss=1.744, ntokens=1069, nsentences=120, sample_size=1069, sample_size_v1=0, sample_size_v2=0, ppl=3.35, wps=520.4, ups=0.49, wpb=1069, bsz=120, num_updates=1110, lr=9.33819e-06, gnorm=1.281, clip=100, loss_scale=512, train_wall=21, gb_free=8.9, wall=2292
2023-06-26 18:57:49 - progress_bar.py[line:272] - INFO: epoch 001:   1120 / 3715 loss=2.868, loss_v1=0, loss_v2=0, nll_loss=1.761, ntokens=1105.4, nsentences=120, sample_size=1105.4, sample_size_v1=0, sample_size_v2=0, ppl=3.39, wps=537.6, ups=0.49, wpb=1105.4, bsz=120, num_updates=1120, lr=9.42232e-06, gnorm=1.304, clip=100, loss_scale=512, train_wall=21, gb_free=8.9, wall=2313
2023-06-26 18:58:09 - progress_bar.py[line:272] - INFO: epoch 001:   1130 / 3715 loss=2.852, loss_v1=0, loss_v2=0, nll_loss=1.742, ntokens=1072.5, nsentences=120, sample_size=1072.5, sample_size_v1=0, sample_size_v2=0, ppl=3.35, wps=521.5, ups=0.49, wpb=1072.5, bsz=120, num_updates=1130, lr=9.50645e-06, gnorm=1.317, clip=100, loss_scale=512, train_wall=21, gb_free=8.9, wall=2333
2023-06-26 18:58:30 - progress_bar.py[line:272] - INFO: epoch 001:   1140 / 3715 loss=2.852, loss_v1=0, loss_v2=0, nll_loss=1.746, ntokens=1114.8, nsentences=120, sample_size=1114.8, sample_size_v1=0, sample_size_v2=0, ppl=3.35, wps=542.8, ups=0.49, wpb=1114.8, bsz=120, num_updates=1140, lr=9.59058e-06, gnorm=1.373, clip=100, loss_scale=512, train_wall=21, gb_free=8.9, wall=2354
2023-06-26 18:58:50 - progress_bar.py[line:272] - INFO: epoch 001:   1150 / 3715 loss=2.834, loss_v1=0, loss_v2=0, nll_loss=1.72, ntokens=1080.1, nsentences=120, sample_size=1080.1, sample_size_v1=0, sample_size_v2=0, ppl=3.29, wps=525.2, ups=0.49, wpb=1080.1, bsz=120, num_updates=1150, lr=9.67471e-06, gnorm=1.379, clip=100, loss_scale=512, train_wall=21, gb_free=8.9, wall=2375
2023-06-26 18:59:11 - progress_bar.py[line:272] - INFO: epoch 001:   1160 / 3715 loss=2.82, loss_v1=0, loss_v2=0, nll_loss=1.706, ntokens=1082.3, nsentences=120, sample_size=1082.3, sample_size_v1=0, sample_size_v2=0, ppl=3.26, wps=527, ups=0.49, wpb=1082.3, bsz=120, num_updates=1160, lr=9.75883e-06, gnorm=1.316, clip=100, loss_scale=512, train_wall=21, gb_free=8.9, wall=2395
2023-06-26 18:59:31 - progress_bar.py[line:272] - INFO: epoch 001:   1170 / 3715 loss=2.81, loss_v1=0, loss_v2=0, nll_loss=1.695, ntokens=1083.9, nsentences=120, sample_size=1083.9, sample_size_v1=0, sample_size_v2=0, ppl=3.24, wps=527.5, ups=0.49, wpb=1083.9, bsz=120, num_updates=1170, lr=9.84296e-06, gnorm=1.395, clip=100, loss_scale=512, train_wall=21, gb_free=8.9, wall=2416
2023-06-26 18:59:52 - progress_bar.py[line:272] - INFO: epoch 001:   1180 / 3715 loss=2.832, loss_v1=0, loss_v2=0, nll_loss=1.718, ntokens=1093.2, nsentences=120, sample_size=1093.2, sample_size_v1=0, sample_size_v2=0, ppl=3.29, wps=532.3, ups=0.49, wpb=1093.2, bsz=120, num_updates=1180, lr=9.92709e-06, gnorm=1.367, clip=100, loss_scale=512, train_wall=21, gb_free=8.9, wall=2436
2023-06-26 19:00:13 - progress_bar.py[line:272] - INFO: epoch 001:   1190 / 3715 loss=2.811, loss_v1=0, loss_v2=0, nll_loss=1.692, ntokens=1085.8, nsentences=120, sample_size=1085.8, sample_size_v1=0, sample_size_v2=0, ppl=3.23, wps=523, ups=0.48, wpb=1085.8, bsz=120, num_updates=1190, lr=1.00112e-05, gnorm=1.373, clip=100, loss_scale=512, train_wall=21, gb_free=8.9, wall=2457
2023-06-26 19:00:33 - progress_bar.py[line:272] - INFO: epoch 001:   1200 / 3715 loss=2.807, loss_v1=0, loss_v2=0, nll_loss=1.691, ntokens=1092.3, nsentences=120, sample_size=1092.3, sample_size_v1=0, sample_size_v2=0, ppl=3.23, wps=531.4, ups=0.49, wpb=1092.3, bsz=120, num_updates=1200, lr=1.00953e-05, gnorm=1.301, clip=100, loss_scale=512, train_wall=21, gb_free=8.9, wall=2478
2023-06-26 19:00:54 - progress_bar.py[line:272] - INFO: epoch 001:   1210 / 3715 loss=2.786, loss_v1=0, loss_v2=0, nll_loss=1.662, ntokens=1070.4, nsentences=120, sample_size=1070.4, sample_size_v1=0, sample_size_v2=0, ppl=3.16, wps=521, ups=0.49, wpb=1070.4, bsz=120, num_updates=1210, lr=1.01795e-05, gnorm=1.259, clip=100, loss_scale=512, train_wall=21, gb_free=8.9, wall=2498
2023-06-26 19:01:14 - progress_bar.py[line:272] - INFO: epoch 001:   1220 / 3715 loss=2.817, loss_v1=0, loss_v2=0, nll_loss=1.7, ntokens=1091, nsentences=120, sample_size=1091, sample_size_v1=0, sample_size_v2=0, ppl=3.25, wps=530.9, ups=0.49, wpb=1091, bsz=120, num_updates=1220, lr=1.02636e-05, gnorm=1.459, clip=100, loss_scale=512, train_wall=21, gb_free=8.9, wall=2519
2023-06-26 19:01:35 - progress_bar.py[line:272] - INFO: epoch 001:   1230 / 3715 loss=2.809, loss_v1=0, loss_v2=0, nll_loss=1.687, ntokens=1084.9, nsentences=120, sample_size=1084.9, sample_size_v1=0, sample_size_v2=0, ppl=3.22, wps=528.1, ups=0.49, wpb=1084.9, bsz=120, num_updates=1230, lr=1.03477e-05, gnorm=1.396, clip=100, loss_scale=512, train_wall=21, gb_free=8.9, wall=2539
2023-06-26 19:01:55 - progress_bar.py[line:272] - INFO: epoch 001:   1240 / 3715 loss=2.768, loss_v1=0, loss_v2=0, nll_loss=1.645, ntokens=1069, nsentences=120, sample_size=1069, sample_size_v1=0, sample_size_v2=0, ppl=3.13, wps=520.1, ups=0.49, wpb=1069, bsz=120, num_updates=1240, lr=1.04319e-05, gnorm=1.38, clip=100, loss_scale=512, train_wall=21, gb_free=8.9, wall=2560
2023-06-26 19:02:16 - progress_bar.py[line:272] - INFO: epoch 001:   1250 / 3715 loss=2.761, loss_v1=0, loss_v2=0, nll_loss=1.635, ntokens=1081.2, nsentences=120, sample_size=1081.2, sample_size_v1=0, sample_size_v2=0, ppl=3.11, wps=526.2, ups=0.49, wpb=1081.2, bsz=120, num_updates=1250, lr=1.0516e-05, gnorm=1.377, clip=100, loss_scale=512, train_wall=21, gb_free=8.9, wall=2580
2023-06-26 19:02:36 - progress_bar.py[line:272] - INFO: epoch 001:   1260 / 3715 loss=2.766, loss_v1=0, loss_v2=0, nll_loss=1.636, ntokens=1069.9, nsentences=120, sample_size=1069.9, sample_size_v1=0, sample_size_v2=0, ppl=3.11, wps=521.1, ups=0.49, wpb=1069.9, bsz=120, num_updates=1260, lr=1.06001e-05, gnorm=1.397, clip=100, loss_scale=512, train_wall=21, gb_free=8.9, wall=2601
2023-06-26 19:02:57 - progress_bar.py[line:272] - INFO: epoch 001:   1270 / 3715 loss=2.783, loss_v1=0, loss_v2=0, nll_loss=1.66, ntokens=1085.2, nsentences=120, sample_size=1085.2, sample_size_v1=0, sample_size_v2=0, ppl=3.16, wps=528.4, ups=0.49, wpb=1085.2, bsz=120, num_updates=1270, lr=1.06842e-05, gnorm=1.44, clip=100, loss_scale=512, train_wall=21, gb_free=8.9, wall=2621
2023-06-26 19:03:18 - progress_bar.py[line:272] - INFO: epoch 001:   1280 / 3715 loss=2.762, loss_v1=0, loss_v2=0, nll_loss=1.632, ntokens=1074.7, nsentences=120, sample_size=1074.7, sample_size_v1=0, sample_size_v2=0, ppl=3.1, wps=523.2, ups=0.49, wpb=1074.7, bsz=120, num_updates=1280, lr=1.07684e-05, gnorm=1.463, clip=100, loss_scale=512, train_wall=21, gb_free=8.9, wall=2642
2023-06-26 19:03:38 - progress_bar.py[line:272] - INFO: epoch 001:   1290 / 3715 loss=2.758, loss_v1=0, loss_v2=0, nll_loss=1.626, ntokens=1099.7, nsentences=120, sample_size=1099.7, sample_size_v1=0, sample_size_v2=0, ppl=3.09, wps=530.1, ups=0.48, wpb=1099.7, bsz=120, num_updates=1290, lr=1.08525e-05, gnorm=1.393, clip=100, loss_scale=512, train_wall=21, gb_free=8.9, wall=2663
2023-06-26 19:03:59 - progress_bar.py[line:272] - INFO: epoch 001:   1300 / 3715 loss=2.749, loss_v1=0, loss_v2=0, nll_loss=1.62, ntokens=1068.4, nsentences=120, sample_size=1068.4, sample_size_v1=0, sample_size_v2=0, ppl=3.07, wps=519.9, ups=0.49, wpb=1068.4, bsz=120, num_updates=1300, lr=1.09366e-05, gnorm=1.374, clip=100, loss_scale=512, train_wall=21, gb_free=8.9, wall=2683
2023-06-26 19:04:19 - progress_bar.py[line:272] - INFO: epoch 001:   1310 / 3715 loss=2.741, loss_v1=0, loss_v2=0, nll_loss=1.608, ntokens=1079.6, nsentences=120, sample_size=1079.6, sample_size_v1=0, sample_size_v2=0, ppl=3.05, wps=525.2, ups=0.49, wpb=1079.6, bsz=120, num_updates=1310, lr=1.10208e-05, gnorm=1.397, clip=100, loss_scale=512, train_wall=21, gb_free=8.9, wall=2704
2023-06-26 19:04:40 - progress_bar.py[line:272] - INFO: epoch 001:   1320 / 3715 loss=2.735, loss_v1=0, loss_v2=0, nll_loss=1.603, ntokens=1093.5, nsentences=120, sample_size=1093.5, sample_size_v1=0, sample_size_v2=0, ppl=3.04, wps=532, ups=0.49, wpb=1093.5, bsz=120, num_updates=1320, lr=1.11049e-05, gnorm=1.345, clip=100, loss_scale=512, train_wall=21, gb_free=8.9, wall=2724
2023-06-26 19:05:01 - progress_bar.py[line:272] - INFO: epoch 001:   1330 / 3715 loss=2.742, loss_v1=0, loss_v2=0, nll_loss=1.609, ntokens=1063.6, nsentences=120, sample_size=1063.6, sample_size_v1=0, sample_size_v2=0, ppl=3.05, wps=516.8, ups=0.49, wpb=1063.6, bsz=120, num_updates=1330, lr=1.1189e-05, gnorm=1.361, clip=100, loss_scale=512, train_wall=21, gb_free=8.9, wall=2745
2023-06-26 19:05:21 - progress_bar.py[line:272] - INFO: epoch 001:   1340 / 3715 loss=2.74, loss_v1=0, loss_v2=0, nll_loss=1.606, ntokens=1083.9, nsentences=120, sample_size=1083.9, sample_size_v1=0, sample_size_v2=0, ppl=3.05, wps=526.6, ups=0.49, wpb=1083.9, bsz=120, num_updates=1340, lr=1.12731e-05, gnorm=1.466, clip=100, loss_scale=512, train_wall=21, gb_free=8.9, wall=2766
2023-06-26 19:05:42 - progress_bar.py[line:272] - INFO: epoch 001:   1350 / 3715 loss=2.724, loss_v1=0, loss_v2=0, nll_loss=1.589, ntokens=1096.2, nsentences=120, sample_size=1096.2, sample_size_v1=0, sample_size_v2=0, ppl=3.01, wps=532, ups=0.49, wpb=1096.2, bsz=120, num_updates=1350, lr=1.13573e-05, gnorm=1.409, clip=100, loss_scale=512, train_wall=21, gb_free=8.9, wall=2786
2023-06-26 19:06:02 - progress_bar.py[line:272] - INFO: epoch 001:   1360 / 3715 loss=2.728, loss_v1=0, loss_v2=0, nll_loss=1.592, ntokens=1098.8, nsentences=120, sample_size=1098.8, sample_size_v1=0, sample_size_v2=0, ppl=3.01, wps=534.2, ups=0.49, wpb=1098.8, bsz=120, num_updates=1360, lr=1.14414e-05, gnorm=1.517, clip=100, loss_scale=512, train_wall=21, gb_free=8.9, wall=2807
2023-06-26 19:06:23 - progress_bar.py[line:272] - INFO: epoch 001:   1370 / 3715 loss=2.724, loss_v1=0, loss_v2=0, nll_loss=1.589, ntokens=1055.2, nsentences=120, sample_size=1055.2, sample_size_v1=0, sample_size_v2=0, ppl=3.01, wps=513.2, ups=0.49, wpb=1055.2, bsz=120, num_updates=1370, lr=1.15255e-05, gnorm=1.49, clip=100, loss_scale=512, train_wall=21, gb_free=8.9, wall=2827
2023-06-26 19:06:43 - progress_bar.py[line:272] - INFO: epoch 001:   1380 / 3715 loss=2.722, loss_v1=0, loss_v2=0, nll_loss=1.583, ntokens=1074.7, nsentences=120, sample_size=1074.7, sample_size_v1=0, sample_size_v2=0, ppl=3, wps=522.5, ups=0.49, wpb=1074.7, bsz=120, num_updates=1380, lr=1.16096e-05, gnorm=1.334, clip=100, loss_scale=512, train_wall=21, gb_free=8.9, wall=2848
2023-06-26 19:07:04 - progress_bar.py[line:272] - INFO: epoch 001:   1390 / 3715 loss=2.735, loss_v1=0, loss_v2=0, nll_loss=1.599, ntokens=1086.7, nsentences=120, sample_size=1086.7, sample_size_v1=0, sample_size_v2=0, ppl=3.03, wps=528.1, ups=0.49, wpb=1086.7, bsz=120, num_updates=1390, lr=1.16938e-05, gnorm=1.391, clip=100, loss_scale=512, train_wall=21, gb_free=8.9, wall=2868
2023-06-26 19:07:25 - progress_bar.py[line:272] - INFO: epoch 001:   1400 / 3715 loss=2.705, loss_v1=0, loss_v2=0, nll_loss=1.566, ntokens=1071.2, nsentences=120, sample_size=1071.2, sample_size_v1=0, sample_size_v2=0, ppl=2.96, wps=519.8, ups=0.49, wpb=1071.2, bsz=120, num_updates=1400, lr=1.17779e-05, gnorm=1.401, clip=100, loss_scale=512, train_wall=21, gb_free=8.9, wall=2889
2023-06-26 19:07:45 - progress_bar.py[line:272] - INFO: epoch 001:   1410 / 3715 loss=2.702, loss_v1=0, loss_v2=0, nll_loss=1.562, ntokens=1100.8, nsentences=120, sample_size=1100.8, sample_size_v1=0, sample_size_v2=0, ppl=2.95, wps=534.6, ups=0.49, wpb=1100.8, bsz=120, num_updates=1410, lr=1.1862e-05, gnorm=1.402, clip=100, loss_scale=512, train_wall=21, gb_free=8.9, wall=2910
2023-06-26 19:08:06 - progress_bar.py[line:272] - INFO: epoch 001:   1420 / 3715 loss=2.715, loss_v1=0, loss_v2=0, nll_loss=1.575, ntokens=1085.7, nsentences=120, sample_size=1085.7, sample_size_v1=0, sample_size_v2=0, ppl=2.98, wps=527.8, ups=0.49, wpb=1085.7, bsz=120, num_updates=1420, lr=1.19462e-05, gnorm=1.514, clip=100, loss_scale=512, train_wall=21, gb_free=8.9, wall=2930
2023-06-26 19:08:26 - progress_bar.py[line:272] - INFO: epoch 001:   1430 / 3715 loss=2.692, loss_v1=0, loss_v2=0, nll_loss=1.55, ntokens=1085.2, nsentences=120, sample_size=1085.2, sample_size_v1=0, sample_size_v2=0, ppl=2.93, wps=527.7, ups=0.49, wpb=1085.2, bsz=120, num_updates=1430, lr=1.20303e-05, gnorm=1.57, clip=100, loss_scale=512, train_wall=21, gb_free=8.9, wall=2951
2023-06-26 19:08:47 - progress_bar.py[line:272] - INFO: epoch 001:   1440 / 3715 loss=2.686, loss_v1=0, loss_v2=0, nll_loss=1.542, ntokens=1081.8, nsentences=120, sample_size=1081.8, sample_size_v1=0, sample_size_v2=0, ppl=2.91, wps=524.9, ups=0.49, wpb=1081.8, bsz=120, num_updates=1440, lr=1.21144e-05, gnorm=1.48, clip=100, loss_scale=512, train_wall=21, gb_free=8.9, wall=2971
2023-06-26 19:09:08 - progress_bar.py[line:272] - INFO: epoch 001:   1450 / 3715 loss=2.685, loss_v1=0, loss_v2=0, nll_loss=1.54, ntokens=1076.8, nsentences=120, sample_size=1076.8, sample_size_v1=0, sample_size_v2=0, ppl=2.91, wps=523.2, ups=0.49, wpb=1076.8, bsz=120, num_updates=1450, lr=1.21985e-05, gnorm=1.439, clip=100, loss_scale=512, train_wall=21, gb_free=8.9, wall=2992
2023-06-26 19:09:28 - progress_bar.py[line:272] - INFO: epoch 001:   1460 / 3715 loss=2.692, loss_v1=0, loss_v2=0, nll_loss=1.548, ntokens=1091.1, nsentences=120, sample_size=1091.1, sample_size_v1=0, sample_size_v2=0, ppl=2.92, wps=530.1, ups=0.49, wpb=1091.1, bsz=120, num_updates=1460, lr=1.22827e-05, gnorm=1.472, clip=100, loss_scale=512, train_wall=21, gb_free=8.9, wall=3013
2023-06-26 19:09:49 - progress_bar.py[line:272] - INFO: epoch 001:   1470 / 3715 loss=2.698, loss_v1=0, loss_v2=0, nll_loss=1.555, ntokens=1085.4, nsentences=120, sample_size=1085.4, sample_size_v1=0, sample_size_v2=0, ppl=2.94, wps=527.4, ups=0.49, wpb=1085.4, bsz=120, num_updates=1470, lr=1.23668e-05, gnorm=1.503, clip=100, loss_scale=512, train_wall=21, gb_free=8.9, wall=3033
2023-06-26 19:10:09 - progress_bar.py[line:272] - INFO: epoch 001:   1480 / 3715 loss=2.706, loss_v1=0, loss_v2=0, nll_loss=1.564, ntokens=1055.8, nsentences=118.5, sample_size=1055.8, sample_size_v1=0, sample_size_v2=0, ppl=2.96, wps=518.6, ups=0.49, wpb=1055.8, bsz=118.5, num_updates=1480, lr=1.24509e-05, gnorm=1.534, clip=100, loss_scale=512, train_wall=20, gb_free=8.9, wall=3053
2023-06-26 19:10:30 - progress_bar.py[line:272] - INFO: epoch 001:   1490 / 3715 loss=2.665, loss_v1=0, loss_v2=0, nll_loss=1.517, ntokens=1078.7, nsentences=120, sample_size=1078.7, sample_size_v1=0, sample_size_v2=0, ppl=2.86, wps=524, ups=0.49, wpb=1078.7, bsz=120, num_updates=1490, lr=1.25351e-05, gnorm=1.455, clip=100, loss_scale=512, train_wall=21, gb_free=8.9, wall=3074
2023-06-26 19:10:50 - progress_bar.py[line:272] - INFO: epoch 001:   1500 / 3715 loss=2.676, loss_v1=0, loss_v2=0, nll_loss=1.528, ntokens=1095.4, nsentences=120, sample_size=1095.4, sample_size_v1=0, sample_size_v2=0, ppl=2.88, wps=531.1, ups=0.48, wpb=1095.4, bsz=120, num_updates=1500, lr=1.26192e-05, gnorm=1.574, clip=100, loss_scale=512, train_wall=21, gb_free=8.9, wall=3095
2023-06-26 19:11:11 - progress_bar.py[line:272] - INFO: epoch 001:   1510 / 3715 loss=2.662, loss_v1=0, loss_v2=0, nll_loss=1.514, ntokens=1099.1, nsentences=120, sample_size=1099.1, sample_size_v1=0, sample_size_v2=0, ppl=2.86, wps=533.5, ups=0.49, wpb=1099.1, bsz=120, num_updates=1510, lr=1.27033e-05, gnorm=1.512, clip=100, loss_scale=512, train_wall=21, gb_free=8.9, wall=3115
2023-06-26 19:11:32 - progress_bar.py[line:272] - INFO: epoch 001:   1520 / 3715 loss=2.693, loss_v1=0, loss_v2=0, nll_loss=1.548, ntokens=1090.6, nsentences=120, sample_size=1090.6, sample_size_v1=0, sample_size_v2=0, ppl=2.92, wps=529, ups=0.49, wpb=1090.6, bsz=120, num_updates=1520, lr=1.27874e-05, gnorm=1.527, clip=100, loss_scale=512, train_wall=21, gb_free=8.9, wall=3136
2023-06-26 19:11:52 - progress_bar.py[line:272] - INFO: epoch 001:   1530 / 3715 loss=2.668, loss_v1=0, loss_v2=0, nll_loss=1.52, ntokens=1069.4, nsentences=120, sample_size=1069.4, sample_size_v1=0, sample_size_v2=0, ppl=2.87, wps=519.6, ups=0.49, wpb=1069.4, bsz=120, num_updates=1530, lr=1.28716e-05, gnorm=1.498, clip=100, loss_scale=512, train_wall=21, gb_free=8.9, wall=3157
2023-06-26 19:12:13 - progress_bar.py[line:272] - INFO: epoch 001:   1540 / 3715 loss=2.664, loss_v1=0, loss_v2=0, nll_loss=1.515, ntokens=1088.4, nsentences=120, sample_size=1088.4, sample_size_v1=0, sample_size_v2=0, ppl=2.86, wps=528.9, ups=0.49, wpb=1088.4, bsz=120, num_updates=1540, lr=1.29557e-05, gnorm=1.605, clip=100, loss_scale=1024, train_wall=21, gb_free=8.9, wall=3177
2023-06-26 19:12:15 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 512.0
2023-06-26 19:12:35 - progress_bar.py[line:272] - INFO: epoch 001:   1551 / 3715 loss=2.656, loss_v1=0, loss_v2=0, nll_loss=1.506, ntokens=1086.8, nsentences=120, sample_size=1086.8, sample_size_v1=0, sample_size_v2=0, ppl=2.84, wps=480.4, ups=0.44, wpb=1086.8, bsz=120, num_updates=1550, lr=1.30398e-05, gnorm=1.67, clip=100, loss_scale=512, train_wall=23, gb_free=8.9, wall=3200
2023-06-26 19:12:56 - progress_bar.py[line:272] - INFO: epoch 001:   1561 / 3715 loss=2.661, loss_v1=0, loss_v2=0, nll_loss=1.51, ntokens=1080.3, nsentences=120, sample_size=1080.3, sample_size_v1=0, sample_size_v2=0, ppl=2.85, wps=525.1, ups=0.49, wpb=1080.3, bsz=120, num_updates=1560, lr=1.31239e-05, gnorm=1.547, clip=100, loss_scale=512, train_wall=21, gb_free=8.9, wall=3220
2023-06-26 19:13:17 - progress_bar.py[line:272] - INFO: epoch 001:   1571 / 3715 loss=2.668, loss_v1=0, loss_v2=0, nll_loss=1.519, ntokens=1089.6, nsentences=120, sample_size=1089.6, sample_size_v1=0, sample_size_v2=0, ppl=2.87, wps=529.5, ups=0.49, wpb=1089.6, bsz=120, num_updates=1570, lr=1.32081e-05, gnorm=1.657, clip=100, loss_scale=512, train_wall=21, gb_free=8.9, wall=3241
2023-06-26 19:13:37 - progress_bar.py[line:272] - INFO: epoch 001:   1581 / 3715 loss=2.683, loss_v1=0, loss_v2=0, nll_loss=1.534, ntokens=1082.8, nsentences=120, sample_size=1082.8, sample_size_v1=0, sample_size_v2=0, ppl=2.9, wps=526.9, ups=0.49, wpb=1082.8, bsz=120, num_updates=1580, lr=1.32922e-05, gnorm=1.556, clip=100, loss_scale=512, train_wall=21, gb_free=8.9, wall=3261
2023-06-26 19:13:58 - progress_bar.py[line:272] - INFO: epoch 001:   1591 / 3715 loss=2.666, loss_v1=0, loss_v2=0, nll_loss=1.515, ntokens=1062.3, nsentences=120, sample_size=1062.3, sample_size_v1=0, sample_size_v2=0, ppl=2.86, wps=517.2, ups=0.49, wpb=1062.3, bsz=120, num_updates=1590, lr=1.33763e-05, gnorm=1.709, clip=100, loss_scale=512, train_wall=21, gb_free=8.9, wall=3282
2023-06-26 19:14:18 - progress_bar.py[line:272] - INFO: epoch 001:   1601 / 3715 loss=2.664, loss_v1=0, loss_v2=0, nll_loss=1.514, ntokens=1076.5, nsentences=120, sample_size=1076.5, sample_size_v1=0, sample_size_v2=0, ppl=2.86, wps=523.3, ups=0.49, wpb=1076.5, bsz=120, num_updates=1600, lr=1.34605e-05, gnorm=1.957, clip=100, loss_scale=512, train_wall=21, gb_free=8.9, wall=3303
2023-06-26 19:14:39 - progress_bar.py[line:272] - INFO: epoch 001:   1611 / 3715 loss=2.668, loss_v1=0, loss_v2=0, nll_loss=1.517, ntokens=1085.6, nsentences=120, sample_size=1085.6, sample_size_v1=0, sample_size_v2=0, ppl=2.86, wps=528.3, ups=0.49, wpb=1085.6, bsz=120, num_updates=1610, lr=1.35446e-05, gnorm=1.761, clip=100, loss_scale=512, train_wall=21, gb_free=8.9, wall=3323
2023-06-26 19:14:59 - progress_bar.py[line:272] - INFO: epoch 001:   1621 / 3715 loss=2.647, loss_v1=0, loss_v2=0, nll_loss=1.494, ntokens=1079.9, nsentences=120, sample_size=1079.9, sample_size_v1=0, sample_size_v2=0, ppl=2.82, wps=523.9, ups=0.49, wpb=1079.9, bsz=120, num_updates=1620, lr=1.36287e-05, gnorm=1.723, clip=100, loss_scale=512, train_wall=21, gb_free=8.9, wall=3344
2023-06-26 19:15:20 - progress_bar.py[line:272] - INFO: epoch 001:   1631 / 3715 loss=2.648, loss_v1=0, loss_v2=0, nll_loss=1.496, ntokens=1102.2, nsentences=120, sample_size=1102.2, sample_size_v1=0, sample_size_v2=0, ppl=2.82, wps=535.5, ups=0.49, wpb=1102.2, bsz=120, num_updates=1630, lr=1.37128e-05, gnorm=1.749, clip=100, loss_scale=512, train_wall=21, gb_free=8.9, wall=3364
2023-06-26 19:15:41 - progress_bar.py[line:272] - INFO: epoch 001:   1641 / 3715 loss=2.647, loss_v1=0, loss_v2=0, nll_loss=1.496, ntokens=1075.5, nsentences=120, sample_size=1075.5, sample_size_v1=0, sample_size_v2=0, ppl=2.82, wps=522.8, ups=0.49, wpb=1075.5, bsz=120, num_updates=1640, lr=1.3797e-05, gnorm=1.709, clip=100, loss_scale=512, train_wall=21, gb_free=8.9, wall=3385
2023-06-26 19:16:01 - progress_bar.py[line:272] - INFO: epoch 001:   1651 / 3715 loss=2.653, loss_v1=0, loss_v2=0, nll_loss=1.5, ntokens=1078.9, nsentences=120, sample_size=1078.9, sample_size_v1=0, sample_size_v2=0, ppl=2.83, wps=524.1, ups=0.49, wpb=1078.9, bsz=120, num_updates=1650, lr=1.38811e-05, gnorm=1.739, clip=100, loss_scale=512, train_wall=21, gb_free=8.9, wall=3405
2023-06-26 19:16:22 - progress_bar.py[line:272] - INFO: epoch 001:   1661 / 3715 loss=2.649, loss_v1=0, loss_v2=0, nll_loss=1.494, ntokens=1063.9, nsentences=120, sample_size=1063.9, sample_size_v1=0, sample_size_v2=0, ppl=2.82, wps=517.1, ups=0.49, wpb=1063.9, bsz=120, num_updates=1660, lr=1.39652e-05, gnorm=1.728, clip=100, loss_scale=512, train_wall=21, gb_free=8.9, wall=3426
2023-06-26 19:16:42 - progress_bar.py[line:272] - INFO: epoch 001:   1671 / 3715 loss=2.632, loss_v1=0, loss_v2=0, nll_loss=1.478, ntokens=1073.6, nsentences=120, sample_size=1073.6, sample_size_v1=0, sample_size_v2=0, ppl=2.78, wps=522, ups=0.49, wpb=1073.6, bsz=120, num_updates=1670, lr=1.40494e-05, gnorm=1.658, clip=100, loss_scale=512, train_wall=21, gb_free=8.9, wall=3447
2023-06-26 19:17:03 - progress_bar.py[line:272] - INFO: epoch 001:   1681 / 3715 loss=2.65, loss_v1=0, loss_v2=0, nll_loss=1.495, ntokens=1069.6, nsentences=120, sample_size=1069.6, sample_size_v1=0, sample_size_v2=0, ppl=2.82, wps=519.5, ups=0.49, wpb=1069.6, bsz=120, num_updates=1680, lr=1.41335e-05, gnorm=1.685, clip=100, loss_scale=512, train_wall=21, gb_free=8.9, wall=3467
2023-06-26 19:17:23 - progress_bar.py[line:272] - INFO: epoch 001:   1691 / 3715 loss=2.644, loss_v1=0, loss_v2=0, nll_loss=1.489, ntokens=1083.6, nsentences=120, sample_size=1083.6, sample_size_v1=0, sample_size_v2=0, ppl=2.81, wps=526.8, ups=0.49, wpb=1083.6, bsz=120, num_updates=1690, lr=1.42176e-05, gnorm=1.73, clip=100, loss_scale=512, train_wall=21, gb_free=8.9, wall=3488
2023-06-26 19:17:44 - progress_bar.py[line:272] - INFO: epoch 001:   1701 / 3715 loss=2.641, loss_v1=0, loss_v2=0, nll_loss=1.487, ntokens=1071.5, nsentences=120, sample_size=1071.5, sample_size_v1=0, sample_size_v2=0, ppl=2.8, wps=521.2, ups=0.49, wpb=1071.5, bsz=120, num_updates=1700, lr=1.43017e-05, gnorm=1.75, clip=100, loss_scale=512, train_wall=21, gb_free=8.9, wall=3508
2023-06-26 19:18:05 - progress_bar.py[line:272] - INFO: epoch 001:   1711 / 3715 loss=2.632, loss_v1=0, loss_v2=0, nll_loss=1.476, ntokens=1077.4, nsentences=120, sample_size=1077.4, sample_size_v1=0, sample_size_v2=0, ppl=2.78, wps=522.8, ups=0.49, wpb=1077.4, bsz=120, num_updates=1710, lr=1.43859e-05, gnorm=1.645, clip=100, loss_scale=512, train_wall=21, gb_free=8.9, wall=3529
2023-06-26 19:18:25 - progress_bar.py[line:272] - INFO: epoch 001:   1721 / 3715 loss=2.626, loss_v1=0, loss_v2=0, nll_loss=1.47, ntokens=1099.8, nsentences=120, sample_size=1099.8, sample_size_v1=0, sample_size_v2=0, ppl=2.77, wps=535.4, ups=0.49, wpb=1099.8, bsz=120, num_updates=1720, lr=1.447e-05, gnorm=1.686, clip=100, loss_scale=512, train_wall=21, gb_free=8.9, wall=3550
2023-06-26 19:18:46 - progress_bar.py[line:272] - INFO: epoch 001:   1731 / 3715 loss=2.622, loss_v1=0, loss_v2=0, nll_loss=1.463, ntokens=1092.6, nsentences=120, sample_size=1092.6, sample_size_v1=0, sample_size_v2=0, ppl=2.76, wps=531.4, ups=0.49, wpb=1092.6, bsz=120, num_updates=1730, lr=1.45541e-05, gnorm=1.641, clip=100, loss_scale=512, train_wall=21, gb_free=8.9, wall=3570
2023-06-26 19:19:06 - progress_bar.py[line:272] - INFO: epoch 001:   1741 / 3715 loss=2.629, loss_v1=0, loss_v2=0, nll_loss=1.475, ntokens=1081.7, nsentences=120, sample_size=1081.7, sample_size_v1=0, sample_size_v2=0, ppl=2.78, wps=526.3, ups=0.49, wpb=1081.7, bsz=120, num_updates=1740, lr=1.46383e-05, gnorm=1.708, clip=100, loss_scale=512, train_wall=21, gb_free=8.9, wall=3591
2023-06-26 19:19:27 - progress_bar.py[line:272] - INFO: epoch 001:   1751 / 3715 loss=2.641, loss_v1=0, loss_v2=0, nll_loss=1.486, ntokens=1082.2, nsentences=120, sample_size=1082.2, sample_size_v1=0, sample_size_v2=0, ppl=2.8, wps=526.6, ups=0.49, wpb=1082.2, bsz=120, num_updates=1750, lr=1.47224e-05, gnorm=1.783, clip=100, loss_scale=512, train_wall=21, gb_free=8.9, wall=3611
2023-06-26 19:19:47 - progress_bar.py[line:272] - INFO: epoch 001:   1761 / 3715 loss=2.613, loss_v1=0, loss_v2=0, nll_loss=1.45, ntokens=1075.2, nsentences=120, sample_size=1075.2, sample_size_v1=0, sample_size_v2=0, ppl=2.73, wps=522.6, ups=0.49, wpb=1075.2, bsz=120, num_updates=1760, lr=1.48065e-05, gnorm=1.701, clip=100, loss_scale=512, train_wall=21, gb_free=8.9, wall=3632
2023-06-26 19:20:08 - progress_bar.py[line:272] - INFO: epoch 001:   1771 / 3715 loss=2.617, loss_v1=0, loss_v2=0, nll_loss=1.462, ntokens=1095.1, nsentences=120, sample_size=1095.1, sample_size_v1=0, sample_size_v2=0, ppl=2.75, wps=533.2, ups=0.49, wpb=1095.1, bsz=120, num_updates=1770, lr=1.48906e-05, gnorm=1.83, clip=100, loss_scale=512, train_wall=21, gb_free=8.9, wall=3652
2023-06-26 19:20:29 - progress_bar.py[line:272] - INFO: epoch 001:   1781 / 3715 loss=2.622, loss_v1=0, loss_v2=0, nll_loss=1.459, ntokens=1070.4, nsentences=120, sample_size=1070.4, sample_size_v1=0, sample_size_v2=0, ppl=2.75, wps=520.7, ups=0.49, wpb=1070.4, bsz=120, num_updates=1780, lr=1.49748e-05, gnorm=1.735, clip=100, loss_scale=512, train_wall=21, gb_free=8.9, wall=3673
2023-06-26 19:20:49 - progress_bar.py[line:272] - INFO: epoch 001:   1791 / 3715 loss=2.629, loss_v1=0, loss_v2=0, nll_loss=1.472, ntokens=1087.9, nsentences=120, sample_size=1087.9, sample_size_v1=0, sample_size_v2=0, ppl=2.77, wps=528.8, ups=0.49, wpb=1087.9, bsz=120, num_updates=1790, lr=1.50589e-05, gnorm=1.792, clip=100, loss_scale=512, train_wall=21, gb_free=8.9, wall=3693
2023-06-26 19:21:10 - progress_bar.py[line:272] - INFO: epoch 001:   1801 / 3715 loss=2.607, loss_v1=0, loss_v2=0, nll_loss=1.446, ntokens=1074.5, nsentences=120, sample_size=1074.5, sample_size_v1=0, sample_size_v2=0, ppl=2.72, wps=522.5, ups=0.49, wpb=1074.5, bsz=120, num_updates=1800, lr=1.5143e-05, gnorm=1.843, clip=100, loss_scale=512, train_wall=21, gb_free=8.9, wall=3714
2023-06-26 19:21:30 - progress_bar.py[line:272] - INFO: epoch 001:   1811 / 3715 loss=2.635, loss_v1=0, loss_v2=0, nll_loss=1.478, ntokens=1072.5, nsentences=120, sample_size=1072.5, sample_size_v1=0, sample_size_v2=0, ppl=2.78, wps=522.1, ups=0.49, wpb=1072.5, bsz=120, num_updates=1810, lr=1.52271e-05, gnorm=1.786, clip=100, loss_scale=512, train_wall=21, gb_free=8.9, wall=3735
2023-06-26 19:21:51 - progress_bar.py[line:272] - INFO: epoch 001:   1821 / 3715 loss=2.629, loss_v1=0, loss_v2=0, nll_loss=1.469, ntokens=1081.4, nsentences=120, sample_size=1081.4, sample_size_v1=0, sample_size_v2=0, ppl=2.77, wps=526.2, ups=0.49, wpb=1081.4, bsz=120, num_updates=1820, lr=1.53113e-05, gnorm=1.861, clip=100, loss_scale=512, train_wall=21, gb_free=8.9, wall=3755
2023-06-26 19:22:11 - progress_bar.py[line:272] - INFO: epoch 001:   1831 / 3715 loss=2.619, loss_v1=0, loss_v2=0, nll_loss=1.465, ntokens=1106.8, nsentences=120, sample_size=1106.8, sample_size_v1=0, sample_size_v2=0, ppl=2.76, wps=537.8, ups=0.49, wpb=1106.8, bsz=120, num_updates=1830, lr=1.53954e-05, gnorm=1.81, clip=100, loss_scale=512, train_wall=21, gb_free=8.9, wall=3776
2023-06-26 19:22:32 - progress_bar.py[line:272] - INFO: epoch 001:   1841 / 3715 loss=2.602, loss_v1=0, loss_v2=0, nll_loss=1.438, ntokens=1082.5, nsentences=120, sample_size=1082.5, sample_size_v1=0, sample_size_v2=0, ppl=2.71, wps=525.7, ups=0.49, wpb=1082.5, bsz=120, num_updates=1840, lr=1.54795e-05, gnorm=1.823, clip=100, loss_scale=512, train_wall=21, gb_free=8.9, wall=3796
2023-06-26 19:22:53 - progress_bar.py[line:272] - INFO: epoch 001:   1851 / 3715 loss=2.595, loss_v1=0, loss_v2=0, nll_loss=1.432, ntokens=1068.7, nsentences=120, sample_size=1068.7, sample_size_v1=0, sample_size_v2=0, ppl=2.7, wps=518.7, ups=0.49, wpb=1068.7, bsz=120, num_updates=1850, lr=1.55637e-05, gnorm=2.031, clip=100, loss_scale=512, train_wall=21, gb_free=8.9, wall=3817
2023-06-26 19:23:13 - progress_bar.py[line:272] - INFO: epoch 001:   1861 / 3715 loss=2.614, loss_v1=0, loss_v2=0, nll_loss=1.452, ntokens=1097.4, nsentences=120, sample_size=1097.4, sample_size_v1=0, sample_size_v2=0, ppl=2.74, wps=532.9, ups=0.49, wpb=1097.4, bsz=120, num_updates=1860, lr=1.56478e-05, gnorm=1.994, clip=100, loss_scale=512, train_wall=21, gb_free=8.9, wall=3837
2023-06-26 19:23:34 - progress_bar.py[line:272] - INFO: epoch 001:   1871 / 3715 loss=2.614, loss_v1=0, loss_v2=0, nll_loss=1.454, ntokens=1073.9, nsentences=120, sample_size=1073.9, sample_size_v1=0, sample_size_v2=0, ppl=2.74, wps=522, ups=0.49, wpb=1073.9, bsz=120, num_updates=1870, lr=1.57319e-05, gnorm=2.081, clip=100, loss_scale=512, train_wall=21, gb_free=8.9, wall=3858
2023-06-26 19:23:54 - progress_bar.py[line:272] - INFO: epoch 001:   1881 / 3715 loss=2.611, loss_v1=0, loss_v2=0, nll_loss=1.447, ntokens=1071.7, nsentences=120, sample_size=1071.7, sample_size_v1=0, sample_size_v2=0, ppl=2.73, wps=520.8, ups=0.49, wpb=1071.7, bsz=120, num_updates=1880, lr=1.5816e-05, gnorm=1.894, clip=100, loss_scale=512, train_wall=21, gb_free=8.9, wall=3879
2023-06-26 19:24:15 - progress_bar.py[line:272] - INFO: epoch 001:   1891 / 3715 loss=2.606, loss_v1=0, loss_v2=0, nll_loss=1.445, ntokens=1083.9, nsentences=120, sample_size=1083.9, sample_size_v1=0, sample_size_v2=0, ppl=2.72, wps=527, ups=0.49, wpb=1083.9, bsz=120, num_updates=1890, lr=1.59002e-05, gnorm=1.938, clip=100, loss_scale=512, train_wall=21, gb_free=8.9, wall=3899
2023-06-26 19:24:35 - progress_bar.py[line:272] - INFO: epoch 001:   1901 / 3715 loss=2.607, loss_v1=0, loss_v2=0, nll_loss=1.443, ntokens=1087, nsentences=120, sample_size=1087, sample_size_v1=0, sample_size_v2=0, ppl=2.72, wps=528.5, ups=0.49, wpb=1087, bsz=120, num_updates=1900, lr=1.59843e-05, gnorm=1.824, clip=100, loss_scale=512, train_wall=21, gb_free=8.9, wall=3920
2023-06-26 19:24:56 - progress_bar.py[line:272] - INFO: epoch 001:   1911 / 3715 loss=2.599, loss_v1=0, loss_v2=0, nll_loss=1.439, ntokens=1085.9, nsentences=120, sample_size=1085.9, sample_size_v1=0, sample_size_v2=0, ppl=2.71, wps=528.1, ups=0.49, wpb=1085.9, bsz=120, num_updates=1910, lr=1.60684e-05, gnorm=1.922, clip=100, loss_scale=512, train_wall=21, gb_free=8.9, wall=3940
2023-06-26 19:25:17 - progress_bar.py[line:272] - INFO: epoch 001:   1921 / 3715 loss=2.602, loss_v1=0, loss_v2=0, nll_loss=1.438, ntokens=1072.5, nsentences=120, sample_size=1072.5, sample_size_v1=0, sample_size_v2=0, ppl=2.71, wps=521.5, ups=0.49, wpb=1072.5, bsz=120, num_updates=1920, lr=1.61526e-05, gnorm=2, clip=100, loss_scale=512, train_wall=21, gb_free=8.9, wall=3961
2023-06-26 19:25:37 - progress_bar.py[line:272] - INFO: epoch 001:   1931 / 3715 loss=2.617, loss_v1=0, loss_v2=0, nll_loss=1.456, ntokens=1076.2, nsentences=120, sample_size=1076.2, sample_size_v1=0, sample_size_v2=0, ppl=2.74, wps=523.3, ups=0.49, wpb=1076.2, bsz=120, num_updates=1930, lr=1.62367e-05, gnorm=1.904, clip=100, loss_scale=512, train_wall=21, gb_free=8.9, wall=3982
2023-06-26 19:25:58 - progress_bar.py[line:272] - INFO: epoch 001:   1941 / 3715 loss=2.615, loss_v1=0, loss_v2=0, nll_loss=1.454, ntokens=1069, nsentences=120, sample_size=1069, sample_size_v1=0, sample_size_v2=0, ppl=2.74, wps=519.9, ups=0.49, wpb=1069, bsz=120, num_updates=1940, lr=1.63208e-05, gnorm=1.907, clip=100, loss_scale=512, train_wall=21, gb_free=8.9, wall=4002
2023-06-26 19:26:18 - progress_bar.py[line:272] - INFO: epoch 001:   1951 / 3715 loss=2.608, loss_v1=0, loss_v2=0, nll_loss=1.445, ntokens=1084.9, nsentences=120, sample_size=1084.9, sample_size_v1=0, sample_size_v2=0, ppl=2.72, wps=527.1, ups=0.49, wpb=1084.9, bsz=120, num_updates=1950, lr=1.64049e-05, gnorm=1.986, clip=100, loss_scale=512, train_wall=21, gb_free=8.9, wall=4023
2023-06-26 19:26:39 - progress_bar.py[line:272] - INFO: epoch 001:   1961 / 3715 loss=2.599, loss_v1=0, loss_v2=0, nll_loss=1.436, ntokens=1088.9, nsentences=120, sample_size=1088.9, sample_size_v1=0, sample_size_v2=0, ppl=2.71, wps=528.7, ups=0.49, wpb=1088.9, bsz=120, num_updates=1960, lr=1.64891e-05, gnorm=1.913, clip=100, loss_scale=512, train_wall=21, gb_free=8.9, wall=4043
2023-06-26 19:26:59 - progress_bar.py[line:272] - INFO: epoch 001:   1971 / 3715 loss=2.602, loss_v1=0, loss_v2=0, nll_loss=1.439, ntokens=1081.7, nsentences=120, sample_size=1081.7, sample_size_v1=0, sample_size_v2=0, ppl=2.71, wps=525.4, ups=0.49, wpb=1081.7, bsz=120, num_updates=1970, lr=1.65732e-05, gnorm=1.952, clip=100, loss_scale=512, train_wall=21, gb_free=8.9, wall=4064
2023-06-26 19:27:20 - progress_bar.py[line:272] - INFO: epoch 001:   1981 / 3715 loss=2.608, loss_v1=0, loss_v2=0, nll_loss=1.445, ntokens=1082, nsentences=120, sample_size=1082, sample_size_v1=0, sample_size_v2=0, ppl=2.72, wps=525.2, ups=0.49, wpb=1082, bsz=120, num_updates=1980, lr=1.66573e-05, gnorm=1.904, clip=100, loss_scale=512, train_wall=21, gb_free=8.9, wall=4084
2023-06-26 19:27:41 - progress_bar.py[line:272] - INFO: epoch 001:   1991 / 3715 loss=2.61, loss_v1=0, loss_v2=0, nll_loss=1.447, ntokens=1062.6, nsentences=120, sample_size=1062.6, sample_size_v1=0, sample_size_v2=0, ppl=2.73, wps=516, ups=0.49, wpb=1062.6, bsz=120, num_updates=1990, lr=1.67414e-05, gnorm=1.847, clip=100, loss_scale=512, train_wall=21, gb_free=8.9, wall=4105
2023-06-26 19:28:01 - progress_bar.py[line:272] - INFO: epoch 001:   2001 / 3715 loss=2.574, loss_v1=0, loss_v2=0, nll_loss=1.406, ntokens=1098, nsentences=120, sample_size=1098, sample_size_v1=0, sample_size_v2=0, ppl=2.65, wps=533.8, ups=0.49, wpb=1098, bsz=120, num_updates=2000, lr=1.68256e-05, gnorm=1.96, clip=100, loss_scale=512, train_wall=21, gb_free=8.9, wall=4126
2023-06-26 19:28:22 - progress_bar.py[line:272] - INFO: epoch 001:   2011 / 3715 loss=2.575, loss_v1=0, loss_v2=0, nll_loss=1.41, ntokens=1090.1, nsentences=120, sample_size=1090.1, sample_size_v1=0, sample_size_v2=0, ppl=2.66, wps=529.8, ups=0.49, wpb=1090.1, bsz=120, num_updates=2010, lr=1.69097e-05, gnorm=1.92, clip=100, loss_scale=512, train_wall=21, gb_free=8.9, wall=4146
2023-06-26 19:28:42 - progress_bar.py[line:272] - INFO: epoch 001:   2021 / 3715 loss=2.588, loss_v1=0, loss_v2=0, nll_loss=1.42, ntokens=1077.5, nsentences=120, sample_size=1077.5, sample_size_v1=0, sample_size_v2=0, ppl=2.68, wps=522.7, ups=0.49, wpb=1077.5, bsz=120, num_updates=2020, lr=1.69938e-05, gnorm=1.88, clip=100, loss_scale=512, train_wall=21, gb_free=8.9, wall=4167
2023-06-26 19:29:03 - progress_bar.py[line:272] - INFO: epoch 001:   2031 / 3715 loss=2.579, loss_v1=0, loss_v2=0, nll_loss=1.416, ntokens=1095.6, nsentences=120, sample_size=1095.6, sample_size_v1=0, sample_size_v2=0, ppl=2.67, wps=531.8, ups=0.49, wpb=1095.6, bsz=120, num_updates=2030, lr=1.7078e-05, gnorm=2.096, clip=100, loss_scale=512, train_wall=21, gb_free=8.9, wall=4187
2023-06-26 19:29:24 - progress_bar.py[line:272] - INFO: epoch 001:   2041 / 3715 loss=2.587, loss_v1=0, loss_v2=0, nll_loss=1.417, ntokens=1095.8, nsentences=120, sample_size=1095.8, sample_size_v1=0, sample_size_v2=0, ppl=2.67, wps=532.1, ups=0.49, wpb=1095.8, bsz=120, num_updates=2040, lr=1.71621e-05, gnorm=2.247, clip=100, loss_scale=512, train_wall=21, gb_free=8.9, wall=4208
2023-06-26 19:29:44 - progress_bar.py[line:272] - INFO: epoch 001:   2051 / 3715 loss=2.587, loss_v1=0, loss_v2=0, nll_loss=1.423, ntokens=1104.2, nsentences=120, sample_size=1104.2, sample_size_v1=0, sample_size_v2=0, ppl=2.68, wps=536.4, ups=0.49, wpb=1104.2, bsz=120, num_updates=2050, lr=1.72462e-05, gnorm=2.161, clip=100, loss_scale=512, train_wall=21, gb_free=8.9, wall=4229
2023-06-26 19:29:50 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 512.0
2023-06-26 19:30:07 - progress_bar.py[line:272] - INFO: epoch 001:   2062 / 3715 loss=2.607, loss_v1=0, loss_v2=0, nll_loss=1.44, ntokens=1101.9, nsentences=120, sample_size=1101.9, sample_size_v1=0, sample_size_v2=0, ppl=2.71, wps=487.4, ups=0.44, wpb=1101.9, bsz=120, num_updates=2060, lr=1.73303e-05, gnorm=2.15, clip=100, loss_scale=512, train_wall=23, gb_free=8.9, wall=4251
2023-06-26 19:30:19 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 256.0
2023-06-26 19:30:29 - progress_bar.py[line:272] - INFO: epoch 001:   2073 / 3715 loss=2.577, loss_v1=0, loss_v2=0, nll_loss=1.414, ntokens=1085.6, nsentences=120, sample_size=1085.6, sample_size_v1=0, sample_size_v2=0, ppl=2.67, wps=479.9, ups=0.44, wpb=1085.6, bsz=120, num_updates=2070, lr=1.74145e-05, gnorm=2.305, clip=100, loss_scale=256, train_wall=23, gb_free=8.9, wall=4274
2023-06-26 19:30:50 - progress_bar.py[line:272] - INFO: epoch 001:   2083 / 3715 loss=2.592, loss_v1=0, loss_v2=0, nll_loss=1.425, ntokens=1080.2, nsentences=120, sample_size=1080.2, sample_size_v1=0, sample_size_v2=0, ppl=2.68, wps=524.6, ups=0.49, wpb=1080.2, bsz=120, num_updates=2080, lr=1.74986e-05, gnorm=2.135, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=4294
2023-06-26 19:31:11 - progress_bar.py[line:272] - INFO: epoch 001:   2093 / 3715 loss=2.585, loss_v1=0, loss_v2=0, nll_loss=1.421, ntokens=1089.9, nsentences=120, sample_size=1089.9, sample_size_v1=0, sample_size_v2=0, ppl=2.68, wps=529.4, ups=0.49, wpb=1089.9, bsz=120, num_updates=2090, lr=1.75827e-05, gnorm=2.3, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=4315
2023-06-26 19:31:31 - progress_bar.py[line:272] - INFO: epoch 001:   2103 / 3715 loss=2.58, loss_v1=0, loss_v2=0, nll_loss=1.41, ntokens=1075.6, nsentences=120, sample_size=1075.6, sample_size_v1=0, sample_size_v2=0, ppl=2.66, wps=522.3, ups=0.49, wpb=1075.6, bsz=120, num_updates=2100, lr=1.76669e-05, gnorm=2.197, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=4336
2023-06-26 19:31:52 - progress_bar.py[line:272] - INFO: epoch 001:   2113 / 3715 loss=2.573, loss_v1=0, loss_v2=0, nll_loss=1.405, ntokens=1079.8, nsentences=120, sample_size=1079.8, sample_size_v1=0, sample_size_v2=0, ppl=2.65, wps=525.1, ups=0.49, wpb=1079.8, bsz=120, num_updates=2110, lr=1.7751e-05, gnorm=2.282, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=4356
2023-06-26 19:32:12 - progress_bar.py[line:272] - INFO: epoch 001:   2123 / 3715 loss=2.584, loss_v1=0, loss_v2=0, nll_loss=1.418, ntokens=1083.4, nsentences=120, sample_size=1083.4, sample_size_v1=0, sample_size_v2=0, ppl=2.67, wps=527, ups=0.49, wpb=1083.4, bsz=120, num_updates=2120, lr=1.78351e-05, gnorm=2.299, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=4377
2023-06-26 19:32:33 - progress_bar.py[line:272] - INFO: epoch 001:   2133 / 3715 loss=2.573, loss_v1=0, loss_v2=0, nll_loss=1.404, ntokens=1070, nsentences=120, sample_size=1070, sample_size_v1=0, sample_size_v2=0, ppl=2.65, wps=521, ups=0.49, wpb=1070, bsz=120, num_updates=2130, lr=1.79192e-05, gnorm=2.131, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=4397
2023-06-26 19:32:53 - progress_bar.py[line:272] - INFO: epoch 001:   2143 / 3715 loss=2.583, loss_v1=0, loss_v2=0, nll_loss=1.412, ntokens=1099.6, nsentences=120, sample_size=1099.6, sample_size_v1=0, sample_size_v2=0, ppl=2.66, wps=535.6, ups=0.49, wpb=1099.6, bsz=120, num_updates=2140, lr=1.80034e-05, gnorm=2.146, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=4418
2023-06-26 19:33:14 - progress_bar.py[line:272] - INFO: epoch 001:   2153 / 3715 loss=2.577, loss_v1=0, loss_v2=0, nll_loss=1.409, ntokens=1095.8, nsentences=120, sample_size=1095.8, sample_size_v1=0, sample_size_v2=0, ppl=2.66, wps=532.7, ups=0.49, wpb=1095.8, bsz=120, num_updates=2150, lr=1.80875e-05, gnorm=2.155, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=4438
2023-06-26 19:33:35 - progress_bar.py[line:272] - INFO: epoch 001:   2163 / 3715 loss=2.572, loss_v1=0, loss_v2=0, nll_loss=1.403, ntokens=1079.2, nsentences=120, sample_size=1079.2, sample_size_v1=0, sample_size_v2=0, ppl=2.65, wps=524.5, ups=0.49, wpb=1079.2, bsz=120, num_updates=2160, lr=1.81716e-05, gnorm=2.185, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=4459
2023-06-26 19:33:55 - progress_bar.py[line:272] - INFO: epoch 001:   2173 / 3715 loss=2.575, loss_v1=0, loss_v2=0, nll_loss=1.406, ntokens=1113.2, nsentences=120, sample_size=1113.2, sample_size_v1=0, sample_size_v2=0, ppl=2.65, wps=541, ups=0.49, wpb=1113.2, bsz=120, num_updates=2170, lr=1.82557e-05, gnorm=2.328, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=4480
2023-06-26 19:34:16 - progress_bar.py[line:272] - INFO: epoch 001:   2183 / 3715 loss=2.572, loss_v1=0, loss_v2=0, nll_loss=1.406, ntokens=1095.2, nsentences=120, sample_size=1095.2, sample_size_v1=0, sample_size_v2=0, ppl=2.65, wps=531.6, ups=0.49, wpb=1095.2, bsz=120, num_updates=2180, lr=1.83399e-05, gnorm=2.405, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=4500
2023-06-26 19:34:36 - progress_bar.py[line:272] - INFO: epoch 001:   2193 / 3715 loss=2.57, loss_v1=0, loss_v2=0, nll_loss=1.397, ntokens=1074.1, nsentences=120, sample_size=1074.1, sample_size_v1=0, sample_size_v2=0, ppl=2.63, wps=521.5, ups=0.49, wpb=1074.1, bsz=120, num_updates=2190, lr=1.8424e-05, gnorm=2.168, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=4521
2023-06-26 19:34:57 - progress_bar.py[line:272] - INFO: epoch 001:   2203 / 3715 loss=2.565, loss_v1=0, loss_v2=0, nll_loss=1.397, ntokens=1102.3, nsentences=120, sample_size=1102.3, sample_size_v1=0, sample_size_v2=0, ppl=2.63, wps=535.7, ups=0.49, wpb=1102.3, bsz=120, num_updates=2200, lr=1.85081e-05, gnorm=2.182, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=4541
2023-06-26 19:35:18 - progress_bar.py[line:272] - INFO: epoch 001:   2213 / 3715 loss=2.576, loss_v1=0, loss_v2=0, nll_loss=1.408, ntokens=1110.4, nsentences=120, sample_size=1110.4, sample_size_v1=0, sample_size_v2=0, ppl=2.65, wps=539.4, ups=0.49, wpb=1110.4, bsz=120, num_updates=2210, lr=1.85923e-05, gnorm=2.366, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=4562
2023-06-26 19:35:38 - progress_bar.py[line:272] - INFO: epoch 001:   2223 / 3715 loss=2.568, loss_v1=0, loss_v2=0, nll_loss=1.398, ntokens=1087.6, nsentences=120, sample_size=1087.6, sample_size_v1=0, sample_size_v2=0, ppl=2.64, wps=528.4, ups=0.49, wpb=1087.6, bsz=120, num_updates=2220, lr=1.86764e-05, gnorm=2.316, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=4583
2023-06-26 19:35:59 - progress_bar.py[line:272] - INFO: epoch 001:   2233 / 3715 loss=2.567, loss_v1=0, loss_v2=0, nll_loss=1.396, ntokens=1089.8, nsentences=120, sample_size=1089.8, sample_size_v1=0, sample_size_v2=0, ppl=2.63, wps=529.7, ups=0.49, wpb=1089.8, bsz=120, num_updates=2230, lr=1.87605e-05, gnorm=2.248, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=4603
2023-06-26 19:36:19 - progress_bar.py[line:272] - INFO: epoch 001:   2243 / 3715 loss=2.569, loss_v1=0, loss_v2=0, nll_loss=1.399, ntokens=1077.3, nsentences=120, sample_size=1077.3, sample_size_v1=0, sample_size_v2=0, ppl=2.64, wps=524.3, ups=0.49, wpb=1077.3, bsz=120, num_updates=2240, lr=1.88446e-05, gnorm=2.299, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=4624
2023-06-26 19:36:40 - progress_bar.py[line:272] - INFO: epoch 001:   2253 / 3715 loss=2.587, loss_v1=0, loss_v2=0, nll_loss=1.42, ntokens=1101.5, nsentences=120, sample_size=1101.5, sample_size_v1=0, sample_size_v2=0, ppl=2.68, wps=535.9, ups=0.49, wpb=1101.5, bsz=120, num_updates=2250, lr=1.89288e-05, gnorm=2.341, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=4644
2023-06-26 19:37:00 - progress_bar.py[line:272] - INFO: epoch 001:   2263 / 3715 loss=2.554, loss_v1=0, loss_v2=0, nll_loss=1.381, ntokens=1078.5, nsentences=120, sample_size=1078.5, sample_size_v1=0, sample_size_v2=0, ppl=2.6, wps=524, ups=0.49, wpb=1078.5, bsz=120, num_updates=2260, lr=1.90129e-05, gnorm=2.43, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=4665
2023-06-26 19:37:21 - progress_bar.py[line:272] - INFO: epoch 001:   2273 / 3715 loss=2.551, loss_v1=0, loss_v2=0, nll_loss=1.382, ntokens=1103.3, nsentences=120, sample_size=1103.3, sample_size_v1=0, sample_size_v2=0, ppl=2.61, wps=535.4, ups=0.49, wpb=1103.3, bsz=120, num_updates=2270, lr=1.9097e-05, gnorm=2.431, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=4685
2023-06-26 19:37:42 - progress_bar.py[line:272] - INFO: epoch 001:   2283 / 3715 loss=2.553, loss_v1=0, loss_v2=0, nll_loss=1.378, ntokens=1090.6, nsentences=120, sample_size=1090.6, sample_size_v1=0, sample_size_v2=0, ppl=2.6, wps=530.7, ups=0.49, wpb=1090.6, bsz=120, num_updates=2280, lr=1.91812e-05, gnorm=2.405, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=4706
2023-06-26 19:38:02 - progress_bar.py[line:272] - INFO: epoch 001:   2293 / 3715 loss=2.567, loss_v1=0, loss_v2=0, nll_loss=1.4, ntokens=1070.2, nsentences=120, sample_size=1070.2, sample_size_v1=0, sample_size_v2=0, ppl=2.64, wps=519.9, ups=0.49, wpb=1070.2, bsz=120, num_updates=2290, lr=1.92653e-05, gnorm=2.4, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=4727
2023-06-26 19:38:23 - progress_bar.py[line:272] - INFO: epoch 001:   2303 / 3715 loss=2.572, loss_v1=0, loss_v2=0, nll_loss=1.4, ntokens=1097, nsentences=120, sample_size=1097, sample_size_v1=0, sample_size_v2=0, ppl=2.64, wps=533.6, ups=0.49, wpb=1097, bsz=120, num_updates=2300, lr=1.93494e-05, gnorm=2.41, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=4747
2023-06-26 19:38:43 - progress_bar.py[line:272] - INFO: epoch 001:   2313 / 3715 loss=2.556, loss_v1=0, loss_v2=0, nll_loss=1.385, ntokens=1079.5, nsentences=120, sample_size=1079.5, sample_size_v1=0, sample_size_v2=0, ppl=2.61, wps=525.8, ups=0.49, wpb=1079.5, bsz=120, num_updates=2310, lr=1.94335e-05, gnorm=2.515, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=4768
2023-06-26 19:39:04 - progress_bar.py[line:272] - INFO: epoch 001:   2323 / 3715 loss=2.573, loss_v1=0, loss_v2=0, nll_loss=1.404, ntokens=1078.4, nsentences=120, sample_size=1078.4, sample_size_v1=0, sample_size_v2=0, ppl=2.65, wps=525.1, ups=0.49, wpb=1078.4, bsz=120, num_updates=2320, lr=1.95177e-05, gnorm=2.535, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=4788
2023-06-26 19:39:24 - progress_bar.py[line:272] - INFO: epoch 001:   2333 / 3715 loss=2.556, loss_v1=0, loss_v2=0, nll_loss=1.385, ntokens=1083.7, nsentences=120, sample_size=1083.7, sample_size_v1=0, sample_size_v2=0, ppl=2.61, wps=526.7, ups=0.49, wpb=1083.7, bsz=120, num_updates=2330, lr=1.96018e-05, gnorm=2.346, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=4809
2023-06-26 19:39:45 - progress_bar.py[line:272] - INFO: epoch 001:   2343 / 3715 loss=2.561, loss_v1=0, loss_v2=0, nll_loss=1.388, ntokens=1081.2, nsentences=120, sample_size=1081.2, sample_size_v1=0, sample_size_v2=0, ppl=2.62, wps=525.5, ups=0.49, wpb=1081.2, bsz=120, num_updates=2340, lr=1.96859e-05, gnorm=2.397, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=4829
2023-06-26 19:40:06 - progress_bar.py[line:272] - INFO: epoch 001:   2353 / 3715 loss=2.554, loss_v1=0, loss_v2=0, nll_loss=1.382, ntokens=1121.8, nsentences=120, sample_size=1121.8, sample_size_v1=0, sample_size_v2=0, ppl=2.61, wps=545.6, ups=0.49, wpb=1121.8, bsz=120, num_updates=2350, lr=1.97701e-05, gnorm=2.2, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=4850
2023-06-26 19:40:26 - progress_bar.py[line:272] - INFO: epoch 001:   2363 / 3715 loss=2.562, loss_v1=0, loss_v2=0, nll_loss=1.392, ntokens=1099.8, nsentences=120, sample_size=1099.8, sample_size_v1=0, sample_size_v2=0, ppl=2.62, wps=535.4, ups=0.49, wpb=1099.8, bsz=120, num_updates=2360, lr=1.98542e-05, gnorm=2.63, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=4870
2023-06-26 19:40:47 - progress_bar.py[line:272] - INFO: epoch 001:   2373 / 3715 loss=2.551, loss_v1=0, loss_v2=0, nll_loss=1.376, ntokens=1078.1, nsentences=120, sample_size=1078.1, sample_size_v1=0, sample_size_v2=0, ppl=2.6, wps=524.6, ups=0.49, wpb=1078.1, bsz=120, num_updates=2370, lr=1.99383e-05, gnorm=2.56, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=4891
2023-06-26 19:41:07 - progress_bar.py[line:272] - INFO: epoch 001:   2383 / 3715 loss=2.534, loss_v1=0, loss_v2=0, nll_loss=1.362, ntokens=1081.3, nsentences=120, sample_size=1081.3, sample_size_v1=0, sample_size_v2=0, ppl=2.57, wps=526.4, ups=0.49, wpb=1081.3, bsz=120, num_updates=2380, lr=2.00224e-05, gnorm=2.671, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=4912
2023-06-26 19:41:28 - progress_bar.py[line:272] - INFO: epoch 001:   2393 / 3715 loss=2.553, loss_v1=0, loss_v2=0, nll_loss=1.376, ntokens=1086.4, nsentences=120, sample_size=1086.4, sample_size_v1=0, sample_size_v2=0, ppl=2.6, wps=528.3, ups=0.49, wpb=1086.4, bsz=120, num_updates=2390, lr=2.01066e-05, gnorm=2.372, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=4932
2023-06-26 19:41:48 - progress_bar.py[line:272] - INFO: epoch 001:   2403 / 3715 loss=2.541, loss_v1=0, loss_v2=0, nll_loss=1.371, ntokens=1044, nsentences=120, sample_size=1044, sample_size_v1=0, sample_size_v2=0, ppl=2.59, wps=507.4, ups=0.49, wpb=1044, bsz=120, num_updates=2400, lr=2.01907e-05, gnorm=2.791, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=4953
2023-06-26 19:42:09 - progress_bar.py[line:272] - INFO: epoch 001:   2413 / 3715 loss=2.541, loss_v1=0, loss_v2=0, nll_loss=1.363, ntokens=1089.8, nsentences=120, sample_size=1089.8, sample_size_v1=0, sample_size_v2=0, ppl=2.57, wps=529.7, ups=0.49, wpb=1089.8, bsz=120, num_updates=2410, lr=2.02748e-05, gnorm=2.505, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=4973
2023-06-26 19:42:30 - progress_bar.py[line:272] - INFO: epoch 001:   2423 / 3715 loss=2.53, loss_v1=0, loss_v2=0, nll_loss=1.356, ntokens=1102.2, nsentences=120, sample_size=1102.2, sample_size_v1=0, sample_size_v2=0, ppl=2.56, wps=535.6, ups=0.49, wpb=1102.2, bsz=120, num_updates=2420, lr=2.03589e-05, gnorm=2.633, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=4994
2023-06-26 19:42:50 - progress_bar.py[line:272] - INFO: epoch 001:   2433 / 3715 loss=2.533, loss_v1=0, loss_v2=0, nll_loss=1.359, ntokens=1096.7, nsentences=120, sample_size=1096.7, sample_size_v1=0, sample_size_v2=0, ppl=2.56, wps=533, ups=0.49, wpb=1096.7, bsz=120, num_updates=2430, lr=2.04431e-05, gnorm=2.655, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=5014
2023-06-26 19:43:11 - progress_bar.py[line:272] - INFO: epoch 001:   2443 / 3715 loss=2.559, loss_v1=0, loss_v2=0, nll_loss=1.384, ntokens=1079.6, nsentences=120, sample_size=1079.6, sample_size_v1=0, sample_size_v2=0, ppl=2.61, wps=524.2, ups=0.49, wpb=1079.6, bsz=120, num_updates=2440, lr=2.05272e-05, gnorm=2.631, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=5035
2023-06-26 19:43:31 - progress_bar.py[line:272] - INFO: epoch 001:   2453 / 3715 loss=2.56, loss_v1=0, loss_v2=0, nll_loss=1.387, ntokens=1083.5, nsentences=120, sample_size=1083.5, sample_size_v1=0, sample_size_v2=0, ppl=2.62, wps=526.9, ups=0.49, wpb=1083.5, bsz=120, num_updates=2450, lr=2.06113e-05, gnorm=2.432, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=5056
2023-06-26 19:43:52 - progress_bar.py[line:272] - INFO: epoch 001:   2463 / 3715 loss=2.539, loss_v1=0, loss_v2=0, nll_loss=1.365, ntokens=1086.5, nsentences=120, sample_size=1086.5, sample_size_v1=0, sample_size_v2=0, ppl=2.58, wps=528.6, ups=0.49, wpb=1086.5, bsz=120, num_updates=2460, lr=2.06955e-05, gnorm=2.616, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=5076
2023-06-26 19:44:12 - progress_bar.py[line:272] - INFO: epoch 001:   2473 / 3715 loss=2.544, loss_v1=0, loss_v2=0, nll_loss=1.368, ntokens=1087.3, nsentences=120, sample_size=1087.3, sample_size_v1=0, sample_size_v2=0, ppl=2.58, wps=528.2, ups=0.49, wpb=1087.3, bsz=120, num_updates=2470, lr=2.07796e-05, gnorm=2.693, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=5097
2023-06-26 19:44:33 - progress_bar.py[line:272] - INFO: epoch 001:   2483 / 3715 loss=2.545, loss_v1=0, loss_v2=0, nll_loss=1.372, ntokens=1078.9, nsentences=120, sample_size=1078.9, sample_size_v1=0, sample_size_v2=0, ppl=2.59, wps=524.5, ups=0.49, wpb=1078.9, bsz=120, num_updates=2480, lr=2.08637e-05, gnorm=2.574, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=5117
2023-06-26 19:44:54 - progress_bar.py[line:272] - INFO: epoch 001:   2493 / 3715 loss=2.534, loss_v1=0, loss_v2=0, nll_loss=1.358, ntokens=1056.8, nsentences=120, sample_size=1056.8, sample_size_v1=0, sample_size_v2=0, ppl=2.56, wps=513.8, ups=0.49, wpb=1056.8, bsz=120, num_updates=2490, lr=2.09478e-05, gnorm=2.911, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=5138
2023-06-26 19:45:14 - progress_bar.py[line:272] - INFO: epoch 001:   2503 / 3715 loss=2.537, loss_v1=0, loss_v2=0, nll_loss=1.36, ntokens=1052.6, nsentences=120, sample_size=1052.6, sample_size_v1=0, sample_size_v2=0, ppl=2.57, wps=512.1, ups=0.49, wpb=1052.6, bsz=120, num_updates=2500, lr=2.1032e-05, gnorm=3.035, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=5158
2023-06-26 19:45:35 - progress_bar.py[line:272] - INFO: epoch 001:   2513 / 3715 loss=2.549, loss_v1=0, loss_v2=0, nll_loss=1.374, ntokens=1060.4, nsentences=120, sample_size=1060.4, sample_size_v1=0, sample_size_v2=0, ppl=2.59, wps=515.7, ups=0.49, wpb=1060.4, bsz=120, num_updates=2510, lr=2.11161e-05, gnorm=2.562, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=5179
2023-06-26 19:45:55 - progress_bar.py[line:272] - INFO: epoch 001:   2523 / 3715 loss=2.545, loss_v1=0, loss_v2=0, nll_loss=1.371, ntokens=1094.3, nsentences=120, sample_size=1094.3, sample_size_v1=0, sample_size_v2=0, ppl=2.59, wps=532.2, ups=0.49, wpb=1094.3, bsz=120, num_updates=2520, lr=2.12002e-05, gnorm=2.521, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=5200
2023-06-26 19:46:16 - progress_bar.py[line:272] - INFO: epoch 001:   2533 / 3715 loss=2.53, loss_v1=0, loss_v2=0, nll_loss=1.355, ntokens=1077, nsentences=120, sample_size=1077, sample_size_v1=0, sample_size_v2=0, ppl=2.56, wps=524.1, ups=0.49, wpb=1077, bsz=120, num_updates=2530, lr=2.12844e-05, gnorm=3.082, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=5220
2023-06-26 19:46:36 - progress_bar.py[line:272] - INFO: epoch 001:   2543 / 3715 loss=2.559, loss_v1=0, loss_v2=0, nll_loss=1.386, ntokens=1109, nsentences=120, sample_size=1109, sample_size_v1=0, sample_size_v2=0, ppl=2.61, wps=539.2, ups=0.49, wpb=1109, bsz=120, num_updates=2540, lr=2.13685e-05, gnorm=2.658, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=5241
2023-06-26 19:46:57 - progress_bar.py[line:272] - INFO: epoch 001:   2553 / 3715 loss=2.535, loss_v1=0, loss_v2=0, nll_loss=1.361, ntokens=1092.7, nsentences=120, sample_size=1092.7, sample_size_v1=0, sample_size_v2=0, ppl=2.57, wps=530.7, ups=0.49, wpb=1092.7, bsz=120, num_updates=2550, lr=2.14526e-05, gnorm=2.839, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=5261
2023-06-26 19:47:18 - progress_bar.py[line:272] - INFO: epoch 001:   2563 / 3715 loss=2.524, loss_v1=0, loss_v2=0, nll_loss=1.345, ntokens=1068.1, nsentences=120, sample_size=1068.1, sample_size_v1=0, sample_size_v2=0, ppl=2.54, wps=519.4, ups=0.49, wpb=1068.1, bsz=120, num_updates=2560, lr=2.15367e-05, gnorm=2.745, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=5282
2023-06-26 19:47:38 - progress_bar.py[line:272] - INFO: epoch 001:   2573 / 3715 loss=2.541, loss_v1=0, loss_v2=0, nll_loss=1.366, ntokens=1091.8, nsentences=120, sample_size=1091.8, sample_size_v1=0, sample_size_v2=0, ppl=2.58, wps=530.4, ups=0.49, wpb=1091.8, bsz=120, num_updates=2570, lr=2.16209e-05, gnorm=2.899, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=5302
2023-06-26 19:47:59 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 256.0
2023-06-26 19:48:01 - progress_bar.py[line:272] - INFO: epoch 001:   2584 / 3715 loss=2.512, loss_v1=0, loss_v2=0, nll_loss=1.335, ntokens=1078.5, nsentences=120, sample_size=1078.5, sample_size_v1=0, sample_size_v2=0, ppl=2.52, wps=477, ups=0.44, wpb=1078.5, bsz=120, num_updates=2580, lr=2.1705e-05, gnorm=2.85, clip=100, loss_scale=256, train_wall=23, gb_free=8.9, wall=5325
2023-06-26 19:48:21 - progress_bar.py[line:272] - INFO: epoch 001:   2594 / 3715 loss=2.524, loss_v1=0, loss_v2=0, nll_loss=1.346, ntokens=1093, nsentences=120, sample_size=1093, sample_size_v1=0, sample_size_v2=0, ppl=2.54, wps=530.6, ups=0.49, wpb=1093, bsz=120, num_updates=2590, lr=2.17891e-05, gnorm=2.66, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=5346
2023-06-26 19:48:42 - progress_bar.py[line:272] - INFO: epoch 001:   2604 / 3715 loss=2.54, loss_v1=0, loss_v2=0, nll_loss=1.367, ntokens=1095.5, nsentences=120, sample_size=1095.5, sample_size_v1=0, sample_size_v2=0, ppl=2.58, wps=532.3, ups=0.49, wpb=1095.5, bsz=120, num_updates=2600, lr=2.18732e-05, gnorm=3.026, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=5366
2023-06-26 19:49:03 - progress_bar.py[line:272] - INFO: epoch 001:   2614 / 3715 loss=2.54, loss_v1=0, loss_v2=0, nll_loss=1.362, ntokens=1087.4, nsentences=120, sample_size=1087.4, sample_size_v1=0, sample_size_v2=0, ppl=2.57, wps=528.2, ups=0.49, wpb=1087.4, bsz=120, num_updates=2610, lr=2.19574e-05, gnorm=2.912, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=5387
2023-06-26 19:49:23 - progress_bar.py[line:272] - INFO: epoch 001:   2624 / 3715 loss=2.545, loss_v1=0, loss_v2=0, nll_loss=1.371, ntokens=1088.9, nsentences=120, sample_size=1088.9, sample_size_v1=0, sample_size_v2=0, ppl=2.59, wps=529.5, ups=0.49, wpb=1088.9, bsz=120, num_updates=2620, lr=2.20415e-05, gnorm=2.936, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=5407
2023-06-26 19:49:44 - progress_bar.py[line:272] - INFO: epoch 001:   2634 / 3715 loss=2.524, loss_v1=0, loss_v2=0, nll_loss=1.347, ntokens=1082.6, nsentences=120, sample_size=1082.6, sample_size_v1=0, sample_size_v2=0, ppl=2.54, wps=526.1, ups=0.49, wpb=1082.6, bsz=120, num_updates=2630, lr=2.21256e-05, gnorm=3.031, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=5428
2023-06-26 19:50:04 - progress_bar.py[line:272] - INFO: epoch 001:   2644 / 3715 loss=2.541, loss_v1=0, loss_v2=0, nll_loss=1.367, ntokens=1096.1, nsentences=120, sample_size=1096.1, sample_size_v1=0, sample_size_v2=0, ppl=2.58, wps=532.4, ups=0.49, wpb=1096.1, bsz=120, num_updates=2640, lr=2.22098e-05, gnorm=3.067, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=5449
2023-06-26 19:50:25 - progress_bar.py[line:272] - INFO: epoch 001:   2654 / 3715 loss=2.521, loss_v1=0, loss_v2=0, nll_loss=1.343, ntokens=1056.7, nsentences=120, sample_size=1056.7, sample_size_v1=0, sample_size_v2=0, ppl=2.54, wps=513.5, ups=0.49, wpb=1056.7, bsz=120, num_updates=2650, lr=2.22939e-05, gnorm=3.089, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=5469
2023-06-26 19:50:45 - progress_bar.py[line:272] - INFO: epoch 001:   2664 / 3715 loss=2.529, loss_v1=0, loss_v2=0, nll_loss=1.348, ntokens=1098.5, nsentences=120, sample_size=1098.5, sample_size_v1=0, sample_size_v2=0, ppl=2.55, wps=534.3, ups=0.49, wpb=1098.5, bsz=120, num_updates=2660, lr=2.2378e-05, gnorm=2.966, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=5490
2023-06-26 19:51:06 - progress_bar.py[line:272] - INFO: epoch 001:   2674 / 3715 loss=2.526, loss_v1=0, loss_v2=0, nll_loss=1.351, ntokens=1084.7, nsentences=120, sample_size=1084.7, sample_size_v1=0, sample_size_v2=0, ppl=2.55, wps=527.3, ups=0.49, wpb=1084.7, bsz=120, num_updates=2670, lr=2.24621e-05, gnorm=3.127, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=5510
2023-06-26 19:51:27 - progress_bar.py[line:272] - INFO: epoch 001:   2684 / 3715 loss=2.532, loss_v1=0, loss_v2=0, nll_loss=1.354, ntokens=1065.3, nsentences=120, sample_size=1065.3, sample_size_v1=0, sample_size_v2=0, ppl=2.56, wps=518.7, ups=0.49, wpb=1065.3, bsz=120, num_updates=2680, lr=2.25463e-05, gnorm=2.924, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=5531
2023-06-26 19:51:47 - progress_bar.py[line:272] - INFO: epoch 001:   2694 / 3715 loss=2.526, loss_v1=0, loss_v2=0, nll_loss=1.351, ntokens=1093.3, nsentences=120, sample_size=1093.3, sample_size_v1=0, sample_size_v2=0, ppl=2.55, wps=532.3, ups=0.49, wpb=1093.3, bsz=120, num_updates=2690, lr=2.26304e-05, gnorm=2.979, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=5551
2023-06-26 19:52:08 - progress_bar.py[line:272] - INFO: epoch 001:   2704 / 3715 loss=2.504, loss_v1=0, loss_v2=0, nll_loss=1.323, ntokens=1103.1, nsentences=120, sample_size=1103.1, sample_size_v1=0, sample_size_v2=0, ppl=2.5, wps=537.2, ups=0.49, wpb=1103.1, bsz=120, num_updates=2700, lr=2.27145e-05, gnorm=3.061, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=5572
2023-06-26 19:52:28 - progress_bar.py[line:272] - INFO: epoch 001:   2714 / 3715 loss=2.508, loss_v1=0, loss_v2=0, nll_loss=1.329, ntokens=1082.4, nsentences=120, sample_size=1082.4, sample_size_v1=0, sample_size_v2=0, ppl=2.51, wps=526.6, ups=0.49, wpb=1082.4, bsz=120, num_updates=2710, lr=2.27987e-05, gnorm=2.997, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=5592
2023-06-26 19:52:49 - progress_bar.py[line:272] - INFO: epoch 001:   2724 / 3715 loss=2.525, loss_v1=0, loss_v2=0, nll_loss=1.346, ntokens=1081.5, nsentences=120, sample_size=1081.5, sample_size_v1=0, sample_size_v2=0, ppl=2.54, wps=525.8, ups=0.49, wpb=1081.5, bsz=120, num_updates=2720, lr=2.28828e-05, gnorm=3.057, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=5613
2023-06-26 19:53:09 - progress_bar.py[line:272] - INFO: epoch 001:   2734 / 3715 loss=2.507, loss_v1=0, loss_v2=0, nll_loss=1.328, ntokens=1084.1, nsentences=120, sample_size=1084.1, sample_size_v1=0, sample_size_v2=0, ppl=2.51, wps=526.8, ups=0.49, wpb=1084.1, bsz=120, num_updates=2730, lr=2.29669e-05, gnorm=2.856, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=5634
2023-06-26 19:53:30 - progress_bar.py[line:272] - INFO: epoch 001:   2744 / 3715 loss=2.502, loss_v1=0, loss_v2=0, nll_loss=1.324, ntokens=1091.9, nsentences=120, sample_size=1091.9, sample_size_v1=0, sample_size_v2=0, ppl=2.5, wps=530.2, ups=0.49, wpb=1091.9, bsz=120, num_updates=2740, lr=2.3051e-05, gnorm=3.111, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=5654
2023-06-26 19:53:51 - progress_bar.py[line:272] - INFO: epoch 001:   2754 / 3715 loss=2.519, loss_v1=0, loss_v2=0, nll_loss=1.339, ntokens=1053, nsentences=120, sample_size=1053, sample_size_v1=0, sample_size_v2=0, ppl=2.53, wps=511.2, ups=0.49, wpb=1053, bsz=120, num_updates=2750, lr=2.31352e-05, gnorm=2.927, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=5675
2023-06-26 19:54:11 - progress_bar.py[line:272] - INFO: epoch 001:   2764 / 3715 loss=2.514, loss_v1=0, loss_v2=0, nll_loss=1.336, ntokens=1086.1, nsentences=120, sample_size=1086.1, sample_size_v1=0, sample_size_v2=0, ppl=2.52, wps=527.5, ups=0.49, wpb=1086.1, bsz=120, num_updates=2760, lr=2.32193e-05, gnorm=3.087, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=5695
2023-06-26 19:54:32 - progress_bar.py[line:272] - INFO: epoch 001:   2774 / 3715 loss=2.517, loss_v1=0, loss_v2=0, nll_loss=1.338, ntokens=1110.8, nsentences=120, sample_size=1110.8, sample_size_v1=0, sample_size_v2=0, ppl=2.53, wps=539.6, ups=0.49, wpb=1110.8, bsz=120, num_updates=2770, lr=2.33034e-05, gnorm=2.939, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=5716
2023-06-26 19:54:52 - progress_bar.py[line:272] - INFO: epoch 001:   2784 / 3715 loss=2.518, loss_v1=0, loss_v2=0, nll_loss=1.338, ntokens=1083.2, nsentences=120, sample_size=1083.2, sample_size_v1=0, sample_size_v2=0, ppl=2.53, wps=526.1, ups=0.49, wpb=1083.2, bsz=120, num_updates=2780, lr=2.33875e-05, gnorm=3.096, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=5737
2023-06-26 19:55:13 - progress_bar.py[line:272] - INFO: epoch 001:   2794 / 3715 loss=2.517, loss_v1=0, loss_v2=0, nll_loss=1.34, ntokens=1088.2, nsentences=120, sample_size=1088.2, sample_size_v1=0, sample_size_v2=0, ppl=2.53, wps=529.1, ups=0.49, wpb=1088.2, bsz=120, num_updates=2790, lr=2.34717e-05, gnorm=3.195, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=5757
2023-06-26 19:55:33 - progress_bar.py[line:272] - INFO: epoch 001:   2804 / 3715 loss=2.508, loss_v1=0, loss_v2=0, nll_loss=1.324, ntokens=1078.9, nsentences=120, sample_size=1078.9, sample_size_v1=0, sample_size_v2=0, ppl=2.5, wps=524.2, ups=0.49, wpb=1078.9, bsz=120, num_updates=2800, lr=2.35558e-05, gnorm=3.316, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=5778
2023-06-26 19:55:54 - progress_bar.py[line:272] - INFO: epoch 001:   2814 / 3715 loss=2.506, loss_v1=0, loss_v2=0, nll_loss=1.328, ntokens=1078.5, nsentences=120, sample_size=1078.5, sample_size_v1=0, sample_size_v2=0, ppl=2.51, wps=524, ups=0.49, wpb=1078.5, bsz=120, num_updates=2810, lr=2.36399e-05, gnorm=3.224, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=5798
2023-06-26 19:56:15 - progress_bar.py[line:272] - INFO: epoch 001:   2824 / 3715 loss=2.514, loss_v1=0, loss_v2=0, nll_loss=1.332, ntokens=1057.7, nsentences=120, sample_size=1057.7, sample_size_v1=0, sample_size_v2=0, ppl=2.52, wps=514.1, ups=0.49, wpb=1057.7, bsz=120, num_updates=2820, lr=2.37241e-05, gnorm=3.152, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=5819
2023-06-26 19:56:35 - progress_bar.py[line:272] - INFO: epoch 001:   2834 / 3715 loss=2.512, loss_v1=0, loss_v2=0, nll_loss=1.335, ntokens=1110.3, nsentences=120, sample_size=1110.3, sample_size_v1=0, sample_size_v2=0, ppl=2.52, wps=539.3, ups=0.49, wpb=1110.3, bsz=120, num_updates=2830, lr=2.38082e-05, gnorm=3.13, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=5840
2023-06-26 19:56:56 - progress_bar.py[line:272] - INFO: epoch 001:   2844 / 3715 loss=2.499, loss_v1=0, loss_v2=0, nll_loss=1.319, ntokens=1090.3, nsentences=120, sample_size=1090.3, sample_size_v1=0, sample_size_v2=0, ppl=2.49, wps=529.5, ups=0.49, wpb=1090.3, bsz=120, num_updates=2840, lr=2.38923e-05, gnorm=3.336, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=5860
2023-06-26 19:57:16 - progress_bar.py[line:272] - INFO: epoch 001:   2854 / 3715 loss=2.508, loss_v1=0, loss_v2=0, nll_loss=1.328, ntokens=1100.4, nsentences=120, sample_size=1100.4, sample_size_v1=0, sample_size_v2=0, ppl=2.51, wps=535.3, ups=0.49, wpb=1100.4, bsz=120, num_updates=2850, lr=2.39764e-05, gnorm=3.39, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=5881
2023-06-26 19:57:37 - progress_bar.py[line:272] - INFO: epoch 001:   2864 / 3715 loss=2.522, loss_v1=0, loss_v2=0, nll_loss=1.341, ntokens=1092.4, nsentences=120, sample_size=1092.4, sample_size_v1=0, sample_size_v2=0, ppl=2.53, wps=531.1, ups=0.49, wpb=1092.4, bsz=120, num_updates=2860, lr=2.40606e-05, gnorm=3.123, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=5901
2023-06-26 19:57:58 - progress_bar.py[line:272] - INFO: epoch 001:   2874 / 3715 loss=2.503, loss_v1=0, loss_v2=0, nll_loss=1.323, ntokens=1085.9, nsentences=120, sample_size=1085.9, sample_size_v1=0, sample_size_v2=0, ppl=2.5, wps=526.9, ups=0.49, wpb=1085.9, bsz=120, num_updates=2870, lr=2.41447e-05, gnorm=3.037, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=5922
2023-06-26 19:58:18 - progress_bar.py[line:272] - INFO: epoch 001:   2884 / 3715 loss=2.503, loss_v1=0, loss_v2=0, nll_loss=1.323, ntokens=1079, nsentences=120, sample_size=1079, sample_size_v1=0, sample_size_v2=0, ppl=2.5, wps=525.3, ups=0.49, wpb=1079, bsz=120, num_updates=2880, lr=2.42288e-05, gnorm=2.937, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=5942
2023-06-26 19:58:39 - progress_bar.py[line:272] - INFO: epoch 001:   2894 / 3715 loss=2.504, loss_v1=0, loss_v2=0, nll_loss=1.322, ntokens=1092.1, nsentences=120, sample_size=1092.1, sample_size_v1=0, sample_size_v2=0, ppl=2.5, wps=531.4, ups=0.49, wpb=1092.1, bsz=120, num_updates=2890, lr=2.4313e-05, gnorm=3.264, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=5963
2023-06-26 19:58:59 - progress_bar.py[line:272] - INFO: epoch 001:   2904 / 3715 loss=2.505, loss_v1=0, loss_v2=0, nll_loss=1.324, ntokens=1065.2, nsentences=120, sample_size=1065.2, sample_size_v1=0, sample_size_v2=0, ppl=2.5, wps=518.5, ups=0.49, wpb=1065.2, bsz=120, num_updates=2900, lr=2.43971e-05, gnorm=3.29, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=5984
2023-06-26 19:59:20 - progress_bar.py[line:272] - INFO: epoch 001:   2914 / 3715 loss=2.507, loss_v1=0, loss_v2=0, nll_loss=1.325, ntokens=1094.9, nsentences=120, sample_size=1094.9, sample_size_v1=0, sample_size_v2=0, ppl=2.51, wps=532.3, ups=0.49, wpb=1094.9, bsz=120, num_updates=2910, lr=2.44812e-05, gnorm=3.535, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=6004
2023-06-26 19:59:40 - progress_bar.py[line:272] - INFO: epoch 001:   2924 / 3715 loss=2.507, loss_v1=0, loss_v2=0, nll_loss=1.326, ntokens=1077.8, nsentences=120, sample_size=1077.8, sample_size_v1=0, sample_size_v2=0, ppl=2.51, wps=525.1, ups=0.49, wpb=1077.8, bsz=120, num_updates=2920, lr=2.45653e-05, gnorm=3.566, clip=100, loss_scale=256, train_wall=20, gb_free=8.9, wall=6025
2023-06-26 19:59:42 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 128.0
2023-06-26 20:00:03 - progress_bar.py[line:272] - INFO: epoch 001:   2935 / 3715 loss=2.509, loss_v1=0, loss_v2=0, nll_loss=1.328, ntokens=1095.1, nsentences=120, sample_size=1095.1, sample_size_v1=0, sample_size_v2=0, ppl=2.51, wps=484.4, ups=0.44, wpb=1095.1, bsz=120, num_updates=2930, lr=2.46495e-05, gnorm=3.507, clip=100, loss_scale=128, train_wall=23, gb_free=8.9, wall=6047
2023-06-26 20:00:23 - progress_bar.py[line:272] - INFO: epoch 001:   2945 / 3715 loss=2.508, loss_v1=0, loss_v2=0, nll_loss=1.328, ntokens=1082.7, nsentences=120, sample_size=1082.7, sample_size_v1=0, sample_size_v2=0, ppl=2.51, wps=526.9, ups=0.49, wpb=1082.7, bsz=120, num_updates=2940, lr=2.47336e-05, gnorm=3.371, clip=100, loss_scale=128, train_wall=21, gb_free=8.9, wall=6068
2023-06-26 20:00:44 - progress_bar.py[line:272] - INFO: epoch 001:   2955 / 3715 loss=2.501, loss_v1=0, loss_v2=0, nll_loss=1.321, ntokens=1091.5, nsentences=120, sample_size=1091.5, sample_size_v1=0, sample_size_v2=0, ppl=2.5, wps=530.5, ups=0.49, wpb=1091.5, bsz=120, num_updates=2950, lr=2.48177e-05, gnorm=3.478, clip=100, loss_scale=128, train_wall=21, gb_free=8.9, wall=6088
2023-06-26 20:01:05 - progress_bar.py[line:272] - INFO: epoch 001:   2965 / 3715 loss=2.516, loss_v1=0, loss_v2=0, nll_loss=1.334, ntokens=1079.7, nsentences=120, sample_size=1079.7, sample_size_v1=0, sample_size_v2=0, ppl=2.52, wps=525.1, ups=0.49, wpb=1079.7, bsz=120, num_updates=2960, lr=2.49019e-05, gnorm=3.2, clip=100, loss_scale=128, train_wall=21, gb_free=8.9, wall=6109
2023-06-26 20:01:25 - progress_bar.py[line:272] - INFO: epoch 001:   2975 / 3715 loss=2.5, loss_v1=0, loss_v2=0, nll_loss=1.32, ntokens=1092.3, nsentences=120, sample_size=1092.3, sample_size_v1=0, sample_size_v2=0, ppl=2.5, wps=531, ups=0.49, wpb=1092.3, bsz=120, num_updates=2970, lr=2.4986e-05, gnorm=3.367, clip=100, loss_scale=128, train_wall=21, gb_free=8.9, wall=6130
2023-06-26 20:01:46 - progress_bar.py[line:272] - INFO: epoch 001:   2985 / 3715 loss=2.516, loss_v1=0, loss_v2=0, nll_loss=1.336, ntokens=1085.6, nsentences=120, sample_size=1085.6, sample_size_v1=0, sample_size_v2=0, ppl=2.52, wps=527.9, ups=0.49, wpb=1085.6, bsz=120, num_updates=2980, lr=2.50701e-05, gnorm=3.237, clip=100, loss_scale=128, train_wall=21, gb_free=8.9, wall=6150
2023-06-26 20:02:06 - progress_bar.py[line:272] - INFO: epoch 001:   2995 / 3715 loss=2.507, loss_v1=0, loss_v2=0, nll_loss=1.325, ntokens=1079.4, nsentences=120, sample_size=1079.4, sample_size_v1=0, sample_size_v2=0, ppl=2.51, wps=525.1, ups=0.49, wpb=1079.4, bsz=120, num_updates=2990, lr=2.51542e-05, gnorm=3.29, clip=100, loss_scale=128, train_wall=21, gb_free=8.9, wall=6171
2023-06-26 20:02:27 - progress_bar.py[line:272] - INFO: epoch 001:   3005 / 3715 loss=2.517, loss_v1=0, loss_v2=0, nll_loss=1.338, ntokens=1091.2, nsentences=120, sample_size=1091.2, sample_size_v1=0, sample_size_v2=0, ppl=2.53, wps=531, ups=0.49, wpb=1091.2, bsz=120, num_updates=3000, lr=2.52384e-05, gnorm=3.019, clip=100, loss_scale=128, train_wall=21, gb_free=8.9, wall=6191
2023-06-26 20:02:47 - progress_bar.py[line:272] - INFO: epoch 001:   3015 / 3715 loss=2.517, loss_v1=0, loss_v2=0, nll_loss=1.336, ntokens=1097.8, nsentences=120, sample_size=1097.8, sample_size_v1=0, sample_size_v2=0, ppl=2.52, wps=532.8, ups=0.49, wpb=1097.8, bsz=120, num_updates=3010, lr=2.53225e-05, gnorm=3.078, clip=100, loss_scale=128, train_wall=21, gb_free=8.9, wall=6212
2023-06-26 20:03:08 - progress_bar.py[line:272] - INFO: epoch 001:   3025 / 3715 loss=2.515, loss_v1=0, loss_v2=0, nll_loss=1.337, ntokens=1073.1, nsentences=120, sample_size=1073.1, sample_size_v1=0, sample_size_v2=0, ppl=2.53, wps=522.1, ups=0.49, wpb=1073.1, bsz=120, num_updates=3020, lr=2.54066e-05, gnorm=3.428, clip=100, loss_scale=128, train_wall=21, gb_free=8.9, wall=6232
2023-06-26 20:03:29 - progress_bar.py[line:272] - INFO: epoch 001:   3035 / 3715 loss=2.498, loss_v1=0, loss_v2=0, nll_loss=1.317, ntokens=1065.7, nsentences=120, sample_size=1065.7, sample_size_v1=0, sample_size_v2=0, ppl=2.49, wps=517.5, ups=0.49, wpb=1065.7, bsz=120, num_updates=3030, lr=2.54907e-05, gnorm=3.317, clip=100, loss_scale=128, train_wall=21, gb_free=8.9, wall=6253
2023-06-26 20:03:49 - progress_bar.py[line:272] - INFO: epoch 001:   3045 / 3715 loss=2.49, loss_v1=0, loss_v2=0, nll_loss=1.306, ntokens=1084.4, nsentences=120, sample_size=1084.4, sample_size_v1=0, sample_size_v2=0, ppl=2.47, wps=526.2, ups=0.49, wpb=1084.4, bsz=120, num_updates=3040, lr=2.55749e-05, gnorm=3.125, clip=100, loss_scale=128, train_wall=21, gb_free=8.9, wall=6274
2023-06-26 20:04:10 - progress_bar.py[line:272] - INFO: epoch 001:   3055 / 3715 loss=2.489, loss_v1=0, loss_v2=0, nll_loss=1.306, ntokens=1081.4, nsentences=120, sample_size=1081.4, sample_size_v1=0, sample_size_v2=0, ppl=2.47, wps=525.4, ups=0.49, wpb=1081.4, bsz=120, num_updates=3050, lr=2.5659e-05, gnorm=3.468, clip=100, loss_scale=128, train_wall=21, gb_free=8.9, wall=6294
2023-06-26 20:04:30 - progress_bar.py[line:272] - INFO: epoch 001:   3065 / 3715 loss=2.497, loss_v1=0, loss_v2=0, nll_loss=1.317, ntokens=1082.3, nsentences=120, sample_size=1082.3, sample_size_v1=0, sample_size_v2=0, ppl=2.49, wps=526.1, ups=0.49, wpb=1082.3, bsz=120, num_updates=3060, lr=2.57431e-05, gnorm=3.421, clip=100, loss_scale=128, train_wall=21, gb_free=8.9, wall=6315
2023-06-26 20:04:51 - progress_bar.py[line:272] - INFO: epoch 001:   3075 / 3715 loss=2.511, loss_v1=0, loss_v2=0, nll_loss=1.328, ntokens=1091.4, nsentences=120, sample_size=1091.4, sample_size_v1=0, sample_size_v2=0, ppl=2.51, wps=530.5, ups=0.49, wpb=1091.4, bsz=120, num_updates=3070, lr=2.58273e-05, gnorm=3.688, clip=100, loss_scale=128, train_wall=21, gb_free=8.7, wall=6335
2023-06-26 20:05:12 - progress_bar.py[line:272] - INFO: epoch 001:   3085 / 3715 loss=2.498, loss_v1=0, loss_v2=0, nll_loss=1.317, ntokens=1073.9, nsentences=120, sample_size=1073.9, sample_size_v1=0, sample_size_v2=0, ppl=2.49, wps=522.2, ups=0.49, wpb=1073.9, bsz=120, num_updates=3080, lr=2.59114e-05, gnorm=3.44, clip=100, loss_scale=128, train_wall=21, gb_free=8.9, wall=6356
2023-06-26 20:05:32 - progress_bar.py[line:272] - INFO: epoch 001:   3095 / 3715 loss=2.519, loss_v1=0, loss_v2=0, nll_loss=1.338, ntokens=1063.9, nsentences=120, sample_size=1063.9, sample_size_v1=0, sample_size_v2=0, ppl=2.53, wps=517, ups=0.49, wpb=1063.9, bsz=120, num_updates=3090, lr=2.59955e-05, gnorm=3.395, clip=100, loss_scale=128, train_wall=21, gb_free=8.9, wall=6376
2023-06-26 20:05:53 - progress_bar.py[line:272] - INFO: epoch 001:   3105 / 3715 loss=2.506, loss_v1=0, loss_v2=0, nll_loss=1.326, ntokens=1061.2, nsentences=120, sample_size=1061.2, sample_size_v1=0, sample_size_v2=0, ppl=2.51, wps=515.4, ups=0.49, wpb=1061.2, bsz=120, num_updates=3100, lr=2.60796e-05, gnorm=3.275, clip=100, loss_scale=128, train_wall=21, gb_free=8.9, wall=6397
2023-06-26 20:06:13 - progress_bar.py[line:272] - INFO: epoch 001:   3115 / 3715 loss=2.497, loss_v1=0, loss_v2=0, nll_loss=1.314, ntokens=1083.1, nsentences=120, sample_size=1083.1, sample_size_v1=0, sample_size_v2=0, ppl=2.49, wps=526, ups=0.49, wpb=1083.1, bsz=120, num_updates=3110, lr=2.61638e-05, gnorm=3.266, clip=100, loss_scale=128, train_wall=21, gb_free=8.9, wall=6418
2023-06-26 20:06:34 - progress_bar.py[line:272] - INFO: epoch 001:   3125 / 3715 loss=2.478, loss_v1=0, loss_v2=0, nll_loss=1.294, ntokens=1065, nsentences=120, sample_size=1065, sample_size_v1=0, sample_size_v2=0, ppl=2.45, wps=517.5, ups=0.49, wpb=1065, bsz=120, num_updates=3120, lr=2.62479e-05, gnorm=3.087, clip=100, loss_scale=128, train_wall=21, gb_free=8.9, wall=6438
2023-06-26 20:06:54 - progress_bar.py[line:272] - INFO: epoch 001:   3135 / 3715 loss=2.508, loss_v1=0, loss_v2=0, nll_loss=1.329, ntokens=1084.4, nsentences=120, sample_size=1084.4, sample_size_v1=0, sample_size_v2=0, ppl=2.51, wps=526.6, ups=0.49, wpb=1084.4, bsz=120, num_updates=3130, lr=2.6332e-05, gnorm=3.42, clip=100, loss_scale=128, train_wall=21, gb_free=8.9, wall=6459
2023-06-26 20:07:15 - progress_bar.py[line:272] - INFO: epoch 001:   3145 / 3715 loss=2.497, loss_v1=0, loss_v2=0, nll_loss=1.314, ntokens=1072.9, nsentences=120, sample_size=1072.9, sample_size_v1=0, sample_size_v2=0, ppl=2.49, wps=521.7, ups=0.49, wpb=1072.9, bsz=120, num_updates=3140, lr=2.64162e-05, gnorm=3.516, clip=100, loss_scale=128, train_wall=21, gb_free=8.9, wall=6479
2023-06-26 20:07:36 - progress_bar.py[line:272] - INFO: epoch 001:   3155 / 3715 loss=2.481, loss_v1=0, loss_v2=0, nll_loss=1.298, ntokens=1081.1, nsentences=120, sample_size=1081.1, sample_size_v1=0, sample_size_v2=0, ppl=2.46, wps=525.9, ups=0.49, wpb=1081.1, bsz=120, num_updates=3150, lr=2.65003e-05, gnorm=3.751, clip=100, loss_scale=128, train_wall=21, gb_free=8.9, wall=6500
2023-06-26 20:07:56 - progress_bar.py[line:272] - INFO: epoch 001:   3165 / 3715 loss=2.498, loss_v1=0, loss_v2=0, nll_loss=1.314, ntokens=1100.8, nsentences=120, sample_size=1100.8, sample_size_v1=0, sample_size_v2=0, ppl=2.49, wps=536, ups=0.49, wpb=1100.8, bsz=120, num_updates=3160, lr=2.65844e-05, gnorm=3.652, clip=100, loss_scale=128, train_wall=21, gb_free=8.9, wall=6520
2023-06-26 20:08:17 - progress_bar.py[line:272] - INFO: epoch 001:   3175 / 3715 loss=2.496, loss_v1=0, loss_v2=0, nll_loss=1.317, ntokens=1085, nsentences=120, sample_size=1085, sample_size_v1=0, sample_size_v2=0, ppl=2.49, wps=528, ups=0.49, wpb=1085, bsz=120, num_updates=3170, lr=2.66685e-05, gnorm=3.818, clip=100, loss_scale=128, train_wall=21, gb_free=8.9, wall=6541
2023-06-26 20:08:37 - progress_bar.py[line:272] - INFO: epoch 001:   3185 / 3715 loss=2.484, loss_v1=0, loss_v2=0, nll_loss=1.301, ntokens=1072.1, nsentences=120, sample_size=1072.1, sample_size_v1=0, sample_size_v2=0, ppl=2.46, wps=521.1, ups=0.49, wpb=1072.1, bsz=120, num_updates=3180, lr=2.67527e-05, gnorm=3.434, clip=100, loss_scale=128, train_wall=21, gb_free=8.9, wall=6562
2023-06-26 20:08:58 - progress_bar.py[line:272] - INFO: epoch 001:   3195 / 3715 loss=2.485, loss_v1=0, loss_v2=0, nll_loss=1.299, ntokens=1089.4, nsentences=120, sample_size=1089.4, sample_size_v1=0, sample_size_v2=0, ppl=2.46, wps=529.6, ups=0.49, wpb=1089.4, bsz=120, num_updates=3190, lr=2.68368e-05, gnorm=3.289, clip=100, loss_scale=128, train_wall=21, gb_free=8.9, wall=6582
2023-06-26 20:09:18 - progress_bar.py[line:272] - INFO: epoch 001:   3205 / 3715 loss=2.459, loss_v1=0, loss_v2=0, nll_loss=1.275, ntokens=1073.7, nsentences=120, sample_size=1073.7, sample_size_v1=0, sample_size_v2=0, ppl=2.42, wps=522.9, ups=0.49, wpb=1073.7, bsz=120, num_updates=3200, lr=2.69209e-05, gnorm=3.652, clip=100, loss_scale=128, train_wall=21, gb_free=8.9, wall=6603
2023-06-26 20:09:39 - progress_bar.py[line:272] - INFO: epoch 001:   3215 / 3715 loss=2.478, loss_v1=0, loss_v2=0, nll_loss=1.291, ntokens=1075.1, nsentences=120, sample_size=1075.1, sample_size_v1=0, sample_size_v2=0, ppl=2.45, wps=523.2, ups=0.49, wpb=1075.1, bsz=120, num_updates=3210, lr=2.7005e-05, gnorm=3.836, clip=100, loss_scale=128, train_wall=21, gb_free=8.9, wall=6623
2023-06-26 20:10:00 - progress_bar.py[line:272] - INFO: epoch 001:   3225 / 3715 loss=2.491, loss_v1=0, loss_v2=0, nll_loss=1.309, ntokens=1090.2, nsentences=120, sample_size=1090.2, sample_size_v1=0, sample_size_v2=0, ppl=2.48, wps=529.8, ups=0.49, wpb=1090.2, bsz=120, num_updates=3220, lr=2.70892e-05, gnorm=3.599, clip=100, loss_scale=128, train_wall=21, gb_free=8.9, wall=6644
2023-06-26 20:10:20 - progress_bar.py[line:272] - INFO: epoch 001:   3235 / 3715 loss=2.497, loss_v1=0, loss_v2=0, nll_loss=1.312, ntokens=1078.5, nsentences=120, sample_size=1078.5, sample_size_v1=0, sample_size_v2=0, ppl=2.48, wps=524, ups=0.49, wpb=1078.5, bsz=120, num_updates=3230, lr=2.71733e-05, gnorm=3.514, clip=100, loss_scale=128, train_wall=21, gb_free=8.9, wall=6664
2023-06-26 20:10:41 - progress_bar.py[line:272] - INFO: epoch 001:   3245 / 3715 loss=2.481, loss_v1=0, loss_v2=0, nll_loss=1.297, ntokens=1083.9, nsentences=120, sample_size=1083.9, sample_size_v1=0, sample_size_v2=0, ppl=2.46, wps=526.7, ups=0.49, wpb=1083.9, bsz=120, num_updates=3240, lr=2.72574e-05, gnorm=3.417, clip=100, loss_scale=128, train_wall=21, gb_free=8.9, wall=6685
2023-06-26 20:11:01 - progress_bar.py[line:272] - INFO: epoch 001:   3255 / 3715 loss=2.492, loss_v1=0, loss_v2=0, nll_loss=1.308, ntokens=1080, nsentences=120, sample_size=1080, sample_size_v1=0, sample_size_v2=0, ppl=2.48, wps=524.6, ups=0.49, wpb=1080, bsz=120, num_updates=3250, lr=2.73416e-05, gnorm=3.399, clip=100, loss_scale=128, train_wall=21, gb_free=8.9, wall=6706
2023-06-26 20:11:22 - progress_bar.py[line:272] - INFO: epoch 001:   3265 / 3715 loss=2.504, loss_v1=0, loss_v2=0, nll_loss=1.321, ntokens=1078.5, nsentences=120, sample_size=1078.5, sample_size_v1=0, sample_size_v2=0, ppl=2.5, wps=524.1, ups=0.49, wpb=1078.5, bsz=120, num_updates=3260, lr=2.74257e-05, gnorm=3.304, clip=100, loss_scale=128, train_wall=21, gb_free=8.9, wall=6726
2023-06-26 20:11:42 - progress_bar.py[line:272] - INFO: epoch 001:   3275 / 3715 loss=2.484, loss_v1=0, loss_v2=0, nll_loss=1.3, ntokens=1083.8, nsentences=120, sample_size=1083.8, sample_size_v1=0, sample_size_v2=0, ppl=2.46, wps=526.5, ups=0.49, wpb=1083.8, bsz=120, num_updates=3270, lr=2.75098e-05, gnorm=3.243, clip=100, loss_scale=128, train_wall=21, gb_free=8.9, wall=6747
2023-06-26 20:12:03 - progress_bar.py[line:272] - INFO: epoch 001:   3285 / 3715 loss=2.486, loss_v1=0, loss_v2=0, nll_loss=1.302, ntokens=1073.6, nsentences=120, sample_size=1073.6, sample_size_v1=0, sample_size_v2=0, ppl=2.46, wps=520.8, ups=0.49, wpb=1073.6, bsz=120, num_updates=3280, lr=2.75939e-05, gnorm=3.44, clip=100, loss_scale=128, train_wall=21, gb_free=8.9, wall=6767
2023-06-26 20:12:24 - progress_bar.py[line:272] - INFO: epoch 001:   3295 / 3715 loss=2.481, loss_v1=0, loss_v2=0, nll_loss=1.295, ntokens=1093, nsentences=120, sample_size=1093, sample_size_v1=0, sample_size_v2=0, ppl=2.45, wps=532.1, ups=0.49, wpb=1093, bsz=120, num_updates=3290, lr=2.76781e-05, gnorm=3.316, clip=100, loss_scale=128, train_wall=21, gb_free=8.9, wall=6788
2023-06-26 20:12:44 - progress_bar.py[line:272] - INFO: epoch 001:   3305 / 3715 loss=2.483, loss_v1=0, loss_v2=0, nll_loss=1.299, ntokens=1099.9, nsentences=120, sample_size=1099.9, sample_size_v1=0, sample_size_v2=0, ppl=2.46, wps=535.6, ups=0.49, wpb=1099.9, bsz=120, num_updates=3300, lr=2.77622e-05, gnorm=3.272, clip=100, loss_scale=128, train_wall=21, gb_free=8.9, wall=6808
2023-06-26 20:13:05 - progress_bar.py[line:272] - INFO: epoch 001:   3315 / 3715 loss=2.489, loss_v1=0, loss_v2=0, nll_loss=1.306, ntokens=1061.9, nsentences=120, sample_size=1061.9, sample_size_v1=0, sample_size_v2=0, ppl=2.47, wps=517, ups=0.49, wpb=1061.9, bsz=120, num_updates=3310, lr=2.78463e-05, gnorm=3.477, clip=100, loss_scale=128, train_wall=21, gb_free=8.9, wall=6829
2023-06-26 20:13:25 - progress_bar.py[line:272] - INFO: epoch 001:   3325 / 3715 loss=2.485, loss_v1=0, loss_v2=0, nll_loss=1.3, ntokens=1085.2, nsentences=120, sample_size=1085.2, sample_size_v1=0, sample_size_v2=0, ppl=2.46, wps=528.2, ups=0.49, wpb=1085.2, bsz=120, num_updates=3320, lr=2.79305e-05, gnorm=3.24, clip=100, loss_scale=128, train_wall=21, gb_free=8.9, wall=6850
2023-06-26 20:13:46 - progress_bar.py[line:272] - INFO: epoch 001:   3335 / 3715 loss=2.48, loss_v1=0, loss_v2=0, nll_loss=1.295, ntokens=1084.1, nsentences=120, sample_size=1084.1, sample_size_v1=0, sample_size_v2=0, ppl=2.45, wps=527.4, ups=0.49, wpb=1084.1, bsz=120, num_updates=3330, lr=2.80146e-05, gnorm=3.394, clip=100, loss_scale=128, train_wall=21, gb_free=8.9, wall=6870
2023-06-26 20:14:06 - progress_bar.py[line:272] - INFO: epoch 001:   3345 / 3715 loss=2.483, loss_v1=0, loss_v2=0, nll_loss=1.298, ntokens=1090.5, nsentences=120, sample_size=1090.5, sample_size_v1=0, sample_size_v2=0, ppl=2.46, wps=530.8, ups=0.49, wpb=1090.5, bsz=120, num_updates=3340, lr=2.80987e-05, gnorm=3.479, clip=100, loss_scale=128, train_wall=21, gb_free=8.9, wall=6891
2023-06-26 20:14:27 - progress_bar.py[line:272] - INFO: epoch 001:   3355 / 3715 loss=2.464, loss_v1=0, loss_v2=0, nll_loss=1.277, ntokens=1088.4, nsentences=120, sample_size=1088.4, sample_size_v1=0, sample_size_v2=0, ppl=2.42, wps=528.1, ups=0.49, wpb=1088.4, bsz=120, num_updates=3350, lr=2.81828e-05, gnorm=3.331, clip=100, loss_scale=128, train_wall=21, gb_free=8.9, wall=6911
2023-06-26 20:14:48 - progress_bar.py[line:272] - INFO: epoch 001:   3365 / 3715 loss=2.494, loss_v1=0, loss_v2=0, nll_loss=1.31, ntokens=1106.7, nsentences=120, sample_size=1106.7, sample_size_v1=0, sample_size_v2=0, ppl=2.48, wps=538, ups=0.49, wpb=1106.7, bsz=120, num_updates=3360, lr=2.8267e-05, gnorm=3.792, clip=100, loss_scale=128, train_wall=21, gb_free=8.9, wall=6932
2023-06-26 20:15:08 - progress_bar.py[line:272] - INFO: epoch 001:   3375 / 3715 loss=2.488, loss_v1=0, loss_v2=0, nll_loss=1.304, ntokens=1072.9, nsentences=120, sample_size=1072.9, sample_size_v1=0, sample_size_v2=0, ppl=2.47, wps=521.8, ups=0.49, wpb=1072.9, bsz=120, num_updates=3370, lr=2.83511e-05, gnorm=3.374, clip=100, loss_scale=128, train_wall=21, gb_free=8.9, wall=6952
2023-06-26 20:15:29 - progress_bar.py[line:272] - INFO: epoch 001:   3385 / 3715 loss=2.486, loss_v1=0, loss_v2=0, nll_loss=1.301, ntokens=1090.4, nsentences=120, sample_size=1090.4, sample_size_v1=0, sample_size_v2=0, ppl=2.46, wps=530.1, ups=0.49, wpb=1090.4, bsz=120, num_updates=3380, lr=2.84352e-05, gnorm=3.559, clip=100, loss_scale=128, train_wall=21, gb_free=8.9, wall=6973
2023-06-26 20:15:49 - progress_bar.py[line:272] - INFO: epoch 001:   3395 / 3715 loss=2.488, loss_v1=0, loss_v2=0, nll_loss=1.305, ntokens=1086.1, nsentences=120, sample_size=1086.1, sample_size_v1=0, sample_size_v2=0, ppl=2.47, wps=527.6, ups=0.49, wpb=1086.1, bsz=120, num_updates=3390, lr=2.85193e-05, gnorm=3.817, clip=100, loss_scale=128, train_wall=21, gb_free=8.9, wall=6994
2023-06-26 20:16:10 - progress_bar.py[line:272] - INFO: epoch 001:   3405 / 3715 loss=2.485, loss_v1=0, loss_v2=0, nll_loss=1.299, ntokens=1074.6, nsentences=120, sample_size=1074.6, sample_size_v1=0, sample_size_v2=0, ppl=2.46, wps=522.1, ups=0.49, wpb=1074.6, bsz=120, num_updates=3400, lr=2.86035e-05, gnorm=4.011, clip=100, loss_scale=128, train_wall=21, gb_free=8.9, wall=7014
2023-06-26 20:16:30 - progress_bar.py[line:272] - INFO: epoch 001:   3415 / 3715 loss=2.472, loss_v1=0, loss_v2=0, nll_loss=1.285, ntokens=1080.2, nsentences=120, sample_size=1080.2, sample_size_v1=0, sample_size_v2=0, ppl=2.44, wps=524.2, ups=0.49, wpb=1080.2, bsz=120, num_updates=3410, lr=2.86876e-05, gnorm=3.587, clip=100, loss_scale=128, train_wall=21, gb_free=8.9, wall=7035
2023-06-26 20:16:51 - progress_bar.py[line:272] - INFO: epoch 001:   3425 / 3715 loss=2.467, loss_v1=0, loss_v2=0, nll_loss=1.28, ntokens=1071.5, nsentences=120, sample_size=1071.5, sample_size_v1=0, sample_size_v2=0, ppl=2.43, wps=520.6, ups=0.49, wpb=1071.5, bsz=120, num_updates=3420, lr=2.87717e-05, gnorm=3.481, clip=100, loss_scale=128, train_wall=21, gb_free=8.9, wall=7055
2023-06-26 20:17:12 - progress_bar.py[line:272] - INFO: epoch 001:   3435 / 3715 loss=2.487, loss_v1=0, loss_v2=0, nll_loss=1.301, ntokens=1074.4, nsentences=120, sample_size=1074.4, sample_size_v1=0, sample_size_v2=0, ppl=2.46, wps=521.8, ups=0.49, wpb=1074.4, bsz=120, num_updates=3430, lr=2.88559e-05, gnorm=3.501, clip=100, loss_scale=128, train_wall=21, gb_free=8.9, wall=7076
2023-06-26 20:17:32 - progress_bar.py[line:272] - INFO: epoch 001:   3445 / 3715 loss=2.453, loss_v1=0, loss_v2=0, nll_loss=1.267, ntokens=1072.1, nsentences=120, sample_size=1072.1, sample_size_v1=0, sample_size_v2=0, ppl=2.41, wps=520.7, ups=0.49, wpb=1072.1, bsz=120, num_updates=3440, lr=2.894e-05, gnorm=3.346, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=7097
2023-06-26 20:17:53 - progress_bar.py[line:272] - INFO: epoch 001:   3455 / 3715 loss=2.478, loss_v1=0, loss_v2=0, nll_loss=1.289, ntokens=1091, nsentences=120, sample_size=1091, sample_size_v1=0, sample_size_v2=0, ppl=2.44, wps=530.8, ups=0.49, wpb=1091, bsz=120, num_updates=3450, lr=2.90241e-05, gnorm=3.488, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=7117
2023-06-26 20:18:13 - progress_bar.py[line:272] - INFO: epoch 001:   3465 / 3715 loss=2.463, loss_v1=0, loss_v2=0, nll_loss=1.28, ntokens=1069.1, nsentences=120, sample_size=1069.1, sample_size_v1=0, sample_size_v2=0, ppl=2.43, wps=520.1, ups=0.49, wpb=1069.1, bsz=120, num_updates=3460, lr=2.91082e-05, gnorm=3.863, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=7138
2023-06-26 20:18:34 - progress_bar.py[line:272] - INFO: epoch 001:   3475 / 3715 loss=2.465, loss_v1=0, loss_v2=0, nll_loss=1.274, ntokens=1082.8, nsentences=120, sample_size=1082.8, sample_size_v1=0, sample_size_v2=0, ppl=2.42, wps=527.1, ups=0.49, wpb=1082.8, bsz=120, num_updates=3470, lr=2.91924e-05, gnorm=3.104, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=7158
2023-06-26 20:18:54 - progress_bar.py[line:272] - INFO: epoch 001:   3485 / 3715 loss=2.48, loss_v1=0, loss_v2=0, nll_loss=1.296, ntokens=1089.1, nsentences=120, sample_size=1089.1, sample_size_v1=0, sample_size_v2=0, ppl=2.46, wps=530.5, ups=0.49, wpb=1089.1, bsz=120, num_updates=3480, lr=2.92765e-05, gnorm=3.538, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=7179
2023-06-26 20:19:15 - progress_bar.py[line:272] - INFO: epoch 001:   3495 / 3715 loss=2.468, loss_v1=0, loss_v2=0, nll_loss=1.284, ntokens=1099.9, nsentences=120, sample_size=1099.9, sample_size_v1=0, sample_size_v2=0, ppl=2.43, wps=535.3, ups=0.49, wpb=1099.9, bsz=120, num_updates=3490, lr=2.93606e-05, gnorm=3.337, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=7199
2023-06-26 20:19:35 - progress_bar.py[line:272] - INFO: epoch 001:   3505 / 3715 loss=2.478, loss_v1=0, loss_v2=0, nll_loss=1.29, ntokens=1100.3, nsentences=120, sample_size=1100.3, sample_size_v1=0, sample_size_v2=0, ppl=2.45, wps=536.2, ups=0.49, wpb=1100.3, bsz=120, num_updates=3500, lr=2.94448e-05, gnorm=3.186, clip=100, loss_scale=256, train_wall=20, gb_free=8.9, wall=7220
2023-06-26 20:19:56 - progress_bar.py[line:272] - INFO: epoch 001:   3515 / 3715 loss=2.485, loss_v1=0, loss_v2=0, nll_loss=1.3, ntokens=1077, nsentences=120, sample_size=1077, sample_size_v1=0, sample_size_v2=0, ppl=2.46, wps=524.4, ups=0.49, wpb=1077, bsz=120, num_updates=3510, lr=2.95289e-05, gnorm=3.48, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=7240
2023-06-26 20:20:17 - progress_bar.py[line:272] - INFO: epoch 001:   3525 / 3715 loss=2.477, loss_v1=0, loss_v2=0, nll_loss=1.29, ntokens=1076.4, nsentences=120, sample_size=1076.4, sample_size_v1=0, sample_size_v2=0, ppl=2.45, wps=523.6, ups=0.49, wpb=1076.4, bsz=120, num_updates=3520, lr=2.9613e-05, gnorm=3.532, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=7261
2023-06-26 20:20:37 - progress_bar.py[line:272] - INFO: epoch 001:   3535 / 3715 loss=2.472, loss_v1=0, loss_v2=0, nll_loss=1.286, ntokens=1076.4, nsentences=120, sample_size=1076.4, sample_size_v1=0, sample_size_v2=0, ppl=2.44, wps=523.6, ups=0.49, wpb=1076.4, bsz=120, num_updates=3530, lr=2.96971e-05, gnorm=3.745, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=7282
2023-06-26 20:20:58 - progress_bar.py[line:272] - INFO: epoch 001:   3545 / 3715 loss=2.458, loss_v1=0, loss_v2=0, nll_loss=1.271, ntokens=1099.5, nsentences=120, sample_size=1099.5, sample_size_v1=0, sample_size_v2=0, ppl=2.41, wps=533.9, ups=0.49, wpb=1099.5, bsz=120, num_updates=3540, lr=2.97813e-05, gnorm=3.356, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=7302
2023-06-26 20:21:18 - progress_bar.py[line:272] - INFO: epoch 001:   3555 / 3715 loss=2.48, loss_v1=0, loss_v2=0, nll_loss=1.292, ntokens=1077.8, nsentences=120, sample_size=1077.8, sample_size_v1=0, sample_size_v2=0, ppl=2.45, wps=524.1, ups=0.49, wpb=1077.8, bsz=120, num_updates=3550, lr=2.98654e-05, gnorm=3.433, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=7323
2023-06-26 20:21:39 - progress_bar.py[line:272] - INFO: epoch 001:   3565 / 3715 loss=2.471, loss_v1=0, loss_v2=0, nll_loss=1.288, ntokens=1062.1, nsentences=120, sample_size=1062.1, sample_size_v1=0, sample_size_v2=0, ppl=2.44, wps=515.9, ups=0.49, wpb=1062.1, bsz=120, num_updates=3560, lr=2.99495e-05, gnorm=3.447, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=7343
2023-06-26 20:21:59 - progress_bar.py[line:272] - INFO: epoch 001:   3575 / 3715 loss=2.458, loss_v1=0, loss_v2=0, nll_loss=1.268, ntokens=1119.3, nsentences=120, sample_size=1119.3, sample_size_v1=0, sample_size_v2=0, ppl=2.41, wps=544, ups=0.49, wpb=1119.3, bsz=120, num_updates=3570, lr=2.99979e-05, gnorm=3.337, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=7364
2023-06-26 20:22:20 - progress_bar.py[line:272] - INFO: epoch 001:   3585 / 3715 loss=2.451, loss_v1=0, loss_v2=0, nll_loss=1.262, ntokens=1095.4, nsentences=120, sample_size=1095.4, sample_size_v1=0, sample_size_v2=0, ppl=2.4, wps=531.9, ups=0.49, wpb=1095.4, bsz=120, num_updates=3580, lr=2.99925e-05, gnorm=3.484, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=7384
2023-06-26 20:22:41 - progress_bar.py[line:272] - INFO: epoch 001:   3595 / 3715 loss=2.484, loss_v1=0, loss_v2=0, nll_loss=1.3, ntokens=1114.6, nsentences=120, sample_size=1114.6, sample_size_v1=0, sample_size_v2=0, ppl=2.46, wps=540.9, ups=0.49, wpb=1114.6, bsz=120, num_updates=3590, lr=2.99871e-05, gnorm=3.612, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=7405
2023-06-26 20:23:01 - progress_bar.py[line:272] - INFO: epoch 001:   3605 / 3715 loss=2.469, loss_v1=0, loss_v2=0, nll_loss=1.281, ntokens=1066.1, nsentences=120, sample_size=1066.1, sample_size_v1=0, sample_size_v2=0, ppl=2.43, wps=518.5, ups=0.49, wpb=1066.1, bsz=120, num_updates=3600, lr=2.99817e-05, gnorm=3.372, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=7426
2023-06-26 20:23:22 - progress_bar.py[line:272] - INFO: epoch 001:   3615 / 3715 loss=2.467, loss_v1=0, loss_v2=0, nll_loss=1.282, ntokens=1081, nsentences=120, sample_size=1081, sample_size_v1=0, sample_size_v2=0, ppl=2.43, wps=525.8, ups=0.49, wpb=1081, bsz=120, num_updates=3610, lr=2.99764e-05, gnorm=3.537, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=7446
2023-06-26 20:23:42 - progress_bar.py[line:272] - INFO: epoch 001:   3625 / 3715 loss=2.472, loss_v1=0, loss_v2=0, nll_loss=1.283, ntokens=1067.8, nsentences=120, sample_size=1067.8, sample_size_v1=0, sample_size_v2=0, ppl=2.43, wps=519.9, ups=0.49, wpb=1067.8, bsz=120, num_updates=3620, lr=2.9971e-05, gnorm=3.55, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=7467
2023-06-26 20:24:03 - progress_bar.py[line:272] - INFO: epoch 001:   3635 / 3715 loss=2.468, loss_v1=0, loss_v2=0, nll_loss=1.279, ntokens=1089.5, nsentences=120, sample_size=1089.5, sample_size_v1=0, sample_size_v2=0, ppl=2.43, wps=529.5, ups=0.49, wpb=1089.5, bsz=120, num_updates=3630, lr=2.99656e-05, gnorm=3.409, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=7487
2023-06-26 20:24:24 - progress_bar.py[line:272] - INFO: epoch 001:   3645 / 3715 loss=2.474, loss_v1=0, loss_v2=0, nll_loss=1.288, ntokens=1072.7, nsentences=120, sample_size=1072.7, sample_size_v1=0, sample_size_v2=0, ppl=2.44, wps=521.8, ups=0.49, wpb=1072.7, bsz=120, num_updates=3640, lr=2.99603e-05, gnorm=3.419, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=7508
2023-06-26 20:24:44 - progress_bar.py[line:272] - INFO: epoch 001:   3655 / 3715 loss=2.47, loss_v1=0, loss_v2=0, nll_loss=1.286, ntokens=1073.7, nsentences=120, sample_size=1073.7, sample_size_v1=0, sample_size_v2=0, ppl=2.44, wps=523.1, ups=0.49, wpb=1073.7, bsz=120, num_updates=3650, lr=2.99549e-05, gnorm=3.478, clip=100, loss_scale=256, train_wall=20, gb_free=8.9, wall=7528
2023-06-26 20:25:05 - progress_bar.py[line:272] - INFO: epoch 001:   3665 / 3715 loss=2.47, loss_v1=0, loss_v2=0, nll_loss=1.281, ntokens=1079.9, nsentences=120, sample_size=1079.9, sample_size_v1=0, sample_size_v2=0, ppl=2.43, wps=525.8, ups=0.49, wpb=1079.9, bsz=120, num_updates=3660, lr=2.99495e-05, gnorm=3.728, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=7549
2023-06-26 20:25:25 - progress_bar.py[line:272] - INFO: epoch 001:   3675 / 3715 loss=2.452, loss_v1=0, loss_v2=0, nll_loss=1.264, ntokens=1086.6, nsentences=120, sample_size=1086.6, sample_size_v1=0, sample_size_v2=0, ppl=2.4, wps=528.8, ups=0.49, wpb=1086.6, bsz=120, num_updates=3670, lr=2.99442e-05, gnorm=3.598, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=7569
2023-06-26 20:25:46 - progress_bar.py[line:272] - INFO: epoch 001:   3685 / 3715 loss=2.444, loss_v1=0, loss_v2=0, nll_loss=1.253, ntokens=1082.4, nsentences=120, sample_size=1082.4, sample_size_v1=0, sample_size_v2=0, ppl=2.38, wps=527.1, ups=0.49, wpb=1082.4, bsz=120, num_updates=3680, lr=2.99388e-05, gnorm=3.309, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=7590
2023-06-26 20:26:06 - progress_bar.py[line:272] - INFO: epoch 001:   3695 / 3715 loss=2.457, loss_v1=0, loss_v2=0, nll_loss=1.27, ntokens=1088.6, nsentences=120, sample_size=1088.6, sample_size_v1=0, sample_size_v2=0, ppl=2.41, wps=529.4, ups=0.49, wpb=1088.6, bsz=120, num_updates=3690, lr=2.99334e-05, gnorm=3.39, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=7611
2023-06-26 20:26:27 - progress_bar.py[line:272] - INFO: epoch 001:   3705 / 3715 loss=2.45, loss_v1=0, loss_v2=0, nll_loss=1.263, ntokens=1088.4, nsentences=120, sample_size=1088.4, sample_size_v1=0, sample_size_v2=0, ppl=2.4, wps=529, ups=0.49, wpb=1088.4, bsz=120, num_updates=3700, lr=2.99281e-05, gnorm=3.649, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=7631
local datafile ../../dataset/OFA_data/vrd_balanced/vg_train_full.tsv slice_id 1 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../dataset/OFA_data/vrd_balanced/vg_train_full.tsv slice_id 2 begin to initialize row_count and line_idx-to-offset mapping
2023-06-26 20:26:47 - progress_bar.py[line:272] - INFO: epoch 001:   3715 / 3715 loss=2.454, loss_v1=0, loss_v2=0, nll_loss=1.26, ntokens=1087.5, nsentences=120, sample_size=1087.5, sample_size_v1=0, sample_size_v2=0, ppl=2.4, wps=529.3, ups=0.49, wpb=1087.5, bsz=120, num_updates=3710, lr=2.99227e-05, gnorm=3.336, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=7652
2023-06-26 20:26:47 - train.py[line:332] - INFO: end of epoch 1 (average epoch stats below)
2023-06-26 20:26:47 - progress_bar.py[line:282] - INFO: epoch 001 | loss 3.268 | loss_v1 0 | loss_v2 0 | nll_loss 2.215 | ntokens 1083.38 | nsentences 119.996 | sample_size 1083.38 | sample_size_v1 0 | sample_size_v2 0 | ppl 4.64 | wps 525.9 | ups 0.49 | wpb 1083.4 | bsz 120 | num_updates 3710 | lr 2.99227e-05 | gnorm 2.891 | clip 100 | loss_scale 256 | train_wall 7632 | gb_free 8.9 | wall 7652
2023-06-26 20:26:47 - trainer.py[line:639] - INFO: loading train data for epoch 2
local datafile ../../dataset/OFA_data/vrd_balanced/vg_train_full.tsv slice_id 0 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../dataset/OFA_data/vrd_balanced/vg_train_full.tsv slice_id 1 finished initializing row_count and line_idx-to-offset mapping
file ../../dataset/OFA_data/vrd_balanced/vg_train_full.tsv slice_id 1 row count 148595 total row count 445785
local datafile ../../dataset/OFA_data/vrd_balanced/vg_train_full.tsv slice_id 2 finished initializing row_count and line_idx-to-offset mapping
file ../../dataset/OFA_data/vrd_balanced/vg_train_full.tsv slice_id 2 row count 148595 total row count 445785
local datafile ../../dataset/OFA_data/vrd_balanced/vg_train_full.tsv slice_id 0 finished initializing row_count and line_idx-to-offset mapping
file ../../dataset/OFA_data/vrd_balanced/vg_train_full.tsv slice_id 0 row count 148595 total row count 445785
/data/hulab/zcai75/anaconda3/envs/vilt/lib/python3.8/site-packages/torchvision/transforms/transforms.py:332: UserWarning: Argument 'interpolation' of type int is deprecated since 0.13 and will be removed in 0.15. Please use InterpolationMode enum.
  warnings.warn(
slice_id 0 seek offset 0
slice_id 2 seek offset 297190
slice_id 1 seek offset 148595
2023-06-26 20:26:48 - trainer.py[line:703] - INFO: begin training epoch 2
2023-06-26 20:26:48 - train.py[line:305] - INFO: Start iterating over samples
2023-06-26 20:27:09 - progress_bar.py[line:272] - INFO: epoch 002:     10 / 3715 loss=2.46, loss_v1=0, loss_v2=0, nll_loss=1.274, ntokens=1087.3, nsentences=120, sample_size=1087.3, sample_size_v1=0, sample_size_v2=0, ppl=2.42, wps=513.8, ups=0.47, wpb=1087.3, bsz=120, num_updates=3720, lr=2.99173e-05, gnorm=3.554, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=7673
2023-06-26 20:27:29 - progress_bar.py[line:272] - INFO: epoch 002:     20 / 3715 loss=2.431, loss_v1=0, loss_v2=0, nll_loss=1.24, ntokens=1074.9, nsentences=120, sample_size=1074.9, sample_size_v1=0, sample_size_v2=0, ppl=2.36, wps=522.6, ups=0.49, wpb=1074.9, bsz=120, num_updates=3730, lr=2.99119e-05, gnorm=3.405, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=7693
2023-06-26 20:27:50 - progress_bar.py[line:272] - INFO: epoch 002:     30 / 3715 loss=2.464, loss_v1=0, loss_v2=0, nll_loss=1.277, ntokens=1091.6, nsentences=120, sample_size=1091.6, sample_size_v1=0, sample_size_v2=0, ppl=2.42, wps=529.4, ups=0.49, wpb=1091.6, bsz=120, num_updates=3740, lr=2.99066e-05, gnorm=3.323, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=7714
2023-06-26 20:28:10 - progress_bar.py[line:272] - INFO: epoch 002:     40 / 3715 loss=2.478, loss_v1=0, loss_v2=0, nll_loss=1.289, ntokens=1092.4, nsentences=120, sample_size=1092.4, sample_size_v1=0, sample_size_v2=0, ppl=2.44, wps=530.9, ups=0.49, wpb=1092.4, bsz=120, num_updates=3750, lr=2.99012e-05, gnorm=3.29, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=7735
2023-06-26 20:28:31 - progress_bar.py[line:272] - INFO: epoch 002:     50 / 3715 loss=2.453, loss_v1=0, loss_v2=0, nll_loss=1.265, ntokens=1082.6, nsentences=120, sample_size=1082.6, sample_size_v1=0, sample_size_v2=0, ppl=2.4, wps=526.7, ups=0.49, wpb=1082.6, bsz=120, num_updates=3760, lr=2.98958e-05, gnorm=3.375, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=7755
2023-06-26 20:28:51 - progress_bar.py[line:272] - INFO: epoch 002:     60 / 3715 loss=2.452, loss_v1=0, loss_v2=0, nll_loss=1.266, ntokens=1073.3, nsentences=120, sample_size=1073.3, sample_size_v1=0, sample_size_v2=0, ppl=2.4, wps=522, ups=0.49, wpb=1073.3, bsz=120, num_updates=3770, lr=2.98905e-05, gnorm=3.647, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=7776
2023-06-26 20:29:12 - progress_bar.py[line:272] - INFO: epoch 002:     70 / 3715 loss=2.446, loss_v1=0, loss_v2=0, nll_loss=1.251, ntokens=1080.3, nsentences=120, sample_size=1080.3, sample_size_v1=0, sample_size_v2=0, ppl=2.38, wps=525.2, ups=0.49, wpb=1080.3, bsz=120, num_updates=3780, lr=2.98851e-05, gnorm=3.525, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=7796
2023-06-26 20:29:33 - progress_bar.py[line:272] - INFO: epoch 002:     80 / 3715 loss=2.468, loss_v1=0, loss_v2=0, nll_loss=1.283, ntokens=1071, nsentences=120, sample_size=1071, sample_size_v1=0, sample_size_v2=0, ppl=2.43, wps=520.8, ups=0.49, wpb=1071, bsz=120, num_updates=3790, lr=2.98797e-05, gnorm=3.384, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=7817
2023-06-26 20:29:53 - progress_bar.py[line:272] - INFO: epoch 002:     90 / 3715 loss=2.462, loss_v1=0, loss_v2=0, nll_loss=1.271, ntokens=1089.7, nsentences=120, sample_size=1089.7, sample_size_v1=0, sample_size_v2=0, ppl=2.41, wps=529.5, ups=0.49, wpb=1089.7, bsz=120, num_updates=3800, lr=2.98744e-05, gnorm=3.755, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=7838
2023-06-26 20:30:14 - progress_bar.py[line:272] - INFO: epoch 002:    100 / 3715 loss=2.449, loss_v1=0, loss_v2=0, nll_loss=1.261, ntokens=1099.5, nsentences=120, sample_size=1099.5, sample_size_v1=0, sample_size_v2=0, ppl=2.4, wps=534.4, ups=0.49, wpb=1099.5, bsz=120, num_updates=3810, lr=2.9869e-05, gnorm=3.525, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=7858
2023-06-26 20:30:34 - progress_bar.py[line:272] - INFO: epoch 002:    110 / 3715 loss=2.458, loss_v1=0, loss_v2=0, nll_loss=1.269, ntokens=1094.3, nsentences=120, sample_size=1094.3, sample_size_v1=0, sample_size_v2=0, ppl=2.41, wps=531.7, ups=0.49, wpb=1094.3, bsz=120, num_updates=3820, lr=2.98636e-05, gnorm=3.501, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=7879
2023-06-26 20:30:55 - progress_bar.py[line:272] - INFO: epoch 002:    120 / 3715 loss=2.451, loss_v1=0, loss_v2=0, nll_loss=1.261, ntokens=1095, nsentences=120, sample_size=1095, sample_size_v1=0, sample_size_v2=0, ppl=2.4, wps=532.2, ups=0.49, wpb=1095, bsz=120, num_updates=3830, lr=2.98583e-05, gnorm=3.711, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=7899
2023-06-26 20:31:15 - progress_bar.py[line:272] - INFO: epoch 002:    130 / 3715 loss=2.442, loss_v1=0, loss_v2=0, nll_loss=1.251, ntokens=1075.3, nsentences=120, sample_size=1075.3, sample_size_v1=0, sample_size_v2=0, ppl=2.38, wps=522.4, ups=0.49, wpb=1075.3, bsz=120, num_updates=3840, lr=2.98529e-05, gnorm=3.718, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=7920
2023-06-26 20:31:36 - progress_bar.py[line:272] - INFO: epoch 002:    140 / 3715 loss=2.455, loss_v1=0, loss_v2=0, nll_loss=1.266, ntokens=1092.9, nsentences=120, sample_size=1092.9, sample_size_v1=0, sample_size_v2=0, ppl=2.4, wps=531.7, ups=0.49, wpb=1092.9, bsz=120, num_updates=3850, lr=2.98475e-05, gnorm=3.55, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=7940
2023-06-26 20:31:57 - progress_bar.py[line:272] - INFO: epoch 002:    150 / 3715 loss=2.448, loss_v1=0, loss_v2=0, nll_loss=1.258, ntokens=1077.7, nsentences=120, sample_size=1077.7, sample_size_v1=0, sample_size_v2=0, ppl=2.39, wps=523.8, ups=0.49, wpb=1077.7, bsz=120, num_updates=3860, lr=2.98421e-05, gnorm=3.572, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=7961
2023-06-26 20:32:17 - progress_bar.py[line:272] - INFO: epoch 002:    160 / 3715 loss=2.447, loss_v1=0, loss_v2=0, nll_loss=1.255, ntokens=1074.5, nsentences=120, sample_size=1074.5, sample_size_v1=0, sample_size_v2=0, ppl=2.39, wps=522.3, ups=0.49, wpb=1074.5, bsz=120, num_updates=3870, lr=2.98368e-05, gnorm=3.646, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=7982
2023-06-26 20:32:38 - progress_bar.py[line:272] - INFO: epoch 002:    170 / 3715 loss=2.448, loss_v1=0, loss_v2=0, nll_loss=1.259, ntokens=1091.3, nsentences=120, sample_size=1091.3, sample_size_v1=0, sample_size_v2=0, ppl=2.39, wps=531.3, ups=0.49, wpb=1091.3, bsz=120, num_updates=3880, lr=2.98314e-05, gnorm=3.585, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=8002
2023-06-26 20:32:58 - progress_bar.py[line:272] - INFO: epoch 002:    180 / 3715 loss=2.444, loss_v1=0, loss_v2=0, nll_loss=1.254, ntokens=1111.3, nsentences=120, sample_size=1111.3, sample_size_v1=0, sample_size_v2=0, ppl=2.39, wps=540.3, ups=0.49, wpb=1111.3, bsz=120, num_updates=3890, lr=2.9826e-05, gnorm=3.715, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=8023
2023-06-26 20:33:19 - progress_bar.py[line:272] - INFO: epoch 002:    190 / 3715 loss=2.443, loss_v1=0, loss_v2=0, nll_loss=1.249, ntokens=1076.4, nsentences=120, sample_size=1076.4, sample_size_v1=0, sample_size_v2=0, ppl=2.38, wps=523.7, ups=0.49, wpb=1076.4, bsz=120, num_updates=3900, lr=2.98207e-05, gnorm=3.658, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=8043
2023-06-26 20:33:39 - progress_bar.py[line:272] - INFO: epoch 002:    200 / 3715 loss=2.434, loss_v1=0, loss_v2=0, nll_loss=1.242, ntokens=1066.6, nsentences=120, sample_size=1066.6, sample_size_v1=0, sample_size_v2=0, ppl=2.37, wps=519.7, ups=0.49, wpb=1066.6, bsz=120, num_updates=3910, lr=2.98153e-05, gnorm=3.62, clip=100, loss_scale=256, train_wall=20, gb_free=8.9, wall=8064
2023-06-26 20:34:00 - progress_bar.py[line:272] - INFO: epoch 002:    210 / 3715 loss=2.436, loss_v1=0, loss_v2=0, nll_loss=1.247, ntokens=1067.4, nsentences=120, sample_size=1067.4, sample_size_v1=0, sample_size_v2=0, ppl=2.37, wps=519.6, ups=0.49, wpb=1067.4, bsz=120, num_updates=3920, lr=2.98099e-05, gnorm=3.595, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=8084
2023-06-26 20:34:21 - progress_bar.py[line:272] - INFO: epoch 002:    220 / 3715 loss=2.444, loss_v1=0, loss_v2=0, nll_loss=1.253, ntokens=1093.8, nsentences=120, sample_size=1093.8, sample_size_v1=0, sample_size_v2=0, ppl=2.38, wps=531.9, ups=0.49, wpb=1093.8, bsz=120, num_updates=3930, lr=2.98046e-05, gnorm=3.665, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=8105
2023-06-26 20:34:41 - progress_bar.py[line:272] - INFO: epoch 002:    230 / 3715 loss=2.443, loss_v1=0, loss_v2=0, nll_loss=1.252, ntokens=1076.7, nsentences=120, sample_size=1076.7, sample_size_v1=0, sample_size_v2=0, ppl=2.38, wps=522.9, ups=0.49, wpb=1076.7, bsz=120, num_updates=3940, lr=2.97992e-05, gnorm=3.75, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=8125
2023-06-26 20:34:51 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 256.0
2023-06-26 20:35:04 - progress_bar.py[line:272] - INFO: epoch 002:    241 / 3715 loss=2.44, loss_v1=0, loss_v2=0, nll_loss=1.249, ntokens=1071.1, nsentences=120, sample_size=1071.1, sample_size_v1=0, sample_size_v2=0, ppl=2.38, wps=473.4, ups=0.44, wpb=1071.1, bsz=120, num_updates=3950, lr=2.97938e-05, gnorm=3.76, clip=100, loss_scale=256, train_wall=23, gb_free=8.9, wall=8148
2023-06-26 20:35:24 - progress_bar.py[line:272] - INFO: epoch 002:    251 / 3715 loss=2.441, loss_v1=0, loss_v2=0, nll_loss=1.251, ntokens=1096.2, nsentences=120, sample_size=1096.2, sample_size_v1=0, sample_size_v2=0, ppl=2.38, wps=532.6, ups=0.49, wpb=1096.2, bsz=120, num_updates=3960, lr=2.97885e-05, gnorm=3.561, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=8169
2023-06-26 20:35:45 - progress_bar.py[line:272] - INFO: epoch 002:    261 / 3715 loss=2.425, loss_v1=0, loss_v2=0, nll_loss=1.233, ntokens=1067.3, nsentences=120, sample_size=1067.3, sample_size_v1=0, sample_size_v2=0, ppl=2.35, wps=518.7, ups=0.49, wpb=1067.3, bsz=120, num_updates=3970, lr=2.97831e-05, gnorm=3.534, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=8189
2023-06-26 20:36:05 - progress_bar.py[line:272] - INFO: epoch 002:    271 / 3715 loss=2.442, loss_v1=0, loss_v2=0, nll_loss=1.25, ntokens=1084.2, nsentences=120, sample_size=1084.2, sample_size_v1=0, sample_size_v2=0, ppl=2.38, wps=527.2, ups=0.49, wpb=1084.2, bsz=120, num_updates=3980, lr=2.97777e-05, gnorm=3.301, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=8210
2023-06-26 20:36:26 - progress_bar.py[line:272] - INFO: epoch 002:    281 / 3715 loss=2.428, loss_v1=0, loss_v2=0, nll_loss=1.236, ntokens=1077.1, nsentences=120, sample_size=1077.1, sample_size_v1=0, sample_size_v2=0, ppl=2.36, wps=523.8, ups=0.49, wpb=1077.1, bsz=120, num_updates=3990, lr=2.97723e-05, gnorm=3.457, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=8230
2023-06-26 20:36:47 - progress_bar.py[line:272] - INFO: epoch 002:    291 / 3715 loss=2.43, loss_v1=0, loss_v2=0, nll_loss=1.24, ntokens=1086.4, nsentences=120, sample_size=1086.4, sample_size_v1=0, sample_size_v2=0, ppl=2.36, wps=527.5, ups=0.49, wpb=1086.4, bsz=120, num_updates=4000, lr=2.9767e-05, gnorm=3.419, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=8251
2023-06-26 20:37:07 - progress_bar.py[line:272] - INFO: epoch 002:    301 / 3715 loss=2.429, loss_v1=0, loss_v2=0, nll_loss=1.235, ntokens=1070.5, nsentences=120, sample_size=1070.5, sample_size_v1=0, sample_size_v2=0, ppl=2.35, wps=520.4, ups=0.49, wpb=1070.5, bsz=120, num_updates=4010, lr=2.97616e-05, gnorm=3.517, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=8272
2023-06-26 20:37:28 - progress_bar.py[line:272] - INFO: epoch 002:    311 / 3715 loss=2.444, loss_v1=0, loss_v2=0, nll_loss=1.252, ntokens=1089.7, nsentences=120, sample_size=1089.7, sample_size_v1=0, sample_size_v2=0, ppl=2.38, wps=529.5, ups=0.49, wpb=1089.7, bsz=120, num_updates=4020, lr=2.97562e-05, gnorm=3.354, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=8292
2023-06-26 20:37:48 - progress_bar.py[line:272] - INFO: epoch 002:    321 / 3715 loss=2.44, loss_v1=0, loss_v2=0, nll_loss=1.248, ntokens=1078.7, nsentences=120, sample_size=1078.7, sample_size_v1=0, sample_size_v2=0, ppl=2.38, wps=524.8, ups=0.49, wpb=1078.7, bsz=120, num_updates=4030, lr=2.97509e-05, gnorm=3.357, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=8313
2023-06-26 20:38:09 - progress_bar.py[line:272] - INFO: epoch 002:    331 / 3715 loss=2.445, loss_v1=0, loss_v2=0, nll_loss=1.255, ntokens=1099.6, nsentences=120, sample_size=1099.6, sample_size_v1=0, sample_size_v2=0, ppl=2.39, wps=534.5, ups=0.49, wpb=1099.6, bsz=120, num_updates=4040, lr=2.97455e-05, gnorm=3.479, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=8333
2023-06-26 20:38:30 - progress_bar.py[line:272] - INFO: epoch 002:    341 / 3715 loss=2.433, loss_v1=0, loss_v2=0, nll_loss=1.239, ntokens=1055.7, nsentences=120, sample_size=1055.7, sample_size_v1=0, sample_size_v2=0, ppl=2.36, wps=513.2, ups=0.49, wpb=1055.7, bsz=120, num_updates=4050, lr=2.97401e-05, gnorm=3.471, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=8354
2023-06-26 20:38:50 - progress_bar.py[line:272] - INFO: epoch 002:    351 / 3715 loss=2.43, loss_v1=0, loss_v2=0, nll_loss=1.241, ntokens=1098.3, nsentences=120, sample_size=1098.3, sample_size_v1=0, sample_size_v2=0, ppl=2.36, wps=533.5, ups=0.49, wpb=1098.3, bsz=120, num_updates=4060, lr=2.97348e-05, gnorm=3.606, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=8374
2023-06-26 20:39:11 - progress_bar.py[line:272] - INFO: epoch 002:    361 / 3715 loss=2.44, loss_v1=0, loss_v2=0, nll_loss=1.248, ntokens=1108.8, nsentences=120, sample_size=1108.8, sample_size_v1=0, sample_size_v2=0, ppl=2.37, wps=537.6, ups=0.48, wpb=1108.8, bsz=120, num_updates=4070, lr=2.97294e-05, gnorm=3.24, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=8395
2023-06-26 20:39:31 - progress_bar.py[line:272] - INFO: epoch 002:    371 / 3715 loss=2.428, loss_v1=0, loss_v2=0, nll_loss=1.237, ntokens=1092.2, nsentences=120, sample_size=1092.2, sample_size_v1=0, sample_size_v2=0, ppl=2.36, wps=531.2, ups=0.49, wpb=1092.2, bsz=120, num_updates=4080, lr=2.9724e-05, gnorm=3.459, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=8416
2023-06-26 20:39:52 - progress_bar.py[line:272] - INFO: epoch 002:    381 / 3715 loss=2.438, loss_v1=0, loss_v2=0, nll_loss=1.245, ntokens=1087.6, nsentences=120, sample_size=1087.6, sample_size_v1=0, sample_size_v2=0, ppl=2.37, wps=528.8, ups=0.49, wpb=1087.6, bsz=120, num_updates=4090, lr=2.97187e-05, gnorm=3.7, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=8436
2023-06-26 20:40:12 - progress_bar.py[line:272] - INFO: epoch 002:    391 / 3715 loss=2.411, loss_v1=0, loss_v2=0, nll_loss=1.217, ntokens=1093.2, nsentences=120, sample_size=1093.2, sample_size_v1=0, sample_size_v2=0, ppl=2.32, wps=531.7, ups=0.49, wpb=1093.2, bsz=120, num_updates=4100, lr=2.97133e-05, gnorm=3.555, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=8457
2023-06-26 20:40:33 - progress_bar.py[line:272] - INFO: epoch 002:    401 / 3715 loss=2.405, loss_v1=0, loss_v2=0, nll_loss=1.212, ntokens=1073.4, nsentences=120, sample_size=1073.4, sample_size_v1=0, sample_size_v2=0, ppl=2.32, wps=522.1, ups=0.49, wpb=1073.4, bsz=120, num_updates=4110, lr=2.97079e-05, gnorm=3.517, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=8477
2023-06-26 20:40:54 - progress_bar.py[line:272] - INFO: epoch 002:    411 / 3715 loss=2.437, loss_v1=0, loss_v2=0, nll_loss=1.243, ntokens=1062, nsentences=120, sample_size=1062, sample_size_v1=0, sample_size_v2=0, ppl=2.37, wps=516.9, ups=0.49, wpb=1062, bsz=120, num_updates=4120, lr=2.97025e-05, gnorm=3.69, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=8498
2023-06-26 20:41:14 - progress_bar.py[line:272] - INFO: epoch 002:    421 / 3715 loss=2.427, loss_v1=0, loss_v2=0, nll_loss=1.235, ntokens=1104.9, nsentences=120, sample_size=1104.9, sample_size_v1=0, sample_size_v2=0, ppl=2.35, wps=538, ups=0.49, wpb=1104.9, bsz=120, num_updates=4130, lr=2.96972e-05, gnorm=3.372, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=8518
2023-06-26 20:41:35 - progress_bar.py[line:272] - INFO: epoch 002:    431 / 3715 loss=2.431, loss_v1=0, loss_v2=0, nll_loss=1.239, ntokens=1074.3, nsentences=120, sample_size=1074.3, sample_size_v1=0, sample_size_v2=0, ppl=2.36, wps=518, ups=0.48, wpb=1074.3, bsz=120, num_updates=4140, lr=2.96918e-05, gnorm=3.351, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=8539
2023-06-26 20:41:55 - progress_bar.py[line:272] - INFO: epoch 002:    441 / 3715 loss=2.422, loss_v1=0, loss_v2=0, nll_loss=1.229, ntokens=1084.4, nsentences=120, sample_size=1084.4, sample_size_v1=0, sample_size_v2=0, ppl=2.34, wps=527.8, ups=0.49, wpb=1084.4, bsz=120, num_updates=4150, lr=2.96864e-05, gnorm=3.4, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=8560
2023-06-26 20:42:16 - progress_bar.py[line:272] - INFO: epoch 002:    451 / 3715 loss=2.429, loss_v1=0, loss_v2=0, nll_loss=1.236, ntokens=1102.9, nsentences=120, sample_size=1102.9, sample_size_v1=0, sample_size_v2=0, ppl=2.36, wps=536.5, ups=0.49, wpb=1102.9, bsz=120, num_updates=4160, lr=2.96811e-05, gnorm=3.345, clip=100, loss_scale=256, train_wall=21, gb_free=8.8, wall=8580
2023-06-26 20:42:36 - progress_bar.py[line:272] - INFO: epoch 002:    461 / 3715 loss=2.418, loss_v1=0, loss_v2=0, nll_loss=1.225, ntokens=1084.5, nsentences=120, sample_size=1084.5, sample_size_v1=0, sample_size_v2=0, ppl=2.34, wps=527.5, ups=0.49, wpb=1084.5, bsz=120, num_updates=4170, lr=2.96757e-05, gnorm=3.406, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=8601
2023-06-26 20:42:57 - progress_bar.py[line:272] - INFO: epoch 002:    471 / 3715 loss=2.42, loss_v1=0, loss_v2=0, nll_loss=1.226, ntokens=1060.3, nsentences=120, sample_size=1060.3, sample_size_v1=0, sample_size_v2=0, ppl=2.34, wps=515.9, ups=0.49, wpb=1060.3, bsz=120, num_updates=4180, lr=2.96703e-05, gnorm=3.692, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=8621
2023-06-26 20:43:18 - progress_bar.py[line:272] - INFO: epoch 002:    481 / 3715 loss=2.433, loss_v1=0, loss_v2=0, nll_loss=1.242, ntokens=1087.8, nsentences=120, sample_size=1087.8, sample_size_v1=0, sample_size_v2=0, ppl=2.37, wps=528.7, ups=0.49, wpb=1087.8, bsz=120, num_updates=4190, lr=2.9665e-05, gnorm=3.827, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=8642
2023-06-26 20:43:38 - progress_bar.py[line:272] - INFO: epoch 002:    491 / 3715 loss=2.426, loss_v1=0, loss_v2=0, nll_loss=1.234, ntokens=1086.4, nsentences=120, sample_size=1086.4, sample_size_v1=0, sample_size_v2=0, ppl=2.35, wps=528, ups=0.49, wpb=1086.4, bsz=120, num_updates=4200, lr=2.96596e-05, gnorm=3.618, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=8663
2023-06-26 20:43:59 - progress_bar.py[line:272] - INFO: epoch 002:    501 / 3715 loss=2.424, loss_v1=0, loss_v2=0, nll_loss=1.231, ntokens=1083.3, nsentences=120, sample_size=1083.3, sample_size_v1=0, sample_size_v2=0, ppl=2.35, wps=526.4, ups=0.49, wpb=1083.3, bsz=120, num_updates=4210, lr=2.96542e-05, gnorm=3.445, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=8683
2023-06-26 20:44:19 - progress_bar.py[line:272] - INFO: epoch 002:    511 / 3715 loss=2.402, loss_v1=0, loss_v2=0, nll_loss=1.205, ntokens=1105.4, nsentences=120, sample_size=1105.4, sample_size_v1=0, sample_size_v2=0, ppl=2.31, wps=537.8, ups=0.49, wpb=1105.4, bsz=120, num_updates=4220, lr=2.96489e-05, gnorm=3.471, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=8704
2023-06-26 20:44:40 - progress_bar.py[line:272] - INFO: epoch 002:    521 / 3715 loss=2.421, loss_v1=0, loss_v2=0, nll_loss=1.226, ntokens=1074.8, nsentences=120, sample_size=1074.8, sample_size_v1=0, sample_size_v2=0, ppl=2.34, wps=523.1, ups=0.49, wpb=1074.8, bsz=120, num_updates=4230, lr=2.96435e-05, gnorm=3.508, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=8724
2023-06-26 20:45:00 - progress_bar.py[line:272] - INFO: epoch 002:    531 / 3715 loss=2.409, loss_v1=0, loss_v2=0, nll_loss=1.216, ntokens=1090.2, nsentences=120, sample_size=1090.2, sample_size_v1=0, sample_size_v2=0, ppl=2.32, wps=530.9, ups=0.49, wpb=1090.2, bsz=120, num_updates=4240, lr=2.96381e-05, gnorm=3.482, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=8745
2023-06-26 20:45:21 - progress_bar.py[line:272] - INFO: epoch 002:    541 / 3715 loss=2.421, loss_v1=0, loss_v2=0, nll_loss=1.226, ntokens=1062.9, nsentences=120, sample_size=1062.9, sample_size_v1=0, sample_size_v2=0, ppl=2.34, wps=516.6, ups=0.49, wpb=1062.9, bsz=120, num_updates=4250, lr=2.96327e-05, gnorm=3.598, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=8765
2023-06-26 20:45:42 - progress_bar.py[line:272] - INFO: epoch 002:    551 / 3715 loss=2.422, loss_v1=0, loss_v2=0, nll_loss=1.227, ntokens=1076.3, nsentences=120, sample_size=1076.3, sample_size_v1=0, sample_size_v2=0, ppl=2.34, wps=523.2, ups=0.49, wpb=1076.3, bsz=120, num_updates=4260, lr=2.96274e-05, gnorm=3.556, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=8786
2023-06-26 20:46:02 - progress_bar.py[line:272] - INFO: epoch 002:    561 / 3715 loss=2.414, loss_v1=0, loss_v2=0, nll_loss=1.22, ntokens=1069.3, nsentences=120, sample_size=1069.3, sample_size_v1=0, sample_size_v2=0, ppl=2.33, wps=519.6, ups=0.49, wpb=1069.3, bsz=120, num_updates=4270, lr=2.9622e-05, gnorm=3.37, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=8807
2023-06-26 20:46:23 - progress_bar.py[line:272] - INFO: epoch 002:    571 / 3715 loss=2.445, loss_v1=0, loss_v2=0, nll_loss=1.253, ntokens=1084, nsentences=120, sample_size=1084, sample_size_v1=0, sample_size_v2=0, ppl=2.38, wps=527.6, ups=0.49, wpb=1084, bsz=120, num_updates=4280, lr=2.96166e-05, gnorm=3.542, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=8827
2023-06-26 20:46:43 - progress_bar.py[line:272] - INFO: epoch 002:    581 / 3715 loss=2.431, loss_v1=0, loss_v2=0, nll_loss=1.24, ntokens=1069.6, nsentences=120, sample_size=1069.6, sample_size_v1=0, sample_size_v2=0, ppl=2.36, wps=516.2, ups=0.48, wpb=1069.6, bsz=120, num_updates=4290, lr=2.96113e-05, gnorm=3.531, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=8848
2023-06-26 20:47:04 - progress_bar.py[line:272] - INFO: epoch 002:    591 / 3715 loss=2.434, loss_v1=0, loss_v2=0, nll_loss=1.239, ntokens=1085.1, nsentences=120, sample_size=1085.1, sample_size_v1=0, sample_size_v2=0, ppl=2.36, wps=528.6, ups=0.49, wpb=1085.1, bsz=120, num_updates=4300, lr=2.96059e-05, gnorm=3.64, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=8868
2023-06-26 20:47:25 - progress_bar.py[line:272] - INFO: epoch 002:    601 / 3715 loss=2.43, loss_v1=0, loss_v2=0, nll_loss=1.239, ntokens=1093.2, nsentences=120, sample_size=1093.2, sample_size_v1=0, sample_size_v2=0, ppl=2.36, wps=532, ups=0.49, wpb=1093.2, bsz=120, num_updates=4310, lr=2.96005e-05, gnorm=3.518, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=8889
2023-06-26 20:47:45 - progress_bar.py[line:272] - INFO: epoch 002:    611 / 3715 loss=2.4, loss_v1=0, loss_v2=0, nll_loss=1.205, ntokens=1096, nsentences=120, sample_size=1096, sample_size_v1=0, sample_size_v2=0, ppl=2.31, wps=533.4, ups=0.49, wpb=1096, bsz=120, num_updates=4320, lr=2.95952e-05, gnorm=3.323, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=8909
2023-06-26 20:48:06 - progress_bar.py[line:272] - INFO: epoch 002:    621 / 3715 loss=2.412, loss_v1=0, loss_v2=0, nll_loss=1.218, ntokens=1067.4, nsentences=120, sample_size=1067.4, sample_size_v1=0, sample_size_v2=0, ppl=2.33, wps=519.7, ups=0.49, wpb=1067.4, bsz=120, num_updates=4330, lr=2.95898e-05, gnorm=3.369, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=8930
2023-06-26 20:48:26 - progress_bar.py[line:272] - INFO: epoch 002:    631 / 3715 loss=2.423, loss_v1=0, loss_v2=0, nll_loss=1.229, ntokens=1078.3, nsentences=120, sample_size=1078.3, sample_size_v1=0, sample_size_v2=0, ppl=2.34, wps=524.8, ups=0.49, wpb=1078.3, bsz=120, num_updates=4340, lr=2.95844e-05, gnorm=3.648, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=8951
2023-06-26 20:48:47 - progress_bar.py[line:272] - INFO: epoch 002:    641 / 3715 loss=2.435, loss_v1=0, loss_v2=0, nll_loss=1.243, ntokens=1068.5, nsentences=120, sample_size=1068.5, sample_size_v1=0, sample_size_v2=0, ppl=2.37, wps=520.2, ups=0.49, wpb=1068.5, bsz=120, num_updates=4350, lr=2.95791e-05, gnorm=3.429, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=8971
2023-06-26 20:49:07 - progress_bar.py[line:272] - INFO: epoch 002:    651 / 3715 loss=2.416, loss_v1=0, loss_v2=0, nll_loss=1.222, ntokens=1077.7, nsentences=120, sample_size=1077.7, sample_size_v1=0, sample_size_v2=0, ppl=2.33, wps=524.2, ups=0.49, wpb=1077.7, bsz=120, num_updates=4360, lr=2.95737e-05, gnorm=3.175, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=8992
2023-06-26 20:49:28 - progress_bar.py[line:272] - INFO: epoch 002:    661 / 3715 loss=2.391, loss_v1=0, loss_v2=0, nll_loss=1.193, ntokens=1067, nsentences=120, sample_size=1067, sample_size_v1=0, sample_size_v2=0, ppl=2.29, wps=519.5, ups=0.49, wpb=1067, bsz=120, num_updates=4370, lr=2.95683e-05, gnorm=3.434, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=9012
2023-06-26 20:49:48 - progress_bar.py[line:272] - INFO: epoch 002:    671 / 3715 loss=2.418, loss_v1=0, loss_v2=0, nll_loss=1.225, ntokens=1075.2, nsentences=120, sample_size=1075.2, sample_size_v1=0, sample_size_v2=0, ppl=2.34, wps=523.5, ups=0.49, wpb=1075.2, bsz=120, num_updates=4380, lr=2.95629e-05, gnorm=3.482, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=9033
2023-06-26 20:50:09 - progress_bar.py[line:272] - INFO: epoch 002:    681 / 3715 loss=2.4, loss_v1=0, loss_v2=0, nll_loss=1.203, ntokens=1080.6, nsentences=120, sample_size=1080.6, sample_size_v1=0, sample_size_v2=0, ppl=2.3, wps=526, ups=0.49, wpb=1080.6, bsz=120, num_updates=4390, lr=2.95576e-05, gnorm=3.355, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=9053
2023-06-26 20:50:29 - progress_bar.py[line:272] - INFO: epoch 002:    691 / 3715 loss=2.424, loss_v1=0, loss_v2=0, nll_loss=1.229, ntokens=1074.8, nsentences=120, sample_size=1074.8, sample_size_v1=0, sample_size_v2=0, ppl=2.34, wps=523.5, ups=0.49, wpb=1074.8, bsz=120, num_updates=4400, lr=2.95522e-05, gnorm=3.349, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=9074
2023-06-26 20:50:50 - progress_bar.py[line:272] - INFO: epoch 002:    701 / 3715 loss=2.417, loss_v1=0, loss_v2=0, nll_loss=1.223, ntokens=1083.3, nsentences=120, sample_size=1083.3, sample_size_v1=0, sample_size_v2=0, ppl=2.33, wps=526.7, ups=0.49, wpb=1083.3, bsz=120, num_updates=4410, lr=2.95468e-05, gnorm=3.522, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=9094
2023-06-26 20:51:11 - progress_bar.py[line:272] - INFO: epoch 002:    711 / 3715 loss=2.423, loss_v1=0, loss_v2=0, nll_loss=1.229, ntokens=1094.3, nsentences=120, sample_size=1094.3, sample_size_v1=0, sample_size_v2=0, ppl=2.34, wps=532, ups=0.49, wpb=1094.3, bsz=120, num_updates=4420, lr=2.95415e-05, gnorm=3.526, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=9115
2023-06-26 20:51:31 - progress_bar.py[line:272] - INFO: epoch 002:    721 / 3715 loss=2.407, loss_v1=0, loss_v2=0, nll_loss=1.211, ntokens=1093.3, nsentences=120, sample_size=1093.3, sample_size_v1=0, sample_size_v2=0, ppl=2.31, wps=530.9, ups=0.49, wpb=1093.3, bsz=120, num_updates=4430, lr=2.95361e-05, gnorm=3.709, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=9136
2023-06-26 20:51:52 - progress_bar.py[line:272] - INFO: epoch 002:    731 / 3715 loss=2.401, loss_v1=0, loss_v2=0, nll_loss=1.205, ntokens=1062.9, nsentences=120, sample_size=1062.9, sample_size_v1=0, sample_size_v2=0, ppl=2.31, wps=516.5, ups=0.49, wpb=1062.9, bsz=120, num_updates=4440, lr=2.95307e-05, gnorm=3.613, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=9156
2023-06-26 20:52:12 - progress_bar.py[line:272] - INFO: epoch 002:    741 / 3715 loss=2.417, loss_v1=0, loss_v2=0, nll_loss=1.222, ntokens=1084.2, nsentences=120, sample_size=1084.2, sample_size_v1=0, sample_size_v2=0, ppl=2.33, wps=526.9, ups=0.49, wpb=1084.2, bsz=120, num_updates=4450, lr=2.95254e-05, gnorm=3.486, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=9177
2023-06-26 20:52:27 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 256.0
2023-06-26 20:52:35 - progress_bar.py[line:272] - INFO: epoch 002:    752 / 3715 loss=2.398, loss_v1=0, loss_v2=0, nll_loss=1.202, ntokens=1091.6, nsentences=120, sample_size=1091.6, sample_size_v1=0, sample_size_v2=0, ppl=2.3, wps=483, ups=0.44, wpb=1091.6, bsz=120, num_updates=4460, lr=2.952e-05, gnorm=3.666, clip=100, loss_scale=256, train_wall=23, gb_free=8.9, wall=9199
2023-06-26 20:52:56 - progress_bar.py[line:272] - INFO: epoch 002:    762 / 3715 loss=2.412, loss_v1=0, loss_v2=0, nll_loss=1.218, ntokens=1088.4, nsentences=120, sample_size=1088.4, sample_size_v1=0, sample_size_v2=0, ppl=2.33, wps=529.1, ups=0.49, wpb=1088.4, bsz=120, num_updates=4470, lr=2.95146e-05, gnorm=3.593, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=9220
2023-06-26 20:53:16 - progress_bar.py[line:272] - INFO: epoch 002:    772 / 3715 loss=2.409, loss_v1=0, loss_v2=0, nll_loss=1.212, ntokens=1052, nsentences=120, sample_size=1052, sample_size_v1=0, sample_size_v2=0, ppl=2.32, wps=511.9, ups=0.49, wpb=1052, bsz=120, num_updates=4480, lr=2.95093e-05, gnorm=3.732, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=9240
2023-06-26 20:53:37 - progress_bar.py[line:272] - INFO: epoch 002:    782 / 3715 loss=2.389, loss_v1=0, loss_v2=0, nll_loss=1.192, ntokens=1081, nsentences=120, sample_size=1081, sample_size_v1=0, sample_size_v2=0, ppl=2.29, wps=525, ups=0.49, wpb=1081, bsz=120, num_updates=4490, lr=2.95039e-05, gnorm=3.809, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=9261
2023-06-26 20:53:57 - progress_bar.py[line:272] - INFO: epoch 002:    792 / 3715 loss=2.401, loss_v1=0, loss_v2=0, nll_loss=1.203, ntokens=1080, nsentences=120, sample_size=1080, sample_size_v1=0, sample_size_v2=0, ppl=2.3, wps=524.8, ups=0.49, wpb=1080, bsz=120, num_updates=4500, lr=2.94985e-05, gnorm=3.566, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=9282
2023-06-26 20:54:18 - progress_bar.py[line:272] - INFO: epoch 002:    802 / 3715 loss=2.414, loss_v1=0, loss_v2=0, nll_loss=1.222, ntokens=1081.3, nsentences=120, sample_size=1081.3, sample_size_v1=0, sample_size_v2=0, ppl=2.33, wps=526, ups=0.49, wpb=1081.3, bsz=120, num_updates=4510, lr=2.94931e-05, gnorm=3.373, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=9302
2023-06-26 20:54:38 - progress_bar.py[line:272] - INFO: epoch 002:    812 / 3715 loss=2.409, loss_v1=0, loss_v2=0, nll_loss=1.212, ntokens=1098, nsentences=120, sample_size=1098, sample_size_v1=0, sample_size_v2=0, ppl=2.32, wps=533.9, ups=0.49, wpb=1098, bsz=120, num_updates=4520, lr=2.94878e-05, gnorm=3.348, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=9323
2023-06-26 20:54:59 - progress_bar.py[line:272] - INFO: epoch 002:    822 / 3715 loss=2.415, loss_v1=0, loss_v2=0, nll_loss=1.223, ntokens=1119.2, nsentences=120, sample_size=1119.2, sample_size_v1=0, sample_size_v2=0, ppl=2.33, wps=545.1, ups=0.49, wpb=1119.2, bsz=120, num_updates=4530, lr=2.94824e-05, gnorm=3.438, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=9343
2023-06-26 20:55:19 - progress_bar.py[line:272] - INFO: epoch 002:    832 / 3715 loss=2.41, loss_v1=0, loss_v2=0, nll_loss=1.213, ntokens=1094, nsentences=120, sample_size=1094, sample_size_v1=0, sample_size_v2=0, ppl=2.32, wps=532.5, ups=0.49, wpb=1094, bsz=120, num_updates=4540, lr=2.9477e-05, gnorm=3.328, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=9364
2023-06-26 20:55:40 - progress_bar.py[line:272] - INFO: epoch 002:    842 / 3715 loss=2.413, loss_v1=0, loss_v2=0, nll_loss=1.22, ntokens=1080.1, nsentences=120, sample_size=1080.1, sample_size_v1=0, sample_size_v2=0, ppl=2.33, wps=525.6, ups=0.49, wpb=1080.1, bsz=120, num_updates=4550, lr=2.94717e-05, gnorm=3.265, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=9384
2023-06-26 20:56:01 - progress_bar.py[line:272] - INFO: epoch 002:    852 / 3715 loss=2.394, loss_v1=0, loss_v2=0, nll_loss=1.196, ntokens=1106.5, nsentences=120, sample_size=1106.5, sample_size_v1=0, sample_size_v2=0, ppl=2.29, wps=537.8, ups=0.49, wpb=1106.5, bsz=120, num_updates=4560, lr=2.94663e-05, gnorm=3.254, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=9405
2023-06-26 20:56:21 - progress_bar.py[line:272] - INFO: epoch 002:    862 / 3715 loss=2.406, loss_v1=0, loss_v2=0, nll_loss=1.212, ntokens=1076.7, nsentences=120, sample_size=1076.7, sample_size_v1=0, sample_size_v2=0, ppl=2.32, wps=523.5, ups=0.49, wpb=1076.7, bsz=120, num_updates=4570, lr=2.94609e-05, gnorm=3.577, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=9426
2023-06-26 20:56:42 - progress_bar.py[line:272] - INFO: epoch 002:    872 / 3715 loss=2.4, loss_v1=0, loss_v2=0, nll_loss=1.203, ntokens=1074.7, nsentences=120, sample_size=1074.7, sample_size_v1=0, sample_size_v2=0, ppl=2.3, wps=523.5, ups=0.49, wpb=1074.7, bsz=120, num_updates=4580, lr=2.94556e-05, gnorm=3.577, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=9446
2023-06-26 20:57:02 - progress_bar.py[line:272] - INFO: epoch 002:    882 / 3715 loss=2.401, loss_v1=0, loss_v2=0, nll_loss=1.205, ntokens=1084.1, nsentences=120, sample_size=1084.1, sample_size_v1=0, sample_size_v2=0, ppl=2.31, wps=527.8, ups=0.49, wpb=1084.1, bsz=120, num_updates=4590, lr=2.94502e-05, gnorm=3.557, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=9467
2023-06-26 20:57:23 - progress_bar.py[line:272] - INFO: epoch 002:    892 / 3715 loss=2.423, loss_v1=0, loss_v2=0, nll_loss=1.231, ntokens=1076.6, nsentences=120, sample_size=1076.6, sample_size_v1=0, sample_size_v2=0, ppl=2.35, wps=523.3, ups=0.49, wpb=1076.6, bsz=120, num_updates=4600, lr=2.94448e-05, gnorm=3.331, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=9487
2023-06-26 20:57:43 - progress_bar.py[line:272] - INFO: epoch 002:    902 / 3715 loss=2.39, loss_v1=0, loss_v2=0, nll_loss=1.193, ntokens=1075.5, nsentences=120, sample_size=1075.5, sample_size_v1=0, sample_size_v2=0, ppl=2.29, wps=522.5, ups=0.49, wpb=1075.5, bsz=120, num_updates=4610, lr=2.94395e-05, gnorm=3.293, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=9508
2023-06-26 20:58:04 - progress_bar.py[line:272] - INFO: epoch 002:    912 / 3715 loss=2.419, loss_v1=0, loss_v2=0, nll_loss=1.224, ntokens=1081.7, nsentences=120, sample_size=1081.7, sample_size_v1=0, sample_size_v2=0, ppl=2.34, wps=526.1, ups=0.49, wpb=1081.7, bsz=120, num_updates=4620, lr=2.94341e-05, gnorm=3.476, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=9528
2023-06-26 20:58:25 - progress_bar.py[line:272] - INFO: epoch 002:    922 / 3715 loss=2.418, loss_v1=0, loss_v2=0, nll_loss=1.225, ntokens=1086.4, nsentences=120, sample_size=1086.4, sample_size_v1=0, sample_size_v2=0, ppl=2.34, wps=528.2, ups=0.49, wpb=1086.4, bsz=120, num_updates=4630, lr=2.94287e-05, gnorm=3.595, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=9549
2023-06-26 20:58:45 - progress_bar.py[line:272] - INFO: epoch 002:    932 / 3715 loss=2.408, loss_v1=0, loss_v2=0, nll_loss=1.209, ntokens=1062.8, nsentences=120, sample_size=1062.8, sample_size_v1=0, sample_size_v2=0, ppl=2.31, wps=515.6, ups=0.49, wpb=1062.8, bsz=120, num_updates=4640, lr=2.94233e-05, gnorm=3.646, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=9570
2023-06-26 20:59:06 - progress_bar.py[line:272] - INFO: epoch 002:    942 / 3715 loss=2.395, loss_v1=0, loss_v2=0, nll_loss=1.202, ntokens=1081.2, nsentences=120, sample_size=1081.2, sample_size_v1=0, sample_size_v2=0, ppl=2.3, wps=525.8, ups=0.49, wpb=1081.2, bsz=120, num_updates=4650, lr=2.9418e-05, gnorm=3.589, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=9590
2023-06-26 20:59:26 - progress_bar.py[line:272] - INFO: epoch 002:    952 / 3715 loss=2.391, loss_v1=0, loss_v2=0, nll_loss=1.19, ntokens=1097.8, nsentences=120, sample_size=1097.8, sample_size_v1=0, sample_size_v2=0, ppl=2.28, wps=534.3, ups=0.49, wpb=1097.8, bsz=120, num_updates=4660, lr=2.94126e-05, gnorm=3.509, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=9611
2023-06-26 20:59:47 - progress_bar.py[line:272] - INFO: epoch 002:    962 / 3715 loss=2.397, loss_v1=0, loss_v2=0, nll_loss=1.201, ntokens=1089.6, nsentences=120, sample_size=1089.6, sample_size_v1=0, sample_size_v2=0, ppl=2.3, wps=530.3, ups=0.49, wpb=1089.6, bsz=120, num_updates=4670, lr=2.94072e-05, gnorm=3.909, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=9631
2023-06-26 21:00:07 - progress_bar.py[line:272] - INFO: epoch 002:    972 / 3715 loss=2.395, loss_v1=0, loss_v2=0, nll_loss=1.2, ntokens=1068.6, nsentences=120, sample_size=1068.6, sample_size_v1=0, sample_size_v2=0, ppl=2.3, wps=519.7, ups=0.49, wpb=1068.6, bsz=120, num_updates=4680, lr=2.94019e-05, gnorm=3.899, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=9652
2023-06-26 21:00:28 - progress_bar.py[line:272] - INFO: epoch 002:    982 / 3715 loss=2.388, loss_v1=0, loss_v2=0, nll_loss=1.188, ntokens=1100.4, nsentences=120, sample_size=1100.4, sample_size_v1=0, sample_size_v2=0, ppl=2.28, wps=535.8, ups=0.49, wpb=1100.4, bsz=120, num_updates=4690, lr=2.93965e-05, gnorm=3.54, clip=100, loss_scale=256, train_wall=21, gb_free=8.8, wall=9672
2023-06-26 21:00:48 - progress_bar.py[line:272] - INFO: epoch 002:    992 / 3715 loss=2.394, loss_v1=0, loss_v2=0, nll_loss=1.199, ntokens=1073.4, nsentences=120, sample_size=1073.4, sample_size_v1=0, sample_size_v2=0, ppl=2.3, wps=522.3, ups=0.49, wpb=1073.4, bsz=120, num_updates=4700, lr=2.93911e-05, gnorm=3.546, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=9693
2023-06-26 21:01:09 - progress_bar.py[line:272] - INFO: epoch 002:   1002 / 3715 loss=2.386, loss_v1=0, loss_v2=0, nll_loss=1.187, ntokens=1089.9, nsentences=120, sample_size=1089.9, sample_size_v1=0, sample_size_v2=0, ppl=2.28, wps=530.7, ups=0.49, wpb=1089.9, bsz=120, num_updates=4710, lr=2.93858e-05, gnorm=3.471, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=9713
2023-06-26 21:01:30 - progress_bar.py[line:272] - INFO: epoch 002:   1012 / 3715 loss=2.371, loss_v1=0, loss_v2=0, nll_loss=1.17, ntokens=1073.4, nsentences=120, sample_size=1073.4, sample_size_v1=0, sample_size_v2=0, ppl=2.25, wps=522.5, ups=0.49, wpb=1073.4, bsz=120, num_updates=4720, lr=2.93804e-05, gnorm=3.861, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=9734
2023-06-26 21:01:50 - progress_bar.py[line:272] - INFO: epoch 002:   1022 / 3715 loss=2.398, loss_v1=0, loss_v2=0, nll_loss=1.203, ntokens=1074.4, nsentences=120, sample_size=1074.4, sample_size_v1=0, sample_size_v2=0, ppl=2.3, wps=523, ups=0.49, wpb=1074.4, bsz=120, num_updates=4730, lr=2.9375e-05, gnorm=3.842, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=9754
2023-06-26 21:02:11 - progress_bar.py[line:272] - INFO: epoch 002:   1032 / 3715 loss=2.403, loss_v1=0, loss_v2=0, nll_loss=1.207, ntokens=1086.7, nsentences=120, sample_size=1086.7, sample_size_v1=0, sample_size_v2=0, ppl=2.31, wps=528.7, ups=0.49, wpb=1086.7, bsz=120, num_updates=4740, lr=2.93697e-05, gnorm=3.601, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=9775
2023-06-26 21:02:31 - progress_bar.py[line:272] - INFO: epoch 002:   1042 / 3715 loss=2.385, loss_v1=0, loss_v2=0, nll_loss=1.187, ntokens=1069.7, nsentences=120, sample_size=1069.7, sample_size_v1=0, sample_size_v2=0, ppl=2.28, wps=520.9, ups=0.49, wpb=1069.7, bsz=120, num_updates=4750, lr=2.93643e-05, gnorm=3.87, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=9796
2023-06-26 21:02:52 - progress_bar.py[line:272] - INFO: epoch 002:   1052 / 3715 loss=2.4, loss_v1=0, loss_v2=0, nll_loss=1.203, ntokens=1072.7, nsentences=120, sample_size=1072.7, sample_size_v1=0, sample_size_v2=0, ppl=2.3, wps=522.4, ups=0.49, wpb=1072.7, bsz=120, num_updates=4760, lr=2.93589e-05, gnorm=4.039, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=9816
2023-06-26 21:03:12 - progress_bar.py[line:272] - INFO: epoch 002:   1062 / 3715 loss=2.39, loss_v1=0, loss_v2=0, nll_loss=1.193, ntokens=1090.1, nsentences=120, sample_size=1090.1, sample_size_v1=0, sample_size_v2=0, ppl=2.29, wps=530.5, ups=0.49, wpb=1090.1, bsz=120, num_updates=4770, lr=2.93535e-05, gnorm=3.627, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=9837
2023-06-26 21:03:33 - progress_bar.py[line:272] - INFO: epoch 002:   1072 / 3715 loss=2.394, loss_v1=0, loss_v2=0, nll_loss=1.197, ntokens=1078.9, nsentences=120, sample_size=1078.9, sample_size_v1=0, sample_size_v2=0, ppl=2.29, wps=524.7, ups=0.49, wpb=1078.9, bsz=120, num_updates=4780, lr=2.93482e-05, gnorm=3.818, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=9857
2023-06-26 21:03:53 - progress_bar.py[line:272] - INFO: epoch 002:   1082 / 3715 loss=2.371, loss_v1=0, loss_v2=0, nll_loss=1.174, ntokens=1094.7, nsentences=120, sample_size=1094.7, sample_size_v1=0, sample_size_v2=0, ppl=2.26, wps=531.8, ups=0.49, wpb=1094.7, bsz=120, num_updates=4790, lr=2.93428e-05, gnorm=3.638, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=9878
2023-06-26 21:04:14 - progress_bar.py[line:272] - INFO: epoch 002:   1092 / 3715 loss=2.379, loss_v1=0, loss_v2=0, nll_loss=1.177, ntokens=1075, nsentences=120, sample_size=1075, sample_size_v1=0, sample_size_v2=0, ppl=2.26, wps=522.2, ups=0.49, wpb=1075, bsz=120, num_updates=4800, lr=2.93374e-05, gnorm=3.577, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=9898
2023-06-26 21:04:35 - progress_bar.py[line:272] - INFO: epoch 002:   1102 / 3715 loss=2.39, loss_v1=0, loss_v2=0, nll_loss=1.196, ntokens=1062, nsentences=120, sample_size=1062, sample_size_v1=0, sample_size_v2=0, ppl=2.29, wps=516.1, ups=0.49, wpb=1062, bsz=120, num_updates=4810, lr=2.93321e-05, gnorm=3.891, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=9919
2023-06-26 21:04:55 - progress_bar.py[line:272] - INFO: epoch 002:   1112 / 3715 loss=2.399, loss_v1=0, loss_v2=0, nll_loss=1.2, ntokens=1076.6, nsentences=120, sample_size=1076.6, sample_size_v1=0, sample_size_v2=0, ppl=2.3, wps=523.4, ups=0.49, wpb=1076.6, bsz=120, num_updates=4820, lr=2.93267e-05, gnorm=3.718, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=9940
2023-06-26 21:05:16 - progress_bar.py[line:272] - INFO: epoch 002:   1122 / 3715 loss=2.397, loss_v1=0, loss_v2=0, nll_loss=1.201, ntokens=1093.8, nsentences=120, sample_size=1093.8, sample_size_v1=0, sample_size_v2=0, ppl=2.3, wps=531.7, ups=0.49, wpb=1093.8, bsz=120, num_updates=4830, lr=2.93213e-05, gnorm=3.275, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=9960
2023-06-26 21:05:36 - progress_bar.py[line:272] - INFO: epoch 002:   1132 / 3715 loss=2.396, loss_v1=0, loss_v2=0, nll_loss=1.197, ntokens=1073.4, nsentences=120, sample_size=1073.4, sample_size_v1=0, sample_size_v2=0, ppl=2.29, wps=521.5, ups=0.49, wpb=1073.4, bsz=120, num_updates=4840, lr=2.9316e-05, gnorm=3.474, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=9981
2023-06-26 21:05:57 - progress_bar.py[line:272] - INFO: epoch 002:   1142 / 3715 loss=2.384, loss_v1=0, loss_v2=0, nll_loss=1.187, ntokens=1110, nsentences=120, sample_size=1110, sample_size_v1=0, sample_size_v2=0, ppl=2.28, wps=539.3, ups=0.49, wpb=1110, bsz=120, num_updates=4850, lr=2.93106e-05, gnorm=3.634, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=10001
2023-06-26 21:06:18 - progress_bar.py[line:272] - INFO: epoch 002:   1152 / 3715 loss=2.391, loss_v1=0, loss_v2=0, nll_loss=1.193, ntokens=1076.1, nsentences=120, sample_size=1076.1, sample_size_v1=0, sample_size_v2=0, ppl=2.29, wps=523.1, ups=0.49, wpb=1076.1, bsz=120, num_updates=4860, lr=2.93052e-05, gnorm=3.507, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=10022
2023-06-26 21:06:38 - progress_bar.py[line:272] - INFO: epoch 002:   1162 / 3715 loss=2.371, loss_v1=0, loss_v2=0, nll_loss=1.172, ntokens=1096.5, nsentences=120, sample_size=1096.5, sample_size_v1=0, sample_size_v2=0, ppl=2.25, wps=533.1, ups=0.49, wpb=1096.5, bsz=120, num_updates=4870, lr=2.92999e-05, gnorm=3.615, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=10042
2023-06-26 21:06:59 - progress_bar.py[line:272] - INFO: epoch 002:   1172 / 3715 loss=2.385, loss_v1=0, loss_v2=0, nll_loss=1.188, ntokens=1086.6, nsentences=120, sample_size=1086.6, sample_size_v1=0, sample_size_v2=0, ppl=2.28, wps=528.4, ups=0.49, wpb=1086.6, bsz=120, num_updates=4880, lr=2.92945e-05, gnorm=3.635, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=10063
2023-06-26 21:07:19 - progress_bar.py[line:272] - INFO: epoch 002:   1182 / 3715 loss=2.407, loss_v1=0, loss_v2=0, nll_loss=1.211, ntokens=1083.2, nsentences=120, sample_size=1083.2, sample_size_v1=0, sample_size_v2=0, ppl=2.31, wps=526.7, ups=0.49, wpb=1083.2, bsz=120, num_updates=4890, lr=2.92891e-05, gnorm=3.676, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=10084
2023-06-26 21:07:40 - progress_bar.py[line:272] - INFO: epoch 002:   1192 / 3715 loss=2.381, loss_v1=0, loss_v2=0, nll_loss=1.182, ntokens=1086.1, nsentences=120, sample_size=1086.1, sample_size_v1=0, sample_size_v2=0, ppl=2.27, wps=527.7, ups=0.49, wpb=1086.1, bsz=120, num_updates=4900, lr=2.92837e-05, gnorm=3.473, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=10104
2023-06-26 21:08:00 - progress_bar.py[line:272] - INFO: epoch 002:   1202 / 3715 loss=2.391, loss_v1=0, loss_v2=0, nll_loss=1.195, ntokens=1084.2, nsentences=120, sample_size=1084.2, sample_size_v1=0, sample_size_v2=0, ppl=2.29, wps=526.9, ups=0.49, wpb=1084.2, bsz=120, num_updates=4910, lr=2.92784e-05, gnorm=3.48, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=10125
2023-06-26 21:08:21 - progress_bar.py[line:272] - INFO: epoch 002:   1212 / 3715 loss=2.365, loss_v1=0, loss_v2=0, nll_loss=1.162, ntokens=1075.6, nsentences=120, sample_size=1075.6, sample_size_v1=0, sample_size_v2=0, ppl=2.24, wps=523, ups=0.49, wpb=1075.6, bsz=120, num_updates=4920, lr=2.9273e-05, gnorm=3.515, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=10145
2023-06-26 21:08:42 - progress_bar.py[line:272] - INFO: epoch 002:   1222 / 3715 loss=2.39, loss_v1=0, loss_v2=0, nll_loss=1.194, ntokens=1091.4, nsentences=120, sample_size=1091.4, sample_size_v1=0, sample_size_v2=0, ppl=2.29, wps=530.8, ups=0.49, wpb=1091.4, bsz=120, num_updates=4930, lr=2.92676e-05, gnorm=3.51, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=10166
2023-06-26 21:09:02 - progress_bar.py[line:272] - INFO: epoch 002:   1232 / 3715 loss=2.378, loss_v1=0, loss_v2=0, nll_loss=1.179, ntokens=1077.8, nsentences=120, sample_size=1077.8, sample_size_v1=0, sample_size_v2=0, ppl=2.26, wps=524.2, ups=0.49, wpb=1077.8, bsz=120, num_updates=4940, lr=2.92623e-05, gnorm=3.843, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=10186
2023-06-26 21:09:23 - progress_bar.py[line:272] - INFO: epoch 002:   1242 / 3715 loss=2.377, loss_v1=0, loss_v2=0, nll_loss=1.177, ntokens=1086.9, nsentences=120, sample_size=1086.9, sample_size_v1=0, sample_size_v2=0, ppl=2.26, wps=528.5, ups=0.49, wpb=1086.9, bsz=120, num_updates=4950, lr=2.92569e-05, gnorm=3.413, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=10207
2023-06-26 21:09:43 - progress_bar.py[line:272] - INFO: epoch 002:   1252 / 3715 loss=2.367, loss_v1=0, loss_v2=0, nll_loss=1.169, ntokens=1081.8, nsentences=120, sample_size=1081.8, sample_size_v1=0, sample_size_v2=0, ppl=2.25, wps=525, ups=0.49, wpb=1081.8, bsz=120, num_updates=4960, lr=2.92515e-05, gnorm=3.637, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=10228
2023-06-26 21:10:04 - progress_bar.py[line:272] - INFO: epoch 002:   1262 / 3715 loss=2.361, loss_v1=0, loss_v2=0, nll_loss=1.157, ntokens=1051, nsentences=120, sample_size=1051, sample_size_v1=0, sample_size_v2=0, ppl=2.23, wps=511.2, ups=0.49, wpb=1051, bsz=120, num_updates=4970, lr=2.92462e-05, gnorm=3.552, clip=100, loss_scale=512, train_wall=21, gb_free=8.9, wall=10248
2023-06-26 21:10:06 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 256.0
2023-06-26 21:10:26 - progress_bar.py[line:272] - INFO: epoch 002:   1273 / 3715 loss=2.393, loss_v1=0, loss_v2=0, nll_loss=1.197, ntokens=1091.9, nsentences=120, sample_size=1091.9, sample_size_v1=0, sample_size_v2=0, ppl=2.29, wps=483.4, ups=0.44, wpb=1091.9, bsz=120, num_updates=4980, lr=2.92408e-05, gnorm=3.607, clip=100, loss_scale=256, train_wall=23, gb_free=8.9, wall=10271
2023-06-26 21:10:47 - progress_bar.py[line:272] - INFO: epoch 002:   1283 / 3715 loss=2.386, loss_v1=0, loss_v2=0, nll_loss=1.188, ntokens=1078.5, nsentences=120, sample_size=1078.5, sample_size_v1=0, sample_size_v2=0, ppl=2.28, wps=524.5, ups=0.49, wpb=1078.5, bsz=120, num_updates=4990, lr=2.92354e-05, gnorm=3.691, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=10291
2023-06-26 21:11:08 - progress_bar.py[line:272] - INFO: epoch 002:   1293 / 3715 loss=2.36, loss_v1=0, loss_v2=0, nll_loss=1.157, ntokens=1092, nsentences=120, sample_size=1092, sample_size_v1=0, sample_size_v2=0, ppl=2.23, wps=531.1, ups=0.49, wpb=1092, bsz=120, num_updates=5000, lr=2.92301e-05, gnorm=3.612, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=10312
2023-06-26 21:11:28 - progress_bar.py[line:272] - INFO: epoch 002:   1303 / 3715 loss=2.378, loss_v1=0, loss_v2=0, nll_loss=1.178, ntokens=1067.6, nsentences=120, sample_size=1067.6, sample_size_v1=0, sample_size_v2=0, ppl=2.26, wps=519.7, ups=0.49, wpb=1067.6, bsz=120, num_updates=5010, lr=2.92247e-05, gnorm=3.892, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=10332
2023-06-26 21:11:49 - progress_bar.py[line:272] - INFO: epoch 002:   1313 / 3715 loss=2.377, loss_v1=0, loss_v2=0, nll_loss=1.177, ntokens=1088.5, nsentences=120, sample_size=1088.5, sample_size_v1=0, sample_size_v2=0, ppl=2.26, wps=529.7, ups=0.49, wpb=1088.5, bsz=120, num_updates=5020, lr=2.92193e-05, gnorm=3.562, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=10353
2023-06-26 21:12:09 - progress_bar.py[line:272] - INFO: epoch 002:   1323 / 3715 loss=2.379, loss_v1=0, loss_v2=0, nll_loss=1.181, ntokens=1080.6, nsentences=120, sample_size=1080.6, sample_size_v1=0, sample_size_v2=0, ppl=2.27, wps=525.6, ups=0.49, wpb=1080.6, bsz=120, num_updates=5030, lr=2.92139e-05, gnorm=3.95, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=10374
2023-06-26 21:12:30 - progress_bar.py[line:272] - INFO: epoch 002:   1333 / 3715 loss=2.369, loss_v1=0, loss_v2=0, nll_loss=1.17, ntokens=1089.4, nsentences=120, sample_size=1089.4, sample_size_v1=0, sample_size_v2=0, ppl=2.25, wps=529.6, ups=0.49, wpb=1089.4, bsz=120, num_updates=5040, lr=2.92086e-05, gnorm=3.857, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=10394
2023-06-26 21:12:50 - progress_bar.py[line:272] - INFO: epoch 002:   1343 / 3715 loss=2.381, loss_v1=0, loss_v2=0, nll_loss=1.182, ntokens=1065.1, nsentences=120, sample_size=1065.1, sample_size_v1=0, sample_size_v2=0, ppl=2.27, wps=518.1, ups=0.49, wpb=1065.1, bsz=120, num_updates=5050, lr=2.92032e-05, gnorm=3.685, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=10415
2023-06-26 21:13:11 - progress_bar.py[line:272] - INFO: epoch 002:   1353 / 3715 loss=2.362, loss_v1=0, loss_v2=0, nll_loss=1.162, ntokens=1106.9, nsentences=120, sample_size=1106.9, sample_size_v1=0, sample_size_v2=0, ppl=2.24, wps=537.9, ups=0.49, wpb=1106.9, bsz=120, num_updates=5060, lr=2.91978e-05, gnorm=3.684, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=10435
2023-06-26 21:13:32 - progress_bar.py[line:272] - INFO: epoch 002:   1363 / 3715 loss=2.381, loss_v1=0, loss_v2=0, nll_loss=1.182, ntokens=1085.6, nsentences=120, sample_size=1085.6, sample_size_v1=0, sample_size_v2=0, ppl=2.27, wps=528, ups=0.49, wpb=1085.6, bsz=120, num_updates=5070, lr=2.91925e-05, gnorm=3.663, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=10456
2023-06-26 21:13:52 - progress_bar.py[line:272] - INFO: epoch 002:   1373 / 3715 loss=2.382, loss_v1=0, loss_v2=0, nll_loss=1.183, ntokens=1064.5, nsentences=120, sample_size=1064.5, sample_size_v1=0, sample_size_v2=0, ppl=2.27, wps=517.9, ups=0.49, wpb=1064.5, bsz=120, num_updates=5080, lr=2.91871e-05, gnorm=3.681, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=10476
2023-06-26 21:14:13 - progress_bar.py[line:272] - INFO: epoch 002:   1383 / 3715 loss=2.379, loss_v1=0, loss_v2=0, nll_loss=1.18, ntokens=1070, nsentences=120, sample_size=1070, sample_size_v1=0, sample_size_v2=0, ppl=2.27, wps=521.2, ups=0.49, wpb=1070, bsz=120, num_updates=5090, lr=2.91817e-05, gnorm=3.674, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=10497
2023-06-26 21:14:33 - progress_bar.py[line:272] - INFO: epoch 002:   1393 / 3715 loss=2.385, loss_v1=0, loss_v2=0, nll_loss=1.188, ntokens=1094.5, nsentences=120, sample_size=1094.5, sample_size_v1=0, sample_size_v2=0, ppl=2.28, wps=532.6, ups=0.49, wpb=1094.5, bsz=120, num_updates=5100, lr=2.91764e-05, gnorm=3.297, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=10518
2023-06-26 21:14:54 - progress_bar.py[line:272] - INFO: epoch 002:   1403 / 3715 loss=2.35, loss_v1=0, loss_v2=0, nll_loss=1.147, ntokens=1060.2, nsentences=120, sample_size=1060.2, sample_size_v1=0, sample_size_v2=0, ppl=2.21, wps=515.2, ups=0.49, wpb=1060.2, bsz=120, num_updates=5110, lr=2.9171e-05, gnorm=3.482, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=10538
2023-06-26 21:15:14 - progress_bar.py[line:272] - INFO: epoch 002:   1413 / 3715 loss=2.354, loss_v1=0, loss_v2=0, nll_loss=1.154, ntokens=1102.8, nsentences=120, sample_size=1102.8, sample_size_v1=0, sample_size_v2=0, ppl=2.23, wps=537, ups=0.49, wpb=1102.8, bsz=120, num_updates=5120, lr=2.91656e-05, gnorm=3.678, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=10559
2023-06-26 21:15:35 - progress_bar.py[line:272] - INFO: epoch 002:   1423 / 3715 loss=2.378, loss_v1=0, loss_v2=0, nll_loss=1.177, ntokens=1090.2, nsentences=120, sample_size=1090.2, sample_size_v1=0, sample_size_v2=0, ppl=2.26, wps=530.8, ups=0.49, wpb=1090.2, bsz=120, num_updates=5130, lr=2.91603e-05, gnorm=3.575, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=10579
2023-06-26 21:15:55 - progress_bar.py[line:272] - INFO: epoch 002:   1433 / 3715 loss=2.353, loss_v1=0, loss_v2=0, nll_loss=1.151, ntokens=1072.8, nsentences=120, sample_size=1072.8, sample_size_v1=0, sample_size_v2=0, ppl=2.22, wps=522.2, ups=0.49, wpb=1072.8, bsz=120, num_updates=5140, lr=2.91549e-05, gnorm=3.781, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=10600
2023-06-26 21:16:16 - progress_bar.py[line:272] - INFO: epoch 002:   1443 / 3715 loss=2.343, loss_v1=0, loss_v2=0, nll_loss=1.14, ntokens=1084.3, nsentences=120, sample_size=1084.3, sample_size_v1=0, sample_size_v2=0, ppl=2.2, wps=528.4, ups=0.49, wpb=1084.3, bsz=120, num_updates=5150, lr=2.91495e-05, gnorm=3.756, clip=100, loss_scale=256, train_wall=20, gb_free=8.9, wall=10620
2023-06-26 21:16:36 - progress_bar.py[line:272] - INFO: epoch 002:   1453 / 3715 loss=2.362, loss_v1=0, loss_v2=0, nll_loss=1.16, ntokens=1093.6, nsentences=120, sample_size=1093.6, sample_size_v1=0, sample_size_v2=0, ppl=2.23, wps=532.7, ups=0.49, wpb=1093.6, bsz=120, num_updates=5160, lr=2.91441e-05, gnorm=3.474, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=10641
2023-06-26 21:16:57 - progress_bar.py[line:272] - INFO: epoch 002:   1463 / 3715 loss=2.37, loss_v1=0, loss_v2=0, nll_loss=1.172, ntokens=1088.4, nsentences=120, sample_size=1088.4, sample_size_v1=0, sample_size_v2=0, ppl=2.25, wps=530.4, ups=0.49, wpb=1088.4, bsz=120, num_updates=5170, lr=2.91388e-05, gnorm=3.907, clip=100, loss_scale=256, train_wall=20, gb_free=8.9, wall=10661
2023-06-26 21:17:18 - progress_bar.py[line:272] - INFO: epoch 002:   1473 / 3715 loss=2.371, loss_v1=0, loss_v2=0, nll_loss=1.172, ntokens=1071, nsentences=120, sample_size=1071, sample_size_v1=0, sample_size_v2=0, ppl=2.25, wps=520.8, ups=0.49, wpb=1071, bsz=120, num_updates=5180, lr=2.91334e-05, gnorm=3.909, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=10682
2023-06-26 21:17:38 - progress_bar.py[line:272] - INFO: epoch 002:   1483 / 3715 loss=2.357, loss_v1=0, loss_v2=0, nll_loss=1.153, ntokens=1075.1, nsentences=120, sample_size=1075.1, sample_size_v1=0, sample_size_v2=0, ppl=2.22, wps=523.4, ups=0.49, wpb=1075.1, bsz=120, num_updates=5190, lr=2.9128e-05, gnorm=3.553, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=10702
2023-06-26 21:17:59 - progress_bar.py[line:272] - INFO: epoch 002:   1493 / 3715 loss=2.344, loss_v1=0, loss_v2=0, nll_loss=1.143, ntokens=1075.3, nsentences=120, sample_size=1075.3, sample_size_v1=0, sample_size_v2=0, ppl=2.21, wps=522.5, ups=0.49, wpb=1075.3, bsz=120, num_updates=5200, lr=2.91227e-05, gnorm=3.634, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=10723
2023-06-26 21:18:19 - progress_bar.py[line:272] - INFO: epoch 002:   1503 / 3715 loss=2.346, loss_v1=0, loss_v2=0, nll_loss=1.143, ntokens=1104.6, nsentences=120, sample_size=1104.6, sample_size_v1=0, sample_size_v2=0, ppl=2.21, wps=537, ups=0.49, wpb=1104.6, bsz=120, num_updates=5210, lr=2.91173e-05, gnorm=3.788, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=10744
2023-06-26 21:18:40 - progress_bar.py[line:272] - INFO: epoch 002:   1513 / 3715 loss=2.363, loss_v1=0, loss_v2=0, nll_loss=1.163, ntokens=1100.9, nsentences=120, sample_size=1100.9, sample_size_v1=0, sample_size_v2=0, ppl=2.24, wps=535.4, ups=0.49, wpb=1100.9, bsz=120, num_updates=5220, lr=2.91119e-05, gnorm=3.682, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=10764
2023-06-26 21:19:00 - progress_bar.py[line:272] - INFO: epoch 002:   1523 / 3715 loss=2.368, loss_v1=0, loss_v2=0, nll_loss=1.166, ntokens=1090.7, nsentences=120, sample_size=1090.7, sample_size_v1=0, sample_size_v2=0, ppl=2.24, wps=530.2, ups=0.49, wpb=1090.7, bsz=120, num_updates=5230, lr=2.91066e-05, gnorm=3.604, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=10785
2023-06-26 21:19:21 - progress_bar.py[line:272] - INFO: epoch 002:   1533 / 3715 loss=2.362, loss_v1=0, loss_v2=0, nll_loss=1.161, ntokens=1071.9, nsentences=120, sample_size=1071.9, sample_size_v1=0, sample_size_v2=0, ppl=2.24, wps=521.2, ups=0.49, wpb=1071.9, bsz=120, num_updates=5240, lr=2.91012e-05, gnorm=3.575, clip=100, loss_scale=256, train_wall=21, gb_free=8.8, wall=10805
2023-06-26 21:19:42 - progress_bar.py[line:272] - INFO: epoch 002:   1543 / 3715 loss=2.358, loss_v1=0, loss_v2=0, nll_loss=1.156, ntokens=1085, nsentences=120, sample_size=1085, sample_size_v1=0, sample_size_v2=0, ppl=2.23, wps=527.5, ups=0.49, wpb=1085, bsz=120, num_updates=5250, lr=2.90958e-05, gnorm=3.494, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=10826
2023-06-26 21:20:02 - progress_bar.py[line:272] - INFO: epoch 002:   1553 / 3715 loss=2.352, loss_v1=0, loss_v2=0, nll_loss=1.151, ntokens=1085, nsentences=120, sample_size=1085, sample_size_v1=0, sample_size_v2=0, ppl=2.22, wps=528, ups=0.49, wpb=1085, bsz=120, num_updates=5260, lr=2.90905e-05, gnorm=3.694, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=10846
2023-06-26 21:20:23 - progress_bar.py[line:272] - INFO: epoch 002:   1563 / 3715 loss=2.356, loss_v1=0, loss_v2=0, nll_loss=1.154, ntokens=1071.7, nsentences=120, sample_size=1071.7, sample_size_v1=0, sample_size_v2=0, ppl=2.22, wps=522.1, ups=0.49, wpb=1071.7, bsz=120, num_updates=5270, lr=2.90851e-05, gnorm=3.628, clip=100, loss_scale=256, train_wall=20, gb_free=8.9, wall=10867
2023-06-26 21:20:43 - progress_bar.py[line:272] - INFO: epoch 002:   1573 / 3715 loss=2.362, loss_v1=0, loss_v2=0, nll_loss=1.162, ntokens=1100.3, nsentences=120, sample_size=1100.3, sample_size_v1=0, sample_size_v2=0, ppl=2.24, wps=535.7, ups=0.49, wpb=1100.3, bsz=120, num_updates=5280, lr=2.90797e-05, gnorm=3.363, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=10888
2023-06-26 21:21:04 - progress_bar.py[line:272] - INFO: epoch 002:   1583 / 3715 loss=2.379, loss_v1=0, loss_v2=0, nll_loss=1.177, ntokens=1077.9, nsentences=120, sample_size=1077.9, sample_size_v1=0, sample_size_v2=0, ppl=2.26, wps=524.3, ups=0.49, wpb=1077.9, bsz=120, num_updates=5290, lr=2.90743e-05, gnorm=3.642, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=10908
2023-06-26 21:21:24 - progress_bar.py[line:272] - INFO: epoch 002:   1593 / 3715 loss=2.355, loss_v1=0, loss_v2=0, nll_loss=1.157, ntokens=1071, nsentences=120, sample_size=1071, sample_size_v1=0, sample_size_v2=0, ppl=2.23, wps=520.5, ups=0.49, wpb=1071, bsz=120, num_updates=5300, lr=2.9069e-05, gnorm=3.417, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=10929
2023-06-26 21:21:45 - progress_bar.py[line:272] - INFO: epoch 002:   1603 / 3715 loss=2.368, loss_v1=0, loss_v2=0, nll_loss=1.166, ntokens=1075.1, nsentences=120, sample_size=1075.1, sample_size_v1=0, sample_size_v2=0, ppl=2.24, wps=522.9, ups=0.49, wpb=1075.1, bsz=120, num_updates=5310, lr=2.90636e-05, gnorm=3.687, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=10949
2023-06-26 21:22:05 - progress_bar.py[line:272] - INFO: epoch 002:   1613 / 3715 loss=2.367, loss_v1=0, loss_v2=0, nll_loss=1.167, ntokens=1076.5, nsentences=120, sample_size=1076.5, sample_size_v1=0, sample_size_v2=0, ppl=2.25, wps=523.8, ups=0.49, wpb=1076.5, bsz=120, num_updates=5320, lr=2.90582e-05, gnorm=3.585, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=10970
2023-06-26 21:22:26 - progress_bar.py[line:272] - INFO: epoch 002:   1623 / 3715 loss=2.351, loss_v1=0, loss_v2=0, nll_loss=1.151, ntokens=1102.7, nsentences=120, sample_size=1102.7, sample_size_v1=0, sample_size_v2=0, ppl=2.22, wps=535.7, ups=0.49, wpb=1102.7, bsz=120, num_updates=5330, lr=2.90529e-05, gnorm=3.899, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=10990
2023-06-26 21:22:47 - progress_bar.py[line:272] - INFO: epoch 002:   1633 / 3715 loss=2.343, loss_v1=0, loss_v2=0, nll_loss=1.136, ntokens=1074.9, nsentences=120, sample_size=1074.9, sample_size_v1=0, sample_size_v2=0, ppl=2.2, wps=523.3, ups=0.49, wpb=1074.9, bsz=120, num_updates=5340, lr=2.90475e-05, gnorm=3.793, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=11011
2023-06-26 21:23:07 - progress_bar.py[line:272] - INFO: epoch 002:   1643 / 3715 loss=2.364, loss_v1=0, loss_v2=0, nll_loss=1.165, ntokens=1085.5, nsentences=120, sample_size=1085.5, sample_size_v1=0, sample_size_v2=0, ppl=2.24, wps=528.5, ups=0.49, wpb=1085.5, bsz=120, num_updates=5350, lr=2.90421e-05, gnorm=3.865, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=11031
2023-06-26 21:23:28 - progress_bar.py[line:272] - INFO: epoch 002:   1653 / 3715 loss=2.358, loss_v1=0, loss_v2=0, nll_loss=1.156, ntokens=1085.2, nsentences=120, sample_size=1085.2, sample_size_v1=0, sample_size_v2=0, ppl=2.23, wps=528.3, ups=0.49, wpb=1085.2, bsz=120, num_updates=5360, lr=2.90368e-05, gnorm=3.831, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=11052
2023-06-26 21:23:48 - progress_bar.py[line:272] - INFO: epoch 002:   1663 / 3715 loss=2.36, loss_v1=0, loss_v2=0, nll_loss=1.158, ntokens=1057.4, nsentences=120, sample_size=1057.4, sample_size_v1=0, sample_size_v2=0, ppl=2.23, wps=514.1, ups=0.49, wpb=1057.4, bsz=120, num_updates=5370, lr=2.90314e-05, gnorm=3.646, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=11073
2023-06-26 21:24:09 - progress_bar.py[line:272] - INFO: epoch 002:   1673 / 3715 loss=2.357, loss_v1=0, loss_v2=0, nll_loss=1.156, ntokens=1071.1, nsentences=120, sample_size=1071.1, sample_size_v1=0, sample_size_v2=0, ppl=2.23, wps=521.6, ups=0.49, wpb=1071.1, bsz=120, num_updates=5380, lr=2.9026e-05, gnorm=3.859, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=11093
2023-06-26 21:24:29 - progress_bar.py[line:272] - INFO: epoch 002:   1683 / 3715 loss=2.364, loss_v1=0, loss_v2=0, nll_loss=1.162, ntokens=1067.2, nsentences=120, sample_size=1067.2, sample_size_v1=0, sample_size_v2=0, ppl=2.24, wps=519, ups=0.49, wpb=1067.2, bsz=120, num_updates=5390, lr=2.90207e-05, gnorm=3.76, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=11114
2023-06-26 21:24:50 - progress_bar.py[line:272] - INFO: epoch 002:   1693 / 3715 loss=2.352, loss_v1=0, loss_v2=0, nll_loss=1.151, ntokens=1085.9, nsentences=120, sample_size=1085.9, sample_size_v1=0, sample_size_v2=0, ppl=2.22, wps=527.8, ups=0.49, wpb=1085.9, bsz=120, num_updates=5400, lr=2.90153e-05, gnorm=3.464, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=11134
2023-06-26 21:25:10 - progress_bar.py[line:272] - INFO: epoch 002:   1703 / 3715 loss=2.358, loss_v1=0, loss_v2=0, nll_loss=1.155, ntokens=1071.4, nsentences=120, sample_size=1071.4, sample_size_v1=0, sample_size_v2=0, ppl=2.23, wps=521.1, ups=0.49, wpb=1071.4, bsz=120, num_updates=5410, lr=2.90099e-05, gnorm=3.98, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=11155
2023-06-26 21:25:31 - progress_bar.py[line:272] - INFO: epoch 002:   1713 / 3715 loss=2.355, loss_v1=0, loss_v2=0, nll_loss=1.153, ntokens=1090.3, nsentences=120, sample_size=1090.3, sample_size_v1=0, sample_size_v2=0, ppl=2.22, wps=529.9, ups=0.49, wpb=1090.3, bsz=120, num_updates=5420, lr=2.90045e-05, gnorm=3.529, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=11175
2023-06-26 21:25:52 - progress_bar.py[line:272] - INFO: epoch 002:   1723 / 3715 loss=2.361, loss_v1=0, loss_v2=0, nll_loss=1.159, ntokens=1090.2, nsentences=120, sample_size=1090.2, sample_size_v1=0, sample_size_v2=0, ppl=2.23, wps=530.1, ups=0.49, wpb=1090.2, bsz=120, num_updates=5430, lr=2.89992e-05, gnorm=3.604, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=11196
2023-06-26 21:26:12 - progress_bar.py[line:272] - INFO: epoch 002:   1733 / 3715 loss=2.337, loss_v1=0, loss_v2=0, nll_loss=1.134, ntokens=1092.5, nsentences=120, sample_size=1092.5, sample_size_v1=0, sample_size_v2=0, ppl=2.19, wps=530.7, ups=0.49, wpb=1092.5, bsz=120, num_updates=5440, lr=2.89938e-05, gnorm=3.642, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=11217
2023-06-26 21:26:33 - progress_bar.py[line:272] - INFO: epoch 002:   1743 / 3715 loss=2.36, loss_v1=0, loss_v2=0, nll_loss=1.158, ntokens=1075.5, nsentences=120, sample_size=1075.5, sample_size_v1=0, sample_size_v2=0, ppl=2.23, wps=522.5, ups=0.49, wpb=1075.5, bsz=120, num_updates=5450, lr=2.89884e-05, gnorm=3.59, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=11237
2023-06-26 21:26:53 - progress_bar.py[line:272] - INFO: epoch 002:   1753 / 3715 loss=2.359, loss_v1=0, loss_v2=0, nll_loss=1.158, ntokens=1091.3, nsentences=120, sample_size=1091.3, sample_size_v1=0, sample_size_v2=0, ppl=2.23, wps=530.2, ups=0.49, wpb=1091.3, bsz=120, num_updates=5460, lr=2.89831e-05, gnorm=3.96, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=11258
2023-06-26 21:27:14 - progress_bar.py[line:272] - INFO: epoch 002:   1763 / 3715 loss=2.337, loss_v1=0, loss_v2=0, nll_loss=1.133, ntokens=1080.8, nsentences=120, sample_size=1080.8, sample_size_v1=0, sample_size_v2=0, ppl=2.19, wps=525.1, ups=0.49, wpb=1080.8, bsz=120, num_updates=5470, lr=2.89777e-05, gnorm=3.484, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=11278
2023-06-26 21:27:35 - progress_bar.py[line:272] - INFO: epoch 002:   1773 / 3715 loss=2.352, loss_v1=0, loss_v2=0, nll_loss=1.15, ntokens=1080, nsentences=120, sample_size=1080, sample_size_v1=0, sample_size_v2=0, ppl=2.22, wps=524.2, ups=0.49, wpb=1080, bsz=120, num_updates=5480, lr=2.89723e-05, gnorm=3.533, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=11299
2023-06-26 21:27:43 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 256.0
2023-06-26 21:27:57 - progress_bar.py[line:272] - INFO: epoch 002:   1784 / 3715 loss=2.351, loss_v1=0, loss_v2=0, nll_loss=1.147, ntokens=1062.1, nsentences=120, sample_size=1062.1, sample_size_v1=0, sample_size_v2=0, ppl=2.21, wps=469.6, ups=0.44, wpb=1062.1, bsz=120, num_updates=5490, lr=2.8967e-05, gnorm=3.687, clip=100, loss_scale=256, train_wall=23, gb_free=8.9, wall=11322
2023-06-26 21:28:18 - progress_bar.py[line:272] - INFO: epoch 002:   1794 / 3715 loss=2.359, loss_v1=0, loss_v2=0, nll_loss=1.157, ntokens=1094.9, nsentences=120, sample_size=1094.9, sample_size_v1=0, sample_size_v2=0, ppl=2.23, wps=532.3, ups=0.49, wpb=1094.9, bsz=120, num_updates=5500, lr=2.89616e-05, gnorm=3.588, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=11342
2023-06-26 21:28:38 - progress_bar.py[line:272] - INFO: epoch 002:   1804 / 3715 loss=2.348, loss_v1=0, loss_v2=0, nll_loss=1.147, ntokens=1087.3, nsentences=120, sample_size=1087.3, sample_size_v1=0, sample_size_v2=0, ppl=2.21, wps=528.4, ups=0.49, wpb=1087.3, bsz=120, num_updates=5510, lr=2.89562e-05, gnorm=3.404, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=11363
2023-06-26 21:28:59 - progress_bar.py[line:272] - INFO: epoch 002:   1814 / 3715 loss=2.36, loss_v1=0, loss_v2=0, nll_loss=1.159, ntokens=1066.8, nsentences=120, sample_size=1066.8, sample_size_v1=0, sample_size_v2=0, ppl=2.23, wps=519.2, ups=0.49, wpb=1066.8, bsz=120, num_updates=5520, lr=2.89509e-05, gnorm=3.777, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=11383
2023-06-26 21:29:19 - progress_bar.py[line:272] - INFO: epoch 002:   1824 / 3715 loss=2.349, loss_v1=0, loss_v2=0, nll_loss=1.146, ntokens=1086.7, nsentences=120, sample_size=1086.7, sample_size_v1=0, sample_size_v2=0, ppl=2.21, wps=528.4, ups=0.49, wpb=1086.7, bsz=120, num_updates=5530, lr=2.89455e-05, gnorm=3.565, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=11404
2023-06-26 21:29:40 - progress_bar.py[line:272] - INFO: epoch 002:   1834 / 3715 loss=2.342, loss_v1=0, loss_v2=0, nll_loss=1.139, ntokens=1088, nsentences=120, sample_size=1088, sample_size_v1=0, sample_size_v2=0, ppl=2.2, wps=528.4, ups=0.49, wpb=1088, bsz=120, num_updates=5540, lr=2.89401e-05, gnorm=3.755, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=11424
2023-06-26 21:30:01 - progress_bar.py[line:272] - INFO: epoch 002:   1844 / 3715 loss=2.347, loss_v1=0, loss_v2=0, nll_loss=1.143, ntokens=1090, nsentences=120, sample_size=1090, sample_size_v1=0, sample_size_v2=0, ppl=2.21, wps=529.9, ups=0.49, wpb=1090, bsz=120, num_updates=5550, lr=2.89347e-05, gnorm=3.403, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=11445
2023-06-26 21:30:21 - progress_bar.py[line:272] - INFO: epoch 002:   1854 / 3715 loss=2.35, loss_v1=0, loss_v2=0, nll_loss=1.146, ntokens=1085.4, nsentences=120, sample_size=1085.4, sample_size_v1=0, sample_size_v2=0, ppl=2.21, wps=527.6, ups=0.49, wpb=1085.4, bsz=120, num_updates=5560, lr=2.89294e-05, gnorm=3.867, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=11466
2023-06-26 21:30:42 - progress_bar.py[line:272] - INFO: epoch 002:   1864 / 3715 loss=2.346, loss_v1=0, loss_v2=0, nll_loss=1.144, ntokens=1072.9, nsentences=120, sample_size=1072.9, sample_size_v1=0, sample_size_v2=0, ppl=2.21, wps=521.8, ups=0.49, wpb=1072.9, bsz=120, num_updates=5570, lr=2.8924e-05, gnorm=3.741, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=11486
2023-06-26 21:31:02 - progress_bar.py[line:272] - INFO: epoch 002:   1874 / 3715 loss=2.361, loss_v1=0, loss_v2=0, nll_loss=1.158, ntokens=1079.4, nsentences=120, sample_size=1079.4, sample_size_v1=0, sample_size_v2=0, ppl=2.23, wps=525, ups=0.49, wpb=1079.4, bsz=120, num_updates=5580, lr=2.89186e-05, gnorm=3.506, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=11507
2023-06-26 21:31:23 - progress_bar.py[line:272] - INFO: epoch 002:   1884 / 3715 loss=2.357, loss_v1=0, loss_v2=0, nll_loss=1.155, ntokens=1078.9, nsentences=120, sample_size=1078.9, sample_size_v1=0, sample_size_v2=0, ppl=2.23, wps=524.4, ups=0.49, wpb=1078.9, bsz=120, num_updates=5590, lr=2.89133e-05, gnorm=3.666, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=11527
2023-06-26 21:31:44 - progress_bar.py[line:272] - INFO: epoch 002:   1894 / 3715 loss=2.363, loss_v1=0, loss_v2=0, nll_loss=1.161, ntokens=1083.8, nsentences=120, sample_size=1083.8, sample_size_v1=0, sample_size_v2=0, ppl=2.24, wps=526.5, ups=0.49, wpb=1083.8, bsz=120, num_updates=5600, lr=2.89079e-05, gnorm=3.608, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=11548
2023-06-26 21:32:04 - progress_bar.py[line:272] - INFO: epoch 002:   1904 / 3715 loss=2.348, loss_v1=0, loss_v2=0, nll_loss=1.145, ntokens=1082.2, nsentences=120, sample_size=1082.2, sample_size_v1=0, sample_size_v2=0, ppl=2.21, wps=526.3, ups=0.49, wpb=1082.2, bsz=120, num_updates=5610, lr=2.89025e-05, gnorm=3.609, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=11568
2023-06-26 21:32:25 - progress_bar.py[line:272] - INFO: epoch 002:   1914 / 3715 loss=2.337, loss_v1=0, loss_v2=0, nll_loss=1.133, ntokens=1089.8, nsentences=120, sample_size=1089.8, sample_size_v1=0, sample_size_v2=0, ppl=2.19, wps=529.7, ups=0.49, wpb=1089.8, bsz=120, num_updates=5620, lr=2.88972e-05, gnorm=3.511, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=11589
2023-06-26 21:32:45 - progress_bar.py[line:272] - INFO: epoch 002:   1924 / 3715 loss=2.36, loss_v1=0, loss_v2=0, nll_loss=1.16, ntokens=1066.2, nsentences=120, sample_size=1066.2, sample_size_v1=0, sample_size_v2=0, ppl=2.23, wps=518.7, ups=0.49, wpb=1066.2, bsz=120, num_updates=5630, lr=2.88918e-05, gnorm=3.723, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=11610
2023-06-26 21:33:06 - progress_bar.py[line:272] - INFO: epoch 002:   1934 / 3715 loss=2.365, loss_v1=0, loss_v2=0, nll_loss=1.166, ntokens=1086.1, nsentences=120, sample_size=1086.1, sample_size_v1=0, sample_size_v2=0, ppl=2.24, wps=528.2, ups=0.49, wpb=1086.1, bsz=120, num_updates=5640, lr=2.88864e-05, gnorm=3.477, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=11630
2023-06-26 21:33:26 - progress_bar.py[line:272] - INFO: epoch 002:   1944 / 3715 loss=2.368, loss_v1=0, loss_v2=0, nll_loss=1.164, ntokens=1069.7, nsentences=120, sample_size=1069.7, sample_size_v1=0, sample_size_v2=0, ppl=2.24, wps=520, ups=0.49, wpb=1069.7, bsz=120, num_updates=5650, lr=2.88811e-05, gnorm=3.631, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=11651
2023-06-26 21:33:47 - progress_bar.py[line:272] - INFO: epoch 002:   1954 / 3715 loss=2.341, loss_v1=0, loss_v2=0, nll_loss=1.141, ntokens=1088.5, nsentences=120, sample_size=1088.5, sample_size_v1=0, sample_size_v2=0, ppl=2.21, wps=529.4, ups=0.49, wpb=1088.5, bsz=120, num_updates=5660, lr=2.88757e-05, gnorm=3.374, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=11671
2023-06-26 21:34:08 - progress_bar.py[line:272] - INFO: epoch 002:   1964 / 3715 loss=2.359, loss_v1=0, loss_v2=0, nll_loss=1.154, ntokens=1082.5, nsentences=120, sample_size=1082.5, sample_size_v1=0, sample_size_v2=0, ppl=2.23, wps=525.7, ups=0.49, wpb=1082.5, bsz=120, num_updates=5670, lr=2.88703e-05, gnorm=3.513, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=11692
2023-06-26 21:34:28 - progress_bar.py[line:272] - INFO: epoch 002:   1974 / 3715 loss=2.359, loss_v1=0, loss_v2=0, nll_loss=1.158, ntokens=1067, nsentences=120, sample_size=1067, sample_size_v1=0, sample_size_v2=0, ppl=2.23, wps=518.8, ups=0.49, wpb=1067, bsz=120, num_updates=5680, lr=2.88649e-05, gnorm=3.416, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=11712
2023-06-26 21:34:49 - progress_bar.py[line:272] - INFO: epoch 002:   1984 / 3715 loss=2.363, loss_v1=0, loss_v2=0, nll_loss=1.164, ntokens=1086.3, nsentences=120, sample_size=1086.3, sample_size_v1=0, sample_size_v2=0, ppl=2.24, wps=528.1, ups=0.49, wpb=1086.3, bsz=120, num_updates=5690, lr=2.88596e-05, gnorm=3.89, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=11733
2023-06-26 21:35:09 - progress_bar.py[line:272] - INFO: epoch 002:   1994 / 3715 loss=2.359, loss_v1=0, loss_v2=0, nll_loss=1.156, ntokens=1071.8, nsentences=120, sample_size=1071.8, sample_size_v1=0, sample_size_v2=0, ppl=2.23, wps=521, ups=0.49, wpb=1071.8, bsz=120, num_updates=5700, lr=2.88542e-05, gnorm=3.669, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=11754
2023-06-26 21:35:30 - progress_bar.py[line:272] - INFO: epoch 002:   2004 / 3715 loss=2.34, loss_v1=0, loss_v2=0, nll_loss=1.135, ntokens=1095, nsentences=120, sample_size=1095, sample_size_v1=0, sample_size_v2=0, ppl=2.2, wps=532.4, ups=0.49, wpb=1095, bsz=120, num_updates=5710, lr=2.88488e-05, gnorm=3.745, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=11774
2023-06-26 21:35:50 - progress_bar.py[line:272] - INFO: epoch 002:   2014 / 3715 loss=2.337, loss_v1=0, loss_v2=0, nll_loss=1.134, ntokens=1097, nsentences=120, sample_size=1097, sample_size_v1=0, sample_size_v2=0, ppl=2.19, wps=533.3, ups=0.49, wpb=1097, bsz=120, num_updates=5720, lr=2.88435e-05, gnorm=3.465, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=11795
2023-06-26 21:36:11 - progress_bar.py[line:272] - INFO: epoch 002:   2024 / 3715 loss=2.338, loss_v1=0, loss_v2=0, nll_loss=1.134, ntokens=1075.6, nsentences=120, sample_size=1075.6, sample_size_v1=0, sample_size_v2=0, ppl=2.19, wps=523, ups=0.49, wpb=1075.6, bsz=120, num_updates=5730, lr=2.88381e-05, gnorm=3.318, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=11815
2023-06-26 21:36:32 - progress_bar.py[line:272] - INFO: epoch 002:   2034 / 3715 loss=2.345, loss_v1=0, loss_v2=0, nll_loss=1.141, ntokens=1099.9, nsentences=120, sample_size=1099.9, sample_size_v1=0, sample_size_v2=0, ppl=2.21, wps=535, ups=0.49, wpb=1099.9, bsz=120, num_updates=5740, lr=2.88327e-05, gnorm=3.502, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=11836
2023-06-26 21:36:52 - progress_bar.py[line:272] - INFO: epoch 002:   2044 / 3715 loss=2.348, loss_v1=0, loss_v2=0, nll_loss=1.145, ntokens=1094.5, nsentences=120, sample_size=1094.5, sample_size_v1=0, sample_size_v2=0, ppl=2.21, wps=531.8, ups=0.49, wpb=1094.5, bsz=120, num_updates=5750, lr=2.88274e-05, gnorm=3.452, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=11856
2023-06-26 21:37:13 - progress_bar.py[line:272] - INFO: epoch 002:   2054 / 3715 loss=2.359, loss_v1=0, loss_v2=0, nll_loss=1.159, ntokens=1096.6, nsentences=120, sample_size=1096.6, sample_size_v1=0, sample_size_v2=0, ppl=2.23, wps=533.2, ups=0.49, wpb=1096.6, bsz=120, num_updates=5760, lr=2.8822e-05, gnorm=3.795, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=11877
2023-06-26 21:37:33 - progress_bar.py[line:272] - INFO: epoch 002:   2064 / 3715 loss=2.357, loss_v1=0, loss_v2=0, nll_loss=1.154, ntokens=1101.7, nsentences=120, sample_size=1101.7, sample_size_v1=0, sample_size_v2=0, ppl=2.23, wps=535.5, ups=0.49, wpb=1101.7, bsz=120, num_updates=5770, lr=2.88166e-05, gnorm=3.299, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=11898
2023-06-26 21:37:54 - progress_bar.py[line:272] - INFO: epoch 002:   2074 / 3715 loss=2.345, loss_v1=0, loss_v2=0, nll_loss=1.143, ntokens=1080.5, nsentences=120, sample_size=1080.5, sample_size_v1=0, sample_size_v2=0, ppl=2.21, wps=525.3, ups=0.49, wpb=1080.5, bsz=120, num_updates=5780, lr=2.88113e-05, gnorm=3.717, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=11918
2023-06-26 21:38:14 - progress_bar.py[line:272] - INFO: epoch 002:   2084 / 3715 loss=2.353, loss_v1=0, loss_v2=0, nll_loss=1.149, ntokens=1087.6, nsentences=120, sample_size=1087.6, sample_size_v1=0, sample_size_v2=0, ppl=2.22, wps=529, ups=0.49, wpb=1087.6, bsz=120, num_updates=5790, lr=2.88059e-05, gnorm=3.518, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=11939
2023-06-26 21:38:35 - progress_bar.py[line:272] - INFO: epoch 002:   2094 / 3715 loss=2.348, loss_v1=0, loss_v2=0, nll_loss=1.146, ntokens=1086.7, nsentences=120, sample_size=1086.7, sample_size_v1=0, sample_size_v2=0, ppl=2.21, wps=528.4, ups=0.49, wpb=1086.7, bsz=120, num_updates=5800, lr=2.88005e-05, gnorm=3.728, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=11959
2023-06-26 21:38:56 - progress_bar.py[line:272] - INFO: epoch 002:   2104 / 3715 loss=2.341, loss_v1=0, loss_v2=0, nll_loss=1.136, ntokens=1076.3, nsentences=120, sample_size=1076.3, sample_size_v1=0, sample_size_v2=0, ppl=2.2, wps=523, ups=0.49, wpb=1076.3, bsz=120, num_updates=5810, lr=2.87951e-05, gnorm=3.552, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=11980
2023-06-26 21:39:16 - progress_bar.py[line:272] - INFO: epoch 002:   2114 / 3715 loss=2.345, loss_v1=0, loss_v2=0, nll_loss=1.14, ntokens=1076, nsentences=120, sample_size=1076, sample_size_v1=0, sample_size_v2=0, ppl=2.2, wps=521.8, ups=0.48, wpb=1076, bsz=120, num_updates=5820, lr=2.87898e-05, gnorm=3.805, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=12000
2023-06-26 21:39:37 - progress_bar.py[line:272] - INFO: epoch 002:   2124 / 3715 loss=2.333, loss_v1=0, loss_v2=0, nll_loss=1.13, ntokens=1084.5, nsentences=120, sample_size=1084.5, sample_size_v1=0, sample_size_v2=0, ppl=2.19, wps=527.3, ups=0.49, wpb=1084.5, bsz=120, num_updates=5830, lr=2.87844e-05, gnorm=3.639, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=12021
2023-06-26 21:39:57 - progress_bar.py[line:272] - INFO: epoch 002:   2134 / 3715 loss=2.346, loss_v1=0, loss_v2=0, nll_loss=1.142, ntokens=1080.6, nsentences=120, sample_size=1080.6, sample_size_v1=0, sample_size_v2=0, ppl=2.21, wps=525.4, ups=0.49, wpb=1080.6, bsz=120, num_updates=5840, lr=2.8779e-05, gnorm=3.626, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=12042
2023-06-26 21:40:18 - progress_bar.py[line:272] - INFO: epoch 002:   2144 / 3715 loss=2.356, loss_v1=0, loss_v2=0, nll_loss=1.153, ntokens=1092.9, nsentences=120, sample_size=1092.9, sample_size_v1=0, sample_size_v2=0, ppl=2.22, wps=531.1, ups=0.49, wpb=1092.9, bsz=120, num_updates=5850, lr=2.87737e-05, gnorm=3.556, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=12062
2023-06-26 21:40:38 - progress_bar.py[line:272] - INFO: epoch 002:   2154 / 3715 loss=2.343, loss_v1=0, loss_v2=0, nll_loss=1.139, ntokens=1092, nsentences=120, sample_size=1092, sample_size_v1=0, sample_size_v2=0, ppl=2.2, wps=530.4, ups=0.49, wpb=1092, bsz=120, num_updates=5860, lr=2.87683e-05, gnorm=3.85, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=12083
2023-06-26 21:40:59 - progress_bar.py[line:272] - INFO: epoch 002:   2164 / 3715 loss=2.332, loss_v1=0, loss_v2=0, nll_loss=1.13, ntokens=1087.3, nsentences=120, sample_size=1087.3, sample_size_v1=0, sample_size_v2=0, ppl=2.19, wps=528.3, ups=0.49, wpb=1087.3, bsz=120, num_updates=5870, lr=2.87629e-05, gnorm=3.681, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=12103
2023-06-26 21:41:20 - progress_bar.py[line:272] - INFO: epoch 002:   2174 / 3715 loss=2.342, loss_v1=0, loss_v2=0, nll_loss=1.138, ntokens=1131.6, nsentences=120, sample_size=1131.6, sample_size_v1=0, sample_size_v2=0, ppl=2.2, wps=549.6, ups=0.49, wpb=1131.6, bsz=120, num_updates=5880, lr=2.87576e-05, gnorm=3.336, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=12124
2023-06-26 21:41:40 - progress_bar.py[line:272] - INFO: epoch 002:   2184 / 3715 loss=2.323, loss_v1=0, loss_v2=0, nll_loss=1.118, ntokens=1073, nsentences=120, sample_size=1073, sample_size_v1=0, sample_size_v2=0, ppl=2.17, wps=521.4, ups=0.49, wpb=1073, bsz=120, num_updates=5890, lr=2.87522e-05, gnorm=3.633, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=12145
2023-06-26 21:42:01 - progress_bar.py[line:272] - INFO: epoch 002:   2194 / 3715 loss=2.339, loss_v1=0, loss_v2=0, nll_loss=1.133, ntokens=1074.5, nsentences=120, sample_size=1074.5, sample_size_v1=0, sample_size_v2=0, ppl=2.19, wps=522.5, ups=0.49, wpb=1074.5, bsz=120, num_updates=5900, lr=2.87468e-05, gnorm=3.759, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=12165
2023-06-26 21:42:21 - progress_bar.py[line:272] - INFO: epoch 002:   2204 / 3715 loss=2.337, loss_v1=0, loss_v2=0, nll_loss=1.133, ntokens=1104.5, nsentences=120, sample_size=1104.5, sample_size_v1=0, sample_size_v2=0, ppl=2.19, wps=536.1, ups=0.49, wpb=1104.5, bsz=120, num_updates=5910, lr=2.87415e-05, gnorm=3.492, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=12186
2023-06-26 21:42:42 - progress_bar.py[line:272] - INFO: epoch 002:   2214 / 3715 loss=2.341, loss_v1=0, loss_v2=0, nll_loss=1.137, ntokens=1105.4, nsentences=120, sample_size=1105.4, sample_size_v1=0, sample_size_v2=0, ppl=2.2, wps=537.2, ups=0.49, wpb=1105.4, bsz=120, num_updates=5920, lr=2.87361e-05, gnorm=3.685, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=12206
2023-06-26 21:43:03 - progress_bar.py[line:272] - INFO: epoch 002:   2224 / 3715 loss=2.333, loss_v1=0, loss_v2=0, nll_loss=1.13, ntokens=1092.4, nsentences=120, sample_size=1092.4, sample_size_v1=0, sample_size_v2=0, ppl=2.19, wps=530.5, ups=0.49, wpb=1092.4, bsz=120, num_updates=5930, lr=2.87307e-05, gnorm=3.67, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=12227
2023-06-26 21:43:23 - progress_bar.py[line:272] - INFO: epoch 002:   2234 / 3715 loss=2.343, loss_v1=0, loss_v2=0, nll_loss=1.137, ntokens=1089.4, nsentences=120, sample_size=1089.4, sample_size_v1=0, sample_size_v2=0, ppl=2.2, wps=529.3, ups=0.49, wpb=1089.4, bsz=120, num_updates=5940, lr=2.87253e-05, gnorm=3.532, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=12248
2023-06-26 21:43:44 - progress_bar.py[line:272] - INFO: epoch 002:   2244 / 3715 loss=2.334, loss_v1=0, loss_v2=0, nll_loss=1.131, ntokens=1077.2, nsentences=120, sample_size=1077.2, sample_size_v1=0, sample_size_v2=0, ppl=2.19, wps=524.2, ups=0.49, wpb=1077.2, bsz=120, num_updates=5950, lr=2.872e-05, gnorm=3.54, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=12268
2023-06-26 21:44:04 - progress_bar.py[line:272] - INFO: epoch 002:   2254 / 3715 loss=2.343, loss_v1=0, loss_v2=0, nll_loss=1.139, ntokens=1094.9, nsentences=120, sample_size=1094.9, sample_size_v1=0, sample_size_v2=0, ppl=2.2, wps=532.3, ups=0.49, wpb=1094.9, bsz=120, num_updates=5960, lr=2.87146e-05, gnorm=3.561, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=12289
2023-06-26 21:44:25 - progress_bar.py[line:272] - INFO: epoch 002:   2264 / 3715 loss=2.334, loss_v1=0, loss_v2=0, nll_loss=1.13, ntokens=1079, nsentences=120, sample_size=1079, sample_size_v1=0, sample_size_v2=0, ppl=2.19, wps=524.6, ups=0.49, wpb=1079, bsz=120, num_updates=5970, lr=2.87092e-05, gnorm=3.873, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=12309
2023-06-26 21:44:45 - progress_bar.py[line:272] - INFO: epoch 002:   2274 / 3715 loss=2.325, loss_v1=0, loss_v2=0, nll_loss=1.121, ntokens=1112.8, nsentences=120, sample_size=1112.8, sample_size_v1=0, sample_size_v2=0, ppl=2.17, wps=541.1, ups=0.49, wpb=1112.8, bsz=120, num_updates=5980, lr=2.87039e-05, gnorm=3.435, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=12330
2023-06-26 21:45:06 - progress_bar.py[line:272] - INFO: epoch 002:   2284 / 3715 loss=2.322, loss_v1=0, loss_v2=0, nll_loss=1.113, ntokens=1089.1, nsentences=120, sample_size=1089.1, sample_size_v1=0, sample_size_v2=0, ppl=2.16, wps=529.5, ups=0.49, wpb=1089.1, bsz=120, num_updates=5990, lr=2.86985e-05, gnorm=3.421, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=12350
2023-06-26 21:45:20 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 256.0
2023-06-26 21:45:29 - progress_bar.py[line:272] - INFO: epoch 002:   2295 / 3715 loss=2.34, loss_v1=0, loss_v2=0, nll_loss=1.141, ntokens=1070, nsentences=120, sample_size=1070, sample_size_v1=0, sample_size_v2=0, ppl=2.21, wps=472.8, ups=0.44, wpb=1070, bsz=120, num_updates=6000, lr=2.86931e-05, gnorm=3.668, clip=100, loss_scale=256, train_wall=23, gb_free=8.9, wall=12373
2023-06-26 21:45:49 - progress_bar.py[line:272] - INFO: epoch 002:   2305 / 3715 loss=2.336, loss_v1=0, loss_v2=0, nll_loss=1.131, ntokens=1091.5, nsentences=120, sample_size=1091.5, sample_size_v1=0, sample_size_v2=0, ppl=2.19, wps=530.5, ups=0.49, wpb=1091.5, bsz=120, num_updates=6010, lr=2.86878e-05, gnorm=3.557, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=12394
2023-06-26 21:46:10 - progress_bar.py[line:272] - INFO: epoch 002:   2315 / 3715 loss=2.325, loss_v1=0, loss_v2=0, nll_loss=1.12, ntokens=1077.8, nsentences=120, sample_size=1077.8, sample_size_v1=0, sample_size_v2=0, ppl=2.17, wps=523.9, ups=0.49, wpb=1077.8, bsz=120, num_updates=6020, lr=2.86824e-05, gnorm=3.741, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=12414
2023-06-26 21:46:30 - progress_bar.py[line:272] - INFO: epoch 002:   2325 / 3715 loss=2.341, loss_v1=0, loss_v2=0, nll_loss=1.136, ntokens=1092.7, nsentences=120, sample_size=1092.7, sample_size_v1=0, sample_size_v2=0, ppl=2.2, wps=530.8, ups=0.49, wpb=1092.7, bsz=120, num_updates=6030, lr=2.8677e-05, gnorm=3.56, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=12435
2023-06-26 21:46:51 - progress_bar.py[line:272] - INFO: epoch 002:   2335 / 3715 loss=2.329, loss_v1=0, loss_v2=0, nll_loss=1.126, ntokens=1078.1, nsentences=120, sample_size=1078.1, sample_size_v1=0, sample_size_v2=0, ppl=2.18, wps=524, ups=0.49, wpb=1078.1, bsz=120, num_updates=6040, lr=2.86717e-05, gnorm=3.769, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=12455
2023-06-26 21:47:12 - progress_bar.py[line:272] - INFO: epoch 002:   2345 / 3715 loss=2.332, loss_v1=0, loss_v2=0, nll_loss=1.127, ntokens=1081.3, nsentences=120, sample_size=1081.3, sample_size_v1=0, sample_size_v2=0, ppl=2.18, wps=525.9, ups=0.49, wpb=1081.3, bsz=120, num_updates=6050, lr=2.86663e-05, gnorm=3.618, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=12476
2023-06-26 21:47:32 - progress_bar.py[line:272] - INFO: epoch 002:   2355 / 3715 loss=2.337, loss_v1=0, loss_v2=0, nll_loss=1.131, ntokens=1125.6, nsentences=120, sample_size=1125.6, sample_size_v1=0, sample_size_v2=0, ppl=2.19, wps=547.3, ups=0.49, wpb=1125.6, bsz=120, num_updates=6060, lr=2.86609e-05, gnorm=3.735, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=12496
2023-06-26 21:47:53 - progress_bar.py[line:272] - INFO: epoch 002:   2365 / 3715 loss=2.322, loss_v1=0, loss_v2=0, nll_loss=1.117, ntokens=1081.3, nsentences=120, sample_size=1081.3, sample_size_v1=0, sample_size_v2=0, ppl=2.17, wps=525.9, ups=0.49, wpb=1081.3, bsz=120, num_updates=6070, lr=2.86555e-05, gnorm=3.828, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=12517
2023-06-26 21:48:13 - progress_bar.py[line:272] - INFO: epoch 002:   2375 / 3715 loss=2.332, loss_v1=0, loss_v2=0, nll_loss=1.127, ntokens=1087.9, nsentences=120, sample_size=1087.9, sample_size_v1=0, sample_size_v2=0, ppl=2.18, wps=529, ups=0.49, wpb=1087.9, bsz=120, num_updates=6080, lr=2.86502e-05, gnorm=3.759, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=12538
2023-06-26 21:48:34 - progress_bar.py[line:272] - INFO: epoch 002:   2385 / 3715 loss=2.315, loss_v1=0, loss_v2=0, nll_loss=1.109, ntokens=1080.2, nsentences=120, sample_size=1080.2, sample_size_v1=0, sample_size_v2=0, ppl=2.16, wps=525.6, ups=0.49, wpb=1080.2, bsz=120, num_updates=6090, lr=2.86448e-05, gnorm=4.164, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=12558
2023-06-26 21:48:54 - progress_bar.py[line:272] - INFO: epoch 002:   2395 / 3715 loss=2.327, loss_v1=0, loss_v2=0, nll_loss=1.12, ntokens=1078.5, nsentences=120, sample_size=1078.5, sample_size_v1=0, sample_size_v2=0, ppl=2.17, wps=524.3, ups=0.49, wpb=1078.5, bsz=120, num_updates=6100, lr=2.86394e-05, gnorm=3.524, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=12579
2023-06-26 21:49:15 - progress_bar.py[line:272] - INFO: epoch 002:   2405 / 3715 loss=2.321, loss_v1=0, loss_v2=0, nll_loss=1.117, ntokens=1055.5, nsentences=120, sample_size=1055.5, sample_size_v1=0, sample_size_v2=0, ppl=2.17, wps=514, ups=0.49, wpb=1055.5, bsz=120, num_updates=6110, lr=2.86341e-05, gnorm=3.675, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=12599
2023-06-26 21:49:35 - progress_bar.py[line:272] - INFO: epoch 002:   2415 / 3715 loss=2.318, loss_v1=0, loss_v2=0, nll_loss=1.111, ntokens=1086, nsentences=120, sample_size=1086, sample_size_v1=0, sample_size_v2=0, ppl=2.16, wps=528.3, ups=0.49, wpb=1086, bsz=120, num_updates=6120, lr=2.86287e-05, gnorm=3.636, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=12620
2023-06-26 21:49:56 - progress_bar.py[line:272] - INFO: epoch 002:   2425 / 3715 loss=2.303, loss_v1=0, loss_v2=0, nll_loss=1.098, ntokens=1111.5, nsentences=120, sample_size=1111.5, sample_size_v1=0, sample_size_v2=0, ppl=2.14, wps=540.3, ups=0.49, wpb=1111.5, bsz=120, num_updates=6130, lr=2.86233e-05, gnorm=3.686, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=12640
2023-06-26 21:50:17 - progress_bar.py[line:272] - INFO: epoch 002:   2435 / 3715 loss=2.317, loss_v1=0, loss_v2=0, nll_loss=1.111, ntokens=1098.3, nsentences=120, sample_size=1098.3, sample_size_v1=0, sample_size_v2=0, ppl=2.16, wps=534.6, ups=0.49, wpb=1098.3, bsz=120, num_updates=6140, lr=2.8618e-05, gnorm=3.562, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=12661
2023-06-26 21:50:37 - progress_bar.py[line:272] - INFO: epoch 002:   2445 / 3715 loss=2.335, loss_v1=0, loss_v2=0, nll_loss=1.131, ntokens=1071.3, nsentences=120, sample_size=1071.3, sample_size_v1=0, sample_size_v2=0, ppl=2.19, wps=521.5, ups=0.49, wpb=1071.3, bsz=120, num_updates=6150, lr=2.86126e-05, gnorm=3.698, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=12681
2023-06-26 21:50:58 - progress_bar.py[line:272] - INFO: epoch 002:   2455 / 3715 loss=2.33, loss_v1=0, loss_v2=0, nll_loss=1.125, ntokens=1081.5, nsentences=120, sample_size=1081.5, sample_size_v1=0, sample_size_v2=0, ppl=2.18, wps=526.3, ups=0.49, wpb=1081.5, bsz=120, num_updates=6160, lr=2.86072e-05, gnorm=3.716, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=12702
2023-06-26 21:51:18 - progress_bar.py[line:272] - INFO: epoch 002:   2465 / 3715 loss=2.33, loss_v1=0, loss_v2=0, nll_loss=1.127, ntokens=1089.9, nsentences=120, sample_size=1089.9, sample_size_v1=0, sample_size_v2=0, ppl=2.18, wps=529.3, ups=0.49, wpb=1089.9, bsz=120, num_updates=6170, lr=2.86019e-05, gnorm=3.726, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=12723
2023-06-26 21:51:39 - progress_bar.py[line:272] - INFO: epoch 002:   2475 / 3715 loss=2.317, loss_v1=0, loss_v2=0, nll_loss=1.108, ntokens=1084.6, nsentences=120, sample_size=1084.6, sample_size_v1=0, sample_size_v2=0, ppl=2.16, wps=526.9, ups=0.49, wpb=1084.6, bsz=120, num_updates=6180, lr=2.85965e-05, gnorm=3.466, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=12743
2023-06-26 21:51:59 - progress_bar.py[line:272] - INFO: epoch 002:   2485 / 3715 loss=2.304, loss_v1=0, loss_v2=0, nll_loss=1.1, ntokens=1090, nsentences=120, sample_size=1090, sample_size_v1=0, sample_size_v2=0, ppl=2.14, wps=529.8, ups=0.49, wpb=1090, bsz=120, num_updates=6190, lr=2.85911e-05, gnorm=3.615, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=12764
2023-06-26 21:52:20 - progress_bar.py[line:272] - INFO: epoch 002:   2495 / 3715 loss=2.31, loss_v1=0, loss_v2=0, nll_loss=1.099, ntokens=1032.9, nsentences=120, sample_size=1032.9, sample_size_v1=0, sample_size_v2=0, ppl=2.14, wps=502, ups=0.49, wpb=1032.9, bsz=120, num_updates=6200, lr=2.85857e-05, gnorm=3.878, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=12784
2023-06-26 21:52:41 - progress_bar.py[line:272] - INFO: epoch 002:   2505 / 3715 loss=2.328, loss_v1=0, loss_v2=0, nll_loss=1.124, ntokens=1071.7, nsentences=120, sample_size=1071.7, sample_size_v1=0, sample_size_v2=0, ppl=2.18, wps=521.6, ups=0.49, wpb=1071.7, bsz=120, num_updates=6210, lr=2.85804e-05, gnorm=3.786, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=12805
2023-06-26 21:53:01 - progress_bar.py[line:272] - INFO: epoch 002:   2515 / 3715 loss=2.324, loss_v1=0, loss_v2=0, nll_loss=1.119, ntokens=1059.2, nsentences=120, sample_size=1059.2, sample_size_v1=0, sample_size_v2=0, ppl=2.17, wps=515.6, ups=0.49, wpb=1059.2, bsz=120, num_updates=6220, lr=2.8575e-05, gnorm=3.935, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=12825
2023-06-26 21:53:22 - progress_bar.py[line:272] - INFO: epoch 002:   2525 / 3715 loss=2.311, loss_v1=0, loss_v2=0, nll_loss=1.103, ntokens=1084.9, nsentences=120, sample_size=1084.9, sample_size_v1=0, sample_size_v2=0, ppl=2.15, wps=526.7, ups=0.49, wpb=1084.9, bsz=120, num_updates=6230, lr=2.85696e-05, gnorm=3.424, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=12846
2023-06-26 21:53:42 - progress_bar.py[line:272] - INFO: epoch 002:   2535 / 3715 loss=2.309, loss_v1=0, loss_v2=0, nll_loss=1.103, ntokens=1090.1, nsentences=120, sample_size=1090.1, sample_size_v1=0, sample_size_v2=0, ppl=2.15, wps=530, ups=0.49, wpb=1090.1, bsz=120, num_updates=6240, lr=2.85643e-05, gnorm=3.442, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=12867
2023-06-26 21:54:03 - progress_bar.py[line:272] - INFO: epoch 002:   2545 / 3715 loss=2.33, loss_v1=0, loss_v2=0, nll_loss=1.126, ntokens=1092.8, nsentences=120, sample_size=1092.8, sample_size_v1=0, sample_size_v2=0, ppl=2.18, wps=530.9, ups=0.49, wpb=1092.8, bsz=120, num_updates=6250, lr=2.85589e-05, gnorm=3.792, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=12887
2023-06-26 21:54:23 - progress_bar.py[line:272] - INFO: epoch 002:   2555 / 3715 loss=2.306, loss_v1=0, loss_v2=0, nll_loss=1.097, ntokens=1098.5, nsentences=120, sample_size=1098.5, sample_size_v1=0, sample_size_v2=0, ppl=2.14, wps=534.5, ups=0.49, wpb=1098.5, bsz=120, num_updates=6260, lr=2.85535e-05, gnorm=3.306, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=12908
2023-06-26 21:54:44 - progress_bar.py[line:272] - INFO: epoch 002:   2565 / 3715 loss=2.314, loss_v1=0, loss_v2=0, nll_loss=1.107, ntokens=1082.6, nsentences=120, sample_size=1082.6, sample_size_v1=0, sample_size_v2=0, ppl=2.15, wps=527, ups=0.49, wpb=1082.6, bsz=120, num_updates=6270, lr=2.85482e-05, gnorm=3.444, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=12928
2023-06-26 21:55:05 - progress_bar.py[line:272] - INFO: epoch 002:   2575 / 3715 loss=2.3, loss_v1=0, loss_v2=0, nll_loss=1.092, ntokens=1088.6, nsentences=120, sample_size=1088.6, sample_size_v1=0, sample_size_v2=0, ppl=2.13, wps=529.2, ups=0.49, wpb=1088.6, bsz=120, num_updates=6280, lr=2.85428e-05, gnorm=3.58, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=12949
2023-06-26 21:55:25 - progress_bar.py[line:272] - INFO: epoch 002:   2585 / 3715 loss=2.312, loss_v1=0, loss_v2=0, nll_loss=1.105, ntokens=1074.8, nsentences=120, sample_size=1074.8, sample_size_v1=0, sample_size_v2=0, ppl=2.15, wps=521.9, ups=0.49, wpb=1074.8, bsz=120, num_updates=6290, lr=2.85374e-05, gnorm=3.855, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=12969
2023-06-26 21:55:46 - progress_bar.py[line:272] - INFO: epoch 002:   2595 / 3715 loss=2.303, loss_v1=0, loss_v2=0, nll_loss=1.094, ntokens=1089.2, nsentences=120, sample_size=1089.2, sample_size_v1=0, sample_size_v2=0, ppl=2.13, wps=529, ups=0.49, wpb=1089.2, bsz=120, num_updates=6300, lr=2.85321e-05, gnorm=3.747, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=12990
2023-06-26 21:56:06 - progress_bar.py[line:272] - INFO: epoch 002:   2605 / 3715 loss=2.322, loss_v1=0, loss_v2=0, nll_loss=1.118, ntokens=1104.5, nsentences=120, sample_size=1104.5, sample_size_v1=0, sample_size_v2=0, ppl=2.17, wps=536.8, ups=0.49, wpb=1104.5, bsz=120, num_updates=6310, lr=2.85267e-05, gnorm=4.05, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=13011
2023-06-26 21:56:27 - progress_bar.py[line:272] - INFO: epoch 002:   2615 / 3715 loss=2.311, loss_v1=0, loss_v2=0, nll_loss=1.104, ntokens=1087.7, nsentences=120, sample_size=1087.7, sample_size_v1=0, sample_size_v2=0, ppl=2.15, wps=528.7, ups=0.49, wpb=1087.7, bsz=120, num_updates=6320, lr=2.85213e-05, gnorm=3.895, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=13031
2023-06-26 21:56:47 - progress_bar.py[line:272] - INFO: epoch 002:   2625 / 3715 loss=2.323, loss_v1=0, loss_v2=0, nll_loss=1.118, ntokens=1085.3, nsentences=120, sample_size=1085.3, sample_size_v1=0, sample_size_v2=0, ppl=2.17, wps=527.7, ups=0.49, wpb=1085.3, bsz=120, num_updates=6330, lr=2.85159e-05, gnorm=3.641, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=13052
2023-06-26 21:57:08 - progress_bar.py[line:272] - INFO: epoch 002:   2635 / 3715 loss=2.306, loss_v1=0, loss_v2=0, nll_loss=1.099, ntokens=1082.5, nsentences=120, sample_size=1082.5, sample_size_v1=0, sample_size_v2=0, ppl=2.14, wps=525.8, ups=0.49, wpb=1082.5, bsz=120, num_updates=6340, lr=2.85106e-05, gnorm=3.864, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=13072
2023-06-26 21:57:29 - progress_bar.py[line:272] - INFO: epoch 002:   2645 / 3715 loss=2.311, loss_v1=0, loss_v2=0, nll_loss=1.106, ntokens=1094.7, nsentences=120, sample_size=1094.7, sample_size_v1=0, sample_size_v2=0, ppl=2.15, wps=532.4, ups=0.49, wpb=1094.7, bsz=120, num_updates=6350, lr=2.85052e-05, gnorm=3.803, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=13093
2023-06-26 21:57:49 - progress_bar.py[line:272] - INFO: epoch 002:   2655 / 3715 loss=2.302, loss_v1=0, loss_v2=0, nll_loss=1.09, ntokens=1062.1, nsentences=120, sample_size=1062.1, sample_size_v1=0, sample_size_v2=0, ppl=2.13, wps=516.2, ups=0.49, wpb=1062.1, bsz=120, num_updates=6360, lr=2.84998e-05, gnorm=3.692, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=13114
2023-06-26 21:58:10 - progress_bar.py[line:272] - INFO: epoch 002:   2665 / 3715 loss=2.309, loss_v1=0, loss_v2=0, nll_loss=1.102, ntokens=1092.2, nsentences=120, sample_size=1092.2, sample_size_v1=0, sample_size_v2=0, ppl=2.15, wps=531.2, ups=0.49, wpb=1092.2, bsz=120, num_updates=6370, lr=2.84945e-05, gnorm=3.69, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=13134
2023-06-26 21:58:30 - progress_bar.py[line:272] - INFO: epoch 002:   2675 / 3715 loss=2.314, loss_v1=0, loss_v2=0, nll_loss=1.107, ntokens=1086.8, nsentences=120, sample_size=1086.8, sample_size_v1=0, sample_size_v2=0, ppl=2.15, wps=527.7, ups=0.49, wpb=1086.8, bsz=120, num_updates=6380, lr=2.84891e-05, gnorm=3.672, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=13155
2023-06-26 21:58:51 - progress_bar.py[line:272] - INFO: epoch 002:   2685 / 3715 loss=2.31, loss_v1=0, loss_v2=0, nll_loss=1.102, ntokens=1075.8, nsentences=120, sample_size=1075.8, sample_size_v1=0, sample_size_v2=0, ppl=2.15, wps=522.4, ups=0.49, wpb=1075.8, bsz=120, num_updates=6390, lr=2.84837e-05, gnorm=3.478, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=13175
2023-06-26 21:59:12 - progress_bar.py[line:272] - INFO: epoch 002:   2695 / 3715 loss=2.313, loss_v1=0, loss_v2=0, nll_loss=1.108, ntokens=1091.6, nsentences=120, sample_size=1091.6, sample_size_v1=0, sample_size_v2=0, ppl=2.16, wps=530.4, ups=0.49, wpb=1091.6, bsz=120, num_updates=6400, lr=2.84784e-05, gnorm=3.548, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=13196
2023-06-26 21:59:32 - progress_bar.py[line:272] - INFO: epoch 002:   2705 / 3715 loss=2.288, loss_v1=0, loss_v2=0, nll_loss=1.078, ntokens=1091.2, nsentences=120, sample_size=1091.2, sample_size_v1=0, sample_size_v2=0, ppl=2.11, wps=530.9, ups=0.49, wpb=1091.2, bsz=120, num_updates=6410, lr=2.8473e-05, gnorm=3.78, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=13216
2023-06-26 21:59:53 - progress_bar.py[line:272] - INFO: epoch 002:   2715 / 3715 loss=2.298, loss_v1=0, loss_v2=0, nll_loss=1.089, ntokens=1089.5, nsentences=120, sample_size=1089.5, sample_size_v1=0, sample_size_v2=0, ppl=2.13, wps=530.5, ups=0.49, wpb=1089.5, bsz=120, num_updates=6420, lr=2.84676e-05, gnorm=3.588, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=13237
2023-06-26 22:00:13 - progress_bar.py[line:272] - INFO: epoch 002:   2725 / 3715 loss=2.295, loss_v1=0, loss_v2=0, nll_loss=1.086, ntokens=1075.5, nsentences=120, sample_size=1075.5, sample_size_v1=0, sample_size_v2=0, ppl=2.12, wps=522.7, ups=0.49, wpb=1075.5, bsz=120, num_updates=6430, lr=2.84623e-05, gnorm=3.667, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=13258
2023-06-26 22:00:34 - progress_bar.py[line:272] - INFO: epoch 002:   2735 / 3715 loss=2.298, loss_v1=0, loss_v2=0, nll_loss=1.089, ntokens=1085.3, nsentences=120, sample_size=1085.3, sample_size_v1=0, sample_size_v2=0, ppl=2.13, wps=527.4, ups=0.49, wpb=1085.3, bsz=120, num_updates=6440, lr=2.84569e-05, gnorm=3.533, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=13278
2023-06-26 22:00:54 - progress_bar.py[line:272] - INFO: epoch 002:   2745 / 3715 loss=2.284, loss_v1=0, loss_v2=0, nll_loss=1.075, ntokens=1090.5, nsentences=120, sample_size=1090.5, sample_size_v1=0, sample_size_v2=0, ppl=2.11, wps=530.2, ups=0.49, wpb=1090.5, bsz=120, num_updates=6450, lr=2.84515e-05, gnorm=3.592, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=13299
2023-06-26 22:01:15 - progress_bar.py[line:272] - INFO: epoch 002:   2755 / 3715 loss=2.315, loss_v1=0, loss_v2=0, nll_loss=1.107, ntokens=1050.9, nsentences=120, sample_size=1050.9, sample_size_v1=0, sample_size_v2=0, ppl=2.15, wps=510.7, ups=0.49, wpb=1050.9, bsz=120, num_updates=6460, lr=2.84461e-05, gnorm=3.507, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=13319
2023-06-26 22:01:36 - progress_bar.py[line:272] - INFO: epoch 002:   2765 / 3715 loss=2.305, loss_v1=0, loss_v2=0, nll_loss=1.098, ntokens=1095.3, nsentences=120, sample_size=1095.3, sample_size_v1=0, sample_size_v2=0, ppl=2.14, wps=532.2, ups=0.49, wpb=1095.3, bsz=120, num_updates=6470, lr=2.84408e-05, gnorm=3.58, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=13340
2023-06-26 22:01:56 - progress_bar.py[line:272] - INFO: epoch 002:   2775 / 3715 loss=2.306, loss_v1=0, loss_v2=0, nll_loss=1.096, ntokens=1108.4, nsentences=120, sample_size=1108.4, sample_size_v1=0, sample_size_v2=0, ppl=2.14, wps=539.4, ups=0.49, wpb=1108.4, bsz=120, num_updates=6480, lr=2.84354e-05, gnorm=3.448, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=13360
2023-06-26 22:02:17 - progress_bar.py[line:272] - INFO: epoch 002:   2785 / 3715 loss=2.313, loss_v1=0, loss_v2=0, nll_loss=1.108, ntokens=1081.7, nsentences=120, sample_size=1081.7, sample_size_v1=0, sample_size_v2=0, ppl=2.16, wps=525.9, ups=0.49, wpb=1081.7, bsz=120, num_updates=6490, lr=2.843e-05, gnorm=3.436, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=13381
2023-06-26 22:02:37 - progress_bar.py[line:272] - INFO: epoch 002:   2795 / 3715 loss=2.292, loss_v1=0, loss_v2=0, nll_loss=1.083, ntokens=1091.6, nsentences=120, sample_size=1091.6, sample_size_v1=0, sample_size_v2=0, ppl=2.12, wps=530.9, ups=0.49, wpb=1091.6, bsz=120, num_updates=6500, lr=2.84247e-05, gnorm=3.755, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=13402
2023-06-26 22:02:56 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 256.0
2023-06-26 22:03:00 - progress_bar.py[line:272] - INFO: epoch 002:   2806 / 3715 loss=2.299, loss_v1=0, loss_v2=0, nll_loss=1.089, ntokens=1069.2, nsentences=120, sample_size=1069.2, sample_size_v1=0, sample_size_v2=0, ppl=2.13, wps=473.3, ups=0.44, wpb=1069.2, bsz=120, num_updates=6510, lr=2.84193e-05, gnorm=3.719, clip=100, loss_scale=256, train_wall=23, gb_free=8.9, wall=13424
2023-06-26 22:03:20 - progress_bar.py[line:272] - INFO: epoch 002:   2816 / 3715 loss=2.3, loss_v1=0, loss_v2=0, nll_loss=1.091, ntokens=1085.9, nsentences=120, sample_size=1085.9, sample_size_v1=0, sample_size_v2=0, ppl=2.13, wps=527.9, ups=0.49, wpb=1085.9, bsz=120, num_updates=6520, lr=2.84139e-05, gnorm=3.714, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=13445
2023-06-26 22:03:41 - progress_bar.py[line:272] - INFO: epoch 002:   2826 / 3715 loss=2.305, loss_v1=0, loss_v2=0, nll_loss=1.097, ntokens=1067.1, nsentences=120, sample_size=1067.1, sample_size_v1=0, sample_size_v2=0, ppl=2.14, wps=518.6, ups=0.49, wpb=1067.1, bsz=120, num_updates=6530, lr=2.84086e-05, gnorm=3.73, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=13465
2023-06-26 22:04:02 - progress_bar.py[line:272] - INFO: epoch 002:   2836 / 3715 loss=2.29, loss_v1=0, loss_v2=0, nll_loss=1.081, ntokens=1095.9, nsentences=120, sample_size=1095.9, sample_size_v1=0, sample_size_v2=0, ppl=2.12, wps=532.5, ups=0.49, wpb=1095.9, bsz=120, num_updates=6540, lr=2.84032e-05, gnorm=3.699, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=13486
2023-06-26 22:04:22 - progress_bar.py[line:272] - INFO: epoch 002:   2846 / 3715 loss=2.277, loss_v1=0, loss_v2=0, nll_loss=1.066, ntokens=1096.2, nsentences=120, sample_size=1096.2, sample_size_v1=0, sample_size_v2=0, ppl=2.09, wps=532.7, ups=0.49, wpb=1096.2, bsz=120, num_updates=6550, lr=2.83978e-05, gnorm=3.513, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=13506
2023-06-26 22:04:43 - progress_bar.py[line:272] - INFO: epoch 002:   2856 / 3715 loss=2.312, loss_v1=0, loss_v2=0, nll_loss=1.105, ntokens=1093.8, nsentences=120, sample_size=1093.8, sample_size_v1=0, sample_size_v2=0, ppl=2.15, wps=531.4, ups=0.49, wpb=1093.8, bsz=120, num_updates=6560, lr=2.83925e-05, gnorm=3.628, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=13527
2023-06-26 22:05:03 - progress_bar.py[line:272] - INFO: epoch 002:   2866 / 3715 loss=2.308, loss_v1=0, loss_v2=0, nll_loss=1.099, ntokens=1094.8, nsentences=120, sample_size=1094.8, sample_size_v1=0, sample_size_v2=0, ppl=2.14, wps=531.9, ups=0.49, wpb=1094.8, bsz=120, num_updates=6570, lr=2.83871e-05, gnorm=3.615, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=13548
2023-06-26 22:05:24 - progress_bar.py[line:272] - INFO: epoch 002:   2876 / 3715 loss=2.275, loss_v1=0, loss_v2=0, nll_loss=1.065, ntokens=1083.7, nsentences=120, sample_size=1083.7, sample_size_v1=0, sample_size_v2=0, ppl=2.09, wps=526.7, ups=0.49, wpb=1083.7, bsz=120, num_updates=6580, lr=2.83817e-05, gnorm=3.415, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=13568
2023-06-26 22:05:44 - progress_bar.py[line:272] - INFO: epoch 002:   2886 / 3715 loss=2.298, loss_v1=0, loss_v2=0, nll_loss=1.089, ntokens=1089.5, nsentences=120, sample_size=1089.5, sample_size_v1=0, sample_size_v2=0, ppl=2.13, wps=530.1, ups=0.49, wpb=1089.5, bsz=120, num_updates=6590, lr=2.83763e-05, gnorm=3.819, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=13589
2023-06-26 22:06:05 - progress_bar.py[line:272] - INFO: epoch 002:   2896 / 3715 loss=2.302, loss_v1=0, loss_v2=0, nll_loss=1.093, ntokens=1077.7, nsentences=120, sample_size=1077.7, sample_size_v1=0, sample_size_v2=0, ppl=2.13, wps=523.7, ups=0.49, wpb=1077.7, bsz=120, num_updates=6600, lr=2.8371e-05, gnorm=3.467, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=13609
2023-06-26 22:06:26 - progress_bar.py[line:272] - INFO: epoch 002:   2906 / 3715 loss=2.289, loss_v1=0, loss_v2=0, nll_loss=1.079, ntokens=1081, nsentences=120, sample_size=1081, sample_size_v1=0, sample_size_v2=0, ppl=2.11, wps=525.5, ups=0.49, wpb=1081, bsz=120, num_updates=6610, lr=2.83656e-05, gnorm=3.456, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=13630
2023-06-26 22:06:46 - progress_bar.py[line:272] - INFO: epoch 002:   2916 / 3715 loss=2.3, loss_v1=0, loss_v2=0, nll_loss=1.09, ntokens=1085.9, nsentences=120, sample_size=1085.9, sample_size_v1=0, sample_size_v2=0, ppl=2.13, wps=527.7, ups=0.49, wpb=1085.9, bsz=120, num_updates=6620, lr=2.83602e-05, gnorm=3.76, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=13651
2023-06-26 22:07:07 - progress_bar.py[line:272] - INFO: epoch 002:   2926 / 3715 loss=2.294, loss_v1=0, loss_v2=0, nll_loss=1.085, ntokens=1083.7, nsentences=120, sample_size=1083.7, sample_size_v1=0, sample_size_v2=0, ppl=2.12, wps=527, ups=0.49, wpb=1083.7, bsz=120, num_updates=6630, lr=2.83549e-05, gnorm=3.584, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=13671
2023-06-26 22:07:27 - progress_bar.py[line:272] - INFO: epoch 002:   2936 / 3715 loss=2.305, loss_v1=0, loss_v2=0, nll_loss=1.097, ntokens=1097.3, nsentences=120, sample_size=1097.3, sample_size_v1=0, sample_size_v2=0, ppl=2.14, wps=533.9, ups=0.49, wpb=1097.3, bsz=120, num_updates=6640, lr=2.83495e-05, gnorm=3.643, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=13692
2023-06-26 22:07:48 - progress_bar.py[line:272] - INFO: epoch 002:   2946 / 3715 loss=2.296, loss_v1=0, loss_v2=0, nll_loss=1.09, ntokens=1081, nsentences=120, sample_size=1081, sample_size_v1=0, sample_size_v2=0, ppl=2.13, wps=526, ups=0.49, wpb=1081, bsz=120, num_updates=6650, lr=2.83441e-05, gnorm=3.539, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=13712
2023-06-26 22:08:08 - progress_bar.py[line:272] - INFO: epoch 002:   2956 / 3715 loss=2.289, loss_v1=0, loss_v2=0, nll_loss=1.077, ntokens=1087.8, nsentences=120, sample_size=1087.8, sample_size_v1=0, sample_size_v2=0, ppl=2.11, wps=528.1, ups=0.49, wpb=1087.8, bsz=120, num_updates=6660, lr=2.83388e-05, gnorm=3.899, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=13733
2023-06-26 22:08:29 - progress_bar.py[line:272] - INFO: epoch 002:   2966 / 3715 loss=2.305, loss_v1=0, loss_v2=0, nll_loss=1.098, ntokens=1078.3, nsentences=120, sample_size=1078.3, sample_size_v1=0, sample_size_v2=0, ppl=2.14, wps=524.3, ups=0.49, wpb=1078.3, bsz=120, num_updates=6670, lr=2.83334e-05, gnorm=3.806, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=13753
2023-06-26 22:08:50 - progress_bar.py[line:272] - INFO: epoch 002:   2976 / 3715 loss=2.295, loss_v1=0, loss_v2=0, nll_loss=1.085, ntokens=1098.9, nsentences=120, sample_size=1098.9, sample_size_v1=0, sample_size_v2=0, ppl=2.12, wps=534.1, ups=0.49, wpb=1098.9, bsz=120, num_updates=6680, lr=2.8328e-05, gnorm=3.772, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=13774
2023-06-26 22:09:10 - progress_bar.py[line:272] - INFO: epoch 002:   2986 / 3715 loss=2.301, loss_v1=0, loss_v2=0, nll_loss=1.093, ntokens=1077.7, nsentences=120, sample_size=1077.7, sample_size_v1=0, sample_size_v2=0, ppl=2.13, wps=524.2, ups=0.49, wpb=1077.7, bsz=120, num_updates=6690, lr=2.83227e-05, gnorm=3.779, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=13795
2023-06-26 22:09:31 - progress_bar.py[line:272] - INFO: epoch 002:   2996 / 3715 loss=2.294, loss_v1=0, loss_v2=0, nll_loss=1.084, ntokens=1093.6, nsentences=120, sample_size=1093.6, sample_size_v1=0, sample_size_v2=0, ppl=2.12, wps=533, ups=0.49, wpb=1093.6, bsz=120, num_updates=6700, lr=2.83173e-05, gnorm=3.734, clip=100, loss_scale=256, train_wall=20, gb_free=8.9, wall=13815
2023-06-26 22:09:51 - progress_bar.py[line:272] - INFO: epoch 002:   3006 / 3715 loss=2.309, loss_v1=0, loss_v2=0, nll_loss=1.102, ntokens=1090.9, nsentences=120, sample_size=1090.9, sample_size_v1=0, sample_size_v2=0, ppl=2.15, wps=531.4, ups=0.49, wpb=1090.9, bsz=120, num_updates=6710, lr=2.83119e-05, gnorm=3.614, clip=100, loss_scale=256, train_wall=20, gb_free=8.9, wall=13836
2023-06-26 22:10:12 - progress_bar.py[line:272] - INFO: epoch 002:   3016 / 3715 loss=2.308, loss_v1=0, loss_v2=0, nll_loss=1.101, ntokens=1087.8, nsentences=120, sample_size=1087.8, sample_size_v1=0, sample_size_v2=0, ppl=2.14, wps=530.2, ups=0.49, wpb=1087.8, bsz=120, num_updates=6720, lr=2.83065e-05, gnorm=3.522, clip=100, loss_scale=256, train_wall=20, gb_free=8.9, wall=13856
2023-06-26 22:10:32 - progress_bar.py[line:272] - INFO: epoch 002:   3026 / 3715 loss=2.303, loss_v1=0, loss_v2=0, nll_loss=1.095, ntokens=1073.1, nsentences=120, sample_size=1073.1, sample_size_v1=0, sample_size_v2=0, ppl=2.14, wps=522.1, ups=0.49, wpb=1073.1, bsz=120, num_updates=6730, lr=2.83012e-05, gnorm=3.683, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=13877
2023-06-26 22:10:53 - progress_bar.py[line:272] - INFO: epoch 002:   3036 / 3715 loss=2.292, loss_v1=0, loss_v2=0, nll_loss=1.083, ntokens=1070.8, nsentences=120, sample_size=1070.8, sample_size_v1=0, sample_size_v2=0, ppl=2.12, wps=521.4, ups=0.49, wpb=1070.8, bsz=120, num_updates=6740, lr=2.82958e-05, gnorm=3.661, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=13897
2023-06-26 22:11:13 - progress_bar.py[line:272] - INFO: epoch 002:   3046 / 3715 loss=2.287, loss_v1=0, loss_v2=0, nll_loss=1.077, ntokens=1085.1, nsentences=120, sample_size=1085.1, sample_size_v1=0, sample_size_v2=0, ppl=2.11, wps=528, ups=0.49, wpb=1085.1, bsz=120, num_updates=6750, lr=2.82904e-05, gnorm=3.445, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=13918
2023-06-26 22:11:34 - progress_bar.py[line:272] - INFO: epoch 002:   3056 / 3715 loss=2.294, loss_v1=0, loss_v2=0, nll_loss=1.085, ntokens=1081.2, nsentences=120, sample_size=1081.2, sample_size_v1=0, sample_size_v2=0, ppl=2.12, wps=525.7, ups=0.49, wpb=1081.2, bsz=120, num_updates=6760, lr=2.82851e-05, gnorm=3.392, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=13938
2023-06-26 22:11:54 - progress_bar.py[line:272] - INFO: epoch 002:   3066 / 3715 loss=2.288, loss_v1=0, loss_v2=0, nll_loss=1.078, ntokens=1087.4, nsentences=120, sample_size=1087.4, sample_size_v1=0, sample_size_v2=0, ppl=2.11, wps=529.6, ups=0.49, wpb=1087.4, bsz=120, num_updates=6770, lr=2.82797e-05, gnorm=3.506, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=13959
2023-06-26 22:12:15 - progress_bar.py[line:272] - INFO: epoch 002:   3076 / 3715 loss=2.29, loss_v1=0, loss_v2=0, nll_loss=1.081, ntokens=1087.2, nsentences=120, sample_size=1087.2, sample_size_v1=0, sample_size_v2=0, ppl=2.12, wps=529.6, ups=0.49, wpb=1087.2, bsz=120, num_updates=6780, lr=2.82743e-05, gnorm=3.695, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=13979
2023-06-26 22:12:36 - progress_bar.py[line:272] - INFO: epoch 002:   3086 / 3715 loss=2.288, loss_v1=0, loss_v2=0, nll_loss=1.078, ntokens=1069.7, nsentences=120, sample_size=1069.7, sample_size_v1=0, sample_size_v2=0, ppl=2.11, wps=520.2, ups=0.49, wpb=1069.7, bsz=120, num_updates=6790, lr=2.8269e-05, gnorm=3.585, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=14000
2023-06-26 22:12:56 - progress_bar.py[line:272] - INFO: epoch 002:   3096 / 3715 loss=2.299, loss_v1=0, loss_v2=0, nll_loss=1.089, ntokens=1064.3, nsentences=120, sample_size=1064.3, sample_size_v1=0, sample_size_v2=0, ppl=2.13, wps=517.6, ups=0.49, wpb=1064.3, bsz=120, num_updates=6800, lr=2.82636e-05, gnorm=3.939, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=14021
2023-06-26 22:13:17 - progress_bar.py[line:272] - INFO: epoch 002:   3106 / 3715 loss=2.295, loss_v1=0, loss_v2=0, nll_loss=1.087, ntokens=1062.7, nsentences=120, sample_size=1062.7, sample_size_v1=0, sample_size_v2=0, ppl=2.12, wps=516.7, ups=0.49, wpb=1062.7, bsz=120, num_updates=6810, lr=2.82582e-05, gnorm=3.571, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=14041
2023-06-26 22:13:37 - progress_bar.py[line:272] - INFO: epoch 002:   3116 / 3715 loss=2.285, loss_v1=0, loss_v2=0, nll_loss=1.076, ntokens=1080.7, nsentences=120, sample_size=1080.7, sample_size_v1=0, sample_size_v2=0, ppl=2.11, wps=525.3, ups=0.49, wpb=1080.7, bsz=120, num_updates=6820, lr=2.82529e-05, gnorm=3.459, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=14062
2023-06-26 22:13:58 - progress_bar.py[line:272] - INFO: epoch 002:   3126 / 3715 loss=2.28, loss_v1=0, loss_v2=0, nll_loss=1.067, ntokens=1068.4, nsentences=120, sample_size=1068.4, sample_size_v1=0, sample_size_v2=0, ppl=2.1, wps=519.3, ups=0.49, wpb=1068.4, bsz=120, num_updates=6830, lr=2.82475e-05, gnorm=3.677, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=14082
2023-06-26 22:14:18 - progress_bar.py[line:272] - INFO: epoch 002:   3136 / 3715 loss=2.292, loss_v1=0, loss_v2=0, nll_loss=1.084, ntokens=1084.7, nsentences=120, sample_size=1084.7, sample_size_v1=0, sample_size_v2=0, ppl=2.12, wps=527.1, ups=0.49, wpb=1084.7, bsz=120, num_updates=6840, lr=2.82421e-05, gnorm=3.692, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=14103
2023-06-26 22:14:39 - progress_bar.py[line:272] - INFO: epoch 002:   3146 / 3715 loss=2.294, loss_v1=0, loss_v2=0, nll_loss=1.084, ntokens=1069, nsentences=120, sample_size=1069, sample_size_v1=0, sample_size_v2=0, ppl=2.12, wps=519.9, ups=0.49, wpb=1069, bsz=120, num_updates=6850, lr=2.82367e-05, gnorm=3.847, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=14123
2023-06-26 22:15:00 - progress_bar.py[line:272] - INFO: epoch 002:   3156 / 3715 loss=2.286, loss_v1=0, loss_v2=0, nll_loss=1.077, ntokens=1079, nsentences=120, sample_size=1079, sample_size_v1=0, sample_size_v2=0, ppl=2.11, wps=524.8, ups=0.49, wpb=1079, bsz=120, num_updates=6860, lr=2.82314e-05, gnorm=3.768, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=14144
2023-06-26 22:15:20 - progress_bar.py[line:272] - INFO: epoch 002:   3166 / 3715 loss=2.293, loss_v1=0, loss_v2=0, nll_loss=1.081, ntokens=1105.1, nsentences=120, sample_size=1105.1, sample_size_v1=0, sample_size_v2=0, ppl=2.12, wps=538.4, ups=0.49, wpb=1105.1, bsz=120, num_updates=6870, lr=2.8226e-05, gnorm=3.591, clip=100, loss_scale=256, train_wall=20, gb_free=8.9, wall=14164
2023-06-26 22:15:41 - progress_bar.py[line:272] - INFO: epoch 002:   3176 / 3715 loss=2.284, loss_v1=0, loss_v2=0, nll_loss=1.076, ntokens=1081.5, nsentences=120, sample_size=1081.5, sample_size_v1=0, sample_size_v2=0, ppl=2.11, wps=525.5, ups=0.49, wpb=1081.5, bsz=120, num_updates=6880, lr=2.82206e-05, gnorm=3.482, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=14185
2023-06-26 22:16:01 - progress_bar.py[line:272] - INFO: epoch 002:   3186 / 3715 loss=2.27, loss_v1=0, loss_v2=0, nll_loss=1.057, ntokens=1076, nsentences=120, sample_size=1076, sample_size_v1=0, sample_size_v2=0, ppl=2.08, wps=522.9, ups=0.49, wpb=1076, bsz=120, num_updates=6890, lr=2.82153e-05, gnorm=3.773, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=14206
2023-06-26 22:16:22 - progress_bar.py[line:272] - INFO: epoch 002:   3196 / 3715 loss=2.283, loss_v1=0, loss_v2=0, nll_loss=1.073, ntokens=1073, nsentences=118.5, sample_size=1073, sample_size_v1=0, sample_size_v2=0, ppl=2.1, wps=527.7, ups=0.49, wpb=1073, bsz=118.5, num_updates=6900, lr=2.82099e-05, gnorm=3.532, clip=100, loss_scale=256, train_wall=20, gb_free=8.9, wall=14226
2023-06-26 22:16:42 - progress_bar.py[line:272] - INFO: epoch 002:   3206 / 3715 loss=2.269, loss_v1=0, loss_v2=0, nll_loss=1.058, ntokens=1073.5, nsentences=120, sample_size=1073.5, sample_size_v1=0, sample_size_v2=0, ppl=2.08, wps=521.8, ups=0.49, wpb=1073.5, bsz=120, num_updates=6910, lr=2.82045e-05, gnorm=3.558, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=14247
2023-06-26 22:17:03 - progress_bar.py[line:272] - INFO: epoch 002:   3216 / 3715 loss=2.271, loss_v1=0, loss_v2=0, nll_loss=1.056, ntokens=1078.2, nsentences=120, sample_size=1078.2, sample_size_v1=0, sample_size_v2=0, ppl=2.08, wps=524.2, ups=0.49, wpb=1078.2, bsz=120, num_updates=6920, lr=2.81992e-05, gnorm=3.309, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=14267
2023-06-26 22:17:23 - progress_bar.py[line:272] - INFO: epoch 002:   3226 / 3715 loss=2.297, loss_v1=0, loss_v2=0, nll_loss=1.089, ntokens=1092, nsentences=120, sample_size=1092, sample_size_v1=0, sample_size_v2=0, ppl=2.13, wps=531, ups=0.49, wpb=1092, bsz=120, num_updates=6930, lr=2.81938e-05, gnorm=3.432, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=14288
2023-06-26 22:17:44 - progress_bar.py[line:272] - INFO: epoch 002:   3236 / 3715 loss=2.287, loss_v1=0, loss_v2=0, nll_loss=1.077, ntokens=1073.4, nsentences=120, sample_size=1073.4, sample_size_v1=0, sample_size_v2=0, ppl=2.11, wps=522, ups=0.49, wpb=1073.4, bsz=120, num_updates=6940, lr=2.81884e-05, gnorm=3.482, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=14308
2023-06-26 22:18:04 - progress_bar.py[line:272] - INFO: epoch 002:   3246 / 3715 loss=2.279, loss_v1=0, loss_v2=0, nll_loss=1.067, ntokens=1082.1, nsentences=120, sample_size=1082.1, sample_size_v1=0, sample_size_v2=0, ppl=2.1, wps=525.8, ups=0.49, wpb=1082.1, bsz=120, num_updates=6950, lr=2.81831e-05, gnorm=3.253, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=14329
2023-06-26 22:18:25 - progress_bar.py[line:272] - INFO: epoch 002:   3256 / 3715 loss=2.286, loss_v1=0, loss_v2=0, nll_loss=1.076, ntokens=1082.7, nsentences=120, sample_size=1082.7, sample_size_v1=0, sample_size_v2=0, ppl=2.11, wps=526.1, ups=0.49, wpb=1082.7, bsz=120, num_updates=6960, lr=2.81777e-05, gnorm=3.477, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=14349
2023-06-26 22:18:46 - progress_bar.py[line:272] - INFO: epoch 002:   3266 / 3715 loss=2.287, loss_v1=0, loss_v2=0, nll_loss=1.078, ntokens=1080.3, nsentences=120, sample_size=1080.3, sample_size_v1=0, sample_size_v2=0, ppl=2.11, wps=525, ups=0.49, wpb=1080.3, bsz=120, num_updates=6970, lr=2.81723e-05, gnorm=3.343, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=14370
2023-06-26 22:19:06 - progress_bar.py[line:272] - INFO: epoch 002:   3276 / 3715 loss=2.285, loss_v1=0, loss_v2=0, nll_loss=1.075, ntokens=1079.2, nsentences=120, sample_size=1079.2, sample_size_v1=0, sample_size_v2=0, ppl=2.11, wps=524.2, ups=0.49, wpb=1079.2, bsz=120, num_updates=6980, lr=2.81669e-05, gnorm=3.498, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=14391
2023-06-26 22:19:27 - progress_bar.py[line:272] - INFO: epoch 002:   3286 / 3715 loss=2.278, loss_v1=0, loss_v2=0, nll_loss=1.067, ntokens=1072.3, nsentences=120, sample_size=1072.3, sample_size_v1=0, sample_size_v2=0, ppl=2.09, wps=520.9, ups=0.49, wpb=1072.3, bsz=120, num_updates=6990, lr=2.81616e-05, gnorm=3.352, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=14411
2023-06-26 22:19:47 - progress_bar.py[line:272] - INFO: epoch 002:   3296 / 3715 loss=2.283, loss_v1=0, loss_v2=0, nll_loss=1.073, ntokens=1097.9, nsentences=120, sample_size=1097.9, sample_size_v1=0, sample_size_v2=0, ppl=2.1, wps=533.6, ups=0.49, wpb=1097.9, bsz=120, num_updates=7000, lr=2.81562e-05, gnorm=3.446, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=14432
2023-06-26 22:20:08 - progress_bar.py[line:272] - INFO: epoch 002:   3306 / 3715 loss=2.287, loss_v1=0, loss_v2=0, nll_loss=1.078, ntokens=1098.4, nsentences=120, sample_size=1098.4, sample_size_v1=0, sample_size_v2=0, ppl=2.11, wps=534.1, ups=0.49, wpb=1098.4, bsz=120, num_updates=7010, lr=2.81508e-05, gnorm=3.443, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=14452
2023-06-26 22:20:29 - progress_bar.py[line:272] - INFO: epoch 002:   3316 / 3715 loss=2.282, loss_v1=0, loss_v2=0, nll_loss=1.07, ntokens=1064.8, nsentences=120, sample_size=1064.8, sample_size_v1=0, sample_size_v2=0, ppl=2.1, wps=518.4, ups=0.49, wpb=1064.8, bsz=120, num_updates=7020, lr=2.81455e-05, gnorm=3.531, clip=100, loss_scale=512, train_wall=21, gb_free=8.9, wall=14473
2023-06-26 22:20:33 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 256.0
2023-06-26 22:20:51 - progress_bar.py[line:272] - INFO: epoch 002:   3327 / 3715 loss=2.262, loss_v1=0, loss_v2=0, nll_loss=1.05, ntokens=1082.7, nsentences=120, sample_size=1082.7, sample_size_v1=0, sample_size_v2=0, ppl=2.07, wps=479.6, ups=0.44, wpb=1082.7, bsz=120, num_updates=7030, lr=2.81401e-05, gnorm=3.318, clip=100, loss_scale=256, train_wall=23, gb_free=8.9, wall=14495
2023-06-26 22:21:12 - progress_bar.py[line:272] - INFO: epoch 002:   3337 / 3715 loss=2.278, loss_v1=0, loss_v2=0, nll_loss=1.066, ntokens=1093.6, nsentences=120, sample_size=1093.6, sample_size_v1=0, sample_size_v2=0, ppl=2.09, wps=532, ups=0.49, wpb=1093.6, bsz=120, num_updates=7040, lr=2.81347e-05, gnorm=3.402, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=14516
2023-06-26 22:21:32 - progress_bar.py[line:272] - INFO: epoch 002:   3347 / 3715 loss=2.286, loss_v1=0, loss_v2=0, nll_loss=1.076, ntokens=1079.8, nsentences=120, sample_size=1079.8, sample_size_v1=0, sample_size_v2=0, ppl=2.11, wps=524.4, ups=0.49, wpb=1079.8, bsz=120, num_updates=7050, lr=2.81294e-05, gnorm=3.673, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=14537
2023-06-26 22:21:53 - progress_bar.py[line:272] - INFO: epoch 002:   3357 / 3715 loss=2.267, loss_v1=0, loss_v2=0, nll_loss=1.055, ntokens=1104.4, nsentences=120, sample_size=1104.4, sample_size_v1=0, sample_size_v2=0, ppl=2.08, wps=536.1, ups=0.49, wpb=1104.4, bsz=120, num_updates=7060, lr=2.8124e-05, gnorm=3.838, clip=100, loss_scale=256, train_wall=21, gb_free=8.8, wall=14557
2023-06-26 22:22:13 - progress_bar.py[line:272] - INFO: epoch 002:   3367 / 3715 loss=2.291, loss_v1=0, loss_v2=0, nll_loss=1.082, ntokens=1097.3, nsentences=120, sample_size=1097.3, sample_size_v1=0, sample_size_v2=0, ppl=2.12, wps=532.6, ups=0.49, wpb=1097.3, bsz=120, num_updates=7070, lr=2.81186e-05, gnorm=3.457, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=14578
2023-06-26 22:22:34 - progress_bar.py[line:272] - INFO: epoch 002:   3377 / 3715 loss=2.283, loss_v1=0, loss_v2=0, nll_loss=1.074, ntokens=1074.3, nsentences=120, sample_size=1074.3, sample_size_v1=0, sample_size_v2=0, ppl=2.11, wps=522.4, ups=0.49, wpb=1074.3, bsz=120, num_updates=7080, lr=2.81133e-05, gnorm=3.737, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=14598
2023-06-26 22:22:55 - progress_bar.py[line:272] - INFO: epoch 002:   3387 / 3715 loss=2.278, loss_v1=0, loss_v2=0, nll_loss=1.066, ntokens=1092.2, nsentences=120, sample_size=1092.2, sample_size_v1=0, sample_size_v2=0, ppl=2.09, wps=530.9, ups=0.49, wpb=1092.2, bsz=120, num_updates=7090, lr=2.81079e-05, gnorm=3.385, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=14619
2023-06-26 22:23:15 - progress_bar.py[line:272] - INFO: epoch 002:   3397 / 3715 loss=2.295, loss_v1=0, loss_v2=0, nll_loss=1.087, ntokens=1080.5, nsentences=120, sample_size=1080.5, sample_size_v1=0, sample_size_v2=0, ppl=2.12, wps=524.7, ups=0.49, wpb=1080.5, bsz=120, num_updates=7100, lr=2.81025e-05, gnorm=3.777, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=14640
2023-06-26 22:23:36 - progress_bar.py[line:272] - INFO: epoch 002:   3407 / 3715 loss=2.286, loss_v1=0, loss_v2=0, nll_loss=1.076, ntokens=1074.4, nsentences=120, sample_size=1074.4, sample_size_v1=0, sample_size_v2=0, ppl=2.11, wps=522, ups=0.49, wpb=1074.4, bsz=120, num_updates=7110, lr=2.80971e-05, gnorm=3.539, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=14660
2023-06-26 22:23:56 - progress_bar.py[line:272] - INFO: epoch 002:   3417 / 3715 loss=2.266, loss_v1=0, loss_v2=0, nll_loss=1.054, ntokens=1080.1, nsentences=120, sample_size=1080.1, sample_size_v1=0, sample_size_v2=0, ppl=2.08, wps=525, ups=0.49, wpb=1080.1, bsz=120, num_updates=7120, lr=2.80918e-05, gnorm=3.568, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=14681
2023-06-26 22:24:17 - progress_bar.py[line:272] - INFO: epoch 002:   3427 / 3715 loss=2.267, loss_v1=0, loss_v2=0, nll_loss=1.054, ntokens=1069.3, nsentences=120, sample_size=1069.3, sample_size_v1=0, sample_size_v2=0, ppl=2.08, wps=520.9, ups=0.49, wpb=1069.3, bsz=120, num_updates=7130, lr=2.80864e-05, gnorm=3.561, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=14701
2023-06-26 22:24:37 - progress_bar.py[line:272] - INFO: epoch 002:   3437 / 3715 loss=2.283, loss_v1=0, loss_v2=0, nll_loss=1.07, ntokens=1073.2, nsentences=120, sample_size=1073.2, sample_size_v1=0, sample_size_v2=0, ppl=2.1, wps=523.1, ups=0.49, wpb=1073.2, bsz=120, num_updates=7140, lr=2.8081e-05, gnorm=3.503, clip=100, loss_scale=256, train_wall=20, gb_free=8.9, wall=14722
2023-06-26 22:24:58 - progress_bar.py[line:272] - INFO: epoch 002:   3447 / 3715 loss=2.266, loss_v1=0, loss_v2=0, nll_loss=1.054, ntokens=1074.7, nsentences=120, sample_size=1074.7, sample_size_v1=0, sample_size_v2=0, ppl=2.08, wps=523.3, ups=0.49, wpb=1074.7, bsz=120, num_updates=7150, lr=2.80757e-05, gnorm=3.413, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=14742
2023-06-26 22:25:19 - progress_bar.py[line:272] - INFO: epoch 002:   3457 / 3715 loss=2.268, loss_v1=0, loss_v2=0, nll_loss=1.056, ntokens=1100.1, nsentences=120, sample_size=1100.1, sample_size_v1=0, sample_size_v2=0, ppl=2.08, wps=535.2, ups=0.49, wpb=1100.1, bsz=120, num_updates=7160, lr=2.80703e-05, gnorm=3.576, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=14763
2023-06-26 22:25:39 - progress_bar.py[line:272] - INFO: epoch 002:   3467 / 3715 loss=2.263, loss_v1=0, loss_v2=0, nll_loss=1.05, ntokens=1065.4, nsentences=120, sample_size=1065.4, sample_size_v1=0, sample_size_v2=0, ppl=2.07, wps=517.6, ups=0.49, wpb=1065.4, bsz=120, num_updates=7170, lr=2.80649e-05, gnorm=3.412, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=14783
2023-06-26 22:26:00 - progress_bar.py[line:272] - INFO: epoch 002:   3477 / 3715 loss=2.276, loss_v1=0, loss_v2=0, nll_loss=1.063, ntokens=1079.6, nsentences=120, sample_size=1079.6, sample_size_v1=0, sample_size_v2=0, ppl=2.09, wps=525, ups=0.49, wpb=1079.6, bsz=120, num_updates=7180, lr=2.80596e-05, gnorm=3.217, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=14804
2023-06-26 22:26:20 - progress_bar.py[line:272] - INFO: epoch 002:   3487 / 3715 loss=2.276, loss_v1=0, loss_v2=0, nll_loss=1.066, ntokens=1093.4, nsentences=120, sample_size=1093.4, sample_size_v1=0, sample_size_v2=0, ppl=2.09, wps=531.2, ups=0.49, wpb=1093.4, bsz=120, num_updates=7190, lr=2.80542e-05, gnorm=3.351, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=14825
2023-06-26 22:26:41 - progress_bar.py[line:272] - INFO: epoch 002:   3497 / 3715 loss=2.272, loss_v1=0, loss_v2=0, nll_loss=1.06, ntokens=1099.9, nsentences=120, sample_size=1099.9, sample_size_v1=0, sample_size_v2=0, ppl=2.08, wps=535.3, ups=0.49, wpb=1099.9, bsz=120, num_updates=7200, lr=2.80488e-05, gnorm=3.444, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=14845
2023-06-26 22:27:01 - progress_bar.py[line:272] - INFO: epoch 002:   3507 / 3715 loss=2.278, loss_v1=0, loss_v2=0, nll_loss=1.067, ntokens=1098.6, nsentences=120, sample_size=1098.6, sample_size_v1=0, sample_size_v2=0, ppl=2.1, wps=534.6, ups=0.49, wpb=1098.6, bsz=120, num_updates=7210, lr=2.80435e-05, gnorm=3.328, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=14866
2023-06-26 22:27:22 - progress_bar.py[line:272] - INFO: epoch 002:   3517 / 3715 loss=2.281, loss_v1=0, loss_v2=0, nll_loss=1.069, ntokens=1069, nsentences=120, sample_size=1069, sample_size_v1=0, sample_size_v2=0, ppl=2.1, wps=519.9, ups=0.49, wpb=1069, bsz=120, num_updates=7220, lr=2.80381e-05, gnorm=3.56, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=14886
2023-06-26 22:27:42 - progress_bar.py[line:272] - INFO: epoch 002:   3527 / 3715 loss=2.268, loss_v1=0, loss_v2=0, nll_loss=1.056, ntokens=1076.7, nsentences=120, sample_size=1076.7, sample_size_v1=0, sample_size_v2=0, ppl=2.08, wps=523.6, ups=0.49, wpb=1076.7, bsz=120, num_updates=7230, lr=2.80327e-05, gnorm=3.491, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=14907
2023-06-26 22:28:03 - progress_bar.py[line:272] - INFO: epoch 002:   3537 / 3715 loss=2.287, loss_v1=0, loss_v2=0, nll_loss=1.077, ntokens=1091.2, nsentences=120, sample_size=1091.2, sample_size_v1=0, sample_size_v2=0, ppl=2.11, wps=530.2, ups=0.49, wpb=1091.2, bsz=120, num_updates=7240, lr=2.80273e-05, gnorm=3.394, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=14927
2023-06-26 22:28:24 - progress_bar.py[line:272] - INFO: epoch 002:   3547 / 3715 loss=2.263, loss_v1=0, loss_v2=0, nll_loss=1.052, ntokens=1089.2, nsentences=120, sample_size=1089.2, sample_size_v1=0, sample_size_v2=0, ppl=2.07, wps=528.9, ups=0.49, wpb=1089.2, bsz=120, num_updates=7250, lr=2.8022e-05, gnorm=3.731, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=14948
2023-06-26 22:28:44 - progress_bar.py[line:272] - INFO: epoch 002:   3557 / 3715 loss=2.268, loss_v1=0, loss_v2=0, nll_loss=1.054, ntokens=1070, nsentences=120, sample_size=1070, sample_size_v1=0, sample_size_v2=0, ppl=2.08, wps=519.9, ups=0.49, wpb=1070, bsz=120, num_updates=7260, lr=2.80166e-05, gnorm=3.627, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=14969
2023-06-26 22:29:05 - progress_bar.py[line:272] - INFO: epoch 002:   3567 / 3715 loss=2.269, loss_v1=0, loss_v2=0, nll_loss=1.059, ntokens=1078.3, nsentences=120, sample_size=1078.3, sample_size_v1=0, sample_size_v2=0, ppl=2.08, wps=524.5, ups=0.49, wpb=1078.3, bsz=120, num_updates=7270, lr=2.80112e-05, gnorm=3.544, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=14989
2023-06-26 22:29:25 - progress_bar.py[line:272] - INFO: epoch 002:   3577 / 3715 loss=2.256, loss_v1=0, loss_v2=0, nll_loss=1.041, ntokens=1107, nsentences=120, sample_size=1107, sample_size_v1=0, sample_size_v2=0, ppl=2.06, wps=538.1, ups=0.49, wpb=1107, bsz=120, num_updates=7280, lr=2.80059e-05, gnorm=3.458, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=15010
2023-06-26 22:29:46 - progress_bar.py[line:272] - INFO: epoch 002:   3587 / 3715 loss=2.252, loss_v1=0, loss_v2=0, nll_loss=1.038, ntokens=1111.4, nsentences=120, sample_size=1111.4, sample_size_v1=0, sample_size_v2=0, ppl=2.05, wps=540.5, ups=0.49, wpb=1111.4, bsz=120, num_updates=7290, lr=2.80005e-05, gnorm=3.335, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=15030
2023-06-26 22:30:07 - progress_bar.py[line:272] - INFO: epoch 002:   3597 / 3715 loss=2.288, loss_v1=0, loss_v2=0, nll_loss=1.08, ntokens=1105.1, nsentences=120, sample_size=1105.1, sample_size_v1=0, sample_size_v2=0, ppl=2.11, wps=537.5, ups=0.49, wpb=1105.1, bsz=120, num_updates=7300, lr=2.79951e-05, gnorm=3.642, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=15051
2023-06-26 22:30:27 - progress_bar.py[line:272] - INFO: epoch 002:   3607 / 3715 loss=2.268, loss_v1=0, loss_v2=0, nll_loss=1.053, ntokens=1063.2, nsentences=120, sample_size=1063.2, sample_size_v1=0, sample_size_v2=0, ppl=2.07, wps=517.3, ups=0.49, wpb=1063.2, bsz=120, num_updates=7310, lr=2.79898e-05, gnorm=3.477, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=15071
2023-06-26 22:30:48 - progress_bar.py[line:272] - INFO: epoch 002:   3617 / 3715 loss=2.269, loss_v1=0, loss_v2=0, nll_loss=1.059, ntokens=1081.4, nsentences=120, sample_size=1081.4, sample_size_v1=0, sample_size_v2=0, ppl=2.08, wps=526, ups=0.49, wpb=1081.4, bsz=120, num_updates=7320, lr=2.79844e-05, gnorm=3.463, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=15092
2023-06-26 22:31:08 - progress_bar.py[line:272] - INFO: epoch 002:   3627 / 3715 loss=2.274, loss_v1=0, loss_v2=0, nll_loss=1.061, ntokens=1080.1, nsentences=120, sample_size=1080.1, sample_size_v1=0, sample_size_v2=0, ppl=2.09, wps=520.7, ups=0.48, wpb=1080.1, bsz=120, num_updates=7330, lr=2.7979e-05, gnorm=3.673, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=15113
2023-06-26 22:31:29 - progress_bar.py[line:272] - INFO: epoch 002:   3637 / 3715 loss=2.268, loss_v1=0, loss_v2=0, nll_loss=1.057, ntokens=1071, nsentences=120, sample_size=1071, sample_size_v1=0, sample_size_v2=0, ppl=2.08, wps=522, ups=0.49, wpb=1071, bsz=120, num_updates=7340, lr=2.79737e-05, gnorm=3.598, clip=100, loss_scale=256, train_wall=20, gb_free=8.9, wall=15133
2023-06-26 22:31:49 - progress_bar.py[line:272] - INFO: epoch 002:   3647 / 3715 loss=2.262, loss_v1=0, loss_v2=0, nll_loss=1.049, ntokens=1077.6, nsentences=120, sample_size=1077.6, sample_size_v1=0, sample_size_v2=0, ppl=2.07, wps=524.8, ups=0.49, wpb=1077.6, bsz=120, num_updates=7350, lr=2.79683e-05, gnorm=3.437, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=15154
2023-06-26 22:32:10 - progress_bar.py[line:272] - INFO: epoch 002:   3657 / 3715 loss=2.275, loss_v1=0, loss_v2=0, nll_loss=1.066, ntokens=1076.7, nsentences=120, sample_size=1076.7, sample_size_v1=0, sample_size_v2=0, ppl=2.09, wps=524.5, ups=0.49, wpb=1076.7, bsz=120, num_updates=7360, lr=2.79629e-05, gnorm=3.724, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=15174
2023-06-26 22:32:31 - progress_bar.py[line:272] - INFO: epoch 002:   3667 / 3715 loss=2.268, loss_v1=0, loss_v2=0, nll_loss=1.056, ntokens=1083.5, nsentences=120, sample_size=1083.5, sample_size_v1=0, sample_size_v2=0, ppl=2.08, wps=527.3, ups=0.49, wpb=1083.5, bsz=120, num_updates=7370, lr=2.79575e-05, gnorm=3.498, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=15195
2023-06-26 22:32:51 - progress_bar.py[line:272] - INFO: epoch 002:   3677 / 3715 loss=2.253, loss_v1=0, loss_v2=0, nll_loss=1.038, ntokens=1084.7, nsentences=120, sample_size=1084.7, sample_size_v1=0, sample_size_v2=0, ppl=2.05, wps=528.1, ups=0.49, wpb=1084.7, bsz=120, num_updates=7380, lr=2.79522e-05, gnorm=3.466, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=15215
2023-06-26 22:33:12 - progress_bar.py[line:272] - INFO: epoch 002:   3687 / 3715 loss=2.257, loss_v1=0, loss_v2=0, nll_loss=1.043, ntokens=1074.2, nsentences=120, sample_size=1074.2, sample_size_v1=0, sample_size_v2=0, ppl=2.06, wps=521.8, ups=0.49, wpb=1074.2, bsz=120, num_updates=7390, lr=2.79468e-05, gnorm=3.62, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=15236
2023-06-26 22:33:32 - progress_bar.py[line:272] - INFO: epoch 002:   3697 / 3715 loss=2.256, loss_v1=0, loss_v2=0, nll_loss=1.043, ntokens=1101.1, nsentences=120, sample_size=1101.1, sample_size_v1=0, sample_size_v2=0, ppl=2.06, wps=535.2, ups=0.49, wpb=1101.1, bsz=120, num_updates=7400, lr=2.79414e-05, gnorm=3.739, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=15257
2023-06-26 22:33:53 - progress_bar.py[line:272] - INFO: epoch 002:   3707 / 3715 loss=2.255, loss_v1=0, loss_v2=0, nll_loss=1.042, ntokens=1082.4, nsentences=120, sample_size=1082.4, sample_size_v1=0, sample_size_v2=0, ppl=2.06, wps=526.6, ups=0.49, wpb=1082.4, bsz=120, num_updates=7410, lr=2.79361e-05, gnorm=3.758, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=15277
2023-06-26 22:34:09 - checkpoint_utils.py[line:64] - INFO: Preparing to save checkpoint for epoch 2 @ 7418 updates
2023-06-26 22:34:09 - trainer.py[line:431] - INFO: Saving checkpoint to ../../checkpoints/OFA/vrd_checkpoints/_16_3e-5_512_rare_balanced_2/checkpoint2.pt
local datafile ../../dataset/OFA_data/vrd_balanced/vg_train_full.tsv slice_id 1 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../dataset/OFA_data/vrd_balanced/vg_train_full.tsv slice_id 2 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../dataset/OFA_data/vrd_balanced/vg_train_full.tsv slice_id 1 finished initializing row_count and line_idx-to-offset mapping
file ../../dataset/OFA_data/vrd_balanced/vg_train_full.tsv slice_id 1 row count 148595 total row count 445785
local datafile ../../dataset/OFA_data/vrd_balanced/vg_train_full.tsv slice_id 2 finished initializing row_count and line_idx-to-offset mapping
file ../../dataset/OFA_data/vrd_balanced/vg_train_full.tsv slice_id 2 row count 148595 total row count 445785
slice_id 2 seek offset 297190
slice_id 1 seek offset 148595
2023-06-26 22:34:16 - trainer.py[line:441] - INFO: Finished saving checkpoint to ../../checkpoints/OFA/vrd_checkpoints/_16_3e-5_512_rare_balanced_2/checkpoint2.pt
2023-06-26 22:34:20 - checkpoint_utils.py[line:133] - INFO: Saved checkpoint ../../checkpoints/OFA/vrd_checkpoints/_16_3e-5_512_rare_balanced_2/checkpoint2.pt (epoch 2 @ 7418 updates, score None) (writing took 10.75311250705272 seconds)
2023-06-26 22:34:20 - train.py[line:332] - INFO: end of epoch 2 (average epoch stats below)
2023-06-26 22:34:20 - progress_bar.py[line:282] - INFO: epoch 002 | loss 2.352 | loss_v1 0 | loss_v2 0 | nll_loss 1.15 | ntokens 1083.44 | nsentences 119.996 | sample_size 1083.44 | sample_size_v1 0 | sample_size_v2 0 | ppl 2.22 | wps 525 | ups 0.48 | wpb 1083.4 | bsz 120 | num_updates 7418 | lr 2.79318e-05 | gnorm 3.592 | clip 100 | loss_scale 256 | train_wall 7629 | gb_free 8.9 | wall 15304
2023-06-26 22:34:20 - trainer.py[line:639] - INFO: loading train data for epoch 3
local datafile ../../dataset/OFA_data/vrd_balanced/vg_train_full.tsv slice_id 0 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../dataset/OFA_data/vrd_balanced/vg_train_full.tsv slice_id 0 finished initializing row_count and line_idx-to-offset mapping
file ../../dataset/OFA_data/vrd_balanced/vg_train_full.tsv slice_id 0 row count 148595 total row count 445785
slice_id 0 seek offset 0
2023-06-26 22:34:20 - trainer.py[line:703] - INFO: begin training epoch 3
2023-06-26 22:34:20 - train.py[line:305] - INFO: Start iterating over samples
2023-06-26 22:34:25 - progress_bar.py[line:272] - INFO: epoch 003:      2 / 3715 loss=2.27, loss_v1=0, loss_v2=0, nll_loss=1.055, ntokens=1084, nsentences=120, sample_size=1084, sample_size_v1=0, sample_size_v2=0, ppl=2.08, wps=340.1, ups=0.31, wpb=1084, bsz=120, num_updates=7420, lr=2.79307e-05, gnorm=3.637, clip=100, loss_scale=256, train_wall=20, gb_free=8.9, wall=15309
2023-06-26 22:34:45 - progress_bar.py[line:272] - INFO: epoch 003:     12 / 3715 loss=2.258, loss_v1=0, loss_v2=0, nll_loss=1.047, ntokens=1086.1, nsentences=120, sample_size=1086.1, sample_size_v1=0, sample_size_v2=0, ppl=2.07, wps=528.2, ups=0.49, wpb=1086.1, bsz=120, num_updates=7430, lr=2.79253e-05, gnorm=3.384, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=15330
2023-06-26 22:35:06 - progress_bar.py[line:272] - INFO: epoch 003:     22 / 3715 loss=2.246, loss_v1=0, loss_v2=0, nll_loss=1.031, ntokens=1078.3, nsentences=120, sample_size=1078.3, sample_size_v1=0, sample_size_v2=0, ppl=2.04, wps=524.3, ups=0.49, wpb=1078.3, bsz=120, num_updates=7440, lr=2.792e-05, gnorm=3.385, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=15350
2023-06-26 22:35:26 - progress_bar.py[line:272] - INFO: epoch 003:     32 / 3715 loss=2.28, loss_v1=0, loss_v2=0, nll_loss=1.07, ntokens=1088.2, nsentences=120, sample_size=1088.2, sample_size_v1=0, sample_size_v2=0, ppl=2.1, wps=528.2, ups=0.49, wpb=1088.2, bsz=120, num_updates=7450, lr=2.79146e-05, gnorm=3.328, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=15371
2023-06-26 22:35:47 - progress_bar.py[line:272] - INFO: epoch 003:     42 / 3715 loss=2.271, loss_v1=0, loss_v2=0, nll_loss=1.059, ntokens=1092, nsentences=120, sample_size=1092, sample_size_v1=0, sample_size_v2=0, ppl=2.08, wps=531.1, ups=0.49, wpb=1092, bsz=120, num_updates=7460, lr=2.79092e-05, gnorm=3.384, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=15391
2023-06-26 22:36:08 - progress_bar.py[line:272] - INFO: epoch 003:     52 / 3715 loss=2.261, loss_v1=0, loss_v2=0, nll_loss=1.048, ntokens=1089.5, nsentences=120, sample_size=1089.5, sample_size_v1=0, sample_size_v2=0, ppl=2.07, wps=529.5, ups=0.49, wpb=1089.5, bsz=120, num_updates=7470, lr=2.79039e-05, gnorm=3.649, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=15412
2023-06-26 22:36:28 - progress_bar.py[line:272] - INFO: epoch 003:     62 / 3715 loss=2.253, loss_v1=0, loss_v2=0, nll_loss=1.04, ntokens=1069.2, nsentences=120, sample_size=1069.2, sample_size_v1=0, sample_size_v2=0, ppl=2.06, wps=519.9, ups=0.49, wpb=1069.2, bsz=120, num_updates=7480, lr=2.78985e-05, gnorm=3.586, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=15432
2023-06-26 22:36:49 - progress_bar.py[line:272] - INFO: epoch 003:     72 / 3715 loss=2.26, loss_v1=0, loss_v2=0, nll_loss=1.045, ntokens=1089.3, nsentences=120, sample_size=1089.3, sample_size_v1=0, sample_size_v2=0, ppl=2.06, wps=529.4, ups=0.49, wpb=1089.3, bsz=120, num_updates=7490, lr=2.78931e-05, gnorm=3.581, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=15453
2023-06-26 22:37:09 - progress_bar.py[line:272] - INFO: epoch 003:     82 / 3715 loss=2.27, loss_v1=0, loss_v2=0, nll_loss=1.059, ntokens=1054.8, nsentences=120, sample_size=1054.8, sample_size_v1=0, sample_size_v2=0, ppl=2.08, wps=512.3, ups=0.49, wpb=1054.8, bsz=120, num_updates=7500, lr=2.78877e-05, gnorm=3.693, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=15474
2023-06-26 22:37:30 - progress_bar.py[line:272] - INFO: epoch 003:     92 / 3715 loss=2.274, loss_v1=0, loss_v2=0, nll_loss=1.062, ntokens=1098.3, nsentences=120, sample_size=1098.3, sample_size_v1=0, sample_size_v2=0, ppl=2.09, wps=533.6, ups=0.49, wpb=1098.3, bsz=120, num_updates=7510, lr=2.78824e-05, gnorm=3.603, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=15494
2023-06-26 22:37:50 - progress_bar.py[line:272] - INFO: epoch 003:    102 / 3715 loss=2.253, loss_v1=0, loss_v2=0, nll_loss=1.04, ntokens=1096.5, nsentences=120, sample_size=1096.5, sample_size_v1=0, sample_size_v2=0, ppl=2.06, wps=532.6, ups=0.49, wpb=1096.5, bsz=120, num_updates=7520, lr=2.7877e-05, gnorm=3.687, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=15515
2023-06-26 22:38:11 - progress_bar.py[line:272] - INFO: epoch 003:    112 / 3715 loss=2.271, loss_v1=0, loss_v2=0, nll_loss=1.059, ntokens=1107.3, nsentences=120, sample_size=1107.3, sample_size_v1=0, sample_size_v2=0, ppl=2.08, wps=538.6, ups=0.49, wpb=1107.3, bsz=120, num_updates=7530, lr=2.78716e-05, gnorm=3.2, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=15535
2023-06-26 22:38:21 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 256.0
2023-06-26 22:38:34 - progress_bar.py[line:272] - INFO: epoch 003:    123 / 3715 loss=2.249, loss_v1=0, loss_v2=0, nll_loss=1.034, ntokens=1080.4, nsentences=120, sample_size=1080.4, sample_size_v1=0, sample_size_v2=0, ppl=2.05, wps=477.9, ups=0.44, wpb=1080.4, bsz=120, num_updates=7540, lr=2.78663e-05, gnorm=3.494, clip=100, loss_scale=256, train_wall=23, gb_free=8.9, wall=15558
2023-06-26 22:38:54 - progress_bar.py[line:272] - INFO: epoch 003:    133 / 3715 loss=2.26, loss_v1=0, loss_v2=0, nll_loss=1.046, ntokens=1073.7, nsentences=120, sample_size=1073.7, sample_size_v1=0, sample_size_v2=0, ppl=2.07, wps=522.4, ups=0.49, wpb=1073.7, bsz=120, num_updates=7550, lr=2.78609e-05, gnorm=3.808, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=15579
2023-06-26 22:39:15 - progress_bar.py[line:272] - INFO: epoch 003:    143 / 3715 loss=2.269, loss_v1=0, loss_v2=0, nll_loss=1.057, ntokens=1094.2, nsentences=120, sample_size=1094.2, sample_size_v1=0, sample_size_v2=0, ppl=2.08, wps=532.1, ups=0.49, wpb=1094.2, bsz=120, num_updates=7560, lr=2.78555e-05, gnorm=3.405, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=15599
2023-06-26 22:39:35 - progress_bar.py[line:272] - INFO: epoch 003:    153 / 3715 loss=2.262, loss_v1=0, loss_v2=0, nll_loss=1.049, ntokens=1080.7, nsentences=120, sample_size=1080.7, sample_size_v1=0, sample_size_v2=0, ppl=2.07, wps=526.1, ups=0.49, wpb=1080.7, bsz=120, num_updates=7570, lr=2.78502e-05, gnorm=3.657, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=15620
2023-06-26 22:39:56 - progress_bar.py[line:272] - INFO: epoch 003:    163 / 3715 loss=2.252, loss_v1=0, loss_v2=0, nll_loss=1.038, ntokens=1069.9, nsentences=120, sample_size=1069.9, sample_size_v1=0, sample_size_v2=0, ppl=2.05, wps=521.1, ups=0.49, wpb=1069.9, bsz=120, num_updates=7580, lr=2.78448e-05, gnorm=3.489, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=15640
2023-06-26 22:40:16 - progress_bar.py[line:272] - INFO: epoch 003:    173 / 3715 loss=2.261, loss_v1=0, loss_v2=0, nll_loss=1.051, ntokens=1085.6, nsentences=120, sample_size=1085.6, sample_size_v1=0, sample_size_v2=0, ppl=2.07, wps=528.7, ups=0.49, wpb=1085.6, bsz=120, num_updates=7590, lr=2.78394e-05, gnorm=3.642, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=15661
2023-06-26 22:40:37 - progress_bar.py[line:272] - INFO: epoch 003:    183 / 3715 loss=2.245, loss_v1=0, loss_v2=0, nll_loss=1.028, ntokens=1105.7, nsentences=120, sample_size=1105.7, sample_size_v1=0, sample_size_v2=0, ppl=2.04, wps=538.4, ups=0.49, wpb=1105.7, bsz=120, num_updates=7600, lr=2.78341e-05, gnorm=3.47, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=15681
2023-06-26 22:40:58 - progress_bar.py[line:272] - INFO: epoch 003:    193 / 3715 loss=2.237, loss_v1=0, loss_v2=0, nll_loss=1.021, ntokens=1087.3, nsentences=120, sample_size=1087.3, sample_size_v1=0, sample_size_v2=0, ppl=2.03, wps=528.7, ups=0.49, wpb=1087.3, bsz=120, num_updates=7610, lr=2.78287e-05, gnorm=3.698, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=15702
2023-06-26 22:41:18 - progress_bar.py[line:272] - INFO: epoch 003:    203 / 3715 loss=2.263, loss_v1=0, loss_v2=0, nll_loss=1.05, ntokens=1059.2, nsentences=120, sample_size=1059.2, sample_size_v1=0, sample_size_v2=0, ppl=2.07, wps=514.6, ups=0.49, wpb=1059.2, bsz=120, num_updates=7620, lr=2.78233e-05, gnorm=3.767, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=15722
2023-06-26 22:41:39 - progress_bar.py[line:272] - INFO: epoch 003:    213 / 3715 loss=2.243, loss_v1=0, loss_v2=0, nll_loss=1.03, ntokens=1086.7, nsentences=120, sample_size=1086.7, sample_size_v1=0, sample_size_v2=0, ppl=2.04, wps=528, ups=0.49, wpb=1086.7, bsz=120, num_updates=7630, lr=2.78179e-05, gnorm=3.732, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=15743
2023-06-26 22:41:59 - progress_bar.py[line:272] - INFO: epoch 003:    223 / 3715 loss=2.258, loss_v1=0, loss_v2=0, nll_loss=1.044, ntokens=1082.8, nsentences=120, sample_size=1082.8, sample_size_v1=0, sample_size_v2=0, ppl=2.06, wps=526.7, ups=0.49, wpb=1082.8, bsz=120, num_updates=7640, lr=2.78126e-05, gnorm=3.69, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=15764
2023-06-26 22:42:20 - progress_bar.py[line:272] - INFO: epoch 003:    233 / 3715 loss=2.252, loss_v1=0, loss_v2=0, nll_loss=1.036, ntokens=1068.9, nsentences=120, sample_size=1068.9, sample_size_v1=0, sample_size_v2=0, ppl=2.05, wps=519.8, ups=0.49, wpb=1068.9, bsz=120, num_updates=7650, lr=2.78072e-05, gnorm=3.67, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=15784
2023-06-26 22:42:40 - progress_bar.py[line:272] - INFO: epoch 003:    243 / 3715 loss=2.255, loss_v1=0, loss_v2=0, nll_loss=1.043, ntokens=1086.3, nsentences=120, sample_size=1086.3, sample_size_v1=0, sample_size_v2=0, ppl=2.06, wps=528, ups=0.49, wpb=1086.3, bsz=120, num_updates=7660, lr=2.78018e-05, gnorm=3.543, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=15805
2023-06-26 22:43:01 - progress_bar.py[line:272] - INFO: epoch 003:    253 / 3715 loss=2.258, loss_v1=0, loss_v2=0, nll_loss=1.044, ntokens=1081.2, nsentences=120, sample_size=1081.2, sample_size_v1=0, sample_size_v2=0, ppl=2.06, wps=526.1, ups=0.49, wpb=1081.2, bsz=120, num_updates=7670, lr=2.77965e-05, gnorm=3.8, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=15825
2023-06-26 22:43:21 - progress_bar.py[line:272] - INFO: epoch 003:    263 / 3715 loss=2.237, loss_v1=0, loss_v2=0, nll_loss=1.023, ntokens=1067.6, nsentences=120, sample_size=1067.6, sample_size_v1=0, sample_size_v2=0, ppl=2.03, wps=519.7, ups=0.49, wpb=1067.6, bsz=120, num_updates=7680, lr=2.77911e-05, gnorm=3.627, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=15846
2023-06-26 22:43:42 - progress_bar.py[line:272] - INFO: epoch 003:    273 / 3715 loss=2.257, loss_v1=0, loss_v2=0, nll_loss=1.044, ntokens=1089.7, nsentences=120, sample_size=1089.7, sample_size_v1=0, sample_size_v2=0, ppl=2.06, wps=530.8, ups=0.49, wpb=1089.7, bsz=120, num_updates=7690, lr=2.77857e-05, gnorm=3.837, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=15866
2023-06-26 22:44:03 - progress_bar.py[line:272] - INFO: epoch 003:    283 / 3715 loss=2.248, loss_v1=0, loss_v2=0, nll_loss=1.033, ntokens=1083.5, nsentences=120, sample_size=1083.5, sample_size_v1=0, sample_size_v2=0, ppl=2.05, wps=528, ups=0.49, wpb=1083.5, bsz=120, num_updates=7700, lr=2.77804e-05, gnorm=3.518, clip=100, loss_scale=256, train_wall=20, gb_free=8.9, wall=15887
2023-06-26 22:44:23 - progress_bar.py[line:272] - INFO: epoch 003:    293 / 3715 loss=2.239, loss_v1=0, loss_v2=0, nll_loss=1.024, ntokens=1076.9, nsentences=120, sample_size=1076.9, sample_size_v1=0, sample_size_v2=0, ppl=2.03, wps=524.4, ups=0.49, wpb=1076.9, bsz=120, num_updates=7710, lr=2.7775e-05, gnorm=3.562, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=15907
2023-06-26 22:44:44 - progress_bar.py[line:272] - INFO: epoch 003:    303 / 3715 loss=2.242, loss_v1=0, loss_v2=0, nll_loss=1.027, ntokens=1067.1, nsentences=120, sample_size=1067.1, sample_size_v1=0, sample_size_v2=0, ppl=2.04, wps=519.8, ups=0.49, wpb=1067.1, bsz=120, num_updates=7720, lr=2.77696e-05, gnorm=3.752, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=15928
2023-06-26 22:45:04 - progress_bar.py[line:272] - INFO: epoch 003:    313 / 3715 loss=2.252, loss_v1=0, loss_v2=0, nll_loss=1.039, ntokens=1094.9, nsentences=120, sample_size=1094.9, sample_size_v1=0, sample_size_v2=0, ppl=2.06, wps=532.5, ups=0.49, wpb=1094.9, bsz=120, num_updates=7730, lr=2.77643e-05, gnorm=3.535, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=15949
2023-06-26 22:45:25 - progress_bar.py[line:272] - INFO: epoch 003:    323 / 3715 loss=2.246, loss_v1=0, loss_v2=0, nll_loss=1.03, ntokens=1093.4, nsentences=120, sample_size=1093.4, sample_size_v1=0, sample_size_v2=0, ppl=2.04, wps=531.1, ups=0.49, wpb=1093.4, bsz=120, num_updates=7740, lr=2.77589e-05, gnorm=3.361, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=15969
2023-06-26 22:45:45 - progress_bar.py[line:272] - INFO: epoch 003:    333 / 3715 loss=2.251, loss_v1=0, loss_v2=0, nll_loss=1.035, ntokens=1082.8, nsentences=120, sample_size=1082.8, sample_size_v1=0, sample_size_v2=0, ppl=2.05, wps=526, ups=0.49, wpb=1082.8, bsz=120, num_updates=7750, lr=2.77535e-05, gnorm=3.64, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=15990
2023-06-26 22:46:06 - progress_bar.py[line:272] - INFO: epoch 003:    343 / 3715 loss=2.253, loss_v1=0, loss_v2=0, nll_loss=1.039, ntokens=1068.8, nsentences=120, sample_size=1068.8, sample_size_v1=0, sample_size_v2=0, ppl=2.06, wps=519.9, ups=0.49, wpb=1068.8, bsz=120, num_updates=7760, lr=2.77481e-05, gnorm=3.684, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=16010
2023-06-26 22:46:26 - progress_bar.py[line:272] - INFO: epoch 003:    353 / 3715 loss=2.244, loss_v1=0, loss_v2=0, nll_loss=1.029, ntokens=1091.6, nsentences=120, sample_size=1091.6, sample_size_v1=0, sample_size_v2=0, ppl=2.04, wps=530.8, ups=0.49, wpb=1091.6, bsz=120, num_updates=7770, lr=2.77428e-05, gnorm=3.496, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=16031
2023-06-26 22:46:47 - progress_bar.py[line:272] - INFO: epoch 003:    363 / 3715 loss=2.245, loss_v1=0, loss_v2=0, nll_loss=1.029, ntokens=1107.3, nsentences=120, sample_size=1107.3, sample_size_v1=0, sample_size_v2=0, ppl=2.04, wps=537.7, ups=0.49, wpb=1107.3, bsz=120, num_updates=7780, lr=2.77374e-05, gnorm=3.369, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=16051
2023-06-26 22:47:08 - progress_bar.py[line:272] - INFO: epoch 003:    373 / 3715 loss=2.242, loss_v1=0, loss_v2=0, nll_loss=1.028, ntokens=1103, nsentences=120, sample_size=1103, sample_size_v1=0, sample_size_v2=0, ppl=2.04, wps=535.8, ups=0.49, wpb=1103, bsz=120, num_updates=7790, lr=2.7732e-05, gnorm=3.614, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=16072
2023-06-26 22:47:28 - progress_bar.py[line:272] - INFO: epoch 003:    383 / 3715 loss=2.25, loss_v1=0, loss_v2=0, nll_loss=1.034, ntokens=1071.2, nsentences=120, sample_size=1071.2, sample_size_v1=0, sample_size_v2=0, ppl=2.05, wps=520.8, ups=0.49, wpb=1071.2, bsz=120, num_updates=7800, lr=2.77267e-05, gnorm=3.706, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=16093
2023-06-26 22:47:49 - progress_bar.py[line:272] - INFO: epoch 003:    393 / 3715 loss=2.222, loss_v1=0, loss_v2=0, nll_loss=1.005, ntokens=1098.5, nsentences=120, sample_size=1098.5, sample_size_v1=0, sample_size_v2=0, ppl=2.01, wps=533.4, ups=0.49, wpb=1098.5, bsz=120, num_updates=7810, lr=2.77213e-05, gnorm=3.587, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=16113
2023-06-26 22:48:09 - progress_bar.py[line:272] - INFO: epoch 003:    403 / 3715 loss=2.238, loss_v1=0, loss_v2=0, nll_loss=1.022, ntokens=1068.2, nsentences=120, sample_size=1068.2, sample_size_v1=0, sample_size_v2=0, ppl=2.03, wps=519.3, ups=0.49, wpb=1068.2, bsz=120, num_updates=7820, lr=2.77159e-05, gnorm=3.666, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=16134
2023-06-26 22:48:30 - progress_bar.py[line:272] - INFO: epoch 003:    413 / 3715 loss=2.245, loss_v1=0, loss_v2=0, nll_loss=1.029, ntokens=1079.2, nsentences=120, sample_size=1079.2, sample_size_v1=0, sample_size_v2=0, ppl=2.04, wps=524.6, ups=0.49, wpb=1079.2, bsz=120, num_updates=7830, lr=2.77106e-05, gnorm=3.742, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=16154
2023-06-26 22:48:51 - progress_bar.py[line:272] - INFO: epoch 003:    423 / 3715 loss=2.247, loss_v1=0, loss_v2=0, nll_loss=1.032, ntokens=1096.5, nsentences=120, sample_size=1096.5, sample_size_v1=0, sample_size_v2=0, ppl=2.05, wps=533, ups=0.49, wpb=1096.5, bsz=120, num_updates=7840, lr=2.77052e-05, gnorm=3.41, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=16175
2023-06-26 22:49:11 - progress_bar.py[line:272] - INFO: epoch 003:    433 / 3715 loss=2.251, loss_v1=0, loss_v2=0, nll_loss=1.036, ntokens=1061.6, nsentences=120, sample_size=1061.6, sample_size_v1=0, sample_size_v2=0, ppl=2.05, wps=515.7, ups=0.49, wpb=1061.6, bsz=120, num_updates=7850, lr=2.76998e-05, gnorm=3.517, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=16196
2023-06-26 22:49:32 - progress_bar.py[line:272] - INFO: epoch 003:    443 / 3715 loss=2.236, loss_v1=0, loss_v2=0, nll_loss=1.022, ntokens=1104.8, nsentences=120, sample_size=1104.8, sample_size_v1=0, sample_size_v2=0, ppl=2.03, wps=536.4, ups=0.49, wpb=1104.8, bsz=120, num_updates=7860, lr=2.76945e-05, gnorm=3.344, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=16216
2023-06-26 22:49:52 - progress_bar.py[line:272] - INFO: epoch 003:    453 / 3715 loss=2.248, loss_v1=0, loss_v2=0, nll_loss=1.032, ntokens=1091.6, nsentences=120, sample_size=1091.6, sample_size_v1=0, sample_size_v2=0, ppl=2.05, wps=530.6, ups=0.49, wpb=1091.6, bsz=120, num_updates=7870, lr=2.76891e-05, gnorm=3.426, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=16237
2023-06-26 22:50:13 - progress_bar.py[line:272] - INFO: epoch 003:    463 / 3715 loss=2.223, loss_v1=0, loss_v2=0, nll_loss=1.006, ntokens=1077.9, nsentences=120, sample_size=1077.9, sample_size_v1=0, sample_size_v2=0, ppl=2.01, wps=523.9, ups=0.49, wpb=1077.9, bsz=120, num_updates=7880, lr=2.76837e-05, gnorm=3.484, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=16257
2023-06-26 22:50:33 - progress_bar.py[line:272] - INFO: epoch 003:    473 / 3715 loss=2.249, loss_v1=0, loss_v2=0, nll_loss=1.036, ntokens=1072.7, nsentences=120, sample_size=1072.7, sample_size_v1=0, sample_size_v2=0, ppl=2.05, wps=521.5, ups=0.49, wpb=1072.7, bsz=120, num_updates=7890, lr=2.76783e-05, gnorm=3.457, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=16278
2023-06-26 22:50:54 - progress_bar.py[line:272] - INFO: epoch 003:    483 / 3715 loss=2.239, loss_v1=0, loss_v2=0, nll_loss=1.023, ntokens=1084.9, nsentences=120, sample_size=1084.9, sample_size_v1=0, sample_size_v2=0, ppl=2.03, wps=527.9, ups=0.49, wpb=1084.9, bsz=120, num_updates=7900, lr=2.7673e-05, gnorm=3.56, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=16298
2023-06-26 22:51:15 - progress_bar.py[line:272] - INFO: epoch 003:    493 / 3715 loss=2.242, loss_v1=0, loss_v2=0, nll_loss=1.027, ntokens=1085.8, nsentences=120, sample_size=1085.8, sample_size_v1=0, sample_size_v2=0, ppl=2.04, wps=528.5, ups=0.49, wpb=1085.8, bsz=120, num_updates=7910, lr=2.76676e-05, gnorm=3.405, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=16319
2023-06-26 22:51:35 - progress_bar.py[line:272] - INFO: epoch 003:    503 / 3715 loss=2.237, loss_v1=0, loss_v2=0, nll_loss=1.02, ntokens=1086.4, nsentences=120, sample_size=1086.4, sample_size_v1=0, sample_size_v2=0, ppl=2.03, wps=528.2, ups=0.49, wpb=1086.4, bsz=120, num_updates=7920, lr=2.76622e-05, gnorm=3.369, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=16340
2023-06-26 22:51:56 - progress_bar.py[line:272] - INFO: epoch 003:    513 / 3715 loss=2.234, loss_v1=0, loss_v2=0, nll_loss=1.02, ntokens=1097, nsentences=120, sample_size=1097, sample_size_v1=0, sample_size_v2=0, ppl=2.03, wps=533.1, ups=0.49, wpb=1097, bsz=120, num_updates=7930, lr=2.76569e-05, gnorm=3.516, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=16360
2023-06-26 22:52:16 - progress_bar.py[line:272] - INFO: epoch 003:    523 / 3715 loss=2.224, loss_v1=0, loss_v2=0, nll_loss=1.006, ntokens=1078.1, nsentences=120, sample_size=1078.1, sample_size_v1=0, sample_size_v2=0, ppl=2.01, wps=524.1, ups=0.49, wpb=1078.1, bsz=120, num_updates=7940, lr=2.76515e-05, gnorm=3.488, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=16381
2023-06-26 22:52:37 - progress_bar.py[line:272] - INFO: epoch 003:    533 / 3715 loss=2.238, loss_v1=0, loss_v2=0, nll_loss=1.022, ntokens=1082.6, nsentences=120, sample_size=1082.6, sample_size_v1=0, sample_size_v2=0, ppl=2.03, wps=526.2, ups=0.49, wpb=1082.6, bsz=120, num_updates=7950, lr=2.76461e-05, gnorm=3.243, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=16401
2023-06-26 22:52:57 - progress_bar.py[line:272] - INFO: epoch 003:    543 / 3715 loss=2.238, loss_v1=0, loss_v2=0, nll_loss=1.021, ntokens=1067.5, nsentences=120, sample_size=1067.5, sample_size_v1=0, sample_size_v2=0, ppl=2.03, wps=518.6, ups=0.49, wpb=1067.5, bsz=120, num_updates=7960, lr=2.76408e-05, gnorm=3.539, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=16422
2023-06-26 22:53:18 - progress_bar.py[line:272] - INFO: epoch 003:    553 / 3715 loss=2.225, loss_v1=0, loss_v2=0, nll_loss=1.007, ntokens=1076.8, nsentences=120, sample_size=1076.8, sample_size_v1=0, sample_size_v2=0, ppl=2.01, wps=523.3, ups=0.49, wpb=1076.8, bsz=120, num_updates=7970, lr=2.76354e-05, gnorm=3.623, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=16442
2023-06-26 22:53:39 - progress_bar.py[line:272] - INFO: epoch 003:    563 / 3715 loss=2.255, loss_v1=0, loss_v2=0, nll_loss=1.041, ntokens=1072, nsentences=120, sample_size=1072, sample_size_v1=0, sample_size_v2=0, ppl=2.06, wps=521.2, ups=0.49, wpb=1072, bsz=120, num_updates=7980, lr=2.763e-05, gnorm=3.513, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=16463
2023-06-26 22:53:59 - progress_bar.py[line:272] - INFO: epoch 003:    573 / 3715 loss=2.253, loss_v1=0, loss_v2=0, nll_loss=1.04, ntokens=1082.5, nsentences=120, sample_size=1082.5, sample_size_v1=0, sample_size_v2=0, ppl=2.06, wps=525.9, ups=0.49, wpb=1082.5, bsz=120, num_updates=7990, lr=2.76247e-05, gnorm=3.304, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=16484
2023-06-26 22:54:20 - progress_bar.py[line:272] - INFO: epoch 003:    583 / 3715 loss=2.253, loss_v1=0, loss_v2=0, nll_loss=1.038, ntokens=1066.1, nsentences=120, sample_size=1066.1, sample_size_v1=0, sample_size_v2=0, ppl=2.05, wps=518.7, ups=0.49, wpb=1066.1, bsz=120, num_updates=8000, lr=2.76193e-05, gnorm=3.595, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=16504
2023-06-26 22:54:40 - progress_bar.py[line:272] - INFO: epoch 003:    593 / 3715 loss=2.259, loss_v1=0, loss_v2=0, nll_loss=1.045, ntokens=1087.8, nsentences=120, sample_size=1087.8, sample_size_v1=0, sample_size_v2=0, ppl=2.06, wps=528.2, ups=0.49, wpb=1087.8, bsz=120, num_updates=8010, lr=2.76139e-05, gnorm=3.475, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=16525
2023-06-26 22:55:01 - progress_bar.py[line:272] - INFO: epoch 003:    603 / 3715 loss=2.236, loss_v1=0, loss_v2=0, nll_loss=1.021, ntokens=1093, nsentences=120, sample_size=1093, sample_size_v1=0, sample_size_v2=0, ppl=2.03, wps=530.4, ups=0.49, wpb=1093, bsz=120, num_updates=8020, lr=2.76085e-05, gnorm=3.323, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=16545
2023-06-26 22:55:22 - progress_bar.py[line:272] - INFO: epoch 003:    613 / 3715 loss=2.228, loss_v1=0, loss_v2=0, nll_loss=1.011, ntokens=1090.2, nsentences=120, sample_size=1090.2, sample_size_v1=0, sample_size_v2=0, ppl=2.02, wps=529.7, ups=0.49, wpb=1090.2, bsz=120, num_updates=8030, lr=2.76032e-05, gnorm=3.305, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=16566
2023-06-26 22:55:42 - progress_bar.py[line:272] - INFO: epoch 003:    623 / 3715 loss=2.219, loss_v1=0, loss_v2=0, nll_loss=1.003, ntokens=1069.2, nsentences=120, sample_size=1069.2, sample_size_v1=0, sample_size_v2=0, ppl=2, wps=519.6, ups=0.49, wpb=1069.2, bsz=120, num_updates=8040, lr=2.75978e-05, gnorm=3.456, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=16587
2023-06-26 22:56:03 - progress_bar.py[line:272] - INFO: epoch 003:    633 / 3715 loss=2.249, loss_v1=0, loss_v2=0, nll_loss=1.035, ntokens=1087.6, nsentences=120, sample_size=1087.6, sample_size_v1=0, sample_size_v2=0, ppl=2.05, wps=528.7, ups=0.49, wpb=1087.6, bsz=120, num_updates=8050, lr=2.75924e-05, gnorm=3.485, clip=100, loss_scale=512, train_wall=21, gb_free=8.9, wall=16607
2023-06-26 22:56:07 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 256.0
2023-06-26 22:56:25 - progress_bar.py[line:272] - INFO: epoch 003:    644 / 3715 loss=2.248, loss_v1=0, loss_v2=0, nll_loss=1.032, ntokens=1068.6, nsentences=120, sample_size=1068.6, sample_size_v1=0, sample_size_v2=0, ppl=2.04, wps=472.5, ups=0.44, wpb=1068.6, bsz=120, num_updates=8060, lr=2.75871e-05, gnorm=3.463, clip=100, loss_scale=256, train_wall=23, gb_free=8.9, wall=16630
2023-06-26 22:56:46 - progress_bar.py[line:272] - INFO: epoch 003:    654 / 3715 loss=2.241, loss_v1=0, loss_v2=0, nll_loss=1.026, ntokens=1072.4, nsentences=120, sample_size=1072.4, sample_size_v1=0, sample_size_v2=0, ppl=2.04, wps=520.9, ups=0.49, wpb=1072.4, bsz=120, num_updates=8070, lr=2.75817e-05, gnorm=3.428, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=16650
2023-06-26 22:57:07 - progress_bar.py[line:272] - INFO: epoch 003:    664 / 3715 loss=2.221, loss_v1=0, loss_v2=0, nll_loss=1.001, ntokens=1072.1, nsentences=120, sample_size=1072.1, sample_size_v1=0, sample_size_v2=0, ppl=2, wps=520.8, ups=0.49, wpb=1072.1, bsz=120, num_updates=8080, lr=2.75763e-05, gnorm=3.423, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=16671
2023-06-26 22:57:27 - progress_bar.py[line:272] - INFO: epoch 003:    674 / 3715 loss=2.236, loss_v1=0, loss_v2=0, nll_loss=1.02, ntokens=1088.2, nsentences=120, sample_size=1088.2, sample_size_v1=0, sample_size_v2=0, ppl=2.03, wps=529.3, ups=0.49, wpb=1088.2, bsz=120, num_updates=8090, lr=2.7571e-05, gnorm=3.487, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=16691
2023-06-26 22:57:48 - progress_bar.py[line:272] - INFO: epoch 003:    684 / 3715 loss=2.227, loss_v1=0, loss_v2=0, nll_loss=1.011, ntokens=1064.2, nsentences=120, sample_size=1064.2, sample_size_v1=0, sample_size_v2=0, ppl=2.02, wps=517.9, ups=0.49, wpb=1064.2, bsz=120, num_updates=8100, lr=2.75656e-05, gnorm=3.454, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=16712
2023-06-26 22:58:08 - progress_bar.py[line:272] - INFO: epoch 003:    694 / 3715 loss=2.235, loss_v1=0, loss_v2=0, nll_loss=1.019, ntokens=1071.8, nsentences=120, sample_size=1071.8, sample_size_v1=0, sample_size_v2=0, ppl=2.03, wps=521.4, ups=0.49, wpb=1071.8, bsz=120, num_updates=8110, lr=2.75602e-05, gnorm=3.548, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=16733
2023-06-26 22:58:29 - progress_bar.py[line:272] - INFO: epoch 003:    704 / 3715 loss=2.252, loss_v1=0, loss_v2=0, nll_loss=1.036, ntokens=1099.8, nsentences=120, sample_size=1099.8, sample_size_v1=0, sample_size_v2=0, ppl=2.05, wps=535.1, ups=0.49, wpb=1099.8, bsz=120, num_updates=8120, lr=2.75549e-05, gnorm=3.579, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=16753
2023-06-26 22:58:49 - progress_bar.py[line:272] - INFO: epoch 003:    714 / 3715 loss=2.232, loss_v1=0, loss_v2=0, nll_loss=1.014, ntokens=1091.9, nsentences=120, sample_size=1091.9, sample_size_v1=0, sample_size_v2=0, ppl=2.02, wps=531.2, ups=0.49, wpb=1091.9, bsz=120, num_updates=8130, lr=2.75495e-05, gnorm=3.642, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=16774
2023-06-26 22:59:10 - progress_bar.py[line:272] - INFO: epoch 003:    724 / 3715 loss=2.223, loss_v1=0, loss_v2=0, nll_loss=1.005, ntokens=1075.4, nsentences=120, sample_size=1075.4, sample_size_v1=0, sample_size_v2=0, ppl=2.01, wps=523.2, ups=0.49, wpb=1075.4, bsz=120, num_updates=8140, lr=2.75441e-05, gnorm=3.379, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=16794
2023-06-26 22:59:30 - progress_bar.py[line:272] - INFO: epoch 003:    734 / 3715 loss=2.228, loss_v1=0, loss_v2=0, nll_loss=1.012, ntokens=1077.8, nsentences=120, sample_size=1077.8, sample_size_v1=0, sample_size_v2=0, ppl=2.02, wps=524.2, ups=0.49, wpb=1077.8, bsz=120, num_updates=8150, lr=2.75387e-05, gnorm=3.486, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=16815
2023-06-26 22:59:51 - progress_bar.py[line:272] - INFO: epoch 003:    744 / 3715 loss=2.232, loss_v1=0, loss_v2=0, nll_loss=1.015, ntokens=1081.2, nsentences=120, sample_size=1081.2, sample_size_v1=0, sample_size_v2=0, ppl=2.02, wps=526.5, ups=0.49, wpb=1081.2, bsz=120, num_updates=8160, lr=2.75334e-05, gnorm=3.329, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=16835
2023-06-26 23:00:12 - progress_bar.py[line:272] - INFO: epoch 003:    754 / 3715 loss=2.249, loss_v1=0, loss_v2=0, nll_loss=1.035, ntokens=1092.8, nsentences=120, sample_size=1092.8, sample_size_v1=0, sample_size_v2=0, ppl=2.05, wps=531, ups=0.49, wpb=1092.8, bsz=120, num_updates=8170, lr=2.7528e-05, gnorm=3.524, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=16856
2023-06-26 23:00:32 - progress_bar.py[line:272] - INFO: epoch 003:    764 / 3715 loss=2.225, loss_v1=0, loss_v2=0, nll_loss=1.009, ntokens=1077.4, nsentences=120, sample_size=1077.4, sample_size_v1=0, sample_size_v2=0, ppl=2.01, wps=524.3, ups=0.49, wpb=1077.4, bsz=120, num_updates=8180, lr=2.75226e-05, gnorm=3.631, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=16876
2023-06-26 23:00:53 - progress_bar.py[line:272] - INFO: epoch 003:    774 / 3715 loss=2.224, loss_v1=0, loss_v2=0, nll_loss=1.007, ntokens=1051.3, nsentences=120, sample_size=1051.3, sample_size_v1=0, sample_size_v2=0, ppl=2.01, wps=511.1, ups=0.49, wpb=1051.3, bsz=120, num_updates=8190, lr=2.75173e-05, gnorm=3.448, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=16897
2023-06-26 23:01:13 - progress_bar.py[line:272] - INFO: epoch 003:    784 / 3715 loss=2.224, loss_v1=0, loss_v2=0, nll_loss=1.005, ntokens=1088.1, nsentences=120, sample_size=1088.1, sample_size_v1=0, sample_size_v2=0, ppl=2.01, wps=529, ups=0.49, wpb=1088.1, bsz=120, num_updates=8200, lr=2.75119e-05, gnorm=3.623, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=16918
2023-06-26 23:01:34 - progress_bar.py[line:272] - INFO: epoch 003:    794 / 3715 loss=2.232, loss_v1=0, loss_v2=0, nll_loss=1.016, ntokens=1076.1, nsentences=120, sample_size=1076.1, sample_size_v1=0, sample_size_v2=0, ppl=2.02, wps=523.3, ups=0.49, wpb=1076.1, bsz=120, num_updates=8210, lr=2.75065e-05, gnorm=3.47, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=16938
2023-06-26 23:01:54 - progress_bar.py[line:272] - INFO: epoch 003:    804 / 3715 loss=2.223, loss_v1=0, loss_v2=0, nll_loss=1.006, ntokens=1084, nsentences=120, sample_size=1084, sample_size_v1=0, sample_size_v2=0, ppl=2.01, wps=527.7, ups=0.49, wpb=1084, bsz=120, num_updates=8220, lr=2.75012e-05, gnorm=3.467, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=16959
2023-06-26 23:02:15 - progress_bar.py[line:272] - INFO: epoch 003:    814 / 3715 loss=2.236, loss_v1=0, loss_v2=0, nll_loss=1.021, ntokens=1109.4, nsentences=120, sample_size=1109.4, sample_size_v1=0, sample_size_v2=0, ppl=2.03, wps=539.8, ups=0.49, wpb=1109.4, bsz=120, num_updates=8230, lr=2.74958e-05, gnorm=3.321, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=16979
2023-06-26 23:02:36 - progress_bar.py[line:272] - INFO: epoch 003:    824 / 3715 loss=2.23, loss_v1=0, loss_v2=0, nll_loss=1.014, ntokens=1100.6, nsentences=120, sample_size=1100.6, sample_size_v1=0, sample_size_v2=0, ppl=2.02, wps=535, ups=0.49, wpb=1100.6, bsz=120, num_updates=8240, lr=2.74904e-05, gnorm=3.632, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=17000
2023-06-26 23:02:56 - progress_bar.py[line:272] - INFO: epoch 003:    834 / 3715 loss=2.239, loss_v1=0, loss_v2=0, nll_loss=1.021, ntokens=1108.6, nsentences=120, sample_size=1108.6, sample_size_v1=0, sample_size_v2=0, ppl=2.03, wps=538.9, ups=0.49, wpb=1108.6, bsz=120, num_updates=8250, lr=2.74851e-05, gnorm=3.363, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=17020
2023-06-26 23:03:17 - progress_bar.py[line:272] - INFO: epoch 003:    844 / 3715 loss=2.228, loss_v1=0, loss_v2=0, nll_loss=1.013, ntokens=1080.1, nsentences=120, sample_size=1080.1, sample_size_v1=0, sample_size_v2=0, ppl=2.02, wps=525.1, ups=0.49, wpb=1080.1, bsz=120, num_updates=8260, lr=2.74797e-05, gnorm=3.421, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=17041
2023-06-26 23:03:37 - progress_bar.py[line:272] - INFO: epoch 003:    854 / 3715 loss=2.225, loss_v1=0, loss_v2=0, nll_loss=1.005, ntokens=1095.5, nsentences=120, sample_size=1095.5, sample_size_v1=0, sample_size_v2=0, ppl=2.01, wps=532.9, ups=0.49, wpb=1095.5, bsz=120, num_updates=8270, lr=2.74743e-05, gnorm=3.297, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=17062
2023-06-26 23:03:58 - progress_bar.py[line:272] - INFO: epoch 003:    864 / 3715 loss=2.233, loss_v1=0, loss_v2=0, nll_loss=1.019, ntokens=1082.8, nsentences=120, sample_size=1082.8, sample_size_v1=0, sample_size_v2=0, ppl=2.03, wps=527, ups=0.49, wpb=1082.8, bsz=120, num_updates=8280, lr=2.74689e-05, gnorm=3.551, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=17082
2023-06-26 23:04:18 - progress_bar.py[line:272] - INFO: epoch 003:    874 / 3715 loss=2.229, loss_v1=0, loss_v2=0, nll_loss=1.011, ntokens=1047.1, nsentences=118.5, sample_size=1047.1, sample_size_v1=0, sample_size_v2=0, ppl=2.02, wps=515.6, ups=0.49, wpb=1047.1, bsz=118.5, num_updates=8290, lr=2.74636e-05, gnorm=3.696, clip=100, loss_scale=256, train_wall=20, gb_free=8.9, wall=17102
2023-06-26 23:04:39 - progress_bar.py[line:272] - INFO: epoch 003:    884 / 3715 loss=2.252, loss_v1=0, loss_v2=0, nll_loss=1.039, ntokens=1091.7, nsentences=120, sample_size=1091.7, sample_size_v1=0, sample_size_v2=0, ppl=2.05, wps=531.7, ups=0.49, wpb=1091.7, bsz=120, num_updates=8300, lr=2.74582e-05, gnorm=3.53, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=17123
2023-06-26 23:04:59 - progress_bar.py[line:272] - INFO: epoch 003:    894 / 3715 loss=2.233, loss_v1=0, loss_v2=0, nll_loss=1.017, ntokens=1081.2, nsentences=120, sample_size=1081.2, sample_size_v1=0, sample_size_v2=0, ppl=2.02, wps=526.2, ups=0.49, wpb=1081.2, bsz=120, num_updates=8310, lr=2.74528e-05, gnorm=3.604, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=17144
2023-06-26 23:05:20 - progress_bar.py[line:272] - INFO: epoch 003:    904 / 3715 loss=2.215, loss_v1=0, loss_v2=0, nll_loss=0.996, ntokens=1070.2, nsentences=120, sample_size=1070.2, sample_size_v1=0, sample_size_v2=0, ppl=1.99, wps=520.6, ups=0.49, wpb=1070.2, bsz=120, num_updates=8320, lr=2.74475e-05, gnorm=3.464, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=17164
2023-06-26 23:05:40 - progress_bar.py[line:272] - INFO: epoch 003:    914 / 3715 loss=2.237, loss_v1=0, loss_v2=0, nll_loss=1.022, ntokens=1084.9, nsentences=120, sample_size=1084.9, sample_size_v1=0, sample_size_v2=0, ppl=2.03, wps=528.3, ups=0.49, wpb=1084.9, bsz=120, num_updates=8330, lr=2.74421e-05, gnorm=3.342, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=17185
2023-06-26 23:06:01 - progress_bar.py[line:272] - INFO: epoch 003:    924 / 3715 loss=2.242, loss_v1=0, loss_v2=0, nll_loss=1.027, ntokens=1083.3, nsentences=120, sample_size=1083.3, sample_size_v1=0, sample_size_v2=0, ppl=2.04, wps=527.4, ups=0.49, wpb=1083.3, bsz=120, num_updates=8340, lr=2.74367e-05, gnorm=3.2, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=17205
2023-06-26 23:06:21 - progress_bar.py[line:272] - INFO: epoch 003:    934 / 3715 loss=2.236, loss_v1=0, loss_v2=0, nll_loss=1.019, ntokens=1064.9, nsentences=120, sample_size=1064.9, sample_size_v1=0, sample_size_v2=0, ppl=2.03, wps=518.1, ups=0.49, wpb=1064.9, bsz=120, num_updates=8350, lr=2.74314e-05, gnorm=3.647, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=17226
2023-06-26 23:06:42 - progress_bar.py[line:272] - INFO: epoch 003:    944 / 3715 loss=2.225, loss_v1=0, loss_v2=0, nll_loss=1.007, ntokens=1083.7, nsentences=120, sample_size=1083.7, sample_size_v1=0, sample_size_v2=0, ppl=2.01, wps=527.2, ups=0.49, wpb=1083.7, bsz=120, num_updates=8360, lr=2.7426e-05, gnorm=3.581, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=17246
2023-06-26 23:07:03 - progress_bar.py[line:272] - INFO: epoch 003:    954 / 3715 loss=2.218, loss_v1=0, loss_v2=0, nll_loss=1, ntokens=1098.8, nsentences=120, sample_size=1098.8, sample_size_v1=0, sample_size_v2=0, ppl=2, wps=533.2, ups=0.49, wpb=1098.8, bsz=120, num_updates=8370, lr=2.74206e-05, gnorm=3.479, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=17267
2023-06-26 23:07:23 - progress_bar.py[line:272] - INFO: epoch 003:    964 / 3715 loss=2.233, loss_v1=0, loss_v2=0, nll_loss=1.017, ntokens=1086.8, nsentences=120, sample_size=1086.8, sample_size_v1=0, sample_size_v2=0, ppl=2.02, wps=528.3, ups=0.49, wpb=1086.8, bsz=120, num_updates=8380, lr=2.74153e-05, gnorm=3.878, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=17287
2023-06-26 23:07:44 - progress_bar.py[line:272] - INFO: epoch 003:    974 / 3715 loss=2.228, loss_v1=0, loss_v2=0, nll_loss=1.011, ntokens=1074.8, nsentences=120, sample_size=1074.8, sample_size_v1=0, sample_size_v2=0, ppl=2.02, wps=522.9, ups=0.49, wpb=1074.8, bsz=120, num_updates=8390, lr=2.74099e-05, gnorm=3.693, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=17308
2023-06-26 23:08:04 - progress_bar.py[line:272] - INFO: epoch 003:    984 / 3715 loss=2.227, loss_v1=0, loss_v2=0, nll_loss=1.01, ntokens=1088.1, nsentences=120, sample_size=1088.1, sample_size_v1=0, sample_size_v2=0, ppl=2.01, wps=529.4, ups=0.49, wpb=1088.1, bsz=120, num_updates=8400, lr=2.74045e-05, gnorm=3.398, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=17329
2023-06-26 23:08:25 - progress_bar.py[line:272] - INFO: epoch 003:    994 / 3715 loss=2.225, loss_v1=0, loss_v2=0, nll_loss=1.008, ntokens=1089.1, nsentences=120, sample_size=1089.1, sample_size_v1=0, sample_size_v2=0, ppl=2.01, wps=529.7, ups=0.49, wpb=1089.1, bsz=120, num_updates=8410, lr=2.73991e-05, gnorm=3.513, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=17349
2023-06-26 23:08:45 - progress_bar.py[line:272] - INFO: epoch 003:   1004 / 3715 loss=2.219, loss_v1=0, loss_v2=0, nll_loss=0.999, ntokens=1082, nsentences=120, sample_size=1082, sample_size_v1=0, sample_size_v2=0, ppl=2, wps=525.8, ups=0.49, wpb=1082, bsz=120, num_updates=8420, lr=2.73938e-05, gnorm=3.349, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=17370
2023-06-26 23:09:06 - progress_bar.py[line:272] - INFO: epoch 003:   1014 / 3715 loss=2.205, loss_v1=0, loss_v2=0, nll_loss=0.985, ntokens=1067.7, nsentences=120, sample_size=1067.7, sample_size_v1=0, sample_size_v2=0, ppl=1.98, wps=518.5, ups=0.49, wpb=1067.7, bsz=120, num_updates=8430, lr=2.73884e-05, gnorm=3.232, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=17390
2023-06-26 23:09:27 - progress_bar.py[line:272] - INFO: epoch 003:   1024 / 3715 loss=2.226, loss_v1=0, loss_v2=0, nll_loss=1.01, ntokens=1084.3, nsentences=120, sample_size=1084.3, sample_size_v1=0, sample_size_v2=0, ppl=2.01, wps=527.1, ups=0.49, wpb=1084.3, bsz=120, num_updates=8440, lr=2.7383e-05, gnorm=3.604, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=17411
2023-06-26 23:09:47 - progress_bar.py[line:272] - INFO: epoch 003:   1034 / 3715 loss=2.242, loss_v1=0, loss_v2=0, nll_loss=1.026, ntokens=1082.4, nsentences=120, sample_size=1082.4, sample_size_v1=0, sample_size_v2=0, ppl=2.04, wps=526.5, ups=0.49, wpb=1082.4, bsz=120, num_updates=8450, lr=2.73777e-05, gnorm=3.546, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=17431
2023-06-26 23:10:08 - progress_bar.py[line:272] - INFO: epoch 003:   1044 / 3715 loss=2.226, loss_v1=0, loss_v2=0, nll_loss=1.009, ntokens=1064.6, nsentences=120, sample_size=1064.6, sample_size_v1=0, sample_size_v2=0, ppl=2.01, wps=517.2, ups=0.49, wpb=1064.6, bsz=120, num_updates=8460, lr=2.73723e-05, gnorm=3.784, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=17452
2023-06-26 23:10:28 - progress_bar.py[line:272] - INFO: epoch 003:   1054 / 3715 loss=2.223, loss_v1=0, loss_v2=0, nll_loss=1.007, ntokens=1081.2, nsentences=120, sample_size=1081.2, sample_size_v1=0, sample_size_v2=0, ppl=2.01, wps=525.9, ups=0.49, wpb=1081.2, bsz=120, num_updates=8470, lr=2.73669e-05, gnorm=3.716, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=17473
2023-06-26 23:10:49 - progress_bar.py[line:272] - INFO: epoch 003:   1064 / 3715 loss=2.239, loss_v1=0, loss_v2=0, nll_loss=1.023, ntokens=1081.9, nsentences=120, sample_size=1081.9, sample_size_v1=0, sample_size_v2=0, ppl=2.03, wps=527, ups=0.49, wpb=1081.9, bsz=120, num_updates=8480, lr=2.73616e-05, gnorm=3.467, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=17493
2023-06-26 23:11:09 - progress_bar.py[line:272] - INFO: epoch 003:   1074 / 3715 loss=2.219, loss_v1=0, loss_v2=0, nll_loss=1, ntokens=1096.7, nsentences=120, sample_size=1096.7, sample_size_v1=0, sample_size_v2=0, ppl=2, wps=533.8, ups=0.49, wpb=1096.7, bsz=120, num_updates=8490, lr=2.73562e-05, gnorm=3.273, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=17514
2023-06-26 23:11:30 - progress_bar.py[line:272] - INFO: epoch 003:   1084 / 3715 loss=2.198, loss_v1=0, loss_v2=0, nll_loss=0.979, ntokens=1086, nsentences=120, sample_size=1086, sample_size_v1=0, sample_size_v2=0, ppl=1.97, wps=529.1, ups=0.49, wpb=1086, bsz=120, num_updates=8500, lr=2.73508e-05, gnorm=3.424, clip=100, loss_scale=256, train_wall=20, gb_free=8.9, wall=17534
2023-06-26 23:11:50 - progress_bar.py[line:272] - INFO: epoch 003:   1094 / 3715 loss=2.213, loss_v1=0, loss_v2=0, nll_loss=0.993, ntokens=1066.1, nsentences=120, sample_size=1066.1, sample_size_v1=0, sample_size_v2=0, ppl=1.99, wps=519.3, ups=0.49, wpb=1066.1, bsz=120, num_updates=8510, lr=2.73455e-05, gnorm=3.662, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=17555
2023-06-26 23:12:11 - progress_bar.py[line:272] - INFO: epoch 003:   1104 / 3715 loss=2.227, loss_v1=0, loss_v2=0, nll_loss=1.01, ntokens=1068.8, nsentences=120, sample_size=1068.8, sample_size_v1=0, sample_size_v2=0, ppl=2.01, wps=520.6, ups=0.49, wpb=1068.8, bsz=120, num_updates=8520, lr=2.73401e-05, gnorm=3.542, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=17575
2023-06-26 23:12:32 - progress_bar.py[line:272] - INFO: epoch 003:   1114 / 3715 loss=2.233, loss_v1=0, loss_v2=0, nll_loss=1.016, ntokens=1066.8, nsentences=120, sample_size=1066.8, sample_size_v1=0, sample_size_v2=0, ppl=2.02, wps=517.7, ups=0.49, wpb=1066.8, bsz=120, num_updates=8530, lr=2.73347e-05, gnorm=3.669, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=17596
2023-06-26 23:12:52 - progress_bar.py[line:272] - INFO: epoch 003:   1124 / 3715 loss=2.216, loss_v1=0, loss_v2=0, nll_loss=0.997, ntokens=1096.7, nsentences=120, sample_size=1096.7, sample_size_v1=0, sample_size_v2=0, ppl=2, wps=532.7, ups=0.49, wpb=1096.7, bsz=120, num_updates=8540, lr=2.73293e-05, gnorm=3.546, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=17616
2023-06-26 23:13:13 - progress_bar.py[line:272] - INFO: epoch 003:   1134 / 3715 loss=2.239, loss_v1=0, loss_v2=0, nll_loss=1.022, ntokens=1087.4, nsentences=120, sample_size=1087.4, sample_size_v1=0, sample_size_v2=0, ppl=2.03, wps=519.2, ups=0.48, wpb=1087.4, bsz=120, num_updates=8550, lr=2.7324e-05, gnorm=3.379, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=17637
2023-06-26 23:13:34 - progress_bar.py[line:272] - INFO: epoch 003:   1144 / 3715 loss=2.22, loss_v1=0, loss_v2=0, nll_loss=1.002, ntokens=1104.8, nsentences=120, sample_size=1104.8, sample_size_v1=0, sample_size_v2=0, ppl=2, wps=523.5, ups=0.47, wpb=1104.8, bsz=120, num_updates=8560, lr=2.73186e-05, gnorm=3.375, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=17659
2023-06-26 23:13:42 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 256.0
2023-06-26 23:13:57 - progress_bar.py[line:272] - INFO: epoch 003:   1155 / 3715 loss=2.22, loss_v1=0, loss_v2=0, nll_loss=1.002, ntokens=1057.8, nsentences=120, sample_size=1057.8, sample_size_v1=0, sample_size_v2=0, ppl=2, wps=467.6, ups=0.44, wpb=1057.8, bsz=120, num_updates=8570, lr=2.73132e-05, gnorm=3.729, clip=100, loss_scale=256, train_wall=23, gb_free=8.9, wall=17681
2023-06-26 23:14:17 - progress_bar.py[line:272] - INFO: epoch 003:   1165 / 3715 loss=2.203, loss_v1=0, loss_v2=0, nll_loss=0.983, ntokens=1100.6, nsentences=120, sample_size=1100.6, sample_size_v1=0, sample_size_v2=0, ppl=1.98, wps=534.7, ups=0.49, wpb=1100.6, bsz=120, num_updates=8580, lr=2.73079e-05, gnorm=3.423, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=17702
2023-06-26 23:14:38 - progress_bar.py[line:272] - INFO: epoch 003:   1175 / 3715 loss=2.236, loss_v1=0, loss_v2=0, nll_loss=1.019, ntokens=1091.7, nsentences=120, sample_size=1091.7, sample_size_v1=0, sample_size_v2=0, ppl=2.03, wps=530.8, ups=0.49, wpb=1091.7, bsz=120, num_updates=8590, lr=2.73025e-05, gnorm=3.528, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=17722
2023-06-26 23:14:59 - progress_bar.py[line:272] - INFO: epoch 003:   1185 / 3715 loss=2.232, loss_v1=0, loss_v2=0, nll_loss=1.016, ntokens=1084.9, nsentences=120, sample_size=1084.9, sample_size_v1=0, sample_size_v2=0, ppl=2.02, wps=527.9, ups=0.49, wpb=1084.9, bsz=120, num_updates=8600, lr=2.72971e-05, gnorm=3.495, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=17743
2023-06-26 23:15:19 - progress_bar.py[line:272] - INFO: epoch 003:   1195 / 3715 loss=2.227, loss_v1=0, loss_v2=0, nll_loss=1.012, ntokens=1088.4, nsentences=120, sample_size=1088.4, sample_size_v1=0, sample_size_v2=0, ppl=2.02, wps=529.5, ups=0.49, wpb=1088.4, bsz=120, num_updates=8610, lr=2.72918e-05, gnorm=3.75, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=17763
2023-06-26 23:15:40 - progress_bar.py[line:272] - INFO: epoch 003:   1205 / 3715 loss=2.215, loss_v1=0, loss_v2=0, nll_loss=0.996, ntokens=1077.2, nsentences=120, sample_size=1077.2, sample_size_v1=0, sample_size_v2=0, ppl=1.99, wps=523.9, ups=0.49, wpb=1077.2, bsz=120, num_updates=8620, lr=2.72864e-05, gnorm=3.558, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=17784
2023-06-26 23:16:00 - progress_bar.py[line:272] - INFO: epoch 003:   1215 / 3715 loss=2.215, loss_v1=0, loss_v2=0, nll_loss=0.995, ntokens=1070.6, nsentences=120, sample_size=1070.6, sample_size_v1=0, sample_size_v2=0, ppl=1.99, wps=520.2, ups=0.49, wpb=1070.6, bsz=120, num_updates=8630, lr=2.7281e-05, gnorm=3.568, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=17805
2023-06-26 23:16:21 - progress_bar.py[line:272] - INFO: epoch 003:   1225 / 3715 loss=2.237, loss_v1=0, loss_v2=0, nll_loss=1.022, ntokens=1096.1, nsentences=120, sample_size=1096.1, sample_size_v1=0, sample_size_v2=0, ppl=2.03, wps=532.7, ups=0.49, wpb=1096.1, bsz=120, num_updates=8640, lr=2.72757e-05, gnorm=3.54, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=17825
2023-06-26 23:16:41 - progress_bar.py[line:272] - INFO: epoch 003:   1235 / 3715 loss=2.203, loss_v1=0, loss_v2=0, nll_loss=0.982, ntokens=1073.7, nsentences=120, sample_size=1073.7, sample_size_v1=0, sample_size_v2=0, ppl=1.98, wps=522.5, ups=0.49, wpb=1073.7, bsz=120, num_updates=8650, lr=2.72703e-05, gnorm=3.416, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=17846
2023-06-26 23:17:02 - progress_bar.py[line:272] - INFO: epoch 003:   1245 / 3715 loss=2.216, loss_v1=0, loss_v2=0, nll_loss=0.998, ntokens=1085.7, nsentences=120, sample_size=1085.7, sample_size_v1=0, sample_size_v2=0, ppl=2, wps=527.7, ups=0.49, wpb=1085.7, bsz=120, num_updates=8660, lr=2.72649e-05, gnorm=3.546, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=17866
2023-06-26 23:17:23 - progress_bar.py[line:272] - INFO: epoch 003:   1255 / 3715 loss=2.209, loss_v1=0, loss_v2=0, nll_loss=0.99, ntokens=1075.2, nsentences=120, sample_size=1075.2, sample_size_v1=0, sample_size_v2=0, ppl=1.99, wps=522.8, ups=0.49, wpb=1075.2, bsz=120, num_updates=8670, lr=2.72595e-05, gnorm=3.66, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=17887
2023-06-26 23:17:43 - progress_bar.py[line:272] - INFO: epoch 003:   1265 / 3715 loss=2.202, loss_v1=0, loss_v2=0, nll_loss=0.982, ntokens=1071.8, nsentences=120, sample_size=1071.8, sample_size_v1=0, sample_size_v2=0, ppl=1.97, wps=521.6, ups=0.49, wpb=1071.8, bsz=120, num_updates=8680, lr=2.72542e-05, gnorm=3.391, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=17907
2023-06-26 23:18:04 - progress_bar.py[line:272] - INFO: epoch 003:   1275 / 3715 loss=2.214, loss_v1=0, loss_v2=0, nll_loss=0.996, ntokens=1079.4, nsentences=120, sample_size=1079.4, sample_size_v1=0, sample_size_v2=0, ppl=1.99, wps=525.3, ups=0.49, wpb=1079.4, bsz=120, num_updates=8690, lr=2.72488e-05, gnorm=3.771, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=17928
2023-06-26 23:18:24 - progress_bar.py[line:272] - INFO: epoch 003:   1285 / 3715 loss=2.224, loss_v1=0, loss_v2=0, nll_loss=1.007, ntokens=1077.9, nsentences=120, sample_size=1077.9, sample_size_v1=0, sample_size_v2=0, ppl=2.01, wps=523.9, ups=0.49, wpb=1077.9, bsz=120, num_updates=8700, lr=2.72434e-05, gnorm=3.614, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=17949
2023-06-26 23:18:45 - progress_bar.py[line:272] - INFO: epoch 003:   1295 / 3715 loss=2.201, loss_v1=0, loss_v2=0, nll_loss=0.98, ntokens=1103.1, nsentences=120, sample_size=1103.1, sample_size_v1=0, sample_size_v2=0, ppl=1.97, wps=536.3, ups=0.49, wpb=1103.1, bsz=120, num_updates=8710, lr=2.72381e-05, gnorm=3.416, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=17969
2023-06-26 23:19:05 - progress_bar.py[line:272] - INFO: epoch 003:   1305 / 3715 loss=2.217, loss_v1=0, loss_v2=0, nll_loss=0.998, ntokens=1066.5, nsentences=120, sample_size=1066.5, sample_size_v1=0, sample_size_v2=0, ppl=2, wps=518.2, ups=0.49, wpb=1066.5, bsz=120, num_updates=8720, lr=2.72327e-05, gnorm=3.748, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=17990
2023-06-26 23:19:26 - progress_bar.py[line:272] - INFO: epoch 003:   1315 / 3715 loss=2.216, loss_v1=0, loss_v2=0, nll_loss=0.997, ntokens=1082.8, nsentences=120, sample_size=1082.8, sample_size_v1=0, sample_size_v2=0, ppl=2, wps=526.1, ups=0.49, wpb=1082.8, bsz=120, num_updates=8730, lr=2.72273e-05, gnorm=3.339, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=18010
2023-06-26 23:19:47 - progress_bar.py[line:272] - INFO: epoch 003:   1325 / 3715 loss=2.207, loss_v1=0, loss_v2=0, nll_loss=0.988, ntokens=1084.1, nsentences=120, sample_size=1084.1, sample_size_v1=0, sample_size_v2=0, ppl=1.98, wps=527, ups=0.49, wpb=1084.1, bsz=120, num_updates=8740, lr=2.7222e-05, gnorm=3.657, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=18031
2023-06-26 23:20:07 - progress_bar.py[line:272] - INFO: epoch 003:   1335 / 3715 loss=2.21, loss_v1=0, loss_v2=0, nll_loss=0.993, ntokens=1083.9, nsentences=120, sample_size=1083.9, sample_size_v1=0, sample_size_v2=0, ppl=1.99, wps=526.4, ups=0.49, wpb=1083.9, bsz=120, num_updates=8750, lr=2.72166e-05, gnorm=3.654, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=18051
2023-06-26 23:20:28 - progress_bar.py[line:272] - INFO: epoch 003:   1345 / 3715 loss=2.222, loss_v1=0, loss_v2=0, nll_loss=1.004, ntokens=1066.4, nsentences=120, sample_size=1066.4, sample_size_v1=0, sample_size_v2=0, ppl=2.01, wps=519.1, ups=0.49, wpb=1066.4, bsz=120, num_updates=8760, lr=2.72112e-05, gnorm=3.54, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=18072
2023-06-26 23:20:48 - progress_bar.py[line:272] - INFO: epoch 003:   1355 / 3715 loss=2.2, loss_v1=0, loss_v2=0, nll_loss=0.98, ntokens=1118.7, nsentences=120, sample_size=1118.7, sample_size_v1=0, sample_size_v2=0, ppl=1.97, wps=543.7, ups=0.49, wpb=1118.7, bsz=120, num_updates=8770, lr=2.72059e-05, gnorm=3.403, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=18093
2023-06-26 23:21:09 - progress_bar.py[line:272] - INFO: epoch 003:   1365 / 3715 loss=2.212, loss_v1=0, loss_v2=0, nll_loss=0.992, ntokens=1064.7, nsentences=120, sample_size=1064.7, sample_size_v1=0, sample_size_v2=0, ppl=1.99, wps=516.4, ups=0.49, wpb=1064.7, bsz=120, num_updates=8780, lr=2.72005e-05, gnorm=3.78, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=18113
2023-06-26 23:21:29 - progress_bar.py[line:272] - INFO: epoch 003:   1375 / 3715 loss=2.211, loss_v1=0, loss_v2=0, nll_loss=0.993, ntokens=1071.7, nsentences=120, sample_size=1071.7, sample_size_v1=0, sample_size_v2=0, ppl=1.99, wps=520.8, ups=0.49, wpb=1071.7, bsz=120, num_updates=8790, lr=2.71951e-05, gnorm=3.755, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=18134
2023-06-26 23:21:50 - progress_bar.py[line:272] - INFO: epoch 003:   1385 / 3715 loss=2.216, loss_v1=0, loss_v2=0, nll_loss=0.998, ntokens=1080, nsentences=120, sample_size=1080, sample_size_v1=0, sample_size_v2=0, ppl=2, wps=524.7, ups=0.49, wpb=1080, bsz=120, num_updates=8800, lr=2.71897e-05, gnorm=3.587, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=18154
2023-06-26 23:22:11 - progress_bar.py[line:272] - INFO: epoch 003:   1395 / 3715 loss=2.21, loss_v1=0, loss_v2=0, nll_loss=0.993, ntokens=1085.1, nsentences=120, sample_size=1085.1, sample_size_v1=0, sample_size_v2=0, ppl=1.99, wps=526.8, ups=0.49, wpb=1085.1, bsz=120, num_updates=8810, lr=2.71844e-05, gnorm=3.438, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=18175
2023-06-26 23:22:31 - progress_bar.py[line:272] - INFO: epoch 003:   1405 / 3715 loss=2.201, loss_v1=0, loss_v2=0, nll_loss=0.98, ntokens=1068.5, nsentences=120, sample_size=1068.5, sample_size_v1=0, sample_size_v2=0, ppl=1.97, wps=518.7, ups=0.49, wpb=1068.5, bsz=120, num_updates=8820, lr=2.7179e-05, gnorm=3.588, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=18196
2023-06-26 23:22:52 - progress_bar.py[line:272] - INFO: epoch 003:   1415 / 3715 loss=2.195, loss_v1=0, loss_v2=0, nll_loss=0.974, ntokens=1098.3, nsentences=120, sample_size=1098.3, sample_size_v1=0, sample_size_v2=0, ppl=1.96, wps=533.5, ups=0.49, wpb=1098.3, bsz=120, num_updates=8830, lr=2.71736e-05, gnorm=3.648, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=18216
2023-06-26 23:23:12 - progress_bar.py[line:272] - INFO: epoch 003:   1425 / 3715 loss=2.218, loss_v1=0, loss_v2=0, nll_loss=0.999, ntokens=1095.4, nsentences=120, sample_size=1095.4, sample_size_v1=0, sample_size_v2=0, ppl=2, wps=531.9, ups=0.49, wpb=1095.4, bsz=120, num_updates=8840, lr=2.71683e-05, gnorm=3.633, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=18237
2023-06-26 23:23:33 - progress_bar.py[line:272] - INFO: epoch 003:   1435 / 3715 loss=2.198, loss_v1=0, loss_v2=0, nll_loss=0.976, ntokens=1078.5, nsentences=120, sample_size=1078.5, sample_size_v1=0, sample_size_v2=0, ppl=1.97, wps=523.6, ups=0.49, wpb=1078.5, bsz=120, num_updates=8850, lr=2.71629e-05, gnorm=3.83, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=18257
2023-06-26 23:23:54 - progress_bar.py[line:272] - INFO: epoch 003:   1445 / 3715 loss=2.18, loss_v1=0, loss_v2=0, nll_loss=0.959, ntokens=1073.4, nsentences=120, sample_size=1073.4, sample_size_v1=0, sample_size_v2=0, ppl=1.94, wps=521.4, ups=0.49, wpb=1073.4, bsz=120, num_updates=8860, lr=2.71575e-05, gnorm=3.581, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=18278
2023-06-26 23:24:14 - progress_bar.py[line:272] - INFO: epoch 003:   1455 / 3715 loss=2.203, loss_v1=0, loss_v2=0, nll_loss=0.981, ntokens=1094.6, nsentences=120, sample_size=1094.6, sample_size_v1=0, sample_size_v2=0, ppl=1.97, wps=532.4, ups=0.49, wpb=1094.6, bsz=120, num_updates=8870, lr=2.71522e-05, gnorm=3.652, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=18299
2023-06-26 23:24:35 - progress_bar.py[line:272] - INFO: epoch 003:   1465 / 3715 loss=2.207, loss_v1=0, loss_v2=0, nll_loss=0.989, ntokens=1088.9, nsentences=120, sample_size=1088.9, sample_size_v1=0, sample_size_v2=0, ppl=1.99, wps=530.1, ups=0.49, wpb=1088.9, bsz=120, num_updates=8880, lr=2.71468e-05, gnorm=3.469, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=18319
2023-06-26 23:24:55 - progress_bar.py[line:272] - INFO: epoch 003:   1475 / 3715 loss=2.208, loss_v1=0, loss_v2=0, nll_loss=0.988, ntokens=1061.2, nsentences=120, sample_size=1061.2, sample_size_v1=0, sample_size_v2=0, ppl=1.98, wps=516.2, ups=0.49, wpb=1061.2, bsz=120, num_updates=8890, lr=2.71414e-05, gnorm=3.751, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=18340
2023-06-26 23:25:16 - progress_bar.py[line:272] - INFO: epoch 003:   1485 / 3715 loss=2.201, loss_v1=0, loss_v2=0, nll_loss=0.982, ntokens=1084.2, nsentences=120, sample_size=1084.2, sample_size_v1=0, sample_size_v2=0, ppl=1.98, wps=527.3, ups=0.49, wpb=1084.2, bsz=120, num_updates=8900, lr=2.71361e-05, gnorm=3.754, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=18360
2023-06-26 23:25:36 - progress_bar.py[line:272] - INFO: epoch 003:   1495 / 3715 loss=2.198, loss_v1=0, loss_v2=0, nll_loss=0.976, ntokens=1084, nsentences=120, sample_size=1084, sample_size_v1=0, sample_size_v2=0, ppl=1.97, wps=527.2, ups=0.49, wpb=1084, bsz=120, num_updates=8910, lr=2.71307e-05, gnorm=3.682, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=18381
2023-06-26 23:25:57 - progress_bar.py[line:272] - INFO: epoch 003:   1505 / 3715 loss=2.186, loss_v1=0, loss_v2=0, nll_loss=0.966, ntokens=1096.6, nsentences=120, sample_size=1096.6, sample_size_v1=0, sample_size_v2=0, ppl=1.95, wps=532.5, ups=0.49, wpb=1096.6, bsz=120, num_updates=8920, lr=2.71253e-05, gnorm=3.613, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=18401
2023-06-26 23:26:18 - progress_bar.py[line:272] - INFO: epoch 003:   1515 / 3715 loss=2.208, loss_v1=0, loss_v2=0, nll_loss=0.987, ntokens=1092.4, nsentences=120, sample_size=1092.4, sample_size_v1=0, sample_size_v2=0, ppl=1.98, wps=531.3, ups=0.49, wpb=1092.4, bsz=120, num_updates=8930, lr=2.71199e-05, gnorm=3.413, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=18422
2023-06-26 23:26:38 - progress_bar.py[line:272] - INFO: epoch 003:   1525 / 3715 loss=2.208, loss_v1=0, loss_v2=0, nll_loss=0.988, ntokens=1096.3, nsentences=120, sample_size=1096.3, sample_size_v1=0, sample_size_v2=0, ppl=1.98, wps=532.7, ups=0.49, wpb=1096.3, bsz=120, num_updates=8940, lr=2.71146e-05, gnorm=3.788, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=18443
2023-06-26 23:26:59 - progress_bar.py[line:272] - INFO: epoch 003:   1535 / 3715 loss=2.207, loss_v1=0, loss_v2=0, nll_loss=0.988, ntokens=1075.2, nsentences=120, sample_size=1075.2, sample_size_v1=0, sample_size_v2=0, ppl=1.98, wps=522.9, ups=0.49, wpb=1075.2, bsz=120, num_updates=8950, lr=2.71092e-05, gnorm=3.475, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=18463
2023-06-26 23:27:19 - progress_bar.py[line:272] - INFO: epoch 003:   1545 / 3715 loss=2.191, loss_v1=0, loss_v2=0, nll_loss=0.97, ntokens=1084.5, nsentences=120, sample_size=1084.5, sample_size_v1=0, sample_size_v2=0, ppl=1.96, wps=526.7, ups=0.49, wpb=1084.5, bsz=120, num_updates=8960, lr=2.71038e-05, gnorm=3.489, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=18484
2023-06-26 23:27:40 - progress_bar.py[line:272] - INFO: epoch 003:   1555 / 3715 loss=2.197, loss_v1=0, loss_v2=0, nll_loss=0.976, ntokens=1086.6, nsentences=120, sample_size=1086.6, sample_size_v1=0, sample_size_v2=0, ppl=1.97, wps=528.3, ups=0.49, wpb=1086.6, bsz=120, num_updates=8970, lr=2.70985e-05, gnorm=3.628, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=18504
2023-06-26 23:28:00 - progress_bar.py[line:272] - INFO: epoch 003:   1565 / 3715 loss=2.191, loss_v1=0, loss_v2=0, nll_loss=0.97, ntokens=1068.1, nsentences=120, sample_size=1068.1, sample_size_v1=0, sample_size_v2=0, ppl=1.96, wps=518.8, ups=0.49, wpb=1068.1, bsz=120, num_updates=8980, lr=2.70931e-05, gnorm=3.658, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=18525
2023-06-26 23:28:21 - progress_bar.py[line:272] - INFO: epoch 003:   1575 / 3715 loss=2.203, loss_v1=0, loss_v2=0, nll_loss=0.983, ntokens=1099.5, nsentences=120, sample_size=1099.5, sample_size_v1=0, sample_size_v2=0, ppl=1.98, wps=533.8, ups=0.49, wpb=1099.5, bsz=120, num_updates=8990, lr=2.70877e-05, gnorm=3.748, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=18545
2023-06-26 23:28:42 - progress_bar.py[line:272] - INFO: epoch 003:   1585 / 3715 loss=2.22, loss_v1=0, loss_v2=0, nll_loss=1.001, ntokens=1078.1, nsentences=120, sample_size=1078.1, sample_size_v1=0, sample_size_v2=0, ppl=2, wps=523.5, ups=0.49, wpb=1078.1, bsz=120, num_updates=9000, lr=2.70824e-05, gnorm=3.498, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=18566
2023-06-26 23:29:02 - progress_bar.py[line:272] - INFO: epoch 003:   1595 / 3715 loss=2.198, loss_v1=0, loss_v2=0, nll_loss=0.979, ntokens=1072.8, nsentences=120, sample_size=1072.8, sample_size_v1=0, sample_size_v2=0, ppl=1.97, wps=520.4, ups=0.49, wpb=1072.8, bsz=120, num_updates=9010, lr=2.7077e-05, gnorm=3.493, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=18587
2023-06-26 23:29:23 - progress_bar.py[line:272] - INFO: epoch 003:   1605 / 3715 loss=2.209, loss_v1=0, loss_v2=0, nll_loss=0.988, ntokens=1071.4, nsentences=120, sample_size=1071.4, sample_size_v1=0, sample_size_v2=0, ppl=1.98, wps=520.2, ups=0.49, wpb=1071.4, bsz=120, num_updates=9020, lr=2.70716e-05, gnorm=3.579, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=18607
2023-06-26 23:29:43 - progress_bar.py[line:272] - INFO: epoch 003:   1615 / 3715 loss=2.197, loss_v1=0, loss_v2=0, nll_loss=0.976, ntokens=1074.8, nsentences=120, sample_size=1074.8, sample_size_v1=0, sample_size_v2=0, ppl=1.97, wps=522, ups=0.49, wpb=1074.8, bsz=120, num_updates=9030, lr=2.70663e-05, gnorm=3.444, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=18628
2023-06-26 23:30:04 - progress_bar.py[line:272] - INFO: epoch 003:   1625 / 3715 loss=2.201, loss_v1=0, loss_v2=0, nll_loss=0.982, ntokens=1106.1, nsentences=120, sample_size=1106.1, sample_size_v1=0, sample_size_v2=0, ppl=1.97, wps=537.1, ups=0.49, wpb=1106.1, bsz=120, num_updates=9040, lr=2.70609e-05, gnorm=3.682, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=18648
2023-06-26 23:30:25 - progress_bar.py[line:272] - INFO: epoch 003:   1635 / 3715 loss=2.194, loss_v1=0, loss_v2=0, nll_loss=0.971, ntokens=1081.7, nsentences=120, sample_size=1081.7, sample_size_v1=0, sample_size_v2=0, ppl=1.96, wps=526.1, ups=0.49, wpb=1081.7, bsz=120, num_updates=9050, lr=2.70555e-05, gnorm=3.796, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=18669
2023-06-26 23:30:45 - progress_bar.py[line:272] - INFO: epoch 003:   1645 / 3715 loss=2.197, loss_v1=0, loss_v2=0, nll_loss=0.977, ntokens=1070.4, nsentences=120, sample_size=1070.4, sample_size_v1=0, sample_size_v2=0, ppl=1.97, wps=520.3, ups=0.49, wpb=1070.4, bsz=120, num_updates=9060, lr=2.70501e-05, gnorm=3.407, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=18690
2023-06-26 23:31:06 - progress_bar.py[line:272] - INFO: epoch 003:   1655 / 3715 loss=2.21, loss_v1=0, loss_v2=0, nll_loss=0.99, ntokens=1090.1, nsentences=120, sample_size=1090.1, sample_size_v1=0, sample_size_v2=0, ppl=1.99, wps=529.9, ups=0.49, wpb=1090.1, bsz=120, num_updates=9070, lr=2.70448e-05, gnorm=3.735, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=18710
2023-06-26 23:31:18 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 256.0
2023-06-26 23:31:28 - progress_bar.py[line:272] - INFO: epoch 003:   1666 / 3715 loss=2.205, loss_v1=0, loss_v2=0, nll_loss=0.984, ntokens=1059, nsentences=120, sample_size=1059, sample_size_v1=0, sample_size_v2=0, ppl=1.98, wps=467.9, ups=0.44, wpb=1059, bsz=120, num_updates=9080, lr=2.70394e-05, gnorm=3.845, clip=100, loss_scale=256, train_wall=23, gb_free=8.9, wall=18733
2023-06-26 23:31:49 - progress_bar.py[line:272] - INFO: epoch 003:   1676 / 3715 loss=2.202, loss_v1=0, loss_v2=0, nll_loss=0.983, ntokens=1076.9, nsentences=120, sample_size=1076.9, sample_size_v1=0, sample_size_v2=0, ppl=1.98, wps=522.1, ups=0.48, wpb=1076.9, bsz=120, num_updates=9090, lr=2.7034e-05, gnorm=3.587, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=18753
2023-06-26 23:32:10 - progress_bar.py[line:272] - INFO: epoch 003:   1686 / 3715 loss=2.202, loss_v1=0, loss_v2=0, nll_loss=0.98, ntokens=1069.9, nsentences=120, sample_size=1069.9, sample_size_v1=0, sample_size_v2=0, ppl=1.97, wps=518.8, ups=0.48, wpb=1069.9, bsz=120, num_updates=9100, lr=2.70287e-05, gnorm=3.739, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=18774
2023-06-26 23:32:30 - progress_bar.py[line:272] - INFO: epoch 003:   1696 / 3715 loss=2.195, loss_v1=0, loss_v2=0, nll_loss=0.975, ntokens=1083.6, nsentences=120, sample_size=1083.6, sample_size_v1=0, sample_size_v2=0, ppl=1.97, wps=525.9, ups=0.49, wpb=1083.6, bsz=120, num_updates=9110, lr=2.70233e-05, gnorm=3.729, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=18795
2023-06-26 23:32:51 - progress_bar.py[line:272] - INFO: epoch 003:   1706 / 3715 loss=2.211, loss_v1=0, loss_v2=0, nll_loss=0.99, ntokens=1072.3, nsentences=120, sample_size=1072.3, sample_size_v1=0, sample_size_v2=0, ppl=1.99, wps=520.7, ups=0.49, wpb=1072.3, bsz=120, num_updates=9120, lr=2.70179e-05, gnorm=3.727, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=18815
2023-06-26 23:33:12 - progress_bar.py[line:272] - INFO: epoch 003:   1716 / 3715 loss=2.195, loss_v1=0, loss_v2=0, nll_loss=0.975, ntokens=1094.2, nsentences=120, sample_size=1094.2, sample_size_v1=0, sample_size_v2=0, ppl=1.97, wps=530.7, ups=0.49, wpb=1094.2, bsz=120, num_updates=9130, lr=2.70126e-05, gnorm=3.494, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=18836
2023-06-26 23:33:32 - progress_bar.py[line:272] - INFO: epoch 003:   1726 / 3715 loss=2.195, loss_v1=0, loss_v2=0, nll_loss=0.974, ntokens=1096.3, nsentences=120, sample_size=1096.3, sample_size_v1=0, sample_size_v2=0, ppl=1.96, wps=532.7, ups=0.49, wpb=1096.3, bsz=120, num_updates=9140, lr=2.70072e-05, gnorm=3.457, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=18856
2023-06-26 23:33:53 - progress_bar.py[line:272] - INFO: epoch 003:   1736 / 3715 loss=2.175, loss_v1=0, loss_v2=0, nll_loss=0.951, ntokens=1087.2, nsentences=120, sample_size=1087.2, sample_size_v1=0, sample_size_v2=0, ppl=1.93, wps=527.8, ups=0.49, wpb=1087.2, bsz=120, num_updates=9150, lr=2.70018e-05, gnorm=3.412, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=18877
2023-06-26 23:34:13 - progress_bar.py[line:272] - INFO: epoch 003:   1746 / 3715 loss=2.206, loss_v1=0, loss_v2=0, nll_loss=0.985, ntokens=1066.7, nsentences=120, sample_size=1066.7, sample_size_v1=0, sample_size_v2=0, ppl=1.98, wps=518.1, ups=0.49, wpb=1066.7, bsz=120, num_updates=9160, lr=2.69965e-05, gnorm=3.543, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=18898
2023-06-26 23:34:34 - progress_bar.py[line:272] - INFO: epoch 003:   1756 / 3715 loss=2.192, loss_v1=0, loss_v2=0, nll_loss=0.972, ntokens=1086.5, nsentences=120, sample_size=1086.5, sample_size_v1=0, sample_size_v2=0, ppl=1.96, wps=528, ups=0.49, wpb=1086.5, bsz=120, num_updates=9170, lr=2.69911e-05, gnorm=3.733, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=18918
2023-06-26 23:34:54 - progress_bar.py[line:272] - INFO: epoch 003:   1766 / 3715 loss=2.177, loss_v1=0, loss_v2=0, nll_loss=0.955, ntokens=1084.8, nsentences=120, sample_size=1084.8, sample_size_v1=0, sample_size_v2=0, ppl=1.94, wps=526.8, ups=0.49, wpb=1084.8, bsz=120, num_updates=9180, lr=2.69857e-05, gnorm=3.871, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=18939
2023-06-26 23:35:15 - progress_bar.py[line:272] - INFO: epoch 003:   1776 / 3715 loss=2.18, loss_v1=0, loss_v2=0, nll_loss=0.957, ntokens=1079.2, nsentences=120, sample_size=1079.2, sample_size_v1=0, sample_size_v2=0, ppl=1.94, wps=524.3, ups=0.49, wpb=1079.2, bsz=120, num_updates=9190, lr=2.69803e-05, gnorm=3.844, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=18959
2023-06-26 23:35:36 - progress_bar.py[line:272] - INFO: epoch 003:   1786 / 3715 loss=2.216, loss_v1=0, loss_v2=0, nll_loss=0.998, ntokens=1065, nsentences=120, sample_size=1065, sample_size_v1=0, sample_size_v2=0, ppl=2, wps=517, ups=0.49, wpb=1065, bsz=120, num_updates=9200, lr=2.6975e-05, gnorm=3.746, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=18980
2023-06-26 23:35:56 - progress_bar.py[line:272] - INFO: epoch 003:   1796 / 3715 loss=2.187, loss_v1=0, loss_v2=0, nll_loss=0.964, ntokens=1092.8, nsentences=120, sample_size=1092.8, sample_size_v1=0, sample_size_v2=0, ppl=1.95, wps=531.2, ups=0.49, wpb=1092.8, bsz=120, num_updates=9210, lr=2.69696e-05, gnorm=3.666, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=19001
2023-06-26 23:36:17 - progress_bar.py[line:272] - INFO: epoch 003:   1806 / 3715 loss=2.2, loss_v1=0, loss_v2=0, nll_loss=0.981, ntokens=1086.1, nsentences=120, sample_size=1086.1, sample_size_v1=0, sample_size_v2=0, ppl=1.97, wps=527.9, ups=0.49, wpb=1086.1, bsz=120, num_updates=9220, lr=2.69642e-05, gnorm=3.596, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=19021
2023-06-26 23:36:37 - progress_bar.py[line:272] - INFO: epoch 003:   1816 / 3715 loss=2.195, loss_v1=0, loss_v2=0, nll_loss=0.974, ntokens=1068.9, nsentences=120, sample_size=1068.9, sample_size_v1=0, sample_size_v2=0, ppl=1.96, wps=519.3, ups=0.49, wpb=1068.9, bsz=120, num_updates=9230, lr=2.69589e-05, gnorm=3.639, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=19042
2023-06-26 23:36:58 - progress_bar.py[line:272] - INFO: epoch 003:   1826 / 3715 loss=2.202, loss_v1=0, loss_v2=0, nll_loss=0.981, ntokens=1101.4, nsentences=120, sample_size=1101.4, sample_size_v1=0, sample_size_v2=0, ppl=1.97, wps=533.3, ups=0.48, wpb=1101.4, bsz=120, num_updates=9240, lr=2.69535e-05, gnorm=3.527, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=19062
2023-06-26 23:37:19 - progress_bar.py[line:272] - INFO: epoch 003:   1836 / 3715 loss=2.179, loss_v1=0, loss_v2=0, nll_loss=0.959, ntokens=1076.5, nsentences=120, sample_size=1076.5, sample_size_v1=0, sample_size_v2=0, ppl=1.94, wps=522.5, ups=0.49, wpb=1076.5, bsz=120, num_updates=9250, lr=2.69481e-05, gnorm=3.687, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=19083
2023-06-26 23:37:39 - progress_bar.py[line:272] - INFO: epoch 003:   1846 / 3715 loss=2.183, loss_v1=0, loss_v2=0, nll_loss=0.958, ntokens=1088.5, nsentences=120, sample_size=1088.5, sample_size_v1=0, sample_size_v2=0, ppl=1.94, wps=529.6, ups=0.49, wpb=1088.5, bsz=120, num_updates=9260, lr=2.69428e-05, gnorm=3.558, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=19104
2023-06-26 23:38:00 - progress_bar.py[line:272] - INFO: epoch 003:   1856 / 3715 loss=2.204, loss_v1=0, loss_v2=0, nll_loss=0.983, ntokens=1090.6, nsentences=120, sample_size=1090.6, sample_size_v1=0, sample_size_v2=0, ppl=1.98, wps=530.8, ups=0.49, wpb=1090.6, bsz=120, num_updates=9270, lr=2.69374e-05, gnorm=3.791, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=19124
2023-06-26 23:38:20 - progress_bar.py[line:272] - INFO: epoch 003:   1866 / 3715 loss=2.199, loss_v1=0, loss_v2=0, nll_loss=0.978, ntokens=1077.3, nsentences=120, sample_size=1077.3, sample_size_v1=0, sample_size_v2=0, ppl=1.97, wps=524, ups=0.49, wpb=1077.3, bsz=120, num_updates=9280, lr=2.6932e-05, gnorm=3.859, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=19145
2023-06-26 23:38:41 - progress_bar.py[line:272] - INFO: epoch 003:   1876 / 3715 loss=2.206, loss_v1=0, loss_v2=0, nll_loss=0.986, ntokens=1068.4, nsentences=120, sample_size=1068.4, sample_size_v1=0, sample_size_v2=0, ppl=1.98, wps=519.5, ups=0.49, wpb=1068.4, bsz=120, num_updates=9290, lr=2.69267e-05, gnorm=3.777, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=19165
2023-06-26 23:39:01 - progress_bar.py[line:272] - INFO: epoch 003:   1886 / 3715 loss=2.197, loss_v1=0, loss_v2=0, nll_loss=0.976, ntokens=1089, nsentences=120, sample_size=1089, sample_size_v1=0, sample_size_v2=0, ppl=1.97, wps=529.4, ups=0.49, wpb=1089, bsz=120, num_updates=9300, lr=2.69213e-05, gnorm=3.655, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=19186
2023-06-26 23:39:22 - progress_bar.py[line:272] - INFO: epoch 003:   1896 / 3715 loss=2.201, loss_v1=0, loss_v2=0, nll_loss=0.98, ntokens=1082.6, nsentences=120, sample_size=1082.6, sample_size_v1=0, sample_size_v2=0, ppl=1.97, wps=525.4, ups=0.49, wpb=1082.6, bsz=120, num_updates=9310, lr=2.69159e-05, gnorm=3.557, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=19206
2023-06-26 23:39:43 - progress_bar.py[line:272] - INFO: epoch 003:   1906 / 3715 loss=2.186, loss_v1=0, loss_v2=0, nll_loss=0.964, ntokens=1089, nsentences=120, sample_size=1089, sample_size_v1=0, sample_size_v2=0, ppl=1.95, wps=528.9, ups=0.49, wpb=1089, bsz=120, num_updates=9320, lr=2.69105e-05, gnorm=3.385, clip=100, loss_scale=256, train_wall=21, gb_free=8.7, wall=19227
2023-06-26 23:40:03 - progress_bar.py[line:272] - INFO: epoch 003:   1916 / 3715 loss=2.177, loss_v1=0, loss_v2=0, nll_loss=0.955, ntokens=1070.7, nsentences=120, sample_size=1070.7, sample_size_v1=0, sample_size_v2=0, ppl=1.94, wps=520.7, ups=0.49, wpb=1070.7, bsz=120, num_updates=9330, lr=2.69052e-05, gnorm=3.639, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=19248
2023-06-26 23:40:24 - progress_bar.py[line:272] - INFO: epoch 003:   1926 / 3715 loss=2.197, loss_v1=0, loss_v2=0, nll_loss=0.976, ntokens=1072.6, nsentences=120, sample_size=1072.6, sample_size_v1=0, sample_size_v2=0, ppl=1.97, wps=521.4, ups=0.49, wpb=1072.6, bsz=120, num_updates=9340, lr=2.68998e-05, gnorm=3.524, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=19268
2023-06-26 23:40:44 - progress_bar.py[line:272] - INFO: epoch 003:   1936 / 3715 loss=2.211, loss_v1=0, loss_v2=0, nll_loss=0.995, ntokens=1080.1, nsentences=120, sample_size=1080.1, sample_size_v1=0, sample_size_v2=0, ppl=1.99, wps=525.4, ups=0.49, wpb=1080.1, bsz=120, num_updates=9350, lr=2.68944e-05, gnorm=3.656, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=19289
2023-06-26 23:41:05 - progress_bar.py[line:272] - INFO: epoch 003:   1946 / 3715 loss=2.202, loss_v1=0, loss_v2=0, nll_loss=0.979, ntokens=1073.2, nsentences=120, sample_size=1073.2, sample_size_v1=0, sample_size_v2=0, ppl=1.97, wps=521.2, ups=0.49, wpb=1073.2, bsz=120, num_updates=9360, lr=2.68891e-05, gnorm=3.583, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=19309
2023-06-26 23:41:26 - progress_bar.py[line:272] - INFO: epoch 003:   1956 / 3715 loss=2.193, loss_v1=0, loss_v2=0, nll_loss=0.974, ntokens=1088.2, nsentences=120, sample_size=1088.2, sample_size_v1=0, sample_size_v2=0, ppl=1.96, wps=528.3, ups=0.49, wpb=1088.2, bsz=120, num_updates=9370, lr=2.68837e-05, gnorm=3.536, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=19330
2023-06-26 23:41:46 - progress_bar.py[line:272] - INFO: epoch 003:   1966 / 3715 loss=2.205, loss_v1=0, loss_v2=0, nll_loss=0.983, ntokens=1083.4, nsentences=120, sample_size=1083.4, sample_size_v1=0, sample_size_v2=0, ppl=1.98, wps=525.9, ups=0.49, wpb=1083.4, bsz=120, num_updates=9380, lr=2.68783e-05, gnorm=3.735, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=19351
2023-06-26 23:42:07 - progress_bar.py[line:272] - INFO: epoch 003:   1976 / 3715 loss=2.197, loss_v1=0, loss_v2=0, nll_loss=0.977, ntokens=1073.4, nsentences=120, sample_size=1073.4, sample_size_v1=0, sample_size_v2=0, ppl=1.97, wps=521, ups=0.49, wpb=1073.4, bsz=120, num_updates=9390, lr=2.6873e-05, gnorm=3.709, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=19371
2023-06-26 23:42:27 - progress_bar.py[line:272] - INFO: epoch 003:   1986 / 3715 loss=2.213, loss_v1=0, loss_v2=0, nll_loss=0.994, ntokens=1081.9, nsentences=120, sample_size=1081.9, sample_size_v1=0, sample_size_v2=0, ppl=1.99, wps=524.9, ups=0.49, wpb=1081.9, bsz=120, num_updates=9400, lr=2.68676e-05, gnorm=3.956, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=19392
2023-06-26 23:42:48 - progress_bar.py[line:272] - INFO: epoch 003:   1996 / 3715 loss=2.188, loss_v1=0, loss_v2=0, nll_loss=0.965, ntokens=1088.6, nsentences=120, sample_size=1088.6, sample_size_v1=0, sample_size_v2=0, ppl=1.95, wps=529.4, ups=0.49, wpb=1088.6, bsz=120, num_updates=9410, lr=2.68622e-05, gnorm=3.851, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=19412
2023-06-26 23:43:09 - progress_bar.py[line:272] - INFO: epoch 003:   2006 / 3715 loss=2.185, loss_v1=0, loss_v2=0, nll_loss=0.963, ntokens=1083.1, nsentences=120, sample_size=1083.1, sample_size_v1=0, sample_size_v2=0, ppl=1.95, wps=525.8, ups=0.49, wpb=1083.1, bsz=120, num_updates=9420, lr=2.68569e-05, gnorm=3.47, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=19433
2023-06-26 23:43:29 - progress_bar.py[line:272] - INFO: epoch 003:   2016 / 3715 loss=2.175, loss_v1=0, loss_v2=0, nll_loss=0.952, ntokens=1099.4, nsentences=120, sample_size=1099.4, sample_size_v1=0, sample_size_v2=0, ppl=1.93, wps=533.4, ups=0.49, wpb=1099.4, bsz=120, num_updates=9430, lr=2.68515e-05, gnorm=3.358, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=19454
2023-06-26 23:43:50 - progress_bar.py[line:272] - INFO: epoch 003:   2026 / 3715 loss=2.189, loss_v1=0, loss_v2=0, nll_loss=0.969, ntokens=1070.9, nsentences=120, sample_size=1070.9, sample_size_v1=0, sample_size_v2=0, ppl=1.96, wps=519.6, ups=0.49, wpb=1070.9, bsz=120, num_updates=9440, lr=2.68461e-05, gnorm=3.428, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=19474
2023-06-26 23:44:10 - progress_bar.py[line:272] - INFO: epoch 003:   2036 / 3715 loss=2.21, loss_v1=0, loss_v2=0, nll_loss=0.99, ntokens=1097.9, nsentences=120, sample_size=1097.9, sample_size_v1=0, sample_size_v2=0, ppl=1.99, wps=533, ups=0.49, wpb=1097.9, bsz=120, num_updates=9450, lr=2.68407e-05, gnorm=3.65, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=19495
2023-06-26 23:44:31 - progress_bar.py[line:272] - INFO: epoch 003:   2046 / 3715 loss=2.193, loss_v1=0, loss_v2=0, nll_loss=0.973, ntokens=1098.5, nsentences=120, sample_size=1098.5, sample_size_v1=0, sample_size_v2=0, ppl=1.96, wps=533.2, ups=0.49, wpb=1098.5, bsz=120, num_updates=9460, lr=2.68354e-05, gnorm=3.611, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=19515
2023-06-26 23:44:52 - progress_bar.py[line:272] - INFO: epoch 003:   2056 / 3715 loss=2.195, loss_v1=0, loss_v2=0, nll_loss=0.973, ntokens=1102.7, nsentences=120, sample_size=1102.7, sample_size_v1=0, sample_size_v2=0, ppl=1.96, wps=535.4, ups=0.49, wpb=1102.7, bsz=120, num_updates=9470, lr=2.683e-05, gnorm=3.421, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=19536
2023-06-26 23:45:12 - progress_bar.py[line:272] - INFO: epoch 003:   2066 / 3715 loss=2.196, loss_v1=0, loss_v2=0, nll_loss=0.977, ntokens=1095.2, nsentences=120, sample_size=1095.2, sample_size_v1=0, sample_size_v2=0, ppl=1.97, wps=531.5, ups=0.49, wpb=1095.2, bsz=120, num_updates=9480, lr=2.68246e-05, gnorm=3.364, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=19557
2023-06-26 23:45:33 - progress_bar.py[line:272] - INFO: epoch 003:   2076 / 3715 loss=2.195, loss_v1=0, loss_v2=0, nll_loss=0.974, ntokens=1088.9, nsentences=120, sample_size=1088.9, sample_size_v1=0, sample_size_v2=0, ppl=1.96, wps=528.5, ups=0.49, wpb=1088.9, bsz=120, num_updates=9490, lr=2.68193e-05, gnorm=3.68, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=19577
2023-06-26 23:45:53 - progress_bar.py[line:272] - INFO: epoch 003:   2086 / 3715 loss=2.195, loss_v1=0, loss_v2=0, nll_loss=0.971, ntokens=1077.3, nsentences=120, sample_size=1077.3, sample_size_v1=0, sample_size_v2=0, ppl=1.96, wps=522.7, ups=0.49, wpb=1077.3, bsz=120, num_updates=9500, lr=2.68139e-05, gnorm=3.779, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=19598
2023-06-26 23:46:14 - progress_bar.py[line:272] - INFO: epoch 003:   2096 / 3715 loss=2.184, loss_v1=0, loss_v2=0, nll_loss=0.964, ntokens=1092.7, nsentences=120, sample_size=1092.7, sample_size_v1=0, sample_size_v2=0, ppl=1.95, wps=529.4, ups=0.48, wpb=1092.7, bsz=120, num_updates=9510, lr=2.68085e-05, gnorm=3.66, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=19618
2023-06-26 23:46:35 - progress_bar.py[line:272] - INFO: epoch 003:   2106 / 3715 loss=2.19, loss_v1=0, loss_v2=0, nll_loss=0.967, ntokens=1068.5, nsentences=120, sample_size=1068.5, sample_size_v1=0, sample_size_v2=0, ppl=1.95, wps=518, ups=0.48, wpb=1068.5, bsz=120, num_updates=9520, lr=2.68032e-05, gnorm=3.643, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=19639
2023-06-26 23:46:55 - progress_bar.py[line:272] - INFO: epoch 003:   2116 / 3715 loss=2.199, loss_v1=0, loss_v2=0, nll_loss=0.979, ntokens=1083.5, nsentences=120, sample_size=1083.5, sample_size_v1=0, sample_size_v2=0, ppl=1.97, wps=526.1, ups=0.49, wpb=1083.5, bsz=120, num_updates=9530, lr=2.67978e-05, gnorm=3.742, clip=100, loss_scale=256, train_wall=21, gb_free=8.8, wall=19660
2023-06-26 23:47:16 - progress_bar.py[line:272] - INFO: epoch 003:   2126 / 3715 loss=2.183, loss_v1=0, loss_v2=0, nll_loss=0.962, ntokens=1078.9, nsentences=120, sample_size=1078.9, sample_size_v1=0, sample_size_v2=0, ppl=1.95, wps=523.9, ups=0.49, wpb=1078.9, bsz=120, num_updates=9540, lr=2.67924e-05, gnorm=3.479, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=19680
2023-06-26 23:47:37 - progress_bar.py[line:272] - INFO: epoch 003:   2136 / 3715 loss=2.191, loss_v1=0, loss_v2=0, nll_loss=0.97, ntokens=1085.2, nsentences=120, sample_size=1085.2, sample_size_v1=0, sample_size_v2=0, ppl=1.96, wps=527.8, ups=0.49, wpb=1085.2, bsz=120, num_updates=9550, lr=2.67871e-05, gnorm=3.629, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=19701
2023-06-26 23:47:57 - progress_bar.py[line:272] - INFO: epoch 003:   2146 / 3715 loss=2.201, loss_v1=0, loss_v2=0, nll_loss=0.98, ntokens=1092.5, nsentences=120, sample_size=1092.5, sample_size_v1=0, sample_size_v2=0, ppl=1.97, wps=530.4, ups=0.49, wpb=1092.5, bsz=120, num_updates=9560, lr=2.67817e-05, gnorm=3.619, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=19721
2023-06-26 23:48:18 - progress_bar.py[line:272] - INFO: epoch 003:   2156 / 3715 loss=2.183, loss_v1=0, loss_v2=0, nll_loss=0.959, ntokens=1088.1, nsentences=120, sample_size=1088.1, sample_size_v1=0, sample_size_v2=0, ppl=1.94, wps=528.2, ups=0.49, wpb=1088.1, bsz=120, num_updates=9570, lr=2.67763e-05, gnorm=3.534, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=19742
2023-06-26 23:48:38 - progress_bar.py[line:272] - INFO: epoch 003:   2166 / 3715 loss=2.182, loss_v1=0, loss_v2=0, nll_loss=0.961, ntokens=1098, nsentences=120, sample_size=1098, sample_size_v1=0, sample_size_v2=0, ppl=1.95, wps=533.7, ups=0.49, wpb=1098, bsz=120, num_updates=9580, lr=2.67709e-05, gnorm=3.831, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=19763
2023-06-26 23:48:55 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 256.0
2023-06-26 23:49:01 - progress_bar.py[line:272] - INFO: epoch 003:   2177 / 3715 loss=2.177, loss_v1=0, loss_v2=0, nll_loss=0.953, ntokens=1103.1, nsentences=120, sample_size=1103.1, sample_size_v1=0, sample_size_v2=0, ppl=1.94, wps=486.7, ups=0.44, wpb=1103.1, bsz=120, num_updates=9590, lr=2.67656e-05, gnorm=3.753, clip=100, loss_scale=256, train_wall=23, gb_free=8.9, wall=19785
2023-06-26 23:49:22 - progress_bar.py[line:272] - INFO: epoch 003:   2187 / 3715 loss=2.179, loss_v1=0, loss_v2=0, nll_loss=0.958, ntokens=1068, nsentences=120, sample_size=1068, sample_size_v1=0, sample_size_v2=0, ppl=1.94, wps=518.4, ups=0.49, wpb=1068, bsz=120, num_updates=9600, lr=2.67602e-05, gnorm=3.673, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=19806
2023-06-26 23:49:42 - progress_bar.py[line:272] - INFO: epoch 003:   2197 / 3715 loss=2.182, loss_v1=0, loss_v2=0, nll_loss=0.957, ntokens=1085, nsentences=120, sample_size=1085, sample_size_v1=0, sample_size_v2=0, ppl=1.94, wps=526.9, ups=0.49, wpb=1085, bsz=120, num_updates=9610, lr=2.67548e-05, gnorm=3.444, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=19827
2023-06-26 23:50:03 - progress_bar.py[line:272] - INFO: epoch 003:   2207 / 3715 loss=2.18, loss_v1=0, loss_v2=0, nll_loss=0.959, ntokens=1091.5, nsentences=120, sample_size=1091.5, sample_size_v1=0, sample_size_v2=0, ppl=1.94, wps=529.8, ups=0.49, wpb=1091.5, bsz=120, num_updates=9620, lr=2.67495e-05, gnorm=3.583, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=19847
2023-06-26 23:50:23 - progress_bar.py[line:272] - INFO: epoch 003:   2217 / 3715 loss=2.185, loss_v1=0, loss_v2=0, nll_loss=0.963, ntokens=1102.3, nsentences=120, sample_size=1102.3, sample_size_v1=0, sample_size_v2=0, ppl=1.95, wps=535, ups=0.49, wpb=1102.3, bsz=120, num_updates=9630, lr=2.67441e-05, gnorm=3.482, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=19868
2023-06-26 23:50:44 - progress_bar.py[line:272] - INFO: epoch 003:   2227 / 3715 loss=2.192, loss_v1=0, loss_v2=0, nll_loss=0.973, ntokens=1100.3, nsentences=120, sample_size=1100.3, sample_size_v1=0, sample_size_v2=0, ppl=1.96, wps=533.7, ups=0.49, wpb=1100.3, bsz=120, num_updates=9640, lr=2.67387e-05, gnorm=3.579, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=19888
2023-06-26 23:51:05 - progress_bar.py[line:272] - INFO: epoch 003:   2237 / 3715 loss=2.194, loss_v1=0, loss_v2=0, nll_loss=0.97, ntokens=1085.5, nsentences=120, sample_size=1085.5, sample_size_v1=0, sample_size_v2=0, ppl=1.96, wps=528, ups=0.49, wpb=1085.5, bsz=120, num_updates=9650, lr=2.67334e-05, gnorm=3.446, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=19909
2023-06-26 23:51:25 - progress_bar.py[line:272] - INFO: epoch 003:   2247 / 3715 loss=2.19, loss_v1=0, loss_v2=0, nll_loss=0.968, ntokens=1076.4, nsentences=120, sample_size=1076.4, sample_size_v1=0, sample_size_v2=0, ppl=1.96, wps=522.1, ups=0.49, wpb=1076.4, bsz=120, num_updates=9660, lr=2.6728e-05, gnorm=3.367, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=19930
2023-06-26 23:51:46 - progress_bar.py[line:272] - INFO: epoch 003:   2257 / 3715 loss=2.19, loss_v1=0, loss_v2=0, nll_loss=0.97, ntokens=1095.5, nsentences=120, sample_size=1095.5, sample_size_v1=0, sample_size_v2=0, ppl=1.96, wps=532.4, ups=0.49, wpb=1095.5, bsz=120, num_updates=9670, lr=2.67226e-05, gnorm=3.629, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=19950
2023-06-26 23:52:06 - progress_bar.py[line:272] - INFO: epoch 003:   2267 / 3715 loss=2.186, loss_v1=0, loss_v2=0, nll_loss=0.963, ntokens=1093.9, nsentences=120, sample_size=1093.9, sample_size_v1=0, sample_size_v2=0, ppl=1.95, wps=531.6, ups=0.49, wpb=1093.9, bsz=120, num_updates=9680, lr=2.67173e-05, gnorm=3.57, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=19971
2023-06-26 23:52:27 - progress_bar.py[line:272] - INFO: epoch 003:   2277 / 3715 loss=2.165, loss_v1=0, loss_v2=0, nll_loss=0.94, ntokens=1095.2, nsentences=120, sample_size=1095.2, sample_size_v1=0, sample_size_v2=0, ppl=1.92, wps=532.1, ups=0.49, wpb=1095.2, bsz=120, num_updates=9690, lr=2.67119e-05, gnorm=3.377, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=19991
2023-06-26 23:52:48 - progress_bar.py[line:272] - INFO: epoch 003:   2287 / 3715 loss=2.182, loss_v1=0, loss_v2=0, nll_loss=0.958, ntokens=1088.1, nsentences=120, sample_size=1088.1, sample_size_v1=0, sample_size_v2=0, ppl=1.94, wps=528.5, ups=0.49, wpb=1088.1, bsz=120, num_updates=9700, lr=2.67065e-05, gnorm=3.642, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=20012
2023-06-26 23:53:08 - progress_bar.py[line:272] - INFO: epoch 003:   2297 / 3715 loss=2.182, loss_v1=0, loss_v2=0, nll_loss=0.963, ntokens=1074.1, nsentences=120, sample_size=1074.1, sample_size_v1=0, sample_size_v2=0, ppl=1.95, wps=521.3, ups=0.49, wpb=1074.1, bsz=120, num_updates=9710, lr=2.67011e-05, gnorm=3.538, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=20032
2023-06-26 23:53:29 - progress_bar.py[line:272] - INFO: epoch 003:   2307 / 3715 loss=2.187, loss_v1=0, loss_v2=0, nll_loss=0.962, ntokens=1096.2, nsentences=120, sample_size=1096.2, sample_size_v1=0, sample_size_v2=0, ppl=1.95, wps=532, ups=0.49, wpb=1096.2, bsz=120, num_updates=9720, lr=2.66958e-05, gnorm=3.55, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=20053
2023-06-26 23:53:49 - progress_bar.py[line:272] - INFO: epoch 003:   2317 / 3715 loss=2.169, loss_v1=0, loss_v2=0, nll_loss=0.946, ntokens=1071.6, nsentences=120, sample_size=1071.6, sample_size_v1=0, sample_size_v2=0, ppl=1.93, wps=520.8, ups=0.49, wpb=1071.6, bsz=120, num_updates=9730, lr=2.66904e-05, gnorm=3.676, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=20074
2023-06-26 23:54:10 - progress_bar.py[line:272] - INFO: epoch 003:   2327 / 3715 loss=2.187, loss_v1=0, loss_v2=0, nll_loss=0.963, ntokens=1085.2, nsentences=120, sample_size=1085.2, sample_size_v1=0, sample_size_v2=0, ppl=1.95, wps=526.7, ups=0.49, wpb=1085.2, bsz=120, num_updates=9740, lr=2.6685e-05, gnorm=3.634, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=20094
2023-06-26 23:54:31 - progress_bar.py[line:272] - INFO: epoch 003:   2337 / 3715 loss=2.175, loss_v1=0, loss_v2=0, nll_loss=0.952, ntokens=1082.4, nsentences=120, sample_size=1082.4, sample_size_v1=0, sample_size_v2=0, ppl=1.93, wps=524.8, ups=0.48, wpb=1082.4, bsz=120, num_updates=9750, lr=2.66797e-05, gnorm=3.858, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=20115
2023-06-26 23:54:51 - progress_bar.py[line:272] - INFO: epoch 003:   2347 / 3715 loss=2.194, loss_v1=0, loss_v2=0, nll_loss=0.973, ntokens=1099.2, nsentences=120, sample_size=1099.2, sample_size_v1=0, sample_size_v2=0, ppl=1.96, wps=534, ups=0.49, wpb=1099.2, bsz=120, num_updates=9760, lr=2.66743e-05, gnorm=3.428, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=20135
2023-06-26 23:55:12 - progress_bar.py[line:272] - INFO: epoch 003:   2357 / 3715 loss=2.182, loss_v1=0, loss_v2=0, nll_loss=0.959, ntokens=1108, nsentences=120, sample_size=1108, sample_size_v1=0, sample_size_v2=0, ppl=1.94, wps=537.9, ups=0.49, wpb=1108, bsz=120, num_updates=9770, lr=2.66689e-05, gnorm=3.283, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=20156
2023-06-26 23:55:32 - progress_bar.py[line:272] - INFO: epoch 003:   2367 / 3715 loss=2.182, loss_v1=0, loss_v2=0, nll_loss=0.96, ntokens=1083.7, nsentences=120, sample_size=1083.7, sample_size_v1=0, sample_size_v2=0, ppl=1.95, wps=526.1, ups=0.49, wpb=1083.7, bsz=120, num_updates=9780, lr=2.66636e-05, gnorm=3.731, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=20177
2023-06-26 23:55:53 - progress_bar.py[line:272] - INFO: epoch 003:   2377 / 3715 loss=2.174, loss_v1=0, loss_v2=0, nll_loss=0.952, ntokens=1086.8, nsentences=120, sample_size=1086.8, sample_size_v1=0, sample_size_v2=0, ppl=1.93, wps=527.8, ups=0.49, wpb=1086.8, bsz=120, num_updates=9790, lr=2.66582e-05, gnorm=3.714, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=20197
2023-06-26 23:56:14 - progress_bar.py[line:272] - INFO: epoch 003:   2387 / 3715 loss=2.173, loss_v1=0, loss_v2=0, nll_loss=0.949, ntokens=1084.2, nsentences=120, sample_size=1084.2, sample_size_v1=0, sample_size_v2=0, ppl=1.93, wps=525.7, ups=0.48, wpb=1084.2, bsz=120, num_updates=9800, lr=2.66528e-05, gnorm=3.73, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=20218
2023-06-26 23:56:34 - progress_bar.py[line:272] - INFO: epoch 003:   2397 / 3715 loss=2.176, loss_v1=0, loss_v2=0, nll_loss=0.952, ntokens=1063.4, nsentences=120, sample_size=1063.4, sample_size_v1=0, sample_size_v2=0, ppl=1.94, wps=516.4, ups=0.49, wpb=1063.4, bsz=120, num_updates=9810, lr=2.66475e-05, gnorm=3.455, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=20239
2023-06-26 23:56:55 - progress_bar.py[line:272] - INFO: epoch 003:   2407 / 3715 loss=2.179, loss_v1=0, loss_v2=0, nll_loss=0.956, ntokens=1069.8, nsentences=120, sample_size=1069.8, sample_size_v1=0, sample_size_v2=0, ppl=1.94, wps=519.8, ups=0.49, wpb=1069.8, bsz=120, num_updates=9820, lr=2.66421e-05, gnorm=3.656, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=20259
2023-06-26 23:57:15 - progress_bar.py[line:272] - INFO: epoch 003:   2417 / 3715 loss=2.18, loss_v1=0, loss_v2=0, nll_loss=0.958, ntokens=1091.4, nsentences=120, sample_size=1091.4, sample_size_v1=0, sample_size_v2=0, ppl=1.94, wps=530.2, ups=0.49, wpb=1091.4, bsz=120, num_updates=9830, lr=2.66367e-05, gnorm=3.498, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=20280
2023-06-26 23:57:36 - progress_bar.py[line:272] - INFO: epoch 003:   2427 / 3715 loss=2.163, loss_v1=0, loss_v2=0, nll_loss=0.94, ntokens=1116.7, nsentences=120, sample_size=1116.7, sample_size_v1=0, sample_size_v2=0, ppl=1.92, wps=541.7, ups=0.49, wpb=1116.7, bsz=120, num_updates=9840, lr=2.66313e-05, gnorm=3.538, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=20300
2023-06-26 23:57:57 - progress_bar.py[line:272] - INFO: epoch 003:   2437 / 3715 loss=2.169, loss_v1=0, loss_v2=0, nll_loss=0.945, ntokens=1083.1, nsentences=120, sample_size=1083.1, sample_size_v1=0, sample_size_v2=0, ppl=1.92, wps=526.7, ups=0.49, wpb=1083.1, bsz=120, num_updates=9850, lr=2.6626e-05, gnorm=3.579, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=20321
2023-06-26 23:58:17 - progress_bar.py[line:272] - INFO: epoch 003:   2447 / 3715 loss=2.188, loss_v1=0, loss_v2=0, nll_loss=0.966, ntokens=1077, nsentences=120, sample_size=1077, sample_size_v1=0, sample_size_v2=0, ppl=1.95, wps=523.9, ups=0.49, wpb=1077, bsz=120, num_updates=9860, lr=2.66206e-05, gnorm=3.675, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=20341
2023-06-26 23:58:38 - progress_bar.py[line:272] - INFO: epoch 003:   2457 / 3715 loss=2.183, loss_v1=0, loss_v2=0, nll_loss=0.96, ntokens=1088.6, nsentences=120, sample_size=1088.6, sample_size_v1=0, sample_size_v2=0, ppl=1.95, wps=529.1, ups=0.49, wpb=1088.6, bsz=120, num_updates=9870, lr=2.66152e-05, gnorm=3.556, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=20362
2023-06-26 23:58:58 - progress_bar.py[line:272] - INFO: epoch 003:   2467 / 3715 loss=2.17, loss_v1=0, loss_v2=0, nll_loss=0.946, ntokens=1083.8, nsentences=120, sample_size=1083.8, sample_size_v1=0, sample_size_v2=0, ppl=1.93, wps=526.9, ups=0.49, wpb=1083.8, bsz=120, num_updates=9880, lr=2.66099e-05, gnorm=3.393, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=20383
2023-06-26 23:59:19 - progress_bar.py[line:272] - INFO: epoch 003:   2477 / 3715 loss=2.166, loss_v1=0, loss_v2=0, nll_loss=0.942, ntokens=1072, nsentences=120, sample_size=1072, sample_size_v1=0, sample_size_v2=0, ppl=1.92, wps=521.6, ups=0.49, wpb=1072, bsz=120, num_updates=9890, lr=2.66045e-05, gnorm=3.558, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=20403
2023-06-26 23:59:39 - progress_bar.py[line:272] - INFO: epoch 003:   2487 / 3715 loss=2.166, loss_v1=0, loss_v2=0, nll_loss=0.944, ntokens=1088.5, nsentences=120, sample_size=1088.5, sample_size_v1=0, sample_size_v2=0, ppl=1.92, wps=529.8, ups=0.49, wpb=1088.5, bsz=120, num_updates=9900, lr=2.65991e-05, gnorm=3.699, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=20424
2023-06-27 00:00:00 - progress_bar.py[line:272] - INFO: epoch 003:   2497 / 3715 loss=2.161, loss_v1=0, loss_v2=0, nll_loss=0.934, ntokens=1038.1, nsentences=120, sample_size=1038.1, sample_size_v1=0, sample_size_v2=0, ppl=1.91, wps=504.6, ups=0.49, wpb=1038.1, bsz=120, num_updates=9910, lr=2.65938e-05, gnorm=3.877, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=20444
2023-06-27 00:00:21 - progress_bar.py[line:272] - INFO: epoch 003:   2507 / 3715 loss=2.186, loss_v1=0, loss_v2=0, nll_loss=0.963, ntokens=1069, nsentences=120, sample_size=1069, sample_size_v1=0, sample_size_v2=0, ppl=1.95, wps=519.1, ups=0.49, wpb=1069, bsz=120, num_updates=9920, lr=2.65884e-05, gnorm=3.787, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=20465
2023-06-27 00:00:41 - progress_bar.py[line:272] - INFO: epoch 003:   2517 / 3715 loss=2.179, loss_v1=0, loss_v2=0, nll_loss=0.957, ntokens=1069.5, nsentences=120, sample_size=1069.5, sample_size_v1=0, sample_size_v2=0, ppl=1.94, wps=519.3, ups=0.49, wpb=1069.5, bsz=120, num_updates=9930, lr=2.6583e-05, gnorm=3.851, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=20485
2023-06-27 00:01:02 - progress_bar.py[line:272] - INFO: epoch 003:   2527 / 3715 loss=2.166, loss_v1=0, loss_v2=0, nll_loss=0.94, ntokens=1081, nsentences=120, sample_size=1081, sample_size_v1=0, sample_size_v2=0, ppl=1.92, wps=524.9, ups=0.49, wpb=1081, bsz=120, num_updates=9940, lr=2.65777e-05, gnorm=3.683, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=20506
2023-06-27 00:01:22 - progress_bar.py[line:272] - INFO: epoch 003:   2537 / 3715 loss=2.18, loss_v1=0, loss_v2=0, nll_loss=0.959, ntokens=1094.9, nsentences=120, sample_size=1094.9, sample_size_v1=0, sample_size_v2=0, ppl=1.94, wps=532.2, ups=0.49, wpb=1094.9, bsz=120, num_updates=9950, lr=2.65723e-05, gnorm=3.473, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=20527
2023-06-27 00:01:43 - progress_bar.py[line:272] - INFO: epoch 003:   2547 / 3715 loss=2.187, loss_v1=0, loss_v2=0, nll_loss=0.965, ntokens=1087.4, nsentences=120, sample_size=1087.4, sample_size_v1=0, sample_size_v2=0, ppl=1.95, wps=528.7, ups=0.49, wpb=1087.4, bsz=120, num_updates=9960, lr=2.65669e-05, gnorm=3.717, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=20547
2023-06-27 00:02:03 - progress_bar.py[line:272] - INFO: epoch 003:   2557 / 3715 loss=2.155, loss_v1=0, loss_v2=0, nll_loss=0.929, ntokens=1092.2, nsentences=120, sample_size=1092.2, sample_size_v1=0, sample_size_v2=0, ppl=1.9, wps=531.1, ups=0.49, wpb=1092.2, bsz=120, num_updates=9970, lr=2.65615e-05, gnorm=3.578, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=20568
2023-06-27 00:02:24 - progress_bar.py[line:272] - INFO: epoch 003:   2567 / 3715 loss=2.176, loss_v1=0, loss_v2=0, nll_loss=0.952, ntokens=1095.2, nsentences=120, sample_size=1095.2, sample_size_v1=0, sample_size_v2=0, ppl=1.93, wps=532.5, ups=0.49, wpb=1095.2, bsz=120, num_updates=9980, lr=2.65562e-05, gnorm=3.503, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=20588
2023-06-27 00:02:45 - progress_bar.py[line:272] - INFO: epoch 003:   2577 / 3715 loss=2.17, loss_v1=0, loss_v2=0, nll_loss=0.947, ntokens=1084, nsentences=120, sample_size=1084, sample_size_v1=0, sample_size_v2=0, ppl=1.93, wps=527, ups=0.49, wpb=1084, bsz=120, num_updates=9990, lr=2.65508e-05, gnorm=3.711, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=20609
2023-06-27 00:03:05 - progress_bar.py[line:272] - INFO: epoch 003:   2587 / 3715 loss=2.16, loss_v1=0, loss_v2=0, nll_loss=0.935, ntokens=1082.8, nsentences=120, sample_size=1082.8, sample_size_v1=0, sample_size_v2=0, ppl=1.91, wps=526, ups=0.49, wpb=1082.8, bsz=120, num_updates=10000, lr=2.65454e-05, gnorm=3.489, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=20629
2023-06-27 00:03:26 - progress_bar.py[line:272] - INFO: epoch 003:   2597 / 3715 loss=2.169, loss_v1=0, loss_v2=0, nll_loss=0.943, ntokens=1086.7, nsentences=120, sample_size=1086.7, sample_size_v1=0, sample_size_v2=0, ppl=1.92, wps=528.8, ups=0.49, wpb=1086.7, bsz=120, num_updates=10010, lr=2.65401e-05, gnorm=3.865, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=20650
2023-06-27 00:03:46 - progress_bar.py[line:272] - INFO: epoch 003:   2607 / 3715 loss=2.166, loss_v1=0, loss_v2=0, nll_loss=0.942, ntokens=1091.2, nsentences=120, sample_size=1091.2, sample_size_v1=0, sample_size_v2=0, ppl=1.92, wps=530.9, ups=0.49, wpb=1091.2, bsz=120, num_updates=10020, lr=2.65347e-05, gnorm=3.687, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=20671
2023-06-27 00:04:07 - progress_bar.py[line:272] - INFO: epoch 003:   2617 / 3715 loss=2.18, loss_v1=0, loss_v2=0, nll_loss=0.956, ntokens=1091.6, nsentences=120, sample_size=1091.6, sample_size_v1=0, sample_size_v2=0, ppl=1.94, wps=530.9, ups=0.49, wpb=1091.6, bsz=120, num_updates=10030, lr=2.65293e-05, gnorm=3.699, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=20691
2023-06-27 00:04:27 - progress_bar.py[line:272] - INFO: epoch 003:   2627 / 3715 loss=2.166, loss_v1=0, loss_v2=0, nll_loss=0.942, ntokens=1092.4, nsentences=120, sample_size=1092.4, sample_size_v1=0, sample_size_v2=0, ppl=1.92, wps=530.9, ups=0.49, wpb=1092.4, bsz=120, num_updates=10040, lr=2.6524e-05, gnorm=3.743, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=20712
2023-06-27 00:04:48 - progress_bar.py[line:272] - INFO: epoch 003:   2637 / 3715 loss=2.169, loss_v1=0, loss_v2=0, nll_loss=0.946, ntokens=1081.9, nsentences=120, sample_size=1081.9, sample_size_v1=0, sample_size_v2=0, ppl=1.93, wps=525.5, ups=0.49, wpb=1081.9, bsz=120, num_updates=10050, lr=2.65186e-05, gnorm=3.981, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=20732
2023-06-27 00:05:09 - progress_bar.py[line:272] - INFO: epoch 003:   2647 / 3715 loss=2.176, loss_v1=0, loss_v2=0, nll_loss=0.952, ntokens=1094.3, nsentences=120, sample_size=1094.3, sample_size_v1=0, sample_size_v2=0, ppl=1.93, wps=531, ups=0.49, wpb=1094.3, bsz=120, num_updates=10060, lr=2.65132e-05, gnorm=3.745, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=20753
2023-06-27 00:05:29 - progress_bar.py[line:272] - INFO: epoch 003:   2657 / 3715 loss=2.164, loss_v1=0, loss_v2=0, nll_loss=0.939, ntokens=1071, nsentences=120, sample_size=1071, sample_size_v1=0, sample_size_v2=0, ppl=1.92, wps=520, ups=0.49, wpb=1071, bsz=120, num_updates=10070, lr=2.65079e-05, gnorm=3.716, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=20774
2023-06-27 00:05:50 - progress_bar.py[line:272] - INFO: epoch 003:   2667 / 3715 loss=2.162, loss_v1=0, loss_v2=0, nll_loss=0.937, ntokens=1082.8, nsentences=120, sample_size=1082.8, sample_size_v1=0, sample_size_v2=0, ppl=1.91, wps=525.4, ups=0.49, wpb=1082.8, bsz=120, num_updates=10080, lr=2.65025e-05, gnorm=3.616, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=20794
2023-06-27 00:06:10 - progress_bar.py[line:272] - INFO: epoch 003:   2677 / 3715 loss=2.183, loss_v1=0, loss_v2=0, nll_loss=0.96, ntokens=1086, nsentences=120, sample_size=1086, sample_size_v1=0, sample_size_v2=0, ppl=1.95, wps=526.6, ups=0.48, wpb=1086, bsz=120, num_updates=10090, lr=2.64971e-05, gnorm=3.861, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=20815
2023-06-27 00:06:31 - progress_bar.py[line:272] - INFO: epoch 003:   2687 / 3715 loss=2.165, loss_v1=0, loss_v2=0, nll_loss=0.939, ntokens=1069.1, nsentences=120, sample_size=1069.1, sample_size_v1=0, sample_size_v2=0, ppl=1.92, wps=518.7, ups=0.49, wpb=1069.1, bsz=120, num_updates=10100, lr=2.64917e-05, gnorm=3.639, clip=100, loss_scale=512, train_wall=21, gb_free=8.9, wall=20835
2023-06-27 00:06:35 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 256.0
2023-06-27 00:06:54 - progress_bar.py[line:272] - INFO: epoch 003:   2698 / 3715 loss=2.159, loss_v1=0, loss_v2=0, nll_loss=0.935, ntokens=1105.4, nsentences=120, sample_size=1105.4, sample_size_v1=0, sample_size_v2=0, ppl=1.91, wps=488.4, ups=0.44, wpb=1105.4, bsz=120, num_updates=10110, lr=2.64864e-05, gnorm=3.611, clip=100, loss_scale=256, train_wall=23, gb_free=8.9, wall=20858
2023-06-27 00:07:14 - progress_bar.py[line:272] - INFO: epoch 003:   2708 / 3715 loss=2.157, loss_v1=0, loss_v2=0, nll_loss=0.933, ntokens=1089.5, nsentences=120, sample_size=1089.5, sample_size_v1=0, sample_size_v2=0, ppl=1.91, wps=528.9, ups=0.49, wpb=1089.5, bsz=120, num_updates=10120, lr=2.6481e-05, gnorm=3.294, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=20879
2023-06-27 00:07:35 - progress_bar.py[line:272] - INFO: epoch 003:   2718 / 3715 loss=2.161, loss_v1=0, loss_v2=0, nll_loss=0.936, ntokens=1085, nsentences=120, sample_size=1085, sample_size_v1=0, sample_size_v2=0, ppl=1.91, wps=526.8, ups=0.49, wpb=1085, bsz=120, num_updates=10130, lr=2.64756e-05, gnorm=3.664, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=20899
2023-06-27 00:07:56 - progress_bar.py[line:272] - INFO: epoch 003:   2728 / 3715 loss=2.15, loss_v1=0, loss_v2=0, nll_loss=0.922, ntokens=1073.4, nsentences=120, sample_size=1073.4, sample_size_v1=0, sample_size_v2=0, ppl=1.89, wps=520.7, ups=0.49, wpb=1073.4, bsz=120, num_updates=10140, lr=2.64703e-05, gnorm=3.549, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=20920
2023-06-27 00:08:16 - progress_bar.py[line:272] - INFO: epoch 003:   2738 / 3715 loss=2.15, loss_v1=0, loss_v2=0, nll_loss=0.925, ntokens=1099.8, nsentences=120, sample_size=1099.8, sample_size_v1=0, sample_size_v2=0, ppl=1.9, wps=533.6, ups=0.49, wpb=1099.8, bsz=120, num_updates=10150, lr=2.64649e-05, gnorm=3.455, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=20940
2023-06-27 00:08:37 - progress_bar.py[line:272] - INFO: epoch 003:   2748 / 3715 loss=2.163, loss_v1=0, loss_v2=0, nll_loss=0.938, ntokens=1061.9, nsentences=120, sample_size=1061.9, sample_size_v1=0, sample_size_v2=0, ppl=1.92, wps=515.2, ups=0.49, wpb=1061.9, bsz=120, num_updates=10160, lr=2.64595e-05, gnorm=3.595, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=20961
2023-06-27 00:08:57 - progress_bar.py[line:272] - INFO: epoch 003:   2758 / 3715 loss=2.164, loss_v1=0, loss_v2=0, nll_loss=0.938, ntokens=1072.4, nsentences=120, sample_size=1072.4, sample_size_v1=0, sample_size_v2=0, ppl=1.92, wps=520.9, ups=0.49, wpb=1072.4, bsz=120, num_updates=10170, lr=2.64542e-05, gnorm=3.539, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=20982
2023-06-27 00:09:18 - progress_bar.py[line:272] - INFO: epoch 003:   2768 / 3715 loss=2.168, loss_v1=0, loss_v2=0, nll_loss=0.945, ntokens=1090.9, nsentences=120, sample_size=1090.9, sample_size_v1=0, sample_size_v2=0, ppl=1.93, wps=529.1, ups=0.49, wpb=1090.9, bsz=120, num_updates=10180, lr=2.64488e-05, gnorm=3.603, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=21002
2023-06-27 00:09:39 - progress_bar.py[line:272] - INFO: epoch 003:   2778 / 3715 loss=2.17, loss_v1=0, loss_v2=0, nll_loss=0.944, ntokens=1108.5, nsentences=120, sample_size=1108.5, sample_size_v1=0, sample_size_v2=0, ppl=1.92, wps=538, ups=0.49, wpb=1108.5, bsz=120, num_updates=10190, lr=2.64434e-05, gnorm=3.656, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=21023
2023-06-27 00:09:59 - progress_bar.py[line:272] - INFO: epoch 003:   2788 / 3715 loss=2.174, loss_v1=0, loss_v2=0, nll_loss=0.951, ntokens=1079.3, nsentences=120, sample_size=1079.3, sample_size_v1=0, sample_size_v2=0, ppl=1.93, wps=524.6, ups=0.49, wpb=1079.3, bsz=120, num_updates=10200, lr=2.64381e-05, gnorm=3.675, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=21043
2023-06-27 00:10:20 - progress_bar.py[line:272] - INFO: epoch 003:   2798 / 3715 loss=2.147, loss_v1=0, loss_v2=0, nll_loss=0.92, ntokens=1094.6, nsentences=120, sample_size=1094.6, sample_size_v1=0, sample_size_v2=0, ppl=1.89, wps=527.4, ups=0.48, wpb=1094.6, bsz=120, num_updates=10210, lr=2.64327e-05, gnorm=3.481, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=21064
2023-06-27 00:10:40 - progress_bar.py[line:272] - INFO: epoch 003:   2808 / 3715 loss=2.16, loss_v1=0, loss_v2=0, nll_loss=0.934, ntokens=1075.9, nsentences=120, sample_size=1075.9, sample_size_v1=0, sample_size_v2=0, ppl=1.91, wps=523.1, ups=0.49, wpb=1075.9, bsz=120, num_updates=10220, lr=2.64273e-05, gnorm=3.566, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=21085
2023-06-27 00:11:01 - progress_bar.py[line:272] - INFO: epoch 003:   2818 / 3715 loss=2.172, loss_v1=0, loss_v2=0, nll_loss=0.948, ntokens=1069.9, nsentences=120, sample_size=1069.9, sample_size_v1=0, sample_size_v2=0, ppl=1.93, wps=520.4, ups=0.49, wpb=1069.9, bsz=120, num_updates=10230, lr=2.64219e-05, gnorm=3.684, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=21105
2023-06-27 00:11:22 - progress_bar.py[line:272] - INFO: epoch 003:   2828 / 3715 loss=2.165, loss_v1=0, loss_v2=0, nll_loss=0.941, ntokens=1080.9, nsentences=120, sample_size=1080.9, sample_size_v1=0, sample_size_v2=0, ppl=1.92, wps=525.7, ups=0.49, wpb=1080.9, bsz=120, num_updates=10240, lr=2.64166e-05, gnorm=3.537, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=21126
2023-06-27 00:11:42 - progress_bar.py[line:272] - INFO: epoch 003:   2838 / 3715 loss=2.155, loss_v1=0, loss_v2=0, nll_loss=0.929, ntokens=1089.6, nsentences=120, sample_size=1089.6, sample_size_v1=0, sample_size_v2=0, ppl=1.9, wps=529.7, ups=0.49, wpb=1089.6, bsz=120, num_updates=10250, lr=2.64112e-05, gnorm=3.764, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=21147
2023-06-27 00:12:03 - progress_bar.py[line:272] - INFO: epoch 003:   2848 / 3715 loss=2.152, loss_v1=0, loss_v2=0, nll_loss=0.927, ntokens=1102.4, nsentences=120, sample_size=1102.4, sample_size_v1=0, sample_size_v2=0, ppl=1.9, wps=536, ups=0.49, wpb=1102.4, bsz=120, num_updates=10260, lr=2.64058e-05, gnorm=3.654, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=21167
2023-06-27 00:12:23 - progress_bar.py[line:272] - INFO: epoch 003:   2858 / 3715 loss=2.16, loss_v1=0, loss_v2=0, nll_loss=0.935, ntokens=1088.8, nsentences=120, sample_size=1088.8, sample_size_v1=0, sample_size_v2=0, ppl=1.91, wps=528.5, ups=0.49, wpb=1088.8, bsz=120, num_updates=10270, lr=2.64005e-05, gnorm=3.391, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=21188
2023-06-27 00:12:44 - progress_bar.py[line:272] - INFO: epoch 003:   2868 / 3715 loss=2.169, loss_v1=0, loss_v2=0, nll_loss=0.945, ntokens=1102.9, nsentences=120, sample_size=1102.9, sample_size_v1=0, sample_size_v2=0, ppl=1.92, wps=534.9, ups=0.49, wpb=1102.9, bsz=120, num_updates=10280, lr=2.63951e-05, gnorm=3.353, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=21208
2023-06-27 00:13:05 - progress_bar.py[line:272] - INFO: epoch 003:   2878 / 3715 loss=2.139, loss_v1=0, loss_v2=0, nll_loss=0.911, ntokens=1073.9, nsentences=120, sample_size=1073.9, sample_size_v1=0, sample_size_v2=0, ppl=1.88, wps=520.3, ups=0.48, wpb=1073.9, bsz=120, num_updates=10290, lr=2.63897e-05, gnorm=3.512, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=21229
2023-06-27 00:13:25 - progress_bar.py[line:272] - INFO: epoch 003:   2888 / 3715 loss=2.166, loss_v1=0, loss_v2=0, nll_loss=0.943, ntokens=1100.8, nsentences=120, sample_size=1100.8, sample_size_v1=0, sample_size_v2=0, ppl=1.92, wps=533.7, ups=0.48, wpb=1100.8, bsz=120, num_updates=10300, lr=2.63844e-05, gnorm=3.611, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=21250
2023-06-27 00:13:46 - progress_bar.py[line:272] - INFO: epoch 003:   2898 / 3715 loss=2.164, loss_v1=0, loss_v2=0, nll_loss=0.939, ntokens=1074.6, nsentences=120, sample_size=1074.6, sample_size_v1=0, sample_size_v2=0, ppl=1.92, wps=521.5, ups=0.49, wpb=1074.6, bsz=120, num_updates=10310, lr=2.6379e-05, gnorm=3.492, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=21270
2023-06-27 00:14:06 - progress_bar.py[line:272] - INFO: epoch 003:   2908 / 3715 loss=2.146, loss_v1=0, loss_v2=0, nll_loss=0.92, ntokens=1073, nsentences=120, sample_size=1073, sample_size_v1=0, sample_size_v2=0, ppl=1.89, wps=520.2, ups=0.48, wpb=1073, bsz=120, num_updates=10320, lr=2.63736e-05, gnorm=3.348, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=21291
2023-06-27 00:14:27 - progress_bar.py[line:272] - INFO: epoch 003:   2918 / 3715 loss=2.169, loss_v1=0, loss_v2=0, nll_loss=0.943, ntokens=1083, nsentences=120, sample_size=1083, sample_size_v1=0, sample_size_v2=0, ppl=1.92, wps=525.3, ups=0.49, wpb=1083, bsz=120, num_updates=10330, lr=2.63683e-05, gnorm=3.509, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=21311
2023-06-27 00:14:48 - progress_bar.py[line:272] - INFO: epoch 003:   2928 / 3715 loss=2.154, loss_v1=0, loss_v2=0, nll_loss=0.93, ntokens=1100.1, nsentences=120, sample_size=1100.1, sample_size_v1=0, sample_size_v2=0, ppl=1.91, wps=533.9, ups=0.49, wpb=1100.1, bsz=120, num_updates=10340, lr=2.63629e-05, gnorm=3.533, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=21332
2023-06-27 00:15:08 - progress_bar.py[line:272] - INFO: epoch 003:   2938 / 3715 loss=2.178, loss_v1=0, loss_v2=0, nll_loss=0.954, ntokens=1080.9, nsentences=120, sample_size=1080.9, sample_size_v1=0, sample_size_v2=0, ppl=1.94, wps=525.1, ups=0.49, wpb=1080.9, bsz=120, num_updates=10350, lr=2.63575e-05, gnorm=3.683, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=21353
2023-06-27 00:15:29 - progress_bar.py[line:272] - INFO: epoch 003:   2948 / 3715 loss=2.158, loss_v1=0, loss_v2=0, nll_loss=0.934, ntokens=1098.5, nsentences=120, sample_size=1098.5, sample_size_v1=0, sample_size_v2=0, ppl=1.91, wps=533.1, ups=0.49, wpb=1098.5, bsz=120, num_updates=10360, lr=2.63521e-05, gnorm=3.629, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=21373
2023-06-27 00:15:49 - progress_bar.py[line:272] - INFO: epoch 003:   2958 / 3715 loss=2.151, loss_v1=0, loss_v2=0, nll_loss=0.924, ntokens=1078, nsentences=120, sample_size=1078, sample_size_v1=0, sample_size_v2=0, ppl=1.9, wps=524.6, ups=0.49, wpb=1078, bsz=120, num_updates=10370, lr=2.63468e-05, gnorm=3.468, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=21394
2023-06-27 00:16:10 - progress_bar.py[line:272] - INFO: epoch 003:   2968 / 3715 loss=2.165, loss_v1=0, loss_v2=0, nll_loss=0.941, ntokens=1080.7, nsentences=120, sample_size=1080.7, sample_size_v1=0, sample_size_v2=0, ppl=1.92, wps=525.7, ups=0.49, wpb=1080.7, bsz=120, num_updates=10380, lr=2.63414e-05, gnorm=3.689, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=21414
2023-06-27 00:16:31 - progress_bar.py[line:272] - INFO: epoch 003:   2978 / 3715 loss=2.161, loss_v1=0, loss_v2=0, nll_loss=0.934, ntokens=1093.3, nsentences=120, sample_size=1093.3, sample_size_v1=0, sample_size_v2=0, ppl=1.91, wps=532.2, ups=0.49, wpb=1093.3, bsz=120, num_updates=10390, lr=2.6336e-05, gnorm=3.529, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=21435
2023-06-27 00:16:51 - progress_bar.py[line:272] - INFO: epoch 003:   2988 / 3715 loss=2.155, loss_v1=0, loss_v2=0, nll_loss=0.931, ntokens=1087.4, nsentences=120, sample_size=1087.4, sample_size_v1=0, sample_size_v2=0, ppl=1.91, wps=529.3, ups=0.49, wpb=1087.4, bsz=120, num_updates=10400, lr=2.63307e-05, gnorm=3.467, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=21455
2023-06-27 00:17:12 - progress_bar.py[line:272] - INFO: epoch 003:   2998 / 3715 loss=2.161, loss_v1=0, loss_v2=0, nll_loss=0.936, ntokens=1089.1, nsentences=120, sample_size=1089.1, sample_size_v1=0, sample_size_v2=0, ppl=1.91, wps=529.6, ups=0.49, wpb=1089.1, bsz=120, num_updates=10410, lr=2.63253e-05, gnorm=3.579, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=21476
2023-06-27 00:17:32 - progress_bar.py[line:272] - INFO: epoch 003:   3008 / 3715 loss=2.165, loss_v1=0, loss_v2=0, nll_loss=0.94, ntokens=1079.8, nsentences=120, sample_size=1079.8, sample_size_v1=0, sample_size_v2=0, ppl=1.92, wps=525.7, ups=0.49, wpb=1079.8, bsz=120, num_updates=10420, lr=2.63199e-05, gnorm=3.594, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=21497
2023-06-27 00:17:53 - progress_bar.py[line:272] - INFO: epoch 003:   3018 / 3715 loss=2.181, loss_v1=0, loss_v2=0, nll_loss=0.958, ntokens=1098.7, nsentences=120, sample_size=1098.7, sample_size_v1=0, sample_size_v2=0, ppl=1.94, wps=534.3, ups=0.49, wpb=1098.7, bsz=120, num_updates=10430, lr=2.63146e-05, gnorm=3.476, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=21517
2023-06-27 00:18:13 - progress_bar.py[line:272] - INFO: epoch 003:   3028 / 3715 loss=2.15, loss_v1=0, loss_v2=0, nll_loss=0.924, ntokens=1062.4, nsentences=120, sample_size=1062.4, sample_size_v1=0, sample_size_v2=0, ppl=1.9, wps=516.9, ups=0.49, wpb=1062.4, bsz=120, num_updates=10440, lr=2.63092e-05, gnorm=3.59, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=21538
2023-06-27 00:18:34 - progress_bar.py[line:272] - INFO: epoch 003:   3038 / 3715 loss=2.154, loss_v1=0, loss_v2=0, nll_loss=0.928, ntokens=1084.5, nsentences=120, sample_size=1084.5, sample_size_v1=0, sample_size_v2=0, ppl=1.9, wps=526.9, ups=0.49, wpb=1084.5, bsz=120, num_updates=10450, lr=2.63038e-05, gnorm=3.532, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=21558
2023-06-27 00:18:55 - progress_bar.py[line:272] - INFO: epoch 003:   3048 / 3715 loss=2.152, loss_v1=0, loss_v2=0, nll_loss=0.927, ntokens=1070, nsentences=120, sample_size=1070, sample_size_v1=0, sample_size_v2=0, ppl=1.9, wps=518.7, ups=0.48, wpb=1070, bsz=120, num_updates=10460, lr=2.62985e-05, gnorm=3.829, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=21579
2023-06-27 00:19:15 - progress_bar.py[line:272] - INFO: epoch 003:   3058 / 3715 loss=2.147, loss_v1=0, loss_v2=0, nll_loss=0.919, ntokens=1092.3, nsentences=120, sample_size=1092.3, sample_size_v1=0, sample_size_v2=0, ppl=1.89, wps=530.3, ups=0.49, wpb=1092.3, bsz=120, num_updates=10470, lr=2.62931e-05, gnorm=3.752, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=21600
2023-06-27 00:19:36 - progress_bar.py[line:272] - INFO: epoch 003:   3068 / 3715 loss=2.145, loss_v1=0, loss_v2=0, nll_loss=0.918, ntokens=1078.9, nsentences=120, sample_size=1078.9, sample_size_v1=0, sample_size_v2=0, ppl=1.89, wps=524.4, ups=0.49, wpb=1078.9, bsz=120, num_updates=10480, lr=2.62877e-05, gnorm=3.525, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=21620
2023-06-27 00:19:56 - progress_bar.py[line:272] - INFO: epoch 003:   3078 / 3715 loss=2.145, loss_v1=0, loss_v2=0, nll_loss=0.918, ntokens=1084.6, nsentences=120, sample_size=1084.6, sample_size_v1=0, sample_size_v2=0, ppl=1.89, wps=526.9, ups=0.49, wpb=1084.6, bsz=120, num_updates=10490, lr=2.62823e-05, gnorm=3.493, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=21641
2023-06-27 00:20:17 - progress_bar.py[line:272] - INFO: epoch 003:   3088 / 3715 loss=2.157, loss_v1=0, loss_v2=0, nll_loss=0.932, ntokens=1079.5, nsentences=120, sample_size=1079.5, sample_size_v1=0, sample_size_v2=0, ppl=1.91, wps=524.5, ups=0.49, wpb=1079.5, bsz=120, num_updates=10500, lr=2.6277e-05, gnorm=3.652, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=21661
2023-06-27 00:20:38 - progress_bar.py[line:272] - INFO: epoch 003:   3098 / 3715 loss=2.158, loss_v1=0, loss_v2=0, nll_loss=0.931, ntokens=1063.4, nsentences=120, sample_size=1063.4, sample_size_v1=0, sample_size_v2=0, ppl=1.91, wps=515.8, ups=0.49, wpb=1063.4, bsz=120, num_updates=10510, lr=2.62716e-05, gnorm=3.709, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=21682
2023-06-27 00:20:58 - progress_bar.py[line:272] - INFO: epoch 003:   3108 / 3715 loss=2.153, loss_v1=0, loss_v2=0, nll_loss=0.927, ntokens=1064.2, nsentences=120, sample_size=1064.2, sample_size_v1=0, sample_size_v2=0, ppl=1.9, wps=516.5, ups=0.49, wpb=1064.2, bsz=120, num_updates=10520, lr=2.62662e-05, gnorm=3.805, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=21702
2023-06-27 00:21:19 - progress_bar.py[line:272] - INFO: epoch 003:   3118 / 3715 loss=2.151, loss_v1=0, loss_v2=0, nll_loss=0.927, ntokens=1074.7, nsentences=120, sample_size=1074.7, sample_size_v1=0, sample_size_v2=0, ppl=1.9, wps=522.1, ups=0.49, wpb=1074.7, bsz=120, num_updates=10530, lr=2.62609e-05, gnorm=3.839, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=21723
2023-06-27 00:21:39 - progress_bar.py[line:272] - INFO: epoch 003:   3128 / 3715 loss=2.145, loss_v1=0, loss_v2=0, nll_loss=0.915, ntokens=1072.2, nsentences=120, sample_size=1072.2, sample_size_v1=0, sample_size_v2=0, ppl=1.89, wps=520.5, ups=0.49, wpb=1072.2, bsz=120, num_updates=10540, lr=2.62555e-05, gnorm=3.684, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=21744
2023-06-27 00:22:00 - progress_bar.py[line:272] - INFO: epoch 003:   3138 / 3715 loss=2.153, loss_v1=0, loss_v2=0, nll_loss=0.928, ntokens=1089.1, nsentences=120, sample_size=1089.1, sample_size_v1=0, sample_size_v2=0, ppl=1.9, wps=528.4, ups=0.49, wpb=1089.1, bsz=120, num_updates=10550, lr=2.62501e-05, gnorm=3.638, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=21764
2023-06-27 00:22:21 - progress_bar.py[line:272] - INFO: epoch 003:   3148 / 3715 loss=2.154, loss_v1=0, loss_v2=0, nll_loss=0.928, ntokens=1063.1, nsentences=120, sample_size=1063.1, sample_size_v1=0, sample_size_v2=0, ppl=1.9, wps=516.9, ups=0.49, wpb=1063.1, bsz=120, num_updates=10560, lr=2.62448e-05, gnorm=3.879, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=21785
2023-06-27 00:22:41 - progress_bar.py[line:272] - INFO: epoch 003:   3158 / 3715 loss=2.136, loss_v1=0, loss_v2=0, nll_loss=0.909, ntokens=1091, nsentences=120, sample_size=1091, sample_size_v1=0, sample_size_v2=0, ppl=1.88, wps=529.9, ups=0.49, wpb=1091, bsz=120, num_updates=10570, lr=2.62394e-05, gnorm=3.622, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=21805
2023-06-27 00:23:02 - progress_bar.py[line:272] - INFO: epoch 003:   3168 / 3715 loss=2.151, loss_v1=0, loss_v2=0, nll_loss=0.923, ntokens=1097.9, nsentences=120, sample_size=1097.9, sample_size_v1=0, sample_size_v2=0, ppl=1.9, wps=533.6, ups=0.49, wpb=1097.9, bsz=120, num_updates=10580, lr=2.6234e-05, gnorm=3.588, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=21826
2023-06-27 00:23:22 - progress_bar.py[line:272] - INFO: epoch 003:   3178 / 3715 loss=2.145, loss_v1=0, loss_v2=0, nll_loss=0.918, ntokens=1079.8, nsentences=120, sample_size=1079.8, sample_size_v1=0, sample_size_v2=0, ppl=1.89, wps=524.5, ups=0.49, wpb=1079.8, bsz=120, num_updates=10590, lr=2.62287e-05, gnorm=3.803, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=21847
2023-06-27 00:23:43 - progress_bar.py[line:272] - INFO: epoch 003:   3188 / 3715 loss=2.141, loss_v1=0, loss_v2=0, nll_loss=0.914, ntokens=1075, nsentences=120, sample_size=1075, sample_size_v1=0, sample_size_v2=0, ppl=1.88, wps=518.1, ups=0.48, wpb=1075, bsz=120, num_updates=10600, lr=2.62233e-05, gnorm=3.437, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=21867
2023-06-27 00:24:04 - progress_bar.py[line:272] - INFO: epoch 003:   3198 / 3715 loss=2.143, loss_v1=0, loss_v2=0, nll_loss=0.916, ntokens=1084.3, nsentences=120, sample_size=1084.3, sample_size_v1=0, sample_size_v2=0, ppl=1.89, wps=526.7, ups=0.49, wpb=1084.3, bsz=120, num_updates=10610, lr=2.62179e-05, gnorm=3.77, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=21888
2023-06-27 00:24:24 - progress_bar.py[line:272] - INFO: epoch 003:   3208 / 3715 loss=2.128, loss_v1=0, loss_v2=0, nll_loss=0.9, ntokens=1071.1, nsentences=120, sample_size=1071.1, sample_size_v1=0, sample_size_v2=0, ppl=1.87, wps=520.4, ups=0.49, wpb=1071.1, bsz=120, num_updates=10620, lr=2.62125e-05, gnorm=3.664, clip=100, loss_scale=512, train_wall=21, gb_free=8.8, wall=21909
2023-06-27 00:24:26 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 256.0
2023-06-27 00:24:47 - progress_bar.py[line:272] - INFO: epoch 003:   3219 / 3715 loss=2.138, loss_v1=0, loss_v2=0, nll_loss=0.909, ntokens=1094.8, nsentences=120, sample_size=1094.8, sample_size_v1=0, sample_size_v2=0, ppl=1.88, wps=483.8, ups=0.44, wpb=1094.8, bsz=120, num_updates=10630, lr=2.62072e-05, gnorm=3.541, clip=100, loss_scale=256, train_wall=23, gb_free=8.9, wall=21931
2023-06-27 00:25:07 - progress_bar.py[line:272] - INFO: epoch 003:   3229 / 3715 loss=2.153, loss_v1=0, loss_v2=0, nll_loss=0.928, ntokens=1070.6, nsentences=120, sample_size=1070.6, sample_size_v1=0, sample_size_v2=0, ppl=1.9, wps=519.3, ups=0.49, wpb=1070.6, bsz=120, num_updates=10640, lr=2.62018e-05, gnorm=3.671, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=21952
2023-06-27 00:25:28 - progress_bar.py[line:272] - INFO: epoch 003:   3239 / 3715 loss=2.149, loss_v1=0, loss_v2=0, nll_loss=0.922, ntokens=1086.3, nsentences=120, sample_size=1086.3, sample_size_v1=0, sample_size_v2=0, ppl=1.89, wps=526.8, ups=0.48, wpb=1086.3, bsz=120, num_updates=10650, lr=2.61964e-05, gnorm=3.551, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=21972
2023-06-27 00:25:49 - progress_bar.py[line:272] - INFO: epoch 003:   3249 / 3715 loss=2.137, loss_v1=0, loss_v2=0, nll_loss=0.908, ntokens=1066.4, nsentences=120, sample_size=1066.4, sample_size_v1=0, sample_size_v2=0, ppl=1.88, wps=517.8, ups=0.49, wpb=1066.4, bsz=120, num_updates=10660, lr=2.61911e-05, gnorm=3.754, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=21993
2023-06-27 00:26:09 - progress_bar.py[line:272] - INFO: epoch 003:   3259 / 3715 loss=2.137, loss_v1=0, loss_v2=0, nll_loss=0.91, ntokens=1092.4, nsentences=120, sample_size=1092.4, sample_size_v1=0, sample_size_v2=0, ppl=1.88, wps=530, ups=0.49, wpb=1092.4, bsz=120, num_updates=10670, lr=2.61857e-05, gnorm=3.596, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=22014
2023-06-27 00:26:30 - progress_bar.py[line:272] - INFO: epoch 003:   3269 / 3715 loss=2.148, loss_v1=0, loss_v2=0, nll_loss=0.922, ntokens=1076.7, nsentences=120, sample_size=1076.7, sample_size_v1=0, sample_size_v2=0, ppl=1.9, wps=522, ups=0.48, wpb=1076.7, bsz=120, num_updates=10680, lr=2.61803e-05, gnorm=3.467, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=22034
2023-06-27 00:26:51 - progress_bar.py[line:272] - INFO: epoch 003:   3279 / 3715 loss=2.134, loss_v1=0, loss_v2=0, nll_loss=0.905, ntokens=1084.4, nsentences=120, sample_size=1084.4, sample_size_v1=0, sample_size_v2=0, ppl=1.87, wps=526.5, ups=0.49, wpb=1084.4, bsz=120, num_updates=10690, lr=2.6175e-05, gnorm=3.63, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=22055
2023-06-27 00:27:11 - progress_bar.py[line:272] - INFO: epoch 003:   3289 / 3715 loss=2.144, loss_v1=0, loss_v2=0, nll_loss=0.917, ntokens=1067.9, nsentences=120, sample_size=1067.9, sample_size_v1=0, sample_size_v2=0, ppl=1.89, wps=519.3, ups=0.49, wpb=1067.9, bsz=120, num_updates=10700, lr=2.61696e-05, gnorm=3.61, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=22075
2023-06-27 00:27:32 - progress_bar.py[line:272] - INFO: epoch 003:   3299 / 3715 loss=2.141, loss_v1=0, loss_v2=0, nll_loss=0.914, ntokens=1107.2, nsentences=120, sample_size=1107.2, sample_size_v1=0, sample_size_v2=0, ppl=1.88, wps=538.5, ups=0.49, wpb=1107.2, bsz=120, num_updates=10710, lr=2.61642e-05, gnorm=3.71, clip=100, loss_scale=256, train_wall=21, gb_free=8.8, wall=22096
2023-06-27 00:27:52 - progress_bar.py[line:272] - INFO: epoch 003:   3309 / 3715 loss=2.159, loss_v1=0, loss_v2=0, nll_loss=0.932, ntokens=1082.3, nsentences=120, sample_size=1082.3, sample_size_v1=0, sample_size_v2=0, ppl=1.91, wps=525.8, ups=0.49, wpb=1082.3, bsz=120, num_updates=10720, lr=2.61589e-05, gnorm=3.666, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=22117
2023-06-27 00:28:13 - progress_bar.py[line:272] - INFO: epoch 003:   3319 / 3715 loss=2.137, loss_v1=0, loss_v2=0, nll_loss=0.908, ntokens=1063.5, nsentences=120, sample_size=1063.5, sample_size_v1=0, sample_size_v2=0, ppl=1.88, wps=517, ups=0.49, wpb=1063.5, bsz=120, num_updates=10730, lr=2.61535e-05, gnorm=3.634, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=22137
2023-06-27 00:28:33 - progress_bar.py[line:272] - INFO: epoch 003:   3329 / 3715 loss=2.131, loss_v1=0, loss_v2=0, nll_loss=0.905, ntokens=1087, nsentences=120, sample_size=1087, sample_size_v1=0, sample_size_v2=0, ppl=1.87, wps=527.1, ups=0.48, wpb=1087, bsz=120, num_updates=10740, lr=2.61481e-05, gnorm=3.502, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=22158
2023-06-27 00:28:54 - progress_bar.py[line:272] - INFO: epoch 003:   3339 / 3715 loss=2.141, loss_v1=0, loss_v2=0, nll_loss=0.911, ntokens=1093.5, nsentences=120, sample_size=1093.5, sample_size_v1=0, sample_size_v2=0, ppl=1.88, wps=531.4, ups=0.49, wpb=1093.5, bsz=120, num_updates=10750, lr=2.61427e-05, gnorm=3.736, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=22178
2023-06-27 00:29:15 - progress_bar.py[line:272] - INFO: epoch 003:   3349 / 3715 loss=2.142, loss_v1=0, loss_v2=0, nll_loss=0.916, ntokens=1101.9, nsentences=120, sample_size=1101.9, sample_size_v1=0, sample_size_v2=0, ppl=1.89, wps=535, ups=0.49, wpb=1101.9, bsz=120, num_updates=10760, lr=2.61374e-05, gnorm=3.686, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=22199
2023-06-27 00:29:35 - progress_bar.py[line:272] - INFO: epoch 003:   3359 / 3715 loss=2.132, loss_v1=0, loss_v2=0, nll_loss=0.903, ntokens=1087.4, nsentences=120, sample_size=1087.4, sample_size_v1=0, sample_size_v2=0, ppl=1.87, wps=527.8, ups=0.49, wpb=1087.4, bsz=120, num_updates=10770, lr=2.6132e-05, gnorm=3.709, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=22220
2023-06-27 00:29:56 - progress_bar.py[line:272] - INFO: epoch 003:   3369 / 3715 loss=2.157, loss_v1=0, loss_v2=0, nll_loss=0.932, ntokens=1095.3, nsentences=120, sample_size=1095.3, sample_size_v1=0, sample_size_v2=0, ppl=1.91, wps=531.5, ups=0.49, wpb=1095.3, bsz=120, num_updates=10780, lr=2.61266e-05, gnorm=3.73, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=22240
2023-06-27 00:30:16 - progress_bar.py[line:272] - INFO: epoch 003:   3379 / 3715 loss=2.145, loss_v1=0, loss_v2=0, nll_loss=0.917, ntokens=1077, nsentences=120, sample_size=1077, sample_size_v1=0, sample_size_v2=0, ppl=1.89, wps=522.8, ups=0.49, wpb=1077, bsz=120, num_updates=10790, lr=2.61213e-05, gnorm=3.606, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=22261
2023-06-27 00:30:37 - progress_bar.py[line:272] - INFO: epoch 003:   3389 / 3715 loss=2.138, loss_v1=0, loss_v2=0, nll_loss=0.912, ntokens=1087.3, nsentences=120, sample_size=1087.3, sample_size_v1=0, sample_size_v2=0, ppl=1.88, wps=528.7, ups=0.49, wpb=1087.3, bsz=120, num_updates=10800, lr=2.61159e-05, gnorm=3.568, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=22281
2023-06-27 00:30:58 - progress_bar.py[line:272] - INFO: epoch 003:   3399 / 3715 loss=2.154, loss_v1=0, loss_v2=0, nll_loss=0.926, ntokens=1070.3, nsentences=120, sample_size=1070.3, sample_size_v1=0, sample_size_v2=0, ppl=1.9, wps=520, ups=0.49, wpb=1070.3, bsz=120, num_updates=10810, lr=2.61105e-05, gnorm=3.889, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=22302
2023-06-27 00:31:18 - progress_bar.py[line:272] - INFO: epoch 003:   3409 / 3715 loss=2.143, loss_v1=0, loss_v2=0, nll_loss=0.917, ntokens=1084.4, nsentences=120, sample_size=1084.4, sample_size_v1=0, sample_size_v2=0, ppl=1.89, wps=526.5, ups=0.49, wpb=1084.4, bsz=120, num_updates=10820, lr=2.61052e-05, gnorm=3.814, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=22323
2023-06-27 00:31:39 - progress_bar.py[line:272] - INFO: epoch 003:   3419 / 3715 loss=2.124, loss_v1=0, loss_v2=0, nll_loss=0.894, ntokens=1076, nsentences=120, sample_size=1076, sample_size_v1=0, sample_size_v2=0, ppl=1.86, wps=522.3, ups=0.49, wpb=1076, bsz=120, num_updates=10830, lr=2.60998e-05, gnorm=3.825, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=22343
2023-06-27 00:31:59 - progress_bar.py[line:272] - INFO: epoch 003:   3429 / 3715 loss=2.122, loss_v1=0, loss_v2=0, nll_loss=0.892, ntokens=1076.8, nsentences=120, sample_size=1076.8, sample_size_v1=0, sample_size_v2=0, ppl=1.86, wps=522.8, ups=0.49, wpb=1076.8, bsz=120, num_updates=10840, lr=2.60944e-05, gnorm=3.899, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=22364
2023-06-27 00:32:20 - progress_bar.py[line:272] - INFO: epoch 003:   3439 / 3715 loss=2.148, loss_v1=0, loss_v2=0, nll_loss=0.92, ntokens=1076.4, nsentences=120, sample_size=1076.4, sample_size_v1=0, sample_size_v2=0, ppl=1.89, wps=522.9, ups=0.49, wpb=1076.4, bsz=120, num_updates=10850, lr=2.60891e-05, gnorm=3.971, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=22384
2023-06-27 00:32:41 - progress_bar.py[line:272] - INFO: epoch 003:   3449 / 3715 loss=2.119, loss_v1=0, loss_v2=0, nll_loss=0.889, ntokens=1075.8, nsentences=120, sample_size=1075.8, sample_size_v1=0, sample_size_v2=0, ppl=1.85, wps=522.1, ups=0.49, wpb=1075.8, bsz=120, num_updates=10860, lr=2.60837e-05, gnorm=3.76, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=22405
2023-06-27 00:33:01 - progress_bar.py[line:272] - INFO: epoch 003:   3459 / 3715 loss=2.118, loss_v1=0, loss_v2=0, nll_loss=0.887, ntokens=1091.2, nsentences=120, sample_size=1091.2, sample_size_v1=0, sample_size_v2=0, ppl=1.85, wps=530.1, ups=0.49, wpb=1091.2, bsz=120, num_updates=10870, lr=2.60783e-05, gnorm=3.729, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=22426
2023-06-27 00:33:22 - progress_bar.py[line:272] - INFO: epoch 003:   3469 / 3715 loss=2.127, loss_v1=0, loss_v2=0, nll_loss=0.899, ntokens=1076.5, nsentences=120, sample_size=1076.5, sample_size_v1=0, sample_size_v2=0, ppl=1.86, wps=522.6, ups=0.49, wpb=1076.5, bsz=120, num_updates=10880, lr=2.60729e-05, gnorm=3.828, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=22446
2023-06-27 00:33:42 - progress_bar.py[line:272] - INFO: epoch 003:   3479 / 3715 loss=2.125, loss_v1=0, loss_v2=0, nll_loss=0.893, ntokens=1077.7, nsentences=120, sample_size=1077.7, sample_size_v1=0, sample_size_v2=0, ppl=1.86, wps=523.2, ups=0.49, wpb=1077.7, bsz=120, num_updates=10890, lr=2.60676e-05, gnorm=3.839, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=22467
2023-06-27 00:34:03 - progress_bar.py[line:272] - INFO: epoch 003:   3489 / 3715 loss=2.135, loss_v1=0, loss_v2=0, nll_loss=0.908, ntokens=1098.5, nsentences=120, sample_size=1098.5, sample_size_v1=0, sample_size_v2=0, ppl=1.88, wps=533.5, ups=0.49, wpb=1098.5, bsz=120, num_updates=10900, lr=2.60622e-05, gnorm=3.531, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=22487
2023-06-27 00:34:24 - progress_bar.py[line:272] - INFO: epoch 003:   3499 / 3715 loss=2.129, loss_v1=0, loss_v2=0, nll_loss=0.9, ntokens=1093.8, nsentences=120, sample_size=1093.8, sample_size_v1=0, sample_size_v2=0, ppl=1.87, wps=530.4, ups=0.48, wpb=1093.8, bsz=120, num_updates=10910, lr=2.60568e-05, gnorm=3.646, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=22508
2023-06-27 00:34:44 - progress_bar.py[line:272] - INFO: epoch 003:   3509 / 3715 loss=2.141, loss_v1=0, loss_v2=0, nll_loss=0.914, ntokens=1091.2, nsentences=120, sample_size=1091.2, sample_size_v1=0, sample_size_v2=0, ppl=1.88, wps=530, ups=0.49, wpb=1091.2, bsz=120, num_updates=10920, lr=2.60515e-05, gnorm=3.725, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=22529
2023-06-27 00:35:05 - progress_bar.py[line:272] - INFO: epoch 003:   3519 / 3715 loss=2.129, loss_v1=0, loss_v2=0, nll_loss=0.899, ntokens=1062.9, nsentences=120, sample_size=1062.9, sample_size_v1=0, sample_size_v2=0, ppl=1.87, wps=516.7, ups=0.49, wpb=1062.9, bsz=120, num_updates=10930, lr=2.60461e-05, gnorm=3.67, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=22549
2023-06-27 00:35:25 - progress_bar.py[line:272] - INFO: epoch 003:   3529 / 3715 loss=2.131, loss_v1=0, loss_v2=0, nll_loss=0.903, ntokens=1084, nsentences=120, sample_size=1084, sample_size_v1=0, sample_size_v2=0, ppl=1.87, wps=526.6, ups=0.49, wpb=1084, bsz=120, num_updates=10940, lr=2.60407e-05, gnorm=3.672, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=22570
2023-06-27 00:35:46 - progress_bar.py[line:272] - INFO: epoch 003:   3539 / 3715 loss=2.152, loss_v1=0, loss_v2=0, nll_loss=0.926, ntokens=1100.7, nsentences=120, sample_size=1100.7, sample_size_v1=0, sample_size_v2=0, ppl=1.9, wps=534.6, ups=0.49, wpb=1100.7, bsz=120, num_updates=10950, lr=2.60354e-05, gnorm=3.772, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=22590
2023-06-27 00:36:07 - progress_bar.py[line:272] - INFO: epoch 003:   3549 / 3715 loss=2.123, loss_v1=0, loss_v2=0, nll_loss=0.894, ntokens=1081, nsentences=120, sample_size=1081, sample_size_v1=0, sample_size_v2=0, ppl=1.86, wps=524, ups=0.48, wpb=1081, bsz=120, num_updates=10960, lr=2.603e-05, gnorm=3.588, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=22611
2023-06-27 00:36:27 - progress_bar.py[line:272] - INFO: epoch 003:   3559 / 3715 loss=2.126, loss_v1=0, loss_v2=0, nll_loss=0.898, ntokens=1064.1, nsentences=120, sample_size=1064.1, sample_size_v1=0, sample_size_v2=0, ppl=1.86, wps=517.1, ups=0.49, wpb=1064.1, bsz=120, num_updates=10970, lr=2.60246e-05, gnorm=3.637, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=22632
2023-06-27 00:36:48 - progress_bar.py[line:272] - INFO: epoch 003:   3569 / 3715 loss=2.125, loss_v1=0, loss_v2=0, nll_loss=0.896, ntokens=1099, nsentences=120, sample_size=1099, sample_size_v1=0, sample_size_v2=0, ppl=1.86, wps=533.4, ups=0.49, wpb=1099, bsz=120, num_updates=10980, lr=2.60193e-05, gnorm=3.594, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=22652
2023-06-27 00:37:08 - progress_bar.py[line:272] - INFO: epoch 003:   3579 / 3715 loss=2.132, loss_v1=0, loss_v2=0, nll_loss=0.901, ntokens=1095.2, nsentences=120, sample_size=1095.2, sample_size_v1=0, sample_size_v2=0, ppl=1.87, wps=531.5, ups=0.49, wpb=1095.2, bsz=120, num_updates=10990, lr=2.60139e-05, gnorm=3.791, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=22673
2023-06-27 00:37:29 - progress_bar.py[line:272] - INFO: epoch 003:   3589 / 3715 loss=2.122, loss_v1=0, loss_v2=0, nll_loss=0.891, ntokens=1112.1, nsentences=120, sample_size=1112.1, sample_size_v1=0, sample_size_v2=0, ppl=1.85, wps=539.6, ups=0.49, wpb=1112.1, bsz=120, num_updates=11000, lr=2.60085e-05, gnorm=3.623, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=22693
2023-06-27 00:37:50 - progress_bar.py[line:272] - INFO: epoch 003:   3599 / 3715 loss=2.142, loss_v1=0, loss_v2=0, nll_loss=0.917, ntokens=1091.3, nsentences=120, sample_size=1091.3, sample_size_v1=0, sample_size_v2=0, ppl=1.89, wps=529.6, ups=0.49, wpb=1091.3, bsz=120, num_updates=11010, lr=2.60031e-05, gnorm=3.612, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=22714
2023-06-27 00:38:10 - progress_bar.py[line:272] - INFO: epoch 003:   3609 / 3715 loss=2.141, loss_v1=0, loss_v2=0, nll_loss=0.911, ntokens=1069.8, nsentences=120, sample_size=1069.8, sample_size_v1=0, sample_size_v2=0, ppl=1.88, wps=519.8, ups=0.49, wpb=1069.8, bsz=120, num_updates=11020, lr=2.59978e-05, gnorm=4.06, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=22735
2023-06-27 00:38:31 - progress_bar.py[line:272] - INFO: epoch 003:   3619 / 3715 loss=2.134, loss_v1=0, loss_v2=0, nll_loss=0.906, ntokens=1077.4, nsentences=120, sample_size=1077.4, sample_size_v1=0, sample_size_v2=0, ppl=1.87, wps=523.2, ups=0.49, wpb=1077.4, bsz=120, num_updates=11030, lr=2.59924e-05, gnorm=3.729, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=22755
2023-06-27 00:38:51 - progress_bar.py[line:272] - INFO: epoch 003:   3629 / 3715 loss=2.137, loss_v1=0, loss_v2=0, nll_loss=0.91, ntokens=1080.4, nsentences=120, sample_size=1080.4, sample_size_v1=0, sample_size_v2=0, ppl=1.88, wps=524.5, ups=0.49, wpb=1080.4, bsz=120, num_updates=11040, lr=2.5987e-05, gnorm=4.052, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=22776
2023-06-27 00:39:12 - progress_bar.py[line:272] - INFO: epoch 003:   3639 / 3715 loss=2.128, loss_v1=0, loss_v2=0, nll_loss=0.899, ntokens=1072.5, nsentences=120, sample_size=1072.5, sample_size_v1=0, sample_size_v2=0, ppl=1.86, wps=521.5, ups=0.49, wpb=1072.5, bsz=120, num_updates=11050, lr=2.59817e-05, gnorm=3.648, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=22796
2023-06-27 00:39:33 - progress_bar.py[line:272] - INFO: epoch 003:   3649 / 3715 loss=2.128, loss_v1=0, loss_v2=0, nll_loss=0.899, ntokens=1081, nsentences=120, sample_size=1081, sample_size_v1=0, sample_size_v2=0, ppl=1.87, wps=525.6, ups=0.49, wpb=1081, bsz=120, num_updates=11060, lr=2.59763e-05, gnorm=3.675, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=22817
2023-06-27 00:39:53 - progress_bar.py[line:272] - INFO: epoch 003:   3659 / 3715 loss=2.13, loss_v1=0, loss_v2=0, nll_loss=0.902, ntokens=1070.9, nsentences=120, sample_size=1070.9, sample_size_v1=0, sample_size_v2=0, ppl=1.87, wps=521, ups=0.49, wpb=1070.9, bsz=120, num_updates=11070, lr=2.59709e-05, gnorm=3.629, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=22837
2023-06-27 00:40:14 - progress_bar.py[line:272] - INFO: epoch 003:   3669 / 3715 loss=2.139, loss_v1=0, loss_v2=0, nll_loss=0.912, ntokens=1089.4, nsentences=120, sample_size=1089.4, sample_size_v1=0, sample_size_v2=0, ppl=1.88, wps=529.8, ups=0.49, wpb=1089.4, bsz=120, num_updates=11080, lr=2.59656e-05, gnorm=3.698, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=22858
2023-06-27 00:40:34 - progress_bar.py[line:272] - INFO: epoch 003:   3679 / 3715 loss=2.104, loss_v1=0, loss_v2=0, nll_loss=0.872, ntokens=1083.7, nsentences=120, sample_size=1083.7, sample_size_v1=0, sample_size_v2=0, ppl=1.83, wps=526.6, ups=0.49, wpb=1083.7, bsz=120, num_updates=11090, lr=2.59602e-05, gnorm=3.71, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=22879
2023-06-27 00:40:55 - progress_bar.py[line:272] - INFO: epoch 003:   3689 / 3715 loss=2.144, loss_v1=0, loss_v2=0, nll_loss=0.917, ntokens=1083.6, nsentences=120, sample_size=1083.6, sample_size_v1=0, sample_size_v2=0, ppl=1.89, wps=526.6, ups=0.49, wpb=1083.6, bsz=120, num_updates=11100, lr=2.59548e-05, gnorm=3.803, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=22899
2023-06-27 00:41:15 - progress_bar.py[line:272] - INFO: epoch 003:   3699 / 3715 loss=2.113, loss_v1=0, loss_v2=0, nll_loss=0.882, ntokens=1105, nsentences=120, sample_size=1105, sample_size_v1=0, sample_size_v2=0, ppl=1.84, wps=537.4, ups=0.49, wpb=1105, bsz=120, num_updates=11110, lr=2.59495e-05, gnorm=3.761, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=22920
2023-06-27 00:41:36 - progress_bar.py[line:272] - INFO: epoch 003:   3709 / 3715 loss=2.124, loss_v1=0, loss_v2=0, nll_loss=0.894, ntokens=1070.7, nsentences=120, sample_size=1070.7, sample_size_v1=0, sample_size_v2=0, ppl=1.86, wps=520.8, ups=0.49, wpb=1070.7, bsz=120, num_updates=11120, lr=2.59441e-05, gnorm=3.914, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=22940
2023-06-27 00:41:48 - train.py[line:332] - INFO: end of epoch 3 (average epoch stats below)
local datafile ../../dataset/OFA_data/vrd_balanced/vg_train_full.tsv slice_id 2 begin to initialize row_count and line_idx-to-offset mappinglocal datafile ../../dataset/OFA_data/vrd_balanced/vg_train_full.tsv slice_id 1 begin to initialize row_count and line_idx-to-offset mapping

2023-06-27 00:41:48 - progress_bar.py[line:282] - INFO: epoch 003 | loss 2.194 | loss_v1 0 | loss_v2 0 | nll_loss 0.973 | ntokens 1083.34 | nsentences 119.996 | sample_size 1083.34 | sample_size_v1 0 | sample_size_v2 0 | ppl 1.96 | wps 525.2 | ups 0.48 | wpb 1083.3 | bsz 120 | num_updates 11126 | lr 2.59409e-05 | gnorm 3.598 | clip 100 | loss_scale 256 | train_wall 7636 | gb_free 8.9 | wall 22953
2023-06-27 00:41:48 - trainer.py[line:639] - INFO: loading train data for epoch 4
local datafile ../../dataset/OFA_data/vrd_balanced/vg_train_full.tsv slice_id 0 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../dataset/OFA_data/vrd_balanced/vg_train_full.tsv slice_id 1 finished initializing row_count and line_idx-to-offset mapping
file ../../dataset/OFA_data/vrd_balanced/vg_train_full.tsv slice_id 1 row count 148595 total row count 445785
local datafile ../../dataset/OFA_data/vrd_balanced/vg_train_full.tsv slice_id 2 finished initializing row_count and line_idx-to-offset mapping
file ../../dataset/OFA_data/vrd_balanced/vg_train_full.tsv slice_id 2 row count 148595 total row count 445785
local datafile ../../dataset/OFA_data/vrd_balanced/vg_train_full.tsv slice_id 0 finished initializing row_count and line_idx-to-offset mapping
file ../../dataset/OFA_data/vrd_balanced/vg_train_full.tsv slice_id 0 row count 148595 total row count 445785
slice_id 2 seek offset 297190
slice_id 0 seek offset 0
slice_id 1 seek offset 148595
2023-06-27 00:41:49 - trainer.py[line:703] - INFO: begin training epoch 4
2023-06-27 00:41:49 - train.py[line:305] - INFO: Start iterating over samples
2023-06-27 00:41:57 - progress_bar.py[line:272] - INFO: epoch 004:      4 / 3715 loss=2.127, loss_v1=0, loss_v2=0, nll_loss=0.897, ntokens=1091.8, nsentences=120, sample_size=1091.8, sample_size_v1=0, sample_size_v2=0, ppl=1.86, wps=516, ups=0.47, wpb=1091.8, bsz=120, num_updates=11130, lr=2.59387e-05, gnorm=3.763, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=22961
2023-06-27 00:42:05 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 256.0
2023-06-27 00:42:20 - progress_bar.py[line:272] - INFO: epoch 004:     15 / 3715 loss=2.126, loss_v1=0, loss_v2=0, nll_loss=0.898, ntokens=1072.3, nsentences=120, sample_size=1072.3, sample_size_v1=0, sample_size_v2=0, ppl=1.86, wps=474.1, ups=0.44, wpb=1072.3, bsz=120, num_updates=11140, lr=2.59334e-05, gnorm=3.764, clip=100, loss_scale=256, train_wall=23, gb_free=8.9, wall=22984
2023-06-27 00:42:40 - progress_bar.py[line:272] - INFO: epoch 004:     25 / 3715 loss=2.123, loss_v1=0, loss_v2=0, nll_loss=0.892, ntokens=1081.3, nsentences=120, sample_size=1081.3, sample_size_v1=0, sample_size_v2=0, ppl=1.86, wps=525.1, ups=0.49, wpb=1081.3, bsz=120, num_updates=11150, lr=2.5928e-05, gnorm=3.693, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=23005
2023-06-27 00:43:01 - progress_bar.py[line:272] - INFO: epoch 004:     35 / 3715 loss=2.153, loss_v1=0, loss_v2=0, nll_loss=0.927, ntokens=1090.4, nsentences=120, sample_size=1090.4, sample_size_v1=0, sample_size_v2=0, ppl=1.9, wps=529.6, ups=0.49, wpb=1090.4, bsz=120, num_updates=11160, lr=2.59226e-05, gnorm=3.616, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=23025
2023-06-27 00:43:22 - progress_bar.py[line:272] - INFO: epoch 004:     45 / 3715 loss=2.12, loss_v1=0, loss_v2=0, nll_loss=0.889, ntokens=1083.4, nsentences=120, sample_size=1083.4, sample_size_v1=0, sample_size_v2=0, ppl=1.85, wps=526.4, ups=0.49, wpb=1083.4, bsz=120, num_updates=11170, lr=2.59172e-05, gnorm=3.877, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=23046
2023-06-27 00:43:42 - progress_bar.py[line:272] - INFO: epoch 004:     55 / 3715 loss=2.129, loss_v1=0, loss_v2=0, nll_loss=0.901, ntokens=1086, nsentences=120, sample_size=1086, sample_size_v1=0, sample_size_v2=0, ppl=1.87, wps=527.2, ups=0.49, wpb=1086, bsz=120, num_updates=11180, lr=2.59119e-05, gnorm=3.713, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=23066
2023-06-27 00:44:03 - progress_bar.py[line:272] - INFO: epoch 004:     65 / 3715 loss=2.114, loss_v1=0, loss_v2=0, nll_loss=0.882, ntokens=1058.4, nsentences=120, sample_size=1058.4, sample_size_v1=0, sample_size_v2=0, ppl=1.84, wps=512.9, ups=0.48, wpb=1058.4, bsz=120, num_updates=11190, lr=2.59065e-05, gnorm=3.775, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=23087
2023-06-27 00:44:23 - progress_bar.py[line:272] - INFO: epoch 004:     75 / 3715 loss=2.126, loss_v1=0, loss_v2=0, nll_loss=0.898, ntokens=1103.3, nsentences=120, sample_size=1103.3, sample_size_v1=0, sample_size_v2=0, ppl=1.86, wps=535.6, ups=0.49, wpb=1103.3, bsz=120, num_updates=11200, lr=2.59011e-05, gnorm=3.792, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=23108
2023-06-27 00:44:44 - progress_bar.py[line:272] - INFO: epoch 004:     85 / 3715 loss=2.14, loss_v1=0, loss_v2=0, nll_loss=0.911, ntokens=1067.2, nsentences=120, sample_size=1067.2, sample_size_v1=0, sample_size_v2=0, ppl=1.88, wps=516.5, ups=0.48, wpb=1067.2, bsz=120, num_updates=11210, lr=2.58958e-05, gnorm=3.861, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=23128
2023-06-27 00:45:05 - progress_bar.py[line:272] - INFO: epoch 004:     95 / 3715 loss=2.13, loss_v1=0, loss_v2=0, nll_loss=0.902, ntokens=1100.4, nsentences=120, sample_size=1100.4, sample_size_v1=0, sample_size_v2=0, ppl=1.87, wps=533.6, ups=0.48, wpb=1100.4, bsz=120, num_updates=11220, lr=2.58904e-05, gnorm=3.734, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=23149
2023-06-27 00:45:25 - progress_bar.py[line:272] - INFO: epoch 004:    105 / 3715 loss=2.127, loss_v1=0, loss_v2=0, nll_loss=0.897, ntokens=1085.2, nsentences=120, sample_size=1085.2, sample_size_v1=0, sample_size_v2=0, ppl=1.86, wps=527.2, ups=0.49, wpb=1085.2, bsz=120, num_updates=11230, lr=2.5885e-05, gnorm=3.567, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=23170
2023-06-27 00:45:46 - progress_bar.py[line:272] - INFO: epoch 004:    115 / 3715 loss=2.133, loss_v1=0, loss_v2=0, nll_loss=0.907, ntokens=1109, nsentences=120, sample_size=1109, sample_size_v1=0, sample_size_v2=0, ppl=1.87, wps=538.5, ups=0.49, wpb=1109, bsz=120, num_updates=11240, lr=2.58797e-05, gnorm=3.62, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=23190
2023-06-27 00:46:06 - progress_bar.py[line:272] - INFO: epoch 004:    125 / 3715 loss=2.118, loss_v1=0, loss_v2=0, nll_loss=0.887, ntokens=1077.5, nsentences=120, sample_size=1077.5, sample_size_v1=0, sample_size_v2=0, ppl=1.85, wps=523.1, ups=0.49, wpb=1077.5, bsz=120, num_updates=11250, lr=2.58743e-05, gnorm=3.983, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=23211
2023-06-27 00:46:27 - progress_bar.py[line:272] - INFO: epoch 004:    135 / 3715 loss=2.132, loss_v1=0, loss_v2=0, nll_loss=0.903, ntokens=1077.1, nsentences=120, sample_size=1077.1, sample_size_v1=0, sample_size_v2=0, ppl=1.87, wps=522.6, ups=0.49, wpb=1077.1, bsz=120, num_updates=11260, lr=2.58689e-05, gnorm=3.939, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=23231
2023-06-27 00:46:48 - progress_bar.py[line:272] - INFO: epoch 004:    145 / 3715 loss=2.116, loss_v1=0, loss_v2=0, nll_loss=0.885, ntokens=1092.8, nsentences=120, sample_size=1092.8, sample_size_v1=0, sample_size_v2=0, ppl=1.85, wps=530.5, ups=0.49, wpb=1092.8, bsz=120, num_updates=11270, lr=2.58636e-05, gnorm=3.677, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=23252
2023-06-27 00:47:08 - progress_bar.py[line:272] - INFO: epoch 004:    155 / 3715 loss=2.12, loss_v1=0, loss_v2=0, nll_loss=0.89, ntokens=1084.9, nsentences=120, sample_size=1084.9, sample_size_v1=0, sample_size_v2=0, ppl=1.85, wps=527, ups=0.49, wpb=1084.9, bsz=120, num_updates=11280, lr=2.58582e-05, gnorm=3.855, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=23273
2023-06-27 00:47:29 - progress_bar.py[line:272] - INFO: epoch 004:    165 / 3715 loss=2.122, loss_v1=0, loss_v2=0, nll_loss=0.893, ntokens=1071.6, nsentences=120, sample_size=1071.6, sample_size_v1=0, sample_size_v2=0, ppl=1.86, wps=521.4, ups=0.49, wpb=1071.6, bsz=120, num_updates=11290, lr=2.58528e-05, gnorm=3.753, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=23293
2023-06-27 00:47:49 - progress_bar.py[line:272] - INFO: epoch 004:    175 / 3715 loss=2.121, loss_v1=0, loss_v2=0, nll_loss=0.893, ntokens=1096.4, nsentences=120, sample_size=1096.4, sample_size_v1=0, sample_size_v2=0, ppl=1.86, wps=533, ups=0.49, wpb=1096.4, bsz=120, num_updates=11300, lr=2.58474e-05, gnorm=4.014, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=23314
2023-06-27 00:48:10 - progress_bar.py[line:272] - INFO: epoch 004:    185 / 3715 loss=2.117, loss_v1=0, loss_v2=0, nll_loss=0.885, ntokens=1090.2, nsentences=120, sample_size=1090.2, sample_size_v1=0, sample_size_v2=0, ppl=1.85, wps=529.6, ups=0.49, wpb=1090.2, bsz=120, num_updates=11310, lr=2.58421e-05, gnorm=3.704, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=23334
2023-06-27 00:48:31 - progress_bar.py[line:272] - INFO: epoch 004:    195 / 3715 loss=2.101, loss_v1=0, loss_v2=0, nll_loss=0.867, ntokens=1083.9, nsentences=120, sample_size=1083.9, sample_size_v1=0, sample_size_v2=0, ppl=1.82, wps=526.5, ups=0.49, wpb=1083.9, bsz=120, num_updates=11320, lr=2.58367e-05, gnorm=3.772, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=23355
2023-06-27 00:48:51 - progress_bar.py[line:272] - INFO: epoch 004:    205 / 3715 loss=2.127, loss_v1=0, loss_v2=0, nll_loss=0.9, ntokens=1060.6, nsentences=120, sample_size=1060.6, sample_size_v1=0, sample_size_v2=0, ppl=1.87, wps=516, ups=0.49, wpb=1060.6, bsz=120, num_updates=11330, lr=2.58313e-05, gnorm=3.818, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=23375
2023-06-27 00:49:12 - progress_bar.py[line:272] - INFO: epoch 004:    215 / 3715 loss=2.111, loss_v1=0, loss_v2=0, nll_loss=0.88, ntokens=1090.7, nsentences=120, sample_size=1090.7, sample_size_v1=0, sample_size_v2=0, ppl=1.84, wps=530.3, ups=0.49, wpb=1090.7, bsz=120, num_updates=11340, lr=2.5826e-05, gnorm=3.879, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=23396
2023-06-27 00:49:32 - progress_bar.py[line:272] - INFO: epoch 004:    225 / 3715 loss=2.125, loss_v1=0, loss_v2=0, nll_loss=0.894, ntokens=1079.1, nsentences=120, sample_size=1079.1, sample_size_v1=0, sample_size_v2=0, ppl=1.86, wps=523.2, ups=0.48, wpb=1079.1, bsz=120, num_updates=11350, lr=2.58206e-05, gnorm=3.778, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=23417
2023-06-27 00:49:53 - progress_bar.py[line:272] - INFO: epoch 004:    235 / 3715 loss=2.114, loss_v1=0, loss_v2=0, nll_loss=0.884, ntokens=1069.8, nsentences=120, sample_size=1069.8, sample_size_v1=0, sample_size_v2=0, ppl=1.85, wps=519.2, ups=0.49, wpb=1069.8, bsz=120, num_updates=11360, lr=2.58152e-05, gnorm=3.798, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=23437
2023-06-27 00:50:14 - progress_bar.py[line:272] - INFO: epoch 004:    245 / 3715 loss=2.114, loss_v1=0, loss_v2=0, nll_loss=0.886, ntokens=1093.3, nsentences=120, sample_size=1093.3, sample_size_v1=0, sample_size_v2=0, ppl=1.85, wps=531.4, ups=0.49, wpb=1093.3, bsz=120, num_updates=11370, lr=2.58099e-05, gnorm=3.734, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=23458
2023-06-27 00:50:34 - progress_bar.py[line:272] - INFO: epoch 004:    255 / 3715 loss=2.106, loss_v1=0, loss_v2=0, nll_loss=0.873, ntokens=1072.2, nsentences=120, sample_size=1072.2, sample_size_v1=0, sample_size_v2=0, ppl=1.83, wps=520.4, ups=0.49, wpb=1072.2, bsz=120, num_updates=11380, lr=2.58045e-05, gnorm=4.074, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=23478
2023-06-27 00:50:55 - progress_bar.py[line:272] - INFO: epoch 004:    265 / 3715 loss=2.109, loss_v1=0, loss_v2=0, nll_loss=0.878, ntokens=1068.6, nsentences=120, sample_size=1068.6, sample_size_v1=0, sample_size_v2=0, ppl=1.84, wps=518.3, ups=0.49, wpb=1068.6, bsz=120, num_updates=11390, lr=2.57991e-05, gnorm=3.778, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=23499
2023-06-27 00:51:15 - progress_bar.py[line:272] - INFO: epoch 004:    275 / 3715 loss=2.117, loss_v1=0, loss_v2=0, nll_loss=0.888, ntokens=1090.5, nsentences=120, sample_size=1090.5, sample_size_v1=0, sample_size_v2=0, ppl=1.85, wps=528.9, ups=0.49, wpb=1090.5, bsz=120, num_updates=11400, lr=2.57938e-05, gnorm=3.886, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=23520
2023-06-27 00:51:36 - progress_bar.py[line:272] - INFO: epoch 004:    285 / 3715 loss=2.116, loss_v1=0, loss_v2=0, nll_loss=0.883, ntokens=1081.6, nsentences=120, sample_size=1081.6, sample_size_v1=0, sample_size_v2=0, ppl=1.84, wps=525.5, ups=0.49, wpb=1081.6, bsz=120, num_updates=11410, lr=2.57884e-05, gnorm=3.695, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=23540
2023-06-27 00:51:57 - progress_bar.py[line:272] - INFO: epoch 004:    295 / 3715 loss=2.121, loss_v1=0, loss_v2=0, nll_loss=0.893, ntokens=1077.4, nsentences=120, sample_size=1077.4, sample_size_v1=0, sample_size_v2=0, ppl=1.86, wps=523, ups=0.49, wpb=1077.4, bsz=120, num_updates=11420, lr=2.5783e-05, gnorm=4.01, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=23561
2023-06-27 00:52:17 - progress_bar.py[line:272] - INFO: epoch 004:    305 / 3715 loss=2.113, loss_v1=0, loss_v2=0, nll_loss=0.881, ntokens=1083.5, nsentences=120, sample_size=1083.5, sample_size_v1=0, sample_size_v2=0, ppl=1.84, wps=527.4, ups=0.49, wpb=1083.5, bsz=120, num_updates=11430, lr=2.57776e-05, gnorm=3.845, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=23581
2023-06-27 00:52:38 - progress_bar.py[line:272] - INFO: epoch 004:    315 / 3715 loss=2.102, loss_v1=0, loss_v2=0, nll_loss=0.871, ntokens=1080.5, nsentences=120, sample_size=1080.5, sample_size_v1=0, sample_size_v2=0, ppl=1.83, wps=525.5, ups=0.49, wpb=1080.5, bsz=120, num_updates=11440, lr=2.57723e-05, gnorm=3.834, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=23602
2023-06-27 00:52:58 - progress_bar.py[line:272] - INFO: epoch 004:    325 / 3715 loss=2.123, loss_v1=0, loss_v2=0, nll_loss=0.891, ntokens=1101, nsentences=120, sample_size=1101, sample_size_v1=0, sample_size_v2=0, ppl=1.85, wps=535.2, ups=0.49, wpb=1101, bsz=120, num_updates=11450, lr=2.57669e-05, gnorm=3.768, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=23623
2023-06-27 00:53:19 - progress_bar.py[line:272] - INFO: epoch 004:    335 / 3715 loss=2.112, loss_v1=0, loss_v2=0, nll_loss=0.881, ntokens=1074.7, nsentences=120, sample_size=1074.7, sample_size_v1=0, sample_size_v2=0, ppl=1.84, wps=522.1, ups=0.49, wpb=1074.7, bsz=120, num_updates=11460, lr=2.57615e-05, gnorm=3.791, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=23643
2023-06-27 00:53:39 - progress_bar.py[line:272] - INFO: epoch 004:    345 / 3715 loss=2.106, loss_v1=0, loss_v2=0, nll_loss=0.875, ntokens=1070.3, nsentences=120, sample_size=1070.3, sample_size_v1=0, sample_size_v2=0, ppl=1.83, wps=520.7, ups=0.49, wpb=1070.3, bsz=120, num_updates=11470, lr=2.57562e-05, gnorm=3.807, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=23664
2023-06-27 00:54:00 - progress_bar.py[line:272] - INFO: epoch 004:    355 / 3715 loss=2.116, loss_v1=0, loss_v2=0, nll_loss=0.885, ntokens=1106.3, nsentences=120, sample_size=1106.3, sample_size_v1=0, sample_size_v2=0, ppl=1.85, wps=536.9, ups=0.49, wpb=1106.3, bsz=120, num_updates=11480, lr=2.57508e-05, gnorm=3.723, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=23684
2023-06-27 00:54:21 - progress_bar.py[line:272] - INFO: epoch 004:    365 / 3715 loss=2.106, loss_v1=0, loss_v2=0, nll_loss=0.875, ntokens=1085.3, nsentences=120, sample_size=1085.3, sample_size_v1=0, sample_size_v2=0, ppl=1.83, wps=526.3, ups=0.48, wpb=1085.3, bsz=120, num_updates=11490, lr=2.57454e-05, gnorm=3.822, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=23705
2023-06-27 00:54:41 - progress_bar.py[line:272] - INFO: epoch 004:    375 / 3715 loss=2.12, loss_v1=0, loss_v2=0, nll_loss=0.89, ntokens=1116.5, nsentences=120, sample_size=1116.5, sample_size_v1=0, sample_size_v2=0, ppl=1.85, wps=541.4, ups=0.48, wpb=1116.5, bsz=120, num_updates=11500, lr=2.57401e-05, gnorm=3.785, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=23726
2023-06-27 00:55:02 - progress_bar.py[line:272] - INFO: epoch 004:    385 / 3715 loss=2.096, loss_v1=0, loss_v2=0, nll_loss=0.863, ntokens=1068.2, nsentences=120, sample_size=1068.2, sample_size_v1=0, sample_size_v2=0, ppl=1.82, wps=517.9, ups=0.48, wpb=1068.2, bsz=120, num_updates=11510, lr=2.57347e-05, gnorm=3.673, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=23746
2023-06-27 00:55:22 - progress_bar.py[line:272] - INFO: epoch 004:    395 / 3715 loss=2.107, loss_v1=0, loss_v2=0, nll_loss=0.875, ntokens=1101.6, nsentences=120, sample_size=1101.6, sample_size_v1=0, sample_size_v2=0, ppl=1.83, wps=534.5, ups=0.49, wpb=1101.6, bsz=120, num_updates=11520, lr=2.57293e-05, gnorm=3.869, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=23767
2023-06-27 00:55:43 - progress_bar.py[line:272] - INFO: epoch 004:    405 / 3715 loss=2.099, loss_v1=0, loss_v2=0, nll_loss=0.866, ntokens=1063.1, nsentences=120, sample_size=1063.1, sample_size_v1=0, sample_size_v2=0, ppl=1.82, wps=516.3, ups=0.49, wpb=1063.1, bsz=120, num_updates=11530, lr=2.5724e-05, gnorm=4.061, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=23787
2023-06-27 00:56:04 - progress_bar.py[line:272] - INFO: epoch 004:    415 / 3715 loss=2.102, loss_v1=0, loss_v2=0, nll_loss=0.868, ntokens=1078.2, nsentences=120, sample_size=1078.2, sample_size_v1=0, sample_size_v2=0, ppl=1.83, wps=523.9, ups=0.49, wpb=1078.2, bsz=120, num_updates=11540, lr=2.57186e-05, gnorm=4.041, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=23808
2023-06-27 00:56:24 - progress_bar.py[line:272] - INFO: epoch 004:    425 / 3715 loss=2.117, loss_v1=0, loss_v2=0, nll_loss=0.888, ntokens=1085.6, nsentences=120, sample_size=1085.6, sample_size_v1=0, sample_size_v2=0, ppl=1.85, wps=527.2, ups=0.49, wpb=1085.6, bsz=120, num_updates=11550, lr=2.57132e-05, gnorm=3.835, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=23829
2023-06-27 00:56:45 - progress_bar.py[line:272] - INFO: epoch 004:    435 / 3715 loss=2.117, loss_v1=0, loss_v2=0, nll_loss=0.885, ntokens=1076.2, nsentences=120, sample_size=1076.2, sample_size_v1=0, sample_size_v2=0, ppl=1.85, wps=521.8, ups=0.48, wpb=1076.2, bsz=120, num_updates=11560, lr=2.57078e-05, gnorm=3.788, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=23849
2023-06-27 00:57:06 - progress_bar.py[line:272] - INFO: epoch 004:    445 / 3715 loss=2.101, loss_v1=0, loss_v2=0, nll_loss=0.87, ntokens=1106.3, nsentences=120, sample_size=1106.3, sample_size_v1=0, sample_size_v2=0, ppl=1.83, wps=535.2, ups=0.48, wpb=1106.3, bsz=120, num_updates=11570, lr=2.57025e-05, gnorm=3.78, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=23870
2023-06-27 00:57:26 - progress_bar.py[line:272] - INFO: epoch 004:    455 / 3715 loss=2.108, loss_v1=0, loss_v2=0, nll_loss=0.876, ntokens=1078.9, nsentences=120, sample_size=1078.9, sample_size_v1=0, sample_size_v2=0, ppl=1.84, wps=523.4, ups=0.49, wpb=1078.9, bsz=120, num_updates=11580, lr=2.56971e-05, gnorm=4.152, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=23891
2023-06-27 00:57:47 - progress_bar.py[line:272] - INFO: epoch 004:    465 / 3715 loss=2.104, loss_v1=0, loss_v2=0, nll_loss=0.872, ntokens=1071.9, nsentences=120, sample_size=1071.9, sample_size_v1=0, sample_size_v2=0, ppl=1.83, wps=520.9, ups=0.49, wpb=1071.9, bsz=120, num_updates=11590, lr=2.56917e-05, gnorm=3.867, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=23911
2023-06-27 00:58:07 - progress_bar.py[line:272] - INFO: epoch 004:    475 / 3715 loss=2.11, loss_v1=0, loss_v2=0, nll_loss=0.88, ntokens=1078.8, nsentences=120, sample_size=1078.8, sample_size_v1=0, sample_size_v2=0, ppl=1.84, wps=524.3, ups=0.49, wpb=1078.8, bsz=120, num_updates=11600, lr=2.56864e-05, gnorm=3.899, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=23932
2023-06-27 00:58:28 - progress_bar.py[line:272] - INFO: epoch 004:    485 / 3715 loss=2.104, loss_v1=0, loss_v2=0, nll_loss=0.871, ntokens=1099.3, nsentences=120, sample_size=1099.3, sample_size_v1=0, sample_size_v2=0, ppl=1.83, wps=534.3, ups=0.49, wpb=1099.3, bsz=120, num_updates=11610, lr=2.5681e-05, gnorm=3.768, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=23952
2023-06-27 00:58:48 - progress_bar.py[line:272] - INFO: epoch 004:    495 / 3715 loss=2.108, loss_v1=0, loss_v2=0, nll_loss=0.877, ntokens=1080.3, nsentences=120, sample_size=1080.3, sample_size_v1=0, sample_size_v2=0, ppl=1.84, wps=525.2, ups=0.49, wpb=1080.3, bsz=120, num_updates=11620, lr=2.56756e-05, gnorm=3.914, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=23973
2023-06-27 00:59:09 - progress_bar.py[line:272] - INFO: epoch 004:    505 / 3715 loss=2.119, loss_v1=0, loss_v2=0, nll_loss=0.886, ntokens=1086.1, nsentences=120, sample_size=1086.1, sample_size_v1=0, sample_size_v2=0, ppl=1.85, wps=528.1, ups=0.49, wpb=1086.1, bsz=120, num_updates=11630, lr=2.56703e-05, gnorm=3.778, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=23993
2023-06-27 00:59:30 - progress_bar.py[line:272] - INFO: epoch 004:    515 / 3715 loss=2.098, loss_v1=0, loss_v2=0, nll_loss=0.868, ntokens=1091.1, nsentences=120, sample_size=1091.1, sample_size_v1=0, sample_size_v2=0, ppl=1.82, wps=530.4, ups=0.49, wpb=1091.1, bsz=120, num_updates=11640, lr=2.56649e-05, gnorm=3.831, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=24014
2023-06-27 00:59:42 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 256.0
2023-06-27 00:59:52 - progress_bar.py[line:272] - INFO: epoch 004:    526 / 3715 loss=2.098, loss_v1=0, loss_v2=0, nll_loss=0.864, ntokens=1085.4, nsentences=120, sample_size=1085.4, sample_size_v1=0, sample_size_v2=0, ppl=1.82, wps=480.3, ups=0.44, wpb=1085.4, bsz=120, num_updates=11650, lr=2.56595e-05, gnorm=3.559, clip=100, loss_scale=256, train_wall=23, gb_free=8.9, wall=24037
2023-06-27 01:00:13 - progress_bar.py[line:272] - INFO: epoch 004:    536 / 3715 loss=2.101, loss_v1=0, loss_v2=0, nll_loss=0.869, ntokens=1077.2, nsentences=120, sample_size=1077.2, sample_size_v1=0, sample_size_v2=0, ppl=1.83, wps=523.2, ups=0.49, wpb=1077.2, bsz=120, num_updates=11660, lr=2.56542e-05, gnorm=3.666, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=24057
2023-06-27 01:00:33 - progress_bar.py[line:272] - INFO: epoch 004:    546 / 3715 loss=2.095, loss_v1=0, loss_v2=0, nll_loss=0.864, ntokens=1062.5, nsentences=120, sample_size=1062.5, sample_size_v1=0, sample_size_v2=0, ppl=1.82, wps=516.6, ups=0.49, wpb=1062.5, bsz=120, num_updates=11670, lr=2.56488e-05, gnorm=4.069, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=24078
2023-06-27 01:00:54 - progress_bar.py[line:272] - INFO: epoch 004:    556 / 3715 loss=2.098, loss_v1=0, loss_v2=0, nll_loss=0.864, ntokens=1081.9, nsentences=120, sample_size=1081.9, sample_size_v1=0, sample_size_v2=0, ppl=1.82, wps=525.8, ups=0.49, wpb=1081.9, bsz=120, num_updates=11680, lr=2.56434e-05, gnorm=3.802, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=24098
2023-06-27 01:01:15 - progress_bar.py[line:272] - INFO: epoch 004:    566 / 3715 loss=2.135, loss_v1=0, loss_v2=0, nll_loss=0.907, ntokens=1060.8, nsentences=120, sample_size=1060.8, sample_size_v1=0, sample_size_v2=0, ppl=1.88, wps=516, ups=0.49, wpb=1060.8, bsz=120, num_updates=11690, lr=2.5638e-05, gnorm=3.836, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=24119
2023-06-27 01:01:35 - progress_bar.py[line:272] - INFO: epoch 004:    576 / 3715 loss=2.108, loss_v1=0, loss_v2=0, nll_loss=0.877, ntokens=1091.3, nsentences=120, sample_size=1091.3, sample_size_v1=0, sample_size_v2=0, ppl=1.84, wps=530.6, ups=0.49, wpb=1091.3, bsz=120, num_updates=11700, lr=2.56327e-05, gnorm=3.953, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=24139
2023-06-27 01:01:56 - progress_bar.py[line:272] - INFO: epoch 004:    586 / 3715 loss=2.119, loss_v1=0, loss_v2=0, nll_loss=0.888, ntokens=1064.3, nsentences=120, sample_size=1064.3, sample_size_v1=0, sample_size_v2=0, ppl=1.85, wps=517.5, ups=0.49, wpb=1064.3, bsz=120, num_updates=11710, lr=2.56273e-05, gnorm=4.005, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=24160
2023-06-27 01:02:16 - progress_bar.py[line:272] - INFO: epoch 004:    596 / 3715 loss=2.118, loss_v1=0, loss_v2=0, nll_loss=0.887, ntokens=1082.5, nsentences=120, sample_size=1082.5, sample_size_v1=0, sample_size_v2=0, ppl=1.85, wps=526.8, ups=0.49, wpb=1082.5, bsz=120, num_updates=11720, lr=2.56219e-05, gnorm=3.79, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=24181
2023-06-27 01:02:37 - progress_bar.py[line:272] - INFO: epoch 004:    606 / 3715 loss=2.102, loss_v1=0, loss_v2=0, nll_loss=0.869, ntokens=1108.2, nsentences=120, sample_size=1108.2, sample_size_v1=0, sample_size_v2=0, ppl=1.83, wps=539.1, ups=0.49, wpb=1108.2, bsz=120, num_updates=11730, lr=2.56166e-05, gnorm=3.691, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=24201
2023-06-27 01:02:57 - progress_bar.py[line:272] - INFO: epoch 004:    616 / 3715 loss=2.105, loss_v1=0, loss_v2=0, nll_loss=0.874, ntokens=1076.2, nsentences=120, sample_size=1076.2, sample_size_v1=0, sample_size_v2=0, ppl=1.83, wps=523.2, ups=0.49, wpb=1076.2, bsz=120, num_updates=11740, lr=2.56112e-05, gnorm=3.818, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=24222
2023-06-27 01:03:18 - progress_bar.py[line:272] - INFO: epoch 004:    626 / 3715 loss=2.09, loss_v1=0, loss_v2=0, nll_loss=0.856, ntokens=1074.7, nsentences=120, sample_size=1074.7, sample_size_v1=0, sample_size_v2=0, ppl=1.81, wps=521.9, ups=0.49, wpb=1074.7, bsz=120, num_updates=11750, lr=2.56058e-05, gnorm=3.67, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=24242
2023-06-27 01:03:39 - progress_bar.py[line:272] - INFO: epoch 004:    636 / 3715 loss=2.117, loss_v1=0, loss_v2=0, nll_loss=0.889, ntokens=1075.9, nsentences=120, sample_size=1075.9, sample_size_v1=0, sample_size_v2=0, ppl=1.85, wps=522.6, ups=0.49, wpb=1075.9, bsz=120, num_updates=11760, lr=2.56005e-05, gnorm=3.677, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=24263
2023-06-27 01:03:59 - progress_bar.py[line:272] - INFO: epoch 004:    646 / 3715 loss=2.127, loss_v1=0, loss_v2=0, nll_loss=0.897, ntokens=1077.9, nsentences=120, sample_size=1077.9, sample_size_v1=0, sample_size_v2=0, ppl=1.86, wps=524.1, ups=0.49, wpb=1077.9, bsz=120, num_updates=11770, lr=2.55951e-05, gnorm=3.731, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=24283
2023-06-27 01:04:20 - progress_bar.py[line:272] - INFO: epoch 004:    656 / 3715 loss=2.079, loss_v1=0, loss_v2=0, nll_loss=0.844, ntokens=1069.5, nsentences=120, sample_size=1069.5, sample_size_v1=0, sample_size_v2=0, ppl=1.8, wps=519.9, ups=0.49, wpb=1069.5, bsz=120, num_updates=11780, lr=2.55897e-05, gnorm=3.672, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=24304
2023-06-27 01:04:40 - progress_bar.py[line:272] - INFO: epoch 004:    666 / 3715 loss=2.098, loss_v1=0, loss_v2=0, nll_loss=0.863, ntokens=1078, nsentences=120, sample_size=1078, sample_size_v1=0, sample_size_v2=0, ppl=1.82, wps=524.3, ups=0.49, wpb=1078, bsz=120, num_updates=11790, lr=2.55844e-05, gnorm=3.835, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=24325
2023-06-27 01:05:01 - progress_bar.py[line:272] - INFO: epoch 004:    676 / 3715 loss=2.108, loss_v1=0, loss_v2=0, nll_loss=0.876, ntokens=1080.1, nsentences=120, sample_size=1080.1, sample_size_v1=0, sample_size_v2=0, ppl=1.84, wps=524.7, ups=0.49, wpb=1080.1, bsz=120, num_updates=11800, lr=2.5579e-05, gnorm=3.963, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=24345
2023-06-27 01:05:21 - progress_bar.py[line:272] - INFO: epoch 004:    686 / 3715 loss=2.097, loss_v1=0, loss_v2=0, nll_loss=0.864, ntokens=1072.1, nsentences=120, sample_size=1072.1, sample_size_v1=0, sample_size_v2=0, ppl=1.82, wps=520.6, ups=0.49, wpb=1072.1, bsz=120, num_updates=11810, lr=2.55736e-05, gnorm=3.707, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=24366
2023-06-27 01:05:42 - progress_bar.py[line:272] - INFO: epoch 004:    696 / 3715 loss=2.1, loss_v1=0, loss_v2=0, nll_loss=0.866, ntokens=1062.2, nsentences=120, sample_size=1062.2, sample_size_v1=0, sample_size_v2=0, ppl=1.82, wps=515.6, ups=0.49, wpb=1062.2, bsz=120, num_updates=11820, lr=2.55682e-05, gnorm=3.708, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=24386
2023-06-27 01:06:03 - progress_bar.py[line:272] - INFO: epoch 004:    706 / 3715 loss=2.121, loss_v1=0, loss_v2=0, nll_loss=0.89, ntokens=1101.4, nsentences=120, sample_size=1101.4, sample_size_v1=0, sample_size_v2=0, ppl=1.85, wps=534.5, ups=0.49, wpb=1101.4, bsz=120, num_updates=11830, lr=2.55629e-05, gnorm=4.008, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=24407
2023-06-27 01:06:23 - progress_bar.py[line:272] - INFO: epoch 004:    716 / 3715 loss=2.089, loss_v1=0, loss_v2=0, nll_loss=0.855, ntokens=1090.4, nsentences=120, sample_size=1090.4, sample_size_v1=0, sample_size_v2=0, ppl=1.81, wps=529.3, ups=0.49, wpb=1090.4, bsz=120, num_updates=11840, lr=2.55575e-05, gnorm=3.873, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=24428
2023-06-27 01:06:44 - progress_bar.py[line:272] - INFO: epoch 004:    726 / 3715 loss=2.09, loss_v1=0, loss_v2=0, nll_loss=0.855, ntokens=1072.2, nsentences=120, sample_size=1072.2, sample_size_v1=0, sample_size_v2=0, ppl=1.81, wps=520.1, ups=0.49, wpb=1072.2, bsz=120, num_updates=11850, lr=2.55521e-05, gnorm=3.699, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=24448
2023-06-27 01:07:04 - progress_bar.py[line:272] - INFO: epoch 004:    736 / 3715 loss=2.109, loss_v1=0, loss_v2=0, nll_loss=0.879, ntokens=1088.7, nsentences=120, sample_size=1088.7, sample_size_v1=0, sample_size_v2=0, ppl=1.84, wps=528.9, ups=0.49, wpb=1088.7, bsz=120, num_updates=11860, lr=2.55468e-05, gnorm=3.859, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=24469
2023-06-27 01:07:25 - progress_bar.py[line:272] - INFO: epoch 004:    746 / 3715 loss=2.084, loss_v1=0, loss_v2=0, nll_loss=0.85, ntokens=1069.4, nsentences=120, sample_size=1069.4, sample_size_v1=0, sample_size_v2=0, ppl=1.8, wps=520.1, ups=0.49, wpb=1069.4, bsz=120, num_updates=11870, lr=2.55414e-05, gnorm=3.648, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=24489
2023-06-27 01:07:46 - progress_bar.py[line:272] - INFO: epoch 004:    756 / 3715 loss=2.109, loss_v1=0, loss_v2=0, nll_loss=0.877, ntokens=1102.7, nsentences=120, sample_size=1102.7, sample_size_v1=0, sample_size_v2=0, ppl=1.84, wps=535.1, ups=0.49, wpb=1102.7, bsz=120, num_updates=11880, lr=2.5536e-05, gnorm=3.994, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=24510
2023-06-27 01:08:06 - progress_bar.py[line:272] - INFO: epoch 004:    766 / 3715 loss=2.095, loss_v1=0, loss_v2=0, nll_loss=0.863, ntokens=1074.5, nsentences=120, sample_size=1074.5, sample_size_v1=0, sample_size_v2=0, ppl=1.82, wps=521.9, ups=0.49, wpb=1074.5, bsz=120, num_updates=11890, lr=2.55307e-05, gnorm=4.181, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=24531
2023-06-27 01:08:27 - progress_bar.py[line:272] - INFO: epoch 004:    776 / 3715 loss=2.086, loss_v1=0, loss_v2=0, nll_loss=0.851, ntokens=1056.4, nsentences=120, sample_size=1056.4, sample_size_v1=0, sample_size_v2=0, ppl=1.8, wps=512.9, ups=0.49, wpb=1056.4, bsz=120, num_updates=11900, lr=2.55253e-05, gnorm=3.804, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=24551
2023-06-27 01:08:47 - progress_bar.py[line:272] - INFO: epoch 004:    786 / 3715 loss=2.1, loss_v1=0, loss_v2=0, nll_loss=0.867, ntokens=1082.5, nsentences=120, sample_size=1082.5, sample_size_v1=0, sample_size_v2=0, ppl=1.82, wps=525.7, ups=0.49, wpb=1082.5, bsz=120, num_updates=11910, lr=2.55199e-05, gnorm=3.723, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=24572
2023-06-27 01:09:08 - progress_bar.py[line:272] - INFO: epoch 004:    796 / 3715 loss=2.095, loss_v1=0, loss_v2=0, nll_loss=0.863, ntokens=1082.6, nsentences=120, sample_size=1082.6, sample_size_v1=0, sample_size_v2=0, ppl=1.82, wps=524.8, ups=0.48, wpb=1082.6, bsz=120, num_updates=11920, lr=2.55146e-05, gnorm=3.697, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=24592
2023-06-27 01:09:29 - progress_bar.py[line:272] - INFO: epoch 004:    806 / 3715 loss=2.086, loss_v1=0, loss_v2=0, nll_loss=0.852, ntokens=1084.8, nsentences=120, sample_size=1084.8, sample_size_v1=0, sample_size_v2=0, ppl=1.81, wps=527.8, ups=0.49, wpb=1084.8, bsz=120, num_updates=11930, lr=2.55092e-05, gnorm=3.791, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=24613
2023-06-27 01:09:49 - progress_bar.py[line:272] - INFO: epoch 004:    816 / 3715 loss=2.099, loss_v1=0, loss_v2=0, nll_loss=0.866, ntokens=1108.9, nsentences=120, sample_size=1108.9, sample_size_v1=0, sample_size_v2=0, ppl=1.82, wps=538.9, ups=0.49, wpb=1108.9, bsz=120, num_updates=11940, lr=2.55038e-05, gnorm=4.012, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=24634
2023-06-27 01:10:10 - progress_bar.py[line:272] - INFO: epoch 004:    826 / 3715 loss=2.091, loss_v1=0, loss_v2=0, nll_loss=0.857, ntokens=1100.3, nsentences=120, sample_size=1100.3, sample_size_v1=0, sample_size_v2=0, ppl=1.81, wps=533.8, ups=0.49, wpb=1100.3, bsz=120, num_updates=11950, lr=2.54984e-05, gnorm=3.881, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=24654
2023-06-27 01:10:30 - progress_bar.py[line:272] - INFO: epoch 004:    836 / 3715 loss=2.11, loss_v1=0, loss_v2=0, nll_loss=0.877, ntokens=1103.6, nsentences=120, sample_size=1103.6, sample_size_v1=0, sample_size_v2=0, ppl=1.84, wps=535.4, ups=0.49, wpb=1103.6, bsz=120, num_updates=11960, lr=2.54931e-05, gnorm=3.745, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=24675
2023-06-27 01:10:51 - progress_bar.py[line:272] - INFO: epoch 004:    846 / 3715 loss=2.095, loss_v1=0, loss_v2=0, nll_loss=0.863, ntokens=1078.9, nsentences=120, sample_size=1078.9, sample_size_v1=0, sample_size_v2=0, ppl=1.82, wps=523.7, ups=0.49, wpb=1078.9, bsz=120, num_updates=11970, lr=2.54877e-05, gnorm=4.018, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=24695
2023-06-27 01:11:12 - progress_bar.py[line:272] - INFO: epoch 004:    856 / 3715 loss=2.095, loss_v1=0, loss_v2=0, nll_loss=0.86, ntokens=1096.7, nsentences=120, sample_size=1096.7, sample_size_v1=0, sample_size_v2=0, ppl=1.82, wps=532.9, ups=0.49, wpb=1096.7, bsz=120, num_updates=11980, lr=2.54823e-05, gnorm=3.715, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=24716
2023-06-27 01:11:32 - progress_bar.py[line:272] - INFO: epoch 004:    866 / 3715 loss=2.096, loss_v1=0, loss_v2=0, nll_loss=0.864, ntokens=1086.4, nsentences=120, sample_size=1086.4, sample_size_v1=0, sample_size_v2=0, ppl=1.82, wps=527.3, ups=0.49, wpb=1086.4, bsz=120, num_updates=11990, lr=2.5477e-05, gnorm=3.854, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=24737
2023-06-27 01:11:53 - progress_bar.py[line:272] - INFO: epoch 004:    876 / 3715 loss=2.108, loss_v1=0, loss_v2=0, nll_loss=0.876, ntokens=1060.6, nsentences=120, sample_size=1060.6, sample_size_v1=0, sample_size_v2=0, ppl=1.84, wps=514.8, ups=0.49, wpb=1060.6, bsz=120, num_updates=12000, lr=2.54716e-05, gnorm=3.9, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=24757
2023-06-27 01:12:13 - progress_bar.py[line:272] - INFO: epoch 004:    886 / 3715 loss=2.118, loss_v1=0, loss_v2=0, nll_loss=0.887, ntokens=1088.3, nsentences=120, sample_size=1088.3, sample_size_v1=0, sample_size_v2=0, ppl=1.85, wps=528.8, ups=0.49, wpb=1088.3, bsz=120, num_updates=12010, lr=2.54662e-05, gnorm=3.932, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=24778
2023-06-27 01:12:34 - progress_bar.py[line:272] - INFO: epoch 004:    896 / 3715 loss=2.097, loss_v1=0, loss_v2=0, nll_loss=0.863, ntokens=1080.4, nsentences=120, sample_size=1080.4, sample_size_v1=0, sample_size_v2=0, ppl=1.82, wps=524.8, ups=0.49, wpb=1080.4, bsz=120, num_updates=12020, lr=2.54609e-05, gnorm=3.737, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=24798
2023-06-27 01:12:55 - progress_bar.py[line:272] - INFO: epoch 004:    906 / 3715 loss=2.084, loss_v1=0, loss_v2=0, nll_loss=0.848, ntokens=1065.8, nsentences=120, sample_size=1065.8, sample_size_v1=0, sample_size_v2=0, ppl=1.8, wps=516.9, ups=0.48, wpb=1065.8, bsz=120, num_updates=12030, lr=2.54555e-05, gnorm=3.823, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=24819
2023-06-27 01:13:15 - progress_bar.py[line:272] - INFO: epoch 004:    916 / 3715 loss=2.115, loss_v1=0, loss_v2=0, nll_loss=0.885, ntokens=1093.5, nsentences=120, sample_size=1093.5, sample_size_v1=0, sample_size_v2=0, ppl=1.85, wps=531.1, ups=0.49, wpb=1093.5, bsz=120, num_updates=12040, lr=2.54501e-05, gnorm=3.832, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=24840
2023-06-27 01:13:36 - progress_bar.py[line:272] - INFO: epoch 004:    926 / 3715 loss=2.105, loss_v1=0, loss_v2=0, nll_loss=0.874, ntokens=1069.2, nsentences=120, sample_size=1069.2, sample_size_v1=0, sample_size_v2=0, ppl=1.83, wps=518.8, ups=0.49, wpb=1069.2, bsz=120, num_updates=12050, lr=2.54448e-05, gnorm=4.236, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=24860
2023-06-27 01:13:56 - progress_bar.py[line:272] - INFO: epoch 004:    936 / 3715 loss=2.092, loss_v1=0, loss_v2=0, nll_loss=0.858, ntokens=1074.7, nsentences=120, sample_size=1074.7, sample_size_v1=0, sample_size_v2=0, ppl=1.81, wps=521.9, ups=0.49, wpb=1074.7, bsz=120, num_updates=12060, lr=2.54394e-05, gnorm=4.273, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=24881
2023-06-27 01:14:17 - progress_bar.py[line:272] - INFO: epoch 004:    946 / 3715 loss=2.092, loss_v1=0, loss_v2=0, nll_loss=0.858, ntokens=1092.6, nsentences=120, sample_size=1092.6, sample_size_v1=0, sample_size_v2=0, ppl=1.81, wps=530.4, ups=0.49, wpb=1092.6, bsz=120, num_updates=12070, lr=2.5434e-05, gnorm=3.823, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=24901
2023-06-27 01:14:38 - progress_bar.py[line:272] - INFO: epoch 004:    956 / 3715 loss=2.087, loss_v1=0, loss_v2=0, nll_loss=0.852, ntokens=1086.3, nsentences=120, sample_size=1086.3, sample_size_v1=0, sample_size_v2=0, ppl=1.81, wps=527.4, ups=0.49, wpb=1086.3, bsz=120, num_updates=12080, lr=2.54286e-05, gnorm=4.146, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=24922
2023-06-27 01:14:58 - progress_bar.py[line:272] - INFO: epoch 004:    966 / 3715 loss=2.107, loss_v1=0, loss_v2=0, nll_loss=0.875, ntokens=1090.6, nsentences=120, sample_size=1090.6, sample_size_v1=0, sample_size_v2=0, ppl=1.83, wps=529.6, ups=0.49, wpb=1090.6, bsz=120, num_updates=12090, lr=2.54233e-05, gnorm=3.989, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=24943
2023-06-27 01:15:19 - progress_bar.py[line:272] - INFO: epoch 004:    976 / 3715 loss=2.1, loss_v1=0, loss_v2=0, nll_loss=0.868, ntokens=1077.2, nsentences=120, sample_size=1077.2, sample_size_v1=0, sample_size_v2=0, ppl=1.83, wps=523.5, ups=0.49, wpb=1077.2, bsz=120, num_updates=12100, lr=2.54179e-05, gnorm=3.873, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=24963
2023-06-27 01:15:39 - progress_bar.py[line:272] - INFO: epoch 004:    986 / 3715 loss=2.1, loss_v1=0, loss_v2=0, nll_loss=0.867, ntokens=1083.8, nsentences=120, sample_size=1083.8, sample_size_v1=0, sample_size_v2=0, ppl=1.82, wps=526.9, ups=0.49, wpb=1083.8, bsz=120, num_updates=12110, lr=2.54125e-05, gnorm=3.972, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=24984
2023-06-27 01:16:00 - progress_bar.py[line:272] - INFO: epoch 004:    996 / 3715 loss=2.095, loss_v1=0, loss_v2=0, nll_loss=0.862, ntokens=1088.1, nsentences=120, sample_size=1088.1, sample_size_v1=0, sample_size_v2=0, ppl=1.82, wps=528.6, ups=0.49, wpb=1088.1, bsz=120, num_updates=12120, lr=2.54072e-05, gnorm=3.895, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=25004
2023-06-27 01:16:21 - progress_bar.py[line:272] - INFO: epoch 004:   1006 / 3715 loss=2.079, loss_v1=0, loss_v2=0, nll_loss=0.843, ntokens=1082.9, nsentences=120, sample_size=1082.9, sample_size_v1=0, sample_size_v2=0, ppl=1.79, wps=525.5, ups=0.49, wpb=1082.9, bsz=120, num_updates=12130, lr=2.54018e-05, gnorm=3.894, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=25025
2023-06-27 01:16:41 - progress_bar.py[line:272] - INFO: epoch 004:   1016 / 3715 loss=2.082, loss_v1=0, loss_v2=0, nll_loss=0.848, ntokens=1076.7, nsentences=120, sample_size=1076.7, sample_size_v1=0, sample_size_v2=0, ppl=1.8, wps=522.6, ups=0.49, wpb=1076.7, bsz=120, num_updates=12140, lr=2.53964e-05, gnorm=4.33, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=25046
2023-06-27 01:17:02 - progress_bar.py[line:272] - INFO: epoch 004:   1026 / 3715 loss=2.083, loss_v1=0, loss_v2=0, nll_loss=0.85, ntokens=1075, nsentences=120, sample_size=1075, sample_size_v1=0, sample_size_v2=0, ppl=1.8, wps=521.4, ups=0.49, wpb=1075, bsz=120, num_updates=12150, lr=2.53911e-05, gnorm=4.344, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=25066
2023-06-27 01:17:18 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 256.0
2023-06-27 01:17:24 - progress_bar.py[line:272] - INFO: epoch 004:   1037 / 3715 loss=2.105, loss_v1=0, loss_v2=0, nll_loss=0.873, ntokens=1073.6, nsentences=120, sample_size=1073.6, sample_size_v1=0, sample_size_v2=0, ppl=1.83, wps=474.3, ups=0.44, wpb=1073.6, bsz=120, num_updates=12160, lr=2.53857e-05, gnorm=4.206, clip=100, loss_scale=256, train_wall=23, gb_free=8.9, wall=25089
2023-06-27 01:17:45 - progress_bar.py[line:272] - INFO: epoch 004:   1047 / 3715 loss=2.102, loss_v1=0, loss_v2=0, nll_loss=0.869, ntokens=1075.4, nsentences=120, sample_size=1075.4, sample_size_v1=0, sample_size_v2=0, ppl=1.83, wps=522.4, ups=0.49, wpb=1075.4, bsz=120, num_updates=12170, lr=2.53803e-05, gnorm=4.143, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=25109
2023-06-27 01:18:04 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 128.0
2023-06-27 01:18:08 - progress_bar.py[line:272] - INFO: epoch 004:   1058 / 3715 loss=2.084, loss_v1=0, loss_v2=0, nll_loss=0.85, ntokens=1079.6, nsentences=120, sample_size=1079.6, sample_size_v1=0, sample_size_v2=0, ppl=1.8, wps=476.4, ups=0.44, wpb=1079.6, bsz=120, num_updates=12180, lr=2.5375e-05, gnorm=3.912, clip=100, loss_scale=128, train_wall=23, gb_free=8.9, wall=25132
2023-06-27 01:18:28 - progress_bar.py[line:272] - INFO: epoch 004:   1068 / 3715 loss=2.108, loss_v1=0, loss_v2=0, nll_loss=0.878, ntokens=1091, nsentences=120, sample_size=1091, sample_size_v1=0, sample_size_v2=0, ppl=1.84, wps=529.3, ups=0.49, wpb=1091, bsz=120, num_updates=12190, lr=2.53696e-05, gnorm=4.026, clip=100, loss_scale=128, train_wall=21, gb_free=8.9, wall=25153
2023-06-27 01:18:49 - progress_bar.py[line:272] - INFO: epoch 004:   1078 / 3715 loss=2.072, loss_v1=0, loss_v2=0, nll_loss=0.835, ntokens=1091.4, nsentences=120, sample_size=1091.4, sample_size_v1=0, sample_size_v2=0, ppl=1.78, wps=529.7, ups=0.49, wpb=1091.4, bsz=120, num_updates=12200, lr=2.53642e-05, gnorm=3.775, clip=100, loss_scale=128, train_wall=21, gb_free=8.9, wall=25173
2023-06-27 01:19:10 - progress_bar.py[line:272] - INFO: epoch 004:   1088 / 3715 loss=2.064, loss_v1=0, loss_v2=0, nll_loss=0.829, ntokens=1091.3, nsentences=120, sample_size=1091.3, sample_size_v1=0, sample_size_v2=0, ppl=1.78, wps=529.7, ups=0.49, wpb=1091.3, bsz=120, num_updates=12210, lr=2.53588e-05, gnorm=3.948, clip=100, loss_scale=128, train_wall=21, gb_free=8.9, wall=25194
2023-06-27 01:19:30 - progress_bar.py[line:272] - INFO: epoch 004:   1098 / 3715 loss=2.08, loss_v1=0, loss_v2=0, nll_loss=0.845, ntokens=1047.3, nsentences=120, sample_size=1047.3, sample_size_v1=0, sample_size_v2=0, ppl=1.8, wps=508.6, ups=0.49, wpb=1047.3, bsz=120, num_updates=12220, lr=2.53535e-05, gnorm=3.897, clip=100, loss_scale=128, train_wall=21, gb_free=8.9, wall=25214
2023-06-27 01:19:51 - progress_bar.py[line:272] - INFO: epoch 004:   1108 / 3715 loss=2.09, loss_v1=0, loss_v2=0, nll_loss=0.856, ntokens=1069.6, nsentences=120, sample_size=1069.6, sample_size_v1=0, sample_size_v2=0, ppl=1.81, wps=519.2, ups=0.49, wpb=1069.6, bsz=120, num_updates=12230, lr=2.53481e-05, gnorm=3.972, clip=100, loss_scale=128, train_wall=21, gb_free=8.9, wall=25235
2023-06-27 01:20:11 - progress_bar.py[line:272] - INFO: epoch 004:   1118 / 3715 loss=2.111, loss_v1=0, loss_v2=0, nll_loss=0.88, ntokens=1093.9, nsentences=120, sample_size=1093.9, sample_size_v1=0, sample_size_v2=0, ppl=1.84, wps=530.7, ups=0.49, wpb=1093.9, bsz=120, num_updates=12240, lr=2.53427e-05, gnorm=3.938, clip=100, loss_scale=128, train_wall=21, gb_free=8.9, wall=25256
2023-06-27 01:20:32 - progress_bar.py[line:272] - INFO: epoch 004:   1128 / 3715 loss=2.081, loss_v1=0, loss_v2=0, nll_loss=0.846, ntokens=1074.7, nsentences=120, sample_size=1074.7, sample_size_v1=0, sample_size_v2=0, ppl=1.8, wps=521.8, ups=0.49, wpb=1074.7, bsz=120, num_updates=12250, lr=2.53374e-05, gnorm=3.939, clip=100, loss_scale=128, train_wall=21, gb_free=8.9, wall=25276
2023-06-27 01:20:53 - progress_bar.py[line:272] - INFO: epoch 004:   1138 / 3715 loss=2.106, loss_v1=0, loss_v2=0, nll_loss=0.873, ntokens=1102.6, nsentences=120, sample_size=1102.6, sample_size_v1=0, sample_size_v2=0, ppl=1.83, wps=534.8, ups=0.49, wpb=1102.6, bsz=120, num_updates=12260, lr=2.5332e-05, gnorm=3.77, clip=100, loss_scale=128, train_wall=21, gb_free=8.9, wall=25297
2023-06-27 01:21:13 - progress_bar.py[line:272] - INFO: epoch 004:   1148 / 3715 loss=2.08, loss_v1=0, loss_v2=0, nll_loss=0.845, ntokens=1099, nsentences=120, sample_size=1099, sample_size_v1=0, sample_size_v2=0, ppl=1.8, wps=533.2, ups=0.49, wpb=1099, bsz=120, num_updates=12270, lr=2.53266e-05, gnorm=3.939, clip=100, loss_scale=128, train_wall=21, gb_free=8.9, wall=25318
2023-06-27 01:21:34 - progress_bar.py[line:272] - INFO: epoch 004:   1158 / 3715 loss=2.078, loss_v1=0, loss_v2=0, nll_loss=0.842, ntokens=1070.2, nsentences=120, sample_size=1070.2, sample_size_v1=0, sample_size_v2=0, ppl=1.79, wps=518.7, ups=0.48, wpb=1070.2, bsz=120, num_updates=12280, lr=2.53213e-05, gnorm=3.943, clip=100, loss_scale=128, train_wall=21, gb_free=8.9, wall=25338
2023-06-27 01:21:54 - progress_bar.py[line:272] - INFO: epoch 004:   1168 / 3715 loss=2.083, loss_v1=0, loss_v2=0, nll_loss=0.848, ntokens=1088.8, nsentences=120, sample_size=1088.8, sample_size_v1=0, sample_size_v2=0, ppl=1.8, wps=527.6, ups=0.48, wpb=1088.8, bsz=120, num_updates=12290, lr=2.53159e-05, gnorm=3.855, clip=100, loss_scale=128, train_wall=21, gb_free=8.9, wall=25359
2023-06-27 01:22:15 - progress_bar.py[line:272] - INFO: epoch 004:   1178 / 3715 loss=2.112, loss_v1=0, loss_v2=0, nll_loss=0.881, ntokens=1094.9, nsentences=120, sample_size=1094.9, sample_size_v1=0, sample_size_v2=0, ppl=1.84, wps=530.8, ups=0.48, wpb=1094.9, bsz=120, num_updates=12300, lr=2.53105e-05, gnorm=3.793, clip=100, loss_scale=128, train_wall=21, gb_free=8.9, wall=25379
2023-06-27 01:22:36 - progress_bar.py[line:272] - INFO: epoch 004:   1188 / 3715 loss=2.108, loss_v1=0, loss_v2=0, nll_loss=0.877, ntokens=1091.7, nsentences=120, sample_size=1091.7, sample_size_v1=0, sample_size_v2=0, ppl=1.84, wps=529.3, ups=0.48, wpb=1091.7, bsz=120, num_updates=12310, lr=2.53052e-05, gnorm=3.891, clip=100, loss_scale=128, train_wall=21, gb_free=8.9, wall=25400
2023-06-27 01:22:56 - progress_bar.py[line:272] - INFO: epoch 004:   1198 / 3715 loss=2.089, loss_v1=0, loss_v2=0, nll_loss=0.857, ntokens=1088.5, nsentences=120, sample_size=1088.5, sample_size_v1=0, sample_size_v2=0, ppl=1.81, wps=528.6, ups=0.49, wpb=1088.5, bsz=120, num_updates=12320, lr=2.52998e-05, gnorm=4.041, clip=100, loss_scale=128, train_wall=21, gb_free=8.9, wall=25421
2023-06-27 01:23:17 - progress_bar.py[line:272] - INFO: epoch 004:   1208 / 3715 loss=2.084, loss_v1=0, loss_v2=0, nll_loss=0.848, ntokens=1062.1, nsentences=120, sample_size=1062.1, sample_size_v1=0, sample_size_v2=0, ppl=1.8, wps=515.8, ups=0.49, wpb=1062.1, bsz=120, num_updates=12330, lr=2.52944e-05, gnorm=3.922, clip=100, loss_scale=128, train_wall=21, gb_free=8.9, wall=25441
2023-06-27 01:23:38 - progress_bar.py[line:272] - INFO: epoch 004:   1218 / 3715 loss=2.09, loss_v1=0, loss_v2=0, nll_loss=0.856, ntokens=1090.3, nsentences=120, sample_size=1090.3, sample_size_v1=0, sample_size_v2=0, ppl=1.81, wps=528.5, ups=0.48, wpb=1090.3, bsz=120, num_updates=12340, lr=2.5289e-05, gnorm=3.802, clip=100, loss_scale=128, train_wall=21, gb_free=8.9, wall=25462
2023-06-27 01:23:58 - progress_bar.py[line:272] - INFO: epoch 004:   1228 / 3715 loss=2.101, loss_v1=0, loss_v2=0, nll_loss=0.868, ntokens=1089.2, nsentences=120, sample_size=1089.2, sample_size_v1=0, sample_size_v2=0, ppl=1.82, wps=528.7, ups=0.49, wpb=1089.2, bsz=120, num_updates=12350, lr=2.52837e-05, gnorm=4.038, clip=100, loss_scale=128, train_wall=21, gb_free=8.9, wall=25483
2023-06-27 01:24:19 - progress_bar.py[line:272] - INFO: epoch 004:   1238 / 3715 loss=2.07, loss_v1=0, loss_v2=0, nll_loss=0.834, ntokens=1074.4, nsentences=120, sample_size=1074.4, sample_size_v1=0, sample_size_v2=0, ppl=1.78, wps=521.6, ups=0.49, wpb=1074.4, bsz=120, num_updates=12360, lr=2.52783e-05, gnorm=3.983, clip=100, loss_scale=128, train_wall=21, gb_free=8.9, wall=25503
2023-06-27 01:24:39 - progress_bar.py[line:272] - INFO: epoch 004:   1248 / 3715 loss=2.065, loss_v1=0, loss_v2=0, nll_loss=0.828, ntokens=1074, nsentences=120, sample_size=1074, sample_size_v1=0, sample_size_v2=0, ppl=1.77, wps=521.9, ups=0.49, wpb=1074, bsz=120, num_updates=12370, lr=2.52729e-05, gnorm=3.792, clip=100, loss_scale=128, train_wall=21, gb_free=8.9, wall=25524
2023-06-27 01:25:00 - progress_bar.py[line:272] - INFO: epoch 004:   1258 / 3715 loss=2.09, loss_v1=0, loss_v2=0, nll_loss=0.856, ntokens=1078.2, nsentences=120, sample_size=1078.2, sample_size_v1=0, sample_size_v2=0, ppl=1.81, wps=523.6, ups=0.49, wpb=1078.2, bsz=120, num_updates=12380, lr=2.52676e-05, gnorm=4.031, clip=100, loss_scale=128, train_wall=21, gb_free=8.9, wall=25544
2023-06-27 01:25:21 - progress_bar.py[line:272] - INFO: epoch 004:   1268 / 3715 loss=2.087, loss_v1=0, loss_v2=0, nll_loss=0.853, ntokens=1077.5, nsentences=120, sample_size=1077.5, sample_size_v1=0, sample_size_v2=0, ppl=1.81, wps=523.3, ups=0.49, wpb=1077.5, bsz=120, num_updates=12390, lr=2.52622e-05, gnorm=3.781, clip=100, loss_scale=128, train_wall=21, gb_free=8.9, wall=25565
2023-06-27 01:25:41 - progress_bar.py[line:272] - INFO: epoch 004:   1278 / 3715 loss=2.063, loss_v1=0, loss_v2=0, nll_loss=0.826, ntokens=1088.7, nsentences=120, sample_size=1088.7, sample_size_v1=0, sample_size_v2=0, ppl=1.77, wps=528.7, ups=0.49, wpb=1088.7, bsz=120, num_updates=12400, lr=2.52568e-05, gnorm=3.715, clip=100, loss_scale=128, train_wall=21, gb_free=8.9, wall=25585
2023-06-27 01:26:02 - progress_bar.py[line:272] - INFO: epoch 004:   1288 / 3715 loss=2.088, loss_v1=0, loss_v2=0, nll_loss=0.854, ntokens=1081.6, nsentences=120, sample_size=1081.6, sample_size_v1=0, sample_size_v2=0, ppl=1.81, wps=524.6, ups=0.49, wpb=1081.6, bsz=120, num_updates=12410, lr=2.52515e-05, gnorm=3.849, clip=100, loss_scale=128, train_wall=21, gb_free=8.9, wall=25606
2023-06-27 01:26:22 - progress_bar.py[line:272] - INFO: epoch 004:   1298 / 3715 loss=2.084, loss_v1=0, loss_v2=0, nll_loss=0.849, ntokens=1084.9, nsentences=120, sample_size=1084.9, sample_size_v1=0, sample_size_v2=0, ppl=1.8, wps=526.3, ups=0.49, wpb=1084.9, bsz=120, num_updates=12420, lr=2.52461e-05, gnorm=4.155, clip=100, loss_scale=128, train_wall=21, gb_free=8.9, wall=25627
2023-06-27 01:26:43 - progress_bar.py[line:272] - INFO: epoch 004:   1308 / 3715 loss=2.086, loss_v1=0, loss_v2=0, nll_loss=0.851, ntokens=1068.2, nsentences=120, sample_size=1068.2, sample_size_v1=0, sample_size_v2=0, ppl=1.8, wps=518.5, ups=0.49, wpb=1068.2, bsz=120, num_updates=12430, lr=2.52407e-05, gnorm=4.045, clip=100, loss_scale=128, train_wall=21, gb_free=8.9, wall=25647
2023-06-27 01:27:04 - progress_bar.py[line:272] - INFO: epoch 004:   1318 / 3715 loss=2.073, loss_v1=0, loss_v2=0, nll_loss=0.839, ntokens=1093.9, nsentences=120, sample_size=1093.9, sample_size_v1=0, sample_size_v2=0, ppl=1.79, wps=530.5, ups=0.48, wpb=1093.9, bsz=120, num_updates=12440, lr=2.52354e-05, gnorm=3.783, clip=100, loss_scale=128, train_wall=21, gb_free=8.9, wall=25668
2023-06-27 01:27:24 - progress_bar.py[line:272] - INFO: epoch 004:   1328 / 3715 loss=2.073, loss_v1=0, loss_v2=0, nll_loss=0.836, ntokens=1066.8, nsentences=120, sample_size=1066.8, sample_size_v1=0, sample_size_v2=0, ppl=1.79, wps=517.8, ups=0.49, wpb=1066.8, bsz=120, num_updates=12450, lr=2.523e-05, gnorm=3.974, clip=100, loss_scale=128, train_wall=21, gb_free=8.9, wall=25689
2023-06-27 01:27:45 - progress_bar.py[line:272] - INFO: epoch 004:   1338 / 3715 loss=2.09, loss_v1=0, loss_v2=0, nll_loss=0.856, ntokens=1084.1, nsentences=120, sample_size=1084.1, sample_size_v1=0, sample_size_v2=0, ppl=1.81, wps=526, ups=0.49, wpb=1084.1, bsz=120, num_updates=12460, lr=2.52246e-05, gnorm=3.876, clip=100, loss_scale=128, train_wall=21, gb_free=8.9, wall=25709
2023-06-27 01:28:05 - progress_bar.py[line:272] - INFO: epoch 004:   1348 / 3715 loss=2.081, loss_v1=0, loss_v2=0, nll_loss=0.847, ntokens=1080.5, nsentences=120, sample_size=1080.5, sample_size_v1=0, sample_size_v2=0, ppl=1.8, wps=524, ups=0.48, wpb=1080.5, bsz=120, num_updates=12470, lr=2.52192e-05, gnorm=3.758, clip=100, loss_scale=128, train_wall=21, gb_free=8.9, wall=25730
2023-06-27 01:28:26 - progress_bar.py[line:272] - INFO: epoch 004:   1358 / 3715 loss=2.085, loss_v1=0, loss_v2=0, nll_loss=0.85, ntokens=1108.9, nsentences=120, sample_size=1108.9, sample_size_v1=0, sample_size_v2=0, ppl=1.8, wps=537.9, ups=0.49, wpb=1108.9, bsz=120, num_updates=12480, lr=2.52139e-05, gnorm=3.912, clip=100, loss_scale=128, train_wall=21, gb_free=8.9, wall=25750
2023-06-27 01:28:47 - progress_bar.py[line:272] - INFO: epoch 004:   1368 / 3715 loss=2.084, loss_v1=0, loss_v2=0, nll_loss=0.848, ntokens=1069.1, nsentences=120, sample_size=1069.1, sample_size_v1=0, sample_size_v2=0, ppl=1.8, wps=518.5, ups=0.49, wpb=1069.1, bsz=120, num_updates=12490, lr=2.52085e-05, gnorm=4.136, clip=100, loss_scale=128, train_wall=21, gb_free=8.9, wall=25771
2023-06-27 01:29:07 - progress_bar.py[line:272] - INFO: epoch 004:   1378 / 3715 loss=2.072, loss_v1=0, loss_v2=0, nll_loss=0.838, ntokens=1075.9, nsentences=120, sample_size=1075.9, sample_size_v1=0, sample_size_v2=0, ppl=1.79, wps=522.1, ups=0.49, wpb=1075.9, bsz=120, num_updates=12500, lr=2.52031e-05, gnorm=3.884, clip=100, loss_scale=128, train_wall=21, gb_free=8.9, wall=25792
2023-06-27 01:29:28 - progress_bar.py[line:272] - INFO: epoch 004:   1388 / 3715 loss=2.1, loss_v1=0, loss_v2=0, nll_loss=0.867, ntokens=1076.6, nsentences=120, sample_size=1076.6, sample_size_v1=0, sample_size_v2=0, ppl=1.82, wps=522.6, ups=0.49, wpb=1076.6, bsz=120, num_updates=12510, lr=2.51978e-05, gnorm=4.107, clip=100, loss_scale=128, train_wall=21, gb_free=8.9, wall=25812
2023-06-27 01:29:48 - progress_bar.py[line:272] - INFO: epoch 004:   1398 / 3715 loss=2.073, loss_v1=0, loss_v2=0, nll_loss=0.839, ntokens=1072.8, nsentences=120, sample_size=1072.8, sample_size_v1=0, sample_size_v2=0, ppl=1.79, wps=520.8, ups=0.49, wpb=1072.8, bsz=120, num_updates=12520, lr=2.51924e-05, gnorm=3.898, clip=100, loss_scale=128, train_wall=21, gb_free=8.9, wall=25833
2023-06-27 01:30:09 - progress_bar.py[line:272] - INFO: epoch 004:   1408 / 3715 loss=2.068, loss_v1=0, loss_v2=0, nll_loss=0.83, ntokens=1090.6, nsentences=120, sample_size=1090.6, sample_size_v1=0, sample_size_v2=0, ppl=1.78, wps=529.6, ups=0.49, wpb=1090.6, bsz=120, num_updates=12530, lr=2.5187e-05, gnorm=3.897, clip=100, loss_scale=128, train_wall=21, gb_free=8.9, wall=25853
2023-06-27 01:30:30 - progress_bar.py[line:272] - INFO: epoch 004:   1418 / 3715 loss=2.091, loss_v1=0, loss_v2=0, nll_loss=0.859, ntokens=1094.5, nsentences=120, sample_size=1094.5, sample_size_v1=0, sample_size_v2=0, ppl=1.81, wps=531.6, ups=0.49, wpb=1094.5, bsz=120, num_updates=12540, lr=2.51817e-05, gnorm=3.894, clip=100, loss_scale=128, train_wall=21, gb_free=8.9, wall=25874
2023-06-27 01:30:50 - progress_bar.py[line:272] - INFO: epoch 004:   1428 / 3715 loss=2.074, loss_v1=0, loss_v2=0, nll_loss=0.836, ntokens=1084.9, nsentences=120, sample_size=1084.9, sample_size_v1=0, sample_size_v2=0, ppl=1.78, wps=526.4, ups=0.49, wpb=1084.9, bsz=120, num_updates=12550, lr=2.51763e-05, gnorm=3.986, clip=100, loss_scale=128, train_wall=21, gb_free=8.9, wall=25895
2023-06-27 01:31:11 - progress_bar.py[line:272] - INFO: epoch 004:   1438 / 3715 loss=2.064, loss_v1=0, loss_v2=0, nll_loss=0.827, ntokens=1077.8, nsentences=120, sample_size=1077.8, sample_size_v1=0, sample_size_v2=0, ppl=1.77, wps=523.1, ups=0.49, wpb=1077.8, bsz=120, num_updates=12560, lr=2.51709e-05, gnorm=3.856, clip=100, loss_scale=128, train_wall=21, gb_free=8.9, wall=25915
2023-06-27 01:31:32 - progress_bar.py[line:272] - INFO: epoch 004:   1448 / 3715 loss=2.062, loss_v1=0, loss_v2=0, nll_loss=0.825, ntokens=1072.8, nsentences=120, sample_size=1072.8, sample_size_v1=0, sample_size_v2=0, ppl=1.77, wps=520.7, ups=0.49, wpb=1072.8, bsz=120, num_updates=12570, lr=2.51656e-05, gnorm=3.887, clip=100, loss_scale=128, train_wall=21, gb_free=8.9, wall=25936
2023-06-27 01:31:52 - progress_bar.py[line:272] - INFO: epoch 004:   1458 / 3715 loss=2.082, loss_v1=0, loss_v2=0, nll_loss=0.848, ntokens=1097.3, nsentences=120, sample_size=1097.3, sample_size_v1=0, sample_size_v2=0, ppl=1.8, wps=532.6, ups=0.49, wpb=1097.3, bsz=120, num_updates=12580, lr=2.51602e-05, gnorm=3.948, clip=100, loss_scale=128, train_wall=21, gb_free=8.9, wall=25956
2023-06-27 01:32:13 - progress_bar.py[line:272] - INFO: epoch 004:   1468 / 3715 loss=2.075, loss_v1=0, loss_v2=0, nll_loss=0.838, ntokens=1086.7, nsentences=120, sample_size=1086.7, sample_size_v1=0, sample_size_v2=0, ppl=1.79, wps=527, ups=0.48, wpb=1086.7, bsz=120, num_updates=12590, lr=2.51548e-05, gnorm=4.006, clip=100, loss_scale=128, train_wall=21, gb_free=8.9, wall=25977
2023-06-27 01:32:33 - progress_bar.py[line:272] - INFO: epoch 004:   1478 / 3715 loss=2.082, loss_v1=0, loss_v2=0, nll_loss=0.848, ntokens=1071.1, nsentences=120, sample_size=1071.1, sample_size_v1=0, sample_size_v2=0, ppl=1.8, wps=519.2, ups=0.48, wpb=1071.1, bsz=120, num_updates=12600, lr=2.51494e-05, gnorm=3.928, clip=100, loss_scale=128, train_wall=21, gb_free=8.9, wall=25998
2023-06-27 01:32:54 - progress_bar.py[line:272] - INFO: epoch 004:   1488 / 3715 loss=2.076, loss_v1=0, loss_v2=0, nll_loss=0.84, ntokens=1076, nsentences=120, sample_size=1076, sample_size_v1=0, sample_size_v2=0, ppl=1.79, wps=522.8, ups=0.49, wpb=1076, bsz=120, num_updates=12610, lr=2.51441e-05, gnorm=4.169, clip=100, loss_scale=128, train_wall=21, gb_free=8.9, wall=26018
2023-06-27 01:33:15 - progress_bar.py[line:272] - INFO: epoch 004:   1498 / 3715 loss=2.061, loss_v1=0, loss_v2=0, nll_loss=0.824, ntokens=1086.8, nsentences=120, sample_size=1086.8, sample_size_v1=0, sample_size_v2=0, ppl=1.77, wps=528.5, ups=0.49, wpb=1086.8, bsz=120, num_updates=12620, lr=2.51387e-05, gnorm=3.666, clip=100, loss_scale=128, train_wall=21, gb_free=8.9, wall=26039
2023-06-27 01:33:35 - progress_bar.py[line:272] - INFO: epoch 004:   1508 / 3715 loss=2.072, loss_v1=0, loss_v2=0, nll_loss=0.837, ntokens=1102.1, nsentences=120, sample_size=1102.1, sample_size_v1=0, sample_size_v2=0, ppl=1.79, wps=535.2, ups=0.49, wpb=1102.1, bsz=120, num_updates=12630, lr=2.51333e-05, gnorm=3.697, clip=100, loss_scale=128, train_wall=21, gb_free=8.9, wall=26059
2023-06-27 01:33:56 - progress_bar.py[line:272] - INFO: epoch 004:   1518 / 3715 loss=2.089, loss_v1=0, loss_v2=0, nll_loss=0.853, ntokens=1097.9, nsentences=120, sample_size=1097.9, sample_size_v1=0, sample_size_v2=0, ppl=1.81, wps=533.3, ups=0.49, wpb=1097.9, bsz=120, num_updates=12640, lr=2.5128e-05, gnorm=3.988, clip=100, loss_scale=128, train_wall=21, gb_free=8.9, wall=26080
2023-06-27 01:34:16 - progress_bar.py[line:272] - INFO: epoch 004:   1528 / 3715 loss=2.075, loss_v1=0, loss_v2=0, nll_loss=0.838, ntokens=1075.1, nsentences=120, sample_size=1075.1, sample_size_v1=0, sample_size_v2=0, ppl=1.79, wps=522.1, ups=0.49, wpb=1075.1, bsz=120, num_updates=12650, lr=2.51226e-05, gnorm=3.948, clip=100, loss_scale=128, train_wall=21, gb_free=8.9, wall=26101
2023-06-27 01:34:37 - progress_bar.py[line:272] - INFO: epoch 004:   1538 / 3715 loss=2.078, loss_v1=0, loss_v2=0, nll_loss=0.843, ntokens=1073, nsentences=120, sample_size=1073, sample_size_v1=0, sample_size_v2=0, ppl=1.79, wps=521.7, ups=0.49, wpb=1073, bsz=120, num_updates=12660, lr=2.51172e-05, gnorm=3.864, clip=100, loss_scale=128, train_wall=21, gb_free=8.9, wall=26121
2023-06-27 01:34:57 - progress_bar.py[line:272] - INFO: epoch 004:   1548 / 3715 loss=2.065, loss_v1=0, loss_v2=0, nll_loss=0.829, ntokens=1098, nsentences=120, sample_size=1098, sample_size_v1=0, sample_size_v2=0, ppl=1.78, wps=533.1, ups=0.49, wpb=1098, bsz=120, num_updates=12670, lr=2.51119e-05, gnorm=3.671, clip=100, loss_scale=128, train_wall=21, gb_free=8.9, wall=26142
2023-06-27 01:35:18 - progress_bar.py[line:272] - INFO: epoch 004:   1558 / 3715 loss=2.078, loss_v1=0, loss_v2=0, nll_loss=0.841, ntokens=1081.1, nsentences=120, sample_size=1081.1, sample_size_v1=0, sample_size_v2=0, ppl=1.79, wps=524.9, ups=0.49, wpb=1081.1, bsz=120, num_updates=12680, lr=2.51065e-05, gnorm=3.971, clip=100, loss_scale=128, train_wall=21, gb_free=8.9, wall=26162
2023-06-27 01:35:39 - progress_bar.py[line:272] - INFO: epoch 004:   1568 / 3715 loss=2.06, loss_v1=0, loss_v2=0, nll_loss=0.824, ntokens=1080.5, nsentences=120, sample_size=1080.5, sample_size_v1=0, sample_size_v2=0, ppl=1.77, wps=525, ups=0.49, wpb=1080.5, bsz=120, num_updates=12690, lr=2.51011e-05, gnorm=3.921, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=26183
2023-06-27 01:35:59 - progress_bar.py[line:272] - INFO: epoch 004:   1578 / 3715 loss=2.088, loss_v1=0, loss_v2=0, nll_loss=0.853, ntokens=1094.7, nsentences=120, sample_size=1094.7, sample_size_v1=0, sample_size_v2=0, ppl=1.81, wps=532.4, ups=0.49, wpb=1094.7, bsz=120, num_updates=12700, lr=2.50958e-05, gnorm=3.875, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=26204
2023-06-27 01:36:20 - progress_bar.py[line:272] - INFO: epoch 004:   1588 / 3715 loss=2.072, loss_v1=0, loss_v2=0, nll_loss=0.835, ntokens=1073.1, nsentences=120, sample_size=1073.1, sample_size_v1=0, sample_size_v2=0, ppl=1.78, wps=521.8, ups=0.49, wpb=1073.1, bsz=120, num_updates=12710, lr=2.50904e-05, gnorm=3.809, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=26224
2023-06-27 01:36:40 - progress_bar.py[line:272] - INFO: epoch 004:   1598 / 3715 loss=2.08, loss_v1=0, loss_v2=0, nll_loss=0.846, ntokens=1070.2, nsentences=120, sample_size=1070.2, sample_size_v1=0, sample_size_v2=0, ppl=1.8, wps=520.6, ups=0.49, wpb=1070.2, bsz=120, num_updates=12720, lr=2.5085e-05, gnorm=4.08, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=26245
2023-06-27 01:37:01 - progress_bar.py[line:272] - INFO: epoch 004:   1608 / 3715 loss=2.07, loss_v1=0, loss_v2=0, nll_loss=0.832, ntokens=1072.6, nsentences=120, sample_size=1072.6, sample_size_v1=0, sample_size_v2=0, ppl=1.78, wps=521.6, ups=0.49, wpb=1072.6, bsz=120, num_updates=12730, lr=2.50796e-05, gnorm=3.886, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=26265
2023-06-27 01:37:22 - progress_bar.py[line:272] - INFO: epoch 004:   1618 / 3715 loss=2.064, loss_v1=0, loss_v2=0, nll_loss=0.829, ntokens=1087.6, nsentences=120, sample_size=1087.6, sample_size_v1=0, sample_size_v2=0, ppl=1.78, wps=528.5, ups=0.49, wpb=1087.6, bsz=120, num_updates=12740, lr=2.50743e-05, gnorm=3.915, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=26286
2023-06-27 01:37:42 - progress_bar.py[line:272] - INFO: epoch 004:   1628 / 3715 loss=2.064, loss_v1=0, loss_v2=0, nll_loss=0.827, ntokens=1099.8, nsentences=120, sample_size=1099.8, sample_size_v1=0, sample_size_v2=0, ppl=1.77, wps=534.7, ups=0.49, wpb=1099.8, bsz=120, num_updates=12750, lr=2.50689e-05, gnorm=3.697, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=26306
2023-06-27 01:38:03 - progress_bar.py[line:272] - INFO: epoch 004:   1638 / 3715 loss=2.07, loss_v1=0, loss_v2=0, nll_loss=0.835, ntokens=1077.2, nsentences=120, sample_size=1077.2, sample_size_v1=0, sample_size_v2=0, ppl=1.78, wps=524.1, ups=0.49, wpb=1077.2, bsz=120, num_updates=12760, lr=2.50635e-05, gnorm=3.927, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=26327
2023-06-27 01:38:23 - progress_bar.py[line:272] - INFO: epoch 004:   1648 / 3715 loss=2.07, loss_v1=0, loss_v2=0, nll_loss=0.833, ntokens=1080.2, nsentences=120, sample_size=1080.2, sample_size_v1=0, sample_size_v2=0, ppl=1.78, wps=525, ups=0.49, wpb=1080.2, bsz=120, num_updates=12770, lr=2.50582e-05, gnorm=4.047, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=26348
2023-06-27 01:38:44 - progress_bar.py[line:272] - INFO: epoch 004:   1658 / 3715 loss=2.073, loss_v1=0, loss_v2=0, nll_loss=0.838, ntokens=1068.1, nsentences=120, sample_size=1068.1, sample_size_v1=0, sample_size_v2=0, ppl=1.79, wps=519, ups=0.49, wpb=1068.1, bsz=120, num_updates=12780, lr=2.50528e-05, gnorm=3.993, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=26368
2023-06-27 01:39:04 - progress_bar.py[line:272] - INFO: epoch 004:   1668 / 3715 loss=2.077, loss_v1=0, loss_v2=0, nll_loss=0.84, ntokens=1075.6, nsentences=120, sample_size=1075.6, sample_size_v1=0, sample_size_v2=0, ppl=1.79, wps=522.3, ups=0.49, wpb=1075.6, bsz=120, num_updates=12790, lr=2.50474e-05, gnorm=3.858, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=26389
2023-06-27 01:39:25 - progress_bar.py[line:272] - INFO: epoch 004:   1678 / 3715 loss=2.069, loss_v1=0, loss_v2=0, nll_loss=0.834, ntokens=1066.4, nsentences=120, sample_size=1066.4, sample_size_v1=0, sample_size_v2=0, ppl=1.78, wps=517.2, ups=0.49, wpb=1066.4, bsz=120, num_updates=12800, lr=2.50421e-05, gnorm=3.945, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=26409
2023-06-27 01:39:46 - progress_bar.py[line:272] - INFO: epoch 004:   1688 / 3715 loss=2.068, loss_v1=0, loss_v2=0, nll_loss=0.831, ntokens=1073.4, nsentences=120, sample_size=1073.4, sample_size_v1=0, sample_size_v2=0, ppl=1.78, wps=521.3, ups=0.49, wpb=1073.4, bsz=120, num_updates=12810, lr=2.50367e-05, gnorm=4.061, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=26430
2023-06-27 01:40:06 - progress_bar.py[line:272] - INFO: epoch 004:   1698 / 3715 loss=2.065, loss_v1=0, loss_v2=0, nll_loss=0.829, ntokens=1077.1, nsentences=120, sample_size=1077.1, sample_size_v1=0, sample_size_v2=0, ppl=1.78, wps=523, ups=0.49, wpb=1077.1, bsz=120, num_updates=12820, lr=2.50313e-05, gnorm=4.11, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=26451
2023-06-27 01:40:27 - progress_bar.py[line:272] - INFO: epoch 004:   1708 / 3715 loss=2.078, loss_v1=0, loss_v2=0, nll_loss=0.843, ntokens=1078.8, nsentences=120, sample_size=1078.8, sample_size_v1=0, sample_size_v2=0, ppl=1.79, wps=523.9, ups=0.49, wpb=1078.8, bsz=120, num_updates=12830, lr=2.5026e-05, gnorm=3.81, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=26471
2023-06-27 01:40:47 - progress_bar.py[line:272] - INFO: epoch 004:   1718 / 3715 loss=2.064, loss_v1=0, loss_v2=0, nll_loss=0.826, ntokens=1097.3, nsentences=120, sample_size=1097.3, sample_size_v1=0, sample_size_v2=0, ppl=1.77, wps=532.9, ups=0.49, wpb=1097.3, bsz=120, num_updates=12840, lr=2.50206e-05, gnorm=3.702, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=26492
2023-06-27 01:41:08 - progress_bar.py[line:272] - INFO: epoch 004:   1728 / 3715 loss=2.064, loss_v1=0, loss_v2=0, nll_loss=0.829, ntokens=1095.9, nsentences=120, sample_size=1095.9, sample_size_v1=0, sample_size_v2=0, ppl=1.78, wps=532, ups=0.49, wpb=1095.9, bsz=120, num_updates=12850, lr=2.50152e-05, gnorm=4.15, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=26512
2023-06-27 01:41:29 - progress_bar.py[line:272] - INFO: epoch 004:   1738 / 3715 loss=2.063, loss_v1=0, loss_v2=0, nll_loss=0.825, ntokens=1080.5, nsentences=120, sample_size=1080.5, sample_size_v1=0, sample_size_v2=0, ppl=1.77, wps=525.1, ups=0.49, wpb=1080.5, bsz=120, num_updates=12860, lr=2.50098e-05, gnorm=3.908, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=26533
2023-06-27 01:41:49 - progress_bar.py[line:272] - INFO: epoch 004:   1748 / 3715 loss=2.074, loss_v1=0, loss_v2=0, nll_loss=0.836, ntokens=1078.1, nsentences=120, sample_size=1078.1, sample_size_v1=0, sample_size_v2=0, ppl=1.78, wps=524.2, ups=0.49, wpb=1078.1, bsz=120, num_updates=12870, lr=2.50045e-05, gnorm=4.076, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=26554
2023-06-27 01:42:10 - progress_bar.py[line:272] - INFO: epoch 004:   1758 / 3715 loss=2.054, loss_v1=0, loss_v2=0, nll_loss=0.817, ntokens=1085, nsentences=120, sample_size=1085, sample_size_v1=0, sample_size_v2=0, ppl=1.76, wps=527.5, ups=0.49, wpb=1085, bsz=120, num_updates=12880, lr=2.49991e-05, gnorm=4.017, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=26574
2023-06-27 01:42:30 - progress_bar.py[line:272] - INFO: epoch 004:   1768 / 3715 loss=2.05, loss_v1=0, loss_v2=0, nll_loss=0.812, ntokens=1080.4, nsentences=120, sample_size=1080.4, sample_size_v1=0, sample_size_v2=0, ppl=1.76, wps=525.1, ups=0.49, wpb=1080.4, bsz=120, num_updates=12890, lr=2.49937e-05, gnorm=4.053, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=26595
2023-06-27 01:42:51 - progress_bar.py[line:272] - INFO: epoch 004:   1778 / 3715 loss=2.062, loss_v1=0, loss_v2=0, nll_loss=0.823, ntokens=1075.6, nsentences=120, sample_size=1075.6, sample_size_v1=0, sample_size_v2=0, ppl=1.77, wps=522.7, ups=0.49, wpb=1075.6, bsz=120, num_updates=12900, lr=2.49884e-05, gnorm=3.969, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=26615
2023-06-27 01:43:11 - progress_bar.py[line:272] - INFO: epoch 004:   1788 / 3715 loss=2.082, loss_v1=0, loss_v2=0, nll_loss=0.847, ntokens=1072.2, nsentences=120, sample_size=1072.2, sample_size_v1=0, sample_size_v2=0, ppl=1.8, wps=521.5, ups=0.49, wpb=1072.2, bsz=120, num_updates=12910, lr=2.4983e-05, gnorm=4.109, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=26636
2023-06-27 01:43:32 - progress_bar.py[line:272] - INFO: epoch 004:   1798 / 3715 loss=2.056, loss_v1=0, loss_v2=0, nll_loss=0.818, ntokens=1086.7, nsentences=120, sample_size=1086.7, sample_size_v1=0, sample_size_v2=0, ppl=1.76, wps=528.3, ups=0.49, wpb=1086.7, bsz=120, num_updates=12920, lr=2.49776e-05, gnorm=3.929, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=26656
2023-06-27 01:43:53 - progress_bar.py[line:272] - INFO: epoch 004:   1808 / 3715 loss=2.067, loss_v1=0, loss_v2=0, nll_loss=0.83, ntokens=1079.1, nsentences=120, sample_size=1079.1, sample_size_v1=0, sample_size_v2=0, ppl=1.78, wps=524.6, ups=0.49, wpb=1079.1, bsz=120, num_updates=12930, lr=2.49723e-05, gnorm=3.857, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=26677
2023-06-27 01:44:13 - progress_bar.py[line:272] - INFO: epoch 004:   1818 / 3715 loss=2.069, loss_v1=0, loss_v2=0, nll_loss=0.833, ntokens=1074.8, nsentences=120, sample_size=1074.8, sample_size_v1=0, sample_size_v2=0, ppl=1.78, wps=522.4, ups=0.49, wpb=1074.8, bsz=120, num_updates=12940, lr=2.49669e-05, gnorm=4.127, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=26698
2023-06-27 01:44:34 - progress_bar.py[line:272] - INFO: epoch 004:   1828 / 3715 loss=2.06, loss_v1=0, loss_v2=0, nll_loss=0.822, ntokens=1108.5, nsentences=120, sample_size=1108.5, sample_size_v1=0, sample_size_v2=0, ppl=1.77, wps=538.3, ups=0.49, wpb=1108.5, bsz=120, num_updates=12950, lr=2.49615e-05, gnorm=3.971, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=26718
2023-06-27 01:44:54 - progress_bar.py[line:272] - INFO: epoch 004:   1838 / 3715 loss=2.042, loss_v1=0, loss_v2=0, nll_loss=0.804, ntokens=1070.2, nsentences=120, sample_size=1070.2, sample_size_v1=0, sample_size_v2=0, ppl=1.75, wps=519.5, ups=0.49, wpb=1070.2, bsz=120, num_updates=12960, lr=2.49562e-05, gnorm=3.897, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=26739
2023-06-27 01:45:15 - progress_bar.py[line:272] - INFO: epoch 004:   1848 / 3715 loss=2.046, loss_v1=0, loss_v2=0, nll_loss=0.806, ntokens=1083.2, nsentences=120, sample_size=1083.2, sample_size_v1=0, sample_size_v2=0, ppl=1.75, wps=525.4, ups=0.49, wpb=1083.2, bsz=120, num_updates=12970, lr=2.49508e-05, gnorm=3.781, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=26759
2023-06-27 01:45:36 - progress_bar.py[line:272] - INFO: epoch 004:   1858 / 3715 loss=2.081, loss_v1=0, loss_v2=0, nll_loss=0.846, ntokens=1094.4, nsentences=120, sample_size=1094.4, sample_size_v1=0, sample_size_v2=0, ppl=1.8, wps=531.2, ups=0.49, wpb=1094.4, bsz=120, num_updates=12980, lr=2.49454e-05, gnorm=3.793, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=26780
2023-06-27 01:45:56 - progress_bar.py[line:272] - INFO: epoch 004:   1868 / 3715 loss=2.078, loss_v1=0, loss_v2=0, nll_loss=0.843, ntokens=1083.9, nsentences=120, sample_size=1083.9, sample_size_v1=0, sample_size_v2=0, ppl=1.79, wps=525.7, ups=0.48, wpb=1083.9, bsz=120, num_updates=12990, lr=2.494e-05, gnorm=4.001, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=26801
2023-06-27 01:46:17 - progress_bar.py[line:272] - INFO: epoch 004:   1878 / 3715 loss=2.069, loss_v1=0, loss_v2=0, nll_loss=0.831, ntokens=1067, nsentences=120, sample_size=1067, sample_size_v1=0, sample_size_v2=0, ppl=1.78, wps=517.4, ups=0.48, wpb=1067, bsz=120, num_updates=13000, lr=2.49347e-05, gnorm=3.963, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=26821
2023-06-27 01:46:37 - progress_bar.py[line:272] - INFO: epoch 004:   1888 / 3715 loss=2.061, loss_v1=0, loss_v2=0, nll_loss=0.824, ntokens=1085.9, nsentences=120, sample_size=1085.9, sample_size_v1=0, sample_size_v2=0, ppl=1.77, wps=526.6, ups=0.48, wpb=1085.9, bsz=120, num_updates=13010, lr=2.49293e-05, gnorm=4.055, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=26842
2023-06-27 01:46:58 - progress_bar.py[line:272] - INFO: epoch 004:   1898 / 3715 loss=2.073, loss_v1=0, loss_v2=0, nll_loss=0.836, ntokens=1076.5, nsentences=120, sample_size=1076.5, sample_size_v1=0, sample_size_v2=0, ppl=1.79, wps=522.4, ups=0.49, wpb=1076.5, bsz=120, num_updates=13020, lr=2.49239e-05, gnorm=3.773, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=26862
2023-06-27 01:47:19 - progress_bar.py[line:272] - INFO: epoch 004:   1908 / 3715 loss=2.059, loss_v1=0, loss_v2=0, nll_loss=0.821, ntokens=1091.3, nsentences=120, sample_size=1091.3, sample_size_v1=0, sample_size_v2=0, ppl=1.77, wps=529.1, ups=0.48, wpb=1091.3, bsz=120, num_updates=13030, lr=2.49186e-05, gnorm=3.927, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=26883
2023-06-27 01:47:39 - progress_bar.py[line:272] - INFO: epoch 004:   1918 / 3715 loss=2.054, loss_v1=0, loss_v2=0, nll_loss=0.818, ntokens=1074.3, nsentences=120, sample_size=1074.3, sample_size_v1=0, sample_size_v2=0, ppl=1.76, wps=521.9, ups=0.49, wpb=1074.3, bsz=120, num_updates=13040, lr=2.49132e-05, gnorm=4.3, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=26904
2023-06-27 01:48:00 - progress_bar.py[line:272] - INFO: epoch 004:   1928 / 3715 loss=2.062, loss_v1=0, loss_v2=0, nll_loss=0.825, ntokens=1079.9, nsentences=120, sample_size=1079.9, sample_size_v1=0, sample_size_v2=0, ppl=1.77, wps=523.4, ups=0.48, wpb=1079.9, bsz=120, num_updates=13050, lr=2.49078e-05, gnorm=3.964, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=26924
2023-06-27 01:48:21 - progress_bar.py[line:272] - INFO: epoch 004:   1938 / 3715 loss=2.079, loss_v1=0, loss_v2=0, nll_loss=0.844, ntokens=1075.6, nsentences=120, sample_size=1075.6, sample_size_v1=0, sample_size_v2=0, ppl=1.8, wps=521.1, ups=0.48, wpb=1075.6, bsz=120, num_updates=13060, lr=2.49025e-05, gnorm=4.133, clip=100, loss_scale=256, train_wall=21, gb_free=8.8, wall=26945
2023-06-27 01:48:41 - progress_bar.py[line:272] - INFO: epoch 004:   1948 / 3715 loss=2.066, loss_v1=0, loss_v2=0, nll_loss=0.826, ntokens=1068.2, nsentences=120, sample_size=1068.2, sample_size_v1=0, sample_size_v2=0, ppl=1.77, wps=518, ups=0.48, wpb=1068.2, bsz=120, num_updates=13070, lr=2.48971e-05, gnorm=4.068, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=26966
2023-06-27 01:49:02 - progress_bar.py[line:272] - INFO: epoch 004:   1958 / 3715 loss=2.059, loss_v1=0, loss_v2=0, nll_loss=0.823, ntokens=1090.7, nsentences=120, sample_size=1090.7, sample_size_v1=0, sample_size_v2=0, ppl=1.77, wps=529.4, ups=0.49, wpb=1090.7, bsz=120, num_updates=13080, lr=2.48917e-05, gnorm=4.082, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=26986
2023-06-27 01:49:22 - progress_bar.py[line:272] - INFO: epoch 004:   1968 / 3715 loss=2.074, loss_v1=0, loss_v2=0, nll_loss=0.837, ntokens=1089.2, nsentences=120, sample_size=1089.2, sample_size_v1=0, sample_size_v2=0, ppl=1.79, wps=528.9, ups=0.49, wpb=1089.2, bsz=120, num_updates=13090, lr=2.48864e-05, gnorm=3.887, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=27007
2023-06-27 01:49:43 - progress_bar.py[line:272] - INFO: epoch 004:   1978 / 3715 loss=2.077, loss_v1=0, loss_v2=0, nll_loss=0.843, ntokens=1073, nsentences=120, sample_size=1073, sample_size_v1=0, sample_size_v2=0, ppl=1.79, wps=520.6, ups=0.49, wpb=1073, bsz=120, num_updates=13100, lr=2.4881e-05, gnorm=4.083, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=27027
2023-06-27 01:50:04 - progress_bar.py[line:272] - INFO: epoch 004:   1988 / 3715 loss=2.077, loss_v1=0, loss_v2=0, nll_loss=0.841, ntokens=1068.3, nsentences=120, sample_size=1068.3, sample_size_v1=0, sample_size_v2=0, ppl=1.79, wps=519.1, ups=0.49, wpb=1068.3, bsz=120, num_updates=13110, lr=2.48756e-05, gnorm=4.197, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=27048
2023-06-27 01:50:24 - progress_bar.py[line:272] - INFO: epoch 004:   1998 / 3715 loss=2.055, loss_v1=0, loss_v2=0, nll_loss=0.816, ntokens=1098.6, nsentences=120, sample_size=1098.6, sample_size_v1=0, sample_size_v2=0, ppl=1.76, wps=533.7, ups=0.49, wpb=1098.6, bsz=120, num_updates=13120, lr=2.48702e-05, gnorm=3.997, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=27069
2023-06-27 01:50:45 - progress_bar.py[line:272] - INFO: epoch 004:   2008 / 3715 loss=2.054, loss_v1=0, loss_v2=0, nll_loss=0.817, ntokens=1091.5, nsentences=120, sample_size=1091.5, sample_size_v1=0, sample_size_v2=0, ppl=1.76, wps=530, ups=0.49, wpb=1091.5, bsz=120, num_updates=13130, lr=2.48649e-05, gnorm=3.899, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=27089
2023-06-27 01:51:05 - progress_bar.py[line:272] - INFO: epoch 004:   2018 / 3715 loss=2.052, loss_v1=0, loss_v2=0, nll_loss=0.813, ntokens=1078.3, nsentences=120, sample_size=1078.3, sample_size_v1=0, sample_size_v2=0, ppl=1.76, wps=523.1, ups=0.49, wpb=1078.3, bsz=120, num_updates=13140, lr=2.48595e-05, gnorm=4.03, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=27110
2023-06-27 01:51:26 - progress_bar.py[line:272] - INFO: epoch 004:   2028 / 3715 loss=2.063, loss_v1=0, loss_v2=0, nll_loss=0.828, ntokens=1084.2, nsentences=120, sample_size=1084.2, sample_size_v1=0, sample_size_v2=0, ppl=1.78, wps=527.5, ups=0.49, wpb=1084.2, bsz=120, num_updates=13150, lr=2.48541e-05, gnorm=3.787, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=27130
2023-06-27 01:51:47 - progress_bar.py[line:272] - INFO: epoch 004:   2038 / 3715 loss=2.068, loss_v1=0, loss_v2=0, nll_loss=0.83, ntokens=1099.8, nsentences=120, sample_size=1099.8, sample_size_v1=0, sample_size_v2=0, ppl=1.78, wps=534.7, ups=0.49, wpb=1099.8, bsz=120, num_updates=13160, lr=2.48488e-05, gnorm=4.033, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=27151
2023-06-27 01:52:07 - progress_bar.py[line:272] - INFO: epoch 004:   2048 / 3715 loss=2.06, loss_v1=0, loss_v2=0, nll_loss=0.824, ntokens=1104.1, nsentences=120, sample_size=1104.1, sample_size_v1=0, sample_size_v2=0, ppl=1.77, wps=531.3, ups=0.48, wpb=1104.1, bsz=120, num_updates=13170, lr=2.48434e-05, gnorm=3.743, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=27172
2023-06-27 01:52:28 - progress_bar.py[line:272] - INFO: epoch 004:   2058 / 3715 loss=2.068, loss_v1=0, loss_v2=0, nll_loss=0.83, ntokens=1096.8, nsentences=120, sample_size=1096.8, sample_size_v1=0, sample_size_v2=0, ppl=1.78, wps=532.3, ups=0.49, wpb=1096.8, bsz=120, num_updates=13180, lr=2.4838e-05, gnorm=3.835, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=27192
2023-06-27 01:52:49 - progress_bar.py[line:272] - INFO: epoch 004:   2068 / 3715 loss=2.083, loss_v1=0, loss_v2=0, nll_loss=0.849, ntokens=1099.4, nsentences=120, sample_size=1099.4, sample_size_v1=0, sample_size_v2=0, ppl=1.8, wps=533.6, ups=0.49, wpb=1099.4, bsz=120, num_updates=13190, lr=2.48327e-05, gnorm=4.04, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=27213
2023-06-27 01:53:09 - progress_bar.py[line:272] - INFO: epoch 004:   2078 / 3715 loss=2.049, loss_v1=0, loss_v2=0, nll_loss=0.809, ntokens=1078.4, nsentences=120, sample_size=1078.4, sample_size_v1=0, sample_size_v2=0, ppl=1.75, wps=523.7, ups=0.49, wpb=1078.4, bsz=120, num_updates=13200, lr=2.48273e-05, gnorm=4.229, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=27233
2023-06-27 01:53:15 - trainer.py[line:921] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 256.0
2023-06-27 01:53:32 - progress_bar.py[line:272] - INFO: epoch 004:   2089 / 3715 loss=2.066, loss_v1=0, loss_v2=0, nll_loss=0.828, ntokens=1075.1, nsentences=120, sample_size=1075.1, sample_size_v1=0, sample_size_v2=0, ppl=1.78, wps=474.6, ups=0.44, wpb=1075.1, bsz=120, num_updates=13210, lr=2.48219e-05, gnorm=3.975, clip=100, loss_scale=256, train_wall=23, gb_free=8.9, wall=27256
2023-06-27 01:53:52 - progress_bar.py[line:272] - INFO: epoch 004:   2099 / 3715 loss=2.063, loss_v1=0, loss_v2=0, nll_loss=0.826, ntokens=1091.4, nsentences=120, sample_size=1091.4, sample_size_v1=0, sample_size_v2=0, ppl=1.77, wps=529.6, ups=0.49, wpb=1091.4, bsz=120, num_updates=13220, lr=2.48166e-05, gnorm=3.98, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=27277
2023-06-27 01:54:13 - progress_bar.py[line:272] - INFO: epoch 004:   2109 / 3715 loss=2.071, loss_v1=0, loss_v2=0, nll_loss=0.834, ntokens=1076.5, nsentences=120, sample_size=1076.5, sample_size_v1=0, sample_size_v2=0, ppl=1.78, wps=522.4, ups=0.49, wpb=1076.5, bsz=120, num_updates=13230, lr=2.48112e-05, gnorm=4.147, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=27297
2023-06-27 01:54:34 - progress_bar.py[line:272] - INFO: epoch 004:   2119 / 3715 loss=2.053, loss_v1=0, loss_v2=0, nll_loss=0.814, ntokens=1084.3, nsentences=120, sample_size=1084.3, sample_size_v1=0, sample_size_v2=0, ppl=1.76, wps=526.7, ups=0.49, wpb=1084.3, bsz=120, num_updates=13240, lr=2.48058e-05, gnorm=3.984, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=27318
2023-06-27 01:54:54 - progress_bar.py[line:272] - INFO: epoch 004:   2129 / 3715 loss=2.069, loss_v1=0, loss_v2=0, nll_loss=0.835, ntokens=1072.8, nsentences=120, sample_size=1072.8, sample_size_v1=0, sample_size_v2=0, ppl=1.78, wps=521.4, ups=0.49, wpb=1072.8, bsz=120, num_updates=13250, lr=2.48004e-05, gnorm=3.822, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=27339
2023-06-27 01:55:15 - progress_bar.py[line:272] - INFO: epoch 004:   2139 / 3715 loss=2.062, loss_v1=0, loss_v2=0, nll_loss=0.825, ntokens=1097.9, nsentences=120, sample_size=1097.9, sample_size_v1=0, sample_size_v2=0, ppl=1.77, wps=533.6, ups=0.49, wpb=1097.9, bsz=120, num_updates=13260, lr=2.47951e-05, gnorm=3.804, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=27359
2023-06-27 01:55:35 - progress_bar.py[line:272] - INFO: epoch 004:   2149 / 3715 loss=2.055, loss_v1=0, loss_v2=0, nll_loss=0.816, ntokens=1088.9, nsentences=120, sample_size=1088.9, sample_size_v1=0, sample_size_v2=0, ppl=1.76, wps=529.6, ups=0.49, wpb=1088.9, bsz=120, num_updates=13270, lr=2.47897e-05, gnorm=4.037, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=27380
2023-06-27 01:55:56 - progress_bar.py[line:272] - INFO: epoch 004:   2159 / 3715 loss=2.057, loss_v1=0, loss_v2=0, nll_loss=0.818, ntokens=1078.5, nsentences=120, sample_size=1078.5, sample_size_v1=0, sample_size_v2=0, ppl=1.76, wps=524.1, ups=0.49, wpb=1078.5, bsz=120, num_updates=13280, lr=2.47843e-05, gnorm=4.053, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=27400
2023-06-27 01:56:16 - progress_bar.py[line:272] - INFO: epoch 004:   2169 / 3715 loss=2.068, loss_v1=0, loss_v2=0, nll_loss=0.832, ntokens=1106.7, nsentences=120, sample_size=1106.7, sample_size_v1=0, sample_size_v2=0, ppl=1.78, wps=538.2, ups=0.49, wpb=1106.7, bsz=120, num_updates=13290, lr=2.4779e-05, gnorm=4.308, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=27421
2023-06-27 01:56:37 - progress_bar.py[line:272] - INFO: epoch 004:   2179 / 3715 loss=2.061, loss_v1=0, loss_v2=0, nll_loss=0.823, ntokens=1110.5, nsentences=120, sample_size=1110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.77, wps=538.9, ups=0.49, wpb=1110.5, bsz=120, num_updates=13300, lr=2.47736e-05, gnorm=3.819, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=27441
2023-06-27 01:56:58 - progress_bar.py[line:272] - INFO: epoch 004:   2189 / 3715 loss=2.054, loss_v1=0, loss_v2=0, nll_loss=0.817, ntokens=1073.4, nsentences=120, sample_size=1073.4, sample_size_v1=0, sample_size_v2=0, ppl=1.76, wps=521.3, ups=0.49, wpb=1073.4, bsz=120, num_updates=13310, lr=2.47682e-05, gnorm=3.87, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=27462
2023-06-27 01:57:18 - progress_bar.py[line:272] - INFO: epoch 004:   2199 / 3715 loss=2.059, loss_v1=0, loss_v2=0, nll_loss=0.819, ntokens=1085.5, nsentences=120, sample_size=1085.5, sample_size_v1=0, sample_size_v2=0, ppl=1.76, wps=527.1, ups=0.49, wpb=1085.5, bsz=120, num_updates=13320, lr=2.47629e-05, gnorm=4.025, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=27483
2023-06-27 01:57:39 - progress_bar.py[line:272] - INFO: epoch 004:   2209 / 3715 loss=2.052, loss_v1=0, loss_v2=0, nll_loss=0.814, ntokens=1100.2, nsentences=120, sample_size=1100.2, sample_size_v1=0, sample_size_v2=0, ppl=1.76, wps=533.9, ups=0.49, wpb=1100.2, bsz=120, num_updates=13330, lr=2.47575e-05, gnorm=3.812, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=27503
2023-06-27 01:58:00 - progress_bar.py[line:272] - INFO: epoch 004:   2219 / 3715 loss=2.058, loss_v1=0, loss_v2=0, nll_loss=0.82, ntokens=1096.3, nsentences=120, sample_size=1096.3, sample_size_v1=0, sample_size_v2=0, ppl=1.77, wps=531.5, ups=0.48, wpb=1096.3, bsz=120, num_updates=13340, lr=2.47521e-05, gnorm=3.739, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=27524
2023-06-27 01:58:20 - progress_bar.py[line:272] - INFO: epoch 004:   2229 / 3715 loss=2.065, loss_v1=0, loss_v2=0, nll_loss=0.831, ntokens=1096.8, nsentences=120, sample_size=1096.8, sample_size_v1=0, sample_size_v2=0, ppl=1.78, wps=532.1, ups=0.49, wpb=1096.8, bsz=120, num_updates=13350, lr=2.47468e-05, gnorm=3.946, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=27544
2023-06-27 01:58:41 - progress_bar.py[line:272] - INFO: epoch 004:   2239 / 3715 loss=2.058, loss_v1=0, loss_v2=0, nll_loss=0.817, ntokens=1080.8, nsentences=120, sample_size=1080.8, sample_size_v1=0, sample_size_v2=0, ppl=1.76, wps=524.7, ups=0.49, wpb=1080.8, bsz=120, num_updates=13360, lr=2.47414e-05, gnorm=3.932, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=27565
2023-06-27 01:59:01 - progress_bar.py[line:272] - INFO: epoch 004:   2249 / 3715 loss=2.068, loss_v1=0, loss_v2=0, nll_loss=0.832, ntokens=1100.8, nsentences=120, sample_size=1100.8, sample_size_v1=0, sample_size_v2=0, ppl=1.78, wps=534.9, ups=0.49, wpb=1100.8, bsz=120, num_updates=13370, lr=2.4736e-05, gnorm=3.788, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=27586
2023-06-27 01:59:22 - progress_bar.py[line:272] - INFO: epoch 004:   2259 / 3715 loss=2.057, loss_v1=0, loss_v2=0, nll_loss=0.82, ntokens=1079.2, nsentences=120, sample_size=1079.2, sample_size_v1=0, sample_size_v2=0, ppl=1.77, wps=525.2, ups=0.49, wpb=1079.2, bsz=120, num_updates=13380, lr=2.47306e-05, gnorm=4.105, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=27606
2023-06-27 01:59:42 - progress_bar.py[line:272] - INFO: epoch 004:   2269 / 3715 loss=2.039, loss_v1=0, loss_v2=0, nll_loss=0.797, ntokens=1105, nsentences=120, sample_size=1105, sample_size_v1=0, sample_size_v2=0, ppl=1.74, wps=537.7, ups=0.49, wpb=1105, bsz=120, num_updates=13390, lr=2.47253e-05, gnorm=3.725, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=27627
2023-06-27 02:00:03 - progress_bar.py[line:272] - INFO: epoch 004:   2279 / 3715 loss=2.05, loss_v1=0, loss_v2=0, nll_loss=0.813, ntokens=1092.7, nsentences=120, sample_size=1092.7, sample_size_v1=0, sample_size_v2=0, ppl=1.76, wps=531.4, ups=0.49, wpb=1092.7, bsz=120, num_updates=13400, lr=2.47199e-05, gnorm=3.787, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=27647
2023-06-27 02:00:24 - progress_bar.py[line:272] - INFO: epoch 004:   2289 / 3715 loss=2.044, loss_v1=0, loss_v2=0, nll_loss=0.802, ntokens=1086.9, nsentences=120, sample_size=1086.9, sample_size_v1=0, sample_size_v2=0, ppl=1.74, wps=527.7, ups=0.49, wpb=1086.9, bsz=120, num_updates=13410, lr=2.47145e-05, gnorm=3.897, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=27668
2023-06-27 02:00:44 - progress_bar.py[line:272] - INFO: epoch 004:   2299 / 3715 loss=2.054, loss_v1=0, loss_v2=0, nll_loss=0.818, ntokens=1065.5, nsentences=120, sample_size=1065.5, sample_size_v1=0, sample_size_v2=0, ppl=1.76, wps=517.5, ups=0.49, wpb=1065.5, bsz=120, num_updates=13420, lr=2.47092e-05, gnorm=4.041, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=27689
2023-06-27 02:01:05 - progress_bar.py[line:272] - INFO: epoch 004:   2309 / 3715 loss=2.062, loss_v1=0, loss_v2=0, nll_loss=0.823, ntokens=1096.9, nsentences=120, sample_size=1096.9, sample_size_v1=0, sample_size_v2=0, ppl=1.77, wps=532.1, ups=0.49, wpb=1096.9, bsz=120, num_updates=13430, lr=2.47038e-05, gnorm=3.765, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=27709
2023-06-27 02:01:25 - progress_bar.py[line:272] - INFO: epoch 004:   2319 / 3715 loss=2.03, loss_v1=0, loss_v2=0, nll_loss=0.789, ntokens=1076, nsentences=120, sample_size=1076, sample_size_v1=0, sample_size_v2=0, ppl=1.73, wps=522.4, ups=0.49, wpb=1076, bsz=120, num_updates=13440, lr=2.46984e-05, gnorm=4.033, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=27730
2023-06-27 02:01:46 - progress_bar.py[line:272] - INFO: epoch 004:   2329 / 3715 loss=2.054, loss_v1=0, loss_v2=0, nll_loss=0.816, ntokens=1077.7, nsentences=120, sample_size=1077.7, sample_size_v1=0, sample_size_v2=0, ppl=1.76, wps=523.8, ups=0.49, wpb=1077.7, bsz=120, num_updates=13450, lr=2.46931e-05, gnorm=4.138, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=27750
2023-06-27 02:02:07 - progress_bar.py[line:272] - INFO: epoch 004:   2339 / 3715 loss=2.064, loss_v1=0, loss_v2=0, nll_loss=0.827, ntokens=1086, nsentences=120, sample_size=1086, sample_size_v1=0, sample_size_v2=0, ppl=1.77, wps=527.4, ups=0.49, wpb=1086, bsz=120, num_updates=13460, lr=2.46877e-05, gnorm=3.897, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=27771
2023-06-27 02:02:27 - progress_bar.py[line:272] - INFO: epoch 004:   2349 / 3715 loss=2.062, loss_v1=0, loss_v2=0, nll_loss=0.824, ntokens=1113.2, nsentences=120, sample_size=1113.2, sample_size_v1=0, sample_size_v2=0, ppl=1.77, wps=540.8, ups=0.49, wpb=1113.2, bsz=120, num_updates=13470, lr=2.46823e-05, gnorm=3.647, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=27792
2023-06-27 02:02:48 - progress_bar.py[line:272] - INFO: epoch 004:   2359 / 3715 loss=2.053, loss_v1=0, loss_v2=0, nll_loss=0.814, ntokens=1094, nsentences=120, sample_size=1094, sample_size_v1=0, sample_size_v2=0, ppl=1.76, wps=531.6, ups=0.49, wpb=1094, bsz=120, num_updates=13480, lr=2.4677e-05, gnorm=3.918, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=27812
2023-06-27 02:03:08 - progress_bar.py[line:272] - INFO: epoch 004:   2369 / 3715 loss=2.043, loss_v1=0, loss_v2=0, nll_loss=0.806, ntokens=1087.6, nsentences=120, sample_size=1087.6, sample_size_v1=0, sample_size_v2=0, ppl=1.75, wps=528.6, ups=0.49, wpb=1087.6, bsz=120, num_updates=13490, lr=2.46716e-05, gnorm=4.062, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=27833
2023-06-27 02:03:29 - progress_bar.py[line:272] - INFO: epoch 004:   2379 / 3715 loss=2.036, loss_v1=0, loss_v2=0, nll_loss=0.794, ntokens=1080.7, nsentences=120, sample_size=1080.7, sample_size_v1=0, sample_size_v2=0, ppl=1.73, wps=524.6, ups=0.49, wpb=1080.7, bsz=120, num_updates=13500, lr=2.46662e-05, gnorm=3.696, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=27853
2023-06-27 02:03:50 - progress_bar.py[line:272] - INFO: epoch 004:   2389 / 3715 loss=2.046, loss_v1=0, loss_v2=0, nll_loss=0.808, ntokens=1090.3, nsentences=120, sample_size=1090.3, sample_size_v1=0, sample_size_v2=0, ppl=1.75, wps=529.1, ups=0.49, wpb=1090.3, bsz=120, num_updates=13510, lr=2.46608e-05, gnorm=3.949, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=27874
2023-06-27 02:04:10 - progress_bar.py[line:272] - INFO: epoch 004:   2399 / 3715 loss=2.045, loss_v1=0, loss_v2=0, nll_loss=0.804, ntokens=1056.7, nsentences=120, sample_size=1056.7, sample_size_v1=0, sample_size_v2=0, ppl=1.75, wps=513, ups=0.49, wpb=1056.7, bsz=120, num_updates=13520, lr=2.46555e-05, gnorm=3.906, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=27895
2023-06-27 02:04:31 - progress_bar.py[line:272] - INFO: epoch 004:   2409 / 3715 loss=2.068, loss_v1=0, loss_v2=0, nll_loss=0.833, ntokens=1073.3, nsentences=120, sample_size=1073.3, sample_size_v1=0, sample_size_v2=0, ppl=1.78, wps=521.1, ups=0.49, wpb=1073.3, bsz=120, num_updates=13530, lr=2.46501e-05, gnorm=3.977, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=27915
2023-06-27 02:04:51 - progress_bar.py[line:272] - INFO: epoch 004:   2419 / 3715 loss=2.043, loss_v1=0, loss_v2=0, nll_loss=0.802, ntokens=1093.9, nsentences=120, sample_size=1093.9, sample_size_v1=0, sample_size_v2=0, ppl=1.74, wps=531.2, ups=0.49, wpb=1093.9, bsz=120, num_updates=13540, lr=2.46447e-05, gnorm=4.012, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=27936
2023-06-27 02:05:12 - progress_bar.py[line:272] - INFO: epoch 004:   2429 / 3715 loss=2.03, loss_v1=0, loss_v2=0, nll_loss=0.79, ntokens=1111.1, nsentences=120, sample_size=1111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.73, wps=537.7, ups=0.48, wpb=1111.1, bsz=120, num_updates=13550, lr=2.46394e-05, gnorm=3.717, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=27956
2023-06-27 02:05:33 - progress_bar.py[line:272] - INFO: epoch 004:   2439 / 3715 loss=2.063, loss_v1=0, loss_v2=0, nll_loss=0.826, ntokens=1082.9, nsentences=120, sample_size=1082.9, sample_size_v1=0, sample_size_v2=0, ppl=1.77, wps=525.4, ups=0.49, wpb=1082.9, bsz=120, num_updates=13560, lr=2.4634e-05, gnorm=3.912, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=27977
2023-06-27 02:05:53 - progress_bar.py[line:272] - INFO: epoch 004:   2449 / 3715 loss=2.054, loss_v1=0, loss_v2=0, nll_loss=0.816, ntokens=1085.9, nsentences=120, sample_size=1085.9, sample_size_v1=0, sample_size_v2=0, ppl=1.76, wps=527.2, ups=0.49, wpb=1085.9, bsz=120, num_updates=13570, lr=2.46286e-05, gnorm=3.911, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=27998
2023-06-27 02:06:14 - progress_bar.py[line:272] - INFO: epoch 004:   2459 / 3715 loss=2.051, loss_v1=0, loss_v2=0, nll_loss=0.811, ntokens=1072.3, nsentences=120, sample_size=1072.3, sample_size_v1=0, sample_size_v2=0, ppl=1.75, wps=521.4, ups=0.49, wpb=1072.3, bsz=120, num_updates=13580, lr=2.46233e-05, gnorm=4.031, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=28018
2023-06-27 02:06:35 - progress_bar.py[line:272] - INFO: epoch 004:   2469 / 3715 loss=2.044, loss_v1=0, loss_v2=0, nll_loss=0.804, ntokens=1095.8, nsentences=120, sample_size=1095.8, sample_size_v1=0, sample_size_v2=0, ppl=1.75, wps=526.5, ups=0.48, wpb=1095.8, bsz=120, num_updates=13590, lr=2.46179e-05, gnorm=3.869, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=28039
2023-06-27 02:06:55 - progress_bar.py[line:272] - INFO: epoch 004:   2479 / 3715 loss=2.037, loss_v1=0, loss_v2=0, nll_loss=0.797, ntokens=1070.3, nsentences=120, sample_size=1070.3, sample_size_v1=0, sample_size_v2=0, ppl=1.74, wps=519.9, ups=0.49, wpb=1070.3, bsz=120, num_updates=13600, lr=2.46125e-05, gnorm=3.875, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=28060
2023-06-27 02:07:16 - progress_bar.py[line:272] - INFO: epoch 004:   2489 / 3715 loss=2.044, loss_v1=0, loss_v2=0, nll_loss=0.805, ntokens=1077, nsentences=120, sample_size=1077, sample_size_v1=0, sample_size_v2=0, ppl=1.75, wps=522.9, ups=0.49, wpb=1077, bsz=120, num_updates=13610, lr=2.46072e-05, gnorm=3.856, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=28080
2023-06-27 02:07:36 - progress_bar.py[line:272] - INFO: epoch 004:   2499 / 3715 loss=2.036, loss_v1=0, loss_v2=0, nll_loss=0.795, ntokens=1048, nsentences=120, sample_size=1048, sample_size_v1=0, sample_size_v2=0, ppl=1.73, wps=508.6, ups=0.49, wpb=1048, bsz=120, num_updates=13620, lr=2.46018e-05, gnorm=3.825, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=28101
2023-06-27 02:07:57 - progress_bar.py[line:272] - INFO: epoch 004:   2509 / 3715 loss=2.053, loss_v1=0, loss_v2=0, nll_loss=0.814, ntokens=1068.5, nsentences=120, sample_size=1068.5, sample_size_v1=0, sample_size_v2=0, ppl=1.76, wps=518.7, ups=0.49, wpb=1068.5, bsz=120, num_updates=13630, lr=2.45964e-05, gnorm=4.002, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=28121
2023-06-27 02:08:18 - progress_bar.py[line:272] - INFO: epoch 004:   2519 / 3715 loss=2.053, loss_v1=0, loss_v2=0, nll_loss=0.815, ntokens=1072.6, nsentences=120, sample_size=1072.6, sample_size_v1=0, sample_size_v2=0, ppl=1.76, wps=521.1, ups=0.49, wpb=1072.6, bsz=120, num_updates=13640, lr=2.4591e-05, gnorm=3.942, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=28142
2023-06-27 02:08:38 - progress_bar.py[line:272] - INFO: epoch 004:   2529 / 3715 loss=2.047, loss_v1=0, loss_v2=0, nll_loss=0.806, ntokens=1085.3, nsentences=120, sample_size=1085.3, sample_size_v1=0, sample_size_v2=0, ppl=1.75, wps=527.7, ups=0.49, wpb=1085.3, bsz=120, num_updates=13650, lr=2.45857e-05, gnorm=3.91, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=28163
2023-06-27 02:08:59 - progress_bar.py[line:272] - INFO: epoch 004:   2539 / 3715 loss=2.05, loss_v1=0, loss_v2=0, nll_loss=0.812, ntokens=1106.9, nsentences=120, sample_size=1106.9, sample_size_v1=0, sample_size_v2=0, ppl=1.76, wps=538, ups=0.49, wpb=1106.9, bsz=120, num_updates=13660, lr=2.45803e-05, gnorm=3.717, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=28183
2023-06-27 02:09:19 - progress_bar.py[line:272] - INFO: epoch 004:   2549 / 3715 loss=2.049, loss_v1=0, loss_v2=0, nll_loss=0.81, ntokens=1085.5, nsentences=120, sample_size=1085.5, sample_size_v1=0, sample_size_v2=0, ppl=1.75, wps=527.3, ups=0.49, wpb=1085.5, bsz=120, num_updates=13670, lr=2.45749e-05, gnorm=4.049, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=28204
2023-06-27 02:09:40 - progress_bar.py[line:272] - INFO: epoch 004:   2559 / 3715 loss=2.032, loss_v1=0, loss_v2=0, nll_loss=0.791, ntokens=1070.4, nsentences=120, sample_size=1070.4, sample_size_v1=0, sample_size_v2=0, ppl=1.73, wps=520, ups=0.49, wpb=1070.4, bsz=120, num_updates=13680, lr=2.45696e-05, gnorm=3.935, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=28224
2023-06-27 02:10:01 - progress_bar.py[line:272] - INFO: epoch 004:   2569 / 3715 loss=2.048, loss_v1=0, loss_v2=0, nll_loss=0.808, ntokens=1109.6, nsentences=120, sample_size=1109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.75, wps=539.4, ups=0.49, wpb=1109.6, bsz=120, num_updates=13690, lr=2.45642e-05, gnorm=3.65, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=28245
2023-06-27 02:10:21 - progress_bar.py[line:272] - INFO: epoch 004:   2579 / 3715 loss=2.038, loss_v1=0, loss_v2=0, nll_loss=0.8, ntokens=1073.6, nsentences=120, sample_size=1073.6, sample_size_v1=0, sample_size_v2=0, ppl=1.74, wps=522, ups=0.49, wpb=1073.6, bsz=120, num_updates=13700, lr=2.45588e-05, gnorm=4.132, clip=100, loss_scale=256, train_wall=21, gb_free=8.9, wall=28265
WARNING:torch.distributed.elastic.agent.server.api:Received 2 death signal, shutting down workers
WARNING:torch.distributed.elastic.multiprocessing.api:Sending process 703867 closing signal SIGINT
WARNING:torch.distributed.elastic.multiprocessing.api:Sending process 703868 closing signal SIGINT
WARNING:torch.distributed.elastic.multiprocessing.api:Sending process 703869 closing signal SIGINT
Traceback (most recent call last):
  File "../../train.py", line 539, in <module>
    cli_main()
  File "../../train.py", line 532, in cli_main
    distributed_utils.call_main(cfg, main)
  File "/home/zcai75/Github/OFA/fairseq/fairseq/distributed/utils.py", line 374, in call_main
    distributed_main(cfg.distributed_training.device_id, main, cfg, kwargs)
  File "/home/zcai75/Github/OFA/fairseq/fairseq/distributed/utils.py", line 348, in distributed_main
    main(cfg, **kwargs)
  File "../../train.py", line 199, in main
    valid_losses, should_stop = train(cfg, trainer, task, epoch_itr)
  File "/data/hulab/zcai75/anaconda3/envs/vilt/lib/python3.8/contextlib.py", line 75, in inner
    return func(*args, **kwds)
  File "../../train.py", line 310, in train
    log_output = trainer.train_step(samples)
  File "/data/hulab/zcai75/anaconda3/envs/vilt/lib/python3.8/contextlib.py", line 75, in inner
    return func(*args, **kwds)
  File "/home/zcai75/Github/OFA_forked/trainer.py", line 773, in train_step
    loss, sample_size_i, logging_output = self.task.train_step(
  File "/home/zcai75/Github/OFA_forked/tasks/ofa_task.py", line 338, in train_step
    optimizer.backward(loss)
  File "/home/zcai75/Github/OFA/fairseq/fairseq/optim/fp16_optimizer.py", line 105, in backward
    loss.backward()
  File "/data/hulab/zcai75/anaconda3/envs/vilt/lib/python3.8/site-packages/torch/_tensor.py", line 396, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph, inputs=inputs)
  File "/data/hulab/zcai75/anaconda3/envs/vilt/lib/python3.8/site-packages/torch/autograd/__init__.py", line 173, in backward
    Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
KeyboardInterrupt
Traceback (most recent call last):
  File "../../train.py", line 539, in <module>
    cli_main()
  File "../../train.py", line 532, in cli_main
    distributed_utils.call_main(cfg, main)
  File "/home/zcai75/Github/OFA/fairseq/fairseq/distributed/utils.py", line 374, in call_main
    distributed_main(cfg.distributed_training.device_id, main, cfg, kwargs)
  File "/home/zcai75/Github/OFA/fairseq/fairseq/distributed/utils.py", line 348, in distributed_main
    main(cfg, **kwargs)
  File "../../train.py", line 199, in main
    valid_losses, should_stop = train(cfg, trainer, task, epoch_itr)
  File "/data/hulab/zcai75/anaconda3/envs/vilt/lib/python3.8/contextlib.py", line 75, in inner
    return func(*args, **kwds)
  File "../../train.py", line 310, in train
    log_output = trainer.train_step(samples)
  File "/data/hulab/zcai75/anaconda3/envs/vilt/lib/python3.8/contextlib.py", line 75, in inner
    return func(*args, **kwds)
  File "/home/zcai75/Github/OFA_forked/trainer.py", line 773, in train_step
    loss, sample_size_i, logging_output = self.task.train_step(
  File "/home/zcai75/Github/OFA_forked/tasks/ofa_task.py", line 338, in train_step
    optimizer.backward(loss)
  File "/home/zcai75/Github/OFA/fairseq/fairseq/optim/fp16_optimizer.py", line 105, in backward
    loss.backward()
  File "/data/hulab/zcai75/anaconda3/envs/vilt/lib/python3.8/site-packages/torch/_tensor.py", line 396, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph, inputs=inputs)
  File "/data/hulab/zcai75/anaconda3/envs/vilt/lib/python3.8/site-packages/torch/autograd/__init__.py", line 173, in backward
    Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
KeyboardInterrupt
Traceback (most recent call last):
wandb: Waiting for W&B process to finish... (failed 255). Press Control-C to abort syncing.
  File "../../train.py", line 539, in <module>
    cli_main()
  File "../../train.py", line 532, in cli_main
    distributed_utils.call_main(cfg, main)
  File "/home/zcai75/Github/OFA/fairseq/fairseq/distributed/utils.py", line 374, in call_main
    distributed_main(cfg.distributed_training.device_id, main, cfg, kwargs)
  File "/home/zcai75/Github/OFA/fairseq/fairseq/distributed/utils.py", line 348, in distributed_main
    main(cfg, **kwargs)
  File "../../train.py", line 199, in main
    valid_losses, should_stop = train(cfg, trainer, task, epoch_itr)
  File "/data/hulab/zcai75/anaconda3/envs/vilt/lib/python3.8/contextlib.py", line 75, in inner
    return func(*args, **kwds)
  File "../../train.py", line 310, in train
    log_output = trainer.train_step(samples)
  File "/data/hulab/zcai75/anaconda3/envs/vilt/lib/python3.8/contextlib.py", line 75, in inner
    return func(*args, **kwds)
  File "/home/zcai75/Github/OFA_forked/trainer.py", line 773, in train_step
    loss, sample_size_i, logging_output = self.task.train_step(
  File "/home/zcai75/Github/OFA_forked/tasks/ofa_task.py", line 338, in train_step
    optimizer.backward(loss)
  File "/home/zcai75/Github/OFA/fairseq/fairseq/optim/fp16_optimizer.py", line 105, in backward
    loss.backward()
  File "/data/hulab/zcai75/anaconda3/envs/vilt/lib/python3.8/site-packages/torch/_tensor.py", line 396, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph, inputs=inputs)
  File "/data/hulab/zcai75/anaconda3/envs/vilt/lib/python3.8/site-packages/torch/autograd/__init__.py", line 173, in backward
    Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
KeyboardInterrupt
wandb: 
wandb: Run history:
wandb:                  train/bsz ▁▁▁
wandb:                 train/clip ▁▁▁
wandb:              train/gb_free ▁▁▁
wandb:                train/gnorm ▁██
wandb:                 train/loss █▂▁
wandb:           train/loss_scale ▁▁▁
wandb:              train/loss_v1 ▁▁▁
wandb:              train/loss_v2 ▁▁▁
wandb:                   train/lr █▅▁
wandb:             train/nll_loss █▂▁
wandb:           train/nsentences ▁▁▁
wandb:              train/ntokens ▄█▁
wandb:                  train/ppl █▂▁
wandb:          train/sample_size ▄█▁
wandb:       train/sample_size_v1 ▁▁▁
wandb:       train/sample_size_v2 ▁▁▁
wandb:           train/train_wall ▄▁█
wandb:                  train/ups █▁▁
wandb:                 train/wall ▁▅█
wandb:                  train/wpb ██▁
wandb:                  train/wps █▁▃
wandb:            train_inner/bsz ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:           train_inner/clip ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:        train_inner/gb_free ████████████▁███████████████████████████
wandb:          train_inner/gnorm █▂▁▁▁▂▂▃▃▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▅▄▄▅▄▄▄▄
wandb:           train_inner/loss █▄▃▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     train_inner/loss_scale ▁▁▃███▃▃▃▁▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▁▃▃▃
wandb:        train_inner/loss_v1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:        train_inner/loss_v2 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:             train_inner/lr ▁▂▂▃▄▄▅▆▇▇████████████▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇
wandb:       train_inner/nll_loss █▄▃▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     train_inner/nsentences ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:        train_inner/ntokens ▃▅▃▇▄▃▄▂▃▃▃▃▇▁▄▇▄▇▅▆▆▃▂▂▂▆▂▂▇▄▅▄▄▇▅▃█▂▆▂
wandb:            train_inner/ppl █▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:    train_inner/sample_size ▃▅▃▇▄▃▄▂▃▃▃▃▇▁▄▇▄▇▅▆▆▃▂▂▂▆▂▂▇▄▅▄▄▇▅▃█▂▆▂
wandb: train_inner/sample_size_v1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: train_inner/sample_size_v2 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     train_inner/train_wall ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁█▁▁▁▁
wandb:            train_inner/ups ███████████████████████████████████▁████
wandb:           train_inner/wall ▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇███
wandb:            train_inner/wpb ▃▅▃▇▄▃▄▂▃▃▃▃▇▁▄▇▄▇▅▆▆▃▂▂▂▆▂▂▇▄▅▄▄▇▅▃█▂▆▂
wandb:            train_inner/wps ▆▇▆█▇▆▇▆▇▆▆▆█▆▇█▇█▇▇▇▇▆▆▆▇▆▆█▇▇▇▇█▇▁█▆█▆
wandb: 
wandb: Run summary:
wandb:                  train/bsz 120.0
wandb:                 train/clip 100.0
wandb:              train/gb_free 8.9
wandb:                train/gnorm 3.598
wandb:                 train/loss 2.194
wandb:           train/loss_scale 256.0
wandb:              train/loss_v1 0.0
wandb:              train/loss_v2 0.0
wandb:                   train/lr 3e-05
wandb:             train/nll_loss 0.973
wandb:           train/nsentences 119.996
wandb:              train/ntokens 1083.34
wandb:                  train/ppl 1.96
wandb:          train/sample_size 1083.34
wandb:       train/sample_size_v1 0.0
wandb:       train/sample_size_v2 0.0
wandb:           train/train_wall 7636.0
wandb:                  train/ups 0.48
wandb:                 train/wall 22953.0
wandb:                  train/wpb 1083.3
wandb:                  train/wps 525.2
wandb:            train_inner/bsz 120.0
wandb:           train_inner/clip 100.0
wandb:        train_inner/gb_free 8.9
wandb:          train_inner/gnorm 4.132
wandb:           train_inner/loss 2.038
wandb:     train_inner/loss_scale 256.0
wandb:        train_inner/loss_v1 0.0
wandb:        train_inner/loss_v2 0.0
wandb:             train_inner/lr 2e-05
wandb:       train_inner/nll_loss 0.8
wandb:     train_inner/nsentences 120.0
wandb:        train_inner/ntokens 1073.6
wandb:            train_inner/ppl 1.74
wandb:    train_inner/sample_size 1073.6
wandb: train_inner/sample_size_v1 0.0
wandb: train_inner/sample_size_v2 0.0
wandb:     train_inner/train_wall 21.0
wandb:            train_inner/ups 0.49
wandb:           train_inner/wall 28265.0
wandb:            train_inner/wpb 1073.6
wandb:            train_inner/wps 522.0
wandb: 
wandb: 🚀 View run _16_3e-5_512_rare_balanced_2 at: https://wandb.ai/jackcai1206/OFA-VG/runs/zb18sa9x
wandb: Synced 6 W&B file(s), 0 media file(s), 2 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230626_181917-zb18sa9x/logs
Traceback (most recent call last):
  File "/data/hulab/zcai75/anaconda3/envs/vilt/lib/python3.8/runpy.py", line 194, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File "/data/hulab/zcai75/anaconda3/envs/vilt/lib/python3.8/runpy.py", line 87, in _run_code
    exec(code, run_globals)
  File "/data/hulab/zcai75/anaconda3/envs/vilt/lib/python3.8/site-packages/torch/distributed/launch.py", line 193, in <module>
    main()
  File "/data/hulab/zcai75/anaconda3/envs/vilt/lib/python3.8/site-packages/torch/distributed/launch.py", line 189, in main
    launch(args)
  File "/data/hulab/zcai75/anaconda3/envs/vilt/lib/python3.8/site-packages/torch/distributed/launch.py", line 174, in launch
    run(args)
  File "/data/hulab/zcai75/anaconda3/envs/vilt/lib/python3.8/site-packages/torch/distributed/run.py", line 752, in run
    elastic_launch(
  File "/data/hulab/zcai75/anaconda3/envs/vilt/lib/python3.8/site-packages/torch/distributed/launcher/api.py", line 131, in __call__
    return launch_agent(self._config, self._entrypoint, list(args))
  File "/data/hulab/zcai75/anaconda3/envs/vilt/lib/python3.8/site-packages/torch/distributed/launcher/api.py", line 236, in launch_agent
    result = agent.run()
  File "/data/hulab/zcai75/anaconda3/envs/vilt/lib/python3.8/site-packages/torch/distributed/elastic/metrics/api.py", line 125, in wrapper
    result = f(*args, **kwargs)
  File "/data/hulab/zcai75/anaconda3/envs/vilt/lib/python3.8/site-packages/torch/distributed/elastic/agent/server/api.py", line 709, in run
    result = self._invoke_run(role)
  File "/data/hulab/zcai75/anaconda3/envs/vilt/lib/python3.8/site-packages/torch/distributed/elastic/agent/server/api.py", line 850, in _invoke_run
    time.sleep(monitor_interval)
  File "/data/hulab/zcai75/anaconda3/envs/vilt/lib/python3.8/site-packages/torch/distributed/elastic/multiprocessing/api.py", line 60, in _terminate_process_handler
    raise SignalException(f"Process {os.getpid()} got signal: {sigval}", sigval=sigval)
torch.distributed.elastic.multiprocessing.api.SignalException: Process 703811 got signal: 2
